{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(tar_list):\n",
    "    df_blank = pd.DataFrame({'smiles':[]})\n",
    "    for dataset in tar_list:\n",
    "        df0 = pd.read_csv(os.path.join(DATASET_PATH, dataset))\n",
    "        df_blank =  pd.merge(df_blank, df0, on=SMILES_COLUMN, how='outer')\n",
    "    return df_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_logd_Lip_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17685, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP without json + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_wo_logp_json_logd_Lip_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17603, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of symmetric molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy import stats\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_COLUMN = 'logP'\n",
    "symmetric_rull = lambda values: (len(values) - 1 <= len(values[values % 2 == 0])) or\\\n",
    "(len(values) - 1 <= len(values[(values % 2 == 1) & (values > 1)]))\n",
    "values_list = [pd.Series(Chem.CanonicalRankAtoms(Chem.MolFromSmiles(smiles), breakTies=False)).value_counts()\\\n",
    "               for smiles in\\\n",
    "               dataset_logP[~dataset_logP[VALUE_COLUMN].isna()][SMILES_COLUMN]]\n",
    "symmetric_indices = [symmetric_rull(values) for values in values_list]\n",
    "not_symmetric_indices = [not e for e in symmetric_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_logP[symmetric_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13080"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_logP[not_symmetric_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_COLUMN = 'logD'\n",
    "symmetric_rull = lambda values: (len(values) - 1 <= len(values[values % 2 == 0])) or\\\n",
    "(len(values) - 1 <= len(values[(values % 2 == 1) & (values > 1)]))\n",
    "values_list = [pd.Series(Chem.CanonicalRankAtoms(Chem.MolFromSmiles(smiles), breakTies=False)).value_counts()\\\n",
    "               for smiles in\\\n",
    "               dataset_logD[~dataset_logD[VALUE_COLUMN].isna()][SMILES_COLUMN]]\n",
    "symmetric_indices = [symmetric_rull(values) for values in values_list]\n",
    "not_symmetric_indices = [not e for e in symmetric_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_logD[symmetric_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4133"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_logD[not_symmetric_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logp + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logS']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'esol.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_esol_wo_averaging.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logS = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14043 entries, 0 to 14042\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  14043 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   logS    1058 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 438.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP without json + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logS']\n",
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'esol.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_wo_logp_json_esol_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13960 entries, 0 to 13959\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13960 non-null  object \n",
      " 1   logP    13688 non-null  float64\n",
      " 2   logS    1058 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 436.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logp + FreeSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','Energy']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'freesolv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_FreeSolv_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_Energy = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13940 entries, 0 to 13939\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13940 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   Energy  565 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 435.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP without + json FreeSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','Energy']\n",
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'freesolv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_wo_logp_json_FreeSolv_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13851 entries, 0 to 13850\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13851 non-null  object \n",
      " 1   logP    13688 non-null  float64\n",
      " 2   Energy  565 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 432.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check intersected molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'logd_Lip_wo_averaging.csv','esol.csv', 'freesolv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))\n",
    "dataset_logS = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[2]))\n",
    "dataset_Energy = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C#CCN(C)C(C)Cc1ccccc1</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>C=CCOc1ccccc1OCC(O)CNC(C)C</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>C=CCc1ccccc1OCC(O)CNC(C)C</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>CC(=O)CCCCn1c(=O)c2c(ncn2C)n(C)c1=O</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13529</th>\n",
       "      <td>c1ccc2[nH]ncc2c1</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13619</th>\n",
       "      <td>c1ccc2ccccc2c1</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13620</th>\n",
       "      <td>c1ccc2cnccc2c1</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13628</th>\n",
       "      <td>c1ccc2ncccc2c1</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13630</th>\n",
       "      <td>c1ccc2ncncc2c1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      smiles  logP\n",
       "94                     C#CCN(C)C(C)Cc1ccccc1  2.90\n",
       "440               C=CCOc1ccccc1OCC(O)CNC(C)C  2.10\n",
       "450                C=CCc1ccccc1OCC(O)CNC(C)C  3.10\n",
       "607    CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O  2.60\n",
       "612      CC(=O)CCCCn1c(=O)c2c(ncn2C)n(C)c1=O  0.29\n",
       "...                                      ...   ...\n",
       "13529                       c1ccc2[nH]ncc2c1  1.77\n",
       "13619                         c1ccc2ccccc2c1  3.30\n",
       "13620                         c1ccc2cnccc2c1  2.08\n",
       "13628                         c1ccc2ncccc2c1  2.03\n",
       "13630                         c1ccc2ncncc2c1  1.00\n",
       "\n",
       "[251 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brc1cc(Br)c(Br)cc1Br</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brc1cc(Br)cc(Br)c1</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brc1ccc(Br)cc1</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Brc1cccc(Br)c1</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13649</th>\n",
       "      <td>c1ccoc1</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13658</th>\n",
       "      <td>c1cnc2c(c1)ccc1ncccc12</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13661</th>\n",
       "      <td>c1cnc2ncncc2n1</td>\n",
       "      <td>-0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13670</th>\n",
       "      <td>c1cncnc1</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       smiles  logP\n",
       "0               BrC(Br)(Br)Br  3.42\n",
       "15       Brc1cc(Br)c(Br)cc1Br  5.13\n",
       "19         Brc1cc(Br)cc(Br)c1  4.51\n",
       "26             Brc1ccc(Br)cc1  3.79\n",
       "34             Brc1cccc(Br)c1  3.75\n",
       "...                       ...   ...\n",
       "13649                 c1ccoc1  1.34\n",
       "13650                 c1ccsc1  1.81\n",
       "13658  c1cnc2c(c1)ccc1ncccc12  2.51\n",
       "13661          c1cnc2ncncc2n1 -0.58\n",
       "13670                c1cncnc1 -0.40\n",
       "\n",
       "[786 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_logS[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + FreeSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BrCc1ccccc1</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brc1ccc(Br)cc1</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brc1ccccc1</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>C#CCCC</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>C#CCCCC</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13619</th>\n",
       "      <td>c1ccc2ccccc2c1</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13628</th>\n",
       "      <td>c1ccc2ncccc2c1</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>c1ccccc1</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13647</th>\n",
       "      <td>c1ccncc1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               smiles  logP\n",
       "11        BrCc1ccccc1  2.92\n",
       "26     Brc1ccc(Br)cc1  3.79\n",
       "38         Brc1ccccc1  2.99\n",
       "87             C#CCCC  1.98\n",
       "90            C#CCCCC  2.73\n",
       "...               ...   ...\n",
       "13619  c1ccc2ccccc2c1  3.30\n",
       "13628  c1ccc2ncccc2c1  2.03\n",
       "13644        c1ccccc1  2.13\n",
       "13647        c1ccncc1  0.65\n",
       "13650         c1ccsc1  1.81\n",
       "\n",
       "[402 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_Energy[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_logd_Lip_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_logd_Lip_wo_averaging shape:  (17685, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (12379, 4)\n",
      "\tvalidation: (2653, 4)\n",
      "\ttest: (2653, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_esol_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_esol_wo_averaging shape:  (14043, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9830, 4)\n",
      "\tvalidation: (2107, 4)\n",
      "\ttest: (2106, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_FreeSolv_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_FreeSolv_wo_averaging shape:  (13940, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9758, 4)\n",
      "\tvalidation: (2091, 4)\n",
      "\ttest: (2091, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets with intersected molecules for logP+logD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(tar_list):\n",
    "    df_blank = pd.DataFrame({'smiles':[]})\n",
    "    for dataset in tar_list:\n",
    "        df0 = pd.read_csv(os.path.join(DATASET_PATH, dataset))\n",
    "        df_blank =  pd.merge(df_blank, df0, on=SMILES_COLUMN, how='outer')\n",
    "    return df_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = dataset[~dataset[VALUE_COLUMNS[0]].isna()]\n",
    "dataset_logD = dataset[~dataset[VALUE_COLUMNS[1]].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13777 entries, 0 to 13776\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13777 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   logD    258 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 430.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4166 entries, 95 to 17684\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  4166 non-null   object \n",
      " 1   logP    258 non-null    float64\n",
      " 2   logD    4166 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 130.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "dataset_logP.to_csv(os.path.join(DATASET_PATH, 'logp_258_Lip_wo_averaging'+'.csv'), index = False)\n",
    "dataset_logD.to_csv(os.path.join(DATASET_PATH, 'logd_258_Logp_wo_averaging'+'.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logp wo logp.json + log D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = dataset[~dataset[VALUE_COLUMNS[0]].isna()]\n",
    "dataset_logD = dataset[~dataset[VALUE_COLUMNS[1]].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13688 entries, 0 to 13687\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13688 non-null  object \n",
      " 1   logP    13688 non-null  float64\n",
      " 2   logD    251 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 427.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4166 entries, 94 to 17602\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  4166 non-null   object \n",
      " 1   logP    251 non-null    float64\n",
      " 2   logD    4166 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 130.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "dataset_logP.to_csv(os.path.join(DATASET_PATH, 'logp_wo_logp_json_251_Lip_wo_averaging'+'.csv'), index = False)\n",
    "dataset_logD.to_csv(os.path.join(DATASET_PATH, 'logd_251_logp_wo_logp_json_wo_averaging'+'.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_258_Lip_wo_averaging shape:  (13777, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9643, 3)\n",
      "\tvalidation: (2067, 3)\n",
      "\ttest: (2067, 3)\n",
      "\n",
      "logd_258_Logp_wo_averaging shape:  (4166, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (2916, 3)\n",
      "\tvalidation: (625, 3)\n",
      "\ttest: (625, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = ['logp_258_Lip_wo_averaging', 'logd_258_Logp_wo_averaging']\n",
    "for file in files:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)    \n",
    "    train, validation, test = train_test_validation_split(data)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_logp_json_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']\n",
    "file = 'logp_wo_logp_json_logd_Lip_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17603 entries, 0 to 17602\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  17603 non-null  int64  \n",
      " 1   smiles      17603 non-null  object \n",
      " 2   logP        13688 non-null  float64\n",
      " 3   logD        4166 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 550.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_logD_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogD 0.647\n",
      "Spearman's rho LogP/LogD 0.645\n",
      "Kendall's tau LogP/LogD 0.503\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logp + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logS']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'esol.csv']\n",
    "file = 'logp_esol_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logS = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14043 entries, 0 to 14042\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    14043 non-null  int64  \n",
      " 1   Unnamed: 0.1  14043 non-null  int64  \n",
      " 2   smiles        14043 non-null  object \n",
      " 3   logP          13777 non-null  float64\n",
      " 4   logS          1058 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 548.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_logS_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogS -0.853\n",
      "Spearman's rho LogP/LogS -0.841\n",
      "Kendall's tau LogP/LogS -0.666\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','Energy']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'freesolv.csv']\n",
    "file = 'logp_FreeSolv_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_Energy = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_Energy_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogS 0.427\n",
      "Spearman's rho LogP/LogS 0.453\n",
      "Kendall's tau LogP/LogS 0.306\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of acid groups and amins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']\n",
    "file = 'logp_logd_Lip_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import Fragments\n",
    "from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Amins\n",
    "\n",
    "fr_NH2 - primary amines\n",
    "\n",
    "fr_NH1 - Secondary amines\n",
    "\n",
    "fr_NH0 - Tertiary amines\n",
    "\n",
    "fr_Ar_NH - aromatic amines\n",
    "\n",
    "\n",
    "### Acids\n",
    "\n",
    "fr_COO2 - carboxylic acids\n",
    "\n",
    "fr_COO - carboxylic acids\n",
    "\n",
    "fr_Ar_COO - Aromatic carboxylic acide\n",
    "\n",
    "fr_Al_COO - carboxylic acids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "amins = ['fr_NH2', 'fr_NH1', 'fr_NH0',  'fr_Ar_NH', ]\n",
    "acids = ['fr_COO2', 'fr_COO', 'fr_Ar_COO', 'fr_Al_COO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17685/17685 [00:07<00:00, 2262.09it/s]\n"
     ]
    }
   ],
   "source": [
    "generator = rdDescriptors.RDKit2D(amins+acids)\n",
    "features ={}\n",
    "for feature in amins+acids:\n",
    "    features[feature] = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    feature = dict(zip(amins+acids,generator.process(data[SMILES_COLUMN][i])[1:]))\n",
    "    for feat in feature.keys():\n",
    "        features[feat].append(feature[feat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features.keys():\n",
    "    data[feature] = features[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "      <th>logD</th>\n",
       "      <th>fr_NH2</th>\n",
       "      <th>fr_NH1</th>\n",
       "      <th>fr_NH0</th>\n",
       "      <th>fr_Ar_NH</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_Ar_COO</th>\n",
       "      <th>fr_Al_COO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BrC1C2CC3C(C2)C13</td>\n",
       "      <td>3.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BrC1CC2CCC1C2</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BrC1CCCCC1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BrC=C(Br)Br</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1             smiles  logP  logD  fr_NH2  fr_NH1  \\\n",
       "0           0             0      BrC(Br)(Br)Br  3.42   NaN       0       0   \n",
       "1           1             1  BrC1C2CC3C(C2)C13  3.11   NaN       0       0   \n",
       "2           2             2      BrC1CC2CCC1C2  3.54   NaN       0       0   \n",
       "3           3             3         BrC1CCCCC1  3.20   NaN       0       0   \n",
       "4           4             4        BrC=C(Br)Br  3.20   NaN       0       0   \n",
       "\n",
       "   fr_NH0  fr_Ar_NH  fr_COO2  fr_COO  fr_Ar_COO  fr_Al_COO  \n",
       "0       0         0        0       0          0          0  \n",
       "1       0         0        0       0          0          0  \n",
       "2       0         0        0       0          0          0  \n",
       "3       0         0        0       0          0          0  \n",
       "4       0         0        0       0          0          0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17685 entries, 0 to 17684\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    17685 non-null  int64  \n",
      " 1   Unnamed: 0.1  17685 non-null  int64  \n",
      " 2   smiles        17685 non-null  object \n",
      " 3   logP          13777 non-null  float64\n",
      " 4   logD          4166 non-null   float64\n",
      " 5   fr_NH2        17685 non-null  int64  \n",
      " 6   fr_NH1        17685 non-null  int64  \n",
      " 7   fr_NH0        17685 non-null  int64  \n",
      " 8   fr_Ar_NH      17685 non-null  int64  \n",
      " 9   fr_COO2       17685 non-null  int64  \n",
      " 10  fr_COO        17685 non-null  int64  \n",
      " 11  fr_Ar_COO     17685 non-null  int64  \n",
      " 12  fr_Al_COO     17685 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total fragments']= data[amins+acids].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "      <th>logD</th>\n",
       "      <th>fr_NH2</th>\n",
       "      <th>fr_NH1</th>\n",
       "      <th>fr_NH0</th>\n",
       "      <th>fr_Ar_NH</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_Ar_COO</th>\n",
       "      <th>fr_Al_COO</th>\n",
       "      <th>Total fragments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BrC1C2CC3C(C2)C13</td>\n",
       "      <td>3.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BrC1CC2CCC1C2</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BrC1CCCCC1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BrC=C(Br)Br</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1             smiles  logP  logD  fr_NH2  fr_NH1  \\\n",
       "0           0             0      BrC(Br)(Br)Br  3.42   NaN       0       0   \n",
       "1           1             1  BrC1C2CC3C(C2)C13  3.11   NaN       0       0   \n",
       "2           2             2      BrC1CC2CCC1C2  3.54   NaN       0       0   \n",
       "3           3             3         BrC1CCCCC1  3.20   NaN       0       0   \n",
       "4           4             4        BrC=C(Br)Br  3.20   NaN       0       0   \n",
       "\n",
       "   fr_NH0  fr_Ar_NH  fr_COO2  fr_COO  fr_Ar_COO  fr_Al_COO  Total fragments  \n",
       "0       0         0        0       0          0          0                0  \n",
       "1       0         0        0       0          0          0                0  \n",
       "2       0         0        0       0          0          0                0  \n",
       "3       0         0        0       0          0          0                0  \n",
       "4       0         0        0       0          0          0                0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecule with acids or amins group  in LogP+LogD dataset =  14819 ;  83.8 % of all data\n",
      "Number of molecule with acids or amins group  in LogD dataset =  4066 ;  97.6 % of all data\n",
      "Number of molecule with acids or amins group  in LogP dataset =  10993 ;  79.8 % of all data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-d3a88120d2bb>:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]), '; ', \\\n",
      "<ipython-input-51-d3a88120d2bb>:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])])/len(dataset_logD)*100,1), '% of all data')\n",
      "<ipython-input-51-d3a88120d2bb>:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])]), '; ', \\\n",
      "<ipython-input-51-d3a88120d2bb>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])])/len(dataset_logP)*100,1), '% of all data')\n"
     ]
    }
   ],
   "source": [
    "print('Number of molecule with acids or amins group  in LogP+LogD dataset = ', len(data[data['Total fragments']>0]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0])/len(data)*100,1), '% of all data')\n",
    "\n",
    "print('Number of molecule with acids or amins group  in LogD dataset = ', \\\n",
    "      len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])])/len(dataset_logD)*100,1), '% of all data')\n",
    "\n",
    "print('Number of molecule with acids or amins group  in LogP dataset = ', \\\n",
    "      len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])])/len(dataset_logP)*100,1), '% of all data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
