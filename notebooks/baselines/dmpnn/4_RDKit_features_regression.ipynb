{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriptastorus.descriptors import rdNormalizedDescriptors\n",
    "from rdkit import Chem\n",
    "import logging\n",
    "\n",
    "# make the normalized descriptor generator\n",
    "generator = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "generator.columns # list of tuples:  (descriptor_name, numpytype) ...\n",
    "\n",
    "# features = generator.process(smiles)\n",
    "# features[0] is True/False if the smiles could be processed correcty\n",
    "# features[1:] are the normalized descriptors as described in generator.columns\n",
    "\n",
    "# example for converting a smiles string into the values\n",
    "def rdkit_2d_normalized_features(smiles: str):\n",
    "    # n.b. the first element is true/false if the descriptors were properly computed\n",
    "    results = generator.process(smiles)\n",
    "    processed, features = results[0], results[1:]\n",
    "    if processed is None:\n",
    "       logging.warning(\"Unable to process smiles %s\", smiles)\n",
    "    # if processed is None, the features are are default values for the type\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_COLUMN = 'Absolute Error'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMN = 'logP'\n",
    "PREDS_COLUMN = 'logP_pred'\n",
    "\n",
    "DATASET_INPUT_PATH = '../../../data/3_final_data/split_data'\n",
    "\n",
    "DATASET_OUTPUT_PATH = '../../../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_train.csv'))\n",
    "val_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_validation.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataframe(df):\n",
    "    import numpy as np\n",
    "    rdkit_table = []\n",
    "    features_names = [gen[0] for gen in generator.columns]\n",
    "    smiles_index_dict = {}\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        smiles = df.iloc[i][SMILES_COLUMN]\n",
    "        logP = df.iloc[i][VALUE_COLUMN]\n",
    "        features = {features_names[j]:feature for j,feature in enumerate(rdkit_2d_normalized_features(smiles))}\n",
    "        features[SMILES_COLUMN] = smiles\n",
    "        features[VALUE_COLUMN] = logP\n",
    "        rdkit_table.append(features)\n",
    "        smiles_index_dict[smiles]=i\n",
    "    rdkit_features = pd.DataFrame(rdkit_table)\n",
    "    return rdkit_features, smiles_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9643/9643 [05:39<00:00, 28.38it/s]\n",
      "100%|██████████| 2067/2067 [01:13<00:00, 28.15it/s]\n",
      "100%|██████████| 2067/2067 [01:13<00:00, 28.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_rdkit, train_smiles_dict = create_feature_dataframe(train_data)\n",
    "val_data_rdkit, val_smiles_dict = create_feature_dataframe(val_data)\n",
    "test_data_rdkit, test_smiles_dict = create_feature_dataframe(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_train_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_train_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(train_smiles_dict, f)\n",
    "val_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_val_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_val_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(val_smiles_dict, f)\n",
    "test_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_test_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_test_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(test_smiles_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_COLUMN = 'logP'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "\n",
    "DATA_PATH = '../../../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_train_drkit_feat.csv'), index_col=0)\n",
    "val_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_val_drkit_feat.csv'), index_col=0)\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_test_drkit_feat.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[VALUE_COLUMN]\n",
    "X_train = train_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "y_val = val_data[VALUE_COLUMN]\n",
    "X_val = val_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "\n",
    "y_test = test_data[VALUE_COLUMN]\n",
    "X_test = test_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSE = 0.550378750673703\n",
      "Valid R2-score is 0.9101585772785692\n",
      "Test RMSE = 0.5765899578624547\n",
      "Test R2-score is 0.9012773315417384\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds, squared=False))\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds, squared=False))\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = features\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]\n",
    "with open(os.path.join(DATA_PATH,'experiments_result'),'w') as f:\n",
    "    f.write(df_20_most_important.reset_index(drop=True).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=10, max_iter=100, warm_start=True, early_stopping = True, solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alisa.Alenicheva/anaconda3/envs/chemprop/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, max_iter=100, random_state=10, solver='lbfgs',\n",
       "             warm_start=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = regr.predict(X_test_scaled)\n",
    "val_preds = regr.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSE = 0.5670377404502589\n",
      "Valid R2-score is 0.9046375862326349\n",
      "Test RMSE = 0.5642646297928993\n",
      "Test R2-score is 0.9054528606765462\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds, squared=False))\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds, squared=False))\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
