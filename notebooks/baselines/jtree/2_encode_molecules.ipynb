{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get encoded atoms logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../../../icml18-jtnn')\n",
    "sys.path.append('../../../../../icml18-jtnn/jtnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_PATH = '../../../../../icml18-jtnn/data/zinc/vocab.txt'\n",
    "MODEL_PATH = '../../../../../icml18-jtnn/molvae'\n",
    "DATASET_PATH = '../../../data/3_final_data/split_data'\n",
    "\n",
    "RAW_PATH = '../../../data/raw/baselines/jtree'\n",
    "\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMN = 'logP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math, random, sys\n",
    "from optparse import OptionParser\n",
    "from collections import deque\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "\n",
    "from jtnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(VOCAB_PATH)] \n",
    "vocab = Vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = int(450)\n",
    "latent_size = int(56)\n",
    "depth = int(3)\n",
    "stereo = True if int(1) == 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mol/anaconda3/envs/jtree/lib/python2.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth, stereo=stereo)\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, 'MPNVAE-h450-L56-d3-beta0.001/model.iter-4')))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_train.csv'), index_col=0)\n",
    "dataset_val = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_validation.csv'), index_col=0)\n",
    "dataset_test = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latent_representation_dataset(df, SMILES_COLUMN, VALUE_COLUMN):\n",
    "    import numpy as np    \n",
    "    vectors = []\n",
    "    broken_smiles = {}\n",
    "    for smiles in tqdm(df[SMILES_COLUMN].values):\n",
    "        try:\n",
    "            latent_representation = model.encode_latent_mean([smiles])\n",
    "        except (KeyError, RuntimeError), e:\n",
    "            broken_smiles[smiles]=e\n",
    "            continue\n",
    "        vectors.append(latent_representation.cpu().detach().numpy())\n",
    "    X = np.array(vectors)\n",
    "    y = df[~df[SMILES_COLUMN].isin(list(broken_smiles.keys()))][VALUE_COLUMN].values\n",
    "    assert len(X)==len(y)\n",
    "    return X, y, broken_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_errs = create_latent_representation_dataset(dataset_train, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'X_train.npy'), 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "with open(os.path.join(RAW_PATH,'y_train.npy'), 'wb') as f:\n",
    "    np.save(f,y_train)   \n",
    "X_val, y_val, val_errs = create_latent_representation_dataset(dataset_val, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'X_val.npy'), 'wb') as f:\n",
    "    np.save(f,X_val)\n",
    "with open(os.path.join(RAW_PATH,'y_val.npy'), 'wb') as f:\n",
    "    np.save(f,y_val)   \n",
    "X_test, y_test, test_errs = create_latent_representation_dataset(dataset_test, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'X_test.npy'), 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "with open(os.path.join(RAW_PATH,'y_test.npy'), 'wb') as f:\n",
    "    np.save(f,y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'train_errs.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(list(train_errs.keys())))\n",
    "with open(os.path.join(RAW_PATH,'val_errs.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(list(val_errs.keys())))\n",
    "with open(os.path.join(RAW_PATH,'test_errs.json'), 'w') as f:\n",
    "    f.write('\\n'.join(list(test_errs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get encoded atoms logD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_PATH = '../../../../../icml18-jtnn/data/zinc/vocab.txt'\n",
    "MODEL_PATH = '../../../../../icml18-jtnn/molvae'\n",
    "DATASET_PATH = '../../../data/3_final_data/split_data'\n",
    "\n",
    "RAW_PATH = '../../../data/raw/baselines/jtree'\n",
    "\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMN = 'logD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math, random, sys\n",
    "from optparse import OptionParser\n",
    "from collections import deque\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "\n",
    "from jtnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(VOCAB_PATH)] \n",
    "vocab = Vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = int(450)\n",
    "latent_size = int(56)\n",
    "depth = int(3)\n",
    "stereo = True if int(1) == 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mol/anaconda3/envs/jtree/lib/python2.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth, stereo=stereo)\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, 'MPNVAE-h450-L56-d3-beta0.001/model.iter-4')))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(os.path.join(DATASET_PATH, 'logd_Lip_wo_averaging_train.csv'), index_col=0)\n",
    "dataset_val = pd.read_csv(os.path.join(DATASET_PATH, 'logd_Lip_wo_averaging_validation.csv'), index_col=0)\n",
    "dataset_test = pd.read_csv(os.path.join(DATASET_PATH, 'logd_Lip_wo_averaging_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latent_representation_dataset(df, SMILES_COLUMN, VALUE_COLUMN):\n",
    "    import numpy as np    \n",
    "    vectors = []\n",
    "    broken_smiles = {}\n",
    "    for smiles in tqdm(df[SMILES_COLUMN].values):\n",
    "        try:\n",
    "            latent_representation = model.encode_latent_mean([smiles])\n",
    "        except (KeyError, RuntimeError), e:\n",
    "            broken_smiles[smiles]=e\n",
    "            continue\n",
    "        vectors.append(latent_representation.cpu().detach().numpy())\n",
    "    X = np.array(vectors)\n",
    "    y = df[~df[SMILES_COLUMN].isin(list(broken_smiles.keys()))][VALUE_COLUMN].values\n",
    "    assert len(X)==len(y)\n",
    "    return X, y, broken_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2916/2916 [06:06<00:00,  7.95it/s]\n",
      "100%|██████████| 625/625 [01:21<00:00,  7.70it/s]\n",
      "100%|██████████| 625/625 [01:15<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, train_errs = create_latent_representation_dataset(dataset_train, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_X_train.npy'), 'wb') as f:\n",
    "    np.save(f,X_train)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_y_train.npy'), 'wb') as f:\n",
    "    np.save(f,y_train)   \n",
    "X_val, y_val, val_errs = create_latent_representation_dataset(dataset_val, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_X_val.npy'), 'wb') as f:\n",
    "    np.save(f,X_val)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_y_val.npy'), 'wb') as f:\n",
    "    np.save(f,y_val)   \n",
    "X_test, y_test, test_errs = create_latent_representation_dataset(dataset_test, SMILES_COLUMN, VALUE_COLUMN)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_X_test.npy'), 'wb') as f:\n",
    "    np.save(f,X_test)\n",
    "with open(os.path.join(RAW_PATH,'logd_Lip_y_test.npy'), 'wb') as f:\n",
    "    np.save(f,y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'train_errs.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(list(train_errs.keys())))\n",
    "with open(os.path.join(RAW_PATH,'val_errs.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(list(val_errs.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'test_errs.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(list(test_errs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add logP errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_train.csv'), index_col=0)\n",
    "dataset_val = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_validation.csv'), index_col=0)\n",
    "dataset_test = pd.read_csv(os.path.join(DATASET_PATH, 'logp_wo_averaging_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9643/9643 [38:36<00:00,  4.16it/s]  \n",
      "100%|██████████| 2067/2067 [07:53<00:00,  4.36it/s] \n",
      "100%|██████████| 2067/2067 [07:47<00:00,  4.42it/s] \n"
     ]
    }
   ],
   "source": [
    "VALUE_COLUMN = 'logP'\n",
    "X_train, y_train, train_errs = create_latent_representation_dataset(dataset_train, SMILES_COLUMN, VALUE_COLUMN)\n",
    "X_val, y_val, val_errs = create_latent_representation_dataset(dataset_val, SMILES_COLUMN, VALUE_COLUMN)   \n",
    "X_test, y_test, test_errs = create_latent_representation_dataset(dataset_test, SMILES_COLUMN, VALUE_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'train_errs.txt'), 'a') as f:\n",
    "    f.write('\\n')\n",
    "    f.write('\\n'.join(list(train_errs.keys())))\n",
    "with open(os.path.join(RAW_PATH,'val_errs.txt'), 'a') as f:\n",
    "    f.write('\\n')\n",
    "    f.write('\\n'.join(list(val_errs.keys())))\n",
    "with open(os.path.join(RAW_PATH,'test_errs.txt'), 'a') as f:\n",
    "    f.write('\\n')\n",
    "    f.write('\\n'.join(list(test_errs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get molecules which can be encoded from our ZINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_PATH = '../../../../icml18-jtnn/data/zinc/vocab.txt'\n",
    "DATA_PATH = '../../../../icml18-jtnn/data/zinc'\n",
    "\n",
    "RAW_PATH = '../../../data/raw/baselines/jtree'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math, random, sys\n",
    "from optparse import OptionParser\n",
    "from collections import deque\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "\n",
    "from jtnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0740694e827a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r\\n \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Vocab' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(VOCAB_PATH)] \n",
    "vocab = Vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = int(450)\n",
    "latent_size = int(56)\n",
    "depth = int(3)\n",
    "stereo = True if int(1) == 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth, stereo=stereo)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILES = [x.strip(\"\\r\\n \") for x in open(os.path.join(DATA_PATH, 'all.txt'))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10502/1999870 [11:00<34:36:52, 15.96it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np    \n",
    "broken_smiles = {}\n",
    "ok_smiles = []\n",
    "for smiles in tqdm(SMILES):\n",
    "    try:\n",
    "        latent_representation = model.encode_latent_mean([smiles])\n",
    "    except (KeyError, RuntimeError), e:\n",
    "        broken_smiles[smiles]=e\n",
    "        continue\n",
    "    ok_smiles.append(smiles)\n",
    "print(len(ok_smiles))\n",
    "with open(os.path.join(DATA_PATH, 'all_filtered.txt'),'w') as f:\n",
    "    f.write('\\n'.join(ok_smiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model based on pretrained vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_squared_error\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RAW_PATH = '../../../data/raw/baselines/jtree'\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(RAW_PATH, 'logs', 'exp_0')\n",
    "os.makedirs(fname)\n",
    "writer = SummaryWriter(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter:',self.counter,' out of ',self.patience)\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print('Validation loss decreased (', round(self.val_loss_min, 6), '-->', round(val_loss, 6),').  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        #Whether y is non-null or not.\n",
    "        is_valid = y**2 > 0\n",
    "        #Loss matrix\n",
    "        loss = criterion(y_pred, y)\n",
    "        #loss matrix after removing null target\n",
    "        # loss_mat = torch.where(is_valid, loss_mat, torch.zeros(loss_mat.shape).to(loss_mat.device).to(loss_mat.dtype))\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        # loss = torch.sum(loss_mat)/torch.sum(is_valid)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def eval(model, loader, scaler, device,  train = False):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "\n",
    "        y_true.append(y.squeeze())\n",
    "        if train:\n",
    "            y_scores.append(pred.squeeze())\n",
    "        else:\n",
    "            y_scores.append(torch.Tensor(scaler.inverse_transform(pred.squeeze().cpu())))\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).cpu().numpy()\n",
    "    y_scores = torch.cat(y_scores, dim = 0).cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_true, y_scores)\n",
    "    rmse = mean_squared_error(y_true, y_scores)**0.5\n",
    "\n",
    "    return r2, rmse #y_true.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, H, D_out = 56, 100, 1\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'X_train.npy'), 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "with open(os.path.join(RAW_PATH,'y_train.npy'), 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "    \n",
    "X_train = torch.Tensor(X_train) # transform to torch tensor\n",
    "# y_train = torch.Tensor(y_train)\n",
    "\n",
    "y_train_transformed = torch.Tensor(scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1))\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train,y_train_transformed), batch_size = 32) # create your dataloader\n",
    "    \n",
    "with open(os.path.join(RAW_PATH,'X_val.npy'), 'rb') as f:\n",
    "    X_val = np.load(f)\n",
    "with open(os.path.join(RAW_PATH,'y_val.npy'), 'rb') as f:\n",
    "    y_val = np.load(f)\n",
    "    \n",
    "X_val = torch.Tensor(X_val) # transform to torch tensor\n",
    "y_val = torch.Tensor(y_val)\n",
    "\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size = 32) # create your dataloader\n",
    "\n",
    "with open(os.path.join(RAW_PATH,'X_test.npy'), 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open(os.path.join(RAW_PATH,'y_test.npy'), 'rb') as f:\n",
    "    y_test = np.load(f)\n",
    "    \n",
    "X_test = torch.Tensor(X_test) # transform to torch tensor\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size = 32) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=50, verbose=True, path=os.path.join(fname, 'chkpnt' + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 361.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.40it/s]\n",
      "Iteration:  33%|███▎      | 98/295 [00:00<00:00, 973.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 932.10it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 566.57it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 565.53it/s]\n",
      "Iteration:  12%|█▏        | 34/295 [00:00<00:00, 336.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.048476\n",
      "train rmse: 0.975461\n",
      " val r2: 0.037040\n",
      " val rmse: 1.789631\n",
      "test r2: 0.056633\n",
      "test rmse: 1.773488\n",
      "('Validation loss decreased (', inf, '-->', 1.789631, ').  Saving model ...')\n",
      "\n",
      "====epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 340.71it/s]\n",
      "Iteration:  35%|███▌      | 104/295 [00:00<00:00, 1039.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1107.84it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 978.64it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 987.18it/s]\n",
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 372.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.053232\n",
      "train rmse: 0.973020\n",
      " val r2: 0.041596\n",
      " val rmse: 1.785392\n",
      "test r2: 0.059655\n",
      "test rmse: 1.770644\n",
      "('Validation loss decreased (', 1.789631, '-->', 1.785392, ').  Saving model ...')\n",
      "\n",
      "====epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.26it/s]\n",
      "Iteration:  42%|████▏     | 124/295 [00:00<00:00, 1238.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.00it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1018.49it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 561.71it/s]\n",
      "Iteration:  13%|█▎        | 37/295 [00:00<00:00, 366.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054364\n",
      "train rmse: 0.972438\n",
      " val r2: 0.042513\n",
      " val rmse: 1.784537\n",
      "test r2: 0.059099\n",
      "test rmse: 1.771168\n",
      "('Validation loss decreased (', 1.785392, '-->', 1.784537, ').  Saving model ...')\n",
      "\n",
      "====epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.64it/s]\n",
      "Iteration:  43%|████▎     | 127/295 [00:00<00:00, 1251.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1113.30it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 565.94it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 563.98it/s]\n",
      "Iteration:  13%|█▎        | 37/295 [00:00<00:00, 362.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.053494\n",
      "train rmse: 0.972886\n",
      " val r2: 0.040913\n",
      " val rmse: 1.786027\n",
      "test r2: 0.056788\n",
      "test rmse: 1.773342\n",
      "('EarlyStopping counter:', 1, ' out of ', 50)\n",
      "\n",
      "====epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.19it/s]\n",
      "Iteration:  44%|████▍     | 131/295 [00:00<00:00, 1309.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1115.77it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 558.35it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 564.55it/s]\n",
      "Iteration:  12%|█▏        | 36/295 [00:00<00:00, 359.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.053537\n",
      "train rmse: 0.972863\n",
      " val r2: 0.040399\n",
      " val rmse: 1.786506\n",
      "test r2: 0.055906\n",
      "test rmse: 1.774171\n",
      "('EarlyStopping counter:', 2, ' out of ', 50)\n",
      "\n",
      "====epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 360.47it/s]\n",
      "Iteration:  43%|████▎     | 126/295 [00:00<00:00, 1251.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1111.95it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 561.21it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 569.85it/s]\n",
      "Iteration:  13%|█▎        | 39/295 [00:00<00:00, 383.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054282\n",
      "train rmse: 0.972480\n",
      " val r2: 0.040908\n",
      " val rmse: 1.786033\n",
      "test r2: 0.055922\n",
      "test rmse: 1.774156\n",
      "('EarlyStopping counter:', 3, ' out of ', 50)\n",
      "\n",
      "====epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.27it/s]\n",
      "Iteration:  38%|███▊      | 112/295 [00:00<00:00, 1115.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 936.40it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 560.35it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 566.74it/s]\n",
      "Iteration:  14%|█▍        | 41/295 [00:00<00:00, 406.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054010\n",
      "train rmse: 0.972620\n",
      " val r2: 0.040521\n",
      " val rmse: 1.786393\n",
      "test r2: 0.055221\n",
      "test rmse: 1.774814\n",
      "('EarlyStopping counter:', 4, ' out of ', 50)\n",
      "\n",
      "====epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.88it/s]\n",
      "Iteration:  40%|████      | 119/295 [00:00<00:00, 1173.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1115.61it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1017.86it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 568.12it/s]\n",
      "Iteration:  14%|█▎        | 40/295 [00:00<00:00, 399.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054677\n",
      "train rmse: 0.972277\n",
      " val r2: 0.041272\n",
      " val rmse: 1.785693\n",
      "test r2: 0.055894\n",
      "test rmse: 1.774182\n",
      "('EarlyStopping counter:', 5, ' out of ', 50)\n",
      "\n",
      "====epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.02it/s]\n",
      "Iteration:  42%|████▏     | 124/295 [00:00<00:00, 1235.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1118.71it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 996.26it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 549.86it/s]\n",
      "Iteration:  12%|█▏        | 36/295 [00:00<00:00, 350.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054519\n",
      "train rmse: 0.972358\n",
      " val r2: 0.040989\n",
      " val rmse: 1.785957\n",
      "test r2: 0.055353\n",
      "test rmse: 1.774691\n",
      "('EarlyStopping counter:', 6, ' out of ', 50)\n",
      "\n",
      "====epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.66it/s]\n",
      "Iteration:  44%|████▍     | 131/295 [00:00<00:00, 1304.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1118.93it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 973.12it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1016.07it/s]\n",
      "Iteration:  14%|█▍        | 42/295 [00:00<00:00, 418.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054721\n",
      "train rmse: 0.972255\n",
      " val r2: 0.041359\n",
      " val rmse: 1.785613\n",
      "test r2: 0.055256\n",
      "test rmse: 1.774781\n",
      "('EarlyStopping counter:', 7, ' out of ', 50)\n",
      "\n",
      "====epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.89it/s]\n",
      "Iteration:  38%|███▊      | 112/295 [00:00<00:00, 1114.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.44it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 550.86it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1014.92it/s]\n",
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 372.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054269\n",
      "train rmse: 0.972487\n",
      " val r2: 0.040955\n",
      " val rmse: 1.785989\n",
      "test r2: 0.054563\n",
      "test rmse: 1.775432\n",
      "('EarlyStopping counter:', 8, ' out of ', 50)\n",
      "\n",
      "====epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.78it/s]\n",
      "Iteration:  40%|████      | 118/295 [00:00<00:00, 1168.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 937.69it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 560.96it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1005.91it/s]\n",
      "Iteration:  13%|█▎        | 39/295 [00:00<00:00, 389.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.053570\n",
      "train rmse: 0.972846\n",
      " val r2: 0.040230\n",
      " val rmse: 1.786664\n",
      "test r2: 0.053744\n",
      "test rmse: 1.776201\n",
      "('EarlyStopping counter:', 9, ' out of ', 50)\n",
      "\n",
      "====epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.73it/s]\n",
      "Iteration:  37%|███▋      | 110/295 [00:00<00:00, 1083.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 938.26it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 559.59it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 565.12it/s]\n",
      "Iteration:  13%|█▎        | 39/295 [00:00<00:00, 383.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.053809\n",
      "train rmse: 0.972723\n",
      " val r2: 0.040348\n",
      " val rmse: 1.786554\n",
      "test r2: 0.053835\n",
      "test rmse: 1.776116\n",
      "('EarlyStopping counter:', 10, ' out of ', 50)\n",
      "\n",
      "====epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.94it/s]\n",
      "Iteration:  39%|███▉      | 115/295 [00:00<00:00, 1148.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 935.59it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 566.36it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 557.71it/s]\n",
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 369.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054004\n",
      "train rmse: 0.972623\n",
      " val r2: 0.040386\n",
      " val rmse: 1.786519\n",
      "test r2: 0.054264\n",
      "test rmse: 1.775713\n",
      "('EarlyStopping counter:', 11, ' out of ', 50)\n",
      "\n",
      "====epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 479.81it/s]\n",
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1796.17it/s]\n",
      "Iteration:   0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1025.74it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1010.77it/s]\n",
      "Iteration:  16%|█▋        | 48/295 [00:00<00:00, 472.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055108\n",
      "train rmse: 0.972056\n",
      " val r2: 0.041317\n",
      " val rmse: 1.785652\n",
      "test r2: 0.055277\n",
      "test rmse: 1.774762\n",
      "('EarlyStopping counter:', 12, ' out of ', 50)\n",
      "\n",
      "====epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 413.15it/s]\n",
      "Iteration:  41%|████      | 120/295 [00:00<00:00, 1174.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1116.25it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 977.87it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1019.89it/s]\n",
      "Iteration:  14%|█▎        | 40/295 [00:00<00:00, 391.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054054\n",
      "train rmse: 0.972598\n",
      " val r2: 0.040070\n",
      " val rmse: 1.786813\n",
      "test r2: 0.054168\n",
      "test rmse: 1.775803\n",
      "('EarlyStopping counter:', 13, ' out of ', 50)\n",
      "\n",
      "====epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.17it/s]\n",
      "Iteration:  44%|████▍     | 131/295 [00:00<00:00, 1306.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1121.47it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1004.16it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1008.78it/s]\n",
      "Iteration:  12%|█▏        | 36/295 [00:00<00:00, 358.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054293\n",
      "train rmse: 0.972475\n",
      " val r2: 0.040103\n",
      " val rmse: 1.786782\n",
      "test r2: 0.054466\n",
      "test rmse: 1.775523\n",
      "('EarlyStopping counter:', 14, ' out of ', 50)\n",
      "\n",
      "====epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 362.04it/s]\n",
      "Iteration:  46%|████▌     | 136/295 [00:00<00:00, 1341.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.35it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 565.68it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 564.46it/s]\n",
      "Iteration:  14%|█▍        | 41/295 [00:00<00:00, 408.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.054830\n",
      "train rmse: 0.972198\n",
      " val r2: 0.040217\n",
      " val rmse: 1.786676\n",
      "test r2: 0.054911\n",
      "test rmse: 1.775105\n",
      "('EarlyStopping counter:', 15, ' out of ', 50)\n",
      "\n",
      "====epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.36it/s]\n",
      "Iteration:  43%|████▎     | 126/295 [00:00<00:00, 1243.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.99it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 563.29it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1016.59it/s]\n",
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 372.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055903\n",
      "train rmse: 0.971646\n",
      " val r2: 0.041000\n",
      " val rmse: 1.785947\n",
      "test r2: 0.056139\n",
      "test rmse: 1.773952\n",
      "('EarlyStopping counter:', 16, ' out of ', 50)\n",
      "\n",
      "====epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.84it/s]\n",
      "Iteration:  38%|███▊      | 113/295 [00:00<00:00, 1125.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1115.67it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 566.01it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 567.53it/s]\n",
      "Iteration:  13%|█▎        | 39/295 [00:00<00:00, 374.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055210\n",
      "train rmse: 0.972003\n",
      " val r2: 0.040161\n",
      " val rmse: 1.786728\n",
      "test r2: 0.055315\n",
      "test rmse: 1.774726\n",
      "('EarlyStopping counter:', 17, ' out of ', 50)\n",
      "\n",
      "====epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 385.96it/s]\n",
      "Iteration:  47%|████▋     | 138/295 [00:00<00:00, 1378.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.04it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1013.59it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 566.44it/s]\n",
      "Iteration:  13%|█▎        | 38/295 [00:00<00:00, 366.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055070\n",
      "train rmse: 0.972075\n",
      " val r2: 0.040191\n",
      " val rmse: 1.786700\n",
      "test r2: 0.055014\n",
      "test rmse: 1.775008\n",
      "('EarlyStopping counter:', 18, ' out of ', 50)\n",
      "\n",
      "====epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.31it/s]\n",
      "Iteration:  42%|████▏     | 125/295 [00:00<00:00, 1242.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 1117.33it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 564.99it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 1023.18it/s]\n",
      "Iteration:  13%|█▎        | 37/295 [00:00<00:00, 365.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055823\n",
      "train rmse: 0.971688\n",
      " val r2: 0.041456\n",
      " val rmse: 1.785522\n",
      "test r2: 0.056057\n",
      "test rmse: 1.774029\n",
      "('EarlyStopping counter:', 19, ' out of ', 50)\n",
      "\n",
      "====epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 361.44it/s]\n",
      "Iteration:  39%|███▉      | 115/295 [00:00<00:00, 1147.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 295/295 [00:00<00:00, 941.92it/s] \n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 561.44it/s]\n",
      "Iteration: 100%|██████████| 64/64 [00:00<00:00, 561.24it/s]\n",
      "Iteration:  12%|█▏        | 34/295 [00:00<00:00, 337.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 0.055955\n",
      "train rmse: 0.971620\n",
      " val r2: 0.041619\n",
      " val rmse: 1.785370\n",
      "test r2: 0.056788\n",
      "test rmse: 1.773341\n",
      "('EarlyStopping counter:', 20, ' out of ', 50)\n",
      "\n",
      "====epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  37%|███▋      | 109/295 [00:00<00:00, 347.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-a7388332ea38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====epoch \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-343ec3813921>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mol/anaconda3/envs/jtree/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "        print(\"====epoch \" + str(epoch))\n",
    "        \n",
    "        train(model, train_loader, optimizer, device)\n",
    "\n",
    "        print(\"====Evaluation\")\n",
    "\n",
    "        train_r2, train_rmse = eval(model, train_loader, scaler,device,  train = True)\n",
    "        \n",
    "        val_r2, val_rmse = eval(model, val_loader, scaler, device)\n",
    "        test_r2, test_rmse = eval( model, test_loader, scaler, device)\n",
    "\n",
    "        print(\"train r2: %f\\ntrain rmse: %f\\n val r2: %f\\n val rmse: %f\\ntest r2: %f\\ntest rmse: %f\"\\\n",
    "              %(train_r2, train_rmse, val_r2, val_rmse, test_r2, test_rmse))\n",
    "\n",
    "        # val_acc_list.append(val_acc)\n",
    "        # test_acc_list.append(test_acc)\n",
    "        # train_acc_list.append(train_acc)\n",
    "\n",
    "#         if not args.filename == \"\":\n",
    "        writer.add_scalar('data/train r2', train_r2, epoch)\n",
    "        writer.add_scalar('data/train rmse', train_rmse, epoch)\n",
    "\n",
    "        writer.add_scalar('data/val r2', val_r2, epoch)\n",
    "        writer.add_scalar('data/val rmse', val_rmse, epoch)\n",
    "        writer.add_scalar('data/test r2', test_r2, epoch)\n",
    "        writer.add_scalar('data/test rmse', test_rmse, epoch)\n",
    "\n",
    "        early_stopping(val_rmse, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RAW_PATH,'X_train.npy'), 'rb') as f:\n",
    "    X_train = np.load(f).squeeze()\n",
    "with open(os.path.join(RAW_PATH,'y_train.npy'), 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "    \n",
    "y_train_transformed = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "with open(os.path.join(RAW_PATH,'X_val.npy'), 'rb') as f:\n",
    "    X_val = np.load(f).squeeze()\n",
    "with open(os.path.join(RAW_PATH,'y_val.npy'), 'rb') as f:\n",
    "    y_val = np.load(f)\n",
    "\n",
    "with open(os.path.join(RAW_PATH,'X_test.npy'), 'rb') as f:\n",
    "    X_test = np.load(f).squeeze()\n",
    "with open(os.path.join(RAW_PATH,'y_test.npy'), 'rb') as f:\n",
    "    y_test = np.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with whole vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = scaler.inverse_transform(model.predict(X_test))\n",
    "val_preds = scaler.inverse_transform(model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Valid RMSE =', 0.905357986166681)\n",
      "Valid R2-score is 0.753553741911\n",
      "('Test RMSE =', 0.9247779104382)\n",
      "Test R2-score is 0.743492953339\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds)**0.5)\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds)**0.5)\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "features = list(range(X_train.shape[1]))\n",
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])\n",
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = [str(i)+ '_tree_feats' for i in range(X_train.shape[1]//2)] +\\\n",
    "                    [str(i)+ '_graph_feats' for i in range(X_train.shape[1]//2, X_train.shape[1])]\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_most_important = pd.read_csv(os.path.join(RAW_PATH,'experiments_result.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 2_tree_feats | 0.13753037 |\n",
      "| 17_tree_feats | 0.11225141 |\n",
      "| 22_tree_feats | 0.061198685 |\n",
      "| 27_tree_feats | 0.040304124 |\n",
      "| 21_tree_feats | 0.03701255 |\n",
      "| 10_tree_feats | 0.029927588999999997 |\n",
      "| 16_tree_feats | 0.026088234 |\n",
      "| 32_graph_feats | 0.02460154 |\n",
      "| 3_tree_feats | 0.024430856 |\n",
      "| 24_tree_feats | 0.02399634 |\n",
      "| 42_graph_feats | 0.021596342 |\n",
      "| 26_tree_feats | 0.021326277 |\n",
      "| 1_tree_feats | 0.021274897999999997 |\n",
      "| 19_tree_feats | 0.018548844 |\n",
      "| 15_tree_feats | 0.017468281000000002 |\n",
      "| 29_graph_feats | 0.01733831 |\n",
      "| 36_graph_feats | 0.015398215 |\n",
      "| 8_tree_feats | 0.014655213 |\n",
      "| 12_tree_feats | 0.014508405 |\n",
      "| 13_tree_feats | 0.013611487 |\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_20_most_important)):\n",
    "    print '|', df_20_most_important.iloc[i]['feature name'], '|', df_20_most_important.iloc[i]['feature importance'], '|'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with tree features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[:, :X_train.shape[1]//2], y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = scaler.inverse_transform(model.predict(X_test[:, :X_train.shape[1]//2]))\n",
    "val_preds = scaler.inverse_transform(model.predict(X_val[:, :X_train.shape[1]//2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Valid RMSE =', 0.9402256664953701)\n",
      "Valid R2-score is 0.734205640941\n",
      "('Test RMSE =', 0.9550508773345758)\n",
      "Test R2-score is 0.726424361726\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds)**0.5)\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds)**0.5)\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])\n",
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = [str(i)+ '_tree_feats' for i in range(X_train.shape[1]//2)]\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature importance</th>\n",
       "      <th>feature name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.176946</td>\n",
       "      <td>2_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.152939</td>\n",
       "      <td>17_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.080504</td>\n",
       "      <td>22_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.051779</td>\n",
       "      <td>27_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.047035</td>\n",
       "      <td>21_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037569</td>\n",
       "      <td>3_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.037453</td>\n",
       "      <td>10_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.037348</td>\n",
       "      <td>16_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.031914</td>\n",
       "      <td>24_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.030068</td>\n",
       "      <td>26_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028452</td>\n",
       "      <td>1_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.025844</td>\n",
       "      <td>15_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.024838</td>\n",
       "      <td>19_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.024040</td>\n",
       "      <td>12_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020233</td>\n",
       "      <td>14_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.019516</td>\n",
       "      <td>23_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.019088</td>\n",
       "      <td>13_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019017</td>\n",
       "      <td>8_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016931</td>\n",
       "      <td>9_tree_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016481</td>\n",
       "      <td>5_tree_feats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature importance   feature name\n",
       "2             0.176946   2_tree_feats\n",
       "17            0.152939  17_tree_feats\n",
       "22            0.080504  22_tree_feats\n",
       "27            0.051779  27_tree_feats\n",
       "21            0.047035  21_tree_feats\n",
       "3             0.037569   3_tree_feats\n",
       "10            0.037453  10_tree_feats\n",
       "16            0.037348  16_tree_feats\n",
       "24            0.031914  24_tree_feats\n",
       "26            0.030068  26_tree_feats\n",
       "1             0.028452   1_tree_feats\n",
       "15            0.025844  15_tree_feats\n",
       "19            0.024838  19_tree_feats\n",
       "12            0.024040  12_tree_feats\n",
       "14            0.020233  14_tree_feats\n",
       "23            0.019516  23_tree_feats\n",
       "13            0.019088  13_tree_feats\n",
       "8             0.019017   8_tree_feats\n",
       "9             0.016931   9_tree_feats\n",
       "5             0.016481   5_tree_feats"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20_most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[:, X_train.shape[1]//2:], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test[:, X_train.shape[1]//2:])\n",
    "val_preds = model.predict(X_val[:, X_train.shape[1]//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Valid RMSE =', 1.3417327115036215)\n",
      "Valid R2-score is 0.458730481237\n",
      "('Test RMSE =', 1.3324128192277744)\n",
      "Test R2-score is 0.467521581709\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds)**0.5)\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds)**0.5)\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])\n",
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = [str(i)+ '_graph_feats' for i in range(X_train.shape[1]//2, X_train.shape[1])]\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature importance</th>\n",
       "      <th>feature name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.055859</td>\n",
       "      <td>55_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.051214</td>\n",
       "      <td>50_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050143</td>\n",
       "      <td>32_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049575</td>\n",
       "      <td>36_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.048136</td>\n",
       "      <td>39_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.046766</td>\n",
       "      <td>42_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.044520</td>\n",
       "      <td>37_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042289</td>\n",
       "      <td>46_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.039642</td>\n",
       "      <td>41_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.038473</td>\n",
       "      <td>49_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.038248</td>\n",
       "      <td>52_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.036629</td>\n",
       "      <td>51_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.036443</td>\n",
       "      <td>53_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.034955</td>\n",
       "      <td>45_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.033760</td>\n",
       "      <td>48_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.033757</td>\n",
       "      <td>54_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032955</td>\n",
       "      <td>29_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.032867</td>\n",
       "      <td>43_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.032256</td>\n",
       "      <td>38_graph_feats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030901</td>\n",
       "      <td>31_graph_feats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature importance    feature name\n",
       "27            0.055859  55_graph_feats\n",
       "22            0.051214  50_graph_feats\n",
       "4             0.050143  32_graph_feats\n",
       "8             0.049575  36_graph_feats\n",
       "11            0.048136  39_graph_feats\n",
       "14            0.046766  42_graph_feats\n",
       "9             0.044520  37_graph_feats\n",
       "18            0.042289  46_graph_feats\n",
       "13            0.039642  41_graph_feats\n",
       "21            0.038473  49_graph_feats\n",
       "24            0.038248  52_graph_feats\n",
       "23            0.036629  51_graph_feats\n",
       "25            0.036443  53_graph_feats\n",
       "17            0.034955  45_graph_feats\n",
       "20            0.033760  48_graph_feats\n",
       "26            0.033757  54_graph_feats\n",
       "1             0.032955  29_graph_feats\n",
       "15            0.032867  43_graph_feats\n",
       "10            0.032256  38_graph_feats\n",
       "3             0.030901  31_graph_feats"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20_most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=5)]: Done  96 out of  96 | elapsed: 48.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7722961415729136\n",
      "{'colsample_bytree': 0.7, 'silent': 1, 'learning_rate': 0.05, 'nthread': 4, 'min_child_weight': 4, 'n_estimators': 1000, 'subsample': 0.7, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 10, 20, 50],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 200, 500, 1000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(np.concatenate((X_train, X_val), axis=0),\n",
    "         np.concatenate((y_train, y_val), axis=0))\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(colsample_bytree=0.7, silent = 1, learning_rate = 0.05, nthread = 4, min_child_weight = 4, n_estimators = 1000, subsample = 0.7, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=4, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=1,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Valid RMSE =', 0.8063512258633068)\n",
      "Valid R2-score is 0.804507520131\n",
      "('Test RMSE =', 0.8211428563420121)\n",
      "Test R2-score is 0.797762427624\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds)**0.5)\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds)**0.5)\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RMSE = [0.5342044580494232, 0.5405131737041414, 0.5144339590477948]\n",
    "test_R2 = [0.9212916061654113, 0.9134389008189245, 0.9156177478399877]\n",
    "\n",
    "val_RMSE = [0.5330971133864346, 0.5393970943801238, 0.5320911200134589]\n",
    "val_R2 = [0.9167385707444774, 0.9193261655969616, 0.9188716678036257]\n",
    "\n",
    "train_RMSE = [0.18383073729520522, 0.18567786361473315, 0.17486524864784958]\n",
    "train_R2 = [0.9662330071097933, 0.9655380319633392, 0.969380081805695]\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE = 0.18145794985259597 +- 0.004722340577254158\n",
      "Train R2-score is 0.9670503736262758+-0.0016716065654506672\n",
      "Valid RMSE = 0.5348617759266725 +- 0.0032331450913189994\n",
      "Valid R2-score is 0.9183121347150216+-0.0011280424749930953\n",
      "Test RMSE = 0.5297171969337865 +- 0.011109545250605615\n",
      "Test R2-score is 0.9167827516081078+-0.003310002079504476\n"
     ]
    }
   ],
   "source": [
    "print(\"Train RMSE =\", np.mean(train_RMSE),'+-',np.std(train_RMSE))\n",
    "print(\"Train R2-score is {0}+-{1}\".format(np.mean(train_R2),np.std(train_R2)))\n",
    "\n",
    "print(\"Valid RMSE =\", np.mean(val_RMSE),'+-',np.std(val_RMSE))\n",
    "print(\"Valid R2-score is {0}+-{1}\".format(np.mean(val_R2),np.std(val_R2)))\n",
    "\n",
    "print(\"Test RMSE =\", np.mean(test_RMSE),'+-',np.std(test_RMSE))\n",
    "print(\"Test R2-score is {0}+-{1}\".format(np.mean(test_R2),np.std(test_R2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jtree]",
   "language": "python",
   "name": "conda-env-jtree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
