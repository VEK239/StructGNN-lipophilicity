{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(tar_list):\n",
    "    df_blank = pd.DataFrame({'smiles':[]})\n",
    "    for dataset in tar_list:\n",
    "        df0 = pd.read_csv(os.path.join(DATASET_PATH, dataset))\n",
    "        df_blank =  pd.merge(df_blank, df0, on=SMILES_COLUMN, how='outer')\n",
    "    return df_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_logd_Lip_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17685, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logp + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logS']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'esol.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_esol_wo_averaging.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logS = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14043 entries, 0 to 14042\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  14043 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   logS    1058 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 438.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logp + FreeSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','Energy']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'freesolv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.to_csv(os.path.join(DATASET_OUTPUT_PATH, 'logp_FreeSolv_wo_averaging.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_Energy = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13940 entries, 0 to 13939\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13940 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   Energy  565 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 435.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check intersected molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>C#CCN(C)C(C)Cc1ccccc1</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>C=CCOc1ccccc1OCC(O)CNC(C)C</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>C=CCc1ccccc1OCC(O)CNC(C)C</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>CC(=O)CCCCn1c(=O)c2c(ncn2C)n(C)c1=O</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13618</th>\n",
       "      <td>c1ccc2[nH]ncc2c1</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13708</th>\n",
       "      <td>c1ccc2ccccc2c1</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13709</th>\n",
       "      <td>c1ccc2cnccc2c1</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>c1ccc2ncccc2c1</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13719</th>\n",
       "      <td>c1ccc2ncncc2c1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      smiles  logP\n",
       "95                     C#CCN(C)C(C)Cc1ccccc1  2.90\n",
       "443               C=CCOc1ccccc1OCC(O)CNC(C)C  2.10\n",
       "453                C=CCc1ccccc1OCC(O)CNC(C)C  3.10\n",
       "612    CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O  2.60\n",
       "617      CC(=O)CCCCn1c(=O)c2c(ncn2C)n(C)c1=O  0.29\n",
       "...                                      ...   ...\n",
       "13618                       c1ccc2[nH]ncc2c1  1.77\n",
       "13708                         c1ccc2ccccc2c1  3.30\n",
       "13709                         c1ccc2cnccc2c1  2.08\n",
       "13717                         c1ccc2ncccc2c1  2.03\n",
       "13719                         c1ccc2ncncc2c1  1.00\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brc1cc(Br)c(Br)cc1Br</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brc1cc(Br)cc(Br)c1</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brc1ccc(Br)cc1</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Brc1cccc(Br)c1</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>c1ccoc1</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13739</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>c1cnc2c(c1)ccc1ncccc12</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>c1cnc2ncncc2n1</td>\n",
       "      <td>-0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13759</th>\n",
       "      <td>c1cncnc1</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       smiles  logP\n",
       "0               BrC(Br)(Br)Br  3.42\n",
       "15       Brc1cc(Br)c(Br)cc1Br  5.13\n",
       "19         Brc1cc(Br)cc(Br)c1  4.51\n",
       "26             Brc1ccc(Br)cc1  3.79\n",
       "34             Brc1cccc(Br)c1  3.75\n",
       "...                       ...   ...\n",
       "13738                 c1ccoc1  1.34\n",
       "13739                 c1ccsc1  1.81\n",
       "13747  c1cnc2c(c1)ccc1ncccc12  2.51\n",
       "13750          c1cnc2ncncc2n1 -0.58\n",
       "13759                c1cncnc1 -0.40\n",
       "\n",
       "[792 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_logS[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + FreeSolv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BrCc1ccccc1</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brc1ccc(Br)cc1</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brc1ccccc1</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>C#CCCC</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>C#CCCCC</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13708</th>\n",
       "      <td>c1ccc2ccccc2c1</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>c1ccc2ncccc2c1</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13733</th>\n",
       "      <td>c1ccccc1</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13736</th>\n",
       "      <td>c1ccncc1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13739</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               smiles  logP\n",
       "11        BrCc1ccccc1  2.92\n",
       "26     Brc1ccc(Br)cc1  3.79\n",
       "38         Brc1ccccc1  2.99\n",
       "88             C#CCCC  1.98\n",
       "91            C#CCCCC  2.73\n",
       "...               ...   ...\n",
       "13708  c1ccc2ccccc2c1  3.30\n",
       "13717  c1ccc2ncccc2c1  2.03\n",
       "13733        c1ccccc1  2.13\n",
       "13736        c1ccncc1  0.65\n",
       "13739         c1ccsc1  1.81\n",
       "\n",
       "[402 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_logP[dataset_logP[SMILES_COLUMN].isin(dataset_Energy[SMILES_COLUMN])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_logd_Lip_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_logd_Lip_wo_averaging shape:  (17685, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (12379, 4)\n",
      "\tvalidation: (2653, 4)\n",
      "\ttest: (2653, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_esol_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_esol_wo_averaging shape:  (14043, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9830, 4)\n",
      "\tvalidation: (2107, 4)\n",
      "\ttest: (2106, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'logp_FreeSolv_wo_averaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_FreeSolv_wo_averaging shape:  (13940, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9758, 4)\n",
      "\tvalidation: (2091, 4)\n",
      "\ttest: (2091, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_OUTPUT_PATH, file+'.csv'))\n",
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "data.to_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "\n",
    "print(file, 'shape: ', data.shape)    \n",
    "train, validation, test = train_test_validation_split(data)\n",
    "print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets with intersected molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(tar_list):\n",
    "    df_blank = pd.DataFrame({'smiles':[]})\n",
    "    for dataset in tar_list:\n",
    "        df0 = pd.read_csv(os.path.join(DATASET_PATH, dataset))\n",
    "        df_blank =  pd.merge(df_blank, df0, on=SMILES_COLUMN, how='outer')\n",
    "    return df_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "DATASET_OUTPUT_PATH = '../data/raw/baselines/dmpnn'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATASET_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_logP = dataset[~dataset[VALUE_COLUMNS[0]].isna()]\n",
    "dataset_logD = dataset[~dataset[VALUE_COLUMNS[1]].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13777 entries, 0 to 13776\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  13777 non-null  object \n",
      " 1   logP    13777 non-null  float64\n",
      " 2   logD    258 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 430.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4166 entries, 95 to 17684\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   smiles  4166 non-null   object \n",
      " 1   logP    258 non-null    float64\n",
      " 2   logD    4166 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 130.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_logD.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "\n",
    "dataset_logP.to_csv(os.path.join(DATASET_PATH, 'logp_258_Lip_wo_averaging'+'.csv'), index = False)\n",
    "dataset_logD.to_csv(os.path.join(DATASET_PATH, 'logd_258_Logp_wo_averaging'+'.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=0.3)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_258_Lip_wo_averaging shape:  (13777, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9643, 3)\n",
      "\tvalidation: (2067, 3)\n",
      "\ttest: (2067, 3)\n",
      "\n",
      "logd_258_Logp_wo_averaging shape:  (4166, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (2916, 3)\n",
      "\tvalidation: (625, 3)\n",
      "\ttest: (625, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = ['logp_258_Lip_wo_averaging', 'logd_258_Logp_wo_averaging']\n",
    "for file in files:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)    \n",
    "    train, validation, test = train_test_validation_split(data)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + LogD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']\n",
    "file = 'logp_logd_Lip_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17685 entries, 0 to 17684\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    17685 non-null  int64  \n",
      " 1   Unnamed: 0.1  17685 non-null  int64  \n",
      " 2   smiles        17685 non-null  object \n",
      " 3   logP          13777 non-null  float64\n",
      " 4   logD          4166 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 690.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_logD_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogD 0.656\n",
      "Spearman's rho LogP/LogD 0.656\n",
      "Kendall's tau LogP/LogD 0.51\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogD', \\\n",
    "      round(logP_logD_cross_section[VALUE_COLUMNS[0]].corr(logP_logD_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logp + LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logS']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'esol.csv']\n",
    "file = 'logp_esol_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logS = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14043 entries, 0 to 14042\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    14043 non-null  int64  \n",
      " 1   Unnamed: 0.1  14043 non-null  int64  \n",
      " 2   smiles        14043 non-null  object \n",
      " 3   logP          13777 non-null  float64\n",
      " 4   logS          1058 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 548.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_logS_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogS -0.853\n",
      "Spearman's rho LogP/LogS -0.841\n",
      "Kendall's tau LogP/LogS -0.666\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogS', \\\n",
    "      round(logP_logS_cross_section[VALUE_COLUMNS[0]].corr(logP_logS_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogP + Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','Energy']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'freesolv.csv']\n",
    "file = 'logp_FreeSolv_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_Energy = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_Energy_cross_section = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r LogP/LogS 0.427\n",
      "Spearman's rho LogP/LogS 0.453\n",
      "Kendall's tau LogP/LogS 0.306\n"
     ]
    }
   ],
   "source": [
    "print('Pearson\\'s r LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]]), 3))\n",
    "print('Spearman\\'s rho LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]], method='spearman'), 3))\n",
    "print('Kendall\\'s tau LogP/LogS', \\\n",
    "      round(logP_Energy_cross_section[VALUE_COLUMNS[0]].corr(logP_Energy_cross_section[VALUE_COLUMNS[1]], method='kendall'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of acid groups and amins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMNS = ['logP','logD']\n",
    "DATASET_NAMES = ['logp_wo_averaging.csv', 'logd_Lip_wo_averaging.csv']\n",
    "file = 'logp_logd_Lip_wo_averaging'\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "dataset_logP = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[0]))\n",
    "dataset_logD = pd.read_csv(os.path.join(DATASET_PATH, DATASET_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import Fragments\n",
    "from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Amins\n",
    "\n",
    "fr_NH2 - primary amines\n",
    "\n",
    "fr_NH1 - Secondary amines\n",
    "\n",
    "fr_NH0 - Tertiary amines\n",
    "\n",
    "fr_Ar_NH - aromatic amines\n",
    "\n",
    "\n",
    "### Acids\n",
    "\n",
    "fr_COO2 - carboxylic acids\n",
    "\n",
    "fr_COO - carboxylic acids\n",
    "\n",
    "fr_Ar_COO - Aromatic carboxylic acide\n",
    "\n",
    "fr_Al_COO - carboxylic acids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "amins = ['fr_NH2', 'fr_NH1', 'fr_NH0',  'fr_Ar_NH', ]\n",
    "acids = ['fr_COO2', 'fr_COO', 'fr_Ar_COO', 'fr_Al_COO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17685/17685 [00:07<00:00, 2262.09it/s]\n"
     ]
    }
   ],
   "source": [
    "generator = rdDescriptors.RDKit2D(amins+acids)\n",
    "features ={}\n",
    "for feature in amins+acids:\n",
    "    features[feature] = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    feature = dict(zip(amins+acids,generator.process(data[SMILES_COLUMN][i])[1:]))\n",
    "    for feat in feature.keys():\n",
    "        features[feat].append(feature[feat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features.keys():\n",
    "    data[feature] = features[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "      <th>logD</th>\n",
       "      <th>fr_NH2</th>\n",
       "      <th>fr_NH1</th>\n",
       "      <th>fr_NH0</th>\n",
       "      <th>fr_Ar_NH</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_Ar_COO</th>\n",
       "      <th>fr_Al_COO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BrC1C2CC3C(C2)C13</td>\n",
       "      <td>3.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BrC1CC2CCC1C2</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BrC1CCCCC1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BrC=C(Br)Br</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1             smiles  logP  logD  fr_NH2  fr_NH1  \\\n",
       "0           0             0      BrC(Br)(Br)Br  3.42   NaN       0       0   \n",
       "1           1             1  BrC1C2CC3C(C2)C13  3.11   NaN       0       0   \n",
       "2           2             2      BrC1CC2CCC1C2  3.54   NaN       0       0   \n",
       "3           3             3         BrC1CCCCC1  3.20   NaN       0       0   \n",
       "4           4             4        BrC=C(Br)Br  3.20   NaN       0       0   \n",
       "\n",
       "   fr_NH0  fr_Ar_NH  fr_COO2  fr_COO  fr_Ar_COO  fr_Al_COO  \n",
       "0       0         0        0       0          0          0  \n",
       "1       0         0        0       0          0          0  \n",
       "2       0         0        0       0          0          0  \n",
       "3       0         0        0       0          0          0  \n",
       "4       0         0        0       0          0          0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17685 entries, 0 to 17684\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    17685 non-null  int64  \n",
      " 1   Unnamed: 0.1  17685 non-null  int64  \n",
      " 2   smiles        17685 non-null  object \n",
      " 3   logP          13777 non-null  float64\n",
      " 4   logD          4166 non-null   float64\n",
      " 5   fr_NH2        17685 non-null  int64  \n",
      " 6   fr_NH1        17685 non-null  int64  \n",
      " 7   fr_NH0        17685 non-null  int64  \n",
      " 8   fr_Ar_NH      17685 non-null  int64  \n",
      " 9   fr_COO2       17685 non-null  int64  \n",
      " 10  fr_COO        17685 non-null  int64  \n",
      " 11  fr_Ar_COO     17685 non-null  int64  \n",
      " 12  fr_Al_COO     17685 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total fragments']= data[amins+acids].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>smiles</th>\n",
       "      <th>logP</th>\n",
       "      <th>logD</th>\n",
       "      <th>fr_NH2</th>\n",
       "      <th>fr_NH1</th>\n",
       "      <th>fr_NH0</th>\n",
       "      <th>fr_Ar_NH</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_Ar_COO</th>\n",
       "      <th>fr_Al_COO</th>\n",
       "      <th>Total fragments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BrC(Br)(Br)Br</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BrC1C2CC3C(C2)C13</td>\n",
       "      <td>3.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BrC1CC2CCC1C2</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BrC1CCCCC1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BrC=C(Br)Br</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1             smiles  logP  logD  fr_NH2  fr_NH1  \\\n",
       "0           0             0      BrC(Br)(Br)Br  3.42   NaN       0       0   \n",
       "1           1             1  BrC1C2CC3C(C2)C13  3.11   NaN       0       0   \n",
       "2           2             2      BrC1CC2CCC1C2  3.54   NaN       0       0   \n",
       "3           3             3         BrC1CCCCC1  3.20   NaN       0       0   \n",
       "4           4             4        BrC=C(Br)Br  3.20   NaN       0       0   \n",
       "\n",
       "   fr_NH0  fr_Ar_NH  fr_COO2  fr_COO  fr_Ar_COO  fr_Al_COO  Total fragments  \n",
       "0       0         0        0       0          0          0                0  \n",
       "1       0         0        0       0          0          0                0  \n",
       "2       0         0        0       0          0          0                0  \n",
       "3       0         0        0       0          0          0                0  \n",
       "4       0         0        0       0          0          0                0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecule with acids or amins group  in LogP+LogD dataset =  14819 ;  83.8 % of all data\n",
      "Number of molecule with acids or amins group  in LogD dataset =  4066 ;  97.6 % of all data\n",
      "Number of molecule with acids or amins group  in LogP dataset =  10993 ;  79.8 % of all data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-d3a88120d2bb>:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]), '; ', \\\n",
      "<ipython-input-51-d3a88120d2bb>:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])])/len(dataset_logD)*100,1), '% of all data')\n",
      "<ipython-input-51-d3a88120d2bb>:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])]), '; ', \\\n",
      "<ipython-input-51-d3a88120d2bb>:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])])/len(dataset_logP)*100,1), '% of all data')\n"
     ]
    }
   ],
   "source": [
    "print('Number of molecule with acids or amins group  in LogP+LogD dataset = ', len(data[data['Total fragments']>0]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0])/len(data)*100,1), '% of all data')\n",
    "\n",
    "print('Number of molecule with acids or amins group  in LogD dataset = ', \\\n",
    "      len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logD[SMILES_COLUMN])])/len(dataset_logD)*100,1), '% of all data')\n",
    "\n",
    "print('Number of molecule with acids or amins group  in LogP dataset = ', \\\n",
    "      len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])]), '; ', \\\n",
    "      round(len(data[data['Total fragments']>0][data[SMILES_COLUMN].isin(dataset_logP[SMILES_COLUMN])])/len(dataset_logP)*100,1), '% of all data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
