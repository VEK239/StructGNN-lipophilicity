{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df, train_fraction):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, rest_data = train_test_split(df, test_size=1 - train_fraction)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_datasets = ['logp_wo_logp_json_wo_averaging', 'logp_wo_logp_json_251_Lip_wo_averaging',\n",
    "                 'logp_wo_logp_json_logd_Lip_wo_averaging']\n",
    "logd_datasets = ['logd_Lip_wo_averaging', 'logd_251_logp_wo_logp_json_wo_averaging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_wo_logp_json_wo_averaging shape:  (13688, 2)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9581, 2)\n",
      "\tvalidation: (2054, 2)\n",
      "\ttest: (2053, 2)\n",
      "\n",
      "logp_wo_logp_json_251_Lip_wo_averaging shape:  (13688, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9581, 3)\n",
      "\tvalidation: (2054, 3)\n",
      "\ttest: (2053, 3)\n",
      "\n",
      "logp_wo_logp_json_logd_Lip_wo_averaging shape:  (17603, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (12322, 4)\n",
      "\tvalidation: (2641, 4)\n",
      "\ttest: (2640, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 0.7\n",
    "for file in logp_datasets:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)    \n",
    "    train, validation, test = train_test_validation_split(data, train_fraction)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logd_Lip_wo_averaging shape:  (4166, 2)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (3332, 2)\n",
      "\tvalidation: (417, 2)\n",
      "\ttest: (417, 2)\n",
      "\n",
      "logd_251_logp_wo_logp_json_wo_averaging shape:  (4166, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (3332, 3)\n",
      "\tvalidation: (417, 3)\n",
      "\ttest: (417, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 0.8\n",
    "for file in logd_datasets:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)    \n",
    "    train, validation, test = train_test_validation_split(data, train_fraction)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze symmetric molecules distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_split_symmetry(args):\n",
    "    dataset_size = sum(part.smiles.count() for part in args.values())\n",
    "    for name, arg in args.items():\n",
    "        mols = [Chem.MolFromSmiles(s) for s in arg.smiles]\n",
    "        values_list = [pd.Series(Chem.CanonicalRankAtoms(mol, breakTies=False)).value_counts() for mol in mols]\n",
    "        symmetry_list = [(len(values) - 1 <= len(values[values % 2 == 0])) \n",
    "                         or (len(values) - 1 <= len(values[(values % 2 == 1) & (values > 1)])) for values in values_list]\n",
    "        symmetry_data = arg[symmetry_list]\n",
    "        symmetric_mols_count = symmetry_data.smiles.count()\n",
    "        print('{0}: {1} symmetric molecules ({2}%)'.format(name, symmetric_mols_count, \n",
    "                                                        symmetric_mols_count / len(mols) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['logp_wo_logp_json_wo_averaging', 'logd_Lip_wo_averaging', 'logp_wo_logp_json_251_Lip_wo_averaging', \n",
    "            'logd_251_logp_wo_logp_json_wo_averaging', 'logp_wo_logp_json_logd_Lip_wo_averaging']\n",
    "DATA_PATH = \"../data/3_final_data/split_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_wo_logp_json_wo_averaging\n",
      "train: 412 symmetric molecules (4.300177434505793%)\n",
      "valid: 99 symmetric molecules (4.8198636806231745%)\n",
      "test: 97 symmetric molecules (4.72479298587433%)\n",
      "logd_Lip_wo_averaging\n",
      "train: 25 symmetric molecules (0.7503001200480192%)\n",
      "valid: 3 symmetric molecules (0.7194244604316548%)\n",
      "test: 5 symmetric molecules (1.1990407673860912%)\n",
      "logp_wo_logp_json_251_Lip_wo_averaging\n",
      "train: 404 symmetric molecules (4.216678843544515%)\n",
      "valid: 103 symmetric molecules (5.0146056475170395%)\n",
      "test: 101 symmetric molecules (4.919629810034096%)\n",
      "logd_251_logp_wo_logp_json_wo_averaging\n",
      "train: 27 symmetric molecules (0.8103241296518607%)\n",
      "valid: 2 symmetric molecules (0.4796163069544364%)\n",
      "test: 4 symmetric molecules (0.9592326139088728%)\n",
      "logp_wo_logp_json_logd_Lip_wo_averaging\n",
      "train: 466 symmetric molecules (3.7818535951955856%)\n",
      "valid: 84 symmetric molecules (3.180613404013631%)\n",
      "test: 84 symmetric molecules (3.1818181818181817%)\n"
     ]
    }
   ],
   "source": [
    "for name in dataset_names:\n",
    "    data_train = pd.read_csv(DATA_PATH + name + '_train.csv')\n",
    "    data_valid = pd.read_csv(DATA_PATH + name + '_validation.csv')\n",
    "    data_test = pd.read_csv(DATA_PATH + name + '_test.csv')\n",
    "    print(name)\n",
    "    analyze_data_split_symmetry({'train':data_train, 'valid':data_valid, 'test':data_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symmetry based splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/3_final_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation_split(df, train_fraction):\n",
    "    train_data, rest_data = train_test_split(df, test_size=1 - train_fraction)\n",
    "    test_data, validation_data = train_test_split(rest_data, test_size=0.5)\n",
    "    return train_data.reset_index(drop=True), validation_data.reset_index(drop=True), test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_datasets = ['logp_wo_logp_json_wo_averaging', 'logp_wo_logp_json_251_Lip_wo_averaging',\n",
    "                 'logp_wo_logp_json_logd_Lip_wo_averaging']\n",
    "logd_datasets = ['logd_Lip_wo_averaging', 'logd_251_logp_wo_logp_json_wo_averaging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_wo_logp_json_wo_averaging shape:  (13688, 2)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9580, 2)\n",
      "\tvalidation: (2055, 2)\n",
      "\ttest: (2053, 2)\n",
      "\n",
      "logp_wo_logp_json_251_Lip_wo_averaging shape:  (13688, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (9580, 3)\n",
      "\tvalidation: (2055, 3)\n",
      "\ttest: (2053, 3)\n",
      "\n",
      "logp_wo_logp_json_logd_Lip_wo_averaging shape:  (17603, 4)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (12321, 4)\n",
      "\tvalidation: (2642, 4)\n",
      "\ttest: (2640, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 0.7\n",
    "for file in logp_datasets:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)\n",
    "    mols = [Chem.MolFromSmiles(s) for s in data.smiles]\n",
    "    values_list = [pd.Series(Chem.CanonicalRankAtoms(mol, breakTies=False)).value_counts() for mol in mols]\n",
    "    symmetry_list = pd.Series([(len(values) - 1 <= len(values[values % 2 == 0])) \n",
    "                     or (len(values) - 1 <= len(values[(values % 2 == 1) & (values > 1)])) for values in values_list])\n",
    "    symmetry_data = data[symmetry_list]\n",
    "    no_symmetry_data = data[~symmetry_list]\n",
    "    train_symm, validation_symm, test_symm = train_test_validation_split(symmetry_data, train_fraction)\n",
    "    train_no_symm, validation_no_symm, test_no_symm = train_test_validation_split(no_symmetry_data, train_fraction)\n",
    "    train = pd.concat([train_symm, train_no_symm], ignore_index=True)\n",
    "    train = shuffle(train).reset_index(drop=True)\n",
    "    validation = pd.concat([validation_symm, validation_no_symm], ignore_index=True)\n",
    "    validation = shuffle(validation).reset_index(drop=True)\n",
    "    test = pd.concat([test_symm, test_no_symm], ignore_index=True)\n",
    "    test = shuffle(test).reset_index(drop=True)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logp_wo_logp_json_wo_averaging\n",
      "train: 425 symmetric molecules (4.4363256784968685%)\n",
      "valid: 92 symmetric molecules (4.476885644768856%)\n",
      "test: 91 symmetric molecules (4.432537749634681%)\n",
      "logp_wo_logp_json_251_Lip_wo_averaging\n",
      "train: 425 symmetric molecules (4.4363256784968685%)\n",
      "valid: 92 symmetric molecules (4.476885644768856%)\n",
      "test: 91 symmetric molecules (4.432537749634681%)\n",
      "logp_wo_logp_json_logd_Lip_wo_averaging\n",
      "train: 443 symmetric molecules (3.5954873792711632%)\n",
      "valid: 96 symmetric molecules (3.6336109008327027%)\n",
      "test: 95 symmetric molecules (3.5984848484848486%)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/3_final_data/split_data_symmetry/\"\n",
    "for name in logp_datasets:\n",
    "    data_train = pd.read_csv(DATA_PATH + name + '_train.csv')\n",
    "    data_valid = pd.read_csv(DATA_PATH + name + '_validation.csv')\n",
    "    data_test = pd.read_csv(DATA_PATH + name + '_test.csv')\n",
    "    print(name)\n",
    "    analyze_data_split_symmetry({'train':data_train, 'valid':data_valid, 'test':data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logd_Lip_wo_averaging shape:  (4166, 2)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (3332, 2)\n",
      "\tvalidation: (418, 2)\n",
      "\ttest: (416, 2)\n",
      "\n",
      "logd_251_logp_wo_logp_json_wo_averaging shape:  (4166, 3)\n",
      "SPLITTED SHAPES:\n",
      "\ttrain: (3332, 3)\n",
      "\tvalidation: (418, 3)\n",
      "\ttest: (416, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fraction = 0.8\n",
    "for file in logd_datasets:\n",
    "    data = pd.read_csv(os.path.join(DATASET_PATH, file+'.csv'))\n",
    "    print(file, 'shape: ', data.shape)\n",
    "    mols = [Chem.MolFromSmiles(s) for s in data.smiles]\n",
    "    values_list = [pd.Series(Chem.CanonicalRankAtoms(mol, breakTies=False)).value_counts() for mol in mols]\n",
    "    symmetry_list = pd.Series([(len(values) - 1 <= len(values[values % 2 == 0])) \n",
    "                     or (len(values) - 1 <= len(values[(values % 2 == 1) & (values > 1)])) for values in values_list])\n",
    "    symmetry_data = data[symmetry_list]\n",
    "    no_symmetry_data = data[~symmetry_list]\n",
    "    train_symm, validation_symm, test_symm = train_test_validation_split(symmetry_data, train_fraction)\n",
    "    train_no_symm, validation_no_symm, test_no_symm = train_test_validation_split(no_symmetry_data, train_fraction)\n",
    "    train = pd.concat([train_symm, train_no_symm], ignore_index=True)\n",
    "    train = shuffle(train).reset_index(drop=True)\n",
    "    validation = pd.concat([validation_symm, validation_no_symm], ignore_index=True)\n",
    "    validation = shuffle(validation).reset_index(drop=True)\n",
    "    test = pd.concat([test_symm, test_no_symm], ignore_index=True)\n",
    "    test = shuffle(test).reset_index(drop=True)\n",
    "    print('SPLITTED SHAPES:\\n\\ttrain: {0}\\n\\tvalidation: {1}\\n\\ttest: {2}\\n'.format(train.shape, validation.shape, test.shape))\n",
    "\n",
    "    train.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry', file + '_train.csv'))\n",
    "    validation.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry', file + '_validation.csv'))\n",
    "    test.to_csv(os.path.join(DATASET_PATH, 'split_data_symmetry',  file + '_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logd_Lip_wo_averaging\n",
      "train: 26 symmetric molecules (0.78031212484994%)\n",
      "valid: 4 symmetric molecules (0.9569377990430622%)\n",
      "test: 3 symmetric molecules (0.7211538461538461%)\n",
      "logd_251_logp_wo_logp_json_wo_averaging\n",
      "train: 26 symmetric molecules (0.78031212484994%)\n",
      "valid: 4 symmetric molecules (0.9569377990430622%)\n",
      "test: 3 symmetric molecules (0.7211538461538461%)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/3_final_data/split_data_symmetry/\"\n",
    "for name in logd_datasets:\n",
    "    data_train = pd.read_csv(DATA_PATH + name + '_train.csv')\n",
    "    data_valid = pd.read_csv(DATA_PATH + name + '_validation.csv')\n",
    "    data_test = pd.read_csv(DATA_PATH + name + '_test.csv')\n",
    "    print(name)\n",
    "    analyze_data_split_symmetry({'train':data_train, 'valid':data_valid, 'test':data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemvae",
   "language": "python",
   "name": "chemvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
