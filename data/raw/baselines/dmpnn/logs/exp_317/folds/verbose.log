Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_317/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.0283e-02, PNorm = 55.5661, GNorm = 5.4307, lr_0 = 1.2200e-04
Loss = 1.5085e-02, PNorm = 55.5723, GNorm = 6.0923, lr_0 = 1.4200e-04
Loss = 1.5145e-02, PNorm = 55.5807, GNorm = 2.7780, lr_0 = 1.6200e-04
Loss = 1.1350e-02, PNorm = 55.5910, GNorm = 7.4148, lr_0 = 1.8200e-04
Loss = 1.0370e-02, PNorm = 55.6033, GNorm = 6.9136, lr_0 = 2.0200e-04
Loss = 9.1569e-03, PNorm = 55.6171, GNorm = 7.7248, lr_0 = 2.2200e-04
Loss = 8.5015e-03, PNorm = 55.6293, GNorm = 11.1974, lr_0 = 2.4200e-04
Loss = 7.5931e-03, PNorm = 55.6446, GNorm = 6.2011, lr_0 = 2.6200e-04
Loss = 8.6335e-03, PNorm = 55.6609, GNorm = 2.3858, lr_0 = 2.8200e-04
Loss = 9.5241e-03, PNorm = 55.6826, GNorm = 3.9719, lr_0 = 3.0200e-04
Loss = 9.0379e-03, PNorm = 55.7031, GNorm = 5.3800, lr_0 = 3.2200e-04
Loss = 8.1775e-03, PNorm = 55.7299, GNorm = 3.8372, lr_0 = 3.4200e-04
Loss = 7.6072e-03, PNorm = 55.7548, GNorm = 3.1536, lr_0 = 3.6200e-04
Loss = 7.9058e-03, PNorm = 55.7799, GNorm = 3.0119, lr_0 = 3.8200e-04
Loss = 7.2630e-03, PNorm = 55.8046, GNorm = 6.1567, lr_0 = 4.0200e-04
Loss = 8.3899e-03, PNorm = 55.8313, GNorm = 3.4298, lr_0 = 4.2200e-04
Loss = 7.9387e-03, PNorm = 55.8577, GNorm = 3.3783, lr_0 = 4.4200e-04
Loss = 6.8536e-03, PNorm = 55.8899, GNorm = 3.9727, lr_0 = 4.6200e-04
Loss = 6.4268e-03, PNorm = 55.9306, GNorm = 2.6678, lr_0 = 4.8200e-04
Loss = 6.0273e-03, PNorm = 55.9711, GNorm = 3.9943, lr_0 = 5.0200e-04
Loss = 6.9037e-03, PNorm = 56.0130, GNorm = 1.3992, lr_0 = 5.2200e-04
Loss = 6.1770e-03, PNorm = 56.0508, GNorm = 2.1932, lr_0 = 5.4200e-04
Validation rmse logD = 0.976064
Validation R2 logD = 0.368444
Validation rmse logP = 1.016592
Validation R2 logP = 0.711571
Epoch 1
Train function
Loss = 5.7799e-03, PNorm = 56.0900, GNorm = 1.9777, lr_0 = 5.6400e-04
Loss = 6.2523e-03, PNorm = 56.1337, GNorm = 2.3033, lr_0 = 5.8400e-04
Loss = 6.7594e-03, PNorm = 56.1811, GNorm = 2.9887, lr_0 = 6.0400e-04
Loss = 6.6031e-03, PNorm = 56.2433, GNorm = 0.8585, lr_0 = 6.2400e-04
Loss = 5.6953e-03, PNorm = 56.3027, GNorm = 1.9804, lr_0 = 6.4400e-04
Loss = 5.8068e-03, PNorm = 56.3609, GNorm = 0.9909, lr_0 = 6.6400e-04
Loss = 5.1429e-03, PNorm = 56.4139, GNorm = 1.3416, lr_0 = 6.8400e-04
Loss = 6.5207e-03, PNorm = 56.4690, GNorm = 2.6207, lr_0 = 7.0400e-04
Loss = 5.0093e-03, PNorm = 56.5403, GNorm = 1.5290, lr_0 = 7.2400e-04
Loss = 4.4476e-03, PNorm = 56.6004, GNorm = 1.6637, lr_0 = 7.4400e-04
Loss = 5.9435e-03, PNorm = 56.6590, GNorm = 1.1240, lr_0 = 7.6400e-04
Loss = 5.4475e-03, PNorm = 56.7244, GNorm = 1.0635, lr_0 = 7.8400e-04
Loss = 5.8900e-03, PNorm = 56.7944, GNorm = 1.5857, lr_0 = 8.0400e-04
Loss = 5.0040e-03, PNorm = 56.8672, GNorm = 1.4540, lr_0 = 8.2400e-04
Loss = 5.4060e-03, PNorm = 56.9315, GNorm = 1.5131, lr_0 = 8.4400e-04
Loss = 4.1589e-03, PNorm = 57.0015, GNorm = 0.6343, lr_0 = 8.6400e-04
Loss = 5.0206e-03, PNorm = 57.0694, GNorm = 1.4504, lr_0 = 8.8400e-04
Loss = 4.3538e-03, PNorm = 57.1439, GNorm = 1.7512, lr_0 = 9.0400e-04
Loss = 4.5749e-03, PNorm = 57.2187, GNorm = 2.8008, lr_0 = 9.2400e-04
Loss = 4.8179e-03, PNorm = 57.2957, GNorm = 3.2369, lr_0 = 9.4400e-04
Loss = 5.4153e-03, PNorm = 57.3910, GNorm = 1.6079, lr_0 = 9.6400e-04
Loss = 4.9884e-03, PNorm = 57.4942, GNorm = 1.8387, lr_0 = 9.8400e-04
Loss = 4.1707e-03, PNorm = 57.5639, GNorm = 1.7979, lr_0 = 9.9979e-04
Loss = 1.4883e-02, PNorm = 57.5703, GNorm = 3.1616, lr_0 = 9.9969e-04
Validation rmse logD = 0.859024
Validation R2 logD = 0.510824
Validation rmse logP = 0.687309
Validation R2 logP = 0.868159
Epoch 2
Train function
Loss = 4.3877e-03, PNorm = 57.6510, GNorm = 2.5267, lr_0 = 9.9864e-04
Loss = 4.4781e-03, PNorm = 57.7510, GNorm = 1.8812, lr_0 = 9.9760e-04
Loss = 4.0671e-03, PNorm = 57.8200, GNorm = 1.0914, lr_0 = 9.9656e-04
Loss = 4.3596e-03, PNorm = 57.8983, GNorm = 0.8461, lr_0 = 9.9552e-04
Loss = 3.4946e-03, PNorm = 57.9692, GNorm = 0.6993, lr_0 = 9.9448e-04
Loss = 4.5569e-03, PNorm = 58.0523, GNorm = 0.8969, lr_0 = 9.9344e-04
Loss = 3.6802e-03, PNorm = 58.1348, GNorm = 1.7622, lr_0 = 9.9241e-04
Loss = 4.2416e-03, PNorm = 58.2273, GNorm = 1.6918, lr_0 = 9.9137e-04
Loss = 5.0210e-03, PNorm = 58.3153, GNorm = 2.4962, lr_0 = 9.9034e-04
Loss = 4.4504e-03, PNorm = 58.4028, GNorm = 1.8834, lr_0 = 9.8930e-04
Loss = 4.0866e-03, PNorm = 58.4825, GNorm = 1.5441, lr_0 = 9.8827e-04
Loss = 5.5373e-03, PNorm = 58.5753, GNorm = 1.0017, lr_0 = 9.8724e-04
Loss = 3.6042e-03, PNorm = 58.6699, GNorm = 0.9768, lr_0 = 9.8621e-04
Loss = 4.1979e-03, PNorm = 58.7431, GNorm = 1.2462, lr_0 = 9.8518e-04
Loss = 3.2777e-03, PNorm = 58.8106, GNorm = 0.9580, lr_0 = 9.8415e-04
Loss = 3.6358e-03, PNorm = 58.8664, GNorm = 1.0687, lr_0 = 9.8312e-04
Loss = 3.7742e-03, PNorm = 58.9277, GNorm = 1.2488, lr_0 = 9.8210e-04
Loss = 3.5214e-03, PNorm = 59.0000, GNorm = 0.7614, lr_0 = 9.8107e-04
Loss = 3.0997e-03, PNorm = 59.0591, GNorm = 1.3755, lr_0 = 9.8005e-04
Loss = 4.0224e-03, PNorm = 59.1171, GNorm = 1.4059, lr_0 = 9.7902e-04
Loss = 3.0414e-03, PNorm = 59.1975, GNorm = 1.1920, lr_0 = 9.7800e-04
Loss = 3.4558e-03, PNorm = 59.2602, GNorm = 1.3976, lr_0 = 9.7698e-04
Validation rmse logD = 0.878240
Validation R2 logD = 0.488693
Validation rmse logP = 0.643449
Validation R2 logP = 0.884449
Epoch 3
Train function
Loss = 3.0993e-03, PNorm = 59.3337, GNorm = 1.0548, lr_0 = 9.7596e-04
Loss = 3.1167e-03, PNorm = 59.4053, GNorm = 0.9382, lr_0 = 9.7494e-04
Loss = 3.5815e-03, PNorm = 59.4788, GNorm = 1.6828, lr_0 = 9.7393e-04
Loss = 3.4787e-03, PNorm = 59.5651, GNorm = 1.8553, lr_0 = 9.7291e-04
Loss = 3.2681e-03, PNorm = 59.6342, GNorm = 0.7882, lr_0 = 9.7189e-04
Loss = 3.0898e-03, PNorm = 59.6906, GNorm = 1.5598, lr_0 = 9.7088e-04
Loss = 3.3166e-03, PNorm = 59.7542, GNorm = 1.1949, lr_0 = 9.6987e-04
Loss = 3.0468e-03, PNorm = 59.8264, GNorm = 1.1961, lr_0 = 9.6885e-04
Loss = 2.6777e-03, PNorm = 59.9019, GNorm = 1.4797, lr_0 = 9.6784e-04
Loss = 2.8514e-03, PNorm = 59.9710, GNorm = 1.6676, lr_0 = 9.6683e-04
Loss = 3.8664e-03, PNorm = 60.0516, GNorm = 1.0856, lr_0 = 9.6582e-04
Loss = 3.3691e-03, PNorm = 60.1452, GNorm = 1.0027, lr_0 = 9.6482e-04
Loss = 4.3787e-03, PNorm = 60.2144, GNorm = 1.2202, lr_0 = 9.6381e-04
Loss = 3.3459e-03, PNorm = 60.2947, GNorm = 1.0469, lr_0 = 9.6280e-04
Loss = 3.1886e-03, PNorm = 60.3838, GNorm = 1.1730, lr_0 = 9.6180e-04
Loss = 2.4983e-03, PNorm = 60.4393, GNorm = 0.7205, lr_0 = 9.6079e-04
Loss = 2.9942e-03, PNorm = 60.4896, GNorm = 0.9975, lr_0 = 9.5979e-04
Loss = 2.8093e-03, PNorm = 60.5397, GNorm = 0.7023, lr_0 = 9.5879e-04
Loss = 2.2489e-03, PNorm = 60.5976, GNorm = 0.8449, lr_0 = 9.5779e-04
Loss = 3.1686e-03, PNorm = 60.6386, GNorm = 1.3896, lr_0 = 9.5679e-04
Loss = 2.8892e-03, PNorm = 60.6995, GNorm = 1.4464, lr_0 = 9.5579e-04
Loss = 2.6690e-03, PNorm = 60.7660, GNorm = 0.8068, lr_0 = 9.5479e-04
Loss = 2.8125e-03, PNorm = 60.8481, GNorm = 0.6694, lr_0 = 9.5380e-04
Validation rmse logD = 0.850594
Validation R2 logD = 0.520377
Validation rmse logP = 0.613460
Validation R2 logP = 0.894969
Epoch 4
Train function
Loss = 2.7577e-03, PNorm = 60.9105, GNorm = 1.2547, lr_0 = 9.5270e-04
Loss = 2.5437e-03, PNorm = 60.9768, GNorm = 1.4443, lr_0 = 9.5171e-04
Loss = 3.6650e-03, PNorm = 61.0584, GNorm = 1.2794, lr_0 = 9.5071e-04
Loss = 2.7122e-03, PNorm = 61.1409, GNorm = 1.1373, lr_0 = 9.4972e-04
Loss = 2.4731e-03, PNorm = 61.2345, GNorm = 0.7194, lr_0 = 9.4873e-04
Loss = 2.6903e-03, PNorm = 61.2832, GNorm = 1.3582, lr_0 = 9.4774e-04
Loss = 2.7354e-03, PNorm = 61.3517, GNorm = 1.1581, lr_0 = 9.4675e-04
Loss = 3.2115e-03, PNorm = 61.4374, GNorm = 2.0429, lr_0 = 9.4576e-04
Loss = 2.5349e-03, PNorm = 61.5074, GNorm = 1.5392, lr_0 = 9.4478e-04
Loss = 3.1499e-03, PNorm = 61.5854, GNorm = 2.0307, lr_0 = 9.4379e-04
Loss = 2.7786e-03, PNorm = 61.6628, GNorm = 0.9384, lr_0 = 9.4280e-04
Loss = 2.4359e-03, PNorm = 61.7306, GNorm = 0.9002, lr_0 = 9.4182e-04
Loss = 2.5973e-03, PNorm = 61.7943, GNorm = 0.6296, lr_0 = 9.4084e-04
Loss = 2.3168e-03, PNorm = 61.8466, GNorm = 0.7819, lr_0 = 9.3986e-04
Loss = 2.4678e-03, PNorm = 61.9125, GNorm = 0.7530, lr_0 = 9.3887e-04
Loss = 2.7344e-03, PNorm = 61.9671, GNorm = 0.9080, lr_0 = 9.3789e-04
Loss = 2.6785e-03, PNorm = 62.0097, GNorm = 1.3228, lr_0 = 9.3692e-04
Loss = 2.8893e-03, PNorm = 62.0698, GNorm = 0.9211, lr_0 = 9.3594e-04
Loss = 2.5338e-03, PNorm = 62.1244, GNorm = 1.9819, lr_0 = 9.3496e-04
Loss = 2.7335e-03, PNorm = 62.1774, GNorm = 1.5722, lr_0 = 9.3399e-04
Loss = 2.5493e-03, PNorm = 62.2276, GNorm = 0.8071, lr_0 = 9.3301e-04
Loss = 2.7413e-03, PNorm = 62.2868, GNorm = 1.2067, lr_0 = 9.3204e-04
Validation rmse logD = 0.799831
Validation R2 logD = 0.575916
Validation rmse logP = 0.577660
Validation R2 logP = 0.906870
Epoch 5
Train function
Loss = 2.4709e-03, PNorm = 62.3653, GNorm = 0.9238, lr_0 = 9.3106e-04
Loss = 2.1463e-03, PNorm = 62.4294, GNorm = 0.9069, lr_0 = 9.3009e-04
Loss = 2.4218e-03, PNorm = 62.4945, GNorm = 0.9557, lr_0 = 9.2912e-04
Loss = 2.0271e-03, PNorm = 62.5543, GNorm = 0.3323, lr_0 = 9.2815e-04
Loss = 2.5003e-03, PNorm = 62.6107, GNorm = 0.9149, lr_0 = 9.2718e-04
Loss = 2.3678e-03, PNorm = 62.6803, GNorm = 0.5367, lr_0 = 9.2622e-04
Loss = 2.7941e-03, PNorm = 62.7599, GNorm = 1.0714, lr_0 = 9.2525e-04
Loss = 2.3312e-03, PNorm = 62.8343, GNorm = 0.9335, lr_0 = 9.2428e-04
Loss = 1.8883e-03, PNorm = 62.8969, GNorm = 0.6606, lr_0 = 9.2332e-04
Loss = 2.5933e-03, PNorm = 62.9604, GNorm = 0.9596, lr_0 = 9.2235e-04
Loss = 1.8912e-03, PNorm = 63.0189, GNorm = 0.5208, lr_0 = 9.2139e-04
Loss = 2.1406e-03, PNorm = 63.0609, GNorm = 0.7165, lr_0 = 9.2043e-04
Loss = 2.2007e-03, PNorm = 63.1075, GNorm = 0.8075, lr_0 = 9.1947e-04
Loss = 2.2938e-03, PNorm = 63.1695, GNorm = 0.5511, lr_0 = 9.1851e-04
Loss = 2.3315e-03, PNorm = 63.2236, GNorm = 0.8796, lr_0 = 9.1755e-04
Loss = 2.2093e-03, PNorm = 63.2818, GNorm = 0.8358, lr_0 = 9.1659e-04
Loss = 2.3508e-03, PNorm = 63.3363, GNorm = 0.5204, lr_0 = 9.1564e-04
Loss = 2.1924e-03, PNorm = 63.3926, GNorm = 1.1277, lr_0 = 9.1468e-04
Loss = 2.6924e-03, PNorm = 63.4604, GNorm = 0.9325, lr_0 = 9.1373e-04
Loss = 2.2490e-03, PNorm = 63.5137, GNorm = 0.6582, lr_0 = 9.1277e-04
Loss = 2.2460e-03, PNorm = 63.5734, GNorm = 0.7423, lr_0 = 9.1182e-04
Loss = 2.2682e-03, PNorm = 63.6281, GNorm = 0.6872, lr_0 = 9.1087e-04
Loss = 1.9885e-03, PNorm = 63.6835, GNorm = 1.0837, lr_0 = 9.0992e-04
Validation rmse logD = 0.706377
Validation R2 logD = 0.669228
Validation rmse logP = 0.536772
Validation R2 logP = 0.919587
Epoch 6
Train function
Loss = 1.7059e-03, PNorm = 63.7496, GNorm = 0.6377, lr_0 = 9.0887e-04
Loss = 1.8685e-03, PNorm = 63.8027, GNorm = 1.3608, lr_0 = 9.0792e-04
Loss = 2.3992e-03, PNorm = 63.8650, GNorm = 1.8624, lr_0 = 9.0698e-04
Loss = 2.0818e-03, PNorm = 63.9220, GNorm = 0.5805, lr_0 = 9.0603e-04
Loss = 1.8982e-03, PNorm = 63.9803, GNorm = 0.9039, lr_0 = 9.0508e-04
Loss = 2.3897e-03, PNorm = 64.0288, GNorm = 1.0933, lr_0 = 9.0414e-04
Loss = 1.6413e-03, PNorm = 64.0864, GNorm = 0.4903, lr_0 = 9.0320e-04
Loss = 1.9817e-03, PNorm = 64.1473, GNorm = 0.7000, lr_0 = 9.0225e-04
Loss = 1.7283e-03, PNorm = 64.1887, GNorm = 0.9690, lr_0 = 9.0131e-04
Loss = 2.2600e-03, PNorm = 64.2429, GNorm = 1.8849, lr_0 = 9.0037e-04
Loss = 2.1788e-03, PNorm = 64.3129, GNorm = 0.6120, lr_0 = 8.9943e-04
Loss = 1.7481e-03, PNorm = 64.3869, GNorm = 0.5526, lr_0 = 8.9849e-04
Loss = 2.1884e-03, PNorm = 64.4411, GNorm = 1.1314, lr_0 = 8.9756e-04
Loss = 1.8562e-03, PNorm = 64.5013, GNorm = 0.5985, lr_0 = 8.9662e-04
Loss = 1.7115e-03, PNorm = 64.5514, GNorm = 1.1183, lr_0 = 8.9568e-04
Loss = 1.5099e-03, PNorm = 64.5988, GNorm = 0.4685, lr_0 = 8.9475e-04
Loss = 1.6722e-03, PNorm = 64.6574, GNorm = 0.6351, lr_0 = 8.9381e-04
Loss = 1.7404e-03, PNorm = 64.7110, GNorm = 0.5975, lr_0 = 8.9288e-04
Loss = 1.9068e-03, PNorm = 64.7630, GNorm = 0.7487, lr_0 = 8.9195e-04
Loss = 1.9449e-03, PNorm = 64.8159, GNorm = 0.5822, lr_0 = 8.9102e-04
Loss = 1.5929e-03, PNorm = 64.8702, GNorm = 1.1592, lr_0 = 8.9009e-04
Loss = 1.8837e-03, PNorm = 64.9159, GNorm = 0.8271, lr_0 = 8.8916e-04
Validation rmse logD = 0.728399
Validation R2 logD = 0.648283
Validation rmse logP = 0.582519
Validation R2 logP = 0.905297
Epoch 7
Train function
Loss = 2.1922e-03, PNorm = 64.9697, GNorm = 1.1989, lr_0 = 8.8823e-04
Loss = 1.6163e-03, PNorm = 65.0334, GNorm = 0.9524, lr_0 = 8.8730e-04
Loss = 2.3393e-03, PNorm = 65.0968, GNorm = 0.6870, lr_0 = 8.8638e-04
Loss = 1.4717e-03, PNorm = 65.1496, GNorm = 0.5512, lr_0 = 8.8545e-04
Loss = 1.8168e-03, PNorm = 65.1973, GNorm = 0.4802, lr_0 = 8.8453e-04
Loss = 1.9319e-03, PNorm = 65.2623, GNorm = 1.0520, lr_0 = 8.8361e-04
Loss = 1.9569e-03, PNorm = 65.3250, GNorm = 0.5722, lr_0 = 8.8268e-04
Loss = 1.7471e-03, PNorm = 65.4034, GNorm = 1.3551, lr_0 = 8.8176e-04
Loss = 1.7285e-03, PNorm = 65.4802, GNorm = 0.9859, lr_0 = 8.8084e-04
Loss = 1.3878e-03, PNorm = 65.5500, GNorm = 1.1171, lr_0 = 8.7992e-04
Loss = 1.6986e-03, PNorm = 65.5975, GNorm = 0.4667, lr_0 = 8.7900e-04
Loss = 1.7870e-03, PNorm = 65.6588, GNorm = 0.6241, lr_0 = 8.7809e-04
Loss = 1.6649e-03, PNorm = 65.7266, GNorm = 1.1682, lr_0 = 8.7717e-04
Loss = 1.7305e-03, PNorm = 65.7741, GNorm = 0.5347, lr_0 = 8.7625e-04
Loss = 1.8438e-03, PNorm = 65.8240, GNorm = 0.8671, lr_0 = 8.7534e-04
Loss = 1.9491e-03, PNorm = 65.8767, GNorm = 1.5983, lr_0 = 8.7443e-04
Loss = 1.5136e-03, PNorm = 65.9244, GNorm = 0.7322, lr_0 = 8.7351e-04
Loss = 1.4388e-03, PNorm = 65.9749, GNorm = 0.6751, lr_0 = 8.7260e-04
Loss = 1.4446e-03, PNorm = 66.0242, GNorm = 0.7382, lr_0 = 8.7169e-04
Loss = 1.3720e-03, PNorm = 66.0636, GNorm = 0.4502, lr_0 = 8.7078e-04
Loss = 1.6373e-03, PNorm = 66.0926, GNorm = 0.9677, lr_0 = 8.6987e-04
Loss = 1.5213e-03, PNorm = 66.1289, GNorm = 1.1092, lr_0 = 8.6896e-04
Loss = 1.7163e-03, PNorm = 66.1835, GNorm = 0.4874, lr_0 = 8.6806e-04
Validation rmse logD = 0.686725
Validation R2 logD = 0.687377
Validation rmse logP = 0.497827
Validation R2 logP = 0.930832
Epoch 8
Train function
Loss = 1.3743e-03, PNorm = 66.2529, GNorm = 0.4218, lr_0 = 8.6706e-04
Loss = 1.5449e-03, PNorm = 66.3003, GNorm = 1.3485, lr_0 = 8.6616e-04
Loss = 1.5484e-03, PNorm = 66.3581, GNorm = 0.7216, lr_0 = 8.6525e-04
Loss = 1.3284e-03, PNorm = 66.4232, GNorm = 0.8515, lr_0 = 8.6435e-04
Loss = 1.5313e-03, PNorm = 66.4755, GNorm = 0.7679, lr_0 = 8.6345e-04
Loss = 1.4747e-03, PNorm = 66.5228, GNorm = 0.4386, lr_0 = 8.6255e-04
Loss = 1.6935e-03, PNorm = 66.5979, GNorm = 0.9671, lr_0 = 8.6165e-04
Loss = 1.4867e-03, PNorm = 66.6522, GNorm = 0.4812, lr_0 = 8.6075e-04
Loss = 1.8212e-03, PNorm = 66.7106, GNorm = 1.2405, lr_0 = 8.5985e-04
Loss = 1.7949e-03, PNorm = 66.7581, GNorm = 1.1721, lr_0 = 8.5895e-04
Loss = 1.8567e-03, PNorm = 66.8401, GNorm = 0.4007, lr_0 = 8.5805e-04
Loss = 1.2681e-03, PNorm = 66.8986, GNorm = 0.6206, lr_0 = 8.5716e-04
Loss = 1.3305e-03, PNorm = 66.9282, GNorm = 0.8804, lr_0 = 8.5626e-04
Loss = 1.4356e-03, PNorm = 66.9854, GNorm = 1.0737, lr_0 = 8.5537e-04
Loss = 1.3223e-03, PNorm = 67.0240, GNorm = 0.7927, lr_0 = 8.5448e-04
Loss = 1.0776e-03, PNorm = 67.0716, GNorm = 0.6132, lr_0 = 8.5359e-04
Loss = 1.5993e-03, PNorm = 67.1208, GNorm = 0.7617, lr_0 = 8.5269e-04
Loss = 1.5254e-03, PNorm = 67.1576, GNorm = 0.4913, lr_0 = 8.5180e-04
Loss = 1.2690e-03, PNorm = 67.2223, GNorm = 0.5259, lr_0 = 8.5092e-04
Loss = 1.5566e-03, PNorm = 67.2657, GNorm = 0.6804, lr_0 = 8.5003e-04
Loss = 1.8771e-03, PNorm = 67.3083, GNorm = 1.3223, lr_0 = 8.4914e-04
Loss = 1.5587e-03, PNorm = 67.3600, GNorm = 0.5860, lr_0 = 8.4825e-04
Validation rmse logD = 0.660021
Validation R2 logD = 0.711218
Validation rmse logP = 0.488998
Validation R2 logP = 0.933264
Epoch 9
Train function
Loss = 1.3695e-03, PNorm = 67.4110, GNorm = 0.7186, lr_0 = 8.4737e-04
Loss = 1.4231e-03, PNorm = 67.4628, GNorm = 1.5130, lr_0 = 8.4648e-04
Loss = 1.2740e-03, PNorm = 67.5255, GNorm = 0.6407, lr_0 = 8.4560e-04
Loss = 1.0975e-03, PNorm = 67.5780, GNorm = 0.4301, lr_0 = 8.4472e-04
Loss = 1.1224e-03, PNorm = 67.6122, GNorm = 0.8735, lr_0 = 8.4384e-04
Loss = 1.4063e-03, PNorm = 67.6600, GNorm = 0.6006, lr_0 = 8.4296e-04
Loss = 1.0851e-03, PNorm = 67.7187, GNorm = 0.7159, lr_0 = 8.4208e-04
Loss = 1.0687e-03, PNorm = 67.7662, GNorm = 0.4099, lr_0 = 8.4120e-04
Loss = 1.2929e-03, PNorm = 67.8106, GNorm = 0.6296, lr_0 = 8.4032e-04
Loss = 1.1884e-03, PNorm = 67.8668, GNorm = 0.4518, lr_0 = 8.3944e-04
Loss = 1.1682e-03, PNorm = 67.9087, GNorm = 0.4308, lr_0 = 8.3857e-04
Loss = 1.0472e-03, PNorm = 67.9506, GNorm = 0.7654, lr_0 = 8.3769e-04
Loss = 1.2545e-03, PNorm = 67.9952, GNorm = 1.1824, lr_0 = 8.3682e-04
Loss = 1.1006e-03, PNorm = 68.0481, GNorm = 0.8055, lr_0 = 8.3594e-04
Loss = 1.7499e-03, PNorm = 68.0885, GNorm = 1.1104, lr_0 = 8.3507e-04
Loss = 1.5130e-03, PNorm = 68.1524, GNorm = 0.5550, lr_0 = 8.3420e-04
Loss = 1.5146e-03, PNorm = 68.2153, GNorm = 0.8358, lr_0 = 8.3333e-04
Loss = 1.0871e-03, PNorm = 68.2606, GNorm = 0.4257, lr_0 = 8.3246e-04
Loss = 1.4944e-03, PNorm = 68.3111, GNorm = 2.0416, lr_0 = 8.3159e-04
Loss = 1.7969e-03, PNorm = 68.3749, GNorm = 0.7586, lr_0 = 8.3072e-04
Loss = 1.7849e-03, PNorm = 68.4423, GNorm = 0.3993, lr_0 = 8.2986e-04
Loss = 1.5554e-03, PNorm = 68.4988, GNorm = 0.6104, lr_0 = 8.2899e-04
Loss = 1.2347e-03, PNorm = 68.5608, GNorm = 0.4580, lr_0 = 8.2812e-04
Validation rmse logD = 0.683565
Validation R2 logD = 0.690248
Validation rmse logP = 0.474032
Validation R2 logP = 0.937286
Epoch 10
Train function
Loss = 9.1774e-04, PNorm = 68.6094, GNorm = 0.8556, lr_0 = 8.2717e-04
Loss = 1.1314e-03, PNorm = 68.6565, GNorm = 0.8069, lr_0 = 8.2631e-04
Loss = 1.0688e-03, PNorm = 68.6983, GNorm = 0.4935, lr_0 = 8.2545e-04
Loss = 1.0600e-03, PNorm = 68.7488, GNorm = 0.6987, lr_0 = 8.2459e-04
Loss = 9.7998e-04, PNorm = 68.7820, GNorm = 0.4969, lr_0 = 8.2373e-04
Loss = 1.0834e-03, PNorm = 68.8351, GNorm = 0.5203, lr_0 = 8.2287e-04
Loss = 1.1948e-03, PNorm = 68.8771, GNorm = 1.1878, lr_0 = 8.2201e-04
Loss = 1.1217e-03, PNorm = 68.9219, GNorm = 0.5267, lr_0 = 8.2115e-04
Loss = 1.0926e-03, PNorm = 68.9664, GNorm = 0.2991, lr_0 = 8.2029e-04
Loss = 1.2445e-03, PNorm = 69.0166, GNorm = 1.1544, lr_0 = 8.1944e-04
Loss = 1.0306e-03, PNorm = 69.0643, GNorm = 0.4089, lr_0 = 8.1858e-04
Loss = 1.2749e-03, PNorm = 69.1020, GNorm = 0.9826, lr_0 = 8.1773e-04
Loss = 1.1917e-03, PNorm = 69.1523, GNorm = 0.6506, lr_0 = 8.1687e-04
Loss = 1.0172e-03, PNorm = 69.1997, GNorm = 0.4656, lr_0 = 8.1602e-04
Loss = 9.0126e-04, PNorm = 69.2415, GNorm = 0.6985, lr_0 = 8.1517e-04
Loss = 1.0414e-03, PNorm = 69.2908, GNorm = 0.5103, lr_0 = 8.1432e-04
Loss = 1.3178e-03, PNorm = 69.3436, GNorm = 0.4036, lr_0 = 8.1347e-04
Loss = 1.0686e-03, PNorm = 69.3805, GNorm = 0.6148, lr_0 = 8.1262e-04
Loss = 1.2643e-03, PNorm = 69.4245, GNorm = 0.4762, lr_0 = 8.1177e-04
Loss = 1.2656e-03, PNorm = 69.4748, GNorm = 0.6760, lr_0 = 8.1092e-04
Loss = 1.5065e-03, PNorm = 69.5278, GNorm = 0.8242, lr_0 = 8.1008e-04
Loss = 1.2279e-03, PNorm = 69.5696, GNorm = 0.5739, lr_0 = 8.0923e-04
Loss = 1.3031e-03, PNorm = 69.6195, GNorm = 0.6845, lr_0 = 8.0839e-04
Validation rmse logD = 0.676736
Validation R2 logD = 0.696405
Validation rmse logP = 0.462447
Validation R2 logP = 0.940314
Epoch 11
Train function
Loss = 1.0619e-03, PNorm = 69.6679, GNorm = 0.7274, lr_0 = 8.0754e-04
Loss = 1.1991e-03, PNorm = 69.7085, GNorm = 0.4799, lr_0 = 8.0670e-04
Loss = 1.0518e-03, PNorm = 69.7665, GNorm = 0.4412, lr_0 = 8.0586e-04
Loss = 1.0579e-03, PNorm = 69.8100, GNorm = 0.8182, lr_0 = 8.0502e-04
Loss = 1.1490e-03, PNorm = 69.8643, GNorm = 0.7472, lr_0 = 8.0418e-04
Loss = 1.0303e-03, PNorm = 69.9144, GNorm = 0.4263, lr_0 = 8.0334e-04
Loss = 8.5808e-04, PNorm = 69.9559, GNorm = 0.4036, lr_0 = 8.0250e-04
Loss = 1.2017e-03, PNorm = 69.9988, GNorm = 0.4333, lr_0 = 8.0166e-04
Loss = 1.0163e-03, PNorm = 70.0436, GNorm = 0.6796, lr_0 = 8.0082e-04
Loss = 8.2714e-04, PNorm = 70.0921, GNorm = 0.4343, lr_0 = 7.9999e-04
Loss = 9.5662e-04, PNorm = 70.1336, GNorm = 0.4316, lr_0 = 7.9915e-04
Loss = 1.0685e-03, PNorm = 70.1805, GNorm = 1.0650, lr_0 = 7.9832e-04
Loss = 1.2897e-03, PNorm = 70.2308, GNorm = 1.1240, lr_0 = 7.9749e-04
Loss = 1.1184e-03, PNorm = 70.2873, GNorm = 0.4352, lr_0 = 7.9665e-04
Loss = 1.1875e-03, PNorm = 70.3330, GNorm = 0.9036, lr_0 = 7.9582e-04
Loss = 1.1770e-03, PNorm = 70.3870, GNorm = 0.4426, lr_0 = 7.9499e-04
Loss = 1.3627e-03, PNorm = 70.4508, GNorm = 1.1161, lr_0 = 7.9416e-04
Loss = 1.0721e-03, PNorm = 70.5252, GNorm = 0.8513, lr_0 = 7.9333e-04
Loss = 1.3332e-03, PNorm = 70.5827, GNorm = 0.4053, lr_0 = 7.9251e-04
Loss = 1.4372e-03, PNorm = 70.6350, GNorm = 0.5830, lr_0 = 7.9168e-04
Loss = 1.0251e-03, PNorm = 70.6892, GNorm = 0.5256, lr_0 = 7.9085e-04
Loss = 1.3464e-03, PNorm = 70.7230, GNorm = 0.4712, lr_0 = 7.9003e-04
Validation rmse logD = 0.655736
Validation R2 logD = 0.714955
Validation rmse logP = 0.499812
Validation R2 logP = 0.930280
Epoch 12
Train function
Loss = 9.5573e-04, PNorm = 70.7737, GNorm = 0.2470, lr_0 = 7.8912e-04
Loss = 1.0861e-03, PNorm = 70.8150, GNorm = 0.6943, lr_0 = 7.8830e-04
Loss = 7.8610e-04, PNorm = 70.8546, GNorm = 0.6740, lr_0 = 7.8747e-04
Loss = 8.1037e-04, PNorm = 70.8955, GNorm = 0.4574, lr_0 = 7.8665e-04
Loss = 8.9830e-04, PNorm = 70.9416, GNorm = 0.2987, lr_0 = 7.8583e-04
Loss = 8.3793e-04, PNorm = 70.9776, GNorm = 0.4611, lr_0 = 7.8501e-04
Loss = 8.6905e-04, PNorm = 71.0160, GNorm = 0.7683, lr_0 = 7.8419e-04
Loss = 8.6499e-04, PNorm = 71.0527, GNorm = 0.7141, lr_0 = 7.8337e-04
Loss = 9.3299e-04, PNorm = 71.0828, GNorm = 0.4446, lr_0 = 7.8255e-04
Loss = 1.0766e-03, PNorm = 71.1325, GNorm = 0.8566, lr_0 = 7.8174e-04
Loss = 8.4339e-04, PNorm = 71.1698, GNorm = 0.3946, lr_0 = 7.8092e-04
Loss = 8.9693e-04, PNorm = 71.1959, GNorm = 0.6789, lr_0 = 7.8011e-04
Loss = 9.4067e-04, PNorm = 71.2432, GNorm = 1.0353, lr_0 = 7.7929e-04
Loss = 8.8399e-04, PNorm = 71.2989, GNorm = 0.5646, lr_0 = 7.7848e-04
Loss = 9.6391e-04, PNorm = 71.3362, GNorm = 0.7803, lr_0 = 7.7767e-04
Loss = 1.1842e-03, PNorm = 71.3888, GNorm = 0.9123, lr_0 = 7.7686e-04
Loss = 9.8862e-04, PNorm = 71.4264, GNorm = 0.5316, lr_0 = 7.7604e-04
Loss = 1.1089e-03, PNorm = 71.4861, GNorm = 1.1637, lr_0 = 7.7523e-04
Loss = 1.0398e-03, PNorm = 71.5323, GNorm = 0.7939, lr_0 = 7.7443e-04
Loss = 8.9053e-04, PNorm = 71.5813, GNorm = 0.4389, lr_0 = 7.7362e-04
Loss = 1.0021e-03, PNorm = 71.6237, GNorm = 0.5435, lr_0 = 7.7281e-04
Loss = 9.8399e-04, PNorm = 71.6668, GNorm = 0.4795, lr_0 = 7.7200e-04
Loss = 9.7774e-04, PNorm = 71.7129, GNorm = 0.4165, lr_0 = 7.7120e-04
Validation rmse logD = 0.648875
Validation R2 logD = 0.720889
Validation rmse logP = 0.456911
Validation R2 logP = 0.941735
Epoch 13
Train function
Loss = 5.9701e-04, PNorm = 71.7613, GNorm = 0.5475, lr_0 = 7.7039e-04
Loss = 8.5718e-04, PNorm = 71.7962, GNorm = 0.8594, lr_0 = 7.6959e-04
Loss = 9.0781e-04, PNorm = 71.8287, GNorm = 0.5422, lr_0 = 7.6879e-04
Loss = 7.6807e-04, PNorm = 71.8658, GNorm = 0.3877, lr_0 = 7.6798e-04
Loss = 6.8002e-04, PNorm = 71.9033, GNorm = 0.5716, lr_0 = 7.6718e-04
Loss = 8.0044e-04, PNorm = 71.9390, GNorm = 0.5286, lr_0 = 7.6638e-04
Loss = 7.8871e-04, PNorm = 71.9773, GNorm = 0.6303, lr_0 = 7.6558e-04
Loss = 6.6561e-04, PNorm = 72.0196, GNorm = 0.7762, lr_0 = 7.6478e-04
Loss = 8.3078e-04, PNorm = 72.0509, GNorm = 0.5194, lr_0 = 7.6398e-04
Loss = 8.6434e-04, PNorm = 72.0870, GNorm = 0.5123, lr_0 = 7.6319e-04
Loss = 7.1186e-04, PNorm = 72.1293, GNorm = 0.4725, lr_0 = 7.6239e-04
Loss = 6.6645e-04, PNorm = 72.1634, GNorm = 0.4710, lr_0 = 7.6159e-04
Loss = 7.6647e-04, PNorm = 72.1951, GNorm = 0.4655, lr_0 = 7.6080e-04
