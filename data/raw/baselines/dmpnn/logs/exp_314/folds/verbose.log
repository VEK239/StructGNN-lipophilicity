Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_314/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.2962e-02, PNorm = 52.9145, GNorm = 9.9378, lr_0 = 1.9340e-04
Loss = 1.7060e-02, PNorm = 52.9205, GNorm = 4.3785, lr_0 = 2.7830e-04
Loss = 1.7309e-02, PNorm = 52.9317, GNorm = 2.0138, lr_0 = 3.6321e-04
Loss = 1.4104e-02, PNorm = 52.9497, GNorm = 2.0013, lr_0 = 4.4811e-04
Loss = 1.2458e-02, PNorm = 52.9704, GNorm = 2.3928, lr_0 = 5.3302e-04
Validation rmse logD = 1.024648
Validation R2 logD = 0.190348
Epoch 1
Train function
Loss = 1.2635e-02, PNorm = 53.0003, GNorm = 5.6123, lr_0 = 6.2642e-04
Loss = 1.2054e-02, PNorm = 53.0341, GNorm = 4.0941, lr_0 = 7.1132e-04
Loss = 1.1678e-02, PNorm = 53.0754, GNorm = 3.1647, lr_0 = 7.9623e-04
Loss = 1.1302e-02, PNorm = 53.1159, GNorm = 2.8943, lr_0 = 8.8113e-04
Loss = 1.2758e-02, PNorm = 53.1641, GNorm = 1.3929, lr_0 = 9.6604e-04
Validation rmse logD = 1.264126
Validation R2 logD = -0.232338
Epoch 2
Train function
Loss = 1.4892e-02, PNorm = 53.2252, GNorm = 6.4884, lr_0 = 9.9690e-04
Loss = 1.1891e-02, PNorm = 53.2951, GNorm = 4.0184, lr_0 = 9.9249e-04
Loss = 9.8439e-03, PNorm = 53.3625, GNorm = 0.9012, lr_0 = 9.8810e-04
Loss = 9.1995e-03, PNorm = 53.4172, GNorm = 1.7371, lr_0 = 9.8373e-04
Loss = 1.0353e-02, PNorm = 53.4695, GNorm = 3.0086, lr_0 = 9.7938e-04
Validation rmse logD = 0.820912
Validation R2 logD = 0.480312
Epoch 3
Train function
Loss = 6.9712e-03, PNorm = 53.5383, GNorm = 2.5987, lr_0 = 9.7462e-04
Loss = 7.1671e-03, PNorm = 53.5889, GNorm = 1.2256, lr_0 = 9.7030e-04
Loss = 8.0522e-03, PNorm = 53.6525, GNorm = 1.5939, lr_0 = 9.6601e-04
Loss = 8.4502e-03, PNorm = 53.7170, GNorm = 1.5646, lr_0 = 9.6174e-04
Loss = 8.8623e-03, PNorm = 53.7953, GNorm = 2.5168, lr_0 = 9.5749e-04
Loss = 8.8129e-03, PNorm = 53.8809, GNorm = 4.3053, lr_0 = 9.5325e-04
Validation rmse logD = 0.910222
Validation R2 logD = 0.361084
Epoch 4
Train function
Loss = 7.5131e-03, PNorm = 53.9540, GNorm = 1.7004, lr_0 = 9.4861e-04
Loss = 7.1857e-03, PNorm = 54.0325, GNorm = 3.5497, lr_0 = 9.4442e-04
Loss = 6.1899e-03, PNorm = 54.1161, GNorm = 1.6862, lr_0 = 9.4024e-04
Loss = 7.4404e-03, PNorm = 54.1833, GNorm = 4.4305, lr_0 = 9.3608e-04
Loss = 7.8213e-03, PNorm = 54.2683, GNorm = 1.2763, lr_0 = 9.3194e-04
Validation rmse logD = 0.760983
Validation R2 logD = 0.553420
Epoch 5
Train function
Loss = 6.3584e-03, PNorm = 54.3649, GNorm = 4.4702, lr_0 = 9.2741e-04
Loss = 7.0141e-03, PNorm = 54.4555, GNorm = 3.1860, lr_0 = 9.2330e-04
Loss = 6.1390e-03, PNorm = 54.5396, GNorm = 2.9172, lr_0 = 9.1922e-04
Loss = 6.7136e-03, PNorm = 54.6173, GNorm = 2.4330, lr_0 = 9.1515e-04
Loss = 5.8134e-03, PNorm = 54.7008, GNorm = 1.3641, lr_0 = 9.1111e-04
Validation rmse logD = 0.699152
Validation R2 logD = 0.623043
Epoch 6
Train function
Loss = 4.0310e-03, PNorm = 54.7865, GNorm = 1.4735, lr_0 = 9.0667e-04
Loss = 5.4200e-03, PNorm = 54.8698, GNorm = 4.3780, lr_0 = 9.0266e-04
Loss = 6.2094e-03, PNorm = 54.9585, GNorm = 0.9620, lr_0 = 8.9867e-04
Loss = 5.8973e-03, PNorm = 55.0332, GNorm = 2.5572, lr_0 = 8.9469e-04
Loss = 5.7866e-03, PNorm = 55.1165, GNorm = 0.7657, lr_0 = 8.9074e-04
Loss = 5.0762e-03, PNorm = 55.1960, GNorm = 2.3267, lr_0 = 8.8680e-04
Validation rmse logD = 0.698171
Validation R2 logD = 0.624100
Epoch 7
Train function
Loss = 4.5143e-03, PNorm = 55.2710, GNorm = 2.8706, lr_0 = 8.8248e-04
Loss = 5.1804e-03, PNorm = 55.3604, GNorm = 0.9667, lr_0 = 8.7858e-04
Loss = 4.6434e-03, PNorm = 55.4552, GNorm = 2.7311, lr_0 = 8.7469e-04
Loss = 5.4071e-03, PNorm = 55.5334, GNorm = 1.5841, lr_0 = 8.7082e-04
Loss = 5.6277e-03, PNorm = 55.6094, GNorm = 2.5511, lr_0 = 8.6697e-04
Validation rmse logD = 0.690405
Validation R2 logD = 0.632416
Epoch 8
Train function
Loss = 4.1538e-03, PNorm = 55.7155, GNorm = 1.0642, lr_0 = 8.6276e-04
Loss = 3.6763e-03, PNorm = 55.8038, GNorm = 1.3524, lr_0 = 8.5894e-04
Loss = 3.9204e-03, PNorm = 55.8830, GNorm = 1.0419, lr_0 = 8.5514e-04
Loss = 4.4642e-03, PNorm = 55.9464, GNorm = 2.2728, lr_0 = 8.5136e-04
Loss = 4.0792e-03, PNorm = 56.0358, GNorm = 2.7082, lr_0 = 8.4759e-04
Validation rmse logD = 0.724996
Validation R2 logD = 0.594659
Epoch 9
Train function
Loss = 5.0451e-03, PNorm = 56.1333, GNorm = 2.0987, lr_0 = 8.4347e-04
Loss = 4.2426e-03, PNorm = 56.2179, GNorm = 1.2866, lr_0 = 8.3974e-04
Loss = 3.9191e-03, PNorm = 56.3028, GNorm = 1.2036, lr_0 = 8.3602e-04
Loss = 3.8897e-03, PNorm = 56.4005, GNorm = 2.3471, lr_0 = 8.3232e-04
Loss = 4.3595e-03, PNorm = 56.5034, GNorm = 0.9319, lr_0 = 8.2864e-04
Loss = 3.4007e-03, PNorm = 56.5659, GNorm = 1.2314, lr_0 = 8.2498e-04
Validation rmse logD = 0.653470
Validation R2 logD = 0.670694
Epoch 10
Train function
Loss = 3.3591e-03, PNorm = 56.6511, GNorm = 0.8014, lr_0 = 8.2133e-04
Loss = 3.5271e-03, PNorm = 56.7492, GNorm = 1.4916, lr_0 = 8.1770e-04
Loss = 3.8405e-03, PNorm = 56.8366, GNorm = 1.3033, lr_0 = 8.1408e-04
Loss = 2.9854e-03, PNorm = 56.9151, GNorm = 1.5964, lr_0 = 8.1048e-04
Loss = 2.7671e-03, PNorm = 56.9803, GNorm = 1.4945, lr_0 = 8.0689e-04
Validation rmse logD = 0.658229
Validation R2 logD = 0.665879
Epoch 11
Train function
Loss = 3.0392e-03, PNorm = 57.0444, GNorm = 1.6662, lr_0 = 8.0297e-04
Loss = 2.8401e-03, PNorm = 57.1144, GNorm = 1.5876, lr_0 = 7.9942e-04
Loss = 2.8386e-03, PNorm = 57.1843, GNorm = 0.8661, lr_0 = 7.9588e-04
Loss = 2.8519e-03, PNorm = 57.2493, GNorm = 0.7719, lr_0 = 7.9236e-04
Loss = 3.4958e-03, PNorm = 57.3282, GNorm = 2.1350, lr_0 = 7.8885e-04
Validation rmse logD = 0.680689
Validation R2 logD = 0.642688
Epoch 12
Train function
Loss = 3.6956e-03, PNorm = 57.4073, GNorm = 1.5701, lr_0 = 7.8502e-04
Loss = 3.0751e-03, PNorm = 57.4927, GNorm = 0.7657, lr_0 = 7.8154e-04
Loss = 2.7656e-03, PNorm = 57.5692, GNorm = 1.2752, lr_0 = 7.7809e-04
Loss = 3.0731e-03, PNorm = 57.6438, GNorm = 1.8684, lr_0 = 7.7465e-04
Loss = 2.7495e-03, PNorm = 57.7226, GNorm = 1.3117, lr_0 = 7.7122e-04
Loss = 2.7391e-03, PNorm = 57.7939, GNorm = 0.8982, lr_0 = 7.6781e-04
Loss = 9.8730e-03, PNorm = 57.8012, GNorm = 1.3339, lr_0 = 7.6747e-04
Validation rmse logD = 0.640727
Validation R2 logD = 0.683411
Epoch 13
Train function
Loss = 2.2716e-03, PNorm = 57.8698, GNorm = 0.7605, lr_0 = 7.6407e-04
Loss = 2.2356e-03, PNorm = 57.9502, GNorm = 0.8886, lr_0 = 7.6069e-04
Loss = 2.8223e-03, PNorm = 58.0204, GNorm = 1.2809, lr_0 = 7.5733e-04
Loss = 2.4576e-03, PNorm = 58.0775, GNorm = 1.6595, lr_0 = 7.5398e-04
Loss = 2.4664e-03, PNorm = 58.1539, GNorm = 1.0420, lr_0 = 7.5064e-04
Validation rmse logD = 0.641994
Validation R2 logD = 0.682158
Epoch 14
Train function
Loss = 2.9330e-03, PNorm = 58.2378, GNorm = 1.4277, lr_0 = 7.4699e-04
Loss = 2.3620e-03, PNorm = 58.3237, GNorm = 0.8291, lr_0 = 7.4369e-04
Loss = 2.3627e-03, PNorm = 58.4039, GNorm = 1.4994, lr_0 = 7.4040e-04
Loss = 2.6242e-03, PNorm = 58.4783, GNorm = 2.5347, lr_0 = 7.3712e-04
Loss = 2.1972e-03, PNorm = 58.5431, GNorm = 1.0603, lr_0 = 7.3386e-04
Validation rmse logD = 0.631210
Validation R2 logD = 0.692746
Epoch 15
Train function
Loss = 1.6507e-03, PNorm = 58.6136, GNorm = 0.4739, lr_0 = 7.3029e-04
Loss = 2.1844e-03, PNorm = 58.6802, GNorm = 1.3389, lr_0 = 7.2706e-04
Loss = 2.0501e-03, PNorm = 58.7646, GNorm = 0.7433, lr_0 = 7.2385e-04
Loss = 2.2059e-03, PNorm = 58.8354, GNorm = 1.6585, lr_0 = 7.2064e-04
Loss = 2.0246e-03, PNorm = 58.8878, GNorm = 1.8919, lr_0 = 7.1746e-04
Validation rmse logD = 0.619902
Validation R2 logD = 0.703656
Epoch 16
Train function
Loss = 1.8380e-03, PNorm = 58.9452, GNorm = 0.7433, lr_0 = 7.1397e-04
Loss = 1.5289e-03, PNorm = 58.9995, GNorm = 0.8085, lr_0 = 7.1081e-04
Loss = 1.4004e-03, PNorm = 59.0517, GNorm = 0.7316, lr_0 = 7.0766e-04
Loss = 1.9231e-03, PNorm = 59.1060, GNorm = 1.0805, lr_0 = 7.0453e-04
Loss = 1.5073e-03, PNorm = 59.1599, GNorm = 0.6477, lr_0 = 7.0142e-04
Loss = 1.9233e-03, PNorm = 59.2168, GNorm = 3.2840, lr_0 = 6.9831e-04
Validation rmse logD = 0.617881
Validation R2 logD = 0.705585
Epoch 17
Train function
Loss = 1.6990e-03, PNorm = 59.2711, GNorm = 1.8114, lr_0 = 6.9492e-04
Loss = 1.6015e-03, PNorm = 59.3265, GNorm = 0.4862, lr_0 = 6.9184e-04
Loss = 1.6554e-03, PNorm = 59.3746, GNorm = 0.5276, lr_0 = 6.8878e-04
Loss = 1.5568e-03, PNorm = 59.4301, GNorm = 1.0450, lr_0 = 6.8574e-04
Loss = 1.4549e-03, PNorm = 59.4847, GNorm = 1.1673, lr_0 = 6.8270e-04
Validation rmse logD = 0.624016
Validation R2 logD = 0.699710
Epoch 18
Train function
Loss = 1.1385e-03, PNorm = 59.5381, GNorm = 0.5264, lr_0 = 6.7938e-04
Loss = 1.2729e-03, PNorm = 59.5945, GNorm = 0.5480, lr_0 = 6.7638e-04
Loss = 1.3050e-03, PNorm = 59.6409, GNorm = 0.6891, lr_0 = 6.7338e-04
Loss = 1.4199e-03, PNorm = 59.6823, GNorm = 0.7501, lr_0 = 6.7041e-04
Loss = 1.5080e-03, PNorm = 59.7247, GNorm = 1.6830, lr_0 = 6.6744e-04
Validation rmse logD = 0.665984
Validation R2 logD = 0.657960
Epoch 19
Train function
Loss = 2.2044e-03, PNorm = 59.7829, GNorm = 2.5690, lr_0 = 6.6419e-04
Loss = 1.6286e-03, PNorm = 59.8377, GNorm = 1.1058, lr_0 = 6.6126e-04
Loss = 1.4879e-03, PNorm = 59.8959, GNorm = 0.6917, lr_0 = 6.5833e-04
Loss = 1.3921e-03, PNorm = 59.9446, GNorm = 0.9749, lr_0 = 6.5542e-04
Loss = 1.1497e-03, PNorm = 59.9982, GNorm = 0.7509, lr_0 = 6.5252e-04
Loss = 1.2007e-03, PNorm = 60.0527, GNorm = 0.7996, lr_0 = 6.4963e-04
Validation rmse logD = 0.606344
Validation R2 logD = 0.716477
Epoch 20
Train function
Loss = 1.0251e-03, PNorm = 60.0972, GNorm = 0.9066, lr_0 = 6.4676e-04
Loss = 1.0276e-03, PNorm = 60.1299, GNorm = 0.5632, lr_0 = 6.4390e-04
Loss = 1.0718e-03, PNorm = 60.1708, GNorm = 0.7486, lr_0 = 6.4105e-04
Loss = 1.1190e-03, PNorm = 60.2096, GNorm = 0.9788, lr_0 = 6.3822e-04
Loss = 1.1286e-03, PNorm = 60.2491, GNorm = 0.7876, lr_0 = 6.3539e-04
Validation rmse logD = 0.598140
Validation R2 logD = 0.724098
Epoch 21
Train function
Loss = 1.0610e-03, PNorm = 60.2851, GNorm = 0.5521, lr_0 = 6.3230e-04
Loss = 1.0304e-03, PNorm = 60.3314, GNorm = 1.8717, lr_0 = 6.2950e-04
Loss = 9.8071e-04, PNorm = 60.3713, GNorm = 0.4987, lr_0 = 6.2672e-04
Loss = 9.4644e-04, PNorm = 60.4114, GNorm = 0.6169, lr_0 = 6.2395e-04
Loss = 9.1839e-04, PNorm = 60.4500, GNorm = 0.6028, lr_0 = 6.2119e-04
Validation rmse logD = 0.588469
Validation R2 logD = 0.732947
Epoch 22
Train function
Loss = 8.4100e-04, PNorm = 60.4826, GNorm = 0.5372, lr_0 = 6.1817e-04
Loss = 1.0114e-03, PNorm = 60.5189, GNorm = 2.9465, lr_0 = 6.1543e-04
Loss = 1.1171e-03, PNorm = 60.5586, GNorm = 1.9159, lr_0 = 6.1271e-04
Loss = 9.8577e-04, PNorm = 60.6076, GNorm = 1.0031, lr_0 = 6.1000e-04
Loss = 9.5214e-04, PNorm = 60.6454, GNorm = 0.5518, lr_0 = 6.0730e-04
Loss = 8.4735e-04, PNorm = 60.6864, GNorm = 0.5892, lr_0 = 6.0461e-04
Validation rmse logD = 0.593690
Validation R2 logD = 0.728188
Epoch 23
Train function
Loss = 7.6344e-04, PNorm = 60.7262, GNorm = 0.7140, lr_0 = 6.0167e-04
Loss = 8.6864e-04, PNorm = 60.7574, GNorm = 0.6567, lr_0 = 5.9901e-04
Loss = 7.1674e-04, PNorm = 60.7768, GNorm = 0.7335, lr_0 = 5.9636e-04
Loss = 8.1086e-04, PNorm = 60.8090, GNorm = 0.9374, lr_0 = 5.9372e-04
Loss = 6.7639e-04, PNorm = 60.8418, GNorm = 0.4525, lr_0 = 5.9110e-04
Validation rmse logD = 0.604639
Validation R2 logD = 0.718070
Epoch 24
Train function
Loss = 7.8320e-04, PNorm = 60.8664, GNorm = 0.6356, lr_0 = 5.8822e-04
Loss = 6.7162e-04, PNorm = 60.8910, GNorm = 0.5193, lr_0 = 5.8562e-04
Loss = 7.7022e-04, PNorm = 60.9215, GNorm = 0.5646, lr_0 = 5.8303e-04
Loss = 6.6363e-04, PNorm = 60.9548, GNorm = 0.8364, lr_0 = 5.8045e-04
Loss = 9.2026e-04, PNorm = 60.9821, GNorm = 1.6334, lr_0 = 5.7788e-04
Validation rmse logD = 0.625201
Validation R2 logD = 0.698568
Epoch 25
Train function
Loss = 7.8042e-04, PNorm = 61.0228, GNorm = 1.1826, lr_0 = 5.7507e-04
Loss = 6.9604e-04, PNorm = 61.0575, GNorm = 1.2220, lr_0 = 5.7253e-04
Loss = 7.2633e-04, PNorm = 61.0765, GNorm = 1.2184, lr_0 = 5.7000e-04
Loss = 6.2782e-04, PNorm = 61.0975, GNorm = 1.1302, lr_0 = 5.6748e-04
Loss = 7.1295e-04, PNorm = 61.1232, GNorm = 0.9195, lr_0 = 5.6497e-04
Loss = 8.1148e-04, PNorm = 61.1547, GNorm = 0.5735, lr_0 = 5.6247e-04
Loss = 2.2263e-03, PNorm = 61.1573, GNorm = 1.2440, lr_0 = 5.6222e-04
Validation rmse logD = 0.595270
Validation R2 logD = 0.726739
Epoch 26
Train function
Loss = 5.2907e-04, PNorm = 61.1850, GNorm = 0.8220, lr_0 = 5.5973e-04
Loss = 6.0703e-04, PNorm = 61.2046, GNorm = 0.3795, lr_0 = 5.5725e-04
Loss = 5.1201e-04, PNorm = 61.2273, GNorm = 1.1718, lr_0 = 5.5479e-04
Loss = 6.3853e-04, PNorm = 61.2476, GNorm = 0.8719, lr_0 = 5.5233e-04
Loss = 6.3878e-04, PNorm = 61.2656, GNorm = 0.5522, lr_0 = 5.4989e-04
Validation rmse logD = 0.597015
Validation R2 logD = 0.725135
Epoch 27
Train function
Loss = 5.2715e-04, PNorm = 61.2911, GNorm = 1.0116, lr_0 = 5.4722e-04
Loss = 5.4523e-04, PNorm = 61.3274, GNorm = 0.4091, lr_0 = 5.4480e-04
Loss = 5.9696e-04, PNorm = 61.3548, GNorm = 0.2974, lr_0 = 5.4239e-04
Loss = 5.5273e-04, PNorm = 61.3799, GNorm = 0.4250, lr_0 = 5.3999e-04
Loss = 5.7442e-04, PNorm = 61.4034, GNorm = 0.3971, lr_0 = 5.3760e-04
Validation rmse logD = 0.593959
Validation R2 logD = 0.727941
Epoch 28
Train function
Loss = 4.3544e-04, PNorm = 61.4239, GNorm = 0.4642, lr_0 = 5.3498e-04
Loss = 4.4503e-04, PNorm = 61.4443, GNorm = 0.4521, lr_0 = 5.3262e-04
Loss = 4.3426e-04, PNorm = 61.4630, GNorm = 0.6761, lr_0 = 5.3026e-04
Loss = 5.2985e-04, PNorm = 61.4825, GNorm = 1.5563, lr_0 = 5.2792e-04
Loss = 4.4442e-04, PNorm = 61.5031, GNorm = 0.4777, lr_0 = 5.2558e-04
Validation rmse logD = 0.609158
Validation R2 logD = 0.713839
Epoch 29
Train function
Loss = 4.3232e-04, PNorm = 61.5243, GNorm = 1.1821, lr_0 = 5.2302e-04
Loss = 6.5502e-04, PNorm = 61.5468, GNorm = 0.9576, lr_0 = 5.2071e-04
Loss = 4.4331e-04, PNorm = 61.5707, GNorm = 0.3067, lr_0 = 5.1841e-04
Loss = 4.8607e-04, PNorm = 61.5924, GNorm = 0.3486, lr_0 = 5.1611e-04
Loss = 4.4166e-04, PNorm = 61.6124, GNorm = 0.8911, lr_0 = 5.1383e-04
Loss = 4.8645e-04, PNorm = 61.6294, GNorm = 1.0684, lr_0 = 5.1156e-04
Validation rmse logD = 0.588146
Validation R2 logD = 0.733241
Epoch 30
Train function
Loss = 4.3823e-04, PNorm = 61.6462, GNorm = 0.5710, lr_0 = 5.0930e-04
Loss = 4.5829e-04, PNorm = 61.6694, GNorm = 0.5496, lr_0 = 5.0704e-04
Loss = 4.0405e-04, PNorm = 61.6885, GNorm = 0.6522, lr_0 = 5.0480e-04
Loss = 3.2619e-04, PNorm = 61.7059, GNorm = 0.5623, lr_0 = 5.0257e-04
Loss = 3.9873e-04, PNorm = 61.7240, GNorm = 0.5695, lr_0 = 5.0034e-04
Validation rmse logD = 0.593156
Validation R2 logD = 0.728677
Epoch 31
Train function
Loss = 4.2006e-04, PNorm = 61.7388, GNorm = 0.5022, lr_0 = 4.9791e-04
Loss = 3.9136e-04, PNorm = 61.7547, GNorm = 0.4302, lr_0 = 4.9571e-04
Loss = 3.1799e-04, PNorm = 61.7735, GNorm = 0.9973, lr_0 = 4.9351e-04
Loss = 3.6578e-04, PNorm = 61.7891, GNorm = 0.2737, lr_0 = 4.9133e-04
Loss = 4.2680e-04, PNorm = 61.8078, GNorm = 0.8159, lr_0 = 4.8916e-04
Validation rmse logD = 0.613270
Validation R2 logD = 0.709964
Epoch 32
Train function
Loss = 6.6078e-04, PNorm = 61.8276, GNorm = 1.7581, lr_0 = 4.8678e-04
Loss = 5.6836e-04, PNorm = 61.8521, GNorm = 0.8282, lr_0 = 4.8463e-04
Loss = 6.6384e-04, PNorm = 61.8838, GNorm = 0.4714, lr_0 = 4.8248e-04
Loss = 4.4284e-04, PNorm = 61.9093, GNorm = 0.4110, lr_0 = 4.8035e-04
Loss = 4.1158e-04, PNorm = 61.9293, GNorm = 0.4638, lr_0 = 4.7822e-04
Loss = 3.3641e-04, PNorm = 61.9425, GNorm = 0.4222, lr_0 = 4.7611e-04
Validation rmse logD = 0.585157
Validation R2 logD = 0.735945
Epoch 33
Train function
Loss = 3.7621e-04, PNorm = 61.9616, GNorm = 0.9685, lr_0 = 4.7379e-04
Loss = 2.8863e-04, PNorm = 61.9786, GNorm = 0.3675, lr_0 = 4.7170e-04
Loss = 3.5280e-04, PNorm = 61.9887, GNorm = 0.5959, lr_0 = 4.6961e-04
Loss = 2.7553e-04, PNorm = 62.0029, GNorm = 0.5838, lr_0 = 4.6753e-04
Loss = 3.6784e-04, PNorm = 62.0160, GNorm = 0.9135, lr_0 = 4.6546e-04
Validation rmse logD = 0.594381
Validation R2 logD = 0.727555
Epoch 34
Train function
Loss = 2.7978e-04, PNorm = 62.0372, GNorm = 0.2708, lr_0 = 4.6320e-04
Loss = 3.3158e-04, PNorm = 62.0560, GNorm = 0.6931, lr_0 = 4.6115e-04
Loss = 4.1461e-04, PNorm = 62.0682, GNorm = 0.4041, lr_0 = 4.5911e-04
Loss = 3.0201e-04, PNorm = 62.0806, GNorm = 0.4231, lr_0 = 4.5708e-04
Loss = 2.9890e-04, PNorm = 62.0983, GNorm = 0.3077, lr_0 = 4.5506e-04
Validation rmse logD = 0.590908
Validation R2 logD = 0.730729
Epoch 35
Train function
Loss = 2.8535e-04, PNorm = 62.1175, GNorm = 0.4098, lr_0 = 4.5284e-04
Loss = 2.5049e-04, PNorm = 62.1312, GNorm = 0.9173, lr_0 = 4.5084e-04
Loss = 3.4177e-04, PNorm = 62.1429, GNorm = 1.0131, lr_0 = 4.4885e-04
Loss = 2.9642e-04, PNorm = 62.1541, GNorm = 0.6593, lr_0 = 4.4686e-04
Loss = 3.0279e-04, PNorm = 62.1679, GNorm = 0.4442, lr_0 = 4.4489e-04
Loss = 3.5051e-04, PNorm = 62.1821, GNorm = 0.5970, lr_0 = 4.4292e-04
Validation rmse logD = 0.593356
Validation R2 logD = 0.728494
Epoch 36
Train function
Loss = 2.7974e-04, PNorm = 62.2044, GNorm = 0.3016, lr_0 = 4.4076e-04
Loss = 2.6177e-04, PNorm = 62.2192, GNorm = 0.2728, lr_0 = 4.3881e-04
Loss = 2.5758e-04, PNorm = 62.2292, GNorm = 0.5904, lr_0 = 4.3687e-04
Loss = 2.2608e-04, PNorm = 62.2393, GNorm = 0.6022, lr_0 = 4.3494e-04
Loss = 3.0657e-04, PNorm = 62.2519, GNorm = 0.6940, lr_0 = 4.3302e-04
Validation rmse logD = 0.588988
Validation R2 logD = 0.732477
Epoch 37
Train function
Loss = 2.2417e-04, PNorm = 62.2598, GNorm = 0.3525, lr_0 = 4.3091e-04
Loss = 2.2428e-04, PNorm = 62.2761, GNorm = 0.2809, lr_0 = 4.2900e-04
Loss = 2.3034e-04, PNorm = 62.2886, GNorm = 0.5656, lr_0 = 4.2711e-04
Loss = 2.4097e-04, PNorm = 62.3004, GNorm = 0.5053, lr_0 = 4.2522e-04
Loss = 2.2934e-04, PNorm = 62.3103, GNorm = 0.3788, lr_0 = 4.2334e-04
Validation rmse logD = 0.596348
Validation R2 logD = 0.725749
Epoch 38
Train function
Loss = 2.8358e-04, PNorm = 62.3205, GNorm = 0.9729, lr_0 = 4.2128e-04
Loss = 4.3382e-04, PNorm = 62.3381, GNorm = 1.2052, lr_0 = 4.1941e-04
Loss = 2.6972e-04, PNorm = 62.3545, GNorm = 0.3582, lr_0 = 4.1756e-04
Loss = 2.5118e-04, PNorm = 62.3684, GNorm = 0.2512, lr_0 = 4.1571e-04
Loss = 2.8273e-04, PNorm = 62.3848, GNorm = 0.3342, lr_0 = 4.1387e-04
Loss = 2.1539e-04, PNorm = 62.3979, GNorm = 0.2346, lr_0 = 4.1204e-04
Loss = 1.7830e-03, PNorm = 62.3988, GNorm = 1.0153, lr_0 = 4.1186e-04
Validation rmse logD = 0.599202
Validation R2 logD = 0.723117
Epoch 39
Train function
Loss = 2.4920e-04, PNorm = 62.4104, GNorm = 1.2454, lr_0 = 4.1004e-04
Loss = 3.0367e-04, PNorm = 62.4237, GNorm = 0.9238, lr_0 = 4.0822e-04
Loss = 2.4231e-04, PNorm = 62.4377, GNorm = 0.8356, lr_0 = 4.0642e-04
Loss = 2.2648e-04, PNorm = 62.4487, GNorm = 0.3745, lr_0 = 4.0462e-04
Loss = 2.4617e-04, PNorm = 62.4602, GNorm = 0.4610, lr_0 = 4.0283e-04
Validation rmse logD = 0.587747
Validation R2 logD = 0.733602
Epoch 40
Train function
Loss = 2.0133e-04, PNorm = 62.4710, GNorm = 0.5964, lr_0 = 4.0105e-04
Loss = 1.8365e-04, PNorm = 62.4784, GNorm = 0.3814, lr_0 = 3.9927e-04
Loss = 1.8408e-04, PNorm = 62.4873, GNorm = 0.2470, lr_0 = 3.9751e-04
Loss = 1.6795e-04, PNorm = 62.4975, GNorm = 0.5332, lr_0 = 3.9575e-04
Loss = 1.6854e-04, PNorm = 62.5089, GNorm = 0.2108, lr_0 = 3.9400e-04
Validation rmse logD = 0.591915
Validation R2 logD = 0.729811
Epoch 41
Train function
Loss = 1.5063e-04, PNorm = 62.5177, GNorm = 0.3003, lr_0 = 3.9208e-04
Loss = 1.8710e-04, PNorm = 62.5255, GNorm = 0.5656, lr_0 = 3.9035e-04
Loss = 1.8532e-04, PNorm = 62.5341, GNorm = 0.7028, lr_0 = 3.8862e-04
Loss = 1.8599e-04, PNorm = 62.5444, GNorm = 0.2372, lr_0 = 3.8690e-04
Loss = 1.4557e-04, PNorm = 62.5523, GNorm = 0.2372, lr_0 = 3.8519e-04
Loss = 1.3002e-04, PNorm = 62.5593, GNorm = 0.4700, lr_0 = 3.8349e-04
Loss = 1.9009e-03, PNorm = 62.5598, GNorm = 0.7522, lr_0 = 3.8332e-04
Validation rmse logD = 0.586726
Validation R2 logD = 0.734527
Epoch 42
Train function
Loss = 1.1530e-04, PNorm = 62.5675, GNorm = 0.2393, lr_0 = 3.8162e-04
Loss = 1.3659e-04, PNorm = 62.5781, GNorm = 0.3101, lr_0 = 3.7993e-04
Loss = 1.3543e-04, PNorm = 62.5864, GNorm = 0.3042, lr_0 = 3.7825e-04
Loss = 2.0210e-04, PNorm = 62.5921, GNorm = 0.4392, lr_0 = 3.7658e-04
Loss = 1.2090e-04, PNorm = 62.5991, GNorm = 0.2078, lr_0 = 3.7491e-04
Validation rmse logD = 0.593619
Validation R2 logD = 0.728253
Epoch 43
Train function
Loss = 1.2480e-04, PNorm = 62.6082, GNorm = 0.3254, lr_0 = 3.7309e-04
Loss = 1.7299e-04, PNorm = 62.6150, GNorm = 0.2844, lr_0 = 3.7144e-04
Loss = 1.5472e-04, PNorm = 62.6224, GNorm = 0.6083, lr_0 = 3.6980e-04
Loss = 1.3012e-04, PNorm = 62.6291, GNorm = 0.3860, lr_0 = 3.6816e-04
Loss = 1.5814e-04, PNorm = 62.6371, GNorm = 0.2162, lr_0 = 3.6653e-04
Validation rmse logD = 0.589640
Validation R2 logD = 0.731883
Epoch 44
Train function
Loss = 1.0790e-04, PNorm = 62.6456, GNorm = 0.1962, lr_0 = 3.6475e-04
Loss = 1.1560e-04, PNorm = 62.6530, GNorm = 0.4350, lr_0 = 3.6314e-04
Loss = 1.4778e-04, PNorm = 62.6610, GNorm = 0.1875, lr_0 = 3.6153e-04
Loss = 1.2726e-04, PNorm = 62.6668, GNorm = 0.1758, lr_0 = 3.5993e-04
Loss = 1.5292e-04, PNorm = 62.6735, GNorm = 0.2178, lr_0 = 3.5834e-04
Validation rmse logD = 0.591077
Validation R2 logD = 0.730576
Epoch 45
Train function
Loss = 5.6304e-05, PNorm = 62.6813, GNorm = 0.2249, lr_0 = 3.5660e-04
Loss = 1.0527e-04, PNorm = 62.6867, GNorm = 0.1977, lr_0 = 3.5502e-04
Loss = 8.5146e-05, PNorm = 62.6933, GNorm = 0.1416, lr_0 = 3.5345e-04
Loss = 1.1550e-04, PNorm = 62.7000, GNorm = 0.2500, lr_0 = 3.5188e-04
Loss = 1.2778e-04, PNorm = 62.7062, GNorm = 0.1433, lr_0 = 3.5033e-04
Loss = 1.2569e-04, PNorm = 62.7124, GNorm = 0.3219, lr_0 = 3.4878e-04
Validation rmse logD = 0.591630
Validation R2 logD = 0.730071
Epoch 46
Train function
Loss = 1.1357e-04, PNorm = 62.7207, GNorm = 0.4330, lr_0 = 3.4708e-04
Loss = 1.2464e-04, PNorm = 62.7279, GNorm = 0.2468, lr_0 = 3.4555e-04
Loss = 1.0885e-04, PNorm = 62.7344, GNorm = 0.4373, lr_0 = 3.4402e-04
Loss = 1.1313e-04, PNorm = 62.7399, GNorm = 0.1651, lr_0 = 3.4250e-04
Loss = 1.2058e-04, PNorm = 62.7493, GNorm = 0.2283, lr_0 = 3.4098e-04
Validation rmse logD = 0.590733
Validation R2 logD = 0.730889
Epoch 47
Train function
Loss = 1.3141e-04, PNorm = 62.7559, GNorm = 0.2251, lr_0 = 3.3932e-04
Loss = 1.2242e-04, PNorm = 62.7645, GNorm = 0.5315, lr_0 = 3.3782e-04
Loss = 1.1571e-04, PNorm = 62.7726, GNorm = 0.2585, lr_0 = 3.3633e-04
Loss = 1.3840e-04, PNorm = 62.7806, GNorm = 0.2212, lr_0 = 3.3484e-04
Loss = 1.1604e-04, PNorm = 62.7827, GNorm = 0.1779, lr_0 = 3.3336e-04
Validation rmse logD = 0.612710
Validation R2 logD = 0.710493
Epoch 48
Train function
Loss = 3.9306e-04, PNorm = 62.7893, GNorm = 1.7189, lr_0 = 3.3174e-04
Loss = 3.0961e-04, PNorm = 62.7982, GNorm = 0.5765, lr_0 = 3.3027e-04
Loss = 1.7582e-04, PNorm = 62.8122, GNorm = 0.4001, lr_0 = 3.2881e-04
Loss = 1.3206e-04, PNorm = 62.8234, GNorm = 0.2352, lr_0 = 3.2735e-04
Loss = 1.6532e-04, PNorm = 62.8321, GNorm = 0.3731, lr_0 = 3.2591e-04
Loss = 1.4765e-04, PNorm = 62.8427, GNorm = 0.2461, lr_0 = 3.2446e-04
Validation rmse logD = 0.590371
Validation R2 logD = 0.731219
Epoch 49
Train function
Loss = 1.2083e-04, PNorm = 62.8536, GNorm = 0.5392, lr_0 = 3.2289e-04
Loss = 1.2360e-04, PNorm = 62.8642, GNorm = 0.7128, lr_0 = 3.2146e-04
Loss = 1.8876e-04, PNorm = 62.8685, GNorm = 0.8994, lr_0 = 3.2004e-04
Loss = 1.3101e-04, PNorm = 62.8742, GNorm = 0.4929, lr_0 = 3.1862e-04
Loss = 1.1441e-04, PNorm = 62.8849, GNorm = 0.4688, lr_0 = 3.1721e-04
Validation rmse logD = 0.593033
Validation R2 logD = 0.728789
Epoch 50
Train function
Loss = 9.7367e-05, PNorm = 62.8938, GNorm = 0.3748, lr_0 = 3.1581e-04
Loss = 9.0104e-05, PNorm = 62.9004, GNorm = 0.1929, lr_0 = 3.1441e-04
Loss = 1.2316e-04, PNorm = 62.9061, GNorm = 0.2551, lr_0 = 3.1302e-04
Loss = 1.6452e-04, PNorm = 62.9137, GNorm = 0.3766, lr_0 = 3.1164e-04
Loss = 1.0349e-04, PNorm = 62.9229, GNorm = 0.3734, lr_0 = 3.1026e-04
Validation rmse logD = 0.590321
Validation R2 logD = 0.731264
Epoch 51
Train function
Loss = 1.3762e-04, PNorm = 62.9301, GNorm = 0.8066, lr_0 = 3.0875e-04
Loss = 1.1802e-04, PNorm = 62.9360, GNorm = 0.2330, lr_0 = 3.0738e-04
Loss = 1.2978e-04, PNorm = 62.9441, GNorm = 0.2681, lr_0 = 3.0602e-04
Loss = 1.0392e-04, PNorm = 62.9493, GNorm = 0.2464, lr_0 = 3.0467e-04
Loss = 9.4006e-05, PNorm = 62.9563, GNorm = 0.1902, lr_0 = 3.0332e-04
Loss = 8.8348e-05, PNorm = 62.9608, GNorm = 0.2377, lr_0 = 3.0198e-04
Validation rmse logD = 0.588887
Validation R2 logD = 0.732568
Epoch 52
Train function
Loss = 9.4670e-05, PNorm = 62.9656, GNorm = 0.2351, lr_0 = 3.0051e-04
Loss = 8.5376e-05, PNorm = 62.9721, GNorm = 0.1898, lr_0 = 2.9918e-04
Loss = 8.5036e-05, PNorm = 62.9768, GNorm = 0.1443, lr_0 = 2.9786e-04
Loss = 7.8843e-05, PNorm = 62.9834, GNorm = 0.1789, lr_0 = 2.9654e-04
Loss = 8.6389e-05, PNorm = 62.9869, GNorm = 0.1629, lr_0 = 2.9523e-04
Validation rmse logD = 0.592580
Validation R2 logD = 0.729204
Epoch 53
Train function
Loss = 4.9503e-05, PNorm = 62.9922, GNorm = 0.1624, lr_0 = 2.9379e-04
Loss = 6.1762e-05, PNorm = 62.9957, GNorm = 0.1108, lr_0 = 2.9249e-04
Loss = 7.1956e-05, PNorm = 62.9997, GNorm = 0.1386, lr_0 = 2.9120e-04
Loss = 5.5041e-05, PNorm = 63.0032, GNorm = 0.1191, lr_0 = 2.8991e-04
Loss = 6.2726e-05, PNorm = 63.0066, GNorm = 0.2828, lr_0 = 2.8863e-04
Validation rmse logD = 0.589497
Validation R2 logD = 0.732014
Epoch 54
Train function
Loss = 5.6532e-05, PNorm = 63.0108, GNorm = 0.2914, lr_0 = 2.8722e-04
Loss = 7.2246e-05, PNorm = 63.0165, GNorm = 0.3376, lr_0 = 2.8595e-04
Loss = 6.6726e-05, PNorm = 63.0204, GNorm = 0.1415, lr_0 = 2.8469e-04
Loss = 4.6327e-05, PNorm = 63.0234, GNorm = 0.1610, lr_0 = 2.8343e-04
Loss = 4.6832e-05, PNorm = 63.0276, GNorm = 0.1672, lr_0 = 2.8218e-04
Loss = 6.1227e-05, PNorm = 63.0309, GNorm = 0.2410, lr_0 = 2.8093e-04
Loss = 7.8432e-04, PNorm = 63.0315, GNorm = 0.6833, lr_0 = 2.8080e-04
Validation rmse logD = 0.589609
Validation R2 logD = 0.731912
Epoch 55
Train function
Loss = 6.8334e-05, PNorm = 63.0372, GNorm = 0.1423, lr_0 = 2.7956e-04
Loss = 6.0646e-05, PNorm = 63.0407, GNorm = 0.1334, lr_0 = 2.7832e-04
Loss = 5.5945e-05, PNorm = 63.0448, GNorm = 0.4071, lr_0 = 2.7709e-04
Loss = 5.2226e-05, PNorm = 63.0486, GNorm = 0.3322, lr_0 = 2.7587e-04
Loss = 5.1291e-05, PNorm = 63.0519, GNorm = 0.2204, lr_0 = 2.7465e-04
Validation rmse logD = 0.592826
Validation R2 logD = 0.728979
Epoch 56
Train function
Loss = 7.2501e-05, PNorm = 63.0592, GNorm = 0.1383, lr_0 = 2.7331e-04
Loss = 5.0588e-05, PNorm = 63.0608, GNorm = 0.1976, lr_0 = 2.7210e-04
Loss = 5.5975e-05, PNorm = 63.0647, GNorm = 0.1034, lr_0 = 2.7090e-04
Loss = 6.0317e-05, PNorm = 63.0692, GNorm = 0.1679, lr_0 = 2.6970e-04
Loss = 4.4516e-05, PNorm = 63.0744, GNorm = 0.1484, lr_0 = 2.6851e-04
Validation rmse logD = 0.588669
Validation R2 logD = 0.732766
Epoch 57
Train function
Loss = 5.2559e-05, PNorm = 63.0770, GNorm = 0.1463, lr_0 = 2.6720e-04
Loss = 6.5103e-05, PNorm = 63.0791, GNorm = 0.3489, lr_0 = 2.6602e-04
Loss = 5.9497e-05, PNorm = 63.0810, GNorm = 0.1760, lr_0 = 2.6484e-04
Loss = 3.9915e-05, PNorm = 63.0854, GNorm = 0.1908, lr_0 = 2.6367e-04
Loss = 6.3568e-05, PNorm = 63.0897, GNorm = 0.3382, lr_0 = 2.6250e-04
Validation rmse logD = 0.591586
Validation R2 logD = 0.730112
Epoch 58
Train function
Loss = 5.2087e-05, PNorm = 63.0934, GNorm = 0.4445, lr_0 = 2.6123e-04
Loss = 6.4125e-05, PNorm = 63.0979, GNorm = 0.3735, lr_0 = 2.6007e-04
Loss = 4.6652e-05, PNorm = 63.1023, GNorm = 0.1193, lr_0 = 2.5892e-04
Loss = 5.2825e-05, PNorm = 63.1066, GNorm = 0.2073, lr_0 = 2.5778e-04
Loss = 6.0721e-05, PNorm = 63.1113, GNorm = 0.3127, lr_0 = 2.5664e-04
Loss = 6.4816e-05, PNorm = 63.1158, GNorm = 0.1988, lr_0 = 2.5550e-04
Validation rmse logD = 0.587525
Validation R2 logD = 0.733804
Epoch 59
Train function
Loss = 6.1358e-05, PNorm = 63.1214, GNorm = 0.2169, lr_0 = 2.5426e-04
Loss = 4.0704e-05, PNorm = 63.1238, GNorm = 0.1070, lr_0 = 2.5313e-04
Loss = 4.2439e-05, PNorm = 63.1270, GNorm = 0.1290, lr_0 = 2.5201e-04
Loss = 4.2120e-05, PNorm = 63.1316, GNorm = 0.1296, lr_0 = 2.5090e-04
Loss = 4.6123e-05, PNorm = 63.1356, GNorm = 0.2064, lr_0 = 2.4979e-04
Validation rmse logD = 0.590625
Validation R2 logD = 0.730987
Epoch 60
Train function
Loss = 4.9527e-05, PNorm = 63.1379, GNorm = 0.2342, lr_0 = 2.4868e-04
Loss = 6.4437e-05, PNorm = 63.1418, GNorm = 0.1432, lr_0 = 2.4758e-04
Loss = 4.0433e-05, PNorm = 63.1445, GNorm = 0.1212, lr_0 = 2.4649e-04
Loss = 3.8349e-05, PNorm = 63.1471, GNorm = 0.1400, lr_0 = 2.4540e-04
Loss = 4.6929e-05, PNorm = 63.1521, GNorm = 0.2746, lr_0 = 2.4431e-04
Validation rmse logD = 0.592479
Validation R2 logD = 0.729296
Epoch 61
Train function
Loss = 3.5723e-05, PNorm = 63.1551, GNorm = 0.1624, lr_0 = 2.4313e-04
Loss = 4.2834e-05, PNorm = 63.1589, GNorm = 0.2208, lr_0 = 2.4205e-04
Loss = 4.4583e-05, PNorm = 63.1616, GNorm = 0.4282, lr_0 = 2.4098e-04
Loss = 3.4596e-05, PNorm = 63.1647, GNorm = 0.1788, lr_0 = 2.3991e-04
Loss = 3.1838e-05, PNorm = 63.1664, GNorm = 0.2071, lr_0 = 2.3885e-04
Loss = 4.4631e-05, PNorm = 63.1699, GNorm = 0.1416, lr_0 = 2.3780e-04
Validation rmse logD = 0.589315
Validation R2 logD = 0.732179
Epoch 62
Train function
Loss = 3.2367e-05, PNorm = 63.1745, GNorm = 0.2547, lr_0 = 2.3664e-04
Loss = 4.1619e-05, PNorm = 63.1778, GNorm = 0.1725, lr_0 = 2.3559e-04
Loss = 3.2765e-05, PNorm = 63.1798, GNorm = 0.1099, lr_0 = 2.3455e-04
Loss = 4.6271e-05, PNorm = 63.1812, GNorm = 0.1984, lr_0 = 2.3351e-04
Loss = 2.9156e-05, PNorm = 63.1844, GNorm = 0.1559, lr_0 = 2.3248e-04
Validation rmse logD = 0.593466
Validation R2 logD = 0.728393
Epoch 63
Train function
Loss = 5.3891e-05, PNorm = 63.1878, GNorm = 0.5014, lr_0 = 2.3135e-04
Loss = 5.5693e-05, PNorm = 63.1930, GNorm = 0.5718, lr_0 = 2.3033e-04
Loss = 5.5671e-05, PNorm = 63.1952, GNorm = 0.0886, lr_0 = 2.2931e-04
Loss = 4.5930e-05, PNorm = 63.1991, GNorm = 0.1209, lr_0 = 2.2829e-04
Loss = 4.1639e-05, PNorm = 63.2031, GNorm = 0.1292, lr_0 = 2.2728e-04
Validation rmse logD = 0.589953
Validation R2 logD = 0.731599
Epoch 64
Train function
Loss = 4.1071e-05, PNorm = 63.2049, GNorm = 0.2718, lr_0 = 2.2618e-04
Loss = 3.5378e-05, PNorm = 63.2081, GNorm = 0.1702, lr_0 = 2.2518e-04
Loss = 3.7161e-05, PNorm = 63.2107, GNorm = 0.1222, lr_0 = 2.2418e-04
Loss = 4.1100e-05, PNorm = 63.2139, GNorm = 0.3249, lr_0 = 2.2319e-04
Loss = 4.1844e-05, PNorm = 63.2155, GNorm = 0.5123, lr_0 = 2.2220e-04
Loss = 4.0219e-05, PNorm = 63.2164, GNorm = 0.3791, lr_0 = 2.2122e-04
Validation rmse logD = 0.589099
Validation R2 logD = 0.732376
Epoch 65
Train function
Loss = 4.6380e-05, PNorm = 63.2197, GNorm = 0.4275, lr_0 = 2.2014e-04
Loss = 3.7773e-05, PNorm = 63.2230, GNorm = 0.1353, lr_0 = 2.1917e-04
Loss = 2.2799e-05, PNorm = 63.2255, GNorm = 0.1730, lr_0 = 2.1820e-04
Loss = 3.4881e-05, PNorm = 63.2289, GNorm = 0.1299, lr_0 = 2.1723e-04
Loss = 3.2410e-05, PNorm = 63.2303, GNorm = 0.1040, lr_0 = 2.1627e-04
Validation rmse logD = 0.590030
Validation R2 logD = 0.731529
Epoch 66
Train function
Loss = 2.6420e-05, PNorm = 63.2327, GNorm = 0.0882, lr_0 = 2.1522e-04
Loss = 2.7819e-05, PNorm = 63.2342, GNorm = 0.1171, lr_0 = 2.1427e-04
Loss = 2.5641e-05, PNorm = 63.2367, GNorm = 0.1191, lr_0 = 2.1332e-04
Loss = 2.8389e-05, PNorm = 63.2393, GNorm = 0.2022, lr_0 = 2.1238e-04
Loss = 4.0287e-05, PNorm = 63.2411, GNorm = 0.4556, lr_0 = 2.1144e-04
Validation rmse logD = 0.591709
Validation R2 logD = 0.729999
Epoch 67
Train function
Loss = 3.7111e-05, PNorm = 63.2448, GNorm = 0.1330, lr_0 = 2.1041e-04
Loss = 2.6725e-05, PNorm = 63.2465, GNorm = 0.0869, lr_0 = 2.0948e-04
Loss = 2.3332e-05, PNorm = 63.2486, GNorm = 0.1042, lr_0 = 2.0855e-04
Loss = 2.3224e-05, PNorm = 63.2514, GNorm = 0.1467, lr_0 = 2.0763e-04
Loss = 2.4414e-05, PNorm = 63.2533, GNorm = 0.1606, lr_0 = 2.0671e-04
Loss = 2.5455e-05, PNorm = 63.2560, GNorm = 0.1183, lr_0 = 2.0580e-04
Loss = 1.2171e-04, PNorm = 63.2562, GNorm = 0.3338, lr_0 = 2.0571e-04
Validation rmse logD = 0.592495
Validation R2 logD = 0.729281
Epoch 68
Train function
Loss = 2.1969e-05, PNorm = 63.2590, GNorm = 0.1576, lr_0 = 2.0480e-04
Loss = 2.4065e-05, PNorm = 63.2605, GNorm = 0.1152, lr_0 = 2.0389e-04
Loss = 2.9135e-05, PNorm = 63.2623, GNorm = 0.1459, lr_0 = 2.0299e-04
Loss = 2.7726e-05, PNorm = 63.2642, GNorm = 0.0932, lr_0 = 2.0209e-04
Loss = 3.6171e-05, PNorm = 63.2648, GNorm = 0.1693, lr_0 = 2.0120e-04
Validation rmse logD = 0.589893
Validation R2 logD = 0.731654
Epoch 69
Train function
Loss = 2.1735e-05, PNorm = 63.2672, GNorm = 0.1372, lr_0 = 2.0022e-04
Loss = 2.4128e-05, PNorm = 63.2692, GNorm = 0.1982, lr_0 = 1.9933e-04
Loss = 2.6746e-05, PNorm = 63.2705, GNorm = 0.1308, lr_0 = 1.9845e-04
Loss = 2.4937e-05, PNorm = 63.2734, GNorm = 0.2621, lr_0 = 1.9757e-04
Loss = 2.1572e-05, PNorm = 63.2765, GNorm = 0.1238, lr_0 = 1.9670e-04
Validation rmse logD = 0.591513
Validation R2 logD = 0.730178
Epoch 70
Train function
Loss = 3.8428e-05, PNorm = 63.2779, GNorm = 0.1521, lr_0 = 1.9583e-04
Loss = 3.0408e-05, PNorm = 63.2805, GNorm = 0.0983, lr_0 = 1.9496e-04
Loss = 3.2523e-05, PNorm = 63.2837, GNorm = 0.2075, lr_0 = 1.9410e-04
Loss = 2.8673e-05, PNorm = 63.2865, GNorm = 0.2559, lr_0 = 1.9324e-04
Loss = 2.6222e-05, PNorm = 63.2896, GNorm = 0.1275, lr_0 = 1.9239e-04
Loss = 2.6735e-05, PNorm = 63.2916, GNorm = 0.1695, lr_0 = 1.9154e-04
Loss = 5.7903e-05, PNorm = 63.2916, GNorm = 0.1362, lr_0 = 1.9145e-04
Validation rmse logD = 0.594597
Validation R2 logD = 0.727357
Epoch 71
Train function
Loss = 2.7241e-05, PNorm = 63.2930, GNorm = 0.0676, lr_0 = 1.9060e-04
Loss = 1.8836e-05, PNorm = 63.2945, GNorm = 0.0724, lr_0 = 1.8976e-04
Loss = 2.5249e-05, PNorm = 63.2956, GNorm = 0.0900, lr_0 = 1.8892e-04
Loss = 1.8113e-05, PNorm = 63.2978, GNorm = 0.0692, lr_0 = 1.8809e-04
Loss = 2.2187e-05, PNorm = 63.3005, GNorm = 0.1754, lr_0 = 1.8725e-04
Validation rmse logD = 0.593201
Validation R2 logD = 0.728635
Epoch 72
Train function
Loss = 1.8482e-05, PNorm = 63.3016, GNorm = 0.2139, lr_0 = 1.8634e-04
Loss = 2.0845e-05, PNorm = 63.3027, GNorm = 0.0734, lr_0 = 1.8552e-04
Loss = 2.6737e-05, PNorm = 63.3045, GNorm = 0.1257, lr_0 = 1.8470e-04
Loss = 2.3104e-05, PNorm = 63.3067, GNorm = 0.1733, lr_0 = 1.8388e-04
Loss = 1.9490e-05, PNorm = 63.3090, GNorm = 0.0823, lr_0 = 1.8307e-04
Validation rmse logD = 0.591515
Validation R2 logD = 0.730176
Epoch 73
Train function
Loss = 1.3177e-05, PNorm = 63.3110, GNorm = 0.1318, lr_0 = 1.8218e-04
Loss = 1.7133e-05, PNorm = 63.3126, GNorm = 0.1242, lr_0 = 1.8137e-04
Loss = 1.7410e-05, PNorm = 63.3139, GNorm = 0.1067, lr_0 = 1.8057e-04
Loss = 2.0957e-05, PNorm = 63.3164, GNorm = 0.1153, lr_0 = 1.7977e-04
Loss = 1.4880e-05, PNorm = 63.3190, GNorm = 0.1935, lr_0 = 1.7897e-04
Validation rmse logD = 0.592136
Validation R2 logD = 0.729609
Epoch 74
Train function
Loss = 1.7241e-05, PNorm = 63.3212, GNorm = 0.1828, lr_0 = 1.7810e-04
Loss = 1.8357e-05, PNorm = 63.3236, GNorm = 0.1272, lr_0 = 1.7732e-04
Loss = 1.7023e-05, PNorm = 63.3246, GNorm = 0.1425, lr_0 = 1.7653e-04
Loss = 1.8897e-05, PNorm = 63.3264, GNorm = 0.2429, lr_0 = 1.7575e-04
Loss = 1.5831e-05, PNorm = 63.3279, GNorm = 0.2001, lr_0 = 1.7497e-04
Loss = 1.6841e-05, PNorm = 63.3287, GNorm = 0.1218, lr_0 = 1.7420e-04
Validation rmse logD = 0.593834
Validation R2 logD = 0.728056
Epoch 75
Train function
Loss = 2.6471e-05, PNorm = 63.3314, GNorm = 0.3694, lr_0 = 1.7335e-04
Loss = 3.0289e-05, PNorm = 63.3321, GNorm = 0.3863, lr_0 = 1.7259e-04
Loss = 2.5508e-05, PNorm = 63.3351, GNorm = 0.2043, lr_0 = 1.7182e-04
Loss = 2.3857e-05, PNorm = 63.3371, GNorm = 0.3399, lr_0 = 1.7106e-04
Loss = 2.0128e-05, PNorm = 63.3387, GNorm = 0.1312, lr_0 = 1.7031e-04
Validation rmse logD = 0.592238
Validation R2 logD = 0.729516
Epoch 76
Train function
Loss = 1.8235e-05, PNorm = 63.3413, GNorm = 0.0476, lr_0 = 1.6948e-04
Loss = 1.4771e-05, PNorm = 63.3435, GNorm = 0.0657, lr_0 = 1.6873e-04
Loss = 1.2890e-05, PNorm = 63.3454, GNorm = 0.0454, lr_0 = 1.6798e-04
Loss = 1.5156e-05, PNorm = 63.3465, GNorm = 0.1303, lr_0 = 1.6724e-04
Loss = 1.7544e-05, PNorm = 63.3475, GNorm = 0.1724, lr_0 = 1.6650e-04
Validation rmse logD = 0.591637
Validation R2 logD = 0.730065
Epoch 77
Train function
Loss = 1.6969e-05, PNorm = 63.3487, GNorm = 0.2293, lr_0 = 1.6569e-04
Loss = 2.4789e-05, PNorm = 63.3503, GNorm = 0.1936, lr_0 = 1.6496e-04
Loss = 2.0572e-05, PNorm = 63.3530, GNorm = 0.1227, lr_0 = 1.6423e-04
Loss = 1.8090e-05, PNorm = 63.3542, GNorm = 0.0692, lr_0 = 1.6350e-04
Loss = 1.8177e-05, PNorm = 63.3568, GNorm = 0.0925, lr_0 = 1.6278e-04
Loss = 1.6595e-05, PNorm = 63.3584, GNorm = 0.0694, lr_0 = 1.6206e-04
Validation rmse logD = 0.589927
Validation R2 logD = 0.731623
Epoch 78
Train function
Loss = 1.8771e-05, PNorm = 63.3591, GNorm = 0.0785, lr_0 = 1.6127e-04
Loss = 1.2653e-05, PNorm = 63.3593, GNorm = 0.1694, lr_0 = 1.6055e-04
Loss = 1.5730e-05, PNorm = 63.3610, GNorm = 0.0758, lr_0 = 1.5984e-04
Loss = 1.7462e-05, PNorm = 63.3633, GNorm = 0.1948, lr_0 = 1.5914e-04
Loss = 1.8250e-05, PNorm = 63.3648, GNorm = 0.1747, lr_0 = 1.5843e-04
Validation rmse logD = 0.593774
Validation R2 logD = 0.728111
Epoch 79
Train function
Loss = 1.5120e-05, PNorm = 63.3669, GNorm = 0.1310, lr_0 = 1.5766e-04
Loss = 2.0318e-05, PNorm = 63.3679, GNorm = 0.0687, lr_0 = 1.5697e-04
Loss = 2.0789e-05, PNorm = 63.3699, GNorm = 0.0924, lr_0 = 1.5627e-04
Loss = 1.6244e-05, PNorm = 63.3715, GNorm = 0.1810, lr_0 = 1.5558e-04
Loss = 2.2944e-05, PNorm = 63.3731, GNorm = 0.2276, lr_0 = 1.5489e-04
Validation rmse logD = 0.594195
Validation R2 logD = 0.727726
Epoch 80
Train function
Loss = 1.6345e-05, PNorm = 63.3757, GNorm = 0.0738, lr_0 = 1.5421e-04
Loss = 1.4541e-05, PNorm = 63.3765, GNorm = 0.1673, lr_0 = 1.5352e-04
Loss = 1.2815e-05, PNorm = 63.3773, GNorm = 0.2111, lr_0 = 1.5284e-04
Loss = 1.6630e-05, PNorm = 63.3790, GNorm = 0.2191, lr_0 = 1.5217e-04
Loss = 2.1472e-05, PNorm = 63.3805, GNorm = 0.3332, lr_0 = 1.5150e-04
Loss = 1.9837e-05, PNorm = 63.3829, GNorm = 0.0987, lr_0 = 1.5083e-04
Validation rmse logD = 0.592014
Validation R2 logD = 0.729721
Epoch 81
Train function
Loss = 2.9838e-05, PNorm = 63.3848, GNorm = 0.3106, lr_0 = 1.5009e-04
Loss = 2.5854e-05, PNorm = 63.3852, GNorm = 0.1720, lr_0 = 1.4943e-04
Loss = 1.7633e-05, PNorm = 63.3875, GNorm = 0.1227, lr_0 = 1.4877e-04
Loss = 1.8372e-05, PNorm = 63.3891, GNorm = 0.2092, lr_0 = 1.4811e-04
Loss = 1.8279e-05, PNorm = 63.3902, GNorm = 0.1234, lr_0 = 1.4745e-04
Validation rmse logD = 0.591102
Validation R2 logD = 0.730553
Epoch 82
Train function
Loss = 1.8372e-05, PNorm = 63.3915, GNorm = 0.2960, lr_0 = 1.4674e-04
Loss = 2.5190e-05, PNorm = 63.3940, GNorm = 0.3215, lr_0 = 1.4609e-04
Loss = 2.8293e-05, PNorm = 63.3953, GNorm = 0.1615, lr_0 = 1.4544e-04
Loss = 3.1447e-05, PNorm = 63.3979, GNorm = 0.1336, lr_0 = 1.4480e-04
Loss = 1.7434e-05, PNorm = 63.3989, GNorm = 0.1024, lr_0 = 1.4416e-04
Validation rmse logD = 0.593556
Validation R2 logD = 0.728311
Epoch 83
Train function
Loss = 1.7327e-05, PNorm = 63.4014, GNorm = 0.0954, lr_0 = 1.4346e-04
Loss = 1.6185e-05, PNorm = 63.4032, GNorm = 0.2316, lr_0 = 1.4282e-04
Loss = 1.7205e-05, PNorm = 63.4044, GNorm = 0.0696, lr_0 = 1.4219e-04
Loss = 1.7660e-05, PNorm = 63.4056, GNorm = 0.1452, lr_0 = 1.4156e-04
Loss = 1.4383e-05, PNorm = 63.4063, GNorm = 0.0804, lr_0 = 1.4093e-04
Loss = 2.0042e-05, PNorm = 63.4081, GNorm = 0.0974, lr_0 = 1.4031e-04
Loss = 2.9603e-05, PNorm = 63.4083, GNorm = 0.1144, lr_0 = 1.4025e-04
Validation rmse logD = 0.594139
Validation R2 logD = 0.727777
Epoch 84
Train function
Loss = 1.2283e-05, PNorm = 63.4094, GNorm = 0.0645, lr_0 = 1.3963e-04
Loss = 1.2699e-05, PNorm = 63.4103, GNorm = 0.0845, lr_0 = 1.3901e-04
Loss = 1.2434e-05, PNorm = 63.4119, GNorm = 0.0602, lr_0 = 1.3840e-04
Loss = 1.5816e-05, PNorm = 63.4138, GNorm = 0.1056, lr_0 = 1.3778e-04
Loss = 1.4329e-05, PNorm = 63.4152, GNorm = 0.1726, lr_0 = 1.3717e-04
Validation rmse logD = 0.594554
Validation R2 logD = 0.727396
Epoch 85
Train function
Loss = 1.2304e-05, PNorm = 63.4151, GNorm = 0.1325, lr_0 = 1.3651e-04
Loss = 1.0573e-05, PNorm = 63.4160, GNorm = 0.0633, lr_0 = 1.3590e-04
Loss = 1.1348e-05, PNorm = 63.4172, GNorm = 0.0675, lr_0 = 1.3530e-04
Loss = 1.2763e-05, PNorm = 63.4181, GNorm = 0.1460, lr_0 = 1.3470e-04
Loss = 1.4817e-05, PNorm = 63.4199, GNorm = 0.1192, lr_0 = 1.3411e-04
Validation rmse logD = 0.592141
Validation R2 logD = 0.729605
Epoch 86
Train function
Loss = 9.1263e-06, PNorm = 63.4201, GNorm = 0.0803, lr_0 = 1.3346e-04
Loss = 1.1240e-05, PNorm = 63.4210, GNorm = 0.0934, lr_0 = 1.3287e-04
Loss = 1.1863e-05, PNorm = 63.4227, GNorm = 0.1136, lr_0 = 1.3228e-04
Loss = 8.0626e-06, PNorm = 63.4240, GNorm = 0.0550, lr_0 = 1.3169e-04
Loss = 9.6170e-06, PNorm = 63.4255, GNorm = 0.0934, lr_0 = 1.3111e-04
Validation rmse logD = 0.593120
Validation R2 logD = 0.728709
Epoch 87
Train function
Loss = 4.1103e-06, PNorm = 63.4267, GNorm = 0.0783, lr_0 = 1.3047e-04
Loss = 7.6656e-06, PNorm = 63.4275, GNorm = 0.1967, lr_0 = 1.2990e-04
Loss = 8.9656e-06, PNorm = 63.4289, GNorm = 0.0315, lr_0 = 1.2932e-04
Loss = 9.4003e-06, PNorm = 63.4294, GNorm = 0.0510, lr_0 = 1.2875e-04
Loss = 7.1978e-06, PNorm = 63.4305, GNorm = 0.0451, lr_0 = 1.2818e-04
Loss = 1.0976e-05, PNorm = 63.4311, GNorm = 0.0399, lr_0 = 1.2761e-04
Validation rmse logD = 0.594211
Validation R2 logD = 0.727711
Epoch 88
Train function
Loss = 1.1029e-05, PNorm = 63.4311, GNorm = 0.1709, lr_0 = 1.2699e-04
Loss = 1.4791e-05, PNorm = 63.4327, GNorm = 0.0929, lr_0 = 1.2643e-04
Loss = 1.0273e-05, PNorm = 63.4328, GNorm = 0.0653, lr_0 = 1.2587e-04
Loss = 8.3646e-06, PNorm = 63.4338, GNorm = 0.0530, lr_0 = 1.2531e-04
Loss = 1.3808e-05, PNorm = 63.4360, GNorm = 0.0795, lr_0 = 1.2476e-04
Validation rmse logD = 0.593541
Validation R2 logD = 0.728324
Epoch 89
Train function
Loss = 1.1064e-05, PNorm = 63.4365, GNorm = 0.1414, lr_0 = 1.2415e-04
Loss = 1.2943e-05, PNorm = 63.4368, GNorm = 0.1855, lr_0 = 1.2360e-04
Loss = 9.7313e-06, PNorm = 63.4383, GNorm = 0.0341, lr_0 = 1.2306e-04
Loss = 1.1648e-05, PNorm = 63.4403, GNorm = 0.1765, lr_0 = 1.2251e-04
Loss = 7.6489e-06, PNorm = 63.4411, GNorm = 0.1297, lr_0 = 1.2197e-04
Validation rmse logD = 0.593290
Validation R2 logD = 0.728554
Epoch 90
Train function
Loss = 1.7171e-05, PNorm = 63.4427, GNorm = 0.1842, lr_0 = 1.2143e-04
Loss = 1.2479e-05, PNorm = 63.4445, GNorm = 0.0513, lr_0 = 1.2089e-04
Loss = 8.7451e-06, PNorm = 63.4452, GNorm = 0.0512, lr_0 = 1.2036e-04
Loss = 1.0072e-05, PNorm = 63.4460, GNorm = 0.1372, lr_0 = 1.1983e-04
Loss = 6.8156e-06, PNorm = 63.4473, GNorm = 0.0413, lr_0 = 1.1930e-04
Loss = 1.0742e-05, PNorm = 63.4484, GNorm = 0.0636, lr_0 = 1.1877e-04
Validation rmse logD = 0.593901
Validation R2 logD = 0.727995
Epoch 91
Train function
Loss = 1.2093e-05, PNorm = 63.4487, GNorm = 0.0607, lr_0 = 1.1819e-04
Loss = 9.0495e-06, PNorm = 63.4503, GNorm = 0.0774, lr_0 = 1.1767e-04
Loss = 1.0475e-05, PNorm = 63.4510, GNorm = 0.0755, lr_0 = 1.1715e-04
Loss = 8.5381e-06, PNorm = 63.4519, GNorm = 0.1871, lr_0 = 1.1663e-04
Loss = 6.3095e-06, PNorm = 63.4525, GNorm = 0.1141, lr_0 = 1.1611e-04
Validation rmse logD = 0.593282
Validation R2 logD = 0.728562
Epoch 92
Train function
Loss = 6.5176e-06, PNorm = 63.4534, GNorm = 0.0752, lr_0 = 1.1555e-04
Loss = 1.0685e-05, PNorm = 63.4546, GNorm = 0.0727, lr_0 = 1.1504e-04
Loss = 1.1625e-05, PNorm = 63.4558, GNorm = 0.1408, lr_0 = 1.1453e-04
Loss = 1.1602e-05, PNorm = 63.4569, GNorm = 0.0839, lr_0 = 1.1402e-04
Loss = 7.3823e-06, PNorm = 63.4578, GNorm = 0.0433, lr_0 = 1.1352e-04
Validation rmse logD = 0.593286
Validation R2 logD = 0.728557
Epoch 93
Train function
Loss = 7.5965e-06, PNorm = 63.4585, GNorm = 0.0728, lr_0 = 1.1297e-04
Loss = 7.2651e-06, PNorm = 63.4595, GNorm = 0.0718, lr_0 = 1.1247e-04
Loss = 6.4894e-06, PNorm = 63.4603, GNorm = 0.0411, lr_0 = 1.1197e-04
Loss = 8.1631e-06, PNorm = 63.4609, GNorm = 0.1115, lr_0 = 1.1147e-04
Loss = 9.7704e-06, PNorm = 63.4619, GNorm = 0.1973, lr_0 = 1.1098e-04
Loss = 1.2718e-05, PNorm = 63.4626, GNorm = 0.1589, lr_0 = 1.1049e-04
Validation rmse logD = 0.595585
Validation R2 logD = 0.726450
Epoch 94
Train function
Loss = 1.1938e-05, PNorm = 63.4633, GNorm = 0.0449, lr_0 = 1.0995e-04
Loss = 1.0152e-05, PNorm = 63.4638, GNorm = 0.0798, lr_0 = 1.0947e-04
Loss = 8.5406e-06, PNorm = 63.4646, GNorm = 0.1222, lr_0 = 1.0898e-04
Loss = 1.3330e-05, PNorm = 63.4653, GNorm = 0.2384, lr_0 = 1.0850e-04
Loss = 1.4649e-05, PNorm = 63.4668, GNorm = 0.1186, lr_0 = 1.0802e-04
Validation rmse logD = 0.594036
Validation R2 logD = 0.727871
Epoch 95
Train function
Loss = 1.0051e-05, PNorm = 63.4683, GNorm = 0.0743, lr_0 = 1.0749e-04
Loss = 8.0463e-06, PNorm = 63.4687, GNorm = 0.0544, lr_0 = 1.0702e-04
Loss = 1.1597e-05, PNorm = 63.4691, GNorm = 0.0624, lr_0 = 1.0654e-04
Loss = 8.9384e-06, PNorm = 63.4705, GNorm = 0.1299, lr_0 = 1.0607e-04
Loss = 1.5094e-05, PNorm = 63.4717, GNorm = 0.1698, lr_0 = 1.0560e-04
Validation rmse logD = 0.595270
Validation R2 logD = 0.726740
Epoch 96
Train function
Loss = 1.1651e-05, PNorm = 63.4735, GNorm = 0.0603, lr_0 = 1.0509e-04
Loss = 9.8833e-06, PNorm = 63.4740, GNorm = 0.0893, lr_0 = 1.0463e-04
Loss = 7.8324e-06, PNorm = 63.4748, GNorm = 0.1707, lr_0 = 1.0416e-04
Loss = 9.9724e-06, PNorm = 63.4753, GNorm = 0.1222, lr_0 = 1.0370e-04
Loss = 9.6772e-06, PNorm = 63.4770, GNorm = 0.0950, lr_0 = 1.0324e-04
Loss = 6.5855e-06, PNorm = 63.4778, GNorm = 0.0425, lr_0 = 1.0279e-04
Loss = 4.9512e-05, PNorm = 63.4780, GNorm = 0.1791, lr_0 = 1.0274e-04
Validation rmse logD = 0.593498
Validation R2 logD = 0.728364
Epoch 97
Train function
Loss = 9.4548e-06, PNorm = 63.4785, GNorm = 0.0674, lr_0 = 1.0229e-04
Loss = 8.6020e-06, PNorm = 63.4787, GNorm = 0.1125, lr_0 = 1.0183e-04
Loss = 8.2440e-06, PNorm = 63.4798, GNorm = 0.0638, lr_0 = 1.0138e-04
Loss = 1.1855e-05, PNorm = 63.4807, GNorm = 0.1520, lr_0 = 1.0094e-04
Loss = 6.2712e-06, PNorm = 63.4814, GNorm = 0.0667, lr_0 = 1.0049e-04
Validation rmse logD = 0.595222
Validation R2 logD = 0.726783
Epoch 98
Train function
Loss = 1.3142e-05, PNorm = 63.4821, GNorm = 0.0917, lr_0 = 1.0000e-04
Loss = 6.2584e-06, PNorm = 63.4831, GNorm = 0.0541, lr_0 = 1.0000e-04
Loss = 7.8166e-06, PNorm = 63.4845, GNorm = 0.0550, lr_0 = 1.0000e-04
Loss = 8.2939e-06, PNorm = 63.4854, GNorm = 0.0766, lr_0 = 1.0000e-04
Loss = 8.7627e-06, PNorm = 63.4863, GNorm = 0.0913, lr_0 = 1.0000e-04
Validation rmse logD = 0.592842
Validation R2 logD = 0.728964
Epoch 99
Train function
Loss = 6.2863e-06, PNorm = 63.4870, GNorm = 0.1590, lr_0 = 1.0000e-04
Loss = 8.9270e-06, PNorm = 63.4874, GNorm = 0.1940, lr_0 = 1.0000e-04
Loss = 1.0722e-05, PNorm = 63.4879, GNorm = 0.1105, lr_0 = 1.0000e-04
Loss = 6.9521e-06, PNorm = 63.4885, GNorm = 0.0587, lr_0 = 1.0000e-04
Loss = 6.4604e-06, PNorm = 63.4893, GNorm = 0.0436, lr_0 = 1.0000e-04
Loss = 1.0356e-05, PNorm = 63.4899, GNorm = 0.2836, lr_0 = 1.0000e-04
Validation rmse logD = 0.594170
Validation R2 logD = 0.727748
Model 0 best validation rmse = 0.585157 on epoch 32
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.594081
Model 0 test R2 logD = 0.755905
Ensemble test rmse  logD= 0.594081
Ensemble test R2  logD= 0.755905
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_314/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 1.8863e-02, PNorm = 52.9144, GNorm = 6.6309, lr_0 = 1.9340e-04
Loss = 1.8042e-02, PNorm = 52.9225, GNorm = 2.3173, lr_0 = 2.7830e-04
Loss = 1.6996e-02, PNorm = 52.9349, GNorm = 4.8471, lr_0 = 3.6321e-04
Loss = 1.5120e-02, PNorm = 52.9527, GNorm = 9.8427, lr_0 = 4.4811e-04
Loss = 1.2996e-02, PNorm = 52.9746, GNorm = 2.5175, lr_0 = 5.3302e-04
Validation rmse logD = 0.968081
Validation R2 logD = 0.381584
Epoch 1
Train function
Loss = 1.4255e-02, PNorm = 53.0108, GNorm = 2.6632, lr_0 = 6.2642e-04
Loss = 1.2636e-02, PNorm = 53.0496, GNorm = 5.6180, lr_0 = 7.1132e-04
Loss = 1.0883e-02, PNorm = 53.0835, GNorm = 3.3278, lr_0 = 7.9623e-04
Loss = 1.1789e-02, PNorm = 53.1240, GNorm = 9.6281, lr_0 = 8.8113e-04
Loss = 1.4655e-02, PNorm = 53.1750, GNorm = 2.1251, lr_0 = 9.6604e-04
Validation rmse logD = 1.000590
Validation R2 logD = 0.339353
Epoch 2
Train function
Loss = 1.2403e-02, PNorm = 53.2472, GNorm = 3.8295, lr_0 = 9.9690e-04
Loss = 1.0156e-02, PNorm = 53.3162, GNorm = 1.3304, lr_0 = 9.9249e-04
Loss = 1.0097e-02, PNorm = 53.3699, GNorm = 1.8076, lr_0 = 9.8810e-04
Loss = 9.7522e-03, PNorm = 53.4156, GNorm = 0.8924, lr_0 = 9.8373e-04
Loss = 1.0976e-02, PNorm = 53.4697, GNorm = 6.7155, lr_0 = 9.7938e-04
Validation rmse logD = 0.835006
Validation R2 logD = 0.539917
Epoch 3
Train function
Loss = 7.8093e-03, PNorm = 53.5418, GNorm = 1.5214, lr_0 = 9.7462e-04
Loss = 9.5298e-03, PNorm = 53.6048, GNorm = 3.9252, lr_0 = 9.7030e-04
Loss = 9.5702e-03, PNorm = 53.6764, GNorm = 5.9317, lr_0 = 9.6601e-04
Loss = 7.9939e-03, PNorm = 53.7569, GNorm = 1.1951, lr_0 = 9.6174e-04
Loss = 9.3822e-03, PNorm = 53.8494, GNorm = 2.7230, lr_0 = 9.5749e-04
Loss = 9.9313e-03, PNorm = 53.9627, GNorm = 1.5228, lr_0 = 9.5325e-04
Validation rmse logD = 0.892318
Validation R2 logD = 0.474592
Epoch 4
Train function
Loss = 9.2677e-03, PNorm = 54.0570, GNorm = 2.3340, lr_0 = 9.4861e-04
Loss = 7.8539e-03, PNorm = 54.1121, GNorm = 5.1044, lr_0 = 9.4442e-04
Loss = 7.8987e-03, PNorm = 54.1717, GNorm = 0.9825, lr_0 = 9.4024e-04
Loss = 7.6913e-03, PNorm = 54.2293, GNorm = 3.1733, lr_0 = 9.3608e-04
Loss = 7.3437e-03, PNorm = 54.2919, GNorm = 1.2827, lr_0 = 9.3194e-04
Validation rmse logD = 0.795143
Validation R2 logD = 0.582797
Epoch 5
Train function
Loss = 7.4676e-03, PNorm = 54.3540, GNorm = 2.5401, lr_0 = 9.2741e-04
Loss = 6.1134e-03, PNorm = 54.4074, GNorm = 0.7979, lr_0 = 9.2330e-04
Loss = 7.3512e-03, PNorm = 54.4629, GNorm = 1.5394, lr_0 = 9.1922e-04
Loss = 5.5612e-03, PNorm = 54.5220, GNorm = 1.5423, lr_0 = 9.1515e-04
Loss = 7.0550e-03, PNorm = 54.5878, GNorm = 2.8223, lr_0 = 9.1111e-04
Validation rmse logD = 0.784874
Validation R2 logD = 0.593503
Epoch 6
Train function
Loss = 6.3797e-03, PNorm = 54.6552, GNorm = 2.9527, lr_0 = 9.0667e-04
Loss = 6.5676e-03, PNorm = 54.7092, GNorm = 2.8671, lr_0 = 9.0266e-04
Loss = 6.4940e-03, PNorm = 54.7840, GNorm = 2.4296, lr_0 = 8.9867e-04
Loss = 4.9181e-03, PNorm = 54.8549, GNorm = 0.8492, lr_0 = 8.9469e-04
Loss = 5.6127e-03, PNorm = 54.9193, GNorm = 1.7034, lr_0 = 8.9074e-04
Loss = 7.0722e-03, PNorm = 54.9630, GNorm = 1.6249, lr_0 = 8.8680e-04
Validation rmse logD = 0.709709
Validation R2 logD = 0.667633
Epoch 7
Train function
Loss = 5.6969e-03, PNorm = 55.0345, GNorm = 1.4968, lr_0 = 8.8248e-04
Loss = 5.3781e-03, PNorm = 55.1165, GNorm = 1.8501, lr_0 = 8.7858e-04
Loss = 6.0723e-03, PNorm = 55.1759, GNorm = 3.3763, lr_0 = 8.7469e-04
Loss = 5.1064e-03, PNorm = 55.2341, GNorm = 1.0526, lr_0 = 8.7082e-04
Loss = 5.7287e-03, PNorm = 55.2963, GNorm = 3.0912, lr_0 = 8.6697e-04
Validation rmse logD = 0.718043
Validation R2 logD = 0.659782
Epoch 8
Train function
Loss = 5.3239e-03, PNorm = 55.3630, GNorm = 2.0132, lr_0 = 8.6276e-04
Loss = 5.0815e-03, PNorm = 55.4325, GNorm = 3.8627, lr_0 = 8.5894e-04
Loss = 4.3806e-03, PNorm = 55.4975, GNorm = 1.6609, lr_0 = 8.5514e-04
Loss = 4.6387e-03, PNorm = 55.5714, GNorm = 2.7956, lr_0 = 8.5136e-04
Loss = 5.5798e-03, PNorm = 55.6361, GNorm = 1.0893, lr_0 = 8.4759e-04
Validation rmse logD = 0.767391
Validation R2 logD = 0.611411
Epoch 9
Train function
Loss = 4.4584e-03, PNorm = 55.7072, GNorm = 2.1860, lr_0 = 8.4384e-04
Loss = 4.0483e-03, PNorm = 55.7696, GNorm = 1.4264, lr_0 = 8.4011e-04
Loss = 3.9001e-03, PNorm = 55.8520, GNorm = 1.0663, lr_0 = 8.3639e-04
Loss = 4.0162e-03, PNorm = 55.9429, GNorm = 0.6717, lr_0 = 8.3269e-04
Loss = 4.5971e-03, PNorm = 56.0045, GNorm = 0.9812, lr_0 = 8.2901e-04
Loss = 4.5285e-03, PNorm = 56.0621, GNorm = 1.2771, lr_0 = 8.2534e-04
Validation rmse logD = 0.682752
Validation R2 logD = 0.692402
Epoch 10
Train function
Loss = 4.3791e-03, PNorm = 56.1528, GNorm = 2.3141, lr_0 = 8.2133e-04
Loss = 4.0260e-03, PNorm = 56.2389, GNorm = 2.0956, lr_0 = 8.1770e-04
Loss = 4.3457e-03, PNorm = 56.3107, GNorm = 2.7391, lr_0 = 8.1408e-04
Loss = 3.0291e-03, PNorm = 56.3653, GNorm = 0.7531, lr_0 = 8.1048e-04
Loss = 3.8376e-03, PNorm = 56.4219, GNorm = 0.8644, lr_0 = 8.0689e-04
Validation rmse logD = 0.643523
Validation R2 logD = 0.726734
Epoch 11
Train function
Loss = 4.0296e-03, PNorm = 56.5289, GNorm = 1.7623, lr_0 = 8.0297e-04
Loss = 3.4855e-03, PNorm = 56.6251, GNorm = 1.2336, lr_0 = 7.9942e-04
Loss = 3.4824e-03, PNorm = 56.7008, GNorm = 0.6752, lr_0 = 7.9588e-04
Loss = 4.3300e-03, PNorm = 56.7808, GNorm = 1.0380, lr_0 = 7.9236e-04
Loss = 3.4583e-03, PNorm = 56.8534, GNorm = 0.8193, lr_0 = 7.8885e-04
Validation rmse logD = 0.649713
Validation R2 logD = 0.721452
Epoch 12
Train function
Loss = 2.6452e-03, PNorm = 56.9332, GNorm = 1.6666, lr_0 = 7.8502e-04
Loss = 3.2398e-03, PNorm = 56.9991, GNorm = 0.8156, lr_0 = 7.8154e-04
Loss = 2.5576e-03, PNorm = 57.0477, GNorm = 2.0483, lr_0 = 7.7809e-04
Loss = 3.2086e-03, PNorm = 57.1082, GNorm = 0.9104, lr_0 = 7.7465e-04
Loss = 3.0629e-03, PNorm = 57.1782, GNorm = 1.0081, lr_0 = 7.7122e-04
Loss = 3.0023e-03, PNorm = 57.2338, GNorm = 1.5122, lr_0 = 7.6781e-04
Loss = 1.2034e-02, PNorm = 57.2391, GNorm = 2.1571, lr_0 = 7.6747e-04
Validation rmse logD = 0.641540
Validation R2 logD = 0.728416
Epoch 13
Train function
Loss = 2.9460e-03, PNorm = 57.2987, GNorm = 0.5371, lr_0 = 7.6407e-04
Loss = 2.5063e-03, PNorm = 57.3712, GNorm = 1.2091, lr_0 = 7.6069e-04
Loss = 2.6366e-03, PNorm = 57.4342, GNorm = 1.1509, lr_0 = 7.5733e-04
Loss = 2.8940e-03, PNorm = 57.4920, GNorm = 1.1254, lr_0 = 7.5398e-04
Loss = 2.6326e-03, PNorm = 57.5557, GNorm = 1.8022, lr_0 = 7.5064e-04
Validation rmse logD = 0.612804
Validation R2 logD = 0.752201
Epoch 14
Train function
Loss = 3.3500e-03, PNorm = 57.6238, GNorm = 2.2856, lr_0 = 7.4699e-04
Loss = 2.8060e-03, PNorm = 57.7038, GNorm = 1.3750, lr_0 = 7.4369e-04
Loss = 2.6155e-03, PNorm = 57.7744, GNorm = 3.0211, lr_0 = 7.4040e-04
Loss = 2.6841e-03, PNorm = 57.8327, GNorm = 1.0515, lr_0 = 7.3712e-04
Loss = 2.5500e-03, PNorm = 57.8909, GNorm = 0.8772, lr_0 = 7.3386e-04
Validation rmse logD = 0.611253
Validation R2 logD = 0.753453
Epoch 15
Train function
Loss = 1.9859e-03, PNorm = 57.9506, GNorm = 1.7028, lr_0 = 7.3029e-04
Loss = 2.1339e-03, PNorm = 58.0041, GNorm = 0.9114, lr_0 = 7.2706e-04
Loss = 1.9129e-03, PNorm = 58.0558, GNorm = 0.7819, lr_0 = 7.2385e-04
Loss = 2.0047e-03, PNorm = 58.1091, GNorm = 1.2837, lr_0 = 7.2064e-04
Loss = 2.2205e-03, PNorm = 58.1598, GNorm = 0.5945, lr_0 = 7.1746e-04
Validation rmse logD = 0.602287
Validation R2 logD = 0.760633
Epoch 16
Train function
Loss = 1.4584e-03, PNorm = 58.2210, GNorm = 0.9760, lr_0 = 7.1397e-04
Loss = 2.2146e-03, PNorm = 58.2711, GNorm = 1.5854, lr_0 = 7.1081e-04
Loss = 1.9311e-03, PNorm = 58.3129, GNorm = 1.0687, lr_0 = 7.0766e-04
Loss = 2.1881e-03, PNorm = 58.3619, GNorm = 1.4630, lr_0 = 7.0453e-04
Loss = 2.1969e-03, PNorm = 58.4063, GNorm = 1.1820, lr_0 = 7.0142e-04
Loss = 2.1792e-03, PNorm = 58.4586, GNorm = 0.7257, lr_0 = 6.9831e-04
Validation rmse logD = 0.602566
Validation R2 logD = 0.760411
Epoch 17
Train function
Loss = 1.6575e-03, PNorm = 58.5228, GNorm = 0.6900, lr_0 = 6.9523e-04
Loss = 1.5631e-03, PNorm = 58.5716, GNorm = 1.3162, lr_0 = 6.9215e-04
Loss = 1.6755e-03, PNorm = 58.6110, GNorm = 0.8426, lr_0 = 6.8909e-04
Loss = 1.7741e-03, PNorm = 58.6761, GNorm = 0.7482, lr_0 = 6.8604e-04
Loss = 2.2228e-03, PNorm = 58.7169, GNorm = 0.7201, lr_0 = 6.8301e-04
Validation rmse logD = 0.598574
Validation R2 logD = 0.763575
Epoch 18
Train function
Loss = 1.3462e-03, PNorm = 58.7736, GNorm = 0.6624, lr_0 = 6.7968e-04
Loss = 1.2825e-03, PNorm = 58.8246, GNorm = 0.8277, lr_0 = 6.7668e-04
Loss = 1.4128e-03, PNorm = 58.8598, GNorm = 0.6834, lr_0 = 6.7368e-04
Loss = 1.5990e-03, PNorm = 58.9060, GNorm = 0.5683, lr_0 = 6.7070e-04
Loss = 1.5356e-03, PNorm = 58.9521, GNorm = 0.7818, lr_0 = 6.6774e-04
Validation rmse logD = 0.597153
Validation R2 logD = 0.764697
Epoch 19
Train function
Loss = 9.1530e-04, PNorm = 59.0052, GNorm = 0.6892, lr_0 = 6.6449e-04
Loss = 1.3127e-03, PNorm = 59.0473, GNorm = 1.7106, lr_0 = 6.6155e-04
Loss = 1.3416e-03, PNorm = 59.0930, GNorm = 0.6129, lr_0 = 6.5862e-04
Loss = 1.3697e-03, PNorm = 59.1395, GNorm = 0.7516, lr_0 = 6.5571e-04
Loss = 1.7038e-03, PNorm = 59.1758, GNorm = 0.6791, lr_0 = 6.5281e-04
Loss = 1.7790e-03, PNorm = 59.2124, GNorm = 1.8173, lr_0 = 6.4992e-04
Validation rmse logD = 0.631414
Validation R2 logD = 0.736921
Epoch 20
Train function
Loss = 1.3048e-03, PNorm = 59.2592, GNorm = 1.7130, lr_0 = 6.4676e-04
Loss = 1.2280e-03, PNorm = 59.2943, GNorm = 0.6593, lr_0 = 6.4390e-04
Loss = 1.0826e-03, PNorm = 59.3282, GNorm = 0.6186, lr_0 = 6.4105e-04
Loss = 1.0923e-03, PNorm = 59.3634, GNorm = 0.5197, lr_0 = 6.3822e-04
Loss = 1.2605e-03, PNorm = 59.4037, GNorm = 0.7627, lr_0 = 6.3539e-04
Validation rmse logD = 0.602643
Validation R2 logD = 0.760350
Epoch 21
Train function
Loss = 9.7204e-04, PNorm = 59.4434, GNorm = 0.5419, lr_0 = 6.3230e-04
Loss = 1.1160e-03, PNorm = 59.4780, GNorm = 0.5047, lr_0 = 6.2950e-04
Loss = 1.1408e-03, PNorm = 59.5200, GNorm = 0.6051, lr_0 = 6.2672e-04
Loss = 1.0850e-03, PNorm = 59.5599, GNorm = 0.6283, lr_0 = 6.2395e-04
Loss = 1.0867e-03, PNorm = 59.5970, GNorm = 0.5622, lr_0 = 6.2119e-04
Validation rmse logD = 0.608330
Validation R2 logD = 0.755806
Epoch 22
Train function
Loss = 1.2253e-03, PNorm = 59.6324, GNorm = 1.4207, lr_0 = 6.1817e-04
Loss = 9.8162e-04, PNorm = 59.6750, GNorm = 1.5147, lr_0 = 6.1543e-04
Loss = 8.8640e-04, PNorm = 59.7131, GNorm = 0.7212, lr_0 = 6.1271e-04
Loss = 9.4414e-04, PNorm = 59.7446, GNorm = 0.6481, lr_0 = 6.1000e-04
Loss = 1.0242e-03, PNorm = 59.7716, GNorm = 1.2525, lr_0 = 6.0730e-04
Loss = 1.1663e-03, PNorm = 59.8080, GNorm = 1.4111, lr_0 = 6.0461e-04
Validation rmse logD = 0.599863
Validation R2 logD = 0.762556
Epoch 23
Train function
Loss = 9.3728e-04, PNorm = 59.8459, GNorm = 0.7040, lr_0 = 6.0167e-04
Loss = 1.0604e-03, PNorm = 59.8803, GNorm = 0.4741, lr_0 = 5.9901e-04
Loss = 1.0508e-03, PNorm = 59.9159, GNorm = 0.5126, lr_0 = 5.9636e-04
Loss = 8.6623e-04, PNorm = 59.9452, GNorm = 0.7146, lr_0 = 5.9372e-04
Loss = 9.3247e-04, PNorm = 59.9697, GNorm = 1.0131, lr_0 = 5.9110e-04
Validation rmse logD = 0.584746
Validation R2 logD = 0.774373
Epoch 24
Train function
Loss = 7.6554e-04, PNorm = 60.0006, GNorm = 0.4472, lr_0 = 5.8822e-04
Loss = 7.3377e-04, PNorm = 60.0285, GNorm = 0.7973, lr_0 = 5.8562e-04
Loss = 7.2604e-04, PNorm = 60.0542, GNorm = 0.4934, lr_0 = 5.8303e-04
Loss = 8.3627e-04, PNorm = 60.0848, GNorm = 1.4624, lr_0 = 5.8045e-04
Loss = 8.0015e-04, PNorm = 60.1197, GNorm = 0.5197, lr_0 = 5.7788e-04
Validation rmse logD = 0.610577
Validation R2 logD = 0.753998
Epoch 25
Train function
Loss = 1.2463e-03, PNorm = 60.1554, GNorm = 2.5422, lr_0 = 5.7533e-04
Loss = 7.6254e-04, PNorm = 60.1873, GNorm = 1.3987, lr_0 = 5.7278e-04
Loss = 8.8362e-04, PNorm = 60.2167, GNorm = 1.8608, lr_0 = 5.7025e-04
Loss = 7.8187e-04, PNorm = 60.2425, GNorm = 0.6718, lr_0 = 5.6773e-04
Loss = 7.1751e-04, PNorm = 60.2729, GNorm = 0.3743, lr_0 = 5.6522e-04
Loss = 7.6243e-04, PNorm = 60.2850, GNorm = 0.4247, lr_0 = 5.6272e-04
Validation rmse logD = 0.590339
Validation R2 logD = 0.770036
Epoch 26
Train function
Loss = 7.4641e-04, PNorm = 60.3092, GNorm = 1.1001, lr_0 = 5.5998e-04
Loss = 7.5266e-04, PNorm = 60.3401, GNorm = 0.4449, lr_0 = 5.5750e-04
Loss = 7.4705e-04, PNorm = 60.3689, GNorm = 0.8296, lr_0 = 5.5503e-04
Loss = 5.8019e-04, PNorm = 60.3939, GNorm = 1.0455, lr_0 = 5.5258e-04
Loss = 7.4369e-04, PNorm = 60.4226, GNorm = 0.4620, lr_0 = 5.5014e-04
Validation rmse logD = 0.594705
Validation R2 logD = 0.766622
Epoch 27
Train function
Loss = 5.7616e-04, PNorm = 60.4488, GNorm = 0.8271, lr_0 = 5.4746e-04
Loss = 5.7282e-04, PNorm = 60.4721, GNorm = 0.3358, lr_0 = 5.4504e-04
Loss = 5.3402e-04, PNorm = 60.4864, GNorm = 0.4030, lr_0 = 5.4263e-04
Loss = 5.3737e-04, PNorm = 60.5058, GNorm = 0.4486, lr_0 = 5.4023e-04
Loss = 6.8705e-04, PNorm = 60.5241, GNorm = 1.1376, lr_0 = 5.3784e-04
Validation rmse logD = 0.594769
Validation R2 logD = 0.766571
Epoch 28
Train function
Loss = 5.7378e-04, PNorm = 60.5507, GNorm = 0.4094, lr_0 = 5.3522e-04
Loss = 5.4472e-04, PNorm = 60.5788, GNorm = 0.7593, lr_0 = 5.3285e-04
Loss = 4.4929e-04, PNorm = 60.5986, GNorm = 0.3687, lr_0 = 5.3050e-04
Loss = 4.7093e-04, PNorm = 60.6180, GNorm = 0.5283, lr_0 = 5.2815e-04
Loss = 5.1516e-04, PNorm = 60.6373, GNorm = 0.6492, lr_0 = 5.2581e-04
Loss = 5.3989e-04, PNorm = 60.6512, GNorm = 0.5824, lr_0 = 5.2349e-04
Loss = 1.5107e-03, PNorm = 60.6527, GNorm = 0.7029, lr_0 = 5.2326e-04
Validation rmse logD = 0.597905
Validation R2 logD = 0.764103
Epoch 29
Train function
Loss = 4.2802e-04, PNorm = 60.6702, GNorm = 1.1690, lr_0 = 5.2094e-04
Loss = 5.0447e-04, PNorm = 60.6864, GNorm = 0.4255, lr_0 = 5.1864e-04
Loss = 4.9652e-04, PNorm = 60.7046, GNorm = 0.4720, lr_0 = 5.1634e-04
Loss = 4.1788e-04, PNorm = 60.7288, GNorm = 0.3202, lr_0 = 5.1406e-04
Loss = 5.6437e-04, PNorm = 60.7472, GNorm = 0.6785, lr_0 = 5.1178e-04
Validation rmse logD = 0.596009
Validation R2 logD = 0.765597
Epoch 30
Train function
Loss = 3.7145e-04, PNorm = 60.7657, GNorm = 0.8826, lr_0 = 5.0930e-04
Loss = 5.7878e-04, PNorm = 60.7830, GNorm = 0.7942, lr_0 = 5.0704e-04
Loss = 6.2582e-04, PNorm = 60.8139, GNorm = 0.7735, lr_0 = 5.0480e-04
Loss = 4.7697e-04, PNorm = 60.8396, GNorm = 0.5741, lr_0 = 5.0257e-04
Loss = 5.1824e-04, PNorm = 60.8630, GNorm = 0.7191, lr_0 = 5.0034e-04
Validation rmse logD = 0.615201
Validation R2 logD = 0.750258
Epoch 31
Train function
Loss = 5.6792e-04, PNorm = 60.8865, GNorm = 0.9558, lr_0 = 4.9791e-04
Loss = 5.6280e-04, PNorm = 60.9119, GNorm = 1.1853, lr_0 = 4.9571e-04
Loss = 5.8567e-04, PNorm = 60.9364, GNorm = 0.5536, lr_0 = 4.9351e-04
Loss = 5.0374e-04, PNorm = 60.9599, GNorm = 0.7662, lr_0 = 4.9133e-04
Loss = 5.3597e-04, PNorm = 60.9795, GNorm = 0.4295, lr_0 = 4.8916e-04
Validation rmse logD = 0.595201
Validation R2 logD = 0.766232
Epoch 32
Train function
Loss = 4.9308e-04, PNorm = 61.0086, GNorm = 0.8850, lr_0 = 4.8678e-04
Loss = 5.5993e-04, PNorm = 61.0424, GNorm = 0.5095, lr_0 = 4.8463e-04
Loss = 4.8279e-04, PNorm = 61.0597, GNorm = 0.4562, lr_0 = 4.8248e-04
Loss = 5.0873e-04, PNorm = 61.0738, GNorm = 1.4565, lr_0 = 4.8035e-04
Loss = 6.1750e-04, PNorm = 61.0887, GNorm = 0.9026, lr_0 = 4.7822e-04
Loss = 4.8157e-04, PNorm = 61.1111, GNorm = 0.6554, lr_0 = 4.7611e-04
Validation rmse logD = 0.595956
Validation R2 logD = 0.765639
Epoch 33
Train function
Loss = 4.9304e-04, PNorm = 61.1303, GNorm = 0.8613, lr_0 = 4.7379e-04
Loss = 4.5422e-04, PNorm = 61.1421, GNorm = 0.3545, lr_0 = 4.7170e-04
Loss = 3.6247e-04, PNorm = 61.1563, GNorm = 0.5020, lr_0 = 4.6961e-04
Loss = 4.4151e-04, PNorm = 61.1745, GNorm = 0.9203, lr_0 = 4.6753e-04
Loss = 3.2682e-04, PNorm = 61.1907, GNorm = 0.6381, lr_0 = 4.6546e-04
Validation rmse logD = 0.584824
Validation R2 logD = 0.774312
Epoch 34
Train function
Loss = 4.2389e-04, PNorm = 61.2106, GNorm = 1.1384, lr_0 = 4.6341e-04
Loss = 4.1762e-04, PNorm = 61.2243, GNorm = 0.5003, lr_0 = 4.6136e-04
Loss = 3.4162e-04, PNorm = 61.2435, GNorm = 0.3865, lr_0 = 4.5931e-04
Loss = 2.8825e-04, PNorm = 61.2634, GNorm = 0.2807, lr_0 = 4.5728e-04
Loss = 3.3529e-04, PNorm = 61.2788, GNorm = 0.5452, lr_0 = 4.5526e-04
Validation rmse logD = 0.593723
Validation R2 logD = 0.767392
Epoch 35
Train function
Loss = 1.9604e-04, PNorm = 61.2907, GNorm = 0.5196, lr_0 = 4.5305e-04
Loss = 3.5500e-04, PNorm = 61.3030, GNorm = 0.7212, lr_0 = 4.5104e-04
Loss = 2.9914e-04, PNorm = 61.3180, GNorm = 0.4023, lr_0 = 4.4905e-04
Loss = 2.8349e-04, PNorm = 61.3336, GNorm = 0.5001, lr_0 = 4.4706e-04
Loss = 2.8109e-04, PNorm = 61.3476, GNorm = 0.5629, lr_0 = 4.4508e-04
Loss = 2.8539e-04, PNorm = 61.3597, GNorm = 0.5810, lr_0 = 4.4311e-04
Validation rmse logD = 0.584360
Validation R2 logD = 0.774670
Epoch 36
Train function
Loss = 2.3782e-04, PNorm = 61.3708, GNorm = 0.2558, lr_0 = 4.4096e-04
Loss = 2.3391e-04, PNorm = 61.3834, GNorm = 0.3841, lr_0 = 4.3901e-04
Loss = 2.9234e-04, PNorm = 61.3998, GNorm = 0.6345, lr_0 = 4.3707e-04
Loss = 2.2742e-04, PNorm = 61.4109, GNorm = 0.8225, lr_0 = 4.3513e-04
Loss = 2.5624e-04, PNorm = 61.4203, GNorm = 0.5667, lr_0 = 4.3321e-04
Validation rmse logD = 0.590712
Validation R2 logD = 0.769745
Epoch 37
Train function
Loss = 2.6384e-04, PNorm = 61.4317, GNorm = 0.5656, lr_0 = 4.3110e-04
Loss = 2.2007e-04, PNorm = 61.4478, GNorm = 0.3245, lr_0 = 4.2919e-04
Loss = 2.5291e-04, PNorm = 61.4627, GNorm = 0.4083, lr_0 = 4.2729e-04
Loss = 2.2118e-04, PNorm = 61.4721, GNorm = 0.4091, lr_0 = 4.2540e-04
Loss = 2.5913e-04, PNorm = 61.4821, GNorm = 0.7803, lr_0 = 4.2352e-04
Validation rmse logD = 0.589889
Validation R2 logD = 0.770386
Epoch 38
Train function
Loss = 2.4775e-04, PNorm = 61.4891, GNorm = 0.4349, lr_0 = 4.2146e-04
Loss = 2.9324e-04, PNorm = 61.5030, GNorm = 0.8769, lr_0 = 4.1960e-04
Loss = 2.8330e-04, PNorm = 61.5208, GNorm = 0.2733, lr_0 = 4.1774e-04
Loss = 2.0101e-04, PNorm = 61.5348, GNorm = 0.6491, lr_0 = 4.1589e-04
Loss = 2.4847e-04, PNorm = 61.5464, GNorm = 0.2637, lr_0 = 4.1406e-04
Loss = 2.5679e-04, PNorm = 61.5562, GNorm = 0.3249, lr_0 = 4.1222e-04
Validation rmse logD = 0.598396
Validation R2 logD = 0.763716
Epoch 39
Train function
Loss = 3.4341e-04, PNorm = 61.5690, GNorm = 1.0107, lr_0 = 4.1022e-04
Loss = 2.7071e-04, PNorm = 61.5844, GNorm = 0.7235, lr_0 = 4.0840e-04
Loss = 2.5790e-04, PNorm = 61.5963, GNorm = 0.5716, lr_0 = 4.0660e-04
Loss = 2.2052e-04, PNorm = 61.6070, GNorm = 0.2457, lr_0 = 4.0480e-04
Loss = 2.1439e-04, PNorm = 61.6168, GNorm = 0.3703, lr_0 = 4.0301e-04
Validation rmse logD = 0.598819
Validation R2 logD = 0.763382
Epoch 40
Train function
Loss = 2.7813e-04, PNorm = 61.6287, GNorm = 0.4527, lr_0 = 4.0105e-04
Loss = 3.0089e-04, PNorm = 61.6437, GNorm = 0.4037, lr_0 = 3.9927e-04
Loss = 2.0066e-04, PNorm = 61.6575, GNorm = 0.2519, lr_0 = 3.9751e-04
Loss = 2.3291e-04, PNorm = 61.6670, GNorm = 0.4734, lr_0 = 3.9575e-04
Loss = 2.0574e-04, PNorm = 61.6795, GNorm = 0.4765, lr_0 = 3.9400e-04
Validation rmse logD = 0.589952
Validation R2 logD = 0.770337
Epoch 41
Train function
Loss = 1.6579e-04, PNorm = 61.6926, GNorm = 0.5118, lr_0 = 3.9208e-04
Loss = 1.8665e-04, PNorm = 61.7033, GNorm = 0.6935, lr_0 = 3.9035e-04
Loss = 2.1273e-04, PNorm = 61.7181, GNorm = 0.5530, lr_0 = 3.8862e-04
Loss = 2.0357e-04, PNorm = 61.7311, GNorm = 0.3655, lr_0 = 3.8690e-04
Loss = 2.1354e-04, PNorm = 61.7440, GNorm = 0.3983, lr_0 = 3.8519e-04
Loss = 1.6786e-04, PNorm = 61.7524, GNorm = 0.2195, lr_0 = 3.8349e-04
Validation rmse logD = 0.590367
Validation R2 logD = 0.770014
Epoch 42
Train function
Loss = 1.8224e-04, PNorm = 61.7571, GNorm = 0.5662, lr_0 = 3.8179e-04
Loss = 1.5935e-04, PNorm = 61.7680, GNorm = 0.3337, lr_0 = 3.8010e-04
Loss = 1.6663e-04, PNorm = 61.7732, GNorm = 0.3214, lr_0 = 3.7842e-04
Loss = 1.7728e-04, PNorm = 61.7770, GNorm = 0.4606, lr_0 = 3.7675e-04
Loss = 1.7295e-04, PNorm = 61.7884, GNorm = 0.3459, lr_0 = 3.7508e-04
Validation rmse logD = 0.594530
Validation R2 logD = 0.766759
Epoch 43
Train function
Loss = 1.5994e-04, PNorm = 61.7988, GNorm = 0.2034, lr_0 = 3.7326e-04
Loss = 1.4272e-04, PNorm = 61.8094, GNorm = 0.1907, lr_0 = 3.7160e-04
Loss = 1.3684e-04, PNorm = 61.8208, GNorm = 0.4137, lr_0 = 3.6996e-04
Loss = 1.2726e-04, PNorm = 61.8274, GNorm = 0.2177, lr_0 = 3.6832e-04
Loss = 1.7290e-04, PNorm = 61.8352, GNorm = 0.2909, lr_0 = 3.6669e-04
Validation rmse logD = 0.598146
Validation R2 logD = 0.763913
Epoch 44
Train function
Loss = 1.2543e-04, PNorm = 61.8424, GNorm = 0.3836, lr_0 = 3.6491e-04
Loss = 1.4916e-04, PNorm = 61.8492, GNorm = 0.2111, lr_0 = 3.6330e-04
Loss = 1.4675e-04, PNorm = 61.8575, GNorm = 0.3190, lr_0 = 3.6169e-04
Loss = 1.3643e-04, PNorm = 61.8655, GNorm = 0.3284, lr_0 = 3.6009e-04
Loss = 1.4514e-04, PNorm = 61.8749, GNorm = 0.2471, lr_0 = 3.5850e-04
Loss = 1.4064e-04, PNorm = 61.8826, GNorm = 0.3286, lr_0 = 3.5691e-04
Loss = 2.7124e-04, PNorm = 61.8833, GNorm = 0.3318, lr_0 = 3.5675e-04
Validation rmse logD = 0.592714
Validation R2 logD = 0.768182
Epoch 45
Train function
Loss = 1.0784e-04, PNorm = 61.8901, GNorm = 0.2297, lr_0 = 3.5518e-04
Loss = 1.1563e-04, PNorm = 61.8981, GNorm = 0.2207, lr_0 = 3.5360e-04
Loss = 1.3088e-04, PNorm = 61.9048, GNorm = 0.3044, lr_0 = 3.5204e-04
Loss = 1.4947e-04, PNorm = 61.9158, GNorm = 0.6844, lr_0 = 3.5048e-04
Loss = 1.4287e-04, PNorm = 61.9235, GNorm = 0.4604, lr_0 = 3.4893e-04
Validation rmse logD = 0.596758
Validation R2 logD = 0.765008
Epoch 46
Train function
Loss = 1.2306e-04, PNorm = 61.9310, GNorm = 0.3784, lr_0 = 3.4724e-04
Loss = 1.2750e-04, PNorm = 61.9415, GNorm = 0.5395, lr_0 = 3.4570e-04
Loss = 1.5879e-04, PNorm = 61.9498, GNorm = 0.4175, lr_0 = 3.4417e-04
Loss = 1.5911e-04, PNorm = 61.9579, GNorm = 0.2438, lr_0 = 3.4265e-04
Loss = 1.2988e-04, PNorm = 61.9664, GNorm = 0.4701, lr_0 = 3.4113e-04
Validation rmse logD = 0.594617
Validation R2 logD = 0.766691
Epoch 47
Train function
Loss = 1.1223e-04, PNorm = 61.9725, GNorm = 0.3072, lr_0 = 3.3947e-04
Loss = 8.9067e-05, PNorm = 61.9785, GNorm = 0.2443, lr_0 = 3.3797e-04
Loss = 1.4292e-04, PNorm = 61.9855, GNorm = 0.2367, lr_0 = 3.3648e-04
Loss = 1.4274e-04, PNorm = 61.9910, GNorm = 0.3581, lr_0 = 3.3499e-04
Loss = 1.1388e-04, PNorm = 61.9986, GNorm = 0.3431, lr_0 = 3.3351e-04
Validation rmse logD = 0.595928
Validation R2 logD = 0.765661
Epoch 48
Train function
Loss = 9.9925e-05, PNorm = 62.0057, GNorm = 0.4938, lr_0 = 3.3188e-04
Loss = 1.0970e-04, PNorm = 62.0144, GNorm = 0.4599, lr_0 = 3.3042e-04
Loss = 1.3928e-04, PNorm = 62.0233, GNorm = 0.1865, lr_0 = 3.2895e-04
Loss = 1.1668e-04, PNorm = 62.0309, GNorm = 0.4547, lr_0 = 3.2750e-04
Loss = 1.2279e-04, PNorm = 62.0393, GNorm = 0.3802, lr_0 = 3.2605e-04
Loss = 1.4348e-04, PNorm = 62.0442, GNorm = 0.2084, lr_0 = 3.2461e-04
Validation rmse logD = 0.595662
Validation R2 logD = 0.765870
Epoch 49
Train function
Loss = 1.1312e-04, PNorm = 62.0541, GNorm = 0.3825, lr_0 = 3.2303e-04
Loss = 1.2899e-04, PNorm = 62.0629, GNorm = 0.4085, lr_0 = 3.2160e-04
Loss = 1.1439e-04, PNorm = 62.0722, GNorm = 0.1856, lr_0 = 3.2018e-04
Loss = 1.4263e-04, PNorm = 62.0771, GNorm = 0.2629, lr_0 = 3.1876e-04
Loss = 1.3530e-04, PNorm = 62.0818, GNorm = 0.2886, lr_0 = 3.1735e-04
Validation rmse logD = 0.595986
Validation R2 logD = 0.765615
Epoch 50
Train function
Loss = 1.1290e-04, PNorm = 62.0843, GNorm = 0.5127, lr_0 = 3.1595e-04
Loss = 1.1822e-04, PNorm = 62.0900, GNorm = 0.1608, lr_0 = 3.1455e-04
Loss = 1.0470e-04, PNorm = 62.1004, GNorm = 0.3152, lr_0 = 3.1316e-04
Loss = 9.8024e-05, PNorm = 62.1093, GNorm = 0.2233, lr_0 = 3.1177e-04
Loss = 1.2017e-04, PNorm = 62.1134, GNorm = 0.2662, lr_0 = 3.1039e-04
Validation rmse logD = 0.590363
Validation R2 logD = 0.770017
Epoch 51
Train function
Loss = 7.9951e-05, PNorm = 62.1201, GNorm = 0.2248, lr_0 = 3.0888e-04
Loss = 7.8665e-05, PNorm = 62.1273, GNorm = 0.2900, lr_0 = 3.0752e-04
Loss = 1.0396e-04, PNorm = 62.1308, GNorm = 0.7660, lr_0 = 3.0616e-04
Loss = 9.7482e-05, PNorm = 62.1341, GNorm = 0.1953, lr_0 = 3.0480e-04
Loss = 8.5861e-05, PNorm = 62.1412, GNorm = 0.1946, lr_0 = 3.0346e-04
Loss = 7.7921e-05, PNorm = 62.1465, GNorm = 0.2111, lr_0 = 3.0211e-04
Validation rmse logD = 0.596646
Validation R2 logD = 0.765096
Epoch 52
Train function
Loss = 6.4718e-05, PNorm = 62.1515, GNorm = 0.1902, lr_0 = 3.0064e-04
Loss = 7.5949e-05, PNorm = 62.1556, GNorm = 0.3029, lr_0 = 2.9931e-04
Loss = 7.3978e-05, PNorm = 62.1617, GNorm = 0.1552, lr_0 = 2.9799e-04
Loss = 9.6674e-05, PNorm = 62.1658, GNorm = 0.3416, lr_0 = 2.9667e-04
Loss = 8.5169e-05, PNorm = 62.1738, GNorm = 0.1907, lr_0 = 2.9536e-04
Validation rmse logD = 0.593445
Validation R2 logD = 0.767609
Epoch 53
Train function
Loss = 7.7950e-05, PNorm = 62.1798, GNorm = 0.1920, lr_0 = 2.9392e-04
Loss = 7.6126e-05, PNorm = 62.1821, GNorm = 0.2777, lr_0 = 2.9262e-04
Loss = 7.1185e-05, PNorm = 62.1851, GNorm = 0.2301, lr_0 = 2.9133e-04
Loss = 7.2663e-05, PNorm = 62.1889, GNorm = 0.1727, lr_0 = 2.9004e-04
Loss = 7.5781e-05, PNorm = 62.1943, GNorm = 0.6163, lr_0 = 2.8876e-04
Validation rmse logD = 0.594370
Validation R2 logD = 0.766884
Epoch 54
Train function
Loss = 6.8693e-05, PNorm = 62.2010, GNorm = 0.2636, lr_0 = 2.8735e-04
Loss = 7.2445e-05, PNorm = 62.2043, GNorm = 0.3380, lr_0 = 2.8608e-04
Loss = 7.1886e-05, PNorm = 62.2106, GNorm = 0.4163, lr_0 = 2.8482e-04
Loss = 7.9964e-05, PNorm = 62.2168, GNorm = 0.7214, lr_0 = 2.8356e-04
Loss = 8.3248e-05, PNorm = 62.2226, GNorm = 0.2338, lr_0 = 2.8230e-04
Loss = 6.9925e-05, PNorm = 62.2279, GNorm = 0.2017, lr_0 = 2.8105e-04
Validation rmse logD = 0.596917
Validation R2 logD = 0.764882
Epoch 55
Train function
Loss = 9.1451e-05, PNorm = 62.2314, GNorm = 0.3416, lr_0 = 2.7969e-04
Loss = 9.9652e-05, PNorm = 62.2372, GNorm = 0.1704, lr_0 = 2.7845e-04
Loss = 5.8322e-05, PNorm = 62.2441, GNorm = 0.1447, lr_0 = 2.7722e-04
Loss = 9.3212e-05, PNorm = 62.2494, GNorm = 0.1617, lr_0 = 2.7599e-04
Loss = 8.7856e-05, PNorm = 62.2547, GNorm = 0.3134, lr_0 = 2.7477e-04
Validation rmse logD = 0.599352
Validation R2 logD = 0.762961
Epoch 56
Train function
Loss = 6.2646e-05, PNorm = 62.2631, GNorm = 0.2445, lr_0 = 2.7343e-04
Loss = 8.1196e-05, PNorm = 62.2676, GNorm = 0.2041, lr_0 = 2.7222e-04
Loss = 5.2421e-05, PNorm = 62.2709, GNorm = 0.1776, lr_0 = 2.7102e-04
Loss = 6.4399e-05, PNorm = 62.2759, GNorm = 0.1895, lr_0 = 2.6982e-04
Loss = 5.9581e-05, PNorm = 62.2806, GNorm = 0.1930, lr_0 = 2.6863e-04
Validation rmse logD = 0.605661
Validation R2 logD = 0.757944
Epoch 57
Train function
Loss = 1.5005e-04, PNorm = 62.2860, GNorm = 0.1871, lr_0 = 2.6732e-04
Loss = 1.4710e-04, PNorm = 62.2917, GNorm = 0.2540, lr_0 = 2.6614e-04
Loss = 1.3224e-04, PNorm = 62.2979, GNorm = 0.2076, lr_0 = 2.6496e-04
Loss = 1.0888e-04, PNorm = 62.3046, GNorm = 0.2352, lr_0 = 2.6379e-04
Loss = 1.0243e-04, PNorm = 62.3138, GNorm = 0.2942, lr_0 = 2.6262e-04
Loss = 6.2285e-05, PNorm = 62.3214, GNorm = 0.2069, lr_0 = 2.6146e-04
Loss = 1.5322e-03, PNorm = 62.3224, GNorm = 0.9077, lr_0 = 2.6134e-04
Validation rmse logD = 0.596643
Validation R2 logD = 0.765098
Epoch 58
Train function
Loss = 8.3538e-05, PNorm = 62.3276, GNorm = 0.3620, lr_0 = 2.6019e-04
Loss = 9.4374e-05, PNorm = 62.3313, GNorm = 0.4261, lr_0 = 2.5904e-04
Loss = 7.4433e-05, PNorm = 62.3333, GNorm = 0.1212, lr_0 = 2.5789e-04
Loss = 8.2948e-05, PNorm = 62.3368, GNorm = 0.3406, lr_0 = 2.5675e-04
Loss = 9.0585e-05, PNorm = 62.3421, GNorm = 0.4331, lr_0 = 2.5561e-04
Validation rmse logD = 0.594553
Validation R2 logD = 0.766741
Epoch 59
Train function
Loss = 7.3219e-05, PNorm = 62.3491, GNorm = 0.3494, lr_0 = 2.5448e-04
Loss = 6.1221e-05, PNorm = 62.3533, GNorm = 0.3234, lr_0 = 2.5336e-04
Loss = 7.5872e-05, PNorm = 62.3574, GNorm = 0.5991, lr_0 = 2.5224e-04
Loss = 6.6004e-05, PNorm = 62.3610, GNorm = 0.3473, lr_0 = 2.5112e-04
Loss = 6.4827e-05, PNorm = 62.3629, GNorm = 0.2021, lr_0 = 2.5001e-04
Validation rmse logD = 0.594999
Validation R2 logD = 0.766391
Epoch 60
Train function
Loss = 5.4149e-05, PNorm = 62.3676, GNorm = 0.1991, lr_0 = 2.4879e-04
Loss = 3.8718e-05, PNorm = 62.3696, GNorm = 0.1441, lr_0 = 2.4769e-04
Loss = 5.4353e-05, PNorm = 62.3742, GNorm = 0.2239, lr_0 = 2.4660e-04
Loss = 6.3089e-05, PNorm = 62.3779, GNorm = 0.2593, lr_0 = 2.4551e-04
Loss = 6.3440e-05, PNorm = 62.3818, GNorm = 0.2721, lr_0 = 2.4442e-04
Loss = 6.2048e-05, PNorm = 62.3877, GNorm = 0.1302, lr_0 = 2.4334e-04
Loss = 2.2461e-04, PNorm = 62.3882, GNorm = 0.2588, lr_0 = 2.4323e-04
Validation rmse logD = 0.595258
Validation R2 logD = 0.766187
Epoch 61
Train function
Loss = 3.6475e-05, PNorm = 62.3916, GNorm = 0.1067, lr_0 = 2.4216e-04
Loss = 4.2787e-05, PNorm = 62.3935, GNorm = 0.0988, lr_0 = 2.4109e-04
Loss = 4.3696e-05, PNorm = 62.3967, GNorm = 0.1849, lr_0 = 2.4002e-04
Loss = 4.8764e-05, PNorm = 62.4002, GNorm = 0.2381, lr_0 = 2.3896e-04
Loss = 4.8528e-05, PNorm = 62.4043, GNorm = 0.1175, lr_0 = 2.3790e-04
Validation rmse logD = 0.595857
Validation R2 logD = 0.765716
Epoch 62
Train function
Loss = 4.3376e-05, PNorm = 62.4072, GNorm = 0.1441, lr_0 = 2.3674e-04
Loss = 5.8862e-05, PNorm = 62.4109, GNorm = 0.3590, lr_0 = 2.3570e-04
Loss = 5.4081e-05, PNorm = 62.4143, GNorm = 0.1840, lr_0 = 2.3465e-04
Loss = 4.0862e-05, PNorm = 62.4179, GNorm = 0.1559, lr_0 = 2.3362e-04
Loss = 4.5370e-05, PNorm = 62.4212, GNorm = 0.1505, lr_0 = 2.3258e-04
Validation rmse logD = 0.594540
Validation R2 logD = 0.766752
Epoch 63
Train function
Loss = 3.4067e-05, PNorm = 62.4265, GNorm = 0.2745, lr_0 = 2.3145e-04
Loss = 5.0463e-05, PNorm = 62.4286, GNorm = 0.1975, lr_0 = 2.3043e-04
Loss = 5.1372e-05, PNorm = 62.4317, GNorm = 0.1730, lr_0 = 2.2941e-04
Loss = 3.9521e-05, PNorm = 62.4341, GNorm = 0.1089, lr_0 = 2.2839e-04
Loss = 4.1471e-05, PNorm = 62.4379, GNorm = 0.1317, lr_0 = 2.2738e-04
Validation rmse logD = 0.596603
Validation R2 logD = 0.765129
Epoch 64
Train function
Loss = 5.6098e-05, PNorm = 62.4404, GNorm = 0.1635, lr_0 = 2.2628e-04
Loss = 2.8164e-05, PNorm = 62.4422, GNorm = 0.1261, lr_0 = 2.2528e-04
Loss = 4.0954e-05, PNorm = 62.4445, GNorm = 0.1908, lr_0 = 2.2428e-04
Loss = 3.2341e-05, PNorm = 62.4465, GNorm = 0.1069, lr_0 = 2.2329e-04
Loss = 3.9214e-05, PNorm = 62.4508, GNorm = 0.1344, lr_0 = 2.2230e-04
Loss = 4.2808e-05, PNorm = 62.4532, GNorm = 0.1516, lr_0 = 2.2132e-04
Validation rmse logD = 0.598104
Validation R2 logD = 0.763946
Epoch 65
Train function
Loss = 2.6949e-05, PNorm = 62.4566, GNorm = 0.0997, lr_0 = 2.2024e-04
Loss = 3.5338e-05, PNorm = 62.4595, GNorm = 0.2967, lr_0 = 2.1927e-04
Loss = 4.5258e-05, PNorm = 62.4616, GNorm = 0.3027, lr_0 = 2.1830e-04
Loss = 5.0054e-05, PNorm = 62.4635, GNorm = 0.3574, lr_0 = 2.1733e-04
Loss = 4.6154e-05, PNorm = 62.4673, GNorm = 0.1503, lr_0 = 2.1637e-04
Validation rmse logD = 0.597441
Validation R2 logD = 0.764469
Epoch 66
Train function
Loss = 2.7039e-05, PNorm = 62.4702, GNorm = 0.2263, lr_0 = 2.1532e-04
Loss = 3.1421e-05, PNorm = 62.4735, GNorm = 0.1297, lr_0 = 2.1436e-04
Loss = 3.2042e-05, PNorm = 62.4766, GNorm = 0.2005, lr_0 = 2.1342e-04
Loss = 3.2128e-05, PNorm = 62.4794, GNorm = 0.1370, lr_0 = 2.1247e-04
Loss = 3.3723e-05, PNorm = 62.4816, GNorm = 0.1448, lr_0 = 2.1153e-04
Validation rmse logD = 0.596841
Validation R2 logD = 0.764942
Epoch 67
Train function
Loss = 1.7678e-05, PNorm = 62.4840, GNorm = 0.1780, lr_0 = 2.1060e-04
Loss = 3.3284e-05, PNorm = 62.4864, GNorm = 0.1106, lr_0 = 2.0966e-04
Loss = 2.8185e-05, PNorm = 62.4886, GNorm = 0.1307, lr_0 = 2.0874e-04
Loss = 2.8974e-05, PNorm = 62.4917, GNorm = 0.0911, lr_0 = 2.0781e-04
Loss = 3.2211e-05, PNorm = 62.4927, GNorm = 0.1618, lr_0 = 2.0689e-04
Loss = 2.9538e-05, PNorm = 62.4949, GNorm = 0.3008, lr_0 = 2.0598e-04
Validation rmse logD = 0.595677
Validation R2 logD = 0.765858
Epoch 68
Train function
Loss = 4.6776e-05, PNorm = 62.4968, GNorm = 0.4117, lr_0 = 2.0498e-04
Loss = 3.5021e-05, PNorm = 62.4982, GNorm = 0.1576, lr_0 = 2.0407e-04
Loss = 4.1988e-05, PNorm = 62.5028, GNorm = 0.2026, lr_0 = 2.0317e-04
Loss = 5.6571e-05, PNorm = 62.5075, GNorm = 0.1126, lr_0 = 2.0227e-04
Loss = 3.4140e-05, PNorm = 62.5113, GNorm = 0.1286, lr_0 = 2.0137e-04
Validation rmse logD = 0.595308
Validation R2 logD = 0.766148
Epoch 69
Train function
Loss = 2.7082e-05, PNorm = 62.5148, GNorm = 0.0763, lr_0 = 2.0039e-04
Loss = 3.6663e-05, PNorm = 62.5169, GNorm = 0.2586, lr_0 = 1.9951e-04
Loss = 3.3265e-05, PNorm = 62.5176, GNorm = 0.1470, lr_0 = 1.9863e-04
Loss = 3.3328e-05, PNorm = 62.5190, GNorm = 0.0950, lr_0 = 1.9775e-04
Loss = 3.1112e-05, PNorm = 62.5221, GNorm = 0.1482, lr_0 = 1.9687e-04
Validation rmse logD = 0.597194
Validation R2 logD = 0.764664
Epoch 70
Train function
Loss = 3.5790e-05, PNorm = 62.5253, GNorm = 0.1614, lr_0 = 1.9592e-04
Loss = 3.0922e-05, PNorm = 62.5282, GNorm = 0.1987, lr_0 = 1.9505e-04
Loss = 2.7597e-05, PNorm = 62.5314, GNorm = 0.1493, lr_0 = 1.9419e-04
Loss = 2.9715e-05, PNorm = 62.5343, GNorm = 0.1370, lr_0 = 1.9333e-04
Loss = 2.6590e-05, PNorm = 62.5369, GNorm = 0.1097, lr_0 = 1.9247e-04
Loss = 2.5497e-05, PNorm = 62.5375, GNorm = 0.0957, lr_0 = 1.9162e-04
Validation rmse logD = 0.597540
Validation R2 logD = 0.764391
Epoch 71
Train function
Loss = 2.7091e-05, PNorm = 62.5409, GNorm = 0.0858, lr_0 = 1.9069e-04
Loss = 2.5601e-05, PNorm = 62.5444, GNorm = 0.1384, lr_0 = 1.8984e-04
Loss = 2.3246e-05, PNorm = 62.5460, GNorm = 0.2206, lr_0 = 1.8900e-04
Loss = 3.6419e-05, PNorm = 62.5462, GNorm = 0.1176, lr_0 = 1.8817e-04
Loss = 3.0238e-05, PNorm = 62.5460, GNorm = 0.1858, lr_0 = 1.8734e-04
Validation rmse logD = 0.596505
Validation R2 logD = 0.765207
Epoch 72
Train function
Loss = 2.5299e-05, PNorm = 62.5501, GNorm = 0.2064, lr_0 = 1.8643e-04
Loss = 2.3723e-05, PNorm = 62.5531, GNorm = 0.2548, lr_0 = 1.8560e-04
Loss = 2.9198e-05, PNorm = 62.5564, GNorm = 0.1227, lr_0 = 1.8478e-04
Loss = 2.3617e-05, PNorm = 62.5585, GNorm = 0.0982, lr_0 = 1.8396e-04
Loss = 2.9663e-05, PNorm = 62.5601, GNorm = 0.0864, lr_0 = 1.8315e-04
Validation rmse logD = 0.596867
Validation R2 logD = 0.764921
Epoch 73
Train function
Loss = 3.5706e-05, PNorm = 62.5640, GNorm = 0.3521, lr_0 = 1.8226e-04
Loss = 4.6464e-05, PNorm = 62.5656, GNorm = 0.1060, lr_0 = 1.8145e-04
Loss = 3.2147e-05, PNorm = 62.5680, GNorm = 0.0906, lr_0 = 1.8065e-04
Loss = 2.9649e-05, PNorm = 62.5701, GNorm = 0.2455, lr_0 = 1.7985e-04
Loss = 3.1776e-05, PNorm = 62.5729, GNorm = 0.2202, lr_0 = 1.7905e-04
Loss = 3.5122e-05, PNorm = 62.5749, GNorm = 0.1071, lr_0 = 1.7826e-04
Loss = 1.2520e-04, PNorm = 62.5752, GNorm = 0.2177, lr_0 = 1.7818e-04
Validation rmse logD = 0.600594
Validation R2 logD = 0.761977
Epoch 74
Train function
Loss = 2.7265e-05, PNorm = 62.5785, GNorm = 0.2157, lr_0 = 1.7739e-04
Loss = 3.4467e-05, PNorm = 62.5814, GNorm = 0.1231, lr_0 = 1.7661e-04
Loss = 2.5638e-05, PNorm = 62.5828, GNorm = 0.1487, lr_0 = 1.7583e-04
Loss = 2.4507e-05, PNorm = 62.5842, GNorm = 0.2433, lr_0 = 1.7505e-04
Loss = 2.8030e-05, PNorm = 62.5858, GNorm = 0.1088, lr_0 = 1.7428e-04
Validation rmse logD = 0.597015
Validation R2 logD = 0.764805
Epoch 75
Train function
Loss = 1.9422e-05, PNorm = 62.5879, GNorm = 0.1941, lr_0 = 1.7351e-04
Loss = 2.0607e-05, PNorm = 62.5884, GNorm = 0.0657, lr_0 = 1.7274e-04
Loss = 2.2091e-05, PNorm = 62.5893, GNorm = 0.1612, lr_0 = 1.7197e-04
Loss = 2.6659e-05, PNorm = 62.5920, GNorm = 0.0965, lr_0 = 1.7121e-04
Loss = 2.3470e-05, PNorm = 62.5949, GNorm = 0.1514, lr_0 = 1.7046e-04
Validation rmse logD = 0.598966
Validation R2 logD = 0.763265
Epoch 76
Train function
Loss = 2.3668e-05, PNorm = 62.5973, GNorm = 0.1031, lr_0 = 1.6963e-04
Loss = 2.1599e-05, PNorm = 62.6005, GNorm = 0.1957, lr_0 = 1.6888e-04
Loss = 2.1981e-05, PNorm = 62.6028, GNorm = 0.1692, lr_0 = 1.6813e-04
Loss = 1.9418e-05, PNorm = 62.6036, GNorm = 0.1854, lr_0 = 1.6739e-04
Loss = 2.5140e-05, PNorm = 62.6054, GNorm = 0.2160, lr_0 = 1.6665e-04
Loss = 2.3658e-05, PNorm = 62.6074, GNorm = 0.1395, lr_0 = 1.6591e-04
Loss = 1.4213e-04, PNorm = 62.6076, GNorm = 0.3691, lr_0 = 1.6584e-04
Validation rmse logD = 0.599256
Validation R2 logD = 0.763036
Epoch 77
Train function
Loss = 2.5872e-05, PNorm = 62.6083, GNorm = 0.3955, lr_0 = 1.6510e-04
Loss = 2.3317e-05, PNorm = 62.6105, GNorm = 0.1075, lr_0 = 1.6437e-04
Loss = 2.4371e-05, PNorm = 62.6127, GNorm = 0.1837, lr_0 = 1.6364e-04
Loss = 2.1088e-05, PNorm = 62.6137, GNorm = 0.1063, lr_0 = 1.6292e-04
Loss = 2.1399e-05, PNorm = 62.6151, GNorm = 0.2207, lr_0 = 1.6220e-04
Validation rmse logD = 0.596050
Validation R2 logD = 0.765565
Epoch 78
Train function
Loss = 4.3982e-05, PNorm = 62.6187, GNorm = 0.1982, lr_0 = 1.6141e-04
Loss = 3.3987e-05, PNorm = 62.6206, GNorm = 0.1198, lr_0 = 1.6070e-04
Loss = 2.6732e-05, PNorm = 62.6233, GNorm = 0.0873, lr_0 = 1.5999e-04
Loss = 2.2173e-05, PNorm = 62.6255, GNorm = 0.1207, lr_0 = 1.5928e-04
Loss = 2.2840e-05, PNorm = 62.6264, GNorm = 0.1074, lr_0 = 1.5857e-04
Validation rmse logD = 0.597900
Validation R2 logD = 0.764107
Epoch 79
Train function
Loss = 1.9790e-05, PNorm = 62.6279, GNorm = 0.0786, lr_0 = 1.5780e-04
Loss = 1.9360e-05, PNorm = 62.6311, GNorm = 0.0618, lr_0 = 1.5710e-04
Loss = 2.1722e-05, PNorm = 62.6331, GNorm = 0.1044, lr_0 = 1.5641e-04
Loss = 1.9554e-05, PNorm = 62.6344, GNorm = 0.1339, lr_0 = 1.5572e-04
Loss = 1.5052e-05, PNorm = 62.6347, GNorm = 0.0732, lr_0 = 1.5503e-04
Validation rmse logD = 0.598462
Validation R2 logD = 0.763664
Epoch 80
Train function
Loss = 2.4788e-05, PNorm = 62.6370, GNorm = 0.1378, lr_0 = 1.5427e-04
Loss = 1.9747e-05, PNorm = 62.6380, GNorm = 0.1029, lr_0 = 1.5359e-04
Loss = 1.6561e-05, PNorm = 62.6394, GNorm = 0.1008, lr_0 = 1.5291e-04
Loss = 2.0159e-05, PNorm = 62.6406, GNorm = 0.2674, lr_0 = 1.5224e-04
Loss = 2.3676e-05, PNorm = 62.6417, GNorm = 0.2351, lr_0 = 1.5156e-04
Loss = 2.0485e-05, PNorm = 62.6424, GNorm = 0.1956, lr_0 = 1.5089e-04
Validation rmse logD = 0.598296
Validation R2 logD = 0.763795
Epoch 81
Train function
Loss = 3.5872e-05, PNorm = 62.6446, GNorm = 0.4805, lr_0 = 1.5016e-04
Loss = 4.8191e-05, PNorm = 62.6470, GNorm = 0.3730, lr_0 = 1.4949e-04
Loss = 5.6398e-05, PNorm = 62.6515, GNorm = 0.2096, lr_0 = 1.4883e-04
Loss = 3.9055e-05, PNorm = 62.6564, GNorm = 0.2903, lr_0 = 1.4817e-04
Loss = 2.1611e-05, PNorm = 62.6581, GNorm = 0.1469, lr_0 = 1.4752e-04
Validation rmse logD = 0.597932
Validation R2 logD = 0.764082
Epoch 82
Train function
Loss = 2.8524e-05, PNorm = 62.6586, GNorm = 0.3848, lr_0 = 1.4680e-04
Loss = 2.8233e-05, PNorm = 62.6600, GNorm = 0.2454, lr_0 = 1.4615e-04
Loss = 2.6275e-05, PNorm = 62.6613, GNorm = 0.1610, lr_0 = 1.4551e-04
Loss = 2.7410e-05, PNorm = 62.6639, GNorm = 0.3203, lr_0 = 1.4486e-04
Loss = 2.3899e-05, PNorm = 62.6653, GNorm = 0.2885, lr_0 = 1.4422e-04
Validation rmse logD = 0.596382
Validation R2 logD = 0.765304
Epoch 83
Train function
Loss = 1.6917e-05, PNorm = 62.6676, GNorm = 0.1137, lr_0 = 1.4352e-04
Loss = 1.5697e-05, PNorm = 62.6678, GNorm = 0.1147, lr_0 = 1.4288e-04
Loss = 2.0567e-05, PNorm = 62.6699, GNorm = 0.0932, lr_0 = 1.4225e-04
Loss = 1.4844e-05, PNorm = 62.6713, GNorm = 0.1514, lr_0 = 1.4162e-04
Loss = 1.4814e-05, PNorm = 62.6731, GNorm = 0.1801, lr_0 = 1.4100e-04
Loss = 1.5373e-05, PNorm = 62.6745, GNorm = 0.0804, lr_0 = 1.4037e-04
Validation rmse logD = 0.596809
Validation R2 logD = 0.764968
Epoch 84
Train function
Loss = 1.2898e-05, PNorm = 62.6766, GNorm = 0.0835, lr_0 = 1.3975e-04
Loss = 1.3789e-05, PNorm = 62.6782, GNorm = 0.1577, lr_0 = 1.3913e-04
Loss = 1.2841e-05, PNorm = 62.6791, GNorm = 0.1143, lr_0 = 1.3852e-04
Loss = 1.6724e-05, PNorm = 62.6804, GNorm = 0.1317, lr_0 = 1.3791e-04
Loss = 1.5074e-05, PNorm = 62.6822, GNorm = 0.1535, lr_0 = 1.3730e-04
Validation rmse logD = 0.597397
Validation R2 logD = 0.764504
Epoch 85
Train function
Loss = 1.4382e-05, PNorm = 62.6840, GNorm = 0.0938, lr_0 = 1.3663e-04
Loss = 1.6962e-05, PNorm = 62.6849, GNorm = 0.1372, lr_0 = 1.3602e-04
Loss = 1.5478e-05, PNorm = 62.6858, GNorm = 0.2055, lr_0 = 1.3542e-04
Loss = 1.5145e-05, PNorm = 62.6876, GNorm = 0.1824, lr_0 = 1.3482e-04
Loss = 1.1964e-05, PNorm = 62.6882, GNorm = 0.0772, lr_0 = 1.3423e-04
Validation rmse logD = 0.598212
Validation R2 logD = 0.763861
Epoch 86
Train function
Loss = 5.4922e-06, PNorm = 62.6893, GNorm = 0.0445, lr_0 = 1.3357e-04
Loss = 1.4602e-05, PNorm = 62.6905, GNorm = 0.1249, lr_0 = 1.3298e-04
Loss = 1.3283e-05, PNorm = 62.6919, GNorm = 0.0997, lr_0 = 1.3239e-04
Loss = 1.2353e-05, PNorm = 62.6928, GNorm = 0.1584, lr_0 = 1.3181e-04
Loss = 1.1265e-05, PNorm = 62.6940, GNorm = 0.0585, lr_0 = 1.3123e-04
Loss = 1.2130e-05, PNorm = 62.6957, GNorm = 0.0956, lr_0 = 1.3065e-04
Validation rmse logD = 0.598298
Validation R2 logD = 0.763794
Epoch 87
Train function
Loss = 1.2917e-05, PNorm = 62.6979, GNorm = 0.0545, lr_0 = 1.3001e-04
Loss = 1.6209e-05, PNorm = 62.6991, GNorm = 0.0893, lr_0 = 1.2944e-04
Loss = 1.2898e-05, PNorm = 62.6994, GNorm = 0.0568, lr_0 = 1.2886e-04
Loss = 1.2940e-05, PNorm = 62.7001, GNorm = 0.0766, lr_0 = 1.2829e-04
Loss = 1.1570e-05, PNorm = 62.7014, GNorm = 0.1304, lr_0 = 1.2773e-04
Validation rmse logD = 0.600468
Validation R2 logD = 0.762076
Epoch 88
Train function
Loss = 1.2420e-05, PNorm = 62.7032, GNorm = 0.0871, lr_0 = 1.2710e-04
Loss = 1.2203e-05, PNorm = 62.7037, GNorm = 0.1536, lr_0 = 1.2654e-04
Loss = 1.3355e-05, PNorm = 62.7042, GNorm = 0.1168, lr_0 = 1.2598e-04
Loss = 1.3812e-05, PNorm = 62.7058, GNorm = 0.0860, lr_0 = 1.2542e-04
Loss = 1.3905e-05, PNorm = 62.7069, GNorm = 0.0583, lr_0 = 1.2487e-04
Validation rmse logD = 0.599435
Validation R2 logD = 0.762895
Epoch 89
Train function
Loss = 2.7873e-05, PNorm = 62.7086, GNorm = 0.0988, lr_0 = 1.2426e-04
Loss = 2.4941e-05, PNorm = 62.7108, GNorm = 0.1269, lr_0 = 1.2371e-04
Loss = 1.9817e-05, PNorm = 62.7128, GNorm = 0.0950, lr_0 = 1.2317e-04
Loss = 1.3796e-05, PNorm = 62.7136, GNorm = 0.0655, lr_0 = 1.2262e-04
Loss = 1.5751e-05, PNorm = 62.7154, GNorm = 0.0704, lr_0 = 1.2208e-04
Loss = 1.5574e-05, PNorm = 62.7165, GNorm = 0.1428, lr_0 = 1.2154e-04
Loss = 8.6649e-05, PNorm = 62.7166, GNorm = 0.2275, lr_0 = 1.2148e-04
Validation rmse logD = 0.599975
Validation R2 logD = 0.762468
Epoch 90
Train function
Loss = 1.0933e-05, PNorm = 62.7177, GNorm = 0.1311, lr_0 = 1.2095e-04
Loss = 1.1678e-05, PNorm = 62.7195, GNorm = 0.0854, lr_0 = 1.2041e-04
Loss = 1.3261e-05, PNorm = 62.7207, GNorm = 0.1103, lr_0 = 1.1988e-04
Loss = 1.5673e-05, PNorm = 62.7212, GNorm = 0.1278, lr_0 = 1.1935e-04
Loss = 1.4636e-05, PNorm = 62.7225, GNorm = 0.1715, lr_0 = 1.1882e-04
Validation rmse logD = 0.598402
Validation R2 logD = 0.763711
Epoch 91
Train function
Loss = 1.4740e-05, PNorm = 62.7231, GNorm = 0.1835, lr_0 = 1.1824e-04
Loss = 1.1037e-05, PNorm = 62.7248, GNorm = 0.1620, lr_0 = 1.1772e-04
Loss = 1.6517e-05, PNorm = 62.7261, GNorm = 0.1207, lr_0 = 1.1720e-04
Loss = 1.5712e-05, PNorm = 62.7272, GNorm = 0.1555, lr_0 = 1.1668e-04
Loss = 1.3918e-05, PNorm = 62.7283, GNorm = 0.1121, lr_0 = 1.1616e-04
Validation rmse logD = 0.598687
Validation R2 logD = 0.763486
Epoch 92
Train function
Loss = 1.4260e-05, PNorm = 62.7291, GNorm = 0.1211, lr_0 = 1.1565e-04
Loss = 1.1562e-05, PNorm = 62.7300, GNorm = 0.0917, lr_0 = 1.1514e-04
Loss = 9.9184e-06, PNorm = 62.7306, GNorm = 0.0708, lr_0 = 1.1463e-04
Loss = 9.3347e-06, PNorm = 62.7309, GNorm = 0.0568, lr_0 = 1.1412e-04
Loss = 1.2107e-05, PNorm = 62.7317, GNorm = 0.0680, lr_0 = 1.1362e-04
Loss = 1.1362e-05, PNorm = 62.7326, GNorm = 0.1252, lr_0 = 1.1312e-04
Loss = 1.8415e-04, PNorm = 62.7330, GNorm = 0.3758, lr_0 = 1.1307e-04
Validation rmse logD = 0.599052
Validation R2 logD = 0.763197
Epoch 93
Train function
Loss = 1.4404e-05, PNorm = 62.7345, GNorm = 0.0808, lr_0 = 1.1257e-04
Loss = 8.9732e-06, PNorm = 62.7352, GNorm = 0.1162, lr_0 = 1.1207e-04
Loss = 1.2972e-05, PNorm = 62.7352, GNorm = 0.1375, lr_0 = 1.1157e-04
Loss = 1.0471e-05, PNorm = 62.7361, GNorm = 0.1232, lr_0 = 1.1108e-04
Loss = 1.1681e-05, PNorm = 62.7374, GNorm = 0.0564, lr_0 = 1.1059e-04
Validation rmse logD = 0.599412
Validation R2 logD = 0.762913
Epoch 94
Train function
Loss = 1.0187e-05, PNorm = 62.7396, GNorm = 0.0656, lr_0 = 1.1005e-04
Loss = 1.0714e-05, PNorm = 62.7403, GNorm = 0.0523, lr_0 = 1.0956e-04
Loss = 1.0902e-05, PNorm = 62.7413, GNorm = 0.2642, lr_0 = 1.0908e-04
Loss = 9.9654e-06, PNorm = 62.7418, GNorm = 0.1176, lr_0 = 1.0860e-04
Loss = 9.9569e-06, PNorm = 62.7431, GNorm = 0.0503, lr_0 = 1.0811e-04
Validation rmse logD = 0.599242
Validation R2 logD = 0.763047
Epoch 95
Train function
Loss = 9.1135e-06, PNorm = 62.7439, GNorm = 0.0570, lr_0 = 1.0759e-04
Loss = 7.0538e-06, PNorm = 62.7445, GNorm = 0.0986, lr_0 = 1.0711e-04
Loss = 7.8071e-06, PNorm = 62.7450, GNorm = 0.1105, lr_0 = 1.0664e-04
Loss = 6.2540e-06, PNorm = 62.7457, GNorm = 0.0743, lr_0 = 1.0617e-04
Loss = 9.6065e-06, PNorm = 62.7468, GNorm = 0.0682, lr_0 = 1.0570e-04
Validation rmse logD = 0.600013
Validation R2 logD = 0.762437
Epoch 96
Train function
Loss = 6.2810e-06, PNorm = 62.7478, GNorm = 0.1250, lr_0 = 1.0518e-04
Loss = 8.9892e-06, PNorm = 62.7484, GNorm = 0.1803, lr_0 = 1.0472e-04
Loss = 8.0610e-06, PNorm = 62.7488, GNorm = 0.1425, lr_0 = 1.0426e-04
Loss = 7.1262e-06, PNorm = 62.7503, GNorm = 0.0655, lr_0 = 1.0379e-04
Loss = 7.2096e-06, PNorm = 62.7512, GNorm = 0.0494, lr_0 = 1.0333e-04
Loss = 9.2850e-06, PNorm = 62.7521, GNorm = 0.0641, lr_0 = 1.0288e-04
Validation rmse logD = 0.599072
Validation R2 logD = 0.763182
Epoch 97
Train function
Loss = 9.2538e-06, PNorm = 62.7529, GNorm = 0.0738, lr_0 = 1.0238e-04
Loss = 9.9794e-06, PNorm = 62.7538, GNorm = 0.1637, lr_0 = 1.0192e-04
Loss = 6.4917e-06, PNorm = 62.7546, GNorm = 0.0615, lr_0 = 1.0147e-04
Loss = 7.6744e-06, PNorm = 62.7550, GNorm = 0.0476, lr_0 = 1.0102e-04
Loss = 7.7165e-06, PNorm = 62.7560, GNorm = 0.0463, lr_0 = 1.0058e-04
Validation rmse logD = 0.599323
Validation R2 logD = 0.762983
Epoch 98
Train function
Loss = 5.5093e-06, PNorm = 62.7570, GNorm = 0.0962, lr_0 = 1.0009e-04
Loss = 7.2202e-06, PNorm = 62.7573, GNorm = 0.0908, lr_0 = 1.0000e-04
Loss = 7.7363e-06, PNorm = 62.7581, GNorm = 0.0613, lr_0 = 1.0000e-04
Loss = 6.3882e-06, PNorm = 62.7589, GNorm = 0.0538, lr_0 = 1.0000e-04
Loss = 6.3063e-06, PNorm = 62.7598, GNorm = 0.0452, lr_0 = 1.0000e-04
Validation rmse logD = 0.599197
Validation R2 logD = 0.763082
Epoch 99
Train function
Loss = 4.1376e-06, PNorm = 62.7611, GNorm = 0.0835, lr_0 = 1.0000e-04
Loss = 6.3885e-06, PNorm = 62.7617, GNorm = 0.1915, lr_0 = 1.0000e-04
Loss = 7.1830e-06, PNorm = 62.7628, GNorm = 0.1017, lr_0 = 1.0000e-04
Loss = 8.2204e-06, PNorm = 62.7633, GNorm = 0.0871, lr_0 = 1.0000e-04
Loss = 9.2643e-06, PNorm = 62.7630, GNorm = 0.0570, lr_0 = 1.0000e-04
Loss = 7.2265e-06, PNorm = 62.7638, GNorm = 0.0983, lr_0 = 1.0000e-04
Validation rmse logD = 0.598757
Validation R2 logD = 0.763430
Model 0 best validation rmse = 0.584360 on epoch 35
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.613909
Model 0 test R2 logD = 0.739339
Ensemble test rmse  logD= 0.613909
Ensemble test R2  logD= 0.739339
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_314/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.2658e-02, PNorm = 52.9145, GNorm = 5.2360, lr_0 = 1.9340e-04
Loss = 1.8278e-02, PNorm = 52.9225, GNorm = 3.3339, lr_0 = 2.7830e-04
Loss = 1.6368e-02, PNorm = 52.9348, GNorm = 2.5297, lr_0 = 3.6321e-04
Loss = 1.3743e-02, PNorm = 52.9522, GNorm = 1.7498, lr_0 = 4.4811e-04
Loss = 1.3387e-02, PNorm = 52.9730, GNorm = 3.1007, lr_0 = 5.3302e-04
Validation rmse logD = 0.999255
Validation R2 logD = 0.329717
Epoch 1
Train function
Loss = 1.3442e-02, PNorm = 53.0063, GNorm = 5.5785, lr_0 = 6.2642e-04
Loss = 1.1429e-02, PNorm = 53.0479, GNorm = 2.1991, lr_0 = 7.1132e-04
Loss = 1.0464e-02, PNorm = 53.0904, GNorm = 6.3159, lr_0 = 7.9623e-04
Loss = 1.0425e-02, PNorm = 53.1383, GNorm = 3.1336, lr_0 = 8.8113e-04
Loss = 1.0972e-02, PNorm = 53.1981, GNorm = 2.3301, lr_0 = 9.6604e-04
Validation rmse logD = 0.879644
Validation R2 logD = 0.480580
Epoch 2
Train function
Loss = 1.1368e-02, PNorm = 53.2784, GNorm = 3.1570, lr_0 = 9.9690e-04
Loss = 9.9253e-03, PNorm = 53.3412, GNorm = 4.1711, lr_0 = 9.9249e-04
Loss = 9.8719e-03, PNorm = 53.4251, GNorm = 4.7480, lr_0 = 9.8810e-04
Loss = 1.0282e-02, PNorm = 53.5013, GNorm = 8.3425, lr_0 = 9.8373e-04
Loss = 8.9564e-03, PNorm = 53.5840, GNorm = 2.4066, lr_0 = 9.7938e-04
Validation rmse logD = 1.015173
Validation R2 logD = 0.308193
Epoch 3
Train function
Loss = 1.2424e-02, PNorm = 53.6625, GNorm = 6.4999, lr_0 = 9.7462e-04
Loss = 8.1562e-03, PNorm = 53.7397, GNorm = 1.5344, lr_0 = 9.7030e-04
Loss = 7.2591e-03, PNorm = 53.8268, GNorm = 2.1501, lr_0 = 9.6601e-04
Loss = 7.5735e-03, PNorm = 53.9282, GNorm = 1.0419, lr_0 = 9.6174e-04
Loss = 8.9111e-03, PNorm = 54.0072, GNorm = 6.9236, lr_0 = 9.5749e-04
Loss = 8.0001e-03, PNorm = 54.0908, GNorm = 2.8294, lr_0 = 9.5325e-04
Validation rmse logD = 0.835707
Validation R2 logD = 0.531173
Epoch 4
Train function
Loss = 6.5702e-03, PNorm = 54.1977, GNorm = 2.8819, lr_0 = 9.4861e-04
Loss = 7.7649e-03, PNorm = 54.2781, GNorm = 1.7334, lr_0 = 9.4442e-04
Loss = 6.9788e-03, PNorm = 54.3626, GNorm = 2.1500, lr_0 = 9.4024e-04
Loss = 7.5691e-03, PNorm = 54.4414, GNorm = 1.3450, lr_0 = 9.3608e-04
Loss = 7.6271e-03, PNorm = 54.5214, GNorm = 3.2287, lr_0 = 9.3194e-04
Validation rmse logD = 0.869738
Validation R2 logD = 0.492213
Epoch 5
Train function
Loss = 6.7257e-03, PNorm = 54.5959, GNorm = 3.5830, lr_0 = 9.2741e-04
Loss = 6.3464e-03, PNorm = 54.6741, GNorm = 1.8591, lr_0 = 9.2330e-04
Loss = 5.6974e-03, PNorm = 54.7455, GNorm = 4.2627, lr_0 = 9.1922e-04
Loss = 5.6140e-03, PNorm = 54.8186, GNorm = 0.8681, lr_0 = 9.1515e-04
Loss = 6.4271e-03, PNorm = 54.8993, GNorm = 2.2816, lr_0 = 9.1111e-04
Validation rmse logD = 0.694197
Validation R2 logD = 0.676502
Epoch 6
Train function
Loss = 5.4641e-03, PNorm = 54.9965, GNorm = 3.3441, lr_0 = 9.0667e-04
Loss = 4.9444e-03, PNorm = 55.0914, GNorm = 1.1842, lr_0 = 9.0266e-04
Loss = 5.2399e-03, PNorm = 55.1870, GNorm = 3.5362, lr_0 = 8.9867e-04
Loss = 5.7816e-03, PNorm = 55.2867, GNorm = 3.6125, lr_0 = 8.9469e-04
Loss = 5.8429e-03, PNorm = 55.3723, GNorm = 1.4270, lr_0 = 8.9074e-04
Loss = 4.6241e-03, PNorm = 55.4473, GNorm = 1.1995, lr_0 = 8.8680e-04
Validation rmse logD = 0.728956
Validation R2 logD = 0.643297
Epoch 7
Train function
Loss = 5.7685e-03, PNorm = 55.5331, GNorm = 5.4283, lr_0 = 8.8248e-04
Loss = 4.5330e-03, PNorm = 55.6262, GNorm = 3.6681, lr_0 = 8.7858e-04
Loss = 3.7906e-03, PNorm = 55.7117, GNorm = 2.0659, lr_0 = 8.7469e-04
Loss = 4.2547e-03, PNorm = 55.7757, GNorm = 0.7156, lr_0 = 8.7082e-04
Loss = 5.3769e-03, PNorm = 55.8485, GNorm = 3.3726, lr_0 = 8.6697e-04
Validation rmse logD = 0.652871
Validation R2 logD = 0.713873
Epoch 8
Train function
Loss = 4.3444e-03, PNorm = 55.9431, GNorm = 1.9312, lr_0 = 8.6276e-04
Loss = 3.5817e-03, PNorm = 56.0227, GNorm = 0.9204, lr_0 = 8.5894e-04
Loss = 4.1835e-03, PNorm = 56.0952, GNorm = 2.8387, lr_0 = 8.5514e-04
Loss = 4.0886e-03, PNorm = 56.1980, GNorm = 1.4351, lr_0 = 8.5136e-04
Loss = 4.0878e-03, PNorm = 56.2773, GNorm = 2.7579, lr_0 = 8.4759e-04
Validation rmse logD = 0.635826
Validation R2 logD = 0.728617
Epoch 9
Train function
Loss = 3.3107e-03, PNorm = 56.3636, GNorm = 3.0588, lr_0 = 8.4384e-04
Loss = 3.0918e-03, PNorm = 56.4419, GNorm = 0.7396, lr_0 = 8.4011e-04
Loss = 3.6844e-03, PNorm = 56.5204, GNorm = 1.2414, lr_0 = 8.3639e-04
Loss = 3.5671e-03, PNorm = 56.6005, GNorm = 3.1250, lr_0 = 8.3269e-04
Loss = 4.1312e-03, PNorm = 56.6765, GNorm = 2.4893, lr_0 = 8.2901e-04
Loss = 4.1371e-03, PNorm = 56.7641, GNorm = 1.2020, lr_0 = 8.2534e-04
Validation rmse logD = 0.625772
Validation R2 logD = 0.737132
Epoch 10
Train function
Loss = 3.9366e-03, PNorm = 56.8624, GNorm = 3.4191, lr_0 = 8.2133e-04
Loss = 3.5049e-03, PNorm = 56.9446, GNorm = 3.2735, lr_0 = 8.1770e-04
Loss = 3.2005e-03, PNorm = 57.0287, GNorm = 0.9040, lr_0 = 8.1408e-04
Loss = 2.9840e-03, PNorm = 57.0858, GNorm = 0.8751, lr_0 = 8.1048e-04
Loss = 2.9727e-03, PNorm = 57.1547, GNorm = 1.2264, lr_0 = 8.0689e-04
Validation rmse logD = 0.658709
Validation R2 logD = 0.708733
Epoch 11
Train function
Loss = 3.3575e-03, PNorm = 57.2609, GNorm = 3.5041, lr_0 = 8.0297e-04
Loss = 3.2273e-03, PNorm = 57.3489, GNorm = 2.6097, lr_0 = 7.9942e-04
Loss = 3.0338e-03, PNorm = 57.4323, GNorm = 2.0511, lr_0 = 7.9588e-04
Loss = 2.6318e-03, PNorm = 57.4985, GNorm = 1.4387, lr_0 = 7.9236e-04
Loss = 2.8870e-03, PNorm = 57.5705, GNorm = 0.8788, lr_0 = 7.8885e-04
Validation rmse logD = 0.614166
Validation R2 logD = 0.746792
Epoch 12
Train function
Loss = 2.6334e-03, PNorm = 57.6275, GNorm = 1.1484, lr_0 = 7.8502e-04
Loss = 2.6060e-03, PNorm = 57.7024, GNorm = 1.2678, lr_0 = 7.8154e-04
Loss = 2.9804e-03, PNorm = 57.7648, GNorm = 2.1477, lr_0 = 7.7809e-04
Loss = 2.7595e-03, PNorm = 57.8380, GNorm = 2.0331, lr_0 = 7.7465e-04
Loss = 2.4147e-03, PNorm = 57.9066, GNorm = 0.8304, lr_0 = 7.7122e-04
Loss = 2.5304e-03, PNorm = 57.9639, GNorm = 1.9491, lr_0 = 7.6781e-04
Loss = 3.3216e-02, PNorm = 57.9732, GNorm = 2.7329, lr_0 = 7.6747e-04
Validation rmse logD = 0.601181
Validation R2 logD = 0.757386
Epoch 13
Train function
Loss = 2.1270e-03, PNorm = 58.0557, GNorm = 1.3189, lr_0 = 7.6407e-04
Loss = 2.4871e-03, PNorm = 58.1227, GNorm = 0.9759, lr_0 = 7.6069e-04
Loss = 2.1469e-03, PNorm = 58.1942, GNorm = 1.0881, lr_0 = 7.5733e-04
Loss = 2.4634e-03, PNorm = 58.2587, GNorm = 0.9468, lr_0 = 7.5398e-04
Loss = 2.1569e-03, PNorm = 58.3263, GNorm = 0.8166, lr_0 = 7.5064e-04
Validation rmse logD = 0.722910
Validation R2 logD = 0.649189
Epoch 14
Train function
Loss = 2.7460e-03, PNorm = 58.3956, GNorm = 1.5895, lr_0 = 7.4699e-04
Loss = 1.8415e-03, PNorm = 58.4548, GNorm = 0.5574, lr_0 = 7.4369e-04
Loss = 1.7110e-03, PNorm = 58.5033, GNorm = 0.8341, lr_0 = 7.4040e-04
Loss = 1.7306e-03, PNorm = 58.5485, GNorm = 0.9060, lr_0 = 7.3712e-04
Loss = 1.8954e-03, PNorm = 58.5871, GNorm = 0.8912, lr_0 = 7.3386e-04
Validation rmse logD = 0.624446
Validation R2 logD = 0.738246
Epoch 15
Train function
Loss = 2.4049e-03, PNorm = 58.6500, GNorm = 1.6758, lr_0 = 7.3029e-04
Loss = 1.6175e-03, PNorm = 58.6902, GNorm = 1.0701, lr_0 = 7.2706e-04
Loss = 1.7536e-03, PNorm = 58.7431, GNorm = 2.3064, lr_0 = 7.2385e-04
Loss = 2.0374e-03, PNorm = 58.8095, GNorm = 2.4848, lr_0 = 7.2064e-04
Loss = 1.9889e-03, PNorm = 58.8652, GNorm = 2.6981, lr_0 = 7.1746e-04
Validation rmse logD = 0.595539
Validation R2 logD = 0.761918
Epoch 16
Train function
Loss = 1.8672e-03, PNorm = 58.9464, GNorm = 1.5446, lr_0 = 7.1397e-04
Loss = 2.5608e-03, PNorm = 59.0280, GNorm = 3.2539, lr_0 = 7.1081e-04
Loss = 2.0118e-03, PNorm = 59.0979, GNorm = 2.0491, lr_0 = 7.0766e-04
Loss = 1.7094e-03, PNorm = 59.1532, GNorm = 0.9470, lr_0 = 7.0453e-04
Loss = 1.7605e-03, PNorm = 59.2140, GNorm = 0.9287, lr_0 = 7.0142e-04
Loss = 1.6254e-03, PNorm = 59.2494, GNorm = 0.7001, lr_0 = 6.9831e-04
Validation rmse logD = 0.629858
Validation R2 logD = 0.733688
Epoch 17
Train function
Loss = 1.5413e-03, PNorm = 59.2945, GNorm = 1.4176, lr_0 = 6.9523e-04
Loss = 1.2428e-03, PNorm = 59.3415, GNorm = 0.4822, lr_0 = 6.9215e-04
Loss = 1.6077e-03, PNorm = 59.3768, GNorm = 1.0687, lr_0 = 6.8909e-04
Loss = 1.4475e-03, PNorm = 59.4152, GNorm = 1.8335, lr_0 = 6.8604e-04
Loss = 1.5456e-03, PNorm = 59.4709, GNorm = 1.0442, lr_0 = 6.8301e-04
Validation rmse logD = 0.595185
Validation R2 logD = 0.762202
Epoch 18
Train function
Loss = 1.0165e-03, PNorm = 59.5156, GNorm = 1.3747, lr_0 = 6.7968e-04
Loss = 1.2024e-03, PNorm = 59.5583, GNorm = 0.6595, lr_0 = 6.7668e-04
Loss = 1.2445e-03, PNorm = 59.5917, GNorm = 1.6602, lr_0 = 6.7368e-04
Loss = 1.0795e-03, PNorm = 59.6198, GNorm = 1.1059, lr_0 = 6.7070e-04
Loss = 1.2671e-03, PNorm = 59.6559, GNorm = 0.8752, lr_0 = 6.6774e-04
Validation rmse logD = 0.602097
Validation R2 logD = 0.756647
Epoch 19
Train function
Loss = 1.0062e-03, PNorm = 59.6976, GNorm = 1.2601, lr_0 = 6.6449e-04
Loss = 1.1919e-03, PNorm = 59.7289, GNorm = 0.6093, lr_0 = 6.6155e-04
Loss = 1.1275e-03, PNorm = 59.7696, GNorm = 0.9025, lr_0 = 6.5862e-04
Loss = 9.8950e-04, PNorm = 59.8051, GNorm = 1.3771, lr_0 = 6.5571e-04
Loss = 1.3266e-03, PNorm = 59.8390, GNorm = 2.2011, lr_0 = 6.5281e-04
Loss = 1.0057e-03, PNorm = 59.8750, GNorm = 1.0155, lr_0 = 6.4992e-04
Validation rmse logD = 0.591301
Validation R2 logD = 0.765295
Epoch 20
Train function
Loss = 8.2848e-04, PNorm = 59.9144, GNorm = 0.8458, lr_0 = 6.4676e-04
Loss = 1.1274e-03, PNorm = 59.9497, GNorm = 1.3908, lr_0 = 6.4390e-04
Loss = 9.2136e-04, PNorm = 59.9821, GNorm = 1.0941, lr_0 = 6.4105e-04
Loss = 7.8147e-04, PNorm = 60.0105, GNorm = 0.4710, lr_0 = 6.3822e-04
Loss = 1.0227e-03, PNorm = 60.0396, GNorm = 0.4707, lr_0 = 6.3539e-04
Validation rmse logD = 0.581048
Validation R2 logD = 0.773364
Epoch 21
Train function
Loss = 6.9601e-04, PNorm = 60.0697, GNorm = 1.3246, lr_0 = 6.3230e-04
Loss = 8.0491e-04, PNorm = 60.0931, GNorm = 0.6104, lr_0 = 6.2950e-04
Loss = 7.5407e-04, PNorm = 60.1205, GNorm = 0.7953, lr_0 = 6.2672e-04
Loss = 9.8843e-04, PNorm = 60.1499, GNorm = 0.5588, lr_0 = 6.2395e-04
Loss = 8.7733e-04, PNorm = 60.1915, GNorm = 0.3984, lr_0 = 6.2119e-04
Validation rmse logD = 0.588839
Validation R2 logD = 0.767245
Epoch 22
Train function
Loss = 7.3324e-04, PNorm = 60.2197, GNorm = 1.1223, lr_0 = 6.1817e-04
Loss = 8.8597e-04, PNorm = 60.2485, GNorm = 0.4660, lr_0 = 6.1543e-04
Loss = 1.0262e-03, PNorm = 60.2773, GNorm = 1.2930, lr_0 = 6.1271e-04
Loss = 8.2391e-04, PNorm = 60.3136, GNorm = 0.8836, lr_0 = 6.1000e-04
Loss = 8.9562e-04, PNorm = 60.3420, GNorm = 0.9256, lr_0 = 6.0730e-04
Loss = 7.2072e-04, PNorm = 60.3697, GNorm = 0.7439, lr_0 = 6.0461e-04
Validation rmse logD = 0.598355
Validation R2 logD = 0.759661
Epoch 23
Train function
Loss = 8.8661e-04, PNorm = 60.3931, GNorm = 1.2280, lr_0 = 6.0167e-04
Loss = 8.7753e-04, PNorm = 60.4288, GNorm = 1.1487, lr_0 = 5.9901e-04
Loss = 6.4989e-04, PNorm = 60.4631, GNorm = 0.6917, lr_0 = 5.9636e-04
Loss = 5.8346e-04, PNorm = 60.4938, GNorm = 0.8766, lr_0 = 5.9372e-04
Loss = 8.6851e-04, PNorm = 60.5232, GNorm = 0.5341, lr_0 = 5.9110e-04
Validation rmse logD = 0.576920
Validation R2 logD = 0.776573
Epoch 24
Train function
Loss = 7.6793e-04, PNorm = 60.5519, GNorm = 1.2325, lr_0 = 5.8822e-04
Loss = 7.2050e-04, PNorm = 60.5768, GNorm = 0.2945, lr_0 = 5.8562e-04
Loss = 6.0146e-04, PNorm = 60.6035, GNorm = 0.7456, lr_0 = 5.8303e-04
Loss = 7.3495e-04, PNorm = 60.6270, GNorm = 0.8548, lr_0 = 5.8045e-04
Loss = 7.0712e-04, PNorm = 60.6498, GNorm = 1.1468, lr_0 = 5.7788e-04
Validation rmse logD = 0.576590
Validation R2 logD = 0.776828
Epoch 25
Train function
Loss = 4.0895e-04, PNorm = 60.6763, GNorm = 0.8580, lr_0 = 5.7533e-04
Loss = 6.3114e-04, PNorm = 60.7047, GNorm = 0.7356, lr_0 = 5.7278e-04
Loss = 5.0799e-04, PNorm = 60.7220, GNorm = 0.3811, lr_0 = 5.7025e-04
Loss = 5.0064e-04, PNorm = 60.7523, GNorm = 0.3370, lr_0 = 5.6773e-04
Loss = 5.6651e-04, PNorm = 60.7691, GNorm = 1.3081, lr_0 = 5.6522e-04
Loss = 6.4728e-04, PNorm = 60.7870, GNorm = 0.9498, lr_0 = 5.6272e-04
Validation rmse logD = 0.580121
Validation R2 logD = 0.774087
Epoch 26
Train function
Loss = 5.0390e-04, PNorm = 60.8138, GNorm = 0.4001, lr_0 = 5.5998e-04
Loss = 5.6905e-04, PNorm = 60.8315, GNorm = 0.6356, lr_0 = 5.5750e-04
Loss = 5.9868e-04, PNorm = 60.8515, GNorm = 0.8077, lr_0 = 5.5503e-04
Loss = 5.5955e-04, PNorm = 60.8660, GNorm = 1.7016, lr_0 = 5.5258e-04
Loss = 6.7924e-04, PNorm = 60.8939, GNorm = 0.3656, lr_0 = 5.5014e-04
Validation rmse logD = 0.575131
Validation R2 logD = 0.777957
Epoch 27
Train function
Loss = 3.6302e-04, PNorm = 60.9256, GNorm = 0.3115, lr_0 = 5.4746e-04
Loss = 6.2009e-04, PNorm = 60.9449, GNorm = 0.5268, lr_0 = 5.4504e-04
Loss = 4.7207e-04, PNorm = 60.9622, GNorm = 0.4286, lr_0 = 5.4263e-04
Loss = 4.1199e-04, PNorm = 60.9845, GNorm = 0.6315, lr_0 = 5.4023e-04
Loss = 4.5030e-04, PNorm = 61.0009, GNorm = 0.4145, lr_0 = 5.3784e-04
Validation rmse logD = 0.583786
Validation R2 logD = 0.771223
Epoch 28
Train function
Loss = 5.9505e-04, PNorm = 61.0241, GNorm = 0.4733, lr_0 = 5.3522e-04
Loss = 5.1917e-04, PNorm = 61.0486, GNorm = 0.8362, lr_0 = 5.3285e-04
Loss = 6.2156e-04, PNorm = 61.0683, GNorm = 0.5331, lr_0 = 5.3050e-04
Loss = 5.0185e-04, PNorm = 61.0962, GNorm = 0.8372, lr_0 = 5.2815e-04
Loss = 6.1567e-04, PNorm = 61.1143, GNorm = 0.5051, lr_0 = 5.2581e-04
Loss = 5.9322e-04, PNorm = 61.1399, GNorm = 1.0975, lr_0 = 5.2349e-04
Loss = 2.1322e-03, PNorm = 61.1419, GNorm = 0.9440, lr_0 = 5.2326e-04
Validation rmse logD = 0.591140
Validation R2 logD = 0.765423
Epoch 29
Train function
Loss = 4.0284e-04, PNorm = 61.1619, GNorm = 0.8916, lr_0 = 5.2094e-04
Loss = 5.3431e-04, PNorm = 61.1886, GNorm = 0.6631, lr_0 = 5.1864e-04
Loss = 3.5696e-04, PNorm = 61.2123, GNorm = 0.3661, lr_0 = 5.1634e-04
Loss = 4.9843e-04, PNorm = 61.2275, GNorm = 1.2732, lr_0 = 5.1406e-04
Loss = 4.8176e-04, PNorm = 61.2441, GNorm = 0.7709, lr_0 = 5.1178e-04
Validation rmse logD = 0.616408
Validation R2 logD = 0.744941
Epoch 30
Train function
Loss = 6.2868e-04, PNorm = 61.2632, GNorm = 1.0733, lr_0 = 5.0930e-04
Loss = 5.2104e-04, PNorm = 61.2940, GNorm = 0.6593, lr_0 = 5.0704e-04
Loss = 4.5940e-04, PNorm = 61.3144, GNorm = 0.3879, lr_0 = 5.0480e-04
Loss = 3.7659e-04, PNorm = 61.3343, GNorm = 0.5266, lr_0 = 5.0257e-04
Loss = 3.9789e-04, PNorm = 61.3491, GNorm = 0.9209, lr_0 = 5.0034e-04
Validation rmse logD = 0.583801
Validation R2 logD = 0.771211
Epoch 31
Train function
Loss = 4.0916e-04, PNorm = 61.3773, GNorm = 0.8646, lr_0 = 4.9791e-04
Loss = 4.1077e-04, PNorm = 61.3873, GNorm = 0.3661, lr_0 = 4.9571e-04
Loss = 4.3132e-04, PNorm = 61.4023, GNorm = 0.3421, lr_0 = 4.9351e-04
Loss = 3.7995e-04, PNorm = 61.4174, GNorm = 0.9486, lr_0 = 4.9133e-04
Loss = 3.9507e-04, PNorm = 61.4340, GNorm = 0.3711, lr_0 = 4.8916e-04
Validation rmse logD = 0.579377
Validation R2 logD = 0.774666
Epoch 32
Train function
Loss = 4.4675e-04, PNorm = 61.4530, GNorm = 1.0737, lr_0 = 4.8678e-04
Loss = 4.4566e-04, PNorm = 61.4744, GNorm = 1.0598, lr_0 = 4.8463e-04
Loss = 3.1878e-04, PNorm = 61.4892, GNorm = 0.4529, lr_0 = 4.8248e-04
Loss = 3.9797e-04, PNorm = 61.5054, GNorm = 0.6084, lr_0 = 4.8035e-04
Loss = 2.9818e-04, PNorm = 61.5254, GNorm = 0.4066, lr_0 = 4.7822e-04
Loss = 2.9165e-04, PNorm = 61.5411, GNorm = 0.4414, lr_0 = 4.7611e-04
Validation rmse logD = 0.587891
Validation R2 logD = 0.767995
Epoch 33
Train function
Loss = 3.6358e-04, PNorm = 61.5481, GNorm = 0.2913, lr_0 = 4.7379e-04
Loss = 3.4425e-04, PNorm = 61.5607, GNorm = 0.3946, lr_0 = 4.7170e-04
Loss = 2.8292e-04, PNorm = 61.5750, GNorm = 1.0400, lr_0 = 4.6961e-04
Loss = 3.1354e-04, PNorm = 61.5904, GNorm = 0.5543, lr_0 = 4.6753e-04
Loss = 3.0898e-04, PNorm = 61.6041, GNorm = 0.4045, lr_0 = 4.6546e-04
Validation rmse logD = 0.582991
Validation R2 logD = 0.771845
Epoch 34
Train function
Loss = 2.5952e-04, PNorm = 61.6178, GNorm = 0.3011, lr_0 = 4.6341e-04
Loss = 2.3179e-04, PNorm = 61.6313, GNorm = 0.5645, lr_0 = 4.6136e-04
Loss = 2.1920e-04, PNorm = 61.6408, GNorm = 0.4669, lr_0 = 4.5931e-04
Loss = 2.6328e-04, PNorm = 61.6456, GNorm = 0.5254, lr_0 = 4.5728e-04
Loss = 2.8403e-04, PNorm = 61.6585, GNorm = 0.4131, lr_0 = 4.5526e-04
Validation rmse logD = 0.580134
Validation R2 logD = 0.774076
Epoch 35
Train function
Loss = 1.0280e-04, PNorm = 61.6753, GNorm = 0.1971, lr_0 = 4.5305e-04
Loss = 2.1537e-04, PNorm = 61.6882, GNorm = 0.5155, lr_0 = 4.5104e-04
Loss = 2.3491e-04, PNorm = 61.6959, GNorm = 0.3634, lr_0 = 4.4905e-04
Loss = 2.1888e-04, PNorm = 61.7079, GNorm = 0.6434, lr_0 = 4.4706e-04
Loss = 2.5360e-04, PNorm = 61.7227, GNorm = 0.4309, lr_0 = 4.4508e-04
Loss = 2.9100e-04, PNorm = 61.7325, GNorm = 0.5962, lr_0 = 4.4311e-04
Validation rmse logD = 0.580795
Validation R2 logD = 0.773561
Epoch 36
Train function
Loss = 2.6661e-04, PNorm = 61.7479, GNorm = 0.6822, lr_0 = 4.4096e-04
Loss = 2.7990e-04, PNorm = 61.7649, GNorm = 0.4866, lr_0 = 4.3901e-04
Loss = 2.2155e-04, PNorm = 61.7786, GNorm = 0.3104, lr_0 = 4.3707e-04
Loss = 2.3183e-04, PNorm = 61.7885, GNorm = 0.1925, lr_0 = 4.3513e-04
Loss = 2.2438e-04, PNorm = 61.7961, GNorm = 0.7297, lr_0 = 4.3321e-04
Validation rmse logD = 0.576644
Validation R2 logD = 0.776786
Epoch 37
Train function
Loss = 2.8705e-04, PNorm = 61.8090, GNorm = 1.1227, lr_0 = 4.3110e-04
Loss = 2.5757e-04, PNorm = 61.8229, GNorm = 0.4377, lr_0 = 4.2919e-04
Loss = 2.6932e-04, PNorm = 61.8307, GNorm = 0.3783, lr_0 = 4.2729e-04
Loss = 2.5169e-04, PNorm = 61.8468, GNorm = 0.3965, lr_0 = 4.2540e-04
Loss = 2.2363e-04, PNorm = 61.8584, GNorm = 0.3326, lr_0 = 4.2352e-04
Validation rmse logD = 0.583474
Validation R2 logD = 0.771468
Epoch 38
Train function
Loss = 1.6889e-04, PNorm = 61.8683, GNorm = 0.2504, lr_0 = 4.2146e-04
Loss = 1.4782e-04, PNorm = 61.8757, GNorm = 0.2475, lr_0 = 4.1960e-04
Loss = 1.8269e-04, PNorm = 61.8834, GNorm = 0.4737, lr_0 = 4.1774e-04
Loss = 1.8783e-04, PNorm = 61.8916, GNorm = 0.3090, lr_0 = 4.1589e-04
Loss = 1.8975e-04, PNorm = 61.9027, GNorm = 0.8349, lr_0 = 4.1406e-04
Loss = 2.6605e-04, PNorm = 61.9138, GNorm = 1.1585, lr_0 = 4.1222e-04
Validation rmse logD = 0.585383
Validation R2 logD = 0.769970
Epoch 39
Train function
Loss = 2.6075e-04, PNorm = 61.9316, GNorm = 0.3021, lr_0 = 4.1022e-04
Loss = 1.6560e-04, PNorm = 61.9423, GNorm = 0.3868, lr_0 = 4.0840e-04
Loss = 1.6680e-04, PNorm = 61.9537, GNorm = 0.2362, lr_0 = 4.0660e-04
Loss = 1.4541e-04, PNorm = 61.9631, GNorm = 0.2065, lr_0 = 4.0480e-04
Loss = 1.9124e-04, PNorm = 61.9703, GNorm = 0.8008, lr_0 = 4.0301e-04
Validation rmse logD = 0.585227
Validation R2 logD = 0.770092
Epoch 40
Train function
Loss = 2.1047e-04, PNorm = 61.9850, GNorm = 0.4538, lr_0 = 4.0105e-04
Loss = 1.6102e-04, PNorm = 61.9947, GNorm = 0.2311, lr_0 = 3.9927e-04
Loss = 1.8067e-04, PNorm = 62.0040, GNorm = 0.5252, lr_0 = 3.9751e-04
Loss = 2.0879e-04, PNorm = 62.0102, GNorm = 0.3569, lr_0 = 3.9575e-04
Loss = 1.7354e-04, PNorm = 62.0227, GNorm = 0.1995, lr_0 = 3.9400e-04
Validation rmse logD = 0.583808
Validation R2 logD = 0.771206
Epoch 41
Train function
Loss = 1.1025e-04, PNorm = 62.0291, GNorm = 0.2041, lr_0 = 3.9208e-04
Loss = 1.3646e-04, PNorm = 62.0357, GNorm = 0.2612, lr_0 = 3.9035e-04
Loss = 1.4201e-04, PNorm = 62.0483, GNorm = 0.2706, lr_0 = 3.8862e-04
Loss = 1.4931e-04, PNorm = 62.0578, GNorm = 0.2569, lr_0 = 3.8690e-04
Loss = 1.3667e-04, PNorm = 62.0636, GNorm = 0.2498, lr_0 = 3.8519e-04
Loss = 1.3752e-04, PNorm = 62.0705, GNorm = 0.2184, lr_0 = 3.8349e-04
Validation rmse logD = 0.578102
Validation R2 logD = 0.775657
Epoch 42
Train function
Loss = 1.2015e-04, PNorm = 62.0778, GNorm = 0.1697, lr_0 = 3.8179e-04
Loss = 1.2621e-04, PNorm = 62.0892, GNorm = 0.5921, lr_0 = 3.8010e-04
Loss = 1.1411e-04, PNorm = 62.0957, GNorm = 0.1683, lr_0 = 3.7842e-04
Loss = 1.3224e-04, PNorm = 62.1031, GNorm = 0.2568, lr_0 = 3.7675e-04
Loss = 1.0668e-04, PNorm = 62.1093, GNorm = 0.2989, lr_0 = 3.7508e-04
Validation rmse logD = 0.577327
Validation R2 logD = 0.776257
Epoch 43
Train function
Loss = 1.5809e-04, PNorm = 62.1178, GNorm = 0.6858, lr_0 = 3.7326e-04
Loss = 1.3323e-04, PNorm = 62.1293, GNorm = 0.6243, lr_0 = 3.7160e-04
Loss = 1.4164e-04, PNorm = 62.1381, GNorm = 0.3251, lr_0 = 3.6996e-04
Loss = 1.6541e-04, PNorm = 62.1493, GNorm = 0.3344, lr_0 = 3.6832e-04
Loss = 1.1790e-04, PNorm = 62.1584, GNorm = 0.2440, lr_0 = 3.6669e-04
Validation rmse logD = 0.581174
Validation R2 logD = 0.773266
Epoch 44
Train function
Loss = 8.8752e-05, PNorm = 62.1659, GNorm = 0.2121, lr_0 = 3.6491e-04
Loss = 1.3841e-04, PNorm = 62.1755, GNorm = 0.2815, lr_0 = 3.6330e-04
Loss = 1.3309e-04, PNorm = 62.1836, GNorm = 0.4150, lr_0 = 3.6169e-04
Loss = 1.1913e-04, PNorm = 62.1910, GNorm = 0.2299, lr_0 = 3.6009e-04
Loss = 1.3708e-04, PNorm = 62.1976, GNorm = 0.3580, lr_0 = 3.5850e-04
Loss = 1.7339e-04, PNorm = 62.2048, GNorm = 0.4935, lr_0 = 3.5691e-04
Loss = 1.6591e-03, PNorm = 62.2060, GNorm = 0.8453, lr_0 = 3.5675e-04
Validation rmse logD = 0.580782
Validation R2 logD = 0.773572
Epoch 45
Train function
Loss = 1.0861e-04, PNorm = 62.2133, GNorm = 0.3066, lr_0 = 3.5518e-04
Loss = 1.3745e-04, PNorm = 62.2194, GNorm = 0.2984, lr_0 = 3.5360e-04
Loss = 1.2794e-04, PNorm = 62.2278, GNorm = 0.2369, lr_0 = 3.5204e-04
Loss = 1.0473e-04, PNorm = 62.2403, GNorm = 0.2000, lr_0 = 3.5048e-04
Loss = 1.0322e-04, PNorm = 62.2465, GNorm = 0.3983, lr_0 = 3.4893e-04
Validation rmse logD = 0.583856
Validation R2 logD = 0.771168
Epoch 46
Train function
Loss = 1.7343e-04, PNorm = 62.2555, GNorm = 0.4096, lr_0 = 3.4724e-04
Loss = 1.5490e-04, PNorm = 62.2634, GNorm = 0.8794, lr_0 = 3.4570e-04
Loss = 1.4928e-04, PNorm = 62.2719, GNorm = 1.0175, lr_0 = 3.4417e-04
Loss = 1.2848e-04, PNorm = 62.2842, GNorm = 0.5445, lr_0 = 3.4265e-04
Loss = 1.6409e-04, PNorm = 62.2918, GNorm = 0.5578, lr_0 = 3.4113e-04
Validation rmse logD = 0.575338
Validation R2 logD = 0.777796
Epoch 47
Train function
Loss = 1.0346e-04, PNorm = 62.3036, GNorm = 0.4716, lr_0 = 3.3947e-04
Loss = 1.0881e-04, PNorm = 62.3118, GNorm = 0.1933, lr_0 = 3.3797e-04
Loss = 1.1590e-04, PNorm = 62.3163, GNorm = 0.3497, lr_0 = 3.3648e-04
Loss = 8.8941e-05, PNorm = 62.3236, GNorm = 0.2607, lr_0 = 3.3499e-04
Loss = 1.4162e-04, PNorm = 62.3301, GNorm = 0.3069, lr_0 = 3.3351e-04
Validation rmse logD = 0.583731
Validation R2 logD = 0.771266
Epoch 48
Train function
Loss = 1.3706e-04, PNorm = 62.3366, GNorm = 0.7666, lr_0 = 3.3188e-04
Loss = 1.2791e-04, PNorm = 62.3459, GNorm = 0.3529, lr_0 = 3.3042e-04
Loss = 1.0855e-04, PNorm = 62.3539, GNorm = 0.2593, lr_0 = 3.2895e-04
Loss = 8.9358e-05, PNorm = 62.3578, GNorm = 0.3794, lr_0 = 3.2750e-04
Loss = 9.2278e-05, PNorm = 62.3614, GNorm = 0.1280, lr_0 = 3.2605e-04
Loss = 1.1285e-04, PNorm = 62.3657, GNorm = 0.2511, lr_0 = 3.2461e-04
Validation rmse logD = 0.579249
Validation R2 logD = 0.774765
Epoch 49
Train function
Loss = 9.5225e-05, PNorm = 62.3767, GNorm = 0.2587, lr_0 = 3.2303e-04
Loss = 1.1687e-04, PNorm = 62.3823, GNorm = 0.3254, lr_0 = 3.2160e-04
Loss = 1.0153e-04, PNorm = 62.3869, GNorm = 0.1949, lr_0 = 3.2018e-04
Loss = 9.3035e-05, PNorm = 62.3902, GNorm = 0.4204, lr_0 = 3.1876e-04
Loss = 9.7800e-05, PNorm = 62.3979, GNorm = 0.1888, lr_0 = 3.1735e-04
Validation rmse logD = 0.581772
Validation R2 logD = 0.772799
Epoch 50
Train function
Loss = 7.8654e-05, PNorm = 62.4074, GNorm = 0.1254, lr_0 = 3.1595e-04
Loss = 1.0371e-04, PNorm = 62.4140, GNorm = 0.2811, lr_0 = 3.1455e-04
Loss = 9.8376e-05, PNorm = 62.4212, GNorm = 0.6242, lr_0 = 3.1316e-04
Loss = 9.9873e-05, PNorm = 62.4288, GNorm = 0.1397, lr_0 = 3.1177e-04
Loss = 7.6808e-05, PNorm = 62.4346, GNorm = 0.2022, lr_0 = 3.1039e-04
Validation rmse logD = 0.579398
Validation R2 logD = 0.774649
Epoch 51
Train function
Loss = 5.1634e-05, PNorm = 62.4386, GNorm = 0.1437, lr_0 = 3.0888e-04
Loss = 7.6864e-05, PNorm = 62.4454, GNorm = 0.1887, lr_0 = 3.0752e-04
Loss = 7.6353e-05, PNorm = 62.4501, GNorm = 0.1551, lr_0 = 3.0616e-04
Loss = 6.9683e-05, PNorm = 62.4548, GNorm = 0.1696, lr_0 = 3.0480e-04
Loss = 6.7258e-05, PNorm = 62.4598, GNorm = 0.4447, lr_0 = 3.0346e-04
Loss = 6.6879e-05, PNorm = 62.4635, GNorm = 0.2930, lr_0 = 3.0211e-04
Validation rmse logD = 0.584478
Validation R2 logD = 0.770681
Epoch 52
Train function
Loss = 7.0713e-05, PNorm = 62.4701, GNorm = 0.4266, lr_0 = 3.0064e-04
Loss = 7.9987e-05, PNorm = 62.4770, GNorm = 0.2893, lr_0 = 2.9931e-04
Loss = 9.5909e-05, PNorm = 62.4826, GNorm = 0.4368, lr_0 = 2.9799e-04
Loss = 9.0527e-05, PNorm = 62.4860, GNorm = 0.1924, lr_0 = 2.9667e-04
Loss = 8.0244e-05, PNorm = 62.4917, GNorm = 0.6863, lr_0 = 2.9536e-04
Validation rmse logD = 0.578016
Validation R2 logD = 0.775723
Epoch 53
Train function
Loss = 9.5561e-05, PNorm = 62.4962, GNorm = 0.7087, lr_0 = 2.9392e-04
Loss = 1.0203e-04, PNorm = 62.5041, GNorm = 0.7389, lr_0 = 2.9262e-04
Loss = 8.7249e-05, PNorm = 62.5100, GNorm = 0.2317, lr_0 = 2.9133e-04
Loss = 6.7431e-05, PNorm = 62.5163, GNorm = 0.1793, lr_0 = 2.9004e-04
Loss = 8.3537e-05, PNorm = 62.5204, GNorm = 0.1768, lr_0 = 2.8876e-04
Validation rmse logD = 0.580373
Validation R2 logD = 0.773890
Epoch 54
Train function
Loss = 3.8802e-05, PNorm = 62.5243, GNorm = 0.1208, lr_0 = 2.8735e-04
Loss = 8.5740e-05, PNorm = 62.5301, GNorm = 0.2887, lr_0 = 2.8608e-04
Loss = 8.1231e-05, PNorm = 62.5322, GNorm = 0.1779, lr_0 = 2.8482e-04
Loss = 7.2096e-05, PNorm = 62.5407, GNorm = 0.2486, lr_0 = 2.8356e-04
Loss = 8.0158e-05, PNorm = 62.5445, GNorm = 0.3522, lr_0 = 2.8230e-04
Loss = 5.8312e-05, PNorm = 62.5516, GNorm = 0.1445, lr_0 = 2.8105e-04
Validation rmse logD = 0.581975
Validation R2 logD = 0.772640
Epoch 55
Train function
Loss = 5.0031e-05, PNorm = 62.5545, GNorm = 0.1521, lr_0 = 2.7969e-04
Loss = 5.3985e-05, PNorm = 62.5574, GNorm = 0.2119, lr_0 = 2.7845e-04
Loss = 5.2409e-05, PNorm = 62.5613, GNorm = 0.3871, lr_0 = 2.7722e-04
Loss = 6.8363e-05, PNorm = 62.5644, GNorm = 0.3769, lr_0 = 2.7599e-04
Loss = 5.5052e-05, PNorm = 62.5674, GNorm = 0.2891, lr_0 = 2.7477e-04
Validation rmse logD = 0.579790
Validation R2 logD = 0.774344
Epoch 56
Train function
Loss = 4.7486e-05, PNorm = 62.5697, GNorm = 0.4176, lr_0 = 2.7343e-04
Loss = 6.4304e-05, PNorm = 62.5760, GNorm = 0.1718, lr_0 = 2.7222e-04
Loss = 5.8777e-05, PNorm = 62.5796, GNorm = 0.3093, lr_0 = 2.7102e-04
Loss = 6.0702e-05, PNorm = 62.5840, GNorm = 0.6314, lr_0 = 2.6982e-04
Loss = 7.1049e-05, PNorm = 62.5889, GNorm = 0.2451, lr_0 = 2.6863e-04
Validation rmse logD = 0.584123
Validation R2 logD = 0.770959
Epoch 57
Train function
Loss = 8.2866e-05, PNorm = 62.5962, GNorm = 0.7945, lr_0 = 2.6732e-04
Loss = 7.3727e-05, PNorm = 62.6022, GNorm = 0.1586, lr_0 = 2.6614e-04
Loss = 5.6409e-05, PNorm = 62.6072, GNorm = 0.1790, lr_0 = 2.6496e-04
Loss = 5.4102e-05, PNorm = 62.6112, GNorm = 0.2159, lr_0 = 2.6379e-04
Loss = 5.5635e-05, PNorm = 62.6164, GNorm = 0.4818, lr_0 = 2.6262e-04
Loss = 6.5146e-05, PNorm = 62.6170, GNorm = 0.3841, lr_0 = 2.6146e-04
Loss = 3.4733e-04, PNorm = 62.6170, GNorm = 0.4183, lr_0 = 2.6134e-04
Validation rmse logD = 0.587199
Validation R2 logD = 0.768540
Epoch 58
Train function
Loss = 8.0008e-05, PNorm = 62.6219, GNorm = 0.2296, lr_0 = 2.6019e-04
Loss = 6.2170e-05, PNorm = 62.6270, GNorm = 0.4658, lr_0 = 2.5904e-04
Loss = 5.3030e-05, PNorm = 62.6328, GNorm = 0.3977, lr_0 = 2.5789e-04
Loss = 5.5457e-05, PNorm = 62.6358, GNorm = 0.1721, lr_0 = 2.5675e-04
Loss = 4.9151e-05, PNorm = 62.6385, GNorm = 0.2340, lr_0 = 2.5561e-04
Validation rmse logD = 0.580203
Validation R2 logD = 0.774022
Epoch 59
Train function
Loss = 6.0330e-05, PNorm = 62.6415, GNorm = 0.3231, lr_0 = 2.5448e-04
Loss = 6.1071e-05, PNorm = 62.6449, GNorm = 0.2234, lr_0 = 2.5336e-04
Loss = 3.9620e-05, PNorm = 62.6500, GNorm = 0.1953, lr_0 = 2.5224e-04
Loss = 4.6329e-05, PNorm = 62.6521, GNorm = 0.1552, lr_0 = 2.5112e-04
Loss = 4.5246e-05, PNorm = 62.6561, GNorm = 0.2057, lr_0 = 2.5001e-04
Validation rmse logD = 0.581201
Validation R2 logD = 0.773245
Epoch 60
Train function
Loss = 3.6192e-05, PNorm = 62.6591, GNorm = 0.1601, lr_0 = 2.4879e-04
Loss = 3.4803e-05, PNorm = 62.6623, GNorm = 0.1585, lr_0 = 2.4769e-04
Loss = 3.8287e-05, PNorm = 62.6640, GNorm = 0.2590, lr_0 = 2.4660e-04
Loss = 4.5174e-05, PNorm = 62.6683, GNorm = 0.3831, lr_0 = 2.4551e-04
Loss = 3.9076e-05, PNorm = 62.6723, GNorm = 0.1486, lr_0 = 2.4442e-04
Loss = 4.0142e-05, PNorm = 62.6763, GNorm = 0.1470, lr_0 = 2.4334e-04
Loss = 1.8607e-04, PNorm = 62.6764, GNorm = 0.4213, lr_0 = 2.4323e-04
Validation rmse logD = 0.584078
Validation R2 logD = 0.770994
Epoch 61
Train function
Loss = 4.0049e-05, PNorm = 62.6781, GNorm = 0.3214, lr_0 = 2.4216e-04
Loss = 3.6728e-05, PNorm = 62.6824, GNorm = 0.1225, lr_0 = 2.4109e-04
Loss = 3.9838e-05, PNorm = 62.6844, GNorm = 0.0994, lr_0 = 2.4002e-04
Loss = 3.8538e-05, PNorm = 62.6849, GNorm = 0.4373, lr_0 = 2.3896e-04
Loss = 4.9194e-05, PNorm = 62.6876, GNorm = 0.1175, lr_0 = 2.3790e-04
Validation rmse logD = 0.581853
Validation R2 logD = 0.772736
Epoch 62
Train function
Loss = 3.7238e-05, PNorm = 62.6915, GNorm = 0.2908, lr_0 = 2.3674e-04
Loss = 4.8943e-05, PNorm = 62.6952, GNorm = 0.1818, lr_0 = 2.3570e-04
Loss = 4.2930e-05, PNorm = 62.6992, GNorm = 0.1365, lr_0 = 2.3465e-04
Loss = 4.0980e-05, PNorm = 62.7043, GNorm = 0.1099, lr_0 = 2.3362e-04
Loss = 3.2258e-05, PNorm = 62.7084, GNorm = 0.1152, lr_0 = 2.3258e-04
Validation rmse logD = 0.582143
Validation R2 logD = 0.772509
Epoch 63
Train function
Loss = 2.7139e-05, PNorm = 62.7109, GNorm = 0.2454, lr_0 = 2.3145e-04
Loss = 4.4061e-05, PNorm = 62.7113, GNorm = 0.1302, lr_0 = 2.3043e-04
Loss = 4.3602e-05, PNorm = 62.7121, GNorm = 0.3978, lr_0 = 2.2941e-04
Loss = 4.5861e-05, PNorm = 62.7171, GNorm = 0.1775, lr_0 = 2.2839e-04
Loss = 3.9965e-05, PNorm = 62.7184, GNorm = 0.3580, lr_0 = 2.2738e-04
Validation rmse logD = 0.582586
Validation R2 logD = 0.772162
Epoch 64
Train function
Loss = 1.7732e-05, PNorm = 62.7219, GNorm = 0.0972, lr_0 = 2.2628e-04
Loss = 4.0572e-05, PNorm = 62.7260, GNorm = 0.2189, lr_0 = 2.2528e-04
Loss = 6.5992e-05, PNorm = 62.7299, GNorm = 0.4687, lr_0 = 2.2428e-04
Loss = 5.1939e-05, PNorm = 62.7335, GNorm = 0.2046, lr_0 = 2.2329e-04
Loss = 5.4026e-05, PNorm = 62.7385, GNorm = 0.2411, lr_0 = 2.2230e-04
Loss = 4.8374e-05, PNorm = 62.7406, GNorm = 0.3275, lr_0 = 2.2132e-04
Validation rmse logD = 0.581202
Validation R2 logD = 0.773244
Epoch 65
Train function
Loss = 3.8801e-05, PNorm = 62.7446, GNorm = 0.2437, lr_0 = 2.2024e-04
Loss = 3.0733e-05, PNorm = 62.7479, GNorm = 0.1325, lr_0 = 2.1927e-04
Loss = 3.5061e-05, PNorm = 62.7501, GNorm = 0.1945, lr_0 = 2.1830e-04
Loss = 3.8090e-05, PNorm = 62.7525, GNorm = 0.2351, lr_0 = 2.1733e-04
Loss = 3.1081e-05, PNorm = 62.7552, GNorm = 0.1082, lr_0 = 2.1637e-04
Validation rmse logD = 0.583978
Validation R2 logD = 0.771073
Epoch 66
Train function
Loss = 3.0536e-05, PNorm = 62.7588, GNorm = 0.2678, lr_0 = 2.1532e-04
Loss = 2.7855e-05, PNorm = 62.7603, GNorm = 0.1283, lr_0 = 2.1436e-04
Loss = 3.1358e-05, PNorm = 62.7623, GNorm = 0.1469, lr_0 = 2.1342e-04
Loss = 2.5208e-05, PNorm = 62.7633, GNorm = 0.2908, lr_0 = 2.1247e-04
Loss = 2.6463e-05, PNorm = 62.7650, GNorm = 0.2324, lr_0 = 2.1153e-04
Validation rmse logD = 0.582696
Validation R2 logD = 0.772076
Epoch 67
Train function
Loss = 1.5180e-05, PNorm = 62.7671, GNorm = 0.1292, lr_0 = 2.1060e-04
Loss = 2.6382e-05, PNorm = 62.7686, GNorm = 0.1370, lr_0 = 2.0966e-04
Loss = 2.7637e-05, PNorm = 62.7692, GNorm = 0.1744, lr_0 = 2.0874e-04
Loss = 3.5149e-05, PNorm = 62.7726, GNorm = 0.3998, lr_0 = 2.0781e-04
Loss = 2.0129e-05, PNorm = 62.7760, GNorm = 0.0706, lr_0 = 2.0689e-04
Loss = 2.9921e-05, PNorm = 62.7779, GNorm = 0.3902, lr_0 = 2.0598e-04
Validation rmse logD = 0.583479
Validation R2 logD = 0.771463
Epoch 68
Train function
Loss = 3.4846e-05, PNorm = 62.7804, GNorm = 0.4017, lr_0 = 2.0498e-04
Loss = 4.4943e-05, PNorm = 62.7819, GNorm = 0.4149, lr_0 = 2.0407e-04
Loss = 2.8563e-05, PNorm = 62.7847, GNorm = 0.1354, lr_0 = 2.0317e-04
Loss = 2.8951e-05, PNorm = 62.7871, GNorm = 0.1197, lr_0 = 2.0227e-04
Loss = 3.6452e-05, PNorm = 62.7903, GNorm = 0.2576, lr_0 = 2.0137e-04
Validation rmse logD = 0.583035
Validation R2 logD = 0.771811
Epoch 69
Train function
Loss = 2.8308e-05, PNorm = 62.7926, GNorm = 0.3722, lr_0 = 2.0039e-04
Loss = 3.1608e-05, PNorm = 62.7949, GNorm = 0.3036, lr_0 = 1.9951e-04
Loss = 2.7836e-05, PNorm = 62.7968, GNorm = 0.3014, lr_0 = 1.9863e-04
Loss = 2.6052e-05, PNorm = 62.8001, GNorm = 0.1250, lr_0 = 1.9775e-04
Loss = 2.5236e-05, PNorm = 62.8033, GNorm = 0.1777, lr_0 = 1.9687e-04
Validation rmse logD = 0.583008
Validation R2 logD = 0.771832
Epoch 70
Train function
Loss = 1.8960e-05, PNorm = 62.8057, GNorm = 0.1737, lr_0 = 1.9592e-04
Loss = 1.6629e-05, PNorm = 62.8084, GNorm = 0.1467, lr_0 = 1.9505e-04
Loss = 2.3119e-05, PNorm = 62.8104, GNorm = 0.0630, lr_0 = 1.9419e-04
Loss = 2.0397e-05, PNorm = 62.8113, GNorm = 0.1452, lr_0 = 1.9333e-04
Loss = 2.4506e-05, PNorm = 62.8125, GNorm = 0.0899, lr_0 = 1.9247e-04
Loss = 1.7476e-05, PNorm = 62.8144, GNorm = 0.0737, lr_0 = 1.9162e-04
Validation rmse logD = 0.583354
Validation R2 logD = 0.771561
Epoch 71
Train function
Loss = 1.5094e-05, PNorm = 62.8158, GNorm = 0.0900, lr_0 = 1.9069e-04
Loss = 1.8217e-05, PNorm = 62.8187, GNorm = 0.0798, lr_0 = 1.8984e-04
Loss = 2.7813e-05, PNorm = 62.8216, GNorm = 0.1416, lr_0 = 1.8900e-04
Loss = 1.7047e-05, PNorm = 62.8238, GNorm = 0.2385, lr_0 = 1.8817e-04
Loss = 2.0839e-05, PNorm = 62.8268, GNorm = 0.0800, lr_0 = 1.8734e-04
Validation rmse logD = 0.582895
Validation R2 logD = 0.771921
Epoch 72
Train function
Loss = 2.0110e-05, PNorm = 62.8294, GNorm = 0.2173, lr_0 = 1.8643e-04
Loss = 2.1007e-05, PNorm = 62.8304, GNorm = 0.1836, lr_0 = 1.8560e-04
Loss = 2.5053e-05, PNorm = 62.8307, GNorm = 0.2856, lr_0 = 1.8478e-04
Loss = 2.1650e-05, PNorm = 62.8330, GNorm = 0.0878, lr_0 = 1.8396e-04
Loss = 2.1332e-05, PNorm = 62.8349, GNorm = 0.1660, lr_0 = 1.8315e-04
Validation rmse logD = 0.582092
Validation R2 logD = 0.772549
Epoch 73
Train function
Loss = 2.3536e-05, PNorm = 62.8356, GNorm = 0.0655, lr_0 = 1.8226e-04
Loss = 1.7593e-05, PNorm = 62.8382, GNorm = 0.1526, lr_0 = 1.8145e-04
Loss = 2.0016e-05, PNorm = 62.8399, GNorm = 0.0765, lr_0 = 1.8065e-04
Loss = 1.9864e-05, PNorm = 62.8422, GNorm = 0.0760, lr_0 = 1.7985e-04
Loss = 1.5554e-05, PNorm = 62.8440, GNorm = 0.2098, lr_0 = 1.7905e-04
Loss = 2.1374e-05, PNorm = 62.8457, GNorm = 0.0629, lr_0 = 1.7826e-04
Loss = 1.3683e-04, PNorm = 62.8460, GNorm = 0.2711, lr_0 = 1.7818e-04
Validation rmse logD = 0.583922
Validation R2 logD = 0.771116
Epoch 74
Train function
Loss = 2.2265e-05, PNorm = 62.8468, GNorm = 0.1278, lr_0 = 1.7739e-04
Loss = 1.5795e-05, PNorm = 62.8481, GNorm = 0.0805, lr_0 = 1.7661e-04
Loss = 2.1099e-05, PNorm = 62.8506, GNorm = 0.1139, lr_0 = 1.7583e-04
Loss = 1.3450e-05, PNorm = 62.8525, GNorm = 0.1598, lr_0 = 1.7505e-04
Loss = 1.4680e-05, PNorm = 62.8538, GNorm = 0.1357, lr_0 = 1.7428e-04
Validation rmse logD = 0.582332
Validation R2 logD = 0.772361
Epoch 75
Train function
Loss = 1.3461e-05, PNorm = 62.8550, GNorm = 0.0756, lr_0 = 1.7351e-04
Loss = 1.6323e-05, PNorm = 62.8571, GNorm = 0.0726, lr_0 = 1.7274e-04
Loss = 1.4467e-05, PNorm = 62.8586, GNorm = 0.0670, lr_0 = 1.7197e-04
Loss = 1.2670e-05, PNorm = 62.8611, GNorm = 0.0579, lr_0 = 1.7121e-04
Loss = 1.4343e-05, PNorm = 62.8623, GNorm = 0.1835, lr_0 = 1.7046e-04
Validation rmse logD = 0.583907
Validation R2 logD = 0.771128
Epoch 76
Train function
Loss = 2.3799e-05, PNorm = 62.8640, GNorm = 0.1119, lr_0 = 1.6963e-04
Loss = 1.6111e-05, PNorm = 62.8652, GNorm = 0.0768, lr_0 = 1.6888e-04
Loss = 1.6335e-05, PNorm = 62.8674, GNorm = 0.0875, lr_0 = 1.6813e-04
Loss = 1.4464e-05, PNorm = 62.8692, GNorm = 0.0579, lr_0 = 1.6739e-04
Loss = 1.4669e-05, PNorm = 62.8705, GNorm = 0.1203, lr_0 = 1.6665e-04
Loss = 1.0919e-05, PNorm = 62.8715, GNorm = 0.0572, lr_0 = 1.6591e-04
Loss = 7.9278e-05, PNorm = 62.8716, GNorm = 0.1969, lr_0 = 1.6584e-04
Validation rmse logD = 0.583970
Validation R2 logD = 0.771079
Epoch 77
Train function
Loss = 1.1880e-05, PNorm = 62.8726, GNorm = 0.0936, lr_0 = 1.6510e-04
Loss = 1.5100e-05, PNorm = 62.8741, GNorm = 0.1228, lr_0 = 1.6437e-04
Loss = 1.5270e-05, PNorm = 62.8758, GNorm = 0.0913, lr_0 = 1.6364e-04
Loss = 1.7071e-05, PNorm = 62.8781, GNorm = 0.1728, lr_0 = 1.6292e-04
Loss = 1.3583e-05, PNorm = 62.8803, GNorm = 0.0741, lr_0 = 1.6220e-04
Validation rmse logD = 0.584347
Validation R2 logD = 0.770783
Epoch 78
Train function
Loss = 1.6597e-05, PNorm = 62.8817, GNorm = 0.2169, lr_0 = 1.6141e-04
Loss = 1.8267e-05, PNorm = 62.8834, GNorm = 0.0772, lr_0 = 1.6070e-04
Loss = 1.2431e-05, PNorm = 62.8850, GNorm = 0.1134, lr_0 = 1.5999e-04
Loss = 1.1510e-05, PNorm = 62.8858, GNorm = 0.1891, lr_0 = 1.5928e-04
Loss = 2.0088e-05, PNorm = 62.8868, GNorm = 0.0731, lr_0 = 1.5857e-04
Validation rmse logD = 0.583430
Validation R2 logD = 0.771502
Epoch 79
Train function
Loss = 1.6087e-05, PNorm = 62.8891, GNorm = 0.1390, lr_0 = 1.5780e-04
Loss = 1.8074e-05, PNorm = 62.8902, GNorm = 0.1177, lr_0 = 1.5710e-04
Loss = 2.1923e-05, PNorm = 62.8927, GNorm = 0.1917, lr_0 = 1.5641e-04
Loss = 1.8175e-05, PNorm = 62.8938, GNorm = 0.1013, lr_0 = 1.5572e-04
Loss = 1.6046e-05, PNorm = 62.8955, GNorm = 0.1577, lr_0 = 1.5503e-04
Validation rmse logD = 0.584637
Validation R2 logD = 0.770556
Epoch 80
Train function
Loss = 1.5802e-05, PNorm = 62.8966, GNorm = 0.1532, lr_0 = 1.5427e-04
Loss = 1.3331e-05, PNorm = 62.8984, GNorm = 0.1476, lr_0 = 1.5359e-04
Loss = 1.7736e-05, PNorm = 62.8993, GNorm = 0.1535, lr_0 = 1.5291e-04
Loss = 1.6746e-05, PNorm = 62.9001, GNorm = 0.0827, lr_0 = 1.5224e-04
Loss = 1.6563e-05, PNorm = 62.9013, GNorm = 0.0797, lr_0 = 1.5156e-04
Loss = 1.3409e-05, PNorm = 62.9030, GNorm = 0.0969, lr_0 = 1.5089e-04
Validation rmse logD = 0.583174
Validation R2 logD = 0.771702
Epoch 81
Train function
Loss = 1.2272e-05, PNorm = 62.9053, GNorm = 0.0749, lr_0 = 1.5016e-04
Loss = 1.2486e-05, PNorm = 62.9065, GNorm = 0.0939, lr_0 = 1.4949e-04
Loss = 1.4201e-05, PNorm = 62.9078, GNorm = 0.1288, lr_0 = 1.4883e-04
Loss = 1.2917e-05, PNorm = 62.9085, GNorm = 0.0623, lr_0 = 1.4817e-04
Loss = 1.6384e-05, PNorm = 62.9091, GNorm = 0.1359, lr_0 = 1.4752e-04
Validation rmse logD = 0.584582
Validation R2 logD = 0.770599
Epoch 82
Train function
Loss = 1.7743e-05, PNorm = 62.9103, GNorm = 0.2486, lr_0 = 1.4680e-04
Loss = 1.3711e-05, PNorm = 62.9115, GNorm = 0.1355, lr_0 = 1.4615e-04
Loss = 1.4598e-05, PNorm = 62.9125, GNorm = 0.3376, lr_0 = 1.4551e-04
Loss = 1.5855e-05, PNorm = 62.9137, GNorm = 0.0961, lr_0 = 1.4486e-04
Loss = 1.5343e-05, PNorm = 62.9158, GNorm = 0.0732, lr_0 = 1.4422e-04
Validation rmse logD = 0.585228
Validation R2 logD = 0.770091
Epoch 83
Train function
Loss = 3.0202e-05, PNorm = 62.9171, GNorm = 0.3590, lr_0 = 1.4352e-04
Loss = 1.9095e-05, PNorm = 62.9185, GNorm = 0.0803, lr_0 = 1.4288e-04
Loss = 1.2901e-05, PNorm = 62.9191, GNorm = 0.0789, lr_0 = 1.4225e-04
Loss = 1.4900e-05, PNorm = 62.9212, GNorm = 0.1254, lr_0 = 1.4162e-04
Loss = 1.2603e-05, PNorm = 62.9222, GNorm = 0.0785, lr_0 = 1.4100e-04
Loss = 1.6631e-05, PNorm = 62.9233, GNorm = 0.2573, lr_0 = 1.4037e-04
Validation rmse logD = 0.585658
Validation R2 logD = 0.769754
Epoch 84
Train function
Loss = 1.6338e-05, PNorm = 62.9251, GNorm = 0.2102, lr_0 = 1.3975e-04
Loss = 1.4350e-05, PNorm = 62.9269, GNorm = 0.1229, lr_0 = 1.3913e-04
Loss = 1.4428e-05, PNorm = 62.9277, GNorm = 0.0961, lr_0 = 1.3852e-04
Loss = 1.1136e-05, PNorm = 62.9288, GNorm = 0.1155, lr_0 = 1.3791e-04
Loss = 1.2016e-05, PNorm = 62.9297, GNorm = 0.1656, lr_0 = 1.3730e-04
Validation rmse logD = 0.584634
Validation R2 logD = 0.770558
Epoch 85
Train function
Loss = 8.9967e-06, PNorm = 62.9306, GNorm = 0.0597, lr_0 = 1.3663e-04
Loss = 1.0458e-05, PNorm = 62.9315, GNorm = 0.1517, lr_0 = 1.3602e-04
Loss = 1.2239e-05, PNorm = 62.9329, GNorm = 0.1013, lr_0 = 1.3542e-04
Loss = 1.5114e-05, PNorm = 62.9327, GNorm = 0.2313, lr_0 = 1.3482e-04
Loss = 1.1340e-05, PNorm = 62.9335, GNorm = 0.1097, lr_0 = 1.3423e-04
Validation rmse logD = 0.585064
Validation R2 logD = 0.770220
Epoch 86
Train function
Loss = 7.0060e-06, PNorm = 62.9363, GNorm = 0.1207, lr_0 = 1.3357e-04
Loss = 1.1513e-05, PNorm = 62.9371, GNorm = 0.0546, lr_0 = 1.3298e-04
Loss = 9.8152e-06, PNorm = 62.9374, GNorm = 0.0660, lr_0 = 1.3239e-04
Loss = 9.1497e-06, PNorm = 62.9383, GNorm = 0.1035, lr_0 = 1.3181e-04
Loss = 7.6856e-06, PNorm = 62.9395, GNorm = 0.0819, lr_0 = 1.3123e-04
Loss = 9.7307e-06, PNorm = 62.9408, GNorm = 0.0590, lr_0 = 1.3065e-04
Validation rmse logD = 0.585551
Validation R2 logD = 0.769837
Epoch 87
Train function
Loss = 9.9102e-06, PNorm = 62.9424, GNorm = 0.1557, lr_0 = 1.3001e-04
Loss = 7.9850e-06, PNorm = 62.9442, GNorm = 0.0455, lr_0 = 1.2944e-04
Loss = 9.0120e-06, PNorm = 62.9457, GNorm = 0.0455, lr_0 = 1.2886e-04
Loss = 8.5205e-06, PNorm = 62.9467, GNorm = 0.1976, lr_0 = 1.2829e-04
Loss = 1.0327e-05, PNorm = 62.9469, GNorm = 0.0762, lr_0 = 1.2773e-04
Validation rmse logD = 0.583796
Validation R2 logD = 0.771215
Epoch 88
Train function
Loss = 6.0321e-06, PNorm = 62.9479, GNorm = 0.1068, lr_0 = 1.2710e-04
Loss = 9.5747e-06, PNorm = 62.9486, GNorm = 0.1507, lr_0 = 1.2654e-04
Loss = 8.6342e-06, PNorm = 62.9500, GNorm = 0.0926, lr_0 = 1.2598e-04
Loss = 6.6948e-06, PNorm = 62.9505, GNorm = 0.1252, lr_0 = 1.2542e-04
Loss = 6.1557e-06, PNorm = 62.9518, GNorm = 0.0692, lr_0 = 1.2487e-04
Validation rmse logD = 0.583789
Validation R2 logD = 0.771221
Epoch 89
Train function
Loss = 1.1489e-05, PNorm = 62.9533, GNorm = 0.2756, lr_0 = 1.2426e-04
Loss = 1.3081e-05, PNorm = 62.9548, GNorm = 0.1587, lr_0 = 1.2371e-04
Loss = 1.0425e-05, PNorm = 62.9554, GNorm = 0.0722, lr_0 = 1.2317e-04
Loss = 1.1275e-05, PNorm = 62.9565, GNorm = 0.1190, lr_0 = 1.2262e-04
Loss = 9.2904e-06, PNorm = 62.9573, GNorm = 0.1778, lr_0 = 1.2208e-04
Loss = 1.1592e-05, PNorm = 62.9579, GNorm = 0.1397, lr_0 = 1.2154e-04
Loss = 2.9349e-05, PNorm = 62.9578, GNorm = 0.1072, lr_0 = 1.2148e-04
Validation rmse logD = 0.583147
Validation R2 logD = 0.771723
Epoch 90
Train function
Loss = 7.8927e-06, PNorm = 62.9582, GNorm = 0.0929, lr_0 = 1.2095e-04
Loss = 9.2363e-06, PNorm = 62.9592, GNorm = 0.1354, lr_0 = 1.2041e-04
Loss = 6.9864e-06, PNorm = 62.9604, GNorm = 0.0897, lr_0 = 1.1988e-04
Loss = 6.2850e-06, PNorm = 62.9609, GNorm = 0.1239, lr_0 = 1.1935e-04
Loss = 7.3574e-06, PNorm = 62.9621, GNorm = 0.0635, lr_0 = 1.1882e-04
Validation rmse logD = 0.584777
Validation R2 logD = 0.770446
Epoch 91
Train function
Loss = 4.8276e-06, PNorm = 62.9628, GNorm = 0.0549, lr_0 = 1.1824e-04
Loss = 6.0263e-06, PNorm = 62.9634, GNorm = 0.0427, lr_0 = 1.1772e-04
Loss = 7.1588e-06, PNorm = 62.9642, GNorm = 0.0723, lr_0 = 1.1720e-04
Loss = 8.0524e-06, PNorm = 62.9647, GNorm = 0.0589, lr_0 = 1.1668e-04
Loss = 6.6407e-06, PNorm = 62.9650, GNorm = 0.1424, lr_0 = 1.1616e-04
Validation rmse logD = 0.584846
Validation R2 logD = 0.770391
Epoch 92
Train function
Loss = 5.8000e-06, PNorm = 62.9658, GNorm = 0.0393, lr_0 = 1.1565e-04
Loss = 7.6010e-06, PNorm = 62.9664, GNorm = 0.1066, lr_0 = 1.1514e-04
Loss = 9.9491e-06, PNorm = 62.9673, GNorm = 0.1057, lr_0 = 1.1463e-04
Loss = 8.9906e-06, PNorm = 62.9680, GNorm = 0.0855, lr_0 = 1.1412e-04
Loss = 8.4309e-06, PNorm = 62.9690, GNorm = 0.1992, lr_0 = 1.1362e-04
Loss = 7.6397e-06, PNorm = 62.9705, GNorm = 0.0552, lr_0 = 1.1312e-04
Loss = 3.7715e-05, PNorm = 62.9706, GNorm = 0.1062, lr_0 = 1.1307e-04
Validation rmse logD = 0.585597
Validation R2 logD = 0.769801
Epoch 93
Train function
Loss = 7.9457e-06, PNorm = 62.9710, GNorm = 0.1190, lr_0 = 1.1257e-04
Loss = 9.3877e-06, PNorm = 62.9726, GNorm = 0.1311, lr_0 = 1.1207e-04
Loss = 7.8797e-06, PNorm = 62.9732, GNorm = 0.0880, lr_0 = 1.1157e-04
Loss = 5.8614e-06, PNorm = 62.9742, GNorm = 0.0708, lr_0 = 1.1108e-04
Loss = 6.0198e-06, PNorm = 62.9742, GNorm = 0.0670, lr_0 = 1.1059e-04
Validation rmse logD = 0.584670
Validation R2 logD = 0.770530
Epoch 94
Train function
Loss = 5.3264e-06, PNorm = 62.9750, GNorm = 0.1361, lr_0 = 1.1005e-04
Loss = 6.3270e-06, PNorm = 62.9760, GNorm = 0.1040, lr_0 = 1.0956e-04
Loss = 7.1634e-06, PNorm = 62.9765, GNorm = 0.0880, lr_0 = 1.0908e-04
Loss = 6.9920e-06, PNorm = 62.9769, GNorm = 0.1333, lr_0 = 1.0860e-04
Loss = 5.2011e-06, PNorm = 62.9775, GNorm = 0.0538, lr_0 = 1.0811e-04
Validation rmse logD = 0.586484
Validation R2 logD = 0.769103
Epoch 95
Train function
Loss = 5.2876e-06, PNorm = 62.9788, GNorm = 0.0392, lr_0 = 1.0759e-04
Loss = 4.4421e-06, PNorm = 62.9793, GNorm = 0.1325, lr_0 = 1.0711e-04
Loss = 6.2824e-06, PNorm = 62.9798, GNorm = 0.1067, lr_0 = 1.0664e-04
Loss = 5.7306e-06, PNorm = 62.9804, GNorm = 0.0529, lr_0 = 1.0617e-04
Loss = 4.9081e-06, PNorm = 62.9810, GNorm = 0.0489, lr_0 = 1.0570e-04
Validation rmse logD = 0.585528
Validation R2 logD = 0.769856
Epoch 96
Train function
Loss = 7.4219e-06, PNorm = 62.9821, GNorm = 0.1183, lr_0 = 1.0518e-04
Loss = 4.2441e-06, PNorm = 62.9828, GNorm = 0.0827, lr_0 = 1.0472e-04
Loss = 4.5996e-06, PNorm = 62.9836, GNorm = 0.0702, lr_0 = 1.0426e-04
Loss = 5.5254e-06, PNorm = 62.9845, GNorm = 0.1133, lr_0 = 1.0379e-04
Loss = 5.6326e-06, PNorm = 62.9850, GNorm = 0.0692, lr_0 = 1.0333e-04
Loss = 3.6834e-06, PNorm = 62.9847, GNorm = 0.0337, lr_0 = 1.0288e-04
Validation rmse logD = 0.586012
Validation R2 logD = 0.769475
Epoch 97
Train function
Loss = 4.5421e-06, PNorm = 62.9853, GNorm = 0.0717, lr_0 = 1.0238e-04
Loss = 5.2442e-06, PNorm = 62.9858, GNorm = 0.0625, lr_0 = 1.0192e-04
Loss = 3.2694e-06, PNorm = 62.9866, GNorm = 0.0605, lr_0 = 1.0147e-04
Loss = 4.2860e-06, PNorm = 62.9878, GNorm = 0.0240, lr_0 = 1.0102e-04
Loss = 4.0046e-06, PNorm = 62.9887, GNorm = 0.1299, lr_0 = 1.0058e-04
Validation rmse logD = 0.586342
Validation R2 logD = 0.769215
Epoch 98
Train function
Loss = 4.3698e-06, PNorm = 62.9893, GNorm = 0.0674, lr_0 = 1.0009e-04
Loss = 5.6116e-06, PNorm = 62.9900, GNorm = 0.1006, lr_0 = 1.0000e-04
Loss = 3.6067e-06, PNorm = 62.9904, GNorm = 0.0808, lr_0 = 1.0000e-04
Loss = 5.7682e-06, PNorm = 62.9912, GNorm = 0.0617, lr_0 = 1.0000e-04
Loss = 5.0780e-06, PNorm = 62.9924, GNorm = 0.0800, lr_0 = 1.0000e-04
Validation rmse logD = 0.586934
Validation R2 logD = 0.768749
Epoch 99
Train function
Loss = 3.5091e-06, PNorm = 62.9930, GNorm = 0.0484, lr_0 = 1.0000e-04
Loss = 3.6564e-06, PNorm = 62.9937, GNorm = 0.0558, lr_0 = 1.0000e-04
Loss = 4.0868e-06, PNorm = 62.9941, GNorm = 0.0465, lr_0 = 1.0000e-04
Loss = 3.7724e-06, PNorm = 62.9944, GNorm = 0.0387, lr_0 = 1.0000e-04
Loss = 5.0291e-06, PNorm = 62.9950, GNorm = 0.1039, lr_0 = 1.0000e-04
Loss = 4.7195e-06, PNorm = 62.9955, GNorm = 0.0348, lr_0 = 1.0000e-04
Validation rmse logD = 0.585565
Validation R2 logD = 0.769826
Model 0 best validation rmse = 0.575131 on epoch 26
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.603902
Model 0 test R2 logD = 0.747768
Ensemble test rmse  logD= 0.603902
Ensemble test R2  logD= 0.747768
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_314/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.1043e-02, PNorm = 52.9138, GNorm = 10.5913, lr_0 = 1.9340e-04
Loss = 1.7885e-02, PNorm = 52.9212, GNorm = 6.7724, lr_0 = 2.7830e-04
Loss = 1.6731e-02, PNorm = 52.9351, GNorm = 6.5157, lr_0 = 3.6321e-04
Loss = 1.5234e-02, PNorm = 52.9535, GNorm = 2.6053, lr_0 = 4.4811e-04
Loss = 1.3651e-02, PNorm = 52.9744, GNorm = 3.8568, lr_0 = 5.3302e-04
Validation rmse logD = 1.084785
Validation R2 logD = 0.180459
Epoch 1
Train function
Loss = 1.2809e-02, PNorm = 53.0031, GNorm = 1.2385, lr_0 = 6.2642e-04
Loss = 1.2976e-02, PNorm = 53.0426, GNorm = 2.6338, lr_0 = 7.1132e-04
Loss = 1.0826e-02, PNorm = 53.0927, GNorm = 1.7861, lr_0 = 7.9623e-04
Loss = 1.2675e-02, PNorm = 53.1310, GNorm = 1.7263, lr_0 = 8.8113e-04
Loss = 1.1392e-02, PNorm = 53.1796, GNorm = 5.9021, lr_0 = 9.6604e-04
Validation rmse logD = 0.827695
Validation R2 logD = 0.522884
Epoch 2
Train function
Loss = 8.2470e-03, PNorm = 53.2405, GNorm = 3.6348, lr_0 = 9.9690e-04
Loss = 1.0288e-02, PNorm = 53.3014, GNorm = 6.2330, lr_0 = 9.9249e-04
Loss = 1.0076e-02, PNorm = 53.3652, GNorm = 1.3443, lr_0 = 9.8810e-04
Loss = 8.5763e-03, PNorm = 53.4251, GNorm = 1.5389, lr_0 = 9.8373e-04
Loss = 9.3867e-03, PNorm = 53.5052, GNorm = 3.9919, lr_0 = 9.7938e-04
Validation rmse logD = 0.789202
Validation R2 logD = 0.566230
Epoch 3
Train function
Loss = 8.8411e-03, PNorm = 53.5882, GNorm = 2.0339, lr_0 = 9.7462e-04
Loss = 8.4799e-03, PNorm = 53.6829, GNorm = 2.9889, lr_0 = 9.7030e-04
Loss = 8.1458e-03, PNorm = 53.7804, GNorm = 3.0344, lr_0 = 9.6601e-04
Loss = 8.3714e-03, PNorm = 53.8650, GNorm = 1.6989, lr_0 = 9.6174e-04
Loss = 7.1883e-03, PNorm = 53.9490, GNorm = 1.1279, lr_0 = 9.5749e-04
Loss = 7.4875e-03, PNorm = 54.0373, GNorm = 2.5428, lr_0 = 9.5325e-04
Validation rmse logD = 0.718624
Validation R2 logD = 0.640345
Epoch 4
Train function
Loss = 6.6586e-03, PNorm = 54.1247, GNorm = 4.1732, lr_0 = 9.4861e-04
Loss = 8.1181e-03, PNorm = 54.2285, GNorm = 6.1917, lr_0 = 9.4442e-04
Loss = 7.8423e-03, PNorm = 54.3071, GNorm = 6.2900, lr_0 = 9.4024e-04
Loss = 6.8172e-03, PNorm = 54.3982, GNorm = 1.2000, lr_0 = 9.3608e-04
Loss = 6.0398e-03, PNorm = 54.4661, GNorm = 1.0145, lr_0 = 9.3194e-04
Validation rmse logD = 0.707119
Validation R2 logD = 0.651768
Epoch 5
Train function
Loss = 5.5334e-03, PNorm = 54.5319, GNorm = 1.2235, lr_0 = 9.2741e-04
Loss = 4.8240e-03, PNorm = 54.6149, GNorm = 1.5028, lr_0 = 9.2330e-04
Loss = 5.5029e-03, PNorm = 54.7059, GNorm = 8.6443, lr_0 = 9.1922e-04
Loss = 6.6570e-03, PNorm = 54.7891, GNorm = 1.2289, lr_0 = 9.1515e-04
Loss = 6.5022e-03, PNorm = 54.8776, GNorm = 2.0578, lr_0 = 9.1111e-04
Validation rmse logD = 0.765774
Validation R2 logD = 0.591601
Epoch 6
Train function
Loss = 7.4506e-03, PNorm = 54.9657, GNorm = 3.1231, lr_0 = 9.0667e-04
Loss = 5.1081e-03, PNorm = 55.0720, GNorm = 1.3378, lr_0 = 9.0266e-04
Loss = 4.4651e-03, PNorm = 55.1617, GNorm = 0.7958, lr_0 = 8.9867e-04
Loss = 4.8348e-03, PNorm = 55.2330, GNorm = 0.9897, lr_0 = 8.9469e-04
Loss = 5.6962e-03, PNorm = 55.3038, GNorm = 2.6412, lr_0 = 8.9074e-04
Loss = 4.6955e-03, PNorm = 55.3903, GNorm = 2.2085, lr_0 = 8.8680e-04
Validation rmse logD = 0.730951
Validation R2 logD = 0.627900
Epoch 7
Train function
Loss = 4.1946e-03, PNorm = 55.4619, GNorm = 3.6106, lr_0 = 8.8248e-04
Loss = 4.9778e-03, PNorm = 55.5249, GNorm = 3.2637, lr_0 = 8.7858e-04
Loss = 4.4381e-03, PNorm = 55.6198, GNorm = 3.1354, lr_0 = 8.7469e-04
Loss = 4.5932e-03, PNorm = 55.6903, GNorm = 1.7714, lr_0 = 8.7082e-04
Loss = 3.9964e-03, PNorm = 55.7623, GNorm = 1.2369, lr_0 = 8.6697e-04
Validation rmse logD = 0.648279
Validation R2 logD = 0.707311
Epoch 8
Train function
Loss = 4.1769e-03, PNorm = 55.8570, GNorm = 0.8436, lr_0 = 8.6276e-04
Loss = 4.3314e-03, PNorm = 55.9545, GNorm = 4.6131, lr_0 = 8.5894e-04
Loss = 4.4249e-03, PNorm = 56.0246, GNorm = 2.2915, lr_0 = 8.5514e-04
Loss = 3.9913e-03, PNorm = 56.0988, GNorm = 1.6856, lr_0 = 8.5136e-04
Loss = 3.8314e-03, PNorm = 56.1724, GNorm = 1.1608, lr_0 = 8.4759e-04
Validation rmse logD = 0.623629
Validation R2 logD = 0.729146
Epoch 9
Train function
Loss = 2.7989e-03, PNorm = 56.2404, GNorm = 1.1249, lr_0 = 8.4384e-04
Loss = 3.1851e-03, PNorm = 56.3116, GNorm = 2.2427, lr_0 = 8.4011e-04
Loss = 4.8502e-03, PNorm = 56.3855, GNorm = 4.6652, lr_0 = 8.3639e-04
Loss = 4.1606e-03, PNorm = 56.4549, GNorm = 2.8382, lr_0 = 8.3269e-04
Loss = 2.9590e-03, PNorm = 56.5342, GNorm = 1.2783, lr_0 = 8.2901e-04
Loss = 3.5146e-03, PNorm = 56.6109, GNorm = 0.9166, lr_0 = 8.2534e-04
Validation rmse logD = 0.614032
Validation R2 logD = 0.737417
Epoch 10
Train function
Loss = 3.3460e-03, PNorm = 56.6731, GNorm = 3.8141, lr_0 = 8.2133e-04
Loss = 3.3227e-03, PNorm = 56.7300, GNorm = 3.1274, lr_0 = 8.1770e-04
Loss = 3.1771e-03, PNorm = 56.8054, GNorm = 1.8308, lr_0 = 8.1408e-04
Loss = 3.3930e-03, PNorm = 56.8828, GNorm = 2.3120, lr_0 = 8.1048e-04
Loss = 2.9983e-03, PNorm = 56.9413, GNorm = 1.3629, lr_0 = 8.0689e-04
Validation rmse logD = 0.596412
Validation R2 logD = 0.752271
Epoch 11
Train function
Loss = 2.2490e-03, PNorm = 57.0160, GNorm = 1.5008, lr_0 = 8.0297e-04
Loss = 2.6497e-03, PNorm = 57.0831, GNorm = 1.7506, lr_0 = 7.9942e-04
Loss = 2.4794e-03, PNorm = 57.1416, GNorm = 1.5611, lr_0 = 7.9588e-04
Loss = 2.3249e-03, PNorm = 57.1914, GNorm = 1.3871, lr_0 = 7.9236e-04
Loss = 3.1123e-03, PNorm = 57.2492, GNorm = 3.3523, lr_0 = 7.8885e-04
Validation rmse logD = 0.670890
Validation R2 logD = 0.686537
Epoch 12
Train function
Loss = 3.9640e-03, PNorm = 57.3353, GNorm = 3.9430, lr_0 = 7.8502e-04
Loss = 3.0740e-03, PNorm = 57.4132, GNorm = 3.9251, lr_0 = 7.8154e-04
Loss = 2.6920e-03, PNorm = 57.4911, GNorm = 1.8067, lr_0 = 7.7809e-04
Loss = 2.1035e-03, PNorm = 57.5534, GNorm = 2.2069, lr_0 = 7.7465e-04
Loss = 2.2596e-03, PNorm = 57.6055, GNorm = 1.4982, lr_0 = 7.7122e-04
Loss = 2.3829e-03, PNorm = 57.6574, GNorm = 2.9069, lr_0 = 7.6781e-04
Loss = 1.9527e-02, PNorm = 57.6627, GNorm = 3.6581, lr_0 = 7.6747e-04
Validation rmse logD = 0.578124
Validation R2 logD = 0.767231
Epoch 13
Train function
Loss = 2.3556e-03, PNorm = 57.7289, GNorm = 3.8039, lr_0 = 7.6407e-04
Loss = 2.5177e-03, PNorm = 57.7877, GNorm = 0.9645, lr_0 = 7.6069e-04
Loss = 2.4990e-03, PNorm = 57.8552, GNorm = 2.5987, lr_0 = 7.5733e-04
Loss = 2.2338e-03, PNorm = 57.9236, GNorm = 1.1966, lr_0 = 7.5398e-04
Loss = 2.5504e-03, PNorm = 57.9922, GNorm = 1.2408, lr_0 = 7.5064e-04
Validation rmse logD = 0.597325
Validation R2 logD = 0.751512
Epoch 14
Train function
Loss = 2.3282e-03, PNorm = 58.0564, GNorm = 2.5085, lr_0 = 7.4699e-04
Loss = 2.3197e-03, PNorm = 58.1142, GNorm = 1.0180, lr_0 = 7.4369e-04
Loss = 1.6477e-03, PNorm = 58.1662, GNorm = 2.0167, lr_0 = 7.4040e-04
Loss = 1.9232e-03, PNorm = 58.2227, GNorm = 0.6791, lr_0 = 7.3712e-04
Loss = 2.0623e-03, PNorm = 58.2787, GNorm = 1.9338, lr_0 = 7.3386e-04
Validation rmse logD = 0.668295
Validation R2 logD = 0.688958
Epoch 15
Train function
Loss = 2.7269e-03, PNorm = 58.3376, GNorm = 2.4618, lr_0 = 7.3029e-04
Loss = 2.1394e-03, PNorm = 58.3950, GNorm = 2.0166, lr_0 = 7.2706e-04
Loss = 1.7237e-03, PNorm = 58.4611, GNorm = 1.5678, lr_0 = 7.2385e-04
Loss = 1.6512e-03, PNorm = 58.5173, GNorm = 0.9745, lr_0 = 7.2064e-04
Loss = 1.9290e-03, PNorm = 58.5693, GNorm = 1.4484, lr_0 = 7.1746e-04
Validation rmse logD = 0.566836
Validation R2 logD = 0.776232
Epoch 16
Train function
Loss = 1.0596e-03, PNorm = 58.6196, GNorm = 0.7470, lr_0 = 7.1397e-04
Loss = 1.2022e-03, PNorm = 58.6661, GNorm = 0.8780, lr_0 = 7.1081e-04
Loss = 1.5890e-03, PNorm = 58.7187, GNorm = 1.3651, lr_0 = 7.0766e-04
Loss = 1.5352e-03, PNorm = 58.7607, GNorm = 0.6837, lr_0 = 7.0453e-04
Loss = 1.3666e-03, PNorm = 58.8034, GNorm = 2.0590, lr_0 = 7.0142e-04
Loss = 1.6557e-03, PNorm = 58.8560, GNorm = 1.0885, lr_0 = 6.9831e-04
Validation rmse logD = 0.572385
Validation R2 logD = 0.771830
Epoch 17
Train function
Loss = 1.0881e-03, PNorm = 58.8973, GNorm = 0.8159, lr_0 = 6.9523e-04
Loss = 1.2323e-03, PNorm = 58.9452, GNorm = 0.7764, lr_0 = 6.9215e-04
Loss = 1.1178e-03, PNorm = 58.9880, GNorm = 0.9617, lr_0 = 6.8909e-04
Loss = 1.4352e-03, PNorm = 59.0296, GNorm = 0.7031, lr_0 = 6.8604e-04
Loss = 1.2910e-03, PNorm = 59.0664, GNorm = 0.5621, lr_0 = 6.8301e-04
Validation rmse logD = 0.616027
Validation R2 logD = 0.735709
Epoch 18
Train function
Loss = 1.3755e-03, PNorm = 59.1184, GNorm = 3.0486, lr_0 = 6.7968e-04
Loss = 1.2554e-03, PNorm = 59.1840, GNorm = 1.4566, lr_0 = 6.7668e-04
Loss = 1.1280e-03, PNorm = 59.2230, GNorm = 1.7368, lr_0 = 6.7368e-04
Loss = 1.3000e-03, PNorm = 59.2656, GNorm = 1.6998, lr_0 = 6.7070e-04
Loss = 1.1901e-03, PNorm = 59.3098, GNorm = 2.8274, lr_0 = 6.6774e-04
Validation rmse logD = 0.569698
Validation R2 logD = 0.773967
Epoch 19
Train function
Loss = 9.4854e-04, PNorm = 59.3559, GNorm = 0.5460, lr_0 = 6.6449e-04
Loss = 1.1646e-03, PNorm = 59.3952, GNorm = 1.7177, lr_0 = 6.6155e-04
Loss = 1.1304e-03, PNorm = 59.4343, GNorm = 2.7676, lr_0 = 6.5862e-04
Loss = 1.0204e-03, PNorm = 59.4753, GNorm = 0.5057, lr_0 = 6.5571e-04
Loss = 9.8655e-04, PNorm = 59.5106, GNorm = 0.7432, lr_0 = 6.5281e-04
Loss = 9.7200e-04, PNorm = 59.5454, GNorm = 0.8185, lr_0 = 6.4992e-04
Validation rmse logD = 0.565905
Validation R2 logD = 0.776966
Epoch 20
Train function
Loss = 1.1749e-03, PNorm = 59.5980, GNorm = 2.0404, lr_0 = 6.4676e-04
Loss = 8.8170e-04, PNorm = 59.6431, GNorm = 0.8337, lr_0 = 6.4390e-04
Loss = 1.1677e-03, PNorm = 59.6848, GNorm = 1.6670, lr_0 = 6.4105e-04
Loss = 8.6487e-04, PNorm = 59.7232, GNorm = 0.5564, lr_0 = 6.3822e-04
Loss = 9.3258e-04, PNorm = 59.7592, GNorm = 1.6724, lr_0 = 6.3539e-04
Validation rmse logD = 0.578201
Validation R2 logD = 0.767169
Epoch 21
Train function
Loss = 8.8986e-04, PNorm = 59.7910, GNorm = 1.6418, lr_0 = 6.3230e-04
Loss = 9.6654e-04, PNorm = 59.8297, GNorm = 1.5814, lr_0 = 6.2950e-04
Loss = 9.1267e-04, PNorm = 59.8628, GNorm = 1.7100, lr_0 = 6.2672e-04
Loss = 1.0801e-03, PNorm = 59.9036, GNorm = 1.2683, lr_0 = 6.2395e-04
Loss = 9.8978e-04, PNorm = 59.9383, GNorm = 1.1961, lr_0 = 6.2119e-04
Validation rmse logD = 0.569729
Validation R2 logD = 0.773942
Epoch 22
Train function
Loss = 1.4291e-03, PNorm = 59.9837, GNorm = 2.3046, lr_0 = 6.1817e-04
Loss = 7.8417e-04, PNorm = 60.0280, GNorm = 1.2212, lr_0 = 6.1543e-04
Loss = 8.9037e-04, PNorm = 60.0597, GNorm = 2.7463, lr_0 = 6.1271e-04
Loss = 8.2950e-04, PNorm = 60.0912, GNorm = 0.7336, lr_0 = 6.1000e-04
Loss = 6.9219e-04, PNorm = 60.1188, GNorm = 0.5295, lr_0 = 6.0730e-04
Loss = 9.2581e-04, PNorm = 60.1488, GNorm = 2.6512, lr_0 = 6.0461e-04
Validation rmse logD = 0.556770
Validation R2 logD = 0.784109
Epoch 23
Train function
Loss = 7.8316e-04, PNorm = 60.1908, GNorm = 0.6206, lr_0 = 6.0167e-04
Loss = 6.7926e-04, PNorm = 60.2273, GNorm = 0.4937, lr_0 = 5.9901e-04
Loss = 7.3206e-04, PNorm = 60.2579, GNorm = 0.8400, lr_0 = 5.9636e-04
Loss = 8.0410e-04, PNorm = 60.2897, GNorm = 0.4753, lr_0 = 5.9372e-04
Loss = 6.6204e-04, PNorm = 60.3165, GNorm = 0.4858, lr_0 = 5.9110e-04
Validation rmse logD = 0.562493
Validation R2 logD = 0.779648
Epoch 24
Train function
Loss = 8.2943e-04, PNorm = 60.3517, GNorm = 2.0196, lr_0 = 5.8822e-04
Loss = 7.4045e-04, PNorm = 60.3815, GNorm = 0.9814, lr_0 = 5.8562e-04
Loss = 6.2176e-04, PNorm = 60.4140, GNorm = 1.2724, lr_0 = 5.8303e-04
Loss = 6.8219e-04, PNorm = 60.4440, GNorm = 1.0574, lr_0 = 5.8045e-04
Loss = 7.9822e-04, PNorm = 60.4653, GNorm = 0.4297, lr_0 = 5.7788e-04
Validation rmse logD = 0.578432
Validation R2 logD = 0.766983
Epoch 25
Train function
Loss = 7.5970e-04, PNorm = 60.5051, GNorm = 1.7201, lr_0 = 5.7533e-04
Loss = 8.0640e-04, PNorm = 60.5304, GNorm = 0.6139, lr_0 = 5.7278e-04
Loss = 6.7088e-04, PNorm = 60.5654, GNorm = 0.8508, lr_0 = 5.7025e-04
Loss = 6.0684e-04, PNorm = 60.5984, GNorm = 0.5270, lr_0 = 5.6773e-04
Loss = 6.4873e-04, PNorm = 60.6173, GNorm = 0.7043, lr_0 = 5.6522e-04
Loss = 6.5106e-04, PNorm = 60.6373, GNorm = 0.4908, lr_0 = 5.6272e-04
Validation rmse logD = 0.554234
Validation R2 logD = 0.786071
Epoch 26
Train function
Loss = 4.5965e-04, PNorm = 60.6594, GNorm = 0.3450, lr_0 = 5.5998e-04
Loss = 4.6456e-04, PNorm = 60.6855, GNorm = 1.0347, lr_0 = 5.5750e-04
Loss = 4.9776e-04, PNorm = 60.7036, GNorm = 1.1560, lr_0 = 5.5503e-04
Loss = 6.9477e-04, PNorm = 60.7292, GNorm = 1.0637, lr_0 = 5.5258e-04
Loss = 7.1211e-04, PNorm = 60.7520, GNorm = 0.4450, lr_0 = 5.5014e-04
Validation rmse logD = 0.572918
Validation R2 logD = 0.771404
Epoch 27
Train function
Loss = 9.1380e-04, PNorm = 60.7872, GNorm = 0.9926, lr_0 = 5.4746e-04
Loss = 8.1714e-04, PNorm = 60.8228, GNorm = 0.9919, lr_0 = 5.4504e-04
Loss = 6.2648e-04, PNorm = 60.8573, GNorm = 0.5196, lr_0 = 5.4263e-04
Loss = 5.1012e-04, PNorm = 60.8861, GNorm = 0.8814, lr_0 = 5.4023e-04
Loss = 5.7155e-04, PNorm = 60.9065, GNorm = 0.7862, lr_0 = 5.3784e-04
Validation rmse logD = 0.565528
Validation R2 logD = 0.777263
Epoch 28
Train function
Loss = 6.2995e-04, PNorm = 60.9322, GNorm = 0.9856, lr_0 = 5.3522e-04
Loss = 5.8506e-04, PNorm = 60.9501, GNorm = 0.7783, lr_0 = 5.3285e-04
Loss = 5.8287e-04, PNorm = 60.9767, GNorm = 0.9683, lr_0 = 5.3050e-04
Loss = 4.7674e-04, PNorm = 61.0004, GNorm = 0.8265, lr_0 = 5.2815e-04
Loss = 5.2202e-04, PNorm = 61.0214, GNorm = 0.6586, lr_0 = 5.2581e-04
Loss = 4.4569e-04, PNorm = 61.0408, GNorm = 0.7624, lr_0 = 5.2349e-04
Loss = 3.7852e-04, PNorm = 61.0428, GNorm = 0.3329, lr_0 = 5.2326e-04
Validation rmse logD = 0.587326
Validation R2 logD = 0.759762
Epoch 29
Train function
Loss = 4.6527e-04, PNorm = 61.0611, GNorm = 0.4864, lr_0 = 5.2094e-04
Loss = 4.4432e-04, PNorm = 61.0808, GNorm = 1.5304, lr_0 = 5.1864e-04
Loss = 5.6557e-04, PNorm = 61.0982, GNorm = 2.3579, lr_0 = 5.1634e-04
Loss = 5.6136e-04, PNorm = 61.1195, GNorm = 2.1260, lr_0 = 5.1406e-04
Loss = 5.6552e-04, PNorm = 61.1443, GNorm = 0.9382, lr_0 = 5.1178e-04
Validation rmse logD = 0.565257
Validation R2 logD = 0.777477
Epoch 30
Train function
Loss = 4.5343e-04, PNorm = 61.1637, GNorm = 0.5831, lr_0 = 5.0930e-04
Loss = 5.8903e-04, PNorm = 61.1881, GNorm = 0.4155, lr_0 = 5.0704e-04
Loss = 4.1756e-04, PNorm = 61.2072, GNorm = 0.4657, lr_0 = 5.0480e-04
Loss = 3.8068e-04, PNorm = 61.2212, GNorm = 0.3757, lr_0 = 5.0257e-04
Loss = 5.0487e-04, PNorm = 61.2391, GNorm = 1.1440, lr_0 = 5.0034e-04
Validation rmse logD = 0.567879
Validation R2 logD = 0.775408
Epoch 31
Train function
Loss = 4.4294e-04, PNorm = 61.2619, GNorm = 0.7609, lr_0 = 4.9791e-04
Loss = 5.0816e-04, PNorm = 61.2784, GNorm = 0.4269, lr_0 = 4.9571e-04
Loss = 4.3225e-04, PNorm = 61.2960, GNorm = 0.6495, lr_0 = 4.9351e-04
Loss = 3.4094e-04, PNorm = 61.3162, GNorm = 0.2940, lr_0 = 4.9133e-04
Loss = 3.3537e-04, PNorm = 61.3330, GNorm = 0.6878, lr_0 = 4.8916e-04
Validation rmse logD = 0.562762
Validation R2 logD = 0.779437
Epoch 32
Train function
Loss = 1.9185e-04, PNorm = 61.3467, GNorm = 0.3508, lr_0 = 4.8678e-04
Loss = 2.5507e-04, PNorm = 61.3604, GNorm = 0.5473, lr_0 = 4.8463e-04
Loss = 2.8365e-04, PNorm = 61.3692, GNorm = 0.3452, lr_0 = 4.8248e-04
Loss = 3.3352e-04, PNorm = 61.3793, GNorm = 0.3783, lr_0 = 4.8035e-04
Loss = 2.3905e-04, PNorm = 61.3868, GNorm = 0.2866, lr_0 = 4.7822e-04
Loss = 4.0058e-04, PNorm = 61.4031, GNorm = 0.5304, lr_0 = 4.7611e-04
Validation rmse logD = 0.560979
Validation R2 logD = 0.780832
Epoch 33
Train function
Loss = 3.0750e-04, PNorm = 61.4192, GNorm = 0.3704, lr_0 = 4.7379e-04
Loss = 3.1997e-04, PNorm = 61.4356, GNorm = 0.8102, lr_0 = 4.7170e-04
Loss = 2.7705e-04, PNorm = 61.4528, GNorm = 0.2881, lr_0 = 4.6961e-04
Loss = 2.5077e-04, PNorm = 61.4631, GNorm = 0.2671, lr_0 = 4.6753e-04
Loss = 3.6810e-04, PNorm = 61.4785, GNorm = 0.4755, lr_0 = 4.6546e-04
Validation rmse logD = 0.570976
Validation R2 logD = 0.772951
Epoch 34
Train function
Loss = 2.3609e-04, PNorm = 61.4929, GNorm = 0.3959, lr_0 = 4.6341e-04
Loss = 2.7774e-04, PNorm = 61.5047, GNorm = 0.3782, lr_0 = 4.6136e-04
Loss = 2.3062e-04, PNorm = 61.5162, GNorm = 0.3022, lr_0 = 4.5931e-04
Loss = 2.8322e-04, PNorm = 61.5300, GNorm = 0.6692, lr_0 = 4.5728e-04
Loss = 2.6954e-04, PNorm = 61.5409, GNorm = 0.5494, lr_0 = 4.5526e-04
Validation rmse logD = 0.564343
Validation R2 logD = 0.778196
Epoch 35
Train function
Loss = 2.5018e-04, PNorm = 61.5510, GNorm = 0.7779, lr_0 = 4.5305e-04
Loss = 2.0538e-04, PNorm = 61.5646, GNorm = 0.5630, lr_0 = 4.5104e-04
Loss = 1.6873e-04, PNorm = 61.5733, GNorm = 0.2336, lr_0 = 4.4905e-04
Loss = 2.4048e-04, PNorm = 61.5868, GNorm = 0.2640, lr_0 = 4.4706e-04
Loss = 2.2545e-04, PNorm = 61.5950, GNorm = 1.0550, lr_0 = 4.4508e-04
Loss = 2.1075e-04, PNorm = 61.6046, GNorm = 0.6660, lr_0 = 4.4311e-04
Validation rmse logD = 0.564422
Validation R2 logD = 0.778134
Epoch 36
Train function
Loss = 2.2960e-04, PNorm = 61.6178, GNorm = 0.5231, lr_0 = 4.4096e-04
Loss = 2.3870e-04, PNorm = 61.6278, GNorm = 1.1510, lr_0 = 4.3901e-04
Loss = 3.1609e-04, PNorm = 61.6454, GNorm = 1.2445, lr_0 = 4.3707e-04
Loss = 2.8459e-04, PNorm = 61.6571, GNorm = 0.7301, lr_0 = 4.3513e-04
Loss = 2.6013e-04, PNorm = 61.6699, GNorm = 0.3799, lr_0 = 4.3321e-04
Validation rmse logD = 0.561679
Validation R2 logD = 0.780285
Epoch 37
Train function
Loss = 1.9119e-04, PNorm = 61.6783, GNorm = 0.5232, lr_0 = 4.3110e-04
Loss = 2.1812e-04, PNorm = 61.6911, GNorm = 0.4973, lr_0 = 4.2919e-04
Loss = 2.2812e-04, PNorm = 61.7031, GNorm = 0.4951, lr_0 = 4.2729e-04
Loss = 2.0207e-04, PNorm = 61.7161, GNorm = 0.4083, lr_0 = 4.2540e-04
Loss = 1.9936e-04, PNorm = 61.7269, GNorm = 0.4654, lr_0 = 4.2352e-04
Validation rmse logD = 0.565149
Validation R2 logD = 0.777562
Epoch 38
Train function
Loss = 2.6425e-04, PNorm = 61.7381, GNorm = 1.2127, lr_0 = 4.2146e-04
Loss = 2.7890e-04, PNorm = 61.7474, GNorm = 0.5783, lr_0 = 4.1960e-04
Loss = 2.1061e-04, PNorm = 61.7590, GNorm = 0.2868, lr_0 = 4.1774e-04
Loss = 1.9461e-04, PNorm = 61.7746, GNorm = 0.2477, lr_0 = 4.1589e-04
Loss = 1.9327e-04, PNorm = 61.7809, GNorm = 0.2271, lr_0 = 4.1406e-04
Loss = 1.8595e-04, PNorm = 61.7885, GNorm = 0.2542, lr_0 = 4.1222e-04
Validation rmse logD = 0.567803
Validation R2 logD = 0.775468
Epoch 39
Train function
Loss = 1.9443e-04, PNorm = 61.8033, GNorm = 0.2293, lr_0 = 4.1022e-04
Loss = 1.8004e-04, PNorm = 61.8132, GNorm = 0.4371, lr_0 = 4.0840e-04
Loss = 1.6924e-04, PNorm = 61.8229, GNorm = 0.7242, lr_0 = 4.0660e-04
Loss = 2.3344e-04, PNorm = 61.8349, GNorm = 0.4584, lr_0 = 4.0480e-04
Loss = 2.1612e-04, PNorm = 61.8478, GNorm = 0.2272, lr_0 = 4.0301e-04
Validation rmse logD = 0.561304
Validation R2 logD = 0.780578
Epoch 40
Train function
Loss = 1.2758e-04, PNorm = 61.8566, GNorm = 0.5886, lr_0 = 4.0105e-04
Loss = 1.8447e-04, PNorm = 61.8677, GNorm = 0.8844, lr_0 = 3.9927e-04
Loss = 1.6954e-04, PNorm = 61.8745, GNorm = 0.8291, lr_0 = 3.9751e-04
Loss = 2.3130e-04, PNorm = 61.8836, GNorm = 0.2825, lr_0 = 3.9575e-04
Loss = 1.4043e-04, PNorm = 61.8965, GNorm = 0.2027, lr_0 = 3.9400e-04
Validation rmse logD = 0.566409
Validation R2 logD = 0.776569
Epoch 41
Train function
Loss = 2.1472e-04, PNorm = 61.9070, GNorm = 1.0332, lr_0 = 3.9208e-04
Loss = 2.1474e-04, PNorm = 61.9185, GNorm = 0.2588, lr_0 = 3.9035e-04
Loss = 2.6540e-04, PNorm = 61.9353, GNorm = 0.5129, lr_0 = 3.8862e-04
Loss = 1.8648e-04, PNorm = 61.9460, GNorm = 0.1862, lr_0 = 3.8690e-04
Loss = 1.7986e-04, PNorm = 61.9564, GNorm = 0.2735, lr_0 = 3.8519e-04
Loss = 1.8296e-04, PNorm = 61.9697, GNorm = 0.6236, lr_0 = 3.8349e-04
Validation rmse logD = 0.567902
Validation R2 logD = 0.775389
Epoch 42
Train function
Loss = 1.5439e-04, PNorm = 61.9744, GNorm = 0.2807, lr_0 = 3.8179e-04
Loss = 1.4169e-04, PNorm = 61.9812, GNorm = 0.2389, lr_0 = 3.8010e-04
Loss = 1.3758e-04, PNorm = 61.9925, GNorm = 0.2985, lr_0 = 3.7842e-04
Loss = 1.4083e-04, PNorm = 61.9994, GNorm = 0.3798, lr_0 = 3.7675e-04
Loss = 1.8722e-04, PNorm = 62.0072, GNorm = 0.9791, lr_0 = 3.7508e-04
Validation rmse logD = 0.557813
Validation R2 logD = 0.783299
Epoch 43
Train function
Loss = 9.5499e-05, PNorm = 62.0153, GNorm = 0.2132, lr_0 = 3.7326e-04
Loss = 1.4234e-04, PNorm = 62.0260, GNorm = 0.5141, lr_0 = 3.7160e-04
Loss = 1.7715e-04, PNorm = 62.0338, GNorm = 0.6166, lr_0 = 3.6996e-04
Loss = 1.3824e-04, PNorm = 62.0413, GNorm = 0.4666, lr_0 = 3.6832e-04
Loss = 1.5075e-04, PNorm = 62.0510, GNorm = 0.6745, lr_0 = 3.6669e-04
Validation rmse logD = 0.566708
Validation R2 logD = 0.776333
Epoch 44
Train function
Loss = 1.3459e-04, PNorm = 62.0608, GNorm = 0.2712, lr_0 = 3.6491e-04
Loss = 1.0001e-04, PNorm = 62.0680, GNorm = 0.3543, lr_0 = 3.6330e-04
Loss = 1.2265e-04, PNorm = 62.0743, GNorm = 0.2178, lr_0 = 3.6169e-04
Loss = 1.4909e-04, PNorm = 62.0817, GNorm = 0.4586, lr_0 = 3.6009e-04
Loss = 1.3275e-04, PNorm = 62.0932, GNorm = 0.2239, lr_0 = 3.5850e-04
Loss = 1.0449e-04, PNorm = 62.0986, GNorm = 0.2103, lr_0 = 3.5691e-04
Loss = 7.1669e-04, PNorm = 62.0991, GNorm = 0.6368, lr_0 = 3.5675e-04
Validation rmse logD = 0.561092
Validation R2 logD = 0.780744
Epoch 45
Train function
Loss = 1.0557e-04, PNorm = 62.1063, GNorm = 0.2126, lr_0 = 3.5518e-04
Loss = 1.0526e-04, PNorm = 62.1151, GNorm = 0.2051, lr_0 = 3.5360e-04
Loss = 1.1078e-04, PNorm = 62.1247, GNorm = 0.2490, lr_0 = 3.5204e-04
Loss = 1.0039e-04, PNorm = 62.1307, GNorm = 0.1804, lr_0 = 3.5048e-04
Loss = 1.2672e-04, PNorm = 62.1344, GNorm = 0.2248, lr_0 = 3.4893e-04
Validation rmse logD = 0.563765
Validation R2 logD = 0.778650
Epoch 46
Train function
Loss = 8.9392e-05, PNorm = 62.1443, GNorm = 0.2334, lr_0 = 3.4724e-04
Loss = 1.0578e-04, PNorm = 62.1541, GNorm = 0.6078, lr_0 = 3.4570e-04
Loss = 8.9566e-05, PNorm = 62.1626, GNorm = 0.1468, lr_0 = 3.4417e-04
Loss = 1.0543e-04, PNorm = 62.1680, GNorm = 0.3148, lr_0 = 3.4265e-04
Loss = 9.8627e-05, PNorm = 62.1741, GNorm = 0.2700, lr_0 = 3.4113e-04
Validation rmse logD = 0.559456
Validation R2 logD = 0.782021
Epoch 47
Train function
Loss = 9.6311e-05, PNorm = 62.1792, GNorm = 0.3253, lr_0 = 3.3947e-04
Loss = 7.9019e-05, PNorm = 62.1863, GNorm = 0.2005, lr_0 = 3.3797e-04
Loss = 1.1052e-04, PNorm = 62.1898, GNorm = 0.6221, lr_0 = 3.3648e-04
Loss = 7.8489e-05, PNorm = 62.1953, GNorm = 0.3823, lr_0 = 3.3499e-04
Loss = 1.2787e-04, PNorm = 62.2005, GNorm = 0.8812, lr_0 = 3.3351e-04
Validation rmse logD = 0.576619
Validation R2 logD = 0.768441
Epoch 48
Train function
Loss = 2.5155e-04, PNorm = 62.2099, GNorm = 1.2773, lr_0 = 3.3188e-04
Loss = 1.3565e-04, PNorm = 62.2169, GNorm = 0.5421, lr_0 = 3.3042e-04
Loss = 9.1276e-05, PNorm = 62.2253, GNorm = 0.2016, lr_0 = 3.2895e-04
Loss = 9.0190e-05, PNorm = 62.2327, GNorm = 0.3720, lr_0 = 3.2750e-04
Loss = 1.1074e-04, PNorm = 62.2423, GNorm = 0.3545, lr_0 = 3.2605e-04
Loss = 1.3688e-04, PNorm = 62.2517, GNorm = 0.5931, lr_0 = 3.2461e-04
Validation rmse logD = 0.561967
Validation R2 logD = 0.780060
Epoch 49
Train function
Loss = 9.1742e-05, PNorm = 62.2613, GNorm = 0.1673, lr_0 = 3.2303e-04
Loss = 7.7452e-05, PNorm = 62.2649, GNorm = 0.2920, lr_0 = 3.2160e-04
Loss = 9.0085e-05, PNorm = 62.2722, GNorm = 0.2367, lr_0 = 3.2018e-04
Loss = 1.0806e-04, PNorm = 62.2806, GNorm = 0.2078, lr_0 = 3.1876e-04
Loss = 8.4172e-05, PNorm = 62.2851, GNorm = 0.3156, lr_0 = 3.1735e-04
Validation rmse logD = 0.560628
Validation R2 logD = 0.781107
Epoch 50
Train function
Loss = 6.4921e-05, PNorm = 62.2913, GNorm = 0.3043, lr_0 = 3.1595e-04
Loss = 9.2623e-05, PNorm = 62.2989, GNorm = 0.3538, lr_0 = 3.1455e-04
Loss = 9.0698e-05, PNorm = 62.3045, GNorm = 0.5416, lr_0 = 3.1316e-04
Loss = 9.9014e-05, PNorm = 62.3088, GNorm = 0.2757, lr_0 = 3.1177e-04
Loss = 7.6783e-05, PNorm = 62.3161, GNorm = 0.2021, lr_0 = 3.1039e-04
Validation rmse logD = 0.565251
Validation R2 logD = 0.777482
Epoch 51
Train function
Loss = 8.1449e-05, PNorm = 62.3212, GNorm = 0.4403, lr_0 = 3.0888e-04
Loss = 9.1898e-05, PNorm = 62.3274, GNorm = 0.2243, lr_0 = 3.0752e-04
Loss = 7.7484e-05, PNorm = 62.3334, GNorm = 0.2557, lr_0 = 3.0616e-04
Loss = 7.7634e-05, PNorm = 62.3387, GNorm = 0.3028, lr_0 = 3.0480e-04
Loss = 5.7550e-05, PNorm = 62.3452, GNorm = 0.1909, lr_0 = 3.0346e-04
Loss = 7.4935e-05, PNorm = 62.3489, GNorm = 0.6702, lr_0 = 3.0211e-04
Validation rmse logD = 0.562064
Validation R2 logD = 0.779984
Epoch 52
Train function
Loss = 8.2873e-05, PNorm = 62.3540, GNorm = 0.2676, lr_0 = 3.0064e-04
Loss = 8.5971e-05, PNorm = 62.3591, GNorm = 0.2490, lr_0 = 2.9931e-04
Loss = 9.1740e-05, PNorm = 62.3665, GNorm = 0.3005, lr_0 = 2.9799e-04
Loss = 7.1481e-05, PNorm = 62.3729, GNorm = 0.3658, lr_0 = 2.9667e-04
Loss = 6.9774e-05, PNorm = 62.3783, GNorm = 0.1701, lr_0 = 2.9536e-04
Validation rmse logD = 0.564434
Validation R2 logD = 0.778125
Epoch 53
Train function
Loss = 8.1697e-05, PNorm = 62.3819, GNorm = 0.3856, lr_0 = 2.9392e-04
Loss = 7.4577e-05, PNorm = 62.3891, GNorm = 0.1284, lr_0 = 2.9262e-04
Loss = 6.4067e-05, PNorm = 62.3926, GNorm = 0.6379, lr_0 = 2.9133e-04
Loss = 7.6230e-05, PNorm = 62.3957, GNorm = 0.1620, lr_0 = 2.9004e-04
Loss = 6.8219e-05, PNorm = 62.4016, GNorm = 0.1562, lr_0 = 2.8876e-04
Validation rmse logD = 0.564680
Validation R2 logD = 0.777931
Epoch 54
Train function
Loss = 4.4983e-05, PNorm = 62.4082, GNorm = 0.1179, lr_0 = 2.8735e-04
Loss = 4.6703e-05, PNorm = 62.4129, GNorm = 0.1542, lr_0 = 2.8608e-04
Loss = 5.2555e-05, PNorm = 62.4169, GNorm = 0.1911, lr_0 = 2.8482e-04
Loss = 7.0285e-05, PNorm = 62.4190, GNorm = 0.2104, lr_0 = 2.8356e-04
Loss = 8.7060e-05, PNorm = 62.4264, GNorm = 0.2925, lr_0 = 2.8230e-04
Loss = 6.6213e-05, PNorm = 62.4330, GNorm = 0.1825, lr_0 = 2.8105e-04
Validation rmse logD = 0.562687
Validation R2 logD = 0.779495
Epoch 55
Train function
Loss = 6.9232e-05, PNorm = 62.4402, GNorm = 0.1758, lr_0 = 2.7969e-04
Loss = 5.8792e-05, PNorm = 62.4450, GNorm = 0.1511, lr_0 = 2.7845e-04
Loss = 5.4887e-05, PNorm = 62.4475, GNorm = 0.3022, lr_0 = 2.7722e-04
Loss = 9.6289e-05, PNorm = 62.4521, GNorm = 0.3936, lr_0 = 2.7599e-04
Loss = 8.5617e-05, PNorm = 62.4562, GNorm = 0.1743, lr_0 = 2.7477e-04
Validation rmse logD = 0.566813
Validation R2 logD = 0.776250
Epoch 56
Train function
Loss = 6.1377e-05, PNorm = 62.4656, GNorm = 0.1596, lr_0 = 2.7343e-04
Loss = 5.8401e-05, PNorm = 62.4676, GNorm = 0.1896, lr_0 = 2.7222e-04
Loss = 6.5758e-05, PNorm = 62.4726, GNorm = 0.1896, lr_0 = 2.7102e-04
Loss = 4.0303e-05, PNorm = 62.4772, GNorm = 0.1623, lr_0 = 2.6982e-04
Loss = 7.2976e-05, PNorm = 62.4821, GNorm = 0.3508, lr_0 = 2.6863e-04
Validation rmse logD = 0.561158
Validation R2 logD = 0.780692
Epoch 57
Train function
Loss = 4.1158e-05, PNorm = 62.4907, GNorm = 0.2496, lr_0 = 2.6732e-04
Loss = 5.9880e-05, PNorm = 62.4965, GNorm = 0.1965, lr_0 = 2.6614e-04
Loss = 5.9443e-05, PNorm = 62.4994, GNorm = 0.1983, lr_0 = 2.6496e-04
Loss = 7.0105e-05, PNorm = 62.5037, GNorm = 0.1788, lr_0 = 2.6379e-04
Loss = 5.2498e-05, PNorm = 62.5091, GNorm = 0.1925, lr_0 = 2.6262e-04
Loss = 4.4230e-05, PNorm = 62.5124, GNorm = 0.4597, lr_0 = 2.6146e-04
Loss = 7.8575e-04, PNorm = 62.5125, GNorm = 0.6814, lr_0 = 2.6134e-04
Validation rmse logD = 0.562617
Validation R2 logD = 0.779550
Epoch 58
Train function
Loss = 7.1119e-05, PNorm = 62.5167, GNorm = 0.3815, lr_0 = 2.6019e-04
Loss = 6.0895e-05, PNorm = 62.5212, GNorm = 0.1485, lr_0 = 2.5904e-04
Loss = 4.8639e-05, PNorm = 62.5266, GNorm = 0.1644, lr_0 = 2.5789e-04
Loss = 4.2437e-05, PNorm = 62.5326, GNorm = 0.3019, lr_0 = 2.5675e-04
Loss = 6.8982e-05, PNorm = 62.5383, GNorm = 0.2353, lr_0 = 2.5561e-04
Validation rmse logD = 0.561494
Validation R2 logD = 0.780430
Epoch 59
Train function
Loss = 5.0633e-05, PNorm = 62.5434, GNorm = 0.3041, lr_0 = 2.5448e-04
Loss = 5.0616e-05, PNorm = 62.5458, GNorm = 0.3575, lr_0 = 2.5336e-04
Loss = 4.2247e-05, PNorm = 62.5469, GNorm = 0.1402, lr_0 = 2.5224e-04
Loss = 6.7219e-05, PNorm = 62.5501, GNorm = 0.2703, lr_0 = 2.5112e-04
Loss = 4.1296e-05, PNorm = 62.5532, GNorm = 0.1333, lr_0 = 2.5001e-04
Validation rmse logD = 0.561476
Validation R2 logD = 0.780444
Epoch 60
Train function
Loss = 4.8930e-05, PNorm = 62.5556, GNorm = 0.1566, lr_0 = 2.4879e-04
Loss = 3.8211e-05, PNorm = 62.5594, GNorm = 0.0874, lr_0 = 2.4769e-04
Loss = 4.6495e-05, PNorm = 62.5649, GNorm = 0.1224, lr_0 = 2.4660e-04
Loss = 5.9403e-05, PNorm = 62.5685, GNorm = 0.2388, lr_0 = 2.4551e-04
Loss = 3.9871e-05, PNorm = 62.5718, GNorm = 0.1509, lr_0 = 2.4442e-04
Loss = 4.1597e-05, PNorm = 62.5748, GNorm = 0.2642, lr_0 = 2.4334e-04
Loss = 1.7067e-04, PNorm = 62.5748, GNorm = 0.4193, lr_0 = 2.4323e-04
Validation rmse logD = 0.562178
Validation R2 logD = 0.779894
Epoch 61
Train function
Loss = 3.5363e-05, PNorm = 62.5775, GNorm = 0.1106, lr_0 = 2.4216e-04
Loss = 3.5349e-05, PNorm = 62.5803, GNorm = 0.1213, lr_0 = 2.4109e-04
Loss = 4.1484e-05, PNorm = 62.5832, GNorm = 0.0962, lr_0 = 2.4002e-04
Loss = 3.8351e-05, PNorm = 62.5866, GNorm = 0.1012, lr_0 = 2.3896e-04
Loss = 3.3524e-05, PNorm = 62.5904, GNorm = 0.1385, lr_0 = 2.3790e-04
Validation rmse logD = 0.562669
Validation R2 logD = 0.779510
Epoch 62
Train function
Loss = 4.4344e-05, PNorm = 62.5938, GNorm = 0.3146, lr_0 = 2.3674e-04
Loss = 2.8158e-05, PNorm = 62.5975, GNorm = 0.0848, lr_0 = 2.3570e-04
Loss = 4.8970e-05, PNorm = 62.6025, GNorm = 0.2431, lr_0 = 2.3465e-04
Loss = 6.5377e-05, PNorm = 62.6071, GNorm = 0.5841, lr_0 = 2.3362e-04
Loss = 4.2528e-05, PNorm = 62.6113, GNorm = 0.2324, lr_0 = 2.3258e-04
Validation rmse logD = 0.561716
Validation R2 logD = 0.780256
Epoch 63
Train function
Loss = 3.8434e-05, PNorm = 62.6162, GNorm = 0.2824, lr_0 = 2.3145e-04
Loss = 4.5281e-05, PNorm = 62.6184, GNorm = 0.1221, lr_0 = 2.3043e-04
Loss = 3.2072e-05, PNorm = 62.6215, GNorm = 0.1385, lr_0 = 2.2941e-04
Loss = 4.8529e-05, PNorm = 62.6251, GNorm = 0.1927, lr_0 = 2.2839e-04
Loss = 4.6076e-05, PNorm = 62.6295, GNorm = 0.2369, lr_0 = 2.2738e-04
Validation rmse logD = 0.560622
Validation R2 logD = 0.781111
Epoch 64
Train function
Loss = 4.0823e-05, PNorm = 62.6335, GNorm = 0.1430, lr_0 = 2.2628e-04
Loss = 5.4071e-05, PNorm = 62.6384, GNorm = 0.1538, lr_0 = 2.2528e-04
Loss = 3.6862e-05, PNorm = 62.6409, GNorm = 0.3460, lr_0 = 2.2428e-04
Loss = 3.2425e-05, PNorm = 62.6418, GNorm = 0.3713, lr_0 = 2.2329e-04
Loss = 4.2123e-05, PNorm = 62.6438, GNorm = 0.2566, lr_0 = 2.2230e-04
Loss = 4.9271e-05, PNorm = 62.6468, GNorm = 0.1554, lr_0 = 2.2132e-04
Validation rmse logD = 0.562776
Validation R2 logD = 0.779426
Epoch 65
Train function
Loss = 2.6600e-05, PNorm = 62.6517, GNorm = 0.1059, lr_0 = 2.2024e-04
Loss = 2.8092e-05, PNorm = 62.6548, GNorm = 0.0860, lr_0 = 2.1927e-04
Loss = 3.0118e-05, PNorm = 62.6566, GNorm = 0.2461, lr_0 = 2.1830e-04
Loss = 4.1196e-05, PNorm = 62.6592, GNorm = 0.1680, lr_0 = 2.1733e-04
Loss = 3.4494e-05, PNorm = 62.6606, GNorm = 0.3171, lr_0 = 2.1637e-04
Validation rmse logD = 0.561266
Validation R2 logD = 0.780608
Epoch 66
Train function
Loss = 4.9920e-05, PNorm = 62.6645, GNorm = 0.2392, lr_0 = 2.1532e-04
Loss = 3.4881e-05, PNorm = 62.6680, GNorm = 0.1038, lr_0 = 2.1436e-04
Loss = 3.5419e-05, PNorm = 62.6690, GNorm = 0.0994, lr_0 = 2.1342e-04
Loss = 2.8550e-05, PNorm = 62.6718, GNorm = 0.2313, lr_0 = 2.1247e-04
Loss = 2.9025e-05, PNorm = 62.6734, GNorm = 0.1161, lr_0 = 2.1153e-04
Validation rmse logD = 0.565675
Validation R2 logD = 0.777147
Epoch 67
Train function
Loss = 2.4762e-05, PNorm = 62.6778, GNorm = 0.3057, lr_0 = 2.1060e-04
Loss = 2.9065e-05, PNorm = 62.6826, GNorm = 0.2590, lr_0 = 2.0966e-04
Loss = 3.2533e-05, PNorm = 62.6858, GNorm = 0.1785, lr_0 = 2.0874e-04
Loss = 3.7118e-05, PNorm = 62.6891, GNorm = 0.1304, lr_0 = 2.0781e-04
Loss = 3.3519e-05, PNorm = 62.6914, GNorm = 0.2280, lr_0 = 2.0689e-04
Loss = 2.1896e-05, PNorm = 62.6924, GNorm = 0.1973, lr_0 = 2.0598e-04
Validation rmse logD = 0.563574
Validation R2 logD = 0.778800
Epoch 68
Train function
Loss = 2.5049e-05, PNorm = 62.6954, GNorm = 0.3703, lr_0 = 2.0498e-04
Loss = 2.6446e-05, PNorm = 62.6994, GNorm = 0.1181, lr_0 = 2.0407e-04
Loss = 2.8789e-05, PNorm = 62.7014, GNorm = 0.3226, lr_0 = 2.0317e-04
Loss = 3.4475e-05, PNorm = 62.7038, GNorm = 0.0727, lr_0 = 2.0227e-04
Loss = 3.1330e-05, PNorm = 62.7063, GNorm = 0.4926, lr_0 = 2.0137e-04
Validation rmse logD = 0.562522
Validation R2 logD = 0.779625
Epoch 69
Train function
Loss = 3.8630e-05, PNorm = 62.7104, GNorm = 0.3951, lr_0 = 2.0039e-04
Loss = 5.1090e-05, PNorm = 62.7126, GNorm = 0.3577, lr_0 = 1.9951e-04
Loss = 4.5435e-05, PNorm = 62.7150, GNorm = 0.2118, lr_0 = 1.9863e-04
Loss = 3.3643e-05, PNorm = 62.7174, GNorm = 0.2192, lr_0 = 1.9775e-04
Loss = 3.5516e-05, PNorm = 62.7205, GNorm = 0.2439, lr_0 = 1.9687e-04
Validation rmse logD = 0.560546
Validation R2 logD = 0.781171
Epoch 70
Train function
Loss = 2.1746e-05, PNorm = 62.7241, GNorm = 0.1394, lr_0 = 1.9592e-04
Loss = 2.3216e-05, PNorm = 62.7271, GNorm = 0.1629, lr_0 = 1.9505e-04
Loss = 3.2006e-05, PNorm = 62.7296, GNorm = 0.4084, lr_0 = 1.9419e-04
Loss = 2.9899e-05, PNorm = 62.7329, GNorm = 0.1883, lr_0 = 1.9333e-04
Loss = 2.4395e-05, PNorm = 62.7339, GNorm = 0.1677, lr_0 = 1.9247e-04
Loss = 2.6471e-05, PNorm = 62.7335, GNorm = 0.1212, lr_0 = 1.9162e-04
Validation rmse logD = 0.562476
Validation R2 logD = 0.779661
Epoch 71
Train function
Loss = 2.6780e-05, PNorm = 62.7352, GNorm = 0.0975, lr_0 = 1.9069e-04
Loss = 3.0293e-05, PNorm = 62.7379, GNorm = 0.2831, lr_0 = 1.8984e-04
Loss = 3.5551e-05, PNorm = 62.7399, GNorm = 0.1214, lr_0 = 1.8900e-04
Loss = 2.3956e-05, PNorm = 62.7425, GNorm = 0.0983, lr_0 = 1.8817e-04
Loss = 2.4606e-05, PNorm = 62.7448, GNorm = 0.2709, lr_0 = 1.8734e-04
Validation rmse logD = 0.562176
Validation R2 logD = 0.779896
Epoch 72
Train function
Loss = 1.9497e-05, PNorm = 62.7466, GNorm = 0.0942, lr_0 = 1.8643e-04
Loss = 2.3066e-05, PNorm = 62.7476, GNorm = 0.3958, lr_0 = 1.8560e-04
Loss = 1.8655e-05, PNorm = 62.7500, GNorm = 0.1889, lr_0 = 1.8478e-04
Loss = 2.3416e-05, PNorm = 62.7525, GNorm = 0.1702, lr_0 = 1.8396e-04
Loss = 2.6734e-05, PNorm = 62.7539, GNorm = 0.4375, lr_0 = 1.8315e-04
Validation rmse logD = 0.562809
Validation R2 logD = 0.779400
Epoch 73
Train function
Loss = 2.9030e-05, PNorm = 62.7563, GNorm = 0.3797, lr_0 = 1.8226e-04
Loss = 2.5738e-05, PNorm = 62.7578, GNorm = 0.1449, lr_0 = 1.8145e-04
Loss = 2.0078e-05, PNorm = 62.7593, GNorm = 0.0987, lr_0 = 1.8065e-04
Loss = 1.8709e-05, PNorm = 62.7622, GNorm = 0.1234, lr_0 = 1.7985e-04
Loss = 1.8113e-05, PNorm = 62.7646, GNorm = 0.1236, lr_0 = 1.7905e-04
Loss = 1.5500e-05, PNorm = 62.7664, GNorm = 0.0912, lr_0 = 1.7826e-04
Loss = 4.7744e-05, PNorm = 62.7666, GNorm = 0.1275, lr_0 = 1.7818e-04
Validation rmse logD = 0.563256
Validation R2 logD = 0.779050
Epoch 74
Train function
Loss = 2.0709e-05, PNorm = 62.7684, GNorm = 0.1636, lr_0 = 1.7739e-04
Loss = 1.3846e-05, PNorm = 62.7691, GNorm = 0.0869, lr_0 = 1.7661e-04
Loss = 1.2902e-05, PNorm = 62.7702, GNorm = 0.0693, lr_0 = 1.7583e-04
Loss = 1.3245e-05, PNorm = 62.7721, GNorm = 0.0801, lr_0 = 1.7505e-04
Loss = 1.1815e-05, PNorm = 62.7727, GNorm = 0.0608, lr_0 = 1.7428e-04
Validation rmse logD = 0.562501
Validation R2 logD = 0.779642
Epoch 75
Train function
Loss = 9.7900e-06, PNorm = 62.7740, GNorm = 0.0786, lr_0 = 1.7351e-04
Loss = 1.7915e-05, PNorm = 62.7755, GNorm = 0.0878, lr_0 = 1.7274e-04
Loss = 1.1707e-05, PNorm = 62.7768, GNorm = 0.0750, lr_0 = 1.7197e-04
Loss = 1.3978e-05, PNorm = 62.7779, GNorm = 0.2075, lr_0 = 1.7121e-04
Loss = 1.6989e-05, PNorm = 62.7795, GNorm = 0.1443, lr_0 = 1.7046e-04
Validation rmse logD = 0.562743
Validation R2 logD = 0.779452
Epoch 76
Train function
Loss = 1.4267e-05, PNorm = 62.7807, GNorm = 0.1922, lr_0 = 1.6963e-04
Loss = 1.6731e-05, PNorm = 62.7819, GNorm = 0.0823, lr_0 = 1.6888e-04
Loss = 2.1036e-05, PNorm = 62.7840, GNorm = 0.0889, lr_0 = 1.6813e-04
Loss = 1.8085e-05, PNorm = 62.7854, GNorm = 0.1254, lr_0 = 1.6739e-04
Loss = 1.5477e-05, PNorm = 62.7865, GNorm = 0.0944, lr_0 = 1.6665e-04
Loss = 1.3840e-05, PNorm = 62.7888, GNorm = 0.1056, lr_0 = 1.6591e-04
Loss = 2.9329e-04, PNorm = 62.7889, GNorm = 0.2636, lr_0 = 1.6584e-04
Validation rmse logD = 0.563644
Validation R2 logD = 0.778745
Epoch 77
Train function
Loss = 2.0712e-05, PNorm = 62.7909, GNorm = 0.1267, lr_0 = 1.6510e-04
Loss = 1.7498e-05, PNorm = 62.7922, GNorm = 0.1654, lr_0 = 1.6437e-04
Loss = 1.8750e-05, PNorm = 62.7931, GNorm = 0.1060, lr_0 = 1.6364e-04
Loss = 2.1193e-05, PNorm = 62.7949, GNorm = 0.2450, lr_0 = 1.6292e-04
Loss = 1.8189e-05, PNorm = 62.7973, GNorm = 0.0847, lr_0 = 1.6220e-04
Validation rmse logD = 0.563816
Validation R2 logD = 0.778610
Epoch 78
Train function
Loss = 1.7295e-05, PNorm = 62.7996, GNorm = 0.2651, lr_0 = 1.6141e-04
Loss = 1.6781e-05, PNorm = 62.8002, GNorm = 0.0825, lr_0 = 1.6070e-04
Loss = 1.6788e-05, PNorm = 62.8022, GNorm = 0.1039, lr_0 = 1.5999e-04
Loss = 1.6186e-05, PNorm = 62.8040, GNorm = 0.1458, lr_0 = 1.5928e-04
Loss = 1.9663e-05, PNorm = 62.8047, GNorm = 0.1956, lr_0 = 1.5857e-04
Validation rmse logD = 0.562186
Validation R2 logD = 0.779888
Epoch 79
Train function
Loss = 1.3392e-05, PNorm = 62.8072, GNorm = 0.1321, lr_0 = 1.5780e-04
Loss = 1.5581e-05, PNorm = 62.8080, GNorm = 0.1506, lr_0 = 1.5710e-04
Loss = 1.4925e-05, PNorm = 62.8090, GNorm = 0.2016, lr_0 = 1.5641e-04
Loss = 1.8782e-05, PNorm = 62.8103, GNorm = 0.0561, lr_0 = 1.5572e-04
Loss = 1.5042e-05, PNorm = 62.8127, GNorm = 0.1532, lr_0 = 1.5503e-04
Validation rmse logD = 0.564380
Validation R2 logD = 0.778167
Epoch 80
Train function
Loss = 1.9686e-05, PNorm = 62.8145, GNorm = 0.2013, lr_0 = 1.5427e-04
Loss = 1.5972e-05, PNorm = 62.8161, GNorm = 0.1562, lr_0 = 1.5359e-04
Loss = 1.7753e-05, PNorm = 62.8178, GNorm = 0.0537, lr_0 = 1.5291e-04
Loss = 1.9058e-05, PNorm = 62.8195, GNorm = 0.0764, lr_0 = 1.5224e-04
Loss = 1.2320e-05, PNorm = 62.8213, GNorm = 0.0959, lr_0 = 1.5156e-04
Loss = 1.3577e-05, PNorm = 62.8227, GNorm = 0.1612, lr_0 = 1.5089e-04
Validation rmse logD = 0.562598
Validation R2 logD = 0.779566
Epoch 81
Train function
Loss = 1.1163e-05, PNorm = 62.8243, GNorm = 0.0783, lr_0 = 1.5016e-04
Loss = 1.0894e-05, PNorm = 62.8254, GNorm = 0.1247, lr_0 = 1.4949e-04
Loss = 1.3632e-05, PNorm = 62.8264, GNorm = 0.1361, lr_0 = 1.4883e-04
Loss = 1.4107e-05, PNorm = 62.8266, GNorm = 0.1330, lr_0 = 1.4817e-04
Loss = 1.5985e-05, PNorm = 62.8280, GNorm = 0.1484, lr_0 = 1.4752e-04
Validation rmse logD = 0.563474
Validation R2 logD = 0.778879
Epoch 82
Train function
Loss = 1.0183e-05, PNorm = 62.8295, GNorm = 0.1043, lr_0 = 1.4680e-04
Loss = 1.3300e-05, PNorm = 62.8309, GNorm = 0.1737, lr_0 = 1.4615e-04
Loss = 1.1319e-05, PNorm = 62.8320, GNorm = 0.0545, lr_0 = 1.4551e-04
Loss = 1.0352e-05, PNorm = 62.8328, GNorm = 0.0817, lr_0 = 1.4486e-04
Loss = 1.6416e-05, PNorm = 62.8334, GNorm = 0.2715, lr_0 = 1.4422e-04
Validation rmse logD = 0.564825
Validation R2 logD = 0.777817
Epoch 83
Train function
Loss = 1.4692e-05, PNorm = 62.8349, GNorm = 0.1073, lr_0 = 1.4352e-04
Loss = 1.5073e-05, PNorm = 62.8363, GNorm = 0.1420, lr_0 = 1.4288e-04
Loss = 1.6019e-05, PNorm = 62.8367, GNorm = 0.1319, lr_0 = 1.4225e-04
Loss = 1.3453e-05, PNorm = 62.8388, GNorm = 0.1098, lr_0 = 1.4162e-04
Loss = 1.7630e-05, PNorm = 62.8399, GNorm = 0.1564, lr_0 = 1.4100e-04
Loss = 1.3687e-05, PNorm = 62.8411, GNorm = 0.0470, lr_0 = 1.4037e-04
Validation rmse logD = 0.561775
Validation R2 logD = 0.780210
Epoch 84
Train function
Loss = 1.3483e-05, PNorm = 62.8426, GNorm = 0.0927, lr_0 = 1.3975e-04
Loss = 1.3847e-05, PNorm = 62.8445, GNorm = 0.1789, lr_0 = 1.3913e-04
Loss = 1.1120e-05, PNorm = 62.8450, GNorm = 0.1125, lr_0 = 1.3852e-04
Loss = 1.3533e-05, PNorm = 62.8459, GNorm = 0.2171, lr_0 = 1.3791e-04
Loss = 1.2470e-05, PNorm = 62.8469, GNorm = 0.1863, lr_0 = 1.3730e-04
Validation rmse logD = 0.562857
Validation R2 logD = 0.779363
Epoch 85
Train function
Loss = 1.0127e-05, PNorm = 62.8483, GNorm = 0.0853, lr_0 = 1.3663e-04
Loss = 1.1814e-05, PNorm = 62.8497, GNorm = 0.1474, lr_0 = 1.3602e-04
Loss = 1.1306e-05, PNorm = 62.8508, GNorm = 0.1079, lr_0 = 1.3542e-04
Loss = 1.0907e-05, PNorm = 62.8517, GNorm = 0.1695, lr_0 = 1.3482e-04
Loss = 1.0830e-05, PNorm = 62.8531, GNorm = 0.0907, lr_0 = 1.3423e-04
Validation rmse logD = 0.562381
Validation R2 logD = 0.779735
Epoch 86
Train function
Loss = 7.8174e-06, PNorm = 62.8552, GNorm = 0.0842, lr_0 = 1.3357e-04
Loss = 1.2053e-05, PNorm = 62.8556, GNorm = 0.2050, lr_0 = 1.3298e-04
Loss = 1.0707e-05, PNorm = 62.8570, GNorm = 0.0637, lr_0 = 1.3239e-04
Loss = 1.0769e-05, PNorm = 62.8568, GNorm = 0.0905, lr_0 = 1.3181e-04
Loss = 1.5244e-05, PNorm = 62.8586, GNorm = 0.1485, lr_0 = 1.3123e-04
Loss = 1.0668e-05, PNorm = 62.8601, GNorm = 0.2601, lr_0 = 1.3065e-04
Validation rmse logD = 0.562074
Validation R2 logD = 0.779976
Epoch 87
Train function
Loss = 2.0753e-05, PNorm = 62.8625, GNorm = 0.0723, lr_0 = 1.3001e-04
Loss = 1.5938e-05, PNorm = 62.8637, GNorm = 0.1910, lr_0 = 1.2944e-04
Loss = 1.5924e-05, PNorm = 62.8644, GNorm = 0.0765, lr_0 = 1.2886e-04
Loss = 1.1925e-05, PNorm = 62.8658, GNorm = 0.1281, lr_0 = 1.2829e-04
Loss = 1.2224e-05, PNorm = 62.8667, GNorm = 0.1047, lr_0 = 1.2773e-04
Validation rmse logD = 0.562420
Validation R2 logD = 0.779705
Epoch 88
Train function
Loss = 8.3314e-06, PNorm = 62.8679, GNorm = 0.0991, lr_0 = 1.2710e-04
Loss = 7.4432e-06, PNorm = 62.8691, GNorm = 0.0708, lr_0 = 1.2654e-04
Loss = 1.0556e-05, PNorm = 62.8703, GNorm = 0.1622, lr_0 = 1.2598e-04
Loss = 1.5163e-05, PNorm = 62.8711, GNorm = 0.0673, lr_0 = 1.2542e-04
Loss = 1.1340e-05, PNorm = 62.8723, GNorm = 0.0452, lr_0 = 1.2487e-04
Validation rmse logD = 0.562216
Validation R2 logD = 0.779865
Epoch 89
Train function
Loss = 8.3869e-06, PNorm = 62.8732, GNorm = 0.1454, lr_0 = 1.2426e-04
Loss = 9.5359e-06, PNorm = 62.8746, GNorm = 0.0852, lr_0 = 1.2371e-04
Loss = 7.6489e-06, PNorm = 62.8759, GNorm = 0.0909, lr_0 = 1.2317e-04
Loss = 7.2286e-06, PNorm = 62.8765, GNorm = 0.0913, lr_0 = 1.2262e-04
Loss = 1.1570e-05, PNorm = 62.8776, GNorm = 0.1195, lr_0 = 1.2208e-04
Loss = 8.7055e-06, PNorm = 62.8791, GNorm = 0.0458, lr_0 = 1.2154e-04
Loss = 3.0647e-05, PNorm = 62.8792, GNorm = 0.1102, lr_0 = 1.2148e-04
Validation rmse logD = 0.562919
Validation R2 logD = 0.779314
Epoch 90
Train function
Loss = 5.7694e-06, PNorm = 62.8800, GNorm = 0.0641, lr_0 = 1.2095e-04
Loss = 7.4906e-06, PNorm = 62.8805, GNorm = 0.1325, lr_0 = 1.2041e-04
Loss = 1.2189e-05, PNorm = 62.8821, GNorm = 0.0576, lr_0 = 1.1988e-04
Loss = 7.3215e-06, PNorm = 62.8836, GNorm = 0.0716, lr_0 = 1.1935e-04
Loss = 9.7293e-06, PNorm = 62.8841, GNorm = 0.1386, lr_0 = 1.1882e-04
Validation rmse logD = 0.562410
Validation R2 logD = 0.779713
Epoch 91
Train function
Loss = 7.2306e-06, PNorm = 62.8849, GNorm = 0.0705, lr_0 = 1.1824e-04
Loss = 1.0284e-05, PNorm = 62.8855, GNorm = 0.0825, lr_0 = 1.1772e-04
Loss = 9.0564e-06, PNorm = 62.8865, GNorm = 0.1173, lr_0 = 1.1720e-04
Loss = 1.1735e-05, PNorm = 62.8873, GNorm = 0.2157, lr_0 = 1.1668e-04
Loss = 5.7521e-06, PNorm = 62.8881, GNorm = 0.0736, lr_0 = 1.1616e-04
Validation rmse logD = 0.562440
Validation R2 logD = 0.779689
Epoch 92
Train function
Loss = 1.0329e-05, PNorm = 62.8895, GNorm = 0.0929, lr_0 = 1.1565e-04
Loss = 8.9084e-06, PNorm = 62.8906, GNorm = 0.1700, lr_0 = 1.1514e-04
Loss = 6.1416e-06, PNorm = 62.8910, GNorm = 0.0674, lr_0 = 1.1463e-04
Loss = 8.8031e-06, PNorm = 62.8924, GNorm = 0.0881, lr_0 = 1.1412e-04
Loss = 6.4146e-06, PNorm = 62.8932, GNorm = 0.1224, lr_0 = 1.1362e-04
Loss = 9.0015e-06, PNorm = 62.8941, GNorm = 0.0874, lr_0 = 1.1312e-04
Loss = 2.6775e-05, PNorm = 62.8943, GNorm = 0.0901, lr_0 = 1.1307e-04
Validation rmse logD = 0.562365
Validation R2 logD = 0.779748
Epoch 93
Train function
Loss = 7.2390e-06, PNorm = 62.8964, GNorm = 0.0559, lr_0 = 1.1257e-04
Loss = 5.9433e-06, PNorm = 62.8974, GNorm = 0.0976, lr_0 = 1.1207e-04
Loss = 7.0819e-06, PNorm = 62.8978, GNorm = 0.0610, lr_0 = 1.1157e-04
Loss = 7.1911e-06, PNorm = 62.8985, GNorm = 0.1048, lr_0 = 1.1108e-04
Loss = 7.2222e-06, PNorm = 62.8991, GNorm = 0.0424, lr_0 = 1.1059e-04
Validation rmse logD = 0.562525
Validation R2 logD = 0.779623
Epoch 94
Train function
Loss = 5.5861e-06, PNorm = 62.8993, GNorm = 0.0422, lr_0 = 1.1005e-04
Loss = 6.4833e-06, PNorm = 62.9002, GNorm = 0.0597, lr_0 = 1.0956e-04
Loss = 5.7491e-06, PNorm = 62.9008, GNorm = 0.0634, lr_0 = 1.0908e-04
Loss = 6.2114e-06, PNorm = 62.9015, GNorm = 0.1138, lr_0 = 1.0860e-04
Loss = 7.6783e-06, PNorm = 62.9020, GNorm = 0.0457, lr_0 = 1.0811e-04
Validation rmse logD = 0.561918
Validation R2 logD = 0.780098
Epoch 95
Train function
Loss = 6.8297e-06, PNorm = 62.9027, GNorm = 0.1171, lr_0 = 1.0759e-04
Loss = 6.0619e-06, PNorm = 62.9028, GNorm = 0.0958, lr_0 = 1.0711e-04
Loss = 9.5042e-06, PNorm = 62.9038, GNorm = 0.1382, lr_0 = 1.0664e-04
Loss = 8.4404e-06, PNorm = 62.9044, GNorm = 0.0602, lr_0 = 1.0617e-04
Loss = 5.4054e-06, PNorm = 62.9056, GNorm = 0.0799, lr_0 = 1.0570e-04
Validation rmse logD = 0.562440
Validation R2 logD = 0.779689
Epoch 96
Train function
Loss = 1.0382e-05, PNorm = 62.9074, GNorm = 0.0634, lr_0 = 1.0518e-04
Loss = 5.5749e-06, PNorm = 62.9085, GNorm = 0.0479, lr_0 = 1.0472e-04
Loss = 3.8751e-06, PNorm = 62.9086, GNorm = 0.0437, lr_0 = 1.0426e-04
Loss = 4.9454e-06, PNorm = 62.9095, GNorm = 0.0373, lr_0 = 1.0379e-04
Loss = 6.3543e-06, PNorm = 62.9100, GNorm = 0.0821, lr_0 = 1.0333e-04
Loss = 9.2371e-06, PNorm = 62.9109, GNorm = 0.1779, lr_0 = 1.0288e-04
Validation rmse logD = 0.563658
Validation R2 logD = 0.778734
Epoch 97
Train function
Loss = 6.4848e-06, PNorm = 62.9116, GNorm = 0.0579, lr_0 = 1.0238e-04
Loss = 6.0230e-06, PNorm = 62.9123, GNorm = 0.0446, lr_0 = 1.0192e-04
Loss = 5.9462e-06, PNorm = 62.9131, GNorm = 0.0396, lr_0 = 1.0147e-04
Loss = 7.2259e-06, PNorm = 62.9137, GNorm = 0.0821, lr_0 = 1.0102e-04
Loss = 6.6737e-06, PNorm = 62.9149, GNorm = 0.0954, lr_0 = 1.0058e-04
Validation rmse logD = 0.564348
Validation R2 logD = 0.778192
Epoch 98
Train function
Loss = 3.8893e-06, PNorm = 62.9152, GNorm = 0.0414, lr_0 = 1.0009e-04
Loss = 5.5194e-06, PNorm = 62.9159, GNorm = 0.0590, lr_0 = 1.0000e-04
Loss = 6.2193e-06, PNorm = 62.9166, GNorm = 0.0839, lr_0 = 1.0000e-04
Loss = 7.6134e-06, PNorm = 62.9172, GNorm = 0.0455, lr_0 = 1.0000e-04
Loss = 3.7831e-06, PNorm = 62.9175, GNorm = 0.0551, lr_0 = 1.0000e-04
Validation rmse logD = 0.562321
Validation R2 logD = 0.779782
Epoch 99
Train function
Loss = 5.3039e-06, PNorm = 62.9185, GNorm = 0.1502, lr_0 = 1.0000e-04
Loss = 1.1058e-05, PNorm = 62.9195, GNorm = 0.0580, lr_0 = 1.0000e-04
Loss = 6.4282e-06, PNorm = 62.9201, GNorm = 0.1621, lr_0 = 1.0000e-04
Loss = 7.0671e-06, PNorm = 62.9213, GNorm = 0.0960, lr_0 = 1.0000e-04
Loss = 4.6509e-06, PNorm = 62.9215, GNorm = 0.0414, lr_0 = 1.0000e-04
Loss = 1.0143e-05, PNorm = 62.9221, GNorm = 0.2134, lr_0 = 1.0000e-04
Validation rmse logD = 0.561134
Validation R2 logD = 0.780711
Model 0 best validation rmse = 0.554234 on epoch 25
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.593107
Model 0 test R2 logD = 0.756705
Ensemble test rmse  logD= 0.593107
Ensemble test R2  logD= 0.756705
4-fold cross validation
	Seed 0 ==> test rmse = 0.594081
	Seed 0 ==> test R2 = 0.755905
	Seed 1 ==> test rmse = 0.613909
	Seed 1 ==> test R2 = 0.739339
	Seed 2 ==> test rmse = 0.603902
	Seed 2 ==> test R2 = 0.747768
	Seed 3 ==> test rmse = 0.593107
	Seed 3 ==> test R2 = 0.756705
Overall val rmse logD= 0.574721 +/- 0.012467
Overall val R2 logD = 0.768661 +/- 0.019339
Overall test rmse logD = 0.601250 +/- 0.008441
Overall test R2 logD = 0.749929 +/- 0.007043
Elapsed time = 1:40:02
