Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 1.9543e-02, PNorm = 52.9405, GNorm = 6.6682, lr_0 = 1.9340e-04
Loss = 1.7024e-02, PNorm = 52.9482, GNorm = 3.1405, lr_0 = 2.7830e-04
Loss = 1.6991e-02, PNorm = 52.9601, GNorm = 4.5283, lr_0 = 3.6321e-04
Loss = 1.5933e-02, PNorm = 52.9774, GNorm = 6.5582, lr_0 = 4.4811e-04
Loss = 1.5374e-02, PNorm = 53.0028, GNorm = 1.4055, lr_0 = 5.3302e-04
Validation rmse logD = 1.002609
Validation R2 logD = 0.287296
Validation rmse logP = 1.193301
Validation R2 logP = 0.386563
Epoch 1
Train function
Loss = 1.5121e-02, PNorm = 53.0341, GNorm = 3.8213, lr_0 = 6.2642e-04
Loss = 1.3589e-02, PNorm = 53.0694, GNorm = 4.2517, lr_0 = 7.1132e-04
Loss = 1.2235e-02, PNorm = 53.1141, GNorm = 2.1827, lr_0 = 7.9623e-04
Loss = 1.0962e-02, PNorm = 53.1649, GNorm = 4.7207, lr_0 = 8.8113e-04
Loss = 1.1342e-02, PNorm = 53.2173, GNorm = 1.8673, lr_0 = 9.6604e-04
Validation rmse logD = 0.870739
Validation R2 logD = 0.462446
Validation rmse logP = 0.917560
Validation R2 logP = 0.637307
Epoch 2
Train function
Loss = 1.0024e-02, PNorm = 53.2888, GNorm = 5.5262, lr_0 = 9.9690e-04
Loss = 9.7552e-03, PNorm = 53.3509, GNorm = 2.1200, lr_0 = 9.9249e-04
Loss = 9.1732e-03, PNorm = 53.4176, GNorm = 1.3354, lr_0 = 9.8810e-04
Loss = 1.0916e-02, PNorm = 53.4936, GNorm = 1.3091, lr_0 = 9.8373e-04
Loss = 1.0935e-02, PNorm = 53.5872, GNorm = 3.6608, lr_0 = 9.7938e-04
Validation rmse logD = 0.842598
Validation R2 logD = 0.496630
Validation rmse logP = 0.902609
Validation R2 logP = 0.649031
Epoch 3
Train function
Loss = 1.4972e-02, PNorm = 53.6887, GNorm = 4.7046, lr_0 = 9.7462e-04
Loss = 8.2177e-03, PNorm = 53.7788, GNorm = 2.7595, lr_0 = 9.7030e-04
Loss = 8.4282e-03, PNorm = 53.8914, GNorm = 1.3808, lr_0 = 9.6601e-04
Loss = 7.7652e-03, PNorm = 53.9854, GNorm = 1.4021, lr_0 = 9.6174e-04
Loss = 7.7742e-03, PNorm = 54.0803, GNorm = 1.4829, lr_0 = 9.5749e-04
Loss = 7.1130e-03, PNorm = 54.1693, GNorm = 4.0976, lr_0 = 9.5325e-04
Validation rmse logD = 0.715537
Validation R2 logD = 0.636997
Validation rmse logP = 0.766378
Validation R2 logP = 0.746979
Epoch 4
Train function
Loss = 7.2805e-03, PNorm = 54.2982, GNorm = 2.3837, lr_0 = 9.4861e-04
Loss = 6.4151e-03, PNorm = 54.3998, GNorm = 1.0044, lr_0 = 9.4442e-04
Loss = 6.1164e-03, PNorm = 54.5064, GNorm = 1.0385, lr_0 = 9.4024e-04
Loss = 6.1814e-03, PNorm = 54.6139, GNorm = 1.7217, lr_0 = 9.3608e-04
Loss = 7.7575e-03, PNorm = 54.7071, GNorm = 2.6791, lr_0 = 9.3194e-04
Validation rmse logD = 0.940876
Validation R2 logD = 0.372359
Validation rmse logP = 0.767894
Validation R2 logP = 0.745978
Epoch 5
Train function
Loss = 1.0913e-02, PNorm = 54.8255, GNorm = 4.3232, lr_0 = 9.2741e-04
Loss = 7.8161e-03, PNorm = 54.9455, GNorm = 2.3035, lr_0 = 9.2330e-04
Loss = 6.6956e-03, PNorm = 55.0615, GNorm = 1.4646, lr_0 = 9.1922e-04
Loss = 6.1943e-03, PNorm = 55.1405, GNorm = 2.7886, lr_0 = 9.1515e-04
Loss = 6.7009e-03, PNorm = 55.2268, GNorm = 1.1703, lr_0 = 9.1111e-04
Validation rmse logD = 0.666094
Validation R2 logD = 0.685430
Validation rmse logP = 0.692068
Validation R2 logP = 0.793667
Epoch 6
Train function
Loss = 4.1575e-03, PNorm = 55.3231, GNorm = 1.0528, lr_0 = 9.0667e-04
Loss = 5.9541e-03, PNorm = 55.4065, GNorm = 3.0835, lr_0 = 9.0266e-04
Loss = 5.7476e-03, PNorm = 55.4982, GNorm = 0.8292, lr_0 = 8.9867e-04
Loss = 6.2144e-03, PNorm = 55.5923, GNorm = 3.9587, lr_0 = 8.9469e-04
Loss = 5.2235e-03, PNorm = 55.6692, GNorm = 0.9026, lr_0 = 8.9074e-04
Loss = 5.2923e-03, PNorm = 55.7469, GNorm = 0.9537, lr_0 = 8.8680e-04
Validation rmse logD = 0.636313
Validation R2 logD = 0.712930
Validation rmse logP = 0.670997
Validation R2 logP = 0.806040
Epoch 7
Train function
Loss = 4.9672e-03, PNorm = 55.8465, GNorm = 3.2386, lr_0 = 8.8248e-04
Loss = 5.1738e-03, PNorm = 55.9260, GNorm = 1.2928, lr_0 = 8.7858e-04
Loss = 4.1373e-03, PNorm = 56.0054, GNorm = 0.8797, lr_0 = 8.7469e-04
Loss = 3.7863e-03, PNorm = 56.0925, GNorm = 1.1430, lr_0 = 8.7082e-04
Loss = 5.0187e-03, PNorm = 56.1686, GNorm = 1.6805, lr_0 = 8.6697e-04
Validation rmse logD = 0.614580
Validation R2 logD = 0.732205
Validation rmse logP = 0.691174
Validation R2 logP = 0.794200
Epoch 8
Train function
Loss = 3.3810e-03, PNorm = 56.2594, GNorm = 2.2943, lr_0 = 8.6276e-04
Loss = 4.9287e-03, PNorm = 56.3388, GNorm = 0.8927, lr_0 = 8.5894e-04
Loss = 3.9001e-03, PNorm = 56.4283, GNorm = 1.4793, lr_0 = 8.5514e-04
Loss = 4.0403e-03, PNorm = 56.5054, GNorm = 1.1930, lr_0 = 8.5136e-04
Loss = 4.4820e-03, PNorm = 56.5778, GNorm = 1.7293, lr_0 = 8.4759e-04
Validation rmse logD = 0.757472
Validation R2 logD = 0.593201
Validation rmse logP = 0.643369
Validation R2 logP = 0.821684
Epoch 9
Train function
Loss = 6.0952e-03, PNorm = 56.6575, GNorm = 2.7252, lr_0 = 8.4347e-04
Loss = 4.2871e-03, PNorm = 56.7449, GNorm = 1.9986, lr_0 = 8.3974e-04
Loss = 4.1466e-03, PNorm = 56.8386, GNorm = 1.0562, lr_0 = 8.3602e-04
Loss = 3.3242e-03, PNorm = 56.9111, GNorm = 1.9699, lr_0 = 8.3232e-04
Loss = 3.7174e-03, PNorm = 56.9687, GNorm = 2.3149, lr_0 = 8.2864e-04
Loss = 3.5891e-03, PNorm = 57.0469, GNorm = 0.6932, lr_0 = 8.2498e-04
Validation rmse logD = 0.651174
Validation R2 logD = 0.699365
Validation rmse logP = 0.610236
Validation R2 logP = 0.839577
Epoch 10
Train function
Loss = 3.2255e-03, PNorm = 57.1185, GNorm = 0.7342, lr_0 = 8.2133e-04
Loss = 3.5082e-03, PNorm = 57.1944, GNorm = 1.5049, lr_0 = 8.1770e-04
Loss = 3.4400e-03, PNorm = 57.2464, GNorm = 1.5898, lr_0 = 8.1408e-04
Loss = 3.1598e-03, PNorm = 57.3184, GNorm = 2.1494, lr_0 = 8.1048e-04
Loss = 3.1118e-03, PNorm = 57.3790, GNorm = 1.4201, lr_0 = 8.0689e-04
Validation rmse logD = 0.595826
Validation R2 logD = 0.748299
Validation rmse logP = 0.665742
Validation R2 logP = 0.809067
Epoch 11
Train function
Loss = 2.8889e-03, PNorm = 57.4487, GNorm = 1.7217, lr_0 = 8.0297e-04
Loss = 3.2776e-03, PNorm = 57.5138, GNorm = 0.8365, lr_0 = 7.9942e-04
Loss = 2.6379e-03, PNorm = 57.5976, GNorm = 1.2132, lr_0 = 7.9588e-04
Loss = 2.5946e-03, PNorm = 57.6595, GNorm = 1.3462, lr_0 = 7.9236e-04
Loss = 3.0501e-03, PNorm = 57.7215, GNorm = 1.3444, lr_0 = 7.8885e-04
Validation rmse logD = 0.597090
Validation R2 logD = 0.747230
Validation rmse logP = 0.622667
Validation R2 logP = 0.832975
Epoch 12
Train function
Loss = 1.5804e-03, PNorm = 57.7934, GNorm = 0.9574, lr_0 = 7.8502e-04
Loss = 2.7278e-03, PNorm = 57.8627, GNorm = 1.6371, lr_0 = 7.8154e-04
Loss = 2.4112e-03, PNorm = 57.9302, GNorm = 0.6621, lr_0 = 7.7809e-04
Loss = 2.0336e-03, PNorm = 57.9952, GNorm = 0.7819, lr_0 = 7.7465e-04
Loss = 2.1359e-03, PNorm = 58.0428, GNorm = 1.3534, lr_0 = 7.7122e-04
Loss = 2.7263e-03, PNorm = 58.0936, GNorm = 0.6188, lr_0 = 7.6781e-04
Loss = 1.0046e-02, PNorm = 58.0983, GNorm = 1.5174, lr_0 = 7.6747e-04
Validation rmse logD = 0.589580
Validation R2 logD = 0.753549
Validation rmse logP = 0.652360
Validation R2 logP = 0.816665
Epoch 13
Train function
Loss = 1.6912e-03, PNorm = 58.1603, GNorm = 0.7020, lr_0 = 7.6407e-04
Loss = 2.3119e-03, PNorm = 58.2291, GNorm = 0.9622, lr_0 = 7.6069e-04
Loss = 2.1832e-03, PNorm = 58.2838, GNorm = 0.8706, lr_0 = 7.5733e-04
Loss = 2.2116e-03, PNorm = 58.3363, GNorm = 1.2490, lr_0 = 7.5398e-04
Loss = 1.8861e-03, PNorm = 58.4022, GNorm = 0.8250, lr_0 = 7.5064e-04
Validation rmse logD = 0.590304
Validation R2 logD = 0.752943
Validation rmse logP = 0.615792
Validation R2 logP = 0.836643
Epoch 14
Train function
Loss = 1.5854e-03, PNorm = 58.4583, GNorm = 1.2750, lr_0 = 7.4699e-04
Loss = 1.7859e-03, PNorm = 58.5168, GNorm = 1.3711, lr_0 = 7.4369e-04
Loss = 1.8368e-03, PNorm = 58.5677, GNorm = 1.8799, lr_0 = 7.4040e-04
Loss = 1.9667e-03, PNorm = 58.6327, GNorm = 0.8399, lr_0 = 7.3712e-04
Loss = 1.8751e-03, PNorm = 58.6902, GNorm = 0.9297, lr_0 = 7.3386e-04
Validation rmse logD = 0.556060
Validation R2 logD = 0.780776
Validation rmse logP = 0.631417
Validation R2 logP = 0.828248
Epoch 15
Train function
Loss = 1.5014e-03, PNorm = 58.7722, GNorm = 1.1473, lr_0 = 7.3029e-04
Loss = 1.9009e-03, PNorm = 58.8219, GNorm = 1.3340, lr_0 = 7.2706e-04
Loss = 2.0271e-03, PNorm = 58.8756, GNorm = 0.9745, lr_0 = 7.2385e-04
Loss = 1.6450e-03, PNorm = 58.9375, GNorm = 1.4464, lr_0 = 7.2064e-04
Loss = 1.6709e-03, PNorm = 58.9979, GNorm = 0.6953, lr_0 = 7.1746e-04
Validation rmse logD = 0.560858
Validation R2 logD = 0.776976
Validation rmse logP = 0.642731
Validation R2 logP = 0.822037
Epoch 16
Train function
Loss = 1.5443e-03, PNorm = 59.0591, GNorm = 0.8066, lr_0 = 7.1397e-04
Loss = 1.3825e-03, PNorm = 59.1190, GNorm = 0.9521, lr_0 = 7.1081e-04
Loss = 1.3131e-03, PNorm = 59.1718, GNorm = 0.9944, lr_0 = 7.0766e-04
Loss = 1.5719e-03, PNorm = 59.2128, GNorm = 0.7789, lr_0 = 7.0453e-04
Loss = 1.4273e-03, PNorm = 59.2572, GNorm = 1.7473, lr_0 = 7.0142e-04
Loss = 1.4572e-03, PNorm = 59.2987, GNorm = 1.6393, lr_0 = 6.9831e-04
Validation rmse logD = 0.628553
Validation R2 logD = 0.719889
Validation rmse logP = 0.626765
Validation R2 logP = 0.830769
Epoch 17
Train function
Loss = 1.4657e-03, PNorm = 59.3608, GNorm = 1.4412, lr_0 = 6.9492e-04
Loss = 1.8615e-03, PNorm = 59.4276, GNorm = 0.6281, lr_0 = 6.9184e-04
Loss = 1.6916e-03, PNorm = 59.4922, GNorm = 1.3407, lr_0 = 6.8878e-04
Loss = 1.5485e-03, PNorm = 59.5565, GNorm = 1.6103, lr_0 = 6.8574e-04
Loss = 1.6044e-03, PNorm = 59.5902, GNorm = 2.6971, lr_0 = 6.8270e-04
Validation rmse logD = 0.580382
Validation R2 logD = 0.761179
Validation rmse logP = 0.619665
Validation R2 logP = 0.834582
Epoch 18
Train function
Loss = 1.4844e-03, PNorm = 59.6530, GNorm = 0.6642, lr_0 = 6.7938e-04
Loss = 1.1608e-03, PNorm = 59.7085, GNorm = 0.7676, lr_0 = 6.7638e-04
Loss = 1.0957e-03, PNorm = 59.7509, GNorm = 0.8555, lr_0 = 6.7338e-04
Loss = 1.1727e-03, PNorm = 59.7879, GNorm = 0.5514, lr_0 = 6.7041e-04
Loss = 1.2353e-03, PNorm = 59.8164, GNorm = 1.3616, lr_0 = 6.6744e-04
Validation rmse logD = 0.571932
Validation R2 logD = 0.768082
Validation rmse logP = 0.621911
Validation R2 logP = 0.833380
Epoch 19
Train function
Loss = 7.3628e-04, PNorm = 59.8581, GNorm = 0.6286, lr_0 = 6.6419e-04
Loss = 1.2629e-03, PNorm = 59.8957, GNorm = 2.0679, lr_0 = 6.6126e-04
Loss = 1.4259e-03, PNorm = 59.9547, GNorm = 1.4230, lr_0 = 6.5833e-04
Loss = 1.2400e-03, PNorm = 60.0003, GNorm = 0.5901, lr_0 = 6.5542e-04
Loss = 1.4322e-03, PNorm = 60.0441, GNorm = 2.7981, lr_0 = 6.5252e-04
Loss = 1.3034e-03, PNorm = 60.0988, GNorm = 1.6470, lr_0 = 6.4963e-04
Validation rmse logD = 0.590573
Validation R2 logD = 0.752717
Validation rmse logP = 0.647736
Validation R2 logP = 0.819255
Epoch 20
Train function
Loss = 1.2231e-03, PNorm = 60.1501, GNorm = 0.7699, lr_0 = 6.4676e-04
Loss = 1.0933e-03, PNorm = 60.2010, GNorm = 0.9700, lr_0 = 6.4390e-04
Loss = 1.0085e-03, PNorm = 60.2371, GNorm = 0.5526, lr_0 = 6.4105e-04
Loss = 9.4095e-04, PNorm = 60.2721, GNorm = 0.4904, lr_0 = 6.3822e-04
Loss = 9.6541e-04, PNorm = 60.3005, GNorm = 0.6024, lr_0 = 6.3539e-04
Validation rmse logD = 0.562087
Validation R2 logD = 0.775997
Validation rmse logP = 0.637202
Validation R2 logP = 0.825086
Epoch 21
Train function
Loss = 1.0158e-03, PNorm = 60.3365, GNorm = 0.5548, lr_0 = 6.3230e-04
Loss = 8.9122e-04, PNorm = 60.3848, GNorm = 0.4360, lr_0 = 6.2950e-04
Loss = 9.3747e-04, PNorm = 60.4313, GNorm = 0.6991, lr_0 = 6.2672e-04
Loss = 9.9864e-04, PNorm = 60.4620, GNorm = 0.6617, lr_0 = 6.2395e-04
Loss = 1.0326e-03, PNorm = 60.4987, GNorm = 0.9103, lr_0 = 6.2119e-04
Validation rmse logD = 0.576705
Validation R2 logD = 0.764195
Validation rmse logP = 0.643462
Validation R2 logP = 0.821633
Epoch 22
Train function
Loss = 7.9263e-04, PNorm = 60.5357, GNorm = 0.4561, lr_0 = 6.1817e-04
Loss = 1.0280e-03, PNorm = 60.5782, GNorm = 0.5384, lr_0 = 6.1543e-04
Loss = 8.0895e-04, PNorm = 60.6154, GNorm = 0.5964, lr_0 = 6.1271e-04
Loss = 6.6617e-04, PNorm = 60.6507, GNorm = 0.6191, lr_0 = 6.1000e-04
Loss = 8.5226e-04, PNorm = 60.6728, GNorm = 0.7608, lr_0 = 6.0730e-04
Loss = 7.4578e-04, PNorm = 60.6973, GNorm = 0.9440, lr_0 = 6.0461e-04
Validation rmse logD = 0.561600
Validation R2 logD = 0.776386
Validation rmse logP = 0.642841
Validation R2 logP = 0.821976
Epoch 23
Train function
Loss = 7.6710e-04, PNorm = 60.7355, GNorm = 0.8569, lr_0 = 6.0167e-04
Loss = 7.8051e-04, PNorm = 60.7681, GNorm = 0.6129, lr_0 = 5.9901e-04
Loss = 6.5508e-04, PNorm = 60.8060, GNorm = 0.7093, lr_0 = 5.9636e-04
Loss = 7.6934e-04, PNorm = 60.8298, GNorm = 0.7049, lr_0 = 5.9372e-04
Loss = 8.3699e-04, PNorm = 60.8579, GNorm = 0.6036, lr_0 = 5.9110e-04
Validation rmse logD = 0.558556
Validation R2 logD = 0.778803
Validation rmse logP = 0.630827
Validation R2 logP = 0.828568
Epoch 24
Train function
Loss = 6.2089e-04, PNorm = 60.8924, GNorm = 0.4089, lr_0 = 5.8822e-04
Loss = 6.7799e-04, PNorm = 60.9161, GNorm = 1.9733, lr_0 = 5.8562e-04
Loss = 8.0165e-04, PNorm = 60.9433, GNorm = 1.7004, lr_0 = 5.8303e-04
Loss = 6.6216e-04, PNorm = 60.9774, GNorm = 0.7100, lr_0 = 5.8045e-04
Loss = 6.0000e-04, PNorm = 61.0071, GNorm = 0.3773, lr_0 = 5.7788e-04
Validation rmse logD = 0.558592
Validation R2 logD = 0.778775
Validation rmse logP = 0.608402
Validation R2 logP = 0.840540
Epoch 25
Train function
Loss = 6.1393e-04, PNorm = 61.0309, GNorm = 0.6336, lr_0 = 5.7507e-04
Loss = 7.9194e-04, PNorm = 61.0712, GNorm = 0.4985, lr_0 = 5.7253e-04
Loss = 9.2838e-04, PNorm = 61.1021, GNorm = 0.9870, lr_0 = 5.7000e-04
Loss = 6.2313e-04, PNorm = 61.1361, GNorm = 0.5709, lr_0 = 5.6748e-04
Loss = 6.7325e-04, PNorm = 61.1675, GNorm = 0.5108, lr_0 = 5.6497e-04
Loss = 5.6489e-04, PNorm = 61.1877, GNorm = 0.5398, lr_0 = 5.6247e-04
Loss = 8.2904e-03, PNorm = 61.1899, GNorm = 1.2670, lr_0 = 5.6222e-04
Validation rmse logD = 0.565965
Validation R2 logD = 0.772896
Validation rmse logP = 0.639849
Validation R2 logP = 0.823630
Epoch 26
Train function
Loss = 5.8253e-04, PNorm = 61.2168, GNorm = 0.4379, lr_0 = 5.5973e-04
Loss = 4.9944e-04, PNorm = 61.2448, GNorm = 0.4921, lr_0 = 5.5725e-04
Loss = 5.1513e-04, PNorm = 61.2702, GNorm = 0.9442, lr_0 = 5.5479e-04
Loss = 4.6752e-04, PNorm = 61.2885, GNorm = 1.3370, lr_0 = 5.5233e-04
Loss = 6.1804e-04, PNorm = 61.3141, GNorm = 0.4200, lr_0 = 5.4989e-04
Validation rmse logD = 0.552256
Validation R2 logD = 0.783764
Validation rmse logP = 0.612861
Validation R2 logP = 0.838194
Epoch 27
Train function
Loss = 4.0927e-04, PNorm = 61.3397, GNorm = 0.2809, lr_0 = 5.4722e-04
Loss = 4.0483e-04, PNorm = 61.3585, GNorm = 0.2544, lr_0 = 5.4480e-04
Loss = 4.4062e-04, PNorm = 61.3720, GNorm = 0.4137, lr_0 = 5.4239e-04
Loss = 4.8088e-04, PNorm = 61.3881, GNorm = 0.9199, lr_0 = 5.3999e-04
Loss = 4.8409e-04, PNorm = 61.4092, GNorm = 0.6682, lr_0 = 5.3760e-04
Validation rmse logD = 0.566930
Validation R2 logD = 0.772121
Validation rmse logP = 0.616972
Validation R2 logP = 0.836016
Epoch 28
Train function
Loss = 5.3504e-04, PNorm = 61.4333, GNorm = 0.4652, lr_0 = 5.3498e-04
Loss = 3.7554e-04, PNorm = 61.4509, GNorm = 0.3239, lr_0 = 5.3262e-04
Loss = 4.0057e-04, PNorm = 61.4674, GNorm = 0.5849, lr_0 = 5.3026e-04
Loss = 3.5623e-04, PNorm = 61.4892, GNorm = 0.5494, lr_0 = 5.2792e-04
Loss = 3.6148e-04, PNorm = 61.5063, GNorm = 0.9545, lr_0 = 5.2558e-04
Validation rmse logD = 0.556921
Validation R2 logD = 0.780096
Validation rmse logP = 0.636472
Validation R2 logP = 0.825487
Epoch 29
Train function
Loss = 3.3718e-04, PNorm = 61.5293, GNorm = 0.7590, lr_0 = 5.2302e-04
Loss = 4.0567e-04, PNorm = 61.5507, GNorm = 0.6494, lr_0 = 5.2071e-04
Loss = 3.7837e-04, PNorm = 61.5657, GNorm = 0.4674, lr_0 = 5.1841e-04
Loss = 3.3672e-04, PNorm = 61.5815, GNorm = 0.2539, lr_0 = 5.1611e-04
Loss = 3.3933e-04, PNorm = 61.5967, GNorm = 0.7101, lr_0 = 5.1383e-04
Loss = 3.4969e-04, PNorm = 61.6133, GNorm = 0.4708, lr_0 = 5.1156e-04
Validation rmse logD = 0.542691
Validation R2 logD = 0.791190
Validation rmse logP = 0.623009
Validation R2 logP = 0.832791
Epoch 30
Train function
Loss = 3.9569e-04, PNorm = 61.6282, GNorm = 0.4090, lr_0 = 5.0930e-04
Loss = 3.3582e-04, PNorm = 61.6447, GNorm = 0.2536, lr_0 = 5.0704e-04
Loss = 3.8151e-04, PNorm = 61.6644, GNorm = 0.8143, lr_0 = 5.0480e-04
Loss = 3.5788e-04, PNorm = 61.6796, GNorm = 0.3903, lr_0 = 5.0257e-04
Loss = 3.0950e-04, PNorm = 61.6902, GNorm = 0.4458, lr_0 = 5.0034e-04
Validation rmse logD = 0.556027
Validation R2 logD = 0.780801
Validation rmse logP = 0.626640
Validation R2 logP = 0.830836
Epoch 31
Train function
Loss = 3.7350e-04, PNorm = 61.7144, GNorm = 0.9736, lr_0 = 4.9791e-04
Loss = 3.3099e-04, PNorm = 61.7303, GNorm = 1.2987, lr_0 = 4.9571e-04
Loss = 3.2129e-04, PNorm = 61.7491, GNorm = 0.4921, lr_0 = 4.9351e-04
Loss = 2.8994e-04, PNorm = 61.7631, GNorm = 0.3588, lr_0 = 4.9133e-04
Loss = 2.8091e-04, PNorm = 61.7773, GNorm = 0.4720, lr_0 = 4.8916e-04
Validation rmse logD = 0.550595
Validation R2 logD = 0.785063
Validation rmse logP = 0.634816
Validation R2 logP = 0.826394
Epoch 32
Train function
Loss = 3.0881e-04, PNorm = 61.7920, GNorm = 0.6075, lr_0 = 4.8678e-04
Loss = 2.7390e-04, PNorm = 61.8020, GNorm = 0.2731, lr_0 = 4.8463e-04
Loss = 3.3114e-04, PNorm = 61.8224, GNorm = 0.3897, lr_0 = 4.8248e-04
Loss = 3.5851e-04, PNorm = 61.8417, GNorm = 0.5302, lr_0 = 4.8035e-04
Loss = 3.0556e-04, PNorm = 61.8587, GNorm = 0.6154, lr_0 = 4.7822e-04
Loss = 3.3405e-04, PNorm = 61.8707, GNorm = 0.2906, lr_0 = 4.7611e-04
Validation rmse logD = 0.547865
Validation R2 logD = 0.787190
Validation rmse logP = 0.635698
Validation R2 logP = 0.825911
Epoch 33
Train function
Loss = 2.9587e-04, PNorm = 61.8900, GNorm = 0.9360, lr_0 = 4.7379e-04
Loss = 3.7539e-04, PNorm = 61.9012, GNorm = 0.5196, lr_0 = 4.7170e-04
Loss = 2.5610e-04, PNorm = 61.9128, GNorm = 0.4570, lr_0 = 4.6961e-04
Loss = 2.8806e-04, PNorm = 61.9271, GNorm = 0.4154, lr_0 = 4.6753e-04
Loss = 3.1246e-04, PNorm = 61.9431, GNorm = 0.7273, lr_0 = 4.6546e-04
Validation rmse logD = 0.554482
Validation R2 logD = 0.782018
Validation rmse logP = 0.625625
Validation R2 logP = 0.831384
Epoch 34
Train function
Loss = 2.6823e-04, PNorm = 61.9563, GNorm = 0.3966, lr_0 = 4.6320e-04
Loss = 2.6479e-04, PNorm = 61.9707, GNorm = 0.6418, lr_0 = 4.6115e-04
Loss = 2.5051e-04, PNorm = 61.9832, GNorm = 0.3460, lr_0 = 4.5911e-04
Loss = 2.5354e-04, PNorm = 62.0013, GNorm = 0.2320, lr_0 = 4.5708e-04
Loss = 2.6272e-04, PNorm = 62.0188, GNorm = 0.5150, lr_0 = 4.5506e-04
Validation rmse logD = 0.544543
Validation R2 logD = 0.789763
Validation rmse logP = 0.637267
Validation R2 logP = 0.825051
Epoch 35
Train function
Loss = 1.6914e-04, PNorm = 62.0292, GNorm = 0.3659, lr_0 = 4.5284e-04
Loss = 2.0765e-04, PNorm = 62.0455, GNorm = 0.3209, lr_0 = 4.5084e-04
Loss = 2.0242e-04, PNorm = 62.0534, GNorm = 0.6885, lr_0 = 4.4885e-04
Loss = 2.0612e-04, PNorm = 62.0669, GNorm = 0.6232, lr_0 = 4.4686e-04
Loss = 1.9089e-04, PNorm = 62.0796, GNorm = 0.2357, lr_0 = 4.4489e-04
Loss = 2.7328e-04, PNorm = 62.0881, GNorm = 0.8710, lr_0 = 4.4292e-04
Validation rmse logD = 0.548988
Validation R2 logD = 0.786316
Validation rmse logP = 0.618248
Validation R2 logP = 0.835337
Epoch 36
Train function
Loss = 2.4554e-04, PNorm = 62.1034, GNorm = 0.2575, lr_0 = 4.4076e-04
Loss = 2.5843e-04, PNorm = 62.1199, GNorm = 0.7002, lr_0 = 4.3881e-04
Loss = 2.8900e-04, PNorm = 62.1328, GNorm = 0.4560, lr_0 = 4.3687e-04
Loss = 2.2469e-04, PNorm = 62.1412, GNorm = 0.9987, lr_0 = 4.3494e-04
Loss = 2.0718e-04, PNorm = 62.1566, GNorm = 0.2763, lr_0 = 4.3302e-04
Validation rmse logD = 0.550542
Validation R2 logD = 0.785105
Validation rmse logP = 0.628411
Validation R2 logP = 0.829879
Epoch 37
Train function
Loss = 2.4749e-04, PNorm = 62.1684, GNorm = 0.3333, lr_0 = 4.3091e-04
Loss = 3.0189e-04, PNorm = 62.1842, GNorm = 0.4125, lr_0 = 4.2900e-04
Loss = 3.4235e-04, PNorm = 62.2019, GNorm = 0.3071, lr_0 = 4.2711e-04
Loss = 2.3954e-04, PNorm = 62.2188, GNorm = 0.3894, lr_0 = 4.2522e-04
Loss = 1.9698e-04, PNorm = 62.2287, GNorm = 0.3144, lr_0 = 4.2334e-04
Validation rmse logD = 0.540351
Validation R2 logD = 0.792987
Validation rmse logP = 0.635608
Validation R2 logP = 0.825960
Epoch 38
Train function
Loss = 1.5594e-04, PNorm = 62.2371, GNorm = 0.3161, lr_0 = 4.2128e-04
Loss = 1.9109e-04, PNorm = 62.2485, GNorm = 0.4892, lr_0 = 4.1941e-04
Loss = 1.8647e-04, PNorm = 62.2615, GNorm = 0.2785, lr_0 = 4.1756e-04
Loss = 1.9177e-04, PNorm = 62.2681, GNorm = 0.4997, lr_0 = 4.1571e-04
Loss = 1.9892e-04, PNorm = 62.2763, GNorm = 0.4001, lr_0 = 4.1387e-04
Loss = 1.9059e-04, PNorm = 62.2868, GNorm = 0.2033, lr_0 = 4.1204e-04
Loss = 2.3682e-03, PNorm = 62.2883, GNorm = 1.0691, lr_0 = 4.1186e-04
Validation rmse logD = 0.545028
Validation R2 logD = 0.789388
Validation rmse logP = 0.620217
Validation R2 logP = 0.834287
Epoch 39
Train function
Loss = 1.5046e-04, PNorm = 62.3036, GNorm = 0.3330, lr_0 = 4.1004e-04
Loss = 1.5721e-04, PNorm = 62.3146, GNorm = 0.2300, lr_0 = 4.0822e-04
Loss = 1.6809e-04, PNorm = 62.3240, GNorm = 0.5088, lr_0 = 4.0642e-04
Loss = 1.3233e-04, PNorm = 62.3296, GNorm = 0.4323, lr_0 = 4.0462e-04
Loss = 1.6709e-04, PNorm = 62.3374, GNorm = 0.3824, lr_0 = 4.0283e-04
Validation rmse logD = 0.552377
Validation R2 logD = 0.783670
Validation rmse logP = 0.620189
Validation R2 logP = 0.834302
Epoch 40
Train function
Loss = 2.5551e-04, PNorm = 62.3493, GNorm = 0.5803, lr_0 = 4.0105e-04
Loss = 1.7386e-04, PNorm = 62.3610, GNorm = 0.2814, lr_0 = 3.9927e-04
Loss = 1.8368e-04, PNorm = 62.3726, GNorm = 0.8547, lr_0 = 3.9751e-04
Loss = 1.7271e-04, PNorm = 62.3789, GNorm = 0.3045, lr_0 = 3.9575e-04
Loss = 1.5325e-04, PNorm = 62.3892, GNorm = 0.3495, lr_0 = 3.9400e-04
Validation rmse logD = 0.546175
Validation R2 logD = 0.788500
Validation rmse logP = 0.620157
Validation R2 logP = 0.834319
Epoch 41
Train function
Loss = 1.5601e-04, PNorm = 62.4037, GNorm = 0.3037, lr_0 = 3.9208e-04
Loss = 2.0605e-04, PNorm = 62.4176, GNorm = 0.3759, lr_0 = 3.9035e-04
Loss = 1.7293e-04, PNorm = 62.4300, GNorm = 0.6298, lr_0 = 3.8862e-04
Loss = 1.4620e-04, PNorm = 62.4404, GNorm = 0.3259, lr_0 = 3.8690e-04
Loss = 1.4840e-04, PNorm = 62.4525, GNorm = 0.5148, lr_0 = 3.8519e-04
Loss = 1.4885e-04, PNorm = 62.4581, GNorm = 0.6412, lr_0 = 3.8349e-04
Loss = 1.0155e-03, PNorm = 62.4586, GNorm = 0.8774, lr_0 = 3.8332e-04
Validation rmse logD = 0.548380
Validation R2 logD = 0.786789
Validation rmse logP = 0.615737
Validation R2 logP = 0.836672
Epoch 42
Train function
Loss = 1.7275e-04, PNorm = 62.4654, GNorm = 0.3289, lr_0 = 3.8162e-04
Loss = 1.6279e-04, PNorm = 62.4774, GNorm = 0.1667, lr_0 = 3.7993e-04
Loss = 1.2089e-04, PNorm = 62.4842, GNorm = 0.5451, lr_0 = 3.7825e-04
Loss = 1.3146e-04, PNorm = 62.4949, GNorm = 0.7645, lr_0 = 3.7658e-04
Loss = 1.2233e-04, PNorm = 62.5017, GNorm = 0.3880, lr_0 = 3.7491e-04
Validation rmse logD = 0.547945
Validation R2 logD = 0.787127
Validation rmse logP = 0.622500
Validation R2 logP = 0.833065
Epoch 43
Train function
Loss = 1.7078e-04, PNorm = 62.5130, GNorm = 0.4512, lr_0 = 3.7309e-04
Loss = 1.8882e-04, PNorm = 62.5220, GNorm = 0.5114, lr_0 = 3.7144e-04
Loss = 1.6308e-04, PNorm = 62.5316, GNorm = 0.3956, lr_0 = 3.6980e-04
Loss = 1.3999e-04, PNorm = 62.5398, GNorm = 0.3360, lr_0 = 3.6816e-04
Loss = 1.3164e-04, PNorm = 62.5472, GNorm = 0.3438, lr_0 = 3.6653e-04
Validation rmse logD = 0.545352
Validation R2 logD = 0.789137
Validation rmse logP = 0.624642
Validation R2 logP = 0.831914
Epoch 44
Train function
Loss = 9.7020e-05, PNorm = 62.5558, GNorm = 0.2728, lr_0 = 3.6475e-04
Loss = 1.0970e-04, PNorm = 62.5633, GNorm = 0.3503, lr_0 = 3.6314e-04
Loss = 1.0707e-04, PNorm = 62.5675, GNorm = 0.2083, lr_0 = 3.6153e-04
Loss = 1.0432e-04, PNorm = 62.5765, GNorm = 0.3445, lr_0 = 3.5993e-04
Loss = 1.0388e-04, PNorm = 62.5852, GNorm = 0.1574, lr_0 = 3.5834e-04
Validation rmse logD = 0.546195
Validation R2 logD = 0.788485
Validation rmse logP = 0.610064
Validation R2 logP = 0.839668
Epoch 45
Train function
Loss = 6.7079e-05, PNorm = 62.5916, GNorm = 0.2027, lr_0 = 3.5660e-04
Loss = 8.6188e-05, PNorm = 62.5964, GNorm = 0.1552, lr_0 = 3.5502e-04
Loss = 8.8820e-05, PNorm = 62.6012, GNorm = 0.1686, lr_0 = 3.5345e-04
Loss = 8.2717e-05, PNorm = 62.6062, GNorm = 0.4367, lr_0 = 3.5188e-04
Loss = 9.6833e-05, PNorm = 62.6107, GNorm = 0.2344, lr_0 = 3.5033e-04
Loss = 1.0102e-04, PNorm = 62.6172, GNorm = 0.1642, lr_0 = 3.4878e-04
Validation rmse logD = 0.540434
Validation R2 logD = 0.792923
Validation rmse logP = 0.619303
Validation R2 logP = 0.834775
Epoch 46
Train function
Loss = 7.1118e-05, PNorm = 62.6243, GNorm = 0.1285, lr_0 = 3.4708e-04
Loss = 7.6463e-05, PNorm = 62.6303, GNorm = 0.2187, lr_0 = 3.4555e-04
Loss = 7.3327e-05, PNorm = 62.6353, GNorm = 0.2055, lr_0 = 3.4402e-04
Loss = 8.9053e-05, PNorm = 62.6406, GNorm = 0.1383, lr_0 = 3.4250e-04
Loss = 7.1352e-05, PNorm = 62.6482, GNorm = 0.2707, lr_0 = 3.4098e-04
Validation rmse logD = 0.543796
Validation R2 logD = 0.790339
Validation rmse logP = 0.614764
Validation R2 logP = 0.837188
Epoch 47
Train function
Loss = 8.2660e-05, PNorm = 62.6551, GNorm = 0.6592, lr_0 = 3.3932e-04
Loss = 6.4569e-05, PNorm = 62.6595, GNorm = 0.1612, lr_0 = 3.3782e-04
Loss = 7.7992e-05, PNorm = 62.6663, GNorm = 0.1672, lr_0 = 3.3633e-04
Loss = 8.0134e-05, PNorm = 62.6719, GNorm = 0.3983, lr_0 = 3.3484e-04
Loss = 5.5937e-05, PNorm = 62.6762, GNorm = 0.1461, lr_0 = 3.3336e-04
Validation rmse logD = 0.543661
Validation R2 logD = 0.790443
Validation rmse logP = 0.620314
Validation R2 logP = 0.834235
Epoch 48
Train function
Loss = 5.0630e-05, PNorm = 62.6820, GNorm = 0.1674, lr_0 = 3.3174e-04
Loss = 7.0178e-05, PNorm = 62.6861, GNorm = 0.1801, lr_0 = 3.3027e-04
Loss = 6.7754e-05, PNorm = 62.6915, GNorm = 0.3711, lr_0 = 3.2881e-04
Loss = 8.9642e-05, PNorm = 62.6957, GNorm = 0.3863, lr_0 = 3.2735e-04
Loss = 7.2846e-05, PNorm = 62.7006, GNorm = 0.2905, lr_0 = 3.2591e-04
Loss = 7.8804e-05, PNorm = 62.7055, GNorm = 0.1652, lr_0 = 3.2446e-04
Validation rmse logD = 0.542837
Validation R2 logD = 0.791077
Validation rmse logP = 0.619689
Validation R2 logP = 0.834569
Epoch 49
Train function
Loss = 6.3813e-05, PNorm = 62.7137, GNorm = 0.1768, lr_0 = 3.2289e-04
Loss = 5.5646e-05, PNorm = 62.7201, GNorm = 0.2620, lr_0 = 3.2146e-04
Loss = 6.5077e-05, PNorm = 62.7232, GNorm = 0.1741, lr_0 = 3.2004e-04
Loss = 6.2503e-05, PNorm = 62.7280, GNorm = 0.2295, lr_0 = 3.1862e-04
Loss = 6.4281e-05, PNorm = 62.7336, GNorm = 0.1271, lr_0 = 3.1721e-04
Validation rmse logD = 0.542375
Validation R2 logD = 0.791433
Validation rmse logP = 0.622112
Validation R2 logP = 0.833272
Epoch 50
Train function
Loss = 5.4950e-05, PNorm = 62.7363, GNorm = 0.1743, lr_0 = 3.1581e-04
Loss = 6.9353e-05, PNorm = 62.7433, GNorm = 0.1697, lr_0 = 3.1441e-04
Loss = 6.7621e-05, PNorm = 62.7492, GNorm = 0.4176, lr_0 = 3.1302e-04
Loss = 5.5376e-05, PNorm = 62.7533, GNorm = 0.1115, lr_0 = 3.1164e-04
Loss = 6.7179e-05, PNorm = 62.7564, GNorm = 0.1719, lr_0 = 3.1026e-04
Validation rmse logD = 0.547953
Validation R2 logD = 0.787121
Validation rmse logP = 0.622887
Validation R2 logP = 0.832857
Epoch 51
Train function
Loss = 1.0732e-04, PNorm = 62.7608, GNorm = 0.7756, lr_0 = 3.0875e-04
Loss = 1.6361e-04, PNorm = 62.7688, GNorm = 0.3325, lr_0 = 3.0738e-04
Loss = 1.1092e-04, PNorm = 62.7755, GNorm = 0.1727, lr_0 = 3.0602e-04
Loss = 9.9982e-05, PNorm = 62.7851, GNorm = 0.3809, lr_0 = 3.0467e-04
Loss = 8.4568e-05, PNorm = 62.7917, GNorm = 0.1660, lr_0 = 3.0332e-04
Loss = 8.8618e-05, PNorm = 62.7975, GNorm = 0.1681, lr_0 = 3.0198e-04
Validation rmse logD = 0.546444
Validation R2 logD = 0.788292
Validation rmse logP = 0.617515
Validation R2 logP = 0.835728
Epoch 52
Train function
Loss = 8.0940e-05, PNorm = 62.8021, GNorm = 0.7385, lr_0 = 3.0051e-04
Loss = 6.7861e-05, PNorm = 62.8078, GNorm = 0.2246, lr_0 = 2.9918e-04
Loss = 7.3406e-05, PNorm = 62.8130, GNorm = 0.2677, lr_0 = 2.9786e-04
Loss = 5.9701e-05, PNorm = 62.8183, GNorm = 0.2060, lr_0 = 2.9654e-04
Loss = 5.6169e-05, PNorm = 62.8230, GNorm = 0.1564, lr_0 = 2.9523e-04
Validation rmse logD = 0.543393
Validation R2 logD = 0.790650
Validation rmse logP = 0.619406
Validation R2 logP = 0.834720
Epoch 53
Train function
Loss = 5.2077e-05, PNorm = 62.8291, GNorm = 0.1769, lr_0 = 2.9379e-04
Loss = 4.9890e-05, PNorm = 62.8323, GNorm = 0.1853, lr_0 = 2.9249e-04
Loss = 4.3646e-05, PNorm = 62.8349, GNorm = 0.1205, lr_0 = 2.9120e-04
Loss = 6.3685e-05, PNorm = 62.8380, GNorm = 0.2715, lr_0 = 2.8991e-04
Loss = 6.7729e-05, PNorm = 62.8429, GNorm = 0.4664, lr_0 = 2.8863e-04
Validation rmse logD = 0.544994
Validation R2 logD = 0.789414
Validation rmse logP = 0.615083
Validation R2 logP = 0.837019
Epoch 54
Train function
Loss = 6.3907e-05, PNorm = 62.8477, GNorm = 0.3984, lr_0 = 2.8722e-04
Loss = 5.1001e-05, PNorm = 62.8509, GNorm = 0.3548, lr_0 = 2.8595e-04
Loss = 4.7014e-05, PNorm = 62.8537, GNorm = 0.2319, lr_0 = 2.8469e-04
Loss = 4.5371e-05, PNorm = 62.8564, GNorm = 0.2345, lr_0 = 2.8343e-04
Loss = 4.5312e-05, PNorm = 62.8593, GNorm = 0.1676, lr_0 = 2.8218e-04
Loss = 5.0623e-05, PNorm = 62.8644, GNorm = 0.2710, lr_0 = 2.8093e-04
Loss = 2.1006e-03, PNorm = 62.8651, GNorm = 0.8695, lr_0 = 2.8080e-04
Validation rmse logD = 0.547546
Validation R2 logD = 0.787437
Validation rmse logP = 0.622010
Validation R2 logP = 0.833327
Epoch 55
Train function
Loss = 7.6365e-05, PNorm = 62.8713, GNorm = 0.2130, lr_0 = 2.7956e-04
Loss = 5.9120e-05, PNorm = 62.8775, GNorm = 0.1036, lr_0 = 2.7832e-04
Loss = 6.0148e-05, PNorm = 62.8810, GNorm = 0.1034, lr_0 = 2.7709e-04
Loss = 5.9092e-05, PNorm = 62.8864, GNorm = 0.1579, lr_0 = 2.7587e-04
Loss = 5.3339e-05, PNorm = 62.8908, GNorm = 0.1436, lr_0 = 2.7465e-04
Validation rmse logD = 0.542906
Validation R2 logD = 0.791024
Validation rmse logP = 0.621301
Validation R2 logP = 0.833707
Epoch 56
Train function
Loss = 3.6965e-05, PNorm = 62.8947, GNorm = 0.0944, lr_0 = 2.7331e-04
Loss = 4.0544e-05, PNorm = 62.8975, GNorm = 0.1282, lr_0 = 2.7210e-04
Loss = 4.9061e-05, PNorm = 62.9001, GNorm = 0.1314, lr_0 = 2.7090e-04
Loss = 4.4499e-05, PNorm = 62.9050, GNorm = 0.2673, lr_0 = 2.6970e-04
Loss = 4.7046e-05, PNorm = 62.9092, GNorm = 0.2746, lr_0 = 2.6851e-04
Validation rmse logD = 0.545760
Validation R2 logD = 0.788821
Validation rmse logP = 0.625062
Validation R2 logP = 0.831687
Epoch 57
Train function
Loss = 6.8455e-05, PNorm = 62.9139, GNorm = 0.2364, lr_0 = 2.6720e-04
Loss = 8.3025e-05, PNorm = 62.9200, GNorm = 0.1594, lr_0 = 2.6602e-04
Loss = 5.7551e-05, PNorm = 62.9241, GNorm = 0.2567, lr_0 = 2.6484e-04
Loss = 4.8488e-05, PNorm = 62.9277, GNorm = 0.0975, lr_0 = 2.6367e-04
Loss = 3.9136e-05, PNorm = 62.9325, GNorm = 0.1364, lr_0 = 2.6250e-04
Validation rmse logD = 0.544967
Validation R2 logD = 0.789435
Validation rmse logP = 0.620217
Validation R2 logP = 0.834287
Epoch 58
Train function
Loss = 3.6522e-05, PNorm = 62.9368, GNorm = 0.1317, lr_0 = 2.6123e-04
Loss = 4.4724e-05, PNorm = 62.9415, GNorm = 0.1646, lr_0 = 2.6007e-04
Loss = 5.3042e-05, PNorm = 62.9436, GNorm = 0.3069, lr_0 = 2.5892e-04
Loss = 5.5349e-05, PNorm = 62.9462, GNorm = 0.3050, lr_0 = 2.5778e-04
Loss = 4.5741e-05, PNorm = 62.9498, GNorm = 0.1379, lr_0 = 2.5664e-04
Loss = 4.8576e-05, PNorm = 62.9531, GNorm = 0.1117, lr_0 = 2.5550e-04
Validation rmse logD = 0.546101
Validation R2 logD = 0.788558
Validation rmse logP = 0.629450
Validation R2 logP = 0.829316
Epoch 59
Train function
Loss = 4.7128e-05, PNorm = 62.9594, GNorm = 0.4137, lr_0 = 2.5426e-04
Loss = 4.0499e-05, PNorm = 62.9618, GNorm = 0.1445, lr_0 = 2.5313e-04
Loss = 4.2379e-05, PNorm = 62.9628, GNorm = 0.1540, lr_0 = 2.5201e-04
Loss = 4.7083e-05, PNorm = 62.9661, GNorm = 0.1172, lr_0 = 2.5090e-04
Loss = 4.1847e-05, PNorm = 62.9698, GNorm = 0.2847, lr_0 = 2.4979e-04
Validation rmse logD = 0.547973
Validation R2 logD = 0.787106
Validation rmse logP = 0.624830
Validation R2 logP = 0.831813
Epoch 60
Train function
Loss = 4.5811e-05, PNorm = 62.9733, GNorm = 0.1622, lr_0 = 2.4868e-04
Loss = 4.3510e-05, PNorm = 62.9737, GNorm = 0.1449, lr_0 = 2.4758e-04
Loss = 4.4506e-05, PNorm = 62.9777, GNorm = 0.2906, lr_0 = 2.4649e-04
Loss = 3.6996e-05, PNorm = 62.9828, GNorm = 0.1828, lr_0 = 2.4540e-04
Loss = 3.8694e-05, PNorm = 62.9855, GNorm = 0.1034, lr_0 = 2.4431e-04
Validation rmse logD = 0.548012
Validation R2 logD = 0.787075
Validation rmse logP = 0.622489
Validation R2 logP = 0.833070
Epoch 61
Train function
Loss = 6.0337e-05, PNorm = 62.9879, GNorm = 0.4933, lr_0 = 2.4313e-04
Loss = 7.0177e-05, PNorm = 62.9908, GNorm = 0.5548, lr_0 = 2.4205e-04
Loss = 4.2956e-05, PNorm = 62.9952, GNorm = 0.1147, lr_0 = 2.4098e-04
Loss = 4.1467e-05, PNorm = 62.9988, GNorm = 0.1186, lr_0 = 2.3991e-04
Loss = 3.2232e-05, PNorm = 63.0037, GNorm = 0.2274, lr_0 = 2.3885e-04
Loss = 2.8465e-05, PNorm = 63.0062, GNorm = 0.1370, lr_0 = 2.3780e-04
Validation rmse logD = 0.543675
Validation R2 logD = 0.790432
Validation rmse logP = 0.619816
Validation R2 logP = 0.834501
Epoch 62
Train function
Loss = 3.3372e-05, PNorm = 63.0090, GNorm = 0.1774, lr_0 = 2.3664e-04
Loss = 3.1776e-05, PNorm = 63.0113, GNorm = 0.0875, lr_0 = 2.3559e-04
Loss = 3.3666e-05, PNorm = 63.0125, GNorm = 0.1992, lr_0 = 2.3455e-04
Loss = 4.0285e-05, PNorm = 63.0162, GNorm = 0.1699, lr_0 = 2.3351e-04
Loss = 3.3608e-05, PNorm = 63.0185, GNorm = 0.2933, lr_0 = 2.3248e-04
Validation rmse logD = 0.545324
Validation R2 logD = 0.789159
Validation rmse logP = 0.619028
Validation R2 logP = 0.834921
Epoch 63
Train function
Loss = 2.6884e-05, PNorm = 63.0240, GNorm = 0.1093, lr_0 = 2.3135e-04
Loss = 2.5259e-05, PNorm = 63.0273, GNorm = 0.0857, lr_0 = 2.3033e-04
Loss = 7.4391e-05, PNorm = 63.0255, GNorm = 0.1212, lr_0 = 2.2931e-04
Loss = 3.7865e-05, PNorm = 63.0296, GNorm = 0.1832, lr_0 = 2.2829e-04
Loss = 3.7664e-05, PNorm = 63.0344, GNorm = 0.1557, lr_0 = 2.2728e-04
Validation rmse logD = 0.545946
Validation R2 logD = 0.788678
Validation rmse logP = 0.623126
Validation R2 logP = 0.832729
Epoch 64
Train function
Loss = 3.1382e-05, PNorm = 63.0384, GNorm = 0.2633, lr_0 = 2.2618e-04
Loss = 3.4582e-05, PNorm = 63.0414, GNorm = 0.2557, lr_0 = 2.2518e-04
Loss = 3.6240e-05, PNorm = 63.0443, GNorm = 0.3239, lr_0 = 2.2418e-04
Loss = 3.9455e-05, PNorm = 63.0477, GNorm = 0.1433, lr_0 = 2.2319e-04
Loss = 2.8583e-05, PNorm = 63.0497, GNorm = 0.0870, lr_0 = 2.2220e-04
Loss = 3.3465e-05, PNorm = 63.0523, GNorm = 0.1520, lr_0 = 2.2122e-04
Validation rmse logD = 0.545271
Validation R2 logD = 0.789200
Validation rmse logP = 0.628079
Validation R2 logP = 0.830059
Epoch 65
Train function
Loss = 2.2053e-05, PNorm = 63.0561, GNorm = 0.1107, lr_0 = 2.2014e-04
Loss = 3.0369e-05, PNorm = 63.0578, GNorm = 0.1455, lr_0 = 2.1917e-04
Loss = 2.4182e-05, PNorm = 63.0605, GNorm = 0.1299, lr_0 = 2.1820e-04
Loss = 2.6363e-05, PNorm = 63.0626, GNorm = 0.2112, lr_0 = 2.1723e-04
Loss = 2.4824e-05, PNorm = 63.0652, GNorm = 0.1885, lr_0 = 2.1627e-04
Validation rmse logD = 0.547484
Validation R2 logD = 0.787485
Validation rmse logP = 0.622682
Validation R2 logP = 0.832967
Epoch 66
Train function
Loss = 2.2117e-05, PNorm = 63.0676, GNorm = 0.1570, lr_0 = 2.1522e-04
Loss = 2.9636e-05, PNorm = 63.0687, GNorm = 0.1541, lr_0 = 2.1427e-04
Loss = 2.3490e-05, PNorm = 63.0699, GNorm = 0.2248, lr_0 = 2.1332e-04
Loss = 2.2580e-05, PNorm = 63.0719, GNorm = 0.1165, lr_0 = 2.1238e-04
Loss = 2.1076e-05, PNorm = 63.0738, GNorm = 0.0779, lr_0 = 2.1144e-04
Validation rmse logD = 0.546726
Validation R2 logD = 0.788073
Validation rmse logP = 0.619642
Validation R2 logP = 0.834594
Epoch 67
Train function
Loss = 2.8500e-05, PNorm = 63.0760, GNorm = 0.1246, lr_0 = 2.1041e-04
Loss = 1.7103e-05, PNorm = 63.0786, GNorm = 0.1193, lr_0 = 2.0948e-04
Loss = 2.5276e-05, PNorm = 63.0806, GNorm = 0.0688, lr_0 = 2.0855e-04
Loss = 2.3472e-05, PNorm = 63.0826, GNorm = 0.3732, lr_0 = 2.0763e-04
Loss = 2.1796e-05, PNorm = 63.0849, GNorm = 0.1008, lr_0 = 2.0671e-04
Loss = 2.0968e-05, PNorm = 63.0879, GNorm = 0.0769, lr_0 = 2.0580e-04
Loss = 4.2517e-04, PNorm = 63.0883, GNorm = 0.5952, lr_0 = 2.0571e-04
Validation rmse logD = 0.546484
Validation R2 logD = 0.788261
Validation rmse logP = 0.620934
Validation R2 logP = 0.833904
Epoch 68
Train function
Loss = 3.2569e-05, PNorm = 63.0909, GNorm = 0.1123, lr_0 = 2.0480e-04
Loss = 2.3781e-05, PNorm = 63.0938, GNorm = 0.1058, lr_0 = 2.0389e-04
Loss = 1.8274e-05, PNorm = 63.0955, GNorm = 0.0937, lr_0 = 2.0299e-04
Loss = 1.8156e-05, PNorm = 63.0961, GNorm = 0.1444, lr_0 = 2.0209e-04
Loss = 2.4141e-05, PNorm = 63.0984, GNorm = 0.1518, lr_0 = 2.0120e-04
Validation rmse logD = 0.544922
Validation R2 logD = 0.789470
Validation rmse logP = 0.622082
Validation R2 logP = 0.833289
Epoch 69
Train function
Loss = 1.8486e-05, PNorm = 63.1007, GNorm = 0.1152, lr_0 = 2.0022e-04
Loss = 1.5679e-05, PNorm = 63.1016, GNorm = 0.1549, lr_0 = 1.9933e-04
Loss = 1.3852e-05, PNorm = 63.1021, GNorm = 0.1146, lr_0 = 1.9845e-04
Loss = 1.7664e-05, PNorm = 63.1032, GNorm = 0.1096, lr_0 = 1.9757e-04
Loss = 2.1067e-05, PNorm = 63.1053, GNorm = 0.1098, lr_0 = 1.9670e-04
Validation rmse logD = 0.545312
Validation R2 logD = 0.789168
Validation rmse logP = 0.628178
Validation R2 logP = 0.830005
Epoch 70
Train function
Loss = 1.4735e-05, PNorm = 63.1089, GNorm = 0.1000, lr_0 = 1.9583e-04
Loss = 1.8231e-05, PNorm = 63.1117, GNorm = 0.1059, lr_0 = 1.9496e-04
Loss = 1.6373e-05, PNorm = 63.1128, GNorm = 0.1132, lr_0 = 1.9410e-04
Loss = 1.7350e-05, PNorm = 63.1133, GNorm = 0.0903, lr_0 = 1.9324e-04
Loss = 1.5422e-05, PNorm = 63.1157, GNorm = 0.0588, lr_0 = 1.9239e-04
Loss = 1.7533e-05, PNorm = 63.1171, GNorm = 0.2119, lr_0 = 1.9154e-04
Loss = 7.4620e-05, PNorm = 63.1173, GNorm = 0.1598, lr_0 = 1.9145e-04
Validation rmse logD = 0.546521
Validation R2 logD = 0.788233
Validation rmse logP = 0.623123
Validation R2 logP = 0.832730
Epoch 71
Train function
Loss = 1.3569e-05, PNorm = 63.1193, GNorm = 0.2244, lr_0 = 1.9060e-04
Loss = 1.5324e-05, PNorm = 63.1219, GNorm = 0.1716, lr_0 = 1.8976e-04
Loss = 1.3164e-05, PNorm = 63.1231, GNorm = 0.1617, lr_0 = 1.8892e-04
Loss = 1.4268e-05, PNorm = 63.1248, GNorm = 0.1045, lr_0 = 1.8809e-04
Loss = 1.5373e-05, PNorm = 63.1269, GNorm = 0.2074, lr_0 = 1.8725e-04
Validation rmse logD = 0.546120
Validation R2 logD = 0.788543
Validation rmse logP = 0.622312
Validation R2 logP = 0.833166
Epoch 72
Train function
Loss = 1.0665e-05, PNorm = 63.1276, GNorm = 0.0539, lr_0 = 1.8634e-04
Loss = 1.2082e-05, PNorm = 63.1289, GNorm = 0.0605, lr_0 = 1.8552e-04
Loss = 1.3162e-05, PNorm = 63.1309, GNorm = 0.0703, lr_0 = 1.8470e-04
Loss = 1.2729e-05, PNorm = 63.1322, GNorm = 0.2482, lr_0 = 1.8388e-04
Loss = 1.2117e-05, PNorm = 63.1330, GNorm = 0.0600, lr_0 = 1.8307e-04
Validation rmse logD = 0.545729
Validation R2 logD = 0.788846
Validation rmse logP = 0.619402
Validation R2 logP = 0.834722
Epoch 73
Train function
Loss = 9.9216e-06, PNorm = 63.1342, GNorm = 0.1063, lr_0 = 1.8218e-04
Loss = 8.7326e-06, PNorm = 63.1357, GNorm = 0.0694, lr_0 = 1.8137e-04
Loss = 1.0606e-05, PNorm = 63.1369, GNorm = 0.1414, lr_0 = 1.8057e-04
Loss = 1.1941e-05, PNorm = 63.1378, GNorm = 0.0468, lr_0 = 1.7977e-04
Loss = 1.3401e-05, PNorm = 63.1392, GNorm = 0.0501, lr_0 = 1.7897e-04
Validation rmse logD = 0.546880
Validation R2 logD = 0.787954
Validation rmse logP = 0.623657
Validation R2 logP = 0.832443
Epoch 74
Train function
Loss = 1.9082e-05, PNorm = 63.1407, GNorm = 0.2298, lr_0 = 1.7810e-04
Loss = 2.2591e-05, PNorm = 63.1439, GNorm = 0.2034, lr_0 = 1.7732e-04
Loss = 1.5280e-05, PNorm = 63.1459, GNorm = 0.0838, lr_0 = 1.7653e-04
Loss = 1.0889e-05, PNorm = 63.1475, GNorm = 0.1105, lr_0 = 1.7575e-04
Loss = 1.3887e-05, PNorm = 63.1493, GNorm = 0.0982, lr_0 = 1.7497e-04
Loss = 1.2085e-05, PNorm = 63.1506, GNorm = 0.0724, lr_0 = 1.7420e-04
Validation rmse logD = 0.547250
Validation R2 logD = 0.787667
Validation rmse logP = 0.622589
Validation R2 logP = 0.833017
Epoch 75
Train function
Loss = 9.5530e-06, PNorm = 63.1511, GNorm = 0.0580, lr_0 = 1.7335e-04
Loss = 9.7232e-06, PNorm = 63.1522, GNorm = 0.0884, lr_0 = 1.7259e-04
Loss = 1.0322e-05, PNorm = 63.1531, GNorm = 0.1027, lr_0 = 1.7182e-04
Loss = 1.0282e-05, PNorm = 63.1545, GNorm = 0.1083, lr_0 = 1.7106e-04
Loss = 1.1957e-05, PNorm = 63.1555, GNorm = 0.0999, lr_0 = 1.7031e-04
Validation rmse logD = 0.547363
Validation R2 logD = 0.787579
Validation rmse logP = 0.623669
Validation R2 logP = 0.832437
Epoch 76
Train function
Loss = 1.2521e-05, PNorm = 63.1579, GNorm = 0.0918, lr_0 = 1.6948e-04
Loss = 1.0890e-05, PNorm = 63.1591, GNorm = 0.1351, lr_0 = 1.6873e-04
Loss = 1.0222e-05, PNorm = 63.1608, GNorm = 0.0596, lr_0 = 1.6798e-04
Loss = 1.0153e-05, PNorm = 63.1616, GNorm = 0.0736, lr_0 = 1.6724e-04
Loss = 1.0288e-05, PNorm = 63.1631, GNorm = 0.0833, lr_0 = 1.6650e-04
Validation rmse logD = 0.547026
Validation R2 logD = 0.787841
Validation rmse logP = 0.623235
Validation R2 logP = 0.832670
Epoch 77
Train function
Loss = 1.1282e-05, PNorm = 63.1642, GNorm = 0.1081, lr_0 = 1.6569e-04
Loss = 8.7393e-06, PNorm = 63.1657, GNorm = 0.0648, lr_0 = 1.6496e-04
Loss = 1.2873e-05, PNorm = 63.1670, GNorm = 0.1264, lr_0 = 1.6423e-04
Loss = 1.3046e-05, PNorm = 63.1679, GNorm = 0.0735, lr_0 = 1.6350e-04
Loss = 1.0123e-05, PNorm = 63.1687, GNorm = 0.0734, lr_0 = 1.6278e-04
Loss = 1.1736e-05, PNorm = 63.1710, GNorm = 0.1147, lr_0 = 1.6206e-04
Validation rmse logD = 0.546928
Validation R2 logD = 0.787916
Validation rmse logP = 0.622930
Validation R2 logP = 0.832834
Epoch 78
Train function
Loss = 9.9341e-06, PNorm = 63.1718, GNorm = 0.1298, lr_0 = 1.6127e-04
Loss = 9.3527e-06, PNorm = 63.1723, GNorm = 0.0553, lr_0 = 1.6055e-04
Loss = 1.0502e-05, PNorm = 63.1734, GNorm = 0.1599, lr_0 = 1.5984e-04
Loss = 1.0812e-05, PNorm = 63.1745, GNorm = 0.0493, lr_0 = 1.5914e-04
Loss = 8.0086e-06, PNorm = 63.1756, GNorm = 0.0533, lr_0 = 1.5843e-04
Validation rmse logD = 0.546358
Validation R2 logD = 0.788359
Validation rmse logP = 0.622499
Validation R2 logP = 0.833065
Epoch 79
Train function
Loss = 7.4000e-06, PNorm = 63.1767, GNorm = 0.1253, lr_0 = 1.5766e-04
Loss = 8.4922e-06, PNorm = 63.1774, GNorm = 0.1181, lr_0 = 1.5697e-04
Loss = 8.6453e-06, PNorm = 63.1786, GNorm = 0.1057, lr_0 = 1.5627e-04
Loss = 1.1522e-05, PNorm = 63.1798, GNorm = 0.2399, lr_0 = 1.5558e-04
Loss = 8.2821e-06, PNorm = 63.1812, GNorm = 0.0572, lr_0 = 1.5489e-04
Validation rmse logD = 0.546766
Validation R2 logD = 0.788042
Validation rmse logP = 0.623233
Validation R2 logP = 0.832671
Epoch 80
Train function
Loss = 8.5057e-06, PNorm = 63.1826, GNorm = 0.1411, lr_0 = 1.5421e-04
Loss = 9.7748e-06, PNorm = 63.1836, GNorm = 0.1292, lr_0 = 1.5352e-04
Loss = 7.4457e-06, PNorm = 63.1847, GNorm = 0.0668, lr_0 = 1.5284e-04
Loss = 9.3706e-06, PNorm = 63.1860, GNorm = 0.1098, lr_0 = 1.5217e-04
Loss = 7.2717e-06, PNorm = 63.1871, GNorm = 0.0735, lr_0 = 1.5150e-04
Loss = 6.7793e-06, PNorm = 63.1881, GNorm = 0.0457, lr_0 = 1.5083e-04
Validation rmse logD = 0.546655
Validation R2 logD = 0.788129
Validation rmse logP = 0.622354
Validation R2 logP = 0.833143
Epoch 81
Train function
Loss = 8.4845e-06, PNorm = 63.1893, GNorm = 0.0525, lr_0 = 1.5009e-04
Loss = 6.4955e-06, PNorm = 63.1906, GNorm = 0.0572, lr_0 = 1.4943e-04
Loss = 7.3461e-06, PNorm = 63.1912, GNorm = 0.0403, lr_0 = 1.4877e-04
Loss = 6.4413e-06, PNorm = 63.1919, GNorm = 0.0352, lr_0 = 1.4811e-04
Loss = 7.6034e-06, PNorm = 63.1925, GNorm = 0.0796, lr_0 = 1.4745e-04
Validation rmse logD = 0.546693
Validation R2 logD = 0.788099
Validation rmse logP = 0.620890
Validation R2 logP = 0.833927
Epoch 82
Train function
Loss = 6.8107e-06, PNorm = 63.1933, GNorm = 0.0365, lr_0 = 1.4674e-04
Loss = 6.1712e-06, PNorm = 63.1943, GNorm = 0.0432, lr_0 = 1.4609e-04
Loss = 5.5160e-06, PNorm = 63.1951, GNorm = 0.0524, lr_0 = 1.4544e-04
Loss = 7.3873e-06, PNorm = 63.1959, GNorm = 0.1206, lr_0 = 1.4480e-04
Loss = 6.7434e-06, PNorm = 63.1973, GNorm = 0.0622, lr_0 = 1.4416e-04
Validation rmse logD = 0.547358
Validation R2 logD = 0.787583
Validation rmse logP = 0.622531
Validation R2 logP = 0.833048
Epoch 83
Train function
Loss = 5.0782e-06, PNorm = 63.1978, GNorm = 0.0642, lr_0 = 1.4346e-04
Loss = 5.3707e-06, PNorm = 63.1985, GNorm = 0.1226, lr_0 = 1.4282e-04
Loss = 5.3896e-06, PNorm = 63.1996, GNorm = 0.0575, lr_0 = 1.4219e-04
Loss = 6.3717e-06, PNorm = 63.2006, GNorm = 0.1186, lr_0 = 1.4156e-04
Loss = 6.0183e-06, PNorm = 63.2012, GNorm = 0.0594, lr_0 = 1.4093e-04
Loss = 7.0745e-06, PNorm = 63.2022, GNorm = 0.0352, lr_0 = 1.4031e-04
Loss = 4.5418e-05, PNorm = 63.2022, GNorm = 0.1279, lr_0 = 1.4025e-04
Validation rmse logD = 0.546764
Validation R2 logD = 0.788044
Validation rmse logP = 0.622396
Validation R2 logP = 0.833120
Epoch 84
Train function
Loss = 8.2750e-06, PNorm = 63.2035, GNorm = 0.0850, lr_0 = 1.3963e-04
Loss = 5.8588e-06, PNorm = 63.2043, GNorm = 0.0960, lr_0 = 1.3901e-04
Loss = 8.2751e-06, PNorm = 63.2052, GNorm = 0.1553, lr_0 = 1.3840e-04
Loss = 7.7318e-06, PNorm = 63.2065, GNorm = 0.1449, lr_0 = 1.3778e-04
Loss = 7.3533e-06, PNorm = 63.2075, GNorm = 0.0582, lr_0 = 1.3717e-04
Validation rmse logD = 0.546717
Validation R2 logD = 0.788080
Validation rmse logP = 0.621488
Validation R2 logP = 0.833607
Epoch 85
Train function
Loss = 9.8843e-06, PNorm = 63.2092, GNorm = 0.0988, lr_0 = 1.3651e-04
Loss = 1.1354e-05, PNorm = 63.2107, GNorm = 0.0733, lr_0 = 1.3590e-04
Loss = 1.0379e-05, PNorm = 63.2117, GNorm = 0.1394, lr_0 = 1.3530e-04
Loss = 8.6898e-06, PNorm = 63.2128, GNorm = 0.1076, lr_0 = 1.3470e-04
Loss = 7.8994e-06, PNorm = 63.2138, GNorm = 0.0598, lr_0 = 1.3411e-04
Validation rmse logD = 0.546341
Validation R2 logD = 0.788372
Validation rmse logP = 0.623252
Validation R2 logP = 0.832661
Epoch 86
Train function
Loss = 8.9113e-06, PNorm = 63.2140, GNorm = 0.1045, lr_0 = 1.3346e-04
Loss = 7.5563e-06, PNorm = 63.2154, GNorm = 0.0629, lr_0 = 1.3287e-04
Loss = 7.2931e-06, PNorm = 63.2167, GNorm = 0.0699, lr_0 = 1.3228e-04
Loss = 6.9478e-06, PNorm = 63.2178, GNorm = 0.0497, lr_0 = 1.3169e-04
Loss = 5.9900e-06, PNorm = 63.2186, GNorm = 0.0584, lr_0 = 1.3111e-04
Validation rmse logD = 0.546807
Validation R2 logD = 0.788011
Validation rmse logP = 0.624505
Validation R2 logP = 0.831988
Epoch 87
Train function
Loss = 6.3453e-06, PNorm = 63.2194, GNorm = 0.1410, lr_0 = 1.3047e-04
Loss = 6.3637e-06, PNorm = 63.2198, GNorm = 0.0475, lr_0 = 1.2990e-04
Loss = 5.4737e-06, PNorm = 63.2203, GNorm = 0.0349, lr_0 = 1.2932e-04
Loss = 4.6168e-06, PNorm = 63.2210, GNorm = 0.0305, lr_0 = 1.2875e-04
Loss = 5.9595e-06, PNorm = 63.2218, GNorm = 0.0629, lr_0 = 1.2818e-04
Loss = 6.5586e-06, PNorm = 63.2225, GNorm = 0.0488, lr_0 = 1.2761e-04
Validation rmse logD = 0.547098
Validation R2 logD = 0.787785
Validation rmse logP = 0.620719
Validation R2 logP = 0.834018
Epoch 88
Train function
Loss = 4.3866e-06, PNorm = 63.2232, GNorm = 0.0588, lr_0 = 1.2699e-04
Loss = 5.4495e-06, PNorm = 63.2238, GNorm = 0.0567, lr_0 = 1.2643e-04
Loss = 5.3913e-06, PNorm = 63.2249, GNorm = 0.1126, lr_0 = 1.2587e-04
Loss = 5.6562e-06, PNorm = 63.2257, GNorm = 0.0815, lr_0 = 1.2531e-04
Loss = 4.2434e-06, PNorm = 63.2262, GNorm = 0.0426, lr_0 = 1.2476e-04
Validation rmse logD = 0.547129
Validation R2 logD = 0.787761
Validation rmse logP = 0.624010
Validation R2 logP = 0.832254
Epoch 89
Train function
Loss = 6.4495e-06, PNorm = 63.2267, GNorm = 0.1439, lr_0 = 1.2415e-04
Loss = 7.3534e-06, PNorm = 63.2278, GNorm = 0.0888, lr_0 = 1.2360e-04
Loss = 5.0824e-06, PNorm = 63.2283, GNorm = 0.0990, lr_0 = 1.2306e-04
Loss = 5.7282e-06, PNorm = 63.2294, GNorm = 0.0932, lr_0 = 1.2251e-04
Loss = 6.2443e-06, PNorm = 63.2306, GNorm = 0.0960, lr_0 = 1.2197e-04
Validation rmse logD = 0.547432
Validation R2 logD = 0.787526
Validation rmse logP = 0.625903
Validation R2 logP = 0.831235
Epoch 90
Train function
Loss = 2.8840e-06, PNorm = 63.2315, GNorm = 0.0318, lr_0 = 1.2143e-04
Loss = 5.1380e-06, PNorm = 63.2325, GNorm = 0.0508, lr_0 = 1.2089e-04
Loss = 5.3783e-06, PNorm = 63.2329, GNorm = 0.0636, lr_0 = 1.2036e-04
Loss = 4.5395e-06, PNorm = 63.2328, GNorm = 0.0524, lr_0 = 1.1983e-04
Loss = 6.1110e-06, PNorm = 63.2339, GNorm = 0.0469, lr_0 = 1.1930e-04
Loss = 4.1778e-06, PNorm = 63.2347, GNorm = 0.0467, lr_0 = 1.1877e-04
Validation rmse logD = 0.547929
Validation R2 logD = 0.787140
Validation rmse logP = 0.625296
Validation R2 logP = 0.831561
Epoch 91
Train function
Loss = 5.1174e-06, PNorm = 63.2354, GNorm = 0.1046, lr_0 = 1.1819e-04
Loss = 4.1018e-06, PNorm = 63.2361, GNorm = 0.0576, lr_0 = 1.1767e-04
Loss = 3.7922e-06, PNorm = 63.2365, GNorm = 0.0492, lr_0 = 1.1715e-04
Loss = 4.6274e-06, PNorm = 63.2372, GNorm = 0.1210, lr_0 = 1.1663e-04
Loss = 4.6391e-06, PNorm = 63.2380, GNorm = 0.0706, lr_0 = 1.1611e-04
Validation rmse logD = 0.547005
Validation R2 logD = 0.787857
Validation rmse logP = 0.622954
Validation R2 logP = 0.832821
Epoch 92
Train function
Loss = 4.7292e-06, PNorm = 63.2389, GNorm = 0.1072, lr_0 = 1.1555e-04
Loss = 5.6742e-06, PNorm = 63.2399, GNorm = 0.0479, lr_0 = 1.1504e-04
Loss = 3.8892e-06, PNorm = 63.2400, GNorm = 0.0345, lr_0 = 1.1453e-04
Loss = 3.2695e-06, PNorm = 63.2406, GNorm = 0.0584, lr_0 = 1.1402e-04
Loss = 4.2793e-06, PNorm = 63.2413, GNorm = 0.0616, lr_0 = 1.1352e-04
Validation rmse logD = 0.547362
Validation R2 logD = 0.787580
Validation rmse logP = 0.622243
Validation R2 logP = 0.833202
Epoch 93
Train function
Loss = 2.4073e-06, PNorm = 63.2417, GNorm = 0.0302, lr_0 = 1.1297e-04
Loss = 5.9673e-06, PNorm = 63.2428, GNorm = 0.0410, lr_0 = 1.1247e-04
Loss = 5.1185e-06, PNorm = 63.2434, GNorm = 0.1181, lr_0 = 1.1197e-04
Loss = 4.8341e-06, PNorm = 63.2443, GNorm = 0.0390, lr_0 = 1.1147e-04
Loss = 4.0437e-06, PNorm = 63.2447, GNorm = 0.0682, lr_0 = 1.1098e-04
Loss = 4.3791e-06, PNorm = 63.2452, GNorm = 0.0544, lr_0 = 1.1049e-04
Validation rmse logD = 0.546605
Validation R2 logD = 0.788167
Validation rmse logP = 0.622122
Validation R2 logP = 0.833267
Epoch 94
Train function
Loss = 5.1764e-06, PNorm = 63.2454, GNorm = 0.1148, lr_0 = 1.0995e-04
Loss = 5.5844e-06, PNorm = 63.2463, GNorm = 0.0421, lr_0 = 1.0947e-04
Loss = 4.9461e-06, PNorm = 63.2466, GNorm = 0.0690, lr_0 = 1.0898e-04
Loss = 5.1895e-06, PNorm = 63.2471, GNorm = 0.0594, lr_0 = 1.0850e-04
Loss = 4.3844e-06, PNorm = 63.2474, GNorm = 0.0521, lr_0 = 1.0802e-04
Validation rmse logD = 0.546882
Validation R2 logD = 0.787952
Validation rmse logP = 0.624247
Validation R2 logP = 0.832126
Epoch 95
Train function
Loss = 4.2344e-06, PNorm = 63.2490, GNorm = 0.0620, lr_0 = 1.0749e-04
Loss = 4.3640e-06, PNorm = 63.2496, GNorm = 0.0409, lr_0 = 1.0702e-04
Loss = 3.7251e-06, PNorm = 63.2504, GNorm = 0.0557, lr_0 = 1.0654e-04
Loss = 4.0555e-06, PNorm = 63.2506, GNorm = 0.0908, lr_0 = 1.0607e-04
Loss = 3.8949e-06, PNorm = 63.2515, GNorm = 0.0399, lr_0 = 1.0560e-04
Validation rmse logD = 0.547783
Validation R2 logD = 0.787253
Validation rmse logP = 0.623541
Validation R2 logP = 0.832506
Epoch 96
Train function
Loss = 3.3879e-06, PNorm = 63.2522, GNorm = 0.0789, lr_0 = 1.0509e-04
Loss = 2.5209e-06, PNorm = 63.2524, GNorm = 0.0297, lr_0 = 1.0463e-04
Loss = 4.7850e-06, PNorm = 63.2529, GNorm = 0.1407, lr_0 = 1.0416e-04
Loss = 3.3828e-06, PNorm = 63.2539, GNorm = 0.0363, lr_0 = 1.0370e-04
Loss = 3.1913e-06, PNorm = 63.2545, GNorm = 0.0664, lr_0 = 1.0324e-04
Loss = 3.9334e-06, PNorm = 63.2551, GNorm = 0.0659, lr_0 = 1.0279e-04
Loss = 6.3833e-05, PNorm = 63.2551, GNorm = 0.2130, lr_0 = 1.0274e-04
Validation rmse logD = 0.547926
Validation R2 logD = 0.787142
Validation rmse logP = 0.624576
Validation R2 logP = 0.831949
Epoch 97
Train function
Loss = 9.2880e-06, PNorm = 63.2569, GNorm = 0.2433, lr_0 = 1.0229e-04
Loss = 5.4355e-06, PNorm = 63.2579, GNorm = 0.0501, lr_0 = 1.0183e-04
Loss = 4.4302e-06, PNorm = 63.2579, GNorm = 0.0719, lr_0 = 1.0138e-04
Loss = 4.5831e-06, PNorm = 63.2586, GNorm = 0.1675, lr_0 = 1.0094e-04
Loss = 4.4786e-06, PNorm = 63.2597, GNorm = 0.0542, lr_0 = 1.0049e-04
Validation rmse logD = 0.548388
Validation R2 logD = 0.786783
Validation rmse logP = 0.624667
Validation R2 logP = 0.831900
Epoch 98
Train function
Loss = 4.3330e-06, PNorm = 63.2594, GNorm = 0.0504, lr_0 = 1.0000e-04
Loss = 9.3976e-06, PNorm = 63.2607, GNorm = 0.1536, lr_0 = 1.0000e-04
Loss = 6.8913e-06, PNorm = 63.2609, GNorm = 0.0423, lr_0 = 1.0000e-04
Loss = 7.2970e-06, PNorm = 63.2615, GNorm = 0.0859, lr_0 = 1.0000e-04
Loss = 5.5114e-06, PNorm = 63.2620, GNorm = 0.0537, lr_0 = 1.0000e-04
Validation rmse logD = 0.547538
Validation R2 logD = 0.787444
Validation rmse logP = 0.623886
Validation R2 logP = 0.832320
Epoch 99
Train function
Loss = 5.7660e-06, PNorm = 63.2620, GNorm = 0.0988, lr_0 = 1.0000e-04
Loss = 6.3032e-06, PNorm = 63.2629, GNorm = 0.0429, lr_0 = 1.0000e-04
Loss = 6.5461e-06, PNorm = 63.2637, GNorm = 0.1444, lr_0 = 1.0000e-04
Loss = 6.8299e-06, PNorm = 63.2643, GNorm = 0.0459, lr_0 = 1.0000e-04
Loss = 5.0589e-06, PNorm = 63.2650, GNorm = 0.0518, lr_0 = 1.0000e-04
Loss = 5.0990e-06, PNorm = 63.2659, GNorm = 0.0663, lr_0 = 1.0000e-04
Validation rmse logD = 0.548015
Validation R2 logD = 0.787073
Validation rmse logP = 0.626144
Validation R2 logP = 0.831104
Model 0 best validation rmse = 0.578129 on epoch 44
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.565380
Model 0 test R2 logD = 0.775499
Model 0 test rmse logP = 0.726758
Model 0 test R2 logP = 0.771930
Ensemble test rmse  logD= 0.565380
Ensemble test R2  logD= 0.775499
Ensemble test rmse  logP= 0.726758
Ensemble test R2  logP= 0.771930
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 2.0880e-02, PNorm = 52.9410, GNorm = 2.4894, lr_0 = 1.9340e-04
Loss = 1.8366e-02, PNorm = 52.9484, GNorm = 5.4377, lr_0 = 2.7830e-04
Loss = 1.7355e-02, PNorm = 52.9612, GNorm = 6.2503, lr_0 = 3.6321e-04
Loss = 1.5358e-02, PNorm = 52.9792, GNorm = 2.9986, lr_0 = 4.4811e-04
Loss = 1.2891e-02, PNorm = 53.0041, GNorm = 2.1781, lr_0 = 5.3302e-04
Validation rmse logD = 1.081458
Validation R2 logD = 0.215974
Validation rmse logP = 1.372842
Validation R2 logP = 0.367376
Epoch 1
Train function
Loss = 1.6763e-02, PNorm = 53.0383, GNorm = 6.0014, lr_0 = 6.2642e-04
Loss = 1.3416e-02, PNorm = 53.0768, GNorm = 2.5650, lr_0 = 7.1132e-04
Loss = 1.2502e-02, PNorm = 53.1186, GNorm = 3.6285, lr_0 = 7.9623e-04
Loss = 1.0262e-02, PNorm = 53.1592, GNorm = 1.8404, lr_0 = 8.8113e-04
Loss = 1.2734e-02, PNorm = 53.2000, GNorm = 2.5189, lr_0 = 9.6604e-04
Validation rmse logD = 0.942889
Validation R2 logD = 0.404019
Validation rmse logP = 1.408167
Validation R2 logP = 0.334401
Epoch 2
Train function
Loss = 1.2349e-02, PNorm = 53.2452, GNorm = 2.3483, lr_0 = 9.9690e-04
Loss = 9.8089e-03, PNorm = 53.2865, GNorm = 2.0718, lr_0 = 9.9249e-04
Loss = 9.9612e-03, PNorm = 53.3329, GNorm = 1.1665, lr_0 = 9.8810e-04
Loss = 9.7862e-03, PNorm = 53.3893, GNorm = 0.9514, lr_0 = 9.8373e-04
Loss = 9.2324e-03, PNorm = 53.4668, GNorm = 0.7520, lr_0 = 9.7938e-04
Validation rmse logD = 0.855338
Validation R2 logD = 0.509559
Validation rmse logP = 0.943277
Validation R2 logP = 0.701336
Epoch 3
Train function
Loss = 9.6967e-03, PNorm = 53.5489, GNorm = 1.8736, lr_0 = 9.7462e-04
Loss = 8.7857e-03, PNorm = 53.6285, GNorm = 1.4990, lr_0 = 9.7030e-04
Loss = 7.3606e-03, PNorm = 53.7270, GNorm = 1.0065, lr_0 = 9.6601e-04
Loss = 8.3898e-03, PNorm = 53.8240, GNorm = 1.6410, lr_0 = 9.6174e-04
Loss = 7.6419e-03, PNorm = 53.9286, GNorm = 1.5113, lr_0 = 9.5749e-04
Loss = 8.3928e-03, PNorm = 54.0083, GNorm = 2.0821, lr_0 = 9.5325e-04
Validation rmse logD = 0.839715
Validation R2 logD = 0.527311
Validation rmse logP = 0.922901
Validation R2 logP = 0.714099
Epoch 4
Train function
Loss = 7.5442e-03, PNorm = 54.0908, GNorm = 1.6947, lr_0 = 9.4861e-04
Loss = 7.0868e-03, PNorm = 54.1899, GNorm = 0.9061, lr_0 = 9.4442e-04
Loss = 7.9127e-03, PNorm = 54.2916, GNorm = 4.2316, lr_0 = 9.4024e-04
Loss = 6.8004e-03, PNorm = 54.4048, GNorm = 2.9194, lr_0 = 9.3608e-04
Loss = 6.7765e-03, PNorm = 54.4999, GNorm = 2.0645, lr_0 = 9.3194e-04
Validation rmse logD = 0.800275
Validation R2 logD = 0.570671
Validation rmse logP = 0.896559
Validation R2 logP = 0.730188
Epoch 5
Train function
Loss = 6.4462e-03, PNorm = 54.5915, GNorm = 1.5218, lr_0 = 9.2741e-04
Loss = 6.9673e-03, PNorm = 54.6580, GNorm = 1.6036, lr_0 = 9.2330e-04
Loss = 5.6554e-03, PNorm = 54.7445, GNorm = 2.1949, lr_0 = 9.1922e-04
Loss = 5.3660e-03, PNorm = 54.7885, GNorm = 2.5528, lr_0 = 9.1515e-04
Loss = 5.6275e-03, PNorm = 54.8585, GNorm = 3.7609, lr_0 = 9.1111e-04
Validation rmse logD = 0.718036
Validation R2 logD = 0.654375
Validation rmse logP = 0.874345
Validation R2 logP = 0.743392
Epoch 6
Train function
Loss = 4.3657e-03, PNorm = 54.9444, GNorm = 1.6563, lr_0 = 9.0667e-04
Loss = 5.0877e-03, PNorm = 55.0242, GNorm = 2.6609, lr_0 = 9.0266e-04
Loss = 5.5274e-03, PNorm = 55.1085, GNorm = 1.7676, lr_0 = 8.9867e-04
Loss = 4.9545e-03, PNorm = 55.1833, GNorm = 1.2607, lr_0 = 8.9469e-04
Loss = 5.3716e-03, PNorm = 55.2642, GNorm = 1.2093, lr_0 = 8.9074e-04
Loss = 6.0385e-03, PNorm = 55.3520, GNorm = 1.7006, lr_0 = 8.8680e-04
Validation rmse logD = 0.690946
Validation R2 logD = 0.679963
Validation rmse logP = 0.825067
Validation R2 logP = 0.771502
Epoch 7
Train function
Loss = 4.2532e-03, PNorm = 55.4562, GNorm = 1.2602, lr_0 = 8.8248e-04
Loss = 5.7402e-03, PNorm = 55.5448, GNorm = 2.5481, lr_0 = 8.7858e-04
Loss = 4.7502e-03, PNorm = 55.6363, GNorm = 1.1600, lr_0 = 8.7469e-04
Loss = 4.4762e-03, PNorm = 55.7257, GNorm = 0.8039, lr_0 = 8.7082e-04
Loss = 4.3710e-03, PNorm = 55.8125, GNorm = 0.9951, lr_0 = 8.6697e-04
Validation rmse logD = 0.669039
Validation R2 logD = 0.699936
Validation rmse logP = 0.801558
Validation R2 logP = 0.784338
Epoch 8
Train function
Loss = 4.0053e-03, PNorm = 55.9087, GNorm = 2.0609, lr_0 = 8.6276e-04
Loss = 4.3117e-03, PNorm = 55.9841, GNorm = 2.0976, lr_0 = 8.5894e-04
Loss = 4.2352e-03, PNorm = 56.0649, GNorm = 1.0404, lr_0 = 8.5514e-04
Loss = 4.5727e-03, PNorm = 56.1472, GNorm = 1.6622, lr_0 = 8.5136e-04
Loss = 3.5157e-03, PNorm = 56.2262, GNorm = 2.0878, lr_0 = 8.4759e-04
Validation rmse logD = 0.783328
Validation R2 logD = 0.588662
Validation rmse logP = 0.896869
Validation R2 logP = 0.730001
Epoch 9
Train function
Loss = 5.7198e-03, PNorm = 56.3119, GNorm = 3.8033, lr_0 = 8.4384e-04
Loss = 4.7233e-03, PNorm = 56.4128, GNorm = 2.0229, lr_0 = 8.4011e-04
Loss = 4.0653e-03, PNorm = 56.5180, GNorm = 1.0683, lr_0 = 8.3639e-04
Loss = 3.5959e-03, PNorm = 56.5988, GNorm = 0.8761, lr_0 = 8.3269e-04
Loss = 3.5044e-03, PNorm = 56.6742, GNorm = 1.7156, lr_0 = 8.2901e-04
Loss = 3.1863e-03, PNorm = 56.7444, GNorm = 0.8980, lr_0 = 8.2534e-04
Validation rmse logD = 0.645039
Validation R2 logD = 0.721077
Validation rmse logP = 0.819009
Validation R2 logP = 0.774845
Epoch 10
Train function
Loss = 2.8675e-03, PNorm = 56.8256, GNorm = 2.2928, lr_0 = 8.2133e-04
Loss = 3.3949e-03, PNorm = 56.8944, GNorm = 1.9208, lr_0 = 8.1770e-04
Loss = 3.3266e-03, PNorm = 56.9705, GNorm = 1.2889, lr_0 = 8.1408e-04
Loss = 3.2621e-03, PNorm = 57.0480, GNorm = 0.8385, lr_0 = 8.1048e-04
Loss = 3.1471e-03, PNorm = 57.1151, GNorm = 3.0273, lr_0 = 8.0689e-04
Validation rmse logD = 0.648222
Validation R2 logD = 0.718318
Validation rmse logP = 0.797864
Validation R2 logP = 0.786321
Epoch 11
Train function
Loss = 2.7843e-03, PNorm = 57.1931, GNorm = 1.6392, lr_0 = 8.0297e-04
Loss = 2.6874e-03, PNorm = 57.2795, GNorm = 0.7253, lr_0 = 7.9942e-04
Loss = 2.6120e-03, PNorm = 57.3370, GNorm = 0.7683, lr_0 = 7.9588e-04
Loss = 2.8615e-03, PNorm = 57.3968, GNorm = 0.8341, lr_0 = 7.9236e-04
Loss = 2.8523e-03, PNorm = 57.4542, GNorm = 1.0428, lr_0 = 7.8885e-04
Validation rmse logD = 0.614251
Validation R2 logD = 0.747069
Validation rmse logP = 0.794321
Validation R2 logP = 0.788214
Epoch 12
Train function
Loss = 2.1038e-03, PNorm = 57.5326, GNorm = 1.2302, lr_0 = 7.8502e-04
Loss = 2.2420e-03, PNorm = 57.6025, GNorm = 0.6641, lr_0 = 7.8154e-04
Loss = 2.4260e-03, PNorm = 57.6627, GNorm = 0.8185, lr_0 = 7.7809e-04
Loss = 2.5292e-03, PNorm = 57.7281, GNorm = 0.6789, lr_0 = 7.7465e-04
Loss = 3.0702e-03, PNorm = 57.8029, GNorm = 2.1827, lr_0 = 7.7122e-04
Loss = 2.8509e-03, PNorm = 57.8830, GNorm = 1.1227, lr_0 = 7.6781e-04
Loss = 2.2984e-02, PNorm = 57.8914, GNorm = 3.6581, lr_0 = 7.6747e-04
Validation rmse logD = 0.600190
Validation R2 logD = 0.758515
Validation rmse logP = 0.766729
Validation R2 logP = 0.802672
Epoch 13
Train function
Loss = 2.2284e-03, PNorm = 57.9753, GNorm = 0.6618, lr_0 = 7.6407e-04
Loss = 1.8903e-03, PNorm = 58.0457, GNorm = 0.7221, lr_0 = 7.6069e-04
Loss = 2.1036e-03, PNorm = 58.0950, GNorm = 1.0800, lr_0 = 7.5733e-04
Loss = 2.3993e-03, PNorm = 58.1618, GNorm = 0.5355, lr_0 = 7.5398e-04
Loss = 2.3923e-03, PNorm = 58.2369, GNorm = 0.7375, lr_0 = 7.5064e-04
Validation rmse logD = 0.623579
Validation R2 logD = 0.739327
Validation rmse logP = 0.771256
Validation R2 logP = 0.800335
Epoch 14
Train function
Loss = 2.0122e-03, PNorm = 58.3066, GNorm = 0.7890, lr_0 = 7.4699e-04
Loss = 1.9438e-03, PNorm = 58.3674, GNorm = 0.9520, lr_0 = 7.4369e-04
Loss = 1.7724e-03, PNorm = 58.4264, GNorm = 0.4868, lr_0 = 7.4040e-04
Loss = 1.8637e-03, PNorm = 58.4799, GNorm = 1.0938, lr_0 = 7.3712e-04
Loss = 1.5035e-03, PNorm = 58.5314, GNorm = 0.6276, lr_0 = 7.3386e-04
Validation rmse logD = 0.628843
Validation R2 logD = 0.734909
Validation rmse logP = 0.766722
Validation R2 logP = 0.802676
Epoch 15
Train function
Loss = 2.4386e-03, PNorm = 58.6031, GNorm = 2.0455, lr_0 = 7.3029e-04
Loss = 1.5610e-03, PNorm = 58.6788, GNorm = 0.5955, lr_0 = 7.2706e-04
Loss = 1.4940e-03, PNorm = 58.7437, GNorm = 1.0304, lr_0 = 7.2385e-04
Loss = 1.5125e-03, PNorm = 58.7944, GNorm = 0.7239, lr_0 = 7.2064e-04
Loss = 1.6144e-03, PNorm = 58.8472, GNorm = 0.7171, lr_0 = 7.1746e-04
Validation rmse logD = 0.644628
Validation R2 logD = 0.721433
Validation rmse logP = 0.774208
Validation R2 logP = 0.798804
Epoch 16
Train function
Loss = 2.0443e-03, PNorm = 58.9111, GNorm = 2.7771, lr_0 = 7.1397e-04
Loss = 2.7715e-03, PNorm = 58.9819, GNorm = 0.6446, lr_0 = 7.1081e-04
Loss = 2.8119e-03, PNorm = 59.0701, GNorm = 2.6340, lr_0 = 7.0766e-04
Loss = 1.9440e-03, PNorm = 59.1633, GNorm = 1.3898, lr_0 = 7.0453e-04
Loss = 1.6890e-03, PNorm = 59.2267, GNorm = 0.5768, lr_0 = 7.0142e-04
Loss = 1.9397e-03, PNorm = 59.2801, GNorm = 1.4660, lr_0 = 6.9831e-04
Validation rmse logD = 0.596640
Validation R2 logD = 0.761364
Validation rmse logP = 0.785683
Validation R2 logP = 0.792796
Epoch 17
Train function
Loss = 1.3596e-03, PNorm = 59.3308, GNorm = 1.2259, lr_0 = 6.9523e-04
Loss = 1.7614e-03, PNorm = 59.3780, GNorm = 0.8356, lr_0 = 6.9215e-04
Loss = 1.6242e-03, PNorm = 59.4315, GNorm = 1.1961, lr_0 = 6.8909e-04
Loss = 1.4940e-03, PNorm = 59.4900, GNorm = 0.8004, lr_0 = 6.8604e-04
Loss = 1.3805e-03, PNorm = 59.5418, GNorm = 0.5414, lr_0 = 6.8301e-04
Validation rmse logD = 0.602530
Validation R2 logD = 0.756629
Validation rmse logP = 0.760121
Validation R2 logP = 0.806059
Epoch 18
Train function
Loss = 1.1080e-03, PNorm = 59.5885, GNorm = 1.6374, lr_0 = 6.7968e-04
Loss = 1.1934e-03, PNorm = 59.6385, GNorm = 1.1446, lr_0 = 6.7668e-04
Loss = 1.2379e-03, PNorm = 59.6790, GNorm = 2.1522, lr_0 = 6.7368e-04
Loss = 1.3225e-03, PNorm = 59.7190, GNorm = 1.1537, lr_0 = 6.7070e-04
Loss = 1.3481e-03, PNorm = 59.7625, GNorm = 1.1432, lr_0 = 6.6774e-04
Validation rmse logD = 0.589732
Validation R2 logD = 0.766858
Validation rmse logP = 0.751763
Validation R2 logP = 0.810301
Epoch 19
Train function
Loss = 1.0104e-03, PNorm = 59.8121, GNorm = 0.7420, lr_0 = 6.6449e-04
Loss = 1.5929e-03, PNorm = 59.8765, GNorm = 1.4857, lr_0 = 6.6155e-04
Loss = 1.1902e-03, PNorm = 59.9282, GNorm = 0.6926, lr_0 = 6.5862e-04
Loss = 1.1935e-03, PNorm = 59.9650, GNorm = 1.3900, lr_0 = 6.5571e-04
Loss = 1.1074e-03, PNorm = 60.0096, GNorm = 0.5090, lr_0 = 6.5281e-04
Loss = 1.0583e-03, PNorm = 60.0526, GNorm = 1.1997, lr_0 = 6.4992e-04
Validation rmse logD = 0.589475
Validation R2 logD = 0.767061
Validation rmse logP = 0.776710
Validation R2 logP = 0.797501
Epoch 20
Train function
Loss = 8.7769e-04, PNorm = 60.1067, GNorm = 0.5996, lr_0 = 6.4676e-04
Loss = 1.1499e-03, PNorm = 60.1508, GNorm = 1.2447, lr_0 = 6.4390e-04
Loss = 9.7369e-04, PNorm = 60.1914, GNorm = 1.3120, lr_0 = 6.4105e-04
Loss = 1.1268e-03, PNorm = 60.2220, GNorm = 1.6913, lr_0 = 6.3822e-04
Loss = 1.1653e-03, PNorm = 60.2438, GNorm = 1.3440, lr_0 = 6.3539e-04
Validation rmse logD = 0.583064
Validation R2 logD = 0.772100
Validation rmse logP = 0.758488
Validation R2 logP = 0.806891
Epoch 21
Train function
Loss = 8.3523e-04, PNorm = 60.2881, GNorm = 0.4183, lr_0 = 6.3230e-04
Loss = 1.0399e-03, PNorm = 60.3245, GNorm = 0.5405, lr_0 = 6.2950e-04
Loss = 9.3543e-04, PNorm = 60.3630, GNorm = 0.6110, lr_0 = 6.2672e-04
Loss = 9.0308e-04, PNorm = 60.4035, GNorm = 0.5652, lr_0 = 6.2395e-04
Loss = 9.5484e-04, PNorm = 60.4325, GNorm = 2.4063, lr_0 = 6.2119e-04
Validation rmse logD = 0.592717
Validation R2 logD = 0.764491
Validation rmse logP = 0.784644
Validation R2 logP = 0.793343
Epoch 22
Train function
Loss = 9.1896e-04, PNorm = 60.4685, GNorm = 1.3079, lr_0 = 6.1817e-04
Loss = 9.1221e-04, PNorm = 60.4984, GNorm = 0.7136, lr_0 = 6.1543e-04
Loss = 7.4752e-04, PNorm = 60.5336, GNorm = 1.1078, lr_0 = 6.1271e-04
Loss = 8.8290e-04, PNorm = 60.5611, GNorm = 1.4141, lr_0 = 6.1000e-04
Loss = 7.7364e-04, PNorm = 60.5864, GNorm = 1.2446, lr_0 = 6.0730e-04
Loss = 1.0281e-03, PNorm = 60.6193, GNorm = 1.9661, lr_0 = 6.0461e-04
Validation rmse logD = 0.598219
Validation R2 logD = 0.760099
Validation rmse logP = 0.754267
Validation R2 logP = 0.809035
Epoch 23
Train function
Loss = 9.9043e-04, PNorm = 60.6640, GNorm = 1.5547, lr_0 = 6.0167e-04
Loss = 1.2844e-03, PNorm = 60.7093, GNorm = 0.3264, lr_0 = 5.9901e-04
Loss = 1.0105e-03, PNorm = 60.7511, GNorm = 1.4404, lr_0 = 5.9636e-04
Loss = 8.7671e-04, PNorm = 60.7817, GNorm = 1.1236, lr_0 = 5.9372e-04
Loss = 8.9217e-04, PNorm = 60.8118, GNorm = 0.4201, lr_0 = 5.9110e-04
Validation rmse logD = 0.612028
Validation R2 logD = 0.748896
Validation rmse logP = 0.743826
Validation R2 logP = 0.814285
Epoch 24
Train function
Loss = 1.0940e-03, PNorm = 60.8540, GNorm = 1.7639, lr_0 = 5.8822e-04
Loss = 9.5845e-04, PNorm = 60.8914, GNorm = 1.7499, lr_0 = 5.8562e-04
Loss = 7.8155e-04, PNorm = 60.9274, GNorm = 0.5124, lr_0 = 5.8303e-04
Loss = 8.5260e-04, PNorm = 60.9555, GNorm = 0.5621, lr_0 = 5.8045e-04
Loss = 6.3622e-04, PNorm = 60.9838, GNorm = 1.2789, lr_0 = 5.7788e-04
Validation rmse logD = 0.581105
Validation R2 logD = 0.773629
Validation rmse logP = 0.761224
Validation R2 logP = 0.805496
Epoch 25
Train function
Loss = 5.7889e-04, PNorm = 61.0101, GNorm = 0.4573, lr_0 = 5.7533e-04
Loss = 8.4043e-04, PNorm = 61.0431, GNorm = 0.5681, lr_0 = 5.7278e-04
Loss = 7.5443e-04, PNorm = 61.0744, GNorm = 0.7621, lr_0 = 5.7025e-04
Loss = 6.6381e-04, PNorm = 61.1061, GNorm = 0.8525, lr_0 = 5.6773e-04
Loss = 5.7293e-04, PNorm = 61.1332, GNorm = 0.6303, lr_0 = 5.6522e-04
Loss = 6.8863e-04, PNorm = 61.1568, GNorm = 1.3585, lr_0 = 5.6272e-04
Validation rmse logD = 0.584767
Validation R2 logD = 0.770767
Validation rmse logP = 0.752646
Validation R2 logP = 0.809855
Epoch 26
Train function
Loss = 5.4013e-04, PNorm = 61.1873, GNorm = 1.2698, lr_0 = 5.5998e-04
Loss = 5.7828e-04, PNorm = 61.2149, GNorm = 0.4485, lr_0 = 5.5750e-04
Loss = 7.9225e-04, PNorm = 61.2334, GNorm = 0.3754, lr_0 = 5.5503e-04
Loss = 5.3142e-04, PNorm = 61.2616, GNorm = 0.4339, lr_0 = 5.5258e-04
Loss = 5.3871e-04, PNorm = 61.2860, GNorm = 0.9431, lr_0 = 5.5014e-04
Validation rmse logD = 0.585135
Validation R2 logD = 0.770478
Validation rmse logP = 0.752376
Validation R2 logP = 0.809991
Epoch 27
Train function
Loss = 8.5011e-04, PNorm = 61.3157, GNorm = 1.0175, lr_0 = 5.4746e-04
Loss = 4.8465e-04, PNorm = 61.3358, GNorm = 0.4221, lr_0 = 5.4504e-04
Loss = 4.6457e-04, PNorm = 61.3561, GNorm = 0.5522, lr_0 = 5.4263e-04
Loss = 5.6322e-04, PNorm = 61.3784, GNorm = 0.3090, lr_0 = 5.4023e-04
Loss = 4.3745e-04, PNorm = 61.3997, GNorm = 0.7973, lr_0 = 5.3784e-04
Validation rmse logD = 0.577781
Validation R2 logD = 0.776211
Validation rmse logP = 0.744595
Validation R2 logP = 0.813901
Epoch 28
Train function
Loss = 4.4215e-04, PNorm = 61.4227, GNorm = 0.9535, lr_0 = 5.3522e-04
Loss = 5.3858e-04, PNorm = 61.4423, GNorm = 0.7716, lr_0 = 5.3285e-04
Loss = 4.1398e-04, PNorm = 61.4658, GNorm = 0.4232, lr_0 = 5.3050e-04
Loss = 3.7999e-04, PNorm = 61.4834, GNorm = 0.3318, lr_0 = 5.2815e-04
Loss = 4.0678e-04, PNorm = 61.4987, GNorm = 0.3195, lr_0 = 5.2581e-04
Loss = 4.1360e-04, PNorm = 61.5193, GNorm = 0.3559, lr_0 = 5.2349e-04
Loss = 6.4726e-04, PNorm = 61.5210, GNorm = 0.5010, lr_0 = 5.2326e-04
Validation rmse logD = 0.577478
Validation R2 logD = 0.776446
Validation rmse logP = 0.748825
Validation R2 logP = 0.811780
Epoch 29
Train function
Loss = 4.1983e-04, PNorm = 61.5344, GNorm = 0.6790, lr_0 = 5.2094e-04
Loss = 4.0504e-04, PNorm = 61.5512, GNorm = 0.4599, lr_0 = 5.1864e-04
Loss = 3.5452e-04, PNorm = 61.5699, GNorm = 0.6245, lr_0 = 5.1634e-04
Loss = 4.5219e-04, PNorm = 61.5880, GNorm = 0.3582, lr_0 = 5.1406e-04
Loss = 3.7220e-04, PNorm = 61.6085, GNorm = 0.5016, lr_0 = 5.1178e-04
Validation rmse logD = 0.581353
Validation R2 logD = 0.773436
Validation rmse logP = 0.754920
Validation R2 logP = 0.808704
Epoch 30
Train function
Loss = 4.3299e-04, PNorm = 61.6321, GNorm = 0.3790, lr_0 = 5.0930e-04
Loss = 3.6823e-04, PNorm = 61.6502, GNorm = 1.2213, lr_0 = 5.0704e-04
Loss = 4.0974e-04, PNorm = 61.6639, GNorm = 0.6954, lr_0 = 5.0480e-04
Loss = 3.9496e-04, PNorm = 61.6826, GNorm = 0.4069, lr_0 = 5.0257e-04
Loss = 4.7056e-04, PNorm = 61.7040, GNorm = 0.2422, lr_0 = 5.0034e-04
Validation rmse logD = 0.593035
Validation R2 logD = 0.764239
Validation rmse logP = 0.738933
Validation R2 logP = 0.816720
Epoch 31
Train function
Loss = 6.2723e-04, PNorm = 61.7262, GNorm = 0.9508, lr_0 = 4.9791e-04
Loss = 5.1521e-04, PNorm = 61.7531, GNorm = 0.3883, lr_0 = 4.9571e-04
Loss = 4.8366e-04, PNorm = 61.7804, GNorm = 0.6090, lr_0 = 4.9351e-04
Loss = 3.8448e-04, PNorm = 61.8045, GNorm = 0.8989, lr_0 = 4.9133e-04
Loss = 4.6523e-04, PNorm = 61.8232, GNorm = 0.6657, lr_0 = 4.8916e-04
Validation rmse logD = 0.579690
Validation R2 logD = 0.774730
Validation rmse logP = 0.729230
Validation R2 logP = 0.821502
Epoch 32
Train function
Loss = 3.4850e-04, PNorm = 61.8423, GNorm = 0.4176, lr_0 = 4.8678e-04
Loss = 2.6557e-04, PNorm = 61.8585, GNorm = 0.4605, lr_0 = 4.8463e-04
Loss = 3.9305e-04, PNorm = 61.8733, GNorm = 0.4851, lr_0 = 4.8248e-04
Loss = 3.8183e-04, PNorm = 61.8919, GNorm = 1.2966, lr_0 = 4.8035e-04
Loss = 3.7305e-04, PNorm = 61.9102, GNorm = 0.5821, lr_0 = 4.7822e-04
Loss = 3.7910e-04, PNorm = 61.9271, GNorm = 0.5035, lr_0 = 4.7611e-04
Validation rmse logD = 0.584035
Validation R2 logD = 0.771341
Validation rmse logP = 0.755639
Validation R2 logP = 0.808339
Epoch 33
Train function
Loss = 3.0120e-04, PNorm = 61.9473, GNorm = 0.4087, lr_0 = 4.7379e-04
Loss = 2.0731e-04, PNorm = 61.9637, GNorm = 0.3451, lr_0 = 4.7170e-04
Loss = 3.2112e-04, PNorm = 61.9743, GNorm = 0.5241, lr_0 = 4.6961e-04
Loss = 3.2069e-04, PNorm = 61.9888, GNorm = 0.4325, lr_0 = 4.6753e-04
Loss = 2.8598e-04, PNorm = 62.0057, GNorm = 0.4643, lr_0 = 4.6546e-04
Validation rmse logD = 0.573184
Validation R2 logD = 0.779758
Validation rmse logP = 0.757281
Validation R2 logP = 0.807506
Epoch 34
Train function
Loss = 2.3448e-04, PNorm = 62.0169, GNorm = 0.3376, lr_0 = 4.6341e-04
Loss = 1.9135e-04, PNorm = 62.0284, GNorm = 0.4018, lr_0 = 4.6136e-04
Loss = 3.2874e-04, PNorm = 62.0447, GNorm = 0.2897, lr_0 = 4.5931e-04
Loss = 2.7137e-04, PNorm = 62.0583, GNorm = 1.1185, lr_0 = 4.5728e-04
Loss = 2.5895e-04, PNorm = 62.0741, GNorm = 0.4193, lr_0 = 4.5526e-04
Validation rmse logD = 0.573658
Validation R2 logD = 0.779394
Validation rmse logP = 0.738301
Validation R2 logP = 0.817034
Epoch 35
Train function
Loss = 1.4687e-04, PNorm = 62.0946, GNorm = 0.2929, lr_0 = 4.5305e-04
Loss = 2.3339e-04, PNorm = 62.1029, GNorm = 0.3041, lr_0 = 4.5104e-04
Loss = 2.5340e-04, PNorm = 62.1151, GNorm = 0.2828, lr_0 = 4.4905e-04
Loss = 2.6974e-04, PNorm = 62.1331, GNorm = 0.8877, lr_0 = 4.4706e-04
Loss = 3.2027e-04, PNorm = 62.1474, GNorm = 0.6815, lr_0 = 4.4508e-04
Loss = 3.1854e-04, PNorm = 62.1652, GNorm = 0.9545, lr_0 = 4.4311e-04
Validation rmse logD = 0.575023
Validation R2 logD = 0.778343
Validation rmse logP = 0.746548
Validation R2 logP = 0.812923
Epoch 36
Train function
Loss = 2.7391e-04, PNorm = 62.1869, GNorm = 0.3879, lr_0 = 4.4096e-04
Loss = 1.9503e-04, PNorm = 62.2033, GNorm = 0.4327, lr_0 = 4.3901e-04
Loss = 2.1025e-04, PNorm = 62.2161, GNorm = 0.4133, lr_0 = 4.3707e-04
Loss = 2.9771e-04, PNorm = 62.2291, GNorm = 0.4395, lr_0 = 4.3513e-04
Loss = 2.2214e-04, PNorm = 62.2391, GNorm = 0.3307, lr_0 = 4.3321e-04
Validation rmse logD = 0.572446
Validation R2 logD = 0.780325
Validation rmse logP = 0.740180
Validation R2 logP = 0.816101
Epoch 37
Train function
Loss = 2.8325e-04, PNorm = 62.2536, GNorm = 0.4227, lr_0 = 4.3110e-04
Loss = 2.3205e-04, PNorm = 62.2700, GNorm = 0.4236, lr_0 = 4.2919e-04
Loss = 2.3110e-04, PNorm = 62.2846, GNorm = 0.4044, lr_0 = 4.2729e-04
Loss = 1.9647e-04, PNorm = 62.2938, GNorm = 0.2846, lr_0 = 4.2540e-04
Loss = 2.0704e-04, PNorm = 62.3083, GNorm = 0.2868, lr_0 = 4.2352e-04
Validation rmse logD = 0.574484
Validation R2 logD = 0.778758
Validation rmse logP = 0.745087
Validation R2 logP = 0.813655
Epoch 38
Train function
Loss = 3.1083e-04, PNorm = 62.3186, GNorm = 0.3652, lr_0 = 4.2146e-04
Loss = 1.7592e-04, PNorm = 62.3297, GNorm = 0.3197, lr_0 = 4.1960e-04
Loss = 1.9062e-04, PNorm = 62.3410, GNorm = 0.7547, lr_0 = 4.1774e-04
Loss = 2.7196e-04, PNorm = 62.3532, GNorm = 0.7057, lr_0 = 4.1589e-04
Loss = 2.3524e-04, PNorm = 62.3653, GNorm = 0.5456, lr_0 = 4.1406e-04
Loss = 2.0347e-04, PNorm = 62.3764, GNorm = 0.2599, lr_0 = 4.1222e-04
Validation rmse logD = 0.577504
Validation R2 logD = 0.776426
Validation rmse logP = 0.745571
Validation R2 logP = 0.813412
Epoch 39
Train function
Loss = 2.7171e-04, PNorm = 62.3910, GNorm = 0.2523, lr_0 = 4.1022e-04
Loss = 2.0565e-04, PNorm = 62.4057, GNorm = 0.3847, lr_0 = 4.0840e-04
Loss = 2.2544e-04, PNorm = 62.4212, GNorm = 0.4185, lr_0 = 4.0660e-04
Loss = 2.0443e-04, PNorm = 62.4318, GNorm = 0.2910, lr_0 = 4.0480e-04
Loss = 1.6057e-04, PNorm = 62.4455, GNorm = 0.2156, lr_0 = 4.0301e-04
Validation rmse logD = 0.582491
Validation R2 logD = 0.772548
Validation rmse logP = 0.737098
Validation R2 logP = 0.817629
Epoch 40
Train function
Loss = 1.8881e-04, PNorm = 62.4589, GNorm = 0.3233, lr_0 = 4.0105e-04
Loss = 1.6635e-04, PNorm = 62.4698, GNorm = 0.1530, lr_0 = 3.9927e-04
Loss = 2.0592e-04, PNorm = 62.4812, GNorm = 0.2814, lr_0 = 3.9751e-04
Loss = 1.9510e-04, PNorm = 62.4948, GNorm = 0.2684, lr_0 = 3.9575e-04
Loss = 2.1577e-04, PNorm = 62.5093, GNorm = 0.3206, lr_0 = 3.9400e-04
Validation rmse logD = 0.579257
Validation R2 logD = 0.775067
Validation rmse logP = 0.735509
Validation R2 logP = 0.818415
Epoch 41
Train function
Loss = 2.1231e-04, PNorm = 62.5226, GNorm = 0.2231, lr_0 = 3.9208e-04
Loss = 2.2828e-04, PNorm = 62.5314, GNorm = 0.7024, lr_0 = 3.9035e-04
Loss = 2.4064e-04, PNorm = 62.5449, GNorm = 0.4352, lr_0 = 3.8862e-04
Loss = 1.5934e-04, PNorm = 62.5592, GNorm = 0.2989, lr_0 = 3.8690e-04
Loss = 2.6111e-04, PNorm = 62.5739, GNorm = 0.2386, lr_0 = 3.8519e-04
Loss = 1.9567e-04, PNorm = 62.5854, GNorm = 0.3926, lr_0 = 3.8349e-04
Validation rmse logD = 0.575376
Validation R2 logD = 0.778071
Validation rmse logP = 0.737435
Validation R2 logP = 0.817463
Epoch 42
Train function
Loss = 1.7173e-04, PNorm = 62.5953, GNorm = 0.2921, lr_0 = 3.8179e-04
Loss = 1.7075e-04, PNorm = 62.6099, GNorm = 0.4873, lr_0 = 3.8010e-04
Loss = 1.6428e-04, PNorm = 62.6217, GNorm = 0.3167, lr_0 = 3.7842e-04
Loss = 1.2675e-04, PNorm = 62.6305, GNorm = 0.2702, lr_0 = 3.7675e-04
Loss = 1.5060e-04, PNorm = 62.6414, GNorm = 0.3183, lr_0 = 3.7508e-04
Validation rmse logD = 0.576726
Validation R2 logD = 0.777028
Validation rmse logP = 0.738749
Validation R2 logP = 0.816812
Epoch 43
Train function
Loss = 1.3613e-04, PNorm = 62.6536, GNorm = 0.2898, lr_0 = 3.7326e-04
Loss = 1.7896e-04, PNorm = 62.6632, GNorm = 0.1608, lr_0 = 3.7160e-04
Loss = 1.6044e-04, PNorm = 62.6709, GNorm = 0.2590, lr_0 = 3.6996e-04
Loss = 1.0551e-04, PNorm = 62.6786, GNorm = 0.2101, lr_0 = 3.6832e-04
Loss = 1.3128e-04, PNorm = 62.6903, GNorm = 0.5548, lr_0 = 3.6669e-04
Validation rmse logD = 0.577857
Validation R2 logD = 0.776152
Validation rmse logP = 0.739742
Validation R2 logP = 0.816319
Epoch 44
Train function
Loss = 1.4038e-04, PNorm = 62.6956, GNorm = 0.1681, lr_0 = 3.6491e-04
Loss = 1.1331e-04, PNorm = 62.7017, GNorm = 0.2496, lr_0 = 3.6330e-04
Loss = 9.9386e-05, PNorm = 62.7092, GNorm = 0.3412, lr_0 = 3.6169e-04
Loss = 1.0105e-04, PNorm = 62.7194, GNorm = 0.3173, lr_0 = 3.6009e-04
Loss = 1.5294e-04, PNorm = 62.7303, GNorm = 0.5248, lr_0 = 3.5850e-04
Loss = 1.2447e-04, PNorm = 62.7411, GNorm = 0.4824, lr_0 = 3.5691e-04
Loss = 1.2468e-03, PNorm = 62.7421, GNorm = 1.0259, lr_0 = 3.5675e-04
Validation rmse logD = 0.577913
Validation R2 logD = 0.776109
Validation rmse logP = 0.739555
Validation R2 logP = 0.816412
Epoch 45
Train function
Loss = 1.1415e-04, PNorm = 62.7502, GNorm = 0.4058, lr_0 = 3.5518e-04
Loss = 1.1055e-04, PNorm = 62.7589, GNorm = 0.1964, lr_0 = 3.5360e-04
Loss = 1.3052e-04, PNorm = 62.7661, GNorm = 0.6763, lr_0 = 3.5204e-04
Loss = 1.5036e-04, PNorm = 62.7755, GNorm = 0.2309, lr_0 = 3.5048e-04
Loss = 1.2670e-04, PNorm = 62.7816, GNorm = 0.1715, lr_0 = 3.4893e-04
Validation rmse logD = 0.574225
Validation R2 logD = 0.778957
Validation rmse logP = 0.739356
Validation R2 logP = 0.816510
Epoch 46
Train function
Loss = 1.0258e-04, PNorm = 62.7922, GNorm = 0.2299, lr_0 = 3.4724e-04
Loss = 1.1924e-04, PNorm = 62.8010, GNorm = 0.4198, lr_0 = 3.4570e-04
Loss = 9.5245e-05, PNorm = 62.8080, GNorm = 0.3089, lr_0 = 3.4417e-04
Loss = 1.1890e-04, PNorm = 62.8155, GNorm = 0.2003, lr_0 = 3.4265e-04
Loss = 9.4067e-05, PNorm = 62.8225, GNorm = 0.1384, lr_0 = 3.4113e-04
Validation rmse logD = 0.572996
Validation R2 logD = 0.779903
Validation rmse logP = 0.734972
Validation R2 logP = 0.818680
Epoch 47
Train function
Loss = 8.6575e-05, PNorm = 62.8303, GNorm = 0.3127, lr_0 = 3.3947e-04
Loss = 1.7262e-04, PNorm = 62.8431, GNorm = 0.3690, lr_0 = 3.3797e-04
Loss = 1.2866e-04, PNorm = 62.8517, GNorm = 0.2243, lr_0 = 3.3648e-04
Loss = 1.3461e-04, PNorm = 62.8567, GNorm = 0.2603, lr_0 = 3.3499e-04
Loss = 1.0635e-04, PNorm = 62.8653, GNorm = 0.3845, lr_0 = 3.3351e-04
Validation rmse logD = 0.573915
Validation R2 logD = 0.779196
Validation rmse logP = 0.747895
Validation R2 logP = 0.812248
Epoch 48
Train function
Loss = 9.7889e-05, PNorm = 62.8738, GNorm = 0.4074, lr_0 = 3.3188e-04
Loss = 1.2858e-04, PNorm = 62.8842, GNorm = 0.2268, lr_0 = 3.3042e-04
Loss = 1.3554e-04, PNorm = 62.8934, GNorm = 0.2675, lr_0 = 3.2895e-04
Loss = 1.0279e-04, PNorm = 62.9003, GNorm = 0.2647, lr_0 = 3.2750e-04
Loss = 1.0818e-04, PNorm = 62.9076, GNorm = 0.1720, lr_0 = 3.2605e-04
Loss = 9.2124e-05, PNorm = 62.9138, GNorm = 0.3853, lr_0 = 3.2461e-04
Validation rmse logD = 0.574273
Validation R2 logD = 0.778921
Validation rmse logP = 0.748096
Validation R2 logP = 0.812147
Epoch 49
Train function
Loss = 1.1923e-04, PNorm = 62.9212, GNorm = 0.4663, lr_0 = 3.2303e-04
Loss = 8.7800e-05, PNorm = 62.9288, GNorm = 0.1896, lr_0 = 3.2160e-04
Loss = 7.9530e-05, PNorm = 62.9355, GNorm = 0.1988, lr_0 = 3.2018e-04
Loss = 8.4599e-05, PNorm = 62.9405, GNorm = 0.2712, lr_0 = 3.1876e-04
Loss = 7.9607e-05, PNorm = 62.9461, GNorm = 0.2913, lr_0 = 3.1735e-04
Validation rmse logD = 0.575511
Validation R2 logD = 0.777967
Validation rmse logP = 0.741968
Validation R2 logP = 0.815212
Epoch 50
Train function
Loss = 9.9703e-05, PNorm = 62.9495, GNorm = 0.1356, lr_0 = 3.1595e-04
Loss = 7.4454e-05, PNorm = 62.9537, GNorm = 0.1475, lr_0 = 3.1455e-04
Loss = 7.0331e-05, PNorm = 62.9591, GNorm = 0.1603, lr_0 = 3.1316e-04
Loss = 5.7203e-05, PNorm = 62.9649, GNorm = 0.1296, lr_0 = 3.1177e-04
Loss = 8.3628e-05, PNorm = 62.9703, GNorm = 0.1840, lr_0 = 3.1039e-04
Validation rmse logD = 0.577139
Validation R2 logD = 0.776708
Validation rmse logP = 0.744073
Validation R2 logP = 0.814162
Epoch 51
Train function
Loss = 5.6434e-05, PNorm = 62.9764, GNorm = 0.2665, lr_0 = 3.0888e-04
Loss = 9.1768e-05, PNorm = 62.9839, GNorm = 0.2364, lr_0 = 3.0752e-04
Loss = 7.9196e-05, PNorm = 62.9898, GNorm = 0.2399, lr_0 = 3.0616e-04
Loss = 6.8634e-05, PNorm = 62.9960, GNorm = 0.1151, lr_0 = 3.0480e-04
Loss = 7.5347e-05, PNorm = 63.0016, GNorm = 0.1983, lr_0 = 3.0346e-04
Loss = 8.3607e-05, PNorm = 63.0076, GNorm = 0.4103, lr_0 = 3.0211e-04
Validation rmse logD = 0.578267
Validation R2 logD = 0.775834
Validation rmse logP = 0.740811
Validation R2 logP = 0.815787
Epoch 52
Train function
Loss = 9.3290e-05, PNorm = 63.0145, GNorm = 0.2217, lr_0 = 3.0064e-04
Loss = 6.5556e-05, PNorm = 63.0201, GNorm = 0.2612, lr_0 = 2.9931e-04
Loss = 8.3954e-05, PNorm = 63.0268, GNorm = 0.1132, lr_0 = 2.9799e-04
Loss = 7.0428e-05, PNorm = 63.0299, GNorm = 0.1376, lr_0 = 2.9667e-04
Loss = 6.3665e-05, PNorm = 63.0344, GNorm = 0.1784, lr_0 = 2.9536e-04
Validation rmse logD = 0.577406
Validation R2 logD = 0.776501
Validation rmse logP = 0.739925
Validation R2 logP = 0.816228
Epoch 53
Train function
Loss = 4.9044e-05, PNorm = 63.0419, GNorm = 0.2291, lr_0 = 2.9392e-04
Loss = 7.1099e-05, PNorm = 63.0483, GNorm = 0.2765, lr_0 = 2.9262e-04
Loss = 5.9347e-05, PNorm = 63.0539, GNorm = 0.1804, lr_0 = 2.9133e-04
Loss = 5.4188e-05, PNorm = 63.0586, GNorm = 0.1370, lr_0 = 2.9004e-04
Loss = 6.2381e-05, PNorm = 63.0634, GNorm = 0.2448, lr_0 = 2.8876e-04
Validation rmse logD = 0.576204
Validation R2 logD = 0.777431
Validation rmse logP = 0.743107
Validation R2 logP = 0.814644
Epoch 54
Train function
Loss = 3.9288e-05, PNorm = 63.0681, GNorm = 0.1466, lr_0 = 2.8735e-04
Loss = 7.4434e-05, PNorm = 63.0720, GNorm = 0.4323, lr_0 = 2.8608e-04
Loss = 6.3065e-05, PNorm = 63.0782, GNorm = 0.1510, lr_0 = 2.8482e-04
Loss = 6.2735e-05, PNorm = 63.0822, GNorm = 0.2702, lr_0 = 2.8356e-04
Loss = 5.8663e-05, PNorm = 63.0887, GNorm = 0.1515, lr_0 = 2.8230e-04
Loss = 5.8415e-05, PNorm = 63.0939, GNorm = 0.2813, lr_0 = 2.8105e-04
Validation rmse logD = 0.578047
Validation R2 logD = 0.776006
Validation rmse logP = 0.741036
Validation R2 logP = 0.815675
Epoch 55
Train function
Loss = 4.5517e-05, PNorm = 63.0986, GNorm = 0.1143, lr_0 = 2.7969e-04
Loss = 4.4385e-05, PNorm = 63.1033, GNorm = 0.1402, lr_0 = 2.7845e-04
Loss = 5.0415e-05, PNorm = 63.1079, GNorm = 0.1816, lr_0 = 2.7722e-04
Loss = 5.4805e-05, PNorm = 63.1120, GNorm = 0.3828, lr_0 = 2.7599e-04
Loss = 7.3250e-05, PNorm = 63.1171, GNorm = 0.4389, lr_0 = 2.7477e-04
Validation rmse logD = 0.578904
Validation R2 logD = 0.775341
Validation rmse logP = 0.738240
Validation R2 logP = 0.817064
Epoch 56
Train function
Loss = 3.9644e-05, PNorm = 63.1223, GNorm = 0.1416, lr_0 = 2.7343e-04
Loss = 3.6617e-05, PNorm = 63.1270, GNorm = 0.1392, lr_0 = 2.7222e-04
Loss = 4.3653e-05, PNorm = 63.1312, GNorm = 0.1394, lr_0 = 2.7102e-04
Loss = 4.5300e-05, PNorm = 63.1348, GNorm = 0.1419, lr_0 = 2.6982e-04
Loss = 5.2699e-05, PNorm = 63.1376, GNorm = 0.4011, lr_0 = 2.6863e-04
Validation rmse logD = 0.580988
Validation R2 logD = 0.773720
Validation rmse logP = 0.742766
Validation R2 logP = 0.814814
Epoch 57
Train function
Loss = 4.7452e-05, PNorm = 63.1426, GNorm = 0.1111, lr_0 = 2.6732e-04
Loss = 5.7033e-05, PNorm = 63.1453, GNorm = 0.1280, lr_0 = 2.6614e-04
Loss = 4.4401e-05, PNorm = 63.1515, GNorm = 0.0993, lr_0 = 2.6496e-04
Loss = 4.3178e-05, PNorm = 63.1558, GNorm = 0.1672, lr_0 = 2.6379e-04
Loss = 4.6738e-05, PNorm = 63.1613, GNorm = 0.3119, lr_0 = 2.6262e-04
Loss = 6.1400e-05, PNorm = 63.1658, GNorm = 0.1752, lr_0 = 2.6146e-04
Loss = 2.1445e-04, PNorm = 63.1663, GNorm = 0.3698, lr_0 = 2.6134e-04
Validation rmse logD = 0.576351
Validation R2 logD = 0.777318
Validation rmse logP = 0.737566
Validation R2 logP = 0.817398
Epoch 58
Train function
Loss = 4.0837e-05, PNorm = 63.1700, GNorm = 0.1186, lr_0 = 2.6019e-04
Loss = 4.3903e-05, PNorm = 63.1746, GNorm = 0.2159, lr_0 = 2.5904e-04
Loss = 4.1076e-05, PNorm = 63.1777, GNorm = 0.2244, lr_0 = 2.5789e-04
Loss = 4.2737e-05, PNorm = 63.1827, GNorm = 0.1094, lr_0 = 2.5675e-04
Loss = 4.2956e-05, PNorm = 63.1865, GNorm = 0.2831, lr_0 = 2.5561e-04
Validation rmse logD = 0.579804
Validation R2 logD = 0.774642
Validation rmse logP = 0.743797
Validation R2 logP = 0.814299
Epoch 59
Train function
Loss = 2.6628e-05, PNorm = 63.1907, GNorm = 0.0853, lr_0 = 2.5448e-04
Loss = 2.7378e-05, PNorm = 63.1932, GNorm = 0.3399, lr_0 = 2.5336e-04
Loss = 2.7334e-05, PNorm = 63.1961, GNorm = 0.0732, lr_0 = 2.5224e-04
Loss = 3.5510e-05, PNorm = 63.1987, GNorm = 0.1004, lr_0 = 2.5112e-04
Loss = 4.1273e-05, PNorm = 63.2040, GNorm = 0.1004, lr_0 = 2.5001e-04
Validation rmse logD = 0.577690
Validation R2 logD = 0.776281
Validation rmse logP = 0.742905
Validation R2 logP = 0.814745
Epoch 60
Train function
Loss = 4.4334e-05, PNorm = 63.2083, GNorm = 0.4829, lr_0 = 2.4879e-04
Loss = 6.0254e-05, PNorm = 63.2129, GNorm = 0.1774, lr_0 = 2.4769e-04
Loss = 5.2447e-05, PNorm = 63.2172, GNorm = 0.1837, lr_0 = 2.4660e-04
Loss = 4.7711e-05, PNorm = 63.2214, GNorm = 0.1161, lr_0 = 2.4551e-04
Loss = 4.1877e-05, PNorm = 63.2260, GNorm = 0.1570, lr_0 = 2.4442e-04
Loss = 4.0181e-05, PNorm = 63.2287, GNorm = 0.2114, lr_0 = 2.4334e-04
Loss = 6.7654e-04, PNorm = 63.2289, GNorm = 0.7725, lr_0 = 2.4323e-04
Validation rmse logD = 0.578067
Validation R2 logD = 0.775990
Validation rmse logP = 0.740203
Validation R2 logP = 0.816090
Epoch 61
Train function
Loss = 6.2225e-05, PNorm = 63.2323, GNorm = 0.2666, lr_0 = 2.4216e-04
Loss = 4.6825e-05, PNorm = 63.2389, GNorm = 0.2607, lr_0 = 2.4109e-04
Loss = 4.2144e-05, PNorm = 63.2427, GNorm = 0.3047, lr_0 = 2.4002e-04
Loss = 4.4625e-05, PNorm = 63.2478, GNorm = 0.1258, lr_0 = 2.3896e-04
Loss = 5.5959e-05, PNorm = 63.2514, GNorm = 0.4455, lr_0 = 2.3790e-04
Validation rmse logD = 0.579174
Validation R2 logD = 0.775131
Validation rmse logP = 0.742595
Validation R2 logP = 0.814899
Epoch 62
Train function
Loss = 4.0927e-05, PNorm = 63.2557, GNorm = 0.1240, lr_0 = 2.3674e-04
Loss = 4.0040e-05, PNorm = 63.2599, GNorm = 0.2758, lr_0 = 2.3570e-04
Loss = 4.6536e-05, PNorm = 63.2644, GNorm = 0.2947, lr_0 = 2.3465e-04
Loss = 4.3986e-05, PNorm = 63.2683, GNorm = 0.0970, lr_0 = 2.3362e-04
Loss = 3.8688e-05, PNorm = 63.2708, GNorm = 0.1927, lr_0 = 2.3258e-04
Validation rmse logD = 0.576910
Validation R2 logD = 0.776886
Validation rmse logP = 0.741251
Validation R2 logP = 0.815569
Epoch 63
Train function
Loss = 3.6910e-05, PNorm = 63.2749, GNorm = 0.1754, lr_0 = 2.3145e-04
Loss = 3.6792e-05, PNorm = 63.2808, GNorm = 0.1040, lr_0 = 2.3043e-04
Loss = 4.7158e-05, PNorm = 63.2833, GNorm = 0.1027, lr_0 = 2.2941e-04
Loss = 3.7403e-05, PNorm = 63.2852, GNorm = 0.1112, lr_0 = 2.2839e-04
Loss = 3.1857e-05, PNorm = 63.2884, GNorm = 0.0714, lr_0 = 2.2738e-04
Validation rmse logD = 0.580249
Validation R2 logD = 0.774295
Validation rmse logP = 0.741754
Validation R2 logP = 0.815318
Epoch 64
Train function
Loss = 2.0467e-05, PNorm = 63.2927, GNorm = 0.1533, lr_0 = 2.2628e-04
Loss = 4.0360e-05, PNorm = 63.2953, GNorm = 0.3354, lr_0 = 2.2528e-04
Loss = 3.7321e-05, PNorm = 63.2971, GNorm = 0.3326, lr_0 = 2.2428e-04
Loss = 3.4397e-05, PNorm = 63.3015, GNorm = 0.2262, lr_0 = 2.2329e-04
Loss = 3.3198e-05, PNorm = 63.3040, GNorm = 0.3109, lr_0 = 2.2230e-04
Loss = 4.0757e-05, PNorm = 63.3086, GNorm = 0.2042, lr_0 = 2.2132e-04
Validation rmse logD = 0.578875
Validation R2 logD = 0.775363
Validation rmse logP = 0.741336
Validation R2 logP = 0.815526
Epoch 65
Train function
Loss = 3.8843e-05, PNorm = 63.3119, GNorm = 0.2201, lr_0 = 2.2024e-04
Loss = 4.0998e-05, PNorm = 63.3151, GNorm = 0.3976, lr_0 = 2.1927e-04
Loss = 3.4549e-05, PNorm = 63.3168, GNorm = 0.2333, lr_0 = 2.1830e-04
Loss = 3.1585e-05, PNorm = 63.3195, GNorm = 0.1690, lr_0 = 2.1733e-04
Loss = 2.8669e-05, PNorm = 63.3221, GNorm = 0.1340, lr_0 = 2.1637e-04
Validation rmse logD = 0.578577
Validation R2 logD = 0.775594
Validation rmse logP = 0.745465
Validation R2 logP = 0.813466
Epoch 66
Train function
Loss = 2.1019e-05, PNorm = 63.3245, GNorm = 0.1485, lr_0 = 2.1532e-04
Loss = 2.4417e-05, PNorm = 63.3269, GNorm = 0.1079, lr_0 = 2.1436e-04
Loss = 2.8136e-05, PNorm = 63.3293, GNorm = 0.3143, lr_0 = 2.1342e-04
Loss = 2.7504e-05, PNorm = 63.3321, GNorm = 0.1273, lr_0 = 2.1247e-04
Loss = 2.8884e-05, PNorm = 63.3357, GNorm = 0.1695, lr_0 = 2.1153e-04
Validation rmse logD = 0.580185
Validation R2 logD = 0.774345
Validation rmse logP = 0.743166
Validation R2 logP = 0.814614
Epoch 67
Train function
Loss = 1.6741e-05, PNorm = 63.3390, GNorm = 0.2289, lr_0 = 2.1060e-04
Loss = 2.9018e-05, PNorm = 63.3435, GNorm = 0.2302, lr_0 = 2.0966e-04
Loss = 2.5148e-05, PNorm = 63.3463, GNorm = 0.1153, lr_0 = 2.0874e-04
Loss = 2.3417e-05, PNorm = 63.3476, GNorm = 0.0947, lr_0 = 2.0781e-04
Loss = 2.7074e-05, PNorm = 63.3491, GNorm = 0.2272, lr_0 = 2.0689e-04
Loss = 2.3036e-05, PNorm = 63.3512, GNorm = 0.1447, lr_0 = 2.0598e-04
Validation rmse logD = 0.579798
Validation R2 logD = 0.774646
Validation rmse logP = 0.743932
Validation R2 logP = 0.814232
Epoch 68
Train function
Loss = 2.7512e-05, PNorm = 63.3544, GNorm = 0.1495, lr_0 = 2.0498e-04
Loss = 2.2647e-05, PNorm = 63.3574, GNorm = 0.1345, lr_0 = 2.0407e-04
Loss = 1.8396e-05, PNorm = 63.3591, GNorm = 0.2483, lr_0 = 2.0317e-04
Loss = 1.9569e-05, PNorm = 63.3614, GNorm = 0.0777, lr_0 = 2.0227e-04
Loss = 2.4909e-05, PNorm = 63.3652, GNorm = 0.1711, lr_0 = 2.0137e-04
Validation rmse logD = 0.579423
Validation R2 logD = 0.774938
Validation rmse logP = 0.741456
Validation R2 logP = 0.815467
Epoch 69
Train function
Loss = 1.8769e-05, PNorm = 63.3686, GNorm = 0.1527, lr_0 = 2.0039e-04
Loss = 2.2408e-05, PNorm = 63.3697, GNorm = 0.1040, lr_0 = 1.9951e-04
Loss = 1.9014e-05, PNorm = 63.3725, GNorm = 0.1062, lr_0 = 1.9863e-04
Loss = 2.1634e-05, PNorm = 63.3746, GNorm = 0.1063, lr_0 = 1.9775e-04
Loss = 2.0717e-05, PNorm = 63.3760, GNorm = 0.1752, lr_0 = 1.9687e-04
Validation rmse logD = 0.577954
Validation R2 logD = 0.776078
Validation rmse logP = 0.740585
Validation R2 logP = 0.815900
Epoch 70
Train function
Loss = 1.2550e-05, PNorm = 63.3774, GNorm = 0.0614, lr_0 = 1.9592e-04
Loss = 2.9165e-05, PNorm = 63.3808, GNorm = 0.1435, lr_0 = 1.9505e-04
Loss = 2.0578e-05, PNorm = 63.3846, GNorm = 0.0714, lr_0 = 1.9419e-04
Loss = 1.7048e-05, PNorm = 63.3872, GNorm = 0.1323, lr_0 = 1.9333e-04
Loss = 2.3805e-05, PNorm = 63.3900, GNorm = 0.0874, lr_0 = 1.9247e-04
Loss = 1.9684e-05, PNorm = 63.3927, GNorm = 0.1002, lr_0 = 1.9162e-04
Validation rmse logD = 0.579090
Validation R2 logD = 0.775196
Validation rmse logP = 0.739028
Validation R2 logP = 0.816673
Epoch 71
Train function
Loss = 1.9041e-05, PNorm = 63.3953, GNorm = 0.1537, lr_0 = 1.9069e-04
Loss = 1.4630e-05, PNorm = 63.3969, GNorm = 0.0658, lr_0 = 1.8984e-04
Loss = 1.8256e-05, PNorm = 63.3977, GNorm = 0.0815, lr_0 = 1.8900e-04
Loss = 1.7031e-05, PNorm = 63.3991, GNorm = 0.1098, lr_0 = 1.8817e-04
Loss = 1.8369e-05, PNorm = 63.4021, GNorm = 0.1955, lr_0 = 1.8734e-04
Validation rmse logD = 0.579791
Validation R2 logD = 0.774652
Validation rmse logP = 0.741188
Validation R2 logP = 0.815600
Epoch 72
Train function
Loss = 1.4134e-05, PNorm = 63.4042, GNorm = 0.1498, lr_0 = 1.8643e-04
Loss = 1.3446e-05, PNorm = 63.4061, GNorm = 0.0838, lr_0 = 1.8560e-04
Loss = 1.3315e-05, PNorm = 63.4068, GNorm = 0.0595, lr_0 = 1.8478e-04
Loss = 1.5322e-05, PNorm = 63.4088, GNorm = 0.2038, lr_0 = 1.8396e-04
Loss = 1.7208e-05, PNorm = 63.4098, GNorm = 0.1531, lr_0 = 1.8315e-04
Validation rmse logD = 0.579340
Validation R2 logD = 0.775002
Validation rmse logP = 0.739112
Validation R2 logP = 0.816631
Epoch 73
Train function
Loss = 1.2482e-05, PNorm = 63.4122, GNorm = 0.0934, lr_0 = 1.8226e-04
Loss = 1.0064e-05, PNorm = 63.4131, GNorm = 0.1057, lr_0 = 1.8145e-04
Loss = 1.1288e-05, PNorm = 63.4142, GNorm = 0.1257, lr_0 = 1.8065e-04
Loss = 1.7201e-05, PNorm = 63.4159, GNorm = 0.0549, lr_0 = 1.7985e-04
Loss = 1.2496e-05, PNorm = 63.4178, GNorm = 0.0966, lr_0 = 1.7905e-04
Loss = 1.8657e-05, PNorm = 63.4189, GNorm = 0.3486, lr_0 = 1.7826e-04
Loss = 4.0584e-05, PNorm = 63.4189, GNorm = 0.1733, lr_0 = 1.7818e-04
Validation rmse logD = 0.580747
Validation R2 logD = 0.773908
Validation rmse logP = 0.741998
Validation R2 logP = 0.815197
Epoch 74
Train function
Loss = 2.0250e-05, PNorm = 63.4194, GNorm = 0.0894, lr_0 = 1.7739e-04
Loss = 1.5286e-05, PNorm = 63.4210, GNorm = 0.1167, lr_0 = 1.7661e-04
Loss = 1.5582e-05, PNorm = 63.4237, GNorm = 0.1687, lr_0 = 1.7583e-04
Loss = 1.5092e-05, PNorm = 63.4250, GNorm = 0.0799, lr_0 = 1.7505e-04
Loss = 1.0452e-05, PNorm = 63.4266, GNorm = 0.0643, lr_0 = 1.7428e-04
Validation rmse logD = 0.580406
Validation R2 logD = 0.774173
Validation rmse logP = 0.739991
Validation R2 logP = 0.816195
Epoch 75
Train function
Loss = 1.1867e-05, PNorm = 63.4283, GNorm = 0.0940, lr_0 = 1.7351e-04
Loss = 1.3284e-05, PNorm = 63.4300, GNorm = 0.0910, lr_0 = 1.7274e-04
Loss = 1.3696e-05, PNorm = 63.4314, GNorm = 0.1734, lr_0 = 1.7197e-04
Loss = 1.5785e-05, PNorm = 63.4336, GNorm = 0.0719, lr_0 = 1.7121e-04
Loss = 1.9512e-05, PNorm = 63.4362, GNorm = 0.0686, lr_0 = 1.7046e-04
Validation rmse logD = 0.580331
Validation R2 logD = 0.774232
Validation rmse logP = 0.743085
Validation R2 logP = 0.814655
Epoch 76
Train function
Loss = 1.2662e-05, PNorm = 63.4372, GNorm = 0.0707, lr_0 = 1.6963e-04
Loss = 1.5839e-05, PNorm = 63.4380, GNorm = 0.0500, lr_0 = 1.6888e-04
Loss = 1.8375e-05, PNorm = 63.4403, GNorm = 0.1964, lr_0 = 1.6813e-04
Loss = 1.9377e-05, PNorm = 63.4422, GNorm = 0.2316, lr_0 = 1.6739e-04
Loss = 1.6150e-05, PNorm = 63.4437, GNorm = 0.1636, lr_0 = 1.6665e-04
Loss = 1.8060e-05, PNorm = 63.4451, GNorm = 0.1693, lr_0 = 1.6591e-04
Loss = 8.1494e-05, PNorm = 63.4452, GNorm = 0.1743, lr_0 = 1.6584e-04
Validation rmse logD = 0.581543
Validation R2 logD = 0.773288
Validation rmse logP = 0.741672
Validation R2 logP = 0.815359
Epoch 77
Train function
Loss = 1.5112e-05, PNorm = 63.4471, GNorm = 0.1177, lr_0 = 1.6510e-04
Loss = 1.3276e-05, PNorm = 63.4490, GNorm = 0.0932, lr_0 = 1.6437e-04
Loss = 1.4177e-05, PNorm = 63.4506, GNorm = 0.0854, lr_0 = 1.6364e-04
Loss = 1.8126e-05, PNorm = 63.4521, GNorm = 0.1866, lr_0 = 1.6292e-04
Loss = 1.5473e-05, PNorm = 63.4540, GNorm = 0.0877, lr_0 = 1.6220e-04
Validation rmse logD = 0.579931
Validation R2 logD = 0.774543
Validation rmse logP = 0.740435
Validation R2 logP = 0.815975
Epoch 78
Train function
Loss = 1.3075e-05, PNorm = 63.4563, GNorm = 0.0620, lr_0 = 1.6141e-04
Loss = 1.3095e-05, PNorm = 63.4578, GNorm = 0.0859, lr_0 = 1.6070e-04
Loss = 1.0942e-05, PNorm = 63.4587, GNorm = 0.1173, lr_0 = 1.5999e-04
Loss = 1.4771e-05, PNorm = 63.4610, GNorm = 0.1345, lr_0 = 1.5928e-04
Loss = 1.5196e-05, PNorm = 63.4623, GNorm = 0.1749, lr_0 = 1.5857e-04
Validation rmse logD = 0.580194
Validation R2 logD = 0.774338
Validation rmse logP = 0.742674
Validation R2 logP = 0.814860
Epoch 79
Train function
Loss = 9.5525e-06, PNorm = 63.4633, GNorm = 0.0885, lr_0 = 1.5780e-04
Loss = 8.9071e-06, PNorm = 63.4644, GNorm = 0.0446, lr_0 = 1.5710e-04
Loss = 9.7161e-06, PNorm = 63.4657, GNorm = 0.1238, lr_0 = 1.5641e-04
Loss = 8.7992e-06, PNorm = 63.4664, GNorm = 0.0570, lr_0 = 1.5572e-04
Loss = 1.8209e-05, PNorm = 63.4683, GNorm = 0.0851, lr_0 = 1.5503e-04
Validation rmse logD = 0.580637
Validation R2 logD = 0.773993
Validation rmse logP = 0.745373
Validation R2 logP = 0.813512
Epoch 80
Train function
Loss = 5.8730e-06, PNorm = 63.4700, GNorm = 0.0443, lr_0 = 1.5427e-04
Loss = 7.9855e-06, PNorm = 63.4707, GNorm = 0.0439, lr_0 = 1.5359e-04
Loss = 8.9327e-06, PNorm = 63.4720, GNorm = 0.1047, lr_0 = 1.5291e-04
Loss = 7.9926e-06, PNorm = 63.4735, GNorm = 0.1358, lr_0 = 1.5224e-04
Loss = 1.1410e-05, PNorm = 63.4746, GNorm = 0.0985, lr_0 = 1.5156e-04
Loss = 1.3668e-05, PNorm = 63.4762, GNorm = 0.0669, lr_0 = 1.5089e-04
Validation rmse logD = 0.582817
Validation R2 logD = 0.772293
Validation rmse logP = 0.739427
Validation R2 logP = 0.816475
Epoch 81
Train function
Loss = 1.8454e-05, PNorm = 63.4783, GNorm = 0.1461, lr_0 = 1.5016e-04
Loss = 1.7155e-05, PNorm = 63.4801, GNorm = 0.1002, lr_0 = 1.4949e-04
Loss = 2.7954e-05, PNorm = 63.4804, GNorm = 0.1139, lr_0 = 1.4883e-04
Loss = 1.4934e-05, PNorm = 63.4823, GNorm = 0.0890, lr_0 = 1.4817e-04
Loss = 1.3446e-05, PNorm = 63.4854, GNorm = 0.1826, lr_0 = 1.4752e-04
Validation rmse logD = 0.580551
Validation R2 logD = 0.774061
Validation rmse logP = 0.741963
Validation R2 logP = 0.815214
Epoch 82
Train function
Loss = 1.6298e-05, PNorm = 63.4857, GNorm = 0.1891, lr_0 = 1.4680e-04
Loss = 1.2414e-05, PNorm = 63.4869, GNorm = 0.0739, lr_0 = 1.4615e-04
Loss = 1.7900e-05, PNorm = 63.4890, GNorm = 0.2100, lr_0 = 1.4551e-04
Loss = 1.5788e-05, PNorm = 63.4906, GNorm = 0.1072, lr_0 = 1.4486e-04
Loss = 1.1253e-05, PNorm = 63.4923, GNorm = 0.0585, lr_0 = 1.4422e-04
Validation rmse logD = 0.581115
Validation R2 logD = 0.773622
Validation rmse logP = 0.744170
Validation R2 logP = 0.814113
Epoch 83
Train function
Loss = 8.3833e-06, PNorm = 63.4937, GNorm = 0.1159, lr_0 = 1.4352e-04
Loss = 1.1942e-05, PNorm = 63.4955, GNorm = 0.0786, lr_0 = 1.4288e-04
Loss = 1.1735e-05, PNorm = 63.4967, GNorm = 0.2079, lr_0 = 1.4225e-04
Loss = 1.0020e-05, PNorm = 63.4981, GNorm = 0.0593, lr_0 = 1.4162e-04
Loss = 9.4077e-06, PNorm = 63.4987, GNorm = 0.1305, lr_0 = 1.4100e-04
Loss = 1.2382e-05, PNorm = 63.4996, GNorm = 0.1384, lr_0 = 1.4037e-04
Validation rmse logD = 0.581380
Validation R2 logD = 0.773415
Validation rmse logP = 0.741454
Validation R2 logP = 0.815468
Epoch 84
Train function
Loss = 1.7210e-05, PNorm = 63.4999, GNorm = 0.1030, lr_0 = 1.3975e-04
Loss = 1.3465e-05, PNorm = 63.5009, GNorm = 0.1723, lr_0 = 1.3913e-04
Loss = 8.8791e-06, PNorm = 63.5014, GNorm = 0.0669, lr_0 = 1.3852e-04
Loss = 1.2279e-05, PNorm = 63.5030, GNorm = 0.0675, lr_0 = 1.3791e-04
Loss = 7.0233e-06, PNorm = 63.5044, GNorm = 0.0611, lr_0 = 1.3730e-04
Validation rmse logD = 0.581788
Validation R2 logD = 0.773097
Validation rmse logP = 0.740658
Validation R2 logP = 0.815864
Epoch 85
Train function
Loss = 9.0425e-06, PNorm = 63.5062, GNorm = 0.0991, lr_0 = 1.3663e-04
Loss = 9.2858e-06, PNorm = 63.5068, GNorm = 0.0647, lr_0 = 1.3602e-04
Loss = 8.7213e-06, PNorm = 63.5074, GNorm = 0.0585, lr_0 = 1.3542e-04
Loss = 1.1408e-05, PNorm = 63.5090, GNorm = 0.1429, lr_0 = 1.3482e-04
Loss = 1.1624e-05, PNorm = 63.5105, GNorm = 0.1514, lr_0 = 1.3423e-04
Validation rmse logD = 0.579979
Validation R2 logD = 0.774505
Validation rmse logP = 0.742557
Validation R2 logP = 0.814918
Epoch 86
Train function
Loss = 2.6486e-05, PNorm = 63.5105, GNorm = 0.4021, lr_0 = 1.3357e-04
Loss = 1.7061e-05, PNorm = 63.5125, GNorm = 0.1934, lr_0 = 1.3298e-04
Loss = 1.6146e-05, PNorm = 63.5149, GNorm = 0.0694, lr_0 = 1.3239e-04
Loss = 1.2182e-05, PNorm = 63.5164, GNorm = 0.1986, lr_0 = 1.3181e-04
Loss = 1.5641e-05, PNorm = 63.5179, GNorm = 0.0683, lr_0 = 1.3123e-04
Loss = 8.0621e-06, PNorm = 63.5187, GNorm = 0.0507, lr_0 = 1.3065e-04
Validation rmse logD = 0.581705
Validation R2 logD = 0.773161
Validation rmse logP = 0.740760
Validation R2 logP = 0.815813
Epoch 87
Train function
Loss = 1.0613e-05, PNorm = 63.5199, GNorm = 0.0972, lr_0 = 1.3001e-04
Loss = 8.7475e-06, PNorm = 63.5212, GNorm = 0.1098, lr_0 = 1.2944e-04
Loss = 8.6721e-06, PNorm = 63.5230, GNorm = 0.0860, lr_0 = 1.2886e-04
Loss = 1.1554e-05, PNorm = 63.5244, GNorm = 0.0714, lr_0 = 1.2829e-04
Loss = 1.0697e-05, PNorm = 63.5245, GNorm = 0.0561, lr_0 = 1.2773e-04
Validation rmse logD = 0.579772
Validation R2 logD = 0.774666
Validation rmse logP = 0.743142
Validation R2 logP = 0.814626
Epoch 88
Train function
Loss = 7.5820e-06, PNorm = 63.5261, GNorm = 0.1050, lr_0 = 1.2710e-04
Loss = 1.0006e-05, PNorm = 63.5268, GNorm = 0.1469, lr_0 = 1.2654e-04
Loss = 8.5322e-06, PNorm = 63.5271, GNorm = 0.1337, lr_0 = 1.2598e-04
Loss = 1.0853e-05, PNorm = 63.5272, GNorm = 0.1604, lr_0 = 1.2542e-04
Loss = 9.4428e-06, PNorm = 63.5284, GNorm = 0.1396, lr_0 = 1.2487e-04
Validation rmse logD = 0.580775
Validation R2 logD = 0.773886
Validation rmse logP = 0.741908
Validation R2 logP = 0.815242
Epoch 89
Train function
Loss = 5.4804e-06, PNorm = 63.5298, GNorm = 0.0546, lr_0 = 1.2426e-04
Loss = 8.6432e-06, PNorm = 63.5302, GNorm = 0.0763, lr_0 = 1.2371e-04
Loss = 9.2819e-06, PNorm = 63.5309, GNorm = 0.1127, lr_0 = 1.2317e-04
Loss = 9.9109e-06, PNorm = 63.5326, GNorm = 0.1901, lr_0 = 1.2262e-04
Loss = 1.1134e-05, PNorm = 63.5339, GNorm = 0.1009, lr_0 = 1.2208e-04
Loss = 1.1400e-05, PNorm = 63.5347, GNorm = 0.0898, lr_0 = 1.2154e-04
Loss = 1.2816e-04, PNorm = 63.5348, GNorm = 0.1672, lr_0 = 1.2148e-04
Validation rmse logD = 0.579556
Validation R2 logD = 0.774834
Validation rmse logP = 0.742108
Validation R2 logP = 0.815142
Epoch 90
Train function
Loss = 1.0575e-05, PNorm = 63.5356, GNorm = 0.0560, lr_0 = 1.2095e-04
Loss = 9.3619e-06, PNorm = 63.5362, GNorm = 0.0646, lr_0 = 1.2041e-04
Loss = 7.1485e-06, PNorm = 63.5370, GNorm = 0.0614, lr_0 = 1.1988e-04
Loss = 7.0247e-06, PNorm = 63.5381, GNorm = 0.0401, lr_0 = 1.1935e-04
Loss = 1.0037e-05, PNorm = 63.5388, GNorm = 0.0607, lr_0 = 1.1882e-04
Validation rmse logD = 0.580752
Validation R2 logD = 0.773904
Validation rmse logP = 0.741057
Validation R2 logP = 0.815665
Epoch 91
Train function
Loss = 7.8651e-06, PNorm = 63.5401, GNorm = 0.1119, lr_0 = 1.1824e-04
Loss = 8.7824e-06, PNorm = 63.5415, GNorm = 0.0502, lr_0 = 1.1772e-04
Loss = 1.9048e-05, PNorm = 63.5430, GNorm = 0.0689, lr_0 = 1.1720e-04
Loss = 7.4431e-06, PNorm = 63.5439, GNorm = 0.0549, lr_0 = 1.1668e-04
Loss = 8.1684e-06, PNorm = 63.5448, GNorm = 0.0464, lr_0 = 1.1616e-04
Validation rmse logD = 0.580807
Validation R2 logD = 0.773861
Validation rmse logP = 0.738771
Validation R2 logP = 0.816801
Epoch 92
Train function
Loss = 1.7152e-05, PNorm = 63.5461, GNorm = 0.0686, lr_0 = 1.1565e-04
Loss = 3.0774e-05, PNorm = 63.5465, GNorm = 0.2691, lr_0 = 1.1514e-04
Loss = 2.3400e-05, PNorm = 63.5474, GNorm = 0.2052, lr_0 = 1.1463e-04
Loss = 1.8183e-05, PNorm = 63.5494, GNorm = 0.0804, lr_0 = 1.1412e-04
Loss = 1.3140e-05, PNorm = 63.5497, GNorm = 0.1135, lr_0 = 1.1362e-04
Loss = 1.1549e-05, PNorm = 63.5507, GNorm = 0.0818, lr_0 = 1.1312e-04
Loss = 6.6100e-05, PNorm = 63.5509, GNorm = 0.1274, lr_0 = 1.1307e-04
Validation rmse logD = 0.580201
Validation R2 logD = 0.774333
Validation rmse logP = 0.743938
Validation R2 logP = 0.814229
Epoch 93
Train function
Loss = 1.4755e-05, PNorm = 63.5527, GNorm = 0.0769, lr_0 = 1.1257e-04
Loss = 1.2708e-05, PNorm = 63.5540, GNorm = 0.0489, lr_0 = 1.1207e-04
Loss = 1.1448e-05, PNorm = 63.5548, GNorm = 0.1648, lr_0 = 1.1157e-04
Loss = 1.2106e-05, PNorm = 63.5562, GNorm = 0.2312, lr_0 = 1.1108e-04
Loss = 1.6257e-05, PNorm = 63.5574, GNorm = 0.0787, lr_0 = 1.1059e-04
Validation rmse logD = 0.581392
Validation R2 logD = 0.773405
Validation rmse logP = 0.745104
Validation R2 logP = 0.813646
Epoch 94
Train function
Loss = 8.3470e-06, PNorm = 63.5584, GNorm = 0.0964, lr_0 = 1.1005e-04
Loss = 1.0064e-05, PNorm = 63.5590, GNorm = 0.1710, lr_0 = 1.0956e-04
Loss = 7.7785e-06, PNorm = 63.5602, GNorm = 0.1292, lr_0 = 1.0908e-04
Loss = 8.0509e-06, PNorm = 63.5605, GNorm = 0.1189, lr_0 = 1.0860e-04
Loss = 8.4592e-06, PNorm = 63.5607, GNorm = 0.0823, lr_0 = 1.0811e-04
Validation rmse logD = 0.581631
Validation R2 logD = 0.773219
Validation rmse logP = 0.739915
Validation R2 logP = 0.816233
Epoch 95
Train function
Loss = 1.6914e-05, PNorm = 63.5627, GNorm = 0.3048, lr_0 = 1.0759e-04
Loss = 1.4739e-05, PNorm = 63.5640, GNorm = 0.3119, lr_0 = 1.0711e-04
Loss = 1.2354e-05, PNorm = 63.5654, GNorm = 0.1908, lr_0 = 1.0664e-04
Loss = 1.1702e-05, PNorm = 63.5657, GNorm = 0.1844, lr_0 = 1.0617e-04
Loss = 1.1231e-05, PNorm = 63.5667, GNorm = 0.0885, lr_0 = 1.0570e-04
Validation rmse logD = 0.582410
Validation R2 logD = 0.772611
Validation rmse logP = 0.740999
Validation R2 logP = 0.815694
Epoch 96
Train function
Loss = 8.3408e-06, PNorm = 63.5675, GNorm = 0.1419, lr_0 = 1.0518e-04
Loss = 1.2922e-05, PNorm = 63.5688, GNorm = 0.1319, lr_0 = 1.0472e-04
Loss = 1.3959e-05, PNorm = 63.5695, GNorm = 0.2430, lr_0 = 1.0426e-04
Loss = 1.1015e-05, PNorm = 63.5698, GNorm = 0.0642, lr_0 = 1.0379e-04
Loss = 1.2695e-05, PNorm = 63.5712, GNorm = 0.0600, lr_0 = 1.0333e-04
Loss = 1.0290e-05, PNorm = 63.5718, GNorm = 0.0470, lr_0 = 1.0288e-04
Validation rmse logD = 0.581814
Validation R2 logD = 0.773076
Validation rmse logP = 0.742893
Validation R2 logP = 0.814751
Epoch 97
Train function
Loss = 9.6139e-06, PNorm = 63.5724, GNorm = 0.1206, lr_0 = 1.0238e-04
Loss = 6.3242e-06, PNorm = 63.5726, GNorm = 0.0887, lr_0 = 1.0192e-04
Loss = 8.3739e-06, PNorm = 63.5732, GNorm = 0.0562, lr_0 = 1.0147e-04
Loss = 6.9805e-06, PNorm = 63.5737, GNorm = 0.1531, lr_0 = 1.0102e-04
Loss = 9.8276e-06, PNorm = 63.5740, GNorm = 0.0662, lr_0 = 1.0058e-04
Validation rmse logD = 0.582431
Validation R2 logD = 0.772594
Validation rmse logP = 0.740470
Validation R2 logP = 0.815957
Epoch 98
Train function
Loss = 1.3571e-05, PNorm = 63.5757, GNorm = 0.2387, lr_0 = 1.0009e-04
Loss = 1.3140e-05, PNorm = 63.5773, GNorm = 0.0801, lr_0 = 1.0000e-04
Loss = 8.4776e-06, PNorm = 63.5784, GNorm = 0.0999, lr_0 = 1.0000e-04
Loss = 7.9067e-06, PNorm = 63.5789, GNorm = 0.1296, lr_0 = 1.0000e-04
Loss = 7.2209e-06, PNorm = 63.5798, GNorm = 0.0794, lr_0 = 1.0000e-04
Validation rmse logD = 0.580894
Validation R2 logD = 0.773793
Validation rmse logP = 0.743891
Validation R2 logP = 0.814252
Epoch 99
Train function
Loss = 3.4505e-06, PNorm = 63.5802, GNorm = 0.0640, lr_0 = 1.0000e-04
Loss = 6.5835e-06, PNorm = 63.5806, GNorm = 0.0603, lr_0 = 1.0000e-04
Loss = 5.3231e-06, PNorm = 63.5815, GNorm = 0.0420, lr_0 = 1.0000e-04
Loss = 4.8511e-06, PNorm = 63.5824, GNorm = 0.0499, lr_0 = 1.0000e-04
Loss = 9.3112e-06, PNorm = 63.5834, GNorm = 0.1308, lr_0 = 1.0000e-04
Loss = 5.7022e-06, PNorm = 63.5841, GNorm = 0.0432, lr_0 = 1.0000e-04
Validation rmse logD = 0.581598
Validation R2 logD = 0.773245
Validation rmse logP = 0.742463
Validation R2 logP = 0.814965
Model 0 best validation rmse = 0.653984 on epoch 46
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.644634
Model 0 test R2 logD = 0.708148
Model 0 test rmse logP = 0.752062
Model 0 test R2 logP = 0.755772
Ensemble test rmse  logD= 0.644634
Ensemble test R2  logD= 0.708148
Ensemble test rmse  logP= 0.752062
Ensemble test R2  logP= 0.755772
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 1.8011e-02, PNorm = 52.9416, GNorm = 4.4944, lr_0 = 1.9340e-04
Loss = 1.8814e-02, PNorm = 52.9514, GNorm = 7.3441, lr_0 = 2.7830e-04
Loss = 1.5119e-02, PNorm = 52.9661, GNorm = 6.2713, lr_0 = 3.6321e-04
Loss = 1.3969e-02, PNorm = 52.9850, GNorm = 1.8912, lr_0 = 4.4811e-04
Loss = 1.4735e-02, PNorm = 53.0101, GNorm = 3.2855, lr_0 = 5.3302e-04
Validation rmse logD = 1.149854
Validation R2 logD = 0.106663
Validation rmse logP = 0.993522
Validation R2 logP = 0.391456
Epoch 1
Train function
Loss = 1.4836e-02, PNorm = 53.0478, GNorm = 1.8211, lr_0 = 6.2642e-04
Loss = 1.4979e-02, PNorm = 53.0924, GNorm = 5.5104, lr_0 = 7.1132e-04
Loss = 1.2025e-02, PNorm = 53.1417, GNorm = 4.4725, lr_0 = 7.9623e-04
Loss = 1.1489e-02, PNorm = 53.1938, GNorm = 4.1956, lr_0 = 8.8113e-04
Loss = 1.0103e-02, PNorm = 53.2509, GNorm = 1.2519, lr_0 = 9.6604e-04
Validation rmse logD = 0.919026
Validation R2 logD = 0.429329
Validation rmse logP = 0.881947
Validation R2 logP = 0.520463
Epoch 2
Train function
Loss = 9.1956e-03, PNorm = 53.3215, GNorm = 1.2972, lr_0 = 9.9690e-04
Loss = 1.0773e-02, PNorm = 53.3946, GNorm = 4.0645, lr_0 = 9.9249e-04
Loss = 8.9152e-03, PNorm = 53.4674, GNorm = 1.7802, lr_0 = 9.8810e-04
Loss = 8.8932e-03, PNorm = 53.5585, GNorm = 3.1163, lr_0 = 9.8373e-04
Loss = 9.0444e-03, PNorm = 53.6448, GNorm = 2.1671, lr_0 = 9.7938e-04
Validation rmse logD = 0.773122
Validation R2 logD = 0.596145
Validation rmse logP = 1.013133
Validation R2 logP = 0.367194
Epoch 3
Train function
Loss = 8.2161e-03, PNorm = 53.7754, GNorm = 2.1022, lr_0 = 9.7462e-04
Loss = 7.9984e-03, PNorm = 53.9036, GNorm = 2.5768, lr_0 = 9.7030e-04
Loss = 6.9495e-03, PNorm = 54.0092, GNorm = 2.0127, lr_0 = 9.6601e-04
Loss = 8.5206e-03, PNorm = 54.1252, GNorm = 1.8995, lr_0 = 9.6174e-04
Loss = 7.2651e-03, PNorm = 54.2251, GNorm = 3.4588, lr_0 = 9.5749e-04
Loss = 7.1399e-03, PNorm = 54.3242, GNorm = 1.2263, lr_0 = 9.5325e-04
Validation rmse logD = 0.788599
Validation R2 logD = 0.579813
Validation rmse logP = 0.831568
Validation R2 logP = 0.573683
Epoch 4
Train function
Loss = 7.4727e-03, PNorm = 54.4457, GNorm = 3.1430, lr_0 = 9.4861e-04
Loss = 6.0185e-03, PNorm = 54.5462, GNorm = 2.4723, lr_0 = 9.4442e-04
Loss = 6.5070e-03, PNorm = 54.6300, GNorm = 2.0839, lr_0 = 9.4024e-04
Loss = 6.9588e-03, PNorm = 54.7100, GNorm = 1.9553, lr_0 = 9.3608e-04
Loss = 6.1845e-03, PNorm = 54.7987, GNorm = 1.6975, lr_0 = 9.3194e-04
Validation rmse logD = 0.733633
Validation R2 logD = 0.636347
Validation rmse logP = 0.645940
Validation R2 logP = 0.742770
Epoch 5
Train function
Loss = 4.7765e-03, PNorm = 54.8728, GNorm = 1.1554, lr_0 = 9.2741e-04
Loss = 6.1231e-03, PNorm = 54.9522, GNorm = 1.5585, lr_0 = 9.2330e-04
Loss = 6.0469e-03, PNorm = 55.0347, GNorm = 1.8831, lr_0 = 9.1922e-04
Loss = 5.2280e-03, PNorm = 55.1289, GNorm = 2.0366, lr_0 = 9.1515e-04
Loss = 5.0735e-03, PNorm = 55.1995, GNorm = 2.6200, lr_0 = 9.1111e-04
Validation rmse logD = 0.741982
Validation R2 logD = 0.628022
Validation rmse logP = 0.677801
Validation R2 logP = 0.716768
Epoch 6
Train function
Loss = 4.3590e-03, PNorm = 55.2609, GNorm = 0.9253, lr_0 = 9.0667e-04
Loss = 5.3753e-03, PNorm = 55.3496, GNorm = 0.7993, lr_0 = 9.0266e-04
Loss = 4.3168e-03, PNorm = 55.4273, GNorm = 1.0962, lr_0 = 8.9867e-04
Loss = 4.8705e-03, PNorm = 55.5076, GNorm = 1.7018, lr_0 = 8.9469e-04
Loss = 5.4236e-03, PNorm = 55.6013, GNorm = 1.1120, lr_0 = 8.9074e-04
Loss = 4.9349e-03, PNorm = 55.6910, GNorm = 3.2410, lr_0 = 8.8680e-04
Validation rmse logD = 0.708496
Validation R2 logD = 0.660840
Validation rmse logP = 0.824468
Validation R2 logP = 0.580932
Epoch 7
Train function
Loss = 3.8547e-03, PNorm = 55.7812, GNorm = 3.6159, lr_0 = 8.8248e-04
Loss = 4.8420e-03, PNorm = 55.8635, GNorm = 1.0616, lr_0 = 8.7858e-04
Loss = 5.3923e-03, PNorm = 55.9453, GNorm = 0.9681, lr_0 = 8.7469e-04
Loss = 4.3940e-03, PNorm = 56.0351, GNorm = 0.9139, lr_0 = 8.7082e-04
Loss = 3.8730e-03, PNorm = 56.1146, GNorm = 1.3161, lr_0 = 8.6697e-04
Validation rmse logD = 0.686147
Validation R2 logD = 0.681900
Validation rmse logP = 0.667412
Validation R2 logP = 0.725385
Epoch 8
Train function
Loss = 3.5198e-03, PNorm = 56.1939, GNorm = 1.9267, lr_0 = 8.6276e-04
Loss = 3.6371e-03, PNorm = 56.2634, GNorm = 1.0453, lr_0 = 8.5894e-04
Loss = 3.6165e-03, PNorm = 56.3295, GNorm = 1.0719, lr_0 = 8.5514e-04
Loss = 3.4290e-03, PNorm = 56.4000, GNorm = 0.7927, lr_0 = 8.5136e-04
Loss = 3.3006e-03, PNorm = 56.4599, GNorm = 2.5087, lr_0 = 8.4759e-04
Validation rmse logD = 0.650261
Validation R2 logD = 0.714304
Validation rmse logP = 0.757511
Validation R2 logP = 0.646234
Epoch 9
Train function
Loss = 3.8193e-03, PNorm = 56.5184, GNorm = 3.2529, lr_0 = 8.4384e-04
Loss = 3.3571e-03, PNorm = 56.6052, GNorm = 1.1461, lr_0 = 8.4011e-04
Loss = 2.8955e-03, PNorm = 56.6851, GNorm = 1.7128, lr_0 = 8.3639e-04
Loss = 3.3515e-03, PNorm = 56.7556, GNorm = 1.0759, lr_0 = 8.3269e-04
Loss = 3.3453e-03, PNorm = 56.8389, GNorm = 1.0751, lr_0 = 8.2901e-04
Loss = 4.0113e-03, PNorm = 56.9025, GNorm = 1.7784, lr_0 = 8.2534e-04
Validation rmse logD = 0.689166
Validation R2 logD = 0.679094
Validation rmse logP = 0.647108
Validation R2 logP = 0.741839
Epoch 10
Train function
Loss = 3.1237e-03, PNorm = 56.9812, GNorm = 1.0812, lr_0 = 8.2133e-04
Loss = 3.2974e-03, PNorm = 57.0691, GNorm = 0.9444, lr_0 = 8.1770e-04
Loss = 2.8760e-03, PNorm = 57.1406, GNorm = 1.3134, lr_0 = 8.1408e-04
Loss = 2.7456e-03, PNorm = 57.2072, GNorm = 0.8090, lr_0 = 8.1048e-04
Loss = 2.8759e-03, PNorm = 57.2653, GNorm = 0.8592, lr_0 = 8.0689e-04
Validation rmse logD = 0.637197
Validation R2 logD = 0.725667
Validation rmse logP = 0.673140
Validation R2 logP = 0.720650
Epoch 11
Train function
Loss = 3.0910e-03, PNorm = 57.3382, GNorm = 3.6266, lr_0 = 8.0297e-04
Loss = 3.1314e-03, PNorm = 57.4002, GNorm = 0.7820, lr_0 = 7.9942e-04
Loss = 2.3938e-03, PNorm = 57.4874, GNorm = 2.6605, lr_0 = 7.9588e-04
Loss = 3.3129e-03, PNorm = 57.5418, GNorm = 1.8978, lr_0 = 7.9236e-04
Loss = 2.9352e-03, PNorm = 57.6078, GNorm = 1.3401, lr_0 = 7.8885e-04
Validation rmse logD = 0.636188
Validation R2 logD = 0.726535
Validation rmse logP = 0.648909
Validation R2 logP = 0.740400
Epoch 12
Train function
Loss = 1.6008e-03, PNorm = 57.6739, GNorm = 0.5116, lr_0 = 7.8502e-04
Loss = 2.1716e-03, PNorm = 57.7342, GNorm = 2.2238, lr_0 = 7.8154e-04
Loss = 1.9935e-03, PNorm = 57.7865, GNorm = 0.8021, lr_0 = 7.7809e-04
Loss = 2.0313e-03, PNorm = 57.8563, GNorm = 0.8122, lr_0 = 7.7465e-04
Loss = 2.4286e-03, PNorm = 57.9068, GNorm = 1.9223, lr_0 = 7.7122e-04
Loss = 2.7099e-03, PNorm = 57.9558, GNorm = 0.8271, lr_0 = 7.6781e-04
Loss = 2.0318e-02, PNorm = 57.9617, GNorm = 3.3221, lr_0 = 7.6747e-04
Validation rmse logD = 0.624503
Validation R2 logD = 0.736489
Validation rmse logP = 0.647007
Validation R2 logP = 0.741919
Epoch 13
Train function
Loss = 2.4967e-03, PNorm = 58.0357, GNorm = 1.6920, lr_0 = 7.6407e-04
Loss = 2.2320e-03, PNorm = 58.1052, GNorm = 1.3383, lr_0 = 7.6069e-04
Loss = 1.9275e-03, PNorm = 58.1627, GNorm = 0.9768, lr_0 = 7.5733e-04
Loss = 1.7670e-03, PNorm = 58.2358, GNorm = 1.0186, lr_0 = 7.5398e-04
Loss = 2.4511e-03, PNorm = 58.2922, GNorm = 0.8404, lr_0 = 7.5064e-04
Validation rmse logD = 0.663733
Validation R2 logD = 0.702342
Validation rmse logP = 0.632057
Validation R2 logP = 0.753708
Epoch 14
Train function
Loss = 2.0037e-03, PNorm = 58.3656, GNorm = 1.0989, lr_0 = 7.4699e-04
Loss = 1.9328e-03, PNorm = 58.4400, GNorm = 1.6578, lr_0 = 7.4369e-04
Loss = 2.2624e-03, PNorm = 58.4905, GNorm = 1.8366, lr_0 = 7.4040e-04
Loss = 2.2422e-03, PNorm = 58.5511, GNorm = 0.9887, lr_0 = 7.3712e-04
Loss = 2.1289e-03, PNorm = 58.6207, GNorm = 0.6342, lr_0 = 7.3386e-04
Validation rmse logD = 0.618745
Validation R2 logD = 0.741325
Validation rmse logP = 0.630589
Validation R2 logP = 0.754851
Epoch 15
Train function
Loss = 1.7511e-03, PNorm = 58.6689, GNorm = 1.8696, lr_0 = 7.3029e-04
Loss = 2.0738e-03, PNorm = 58.7275, GNorm = 1.8114, lr_0 = 7.2706e-04
Loss = 1.9272e-03, PNorm = 58.7835, GNorm = 1.2696, lr_0 = 7.2385e-04
Loss = 1.9217e-03, PNorm = 58.8557, GNorm = 0.7005, lr_0 = 7.2064e-04
Loss = 1.6913e-03, PNorm = 58.9079, GNorm = 1.7446, lr_0 = 7.1746e-04
Validation rmse logD = 0.611133
Validation R2 logD = 0.747651
Validation rmse logP = 0.630072
Validation R2 logP = 0.755253
Epoch 16
Train function
Loss = 1.0128e-03, PNorm = 58.9638, GNorm = 0.8606, lr_0 = 7.1397e-04
Loss = 1.4897e-03, PNorm = 59.0157, GNorm = 1.4819, lr_0 = 7.1081e-04
Loss = 1.2531e-03, PNorm = 59.0572, GNorm = 0.4850, lr_0 = 7.0766e-04
Loss = 1.4186e-03, PNorm = 59.1010, GNorm = 1.8072, lr_0 = 7.0453e-04
Loss = 1.6305e-03, PNorm = 59.1464, GNorm = 1.5766, lr_0 = 7.0142e-04
Loss = 1.1085e-03, PNorm = 59.1892, GNorm = 1.4922, lr_0 = 6.9831e-04
Validation rmse logD = 0.614769
Validation R2 logD = 0.744640
Validation rmse logP = 0.628632
Validation R2 logP = 0.756371
Epoch 17
Train function
Loss = 1.1769e-03, PNorm = 59.2303, GNorm = 0.6913, lr_0 = 6.9523e-04
Loss = 1.0899e-03, PNorm = 59.2682, GNorm = 0.6503, lr_0 = 6.9215e-04
Loss = 1.0574e-03, PNorm = 59.3113, GNorm = 0.3423, lr_0 = 6.8909e-04
Loss = 1.0164e-03, PNorm = 59.3572, GNorm = 0.6914, lr_0 = 6.8604e-04
Loss = 1.2010e-03, PNorm = 59.3918, GNorm = 0.5617, lr_0 = 6.8301e-04
Validation rmse logD = 0.615470
Validation R2 logD = 0.744057
Validation rmse logP = 0.617412
Validation R2 logP = 0.764990
Epoch 18
Train function
Loss = 1.0161e-03, PNorm = 59.4354, GNorm = 0.9808, lr_0 = 6.7968e-04
Loss = 1.4303e-03, PNorm = 59.4753, GNorm = 2.4029, lr_0 = 6.7668e-04
Loss = 1.2201e-03, PNorm = 59.5241, GNorm = 0.4152, lr_0 = 6.7368e-04
Loss = 1.5823e-03, PNorm = 59.5764, GNorm = 1.3803, lr_0 = 6.7070e-04
Loss = 1.1760e-03, PNorm = 59.6257, GNorm = 1.0310, lr_0 = 6.6774e-04
Validation rmse logD = 0.609173
Validation R2 logD = 0.749267
Validation rmse logP = 0.644497
Validation R2 logP = 0.743918
Epoch 19
Train function
Loss = 8.9390e-04, PNorm = 59.6715, GNorm = 0.5791, lr_0 = 6.6449e-04
Loss = 1.0176e-03, PNorm = 59.7258, GNorm = 1.1539, lr_0 = 6.6155e-04
Loss = 1.0457e-03, PNorm = 59.7613, GNorm = 0.8257, lr_0 = 6.5862e-04
Loss = 1.0748e-03, PNorm = 59.8058, GNorm = 0.5499, lr_0 = 6.5571e-04
Loss = 1.0322e-03, PNorm = 59.8416, GNorm = 0.4616, lr_0 = 6.5281e-04
Loss = 9.6140e-04, PNorm = 59.8829, GNorm = 0.5296, lr_0 = 6.4992e-04
Validation rmse logD = 0.612186
Validation R2 logD = 0.746781
Validation rmse logP = 0.622937
Validation R2 logP = 0.760764
Epoch 20
Train function
Loss = 1.2770e-03, PNorm = 59.9313, GNorm = 1.6797, lr_0 = 6.4676e-04
Loss = 1.2268e-03, PNorm = 59.9823, GNorm = 0.6860, lr_0 = 6.4390e-04
Loss = 8.5714e-04, PNorm = 60.0260, GNorm = 0.7515, lr_0 = 6.4105e-04
Loss = 8.6458e-04, PNorm = 60.0659, GNorm = 0.6782, lr_0 = 6.3822e-04
Loss = 9.5322e-04, PNorm = 60.0971, GNorm = 0.6809, lr_0 = 6.3539e-04
Validation rmse logD = 0.605330
Validation R2 logD = 0.752420
Validation rmse logP = 0.645973
Validation R2 logP = 0.742744
Epoch 21
Train function
Loss = 6.8530e-04, PNorm = 60.1496, GNorm = 0.4319, lr_0 = 6.3230e-04
Loss = 7.1405e-04, PNorm = 60.1818, GNorm = 0.6458, lr_0 = 6.2950e-04
Loss = 9.1037e-04, PNorm = 60.2075, GNorm = 1.0892, lr_0 = 6.2672e-04
Loss = 8.4670e-04, PNorm = 60.2456, GNorm = 0.6951, lr_0 = 6.2395e-04
Loss = 1.0060e-03, PNorm = 60.2803, GNorm = 0.5025, lr_0 = 6.2119e-04
Validation rmse logD = 0.600982
Validation R2 logD = 0.755965
Validation rmse logP = 0.627964
Validation R2 logP = 0.756888
Epoch 22
Train function
Loss = 4.9193e-04, PNorm = 60.3117, GNorm = 0.4881, lr_0 = 6.1817e-04
Loss = 7.1493e-04, PNorm = 60.3495, GNorm = 0.5100, lr_0 = 6.1543e-04
Loss = 6.7500e-04, PNorm = 60.3731, GNorm = 0.7628, lr_0 = 6.1271e-04
Loss = 9.1616e-04, PNorm = 60.4084, GNorm = 1.3705, lr_0 = 6.1000e-04
Loss = 5.9589e-04, PNorm = 60.4415, GNorm = 0.4536, lr_0 = 6.0730e-04
Loss = 7.4834e-04, PNorm = 60.4741, GNorm = 1.1012, lr_0 = 6.0461e-04
Validation rmse logD = 0.601155
Validation R2 logD = 0.755824
Validation rmse logP = 0.613979
Validation R2 logP = 0.767596
Epoch 23
Train function
Loss = 5.3429e-04, PNorm = 60.5044, GNorm = 0.8064, lr_0 = 6.0167e-04
Loss = 5.6351e-04, PNorm = 60.5282, GNorm = 0.3945, lr_0 = 5.9901e-04
Loss = 5.2404e-04, PNorm = 60.5551, GNorm = 0.4614, lr_0 = 5.9636e-04
Loss = 5.5468e-04, PNorm = 60.5880, GNorm = 1.0503, lr_0 = 5.9372e-04
Loss = 5.8740e-04, PNorm = 60.6135, GNorm = 0.5234, lr_0 = 5.9110e-04
Validation rmse logD = 0.607773
Validation R2 logD = 0.750418
Validation rmse logP = 0.624546
Validation R2 logP = 0.759527
Epoch 24
Train function
Loss = 5.6196e-04, PNorm = 60.6405, GNorm = 0.4931, lr_0 = 5.8822e-04
Loss = 7.0433e-04, PNorm = 60.6713, GNorm = 0.6993, lr_0 = 5.8562e-04
Loss = 5.0746e-04, PNorm = 60.7038, GNorm = 0.5246, lr_0 = 5.8303e-04
Loss = 5.8579e-04, PNorm = 60.7217, GNorm = 0.9547, lr_0 = 5.8045e-04
Loss = 6.5241e-04, PNorm = 60.7455, GNorm = 0.6118, lr_0 = 5.7788e-04
Validation rmse logD = 0.612022
Validation R2 logD = 0.746916
Validation rmse logP = 0.588085
Validation R2 logP = 0.786785
Epoch 25
Train function
Loss = 1.0215e-03, PNorm = 60.7739, GNorm = 0.5648, lr_0 = 5.7533e-04
Loss = 5.1815e-04, PNorm = 60.8070, GNorm = 1.0208, lr_0 = 5.7278e-04
Loss = 5.2441e-04, PNorm = 60.8251, GNorm = 0.6202, lr_0 = 5.7025e-04
Loss = 6.2099e-04, PNorm = 60.8550, GNorm = 1.3254, lr_0 = 5.6773e-04
Loss = 7.0312e-04, PNorm = 60.8840, GNorm = 1.6543, lr_0 = 5.6522e-04
Loss = 7.5533e-04, PNorm = 60.9116, GNorm = 1.9493, lr_0 = 5.6272e-04
Validation rmse logD = 0.596018
Validation R2 logD = 0.759979
Validation rmse logP = 0.619823
Validation R2 logP = 0.763150
Epoch 26
Train function
Loss = 5.6551e-04, PNorm = 60.9470, GNorm = 1.0582, lr_0 = 5.5998e-04
Loss = 5.3016e-04, PNorm = 60.9759, GNorm = 0.5318, lr_0 = 5.5750e-04
Loss = 6.3846e-04, PNorm = 60.9988, GNorm = 0.5579, lr_0 = 5.5503e-04
Loss = 5.5015e-04, PNorm = 61.0230, GNorm = 0.4995, lr_0 = 5.5258e-04
Loss = 5.1610e-04, PNorm = 61.0453, GNorm = 1.0240, lr_0 = 5.5014e-04
Validation rmse logD = 0.598286
Validation R2 logD = 0.758149
Validation rmse logP = 0.610480
Validation R2 logP = 0.770237
Epoch 27
Train function
Loss = 5.9630e-04, PNorm = 61.0760, GNorm = 1.8207, lr_0 = 5.4746e-04
Loss = 5.9041e-04, PNorm = 61.1102, GNorm = 1.5575, lr_0 = 5.4504e-04
Loss = 7.2181e-04, PNorm = 61.1424, GNorm = 1.1613, lr_0 = 5.4263e-04
Loss = 5.7453e-04, PNorm = 61.1653, GNorm = 1.5093, lr_0 = 5.4023e-04
Loss = 4.7022e-04, PNorm = 61.1829, GNorm = 0.5761, lr_0 = 5.3784e-04
Validation rmse logD = 0.600284
Validation R2 logD = 0.756531
Validation rmse logP = 0.615721
Validation R2 logP = 0.766275
Epoch 28
Train function
Loss = 3.8540e-04, PNorm = 61.2131, GNorm = 0.3395, lr_0 = 5.3522e-04
Loss = 4.2907e-04, PNorm = 61.2367, GNorm = 0.8575, lr_0 = 5.3285e-04
Loss = 4.4325e-04, PNorm = 61.2541, GNorm = 0.3556, lr_0 = 5.3050e-04
Loss = 5.5651e-04, PNorm = 61.2758, GNorm = 0.6266, lr_0 = 5.2815e-04
Loss = 5.6141e-04, PNorm = 61.2994, GNorm = 0.7070, lr_0 = 5.2581e-04
Loss = 6.0983e-04, PNorm = 61.3225, GNorm = 1.0608, lr_0 = 5.2349e-04
Loss = 8.0278e-03, PNorm = 61.3269, GNorm = 2.2139, lr_0 = 5.2326e-04
Validation rmse logD = 0.594082
Validation R2 logD = 0.761536
Validation rmse logP = 0.592241
Validation R2 logP = 0.783761
Epoch 29
Train function
Loss = 6.6971e-04, PNorm = 61.3581, GNorm = 0.5454, lr_0 = 5.2094e-04
Loss = 5.1083e-04, PNorm = 61.3869, GNorm = 0.4086, lr_0 = 5.1864e-04
Loss = 3.8267e-04, PNorm = 61.4109, GNorm = 0.6014, lr_0 = 5.1634e-04
Loss = 3.6525e-04, PNorm = 61.4307, GNorm = 0.2668, lr_0 = 5.1406e-04
Loss = 4.2160e-04, PNorm = 61.4483, GNorm = 0.3910, lr_0 = 5.1178e-04
Validation rmse logD = 0.600587
Validation R2 logD = 0.756285
Validation rmse logP = 0.598771
Validation R2 logP = 0.778966
Epoch 30
Train function
Loss = 3.6760e-04, PNorm = 61.4639, GNorm = 0.3224, lr_0 = 5.0930e-04
Loss = 4.9835e-04, PNorm = 61.4835, GNorm = 0.3422, lr_0 = 5.0704e-04
Loss = 4.4007e-04, PNorm = 61.5065, GNorm = 0.6063, lr_0 = 5.0480e-04
Loss = 4.2618e-04, PNorm = 61.5292, GNorm = 0.3477, lr_0 = 5.0257e-04
Loss = 3.9994e-04, PNorm = 61.5475, GNorm = 0.7364, lr_0 = 5.0034e-04
Validation rmse logD = 0.599581
Validation R2 logD = 0.757101
Validation rmse logP = 0.630183
Validation R2 logP = 0.755166
Epoch 31
Train function
Loss = 4.4920e-04, PNorm = 61.5637, GNorm = 0.7454, lr_0 = 4.9791e-04
Loss = 3.5268e-04, PNorm = 61.5828, GNorm = 0.6711, lr_0 = 4.9571e-04
Loss = 2.9778e-04, PNorm = 61.5997, GNorm = 0.8209, lr_0 = 4.9351e-04
Loss = 3.9337e-04, PNorm = 61.6137, GNorm = 0.8514, lr_0 = 4.9133e-04
Loss = 4.1876e-04, PNorm = 61.6300, GNorm = 0.5828, lr_0 = 4.8916e-04
Validation rmse logD = 0.596570
Validation R2 logD = 0.759535
Validation rmse logP = 0.597998
Validation R2 logP = 0.779536
Epoch 32
Train function
Loss = 3.1263e-04, PNorm = 61.6471, GNorm = 0.3111, lr_0 = 4.8678e-04
Loss = 3.2312e-04, PNorm = 61.6641, GNorm = 0.2218, lr_0 = 4.8463e-04
Loss = 2.5923e-04, PNorm = 61.6723, GNorm = 0.5755, lr_0 = 4.8248e-04
Loss = 3.3488e-04, PNorm = 61.6863, GNorm = 0.5300, lr_0 = 4.8035e-04
Loss = 3.3124e-04, PNorm = 61.7027, GNorm = 0.5546, lr_0 = 4.7822e-04
Loss = 3.0482e-04, PNorm = 61.7237, GNorm = 0.2623, lr_0 = 4.7611e-04
Validation rmse logD = 0.592889
Validation R2 logD = 0.762492
Validation rmse logP = 0.603520
Validation R2 logP = 0.775446
Epoch 33
Train function
Loss = 3.1138e-04, PNorm = 61.7377, GNorm = 0.4192, lr_0 = 4.7379e-04
Loss = 3.1674e-04, PNorm = 61.7521, GNorm = 0.5128, lr_0 = 4.7170e-04
Loss = 2.9885e-04, PNorm = 61.7655, GNorm = 0.4382, lr_0 = 4.6961e-04
Loss = 2.2364e-04, PNorm = 61.7772, GNorm = 0.2780, lr_0 = 4.6753e-04
Loss = 2.2081e-04, PNorm = 61.7856, GNorm = 0.3938, lr_0 = 4.6546e-04
Validation rmse logD = 0.591990
Validation R2 logD = 0.763212
Validation rmse logP = 0.601364
Validation R2 logP = 0.777048
Epoch 34
Train function
Loss = 1.7917e-04, PNorm = 61.7996, GNorm = 0.6939, lr_0 = 4.6341e-04
Loss = 2.3615e-04, PNorm = 61.8122, GNorm = 0.6433, lr_0 = 4.6136e-04
Loss = 2.2612e-04, PNorm = 61.8270, GNorm = 0.3833, lr_0 = 4.5931e-04
Loss = 2.0438e-04, PNorm = 61.8393, GNorm = 0.2750, lr_0 = 4.5728e-04
Loss = 2.3516e-04, PNorm = 61.8498, GNorm = 0.3672, lr_0 = 4.5526e-04
Validation rmse logD = 0.594628
Validation R2 logD = 0.761097
Validation rmse logP = 0.584213
Validation R2 logP = 0.789584
Epoch 35
Train function
Loss = 1.5740e-04, PNorm = 61.8615, GNorm = 0.2787, lr_0 = 4.5305e-04
Loss = 2.6307e-04, PNorm = 61.8783, GNorm = 0.5771, lr_0 = 4.5104e-04
Loss = 2.1043e-04, PNorm = 61.8902, GNorm = 0.5978, lr_0 = 4.4905e-04
Loss = 1.7736e-04, PNorm = 61.9008, GNorm = 0.4255, lr_0 = 4.4706e-04
Loss = 2.2001e-04, PNorm = 61.9100, GNorm = 0.5375, lr_0 = 4.4508e-04
Loss = 2.0405e-04, PNorm = 61.9196, GNorm = 0.3412, lr_0 = 4.4311e-04
Validation rmse logD = 0.600280
Validation R2 logD = 0.756534
Validation rmse logP = 0.590895
Validation R2 logP = 0.784743
Epoch 36
Train function
Loss = 2.2943e-04, PNorm = 61.9312, GNorm = 0.6473, lr_0 = 4.4096e-04
Loss = 1.8553e-04, PNorm = 61.9431, GNorm = 0.2271, lr_0 = 4.3901e-04
Loss = 1.7674e-04, PNorm = 61.9528, GNorm = 0.2346, lr_0 = 4.3707e-04
Loss = 1.6030e-04, PNorm = 61.9607, GNorm = 0.2198, lr_0 = 4.3513e-04
Loss = 2.0621e-04, PNorm = 61.9686, GNorm = 0.3400, lr_0 = 4.3321e-04
Validation rmse logD = 0.593921
Validation R2 logD = 0.761665
Validation rmse logP = 0.612291
Validation R2 logP = 0.768872
Epoch 37
Train function
Loss = 1.5071e-04, PNorm = 61.9798, GNorm = 0.4082, lr_0 = 4.3110e-04
Loss = 2.3999e-04, PNorm = 61.9908, GNorm = 0.3970, lr_0 = 4.2919e-04
Loss = 2.3113e-04, PNorm = 62.0037, GNorm = 0.8021, lr_0 = 4.2729e-04
Loss = 2.5127e-04, PNorm = 62.0183, GNorm = 1.1498, lr_0 = 4.2540e-04
Loss = 2.5481e-04, PNorm = 62.0361, GNorm = 0.2378, lr_0 = 4.2352e-04
Validation rmse logD = 0.602485
Validation R2 logD = 0.754742
Validation rmse logP = 0.589593
Validation R2 logP = 0.785690
Epoch 38
Train function
Loss = 4.0775e-04, PNorm = 62.0483, GNorm = 1.1393, lr_0 = 4.2146e-04
Loss = 2.6425e-04, PNorm = 62.0691, GNorm = 0.3286, lr_0 = 4.1960e-04
Loss = 2.1046e-04, PNorm = 62.0816, GNorm = 0.2034, lr_0 = 4.1774e-04
Loss = 2.0705e-04, PNorm = 62.0936, GNorm = 0.3304, lr_0 = 4.1589e-04
Loss = 1.9196e-04, PNorm = 62.1043, GNorm = 0.5245, lr_0 = 4.1406e-04
Loss = 2.5012e-04, PNorm = 62.1198, GNorm = 0.4217, lr_0 = 4.1222e-04
Validation rmse logD = 0.595320
Validation R2 logD = 0.760541
Validation rmse logP = 0.607669
Validation R2 logP = 0.772348
Epoch 39
Train function
Loss = 1.9805e-04, PNorm = 62.1352, GNorm = 0.4369, lr_0 = 4.1022e-04
Loss = 2.8755e-04, PNorm = 62.1450, GNorm = 0.6304, lr_0 = 4.0840e-04
Loss = 1.9287e-04, PNorm = 62.1591, GNorm = 0.2857, lr_0 = 4.0660e-04
Loss = 1.5845e-04, PNorm = 62.1714, GNorm = 0.2618, lr_0 = 4.0480e-04
Loss = 1.7183e-04, PNorm = 62.1796, GNorm = 0.2512, lr_0 = 4.0301e-04
Validation rmse logD = 0.596427
Validation R2 logD = 0.759649
Validation rmse logP = 0.602366
Validation R2 logP = 0.776304
Epoch 40
Train function
Loss = 2.3973e-04, PNorm = 62.1856, GNorm = 0.8498, lr_0 = 4.0105e-04
Loss = 1.7260e-04, PNorm = 62.2001, GNorm = 0.2323, lr_0 = 3.9927e-04
Loss = 1.6466e-04, PNorm = 62.2113, GNorm = 0.1969, lr_0 = 3.9751e-04
Loss = 1.8359e-04, PNorm = 62.2216, GNorm = 0.8388, lr_0 = 3.9575e-04
Loss = 1.6109e-04, PNorm = 62.2289, GNorm = 0.4257, lr_0 = 3.9400e-04
Validation rmse logD = 0.602157
Validation R2 logD = 0.755009
Validation rmse logP = 0.607192
Validation R2 logP = 0.772706
Epoch 41
Train function
Loss = 1.5313e-04, PNorm = 62.2372, GNorm = 0.4636, lr_0 = 3.9208e-04
Loss = 3.4850e-04, PNorm = 62.2495, GNorm = 0.4532, lr_0 = 3.9035e-04
Loss = 3.4741e-04, PNorm = 62.2616, GNorm = 0.8751, lr_0 = 3.8862e-04
Loss = 2.0117e-04, PNorm = 62.2777, GNorm = 0.3394, lr_0 = 3.8690e-04
Loss = 1.6030e-04, PNorm = 62.2904, GNorm = 0.3334, lr_0 = 3.8519e-04
Loss = 1.4146e-04, PNorm = 62.3013, GNorm = 0.4006, lr_0 = 3.8349e-04
Validation rmse logD = 0.593612
Validation R2 logD = 0.761913
Validation rmse logP = 0.599582
Validation R2 logP = 0.778367
Epoch 42
Train function
Loss = 1.5279e-04, PNorm = 62.3092, GNorm = 0.3748, lr_0 = 3.8179e-04
Loss = 1.2439e-04, PNorm = 62.3154, GNorm = 0.3912, lr_0 = 3.8010e-04
Loss = 1.6962e-04, PNorm = 62.3248, GNorm = 0.9027, lr_0 = 3.7842e-04
Loss = 1.6395e-04, PNorm = 62.3314, GNorm = 0.6622, lr_0 = 3.7675e-04
Loss = 1.6988e-04, PNorm = 62.3393, GNorm = 0.2589, lr_0 = 3.7508e-04
Validation rmse logD = 0.595315
Validation R2 logD = 0.760545
Validation rmse logP = 0.612320
Validation R2 logP = 0.768850
Epoch 43
Train function
Loss = 1.7514e-04, PNorm = 62.3505, GNorm = 0.5623, lr_0 = 3.7326e-04
Loss = 2.1450e-04, PNorm = 62.3626, GNorm = 0.5147, lr_0 = 3.7160e-04
Loss = 1.4456e-04, PNorm = 62.3742, GNorm = 0.3667, lr_0 = 3.6996e-04
Loss = 1.6483e-04, PNorm = 62.3840, GNorm = 0.3780, lr_0 = 3.6832e-04
Loss = 1.5481e-04, PNorm = 62.3919, GNorm = 0.2931, lr_0 = 3.6669e-04
Validation rmse logD = 0.595740
Validation R2 logD = 0.760203
Validation rmse logP = 0.591801
Validation R2 logP = 0.784082
Epoch 44
Train function
Loss = 1.1303e-04, PNorm = 62.4001, GNorm = 0.1987, lr_0 = 3.6491e-04
Loss = 1.6840e-04, PNorm = 62.4065, GNorm = 0.3851, lr_0 = 3.6330e-04
Loss = 1.4817e-04, PNorm = 62.4142, GNorm = 0.3479, lr_0 = 3.6169e-04
Loss = 1.6589e-04, PNorm = 62.4238, GNorm = 1.0928, lr_0 = 3.6009e-04
Loss = 1.4259e-04, PNorm = 62.4347, GNorm = 0.6437, lr_0 = 3.5850e-04
Loss = 1.7338e-04, PNorm = 62.4444, GNorm = 0.8475, lr_0 = 3.5691e-04
Loss = 1.0822e-03, PNorm = 62.4456, GNorm = 0.8387, lr_0 = 3.5675e-04
Validation rmse logD = 0.597240
Validation R2 logD = 0.758994
Validation rmse logP = 0.609756
Validation R2 logP = 0.770781
Epoch 45
Train function
Loss = 1.3020e-04, PNorm = 62.4559, GNorm = 0.1312, lr_0 = 3.5518e-04
Loss = 1.1620e-04, PNorm = 62.4620, GNorm = 0.2132, lr_0 = 3.5360e-04
Loss = 1.0096e-04, PNorm = 62.4694, GNorm = 0.3328, lr_0 = 3.5204e-04
Loss = 8.0308e-05, PNorm = 62.4757, GNorm = 0.1786, lr_0 = 3.5048e-04
Loss = 1.2319e-04, PNorm = 62.4818, GNorm = 0.2175, lr_0 = 3.4893e-04
Validation rmse logD = 0.594220
Validation R2 logD = 0.761425
Validation rmse logP = 0.595566
Validation R2 logP = 0.781326
Epoch 46
Train function
Loss = 8.7557e-05, PNorm = 62.4885, GNorm = 0.3490, lr_0 = 3.4724e-04
Loss = 8.4562e-05, PNorm = 62.4925, GNorm = 0.2131, lr_0 = 3.4570e-04
Loss = 8.9269e-05, PNorm = 62.5002, GNorm = 0.1917, lr_0 = 3.4417e-04
Loss = 1.0136e-04, PNorm = 62.5083, GNorm = 0.3881, lr_0 = 3.4265e-04
Loss = 8.9213e-05, PNorm = 62.5147, GNorm = 0.3220, lr_0 = 3.4113e-04
Validation rmse logD = 0.599308
Validation R2 logD = 0.757322
Validation rmse logP = 0.617613
Validation R2 logP = 0.764836
Epoch 47
Train function
Loss = 1.2254e-04, PNorm = 62.5198, GNorm = 0.6022, lr_0 = 3.3947e-04
Loss = 9.0243e-05, PNorm = 62.5260, GNorm = 0.2449, lr_0 = 3.3797e-04
Loss = 7.1275e-05, PNorm = 62.5325, GNorm = 0.1494, lr_0 = 3.3648e-04
Loss = 7.5768e-05, PNorm = 62.5372, GNorm = 0.3330, lr_0 = 3.3499e-04
Loss = 8.1310e-05, PNorm = 62.5412, GNorm = 0.2201, lr_0 = 3.3351e-04
Validation rmse logD = 0.596476
Validation R2 logD = 0.759610
Validation rmse logP = 0.602539
Validation R2 logP = 0.776176
Epoch 48
Train function
Loss = 4.4475e-05, PNorm = 62.5458, GNorm = 0.2967, lr_0 = 3.3188e-04
Loss = 8.2743e-05, PNorm = 62.5483, GNorm = 0.4775, lr_0 = 3.3042e-04
Loss = 7.6685e-05, PNorm = 62.5524, GNorm = 0.2032, lr_0 = 3.2895e-04
Loss = 8.0814e-05, PNorm = 62.5578, GNorm = 0.3342, lr_0 = 3.2750e-04
Loss = 7.4145e-05, PNorm = 62.5634, GNorm = 0.2179, lr_0 = 3.2605e-04
Loss = 6.4651e-05, PNorm = 62.5692, GNorm = 0.5338, lr_0 = 3.2461e-04
Validation rmse logD = 0.598215
Validation R2 logD = 0.758206
Validation rmse logP = 0.602686
Validation R2 logP = 0.776067
Epoch 49
Train function
Loss = 9.9675e-05, PNorm = 62.5747, GNorm = 0.4492, lr_0 = 3.2303e-04
Loss = 1.1737e-04, PNorm = 62.5804, GNorm = 0.4154, lr_0 = 3.2160e-04
Loss = 9.9063e-05, PNorm = 62.5881, GNorm = 0.2506, lr_0 = 3.2018e-04
Loss = 6.3683e-05, PNorm = 62.5960, GNorm = 0.4062, lr_0 = 3.1876e-04
Loss = 6.7165e-05, PNorm = 62.6002, GNorm = 0.1491, lr_0 = 3.1735e-04
Validation rmse logD = 0.597077
Validation R2 logD = 0.759125
Validation rmse logP = 0.612026
Validation R2 logP = 0.769072
Epoch 50
Train function
Loss = 8.4432e-05, PNorm = 62.6053, GNorm = 0.2044, lr_0 = 3.1595e-04
Loss = 7.5856e-05, PNorm = 62.6094, GNorm = 0.3590, lr_0 = 3.1455e-04
Loss = 6.3687e-05, PNorm = 62.6145, GNorm = 0.1782, lr_0 = 3.1316e-04
Loss = 7.1309e-05, PNorm = 62.6213, GNorm = 0.1630, lr_0 = 3.1177e-04
Loss = 5.6600e-05, PNorm = 62.6242, GNorm = 0.1709, lr_0 = 3.1039e-04
Validation rmse logD = 0.596405
Validation R2 logD = 0.759667
Validation rmse logP = 0.602602
Validation R2 logP = 0.776128
Epoch 51
Train function
Loss = 6.0680e-05, PNorm = 62.6295, GNorm = 0.3946, lr_0 = 3.0888e-04
Loss = 6.4041e-05, PNorm = 62.6327, GNorm = 0.1543, lr_0 = 3.0752e-04
Loss = 6.7387e-05, PNorm = 62.6349, GNorm = 0.1469, lr_0 = 3.0616e-04
Loss = 7.0078e-05, PNorm = 62.6394, GNorm = 0.1298, lr_0 = 3.0480e-04
Loss = 6.5609e-05, PNorm = 62.6451, GNorm = 0.2979, lr_0 = 3.0346e-04
Loss = 7.6720e-05, PNorm = 62.6506, GNorm = 0.5968, lr_0 = 3.0211e-04
Validation rmse logD = 0.594531
Validation R2 logD = 0.761175
Validation rmse logP = 0.605173
Validation R2 logP = 0.774214
Epoch 52
Train function
Loss = 7.3763e-05, PNorm = 62.6575, GNorm = 0.3591, lr_0 = 3.0064e-04
Loss = 1.0682e-04, PNorm = 62.6634, GNorm = 0.7007, lr_0 = 2.9931e-04
Loss = 7.4741e-05, PNorm = 62.6691, GNorm = 0.4651, lr_0 = 2.9799e-04
Loss = 7.5945e-05, PNorm = 62.6752, GNorm = 0.1645, lr_0 = 2.9667e-04
Loss = 7.7511e-05, PNorm = 62.6794, GNorm = 0.3000, lr_0 = 2.9536e-04
Validation rmse logD = 0.594817
Validation R2 logD = 0.760946
Validation rmse logP = 0.599423
Validation R2 logP = 0.778485
Epoch 53
Train function
Loss = 8.3723e-05, PNorm = 62.6827, GNorm = 0.3367, lr_0 = 2.9392e-04
Loss = 7.8499e-05, PNorm = 62.6894, GNorm = 0.2385, lr_0 = 2.9262e-04
Loss = 8.4007e-05, PNorm = 62.6956, GNorm = 0.1388, lr_0 = 2.9133e-04
Loss = 5.7498e-05, PNorm = 62.7002, GNorm = 0.1316, lr_0 = 2.9004e-04
Loss = 5.9391e-05, PNorm = 62.7037, GNorm = 0.1310, lr_0 = 2.8876e-04
Validation rmse logD = 0.595150
Validation R2 logD = 0.760678
Validation rmse logP = 0.609270
Validation R2 logP = 0.771147
Epoch 54
Train function
Loss = 4.4568e-05, PNorm = 62.7061, GNorm = 0.1029, lr_0 = 2.8735e-04
Loss = 5.0484e-05, PNorm = 62.7084, GNorm = 0.2634, lr_0 = 2.8608e-04
Loss = 6.2721e-05, PNorm = 62.7109, GNorm = 0.5057, lr_0 = 2.8482e-04
Loss = 7.6758e-05, PNorm = 62.7146, GNorm = 0.3106, lr_0 = 2.8356e-04
Loss = 5.5515e-05, PNorm = 62.7193, GNorm = 0.4554, lr_0 = 2.8230e-04
Loss = 5.0629e-05, PNorm = 62.7218, GNorm = 0.1820, lr_0 = 2.8105e-04
Validation rmse logD = 0.596155
Validation R2 logD = 0.759869
Validation rmse logP = 0.597946
Validation R2 logP = 0.779575
Epoch 55
Train function
Loss = 4.2249e-05, PNorm = 62.7243, GNorm = 0.1875, lr_0 = 2.7969e-04
Loss = 5.5401e-05, PNorm = 62.7289, GNorm = 0.0819, lr_0 = 2.7845e-04
Loss = 3.9316e-05, PNorm = 62.7335, GNorm = 0.1182, lr_0 = 2.7722e-04
Loss = 3.7129e-05, PNorm = 62.7367, GNorm = 0.1811, lr_0 = 2.7599e-04
Loss = 5.4410e-05, PNorm = 62.7419, GNorm = 0.1426, lr_0 = 2.7477e-04
Validation rmse logD = 0.595336
Validation R2 logD = 0.760528
Validation rmse logP = 0.602413
Validation R2 logP = 0.776269
Epoch 56
Train function
Loss = 4.5379e-05, PNorm = 62.7452, GNorm = 0.1126, lr_0 = 2.7343e-04
Loss = 3.4034e-05, PNorm = 62.7493, GNorm = 0.1120, lr_0 = 2.7222e-04
Loss = 3.9238e-05, PNorm = 62.7525, GNorm = 0.2371, lr_0 = 2.7102e-04
Loss = 4.0777e-05, PNorm = 62.7538, GNorm = 0.2639, lr_0 = 2.6982e-04
Loss = 5.1919e-05, PNorm = 62.7579, GNorm = 0.1414, lr_0 = 2.6863e-04
Validation rmse logD = 0.595000
Validation R2 logD = 0.760799
Validation rmse logP = 0.603876
Validation R2 logP = 0.775181
Epoch 57
Train function
Loss = 2.6970e-05, PNorm = 62.7633, GNorm = 0.2905, lr_0 = 2.6732e-04
Loss = 4.6952e-05, PNorm = 62.7668, GNorm = 0.1160, lr_0 = 2.6614e-04
Loss = 4.5065e-05, PNorm = 62.7708, GNorm = 0.1995, lr_0 = 2.6496e-04
Loss = 4.6241e-05, PNorm = 62.7726, GNorm = 0.4787, lr_0 = 2.6379e-04
Loss = 5.1792e-05, PNorm = 62.7764, GNorm = 0.4580, lr_0 = 2.6262e-04
Loss = 7.0789e-05, PNorm = 62.7811, GNorm = 0.1134, lr_0 = 2.6146e-04
Loss = 2.4518e-04, PNorm = 62.7814, GNorm = 0.3952, lr_0 = 2.6134e-04
Validation rmse logD = 0.595397
Validation R2 logD = 0.760479
Validation rmse logP = 0.600727
Validation R2 logP = 0.777519
Epoch 58
Train function
Loss = 5.2258e-05, PNorm = 62.7859, GNorm = 0.2624, lr_0 = 2.6019e-04
Loss = 5.1303e-05, PNorm = 62.7888, GNorm = 0.5924, lr_0 = 2.5904e-04
Loss = 5.3979e-05, PNorm = 62.7941, GNorm = 0.2214, lr_0 = 2.5789e-04
Loss = 4.4241e-05, PNorm = 62.7991, GNorm = 0.3107, lr_0 = 2.5675e-04
Loss = 7.6422e-05, PNorm = 62.8029, GNorm = 0.2976, lr_0 = 2.5561e-04
Validation rmse logD = 0.596037
Validation R2 logD = 0.759964
Validation rmse logP = 0.604216
Validation R2 logP = 0.774927
Epoch 59
Train function
Loss = 5.5425e-05, PNorm = 62.8071, GNorm = 0.1122, lr_0 = 2.5448e-04
Loss = 5.7339e-05, PNorm = 62.8103, GNorm = 0.4140, lr_0 = 2.5336e-04
Loss = 4.1087e-05, PNorm = 62.8145, GNorm = 0.1102, lr_0 = 2.5224e-04
Loss = 3.9631e-05, PNorm = 62.8165, GNorm = 0.1320, lr_0 = 2.5112e-04
Loss = 4.2267e-05, PNorm = 62.8190, GNorm = 0.1854, lr_0 = 2.5001e-04
Validation rmse logD = 0.596425
Validation R2 logD = 0.759651
Validation rmse logP = 0.612811
Validation R2 logP = 0.768479
Epoch 60
Train function
Loss = 4.3926e-05, PNorm = 62.8205, GNorm = 0.1609, lr_0 = 2.4879e-04
Loss = 4.7115e-05, PNorm = 62.8230, GNorm = 0.1118, lr_0 = 2.4769e-04
Loss = 4.3576e-05, PNorm = 62.8268, GNorm = 0.2165, lr_0 = 2.4660e-04
Loss = 5.5128e-05, PNorm = 62.8318, GNorm = 0.2842, lr_0 = 2.4551e-04
Loss = 3.7891e-05, PNorm = 62.8356, GNorm = 0.1058, lr_0 = 2.4442e-04
Loss = 3.8505e-05, PNorm = 62.8400, GNorm = 0.1944, lr_0 = 2.4334e-04
Loss = 8.8093e-04, PNorm = 62.8402, GNorm = 0.5355, lr_0 = 2.4323e-04
Validation rmse logD = 0.596580
Validation R2 logD = 0.759526
Validation rmse logP = 0.604924
Validation R2 logP = 0.774400
Epoch 61
Train function
Loss = 4.6866e-05, PNorm = 62.8418, GNorm = 0.4245, lr_0 = 2.4216e-04
Loss = 7.8923e-05, PNorm = 62.8461, GNorm = 0.2671, lr_0 = 2.4109e-04
Loss = 5.3878e-05, PNorm = 62.8527, GNorm = 0.1771, lr_0 = 2.4002e-04
Loss = 4.2031e-05, PNorm = 62.8549, GNorm = 0.1425, lr_0 = 2.3896e-04
Loss = 4.2004e-05, PNorm = 62.8586, GNorm = 0.1669, lr_0 = 2.3790e-04
Validation rmse logD = 0.597692
Validation R2 logD = 0.758629
Validation rmse logP = 0.608273
Validation R2 logP = 0.771895
Epoch 62
Train function
Loss = 4.6343e-05, PNorm = 62.8639, GNorm = 0.1483, lr_0 = 2.3674e-04
Loss = 4.5032e-05, PNorm = 62.8660, GNorm = 0.1448, lr_0 = 2.3570e-04
Loss = 4.9228e-05, PNorm = 62.8702, GNorm = 0.1100, lr_0 = 2.3465e-04
Loss = 3.9219e-05, PNorm = 62.8737, GNorm = 0.2074, lr_0 = 2.3362e-04
Loss = 5.0056e-05, PNorm = 62.8764, GNorm = 0.1783, lr_0 = 2.3258e-04
Validation rmse logD = 0.595660
Validation R2 logD = 0.760268
Validation rmse logP = 0.604746
Validation R2 logP = 0.774533
Epoch 63
Train function
Loss = 2.8208e-05, PNorm = 62.8788, GNorm = 0.1233, lr_0 = 2.3145e-04
Loss = 3.6037e-05, PNorm = 62.8804, GNorm = 0.1733, lr_0 = 2.3043e-04
Loss = 3.7146e-05, PNorm = 62.8836, GNorm = 0.1798, lr_0 = 2.2941e-04
Loss = 3.1682e-05, PNorm = 62.8864, GNorm = 0.1209, lr_0 = 2.2839e-04
Loss = 2.7648e-05, PNorm = 62.8892, GNorm = 0.2798, lr_0 = 2.2738e-04
Validation rmse logD = 0.594672
Validation R2 logD = 0.761062
Validation rmse logP = 0.603063
Validation R2 logP = 0.775786
Epoch 64
Train function
Loss = 1.6242e-05, PNorm = 62.8929, GNorm = 0.1333, lr_0 = 2.2628e-04
Loss = 2.9076e-05, PNorm = 62.8949, GNorm = 0.2097, lr_0 = 2.2528e-04
Loss = 3.7189e-05, PNorm = 62.8975, GNorm = 0.2740, lr_0 = 2.2428e-04
Loss = 3.7277e-05, PNorm = 62.8998, GNorm = 0.3679, lr_0 = 2.2329e-04
Loss = 3.5310e-05, PNorm = 62.9030, GNorm = 0.3157, lr_0 = 2.2230e-04
Loss = 3.2937e-05, PNorm = 62.9054, GNorm = 0.1009, lr_0 = 2.2132e-04
Validation rmse logD = 0.595606
Validation R2 logD = 0.760311
Validation rmse logP = 0.608349
Validation R2 logP = 0.771839
Epoch 65
Train function
Loss = 3.0197e-05, PNorm = 62.9090, GNorm = 0.1468, lr_0 = 2.2024e-04
Loss = 2.5526e-05, PNorm = 62.9099, GNorm = 0.0670, lr_0 = 2.1927e-04
Loss = 2.6939e-05, PNorm = 62.9119, GNorm = 0.1620, lr_0 = 2.1830e-04
Loss = 2.7907e-05, PNorm = 62.9131, GNorm = 0.1990, lr_0 = 2.1733e-04
Loss = 3.0738e-05, PNorm = 62.9154, GNorm = 0.3447, lr_0 = 2.1637e-04
Validation rmse logD = 0.596071
Validation R2 logD = 0.759937
Validation rmse logP = 0.606878
Validation R2 logP = 0.772941
Epoch 66
Train function
Loss = 2.1372e-05, PNorm = 62.9175, GNorm = 0.0905, lr_0 = 2.1532e-04
Loss = 2.2021e-05, PNorm = 62.9207, GNorm = 0.1127, lr_0 = 2.1436e-04
Loss = 2.9798e-05, PNorm = 62.9207, GNorm = 0.2373, lr_0 = 2.1342e-04
Loss = 2.3514e-05, PNorm = 62.9239, GNorm = 0.1456, lr_0 = 2.1247e-04
Loss = 2.6143e-05, PNorm = 62.9264, GNorm = 0.2950, lr_0 = 2.1153e-04
Validation rmse logD = 0.595865
Validation R2 logD = 0.760102
Validation rmse logP = 0.608241
Validation R2 logP = 0.771919
Epoch 67
Train function
Loss = 2.4584e-05, PNorm = 62.9286, GNorm = 0.2260, lr_0 = 2.1060e-04
Loss = 2.0635e-05, PNorm = 62.9311, GNorm = 0.2251, lr_0 = 2.0966e-04
Loss = 3.0415e-05, PNorm = 62.9324, GNorm = 0.0663, lr_0 = 2.0874e-04
Loss = 2.2345e-05, PNorm = 62.9341, GNorm = 0.3303, lr_0 = 2.0781e-04
Loss = 2.3867e-05, PNorm = 62.9359, GNorm = 0.2044, lr_0 = 2.0689e-04
Loss = 2.8654e-05, PNorm = 62.9378, GNorm = 0.1732, lr_0 = 2.0598e-04
Validation rmse logD = 0.595289
Validation R2 logD = 0.760566
Validation rmse logP = 0.607710
Validation R2 logP = 0.772318
Epoch 68
Train function
Loss = 2.4537e-05, PNorm = 62.9410, GNorm = 0.2265, lr_0 = 2.0498e-04
Loss = 2.8043e-05, PNorm = 62.9431, GNorm = 0.2331, lr_0 = 2.0407e-04
Loss = 2.4207e-05, PNorm = 62.9439, GNorm = 0.2309, lr_0 = 2.0317e-04
Loss = 2.0102e-05, PNorm = 62.9456, GNorm = 0.1143, lr_0 = 2.0227e-04
Loss = 2.4585e-05, PNorm = 62.9472, GNorm = 0.0951, lr_0 = 2.0137e-04
Validation rmse logD = 0.596877
Validation R2 logD = 0.759287
Validation rmse logP = 0.606701
Validation R2 logP = 0.773073
Epoch 69
Train function
Loss = 1.6253e-05, PNorm = 62.9505, GNorm = 0.1475, lr_0 = 2.0039e-04
Loss = 1.8275e-05, PNorm = 62.9514, GNorm = 0.0748, lr_0 = 1.9951e-04
Loss = 1.8401e-05, PNorm = 62.9534, GNorm = 0.0768, lr_0 = 1.9863e-04
Loss = 1.4151e-05, PNorm = 62.9550, GNorm = 0.0662, lr_0 = 1.9775e-04
Loss = 1.5598e-05, PNorm = 62.9562, GNorm = 0.1724, lr_0 = 1.9687e-04
Validation rmse logD = 0.598084
Validation R2 logD = 0.758313
Validation rmse logP = 0.603855
Validation R2 logP = 0.775197
Epoch 70
Train function
Loss = 3.4957e-05, PNorm = 62.9580, GNorm = 0.5581, lr_0 = 1.9592e-04
Loss = 5.0118e-05, PNorm = 62.9606, GNorm = 0.2043, lr_0 = 1.9505e-04
Loss = 4.7257e-05, PNorm = 62.9644, GNorm = 0.2250, lr_0 = 1.9419e-04
Loss = 2.5412e-05, PNorm = 62.9685, GNorm = 0.0974, lr_0 = 1.9333e-04
Loss = 2.8528e-05, PNorm = 62.9719, GNorm = 0.1451, lr_0 = 1.9247e-04
Loss = 2.0823e-05, PNorm = 62.9733, GNorm = 0.1555, lr_0 = 1.9162e-04
Validation rmse logD = 0.598044
Validation R2 logD = 0.758345
Validation rmse logP = 0.601000
Validation R2 logP = 0.777317
Epoch 71
Train function
Loss = 2.7422e-05, PNorm = 62.9758, GNorm = 0.2353, lr_0 = 1.9069e-04
Loss = 2.9798e-05, PNorm = 62.9779, GNorm = 0.2880, lr_0 = 1.8984e-04
Loss = 2.0075e-05, PNorm = 62.9782, GNorm = 0.0921, lr_0 = 1.8900e-04
Loss = 2.4732e-05, PNorm = 62.9813, GNorm = 0.2133, lr_0 = 1.8817e-04
Loss = 2.2792e-05, PNorm = 62.9838, GNorm = 0.0431, lr_0 = 1.8734e-04
Validation rmse logD = 0.597625
Validation R2 logD = 0.758683
Validation rmse logP = 0.600392
Validation R2 logP = 0.777768
Epoch 72
Train function
Loss = 2.3420e-05, PNorm = 62.9857, GNorm = 0.2868, lr_0 = 1.8643e-04
Loss = 2.1584e-05, PNorm = 62.9864, GNorm = 0.1481, lr_0 = 1.8560e-04
Loss = 1.9039e-05, PNorm = 62.9883, GNorm = 0.1063, lr_0 = 1.8478e-04
Loss = 1.9217e-05, PNorm = 62.9900, GNorm = 0.0849, lr_0 = 1.8396e-04
Loss = 2.3359e-05, PNorm = 62.9922, GNorm = 0.1543, lr_0 = 1.8315e-04
Validation rmse logD = 0.597945
Validation R2 logD = 0.758425
Validation rmse logP = 0.606827
Validation R2 logP = 0.772979
Epoch 73
Train function
Loss = 1.8950e-05, PNorm = 62.9954, GNorm = 0.1639, lr_0 = 1.8226e-04
Loss = 1.3283e-05, PNorm = 62.9972, GNorm = 0.0806, lr_0 = 1.8145e-04
Loss = 1.5092e-05, PNorm = 62.9990, GNorm = 0.1186, lr_0 = 1.8065e-04
Loss = 1.2821e-05, PNorm = 63.0007, GNorm = 0.0673, lr_0 = 1.7985e-04
Loss = 2.1672e-05, PNorm = 63.0035, GNorm = 0.1569, lr_0 = 1.7905e-04
Loss = 2.1502e-05, PNorm = 63.0057, GNorm = 0.1333, lr_0 = 1.7826e-04
Loss = 1.2265e-04, PNorm = 63.0061, GNorm = 0.2482, lr_0 = 1.7818e-04
Validation rmse logD = 0.596551
Validation R2 logD = 0.759550
Validation rmse logP = 0.602003
Validation R2 logP = 0.776573
Epoch 74
Train function
Loss = 1.5308e-05, PNorm = 63.0069, GNorm = 0.0667, lr_0 = 1.7739e-04
Loss = 1.3485e-05, PNorm = 63.0080, GNorm = 0.1695, lr_0 = 1.7661e-04
Loss = 2.4731e-05, PNorm = 63.0096, GNorm = 0.2282, lr_0 = 1.7583e-04
Loss = 3.3759e-05, PNorm = 63.0089, GNorm = 0.1799, lr_0 = 1.7505e-04
Loss = 2.3219e-05, PNorm = 63.0119, GNorm = 0.1127, lr_0 = 1.7428e-04
Validation rmse logD = 0.596342
Validation R2 logD = 0.759718
Validation rmse logP = 0.607270
Validation R2 logP = 0.772647
Epoch 75
Train function
Loss = 1.9553e-05, PNorm = 63.0132, GNorm = 0.1693, lr_0 = 1.7351e-04
Loss = 2.5661e-05, PNorm = 63.0158, GNorm = 0.1669, lr_0 = 1.7274e-04
Loss = 2.6140e-05, PNorm = 63.0177, GNorm = 0.0856, lr_0 = 1.7197e-04
Loss = 1.8685e-05, PNorm = 63.0207, GNorm = 0.0688, lr_0 = 1.7121e-04
Loss = 1.7665e-05, PNorm = 63.0222, GNorm = 0.1427, lr_0 = 1.7046e-04
Validation rmse logD = 0.597683
Validation R2 logD = 0.758636
Validation rmse logP = 0.604897
Validation R2 logP = 0.774420
Epoch 76
Train function
Loss = 1.6903e-05, PNorm = 63.0240, GNorm = 0.1982, lr_0 = 1.6963e-04
Loss = 1.9022e-05, PNorm = 63.0242, GNorm = 0.2342, lr_0 = 1.6888e-04
Loss = 1.8509e-05, PNorm = 63.0259, GNorm = 0.0916, lr_0 = 1.6813e-04
Loss = 1.7744e-05, PNorm = 63.0266, GNorm = 0.1621, lr_0 = 1.6739e-04
Loss = 1.5386e-05, PNorm = 63.0285, GNorm = 0.0814, lr_0 = 1.6665e-04
Loss = 1.9473e-05, PNorm = 63.0301, GNorm = 0.0941, lr_0 = 1.6591e-04
Loss = 3.0104e-04, PNorm = 63.0304, GNorm = 0.4844, lr_0 = 1.6584e-04
Validation rmse logD = 0.595518
Validation R2 logD = 0.760382
Validation rmse logP = 0.608781
Validation R2 logP = 0.771514
Epoch 77
Train function
Loss = 2.6090e-05, PNorm = 63.0333, GNorm = 0.0781, lr_0 = 1.6510e-04
Loss = 2.0932e-05, PNorm = 63.0350, GNorm = 0.1788, lr_0 = 1.6437e-04
Loss = 1.9717e-05, PNorm = 63.0362, GNorm = 0.1953, lr_0 = 1.6364e-04
Loss = 1.5892e-05, PNorm = 63.0382, GNorm = 0.0621, lr_0 = 1.6292e-04
Loss = 1.7587e-05, PNorm = 63.0401, GNorm = 0.1357, lr_0 = 1.6220e-04
Validation rmse logD = 0.598681
Validation R2 logD = 0.757830
Validation rmse logP = 0.604430
Validation R2 logP = 0.774768
Epoch 78
Train function
Loss = 1.7414e-05, PNorm = 63.0425, GNorm = 0.1790, lr_0 = 1.6141e-04
Loss = 1.5965e-05, PNorm = 63.0437, GNorm = 0.1321, lr_0 = 1.6070e-04
Loss = 1.3399e-05, PNorm = 63.0440, GNorm = 0.0856, lr_0 = 1.5999e-04
Loss = 1.3817e-05, PNorm = 63.0450, GNorm = 0.0631, lr_0 = 1.5928e-04
Loss = 1.2088e-05, PNorm = 63.0461, GNorm = 0.0683, lr_0 = 1.5857e-04
Validation rmse logD = 0.597714
Validation R2 logD = 0.758611
Validation rmse logP = 0.607123
Validation R2 logP = 0.772757
Epoch 79
Train function
Loss = 8.4925e-06, PNorm = 63.0470, GNorm = 0.0521, lr_0 = 1.5780e-04
Loss = 1.3154e-05, PNorm = 63.0473, GNorm = 0.0680, lr_0 = 1.5710e-04
Loss = 1.2926e-05, PNorm = 63.0486, GNorm = 0.1447, lr_0 = 1.5641e-04
Loss = 1.2202e-05, PNorm = 63.0500, GNorm = 0.0608, lr_0 = 1.5572e-04
Loss = 1.5404e-05, PNorm = 63.0514, GNorm = 0.1187, lr_0 = 1.5503e-04
Validation rmse logD = 0.596462
Validation R2 logD = 0.759621
Validation rmse logP = 0.604722
Validation R2 logP = 0.774550
Epoch 80
Train function
Loss = 2.1104e-05, PNorm = 63.0528, GNorm = 0.1243, lr_0 = 1.5427e-04
Loss = 1.5445e-05, PNorm = 63.0547, GNorm = 0.1131, lr_0 = 1.5359e-04
Loss = 1.0018e-05, PNorm = 63.0557, GNorm = 0.1947, lr_0 = 1.5291e-04
Loss = 1.0388e-05, PNorm = 63.0568, GNorm = 0.0845, lr_0 = 1.5224e-04
Loss = 1.2356e-05, PNorm = 63.0592, GNorm = 0.2002, lr_0 = 1.5156e-04
Loss = 1.3585e-05, PNorm = 63.0607, GNorm = 0.2426, lr_0 = 1.5089e-04
Validation rmse logD = 0.597023
Validation R2 logD = 0.759169
Validation rmse logP = 0.604599
Validation R2 logP = 0.774642
Epoch 81
Train function
Loss = 1.4098e-05, PNorm = 63.0613, GNorm = 0.0734, lr_0 = 1.5016e-04
Loss = 9.5741e-06, PNorm = 63.0624, GNorm = 0.0567, lr_0 = 1.4949e-04
Loss = 1.0940e-05, PNorm = 63.0632, GNorm = 0.0683, lr_0 = 1.4883e-04
Loss = 1.1388e-05, PNorm = 63.0639, GNorm = 0.0957, lr_0 = 1.4817e-04
Loss = 1.1008e-05, PNorm = 63.0650, GNorm = 0.0816, lr_0 = 1.4752e-04
Validation rmse logD = 0.596627
Validation R2 logD = 0.759488
Validation rmse logP = 0.603066
Validation R2 logP = 0.775783
Epoch 82
Train function
Loss = 9.8642e-06, PNorm = 63.0667, GNorm = 0.0757, lr_0 = 1.4680e-04
Loss = 1.3067e-05, PNorm = 63.0676, GNorm = 0.1751, lr_0 = 1.4615e-04
Loss = 8.4262e-06, PNorm = 63.0689, GNorm = 0.1009, lr_0 = 1.4551e-04
Loss = 1.2040e-05, PNorm = 63.0706, GNorm = 0.0434, lr_0 = 1.4486e-04
Loss = 1.2394e-05, PNorm = 63.0718, GNorm = 0.2107, lr_0 = 1.4422e-04
Validation rmse logD = 0.596975
Validation R2 logD = 0.759208
Validation rmse logP = 0.606139
Validation R2 logP = 0.773493
Epoch 83
Train function
Loss = 2.0481e-05, PNorm = 63.0732, GNorm = 0.0634, lr_0 = 1.4352e-04
Loss = 8.7777e-06, PNorm = 63.0733, GNorm = 0.0959, lr_0 = 1.4288e-04
Loss = 1.1064e-05, PNorm = 63.0744, GNorm = 0.0955, lr_0 = 1.4225e-04
Loss = 7.1734e-06, PNorm = 63.0758, GNorm = 0.0520, lr_0 = 1.4162e-04
Loss = 1.1760e-05, PNorm = 63.0771, GNorm = 0.0616, lr_0 = 1.4100e-04
Loss = 8.8284e-06, PNorm = 63.0777, GNorm = 0.0931, lr_0 = 1.4037e-04
Validation rmse logD = 0.596013
Validation R2 logD = 0.759983
Validation rmse logP = 0.603015
Validation R2 logP = 0.775822
Epoch 84
Train function
Loss = 9.9065e-06, PNorm = 63.0784, GNorm = 0.0844, lr_0 = 1.3975e-04
Loss = 1.1008e-05, PNorm = 63.0791, GNorm = 0.1538, lr_0 = 1.3913e-04
Loss = 9.9027e-06, PNorm = 63.0800, GNorm = 0.0650, lr_0 = 1.3852e-04
Loss = 9.7254e-06, PNorm = 63.0807, GNorm = 0.1012, lr_0 = 1.3791e-04
Loss = 1.4299e-05, PNorm = 63.0810, GNorm = 0.2263, lr_0 = 1.3730e-04
Validation rmse logD = 0.597529
Validation R2 logD = 0.758760
Validation rmse logP = 0.606055
Validation R2 logP = 0.773555
Epoch 85
Train function
Loss = 1.1355e-05, PNorm = 63.0816, GNorm = 0.2063, lr_0 = 1.3663e-04
Loss = 1.1224e-05, PNorm = 63.0830, GNorm = 0.1426, lr_0 = 1.3602e-04
Loss = 1.2710e-05, PNorm = 63.0848, GNorm = 0.1055, lr_0 = 1.3542e-04
Loss = 1.0686e-05, PNorm = 63.0861, GNorm = 0.1501, lr_0 = 1.3482e-04
Loss = 9.5878e-06, PNorm = 63.0874, GNorm = 0.1426, lr_0 = 1.3423e-04
Validation rmse logD = 0.597403
Validation R2 logD = 0.758862
Validation rmse logP = 0.604876
Validation R2 logP = 0.774436
Epoch 86
Train function
Loss = 7.9482e-06, PNorm = 63.0875, GNorm = 0.1296, lr_0 = 1.3357e-04
Loss = 9.3116e-06, PNorm = 63.0888, GNorm = 0.0658, lr_0 = 1.3298e-04
Loss = 1.0235e-05, PNorm = 63.0898, GNorm = 0.0896, lr_0 = 1.3239e-04
Loss = 9.4056e-06, PNorm = 63.0912, GNorm = 0.0514, lr_0 = 1.3181e-04
Loss = 8.4174e-06, PNorm = 63.0921, GNorm = 0.0747, lr_0 = 1.3123e-04
Loss = 9.0285e-06, PNorm = 63.0923, GNorm = 0.1331, lr_0 = 1.3065e-04
Validation rmse logD = 0.596984
Validation R2 logD = 0.759200
Validation rmse logP = 0.605578
Validation R2 logP = 0.773912
Epoch 87
Train function
Loss = 9.7585e-06, PNorm = 63.0931, GNorm = 0.1355, lr_0 = 1.3001e-04
Loss = 1.5239e-05, PNorm = 63.0935, GNorm = 0.1829, lr_0 = 1.2944e-04
Loss = 1.2550e-05, PNorm = 63.0949, GNorm = 0.1355, lr_0 = 1.2886e-04
Loss = 1.1802e-05, PNorm = 63.0963, GNorm = 0.0718, lr_0 = 1.2829e-04
Loss = 9.4961e-06, PNorm = 63.0975, GNorm = 0.0570, lr_0 = 1.2773e-04
Validation rmse logD = 0.597119
Validation R2 logD = 0.759091
Validation rmse logP = 0.606839
Validation R2 logP = 0.772970
Epoch 88
Train function
Loss = 8.9992e-06, PNorm = 63.0986, GNorm = 0.1281, lr_0 = 1.2710e-04
Loss = 7.8351e-06, PNorm = 63.0998, GNorm = 0.1248, lr_0 = 1.2654e-04
Loss = 1.2840e-05, PNorm = 63.1008, GNorm = 0.1173, lr_0 = 1.2598e-04
Loss = 8.3745e-06, PNorm = 63.1018, GNorm = 0.0648, lr_0 = 1.2542e-04
Loss = 8.6308e-06, PNorm = 63.1023, GNorm = 0.1711, lr_0 = 1.2487e-04
Validation rmse logD = 0.596798
Validation R2 logD = 0.759350
Validation rmse logP = 0.604523
Validation R2 logP = 0.774699
Epoch 89
Train function
Loss = 9.0868e-06, PNorm = 63.1027, GNorm = 0.0783, lr_0 = 1.2426e-04
Loss = 8.8874e-06, PNorm = 63.1040, GNorm = 0.0682, lr_0 = 1.2371e-04
Loss = 7.7376e-06, PNorm = 63.1048, GNorm = 0.1065, lr_0 = 1.2317e-04
Loss = 6.7345e-06, PNorm = 63.1056, GNorm = 0.0685, lr_0 = 1.2262e-04
Loss = 8.7501e-06, PNorm = 63.1065, GNorm = 0.0707, lr_0 = 1.2208e-04
Loss = 8.0084e-06, PNorm = 63.1083, GNorm = 0.1201, lr_0 = 1.2154e-04
Loss = 1.0747e-04, PNorm = 63.1085, GNorm = 0.3077, lr_0 = 1.2148e-04
Validation rmse logD = 0.597094
Validation R2 logD = 0.759112
Validation rmse logP = 0.606658
Validation R2 logP = 0.773105
Epoch 90
Train function
Loss = 7.2829e-06, PNorm = 63.1093, GNorm = 0.1053, lr_0 = 1.2095e-04
Loss = 7.9141e-06, PNorm = 63.1107, GNorm = 0.0408, lr_0 = 1.2041e-04
Loss = 6.9315e-06, PNorm = 63.1108, GNorm = 0.0325, lr_0 = 1.1988e-04
Loss = 7.7695e-06, PNorm = 63.1116, GNorm = 0.0898, lr_0 = 1.1935e-04
Loss = 6.4547e-06, PNorm = 63.1123, GNorm = 0.1160, lr_0 = 1.1882e-04
Validation rmse logD = 0.597029
Validation R2 logD = 0.759164
Validation rmse logP = 0.604747
Validation R2 logP = 0.774532
Epoch 91
Train function
Loss = 6.8313e-06, PNorm = 63.1133, GNorm = 0.1114, lr_0 = 1.1824e-04
Loss = 6.8262e-06, PNorm = 63.1140, GNorm = 0.0450, lr_0 = 1.1772e-04
Loss = 7.5538e-06, PNorm = 63.1152, GNorm = 0.0777, lr_0 = 1.1720e-04
Loss = 8.2445e-06, PNorm = 63.1164, GNorm = 0.0704, lr_0 = 1.1668e-04
Loss = 7.4758e-06, PNorm = 63.1169, GNorm = 0.0344, lr_0 = 1.1616e-04
Validation rmse logD = 0.596692
Validation R2 logD = 0.759436
Validation rmse logP = 0.605522
Validation R2 logP = 0.773954
Epoch 92
Train function
Loss = 7.7824e-06, PNorm = 63.1177, GNorm = 0.0664, lr_0 = 1.1565e-04
Loss = 5.8659e-06, PNorm = 63.1184, GNorm = 0.1036, lr_0 = 1.1514e-04
Loss = 8.1103e-06, PNorm = 63.1193, GNorm = 0.0502, lr_0 = 1.1463e-04
Loss = 5.7674e-06, PNorm = 63.1201, GNorm = 0.1109, lr_0 = 1.1412e-04
Loss = 9.1122e-06, PNorm = 63.1212, GNorm = 0.0688, lr_0 = 1.1362e-04
Loss = 6.0619e-06, PNorm = 63.1217, GNorm = 0.1018, lr_0 = 1.1312e-04
Loss = 1.5345e-04, PNorm = 63.1218, GNorm = 0.2228, lr_0 = 1.1307e-04
Validation rmse logD = 0.597186
Validation R2 logD = 0.759037
Validation rmse logP = 0.604350
Validation R2 logP = 0.774828
Epoch 93
Train function
Loss = 7.6409e-06, PNorm = 63.1230, GNorm = 0.1578, lr_0 = 1.1257e-04
Loss = 6.2287e-06, PNorm = 63.1237, GNorm = 0.0840, lr_0 = 1.1207e-04
Loss = 8.1729e-06, PNorm = 63.1241, GNorm = 0.0915, lr_0 = 1.1157e-04
Loss = 7.9196e-06, PNorm = 63.1249, GNorm = 0.1618, lr_0 = 1.1108e-04
Loss = 1.2727e-05, PNorm = 63.1255, GNorm = 0.0858, lr_0 = 1.1059e-04
Validation rmse logD = 0.596675
Validation R2 logD = 0.759450
Validation rmse logP = 0.604666
Validation R2 logP = 0.774593
Epoch 94
Train function
Loss = 7.8590e-06, PNorm = 63.1266, GNorm = 0.1427, lr_0 = 1.1005e-04
Loss = 1.0836e-05, PNorm = 63.1285, GNorm = 0.1114, lr_0 = 1.0956e-04
Loss = 7.7043e-06, PNorm = 63.1292, GNorm = 0.0979, lr_0 = 1.0908e-04
Loss = 5.9270e-06, PNorm = 63.1296, GNorm = 0.0518, lr_0 = 1.0860e-04
Loss = 4.5987e-06, PNorm = 63.1297, GNorm = 0.0566, lr_0 = 1.0811e-04
Validation rmse logD = 0.596920
Validation R2 logD = 0.759252
Validation rmse logP = 0.606017
Validation R2 logP = 0.773584
Epoch 95
Train function
Loss = 7.8896e-06, PNorm = 63.1307, GNorm = 0.2167, lr_0 = 1.0759e-04
Loss = 7.2079e-06, PNorm = 63.1321, GNorm = 0.0934, lr_0 = 1.0711e-04
Loss = 7.2951e-06, PNorm = 63.1330, GNorm = 0.1174, lr_0 = 1.0664e-04
Loss = 4.6207e-06, PNorm = 63.1342, GNorm = 0.0354, lr_0 = 1.0617e-04
Loss = 4.4795e-06, PNorm = 63.1350, GNorm = 0.0595, lr_0 = 1.0570e-04
Validation rmse logD = 0.597126
Validation R2 logD = 0.759086
Validation rmse logP = 0.608922
Validation R2 logP = 0.771408
Epoch 96
Train function
Loss = 7.9139e-06, PNorm = 63.1355, GNorm = 0.1755, lr_0 = 1.0518e-04
Loss = 1.1335e-05, PNorm = 63.1357, GNorm = 0.1067, lr_0 = 1.0472e-04
Loss = 7.2675e-06, PNorm = 63.1359, GNorm = 0.0543, lr_0 = 1.0426e-04
Loss = 1.0098e-05, PNorm = 63.1374, GNorm = 0.0726, lr_0 = 1.0379e-04
Loss = 6.6920e-06, PNorm = 63.1380, GNorm = 0.0450, lr_0 = 1.0333e-04
Loss = 6.4264e-06, PNorm = 63.1384, GNorm = 0.1065, lr_0 = 1.0288e-04
Validation rmse logD = 0.596609
Validation R2 logD = 0.759503
Validation rmse logP = 0.606744
Validation R2 logP = 0.773041
Epoch 97
Train function
Loss = 6.9561e-06, PNorm = 63.1396, GNorm = 0.0392, lr_0 = 1.0238e-04
Loss = 6.7478e-06, PNorm = 63.1408, GNorm = 0.1242, lr_0 = 1.0192e-04
Loss = 5.9138e-06, PNorm = 63.1411, GNorm = 0.1927, lr_0 = 1.0147e-04
Loss = 5.9147e-06, PNorm = 63.1413, GNorm = 0.0826, lr_0 = 1.0102e-04
Loss = 7.4689e-06, PNorm = 63.1422, GNorm = 0.0549, lr_0 = 1.0058e-04
Validation rmse logD = 0.596629
Validation R2 logD = 0.759487
Validation rmse logP = 0.604229
Validation R2 logP = 0.774918
Epoch 98
Train function
Loss = 1.1631e-05, PNorm = 63.1428, GNorm = 0.0964, lr_0 = 1.0009e-04
Loss = 7.4649e-06, PNorm = 63.1438, GNorm = 0.0472, lr_0 = 1.0000e-04
Loss = 1.1417e-05, PNorm = 63.1443, GNorm = 0.1744, lr_0 = 1.0000e-04
Loss = 9.3164e-06, PNorm = 63.1456, GNorm = 0.2498, lr_0 = 1.0000e-04
Loss = 9.6572e-06, PNorm = 63.1472, GNorm = 0.1580, lr_0 = 1.0000e-04
Validation rmse logD = 0.596848
Validation R2 logD = 0.759310
Validation rmse logP = 0.604851
Validation R2 logP = 0.774454
Epoch 99
Train function
Loss = 6.2259e-06, PNorm = 63.1482, GNorm = 0.0886, lr_0 = 1.0000e-04
Loss = 7.7477e-06, PNorm = 63.1488, GNorm = 0.1108, lr_0 = 1.0000e-04
Loss = 6.4470e-06, PNorm = 63.1497, GNorm = 0.0690, lr_0 = 1.0000e-04
Loss = 7.3346e-06, PNorm = 63.1503, GNorm = 0.0795, lr_0 = 1.0000e-04
Loss = 7.0751e-06, PNorm = 63.1503, GNorm = 0.1068, lr_0 = 1.0000e-04
Loss = 4.3957e-06, PNorm = 63.1506, GNorm = 0.0390, lr_0 = 1.0000e-04
Validation rmse logD = 0.598370
Validation R2 logD = 0.758081
Validation rmse logP = 0.607577
Validation R2 logP = 0.772417
Model 0 best validation rmse = 0.589421 on epoch 34
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.641571
Model 0 test R2 logD = 0.710914
Model 0 test rmse logP = 0.813783
Model 0 test R2 logP = 0.714040
Ensemble test rmse  logD= 0.641571
Ensemble test R2  logD= 0.710914
Ensemble test rmse  logP= 0.813783
Ensemble test R2  logP= 0.714040
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 2.0400e-02, PNorm = 52.9418, GNorm = 5.3595, lr_0 = 1.9340e-04
Loss = 1.8608e-02, PNorm = 52.9490, GNorm = 5.8495, lr_0 = 2.7830e-04
Loss = 1.7424e-02, PNorm = 52.9607, GNorm = 9.4055, lr_0 = 3.6321e-04
Loss = 1.4984e-02, PNorm = 52.9783, GNorm = 3.4000, lr_0 = 4.4811e-04
Loss = 1.3941e-02, PNorm = 53.0018, GNorm = 2.8154, lr_0 = 5.3302e-04
Validation rmse logD = 1.045692
Validation R2 logD = 0.209396
Validation rmse logP = 1.195291
Validation R2 logP = 0.273902
Epoch 1
Train function
Loss = 1.5429e-02, PNorm = 53.0321, GNorm = 6.9581, lr_0 = 6.2642e-04
Loss = 1.2728e-02, PNorm = 53.0657, GNorm = 2.7954, lr_0 = 7.1132e-04
Loss = 1.3405e-02, PNorm = 53.1069, GNorm = 3.5543, lr_0 = 7.9623e-04
Loss = 1.0624e-02, PNorm = 53.1591, GNorm = 1.5502, lr_0 = 8.8113e-04
Loss = 9.7102e-03, PNorm = 53.2182, GNorm = 3.1044, lr_0 = 9.6604e-04
Validation rmse logD = 0.946626
Validation R2 logD = 0.352099
Validation rmse logP = 1.043892
Validation R2 logP = 0.446192
Epoch 2
Train function
Loss = 9.5893e-03, PNorm = 53.2839, GNorm = 4.9319, lr_0 = 9.9690e-04
Loss = 1.0999e-02, PNorm = 53.3537, GNorm = 2.8241, lr_0 = 9.9249e-04
Loss = 9.6107e-03, PNorm = 53.4263, GNorm = 2.0383, lr_0 = 9.8810e-04
Loss = 9.5290e-03, PNorm = 53.5002, GNorm = 4.8146, lr_0 = 9.8373e-04
Loss = 1.0753e-02, PNorm = 53.5724, GNorm = 1.1509, lr_0 = 9.7938e-04
Validation rmse logD = 0.819816
Validation R2 logD = 0.514058
Validation rmse logP = 0.932453
Validation R2 logP = 0.558122
Epoch 3
Train function
Loss = 1.1134e-02, PNorm = 53.6645, GNorm = 1.0677, lr_0 = 9.7462e-04
Loss = 9.1156e-03, PNorm = 53.7430, GNorm = 1.3277, lr_0 = 9.7030e-04
Loss = 8.8060e-03, PNorm = 53.8288, GNorm = 1.9472, lr_0 = 9.6601e-04
Loss = 7.2713e-03, PNorm = 53.9219, GNorm = 0.8184, lr_0 = 9.6174e-04
Loss = 6.8674e-03, PNorm = 54.0137, GNorm = 1.7661, lr_0 = 9.5749e-04
Loss = 7.3607e-03, PNorm = 54.1107, GNorm = 2.7001, lr_0 = 9.5325e-04
Validation rmse logD = 0.773449
Validation R2 logD = 0.567471
Validation rmse logP = 0.834606
Validation R2 logP = 0.645994
Epoch 4
Train function
Loss = 6.4585e-03, PNorm = 54.2323, GNorm = 1.1423, lr_0 = 9.4861e-04
Loss = 7.0829e-03, PNorm = 54.3478, GNorm = 1.7465, lr_0 = 9.4442e-04
Loss = 7.2196e-03, PNorm = 54.4407, GNorm = 3.1427, lr_0 = 9.4024e-04
Loss = 8.0821e-03, PNorm = 54.5618, GNorm = 3.4162, lr_0 = 9.3608e-04
Loss = 7.1140e-03, PNorm = 54.6551, GNorm = 3.5505, lr_0 = 9.3194e-04
Validation rmse logD = 0.794205
Validation R2 logD = 0.543945
Validation rmse logP = 0.828920
Validation R2 logP = 0.650801
Epoch 5
Train function
Loss = 7.6832e-03, PNorm = 54.7513, GNorm = 2.3174, lr_0 = 9.2741e-04
Loss = 5.6625e-03, PNorm = 54.8573, GNorm = 2.4803, lr_0 = 9.2330e-04
Loss = 5.9311e-03, PNorm = 54.9518, GNorm = 0.7562, lr_0 = 9.1922e-04
Loss = 6.0622e-03, PNorm = 55.0473, GNorm = 1.5492, lr_0 = 9.1515e-04
Loss = 5.1918e-03, PNorm = 55.1418, GNorm = 0.7848, lr_0 = 9.1111e-04
Validation rmse logD = 0.714095
Validation R2 logD = 0.631308
Validation rmse logP = 0.844413
Validation R2 logP = 0.637625
Epoch 6
Train function
Loss = 5.7197e-03, PNorm = 55.2291, GNorm = 0.8095, lr_0 = 9.0667e-04
Loss = 6.0385e-03, PNorm = 55.3293, GNorm = 2.7575, lr_0 = 9.0266e-04
Loss = 4.9854e-03, PNorm = 55.4502, GNorm = 0.6665, lr_0 = 8.9867e-04
Loss = 5.6621e-03, PNorm = 55.5481, GNorm = 2.2173, lr_0 = 8.9469e-04
Loss = 5.3491e-03, PNorm = 55.6338, GNorm = 3.2174, lr_0 = 8.9074e-04
Loss = 5.3482e-03, PNorm = 55.7301, GNorm = 2.8303, lr_0 = 8.8680e-04
Validation rmse logD = 0.721106
Validation R2 logD = 0.624033
Validation rmse logP = 0.775917
Validation R2 logP = 0.694030
Epoch 7
Train function
Loss = 4.7369e-03, PNorm = 55.8262, GNorm = 2.3373, lr_0 = 8.8248e-04
Loss = 5.1621e-03, PNorm = 55.9204, GNorm = 1.8483, lr_0 = 8.7858e-04
Loss = 3.7042e-03, PNorm = 56.0055, GNorm = 1.5075, lr_0 = 8.7469e-04
Loss = 5.0823e-03, PNorm = 56.0838, GNorm = 1.5190, lr_0 = 8.7082e-04
Loss = 4.2822e-03, PNorm = 56.1782, GNorm = 0.9019, lr_0 = 8.6697e-04
Validation rmse logD = 0.640558
Validation R2 logD = 0.703333
Validation rmse logP = 0.797140
Validation R2 logP = 0.677063
Epoch 8
Train function
Loss = 3.4646e-03, PNorm = 56.2833, GNorm = 4.5894, lr_0 = 8.6276e-04
Loss = 4.5016e-03, PNorm = 56.3879, GNorm = 4.7250, lr_0 = 8.5894e-04
Loss = 5.0053e-03, PNorm = 56.4917, GNorm = 1.4478, lr_0 = 8.5514e-04
Loss = 4.4853e-03, PNorm = 56.5965, GNorm = 0.7710, lr_0 = 8.5136e-04
Loss = 3.6347e-03, PNorm = 56.6818, GNorm = 1.6355, lr_0 = 8.4759e-04
Validation rmse logD = 0.672314
Validation R2 logD = 0.673190
Validation rmse logP = 0.749203
Validation R2 logP = 0.714736
Epoch 9
Train function
Loss = 3.5278e-03, PNorm = 56.7473, GNorm = 1.5175, lr_0 = 8.4384e-04
Loss = 3.7515e-03, PNorm = 56.8269, GNorm = 3.1564, lr_0 = 8.4011e-04
Loss = 3.8654e-03, PNorm = 56.9073, GNorm = 1.1309, lr_0 = 8.3639e-04
Loss = 3.7833e-03, PNorm = 56.9936, GNorm = 1.3238, lr_0 = 8.3269e-04
Loss = 3.0560e-03, PNorm = 57.0955, GNorm = 1.0951, lr_0 = 8.2901e-04
Loss = 3.4198e-03, PNorm = 57.1676, GNorm = 1.0087, lr_0 = 8.2534e-04
Validation rmse logD = 0.618564
Validation R2 logD = 0.723356
Validation rmse logP = 0.727608
Validation R2 logP = 0.730944
Epoch 10
Train function
Loss = 2.8490e-03, PNorm = 57.2499, GNorm = 0.8559, lr_0 = 8.2133e-04
Loss = 2.9522e-03, PNorm = 57.3392, GNorm = 0.8683, lr_0 = 8.1770e-04
Loss = 3.1665e-03, PNorm = 57.4246, GNorm = 1.3039, lr_0 = 8.1408e-04
Loss = 3.5348e-03, PNorm = 57.5133, GNorm = 1.6180, lr_0 = 8.1048e-04
Loss = 2.8761e-03, PNorm = 57.5986, GNorm = 0.7675, lr_0 = 8.0689e-04
Validation rmse logD = 0.631610
Validation R2 logD = 0.711564
Validation rmse logP = 0.756806
Validation R2 logP = 0.708917
Epoch 11
Train function
Loss = 2.8263e-03, PNorm = 57.6883, GNorm = 0.8534, lr_0 = 8.0297e-04
Loss = 2.8236e-03, PNorm = 57.7643, GNorm = 2.1847, lr_0 = 7.9942e-04
Loss = 2.9191e-03, PNorm = 57.8451, GNorm = 3.7747, lr_0 = 7.9588e-04
Loss = 2.9153e-03, PNorm = 57.9321, GNorm = 0.9386, lr_0 = 7.9236e-04
Loss = 2.3203e-03, PNorm = 58.0236, GNorm = 0.8435, lr_0 = 7.8885e-04
Validation rmse logD = 0.656317
Validation R2 logD = 0.688556
Validation rmse logP = 0.729235
Validation R2 logP = 0.729739
Epoch 12
Train function
Loss = 2.0861e-03, PNorm = 58.1220, GNorm = 0.6532, lr_0 = 7.8502e-04
Loss = 2.6430e-03, PNorm = 58.1989, GNorm = 0.8192, lr_0 = 7.8154e-04
Loss = 2.8186e-03, PNorm = 58.2753, GNorm = 1.5846, lr_0 = 7.7809e-04
Loss = 2.6298e-03, PNorm = 58.3594, GNorm = 1.0388, lr_0 = 7.7465e-04
Loss = 2.0962e-03, PNorm = 58.4383, GNorm = 1.1099, lr_0 = 7.7122e-04
Loss = 2.1214e-03, PNorm = 58.5007, GNorm = 1.5867, lr_0 = 7.6781e-04
Loss = 1.5643e-02, PNorm = 58.5054, GNorm = 3.6686, lr_0 = 7.6747e-04
Validation rmse logD = 0.613794
Validation R2 logD = 0.727606
Validation rmse logP = 0.711867
Validation R2 logP = 0.742459
Epoch 13
Train function
Loss = 1.8807e-03, PNorm = 58.5711, GNorm = 0.8721, lr_0 = 7.6407e-04
Loss = 2.2663e-03, PNorm = 58.6393, GNorm = 0.6936, lr_0 = 7.6069e-04
Loss = 2.3712e-03, PNorm = 58.7163, GNorm = 3.1300, lr_0 = 7.5733e-04
Loss = 2.7069e-03, PNorm = 58.7764, GNorm = 2.2281, lr_0 = 7.5398e-04
Loss = 2.3276e-03, PNorm = 58.8547, GNorm = 1.3477, lr_0 = 7.5064e-04
Validation rmse logD = 0.648274
Validation R2 logD = 0.696143
Validation rmse logP = 0.708500
Validation R2 logP = 0.744890
Epoch 14
Train function
Loss = 2.4650e-03, PNorm = 58.9626, GNorm = 1.0831, lr_0 = 7.4699e-04
Loss = 2.2033e-03, PNorm = 59.0464, GNorm = 1.8114, lr_0 = 7.4369e-04
Loss = 2.5263e-03, PNorm = 59.1190, GNorm = 1.5799, lr_0 = 7.4040e-04
Loss = 2.1887e-03, PNorm = 59.1969, GNorm = 0.6505, lr_0 = 7.3712e-04
Loss = 1.8977e-03, PNorm = 59.2592, GNorm = 1.9935, lr_0 = 7.3386e-04
Validation rmse logD = 0.637953
Validation R2 logD = 0.705741
Validation rmse logP = 0.708228
Validation R2 logP = 0.745086
Epoch 15
Train function
Loss = 1.8704e-03, PNorm = 59.3342, GNorm = 0.8457, lr_0 = 7.3029e-04
Loss = 1.8151e-03, PNorm = 59.3986, GNorm = 1.6547, lr_0 = 7.2706e-04
Loss = 1.8989e-03, PNorm = 59.4683, GNorm = 1.2321, lr_0 = 7.2385e-04
Loss = 1.9941e-03, PNorm = 59.5296, GNorm = 0.7769, lr_0 = 7.2064e-04
Loss = 1.7415e-03, PNorm = 59.5887, GNorm = 0.5641, lr_0 = 7.1746e-04
Validation rmse logD = 0.617589
Validation R2 logD = 0.724228
Validation rmse logP = 0.693397
Validation R2 logP = 0.755650
Epoch 16
Train function
Loss = 9.6103e-04, PNorm = 59.6503, GNorm = 1.2081, lr_0 = 7.1397e-04
Loss = 1.3125e-03, PNorm = 59.7046, GNorm = 0.9409, lr_0 = 7.1081e-04
Loss = 1.3542e-03, PNorm = 59.7601, GNorm = 1.6588, lr_0 = 7.0766e-04
Loss = 1.6420e-03, PNorm = 59.8191, GNorm = 0.6769, lr_0 = 7.0453e-04
Loss = 1.2662e-03, PNorm = 59.8601, GNorm = 0.9771, lr_0 = 7.0142e-04
Loss = 1.3546e-03, PNorm = 59.8967, GNorm = 1.0860, lr_0 = 6.9831e-04
Validation rmse logD = 0.611109
Validation R2 logD = 0.729985
Validation rmse logP = 0.699963
Validation R2 logP = 0.751001
Epoch 17
Train function
Loss = 1.4530e-03, PNorm = 59.9378, GNorm = 0.9358, lr_0 = 6.9523e-04
Loss = 1.1425e-03, PNorm = 59.9894, GNorm = 0.5776, lr_0 = 6.9215e-04
Loss = 1.0908e-03, PNorm = 60.0293, GNorm = 0.6463, lr_0 = 6.8909e-04
Loss = 1.2225e-03, PNorm = 60.0845, GNorm = 0.7251, lr_0 = 6.8604e-04
Loss = 1.2576e-03, PNorm = 60.1300, GNorm = 0.6292, lr_0 = 6.8301e-04
Validation rmse logD = 0.595519
Validation R2 logD = 0.743585
Validation rmse logP = 0.724397
Validation R2 logP = 0.733314
Epoch 18
Train function
Loss = 8.9836e-04, PNorm = 60.1829, GNorm = 0.8038, lr_0 = 6.7968e-04
Loss = 9.9802e-04, PNorm = 60.2355, GNorm = 0.5302, lr_0 = 6.7668e-04
Loss = 9.3841e-04, PNorm = 60.2798, GNorm = 0.5846, lr_0 = 6.7368e-04
Loss = 1.1711e-03, PNorm = 60.3238, GNorm = 1.2749, lr_0 = 6.7070e-04
Loss = 8.7067e-04, PNorm = 60.3628, GNorm = 0.4535, lr_0 = 6.6774e-04
Validation rmse logD = 0.616901
Validation R2 logD = 0.724841
Validation rmse logP = 0.707560
Validation R2 logP = 0.745566
Epoch 19
Train function
Loss = 1.1304e-03, PNorm = 60.4026, GNorm = 1.6219, lr_0 = 6.6449e-04
Loss = 9.2713e-04, PNorm = 60.4488, GNorm = 0.5632, lr_0 = 6.6155e-04
Loss = 7.9424e-04, PNorm = 60.4935, GNorm = 1.2084, lr_0 = 6.5862e-04
Loss = 8.5846e-04, PNorm = 60.5360, GNorm = 0.7996, lr_0 = 6.5571e-04
Loss = 9.0516e-04, PNorm = 60.5710, GNorm = 1.0561, lr_0 = 6.5281e-04
Loss = 9.3947e-04, PNorm = 60.6060, GNorm = 0.9316, lr_0 = 6.4992e-04
Validation rmse logD = 0.633702
Validation R2 logD = 0.709650
Validation rmse logP = 0.694895
Validation R2 logP = 0.754593
Epoch 20
Train function
Loss = 1.2505e-03, PNorm = 60.6554, GNorm = 0.7507, lr_0 = 6.4676e-04
Loss = 1.4596e-03, PNorm = 60.7200, GNorm = 0.7254, lr_0 = 6.4390e-04
Loss = 8.3583e-04, PNorm = 60.7708, GNorm = 0.3973, lr_0 = 6.4105e-04
Loss = 8.1905e-04, PNorm = 60.8187, GNorm = 0.4309, lr_0 = 6.3822e-04
Loss = 8.8372e-04, PNorm = 60.8577, GNorm = 0.4043, lr_0 = 6.3539e-04
Validation rmse logD = 0.637532
Validation R2 logD = 0.706129
Validation rmse logP = 0.696889
Validation R2 logP = 0.753183
Epoch 21
Train function
Loss = 7.8564e-04, PNorm = 60.8972, GNorm = 0.3754, lr_0 = 6.3230e-04
Loss = 7.1818e-04, PNorm = 60.9296, GNorm = 0.4638, lr_0 = 6.2950e-04
Loss = 6.7627e-04, PNorm = 60.9657, GNorm = 0.9253, lr_0 = 6.2672e-04
Loss = 9.8675e-04, PNorm = 61.0053, GNorm = 1.2733, lr_0 = 6.2395e-04
Loss = 9.2097e-04, PNorm = 61.0424, GNorm = 1.6869, lr_0 = 6.2119e-04
Validation rmse logD = 0.623306
Validation R2 logD = 0.719099
Validation rmse logP = 0.698606
Validation R2 logP = 0.751965
Epoch 22
Train function
Loss = 1.4360e-03, PNorm = 61.0946, GNorm = 1.7268, lr_0 = 6.1817e-04
Loss = 1.0680e-03, PNorm = 61.1425, GNorm = 0.4487, lr_0 = 6.1543e-04
Loss = 8.1136e-04, PNorm = 61.1946, GNorm = 0.8372, lr_0 = 6.1271e-04
Loss = 7.5885e-04, PNorm = 61.2258, GNorm = 0.4409, lr_0 = 6.1000e-04
Loss = 7.2222e-04, PNorm = 61.2494, GNorm = 0.3678, lr_0 = 6.0730e-04
Loss = 6.5921e-04, PNorm = 61.2793, GNorm = 0.4093, lr_0 = 6.0461e-04
Validation rmse logD = 0.619433
Validation R2 logD = 0.722578
Validation rmse logP = 0.680245
Validation R2 logP = 0.764832
Epoch 23
Train function
Loss = 6.2767e-04, PNorm = 61.3192, GNorm = 0.3984, lr_0 = 6.0167e-04
Loss = 6.3197e-04, PNorm = 61.3529, GNorm = 0.5376, lr_0 = 5.9901e-04
Loss = 7.1394e-04, PNorm = 61.3840, GNorm = 0.6816, lr_0 = 5.9636e-04
Loss = 6.4682e-04, PNorm = 61.4099, GNorm = 0.5647, lr_0 = 5.9372e-04
Loss = 6.1720e-04, PNorm = 61.4379, GNorm = 1.0368, lr_0 = 5.9110e-04
Validation rmse logD = 0.614143
Validation R2 logD = 0.727296
Validation rmse logP = 0.693037
Validation R2 logP = 0.755904
Epoch 24
Train function
Loss = 5.5201e-04, PNorm = 61.4665, GNorm = 0.6633, lr_0 = 5.8822e-04
Loss = 4.6397e-04, PNorm = 61.4897, GNorm = 0.3447, lr_0 = 5.8562e-04
Loss = 5.6431e-04, PNorm = 61.5204, GNorm = 0.6763, lr_0 = 5.8303e-04
Loss = 5.6205e-04, PNorm = 61.5452, GNorm = 0.4091, lr_0 = 5.8045e-04
Loss = 4.7613e-04, PNorm = 61.5696, GNorm = 0.7855, lr_0 = 5.7788e-04
Validation rmse logD = 0.644419
Validation R2 logD = 0.699746
Validation rmse logP = 0.691869
Validation R2 logP = 0.756726
Epoch 25
Train function
Loss = 9.4058e-04, PNorm = 61.5928, GNorm = 1.5239, lr_0 = 5.7533e-04
Loss = 6.7629e-04, PNorm = 61.6298, GNorm = 1.5220, lr_0 = 5.7278e-04
Loss = 5.7853e-04, PNorm = 61.6632, GNorm = 0.6393, lr_0 = 5.7025e-04
Loss = 4.7495e-04, PNorm = 61.6938, GNorm = 0.5077, lr_0 = 5.6773e-04
Loss = 4.5288e-04, PNorm = 61.7134, GNorm = 0.7091, lr_0 = 5.6522e-04
Loss = 5.5204e-04, PNorm = 61.7334, GNorm = 0.4396, lr_0 = 5.6272e-04
Validation rmse logD = 0.615358
Validation R2 logD = 0.726216
Validation rmse logP = 0.691731
Validation R2 logP = 0.756823
Epoch 26
Train function
Loss = 5.2733e-04, PNorm = 61.7611, GNorm = 0.7308, lr_0 = 5.5998e-04
Loss = 5.2838e-04, PNorm = 61.7875, GNorm = 0.3584, lr_0 = 5.5750e-04
Loss = 5.2398e-04, PNorm = 61.8157, GNorm = 0.6674, lr_0 = 5.5503e-04
Loss = 4.7558e-04, PNorm = 61.8384, GNorm = 0.3765, lr_0 = 5.5258e-04
Loss = 3.9387e-04, PNorm = 61.8594, GNorm = 0.4026, lr_0 = 5.5014e-04
Validation rmse logD = 0.612881
Validation R2 logD = 0.728416
Validation rmse logP = 0.694488
Validation R2 logP = 0.754881
Epoch 27
Train function
Loss = 3.2001e-04, PNorm = 61.8832, GNorm = 0.3154, lr_0 = 5.4746e-04
Loss = 3.3713e-04, PNorm = 61.8994, GNorm = 0.4906, lr_0 = 5.4504e-04
Loss = 3.9507e-04, PNorm = 61.9200, GNorm = 0.3066, lr_0 = 5.4263e-04
Loss = 3.5566e-04, PNorm = 61.9435, GNorm = 0.4742, lr_0 = 5.4023e-04
Loss = 4.1812e-04, PNorm = 61.9634, GNorm = 0.3725, lr_0 = 5.3784e-04
Validation rmse logD = 0.629345
Validation R2 logD = 0.713629
Validation rmse logP = 0.685453
Validation R2 logP = 0.761217
Epoch 28
Train function
Loss = 3.7873e-04, PNorm = 61.9831, GNorm = 0.4984, lr_0 = 5.3522e-04
Loss = 4.4207e-04, PNorm = 61.9973, GNorm = 0.5253, lr_0 = 5.3285e-04
Loss = 4.2404e-04, PNorm = 62.0176, GNorm = 0.6339, lr_0 = 5.3050e-04
Loss = 3.9271e-04, PNorm = 62.0422, GNorm = 0.9641, lr_0 = 5.2815e-04
Loss = 4.0508e-04, PNorm = 62.0668, GNorm = 0.6051, lr_0 = 5.2581e-04
Loss = 3.9148e-04, PNorm = 62.0893, GNorm = 1.0037, lr_0 = 5.2349e-04
Loss = 1.4024e-03, PNorm = 62.0907, GNorm = 0.6575, lr_0 = 5.2326e-04
Validation rmse logD = 0.631165
Validation R2 logD = 0.711970
Validation rmse logP = 0.692885
Validation R2 logP = 0.756011
Epoch 29
Train function
Loss = 4.3418e-04, PNorm = 62.1185, GNorm = 0.4299, lr_0 = 5.2094e-04
Loss = 3.4600e-04, PNorm = 62.1408, GNorm = 0.4740, lr_0 = 5.1864e-04
Loss = 3.5075e-04, PNorm = 62.1555, GNorm = 0.3898, lr_0 = 5.1634e-04
Loss = 3.4885e-04, PNorm = 62.1714, GNorm = 0.5457, lr_0 = 5.1406e-04
Loss = 3.0066e-04, PNorm = 62.1876, GNorm = 0.3387, lr_0 = 5.1178e-04
Validation rmse logD = 0.608763
Validation R2 logD = 0.732054
Validation rmse logP = 0.681157
Validation R2 logP = 0.764200
Epoch 30
Train function
Loss = 2.8688e-04, PNorm = 62.2052, GNorm = 0.3128, lr_0 = 5.0930e-04
Loss = 2.4674e-04, PNorm = 62.2202, GNorm = 0.5249, lr_0 = 5.0704e-04
Loss = 2.7077e-04, PNorm = 62.2377, GNorm = 0.6494, lr_0 = 5.0480e-04
Loss = 3.0275e-04, PNorm = 62.2555, GNorm = 0.3209, lr_0 = 5.0257e-04
Loss = 2.7953e-04, PNorm = 62.2669, GNorm = 0.2086, lr_0 = 5.0034e-04
Validation rmse logD = 0.610813
Validation R2 logD = 0.730246
Validation rmse logP = 0.688153
Validation R2 logP = 0.759332
Epoch 31
Train function
Loss = 2.8090e-04, PNorm = 62.2831, GNorm = 0.4066, lr_0 = 4.9791e-04
Loss = 2.5346e-04, PNorm = 62.3015, GNorm = 0.2844, lr_0 = 4.9571e-04
Loss = 2.4459e-04, PNorm = 62.3184, GNorm = 0.2221, lr_0 = 4.9351e-04
Loss = 2.8152e-04, PNorm = 62.3318, GNorm = 0.8921, lr_0 = 4.9133e-04
Loss = 3.2195e-04, PNorm = 62.3450, GNorm = 0.4428, lr_0 = 4.8916e-04
Validation rmse logD = 0.608402
Validation R2 logD = 0.732371
Validation rmse logP = 0.691757
Validation R2 logP = 0.756805
Epoch 32
Train function
Loss = 2.3182e-04, PNorm = 62.3640, GNorm = 0.4547, lr_0 = 4.8678e-04
Loss = 2.9708e-04, PNorm = 62.3834, GNorm = 0.3908, lr_0 = 4.8463e-04
Loss = 2.3759e-04, PNorm = 62.4020, GNorm = 0.4209, lr_0 = 4.8248e-04
Loss = 2.2079e-04, PNorm = 62.4160, GNorm = 0.3726, lr_0 = 4.8035e-04
Loss = 2.7338e-04, PNorm = 62.4274, GNorm = 0.8448, lr_0 = 4.7822e-04
Loss = 2.8449e-04, PNorm = 62.4367, GNorm = 0.4063, lr_0 = 4.7611e-04
Validation rmse logD = 0.620621
Validation R2 logD = 0.721513
Validation rmse logP = 0.687053
Validation R2 logP = 0.760101
Epoch 33
Train function
Loss = 2.9603e-04, PNorm = 62.4554, GNorm = 1.0111, lr_0 = 4.7379e-04
Loss = 2.3372e-04, PNorm = 62.4758, GNorm = 0.5380, lr_0 = 4.7170e-04
Loss = 2.2598e-04, PNorm = 62.4877, GNorm = 0.3148, lr_0 = 4.6961e-04
Loss = 2.0958e-04, PNorm = 62.4978, GNorm = 0.2591, lr_0 = 4.6753e-04
Loss = 2.6152e-04, PNorm = 62.5104, GNorm = 0.6482, lr_0 = 4.6546e-04
Validation rmse logD = 0.621142
Validation R2 logD = 0.721046
Validation rmse logP = 0.697392
Validation R2 logP = 0.752826
Epoch 34
Train function
Loss = 2.4308e-04, PNorm = 62.5285, GNorm = 0.3191, lr_0 = 4.6341e-04
Loss = 2.7843e-04, PNorm = 62.5412, GNorm = 1.2357, lr_0 = 4.6136e-04
Loss = 2.4278e-04, PNorm = 62.5562, GNorm = 0.5022, lr_0 = 4.5931e-04
Loss = 2.4096e-04, PNorm = 62.5699, GNorm = 0.2616, lr_0 = 4.5728e-04
Loss = 2.2572e-04, PNorm = 62.5817, GNorm = 0.3846, lr_0 = 4.5526e-04
Validation rmse logD = 0.615873
Validation R2 logD = 0.725758
Validation rmse logP = 0.688923
Validation R2 logP = 0.758793
Epoch 35
Train function
Loss = 1.9335e-04, PNorm = 62.5969, GNorm = 0.2876, lr_0 = 4.5305e-04
Loss = 2.0033e-04, PNorm = 62.6091, GNorm = 0.4396, lr_0 = 4.5104e-04
Loss = 2.3878e-04, PNorm = 62.6245, GNorm = 0.7127, lr_0 = 4.4905e-04
Loss = 2.0486e-04, PNorm = 62.6401, GNorm = 0.3632, lr_0 = 4.4706e-04
Loss = 2.0103e-04, PNorm = 62.6542, GNorm = 0.4484, lr_0 = 4.4508e-04
Loss = 2.4335e-04, PNorm = 62.6661, GNorm = 0.7502, lr_0 = 4.4311e-04
Validation rmse logD = 0.632741
Validation R2 logD = 0.710530
Validation rmse logP = 0.685609
Validation R2 logP = 0.761108
Epoch 36
Train function
Loss = 3.0062e-04, PNorm = 62.6806, GNorm = 0.2175, lr_0 = 4.4096e-04
Loss = 3.8147e-04, PNorm = 62.6911, GNorm = 0.5084, lr_0 = 4.3901e-04
Loss = 2.3762e-04, PNorm = 62.7096, GNorm = 0.7990, lr_0 = 4.3707e-04
Loss = 2.8001e-04, PNorm = 62.7282, GNorm = 0.3169, lr_0 = 4.3513e-04
Loss = 2.2377e-04, PNorm = 62.7430, GNorm = 0.2506, lr_0 = 4.3321e-04
Validation rmse logD = 0.614001
Validation R2 logD = 0.727422
Validation rmse logP = 0.698227
Validation R2 logP = 0.752234
Epoch 37
Train function
Loss = 2.3650e-04, PNorm = 62.7625, GNorm = 0.4137, lr_0 = 4.3110e-04
Loss = 2.3470e-04, PNorm = 62.7761, GNorm = 0.5213, lr_0 = 4.2919e-04
Loss = 1.8232e-04, PNorm = 62.7886, GNorm = 0.5033, lr_0 = 4.2729e-04
Loss = 2.1764e-04, PNorm = 62.8042, GNorm = 0.5287, lr_0 = 4.2540e-04
Loss = 2.0366e-04, PNorm = 62.8115, GNorm = 0.4581, lr_0 = 4.2352e-04
Validation rmse logD = 0.614865
Validation R2 logD = 0.726655
Validation rmse logP = 0.693000
Validation R2 logP = 0.755930
Epoch 38
Train function
Loss = 1.5202e-04, PNorm = 62.8275, GNorm = 0.3070, lr_0 = 4.2146e-04
Loss = 1.2652e-04, PNorm = 62.8390, GNorm = 0.2284, lr_0 = 4.1960e-04
Loss = 1.3980e-04, PNorm = 62.8455, GNorm = 0.3048, lr_0 = 4.1774e-04
Loss = 1.6059e-04, PNorm = 62.8543, GNorm = 0.2525, lr_0 = 4.1589e-04
Loss = 1.6126e-04, PNorm = 62.8609, GNorm = 0.3500, lr_0 = 4.1406e-04
Loss = 1.6987e-04, PNorm = 62.8696, GNorm = 0.1976, lr_0 = 4.1222e-04
Validation rmse logD = 0.609596
Validation R2 logD = 0.731319
Validation rmse logP = 0.693499
Validation R2 logP = 0.755578
Epoch 39
Train function
Loss = 1.0184e-04, PNorm = 62.8774, GNorm = 0.1510, lr_0 = 4.1022e-04
Loss = 1.3583e-04, PNorm = 62.8850, GNorm = 0.3737, lr_0 = 4.0840e-04
Loss = 1.3117e-04, PNorm = 62.8922, GNorm = 0.2855, lr_0 = 4.0660e-04
Loss = 1.1432e-04, PNorm = 62.9020, GNorm = 0.2475, lr_0 = 4.0480e-04
Loss = 1.5229e-04, PNorm = 62.9103, GNorm = 0.5710, lr_0 = 4.0301e-04
Validation rmse logD = 0.614069
Validation R2 logD = 0.727362
Validation rmse logP = 0.690417
Validation R2 logP = 0.757746
Epoch 40
Train function
Loss = 1.5507e-04, PNorm = 62.9177, GNorm = 0.2171, lr_0 = 4.0105e-04
Loss = 1.5560e-04, PNorm = 62.9262, GNorm = 0.4004, lr_0 = 3.9927e-04
Loss = 1.4995e-04, PNorm = 62.9370, GNorm = 0.4373, lr_0 = 3.9751e-04
Loss = 1.7538e-04, PNorm = 62.9458, GNorm = 0.6121, lr_0 = 3.9575e-04
Loss = 1.5590e-04, PNorm = 62.9569, GNorm = 0.3045, lr_0 = 3.9400e-04
Validation rmse logD = 0.612124
Validation R2 logD = 0.729086
Validation rmse logP = 0.689264
Validation R2 logP = 0.758554
Epoch 41
Train function
Loss = 1.2457e-04, PNorm = 62.9679, GNorm = 0.7694, lr_0 = 3.9208e-04
Loss = 1.3411e-04, PNorm = 62.9776, GNorm = 0.2522, lr_0 = 3.9035e-04
Loss = 1.4215e-04, PNorm = 62.9874, GNorm = 0.2551, lr_0 = 3.8862e-04
Loss = 1.0095e-04, PNorm = 62.9963, GNorm = 0.2294, lr_0 = 3.8690e-04
Loss = 1.2713e-04, PNorm = 63.0052, GNorm = 0.1824, lr_0 = 3.8519e-04
Loss = 1.1534e-04, PNorm = 63.0134, GNorm = 0.2361, lr_0 = 3.8349e-04
Validation rmse logD = 0.620660
Validation R2 logD = 0.721478
Validation rmse logP = 0.686375
Validation R2 logP = 0.760574
Epoch 42
Train function
Loss = 1.0892e-04, PNorm = 63.0204, GNorm = 0.2380, lr_0 = 3.8179e-04
Loss = 1.0001e-04, PNorm = 63.0275, GNorm = 0.1698, lr_0 = 3.8010e-04
Loss = 9.2396e-05, PNorm = 63.0308, GNorm = 0.4208, lr_0 = 3.7842e-04
Loss = 1.1813e-04, PNorm = 63.0370, GNorm = 0.5627, lr_0 = 3.7675e-04
Loss = 1.4453e-04, PNorm = 63.0456, GNorm = 0.8332, lr_0 = 3.7508e-04
Validation rmse logD = 0.621511
Validation R2 logD = 0.720714
Validation rmse logP = 0.690296
Validation R2 logP = 0.757831
Epoch 43
Train function
Loss = 1.5709e-04, PNorm = 63.0552, GNorm = 0.3201, lr_0 = 3.7326e-04
Loss = 1.2122e-04, PNorm = 63.0655, GNorm = 0.3257, lr_0 = 3.7160e-04
Loss = 1.3772e-04, PNorm = 63.0732, GNorm = 0.3333, lr_0 = 3.6996e-04
Loss = 1.2013e-04, PNorm = 63.0825, GNorm = 0.2028, lr_0 = 3.6832e-04
Loss = 9.7970e-05, PNorm = 63.0904, GNorm = 0.2421, lr_0 = 3.6669e-04
Validation rmse logD = 0.615485
Validation R2 logD = 0.726104
Validation rmse logP = 0.685749
Validation R2 logP = 0.761011
Epoch 44
Train function
Loss = 7.2771e-05, PNorm = 63.0965, GNorm = 0.1905, lr_0 = 3.6491e-04
Loss = 9.0086e-05, PNorm = 63.1016, GNorm = 0.1141, lr_0 = 3.6330e-04
Loss = 8.6063e-05, PNorm = 63.1054, GNorm = 0.3364, lr_0 = 3.6169e-04
Loss = 8.0303e-05, PNorm = 63.1130, GNorm = 0.1954, lr_0 = 3.6009e-04
Loss = 1.0084e-04, PNorm = 63.1202, GNorm = 0.2409, lr_0 = 3.5850e-04
Loss = 1.0013e-04, PNorm = 63.1259, GNorm = 0.3002, lr_0 = 3.5691e-04
Loss = 1.2329e-03, PNorm = 63.1270, GNorm = 0.6095, lr_0 = 3.5675e-04
Validation rmse logD = 0.615016
Validation R2 logD = 0.726520
Validation rmse logP = 0.684586
Validation R2 logP = 0.761821
Epoch 45
Train function
Loss = 8.0510e-05, PNorm = 63.1340, GNorm = 0.1695, lr_0 = 3.5518e-04
Loss = 8.3680e-05, PNorm = 63.1411, GNorm = 0.1111, lr_0 = 3.5360e-04
Loss = 1.0437e-04, PNorm = 63.1486, GNorm = 0.5080, lr_0 = 3.5204e-04
Loss = 8.1980e-05, PNorm = 63.1554, GNorm = 0.2792, lr_0 = 3.5048e-04
Loss = 8.6314e-05, PNorm = 63.1621, GNorm = 0.3028, lr_0 = 3.4893e-04
Validation rmse logD = 0.618386
Validation R2 logD = 0.723515
Validation rmse logP = 0.686125
Validation R2 logP = 0.760748
Epoch 46
Train function
Loss = 7.3929e-05, PNorm = 63.1672, GNorm = 0.2441, lr_0 = 3.4724e-04
Loss = 6.2726e-05, PNorm = 63.1713, GNorm = 0.2204, lr_0 = 3.4570e-04
Loss = 8.2906e-05, PNorm = 63.1752, GNorm = 0.3563, lr_0 = 3.4417e-04
Loss = 9.7486e-05, PNorm = 63.1817, GNorm = 0.3513, lr_0 = 3.4265e-04
Loss = 1.2685e-04, PNorm = 63.1899, GNorm = 0.3837, lr_0 = 3.4113e-04
Validation rmse logD = 0.620755
Validation R2 logD = 0.721393
Validation rmse logP = 0.685776
Validation R2 logP = 0.760992
Epoch 47
Train function
Loss = 1.0742e-04, PNorm = 63.1989, GNorm = 0.4337, lr_0 = 3.3947e-04
Loss = 8.8757e-05, PNorm = 63.2031, GNorm = 0.1647, lr_0 = 3.3797e-04
Loss = 1.0188e-04, PNorm = 63.2091, GNorm = 0.5331, lr_0 = 3.3648e-04
Loss = 8.6356e-05, PNorm = 63.2143, GNorm = 0.1854, lr_0 = 3.3499e-04
Loss = 8.7003e-05, PNorm = 63.2223, GNorm = 0.2643, lr_0 = 3.3351e-04
Validation rmse logD = 0.614445
Validation R2 logD = 0.727028
Validation rmse logP = 0.683160
Validation R2 logP = 0.762812
Epoch 48
Train function
Loss = 8.6733e-05, PNorm = 63.2307, GNorm = 0.2457, lr_0 = 3.3188e-04
Loss = 6.9403e-05, PNorm = 63.2368, GNorm = 0.1997, lr_0 = 3.3042e-04
Loss = 8.8324e-05, PNorm = 63.2428, GNorm = 0.1748, lr_0 = 3.2895e-04
Loss = 1.0386e-04, PNorm = 63.2497, GNorm = 0.2000, lr_0 = 3.2750e-04
Loss = 8.1024e-05, PNorm = 63.2542, GNorm = 0.1553, lr_0 = 3.2605e-04
Loss = 8.8059e-05, PNorm = 63.2577, GNorm = 0.1476, lr_0 = 3.2461e-04
Validation rmse logD = 0.612505
Validation R2 logD = 0.728749
Validation rmse logP = 0.689558
Validation R2 logP = 0.758348
Epoch 49
Train function
Loss = 6.0179e-05, PNorm = 63.2648, GNorm = 0.1539, lr_0 = 3.2303e-04
Loss = 8.9734e-05, PNorm = 63.2717, GNorm = 0.1035, lr_0 = 3.2160e-04
Loss = 5.3337e-05, PNorm = 63.2787, GNorm = 0.1420, lr_0 = 3.2018e-04
Loss = 6.5898e-05, PNorm = 63.2829, GNorm = 0.1796, lr_0 = 3.1876e-04
Loss = 7.0383e-05, PNorm = 63.2876, GNorm = 0.1793, lr_0 = 3.1735e-04
Validation rmse logD = 0.621457
Validation R2 logD = 0.720762
Validation rmse logP = 0.690227
Validation R2 logP = 0.757879
Epoch 50
Train function
Loss = 5.6554e-05, PNorm = 63.2907, GNorm = 0.1542, lr_0 = 3.1595e-04
Loss = 7.0830e-05, PNorm = 63.2940, GNorm = 0.1774, lr_0 = 3.1455e-04
Loss = 6.2468e-05, PNorm = 63.2988, GNorm = 0.1001, lr_0 = 3.1316e-04
Loss = 5.0515e-05, PNorm = 63.3037, GNorm = 0.1238, lr_0 = 3.1177e-04
Loss = 6.2030e-05, PNorm = 63.3102, GNorm = 0.1278, lr_0 = 3.1039e-04
Validation rmse logD = 0.615883
Validation R2 logD = 0.725749
Validation rmse logP = 0.684801
Validation R2 logP = 0.761671
Epoch 51
Train function
Loss = 5.1173e-05, PNorm = 63.3171, GNorm = 0.2375, lr_0 = 3.0888e-04
Loss = 6.8377e-05, PNorm = 63.3257, GNorm = 0.1470, lr_0 = 3.0752e-04
Loss = 6.4678e-05, PNorm = 63.3331, GNorm = 0.2138, lr_0 = 3.0616e-04
Loss = 7.7200e-05, PNorm = 63.3374, GNorm = 0.3528, lr_0 = 3.0480e-04
Loss = 8.5858e-05, PNorm = 63.3395, GNorm = 0.1599, lr_0 = 3.0346e-04
Loss = 8.6483e-05, PNorm = 63.3443, GNorm = 0.2214, lr_0 = 3.0211e-04
Validation rmse logD = 0.613838
Validation R2 logD = 0.727567
Validation rmse logP = 0.685612
Validation R2 logP = 0.761106
Epoch 52
Train function
Loss = 5.7353e-05, PNorm = 63.3508, GNorm = 0.2279, lr_0 = 3.0064e-04
Loss = 6.7451e-05, PNorm = 63.3561, GNorm = 0.4390, lr_0 = 2.9931e-04
Loss = 4.6440e-05, PNorm = 63.3600, GNorm = 0.2957, lr_0 = 2.9799e-04
Loss = 5.5327e-05, PNorm = 63.3646, GNorm = 0.2335, lr_0 = 2.9667e-04
Loss = 4.7441e-05, PNorm = 63.3686, GNorm = 0.2782, lr_0 = 2.9536e-04
Validation rmse logD = 0.614229
Validation R2 logD = 0.727220
Validation rmse logP = 0.685476
Validation R2 logP = 0.761201
Epoch 53
Train function
Loss = 5.5864e-05, PNorm = 63.3717, GNorm = 0.4321, lr_0 = 2.9392e-04
Loss = 3.4863e-05, PNorm = 63.3752, GNorm = 0.2707, lr_0 = 2.9262e-04
Loss = 5.1576e-05, PNorm = 63.3782, GNorm = 0.2726, lr_0 = 2.9133e-04
Loss = 4.8271e-05, PNorm = 63.3819, GNorm = 0.1447, lr_0 = 2.9004e-04
Loss = 4.7108e-05, PNorm = 63.3855, GNorm = 0.2170, lr_0 = 2.8876e-04
Validation rmse logD = 0.619166
Validation R2 logD = 0.722818
Validation rmse logP = 0.686764
Validation R2 logP = 0.760302
Epoch 54
Train function
Loss = 5.4241e-05, PNorm = 63.3910, GNorm = 0.4742, lr_0 = 2.8735e-04
Loss = 5.2048e-05, PNorm = 63.3938, GNorm = 0.3047, lr_0 = 2.8608e-04
Loss = 4.6527e-05, PNorm = 63.3954, GNorm = 0.4183, lr_0 = 2.8482e-04
Loss = 4.3052e-05, PNorm = 63.3998, GNorm = 0.1503, lr_0 = 2.8356e-04
Loss = 3.5024e-05, PNorm = 63.4033, GNorm = 0.2030, lr_0 = 2.8230e-04
Loss = 4.7929e-05, PNorm = 63.4073, GNorm = 0.1483, lr_0 = 2.8105e-04
Validation rmse logD = 0.618373
Validation R2 logD = 0.723527
Validation rmse logP = 0.685478
Validation R2 logP = 0.761199
Epoch 55
Train function
Loss = 3.6004e-05, PNorm = 63.4106, GNorm = 0.1860, lr_0 = 2.7969e-04
Loss = 3.9767e-05, PNorm = 63.4133, GNorm = 0.1628, lr_0 = 2.7845e-04
Loss = 3.6667e-05, PNorm = 63.4166, GNorm = 0.4269, lr_0 = 2.7722e-04
Loss = 7.2050e-05, PNorm = 63.4201, GNorm = 0.1962, lr_0 = 2.7599e-04
Loss = 7.6528e-05, PNorm = 63.4285, GNorm = 0.1548, lr_0 = 2.7477e-04
Validation rmse logD = 0.617146
Validation R2 logD = 0.724623
Validation rmse logP = 0.683376
Validation R2 logP = 0.762662
Epoch 56
Train function
Loss = 5.9260e-05, PNorm = 63.4322, GNorm = 0.3475, lr_0 = 2.7343e-04
Loss = 6.3164e-05, PNorm = 63.4358, GNorm = 0.2915, lr_0 = 2.7222e-04
Loss = 4.2015e-05, PNorm = 63.4423, GNorm = 0.1092, lr_0 = 2.7102e-04
Loss = 3.7668e-05, PNorm = 63.4473, GNorm = 0.2060, lr_0 = 2.6982e-04
Loss = 4.4530e-05, PNorm = 63.4489, GNorm = 0.2093, lr_0 = 2.6863e-04
Validation rmse logD = 0.618412
Validation R2 logD = 0.723492
Validation rmse logP = 0.685619
Validation R2 logP = 0.761101
Epoch 57
Train function
Loss = 2.1889e-05, PNorm = 63.4515, GNorm = 0.0826, lr_0 = 2.6732e-04
Loss = 4.5671e-05, PNorm = 63.4531, GNorm = 0.2757, lr_0 = 2.6614e-04
Loss = 4.6330e-05, PNorm = 63.4555, GNorm = 0.0973, lr_0 = 2.6496e-04
Loss = 3.6740e-05, PNorm = 63.4604, GNorm = 0.1012, lr_0 = 2.6379e-04
Loss = 3.3647e-05, PNorm = 63.4638, GNorm = 0.0874, lr_0 = 2.6262e-04
Loss = 4.4858e-05, PNorm = 63.4666, GNorm = 0.3233, lr_0 = 2.6146e-04
Loss = 3.1078e-04, PNorm = 63.4664, GNorm = 0.5083, lr_0 = 2.6134e-04
Validation rmse logD = 0.621728
Validation R2 logD = 0.720519
Validation rmse logP = 0.683508
Validation R2 logP = 0.762570
Epoch 58
Train function
Loss = 5.3877e-05, PNorm = 63.4701, GNorm = 0.0867, lr_0 = 2.6019e-04
Loss = 3.8466e-05, PNorm = 63.4739, GNorm = 0.2110, lr_0 = 2.5904e-04
Loss = 3.7703e-05, PNorm = 63.4786, GNorm = 0.1853, lr_0 = 2.5789e-04
Loss = 4.0297e-05, PNorm = 63.4817, GNorm = 0.1787, lr_0 = 2.5675e-04
Loss = 3.8265e-05, PNorm = 63.4848, GNorm = 0.1378, lr_0 = 2.5561e-04
Validation rmse logD = 0.621726
Validation R2 logD = 0.720520
Validation rmse logP = 0.688038
Validation R2 logP = 0.759413
Epoch 59
Train function
Loss = 5.0570e-05, PNorm = 63.4872, GNorm = 0.1688, lr_0 = 2.5448e-04
Loss = 4.3311e-05, PNorm = 63.4896, GNorm = 0.2010, lr_0 = 2.5336e-04
Loss = 4.5061e-05, PNorm = 63.4936, GNorm = 0.4642, lr_0 = 2.5224e-04
Loss = 4.7954e-05, PNorm = 63.4969, GNorm = 0.3178, lr_0 = 2.5112e-04
Loss = 3.9074e-05, PNorm = 63.5018, GNorm = 0.1032, lr_0 = 2.5001e-04
Validation rmse logD = 0.621078
Validation R2 logD = 0.721103
Validation rmse logP = 0.683891
Validation R2 logP = 0.762304
Epoch 60
Train function
Loss = 4.2315e-05, PNorm = 63.5070, GNorm = 0.1202, lr_0 = 2.4879e-04
Loss = 4.2927e-05, PNorm = 63.5096, GNorm = 0.1453, lr_0 = 2.4769e-04
Loss = 3.9536e-05, PNorm = 63.5118, GNorm = 0.1218, lr_0 = 2.4660e-04
Loss = 3.4760e-05, PNorm = 63.5156, GNorm = 0.2039, lr_0 = 2.4551e-04
Loss = 3.4134e-05, PNorm = 63.5201, GNorm = 0.1894, lr_0 = 2.4442e-04
Loss = 3.7134e-05, PNorm = 63.5227, GNorm = 0.1868, lr_0 = 2.4334e-04
Loss = 1.2316e-04, PNorm = 63.5229, GNorm = 0.2961, lr_0 = 2.4323e-04
Validation rmse logD = 0.619732
Validation R2 logD = 0.722310
Validation rmse logP = 0.683085
Validation R2 logP = 0.762864
Epoch 61
Train function
Loss = 2.5662e-05, PNorm = 63.5254, GNorm = 0.1289, lr_0 = 2.4216e-04
Loss = 3.2048e-05, PNorm = 63.5278, GNorm = 0.0865, lr_0 = 2.4109e-04
Loss = 2.9023e-05, PNorm = 63.5311, GNorm = 0.1063, lr_0 = 2.4002e-04
Loss = 2.5912e-05, PNorm = 63.5336, GNorm = 0.1644, lr_0 = 2.3896e-04
Loss = 2.7855e-05, PNorm = 63.5352, GNorm = 0.1352, lr_0 = 2.3790e-04
Validation rmse logD = 0.616576
Validation R2 logD = 0.725132
Validation rmse logP = 0.684945
Validation R2 logP = 0.761571
Epoch 62
Train function
Loss = 2.7346e-05, PNorm = 63.5374, GNorm = 0.0776, lr_0 = 2.3674e-04
Loss = 2.2151e-05, PNorm = 63.5383, GNorm = 0.0917, lr_0 = 2.3570e-04
Loss = 2.2669e-05, PNorm = 63.5405, GNorm = 0.0809, lr_0 = 2.3465e-04
Loss = 2.7931e-05, PNorm = 63.5434, GNorm = 0.1267, lr_0 = 2.3362e-04
Loss = 2.5979e-05, PNorm = 63.5459, GNorm = 0.1287, lr_0 = 2.3258e-04
Validation rmse logD = 0.617916
Validation R2 logD = 0.723935
Validation rmse logP = 0.683961
Validation R2 logP = 0.762255
Epoch 63
Train function
Loss = 2.6726e-05, PNorm = 63.5494, GNorm = 0.2133, lr_0 = 2.3145e-04
Loss = 3.1201e-05, PNorm = 63.5522, GNorm = 0.1068, lr_0 = 2.3043e-04
Loss = 3.3499e-05, PNorm = 63.5554, GNorm = 0.1620, lr_0 = 2.2941e-04
Loss = 2.7853e-05, PNorm = 63.5583, GNorm = 0.1701, lr_0 = 2.2839e-04
Loss = 2.7294e-05, PNorm = 63.5623, GNorm = 0.1951, lr_0 = 2.2738e-04
Validation rmse logD = 0.620975
Validation R2 logD = 0.721196
Validation rmse logP = 0.683836
Validation R2 logP = 0.762342
Epoch 64
Train function
Loss = 4.9264e-05, PNorm = 63.5647, GNorm = 0.4688, lr_0 = 2.2628e-04
Loss = 3.7958e-05, PNorm = 63.5683, GNorm = 0.3653, lr_0 = 2.2528e-04
Loss = 4.1562e-05, PNorm = 63.5711, GNorm = 0.3084, lr_0 = 2.2428e-04
Loss = 3.3638e-05, PNorm = 63.5740, GNorm = 0.1688, lr_0 = 2.2329e-04
Loss = 3.3254e-05, PNorm = 63.5764, GNorm = 0.1851, lr_0 = 2.2230e-04
Loss = 2.9109e-05, PNorm = 63.5798, GNorm = 0.2800, lr_0 = 2.2132e-04
Validation rmse logD = 0.617945
Validation R2 logD = 0.723909
Validation rmse logP = 0.683007
Validation R2 logP = 0.762918
Epoch 65
Train function
Loss = 3.1580e-05, PNorm = 63.5823, GNorm = 0.2777, lr_0 = 2.2024e-04
Loss = 3.2067e-05, PNorm = 63.5866, GNorm = 0.1638, lr_0 = 2.1927e-04
Loss = 2.5962e-05, PNorm = 63.5894, GNorm = 0.1714, lr_0 = 2.1830e-04
Loss = 2.5432e-05, PNorm = 63.5902, GNorm = 0.1546, lr_0 = 2.1733e-04
Loss = 2.7555e-05, PNorm = 63.5917, GNorm = 0.1101, lr_0 = 2.1637e-04
Validation rmse logD = 0.615734
Validation R2 logD = 0.725881
Validation rmse logP = 0.686049
Validation R2 logP = 0.760802
Epoch 66
Train function
Loss = 2.1947e-05, PNorm = 63.5952, GNorm = 0.1397, lr_0 = 2.1532e-04
Loss = 2.9266e-05, PNorm = 63.5973, GNorm = 0.1886, lr_0 = 2.1436e-04
Loss = 2.9936e-05, PNorm = 63.5990, GNorm = 0.2459, lr_0 = 2.1342e-04
Loss = 2.3909e-05, PNorm = 63.6011, GNorm = 0.0970, lr_0 = 2.1247e-04
Loss = 1.7733e-05, PNorm = 63.6033, GNorm = 0.0613, lr_0 = 2.1153e-04
Validation rmse logD = 0.617371
Validation R2 logD = 0.724422
Validation rmse logP = 0.680635
Validation R2 logP = 0.764562
Epoch 67
Train function
Loss = 1.9916e-05, PNorm = 63.6051, GNorm = 0.1697, lr_0 = 2.1060e-04
Loss = 2.2802e-05, PNorm = 63.6074, GNorm = 0.0946, lr_0 = 2.0966e-04
Loss = 1.7020e-05, PNorm = 63.6093, GNorm = 0.0651, lr_0 = 2.0874e-04
Loss = 2.0548e-05, PNorm = 63.6121, GNorm = 0.0735, lr_0 = 2.0781e-04
Loss = 2.6897e-05, PNorm = 63.6150, GNorm = 0.2095, lr_0 = 2.0689e-04
Loss = 2.8938e-05, PNorm = 63.6179, GNorm = 0.3016, lr_0 = 2.0598e-04
Validation rmse logD = 0.621804
Validation R2 logD = 0.720451
Validation rmse logP = 0.681553
Validation R2 logP = 0.763927
Epoch 68
Train function
Loss = 3.7664e-05, PNorm = 63.6208, GNorm = 0.4048, lr_0 = 2.0498e-04
Loss = 2.3463e-05, PNorm = 63.6229, GNorm = 0.0666, lr_0 = 2.0407e-04
Loss = 1.8857e-05, PNorm = 63.6251, GNorm = 0.0764, lr_0 = 2.0317e-04
Loss = 1.7085e-05, PNorm = 63.6268, GNorm = 0.0655, lr_0 = 2.0227e-04
Loss = 2.0827e-05, PNorm = 63.6278, GNorm = 0.1566, lr_0 = 2.0137e-04
Validation rmse logD = 0.616676
Validation R2 logD = 0.725042
Validation rmse logP = 0.685032
Validation R2 logP = 0.761510
Epoch 69
Train function
Loss = 3.0669e-05, PNorm = 63.6310, GNorm = 0.1440, lr_0 = 2.0039e-04
Loss = 2.6443e-05, PNorm = 63.6329, GNorm = 0.0932, lr_0 = 1.9951e-04
Loss = 2.2606e-05, PNorm = 63.6358, GNorm = 0.1841, lr_0 = 1.9863e-04
Loss = 2.3868e-05, PNorm = 63.6369, GNorm = 0.2193, lr_0 = 1.9775e-04
Loss = 1.7114e-05, PNorm = 63.6381, GNorm = 0.0626, lr_0 = 1.9687e-04
Validation rmse logD = 0.616166
Validation R2 logD = 0.725497
Validation rmse logP = 0.680737
Validation R2 logP = 0.764492
Epoch 70
Train function
Loss = 1.3974e-05, PNorm = 63.6409, GNorm = 0.0944, lr_0 = 1.9592e-04
Loss = 1.8177e-05, PNorm = 63.6423, GNorm = 0.0683, lr_0 = 1.9505e-04
Loss = 1.8395e-05, PNorm = 63.6428, GNorm = 0.0849, lr_0 = 1.9419e-04
Loss = 2.2380e-05, PNorm = 63.6450, GNorm = 0.1429, lr_0 = 1.9333e-04
Loss = 2.5923e-05, PNorm = 63.6474, GNorm = 0.1074, lr_0 = 1.9247e-04
Loss = 2.9919e-05, PNorm = 63.6510, GNorm = 0.0810, lr_0 = 1.9162e-04
Validation rmse logD = 0.618326
Validation R2 logD = 0.723569
Validation rmse logP = 0.680253
Validation R2 logP = 0.764826
Epoch 71
Train function
Loss = 2.5402e-05, PNorm = 63.6536, GNorm = 0.3405, lr_0 = 1.9069e-04
Loss = 2.3705e-05, PNorm = 63.6561, GNorm = 0.0746, lr_0 = 1.8984e-04
Loss = 1.9190e-05, PNorm = 63.6579, GNorm = 0.0712, lr_0 = 1.8900e-04
Loss = 1.6164e-05, PNorm = 63.6594, GNorm = 0.2005, lr_0 = 1.8817e-04
Loss = 2.2217e-05, PNorm = 63.6616, GNorm = 0.0675, lr_0 = 1.8734e-04
Validation rmse logD = 0.616685
Validation R2 logD = 0.725034
Validation rmse logP = 0.684363
Validation R2 logP = 0.761975
Epoch 72
Train function
Loss = 2.9650e-05, PNorm = 63.6621, GNorm = 0.1385, lr_0 = 1.8643e-04
Loss = 3.8646e-05, PNorm = 63.6652, GNorm = 0.0896, lr_0 = 1.8560e-04
Loss = 1.0236e-04, PNorm = 63.6667, GNorm = 0.4364, lr_0 = 1.8478e-04
Loss = 3.9355e-05, PNorm = 63.6720, GNorm = 0.1216, lr_0 = 1.8396e-04
Loss = 3.0927e-05, PNorm = 63.6764, GNorm = 0.1215, lr_0 = 1.8315e-04
Validation rmse logD = 0.617077
Validation R2 logD = 0.724685
Validation rmse logP = 0.682102
Validation R2 logP = 0.763546
Epoch 73
Train function
Loss = 2.4282e-05, PNorm = 63.6806, GNorm = 0.2915, lr_0 = 1.8226e-04
Loss = 3.0758e-05, PNorm = 63.6829, GNorm = 0.1477, lr_0 = 1.8145e-04
Loss = 2.7097e-05, PNorm = 63.6851, GNorm = 0.0973, lr_0 = 1.8065e-04
Loss = 2.0038e-05, PNorm = 63.6875, GNorm = 0.0788, lr_0 = 1.7985e-04
Loss = 2.7137e-05, PNorm = 63.6893, GNorm = 0.1989, lr_0 = 1.7905e-04
Loss = 2.3199e-05, PNorm = 63.6915, GNorm = 0.1592, lr_0 = 1.7826e-04
Loss = 3.3344e-04, PNorm = 63.6917, GNorm = 0.5189, lr_0 = 1.7818e-04
Validation rmse logD = 0.618234
Validation R2 logD = 0.723651
Validation rmse logP = 0.686450
Validation R2 logP = 0.760522
Epoch 74
Train function
Loss = 2.5964e-05, PNorm = 63.6924, GNorm = 0.2062, lr_0 = 1.7739e-04
Loss = 3.2990e-05, PNorm = 63.6928, GNorm = 0.1783, lr_0 = 1.7661e-04
Loss = 4.6085e-05, PNorm = 63.6940, GNorm = 0.1276, lr_0 = 1.7583e-04
Loss = 2.8458e-05, PNorm = 63.6966, GNorm = 0.2235, lr_0 = 1.7505e-04
Loss = 2.4992e-05, PNorm = 63.7010, GNorm = 0.2502, lr_0 = 1.7428e-04
Validation rmse logD = 0.619187
Validation R2 logD = 0.722799
Validation rmse logP = 0.683388
Validation R2 logP = 0.762653
Epoch 75
Train function
Loss = 4.3027e-05, PNorm = 63.7038, GNorm = 0.3253, lr_0 = 1.7351e-04
Loss = 3.3891e-05, PNorm = 63.7057, GNorm = 0.2183, lr_0 = 1.7274e-04
Loss = 3.8238e-05, PNorm = 63.7067, GNorm = 0.1015, lr_0 = 1.7197e-04
Loss = 2.3806e-05, PNorm = 63.7106, GNorm = 0.1519, lr_0 = 1.7121e-04
Loss = 2.3961e-05, PNorm = 63.7129, GNorm = 0.1804, lr_0 = 1.7046e-04
Validation rmse logD = 0.618987
Validation R2 logD = 0.722977
Validation rmse logP = 0.682735
Validation R2 logP = 0.763107
Epoch 76
Train function
Loss = 2.4070e-05, PNorm = 63.7154, GNorm = 0.1170, lr_0 = 1.6963e-04
Loss = 2.2943e-05, PNorm = 63.7166, GNorm = 0.1179, lr_0 = 1.6888e-04
Loss = 1.8588e-05, PNorm = 63.7181, GNorm = 0.1029, lr_0 = 1.6813e-04
Loss = 1.8843e-05, PNorm = 63.7186, GNorm = 0.2141, lr_0 = 1.6739e-04
Loss = 2.0134e-05, PNorm = 63.7204, GNorm = 0.1047, lr_0 = 1.6665e-04
Loss = 1.9238e-05, PNorm = 63.7229, GNorm = 0.0724, lr_0 = 1.6591e-04
Loss = 1.0007e-04, PNorm = 63.7231, GNorm = 0.1768, lr_0 = 1.6584e-04
Validation rmse logD = 0.618420
Validation R2 logD = 0.723485
Validation rmse logP = 0.684446
Validation R2 logP = 0.761918
Epoch 77
Train function
Loss = 1.5477e-05, PNorm = 63.7244, GNorm = 0.2184, lr_0 = 1.6510e-04
Loss = 1.7267e-05, PNorm = 63.7263, GNorm = 0.2149, lr_0 = 1.6437e-04
Loss = 1.9198e-05, PNorm = 63.7276, GNorm = 0.3014, lr_0 = 1.6364e-04
Loss = 1.8858e-05, PNorm = 63.7294, GNorm = 0.0807, lr_0 = 1.6292e-04
Loss = 1.7158e-05, PNorm = 63.7309, GNorm = 0.0946, lr_0 = 1.6220e-04
Validation rmse logD = 0.616985
Validation R2 logD = 0.724766
Validation rmse logP = 0.685742
Validation R2 logP = 0.761015
Epoch 78
Train function
Loss = 1.7365e-05, PNorm = 63.7332, GNorm = 0.1651, lr_0 = 1.6141e-04
Loss = 1.2187e-05, PNorm = 63.7343, GNorm = 0.1194, lr_0 = 1.6070e-04
Loss = 1.2617e-05, PNorm = 63.7351, GNorm = 0.0474, lr_0 = 1.5999e-04
Loss = 1.3828e-05, PNorm = 63.7364, GNorm = 0.0685, lr_0 = 1.5928e-04
Loss = 1.4506e-05, PNorm = 63.7371, GNorm = 0.0645, lr_0 = 1.5857e-04
Validation rmse logD = 0.616252
Validation R2 logD = 0.725420
Validation rmse logP = 0.682479
Validation R2 logP = 0.763285
Epoch 79
Train function
Loss = 1.0471e-05, PNorm = 63.7384, GNorm = 0.0897, lr_0 = 1.5780e-04
Loss = 1.1653e-05, PNorm = 63.7406, GNorm = 0.0964, lr_0 = 1.5710e-04
Loss = 1.1830e-05, PNorm = 63.7411, GNorm = 0.1597, lr_0 = 1.5641e-04
Loss = 1.4819e-05, PNorm = 63.7414, GNorm = 0.1844, lr_0 = 1.5572e-04
Loss = 1.2301e-05, PNorm = 63.7423, GNorm = 0.0499, lr_0 = 1.5503e-04
Validation rmse logD = 0.616716
Validation R2 logD = 0.725006
Validation rmse logP = 0.683594
Validation R2 logP = 0.762510
Epoch 80
Train function
Loss = 1.5091e-05, PNorm = 63.7437, GNorm = 0.1673, lr_0 = 1.5427e-04
Loss = 1.1832e-05, PNorm = 63.7454, GNorm = 0.0443, lr_0 = 1.5359e-04
Loss = 9.8211e-06, PNorm = 63.7462, GNorm = 0.0626, lr_0 = 1.5291e-04
Loss = 8.0694e-06, PNorm = 63.7468, GNorm = 0.0858, lr_0 = 1.5224e-04
Loss = 9.0889e-06, PNorm = 63.7483, GNorm = 0.0913, lr_0 = 1.5156e-04
Loss = 1.1456e-05, PNorm = 63.7501, GNorm = 0.0800, lr_0 = 1.5089e-04
Validation rmse logD = 0.619460
Validation R2 logD = 0.722554
Validation rmse logP = 0.683781
Validation R2 logP = 0.762381
Epoch 81
Train function
Loss = 7.3125e-06, PNorm = 63.7514, GNorm = 0.0560, lr_0 = 1.5016e-04
Loss = 8.3448e-06, PNorm = 63.7527, GNorm = 0.0647, lr_0 = 1.4949e-04
Loss = 8.4921e-06, PNorm = 63.7530, GNorm = 0.0553, lr_0 = 1.4883e-04
Loss = 8.0561e-06, PNorm = 63.7547, GNorm = 0.1018, lr_0 = 1.4817e-04
Loss = 9.2923e-06, PNorm = 63.7553, GNorm = 0.0630, lr_0 = 1.4752e-04
Validation rmse logD = 0.617925
Validation R2 logD = 0.723928
Validation rmse logP = 0.684733
Validation R2 logP = 0.761719
Epoch 82
Train function
Loss = 8.8826e-06, PNorm = 63.7568, GNorm = 0.0730, lr_0 = 1.4680e-04
Loss = 9.1869e-06, PNorm = 63.7570, GNorm = 0.0706, lr_0 = 1.4615e-04
Loss = 9.5819e-06, PNorm = 63.7586, GNorm = 0.0736, lr_0 = 1.4551e-04
Loss = 1.0322e-05, PNorm = 63.7590, GNorm = 0.0530, lr_0 = 1.4486e-04
Loss = 8.8380e-06, PNorm = 63.7600, GNorm = 0.0692, lr_0 = 1.4422e-04
Validation rmse logD = 0.616480
Validation R2 logD = 0.725217
Validation rmse logP = 0.683339
Validation R2 logP = 0.762687
Epoch 83
Train function
Loss = 9.2466e-06, PNorm = 63.7614, GNorm = 0.0742, lr_0 = 1.4352e-04
Loss = 8.9545e-06, PNorm = 63.7621, GNorm = 0.0642, lr_0 = 1.4288e-04
Loss = 9.2898e-06, PNorm = 63.7634, GNorm = 0.0474, lr_0 = 1.4225e-04
Loss = 7.8713e-06, PNorm = 63.7645, GNorm = 0.0479, lr_0 = 1.4162e-04
Loss = 1.0045e-05, PNorm = 63.7656, GNorm = 0.0462, lr_0 = 1.4100e-04
Loss = 9.4250e-06, PNorm = 63.7669, GNorm = 0.0875, lr_0 = 1.4037e-04
Validation rmse logD = 0.617683
Validation R2 logD = 0.724144
Validation rmse logP = 0.683704
Validation R2 logP = 0.762434
Epoch 84
Train function
Loss = 9.4163e-06, PNorm = 63.7680, GNorm = 0.1753, lr_0 = 1.3975e-04
Loss = 7.1419e-06, PNorm = 63.7685, GNorm = 0.0628, lr_0 = 1.3913e-04
Loss = 7.3530e-06, PNorm = 63.7687, GNorm = 0.0997, lr_0 = 1.3852e-04
Loss = 8.4642e-06, PNorm = 63.7700, GNorm = 0.0724, lr_0 = 1.3791e-04
Loss = 7.5700e-06, PNorm = 63.7710, GNorm = 0.0957, lr_0 = 1.3730e-04
Validation rmse logD = 0.617067
Validation R2 logD = 0.724693
Validation rmse logP = 0.684589
Validation R2 logP = 0.761818
Epoch 85
Train function
Loss = 5.7067e-06, PNorm = 63.7721, GNorm = 0.1160, lr_0 = 1.3663e-04
Loss = 6.6378e-06, PNorm = 63.7734, GNorm = 0.1219, lr_0 = 1.3602e-04
Loss = 6.0494e-06, PNorm = 63.7743, GNorm = 0.1558, lr_0 = 1.3542e-04
Loss = 5.9119e-06, PNorm = 63.7752, GNorm = 0.1459, lr_0 = 1.3482e-04
Loss = 8.5429e-06, PNorm = 63.7756, GNorm = 0.1713, lr_0 = 1.3423e-04
Validation rmse logD = 0.618009
Validation R2 logD = 0.723853
Validation rmse logP = 0.684336
Validation R2 logP = 0.761995
Epoch 86
Train function
Loss = 3.8624e-06, PNorm = 63.7766, GNorm = 0.0303, lr_0 = 1.3357e-04
Loss = 5.3250e-06, PNorm = 63.7776, GNorm = 0.0990, lr_0 = 1.3298e-04
Loss = 5.4964e-06, PNorm = 63.7784, GNorm = 0.0751, lr_0 = 1.3239e-04
Loss = 6.4967e-06, PNorm = 63.7787, GNorm = 0.0862, lr_0 = 1.3181e-04
Loss = 6.6690e-06, PNorm = 63.7795, GNorm = 0.0776, lr_0 = 1.3123e-04
Loss = 8.1545e-06, PNorm = 63.7801, GNorm = 0.0506, lr_0 = 1.3065e-04
Validation rmse logD = 0.617406
Validation R2 logD = 0.724391
Validation rmse logP = 0.684440
Validation R2 logP = 0.761922
Epoch 87
Train function
Loss = 5.3081e-06, PNorm = 63.7803, GNorm = 0.0541, lr_0 = 1.3001e-04
Loss = 6.6293e-06, PNorm = 63.7813, GNorm = 0.0975, lr_0 = 1.2944e-04
Loss = 6.2185e-06, PNorm = 63.7825, GNorm = 0.0349, lr_0 = 1.2886e-04
Loss = 7.5274e-06, PNorm = 63.7831, GNorm = 0.0876, lr_0 = 1.2829e-04
Loss = 6.3230e-06, PNorm = 63.7842, GNorm = 0.0883, lr_0 = 1.2773e-04
Validation rmse logD = 0.617727
Validation R2 logD = 0.724104
Validation rmse logP = 0.683179
Validation R2 logP = 0.762799
Epoch 88
Train function
Loss = 5.2872e-06, PNorm = 63.7851, GNorm = 0.1249, lr_0 = 1.2710e-04
Loss = 6.3146e-06, PNorm = 63.7858, GNorm = 0.0931, lr_0 = 1.2654e-04
Loss = 5.8472e-06, PNorm = 63.7862, GNorm = 0.1462, lr_0 = 1.2598e-04
Loss = 4.2982e-06, PNorm = 63.7863, GNorm = 0.0565, lr_0 = 1.2542e-04
Loss = 4.9022e-06, PNorm = 63.7871, GNorm = 0.0626, lr_0 = 1.2487e-04
Validation rmse logD = 0.617888
Validation R2 logD = 0.723961
Validation rmse logP = 0.683550
Validation R2 logP = 0.762541
Epoch 89
Train function
Loss = 4.9290e-06, PNorm = 63.7876, GNorm = 0.0535, lr_0 = 1.2426e-04
Loss = 8.8906e-06, PNorm = 63.7890, GNorm = 0.0553, lr_0 = 1.2371e-04
Loss = 7.7077e-06, PNorm = 63.7905, GNorm = 0.1825, lr_0 = 1.2317e-04
Loss = 7.6255e-06, PNorm = 63.7915, GNorm = 0.1246, lr_0 = 1.2262e-04
Loss = 5.0619e-06, PNorm = 63.7923, GNorm = 0.0537, lr_0 = 1.2208e-04
Loss = 7.1478e-06, PNorm = 63.7930, GNorm = 0.0967, lr_0 = 1.2154e-04
Loss = 3.5488e-05, PNorm = 63.7930, GNorm = 0.1782, lr_0 = 1.2148e-04
Validation rmse logD = 0.617352
Validation R2 logD = 0.724439
Validation rmse logP = 0.683450
Validation R2 logP = 0.762610
Epoch 90
Train function
Loss = 7.1946e-06, PNorm = 63.7935, GNorm = 0.1109, lr_0 = 1.2095e-04
Loss = 6.0951e-06, PNorm = 63.7935, GNorm = 0.0329, lr_0 = 1.2041e-04
Loss = 5.2730e-06, PNorm = 63.7946, GNorm = 0.1038, lr_0 = 1.1988e-04
Loss = 6.4608e-06, PNorm = 63.7960, GNorm = 0.0702, lr_0 = 1.1935e-04
Loss = 4.9547e-06, PNorm = 63.7965, GNorm = 0.0343, lr_0 = 1.1882e-04
Validation rmse logD = 0.619246
Validation R2 logD = 0.722746
Validation rmse logP = 0.684775
Validation R2 logP = 0.761689
Epoch 91
Train function
Loss = 5.4518e-06, PNorm = 63.7972, GNorm = 0.0368, lr_0 = 1.1824e-04
Loss = 4.6034e-06, PNorm = 63.7979, GNorm = 0.0375, lr_0 = 1.1772e-04
Loss = 4.6578e-06, PNorm = 63.7987, GNorm = 0.0635, lr_0 = 1.1720e-04
Loss = 4.5484e-06, PNorm = 63.7995, GNorm = 0.0431, lr_0 = 1.1668e-04
Loss = 4.9043e-06, PNorm = 63.8001, GNorm = 0.0787, lr_0 = 1.1616e-04
Validation rmse logD = 0.617727
Validation R2 logD = 0.724104
Validation rmse logP = 0.683641
Validation R2 logP = 0.762477
Epoch 92
Train function
Loss = 2.3389e-06, PNorm = 63.8004, GNorm = 0.0207, lr_0 = 1.1565e-04
Loss = 4.3896e-06, PNorm = 63.8008, GNorm = 0.0711, lr_0 = 1.1514e-04
Loss = 4.7862e-06, PNorm = 63.8015, GNorm = 0.0550, lr_0 = 1.1463e-04
Loss = 4.9705e-06, PNorm = 63.8027, GNorm = 0.0737, lr_0 = 1.1412e-04
Loss = 5.3676e-06, PNorm = 63.8031, GNorm = 0.0602, lr_0 = 1.1362e-04
Loss = 4.9440e-06, PNorm = 63.8037, GNorm = 0.0531, lr_0 = 1.1312e-04
Loss = 2.8065e-05, PNorm = 63.8037, GNorm = 0.1045, lr_0 = 1.1307e-04
Validation rmse logD = 0.618024
Validation R2 logD = 0.723839
Validation rmse logP = 0.683214
Validation R2 logP = 0.762774
Epoch 93
Train function
Loss = 4.0163e-06, PNorm = 63.8038, GNorm = 0.0405, lr_0 = 1.1257e-04
Loss = 4.1454e-06, PNorm = 63.8051, GNorm = 0.0315, lr_0 = 1.1207e-04
Loss = 4.1057e-06, PNorm = 63.8061, GNorm = 0.0450, lr_0 = 1.1157e-04
Loss = 4.5445e-06, PNorm = 63.8066, GNorm = 0.0602, lr_0 = 1.1108e-04
Loss = 4.6283e-06, PNorm = 63.8072, GNorm = 0.0345, lr_0 = 1.1059e-04
Validation rmse logD = 0.617753
Validation R2 logD = 0.724081
Validation rmse logP = 0.684172
Validation R2 logP = 0.762109
Epoch 94
Train function
Loss = 4.4733e-06, PNorm = 63.8086, GNorm = 0.0989, lr_0 = 1.1005e-04
Loss = 4.3621e-06, PNorm = 63.8093, GNorm = 0.0950, lr_0 = 1.0956e-04
Loss = 5.3606e-06, PNorm = 63.8100, GNorm = 0.0825, lr_0 = 1.0908e-04
Loss = 3.7825e-06, PNorm = 63.8104, GNorm = 0.0561, lr_0 = 1.0860e-04
Loss = 3.8949e-06, PNorm = 63.8105, GNorm = 0.0337, lr_0 = 1.0811e-04
Validation rmse logD = 0.617677
Validation R2 logD = 0.724149
Validation rmse logP = 0.683737
Validation R2 logP = 0.762411
Epoch 95
Train function
Loss = 3.1218e-06, PNorm = 63.8111, GNorm = 0.0531, lr_0 = 1.0759e-04
Loss = 3.7106e-06, PNorm = 63.8120, GNorm = 0.0356, lr_0 = 1.0711e-04
Loss = 4.1898e-06, PNorm = 63.8127, GNorm = 0.0421, lr_0 = 1.0664e-04
Loss = 3.1496e-06, PNorm = 63.8131, GNorm = 0.0315, lr_0 = 1.0617e-04
Loss = 4.4526e-06, PNorm = 63.8136, GNorm = 0.0472, lr_0 = 1.0570e-04
Validation rmse logD = 0.618835
Validation R2 logD = 0.723114
Validation rmse logP = 0.683229
Validation R2 logP = 0.762764
Epoch 96
Train function
Loss = 8.4638e-06, PNorm = 63.8140, GNorm = 0.2032, lr_0 = 1.0518e-04
Loss = 6.3658e-06, PNorm = 63.8141, GNorm = 0.1147, lr_0 = 1.0472e-04
Loss = 7.5172e-06, PNorm = 63.8144, GNorm = 0.0999, lr_0 = 1.0426e-04
Loss = 5.0093e-06, PNorm = 63.8154, GNorm = 0.0372, lr_0 = 1.0379e-04
Loss = 4.1736e-06, PNorm = 63.8169, GNorm = 0.0405, lr_0 = 1.0333e-04
Loss = 3.9560e-06, PNorm = 63.8176, GNorm = 0.0535, lr_0 = 1.0288e-04
Validation rmse logD = 0.618602
Validation R2 logD = 0.723323
Validation rmse logP = 0.683705
Validation R2 logP = 0.762433
Epoch 97
Train function
Loss = 4.6527e-06, PNorm = 63.8186, GNorm = 0.1017, lr_0 = 1.0238e-04
Loss = 3.7321e-06, PNorm = 63.8192, GNorm = 0.0765, lr_0 = 1.0192e-04
Loss = 5.1712e-06, PNorm = 63.8199, GNorm = 0.1022, lr_0 = 1.0147e-04
Loss = 4.0777e-06, PNorm = 63.8204, GNorm = 0.0717, lr_0 = 1.0102e-04
Loss = 5.1219e-06, PNorm = 63.8207, GNorm = 0.1121, lr_0 = 1.0058e-04
Validation rmse logD = 0.619561
Validation R2 logD = 0.722463
Validation rmse logP = 0.684618
Validation R2 logP = 0.761798
Epoch 98
Train function
Loss = 3.7120e-06, PNorm = 63.8213, GNorm = 0.0350, lr_0 = 1.0009e-04
Loss = 4.4292e-06, PNorm = 63.8216, GNorm = 0.0400, lr_0 = 1.0000e-04
Loss = 3.8272e-06, PNorm = 63.8219, GNorm = 0.0384, lr_0 = 1.0000e-04
Loss = 4.4678e-06, PNorm = 63.8223, GNorm = 0.0727, lr_0 = 1.0000e-04
Loss = 5.6025e-06, PNorm = 63.8227, GNorm = 0.1092, lr_0 = 1.0000e-04
Validation rmse logD = 0.618895
Validation R2 logD = 0.723060
Validation rmse logP = 0.684010
Validation R2 logP = 0.762221
Epoch 99
Train function
Loss = 3.8551e-06, PNorm = 63.8233, GNorm = 0.0608, lr_0 = 1.0000e-04
Loss = 3.1599e-06, PNorm = 63.8238, GNorm = 0.0429, lr_0 = 1.0000e-04
Loss = 3.5081e-06, PNorm = 63.8248, GNorm = 0.0692, lr_0 = 1.0000e-04
Loss = 3.2716e-06, PNorm = 63.8255, GNorm = 0.0818, lr_0 = 1.0000e-04
Loss = 4.1254e-06, PNorm = 63.8264, GNorm = 0.0843, lr_0 = 1.0000e-04
Loss = 3.7396e-06, PNorm = 63.8269, GNorm = 0.0398, lr_0 = 1.0000e-04
Validation rmse logD = 0.618470
Validation R2 logD = 0.723440
Validation rmse logP = 0.683056
Validation R2 logP = 0.762884
Model 0 best validation rmse = 0.644960 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.643972
Model 0 test R2 logD = 0.708747
Model 0 test rmse logP = 0.929262
Model 0 test R2 logP = 0.627124
Ensemble test rmse  logD= 0.643972
Ensemble test R2  logD= 0.708747
Ensemble test rmse  logP= 0.929262
Ensemble test R2  logP= 0.627124
4-fold cross validation
	Seed 0 ==> test rmse = 0.646069
	Seed 0 ==> test R2 = 0.773714
	Seed 1 ==> test rmse = 0.698348
	Seed 1 ==> test R2 = 0.731960
	Seed 2 ==> test rmse = 0.727677
	Seed 2 ==> test R2 = 0.712477
	Seed 3 ==> test rmse = 0.786617
	Seed 3 ==> test R2 = 0.667935
Overall val rmse logD= 0.580645 +/- 0.023619
Overall val R2 logD = 0.765385 +/- 0.021643
Overall test rmse logD = 0.623889 +/- 0.033799
Overall test R2 logD = 0.725827 +/- 0.028697
Overall val rmse logP= 0.652601 +/- 0.059344
Overall val R2 logP = 0.803033 +/- 0.028617
Overall test rmse logP = 0.805466 +/- 0.078169
Overall test R2 logP = 0.717217 +/- 0.056140
Elapsed time = 3:31:38
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 2.2128e-02, PNorm = 52.9411, GNorm = 7.2829, lr_0 = 1.9340e-04
Loss = 1.9542e-02, PNorm = 52.9488, GNorm = 3.2468, lr_0 = 2.7830e-04
Loss = 1.4041e-02, PNorm = 52.9619, GNorm = 1.0930, lr_0 = 3.6321e-04
Loss = 1.5038e-02, PNorm = 52.9789, GNorm = 2.2895, lr_0 = 4.4811e-04
Loss = 1.2285e-02, PNorm = 53.0029, GNorm = 5.3178, lr_0 = 5.3302e-04
Validation rmse logD = 0.990129
Validation R2 logD = 0.289393
Validation rmse logP = 1.095624
Validation R2 logP = 0.426726
Epoch 1
Train function
Loss = 1.2884e-02, PNorm = 53.0342, GNorm = 1.8385, lr_0 = 6.2642e-04
Loss = 1.1560e-02, PNorm = 53.0689, GNorm = 2.8666, lr_0 = 7.1132e-04
Loss = 1.0821e-02, PNorm = 53.1123, GNorm = 1.4010, lr_0 = 7.9623e-04
Loss = 1.0747e-02, PNorm = 53.1601, GNorm = 1.0007, lr_0 = 8.8113e-04
Loss = 1.1341e-02, PNorm = 53.2212, GNorm = 2.1322, lr_0 = 9.6604e-04
Validation rmse logD = 0.849954
Validation R2 logD = 0.476356
Validation rmse logP = 1.064377
Validation R2 logP = 0.458958
Epoch 2
Train function
Loss = 1.0710e-02, PNorm = 53.2932, GNorm = 4.1594, lr_0 = 9.9690e-04
Loss = 1.0108e-02, PNorm = 53.3656, GNorm = 3.8330, lr_0 = 9.9249e-04
Loss = 1.1699e-02, PNorm = 53.4426, GNorm = 1.1342, lr_0 = 9.8810e-04
Loss = 1.1444e-02, PNorm = 53.5287, GNorm = 3.5287, lr_0 = 9.8373e-04
Loss = 9.8095e-03, PNorm = 53.5920, GNorm = 3.0554, lr_0 = 9.7938e-04
Validation rmse logD = 0.844114
Validation R2 logD = 0.483527
Validation rmse logP = 0.976365
Validation R2 logP = 0.544736
Epoch 3
Train function
Loss = 8.7950e-03, PNorm = 53.6695, GNorm = 1.7021, lr_0 = 9.7462e-04
Loss = 1.0215e-02, PNorm = 53.7380, GNorm = 2.5189, lr_0 = 9.7030e-04
Loss = 8.8954e-03, PNorm = 53.8058, GNorm = 2.2069, lr_0 = 9.6601e-04
Loss = 8.5277e-03, PNorm = 53.8868, GNorm = 3.2633, lr_0 = 9.6174e-04
Loss = 7.5555e-03, PNorm = 53.9795, GNorm = 3.2609, lr_0 = 9.5749e-04
Loss = 7.0938e-03, PNorm = 54.0835, GNorm = 1.2478, lr_0 = 9.5325e-04
Validation rmse logD = 0.792038
Validation R2 logD = 0.545287
Validation rmse logP = 0.814369
Validation R2 logP = 0.683275
Epoch 4
Train function
Loss = 7.2644e-03, PNorm = 54.1799, GNorm = 0.9572, lr_0 = 9.4861e-04
Loss = 6.8930e-03, PNorm = 54.2936, GNorm = 2.7084, lr_0 = 9.4442e-04
Loss = 7.0872e-03, PNorm = 54.3899, GNorm = 4.6470, lr_0 = 9.4024e-04
Loss = 6.9411e-03, PNorm = 54.4819, GNorm = 1.6026, lr_0 = 9.3608e-04
Loss = 7.5115e-03, PNorm = 54.5582, GNorm = 1.0482, lr_0 = 9.3194e-04
Validation rmse logD = 1.218773
Validation R2 logD = -0.076690
Validation rmse logP = 1.002194
Validation R2 logP = 0.520330
Epoch 5
Train function
Loss = 9.6156e-03, PNorm = 54.6455, GNorm = 2.9817, lr_0 = 9.2741e-04
Loss = 7.5860e-03, PNorm = 54.7497, GNorm = 1.3626, lr_0 = 9.2330e-04
Loss = 6.8330e-03, PNorm = 54.8457, GNorm = 0.6872, lr_0 = 9.1922e-04
Loss = 6.8482e-03, PNorm = 54.9357, GNorm = 2.4341, lr_0 = 9.1515e-04
Loss = 5.1033e-03, PNorm = 55.0200, GNorm = 1.2190, lr_0 = 9.1111e-04
Validation rmse logD = 0.731310
Validation R2 logD = 0.612343
Validation rmse logP = 0.766522
Validation R2 logP = 0.719399
Epoch 6
Train function
Loss = 5.0088e-03, PNorm = 55.0981, GNorm = 1.2642, lr_0 = 9.0667e-04
Loss = 5.4050e-03, PNorm = 55.1829, GNorm = 1.7025, lr_0 = 9.0266e-04
Loss = 5.2783e-03, PNorm = 55.2676, GNorm = 1.1023, lr_0 = 8.9867e-04
Loss = 5.3852e-03, PNorm = 55.3484, GNorm = 0.9089, lr_0 = 8.9469e-04
Loss = 4.8600e-03, PNorm = 55.4293, GNorm = 1.2364, lr_0 = 8.9074e-04
Loss = 5.3646e-03, PNorm = 55.5161, GNorm = 0.6654, lr_0 = 8.8680e-04
Validation rmse logD = 0.702500
Validation R2 logD = 0.642284
Validation rmse logP = 0.740216
Validation R2 logP = 0.738328
Epoch 7
Train function
Loss = 4.4808e-03, PNorm = 55.5945, GNorm = 0.8606, lr_0 = 8.8248e-04
Loss = 4.2857e-03, PNorm = 55.6747, GNorm = 0.6296, lr_0 = 8.7858e-04
Loss = 4.6337e-03, PNorm = 55.7392, GNorm = 2.0411, lr_0 = 8.7469e-04
Loss = 5.1909e-03, PNorm = 55.8300, GNorm = 1.0171, lr_0 = 8.7082e-04
Loss = 5.3137e-03, PNorm = 55.9158, GNorm = 2.7518, lr_0 = 8.6697e-04
Validation rmse logD = 0.658710
Validation R2 logD = 0.685490
Validation rmse logP = 0.738679
Validation R2 logP = 0.739414
Epoch 8
Train function
Loss = 4.0037e-03, PNorm = 56.0042, GNorm = 2.3500, lr_0 = 8.6276e-04
Loss = 4.8386e-03, PNorm = 56.0844, GNorm = 0.7259, lr_0 = 8.5894e-04
Loss = 3.9943e-03, PNorm = 56.1764, GNorm = 0.7910, lr_0 = 8.5514e-04
Loss = 3.6355e-03, PNorm = 56.2499, GNorm = 0.7303, lr_0 = 8.5136e-04
Loss = 4.3252e-03, PNorm = 56.3226, GNorm = 3.2773, lr_0 = 8.4759e-04
Validation rmse logD = 0.683440
Validation R2 logD = 0.661432
Validation rmse logP = 0.751577
Validation R2 logP = 0.730234
Epoch 9
Train function
Loss = 3.8220e-03, PNorm = 56.4091, GNorm = 0.7754, lr_0 = 8.4347e-04
Loss = 3.9667e-03, PNorm = 56.4973, GNorm = 1.1088, lr_0 = 8.3974e-04
Loss = 3.4027e-03, PNorm = 56.5917, GNorm = 1.0543, lr_0 = 8.3602e-04
Loss = 3.4249e-03, PNorm = 56.6590, GNorm = 1.1289, lr_0 = 8.3232e-04
Loss = 3.9616e-03, PNorm = 56.7419, GNorm = 1.5381, lr_0 = 8.2864e-04
Loss = 3.6548e-03, PNorm = 56.8225, GNorm = 1.9756, lr_0 = 8.2498e-04
Validation rmse logD = 0.641717
Validation R2 logD = 0.701508
Validation rmse logP = 0.709325
Validation R2 logP = 0.759713
Epoch 10
Train function
Loss = 3.3629e-03, PNorm = 56.9086, GNorm = 1.0519, lr_0 = 8.2133e-04
Loss = 3.3357e-03, PNorm = 56.9966, GNorm = 1.1050, lr_0 = 8.1770e-04
Loss = 3.6834e-03, PNorm = 57.0736, GNorm = 2.6282, lr_0 = 8.1408e-04
Loss = 3.2711e-03, PNorm = 57.1427, GNorm = 2.0645, lr_0 = 8.1048e-04
Loss = 2.9907e-03, PNorm = 57.1989, GNorm = 1.0841, lr_0 = 8.0689e-04
Validation rmse logD = 0.611974
Validation R2 logD = 0.728537
Validation rmse logP = 0.731732
Validation R2 logP = 0.744292
Epoch 11
Train function
Loss = 3.1311e-03, PNorm = 57.2781, GNorm = 4.2435, lr_0 = 8.0297e-04
Loss = 2.8805e-03, PNorm = 57.3492, GNorm = 1.2311, lr_0 = 7.9942e-04
Loss = 2.9310e-03, PNorm = 57.4328, GNorm = 0.6931, lr_0 = 7.9588e-04
Loss = 2.7441e-03, PNorm = 57.5167, GNorm = 1.8866, lr_0 = 7.9236e-04
Loss = 2.9302e-03, PNorm = 57.5868, GNorm = 0.7563, lr_0 = 7.8885e-04
Validation rmse logD = 0.677762
Validation R2 logD = 0.667034
Validation rmse logP = 0.705312
Validation R2 logP = 0.762424
Epoch 12
Train function
Loss = 4.0833e-03, PNorm = 57.6582, GNorm = 3.1504, lr_0 = 7.8502e-04
Loss = 4.2335e-03, PNorm = 57.7578, GNorm = 3.9037, lr_0 = 7.8154e-04
Loss = 2.9551e-03, PNorm = 57.8411, GNorm = 1.9080, lr_0 = 7.7809e-04
Loss = 2.6506e-03, PNorm = 57.9153, GNorm = 0.8451, lr_0 = 7.7465e-04
Loss = 3.0784e-03, PNorm = 57.9807, GNorm = 3.0115, lr_0 = 7.7122e-04
Loss = 2.7075e-03, PNorm = 58.0437, GNorm = 0.6498, lr_0 = 7.6781e-04
Loss = 4.2479e-02, PNorm = 58.0489, GNorm = 4.9728, lr_0 = 7.6747e-04
Validation rmse logD = 0.763836
Validation R2 logD = 0.577093
Validation rmse logP = 0.739412
Validation R2 logP = 0.738896
Epoch 13
Train function
Loss = 3.6642e-03, PNorm = 58.1225, GNorm = 0.9885, lr_0 = 7.6407e-04
Loss = 2.5604e-03, PNorm = 58.2133, GNorm = 2.4057, lr_0 = 7.6069e-04
Loss = 2.6728e-03, PNorm = 58.2784, GNorm = 1.2666, lr_0 = 7.5733e-04
Loss = 2.4618e-03, PNorm = 58.3398, GNorm = 1.7767, lr_0 = 7.5398e-04
Loss = 2.3026e-03, PNorm = 58.3984, GNorm = 1.7895, lr_0 = 7.5064e-04
Validation rmse logD = 0.593660
Validation R2 logD = 0.744541
Validation rmse logP = 0.756052
Validation R2 logP = 0.727012
Epoch 14
Train function
Loss = 2.0622e-03, PNorm = 58.4494, GNorm = 0.7727, lr_0 = 7.4699e-04
Loss = 1.5602e-03, PNorm = 58.5120, GNorm = 0.3578, lr_0 = 7.4369e-04
Loss = 2.0048e-03, PNorm = 58.5573, GNorm = 1.3338, lr_0 = 7.4040e-04
Loss = 2.0354e-03, PNorm = 58.6100, GNorm = 1.3877, lr_0 = 7.3712e-04
Loss = 1.8205e-03, PNorm = 58.6691, GNorm = 1.5910, lr_0 = 7.3386e-04
Validation rmse logD = 0.601742
Validation R2 logD = 0.737538
Validation rmse logP = 0.734260
Validation R2 logP = 0.742523
Epoch 15
Train function
Loss = 2.2998e-03, PNorm = 58.7238, GNorm = 0.9022, lr_0 = 7.3029e-04
Loss = 1.5099e-03, PNorm = 58.7801, GNorm = 0.8227, lr_0 = 7.2706e-04
Loss = 1.5046e-03, PNorm = 58.8258, GNorm = 0.7061, lr_0 = 7.2385e-04
Loss = 1.6283e-03, PNorm = 58.8827, GNorm = 0.8388, lr_0 = 7.2064e-04
Loss = 1.7464e-03, PNorm = 58.9323, GNorm = 0.6820, lr_0 = 7.1746e-04
Validation rmse logD = 0.578862
Validation R2 logD = 0.757118
Validation rmse logP = 0.762100
Validation R2 logP = 0.722627
Epoch 16
Train function
Loss = 1.5140e-03, PNorm = 58.9915, GNorm = 0.6503, lr_0 = 7.1397e-04
Loss = 2.1318e-03, PNorm = 59.0547, GNorm = 1.1856, lr_0 = 7.1081e-04
Loss = 2.0391e-03, PNorm = 59.1216, GNorm = 1.9475, lr_0 = 7.0766e-04
Loss = 1.5707e-03, PNorm = 59.1763, GNorm = 1.1630, lr_0 = 7.0453e-04
Loss = 1.6407e-03, PNorm = 59.2254, GNorm = 0.6574, lr_0 = 7.0142e-04
Loss = 1.3815e-03, PNorm = 59.2762, GNorm = 0.6025, lr_0 = 6.9831e-04
Validation rmse logD = 0.579937
Validation R2 logD = 0.756215
Validation rmse logP = 0.748975
Validation R2 logP = 0.732099
Epoch 17
Train function
Loss = 9.8740e-04, PNorm = 59.3319, GNorm = 0.6307, lr_0 = 6.9492e-04
Loss = 1.1987e-03, PNorm = 59.3705, GNorm = 0.5911, lr_0 = 6.9184e-04
Loss = 1.3903e-03, PNorm = 59.4128, GNorm = 0.5636, lr_0 = 6.8878e-04
Loss = 1.3135e-03, PNorm = 59.4526, GNorm = 0.5722, lr_0 = 6.8574e-04
Loss = 1.1489e-03, PNorm = 59.4898, GNorm = 0.4252, lr_0 = 6.8270e-04
Validation rmse logD = 0.655289
Validation R2 logD = 0.688749
Validation rmse logP = 0.729928
Validation R2 logP = 0.745552
Epoch 18
Train function
Loss = 2.0716e-03, PNorm = 59.5449, GNorm = 2.9630, lr_0 = 6.7938e-04
Loss = 1.9908e-03, PNorm = 59.6195, GNorm = 2.0709, lr_0 = 6.7638e-04
Loss = 1.8471e-03, PNorm = 59.6932, GNorm = 1.2130, lr_0 = 6.7338e-04
Loss = 1.6543e-03, PNorm = 59.7548, GNorm = 2.0999, lr_0 = 6.7041e-04
Loss = 1.4710e-03, PNorm = 59.8082, GNorm = 1.8575, lr_0 = 6.6744e-04
Validation rmse logD = 0.592687
Validation R2 logD = 0.745378
Validation rmse logP = 0.728638
Validation R2 logP = 0.746450
Epoch 19
Train function
Loss = 9.7322e-04, PNorm = 59.8727, GNorm = 1.0568, lr_0 = 6.6419e-04
Loss = 1.1080e-03, PNorm = 59.9193, GNorm = 0.7477, lr_0 = 6.6126e-04
Loss = 1.2108e-03, PNorm = 59.9498, GNorm = 0.8174, lr_0 = 6.5833e-04
Loss = 1.0121e-03, PNorm = 59.9867, GNorm = 1.0563, lr_0 = 6.5542e-04
Loss = 1.1698e-03, PNorm = 60.0206, GNorm = 0.9112, lr_0 = 6.5252e-04
Loss = 1.2964e-03, PNorm = 60.0567, GNorm = 1.8395, lr_0 = 6.4963e-04
Validation rmse logD = 0.572619
Validation R2 logD = 0.762329
Validation rmse logP = 0.753871
Validation R2 logP = 0.728585
Epoch 20
Train function
Loss = 1.1399e-03, PNorm = 60.1080, GNorm = 0.6036, lr_0 = 6.4676e-04
Loss = 1.4732e-03, PNorm = 60.1541, GNorm = 0.8472, lr_0 = 6.4390e-04
Loss = 9.8775e-04, PNorm = 60.1916, GNorm = 0.4223, lr_0 = 6.4105e-04
Loss = 9.3807e-04, PNorm = 60.2296, GNorm = 0.3809, lr_0 = 6.3822e-04
Loss = 1.2788e-03, PNorm = 60.2715, GNorm = 0.8602, lr_0 = 6.3539e-04
Validation rmse logD = 0.587276
Validation R2 logD = 0.750006
Validation rmse logP = 0.718235
Validation R2 logP = 0.753639
Epoch 21
Train function
Loss = 8.5714e-04, PNorm = 60.3154, GNorm = 0.6266, lr_0 = 6.3230e-04
Loss = 8.3683e-04, PNorm = 60.3475, GNorm = 0.6181, lr_0 = 6.2950e-04
Loss = 8.2569e-04, PNorm = 60.3760, GNorm = 0.3669, lr_0 = 6.2672e-04
Loss = 7.6231e-04, PNorm = 60.4139, GNorm = 0.4448, lr_0 = 6.2395e-04
Loss = 9.0877e-04, PNorm = 60.4439, GNorm = 0.7812, lr_0 = 6.2119e-04
Validation rmse logD = 0.591291
Validation R2 logD = 0.746576
Validation rmse logP = 0.731625
Validation R2 logP = 0.744367
Epoch 22
Train function
Loss = 7.8564e-04, PNorm = 60.4789, GNorm = 0.4770, lr_0 = 6.1817e-04
Loss = 6.7798e-04, PNorm = 60.5120, GNorm = 0.5052, lr_0 = 6.1543e-04
Loss = 7.1034e-04, PNorm = 60.5369, GNorm = 0.4914, lr_0 = 6.1271e-04
Loss = 8.2984e-04, PNorm = 60.5690, GNorm = 0.5399, lr_0 = 6.1000e-04
Loss = 7.3055e-04, PNorm = 60.6025, GNorm = 0.4415, lr_0 = 6.0730e-04
Loss = 7.5224e-04, PNorm = 60.6327, GNorm = 0.3942, lr_0 = 6.0461e-04
Validation rmse logD = 0.568901
Validation R2 logD = 0.765405
Validation rmse logP = 0.742048
Validation R2 logP = 0.737031
Epoch 23
Train function
Loss = 6.6821e-04, PNorm = 60.6694, GNorm = 0.3793, lr_0 = 6.0167e-04
Loss = 5.8077e-04, PNorm = 60.6996, GNorm = 0.4520, lr_0 = 5.9901e-04
Loss = 7.0218e-04, PNorm = 60.7282, GNorm = 0.6894, lr_0 = 5.9636e-04
Loss = 7.2031e-04, PNorm = 60.7583, GNorm = 2.7329, lr_0 = 5.9372e-04
Loss = 8.4305e-04, PNorm = 60.7920, GNorm = 1.1917, lr_0 = 5.9110e-04
Validation rmse logD = 0.569652
Validation R2 logD = 0.764785
Validation rmse logP = 0.727267
Validation R2 logP = 0.747403
Epoch 24
Train function
Loss = 5.7059e-04, PNorm = 60.8270, GNorm = 0.8525, lr_0 = 5.8822e-04
Loss = 6.0502e-04, PNorm = 60.8607, GNorm = 0.5032, lr_0 = 5.8562e-04
Loss = 6.1010e-04, PNorm = 60.8856, GNorm = 1.3384, lr_0 = 5.8303e-04
Loss = 6.6154e-04, PNorm = 60.9115, GNorm = 0.8279, lr_0 = 5.8045e-04
Loss = 7.9716e-04, PNorm = 60.9418, GNorm = 0.8667, lr_0 = 5.7788e-04
Validation rmse logD = 0.585787
Validation R2 logD = 0.751272
Validation rmse logP = 0.732216
Validation R2 logP = 0.743954
Epoch 25
Train function
Loss = 4.9213e-04, PNorm = 60.9722, GNorm = 0.3510, lr_0 = 5.7507e-04
Loss = 5.5974e-04, PNorm = 60.9958, GNorm = 0.4027, lr_0 = 5.7253e-04
Loss = 4.6000e-04, PNorm = 61.0216, GNorm = 0.5534, lr_0 = 5.7000e-04
Loss = 6.3320e-04, PNorm = 61.0473, GNorm = 0.4752, lr_0 = 5.6748e-04
Loss = 4.6911e-04, PNorm = 61.0732, GNorm = 0.3344, lr_0 = 5.6497e-04
Loss = 5.5684e-04, PNorm = 61.0950, GNorm = 0.6305, lr_0 = 5.6247e-04
Loss = 1.4880e-03, PNorm = 61.0971, GNorm = 0.9341, lr_0 = 5.6222e-04
Validation rmse logD = 0.568660
Validation R2 logD = 0.765604
Validation rmse logP = 0.726868
Validation R2 logP = 0.747681
Epoch 26
Train function
Loss = 4.5912e-04, PNorm = 61.1162, GNorm = 0.9573, lr_0 = 5.5973e-04
Loss = 4.1380e-04, PNorm = 61.1383, GNorm = 0.4971, lr_0 = 5.5725e-04
Loss = 4.6811e-04, PNorm = 61.1581, GNorm = 0.4618, lr_0 = 5.5479e-04
Loss = 5.8484e-04, PNorm = 61.1811, GNorm = 0.4750, lr_0 = 5.5233e-04
Loss = 5.2652e-04, PNorm = 61.2057, GNorm = 0.3466, lr_0 = 5.4989e-04
Validation rmse logD = 0.586828
Validation R2 logD = 0.750387
Validation rmse logP = 0.719679
Validation R2 logP = 0.752647
Epoch 27
Train function
Loss = 6.1531e-04, PNorm = 61.2247, GNorm = 1.3057, lr_0 = 5.4722e-04
Loss = 6.0105e-04, PNorm = 61.2578, GNorm = 0.9972, lr_0 = 5.4480e-04
Loss = 4.8602e-04, PNorm = 61.2867, GNorm = 0.3719, lr_0 = 5.4239e-04
Loss = 5.5080e-04, PNorm = 61.3192, GNorm = 0.5465, lr_0 = 5.3999e-04
Loss = 6.5654e-04, PNorm = 61.3421, GNorm = 0.3879, lr_0 = 5.3760e-04
Validation rmse logD = 0.569868
Validation R2 logD = 0.764607
Validation rmse logP = 0.732449
Validation R2 logP = 0.743791
Epoch 28
Train function
Loss = 5.1977e-04, PNorm = 61.3677, GNorm = 0.5673, lr_0 = 5.3498e-04
Loss = 4.5645e-04, PNorm = 61.3922, GNorm = 0.7058, lr_0 = 5.3262e-04
Loss = 6.8157e-04, PNorm = 61.4161, GNorm = 0.8916, lr_0 = 5.3026e-04
Loss = 4.0584e-04, PNorm = 61.4425, GNorm = 0.5877, lr_0 = 5.2792e-04
Loss = 4.5246e-04, PNorm = 61.4695, GNorm = 0.9992, lr_0 = 5.2558e-04
Validation rmse logD = 0.625219
Validation R2 logD = 0.716659
Validation rmse logP = 0.711112
Validation R2 logP = 0.758501
Epoch 29
Train function
Loss = 1.0357e-03, PNorm = 61.4888, GNorm = 2.2473, lr_0 = 5.2302e-04
Loss = 6.9352e-04, PNorm = 61.5146, GNorm = 0.6892, lr_0 = 5.2071e-04
Loss = 7.7927e-04, PNorm = 61.5468, GNorm = 1.0501, lr_0 = 5.1841e-04
Loss = 5.1541e-04, PNorm = 61.5791, GNorm = 0.9437, lr_0 = 5.1611e-04
Loss = 5.3121e-04, PNorm = 61.6047, GNorm = 0.7771, lr_0 = 5.1383e-04
Loss = 4.1448e-04, PNorm = 61.6290, GNorm = 0.4526, lr_0 = 5.1156e-04
Validation rmse logD = 0.569714
Validation R2 logD = 0.764734
Validation rmse logP = 0.725281
Validation R2 logP = 0.748781
Epoch 30
Train function
Loss = 4.0448e-04, PNorm = 61.6415, GNorm = 0.2863, lr_0 = 5.0930e-04
Loss = 4.2041e-04, PNorm = 61.6606, GNorm = 0.3522, lr_0 = 5.0704e-04
Loss = 4.5136e-04, PNorm = 61.6766, GNorm = 0.6790, lr_0 = 5.0480e-04
Loss = 3.1961e-04, PNorm = 61.6990, GNorm = 0.4830, lr_0 = 5.0257e-04
Loss = 3.8275e-04, PNorm = 61.7184, GNorm = 0.2568, lr_0 = 5.0034e-04
Validation rmse logD = 0.569438
Validation R2 logD = 0.764962
Validation rmse logP = 0.731032
Validation R2 logP = 0.744781
Epoch 31
Train function
Loss = 2.9605e-04, PNorm = 61.7357, GNorm = 0.4782, lr_0 = 4.9791e-04
Loss = 3.6682e-04, PNorm = 61.7576, GNorm = 0.2537, lr_0 = 4.9571e-04
Loss = 4.1816e-04, PNorm = 61.7753, GNorm = 0.4344, lr_0 = 4.9351e-04
Loss = 4.1758e-04, PNorm = 61.7904, GNorm = 0.7418, lr_0 = 4.9133e-04
Loss = 3.0813e-04, PNorm = 61.8090, GNorm = 0.6307, lr_0 = 4.8916e-04
Validation rmse logD = 0.570461
Validation R2 logD = 0.764116
Validation rmse logP = 0.729861
Validation R2 logP = 0.745598
Epoch 32
Train function
Loss = 3.3987e-04, PNorm = 61.8273, GNorm = 0.3995, lr_0 = 4.8678e-04
Loss = 4.2517e-04, PNorm = 61.8451, GNorm = 0.3273, lr_0 = 4.8463e-04
Loss = 5.7280e-04, PNorm = 61.8672, GNorm = 0.5751, lr_0 = 4.8248e-04
Loss = 3.2714e-04, PNorm = 61.8893, GNorm = 0.3556, lr_0 = 4.8035e-04
Loss = 2.8993e-04, PNorm = 61.9083, GNorm = 0.3627, lr_0 = 4.7822e-04
Loss = 3.0033e-04, PNorm = 61.9229, GNorm = 0.2700, lr_0 = 4.7611e-04
Validation rmse logD = 0.565881
Validation R2 logD = 0.767889
Validation rmse logP = 0.709418
Validation R2 logP = 0.759650
Epoch 33
Train function
Loss = 2.3816e-04, PNorm = 61.9431, GNorm = 0.2069, lr_0 = 4.7379e-04
Loss = 2.6228e-04, PNorm = 61.9601, GNorm = 0.3375, lr_0 = 4.7170e-04
Loss = 3.5110e-04, PNorm = 61.9756, GNorm = 1.1942, lr_0 = 4.6961e-04
Loss = 2.4421e-04, PNorm = 61.9901, GNorm = 0.6189, lr_0 = 4.6753e-04
Loss = 2.7322e-04, PNorm = 62.0017, GNorm = 0.7993, lr_0 = 4.6546e-04
Validation rmse logD = 0.562225
Validation R2 logD = 0.770878
Validation rmse logP = 0.712422
Validation R2 logP = 0.757610
Epoch 34
Train function
Loss = 2.4879e-04, PNorm = 62.0198, GNorm = 0.4617, lr_0 = 4.6320e-04
Loss = 2.5847e-04, PNorm = 62.0358, GNorm = 0.3223, lr_0 = 4.6115e-04
Loss = 2.2607e-04, PNorm = 62.0467, GNorm = 0.3666, lr_0 = 4.5911e-04
Loss = 3.1786e-04, PNorm = 62.0583, GNorm = 0.8445, lr_0 = 4.5708e-04
Loss = 3.3145e-04, PNorm = 62.0737, GNorm = 0.4612, lr_0 = 4.5506e-04
Validation rmse logD = 0.568339
Validation R2 logD = 0.765868
Validation rmse logP = 0.724999
Validation R2 logP = 0.748977
Epoch 35
Train function
Loss = 2.2645e-04, PNorm = 62.0864, GNorm = 0.8860, lr_0 = 4.5284e-04
Loss = 3.9808e-04, PNorm = 62.1062, GNorm = 0.5401, lr_0 = 4.5084e-04
Loss = 2.9019e-04, PNorm = 62.1238, GNorm = 0.8315, lr_0 = 4.4885e-04
Loss = 3.2021e-04, PNorm = 62.1428, GNorm = 0.8844, lr_0 = 4.4686e-04
Loss = 3.1098e-04, PNorm = 62.1569, GNorm = 0.5161, lr_0 = 4.4489e-04
Loss = 1.8612e-04, PNorm = 62.1686, GNorm = 0.1697, lr_0 = 4.4292e-04
Validation rmse logD = 0.566762
Validation R2 logD = 0.767166
Validation rmse logP = 0.711005
Validation R2 logP = 0.758574
Epoch 36
Train function
Loss = 1.9504e-04, PNorm = 62.1849, GNorm = 0.4294, lr_0 = 4.4076e-04
Loss = 2.5613e-04, PNorm = 62.1904, GNorm = 0.3118, lr_0 = 4.3881e-04
Loss = 2.5581e-04, PNorm = 62.2047, GNorm = 0.3869, lr_0 = 4.3687e-04
Loss = 2.2454e-04, PNorm = 62.2139, GNorm = 0.5502, lr_0 = 4.3494e-04
Loss = 2.3570e-04, PNorm = 62.2277, GNorm = 0.2085, lr_0 = 4.3302e-04
Validation rmse logD = 0.565726
Validation R2 logD = 0.768016
Validation rmse logP = 0.702854
Validation R2 logP = 0.764077
Epoch 37
Train function
Loss = 2.2820e-04, PNorm = 62.2419, GNorm = 0.5252, lr_0 = 4.3091e-04
Loss = 1.9891e-04, PNorm = 62.2533, GNorm = 0.1856, lr_0 = 4.2900e-04
Loss = 2.4322e-04, PNorm = 62.2629, GNorm = 0.3904, lr_0 = 4.2711e-04
Loss = 1.8938e-04, PNorm = 62.2716, GNorm = 0.6743, lr_0 = 4.2522e-04
Loss = 1.3796e-04, PNorm = 62.2801, GNorm = 0.2232, lr_0 = 4.2334e-04
Validation rmse logD = 0.563914
Validation R2 logD = 0.769500
Validation rmse logP = 0.711186
Validation R2 logP = 0.758451
Epoch 38
Train function
Loss = 1.7925e-04, PNorm = 62.2867, GNorm = 0.3423, lr_0 = 4.2128e-04
Loss = 2.0489e-04, PNorm = 62.3026, GNorm = 0.3256, lr_0 = 4.1941e-04
Loss = 1.9373e-04, PNorm = 62.3124, GNorm = 0.1883, lr_0 = 4.1756e-04
Loss = 2.1125e-04, PNorm = 62.3207, GNorm = 0.4672, lr_0 = 4.1571e-04
Loss = 1.6750e-04, PNorm = 62.3316, GNorm = 0.3279, lr_0 = 4.1387e-04
Loss = 1.7740e-04, PNorm = 62.3438, GNorm = 0.3694, lr_0 = 4.1204e-04
Loss = 1.4377e-02, PNorm = 62.3458, GNorm = 2.3366, lr_0 = 4.1186e-04
Validation rmse logD = 0.575217
Validation R2 logD = 0.760167
Validation rmse logP = 0.717457
Validation R2 logP = 0.754172
Epoch 39
Train function
Loss = 4.4028e-04, PNorm = 62.3659, GNorm = 0.8822, lr_0 = 4.1004e-04
Loss = 3.4834e-04, PNorm = 62.3869, GNorm = 0.3153, lr_0 = 4.0822e-04
Loss = 3.1950e-04, PNorm = 62.4098, GNorm = 0.8693, lr_0 = 4.0642e-04
Loss = 2.1102e-04, PNorm = 62.4260, GNorm = 0.2162, lr_0 = 4.0462e-04
Loss = 2.8113e-04, PNorm = 62.4390, GNorm = 0.4117, lr_0 = 4.0283e-04
Validation rmse logD = 0.563711
Validation R2 logD = 0.769666
Validation rmse logP = 0.718121
Validation R2 logP = 0.753717
Epoch 40
Train function
Loss = 2.1632e-04, PNorm = 62.4499, GNorm = 0.2673, lr_0 = 4.0105e-04
Loss = 1.6875e-04, PNorm = 62.4602, GNorm = 0.3376, lr_0 = 3.9927e-04
Loss = 2.2081e-04, PNorm = 62.4691, GNorm = 0.3142, lr_0 = 3.9751e-04
Loss = 1.6547e-04, PNorm = 62.4816, GNorm = 0.2704, lr_0 = 3.9575e-04
Loss = 1.6873e-04, PNorm = 62.4875, GNorm = 0.2142, lr_0 = 3.9400e-04
Validation rmse logD = 0.563882
Validation R2 logD = 0.769526
Validation rmse logP = 0.712189
Validation R2 logP = 0.757768
Epoch 41
Train function
Loss = 2.1666e-04, PNorm = 62.4958, GNorm = 0.3058, lr_0 = 3.9208e-04
Loss = 1.4768e-04, PNorm = 62.5025, GNorm = 0.3449, lr_0 = 3.9035e-04
Loss = 1.3239e-04, PNorm = 62.5119, GNorm = 0.3138, lr_0 = 3.8862e-04
Loss = 1.3671e-04, PNorm = 62.5188, GNorm = 0.2232, lr_0 = 3.8690e-04
Loss = 1.7431e-04, PNorm = 62.5274, GNorm = 0.2127, lr_0 = 3.8519e-04
Loss = 1.5008e-04, PNorm = 62.5371, GNorm = 0.2357, lr_0 = 3.8349e-04
Loss = 1.2025e-03, PNorm = 62.5382, GNorm = 0.6724, lr_0 = 3.8332e-04
Validation rmse logD = 0.566275
Validation R2 logD = 0.767566
Validation rmse logP = 0.714111
Validation R2 logP = 0.756460
Epoch 42
Train function
Loss = 1.4461e-04, PNorm = 62.5478, GNorm = 0.2937, lr_0 = 3.8162e-04
Loss = 1.3921e-04, PNorm = 62.5548, GNorm = 0.2915, lr_0 = 3.7993e-04
Loss = 1.2987e-04, PNorm = 62.5608, GNorm = 0.2050, lr_0 = 3.7825e-04
Loss = 1.6509e-04, PNorm = 62.5686, GNorm = 0.2038, lr_0 = 3.7658e-04
Loss = 1.4123e-04, PNorm = 62.5796, GNorm = 0.2322, lr_0 = 3.7491e-04
Validation rmse logD = 0.566208
Validation R2 logD = 0.767621
Validation rmse logP = 0.723505
Validation R2 logP = 0.750010
Epoch 43
Train function
Loss = 1.3276e-04, PNorm = 62.5872, GNorm = 0.2022, lr_0 = 3.7309e-04
Loss = 1.8375e-04, PNorm = 62.5930, GNorm = 0.2212, lr_0 = 3.7144e-04
Loss = 1.4958e-04, PNorm = 62.6046, GNorm = 0.1753, lr_0 = 3.6980e-04
Loss = 1.5629e-04, PNorm = 62.6148, GNorm = 0.4912, lr_0 = 3.6816e-04
Loss = 1.3946e-04, PNorm = 62.6205, GNorm = 0.4588, lr_0 = 3.6653e-04
Validation rmse logD = 0.566014
Validation R2 logD = 0.767780
Validation rmse logP = 0.701412
Validation R2 logP = 0.765044
Epoch 44
Train function
Loss = 1.0147e-04, PNorm = 62.6309, GNorm = 0.1856, lr_0 = 3.6475e-04
Loss = 1.4322e-04, PNorm = 62.6403, GNorm = 0.2285, lr_0 = 3.6314e-04
Loss = 9.9344e-05, PNorm = 62.6464, GNorm = 0.1942, lr_0 = 3.6153e-04
Loss = 1.0577e-04, PNorm = 62.6514, GNorm = 0.4778, lr_0 = 3.5993e-04
Loss = 1.5267e-04, PNorm = 62.6599, GNorm = 0.2564, lr_0 = 3.5834e-04
Validation rmse logD = 0.560888
Validation R2 logD = 0.771967
Validation rmse logP = 0.713156
Validation R2 logP = 0.757110
Epoch 45
Train function
Loss = 8.4574e-05, PNorm = 62.6682, GNorm = 0.2138, lr_0 = 3.5660e-04
Loss = 1.4095e-04, PNorm = 62.6738, GNorm = 0.3236, lr_0 = 3.5502e-04
Loss = 1.2470e-04, PNorm = 62.6818, GNorm = 0.1713, lr_0 = 3.5345e-04
Loss = 9.3063e-05, PNorm = 62.6896, GNorm = 0.2032, lr_0 = 3.5188e-04
Loss = 1.0308e-04, PNorm = 62.6959, GNorm = 0.4405, lr_0 = 3.5033e-04
Loss = 1.1904e-04, PNorm = 62.7037, GNorm = 0.4936, lr_0 = 3.4878e-04
Validation rmse logD = 0.586618
Validation R2 logD = 0.750566
Validation rmse logP = 0.707163
Validation R2 logP = 0.761176
Epoch 46
Train function
Loss = 2.8419e-04, PNorm = 62.7148, GNorm = 1.1696, lr_0 = 3.4708e-04
Loss = 1.5005e-04, PNorm = 62.7254, GNorm = 0.3489, lr_0 = 3.4555e-04
Loss = 1.1274e-04, PNorm = 62.7357, GNorm = 0.2447, lr_0 = 3.4402e-04
Loss = 1.2788e-04, PNorm = 62.7423, GNorm = 0.2641, lr_0 = 3.4250e-04
Loss = 1.1698e-04, PNorm = 62.7521, GNorm = 0.1376, lr_0 = 3.4098e-04
Validation rmse logD = 0.566483
Validation R2 logD = 0.767395
Validation rmse logP = 0.710997
Validation R2 logP = 0.758579
Epoch 47
Train function
Loss = 1.3602e-04, PNorm = 62.7627, GNorm = 0.3965, lr_0 = 3.3932e-04
Loss = 1.2690e-04, PNorm = 62.7744, GNorm = 0.4184, lr_0 = 3.3782e-04
Loss = 9.7744e-05, PNorm = 62.7849, GNorm = 0.1416, lr_0 = 3.3633e-04
Loss = 1.4174e-04, PNorm = 62.7889, GNorm = 0.5449, lr_0 = 3.3484e-04
Loss = 1.4825e-04, PNorm = 62.7950, GNorm = 0.5372, lr_0 = 3.3336e-04
Validation rmse logD = 0.566018
Validation R2 logD = 0.767777
Validation rmse logP = 0.712993
Validation R2 logP = 0.757222
Epoch 48
Train function
Loss = 1.5064e-04, PNorm = 62.8037, GNorm = 0.5004, lr_0 = 3.3174e-04
Loss = 9.5050e-05, PNorm = 62.8099, GNorm = 0.1585, lr_0 = 3.3027e-04
Loss = 8.7349e-05, PNorm = 62.8149, GNorm = 0.1813, lr_0 = 3.2881e-04
Loss = 8.4049e-05, PNorm = 62.8199, GNorm = 0.1323, lr_0 = 3.2735e-04
Loss = 8.3266e-05, PNorm = 62.8251, GNorm = 0.1944, lr_0 = 3.2591e-04
Loss = 1.0165e-04, PNorm = 62.8335, GNorm = 0.1299, lr_0 = 3.2446e-04
Validation rmse logD = 0.566935
Validation R2 logD = 0.767023
Validation rmse logP = 0.716069
Validation R2 logP = 0.755122
Epoch 49
Train function
Loss = 9.3614e-05, PNorm = 62.8368, GNorm = 0.2258, lr_0 = 3.2289e-04
Loss = 1.0295e-04, PNorm = 62.8460, GNorm = 0.2289, lr_0 = 3.2146e-04
Loss = 9.7512e-05, PNorm = 62.8537, GNorm = 0.5503, lr_0 = 3.2004e-04
Loss = 8.9991e-05, PNorm = 62.8584, GNorm = 0.1971, lr_0 = 3.1862e-04
Loss = 8.3146e-05, PNorm = 62.8652, GNorm = 0.1396, lr_0 = 3.1721e-04
Validation rmse logD = 0.563856
Validation R2 logD = 0.769547
Validation rmse logP = 0.716009
Validation R2 logP = 0.755164
Epoch 50
Train function
Loss = 5.3745e-05, PNorm = 62.8699, GNorm = 0.2588, lr_0 = 3.1581e-04
Loss = 7.7182e-05, PNorm = 62.8749, GNorm = 0.3157, lr_0 = 3.1441e-04
Loss = 8.5360e-05, PNorm = 62.8811, GNorm = 0.2200, lr_0 = 3.1302e-04
Loss = 8.2636e-05, PNorm = 62.8855, GNorm = 0.2518, lr_0 = 3.1164e-04
Loss = 8.3144e-05, PNorm = 62.8894, GNorm = 0.1840, lr_0 = 3.1026e-04
Validation rmse logD = 0.561499
Validation R2 logD = 0.771470
Validation rmse logP = 0.715451
Validation R2 logP = 0.755545
Epoch 51
Train function
Loss = 3.7975e-05, PNorm = 62.8947, GNorm = 0.1758, lr_0 = 3.0875e-04
Loss = 3.9670e-05, PNorm = 62.9000, GNorm = 0.1160, lr_0 = 3.0738e-04
Loss = 5.3760e-05, PNorm = 62.9028, GNorm = 0.2094, lr_0 = 3.0602e-04
Loss = 9.1550e-05, PNorm = 62.9088, GNorm = 0.4790, lr_0 = 3.0467e-04
Loss = 6.6135e-05, PNorm = 62.9127, GNorm = 0.1523, lr_0 = 3.0332e-04
Loss = 5.6520e-05, PNorm = 62.9156, GNorm = 0.2475, lr_0 = 3.0198e-04
Validation rmse logD = 0.563182
Validation R2 logD = 0.770098
Validation rmse logP = 0.708369
Validation R2 logP = 0.760360
Epoch 52
Train function
Loss = 5.4728e-05, PNorm = 62.9192, GNorm = 0.1504, lr_0 = 3.0051e-04
Loss = 5.2912e-05, PNorm = 62.9236, GNorm = 0.0966, lr_0 = 2.9918e-04
Loss = 5.0499e-05, PNorm = 62.9271, GNorm = 0.1860, lr_0 = 2.9786e-04
Loss = 5.3674e-05, PNorm = 62.9302, GNorm = 0.2515, lr_0 = 2.9654e-04
Loss = 6.7254e-05, PNorm = 62.9333, GNorm = 0.2067, lr_0 = 2.9523e-04
Validation rmse logD = 0.566431
Validation R2 logD = 0.767438
Validation rmse logP = 0.716505
Validation R2 logP = 0.754824
Epoch 53
Train function
Loss = 7.2754e-05, PNorm = 62.9382, GNorm = 0.4193, lr_0 = 2.9379e-04
Loss = 6.1234e-05, PNorm = 62.9453, GNorm = 0.2675, lr_0 = 2.9249e-04
Loss = 9.7122e-05, PNorm = 62.9516, GNorm = 0.3433, lr_0 = 2.9120e-04
Loss = 7.2244e-05, PNorm = 62.9571, GNorm = 0.2094, lr_0 = 2.8991e-04
Loss = 8.5720e-05, PNorm = 62.9625, GNorm = 0.2774, lr_0 = 2.8863e-04
Validation rmse logD = 0.564588
Validation R2 logD = 0.768948
Validation rmse logP = 0.709526
Validation R2 logP = 0.759577
Epoch 54
Train function
Loss = 5.2808e-05, PNorm = 62.9709, GNorm = 0.1437, lr_0 = 2.8722e-04
Loss = 5.7815e-05, PNorm = 62.9750, GNorm = 0.1722, lr_0 = 2.8595e-04
Loss = 5.7531e-05, PNorm = 62.9796, GNorm = 0.2193, lr_0 = 2.8469e-04
Loss = 5.5661e-05, PNorm = 62.9862, GNorm = 0.1631, lr_0 = 2.8343e-04
Loss = 7.0203e-05, PNorm = 62.9906, GNorm = 0.3669, lr_0 = 2.8218e-04
Loss = 7.2927e-05, PNorm = 62.9953, GNorm = 0.3101, lr_0 = 2.8093e-04
Loss = 9.2337e-05, PNorm = 62.9957, GNorm = 0.1742, lr_0 = 2.8080e-04
Validation rmse logD = 0.564933
Validation R2 logD = 0.768666
Validation rmse logP = 0.709350
Validation R2 logP = 0.759696
Epoch 55
Train function
Loss = 6.4646e-05, PNorm = 62.9989, GNorm = 0.3290, lr_0 = 2.7956e-04
Loss = 6.1929e-05, PNorm = 63.0033, GNorm = 0.4644, lr_0 = 2.7832e-04
Loss = 4.7490e-05, PNorm = 63.0090, GNorm = 0.1806, lr_0 = 2.7709e-04
Loss = 5.5112e-05, PNorm = 63.0137, GNorm = 0.1186, lr_0 = 2.7587e-04
Loss = 5.8055e-05, PNorm = 63.0200, GNorm = 0.4669, lr_0 = 2.7465e-04
Validation rmse logD = 0.565871
Validation R2 logD = 0.767897
Validation rmse logP = 0.715070
Validation R2 logP = 0.755805
Epoch 56
Train function
Loss = 5.7073e-05, PNorm = 63.0254, GNorm = 0.5560, lr_0 = 2.7331e-04
Loss = 7.0771e-05, PNorm = 63.0283, GNorm = 0.4042, lr_0 = 2.7210e-04
Loss = 8.7602e-05, PNorm = 63.0314, GNorm = 0.2452, lr_0 = 2.7090e-04
Loss = 6.8510e-05, PNorm = 63.0370, GNorm = 0.5108, lr_0 = 2.6970e-04
Loss = 7.6405e-05, PNorm = 63.0423, GNorm = 0.2230, lr_0 = 2.6851e-04
Validation rmse logD = 0.570281
Validation R2 logD = 0.764265
Validation rmse logP = 0.703107
Validation R2 logP = 0.763907
Epoch 57
Train function
Loss = 7.0582e-05, PNorm = 63.0488, GNorm = 0.5461, lr_0 = 2.6720e-04
Loss = 4.6321e-05, PNorm = 63.0515, GNorm = 0.2566, lr_0 = 2.6602e-04
Loss = 5.3146e-05, PNorm = 63.0569, GNorm = 0.1698, lr_0 = 2.6484e-04
Loss = 4.9842e-05, PNorm = 63.0622, GNorm = 0.1254, lr_0 = 2.6367e-04
Loss = 4.4204e-05, PNorm = 63.0644, GNorm = 0.2169, lr_0 = 2.6250e-04
Validation rmse logD = 0.567089
Validation R2 logD = 0.766897
Validation rmse logP = 0.707728
Validation R2 logP = 0.760794
Epoch 58
Train function
Loss = 5.0375e-05, PNorm = 63.0678, GNorm = 0.4423, lr_0 = 2.6123e-04
Loss = 1.3978e-04, PNorm = 63.0723, GNorm = 0.2357, lr_0 = 2.6007e-04
Loss = 8.2600e-05, PNorm = 63.0764, GNorm = 0.4200, lr_0 = 2.5892e-04
Loss = 6.7556e-05, PNorm = 63.0823, GNorm = 0.2390, lr_0 = 2.5778e-04
Loss = 6.0105e-05, PNorm = 63.0889, GNorm = 0.2456, lr_0 = 2.5664e-04
Loss = 6.8570e-05, PNorm = 63.0936, GNorm = 0.1984, lr_0 = 2.5550e-04
Validation rmse logD = 0.563740
Validation R2 logD = 0.769642
Validation rmse logP = 0.712945
Validation R2 logP = 0.757254
Epoch 59
Train function
Loss = 4.2845e-05, PNorm = 63.0974, GNorm = 0.2240, lr_0 = 2.5426e-04
Loss = 5.2868e-05, PNorm = 63.1017, GNorm = 0.2018, lr_0 = 2.5313e-04
Loss = 4.9082e-05, PNorm = 63.1048, GNorm = 0.1891, lr_0 = 2.5201e-04
Loss = 4.5073e-05, PNorm = 63.1103, GNorm = 0.1158, lr_0 = 2.5090e-04
Loss = 3.8194e-05, PNorm = 63.1138, GNorm = 0.2178, lr_0 = 2.4979e-04
Validation rmse logD = 0.563818
Validation R2 logD = 0.769579
Validation rmse logP = 0.711698
Validation R2 logP = 0.758103
Epoch 60
Train function
Loss = 3.6938e-05, PNorm = 63.1154, GNorm = 0.1475, lr_0 = 2.4868e-04
Loss = 5.2910e-05, PNorm = 63.1181, GNorm = 0.5855, lr_0 = 2.4758e-04
Loss = 4.0373e-05, PNorm = 63.1214, GNorm = 0.1427, lr_0 = 2.4649e-04
Loss = 4.2180e-05, PNorm = 63.1246, GNorm = 0.1354, lr_0 = 2.4540e-04
Loss = 4.1421e-05, PNorm = 63.1278, GNorm = 0.2684, lr_0 = 2.4431e-04
Validation rmse logD = 0.563700
Validation R2 logD = 0.769675
Validation rmse logP = 0.712196
Validation R2 logP = 0.757764
Epoch 61
Train function
Loss = 2.3995e-05, PNorm = 63.1323, GNorm = 0.0848, lr_0 = 2.4313e-04
Loss = 2.9649e-05, PNorm = 63.1347, GNorm = 0.0886, lr_0 = 2.4205e-04
Loss = 2.7853e-05, PNorm = 63.1362, GNorm = 0.1041, lr_0 = 2.4098e-04
Loss = 3.6535e-05, PNorm = 63.1403, GNorm = 0.1856, lr_0 = 2.3991e-04
Loss = 3.6343e-05, PNorm = 63.1442, GNorm = 0.1047, lr_0 = 2.3885e-04
Loss = 4.0266e-05, PNorm = 63.1474, GNorm = 0.1042, lr_0 = 2.3780e-04
Validation rmse logD = 0.566839
Validation R2 logD = 0.767102
Validation rmse logP = 0.717876
Validation R2 logP = 0.753885
Epoch 62
Train function
Loss = 3.9977e-05, PNorm = 63.1506, GNorm = 0.2567, lr_0 = 2.3664e-04
Loss = 3.1363e-05, PNorm = 63.1521, GNorm = 0.2240, lr_0 = 2.3559e-04
Loss = 4.8331e-05, PNorm = 63.1546, GNorm = 0.2609, lr_0 = 2.3455e-04
Loss = 5.0846e-05, PNorm = 63.1587, GNorm = 0.1575, lr_0 = 2.3351e-04
Loss = 3.3006e-05, PNorm = 63.1614, GNorm = 0.1389, lr_0 = 2.3248e-04
Validation rmse logD = 0.565320
Validation R2 logD = 0.768349
Validation rmse logP = 0.712201
Validation R2 logP = 0.757760
Epoch 63
Train function
Loss = 3.1216e-05, PNorm = 63.1637, GNorm = 0.1155, lr_0 = 2.3135e-04
Loss = 3.6630e-05, PNorm = 63.1666, GNorm = 0.0823, lr_0 = 2.3033e-04
Loss = 2.8895e-05, PNorm = 63.1691, GNorm = 0.1639, lr_0 = 2.2931e-04
Loss = 3.0571e-05, PNorm = 63.1723, GNorm = 0.0816, lr_0 = 2.2829e-04
Loss = 4.1529e-05, PNorm = 63.1753, GNorm = 0.1582, lr_0 = 2.2728e-04
Validation rmse logD = 0.565255
Validation R2 logD = 0.768402
Validation rmse logP = 0.710792
Validation R2 logP = 0.758718
Epoch 64
Train function
Loss = 1.5917e-05, PNorm = 63.1786, GNorm = 0.1520, lr_0 = 2.2618e-04
Loss = 2.4785e-05, PNorm = 63.1809, GNorm = 0.0926, lr_0 = 2.2518e-04
Loss = 2.6484e-05, PNorm = 63.1829, GNorm = 0.1789, lr_0 = 2.2418e-04
Loss = 2.4628e-05, PNorm = 63.1853, GNorm = 0.0771, lr_0 = 2.2319e-04
Loss = 3.0157e-05, PNorm = 63.1879, GNorm = 0.1238, lr_0 = 2.2220e-04
Loss = 2.3993e-05, PNorm = 63.1889, GNorm = 0.2297, lr_0 = 2.2122e-04
Validation rmse logD = 0.565468
Validation R2 logD = 0.768228
Validation rmse logP = 0.711452
Validation R2 logP = 0.758270
Epoch 65
Train function
Loss = 2.4917e-05, PNorm = 63.1917, GNorm = 0.2066, lr_0 = 2.2014e-04
Loss = 2.4079e-05, PNorm = 63.1943, GNorm = 0.0715, lr_0 = 2.1917e-04
Loss = 2.6322e-05, PNorm = 63.1978, GNorm = 0.1517, lr_0 = 2.1820e-04
Loss = 3.2924e-05, PNorm = 63.1999, GNorm = 0.2090, lr_0 = 2.1723e-04
Loss = 2.6554e-05, PNorm = 63.2030, GNorm = 0.1547, lr_0 = 2.1627e-04
Validation rmse logD = 0.566466
Validation R2 logD = 0.767409
Validation rmse logP = 0.710888
Validation R2 logP = 0.758653
Epoch 66
Train function
Loss = 1.7989e-05, PNorm = 63.2063, GNorm = 0.1264, lr_0 = 2.1522e-04
Loss = 2.2447e-05, PNorm = 63.2076, GNorm = 0.0812, lr_0 = 2.1427e-04
Loss = 2.7038e-05, PNorm = 63.2102, GNorm = 0.0926, lr_0 = 2.1332e-04
Loss = 1.6602e-05, PNorm = 63.2110, GNorm = 0.1264, lr_0 = 2.1238e-04
Loss = 2.6365e-05, PNorm = 63.2136, GNorm = 0.3809, lr_0 = 2.1144e-04
Validation rmse logD = 0.566182
Validation R2 logD = 0.767642
Validation rmse logP = 0.712931
Validation R2 logP = 0.757264
Epoch 67
Train function
Loss = 3.5381e-05, PNorm = 63.2169, GNorm = 0.0869, lr_0 = 2.1041e-04
Loss = 4.0938e-05, PNorm = 63.2190, GNorm = 0.1960, lr_0 = 2.0948e-04
Loss = 4.0769e-05, PNorm = 63.2227, GNorm = 0.1751, lr_0 = 2.0855e-04
Loss = 3.7321e-05, PNorm = 63.2262, GNorm = 0.2829, lr_0 = 2.0763e-04
Loss = 3.4617e-05, PNorm = 63.2302, GNorm = 0.2756, lr_0 = 2.0671e-04
Loss = 3.0330e-05, PNorm = 63.2337, GNorm = 0.3028, lr_0 = 2.0580e-04
Loss = 6.5089e-04, PNorm = 63.2343, GNorm = 0.8013, lr_0 = 2.0571e-04
Validation rmse logD = 0.565465
Validation R2 logD = 0.768230
Validation rmse logP = 0.707132
Validation R2 logP = 0.761197
Epoch 68
Train function
Loss = 4.9990e-05, PNorm = 63.2375, GNorm = 0.1414, lr_0 = 2.0480e-04
Loss = 4.9873e-05, PNorm = 63.2414, GNorm = 0.1313, lr_0 = 2.0389e-04
Loss = 3.7980e-05, PNorm = 63.2460, GNorm = 0.2308, lr_0 = 2.0299e-04
Loss = 3.3572e-05, PNorm = 63.2484, GNorm = 0.1127, lr_0 = 2.0209e-04
Loss = 5.9638e-05, PNorm = 63.2500, GNorm = 0.3760, lr_0 = 2.0120e-04
Validation rmse logD = 0.568000
Validation R2 logD = 0.766147
Validation rmse logP = 0.707939
Validation R2 logP = 0.760651
Epoch 69
Train function
Loss = 3.8838e-05, PNorm = 63.2519, GNorm = 0.0958, lr_0 = 2.0022e-04
Loss = 3.6414e-05, PNorm = 63.2543, GNorm = 0.2135, lr_0 = 1.9933e-04
Loss = 3.6772e-05, PNorm = 63.2560, GNorm = 0.1641, lr_0 = 1.9845e-04
Loss = 3.3560e-05, PNorm = 63.2582, GNorm = 0.3480, lr_0 = 1.9757e-04
Loss = 4.5686e-05, PNorm = 63.2625, GNorm = 0.1727, lr_0 = 1.9670e-04
Validation rmse logD = 0.566784
Validation R2 logD = 0.767148
Validation rmse logP = 0.704431
Validation R2 logP = 0.763017
Epoch 70
Train function
Loss = 2.7275e-05, PNorm = 63.2660, GNorm = 0.1117, lr_0 = 1.9583e-04
Loss = 3.3577e-05, PNorm = 63.2687, GNorm = 0.1255, lr_0 = 1.9496e-04
Loss = 4.0768e-05, PNorm = 63.2697, GNorm = 0.1480, lr_0 = 1.9410e-04
Loss = 2.5473e-05, PNorm = 63.2734, GNorm = 0.2568, lr_0 = 1.9324e-04
Loss = 3.3503e-05, PNorm = 63.2748, GNorm = 0.0959, lr_0 = 1.9239e-04
Loss = 3.6417e-05, PNorm = 63.2770, GNorm = 0.1517, lr_0 = 1.9154e-04
Loss = 2.6484e-04, PNorm = 63.2772, GNorm = 0.4916, lr_0 = 1.9145e-04
Validation rmse logD = 0.566820
Validation R2 logD = 0.767118
Validation rmse logP = 0.710465
Validation R2 logP = 0.758940
Epoch 71
Train function
Loss = 3.3362e-05, PNorm = 63.2798, GNorm = 0.4149, lr_0 = 1.9060e-04
Loss = 3.1107e-05, PNorm = 63.2815, GNorm = 0.1187, lr_0 = 1.8976e-04
Loss = 3.0049e-05, PNorm = 63.2851, GNorm = 0.1446, lr_0 = 1.8892e-04
Loss = 2.8174e-05, PNorm = 63.2857, GNorm = 0.2614, lr_0 = 1.8809e-04
Loss = 3.1396e-05, PNorm = 63.2868, GNorm = 0.1307, lr_0 = 1.8725e-04
Validation rmse logD = 0.566588
Validation R2 logD = 0.767309
Validation rmse logP = 0.710157
Validation R2 logP = 0.759149
Epoch 72
Train function
Loss = 2.2123e-05, PNorm = 63.2885, GNorm = 0.1265, lr_0 = 1.8634e-04
Loss = 2.4240e-05, PNorm = 63.2907, GNorm = 0.1269, lr_0 = 1.8552e-04
Loss = 2.0638e-05, PNorm = 63.2929, GNorm = 0.1352, lr_0 = 1.8470e-04
Loss = 2.2335e-05, PNorm = 63.2947, GNorm = 0.0834, lr_0 = 1.8388e-04
Loss = 2.1047e-05, PNorm = 63.2959, GNorm = 0.0701, lr_0 = 1.8307e-04
Validation rmse logD = 0.564939
Validation R2 logD = 0.768662
Validation rmse logP = 0.708846
Validation R2 logP = 0.760037
Epoch 73
Train function
Loss = 1.3370e-05, PNorm = 63.2970, GNorm = 0.0950, lr_0 = 1.8218e-04
Loss = 2.0103e-05, PNorm = 63.2992, GNorm = 0.0690, lr_0 = 1.8137e-04
Loss = 2.1295e-05, PNorm = 63.3007, GNorm = 0.1797, lr_0 = 1.8057e-04
Loss = 1.8801e-05, PNorm = 63.3023, GNorm = 0.1667, lr_0 = 1.7977e-04
Loss = 1.8067e-05, PNorm = 63.3044, GNorm = 0.0599, lr_0 = 1.7897e-04
Validation rmse logD = 0.567556
Validation R2 logD = 0.766513
Validation rmse logP = 0.709691
Validation R2 logP = 0.759465
Epoch 74
Train function
Loss = 1.8648e-05, PNorm = 63.3055, GNorm = 0.1192, lr_0 = 1.7810e-04
Loss = 1.0871e-05, PNorm = 63.3062, GNorm = 0.0823, lr_0 = 1.7732e-04
Loss = 1.5408e-05, PNorm = 63.3071, GNorm = 0.1326, lr_0 = 1.7653e-04
Loss = 2.3573e-05, PNorm = 63.3110, GNorm = 0.1010, lr_0 = 1.7575e-04
Loss = 1.6007e-05, PNorm = 63.3135, GNorm = 0.1090, lr_0 = 1.7497e-04
Loss = 1.9873e-05, PNorm = 63.3141, GNorm = 0.0913, lr_0 = 1.7420e-04
Validation rmse logD = 0.564966
Validation R2 logD = 0.768639
Validation rmse logP = 0.710275
Validation R2 logP = 0.759069
Epoch 75
Train function
Loss = 1.4257e-05, PNorm = 63.3161, GNorm = 0.0597, lr_0 = 1.7335e-04
Loss = 1.9068e-05, PNorm = 63.3186, GNorm = 0.1505, lr_0 = 1.7259e-04
Loss = 1.0154e-05, PNorm = 63.3201, GNorm = 0.0968, lr_0 = 1.7182e-04
Loss = 1.6034e-05, PNorm = 63.3210, GNorm = 0.2148, lr_0 = 1.7106e-04
Loss = 1.7273e-05, PNorm = 63.3228, GNorm = 0.0882, lr_0 = 1.7031e-04
Validation rmse logD = 0.565916
Validation R2 logD = 0.767860
Validation rmse logP = 0.707278
Validation R2 logP = 0.761098
Epoch 76
Train function
Loss = 1.8496e-05, PNorm = 63.3243, GNorm = 0.1133, lr_0 = 1.6948e-04
Loss = 1.8818e-05, PNorm = 63.3263, GNorm = 0.1395, lr_0 = 1.6873e-04
Loss = 1.7495e-05, PNorm = 63.3267, GNorm = 0.1294, lr_0 = 1.6798e-04
Loss = 1.7086e-05, PNorm = 63.3282, GNorm = 0.0842, lr_0 = 1.6724e-04
Loss = 1.5615e-05, PNorm = 63.3301, GNorm = 0.1156, lr_0 = 1.6650e-04
Validation rmse logD = 0.565682
Validation R2 logD = 0.768053
Validation rmse logP = 0.711739
Validation R2 logP = 0.758075
Epoch 77
Train function
Loss = 2.0062e-05, PNorm = 63.3318, GNorm = 0.1407, lr_0 = 1.6569e-04
Loss = 1.7922e-05, PNorm = 63.3333, GNorm = 0.1442, lr_0 = 1.6496e-04
Loss = 1.3437e-05, PNorm = 63.3345, GNorm = 0.0854, lr_0 = 1.6423e-04
Loss = 1.5159e-05, PNorm = 63.3368, GNorm = 0.0920, lr_0 = 1.6350e-04
Loss = 1.3995e-05, PNorm = 63.3384, GNorm = 0.1309, lr_0 = 1.6278e-04
Loss = 1.3350e-05, PNorm = 63.3393, GNorm = 0.0990, lr_0 = 1.6206e-04
Validation rmse logD = 0.565799
Validation R2 logD = 0.767957
Validation rmse logP = 0.713176
Validation R2 logP = 0.757097
Epoch 78
Train function
Loss = 1.4599e-05, PNorm = 63.3421, GNorm = 0.1138, lr_0 = 1.6127e-04
Loss = 1.1643e-05, PNorm = 63.3427, GNorm = 0.0687, lr_0 = 1.6055e-04
Loss = 1.2702e-05, PNorm = 63.3437, GNorm = 0.1179, lr_0 = 1.5984e-04
Loss = 1.0197e-05, PNorm = 63.3450, GNorm = 0.0792, lr_0 = 1.5914e-04
Loss = 1.6953e-05, PNorm = 63.3462, GNorm = 0.1630, lr_0 = 1.5843e-04
Validation rmse logD = 0.566741
Validation R2 logD = 0.767183
Validation rmse logP = 0.708990
Validation R2 logP = 0.759940
Epoch 79
Train function
Loss = 9.8437e-06, PNorm = 63.3481, GNorm = 0.1214, lr_0 = 1.5766e-04
Loss = 1.1808e-05, PNorm = 63.3487, GNorm = 0.0827, lr_0 = 1.5697e-04
Loss = 1.4579e-05, PNorm = 63.3495, GNorm = 0.0980, lr_0 = 1.5627e-04
Loss = 1.0684e-05, PNorm = 63.3508, GNorm = 0.0568, lr_0 = 1.5558e-04
Loss = 1.1745e-05, PNorm = 63.3517, GNorm = 0.1649, lr_0 = 1.5489e-04
Validation rmse logD = 0.566248
Validation R2 logD = 0.767588
Validation rmse logP = 0.711923
Validation R2 logP = 0.757950
Epoch 80
Train function
Loss = 1.0184e-05, PNorm = 63.3532, GNorm = 0.1494, lr_0 = 1.5421e-04
Loss = 1.4030e-05, PNorm = 63.3546, GNorm = 0.0527, lr_0 = 1.5352e-04
Loss = 1.0109e-05, PNorm = 63.3564, GNorm = 0.1158, lr_0 = 1.5284e-04
Loss = 9.1103e-06, PNorm = 63.3576, GNorm = 0.0905, lr_0 = 1.5217e-04
Loss = 9.4758e-06, PNorm = 63.3582, GNorm = 0.1513, lr_0 = 1.5150e-04
Loss = 9.8027e-06, PNorm = 63.3593, GNorm = 0.0899, lr_0 = 1.5083e-04
Validation rmse logD = 0.568071
Validation R2 logD = 0.766089
Validation rmse logP = 0.708775
Validation R2 logP = 0.760086
Epoch 81
Train function
Loss = 1.6088e-05, PNorm = 63.3614, GNorm = 0.1350, lr_0 = 1.5009e-04
Loss = 1.5256e-05, PNorm = 63.3615, GNorm = 0.1669, lr_0 = 1.4943e-04
Loss = 1.3229e-05, PNorm = 63.3616, GNorm = 0.0714, lr_0 = 1.4877e-04
Loss = 1.1087e-05, PNorm = 63.3625, GNorm = 0.1576, lr_0 = 1.4811e-04
Loss = 1.4048e-05, PNorm = 63.3647, GNorm = 0.1117, lr_0 = 1.4745e-04
Validation rmse logD = 0.565994
Validation R2 logD = 0.767796
Validation rmse logP = 0.708886
Validation R2 logP = 0.760010
Epoch 82
Train function
Loss = 2.1112e-05, PNorm = 63.3675, GNorm = 0.3169, lr_0 = 1.4674e-04
Loss = 1.8840e-05, PNorm = 63.3689, GNorm = 0.1635, lr_0 = 1.4609e-04
Loss = 1.3234e-05, PNorm = 63.3695, GNorm = 0.0700, lr_0 = 1.4544e-04
Loss = 9.6553e-06, PNorm = 63.3706, GNorm = 0.0626, lr_0 = 1.4480e-04
Loss = 1.0562e-05, PNorm = 63.3712, GNorm = 0.1187, lr_0 = 1.4416e-04
Validation rmse logD = 0.566014
Validation R2 logD = 0.767780
Validation rmse logP = 0.708896
Validation R2 logP = 0.760004
Epoch 83
Train function
Loss = 1.1760e-05, PNorm = 63.3725, GNorm = 0.0950, lr_0 = 1.4346e-04
Loss = 8.7578e-06, PNorm = 63.3744, GNorm = 0.1026, lr_0 = 1.4282e-04
Loss = 8.5102e-06, PNorm = 63.3757, GNorm = 0.0702, lr_0 = 1.4219e-04
Loss = 8.9713e-06, PNorm = 63.3768, GNorm = 0.1849, lr_0 = 1.4156e-04
Loss = 1.6114e-05, PNorm = 63.3770, GNorm = 0.2693, lr_0 = 1.4093e-04
Loss = 1.6008e-05, PNorm = 63.3787, GNorm = 0.0689, lr_0 = 1.4031e-04
Loss = 2.1205e-04, PNorm = 63.3789, GNorm = 0.3227, lr_0 = 1.4025e-04
Validation rmse logD = 0.567499
Validation R2 logD = 0.766559
Validation rmse logP = 0.708897
Validation R2 logP = 0.760003
Epoch 84
Train function
Loss = 1.4763e-05, PNorm = 63.3802, GNorm = 0.0747, lr_0 = 1.3963e-04
Loss = 1.0003e-05, PNorm = 63.3818, GNorm = 0.0560, lr_0 = 1.3901e-04
Loss = 1.4084e-05, PNorm = 63.3835, GNorm = 0.0767, lr_0 = 1.3840e-04
Loss = 1.1369e-05, PNorm = 63.3844, GNorm = 0.1313, lr_0 = 1.3778e-04
Loss = 1.1865e-05, PNorm = 63.3859, GNorm = 0.0599, lr_0 = 1.3717e-04
Validation rmse logD = 0.567499
Validation R2 logD = 0.766560
Validation rmse logP = 0.710565
Validation R2 logP = 0.758872
Epoch 85
Train function
Loss = 6.9237e-06, PNorm = 63.3866, GNorm = 0.0566, lr_0 = 1.3651e-04
Loss = 1.1760e-05, PNorm = 63.3875, GNorm = 0.1568, lr_0 = 1.3590e-04
Loss = 1.1737e-05, PNorm = 63.3891, GNorm = 0.1284, lr_0 = 1.3530e-04
Loss = 1.0515e-05, PNorm = 63.3899, GNorm = 0.0844, lr_0 = 1.3470e-04
Loss = 1.1233e-05, PNorm = 63.3907, GNorm = 0.1308, lr_0 = 1.3411e-04
Validation rmse logD = 0.566632
Validation R2 logD = 0.767273
Validation rmse logP = 0.709631
Validation R2 logP = 0.759506
Epoch 86
Train function
Loss = 7.0957e-06, PNorm = 63.3916, GNorm = 0.1315, lr_0 = 1.3346e-04
Loss = 7.3406e-06, PNorm = 63.3927, GNorm = 0.1008, lr_0 = 1.3287e-04
Loss = 8.4005e-06, PNorm = 63.3932, GNorm = 0.0908, lr_0 = 1.3228e-04
Loss = 9.3034e-06, PNorm = 63.3946, GNorm = 0.1164, lr_0 = 1.3169e-04
Loss = 7.4003e-06, PNorm = 63.3953, GNorm = 0.0672, lr_0 = 1.3111e-04
Validation rmse logD = 0.567087
Validation R2 logD = 0.766899
Validation rmse logP = 0.710401
Validation R2 logP = 0.758983
Epoch 87
Train function
Loss = 1.3063e-05, PNorm = 63.3957, GNorm = 0.2436, lr_0 = 1.3047e-04
Loss = 1.1620e-05, PNorm = 63.3970, GNorm = 0.2089, lr_0 = 1.2990e-04
Loss = 8.3816e-06, PNorm = 63.3972, GNorm = 0.2066, lr_0 = 1.2932e-04
Loss = 1.0414e-05, PNorm = 63.3980, GNorm = 0.0606, lr_0 = 1.2875e-04
Loss = 9.9069e-06, PNorm = 63.3988, GNorm = 0.0787, lr_0 = 1.2818e-04
Loss = 9.4005e-06, PNorm = 63.3995, GNorm = 0.0821, lr_0 = 1.2761e-04
Validation rmse logD = 0.565964
Validation R2 logD = 0.767821
Validation rmse logP = 0.711574
Validation R2 logP = 0.758187
Epoch 88
Train function
Loss = 1.1312e-05, PNorm = 63.4005, GNorm = 0.0942, lr_0 = 1.2699e-04
Loss = 9.5609e-06, PNorm = 63.4021, GNorm = 0.1325, lr_0 = 1.2643e-04
Loss = 9.7337e-06, PNorm = 63.4034, GNorm = 0.1633, lr_0 = 1.2587e-04
Loss = 1.4359e-05, PNorm = 63.4046, GNorm = 0.0962, lr_0 = 1.2531e-04
Loss = 8.5751e-06, PNorm = 63.4061, GNorm = 0.1272, lr_0 = 1.2476e-04
Validation rmse logD = 0.567717
Validation R2 logD = 0.766380
Validation rmse logP = 0.709213
Validation R2 logP = 0.759789
Epoch 89
Train function
Loss = 7.9863e-06, PNorm = 63.4068, GNorm = 0.0562, lr_0 = 1.2415e-04
Loss = 7.0512e-06, PNorm = 63.4074, GNorm = 0.0501, lr_0 = 1.2360e-04
Loss = 8.4279e-06, PNorm = 63.4083, GNorm = 0.0654, lr_0 = 1.2306e-04
Loss = 8.5611e-06, PNorm = 63.4092, GNorm = 0.0698, lr_0 = 1.2251e-04
Loss = 7.7775e-06, PNorm = 63.4104, GNorm = 0.0434, lr_0 = 1.2197e-04
Validation rmse logD = 0.567159
Validation R2 logD = 0.766840
Validation rmse logP = 0.707436
Validation R2 logP = 0.760991
Epoch 90
Train function
Loss = 4.8089e-06, PNorm = 63.4110, GNorm = 0.0739, lr_0 = 1.2143e-04
Loss = 8.6256e-06, PNorm = 63.4117, GNorm = 0.0589, lr_0 = 1.2089e-04
Loss = 7.8599e-06, PNorm = 63.4120, GNorm = 0.0689, lr_0 = 1.2036e-04
Loss = 8.5648e-06, PNorm = 63.4132, GNorm = 0.0719, lr_0 = 1.1983e-04
Loss = 1.2279e-05, PNorm = 63.4143, GNorm = 0.0483, lr_0 = 1.1930e-04
Loss = 9.0053e-06, PNorm = 63.4155, GNorm = 0.0376, lr_0 = 1.1877e-04
Validation rmse logD = 0.567822
Validation R2 logD = 0.766294
Validation rmse logP = 0.709014
Validation R2 logP = 0.759924
Epoch 91
Train function
Loss = 6.3998e-06, PNorm = 63.4168, GNorm = 0.0625, lr_0 = 1.1819e-04
Loss = 7.9488e-06, PNorm = 63.4173, GNorm = 0.1138, lr_0 = 1.1767e-04
Loss = 1.3367e-05, PNorm = 63.4189, GNorm = 0.2310, lr_0 = 1.1715e-04
Loss = 1.0614e-05, PNorm = 63.4191, GNorm = 0.1732, lr_0 = 1.1663e-04
Loss = 1.0007e-05, PNorm = 63.4197, GNorm = 0.0747, lr_0 = 1.1611e-04
Validation rmse logD = 0.567401
Validation R2 logD = 0.766641
Validation rmse logP = 0.707027
Validation R2 logP = 0.761268
Epoch 92
Train function
Loss = 9.5266e-06, PNorm = 63.4200, GNorm = 0.0610, lr_0 = 1.1555e-04
Loss = 1.0935e-05, PNorm = 63.4213, GNorm = 0.1596, lr_0 = 1.1504e-04
Loss = 6.9044e-06, PNorm = 63.4222, GNorm = 0.1136, lr_0 = 1.1453e-04
Loss = 6.4815e-06, PNorm = 63.4228, GNorm = 0.1439, lr_0 = 1.1402e-04
Loss = 8.2832e-06, PNorm = 63.4239, GNorm = 0.0668, lr_0 = 1.1352e-04
Validation rmse logD = 0.567462
Validation R2 logD = 0.766590
Validation rmse logP = 0.709839
Validation R2 logP = 0.759365
Epoch 93
Train function
Loss = 3.9380e-06, PNorm = 63.4250, GNorm = 0.1074, lr_0 = 1.1297e-04
Loss = 4.8614e-06, PNorm = 63.4254, GNorm = 0.0299, lr_0 = 1.1247e-04
Loss = 5.9528e-06, PNorm = 63.4262, GNorm = 0.0481, lr_0 = 1.1197e-04
Loss = 5.7463e-06, PNorm = 63.4270, GNorm = 0.0321, lr_0 = 1.1147e-04
Loss = 8.4923e-06, PNorm = 63.4277, GNorm = 0.0471, lr_0 = 1.1098e-04
Loss = 6.1847e-06, PNorm = 63.4285, GNorm = 0.0794, lr_0 = 1.1049e-04
Validation rmse logD = 0.567076
Validation R2 logD = 0.766907
Validation rmse logP = 0.708648
Validation R2 logP = 0.760172
Epoch 94
Train function
Loss = 5.0858e-06, PNorm = 63.4291, GNorm = 0.0370, lr_0 = 1.0995e-04
Loss = 9.2600e-06, PNorm = 63.4301, GNorm = 0.0823, lr_0 = 1.0947e-04
Loss = 6.3750e-06, PNorm = 63.4313, GNorm = 0.0809, lr_0 = 1.0898e-04
Loss = 6.5379e-06, PNorm = 63.4312, GNorm = 0.0525, lr_0 = 1.0850e-04
Loss = 5.9739e-06, PNorm = 63.4321, GNorm = 0.0537, lr_0 = 1.0802e-04
Validation rmse logD = 0.565982
Validation R2 logD = 0.767806
Validation rmse logP = 0.710320
Validation R2 logP = 0.759039
Epoch 95
Train function
Loss = 4.6515e-06, PNorm = 63.4325, GNorm = 0.0685, lr_0 = 1.0749e-04
Loss = 5.1268e-06, PNorm = 63.4332, GNorm = 0.1337, lr_0 = 1.0702e-04
Loss = 6.8387e-06, PNorm = 63.4336, GNorm = 0.0798, lr_0 = 1.0654e-04
Loss = 6.6310e-06, PNorm = 63.4345, GNorm = 0.0625, lr_0 = 1.0607e-04
Loss = 6.7659e-06, PNorm = 63.4358, GNorm = 0.1424, lr_0 = 1.0560e-04
Validation rmse logD = 0.566492
Validation R2 logD = 0.767388
Validation rmse logP = 0.708138
Validation R2 logP = 0.760517
Epoch 96
Train function
Loss = 6.9280e-06, PNorm = 63.4362, GNorm = 0.1296, lr_0 = 1.0509e-04
Loss = 5.4459e-06, PNorm = 63.4366, GNorm = 0.1528, lr_0 = 1.0463e-04
Loss = 5.5230e-06, PNorm = 63.4372, GNorm = 0.0371, lr_0 = 1.0416e-04
Loss = 7.0710e-06, PNorm = 63.4380, GNorm = 0.1203, lr_0 = 1.0370e-04
Loss = 5.4001e-06, PNorm = 63.4389, GNorm = 0.1505, lr_0 = 1.0324e-04
Loss = 5.3314e-06, PNorm = 63.4392, GNorm = 0.0938, lr_0 = 1.0279e-04
Loss = 2.5851e-05, PNorm = 63.4392, GNorm = 0.0875, lr_0 = 1.0274e-04
Validation rmse logD = 0.566945
Validation R2 logD = 0.767016
Validation rmse logP = 0.710143
Validation R2 logP = 0.759158
Epoch 97
Train function
Loss = 5.2027e-06, PNorm = 63.4400, GNorm = 0.0313, lr_0 = 1.0229e-04
Loss = 5.4270e-06, PNorm = 63.4408, GNorm = 0.0499, lr_0 = 1.0183e-04
Loss = 4.4620e-06, PNorm = 63.4412, GNorm = 0.0740, lr_0 = 1.0138e-04
Loss = 4.8476e-06, PNorm = 63.4421, GNorm = 0.0490, lr_0 = 1.0094e-04
Loss = 5.9837e-06, PNorm = 63.4431, GNorm = 0.0293, lr_0 = 1.0049e-04
Validation rmse logD = 0.567113
Validation R2 logD = 0.766877
Validation rmse logP = 0.708764
Validation R2 logP = 0.760093
Epoch 98
Train function
Loss = 4.1516e-06, PNorm = 63.4438, GNorm = 0.0325, lr_0 = 1.0000e-04
Loss = 5.1783e-06, PNorm = 63.4444, GNorm = 0.0726, lr_0 = 1.0000e-04
Loss = 5.3822e-06, PNorm = 63.4447, GNorm = 0.0402, lr_0 = 1.0000e-04
Loss = 5.5752e-06, PNorm = 63.4452, GNorm = 0.0349, lr_0 = 1.0000e-04
Loss = 5.3062e-06, PNorm = 63.4458, GNorm = 0.1199, lr_0 = 1.0000e-04
Validation rmse logD = 0.567362
Validation R2 logD = 0.766673
Validation rmse logP = 0.708982
Validation R2 logP = 0.759945
Epoch 99
Train function
Loss = 3.6938e-06, PNorm = 63.4461, GNorm = 0.0524, lr_0 = 1.0000e-04
Loss = 3.9657e-06, PNorm = 63.4468, GNorm = 0.0623, lr_0 = 1.0000e-04
Loss = 4.3473e-06, PNorm = 63.4473, GNorm = 0.0682, lr_0 = 1.0000e-04
Loss = 5.0669e-06, PNorm = 63.4479, GNorm = 0.0463, lr_0 = 1.0000e-04
Loss = 4.5124e-06, PNorm = 63.4490, GNorm = 0.0307, lr_0 = 1.0000e-04
Loss = 6.4490e-06, PNorm = 63.4500, GNorm = 0.1598, lr_0 = 1.0000e-04
Validation rmse logD = 0.567426
Validation R2 logD = 0.766620
Validation rmse logP = 0.709006
Validation R2 logP = 0.759929
Model 0 best validation rmse = 0.633713 on epoch 43
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.656390
Model 0 test R2 logD = 0.697406
Model 0 test rmse logP = 0.738606
Model 0 test R2 logP = 0.764433
Ensemble test rmse  logD= 0.656390
Ensemble test R2  logD= 0.697406
Ensemble test rmse  logP= 0.738606
Ensemble test R2  logP= 0.764433
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 1.9440e-02, PNorm = 52.9411, GNorm = 2.5300, lr_0 = 1.9340e-04
Loss = 1.8291e-02, PNorm = 52.9501, GNorm = 5.1823, lr_0 = 2.7830e-04
Loss = 1.6669e-02, PNorm = 52.9622, GNorm = 9.7306, lr_0 = 3.6321e-04
Loss = 1.3804e-02, PNorm = 52.9804, GNorm = 2.6876, lr_0 = 4.4811e-04
Loss = 1.4972e-02, PNorm = 53.0046, GNorm = 6.8352, lr_0 = 5.3302e-04
Validation rmse logD = 0.963402
Validation R2 logD = 0.363595
Validation rmse logP = 1.308407
Validation R2 logP = 0.157336
Epoch 1
Train function
Loss = 1.2111e-02, PNorm = 53.0347, GNorm = 1.1083, lr_0 = 6.2642e-04
Loss = 1.1663e-02, PNorm = 53.0696, GNorm = 4.0486, lr_0 = 7.1132e-04
Loss = 1.1913e-02, PNorm = 53.1134, GNorm = 3.9900, lr_0 = 7.9623e-04
Loss = 1.1867e-02, PNorm = 53.1597, GNorm = 2.1987, lr_0 = 8.8113e-04
Loss = 1.2266e-02, PNorm = 53.2191, GNorm = 1.2318, lr_0 = 9.6604e-04
Validation rmse logD = 1.116969
Validation R2 logD = 0.144538
Validation rmse logP = 1.172601
Validation R2 logP = 0.323186
Epoch 2
Train function
Loss = 1.3353e-02, PNorm = 53.2931, GNorm = 5.2518, lr_0 = 9.9690e-04
Loss = 1.0160e-02, PNorm = 53.3601, GNorm = 3.1784, lr_0 = 9.9249e-04
Loss = 9.8028e-03, PNorm = 53.4241, GNorm = 4.2973, lr_0 = 9.8810e-04
Loss = 9.1574e-03, PNorm = 53.4972, GNorm = 1.8379, lr_0 = 9.8373e-04
Loss = 9.4343e-03, PNorm = 53.5893, GNorm = 1.8800, lr_0 = 9.7938e-04
Validation rmse logD = 0.845822
Validation R2 logD = 0.509458
Validation rmse logP = 0.882777
Validation R2 logP = 0.616407
Epoch 3
Train function
Loss = 4.7543e-03, PNorm = 53.6912, GNorm = 1.4832, lr_0 = 9.7462e-04
Loss = 8.4278e-03, PNorm = 53.7941, GNorm = 3.0253, lr_0 = 9.7030e-04
Loss = 7.7650e-03, PNorm = 53.8820, GNorm = 1.2046, lr_0 = 9.6601e-04
Loss = 7.5771e-03, PNorm = 53.9828, GNorm = 2.4025, lr_0 = 9.6174e-04
Loss = 8.0548e-03, PNorm = 54.0746, GNorm = 1.4127, lr_0 = 9.5749e-04
Loss = 8.1099e-03, PNorm = 54.1726, GNorm = 1.5612, lr_0 = 9.5325e-04
Validation rmse logD = 0.810681
Validation R2 logD = 0.549371
Validation rmse logP = 0.866527
Validation R2 logP = 0.630399
Epoch 4
Train function
Loss = 6.9658e-03, PNorm = 54.2715, GNorm = 2.9296, lr_0 = 9.4861e-04
Loss = 6.6499e-03, PNorm = 54.3585, GNorm = 1.7334, lr_0 = 9.4442e-04
Loss = 6.9615e-03, PNorm = 54.4598, GNorm = 2.4719, lr_0 = 9.4024e-04
Loss = 6.6693e-03, PNorm = 54.5597, GNorm = 0.9314, lr_0 = 9.3608e-04
Loss = 5.9113e-03, PNorm = 54.6487, GNorm = 2.2725, lr_0 = 9.3194e-04
Validation rmse logD = 0.911035
Validation R2 logD = 0.430900
Validation rmse logP = 0.881331
Validation R2 logP = 0.617662
Epoch 5
Train function
Loss = 7.8196e-03, PNorm = 54.7315, GNorm = 5.2565, lr_0 = 9.2741e-04
Loss = 6.4328e-03, PNorm = 54.8186, GNorm = 1.5114, lr_0 = 9.2330e-04
Loss = 6.4057e-03, PNorm = 54.9012, GNorm = 2.1565, lr_0 = 9.1922e-04
Loss = 5.8214e-03, PNorm = 54.9946, GNorm = 1.5009, lr_0 = 9.1515e-04
Loss = 5.8334e-03, PNorm = 55.0827, GNorm = 1.4376, lr_0 = 9.1111e-04
Validation rmse logD = 0.721368
Validation R2 logD = 0.643193
Validation rmse logP = 0.862215
Validation R2 logP = 0.634068
Epoch 6
Train function
Loss = 5.5682e-03, PNorm = 55.1990, GNorm = 3.8788, lr_0 = 9.0667e-04
Loss = 4.4477e-03, PNorm = 55.2952, GNorm = 1.6656, lr_0 = 9.0266e-04
Loss = 5.1677e-03, PNorm = 55.3836, GNorm = 2.6515, lr_0 = 8.9867e-04
Loss = 4.5583e-03, PNorm = 55.4673, GNorm = 3.3040, lr_0 = 8.9469e-04
Loss = 4.7885e-03, PNorm = 55.5491, GNorm = 1.3672, lr_0 = 8.9074e-04
Loss = 5.1660e-03, PNorm = 55.6347, GNorm = 2.9192, lr_0 = 8.8680e-04
Validation rmse logD = 0.854839
Validation R2 logD = 0.498943
Validation rmse logP = 0.808893
Validation R2 logP = 0.677930
Epoch 7
Train function
Loss = 5.7978e-03, PNorm = 55.7469, GNorm = 4.1442, lr_0 = 8.8248e-04
Loss = 4.6207e-03, PNorm = 55.8497, GNorm = 2.9454, lr_0 = 8.7858e-04
Loss = 4.6337e-03, PNorm = 55.9440, GNorm = 1.0257, lr_0 = 8.7469e-04
Loss = 3.9837e-03, PNorm = 56.0351, GNorm = 1.0183, lr_0 = 8.7082e-04
Loss = 3.9065e-03, PNorm = 56.1074, GNorm = 1.0870, lr_0 = 8.6697e-04
Validation rmse logD = 0.703746
Validation R2 logD = 0.660414
Validation rmse logP = 0.782624
Validation R2 logP = 0.698508
Epoch 8
Train function
Loss = 3.4082e-03, PNorm = 56.2100, GNorm = 2.5482, lr_0 = 8.6276e-04
Loss = 3.8280e-03, PNorm = 56.2948, GNorm = 2.1629, lr_0 = 8.5894e-04
Loss = 3.5172e-03, PNorm = 56.3558, GNorm = 1.8925, lr_0 = 8.5514e-04
Loss = 3.0324e-03, PNorm = 56.4271, GNorm = 0.7236, lr_0 = 8.5136e-04
Loss = 4.0805e-03, PNorm = 56.5027, GNorm = 1.9329, lr_0 = 8.4759e-04
Validation rmse logD = 0.668468
Validation R2 logD = 0.693606
Validation rmse logP = 0.762258
Validation R2 logP = 0.713996
Epoch 9
Train function
Loss = 3.0625e-03, PNorm = 56.5952, GNorm = 2.2338, lr_0 = 8.4384e-04
Loss = 2.8601e-03, PNorm = 56.6840, GNorm = 0.9328, lr_0 = 8.4011e-04
Loss = 2.8615e-03, PNorm = 56.7587, GNorm = 0.7130, lr_0 = 8.3639e-04
Loss = 3.2306e-03, PNorm = 56.8474, GNorm = 1.8892, lr_0 = 8.3269e-04
Loss = 3.4294e-03, PNorm = 56.9234, GNorm = 1.8300, lr_0 = 8.2901e-04
Loss = 3.7700e-03, PNorm = 56.9902, GNorm = 0.7689, lr_0 = 8.2534e-04
Validation rmse logD = 0.660530
Validation R2 logD = 0.700840
Validation rmse logP = 0.784813
Validation R2 logP = 0.696820
Epoch 10
Train function
Loss = 3.0796e-03, PNorm = 57.0663, GNorm = 2.3972, lr_0 = 8.2133e-04
Loss = 2.8675e-03, PNorm = 57.1443, GNorm = 0.7316, lr_0 = 8.1770e-04
Loss = 2.7803e-03, PNorm = 57.2253, GNorm = 0.6706, lr_0 = 8.1408e-04
Loss = 2.7866e-03, PNorm = 57.2920, GNorm = 2.6119, lr_0 = 8.1048e-04
Loss = 3.0225e-03, PNorm = 57.3640, GNorm = 1.6905, lr_0 = 8.0689e-04
Validation rmse logD = 0.643315
Validation R2 logD = 0.716231
Validation rmse logP = 0.780765
Validation R2 logP = 0.699939
Epoch 11
Train function
Loss = 2.4561e-03, PNorm = 57.4451, GNorm = 1.5806, lr_0 = 8.0297e-04
Loss = 2.8269e-03, PNorm = 57.5140, GNorm = 1.5904, lr_0 = 7.9942e-04
Loss = 2.3238e-03, PNorm = 57.5900, GNorm = 0.9651, lr_0 = 7.9588e-04
Loss = 2.3545e-03, PNorm = 57.6605, GNorm = 1.1864, lr_0 = 7.9236e-04
Loss = 2.5832e-03, PNorm = 57.7228, GNorm = 2.1563, lr_0 = 7.8885e-04
Validation rmse logD = 0.639850
Validation R2 logD = 0.719279
Validation rmse logP = 0.737966
Validation R2 logP = 0.731934
Epoch 12
Train function
Loss = 2.0335e-03, PNorm = 57.8119, GNorm = 1.0407, lr_0 = 7.8502e-04
Loss = 1.9202e-03, PNorm = 57.8763, GNorm = 1.1778, lr_0 = 7.8154e-04
Loss = 2.0586e-03, PNorm = 57.9404, GNorm = 2.2423, lr_0 = 7.7809e-04
Loss = 2.2217e-03, PNorm = 58.0100, GNorm = 1.1520, lr_0 = 7.7465e-04
Loss = 2.2990e-03, PNorm = 58.0845, GNorm = 0.8360, lr_0 = 7.7122e-04
Loss = 2.4180e-03, PNorm = 58.1684, GNorm = 0.9355, lr_0 = 7.6781e-04
Loss = 2.1870e-02, PNorm = 58.1765, GNorm = 3.4305, lr_0 = 7.6747e-04
Validation rmse logD = 0.620951
Validation R2 logD = 0.735617
Validation rmse logP = 0.717682
Validation R2 logP = 0.746468
Epoch 13
Train function
Loss = 1.8867e-03, PNorm = 58.2595, GNorm = 1.5803, lr_0 = 7.6407e-04
Loss = 2.4055e-03, PNorm = 58.3407, GNorm = 2.8260, lr_0 = 7.6069e-04
Loss = 2.0772e-03, PNorm = 58.4177, GNorm = 0.9499, lr_0 = 7.5733e-04
Loss = 1.8202e-03, PNorm = 58.4866, GNorm = 1.8815, lr_0 = 7.5398e-04
Loss = 2.1186e-03, PNorm = 58.5398, GNorm = 0.6182, lr_0 = 7.5064e-04
Validation rmse logD = 0.617832
Validation R2 logD = 0.738266
Validation rmse logP = 0.720976
Validation R2 logP = 0.744136
Epoch 14
Train function
Loss = 1.6352e-03, PNorm = 58.6123, GNorm = 0.8539, lr_0 = 7.4699e-04
Loss = 1.7707e-03, PNorm = 58.6802, GNorm = 1.8106, lr_0 = 7.4369e-04
Loss = 1.5507e-03, PNorm = 58.7276, GNorm = 1.6963, lr_0 = 7.4040e-04
Loss = 1.6323e-03, PNorm = 58.7859, GNorm = 0.7446, lr_0 = 7.3712e-04
Loss = 1.7694e-03, PNorm = 58.8296, GNorm = 0.7448, lr_0 = 7.3386e-04
Validation rmse logD = 0.629370
Validation R2 logD = 0.728399
Validation rmse logP = 0.732633
Validation R2 logP = 0.735794
Epoch 15
Train function
Loss = 1.1616e-03, PNorm = 58.8848, GNorm = 0.9571, lr_0 = 7.3029e-04
Loss = 1.3599e-03, PNorm = 58.9367, GNorm = 0.6412, lr_0 = 7.2706e-04
Loss = 1.3967e-03, PNorm = 58.9941, GNorm = 0.5447, lr_0 = 7.2385e-04
Loss = 1.3192e-03, PNorm = 59.0391, GNorm = 0.7235, lr_0 = 7.2064e-04
Loss = 1.4640e-03, PNorm = 59.0815, GNorm = 0.9980, lr_0 = 7.1746e-04
Validation rmse logD = 0.618681
Validation R2 logD = 0.737546
Validation rmse logP = 0.695234
Validation R2 logP = 0.762080
Epoch 16
Train function
Loss = 1.2610e-03, PNorm = 59.1407, GNorm = 1.4115, lr_0 = 7.1397e-04
Loss = 1.0481e-03, PNorm = 59.1907, GNorm = 0.9852, lr_0 = 7.1081e-04
Loss = 1.2037e-03, PNorm = 59.2364, GNorm = 0.9450, lr_0 = 7.0766e-04
Loss = 1.2554e-03, PNorm = 59.2701, GNorm = 0.9080, lr_0 = 7.0453e-04
Loss = 1.4216e-03, PNorm = 59.3181, GNorm = 1.7554, lr_0 = 7.0142e-04
Loss = 1.3716e-03, PNorm = 59.3767, GNorm = 0.8172, lr_0 = 6.9831e-04
Validation rmse logD = 0.617682
Validation R2 logD = 0.738394
Validation rmse logP = 0.709957
Validation R2 logP = 0.751896
Epoch 17
Train function
Loss = 1.0380e-03, PNorm = 59.4284, GNorm = 1.3001, lr_0 = 6.9523e-04
Loss = 1.1550e-03, PNorm = 59.4751, GNorm = 1.7895, lr_0 = 6.9215e-04
Loss = 1.1440e-03, PNorm = 59.5233, GNorm = 0.9179, lr_0 = 6.8909e-04
Loss = 1.0212e-03, PNorm = 59.5733, GNorm = 0.7573, lr_0 = 6.8604e-04
Loss = 1.1050e-03, PNorm = 59.6083, GNorm = 0.6052, lr_0 = 6.8301e-04
Validation rmse logD = 0.638515
Validation R2 logD = 0.720449
Validation rmse logP = 0.702059
Validation R2 logP = 0.757386
Epoch 18
Train function
Loss = 1.0504e-03, PNorm = 59.6608, GNorm = 0.8417, lr_0 = 6.7968e-04
Loss = 1.2254e-03, PNorm = 59.7115, GNorm = 1.3938, lr_0 = 6.7668e-04
Loss = 1.1516e-03, PNorm = 59.7682, GNorm = 0.8529, lr_0 = 6.7368e-04
Loss = 1.0987e-03, PNorm = 59.8102, GNorm = 1.7813, lr_0 = 6.7070e-04
Loss = 1.0118e-03, PNorm = 59.8556, GNorm = 0.9319, lr_0 = 6.6774e-04
Validation rmse logD = 0.630309
Validation R2 logD = 0.727589
Validation rmse logP = 0.690304
Validation R2 logP = 0.765442
Epoch 19
Train function
Loss = 1.6054e-03, PNorm = 59.8884, GNorm = 1.9212, lr_0 = 6.6449e-04
Loss = 8.9531e-04, PNorm = 59.9190, GNorm = 0.4291, lr_0 = 6.6155e-04
Loss = 9.5427e-04, PNorm = 59.9635, GNorm = 1.6671, lr_0 = 6.5862e-04
Loss = 1.2073e-03, PNorm = 59.9972, GNorm = 1.5375, lr_0 = 6.5571e-04
Loss = 1.0347e-03, PNorm = 60.0509, GNorm = 0.8942, lr_0 = 6.5281e-04
Loss = 9.1481e-04, PNorm = 60.0957, GNorm = 0.5095, lr_0 = 6.4992e-04
Validation rmse logD = 0.606699
Validation R2 logD = 0.747614
Validation rmse logP = 0.701245
Validation R2 logP = 0.757948
Epoch 20
Train function
Loss = 7.8682e-04, PNorm = 60.1397, GNorm = 0.7577, lr_0 = 6.4676e-04
Loss = 7.7182e-04, PNorm = 60.1735, GNorm = 0.7142, lr_0 = 6.4390e-04
Loss = 9.1333e-04, PNorm = 60.2016, GNorm = 0.6772, lr_0 = 6.4105e-04
Loss = 8.0123e-04, PNorm = 60.2340, GNorm = 1.3406, lr_0 = 6.3822e-04
Loss = 1.0751e-03, PNorm = 60.2695, GNorm = 2.7255, lr_0 = 6.3539e-04
Validation rmse logD = 0.596701
Validation R2 logD = 0.755864
Validation rmse logP = 0.705632
Validation R2 logP = 0.754910
Epoch 21
Train function
Loss = 5.9645e-04, PNorm = 60.3023, GNorm = 0.4584, lr_0 = 6.3230e-04
Loss = 7.2493e-04, PNorm = 60.3461, GNorm = 0.5157, lr_0 = 6.2950e-04
Loss = 6.8712e-04, PNorm = 60.3797, GNorm = 0.5162, lr_0 = 6.2672e-04
Loss = 6.8803e-04, PNorm = 60.4100, GNorm = 0.4900, lr_0 = 6.2395e-04
Loss = 6.7613e-04, PNorm = 60.4426, GNorm = 0.8310, lr_0 = 6.2119e-04
Validation rmse logD = 0.602500
Validation R2 logD = 0.751096
Validation rmse logP = 0.688625
Validation R2 logP = 0.766582
Epoch 22
Train function
Loss = 4.5884e-04, PNorm = 60.4733, GNorm = 0.6259, lr_0 = 6.1817e-04
Loss = 6.2507e-04, PNorm = 60.5078, GNorm = 0.4018, lr_0 = 6.1543e-04
Loss = 6.3903e-04, PNorm = 60.5420, GNorm = 0.4984, lr_0 = 6.1271e-04
Loss = 6.2705e-04, PNorm = 60.5692, GNorm = 1.3642, lr_0 = 6.1000e-04
Loss = 7.5663e-04, PNorm = 60.5999, GNorm = 0.9571, lr_0 = 6.0730e-04
Loss = 7.1699e-04, PNorm = 60.6318, GNorm = 1.7680, lr_0 = 6.0461e-04
Validation rmse logD = 0.602146
Validation R2 logD = 0.751388
Validation rmse logP = 0.686498
Validation R2 logP = 0.768022
Epoch 23
Train function
Loss = 6.2500e-04, PNorm = 60.6728, GNorm = 0.3656, lr_0 = 6.0167e-04
Loss = 6.1440e-04, PNorm = 60.6984, GNorm = 0.3754, lr_0 = 5.9901e-04
Loss = 5.3746e-04, PNorm = 60.7212, GNorm = 0.6822, lr_0 = 5.9636e-04
Loss = 6.6141e-04, PNorm = 60.7460, GNorm = 0.4723, lr_0 = 5.9372e-04
Loss = 6.1013e-04, PNorm = 60.7734, GNorm = 0.3652, lr_0 = 5.9110e-04
Validation rmse logD = 0.607172
Validation R2 logD = 0.747220
Validation rmse logP = 0.715559
Validation R2 logP = 0.747966
Epoch 24
Train function
Loss = 4.8933e-04, PNorm = 60.8060, GNorm = 0.3542, lr_0 = 5.8822e-04
Loss = 4.5115e-04, PNorm = 60.8296, GNorm = 0.3853, lr_0 = 5.8562e-04
Loss = 4.3602e-04, PNorm = 60.8542, GNorm = 0.3704, lr_0 = 5.8303e-04
Loss = 5.1174e-04, PNorm = 60.8778, GNorm = 1.2667, lr_0 = 5.8045e-04
Loss = 4.9727e-04, PNorm = 60.8976, GNorm = 0.7119, lr_0 = 5.7788e-04
Validation rmse logD = 0.601193
Validation R2 logD = 0.752174
Validation rmse logP = 0.681584
Validation R2 logP = 0.771331
Epoch 25
Train function
Loss = 2.8481e-04, PNorm = 60.9172, GNorm = 0.3787, lr_0 = 5.7533e-04
Loss = 4.0226e-04, PNorm = 60.9380, GNorm = 0.5626, lr_0 = 5.7278e-04
Loss = 3.7719e-04, PNorm = 60.9608, GNorm = 0.3982, lr_0 = 5.7025e-04
Loss = 4.3114e-04, PNorm = 60.9811, GNorm = 0.3437, lr_0 = 5.6773e-04
Loss = 4.2028e-04, PNorm = 60.9999, GNorm = 0.2891, lr_0 = 5.6522e-04
Loss = 5.1671e-04, PNorm = 61.0235, GNorm = 0.8653, lr_0 = 5.6272e-04
Validation rmse logD = 0.594650
Validation R2 logD = 0.757539
Validation rmse logP = 0.690917
Validation R2 logP = 0.765026
Epoch 26
Train function
Loss = 3.4733e-04, PNorm = 61.0445, GNorm = 0.6890, lr_0 = 5.5998e-04
Loss = 4.0538e-04, PNorm = 61.0608, GNorm = 0.6019, lr_0 = 5.5750e-04
Loss = 4.3611e-04, PNorm = 61.0819, GNorm = 0.9901, lr_0 = 5.5503e-04
Loss = 4.9194e-04, PNorm = 61.1054, GNorm = 0.5310, lr_0 = 5.5258e-04
Loss = 4.6311e-04, PNorm = 61.1305, GNorm = 0.7474, lr_0 = 5.5014e-04
Validation rmse logD = 0.604290
Validation R2 logD = 0.749614
Validation rmse logP = 0.687059
Validation R2 logP = 0.767643
Epoch 27
Train function
Loss = 4.5438e-04, PNorm = 61.1592, GNorm = 0.5216, lr_0 = 5.4746e-04
Loss = 4.2326e-04, PNorm = 61.1779, GNorm = 0.7626, lr_0 = 5.4504e-04
Loss = 3.6221e-04, PNorm = 61.2011, GNorm = 0.7892, lr_0 = 5.4263e-04
Loss = 3.5537e-04, PNorm = 61.2187, GNorm = 0.9789, lr_0 = 5.4023e-04
Loss = 4.8851e-04, PNorm = 61.2343, GNorm = 1.5391, lr_0 = 5.3784e-04
Validation rmse logD = 0.620261
Validation R2 logD = 0.736205
Validation rmse logP = 0.698845
Validation R2 logP = 0.759602
Epoch 28
Train function
Loss = 6.5845e-04, PNorm = 61.2650, GNorm = 0.7538, lr_0 = 5.3522e-04
Loss = 6.5830e-04, PNorm = 61.2996, GNorm = 1.5825, lr_0 = 5.3285e-04
Loss = 5.8597e-04, PNorm = 61.3247, GNorm = 0.8919, lr_0 = 5.3050e-04
Loss = 6.9589e-04, PNorm = 61.3549, GNorm = 1.5078, lr_0 = 5.2815e-04
Loss = 5.4430e-04, PNorm = 61.3876, GNorm = 1.1434, lr_0 = 5.2581e-04
Loss = 5.2046e-04, PNorm = 61.4149, GNorm = 0.7067, lr_0 = 5.2349e-04
Loss = 2.5038e-03, PNorm = 61.4172, GNorm = 1.0809, lr_0 = 5.2326e-04
Validation rmse logD = 0.602432
Validation R2 logD = 0.751152
Validation rmse logP = 0.697053
Validation R2 logP = 0.760833
Epoch 29
Train function
Loss = 5.1241e-04, PNorm = 61.4414, GNorm = 0.9852, lr_0 = 5.2094e-04
Loss = 4.1778e-04, PNorm = 61.4534, GNorm = 0.4482, lr_0 = 5.1864e-04
Loss = 5.3551e-04, PNorm = 61.4743, GNorm = 0.9829, lr_0 = 5.1634e-04
Loss = 4.2410e-04, PNorm = 61.4943, GNorm = 0.3842, lr_0 = 5.1406e-04
Loss = 2.9659e-04, PNorm = 61.5112, GNorm = 0.4100, lr_0 = 5.1178e-04
Validation rmse logD = 0.600076
Validation R2 logD = 0.753094
Validation rmse logP = 0.691870
Validation R2 logP = 0.764377
Epoch 30
Train function
Loss = 3.5819e-04, PNorm = 61.5285, GNorm = 0.2711, lr_0 = 5.0930e-04
Loss = 3.8771e-04, PNorm = 61.5422, GNorm = 0.5991, lr_0 = 5.0704e-04
Loss = 4.9762e-04, PNorm = 61.5638, GNorm = 1.2158, lr_0 = 5.0480e-04
Loss = 4.4660e-04, PNorm = 61.5856, GNorm = 0.7703, lr_0 = 5.0257e-04
Loss = 3.6925e-04, PNorm = 61.6038, GNorm = 0.3336, lr_0 = 5.0034e-04
Validation rmse logD = 0.592423
Validation R2 logD = 0.759352
Validation rmse logP = 0.688611
Validation R2 logP = 0.766591
Epoch 31
Train function
Loss = 2.9335e-04, PNorm = 61.6181, GNorm = 0.3806, lr_0 = 4.9791e-04
Loss = 4.2838e-04, PNorm = 61.6343, GNorm = 0.4537, lr_0 = 4.9571e-04
Loss = 3.1396e-04, PNorm = 61.6508, GNorm = 0.3059, lr_0 = 4.9351e-04
Loss = 2.9348e-04, PNorm = 61.6715, GNorm = 0.2557, lr_0 = 4.9133e-04
Loss = 2.6784e-04, PNorm = 61.6850, GNorm = 0.2669, lr_0 = 4.8916e-04
Validation rmse logD = 0.594743
Validation R2 logD = 0.757463
Validation rmse logP = 0.685806
Validation R2 logP = 0.768489
Epoch 32
Train function
Loss = 2.6374e-04, PNorm = 61.6938, GNorm = 0.2701, lr_0 = 4.8678e-04
Loss = 2.9872e-04, PNorm = 61.7089, GNorm = 0.3013, lr_0 = 4.8463e-04
Loss = 2.0820e-04, PNorm = 61.7260, GNorm = 0.2633, lr_0 = 4.8248e-04
Loss = 2.2935e-04, PNorm = 61.7346, GNorm = 0.2724, lr_0 = 4.8035e-04
Loss = 2.3359e-04, PNorm = 61.7450, GNorm = 0.2675, lr_0 = 4.7822e-04
Loss = 2.4060e-04, PNorm = 61.7573, GNorm = 0.5062, lr_0 = 4.7611e-04
Validation rmse logD = 0.597705
Validation R2 logD = 0.755042
Validation rmse logP = 0.695857
Validation R2 logP = 0.761653
Epoch 33
Train function
Loss = 2.2237e-04, PNorm = 61.7672, GNorm = 0.6743, lr_0 = 4.7379e-04
Loss = 2.3233e-04, PNorm = 61.7813, GNorm = 0.2986, lr_0 = 4.7170e-04
Loss = 2.7537e-04, PNorm = 61.7947, GNorm = 0.2324, lr_0 = 4.6961e-04
Loss = 2.4164e-04, PNorm = 61.8045, GNorm = 0.3671, lr_0 = 4.6753e-04
Loss = 2.8197e-04, PNorm = 61.8154, GNorm = 0.3197, lr_0 = 4.6546e-04
Validation rmse logD = 0.589523
Validation R2 logD = 0.761702
Validation rmse logP = 0.689821
Validation R2 logP = 0.765771
Epoch 34
Train function
Loss = 1.8882e-04, PNorm = 61.8285, GNorm = 0.2889, lr_0 = 4.6341e-04
Loss = 1.6283e-04, PNorm = 61.8418, GNorm = 0.2717, lr_0 = 4.6136e-04
Loss = 1.7786e-04, PNorm = 61.8483, GNorm = 0.2298, lr_0 = 4.5931e-04
Loss = 1.7151e-04, PNorm = 61.8584, GNorm = 0.2735, lr_0 = 4.5728e-04
Loss = 1.9506e-04, PNorm = 61.8610, GNorm = 0.5671, lr_0 = 4.5526e-04
Validation rmse logD = 0.595320
Validation R2 logD = 0.756993
Validation rmse logP = 0.683898
Validation R2 logP = 0.769775
Epoch 35
Train function
Loss = 6.4757e-05, PNorm = 61.8682, GNorm = 0.1446, lr_0 = 4.5305e-04
Loss = 1.5784e-04, PNorm = 61.8768, GNorm = 0.1894, lr_0 = 4.5104e-04
Loss = 1.7780e-04, PNorm = 61.8874, GNorm = 0.8419, lr_0 = 4.4905e-04
Loss = 1.4902e-04, PNorm = 61.8984, GNorm = 0.4556, lr_0 = 4.4706e-04
Loss = 1.7322e-04, PNorm = 61.9069, GNorm = 0.2635, lr_0 = 4.4508e-04
Loss = 1.8409e-04, PNorm = 61.9150, GNorm = 0.3298, lr_0 = 4.4311e-04
Validation rmse logD = 0.593601
Validation R2 logD = 0.758394
Validation rmse logP = 0.691113
Validation R2 logP = 0.764892
Epoch 36
Train function
Loss = 1.6277e-04, PNorm = 61.9259, GNorm = 0.3117, lr_0 = 4.4096e-04
Loss = 2.4247e-04, PNorm = 61.9404, GNorm = 0.5245, lr_0 = 4.3901e-04
Loss = 2.5567e-04, PNorm = 61.9502, GNorm = 0.5584, lr_0 = 4.3707e-04
Loss = 2.1676e-04, PNorm = 61.9670, GNorm = 0.8269, lr_0 = 4.3513e-04
Loss = 1.8622e-04, PNorm = 61.9791, GNorm = 0.6406, lr_0 = 4.3321e-04
Validation rmse logD = 0.594664
Validation R2 logD = 0.757528
Validation rmse logP = 0.693217
Validation R2 logP = 0.763459
Epoch 37
Train function
Loss = 2.5891e-04, PNorm = 61.9932, GNorm = 0.5977, lr_0 = 4.3110e-04
Loss = 2.5391e-04, PNorm = 62.0064, GNorm = 0.5653, lr_0 = 4.2919e-04
Loss = 2.1587e-04, PNorm = 62.0155, GNorm = 0.5802, lr_0 = 4.2729e-04
Loss = 2.1249e-04, PNorm = 62.0254, GNorm = 0.2636, lr_0 = 4.2540e-04
Loss = 1.9868e-04, PNorm = 62.0393, GNorm = 0.5063, lr_0 = 4.2352e-04
Validation rmse logD = 0.598777
Validation R2 logD = 0.754162
Validation rmse logP = 0.690531
Validation R2 logP = 0.765288
Epoch 38
Train function
Loss = 1.3445e-04, PNorm = 62.0482, GNorm = 0.3459, lr_0 = 4.2146e-04
Loss = 1.3922e-04, PNorm = 62.0573, GNorm = 0.2864, lr_0 = 4.1960e-04
Loss = 1.2879e-04, PNorm = 62.0679, GNorm = 0.2082, lr_0 = 4.1774e-04
Loss = 1.5174e-04, PNorm = 62.0744, GNorm = 0.6063, lr_0 = 4.1589e-04
Loss = 1.3195e-04, PNorm = 62.0819, GNorm = 0.2177, lr_0 = 4.1406e-04
Loss = 1.7351e-04, PNorm = 62.0905, GNorm = 0.3035, lr_0 = 4.1222e-04
Validation rmse logD = 0.595048
Validation R2 logD = 0.757215
Validation rmse logP = 0.691377
Validation R2 logP = 0.764713
Epoch 39
Train function
Loss = 1.2678e-04, PNorm = 62.1000, GNorm = 0.2016, lr_0 = 4.1022e-04
Loss = 1.6024e-04, PNorm = 62.1026, GNorm = 0.4249, lr_0 = 4.0840e-04
Loss = 1.5100e-04, PNorm = 62.1141, GNorm = 0.2540, lr_0 = 4.0660e-04
Loss = 1.4293e-04, PNorm = 62.1207, GNorm = 0.2033, lr_0 = 4.0480e-04
Loss = 1.4790e-04, PNorm = 62.1302, GNorm = 0.2008, lr_0 = 4.0301e-04
Validation rmse logD = 0.596032
Validation R2 logD = 0.756411
Validation rmse logP = 0.687694
Validation R2 logP = 0.767213
Epoch 40
Train function
Loss = 1.1934e-04, PNorm = 62.1390, GNorm = 0.2236, lr_0 = 4.0105e-04
Loss = 1.3565e-04, PNorm = 62.1494, GNorm = 0.2251, lr_0 = 3.9927e-04
Loss = 1.2712e-04, PNorm = 62.1582, GNorm = 0.2663, lr_0 = 3.9751e-04
Loss = 1.3947e-04, PNorm = 62.1642, GNorm = 0.4192, lr_0 = 3.9575e-04
Loss = 1.3861e-04, PNorm = 62.1727, GNorm = 0.2582, lr_0 = 3.9400e-04
Validation rmse logD = 0.598714
Validation R2 logD = 0.754214
Validation rmse logP = 0.683193
Validation R2 logP = 0.770250
Epoch 41
Train function
Loss = 1.1690e-04, PNorm = 62.1785, GNorm = 0.1194, lr_0 = 3.9208e-04
Loss = 1.3557e-04, PNorm = 62.1882, GNorm = 0.3840, lr_0 = 3.9035e-04
Loss = 1.2161e-04, PNorm = 62.1948, GNorm = 0.3075, lr_0 = 3.8862e-04
Loss = 1.2143e-04, PNorm = 62.2036, GNorm = 0.6136, lr_0 = 3.8690e-04
Loss = 1.2393e-04, PNorm = 62.2125, GNorm = 0.4449, lr_0 = 3.8519e-04
Loss = 1.7023e-04, PNorm = 62.2225, GNorm = 0.2868, lr_0 = 3.8349e-04
Validation rmse logD = 0.591416
Validation R2 logD = 0.760169
Validation rmse logP = 0.690318
Validation R2 logP = 0.765433
Epoch 42
Train function
Loss = 1.0442e-04, PNorm = 62.2290, GNorm = 0.6825, lr_0 = 3.8179e-04
Loss = 1.4320e-04, PNorm = 62.2378, GNorm = 0.4433, lr_0 = 3.8010e-04
Loss = 1.2058e-04, PNorm = 62.2443, GNorm = 0.2921, lr_0 = 3.7842e-04
Loss = 1.3329e-04, PNorm = 62.2516, GNorm = 0.4155, lr_0 = 3.7675e-04
Loss = 1.3626e-04, PNorm = 62.2585, GNorm = 0.7969, lr_0 = 3.7508e-04
Validation rmse logD = 0.595252
Validation R2 logD = 0.757048
Validation rmse logP = 0.692486
Validation R2 logP = 0.763957
Epoch 43
Train function
Loss = 1.1224e-04, PNorm = 62.2639, GNorm = 0.6583, lr_0 = 3.7326e-04
Loss = 1.1314e-04, PNorm = 62.2741, GNorm = 0.4477, lr_0 = 3.7160e-04
Loss = 1.0393e-04, PNorm = 62.2828, GNorm = 0.2145, lr_0 = 3.6996e-04
Loss = 9.7287e-05, PNorm = 62.2901, GNorm = 0.3329, lr_0 = 3.6832e-04
Loss = 9.1589e-05, PNorm = 62.2921, GNorm = 0.2012, lr_0 = 3.6669e-04
Validation rmse logD = 0.595023
Validation R2 logD = 0.757235
Validation rmse logP = 0.688696
Validation R2 logP = 0.766534
Epoch 44
Train function
Loss = 8.8878e-05, PNorm = 62.2981, GNorm = 0.1594, lr_0 = 3.6491e-04
Loss = 7.7822e-05, PNorm = 62.3054, GNorm = 0.1435, lr_0 = 3.6330e-04
Loss = 7.7964e-05, PNorm = 62.3090, GNorm = 0.1572, lr_0 = 3.6169e-04
Loss = 8.0055e-05, PNorm = 62.3153, GNorm = 0.2333, lr_0 = 3.6009e-04
Loss = 8.9824e-05, PNorm = 62.3206, GNorm = 0.3083, lr_0 = 3.5850e-04
Loss = 9.2067e-05, PNorm = 62.3259, GNorm = 0.4079, lr_0 = 3.5691e-04
Loss = 6.9073e-04, PNorm = 62.3264, GNorm = 0.7420, lr_0 = 3.5675e-04
Validation rmse logD = 0.593988
Validation R2 logD = 0.758079
Validation rmse logP = 0.687708
Validation R2 logP = 0.767203
Epoch 45
Train function
Loss = 1.0059e-04, PNorm = 62.3325, GNorm = 0.2850, lr_0 = 3.5518e-04
Loss = 8.2263e-05, PNorm = 62.3365, GNorm = 0.1571, lr_0 = 3.5360e-04
Loss = 8.2475e-05, PNorm = 62.3398, GNorm = 0.1591, lr_0 = 3.5204e-04
Loss = 8.6565e-05, PNorm = 62.3464, GNorm = 0.2082, lr_0 = 3.5048e-04
Loss = 8.8795e-05, PNorm = 62.3523, GNorm = 0.3579, lr_0 = 3.4893e-04
Validation rmse logD = 0.593073
Validation R2 logD = 0.758824
Validation rmse logP = 0.686071
Validation R2 logP = 0.768310
Epoch 46
Train function
Loss = 6.9855e-05, PNorm = 62.3591, GNorm = 0.2321, lr_0 = 3.4724e-04
Loss = 7.9150e-05, PNorm = 62.3638, GNorm = 0.2532, lr_0 = 3.4570e-04
Loss = 7.1785e-05, PNorm = 62.3684, GNorm = 0.2365, lr_0 = 3.4417e-04
Loss = 6.6801e-05, PNorm = 62.3746, GNorm = 0.3509, lr_0 = 3.4265e-04
Loss = 1.0443e-04, PNorm = 62.3803, GNorm = 0.5242, lr_0 = 3.4113e-04
Validation rmse logD = 0.591843
Validation R2 logD = 0.759823
Validation rmse logP = 0.691461
Validation R2 logP = 0.764655
Epoch 47
Train function
Loss = 8.3523e-05, PNorm = 62.3840, GNorm = 0.5812, lr_0 = 3.3947e-04
Loss = 1.0029e-04, PNorm = 62.3912, GNorm = 0.1354, lr_0 = 3.3797e-04
Loss = 7.3148e-05, PNorm = 62.3960, GNorm = 0.1379, lr_0 = 3.3648e-04
Loss = 7.6808e-05, PNorm = 62.4020, GNorm = 0.3313, lr_0 = 3.3499e-04
Loss = 7.9883e-05, PNorm = 62.4085, GNorm = 0.1728, lr_0 = 3.3351e-04
Validation rmse logD = 0.596652
Validation R2 logD = 0.755904
Validation rmse logP = 0.691984
Validation R2 logP = 0.764299
Epoch 48
Train function
Loss = 8.4961e-05, PNorm = 62.4153, GNorm = 0.2723, lr_0 = 3.3188e-04
Loss = 1.0513e-04, PNorm = 62.4208, GNorm = 0.4413, lr_0 = 3.3042e-04
Loss = 1.4855e-04, PNorm = 62.4282, GNorm = 1.0421, lr_0 = 3.2895e-04
Loss = 1.3023e-04, PNorm = 62.4380, GNorm = 0.2307, lr_0 = 3.2750e-04
Loss = 1.0943e-04, PNorm = 62.4446, GNorm = 0.1848, lr_0 = 3.2605e-04
Loss = 8.5950e-05, PNorm = 62.4538, GNorm = 0.4431, lr_0 = 3.2461e-04
Validation rmse logD = 0.600777
Validation R2 logD = 0.752517
Validation rmse logP = 0.688377
Validation R2 logP = 0.766750
Epoch 49
Train function
Loss = 1.0806e-04, PNorm = 62.4677, GNorm = 0.3191, lr_0 = 3.2303e-04
Loss = 1.3842e-04, PNorm = 62.4715, GNorm = 0.2102, lr_0 = 3.2160e-04
Loss = 1.1309e-04, PNorm = 62.4788, GNorm = 0.5130, lr_0 = 3.2018e-04
Loss = 9.4515e-05, PNorm = 62.4867, GNorm = 0.5434, lr_0 = 3.1876e-04
Loss = 9.1014e-05, PNorm = 62.4925, GNorm = 0.4126, lr_0 = 3.1735e-04
Validation rmse logD = 0.596278
Validation R2 logD = 0.756210
Validation rmse logP = 0.688123
Validation R2 logP = 0.766923
Epoch 50
Train function
Loss = 7.4615e-05, PNorm = 62.4945, GNorm = 0.1494, lr_0 = 3.1595e-04
Loss = 8.8266e-05, PNorm = 62.5012, GNorm = 0.1361, lr_0 = 3.1455e-04
Loss = 7.3071e-05, PNorm = 62.5088, GNorm = 0.3905, lr_0 = 3.1316e-04
Loss = 8.1386e-05, PNorm = 62.5114, GNorm = 0.2019, lr_0 = 3.1177e-04
Loss = 9.0088e-05, PNorm = 62.5156, GNorm = 0.2583, lr_0 = 3.1039e-04
Validation rmse logD = 0.592487
Validation R2 logD = 0.759300
Validation rmse logP = 0.687592
Validation R2 logP = 0.767282
Epoch 51
Train function
Loss = 3.6022e-05, PNorm = 62.5215, GNorm = 0.1120, lr_0 = 3.0888e-04
Loss = 6.9435e-05, PNorm = 62.5274, GNorm = 0.2111, lr_0 = 3.0752e-04
Loss = 8.3285e-05, PNorm = 62.5316, GNorm = 0.1844, lr_0 = 3.0616e-04
Loss = 6.4795e-05, PNorm = 62.5373, GNorm = 0.1171, lr_0 = 3.0480e-04
Loss = 6.9706e-05, PNorm = 62.5420, GNorm = 0.3291, lr_0 = 3.0346e-04
Loss = 7.7121e-05, PNorm = 62.5465, GNorm = 0.1297, lr_0 = 3.0211e-04
Validation rmse logD = 0.597445
Validation R2 logD = 0.755255
Validation rmse logP = 0.686328
Validation R2 logP = 0.768137
Epoch 52
Train function
Loss = 6.9790e-05, PNorm = 62.5513, GNorm = 0.4909, lr_0 = 3.0064e-04
Loss = 7.7242e-05, PNorm = 62.5538, GNorm = 0.5722, lr_0 = 2.9931e-04
Loss = 6.6586e-05, PNorm = 62.5595, GNorm = 0.6823, lr_0 = 2.9799e-04
Loss = 6.6696e-05, PNorm = 62.5654, GNorm = 0.1627, lr_0 = 2.9667e-04
Loss = 7.0648e-05, PNorm = 62.5698, GNorm = 0.2335, lr_0 = 2.9536e-04
Validation rmse logD = 0.596322
Validation R2 logD = 0.756174
Validation rmse logP = 0.686684
Validation R2 logP = 0.767896
Epoch 53
Train function
Loss = 6.4679e-05, PNorm = 62.5738, GNorm = 0.1344, lr_0 = 2.9392e-04
Loss = 6.0243e-05, PNorm = 62.5753, GNorm = 0.2411, lr_0 = 2.9262e-04
Loss = 7.0806e-05, PNorm = 62.5793, GNorm = 0.1752, lr_0 = 2.9133e-04
Loss = 3.8612e-05, PNorm = 62.5847, GNorm = 0.1569, lr_0 = 2.9004e-04
Loss = 6.4684e-05, PNorm = 62.5894, GNorm = 0.1834, lr_0 = 2.8876e-04
Validation rmse logD = 0.596472
Validation R2 logD = 0.756052
Validation rmse logP = 0.685571
Validation R2 logP = 0.768648
Epoch 54
Train function
Loss = 4.3101e-05, PNorm = 62.5940, GNorm = 0.1585, lr_0 = 2.8735e-04
Loss = 3.4399e-05, PNorm = 62.5974, GNorm = 0.1751, lr_0 = 2.8608e-04
Loss = 5.1900e-05, PNorm = 62.6009, GNorm = 0.4155, lr_0 = 2.8482e-04
Loss = 5.7319e-05, PNorm = 62.6024, GNorm = 0.3414, lr_0 = 2.8356e-04
Loss = 5.0264e-05, PNorm = 62.6091, GNorm = 0.2250, lr_0 = 2.8230e-04
Loss = 5.9344e-05, PNorm = 62.6129, GNorm = 0.0996, lr_0 = 2.8105e-04
Validation rmse logD = 0.595566
Validation R2 logD = 0.756792
Validation rmse logP = 0.689389
Validation R2 logP = 0.766064
Epoch 55
Train function
Loss = 4.7504e-05, PNorm = 62.6180, GNorm = 0.2313, lr_0 = 2.7969e-04
Loss = 5.3500e-05, PNorm = 62.6192, GNorm = 0.1004, lr_0 = 2.7845e-04
Loss = 4.4236e-05, PNorm = 62.6220, GNorm = 0.3373, lr_0 = 2.7722e-04
Loss = 4.0516e-05, PNorm = 62.6252, GNorm = 0.2983, lr_0 = 2.7599e-04
Loss = 4.8433e-05, PNorm = 62.6288, GNorm = 0.1181, lr_0 = 2.7477e-04
Validation rmse logD = 0.595360
Validation R2 logD = 0.756960
Validation rmse logP = 0.685836
Validation R2 logP = 0.768469
Epoch 56
Train function
Loss = 6.1278e-05, PNorm = 62.6304, GNorm = 0.2325, lr_0 = 2.7343e-04
Loss = 8.4847e-05, PNorm = 62.6365, GNorm = 0.4527, lr_0 = 2.7222e-04
Loss = 7.1319e-05, PNorm = 62.6395, GNorm = 0.7737, lr_0 = 2.7102e-04
Loss = 8.1160e-05, PNorm = 62.6398, GNorm = 0.2554, lr_0 = 2.6982e-04
Loss = 7.1049e-05, PNorm = 62.6466, GNorm = 0.1886, lr_0 = 2.6863e-04
Validation rmse logD = 0.599332
Validation R2 logD = 0.753706
Validation rmse logP = 0.687732
Validation R2 logP = 0.767187
Epoch 57
Train function
Loss = 4.7674e-05, PNorm = 62.6527, GNorm = 0.2451, lr_0 = 2.6732e-04
Loss = 4.6197e-05, PNorm = 62.6560, GNorm = 0.1815, lr_0 = 2.6614e-04
Loss = 4.4446e-05, PNorm = 62.6600, GNorm = 0.0921, lr_0 = 2.6496e-04
Loss = 4.3712e-05, PNorm = 62.6630, GNorm = 0.1238, lr_0 = 2.6379e-04
Loss = 4.6789e-05, PNorm = 62.6670, GNorm = 0.1400, lr_0 = 2.6262e-04
Loss = 4.5400e-05, PNorm = 62.6701, GNorm = 0.1454, lr_0 = 2.6146e-04
Loss = 3.4124e-04, PNorm = 62.6707, GNorm = 0.3244, lr_0 = 2.6134e-04
Validation rmse logD = 0.596419
Validation R2 logD = 0.756095
Validation rmse logP = 0.692883
Validation R2 logP = 0.763686
Epoch 58
Train function
Loss = 4.7868e-05, PNorm = 62.6746, GNorm = 0.1990, lr_0 = 2.6019e-04
Loss = 4.9085e-05, PNorm = 62.6796, GNorm = 0.1405, lr_0 = 2.5904e-04
Loss = 3.9718e-05, PNorm = 62.6830, GNorm = 0.1648, lr_0 = 2.5789e-04
Loss = 3.7875e-05, PNorm = 62.6856, GNorm = 0.0903, lr_0 = 2.5675e-04
Loss = 3.2763e-05, PNorm = 62.6870, GNorm = 0.1217, lr_0 = 2.5561e-04
Validation rmse logD = 0.595507
Validation R2 logD = 0.756840
Validation rmse logP = 0.691569
Validation R2 logP = 0.764582
Epoch 59
Train function
Loss = 3.9024e-05, PNorm = 62.6899, GNorm = 0.4082, lr_0 = 2.5448e-04
Loss = 3.2009e-05, PNorm = 62.6942, GNorm = 0.2321, lr_0 = 2.5336e-04
Loss = 3.9102e-05, PNorm = 62.6958, GNorm = 0.2054, lr_0 = 2.5224e-04
Loss = 3.3143e-05, PNorm = 62.6980, GNorm = 0.1272, lr_0 = 2.5112e-04
Loss = 3.2836e-05, PNorm = 62.7008, GNorm = 0.0796, lr_0 = 2.5001e-04
Validation rmse logD = 0.600208
Validation R2 logD = 0.752986
Validation rmse logP = 0.691692
Validation R2 logP = 0.764498
Epoch 60
Train function
Loss = 4.0670e-05, PNorm = 62.7044, GNorm = 0.1572, lr_0 = 2.4879e-04
Loss = 3.8900e-05, PNorm = 62.7069, GNorm = 0.1001, lr_0 = 2.4769e-04
Loss = 4.2510e-05, PNorm = 62.7102, GNorm = 0.2882, lr_0 = 2.4660e-04
Loss = 3.0881e-05, PNorm = 62.7125, GNorm = 0.2389, lr_0 = 2.4551e-04
Loss = 3.5287e-05, PNorm = 62.7159, GNorm = 0.2642, lr_0 = 2.4442e-04
Loss = 4.0101e-05, PNorm = 62.7183, GNorm = 0.2556, lr_0 = 2.4334e-04
Loss = 6.8151e-05, PNorm = 62.7187, GNorm = 0.1449, lr_0 = 2.4323e-04
Validation rmse logD = 0.598205
Validation R2 logD = 0.754631
Validation rmse logP = 0.692402
Validation R2 logP = 0.764015
Epoch 61
Train function
Loss = 3.5934e-05, PNorm = 62.7213, GNorm = 0.2957, lr_0 = 2.4216e-04
Loss = 3.2471e-05, PNorm = 62.7237, GNorm = 0.1113, lr_0 = 2.4109e-04
Loss = 3.2627e-05, PNorm = 62.7258, GNorm = 0.1209, lr_0 = 2.4002e-04
Loss = 3.4871e-05, PNorm = 62.7279, GNorm = 0.3385, lr_0 = 2.3896e-04
Loss = 3.1637e-05, PNorm = 62.7300, GNorm = 0.1782, lr_0 = 2.3790e-04
Validation rmse logD = 0.596702
Validation R2 logD = 0.755863
Validation rmse logP = 0.689408
Validation R2 logP = 0.766051
Epoch 62
Train function
Loss = 2.2177e-05, PNorm = 62.7335, GNorm = 0.1026, lr_0 = 2.3674e-04
Loss = 2.8403e-05, PNorm = 62.7346, GNorm = 0.1188, lr_0 = 2.3570e-04
Loss = 2.5363e-05, PNorm = 62.7388, GNorm = 0.0891, lr_0 = 2.3465e-04
Loss = 2.2095e-05, PNorm = 62.7411, GNorm = 0.1215, lr_0 = 2.3362e-04
Loss = 3.3126e-05, PNorm = 62.7434, GNorm = 0.2525, lr_0 = 2.3258e-04
Validation rmse logD = 0.597105
Validation R2 logD = 0.755533
Validation rmse logP = 0.690279
Validation R2 logP = 0.765459
Epoch 63
Train function
Loss = 2.2097e-05, PNorm = 62.7463, GNorm = 0.1807, lr_0 = 2.3145e-04
Loss = 2.4961e-05, PNorm = 62.7489, GNorm = 0.0919, lr_0 = 2.3043e-04
Loss = 2.6052e-05, PNorm = 62.7508, GNorm = 0.2987, lr_0 = 2.2941e-04
Loss = 2.9232e-05, PNorm = 62.7537, GNorm = 0.1082, lr_0 = 2.2839e-04
Loss = 2.3315e-05, PNorm = 62.7565, GNorm = 0.2308, lr_0 = 2.2738e-04
Validation rmse logD = 0.601338
Validation R2 logD = 0.752055
Validation rmse logP = 0.691148
Validation R2 logP = 0.764869
Epoch 64
Train function
Loss = 6.1697e-05, PNorm = 62.7582, GNorm = 0.6351, lr_0 = 2.2628e-04
Loss = 4.0301e-05, PNorm = 62.7602, GNorm = 0.2778, lr_0 = 2.2528e-04
Loss = 2.9611e-05, PNorm = 62.7624, GNorm = 0.1762, lr_0 = 2.2428e-04
Loss = 2.4820e-05, PNorm = 62.7661, GNorm = 0.1558, lr_0 = 2.2329e-04
Loss = 2.9277e-05, PNorm = 62.7675, GNorm = 0.3175, lr_0 = 2.2230e-04
Loss = 3.1552e-05, PNorm = 62.7685, GNorm = 0.1438, lr_0 = 2.2132e-04
Validation rmse logD = 0.596283
Validation R2 logD = 0.756206
Validation rmse logP = 0.689948
Validation R2 logP = 0.765684
Epoch 65
Train function
Loss = 2.4558e-05, PNorm = 62.7702, GNorm = 0.0916, lr_0 = 2.2024e-04
Loss = 2.8363e-05, PNorm = 62.7746, GNorm = 0.1642, lr_0 = 2.1927e-04
Loss = 2.9501e-05, PNorm = 62.7758, GNorm = 0.1134, lr_0 = 2.1830e-04
Loss = 2.8844e-05, PNorm = 62.7768, GNorm = 0.1060, lr_0 = 2.1733e-04
Loss = 2.7053e-05, PNorm = 62.7796, GNorm = 0.0753, lr_0 = 2.1637e-04
Validation rmse logD = 0.595246
Validation R2 logD = 0.757053
Validation rmse logP = 0.689870
Validation R2 logP = 0.765737
Epoch 66
Train function
Loss = 2.2670e-05, PNorm = 62.7824, GNorm = 0.2292, lr_0 = 2.1532e-04
Loss = 2.2994e-05, PNorm = 62.7857, GNorm = 0.1138, lr_0 = 2.1436e-04
Loss = 1.8625e-05, PNorm = 62.7883, GNorm = 0.0980, lr_0 = 2.1342e-04
Loss = 2.3064e-05, PNorm = 62.7901, GNorm = 0.0865, lr_0 = 2.1247e-04
Loss = 2.5273e-05, PNorm = 62.7909, GNorm = 0.1039, lr_0 = 2.1153e-04
Validation rmse logD = 0.596166
Validation R2 logD = 0.756302
Validation rmse logP = 0.690085
Validation R2 logP = 0.765591
Epoch 67
Train function
Loss = 6.0030e-06, PNorm = 62.7930, GNorm = 0.0466, lr_0 = 2.1060e-04
Loss = 1.9659e-05, PNorm = 62.7942, GNorm = 0.0749, lr_0 = 2.0966e-04
Loss = 2.5714e-05, PNorm = 62.7963, GNorm = 0.2487, lr_0 = 2.0874e-04
Loss = 2.2710e-05, PNorm = 62.7976, GNorm = 0.0882, lr_0 = 2.0781e-04
Loss = 2.4527e-05, PNorm = 62.8000, GNorm = 0.1943, lr_0 = 2.0689e-04
Loss = 2.1185e-05, PNorm = 62.8014, GNorm = 0.1354, lr_0 = 2.0598e-04
Validation rmse logD = 0.595614
Validation R2 logD = 0.756753
Validation rmse logP = 0.691301
Validation R2 logP = 0.764764
Epoch 68
Train function
Loss = 2.4287e-05, PNorm = 62.8041, GNorm = 0.1862, lr_0 = 2.0498e-04
Loss = 2.4256e-05, PNorm = 62.8078, GNorm = 0.1294, lr_0 = 2.0407e-04
Loss = 2.3087e-05, PNorm = 62.8095, GNorm = 0.1986, lr_0 = 2.0317e-04
Loss = 2.0206e-05, PNorm = 62.8126, GNorm = 0.1376, lr_0 = 2.0227e-04
Loss = 2.4033e-05, PNorm = 62.8149, GNorm = 0.1004, lr_0 = 2.0137e-04
Validation rmse logD = 0.596625
Validation R2 logD = 0.755926
Validation rmse logP = 0.693526
Validation R2 logP = 0.763248
Epoch 69
Train function
Loss = 2.3398e-05, PNorm = 62.8157, GNorm = 0.3537, lr_0 = 2.0039e-04
Loss = 2.3390e-05, PNorm = 62.8164, GNorm = 0.1272, lr_0 = 1.9951e-04
Loss = 1.9697e-05, PNorm = 62.8197, GNorm = 0.1389, lr_0 = 1.9863e-04
Loss = 1.9255e-05, PNorm = 62.8212, GNorm = 0.0889, lr_0 = 1.9775e-04
Loss = 2.0316e-05, PNorm = 62.8236, GNorm = 0.1810, lr_0 = 1.9687e-04
Validation rmse logD = 0.595792
Validation R2 logD = 0.756607
Validation rmse logP = 0.690399
Validation R2 logP = 0.765378
Epoch 70
Train function
Loss = 1.2808e-05, PNorm = 62.8253, GNorm = 0.1318, lr_0 = 1.9592e-04
Loss = 1.7054e-05, PNorm = 62.8272, GNorm = 0.1351, lr_0 = 1.9505e-04
Loss = 2.0304e-05, PNorm = 62.8295, GNorm = 0.0611, lr_0 = 1.9419e-04
Loss = 2.2486e-05, PNorm = 62.8327, GNorm = 0.1809, lr_0 = 1.9333e-04
Loss = 2.1219e-05, PNorm = 62.8334, GNorm = 0.1005, lr_0 = 1.9247e-04
Loss = 1.7966e-05, PNorm = 62.8354, GNorm = 0.1339, lr_0 = 1.9162e-04
Validation rmse logD = 0.597921
Validation R2 logD = 0.754865
Validation rmse logP = 0.689434
Validation R2 logP = 0.766033
Epoch 71
Train function
Loss = 1.4616e-05, PNorm = 62.8369, GNorm = 0.0772, lr_0 = 1.9069e-04
Loss = 1.4458e-05, PNorm = 62.8380, GNorm = 0.0968, lr_0 = 1.8984e-04
Loss = 1.6566e-05, PNorm = 62.8389, GNorm = 0.0699, lr_0 = 1.8900e-04
Loss = 1.7769e-05, PNorm = 62.8408, GNorm = 0.1472, lr_0 = 1.8817e-04
Loss = 2.0059e-05, PNorm = 62.8423, GNorm = 0.2075, lr_0 = 1.8734e-04
Validation rmse logD = 0.596557
Validation R2 logD = 0.755982
Validation rmse logP = 0.691709
Validation R2 logP = 0.764487
Epoch 72
Train function
Loss = 2.0439e-05, PNorm = 62.8449, GNorm = 0.1446, lr_0 = 1.8643e-04
Loss = 2.2979e-05, PNorm = 62.8485, GNorm = 0.3023, lr_0 = 1.8560e-04
Loss = 2.1822e-05, PNorm = 62.8510, GNorm = 0.1673, lr_0 = 1.8478e-04
Loss = 2.2332e-05, PNorm = 62.8536, GNorm = 0.1798, lr_0 = 1.8396e-04
Loss = 2.1899e-05, PNorm = 62.8554, GNorm = 0.1417, lr_0 = 1.8315e-04
Validation rmse logD = 0.597460
Validation R2 logD = 0.755243
Validation rmse logP = 0.691990
Validation R2 logP = 0.764295
Epoch 73
Train function
Loss = 1.2688e-05, PNorm = 62.8570, GNorm = 0.1078, lr_0 = 1.8226e-04
Loss = 1.6546e-05, PNorm = 62.8591, GNorm = 0.0494, lr_0 = 1.8145e-04
Loss = 1.8247e-05, PNorm = 62.8603, GNorm = 0.1201, lr_0 = 1.8065e-04
Loss = 1.8366e-05, PNorm = 62.8609, GNorm = 0.2710, lr_0 = 1.7985e-04
Loss = 2.1712e-05, PNorm = 62.8623, GNorm = 0.1374, lr_0 = 1.7905e-04
Loss = 1.7369e-05, PNorm = 62.8637, GNorm = 0.0728, lr_0 = 1.7826e-04
Loss = 3.2144e-05, PNorm = 62.8640, GNorm = 0.0986, lr_0 = 1.7818e-04
Validation rmse logD = 0.595927
Validation R2 logD = 0.756497
Validation rmse logP = 0.691914
Validation R2 logP = 0.764347
Epoch 74
Train function
Loss = 1.6392e-05, PNorm = 62.8656, GNorm = 0.1000, lr_0 = 1.7739e-04
Loss = 1.3122e-05, PNorm = 62.8658, GNorm = 0.0601, lr_0 = 1.7661e-04
Loss = 1.3004e-05, PNorm = 62.8680, GNorm = 0.0712, lr_0 = 1.7583e-04
Loss = 1.1984e-05, PNorm = 62.8686, GNorm = 0.0672, lr_0 = 1.7505e-04
Loss = 1.7595e-05, PNorm = 62.8706, GNorm = 0.2025, lr_0 = 1.7428e-04
Validation rmse logD = 0.595914
Validation R2 logD = 0.756507
Validation rmse logP = 0.691747
Validation R2 logP = 0.764461
Epoch 75
Train function
Loss = 1.4674e-05, PNorm = 62.8723, GNorm = 0.0729, lr_0 = 1.7351e-04
Loss = 2.0479e-05, PNorm = 62.8742, GNorm = 0.1631, lr_0 = 1.7274e-04
Loss = 1.9963e-05, PNorm = 62.8755, GNorm = 0.1270, lr_0 = 1.7197e-04
Loss = 1.5589e-05, PNorm = 62.8784, GNorm = 0.1124, lr_0 = 1.7121e-04
Loss = 1.5920e-05, PNorm = 62.8815, GNorm = 0.0638, lr_0 = 1.7046e-04
Validation rmse logD = 0.596851
Validation R2 logD = 0.755741
Validation rmse logP = 0.692774
Validation R2 logP = 0.763761
Epoch 76
Train function
Loss = 1.4155e-05, PNorm = 62.8816, GNorm = 0.0809, lr_0 = 1.6963e-04
Loss = 1.2393e-05, PNorm = 62.8828, GNorm = 0.1221, lr_0 = 1.6888e-04
Loss = 1.1425e-05, PNorm = 62.8844, GNorm = 0.1290, lr_0 = 1.6813e-04
Loss = 1.0553e-05, PNorm = 62.8850, GNorm = 0.1172, lr_0 = 1.6739e-04
Loss = 1.7326e-05, PNorm = 62.8869, GNorm = 0.1780, lr_0 = 1.6665e-04
Loss = 1.2703e-05, PNorm = 62.8879, GNorm = 0.3089, lr_0 = 1.6591e-04
Loss = 4.5767e-05, PNorm = 62.8878, GNorm = 0.1126, lr_0 = 1.6584e-04
Validation rmse logD = 0.596269
Validation R2 logD = 0.756217
Validation rmse logP = 0.690349
Validation R2 logP = 0.765412
Epoch 77
Train function
Loss = 9.3677e-06, PNorm = 62.8886, GNorm = 0.0814, lr_0 = 1.6510e-04
Loss = 1.1719e-05, PNorm = 62.8900, GNorm = 0.0579, lr_0 = 1.6437e-04
Loss = 1.2590e-05, PNorm = 62.8917, GNorm = 0.0911, lr_0 = 1.6364e-04
Loss = 1.5010e-05, PNorm = 62.8935, GNorm = 0.0801, lr_0 = 1.6292e-04
Loss = 9.9270e-06, PNorm = 62.8942, GNorm = 0.0471, lr_0 = 1.6220e-04
Validation rmse logD = 0.598222
Validation R2 logD = 0.754617
Validation rmse logP = 0.692060
Validation R2 logP = 0.764248
Epoch 78
Train function
Loss = 1.1803e-05, PNorm = 62.8958, GNorm = 0.0841, lr_0 = 1.6141e-04
Loss = 1.1123e-05, PNorm = 62.8966, GNorm = 0.1918, lr_0 = 1.6070e-04
Loss = 1.0063e-05, PNorm = 62.8969, GNorm = 0.0462, lr_0 = 1.5999e-04
Loss = 1.0225e-05, PNorm = 62.8982, GNorm = 0.0642, lr_0 = 1.5928e-04
Loss = 9.5370e-06, PNorm = 62.8994, GNorm = 0.0768, lr_0 = 1.5857e-04
Validation rmse logD = 0.598351
Validation R2 logD = 0.754512
Validation rmse logP = 0.692340
Validation R2 logP = 0.764056
Epoch 79
Train function
Loss = 9.9499e-06, PNorm = 62.9009, GNorm = 0.1265, lr_0 = 1.5780e-04
Loss = 1.3576e-05, PNorm = 62.9022, GNorm = 0.2710, lr_0 = 1.5710e-04
Loss = 1.4172e-05, PNorm = 62.9031, GNorm = 0.1361, lr_0 = 1.5641e-04
Loss = 1.1644e-05, PNorm = 62.9044, GNorm = 0.1499, lr_0 = 1.5572e-04
Loss = 1.8207e-05, PNorm = 62.9059, GNorm = 0.0815, lr_0 = 1.5503e-04
Validation rmse logD = 0.596893
Validation R2 logD = 0.755706
Validation rmse logP = 0.689355
Validation R2 logP = 0.766087
Epoch 80
Train function
Loss = 2.8405e-05, PNorm = 62.9076, GNorm = 0.3742, lr_0 = 1.5427e-04
Loss = 2.4996e-05, PNorm = 62.9091, GNorm = 0.3694, lr_0 = 1.5359e-04
Loss = 2.1159e-05, PNorm = 62.9115, GNorm = 0.1358, lr_0 = 1.5291e-04
Loss = 1.6093e-05, PNorm = 62.9136, GNorm = 0.0741, lr_0 = 1.5224e-04
Loss = 1.3827e-05, PNorm = 62.9158, GNorm = 0.1047, lr_0 = 1.5156e-04
Loss = 1.7077e-05, PNorm = 62.9166, GNorm = 0.1802, lr_0 = 1.5089e-04
Validation rmse logD = 0.596470
Validation R2 logD = 0.756053
Validation rmse logP = 0.691458
Validation R2 logP = 0.764658
Epoch 81
Train function
Loss = 1.2538e-05, PNorm = 62.9158, GNorm = 0.0792, lr_0 = 1.5016e-04
Loss = 1.4528e-05, PNorm = 62.9168, GNorm = 0.1220, lr_0 = 1.4949e-04
Loss = 1.1660e-05, PNorm = 62.9173, GNorm = 0.1248, lr_0 = 1.4883e-04
Loss = 1.2766e-05, PNorm = 62.9183, GNorm = 0.2769, lr_0 = 1.4817e-04
Loss = 1.9969e-05, PNorm = 62.9200, GNorm = 0.1449, lr_0 = 1.4752e-04
Validation rmse logD = 0.597731
Validation R2 logD = 0.755020
Validation rmse logP = 0.694968
Validation R2 logP = 0.762262
Epoch 82
Train function
Loss = 1.2841e-05, PNorm = 62.9241, GNorm = 0.0678, lr_0 = 1.4680e-04
Loss = 2.1266e-05, PNorm = 62.9250, GNorm = 0.0662, lr_0 = 1.4615e-04
Loss = 1.7778e-05, PNorm = 62.9257, GNorm = 0.2891, lr_0 = 1.4551e-04
Loss = 1.9035e-05, PNorm = 62.9251, GNorm = 0.1849, lr_0 = 1.4486e-04
Loss = 1.5190e-05, PNorm = 62.9265, GNorm = 0.0691, lr_0 = 1.4422e-04
Validation rmse logD = 0.597871
Validation R2 logD = 0.754906
Validation rmse logP = 0.690286
Validation R2 logP = 0.765455
Epoch 83
Train function
Loss = 7.7215e-06, PNorm = 62.9281, GNorm = 0.0584, lr_0 = 1.4352e-04
Loss = 1.1001e-05, PNorm = 62.9299, GNorm = 0.0545, lr_0 = 1.4288e-04
Loss = 1.1008e-05, PNorm = 62.9309, GNorm = 0.0738, lr_0 = 1.4225e-04
Loss = 1.2782e-05, PNorm = 62.9317, GNorm = 0.1083, lr_0 = 1.4162e-04
Loss = 1.0988e-05, PNorm = 62.9333, GNorm = 0.1315, lr_0 = 1.4100e-04
Loss = 1.0471e-05, PNorm = 62.9336, GNorm = 0.0692, lr_0 = 1.4037e-04
Validation rmse logD = 0.596875
Validation R2 logD = 0.755722
Validation rmse logP = 0.693063
Validation R2 logP = 0.763563
Epoch 84
Train function
Loss = 1.1617e-05, PNorm = 62.9342, GNorm = 0.1486, lr_0 = 1.3975e-04
Loss = 7.3767e-06, PNorm = 62.9347, GNorm = 0.0948, lr_0 = 1.3913e-04
Loss = 1.0515e-05, PNorm = 62.9360, GNorm = 0.0475, lr_0 = 1.3852e-04
Loss = 8.8011e-06, PNorm = 62.9372, GNorm = 0.0722, lr_0 = 1.3791e-04
Loss = 8.8696e-06, PNorm = 62.9390, GNorm = 0.0647, lr_0 = 1.3730e-04
Validation rmse logD = 0.598134
Validation R2 logD = 0.754690
Validation rmse logP = 0.691665
Validation R2 logP = 0.764517
Epoch 85
Train function
Loss = 7.3663e-06, PNorm = 62.9392, GNorm = 0.0823, lr_0 = 1.3663e-04
Loss = 1.0965e-05, PNorm = 62.9396, GNorm = 0.1284, lr_0 = 1.3602e-04
Loss = 1.1016e-05, PNorm = 62.9409, GNorm = 0.1134, lr_0 = 1.3542e-04
Loss = 8.4697e-06, PNorm = 62.9418, GNorm = 0.0490, lr_0 = 1.3482e-04
Loss = 1.0582e-05, PNorm = 62.9426, GNorm = 0.0646, lr_0 = 1.3423e-04
Validation rmse logD = 0.595321
Validation R2 logD = 0.756991
Validation rmse logP = 0.690876
Validation R2 logP = 0.765053
Epoch 86
Train function
Loss = 6.0808e-06, PNorm = 62.9436, GNorm = 0.0848, lr_0 = 1.3357e-04
Loss = 9.4396e-06, PNorm = 62.9440, GNorm = 0.0799, lr_0 = 1.3298e-04
Loss = 8.0660e-06, PNorm = 62.9447, GNorm = 0.1410, lr_0 = 1.3239e-04
Loss = 6.4579e-06, PNorm = 62.9460, GNorm = 0.0453, lr_0 = 1.3181e-04
Loss = 5.2361e-06, PNorm = 62.9464, GNorm = 0.0792, lr_0 = 1.3123e-04
Loss = 1.1708e-05, PNorm = 62.9472, GNorm = 0.1716, lr_0 = 1.3065e-04
Validation rmse logD = 0.597638
Validation R2 logD = 0.755096
Validation rmse logP = 0.692595
Validation R2 logP = 0.763883
Epoch 87
Train function
Loss = 9.7739e-06, PNorm = 62.9483, GNorm = 0.1474, lr_0 = 1.3001e-04
Loss = 7.8320e-06, PNorm = 62.9496, GNorm = 0.0459, lr_0 = 1.2944e-04
Loss = 6.4374e-06, PNorm = 62.9508, GNorm = 0.1001, lr_0 = 1.2886e-04
Loss = 6.4982e-06, PNorm = 62.9523, GNorm = 0.0827, lr_0 = 1.2829e-04
Loss = 9.7556e-06, PNorm = 62.9534, GNorm = 0.1562, lr_0 = 1.2773e-04
Validation rmse logD = 0.598453
Validation R2 logD = 0.754428
Validation rmse logP = 0.693159
Validation R2 logP = 0.763498
Epoch 88
Train function
Loss = 8.4052e-06, PNorm = 62.9543, GNorm = 0.0581, lr_0 = 1.2710e-04
Loss = 5.6681e-06, PNorm = 62.9546, GNorm = 0.1084, lr_0 = 1.2654e-04
Loss = 6.6604e-06, PNorm = 62.9547, GNorm = 0.0941, lr_0 = 1.2598e-04
Loss = 6.4062e-06, PNorm = 62.9551, GNorm = 0.0941, lr_0 = 1.2542e-04
Loss = 8.3978e-06, PNorm = 62.9563, GNorm = 0.1328, lr_0 = 1.2487e-04
Validation rmse logD = 0.597310
Validation R2 logD = 0.755366
Validation rmse logP = 0.691900
Validation R2 logP = 0.764356
Epoch 89
Train function
Loss = 6.2971e-06, PNorm = 62.9572, GNorm = 0.0466, lr_0 = 1.2426e-04
Loss = 7.3673e-06, PNorm = 62.9577, GNorm = 0.1339, lr_0 = 1.2371e-04
Loss = 6.2831e-06, PNorm = 62.9584, GNorm = 0.1164, lr_0 = 1.2317e-04
Loss = 5.7664e-06, PNorm = 62.9594, GNorm = 0.0565, lr_0 = 1.2262e-04
Loss = 5.6957e-06, PNorm = 62.9607, GNorm = 0.1567, lr_0 = 1.2208e-04
Loss = 8.0204e-06, PNorm = 62.9616, GNorm = 0.1314, lr_0 = 1.2154e-04
Loss = 6.4682e-05, PNorm = 62.9619, GNorm = 0.2576, lr_0 = 1.2148e-04
Validation rmse logD = 0.597431
Validation R2 logD = 0.755266
Validation rmse logP = 0.691953
Validation R2 logP = 0.764320
Epoch 90
Train function
Loss = 6.2924e-06, PNorm = 62.9626, GNorm = 0.1473, lr_0 = 1.2095e-04
Loss = 7.6172e-06, PNorm = 62.9635, GNorm = 0.0434, lr_0 = 1.2041e-04
Loss = 5.0801e-06, PNorm = 62.9640, GNorm = 0.0705, lr_0 = 1.1988e-04
Loss = 6.8515e-06, PNorm = 62.9647, GNorm = 0.0734, lr_0 = 1.1935e-04
Loss = 9.5927e-06, PNorm = 62.9655, GNorm = 0.1525, lr_0 = 1.1882e-04
Validation rmse logD = 0.597554
Validation R2 logD = 0.755166
Validation rmse logP = 0.691972
Validation R2 logP = 0.764307
Epoch 91
Train function
Loss = 4.7144e-06, PNorm = 62.9667, GNorm = 0.0589, lr_0 = 1.1824e-04
Loss = 5.3134e-06, PNorm = 62.9678, GNorm = 0.0924, lr_0 = 1.1772e-04
Loss = 6.4582e-06, PNorm = 62.9686, GNorm = 0.0573, lr_0 = 1.1720e-04
Loss = 4.3174e-06, PNorm = 62.9694, GNorm = 0.0420, lr_0 = 1.1668e-04
Loss = 6.3972e-06, PNorm = 62.9702, GNorm = 0.0318, lr_0 = 1.1616e-04
Validation rmse logD = 0.597687
Validation R2 logD = 0.755057
Validation rmse logP = 0.691792
Validation R2 logP = 0.764430
Epoch 92
Train function
Loss = 4.0009e-06, PNorm = 62.9711, GNorm = 0.0509, lr_0 = 1.1565e-04
Loss = 4.6104e-06, PNorm = 62.9713, GNorm = 0.0335, lr_0 = 1.1514e-04
Loss = 4.5838e-06, PNorm = 62.9721, GNorm = 0.0597, lr_0 = 1.1463e-04
Loss = 6.5357e-06, PNorm = 62.9725, GNorm = 0.1444, lr_0 = 1.1412e-04
Loss = 6.8195e-06, PNorm = 62.9737, GNorm = 0.0707, lr_0 = 1.1362e-04
Loss = 7.2626e-06, PNorm = 62.9740, GNorm = 0.1157, lr_0 = 1.1312e-04
Loss = 1.9229e-04, PNorm = 62.9743, GNorm = 0.2235, lr_0 = 1.1307e-04
Validation rmse logD = 0.597405
Validation R2 logD = 0.755288
Validation rmse logP = 0.690143
Validation R2 logP = 0.765552
Epoch 93
Train function
Loss = 1.0469e-05, PNorm = 62.9755, GNorm = 0.0763, lr_0 = 1.1257e-04
Loss = 5.6332e-06, PNorm = 62.9753, GNorm = 0.0585, lr_0 = 1.1207e-04
Loss = 7.8079e-06, PNorm = 62.9760, GNorm = 0.0585, lr_0 = 1.1157e-04
Loss = 5.8718e-06, PNorm = 62.9763, GNorm = 0.1155, lr_0 = 1.1108e-04
Loss = 7.3171e-06, PNorm = 62.9771, GNorm = 0.0672, lr_0 = 1.1059e-04
Validation rmse logD = 0.597659
Validation R2 logD = 0.755080
Validation rmse logP = 0.692463
Validation R2 logP = 0.763973
Epoch 94
Train function
Loss = 7.0527e-06, PNorm = 62.9776, GNorm = 0.1028, lr_0 = 1.1005e-04
Loss = 4.9475e-06, PNorm = 62.9786, GNorm = 0.0449, lr_0 = 1.0956e-04
Loss = 6.8500e-06, PNorm = 62.9799, GNorm = 0.0936, lr_0 = 1.0908e-04
Loss = 9.0230e-06, PNorm = 62.9804, GNorm = 0.0538, lr_0 = 1.0860e-04
Loss = 1.0397e-05, PNorm = 62.9814, GNorm = 0.0956, lr_0 = 1.0811e-04
Validation rmse logD = 0.596758
Validation R2 logD = 0.755817
Validation rmse logP = 0.692219
Validation R2 logP = 0.764139
Epoch 95
Train function
Loss = 9.8996e-06, PNorm = 62.9832, GNorm = 0.2177, lr_0 = 1.0759e-04
Loss = 1.2709e-05, PNorm = 62.9840, GNorm = 0.0995, lr_0 = 1.0711e-04
Loss = 1.3116e-05, PNorm = 62.9845, GNorm = 0.0576, lr_0 = 1.0664e-04
Loss = 1.0768e-05, PNorm = 62.9847, GNorm = 0.0534, lr_0 = 1.0617e-04
Loss = 7.7918e-06, PNorm = 62.9863, GNorm = 0.0438, lr_0 = 1.0570e-04
Validation rmse logD = 0.599545
Validation R2 logD = 0.753531
Validation rmse logP = 0.693378
Validation R2 logP = 0.763349
Epoch 96
Train function
Loss = 9.6226e-06, PNorm = 62.9876, GNorm = 0.1928, lr_0 = 1.0518e-04
Loss = 1.2358e-05, PNorm = 62.9885, GNorm = 0.1716, lr_0 = 1.0472e-04
Loss = 1.2039e-05, PNorm = 62.9892, GNorm = 0.1893, lr_0 = 1.0426e-04
Loss = 1.0782e-05, PNorm = 62.9899, GNorm = 0.0666, lr_0 = 1.0379e-04
Loss = 1.0607e-05, PNorm = 62.9906, GNorm = 0.0614, lr_0 = 1.0333e-04
Loss = 7.0769e-06, PNorm = 62.9908, GNorm = 0.1543, lr_0 = 1.0288e-04
Validation rmse logD = 0.598259
Validation R2 logD = 0.754588
Validation rmse logP = 0.694356
Validation R2 logP = 0.762681
Epoch 97
Train function
Loss = 8.6273e-06, PNorm = 62.9920, GNorm = 0.0782, lr_0 = 1.0238e-04
Loss = 9.6261e-06, PNorm = 62.9934, GNorm = 0.1910, lr_0 = 1.0192e-04
Loss = 6.5669e-06, PNorm = 62.9943, GNorm = 0.0913, lr_0 = 1.0147e-04
Loss = 6.0523e-06, PNorm = 62.9951, GNorm = 0.0373, lr_0 = 1.0102e-04
Loss = 8.7597e-06, PNorm = 62.9958, GNorm = 0.2255, lr_0 = 1.0058e-04
Validation rmse logD = 0.600614
Validation R2 logD = 0.752652
Validation rmse logP = 0.692942
Validation R2 logP = 0.763646
Epoch 98
Train function
Loss = 1.0516e-05, PNorm = 62.9961, GNorm = 0.1456, lr_0 = 1.0009e-04
Loss = 8.7772e-06, PNorm = 62.9966, GNorm = 0.1941, lr_0 = 1.0000e-04
Loss = 1.1231e-05, PNorm = 62.9977, GNorm = 0.0701, lr_0 = 1.0000e-04
Loss = 8.1334e-06, PNorm = 62.9988, GNorm = 0.0595, lr_0 = 1.0000e-04
Loss = 7.8131e-06, PNorm = 63.0000, GNorm = 0.0462, lr_0 = 1.0000e-04
Validation rmse logD = 0.597366
Validation R2 logD = 0.755320
Validation rmse logP = 0.693479
Validation R2 logP = 0.763280
Epoch 99
Train function
Loss = 6.6784e-06, PNorm = 63.0007, GNorm = 0.0876, lr_0 = 1.0000e-04
Loss = 7.0694e-06, PNorm = 63.0009, GNorm = 0.0623, lr_0 = 1.0000e-04
Loss = 7.1111e-06, PNorm = 63.0020, GNorm = 0.0322, lr_0 = 1.0000e-04
Loss = 5.2388e-06, PNorm = 63.0025, GNorm = 0.1071, lr_0 = 1.0000e-04
Loss = 3.8964e-06, PNorm = 63.0025, GNorm = 0.0440, lr_0 = 1.0000e-04
Loss = 5.8171e-06, PNorm = 63.0028, GNorm = 0.0758, lr_0 = 1.0000e-04
Validation rmse logD = 0.597557
Validation R2 logD = 0.755163
Validation rmse logP = 0.693205
Validation R2 logP = 0.763467
Model 0 best validation rmse = 0.639572 on epoch 45
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.570265
Model 0 test R2 logD = 0.771603
Model 0 test rmse logP = 0.966379
Model 0 test R2 logP = 0.596742
Ensemble test rmse  logD= 0.570265
Ensemble test R2  logD= 0.771603
Ensemble test rmse  logP= 0.966379
Ensemble test R2  logP= 0.596742
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 1.9696e-02, PNorm = 52.9413, GNorm = 4.4026, lr_0 = 1.9340e-04
Loss = 1.6474e-02, PNorm = 52.9513, GNorm = 2.9570, lr_0 = 2.7830e-04
Loss = 1.4983e-02, PNorm = 52.9649, GNorm = 8.8399, lr_0 = 3.6321e-04
Loss = 1.6436e-02, PNorm = 52.9835, GNorm = 2.5843, lr_0 = 4.4811e-04
Loss = 1.3791e-02, PNorm = 53.0129, GNorm = 1.6652, lr_0 = 5.3302e-04
Validation rmse logD = 1.114279
Validation R2 logD = 0.204623
Validation rmse logP = 1.101511
Validation R2 logP = 0.473479
Epoch 1
Train function
Loss = 1.2976e-02, PNorm = 53.0522, GNorm = 5.2095, lr_0 = 6.2642e-04
Loss = 1.2226e-02, PNorm = 53.0918, GNorm = 1.8136, lr_0 = 7.1132e-04
Loss = 1.1330e-02, PNorm = 53.1297, GNorm = 1.2345, lr_0 = 7.9623e-04
Loss = 1.2249e-02, PNorm = 53.1718, GNorm = 4.8975, lr_0 = 8.8113e-04
Loss = 1.0596e-02, PNorm = 53.2324, GNorm = 1.6021, lr_0 = 9.6604e-04
Validation rmse logD = 0.900973
Validation R2 logD = 0.479993
Validation rmse logP = 1.060087
Validation R2 logP = 0.512336
Epoch 2
Train function
Loss = 9.9381e-03, PNorm = 53.3141, GNorm = 0.9413, lr_0 = 9.9690e-04
Loss = 1.1128e-02, PNorm = 53.3971, GNorm = 0.9869, lr_0 = 9.9249e-04
Loss = 9.9457e-03, PNorm = 53.4746, GNorm = 1.5444, lr_0 = 9.8810e-04
Loss = 8.4506e-03, PNorm = 53.5591, GNorm = 1.3234, lr_0 = 9.8373e-04
Loss = 8.3236e-03, PNorm = 53.6624, GNorm = 5.8061, lr_0 = 9.7938e-04
Validation rmse logD = 0.864109
Validation R2 logD = 0.521676
Validation rmse logP = 0.754426
Validation R2 logP = 0.753014
Epoch 3
Train function
Loss = 6.6916e-03, PNorm = 53.7696, GNorm = 2.0674, lr_0 = 9.7462e-04
Loss = 7.3081e-03, PNorm = 53.8628, GNorm = 1.2113, lr_0 = 9.7030e-04
Loss = 9.2958e-03, PNorm = 53.9593, GNorm = 1.6770, lr_0 = 9.6601e-04
Loss = 6.7774e-03, PNorm = 54.0510, GNorm = 2.2842, lr_0 = 9.6174e-04
Loss = 7.9231e-03, PNorm = 54.1457, GNorm = 4.1518, lr_0 = 9.5749e-04
Loss = 7.4190e-03, PNorm = 54.2327, GNorm = 1.5889, lr_0 = 9.5325e-04
Validation rmse logD = 0.843304
Validation R2 logD = 0.544431
Validation rmse logP = 0.737298
Validation R2 logP = 0.764102
Epoch 4
Train function
Loss = 7.9323e-03, PNorm = 54.3368, GNorm = 1.2857, lr_0 = 9.4861e-04
Loss = 7.9675e-03, PNorm = 54.4247, GNorm = 4.1154, lr_0 = 9.4442e-04
Loss = 6.4146e-03, PNorm = 54.5070, GNorm = 1.0825, lr_0 = 9.4024e-04
Loss = 8.3971e-03, PNorm = 54.6035, GNorm = 3.0190, lr_0 = 9.3608e-04
Loss = 6.9237e-03, PNorm = 54.6915, GNorm = 4.0077, lr_0 = 9.3194e-04
Validation rmse logD = 0.766635
Validation R2 logD = 0.623502
Validation rmse logP = 0.821184
Validation R2 logP = 0.707370
Epoch 5
Train function
Loss = 5.0183e-03, PNorm = 54.7734, GNorm = 2.7565, lr_0 = 9.2741e-04
Loss = 6.3799e-03, PNorm = 54.8302, GNorm = 3.5023, lr_0 = 9.2330e-04
Loss = 6.1631e-03, PNorm = 54.9095, GNorm = 1.1837, lr_0 = 9.1922e-04
Loss = 5.4187e-03, PNorm = 54.9893, GNorm = 0.9580, lr_0 = 9.1515e-04
Loss = 6.1396e-03, PNorm = 55.0753, GNorm = 0.6815, lr_0 = 9.1111e-04
Validation rmse logD = 0.889709
Validation R2 logD = 0.492914
Validation rmse logP = 0.738502
Validation R2 logP = 0.763331
Epoch 6
Train function
Loss = 8.8777e-03, PNorm = 55.1533, GNorm = 5.7612, lr_0 = 9.0667e-04
Loss = 6.1190e-03, PNorm = 55.2364, GNorm = 3.0572, lr_0 = 9.0266e-04
Loss = 5.2509e-03, PNorm = 55.3098, GNorm = 0.9923, lr_0 = 8.9867e-04
Loss = 5.3784e-03, PNorm = 55.3926, GNorm = 1.3366, lr_0 = 8.9469e-04
Loss = 4.7508e-03, PNorm = 55.4674, GNorm = 2.3145, lr_0 = 8.9074e-04
Loss = 4.5062e-03, PNorm = 55.5401, GNorm = 1.6892, lr_0 = 8.8680e-04
Validation rmse logD = 0.699108
Validation R2 logD = 0.686907
Validation rmse logP = 0.688114
Validation R2 logP = 0.794525
Epoch 7
Train function
Loss = 4.9732e-03, PNorm = 55.6316, GNorm = 2.3183, lr_0 = 8.8248e-04
Loss = 4.5368e-03, PNorm = 55.7172, GNorm = 1.9734, lr_0 = 8.7858e-04
Loss = 4.1012e-03, PNorm = 55.7930, GNorm = 0.8741, lr_0 = 8.7469e-04
Loss = 4.1958e-03, PNorm = 55.8724, GNorm = 1.1086, lr_0 = 8.7082e-04
Loss = 5.0598e-03, PNorm = 55.9607, GNorm = 3.1161, lr_0 = 8.6697e-04
Validation rmse logD = 0.735275
Validation R2 logD = 0.653674
Validation rmse logP = 0.724715
Validation R2 logP = 0.772085
Epoch 8
Train function
Loss = 6.2104e-03, PNorm = 56.0533, GNorm = 6.0927, lr_0 = 8.6276e-04
Loss = 5.1303e-03, PNorm = 56.1602, GNorm = 2.3530, lr_0 = 8.5894e-04
Loss = 4.2241e-03, PNorm = 56.2599, GNorm = 1.0874, lr_0 = 8.5514e-04
Loss = 3.5482e-03, PNorm = 56.3494, GNorm = 0.8612, lr_0 = 8.5136e-04
Loss = 4.3783e-03, PNorm = 56.4303, GNorm = 1.2910, lr_0 = 8.4759e-04
Validation rmse logD = 0.715405
Validation R2 logD = 0.672140
Validation rmse logP = 0.701537
Validation R2 logP = 0.786430
Epoch 9
Train function
Loss = 4.2760e-03, PNorm = 56.5015, GNorm = 5.0147, lr_0 = 8.4384e-04
Loss = 4.0218e-03, PNorm = 56.5678, GNorm = 5.3775, lr_0 = 8.4011e-04
Loss = 4.9683e-03, PNorm = 56.6488, GNorm = 2.5909, lr_0 = 8.3639e-04
Loss = 4.9029e-03, PNorm = 56.7321, GNorm = 1.5405, lr_0 = 8.3269e-04
Loss = 3.9865e-03, PNorm = 56.8222, GNorm = 1.0248, lr_0 = 8.2901e-04
Loss = 3.9729e-03, PNorm = 56.8992, GNorm = 1.6887, lr_0 = 8.2534e-04
Validation rmse logD = 0.651469
Validation R2 logD = 0.728123
Validation rmse logP = 0.673684
Validation R2 logP = 0.803052
Epoch 10
Train function
Loss = 3.1686e-03, PNorm = 56.9737, GNorm = 2.3702, lr_0 = 8.2133e-04
Loss = 3.4905e-03, PNorm = 57.0429, GNorm = 1.0809, lr_0 = 8.1770e-04
Loss = 3.1899e-03, PNorm = 57.1020, GNorm = 0.7096, lr_0 = 8.1408e-04
Loss = 2.7821e-03, PNorm = 57.1791, GNorm = 1.0662, lr_0 = 8.1048e-04
Loss = 3.3845e-03, PNorm = 57.2404, GNorm = 1.1220, lr_0 = 8.0689e-04
Validation rmse logD = 0.678669
Validation R2 logD = 0.704947
Validation rmse logP = 0.673404
Validation R2 logP = 0.803216
Epoch 11
Train function
Loss = 3.0375e-03, PNorm = 57.3095, GNorm = 1.8687, lr_0 = 8.0297e-04
Loss = 3.6857e-03, PNorm = 57.3904, GNorm = 4.5082, lr_0 = 7.9942e-04
Loss = 3.2136e-03, PNorm = 57.4762, GNorm = 1.0020, lr_0 = 7.9588e-04
Loss = 3.7240e-03, PNorm = 57.5532, GNorm = 2.5227, lr_0 = 7.9236e-04
Loss = 3.1866e-03, PNorm = 57.6240, GNorm = 1.0879, lr_0 = 7.8885e-04
Validation rmse logD = 0.639001
Validation R2 logD = 0.738430
Validation rmse logP = 0.662426
Validation R2 logP = 0.809580
Epoch 12
Train function
Loss = 2.0416e-03, PNorm = 57.6978, GNorm = 2.0653, lr_0 = 7.8502e-04
Loss = 2.6665e-03, PNorm = 57.7716, GNorm = 0.8559, lr_0 = 7.8154e-04
Loss = 2.4979e-03, PNorm = 57.8321, GNorm = 1.9727, lr_0 = 7.7809e-04
Loss = 2.0757e-03, PNorm = 57.9067, GNorm = 0.6961, lr_0 = 7.7465e-04
Loss = 2.3019e-03, PNorm = 57.9689, GNorm = 0.6681, lr_0 = 7.7122e-04
Loss = 3.3391e-03, PNorm = 58.0195, GNorm = 1.4092, lr_0 = 7.6781e-04
Loss = 2.2613e-02, PNorm = 58.0240, GNorm = 2.4261, lr_0 = 7.6747e-04
Validation rmse logD = 0.661697
Validation R2 logD = 0.719519
Validation rmse logP = 0.664229
Validation R2 logP = 0.808542
Epoch 13
Train function
Loss = 2.5345e-03, PNorm = 58.0902, GNorm = 0.7616, lr_0 = 7.6407e-04
Loss = 2.7564e-03, PNorm = 58.1816, GNorm = 1.1482, lr_0 = 7.6069e-04
Loss = 1.9287e-03, PNorm = 58.2497, GNorm = 1.5442, lr_0 = 7.5733e-04
Loss = 2.0757e-03, PNorm = 58.3165, GNorm = 0.9869, lr_0 = 7.5398e-04
Loss = 2.4830e-03, PNorm = 58.3877, GNorm = 0.5387, lr_0 = 7.5064e-04
Validation rmse logD = 0.638476
Validation R2 logD = 0.738859
Validation rmse logP = 0.651747
Validation R2 logP = 0.815670
Epoch 14
Train function
Loss = 1.9146e-03, PNorm = 58.4633, GNorm = 0.7181, lr_0 = 7.4699e-04
Loss = 2.1594e-03, PNorm = 58.5195, GNorm = 1.2070, lr_0 = 7.4369e-04
Loss = 1.7178e-03, PNorm = 58.5719, GNorm = 0.8766, lr_0 = 7.4040e-04
Loss = 2.0903e-03, PNorm = 58.6377, GNorm = 0.8890, lr_0 = 7.3712e-04
Loss = 1.8954e-03, PNorm = 58.6951, GNorm = 1.1956, lr_0 = 7.3386e-04
Validation rmse logD = 0.626418
Validation R2 logD = 0.748630
Validation rmse logP = 0.671777
Validation R2 logP = 0.804166
Epoch 15
Train function
Loss = 2.0813e-03, PNorm = 58.7588, GNorm = 0.8731, lr_0 = 7.3029e-04
Loss = 1.4334e-03, PNorm = 58.8210, GNorm = 0.6216, lr_0 = 7.2706e-04
Loss = 1.4788e-03, PNorm = 58.8732, GNorm = 0.8382, lr_0 = 7.2385e-04
Loss = 1.6174e-03, PNorm = 58.9299, GNorm = 1.5920, lr_0 = 7.2064e-04
Loss = 1.8943e-03, PNorm = 58.9800, GNorm = 1.0290, lr_0 = 7.1746e-04
Validation rmse logD = 0.619834
Validation R2 logD = 0.753886
Validation rmse logP = 0.651219
Validation R2 logP = 0.815968
Epoch 16
Train function
Loss = 9.8093e-04, PNorm = 59.0372, GNorm = 0.8470, lr_0 = 7.1397e-04
Loss = 1.4411e-03, PNorm = 59.1070, GNorm = 0.4663, lr_0 = 7.1081e-04
Loss = 1.7748e-03, PNorm = 59.1645, GNorm = 1.7181, lr_0 = 7.0766e-04
Loss = 2.2364e-03, PNorm = 59.2282, GNorm = 1.0209, lr_0 = 7.0453e-04
Loss = 1.3902e-03, PNorm = 59.2919, GNorm = 1.0022, lr_0 = 7.0142e-04
Loss = 1.4739e-03, PNorm = 59.3478, GNorm = 1.5646, lr_0 = 6.9831e-04
Validation rmse logD = 0.611824
Validation R2 logD = 0.760206
Validation rmse logP = 0.693049
Validation R2 logP = 0.791567
Epoch 17
Train function
Loss = 1.3181e-03, PNorm = 59.4016, GNorm = 0.5692, lr_0 = 6.9523e-04
Loss = 1.3699e-03, PNorm = 59.4492, GNorm = 1.1130, lr_0 = 6.9215e-04
Loss = 1.6601e-03, PNorm = 59.4959, GNorm = 1.4819, lr_0 = 6.8909e-04
Loss = 1.6396e-03, PNorm = 59.5461, GNorm = 1.5946, lr_0 = 6.8604e-04
Loss = 1.3614e-03, PNorm = 59.5961, GNorm = 0.8022, lr_0 = 6.8301e-04
Validation rmse logD = 0.621917
Validation R2 logD = 0.752229
Validation rmse logP = 0.672370
Validation R2 logP = 0.803820
Epoch 18
Train function
Loss = 1.7009e-03, PNorm = 59.6452, GNorm = 1.0232, lr_0 = 6.7968e-04
Loss = 1.6050e-03, PNorm = 59.7053, GNorm = 1.1936, lr_0 = 6.7668e-04
Loss = 1.6338e-03, PNorm = 59.7530, GNorm = 1.8100, lr_0 = 6.7368e-04
Loss = 1.6135e-03, PNorm = 59.8083, GNorm = 1.6675, lr_0 = 6.7070e-04
Loss = 1.6997e-03, PNorm = 59.8737, GNorm = 1.0306, lr_0 = 6.6774e-04
Validation rmse logD = 0.608673
Validation R2 logD = 0.762670
Validation rmse logP = 0.645756
Validation R2 logP = 0.819043
Epoch 19
Train function
Loss = 7.2351e-04, PNorm = 59.9433, GNorm = 0.5562, lr_0 = 6.6449e-04
Loss = 1.1037e-03, PNorm = 59.9976, GNorm = 0.7399, lr_0 = 6.6155e-04
Loss = 1.2512e-03, PNorm = 60.0437, GNorm = 0.8427, lr_0 = 6.5862e-04
Loss = 1.2775e-03, PNorm = 60.0876, GNorm = 1.1843, lr_0 = 6.5571e-04
Loss = 1.1263e-03, PNorm = 60.1217, GNorm = 0.4706, lr_0 = 6.5281e-04
Loss = 1.0911e-03, PNorm = 60.1636, GNorm = 1.0374, lr_0 = 6.4992e-04
Validation rmse logD = 0.608374
Validation R2 logD = 0.762903
Validation rmse logP = 0.651860
Validation R2 logP = 0.815606
Epoch 20
Train function
Loss = 8.6937e-04, PNorm = 60.2109, GNorm = 0.4426, lr_0 = 6.4676e-04
Loss = 7.8700e-04, PNorm = 60.2443, GNorm = 0.5916, lr_0 = 6.4390e-04
Loss = 1.0888e-03, PNorm = 60.2753, GNorm = 1.2299, lr_0 = 6.4105e-04
Loss = 9.3235e-04, PNorm = 60.3126, GNorm = 1.2518, lr_0 = 6.3822e-04
Loss = 1.0585e-03, PNorm = 60.3524, GNorm = 1.5859, lr_0 = 6.3539e-04
Validation rmse logD = 0.623522
Validation R2 logD = 0.750949
Validation rmse logP = 0.683742
Validation R2 logP = 0.797128
Epoch 21
Train function
Loss = 1.2009e-03, PNorm = 60.4057, GNorm = 1.2572, lr_0 = 6.3230e-04
Loss = 9.8800e-04, PNorm = 60.4551, GNorm = 1.6649, lr_0 = 6.2950e-04
Loss = 1.0670e-03, PNorm = 60.5000, GNorm = 0.7838, lr_0 = 6.2672e-04
Loss = 7.6899e-04, PNorm = 60.5416, GNorm = 0.9190, lr_0 = 6.2395e-04
Loss = 1.1166e-03, PNorm = 60.5754, GNorm = 1.4451, lr_0 = 6.2119e-04
Validation rmse logD = 0.606282
Validation R2 logD = 0.764530
Validation rmse logP = 0.639004
Validation R2 logP = 0.822808
Epoch 22
Train function
Loss = 1.0951e-03, PNorm = 60.6181, GNorm = 0.6378, lr_0 = 6.1817e-04
Loss = 7.3556e-04, PNorm = 60.6588, GNorm = 0.8973, lr_0 = 6.1543e-04
Loss = 6.3062e-04, PNorm = 60.7000, GNorm = 0.7716, lr_0 = 6.1271e-04
Loss = 8.4556e-04, PNorm = 60.7251, GNorm = 0.9805, lr_0 = 6.1000e-04
Loss = 8.4407e-04, PNorm = 60.7576, GNorm = 0.7165, lr_0 = 6.0730e-04
Loss = 7.3480e-04, PNorm = 60.7894, GNorm = 0.6582, lr_0 = 6.0461e-04
Validation rmse logD = 0.614422
Validation R2 logD = 0.758165
Validation rmse logP = 0.658997
Validation R2 logP = 0.811546
Epoch 23
Train function
Loss = 6.8476e-04, PNorm = 60.8189, GNorm = 0.7589, lr_0 = 6.0167e-04
Loss = 7.7105e-04, PNorm = 60.8419, GNorm = 0.5537, lr_0 = 5.9901e-04
Loss = 7.1106e-04, PNorm = 60.8744, GNorm = 1.6717, lr_0 = 5.9636e-04
Loss = 7.9982e-04, PNorm = 60.9190, GNorm = 0.8633, lr_0 = 5.9372e-04
Loss = 8.3564e-04, PNorm = 60.9557, GNorm = 1.2708, lr_0 = 5.9110e-04
Validation rmse logD = 0.606082
Validation R2 logD = 0.764686
Validation rmse logP = 0.640859
Validation R2 logP = 0.821777
Epoch 24
Train function
Loss = 5.3124e-04, PNorm = 60.9999, GNorm = 0.9441, lr_0 = 5.8822e-04
Loss = 5.8974e-04, PNorm = 61.0327, GNorm = 0.5897, lr_0 = 5.8562e-04
Loss = 7.3519e-04, PNorm = 61.0645, GNorm = 0.3466, lr_0 = 5.8303e-04
Loss = 6.3880e-04, PNorm = 61.0882, GNorm = 0.3190, lr_0 = 5.8045e-04
Loss = 6.4763e-04, PNorm = 61.1204, GNorm = 0.3792, lr_0 = 5.7788e-04
Validation rmse logD = 0.591524
Validation R2 logD = 0.775855
Validation rmse logP = 0.652915
Validation R2 logP = 0.815009
Epoch 25
Train function
Loss = 3.7348e-04, PNorm = 61.1467, GNorm = 0.5299, lr_0 = 5.7533e-04
Loss = 5.2701e-04, PNorm = 61.1767, GNorm = 0.3825, lr_0 = 5.7278e-04
Loss = 5.5198e-04, PNorm = 61.2063, GNorm = 0.6116, lr_0 = 5.7025e-04
Loss = 4.6477e-04, PNorm = 61.2323, GNorm = 0.7188, lr_0 = 5.6773e-04
Loss = 5.2920e-04, PNorm = 61.2566, GNorm = 0.3454, lr_0 = 5.6522e-04
Loss = 6.6815e-04, PNorm = 61.2835, GNorm = 0.6907, lr_0 = 5.6272e-04
Validation rmse logD = 0.599995
Validation R2 logD = 0.769389
Validation rmse logP = 0.631375
Validation R2 logP = 0.827013
Epoch 26
Train function
Loss = 5.5927e-04, PNorm = 61.3276, GNorm = 0.4455, lr_0 = 5.5998e-04
Loss = 5.0154e-04, PNorm = 61.3590, GNorm = 0.6158, lr_0 = 5.5750e-04
Loss = 7.2086e-04, PNorm = 61.3881, GNorm = 0.7661, lr_0 = 5.5503e-04
Loss = 5.6922e-04, PNorm = 61.4158, GNorm = 0.5122, lr_0 = 5.5258e-04
Loss = 5.7505e-04, PNorm = 61.4419, GNorm = 0.3653, lr_0 = 5.5014e-04
Validation rmse logD = 0.603169
Validation R2 logD = 0.766942
Validation rmse logP = 0.638805
Validation R2 logP = 0.822918
Epoch 27
Train function
Loss = 4.5675e-04, PNorm = 61.4756, GNorm = 0.9353, lr_0 = 5.4746e-04
Loss = 5.7908e-04, PNorm = 61.5084, GNorm = 1.4084, lr_0 = 5.4504e-04
Loss = 4.4544e-04, PNorm = 61.5390, GNorm = 0.5782, lr_0 = 5.4263e-04
Loss = 4.1627e-04, PNorm = 61.5639, GNorm = 0.8381, lr_0 = 5.4023e-04
Loss = 4.5471e-04, PNorm = 61.5843, GNorm = 0.7692, lr_0 = 5.3784e-04
Validation rmse logD = 0.610656
Validation R2 logD = 0.761121
Validation rmse logP = 0.655047
Validation R2 logP = 0.813798
Epoch 28
Train function
Loss = 4.6013e-04, PNorm = 61.6107, GNorm = 0.5707, lr_0 = 5.3522e-04
Loss = 5.1976e-04, PNorm = 61.6345, GNorm = 0.5044, lr_0 = 5.3285e-04
Loss = 4.4774e-04, PNorm = 61.6579, GNorm = 1.0947, lr_0 = 5.3050e-04
Loss = 4.3140e-04, PNorm = 61.6818, GNorm = 0.3836, lr_0 = 5.2815e-04
Loss = 4.3225e-04, PNorm = 61.7027, GNorm = 0.4501, lr_0 = 5.2581e-04
Loss = 3.8779e-04, PNorm = 61.7234, GNorm = 0.3930, lr_0 = 5.2349e-04
Loss = 1.0249e-03, PNorm = 61.7256, GNorm = 0.6244, lr_0 = 5.2326e-04
Validation rmse logD = 0.589809
Validation R2 logD = 0.777152
Validation rmse logP = 0.666657
Validation R2 logP = 0.807140
Epoch 29
Train function
Loss = 3.9906e-04, PNorm = 61.7489, GNorm = 0.4297, lr_0 = 5.2094e-04
Loss = 3.1810e-04, PNorm = 61.7618, GNorm = 0.2759, lr_0 = 5.1864e-04
Loss = 3.0226e-04, PNorm = 61.7789, GNorm = 0.6302, lr_0 = 5.1634e-04
Loss = 3.9400e-04, PNorm = 61.8018, GNorm = 0.4056, lr_0 = 5.1406e-04
Loss = 3.8536e-04, PNorm = 61.8244, GNorm = 0.5494, lr_0 = 5.1178e-04
Validation rmse logD = 0.594814
Validation R2 logD = 0.773354
Validation rmse logP = 0.646848
Validation R2 logP = 0.818431
Epoch 30
Train function
Loss = 3.2104e-04, PNorm = 61.8412, GNorm = 0.6178, lr_0 = 5.0930e-04
Loss = 4.0925e-04, PNorm = 61.8562, GNorm = 0.5452, lr_0 = 5.0704e-04
Loss = 3.3280e-04, PNorm = 61.8760, GNorm = 0.5407, lr_0 = 5.0480e-04
Loss = 3.1877e-04, PNorm = 61.8943, GNorm = 0.2936, lr_0 = 5.0257e-04
Loss = 4.0511e-04, PNorm = 61.9118, GNorm = 0.3926, lr_0 = 5.0034e-04
Validation rmse logD = 0.619505
Validation R2 logD = 0.754148
Validation rmse logP = 0.649642
Validation R2 logP = 0.816859
Epoch 31
Train function
Loss = 4.9885e-04, PNorm = 61.9352, GNorm = 1.2537, lr_0 = 4.9791e-04
Loss = 4.2705e-04, PNorm = 61.9666, GNorm = 1.1445, lr_0 = 4.9571e-04
Loss = 4.4448e-04, PNorm = 61.9943, GNorm = 1.0337, lr_0 = 4.9351e-04
Loss = 4.4272e-04, PNorm = 62.0122, GNorm = 0.5749, lr_0 = 4.9133e-04
Loss = 3.6444e-04, PNorm = 62.0381, GNorm = 0.2843, lr_0 = 4.8916e-04
Validation rmse logD = 0.592596
Validation R2 logD = 0.775041
Validation rmse logP = 0.637427
Validation R2 logP = 0.823681
Epoch 32
Train function
Loss = 2.5191e-04, PNorm = 62.0613, GNorm = 0.3294, lr_0 = 4.8678e-04
Loss = 3.9649e-04, PNorm = 62.0784, GNorm = 1.1002, lr_0 = 4.8463e-04
Loss = 2.8031e-04, PNorm = 62.0988, GNorm = 0.4876, lr_0 = 4.8248e-04
Loss = 3.5315e-04, PNorm = 62.1171, GNorm = 0.8395, lr_0 = 4.8035e-04
Loss = 2.9867e-04, PNorm = 62.1344, GNorm = 1.0934, lr_0 = 4.7822e-04
Loss = 3.2468e-04, PNorm = 62.1509, GNorm = 0.2626, lr_0 = 4.7611e-04
Validation rmse logD = 0.594680
Validation R2 logD = 0.773456
Validation rmse logP = 0.645457
Validation R2 logP = 0.819210
Epoch 33
Train function
Loss = 2.5614e-04, PNorm = 62.1686, GNorm = 0.3634, lr_0 = 4.7379e-04
Loss = 2.4035e-04, PNorm = 62.1810, GNorm = 0.3650, lr_0 = 4.7170e-04
Loss = 3.0163e-04, PNorm = 62.1930, GNorm = 0.3274, lr_0 = 4.6961e-04
Loss = 2.3646e-04, PNorm = 62.2082, GNorm = 0.6473, lr_0 = 4.6753e-04
Loss = 2.5804e-04, PNorm = 62.2192, GNorm = 0.6173, lr_0 = 4.6546e-04
Validation rmse logD = 0.592421
Validation R2 logD = 0.775174
Validation rmse logP = 0.645049
Validation R2 logP = 0.819439
Epoch 34
Train function
Loss = 2.4877e-04, PNorm = 62.2323, GNorm = 0.2543, lr_0 = 4.6341e-04
Loss = 2.3689e-04, PNorm = 62.2483, GNorm = 0.4656, lr_0 = 4.6136e-04
Loss = 2.2101e-04, PNorm = 62.2604, GNorm = 0.9192, lr_0 = 4.5931e-04
Loss = 2.5414e-04, PNorm = 62.2744, GNorm = 0.5676, lr_0 = 4.5728e-04
Loss = 2.5999e-04, PNorm = 62.2923, GNorm = 0.2966, lr_0 = 4.5526e-04
Validation rmse logD = 0.590640
Validation R2 logD = 0.776524
Validation rmse logP = 0.636849
Validation R2 logP = 0.824001
Epoch 35
Train function
Loss = 3.3522e-04, PNorm = 62.3032, GNorm = 0.4604, lr_0 = 4.5305e-04
Loss = 1.9347e-04, PNorm = 62.3126, GNorm = 0.6805, lr_0 = 4.5104e-04
Loss = 2.5151e-04, PNorm = 62.3267, GNorm = 0.2612, lr_0 = 4.4905e-04
Loss = 2.2421e-04, PNorm = 62.3403, GNorm = 0.2873, lr_0 = 4.4706e-04
Loss = 1.6990e-04, PNorm = 62.3520, GNorm = 0.3868, lr_0 = 4.4508e-04
Loss = 2.3416e-04, PNorm = 62.3661, GNorm = 0.6909, lr_0 = 4.4311e-04
Validation rmse logD = 0.590541
Validation R2 logD = 0.776599
Validation rmse logP = 0.642419
Validation R2 logP = 0.820909
Epoch 36
Train function
Loss = 1.9390e-04, PNorm = 62.3841, GNorm = 0.4033, lr_0 = 4.4096e-04
Loss = 1.7562e-04, PNorm = 62.3965, GNorm = 0.2727, lr_0 = 4.3901e-04
Loss = 1.7465e-04, PNorm = 62.4045, GNorm = 0.3175, lr_0 = 4.3707e-04
Loss = 2.5325e-04, PNorm = 62.4153, GNorm = 0.9312, lr_0 = 4.3513e-04
Loss = 2.0043e-04, PNorm = 62.4311, GNorm = 0.5623, lr_0 = 4.3321e-04
Validation rmse logD = 0.591443
Validation R2 logD = 0.775916
Validation rmse logP = 0.637304
Validation R2 logP = 0.823749
Epoch 37
Train function
Loss = 2.0399e-04, PNorm = 62.4395, GNorm = 0.4477, lr_0 = 4.3110e-04
Loss = 2.3422e-04, PNorm = 62.4525, GNorm = 1.2610, lr_0 = 4.2919e-04
Loss = 1.9766e-04, PNorm = 62.4654, GNorm = 0.4079, lr_0 = 4.2729e-04
Loss = 1.9144e-04, PNorm = 62.4828, GNorm = 0.5915, lr_0 = 4.2540e-04
Loss = 2.0365e-04, PNorm = 62.4966, GNorm = 0.8735, lr_0 = 4.2352e-04
Validation rmse logD = 0.595177
Validation R2 logD = 0.773077
Validation rmse logP = 0.643954
Validation R2 logP = 0.820051
Epoch 38
Train function
Loss = 1.4912e-04, PNorm = 62.5153, GNorm = 0.2119, lr_0 = 4.2146e-04
Loss = 1.7558e-04, PNorm = 62.5255, GNorm = 0.6463, lr_0 = 4.1960e-04
Loss = 2.1312e-04, PNorm = 62.5364, GNorm = 0.2714, lr_0 = 4.1774e-04
Loss = 1.8653e-04, PNorm = 62.5413, GNorm = 0.2562, lr_0 = 4.1589e-04
Loss = 1.6704e-04, PNorm = 62.5548, GNorm = 0.3466, lr_0 = 4.1406e-04
Loss = 1.4283e-04, PNorm = 62.5626, GNorm = 0.5465, lr_0 = 4.1222e-04
Validation rmse logD = 0.595807
Validation R2 logD = 0.772597
Validation rmse logP = 0.645311
Validation R2 logP = 0.819292
Epoch 39
Train function
Loss = 1.8008e-04, PNorm = 62.5730, GNorm = 0.2728, lr_0 = 4.1022e-04
Loss = 1.7632e-04, PNorm = 62.5848, GNorm = 0.3466, lr_0 = 4.0840e-04
Loss = 1.2215e-04, PNorm = 62.5933, GNorm = 0.2322, lr_0 = 4.0660e-04
Loss = 2.1518e-04, PNorm = 62.6031, GNorm = 0.5008, lr_0 = 4.0480e-04
Loss = 1.9229e-04, PNorm = 62.6125, GNorm = 0.6805, lr_0 = 4.0301e-04
Validation rmse logD = 0.597311
Validation R2 logD = 0.771447
Validation rmse logP = 0.645462
Validation R2 logP = 0.819208
Epoch 40
Train function
Loss = 1.9715e-04, PNorm = 62.6241, GNorm = 0.5069, lr_0 = 4.0105e-04
Loss = 2.2747e-04, PNorm = 62.6334, GNorm = 0.8853, lr_0 = 3.9927e-04
Loss = 1.4792e-04, PNorm = 62.6462, GNorm = 0.3204, lr_0 = 3.9751e-04
Loss = 1.5878e-04, PNorm = 62.6578, GNorm = 0.3289, lr_0 = 3.9575e-04
Loss = 1.4218e-04, PNorm = 62.6697, GNorm = 0.2617, lr_0 = 3.9400e-04
Validation rmse logD = 0.595328
Validation R2 logD = 0.772962
Validation rmse logP = 0.640385
Validation R2 logP = 0.822041
Epoch 41
Train function
Loss = 1.1234e-04, PNorm = 62.6822, GNorm = 0.1742, lr_0 = 3.9208e-04
Loss = 1.7859e-04, PNorm = 62.6906, GNorm = 0.4565, lr_0 = 3.9035e-04
Loss = 1.5303e-04, PNorm = 62.7032, GNorm = 0.2384, lr_0 = 3.8862e-04
Loss = 1.3868e-04, PNorm = 62.7138, GNorm = 0.2646, lr_0 = 3.8690e-04
Loss = 1.4760e-04, PNorm = 62.7243, GNorm = 0.2218, lr_0 = 3.8519e-04
Loss = 1.4786e-04, PNorm = 62.7339, GNorm = 0.2070, lr_0 = 3.8349e-04
Validation rmse logD = 0.590765
Validation R2 logD = 0.776430
Validation rmse logP = 0.640339
Validation R2 logP = 0.822066
Epoch 42
Train function
Loss = 1.2886e-04, PNorm = 62.7428, GNorm = 0.6798, lr_0 = 3.8179e-04
Loss = 1.5632e-04, PNorm = 62.7544, GNorm = 0.4830, lr_0 = 3.8010e-04
Loss = 1.4301e-04, PNorm = 62.7634, GNorm = 0.3790, lr_0 = 3.7842e-04
Loss = 1.3101e-04, PNorm = 62.7738, GNorm = 0.5042, lr_0 = 3.7675e-04
Loss = 1.3404e-04, PNorm = 62.7840, GNorm = 0.2252, lr_0 = 3.7508e-04
Validation rmse logD = 0.591972
Validation R2 logD = 0.775515
Validation rmse logP = 0.634054
Validation R2 logP = 0.825542
Epoch 43
Train function
Loss = 1.3556e-04, PNorm = 62.7891, GNorm = 0.3770, lr_0 = 3.7326e-04
Loss = 1.2197e-04, PNorm = 62.7965, GNorm = 0.3188, lr_0 = 3.7160e-04
Loss = 1.2818e-04, PNorm = 62.8028, GNorm = 0.4764, lr_0 = 3.6996e-04
Loss = 1.3218e-04, PNorm = 62.8093, GNorm = 0.6880, lr_0 = 3.6832e-04
Loss = 1.5988e-04, PNorm = 62.8190, GNorm = 0.5770, lr_0 = 3.6669e-04
Validation rmse logD = 0.592087
Validation R2 logD = 0.775428
Validation rmse logP = 0.632306
Validation R2 logP = 0.826503
Epoch 44
Train function
Loss = 1.6488e-04, PNorm = 62.8289, GNorm = 0.5857, lr_0 = 3.6491e-04
Loss = 2.0470e-04, PNorm = 62.8402, GNorm = 0.7506, lr_0 = 3.6330e-04
Loss = 2.0574e-04, PNorm = 62.8522, GNorm = 0.8010, lr_0 = 3.6169e-04
Loss = 1.8489e-04, PNorm = 62.8677, GNorm = 0.3668, lr_0 = 3.6009e-04
Loss = 1.8726e-04, PNorm = 62.8770, GNorm = 0.5950, lr_0 = 3.5850e-04
Loss = 1.6151e-04, PNorm = 62.8870, GNorm = 0.4186, lr_0 = 3.5691e-04
Loss = 8.2402e-04, PNorm = 62.8886, GNorm = 0.5253, lr_0 = 3.5675e-04
Validation rmse logD = 0.592961
Validation R2 logD = 0.774764
Validation rmse logP = 0.638205
Validation R2 logP = 0.823250
Epoch 45
Train function
Loss = 1.5013e-04, PNorm = 62.8989, GNorm = 0.5202, lr_0 = 3.5518e-04
Loss = 1.1484e-04, PNorm = 62.9066, GNorm = 0.2656, lr_0 = 3.5360e-04
Loss = 1.2407e-04, PNorm = 62.9132, GNorm = 0.5565, lr_0 = 3.5204e-04
Loss = 1.2912e-04, PNorm = 62.9209, GNorm = 0.1966, lr_0 = 3.5048e-04
Loss = 9.8597e-05, PNorm = 62.9282, GNorm = 0.2902, lr_0 = 3.4893e-04
Validation rmse logD = 0.599608
Validation R2 logD = 0.769686
Validation rmse logP = 0.637477
Validation R2 logP = 0.823653
Epoch 46
Train function
Loss = 1.6791e-04, PNorm = 62.9352, GNorm = 0.5509, lr_0 = 3.4724e-04
Loss = 1.3853e-04, PNorm = 62.9413, GNorm = 0.3722, lr_0 = 3.4570e-04
Loss = 1.2499e-04, PNorm = 62.9512, GNorm = 0.2361, lr_0 = 3.4417e-04
Loss = 1.3785e-04, PNorm = 62.9613, GNorm = 0.2258, lr_0 = 3.4265e-04
Loss = 9.9985e-05, PNorm = 62.9706, GNorm = 0.4430, lr_0 = 3.4113e-04
Validation rmse logD = 0.592281
Validation R2 logD = 0.775280
Validation rmse logP = 0.643524
Validation R2 logP = 0.820292
Epoch 47
Train function
Loss = 1.0297e-04, PNorm = 62.9729, GNorm = 0.3493, lr_0 = 3.3947e-04
Loss = 1.0866e-04, PNorm = 62.9793, GNorm = 0.1399, lr_0 = 3.3797e-04
Loss = 1.3340e-04, PNorm = 62.9856, GNorm = 0.6306, lr_0 = 3.3648e-04
Loss = 1.3335e-04, PNorm = 62.9932, GNorm = 0.1475, lr_0 = 3.3499e-04
Loss = 1.0477e-04, PNorm = 63.0005, GNorm = 0.3127, lr_0 = 3.3351e-04
Validation rmse logD = 0.590811
Validation R2 logD = 0.776395
Validation rmse logP = 0.633760
Validation R2 logP = 0.825704
Epoch 48
Train function
Loss = 7.9236e-05, PNorm = 63.0093, GNorm = 0.2188, lr_0 = 3.3188e-04
Loss = 9.2194e-05, PNorm = 63.0152, GNorm = 0.2079, lr_0 = 3.3042e-04
Loss = 8.5621e-05, PNorm = 63.0199, GNorm = 0.1545, lr_0 = 3.2895e-04
Loss = 7.1635e-05, PNorm = 63.0257, GNorm = 0.4002, lr_0 = 3.2750e-04
Loss = 8.7854e-05, PNorm = 63.0321, GNorm = 0.1920, lr_0 = 3.2605e-04
Loss = 8.4268e-05, PNorm = 63.0356, GNorm = 0.2681, lr_0 = 3.2461e-04
Validation rmse logD = 0.590225
Validation R2 logD = 0.776838
Validation rmse logP = 0.637984
Validation R2 logP = 0.823373
Epoch 49
Train function
Loss = 5.9556e-05, PNorm = 63.0412, GNorm = 0.3338, lr_0 = 3.2303e-04
Loss = 6.2618e-05, PNorm = 63.0468, GNorm = 0.1981, lr_0 = 3.2160e-04
Loss = 5.5267e-05, PNorm = 63.0499, GNorm = 0.1536, lr_0 = 3.2018e-04
Loss = 8.1628e-05, PNorm = 63.0536, GNorm = 0.3324, lr_0 = 3.1876e-04
Loss = 8.0372e-05, PNorm = 63.0598, GNorm = 0.4983, lr_0 = 3.1735e-04
Validation rmse logD = 0.589369
Validation R2 logD = 0.777485
Validation rmse logP = 0.632448
Validation R2 logP = 0.826424
Epoch 50
Train function
Loss = 7.7320e-05, PNorm = 63.0657, GNorm = 0.2633, lr_0 = 3.1595e-04
Loss = 1.1716e-04, PNorm = 63.0704, GNorm = 0.2334, lr_0 = 3.1455e-04
Loss = 9.6265e-05, PNorm = 63.0790, GNorm = 0.3832, lr_0 = 3.1316e-04
Loss = 7.3394e-05, PNorm = 63.0854, GNorm = 0.1587, lr_0 = 3.1177e-04
Loss = 7.1845e-05, PNorm = 63.0894, GNorm = 0.4239, lr_0 = 3.1039e-04
Validation rmse logD = 0.588967
Validation R2 logD = 0.777788
Validation rmse logP = 0.634969
Validation R2 logP = 0.825038
Epoch 51
Train function
Loss = 4.7055e-05, PNorm = 63.0937, GNorm = 0.2601, lr_0 = 3.0888e-04
Loss = 1.3381e-04, PNorm = 63.0972, GNorm = 0.5490, lr_0 = 3.0752e-04
Loss = 1.3112e-04, PNorm = 63.1043, GNorm = 0.4591, lr_0 = 3.0616e-04
Loss = 7.9876e-05, PNorm = 63.1156, GNorm = 0.6373, lr_0 = 3.0480e-04
Loss = 8.6229e-05, PNorm = 63.1240, GNorm = 0.4537, lr_0 = 3.0346e-04
Loss = 8.9721e-05, PNorm = 63.1301, GNorm = 0.5838, lr_0 = 3.0211e-04
Validation rmse logD = 0.589931
Validation R2 logD = 0.777060
Validation rmse logP = 0.634366
Validation R2 logP = 0.825370
Epoch 52
Train function
Loss = 7.9178e-05, PNorm = 63.1358, GNorm = 0.1575, lr_0 = 3.0064e-04
Loss = 7.3070e-05, PNorm = 63.1411, GNorm = 0.2369, lr_0 = 2.9931e-04
Loss = 8.5174e-05, PNorm = 63.1452, GNorm = 0.2379, lr_0 = 2.9799e-04
Loss = 7.6657e-05, PNorm = 63.1495, GNorm = 0.2134, lr_0 = 2.9667e-04
Loss = 7.8124e-05, PNorm = 63.1544, GNorm = 0.2559, lr_0 = 2.9536e-04
Validation rmse logD = 0.588861
Validation R2 logD = 0.777868
Validation rmse logP = 0.633453
Validation R2 logP = 0.825872
Epoch 53
Train function
Loss = 5.8173e-05, PNorm = 63.1609, GNorm = 0.1933, lr_0 = 2.9392e-04
Loss = 7.1404e-05, PNorm = 63.1639, GNorm = 0.2419, lr_0 = 2.9262e-04
Loss = 6.7592e-05, PNorm = 63.1677, GNorm = 0.2085, lr_0 = 2.9133e-04
Loss = 7.7421e-05, PNorm = 63.1741, GNorm = 0.2510, lr_0 = 2.9004e-04
Loss = 6.3254e-05, PNorm = 63.1814, GNorm = 0.4817, lr_0 = 2.8876e-04
Validation rmse logD = 0.590513
Validation R2 logD = 0.776620
Validation rmse logP = 0.636782
Validation R2 logP = 0.824038
Epoch 54
Train function
Loss = 6.0100e-05, PNorm = 63.1834, GNorm = 0.4668, lr_0 = 2.8735e-04
Loss = 8.4996e-05, PNorm = 63.1878, GNorm = 0.2791, lr_0 = 2.8608e-04
Loss = 7.8383e-05, PNorm = 63.1940, GNorm = 0.1534, lr_0 = 2.8482e-04
Loss = 6.5004e-05, PNorm = 63.1994, GNorm = 0.1241, lr_0 = 2.8356e-04
Loss = 7.1960e-05, PNorm = 63.2038, GNorm = 0.2992, lr_0 = 2.8230e-04
Loss = 7.8937e-05, PNorm = 63.2076, GNorm = 0.2283, lr_0 = 2.8105e-04
Validation rmse logD = 0.589910
Validation R2 logD = 0.777076
Validation rmse logP = 0.630888
Validation R2 logP = 0.827280
Epoch 55
Train function
Loss = 5.6009e-05, PNorm = 63.2113, GNorm = 0.1456, lr_0 = 2.7969e-04
Loss = 5.0617e-05, PNorm = 63.2180, GNorm = 0.1180, lr_0 = 2.7845e-04
Loss = 4.0084e-05, PNorm = 63.2198, GNorm = 0.1444, lr_0 = 2.7722e-04
Loss = 4.2814e-05, PNorm = 63.2236, GNorm = 0.1425, lr_0 = 2.7599e-04
Loss = 5.0045e-05, PNorm = 63.2262, GNorm = 0.1505, lr_0 = 2.7477e-04
Validation rmse logD = 0.590497
Validation R2 logD = 0.776632
Validation rmse logP = 0.637047
Validation R2 logP = 0.823891
Epoch 56
Train function
Loss = 6.2544e-05, PNorm = 63.2310, GNorm = 0.3070, lr_0 = 2.7343e-04
Loss = 6.2442e-05, PNorm = 63.2356, GNorm = 0.1791, lr_0 = 2.7222e-04
Loss = 5.1619e-05, PNorm = 63.2401, GNorm = 0.1438, lr_0 = 2.7102e-04
Loss = 5.2660e-05, PNorm = 63.2431, GNorm = 0.1468, lr_0 = 2.6982e-04
Loss = 6.0520e-05, PNorm = 63.2449, GNorm = 0.1333, lr_0 = 2.6863e-04
Validation rmse logD = 0.590352
Validation R2 logD = 0.776742
Validation rmse logP = 0.641247
Validation R2 logP = 0.821561
Epoch 57
Train function
Loss = 4.8725e-05, PNorm = 63.2499, GNorm = 0.1994, lr_0 = 2.6732e-04
Loss = 5.1453e-05, PNorm = 63.2532, GNorm = 0.3195, lr_0 = 2.6614e-04
Loss = 5.2810e-05, PNorm = 63.2551, GNorm = 0.2046, lr_0 = 2.6496e-04
Loss = 4.1565e-05, PNorm = 63.2584, GNorm = 0.1530, lr_0 = 2.6379e-04
Loss = 4.0670e-05, PNorm = 63.2622, GNorm = 0.1448, lr_0 = 2.6262e-04
Loss = 4.9482e-05, PNorm = 63.2640, GNorm = 0.1761, lr_0 = 2.6146e-04
Loss = 1.6588e-04, PNorm = 63.2642, GNorm = 0.2468, lr_0 = 2.6134e-04
Validation rmse logD = 0.591017
Validation R2 logD = 0.776239
Validation rmse logP = 0.635595
Validation R2 logP = 0.824693
Epoch 58
Train function
Loss = 3.7732e-05, PNorm = 63.2676, GNorm = 0.3340, lr_0 = 2.6019e-04
Loss = 4.9538e-05, PNorm = 63.2704, GNorm = 0.3011, lr_0 = 2.5904e-04
Loss = 4.5213e-05, PNorm = 63.2727, GNorm = 0.1557, lr_0 = 2.5789e-04
Loss = 3.8173e-05, PNorm = 63.2749, GNorm = 0.0817, lr_0 = 2.5675e-04
Loss = 4.2454e-05, PNorm = 63.2787, GNorm = 0.2214, lr_0 = 2.5561e-04
Validation rmse logD = 0.593169
Validation R2 logD = 0.774606
Validation rmse logP = 0.630179
Validation R2 logP = 0.827668
Epoch 59
Train function
Loss = 5.5015e-05, PNorm = 63.2829, GNorm = 0.3127, lr_0 = 2.5448e-04
Loss = 4.7402e-05, PNorm = 63.2861, GNorm = 0.1924, lr_0 = 2.5336e-04
Loss = 3.5489e-05, PNorm = 63.2898, GNorm = 0.2513, lr_0 = 2.5224e-04
Loss = 3.3151e-05, PNorm = 63.2933, GNorm = 0.1549, lr_0 = 2.5112e-04
Loss = 3.1637e-05, PNorm = 63.2962, GNorm = 0.1313, lr_0 = 2.5001e-04
Validation rmse logD = 0.587385
Validation R2 logD = 0.778980
Validation rmse logP = 0.629543
Validation R2 logP = 0.828016
Epoch 60
Train function
Loss = 5.6751e-05, PNorm = 63.2993, GNorm = 0.4995, lr_0 = 2.4879e-04
Loss = 4.1678e-05, PNorm = 63.3016, GNorm = 0.3409, lr_0 = 2.4769e-04
Loss = 3.9938e-05, PNorm = 63.3045, GNorm = 0.1676, lr_0 = 2.4660e-04
Loss = 4.7150e-05, PNorm = 63.3083, GNorm = 0.4816, lr_0 = 2.4551e-04
Loss = 4.8019e-05, PNorm = 63.3101, GNorm = 0.4537, lr_0 = 2.4442e-04
Loss = 5.7572e-05, PNorm = 63.3127, GNorm = 0.1720, lr_0 = 2.4334e-04
Loss = 2.3520e-04, PNorm = 63.3133, GNorm = 0.2332, lr_0 = 2.4323e-04
Validation rmse logD = 0.589307
Validation R2 logD = 0.777531
Validation rmse logP = 0.630538
Validation R2 logP = 0.827471
Epoch 61
Train function
Loss = 3.6238e-05, PNorm = 63.3169, GNorm = 0.1061, lr_0 = 2.4216e-04
Loss = 4.3885e-05, PNorm = 63.3207, GNorm = 0.1783, lr_0 = 2.4109e-04
Loss = 4.1218e-05, PNorm = 63.3224, GNorm = 0.2104, lr_0 = 2.4002e-04
Loss = 4.0296e-05, PNorm = 63.3252, GNorm = 0.1411, lr_0 = 2.3896e-04
Loss = 4.0511e-05, PNorm = 63.3283, GNorm = 0.1907, lr_0 = 2.3790e-04
Validation rmse logD = 0.589452
Validation R2 logD = 0.777422
Validation rmse logP = 0.629891
Validation R2 logP = 0.827825
Epoch 62
Train function
Loss = 4.4285e-05, PNorm = 63.3323, GNorm = 0.0783, lr_0 = 2.3674e-04
Loss = 3.2289e-05, PNorm = 63.3341, GNorm = 0.0872, lr_0 = 2.3570e-04
Loss = 3.7969e-05, PNorm = 63.3353, GNorm = 0.1094, lr_0 = 2.3465e-04
Loss = 3.8559e-05, PNorm = 63.3383, GNorm = 0.2122, lr_0 = 2.3362e-04
Loss = 3.3623e-05, PNorm = 63.3414, GNorm = 0.1253, lr_0 = 2.3258e-04
Validation rmse logD = 0.589749
Validation R2 logD = 0.777197
Validation rmse logP = 0.632433
Validation R2 logP = 0.826433
Epoch 63
Train function
Loss = 3.0374e-05, PNorm = 63.3450, GNorm = 0.3069, lr_0 = 2.3145e-04
Loss = 4.5601e-05, PNorm = 63.3478, GNorm = 0.5402, lr_0 = 2.3043e-04
Loss = 6.2240e-05, PNorm = 63.3516, GNorm = 0.6076, lr_0 = 2.2941e-04
Loss = 4.0778e-05, PNorm = 63.3556, GNorm = 0.3446, lr_0 = 2.2839e-04
Loss = 5.3123e-05, PNorm = 63.3599, GNorm = 0.0875, lr_0 = 2.2738e-04
Validation rmse logD = 0.589473
Validation R2 logD = 0.777406
Validation rmse logP = 0.630725
Validation R2 logP = 0.827369
Epoch 64
Train function
Loss = 5.3398e-05, PNorm = 63.3632, GNorm = 0.3802, lr_0 = 2.2628e-04
Loss = 4.1538e-05, PNorm = 63.3670, GNorm = 0.1170, lr_0 = 2.2528e-04
Loss = 3.7478e-05, PNorm = 63.3690, GNorm = 0.0923, lr_0 = 2.2428e-04
Loss = 3.5547e-05, PNorm = 63.3710, GNorm = 0.1750, lr_0 = 2.2329e-04
Loss = 3.4702e-05, PNorm = 63.3732, GNorm = 0.2939, lr_0 = 2.2230e-04
Loss = 3.4526e-05, PNorm = 63.3741, GNorm = 0.2353, lr_0 = 2.2132e-04
Validation rmse logD = 0.587808
Validation R2 logD = 0.778662
Validation rmse logP = 0.632211
Validation R2 logP = 0.826555
Epoch 65
Train function
Loss = 4.6525e-05, PNorm = 63.3791, GNorm = 0.5645, lr_0 = 2.2024e-04
Loss = 2.7335e-05, PNorm = 63.3807, GNorm = 0.0826, lr_0 = 2.1927e-04
Loss = 3.1978e-05, PNorm = 63.3828, GNorm = 0.1050, lr_0 = 2.1830e-04
Loss = 2.7280e-05, PNorm = 63.3855, GNorm = 0.1101, lr_0 = 2.1733e-04
Loss = 2.9553e-05, PNorm = 63.3883, GNorm = 0.1509, lr_0 = 2.1637e-04
Validation rmse logD = 0.589352
Validation R2 logD = 0.777497
Validation rmse logP = 0.628951
Validation R2 logP = 0.828339
Epoch 66
Train function
Loss = 3.6503e-05, PNorm = 63.3914, GNorm = 0.2587, lr_0 = 2.1532e-04
Loss = 4.3349e-05, PNorm = 63.3938, GNorm = 0.1099, lr_0 = 2.1436e-04
Loss = 4.7250e-05, PNorm = 63.3964, GNorm = 0.1281, lr_0 = 2.1342e-04
Loss = 4.1892e-05, PNorm = 63.4002, GNorm = 0.0919, lr_0 = 2.1247e-04
Loss = 3.8738e-05, PNorm = 63.4025, GNorm = 0.2135, lr_0 = 2.1153e-04
Validation rmse logD = 0.588917
Validation R2 logD = 0.777826
Validation rmse logP = 0.629396
Validation R2 logP = 0.828096
Epoch 67
Train function
Loss = 2.8350e-05, PNorm = 63.4060, GNorm = 0.1900, lr_0 = 2.1060e-04
Loss = 2.8264e-05, PNorm = 63.4059, GNorm = 0.1327, lr_0 = 2.0966e-04
Loss = 2.6502e-05, PNorm = 63.4075, GNorm = 0.0920, lr_0 = 2.0874e-04
Loss = 3.3451e-05, PNorm = 63.4093, GNorm = 0.1553, lr_0 = 2.0781e-04
Loss = 2.8529e-05, PNorm = 63.4118, GNorm = 0.2297, lr_0 = 2.0689e-04
Loss = 2.6604e-05, PNorm = 63.4130, GNorm = 0.2693, lr_0 = 2.0598e-04
Validation rmse logD = 0.587660
Validation R2 logD = 0.778774
Validation rmse logP = 0.630039
Validation R2 logP = 0.827745
Epoch 68
Train function
Loss = 3.4298e-05, PNorm = 63.4150, GNorm = 0.1303, lr_0 = 2.0498e-04
Loss = 2.4273e-05, PNorm = 63.4187, GNorm = 0.1118, lr_0 = 2.0407e-04
Loss = 2.4290e-05, PNorm = 63.4210, GNorm = 0.0813, lr_0 = 2.0317e-04
Loss = 2.3579e-05, PNorm = 63.4233, GNorm = 0.1969, lr_0 = 2.0227e-04
Loss = 3.1642e-05, PNorm = 63.4244, GNorm = 0.2957, lr_0 = 2.0137e-04
Validation rmse logD = 0.589368
Validation R2 logD = 0.777485
Validation rmse logP = 0.627643
Validation R2 logP = 0.829052
Epoch 69
Train function
Loss = 3.1068e-05, PNorm = 63.4265, GNorm = 0.0743, lr_0 = 2.0039e-04
Loss = 1.6389e-05, PNorm = 63.4278, GNorm = 0.1116, lr_0 = 1.9951e-04
Loss = 2.2309e-05, PNorm = 63.4303, GNorm = 0.1800, lr_0 = 1.9863e-04
Loss = 2.2914e-05, PNorm = 63.4327, GNorm = 0.1441, lr_0 = 1.9775e-04
Loss = 1.7945e-05, PNorm = 63.4338, GNorm = 0.0931, lr_0 = 1.9687e-04
Validation rmse logD = 0.588082
Validation R2 logD = 0.778456
Validation rmse logP = 0.630632
Validation R2 logP = 0.827420
Epoch 70
Train function
Loss = 2.7371e-05, PNorm = 63.4351, GNorm = 0.1399, lr_0 = 1.9592e-04
Loss = 2.5241e-05, PNorm = 63.4373, GNorm = 0.2574, lr_0 = 1.9505e-04
Loss = 1.7321e-05, PNorm = 63.4397, GNorm = 0.1119, lr_0 = 1.9419e-04
Loss = 1.8012e-05, PNorm = 63.4406, GNorm = 0.0827, lr_0 = 1.9333e-04
Loss = 2.0117e-05, PNorm = 63.4418, GNorm = 0.0763, lr_0 = 1.9247e-04
Loss = 2.1446e-05, PNorm = 63.4445, GNorm = 0.1266, lr_0 = 1.9162e-04
Validation rmse logD = 0.588882
Validation R2 logD = 0.777852
Validation rmse logP = 0.630206
Validation R2 logP = 0.827653
Epoch 71
Train function
Loss = 2.1127e-05, PNorm = 63.4457, GNorm = 0.1192, lr_0 = 1.9069e-04
Loss = 1.5956e-05, PNorm = 63.4465, GNorm = 0.0879, lr_0 = 1.8984e-04
Loss = 1.8691e-05, PNorm = 63.4490, GNorm = 0.1224, lr_0 = 1.8900e-04
Loss = 2.5423e-05, PNorm = 63.4500, GNorm = 0.2821, lr_0 = 1.8817e-04
Loss = 2.8478e-05, PNorm = 63.4510, GNorm = 0.4414, lr_0 = 1.8734e-04
Validation rmse logD = 0.589477
Validation R2 logD = 0.777403
Validation rmse logP = 0.631264
Validation R2 logP = 0.827074
Epoch 72
Train function
Loss = 4.6560e-05, PNorm = 63.4542, GNorm = 0.2004, lr_0 = 1.8643e-04
Loss = 3.6004e-05, PNorm = 63.4549, GNorm = 0.1220, lr_0 = 1.8560e-04
Loss = 4.2509e-05, PNorm = 63.4576, GNorm = 0.4164, lr_0 = 1.8478e-04
Loss = 2.7131e-05, PNorm = 63.4614, GNorm = 0.1852, lr_0 = 1.8396e-04
Loss = 3.6242e-05, PNorm = 63.4646, GNorm = 0.1656, lr_0 = 1.8315e-04
Validation rmse logD = 0.587190
Validation R2 logD = 0.779127
Validation rmse logP = 0.629783
Validation R2 logP = 0.827884
Epoch 73
Train function
Loss = 2.1216e-05, PNorm = 63.4674, GNorm = 0.1221, lr_0 = 1.8226e-04
Loss = 2.3302e-05, PNorm = 63.4701, GNorm = 0.2567, lr_0 = 1.8145e-04
Loss = 2.0366e-05, PNorm = 63.4710, GNorm = 0.1924, lr_0 = 1.8065e-04
Loss = 2.0893e-05, PNorm = 63.4729, GNorm = 0.1125, lr_0 = 1.7985e-04
Loss = 2.2747e-05, PNorm = 63.4743, GNorm = 0.0947, lr_0 = 1.7905e-04
Loss = 1.8090e-05, PNorm = 63.4752, GNorm = 0.1571, lr_0 = 1.7826e-04
Loss = 5.1832e-05, PNorm = 63.4753, GNorm = 0.1121, lr_0 = 1.7818e-04
Validation rmse logD = 0.587572
Validation R2 logD = 0.778840
Validation rmse logP = 0.631451
Validation R2 logP = 0.826971
Epoch 74
Train function
Loss = 2.1071e-05, PNorm = 63.4765, GNorm = 0.1821, lr_0 = 1.7739e-04
Loss = 1.4589e-05, PNorm = 63.4795, GNorm = 0.0780, lr_0 = 1.7661e-04
Loss = 1.1971e-05, PNorm = 63.4828, GNorm = 0.0606, lr_0 = 1.7583e-04
Loss = 1.5696e-05, PNorm = 63.4838, GNorm = 0.0943, lr_0 = 1.7505e-04
Loss = 1.3248e-05, PNorm = 63.4850, GNorm = 0.0765, lr_0 = 1.7428e-04
Validation rmse logD = 0.589216
Validation R2 logD = 0.777600
Validation rmse logP = 0.630419
Validation R2 logP = 0.827536
Epoch 75
Train function
Loss = 1.4440e-05, PNorm = 63.4868, GNorm = 0.0709, lr_0 = 1.7351e-04
Loss = 2.2425e-05, PNorm = 63.4878, GNorm = 0.1882, lr_0 = 1.7274e-04
Loss = 1.8853e-05, PNorm = 63.4888, GNorm = 0.1213, lr_0 = 1.7197e-04
Loss = 1.4172e-05, PNorm = 63.4905, GNorm = 0.0835, lr_0 = 1.7121e-04
Loss = 1.5153e-05, PNorm = 63.4916, GNorm = 0.1630, lr_0 = 1.7046e-04
Validation rmse logD = 0.589060
Validation R2 logD = 0.777718
Validation rmse logP = 0.629669
Validation R2 logP = 0.827947
Epoch 76
Train function
Loss = 1.2471e-05, PNorm = 63.4934, GNorm = 0.0984, lr_0 = 1.6963e-04
Loss = 1.4735e-05, PNorm = 63.4937, GNorm = 0.1189, lr_0 = 1.6888e-04
Loss = 1.0709e-05, PNorm = 63.4945, GNorm = 0.0722, lr_0 = 1.6813e-04
Loss = 1.8431e-05, PNorm = 63.4957, GNorm = 0.1812, lr_0 = 1.6739e-04
Loss = 1.5163e-05, PNorm = 63.4969, GNorm = 0.0646, lr_0 = 1.6665e-04
Loss = 1.5175e-05, PNorm = 63.4980, GNorm = 0.1360, lr_0 = 1.6591e-04
Loss = 8.4124e-05, PNorm = 63.4982, GNorm = 0.2529, lr_0 = 1.6584e-04
Validation rmse logD = 0.588209
Validation R2 logD = 0.778360
Validation rmse logP = 0.627537
Validation R2 logP = 0.829110
Epoch 77
Train function
Loss = 1.2567e-05, PNorm = 63.5000, GNorm = 0.1209, lr_0 = 1.6510e-04
Loss = 1.3134e-05, PNorm = 63.5015, GNorm = 0.0859, lr_0 = 1.6437e-04
Loss = 1.8129e-05, PNorm = 63.5028, GNorm = 0.1880, lr_0 = 1.6364e-04
Loss = 1.0761e-05, PNorm = 63.5041, GNorm = 0.0387, lr_0 = 1.6292e-04
Loss = 1.7566e-05, PNorm = 63.5056, GNorm = 0.1356, lr_0 = 1.6220e-04
Validation rmse logD = 0.588642
Validation R2 logD = 0.778034
Validation rmse logP = 0.629946
Validation R2 logP = 0.827795
Epoch 78
Train function
Loss = 2.6063e-05, PNorm = 63.5066, GNorm = 0.2646, lr_0 = 1.6141e-04
Loss = 2.1045e-05, PNorm = 63.5087, GNorm = 0.0589, lr_0 = 1.6070e-04
Loss = 1.6001e-05, PNorm = 63.5102, GNorm = 0.1913, lr_0 = 1.5999e-04
Loss = 1.5984e-05, PNorm = 63.5122, GNorm = 0.1868, lr_0 = 1.5928e-04
Loss = 1.9307e-05, PNorm = 63.5120, GNorm = 0.1016, lr_0 = 1.5857e-04
Validation rmse logD = 0.589225
Validation R2 logD = 0.777594
Validation rmse logP = 0.630349
Validation R2 logP = 0.827575
Epoch 79
Train function
Loss = 1.2571e-05, PNorm = 63.5141, GNorm = 0.1011, lr_0 = 1.5780e-04
Loss = 1.4885e-05, PNorm = 63.5164, GNorm = 0.0794, lr_0 = 1.5710e-04
Loss = 1.2902e-05, PNorm = 63.5173, GNorm = 0.0614, lr_0 = 1.5641e-04
Loss = 1.5158e-05, PNorm = 63.5186, GNorm = 0.1809, lr_0 = 1.5572e-04
Loss = 1.4248e-05, PNorm = 63.5194, GNorm = 0.1378, lr_0 = 1.5503e-04
Validation rmse logD = 0.588493
Validation R2 logD = 0.778146
Validation rmse logP = 0.630449
Validation R2 logP = 0.827520
Epoch 80
Train function
Loss = 1.9139e-05, PNorm = 63.5203, GNorm = 0.2954, lr_0 = 1.5427e-04
Loss = 1.6904e-05, PNorm = 63.5212, GNorm = 0.0723, lr_0 = 1.5359e-04
Loss = 1.2661e-05, PNorm = 63.5215, GNorm = 0.0887, lr_0 = 1.5291e-04
Loss = 1.4426e-05, PNorm = 63.5230, GNorm = 0.0679, lr_0 = 1.5224e-04
Loss = 1.2356e-05, PNorm = 63.5251, GNorm = 0.0595, lr_0 = 1.5156e-04
Loss = 1.5704e-05, PNorm = 63.5251, GNorm = 0.0385, lr_0 = 1.5089e-04
Validation rmse logD = 0.589952
Validation R2 logD = 0.777044
Validation rmse logP = 0.630116
Validation R2 logP = 0.827702
Epoch 81
Train function
Loss = 1.1789e-05, PNorm = 63.5266, GNorm = 0.2160, lr_0 = 1.5016e-04
Loss = 1.2520e-05, PNorm = 63.5278, GNorm = 0.1542, lr_0 = 1.4949e-04
Loss = 1.5701e-05, PNorm = 63.5292, GNorm = 0.1132, lr_0 = 1.4883e-04
Loss = 1.2679e-05, PNorm = 63.5308, GNorm = 0.1314, lr_0 = 1.4817e-04
Loss = 1.2496e-05, PNorm = 63.5314, GNorm = 0.0457, lr_0 = 1.4752e-04
Validation rmse logD = 0.589521
Validation R2 logD = 0.777370
Validation rmse logP = 0.629357
Validation R2 logP = 0.828117
Epoch 82
Train function
Loss = 1.0507e-05, PNorm = 63.5327, GNorm = 0.0517, lr_0 = 1.4680e-04
Loss = 7.4177e-06, PNorm = 63.5335, GNorm = 0.0640, lr_0 = 1.4615e-04
Loss = 1.0598e-05, PNorm = 63.5348, GNorm = 0.0854, lr_0 = 1.4551e-04
Loss = 1.1819e-05, PNorm = 63.5361, GNorm = 0.0845, lr_0 = 1.4486e-04
Loss = 1.4028e-05, PNorm = 63.5367, GNorm = 0.1449, lr_0 = 1.4422e-04
Validation rmse logD = 0.588591
Validation R2 logD = 0.778072
Validation rmse logP = 0.629975
Validation R2 logP = 0.827779
Epoch 83
Train function
Loss = 7.2479e-06, PNorm = 63.5381, GNorm = 0.1365, lr_0 = 1.4352e-04
Loss = 1.0154e-05, PNorm = 63.5401, GNorm = 0.0559, lr_0 = 1.4288e-04
Loss = 7.1430e-06, PNorm = 63.5412, GNorm = 0.0785, lr_0 = 1.4225e-04
Loss = 1.3233e-05, PNorm = 63.5417, GNorm = 0.1009, lr_0 = 1.4162e-04
Loss = 1.0233e-05, PNorm = 63.5428, GNorm = 0.0391, lr_0 = 1.4100e-04
Loss = 9.6013e-06, PNorm = 63.5435, GNorm = 0.1260, lr_0 = 1.4037e-04
Validation rmse logD = 0.588954
Validation R2 logD = 0.777798
Validation rmse logP = 0.629390
Validation R2 logP = 0.828099
Epoch 84
Train function
Loss = 7.3476e-06, PNorm = 63.5440, GNorm = 0.1450, lr_0 = 1.3975e-04
Loss = 8.4604e-06, PNorm = 63.5450, GNorm = 0.0493, lr_0 = 1.3913e-04
Loss = 1.0996e-05, PNorm = 63.5463, GNorm = 0.1942, lr_0 = 1.3852e-04
Loss = 6.9760e-06, PNorm = 63.5476, GNorm = 0.1591, lr_0 = 1.3791e-04
Loss = 9.4672e-06, PNorm = 63.5484, GNorm = 0.0890, lr_0 = 1.3730e-04
Validation rmse logD = 0.590158
Validation R2 logD = 0.776889
Validation rmse logP = 0.627203
Validation R2 logP = 0.829292
Epoch 85
Train function
Loss = 2.2274e-05, PNorm = 63.5495, GNorm = 0.1867, lr_0 = 1.3663e-04
Loss = 1.2698e-05, PNorm = 63.5508, GNorm = 0.0654, lr_0 = 1.3602e-04
Loss = 2.2533e-05, PNorm = 63.5520, GNorm = 0.2183, lr_0 = 1.3542e-04
Loss = 1.1910e-05, PNorm = 63.5525, GNorm = 0.1138, lr_0 = 1.3482e-04
Loss = 9.8344e-06, PNorm = 63.5537, GNorm = 0.1492, lr_0 = 1.3423e-04
Validation rmse logD = 0.588433
Validation R2 logD = 0.778191
Validation rmse logP = 0.629238
Validation R2 logP = 0.828182
Epoch 86
Train function
Loss = 7.4121e-06, PNorm = 63.5548, GNorm = 0.1012, lr_0 = 1.3357e-04
Loss = 8.7652e-06, PNorm = 63.5558, GNorm = 0.0488, lr_0 = 1.3298e-04
Loss = 8.6783e-06, PNorm = 63.5575, GNorm = 0.0614, lr_0 = 1.3239e-04
Loss = 9.2500e-06, PNorm = 63.5590, GNorm = 0.0456, lr_0 = 1.3181e-04
Loss = 1.2271e-05, PNorm = 63.5604, GNorm = 0.0603, lr_0 = 1.3123e-04
Loss = 1.3703e-05, PNorm = 63.5625, GNorm = 0.0608, lr_0 = 1.3065e-04
Validation rmse logD = 0.588453
Validation R2 logD = 0.778176
Validation rmse logP = 0.627986
Validation R2 logP = 0.828865
Epoch 87
Train function
Loss = 1.1447e-05, PNorm = 63.5626, GNorm = 0.1655, lr_0 = 1.3001e-04
Loss = 7.3715e-06, PNorm = 63.5637, GNorm = 0.0669, lr_0 = 1.2944e-04
Loss = 9.1538e-06, PNorm = 63.5649, GNorm = 0.0587, lr_0 = 1.2886e-04
Loss = 1.3308e-05, PNorm = 63.5659, GNorm = 0.0624, lr_0 = 1.2829e-04
Loss = 1.2040e-05, PNorm = 63.5665, GNorm = 0.0730, lr_0 = 1.2773e-04
Validation rmse logD = 0.589221
Validation R2 logD = 0.777597
Validation rmse logP = 0.630686
Validation R2 logP = 0.827390
Epoch 88
Train function
Loss = 8.9242e-06, PNorm = 63.5670, GNorm = 0.0993, lr_0 = 1.2710e-04
Loss = 8.4896e-06, PNorm = 63.5680, GNorm = 0.1678, lr_0 = 1.2654e-04
Loss = 1.4890e-05, PNorm = 63.5696, GNorm = 0.0344, lr_0 = 1.2598e-04
Loss = 1.1839e-05, PNorm = 63.5711, GNorm = 0.1228, lr_0 = 1.2542e-04
Loss = 1.3239e-05, PNorm = 63.5714, GNorm = 0.1076, lr_0 = 1.2487e-04
Validation rmse logD = 0.589326
Validation R2 logD = 0.777517
Validation rmse logP = 0.628397
Validation R2 logP = 0.828641
Epoch 89
Train function
Loss = 1.1655e-05, PNorm = 63.5732, GNorm = 0.0499, lr_0 = 1.2426e-04
Loss = 1.2493e-05, PNorm = 63.5747, GNorm = 0.2395, lr_0 = 1.2371e-04
Loss = 1.1688e-05, PNorm = 63.5753, GNorm = 0.1633, lr_0 = 1.2317e-04
Loss = 1.2949e-05, PNorm = 63.5765, GNorm = 0.1457, lr_0 = 1.2262e-04
Loss = 1.0847e-05, PNorm = 63.5776, GNorm = 0.1022, lr_0 = 1.2208e-04
Loss = 9.2052e-06, PNorm = 63.5784, GNorm = 0.0481, lr_0 = 1.2154e-04
Loss = 4.1245e-05, PNorm = 63.5785, GNorm = 0.1379, lr_0 = 1.2148e-04
Validation rmse logD = 0.588026
Validation R2 logD = 0.778498
Validation rmse logP = 0.629114
Validation R2 logP = 0.828250
Epoch 90
Train function
Loss = 7.1845e-06, PNorm = 63.5797, GNorm = 0.0442, lr_0 = 1.2095e-04
Loss = 8.7737e-06, PNorm = 63.5805, GNorm = 0.0390, lr_0 = 1.2041e-04
Loss = 8.3072e-06, PNorm = 63.5809, GNorm = 0.0603, lr_0 = 1.1988e-04
Loss = 8.8209e-06, PNorm = 63.5812, GNorm = 0.1471, lr_0 = 1.1935e-04
Loss = 1.0570e-05, PNorm = 63.5817, GNorm = 0.0940, lr_0 = 1.1882e-04
Validation rmse logD = 0.588447
Validation R2 logD = 0.778180
Validation rmse logP = 0.628707
Validation R2 logP = 0.828472
Epoch 91
Train function
Loss = 1.1131e-05, PNorm = 63.5823, GNorm = 0.2018, lr_0 = 1.1824e-04
Loss = 1.0022e-05, PNorm = 63.5831, GNorm = 0.0858, lr_0 = 1.1772e-04
Loss = 1.0190e-05, PNorm = 63.5840, GNorm = 0.0986, lr_0 = 1.1720e-04
Loss = 9.8812e-06, PNorm = 63.5854, GNorm = 0.1478, lr_0 = 1.1668e-04
Loss = 6.5608e-06, PNorm = 63.5867, GNorm = 0.0806, lr_0 = 1.1616e-04
Validation rmse logD = 0.588809
Validation R2 logD = 0.777907
Validation rmse logP = 0.627851
Validation R2 logP = 0.828939
Epoch 92
Train function
Loss = 4.7205e-06, PNorm = 63.5882, GNorm = 0.0497, lr_0 = 1.1565e-04
Loss = 5.9381e-06, PNorm = 63.5889, GNorm = 0.0419, lr_0 = 1.1514e-04
Loss = 6.8900e-06, PNorm = 63.5893, GNorm = 0.0436, lr_0 = 1.1463e-04
Loss = 1.0994e-05, PNorm = 63.5908, GNorm = 0.2469, lr_0 = 1.1412e-04
Loss = 1.1355e-05, PNorm = 63.5920, GNorm = 0.1214, lr_0 = 1.1362e-04
Loss = 1.3737e-05, PNorm = 63.5922, GNorm = 0.1611, lr_0 = 1.1312e-04
Loss = 2.7794e-05, PNorm = 63.5923, GNorm = 0.1099, lr_0 = 1.1307e-04
Validation rmse logD = 0.588042
Validation R2 logD = 0.778485
Validation rmse logP = 0.628135
Validation R2 logP = 0.828784
Epoch 93
Train function
Loss = 1.1001e-05, PNorm = 63.5932, GNorm = 0.0816, lr_0 = 1.1257e-04
Loss = 1.1097e-05, PNorm = 63.5946, GNorm = 0.0372, lr_0 = 1.1207e-04
Loss = 7.6120e-06, PNorm = 63.5951, GNorm = 0.1403, lr_0 = 1.1157e-04
Loss = 5.5327e-06, PNorm = 63.5957, GNorm = 0.0321, lr_0 = 1.1108e-04
Loss = 5.4311e-06, PNorm = 63.5960, GNorm = 0.0515, lr_0 = 1.1059e-04
Validation rmse logD = 0.588448
Validation R2 logD = 0.778180
Validation rmse logP = 0.628730
Validation R2 logP = 0.828459
Epoch 94
Train function
Loss = 6.4863e-06, PNorm = 63.5970, GNorm = 0.0537, lr_0 = 1.1005e-04
Loss = 5.3598e-06, PNorm = 63.5978, GNorm = 0.0674, lr_0 = 1.0956e-04
Loss = 7.0097e-06, PNorm = 63.5981, GNorm = 0.0801, lr_0 = 1.0908e-04
Loss = 6.2335e-06, PNorm = 63.5992, GNorm = 0.0682, lr_0 = 1.0860e-04
Loss = 5.7340e-06, PNorm = 63.5999, GNorm = 0.0471, lr_0 = 1.0811e-04
Validation rmse logD = 0.588483
Validation R2 logD = 0.778154
Validation rmse logP = 0.629598
Validation R2 logP = 0.827985
Epoch 95
Train function
Loss = 5.7302e-06, PNorm = 63.6005, GNorm = 0.0720, lr_0 = 1.0759e-04
Loss = 6.0839e-06, PNorm = 63.6012, GNorm = 0.1833, lr_0 = 1.0711e-04
Loss = 7.1804e-06, PNorm = 63.6016, GNorm = 0.1748, lr_0 = 1.0664e-04
Loss = 8.1825e-06, PNorm = 63.6025, GNorm = 0.0470, lr_0 = 1.0617e-04
Loss = 7.2804e-06, PNorm = 63.6032, GNorm = 0.0746, lr_0 = 1.0570e-04
Validation rmse logD = 0.589233
Validation R2 logD = 0.777587
Validation rmse logP = 0.627432
Validation R2 logP = 0.829167
Epoch 96
Train function
Loss = 7.3529e-06, PNorm = 63.6035, GNorm = 0.1137, lr_0 = 1.0518e-04
Loss = 6.6956e-06, PNorm = 63.6037, GNorm = 0.0576, lr_0 = 1.0472e-04
Loss = 5.3855e-06, PNorm = 63.6036, GNorm = 0.0596, lr_0 = 1.0426e-04
Loss = 5.5717e-06, PNorm = 63.6039, GNorm = 0.0428, lr_0 = 1.0379e-04
Loss = 4.7461e-06, PNorm = 63.6047, GNorm = 0.1141, lr_0 = 1.0333e-04
Loss = 5.6303e-06, PNorm = 63.6056, GNorm = 0.0312, lr_0 = 1.0288e-04
Validation rmse logD = 0.589384
Validation R2 logD = 0.777474
Validation rmse logP = 0.628841
Validation R2 logP = 0.828399
Epoch 97
Train function
Loss = 5.9078e-06, PNorm = 63.6063, GNorm = 0.1138, lr_0 = 1.0238e-04
Loss = 5.8233e-06, PNorm = 63.6070, GNorm = 0.0881, lr_0 = 1.0192e-04
Loss = 4.0139e-06, PNorm = 63.6078, GNorm = 0.0435, lr_0 = 1.0147e-04
Loss = 5.5933e-06, PNorm = 63.6082, GNorm = 0.0614, lr_0 = 1.0102e-04
Loss = 6.9108e-06, PNorm = 63.6085, GNorm = 0.1336, lr_0 = 1.0058e-04
Validation rmse logD = 0.588819
Validation R2 logD = 0.777900
Validation rmse logP = 0.628429
Validation R2 logP = 0.828623
Epoch 98
Train function
Loss = 7.6572e-06, PNorm = 63.6090, GNorm = 0.1236, lr_0 = 1.0009e-04
Loss = 5.2871e-06, PNorm = 63.6096, GNorm = 0.1217, lr_0 = 1.0000e-04
Loss = 5.4738e-06, PNorm = 63.6104, GNorm = 0.1164, lr_0 = 1.0000e-04
Loss = 6.3374e-06, PNorm = 63.6108, GNorm = 0.1002, lr_0 = 1.0000e-04
Loss = 9.8441e-06, PNorm = 63.6119, GNorm = 0.0358, lr_0 = 1.0000e-04
Validation rmse logD = 0.588711
Validation R2 logD = 0.777982
Validation rmse logP = 0.628196
Validation R2 logP = 0.828751
Epoch 99
Train function
Loss = 4.0473e-06, PNorm = 63.6125, GNorm = 0.1031, lr_0 = 1.0000e-04
Loss = 1.1148e-05, PNorm = 63.6132, GNorm = 0.1568, lr_0 = 1.0000e-04
Loss = 9.6969e-06, PNorm = 63.6140, GNorm = 0.0530, lr_0 = 1.0000e-04
Loss = 4.8657e-06, PNorm = 63.6147, GNorm = 0.0297, lr_0 = 1.0000e-04
Loss = 6.5669e-06, PNorm = 63.6154, GNorm = 0.0877, lr_0 = 1.0000e-04
Loss = 6.8091e-06, PNorm = 63.6160, GNorm = 0.1691, lr_0 = 1.0000e-04
Validation rmse logD = 0.589148
Validation R2 logD = 0.777651
Validation rmse logP = 0.627561
Validation R2 logP = 0.829097
Model 0 best validation rmse = 0.607873 on epoch 76
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.621702
Model 0 test R2 logD = 0.728543
Model 0 test rmse logP = 0.776798
Model 0 test R2 logP = 0.739442
Ensemble test rmse  logD= 0.621702
Ensemble test R2  logD= 0.728543
Ensemble test rmse  logP= 0.776798
Ensemble test R2  logP= 0.739442
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_321/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,306,402
Moving model to cuda
Epoch 0
Train function
Loss = 2.0704e-02, PNorm = 52.9422, GNorm = 6.4073, lr_0 = 1.9340e-04
Loss = 1.7236e-02, PNorm = 52.9512, GNorm = 15.4827, lr_0 = 2.7830e-04
Loss = 1.4632e-02, PNorm = 52.9644, GNorm = 2.0039, lr_0 = 3.6321e-04
Loss = 1.4092e-02, PNorm = 52.9844, GNorm = 8.2805, lr_0 = 4.4811e-04
Loss = 1.5579e-02, PNorm = 53.0026, GNorm = 1.5702, lr_0 = 5.3302e-04
Validation rmse logD = 0.941377
Validation R2 logD = 0.350020
Validation rmse logP = 1.293546
Validation R2 logP = 0.365083
Epoch 1
Train function
Loss = 1.3217e-02, PNorm = 53.0338, GNorm = 1.2359, lr_0 = 6.2642e-04
Loss = 1.0619e-02, PNorm = 53.0730, GNorm = 3.0427, lr_0 = 7.1132e-04
Loss = 1.1629e-02, PNorm = 53.1108, GNorm = 4.1928, lr_0 = 7.9623e-04
Loss = 1.1645e-02, PNorm = 53.1574, GNorm = 2.6085, lr_0 = 8.8113e-04
Loss = 1.0639e-02, PNorm = 53.2201, GNorm = 1.3625, lr_0 = 9.6604e-04
Validation rmse logD = 0.915612
Validation R2 logD = 0.385112
Validation rmse logP = 1.380628
Validation R2 logP = 0.276721
Epoch 2
Train function
Loss = 9.7929e-03, PNorm = 53.2932, GNorm = 1.1699, lr_0 = 9.9690e-04
Loss = 1.1703e-02, PNorm = 53.3734, GNorm = 2.1508, lr_0 = 9.9249e-04
Loss = 1.1320e-02, PNorm = 53.4528, GNorm = 4.0627, lr_0 = 9.8810e-04
Loss = 1.1066e-02, PNorm = 53.5202, GNorm = 4.1351, lr_0 = 9.8373e-04
Loss = 9.5964e-03, PNorm = 53.5854, GNorm = 1.0620, lr_0 = 9.7938e-04
Validation rmse logD = 0.858297
Validation R2 logD = 0.459683
Validation rmse logP = 0.782504
Validation R2 logP = 0.767659
Epoch 3
Train function
Loss = 1.1315e-02, PNorm = 53.6502, GNorm = 5.2170, lr_0 = 9.7462e-04
Loss = 8.4461e-03, PNorm = 53.7197, GNorm = 0.8446, lr_0 = 9.7030e-04
Loss = 1.0231e-02, PNorm = 53.8081, GNorm = 5.4201, lr_0 = 9.6601e-04
Loss = 8.2467e-03, PNorm = 53.8896, GNorm = 1.7728, lr_0 = 9.6174e-04
Loss = 7.6868e-03, PNorm = 53.9703, GNorm = 1.2698, lr_0 = 9.5749e-04
Loss = 8.4196e-03, PNorm = 54.0676, GNorm = 0.8367, lr_0 = 9.5325e-04
Validation rmse logD = 0.756159
Validation R2 logD = 0.580629
Validation rmse logP = 0.771852
Validation R2 logP = 0.773941
Epoch 4
Train function
Loss = 8.3471e-03, PNorm = 54.1822, GNorm = 1.1322, lr_0 = 9.4861e-04
Loss = 7.1871e-03, PNorm = 54.3002, GNorm = 1.9934, lr_0 = 9.4442e-04
Loss = 7.6223e-03, PNorm = 54.3875, GNorm = 3.7517, lr_0 = 9.4024e-04
Loss = 7.5741e-03, PNorm = 54.4646, GNorm = 3.4004, lr_0 = 9.3608e-04
Loss = 7.3576e-03, PNorm = 54.5459, GNorm = 1.4450, lr_0 = 9.3194e-04
Validation rmse logD = 0.702917
Validation R2 logD = 0.637606
Validation rmse logP = 0.700767
Validation R2 logP = 0.813662
Epoch 5
Train function
Loss = 8.4219e-03, PNorm = 54.6459, GNorm = 2.3983, lr_0 = 9.2741e-04
Loss = 6.7814e-03, PNorm = 54.7427, GNorm = 3.8384, lr_0 = 9.2330e-04
Loss = 6.2951e-03, PNorm = 54.8376, GNorm = 1.4714, lr_0 = 9.1922e-04
Loss = 5.6369e-03, PNorm = 54.9223, GNorm = 2.1213, lr_0 = 9.1515e-04
Loss = 6.2492e-03, PNorm = 55.0028, GNorm = 0.9818, lr_0 = 9.1111e-04
Validation rmse logD = 0.703582
Validation R2 logD = 0.636920
Validation rmse logP = 0.768706
Validation R2 logP = 0.775781
Epoch 6
Train function
Loss = 5.5923e-03, PNorm = 55.0793, GNorm = 4.4415, lr_0 = 9.0667e-04
Loss = 5.8712e-03, PNorm = 55.1748, GNorm = 1.3441, lr_0 = 9.0266e-04
Loss = 5.7073e-03, PNorm = 55.2644, GNorm = 1.3058, lr_0 = 8.9867e-04
Loss = 5.7876e-03, PNorm = 55.3488, GNorm = 2.5568, lr_0 = 8.9469e-04
Loss = 5.4926e-03, PNorm = 55.4497, GNorm = 0.9968, lr_0 = 8.9074e-04
Loss = 5.5097e-03, PNorm = 55.5438, GNorm = 1.2242, lr_0 = 8.8680e-04
Validation rmse logD = 0.685122
Validation R2 logD = 0.655722
Validation rmse logP = 0.668524
Validation R2 logP = 0.830415
Epoch 7
Train function
Loss = 5.3121e-03, PNorm = 55.6342, GNorm = 1.8094, lr_0 = 8.8248e-04
Loss = 4.4076e-03, PNorm = 55.7231, GNorm = 1.0942, lr_0 = 8.7858e-04
Loss = 4.9703e-03, PNorm = 55.8159, GNorm = 1.1618, lr_0 = 8.7469e-04
Loss = 5.4688e-03, PNorm = 55.9105, GNorm = 1.8196, lr_0 = 8.7082e-04
Loss = 4.3686e-03, PNorm = 55.9871, GNorm = 1.8039, lr_0 = 8.6697e-04
Validation rmse logD = 0.794851
Validation R2 logD = 0.536613
Validation rmse logP = 0.655025
Validation R2 logP = 0.837195
Epoch 8
Train function
Loss = 7.0706e-03, PNorm = 56.0737, GNorm = 3.5874, lr_0 = 8.6276e-04
Loss = 5.7462e-03, PNorm = 56.1930, GNorm = 0.8226, lr_0 = 8.5894e-04
Loss = 4.1980e-03, PNorm = 56.2840, GNorm = 0.8463, lr_0 = 8.5514e-04
Loss = 4.3969e-03, PNorm = 56.3641, GNorm = 1.0279, lr_0 = 8.5136e-04
Loss = 3.9803e-03, PNorm = 56.4444, GNorm = 0.9119, lr_0 = 8.4759e-04
Validation rmse logD = 0.650136
Validation R2 logD = 0.689986
Validation rmse logP = 0.660081
Validation R2 logP = 0.834672
Epoch 9
Train function
Loss = 3.9104e-03, PNorm = 56.5337, GNorm = 2.0789, lr_0 = 8.4384e-04
Loss = 3.7028e-03, PNorm = 56.6198, GNorm = 1.0120, lr_0 = 8.4011e-04
Loss = 3.8398e-03, PNorm = 56.7027, GNorm = 0.5993, lr_0 = 8.3639e-04
Loss = 3.3645e-03, PNorm = 56.7897, GNorm = 0.8795, lr_0 = 8.3269e-04
Loss = 4.0050e-03, PNorm = 56.8609, GNorm = 1.3488, lr_0 = 8.2901e-04
Loss = 4.0618e-03, PNorm = 56.9509, GNorm = 2.1176, lr_0 = 8.2534e-04
Validation rmse logD = 0.741852
Validation R2 logD = 0.596348
Validation rmse logP = 0.651294
Validation R2 logP = 0.839044
Epoch 10
Train function
Loss = 4.2014e-03, PNorm = 57.0612, GNorm = 3.0140, lr_0 = 8.2133e-04
Loss = 3.7709e-03, PNorm = 57.1664, GNorm = 0.8434, lr_0 = 8.1770e-04
Loss = 3.6932e-03, PNorm = 57.2424, GNorm = 1.5221, lr_0 = 8.1408e-04
Loss = 3.2452e-03, PNorm = 57.3216, GNorm = 2.2182, lr_0 = 8.1048e-04
Loss = 4.1804e-03, PNorm = 57.4068, GNorm = 1.1938, lr_0 = 8.0689e-04
Validation rmse logD = 0.592449
Validation R2 logD = 0.742561
Validation rmse logP = 0.657638
Validation R2 logP = 0.835893
Epoch 11
Train function
Loss = 2.5823e-03, PNorm = 57.4888, GNorm = 0.9707, lr_0 = 8.0297e-04
Loss = 3.2681e-03, PNorm = 57.5766, GNorm = 0.9990, lr_0 = 7.9942e-04
Loss = 2.7349e-03, PNorm = 57.6513, GNorm = 0.8400, lr_0 = 7.9588e-04
Loss = 3.1930e-03, PNorm = 57.7222, GNorm = 0.8176, lr_0 = 7.9236e-04
Loss = 3.0856e-03, PNorm = 57.7855, GNorm = 1.0597, lr_0 = 7.8885e-04
Validation rmse logD = 0.630619
Validation R2 logD = 0.708320
Validation rmse logP = 0.633806
Validation R2 logP = 0.847571
Epoch 12
Train function
Loss = 3.5606e-03, PNorm = 57.8514, GNorm = 1.5415, lr_0 = 7.8502e-04
Loss = 2.8462e-03, PNorm = 57.9233, GNorm = 1.0064, lr_0 = 7.8154e-04
Loss = 2.2530e-03, PNorm = 58.0042, GNorm = 0.5533, lr_0 = 7.7809e-04
Loss = 2.5454e-03, PNorm = 58.0563, GNorm = 0.8755, lr_0 = 7.7465e-04
Loss = 2.3261e-03, PNorm = 58.1234, GNorm = 0.5252, lr_0 = 7.7122e-04
Loss = 2.6762e-03, PNorm = 58.1850, GNorm = 1.5870, lr_0 = 7.6781e-04
Loss = 9.2868e-03, PNorm = 58.1888, GNorm = 2.3470, lr_0 = 7.6747e-04
Validation rmse logD = 0.599608
Validation R2 logD = 0.736302
Validation rmse logP = 0.651950
Validation R2 logP = 0.838719
Epoch 13
Train function
Loss = 2.5470e-03, PNorm = 58.2485, GNorm = 1.7679, lr_0 = 7.6407e-04
Loss = 2.9066e-03, PNorm = 58.3248, GNorm = 0.9333, lr_0 = 7.6069e-04
Loss = 2.0549e-03, PNorm = 58.3960, GNorm = 0.6468, lr_0 = 7.5733e-04
Loss = 2.1696e-03, PNorm = 58.4729, GNorm = 0.9022, lr_0 = 7.5398e-04
Loss = 2.6477e-03, PNorm = 58.5362, GNorm = 1.0326, lr_0 = 7.5064e-04
Validation rmse logD = 0.579290
Validation R2 logD = 0.753870
Validation rmse logP = 0.619847
Validation R2 logP = 0.854212
Epoch 14
Train function
Loss = 2.1496e-03, PNorm = 58.6248, GNorm = 0.9370, lr_0 = 7.4699e-04
Loss = 1.9651e-03, PNorm = 58.6924, GNorm = 1.7539, lr_0 = 7.4369e-04
Loss = 2.1663e-03, PNorm = 58.7620, GNorm = 0.5003, lr_0 = 7.4040e-04
Loss = 1.7147e-03, PNorm = 58.8250, GNorm = 1.0667, lr_0 = 7.3712e-04
Loss = 2.3179e-03, PNorm = 58.8862, GNorm = 1.9099, lr_0 = 7.3386e-04
Validation rmse logD = 0.563327
Validation R2 logD = 0.767248
Validation rmse logP = 0.619999
Validation R2 logP = 0.854141
Epoch 15
Train function
Loss = 1.9233e-03, PNorm = 58.9639, GNorm = 1.8391, lr_0 = 7.3029e-04
Loss = 1.8226e-03, PNorm = 59.0396, GNorm = 1.1172, lr_0 = 7.2706e-04
Loss = 1.8964e-03, PNorm = 59.1123, GNorm = 0.5861, lr_0 = 7.2385e-04
Loss = 1.9640e-03, PNorm = 59.1760, GNorm = 1.1311, lr_0 = 7.2064e-04
Loss = 2.0471e-03, PNorm = 59.2278, GNorm = 0.5162, lr_0 = 7.1746e-04
Validation rmse logD = 0.586542
Validation R2 logD = 0.747669
Validation rmse logP = 0.635269
Validation R2 logP = 0.846867
Epoch 16
Train function
Loss = 1.3553e-03, PNorm = 59.3053, GNorm = 1.3107, lr_0 = 7.1397e-04
Loss = 1.9252e-03, PNorm = 59.3699, GNorm = 1.0802, lr_0 = 7.1081e-04
Loss = 1.9993e-03, PNorm = 59.4421, GNorm = 1.1566, lr_0 = 7.0766e-04
Loss = 1.5471e-03, PNorm = 59.5036, GNorm = 1.2529, lr_0 = 7.0453e-04
Loss = 1.5288e-03, PNorm = 59.5514, GNorm = 0.7158, lr_0 = 7.0142e-04
Loss = 1.6385e-03, PNorm = 59.5976, GNorm = 0.4783, lr_0 = 6.9831e-04
Validation rmse logD = 0.572157
Validation R2 logD = 0.759893
Validation rmse logP = 0.617444
Validation R2 logP = 0.855340
Epoch 17
Train function
Loss = 1.5980e-03, PNorm = 59.6741, GNorm = 1.8588, lr_0 = 6.9523e-04
Loss = 1.7718e-03, PNorm = 59.7244, GNorm = 0.7126, lr_0 = 6.9215e-04
Loss = 1.4650e-03, PNorm = 59.7758, GNorm = 0.6349, lr_0 = 6.8909e-04
Loss = 1.6171e-03, PNorm = 59.8365, GNorm = 1.2114, lr_0 = 6.8604e-04
Loss = 1.5222e-03, PNorm = 59.8871, GNorm = 0.9037, lr_0 = 6.8301e-04
Validation rmse logD = 0.613099
Validation R2 logD = 0.724301
Validation rmse logP = 0.617014
Validation R2 logP = 0.855541
Epoch 18
Train function
Loss = 1.6498e-03, PNorm = 59.9529, GNorm = 2.0491, lr_0 = 6.7968e-04
Loss = 1.3692e-03, PNorm = 60.0051, GNorm = 1.3498, lr_0 = 6.7668e-04
Loss = 1.3733e-03, PNorm = 60.0529, GNorm = 0.6705, lr_0 = 6.7368e-04
Loss = 1.3666e-03, PNorm = 60.0854, GNorm = 0.5242, lr_0 = 6.7070e-04
Loss = 1.3644e-03, PNorm = 60.1252, GNorm = 1.4170, lr_0 = 6.6774e-04
Validation rmse logD = 0.567096
Validation R2 logD = 0.764123
Validation rmse logP = 0.607062
Validation R2 logP = 0.860164
Epoch 19
Train function
Loss = 1.0840e-03, PNorm = 60.1810, GNorm = 0.7289, lr_0 = 6.6449e-04
Loss = 1.1124e-03, PNorm = 60.2204, GNorm = 0.7100, lr_0 = 6.6155e-04
Loss = 1.0528e-03, PNorm = 60.2597, GNorm = 0.7222, lr_0 = 6.5862e-04
Loss = 1.1412e-03, PNorm = 60.3020, GNorm = 1.1862, lr_0 = 6.5571e-04
Loss = 1.0915e-03, PNorm = 60.3387, GNorm = 0.4632, lr_0 = 6.5281e-04
Loss = 1.0533e-03, PNorm = 60.3742, GNorm = 0.6116, lr_0 = 6.4992e-04
Validation rmse logD = 0.582069
Validation R2 logD = 0.751503
Validation rmse logP = 0.619521
Validation R2 logP = 0.854365
Epoch 20
Train function
Loss = 1.2554e-03, PNorm = 60.4268, GNorm = 1.4189, lr_0 = 6.4676e-04
Loss = 1.8095e-03, PNorm = 60.4874, GNorm = 1.2139, lr_0 = 6.4390e-04
Loss = 1.4027e-03, PNorm = 60.5495, GNorm = 0.9754, lr_0 = 6.4105e-04
Loss = 1.5629e-03, PNorm = 60.6026, GNorm = 1.5671, lr_0 = 6.3822e-04
Loss = 1.1453e-03, PNorm = 60.6566, GNorm = 0.4552, lr_0 = 6.3539e-04
Validation rmse logD = 0.570072
Validation R2 logD = 0.761641
Validation rmse logP = 0.606575
Validation R2 logP = 0.860388
Epoch 21
Train function
Loss = 1.0419e-03, PNorm = 60.7000, GNorm = 0.4579, lr_0 = 6.3230e-04
Loss = 8.7362e-04, PNorm = 60.7303, GNorm = 0.6885, lr_0 = 6.2950e-04
Loss = 7.8316e-04, PNorm = 60.7561, GNorm = 0.5167, lr_0 = 6.2672e-04
Loss = 9.0154e-04, PNorm = 60.7776, GNorm = 0.4735, lr_0 = 6.2395e-04
Loss = 1.0716e-03, PNorm = 60.8109, GNorm = 0.5498, lr_0 = 6.2119e-04
Validation rmse logD = 0.586047
Validation R2 logD = 0.748094
Validation rmse logP = 0.623821
Validation R2 logP = 0.852337
Epoch 22
Train function
Loss = 1.2818e-03, PNorm = 60.8531, GNorm = 2.1308, lr_0 = 6.1817e-04
Loss = 9.6052e-04, PNorm = 60.8842, GNorm = 1.2929, lr_0 = 6.1543e-04
Loss = 1.0966e-03, PNorm = 60.9218, GNorm = 0.7813, lr_0 = 6.1271e-04
Loss = 9.5692e-04, PNorm = 60.9630, GNorm = 0.7438, lr_0 = 6.1000e-04
Loss = 9.2785e-04, PNorm = 60.9979, GNorm = 1.5609, lr_0 = 6.0730e-04
Loss = 8.7783e-04, PNorm = 61.0259, GNorm = 1.4567, lr_0 = 6.0461e-04
Validation rmse logD = 0.555276
Validation R2 logD = 0.773853
Validation rmse logP = 0.595994
Validation R2 logP = 0.865216
Epoch 23
Train function
Loss = 7.3547e-04, PNorm = 61.0656, GNorm = 1.0498, lr_0 = 6.0167e-04
Loss = 7.9371e-04, PNorm = 61.0944, GNorm = 0.4095, lr_0 = 5.9901e-04
Loss = 6.8640e-04, PNorm = 61.1202, GNorm = 0.3458, lr_0 = 5.9636e-04
Loss = 6.3310e-04, PNorm = 61.1420, GNorm = 0.4382, lr_0 = 5.9372e-04
Loss = 7.6711e-04, PNorm = 61.1661, GNorm = 0.3614, lr_0 = 5.9110e-04
Validation rmse logD = 0.545847
Validation R2 logD = 0.781468
Validation rmse logP = 0.610412
Validation R2 logP = 0.858616
Epoch 24
Train function
Loss = 5.1841e-04, PNorm = 61.1921, GNorm = 0.8935, lr_0 = 5.8822e-04
Loss = 5.4037e-04, PNorm = 61.2178, GNorm = 0.6630, lr_0 = 5.8562e-04
Loss = 7.5582e-04, PNorm = 61.2379, GNorm = 0.5894, lr_0 = 5.8303e-04
Loss = 6.8297e-04, PNorm = 61.2683, GNorm = 0.7465, lr_0 = 5.8045e-04
Loss = 5.9870e-04, PNorm = 61.2915, GNorm = 0.7115, lr_0 = 5.7788e-04
Validation rmse logD = 0.554621
Validation R2 logD = 0.774387
Validation rmse logP = 0.605707
Validation R2 logP = 0.860788
Epoch 25
Train function
Loss = 5.2081e-04, PNorm = 61.3159, GNorm = 0.4476, lr_0 = 5.7533e-04
Loss = 6.1270e-04, PNorm = 61.3381, GNorm = 0.5414, lr_0 = 5.7278e-04
Loss = 5.1684e-04, PNorm = 61.3589, GNorm = 1.1890, lr_0 = 5.7025e-04
Loss = 4.7003e-04, PNorm = 61.3774, GNorm = 0.9103, lr_0 = 5.6773e-04
Loss = 6.7924e-04, PNorm = 61.4080, GNorm = 0.6101, lr_0 = 5.6522e-04
Loss = 5.6460e-04, PNorm = 61.4355, GNorm = 0.5020, lr_0 = 5.6272e-04
Validation rmse logD = 0.555705
Validation R2 logD = 0.773503
Validation rmse logP = 0.605698
Validation R2 logP = 0.860792
Epoch 26
Train function
Loss = 5.7367e-04, PNorm = 61.4618, GNorm = 0.5084, lr_0 = 5.5998e-04
Loss = 5.0865e-04, PNorm = 61.4918, GNorm = 0.2768, lr_0 = 5.5750e-04
Loss = 5.3327e-04, PNorm = 61.5192, GNorm = 0.5722, lr_0 = 5.5503e-04
Loss = 4.3417e-04, PNorm = 61.5329, GNorm = 0.8122, lr_0 = 5.5258e-04
Loss = 5.1880e-04, PNorm = 61.5534, GNorm = 1.2107, lr_0 = 5.5014e-04
Validation rmse logD = 0.553622
Validation R2 logD = 0.775198
Validation rmse logP = 0.600809
Validation R2 logP = 0.863030
Epoch 27
Train function
Loss = 5.3376e-04, PNorm = 61.5746, GNorm = 1.0802, lr_0 = 5.4746e-04
Loss = 6.3578e-04, PNorm = 61.5956, GNorm = 0.6221, lr_0 = 5.4504e-04
Loss = 5.9630e-04, PNorm = 61.6169, GNorm = 0.9029, lr_0 = 5.4263e-04
Loss = 4.5761e-04, PNorm = 61.6481, GNorm = 0.3495, lr_0 = 5.4023e-04
Loss = 4.7000e-04, PNorm = 61.6716, GNorm = 0.6374, lr_0 = 5.3784e-04
Validation rmse logD = 0.553081
Validation R2 logD = 0.775637
Validation rmse logP = 0.626422
Validation R2 logP = 0.851102
Epoch 28
Train function
Loss = 4.2490e-04, PNorm = 61.6945, GNorm = 0.3846, lr_0 = 5.3522e-04
Loss = 4.3943e-04, PNorm = 61.7168, GNorm = 0.7079, lr_0 = 5.3285e-04
Loss = 4.3356e-04, PNorm = 61.7313, GNorm = 0.6662, lr_0 = 5.3050e-04
Loss = 5.0943e-04, PNorm = 61.7554, GNorm = 0.4358, lr_0 = 5.2815e-04
Loss = 5.1184e-04, PNorm = 61.7743, GNorm = 0.3750, lr_0 = 5.2581e-04
Loss = 4.2029e-04, PNorm = 61.7940, GNorm = 0.5257, lr_0 = 5.2349e-04
Loss = 1.2943e-03, PNorm = 61.7965, GNorm = 0.8846, lr_0 = 5.2326e-04
Validation rmse logD = 0.559203
Validation R2 logD = 0.770643
Validation rmse logP = 0.608855
Validation R2 logP = 0.859337
Epoch 29
Train function
Loss = 4.2103e-04, PNorm = 61.8227, GNorm = 0.8984, lr_0 = 5.2094e-04
Loss = 4.2355e-04, PNorm = 61.8422, GNorm = 0.4259, lr_0 = 5.1864e-04
Loss = 3.9173e-04, PNorm = 61.8569, GNorm = 0.6584, lr_0 = 5.1634e-04
Loss = 3.0626e-04, PNorm = 61.8698, GNorm = 0.3230, lr_0 = 5.1406e-04
Loss = 3.4794e-04, PNorm = 61.8861, GNorm = 0.7485, lr_0 = 5.1178e-04
Validation rmse logD = 0.563350
Validation R2 logD = 0.767229
Validation rmse logP = 0.610446
Validation R2 logP = 0.858601
Epoch 30
Train function
Loss = 5.9355e-04, PNorm = 61.9024, GNorm = 0.3608, lr_0 = 5.0930e-04
Loss = 6.4584e-04, PNorm = 61.9299, GNorm = 0.4872, lr_0 = 5.0704e-04
Loss = 5.9823e-04, PNorm = 61.9621, GNorm = 0.9872, lr_0 = 5.0480e-04
Loss = 4.3039e-04, PNorm = 61.9893, GNorm = 0.5426, lr_0 = 5.0257e-04
Loss = 4.5590e-04, PNorm = 62.0119, GNorm = 0.4850, lr_0 = 5.0034e-04
Validation rmse logD = 0.566986
Validation R2 logD = 0.764214
Validation rmse logP = 0.600947
Validation R2 logP = 0.862967
Epoch 31
Train function
Loss = 4.4113e-04, PNorm = 62.0322, GNorm = 1.0236, lr_0 = 4.9791e-04
Loss = 3.5385e-04, PNorm = 62.0491, GNorm = 0.3589, lr_0 = 4.9571e-04
Loss = 3.0903e-04, PNorm = 62.0680, GNorm = 0.3747, lr_0 = 4.9351e-04
Loss = 4.2252e-04, PNorm = 62.0821, GNorm = 0.4868, lr_0 = 4.9133e-04
Loss = 3.5768e-04, PNorm = 62.0921, GNorm = 0.4670, lr_0 = 4.8916e-04
Validation rmse logD = 0.559787
Validation R2 logD = 0.770164
Validation rmse logP = 0.607648
Validation R2 logP = 0.859894
Epoch 32
Train function
Loss = 4.1793e-04, PNorm = 62.1154, GNorm = 1.2820, lr_0 = 4.8678e-04
Loss = 4.4010e-04, PNorm = 62.1380, GNorm = 0.9733, lr_0 = 4.8463e-04
Loss = 3.2834e-04, PNorm = 62.1507, GNorm = 0.5520, lr_0 = 4.8248e-04
Loss = 3.4958e-04, PNorm = 62.1682, GNorm = 0.6347, lr_0 = 4.8035e-04
Loss = 3.9391e-04, PNorm = 62.1853, GNorm = 0.2651, lr_0 = 4.7822e-04
Loss = 2.9482e-04, PNorm = 62.2010, GNorm = 0.3006, lr_0 = 4.7611e-04
Validation rmse logD = 0.540275
Validation R2 logD = 0.785907
Validation rmse logP = 0.610647
Validation R2 logP = 0.858507
Epoch 33
Train function
Loss = 2.7900e-04, PNorm = 62.2213, GNorm = 0.3296, lr_0 = 4.7379e-04
Loss = 2.5864e-04, PNorm = 62.2347, GNorm = 0.5485, lr_0 = 4.7170e-04
Loss = 2.5465e-04, PNorm = 62.2481, GNorm = 0.2761, lr_0 = 4.6961e-04
Loss = 2.7486e-04, PNorm = 62.2613, GNorm = 0.5294, lr_0 = 4.6753e-04
Loss = 3.5400e-04, PNorm = 62.2747, GNorm = 0.3086, lr_0 = 4.6546e-04
Validation rmse logD = 0.554209
Validation R2 logD = 0.774721
Validation rmse logP = 0.605625
Validation R2 logP = 0.860825
Epoch 34
Train function
Loss = 1.8051e-04, PNorm = 62.2919, GNorm = 0.2644, lr_0 = 4.6341e-04
Loss = 2.2551e-04, PNorm = 62.3015, GNorm = 0.3353, lr_0 = 4.6136e-04
Loss = 2.4293e-04, PNorm = 62.3150, GNorm = 0.4534, lr_0 = 4.5931e-04
Loss = 2.7420e-04, PNorm = 62.3311, GNorm = 0.3027, lr_0 = 4.5728e-04
Loss = 2.5563e-04, PNorm = 62.3444, GNorm = 0.4437, lr_0 = 4.5526e-04
Validation rmse logD = 0.549124
Validation R2 logD = 0.778836
Validation rmse logP = 0.603576
Validation R2 logP = 0.861765
Epoch 35
Train function
Loss = 2.0692e-04, PNorm = 62.3584, GNorm = 0.3007, lr_0 = 4.5305e-04
Loss = 1.7297e-04, PNorm = 62.3713, GNorm = 0.1655, lr_0 = 4.5104e-04
Loss = 1.6893e-04, PNorm = 62.3792, GNorm = 0.4265, lr_0 = 4.4905e-04
Loss = 1.9816e-04, PNorm = 62.3884, GNorm = 0.4316, lr_0 = 4.4706e-04
Loss = 1.8573e-04, PNorm = 62.3984, GNorm = 0.6830, lr_0 = 4.4508e-04
Loss = 3.1936e-04, PNorm = 62.4083, GNorm = 0.2742, lr_0 = 4.4311e-04
Validation rmse logD = 0.546503
Validation R2 logD = 0.780942
Validation rmse logP = 0.614652
Validation R2 logP = 0.856645
Epoch 36
Train function
Loss = 2.8315e-04, PNorm = 62.4233, GNorm = 0.4776, lr_0 = 4.4096e-04
Loss = 2.1853e-04, PNorm = 62.4398, GNorm = 0.3176, lr_0 = 4.3901e-04
Loss = 3.1663e-04, PNorm = 62.4534, GNorm = 0.2527, lr_0 = 4.3707e-04
Loss = 1.9581e-04, PNorm = 62.4644, GNorm = 0.3120, lr_0 = 4.3513e-04
Loss = 2.5416e-04, PNorm = 62.4760, GNorm = 0.4515, lr_0 = 4.3321e-04
Validation rmse logD = 0.545650
Validation R2 logD = 0.781626
Validation rmse logP = 0.607707
Validation R2 logP = 0.859866
Epoch 37
Train function
Loss = 2.8234e-04, PNorm = 62.4918, GNorm = 0.4948, lr_0 = 4.3110e-04
Loss = 1.8903e-04, PNorm = 62.5010, GNorm = 0.1927, lr_0 = 4.2919e-04
Loss = 1.7425e-04, PNorm = 62.5122, GNorm = 0.2992, lr_0 = 4.2729e-04
Loss = 1.5316e-04, PNorm = 62.5249, GNorm = 0.2678, lr_0 = 4.2540e-04
Loss = 2.0734e-04, PNorm = 62.5327, GNorm = 0.2991, lr_0 = 4.2352e-04
Validation rmse logD = 0.546603
Validation R2 logD = 0.780863
Validation rmse logP = 0.593842
Validation R2 logP = 0.866188
Epoch 38
Train function
Loss = 1.2294e-04, PNorm = 62.5409, GNorm = 0.2783, lr_0 = 4.2146e-04
Loss = 1.6604e-04, PNorm = 62.5482, GNorm = 0.6431, lr_0 = 4.1960e-04
Loss = 2.2195e-04, PNorm = 62.5594, GNorm = 0.4295, lr_0 = 4.1774e-04
Loss = 1.6995e-04, PNorm = 62.5692, GNorm = 0.3185, lr_0 = 4.1589e-04
Loss = 2.0669e-04, PNorm = 62.5804, GNorm = 0.7634, lr_0 = 4.1406e-04
Loss = 1.9341e-04, PNorm = 62.5957, GNorm = 0.3136, lr_0 = 4.1222e-04
Validation rmse logD = 0.548734
Validation R2 logD = 0.779150
Validation rmse logP = 0.605321
Validation R2 logP = 0.860965
Epoch 39
Train function
Loss = 1.5523e-04, PNorm = 62.6086, GNorm = 0.4485, lr_0 = 4.1022e-04
Loss = 1.4875e-04, PNorm = 62.6156, GNorm = 0.2995, lr_0 = 4.0840e-04
Loss = 1.6043e-04, PNorm = 62.6246, GNorm = 0.1902, lr_0 = 4.0660e-04
Loss = 1.6049e-04, PNorm = 62.6328, GNorm = 0.3797, lr_0 = 4.0480e-04
Loss = 1.7604e-04, PNorm = 62.6380, GNorm = 0.2520, lr_0 = 4.0301e-04
Validation rmse logD = 0.542242
Validation R2 logD = 0.784345
Validation rmse logP = 0.594739
Validation R2 logP = 0.865784
Epoch 40
Train function
Loss = 1.0754e-04, PNorm = 62.6476, GNorm = 0.2122, lr_0 = 4.0105e-04
Loss = 1.4280e-04, PNorm = 62.6540, GNorm = 0.3736, lr_0 = 3.9927e-04
Loss = 1.5987e-04, PNorm = 62.6642, GNorm = 0.6283, lr_0 = 3.9751e-04
Loss = 1.8948e-04, PNorm = 62.6729, GNorm = 0.2509, lr_0 = 3.9575e-04
Loss = 2.1110e-04, PNorm = 62.6875, GNorm = 0.3612, lr_0 = 3.9400e-04
Validation rmse logD = 0.544820
Validation R2 logD = 0.782290
Validation rmse logP = 0.604397
Validation R2 logP = 0.861389
Epoch 41
Train function
Loss = 1.6430e-04, PNorm = 62.7009, GNorm = 0.3480, lr_0 = 3.9208e-04
Loss = 1.6846e-04, PNorm = 62.7147, GNorm = 0.3176, lr_0 = 3.9035e-04
Loss = 1.5070e-04, PNorm = 62.7225, GNorm = 0.3488, lr_0 = 3.8862e-04
Loss = 1.9731e-04, PNorm = 62.7360, GNorm = 0.4331, lr_0 = 3.8690e-04
Loss = 1.6844e-04, PNorm = 62.7449, GNorm = 0.2119, lr_0 = 3.8519e-04
Loss = 1.3182e-04, PNorm = 62.7535, GNorm = 0.5478, lr_0 = 3.8349e-04
Validation rmse logD = 0.553099
Validation R2 logD = 0.775623
Validation rmse logP = 0.603631
Validation R2 logP = 0.861740
Epoch 42
Train function
Loss = 1.8167e-04, PNorm = 62.7646, GNorm = 0.2726, lr_0 = 3.8179e-04
Loss = 2.6182e-04, PNorm = 62.7699, GNorm = 0.4936, lr_0 = 3.8010e-04
Loss = 2.1671e-04, PNorm = 62.7863, GNorm = 0.3743, lr_0 = 3.7842e-04
Loss = 1.8825e-04, PNorm = 62.8013, GNorm = 0.8513, lr_0 = 3.7675e-04
Loss = 1.7412e-04, PNorm = 62.8144, GNorm = 0.4108, lr_0 = 3.7508e-04
Validation rmse logD = 0.555862
Validation R2 logD = 0.773376
Validation rmse logP = 0.604132
Validation R2 logP = 0.861511
Epoch 43
Train function
Loss = 2.0530e-04, PNorm = 62.8268, GNorm = 0.9003, lr_0 = 3.7326e-04
Loss = 1.9311e-04, PNorm = 62.8427, GNorm = 0.2997, lr_0 = 3.7160e-04
Loss = 1.7552e-04, PNorm = 62.8539, GNorm = 0.4781, lr_0 = 3.6996e-04
Loss = 1.5264e-04, PNorm = 62.8624, GNorm = 0.3417, lr_0 = 3.6832e-04
Loss = 1.8635e-04, PNorm = 62.8688, GNorm = 0.7994, lr_0 = 3.6669e-04
Validation rmse logD = 0.569745
Validation R2 logD = 0.761914
Validation rmse logP = 0.609731
Validation R2 logP = 0.858932
Epoch 44
Train function
Loss = 3.9804e-04, PNorm = 62.8890, GNorm = 0.7624, lr_0 = 3.6491e-04
Loss = 4.0593e-04, PNorm = 62.9129, GNorm = 0.4084, lr_0 = 3.6330e-04
Loss = 3.2347e-04, PNorm = 62.9338, GNorm = 0.2324, lr_0 = 3.6169e-04
Loss = 2.5146e-04, PNorm = 62.9538, GNorm = 0.3839, lr_0 = 3.6009e-04
Loss = 2.4848e-04, PNorm = 62.9668, GNorm = 0.2585, lr_0 = 3.5850e-04
Loss = 1.7081e-04, PNorm = 62.9799, GNorm = 0.1673, lr_0 = 3.5691e-04
Loss = 8.9925e-04, PNorm = 62.9813, GNorm = 0.5987, lr_0 = 3.5675e-04
Validation rmse logD = 0.551913
Validation R2 logD = 0.776584
Validation rmse logP = 0.595418
Validation R2 logP = 0.865477
Epoch 45
Train function
Loss = 1.3747e-04, PNorm = 62.9956, GNorm = 0.3464, lr_0 = 3.5518e-04
Loss = 1.5446e-04, PNorm = 63.0040, GNorm = 0.2596, lr_0 = 3.5360e-04
Loss = 1.8296e-04, PNorm = 63.0120, GNorm = 0.2184, lr_0 = 3.5204e-04
Loss = 1.7918e-04, PNorm = 63.0198, GNorm = 0.7734, lr_0 = 3.5048e-04
Loss = 1.4667e-04, PNorm = 63.0271, GNorm = 0.4808, lr_0 = 3.4893e-04
Validation rmse logD = 0.547598
Validation R2 logD = 0.780063
Validation rmse logP = 0.603917
Validation R2 logP = 0.861609
Epoch 46
Train function
Loss = 9.0031e-05, PNorm = 63.0310, GNorm = 0.1336, lr_0 = 3.4724e-04
Loss = 9.8093e-05, PNorm = 63.0389, GNorm = 0.2011, lr_0 = 3.4570e-04
Loss = 1.0581e-04, PNorm = 63.0479, GNorm = 0.5162, lr_0 = 3.4417e-04
Loss = 1.1861e-04, PNorm = 63.0549, GNorm = 0.2861, lr_0 = 3.4265e-04
Loss = 1.1316e-04, PNorm = 63.0591, GNorm = 0.2473, lr_0 = 3.4113e-04
Validation rmse logD = 0.545655
Validation R2 logD = 0.781622
Validation rmse logP = 0.607614
Validation R2 logP = 0.859910
Epoch 47
Train function
Loss = 8.5326e-05, PNorm = 63.0651, GNorm = 0.1497, lr_0 = 3.3947e-04
Loss = 9.9522e-05, PNorm = 63.0718, GNorm = 0.5143, lr_0 = 3.3797e-04
Loss = 8.3563e-05, PNorm = 63.0771, GNorm = 0.2149, lr_0 = 3.3648e-04
Loss = 9.6547e-05, PNorm = 63.0830, GNorm = 0.3688, lr_0 = 3.3499e-04
Loss = 1.1412e-04, PNorm = 63.0905, GNorm = 0.4384, lr_0 = 3.3351e-04
Validation rmse logD = 0.546503
Validation R2 logD = 0.780942
Validation rmse logP = 0.602387
Validation R2 logP = 0.862309
Epoch 48
Train function
Loss = 1.0412e-04, PNorm = 63.0975, GNorm = 0.1678, lr_0 = 3.3188e-04
Loss = 7.4554e-05, PNorm = 63.1025, GNorm = 0.1834, lr_0 = 3.3042e-04
Loss = 1.2162e-04, PNorm = 63.1086, GNorm = 0.5751, lr_0 = 3.2895e-04
Loss = 1.2335e-04, PNorm = 63.1133, GNorm = 0.1587, lr_0 = 3.2750e-04
Loss = 8.2262e-05, PNorm = 63.1178, GNorm = 0.2026, lr_0 = 3.2605e-04
Loss = 8.3644e-05, PNorm = 63.1246, GNorm = 0.3344, lr_0 = 3.2461e-04
Validation rmse logD = 0.548638
Validation R2 logD = 0.779228
Validation rmse logP = 0.601463
Validation R2 logP = 0.862731
Epoch 49
Train function
Loss = 9.3338e-05, PNorm = 63.1321, GNorm = 0.2280, lr_0 = 3.2303e-04
Loss = 9.1529e-05, PNorm = 63.1378, GNorm = 0.1762, lr_0 = 3.2160e-04
Loss = 9.4045e-05, PNorm = 63.1433, GNorm = 0.2341, lr_0 = 3.2018e-04
Loss = 8.9715e-05, PNorm = 63.1502, GNorm = 0.3845, lr_0 = 3.1876e-04
Loss = 9.9605e-05, PNorm = 63.1554, GNorm = 0.1163, lr_0 = 3.1735e-04
Validation rmse logD = 0.550228
Validation R2 logD = 0.777946
Validation rmse logP = 0.597302
Validation R2 logP = 0.864624
Epoch 50
Train function
Loss = 8.5873e-05, PNorm = 63.1616, GNorm = 0.2645, lr_0 = 3.1595e-04
Loss = 8.9265e-05, PNorm = 63.1675, GNorm = 0.2061, lr_0 = 3.1455e-04
Loss = 8.2401e-05, PNorm = 63.1717, GNorm = 0.2740, lr_0 = 3.1316e-04
Loss = 8.9405e-05, PNorm = 63.1763, GNorm = 0.2661, lr_0 = 3.1177e-04
Loss = 1.0721e-04, PNorm = 63.1815, GNorm = 0.3435, lr_0 = 3.1039e-04
Validation rmse logD = 0.550744
Validation R2 logD = 0.777530
Validation rmse logP = 0.604538
Validation R2 logP = 0.861324
Epoch 51
Train function
Loss = 1.6805e-04, PNorm = 63.1898, GNorm = 0.3022, lr_0 = 3.0888e-04
Loss = 9.7932e-05, PNorm = 63.1987, GNorm = 0.1714, lr_0 = 3.0752e-04
Loss = 9.8944e-05, PNorm = 63.2011, GNorm = 0.2054, lr_0 = 3.0616e-04
Loss = 9.6011e-05, PNorm = 63.2074, GNorm = 0.4193, lr_0 = 3.0480e-04
Loss = 7.7834e-05, PNorm = 63.2108, GNorm = 0.2790, lr_0 = 3.0346e-04
Loss = 8.8909e-05, PNorm = 63.2172, GNorm = 0.2347, lr_0 = 3.0211e-04
Validation rmse logD = 0.549480
Validation R2 logD = 0.778550
Validation rmse logP = 0.602220
Validation R2 logP = 0.862386
Epoch 52
Train function
Loss = 7.3407e-05, PNorm = 63.2234, GNorm = 0.1637, lr_0 = 3.0064e-04
Loss = 9.0959e-05, PNorm = 63.2297, GNorm = 0.1736, lr_0 = 2.9931e-04
Loss = 8.1587e-05, PNorm = 63.2357, GNorm = 0.2528, lr_0 = 2.9799e-04
Loss = 7.1333e-05, PNorm = 63.2396, GNorm = 0.4082, lr_0 = 2.9667e-04
Loss = 7.8139e-05, PNorm = 63.2422, GNorm = 0.2209, lr_0 = 2.9536e-04
Validation rmse logD = 0.550765
Validation R2 logD = 0.777513
Validation rmse logP = 0.600184
Validation R2 logP = 0.863315
Epoch 53
Train function
Loss = 8.3185e-05, PNorm = 63.2498, GNorm = 0.4211, lr_0 = 2.9392e-04
Loss = 7.0899e-05, PNorm = 63.2546, GNorm = 0.5843, lr_0 = 2.9262e-04
Loss = 1.0215e-04, PNorm = 63.2595, GNorm = 0.4777, lr_0 = 2.9133e-04
Loss = 6.6633e-05, PNorm = 63.2651, GNorm = 0.2074, lr_0 = 2.9004e-04
Loss = 7.6713e-05, PNorm = 63.2702, GNorm = 0.4022, lr_0 = 2.8876e-04
Validation rmse logD = 0.548226
Validation R2 logD = 0.779559
Validation rmse logP = 0.597051
Validation R2 logP = 0.864738
Epoch 54
Train function
Loss = 6.4827e-05, PNorm = 63.2771, GNorm = 0.4263, lr_0 = 2.8735e-04
Loss = 6.6502e-05, PNorm = 63.2800, GNorm = 0.1898, lr_0 = 2.8608e-04
Loss = 6.3843e-05, PNorm = 63.2840, GNorm = 0.2012, lr_0 = 2.8482e-04
Loss = 6.0579e-05, PNorm = 63.2903, GNorm = 0.1303, lr_0 = 2.8356e-04
Loss = 7.4273e-05, PNorm = 63.2948, GNorm = 0.3808, lr_0 = 2.8230e-04
Loss = 7.6809e-05, PNorm = 63.2990, GNorm = 0.1720, lr_0 = 2.8105e-04
Validation rmse logD = 0.546848
Validation R2 logD = 0.780666
Validation rmse logP = 0.599456
Validation R2 logP = 0.863646
Epoch 55
Train function
Loss = 4.7690e-05, PNorm = 63.3021, GNorm = 0.1811, lr_0 = 2.7969e-04
Loss = 5.1773e-05, PNorm = 63.3069, GNorm = 0.1512, lr_0 = 2.7845e-04
Loss = 5.4553e-05, PNorm = 63.3106, GNorm = 0.1486, lr_0 = 2.7722e-04
Loss = 6.2925e-05, PNorm = 63.3134, GNorm = 0.3334, lr_0 = 2.7599e-04
Loss = 7.1034e-05, PNorm = 63.3187, GNorm = 0.4442, lr_0 = 2.7477e-04
Validation rmse logD = 0.549696
Validation R2 logD = 0.778375
Validation rmse logP = 0.601901
Validation R2 logP = 0.862532
Epoch 56
Train function
Loss = 5.9698e-05, PNorm = 63.3244, GNorm = 0.1159, lr_0 = 2.7343e-04
Loss = 6.3145e-05, PNorm = 63.3285, GNorm = 0.2111, lr_0 = 2.7222e-04
Loss = 6.3176e-05, PNorm = 63.3318, GNorm = 0.2299, lr_0 = 2.7102e-04
Loss = 4.9013e-05, PNorm = 63.3358, GNorm = 0.1967, lr_0 = 2.6982e-04
Loss = 5.4568e-05, PNorm = 63.3396, GNorm = 0.1323, lr_0 = 2.6863e-04
Validation rmse logD = 0.547074
Validation R2 logD = 0.780484
Validation rmse logP = 0.597482
Validation R2 logP = 0.864543
Epoch 57
Train function
Loss = 5.0198e-05, PNorm = 63.3442, GNorm = 0.4000, lr_0 = 2.6732e-04
Loss = 5.1990e-05, PNorm = 63.3474, GNorm = 0.2785, lr_0 = 2.6614e-04
Loss = 5.5859e-05, PNorm = 63.3501, GNorm = 0.2226, lr_0 = 2.6496e-04
Loss = 5.5746e-05, PNorm = 63.3540, GNorm = 0.1411, lr_0 = 2.6379e-04
Loss = 5.1984e-05, PNorm = 63.3577, GNorm = 0.1756, lr_0 = 2.6262e-04
Loss = 7.2934e-05, PNorm = 63.3651, GNorm = 0.3341, lr_0 = 2.6146e-04
Loss = 2.0919e-04, PNorm = 63.3656, GNorm = 0.3085, lr_0 = 2.6134e-04
Validation rmse logD = 0.548359
Validation R2 logD = 0.779452
Validation rmse logP = 0.594911
Validation R2 logP = 0.865706
Epoch 58
Train function
Loss = 4.5935e-05, PNorm = 63.3677, GNorm = 0.1891, lr_0 = 2.6019e-04
Loss = 4.8831e-05, PNorm = 63.3735, GNorm = 0.1129, lr_0 = 2.5904e-04
Loss = 5.0574e-05, PNorm = 63.3771, GNorm = 0.1927, lr_0 = 2.5789e-04
Loss = 5.0459e-05, PNorm = 63.3824, GNorm = 0.1142, lr_0 = 2.5675e-04
Loss = 3.6093e-05, PNorm = 63.3853, GNorm = 0.1146, lr_0 = 2.5561e-04
Validation rmse logD = 0.549458
Validation R2 logD = 0.778567
Validation rmse logP = 0.601927
Validation R2 logP = 0.862520
Epoch 59
Train function
Loss = 6.3375e-05, PNorm = 63.3889, GNorm = 0.2617, lr_0 = 2.5448e-04
Loss = 4.7141e-05, PNorm = 63.3916, GNorm = 0.2880, lr_0 = 2.5336e-04
Loss = 7.5528e-05, PNorm = 63.3943, GNorm = 0.3635, lr_0 = 2.5224e-04
Loss = 5.5908e-05, PNorm = 63.3977, GNorm = 0.3334, lr_0 = 2.5112e-04
Loss = 4.8509e-05, PNorm = 63.4018, GNorm = 0.2419, lr_0 = 2.5001e-04
Validation rmse logD = 0.556992
Validation R2 logD = 0.772453
Validation rmse logP = 0.600146
Validation R2 logP = 0.863332
Epoch 60
Train function
Loss = 1.0181e-04, PNorm = 63.4089, GNorm = 0.2824, lr_0 = 2.4879e-04
Loss = 9.4618e-05, PNorm = 63.4131, GNorm = 0.1668, lr_0 = 2.4769e-04
Loss = 8.4108e-05, PNorm = 63.4176, GNorm = 0.1242, lr_0 = 2.4660e-04
Loss = 6.2591e-05, PNorm = 63.4224, GNorm = 0.1939, lr_0 = 2.4551e-04
Loss = 5.2379e-05, PNorm = 63.4275, GNorm = 0.1994, lr_0 = 2.4442e-04
Loss = 4.9503e-05, PNorm = 63.4319, GNorm = 0.4097, lr_0 = 2.4334e-04
Loss = 1.8526e-04, PNorm = 63.4323, GNorm = 0.2858, lr_0 = 2.4323e-04
Validation rmse logD = 0.547509
Validation R2 logD = 0.780135
Validation rmse logP = 0.602024
Validation R2 logP = 0.862476
Epoch 61
Train function
Loss = 4.2917e-05, PNorm = 63.4361, GNorm = 0.1384, lr_0 = 2.4216e-04
Loss = 3.8283e-05, PNorm = 63.4383, GNorm = 0.1358, lr_0 = 2.4109e-04
Loss = 4.6026e-05, PNorm = 63.4430, GNorm = 0.2345, lr_0 = 2.4002e-04
Loss = 4.2049e-05, PNorm = 63.4468, GNorm = 0.0972, lr_0 = 2.3896e-04
Loss = 3.7227e-05, PNorm = 63.4496, GNorm = 0.2778, lr_0 = 2.3790e-04
Validation rmse logD = 0.550368
Validation R2 logD = 0.777833
Validation rmse logP = 0.600564
Validation R2 logP = 0.863142
Epoch 62
Train function
Loss = 4.4427e-05, PNorm = 63.4531, GNorm = 0.1804, lr_0 = 2.3674e-04
Loss = 4.4581e-05, PNorm = 63.4565, GNorm = 0.0835, lr_0 = 2.3570e-04
Loss = 3.6365e-05, PNorm = 63.4588, GNorm = 0.0942, lr_0 = 2.3465e-04
Loss = 3.2825e-05, PNorm = 63.4613, GNorm = 0.1197, lr_0 = 2.3362e-04
Loss = 4.6133e-05, PNorm = 63.4648, GNorm = 0.3254, lr_0 = 2.3258e-04
Validation rmse logD = 0.548584
Validation R2 logD = 0.779271
Validation rmse logP = 0.596321
Validation R2 logP = 0.865068
Epoch 63
Train function
Loss = 3.6312e-05, PNorm = 63.4684, GNorm = 0.1868, lr_0 = 2.3145e-04
Loss = 2.8722e-05, PNorm = 63.4699, GNorm = 0.2503, lr_0 = 2.3043e-04
Loss = 3.7110e-05, PNorm = 63.4723, GNorm = 0.2620, lr_0 = 2.2941e-04
Loss = 4.5329e-05, PNorm = 63.4769, GNorm = 0.1889, lr_0 = 2.2839e-04
Loss = 3.5434e-05, PNorm = 63.4800, GNorm = 0.1283, lr_0 = 2.2738e-04
Validation rmse logD = 0.548845
Validation R2 logD = 0.779061
Validation rmse logP = 0.602698
Validation R2 logP = 0.862167
Epoch 64
Train function
Loss = 1.7881e-05, PNorm = 63.4812, GNorm = 0.0970, lr_0 = 2.2628e-04
Loss = 2.8892e-05, PNorm = 63.4839, GNorm = 0.1494, lr_0 = 2.2528e-04
Loss = 3.2238e-05, PNorm = 63.4866, GNorm = 0.1832, lr_0 = 2.2428e-04
Loss = 3.1495e-05, PNorm = 63.4895, GNorm = 0.1276, lr_0 = 2.2329e-04
Loss = 2.9442e-05, PNorm = 63.4916, GNorm = 0.1859, lr_0 = 2.2230e-04
Loss = 3.6835e-05, PNorm = 63.4944, GNorm = 0.1516, lr_0 = 2.2132e-04
Validation rmse logD = 0.550636
Validation R2 logD = 0.777616
Validation rmse logP = 0.596899
Validation R2 logP = 0.864807
Epoch 65
Train function
Loss = 4.6953e-05, PNorm = 63.4986, GNorm = 0.3001, lr_0 = 2.2024e-04
Loss = 3.6717e-05, PNorm = 63.5010, GNorm = 0.2719, lr_0 = 2.1927e-04
Loss = 3.7730e-05, PNorm = 63.5034, GNorm = 0.2025, lr_0 = 2.1830e-04
Loss = 3.4863e-05, PNorm = 63.5066, GNorm = 0.1510, lr_0 = 2.1733e-04
Loss = 3.9125e-05, PNorm = 63.5117, GNorm = 0.0828, lr_0 = 2.1637e-04
Validation rmse logD = 0.548591
Validation R2 logD = 0.779266
Validation rmse logP = 0.601257
Validation R2 logP = 0.862826
Epoch 66
Train function
Loss = 6.9355e-05, PNorm = 63.5154, GNorm = 0.4815, lr_0 = 2.1532e-04
Loss = 5.7257e-05, PNorm = 63.5185, GNorm = 0.1596, lr_0 = 2.1436e-04
Loss = 5.7007e-05, PNorm = 63.5207, GNorm = 0.1227, lr_0 = 2.1342e-04
Loss = 3.8130e-05, PNorm = 63.5245, GNorm = 0.1192, lr_0 = 2.1247e-04
Loss = 3.3223e-05, PNorm = 63.5258, GNorm = 0.1400, lr_0 = 2.1153e-04
Validation rmse logD = 0.552091
Validation R2 logD = 0.776440
Validation rmse logP = 0.607184
Validation R2 logP = 0.860108
Epoch 67
Train function
Loss = 9.9583e-05, PNorm = 63.5276, GNorm = 0.7272, lr_0 = 2.1060e-04
Loss = 4.7914e-05, PNorm = 63.5329, GNorm = 0.1378, lr_0 = 2.0966e-04
Loss = 2.9774e-05, PNorm = 63.5357, GNorm = 0.0999, lr_0 = 2.0874e-04
Loss = 3.1965e-05, PNorm = 63.5402, GNorm = 0.1016, lr_0 = 2.0781e-04
Loss = 3.6104e-05, PNorm = 63.5422, GNorm = 0.1013, lr_0 = 2.0689e-04
Loss = 3.5230e-05, PNorm = 63.5443, GNorm = 0.1180, lr_0 = 2.0598e-04
Validation rmse logD = 0.549061
Validation R2 logD = 0.778887
Validation rmse logP = 0.597337
Validation R2 logP = 0.864608
Epoch 68
Train function
Loss = 4.1848e-05, PNorm = 63.5486, GNorm = 0.2708, lr_0 = 2.0498e-04
Loss = 4.0408e-05, PNorm = 63.5535, GNorm = 0.3638, lr_0 = 2.0407e-04
Loss = 4.0125e-05, PNorm = 63.5559, GNorm = 0.3179, lr_0 = 2.0317e-04
Loss = 3.0906e-05, PNorm = 63.5566, GNorm = 0.2047, lr_0 = 2.0227e-04
Loss = 3.6492e-05, PNorm = 63.5588, GNorm = 0.1368, lr_0 = 2.0137e-04
Validation rmse logD = 0.548977
Validation R2 logD = 0.778954
Validation rmse logP = 0.596621
Validation R2 logP = 0.864933
Epoch 69
Train function
Loss = 2.5137e-05, PNorm = 63.5602, GNorm = 0.1504, lr_0 = 2.0039e-04
Loss = 2.9892e-05, PNorm = 63.5634, GNorm = 0.0792, lr_0 = 1.9951e-04
Loss = 3.4877e-05, PNorm = 63.5667, GNorm = 0.1212, lr_0 = 1.9863e-04
Loss = 2.5846e-05, PNorm = 63.5686, GNorm = 0.1030, lr_0 = 1.9775e-04
Loss = 2.2479e-05, PNorm = 63.5698, GNorm = 0.0994, lr_0 = 1.9687e-04
Validation rmse logD = 0.552013
Validation R2 logD = 0.776503
Validation rmse logP = 0.601741
Validation R2 logP = 0.862605
Epoch 70
Train function
Loss = 3.7295e-05, PNorm = 63.5725, GNorm = 0.1656, lr_0 = 1.9592e-04
Loss = 3.9998e-05, PNorm = 63.5750, GNorm = 0.2743, lr_0 = 1.9505e-04
Loss = 4.3254e-05, PNorm = 63.5786, GNorm = 0.2619, lr_0 = 1.9419e-04
Loss = 3.4536e-05, PNorm = 63.5818, GNorm = 0.1902, lr_0 = 1.9333e-04
Loss = 3.0587e-05, PNorm = 63.5836, GNorm = 0.1687, lr_0 = 1.9247e-04
Loss = 2.8401e-05, PNorm = 63.5862, GNorm = 0.1315, lr_0 = 1.9162e-04
Validation rmse logD = 0.549130
Validation R2 logD = 0.778831
Validation rmse logP = 0.603778
Validation R2 logP = 0.861673
Epoch 71
Train function
Loss = 3.0863e-05, PNorm = 63.5887, GNorm = 0.2860, lr_0 = 1.9069e-04
Loss = 1.7304e-05, PNorm = 63.5910, GNorm = 0.1584, lr_0 = 1.8984e-04
Loss = 1.8765e-05, PNorm = 63.5936, GNorm = 0.0694, lr_0 = 1.8900e-04
Loss = 2.0513e-05, PNorm = 63.5953, GNorm = 0.0908, lr_0 = 1.8817e-04
Loss = 2.5686e-05, PNorm = 63.5976, GNorm = 0.0857, lr_0 = 1.8734e-04
Validation rmse logD = 0.549013
Validation R2 logD = 0.778926
Validation rmse logP = 0.600328
Validation R2 logP = 0.863249
Epoch 72
Train function
Loss = 2.5602e-05, PNorm = 63.5985, GNorm = 0.0911, lr_0 = 1.8643e-04
Loss = 2.7087e-05, PNorm = 63.6019, GNorm = 0.2104, lr_0 = 1.8560e-04
Loss = 2.3502e-05, PNorm = 63.6044, GNorm = 0.0975, lr_0 = 1.8478e-04
Loss = 2.0842e-05, PNorm = 63.6048, GNorm = 0.1468, lr_0 = 1.8396e-04
Loss = 1.8976e-05, PNorm = 63.6076, GNorm = 0.1767, lr_0 = 1.8315e-04
Validation rmse logD = 0.548408
Validation R2 logD = 0.779413
Validation rmse logP = 0.600852
Validation R2 logP = 0.863010
Epoch 73
Train function
Loss = 1.3073e-05, PNorm = 63.6081, GNorm = 0.1138, lr_0 = 1.8226e-04
Loss = 1.6683e-05, PNorm = 63.6095, GNorm = 0.1130, lr_0 = 1.8145e-04
Loss = 1.7970e-05, PNorm = 63.6112, GNorm = 0.0556, lr_0 = 1.8065e-04
Loss = 1.6161e-05, PNorm = 63.6123, GNorm = 0.1024, lr_0 = 1.7985e-04
Loss = 1.8549e-05, PNorm = 63.6131, GNorm = 0.2066, lr_0 = 1.7905e-04
Loss = 2.0402e-05, PNorm = 63.6147, GNorm = 0.1201, lr_0 = 1.7826e-04
Loss = 1.2373e-04, PNorm = 63.6150, GNorm = 0.2682, lr_0 = 1.7818e-04
Validation rmse logD = 0.549084
Validation R2 logD = 0.778868
Validation rmse logP = 0.599973
Validation R2 logP = 0.863411
Epoch 74
Train function
Loss = 2.1962e-05, PNorm = 63.6169, GNorm = 0.1322, lr_0 = 1.7739e-04
Loss = 2.0221e-05, PNorm = 63.6188, GNorm = 0.0758, lr_0 = 1.7661e-04
Loss = 1.9377e-05, PNorm = 63.6205, GNorm = 0.1450, lr_0 = 1.7583e-04
Loss = 1.4065e-05, PNorm = 63.6217, GNorm = 0.0937, lr_0 = 1.7505e-04
Loss = 1.9544e-05, PNorm = 63.6236, GNorm = 0.0785, lr_0 = 1.7428e-04
Validation rmse logD = 0.549088
Validation R2 logD = 0.778865
Validation rmse logP = 0.603143
Validation R2 logP = 0.861964
Epoch 75
Train function
Loss = 2.1247e-05, PNorm = 63.6258, GNorm = 0.1294, lr_0 = 1.7351e-04
Loss = 1.8308e-05, PNorm = 63.6269, GNorm = 0.1707, lr_0 = 1.7274e-04
Loss = 1.8962e-05, PNorm = 63.6286, GNorm = 0.0658, lr_0 = 1.7197e-04
Loss = 1.3162e-05, PNorm = 63.6298, GNorm = 0.0958, lr_0 = 1.7121e-04
Loss = 1.8797e-05, PNorm = 63.6313, GNorm = 0.0916, lr_0 = 1.7046e-04
Validation rmse logD = 0.547884
Validation R2 logD = 0.779834
Validation rmse logP = 0.598709
Validation R2 logP = 0.863986
Epoch 76
Train function
Loss = 1.1040e-05, PNorm = 63.6328, GNorm = 0.0658, lr_0 = 1.6963e-04
Loss = 1.3118e-05, PNorm = 63.6343, GNorm = 0.1140, lr_0 = 1.6888e-04
Loss = 1.3967e-05, PNorm = 63.6366, GNorm = 0.2681, lr_0 = 1.6813e-04
Loss = 1.5798e-05, PNorm = 63.6381, GNorm = 0.1986, lr_0 = 1.6739e-04
Loss = 2.0139e-05, PNorm = 63.6392, GNorm = 0.1252, lr_0 = 1.6665e-04
Loss = 2.1064e-05, PNorm = 63.6403, GNorm = 0.0875, lr_0 = 1.6591e-04
Loss = 1.2326e-04, PNorm = 63.6405, GNorm = 0.2369, lr_0 = 1.6584e-04
Validation rmse logD = 0.548876
Validation R2 logD = 0.779036
Validation rmse logP = 0.601407
Validation R2 logP = 0.862757
Epoch 77
Train function
Loss = 1.9444e-05, PNorm = 63.6433, GNorm = 0.0619, lr_0 = 1.6510e-04
Loss = 2.0713e-05, PNorm = 63.6450, GNorm = 0.0930, lr_0 = 1.6437e-04
Loss = 1.6603e-05, PNorm = 63.6469, GNorm = 0.0697, lr_0 = 1.6364e-04
Loss = 1.8687e-05, PNorm = 63.6483, GNorm = 0.0586, lr_0 = 1.6292e-04
Loss = 1.5820e-05, PNorm = 63.6496, GNorm = 0.0738, lr_0 = 1.6220e-04
Validation rmse logD = 0.550313
Validation R2 logD = 0.777878
Validation rmse logP = 0.600795
Validation R2 logP = 0.863036
Epoch 78
Train function
Loss = 1.3847e-05, PNorm = 63.6509, GNorm = 0.1813, lr_0 = 1.6141e-04
Loss = 1.4626e-05, PNorm = 63.6522, GNorm = 0.1995, lr_0 = 1.6070e-04
Loss = 1.4458e-05, PNorm = 63.6536, GNorm = 0.0660, lr_0 = 1.5999e-04
Loss = 1.2215e-05, PNorm = 63.6549, GNorm = 0.0808, lr_0 = 1.5928e-04
Loss = 2.3705e-05, PNorm = 63.6569, GNorm = 0.1747, lr_0 = 1.5857e-04
Validation rmse logD = 0.549806
Validation R2 logD = 0.778286
Validation rmse logP = 0.602879
Validation R2 logP = 0.862084
Epoch 79
Train function
Loss = 1.4189e-05, PNorm = 63.6590, GNorm = 0.1832, lr_0 = 1.5780e-04
Loss = 1.4621e-05, PNorm = 63.6609, GNorm = 0.1777, lr_0 = 1.5710e-04
Loss = 1.5831e-05, PNorm = 63.6617, GNorm = 0.0631, lr_0 = 1.5641e-04
Loss = 1.9159e-05, PNorm = 63.6628, GNorm = 0.1147, lr_0 = 1.5572e-04
Loss = 2.0585e-05, PNorm = 63.6647, GNorm = 0.1358, lr_0 = 1.5503e-04
Validation rmse logD = 0.549293
Validation R2 logD = 0.778700
Validation rmse logP = 0.601446
Validation R2 logP = 0.862739
Epoch 80
Train function
Loss = 9.8755e-06, PNorm = 63.6664, GNorm = 0.1310, lr_0 = 1.5427e-04
Loss = 1.4837e-05, PNorm = 63.6673, GNorm = 0.2763, lr_0 = 1.5359e-04
Loss = 1.2754e-05, PNorm = 63.6691, GNorm = 0.1270, lr_0 = 1.5291e-04
Loss = 1.0910e-05, PNorm = 63.6704, GNorm = 0.1411, lr_0 = 1.5224e-04
Loss = 9.8737e-06, PNorm = 63.6712, GNorm = 0.0882, lr_0 = 1.5156e-04
Loss = 1.0683e-05, PNorm = 63.6721, GNorm = 0.0512, lr_0 = 1.5089e-04
Validation rmse logD = 0.548789
Validation R2 logD = 0.779106
Validation rmse logP = 0.597762
Validation R2 logP = 0.864415
Epoch 81
Train function
Loss = 1.3062e-05, PNorm = 63.6724, GNorm = 0.2765, lr_0 = 1.5016e-04
Loss = 1.5752e-05, PNorm = 63.6740, GNorm = 0.2117, lr_0 = 1.4949e-04
Loss = 1.3102e-05, PNorm = 63.6757, GNorm = 0.0788, lr_0 = 1.4883e-04
Loss = 1.2170e-05, PNorm = 63.6768, GNorm = 0.1016, lr_0 = 1.4817e-04
Loss = 2.2146e-05, PNorm = 63.6778, GNorm = 0.2254, lr_0 = 1.4752e-04
Validation rmse logD = 0.549273
Validation R2 logD = 0.778717
Validation rmse logP = 0.598795
Validation R2 logP = 0.863947
Epoch 82
Train function
Loss = 1.5149e-05, PNorm = 63.6805, GNorm = 0.2180, lr_0 = 1.4680e-04
Loss = 1.8781e-05, PNorm = 63.6819, GNorm = 0.1887, lr_0 = 1.4615e-04
Loss = 1.3222e-05, PNorm = 63.6833, GNorm = 0.0696, lr_0 = 1.4551e-04
Loss = 1.4410e-05, PNorm = 63.6845, GNorm = 0.0620, lr_0 = 1.4486e-04
Loss = 1.1199e-05, PNorm = 63.6856, GNorm = 0.1029, lr_0 = 1.4422e-04
Validation rmse logD = 0.548300
Validation R2 logD = 0.779500
Validation rmse logP = 0.601948
Validation R2 logP = 0.862510
Epoch 83
Train function
Loss = 6.8960e-06, PNorm = 63.6864, GNorm = 0.0752, lr_0 = 1.4352e-04
Loss = 1.3969e-05, PNorm = 63.6879, GNorm = 0.1026, lr_0 = 1.4288e-04
Loss = 1.4580e-05, PNorm = 63.6884, GNorm = 0.1101, lr_0 = 1.4225e-04
Loss = 1.3815e-05, PNorm = 63.6897, GNorm = 0.1661, lr_0 = 1.4162e-04
Loss = 1.5120e-05, PNorm = 63.6907, GNorm = 0.1249, lr_0 = 1.4100e-04
Loss = 1.4992e-05, PNorm = 63.6915, GNorm = 0.0715, lr_0 = 1.4037e-04
Validation rmse logD = 0.550356
Validation R2 logD = 0.777842
Validation rmse logP = 0.599173
Validation R2 logP = 0.863775
Epoch 84
Train function
Loss = 3.2164e-05, PNorm = 63.6927, GNorm = 0.0724, lr_0 = 1.3975e-04
Loss = 3.6740e-05, PNorm = 63.6954, GNorm = 0.2994, lr_0 = 1.3913e-04
Loss = 2.7747e-05, PNorm = 63.6984, GNorm = 0.1058, lr_0 = 1.3852e-04
Loss = 1.8921e-05, PNorm = 63.7004, GNorm = 0.1207, lr_0 = 1.3791e-04
Loss = 1.6593e-05, PNorm = 63.7025, GNorm = 0.0524, lr_0 = 1.3730e-04
Validation rmse logD = 0.549402
Validation R2 logD = 0.778612
Validation rmse logP = 0.597885
Validation R2 logP = 0.864360
Epoch 85
Train function
Loss = 1.2325e-05, PNorm = 63.7044, GNorm = 0.0644, lr_0 = 1.3663e-04
Loss = 1.9163e-05, PNorm = 63.7058, GNorm = 0.0853, lr_0 = 1.3602e-04
Loss = 1.3104e-05, PNorm = 63.7063, GNorm = 0.1058, lr_0 = 1.3542e-04
Loss = 2.0725e-05, PNorm = 63.7079, GNorm = 0.2601, lr_0 = 1.3482e-04
Loss = 1.9729e-05, PNorm = 63.7093, GNorm = 0.1202, lr_0 = 1.3423e-04
Validation rmse logD = 0.550705
Validation R2 logD = 0.777561
Validation rmse logP = 0.603377
Validation R2 logP = 0.861857
Epoch 86
Train function
Loss = 1.6998e-05, PNorm = 63.7110, GNorm = 0.1089, lr_0 = 1.3357e-04
Loss = 2.1473e-05, PNorm = 63.7117, GNorm = 0.1189, lr_0 = 1.3298e-04
Loss = 1.6072e-05, PNorm = 63.7134, GNorm = 0.0725, lr_0 = 1.3239e-04
Loss = 1.1873e-05, PNorm = 63.7145, GNorm = 0.0654, lr_0 = 1.3181e-04
Loss = 1.3176e-05, PNorm = 63.7157, GNorm = 0.0667, lr_0 = 1.3123e-04
Loss = 1.6033e-05, PNorm = 63.7162, GNorm = 0.1768, lr_0 = 1.3065e-04
Validation rmse logD = 0.548023
Validation R2 logD = 0.779722
Validation rmse logP = 0.598457
Validation R2 logP = 0.864100
Epoch 87
Train function
Loss = 1.7384e-05, PNorm = 63.7183, GNorm = 0.0660, lr_0 = 1.3001e-04
Loss = 9.0436e-06, PNorm = 63.7190, GNorm = 0.0517, lr_0 = 1.2944e-04
Loss = 8.5202e-06, PNorm = 63.7195, GNorm = 0.0811, lr_0 = 1.2886e-04
Loss = 9.8092e-06, PNorm = 63.7203, GNorm = 0.1061, lr_0 = 1.2829e-04
Loss = 1.1625e-05, PNorm = 63.7211, GNorm = 0.1921, lr_0 = 1.2773e-04
Validation rmse logD = 0.550906
Validation R2 logD = 0.777399
Validation rmse logP = 0.598577
Validation R2 logP = 0.864046
Epoch 88
Train function
Loss = 1.1484e-05, PNorm = 63.7223, GNorm = 0.0682, lr_0 = 1.2710e-04
Loss = 1.3158e-05, PNorm = 63.7238, GNorm = 0.0915, lr_0 = 1.2654e-04
Loss = 1.1369e-05, PNorm = 63.7254, GNorm = 0.1221, lr_0 = 1.2598e-04
Loss = 1.0239e-05, PNorm = 63.7272, GNorm = 0.0652, lr_0 = 1.2542e-04
Loss = 1.0833e-05, PNorm = 63.7278, GNorm = 0.0503, lr_0 = 1.2487e-04
Validation rmse logD = 0.548626
Validation R2 logD = 0.779237
Validation rmse logP = 0.600711
Validation R2 logP = 0.863074
Epoch 89
Train function
Loss = 1.0536e-05, PNorm = 63.7283, GNorm = 0.0583, lr_0 = 1.2426e-04
Loss = 7.6479e-06, PNorm = 63.7291, GNorm = 0.0947, lr_0 = 1.2371e-04
Loss = 9.7375e-06, PNorm = 63.7300, GNorm = 0.1210, lr_0 = 1.2317e-04
Loss = 1.3667e-05, PNorm = 63.7302, GNorm = 0.1284, lr_0 = 1.2262e-04
Loss = 9.9531e-06, PNorm = 63.7307, GNorm = 0.0533, lr_0 = 1.2208e-04
Loss = 1.3686e-05, PNorm = 63.7317, GNorm = 0.1028, lr_0 = 1.2154e-04
Loss = 1.2027e-04, PNorm = 63.7318, GNorm = 0.1826, lr_0 = 1.2148e-04
Validation rmse logD = 0.548769
Validation R2 logD = 0.779122
Validation rmse logP = 0.599662
Validation R2 logP = 0.863552
Epoch 90
Train function
Loss = 1.3687e-05, PNorm = 63.7333, GNorm = 0.1886, lr_0 = 1.2095e-04
Loss = 1.3812e-05, PNorm = 63.7347, GNorm = 0.2131, lr_0 = 1.2041e-04
Loss = 1.0401e-05, PNorm = 63.7361, GNorm = 0.1207, lr_0 = 1.1988e-04
Loss = 8.3579e-06, PNorm = 63.7372, GNorm = 0.1090, lr_0 = 1.1935e-04
Loss = 1.1559e-05, PNorm = 63.7384, GNorm = 0.0788, lr_0 = 1.1882e-04
Validation rmse logD = 0.550785
Validation R2 logD = 0.777496
Validation rmse logP = 0.600787
Validation R2 logP = 0.863040
Epoch 91
Train function
Loss = 9.7336e-06, PNorm = 63.7393, GNorm = 0.0604, lr_0 = 1.1824e-04
Loss = 1.1530e-05, PNorm = 63.7396, GNorm = 0.1090, lr_0 = 1.1772e-04
Loss = 9.1657e-06, PNorm = 63.7399, GNorm = 0.0921, lr_0 = 1.1720e-04
Loss = 8.0436e-06, PNorm = 63.7410, GNorm = 0.0371, lr_0 = 1.1668e-04
Loss = 6.6787e-06, PNorm = 63.7416, GNorm = 0.0490, lr_0 = 1.1616e-04
Validation rmse logD = 0.549152
Validation R2 logD = 0.778814
Validation rmse logP = 0.602290
Validation R2 logP = 0.862354
Epoch 92
Train function
Loss = 5.9036e-06, PNorm = 63.7431, GNorm = 0.0858, lr_0 = 1.1565e-04
Loss = 6.0705e-06, PNorm = 63.7441, GNorm = 0.0973, lr_0 = 1.1514e-04
Loss = 5.9272e-06, PNorm = 63.7441, GNorm = 0.1094, lr_0 = 1.1463e-04
Loss = 7.0021e-06, PNorm = 63.7448, GNorm = 0.1406, lr_0 = 1.1412e-04
Loss = 8.7636e-06, PNorm = 63.7452, GNorm = 0.0509, lr_0 = 1.1362e-04
Loss = 1.0469e-05, PNorm = 63.7463, GNorm = 0.1678, lr_0 = 1.1312e-04
Loss = 7.9088e-05, PNorm = 63.7464, GNorm = 0.2670, lr_0 = 1.1307e-04
Validation rmse logD = 0.549295
Validation R2 logD = 0.778698
Validation rmse logP = 0.602490
Validation R2 logP = 0.862262
Epoch 93
Train function
Loss = 9.5714e-06, PNorm = 63.7470, GNorm = 0.0847, lr_0 = 1.1257e-04
Loss = 8.3873e-06, PNorm = 63.7481, GNorm = 0.0660, lr_0 = 1.1207e-04
Loss = 1.3546e-05, PNorm = 63.7489, GNorm = 0.1075, lr_0 = 1.1157e-04
Loss = 1.0167e-05, PNorm = 63.7503, GNorm = 0.1201, lr_0 = 1.1108e-04
Loss = 6.4748e-06, PNorm = 63.7514, GNorm = 0.0345, lr_0 = 1.1059e-04
Validation rmse logD = 0.549670
Validation R2 logD = 0.778396
Validation rmse logP = 0.600541
Validation R2 logP = 0.863152
Epoch 94
Train function
Loss = 6.9087e-06, PNorm = 63.7524, GNorm = 0.1139, lr_0 = 1.1005e-04
Loss = 7.7839e-06, PNorm = 63.7534, GNorm = 0.0837, lr_0 = 1.0956e-04
Loss = 8.8994e-06, PNorm = 63.7545, GNorm = 0.0854, lr_0 = 1.0908e-04
Loss = 8.7138e-06, PNorm = 63.7552, GNorm = 0.0513, lr_0 = 1.0860e-04
Loss = 5.1002e-06, PNorm = 63.7563, GNorm = 0.0443, lr_0 = 1.0811e-04
Validation rmse logD = 0.549684
Validation R2 logD = 0.778385
Validation rmse logP = 0.601811
Validation R2 logP = 0.862573
Epoch 95
Train function
Loss = 7.5468e-06, PNorm = 63.7567, GNorm = 0.0828, lr_0 = 1.0759e-04
Loss = 5.6907e-06, PNorm = 63.7573, GNorm = 0.0347, lr_0 = 1.0711e-04
Loss = 4.9685e-06, PNorm = 63.7573, GNorm = 0.0678, lr_0 = 1.0664e-04
Loss = 5.1214e-06, PNorm = 63.7575, GNorm = 0.0476, lr_0 = 1.0617e-04
Loss = 6.9026e-06, PNorm = 63.7586, GNorm = 0.0393, lr_0 = 1.0570e-04
Validation rmse logD = 0.549389
Validation R2 logD = 0.778623
Validation rmse logP = 0.601917
Validation R2 logP = 0.862524
Epoch 96
Train function
Loss = 1.1119e-05, PNorm = 63.7592, GNorm = 0.0619, lr_0 = 1.0518e-04
Loss = 7.2081e-06, PNorm = 63.7600, GNorm = 0.0478, lr_0 = 1.0472e-04
Loss = 3.3750e-06, PNorm = 63.7610, GNorm = 0.0537, lr_0 = 1.0426e-04
Loss = 4.8112e-06, PNorm = 63.7619, GNorm = 0.0590, lr_0 = 1.0379e-04
Loss = 5.8143e-06, PNorm = 63.7625, GNorm = 0.0951, lr_0 = 1.0333e-04
Loss = 5.8734e-06, PNorm = 63.7633, GNorm = 0.0412, lr_0 = 1.0288e-04
Validation rmse logD = 0.550121
Validation R2 logD = 0.778032
Validation rmse logP = 0.600731
Validation R2 logP = 0.863066
Epoch 97
Train function
Loss = 6.5093e-06, PNorm = 63.7636, GNorm = 0.0777, lr_0 = 1.0238e-04
Loss = 5.9140e-06, PNorm = 63.7638, GNorm = 0.0564, lr_0 = 1.0192e-04
Loss = 3.8792e-06, PNorm = 63.7644, GNorm = 0.0672, lr_0 = 1.0147e-04
Loss = 7.3008e-06, PNorm = 63.7654, GNorm = 0.0891, lr_0 = 1.0102e-04
Loss = 7.0777e-06, PNorm = 63.7661, GNorm = 0.1418, lr_0 = 1.0058e-04
Validation rmse logD = 0.550056
Validation R2 logD = 0.778085
Validation rmse logP = 0.600956
Validation R2 logP = 0.862963
Epoch 98
Train function
Loss = 6.3900e-06, PNorm = 63.7669, GNorm = 0.1242, lr_0 = 1.0009e-04
Loss = 5.6778e-06, PNorm = 63.7678, GNorm = 0.1210, lr_0 = 1.0000e-04
Loss = 6.7683e-06, PNorm = 63.7685, GNorm = 0.0654, lr_0 = 1.0000e-04
Loss = 4.6334e-06, PNorm = 63.7691, GNorm = 0.0378, lr_0 = 1.0000e-04
Loss = 5.2824e-06, PNorm = 63.7695, GNorm = 0.0461, lr_0 = 1.0000e-04
Validation rmse logD = 0.550148
Validation R2 logD = 0.778010
Validation rmse logP = 0.600490
Validation R2 logP = 0.863175
Epoch 99
Train function
Loss = 3.7449e-06, PNorm = 63.7707, GNorm = 0.0479, lr_0 = 1.0000e-04
Loss = 5.5790e-06, PNorm = 63.7718, GNorm = 0.0555, lr_0 = 1.0000e-04
Loss = 5.1907e-06, PNorm = 63.7720, GNorm = 0.0758, lr_0 = 1.0000e-04
Loss = 5.7890e-06, PNorm = 63.7724, GNorm = 0.0922, lr_0 = 1.0000e-04
Loss = 7.8346e-06, PNorm = 63.7731, GNorm = 0.0815, lr_0 = 1.0000e-04
Loss = 5.6599e-06, PNorm = 63.7739, GNorm = 0.1413, lr_0 = 1.0000e-04
Validation rmse logD = 0.549891
Validation R2 logD = 0.778218
Validation rmse logP = 0.601976
Validation R2 logP = 0.862497
Model 0 best validation rmse = 0.568491 on epoch 39
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.672166
Model 0 test R2 logD = 0.682686
Model 0 test rmse logP = 0.798285
Model 0 test R2 logP = 0.724828
Ensemble test rmse  logD= 0.672166
Ensemble test R2  logD= 0.682686
Ensemble test rmse  logP= 0.798285
Ensemble test R2  logP= 0.724828
4-fold cross validation
	Seed 0 ==> test rmse = 0.697498
	Seed 0 ==> test R2 = 0.730920
	Seed 1 ==> test rmse = 0.768322
	Seed 1 ==> test R2 = 0.684172
	Seed 2 ==> test rmse = 0.699250
	Seed 2 ==> test R2 = 0.733993
	Seed 3 ==> test rmse = 0.735225
	Seed 3 ==> test R2 = 0.703757
Overall val rmse logD= 0.572385 +/- 0.020171
Overall val R2 logD = 0.772327 +/- 0.009796
Overall test rmse logD = 0.630131 +/- 0.039088
Overall test R2 logD = 0.720059 +/- 0.034054
Overall val rmse logP= 0.652440 +/- 0.043240
Overall val R2 logP = 0.807062 +/- 0.042431
Overall test rmse logP = 0.820017 +/- 0.087163
Overall test R2 logP = 0.706362 +/- 0.064854
Elapsed time = 4:29:28
