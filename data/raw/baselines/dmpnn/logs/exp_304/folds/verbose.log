Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_304/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=895, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,222,401
Moving model to cuda
Epoch 0
Train function
Loss = 2.2886e-02, PNorm = 52.4962, GNorm = 8.3933, lr_0 = 1.9340e-04
Loss = 1.8223e-02, PNorm = 52.5030, GNorm = 5.9890, lr_0 = 2.7830e-04
Loss = 1.7965e-02, PNorm = 52.5150, GNorm = 1.2017, lr_0 = 3.6321e-04
Loss = 1.6303e-02, PNorm = 52.5333, GNorm = 2.6154, lr_0 = 4.4811e-04
Loss = 1.5759e-02, PNorm = 52.5544, GNorm = 7.1066, lr_0 = 5.3302e-04
Validation rmse logD = 0.993904
Validation R2 logD = 0.238205
Epoch 1
Train function
Loss = 1.3660e-02, PNorm = 52.5891, GNorm = 1.6268, lr_0 = 6.2642e-04
Loss = 1.4816e-02, PNorm = 52.6420, GNorm = 2.3215, lr_0 = 7.1132e-04
Loss = 1.3159e-02, PNorm = 52.7184, GNorm = 6.3350, lr_0 = 7.9623e-04
Loss = 1.3406e-02, PNorm = 52.7875, GNorm = 2.2757, lr_0 = 8.8113e-04
Loss = 1.6594e-02, PNorm = 52.8738, GNorm = 3.9244, lr_0 = 9.6604e-04
Validation rmse logD = 0.983150
Validation R2 logD = 0.254601
Epoch 2
Train function
Loss = 1.5971e-02, PNorm = 52.9901, GNorm = 3.4376, lr_0 = 9.9690e-04
Loss = 1.2795e-02, PNorm = 53.0924, GNorm = 1.1010, lr_0 = 9.9249e-04
Loss = 1.2274e-02, PNorm = 53.1862, GNorm = 2.8045, lr_0 = 9.8810e-04
Loss = 1.0830e-02, PNorm = 53.2866, GNorm = 1.0416, lr_0 = 9.8373e-04
Loss = 1.2531e-02, PNorm = 53.3801, GNorm = 2.9844, lr_0 = 9.7938e-04
Validation rmse logD = 0.847704
Validation R2 logD = 0.445837
Epoch 3
Train function
Loss = 7.3396e-03, PNorm = 53.4956, GNorm = 0.9498, lr_0 = 9.7462e-04
Loss = 8.1495e-03, PNorm = 53.5633, GNorm = 1.7768, lr_0 = 9.7030e-04
Loss = 9.6759e-03, PNorm = 53.6443, GNorm = 1.2329, lr_0 = 9.6601e-04
Loss = 9.5192e-03, PNorm = 53.7391, GNorm = 2.3796, lr_0 = 9.6174e-04
Loss = 9.2037e-03, PNorm = 53.8463, GNorm = 2.1829, lr_0 = 9.5749e-04
Loss = 8.5954e-03, PNorm = 53.9677, GNorm = 2.0590, lr_0 = 9.5325e-04
Validation rmse logD = 0.815415
Validation R2 logD = 0.487249
Epoch 4
Train function
Loss = 7.7384e-03, PNorm = 54.0598, GNorm = 1.1686, lr_0 = 9.4861e-04
Loss = 7.3244e-03, PNorm = 54.1548, GNorm = 2.3170, lr_0 = 9.4442e-04
Loss = 6.6074e-03, PNorm = 54.2400, GNorm = 1.1645, lr_0 = 9.4024e-04
Loss = 6.9283e-03, PNorm = 54.3463, GNorm = 2.4698, lr_0 = 9.3608e-04
Loss = 7.1038e-03, PNorm = 54.4595, GNorm = 1.2707, lr_0 = 9.3194e-04
Validation rmse logD = 0.765299
Validation R2 logD = 0.548340
Epoch 5
Train function
Loss = 6.3040e-03, PNorm = 54.5813, GNorm = 1.1005, lr_0 = 9.2741e-04
Loss = 5.7227e-03, PNorm = 54.6951, GNorm = 2.1747, lr_0 = 9.2330e-04
Loss = 6.7197e-03, PNorm = 54.8093, GNorm = 4.0582, lr_0 = 9.1922e-04
Loss = 7.0902e-03, PNorm = 54.9349, GNorm = 0.9709, lr_0 = 9.1515e-04
Loss = 6.3302e-03, PNorm = 55.0283, GNorm = 1.0727, lr_0 = 9.1111e-04
Validation rmse logD = 0.723069
Validation R2 logD = 0.596811
Epoch 6
Train function
Loss = 4.5080e-03, PNorm = 55.1279, GNorm = 1.1940, lr_0 = 9.0667e-04
Loss = 5.3703e-03, PNorm = 55.2237, GNorm = 3.8154, lr_0 = 9.0266e-04
Loss = 5.7604e-03, PNorm = 55.3124, GNorm = 1.4803, lr_0 = 8.9867e-04
Loss = 5.3039e-03, PNorm = 55.4075, GNorm = 0.9245, lr_0 = 8.9469e-04
Loss = 5.5740e-03, PNorm = 55.4936, GNorm = 2.2469, lr_0 = 8.9074e-04
Loss = 5.1558e-03, PNorm = 55.6017, GNorm = 0.9019, lr_0 = 8.8680e-04
Validation rmse logD = 0.690402
Validation R2 logD = 0.632419
Epoch 7
Train function
Loss = 4.2716e-03, PNorm = 55.6918, GNorm = 2.2174, lr_0 = 8.8248e-04
Loss = 4.7602e-03, PNorm = 55.7760, GNorm = 1.3664, lr_0 = 8.7858e-04
Loss = 4.6805e-03, PNorm = 55.8789, GNorm = 3.4148, lr_0 = 8.7469e-04
Loss = 5.4787e-03, PNorm = 55.9612, GNorm = 3.6299, lr_0 = 8.7082e-04
Loss = 6.8418e-03, PNorm = 56.0637, GNorm = 2.3233, lr_0 = 8.6697e-04
Validation rmse logD = 0.717442
Validation R2 logD = 0.603062
Epoch 8
Train function
Loss = 4.7997e-03, PNorm = 56.1884, GNorm = 2.6546, lr_0 = 8.6276e-04
Loss = 3.8211e-03, PNorm = 56.2800, GNorm = 1.3933, lr_0 = 8.5894e-04
Loss = 3.8938e-03, PNorm = 56.3761, GNorm = 1.1298, lr_0 = 8.5514e-04
Loss = 4.3738e-03, PNorm = 56.4332, GNorm = 1.6466, lr_0 = 8.5136e-04
Loss = 3.8205e-03, PNorm = 56.5227, GNorm = 2.1818, lr_0 = 8.4759e-04
Validation rmse logD = 0.765667
Validation R2 logD = 0.547906
Epoch 9
Train function
Loss = 5.0721e-03, PNorm = 56.6222, GNorm = 1.3980, lr_0 = 8.4347e-04
Loss = 5.0017e-03, PNorm = 56.7239, GNorm = 2.0189, lr_0 = 8.3974e-04
Loss = 4.6157e-03, PNorm = 56.8262, GNorm = 1.7335, lr_0 = 8.3602e-04
Loss = 3.5086e-03, PNorm = 56.9115, GNorm = 0.6944, lr_0 = 8.3232e-04
Loss = 4.1969e-03, PNorm = 57.0011, GNorm = 0.9853, lr_0 = 8.2864e-04
Loss = 3.2665e-03, PNorm = 57.0516, GNorm = 1.3106, lr_0 = 8.2498e-04
Validation rmse logD = 0.668130
Validation R2 logD = 0.655752
Epoch 10
Train function
Loss = 3.3896e-03, PNorm = 57.1183, GNorm = 1.2391, lr_0 = 8.2133e-04
Loss = 3.4687e-03, PNorm = 57.2017, GNorm = 0.7742, lr_0 = 8.1770e-04
Loss = 3.6438e-03, PNorm = 57.2751, GNorm = 1.5490, lr_0 = 8.1408e-04
Loss = 2.9271e-03, PNorm = 57.3436, GNorm = 1.6150, lr_0 = 8.1048e-04
Loss = 2.9708e-03, PNorm = 57.3957, GNorm = 2.5357, lr_0 = 8.0689e-04
Validation rmse logD = 0.646300
Validation R2 logD = 0.677880
Epoch 11
Train function
Loss = 3.0950e-03, PNorm = 57.4527, GNorm = 1.7352, lr_0 = 8.0297e-04
Loss = 2.8823e-03, PNorm = 57.5251, GNorm = 1.6730, lr_0 = 7.9942e-04
Loss = 3.1072e-03, PNorm = 57.5901, GNorm = 1.1256, lr_0 = 7.9588e-04
Loss = 3.0294e-03, PNorm = 57.6620, GNorm = 2.8056, lr_0 = 7.9236e-04
Loss = 3.8587e-03, PNorm = 57.7458, GNorm = 2.7125, lr_0 = 7.8885e-04
Validation rmse logD = 0.629683
Validation R2 logD = 0.694231
Epoch 12
Train function
Loss = 3.5230e-03, PNorm = 57.8227, GNorm = 1.6604, lr_0 = 7.8502e-04
Loss = 2.4661e-03, PNorm = 57.8997, GNorm = 1.6677, lr_0 = 7.8154e-04
Loss = 2.4140e-03, PNorm = 57.9531, GNorm = 0.9400, lr_0 = 7.7809e-04
Loss = 2.2476e-03, PNorm = 58.0088, GNorm = 1.3720, lr_0 = 7.7465e-04
Loss = 2.2765e-03, PNorm = 58.0613, GNorm = 1.5555, lr_0 = 7.7122e-04
Loss = 2.3966e-03, PNorm = 58.1048, GNorm = 1.3937, lr_0 = 7.6781e-04
Loss = 8.6252e-03, PNorm = 58.1104, GNorm = 1.1386, lr_0 = 7.6747e-04
Validation rmse logD = 0.630093
Validation R2 logD = 0.693833
Epoch 13
Train function
Loss = 2.0731e-03, PNorm = 58.1639, GNorm = 0.8594, lr_0 = 7.6407e-04
Loss = 2.0134e-03, PNorm = 58.2362, GNorm = 0.9685, lr_0 = 7.6069e-04
Loss = 2.3715e-03, PNorm = 58.2812, GNorm = 1.6689, lr_0 = 7.5733e-04
Loss = 2.0771e-03, PNorm = 58.3244, GNorm = 1.1741, lr_0 = 7.5398e-04
Loss = 2.1105e-03, PNorm = 58.3841, GNorm = 1.7333, lr_0 = 7.5064e-04
Validation rmse logD = 0.701360
Validation R2 logD = 0.620658
Epoch 14
Train function
Loss = 3.9450e-03, PNorm = 58.4581, GNorm = 3.9871, lr_0 = 7.4699e-04
Loss = 2.6742e-03, PNorm = 58.5580, GNorm = 1.3867, lr_0 = 7.4369e-04
Loss = 2.2901e-03, PNorm = 58.6426, GNorm = 1.2200, lr_0 = 7.4040e-04
Loss = 2.5543e-03, PNorm = 58.7104, GNorm = 2.4925, lr_0 = 7.3712e-04
Loss = 2.0057e-03, PNorm = 58.7716, GNorm = 1.0064, lr_0 = 7.3386e-04
Validation rmse logD = 0.637316
Validation R2 logD = 0.686773
Epoch 15
Train function
Loss = 1.9114e-03, PNorm = 58.8312, GNorm = 0.6821, lr_0 = 7.3029e-04
Loss = 2.0419e-03, PNorm = 58.8937, GNorm = 1.7224, lr_0 = 7.2706e-04
Loss = 2.0488e-03, PNorm = 58.9646, GNorm = 0.6560, lr_0 = 7.2385e-04
Loss = 2.1272e-03, PNorm = 59.0150, GNorm = 1.8896, lr_0 = 7.2064e-04
Loss = 1.9820e-03, PNorm = 59.0601, GNorm = 2.8812, lr_0 = 7.1746e-04
Validation rmse logD = 0.617909
Validation R2 logD = 0.705559
Epoch 16
Train function
Loss = 2.0643e-03, PNorm = 59.1053, GNorm = 0.9784, lr_0 = 7.1397e-04
Loss = 1.5093e-03, PNorm = 59.1634, GNorm = 0.6152, lr_0 = 7.1081e-04
Loss = 1.3298e-03, PNorm = 59.2099, GNorm = 0.6759, lr_0 = 7.0766e-04
Loss = 1.6441e-03, PNorm = 59.2575, GNorm = 1.2144, lr_0 = 7.0453e-04
Loss = 1.5428e-03, PNorm = 59.2947, GNorm = 0.7292, lr_0 = 7.0142e-04
Loss = 1.9521e-03, PNorm = 59.3423, GNorm = 2.8856, lr_0 = 6.9831e-04
Validation rmse logD = 0.639277
Validation R2 logD = 0.684843
Epoch 17
Train function
Loss = 1.6832e-03, PNorm = 59.3931, GNorm = 2.1891, lr_0 = 6.9492e-04
Loss = 1.4784e-03, PNorm = 59.4371, GNorm = 0.5337, lr_0 = 6.9184e-04
Loss = 1.4148e-03, PNorm = 59.4851, GNorm = 0.5898, lr_0 = 6.8878e-04
Loss = 1.4587e-03, PNorm = 59.5256, GNorm = 0.7133, lr_0 = 6.8574e-04
Loss = 1.4201e-03, PNorm = 59.5641, GNorm = 0.9611, lr_0 = 6.8270e-04
Validation rmse logD = 0.599019
Validation R2 logD = 0.723286
Epoch 18
Train function
Loss = 1.1197e-03, PNorm = 59.6123, GNorm = 0.7621, lr_0 = 6.7938e-04
Loss = 1.5554e-03, PNorm = 59.6633, GNorm = 1.6285, lr_0 = 6.7638e-04
Loss = 1.4187e-03, PNorm = 59.7058, GNorm = 0.8326, lr_0 = 6.7338e-04
Loss = 1.2784e-03, PNorm = 59.7430, GNorm = 1.0091, lr_0 = 6.7041e-04
Loss = 1.3570e-03, PNorm = 59.7852, GNorm = 1.0654, lr_0 = 6.6744e-04
Validation rmse logD = 0.647788
Validation R2 logD = 0.676396
Epoch 19
Train function
Loss = 1.7359e-03, PNorm = 59.8270, GNorm = 1.6908, lr_0 = 6.6419e-04
Loss = 1.5023e-03, PNorm = 59.8712, GNorm = 1.4521, lr_0 = 6.6126e-04
Loss = 1.5184e-03, PNorm = 59.9208, GNorm = 0.9629, lr_0 = 6.5833e-04
Loss = 1.3968e-03, PNorm = 59.9518, GNorm = 0.9480, lr_0 = 6.5542e-04
Loss = 1.0547e-03, PNorm = 60.0005, GNorm = 1.0736, lr_0 = 6.5252e-04
Loss = 1.1328e-03, PNorm = 60.0458, GNorm = 0.7205, lr_0 = 6.4963e-04
Validation rmse logD = 0.630767
Validation R2 logD = 0.693178
Epoch 20
Train function
Loss = 1.2558e-03, PNorm = 60.0917, GNorm = 1.3088, lr_0 = 6.4676e-04
Loss = 1.1781e-03, PNorm = 60.1288, GNorm = 0.6851, lr_0 = 6.4390e-04
Loss = 1.0324e-03, PNorm = 60.1630, GNorm = 1.0298, lr_0 = 6.4105e-04
Loss = 1.1340e-03, PNorm = 60.1925, GNorm = 1.0879, lr_0 = 6.3822e-04
Loss = 1.2928e-03, PNorm = 60.2237, GNorm = 0.7669, lr_0 = 6.3539e-04
Validation rmse logD = 0.596112
Validation R2 logD = 0.725966
Epoch 21
Train function
Loss = 8.9121e-04, PNorm = 60.2631, GNorm = 0.8855, lr_0 = 6.3230e-04
Loss = 9.1794e-04, PNorm = 60.2995, GNorm = 1.4678, lr_0 = 6.2950e-04
Loss = 7.7847e-04, PNorm = 60.3337, GNorm = 0.4389, lr_0 = 6.2672e-04
Loss = 8.5216e-04, PNorm = 60.3631, GNorm = 0.5332, lr_0 = 6.2395e-04
Loss = 8.5017e-04, PNorm = 60.3938, GNorm = 0.5619, lr_0 = 6.2119e-04
Validation rmse logD = 0.584805
Validation R2 logD = 0.736263
Epoch 22
Train function
Loss = 7.5868e-04, PNorm = 60.4188, GNorm = 0.4443, lr_0 = 6.1817e-04
Loss = 1.0151e-03, PNorm = 60.4476, GNorm = 3.0690, lr_0 = 6.1543e-04
Loss = 1.0886e-03, PNorm = 60.4781, GNorm = 2.1409, lr_0 = 6.1271e-04
Loss = 9.8364e-04, PNorm = 60.5164, GNorm = 0.5484, lr_0 = 6.1000e-04
Loss = 8.2719e-04, PNorm = 60.5535, GNorm = 0.6860, lr_0 = 6.0730e-04
Loss = 7.7101e-04, PNorm = 60.5875, GNorm = 0.4989, lr_0 = 6.0461e-04
Validation rmse logD = 0.589754
Validation R2 logD = 0.731780
Epoch 23
Train function
Loss = 7.9696e-04, PNorm = 60.6169, GNorm = 0.8401, lr_0 = 6.0167e-04
Loss = 7.5194e-04, PNorm = 60.6487, GNorm = 0.4865, lr_0 = 5.9901e-04
Loss = 6.4089e-04, PNorm = 60.6681, GNorm = 1.0553, lr_0 = 5.9636e-04
Loss = 7.2273e-04, PNorm = 60.6968, GNorm = 0.5003, lr_0 = 5.9372e-04
Loss = 7.0583e-04, PNorm = 60.7206, GNorm = 0.3743, lr_0 = 5.9110e-04
Validation rmse logD = 0.595415
Validation R2 logD = 0.726606
Epoch 24
Train function
Loss = 9.3844e-04, PNorm = 60.7395, GNorm = 1.1242, lr_0 = 5.8822e-04
Loss = 7.0759e-04, PNorm = 60.7723, GNorm = 0.4381, lr_0 = 5.8562e-04
Loss = 7.9653e-04, PNorm = 60.8070, GNorm = 0.4686, lr_0 = 5.8303e-04
Loss = 5.5737e-04, PNorm = 60.8422, GNorm = 0.5068, lr_0 = 5.8045e-04
Loss = 8.0988e-04, PNorm = 60.8668, GNorm = 1.3905, lr_0 = 5.7788e-04
Validation rmse logD = 0.631685
Validation R2 logD = 0.692283
Epoch 25
Train function
Loss = 9.0338e-04, PNorm = 60.9032, GNorm = 1.3507, lr_0 = 5.7507e-04
Loss = 8.1329e-04, PNorm = 60.9369, GNorm = 1.0413, lr_0 = 5.7253e-04
Loss = 6.7523e-04, PNorm = 60.9607, GNorm = 0.4033, lr_0 = 5.7000e-04
Loss = 6.1961e-04, PNorm = 60.9844, GNorm = 1.0979, lr_0 = 5.6748e-04
Loss = 6.1106e-04, PNorm = 61.0084, GNorm = 0.7444, lr_0 = 5.6497e-04
Loss = 7.0411e-04, PNorm = 61.0332, GNorm = 0.4664, lr_0 = 5.6247e-04
Loss = 2.1710e-03, PNorm = 61.0350, GNorm = 0.7512, lr_0 = 5.6222e-04
Validation rmse logD = 0.590501
Validation R2 logD = 0.731100
Epoch 26
Train function
Loss = 4.7605e-04, PNorm = 61.0522, GNorm = 0.5094, lr_0 = 5.5973e-04
Loss = 5.6941e-04, PNorm = 61.0712, GNorm = 0.2786, lr_0 = 5.5725e-04
Loss = 5.2583e-04, PNorm = 61.0954, GNorm = 0.3870, lr_0 = 5.5479e-04
Loss = 6.0321e-04, PNorm = 61.1096, GNorm = 0.4376, lr_0 = 5.5233e-04
Loss = 6.9677e-04, PNorm = 61.1376, GNorm = 0.9344, lr_0 = 5.4989e-04
Validation rmse logD = 0.595097
Validation R2 logD = 0.726898
Epoch 27
Train function
Loss = 5.9002e-04, PNorm = 61.1720, GNorm = 1.3074, lr_0 = 5.4722e-04
Loss = 6.0505e-04, PNorm = 61.2072, GNorm = 0.6243, lr_0 = 5.4480e-04
Loss = 5.9411e-04, PNorm = 61.2294, GNorm = 0.3942, lr_0 = 5.4239e-04
Loss = 6.7750e-04, PNorm = 61.2500, GNorm = 0.5768, lr_0 = 5.3999e-04
Loss = 5.4357e-04, PNorm = 61.2729, GNorm = 0.6841, lr_0 = 5.3760e-04
Validation rmse logD = 0.589685
Validation R2 logD = 0.731843
Epoch 28
Train function
Loss = 5.6046e-04, PNorm = 61.2941, GNorm = 0.3068, lr_0 = 5.3498e-04
Loss = 5.9759e-04, PNorm = 61.3195, GNorm = 0.6016, lr_0 = 5.3262e-04
Loss = 5.1283e-04, PNorm = 61.3406, GNorm = 0.3021, lr_0 = 5.3026e-04
Loss = 5.1924e-04, PNorm = 61.3627, GNorm = 1.0995, lr_0 = 5.2792e-04
Loss = 4.5730e-04, PNorm = 61.3830, GNorm = 1.0551, lr_0 = 5.2558e-04
Validation rmse logD = 0.594269
Validation R2 logD = 0.727658
Epoch 29
Train function
Loss = 4.3142e-04, PNorm = 61.4097, GNorm = 1.0253, lr_0 = 5.2302e-04
Loss = 7.1030e-04, PNorm = 61.4420, GNorm = 0.9294, lr_0 = 5.2071e-04
Loss = 4.9458e-04, PNorm = 61.4725, GNorm = 0.6909, lr_0 = 5.1841e-04
Loss = 5.5113e-04, PNorm = 61.4940, GNorm = 0.3541, lr_0 = 5.1611e-04
Loss = 5.1895e-04, PNorm = 61.5119, GNorm = 1.3721, lr_0 = 5.1383e-04
Loss = 5.2911e-04, PNorm = 61.5268, GNorm = 0.7072, lr_0 = 5.1156e-04
Validation rmse logD = 0.583288
Validation R2 logD = 0.737630
Epoch 30
Train function
Loss = 4.0074e-04, PNorm = 61.5432, GNorm = 0.4211, lr_0 = 5.0930e-04
Loss = 4.4396e-04, PNorm = 61.5642, GNorm = 0.5910, lr_0 = 5.0704e-04
Loss = 4.7278e-04, PNorm = 61.5855, GNorm = 1.2610, lr_0 = 5.0480e-04
Loss = 3.4299e-04, PNorm = 61.6012, GNorm = 0.3626, lr_0 = 5.0257e-04
Loss = 3.8686e-04, PNorm = 61.6158, GNorm = 0.5201, lr_0 = 5.0034e-04
Validation rmse logD = 0.586522
Validation R2 logD = 0.734712
Epoch 31
Train function
Loss = 3.7033e-04, PNorm = 61.6335, GNorm = 0.5573, lr_0 = 4.9791e-04
Loss = 3.6084e-04, PNorm = 61.6505, GNorm = 0.4241, lr_0 = 4.9571e-04
Loss = 3.4360e-04, PNorm = 61.6666, GNorm = 0.9698, lr_0 = 4.9351e-04
Loss = 3.7151e-04, PNorm = 61.6793, GNorm = 0.2786, lr_0 = 4.9133e-04
Loss = 4.6841e-04, PNorm = 61.6986, GNorm = 0.5092, lr_0 = 4.8916e-04
Validation rmse logD = 0.609683
Validation R2 logD = 0.713346
Epoch 32
Train function
Loss = 6.4900e-04, PNorm = 61.7209, GNorm = 1.4640, lr_0 = 4.8678e-04
Loss = 5.9712e-04, PNorm = 61.7449, GNorm = 1.3798, lr_0 = 4.8463e-04
Loss = 7.0640e-04, PNorm = 61.7746, GNorm = 0.4752, lr_0 = 4.8248e-04
Loss = 4.6848e-04, PNorm = 61.8019, GNorm = 0.6193, lr_0 = 4.8035e-04
Loss = 4.3213e-04, PNorm = 61.8216, GNorm = 0.3588, lr_0 = 4.7822e-04
Loss = 3.3372e-04, PNorm = 61.8328, GNorm = 0.3016, lr_0 = 4.7611e-04
Validation rmse logD = 0.574079
Validation R2 logD = 0.745849
Epoch 33
Train function
Loss = 3.1552e-04, PNorm = 61.8475, GNorm = 0.4556, lr_0 = 4.7379e-04
Loss = 2.7236e-04, PNorm = 61.8572, GNorm = 0.3592, lr_0 = 4.7170e-04
Loss = 3.8128e-04, PNorm = 61.8677, GNorm = 0.9500, lr_0 = 4.6961e-04
Loss = 3.4764e-04, PNorm = 61.8821, GNorm = 0.8927, lr_0 = 4.6753e-04
Loss = 4.1733e-04, PNorm = 61.8991, GNorm = 0.9890, lr_0 = 4.6546e-04
Validation rmse logD = 0.582573
Validation R2 logD = 0.738272
Epoch 34
Train function
Loss = 3.3466e-04, PNorm = 61.9222, GNorm = 0.4052, lr_0 = 4.6320e-04
Loss = 3.5997e-04, PNorm = 61.9366, GNorm = 0.4921, lr_0 = 4.6115e-04
Loss = 3.5288e-04, PNorm = 61.9492, GNorm = 0.4282, lr_0 = 4.5911e-04
Loss = 3.5659e-04, PNorm = 61.9646, GNorm = 0.3181, lr_0 = 4.5708e-04
Loss = 3.6265e-04, PNorm = 61.9802, GNorm = 0.3496, lr_0 = 4.5506e-04
Validation rmse logD = 0.581765
Validation R2 logD = 0.738997
Epoch 35
Train function
Loss = 2.9834e-04, PNorm = 61.9982, GNorm = 0.3461, lr_0 = 4.5284e-04
Loss = 2.8701e-04, PNorm = 62.0105, GNorm = 0.4236, lr_0 = 4.5084e-04
Loss = 2.6543e-04, PNorm = 62.0256, GNorm = 0.6452, lr_0 = 4.4885e-04
Loss = 2.9646e-04, PNorm = 62.0366, GNorm = 0.4356, lr_0 = 4.4686e-04
Loss = 2.8780e-04, PNorm = 62.0464, GNorm = 0.5117, lr_0 = 4.4489e-04
Loss = 2.9669e-04, PNorm = 62.0623, GNorm = 0.2522, lr_0 = 4.4292e-04
Validation rmse logD = 0.573013
Validation R2 logD = 0.746791
Epoch 36
Train function
Loss = 2.7750e-04, PNorm = 62.0810, GNorm = 0.5209, lr_0 = 4.4076e-04
Loss = 2.7808e-04, PNorm = 62.0914, GNorm = 0.2802, lr_0 = 4.3881e-04
Loss = 2.3928e-04, PNorm = 62.1036, GNorm = 0.4745, lr_0 = 4.3687e-04
Loss = 2.4148e-04, PNorm = 62.1166, GNorm = 0.4132, lr_0 = 4.3494e-04
Loss = 3.2362e-04, PNorm = 62.1324, GNorm = 0.4757, lr_0 = 4.3302e-04
Validation rmse logD = 0.576209
Validation R2 logD = 0.743959
Epoch 37
Train function
Loss = 2.0757e-04, PNorm = 62.1409, GNorm = 0.2424, lr_0 = 4.3091e-04
Loss = 2.2888e-04, PNorm = 62.1555, GNorm = 0.2602, lr_0 = 4.2900e-04
Loss = 1.9922e-04, PNorm = 62.1662, GNorm = 0.2452, lr_0 = 4.2711e-04
Loss = 2.0518e-04, PNorm = 62.1785, GNorm = 0.2860, lr_0 = 4.2522e-04
Loss = 2.3157e-04, PNorm = 62.1889, GNorm = 0.3192, lr_0 = 4.2334e-04
Validation rmse logD = 0.581628
Validation R2 logD = 0.739121
Epoch 38
Train function
Loss = 2.5543e-04, PNorm = 62.1973, GNorm = 0.8176, lr_0 = 4.2128e-04
Loss = 3.4486e-04, PNorm = 62.2146, GNorm = 1.0131, lr_0 = 4.1941e-04
Loss = 2.7476e-04, PNorm = 62.2317, GNorm = 0.3451, lr_0 = 4.1756e-04
Loss = 2.1965e-04, PNorm = 62.2428, GNorm = 0.2957, lr_0 = 4.1571e-04
Loss = 2.7005e-04, PNorm = 62.2533, GNorm = 0.5792, lr_0 = 4.1387e-04
Loss = 2.4971e-04, PNorm = 62.2673, GNorm = 0.2392, lr_0 = 4.1204e-04
Loss = 3.2302e-03, PNorm = 62.2681, GNorm = 1.6038, lr_0 = 4.1186e-04
Validation rmse logD = 0.581452
Validation R2 logD = 0.739278
Epoch 39
Train function
Loss = 2.2333e-04, PNorm = 62.2829, GNorm = 0.8750, lr_0 = 4.1004e-04
Loss = 2.9588e-04, PNorm = 62.3005, GNorm = 0.5067, lr_0 = 4.0822e-04
Loss = 3.1093e-04, PNorm = 62.3134, GNorm = 0.4163, lr_0 = 4.0642e-04
Loss = 2.2770e-04, PNorm = 62.3227, GNorm = 0.3206, lr_0 = 4.0462e-04
Loss = 2.4498e-04, PNorm = 62.3335, GNorm = 0.4361, lr_0 = 4.0283e-04
Validation rmse logD = 0.582313
Validation R2 logD = 0.738505
Epoch 40
Train function
Loss = 2.8969e-04, PNorm = 62.3447, GNorm = 1.1513, lr_0 = 4.0105e-04
Loss = 2.8960e-04, PNorm = 62.3562, GNorm = 0.3548, lr_0 = 3.9927e-04
Loss = 2.6325e-04, PNorm = 62.3695, GNorm = 0.6152, lr_0 = 3.9751e-04
Loss = 2.1847e-04, PNorm = 62.3801, GNorm = 0.4349, lr_0 = 3.9575e-04
Loss = 2.4299e-04, PNorm = 62.3877, GNorm = 0.2901, lr_0 = 3.9400e-04
Validation rmse logD = 0.584924
Validation R2 logD = 0.736156
Epoch 41
Train function
Loss = 1.9184e-04, PNorm = 62.3995, GNorm = 0.2310, lr_0 = 3.9208e-04
Loss = 2.2251e-04, PNorm = 62.4114, GNorm = 0.7847, lr_0 = 3.9035e-04
Loss = 2.3964e-04, PNorm = 62.4223, GNorm = 0.7572, lr_0 = 3.8862e-04
Loss = 2.2653e-04, PNorm = 62.4348, GNorm = 0.5638, lr_0 = 3.8690e-04
Loss = 1.8346e-04, PNorm = 62.4435, GNorm = 0.2459, lr_0 = 3.8519e-04
Loss = 1.7982e-04, PNorm = 62.4517, GNorm = 0.2953, lr_0 = 3.8349e-04
Loss = 1.6279e-03, PNorm = 62.4526, GNorm = 0.5913, lr_0 = 3.8332e-04
Validation rmse logD = 0.579201
Validation R2 logD = 0.741293
Epoch 42
Train function
Loss = 1.3817e-04, PNorm = 62.4597, GNorm = 0.1526, lr_0 = 3.8162e-04
Loss = 1.7560e-04, PNorm = 62.4712, GNorm = 0.5178, lr_0 = 3.7993e-04
Loss = 1.6115e-04, PNorm = 62.4802, GNorm = 0.3508, lr_0 = 3.7825e-04
Loss = 2.3775e-04, PNorm = 62.4893, GNorm = 0.4121, lr_0 = 3.7658e-04
Loss = 1.4068e-04, PNorm = 62.4989, GNorm = 0.2179, lr_0 = 3.7491e-04
Validation rmse logD = 0.584347
Validation R2 logD = 0.736676
Epoch 43
Train function
Loss = 1.2003e-04, PNorm = 62.5074, GNorm = 0.2843, lr_0 = 3.7309e-04
Loss = 1.4149e-04, PNorm = 62.5167, GNorm = 0.2172, lr_0 = 3.7144e-04
Loss = 1.2931e-04, PNorm = 62.5268, GNorm = 0.1246, lr_0 = 3.6980e-04
Loss = 1.3513e-04, PNorm = 62.5357, GNorm = 0.1594, lr_0 = 3.6816e-04
Loss = 1.6584e-04, PNorm = 62.5441, GNorm = 0.2223, lr_0 = 3.6653e-04
Validation rmse logD = 0.585231
Validation R2 logD = 0.735878
Epoch 44
Train function
Loss = 1.5600e-04, PNorm = 62.5530, GNorm = 0.3520, lr_0 = 3.6475e-04
Loss = 2.0513e-04, PNorm = 62.5597, GNorm = 0.3286, lr_0 = 3.6314e-04
Loss = 1.8154e-04, PNorm = 62.5686, GNorm = 0.4492, lr_0 = 3.6153e-04
Loss = 1.7314e-04, PNorm = 62.5757, GNorm = 0.4385, lr_0 = 3.5993e-04
Loss = 1.8750e-04, PNorm = 62.5842, GNorm = 0.2840, lr_0 = 3.5834e-04
Validation rmse logD = 0.577093
Validation R2 logD = 0.743173
Epoch 45
Train function
Loss = 1.2525e-04, PNorm = 62.5912, GNorm = 0.4798, lr_0 = 3.5660e-04
Loss = 1.4676e-04, PNorm = 62.5984, GNorm = 0.2934, lr_0 = 3.5502e-04
Loss = 1.4442e-04, PNorm = 62.6114, GNorm = 0.4072, lr_0 = 3.5345e-04
Loss = 1.7207e-04, PNorm = 62.6200, GNorm = 0.3725, lr_0 = 3.5188e-04
Loss = 1.7544e-04, PNorm = 62.6278, GNorm = 0.1629, lr_0 = 3.5033e-04
Loss = 1.3352e-04, PNorm = 62.6360, GNorm = 0.2221, lr_0 = 3.4878e-04
Validation rmse logD = 0.583866
Validation R2 logD = 0.737109
Epoch 46
Train function
Loss = 1.0932e-04, PNorm = 62.6424, GNorm = 0.6297, lr_0 = 3.4708e-04
Loss = 1.0832e-04, PNorm = 62.6477, GNorm = 0.2182, lr_0 = 3.4555e-04
Loss = 1.0367e-04, PNorm = 62.6550, GNorm = 0.1761, lr_0 = 3.4402e-04
Loss = 1.1125e-04, PNorm = 62.6620, GNorm = 0.2025, lr_0 = 3.4250e-04
Loss = 1.3656e-04, PNorm = 62.6717, GNorm = 0.4161, lr_0 = 3.4098e-04
Validation rmse logD = 0.581202
Validation R2 logD = 0.739503
Epoch 47
Train function
Loss = 1.1889e-04, PNorm = 62.6777, GNorm = 0.1640, lr_0 = 3.3932e-04
Loss = 1.3516e-04, PNorm = 62.6845, GNorm = 0.4297, lr_0 = 3.3782e-04
Loss = 1.0313e-04, PNorm = 62.6914, GNorm = 0.2799, lr_0 = 3.3633e-04
Loss = 1.1036e-04, PNorm = 62.6997, GNorm = 0.2209, lr_0 = 3.3484e-04
Loss = 1.1531e-04, PNorm = 62.7031, GNorm = 0.2193, lr_0 = 3.3336e-04
Validation rmse logD = 0.595517
Validation R2 logD = 0.726512
Epoch 48
Train function
Loss = 3.5845e-04, PNorm = 62.7108, GNorm = 1.7055, lr_0 = 3.3174e-04
Loss = 2.8368e-04, PNorm = 62.7206, GNorm = 0.4090, lr_0 = 3.3027e-04
Loss = 1.8559e-04, PNorm = 62.7347, GNorm = 0.5202, lr_0 = 3.2881e-04
Loss = 1.4640e-04, PNorm = 62.7436, GNorm = 0.3658, lr_0 = 3.2735e-04
Loss = 1.4235e-04, PNorm = 62.7536, GNorm = 0.2936, lr_0 = 3.2591e-04
Loss = 1.4068e-04, PNorm = 62.7625, GNorm = 0.2284, lr_0 = 3.2446e-04
Validation rmse logD = 0.579074
Validation R2 logD = 0.741407
Epoch 49
Train function
Loss = 1.1452e-04, PNorm = 62.7721, GNorm = 0.3892, lr_0 = 3.2289e-04
Loss = 1.1742e-04, PNorm = 62.7814, GNorm = 0.4142, lr_0 = 3.2146e-04
Loss = 1.4198e-04, PNorm = 62.7869, GNorm = 0.4665, lr_0 = 3.2004e-04
Loss = 1.2036e-04, PNorm = 62.7917, GNorm = 0.4943, lr_0 = 3.1862e-04
Loss = 1.1289e-04, PNorm = 62.7978, GNorm = 0.2376, lr_0 = 3.1721e-04
Validation rmse logD = 0.586255
Validation R2 logD = 0.734954
Epoch 50
Train function
Loss = 9.5705e-05, PNorm = 62.8038, GNorm = 0.3256, lr_0 = 3.1581e-04
Loss = 8.4417e-05, PNorm = 62.8094, GNorm = 0.2357, lr_0 = 3.1441e-04
Loss = 9.8095e-05, PNorm = 62.8137, GNorm = 0.3080, lr_0 = 3.1302e-04
Loss = 1.1380e-04, PNorm = 62.8203, GNorm = 0.4831, lr_0 = 3.1164e-04
Loss = 1.0523e-04, PNorm = 62.8288, GNorm = 0.2466, lr_0 = 3.1026e-04
Validation rmse logD = 0.582551
Validation R2 logD = 0.738292
Epoch 51
Train function
Loss = 9.6474e-05, PNorm = 62.8376, GNorm = 0.5917, lr_0 = 3.0875e-04
Loss = 1.0728e-04, PNorm = 62.8443, GNorm = 0.3274, lr_0 = 3.0738e-04
Loss = 1.3849e-04, PNorm = 62.8528, GNorm = 0.1592, lr_0 = 3.0602e-04
Loss = 1.0248e-04, PNorm = 62.8584, GNorm = 0.2465, lr_0 = 3.0467e-04
Loss = 8.9064e-05, PNorm = 62.8664, GNorm = 0.1209, lr_0 = 3.0332e-04
Loss = 7.9871e-05, PNorm = 62.8713, GNorm = 0.2507, lr_0 = 3.0198e-04
Validation rmse logD = 0.579137
Validation R2 logD = 0.741351
Epoch 52
Train function
Loss = 1.0853e-04, PNorm = 62.8775, GNorm = 0.2257, lr_0 = 3.0051e-04
Loss = 1.1584e-04, PNorm = 62.8851, GNorm = 0.2366, lr_0 = 2.9918e-04
Loss = 1.1170e-04, PNorm = 62.8901, GNorm = 0.1727, lr_0 = 2.9786e-04
Loss = 1.2712e-04, PNorm = 62.8975, GNorm = 0.1786, lr_0 = 2.9654e-04
Loss = 1.2566e-04, PNorm = 62.9051, GNorm = 0.2808, lr_0 = 2.9523e-04
Validation rmse logD = 0.581637
Validation R2 logD = 0.739112
Epoch 53
Train function
Loss = 6.9623e-05, PNorm = 62.9141, GNorm = 0.3113, lr_0 = 2.9379e-04
Loss = 9.4948e-05, PNorm = 62.9209, GNorm = 0.1295, lr_0 = 2.9249e-04
Loss = 8.3146e-05, PNorm = 62.9256, GNorm = 0.1903, lr_0 = 2.9120e-04
Loss = 8.3209e-05, PNorm = 62.9306, GNorm = 0.1474, lr_0 = 2.8991e-04
Loss = 9.2417e-05, PNorm = 62.9344, GNorm = 0.1637, lr_0 = 2.8863e-04
Validation rmse logD = 0.577727
Validation R2 logD = 0.742609
Epoch 54
Train function
Loss = 7.7011e-05, PNorm = 62.9380, GNorm = 0.3428, lr_0 = 2.8722e-04
Loss = 1.1339e-04, PNorm = 62.9431, GNorm = 0.1776, lr_0 = 2.8595e-04
Loss = 9.5656e-05, PNorm = 62.9474, GNorm = 0.2570, lr_0 = 2.8469e-04
Loss = 7.8480e-05, PNorm = 62.9524, GNorm = 0.4264, lr_0 = 2.8343e-04
Loss = 7.7241e-05, PNorm = 62.9594, GNorm = 0.1517, lr_0 = 2.8218e-04
Loss = 7.8200e-05, PNorm = 62.9648, GNorm = 0.2190, lr_0 = 2.8093e-04
Loss = 1.7729e-03, PNorm = 62.9658, GNorm = 0.8965, lr_0 = 2.8080e-04
Validation rmse logD = 0.577270
Validation R2 logD = 0.743016
Epoch 55
Train function
Loss = 8.7910e-05, PNorm = 62.9751, GNorm = 0.2218, lr_0 = 2.7956e-04
Loss = 6.9072e-05, PNorm = 62.9774, GNorm = 0.3727, lr_0 = 2.7832e-04
Loss = 6.7440e-05, PNorm = 62.9814, GNorm = 0.1665, lr_0 = 2.7709e-04
Loss = 6.9388e-05, PNorm = 62.9856, GNorm = 0.3336, lr_0 = 2.7587e-04
Loss = 6.3877e-05, PNorm = 62.9896, GNorm = 0.3613, lr_0 = 2.7465e-04
Validation rmse logD = 0.579922
Validation R2 logD = 0.740648
Epoch 56
Train function
Loss = 8.4599e-05, PNorm = 62.9938, GNorm = 0.1521, lr_0 = 2.7331e-04
Loss = 6.0633e-05, PNorm = 62.9973, GNorm = 0.1281, lr_0 = 2.7210e-04
Loss = 5.0827e-05, PNorm = 63.0023, GNorm = 0.1893, lr_0 = 2.7090e-04
Loss = 7.1797e-05, PNorm = 63.0082, GNorm = 0.4036, lr_0 = 2.6970e-04
Loss = 6.1374e-05, PNorm = 63.0117, GNorm = 0.2089, lr_0 = 2.6851e-04
Validation rmse logD = 0.582105
Validation R2 logD = 0.738692
Epoch 57
Train function
Loss = 8.0361e-05, PNorm = 63.0156, GNorm = 0.2459, lr_0 = 2.6720e-04
Loss = 7.6121e-05, PNorm = 63.0215, GNorm = 0.3506, lr_0 = 2.6602e-04
Loss = 7.6158e-05, PNorm = 63.0247, GNorm = 0.1704, lr_0 = 2.6484e-04
Loss = 4.9481e-05, PNorm = 63.0275, GNorm = 0.1131, lr_0 = 2.6367e-04
Loss = 6.7543e-05, PNorm = 63.0293, GNorm = 0.2809, lr_0 = 2.6250e-04
Validation rmse logD = 0.579986
Validation R2 logD = 0.740592
Epoch 58
Train function
Loss = 4.8158e-05, PNorm = 63.0345, GNorm = 0.3130, lr_0 = 2.6123e-04
Loss = 6.4445e-05, PNorm = 63.0378, GNorm = 0.3814, lr_0 = 2.6007e-04
Loss = 5.2956e-05, PNorm = 63.0408, GNorm = 0.1299, lr_0 = 2.5892e-04
Loss = 5.5006e-05, PNorm = 63.0430, GNorm = 0.1324, lr_0 = 2.5778e-04
Loss = 5.6235e-05, PNorm = 63.0468, GNorm = 0.3340, lr_0 = 2.5664e-04
Loss = 6.6790e-05, PNorm = 63.0516, GNorm = 0.3903, lr_0 = 2.5550e-04
Validation rmse logD = 0.581345
Validation R2 logD = 0.739375
Epoch 59
Train function
Loss = 5.3242e-05, PNorm = 63.0564, GNorm = 0.2774, lr_0 = 2.5426e-04
Loss = 5.1078e-05, PNorm = 63.0590, GNorm = 0.2107, lr_0 = 2.5313e-04
Loss = 5.1797e-05, PNorm = 63.0618, GNorm = 0.1480, lr_0 = 2.5201e-04
Loss = 5.5567e-05, PNorm = 63.0664, GNorm = 0.1806, lr_0 = 2.5090e-04
Loss = 5.5296e-05, PNorm = 63.0716, GNorm = 0.1217, lr_0 = 2.4979e-04
Validation rmse logD = 0.578320
Validation R2 logD = 0.742080
Epoch 60
Train function
Loss = 8.1170e-05, PNorm = 63.0751, GNorm = 0.4805, lr_0 = 2.4868e-04
Loss = 9.8514e-05, PNorm = 63.0813, GNorm = 0.2809, lr_0 = 2.4758e-04
Loss = 7.2843e-05, PNorm = 63.0843, GNorm = 0.2657, lr_0 = 2.4649e-04
Loss = 5.7350e-05, PNorm = 63.0904, GNorm = 0.1527, lr_0 = 2.4540e-04
Loss = 6.2463e-05, PNorm = 63.0965, GNorm = 0.3765, lr_0 = 2.4431e-04
Validation rmse logD = 0.581941
Validation R2 logD = 0.738839
Epoch 61
Train function
Loss = 7.7750e-05, PNorm = 63.0991, GNorm = 0.4216, lr_0 = 2.4313e-04
Loss = 5.9301e-05, PNorm = 63.1013, GNorm = 0.3227, lr_0 = 2.4205e-04
Loss = 6.4595e-05, PNorm = 63.1046, GNorm = 0.4927, lr_0 = 2.4098e-04
Loss = 4.9008e-05, PNorm = 63.1077, GNorm = 0.3877, lr_0 = 2.3991e-04
Loss = 5.0765e-05, PNorm = 63.1105, GNorm = 0.3572, lr_0 = 2.3885e-04
Loss = 5.5989e-05, PNorm = 63.1155, GNorm = 0.1400, lr_0 = 2.3780e-04
Validation rmse logD = 0.583111
Validation R2 logD = 0.737789
Epoch 62
Train function
Loss = 5.8141e-05, PNorm = 63.1196, GNorm = 0.4139, lr_0 = 2.3664e-04
Loss = 5.6728e-05, PNorm = 63.1239, GNorm = 0.3513, lr_0 = 2.3559e-04
Loss = 5.2790e-05, PNorm = 63.1275, GNorm = 0.2898, lr_0 = 2.3455e-04
Loss = 5.6194e-05, PNorm = 63.1311, GNorm = 0.1703, lr_0 = 2.3351e-04
Loss = 4.1641e-05, PNorm = 63.1335, GNorm = 0.0879, lr_0 = 2.3248e-04
Validation rmse logD = 0.578959
Validation R2 logD = 0.741509
Epoch 63
Train function
Loss = 6.2641e-05, PNorm = 63.1366, GNorm = 0.3943, lr_0 = 2.3135e-04
Loss = 5.6433e-05, PNorm = 63.1417, GNorm = 0.2903, lr_0 = 2.3033e-04
Loss = 5.8344e-05, PNorm = 63.1444, GNorm = 0.1560, lr_0 = 2.2931e-04
Loss = 4.8039e-05, PNorm = 63.1489, GNorm = 0.1577, lr_0 = 2.2829e-04
Loss = 4.7371e-05, PNorm = 63.1516, GNorm = 0.2282, lr_0 = 2.2728e-04
Validation rmse logD = 0.581012
Validation R2 logD = 0.739673
Epoch 64
Train function
Loss = 2.8814e-05, PNorm = 63.1534, GNorm = 0.1210, lr_0 = 2.2618e-04
Loss = 3.7274e-05, PNorm = 63.1556, GNorm = 0.0827, lr_0 = 2.2518e-04
Loss = 4.0789e-05, PNorm = 63.1588, GNorm = 0.2560, lr_0 = 2.2418e-04
Loss = 4.9844e-05, PNorm = 63.1636, GNorm = 0.2386, lr_0 = 2.2319e-04
Loss = 5.7573e-05, PNorm = 63.1647, GNorm = 0.4080, lr_0 = 2.2220e-04
Loss = 4.8043e-05, PNorm = 63.1681, GNorm = 0.3492, lr_0 = 2.2122e-04
Validation rmse logD = 0.583914
Validation R2 logD = 0.737066
Epoch 65
Train function
Loss = 5.4479e-05, PNorm = 63.1720, GNorm = 0.2608, lr_0 = 2.2014e-04
Loss = 5.0410e-05, PNorm = 63.1757, GNorm = 0.3558, lr_0 = 2.1917e-04
Loss = 3.7280e-05, PNorm = 63.1780, GNorm = 0.1350, lr_0 = 2.1820e-04
Loss = 4.3091e-05, PNorm = 63.1823, GNorm = 0.1254, lr_0 = 2.1723e-04
Loss = 3.7712e-05, PNorm = 63.1839, GNorm = 0.0929, lr_0 = 2.1627e-04
Validation rmse logD = 0.578140
Validation R2 logD = 0.742240
Epoch 66
Train function
Loss = 3.1316e-05, PNorm = 63.1870, GNorm = 0.1035, lr_0 = 2.1522e-04
Loss = 3.8328e-05, PNorm = 63.1897, GNorm = 0.1002, lr_0 = 2.1427e-04
Loss = 3.4189e-05, PNorm = 63.1921, GNorm = 0.1324, lr_0 = 2.1332e-04
Loss = 3.4683e-05, PNorm = 63.1951, GNorm = 0.0870, lr_0 = 2.1238e-04
Loss = 4.1602e-05, PNorm = 63.1980, GNorm = 0.3744, lr_0 = 2.1144e-04
Validation rmse logD = 0.582685
Validation R2 logD = 0.738171
Epoch 67
Train function
Loss = 4.4825e-05, PNorm = 63.2019, GNorm = 0.2003, lr_0 = 2.1041e-04
Loss = 3.4176e-05, PNorm = 63.2052, GNorm = 0.0655, lr_0 = 2.0948e-04
Loss = 2.5598e-05, PNorm = 63.2073, GNorm = 0.2667, lr_0 = 2.0855e-04
Loss = 2.9008e-05, PNorm = 63.2094, GNorm = 0.1744, lr_0 = 2.0763e-04
Loss = 2.9461e-05, PNorm = 63.2112, GNorm = 0.1846, lr_0 = 2.0671e-04
Loss = 3.4720e-05, PNorm = 63.2142, GNorm = 0.0865, lr_0 = 2.0580e-04
Loss = 2.3190e-04, PNorm = 63.2143, GNorm = 0.3757, lr_0 = 2.0571e-04
Validation rmse logD = 0.582914
Validation R2 logD = 0.737965
Epoch 68
Train function
Loss = 2.4730e-05, PNorm = 63.2168, GNorm = 0.0950, lr_0 = 2.0480e-04
Loss = 3.7107e-05, PNorm = 63.2192, GNorm = 0.1376, lr_0 = 2.0389e-04
Loss = 3.8098e-05, PNorm = 63.2205, GNorm = 0.1259, lr_0 = 2.0299e-04
Loss = 3.2019e-05, PNorm = 63.2218, GNorm = 0.1241, lr_0 = 2.0209e-04
Loss = 3.2625e-05, PNorm = 63.2234, GNorm = 0.0843, lr_0 = 2.0120e-04
Validation rmse logD = 0.581956
Validation R2 logD = 0.738826
Epoch 69
Train function
Loss = 2.0610e-05, PNorm = 63.2259, GNorm = 0.0738, lr_0 = 2.0022e-04
Loss = 2.4934e-05, PNorm = 63.2274, GNorm = 0.1061, lr_0 = 1.9933e-04
Loss = 2.5877e-05, PNorm = 63.2303, GNorm = 0.1029, lr_0 = 1.9845e-04
Loss = 2.8300e-05, PNorm = 63.2342, GNorm = 0.1696, lr_0 = 1.9757e-04
Loss = 2.5215e-05, PNorm = 63.2365, GNorm = 0.1416, lr_0 = 1.9670e-04
Validation rmse logD = 0.582607
Validation R2 logD = 0.738241
Epoch 70
Train function
Loss = 3.5117e-05, PNorm = 63.2376, GNorm = 0.1645, lr_0 = 1.9583e-04
Loss = 3.2779e-05, PNorm = 63.2383, GNorm = 0.1031, lr_0 = 1.9496e-04
Loss = 3.9541e-05, PNorm = 63.2424, GNorm = 0.1188, lr_0 = 1.9410e-04
Loss = 3.4600e-05, PNorm = 63.2456, GNorm = 0.0852, lr_0 = 1.9324e-04
Loss = 2.8842e-05, PNorm = 63.2485, GNorm = 0.1048, lr_0 = 1.9239e-04
Loss = 3.2413e-05, PNorm = 63.2510, GNorm = 0.2851, lr_0 = 1.9154e-04
Loss = 8.0753e-05, PNorm = 63.2509, GNorm = 0.1733, lr_0 = 1.9145e-04
Validation rmse logD = 0.583411
Validation R2 logD = 0.737518
Epoch 71
Train function
Loss = 3.8642e-05, PNorm = 63.2523, GNorm = 0.0857, lr_0 = 1.9060e-04
Loss = 2.6512e-05, PNorm = 63.2542, GNorm = 0.1567, lr_0 = 1.8976e-04
Loss = 3.5049e-05, PNorm = 63.2566, GNorm = 0.1866, lr_0 = 1.8892e-04
Loss = 2.5213e-05, PNorm = 63.2604, GNorm = 0.1120, lr_0 = 1.8809e-04
Loss = 2.6297e-05, PNorm = 63.2635, GNorm = 0.0972, lr_0 = 1.8725e-04
Validation rmse logD = 0.582465
Validation R2 logD = 0.738369
Epoch 72
Train function
Loss = 2.8529e-05, PNorm = 63.2658, GNorm = 0.1774, lr_0 = 1.8634e-04
Loss = 3.0611e-05, PNorm = 63.2671, GNorm = 0.1069, lr_0 = 1.8552e-04
Loss = 3.1684e-05, PNorm = 63.2698, GNorm = 0.1899, lr_0 = 1.8470e-04
Loss = 2.5882e-05, PNorm = 63.2731, GNorm = 0.1081, lr_0 = 1.8388e-04
Loss = 1.9625e-05, PNorm = 63.2761, GNorm = 0.0623, lr_0 = 1.8307e-04
Validation rmse logD = 0.581360
Validation R2 logD = 0.739361
Epoch 73
Train function
Loss = 1.4600e-05, PNorm = 63.2781, GNorm = 0.0978, lr_0 = 1.8218e-04
Loss = 1.7484e-05, PNorm = 63.2790, GNorm = 0.0761, lr_0 = 1.8137e-04
Loss = 1.7356e-05, PNorm = 63.2802, GNorm = 0.1070, lr_0 = 1.8057e-04
Loss = 2.7329e-05, PNorm = 63.2824, GNorm = 0.1080, lr_0 = 1.7977e-04
Loss = 2.7469e-05, PNorm = 63.2841, GNorm = 0.2357, lr_0 = 1.7897e-04
Validation rmse logD = 0.580603
Validation R2 logD = 0.740039
Epoch 74
Train function
Loss = 2.7073e-05, PNorm = 63.2866, GNorm = 0.0999, lr_0 = 1.7810e-04
Loss = 2.1695e-05, PNorm = 63.2897, GNorm = 0.1683, lr_0 = 1.7732e-04
Loss = 2.1969e-05, PNorm = 63.2907, GNorm = 0.1945, lr_0 = 1.7653e-04
Loss = 2.4911e-05, PNorm = 63.2926, GNorm = 0.2894, lr_0 = 1.7575e-04
Loss = 2.1432e-05, PNorm = 63.2948, GNorm = 0.1491, lr_0 = 1.7497e-04
Loss = 2.4847e-05, PNorm = 63.2957, GNorm = 0.1386, lr_0 = 1.7420e-04
Validation rmse logD = 0.580913
Validation R2 logD = 0.739762
Epoch 75
Train function
Loss = 2.8913e-05, PNorm = 63.2972, GNorm = 0.1197, lr_0 = 1.7335e-04
Loss = 2.3757e-05, PNorm = 63.2987, GNorm = 0.1227, lr_0 = 1.7259e-04
Loss = 2.4135e-05, PNorm = 63.3020, GNorm = 0.2168, lr_0 = 1.7182e-04
Loss = 2.9803e-05, PNorm = 63.3031, GNorm = 0.2388, lr_0 = 1.7106e-04
Loss = 2.6698e-05, PNorm = 63.3054, GNorm = 0.2770, lr_0 = 1.7031e-04
Validation rmse logD = 0.581932
Validation R2 logD = 0.738848
Epoch 76
Train function
Loss = 2.4784e-05, PNorm = 63.3096, GNorm = 0.1084, lr_0 = 1.6948e-04
Loss = 2.2538e-05, PNorm = 63.3122, GNorm = 0.2143, lr_0 = 1.6873e-04
Loss = 1.7853e-05, PNorm = 63.3142, GNorm = 0.0922, lr_0 = 1.6798e-04
Loss = 1.9507e-05, PNorm = 63.3156, GNorm = 0.2897, lr_0 = 1.6724e-04
Loss = 2.4543e-05, PNorm = 63.3163, GNorm = 0.2877, lr_0 = 1.6650e-04
Validation rmse logD = 0.581200
Validation R2 logD = 0.739505
Epoch 77
Train function
Loss = 2.8513e-05, PNorm = 63.3189, GNorm = 0.3354, lr_0 = 1.6569e-04
Loss = 4.5663e-05, PNorm = 63.3201, GNorm = 0.1860, lr_0 = 1.6496e-04
Loss = 3.3275e-05, PNorm = 63.3237, GNorm = 0.1988, lr_0 = 1.6423e-04
Loss = 2.7645e-05, PNorm = 63.3266, GNorm = 0.1022, lr_0 = 1.6350e-04
Loss = 2.2742e-05, PNorm = 63.3299, GNorm = 0.0734, lr_0 = 1.6278e-04
Loss = 2.3205e-05, PNorm = 63.3318, GNorm = 0.1548, lr_0 = 1.6206e-04
Validation rmse logD = 0.580734
Validation R2 logD = 0.739922
Epoch 78
Train function
Loss = 2.6563e-05, PNorm = 63.3319, GNorm = 0.0955, lr_0 = 1.6127e-04
Loss = 2.5713e-05, PNorm = 63.3324, GNorm = 0.2826, lr_0 = 1.6055e-04
Loss = 2.4593e-05, PNorm = 63.3341, GNorm = 0.2315, lr_0 = 1.5984e-04
Loss = 2.3869e-05, PNorm = 63.3371, GNorm = 0.1762, lr_0 = 1.5914e-04
Loss = 2.3016e-05, PNorm = 63.3380, GNorm = 0.0568, lr_0 = 1.5843e-04
Validation rmse logD = 0.580784
Validation R2 logD = 0.739877
Epoch 79
Train function
Loss = 2.0369e-05, PNorm = 63.3402, GNorm = 0.2876, lr_0 = 1.5766e-04
Loss = 2.2572e-05, PNorm = 63.3424, GNorm = 0.2427, lr_0 = 1.5697e-04
Loss = 2.3168e-05, PNorm = 63.3438, GNorm = 0.2003, lr_0 = 1.5627e-04
Loss = 1.7698e-05, PNorm = 63.3443, GNorm = 0.0892, lr_0 = 1.5558e-04
Loss = 2.4999e-05, PNorm = 63.3459, GNorm = 0.1438, lr_0 = 1.5489e-04
Validation rmse logD = 0.582340
Validation R2 logD = 0.738482
Epoch 80
Train function
Loss = 2.1689e-05, PNorm = 63.3484, GNorm = 0.1747, lr_0 = 1.5421e-04
Loss = 2.2348e-05, PNorm = 63.3501, GNorm = 0.0886, lr_0 = 1.5352e-04
Loss = 1.4004e-05, PNorm = 63.3507, GNorm = 0.1003, lr_0 = 1.5284e-04
Loss = 2.2640e-05, PNorm = 63.3527, GNorm = 0.2585, lr_0 = 1.5217e-04
Loss = 1.9869e-05, PNorm = 63.3549, GNorm = 0.2535, lr_0 = 1.5150e-04
Loss = 2.0343e-05, PNorm = 63.3565, GNorm = 0.0741, lr_0 = 1.5083e-04
Validation rmse logD = 0.581747
Validation R2 logD = 0.739014
Epoch 81
Train function
Loss = 2.2417e-05, PNorm = 63.3586, GNorm = 0.1508, lr_0 = 1.5009e-04
Loss = 1.7574e-05, PNorm = 63.3593, GNorm = 0.0808, lr_0 = 1.4943e-04
Loss = 1.3693e-05, PNorm = 63.3608, GNorm = 0.0970, lr_0 = 1.4877e-04
Loss = 1.7537e-05, PNorm = 63.3622, GNorm = 0.1615, lr_0 = 1.4811e-04
Loss = 1.7597e-05, PNorm = 63.3630, GNorm = 0.1211, lr_0 = 1.4745e-04
Validation rmse logD = 0.581389
Validation R2 logD = 0.739334
Epoch 82
Train function
Loss = 1.4903e-05, PNorm = 63.3647, GNorm = 0.0890, lr_0 = 1.4674e-04
Loss = 2.0347e-05, PNorm = 63.3660, GNorm = 0.1095, lr_0 = 1.4609e-04
Loss = 2.0632e-05, PNorm = 63.3668, GNorm = 0.1983, lr_0 = 1.4544e-04
Loss = 2.7675e-05, PNorm = 63.3686, GNorm = 0.1749, lr_0 = 1.4480e-04
Loss = 1.6881e-05, PNorm = 63.3699, GNorm = 0.2190, lr_0 = 1.4416e-04
Validation rmse logD = 0.581815
Validation R2 logD = 0.738952
Epoch 83
Train function
Loss = 1.3658e-05, PNorm = 63.3720, GNorm = 0.2124, lr_0 = 1.4346e-04
Loss = 1.8245e-05, PNorm = 63.3739, GNorm = 0.1359, lr_0 = 1.4282e-04
Loss = 1.5781e-05, PNorm = 63.3755, GNorm = 0.1059, lr_0 = 1.4219e-04
Loss = 1.3435e-05, PNorm = 63.3772, GNorm = 0.1672, lr_0 = 1.4156e-04
Loss = 1.2811e-05, PNorm = 63.3786, GNorm = 0.0806, lr_0 = 1.4093e-04
Loss = 2.0380e-05, PNorm = 63.3798, GNorm = 0.0640, lr_0 = 1.4031e-04
Loss = 9.0125e-05, PNorm = 63.3801, GNorm = 0.2215, lr_0 = 1.4025e-04
Validation rmse logD = 0.581327
Validation R2 logD = 0.739390
Epoch 84
Train function
Loss = 1.3911e-05, PNorm = 63.3816, GNorm = 0.0650, lr_0 = 1.3963e-04
Loss = 1.1436e-05, PNorm = 63.3827, GNorm = 0.1027, lr_0 = 1.3901e-04
Loss = 1.1798e-05, PNorm = 63.3847, GNorm = 0.0977, lr_0 = 1.3840e-04
Loss = 1.7622e-05, PNorm = 63.3855, GNorm = 0.0813, lr_0 = 1.3778e-04
Loss = 1.7110e-05, PNorm = 63.3864, GNorm = 0.1609, lr_0 = 1.3717e-04
Validation rmse logD = 0.586314
Validation R2 logD = 0.734900
Epoch 85
Train function
Loss = 1.9445e-05, PNorm = 63.3870, GNorm = 0.2384, lr_0 = 1.3651e-04
Loss = 1.7002e-05, PNorm = 63.3881, GNorm = 0.0937, lr_0 = 1.3590e-04
Loss = 1.3849e-05, PNorm = 63.3902, GNorm = 0.0949, lr_0 = 1.3530e-04
Loss = 1.6346e-05, PNorm = 63.3914, GNorm = 0.2526, lr_0 = 1.3470e-04
Loss = 1.6346e-05, PNorm = 63.3931, GNorm = 0.1387, lr_0 = 1.3411e-04
Validation rmse logD = 0.582371
Validation R2 logD = 0.738453
Epoch 86
Train function
Loss = 1.4836e-05, PNorm = 63.3935, GNorm = 0.1071, lr_0 = 1.3346e-04
Loss = 2.4374e-05, PNorm = 63.3943, GNorm = 0.1427, lr_0 = 1.3287e-04
Loss = 2.1937e-05, PNorm = 63.3971, GNorm = 0.1597, lr_0 = 1.3228e-04
Loss = 1.7932e-05, PNorm = 63.3981, GNorm = 0.1523, lr_0 = 1.3169e-04
Loss = 1.5586e-05, PNorm = 63.3997, GNorm = 0.1341, lr_0 = 1.3111e-04
Validation rmse logD = 0.582657
Validation R2 logD = 0.738197
Epoch 87
Train function
Loss = 8.2147e-06, PNorm = 63.4016, GNorm = 0.0557, lr_0 = 1.3047e-04
Loss = 2.1806e-05, PNorm = 63.4028, GNorm = 0.3920, lr_0 = 1.2990e-04
Loss = 2.6473e-05, PNorm = 63.4056, GNorm = 0.2019, lr_0 = 1.2932e-04
Loss = 3.1787e-05, PNorm = 63.4058, GNorm = 0.3343, lr_0 = 1.2875e-04
Loss = 2.5211e-05, PNorm = 63.4078, GNorm = 0.2867, lr_0 = 1.2818e-04
Loss = 2.1568e-05, PNorm = 63.4089, GNorm = 0.1771, lr_0 = 1.2761e-04
Validation rmse logD = 0.582579
Validation R2 logD = 0.738266
Epoch 88
Train function
Loss = 2.7069e-05, PNorm = 63.4104, GNorm = 0.2840, lr_0 = 1.2699e-04
Loss = 2.8019e-05, PNorm = 63.4124, GNorm = 0.1014, lr_0 = 1.2643e-04
Loss = 2.1827e-05, PNorm = 63.4131, GNorm = 0.1401, lr_0 = 1.2587e-04
Loss = 1.5745e-05, PNorm = 63.4138, GNorm = 0.1501, lr_0 = 1.2531e-04
Loss = 2.1916e-05, PNorm = 63.4160, GNorm = 0.1760, lr_0 = 1.2476e-04
Validation rmse logD = 0.584301
Validation R2 logD = 0.736717
Epoch 89
Train function
Loss = 1.5851e-05, PNorm = 63.4165, GNorm = 0.1578, lr_0 = 1.2415e-04
Loss = 1.9609e-05, PNorm = 63.4180, GNorm = 0.1658, lr_0 = 1.2360e-04
Loss = 1.3539e-05, PNorm = 63.4190, GNorm = 0.0802, lr_0 = 1.2306e-04
Loss = 1.3763e-05, PNorm = 63.4203, GNorm = 0.0780, lr_0 = 1.2251e-04
Loss = 1.2167e-05, PNorm = 63.4212, GNorm = 0.0768, lr_0 = 1.2197e-04
Validation rmse logD = 0.582565
Validation R2 logD = 0.738280
Epoch 90
Train function
Loss = 2.5372e-05, PNorm = 63.4228, GNorm = 0.1376, lr_0 = 1.2143e-04
Loss = 1.3661e-05, PNorm = 63.4249, GNorm = 0.1032, lr_0 = 1.2089e-04
Loss = 1.3856e-05, PNorm = 63.4259, GNorm = 0.1520, lr_0 = 1.2036e-04
Loss = 1.0696e-05, PNorm = 63.4263, GNorm = 0.0528, lr_0 = 1.1983e-04
Loss = 9.5364e-06, PNorm = 63.4274, GNorm = 0.0695, lr_0 = 1.1930e-04
Loss = 1.4399e-05, PNorm = 63.4296, GNorm = 0.1665, lr_0 = 1.1877e-04
Validation rmse logD = 0.583373
Validation R2 logD = 0.737553
Epoch 91
Train function
Loss = 1.4996e-05, PNorm = 63.4298, GNorm = 0.0559, lr_0 = 1.1819e-04
Loss = 1.1051e-05, PNorm = 63.4313, GNorm = 0.1314, lr_0 = 1.1767e-04
Loss = 1.4978e-05, PNorm = 63.4321, GNorm = 0.1402, lr_0 = 1.1715e-04
Loss = 1.2983e-05, PNorm = 63.4335, GNorm = 0.1901, lr_0 = 1.1663e-04
Loss = 1.1799e-05, PNorm = 63.4343, GNorm = 0.1115, lr_0 = 1.1611e-04
Validation rmse logD = 0.581765
Validation R2 logD = 0.738998
Epoch 92
Train function
Loss = 8.9032e-06, PNorm = 63.4346, GNorm = 0.0815, lr_0 = 1.1555e-04
Loss = 1.4789e-05, PNorm = 63.4361, GNorm = 0.1003, lr_0 = 1.1504e-04
Loss = 1.5524e-05, PNorm = 63.4370, GNorm = 0.1430, lr_0 = 1.1453e-04
Loss = 1.3400e-05, PNorm = 63.4378, GNorm = 0.0361, lr_0 = 1.1402e-04
Loss = 1.0029e-05, PNorm = 63.4394, GNorm = 0.0412, lr_0 = 1.1352e-04
Validation rmse logD = 0.582723
Validation R2 logD = 0.738138
Epoch 93
Train function
Loss = 6.4812e-06, PNorm = 63.4404, GNorm = 0.0668, lr_0 = 1.1297e-04
Loss = 7.7092e-06, PNorm = 63.4413, GNorm = 0.0580, lr_0 = 1.1247e-04
Loss = 7.1179e-06, PNorm = 63.4419, GNorm = 0.0803, lr_0 = 1.1197e-04
Loss = 1.0064e-05, PNorm = 63.4424, GNorm = 0.1488, lr_0 = 1.1147e-04
Loss = 1.4363e-05, PNorm = 63.4433, GNorm = 0.2186, lr_0 = 1.1098e-04
Loss = 1.3969e-05, PNorm = 63.4447, GNorm = 0.1031, lr_0 = 1.1049e-04
Validation rmse logD = 0.584169
Validation R2 logD = 0.736836
Epoch 94
Train function
Loss = 1.3688e-05, PNorm = 63.4461, GNorm = 0.0582, lr_0 = 1.0995e-04
Loss = 1.3262e-05, PNorm = 63.4468, GNorm = 0.0871, lr_0 = 1.0947e-04
Loss = 1.2914e-05, PNorm = 63.4484, GNorm = 0.1439, lr_0 = 1.0898e-04
Loss = 1.6238e-05, PNorm = 63.4488, GNorm = 0.1856, lr_0 = 1.0850e-04
Loss = 1.6611e-05, PNorm = 63.4499, GNorm = 0.1838, lr_0 = 1.0802e-04
Validation rmse logD = 0.585718
Validation R2 logD = 0.735438
Epoch 95
Train function
Loss = 1.4444e-05, PNorm = 63.4507, GNorm = 0.0987, lr_0 = 1.0749e-04
Loss = 1.0896e-05, PNorm = 63.4520, GNorm = 0.0857, lr_0 = 1.0702e-04
Loss = 1.3533e-05, PNorm = 63.4521, GNorm = 0.1018, lr_0 = 1.0654e-04
Loss = 1.1967e-05, PNorm = 63.4529, GNorm = 0.1338, lr_0 = 1.0607e-04
Loss = 1.4887e-05, PNorm = 63.4543, GNorm = 0.1271, lr_0 = 1.0560e-04
Validation rmse logD = 0.584254
Validation R2 logD = 0.736760
Epoch 96
Train function
Loss = 1.1171e-05, PNorm = 63.4556, GNorm = 0.0631, lr_0 = 1.0509e-04
Loss = 1.2215e-05, PNorm = 63.4563, GNorm = 0.0779, lr_0 = 1.0463e-04
Loss = 1.0699e-05, PNorm = 63.4571, GNorm = 0.1695, lr_0 = 1.0416e-04
Loss = 1.0733e-05, PNorm = 63.4572, GNorm = 0.1029, lr_0 = 1.0370e-04
Loss = 1.0714e-05, PNorm = 63.4579, GNorm = 0.1492, lr_0 = 1.0324e-04
Loss = 9.2084e-06, PNorm = 63.4593, GNorm = 0.0551, lr_0 = 1.0279e-04
Loss = 4.2658e-06, PNorm = 63.4594, GNorm = 0.0519, lr_0 = 1.0274e-04
Validation rmse logD = 0.583991
Validation R2 logD = 0.736996
Epoch 97
Train function
Loss = 7.2801e-06, PNorm = 63.4604, GNorm = 0.0473, lr_0 = 1.0229e-04
Loss = 8.8488e-06, PNorm = 63.4612, GNorm = 0.1107, lr_0 = 1.0183e-04
Loss = 9.0139e-06, PNorm = 63.4623, GNorm = 0.0611, lr_0 = 1.0138e-04
Loss = 1.2008e-05, PNorm = 63.4639, GNorm = 0.1652, lr_0 = 1.0094e-04
Loss = 8.2698e-06, PNorm = 63.4643, GNorm = 0.0647, lr_0 = 1.0049e-04
Validation rmse logD = 0.583908
Validation R2 logD = 0.737071
Epoch 98
Train function
Loss = 5.1932e-06, PNorm = 63.4649, GNorm = 0.0438, lr_0 = 1.0000e-04
Loss = 5.9485e-06, PNorm = 63.4657, GNorm = 0.0994, lr_0 = 1.0000e-04
Loss = 9.7818e-06, PNorm = 63.4672, GNorm = 0.2103, lr_0 = 1.0000e-04
Loss = 1.0516e-05, PNorm = 63.4685, GNorm = 0.0696, lr_0 = 1.0000e-04
Loss = 9.0917e-06, PNorm = 63.4686, GNorm = 0.0515, lr_0 = 1.0000e-04
Validation rmse logD = 0.581920
Validation R2 logD = 0.738859
Epoch 99
Train function
Loss = 5.6195e-06, PNorm = 63.4691, GNorm = 0.1308, lr_0 = 1.0000e-04
Loss = 8.2597e-06, PNorm = 63.4702, GNorm = 0.1764, lr_0 = 1.0000e-04
Loss = 1.4646e-05, PNorm = 63.4711, GNorm = 0.1942, lr_0 = 1.0000e-04
Loss = 7.6897e-06, PNorm = 63.4716, GNorm = 0.0636, lr_0 = 1.0000e-04
Loss = 8.6746e-06, PNorm = 63.4725, GNorm = 0.0659, lr_0 = 1.0000e-04
Loss = 1.1047e-05, PNorm = 63.4730, GNorm = 0.2622, lr_0 = 1.0000e-04
Validation rmse logD = 0.581975
Validation R2 logD = 0.738809
Model 0 best validation rmse = 0.573013 on epoch 35
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.562715
Model 0 test R2 logD = 0.780999
Ensemble test rmse  logD= 0.562715
Ensemble test R2  logD= 0.780999
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_304/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=895, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,222,401
Moving model to cuda
Epoch 0
Train function
Loss = 2.0395e-02, PNorm = 52.4950, GNorm = 12.1551, lr_0 = 1.9340e-04
Loss = 1.9329e-02, PNorm = 52.5025, GNorm = 5.1534, lr_0 = 2.7830e-04
Loss = 1.8229e-02, PNorm = 52.5150, GNorm = 3.6001, lr_0 = 3.6321e-04
Loss = 1.6606e-02, PNorm = 52.5358, GNorm = 4.7521, lr_0 = 4.4811e-04
Loss = 1.5462e-02, PNorm = 52.5591, GNorm = 2.3740, lr_0 = 5.3302e-04
Validation rmse logD = 1.090689
Validation R2 logD = 0.215018
Epoch 1
Train function
Loss = 1.7910e-02, PNorm = 52.6009, GNorm = 2.3148, lr_0 = 6.2642e-04
Loss = 1.5794e-02, PNorm = 52.6502, GNorm = 1.3195, lr_0 = 7.1132e-04
Loss = 1.2308e-02, PNorm = 52.7138, GNorm = 1.1178, lr_0 = 7.9623e-04
Loss = 1.3657e-02, PNorm = 52.7893, GNorm = 6.0404, lr_0 = 8.8113e-04
Loss = 1.6874e-02, PNorm = 52.8771, GNorm = 4.8387, lr_0 = 9.6604e-04
Validation rmse logD = 1.025691
Validation R2 logD = 0.305790
Epoch 2
Train function
Loss = 1.4034e-02, PNorm = 53.0043, GNorm = 1.1515, lr_0 = 9.9690e-04
Loss = 1.1511e-02, PNorm = 53.1215, GNorm = 1.3871, lr_0 = 9.9249e-04
Loss = 1.2975e-02, PNorm = 53.2362, GNorm = 3.5506, lr_0 = 9.8810e-04
Loss = 1.1773e-02, PNorm = 53.3507, GNorm = 2.8371, lr_0 = 9.8373e-04
Loss = 1.2079e-02, PNorm = 53.4908, GNorm = 4.2207, lr_0 = 9.7938e-04
Validation rmse logD = 0.981519
Validation R2 logD = 0.364297
Epoch 3
Train function
Loss = 1.1537e-02, PNorm = 53.6183, GNorm = 4.5932, lr_0 = 9.7462e-04
Loss = 1.0650e-02, PNorm = 53.7048, GNorm = 3.6098, lr_0 = 9.7030e-04
Loss = 1.0953e-02, PNorm = 53.8106, GNorm = 5.4157, lr_0 = 9.6601e-04
Loss = 9.0278e-03, PNorm = 53.9211, GNorm = 1.8672, lr_0 = 9.6174e-04
Loss = 9.0261e-03, PNorm = 54.0337, GNorm = 2.1343, lr_0 = 9.5749e-04
Loss = 9.7562e-03, PNorm = 54.1400, GNorm = 0.8818, lr_0 = 9.5325e-04
Validation rmse logD = 0.856028
Validation R2 logD = 0.516459
Epoch 4
Train function
Loss = 8.9668e-03, PNorm = 54.2467, GNorm = 1.8041, lr_0 = 9.4861e-04
Loss = 7.4660e-03, PNorm = 54.3416, GNorm = 3.5078, lr_0 = 9.4442e-04
Loss = 7.2622e-03, PNorm = 54.4584, GNorm = 1.2066, lr_0 = 9.4024e-04
Loss = 7.2263e-03, PNorm = 54.5557, GNorm = 1.4069, lr_0 = 9.3608e-04
Loss = 7.1556e-03, PNorm = 54.6559, GNorm = 1.3160, lr_0 = 9.3194e-04
Validation rmse logD = 0.801518
Validation R2 logD = 0.576080
Epoch 5
Train function
Loss = 7.7459e-03, PNorm = 54.7738, GNorm = 2.1065, lr_0 = 9.2741e-04
Loss = 7.3843e-03, PNorm = 54.8950, GNorm = 1.3757, lr_0 = 9.2330e-04
Loss = 7.4954e-03, PNorm = 55.0012, GNorm = 1.5681, lr_0 = 9.1922e-04
Loss = 5.7244e-03, PNorm = 55.1070, GNorm = 1.0001, lr_0 = 9.1515e-04
Loss = 6.6205e-03, PNorm = 55.1943, GNorm = 1.7330, lr_0 = 9.1111e-04
Validation rmse logD = 0.714685
Validation R2 logD = 0.662956
Epoch 6
Train function
Loss = 5.8926e-03, PNorm = 55.2985, GNorm = 1.9263, lr_0 = 9.0667e-04
Loss = 6.4023e-03, PNorm = 55.4289, GNorm = 3.9854, lr_0 = 9.0266e-04
Loss = 7.0957e-03, PNorm = 55.5398, GNorm = 3.0497, lr_0 = 8.9867e-04
Loss = 4.6329e-03, PNorm = 55.6691, GNorm = 0.6568, lr_0 = 8.9469e-04
Loss = 5.7685e-03, PNorm = 55.7662, GNorm = 1.7678, lr_0 = 8.9074e-04
Loss = 6.5316e-03, PNorm = 55.8401, GNorm = 1.4212, lr_0 = 8.8680e-04
Validation rmse logD = 0.694164
Validation R2 logD = 0.682034
Epoch 7
Train function
Loss = 4.6030e-03, PNorm = 55.9285, GNorm = 0.8117, lr_0 = 8.8248e-04
Loss = 4.8894e-03, PNorm = 56.0270, GNorm = 0.9407, lr_0 = 8.7858e-04
Loss = 5.3816e-03, PNorm = 56.1122, GNorm = 0.7947, lr_0 = 8.7469e-04
Loss = 4.7181e-03, PNorm = 56.1997, GNorm = 1.2198, lr_0 = 8.7082e-04
Loss = 4.8744e-03, PNorm = 56.2878, GNorm = 2.5738, lr_0 = 8.6697e-04
Validation rmse logD = 0.776142
Validation R2 logD = 0.602498
Epoch 8
Train function
Loss = 5.6122e-03, PNorm = 56.3836, GNorm = 2.4598, lr_0 = 8.6276e-04
Loss = 4.1997e-03, PNorm = 56.4813, GNorm = 0.7160, lr_0 = 8.5894e-04
Loss = 4.0294e-03, PNorm = 56.5621, GNorm = 1.1835, lr_0 = 8.5514e-04
Loss = 4.2538e-03, PNorm = 56.6448, GNorm = 1.1414, lr_0 = 8.5136e-04
Loss = 4.8144e-03, PNorm = 56.7360, GNorm = 1.0942, lr_0 = 8.4759e-04
Validation rmse logD = 0.664909
Validation R2 logD = 0.708270
Epoch 9
Train function
Loss = 2.5283e-03, PNorm = 56.8222, GNorm = 1.2111, lr_0 = 8.4384e-04
Loss = 3.4477e-03, PNorm = 56.9038, GNorm = 1.0633, lr_0 = 8.4011e-04
Loss = 3.2459e-03, PNorm = 56.9996, GNorm = 0.6082, lr_0 = 8.3639e-04
Loss = 3.7878e-03, PNorm = 57.0822, GNorm = 0.8088, lr_0 = 8.3269e-04
Loss = 4.1982e-03, PNorm = 57.1521, GNorm = 0.9997, lr_0 = 8.2901e-04
Loss = 3.7714e-03, PNorm = 57.2288, GNorm = 1.5620, lr_0 = 8.2534e-04
Validation rmse logD = 0.642140
Validation R2 logD = 0.727907
Epoch 10
Train function
Loss = 3.6717e-03, PNorm = 57.3252, GNorm = 1.2480, lr_0 = 8.2133e-04
Loss = 3.1273e-03, PNorm = 57.4164, GNorm = 1.2694, lr_0 = 8.1770e-04
Loss = 3.3213e-03, PNorm = 57.5045, GNorm = 0.9297, lr_0 = 8.1408e-04
Loss = 2.7115e-03, PNorm = 57.5741, GNorm = 0.6920, lr_0 = 8.1048e-04
Loss = 2.9761e-03, PNorm = 57.6444, GNorm = 1.2622, lr_0 = 8.0689e-04
Validation rmse logD = 0.677790
Validation R2 logD = 0.696857
Epoch 11
Train function
Loss = 4.8641e-03, PNorm = 57.7597, GNorm = 2.2564, lr_0 = 8.0297e-04
Loss = 3.2615e-03, PNorm = 57.8824, GNorm = 1.4980, lr_0 = 7.9942e-04
Loss = 3.2578e-03, PNorm = 57.9943, GNorm = 0.7378, lr_0 = 7.9588e-04
Loss = 3.7907e-03, PNorm = 58.1090, GNorm = 0.8345, lr_0 = 7.9236e-04
Loss = 2.9557e-03, PNorm = 58.2124, GNorm = 1.5225, lr_0 = 7.8885e-04
Validation rmse logD = 0.638351
Validation R2 logD = 0.731109
Epoch 12
Train function
Loss = 2.6803e-03, PNorm = 58.3044, GNorm = 1.0038, lr_0 = 7.8502e-04
Loss = 3.0804e-03, PNorm = 58.3774, GNorm = 1.0758, lr_0 = 7.8154e-04
Loss = 2.7986e-03, PNorm = 58.4532, GNorm = 2.0975, lr_0 = 7.7809e-04
Loss = 3.3195e-03, PNorm = 58.5232, GNorm = 1.0372, lr_0 = 7.7465e-04
Loss = 2.8500e-03, PNorm = 58.6048, GNorm = 1.1943, lr_0 = 7.7122e-04
Loss = 2.5704e-03, PNorm = 58.6851, GNorm = 1.0445, lr_0 = 7.6781e-04
Loss = 2.3849e-02, PNorm = 58.6936, GNorm = 2.9489, lr_0 = 7.6747e-04
Validation rmse logD = 0.662154
Validation R2 logD = 0.710682
Epoch 13
Train function
Loss = 2.5251e-03, PNorm = 58.7503, GNorm = 0.9077, lr_0 = 7.6407e-04
Loss = 2.2104e-03, PNorm = 58.8237, GNorm = 0.9414, lr_0 = 7.6069e-04
Loss = 2.3447e-03, PNorm = 58.8817, GNorm = 1.2272, lr_0 = 7.5733e-04
Loss = 2.3418e-03, PNorm = 58.9461, GNorm = 0.7609, lr_0 = 7.5398e-04
Loss = 2.3319e-03, PNorm = 59.0091, GNorm = 1.0271, lr_0 = 7.5064e-04
Validation rmse logD = 0.628536
Validation R2 logD = 0.739314
Epoch 14
Train function
Loss = 3.2082e-03, PNorm = 59.0866, GNorm = 2.2853, lr_0 = 7.4699e-04
Loss = 2.8480e-03, PNorm = 59.1696, GNorm = 2.7710, lr_0 = 7.4369e-04
Loss = 2.5391e-03, PNorm = 59.2412, GNorm = 1.9364, lr_0 = 7.4040e-04
Loss = 2.1820e-03, PNorm = 59.3110, GNorm = 0.7519, lr_0 = 7.3712e-04
Loss = 2.0785e-03, PNorm = 59.3722, GNorm = 0.8686, lr_0 = 7.3386e-04
Validation rmse logD = 0.605013
Validation R2 logD = 0.758461
Epoch 15
Train function
Loss = 1.8378e-03, PNorm = 59.4328, GNorm = 1.1080, lr_0 = 7.3029e-04
Loss = 1.6689e-03, PNorm = 59.4809, GNorm = 0.6000, lr_0 = 7.2706e-04
Loss = 1.4967e-03, PNorm = 59.5213, GNorm = 1.2712, lr_0 = 7.2385e-04
Loss = 1.7792e-03, PNorm = 59.5734, GNorm = 1.6001, lr_0 = 7.2064e-04
Loss = 1.6669e-03, PNorm = 59.6170, GNorm = 0.5872, lr_0 = 7.1746e-04
Validation rmse logD = 0.593026
Validation R2 logD = 0.767937
Epoch 16
Train function
Loss = 7.0861e-04, PNorm = 59.6715, GNorm = 0.6658, lr_0 = 7.1397e-04
Loss = 1.2575e-03, PNorm = 59.7146, GNorm = 0.5897, lr_0 = 7.1081e-04
Loss = 1.3163e-03, PNorm = 59.7571, GNorm = 0.9823, lr_0 = 7.0766e-04
Loss = 1.5945e-03, PNorm = 59.8008, GNorm = 0.6331, lr_0 = 7.0453e-04
Loss = 1.7216e-03, PNorm = 59.8355, GNorm = 1.0912, lr_0 = 7.0142e-04
Loss = 1.8085e-03, PNorm = 59.8828, GNorm = 0.6392, lr_0 = 6.9831e-04
Validation rmse logD = 0.596581
Validation R2 logD = 0.765147
Epoch 17
Train function
Loss = 1.2957e-03, PNorm = 59.9487, GNorm = 0.7802, lr_0 = 6.9523e-04
Loss = 1.4204e-03, PNorm = 59.9917, GNorm = 0.8298, lr_0 = 6.9215e-04
Loss = 1.3675e-03, PNorm = 60.0295, GNorm = 0.5807, lr_0 = 6.8909e-04
Loss = 1.3540e-03, PNorm = 60.0857, GNorm = 0.6086, lr_0 = 6.8604e-04
Loss = 1.5933e-03, PNorm = 60.1321, GNorm = 1.3618, lr_0 = 6.8301e-04
Validation rmse logD = 0.621117
Validation R2 logD = 0.745432
Epoch 18
Train function
Loss = 1.4873e-03, PNorm = 60.1847, GNorm = 0.6809, lr_0 = 6.7968e-04
Loss = 1.2647e-03, PNorm = 60.2431, GNorm = 0.5557, lr_0 = 6.7668e-04
Loss = 9.9198e-04, PNorm = 60.2881, GNorm = 0.8453, lr_0 = 6.7368e-04
Loss = 1.2610e-03, PNorm = 60.3326, GNorm = 0.6231, lr_0 = 6.7070e-04
Loss = 1.1570e-03, PNorm = 60.3732, GNorm = 0.6226, lr_0 = 6.6774e-04
Validation rmse logD = 0.587222
Validation R2 logD = 0.772458
Epoch 19
Train function
Loss = 6.2095e-04, PNorm = 60.4090, GNorm = 0.4526, lr_0 = 6.6449e-04
Loss = 9.3265e-04, PNorm = 60.4439, GNorm = 0.9835, lr_0 = 6.6155e-04
Loss = 9.8595e-04, PNorm = 60.4840, GNorm = 0.5950, lr_0 = 6.5862e-04
Loss = 9.6236e-04, PNorm = 60.5178, GNorm = 0.5869, lr_0 = 6.5571e-04
Loss = 1.1425e-03, PNorm = 60.5488, GNorm = 0.8540, lr_0 = 6.5281e-04
Loss = 1.0375e-03, PNorm = 60.5839, GNorm = 0.3640, lr_0 = 6.4992e-04
Validation rmse logD = 0.586023
Validation R2 logD = 0.773386
Epoch 20
Train function
Loss = 8.5611e-04, PNorm = 60.6227, GNorm = 0.8122, lr_0 = 6.4676e-04
Loss = 9.1662e-04, PNorm = 60.6598, GNorm = 1.6425, lr_0 = 6.4390e-04
Loss = 9.6765e-04, PNorm = 60.6958, GNorm = 1.4284, lr_0 = 6.4105e-04
Loss = 9.3166e-04, PNorm = 60.7337, GNorm = 0.5081, lr_0 = 6.3822e-04
Loss = 1.0727e-03, PNorm = 60.7774, GNorm = 2.3791, lr_0 = 6.3539e-04
Validation rmse logD = 0.606690
Validation R2 logD = 0.757120
Epoch 21
Train function
Loss = 8.4585e-04, PNorm = 60.8103, GNorm = 0.8457, lr_0 = 6.3230e-04
Loss = 9.2123e-04, PNorm = 60.8422, GNorm = 0.7119, lr_0 = 6.2950e-04
Loss = 8.1995e-04, PNorm = 60.8730, GNorm = 0.6286, lr_0 = 6.2672e-04
Loss = 7.9676e-04, PNorm = 60.9022, GNorm = 0.5930, lr_0 = 6.2395e-04
Loss = 7.2609e-04, PNorm = 60.9298, GNorm = 0.4207, lr_0 = 6.2119e-04
Validation rmse logD = 0.616445
Validation R2 logD = 0.749247
Epoch 22
Train function
Loss = 1.2229e-03, PNorm = 60.9555, GNorm = 2.3287, lr_0 = 6.1817e-04
Loss = 8.7175e-04, PNorm = 60.9906, GNorm = 1.7471, lr_0 = 6.1543e-04
Loss = 7.1576e-04, PNorm = 61.0220, GNorm = 0.5069, lr_0 = 6.1271e-04
Loss = 7.1345e-04, PNorm = 61.0446, GNorm = 0.6766, lr_0 = 6.1000e-04
Loss = 7.5764e-04, PNorm = 61.0656, GNorm = 1.0292, lr_0 = 6.0730e-04
Loss = 7.9871e-04, PNorm = 61.1009, GNorm = 1.7880, lr_0 = 6.0461e-04
Validation rmse logD = 0.608321
Validation R2 logD = 0.755813
Epoch 23
Train function
Loss = 6.8299e-04, PNorm = 61.1343, GNorm = 0.4897, lr_0 = 6.0167e-04
Loss = 5.8557e-04, PNorm = 61.1630, GNorm = 0.6625, lr_0 = 5.9901e-04
Loss = 7.7397e-04, PNorm = 61.1883, GNorm = 0.7715, lr_0 = 5.9636e-04
Loss = 6.8501e-04, PNorm = 61.2149, GNorm = 0.3907, lr_0 = 5.9372e-04
Loss = 7.1814e-04, PNorm = 61.2424, GNorm = 0.5774, lr_0 = 5.9110e-04
Validation rmse logD = 0.595110
Validation R2 logD = 0.766304
Epoch 24
Train function
Loss = 4.9068e-04, PNorm = 61.2700, GNorm = 0.3704, lr_0 = 5.8822e-04
Loss = 5.2428e-04, PNorm = 61.2947, GNorm = 0.4031, lr_0 = 5.8562e-04
Loss = 4.6253e-04, PNorm = 61.3148, GNorm = 0.4722, lr_0 = 5.8303e-04
Loss = 6.3279e-04, PNorm = 61.3322, GNorm = 0.8912, lr_0 = 5.8045e-04
Loss = 6.2627e-04, PNorm = 61.3580, GNorm = 0.4903, lr_0 = 5.7788e-04
Validation rmse logD = 0.604108
Validation R2 logD = 0.759183
Epoch 25
Train function
Loss = 6.0125e-04, PNorm = 61.3927, GNorm = 1.0144, lr_0 = 5.7533e-04
Loss = 5.3540e-04, PNorm = 61.4104, GNorm = 0.7547, lr_0 = 5.7278e-04
Loss = 5.3022e-04, PNorm = 61.4356, GNorm = 0.8257, lr_0 = 5.7025e-04
Loss = 4.3691e-04, PNorm = 61.4579, GNorm = 0.6653, lr_0 = 5.6773e-04
Loss = 5.3591e-04, PNorm = 61.4767, GNorm = 0.4602, lr_0 = 5.6522e-04
Loss = 5.9584e-04, PNorm = 61.4933, GNorm = 0.5166, lr_0 = 5.6272e-04
Validation rmse logD = 0.590015
Validation R2 logD = 0.770288
Epoch 26
Train function
Loss = 5.1033e-04, PNorm = 61.5153, GNorm = 0.6003, lr_0 = 5.5998e-04
Loss = 5.3561e-04, PNorm = 61.5425, GNorm = 0.3910, lr_0 = 5.5750e-04
Loss = 4.6515e-04, PNorm = 61.5657, GNorm = 0.7337, lr_0 = 5.5503e-04
Loss = 4.7194e-04, PNorm = 61.5843, GNorm = 0.8093, lr_0 = 5.5258e-04
Loss = 5.1966e-04, PNorm = 61.6096, GNorm = 0.6633, lr_0 = 5.5014e-04
Validation rmse logD = 0.603277
Validation R2 logD = 0.759845
Epoch 27
Train function
Loss = 5.3372e-04, PNorm = 61.6351, GNorm = 0.3594, lr_0 = 5.4746e-04
Loss = 6.2105e-04, PNorm = 61.6627, GNorm = 0.3543, lr_0 = 5.4504e-04
Loss = 4.4657e-04, PNorm = 61.6846, GNorm = 0.4331, lr_0 = 5.4263e-04
Loss = 4.2571e-04, PNorm = 61.7040, GNorm = 0.4504, lr_0 = 5.4023e-04
Loss = 6.0743e-04, PNorm = 61.7210, GNorm = 0.9724, lr_0 = 5.3784e-04
Validation rmse logD = 0.610921
Validation R2 logD = 0.753721
Epoch 28
Train function
Loss = 6.3536e-04, PNorm = 61.7503, GNorm = 0.3945, lr_0 = 5.3522e-04
Loss = 5.2142e-04, PNorm = 61.7754, GNorm = 1.0357, lr_0 = 5.3285e-04
Loss = 4.7517e-04, PNorm = 61.7990, GNorm = 0.4075, lr_0 = 5.3050e-04
Loss = 4.1949e-04, PNorm = 61.8198, GNorm = 0.4256, lr_0 = 5.2815e-04
Loss = 4.0792e-04, PNorm = 61.8421, GNorm = 0.3860, lr_0 = 5.2581e-04
Loss = 4.3172e-04, PNorm = 61.8558, GNorm = 0.3710, lr_0 = 5.2349e-04
Loss = 2.4712e-03, PNorm = 61.8563, GNorm = 1.3599, lr_0 = 5.2326e-04
Validation rmse logD = 0.591079
Validation R2 logD = 0.769459
Epoch 29
Train function
Loss = 3.8597e-04, PNorm = 61.8723, GNorm = 0.4369, lr_0 = 5.2094e-04
Loss = 3.5576e-04, PNorm = 61.8835, GNorm = 0.4866, lr_0 = 5.1864e-04
Loss = 4.0705e-04, PNorm = 61.9026, GNorm = 0.8429, lr_0 = 5.1634e-04
Loss = 3.9963e-04, PNorm = 61.9270, GNorm = 0.3597, lr_0 = 5.1406e-04
Loss = 3.9766e-04, PNorm = 61.9446, GNorm = 0.5916, lr_0 = 5.1178e-04
Validation rmse logD = 0.600707
Validation R2 logD = 0.761887
Epoch 30
Train function
Loss = 4.1691e-04, PNorm = 61.9666, GNorm = 0.8367, lr_0 = 5.0930e-04
Loss = 4.0541e-04, PNorm = 61.9853, GNorm = 0.5724, lr_0 = 5.0704e-04
Loss = 3.5625e-04, PNorm = 62.0071, GNorm = 0.8097, lr_0 = 5.0480e-04
Loss = 4.1225e-04, PNorm = 62.0266, GNorm = 0.9191, lr_0 = 5.0257e-04
Loss = 4.9447e-04, PNorm = 62.0425, GNorm = 1.0014, lr_0 = 5.0034e-04
Validation rmse logD = 0.604135
Validation R2 logD = 0.759162
Epoch 31
Train function
Loss = 4.3791e-04, PNorm = 62.0667, GNorm = 0.7963, lr_0 = 4.9791e-04
Loss = 4.3542e-04, PNorm = 62.0813, GNorm = 0.9051, lr_0 = 4.9571e-04
Loss = 3.9783e-04, PNorm = 62.1017, GNorm = 0.4834, lr_0 = 4.9351e-04
Loss = 3.5684e-04, PNorm = 62.1250, GNorm = 0.2455, lr_0 = 4.9133e-04
Loss = 3.1611e-04, PNorm = 62.1417, GNorm = 0.6388, lr_0 = 4.8916e-04
Validation rmse logD = 0.589070
Validation R2 logD = 0.771023
Epoch 32
Train function
Loss = 3.1865e-04, PNorm = 62.1602, GNorm = 0.8948, lr_0 = 4.8678e-04
Loss = 4.4168e-04, PNorm = 62.1763, GNorm = 0.4378, lr_0 = 4.8463e-04
Loss = 4.6021e-04, PNorm = 62.1910, GNorm = 0.6463, lr_0 = 4.8248e-04
Loss = 4.7356e-04, PNorm = 62.2091, GNorm = 1.6474, lr_0 = 4.8035e-04
Loss = 4.4558e-04, PNorm = 62.2287, GNorm = 1.0638, lr_0 = 4.7822e-04
Loss = 3.1919e-04, PNorm = 62.2508, GNorm = 0.4149, lr_0 = 4.7611e-04
Validation rmse logD = 0.585160
Validation R2 logD = 0.774053
Epoch 33
Train function
Loss = 3.5713e-04, PNorm = 62.2738, GNorm = 0.4760, lr_0 = 4.7379e-04
Loss = 3.6557e-04, PNorm = 62.2846, GNorm = 0.5717, lr_0 = 4.7170e-04
Loss = 3.0922e-04, PNorm = 62.2965, GNorm = 0.4669, lr_0 = 4.6961e-04
Loss = 3.2436e-04, PNorm = 62.3084, GNorm = 0.6197, lr_0 = 4.6753e-04
Loss = 2.5158e-04, PNorm = 62.3238, GNorm = 0.4949, lr_0 = 4.6546e-04
Validation rmse logD = 0.578256
Validation R2 logD = 0.779353
Epoch 34
Train function
Loss = 3.2012e-04, PNorm = 62.3399, GNorm = 0.8187, lr_0 = 4.6341e-04
Loss = 2.9160e-04, PNorm = 62.3547, GNorm = 0.4310, lr_0 = 4.6136e-04
Loss = 2.6385e-04, PNorm = 62.3681, GNorm = 0.2841, lr_0 = 4.5931e-04
Loss = 2.2002e-04, PNorm = 62.3850, GNorm = 0.1906, lr_0 = 4.5728e-04
Loss = 2.8353e-04, PNorm = 62.3979, GNorm = 0.3041, lr_0 = 4.5526e-04
Validation rmse logD = 0.591952
Validation R2 logD = 0.768778
Epoch 35
Train function
Loss = 1.9785e-04, PNorm = 62.4094, GNorm = 0.5777, lr_0 = 4.5305e-04
Loss = 2.7252e-04, PNorm = 62.4215, GNorm = 0.5447, lr_0 = 4.5104e-04
Loss = 2.4439e-04, PNorm = 62.4363, GNorm = 0.3866, lr_0 = 4.4905e-04
Loss = 2.0895e-04, PNorm = 62.4492, GNorm = 0.6055, lr_0 = 4.4706e-04
Loss = 2.5410e-04, PNorm = 62.4632, GNorm = 0.2643, lr_0 = 4.4508e-04
Loss = 2.3848e-04, PNorm = 62.4740, GNorm = 0.2413, lr_0 = 4.4311e-04
Validation rmse logD = 0.584654
Validation R2 logD = 0.774443
Epoch 36
Train function
Loss = 1.7712e-04, PNorm = 62.4859, GNorm = 0.2175, lr_0 = 4.4096e-04
Loss = 1.8891e-04, PNorm = 62.4922, GNorm = 0.3723, lr_0 = 4.3901e-04
Loss = 2.2347e-04, PNorm = 62.5025, GNorm = 0.6644, lr_0 = 4.3707e-04
Loss = 2.3642e-04, PNorm = 62.5181, GNorm = 0.6546, lr_0 = 4.3513e-04
Loss = 1.9972e-04, PNorm = 62.5295, GNorm = 0.3041, lr_0 = 4.3321e-04
Validation rmse logD = 0.592151
Validation R2 logD = 0.768622
Epoch 37
Train function
Loss = 2.1732e-04, PNorm = 62.5444, GNorm = 0.6775, lr_0 = 4.3110e-04
Loss = 1.5045e-04, PNorm = 62.5534, GNorm = 0.2856, lr_0 = 4.2919e-04
Loss = 1.9702e-04, PNorm = 62.5682, GNorm = 0.1685, lr_0 = 4.2729e-04
Loss = 1.8266e-04, PNorm = 62.5788, GNorm = 0.3374, lr_0 = 4.2540e-04
Loss = 2.1172e-04, PNorm = 62.5902, GNorm = 0.7602, lr_0 = 4.2352e-04
Validation rmse logD = 0.586346
Validation R2 logD = 0.773136
Epoch 38
Train function
Loss = 2.4757e-04, PNorm = 62.6034, GNorm = 0.4433, lr_0 = 4.2146e-04
Loss = 2.4565e-04, PNorm = 62.6170, GNorm = 0.6649, lr_0 = 4.1960e-04
Loss = 2.7436e-04, PNorm = 62.6349, GNorm = 0.4767, lr_0 = 4.1774e-04
Loss = 1.9175e-04, PNorm = 62.6477, GNorm = 0.4126, lr_0 = 4.1589e-04
Loss = 1.9962e-04, PNorm = 62.6599, GNorm = 0.1943, lr_0 = 4.1406e-04
Loss = 2.0440e-04, PNorm = 62.6744, GNorm = 0.2847, lr_0 = 4.1222e-04
Validation rmse logD = 0.590174
Validation R2 logD = 0.770164
Epoch 39
Train function
Loss = 2.2449e-04, PNorm = 62.6847, GNorm = 0.2838, lr_0 = 4.1022e-04
Loss = 1.7543e-04, PNorm = 62.6971, GNorm = 0.1990, lr_0 = 4.0840e-04
Loss = 2.6615e-04, PNorm = 62.7063, GNorm = 0.5001, lr_0 = 4.0660e-04
Loss = 1.9207e-04, PNorm = 62.7178, GNorm = 0.3307, lr_0 = 4.0480e-04
Loss = 1.8490e-04, PNorm = 62.7293, GNorm = 0.2385, lr_0 = 4.0301e-04
Validation rmse logD = 0.605512
Validation R2 logD = 0.758063
Epoch 40
Train function
Loss = 3.1419e-04, PNorm = 62.7407, GNorm = 0.6536, lr_0 = 4.0105e-04
Loss = 3.6233e-04, PNorm = 62.7535, GNorm = 0.3805, lr_0 = 3.9927e-04
Loss = 2.2553e-04, PNorm = 62.7678, GNorm = 0.2425, lr_0 = 3.9751e-04
Loss = 2.4899e-04, PNorm = 62.7774, GNorm = 0.3832, lr_0 = 3.9575e-04
Loss = 1.9240e-04, PNorm = 62.7914, GNorm = 0.3515, lr_0 = 3.9400e-04
Validation rmse logD = 0.591588
Validation R2 logD = 0.769062
Epoch 41
Train function
Loss = 1.8087e-04, PNorm = 62.8064, GNorm = 0.3406, lr_0 = 3.9208e-04
Loss = 1.8888e-04, PNorm = 62.8152, GNorm = 0.2225, lr_0 = 3.9035e-04
Loss = 2.3305e-04, PNorm = 62.8280, GNorm = 0.7164, lr_0 = 3.8862e-04
Loss = 1.9563e-04, PNorm = 62.8353, GNorm = 0.4370, lr_0 = 3.8690e-04
Loss = 1.7348e-04, PNorm = 62.8461, GNorm = 0.3555, lr_0 = 3.8519e-04
Loss = 1.6395e-04, PNorm = 62.8555, GNorm = 0.1548, lr_0 = 3.8349e-04
Validation rmse logD = 0.587054
Validation R2 logD = 0.772588
Epoch 42
Train function
Loss = 1.3976e-04, PNorm = 62.8603, GNorm = 0.7191, lr_0 = 3.8179e-04
Loss = 1.4143e-04, PNorm = 62.8731, GNorm = 0.3029, lr_0 = 3.8010e-04
Loss = 1.4405e-04, PNorm = 62.8815, GNorm = 0.1788, lr_0 = 3.7842e-04
Loss = 1.4637e-04, PNorm = 62.8873, GNorm = 0.4581, lr_0 = 3.7675e-04
Loss = 1.3425e-04, PNorm = 62.8963, GNorm = 0.4146, lr_0 = 3.7508e-04
Validation rmse logD = 0.584422
Validation R2 logD = 0.774623
Epoch 43
Train function
Loss = 1.2273e-04, PNorm = 62.9070, GNorm = 0.3303, lr_0 = 3.7326e-04
Loss = 1.0605e-04, PNorm = 62.9140, GNorm = 0.1714, lr_0 = 3.7160e-04
Loss = 1.1155e-04, PNorm = 62.9199, GNorm = 0.3067, lr_0 = 3.6996e-04
Loss = 1.2815e-04, PNorm = 62.9253, GNorm = 0.4227, lr_0 = 3.6832e-04
Loss = 1.1476e-04, PNorm = 62.9328, GNorm = 0.2311, lr_0 = 3.6669e-04
Validation rmse logD = 0.585785
Validation R2 logD = 0.773570
Epoch 44
Train function
Loss = 9.6578e-05, PNorm = 62.9437, GNorm = 0.3543, lr_0 = 3.6491e-04
Loss = 1.0517e-04, PNorm = 62.9495, GNorm = 0.2096, lr_0 = 3.6330e-04
Loss = 1.2121e-04, PNorm = 62.9544, GNorm = 0.1602, lr_0 = 3.6169e-04
Loss = 9.5481e-05, PNorm = 62.9617, GNorm = 0.5226, lr_0 = 3.6009e-04
Loss = 1.3985e-04, PNorm = 62.9709, GNorm = 0.3034, lr_0 = 3.5850e-04
Loss = 1.1628e-04, PNorm = 62.9813, GNorm = 0.3204, lr_0 = 3.5691e-04
Loss = 2.5926e-04, PNorm = 62.9823, GNorm = 0.3428, lr_0 = 3.5675e-04
Validation rmse logD = 0.588162
Validation R2 logD = 0.771729
Epoch 45
Train function
Loss = 8.8014e-05, PNorm = 62.9888, GNorm = 0.2241, lr_0 = 3.5518e-04
Loss = 9.3986e-05, PNorm = 62.9937, GNorm = 0.3250, lr_0 = 3.5360e-04
Loss = 1.0396e-04, PNorm = 62.9992, GNorm = 0.2687, lr_0 = 3.5204e-04
Loss = 1.2803e-04, PNorm = 63.0104, GNorm = 0.5112, lr_0 = 3.5048e-04
Loss = 1.1871e-04, PNorm = 63.0189, GNorm = 0.3013, lr_0 = 3.4893e-04
Validation rmse logD = 0.588949
Validation R2 logD = 0.771118
Epoch 46
Train function
Loss = 1.0181e-04, PNorm = 63.0263, GNorm = 0.1582, lr_0 = 3.4724e-04
Loss = 9.3254e-05, PNorm = 63.0316, GNorm = 0.2495, lr_0 = 3.4570e-04
Loss = 9.8623e-05, PNorm = 63.0371, GNorm = 0.3480, lr_0 = 3.4417e-04
Loss = 1.0594e-04, PNorm = 63.0422, GNorm = 0.3643, lr_0 = 3.4265e-04
Loss = 8.8689e-05, PNorm = 63.0507, GNorm = 0.2583, lr_0 = 3.4113e-04
Validation rmse logD = 0.588306
Validation R2 logD = 0.771617
Epoch 47
Train function
Loss = 7.1607e-05, PNorm = 63.0585, GNorm = 0.1517, lr_0 = 3.3947e-04
Loss = 7.5816e-05, PNorm = 63.0650, GNorm = 0.1550, lr_0 = 3.3797e-04
Loss = 9.9735e-05, PNorm = 63.0715, GNorm = 0.2600, lr_0 = 3.3648e-04
Loss = 1.0672e-04, PNorm = 63.0758, GNorm = 0.7648, lr_0 = 3.3499e-04
Loss = 1.3978e-04, PNorm = 63.0821, GNorm = 0.6298, lr_0 = 3.3351e-04
Validation rmse logD = 0.589267
Validation R2 logD = 0.770870
Epoch 48
Train function
Loss = 1.1635e-04, PNorm = 63.0871, GNorm = 0.5954, lr_0 = 3.3188e-04
Loss = 9.5228e-05, PNorm = 63.0956, GNorm = 0.1931, lr_0 = 3.3042e-04
Loss = 1.0052e-04, PNorm = 63.1043, GNorm = 0.4416, lr_0 = 3.2895e-04
Loss = 1.1244e-04, PNorm = 63.1103, GNorm = 0.8250, lr_0 = 3.2750e-04
Loss = 1.2206e-04, PNorm = 63.1203, GNorm = 0.6141, lr_0 = 3.2605e-04
Loss = 1.2343e-04, PNorm = 63.1268, GNorm = 0.4881, lr_0 = 3.2461e-04
Validation rmse logD = 0.589434
Validation R2 logD = 0.770741
Epoch 49
Train function
Loss = 1.3608e-04, PNorm = 63.1358, GNorm = 0.2232, lr_0 = 3.2303e-04
Loss = 8.1656e-05, PNorm = 63.1427, GNorm = 0.1450, lr_0 = 3.2160e-04
Loss = 9.3994e-05, PNorm = 63.1495, GNorm = 0.1727, lr_0 = 3.2018e-04
Loss = 1.0057e-04, PNorm = 63.1544, GNorm = 0.2191, lr_0 = 3.1876e-04
Loss = 8.3854e-05, PNorm = 63.1596, GNorm = 0.1679, lr_0 = 3.1735e-04
Validation rmse logD = 0.587727
Validation R2 logD = 0.772066
Epoch 50
Train function
Loss = 8.0840e-05, PNorm = 63.1632, GNorm = 0.2222, lr_0 = 3.1595e-04
Loss = 7.3592e-05, PNorm = 63.1673, GNorm = 0.3954, lr_0 = 3.1455e-04
Loss = 7.9578e-05, PNorm = 63.1704, GNorm = 0.4752, lr_0 = 3.1316e-04
Loss = 6.8144e-05, PNorm = 63.1749, GNorm = 0.1725, lr_0 = 3.1177e-04
Loss = 1.0089e-04, PNorm = 63.1812, GNorm = 0.3185, lr_0 = 3.1039e-04
Validation rmse logD = 0.586340
Validation R2 logD = 0.773141
Epoch 51
Train function
Loss = 6.2693e-05, PNorm = 63.1893, GNorm = 0.1436, lr_0 = 3.0888e-04
Loss = 6.4161e-05, PNorm = 63.1954, GNorm = 0.2224, lr_0 = 3.0752e-04
Loss = 6.4521e-05, PNorm = 63.2017, GNorm = 0.2975, lr_0 = 3.0616e-04
Loss = 6.6759e-05, PNorm = 63.2073, GNorm = 0.1654, lr_0 = 3.0480e-04
Loss = 6.6632e-05, PNorm = 63.2113, GNorm = 0.1984, lr_0 = 3.0346e-04
Loss = 6.9965e-05, PNorm = 63.2182, GNorm = 0.2489, lr_0 = 3.0211e-04
Validation rmse logD = 0.586251
Validation R2 logD = 0.773210
Epoch 52
Train function
Loss = 4.7641e-05, PNorm = 63.2231, GNorm = 0.1214, lr_0 = 3.0064e-04
Loss = 6.2636e-05, PNorm = 63.2257, GNorm = 0.1670, lr_0 = 2.9931e-04
Loss = 6.6603e-05, PNorm = 63.2313, GNorm = 0.3149, lr_0 = 2.9799e-04
Loss = 8.2902e-05, PNorm = 63.2349, GNorm = 0.2070, lr_0 = 2.9667e-04
Loss = 7.3593e-05, PNorm = 63.2424, GNorm = 0.1828, lr_0 = 2.9536e-04
Validation rmse logD = 0.585899
Validation R2 logD = 0.773482
Epoch 53
Train function
Loss = 5.8706e-05, PNorm = 63.2489, GNorm = 0.2762, lr_0 = 2.9392e-04
Loss = 6.9685e-05, PNorm = 63.2542, GNorm = 0.1610, lr_0 = 2.9262e-04
Loss = 5.7620e-05, PNorm = 63.2596, GNorm = 0.2014, lr_0 = 2.9133e-04
Loss = 5.8486e-05, PNorm = 63.2648, GNorm = 0.1262, lr_0 = 2.9004e-04
Loss = 6.0646e-05, PNorm = 63.2692, GNorm = 0.4487, lr_0 = 2.8876e-04
Validation rmse logD = 0.587890
Validation R2 logD = 0.771940
Epoch 54
Train function
Loss = 6.3769e-05, PNorm = 63.2724, GNorm = 0.3753, lr_0 = 2.8735e-04
Loss = 6.3956e-05, PNorm = 63.2762, GNorm = 0.2084, lr_0 = 2.8608e-04
Loss = 6.4373e-05, PNorm = 63.2820, GNorm = 0.2229, lr_0 = 2.8482e-04
Loss = 5.6948e-05, PNorm = 63.2847, GNorm = 0.4106, lr_0 = 2.8356e-04
Loss = 7.2923e-05, PNorm = 63.2906, GNorm = 0.2659, lr_0 = 2.8230e-04
Loss = 5.1997e-05, PNorm = 63.2969, GNorm = 0.1261, lr_0 = 2.8105e-04
Validation rmse logD = 0.589736
Validation R2 logD = 0.770505
Epoch 55
Train function
Loss = 5.0789e-05, PNorm = 63.3024, GNorm = 0.2508, lr_0 = 2.7969e-04
Loss = 6.0317e-05, PNorm = 63.3062, GNorm = 0.3410, lr_0 = 2.7845e-04
Loss = 4.2850e-05, PNorm = 63.3090, GNorm = 0.3231, lr_0 = 2.7722e-04
Loss = 6.4388e-05, PNorm = 63.3134, GNorm = 0.1582, lr_0 = 2.7599e-04
Loss = 6.3884e-05, PNorm = 63.3204, GNorm = 0.1934, lr_0 = 2.7477e-04
Validation rmse logD = 0.587455
Validation R2 logD = 0.772277
Epoch 56
Train function
Loss = 7.1370e-05, PNorm = 63.3276, GNorm = 0.5053, lr_0 = 2.7343e-04
Loss = 7.9213e-05, PNorm = 63.3344, GNorm = 0.1865, lr_0 = 2.7222e-04
Loss = 4.9218e-05, PNorm = 63.3391, GNorm = 0.1793, lr_0 = 2.7102e-04
Loss = 7.7048e-05, PNorm = 63.3428, GNorm = 0.2826, lr_0 = 2.6982e-04
Loss = 5.7448e-05, PNorm = 63.3476, GNorm = 0.2096, lr_0 = 2.6863e-04
Validation rmse logD = 0.590591
Validation R2 logD = 0.769839
Epoch 57
Train function
Loss = 8.5556e-05, PNorm = 63.3534, GNorm = 0.3231, lr_0 = 2.6732e-04
Loss = 7.6100e-05, PNorm = 63.3591, GNorm = 0.1510, lr_0 = 2.6614e-04
Loss = 7.1969e-05, PNorm = 63.3639, GNorm = 0.2584, lr_0 = 2.6496e-04
Loss = 5.6367e-05, PNorm = 63.3682, GNorm = 0.2345, lr_0 = 2.6379e-04
Loss = 7.2048e-05, PNorm = 63.3733, GNorm = 0.4531, lr_0 = 2.6262e-04
Loss = 5.7392e-05, PNorm = 63.3767, GNorm = 0.1673, lr_0 = 2.6146e-04
Loss = 1.7767e-03, PNorm = 63.3774, GNorm = 1.0310, lr_0 = 2.6134e-04
Validation rmse logD = 0.593076
Validation R2 logD = 0.767899
Epoch 58
Train function
Loss = 1.1178e-04, PNorm = 63.3820, GNorm = 0.5066, lr_0 = 2.6019e-04
Loss = 1.3564e-04, PNorm = 63.3860, GNorm = 0.3655, lr_0 = 2.5904e-04
Loss = 9.5082e-05, PNorm = 63.3930, GNorm = 0.2297, lr_0 = 2.5789e-04
Loss = 9.0389e-05, PNorm = 63.4010, GNorm = 0.2180, lr_0 = 2.5675e-04
Loss = 7.8101e-05, PNorm = 63.4066, GNorm = 0.1759, lr_0 = 2.5561e-04
Validation rmse logD = 0.594252
Validation R2 logD = 0.766977
Epoch 59
Train function
Loss = 7.6792e-05, PNorm = 63.4118, GNorm = 0.2302, lr_0 = 2.5448e-04
Loss = 7.9394e-05, PNorm = 63.4142, GNorm = 0.1635, lr_0 = 2.5336e-04
Loss = 7.9146e-05, PNorm = 63.4168, GNorm = 0.6076, lr_0 = 2.5224e-04
Loss = 6.9693e-05, PNorm = 63.4213, GNorm = 0.1194, lr_0 = 2.5112e-04
Loss = 7.1775e-05, PNorm = 63.4266, GNorm = 0.3456, lr_0 = 2.5001e-04
Validation rmse logD = 0.587887
Validation R2 logD = 0.771942
Epoch 60
Train function
Loss = 4.5686e-05, PNorm = 63.4313, GNorm = 0.1499, lr_0 = 2.4879e-04
Loss = 4.3141e-05, PNorm = 63.4360, GNorm = 0.2136, lr_0 = 2.4769e-04
Loss = 6.1817e-05, PNorm = 63.4402, GNorm = 0.2517, lr_0 = 2.4660e-04
Loss = 5.0043e-05, PNorm = 63.4435, GNorm = 0.1015, lr_0 = 2.4551e-04
Loss = 5.8826e-05, PNorm = 63.4480, GNorm = 0.2964, lr_0 = 2.4442e-04
Loss = 6.0627e-05, PNorm = 63.4527, GNorm = 0.1924, lr_0 = 2.4334e-04
Loss = 3.5226e-04, PNorm = 63.4529, GNorm = 0.5692, lr_0 = 2.4323e-04
Validation rmse logD = 0.586809
Validation R2 logD = 0.772778
Epoch 61
Train function
Loss = 3.6882e-05, PNorm = 63.4551, GNorm = 0.2319, lr_0 = 2.4216e-04
Loss = 4.5337e-05, PNorm = 63.4573, GNorm = 0.1937, lr_0 = 2.4109e-04
Loss = 4.8786e-05, PNorm = 63.4603, GNorm = 0.2525, lr_0 = 2.4002e-04
Loss = 4.8207e-05, PNorm = 63.4654, GNorm = 0.2427, lr_0 = 2.3896e-04
Loss = 4.2091e-05, PNorm = 63.4684, GNorm = 0.2059, lr_0 = 2.3790e-04
Validation rmse logD = 0.588018
Validation R2 logD = 0.771840
Epoch 62
Train function
Loss = 3.6338e-05, PNorm = 63.4709, GNorm = 0.1614, lr_0 = 2.3674e-04
Loss = 5.9262e-05, PNorm = 63.4755, GNorm = 0.4031, lr_0 = 2.3570e-04
Loss = 5.1608e-05, PNorm = 63.4788, GNorm = 0.1414, lr_0 = 2.3465e-04
Loss = 4.0632e-05, PNorm = 63.4815, GNorm = 0.2255, lr_0 = 2.3362e-04
Loss = 4.3052e-05, PNorm = 63.4869, GNorm = 0.0879, lr_0 = 2.3258e-04
Validation rmse logD = 0.591935
Validation R2 logD = 0.768791
Epoch 63
Train function
Loss = 4.0351e-05, PNorm = 63.4912, GNorm = 0.3243, lr_0 = 2.3145e-04
Loss = 4.5248e-05, PNorm = 63.4931, GNorm = 0.2197, lr_0 = 2.3043e-04
Loss = 4.3117e-05, PNorm = 63.4962, GNorm = 0.2964, lr_0 = 2.2941e-04
Loss = 3.5383e-05, PNorm = 63.4990, GNorm = 0.1125, lr_0 = 2.2839e-04
Loss = 3.6614e-05, PNorm = 63.5008, GNorm = 0.1875, lr_0 = 2.2738e-04
Validation rmse logD = 0.590364
Validation R2 logD = 0.770016
Epoch 64
Train function
Loss = 3.4098e-05, PNorm = 63.5042, GNorm = 0.2293, lr_0 = 2.2628e-04
Loss = 2.8846e-05, PNorm = 63.5061, GNorm = 0.1183, lr_0 = 2.2528e-04
Loss = 2.7631e-05, PNorm = 63.5085, GNorm = 0.1488, lr_0 = 2.2428e-04
Loss = 3.2262e-05, PNorm = 63.5104, GNorm = 0.1936, lr_0 = 2.2329e-04
Loss = 3.6232e-05, PNorm = 63.5137, GNorm = 0.1114, lr_0 = 2.2230e-04
Loss = 3.6579e-05, PNorm = 63.5161, GNorm = 0.0942, lr_0 = 2.2132e-04
Validation rmse logD = 0.589527
Validation R2 logD = 0.770668
Epoch 65
Train function
Loss = 2.5364e-05, PNorm = 63.5198, GNorm = 0.0935, lr_0 = 2.2024e-04
Loss = 3.0029e-05, PNorm = 63.5225, GNorm = 0.1205, lr_0 = 2.1927e-04
Loss = 3.0159e-05, PNorm = 63.5254, GNorm = 0.2771, lr_0 = 2.1830e-04
Loss = 3.1648e-05, PNorm = 63.5273, GNorm = 0.3787, lr_0 = 2.1733e-04
Loss = 4.2233e-05, PNorm = 63.5303, GNorm = 0.3590, lr_0 = 2.1637e-04
Validation rmse logD = 0.588204
Validation R2 logD = 0.771696
Epoch 66
Train function
Loss = 2.3932e-05, PNorm = 63.5325, GNorm = 0.1977, lr_0 = 2.1532e-04
Loss = 2.8255e-05, PNorm = 63.5359, GNorm = 0.1018, lr_0 = 2.1436e-04
Loss = 2.8063e-05, PNorm = 63.5381, GNorm = 0.1124, lr_0 = 2.1342e-04
Loss = 2.8146e-05, PNorm = 63.5389, GNorm = 0.1761, lr_0 = 2.1247e-04
Loss = 3.4514e-05, PNorm = 63.5415, GNorm = 0.1695, lr_0 = 2.1153e-04
Validation rmse logD = 0.588268
Validation R2 logD = 0.771647
Epoch 67
Train function
Loss = 2.1033e-05, PNorm = 63.5445, GNorm = 0.0956, lr_0 = 2.1060e-04
Loss = 2.6867e-05, PNorm = 63.5461, GNorm = 0.1125, lr_0 = 2.0966e-04
Loss = 2.8677e-05, PNorm = 63.5483, GNorm = 0.1271, lr_0 = 2.0874e-04
Loss = 2.6526e-05, PNorm = 63.5516, GNorm = 0.1144, lr_0 = 2.0781e-04
Loss = 2.5077e-05, PNorm = 63.5527, GNorm = 0.2204, lr_0 = 2.0689e-04
Loss = 2.6860e-05, PNorm = 63.5553, GNorm = 0.1978, lr_0 = 2.0598e-04
Validation rmse logD = 0.589232
Validation R2 logD = 0.770898
Epoch 68
Train function
Loss = 2.6167e-05, PNorm = 63.5586, GNorm = 0.2602, lr_0 = 2.0498e-04
Loss = 2.5622e-05, PNorm = 63.5597, GNorm = 0.0875, lr_0 = 2.0407e-04
Loss = 2.7703e-05, PNorm = 63.5624, GNorm = 0.1666, lr_0 = 2.0317e-04
Loss = 3.4022e-05, PNorm = 63.5652, GNorm = 0.1683, lr_0 = 2.0227e-04
Loss = 2.5612e-05, PNorm = 63.5683, GNorm = 0.0881, lr_0 = 2.0137e-04
Validation rmse logD = 0.589442
Validation R2 logD = 0.770734
Epoch 69
Train function
Loss = 3.1244e-05, PNorm = 63.5723, GNorm = 0.2979, lr_0 = 2.0039e-04
Loss = 3.1212e-05, PNorm = 63.5759, GNorm = 0.1747, lr_0 = 1.9951e-04
Loss = 2.8408e-05, PNorm = 63.5784, GNorm = 0.0731, lr_0 = 1.9863e-04
Loss = 2.3576e-05, PNorm = 63.5795, GNorm = 0.1106, lr_0 = 1.9775e-04
Loss = 2.9783e-05, PNorm = 63.5820, GNorm = 0.0690, lr_0 = 1.9687e-04
Validation rmse logD = 0.587906
Validation R2 logD = 0.771928
Epoch 70
Train function
Loss = 3.1434e-05, PNorm = 63.5841, GNorm = 0.1222, lr_0 = 1.9592e-04
Loss = 3.1528e-05, PNorm = 63.5880, GNorm = 0.3524, lr_0 = 1.9505e-04
Loss = 3.7707e-05, PNorm = 63.5925, GNorm = 0.2371, lr_0 = 1.9419e-04
Loss = 3.8973e-05, PNorm = 63.5945, GNorm = 0.2135, lr_0 = 1.9333e-04
Loss = 3.9331e-05, PNorm = 63.5968, GNorm = 0.3470, lr_0 = 1.9247e-04
Loss = 3.2673e-05, PNorm = 63.5994, GNorm = 0.2961, lr_0 = 1.9162e-04
Validation rmse logD = 0.590990
Validation R2 logD = 0.769528
Epoch 71
Train function
Loss = 2.7864e-05, PNorm = 63.6004, GNorm = 0.0800, lr_0 = 1.9069e-04
Loss = 2.6702e-05, PNorm = 63.6031, GNorm = 0.1431, lr_0 = 1.8984e-04
Loss = 2.5736e-05, PNorm = 63.6061, GNorm = 0.1215, lr_0 = 1.8900e-04
Loss = 3.2033e-05, PNorm = 63.6081, GNorm = 0.1876, lr_0 = 1.8817e-04
Loss = 2.6951e-05, PNorm = 63.6108, GNorm = 0.1508, lr_0 = 1.8734e-04
Validation rmse logD = 0.591150
Validation R2 logD = 0.769404
Epoch 72
Train function
Loss = 2.0099e-05, PNorm = 63.6136, GNorm = 0.0961, lr_0 = 1.8643e-04
Loss = 2.9319e-05, PNorm = 63.6142, GNorm = 0.2271, lr_0 = 1.8560e-04
Loss = 2.4008e-05, PNorm = 63.6143, GNorm = 0.1786, lr_0 = 1.8478e-04
Loss = 2.5382e-05, PNorm = 63.6172, GNorm = 0.1837, lr_0 = 1.8396e-04
Loss = 2.0087e-05, PNorm = 63.6198, GNorm = 0.1484, lr_0 = 1.8315e-04
Validation rmse logD = 0.590866
Validation R2 logD = 0.769625
Epoch 73
Train function
Loss = 2.4501e-05, PNorm = 63.6223, GNorm = 0.1324, lr_0 = 1.8226e-04
Loss = 2.7016e-05, PNorm = 63.6258, GNorm = 0.0736, lr_0 = 1.8145e-04
Loss = 2.2621e-05, PNorm = 63.6270, GNorm = 0.1247, lr_0 = 1.8065e-04
Loss = 2.1750e-05, PNorm = 63.6282, GNorm = 0.0888, lr_0 = 1.7985e-04
Loss = 2.5317e-05, PNorm = 63.6305, GNorm = 0.0813, lr_0 = 1.7905e-04
Loss = 2.9629e-05, PNorm = 63.6329, GNorm = 0.1279, lr_0 = 1.7826e-04
Loss = 2.4685e-05, PNorm = 63.6332, GNorm = 0.0791, lr_0 = 1.7818e-04
Validation rmse logD = 0.591007
Validation R2 logD = 0.769515
Epoch 74
Train function
Loss = 2.0917e-05, PNorm = 63.6353, GNorm = 0.1626, lr_0 = 1.7739e-04
Loss = 2.1803e-05, PNorm = 63.6367, GNorm = 0.0808, lr_0 = 1.7661e-04
Loss = 2.0967e-05, PNorm = 63.6379, GNorm = 0.1409, lr_0 = 1.7583e-04
Loss = 2.6856e-05, PNorm = 63.6409, GNorm = 0.3059, lr_0 = 1.7505e-04
Loss = 2.3325e-05, PNorm = 63.6432, GNorm = 0.2043, lr_0 = 1.7428e-04
Validation rmse logD = 0.591404
Validation R2 logD = 0.769205
Epoch 75
Train function
Loss = 3.3015e-05, PNorm = 63.6444, GNorm = 0.2604, lr_0 = 1.7351e-04
Loss = 2.7131e-05, PNorm = 63.6445, GNorm = 0.1037, lr_0 = 1.7274e-04
Loss = 2.4316e-05, PNorm = 63.6462, GNorm = 0.0864, lr_0 = 1.7197e-04
Loss = 2.7092e-05, PNorm = 63.6485, GNorm = 0.1927, lr_0 = 1.7121e-04
Loss = 1.7823e-05, PNorm = 63.6511, GNorm = 0.0883, lr_0 = 1.7046e-04
Validation rmse logD = 0.590970
Validation R2 logD = 0.769544
Epoch 76
Train function
Loss = 2.5148e-05, PNorm = 63.6539, GNorm = 0.0636, lr_0 = 1.6963e-04
Loss = 1.7609e-05, PNorm = 63.6558, GNorm = 0.1350, lr_0 = 1.6888e-04
Loss = 1.5391e-05, PNorm = 63.6573, GNorm = 0.0924, lr_0 = 1.6813e-04
Loss = 1.7422e-05, PNorm = 63.6579, GNorm = 0.0437, lr_0 = 1.6739e-04
Loss = 1.5728e-05, PNorm = 63.6595, GNorm = 0.1454, lr_0 = 1.6665e-04
Loss = 1.9972e-05, PNorm = 63.6616, GNorm = 0.1067, lr_0 = 1.6591e-04
Loss = 4.0379e-05, PNorm = 63.6617, GNorm = 0.1298, lr_0 = 1.6584e-04
Validation rmse logD = 0.591383
Validation R2 logD = 0.769222
Epoch 77
Train function
Loss = 1.3513e-05, PNorm = 63.6630, GNorm = 0.0878, lr_0 = 1.6510e-04
Loss = 1.4243e-05, PNorm = 63.6638, GNorm = 0.0957, lr_0 = 1.6437e-04
Loss = 1.6971e-05, PNorm = 63.6659, GNorm = 0.0889, lr_0 = 1.6364e-04
Loss = 1.1956e-05, PNorm = 63.6665, GNorm = 0.0997, lr_0 = 1.6292e-04
Loss = 1.4098e-05, PNorm = 63.6680, GNorm = 0.0736, lr_0 = 1.6220e-04
Validation rmse logD = 0.588213
Validation R2 logD = 0.771689
Epoch 78
Train function
Loss = 2.8138e-05, PNorm = 63.6712, GNorm = 0.1051, lr_0 = 1.6141e-04
Loss = 2.3198e-05, PNorm = 63.6720, GNorm = 0.2361, lr_0 = 1.6070e-04
Loss = 1.7498e-05, PNorm = 63.6739, GNorm = 0.0818, lr_0 = 1.5999e-04
Loss = 1.3863e-05, PNorm = 63.6760, GNorm = 0.1421, lr_0 = 1.5928e-04
Loss = 1.9135e-05, PNorm = 63.6772, GNorm = 0.1406, lr_0 = 1.5857e-04
Validation rmse logD = 0.590383
Validation R2 logD = 0.770002
Epoch 79
Train function
Loss = 1.5441e-05, PNorm = 63.6791, GNorm = 0.0743, lr_0 = 1.5780e-04
Loss = 1.6169e-05, PNorm = 63.6807, GNorm = 0.0837, lr_0 = 1.5710e-04
Loss = 1.9120e-05, PNorm = 63.6821, GNorm = 0.2322, lr_0 = 1.5641e-04
Loss = 1.4636e-05, PNorm = 63.6839, GNorm = 0.0878, lr_0 = 1.5572e-04
Loss = 1.4263e-05, PNorm = 63.6850, GNorm = 0.0796, lr_0 = 1.5503e-04
Validation rmse logD = 0.591294
Validation R2 logD = 0.769291
Epoch 80
Train function
Loss = 1.7469e-05, PNorm = 63.6867, GNorm = 0.0972, lr_0 = 1.5427e-04
Loss = 1.4382e-05, PNorm = 63.6880, GNorm = 0.1636, lr_0 = 1.5359e-04
Loss = 1.3456e-05, PNorm = 63.6902, GNorm = 0.1186, lr_0 = 1.5291e-04
Loss = 1.1256e-05, PNorm = 63.6912, GNorm = 0.1313, lr_0 = 1.5224e-04
Loss = 1.6454e-05, PNorm = 63.6915, GNorm = 0.2439, lr_0 = 1.5156e-04
Loss = 1.9953e-05, PNorm = 63.6926, GNorm = 0.2773, lr_0 = 1.5089e-04
Validation rmse logD = 0.590694
Validation R2 logD = 0.769759
Epoch 81
Train function
Loss = 1.8880e-05, PNorm = 63.6953, GNorm = 0.1245, lr_0 = 1.5016e-04
Loss = 2.0570e-05, PNorm = 63.6960, GNorm = 0.2036, lr_0 = 1.4949e-04
Loss = 2.5223e-05, PNorm = 63.6983, GNorm = 0.0727, lr_0 = 1.4883e-04
Loss = 1.8469e-05, PNorm = 63.6996, GNorm = 0.0958, lr_0 = 1.4817e-04
Loss = 1.5002e-05, PNorm = 63.7004, GNorm = 0.0715, lr_0 = 1.4752e-04
Validation rmse logD = 0.589978
Validation R2 logD = 0.770317
Epoch 82
Train function
Loss = 1.9095e-05, PNorm = 63.7022, GNorm = 0.1586, lr_0 = 1.4680e-04
Loss = 2.6874e-05, PNorm = 63.7055, GNorm = 0.2128, lr_0 = 1.4615e-04
Loss = 2.4990e-05, PNorm = 63.7084, GNorm = 0.0857, lr_0 = 1.4551e-04
Loss = 5.1565e-05, PNorm = 63.7119, GNorm = 0.0946, lr_0 = 1.4486e-04
Loss = 2.1481e-05, PNorm = 63.7141, GNorm = 0.1278, lr_0 = 1.4422e-04
Validation rmse logD = 0.588273
Validation R2 logD = 0.771642
Epoch 83
Train function
Loss = 1.0031e-05, PNorm = 63.7158, GNorm = 0.0594, lr_0 = 1.4352e-04
Loss = 1.7366e-05, PNorm = 63.7172, GNorm = 0.1396, lr_0 = 1.4288e-04
Loss = 1.7233e-05, PNorm = 63.7187, GNorm = 0.2011, lr_0 = 1.4225e-04
Loss = 1.5867e-05, PNorm = 63.7192, GNorm = 0.0965, lr_0 = 1.4162e-04
Loss = 1.2636e-05, PNorm = 63.7209, GNorm = 0.0915, lr_0 = 1.4100e-04
Loss = 1.5937e-05, PNorm = 63.7219, GNorm = 0.2128, lr_0 = 1.4037e-04
Validation rmse logD = 0.589864
Validation R2 logD = 0.770406
Epoch 84
Train function
Loss = 1.1552e-05, PNorm = 63.7225, GNorm = 0.0720, lr_0 = 1.3975e-04
Loss = 1.1800e-05, PNorm = 63.7236, GNorm = 0.0862, lr_0 = 1.3913e-04
Loss = 1.0970e-05, PNorm = 63.7242, GNorm = 0.0808, lr_0 = 1.3852e-04
Loss = 1.5306e-05, PNorm = 63.7254, GNorm = 0.1477, lr_0 = 1.3791e-04
Loss = 1.0347e-05, PNorm = 63.7268, GNorm = 0.0505, lr_0 = 1.3730e-04
Validation rmse logD = 0.590873
Validation R2 logD = 0.769620
Epoch 85
Train function
Loss = 9.1666e-06, PNorm = 63.7292, GNorm = 0.0392, lr_0 = 1.3663e-04
Loss = 1.1605e-05, PNorm = 63.7296, GNorm = 0.1006, lr_0 = 1.3602e-04
Loss = 1.0105e-05, PNorm = 63.7304, GNorm = 0.0615, lr_0 = 1.3542e-04
Loss = 1.1743e-05, PNorm = 63.7313, GNorm = 0.0826, lr_0 = 1.3482e-04
Loss = 1.2903e-05, PNorm = 63.7325, GNorm = 0.1139, lr_0 = 1.3423e-04
Validation rmse logD = 0.590246
Validation R2 logD = 0.770108
Epoch 86
Train function
Loss = 7.0116e-06, PNorm = 63.7327, GNorm = 0.0965, lr_0 = 1.3357e-04
Loss = 1.2141e-05, PNorm = 63.7342, GNorm = 0.0861, lr_0 = 1.3298e-04
Loss = 1.0291e-05, PNorm = 63.7362, GNorm = 0.0813, lr_0 = 1.3239e-04
Loss = 1.1044e-05, PNorm = 63.7379, GNorm = 0.1753, lr_0 = 1.3181e-04
Loss = 1.0855e-05, PNorm = 63.7395, GNorm = 0.0683, lr_0 = 1.3123e-04
Loss = 9.5199e-06, PNorm = 63.7402, GNorm = 0.0741, lr_0 = 1.3065e-04
Validation rmse logD = 0.590583
Validation R2 logD = 0.769846
Epoch 87
Train function
Loss = 1.1083e-05, PNorm = 63.7413, GNorm = 0.0821, lr_0 = 1.3001e-04
Loss = 8.9937e-06, PNorm = 63.7421, GNorm = 0.0617, lr_0 = 1.2944e-04
Loss = 1.1843e-05, PNorm = 63.7425, GNorm = 0.0973, lr_0 = 1.2886e-04
Loss = 1.0214e-05, PNorm = 63.7432, GNorm = 0.0589, lr_0 = 1.2829e-04
Loss = 1.0095e-05, PNorm = 63.7447, GNorm = 0.0871, lr_0 = 1.2773e-04
Validation rmse logD = 0.591991
Validation R2 logD = 0.768747
Epoch 88
Train function
Loss = 1.1623e-05, PNorm = 63.7456, GNorm = 0.0705, lr_0 = 1.2710e-04
Loss = 7.9797e-06, PNorm = 63.7464, GNorm = 0.0639, lr_0 = 1.2654e-04
Loss = 1.0073e-05, PNorm = 63.7475, GNorm = 0.1070, lr_0 = 1.2598e-04
Loss = 8.8984e-06, PNorm = 63.7486, GNorm = 0.0767, lr_0 = 1.2542e-04
Loss = 7.4041e-06, PNorm = 63.7503, GNorm = 0.0940, lr_0 = 1.2487e-04
Validation rmse logD = 0.591024
Validation R2 logD = 0.769502
Epoch 89
Train function
Loss = 2.0358e-05, PNorm = 63.7517, GNorm = 0.0950, lr_0 = 1.2426e-04
Loss = 1.7478e-05, PNorm = 63.7520, GNorm = 0.0444, lr_0 = 1.2371e-04
Loss = 1.4915e-05, PNorm = 63.7530, GNorm = 0.1144, lr_0 = 1.2317e-04
Loss = 9.7406e-06, PNorm = 63.7539, GNorm = 0.1366, lr_0 = 1.2262e-04
Loss = 1.0681e-05, PNorm = 63.7548, GNorm = 0.2023, lr_0 = 1.2208e-04
Loss = 1.0345e-05, PNorm = 63.7556, GNorm = 0.1266, lr_0 = 1.2154e-04
Loss = 1.4764e-05, PNorm = 63.7558, GNorm = 0.0853, lr_0 = 1.2148e-04
Validation rmse logD = 0.590355
Validation R2 logD = 0.770023
Epoch 90
Train function
Loss = 6.8704e-06, PNorm = 63.7574, GNorm = 0.0438, lr_0 = 1.2095e-04
Loss = 7.1919e-06, PNorm = 63.7587, GNorm = 0.1436, lr_0 = 1.2041e-04
Loss = 1.1699e-05, PNorm = 63.7603, GNorm = 0.0860, lr_0 = 1.1988e-04
Loss = 1.0782e-05, PNorm = 63.7613, GNorm = 0.0609, lr_0 = 1.1935e-04
Loss = 1.3243e-05, PNorm = 63.7624, GNorm = 0.1636, lr_0 = 1.1882e-04
Validation rmse logD = 0.591115
Validation R2 logD = 0.769431
Epoch 91
Train function
Loss = 1.0607e-05, PNorm = 63.7640, GNorm = 0.0732, lr_0 = 1.1824e-04
Loss = 8.4909e-06, PNorm = 63.7649, GNorm = 0.0537, lr_0 = 1.1772e-04
Loss = 9.5692e-06, PNorm = 63.7655, GNorm = 0.0777, lr_0 = 1.1720e-04
Loss = 1.1441e-05, PNorm = 63.7652, GNorm = 0.1066, lr_0 = 1.1668e-04
Loss = 1.3813e-05, PNorm = 63.7662, GNorm = 0.2386, lr_0 = 1.1616e-04
Validation rmse logD = 0.591513
Validation R2 logD = 0.769120
Epoch 92
Train function
Loss = 1.4412e-05, PNorm = 63.7685, GNorm = 0.1281, lr_0 = 1.1565e-04
Loss = 1.5647e-05, PNorm = 63.7700, GNorm = 0.0659, lr_0 = 1.1514e-04
Loss = 1.1735e-05, PNorm = 63.7709, GNorm = 0.1182, lr_0 = 1.1463e-04
Loss = 1.1897e-05, PNorm = 63.7721, GNorm = 0.0790, lr_0 = 1.1412e-04
Loss = 1.2001e-05, PNorm = 63.7730, GNorm = 0.1735, lr_0 = 1.1362e-04
Loss = 1.1962e-05, PNorm = 63.7736, GNorm = 0.1631, lr_0 = 1.1312e-04
Loss = 1.3729e-04, PNorm = 63.7738, GNorm = 0.3376, lr_0 = 1.1307e-04
Validation rmse logD = 0.590239
Validation R2 logD = 0.770113
Epoch 93
Train function
Loss = 1.1671e-05, PNorm = 63.7746, GNorm = 0.0574, lr_0 = 1.1257e-04
Loss = 9.9380e-06, PNorm = 63.7751, GNorm = 0.0534, lr_0 = 1.1207e-04
Loss = 1.1046e-05, PNorm = 63.7766, GNorm = 0.0792, lr_0 = 1.1157e-04
Loss = 9.0463e-06, PNorm = 63.7776, GNorm = 0.0497, lr_0 = 1.1108e-04
Loss = 9.1430e-06, PNorm = 63.7785, GNorm = 0.1665, lr_0 = 1.1059e-04
Validation rmse logD = 0.592101
Validation R2 logD = 0.768661
Epoch 94
Train function
Loss = 8.5652e-06, PNorm = 63.7786, GNorm = 0.0560, lr_0 = 1.1005e-04
Loss = 1.2329e-05, PNorm = 63.7798, GNorm = 0.0688, lr_0 = 1.0956e-04
Loss = 7.5365e-06, PNorm = 63.7809, GNorm = 0.0786, lr_0 = 1.0908e-04
Loss = 8.0406e-06, PNorm = 63.7819, GNorm = 0.0659, lr_0 = 1.0860e-04
Loss = 8.9907e-06, PNorm = 63.7831, GNorm = 0.0881, lr_0 = 1.0811e-04
Validation rmse logD = 0.592069
Validation R2 logD = 0.768686
Epoch 95
Train function
Loss = 1.1009e-05, PNorm = 63.7844, GNorm = 0.1448, lr_0 = 1.0759e-04
Loss = 7.7987e-06, PNorm = 63.7851, GNorm = 0.1138, lr_0 = 1.0711e-04
Loss = 8.3969e-06, PNorm = 63.7857, GNorm = 0.1022, lr_0 = 1.0664e-04
Loss = 1.0222e-05, PNorm = 63.7873, GNorm = 0.0657, lr_0 = 1.0617e-04
Loss = 1.4709e-05, PNorm = 63.7877, GNorm = 0.1190, lr_0 = 1.0570e-04
Validation rmse logD = 0.593978
Validation R2 logD = 0.767192
Epoch 96
Train function
Loss = 4.9704e-06, PNorm = 63.7892, GNorm = 0.0704, lr_0 = 1.0518e-04
Loss = 1.0222e-05, PNorm = 63.7907, GNorm = 0.1808, lr_0 = 1.0472e-04
Loss = 1.2040e-05, PNorm = 63.7913, GNorm = 0.2451, lr_0 = 1.0426e-04
Loss = 9.9172e-06, PNorm = 63.7926, GNorm = 0.1753, lr_0 = 1.0379e-04
Loss = 1.1511e-05, PNorm = 63.7939, GNorm = 0.0462, lr_0 = 1.0333e-04
Loss = 1.0470e-05, PNorm = 63.7948, GNorm = 0.0668, lr_0 = 1.0288e-04
Validation rmse logD = 0.591208
Validation R2 logD = 0.769359
Epoch 97
Train function
Loss = 1.2603e-05, PNorm = 63.7951, GNorm = 0.1663, lr_0 = 1.0238e-04
Loss = 1.2948e-05, PNorm = 63.7962, GNorm = 0.2215, lr_0 = 1.0192e-04
Loss = 9.3881e-06, PNorm = 63.7963, GNorm = 0.0817, lr_0 = 1.0147e-04
Loss = 1.1384e-05, PNorm = 63.7975, GNorm = 0.0531, lr_0 = 1.0102e-04
Loss = 9.4807e-06, PNorm = 63.7991, GNorm = 0.0542, lr_0 = 1.0058e-04
Validation rmse logD = 0.591602
Validation R2 logD = 0.769051
Epoch 98
Train function
Loss = 9.1485e-06, PNorm = 63.8001, GNorm = 0.1834, lr_0 = 1.0009e-04
Loss = 9.7405e-06, PNorm = 63.8003, GNorm = 0.1217, lr_0 = 1.0000e-04
Loss = 7.9704e-06, PNorm = 63.8015, GNorm = 0.0376, lr_0 = 1.0000e-04
Loss = 5.3734e-06, PNorm = 63.8019, GNorm = 0.0417, lr_0 = 1.0000e-04
Loss = 6.3738e-06, PNorm = 63.8019, GNorm = 0.0497, lr_0 = 1.0000e-04
Validation rmse logD = 0.591218
Validation R2 logD = 0.769350
Epoch 99
Train function
Loss = 3.3556e-06, PNorm = 63.8025, GNorm = 0.0320, lr_0 = 1.0000e-04
Loss = 5.7804e-06, PNorm = 63.8027, GNorm = 0.1008, lr_0 = 1.0000e-04
Loss = 5.3831e-06, PNorm = 63.8034, GNorm = 0.0666, lr_0 = 1.0000e-04
Loss = 7.4597e-06, PNorm = 63.8036, GNorm = 0.1813, lr_0 = 1.0000e-04
Loss = 8.4747e-06, PNorm = 63.8040, GNorm = 0.1197, lr_0 = 1.0000e-04
Loss = 7.8964e-06, PNorm = 63.8049, GNorm = 0.0643, lr_0 = 1.0000e-04
Validation rmse logD = 0.591866
Validation R2 logD = 0.768845
Model 0 best validation rmse = 0.578256 on epoch 33
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.594308
Model 0 test R2 logD = 0.755719
Ensemble test rmse  logD= 0.594308
Ensemble test R2  logD= 0.755719
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_304/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=895, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,222,401
Moving model to cuda
Epoch 0
Train function
Loss = 2.1591e-02, PNorm = 52.4974, GNorm = 2.7580, lr_0 = 1.9340e-04
Loss = 1.8865e-02, PNorm = 52.5062, GNorm = 6.8045, lr_0 = 2.7830e-04
Loss = 1.6480e-02, PNorm = 52.5187, GNorm = 2.3732, lr_0 = 3.6321e-04
Loss = 1.5840e-02, PNorm = 52.5336, GNorm = 2.1183, lr_0 = 4.4811e-04
Loss = 1.5396e-02, PNorm = 52.5542, GNorm = 4.2857, lr_0 = 5.3302e-04
Validation rmse logD = 1.067114
Validation R2 logD = 0.235589
Epoch 1
Train function
Loss = 1.6578e-02, PNorm = 52.5915, GNorm = 6.8898, lr_0 = 6.2642e-04
Loss = 1.4307e-02, PNorm = 52.6432, GNorm = 2.7091, lr_0 = 7.1132e-04
Loss = 1.2348e-02, PNorm = 52.6984, GNorm = 6.1787, lr_0 = 7.9623e-04
Loss = 1.3603e-02, PNorm = 52.7597, GNorm = 1.2386, lr_0 = 8.8113e-04
Loss = 1.3562e-02, PNorm = 52.8544, GNorm = 1.1143, lr_0 = 9.6604e-04
Validation rmse logD = 0.944474
Validation R2 logD = 0.401196
Epoch 2
Train function
Loss = 1.3422e-02, PNorm = 52.9626, GNorm = 1.3292, lr_0 = 9.9690e-04
Loss = 1.2110e-02, PNorm = 53.0532, GNorm = 0.9989, lr_0 = 9.9249e-04
Loss = 1.1794e-02, PNorm = 53.1752, GNorm = 2.8706, lr_0 = 9.8810e-04
Loss = 1.1423e-02, PNorm = 53.2936, GNorm = 8.6653, lr_0 = 9.8373e-04
Loss = 1.1209e-02, PNorm = 53.4208, GNorm = 2.8675, lr_0 = 9.7938e-04
Validation rmse logD = 0.959707
Validation R2 logD = 0.381724
Epoch 3
Train function
Loss = 1.2152e-02, PNorm = 53.5198, GNorm = 4.1434, lr_0 = 9.7462e-04
Loss = 9.0032e-03, PNorm = 53.6086, GNorm = 1.5366, lr_0 = 9.7030e-04
Loss = 8.1695e-03, PNorm = 53.7351, GNorm = 1.4964, lr_0 = 9.6601e-04
Loss = 9.0751e-03, PNorm = 53.8471, GNorm = 1.1019, lr_0 = 9.6174e-04
Loss = 9.5864e-03, PNorm = 53.9699, GNorm = 3.9119, lr_0 = 9.5749e-04
Loss = 8.4797e-03, PNorm = 54.0624, GNorm = 2.3191, lr_0 = 9.5325e-04
Validation rmse logD = 0.775604
Validation R2 logD = 0.596182
Epoch 4
Train function
Loss = 6.7515e-03, PNorm = 54.1728, GNorm = 1.2839, lr_0 = 9.4861e-04
Loss = 8.8739e-03, PNorm = 54.2585, GNorm = 1.3502, lr_0 = 9.4442e-04
Loss = 8.3838e-03, PNorm = 54.3476, GNorm = 3.4294, lr_0 = 9.4024e-04
Loss = 8.4538e-03, PNorm = 54.4524, GNorm = 1.4303, lr_0 = 9.3608e-04
Loss = 8.9010e-03, PNorm = 54.5461, GNorm = 1.7919, lr_0 = 9.3194e-04
Validation rmse logD = 0.965774
Validation R2 logD = 0.373883
Epoch 5
Train function
Loss = 7.4752e-03, PNorm = 54.6475, GNorm = 2.2129, lr_0 = 9.2741e-04
Loss = 6.7881e-03, PNorm = 54.7417, GNorm = 1.1182, lr_0 = 9.2330e-04
Loss = 6.2625e-03, PNorm = 54.8184, GNorm = 3.6790, lr_0 = 9.1922e-04
Loss = 6.5733e-03, PNorm = 54.9132, GNorm = 1.0724, lr_0 = 9.1515e-04
Loss = 6.9121e-03, PNorm = 55.0127, GNorm = 3.1765, lr_0 = 9.1111e-04
Validation rmse logD = 0.731565
Validation R2 logD = 0.640738
Epoch 6
Train function
Loss = 4.4816e-03, PNorm = 55.1111, GNorm = 0.9013, lr_0 = 9.0667e-04
Loss = 5.5525e-03, PNorm = 55.1966, GNorm = 1.1380, lr_0 = 9.0266e-04
Loss = 5.1697e-03, PNorm = 55.2895, GNorm = 1.7348, lr_0 = 8.9867e-04
Loss = 5.4311e-03, PNorm = 55.3650, GNorm = 1.1066, lr_0 = 8.9469e-04
Loss = 6.7392e-03, PNorm = 55.4539, GNorm = 3.7366, lr_0 = 8.9074e-04
Loss = 5.7949e-03, PNorm = 55.5243, GNorm = 1.6144, lr_0 = 8.8680e-04
Validation rmse logD = 0.744062
Validation R2 logD = 0.628359
Epoch 7
Train function
Loss = 7.0221e-03, PNorm = 55.6112, GNorm = 4.8900, lr_0 = 8.8248e-04
Loss = 5.5474e-03, PNorm = 55.7212, GNorm = 3.9066, lr_0 = 8.7858e-04
Loss = 4.6832e-03, PNorm = 55.8139, GNorm = 0.8729, lr_0 = 8.7469e-04
Loss = 4.4713e-03, PNorm = 55.8795, GNorm = 2.5191, lr_0 = 8.7082e-04
Loss = 5.1795e-03, PNorm = 55.9471, GNorm = 2.1712, lr_0 = 8.6697e-04
Validation rmse logD = 0.655734
Validation R2 logD = 0.711358
Epoch 8
Train function
Loss = 4.5302e-03, PNorm = 56.0378, GNorm = 0.9793, lr_0 = 8.6276e-04
Loss = 3.8261e-03, PNorm = 56.1165, GNorm = 1.7146, lr_0 = 8.5894e-04
Loss = 4.6638e-03, PNorm = 56.1825, GNorm = 5.0148, lr_0 = 8.5514e-04
Loss = 4.3810e-03, PNorm = 56.2647, GNorm = 0.9555, lr_0 = 8.5136e-04
Loss = 4.2154e-03, PNorm = 56.3395, GNorm = 3.3820, lr_0 = 8.4759e-04
Validation rmse logD = 0.648589
Validation R2 logD = 0.717614
Epoch 9
Train function
Loss = 4.1672e-03, PNorm = 56.4056, GNorm = 3.7502, lr_0 = 8.4384e-04
Loss = 3.5782e-03, PNorm = 56.4678, GNorm = 1.3736, lr_0 = 8.4011e-04
Loss = 4.2183e-03, PNorm = 56.5606, GNorm = 1.1156, lr_0 = 8.3639e-04
Loss = 3.6738e-03, PNorm = 56.6337, GNorm = 1.4867, lr_0 = 8.3269e-04
Loss = 3.7920e-03, PNorm = 56.7089, GNorm = 1.4596, lr_0 = 8.2901e-04
Loss = 4.2151e-03, PNorm = 56.7645, GNorm = 1.7688, lr_0 = 8.2534e-04
Validation rmse logD = 0.661223
Validation R2 logD = 0.706505
Epoch 10
Train function
Loss = 3.3365e-03, PNorm = 56.8223, GNorm = 0.9027, lr_0 = 8.2133e-04
Loss = 3.4295e-03, PNorm = 56.8965, GNorm = 2.4080, lr_0 = 8.1770e-04
Loss = 3.6578e-03, PNorm = 56.9771, GNorm = 1.4697, lr_0 = 8.1408e-04
Loss = 3.2491e-03, PNorm = 57.0372, GNorm = 1.1182, lr_0 = 8.1048e-04
Loss = 2.7687e-03, PNorm = 57.0900, GNorm = 0.9433, lr_0 = 8.0689e-04
Validation rmse logD = 0.725076
Validation R2 logD = 0.647084
Epoch 11
Train function
Loss = 4.1224e-03, PNorm = 57.1764, GNorm = 2.4202, lr_0 = 8.0297e-04
Loss = 3.3277e-03, PNorm = 57.2548, GNorm = 2.2329, lr_0 = 7.9942e-04
Loss = 3.0490e-03, PNorm = 57.3342, GNorm = 1.9034, lr_0 = 7.9588e-04
Loss = 2.7278e-03, PNorm = 57.3978, GNorm = 1.8427, lr_0 = 7.9236e-04
Loss = 2.8921e-03, PNorm = 57.4582, GNorm = 0.9864, lr_0 = 7.8885e-04
Validation rmse logD = 0.639172
Validation R2 logD = 0.725754
Epoch 12
Train function
Loss = 3.1325e-03, PNorm = 57.5142, GNorm = 1.1628, lr_0 = 7.8502e-04
Loss = 2.7722e-03, PNorm = 57.5718, GNorm = 1.5120, lr_0 = 7.8154e-04
Loss = 2.4854e-03, PNorm = 57.6227, GNorm = 1.0452, lr_0 = 7.7809e-04
Loss = 2.4246e-03, PNorm = 57.6816, GNorm = 1.8811, lr_0 = 7.7465e-04
Loss = 2.4008e-03, PNorm = 57.7391, GNorm = 0.7240, lr_0 = 7.7122e-04
Loss = 2.6372e-03, PNorm = 57.7966, GNorm = 1.5685, lr_0 = 7.6781e-04
Loss = 2.7594e-02, PNorm = 57.8035, GNorm = 2.2741, lr_0 = 7.6747e-04
Validation rmse logD = 0.615248
Validation R2 logD = 0.745899
Epoch 13
Train function
Loss = 2.0412e-03, PNorm = 57.8591, GNorm = 0.9071, lr_0 = 7.6407e-04
Loss = 2.7801e-03, PNorm = 57.9147, GNorm = 2.2212, lr_0 = 7.6069e-04
Loss = 2.1970e-03, PNorm = 57.9837, GNorm = 0.7572, lr_0 = 7.5733e-04
Loss = 2.5797e-03, PNorm = 58.0375, GNorm = 1.9579, lr_0 = 7.5398e-04
Loss = 1.9119e-03, PNorm = 58.0979, GNorm = 1.0861, lr_0 = 7.5064e-04
Validation rmse logD = 0.647927
Validation R2 logD = 0.718190
Epoch 14
Train function
Loss = 2.5340e-03, PNorm = 58.1658, GNorm = 1.0265, lr_0 = 7.4699e-04
Loss = 2.0707e-03, PNorm = 58.2112, GNorm = 1.0701, lr_0 = 7.4369e-04
Loss = 2.0700e-03, PNorm = 58.2729, GNorm = 1.6446, lr_0 = 7.4040e-04
Loss = 2.0060e-03, PNorm = 58.3184, GNorm = 1.0617, lr_0 = 7.3712e-04
Loss = 2.0519e-03, PNorm = 58.3609, GNorm = 0.7899, lr_0 = 7.3386e-04
Validation rmse logD = 0.604889
Validation R2 logD = 0.754384
Epoch 15
Train function
Loss = 2.1287e-03, PNorm = 58.4367, GNorm = 1.7044, lr_0 = 7.3029e-04
Loss = 2.1778e-03, PNorm = 58.4978, GNorm = 1.1631, lr_0 = 7.2706e-04
Loss = 2.0008e-03, PNorm = 58.5620, GNorm = 1.0317, lr_0 = 7.2385e-04
Loss = 2.2185e-03, PNorm = 58.6258, GNorm = 1.7552, lr_0 = 7.2064e-04
Loss = 2.0526e-03, PNorm = 58.6822, GNorm = 2.3877, lr_0 = 7.1746e-04
Validation rmse logD = 0.670820
Validation R2 logD = 0.697923
Epoch 16
Train function
Loss = 3.4515e-03, PNorm = 58.7505, GNorm = 3.7902, lr_0 = 7.1397e-04
Loss = 3.0858e-03, PNorm = 58.8004, GNorm = 3.8181, lr_0 = 7.1081e-04
Loss = 2.2616e-03, PNorm = 58.8707, GNorm = 1.5503, lr_0 = 7.0766e-04
Loss = 2.0313e-03, PNorm = 58.9269, GNorm = 1.6655, lr_0 = 7.0453e-04
Loss = 1.8716e-03, PNorm = 58.9879, GNorm = 0.7619, lr_0 = 7.0142e-04
Loss = 1.6743e-03, PNorm = 59.0287, GNorm = 1.1376, lr_0 = 6.9831e-04
Validation rmse logD = 0.618801
Validation R2 logD = 0.742957
Epoch 17
Train function
Loss = 1.3170e-03, PNorm = 59.0717, GNorm = 0.6465, lr_0 = 6.9523e-04
Loss = 1.3013e-03, PNorm = 59.1112, GNorm = 0.5183, lr_0 = 6.9215e-04
Loss = 1.5875e-03, PNorm = 59.1427, GNorm = 1.9063, lr_0 = 6.8909e-04
Loss = 1.5700e-03, PNorm = 59.1725, GNorm = 1.6006, lr_0 = 6.8604e-04
Loss = 1.5525e-03, PNorm = 59.2216, GNorm = 0.7374, lr_0 = 6.8301e-04
Validation rmse logD = 0.602923
Validation R2 logD = 0.755978
Epoch 18
Train function
Loss = 1.2392e-03, PNorm = 59.2605, GNorm = 1.5026, lr_0 = 6.7968e-04
Loss = 1.5954e-03, PNorm = 59.3068, GNorm = 0.6054, lr_0 = 6.7668e-04
Loss = 1.3301e-03, PNorm = 59.3408, GNorm = 0.9649, lr_0 = 6.7368e-04
Loss = 1.1612e-03, PNorm = 59.3688, GNorm = 0.8940, lr_0 = 6.7070e-04
Loss = 1.3700e-03, PNorm = 59.4118, GNorm = 0.5480, lr_0 = 6.6774e-04
Validation rmse logD = 0.619573
Validation R2 logD = 0.742314
Epoch 19
Train function
Loss = 1.3478e-03, PNorm = 59.4498, GNorm = 1.7054, lr_0 = 6.6449e-04
Loss = 1.3235e-03, PNorm = 59.4848, GNorm = 1.0747, lr_0 = 6.6155e-04
Loss = 1.2771e-03, PNorm = 59.5288, GNorm = 1.2812, lr_0 = 6.5862e-04
Loss = 1.0587e-03, PNorm = 59.5573, GNorm = 1.4576, lr_0 = 6.5571e-04
Loss = 1.3507e-03, PNorm = 59.5875, GNorm = 1.8791, lr_0 = 6.5281e-04
Loss = 9.6262e-04, PNorm = 59.6213, GNorm = 0.5343, lr_0 = 6.4992e-04
Validation rmse logD = 0.593031
Validation R2 logD = 0.763920
Epoch 20
Train function
Loss = 1.1467e-03, PNorm = 59.6593, GNorm = 1.6048, lr_0 = 6.4676e-04
Loss = 1.1512e-03, PNorm = 59.6959, GNorm = 1.0550, lr_0 = 6.4390e-04
Loss = 9.1784e-04, PNorm = 59.7284, GNorm = 0.5740, lr_0 = 6.4105e-04
Loss = 9.4963e-04, PNorm = 59.7578, GNorm = 0.5011, lr_0 = 6.3822e-04
Loss = 1.0406e-03, PNorm = 59.7893, GNorm = 0.6273, lr_0 = 6.3539e-04
Validation rmse logD = 0.586040
Validation R2 logD = 0.769453
Epoch 21
Train function
Loss = 7.1887e-04, PNorm = 59.8254, GNorm = 0.5370, lr_0 = 6.3230e-04
Loss = 8.8832e-04, PNorm = 59.8441, GNorm = 0.9532, lr_0 = 6.2950e-04
Loss = 7.6331e-04, PNorm = 59.8630, GNorm = 0.6140, lr_0 = 6.2672e-04
Loss = 9.9417e-04, PNorm = 59.8876, GNorm = 0.8043, lr_0 = 6.2395e-04
Loss = 9.6604e-04, PNorm = 59.9267, GNorm = 0.6473, lr_0 = 6.2119e-04
Validation rmse logD = 0.609937
Validation R2 logD = 0.750267
Epoch 22
Train function
Loss = 9.4154e-04, PNorm = 59.9494, GNorm = 0.4789, lr_0 = 6.1817e-04
Loss = 1.1551e-03, PNorm = 59.9792, GNorm = 0.4550, lr_0 = 6.1543e-04
Loss = 1.4709e-03, PNorm = 60.0167, GNorm = 2.1727, lr_0 = 6.1271e-04
Loss = 1.1114e-03, PNorm = 60.0504, GNorm = 0.5740, lr_0 = 6.1000e-04
Loss = 9.7612e-04, PNorm = 60.0897, GNorm = 1.1524, lr_0 = 6.0730e-04
Loss = 7.9080e-04, PNorm = 60.1239, GNorm = 0.4062, lr_0 = 6.0461e-04
Validation rmse logD = 0.600945
Validation R2 logD = 0.757577
Epoch 23
Train function
Loss = 8.7786e-04, PNorm = 60.1496, GNorm = 0.8266, lr_0 = 6.0167e-04
Loss = 8.2838e-04, PNorm = 60.1846, GNorm = 0.5652, lr_0 = 5.9901e-04
Loss = 7.0010e-04, PNorm = 60.2109, GNorm = 0.4673, lr_0 = 5.9636e-04
Loss = 7.2624e-04, PNorm = 60.2349, GNorm = 1.3305, lr_0 = 5.9372e-04
Loss = 9.7203e-04, PNorm = 60.2566, GNorm = 0.5038, lr_0 = 5.9110e-04
Validation rmse logD = 0.581342
Validation R2 logD = 0.773134
Epoch 24
Train function
Loss = 8.0944e-04, PNorm = 60.2808, GNorm = 0.7297, lr_0 = 5.8822e-04
Loss = 7.6323e-04, PNorm = 60.3051, GNorm = 0.4853, lr_0 = 5.8562e-04
Loss = 6.2273e-04, PNorm = 60.3301, GNorm = 0.8408, lr_0 = 5.8303e-04
Loss = 8.7461e-04, PNorm = 60.3497, GNorm = 0.6910, lr_0 = 5.8045e-04
Loss = 6.9210e-04, PNorm = 60.3649, GNorm = 0.9733, lr_0 = 5.7788e-04
Validation rmse logD = 0.588286
Validation R2 logD = 0.767682
Epoch 25
Train function
Loss = 4.8301e-04, PNorm = 60.3917, GNorm = 0.3848, lr_0 = 5.7533e-04
Loss = 6.5043e-04, PNorm = 60.4182, GNorm = 0.8015, lr_0 = 5.7278e-04
Loss = 6.1012e-04, PNorm = 60.4329, GNorm = 0.5561, lr_0 = 5.7025e-04
Loss = 4.7234e-04, PNorm = 60.4574, GNorm = 0.5134, lr_0 = 5.6773e-04
Loss = 6.1726e-04, PNorm = 60.4697, GNorm = 0.7818, lr_0 = 5.6522e-04
Loss = 6.7668e-04, PNorm = 60.4893, GNorm = 0.8046, lr_0 = 5.6272e-04
Validation rmse logD = 0.592973
Validation R2 logD = 0.763966
Epoch 26
Train function
Loss = 6.1189e-04, PNorm = 60.5152, GNorm = 0.3575, lr_0 = 5.5998e-04
Loss = 6.8676e-04, PNorm = 60.5356, GNorm = 0.5066, lr_0 = 5.5750e-04
Loss = 6.9613e-04, PNorm = 60.5564, GNorm = 0.9847, lr_0 = 5.5503e-04
Loss = 6.5651e-04, PNorm = 60.5837, GNorm = 1.9083, lr_0 = 5.5258e-04
Loss = 7.2603e-04, PNorm = 60.6095, GNorm = 0.3329, lr_0 = 5.5014e-04
Validation rmse logD = 0.590360
Validation R2 logD = 0.766042
Epoch 27
Train function
Loss = 4.7343e-04, PNorm = 60.6335, GNorm = 1.0869, lr_0 = 5.4746e-04
Loss = 7.2916e-04, PNorm = 60.6532, GNorm = 0.4958, lr_0 = 5.4504e-04
Loss = 5.7840e-04, PNorm = 60.6746, GNorm = 0.5970, lr_0 = 5.4263e-04
Loss = 5.4329e-04, PNorm = 60.7010, GNorm = 0.5624, lr_0 = 5.4023e-04
Loss = 5.9649e-04, PNorm = 60.7202, GNorm = 0.8088, lr_0 = 5.3784e-04
Validation rmse logD = 0.592720
Validation R2 logD = 0.764168
Epoch 28
Train function
Loss = 5.0669e-04, PNorm = 60.7356, GNorm = 0.3922, lr_0 = 5.3522e-04
Loss = 4.7635e-04, PNorm = 60.7558, GNorm = 0.6988, lr_0 = 5.3285e-04
Loss = 6.1118e-04, PNorm = 60.7733, GNorm = 0.3765, lr_0 = 5.3050e-04
Loss = 5.6073e-04, PNorm = 60.7928, GNorm = 0.6361, lr_0 = 5.2815e-04
Loss = 5.8743e-04, PNorm = 60.8157, GNorm = 0.5508, lr_0 = 5.2581e-04
Loss = 6.7975e-04, PNorm = 60.8389, GNorm = 1.5927, lr_0 = 5.2349e-04
Loss = 2.8587e-03, PNorm = 60.8402, GNorm = 1.5890, lr_0 = 5.2326e-04
Validation rmse logD = 0.598890
Validation R2 logD = 0.759232
Epoch 29
Train function
Loss = 5.0528e-04, PNorm = 60.8570, GNorm = 0.2659, lr_0 = 5.2094e-04
Loss = 5.7912e-04, PNorm = 60.8847, GNorm = 0.5283, lr_0 = 5.1864e-04
Loss = 4.6162e-04, PNorm = 60.9036, GNorm = 0.6098, lr_0 = 5.1634e-04
Loss = 6.4459e-04, PNorm = 60.9236, GNorm = 1.8560, lr_0 = 5.1406e-04
Loss = 5.8502e-04, PNorm = 60.9443, GNorm = 1.2487, lr_0 = 5.1178e-04
Validation rmse logD = 0.644086
Validation R2 logD = 0.721521
Epoch 30
Train function
Loss = 8.8968e-04, PNorm = 60.9610, GNorm = 1.4038, lr_0 = 5.0930e-04
Loss = 6.4698e-04, PNorm = 60.9983, GNorm = 0.9095, lr_0 = 5.0704e-04
Loss = 5.3470e-04, PNorm = 61.0195, GNorm = 0.4796, lr_0 = 5.0480e-04
Loss = 4.3636e-04, PNorm = 61.0379, GNorm = 0.7268, lr_0 = 5.0257e-04
Loss = 4.9889e-04, PNorm = 61.0512, GNorm = 0.8686, lr_0 = 5.0034e-04
Validation rmse logD = 0.591365
Validation R2 logD = 0.765245
Epoch 31
Train function
Loss = 4.5002e-04, PNorm = 61.0764, GNorm = 0.8229, lr_0 = 4.9791e-04
Loss = 3.8469e-04, PNorm = 61.0902, GNorm = 0.5198, lr_0 = 4.9571e-04
Loss = 4.2576e-04, PNorm = 61.1046, GNorm = 0.8381, lr_0 = 4.9351e-04
Loss = 4.2776e-04, PNorm = 61.1144, GNorm = 1.0061, lr_0 = 4.9133e-04
Loss = 4.8728e-04, PNorm = 61.1306, GNorm = 0.3511, lr_0 = 4.8916e-04
Validation rmse logD = 0.580379
Validation R2 logD = 0.773885
Epoch 32
Train function
Loss = 2.6141e-04, PNorm = 61.1499, GNorm = 0.3056, lr_0 = 4.8678e-04
Loss = 4.0784e-04, PNorm = 61.1700, GNorm = 0.6595, lr_0 = 4.8463e-04
Loss = 3.3483e-04, PNorm = 61.1880, GNorm = 0.2749, lr_0 = 4.8248e-04
Loss = 4.2892e-04, PNorm = 61.2030, GNorm = 0.3309, lr_0 = 4.8035e-04
Loss = 3.2154e-04, PNorm = 61.2181, GNorm = 0.4553, lr_0 = 4.7822e-04
Loss = 3.4926e-04, PNorm = 61.2303, GNorm = 0.3456, lr_0 = 4.7611e-04
Validation rmse logD = 0.591453
Validation R2 logD = 0.765174
Epoch 33
Train function
Loss = 4.0001e-04, PNorm = 61.2432, GNorm = 0.2586, lr_0 = 4.7379e-04
Loss = 3.7568e-04, PNorm = 61.2572, GNorm = 0.3907, lr_0 = 4.7170e-04
Loss = 3.4045e-04, PNorm = 61.2736, GNorm = 0.8727, lr_0 = 4.6961e-04
Loss = 3.5724e-04, PNorm = 61.2879, GNorm = 0.3206, lr_0 = 4.6753e-04
Loss = 3.1911e-04, PNorm = 61.3010, GNorm = 0.3630, lr_0 = 4.6546e-04
Validation rmse logD = 0.589381
Validation R2 logD = 0.766817
Epoch 34
Train function
Loss = 3.8372e-04, PNorm = 61.3102, GNorm = 1.0074, lr_0 = 4.6341e-04
Loss = 3.6516e-04, PNorm = 61.3278, GNorm = 1.1330, lr_0 = 4.6136e-04
Loss = 3.0856e-04, PNorm = 61.3406, GNorm = 1.0092, lr_0 = 4.5931e-04
Loss = 3.7429e-04, PNorm = 61.3502, GNorm = 1.5108, lr_0 = 4.5728e-04
Loss = 3.6169e-04, PNorm = 61.3634, GNorm = 0.7490, lr_0 = 4.5526e-04
Validation rmse logD = 0.586877
Validation R2 logD = 0.768794
Epoch 35
Train function
Loss = 1.3922e-04, PNorm = 61.3787, GNorm = 0.2843, lr_0 = 4.5305e-04
Loss = 3.0241e-04, PNorm = 61.3955, GNorm = 0.5086, lr_0 = 4.5104e-04
Loss = 3.7263e-04, PNorm = 61.4048, GNorm = 0.7456, lr_0 = 4.4905e-04
Loss = 3.3288e-04, PNorm = 61.4203, GNorm = 0.4365, lr_0 = 4.4706e-04
Loss = 3.2545e-04, PNorm = 61.4364, GNorm = 0.5618, lr_0 = 4.4508e-04
Loss = 3.6871e-04, PNorm = 61.4526, GNorm = 0.7038, lr_0 = 4.4311e-04
Validation rmse logD = 0.588558
Validation R2 logD = 0.767467
Epoch 36
Train function
Loss = 3.6636e-04, PNorm = 61.4653, GNorm = 0.8800, lr_0 = 4.4096e-04
Loss = 3.0568e-04, PNorm = 61.4848, GNorm = 0.3465, lr_0 = 4.3901e-04
Loss = 3.1929e-04, PNorm = 61.5009, GNorm = 0.5070, lr_0 = 4.3707e-04
Loss = 3.2106e-04, PNorm = 61.5135, GNorm = 0.4454, lr_0 = 4.3513e-04
Loss = 2.9289e-04, PNorm = 61.5215, GNorm = 0.4481, lr_0 = 4.3321e-04
Validation rmse logD = 0.585054
Validation R2 logD = 0.770228
Epoch 37
Train function
Loss = 2.6350e-04, PNorm = 61.5368, GNorm = 0.5023, lr_0 = 4.3110e-04
Loss = 2.6762e-04, PNorm = 61.5476, GNorm = 0.2292, lr_0 = 4.2919e-04
Loss = 2.7613e-04, PNorm = 61.5573, GNorm = 0.2983, lr_0 = 4.2729e-04
Loss = 2.9295e-04, PNorm = 61.5728, GNorm = 0.2895, lr_0 = 4.2540e-04
Loss = 2.6287e-04, PNorm = 61.5849, GNorm = 0.3367, lr_0 = 4.2352e-04
Validation rmse logD = 0.588899
Validation R2 logD = 0.767198
Epoch 38
Train function
Loss = 1.6612e-04, PNorm = 61.5934, GNorm = 0.3827, lr_0 = 4.2146e-04
Loss = 2.2127e-04, PNorm = 61.6032, GNorm = 0.6865, lr_0 = 4.1960e-04
Loss = 2.4406e-04, PNorm = 61.6134, GNorm = 0.2283, lr_0 = 4.1774e-04
Loss = 2.2287e-04, PNorm = 61.6209, GNorm = 0.2679, lr_0 = 4.1589e-04
Loss = 2.2251e-04, PNorm = 61.6294, GNorm = 1.1888, lr_0 = 4.1406e-04
Loss = 3.0464e-04, PNorm = 61.6398, GNorm = 0.8324, lr_0 = 4.1222e-04
Validation rmse logD = 0.593774
Validation R2 logD = 0.763328
Epoch 39
Train function
Loss = 3.4905e-04, PNorm = 61.6536, GNorm = 0.4157, lr_0 = 4.1022e-04
Loss = 2.0249e-04, PNorm = 61.6656, GNorm = 0.2640, lr_0 = 4.0840e-04
Loss = 2.2793e-04, PNorm = 61.6790, GNorm = 0.3161, lr_0 = 4.0660e-04
Loss = 2.0597e-04, PNorm = 61.6933, GNorm = 0.2397, lr_0 = 4.0480e-04
Loss = 2.3768e-04, PNorm = 61.7007, GNorm = 0.9766, lr_0 = 4.0301e-04
Validation rmse logD = 0.593666
Validation R2 logD = 0.763414
Epoch 40
Train function
Loss = 2.4922e-04, PNorm = 61.7089, GNorm = 0.4736, lr_0 = 4.0105e-04
Loss = 2.1408e-04, PNorm = 61.7211, GNorm = 0.2865, lr_0 = 3.9927e-04
Loss = 2.3877e-04, PNorm = 61.7332, GNorm = 0.7423, lr_0 = 3.9751e-04
Loss = 2.7748e-04, PNorm = 61.7435, GNorm = 0.9908, lr_0 = 3.9575e-04
Loss = 2.4048e-04, PNorm = 61.7574, GNorm = 0.2655, lr_0 = 3.9400e-04
Validation rmse logD = 0.589551
Validation R2 logD = 0.766682
Epoch 41
Train function
Loss = 1.9954e-04, PNorm = 61.7671, GNorm = 0.2842, lr_0 = 3.9208e-04
Loss = 2.0805e-04, PNorm = 61.7744, GNorm = 0.2209, lr_0 = 3.9035e-04
Loss = 1.6174e-04, PNorm = 61.7861, GNorm = 0.2500, lr_0 = 3.8862e-04
Loss = 1.7256e-04, PNorm = 61.7918, GNorm = 0.2088, lr_0 = 3.8690e-04
Loss = 1.9305e-04, PNorm = 61.7965, GNorm = 0.2965, lr_0 = 3.8519e-04
Loss = 1.7603e-04, PNorm = 61.8054, GNorm = 0.2590, lr_0 = 3.8349e-04
Validation rmse logD = 0.592919
Validation R2 logD = 0.764009
Epoch 42
Train function
Loss = 1.8971e-04, PNorm = 61.8133, GNorm = 0.2082, lr_0 = 3.8179e-04
Loss = 1.9888e-04, PNorm = 61.8210, GNorm = 0.2357, lr_0 = 3.8010e-04
Loss = 1.8182e-04, PNorm = 61.8293, GNorm = 0.5413, lr_0 = 3.7842e-04
Loss = 1.8756e-04, PNorm = 61.8398, GNorm = 0.5689, lr_0 = 3.7675e-04
Loss = 1.7716e-04, PNorm = 61.8446, GNorm = 0.1646, lr_0 = 3.7508e-04
Validation rmse logD = 0.587386
Validation R2 logD = 0.768393
Epoch 43
Train function
Loss = 1.7253e-04, PNorm = 61.8553, GNorm = 0.5066, lr_0 = 3.7326e-04
Loss = 1.4747e-04, PNorm = 61.8669, GNorm = 0.2212, lr_0 = 3.7160e-04
Loss = 1.8202e-04, PNorm = 61.8750, GNorm = 0.2072, lr_0 = 3.6996e-04
Loss = 1.6933e-04, PNorm = 61.8852, GNorm = 0.3678, lr_0 = 3.6832e-04
Loss = 1.5311e-04, PNorm = 61.8945, GNorm = 0.3201, lr_0 = 3.6669e-04
Validation rmse logD = 0.590020
Validation R2 logD = 0.766311
Epoch 44
Train function
Loss = 1.6155e-04, PNorm = 61.9047, GNorm = 0.4536, lr_0 = 3.6491e-04
Loss = 1.6756e-04, PNorm = 61.9140, GNorm = 0.5311, lr_0 = 3.6330e-04
Loss = 1.8177e-04, PNorm = 61.9198, GNorm = 0.3463, lr_0 = 3.6169e-04
Loss = 1.5894e-04, PNorm = 61.9287, GNorm = 0.3227, lr_0 = 3.6009e-04
Loss = 1.3163e-04, PNorm = 61.9355, GNorm = 0.3253, lr_0 = 3.5850e-04
Loss = 1.7458e-04, PNorm = 61.9422, GNorm = 0.3664, lr_0 = 3.5691e-04
Loss = 1.3760e-03, PNorm = 61.9432, GNorm = 0.9754, lr_0 = 3.5675e-04
Validation rmse logD = 0.593014
Validation R2 logD = 0.763934
Epoch 45
Train function
Loss = 1.6181e-04, PNorm = 61.9485, GNorm = 0.3635, lr_0 = 3.5518e-04
Loss = 1.5066e-04, PNorm = 61.9533, GNorm = 0.3132, lr_0 = 3.5360e-04
Loss = 1.5611e-04, PNorm = 61.9645, GNorm = 0.2725, lr_0 = 3.5204e-04
Loss = 1.3119e-04, PNorm = 61.9733, GNorm = 0.2257, lr_0 = 3.5048e-04
Loss = 1.2892e-04, PNorm = 61.9791, GNorm = 0.3622, lr_0 = 3.4893e-04
Validation rmse logD = 0.595192
Validation R2 logD = 0.762196
Epoch 46
Train function
Loss = 1.8715e-04, PNorm = 61.9865, GNorm = 0.5386, lr_0 = 3.4724e-04
Loss = 1.7801e-04, PNorm = 61.9952, GNorm = 1.0322, lr_0 = 3.4570e-04
Loss = 2.0639e-04, PNorm = 62.0020, GNorm = 1.0770, lr_0 = 3.4417e-04
Loss = 1.6565e-04, PNorm = 62.0123, GNorm = 0.4048, lr_0 = 3.4265e-04
Loss = 1.6795e-04, PNorm = 62.0197, GNorm = 0.9170, lr_0 = 3.4113e-04
Validation rmse logD = 0.583574
Validation R2 logD = 0.771389
Epoch 47
Train function
Loss = 1.2600e-04, PNorm = 62.0305, GNorm = 0.3913, lr_0 = 3.3947e-04
Loss = 1.4394e-04, PNorm = 62.0377, GNorm = 0.3254, lr_0 = 3.3797e-04
Loss = 1.7316e-04, PNorm = 62.0438, GNorm = 0.3603, lr_0 = 3.3648e-04
Loss = 1.3095e-04, PNorm = 62.0532, GNorm = 0.4929, lr_0 = 3.3499e-04
Loss = 1.7323e-04, PNorm = 62.0597, GNorm = 0.5981, lr_0 = 3.3351e-04
Validation rmse logD = 0.590364
Validation R2 logD = 0.766038
Epoch 48
Train function
Loss = 1.7572e-04, PNorm = 62.0676, GNorm = 0.8112, lr_0 = 3.3188e-04
Loss = 1.6080e-04, PNorm = 62.0778, GNorm = 0.6181, lr_0 = 3.3042e-04
Loss = 1.5260e-04, PNorm = 62.0876, GNorm = 0.3326, lr_0 = 3.2895e-04
Loss = 1.1408e-04, PNorm = 62.0931, GNorm = 0.2907, lr_0 = 3.2750e-04
Loss = 1.3693e-04, PNorm = 62.0979, GNorm = 0.3280, lr_0 = 3.2605e-04
Loss = 1.4850e-04, PNorm = 62.1020, GNorm = 0.2153, lr_0 = 3.2461e-04
Validation rmse logD = 0.587471
Validation R2 logD = 0.768326
Epoch 49
Train function
Loss = 1.1164e-04, PNorm = 62.1115, GNorm = 0.2458, lr_0 = 3.2303e-04
Loss = 1.5822e-04, PNorm = 62.1155, GNorm = 0.3129, lr_0 = 3.2160e-04
Loss = 1.0954e-04, PNorm = 62.1218, GNorm = 0.2652, lr_0 = 3.2018e-04
Loss = 1.1240e-04, PNorm = 62.1279, GNorm = 0.4074, lr_0 = 3.1876e-04
Loss = 1.1780e-04, PNorm = 62.1340, GNorm = 0.1842, lr_0 = 3.1735e-04
Validation rmse logD = 0.587752
Validation R2 logD = 0.768104
Epoch 50
Train function
Loss = 1.0310e-04, PNorm = 62.1403, GNorm = 0.1462, lr_0 = 3.1595e-04
Loss = 1.2559e-04, PNorm = 62.1485, GNorm = 0.2249, lr_0 = 3.1455e-04
Loss = 1.4528e-04, PNorm = 62.1567, GNorm = 0.7463, lr_0 = 3.1316e-04
Loss = 1.1381e-04, PNorm = 62.1646, GNorm = 0.2512, lr_0 = 3.1177e-04
Loss = 1.1098e-04, PNorm = 62.1726, GNorm = 0.3051, lr_0 = 3.1039e-04
Validation rmse logD = 0.588841
Validation R2 logD = 0.767244
Epoch 51
Train function
Loss = 5.6971e-05, PNorm = 62.1789, GNorm = 0.3930, lr_0 = 3.0888e-04
Loss = 1.1499e-04, PNorm = 62.1852, GNorm = 0.2653, lr_0 = 3.0752e-04
Loss = 1.0633e-04, PNorm = 62.1912, GNorm = 0.3267, lr_0 = 3.0616e-04
Loss = 1.0007e-04, PNorm = 62.1965, GNorm = 0.1551, lr_0 = 3.0480e-04
Loss = 8.5040e-05, PNorm = 62.2023, GNorm = 0.2499, lr_0 = 3.0346e-04
Loss = 1.1217e-04, PNorm = 62.2050, GNorm = 0.4987, lr_0 = 3.0211e-04
Validation rmse logD = 0.597690
Validation R2 logD = 0.760196
Epoch 52
Train function
Loss = 1.2593e-04, PNorm = 62.2101, GNorm = 0.5172, lr_0 = 3.0064e-04
Loss = 1.1888e-04, PNorm = 62.2147, GNorm = 0.1994, lr_0 = 2.9931e-04
Loss = 1.3250e-04, PNorm = 62.2203, GNorm = 0.2393, lr_0 = 2.9799e-04
Loss = 1.1138e-04, PNorm = 62.2266, GNorm = 0.3528, lr_0 = 2.9667e-04
Loss = 1.0514e-04, PNorm = 62.2333, GNorm = 0.5889, lr_0 = 2.9536e-04
Validation rmse logD = 0.589448
Validation R2 logD = 0.766764
Epoch 53
Train function
Loss = 1.2535e-04, PNorm = 62.2396, GNorm = 0.1998, lr_0 = 2.9392e-04
Loss = 1.1916e-04, PNorm = 62.2460, GNorm = 0.5516, lr_0 = 2.9262e-04
Loss = 1.1808e-04, PNorm = 62.2530, GNorm = 0.4819, lr_0 = 2.9133e-04
Loss = 1.0766e-04, PNorm = 62.2611, GNorm = 0.4584, lr_0 = 2.9004e-04
Loss = 9.5378e-05, PNorm = 62.2653, GNorm = 0.2617, lr_0 = 2.8876e-04
Validation rmse logD = 0.589830
Validation R2 logD = 0.766461
Epoch 54
Train function
Loss = 5.7430e-05, PNorm = 62.2697, GNorm = 0.1899, lr_0 = 2.8735e-04
Loss = 8.0892e-05, PNorm = 62.2744, GNorm = 0.1796, lr_0 = 2.8608e-04
Loss = 9.8820e-05, PNorm = 62.2769, GNorm = 0.3328, lr_0 = 2.8482e-04
Loss = 8.2806e-05, PNorm = 62.2830, GNorm = 0.2746, lr_0 = 2.8356e-04
Loss = 8.8521e-05, PNorm = 62.2883, GNorm = 0.2465, lr_0 = 2.8230e-04
Loss = 9.0502e-05, PNorm = 62.2934, GNorm = 0.1156, lr_0 = 2.8105e-04
Validation rmse logD = 0.590942
Validation R2 logD = 0.765580
Epoch 55
Train function
Loss = 6.1296e-05, PNorm = 62.2983, GNorm = 0.2605, lr_0 = 2.7969e-04
Loss = 7.3883e-05, PNorm = 62.3020, GNorm = 0.2154, lr_0 = 2.7845e-04
Loss = 6.6821e-05, PNorm = 62.3053, GNorm = 0.1680, lr_0 = 2.7722e-04
Loss = 8.3727e-05, PNorm = 62.3094, GNorm = 0.4898, lr_0 = 2.7599e-04
Loss = 7.3831e-05, PNorm = 62.3132, GNorm = 0.2539, lr_0 = 2.7477e-04
Validation rmse logD = 0.592247
Validation R2 logD = 0.764544
Epoch 56
Train function
Loss = 6.4882e-05, PNorm = 62.3158, GNorm = 0.2155, lr_0 = 2.7343e-04
Loss = 6.4029e-05, PNorm = 62.3216, GNorm = 0.1196, lr_0 = 2.7222e-04
Loss = 7.3164e-05, PNorm = 62.3269, GNorm = 0.2144, lr_0 = 2.7102e-04
Loss = 8.3981e-05, PNorm = 62.3303, GNorm = 0.6601, lr_0 = 2.6982e-04
Loss = 9.7016e-05, PNorm = 62.3363, GNorm = 0.2616, lr_0 = 2.6863e-04
Validation rmse logD = 0.595603
Validation R2 logD = 0.761868
Epoch 57
Train function
Loss = 8.2532e-05, PNorm = 62.3423, GNorm = 0.5742, lr_0 = 2.6732e-04
Loss = 6.5874e-05, PNorm = 62.3473, GNorm = 0.3280, lr_0 = 2.6614e-04
Loss = 7.1409e-05, PNorm = 62.3520, GNorm = 0.4502, lr_0 = 2.6496e-04
Loss = 8.8421e-05, PNorm = 62.3563, GNorm = 0.4551, lr_0 = 2.6379e-04
Loss = 7.4549e-05, PNorm = 62.3618, GNorm = 0.5742, lr_0 = 2.6262e-04
Loss = 6.9874e-05, PNorm = 62.3668, GNorm = 0.1719, lr_0 = 2.6146e-04
Loss = 5.8863e-05, PNorm = 62.3671, GNorm = 0.1572, lr_0 = 2.6134e-04
Validation rmse logD = 0.595053
Validation R2 logD = 0.762307
Epoch 58
Train function
Loss = 6.5083e-05, PNorm = 62.3701, GNorm = 0.1825, lr_0 = 2.6019e-04
Loss = 5.1574e-05, PNorm = 62.3733, GNorm = 0.1900, lr_0 = 2.5904e-04
Loss = 7.6981e-05, PNorm = 62.3779, GNorm = 0.3552, lr_0 = 2.5789e-04
Loss = 6.6754e-05, PNorm = 62.3800, GNorm = 0.1644, lr_0 = 2.5675e-04
Loss = 5.6112e-05, PNorm = 62.3845, GNorm = 0.2936, lr_0 = 2.5561e-04
Validation rmse logD = 0.591542
Validation R2 logD = 0.765104
Epoch 59
Train function
Loss = 7.7115e-05, PNorm = 62.3878, GNorm = 0.2106, lr_0 = 2.5448e-04
Loss = 6.9753e-05, PNorm = 62.3908, GNorm = 0.2321, lr_0 = 2.5336e-04
Loss = 5.2246e-05, PNorm = 62.3967, GNorm = 0.1214, lr_0 = 2.5224e-04
Loss = 5.3707e-05, PNorm = 62.4008, GNorm = 0.1307, lr_0 = 2.5112e-04
Loss = 7.1811e-05, PNorm = 62.4052, GNorm = 0.2637, lr_0 = 2.5001e-04
Validation rmse logD = 0.592130
Validation R2 logD = 0.764636
Epoch 60
Train function
Loss = 4.7958e-05, PNorm = 62.4082, GNorm = 0.1756, lr_0 = 2.4879e-04
Loss = 6.9198e-05, PNorm = 62.4115, GNorm = 0.4650, lr_0 = 2.4769e-04
Loss = 5.5655e-05, PNorm = 62.4154, GNorm = 0.1466, lr_0 = 2.4660e-04
Loss = 6.7775e-05, PNorm = 62.4184, GNorm = 0.3545, lr_0 = 2.4551e-04
Loss = 6.5410e-05, PNorm = 62.4229, GNorm = 0.1903, lr_0 = 2.4442e-04
Loss = 9.3143e-05, PNorm = 62.4276, GNorm = 0.2436, lr_0 = 2.4334e-04
Loss = 2.0216e-04, PNorm = 62.4281, GNorm = 0.3489, lr_0 = 2.4323e-04
Validation rmse logD = 0.595612
Validation R2 logD = 0.761860
Epoch 61
Train function
Loss = 5.8651e-05, PNorm = 62.4313, GNorm = 0.2723, lr_0 = 2.4216e-04
Loss = 4.7383e-05, PNorm = 62.4350, GNorm = 0.1644, lr_0 = 2.4109e-04
Loss = 6.6655e-05, PNorm = 62.4384, GNorm = 0.2650, lr_0 = 2.4002e-04
Loss = 5.0299e-05, PNorm = 62.4416, GNorm = 0.1538, lr_0 = 2.3896e-04
Loss = 6.3703e-05, PNorm = 62.4455, GNorm = 0.1383, lr_0 = 2.3790e-04
Validation rmse logD = 0.593720
Validation R2 logD = 0.763371
Epoch 62
Train function
Loss = 5.9943e-05, PNorm = 62.4473, GNorm = 0.1475, lr_0 = 2.3674e-04
Loss = 5.7654e-05, PNorm = 62.4534, GNorm = 0.3510, lr_0 = 2.3570e-04
Loss = 5.9797e-05, PNorm = 62.4573, GNorm = 0.4539, lr_0 = 2.3465e-04
Loss = 7.4116e-05, PNorm = 62.4643, GNorm = 0.3048, lr_0 = 2.3362e-04
Loss = 5.6894e-05, PNorm = 62.4687, GNorm = 0.1784, lr_0 = 2.3258e-04
Validation rmse logD = 0.593230
Validation R2 logD = 0.763761
Epoch 63
Train function
Loss = 6.0330e-05, PNorm = 62.4720, GNorm = 0.2314, lr_0 = 2.3145e-04
Loss = 5.1600e-05, PNorm = 62.4725, GNorm = 0.1137, lr_0 = 2.3043e-04
Loss = 6.2240e-05, PNorm = 62.4747, GNorm = 0.4814, lr_0 = 2.2941e-04
Loss = 6.6696e-05, PNorm = 62.4806, GNorm = 0.1897, lr_0 = 2.2839e-04
Loss = 7.5620e-05, PNorm = 62.4830, GNorm = 0.6288, lr_0 = 2.2738e-04
Validation rmse logD = 0.593951
Validation R2 logD = 0.763186
Epoch 64
Train function
Loss = 3.4979e-05, PNorm = 62.4885, GNorm = 0.2491, lr_0 = 2.2628e-04
Loss = 5.6136e-05, PNorm = 62.4942, GNorm = 0.4976, lr_0 = 2.2528e-04
Loss = 6.4981e-05, PNorm = 62.4963, GNorm = 0.3601, lr_0 = 2.2428e-04
Loss = 6.4333e-05, PNorm = 62.4996, GNorm = 0.2873, lr_0 = 2.2329e-04
Loss = 6.3582e-05, PNorm = 62.5030, GNorm = 0.1173, lr_0 = 2.2230e-04
Loss = 6.9323e-05, PNorm = 62.5077, GNorm = 0.1175, lr_0 = 2.2132e-04
Validation rmse logD = 0.593128
Validation R2 logD = 0.763842
Epoch 65
Train function
Loss = 4.6876e-05, PNorm = 62.5112, GNorm = 0.1760, lr_0 = 2.2024e-04
Loss = 4.8731e-05, PNorm = 62.5128, GNorm = 0.2288, lr_0 = 2.1927e-04
Loss = 5.2912e-05, PNorm = 62.5159, GNorm = 0.3199, lr_0 = 2.1830e-04
Loss = 6.2631e-05, PNorm = 62.5203, GNorm = 0.2394, lr_0 = 2.1733e-04
Loss = 4.2659e-05, PNorm = 62.5227, GNorm = 0.1388, lr_0 = 2.1637e-04
Validation rmse logD = 0.596506
Validation R2 logD = 0.761145
Epoch 66
Train function
Loss = 4.6680e-05, PNorm = 62.5264, GNorm = 0.1912, lr_0 = 2.1532e-04
Loss = 4.8639e-05, PNorm = 62.5285, GNorm = 0.3744, lr_0 = 2.1436e-04
Loss = 4.3791e-05, PNorm = 62.5324, GNorm = 0.1686, lr_0 = 2.1342e-04
Loss = 4.0675e-05, PNorm = 62.5348, GNorm = 0.2778, lr_0 = 2.1247e-04
Loss = 5.1579e-05, PNorm = 62.5363, GNorm = 0.5092, lr_0 = 2.1153e-04
Validation rmse logD = 0.593092
Validation R2 logD = 0.763871
Epoch 67
Train function
Loss = 2.1506e-05, PNorm = 62.5390, GNorm = 0.1506, lr_0 = 2.1060e-04
Loss = 5.4190e-05, PNorm = 62.5425, GNorm = 0.1580, lr_0 = 2.0966e-04
Loss = 4.7043e-05, PNorm = 62.5445, GNorm = 0.1294, lr_0 = 2.0874e-04
Loss = 6.9721e-05, PNorm = 62.5462, GNorm = 0.4395, lr_0 = 2.0781e-04
Loss = 3.9330e-05, PNorm = 62.5490, GNorm = 0.1490, lr_0 = 2.0689e-04
Loss = 3.9601e-05, PNorm = 62.5525, GNorm = 0.1933, lr_0 = 2.0598e-04
Validation rmse logD = 0.593917
Validation R2 logD = 0.763213
Epoch 68
Train function
Loss = 2.7196e-05, PNorm = 62.5551, GNorm = 0.1224, lr_0 = 2.0498e-04
Loss = 3.4424e-05, PNorm = 62.5574, GNorm = 0.4799, lr_0 = 2.0407e-04
Loss = 2.9086e-05, PNorm = 62.5605, GNorm = 0.1130, lr_0 = 2.0317e-04
Loss = 3.5608e-05, PNorm = 62.5631, GNorm = 0.1427, lr_0 = 2.0227e-04
Loss = 5.0133e-05, PNorm = 62.5659, GNorm = 0.1351, lr_0 = 2.0137e-04
Validation rmse logD = 0.593272
Validation R2 logD = 0.763728
Epoch 69
Train function
Loss = 4.0799e-05, PNorm = 62.5706, GNorm = 0.4205, lr_0 = 2.0039e-04
Loss = 4.5395e-05, PNorm = 62.5738, GNorm = 0.2888, lr_0 = 1.9951e-04
Loss = 4.3954e-05, PNorm = 62.5763, GNorm = 0.4340, lr_0 = 1.9863e-04
Loss = 3.9491e-05, PNorm = 62.5784, GNorm = 0.1111, lr_0 = 1.9775e-04
Loss = 3.4865e-05, PNorm = 62.5807, GNorm = 0.2133, lr_0 = 1.9687e-04
Validation rmse logD = 0.594175
Validation R2 logD = 0.763008
Epoch 70
Train function
Loss = 2.2321e-05, PNorm = 62.5835, GNorm = 0.0931, lr_0 = 1.9592e-04
Loss = 2.4666e-05, PNorm = 62.5851, GNorm = 0.1485, lr_0 = 1.9505e-04
Loss = 3.7504e-05, PNorm = 62.5880, GNorm = 0.2315, lr_0 = 1.9419e-04
Loss = 2.8225e-05, PNorm = 62.5894, GNorm = 0.3427, lr_0 = 1.9333e-04
Loss = 4.2829e-05, PNorm = 62.5912, GNorm = 0.3508, lr_0 = 1.9247e-04
Loss = 3.1954e-05, PNorm = 62.5939, GNorm = 0.0946, lr_0 = 1.9162e-04
Validation rmse logD = 0.594304
Validation R2 logD = 0.762905
Epoch 71
Train function
Loss = 2.6790e-05, PNorm = 62.5963, GNorm = 0.1361, lr_0 = 1.9069e-04
Loss = 2.6620e-05, PNorm = 62.5992, GNorm = 0.1764, lr_0 = 1.8984e-04
Loss = 3.5797e-05, PNorm = 62.6021, GNorm = 0.1512, lr_0 = 1.8900e-04
Loss = 2.8737e-05, PNorm = 62.6037, GNorm = 0.2633, lr_0 = 1.8817e-04
Loss = 2.9276e-05, PNorm = 62.6054, GNorm = 0.0984, lr_0 = 1.8734e-04
Validation rmse logD = 0.593697
Validation R2 logD = 0.763389
Epoch 72
Train function
Loss = 2.8024e-05, PNorm = 62.6080, GNorm = 0.2306, lr_0 = 1.8643e-04
Loss = 2.5038e-05, PNorm = 62.6097, GNorm = 0.1769, lr_0 = 1.8560e-04
Loss = 2.6962e-05, PNorm = 62.6113, GNorm = 0.0955, lr_0 = 1.8478e-04
Loss = 2.7700e-05, PNorm = 62.6128, GNorm = 0.1832, lr_0 = 1.8396e-04
Loss = 3.6219e-05, PNorm = 62.6152, GNorm = 0.1327, lr_0 = 1.8315e-04
Validation rmse logD = 0.593823
Validation R2 logD = 0.763289
Epoch 73
Train function
Loss = 2.3902e-05, PNorm = 62.6170, GNorm = 0.1610, lr_0 = 1.8226e-04
Loss = 2.2942e-05, PNorm = 62.6186, GNorm = 0.0708, lr_0 = 1.8145e-04
Loss = 2.3156e-05, PNorm = 62.6204, GNorm = 0.0668, lr_0 = 1.8065e-04
Loss = 2.9054e-05, PNorm = 62.6223, GNorm = 0.0874, lr_0 = 1.7985e-04
Loss = 2.5456e-05, PNorm = 62.6243, GNorm = 0.1500, lr_0 = 1.7905e-04
Loss = 2.6307e-05, PNorm = 62.6268, GNorm = 0.0785, lr_0 = 1.7826e-04
Loss = 8.5579e-05, PNorm = 62.6272, GNorm = 0.2531, lr_0 = 1.7818e-04
Validation rmse logD = 0.595501
Validation R2 logD = 0.761949
Epoch 74
Train function
Loss = 2.2049e-05, PNorm = 62.6289, GNorm = 0.1537, lr_0 = 1.7739e-04
Loss = 1.9150e-05, PNorm = 62.6304, GNorm = 0.1813, lr_0 = 1.7661e-04
Loss = 3.1968e-05, PNorm = 62.6329, GNorm = 0.1834, lr_0 = 1.7583e-04
Loss = 2.2993e-05, PNorm = 62.6352, GNorm = 0.0836, lr_0 = 1.7505e-04
Loss = 2.4771e-05, PNorm = 62.6370, GNorm = 0.0865, lr_0 = 1.7428e-04
Validation rmse logD = 0.593313
Validation R2 logD = 0.763695
Epoch 75
Train function
Loss = 2.2354e-05, PNorm = 62.6384, GNorm = 0.2907, lr_0 = 1.7351e-04
Loss = 2.5336e-05, PNorm = 62.6406, GNorm = 0.1824, lr_0 = 1.7274e-04
Loss = 2.6770e-05, PNorm = 62.6424, GNorm = 0.0753, lr_0 = 1.7197e-04
Loss = 2.0764e-05, PNorm = 62.6447, GNorm = 0.1512, lr_0 = 1.7121e-04
Loss = 1.9582e-05, PNorm = 62.6467, GNorm = 0.1811, lr_0 = 1.7046e-04
Validation rmse logD = 0.595144
Validation R2 logD = 0.762234
Epoch 76
Train function
Loss = 2.9352e-05, PNorm = 62.6490, GNorm = 0.1157, lr_0 = 1.6963e-04
Loss = 2.2961e-05, PNorm = 62.6500, GNorm = 0.1843, lr_0 = 1.6888e-04
Loss = 2.9175e-05, PNorm = 62.6512, GNorm = 0.1568, lr_0 = 1.6813e-04
Loss = 2.5304e-05, PNorm = 62.6534, GNorm = 0.0726, lr_0 = 1.6739e-04
Loss = 3.2213e-05, PNorm = 62.6556, GNorm = 0.3469, lr_0 = 1.6665e-04
Loss = 2.3056e-05, PNorm = 62.6577, GNorm = 0.3875, lr_0 = 1.6591e-04
Loss = 1.7230e-04, PNorm = 62.6576, GNorm = 0.3156, lr_0 = 1.6584e-04
Validation rmse logD = 0.598387
Validation R2 logD = 0.759636
Epoch 77
Train function
Loss = 3.5093e-05, PNorm = 62.6594, GNorm = 0.2256, lr_0 = 1.6510e-04
Loss = 4.8193e-05, PNorm = 62.6610, GNorm = 0.3642, lr_0 = 1.6437e-04
Loss = 2.8120e-05, PNorm = 62.6636, GNorm = 0.2250, lr_0 = 1.6364e-04
Loss = 4.1609e-05, PNorm = 62.6659, GNorm = 0.1990, lr_0 = 1.6292e-04
Loss = 2.8733e-05, PNorm = 62.6682, GNorm = 0.0717, lr_0 = 1.6220e-04
Validation rmse logD = 0.595312
Validation R2 logD = 0.762100
Epoch 78
Train function
Loss = 2.9268e-05, PNorm = 62.6694, GNorm = 0.1187, lr_0 = 1.6141e-04
Loss = 4.3661e-05, PNorm = 62.6732, GNorm = 0.2976, lr_0 = 1.6070e-04
Loss = 3.2358e-05, PNorm = 62.6756, GNorm = 0.1826, lr_0 = 1.5999e-04
Loss = 3.2227e-05, PNorm = 62.6781, GNorm = 0.1363, lr_0 = 1.5928e-04
Loss = 5.1755e-05, PNorm = 62.6816, GNorm = 0.1236, lr_0 = 1.5857e-04
Validation rmse logD = 0.592812
Validation R2 logD = 0.764094
Epoch 79
Train function
Loss = 2.6705e-05, PNorm = 62.6832, GNorm = 0.1376, lr_0 = 1.5780e-04
Loss = 3.8914e-05, PNorm = 62.6853, GNorm = 0.1133, lr_0 = 1.5710e-04
Loss = 3.5746e-05, PNorm = 62.6886, GNorm = 0.1496, lr_0 = 1.5641e-04
Loss = 3.4952e-05, PNorm = 62.6913, GNorm = 0.1797, lr_0 = 1.5572e-04
Loss = 3.5159e-05, PNorm = 62.6931, GNorm = 0.2020, lr_0 = 1.5503e-04
Validation rmse logD = 0.597449
Validation R2 logD = 0.760389
Epoch 80
Train function
Loss = 3.3684e-05, PNorm = 62.6946, GNorm = 0.3472, lr_0 = 1.5427e-04
Loss = 3.1715e-05, PNorm = 62.6968, GNorm = 0.3925, lr_0 = 1.5359e-04
Loss = 3.7838e-05, PNorm = 62.6986, GNorm = 0.1144, lr_0 = 1.5291e-04
Loss = 2.9562e-05, PNorm = 62.7007, GNorm = 0.2060, lr_0 = 1.5224e-04
Loss = 2.9250e-05, PNorm = 62.7026, GNorm = 0.2599, lr_0 = 1.5156e-04
Loss = 2.7795e-05, PNorm = 62.7054, GNorm = 0.2622, lr_0 = 1.5089e-04
Validation rmse logD = 0.592130
Validation R2 logD = 0.764637
Epoch 81
Train function
Loss = 3.8164e-05, PNorm = 62.7056, GNorm = 0.2498, lr_0 = 1.5016e-04
Loss = 3.3886e-05, PNorm = 62.7075, GNorm = 0.2886, lr_0 = 1.4949e-04
Loss = 2.6810e-05, PNorm = 62.7103, GNorm = 0.1394, lr_0 = 1.4883e-04
Loss = 2.6260e-05, PNorm = 62.7124, GNorm = 0.1471, lr_0 = 1.4817e-04
Loss = 3.7956e-05, PNorm = 62.7144, GNorm = 0.0941, lr_0 = 1.4752e-04
Validation rmse logD = 0.597765
Validation R2 logD = 0.760135
Epoch 82
Train function
Loss = 3.2990e-05, PNorm = 62.7166, GNorm = 0.2686, lr_0 = 1.4680e-04
Loss = 2.5632e-05, PNorm = 62.7187, GNorm = 0.1198, lr_0 = 1.4615e-04
Loss = 3.0660e-05, PNorm = 62.7204, GNorm = 0.3417, lr_0 = 1.4551e-04
Loss = 2.2298e-05, PNorm = 62.7212, GNorm = 0.1178, lr_0 = 1.4486e-04
Loss = 3.1267e-05, PNorm = 62.7225, GNorm = 0.0630, lr_0 = 1.4422e-04
Validation rmse logD = 0.597362
Validation R2 logD = 0.760459
Epoch 83
Train function
Loss = 1.4434e-05, PNorm = 62.7242, GNorm = 0.2265, lr_0 = 1.4352e-04
Loss = 2.3244e-05, PNorm = 62.7263, GNorm = 0.0905, lr_0 = 1.4288e-04
Loss = 1.5745e-05, PNorm = 62.7269, GNorm = 0.0964, lr_0 = 1.4225e-04
Loss = 2.1216e-05, PNorm = 62.7283, GNorm = 0.2075, lr_0 = 1.4162e-04
Loss = 2.2057e-05, PNorm = 62.7291, GNorm = 0.1079, lr_0 = 1.4100e-04
Loss = 3.3203e-05, PNorm = 62.7311, GNorm = 0.3055, lr_0 = 1.4037e-04
Validation rmse logD = 0.595637
Validation R2 logD = 0.761841
Epoch 84
Train function
Loss = 1.6998e-05, PNorm = 62.7329, GNorm = 0.1847, lr_0 = 1.3975e-04
Loss = 1.4271e-05, PNorm = 62.7335, GNorm = 0.0816, lr_0 = 1.3913e-04
Loss = 2.8258e-05, PNorm = 62.7350, GNorm = 0.1544, lr_0 = 1.3852e-04
Loss = 2.0071e-05, PNorm = 62.7369, GNorm = 0.1035, lr_0 = 1.3791e-04
Loss = 1.8282e-05, PNorm = 62.7382, GNorm = 0.2573, lr_0 = 1.3730e-04
Validation rmse logD = 0.595397
Validation R2 logD = 0.762032
Epoch 85
Train function
Loss = 1.8230e-05, PNorm = 62.7397, GNorm = 0.0886, lr_0 = 1.3663e-04
Loss = 2.0192e-05, PNorm = 62.7412, GNorm = 0.1194, lr_0 = 1.3602e-04
Loss = 2.1783e-05, PNorm = 62.7429, GNorm = 0.0988, lr_0 = 1.3542e-04
Loss = 1.8325e-05, PNorm = 62.7449, GNorm = 0.0825, lr_0 = 1.3482e-04
Loss = 2.2794e-05, PNorm = 62.7464, GNorm = 0.3179, lr_0 = 1.3423e-04
Validation rmse logD = 0.596857
Validation R2 logD = 0.760864
Epoch 86
Train function
Loss = 1.7308e-05, PNorm = 62.7488, GNorm = 0.2779, lr_0 = 1.3357e-04
Loss = 2.2399e-05, PNorm = 62.7510, GNorm = 0.1350, lr_0 = 1.3298e-04
Loss = 1.8561e-05, PNorm = 62.7517, GNorm = 0.1488, lr_0 = 1.3239e-04
Loss = 1.9419e-05, PNorm = 62.7526, GNorm = 0.1509, lr_0 = 1.3181e-04
Loss = 1.1557e-05, PNorm = 62.7532, GNorm = 0.1430, lr_0 = 1.3123e-04
Loss = 2.0813e-05, PNorm = 62.7544, GNorm = 0.1341, lr_0 = 1.3065e-04
Validation rmse logD = 0.595267
Validation R2 logD = 0.762136
Epoch 87
Train function
Loss = 1.6413e-05, PNorm = 62.7551, GNorm = 0.1932, lr_0 = 1.3001e-04
Loss = 1.5243e-05, PNorm = 62.7576, GNorm = 0.0986, lr_0 = 1.2944e-04
Loss = 1.6464e-05, PNorm = 62.7585, GNorm = 0.0636, lr_0 = 1.2886e-04
Loss = 1.5783e-05, PNorm = 62.7595, GNorm = 0.1845, lr_0 = 1.2829e-04
Loss = 1.7293e-05, PNorm = 62.7603, GNorm = 0.0853, lr_0 = 1.2773e-04
Validation rmse logD = 0.593872
Validation R2 logD = 0.763250
Epoch 88
Train function
Loss = 2.2728e-05, PNorm = 62.7616, GNorm = 0.1817, lr_0 = 1.2710e-04
Loss = 2.8031e-05, PNorm = 62.7621, GNorm = 0.2912, lr_0 = 1.2654e-04
Loss = 2.9529e-05, PNorm = 62.7646, GNorm = 0.0964, lr_0 = 1.2598e-04
Loss = 2.6769e-05, PNorm = 62.7650, GNorm = 0.2683, lr_0 = 1.2542e-04
Loss = 2.7041e-05, PNorm = 62.7682, GNorm = 0.0947, lr_0 = 1.2487e-04
Validation rmse logD = 0.592285
Validation R2 logD = 0.764514
Epoch 89
Train function
Loss = 2.2327e-05, PNorm = 62.7691, GNorm = 0.2842, lr_0 = 1.2426e-04
Loss = 2.9732e-05, PNorm = 62.7720, GNorm = 0.2866, lr_0 = 1.2371e-04
Loss = 2.4205e-05, PNorm = 62.7740, GNorm = 0.2676, lr_0 = 1.2317e-04
Loss = 2.4641e-05, PNorm = 62.7767, GNorm = 0.0846, lr_0 = 1.2262e-04
Loss = 1.7796e-05, PNorm = 62.7774, GNorm = 0.1199, lr_0 = 1.2208e-04
Loss = 2.2403e-05, PNorm = 62.7776, GNorm = 0.2437, lr_0 = 1.2154e-04
Loss = 1.3582e-04, PNorm = 62.7775, GNorm = 0.2112, lr_0 = 1.2148e-04
Validation rmse logD = 0.595305
Validation R2 logD = 0.762106
Epoch 90
Train function
Loss = 1.3669e-05, PNorm = 62.7777, GNorm = 0.0981, lr_0 = 1.2095e-04
Loss = 2.0583e-05, PNorm = 62.7796, GNorm = 0.1670, lr_0 = 1.2041e-04
Loss = 1.6030e-05, PNorm = 62.7814, GNorm = 0.1715, lr_0 = 1.1988e-04
Loss = 1.2253e-05, PNorm = 62.7833, GNorm = 0.1410, lr_0 = 1.1935e-04
Loss = 1.5147e-05, PNorm = 62.7842, GNorm = 0.0690, lr_0 = 1.1882e-04
Validation rmse logD = 0.595238
Validation R2 logD = 0.762159
Epoch 91
Train function
Loss = 1.2634e-05, PNorm = 62.7857, GNorm = 0.1371, lr_0 = 1.1824e-04
Loss = 1.3593e-05, PNorm = 62.7868, GNorm = 0.2266, lr_0 = 1.1772e-04
Loss = 1.6938e-05, PNorm = 62.7881, GNorm = 0.2382, lr_0 = 1.1720e-04
Loss = 1.7679e-05, PNorm = 62.7893, GNorm = 0.2389, lr_0 = 1.1668e-04
Loss = 1.8571e-05, PNorm = 62.7890, GNorm = 0.1221, lr_0 = 1.1616e-04
Validation rmse logD = 0.596801
Validation R2 logD = 0.760909
Epoch 92
Train function
Loss = 1.0922e-05, PNorm = 62.7898, GNorm = 0.1306, lr_0 = 1.1565e-04
Loss = 1.6335e-05, PNorm = 62.7912, GNorm = 0.1841, lr_0 = 1.1514e-04
Loss = 1.5253e-05, PNorm = 62.7928, GNorm = 0.0673, lr_0 = 1.1463e-04
Loss = 1.4387e-05, PNorm = 62.7946, GNorm = 0.0915, lr_0 = 1.1412e-04
Loss = 1.3229e-05, PNorm = 62.7951, GNorm = 0.0874, lr_0 = 1.1362e-04
Loss = 1.6080e-05, PNorm = 62.7958, GNorm = 0.1852, lr_0 = 1.1312e-04
Loss = 1.6866e-04, PNorm = 62.7959, GNorm = 0.3355, lr_0 = 1.1307e-04
Validation rmse logD = 0.596729
Validation R2 logD = 0.760966
Epoch 93
Train function
Loss = 1.5609e-05, PNorm = 62.7961, GNorm = 0.2204, lr_0 = 1.1257e-04
Loss = 1.4624e-05, PNorm = 62.7974, GNorm = 0.0460, lr_0 = 1.1207e-04
Loss = 1.2836e-05, PNorm = 62.7984, GNorm = 0.1648, lr_0 = 1.1157e-04
Loss = 8.0874e-06, PNorm = 62.7991, GNorm = 0.0994, lr_0 = 1.1108e-04
Loss = 1.0164e-05, PNorm = 62.8001, GNorm = 0.0534, lr_0 = 1.1059e-04
Validation rmse logD = 0.596961
Validation R2 logD = 0.760780
Epoch 94
Train function
Loss = 7.8233e-06, PNorm = 62.8021, GNorm = 0.0327, lr_0 = 1.1005e-04
Loss = 9.7634e-06, PNorm = 62.8023, GNorm = 0.1018, lr_0 = 1.0956e-04
Loss = 9.2126e-06, PNorm = 62.8032, GNorm = 0.1169, lr_0 = 1.0908e-04
Loss = 1.5042e-05, PNorm = 62.8034, GNorm = 0.2515, lr_0 = 1.0860e-04
Loss = 1.2560e-05, PNorm = 62.8043, GNorm = 0.0726, lr_0 = 1.0811e-04
Validation rmse logD = 0.597461
Validation R2 logD = 0.760380
Epoch 95
Train function
Loss = 8.4849e-06, PNorm = 62.8052, GNorm = 0.0565, lr_0 = 1.0759e-04
Loss = 7.9717e-06, PNorm = 62.8060, GNorm = 0.0832, lr_0 = 1.0711e-04
Loss = 1.0914e-05, PNorm = 62.8064, GNorm = 0.0827, lr_0 = 1.0664e-04
Loss = 1.0763e-05, PNorm = 62.8068, GNorm = 0.0810, lr_0 = 1.0617e-04
Loss = 9.8085e-06, PNorm = 62.8075, GNorm = 0.1153, lr_0 = 1.0570e-04
Validation rmse logD = 0.596911
Validation R2 logD = 0.760820
Epoch 96
Train function
Loss = 1.4562e-05, PNorm = 62.8090, GNorm = 0.1474, lr_0 = 1.0518e-04
Loss = 6.9879e-06, PNorm = 62.8099, GNorm = 0.0970, lr_0 = 1.0472e-04
Loss = 9.4392e-06, PNorm = 62.8110, GNorm = 0.0636, lr_0 = 1.0426e-04
Loss = 1.1626e-05, PNorm = 62.8119, GNorm = 0.1346, lr_0 = 1.0379e-04
Loss = 9.9426e-06, PNorm = 62.8130, GNorm = 0.0799, lr_0 = 1.0333e-04
Loss = 7.6257e-06, PNorm = 62.8131, GNorm = 0.0677, lr_0 = 1.0288e-04
Validation rmse logD = 0.597555
Validation R2 logD = 0.760304
Epoch 97
Train function
Loss = 9.8203e-06, PNorm = 62.8138, GNorm = 0.0900, lr_0 = 1.0238e-04
Loss = 8.8156e-06, PNorm = 62.8148, GNorm = 0.0587, lr_0 = 1.0192e-04
Loss = 6.4124e-06, PNorm = 62.8150, GNorm = 0.0591, lr_0 = 1.0147e-04
Loss = 8.6734e-06, PNorm = 62.8158, GNorm = 0.0491, lr_0 = 1.0102e-04
Loss = 8.9580e-06, PNorm = 62.8171, GNorm = 0.1163, lr_0 = 1.0058e-04
Validation rmse logD = 0.597963
Validation R2 logD = 0.759976
Epoch 98
Train function
Loss = 8.7175e-06, PNorm = 62.8177, GNorm = 0.1028, lr_0 = 1.0009e-04
Loss = 1.0586e-05, PNorm = 62.8187, GNorm = 0.1702, lr_0 = 1.0000e-04
Loss = 7.3693e-06, PNorm = 62.8192, GNorm = 0.0636, lr_0 = 1.0000e-04
Loss = 9.4185e-06, PNorm = 62.8197, GNorm = 0.0712, lr_0 = 1.0000e-04
Loss = 1.0394e-05, PNorm = 62.8206, GNorm = 0.0397, lr_0 = 1.0000e-04
Validation rmse logD = 0.598412
Validation R2 logD = 0.759616
Epoch 99
Train function
Loss = 5.8086e-06, PNorm = 62.8224, GNorm = 0.1441, lr_0 = 1.0000e-04
Loss = 7.5373e-06, PNorm = 62.8239, GNorm = 0.0554, lr_0 = 1.0000e-04
Loss = 8.0117e-06, PNorm = 62.8239, GNorm = 0.0934, lr_0 = 1.0000e-04
Loss = 8.0459e-06, PNorm = 62.8239, GNorm = 0.1379, lr_0 = 1.0000e-04
Loss = 1.4433e-05, PNorm = 62.8247, GNorm = 0.2050, lr_0 = 1.0000e-04
Loss = 1.0471e-05, PNorm = 62.8253, GNorm = 0.0911, lr_0 = 1.0000e-04
Validation rmse logD = 0.595112
Validation R2 logD = 0.762260
Model 0 best validation rmse = 0.580379 on epoch 31
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.617083
Model 0 test R2 logD = 0.736637
Ensemble test rmse  logD= 0.617083
Ensemble test R2  logD= 0.736637
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_304/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=895, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,222,401
Moving model to cuda
Epoch 0
Train function
Loss = 2.0145e-02, PNorm = 52.4954, GNorm = 11.5217, lr_0 = 1.9340e-04
Loss = 1.8373e-02, PNorm = 52.5018, GNorm = 7.8033, lr_0 = 2.7830e-04
Loss = 1.7246e-02, PNorm = 52.5164, GNorm = 3.7618, lr_0 = 3.6321e-04
Loss = 1.6623e-02, PNorm = 52.5363, GNorm = 2.4647, lr_0 = 4.4811e-04
Loss = 1.5479e-02, PNorm = 52.5592, GNorm = 5.0087, lr_0 = 5.3302e-04
Validation rmse logD = 1.086686
Validation R2 logD = 0.177585
Epoch 1
Train function
Loss = 1.4799e-02, PNorm = 52.5941, GNorm = 2.8998, lr_0 = 6.2642e-04
Loss = 1.5750e-02, PNorm = 52.6513, GNorm = 1.4846, lr_0 = 7.1132e-04
Loss = 1.3412e-02, PNorm = 52.7243, GNorm = 1.7604, lr_0 = 7.9623e-04
Loss = 1.5209e-02, PNorm = 52.7931, GNorm = 2.6212, lr_0 = 8.8113e-04
Loss = 1.3549e-02, PNorm = 52.8666, GNorm = 5.2688, lr_0 = 9.6604e-04
Validation rmse logD = 0.943208
Validation R2 logD = 0.380419
Epoch 2
Train function
Loss = 9.9581e-03, PNorm = 52.9685, GNorm = 4.0908, lr_0 = 9.9690e-04
Loss = 1.2282e-02, PNorm = 53.0691, GNorm = 5.9877, lr_0 = 9.9249e-04
Loss = 1.1713e-02, PNorm = 53.1625, GNorm = 1.3740, lr_0 = 9.8810e-04
Loss = 9.9935e-03, PNorm = 53.2639, GNorm = 1.6553, lr_0 = 9.8373e-04
Loss = 1.0815e-02, PNorm = 53.3733, GNorm = 3.4679, lr_0 = 9.7938e-04
Validation rmse logD = 0.951631
Validation R2 logD = 0.369303
Epoch 3
Train function
Loss = 1.0736e-02, PNorm = 53.4866, GNorm = 1.9568, lr_0 = 9.7462e-04
Loss = 1.0690e-02, PNorm = 53.6262, GNorm = 1.6444, lr_0 = 9.7030e-04
Loss = 9.2077e-03, PNorm = 53.7633, GNorm = 3.8000, lr_0 = 9.6601e-04
Loss = 1.0889e-02, PNorm = 53.8386, GNorm = 1.9428, lr_0 = 9.6174e-04
Loss = 9.1801e-03, PNorm = 53.9467, GNorm = 3.1770, lr_0 = 9.5749e-04
Loss = 8.4227e-03, PNorm = 54.0519, GNorm = 1.4000, lr_0 = 9.5325e-04
Validation rmse logD = 0.765612
Validation R2 logD = 0.591774
Epoch 4
Train function
Loss = 7.5510e-03, PNorm = 54.1588, GNorm = 2.2145, lr_0 = 9.4861e-04
Loss = 8.8138e-03, PNorm = 54.2609, GNorm = 4.3783, lr_0 = 9.4442e-04
Loss = 8.2923e-03, PNorm = 54.3606, GNorm = 5.8754, lr_0 = 9.4024e-04
Loss = 7.4008e-03, PNorm = 54.4721, GNorm = 2.7959, lr_0 = 9.3608e-04
Loss = 7.4015e-03, PNorm = 54.5509, GNorm = 2.6338, lr_0 = 9.3194e-04
Validation rmse logD = 0.731277
Validation R2 logD = 0.627568
Epoch 5
Train function
Loss = 6.8154e-03, PNorm = 54.6472, GNorm = 1.1332, lr_0 = 9.2741e-04
Loss = 5.4228e-03, PNorm = 54.7405, GNorm = 1.2768, lr_0 = 9.2330e-04
Loss = 5.3794e-03, PNorm = 54.8337, GNorm = 5.8694, lr_0 = 9.1922e-04
Loss = 7.0496e-03, PNorm = 54.9181, GNorm = 0.9516, lr_0 = 9.1515e-04
Loss = 6.9725e-03, PNorm = 55.0259, GNorm = 1.0193, lr_0 = 9.1111e-04
Validation rmse logD = 0.674800
Validation R2 logD = 0.682873
Epoch 6
Train function
Loss = 6.9260e-03, PNorm = 55.1216, GNorm = 1.2164, lr_0 = 9.0667e-04
Loss = 5.3529e-03, PNorm = 55.2481, GNorm = 1.7377, lr_0 = 9.0266e-04
Loss = 5.3798e-03, PNorm = 55.3346, GNorm = 1.4400, lr_0 = 8.9867e-04
Loss = 5.2465e-03, PNorm = 55.4262, GNorm = 2.4088, lr_0 = 8.9469e-04
Loss = 5.8586e-03, PNorm = 55.5084, GNorm = 1.4991, lr_0 = 8.9074e-04
Loss = 5.3310e-03, PNorm = 55.5937, GNorm = 1.5742, lr_0 = 8.8680e-04
Validation rmse logD = 0.674657
Validation R2 logD = 0.683007
Epoch 7
Train function
Loss = 4.2636e-03, PNorm = 55.6814, GNorm = 2.6714, lr_0 = 8.8248e-04
Loss = 4.9490e-03, PNorm = 55.7637, GNorm = 1.5799, lr_0 = 8.7858e-04
Loss = 4.9442e-03, PNorm = 55.8447, GNorm = 1.4355, lr_0 = 8.7469e-04
Loss = 4.6856e-03, PNorm = 55.9175, GNorm = 0.7254, lr_0 = 8.7082e-04
Loss = 4.4888e-03, PNorm = 55.9908, GNorm = 2.0439, lr_0 = 8.6697e-04
Validation rmse logD = 0.708986
Validation R2 logD = 0.649928
Epoch 8
Train function
Loss = 4.5194e-03, PNorm = 56.0850, GNorm = 1.0548, lr_0 = 8.6276e-04
Loss = 4.6971e-03, PNorm = 56.1825, GNorm = 3.7611, lr_0 = 8.5894e-04
Loss = 4.3643e-03, PNorm = 56.2708, GNorm = 1.4266, lr_0 = 8.5514e-04
Loss = 4.3075e-03, PNorm = 56.3497, GNorm = 1.1266, lr_0 = 8.5136e-04
Loss = 4.3064e-03, PNorm = 56.4277, GNorm = 0.7765, lr_0 = 8.4759e-04
Validation rmse logD = 0.606698
Validation R2 logD = 0.743653
Epoch 9
Train function
Loss = 3.0053e-03, PNorm = 56.5014, GNorm = 1.1633, lr_0 = 8.4384e-04
Loss = 3.6269e-03, PNorm = 56.5668, GNorm = 1.3091, lr_0 = 8.4011e-04
Loss = 4.5175e-03, PNorm = 56.6465, GNorm = 3.8170, lr_0 = 8.3639e-04
Loss = 3.8635e-03, PNorm = 56.7077, GNorm = 2.0705, lr_0 = 8.3269e-04
Loss = 3.1376e-03, PNorm = 56.7870, GNorm = 1.6911, lr_0 = 8.2901e-04
Loss = 3.5135e-03, PNorm = 56.8511, GNorm = 1.0353, lr_0 = 8.2534e-04
Validation rmse logD = 0.587729
Validation R2 logD = 0.759433
Epoch 10
Train function
Loss = 3.2070e-03, PNorm = 56.9145, GNorm = 2.2299, lr_0 = 8.2133e-04
Loss = 3.1660e-03, PNorm = 56.9681, GNorm = 1.8533, lr_0 = 8.1770e-04
Loss = 3.1532e-03, PNorm = 57.0331, GNorm = 0.7485, lr_0 = 8.1408e-04
Loss = 3.6645e-03, PNorm = 57.1057, GNorm = 2.0402, lr_0 = 8.1048e-04
Loss = 3.2770e-03, PNorm = 57.1858, GNorm = 1.6031, lr_0 = 8.0689e-04
Validation rmse logD = 0.616033
Validation R2 logD = 0.735704
Epoch 11
Train function
Loss = 3.1066e-03, PNorm = 57.2625, GNorm = 2.4073, lr_0 = 8.0297e-04
Loss = 3.1062e-03, PNorm = 57.3358, GNorm = 0.9281, lr_0 = 7.9942e-04
Loss = 2.7055e-03, PNorm = 57.4138, GNorm = 1.5842, lr_0 = 7.9588e-04
Loss = 2.7683e-03, PNorm = 57.4808, GNorm = 1.0474, lr_0 = 7.9236e-04
Loss = 3.1379e-03, PNorm = 57.5319, GNorm = 2.3299, lr_0 = 7.8885e-04
Validation rmse logD = 0.629625
Validation R2 logD = 0.723912
Epoch 12
Train function
Loss = 3.9672e-03, PNorm = 57.6071, GNorm = 3.8633, lr_0 = 7.8502e-04
Loss = 3.1662e-03, PNorm = 57.6742, GNorm = 3.5379, lr_0 = 7.8154e-04
Loss = 2.8949e-03, PNorm = 57.7543, GNorm = 2.2414, lr_0 = 7.7809e-04
Loss = 2.1659e-03, PNorm = 57.8150, GNorm = 2.3992, lr_0 = 7.7465e-04
Loss = 2.2637e-03, PNorm = 57.8519, GNorm = 0.8273, lr_0 = 7.7122e-04
Loss = 2.6452e-03, PNorm = 57.8987, GNorm = 2.9740, lr_0 = 7.6781e-04
Loss = 1.1201e-02, PNorm = 57.9035, GNorm = 1.9328, lr_0 = 7.6747e-04
Validation rmse logD = 0.583399
Validation R2 logD = 0.762964
Epoch 13
Train function
Loss = 2.8191e-03, PNorm = 57.9613, GNorm = 5.4061, lr_0 = 7.6407e-04
Loss = 2.8202e-03, PNorm = 58.0241, GNorm = 2.6452, lr_0 = 7.6069e-04
Loss = 3.0531e-03, PNorm = 58.0871, GNorm = 3.2852, lr_0 = 7.5733e-04
Loss = 2.3566e-03, PNorm = 58.1743, GNorm = 1.1518, lr_0 = 7.5398e-04
Loss = 2.7640e-03, PNorm = 58.2321, GNorm = 0.6255, lr_0 = 7.5064e-04
Validation rmse logD = 0.573212
Validation R2 logD = 0.771170
Epoch 14
Train function
Loss = 2.0782e-03, PNorm = 58.2906, GNorm = 1.4539, lr_0 = 7.4699e-04
Loss = 2.0480e-03, PNorm = 58.3409, GNorm = 0.7866, lr_0 = 7.4369e-04
Loss = 2.0683e-03, PNorm = 58.3902, GNorm = 2.9413, lr_0 = 7.4040e-04
Loss = 2.0784e-03, PNorm = 58.4431, GNorm = 0.9257, lr_0 = 7.3712e-04
Loss = 2.1312e-03, PNorm = 58.4882, GNorm = 1.7161, lr_0 = 7.3386e-04
Validation rmse logD = 0.588223
Validation R2 logD = 0.759028
Epoch 15
Train function
Loss = 1.9756e-03, PNorm = 58.5419, GNorm = 1.3300, lr_0 = 7.3029e-04
Loss = 2.0552e-03, PNorm = 58.5885, GNorm = 2.9415, lr_0 = 7.2706e-04
Loss = 1.6339e-03, PNorm = 58.6472, GNorm = 1.7922, lr_0 = 7.2385e-04
Loss = 1.6668e-03, PNorm = 58.6904, GNorm = 1.4366, lr_0 = 7.2064e-04
Loss = 2.1926e-03, PNorm = 58.7370, GNorm = 1.2904, lr_0 = 7.1746e-04
Validation rmse logD = 0.555595
Validation R2 logD = 0.785019
Epoch 16
Train function
Loss = 1.4583e-03, PNorm = 58.7837, GNorm = 0.6029, lr_0 = 7.1397e-04
Loss = 1.3777e-03, PNorm = 58.8384, GNorm = 1.2900, lr_0 = 7.1081e-04
Loss = 1.5298e-03, PNorm = 58.8808, GNorm = 1.1342, lr_0 = 7.0766e-04
Loss = 1.6337e-03, PNorm = 58.9184, GNorm = 1.6220, lr_0 = 7.0453e-04
Loss = 1.3616e-03, PNorm = 58.9644, GNorm = 0.9084, lr_0 = 7.0142e-04
Loss = 1.7266e-03, PNorm = 59.0077, GNorm = 0.8332, lr_0 = 6.9831e-04
Validation rmse logD = 0.560629
Validation R2 logD = 0.781106
Epoch 17
Train function
Loss = 1.2604e-03, PNorm = 59.0476, GNorm = 0.5700, lr_0 = 6.9523e-04
Loss = 1.6603e-03, PNorm = 59.0995, GNorm = 0.6850, lr_0 = 6.9215e-04
Loss = 1.3173e-03, PNorm = 59.1532, GNorm = 0.8392, lr_0 = 6.8909e-04
Loss = 1.4738e-03, PNorm = 59.1906, GNorm = 1.1012, lr_0 = 6.8604e-04
Loss = 1.4146e-03, PNorm = 59.2229, GNorm = 0.5115, lr_0 = 6.8301e-04
Validation rmse logD = 0.579786
Validation R2 logD = 0.765891
Epoch 18
Train function
Loss = 1.4593e-03, PNorm = 59.2703, GNorm = 3.4060, lr_0 = 6.7968e-04
Loss = 1.2550e-03, PNorm = 59.3250, GNorm = 0.6456, lr_0 = 6.7668e-04
Loss = 1.1826e-03, PNorm = 59.3585, GNorm = 1.9411, lr_0 = 6.7368e-04
Loss = 1.4001e-03, PNorm = 59.4029, GNorm = 1.5896, lr_0 = 6.7070e-04
Loss = 1.2554e-03, PNorm = 59.4445, GNorm = 1.7256, lr_0 = 6.6774e-04
Validation rmse logD = 0.608618
Validation R2 logD = 0.742028
Epoch 19
Train function
Loss = 1.4631e-03, PNorm = 59.4847, GNorm = 1.9110, lr_0 = 6.6449e-04
Loss = 2.0660e-03, PNorm = 59.5294, GNorm = 3.5921, lr_0 = 6.6155e-04
Loss = 1.8119e-03, PNorm = 59.5884, GNorm = 3.0854, lr_0 = 6.5862e-04
Loss = 1.3557e-03, PNorm = 59.6461, GNorm = 1.5213, lr_0 = 6.5571e-04
Loss = 1.1775e-03, PNorm = 59.6913, GNorm = 0.7514, lr_0 = 6.5281e-04
Loss = 1.1130e-03, PNorm = 59.7196, GNorm = 0.7256, lr_0 = 6.4992e-04
Validation rmse logD = 0.585583
Validation R2 logD = 0.761186
Epoch 20
Train function
Loss = 1.7440e-03, PNorm = 59.7680, GNorm = 2.5267, lr_0 = 6.4676e-04
Loss = 1.1098e-03, PNorm = 59.8138, GNorm = 0.5512, lr_0 = 6.4390e-04
Loss = 1.2221e-03, PNorm = 59.8559, GNorm = 0.8719, lr_0 = 6.4105e-04
Loss = 9.8246e-04, PNorm = 59.8829, GNorm = 0.8934, lr_0 = 6.3822e-04
Loss = 1.0908e-03, PNorm = 59.9198, GNorm = 1.6963, lr_0 = 6.3539e-04
Validation rmse logD = 0.563659
Validation R2 logD = 0.778734
Epoch 21
Train function
Loss = 1.0085e-03, PNorm = 59.9439, GNorm = 1.7036, lr_0 = 6.3230e-04
Loss = 1.1404e-03, PNorm = 59.9761, GNorm = 1.6978, lr_0 = 6.2950e-04
Loss = 1.2171e-03, PNorm = 60.0072, GNorm = 1.0281, lr_0 = 6.2672e-04
Loss = 1.4120e-03, PNorm = 60.0378, GNorm = 1.3195, lr_0 = 6.2395e-04
Loss = 1.1044e-03, PNorm = 60.0692, GNorm = 0.8666, lr_0 = 6.2119e-04
Validation rmse logD = 0.548318
Validation R2 logD = 0.790614
Epoch 22
Train function
Loss = 1.4358e-03, PNorm = 60.1099, GNorm = 1.8942, lr_0 = 6.1817e-04
Loss = 8.7275e-04, PNorm = 60.1461, GNorm = 0.4570, lr_0 = 6.1543e-04
Loss = 9.5147e-04, PNorm = 60.1718, GNorm = 1.4079, lr_0 = 6.1271e-04
Loss = 8.7338e-04, PNorm = 60.2013, GNorm = 0.6386, lr_0 = 6.1000e-04
Loss = 8.4644e-04, PNorm = 60.2318, GNorm = 0.3567, lr_0 = 6.0730e-04
Loss = 8.3022e-04, PNorm = 60.2599, GNorm = 1.9474, lr_0 = 6.0461e-04
Validation rmse logD = 0.588649
Validation R2 logD = 0.758679
Epoch 23
Train function
Loss = 1.0608e-03, PNorm = 60.2853, GNorm = 0.4653, lr_0 = 6.0167e-04
Loss = 8.1906e-04, PNorm = 60.3180, GNorm = 0.5749, lr_0 = 5.9901e-04
Loss = 8.7710e-04, PNorm = 60.3461, GNorm = 0.3966, lr_0 = 5.9636e-04
Loss = 9.8988e-04, PNorm = 60.3787, GNorm = 0.9056, lr_0 = 5.9372e-04
Loss = 8.2317e-04, PNorm = 60.4044, GNorm = 0.6414, lr_0 = 5.9110e-04
Validation rmse logD = 0.547251
Validation R2 logD = 0.791428
Epoch 24
Train function
Loss = 1.0145e-03, PNorm = 60.4349, GNorm = 2.2000, lr_0 = 5.8822e-04
Loss = 9.9465e-04, PNorm = 60.4625, GNorm = 2.5712, lr_0 = 5.8562e-04
Loss = 1.1876e-03, PNorm = 60.5021, GNorm = 2.6975, lr_0 = 5.8303e-04
Loss = 1.0337e-03, PNorm = 60.5324, GNorm = 2.5574, lr_0 = 5.8045e-04
Loss = 1.0858e-03, PNorm = 60.5613, GNorm = 1.0673, lr_0 = 5.7788e-04
Validation rmse logD = 0.565559
Validation R2 logD = 0.777239
Epoch 25
Train function
Loss = 7.6225e-04, PNorm = 60.5981, GNorm = 0.9251, lr_0 = 5.7533e-04
Loss = 8.4803e-04, PNorm = 60.6240, GNorm = 0.6236, lr_0 = 5.7278e-04
Loss = 6.6256e-04, PNorm = 60.6533, GNorm = 0.6850, lr_0 = 5.7025e-04
Loss = 8.6762e-04, PNorm = 60.6815, GNorm = 0.7765, lr_0 = 5.6773e-04
Loss = 8.6699e-04, PNorm = 60.7006, GNorm = 0.6485, lr_0 = 5.6522e-04
Loss = 7.4125e-04, PNorm = 60.7273, GNorm = 0.7692, lr_0 = 5.6272e-04
Validation rmse logD = 0.555403
Validation R2 logD = 0.785168
Epoch 26
Train function
Loss = 5.5734e-04, PNorm = 60.7475, GNorm = 0.5880, lr_0 = 5.5998e-04
Loss = 5.5969e-04, PNorm = 60.7712, GNorm = 0.9014, lr_0 = 5.5750e-04
Loss = 6.0596e-04, PNorm = 60.7890, GNorm = 0.4961, lr_0 = 5.5503e-04
Loss = 7.6025e-04, PNorm = 60.8075, GNorm = 0.6002, lr_0 = 5.5258e-04
Loss = 8.9596e-04, PNorm = 60.8272, GNorm = 1.4519, lr_0 = 5.5014e-04
Validation rmse logD = 0.572741
Validation R2 logD = 0.771545
Epoch 27
Train function
Loss = 1.1844e-03, PNorm = 60.8619, GNorm = 1.3776, lr_0 = 5.4746e-04
Loss = 1.1495e-03, PNorm = 60.8933, GNorm = 2.5562, lr_0 = 5.4504e-04
Loss = 9.7546e-04, PNorm = 60.9282, GNorm = 1.2914, lr_0 = 5.4263e-04
Loss = 7.5513e-04, PNorm = 60.9634, GNorm = 1.0293, lr_0 = 5.4023e-04
Loss = 6.0177e-04, PNorm = 60.9890, GNorm = 0.8098, lr_0 = 5.3784e-04
Validation rmse logD = 0.542698
Validation R2 logD = 0.794884
Epoch 28
Train function
Loss = 6.2848e-04, PNorm = 61.0082, GNorm = 0.9193, lr_0 = 5.3522e-04
Loss = 4.9726e-04, PNorm = 61.0294, GNorm = 0.6213, lr_0 = 5.3285e-04
Loss = 5.8155e-04, PNorm = 61.0435, GNorm = 1.0511, lr_0 = 5.3050e-04
Loss = 5.7838e-04, PNorm = 61.0627, GNorm = 0.7070, lr_0 = 5.2815e-04
Loss = 6.3595e-04, PNorm = 61.0820, GNorm = 0.6081, lr_0 = 5.2581e-04
Loss = 5.4213e-04, PNorm = 61.0996, GNorm = 0.4843, lr_0 = 5.2349e-04
Loss = 2.3671e-03, PNorm = 61.1024, GNorm = 1.4145, lr_0 = 5.2326e-04
Validation rmse logD = 0.541398
Validation R2 logD = 0.795866
Epoch 29
Train function
Loss = 4.9222e-04, PNorm = 61.1224, GNorm = 0.2434, lr_0 = 5.2094e-04
Loss = 4.9537e-04, PNorm = 61.1390, GNorm = 0.7444, lr_0 = 5.1864e-04
Loss = 4.7771e-04, PNorm = 61.1493, GNorm = 0.9034, lr_0 = 5.1634e-04
Loss = 5.5055e-04, PNorm = 61.1676, GNorm = 1.5006, lr_0 = 5.1406e-04
Loss = 5.4353e-04, PNorm = 61.1849, GNorm = 0.4995, lr_0 = 5.1178e-04
Validation rmse logD = 0.548788
Validation R2 logD = 0.790255
Epoch 30
Train function
Loss = 4.0991e-04, PNorm = 61.1966, GNorm = 0.3629, lr_0 = 5.0930e-04
Loss = 4.7578e-04, PNorm = 61.2137, GNorm = 0.4734, lr_0 = 5.0704e-04
Loss = 4.5739e-04, PNorm = 61.2306, GNorm = 0.7721, lr_0 = 5.0480e-04
Loss = 4.1384e-04, PNorm = 61.2442, GNorm = 0.3899, lr_0 = 5.0257e-04
Loss = 5.8018e-04, PNorm = 61.2649, GNorm = 0.6655, lr_0 = 5.0034e-04
Validation rmse logD = 0.551428
Validation R2 logD = 0.788232
Epoch 31
Train function
Loss = 4.3635e-04, PNorm = 61.2811, GNorm = 1.1309, lr_0 = 4.9791e-04
Loss = 5.2319e-04, PNorm = 61.2953, GNorm = 0.3681, lr_0 = 4.9571e-04
Loss = 4.6309e-04, PNorm = 61.3116, GNorm = 1.0626, lr_0 = 4.9351e-04
Loss = 3.5729e-04, PNorm = 61.3263, GNorm = 0.4938, lr_0 = 4.9133e-04
Loss = 4.9751e-04, PNorm = 61.3396, GNorm = 0.8195, lr_0 = 4.8916e-04
Validation rmse logD = 0.542944
Validation R2 logD = 0.794698
Epoch 32
Train function
Loss = 2.3360e-04, PNorm = 61.3542, GNorm = 0.2219, lr_0 = 4.8678e-04
Loss = 3.9302e-04, PNorm = 61.3746, GNorm = 0.3776, lr_0 = 4.8463e-04
Loss = 3.6902e-04, PNorm = 61.3888, GNorm = 0.4838, lr_0 = 4.8248e-04
Loss = 4.2999e-04, PNorm = 61.4036, GNorm = 0.2926, lr_0 = 4.8035e-04
Loss = 3.2718e-04, PNorm = 61.4144, GNorm = 0.3829, lr_0 = 4.7822e-04
Loss = 4.8095e-04, PNorm = 61.4333, GNorm = 0.6211, lr_0 = 4.7611e-04
Validation rmse logD = 0.551709
Validation R2 logD = 0.788016
Epoch 33
Train function
Loss = 4.1466e-04, PNorm = 61.4466, GNorm = 1.5915, lr_0 = 4.7379e-04
Loss = 4.1009e-04, PNorm = 61.4617, GNorm = 0.9684, lr_0 = 4.7170e-04
Loss = 4.0793e-04, PNorm = 61.4784, GNorm = 0.4093, lr_0 = 4.6961e-04
Loss = 4.0836e-04, PNorm = 61.4925, GNorm = 0.4244, lr_0 = 4.6753e-04
Loss = 5.5594e-04, PNorm = 61.5097, GNorm = 0.3705, lr_0 = 4.6546e-04
Validation rmse logD = 0.552491
Validation R2 logD = 0.787414
Epoch 34
Train function
Loss = 3.3941e-04, PNorm = 61.5258, GNorm = 0.6167, lr_0 = 4.6341e-04
Loss = 4.2163e-04, PNorm = 61.5402, GNorm = 0.3529, lr_0 = 4.6136e-04
Loss = 2.8693e-04, PNorm = 61.5522, GNorm = 0.3540, lr_0 = 4.5931e-04
Loss = 3.5216e-04, PNorm = 61.5651, GNorm = 0.7163, lr_0 = 4.5728e-04
Loss = 3.6730e-04, PNorm = 61.5809, GNorm = 0.5353, lr_0 = 4.5526e-04
Validation rmse logD = 0.554238
Validation R2 logD = 0.786068
Epoch 35
Train function
Loss = 3.8710e-04, PNorm = 61.5961, GNorm = 1.0397, lr_0 = 4.5305e-04
Loss = 2.7046e-04, PNorm = 61.6078, GNorm = 0.4212, lr_0 = 4.5104e-04
Loss = 2.2759e-04, PNorm = 61.6181, GNorm = 0.2820, lr_0 = 4.4905e-04
Loss = 3.0346e-04, PNorm = 61.6278, GNorm = 0.2981, lr_0 = 4.4706e-04
Loss = 3.4400e-04, PNorm = 61.6359, GNorm = 1.3041, lr_0 = 4.4508e-04
Loss = 2.9899e-04, PNorm = 61.6465, GNorm = 0.5413, lr_0 = 4.4311e-04
Validation rmse logD = 0.544559
Validation R2 logD = 0.793475
Epoch 36
Train function
Loss = 2.6486e-04, PNorm = 61.6648, GNorm = 0.3044, lr_0 = 4.4096e-04
Loss = 2.8503e-04, PNorm = 61.6792, GNorm = 0.8594, lr_0 = 4.3901e-04
Loss = 3.5735e-04, PNorm = 61.6935, GNorm = 0.9432, lr_0 = 4.3707e-04
Loss = 3.1874e-04, PNorm = 61.7056, GNorm = 0.5475, lr_0 = 4.3513e-04
Loss = 2.9673e-04, PNorm = 61.7185, GNorm = 0.3427, lr_0 = 4.3321e-04
Validation rmse logD = 0.545282
Validation R2 logD = 0.792926
Epoch 37
Train function
Loss = 1.9309e-04, PNorm = 61.7315, GNorm = 0.5028, lr_0 = 4.3110e-04
Loss = 2.4793e-04, PNorm = 61.7389, GNorm = 0.3353, lr_0 = 4.2919e-04
Loss = 3.3900e-04, PNorm = 61.7494, GNorm = 0.5745, lr_0 = 4.2729e-04
Loss = 2.6841e-04, PNorm = 61.7629, GNorm = 0.2561, lr_0 = 4.2540e-04
Loss = 2.6330e-04, PNorm = 61.7717, GNorm = 0.2395, lr_0 = 4.2352e-04
Validation rmse logD = 0.547750
Validation R2 logD = 0.791047
Epoch 38
Train function
Loss = 2.0472e-04, PNorm = 61.7880, GNorm = 0.4763, lr_0 = 4.2146e-04
Loss = 2.6403e-04, PNorm = 61.7973, GNorm = 0.2944, lr_0 = 4.1960e-04
Loss = 2.3382e-04, PNorm = 61.8088, GNorm = 0.6017, lr_0 = 4.1774e-04
Loss = 2.7193e-04, PNorm = 61.8202, GNorm = 0.3001, lr_0 = 4.1589e-04
Loss = 2.0450e-04, PNorm = 61.8289, GNorm = 0.2345, lr_0 = 4.1406e-04
Loss = 2.6720e-04, PNorm = 61.8385, GNorm = 0.3540, lr_0 = 4.1222e-04
Validation rmse logD = 0.556290
Validation R2 logD = 0.784481
Epoch 39
Train function
Loss = 2.9960e-04, PNorm = 61.8546, GNorm = 0.3667, lr_0 = 4.1022e-04
Loss = 2.7247e-04, PNorm = 61.8631, GNorm = 0.8560, lr_0 = 4.0840e-04
Loss = 2.3169e-04, PNorm = 61.8737, GNorm = 0.4923, lr_0 = 4.0660e-04
Loss = 2.4984e-04, PNorm = 61.8829, GNorm = 0.2762, lr_0 = 4.0480e-04
Loss = 2.6509e-04, PNorm = 61.8953, GNorm = 0.6050, lr_0 = 4.0301e-04
Validation rmse logD = 0.542052
Validation R2 logD = 0.795372
Epoch 40
Train function
Loss = 1.5219e-04, PNorm = 61.9058, GNorm = 0.3789, lr_0 = 4.0105e-04
Loss = 2.6005e-04, PNorm = 61.9198, GNorm = 1.3971, lr_0 = 3.9927e-04
Loss = 2.1240e-04, PNorm = 61.9304, GNorm = 0.7470, lr_0 = 3.9751e-04
Loss = 3.0338e-04, PNorm = 61.9383, GNorm = 0.3213, lr_0 = 3.9575e-04
Loss = 1.8723e-04, PNorm = 61.9508, GNorm = 0.3350, lr_0 = 3.9400e-04
Validation rmse logD = 0.551693
Validation R2 logD = 0.788028
Epoch 41
Train function
Loss = 3.2851e-04, PNorm = 61.9621, GNorm = 0.8779, lr_0 = 3.9208e-04
Loss = 2.3824e-04, PNorm = 61.9709, GNorm = 0.3280, lr_0 = 3.9035e-04
Loss = 3.0030e-04, PNorm = 61.9861, GNorm = 0.3194, lr_0 = 3.8862e-04
Loss = 2.2796e-04, PNorm = 61.9967, GNorm = 0.3114, lr_0 = 3.8690e-04
Loss = 2.4276e-04, PNorm = 62.0104, GNorm = 0.3056, lr_0 = 3.8519e-04
Loss = 3.2811e-04, PNorm = 62.0241, GNorm = 0.9704, lr_0 = 3.8349e-04
Validation rmse logD = 0.547643
Validation R2 logD = 0.791129
Epoch 42
Train function
Loss = 1.9894e-04, PNorm = 62.0348, GNorm = 0.6125, lr_0 = 3.8179e-04
Loss = 2.0329e-04, PNorm = 62.0450, GNorm = 0.3035, lr_0 = 3.8010e-04
Loss = 2.1692e-04, PNorm = 62.0555, GNorm = 0.2700, lr_0 = 3.7842e-04
Loss = 2.1651e-04, PNorm = 62.0633, GNorm = 0.4513, lr_0 = 3.7675e-04
Loss = 2.2530e-04, PNorm = 62.0718, GNorm = 0.5050, lr_0 = 3.7508e-04
Validation rmse logD = 0.544434
Validation R2 logD = 0.793570
Epoch 43
Train function
Loss = 1.3962e-04, PNorm = 62.0820, GNorm = 0.5224, lr_0 = 3.7326e-04
Loss = 1.7795e-04, PNorm = 62.0906, GNorm = 0.2018, lr_0 = 3.7160e-04
Loss = 1.8724e-04, PNorm = 62.0964, GNorm = 0.3867, lr_0 = 3.6996e-04
Loss = 1.6494e-04, PNorm = 62.1045, GNorm = 0.4821, lr_0 = 3.6832e-04
Loss = 1.7621e-04, PNorm = 62.1139, GNorm = 0.5695, lr_0 = 3.6669e-04
Validation rmse logD = 0.546364
Validation R2 logD = 0.792104
Epoch 44
Train function
Loss = 1.6227e-04, PNorm = 62.1216, GNorm = 0.2310, lr_0 = 3.6491e-04
Loss = 1.2614e-04, PNorm = 62.1278, GNorm = 0.3582, lr_0 = 3.6330e-04
Loss = 1.5804e-04, PNorm = 62.1340, GNorm = 0.5155, lr_0 = 3.6169e-04
Loss = 2.0722e-04, PNorm = 62.1410, GNorm = 0.2454, lr_0 = 3.6009e-04
Loss = 1.7832e-04, PNorm = 62.1541, GNorm = 0.3148, lr_0 = 3.5850e-04
Loss = 1.3080e-04, PNorm = 62.1607, GNorm = 0.2423, lr_0 = 3.5691e-04
Loss = 1.6730e-03, PNorm = 62.1610, GNorm = 0.7271, lr_0 = 3.5675e-04
Validation rmse logD = 0.541921
Validation R2 logD = 0.795471
Epoch 45
Train function
Loss = 1.2560e-04, PNorm = 62.1685, GNorm = 0.2602, lr_0 = 3.5518e-04
Loss = 1.6183e-04, PNorm = 62.1782, GNorm = 0.5874, lr_0 = 3.5360e-04
Loss = 1.7902e-04, PNorm = 62.1856, GNorm = 0.4910, lr_0 = 3.5204e-04
Loss = 1.4611e-04, PNorm = 62.1926, GNorm = 0.4117, lr_0 = 3.5048e-04
Loss = 2.2312e-04, PNorm = 62.1998, GNorm = 0.1938, lr_0 = 3.4893e-04
Validation rmse logD = 0.560311
Validation R2 logD = 0.781354
Epoch 46
Train function
Loss = 1.4789e-04, PNorm = 62.2105, GNorm = 0.7115, lr_0 = 3.4724e-04
Loss = 2.1788e-04, PNorm = 62.2191, GNorm = 0.9039, lr_0 = 3.4570e-04
Loss = 1.4679e-04, PNorm = 62.2295, GNorm = 0.1847, lr_0 = 3.4417e-04
Loss = 1.5190e-04, PNorm = 62.2363, GNorm = 0.4014, lr_0 = 3.4265e-04
Loss = 1.3912e-04, PNorm = 62.2463, GNorm = 0.2748, lr_0 = 3.4113e-04
Validation rmse logD = 0.539477
Validation R2 logD = 0.797312
Epoch 47
Train function
Loss = 1.3487e-04, PNorm = 62.2550, GNorm = 0.6213, lr_0 = 3.3947e-04
Loss = 1.5077e-04, PNorm = 62.2636, GNorm = 0.6060, lr_0 = 3.3797e-04
Loss = 1.9125e-04, PNorm = 62.2687, GNorm = 0.1469, lr_0 = 3.3648e-04
Loss = 1.2028e-04, PNorm = 62.2738, GNorm = 0.6698, lr_0 = 3.3499e-04
Loss = 1.7524e-04, PNorm = 62.2795, GNorm = 0.8957, lr_0 = 3.3351e-04
Validation rmse logD = 0.554511
Validation R2 logD = 0.785857
Epoch 48
Train function
Loss = 2.3352e-04, PNorm = 62.2910, GNorm = 0.9258, lr_0 = 3.3188e-04
Loss = 1.4247e-04, PNorm = 62.2992, GNorm = 0.6549, lr_0 = 3.3042e-04
Loss = 1.1950e-04, PNorm = 62.3050, GNorm = 0.2609, lr_0 = 3.2895e-04
Loss = 1.3616e-04, PNorm = 62.3118, GNorm = 0.4392, lr_0 = 3.2750e-04
Loss = 1.4766e-04, PNorm = 62.3203, GNorm = 0.5270, lr_0 = 3.2605e-04
Loss = 1.6161e-04, PNorm = 62.3283, GNorm = 0.5346, lr_0 = 3.2461e-04
Validation rmse logD = 0.549549
Validation R2 logD = 0.789673
Epoch 49
Train function
Loss = 1.3161e-04, PNorm = 62.3391, GNorm = 0.2641, lr_0 = 3.2303e-04
Loss = 1.0246e-04, PNorm = 62.3443, GNorm = 0.1722, lr_0 = 3.2160e-04
Loss = 1.2498e-04, PNorm = 62.3511, GNorm = 0.5042, lr_0 = 3.2018e-04
Loss = 1.4820e-04, PNorm = 62.3567, GNorm = 0.3458, lr_0 = 3.1876e-04
Loss = 1.1743e-04, PNorm = 62.3645, GNorm = 0.3374, lr_0 = 3.1735e-04
Validation rmse logD = 0.546352
Validation R2 logD = 0.792113
Epoch 50
Train function
Loss = 1.0179e-04, PNorm = 62.3726, GNorm = 0.4331, lr_0 = 3.1595e-04
Loss = 1.4410e-04, PNorm = 62.3832, GNorm = 0.2522, lr_0 = 3.1455e-04
Loss = 1.2388e-04, PNorm = 62.3939, GNorm = 0.2913, lr_0 = 3.1316e-04
Loss = 1.3976e-04, PNorm = 62.3980, GNorm = 0.3607, lr_0 = 3.1177e-04
Loss = 1.1121e-04, PNorm = 62.4037, GNorm = 0.2287, lr_0 = 3.1039e-04
Validation rmse logD = 0.546187
Validation R2 logD = 0.792238
Epoch 51
Train function
Loss = 8.4544e-05, PNorm = 62.4104, GNorm = 0.1632, lr_0 = 3.0888e-04
Loss = 1.0299e-04, PNorm = 62.4160, GNorm = 0.2395, lr_0 = 3.0752e-04
Loss = 1.0756e-04, PNorm = 62.4201, GNorm = 0.2985, lr_0 = 3.0616e-04
Loss = 9.0121e-05, PNorm = 62.4253, GNorm = 0.3345, lr_0 = 3.0480e-04
Loss = 1.0810e-04, PNorm = 62.4313, GNorm = 0.7006, lr_0 = 3.0346e-04
Loss = 1.2933e-04, PNorm = 62.4357, GNorm = 0.8726, lr_0 = 3.0211e-04
Validation rmse logD = 0.547362
Validation R2 logD = 0.791343
Epoch 52
Train function
Loss = 1.2879e-04, PNorm = 62.4415, GNorm = 0.2578, lr_0 = 3.0064e-04
Loss = 1.1716e-04, PNorm = 62.4475, GNorm = 0.2817, lr_0 = 2.9931e-04
Loss = 1.0104e-04, PNorm = 62.4550, GNorm = 0.2049, lr_0 = 2.9799e-04
Loss = 8.8762e-05, PNorm = 62.4597, GNorm = 0.2528, lr_0 = 2.9667e-04
Loss = 8.1849e-05, PNorm = 62.4660, GNorm = 0.3408, lr_0 = 2.9536e-04
Validation rmse logD = 0.544801
Validation R2 logD = 0.793291
Epoch 53
Train function
Loss = 1.0903e-04, PNorm = 62.4713, GNorm = 0.2439, lr_0 = 2.9392e-04
Loss = 9.6476e-05, PNorm = 62.4771, GNorm = 0.3402, lr_0 = 2.9262e-04
Loss = 8.9202e-05, PNorm = 62.4806, GNorm = 0.5769, lr_0 = 2.9133e-04
Loss = 1.1994e-04, PNorm = 62.4860, GNorm = 0.2571, lr_0 = 2.9004e-04
Loss = 1.0140e-04, PNorm = 62.4897, GNorm = 0.2508, lr_0 = 2.8876e-04
Validation rmse logD = 0.544424
Validation R2 logD = 0.793577
Epoch 54
Train function
Loss = 8.1262e-05, PNorm = 62.4991, GNorm = 0.3220, lr_0 = 2.8735e-04
Loss = 8.9753e-05, PNorm = 62.5037, GNorm = 0.1950, lr_0 = 2.8608e-04
Loss = 9.2530e-05, PNorm = 62.5078, GNorm = 0.1220, lr_0 = 2.8482e-04
Loss = 1.1401e-04, PNorm = 62.5123, GNorm = 0.6674, lr_0 = 2.8356e-04
Loss = 1.3992e-04, PNorm = 62.5209, GNorm = 0.5190, lr_0 = 2.8230e-04
Loss = 1.0563e-04, PNorm = 62.5258, GNorm = 0.2981, lr_0 = 2.8105e-04
Validation rmse logD = 0.544506
Validation R2 logD = 0.793515
Epoch 55
Train function
Loss = 8.5149e-05, PNorm = 62.5324, GNorm = 0.2566, lr_0 = 2.7969e-04
Loss = 8.4590e-05, PNorm = 62.5368, GNorm = 0.5763, lr_0 = 2.7845e-04
Loss = 9.7432e-05, PNorm = 62.5401, GNorm = 0.4127, lr_0 = 2.7722e-04
Loss = 1.0946e-04, PNorm = 62.5436, GNorm = 0.4553, lr_0 = 2.7599e-04
Loss = 1.2131e-04, PNorm = 62.5500, GNorm = 0.2418, lr_0 = 2.7477e-04
Validation rmse logD = 0.549669
Validation R2 logD = 0.789581
Epoch 56
Train function
Loss = 7.6276e-05, PNorm = 62.5594, GNorm = 0.2980, lr_0 = 2.7343e-04
Loss = 6.3258e-05, PNorm = 62.5632, GNorm = 0.2495, lr_0 = 2.7222e-04
Loss = 9.8518e-05, PNorm = 62.5676, GNorm = 0.2479, lr_0 = 2.7102e-04
Loss = 6.9353e-05, PNorm = 62.5712, GNorm = 0.4899, lr_0 = 2.6982e-04
Loss = 1.0378e-04, PNorm = 62.5747, GNorm = 0.1617, lr_0 = 2.6863e-04
Validation rmse logD = 0.545468
Validation R2 logD = 0.792785
Epoch 57
Train function
Loss = 9.4957e-05, PNorm = 62.5789, GNorm = 0.2350, lr_0 = 2.6732e-04
Loss = 9.7576e-05, PNorm = 62.5847, GNorm = 0.3188, lr_0 = 2.6614e-04
Loss = 7.8199e-05, PNorm = 62.5926, GNorm = 0.5292, lr_0 = 2.6496e-04
Loss = 9.7330e-05, PNorm = 62.5978, GNorm = 0.3790, lr_0 = 2.6379e-04
Loss = 8.5715e-05, PNorm = 62.6043, GNorm = 0.4406, lr_0 = 2.6262e-04
Loss = 6.7359e-05, PNorm = 62.6102, GNorm = 0.2291, lr_0 = 2.6146e-04
Loss = 6.8775e-04, PNorm = 62.6104, GNorm = 0.4433, lr_0 = 2.6134e-04
Validation rmse logD = 0.546286
Validation R2 logD = 0.792163
Epoch 58
Train function
Loss = 6.2199e-05, PNorm = 62.6130, GNorm = 0.2743, lr_0 = 2.6019e-04
Loss = 6.5662e-05, PNorm = 62.6175, GNorm = 0.1521, lr_0 = 2.5904e-04
Loss = 6.5421e-05, PNorm = 62.6216, GNorm = 0.2363, lr_0 = 2.5789e-04
Loss = 5.5159e-05, PNorm = 62.6255, GNorm = 0.1444, lr_0 = 2.5675e-04
Loss = 8.9731e-05, PNorm = 62.6311, GNorm = 0.1872, lr_0 = 2.5561e-04
Validation rmse logD = 0.550030
Validation R2 logD = 0.789304
Epoch 59
Train function
Loss = 7.8919e-05, PNorm = 62.6353, GNorm = 0.4114, lr_0 = 2.5448e-04
Loss = 7.2939e-05, PNorm = 62.6388, GNorm = 0.2367, lr_0 = 2.5336e-04
Loss = 1.1279e-04, PNorm = 62.6425, GNorm = 0.4186, lr_0 = 2.5224e-04
Loss = 1.0157e-04, PNorm = 62.6472, GNorm = 0.4133, lr_0 = 2.5112e-04
Loss = 7.0486e-05, PNorm = 62.6521, GNorm = 0.3043, lr_0 = 2.5001e-04
Validation rmse logD = 0.545375
Validation R2 logD = 0.792856
Epoch 60
Train function
Loss = 7.0225e-05, PNorm = 62.6561, GNorm = 0.2343, lr_0 = 2.4879e-04
Loss = 5.9380e-05, PNorm = 62.6612, GNorm = 0.1497, lr_0 = 2.4769e-04
Loss = 5.7761e-05, PNorm = 62.6646, GNorm = 0.2014, lr_0 = 2.4660e-04
Loss = 6.9373e-05, PNorm = 62.6685, GNorm = 0.1513, lr_0 = 2.4551e-04
Loss = 5.3554e-05, PNorm = 62.6713, GNorm = 0.2103, lr_0 = 2.4442e-04
Loss = 5.6515e-05, PNorm = 62.6739, GNorm = 0.2042, lr_0 = 2.4334e-04
Loss = 2.2689e-04, PNorm = 62.6742, GNorm = 0.2940, lr_0 = 2.4323e-04
Validation rmse logD = 0.544604
Validation R2 logD = 0.793441
Epoch 61
Train function
Loss = 4.0258e-05, PNorm = 62.6787, GNorm = 0.2348, lr_0 = 2.4216e-04
Loss = 4.0813e-05, PNorm = 62.6825, GNorm = 0.1707, lr_0 = 2.4109e-04
Loss = 5.6674e-05, PNorm = 62.6852, GNorm = 0.0997, lr_0 = 2.4002e-04
Loss = 6.1121e-05, PNorm = 62.6893, GNorm = 0.1630, lr_0 = 2.3896e-04
Loss = 4.8197e-05, PNorm = 62.6936, GNorm = 0.1158, lr_0 = 2.3790e-04
Validation rmse logD = 0.547636
Validation R2 logD = 0.791134
Epoch 62
Train function
Loss = 5.8314e-05, PNorm = 62.6961, GNorm = 0.3449, lr_0 = 2.3674e-04
Loss = 4.1644e-05, PNorm = 62.6999, GNorm = 0.2299, lr_0 = 2.3570e-04
Loss = 6.3672e-05, PNorm = 62.7043, GNorm = 0.2048, lr_0 = 2.3465e-04
Loss = 6.2883e-05, PNorm = 62.7086, GNorm = 0.3054, lr_0 = 2.3362e-04
Loss = 4.0328e-05, PNorm = 62.7124, GNorm = 0.1315, lr_0 = 2.3258e-04
Validation rmse logD = 0.547756
Validation R2 logD = 0.791043
Epoch 63
Train function
Loss = 3.7458e-05, PNorm = 62.7153, GNorm = 0.3014, lr_0 = 2.3145e-04
Loss = 3.9206e-05, PNorm = 62.7174, GNorm = 0.1574, lr_0 = 2.3043e-04
Loss = 4.1240e-05, PNorm = 62.7200, GNorm = 0.1528, lr_0 = 2.2941e-04
Loss = 6.3651e-05, PNorm = 62.7247, GNorm = 0.2657, lr_0 = 2.2839e-04
Loss = 5.5849e-05, PNorm = 62.7290, GNorm = 0.1945, lr_0 = 2.2738e-04
Validation rmse logD = 0.545635
Validation R2 logD = 0.792658
Epoch 64
Train function
Loss = 6.1582e-05, PNorm = 62.7323, GNorm = 0.2985, lr_0 = 2.2628e-04
Loss = 9.4554e-05, PNorm = 62.7388, GNorm = 0.2065, lr_0 = 2.2528e-04
Loss = 7.2738e-05, PNorm = 62.7421, GNorm = 0.5244, lr_0 = 2.2428e-04
Loss = 5.5299e-05, PNorm = 62.7454, GNorm = 0.5049, lr_0 = 2.2329e-04
Loss = 6.7436e-05, PNorm = 62.7519, GNorm = 0.2787, lr_0 = 2.2230e-04
Loss = 7.4312e-05, PNorm = 62.7566, GNorm = 0.3025, lr_0 = 2.2132e-04
Validation rmse logD = 0.546859
Validation R2 logD = 0.791727
Epoch 65
Train function
Loss = 5.4959e-05, PNorm = 62.7604, GNorm = 0.2075, lr_0 = 2.2024e-04
Loss = 5.6252e-05, PNorm = 62.7649, GNorm = 0.1621, lr_0 = 2.1927e-04
Loss = 5.6490e-05, PNorm = 62.7677, GNorm = 0.1518, lr_0 = 2.1830e-04
Loss = 6.3319e-05, PNorm = 62.7718, GNorm = 0.2836, lr_0 = 2.1733e-04
Loss = 5.3375e-05, PNorm = 62.7733, GNorm = 0.1055, lr_0 = 2.1637e-04
Validation rmse logD = 0.545432
Validation R2 logD = 0.792812
Epoch 66
Train function
Loss = 7.1006e-05, PNorm = 62.7775, GNorm = 0.2770, lr_0 = 2.1532e-04
Loss = 5.2694e-05, PNorm = 62.7809, GNorm = 0.3060, lr_0 = 2.1436e-04
Loss = 5.5230e-05, PNorm = 62.7820, GNorm = 0.1676, lr_0 = 2.1342e-04
Loss = 4.3012e-05, PNorm = 62.7842, GNorm = 0.0909, lr_0 = 2.1247e-04
Loss = 3.8934e-05, PNorm = 62.7867, GNorm = 0.3880, lr_0 = 2.1153e-04
Validation rmse logD = 0.550313
Validation R2 logD = 0.789087
Epoch 67
Train function
Loss = 3.5053e-05, PNorm = 62.7914, GNorm = 0.3190, lr_0 = 2.1060e-04
Loss = 5.9542e-05, PNorm = 62.7977, GNorm = 0.6373, lr_0 = 2.0966e-04
Loss = 5.2506e-05, PNorm = 62.8007, GNorm = 0.2167, lr_0 = 2.0874e-04
Loss = 5.6160e-05, PNorm = 62.8049, GNorm = 0.2516, lr_0 = 2.0781e-04
Loss = 6.7317e-05, PNorm = 62.8095, GNorm = 0.2774, lr_0 = 2.0689e-04
Loss = 4.9074e-05, PNorm = 62.8116, GNorm = 0.2863, lr_0 = 2.0598e-04
Validation rmse logD = 0.546714
Validation R2 logD = 0.791837
Epoch 68
Train function
Loss = 4.9279e-05, PNorm = 62.8161, GNorm = 0.3909, lr_0 = 2.0498e-04
Loss = 3.5698e-05, PNorm = 62.8196, GNorm = 0.2046, lr_0 = 2.0407e-04
Loss = 3.8052e-05, PNorm = 62.8222, GNorm = 0.2652, lr_0 = 2.0317e-04
Loss = 4.7159e-05, PNorm = 62.8247, GNorm = 0.1089, lr_0 = 2.0227e-04
Loss = 3.7411e-05, PNorm = 62.8264, GNorm = 0.1172, lr_0 = 2.0137e-04
Validation rmse logD = 0.545369
Validation R2 logD = 0.792860
Epoch 69
Train function
Loss = 4.8939e-05, PNorm = 62.8309, GNorm = 0.1799, lr_0 = 2.0039e-04
Loss = 4.5948e-05, PNorm = 62.8338, GNorm = 0.2595, lr_0 = 1.9951e-04
Loss = 3.8481e-05, PNorm = 62.8360, GNorm = 0.2726, lr_0 = 1.9863e-04
Loss = 3.6117e-05, PNorm = 62.8373, GNorm = 0.1236, lr_0 = 1.9775e-04
Loss = 3.8652e-05, PNorm = 62.8386, GNorm = 0.3691, lr_0 = 1.9687e-04
Validation rmse logD = 0.546087
Validation R2 logD = 0.792314
Epoch 70
Train function
Loss = 3.0339e-05, PNorm = 62.8407, GNorm = 0.2640, lr_0 = 1.9592e-04
Loss = 2.6671e-05, PNorm = 62.8432, GNorm = 0.3578, lr_0 = 1.9505e-04
Loss = 4.3267e-05, PNorm = 62.8458, GNorm = 0.3970, lr_0 = 1.9419e-04
Loss = 4.5769e-05, PNorm = 62.8496, GNorm = 0.2618, lr_0 = 1.9333e-04
Loss = 3.8116e-05, PNorm = 62.8514, GNorm = 0.2265, lr_0 = 1.9247e-04
Loss = 3.3427e-05, PNorm = 62.8531, GNorm = 0.3568, lr_0 = 1.9162e-04
Validation rmse logD = 0.548447
Validation R2 logD = 0.790515
Epoch 71
Train function
Loss = 2.9159e-05, PNorm = 62.8555, GNorm = 0.1520, lr_0 = 1.9069e-04
Loss = 2.9019e-05, PNorm = 62.8574, GNorm = 0.3229, lr_0 = 1.8984e-04
Loss = 5.1297e-05, PNorm = 62.8591, GNorm = 0.2147, lr_0 = 1.8900e-04
Loss = 4.4122e-05, PNorm = 62.8614, GNorm = 0.2512, lr_0 = 1.8817e-04
Loss = 4.0302e-05, PNorm = 62.8645, GNorm = 0.2911, lr_0 = 1.8734e-04
Validation rmse logD = 0.548782
Validation R2 logD = 0.790259
Epoch 72
Train function
Loss = 2.9653e-05, PNorm = 62.8654, GNorm = 0.1301, lr_0 = 1.8643e-04
Loss = 3.0853e-05, PNorm = 62.8671, GNorm = 0.3790, lr_0 = 1.8560e-04
Loss = 2.7090e-05, PNorm = 62.8695, GNorm = 0.2248, lr_0 = 1.8478e-04
Loss = 3.3506e-05, PNorm = 62.8720, GNorm = 0.0931, lr_0 = 1.8396e-04
Loss = 3.2509e-05, PNorm = 62.8735, GNorm = 0.2070, lr_0 = 1.8315e-04
Validation rmse logD = 0.547908
Validation R2 logD = 0.790927
Epoch 73
Train function
Loss = 3.3987e-05, PNorm = 62.8770, GNorm = 0.2480, lr_0 = 1.8226e-04
Loss = 3.0089e-05, PNorm = 62.8794, GNorm = 0.1575, lr_0 = 1.8145e-04
Loss = 2.7657e-05, PNorm = 62.8813, GNorm = 0.1611, lr_0 = 1.8065e-04
Loss = 3.0995e-05, PNorm = 62.8831, GNorm = 0.2524, lr_0 = 1.7985e-04
Loss = 2.4450e-05, PNorm = 62.8842, GNorm = 0.1546, lr_0 = 1.7905e-04
Loss = 2.4500e-05, PNorm = 62.8859, GNorm = 0.1772, lr_0 = 1.7826e-04
Loss = 3.4040e-05, PNorm = 62.8861, GNorm = 0.1215, lr_0 = 1.7818e-04
Validation rmse logD = 0.547930
Validation R2 logD = 0.790910
Epoch 74
Train function
Loss = 3.1749e-05, PNorm = 62.8890, GNorm = 0.1128, lr_0 = 1.7739e-04
Loss = 2.3790e-05, PNorm = 62.8904, GNorm = 0.1315, lr_0 = 1.7661e-04
Loss = 2.0088e-05, PNorm = 62.8913, GNorm = 0.1455, lr_0 = 1.7583e-04
Loss = 1.7801e-05, PNorm = 62.8937, GNorm = 0.1336, lr_0 = 1.7505e-04
Loss = 2.0240e-05, PNorm = 62.8947, GNorm = 0.0840, lr_0 = 1.7428e-04
Validation rmse logD = 0.552268
Validation R2 logD = 0.787586
Epoch 75
Train function
Loss = 2.0150e-05, PNorm = 62.8969, GNorm = 0.0974, lr_0 = 1.7351e-04
Loss = 3.2937e-05, PNorm = 62.8991, GNorm = 0.1560, lr_0 = 1.7274e-04
Loss = 2.3728e-05, PNorm = 62.9003, GNorm = 0.2374, lr_0 = 1.7197e-04
Loss = 2.1663e-05, PNorm = 62.9016, GNorm = 0.2654, lr_0 = 1.7121e-04
Loss = 2.1669e-05, PNorm = 62.9040, GNorm = 0.2866, lr_0 = 1.7046e-04
Validation rmse logD = 0.549165
Validation R2 logD = 0.789966
Epoch 76
Train function
Loss = 1.6863e-05, PNorm = 62.9052, GNorm = 0.1808, lr_0 = 1.6963e-04
Loss = 2.1505e-05, PNorm = 62.9065, GNorm = 0.0883, lr_0 = 1.6888e-04
Loss = 2.9787e-05, PNorm = 62.9087, GNorm = 0.1801, lr_0 = 1.6813e-04
Loss = 2.2362e-05, PNorm = 62.9101, GNorm = 0.1541, lr_0 = 1.6739e-04
Loss = 2.2896e-05, PNorm = 62.9116, GNorm = 0.0820, lr_0 = 1.6665e-04
Loss = 1.8639e-05, PNorm = 62.9133, GNorm = 0.0926, lr_0 = 1.6591e-04
Loss = 2.2143e-04, PNorm = 62.9134, GNorm = 0.3764, lr_0 = 1.6584e-04
Validation rmse logD = 0.547702
Validation R2 logD = 0.791084
Epoch 77
Train function
Loss = 1.8413e-05, PNorm = 62.9147, GNorm = 0.0714, lr_0 = 1.6510e-04
Loss = 1.8686e-05, PNorm = 62.9162, GNorm = 0.0793, lr_0 = 1.6437e-04
Loss = 3.1345e-05, PNorm = 62.9172, GNorm = 0.1206, lr_0 = 1.6364e-04
Loss = 3.4705e-05, PNorm = 62.9186, GNorm = 0.0974, lr_0 = 1.6292e-04
Loss = 3.2822e-05, PNorm = 62.9206, GNorm = 0.0999, lr_0 = 1.6220e-04
Validation rmse logD = 0.548181
Validation R2 logD = 0.790718
Epoch 78
Train function
Loss = 2.4830e-05, PNorm = 62.9224, GNorm = 0.0803, lr_0 = 1.6141e-04
Loss = 2.7903e-05, PNorm = 62.9227, GNorm = 0.0993, lr_0 = 1.6070e-04
Loss = 2.7059e-05, PNorm = 62.9243, GNorm = 0.1792, lr_0 = 1.5999e-04
Loss = 2.7098e-05, PNorm = 62.9272, GNorm = 0.1437, lr_0 = 1.5928e-04
Loss = 3.2205e-05, PNorm = 62.9298, GNorm = 0.3894, lr_0 = 1.5857e-04
Validation rmse logD = 0.548274
Validation R2 logD = 0.790648
Epoch 79
Train function
Loss = 1.8857e-05, PNorm = 62.9323, GNorm = 0.1070, lr_0 = 1.5780e-04
Loss = 2.1966e-05, PNorm = 62.9335, GNorm = 0.1339, lr_0 = 1.5710e-04
Loss = 1.8265e-05, PNorm = 62.9356, GNorm = 0.0577, lr_0 = 1.5641e-04
Loss = 2.7006e-05, PNorm = 62.9366, GNorm = 0.1450, lr_0 = 1.5572e-04
Loss = 1.9703e-05, PNorm = 62.9384, GNorm = 0.2454, lr_0 = 1.5503e-04
Validation rmse logD = 0.547454
Validation R2 logD = 0.791273
Epoch 80
Train function
Loss = 3.1270e-05, PNorm = 62.9402, GNorm = 0.2895, lr_0 = 1.5427e-04
Loss = 1.9517e-05, PNorm = 62.9415, GNorm = 0.1189, lr_0 = 1.5359e-04
Loss = 1.9595e-05, PNorm = 62.9435, GNorm = 0.0668, lr_0 = 1.5291e-04
Loss = 2.2977e-05, PNorm = 62.9449, GNorm = 0.1216, lr_0 = 1.5224e-04
Loss = 1.5311e-05, PNorm = 62.9462, GNorm = 0.0617, lr_0 = 1.5156e-04
Loss = 1.8844e-05, PNorm = 62.9469, GNorm = 0.2135, lr_0 = 1.5089e-04
Validation rmse logD = 0.546970
Validation R2 logD = 0.791642
Epoch 81
Train function
Loss = 1.6002e-05, PNorm = 62.9487, GNorm = 0.1376, lr_0 = 1.5016e-04
Loss = 1.5146e-05, PNorm = 62.9502, GNorm = 0.1463, lr_0 = 1.4949e-04
Loss = 1.6893e-05, PNorm = 62.9521, GNorm = 0.1157, lr_0 = 1.4883e-04
Loss = 2.2921e-05, PNorm = 62.9533, GNorm = 0.2337, lr_0 = 1.4817e-04
Loss = 2.2593e-05, PNorm = 62.9546, GNorm = 0.1526, lr_0 = 1.4752e-04
Validation rmse logD = 0.548725
Validation R2 logD = 0.790303
Epoch 82
Train function
Loss = 1.5789e-05, PNorm = 62.9560, GNorm = 0.1222, lr_0 = 1.4680e-04
Loss = 2.0983e-05, PNorm = 62.9570, GNorm = 0.1369, lr_0 = 1.4615e-04
Loss = 1.5433e-05, PNorm = 62.9580, GNorm = 0.0434, lr_0 = 1.4551e-04
Loss = 1.7876e-05, PNorm = 62.9591, GNorm = 0.0889, lr_0 = 1.4486e-04
Loss = 2.1611e-05, PNorm = 62.9604, GNorm = 0.2071, lr_0 = 1.4422e-04
Validation rmse logD = 0.549906
Validation R2 logD = 0.789399
Epoch 83
Train function
Loss = 2.0326e-05, PNorm = 62.9625, GNorm = 0.2061, lr_0 = 1.4352e-04
Loss = 2.1136e-05, PNorm = 62.9640, GNorm = 0.2026, lr_0 = 1.4288e-04
Loss = 2.2619e-05, PNorm = 62.9651, GNorm = 0.1196, lr_0 = 1.4225e-04
Loss = 1.5830e-05, PNorm = 62.9671, GNorm = 0.0698, lr_0 = 1.4162e-04
Loss = 2.9356e-05, PNorm = 62.9693, GNorm = 0.1955, lr_0 = 1.4100e-04
Loss = 1.8845e-05, PNorm = 62.9705, GNorm = 0.0891, lr_0 = 1.4037e-04
Validation rmse logD = 0.547817
Validation R2 logD = 0.790996
Epoch 84
Train function
Loss = 1.8700e-05, PNorm = 62.9722, GNorm = 0.1331, lr_0 = 1.3975e-04
Loss = 1.3273e-05, PNorm = 62.9738, GNorm = 0.0841, lr_0 = 1.3913e-04
Loss = 1.4942e-05, PNorm = 62.9748, GNorm = 0.1704, lr_0 = 1.3852e-04
Loss = 1.4412e-05, PNorm = 62.9755, GNorm = 0.0662, lr_0 = 1.3791e-04
Loss = 1.6807e-05, PNorm = 62.9769, GNorm = 0.3119, lr_0 = 1.3730e-04
Validation rmse logD = 0.549407
Validation R2 logD = 0.789781
Epoch 85
Train function
Loss = 1.4309e-05, PNorm = 62.9782, GNorm = 0.0806, lr_0 = 1.3663e-04
Loss = 1.4525e-05, PNorm = 62.9798, GNorm = 0.0638, lr_0 = 1.3602e-04
Loss = 1.2338e-05, PNorm = 62.9807, GNorm = 0.0937, lr_0 = 1.3542e-04
Loss = 1.2593e-05, PNorm = 62.9809, GNorm = 0.0862, lr_0 = 1.3482e-04
Loss = 1.4052e-05, PNorm = 62.9830, GNorm = 0.0887, lr_0 = 1.3423e-04
Validation rmse logD = 0.547342
Validation R2 logD = 0.791358
Epoch 86
Train function
Loss = 1.1804e-05, PNorm = 62.9839, GNorm = 0.0889, lr_0 = 1.3357e-04
Loss = 1.3089e-05, PNorm = 62.9845, GNorm = 0.1398, lr_0 = 1.3298e-04
Loss = 1.2578e-05, PNorm = 62.9864, GNorm = 0.0987, lr_0 = 1.3239e-04
Loss = 1.2467e-05, PNorm = 62.9869, GNorm = 0.1060, lr_0 = 1.3181e-04
Loss = 2.2219e-05, PNorm = 62.9881, GNorm = 0.2638, lr_0 = 1.3123e-04
Loss = 1.7062e-05, PNorm = 62.9899, GNorm = 0.2564, lr_0 = 1.3065e-04
Validation rmse logD = 0.549616
Validation R2 logD = 0.789621
Epoch 87
Train function
Loss = 2.8095e-05, PNorm = 62.9924, GNorm = 0.1885, lr_0 = 1.3001e-04
Loss = 2.1818e-05, PNorm = 62.9930, GNorm = 0.2501, lr_0 = 1.2944e-04
Loss = 2.6183e-05, PNorm = 62.9928, GNorm = 0.0990, lr_0 = 1.2886e-04
Loss = 2.4310e-05, PNorm = 62.9940, GNorm = 0.2118, lr_0 = 1.2829e-04
Loss = 1.8783e-05, PNorm = 62.9953, GNorm = 0.1400, lr_0 = 1.2773e-04
Validation rmse logD = 0.549262
Validation R2 logD = 0.789892
Epoch 88
Train function
Loss = 1.6009e-05, PNorm = 62.9957, GNorm = 0.0800, lr_0 = 1.2710e-04
Loss = 1.3661e-05, PNorm = 62.9965, GNorm = 0.0831, lr_0 = 1.2654e-04
Loss = 1.5166e-05, PNorm = 62.9982, GNorm = 0.1817, lr_0 = 1.2598e-04
Loss = 2.0593e-05, PNorm = 62.9996, GNorm = 0.0858, lr_0 = 1.2542e-04
Loss = 1.5677e-05, PNorm = 63.0012, GNorm = 0.0459, lr_0 = 1.2487e-04
Validation rmse logD = 0.549100
Validation R2 logD = 0.790016
Epoch 89
Train function
Loss = 1.4309e-05, PNorm = 63.0029, GNorm = 0.1497, lr_0 = 1.2426e-04
Loss = 2.0538e-05, PNorm = 63.0045, GNorm = 0.1141, lr_0 = 1.2371e-04
Loss = 1.3723e-05, PNorm = 63.0062, GNorm = 0.0956, lr_0 = 1.2317e-04
Loss = 1.6984e-05, PNorm = 63.0069, GNorm = 0.1747, lr_0 = 1.2262e-04
Loss = 2.4305e-05, PNorm = 63.0079, GNorm = 0.2030, lr_0 = 1.2208e-04
Loss = 1.9059e-05, PNorm = 63.0099, GNorm = 0.0865, lr_0 = 1.2154e-04
Loss = 8.1391e-05, PNorm = 63.0100, GNorm = 0.1917, lr_0 = 1.2148e-04
Validation rmse logD = 0.550779
Validation R2 logD = 0.788730
Epoch 90
Train function
Loss = 1.2590e-05, PNorm = 63.0105, GNorm = 0.1150, lr_0 = 1.2095e-04
Loss = 1.9022e-05, PNorm = 63.0117, GNorm = 0.2491, lr_0 = 1.2041e-04
Loss = 2.1486e-05, PNorm = 63.0135, GNorm = 0.1337, lr_0 = 1.1988e-04
Loss = 1.3548e-05, PNorm = 63.0155, GNorm = 0.0726, lr_0 = 1.1935e-04
Loss = 1.5039e-05, PNorm = 63.0163, GNorm = 0.1178, lr_0 = 1.1882e-04
Validation rmse logD = 0.548718
Validation R2 logD = 0.790308
Epoch 91
Train function
Loss = 1.1447e-05, PNorm = 63.0177, GNorm = 0.0888, lr_0 = 1.1824e-04
Loss = 1.0227e-05, PNorm = 63.0179, GNorm = 0.0730, lr_0 = 1.1772e-04
Loss = 1.1595e-05, PNorm = 63.0188, GNorm = 0.1200, lr_0 = 1.1720e-04
Loss = 1.2477e-05, PNorm = 63.0195, GNorm = 0.1155, lr_0 = 1.1668e-04
Loss = 8.0783e-06, PNorm = 63.0200, GNorm = 0.0714, lr_0 = 1.1616e-04
Validation rmse logD = 0.549355
Validation R2 logD = 0.789821
Epoch 92
Train function
Loss = 1.2166e-05, PNorm = 63.0211, GNorm = 0.0817, lr_0 = 1.1565e-04
Loss = 1.4443e-05, PNorm = 63.0221, GNorm = 0.0851, lr_0 = 1.1514e-04
Loss = 9.0421e-06, PNorm = 63.0231, GNorm = 0.0658, lr_0 = 1.1463e-04
Loss = 1.2698e-05, PNorm = 63.0240, GNorm = 0.1072, lr_0 = 1.1412e-04
Loss = 9.2431e-06, PNorm = 63.0250, GNorm = 0.0806, lr_0 = 1.1362e-04
Loss = 1.0550e-05, PNorm = 63.0257, GNorm = 0.1196, lr_0 = 1.1312e-04
Loss = 7.3880e-05, PNorm = 63.0257, GNorm = 0.1690, lr_0 = 1.1307e-04
Validation rmse logD = 0.549642
Validation R2 logD = 0.789602
Epoch 93
Train function
Loss = 1.5673e-05, PNorm = 63.0269, GNorm = 0.0909, lr_0 = 1.1257e-04
Loss = 9.6749e-06, PNorm = 63.0281, GNorm = 0.0776, lr_0 = 1.1207e-04
Loss = 1.1066e-05, PNorm = 63.0288, GNorm = 0.0395, lr_0 = 1.1157e-04
Loss = 1.1507e-05, PNorm = 63.0303, GNorm = 0.0798, lr_0 = 1.1108e-04
Loss = 8.7481e-06, PNorm = 63.0307, GNorm = 0.0771, lr_0 = 1.1059e-04
Validation rmse logD = 0.548058
Validation R2 logD = 0.790812
Epoch 94
Train function
Loss = 9.0700e-06, PNorm = 63.0312, GNorm = 0.0651, lr_0 = 1.1005e-04
Loss = 1.0557e-05, PNorm = 63.0320, GNorm = 0.1180, lr_0 = 1.0956e-04
Loss = 1.1802e-05, PNorm = 63.0330, GNorm = 0.3321, lr_0 = 1.0908e-04
Loss = 1.3904e-05, PNorm = 63.0344, GNorm = 0.0693, lr_0 = 1.0860e-04
Loss = 9.8343e-06, PNorm = 63.0352, GNorm = 0.0982, lr_0 = 1.0811e-04
Validation rmse logD = 0.548224
Validation R2 logD = 0.790686
Epoch 95
Train function
Loss = 8.7197e-06, PNorm = 63.0358, GNorm = 0.1392, lr_0 = 1.0759e-04
Loss = 9.0370e-06, PNorm = 63.0365, GNorm = 0.0533, lr_0 = 1.0711e-04
Loss = 1.3208e-05, PNorm = 63.0377, GNorm = 0.0670, lr_0 = 1.0664e-04
Loss = 1.0195e-05, PNorm = 63.0380, GNorm = 0.1067, lr_0 = 1.0617e-04
Loss = 1.0990e-05, PNorm = 63.0386, GNorm = 0.1514, lr_0 = 1.0570e-04
Validation rmse logD = 0.548424
Validation R2 logD = 0.790533
Epoch 96
Train function
Loss = 1.0945e-05, PNorm = 63.0401, GNorm = 0.0790, lr_0 = 1.0518e-04
Loss = 1.0733e-05, PNorm = 63.0411, GNorm = 0.0973, lr_0 = 1.0472e-04
Loss = 6.4812e-06, PNorm = 63.0418, GNorm = 0.0555, lr_0 = 1.0426e-04
Loss = 6.2189e-06, PNorm = 63.0427, GNorm = 0.0479, lr_0 = 1.0379e-04
Loss = 8.0679e-06, PNorm = 63.0432, GNorm = 0.0474, lr_0 = 1.0333e-04
Loss = 1.3102e-05, PNorm = 63.0448, GNorm = 0.1371, lr_0 = 1.0288e-04
Validation rmse logD = 0.549534
Validation R2 logD = 0.789684
Epoch 97
Train function
Loss = 7.9376e-06, PNorm = 63.0450, GNorm = 0.0841, lr_0 = 1.0238e-04
Loss = 9.4173e-06, PNorm = 63.0456, GNorm = 0.0545, lr_0 = 1.0192e-04
Loss = 6.0579e-06, PNorm = 63.0465, GNorm = 0.0735, lr_0 = 1.0147e-04
Loss = 1.2246e-05, PNorm = 63.0469, GNorm = 0.1153, lr_0 = 1.0102e-04
Loss = 1.1285e-05, PNorm = 63.0484, GNorm = 0.1050, lr_0 = 1.0058e-04
Validation rmse logD = 0.549982
Validation R2 logD = 0.789341
Epoch 98
Train function
Loss = 6.7902e-06, PNorm = 63.0490, GNorm = 0.0990, lr_0 = 1.0009e-04
Loss = 8.5533e-06, PNorm = 63.0503, GNorm = 0.1220, lr_0 = 1.0000e-04
Loss = 8.5826e-06, PNorm = 63.0508, GNorm = 0.1128, lr_0 = 1.0000e-04
Loss = 1.1998e-05, PNorm = 63.0512, GNorm = 0.0903, lr_0 = 1.0000e-04
Loss = 6.8111e-06, PNorm = 63.0511, GNorm = 0.1048, lr_0 = 1.0000e-04
Validation rmse logD = 0.548503
Validation R2 logD = 0.790472
Epoch 99
Train function
Loss = 1.0025e-05, PNorm = 63.0524, GNorm = 0.2740, lr_0 = 1.0000e-04
Loss = 1.8833e-05, PNorm = 63.0540, GNorm = 0.1670, lr_0 = 1.0000e-04
Loss = 1.1660e-05, PNorm = 63.0555, GNorm = 0.0728, lr_0 = 1.0000e-04
Loss = 1.1039e-05, PNorm = 63.0572, GNorm = 0.0504, lr_0 = 1.0000e-04
Loss = 6.6669e-06, PNorm = 63.0571, GNorm = 0.0332, lr_0 = 1.0000e-04
Loss = 1.0197e-05, PNorm = 63.0573, GNorm = 0.0478, lr_0 = 1.0000e-04
Validation rmse logD = 0.549214
Validation R2 logD = 0.789929
Model 0 best validation rmse = 0.539477 on epoch 46
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.585614
Model 0 test R2 logD = 0.762813
Ensemble test rmse  logD= 0.585614
Ensemble test R2  logD= 0.762813
4-fold cross validation
	Seed 0 ==> test rmse = 0.562715
	Seed 0 ==> test R2 = 0.780999
	Seed 1 ==> test rmse = 0.594308
	Seed 1 ==> test R2 = 0.755719
	Seed 2 ==> test rmse = 0.617083
	Seed 2 ==> test R2 = 0.736637
	Seed 3 ==> test rmse = 0.585614
	Seed 3 ==> test R2 = 0.762813
Overall val rmse logD= 0.567781 +/- 0.016560
Overall val R2 logD = 0.774335 +/- 0.018111
Overall test rmse logD = 0.589930 +/- 0.019466
Overall test R2 logD = 0.759042 +/- 0.015886
Elapsed time = 1:31:54
