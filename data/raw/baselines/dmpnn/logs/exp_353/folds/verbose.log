Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,166 | train size = 2,832 | val size = 500 | test size = 834
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.1697e-02, PNorm = 52.9124, GNorm = 4.1554, lr_0 = 1.0804e-04
Loss = 1.8384e-02, PNorm = 52.9148, GNorm = 4.9643, lr_0 = 1.0804e-04
Loss = 1.7281e-02, PNorm = 52.9177, GNorm = 3.4420, lr_0 = 1.0804e-04
Loss = 1.8159e-02, PNorm = 52.9211, GNorm = 2.2784, lr_0 = 1.0804e-04
Loss = 1.5113e-02, PNorm = 52.9244, GNorm = 2.1921, lr_0 = 1.0804e-04
Validation rmse logD = 1.098394
Validation R2 logD = 0.232343
Epoch 1
Train function
Loss = 1.5136e-02, PNorm = 52.9282, GNorm = 2.0955, lr_0 = 1.0804e-04
Loss = 1.3759e-02, PNorm = 52.9323, GNorm = 8.0529, lr_0 = 1.0804e-04
Loss = 1.5371e-02, PNorm = 52.9363, GNorm = 4.2659, lr_0 = 1.0804e-04
Loss = 1.4109e-02, PNorm = 52.9413, GNorm = 7.7662, lr_0 = 1.0804e-04
Loss = 1.1450e-02, PNorm = 52.9465, GNorm = 1.9915, lr_0 = 1.0804e-04
Loss = 1.3588e-02, PNorm = 52.9519, GNorm = 2.8633, lr_0 = 1.0804e-04
Validation rmse logD = 1.002233
Validation R2 logD = 0.360872
Epoch 2
Train function
Loss = 1.3907e-02, PNorm = 52.9584, GNorm = 2.8636, lr_0 = 1.0804e-04
Loss = 1.2225e-02, PNorm = 52.9650, GNorm = 5.4042, lr_0 = 1.0804e-04
Loss = 1.2184e-02, PNorm = 52.9708, GNorm = 1.7953, lr_0 = 1.0804e-04
Loss = 1.2605e-02, PNorm = 52.9777, GNorm = 5.5174, lr_0 = 1.0804e-04
Loss = 1.0306e-02, PNorm = 52.9851, GNorm = 1.9824, lr_0 = 1.0804e-04
Validation rmse logD = 0.950140
Validation R2 logD = 0.425585
Epoch 3
Train function
Loss = 6.6862e-03, PNorm = 52.9915, GNorm = 1.2228, lr_0 = 1.0804e-04
Loss = 1.1316e-02, PNorm = 52.9973, GNorm = 3.4938, lr_0 = 1.0804e-04
Loss = 1.1408e-02, PNorm = 53.0059, GNorm = 2.4331, lr_0 = 1.0804e-04
Loss = 9.8432e-03, PNorm = 53.0148, GNorm = 1.6264, lr_0 = 1.0804e-04
Loss = 1.0636e-02, PNorm = 53.0218, GNorm = 2.3426, lr_0 = 1.0804e-04
Loss = 1.0672e-02, PNorm = 53.0292, GNorm = 4.9855, lr_0 = 1.0804e-04
Validation rmse logD = 0.907203
Validation R2 logD = 0.476328
Epoch 4
Train function
Loss = 9.4595e-03, PNorm = 53.0377, GNorm = 6.1992, lr_0 = 1.0804e-04
Loss = 9.4895e-03, PNorm = 53.0462, GNorm = 2.8734, lr_0 = 1.0804e-04
Loss = 1.0029e-02, PNorm = 53.0547, GNorm = 2.2445, lr_0 = 1.0804e-04
Loss = 9.1591e-03, PNorm = 53.0643, GNorm = 3.4652, lr_0 = 1.0804e-04
Loss = 9.6447e-03, PNorm = 53.0737, GNorm = 2.8894, lr_0 = 1.0804e-04
Loss = 9.3602e-03, PNorm = 53.0841, GNorm = 2.5865, lr_0 = 1.0804e-04
Validation rmse logD = 0.830168
Validation R2 logD = 0.561487
Epoch 5
Train function
Loss = 7.8344e-03, PNorm = 53.0953, GNorm = 2.5922, lr_0 = 1.0804e-04
Loss = 9.4912e-03, PNorm = 53.1053, GNorm = 2.8482, lr_0 = 1.0804e-04
Loss = 9.6278e-03, PNorm = 53.1140, GNorm = 6.6490, lr_0 = 1.0804e-04
Loss = 8.5227e-03, PNorm = 53.1236, GNorm = 3.7182, lr_0 = 1.0804e-04
Loss = 9.3226e-03, PNorm = 53.1334, GNorm = 5.9680, lr_0 = 1.0804e-04
Validation rmse logD = 0.877687
Validation R2 logD = 0.509849
Epoch 6
Train function
Loss = 9.1595e-03, PNorm = 53.1437, GNorm = 7.7226, lr_0 = 1.0804e-04
Loss = 9.0054e-03, PNorm = 53.1542, GNorm = 4.4058, lr_0 = 1.0804e-04
Loss = 8.2280e-03, PNorm = 53.1629, GNorm = 1.7751, lr_0 = 1.0804e-04
Loss = 8.0975e-03, PNorm = 53.1728, GNorm = 2.7014, lr_0 = 1.0804e-04
Loss = 8.0007e-03, PNorm = 53.1840, GNorm = 3.6167, lr_0 = 1.0804e-04
Loss = 8.1091e-03, PNorm = 53.1948, GNorm = 1.9940, lr_0 = 1.0804e-04
Validation rmse logD = 0.773988
Validation R2 logD = 0.618830
Epoch 7
Train function
Loss = 9.9216e-03, PNorm = 53.2034, GNorm = 1.5939, lr_0 = 1.0804e-04
Loss = 7.7428e-03, PNorm = 53.2114, GNorm = 5.2074, lr_0 = 1.0804e-04
Loss = 8.0882e-03, PNorm = 53.2209, GNorm = 1.7867, lr_0 = 1.0804e-04
Loss = 6.8366e-03, PNorm = 53.2307, GNorm = 3.4576, lr_0 = 1.0804e-04
Loss = 6.9542e-03, PNorm = 53.2419, GNorm = 1.9160, lr_0 = 1.0804e-04
Loss = 7.4467e-03, PNorm = 53.2544, GNorm = 5.8966, lr_0 = 1.0804e-04
Validation rmse logD = 0.752715
Validation R2 logD = 0.639494
Epoch 8
Train function
Loss = 5.6366e-03, PNorm = 53.2658, GNorm = 2.6937, lr_0 = 1.0804e-04
Loss = 6.8399e-03, PNorm = 53.2773, GNorm = 2.1511, lr_0 = 1.0804e-04
Loss = 7.2242e-03, PNorm = 53.2858, GNorm = 3.9588, lr_0 = 1.0804e-04
Loss = 6.2189e-03, PNorm = 53.2960, GNorm = 2.8095, lr_0 = 1.0804e-04
Loss = 6.0199e-03, PNorm = 53.3078, GNorm = 3.3433, lr_0 = 1.0804e-04
Validation rmse logD = 0.744248
Validation R2 logD = 0.647560
Epoch 9
Train function
Loss = 8.1464e-03, PNorm = 53.3174, GNorm = 6.4731, lr_0 = 1.0804e-04
Loss = 5.9989e-03, PNorm = 53.3301, GNorm = 2.5894, lr_0 = 1.0804e-04
Loss = 5.9044e-03, PNorm = 53.3405, GNorm = 3.4162, lr_0 = 1.0804e-04
Loss = 5.3597e-03, PNorm = 53.3514, GNorm = 3.3182, lr_0 = 1.0804e-04
Loss = 5.8459e-03, PNorm = 53.3616, GNorm = 1.8613, lr_0 = 1.0804e-04
Loss = 6.0145e-03, PNorm = 53.3706, GNorm = 2.2544, lr_0 = 1.0804e-04
Validation rmse logD = 0.737601
Validation R2 logD = 0.653827
Epoch 10
Train function
Loss = 3.7125e-03, PNorm = 53.3801, GNorm = 5.1023, lr_0 = 1.0804e-04
Loss = 5.4721e-03, PNorm = 53.3895, GNorm = 2.4316, lr_0 = 1.0804e-04
Loss = 7.0193e-03, PNorm = 53.3987, GNorm = 3.1528, lr_0 = 1.0804e-04
Loss = 6.7696e-03, PNorm = 53.4065, GNorm = 7.3444, lr_0 = 1.0804e-04
Loss = 6.2459e-03, PNorm = 53.4155, GNorm = 2.0369, lr_0 = 1.0804e-04
Loss = 7.0964e-03, PNorm = 53.4244, GNorm = 10.5064, lr_0 = 1.0804e-04
Validation rmse logD = 0.737672
Validation R2 logD = 0.653760
Epoch 11
Train function
Loss = 4.7317e-03, PNorm = 53.4336, GNorm = 3.0780, lr_0 = 1.0804e-04
Loss = 5.2458e-03, PNorm = 53.4428, GNorm = 2.5228, lr_0 = 1.0804e-04
Loss = 5.8757e-03, PNorm = 53.4526, GNorm = 3.3122, lr_0 = 1.0804e-04
Loss = 4.9145e-03, PNorm = 53.4616, GNorm = 6.8009, lr_0 = 1.0804e-04
Loss = 5.4862e-03, PNorm = 53.4697, GNorm = 3.3434, lr_0 = 1.0804e-04
Validation rmse logD = 0.707228
Validation R2 logD = 0.681749
Epoch 12
Train function
Loss = 4.6468e-03, PNorm = 53.4793, GNorm = 4.2311, lr_0 = 1.0804e-04
Loss = 5.1568e-03, PNorm = 53.4869, GNorm = 4.7182, lr_0 = 1.0804e-04
Loss = 5.4048e-03, PNorm = 53.4973, GNorm = 2.0180, lr_0 = 1.0804e-04
Loss = 4.8761e-03, PNorm = 53.5074, GNorm = 7.7213, lr_0 = 1.0804e-04
Loss = 4.5185e-03, PNorm = 53.5150, GNorm = 7.7031, lr_0 = 1.0804e-04
Loss = 5.1298e-03, PNorm = 53.5218, GNorm = 2.0320, lr_0 = 1.0804e-04
Validation rmse logD = 0.683394
Validation R2 logD = 0.702839
Epoch 13
Train function
Loss = 4.6666e-03, PNorm = 53.5330, GNorm = 3.5177, lr_0 = 1.0804e-04
Loss = 4.9186e-03, PNorm = 53.5416, GNorm = 7.0343, lr_0 = 1.0804e-04
Loss = 5.6563e-03, PNorm = 53.5500, GNorm = 6.0212, lr_0 = 1.0804e-04
Loss = 4.4521e-03, PNorm = 53.5585, GNorm = 5.4769, lr_0 = 1.0804e-04
Loss = 5.1813e-03, PNorm = 53.5678, GNorm = 1.5898, lr_0 = 1.0804e-04
Loss = 4.4815e-03, PNorm = 53.5741, GNorm = 1.8489, lr_0 = 1.0804e-04
Validation rmse logD = 0.649023
Validation R2 logD = 0.731978
Epoch 14
Train function
Loss = 4.5038e-03, PNorm = 53.5841, GNorm = 2.3916, lr_0 = 1.0804e-04
Loss = 3.7746e-03, PNorm = 53.5935, GNorm = 2.6751, lr_0 = 1.0804e-04
Loss = 4.0067e-03, PNorm = 53.6011, GNorm = 1.9331, lr_0 = 1.0804e-04
Loss = 5.0699e-03, PNorm = 53.6090, GNorm = 8.8105, lr_0 = 1.0804e-04
Loss = 4.5556e-03, PNorm = 53.6173, GNorm = 3.5387, lr_0 = 1.0804e-04
Validation rmse logD = 0.680034
Validation R2 logD = 0.705753
Epoch 15
Train function
Loss = 4.6550e-03, PNorm = 53.6259, GNorm = 2.1879, lr_0 = 1.0804e-04
Loss = 4.2723e-03, PNorm = 53.6338, GNorm = 3.7314, lr_0 = 1.0804e-04
Loss = 4.0238e-03, PNorm = 53.6423, GNorm = 2.8269, lr_0 = 1.0804e-04
Loss = 4.5827e-03, PNorm = 53.6516, GNorm = 4.4947, lr_0 = 1.0804e-04
Loss = 4.6895e-03, PNorm = 53.6594, GNorm = 2.3261, lr_0 = 1.0804e-04
Loss = 3.8087e-03, PNorm = 53.6675, GNorm = 2.0386, lr_0 = 1.0804e-04
Validation rmse logD = 0.632611
Validation R2 logD = 0.745362
Epoch 16
Train function
Loss = 4.0322e-03, PNorm = 53.6778, GNorm = 1.8906, lr_0 = 1.0804e-04
Loss = 3.1008e-03, PNorm = 53.6861, GNorm = 7.2268, lr_0 = 1.0804e-04
Loss = 3.9463e-03, PNorm = 53.6934, GNorm = 1.6332, lr_0 = 1.0804e-04
Loss = 3.9942e-03, PNorm = 53.6997, GNorm = 3.4173, lr_0 = 1.0804e-04
Loss = 3.9717e-03, PNorm = 53.7090, GNorm = 6.7637, lr_0 = 1.0804e-04
Loss = 3.8448e-03, PNorm = 53.7167, GNorm = 4.1591, lr_0 = 1.0804e-04
Validation rmse logD = 0.633824
Validation R2 logD = 0.744384
Epoch 17
Train function
Loss = 3.1231e-03, PNorm = 53.7256, GNorm = 2.5498, lr_0 = 1.0804e-04
Loss = 4.0136e-03, PNorm = 53.7333, GNorm = 6.2215, lr_0 = 1.0804e-04
Loss = 3.8761e-03, PNorm = 53.7419, GNorm = 3.8356, lr_0 = 1.0804e-04
Loss = 3.7217e-03, PNorm = 53.7506, GNorm = 2.7242, lr_0 = 1.0804e-04
Loss = 3.5695e-03, PNorm = 53.7589, GNorm = 2.1818, lr_0 = 1.0804e-04
Validation rmse logD = 0.643002
Validation R2 logD = 0.736928
Epoch 18
Train function
Loss = 2.6676e-03, PNorm = 53.7684, GNorm = 4.2398, lr_0 = 1.0804e-04
Loss = 3.4858e-03, PNorm = 53.7765, GNorm = 3.4923, lr_0 = 1.0804e-04
Loss = 3.1792e-03, PNorm = 53.7845, GNorm = 2.1788, lr_0 = 1.0804e-04
Loss = 3.9565e-03, PNorm = 53.7929, GNorm = 7.7211, lr_0 = 1.0804e-04
Loss = 3.3105e-03, PNorm = 53.8011, GNorm = 3.6323, lr_0 = 1.0804e-04
Loss = 3.4232e-03, PNorm = 53.8088, GNorm = 5.6233, lr_0 = 1.0804e-04
Validation rmse logD = 0.618121
Validation R2 logD = 0.756893
Epoch 19
Train function
Loss = 3.6893e-03, PNorm = 53.8159, GNorm = 1.4642, lr_0 = 1.0804e-04
Loss = 3.2486e-03, PNorm = 53.8239, GNorm = 3.8724, lr_0 = 1.0804e-04
Loss = 4.0258e-03, PNorm = 53.8308, GNorm = 4.2323, lr_0 = 1.0804e-04
Loss = 3.2439e-03, PNorm = 53.8391, GNorm = 2.7763, lr_0 = 1.0804e-04
Loss = 3.0405e-03, PNorm = 53.8483, GNorm = 1.8275, lr_0 = 1.0804e-04
Loss = 3.1353e-03, PNorm = 53.8562, GNorm = 2.5945, lr_0 = 1.0804e-04
Validation rmse logD = 0.618683
Validation R2 logD = 0.756451
Epoch 20
Train function
Loss = 2.9873e-03, PNorm = 53.8661, GNorm = 2.7432, lr_0 = 1.0804e-04
Loss = 4.4406e-03, PNorm = 53.8710, GNorm = 10.2167, lr_0 = 1.0804e-04
Loss = 4.3299e-03, PNorm = 53.8781, GNorm = 8.4429, lr_0 = 1.0804e-04
Loss = 3.2176e-03, PNorm = 53.8855, GNorm = 2.3161, lr_0 = 1.0804e-04
Loss = 3.6544e-03, PNorm = 53.8944, GNorm = 6.9482, lr_0 = 1.0804e-04
Validation rmse logD = 0.638799
Validation R2 logD = 0.740355
Epoch 21
Train function
Loss = 3.4798e-03, PNorm = 53.9023, GNorm = 4.9928, lr_0 = 1.0804e-04
Loss = 3.2238e-03, PNorm = 53.9109, GNorm = 7.6144, lr_0 = 1.0804e-04
Loss = 2.7209e-03, PNorm = 53.9186, GNorm = 2.0070, lr_0 = 1.0804e-04
Loss = 2.9506e-03, PNorm = 53.9256, GNorm = 1.9976, lr_0 = 1.0804e-04
Loss = 3.2385e-03, PNorm = 53.9333, GNorm = 5.3065, lr_0 = 1.0804e-04
Loss = 3.3795e-03, PNorm = 53.9413, GNorm = 4.5280, lr_0 = 1.0804e-04
Validation rmse logD = 0.634784
Validation R2 logD = 0.743609
Epoch 22
Train function
Loss = 3.0439e-03, PNorm = 53.9489, GNorm = 6.3140, lr_0 = 1.0804e-04
Loss = 3.4508e-03, PNorm = 53.9543, GNorm = 3.3241, lr_0 = 1.0804e-04
Loss = 3.1459e-03, PNorm = 53.9633, GNorm = 5.6322, lr_0 = 1.0804e-04
Loss = 3.4793e-03, PNorm = 53.9720, GNorm = 4.1293, lr_0 = 1.0804e-04
Loss = 2.7363e-03, PNorm = 53.9812, GNorm = 2.1104, lr_0 = 1.0804e-04
Loss = 3.1407e-03, PNorm = 53.9890, GNorm = 1.6070, lr_0 = 1.0804e-04
Validation rmse logD = 0.673793
Validation R2 logD = 0.711130
Epoch 23
Train function
Loss = 2.9362e-03, PNorm = 53.9946, GNorm = 7.5548, lr_0 = 1.0804e-04
Loss = 2.6947e-03, PNorm = 54.0034, GNorm = 5.2496, lr_0 = 1.0804e-04
Loss = 2.8316e-03, PNorm = 54.0104, GNorm = 4.6575, lr_0 = 1.0804e-04
Loss = 2.7453e-03, PNorm = 54.0169, GNorm = 2.3603, lr_0 = 1.0804e-04
Loss = 3.0898e-03, PNorm = 54.0233, GNorm = 4.0347, lr_0 = 1.0804e-04
Validation rmse logD = 0.607548
Validation R2 logD = 0.765139
Epoch 24
Train function
Loss = 1.9532e-03, PNorm = 54.0306, GNorm = 1.6683, lr_0 = 1.0804e-04
Loss = 2.7092e-03, PNorm = 54.0388, GNorm = 2.3638, lr_0 = 1.0804e-04
Loss = 3.1048e-03, PNorm = 54.0477, GNorm = 11.9114, lr_0 = 1.0804e-04
Loss = 3.1422e-03, PNorm = 54.0543, GNorm = 5.6232, lr_0 = 1.0804e-04
Loss = 3.2914e-03, PNorm = 54.0613, GNorm = 6.4335, lr_0 = 1.0804e-04
Loss = 3.1488e-03, PNorm = 54.0673, GNorm = 3.4325, lr_0 = 1.0804e-04
Validation rmse logD = 0.606181
Validation R2 logD = 0.766194
Epoch 25
Train function
Loss = 2.3588e-03, PNorm = 54.0753, GNorm = 4.2711, lr_0 = 1.0804e-04
Loss = 2.6456e-03, PNorm = 54.0836, GNorm = 2.8741, lr_0 = 1.0804e-04
Loss = 2.7143e-03, PNorm = 54.0890, GNorm = 2.6665, lr_0 = 1.0804e-04
Loss = 2.5753e-03, PNorm = 54.0967, GNorm = 6.8846, lr_0 = 1.0804e-04
Loss = 2.6282e-03, PNorm = 54.1046, GNorm = 3.6537, lr_0 = 1.0804e-04
Loss = 2.5624e-03, PNorm = 54.1110, GNorm = 3.3219, lr_0 = 1.0804e-04
Validation rmse logD = 0.593519
Validation R2 logD = 0.775860
Epoch 26
Train function
Loss = 2.3273e-03, PNorm = 54.1206, GNorm = 7.0795, lr_0 = 1.0804e-04
Loss = 2.3517e-03, PNorm = 54.1277, GNorm = 2.2049, lr_0 = 1.0804e-04
Loss = 2.7951e-03, PNorm = 54.1377, GNorm = 4.8376, lr_0 = 1.0804e-04
Loss = 2.1634e-03, PNorm = 54.1440, GNorm = 3.3151, lr_0 = 1.0804e-04
Loss = 2.4429e-03, PNorm = 54.1501, GNorm = 3.0637, lr_0 = 1.0804e-04
Validation rmse logD = 0.589929
Validation R2 logD = 0.778563
Epoch 27
Train function
Loss = 2.8545e-03, PNorm = 54.1544, GNorm = 4.7824, lr_0 = 1.0804e-04
Loss = 2.9292e-03, PNorm = 54.1601, GNorm = 7.7432, lr_0 = 1.0804e-04
Loss = 2.2708e-03, PNorm = 54.1672, GNorm = 2.1731, lr_0 = 1.0804e-04
Loss = 2.3075e-03, PNorm = 54.1760, GNorm = 3.9981, lr_0 = 1.0804e-04
Loss = 2.1014e-03, PNorm = 54.1833, GNorm = 1.8468, lr_0 = 1.0804e-04
Loss = 1.9967e-03, PNorm = 54.1901, GNorm = 2.0363, lr_0 = 1.0804e-04
Validation rmse logD = 0.577714
Validation R2 logD = 0.787638
Epoch 28
Train function
Loss = 2.1034e-03, PNorm = 54.1962, GNorm = 2.7292, lr_0 = 1.0804e-04
Loss = 2.5822e-03, PNorm = 54.2023, GNorm = 5.2379, lr_0 = 1.0804e-04
Loss = 2.1199e-03, PNorm = 54.2091, GNorm = 1.8152, lr_0 = 1.0804e-04
Loss = 2.3088e-03, PNorm = 54.2168, GNorm = 3.7862, lr_0 = 1.0804e-04
Loss = 2.4398e-03, PNorm = 54.2229, GNorm = 1.4365, lr_0 = 1.0804e-04
Loss = 2.0521e-03, PNorm = 54.2304, GNorm = 1.0654, lr_0 = 1.0804e-04
Validation rmse logD = 0.612382
Validation R2 logD = 0.761387
Epoch 29
Train function
Loss = 2.0894e-03, PNorm = 54.2372, GNorm = 2.2604, lr_0 = 1.0804e-04
Loss = 2.0404e-03, PNorm = 54.2444, GNorm = 3.2898, lr_0 = 1.0804e-04
Loss = 2.5325e-03, PNorm = 54.2524, GNorm = 1.7742, lr_0 = 1.0804e-04
Loss = 1.7477e-03, PNorm = 54.2582, GNorm = 3.5246, lr_0 = 1.0804e-04
Loss = 2.1739e-03, PNorm = 54.2658, GNorm = 10.5125, lr_0 = 1.0804e-04
Validation rmse logD = 0.575256
Validation R2 logD = 0.789442
Epoch 30
Train function
Loss = 1.6387e-03, PNorm = 54.2705, GNorm = 1.1815, lr_0 = 1.0804e-04
Loss = 2.1378e-03, PNorm = 54.2768, GNorm = 2.9895, lr_0 = 1.0804e-04
Loss = 2.2170e-03, PNorm = 54.2859, GNorm = 2.7440, lr_0 = 1.0804e-04
Loss = 1.9110e-03, PNorm = 54.2934, GNorm = 1.8606, lr_0 = 1.0804e-04
Loss = 1.9141e-03, PNorm = 54.3004, GNorm = 5.3065, lr_0 = 1.0804e-04
Loss = 2.2982e-03, PNorm = 54.3071, GNorm = 7.2840, lr_0 = 1.0804e-04
Validation rmse logD = 0.573827
Validation R2 logD = 0.790487
Epoch 31
Train function
Loss = 1.5142e-03, PNorm = 54.3144, GNorm = 1.3446, lr_0 = 1.0804e-04
Loss = 2.0185e-03, PNorm = 54.3211, GNorm = 4.7805, lr_0 = 1.0804e-04
Loss = 1.9811e-03, PNorm = 54.3291, GNorm = 1.4413, lr_0 = 1.0804e-04
Loss = 1.7519e-03, PNorm = 54.3358, GNorm = 1.4683, lr_0 = 1.0804e-04
Loss = 1.7976e-03, PNorm = 54.3421, GNorm = 3.5759, lr_0 = 1.0804e-04
Loss = 2.0539e-03, PNorm = 54.3485, GNorm = 2.0816, lr_0 = 1.0804e-04
Validation rmse logD = 0.570121
Validation R2 logD = 0.793184
Epoch 32
Train function
Loss = 1.5803e-03, PNorm = 54.3556, GNorm = 2.9411, lr_0 = 1.0804e-04
Loss = 1.8307e-03, PNorm = 54.3623, GNorm = 3.4366, lr_0 = 1.0804e-04
Loss = 1.8119e-03, PNorm = 54.3680, GNorm = 1.8895, lr_0 = 1.0804e-04
Loss = 1.6428e-03, PNorm = 54.3736, GNorm = 1.8284, lr_0 = 1.0804e-04
Loss = 2.0735e-03, PNorm = 54.3803, GNorm = 2.7220, lr_0 = 1.0804e-04
Validation rmse logD = 0.576302
Validation R2 logD = 0.788675
Epoch 33
Train function
Loss = 1.6285e-03, PNorm = 54.3868, GNorm = 4.3138, lr_0 = 1.0804e-04
Loss = 2.0218e-03, PNorm = 54.3935, GNorm = 2.1349, lr_0 = 1.0804e-04
Loss = 1.8397e-03, PNorm = 54.3988, GNorm = 1.7017, lr_0 = 1.0804e-04
Loss = 1.9589e-03, PNorm = 54.4047, GNorm = 2.7784, lr_0 = 1.0804e-04
Loss = 1.5639e-03, PNorm = 54.4126, GNorm = 4.2301, lr_0 = 1.0804e-04
Loss = 1.8612e-03, PNorm = 54.4194, GNorm = 2.3238, lr_0 = 1.0804e-04
Validation rmse logD = 0.583148
Validation R2 logD = 0.783625
Epoch 34
Train function
Loss = 1.7035e-03, PNorm = 54.4250, GNorm = 5.1692, lr_0 = 1.0804e-04
Loss = 1.7066e-03, PNorm = 54.4318, GNorm = 2.4662, lr_0 = 1.0804e-04
Loss = 1.6362e-03, PNorm = 54.4378, GNorm = 3.0855, lr_0 = 1.0804e-04
Loss = 1.6645e-03, PNorm = 54.4452, GNorm = 3.7406, lr_0 = 1.0804e-04
Loss = 1.8077e-03, PNorm = 54.4513, GNorm = 2.5519, lr_0 = 1.0804e-04
Loss = 1.9805e-03, PNorm = 54.4580, GNorm = 1.9318, lr_0 = 1.0804e-04
Validation rmse logD = 0.568908
Validation R2 logD = 0.794063
Epoch 35
Train function
Loss = 2.0674e-03, PNorm = 54.4656, GNorm = 1.3365, lr_0 = 1.0804e-04
Loss = 2.4024e-03, PNorm = 54.4697, GNorm = 5.3352, lr_0 = 1.0804e-04
Loss = 2.8298e-03, PNorm = 54.4747, GNorm = 5.2944, lr_0 = 1.0804e-04
Loss = 2.4924e-03, PNorm = 54.4822, GNorm = 7.0104, lr_0 = 1.0804e-04
Loss = 2.2651e-03, PNorm = 54.4889, GNorm = 4.2429, lr_0 = 1.0804e-04
Validation rmse logD = 0.567665
Validation R2 logD = 0.794962
Epoch 36
Train function
Loss = 8.9035e-04, PNorm = 54.4967, GNorm = 1.3254, lr_0 = 1.0804e-04
Loss = 1.6043e-03, PNorm = 54.5045, GNorm = 1.3148, lr_0 = 1.0804e-04
Loss = 1.7790e-03, PNorm = 54.5106, GNorm = 7.5581, lr_0 = 1.0804e-04
Loss = 1.6386e-03, PNorm = 54.5170, GNorm = 1.1326, lr_0 = 1.0804e-04
Loss = 1.6238e-03, PNorm = 54.5230, GNorm = 1.3495, lr_0 = 1.0804e-04
Loss = 1.7318e-03, PNorm = 54.5296, GNorm = 5.7117, lr_0 = 1.0804e-04
Validation rmse logD = 0.578936
Validation R2 logD = 0.786739
Epoch 37
Train function
Loss = 1.6762e-03, PNorm = 54.5370, GNorm = 7.9186, lr_0 = 1.0804e-04
Loss = 1.9144e-03, PNorm = 54.5425, GNorm = 6.9968, lr_0 = 1.0804e-04
Loss = 1.7422e-03, PNorm = 54.5480, GNorm = 3.6655, lr_0 = 1.0804e-04
Loss = 1.9308e-03, PNorm = 54.5549, GNorm = 1.7374, lr_0 = 1.0804e-04
Loss = 1.7166e-03, PNorm = 54.5612, GNorm = 6.3459, lr_0 = 1.0804e-04
Loss = 1.8816e-03, PNorm = 54.5678, GNorm = 3.6924, lr_0 = 1.0804e-04
Validation rmse logD = 0.560394
Validation R2 logD = 0.800181
Epoch 38
Train function
Loss = 1.4100e-03, PNorm = 54.5752, GNorm = 1.5359, lr_0 = 1.0804e-04
Loss = 1.2243e-03, PNorm = 54.5808, GNorm = 4.0260, lr_0 = 1.0804e-04
Loss = 1.4918e-03, PNorm = 54.5861, GNorm = 3.7017, lr_0 = 1.0804e-04
Loss = 1.3589e-03, PNorm = 54.5911, GNorm = 1.2512, lr_0 = 1.0804e-04
Loss = 1.5633e-03, PNorm = 54.5964, GNorm = 3.6247, lr_0 = 1.0804e-04
Validation rmse logD = 0.560164
Validation R2 logD = 0.800345
Epoch 39
Train function
Loss = 1.5756e-03, PNorm = 54.6029, GNorm = 2.6653, lr_0 = 1.0804e-04
Loss = 1.4954e-03, PNorm = 54.6098, GNorm = 8.6370, lr_0 = 1.0804e-04
Loss = 1.3591e-03, PNorm = 54.6163, GNorm = 2.6629, lr_0 = 1.0804e-04
Loss = 1.5929e-03, PNorm = 54.6209, GNorm = 1.2887, lr_0 = 1.0804e-04
Loss = 1.2617e-03, PNorm = 54.6256, GNorm = 1.3869, lr_0 = 1.0804e-04
Loss = 1.5164e-03, PNorm = 54.6318, GNorm = 2.4898, lr_0 = 1.0804e-04
Validation rmse logD = 0.572661
Validation R2 logD = 0.791337
Epoch 40
Train function
Loss = 1.0997e-03, PNorm = 54.6364, GNorm = 1.6715, lr_0 = 1.0804e-04
Loss = 1.4232e-03, PNorm = 54.6400, GNorm = 1.7018, lr_0 = 1.0804e-04
Loss = 1.5851e-03, PNorm = 54.6458, GNorm = 6.0697, lr_0 = 1.0804e-04
Loss = 1.6656e-03, PNorm = 54.6515, GNorm = 2.9069, lr_0 = 1.0804e-04
Loss = 1.3482e-03, PNorm = 54.6597, GNorm = 1.3775, lr_0 = 1.0804e-04
Loss = 1.3534e-03, PNorm = 54.6657, GNorm = 1.8027, lr_0 = 1.0804e-04
Validation rmse logD = 0.550887
Validation R2 logD = 0.806903
Epoch 41
Train function
Loss = 1.0884e-03, PNorm = 54.6710, GNorm = 1.4128, lr_0 = 1.0804e-04
Loss = 1.1262e-03, PNorm = 54.6757, GNorm = 1.3304, lr_0 = 1.0804e-04
Loss = 9.8440e-04, PNorm = 54.6812, GNorm = 1.6772, lr_0 = 1.0804e-04
Loss = 1.3567e-03, PNorm = 54.6870, GNorm = 6.0900, lr_0 = 1.0804e-04
Loss = 1.2322e-03, PNorm = 54.6929, GNorm = 2.6883, lr_0 = 1.0804e-04
Validation rmse logD = 0.561834
Validation R2 logD = 0.799152
Epoch 42
Train function
Loss = 1.3688e-03, PNorm = 54.6973, GNorm = 2.2826, lr_0 = 1.0804e-04
Loss = 1.2766e-03, PNorm = 54.7017, GNorm = 2.7478, lr_0 = 1.0804e-04
Loss = 1.0234e-03, PNorm = 54.7083, GNorm = 3.5597, lr_0 = 1.0804e-04
Loss = 1.2126e-03, PNorm = 54.7127, GNorm = 2.0675, lr_0 = 1.0804e-04
Loss = 1.2803e-03, PNorm = 54.7175, GNorm = 3.9473, lr_0 = 1.0804e-04
Loss = 1.3108e-03, PNorm = 54.7237, GNorm = 1.7482, lr_0 = 1.0804e-04
Validation rmse logD = 0.546537
Validation R2 logD = 0.809941
Epoch 43
Train function
Loss = 7.9532e-04, PNorm = 54.7292, GNorm = 4.2035, lr_0 = 1.0804e-04
Loss = 1.1726e-03, PNorm = 54.7345, GNorm = 3.0602, lr_0 = 1.0804e-04
Loss = 1.1418e-03, PNorm = 54.7403, GNorm = 2.7507, lr_0 = 1.0804e-04
Loss = 1.0094e-03, PNorm = 54.7456, GNorm = 1.3947, lr_0 = 1.0804e-04
Loss = 1.1105e-03, PNorm = 54.7525, GNorm = 2.9340, lr_0 = 1.0804e-04
Loss = 1.0864e-03, PNorm = 54.7580, GNorm = 1.6293, lr_0 = 1.0804e-04
Validation rmse logD = 0.545305
Validation R2 logD = 0.810797
Epoch 44
Train function
Loss = 8.5987e-04, PNorm = 54.7626, GNorm = 2.5271, lr_0 = 1.0804e-04
Loss = 8.6228e-04, PNorm = 54.7669, GNorm = 2.2672, lr_0 = 1.0804e-04
Loss = 9.7181e-04, PNorm = 54.7716, GNorm = 1.3329, lr_0 = 1.0804e-04
Loss = 1.2820e-03, PNorm = 54.7773, GNorm = 3.2839, lr_0 = 1.0804e-04
Loss = 1.8837e-03, PNorm = 54.7818, GNorm = 3.2563, lr_0 = 1.0804e-04
Validation rmse logD = 0.588601
Validation R2 logD = 0.779559
Epoch 45
Train function
Loss = 1.0131e-03, PNorm = 54.7894, GNorm = 4.0062, lr_0 = 1.0804e-04
Loss = 8.7987e-04, PNorm = 54.7938, GNorm = 2.3158, lr_0 = 1.0804e-04
Loss = 1.1315e-03, PNorm = 54.7995, GNorm = 3.2587, lr_0 = 1.0804e-04
Loss = 8.8497e-04, PNorm = 54.8045, GNorm = 1.6290, lr_0 = 1.0804e-04
Loss = 1.2462e-03, PNorm = 54.8087, GNorm = 4.4959, lr_0 = 1.0804e-04
Loss = 1.3822e-03, PNorm = 54.8135, GNorm = 1.2670, lr_0 = 1.0804e-04
Validation rmse logD = 0.542222
Validation R2 logD = 0.812930
Epoch 46
Train function
Loss = 8.7590e-04, PNorm = 54.8208, GNorm = 1.0898, lr_0 = 1.0804e-04
Loss = 1.0497e-03, PNorm = 54.8268, GNorm = 2.7650, lr_0 = 1.0804e-04
Loss = 9.6465e-04, PNorm = 54.8326, GNorm = 0.9121, lr_0 = 1.0804e-04
Loss = 1.0601e-03, PNorm = 54.8381, GNorm = 7.5729, lr_0 = 1.0804e-04
Loss = 1.3785e-03, PNorm = 54.8412, GNorm = 9.0523, lr_0 = 1.0804e-04
Loss = 1.4940e-03, PNorm = 54.8452, GNorm = 1.6377, lr_0 = 1.0804e-04
Validation rmse logD = 0.541642
Validation R2 logD = 0.813330
Epoch 47
Train function
Loss = 1.1553e-03, PNorm = 54.8497, GNorm = 3.3230, lr_0 = 1.0804e-04
Loss = 1.1202e-03, PNorm = 54.8564, GNorm = 4.8470, lr_0 = 1.0804e-04
Loss = 8.9800e-04, PNorm = 54.8618, GNorm = 2.5634, lr_0 = 1.0804e-04
Loss = 9.7331e-04, PNorm = 54.8675, GNorm = 2.2100, lr_0 = 1.0804e-04
Loss = 8.5440e-04, PNorm = 54.8724, GNorm = 1.2540, lr_0 = 1.0804e-04
Validation rmse logD = 0.544335
Validation R2 logD = 0.811469
Epoch 48
Train function
Loss = 7.5143e-04, PNorm = 54.8769, GNorm = 5.7160, lr_0 = 1.0804e-04
Loss = 9.4778e-04, PNorm = 54.8812, GNorm = 4.7688, lr_0 = 1.0804e-04
Loss = 9.5465e-04, PNorm = 54.8862, GNorm = 1.1369, lr_0 = 1.0804e-04
Loss = 8.6767e-04, PNorm = 54.8901, GNorm = 2.1677, lr_0 = 1.0804e-04
Loss = 1.0638e-03, PNorm = 54.8940, GNorm = 5.3451, lr_0 = 1.0804e-04
Loss = 1.0369e-03, PNorm = 54.9003, GNorm = 3.7823, lr_0 = 1.0804e-04
Validation rmse logD = 0.586908
Validation R2 logD = 0.780825
Epoch 49
Train function
Loss = 1.0456e-03, PNorm = 54.9056, GNorm = 1.6009, lr_0 = 1.0804e-04
Loss = 8.4512e-04, PNorm = 54.9112, GNorm = 2.2847, lr_0 = 1.0804e-04
Loss = 7.8828e-04, PNorm = 54.9145, GNorm = 2.4022, lr_0 = 1.0804e-04
Loss = 8.5462e-04, PNorm = 54.9176, GNorm = 3.3193, lr_0 = 1.0804e-04
Loss = 1.0628e-03, PNorm = 54.9236, GNorm = 5.7160, lr_0 = 1.0804e-04
Loss = 1.1362e-03, PNorm = 54.9292, GNorm = 6.9310, lr_0 = 1.0804e-04
Validation rmse logD = 0.555161
Validation R2 logD = 0.803895
Epoch 50
Train function
Loss = 8.3119e-04, PNorm = 54.9326, GNorm = 2.0588, lr_0 = 1.0804e-04
Loss = 9.0187e-04, PNorm = 54.9369, GNorm = 2.4198, lr_0 = 1.0804e-04
Loss = 8.9804e-04, PNorm = 54.9417, GNorm = 2.8478, lr_0 = 1.0804e-04
Loss = 9.8114e-04, PNorm = 54.9472, GNorm = 2.4542, lr_0 = 1.0804e-04
Loss = 1.1761e-03, PNorm = 54.9521, GNorm = 1.6442, lr_0 = 1.0804e-04
Validation rmse logD = 0.542815
Validation R2 logD = 0.812521
Epoch 51
Train function
Loss = 7.9729e-04, PNorm = 54.9578, GNorm = 4.0897, lr_0 = 1.0804e-04
Loss = 8.3217e-04, PNorm = 54.9641, GNorm = 2.7735, lr_0 = 1.0804e-04
Loss = 7.7850e-04, PNorm = 54.9678, GNorm = 1.0869, lr_0 = 1.0804e-04
Loss = 8.0185e-04, PNorm = 54.9703, GNorm = 2.3194, lr_0 = 1.0804e-04
Loss = 9.0362e-04, PNorm = 54.9758, GNorm = 1.2243, lr_0 = 1.0804e-04
Loss = 1.0469e-03, PNorm = 54.9804, GNorm = 7.6117, lr_0 = 1.0804e-04
Validation rmse logD = 0.553017
Validation R2 logD = 0.805407
Epoch 52
Train function
Loss = 9.9177e-04, PNorm = 54.9848, GNorm = 2.9401, lr_0 = 1.0804e-04
Loss = 8.6773e-04, PNorm = 54.9910, GNorm = 1.3778, lr_0 = 1.0804e-04
Loss = 7.9990e-04, PNorm = 54.9967, GNorm = 3.4593, lr_0 = 1.0804e-04
Loss = 9.2838e-04, PNorm = 54.9999, GNorm = 2.6278, lr_0 = 1.0804e-04
Loss = 8.2378e-04, PNorm = 55.0016, GNorm = 4.1097, lr_0 = 1.0804e-04
Loss = 7.4798e-04, PNorm = 55.0069, GNorm = 1.3054, lr_0 = 1.0804e-04
Validation rmse logD = 0.563669
Validation R2 logD = 0.797838
Epoch 53
Train function
Loss = 6.2465e-04, PNorm = 55.0115, GNorm = 1.2288, lr_0 = 1.0804e-04
Loss = 8.5038e-04, PNorm = 55.0153, GNorm = 3.5482, lr_0 = 1.0804e-04
Loss = 8.5812e-04, PNorm = 55.0200, GNorm = 1.2140, lr_0 = 1.0804e-04
Loss = 9.3091e-04, PNorm = 55.0242, GNorm = 2.9778, lr_0 = 1.0804e-04
Loss = 7.0433e-04, PNorm = 55.0285, GNorm = 1.4107, lr_0 = 1.0804e-04
Validation rmse logD = 0.534880
Validation R2 logD = 0.817962
Epoch 54
Train function
Loss = 5.9157e-04, PNorm = 55.0336, GNorm = 2.0573, lr_0 = 1.0804e-04
Loss = 6.8975e-04, PNorm = 55.0386, GNorm = 1.6568, lr_0 = 1.0804e-04
Loss = 7.4070e-04, PNorm = 55.0435, GNorm = 2.1712, lr_0 = 1.0804e-04
Loss = 7.0013e-04, PNorm = 55.0472, GNorm = 1.1054, lr_0 = 1.0804e-04
Loss = 8.3675e-04, PNorm = 55.0516, GNorm = 1.7901, lr_0 = 1.0804e-04
Loss = 7.4517e-04, PNorm = 55.0561, GNorm = 4.2800, lr_0 = 1.0804e-04
Validation rmse logD = 0.538635
Validation R2 logD = 0.815397
Epoch 55
Train function
Loss = 7.5305e-04, PNorm = 55.0608, GNorm = 0.8663, lr_0 = 1.0804e-04
Loss = 6.3351e-04, PNorm = 55.0648, GNorm = 3.3829, lr_0 = 1.0804e-04
Loss = 8.8260e-04, PNorm = 55.0677, GNorm = 2.4983, lr_0 = 1.0804e-04
Loss = 6.9366e-04, PNorm = 55.0714, GNorm = 1.2408, lr_0 = 1.0804e-04
Loss = 9.4029e-04, PNorm = 55.0744, GNorm = 3.0980, lr_0 = 1.0804e-04
Loss = 7.8030e-04, PNorm = 55.0783, GNorm = 1.8142, lr_0 = 1.0804e-04
Validation rmse logD = 0.538337
Validation R2 logD = 0.815601
Epoch 56
Train function
Loss = 8.3030e-04, PNorm = 55.0830, GNorm = 5.0452, lr_0 = 1.0804e-04
Loss = 7.9803e-04, PNorm = 55.0872, GNorm = 4.9883, lr_0 = 1.0804e-04
Loss = 6.1864e-04, PNorm = 55.0902, GNorm = 2.4152, lr_0 = 1.0804e-04
Loss = 6.3956e-04, PNorm = 55.0951, GNorm = 2.2410, lr_0 = 1.0804e-04
Loss = 6.5712e-04, PNorm = 55.1000, GNorm = 2.2400, lr_0 = 1.0804e-04
Validation rmse logD = 0.543648
Validation R2 logD = 0.811945
Epoch 57
Train function
Loss = 8.3040e-04, PNorm = 55.1033, GNorm = 3.2243, lr_0 = 1.0804e-04
Loss = 8.1022e-04, PNorm = 55.1085, GNorm = 3.1661, lr_0 = 1.0804e-04
Loss = 7.0239e-04, PNorm = 55.1125, GNorm = 1.7720, lr_0 = 1.0804e-04
Loss = 7.4052e-04, PNorm = 55.1167, GNorm = 1.1565, lr_0 = 1.0804e-04
Loss = 7.2263e-04, PNorm = 55.1218, GNorm = 2.0202, lr_0 = 1.0804e-04
Loss = 7.4246e-04, PNorm = 55.1255, GNorm = 1.5649, lr_0 = 1.0804e-04
Validation rmse logD = 0.541309
Validation R2 logD = 0.813559
Epoch 58
Train function
Loss = 9.1345e-04, PNorm = 55.1295, GNorm = 4.1925, lr_0 = 1.0804e-04
Loss = 1.0504e-03, PNorm = 55.1337, GNorm = 6.4120, lr_0 = 1.0804e-04
Loss = 9.0807e-04, PNorm = 55.1394, GNorm = 3.8433, lr_0 = 1.0804e-04
Loss = 7.0545e-04, PNorm = 55.1450, GNorm = 1.3705, lr_0 = 1.0804e-04
Loss = 7.1877e-04, PNorm = 55.1484, GNorm = 1.1411, lr_0 = 1.0804e-04
Loss = 6.9448e-04, PNorm = 55.1527, GNorm = 1.4845, lr_0 = 1.0804e-04
Validation rmse logD = 0.535284
Validation R2 logD = 0.817686
Epoch 59
Train function
Loss = 5.5295e-04, PNorm = 55.1570, GNorm = 1.2044, lr_0 = 1.0804e-04
Loss = 6.2284e-04, PNorm = 55.1630, GNorm = 1.7900, lr_0 = 1.0804e-04
Loss = 5.5106e-04, PNorm = 55.1670, GNorm = 1.6177, lr_0 = 1.0804e-04
Loss = 5.9671e-04, PNorm = 55.1716, GNorm = 2.7755, lr_0 = 1.0804e-04
Loss = 6.3398e-04, PNorm = 55.1743, GNorm = 3.0335, lr_0 = 1.0804e-04
Validation rmse logD = 0.542049
Validation R2 logD = 0.813049
Epoch 60
Train function
Loss = 6.4186e-04, PNorm = 55.1796, GNorm = 4.6445, lr_0 = 1.0804e-04
Loss = 7.7860e-04, PNorm = 55.1846, GNorm = 5.3188, lr_0 = 1.0804e-04
Loss = 9.5690e-04, PNorm = 55.1879, GNorm = 4.9368, lr_0 = 1.0804e-04
Loss = 9.9625e-04, PNorm = 55.1926, GNorm = 6.7400, lr_0 = 1.0804e-04
Loss = 9.7857e-04, PNorm = 55.1975, GNorm = 3.7772, lr_0 = 1.0804e-04
Loss = 7.0567e-04, PNorm = 55.2027, GNorm = 3.1257, lr_0 = 1.0804e-04
Validation rmse logD = 0.561603
Validation R2 logD = 0.799318
Epoch 61
Train function
Loss = 7.1373e-04, PNorm = 55.2070, GNorm = 3.7636, lr_0 = 1.0804e-04
Loss = 6.0246e-04, PNorm = 55.2109, GNorm = 2.2270, lr_0 = 1.0804e-04
Loss = 6.9585e-04, PNorm = 55.2154, GNorm = 2.4992, lr_0 = 1.0804e-04
Loss = 6.3761e-04, PNorm = 55.2197, GNorm = 5.7571, lr_0 = 1.0804e-04
Loss = 5.6626e-04, PNorm = 55.2235, GNorm = 0.8686, lr_0 = 1.0804e-04
Loss = 6.3604e-04, PNorm = 55.2274, GNorm = 2.3350, lr_0 = 1.0804e-04
Validation rmse logD = 0.526129
Validation R2 logD = 0.823869
Epoch 62
Train function
Loss = 5.2071e-04, PNorm = 55.2308, GNorm = 1.3670, lr_0 = 1.0804e-04
Loss = 6.0984e-04, PNorm = 55.2342, GNorm = 3.7336, lr_0 = 1.0804e-04
Loss = 5.7258e-04, PNorm = 55.2366, GNorm = 1.3424, lr_0 = 1.0804e-04
Loss = 6.1289e-04, PNorm = 55.2402, GNorm = 2.1696, lr_0 = 1.0804e-04
Loss = 6.2358e-04, PNorm = 55.2434, GNorm = 3.6815, lr_0 = 1.0804e-04
Validation rmse logD = 0.543290
Validation R2 logD = 0.812192
Epoch 63
Train function
Loss = 6.2912e-04, PNorm = 55.2485, GNorm = 2.2541, lr_0 = 1.0804e-04
Loss = 4.2837e-04, PNorm = 55.2519, GNorm = 2.4177, lr_0 = 1.0804e-04
Loss = 5.7524e-04, PNorm = 55.2573, GNorm = 1.2580, lr_0 = 1.0804e-04
Loss = 5.6457e-04, PNorm = 55.2603, GNorm = 1.7463, lr_0 = 1.0804e-04
Loss = 6.4364e-04, PNorm = 55.2644, GNorm = 1.4355, lr_0 = 1.0804e-04
Loss = 8.1844e-04, PNorm = 55.2677, GNorm = 1.4069, lr_0 = 1.0804e-04
Validation rmse logD = 0.583401
Validation R2 logD = 0.783436
Epoch 64
Train function
Loss = 9.2965e-04, PNorm = 55.2714, GNorm = 5.5410, lr_0 = 1.0804e-04
Loss = 8.3563e-04, PNorm = 55.2757, GNorm = 5.0022, lr_0 = 1.0804e-04
Loss = 8.2855e-04, PNorm = 55.2801, GNorm = 5.9023, lr_0 = 1.0804e-04
Loss = 7.8651e-04, PNorm = 55.2851, GNorm = 3.6906, lr_0 = 1.0804e-04
Loss = 9.0971e-04, PNorm = 55.2904, GNorm = 2.7880, lr_0 = 1.0804e-04
Loss = 1.3062e-03, PNorm = 55.2953, GNorm = 2.8258, lr_0 = 1.0804e-04
Validation rmse logD = 0.553269
Validation R2 logD = 0.805229
Epoch 65
Train function
Loss = 7.4017e-04, PNorm = 55.2995, GNorm = 4.0210, lr_0 = 1.0804e-04
Loss = 5.1142e-04, PNorm = 55.3056, GNorm = 2.1229, lr_0 = 1.0804e-04
Loss = 5.0514e-04, PNorm = 55.3110, GNorm = 0.9662, lr_0 = 1.0804e-04
Loss = 5.5886e-04, PNorm = 55.3149, GNorm = 1.9119, lr_0 = 1.0804e-04
Loss = 7.5063e-04, PNorm = 55.3167, GNorm = 2.1168, lr_0 = 1.0804e-04
Validation rmse logD = 0.571260
Validation R2 logD = 0.792357
Epoch 66
Train function
Loss = 8.7896e-04, PNorm = 55.3206, GNorm = 2.4111, lr_0 = 1.0804e-04
Loss = 6.1993e-04, PNorm = 55.3246, GNorm = 1.0759, lr_0 = 1.0804e-04
Loss = 7.4638e-04, PNorm = 55.3286, GNorm = 3.2747, lr_0 = 1.0804e-04
Loss = 7.2536e-04, PNorm = 55.3337, GNorm = 1.8325, lr_0 = 1.0804e-04
Loss = 5.8809e-04, PNorm = 55.3375, GNorm = 1.5523, lr_0 = 1.0804e-04
Loss = 5.9704e-04, PNorm = 55.3407, GNorm = 2.3382, lr_0 = 1.0804e-04
Validation rmse logD = 0.519939
Validation R2 logD = 0.827990
Epoch 67
Train function
Loss = 5.6319e-04, PNorm = 55.3445, GNorm = 6.4135, lr_0 = 1.0804e-04
Loss = 6.1432e-04, PNorm = 55.3472, GNorm = 3.7974, lr_0 = 1.0804e-04
Loss = 5.6578e-04, PNorm = 55.3510, GNorm = 5.8839, lr_0 = 1.0804e-04
Loss = 6.9694e-04, PNorm = 55.3545, GNorm = 3.3648, lr_0 = 1.0804e-04
Loss = 7.8367e-04, PNorm = 55.3580, GNorm = 1.8323, lr_0 = 1.0804e-04
Loss = 6.2857e-04, PNorm = 55.3630, GNorm = 4.3612, lr_0 = 1.0804e-04
Validation rmse logD = 0.533903
Validation R2 logD = 0.818626
Epoch 68
Train function
Loss = 5.9478e-04, PNorm = 55.3672, GNorm = 1.7925, lr_0 = 1.0804e-04
Loss = 4.9224e-04, PNorm = 55.3709, GNorm = 2.5243, lr_0 = 1.0804e-04
Loss = 5.4941e-04, PNorm = 55.3747, GNorm = 3.9238, lr_0 = 1.0804e-04
Loss = 5.3164e-04, PNorm = 55.3769, GNorm = 2.7862, lr_0 = 1.0804e-04
Loss = 5.3768e-04, PNorm = 55.3811, GNorm = 0.9749, lr_0 = 1.0804e-04
Validation rmse logD = 0.531772
Validation R2 logD = 0.820071
Epoch 69
Train function
Loss = 4.8446e-04, PNorm = 55.3847, GNorm = 1.0853, lr_0 = 1.0804e-04
Loss = 5.0670e-04, PNorm = 55.3867, GNorm = 1.4764, lr_0 = 1.0804e-04
Loss = 8.0248e-04, PNorm = 55.3902, GNorm = 0.6378, lr_0 = 1.0804e-04
Loss = 7.7726e-04, PNorm = 55.3942, GNorm = 2.0739, lr_0 = 1.0804e-04
Loss = 7.7726e-04, PNorm = 55.3988, GNorm = 2.0132, lr_0 = 1.0804e-04
Loss = 8.2829e-04, PNorm = 55.4030, GNorm = 6.6262, lr_0 = 1.0804e-04
Validation rmse logD = 0.520002
Validation R2 logD = 0.827948
Epoch 70
Train function
Loss = 9.2387e-04, PNorm = 55.4080, GNorm = 5.0324, lr_0 = 1.0804e-04
Loss = 7.7439e-04, PNorm = 55.4120, GNorm = 6.1282, lr_0 = 1.0804e-04
Loss = 7.2852e-04, PNorm = 55.4163, GNorm = 1.9484, lr_0 = 1.0804e-04
Loss = 6.7276e-04, PNorm = 55.4198, GNorm = 4.5609, lr_0 = 1.0804e-04
Loss = 6.4106e-04, PNorm = 55.4249, GNorm = 3.1780, lr_0 = 1.0804e-04
Loss = 5.5244e-04, PNorm = 55.4291, GNorm = 1.1932, lr_0 = 1.0804e-04
Validation rmse logD = 0.530231
Validation R2 logD = 0.821112
Epoch 71
Train function
Loss = 4.4971e-04, PNorm = 55.4333, GNorm = 1.3498, lr_0 = 1.0804e-04
Loss = 4.6539e-04, PNorm = 55.4367, GNorm = 2.6040, lr_0 = 1.0804e-04
Loss = 4.2742e-04, PNorm = 55.4396, GNorm = 0.8950, lr_0 = 1.0804e-04
Loss = 4.6216e-04, PNorm = 55.4431, GNorm = 2.0704, lr_0 = 1.0804e-04
Loss = 4.9589e-04, PNorm = 55.4471, GNorm = 0.7432, lr_0 = 1.0804e-04
Validation rmse logD = 0.517278
Validation R2 logD = 0.829745
Epoch 72
Train function
Loss = 3.4422e-04, PNorm = 55.4492, GNorm = 0.9151, lr_0 = 1.0804e-04
Loss = 4.7028e-04, PNorm = 55.4522, GNorm = 1.4877, lr_0 = 1.0804e-04
Loss = 3.2030e-04, PNorm = 55.4555, GNorm = 1.5937, lr_0 = 1.0804e-04
Loss = 3.1799e-04, PNorm = 55.4577, GNorm = 1.0809, lr_0 = 1.0804e-04
Loss = 4.5459e-04, PNorm = 55.4594, GNorm = 2.5423, lr_0 = 1.0804e-04
Loss = 6.5513e-04, PNorm = 55.4617, GNorm = 8.2748, lr_0 = 1.0804e-04
Validation rmse logD = 0.523432
Validation R2 logD = 0.825671
Epoch 73
Train function
Loss = 6.4709e-04, PNorm = 55.4647, GNorm = 1.3127, lr_0 = 1.0804e-04
Loss = 5.7618e-04, PNorm = 55.4687, GNorm = 1.0212, lr_0 = 1.0804e-04
Loss = 4.5284e-04, PNorm = 55.4721, GNorm = 0.9642, lr_0 = 1.0804e-04
Loss = 3.8322e-04, PNorm = 55.4758, GNorm = 1.1120, lr_0 = 1.0804e-04
Loss = 4.6096e-04, PNorm = 55.4795, GNorm = 1.2149, lr_0 = 1.0804e-04
Loss = 4.2608e-04, PNorm = 55.4833, GNorm = 1.4172, lr_0 = 1.0804e-04
Validation rmse logD = 0.520182
Validation R2 logD = 0.827829
Epoch 74
Train function
Loss = 3.5485e-04, PNorm = 55.4866, GNorm = 3.1703, lr_0 = 1.0804e-04
Loss = 3.3762e-04, PNorm = 55.4894, GNorm = 3.1161, lr_0 = 1.0804e-04
Loss = 5.1619e-04, PNorm = 55.4924, GNorm = 1.7352, lr_0 = 1.0804e-04
Loss = 4.9339e-04, PNorm = 55.4949, GNorm = 4.4983, lr_0 = 1.0804e-04
Loss = 6.3748e-04, PNorm = 55.4981, GNorm = 1.2732, lr_0 = 1.0804e-04
Validation rmse logD = 0.517349
Validation R2 logD = 0.829699
Epoch 75
Train function
Loss = 2.8468e-04, PNorm = 55.5027, GNorm = 0.8987, lr_0 = 1.0804e-04
Loss = 4.5523e-04, PNorm = 55.5060, GNorm = 2.7522, lr_0 = 1.0804e-04
Loss = 5.4204e-04, PNorm = 55.5095, GNorm = 0.8419, lr_0 = 1.0804e-04
Loss = 3.0993e-04, PNorm = 55.5136, GNorm = 1.4682, lr_0 = 1.0804e-04
Loss = 3.8215e-04, PNorm = 55.5166, GNorm = 1.2977, lr_0 = 1.0804e-04
Loss = 4.0502e-04, PNorm = 55.5192, GNorm = 1.3192, lr_0 = 1.0804e-04
Validation rmse logD = 0.520001
Validation R2 logD = 0.827948
Epoch 76
Train function
Loss = 3.6282e-04, PNorm = 55.5234, GNorm = 1.8406, lr_0 = 1.0804e-04
Loss = 3.6021e-04, PNorm = 55.5268, GNorm = 3.8791, lr_0 = 1.0804e-04
Loss = 5.1781e-04, PNorm = 55.5302, GNorm = 2.0473, lr_0 = 1.0804e-04
Loss = 4.7816e-04, PNorm = 55.5334, GNorm = 1.3722, lr_0 = 1.0804e-04
Loss = 4.1441e-04, PNorm = 55.5361, GNorm = 2.3285, lr_0 = 1.0804e-04
Loss = 3.4971e-04, PNorm = 55.5390, GNorm = 1.2023, lr_0 = 1.0804e-04
Validation rmse logD = 0.507406
Validation R2 logD = 0.836182
Epoch 77
Train function
Loss = 3.5093e-04, PNorm = 55.5422, GNorm = 2.6425, lr_0 = 1.0804e-04
Loss = 3.1331e-04, PNorm = 55.5456, GNorm = 0.8393, lr_0 = 1.0804e-04
Loss = 3.7928e-04, PNorm = 55.5484, GNorm = 1.9454, lr_0 = 1.0804e-04
Loss = 3.6125e-04, PNorm = 55.5504, GNorm = 0.9815, lr_0 = 1.0804e-04
Loss = 5.0690e-04, PNorm = 55.5528, GNorm = 2.4553, lr_0 = 1.0804e-04
Validation rmse logD = 0.531589
Validation R2 logD = 0.820195
Epoch 78
Train function
Loss = 3.3652e-04, PNorm = 55.5560, GNorm = 1.4716, lr_0 = 1.0804e-04
Loss = 3.3736e-04, PNorm = 55.5582, GNorm = 0.8155, lr_0 = 1.0804e-04
Loss = 3.5747e-04, PNorm = 55.5618, GNorm = 1.8410, lr_0 = 1.0804e-04
Loss = 4.0325e-04, PNorm = 55.5662, GNorm = 1.8414, lr_0 = 1.0804e-04
Loss = 4.5265e-04, PNorm = 55.5683, GNorm = 0.7758, lr_0 = 1.0804e-04
Loss = 6.6359e-04, PNorm = 55.5703, GNorm = 5.8707, lr_0 = 1.0804e-04
Validation rmse logD = 0.561743
Validation R2 logD = 0.799218
Epoch 79
Train function
Loss = 5.6846e-04, PNorm = 55.5745, GNorm = 1.0584, lr_0 = 1.0804e-04
Loss = 3.5083e-04, PNorm = 55.5778, GNorm = 2.1153, lr_0 = 1.0804e-04
Loss = 3.8286e-04, PNorm = 55.5807, GNorm = 4.1619, lr_0 = 1.0804e-04
Loss = 4.3736e-04, PNorm = 55.5844, GNorm = 2.3717, lr_0 = 1.0804e-04
Loss = 3.7635e-04, PNorm = 55.5873, GNorm = 0.8488, lr_0 = 1.0804e-04
Loss = 3.8175e-04, PNorm = 55.5906, GNorm = 1.0408, lr_0 = 1.0804e-04
Validation rmse logD = 0.511200
Validation R2 logD = 0.833723
Epoch 80
Train function
Loss = 2.9540e-04, PNorm = 55.5937, GNorm = 0.8267, lr_0 = 1.0804e-04
Loss = 3.2493e-04, PNorm = 55.5966, GNorm = 1.5768, lr_0 = 1.0804e-04
Loss = 3.5743e-04, PNorm = 55.5999, GNorm = 1.0594, lr_0 = 1.0804e-04
Loss = 3.2433e-04, PNorm = 55.6025, GNorm = 3.2412, lr_0 = 1.0804e-04
Loss = 3.9415e-04, PNorm = 55.6045, GNorm = 2.2704, lr_0 = 1.0804e-04
Validation rmse logD = 0.530704
Validation R2 logD = 0.820793
Epoch 81
Train function
Loss = 3.4600e-04, PNorm = 55.6071, GNorm = 3.5982, lr_0 = 1.0804e-04
Loss = 4.1024e-04, PNorm = 55.6089, GNorm = 1.5020, lr_0 = 1.0804e-04
Loss = 3.8277e-04, PNorm = 55.6117, GNorm = 2.8690, lr_0 = 1.0804e-04
Loss = 3.9070e-04, PNorm = 55.6156, GNorm = 1.8665, lr_0 = 1.0804e-04
Loss = 3.1963e-04, PNorm = 55.6187, GNorm = 2.4665, lr_0 = 1.0804e-04
Loss = 3.4277e-04, PNorm = 55.6212, GNorm = 2.3080, lr_0 = 1.0804e-04
Validation rmse logD = 0.538510
Validation R2 logD = 0.815482
Epoch 82
Train function
Loss = 6.0070e-04, PNorm = 55.6267, GNorm = 2.5834, lr_0 = 1.0804e-04
Loss = 4.4015e-04, PNorm = 55.6298, GNorm = 0.5790, lr_0 = 1.0804e-04
Loss = 3.2312e-04, PNorm = 55.6331, GNorm = 1.0829, lr_0 = 1.0804e-04
Loss = 2.4578e-04, PNorm = 55.6359, GNorm = 0.9572, lr_0 = 1.0804e-04
Loss = 3.4568e-04, PNorm = 55.6390, GNorm = 1.9986, lr_0 = 1.0804e-04
Loss = 2.8677e-04, PNorm = 55.6418, GNorm = 1.5525, lr_0 = 1.0804e-04
Validation rmse logD = 0.519950
Validation R2 logD = 0.827982
Epoch 83
Train function
Loss = 2.7030e-04, PNorm = 55.6441, GNorm = 0.5185, lr_0 = 1.0804e-04
Loss = 3.1957e-04, PNorm = 55.6465, GNorm = 3.8619, lr_0 = 1.0804e-04
Loss = 3.1706e-04, PNorm = 55.6486, GNorm = 0.9203, lr_0 = 1.0804e-04
Loss = 3.1048e-04, PNorm = 55.6512, GNorm = 1.7682, lr_0 = 1.0804e-04
Loss = 3.6329e-04, PNorm = 55.6539, GNorm = 0.8332, lr_0 = 1.0804e-04
Validation rmse logD = 0.519226
Validation R2 logD = 0.828461
Epoch 84
Train function
Loss = 3.5316e-04, PNorm = 55.6571, GNorm = 1.4532, lr_0 = 1.0804e-04
Loss = 4.6446e-04, PNorm = 55.6602, GNorm = 3.3673, lr_0 = 1.0804e-04
Loss = 6.1034e-04, PNorm = 55.6637, GNorm = 3.8057, lr_0 = 1.0804e-04
Loss = 3.6631e-04, PNorm = 55.6676, GNorm = 1.0122, lr_0 = 1.0804e-04
Loss = 2.9086e-04, PNorm = 55.6712, GNorm = 2.0788, lr_0 = 1.0804e-04
Loss = 3.7691e-04, PNorm = 55.6752, GNorm = 0.7766, lr_0 = 1.0804e-04
Validation rmse logD = 0.520247
Validation R2 logD = 0.827786
Epoch 85
Train function
Loss = 3.2446e-04, PNorm = 55.6767, GNorm = 2.0872, lr_0 = 1.0804e-04
Loss = 3.0123e-04, PNorm = 55.6800, GNorm = 1.5534, lr_0 = 1.0804e-04
Loss = 2.8801e-04, PNorm = 55.6836, GNorm = 1.0143, lr_0 = 1.0804e-04
Loss = 3.1490e-04, PNorm = 55.6854, GNorm = 1.5296, lr_0 = 1.0804e-04
Loss = 4.1100e-04, PNorm = 55.6885, GNorm = 4.6325, lr_0 = 1.0804e-04
Loss = 4.2417e-04, PNorm = 55.6918, GNorm = 0.6376, lr_0 = 1.0804e-04
Validation rmse logD = 0.518341
Validation R2 logD = 0.829045
Epoch 86
Train function
Loss = 3.1416e-04, PNorm = 55.6955, GNorm = 2.7208, lr_0 = 1.0804e-04
Loss = 3.3130e-04, PNorm = 55.6989, GNorm = 2.3042, lr_0 = 1.0804e-04
Loss = 3.4362e-04, PNorm = 55.7022, GNorm = 0.7809, lr_0 = 1.0804e-04
Loss = 2.7842e-04, PNorm = 55.7051, GNorm = 0.7688, lr_0 = 1.0804e-04
Loss = 3.2300e-04, PNorm = 55.7076, GNorm = 1.2064, lr_0 = 1.0804e-04
Validation rmse logD = 0.515104
Validation R2 logD = 0.831174
Epoch 87
Train function
Loss = 2.2947e-04, PNorm = 55.7101, GNorm = 1.8905, lr_0 = 1.0804e-04
Loss = 3.4064e-04, PNorm = 55.7118, GNorm = 0.9221, lr_0 = 1.0804e-04
Loss = 3.9493e-04, PNorm = 55.7143, GNorm = 2.8975, lr_0 = 1.0804e-04
Loss = 3.1320e-04, PNorm = 55.7182, GNorm = 0.8253, lr_0 = 1.0804e-04
Loss = 3.3237e-04, PNorm = 55.7212, GNorm = 2.9234, lr_0 = 1.0804e-04
Loss = 3.2968e-04, PNorm = 55.7232, GNorm = 0.8104, lr_0 = 1.0804e-04
Validation rmse logD = 0.518921
Validation R2 logD = 0.828662
Epoch 88
Train function
Loss = 5.9938e-04, PNorm = 55.7258, GNorm = 7.0444, lr_0 = 1.0804e-04
Loss = 5.0183e-04, PNorm = 55.7283, GNorm = 1.3850, lr_0 = 1.0804e-04
Loss = 3.4711e-04, PNorm = 55.7330, GNorm = 1.7267, lr_0 = 1.0804e-04
Loss = 2.6654e-04, PNorm = 55.7361, GNorm = 1.8604, lr_0 = 1.0804e-04
Loss = 3.1129e-04, PNorm = 55.7385, GNorm = 0.7214, lr_0 = 1.0804e-04
Loss = 3.4781e-04, PNorm = 55.7399, GNorm = 2.9256, lr_0 = 1.0804e-04
Loss = 6.0474e-04, PNorm = 55.7401, GNorm = 0.9246, lr_0 = 1.0804e-04
Validation rmse logD = 0.514940
Validation R2 logD = 0.831281
Epoch 89
Train function
Loss = 2.4902e-04, PNorm = 55.7432, GNorm = 1.4728, lr_0 = 1.0804e-04
Loss = 2.8316e-04, PNorm = 55.7458, GNorm = 1.6764, lr_0 = 1.0804e-04
Loss = 4.8607e-04, PNorm = 55.7478, GNorm = 4.8292, lr_0 = 1.0804e-04
Loss = 4.9591e-04, PNorm = 55.7500, GNorm = 3.2871, lr_0 = 1.0804e-04
Loss = 7.3790e-04, PNorm = 55.7542, GNorm = 7.1337, lr_0 = 1.0804e-04
Validation rmse logD = 0.523446
Validation R2 logD = 0.825661
Epoch 90
Train function
Loss = 8.7461e-04, PNorm = 55.7560, GNorm = 5.2629, lr_0 = 1.0804e-04
Loss = 6.9352e-04, PNorm = 55.7610, GNorm = 4.1073, lr_0 = 1.0804e-04
Loss = 5.2392e-04, PNorm = 55.7663, GNorm = 3.3248, lr_0 = 1.0804e-04
Loss = 3.9101e-04, PNorm = 55.7720, GNorm = 1.2675, lr_0 = 1.0804e-04
Loss = 3.7726e-04, PNorm = 55.7752, GNorm = 0.9281, lr_0 = 1.0804e-04
Loss = 3.6024e-04, PNorm = 55.7783, GNorm = 1.9390, lr_0 = 1.0804e-04
Validation rmse logD = 0.522497
Validation R2 logD = 0.826293
Epoch 91
Train function
Loss = 2.4335e-04, PNorm = 55.7818, GNorm = 0.7860, lr_0 = 1.0804e-04
Loss = 4.1897e-04, PNorm = 55.7847, GNorm = 3.4069, lr_0 = 1.0804e-04
Loss = 3.9990e-04, PNorm = 55.7877, GNorm = 3.5797, lr_0 = 1.0804e-04
Loss = 4.1853e-04, PNorm = 55.7914, GNorm = 1.6143, lr_0 = 1.0804e-04
Loss = 4.6353e-04, PNorm = 55.7944, GNorm = 3.9856, lr_0 = 1.0804e-04
Loss = 4.4615e-04, PNorm = 55.7979, GNorm = 3.6189, lr_0 = 1.0804e-04
Loss = 7.0806e-04, PNorm = 55.7984, GNorm = 3.0324, lr_0 = 1.0804e-04
Validation rmse logD = 0.527847
Validation R2 logD = 0.822718
Epoch 92
Train function
Loss = 5.2387e-04, PNorm = 55.8008, GNorm = 1.1529, lr_0 = 1.0804e-04
Loss = 4.8300e-04, PNorm = 55.8039, GNorm = 1.7049, lr_0 = 1.0804e-04
Loss = 3.1673e-04, PNorm = 55.8076, GNorm = 0.6208, lr_0 = 1.0804e-04
Loss = 4.4511e-04, PNorm = 55.8108, GNorm = 3.1081, lr_0 = 1.0804e-04
Loss = 4.4705e-04, PNorm = 55.8134, GNorm = 3.9558, lr_0 = 1.0804e-04
Validation rmse logD = 0.517285
Validation R2 logD = 0.829741
Epoch 93
Train function
Loss = 3.0745e-04, PNorm = 55.8163, GNorm = 1.7735, lr_0 = 1.0804e-04
Loss = 3.8216e-04, PNorm = 55.8194, GNorm = 0.8500, lr_0 = 1.0804e-04
Loss = 2.9632e-04, PNorm = 55.8220, GNorm = 0.7043, lr_0 = 1.0804e-04
Loss = 4.0421e-04, PNorm = 55.8235, GNorm = 1.8783, lr_0 = 1.0804e-04
Loss = 4.7786e-04, PNorm = 55.8267, GNorm = 4.2920, lr_0 = 1.0804e-04
Loss = 3.5101e-04, PNorm = 55.8302, GNorm = 2.1978, lr_0 = 1.0804e-04
Validation rmse logD = 0.518370
Validation R2 logD = 0.829026
Epoch 94
Train function
Loss = 3.5308e-04, PNorm = 55.8332, GNorm = 1.7483, lr_0 = 1.0804e-04
Loss = 2.6108e-04, PNorm = 55.8373, GNorm = 0.9218, lr_0 = 1.0804e-04
Loss = 2.7013e-04, PNorm = 55.8401, GNorm = 1.2080, lr_0 = 1.0804e-04
Loss = 2.5421e-04, PNorm = 55.8423, GNorm = 2.1871, lr_0 = 1.0804e-04
Loss = 2.3423e-04, PNorm = 55.8443, GNorm = 0.6310, lr_0 = 1.0804e-04
Loss = 2.3648e-04, PNorm = 55.8469, GNorm = 1.2378, lr_0 = 1.0804e-04
Loss = 4.0176e-04, PNorm = 55.8470, GNorm = 2.4865, lr_0 = 1.0804e-04
Validation rmse logD = 0.510850
Validation R2 logD = 0.833950
Epoch 95
Train function
Loss = 2.3164e-04, PNorm = 55.8480, GNorm = 1.3491, lr_0 = 1.0804e-04
Loss = 2.3384e-04, PNorm = 55.8495, GNorm = 1.0980, lr_0 = 1.0804e-04
Loss = 2.1329e-04, PNorm = 55.8525, GNorm = 0.5590, lr_0 = 1.0804e-04
Loss = 2.4267e-04, PNorm = 55.8545, GNorm = 1.1196, lr_0 = 1.0804e-04
Loss = 2.2641e-04, PNorm = 55.8574, GNorm = 0.6591, lr_0 = 1.0804e-04
Validation rmse logD = 0.512538
Validation R2 logD = 0.832851
Epoch 96
Train function
Loss = 1.6913e-04, PNorm = 55.8593, GNorm = 0.6793, lr_0 = 1.0804e-04
Loss = 1.8644e-04, PNorm = 55.8616, GNorm = 2.0823, lr_0 = 1.0804e-04
Loss = 1.9634e-04, PNorm = 55.8625, GNorm = 1.0696, lr_0 = 1.0804e-04
Loss = 2.1746e-04, PNorm = 55.8639, GNorm = 0.9042, lr_0 = 1.0804e-04
Loss = 2.5203e-04, PNorm = 55.8659, GNorm = 2.5328, lr_0 = 1.0804e-04
Loss = 2.5692e-04, PNorm = 55.8681, GNorm = 1.4217, lr_0 = 1.0804e-04
Validation rmse logD = 0.515902
Validation R2 logD = 0.830650
Epoch 97
Train function
Loss = 1.9288e-04, PNorm = 55.8689, GNorm = 0.4895, lr_0 = 1.0804e-04
Loss = 2.1699e-04, PNorm = 55.8715, GNorm = 3.1949, lr_0 = 1.0804e-04
Loss = 2.0069e-04, PNorm = 55.8742, GNorm = 0.7664, lr_0 = 1.0804e-04
Loss = 2.3119e-04, PNorm = 55.8776, GNorm = 3.5044, lr_0 = 1.0804e-04
Loss = 3.1795e-04, PNorm = 55.8797, GNorm = 2.9700, lr_0 = 1.0804e-04
Loss = 3.0723e-04, PNorm = 55.8818, GNorm = 1.3902, lr_0 = 1.0804e-04
Loss = 3.7509e-04, PNorm = 55.8821, GNorm = 0.9495, lr_0 = 1.0804e-04
Validation rmse logD = 0.511689
Validation R2 logD = 0.833405
Epoch 98
Train function
Loss = 2.8643e-04, PNorm = 55.8841, GNorm = 2.3361, lr_0 = 1.0804e-04
Loss = 2.7559e-04, PNorm = 55.8857, GNorm = 0.6362, lr_0 = 1.0804e-04
Loss = 3.4526e-04, PNorm = 55.8888, GNorm = 3.8225, lr_0 = 1.0804e-04
Loss = 3.8320e-04, PNorm = 55.8917, GNorm = 2.2132, lr_0 = 1.0804e-04
Loss = 3.0422e-04, PNorm = 55.8956, GNorm = 3.6517, lr_0 = 1.0804e-04
Validation rmse logD = 0.519840
Validation R2 logD = 0.828055
Epoch 99
Train function
Loss = 4.6147e-04, PNorm = 55.8964, GNorm = 1.2721, lr_0 = 1.0804e-04
Loss = 4.1527e-04, PNorm = 55.8987, GNorm = 3.2060, lr_0 = 1.0804e-04
Loss = 3.4489e-04, PNorm = 55.9028, GNorm = 2.6546, lr_0 = 1.0804e-04
Loss = 2.6753e-04, PNorm = 55.9062, GNorm = 1.4819, lr_0 = 1.0804e-04
Loss = 2.6199e-04, PNorm = 55.9095, GNorm = 3.7350, lr_0 = 1.0804e-04
Loss = 3.2168e-04, PNorm = 55.9124, GNorm = 1.6874, lr_0 = 1.0804e-04
Validation rmse logD = 0.524947
Validation R2 logD = 0.824660
Model 0 best validation rmse = 0.507406 on epoch 76
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.578928
Model 0 test R2 logD = 0.792505
Ensemble test rmse  logD= 0.578928
Ensemble test R2  logD= 0.792505
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2832,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.3531e-02, PNorm = 52.9125, GNorm = 9.3832, lr_0 = 1.0804e-04
Loss = 1.9336e-02, PNorm = 52.9146, GNorm = 7.5281, lr_0 = 1.0804e-04
Loss = 1.9188e-02, PNorm = 52.9174, GNorm = 2.7782, lr_0 = 1.0804e-04
Loss = 1.6129e-02, PNorm = 52.9201, GNorm = 7.3626, lr_0 = 1.0804e-04
Loss = 1.5184e-02, PNorm = 52.9228, GNorm = 5.7809, lr_0 = 1.0804e-04
Validation rmse logD = 1.033791
Validation R2 logD = 0.275473
Epoch 1
Train function
Loss = 1.2518e-02, PNorm = 52.9267, GNorm = 2.2439, lr_0 = 1.0804e-04
Loss = 1.4781e-02, PNorm = 52.9312, GNorm = 1.7203, lr_0 = 1.0804e-04
Loss = 1.4210e-02, PNorm = 52.9359, GNorm = 2.1848, lr_0 = 1.0804e-04
Loss = 1.3017e-02, PNorm = 52.9408, GNorm = 1.8570, lr_0 = 1.0804e-04
Loss = 1.3044e-02, PNorm = 52.9464, GNorm = 2.2407, lr_0 = 1.0804e-04
Loss = 1.2717e-02, PNorm = 52.9523, GNorm = 8.3287, lr_0 = 1.0804e-04
Validation rmse logD = 0.951274
Validation R2 logD = 0.386520
Epoch 2
Train function
Loss = 1.2323e-02, PNorm = 52.9594, GNorm = 1.5117, lr_0 = 1.0804e-04
Loss = 1.1476e-02, PNorm = 52.9672, GNorm = 6.3409, lr_0 = 1.0804e-04
Loss = 1.1037e-02, PNorm = 52.9745, GNorm = 3.9651, lr_0 = 1.0804e-04
Loss = 1.0968e-02, PNorm = 52.9814, GNorm = 3.2398, lr_0 = 1.0804e-04
Loss = 1.1192e-02, PNorm = 52.9893, GNorm = 2.7242, lr_0 = 1.0804e-04
Validation rmse logD = 0.887990
Validation R2 logD = 0.465430
Epoch 3
Train function
Loss = 9.0634e-03, PNorm = 52.9982, GNorm = 3.4394, lr_0 = 1.0804e-04
Loss = 1.0269e-02, PNorm = 53.0074, GNorm = 3.9442, lr_0 = 1.0804e-04
Loss = 9.5706e-03, PNorm = 53.0146, GNorm = 1.9863, lr_0 = 1.0804e-04
Loss = 1.0153e-02, PNorm = 53.0215, GNorm = 6.8413, lr_0 = 1.0804e-04
Loss = 1.0855e-02, PNorm = 53.0288, GNorm = 10.1031, lr_0 = 1.0804e-04
Loss = 1.0072e-02, PNorm = 53.0368, GNorm = 3.4642, lr_0 = 1.0804e-04
Validation rmse logD = 0.880731
Validation R2 logD = 0.474134
Epoch 4
Train function
Loss = 9.7698e-03, PNorm = 53.0455, GNorm = 2.6637, lr_0 = 1.0804e-04
Loss = 9.1438e-03, PNorm = 53.0546, GNorm = 2.7054, lr_0 = 1.0804e-04
Loss = 1.0379e-02, PNorm = 53.0624, GNorm = 4.6391, lr_0 = 1.0804e-04
Loss = 9.0283e-03, PNorm = 53.0714, GNorm = 3.0073, lr_0 = 1.0804e-04
Loss = 8.5700e-03, PNorm = 53.0816, GNorm = 3.1487, lr_0 = 1.0804e-04
Loss = 8.4043e-03, PNorm = 53.0911, GNorm = 3.0314, lr_0 = 1.0804e-04
Validation rmse logD = 0.829164
Validation R2 logD = 0.533910
Epoch 5
Train function
Loss = 7.5188e-03, PNorm = 53.0991, GNorm = 4.8041, lr_0 = 1.0804e-04
Loss = 8.2282e-03, PNorm = 53.1079, GNorm = 1.8023, lr_0 = 1.0804e-04
Loss = 8.4128e-03, PNorm = 53.1177, GNorm = 3.3370, lr_0 = 1.0804e-04
Loss = 8.9359e-03, PNorm = 53.1265, GNorm = 1.6677, lr_0 = 1.0804e-04
Loss = 8.1715e-03, PNorm = 53.1366, GNorm = 7.5244, lr_0 = 1.0804e-04
Validation rmse logD = 0.817618
Validation R2 logD = 0.546800
Epoch 6
Train function
Loss = 5.1738e-03, PNorm = 53.1484, GNorm = 5.4278, lr_0 = 1.0804e-04
Loss = 8.3898e-03, PNorm = 53.1582, GNorm = 8.0403, lr_0 = 1.0804e-04
Loss = 7.4316e-03, PNorm = 53.1689, GNorm = 2.9076, lr_0 = 1.0804e-04
Loss = 8.6780e-03, PNorm = 53.1801, GNorm = 4.7960, lr_0 = 1.0804e-04
Loss = 7.6853e-03, PNorm = 53.1893, GNorm = 6.0790, lr_0 = 1.0804e-04
Loss = 7.6351e-03, PNorm = 53.1998, GNorm = 2.8001, lr_0 = 1.0804e-04
Validation rmse logD = 0.792414
Validation R2 logD = 0.574310
Epoch 7
Train function
Loss = 5.4487e-03, PNorm = 53.2100, GNorm = 1.2559, lr_0 = 1.0804e-04
Loss = 6.1591e-03, PNorm = 53.2197, GNorm = 3.3666, lr_0 = 1.0804e-04
Loss = 6.7377e-03, PNorm = 53.2317, GNorm = 2.3784, lr_0 = 1.0804e-04
Loss = 6.8932e-03, PNorm = 53.2423, GNorm = 2.6484, lr_0 = 1.0804e-04
Loss = 7.4848e-03, PNorm = 53.2515, GNorm = 4.6159, lr_0 = 1.0804e-04
Loss = 7.2355e-03, PNorm = 53.2601, GNorm = 6.7445, lr_0 = 1.0804e-04
Validation rmse logD = 0.779174
Validation R2 logD = 0.588417
Epoch 8
Train function
Loss = 5.4011e-03, PNorm = 53.2699, GNorm = 2.9646, lr_0 = 1.0804e-04
Loss = 6.7825e-03, PNorm = 53.2799, GNorm = 1.2778, lr_0 = 1.0804e-04
Loss = 5.8532e-03, PNorm = 53.2901, GNorm = 2.1659, lr_0 = 1.0804e-04
Loss = 5.5631e-03, PNorm = 53.3008, GNorm = 3.2875, lr_0 = 1.0804e-04
Loss = 6.7632e-03, PNorm = 53.3085, GNorm = 2.2817, lr_0 = 1.0804e-04
Validation rmse logD = 0.737940
Validation R2 logD = 0.630826
Epoch 9
Train function
Loss = 4.3278e-03, PNorm = 53.3201, GNorm = 2.7287, lr_0 = 1.0804e-04
Loss = 5.9032e-03, PNorm = 53.3314, GNorm = 7.7144, lr_0 = 1.0804e-04
Loss = 6.2660e-03, PNorm = 53.3429, GNorm = 7.1238, lr_0 = 1.0804e-04
Loss = 6.2017e-03, PNorm = 53.3521, GNorm = 6.3693, lr_0 = 1.0804e-04
Loss = 6.2886e-03, PNorm = 53.3609, GNorm = 2.8881, lr_0 = 1.0804e-04
Loss = 6.8003e-03, PNorm = 53.3696, GNorm = 2.9864, lr_0 = 1.0804e-04
Validation rmse logD = 0.714829
Validation R2 logD = 0.653588
Epoch 10
Train function
Loss = 5.9773e-03, PNorm = 53.3787, GNorm = 9.1241, lr_0 = 1.0804e-04
Loss = 6.3059e-03, PNorm = 53.3876, GNorm = 4.0853, lr_0 = 1.0804e-04
Loss = 5.4613e-03, PNorm = 53.3976, GNorm = 6.7661, lr_0 = 1.0804e-04
Loss = 5.1711e-03, PNorm = 53.4081, GNorm = 5.3652, lr_0 = 1.0804e-04
Loss = 4.4507e-03, PNorm = 53.4181, GNorm = 1.6913, lr_0 = 1.0804e-04
Loss = 4.8719e-03, PNorm = 53.4263, GNorm = 3.1130, lr_0 = 1.0804e-04
Validation rmse logD = 0.738739
Validation R2 logD = 0.630026
Epoch 11
Train function
Loss = 5.1444e-03, PNorm = 53.4359, GNorm = 2.6956, lr_0 = 1.0804e-04
Loss = 5.1010e-03, PNorm = 53.4470, GNorm = 9.8748, lr_0 = 1.0804e-04
Loss = 4.4272e-03, PNorm = 53.4537, GNorm = 2.1699, lr_0 = 1.0804e-04
Loss = 4.7618e-03, PNorm = 53.4623, GNorm = 1.6004, lr_0 = 1.0804e-04
Loss = 5.3613e-03, PNorm = 53.4709, GNorm = 5.1817, lr_0 = 1.0804e-04
Validation rmse logD = 0.743963
Validation R2 logD = 0.624775
Epoch 12
Train function
Loss = 1.0042e-02, PNorm = 53.4799, GNorm = 9.7469, lr_0 = 1.0804e-04
Loss = 5.1239e-03, PNorm = 53.4903, GNorm = 12.3457, lr_0 = 1.0804e-04
Loss = 4.9630e-03, PNorm = 53.5000, GNorm = 4.1648, lr_0 = 1.0804e-04
Loss = 4.4585e-03, PNorm = 53.5087, GNorm = 4.4038, lr_0 = 1.0804e-04
Loss = 4.0750e-03, PNorm = 53.5182, GNorm = 3.7540, lr_0 = 1.0804e-04
Loss = 4.7057e-03, PNorm = 53.5261, GNorm = 5.3231, lr_0 = 1.0804e-04
Validation rmse logD = 0.700840
Validation R2 logD = 0.667014
Epoch 13
Train function
Loss = 4.1890e-03, PNorm = 53.5340, GNorm = 2.6712, lr_0 = 1.0804e-04
Loss = 4.4932e-03, PNorm = 53.5432, GNorm = 4.2267, lr_0 = 1.0804e-04
Loss = 4.4915e-03, PNorm = 53.5503, GNorm = 3.5723, lr_0 = 1.0804e-04
Loss = 5.1290e-03, PNorm = 53.5608, GNorm = 3.1712, lr_0 = 1.0804e-04
Loss = 4.3418e-03, PNorm = 53.5700, GNorm = 5.8552, lr_0 = 1.0804e-04
Loss = 3.6436e-03, PNorm = 53.5783, GNorm = 1.9045, lr_0 = 1.0804e-04
Validation rmse logD = 0.666597
Validation R2 logD = 0.698758
Epoch 14
Train function
Loss = 4.2115e-03, PNorm = 53.5856, GNorm = 5.9563, lr_0 = 1.0804e-04
Loss = 4.6691e-03, PNorm = 53.5949, GNorm = 2.4392, lr_0 = 1.0804e-04
Loss = 4.2619e-03, PNorm = 53.6021, GNorm = 4.3134, lr_0 = 1.0804e-04
Loss = 4.2546e-03, PNorm = 53.6108, GNorm = 2.9757, lr_0 = 1.0804e-04
Loss = 4.6556e-03, PNorm = 53.6193, GNorm = 5.6448, lr_0 = 1.0804e-04
Validation rmse logD = 0.712237
Validation R2 logD = 0.656095
Epoch 15
Train function
Loss = 3.3614e-03, PNorm = 53.6278, GNorm = 8.2497, lr_0 = 1.0804e-04
Loss = 4.0419e-03, PNorm = 53.6359, GNorm = 3.6797, lr_0 = 1.0804e-04
Loss = 5.1251e-03, PNorm = 53.6447, GNorm = 7.0192, lr_0 = 1.0804e-04
Loss = 4.4765e-03, PNorm = 53.6517, GNorm = 9.4327, lr_0 = 1.0804e-04
Loss = 3.7197e-03, PNorm = 53.6613, GNorm = 2.4189, lr_0 = 1.0804e-04
Loss = 3.4904e-03, PNorm = 53.6694, GNorm = 5.1169, lr_0 = 1.0804e-04
Validation rmse logD = 0.694917
Validation R2 logD = 0.672618
Epoch 16
Train function
Loss = 3.3176e-03, PNorm = 53.6778, GNorm = 9.9395, lr_0 = 1.0804e-04
Loss = 4.2489e-03, PNorm = 53.6859, GNorm = 1.7055, lr_0 = 1.0804e-04
Loss = 3.8758e-03, PNorm = 53.6961, GNorm = 6.1694, lr_0 = 1.0804e-04
Loss = 3.8036e-03, PNorm = 53.7043, GNorm = 1.8925, lr_0 = 1.0804e-04
Loss = 3.1932e-03, PNorm = 53.7120, GNorm = 3.6979, lr_0 = 1.0804e-04
Loss = 3.4934e-03, PNorm = 53.7183, GNorm = 1.9646, lr_0 = 1.0804e-04
Validation rmse logD = 0.657153
Validation R2 logD = 0.707233
Epoch 17
Train function
Loss = 3.2171e-03, PNorm = 53.7245, GNorm = 7.9873, lr_0 = 1.0804e-04
Loss = 3.5050e-03, PNorm = 53.7322, GNorm = 4.0531, lr_0 = 1.0804e-04
Loss = 3.5030e-03, PNorm = 53.7382, GNorm = 4.4306, lr_0 = 1.0804e-04
Loss = 3.9800e-03, PNorm = 53.7459, GNorm = 2.7844, lr_0 = 1.0804e-04
Loss = 4.2951e-03, PNorm = 53.7561, GNorm = 6.9321, lr_0 = 1.0804e-04
Validation rmse logD = 0.656185
Validation R2 logD = 0.708095
Epoch 18
Train function
Loss = 3.0464e-03, PNorm = 53.7641, GNorm = 3.2004, lr_0 = 1.0804e-04
Loss = 3.2919e-03, PNorm = 53.7731, GNorm = 4.6471, lr_0 = 1.0804e-04
Loss = 3.2595e-03, PNorm = 53.7812, GNorm = 10.7640, lr_0 = 1.0804e-04
Loss = 3.9024e-03, PNorm = 53.7879, GNorm = 2.7057, lr_0 = 1.0804e-04
Loss = 4.4839e-03, PNorm = 53.7959, GNorm = 1.9511, lr_0 = 1.0804e-04
Loss = 5.1060e-03, PNorm = 53.8027, GNorm = 3.1918, lr_0 = 1.0804e-04
Validation rmse logD = 0.648432
Validation R2 logD = 0.714953
Epoch 19
Train function
Loss = 4.0847e-03, PNorm = 53.8103, GNorm = 3.5325, lr_0 = 1.0804e-04
Loss = 3.0050e-03, PNorm = 53.8207, GNorm = 4.0466, lr_0 = 1.0804e-04
Loss = 3.4516e-03, PNorm = 53.8297, GNorm = 4.7746, lr_0 = 1.0804e-04
Loss = 3.4446e-03, PNorm = 53.8362, GNorm = 1.4999, lr_0 = 1.0804e-04
Loss = 3.4501e-03, PNorm = 53.8438, GNorm = 7.3314, lr_0 = 1.0804e-04
Loss = 3.1165e-03, PNorm = 53.8520, GNorm = 6.0428, lr_0 = 1.0804e-04
Validation rmse logD = 0.671870
Validation R2 logD = 0.693973
Epoch 20
Train function
Loss = 3.3074e-03, PNorm = 53.8596, GNorm = 1.4965, lr_0 = 1.0804e-04
Loss = 3.0182e-03, PNorm = 53.8671, GNorm = 4.1295, lr_0 = 1.0804e-04
Loss = 3.1460e-03, PNorm = 53.8745, GNorm = 1.6697, lr_0 = 1.0804e-04
Loss = 2.9056e-03, PNorm = 53.8818, GNorm = 1.5189, lr_0 = 1.0804e-04
Loss = 3.5427e-03, PNorm = 53.8879, GNorm = 8.1721, lr_0 = 1.0804e-04
Validation rmse logD = 0.655990
Validation R2 logD = 0.708268
Epoch 21
Train function
Loss = 2.3575e-03, PNorm = 53.8945, GNorm = 4.0648, lr_0 = 1.0804e-04
Loss = 3.1681e-03, PNorm = 53.9027, GNorm = 5.6225, lr_0 = 1.0804e-04
Loss = 2.7962e-03, PNorm = 53.9093, GNorm = 1.5012, lr_0 = 1.0804e-04
Loss = 2.9044e-03, PNorm = 53.9172, GNorm = 3.1300, lr_0 = 1.0804e-04
Loss = 3.5848e-03, PNorm = 53.9236, GNorm = 3.8968, lr_0 = 1.0804e-04
Loss = 3.1397e-03, PNorm = 53.9324, GNorm = 4.2550, lr_0 = 1.0804e-04
Validation rmse logD = 0.618586
Validation R2 logD = 0.740589
Epoch 22
Train function
Loss = 2.8895e-03, PNorm = 53.9396, GNorm = 1.6213, lr_0 = 1.0804e-04
Loss = 2.9357e-03, PNorm = 53.9481, GNorm = 5.9950, lr_0 = 1.0804e-04
Loss = 2.6226e-03, PNorm = 53.9541, GNorm = 5.4725, lr_0 = 1.0804e-04
Loss = 2.7313e-03, PNorm = 53.9631, GNorm = 3.7326, lr_0 = 1.0804e-04
Loss = 2.2384e-03, PNorm = 53.9692, GNorm = 2.9776, lr_0 = 1.0804e-04
Loss = 3.0212e-03, PNorm = 53.9749, GNorm = 2.6777, lr_0 = 1.0804e-04
Validation rmse logD = 0.622287
Validation R2 logD = 0.737475
Epoch 23
Train function
Loss = 2.4794e-03, PNorm = 53.9813, GNorm = 1.5121, lr_0 = 1.0804e-04
Loss = 2.1227e-03, PNorm = 53.9868, GNorm = 1.6042, lr_0 = 1.0804e-04
Loss = 2.7687e-03, PNorm = 53.9933, GNorm = 6.3855, lr_0 = 1.0804e-04
Loss = 2.6154e-03, PNorm = 54.0014, GNorm = 5.2247, lr_0 = 1.0804e-04
Loss = 2.2989e-03, PNorm = 54.0098, GNorm = 2.2270, lr_0 = 1.0804e-04
Validation rmse logD = 0.627043
Validation R2 logD = 0.733447
Epoch 24
Train function
Loss = 1.9076e-03, PNorm = 54.0182, GNorm = 6.3781, lr_0 = 1.0804e-04
Loss = 2.6651e-03, PNorm = 54.0242, GNorm = 4.2595, lr_0 = 1.0804e-04
Loss = 2.3455e-03, PNorm = 54.0322, GNorm = 1.5796, lr_0 = 1.0804e-04
Loss = 2.4477e-03, PNorm = 54.0399, GNorm = 2.0316, lr_0 = 1.0804e-04
Loss = 2.5416e-03, PNorm = 54.0472, GNorm = 1.4224, lr_0 = 1.0804e-04
Loss = 2.4516e-03, PNorm = 54.0533, GNorm = 4.3299, lr_0 = 1.0804e-04
Validation rmse logD = 0.628360
Validation R2 logD = 0.732326
Epoch 25
Train function
Loss = 2.0629e-03, PNorm = 54.0598, GNorm = 3.9671, lr_0 = 1.0804e-04
Loss = 1.7444e-03, PNorm = 54.0674, GNorm = 2.9078, lr_0 = 1.0804e-04
Loss = 2.8381e-03, PNorm = 54.0752, GNorm = 5.1216, lr_0 = 1.0804e-04
Loss = 2.9031e-03, PNorm = 54.0818, GNorm = 8.4763, lr_0 = 1.0804e-04
Loss = 2.6342e-03, PNorm = 54.0873, GNorm = 1.2938, lr_0 = 1.0804e-04
Loss = 2.6933e-03, PNorm = 54.0954, GNorm = 1.4266, lr_0 = 1.0804e-04
Validation rmse logD = 0.619969
Validation R2 logD = 0.739427
Epoch 26
Train function
Loss = 2.2042e-03, PNorm = 54.1024, GNorm = 2.1554, lr_0 = 1.0804e-04
Loss = 2.5109e-03, PNorm = 54.1088, GNorm = 6.5247, lr_0 = 1.0804e-04
Loss = 3.3273e-03, PNorm = 54.1160, GNorm = 8.0460, lr_0 = 1.0804e-04
Loss = 3.4067e-03, PNorm = 54.1242, GNorm = 6.7751, lr_0 = 1.0804e-04
Loss = 3.3680e-03, PNorm = 54.1318, GNorm = 7.0138, lr_0 = 1.0804e-04
Validation rmse logD = 0.630315
Validation R2 logD = 0.730658
Epoch 27
Train function
Loss = 2.3683e-03, PNorm = 54.1402, GNorm = 2.7868, lr_0 = 1.0804e-04
Loss = 2.2321e-03, PNorm = 54.1494, GNorm = 3.8963, lr_0 = 1.0804e-04
Loss = 2.1485e-03, PNorm = 54.1560, GNorm = 4.1107, lr_0 = 1.0804e-04
Loss = 2.2550e-03, PNorm = 54.1640, GNorm = 5.9033, lr_0 = 1.0804e-04
Loss = 1.9501e-03, PNorm = 54.1717, GNorm = 1.9749, lr_0 = 1.0804e-04
Loss = 2.2079e-03, PNorm = 54.1771, GNorm = 2.4159, lr_0 = 1.0804e-04
Validation rmse logD = 0.631377
Validation R2 logD = 0.729750
Epoch 28
Train function
Loss = 1.9836e-03, PNorm = 54.1830, GNorm = 4.2169, lr_0 = 1.0804e-04
Loss = 1.6854e-03, PNorm = 54.1910, GNorm = 1.9097, lr_0 = 1.0804e-04
Loss = 2.0800e-03, PNorm = 54.1969, GNorm = 3.2252, lr_0 = 1.0804e-04
Loss = 2.6073e-03, PNorm = 54.2019, GNorm = 7.6678, lr_0 = 1.0804e-04
Loss = 2.2789e-03, PNorm = 54.2063, GNorm = 7.2403, lr_0 = 1.0804e-04
Loss = 2.0850e-03, PNorm = 54.2130, GNorm = 1.5030, lr_0 = 1.0804e-04
Validation rmse logD = 0.631739
Validation R2 logD = 0.729440
Epoch 29
Train function
Loss = 1.7306e-03, PNorm = 54.2190, GNorm = 4.1191, lr_0 = 1.0804e-04
Loss = 2.1277e-03, PNorm = 54.2253, GNorm = 2.1371, lr_0 = 1.0804e-04
Loss = 1.9678e-03, PNorm = 54.2317, GNorm = 3.4291, lr_0 = 1.0804e-04
Loss = 1.7364e-03, PNorm = 54.2385, GNorm = 3.2092, lr_0 = 1.0804e-04
Loss = 1.7752e-03, PNorm = 54.2461, GNorm = 2.4167, lr_0 = 1.0804e-04
Validation rmse logD = 0.619584
Validation R2 logD = 0.739751
Epoch 30
Train function
Loss = 1.1807e-03, PNorm = 54.2539, GNorm = 1.8731, lr_0 = 1.0804e-04
Loss = 1.8092e-03, PNorm = 54.2594, GNorm = 1.5080, lr_0 = 1.0804e-04
Loss = 2.0817e-03, PNorm = 54.2660, GNorm = 1.7120, lr_0 = 1.0804e-04
Loss = 1.6771e-03, PNorm = 54.2729, GNorm = 2.6785, lr_0 = 1.0804e-04
Loss = 1.7304e-03, PNorm = 54.2783, GNorm = 2.6505, lr_0 = 1.0804e-04
Loss = 2.0942e-03, PNorm = 54.2843, GNorm = 5.3333, lr_0 = 1.0804e-04
Validation rmse logD = 0.659858
Validation R2 logD = 0.704818
Epoch 31
Train function
Loss = 2.2489e-03, PNorm = 54.2913, GNorm = 5.1996, lr_0 = 1.0804e-04
Loss = 1.5344e-03, PNorm = 54.2974, GNorm = 3.7826, lr_0 = 1.0804e-04
Loss = 1.9421e-03, PNorm = 54.3028, GNorm = 3.3414, lr_0 = 1.0804e-04
Loss = 1.7426e-03, PNorm = 54.3089, GNorm = 7.7093, lr_0 = 1.0804e-04
Loss = 1.9780e-03, PNorm = 54.3135, GNorm = 1.9616, lr_0 = 1.0804e-04
Loss = 1.7849e-03, PNorm = 54.3208, GNorm = 4.1290, lr_0 = 1.0804e-04
Validation rmse logD = 0.601103
Validation R2 logD = 0.755044
Epoch 32
Train function
Loss = 1.8555e-03, PNorm = 54.3290, GNorm = 1.3778, lr_0 = 1.0804e-04
Loss = 1.6586e-03, PNorm = 54.3348, GNorm = 4.1822, lr_0 = 1.0804e-04
Loss = 1.5044e-03, PNorm = 54.3405, GNorm = 2.9354, lr_0 = 1.0804e-04
Loss = 1.5482e-03, PNorm = 54.3454, GNorm = 3.7139, lr_0 = 1.0804e-04
Loss = 1.8546e-03, PNorm = 54.3505, GNorm = 1.7347, lr_0 = 1.0804e-04
Validation rmse logD = 0.598076
Validation R2 logD = 0.757506
Epoch 33
Train function
Loss = 1.9161e-03, PNorm = 54.3572, GNorm = 4.6314, lr_0 = 1.0804e-04
Loss = 1.6018e-03, PNorm = 54.3641, GNorm = 1.4433, lr_0 = 1.0804e-04
Loss = 1.3973e-03, PNorm = 54.3713, GNorm = 3.1249, lr_0 = 1.0804e-04
Loss = 1.7841e-03, PNorm = 54.3783, GNorm = 3.6842, lr_0 = 1.0804e-04
Loss = 1.4940e-03, PNorm = 54.3854, GNorm = 1.7035, lr_0 = 1.0804e-04
Loss = 2.0068e-03, PNorm = 54.3913, GNorm = 2.4109, lr_0 = 1.0804e-04
Validation rmse logD = 0.604979
Validation R2 logD = 0.751876
Epoch 34
Train function
Loss = 2.0640e-03, PNorm = 54.3972, GNorm = 2.7972, lr_0 = 1.0804e-04
Loss = 1.4313e-03, PNorm = 54.4029, GNorm = 1.5362, lr_0 = 1.0804e-04
Loss = 1.5079e-03, PNorm = 54.4088, GNorm = 2.3256, lr_0 = 1.0804e-04
Loss = 1.3632e-03, PNorm = 54.4157, GNorm = 3.2967, lr_0 = 1.0804e-04
Loss = 1.4876e-03, PNorm = 54.4209, GNorm = 2.7267, lr_0 = 1.0804e-04
Loss = 1.4745e-03, PNorm = 54.4265, GNorm = 3.5369, lr_0 = 1.0804e-04
Validation rmse logD = 0.598187
Validation R2 logD = 0.757416
Epoch 35
Train function
Loss = 1.6030e-03, PNorm = 54.4318, GNorm = 2.8291, lr_0 = 1.0804e-04
Loss = 1.3126e-03, PNorm = 54.4393, GNorm = 3.7507, lr_0 = 1.0804e-04
Loss = 1.6587e-03, PNorm = 54.4447, GNorm = 5.5268, lr_0 = 1.0804e-04
Loss = 1.7128e-03, PNorm = 54.4506, GNorm = 3.0038, lr_0 = 1.0804e-04
Loss = 1.5483e-03, PNorm = 54.4547, GNorm = 5.5202, lr_0 = 1.0804e-04
Validation rmse logD = 0.647744
Validation R2 logD = 0.715557
Epoch 36
Train function
Loss = 2.0903e-03, PNorm = 54.4620, GNorm = 7.5059, lr_0 = 1.0804e-04
Loss = 1.2372e-03, PNorm = 54.4688, GNorm = 1.6402, lr_0 = 1.0804e-04
Loss = 1.3137e-03, PNorm = 54.4761, GNorm = 2.2782, lr_0 = 1.0804e-04
Loss = 1.4484e-03, PNorm = 54.4799, GNorm = 1.6048, lr_0 = 1.0804e-04
Loss = 1.2145e-03, PNorm = 54.4848, GNorm = 3.6968, lr_0 = 1.0804e-04
Loss = 1.7264e-03, PNorm = 54.4911, GNorm = 1.8895, lr_0 = 1.0804e-04
Validation rmse logD = 0.594847
Validation R2 logD = 0.760117
Epoch 37
Train function
Loss = 1.2679e-03, PNorm = 54.4974, GNorm = 4.4559, lr_0 = 1.0804e-04
Loss = 1.5651e-03, PNorm = 54.5041, GNorm = 5.8306, lr_0 = 1.0804e-04
Loss = 1.4117e-03, PNorm = 54.5091, GNorm = 2.2766, lr_0 = 1.0804e-04
Loss = 1.5989e-03, PNorm = 54.5144, GNorm = 7.0187, lr_0 = 1.0804e-04
Loss = 1.4459e-03, PNorm = 54.5195, GNorm = 1.7287, lr_0 = 1.0804e-04
Loss = 1.3011e-03, PNorm = 54.5246, GNorm = 2.3110, lr_0 = 1.0804e-04
Validation rmse logD = 0.594228
Validation R2 logD = 0.760616
Epoch 38
Train function
Loss = 1.0464e-03, PNorm = 54.5299, GNorm = 2.2288, lr_0 = 1.0804e-04
Loss = 1.1930e-03, PNorm = 54.5374, GNorm = 2.3646, lr_0 = 1.0804e-04
Loss = 1.2864e-03, PNorm = 54.5423, GNorm = 6.2965, lr_0 = 1.0804e-04
Loss = 1.4894e-03, PNorm = 54.5479, GNorm = 1.5041, lr_0 = 1.0804e-04
Loss = 1.4883e-03, PNorm = 54.5540, GNorm = 1.7067, lr_0 = 1.0804e-04
Validation rmse logD = 0.638851
Validation R2 logD = 0.723313
Epoch 39
Train function
Loss = 3.1097e-03, PNorm = 54.5603, GNorm = 8.5808, lr_0 = 1.0804e-04
Loss = 1.3493e-03, PNorm = 54.5655, GNorm = 2.6464, lr_0 = 1.0804e-04
Loss = 1.2506e-03, PNorm = 54.5709, GNorm = 3.1886, lr_0 = 1.0804e-04
Loss = 1.3545e-03, PNorm = 54.5771, GNorm = 5.0526, lr_0 = 1.0804e-04
Loss = 1.2216e-03, PNorm = 54.5826, GNorm = 4.2764, lr_0 = 1.0804e-04
Loss = 1.2399e-03, PNorm = 54.5877, GNorm = 1.9025, lr_0 = 1.0804e-04
Validation rmse logD = 0.605626
Validation R2 logD = 0.751344
Epoch 40
Train function
Loss = 1.2160e-03, PNorm = 54.5933, GNorm = 1.7281, lr_0 = 1.0804e-04
Loss = 1.3752e-03, PNorm = 54.5988, GNorm = 2.2036, lr_0 = 1.0804e-04
Loss = 1.2744e-03, PNorm = 54.6055, GNorm = 3.8904, lr_0 = 1.0804e-04
Loss = 1.2049e-03, PNorm = 54.6112, GNorm = 6.7204, lr_0 = 1.0804e-04
Loss = 1.0170e-03, PNorm = 54.6143, GNorm = 2.2673, lr_0 = 1.0804e-04
Loss = 1.3118e-03, PNorm = 54.6194, GNorm = 5.3417, lr_0 = 1.0804e-04
Validation rmse logD = 0.594315
Validation R2 logD = 0.760546
Epoch 41
Train function
Loss = 1.2175e-03, PNorm = 54.6269, GNorm = 4.3934, lr_0 = 1.0804e-04
Loss = 8.6305e-04, PNorm = 54.6321, GNorm = 2.6656, lr_0 = 1.0804e-04
Loss = 9.8237e-04, PNorm = 54.6361, GNorm = 3.7596, lr_0 = 1.0804e-04
Loss = 1.0258e-03, PNorm = 54.6415, GNorm = 1.0512, lr_0 = 1.0804e-04
Loss = 1.5902e-03, PNorm = 54.6458, GNorm = 6.2429, lr_0 = 1.0804e-04
Validation rmse logD = 0.591071
Validation R2 logD = 0.763152
Epoch 42
Train function
Loss = 1.2916e-03, PNorm = 54.6505, GNorm = 1.7311, lr_0 = 1.0804e-04
Loss = 1.4020e-03, PNorm = 54.6569, GNorm = 1.3703, lr_0 = 1.0804e-04
Loss = 9.4429e-04, PNorm = 54.6622, GNorm = 1.3145, lr_0 = 1.0804e-04
Loss = 1.0426e-03, PNorm = 54.6681, GNorm = 2.1607, lr_0 = 1.0804e-04
Loss = 1.3592e-03, PNorm = 54.6733, GNorm = 4.4647, lr_0 = 1.0804e-04
Loss = 1.1995e-03, PNorm = 54.6775, GNorm = 1.0537, lr_0 = 1.0804e-04
Validation rmse logD = 0.585864
Validation R2 logD = 0.767308
Epoch 43
Train function
Loss = 1.1270e-03, PNorm = 54.6829, GNorm = 1.8963, lr_0 = 1.0804e-04
Loss = 8.4675e-04, PNorm = 54.6889, GNorm = 1.2138, lr_0 = 1.0804e-04
Loss = 1.0744e-03, PNorm = 54.6951, GNorm = 1.5341, lr_0 = 1.0804e-04
Loss = 1.3681e-03, PNorm = 54.7005, GNorm = 4.3555, lr_0 = 1.0804e-04
Loss = 1.8831e-03, PNorm = 54.7033, GNorm = 11.5137, lr_0 = 1.0804e-04
Loss = 1.6696e-03, PNorm = 54.7089, GNorm = 1.7936, lr_0 = 1.0804e-04
Validation rmse logD = 0.659970
Validation R2 logD = 0.704718
Epoch 44
Train function
Loss = 1.6180e-03, PNorm = 54.7155, GNorm = 6.0387, lr_0 = 1.0804e-04
Loss = 1.0730e-03, PNorm = 54.7218, GNorm = 1.3774, lr_0 = 1.0804e-04
Loss = 1.2022e-03, PNorm = 54.7268, GNorm = 2.9794, lr_0 = 1.0804e-04
Loss = 1.0778e-03, PNorm = 54.7311, GNorm = 3.3596, lr_0 = 1.0804e-04
Loss = 1.2955e-03, PNorm = 54.7365, GNorm = 1.5428, lr_0 = 1.0804e-04
Validation rmse logD = 0.595925
Validation R2 logD = 0.759247
Epoch 45
Train function
Loss = 9.7901e-04, PNorm = 54.7429, GNorm = 1.5584, lr_0 = 1.0804e-04
Loss = 9.4676e-04, PNorm = 54.7484, GNorm = 3.1021, lr_0 = 1.0804e-04
Loss = 1.0250e-03, PNorm = 54.7533, GNorm = 6.7852, lr_0 = 1.0804e-04
Loss = 9.7890e-04, PNorm = 54.7580, GNorm = 3.8964, lr_0 = 1.0804e-04
Loss = 9.9918e-04, PNorm = 54.7624, GNorm = 1.2954, lr_0 = 1.0804e-04
Loss = 1.1385e-03, PNorm = 54.7673, GNorm = 1.3388, lr_0 = 1.0804e-04
Validation rmse logD = 0.584007
Validation R2 logD = 0.768781
Epoch 46
Train function
Loss = 8.4174e-04, PNorm = 54.7723, GNorm = 1.3353, lr_0 = 1.0804e-04
Loss = 8.3952e-04, PNorm = 54.7772, GNorm = 1.3347, lr_0 = 1.0804e-04
Loss = 8.1404e-04, PNorm = 54.7824, GNorm = 2.9481, lr_0 = 1.0804e-04
Loss = 1.0353e-03, PNorm = 54.7859, GNorm = 1.1443, lr_0 = 1.0804e-04
Loss = 9.9748e-04, PNorm = 54.7905, GNorm = 1.5059, lr_0 = 1.0804e-04
Loss = 9.3334e-04, PNorm = 54.7959, GNorm = 2.3802, lr_0 = 1.0804e-04
Validation rmse logD = 0.588258
Validation R2 logD = 0.765402
Epoch 47
Train function
Loss = 7.4509e-04, PNorm = 54.8013, GNorm = 3.3266, lr_0 = 1.0804e-04
Loss = 7.1399e-04, PNorm = 54.8064, GNorm = 1.2759, lr_0 = 1.0804e-04
Loss = 8.3299e-04, PNorm = 54.8118, GNorm = 1.5038, lr_0 = 1.0804e-04
Loss = 9.7391e-04, PNorm = 54.8168, GNorm = 3.2058, lr_0 = 1.0804e-04
Loss = 1.1390e-03, PNorm = 54.8213, GNorm = 1.6564, lr_0 = 1.0804e-04
Validation rmse logD = 0.583088
Validation R2 logD = 0.769508
Epoch 48
Train function
Loss = 5.8827e-04, PNorm = 54.8255, GNorm = 2.8104, lr_0 = 1.0804e-04
Loss = 6.9935e-04, PNorm = 54.8294, GNorm = 2.9885, lr_0 = 1.0804e-04
Loss = 7.9548e-04, PNorm = 54.8340, GNorm = 3.1595, lr_0 = 1.0804e-04
Loss = 8.8100e-04, PNorm = 54.8389, GNorm = 3.0433, lr_0 = 1.0804e-04
Loss = 1.2310e-03, PNorm = 54.8421, GNorm = 3.1711, lr_0 = 1.0804e-04
Loss = 9.9172e-04, PNorm = 54.8476, GNorm = 1.4052, lr_0 = 1.0804e-04
Validation rmse logD = 0.627293
Validation R2 logD = 0.733234
Epoch 49
Train function
Loss = 8.7789e-04, PNorm = 54.8533, GNorm = 2.3243, lr_0 = 1.0804e-04
Loss = 8.0888e-04, PNorm = 54.8576, GNorm = 1.2955, lr_0 = 1.0804e-04
Loss = 8.0084e-04, PNorm = 54.8617, GNorm = 2.5169, lr_0 = 1.0804e-04
Loss = 9.2917e-04, PNorm = 54.8665, GNorm = 1.4802, lr_0 = 1.0804e-04
Loss = 8.7203e-04, PNorm = 54.8705, GNorm = 1.3623, lr_0 = 1.0804e-04
Loss = 1.0997e-03, PNorm = 54.8747, GNorm = 8.0187, lr_0 = 1.0804e-04
Validation rmse logD = 0.584248
Validation R2 logD = 0.768589
Epoch 50
Train function
Loss = 1.0468e-03, PNorm = 54.8786, GNorm = 3.9032, lr_0 = 1.0804e-04
Loss = 9.7129e-04, PNorm = 54.8832, GNorm = 2.3879, lr_0 = 1.0804e-04
Loss = 8.9839e-04, PNorm = 54.8884, GNorm = 0.9371, lr_0 = 1.0804e-04
Loss = 7.6803e-04, PNorm = 54.8936, GNorm = 1.3822, lr_0 = 1.0804e-04
Loss = 8.3259e-04, PNorm = 54.8979, GNorm = 2.3155, lr_0 = 1.0804e-04
Validation rmse logD = 0.587676
Validation R2 logD = 0.765866
Epoch 51
Train function
Loss = 9.4446e-04, PNorm = 54.9016, GNorm = 5.0134, lr_0 = 1.0804e-04
Loss = 7.9724e-04, PNorm = 54.9058, GNorm = 4.2649, lr_0 = 1.0804e-04
Loss = 8.8856e-04, PNorm = 54.9099, GNorm = 4.3902, lr_0 = 1.0804e-04
Loss = 1.2550e-03, PNorm = 54.9145, GNorm = 1.0655, lr_0 = 1.0804e-04
Loss = 1.0542e-03, PNorm = 54.9195, GNorm = 4.0389, lr_0 = 1.0804e-04
Loss = 1.1347e-03, PNorm = 54.9249, GNorm = 6.9704, lr_0 = 1.0804e-04
Validation rmse logD = 0.607782
Validation R2 logD = 0.749571
Epoch 52
Train function
Loss = 7.7798e-04, PNorm = 54.9300, GNorm = 3.2347, lr_0 = 1.0804e-04
Loss = 8.6399e-04, PNorm = 54.9341, GNorm = 1.6920, lr_0 = 1.0804e-04
Loss = 8.7152e-04, PNorm = 54.9394, GNorm = 5.3389, lr_0 = 1.0804e-04
Loss = 1.0233e-03, PNorm = 54.9447, GNorm = 4.4762, lr_0 = 1.0804e-04
Loss = 9.7217e-04, PNorm = 54.9503, GNorm = 1.1195, lr_0 = 1.0804e-04
Loss = 8.2569e-04, PNorm = 54.9555, GNorm = 4.9048, lr_0 = 1.0804e-04
Validation rmse logD = 0.583122
Validation R2 logD = 0.769480
Epoch 53
Train function
Loss = 6.7648e-04, PNorm = 54.9604, GNorm = 1.4100, lr_0 = 1.0804e-04
Loss = 6.0123e-04, PNorm = 54.9637, GNorm = 1.0365, lr_0 = 1.0804e-04
Loss = 6.5824e-04, PNorm = 54.9665, GNorm = 1.3118, lr_0 = 1.0804e-04
Loss = 6.6587e-04, PNorm = 54.9712, GNorm = 1.3414, lr_0 = 1.0804e-04
Loss = 7.3519e-04, PNorm = 54.9765, GNorm = 1.8037, lr_0 = 1.0804e-04
Validation rmse logD = 0.590986
Validation R2 logD = 0.763221
Epoch 54
Train function
Loss = 7.6315e-04, PNorm = 54.9802, GNorm = 2.8424, lr_0 = 1.0804e-04
Loss = 5.9998e-04, PNorm = 54.9843, GNorm = 2.9163, lr_0 = 1.0804e-04
Loss = 7.1048e-04, PNorm = 54.9886, GNorm = 3.0500, lr_0 = 1.0804e-04
Loss = 6.2841e-04, PNorm = 54.9915, GNorm = 1.0937, lr_0 = 1.0804e-04
Loss = 7.1915e-04, PNorm = 54.9953, GNorm = 1.0709, lr_0 = 1.0804e-04
Loss = 5.9987e-04, PNorm = 54.9995, GNorm = 1.3404, lr_0 = 1.0804e-04
Validation rmse logD = 0.589276
Validation R2 logD = 0.764589
Epoch 55
Train function
Loss = 6.9339e-04, PNorm = 55.0023, GNorm = 1.2853, lr_0 = 1.0804e-04
Loss = 8.1012e-04, PNorm = 55.0064, GNorm = 3.6395, lr_0 = 1.0804e-04
Loss = 7.2512e-04, PNorm = 55.0106, GNorm = 2.2407, lr_0 = 1.0804e-04
Loss = 7.2189e-04, PNorm = 55.0138, GNorm = 1.5487, lr_0 = 1.0804e-04
Loss = 8.6310e-04, PNorm = 55.0188, GNorm = 2.4227, lr_0 = 1.0804e-04
Loss = 6.8760e-04, PNorm = 55.0238, GNorm = 2.0993, lr_0 = 1.0804e-04
Validation rmse logD = 0.567974
Validation R2 logD = 0.781301
Epoch 56
Train function
Loss = 5.5467e-04, PNorm = 55.0286, GNorm = 1.7303, lr_0 = 1.0804e-04
Loss = 5.3796e-04, PNorm = 55.0304, GNorm = 2.3590, lr_0 = 1.0804e-04
Loss = 9.0764e-04, PNorm = 55.0353, GNorm = 2.4728, lr_0 = 1.0804e-04
Loss = 7.2176e-04, PNorm = 55.0404, GNorm = 3.0313, lr_0 = 1.0804e-04
Loss = 1.0035e-03, PNorm = 55.0435, GNorm = 7.1474, lr_0 = 1.0804e-04
Validation rmse logD = 0.598970
Validation R2 logD = 0.756780
Epoch 57
Train function
Loss = 6.8496e-04, PNorm = 55.0476, GNorm = 2.5876, lr_0 = 1.0804e-04
Loss = 6.2822e-04, PNorm = 55.0527, GNorm = 2.0049, lr_0 = 1.0804e-04
Loss = 6.2010e-04, PNorm = 55.0569, GNorm = 1.1972, lr_0 = 1.0804e-04
Loss = 7.2933e-04, PNorm = 55.0601, GNorm = 2.5046, lr_0 = 1.0804e-04
Loss = 6.6450e-04, PNorm = 55.0645, GNorm = 1.6611, lr_0 = 1.0804e-04
Loss = 4.6312e-04, PNorm = 55.0692, GNorm = 1.2209, lr_0 = 1.0804e-04
Validation rmse logD = 0.577471
Validation R2 logD = 0.773927
Epoch 58
Train function
Loss = 5.1068e-04, PNorm = 55.0726, GNorm = 3.2083, lr_0 = 1.0804e-04
Loss = 7.4222e-04, PNorm = 55.0753, GNorm = 5.7752, lr_0 = 1.0804e-04
Loss = 8.5550e-04, PNorm = 55.0793, GNorm = 0.9941, lr_0 = 1.0804e-04
Loss = 6.1154e-04, PNorm = 55.0838, GNorm = 2.6533, lr_0 = 1.0804e-04
Loss = 7.1152e-04, PNorm = 55.0881, GNorm = 1.4064, lr_0 = 1.0804e-04
Loss = 5.3805e-04, PNorm = 55.0921, GNorm = 2.3018, lr_0 = 1.0804e-04
Validation rmse logD = 0.576278
Validation R2 logD = 0.774860
Epoch 59
Train function
Loss = 5.1571e-04, PNorm = 55.0959, GNorm = 3.8146, lr_0 = 1.0804e-04
Loss = 7.3614e-04, PNorm = 55.1002, GNorm = 2.5857, lr_0 = 1.0804e-04
Loss = 8.1514e-04, PNorm = 55.1045, GNorm = 3.4613, lr_0 = 1.0804e-04
Loss = 5.7352e-04, PNorm = 55.1090, GNorm = 1.1405, lr_0 = 1.0804e-04
Loss = 6.2384e-04, PNorm = 55.1131, GNorm = 0.8786, lr_0 = 1.0804e-04
Validation rmse logD = 0.587691
Validation R2 logD = 0.765854
Epoch 60
Train function
Loss = 6.7648e-04, PNorm = 55.1166, GNorm = 0.9532, lr_0 = 1.0804e-04
Loss = 4.9381e-04, PNorm = 55.1202, GNorm = 2.0690, lr_0 = 1.0804e-04
Loss = 5.9464e-04, PNorm = 55.1229, GNorm = 0.9672, lr_0 = 1.0804e-04
Loss = 7.2138e-04, PNorm = 55.1264, GNorm = 6.5356, lr_0 = 1.0804e-04
Loss = 5.9298e-04, PNorm = 55.1299, GNorm = 5.0321, lr_0 = 1.0804e-04
Loss = 7.2528e-04, PNorm = 55.1330, GNorm = 2.0443, lr_0 = 1.0804e-04
Validation rmse logD = 0.576241
Validation R2 logD = 0.774888
Epoch 61
Train function
Loss = 6.6433e-04, PNorm = 55.1368, GNorm = 4.0024, lr_0 = 1.0804e-04
Loss = 6.6373e-04, PNorm = 55.1421, GNorm = 3.3031, lr_0 = 1.0804e-04
Loss = 7.0883e-04, PNorm = 55.1455, GNorm = 2.0666, lr_0 = 1.0804e-04
Loss = 6.2164e-04, PNorm = 55.1500, GNorm = 2.3706, lr_0 = 1.0804e-04
Loss = 6.8819e-04, PNorm = 55.1547, GNorm = 1.8705, lr_0 = 1.0804e-04
Loss = 5.5243e-04, PNorm = 55.1580, GNorm = 2.7804, lr_0 = 1.0804e-04
Validation rmse logD = 0.579925
Validation R2 logD = 0.772001
Epoch 62
Train function
Loss = 4.5614e-04, PNorm = 55.1627, GNorm = 2.2148, lr_0 = 1.0804e-04
Loss = 4.6222e-04, PNorm = 55.1657, GNorm = 3.3358, lr_0 = 1.0804e-04
Loss = 4.6629e-04, PNorm = 55.1696, GNorm = 1.7730, lr_0 = 1.0804e-04
Loss = 6.2185e-04, PNorm = 55.1714, GNorm = 1.9553, lr_0 = 1.0804e-04
Loss = 5.1616e-04, PNorm = 55.1747, GNorm = 1.8416, lr_0 = 1.0804e-04
Validation rmse logD = 0.588283
Validation R2 logD = 0.765382
Epoch 63
Train function
Loss = 3.8706e-04, PNorm = 55.1786, GNorm = 1.3771, lr_0 = 1.0804e-04
Loss = 3.7391e-04, PNorm = 55.1812, GNorm = 1.1608, lr_0 = 1.0804e-04
Loss = 5.8131e-04, PNorm = 55.1824, GNorm = 4.4560, lr_0 = 1.0804e-04
Loss = 5.7585e-04, PNorm = 55.1860, GNorm = 1.5646, lr_0 = 1.0804e-04
Loss = 7.3549e-04, PNorm = 55.1903, GNorm = 2.3194, lr_0 = 1.0804e-04
Loss = 6.0478e-04, PNorm = 55.1940, GNorm = 2.1925, lr_0 = 1.0804e-04
Validation rmse logD = 0.589954
Validation R2 logD = 0.764047
Epoch 64
Train function
Loss = 7.3536e-04, PNorm = 55.1980, GNorm = 1.9793, lr_0 = 1.0804e-04
Loss = 3.8219e-04, PNorm = 55.2031, GNorm = 1.2718, lr_0 = 1.0804e-04
Loss = 4.4610e-04, PNorm = 55.2054, GNorm = 1.0604, lr_0 = 1.0804e-04
Loss = 4.8171e-04, PNorm = 55.2086, GNorm = 3.8616, lr_0 = 1.0804e-04
Loss = 6.6729e-04, PNorm = 55.2106, GNorm = 4.7607, lr_0 = 1.0804e-04
Loss = 7.7006e-04, PNorm = 55.2147, GNorm = 3.7467, lr_0 = 1.0804e-04
Validation rmse logD = 0.573519
Validation R2 logD = 0.777010
Epoch 65
Train function
Loss = 5.3983e-04, PNorm = 55.2189, GNorm = 1.3702, lr_0 = 1.0804e-04
Loss = 6.7031e-04, PNorm = 55.2229, GNorm = 2.2605, lr_0 = 1.0804e-04
Loss = 5.8849e-04, PNorm = 55.2260, GNorm = 3.4923, lr_0 = 1.0804e-04
Loss = 8.4165e-04, PNorm = 55.2293, GNorm = 5.6963, lr_0 = 1.0804e-04
Loss = 7.1157e-04, PNorm = 55.2340, GNorm = 1.3786, lr_0 = 1.0804e-04
Validation rmse logD = 0.585490
Validation R2 logD = 0.767604
Epoch 66
Train function
Loss = 5.1328e-04, PNorm = 55.2394, GNorm = 3.2443, lr_0 = 1.0804e-04
Loss = 5.4074e-04, PNorm = 55.2440, GNorm = 2.6678, lr_0 = 1.0804e-04
Loss = 5.4649e-04, PNorm = 55.2479, GNorm = 2.5451, lr_0 = 1.0804e-04
Loss = 4.5791e-04, PNorm = 55.2520, GNorm = 0.9222, lr_0 = 1.0804e-04
Loss = 6.4637e-04, PNorm = 55.2555, GNorm = 1.1984, lr_0 = 1.0804e-04
Loss = 5.1168e-04, PNorm = 55.2588, GNorm = 0.7993, lr_0 = 1.0804e-04
Validation rmse logD = 0.610286
Validation R2 logD = 0.747503
Epoch 67
Train function
Loss = 4.7396e-04, PNorm = 55.2624, GNorm = 2.4084, lr_0 = 1.0804e-04
Loss = 5.7413e-04, PNorm = 55.2653, GNorm = 1.4620, lr_0 = 1.0804e-04
Loss = 5.4760e-04, PNorm = 55.2695, GNorm = 0.5329, lr_0 = 1.0804e-04
Loss = 5.7527e-04, PNorm = 55.2740, GNorm = 1.3366, lr_0 = 1.0804e-04
Loss = 4.0901e-04, PNorm = 55.2777, GNorm = 2.2212, lr_0 = 1.0804e-04
Loss = 7.0084e-04, PNorm = 55.2801, GNorm = 3.9413, lr_0 = 1.0804e-04
Validation rmse logD = 0.574159
Validation R2 logD = 0.776512
Epoch 68
Train function
Loss = 6.8796e-04, PNorm = 55.2845, GNorm = 0.7058, lr_0 = 1.0804e-04
Loss = 4.3109e-04, PNorm = 55.2879, GNorm = 0.9777, lr_0 = 1.0804e-04
Loss = 4.3311e-04, PNorm = 55.2905, GNorm = 1.0332, lr_0 = 1.0804e-04
Loss = 3.7654e-04, PNorm = 55.2946, GNorm = 0.8443, lr_0 = 1.0804e-04
Loss = 5.2160e-04, PNorm = 55.2976, GNorm = 1.4226, lr_0 = 1.0804e-04
Validation rmse logD = 0.579156
Validation R2 logD = 0.772606
Epoch 69
Train function
Loss = 4.4409e-04, PNorm = 55.2999, GNorm = 1.1712, lr_0 = 1.0804e-04
Loss = 4.0085e-04, PNorm = 55.3030, GNorm = 2.2077, lr_0 = 1.0804e-04
Loss = 5.1405e-04, PNorm = 55.3066, GNorm = 1.8034, lr_0 = 1.0804e-04
Loss = 4.6821e-04, PNorm = 55.3122, GNorm = 2.4589, lr_0 = 1.0804e-04
Loss = 4.3052e-04, PNorm = 55.3153, GNorm = 0.7214, lr_0 = 1.0804e-04
Loss = 6.9282e-04, PNorm = 55.3167, GNorm = 6.7122, lr_0 = 1.0804e-04
Validation rmse logD = 0.572683
Validation R2 logD = 0.777660
Epoch 70
Train function
Loss = 6.5295e-04, PNorm = 55.3198, GNorm = 6.4106, lr_0 = 1.0804e-04
Loss = 7.2749e-04, PNorm = 55.3243, GNorm = 4.6631, lr_0 = 1.0804e-04
Loss = 6.3883e-04, PNorm = 55.3276, GNorm = 2.3121, lr_0 = 1.0804e-04
Loss = 8.0347e-04, PNorm = 55.3332, GNorm = 1.1646, lr_0 = 1.0804e-04
Loss = 4.2707e-04, PNorm = 55.3377, GNorm = 1.9350, lr_0 = 1.0804e-04
Loss = 5.4200e-04, PNorm = 55.3408, GNorm = 2.9874, lr_0 = 1.0804e-04
Validation rmse logD = 0.580795
Validation R2 logD = 0.771317
Epoch 71
Train function
Loss = 3.9132e-04, PNorm = 55.3438, GNorm = 1.7980, lr_0 = 1.0804e-04
Loss = 4.0299e-04, PNorm = 55.3475, GNorm = 1.2995, lr_0 = 1.0804e-04
Loss = 3.3008e-04, PNorm = 55.3509, GNorm = 1.3696, lr_0 = 1.0804e-04
Loss = 5.1979e-04, PNorm = 55.3545, GNorm = 1.4306, lr_0 = 1.0804e-04
Loss = 4.3165e-04, PNorm = 55.3583, GNorm = 2.4387, lr_0 = 1.0804e-04
Validation rmse logD = 0.579897
Validation R2 logD = 0.772023
Epoch 72
Train function
Loss = 2.9873e-04, PNorm = 55.3630, GNorm = 1.2398, lr_0 = 1.0804e-04
Loss = 3.6624e-04, PNorm = 55.3647, GNorm = 1.8255, lr_0 = 1.0804e-04
Loss = 5.0981e-04, PNorm = 55.3680, GNorm = 2.4267, lr_0 = 1.0804e-04
Loss = 3.5587e-04, PNorm = 55.3701, GNorm = 0.7484, lr_0 = 1.0804e-04
Loss = 3.3138e-04, PNorm = 55.3724, GNorm = 1.2495, lr_0 = 1.0804e-04
Loss = 5.4626e-04, PNorm = 55.3751, GNorm = 3.9160, lr_0 = 1.0804e-04
Validation rmse logD = 0.572739
Validation R2 logD = 0.777616
Epoch 73
Train function
Loss = 4.5260e-04, PNorm = 55.3783, GNorm = 2.2887, lr_0 = 1.0804e-04
Loss = 4.6452e-04, PNorm = 55.3806, GNorm = 2.3728, lr_0 = 1.0804e-04
Loss = 8.4680e-04, PNorm = 55.3848, GNorm = 1.1455, lr_0 = 1.0804e-04
Loss = 8.3145e-04, PNorm = 55.3891, GNorm = 2.1224, lr_0 = 1.0804e-04
Loss = 6.0544e-04, PNorm = 55.3936, GNorm = 2.1877, lr_0 = 1.0804e-04
Loss = 5.3571e-04, PNorm = 55.3980, GNorm = 2.8023, lr_0 = 1.0804e-04
Validation rmse logD = 0.583600
Validation R2 logD = 0.769103
Epoch 74
Train function
Loss = 3.5187e-04, PNorm = 55.4023, GNorm = 0.7355, lr_0 = 1.0804e-04
Loss = 4.0420e-04, PNorm = 55.4028, GNorm = 2.1031, lr_0 = 1.0804e-04
Loss = 4.4291e-04, PNorm = 55.4057, GNorm = 1.6843, lr_0 = 1.0804e-04
Loss = 6.0260e-04, PNorm = 55.4092, GNorm = 2.4472, lr_0 = 1.0804e-04
Loss = 6.1661e-04, PNorm = 55.4118, GNorm = 1.8215, lr_0 = 1.0804e-04
Validation rmse logD = 0.577038
Validation R2 logD = 0.774265
Epoch 75
Train function
Loss = 7.0070e-04, PNorm = 55.4151, GNorm = 4.3628, lr_0 = 1.0804e-04
Loss = 4.5553e-04, PNorm = 55.4198, GNorm = 1.6217, lr_0 = 1.0804e-04
Loss = 6.6177e-04, PNorm = 55.4224, GNorm = 2.6500, lr_0 = 1.0804e-04
Loss = 7.3186e-04, PNorm = 55.4255, GNorm = 4.2827, lr_0 = 1.0804e-04
Loss = 5.1389e-04, PNorm = 55.4302, GNorm = 5.6101, lr_0 = 1.0804e-04
Loss = 4.8578e-04, PNorm = 55.4350, GNorm = 1.2831, lr_0 = 1.0804e-04
Validation rmse logD = 0.576714
Validation R2 logD = 0.774519
Epoch 76
Train function
Loss = 2.1773e-04, PNorm = 55.4383, GNorm = 1.2341, lr_0 = 1.0804e-04
Loss = 2.7908e-04, PNorm = 55.4405, GNorm = 0.6783, lr_0 = 1.0804e-04
Loss = 3.1348e-04, PNorm = 55.4426, GNorm = 3.1445, lr_0 = 1.0804e-04
Loss = 3.9069e-04, PNorm = 55.4452, GNorm = 1.9587, lr_0 = 1.0804e-04
Loss = 4.6293e-04, PNorm = 55.4478, GNorm = 3.1775, lr_0 = 1.0804e-04
Loss = 4.2280e-04, PNorm = 55.4510, GNorm = 0.9055, lr_0 = 1.0804e-04
Validation rmse logD = 0.579355
Validation R2 logD = 0.772449
Epoch 77
Train function
Loss = 2.6292e-04, PNorm = 55.4545, GNorm = 1.2256, lr_0 = 1.0804e-04
Loss = 2.6069e-04, PNorm = 55.4564, GNorm = 2.2722, lr_0 = 1.0804e-04
Loss = 3.5772e-04, PNorm = 55.4595, GNorm = 2.5087, lr_0 = 1.0804e-04
Loss = 4.0452e-04, PNorm = 55.4633, GNorm = 0.5678, lr_0 = 1.0804e-04
Loss = 2.9158e-04, PNorm = 55.4667, GNorm = 1.8583, lr_0 = 1.0804e-04
Validation rmse logD = 0.587688
Validation R2 logD = 0.765857
Epoch 78
Train function
Loss = 3.3873e-04, PNorm = 55.4692, GNorm = 2.7462, lr_0 = 1.0804e-04
Loss = 2.8290e-04, PNorm = 55.4707, GNorm = 0.9773, lr_0 = 1.0804e-04
Loss = 2.6903e-04, PNorm = 55.4735, GNorm = 2.4024, lr_0 = 1.0804e-04
Loss = 2.7763e-04, PNorm = 55.4757, GNorm = 1.3835, lr_0 = 1.0804e-04
Loss = 3.6485e-04, PNorm = 55.4786, GNorm = 2.4544, lr_0 = 1.0804e-04
Loss = 3.7037e-04, PNorm = 55.4810, GNorm = 2.2774, lr_0 = 1.0804e-04
Validation rmse logD = 0.575821
Validation R2 logD = 0.775216
Epoch 79
Train function
Loss = 3.8543e-04, PNorm = 55.4847, GNorm = 1.8894, lr_0 = 1.0804e-04
Loss = 3.8710e-04, PNorm = 55.4868, GNorm = 3.0769, lr_0 = 1.0804e-04
Loss = 4.2275e-04, PNorm = 55.4901, GNorm = 1.0252, lr_0 = 1.0804e-04
Loss = 3.9584e-04, PNorm = 55.4930, GNorm = 2.5188, lr_0 = 1.0804e-04
Loss = 5.1864e-04, PNorm = 55.4958, GNorm = 4.5051, lr_0 = 1.0804e-04
Loss = 6.0139e-04, PNorm = 55.4990, GNorm = 1.4103, lr_0 = 1.0804e-04
Validation rmse logD = 0.576946
Validation R2 logD = 0.774338
Epoch 80
Train function
Loss = 5.1477e-04, PNorm = 55.5032, GNorm = 5.1725, lr_0 = 1.0804e-04
Loss = 3.8924e-04, PNorm = 55.5082, GNorm = 0.5327, lr_0 = 1.0804e-04
Loss = 3.2107e-04, PNorm = 55.5115, GNorm = 1.7404, lr_0 = 1.0804e-04
Loss = 2.9836e-04, PNorm = 55.5144, GNorm = 1.6146, lr_0 = 1.0804e-04
Loss = 3.1622e-04, PNorm = 55.5171, GNorm = 2.6783, lr_0 = 1.0804e-04
Validation rmse logD = 0.577524
Validation R2 logD = 0.773885
Epoch 81
Train function
Loss = 2.2753e-04, PNorm = 55.5201, GNorm = 1.5535, lr_0 = 1.0804e-04
Loss = 3.8003e-04, PNorm = 55.5219, GNorm = 2.9190, lr_0 = 1.0804e-04
Loss = 3.6219e-04, PNorm = 55.5248, GNorm = 1.6187, lr_0 = 1.0804e-04
Loss = 5.1523e-04, PNorm = 55.5263, GNorm = 4.1642, lr_0 = 1.0804e-04
Loss = 4.4149e-04, PNorm = 55.5303, GNorm = 1.7518, lr_0 = 1.0804e-04
Loss = 4.7022e-04, PNorm = 55.5349, GNorm = 2.6199, lr_0 = 1.0804e-04
Validation rmse logD = 0.578507
Validation R2 logD = 0.773115
Epoch 82
Train function
Loss = 3.5082e-04, PNorm = 55.5389, GNorm = 0.9487, lr_0 = 1.0804e-04
Loss = 3.3968e-04, PNorm = 55.5434, GNorm = 1.1391, lr_0 = 1.0804e-04
Loss = 3.5168e-04, PNorm = 55.5462, GNorm = 2.6565, lr_0 = 1.0804e-04
Loss = 3.4017e-04, PNorm = 55.5491, GNorm = 1.2041, lr_0 = 1.0804e-04
Loss = 2.7600e-04, PNorm = 55.5521, GNorm = 0.7627, lr_0 = 1.0804e-04
Loss = 3.0071e-04, PNorm = 55.5549, GNorm = 1.2438, lr_0 = 1.0804e-04
Validation rmse logD = 0.578303
Validation R2 logD = 0.773275
Epoch 83
Train function
Loss = 3.0808e-04, PNorm = 55.5589, GNorm = 1.0014, lr_0 = 1.0804e-04
Loss = 2.0783e-04, PNorm = 55.5617, GNorm = 2.3855, lr_0 = 1.0804e-04
Loss = 2.7894e-04, PNorm = 55.5635, GNorm = 1.7365, lr_0 = 1.0804e-04
Loss = 3.1535e-04, PNorm = 55.5655, GNorm = 1.0590, lr_0 = 1.0804e-04
Loss = 2.6159e-04, PNorm = 55.5671, GNorm = 0.9089, lr_0 = 1.0804e-04
Validation rmse logD = 0.571159
Validation R2 logD = 0.778842
Epoch 84
Train function
Loss = 1.8681e-04, PNorm = 55.5684, GNorm = 0.7004, lr_0 = 1.0804e-04
Loss = 3.0992e-04, PNorm = 55.5700, GNorm = 1.5279, lr_0 = 1.0804e-04
Loss = 2.5253e-04, PNorm = 55.5720, GNorm = 1.6432, lr_0 = 1.0804e-04
Loss = 4.0074e-04, PNorm = 55.5755, GNorm = 2.4546, lr_0 = 1.0804e-04
Loss = 3.1010e-04, PNorm = 55.5782, GNorm = 2.0407, lr_0 = 1.0804e-04
Loss = 2.5010e-04, PNorm = 55.5818, GNorm = 0.8211, lr_0 = 1.0804e-04
Validation rmse logD = 0.570276
Validation R2 logD = 0.779525
Epoch 85
Train function
Loss = 2.6066e-04, PNorm = 55.5836, GNorm = 1.7442, lr_0 = 1.0804e-04
Loss = 2.7604e-04, PNorm = 55.5854, GNorm = 0.7616, lr_0 = 1.0804e-04
Loss = 3.2902e-04, PNorm = 55.5881, GNorm = 1.2352, lr_0 = 1.0804e-04
Loss = 2.6738e-04, PNorm = 55.5905, GNorm = 0.8896, lr_0 = 1.0804e-04
Loss = 4.2360e-04, PNorm = 55.5930, GNorm = 4.9109, lr_0 = 1.0804e-04
Loss = 7.1874e-04, PNorm = 55.5965, GNorm = 3.5978, lr_0 = 1.0804e-04
Validation rmse logD = 0.575746
Validation R2 logD = 0.775276
Epoch 86
Train function
Loss = 7.7925e-04, PNorm = 55.6022, GNorm = 3.4642, lr_0 = 1.0804e-04
Loss = 5.4828e-04, PNorm = 55.6063, GNorm = 2.8973, lr_0 = 1.0804e-04
Loss = 7.1534e-04, PNorm = 55.6107, GNorm = 3.3477, lr_0 = 1.0804e-04
Loss = 6.0017e-04, PNorm = 55.6149, GNorm = 2.9279, lr_0 = 1.0804e-04
Loss = 4.1103e-04, PNorm = 55.6197, GNorm = 1.3485, lr_0 = 1.0804e-04
Validation rmse logD = 0.581561
Validation R2 logD = 0.770713
Epoch 87
Train function
Loss = 4.6894e-04, PNorm = 55.6244, GNorm = 3.4063, lr_0 = 1.0804e-04
Loss = 4.3001e-04, PNorm = 55.6271, GNorm = 3.9579, lr_0 = 1.0804e-04
Loss = 4.5119e-04, PNorm = 55.6293, GNorm = 3.1508, lr_0 = 1.0804e-04
Loss = 3.8018e-04, PNorm = 55.6331, GNorm = 2.5353, lr_0 = 1.0804e-04
Loss = 3.3976e-04, PNorm = 55.6376, GNorm = 0.8299, lr_0 = 1.0804e-04
Loss = 3.1377e-04, PNorm = 55.6411, GNorm = 0.6196, lr_0 = 1.0804e-04
Validation rmse logD = 0.592970
Validation R2 logD = 0.761628
Epoch 88
Train function
Loss = 4.6456e-04, PNorm = 55.6440, GNorm = 3.4336, lr_0 = 1.0804e-04
Loss = 4.1845e-04, PNorm = 55.6466, GNorm = 1.3435, lr_0 = 1.0804e-04
Loss = 4.3547e-04, PNorm = 55.6500, GNorm = 3.7012, lr_0 = 1.0804e-04
Loss = 3.8434e-04, PNorm = 55.6524, GNorm = 0.9024, lr_0 = 1.0804e-04
Loss = 3.1683e-04, PNorm = 55.6550, GNorm = 0.6858, lr_0 = 1.0804e-04
Loss = 3.5367e-04, PNorm = 55.6577, GNorm = 2.3401, lr_0 = 1.0804e-04
Validation rmse logD = 0.576822
Validation R2 logD = 0.774434
Epoch 89
Train function
Loss = 2.9497e-04, PNorm = 55.6620, GNorm = 1.1939, lr_0 = 1.0804e-04
Loss = 2.4346e-04, PNorm = 55.6641, GNorm = 2.1597, lr_0 = 1.0804e-04
Loss = 2.9619e-04, PNorm = 55.6665, GNorm = 1.1755, lr_0 = 1.0804e-04
Loss = 3.1533e-04, PNorm = 55.6708, GNorm = 0.9477, lr_0 = 1.0804e-04
Loss = 4.0063e-04, PNorm = 55.6735, GNorm = 2.1636, lr_0 = 1.0804e-04
Validation rmse logD = 0.586781
Validation R2 logD = 0.766578
Epoch 90
Train function
Loss = 3.6201e-04, PNorm = 55.6770, GNorm = 1.6231, lr_0 = 1.0804e-04
Loss = 3.4848e-04, PNorm = 55.6802, GNorm = 3.0375, lr_0 = 1.0804e-04
Loss = 4.9017e-04, PNorm = 55.6814, GNorm = 3.0169, lr_0 = 1.0804e-04
Loss = 3.2658e-04, PNorm = 55.6845, GNorm = 1.1129, lr_0 = 1.0804e-04
Loss = 2.6448e-04, PNorm = 55.6878, GNorm = 0.4994, lr_0 = 1.0804e-04
Loss = 3.0305e-04, PNorm = 55.6912, GNorm = 0.6269, lr_0 = 1.0804e-04
Validation rmse logD = 0.579836
Validation R2 logD = 0.772071
Epoch 91
Train function
Loss = 5.1251e-04, PNorm = 55.6932, GNorm = 4.8303, lr_0 = 1.0804e-04
Loss = 3.9529e-04, PNorm = 55.6961, GNorm = 1.1809, lr_0 = 1.0804e-04
Loss = 5.3421e-04, PNorm = 55.6990, GNorm = 4.5456, lr_0 = 1.0804e-04
Loss = 4.1169e-04, PNorm = 55.7029, GNorm = 3.0242, lr_0 = 1.0804e-04
Loss = 2.7884e-04, PNorm = 55.7065, GNorm = 0.7779, lr_0 = 1.0804e-04
Loss = 3.3468e-04, PNorm = 55.7100, GNorm = 2.3114, lr_0 = 1.0804e-04
Validation rmse logD = 0.576645
Validation R2 logD = 0.774573
Epoch 92
Train function
Loss = 2.0596e-04, PNorm = 55.7133, GNorm = 2.8251, lr_0 = 1.0804e-04
Loss = 2.4076e-04, PNorm = 55.7153, GNorm = 0.9867, lr_0 = 1.0804e-04
Loss = 3.0389e-04, PNorm = 55.7170, GNorm = 3.0845, lr_0 = 1.0804e-04
Loss = 3.3933e-04, PNorm = 55.7183, GNorm = 0.8922, lr_0 = 1.0804e-04
Loss = 3.6135e-04, PNorm = 55.7209, GNorm = 0.9370, lr_0 = 1.0804e-04
Validation rmse logD = 0.577055
Validation R2 logD = 0.774252
Epoch 93
Train function
Loss = 3.9122e-04, PNorm = 55.7247, GNorm = 3.4411, lr_0 = 1.0804e-04
Loss = 2.8215e-04, PNorm = 55.7273, GNorm = 0.6794, lr_0 = 1.0804e-04
Loss = 2.9936e-04, PNorm = 55.7297, GNorm = 2.4968, lr_0 = 1.0804e-04
Loss = 3.1965e-04, PNorm = 55.7323, GNorm = 2.4598, lr_0 = 1.0804e-04
Loss = 3.2392e-04, PNorm = 55.7357, GNorm = 3.4135, lr_0 = 1.0804e-04
Loss = 3.1387e-04, PNorm = 55.7392, GNorm = 2.4410, lr_0 = 1.0804e-04
Validation rmse logD = 0.596825
Validation R2 logD = 0.758519
Epoch 94
Train function
Loss = 2.8122e-04, PNorm = 55.7403, GNorm = 2.2428, lr_0 = 1.0804e-04
Loss = 2.1829e-04, PNorm = 55.7433, GNorm = 1.1802, lr_0 = 1.0804e-04
Loss = 3.0943e-04, PNorm = 55.7465, GNorm = 1.9611, lr_0 = 1.0804e-04
Loss = 3.1298e-04, PNorm = 55.7496, GNorm = 1.7547, lr_0 = 1.0804e-04
Loss = 3.1787e-04, PNorm = 55.7523, GNorm = 3.0650, lr_0 = 1.0804e-04
Loss = 2.4726e-04, PNorm = 55.7548, GNorm = 0.6583, lr_0 = 1.0804e-04
Validation rmse logD = 0.586142
Validation R2 logD = 0.767086
Epoch 95
Train function
Loss = 1.9116e-04, PNorm = 55.7560, GNorm = 1.7346, lr_0 = 1.0804e-04
Loss = 3.0846e-04, PNorm = 55.7585, GNorm = 0.3670, lr_0 = 1.0804e-04
Loss = 2.5345e-04, PNorm = 55.7606, GNorm = 1.2406, lr_0 = 1.0804e-04
Loss = 2.4400e-04, PNorm = 55.7623, GNorm = 2.5142, lr_0 = 1.0804e-04
Loss = 3.1003e-04, PNorm = 55.7645, GNorm = 0.6152, lr_0 = 1.0804e-04
Validation rmse logD = 0.581061
Validation R2 logD = 0.771107
Epoch 96
Train function
Loss = 2.1775e-04, PNorm = 55.7664, GNorm = 0.8113, lr_0 = 1.0804e-04
Loss = 2.3167e-04, PNorm = 55.7698, GNorm = 2.2613, lr_0 = 1.0804e-04
Loss = 2.2854e-04, PNorm = 55.7732, GNorm = 1.0431, lr_0 = 1.0804e-04
Loss = 2.0879e-04, PNorm = 55.7754, GNorm = 1.8605, lr_0 = 1.0804e-04
Loss = 3.4345e-04, PNorm = 55.7765, GNorm = 1.9230, lr_0 = 1.0804e-04
Loss = 3.1768e-04, PNorm = 55.7789, GNorm = 1.5532, lr_0 = 1.0804e-04
Validation rmse logD = 0.576089
Validation R2 logD = 0.775007
Epoch 97
Train function
Loss = 1.5994e-04, PNorm = 55.7826, GNorm = 0.7280, lr_0 = 1.0804e-04
Loss = 2.1166e-04, PNorm = 55.7847, GNorm = 1.1692, lr_0 = 1.0804e-04
Loss = 1.9754e-04, PNorm = 55.7860, GNorm = 1.3798, lr_0 = 1.0804e-04
Loss = 3.4872e-04, PNorm = 55.7889, GNorm = 1.4422, lr_0 = 1.0804e-04
Loss = 2.8244e-04, PNorm = 55.7920, GNorm = 1.6652, lr_0 = 1.0804e-04
Loss = 2.4577e-04, PNorm = 55.7943, GNorm = 3.1055, lr_0 = 1.0804e-04
Validation rmse logD = 0.577440
Validation R2 logD = 0.773951
Epoch 98
Train function
Loss = 3.2050e-04, PNorm = 55.7977, GNorm = 2.0137, lr_0 = 1.0804e-04
Loss = 3.6370e-04, PNorm = 55.8001, GNorm = 4.1022, lr_0 = 1.0804e-04
Loss = 4.0583e-04, PNorm = 55.8026, GNorm = 2.4125, lr_0 = 1.0804e-04
Loss = 4.5010e-04, PNorm = 55.8069, GNorm = 0.5482, lr_0 = 1.0804e-04
Loss = 3.6063e-04, PNorm = 55.8111, GNorm = 2.0239, lr_0 = 1.0804e-04
Validation rmse logD = 0.574142
Validation R2 logD = 0.776525
Epoch 99
Train function
Loss = 2.6189e-04, PNorm = 55.8154, GNorm = 1.1590, lr_0 = 1.0804e-04
Loss = 1.7826e-04, PNorm = 55.8177, GNorm = 1.3751, lr_0 = 1.0804e-04
Loss = 2.1034e-04, PNorm = 55.8190, GNorm = 0.7735, lr_0 = 1.0804e-04
Loss = 1.9336e-04, PNorm = 55.8214, GNorm = 0.7452, lr_0 = 1.0804e-04
Loss = 2.7631e-04, PNorm = 55.8228, GNorm = 0.9552, lr_0 = 1.0804e-04
Loss = 2.8652e-04, PNorm = 55.8267, GNorm = 2.5849, lr_0 = 1.0804e-04
Validation rmse logD = 0.573395
Validation R2 logD = 0.777107
Model 0 best validation rmse = 0.567974 on epoch 55
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.529502
Model 0 test R2 logD = 0.780097
Ensemble test rmse  logD= 0.529502
Ensemble test R2  logD= 0.780097
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.1757e-02, PNorm = 52.9125, GNorm = 2.3064, lr_0 = 1.0804e-04
Loss = 2.0725e-02, PNorm = 52.9147, GNorm = 7.5026, lr_0 = 1.0804e-04
Loss = 1.5281e-02, PNorm = 52.9174, GNorm = 9.0374, lr_0 = 1.0804e-04
Loss = 1.4707e-02, PNorm = 52.9209, GNorm = 3.0922, lr_0 = 1.0804e-04
Loss = 1.4976e-02, PNorm = 52.9249, GNorm = 2.8633, lr_0 = 1.0804e-04
Validation rmse logD = 1.027417
Validation R2 logD = 0.284086
Epoch 1
Train function
Loss = 1.2472e-02, PNorm = 52.9298, GNorm = 1.7153, lr_0 = 1.0804e-04
Loss = 1.4045e-02, PNorm = 52.9340, GNorm = 6.0653, lr_0 = 1.0804e-04
Loss = 1.3873e-02, PNorm = 52.9384, GNorm = 2.8258, lr_0 = 1.0804e-04
Loss = 1.3112e-02, PNorm = 52.9440, GNorm = 2.5996, lr_0 = 1.0804e-04
Loss = 1.2554e-02, PNorm = 52.9489, GNorm = 6.0225, lr_0 = 1.0804e-04
Loss = 1.3551e-02, PNorm = 52.9540, GNorm = 3.2794, lr_0 = 1.0804e-04
Validation rmse logD = 0.956077
Validation R2 logD = 0.380055
Epoch 2
Train function
Loss = 1.2260e-02, PNorm = 52.9598, GNorm = 3.7007, lr_0 = 1.0804e-04
Loss = 1.0946e-02, PNorm = 52.9670, GNorm = 3.3816, lr_0 = 1.0804e-04
Loss = 1.1205e-02, PNorm = 52.9732, GNorm = 9.1767, lr_0 = 1.0804e-04
Loss = 1.2948e-02, PNorm = 52.9796, GNorm = 3.5123, lr_0 = 1.0804e-04
Loss = 1.0696e-02, PNorm = 52.9872, GNorm = 2.4243, lr_0 = 1.0804e-04
Validation rmse logD = 0.908415
Validation R2 logD = 0.440325
Epoch 3
Train function
Loss = 7.9108e-03, PNorm = 52.9961, GNorm = 1.4416, lr_0 = 1.0804e-04
Loss = 1.0802e-02, PNorm = 53.0047, GNorm = 3.4728, lr_0 = 1.0804e-04
Loss = 1.0005e-02, PNorm = 53.0125, GNorm = 6.9123, lr_0 = 1.0804e-04
Loss = 1.0271e-02, PNorm = 53.0230, GNorm = 5.7438, lr_0 = 1.0804e-04
Loss = 1.0653e-02, PNorm = 53.0296, GNorm = 7.6636, lr_0 = 1.0804e-04
Loss = 8.3752e-03, PNorm = 53.0366, GNorm = 8.2436, lr_0 = 1.0804e-04
Validation rmse logD = 0.946071
Validation R2 logD = 0.392964
Epoch 4
Train function
Loss = 1.0800e-02, PNorm = 53.0454, GNorm = 5.3209, lr_0 = 1.0804e-04
Loss = 9.7211e-03, PNorm = 53.0546, GNorm = 2.5685, lr_0 = 1.0804e-04
Loss = 7.7078e-03, PNorm = 53.0646, GNorm = 2.2777, lr_0 = 1.0804e-04
Loss = 8.7758e-03, PNorm = 53.0736, GNorm = 6.0572, lr_0 = 1.0804e-04
Loss = 8.6334e-03, PNorm = 53.0817, GNorm = 1.3186, lr_0 = 1.0804e-04
Loss = 9.7861e-03, PNorm = 53.0911, GNorm = 2.9287, lr_0 = 1.0804e-04
Validation rmse logD = 1.007074
Validation R2 logD = 0.312156
Epoch 5
Train function
Loss = 1.2095e-02, PNorm = 53.0995, GNorm = 6.1775, lr_0 = 1.0804e-04
Loss = 8.3611e-03, PNorm = 53.1077, GNorm = 4.0842, lr_0 = 1.0804e-04
Loss = 8.4217e-03, PNorm = 53.1185, GNorm = 2.7437, lr_0 = 1.0804e-04
Loss = 9.5623e-03, PNorm = 53.1287, GNorm = 8.8762, lr_0 = 1.0804e-04
Loss = 8.1933e-03, PNorm = 53.1374, GNorm = 2.8427, lr_0 = 1.0804e-04
Validation rmse logD = 0.851850
Validation R2 logD = 0.507854
Epoch 6
Train function
Loss = 1.1893e-02, PNorm = 53.1483, GNorm = 7.0534, lr_0 = 1.0804e-04
Loss = 7.4254e-03, PNorm = 53.1576, GNorm = 3.6581, lr_0 = 1.0804e-04
Loss = 7.1935e-03, PNorm = 53.1666, GNorm = 6.3736, lr_0 = 1.0804e-04
Loss = 7.8128e-03, PNorm = 53.1769, GNorm = 1.9651, lr_0 = 1.0804e-04
Loss = 6.8237e-03, PNorm = 53.1888, GNorm = 1.6369, lr_0 = 1.0804e-04
Loss = 7.8786e-03, PNorm = 53.2002, GNorm = 2.3868, lr_0 = 1.0804e-04
Validation rmse logD = 0.772152
Validation R2 logD = 0.595636
Epoch 7
Train function
Loss = 6.7595e-03, PNorm = 53.2095, GNorm = 6.2854, lr_0 = 1.0804e-04
Loss = 5.6067e-03, PNorm = 53.2187, GNorm = 1.5186, lr_0 = 1.0804e-04
Loss = 6.7157e-03, PNorm = 53.2287, GNorm = 4.5017, lr_0 = 1.0804e-04
Loss = 6.3735e-03, PNorm = 53.2395, GNorm = 2.3747, lr_0 = 1.0804e-04
Loss = 6.9076e-03, PNorm = 53.2497, GNorm = 3.0683, lr_0 = 1.0804e-04
Loss = 8.2833e-03, PNorm = 53.2597, GNorm = 1.7244, lr_0 = 1.0804e-04
Validation rmse logD = 0.762358
Validation R2 logD = 0.605829
Epoch 8
Train function
Loss = 7.9054e-03, PNorm = 53.2685, GNorm = 5.9921, lr_0 = 1.0804e-04
Loss = 6.0694e-03, PNorm = 53.2789, GNorm = 2.0158, lr_0 = 1.0804e-04
Loss = 6.3870e-03, PNorm = 53.2890, GNorm = 4.1305, lr_0 = 1.0804e-04
Loss = 7.1452e-03, PNorm = 53.2986, GNorm = 2.4077, lr_0 = 1.0804e-04
Loss = 7.5305e-03, PNorm = 53.3072, GNorm = 8.4184, lr_0 = 1.0804e-04
Validation rmse logD = 0.762121
Validation R2 logD = 0.606074
Epoch 9
Train function
Loss = 5.4509e-03, PNorm = 53.3181, GNorm = 7.7539, lr_0 = 1.0804e-04
Loss = 6.3091e-03, PNorm = 53.3273, GNorm = 5.4176, lr_0 = 1.0804e-04
Loss = 6.5951e-03, PNorm = 53.3368, GNorm = 2.3961, lr_0 = 1.0804e-04
Loss = 5.9303e-03, PNorm = 53.3472, GNorm = 7.7428, lr_0 = 1.0804e-04
Loss = 6.1127e-03, PNorm = 53.3571, GNorm = 1.7235, lr_0 = 1.0804e-04
Loss = 5.8230e-03, PNorm = 53.3666, GNorm = 3.0528, lr_0 = 1.0804e-04
Validation rmse logD = 0.693456
Validation R2 logD = 0.673859
Epoch 10
Train function
Loss = 7.1721e-03, PNorm = 53.3738, GNorm = 1.5829, lr_0 = 1.0804e-04
Loss = 6.0005e-03, PNorm = 53.3815, GNorm = 6.6763, lr_0 = 1.0804e-04
Loss = 5.1375e-03, PNorm = 53.3924, GNorm = 3.4570, lr_0 = 1.0804e-04
Loss = 5.3012e-03, PNorm = 53.4025, GNorm = 8.4080, lr_0 = 1.0804e-04
Loss = 5.6741e-03, PNorm = 53.4081, GNorm = 2.2816, lr_0 = 1.0804e-04
Loss = 5.3893e-03, PNorm = 53.4134, GNorm = 7.1152, lr_0 = 1.0804e-04
Validation rmse logD = 0.739095
Validation R2 logD = 0.629517
Epoch 11
Train function
Loss = 6.3461e-03, PNorm = 53.4252, GNorm = 4.5583, lr_0 = 1.0804e-04
Loss = 5.2297e-03, PNorm = 53.4366, GNorm = 5.4594, lr_0 = 1.0804e-04
Loss = 5.8738e-03, PNorm = 53.4455, GNorm = 2.6568, lr_0 = 1.0804e-04
Loss = 4.2636e-03, PNorm = 53.4536, GNorm = 1.4925, lr_0 = 1.0804e-04
Loss = 5.2074e-03, PNorm = 53.4619, GNorm = 7.6678, lr_0 = 1.0804e-04
Validation rmse logD = 0.672376
Validation R2 logD = 0.693386
Epoch 12
Train function
Loss = 7.3402e-03, PNorm = 53.4690, GNorm = 2.8509, lr_0 = 1.0804e-04
Loss = 5.3883e-03, PNorm = 53.4766, GNorm = 7.4013, lr_0 = 1.0804e-04
Loss = 5.3412e-03, PNorm = 53.4842, GNorm = 6.0721, lr_0 = 1.0804e-04
Loss = 5.6865e-03, PNorm = 53.4913, GNorm = 2.3712, lr_0 = 1.0804e-04
Loss = 4.8532e-03, PNorm = 53.4978, GNorm = 4.6186, lr_0 = 1.0804e-04
Loss = 4.9588e-03, PNorm = 53.5070, GNorm = 7.0569, lr_0 = 1.0804e-04
Validation rmse logD = 0.653274
Validation R2 logD = 0.710560
Epoch 13
Train function
Loss = 4.1755e-03, PNorm = 53.5173, GNorm = 4.4955, lr_0 = 1.0804e-04
Loss = 4.2552e-03, PNorm = 53.5275, GNorm = 2.9644, lr_0 = 1.0804e-04
Loss = 5.5658e-03, PNorm = 53.5340, GNorm = 2.1034, lr_0 = 1.0804e-04
Loss = 4.5502e-03, PNorm = 53.5416, GNorm = 2.5290, lr_0 = 1.0804e-04
Loss = 5.4542e-03, PNorm = 53.5477, GNorm = 2.0853, lr_0 = 1.0804e-04
Loss = 4.0894e-03, PNorm = 53.5553, GNorm = 2.1612, lr_0 = 1.0804e-04
Validation rmse logD = 0.641112
Validation R2 logD = 0.721237
Epoch 14
Train function
Loss = 3.8193e-03, PNorm = 53.5649, GNorm = 1.7116, lr_0 = 1.0804e-04
Loss = 4.2594e-03, PNorm = 53.5734, GNorm = 3.5877, lr_0 = 1.0804e-04
Loss = 4.7500e-03, PNorm = 53.5834, GNorm = 4.0846, lr_0 = 1.0804e-04
Loss = 4.0618e-03, PNorm = 53.5927, GNorm = 7.8000, lr_0 = 1.0804e-04
Loss = 4.5867e-03, PNorm = 53.6008, GNorm = 2.4513, lr_0 = 1.0804e-04
Validation rmse logD = 0.627687
Validation R2 logD = 0.732790
Epoch 15
Train function
Loss = 2.2956e-03, PNorm = 53.6087, GNorm = 3.6183, lr_0 = 1.0804e-04
Loss = 3.5701e-03, PNorm = 53.6160, GNorm = 1.6973, lr_0 = 1.0804e-04
Loss = 4.0833e-03, PNorm = 53.6239, GNorm = 2.5209, lr_0 = 1.0804e-04
Loss = 4.3056e-03, PNorm = 53.6320, GNorm = 2.1727, lr_0 = 1.0804e-04
Loss = 4.4353e-03, PNorm = 53.6373, GNorm = 4.8240, lr_0 = 1.0804e-04
Loss = 4.9407e-03, PNorm = 53.6448, GNorm = 2.3041, lr_0 = 1.0804e-04
Validation rmse logD = 0.638104
Validation R2 logD = 0.723847
Epoch 16
Train function
Loss = 5.1858e-03, PNorm = 53.6550, GNorm = 4.4081, lr_0 = 1.0804e-04
Loss = 4.8585e-03, PNorm = 53.6641, GNorm = 9.3524, lr_0 = 1.0804e-04
Loss = 3.8413e-03, PNorm = 53.6735, GNorm = 7.1198, lr_0 = 1.0804e-04
Loss = 4.8789e-03, PNorm = 53.6819, GNorm = 8.8815, lr_0 = 1.0804e-04
Loss = 3.9287e-03, PNorm = 53.6900, GNorm = 2.0564, lr_0 = 1.0804e-04
Loss = 3.7553e-03, PNorm = 53.6973, GNorm = 3.4082, lr_0 = 1.0804e-04
Validation rmse logD = 0.615565
Validation R2 logD = 0.743011
Epoch 17
Train function
Loss = 3.6870e-03, PNorm = 53.7042, GNorm = 7.6245, lr_0 = 1.0804e-04
Loss = 3.8020e-03, PNorm = 53.7124, GNorm = 3.4890, lr_0 = 1.0804e-04
Loss = 3.4863e-03, PNorm = 53.7210, GNorm = 2.2644, lr_0 = 1.0804e-04
Loss = 4.6607e-03, PNorm = 53.7285, GNorm = 8.7790, lr_0 = 1.0804e-04
Loss = 4.7028e-03, PNorm = 53.7365, GNorm = 4.4832, lr_0 = 1.0804e-04
Validation rmse logD = 0.618960
Validation R2 logD = 0.740168
Epoch 18
Train function
Loss = 3.2672e-03, PNorm = 53.7449, GNorm = 2.6174, lr_0 = 1.0804e-04
Loss = 3.6460e-03, PNorm = 53.7526, GNorm = 3.6480, lr_0 = 1.0804e-04
Loss = 3.9178e-03, PNorm = 53.7580, GNorm = 7.2453, lr_0 = 1.0804e-04
Loss = 3.7926e-03, PNorm = 53.7658, GNorm = 5.5981, lr_0 = 1.0804e-04
Loss = 3.6966e-03, PNorm = 53.7747, GNorm = 8.2584, lr_0 = 1.0804e-04
Loss = 3.6445e-03, PNorm = 53.7847, GNorm = 8.8012, lr_0 = 1.0804e-04
Validation rmse logD = 0.636548
Validation R2 logD = 0.725192
Epoch 19
Train function
Loss = 4.4587e-03, PNorm = 53.7927, GNorm = 6.0757, lr_0 = 1.0804e-04
Loss = 3.4208e-03, PNorm = 53.8010, GNorm = 3.6166, lr_0 = 1.0804e-04
Loss = 3.2882e-03, PNorm = 53.8092, GNorm = 4.4004, lr_0 = 1.0804e-04
Loss = 3.7477e-03, PNorm = 53.8173, GNorm = 4.3427, lr_0 = 1.0804e-04
Loss = 3.4897e-03, PNorm = 53.8265, GNorm = 2.6669, lr_0 = 1.0804e-04
Loss = 3.3785e-03, PNorm = 53.8359, GNorm = 2.9360, lr_0 = 1.0804e-04
Validation rmse logD = 0.589023
Validation R2 logD = 0.764695
Epoch 20
Train function
Loss = 3.1465e-03, PNorm = 53.8420, GNorm = 3.7656, lr_0 = 1.0804e-04
Loss = 3.8124e-03, PNorm = 53.8486, GNorm = 7.3553, lr_0 = 1.0804e-04
Loss = 3.5776e-03, PNorm = 53.8568, GNorm = 3.6833, lr_0 = 1.0804e-04
Loss = 2.8725e-03, PNorm = 53.8642, GNorm = 4.5494, lr_0 = 1.0804e-04
Loss = 3.4830e-03, PNorm = 53.8708, GNorm = 5.1668, lr_0 = 1.0804e-04
Validation rmse logD = 0.595852
Validation R2 logD = 0.759207
Epoch 21
Train function
Loss = 1.8215e-03, PNorm = 53.8787, GNorm = 3.8692, lr_0 = 1.0804e-04
Loss = 3.2331e-03, PNorm = 53.8870, GNorm = 4.3437, lr_0 = 1.0804e-04
Loss = 2.7291e-03, PNorm = 53.8965, GNorm = 3.2169, lr_0 = 1.0804e-04
Loss = 3.1480e-03, PNorm = 53.9044, GNorm = 2.0431, lr_0 = 1.0804e-04
Loss = 3.4028e-03, PNorm = 53.9108, GNorm = 8.5127, lr_0 = 1.0804e-04
Loss = 3.6522e-03, PNorm = 53.9188, GNorm = 6.5853, lr_0 = 1.0804e-04
Validation rmse logD = 0.585849
Validation R2 logD = 0.767224
Epoch 22
Train function
Loss = 3.0212e-03, PNorm = 53.9256, GNorm = 2.9113, lr_0 = 1.0804e-04
Loss = 2.8053e-03, PNorm = 53.9335, GNorm = 1.5941, lr_0 = 1.0804e-04
Loss = 2.9418e-03, PNorm = 53.9407, GNorm = 6.5820, lr_0 = 1.0804e-04
Loss = 3.3932e-03, PNorm = 53.9499, GNorm = 6.5903, lr_0 = 1.0804e-04
Loss = 2.9765e-03, PNorm = 53.9582, GNorm = 4.9795, lr_0 = 1.0804e-04
Loss = 2.9958e-03, PNorm = 53.9653, GNorm = 4.5354, lr_0 = 1.0804e-04
Validation rmse logD = 0.578022
Validation R2 logD = 0.773402
Epoch 23
Train function
Loss = 2.6485e-03, PNorm = 53.9730, GNorm = 2.3237, lr_0 = 1.0804e-04
Loss = 2.7913e-03, PNorm = 53.9791, GNorm = 2.1465, lr_0 = 1.0804e-04
Loss = 2.7715e-03, PNorm = 53.9874, GNorm = 4.2620, lr_0 = 1.0804e-04
Loss = 2.6220e-03, PNorm = 53.9946, GNorm = 1.1706, lr_0 = 1.0804e-04
Loss = 2.6279e-03, PNorm = 54.0029, GNorm = 4.6396, lr_0 = 1.0804e-04
Validation rmse logD = 0.595604
Validation R2 logD = 0.759407
Epoch 24
Train function
Loss = 2.7544e-03, PNorm = 54.0100, GNorm = 6.5516, lr_0 = 1.0804e-04
Loss = 2.9016e-03, PNorm = 54.0177, GNorm = 5.2372, lr_0 = 1.0804e-04
Loss = 2.7158e-03, PNorm = 54.0265, GNorm = 3.7516, lr_0 = 1.0804e-04
Loss = 3.0147e-03, PNorm = 54.0341, GNorm = 5.4969, lr_0 = 1.0804e-04
Loss = 3.0452e-03, PNorm = 54.0410, GNorm = 2.3211, lr_0 = 1.0804e-04
Loss = 2.6764e-03, PNorm = 54.0478, GNorm = 2.5335, lr_0 = 1.0804e-04
Validation rmse logD = 0.576076
Validation R2 logD = 0.774925
Epoch 25
Train function
Loss = 2.4021e-03, PNorm = 54.0567, GNorm = 3.7816, lr_0 = 1.0804e-04
Loss = 2.9608e-03, PNorm = 54.0653, GNorm = 2.8780, lr_0 = 1.0804e-04
Loss = 2.4458e-03, PNorm = 54.0723, GNorm = 4.2159, lr_0 = 1.0804e-04
Loss = 2.5557e-03, PNorm = 54.0800, GNorm = 6.7261, lr_0 = 1.0804e-04
Loss = 2.3973e-03, PNorm = 54.0877, GNorm = 5.1847, lr_0 = 1.0804e-04
Loss = 3.2002e-03, PNorm = 54.0929, GNorm = 4.2231, lr_0 = 1.0804e-04
Validation rmse logD = 0.568630
Validation R2 logD = 0.780706
Epoch 26
Train function
Loss = 2.2708e-03, PNorm = 54.1009, GNorm = 1.9281, lr_0 = 1.0804e-04
Loss = 2.5040e-03, PNorm = 54.1089, GNorm = 2.1615, lr_0 = 1.0804e-04
Loss = 2.5615e-03, PNorm = 54.1157, GNorm = 4.0310, lr_0 = 1.0804e-04
Loss = 2.5170e-03, PNorm = 54.1227, GNorm = 5.3112, lr_0 = 1.0804e-04
Loss = 2.5906e-03, PNorm = 54.1310, GNorm = 1.9601, lr_0 = 1.0804e-04
Validation rmse logD = 0.576650
Validation R2 logD = 0.774477
Epoch 27
Train function
Loss = 3.3448e-03, PNorm = 54.1394, GNorm = 4.6652, lr_0 = 1.0804e-04
Loss = 2.2979e-03, PNorm = 54.1448, GNorm = 7.5517, lr_0 = 1.0804e-04
Loss = 2.0226e-03, PNorm = 54.1518, GNorm = 2.8340, lr_0 = 1.0804e-04
Loss = 2.3385e-03, PNorm = 54.1586, GNorm = 1.7180, lr_0 = 1.0804e-04
Loss = 2.1552e-03, PNorm = 54.1664, GNorm = 2.1171, lr_0 = 1.0804e-04
Loss = 2.4080e-03, PNorm = 54.1752, GNorm = 2.4747, lr_0 = 1.0804e-04
Validation rmse logD = 0.604325
Validation R2 logD = 0.752310
Epoch 28
Train function
Loss = 1.9069e-03, PNorm = 54.1816, GNorm = 6.5172, lr_0 = 1.0804e-04
Loss = 2.6188e-03, PNorm = 54.1886, GNorm = 3.4874, lr_0 = 1.0804e-04
Loss = 2.5745e-03, PNorm = 54.1947, GNorm = 2.6021, lr_0 = 1.0804e-04
Loss = 1.8382e-03, PNorm = 54.2014, GNorm = 4.0426, lr_0 = 1.0804e-04
Loss = 2.3686e-03, PNorm = 54.2074, GNorm = 2.4058, lr_0 = 1.0804e-04
Loss = 2.7234e-03, PNorm = 54.2133, GNorm = 4.5693, lr_0 = 1.0804e-04
Validation rmse logD = 0.570803
Validation R2 logD = 0.779027
Epoch 29
Train function
Loss = 1.7465e-03, PNorm = 54.2220, GNorm = 7.0637, lr_0 = 1.0804e-04
Loss = 1.9770e-03, PNorm = 54.2300, GNorm = 1.9011, lr_0 = 1.0804e-04
Loss = 2.3545e-03, PNorm = 54.2370, GNorm = 5.5691, lr_0 = 1.0804e-04
Loss = 2.0785e-03, PNorm = 54.2430, GNorm = 2.2711, lr_0 = 1.0804e-04
Loss = 2.4229e-03, PNorm = 54.2479, GNorm = 3.7827, lr_0 = 1.0804e-04
Validation rmse logD = 0.558295
Validation R2 logD = 0.788605
Epoch 30
Train function
Loss = 1.5214e-03, PNorm = 54.2558, GNorm = 1.4902, lr_0 = 1.0804e-04
Loss = 1.6890e-03, PNorm = 54.2639, GNorm = 2.3257, lr_0 = 1.0804e-04
Loss = 2.0277e-03, PNorm = 54.2703, GNorm = 7.6221, lr_0 = 1.0804e-04
Loss = 2.2927e-03, PNorm = 54.2753, GNorm = 2.0211, lr_0 = 1.0804e-04
Loss = 2.2378e-03, PNorm = 54.2826, GNorm = 6.8075, lr_0 = 1.0804e-04
Loss = 2.6618e-03, PNorm = 54.2886, GNorm = 3.6433, lr_0 = 1.0804e-04
Validation rmse logD = 0.558221
Validation R2 logD = 0.788661
Epoch 31
Train function
Loss = 1.6171e-03, PNorm = 54.2947, GNorm = 4.2792, lr_0 = 1.0804e-04
Loss = 2.4502e-03, PNorm = 54.3020, GNorm = 12.2254, lr_0 = 1.0804e-04
Loss = 2.1560e-03, PNorm = 54.3081, GNorm = 2.8746, lr_0 = 1.0804e-04
Loss = 2.1289e-03, PNorm = 54.3146, GNorm = 5.8856, lr_0 = 1.0804e-04
Loss = 2.4424e-03, PNorm = 54.3229, GNorm = 5.1829, lr_0 = 1.0804e-04
Loss = 1.8844e-03, PNorm = 54.3294, GNorm = 5.0506, lr_0 = 1.0804e-04
Validation rmse logD = 0.548882
Validation R2 logD = 0.795673
Epoch 32
Train function
Loss = 1.8707e-03, PNorm = 54.3357, GNorm = 2.4637, lr_0 = 1.0804e-04
Loss = 1.6519e-03, PNorm = 54.3424, GNorm = 1.7643, lr_0 = 1.0804e-04
Loss = 1.8022e-03, PNorm = 54.3481, GNorm = 2.2654, lr_0 = 1.0804e-04
Loss = 1.9042e-03, PNorm = 54.3564, GNorm = 1.7430, lr_0 = 1.0804e-04
Loss = 1.7914e-03, PNorm = 54.3612, GNorm = 4.9622, lr_0 = 1.0804e-04
Validation rmse logD = 0.579497
Validation R2 logD = 0.772244
Epoch 33
Train function
Loss = 1.2663e-03, PNorm = 54.3675, GNorm = 3.5141, lr_0 = 1.0804e-04
Loss = 1.6733e-03, PNorm = 54.3727, GNorm = 3.7520, lr_0 = 1.0804e-04
Loss = 1.9130e-03, PNorm = 54.3792, GNorm = 3.9147, lr_0 = 1.0804e-04
Loss = 2.1304e-03, PNorm = 54.3858, GNorm = 6.9984, lr_0 = 1.0804e-04
Loss = 1.8453e-03, PNorm = 54.3906, GNorm = 1.8185, lr_0 = 1.0804e-04
Loss = 1.7060e-03, PNorm = 54.3964, GNorm = 2.1018, lr_0 = 1.0804e-04
Validation rmse logD = 0.548848
Validation R2 logD = 0.795698
Epoch 34
Train function
Loss = 1.3698e-03, PNorm = 54.4035, GNorm = 3.5721, lr_0 = 1.0804e-04
Loss = 1.2943e-03, PNorm = 54.4114, GNorm = 2.8062, lr_0 = 1.0804e-04
Loss = 2.0948e-03, PNorm = 54.4163, GNorm = 8.9216, lr_0 = 1.0804e-04
Loss = 1.8720e-03, PNorm = 54.4221, GNorm = 1.5889, lr_0 = 1.0804e-04
Loss = 2.2017e-03, PNorm = 54.4276, GNorm = 5.2120, lr_0 = 1.0804e-04
Loss = 1.9160e-03, PNorm = 54.4325, GNorm = 5.2343, lr_0 = 1.0804e-04
Validation rmse logD = 0.569963
Validation R2 logD = 0.779676
Epoch 35
Train function
Loss = 1.9063e-03, PNorm = 54.4376, GNorm = 1.6503, lr_0 = 1.0804e-04
Loss = 1.7394e-03, PNorm = 54.4447, GNorm = 1.9896, lr_0 = 1.0804e-04
Loss = 1.6956e-03, PNorm = 54.4513, GNorm = 9.0088, lr_0 = 1.0804e-04
Loss = 1.7338e-03, PNorm = 54.4563, GNorm = 2.7259, lr_0 = 1.0804e-04
Loss = 1.6439e-03, PNorm = 54.4626, GNorm = 1.7159, lr_0 = 1.0804e-04
Validation rmse logD = 0.559108
Validation R2 logD = 0.787989
Epoch 36
Train function
Loss = 1.4505e-03, PNorm = 54.4701, GNorm = 1.9811, lr_0 = 1.0804e-04
Loss = 1.5784e-03, PNorm = 54.4763, GNorm = 3.7397, lr_0 = 1.0804e-04
Loss = 1.9825e-03, PNorm = 54.4821, GNorm = 6.8881, lr_0 = 1.0804e-04
Loss = 1.8065e-03, PNorm = 54.4889, GNorm = 2.0148, lr_0 = 1.0804e-04
Loss = 1.4129e-03, PNorm = 54.4958, GNorm = 8.3590, lr_0 = 1.0804e-04
Loss = 1.5112e-03, PNorm = 54.5004, GNorm = 3.5466, lr_0 = 1.0804e-04
Validation rmse logD = 0.551327
Validation R2 logD = 0.793849
Epoch 37
Train function
Loss = 1.4539e-03, PNorm = 54.5082, GNorm = 1.7163, lr_0 = 1.0804e-04
Loss = 1.3872e-03, PNorm = 54.5134, GNorm = 2.7236, lr_0 = 1.0804e-04
Loss = 1.3661e-03, PNorm = 54.5186, GNorm = 4.7420, lr_0 = 1.0804e-04
Loss = 1.3244e-03, PNorm = 54.5256, GNorm = 3.3768, lr_0 = 1.0804e-04
Loss = 1.8992e-03, PNorm = 54.5308, GNorm = 1.4687, lr_0 = 1.0804e-04
Loss = 1.4339e-03, PNorm = 54.5354, GNorm = 1.3299, lr_0 = 1.0804e-04
Validation rmse logD = 0.566870
Validation R2 logD = 0.782061
Epoch 38
Train function
Loss = 1.4944e-03, PNorm = 54.5417, GNorm = 6.6626, lr_0 = 1.0804e-04
Loss = 1.4247e-03, PNorm = 54.5462, GNorm = 1.5827, lr_0 = 1.0804e-04
Loss = 1.4333e-03, PNorm = 54.5522, GNorm = 1.5417, lr_0 = 1.0804e-04
Loss = 1.5479e-03, PNorm = 54.5582, GNorm = 6.0958, lr_0 = 1.0804e-04
Loss = 1.9370e-03, PNorm = 54.5622, GNorm = 4.6927, lr_0 = 1.0804e-04
Validation rmse logD = 0.559551
Validation R2 logD = 0.787653
Epoch 39
Train function
Loss = 1.0804e-03, PNorm = 54.5710, GNorm = 2.3756, lr_0 = 1.0804e-04
Loss = 1.2327e-03, PNorm = 54.5770, GNorm = 5.5349, lr_0 = 1.0804e-04
Loss = 1.1941e-03, PNorm = 54.5820, GNorm = 1.7700, lr_0 = 1.0804e-04
Loss = 1.5586e-03, PNorm = 54.5881, GNorm = 6.8615, lr_0 = 1.0804e-04
Loss = 1.9119e-03, PNorm = 54.5923, GNorm = 5.6151, lr_0 = 1.0804e-04
Loss = 1.5667e-03, PNorm = 54.5983, GNorm = 1.9200, lr_0 = 1.0804e-04
Validation rmse logD = 0.547711
Validation R2 logD = 0.796544
Epoch 40
Train function
Loss = 1.2695e-03, PNorm = 54.6046, GNorm = 1.6753, lr_0 = 1.0804e-04
Loss = 1.2836e-03, PNorm = 54.6113, GNorm = 1.6694, lr_0 = 1.0804e-04
Loss = 1.3997e-03, PNorm = 54.6168, GNorm = 5.6684, lr_0 = 1.0804e-04
Loss = 1.4327e-03, PNorm = 54.6201, GNorm = 1.8146, lr_0 = 1.0804e-04
Loss = 1.4108e-03, PNorm = 54.6266, GNorm = 3.3098, lr_0 = 1.0804e-04
Loss = 1.8390e-03, PNorm = 54.6319, GNorm = 2.7820, lr_0 = 1.0804e-04
Validation rmse logD = 0.554433
Validation R2 logD = 0.791520
Epoch 41
Train function
Loss = 1.0415e-03, PNorm = 54.6387, GNorm = 3.3208, lr_0 = 1.0804e-04
Loss = 1.3811e-03, PNorm = 54.6433, GNorm = 2.4526, lr_0 = 1.0804e-04
Loss = 1.5833e-03, PNorm = 54.6494, GNorm = 1.9550, lr_0 = 1.0804e-04
Loss = 1.0351e-03, PNorm = 54.6542, GNorm = 1.5618, lr_0 = 1.0804e-04
Loss = 9.6037e-04, PNorm = 54.6596, GNorm = 1.9013, lr_0 = 1.0804e-04
Validation rmse logD = 0.589436
Validation R2 logD = 0.764365
Epoch 42
Train function
Loss = 1.1240e-03, PNorm = 54.6653, GNorm = 4.3196, lr_0 = 1.0804e-04
Loss = 1.4811e-03, PNorm = 54.6700, GNorm = 2.0650, lr_0 = 1.0804e-04
Loss = 1.1481e-03, PNorm = 54.6774, GNorm = 1.9481, lr_0 = 1.0804e-04
Loss = 1.4969e-03, PNorm = 54.6827, GNorm = 2.1479, lr_0 = 1.0804e-04
Loss = 1.1587e-03, PNorm = 54.6883, GNorm = 2.5779, lr_0 = 1.0804e-04
Loss = 1.2680e-03, PNorm = 54.6941, GNorm = 1.7032, lr_0 = 1.0804e-04
Validation rmse logD = 0.534391
Validation R2 logD = 0.806320
Epoch 43
Train function
Loss = 1.1093e-03, PNorm = 54.6977, GNorm = 3.0605, lr_0 = 1.0804e-04
Loss = 1.2884e-03, PNorm = 54.7019, GNorm = 2.0140, lr_0 = 1.0804e-04
Loss = 1.2419e-03, PNorm = 54.7077, GNorm = 4.5541, lr_0 = 1.0804e-04
Loss = 1.0952e-03, PNorm = 54.7125, GNorm = 1.7692, lr_0 = 1.0804e-04
Loss = 1.2551e-03, PNorm = 54.7173, GNorm = 1.4324, lr_0 = 1.0804e-04
Loss = 1.1652e-03, PNorm = 54.7225, GNorm = 1.3351, lr_0 = 1.0804e-04
Validation rmse logD = 0.539089
Validation R2 logD = 0.802900
Epoch 44
Train function
Loss = 1.0476e-03, PNorm = 54.7271, GNorm = 3.0847, lr_0 = 1.0804e-04
Loss = 1.0539e-03, PNorm = 54.7318, GNorm = 1.4052, lr_0 = 1.0804e-04
Loss = 9.6301e-04, PNorm = 54.7366, GNorm = 4.7589, lr_0 = 1.0804e-04
Loss = 1.0470e-03, PNorm = 54.7412, GNorm = 3.2911, lr_0 = 1.0804e-04
Loss = 1.2814e-03, PNorm = 54.7453, GNorm = 5.9488, lr_0 = 1.0804e-04
Validation rmse logD = 0.558906
Validation R2 logD = 0.788142
Epoch 45
Train function
Loss = 9.3122e-04, PNorm = 54.7502, GNorm = 2.1630, lr_0 = 1.0804e-04
Loss = 9.6090e-04, PNorm = 54.7556, GNorm = 1.1134, lr_0 = 1.0804e-04
Loss = 1.0222e-03, PNorm = 54.7608, GNorm = 2.8811, lr_0 = 1.0804e-04
Loss = 1.0378e-03, PNorm = 54.7645, GNorm = 2.7944, lr_0 = 1.0804e-04
Loss = 1.1003e-03, PNorm = 54.7698, GNorm = 3.9073, lr_0 = 1.0804e-04
Loss = 1.3042e-03, PNorm = 54.7749, GNorm = 1.9120, lr_0 = 1.0804e-04
Validation rmse logD = 0.557615
Validation R2 logD = 0.789120
Epoch 46
Train function
Loss = 1.2836e-03, PNorm = 54.7800, GNorm = 6.5745, lr_0 = 1.0804e-04
Loss = 1.0912e-03, PNorm = 54.7847, GNorm = 4.1095, lr_0 = 1.0804e-04
Loss = 1.5003e-03, PNorm = 54.7902, GNorm = 2.3537, lr_0 = 1.0804e-04
Loss = 9.8866e-04, PNorm = 54.7968, GNorm = 2.4296, lr_0 = 1.0804e-04
Loss = 1.1871e-03, PNorm = 54.8023, GNorm = 4.2051, lr_0 = 1.0804e-04
Loss = 1.1191e-03, PNorm = 54.8072, GNorm = 2.0506, lr_0 = 1.0804e-04
Validation rmse logD = 0.545139
Validation R2 logD = 0.798450
Epoch 47
Train function
Loss = 8.5934e-04, PNorm = 54.8112, GNorm = 2.5473, lr_0 = 1.0804e-04
Loss = 1.0174e-03, PNorm = 54.8160, GNorm = 4.1187, lr_0 = 1.0804e-04
Loss = 1.1408e-03, PNorm = 54.8197, GNorm = 4.4259, lr_0 = 1.0804e-04
Loss = 1.0289e-03, PNorm = 54.8242, GNorm = 2.0271, lr_0 = 1.0804e-04
Loss = 1.2674e-03, PNorm = 54.8288, GNorm = 6.5678, lr_0 = 1.0804e-04
Validation rmse logD = 0.538599
Validation R2 logD = 0.803257
Epoch 48
Train function
Loss = 7.5893e-04, PNorm = 54.8343, GNorm = 1.6485, lr_0 = 1.0804e-04
Loss = 1.1836e-03, PNorm = 54.8390, GNorm = 6.2934, lr_0 = 1.0804e-04
Loss = 1.3567e-03, PNorm = 54.8447, GNorm = 3.6952, lr_0 = 1.0804e-04
Loss = 1.0015e-03, PNorm = 54.8510, GNorm = 2.4652, lr_0 = 1.0804e-04
Loss = 8.2598e-04, PNorm = 54.8576, GNorm = 1.3939, lr_0 = 1.0804e-04
Loss = 8.5597e-04, PNorm = 54.8620, GNorm = 2.8565, lr_0 = 1.0804e-04
Validation rmse logD = 0.563329
Validation R2 logD = 0.784775
Epoch 49
Train function
Loss = 1.1295e-03, PNorm = 54.8674, GNorm = 1.0651, lr_0 = 1.0804e-04
Loss = 9.2386e-04, PNorm = 54.8721, GNorm = 1.5389, lr_0 = 1.0804e-04
Loss = 8.1316e-04, PNorm = 54.8764, GNorm = 2.9088, lr_0 = 1.0804e-04
Loss = 1.0522e-03, PNorm = 54.8807, GNorm = 6.3397, lr_0 = 1.0804e-04
Loss = 8.3168e-04, PNorm = 54.8831, GNorm = 1.8551, lr_0 = 1.0804e-04
Loss = 1.1642e-03, PNorm = 54.8882, GNorm = 6.0398, lr_0 = 1.0804e-04
Validation rmse logD = 0.565403
Validation R2 logD = 0.783188
Epoch 50
Train function
Loss = 1.1456e-03, PNorm = 54.8918, GNorm = 2.4527, lr_0 = 1.0804e-04
Loss = 9.6406e-04, PNorm = 54.8965, GNorm = 1.3596, lr_0 = 1.0804e-04
Loss = 1.1594e-03, PNorm = 54.9027, GNorm = 8.0477, lr_0 = 1.0804e-04
Loss = 1.1151e-03, PNorm = 54.9080, GNorm = 4.1013, lr_0 = 1.0804e-04
Loss = 1.0936e-03, PNorm = 54.9126, GNorm = 3.3608, lr_0 = 1.0804e-04
Validation rmse logD = 0.525908
Validation R2 logD = 0.812420
Epoch 51
Train function
Loss = 6.2624e-04, PNorm = 54.9175, GNorm = 1.2658, lr_0 = 1.0804e-04
Loss = 7.0264e-04, PNorm = 54.9227, GNorm = 1.6197, lr_0 = 1.0804e-04
Loss = 7.4786e-04, PNorm = 54.9267, GNorm = 4.8289, lr_0 = 1.0804e-04
Loss = 9.9773e-04, PNorm = 54.9317, GNorm = 1.2129, lr_0 = 1.0804e-04
Loss = 8.4554e-04, PNorm = 54.9371, GNorm = 1.6411, lr_0 = 1.0804e-04
Loss = 1.0472e-03, PNorm = 54.9412, GNorm = 1.3753, lr_0 = 1.0804e-04
Validation rmse logD = 0.573109
Validation R2 logD = 0.777237
Epoch 52
Train function
Loss = 1.4497e-03, PNorm = 54.9446, GNorm = 1.2727, lr_0 = 1.0804e-04
Loss = 1.1942e-03, PNorm = 54.9490, GNorm = 4.8027, lr_0 = 1.0804e-04
Loss = 1.3738e-03, PNorm = 54.9547, GNorm = 8.3414, lr_0 = 1.0804e-04
Loss = 1.5586e-03, PNorm = 54.9591, GNorm = 6.3517, lr_0 = 1.0804e-04
Loss = 1.3202e-03, PNorm = 54.9633, GNorm = 1.8666, lr_0 = 1.0804e-04
Loss = 1.0065e-03, PNorm = 54.9703, GNorm = 5.1962, lr_0 = 1.0804e-04
Validation rmse logD = 0.535001
Validation R2 logD = 0.805877
Epoch 53
Train function
Loss = 7.6553e-04, PNorm = 54.9764, GNorm = 2.9975, lr_0 = 1.0804e-04
Loss = 1.1365e-03, PNorm = 54.9812, GNorm = 3.8806, lr_0 = 1.0804e-04
Loss = 1.0008e-03, PNorm = 54.9854, GNorm = 1.9908, lr_0 = 1.0804e-04
Loss = 1.1062e-03, PNorm = 54.9906, GNorm = 7.1033, lr_0 = 1.0804e-04
Loss = 8.7911e-04, PNorm = 54.9941, GNorm = 1.3858, lr_0 = 1.0804e-04
Validation rmse logD = 0.529003
Validation R2 logD = 0.810206
Epoch 54
Train function
Loss = 6.0205e-04, PNorm = 54.9991, GNorm = 2.1286, lr_0 = 1.0804e-04
Loss = 7.7718e-04, PNorm = 55.0048, GNorm = 1.7194, lr_0 = 1.0804e-04
Loss = 7.8176e-04, PNorm = 55.0098, GNorm = 1.1547, lr_0 = 1.0804e-04
Loss = 9.4543e-04, PNorm = 55.0142, GNorm = 6.5613, lr_0 = 1.0804e-04
Loss = 7.8394e-04, PNorm = 55.0178, GNorm = 0.9248, lr_0 = 1.0804e-04
Loss = 7.7846e-04, PNorm = 55.0221, GNorm = 2.3424, lr_0 = 1.0804e-04
Validation rmse logD = 0.527880
Validation R2 logD = 0.811011
Epoch 55
Train function
Loss = 7.0225e-04, PNorm = 55.0261, GNorm = 2.8118, lr_0 = 1.0804e-04
Loss = 8.0262e-04, PNorm = 55.0306, GNorm = 4.8386, lr_0 = 1.0804e-04
Loss = 9.6906e-04, PNorm = 55.0336, GNorm = 6.5176, lr_0 = 1.0804e-04
Loss = 9.1608e-04, PNorm = 55.0376, GNorm = 1.0594, lr_0 = 1.0804e-04
Loss = 7.5692e-04, PNorm = 55.0416, GNorm = 3.5354, lr_0 = 1.0804e-04
Loss = 1.0124e-03, PNorm = 55.0451, GNorm = 1.7447, lr_0 = 1.0804e-04
Validation rmse logD = 0.533170
Validation R2 logD = 0.807204
Epoch 56
Train function
Loss = 6.0931e-04, PNorm = 55.0510, GNorm = 1.2140, lr_0 = 1.0804e-04
Loss = 7.3455e-04, PNorm = 55.0552, GNorm = 2.0629, lr_0 = 1.0804e-04
Loss = 8.7456e-04, PNorm = 55.0595, GNorm = 1.3842, lr_0 = 1.0804e-04
Loss = 8.5914e-04, PNorm = 55.0631, GNorm = 4.2983, lr_0 = 1.0804e-04
Loss = 7.6957e-04, PNorm = 55.0662, GNorm = 4.8153, lr_0 = 1.0804e-04
Validation rmse logD = 0.526528
Validation R2 logD = 0.811977
Epoch 57
Train function
Loss = 5.2742e-04, PNorm = 55.0701, GNorm = 0.9688, lr_0 = 1.0804e-04
Loss = 9.5908e-04, PNorm = 55.0725, GNorm = 4.9698, lr_0 = 1.0804e-04
Loss = 8.9290e-04, PNorm = 55.0766, GNorm = 4.7404, lr_0 = 1.0804e-04
Loss = 9.3419e-04, PNorm = 55.0822, GNorm = 5.4686, lr_0 = 1.0804e-04
Loss = 7.2147e-04, PNorm = 55.0867, GNorm = 1.2456, lr_0 = 1.0804e-04
Loss = 7.2395e-04, PNorm = 55.0907, GNorm = 3.4022, lr_0 = 1.0804e-04
Validation rmse logD = 0.580683
Validation R2 logD = 0.771311
Epoch 58
Train function
Loss = 8.4359e-04, PNorm = 55.0953, GNorm = 4.7543, lr_0 = 1.0804e-04
Loss = 7.5588e-04, PNorm = 55.1003, GNorm = 2.0958, lr_0 = 1.0804e-04
Loss = 5.9927e-04, PNorm = 55.1050, GNorm = 1.3362, lr_0 = 1.0804e-04
Loss = 9.8287e-04, PNorm = 55.1092, GNorm = 1.5010, lr_0 = 1.0804e-04
Loss = 6.0730e-04, PNorm = 55.1136, GNorm = 3.8863, lr_0 = 1.0804e-04
Loss = 8.1508e-04, PNorm = 55.1168, GNorm = 1.2012, lr_0 = 1.0804e-04
Validation rmse logD = 0.534447
Validation R2 logD = 0.806279
Epoch 59
Train function
Loss = 5.7846e-04, PNorm = 55.1206, GNorm = 1.6561, lr_0 = 1.0804e-04
Loss = 5.3563e-04, PNorm = 55.1253, GNorm = 1.1606, lr_0 = 1.0804e-04
Loss = 7.4578e-04, PNorm = 55.1273, GNorm = 4.3247, lr_0 = 1.0804e-04
Loss = 6.9836e-04, PNorm = 55.1305, GNorm = 1.2013, lr_0 = 1.0804e-04
Loss = 6.1356e-04, PNorm = 55.1350, GNorm = 2.1234, lr_0 = 1.0804e-04
Validation rmse logD = 0.544142
Validation R2 logD = 0.799187
Epoch 60
Train function
Loss = 6.2404e-04, PNorm = 55.1379, GNorm = 1.1621, lr_0 = 1.0804e-04
Loss = 5.5470e-04, PNorm = 55.1416, GNorm = 2.0157, lr_0 = 1.0804e-04
Loss = 6.8209e-04, PNorm = 55.1454, GNorm = 5.8614, lr_0 = 1.0804e-04
Loss = 9.4775e-04, PNorm = 55.1480, GNorm = 5.7393, lr_0 = 1.0804e-04
Loss = 8.5395e-04, PNorm = 55.1517, GNorm = 2.5348, lr_0 = 1.0804e-04
Loss = 7.5662e-04, PNorm = 55.1564, GNorm = 2.0154, lr_0 = 1.0804e-04
Validation rmse logD = 0.521630
Validation R2 logD = 0.815459
Epoch 61
Train function
Loss = 1.0167e-03, PNorm = 55.1614, GNorm = 5.5507, lr_0 = 1.0804e-04
Loss = 7.0067e-04, PNorm = 55.1650, GNorm = 5.6700, lr_0 = 1.0804e-04
Loss = 5.8945e-04, PNorm = 55.1690, GNorm = 1.4748, lr_0 = 1.0804e-04
Loss = 5.8750e-04, PNorm = 55.1724, GNorm = 3.1793, lr_0 = 1.0804e-04
Loss = 5.9729e-04, PNorm = 55.1756, GNorm = 1.3462, lr_0 = 1.0804e-04
Loss = 6.4942e-04, PNorm = 55.1798, GNorm = 0.7603, lr_0 = 1.0804e-04
Validation rmse logD = 0.537483
Validation R2 logD = 0.804072
Epoch 62
Train function
Loss = 7.3284e-04, PNorm = 55.1833, GNorm = 3.2025, lr_0 = 1.0804e-04
Loss = 4.7393e-04, PNorm = 55.1867, GNorm = 1.8292, lr_0 = 1.0804e-04
Loss = 6.3396e-04, PNorm = 55.1914, GNorm = 1.4689, lr_0 = 1.0804e-04
Loss = 5.0907e-04, PNorm = 55.1950, GNorm = 1.0804, lr_0 = 1.0804e-04
Loss = 7.4187e-04, PNorm = 55.1988, GNorm = 4.4197, lr_0 = 1.0804e-04
Validation rmse logD = 0.564704
Validation R2 logD = 0.783724
Epoch 63
Train function
Loss = 7.5139e-04, PNorm = 55.2025, GNorm = 5.6208, lr_0 = 1.0804e-04
Loss = 6.9803e-04, PNorm = 55.2056, GNorm = 2.9235, lr_0 = 1.0804e-04
Loss = 6.9382e-04, PNorm = 55.2087, GNorm = 1.0048, lr_0 = 1.0804e-04
Loss = 7.0725e-04, PNorm = 55.2128, GNorm = 1.0069, lr_0 = 1.0804e-04
Loss = 6.0789e-04, PNorm = 55.2173, GNorm = 2.4878, lr_0 = 1.0804e-04
Loss = 9.6662e-04, PNorm = 55.2206, GNorm = 6.5397, lr_0 = 1.0804e-04
Validation rmse logD = 0.533154
Validation R2 logD = 0.807215
Epoch 64
Train function
Loss = 6.8329e-04, PNorm = 55.2261, GNorm = 1.2147, lr_0 = 1.0804e-04
Loss = 5.6643e-04, PNorm = 55.2320, GNorm = 1.8427, lr_0 = 1.0804e-04
Loss = 7.0907e-04, PNorm = 55.2370, GNorm = 5.2209, lr_0 = 1.0804e-04
Loss = 5.6738e-04, PNorm = 55.2400, GNorm = 0.7687, lr_0 = 1.0804e-04
Loss = 5.1842e-04, PNorm = 55.2430, GNorm = 2.3041, lr_0 = 1.0804e-04
Loss = 5.4838e-04, PNorm = 55.2461, GNorm = 4.3912, lr_0 = 1.0804e-04
Validation rmse logD = 0.534511
Validation R2 logD = 0.806233
Epoch 65
Train function
Loss = 6.5685e-04, PNorm = 55.2500, GNorm = 5.2986, lr_0 = 1.0804e-04
Loss = 6.7282e-04, PNorm = 55.2537, GNorm = 4.3664, lr_0 = 1.0804e-04
Loss = 7.6497e-04, PNorm = 55.2581, GNorm = 4.6457, lr_0 = 1.0804e-04
Loss = 8.9113e-04, PNorm = 55.2624, GNorm = 6.3999, lr_0 = 1.0804e-04
Loss = 9.1626e-04, PNorm = 55.2661, GNorm = 2.9768, lr_0 = 1.0804e-04
Validation rmse logD = 0.547273
Validation R2 logD = 0.796869
Epoch 66
Train function
Loss = 1.0529e-03, PNorm = 55.2703, GNorm = 6.2015, lr_0 = 1.0804e-04
Loss = 8.3234e-04, PNorm = 55.2743, GNorm = 5.0003, lr_0 = 1.0804e-04
Loss = 6.9441e-04, PNorm = 55.2785, GNorm = 1.3841, lr_0 = 1.0804e-04
Loss = 7.8039e-04, PNorm = 55.2825, GNorm = 1.1416, lr_0 = 1.0804e-04
Loss = 7.0255e-04, PNorm = 55.2842, GNorm = 1.4406, lr_0 = 1.0804e-04
Loss = 5.7906e-04, PNorm = 55.2877, GNorm = 3.3941, lr_0 = 1.0804e-04
Validation rmse logD = 0.537132
Validation R2 logD = 0.804327
Epoch 67
Train function
Loss = 5.9434e-04, PNorm = 55.2921, GNorm = 1.1182, lr_0 = 1.0804e-04
Loss = 4.4613e-04, PNorm = 55.2966, GNorm = 1.4353, lr_0 = 1.0804e-04
Loss = 6.4898e-04, PNorm = 55.2996, GNorm = 3.4214, lr_0 = 1.0804e-04
Loss = 6.6214e-04, PNorm = 55.3031, GNorm = 2.3013, lr_0 = 1.0804e-04
Loss = 5.3799e-04, PNorm = 55.3058, GNorm = 1.3835, lr_0 = 1.0804e-04
Loss = 5.7538e-04, PNorm = 55.3097, GNorm = 5.5335, lr_0 = 1.0804e-04
Validation rmse logD = 0.527706
Validation R2 logD = 0.811135
Epoch 68
Train function
Loss = 6.4468e-04, PNorm = 55.3135, GNorm = 2.3922, lr_0 = 1.0804e-04
Loss = 8.5448e-04, PNorm = 55.3149, GNorm = 2.7202, lr_0 = 1.0804e-04
Loss = 7.5073e-04, PNorm = 55.3190, GNorm = 3.6312, lr_0 = 1.0804e-04
Loss = 7.5621e-04, PNorm = 55.3238, GNorm = 2.0418, lr_0 = 1.0804e-04
Loss = 7.2218e-04, PNorm = 55.3275, GNorm = 5.9646, lr_0 = 1.0804e-04
Validation rmse logD = 0.538176
Validation R2 logD = 0.803566
Epoch 69
Train function
Loss = 5.4606e-04, PNorm = 55.3327, GNorm = 3.2620, lr_0 = 1.0804e-04
Loss = 4.6355e-04, PNorm = 55.3374, GNorm = 1.9617, lr_0 = 1.0804e-04
Loss = 5.9507e-04, PNorm = 55.3410, GNorm = 1.7681, lr_0 = 1.0804e-04
Loss = 4.8207e-04, PNorm = 55.3445, GNorm = 2.6744, lr_0 = 1.0804e-04
Loss = 5.9836e-04, PNorm = 55.3482, GNorm = 2.4841, lr_0 = 1.0804e-04
Loss = 4.4092e-04, PNorm = 55.3511, GNorm = 1.3026, lr_0 = 1.0804e-04
Validation rmse logD = 0.531999
Validation R2 logD = 0.808050
Epoch 70
Train function
Loss = 3.7842e-04, PNorm = 55.3539, GNorm = 1.2208, lr_0 = 1.0804e-04
Loss = 4.5298e-04, PNorm = 55.3574, GNorm = 1.1837, lr_0 = 1.0804e-04
Loss = 6.7679e-04, PNorm = 55.3608, GNorm = 2.4891, lr_0 = 1.0804e-04
Loss = 4.5649e-04, PNorm = 55.3646, GNorm = 2.7411, lr_0 = 1.0804e-04
Loss = 4.5154e-04, PNorm = 55.3673, GNorm = 0.7971, lr_0 = 1.0804e-04
Loss = 4.1786e-04, PNorm = 55.3704, GNorm = 0.6958, lr_0 = 1.0804e-04
Validation rmse logD = 0.532299
Validation R2 logD = 0.807833
Epoch 71
Train function
Loss = 3.9475e-04, PNorm = 55.3743, GNorm = 1.6506, lr_0 = 1.0804e-04
Loss = 3.9298e-04, PNorm = 55.3776, GNorm = 0.8950, lr_0 = 1.0804e-04
Loss = 4.6031e-04, PNorm = 55.3796, GNorm = 2.0409, lr_0 = 1.0804e-04
Loss = 5.3518e-04, PNorm = 55.3830, GNorm = 2.8705, lr_0 = 1.0804e-04
Loss = 7.6167e-04, PNorm = 55.3844, GNorm = 1.8146, lr_0 = 1.0804e-04
Validation rmse logD = 0.528353
Validation R2 logD = 0.810672
Epoch 72
Train function
Loss = 4.0821e-04, PNorm = 55.3885, GNorm = 0.9541, lr_0 = 1.0804e-04
Loss = 5.5307e-04, PNorm = 55.3921, GNorm = 0.7790, lr_0 = 1.0804e-04
Loss = 5.6733e-04, PNorm = 55.3949, GNorm = 5.1541, lr_0 = 1.0804e-04
Loss = 7.7746e-04, PNorm = 55.3989, GNorm = 5.5673, lr_0 = 1.0804e-04
Loss = 8.4452e-04, PNorm = 55.4028, GNorm = 4.0366, lr_0 = 1.0804e-04
Loss = 9.5043e-04, PNorm = 55.4083, GNorm = 1.0757, lr_0 = 1.0804e-04
Validation rmse logD = 0.525131
Validation R2 logD = 0.812974
Epoch 73
Train function
Loss = 6.6729e-04, PNorm = 55.4127, GNorm = 2.6436, lr_0 = 1.0804e-04
Loss = 6.2940e-04, PNorm = 55.4179, GNorm = 4.4701, lr_0 = 1.0804e-04
Loss = 8.0178e-04, PNorm = 55.4211, GNorm = 5.1244, lr_0 = 1.0804e-04
Loss = 6.3515e-04, PNorm = 55.4234, GNorm = 1.5961, lr_0 = 1.0804e-04
Loss = 6.0100e-04, PNorm = 55.4279, GNorm = 1.0730, lr_0 = 1.0804e-04
Loss = 5.2418e-04, PNorm = 55.4320, GNorm = 3.6470, lr_0 = 1.0804e-04
Validation rmse logD = 0.532503
Validation R2 logD = 0.807686
Epoch 74
Train function
Loss = 3.7698e-04, PNorm = 55.4350, GNorm = 1.9525, lr_0 = 1.0804e-04
Loss = 3.4485e-04, PNorm = 55.4380, GNorm = 3.5699, lr_0 = 1.0804e-04
Loss = 4.2739e-04, PNorm = 55.4410, GNorm = 2.1491, lr_0 = 1.0804e-04
Loss = 3.3825e-04, PNorm = 55.4437, GNorm = 0.9162, lr_0 = 1.0804e-04
Loss = 5.8486e-04, PNorm = 55.4484, GNorm = 0.8221, lr_0 = 1.0804e-04
Validation rmse logD = 0.528506
Validation R2 logD = 0.810562
Epoch 75
Train function
Loss = 3.9262e-04, PNorm = 55.4517, GNorm = 1.1180, lr_0 = 1.0804e-04
Loss = 5.1063e-04, PNorm = 55.4556, GNorm = 1.2929, lr_0 = 1.0804e-04
Loss = 4.5850e-04, PNorm = 55.4572, GNorm = 2.7269, lr_0 = 1.0804e-04
Loss = 4.0679e-04, PNorm = 55.4607, GNorm = 0.7068, lr_0 = 1.0804e-04
Loss = 3.9426e-04, PNorm = 55.4636, GNorm = 1.0653, lr_0 = 1.0804e-04
Loss = 3.9836e-04, PNorm = 55.4665, GNorm = 3.3626, lr_0 = 1.0804e-04
Validation rmse logD = 0.533999
Validation R2 logD = 0.806604
Epoch 76
Train function
Loss = 6.1753e-04, PNorm = 55.4682, GNorm = 1.6155, lr_0 = 1.0804e-04
Loss = 3.9311e-04, PNorm = 55.4714, GNorm = 1.1120, lr_0 = 1.0804e-04
Loss = 5.6635e-04, PNorm = 55.4752, GNorm = 3.8503, lr_0 = 1.0804e-04
Loss = 7.3618e-04, PNorm = 55.4784, GNorm = 1.3871, lr_0 = 1.0804e-04
Loss = 5.2122e-04, PNorm = 55.4835, GNorm = 1.2655, lr_0 = 1.0804e-04
Loss = 4.8470e-04, PNorm = 55.4885, GNorm = 0.9517, lr_0 = 1.0804e-04
Validation rmse logD = 0.522013
Validation R2 logD = 0.815188
Epoch 77
Train function
Loss = 3.0621e-04, PNorm = 55.4922, GNorm = 2.2490, lr_0 = 1.0804e-04
Loss = 5.3528e-04, PNorm = 55.4945, GNorm = 3.4625, lr_0 = 1.0804e-04
Loss = 5.0803e-04, PNorm = 55.4976, GNorm = 3.2608, lr_0 = 1.0804e-04
Loss = 5.9698e-04, PNorm = 55.4997, GNorm = 0.7674, lr_0 = 1.0804e-04
Loss = 6.9560e-04, PNorm = 55.5028, GNorm = 1.8344, lr_0 = 1.0804e-04
Validation rmse logD = 0.526622
Validation R2 logD = 0.811910
Epoch 78
Train function
Loss = 3.8619e-04, PNorm = 55.5066, GNorm = 1.1619, lr_0 = 1.0804e-04
Loss = 4.5656e-04, PNorm = 55.5106, GNorm = 4.1910, lr_0 = 1.0804e-04
Loss = 3.8935e-04, PNorm = 55.5145, GNorm = 1.0068, lr_0 = 1.0804e-04
Loss = 4.6742e-04, PNorm = 55.5159, GNorm = 1.4444, lr_0 = 1.0804e-04
Loss = 4.4870e-04, PNorm = 55.5180, GNorm = 3.1434, lr_0 = 1.0804e-04
Loss = 4.8441e-04, PNorm = 55.5220, GNorm = 0.7768, lr_0 = 1.0804e-04
Validation rmse logD = 0.521042
Validation R2 logD = 0.815875
Epoch 79
Train function
Loss = 1.7482e-04, PNorm = 55.5253, GNorm = 0.7209, lr_0 = 1.0804e-04
Loss = 3.8639e-04, PNorm = 55.5286, GNorm = 0.6711, lr_0 = 1.0804e-04
Loss = 5.2515e-04, PNorm = 55.5312, GNorm = 3.4776, lr_0 = 1.0804e-04
Loss = 5.0542e-04, PNorm = 55.5339, GNorm = 2.8236, lr_0 = 1.0804e-04
Loss = 4.2102e-04, PNorm = 55.5370, GNorm = 0.9727, lr_0 = 1.0804e-04
Loss = 5.5465e-04, PNorm = 55.5393, GNorm = 2.6181, lr_0 = 1.0804e-04
Validation rmse logD = 0.522426
Validation R2 logD = 0.814896
Epoch 80
Train function
Loss = 3.7909e-04, PNorm = 55.5441, GNorm = 2.4939, lr_0 = 1.0804e-04
Loss = 3.5170e-04, PNorm = 55.5467, GNorm = 0.9546, lr_0 = 1.0804e-04
Loss = 3.5340e-04, PNorm = 55.5498, GNorm = 0.9009, lr_0 = 1.0804e-04
Loss = 4.6642e-04, PNorm = 55.5524, GNorm = 2.4489, lr_0 = 1.0804e-04
Loss = 5.6277e-04, PNorm = 55.5551, GNorm = 4.0686, lr_0 = 1.0804e-04
Validation rmse logD = 0.524212
Validation R2 logD = 0.813628
Epoch 81
Train function
Loss = 3.1473e-04, PNorm = 55.5591, GNorm = 2.2674, lr_0 = 1.0804e-04
Loss = 7.3517e-04, PNorm = 55.5623, GNorm = 2.4228, lr_0 = 1.0804e-04
Loss = 8.5277e-04, PNorm = 55.5662, GNorm = 6.9628, lr_0 = 1.0804e-04
Loss = 8.0590e-04, PNorm = 55.5701, GNorm = 6.0333, lr_0 = 1.0804e-04
Loss = 5.9145e-04, PNorm = 55.5749, GNorm = 3.4881, lr_0 = 1.0804e-04
Loss = 5.0882e-04, PNorm = 55.5790, GNorm = 1.0309, lr_0 = 1.0804e-04
Validation rmse logD = 0.539489
Validation R2 logD = 0.802607
Epoch 82
Train function
Loss = 3.9863e-04, PNorm = 55.5827, GNorm = 2.1964, lr_0 = 1.0804e-04
Loss = 4.6458e-04, PNorm = 55.5866, GNorm = 1.2251, lr_0 = 1.0804e-04
Loss = 4.6400e-04, PNorm = 55.5898, GNorm = 1.4633, lr_0 = 1.0804e-04
Loss = 3.3600e-04, PNorm = 55.5925, GNorm = 2.3550, lr_0 = 1.0804e-04
Loss = 3.8362e-04, PNorm = 55.5959, GNorm = 1.5306, lr_0 = 1.0804e-04
Loss = 4.0316e-04, PNorm = 55.5991, GNorm = 1.0029, lr_0 = 1.0804e-04
Validation rmse logD = 0.524967
Validation R2 logD = 0.813090
Epoch 83
Train function
Loss = 2.6205e-04, PNorm = 55.6012, GNorm = 0.5854, lr_0 = 1.0804e-04
Loss = 3.3277e-04, PNorm = 55.6039, GNorm = 1.4177, lr_0 = 1.0804e-04
Loss = 3.0074e-04, PNorm = 55.6055, GNorm = 1.7600, lr_0 = 1.0804e-04
Loss = 5.1097e-04, PNorm = 55.6082, GNorm = 1.5103, lr_0 = 1.0804e-04
Loss = 4.9561e-04, PNorm = 55.6114, GNorm = 3.8775, lr_0 = 1.0804e-04
Validation rmse logD = 0.526783
Validation R2 logD = 0.811795
Epoch 84
Train function
Loss = 3.2012e-04, PNorm = 55.6146, GNorm = 1.3405, lr_0 = 1.0804e-04
Loss = 3.0236e-04, PNorm = 55.6173, GNorm = 2.0437, lr_0 = 1.0804e-04
Loss = 3.8847e-04, PNorm = 55.6210, GNorm = 4.0188, lr_0 = 1.0804e-04
Loss = 4.9156e-04, PNorm = 55.6240, GNorm = 3.0802, lr_0 = 1.0804e-04
Loss = 6.8019e-04, PNorm = 55.6246, GNorm = 0.8840, lr_0 = 1.0804e-04
Loss = 4.8623e-04, PNorm = 55.6270, GNorm = 3.6319, lr_0 = 1.0804e-04
Validation rmse logD = 0.536370
Validation R2 logD = 0.804882
Epoch 85
Train function
Loss = 5.1244e-04, PNorm = 55.6311, GNorm = 2.6264, lr_0 = 1.0804e-04
Loss = 4.6000e-04, PNorm = 55.6351, GNorm = 1.4851, lr_0 = 1.0804e-04
Loss = 5.2552e-04, PNorm = 55.6391, GNorm = 2.0347, lr_0 = 1.0804e-04
Loss = 8.0735e-04, PNorm = 55.6414, GNorm = 7.1747, lr_0 = 1.0804e-04
Loss = 7.4661e-04, PNorm = 55.6444, GNorm = 5.5256, lr_0 = 1.0804e-04
Loss = 5.3483e-04, PNorm = 55.6499, GNorm = 0.7839, lr_0 = 1.0804e-04
Validation rmse logD = 0.575546
Validation R2 logD = 0.775339
Epoch 86
Train function
Loss = 7.6613e-04, PNorm = 55.6536, GNorm = 4.0575, lr_0 = 1.0804e-04
Loss = 5.4481e-04, PNorm = 55.6572, GNorm = 4.1517, lr_0 = 1.0804e-04
Loss = 4.4882e-04, PNorm = 55.6627, GNorm = 0.9535, lr_0 = 1.0804e-04
Loss = 4.3494e-04, PNorm = 55.6657, GNorm = 1.0117, lr_0 = 1.0804e-04
Loss = 4.8708e-04, PNorm = 55.6691, GNorm = 1.9031, lr_0 = 1.0804e-04
Validation rmse logD = 0.521904
Validation R2 logD = 0.815265
Epoch 87
Train function
Loss = 1.4648e-04, PNorm = 55.6723, GNorm = 0.7201, lr_0 = 1.0804e-04
Loss = 3.8216e-04, PNorm = 55.6769, GNorm = 3.0176, lr_0 = 1.0804e-04
Loss = 3.2064e-04, PNorm = 55.6809, GNorm = 1.1674, lr_0 = 1.0804e-04
Loss = 3.2506e-04, PNorm = 55.6836, GNorm = 1.7871, lr_0 = 1.0804e-04
Loss = 4.2631e-04, PNorm = 55.6856, GNorm = 4.9850, lr_0 = 1.0804e-04
Loss = 5.4739e-04, PNorm = 55.6875, GNorm = 3.5032, lr_0 = 1.0804e-04
Validation rmse logD = 0.520854
Validation R2 logD = 0.816008
Epoch 88
Train function
Loss = 3.2551e-04, PNorm = 55.6902, GNorm = 1.4203, lr_0 = 1.0804e-04
Loss = 3.3601e-04, PNorm = 55.6935, GNorm = 0.9986, lr_0 = 1.0804e-04
Loss = 3.1551e-04, PNorm = 55.6963, GNorm = 0.7964, lr_0 = 1.0804e-04
Loss = 2.9680e-04, PNorm = 55.7003, GNorm = 1.3602, lr_0 = 1.0804e-04
Loss = 4.5446e-04, PNorm = 55.7025, GNorm = 2.9258, lr_0 = 1.0804e-04
Loss = 3.6721e-04, PNorm = 55.7050, GNorm = 3.3697, lr_0 = 1.0804e-04
Validation rmse logD = 0.553924
Validation R2 logD = 0.791902
Epoch 89
Train function
Loss = 4.6562e-04, PNorm = 55.7078, GNorm = 1.1093, lr_0 = 1.0804e-04
Loss = 4.8218e-04, PNorm = 55.7106, GNorm = 1.7200, lr_0 = 1.0804e-04
Loss = 5.5787e-04, PNorm = 55.7138, GNorm = 0.9390, lr_0 = 1.0804e-04
Loss = 4.9638e-04, PNorm = 55.7168, GNorm = 3.8888, lr_0 = 1.0804e-04
Loss = 3.4857e-04, PNorm = 55.7198, GNorm = 1.0642, lr_0 = 1.0804e-04
Validation rmse logD = 0.519758
Validation R2 logD = 0.816781
Epoch 90
Train function
Loss = 3.6072e-04, PNorm = 55.7226, GNorm = 0.9463, lr_0 = 1.0804e-04
Loss = 2.8045e-04, PNorm = 55.7255, GNorm = 1.5950, lr_0 = 1.0804e-04
Loss = 3.6173e-04, PNorm = 55.7280, GNorm = 1.0305, lr_0 = 1.0804e-04
Loss = 3.1952e-04, PNorm = 55.7318, GNorm = 1.5628, lr_0 = 1.0804e-04
Loss = 2.5769e-04, PNorm = 55.7353, GNorm = 1.5352, lr_0 = 1.0804e-04
Loss = 3.2964e-04, PNorm = 55.7379, GNorm = 0.5417, lr_0 = 1.0804e-04
Validation rmse logD = 0.519916
Validation R2 logD = 0.816670
Epoch 91
Train function
Loss = 1.9242e-04, PNorm = 55.7410, GNorm = 0.8869, lr_0 = 1.0804e-04
Loss = 2.7477e-04, PNorm = 55.7425, GNorm = 1.7971, lr_0 = 1.0804e-04
Loss = 2.4424e-04, PNorm = 55.7437, GNorm = 0.6817, lr_0 = 1.0804e-04
Loss = 3.8225e-04, PNorm = 55.7454, GNorm = 1.0637, lr_0 = 1.0804e-04
Loss = 3.3626e-04, PNorm = 55.7476, GNorm = 1.5692, lr_0 = 1.0804e-04
Loss = 3.8198e-04, PNorm = 55.7496, GNorm = 3.8937, lr_0 = 1.0804e-04
Validation rmse logD = 0.523650
Validation R2 logD = 0.814027
Epoch 92
Train function
Loss = 2.6858e-04, PNorm = 55.7515, GNorm = 0.7026, lr_0 = 1.0804e-04
Loss = 2.8928e-04, PNorm = 55.7553, GNorm = 1.7482, lr_0 = 1.0804e-04
Loss = 2.5226e-04, PNorm = 55.7574, GNorm = 0.6249, lr_0 = 1.0804e-04
Loss = 3.5677e-04, PNorm = 55.7597, GNorm = 1.5046, lr_0 = 1.0804e-04
Loss = 2.9288e-04, PNorm = 55.7626, GNorm = 1.9752, lr_0 = 1.0804e-04
Validation rmse logD = 0.523343
Validation R2 logD = 0.814245
Epoch 93
Train function
Loss = 1.7147e-04, PNorm = 55.7648, GNorm = 1.1650, lr_0 = 1.0804e-04
Loss = 2.2638e-04, PNorm = 55.7667, GNorm = 1.1932, lr_0 = 1.0804e-04
Loss = 2.7741e-04, PNorm = 55.7686, GNorm = 1.0884, lr_0 = 1.0804e-04
Loss = 2.6327e-04, PNorm = 55.7705, GNorm = 0.7452, lr_0 = 1.0804e-04
Loss = 2.6590e-04, PNorm = 55.7737, GNorm = 0.9371, lr_0 = 1.0804e-04
Loss = 2.8425e-04, PNorm = 55.7755, GNorm = 0.9420, lr_0 = 1.0804e-04
Validation rmse logD = 0.524233
Validation R2 logD = 0.813613
Epoch 94
Train function
Loss = 2.4558e-04, PNorm = 55.7786, GNorm = 1.1196, lr_0 = 1.0804e-04
Loss = 2.3959e-04, PNorm = 55.7817, GNorm = 0.9290, lr_0 = 1.0804e-04
Loss = 2.5181e-04, PNorm = 55.7838, GNorm = 2.1390, lr_0 = 1.0804e-04
Loss = 2.5156e-04, PNorm = 55.7864, GNorm = 0.6405, lr_0 = 1.0804e-04
Loss = 1.8695e-04, PNorm = 55.7877, GNorm = 0.5809, lr_0 = 1.0804e-04
Loss = 4.6451e-04, PNorm = 55.7888, GNorm = 3.3410, lr_0 = 1.0804e-04
Validation rmse logD = 0.525482
Validation R2 logD = 0.812724
Epoch 95
Train function
Loss = 2.6483e-04, PNorm = 55.7923, GNorm = 1.2089, lr_0 = 1.0804e-04
Loss = 3.2588e-04, PNorm = 55.7944, GNorm = 2.4093, lr_0 = 1.0804e-04
Loss = 4.0300e-04, PNorm = 55.7978, GNorm = 3.6393, lr_0 = 1.0804e-04
Loss = 4.9312e-04, PNorm = 55.8005, GNorm = 3.1657, lr_0 = 1.0804e-04
Loss = 3.2906e-04, PNorm = 55.8039, GNorm = 2.6461, lr_0 = 1.0804e-04
Validation rmse logD = 0.520304
Validation R2 logD = 0.816397
Epoch 96
Train function
Loss = 3.9208e-04, PNorm = 55.8074, GNorm = 1.3605, lr_0 = 1.0804e-04
Loss = 3.4303e-04, PNorm = 55.8089, GNorm = 0.6915, lr_0 = 1.0804e-04
Loss = 2.7986e-04, PNorm = 55.8109, GNorm = 0.5331, lr_0 = 1.0804e-04
Loss = 2.5866e-04, PNorm = 55.8134, GNorm = 1.8070, lr_0 = 1.0804e-04
Loss = 2.5281e-04, PNorm = 55.8149, GNorm = 0.4748, lr_0 = 1.0804e-04
Loss = 2.7327e-04, PNorm = 55.8167, GNorm = 0.7677, lr_0 = 1.0804e-04
Validation rmse logD = 0.529068
Validation R2 logD = 0.810159
Epoch 97
Train function
Loss = 3.6728e-04, PNorm = 55.8194, GNorm = 0.4294, lr_0 = 1.0804e-04
Loss = 3.6655e-04, PNorm = 55.8211, GNorm = 5.3759, lr_0 = 1.0804e-04
Loss = 3.7278e-04, PNorm = 55.8232, GNorm = 1.5122, lr_0 = 1.0804e-04
Loss = 3.5912e-04, PNorm = 55.8264, GNorm = 1.3469, lr_0 = 1.0804e-04
Loss = 2.6101e-04, PNorm = 55.8305, GNorm = 2.9895, lr_0 = 1.0804e-04
Loss = 2.2261e-04, PNorm = 55.8341, GNorm = 1.0602, lr_0 = 1.0804e-04
Validation rmse logD = 0.534983
Validation R2 logD = 0.805890
Epoch 98
Train function
Loss = 1.8077e-04, PNorm = 55.8361, GNorm = 0.8781, lr_0 = 1.0804e-04
Loss = 3.1078e-04, PNorm = 55.8380, GNorm = 1.9672, lr_0 = 1.0804e-04
Loss = 2.8818e-04, PNorm = 55.8404, GNorm = 0.4958, lr_0 = 1.0804e-04
Loss = 2.4155e-04, PNorm = 55.8428, GNorm = 0.8863, lr_0 = 1.0804e-04
Loss = 3.0568e-04, PNorm = 55.8450, GNorm = 1.1843, lr_0 = 1.0804e-04
Validation rmse logD = 0.527959
Validation R2 logD = 0.810954
Epoch 99
Train function
Loss = 3.0299e-04, PNorm = 55.8473, GNorm = 2.2167, lr_0 = 1.0804e-04
Loss = 2.6056e-04, PNorm = 55.8492, GNorm = 3.9786, lr_0 = 1.0804e-04
Loss = 3.0033e-04, PNorm = 55.8509, GNorm = 0.7370, lr_0 = 1.0804e-04
Loss = 4.3954e-04, PNorm = 55.8540, GNorm = 2.9317, lr_0 = 1.0804e-04
Loss = 2.6809e-04, PNorm = 55.8581, GNorm = 1.1949, lr_0 = 1.0804e-04
Loss = 2.9503e-04, PNorm = 55.8602, GNorm = 2.6063, lr_0 = 1.0804e-04
Validation rmse logD = 0.520382
Validation R2 logD = 0.816341
Model 0 best validation rmse = 0.519758 on epoch 89
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.555350
Model 0 test R2 logD = 0.790018
Ensemble test rmse  logD= 0.555350
Ensemble test R2  logD= 0.790018
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 1.8856e-02, PNorm = 52.9137, GNorm = 3.0662, lr_0 = 1.0804e-04
Loss = 1.6946e-02, PNorm = 52.9178, GNorm = 2.2094, lr_0 = 1.0804e-04
Loss = 1.7392e-02, PNorm = 52.9214, GNorm = 5.0479, lr_0 = 1.0804e-04
Loss = 1.7064e-02, PNorm = 52.9241, GNorm = 9.0748, lr_0 = 1.0804e-04
Loss = 1.5130e-02, PNorm = 52.9271, GNorm = 1.8464, lr_0 = 1.0804e-04
Validation rmse logD = 1.079251
Validation R2 logD = 0.249938
Epoch 1
Train function
Loss = 1.1675e-02, PNorm = 52.9302, GNorm = 2.6826, lr_0 = 1.0804e-04
Loss = 1.4028e-02, PNorm = 52.9338, GNorm = 7.2533, lr_0 = 1.0804e-04
Loss = 1.3694e-02, PNorm = 52.9381, GNorm = 7.2263, lr_0 = 1.0804e-04
Loss = 1.3963e-02, PNorm = 52.9432, GNorm = 2.9481, lr_0 = 1.0804e-04
Loss = 1.3567e-02, PNorm = 52.9488, GNorm = 3.1451, lr_0 = 1.0804e-04
Loss = 1.2745e-02, PNorm = 52.9546, GNorm = 1.8435, lr_0 = 1.0804e-04
Validation rmse logD = 1.019522
Validation R2 logD = 0.330662
Epoch 2
Train function
Loss = 1.3502e-02, PNorm = 52.9611, GNorm = 2.7891, lr_0 = 1.0804e-04
Loss = 1.3207e-02, PNorm = 52.9675, GNorm = 3.9238, lr_0 = 1.0804e-04
Loss = 1.1280e-02, PNorm = 52.9743, GNorm = 2.3413, lr_0 = 1.0804e-04
Loss = 1.1894e-02, PNorm = 52.9815, GNorm = 1.9976, lr_0 = 1.0804e-04
Loss = 1.1069e-02, PNorm = 52.9899, GNorm = 3.0427, lr_0 = 1.0804e-04
Validation rmse logD = 0.940918
Validation R2 logD = 0.429893
Epoch 3
Train function
Loss = 1.3452e-02, PNorm = 52.9985, GNorm = 1.9386, lr_0 = 1.0804e-04
Loss = 9.9483e-03, PNorm = 53.0064, GNorm = 1.8754, lr_0 = 1.0804e-04
Loss = 1.0125e-02, PNorm = 53.0142, GNorm = 7.2118, lr_0 = 1.0804e-04
Loss = 1.0824e-02, PNorm = 53.0232, GNorm = 3.9306, lr_0 = 1.0804e-04
Loss = 1.1771e-02, PNorm = 53.0326, GNorm = 10.1553, lr_0 = 1.0804e-04
Loss = 9.7032e-03, PNorm = 53.0414, GNorm = 2.0950, lr_0 = 1.0804e-04
Validation rmse logD = 0.888283
Validation R2 logD = 0.491894
Epoch 4
Train function
Loss = 9.2081e-03, PNorm = 53.0480, GNorm = 1.9798, lr_0 = 1.0804e-04
Loss = 8.7427e-03, PNorm = 53.0570, GNorm = 5.3617, lr_0 = 1.0804e-04
Loss = 8.8741e-03, PNorm = 53.0691, GNorm = 3.4268, lr_0 = 1.0804e-04
Loss = 9.9310e-03, PNorm = 53.0773, GNorm = 3.2926, lr_0 = 1.0804e-04
Loss = 9.7182e-03, PNorm = 53.0857, GNorm = 3.0332, lr_0 = 1.0804e-04
Loss = 9.4731e-03, PNorm = 53.0951, GNorm = 4.2940, lr_0 = 1.0804e-04
Validation rmse logD = 0.855245
Validation R2 logD = 0.528986
Epoch 5
Train function
Loss = 8.7747e-03, PNorm = 53.1064, GNorm = 4.9484, lr_0 = 1.0804e-04
Loss = 8.7937e-03, PNorm = 53.1163, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 1.0679e-02, PNorm = 53.1249, GNorm = 8.3002, lr_0 = 1.0804e-04
Loss = 8.3885e-03, PNorm = 53.1331, GNorm = 1.7461, lr_0 = 1.0804e-04
Loss = 8.3168e-03, PNorm = 53.1426, GNorm = 1.7142, lr_0 = 1.0804e-04
Validation rmse logD = 0.818964
Validation R2 logD = 0.568101
Epoch 6
Train function
Loss = 7.8727e-03, PNorm = 53.1544, GNorm = 5.8681, lr_0 = 1.0804e-04
Loss = 7.0385e-03, PNorm = 53.1662, GNorm = 5.1814, lr_0 = 1.0804e-04
Loss = 7.8380e-03, PNorm = 53.1784, GNorm = 7.1594, lr_0 = 1.0804e-04
Loss = 8.4393e-03, PNorm = 53.1896, GNorm = 5.5202, lr_0 = 1.0804e-04
Loss = 9.9087e-03, PNorm = 53.1961, GNorm = 2.9740, lr_0 = 1.0804e-04
Loss = 8.2476e-03, PNorm = 53.2057, GNorm = 3.9510, lr_0 = 1.0804e-04
Validation rmse logD = 0.810037
Validation R2 logD = 0.577465
Epoch 7
Train function
Loss = 8.1421e-03, PNorm = 53.2155, GNorm = 2.1056, lr_0 = 1.0804e-04
Loss = 7.5610e-03, PNorm = 53.2260, GNorm = 4.8445, lr_0 = 1.0804e-04
Loss = 6.5202e-03, PNorm = 53.2363, GNorm = 1.9267, lr_0 = 1.0804e-04
Loss = 7.0200e-03, PNorm = 53.2462, GNorm = 4.3110, lr_0 = 1.0804e-04
Loss = 6.6507e-03, PNorm = 53.2571, GNorm = 1.3608, lr_0 = 1.0804e-04
Loss = 6.5652e-03, PNorm = 53.2676, GNorm = 4.2661, lr_0 = 1.0804e-04
Validation rmse logD = 0.823244
Validation R2 logD = 0.563575
Epoch 8
Train function
Loss = 7.0625e-03, PNorm = 53.2767, GNorm = 9.2397, lr_0 = 1.0804e-04
Loss = 7.3472e-03, PNorm = 53.2859, GNorm = 3.4229, lr_0 = 1.0804e-04
Loss = 6.9351e-03, PNorm = 53.2962, GNorm = 13.2792, lr_0 = 1.0804e-04
Loss = 6.7009e-03, PNorm = 53.3057, GNorm = 1.9284, lr_0 = 1.0804e-04
Loss = 6.6364e-03, PNorm = 53.3169, GNorm = 4.8414, lr_0 = 1.0804e-04
Validation rmse logD = 0.731043
Validation R2 logD = 0.655857
Epoch 9
Train function
Loss = 5.6566e-03, PNorm = 53.3293, GNorm = 2.6316, lr_0 = 1.0804e-04
Loss = 6.5111e-03, PNorm = 53.3402, GNorm = 1.7981, lr_0 = 1.0804e-04
Loss = 5.8410e-03, PNorm = 53.3508, GNorm = 1.7011, lr_0 = 1.0804e-04
Loss = 6.5735e-03, PNorm = 53.3590, GNorm = 5.1968, lr_0 = 1.0804e-04
Loss = 5.9984e-03, PNorm = 53.3694, GNorm = 2.0504, lr_0 = 1.0804e-04
Loss = 6.1052e-03, PNorm = 53.3805, GNorm = 6.2882, lr_0 = 1.0804e-04
Validation rmse logD = 0.722323
Validation R2 logD = 0.664018
Epoch 10
Train function
Loss = 6.4461e-03, PNorm = 53.3892, GNorm = 2.6246, lr_0 = 1.0804e-04
Loss = 6.0017e-03, PNorm = 53.3998, GNorm = 6.0184, lr_0 = 1.0804e-04
Loss = 5.8383e-03, PNorm = 53.4096, GNorm = 3.7141, lr_0 = 1.0804e-04
Loss = 5.5719e-03, PNorm = 53.4166, GNorm = 3.1572, lr_0 = 1.0804e-04
Loss = 5.8389e-03, PNorm = 53.4273, GNorm = 3.5244, lr_0 = 1.0804e-04
Loss = 5.4158e-03, PNorm = 53.4375, GNorm = 8.5281, lr_0 = 1.0804e-04
Validation rmse logD = 0.731626
Validation R2 logD = 0.655309
Epoch 11
Train function
Loss = 5.7652e-03, PNorm = 53.4460, GNorm = 7.3282, lr_0 = 1.0804e-04
Loss = 5.1652e-03, PNorm = 53.4566, GNorm = 3.6690, lr_0 = 1.0804e-04
Loss = 5.7310e-03, PNorm = 53.4648, GNorm = 2.4303, lr_0 = 1.0804e-04
Loss = 5.3781e-03, PNorm = 53.4752, GNorm = 6.6845, lr_0 = 1.0804e-04
Loss = 4.9643e-03, PNorm = 53.4862, GNorm = 7.9753, lr_0 = 1.0804e-04
Validation rmse logD = 0.683858
Validation R2 logD = 0.698849
Epoch 12
Train function
Loss = 3.4096e-03, PNorm = 53.4954, GNorm = 1.3684, lr_0 = 1.0804e-04
Loss = 5.0218e-03, PNorm = 53.5041, GNorm = 3.8704, lr_0 = 1.0804e-04
Loss = 4.6987e-03, PNorm = 53.5134, GNorm = 1.8413, lr_0 = 1.0804e-04
Loss = 4.9241e-03, PNorm = 53.5228, GNorm = 2.6951, lr_0 = 1.0804e-04
Loss = 5.0588e-03, PNorm = 53.5332, GNorm = 7.1846, lr_0 = 1.0804e-04
Loss = 5.1726e-03, PNorm = 53.5425, GNorm = 3.7684, lr_0 = 1.0804e-04
Validation rmse logD = 0.712490
Validation R2 logD = 0.673103
Epoch 13
Train function
Loss = 5.4963e-03, PNorm = 53.5521, GNorm = 6.1399, lr_0 = 1.0804e-04
Loss = 4.5475e-03, PNorm = 53.5620, GNorm = 6.1539, lr_0 = 1.0804e-04
Loss = 4.5832e-03, PNorm = 53.5724, GNorm = 5.7691, lr_0 = 1.0804e-04
Loss = 6.5205e-03, PNorm = 53.5807, GNorm = 10.6760, lr_0 = 1.0804e-04
Loss = 4.9640e-03, PNorm = 53.5902, GNorm = 2.0720, lr_0 = 1.0804e-04
Loss = 5.1093e-03, PNorm = 53.6014, GNorm = 8.3404, lr_0 = 1.0804e-04
Validation rmse logD = 0.683620
Validation R2 logD = 0.699058
Epoch 14
Train function
Loss = 3.7142e-03, PNorm = 53.6109, GNorm = 1.8326, lr_0 = 1.0804e-04
Loss = 4.3748e-03, PNorm = 53.6190, GNorm = 2.0405, lr_0 = 1.0804e-04
Loss = 4.4581e-03, PNorm = 53.6284, GNorm = 2.1494, lr_0 = 1.0804e-04
Loss = 4.5152e-03, PNorm = 53.6384, GNorm = 2.3595, lr_0 = 1.0804e-04
Loss = 4.7012e-03, PNorm = 53.6472, GNorm = 1.4990, lr_0 = 1.0804e-04
Validation rmse logD = 0.669498
Validation R2 logD = 0.711364
Epoch 15
Train function
Loss = 3.8194e-03, PNorm = 53.6561, GNorm = 3.4135, lr_0 = 1.0804e-04
Loss = 3.7635e-03, PNorm = 53.6662, GNorm = 3.4178, lr_0 = 1.0804e-04
Loss = 4.5022e-03, PNorm = 53.6741, GNorm = 8.1283, lr_0 = 1.0804e-04
Loss = 4.6167e-03, PNorm = 53.6826, GNorm = 8.3445, lr_0 = 1.0804e-04
Loss = 4.4580e-03, PNorm = 53.6909, GNorm = 6.7735, lr_0 = 1.0804e-04
Loss = 4.4818e-03, PNorm = 53.7004, GNorm = 2.3985, lr_0 = 1.0804e-04
Validation rmse logD = 0.687940
Validation R2 logD = 0.695243
Epoch 16
Train function
Loss = 3.5086e-03, PNorm = 53.7080, GNorm = 2.2220, lr_0 = 1.0804e-04
Loss = 3.7252e-03, PNorm = 53.7170, GNorm = 5.0861, lr_0 = 1.0804e-04
Loss = 4.3729e-03, PNorm = 53.7248, GNorm = 12.9314, lr_0 = 1.0804e-04
Loss = 4.3754e-03, PNorm = 53.7326, GNorm = 7.1184, lr_0 = 1.0804e-04
Loss = 4.2603e-03, PNorm = 53.7399, GNorm = 2.8208, lr_0 = 1.0804e-04
Loss = 4.2244e-03, PNorm = 53.7484, GNorm = 6.1086, lr_0 = 1.0804e-04
Validation rmse logD = 0.705541
Validation R2 logD = 0.679449
Epoch 17
Train function
Loss = 4.1612e-03, PNorm = 53.7578, GNorm = 10.5244, lr_0 = 1.0804e-04
Loss = 4.5067e-03, PNorm = 53.7654, GNorm = 2.0772, lr_0 = 1.0804e-04
Loss = 3.9528e-03, PNorm = 53.7763, GNorm = 6.1405, lr_0 = 1.0804e-04
Loss = 4.9879e-03, PNorm = 53.7851, GNorm = 1.5912, lr_0 = 1.0804e-04
Loss = 3.6515e-03, PNorm = 53.7937, GNorm = 3.6178, lr_0 = 1.0804e-04
Validation rmse logD = 0.668145
Validation R2 logD = 0.712529
Epoch 18
Train function
Loss = 2.7197e-03, PNorm = 53.8039, GNorm = 2.2395, lr_0 = 1.0804e-04
Loss = 3.7883e-03, PNorm = 53.8125, GNorm = 5.9162, lr_0 = 1.0804e-04
Loss = 3.4010e-03, PNorm = 53.8198, GNorm = 4.6878, lr_0 = 1.0804e-04
Loss = 3.5014e-03, PNorm = 53.8289, GNorm = 3.3035, lr_0 = 1.0804e-04
Loss = 4.0769e-03, PNorm = 53.8390, GNorm = 4.9151, lr_0 = 1.0804e-04
Loss = 3.4111e-03, PNorm = 53.8470, GNorm = 2.4385, lr_0 = 1.0804e-04
Validation rmse logD = 0.679133
Validation R2 logD = 0.702996
Epoch 19
Train function
Loss = 3.3983e-03, PNorm = 53.8548, GNorm = 2.4782, lr_0 = 1.0804e-04
Loss = 3.4920e-03, PNorm = 53.8625, GNorm = 6.0117, lr_0 = 1.0804e-04
Loss = 3.6601e-03, PNorm = 53.8695, GNorm = 2.2107, lr_0 = 1.0804e-04
Loss = 3.7195e-03, PNorm = 53.8798, GNorm = 1.5031, lr_0 = 1.0804e-04
Loss = 2.9442e-03, PNorm = 53.8890, GNorm = 2.6955, lr_0 = 1.0804e-04
Loss = 3.8763e-03, PNorm = 53.8961, GNorm = 2.3544, lr_0 = 1.0804e-04
Validation rmse logD = 0.650799
Validation R2 logD = 0.727262
Epoch 20
Train function
Loss = 3.2653e-03, PNorm = 53.9024, GNorm = 2.1518, lr_0 = 1.0804e-04
Loss = 3.2410e-03, PNorm = 53.9091, GNorm = 7.0499, lr_0 = 1.0804e-04
Loss = 3.0347e-03, PNorm = 53.9180, GNorm = 3.2580, lr_0 = 1.0804e-04
Loss = 3.2819e-03, PNorm = 53.9256, GNorm = 3.5430, lr_0 = 1.0804e-04
Loss = 3.1944e-03, PNorm = 53.9325, GNorm = 3.2740, lr_0 = 1.0804e-04
Validation rmse logD = 0.673719
Validation R2 logD = 0.707712
Epoch 21
Train function
Loss = 3.6787e-03, PNorm = 53.9435, GNorm = 7.0147, lr_0 = 1.0804e-04
Loss = 2.7669e-03, PNorm = 53.9509, GNorm = 1.1283, lr_0 = 1.0804e-04
Loss = 2.9103e-03, PNorm = 53.9584, GNorm = 3.9206, lr_0 = 1.0804e-04
Loss = 3.2413e-03, PNorm = 53.9662, GNorm = 2.1923, lr_0 = 1.0804e-04
Loss = 3.4208e-03, PNorm = 53.9734, GNorm = 4.9675, lr_0 = 1.0804e-04
Loss = 3.2179e-03, PNorm = 53.9809, GNorm = 4.6297, lr_0 = 1.0804e-04
Validation rmse logD = 0.675040
Validation R2 logD = 0.706565
Epoch 22
Train function
Loss = 3.2296e-03, PNorm = 53.9908, GNorm = 8.5607, lr_0 = 1.0804e-04
Loss = 2.8936e-03, PNorm = 53.9996, GNorm = 9.4818, lr_0 = 1.0804e-04
Loss = 3.9039e-03, PNorm = 54.0074, GNorm = 6.5178, lr_0 = 1.0804e-04
Loss = 3.1435e-03, PNorm = 54.0160, GNorm = 7.0073, lr_0 = 1.0804e-04
Loss = 3.4510e-03, PNorm = 54.0239, GNorm = 4.0354, lr_0 = 1.0804e-04
Loss = 3.7330e-03, PNorm = 54.0311, GNorm = 2.3851, lr_0 = 1.0804e-04
Validation rmse logD = 0.628821
Validation R2 logD = 0.745371
Epoch 23
Train function
Loss = 2.7286e-03, PNorm = 54.0397, GNorm = 2.4531, lr_0 = 1.0804e-04
Loss = 2.3594e-03, PNorm = 54.0487, GNorm = 2.6012, lr_0 = 1.0804e-04
Loss = 3.2813e-03, PNorm = 54.0568, GNorm = 6.6403, lr_0 = 1.0804e-04
Loss = 2.8527e-03, PNorm = 54.0656, GNorm = 1.2985, lr_0 = 1.0804e-04
Loss = 2.9270e-03, PNorm = 54.0728, GNorm = 1.6800, lr_0 = 1.0804e-04
Validation rmse logD = 0.624051
Validation R2 logD = 0.749220
Epoch 24
Train function
Loss = 2.2987e-03, PNorm = 54.0811, GNorm = 2.6051, lr_0 = 1.0804e-04
Loss = 3.1072e-03, PNorm = 54.0906, GNorm = 1.7801, lr_0 = 1.0804e-04
Loss = 2.7324e-03, PNorm = 54.0982, GNorm = 3.1583, lr_0 = 1.0804e-04
Loss = 2.9057e-03, PNorm = 54.1057, GNorm = 5.8216, lr_0 = 1.0804e-04
Loss = 2.7651e-03, PNorm = 54.1131, GNorm = 2.8406, lr_0 = 1.0804e-04
Loss = 2.3951e-03, PNorm = 54.1215, GNorm = 6.1762, lr_0 = 1.0804e-04
Validation rmse logD = 0.632202
Validation R2 logD = 0.742626
Epoch 25
Train function
Loss = 2.2383e-03, PNorm = 54.1281, GNorm = 3.7085, lr_0 = 1.0804e-04
Loss = 2.8029e-03, PNorm = 54.1356, GNorm = 3.0053, lr_0 = 1.0804e-04
Loss = 2.7160e-03, PNorm = 54.1430, GNorm = 3.8258, lr_0 = 1.0804e-04
Loss = 2.7074e-03, PNorm = 54.1510, GNorm = 5.5089, lr_0 = 1.0804e-04
Loss = 2.4251e-03, PNorm = 54.1590, GNorm = 3.4407, lr_0 = 1.0804e-04
Loss = 2.4915e-03, PNorm = 54.1674, GNorm = 5.6401, lr_0 = 1.0804e-04
Validation rmse logD = 0.609856
Validation R2 logD = 0.760499
Epoch 26
Train function
Loss = 1.9165e-03, PNorm = 54.1740, GNorm = 2.6891, lr_0 = 1.0804e-04
Loss = 2.0432e-03, PNorm = 54.1787, GNorm = 4.1728, lr_0 = 1.0804e-04
Loss = 2.2408e-03, PNorm = 54.1852, GNorm = 3.5224, lr_0 = 1.0804e-04
Loss = 2.2880e-03, PNorm = 54.1916, GNorm = 2.3571, lr_0 = 1.0804e-04
Loss = 3.1251e-03, PNorm = 54.2008, GNorm = 1.5767, lr_0 = 1.0804e-04
Validation rmse logD = 0.612976
Validation R2 logD = 0.758042
Epoch 27
Train function
Loss = 1.8354e-03, PNorm = 54.2116, GNorm = 1.6897, lr_0 = 1.0804e-04
Loss = 2.3464e-03, PNorm = 54.2198, GNorm = 4.0173, lr_0 = 1.0804e-04
Loss = 2.0851e-03, PNorm = 54.2271, GNorm = 2.1900, lr_0 = 1.0804e-04
Loss = 2.0463e-03, PNorm = 54.2342, GNorm = 6.2388, lr_0 = 1.0804e-04
Loss = 2.9767e-03, PNorm = 54.2435, GNorm = 2.4760, lr_0 = 1.0804e-04
Loss = 2.2569e-03, PNorm = 54.2500, GNorm = 1.5269, lr_0 = 1.0804e-04
Validation rmse logD = 0.611638
Validation R2 logD = 0.759098
Epoch 28
Train function
Loss = 2.3238e-03, PNorm = 54.2566, GNorm = 6.5596, lr_0 = 1.0804e-04
Loss = 2.9778e-03, PNorm = 54.2648, GNorm = 6.5109, lr_0 = 1.0804e-04
Loss = 1.9546e-03, PNorm = 54.2725, GNorm = 1.5514, lr_0 = 1.0804e-04
Loss = 2.1707e-03, PNorm = 54.2801, GNorm = 5.1245, lr_0 = 1.0804e-04
Loss = 2.2868e-03, PNorm = 54.2868, GNorm = 2.7976, lr_0 = 1.0804e-04
Loss = 2.4391e-03, PNorm = 54.2935, GNorm = 4.0336, lr_0 = 1.0804e-04
Validation rmse logD = 0.596100
Validation R2 logD = 0.771182
Epoch 29
Train function
Loss = 2.1266e-03, PNorm = 54.3004, GNorm = 2.0783, lr_0 = 1.0804e-04
Loss = 2.0414e-03, PNorm = 54.3073, GNorm = 3.6838, lr_0 = 1.0804e-04
Loss = 2.1967e-03, PNorm = 54.3150, GNorm = 2.3649, lr_0 = 1.0804e-04
Loss = 2.3457e-03, PNorm = 54.3222, GNorm = 8.0160, lr_0 = 1.0804e-04
Loss = 2.3709e-03, PNorm = 54.3284, GNorm = 1.9445, lr_0 = 1.0804e-04
Validation rmse logD = 0.616758
Validation R2 logD = 0.755048
Epoch 30
Train function
Loss = 1.7287e-03, PNorm = 54.3358, GNorm = 1.5351, lr_0 = 1.0804e-04
Loss = 1.8825e-03, PNorm = 54.3444, GNorm = 4.8512, lr_0 = 1.0804e-04
Loss = 2.1282e-03, PNorm = 54.3530, GNorm = 6.2831, lr_0 = 1.0804e-04
Loss = 2.1090e-03, PNorm = 54.3610, GNorm = 1.5465, lr_0 = 1.0804e-04
Loss = 2.0358e-03, PNorm = 54.3677, GNorm = 6.1552, lr_0 = 1.0804e-04
Loss = 2.5512e-03, PNorm = 54.3729, GNorm = 5.7537, lr_0 = 1.0804e-04
Validation rmse logD = 0.589888
Validation R2 logD = 0.775926
Epoch 31
Train function
Loss = 2.2344e-03, PNorm = 54.3786, GNorm = 1.7988, lr_0 = 1.0804e-04
Loss = 1.6745e-03, PNorm = 54.3859, GNorm = 3.2642, lr_0 = 1.0804e-04
Loss = 1.8461e-03, PNorm = 54.3937, GNorm = 2.0102, lr_0 = 1.0804e-04
Loss = 2.2371e-03, PNorm = 54.4017, GNorm = 5.2840, lr_0 = 1.0804e-04
Loss = 1.8491e-03, PNorm = 54.4092, GNorm = 3.2623, lr_0 = 1.0804e-04
Loss = 1.6769e-03, PNorm = 54.4151, GNorm = 3.5201, lr_0 = 1.0804e-04
Validation rmse logD = 0.627600
Validation R2 logD = 0.746360
Epoch 32
Train function
Loss = 1.6753e-03, PNorm = 54.4211, GNorm = 2.3049, lr_0 = 1.0804e-04
Loss = 1.6498e-03, PNorm = 54.4264, GNorm = 1.7187, lr_0 = 1.0804e-04
Loss = 2.2677e-03, PNorm = 54.4323, GNorm = 4.1443, lr_0 = 1.0804e-04
Loss = 2.1614e-03, PNorm = 54.4397, GNorm = 11.1389, lr_0 = 1.0804e-04
Loss = 2.0494e-03, PNorm = 54.4467, GNorm = 1.4642, lr_0 = 1.0804e-04
Validation rmse logD = 0.601155
Validation R2 logD = 0.767285
Epoch 33
Train function
Loss = 1.6156e-03, PNorm = 54.4551, GNorm = 2.3158, lr_0 = 1.0804e-04
Loss = 1.7930e-03, PNorm = 54.4628, GNorm = 4.0352, lr_0 = 1.0804e-04
Loss = 1.7467e-03, PNorm = 54.4696, GNorm = 2.1495, lr_0 = 1.0804e-04
Loss = 1.7084e-03, PNorm = 54.4760, GNorm = 2.8401, lr_0 = 1.0804e-04
Loss = 2.0133e-03, PNorm = 54.4801, GNorm = 6.0957, lr_0 = 1.0804e-04
Loss = 1.8379e-03, PNorm = 54.4865, GNorm = 1.8605, lr_0 = 1.0804e-04
Validation rmse logD = 0.602795
Validation R2 logD = 0.766013
Epoch 34
Train function
Loss = 1.5655e-03, PNorm = 54.4941, GNorm = 2.2865, lr_0 = 1.0804e-04
Loss = 1.7663e-03, PNorm = 54.5011, GNorm = 3.7378, lr_0 = 1.0804e-04
Loss = 2.1783e-03, PNorm = 54.5071, GNorm = 6.5947, lr_0 = 1.0804e-04
Loss = 2.1967e-03, PNorm = 54.5141, GNorm = 4.9989, lr_0 = 1.0804e-04
Loss = 2.0016e-03, PNorm = 54.5206, GNorm = 9.0910, lr_0 = 1.0804e-04
Loss = 1.6920e-03, PNorm = 54.5274, GNorm = 4.8358, lr_0 = 1.0804e-04
Validation rmse logD = 0.609509
Validation R2 logD = 0.760772
Epoch 35
Train function
Loss = 1.6624e-03, PNorm = 54.5345, GNorm = 1.5792, lr_0 = 1.0804e-04
Loss = 1.4277e-03, PNorm = 54.5427, GNorm = 1.7536, lr_0 = 1.0804e-04
Loss = 1.4808e-03, PNorm = 54.5509, GNorm = 5.4080, lr_0 = 1.0804e-04
Loss = 1.7400e-03, PNorm = 54.5553, GNorm = 4.4296, lr_0 = 1.0804e-04
Loss = 1.8480e-03, PNorm = 54.5613, GNorm = 5.7668, lr_0 = 1.0804e-04
Validation rmse logD = 0.586782
Validation R2 logD = 0.778280
Epoch 36
Train function
Loss = 1.3821e-03, PNorm = 54.5658, GNorm = 2.1356, lr_0 = 1.0804e-04
Loss = 2.1254e-03, PNorm = 54.5720, GNorm = 7.4301, lr_0 = 1.0804e-04
Loss = 1.6889e-03, PNorm = 54.5788, GNorm = 3.3644, lr_0 = 1.0804e-04
Loss = 1.4291e-03, PNorm = 54.5858, GNorm = 1.4550, lr_0 = 1.0804e-04
Loss = 1.4561e-03, PNorm = 54.5938, GNorm = 2.2487, lr_0 = 1.0804e-04
Loss = 1.5946e-03, PNorm = 54.6003, GNorm = 6.6021, lr_0 = 1.0804e-04
Validation rmse logD = 0.599697
Validation R2 logD = 0.768412
Epoch 37
Train function
Loss = 1.1371e-03, PNorm = 54.6057, GNorm = 1.7292, lr_0 = 1.0804e-04
Loss = 1.3522e-03, PNorm = 54.6114, GNorm = 1.4280, lr_0 = 1.0804e-04
Loss = 1.3907e-03, PNorm = 54.6176, GNorm = 2.7137, lr_0 = 1.0804e-04
Loss = 1.8832e-03, PNorm = 54.6219, GNorm = 10.4157, lr_0 = 1.0804e-04
Loss = 2.0032e-03, PNorm = 54.6263, GNorm = 4.9904, lr_0 = 1.0804e-04
Loss = 1.9943e-03, PNorm = 54.6344, GNorm = 6.1905, lr_0 = 1.0804e-04
Validation rmse logD = 0.612106
Validation R2 logD = 0.758729
Epoch 38
Train function
Loss = 1.6409e-03, PNorm = 54.6426, GNorm = 5.1901, lr_0 = 1.0804e-04
Loss = 1.3324e-03, PNorm = 54.6499, GNorm = 1.9804, lr_0 = 1.0804e-04
Loss = 2.0402e-03, PNorm = 54.6559, GNorm = 7.5198, lr_0 = 1.0804e-04
Loss = 1.6865e-03, PNorm = 54.6608, GNorm = 5.2500, lr_0 = 1.0804e-04
Loss = 1.6649e-03, PNorm = 54.6677, GNorm = 4.1867, lr_0 = 1.0804e-04
Validation rmse logD = 0.628408
Validation R2 logD = 0.745706
Epoch 39
Train function
Loss = 1.8073e-03, PNorm = 54.6741, GNorm = 6.1619, lr_0 = 1.0804e-04
Loss = 1.6754e-03, PNorm = 54.6785, GNorm = 3.6915, lr_0 = 1.0804e-04
Loss = 1.6424e-03, PNorm = 54.6850, GNorm = 1.9180, lr_0 = 1.0804e-04
Loss = 1.2208e-03, PNorm = 54.6922, GNorm = 1.5762, lr_0 = 1.0804e-04
Loss = 1.7467e-03, PNorm = 54.6973, GNorm = 3.6863, lr_0 = 1.0804e-04
Loss = 1.1925e-03, PNorm = 54.7025, GNorm = 2.4118, lr_0 = 1.0804e-04
Validation rmse logD = 0.630045
Validation R2 logD = 0.744380
Epoch 40
Train function
Loss = 2.1981e-03, PNorm = 54.7080, GNorm = 7.2325, lr_0 = 1.0804e-04
Loss = 1.5553e-03, PNorm = 54.7131, GNorm = 1.7781, lr_0 = 1.0804e-04
Loss = 1.8104e-03, PNorm = 54.7194, GNorm = 7.2888, lr_0 = 1.0804e-04
Loss = 1.5043e-03, PNorm = 54.7255, GNorm = 1.4124, lr_0 = 1.0804e-04
Loss = 1.3809e-03, PNorm = 54.7341, GNorm = 3.7818, lr_0 = 1.0804e-04
Loss = 1.1849e-03, PNorm = 54.7408, GNorm = 2.2918, lr_0 = 1.0804e-04
Validation rmse logD = 0.572377
Validation R2 logD = 0.789032
Epoch 41
Train function
Loss = 1.3555e-03, PNorm = 54.7478, GNorm = 4.1665, lr_0 = 1.0804e-04
Loss = 1.1945e-03, PNorm = 54.7510, GNorm = 1.3560, lr_0 = 1.0804e-04
Loss = 1.3291e-03, PNorm = 54.7543, GNorm = 7.3648, lr_0 = 1.0804e-04
Loss = 1.3416e-03, PNorm = 54.7594, GNorm = 1.3736, lr_0 = 1.0804e-04
Loss = 1.2807e-03, PNorm = 54.7657, GNorm = 1.1648, lr_0 = 1.0804e-04
Validation rmse logD = 0.576181
Validation R2 logD = 0.786218
Epoch 42
Train function
Loss = 1.1072e-03, PNorm = 54.7734, GNorm = 2.1870, lr_0 = 1.0804e-04
Loss = 1.1610e-03, PNorm = 54.7781, GNorm = 3.9793, lr_0 = 1.0804e-04
Loss = 1.1782e-03, PNorm = 54.7835, GNorm = 2.0008, lr_0 = 1.0804e-04
Loss = 1.2569e-03, PNorm = 54.7886, GNorm = 2.7029, lr_0 = 1.0804e-04
Loss = 1.9215e-03, PNorm = 54.7920, GNorm = 6.9260, lr_0 = 1.0804e-04
Loss = 2.0939e-03, PNorm = 54.7981, GNorm = 5.4150, lr_0 = 1.0804e-04
Validation rmse logD = 0.574187
Validation R2 logD = 0.787696
Epoch 43
Train function
Loss = 1.5288e-03, PNorm = 54.8044, GNorm = 1.2909, lr_0 = 1.0804e-04
Loss = 1.5103e-03, PNorm = 54.8114, GNorm = 1.5347, lr_0 = 1.0804e-04
Loss = 1.5472e-03, PNorm = 54.8170, GNorm = 2.7559, lr_0 = 1.0804e-04
Loss = 1.4969e-03, PNorm = 54.8218, GNorm = 3.2319, lr_0 = 1.0804e-04
Loss = 1.3560e-03, PNorm = 54.8285, GNorm = 1.7185, lr_0 = 1.0804e-04
Loss = 1.4456e-03, PNorm = 54.8356, GNorm = 1.6138, lr_0 = 1.0804e-04
Validation rmse logD = 0.576719
Validation R2 logD = 0.785819
Epoch 44
Train function
Loss = 1.0330e-03, PNorm = 54.8409, GNorm = 1.7608, lr_0 = 1.0804e-04
Loss = 1.1872e-03, PNorm = 54.8467, GNorm = 1.6640, lr_0 = 1.0804e-04
Loss = 1.1337e-03, PNorm = 54.8522, GNorm = 1.3678, lr_0 = 1.0804e-04
Loss = 9.6191e-04, PNorm = 54.8574, GNorm = 1.2273, lr_0 = 1.0804e-04
Loss = 1.1542e-03, PNorm = 54.8633, GNorm = 2.7185, lr_0 = 1.0804e-04
Validation rmse logD = 0.593108
Validation R2 logD = 0.773473
Epoch 45
Train function
Loss = 7.8908e-04, PNorm = 54.8686, GNorm = 2.2523, lr_0 = 1.0804e-04
Loss = 9.6665e-04, PNorm = 54.8726, GNorm = 1.8231, lr_0 = 1.0804e-04
Loss = 8.9079e-04, PNorm = 54.8766, GNorm = 2.2961, lr_0 = 1.0804e-04
Loss = 1.0995e-03, PNorm = 54.8820, GNorm = 1.5219, lr_0 = 1.0804e-04
Loss = 9.6166e-04, PNorm = 54.8864, GNorm = 4.5173, lr_0 = 1.0804e-04
Loss = 1.0925e-03, PNorm = 54.8916, GNorm = 2.3397, lr_0 = 1.0804e-04
Validation rmse logD = 0.631370
Validation R2 logD = 0.743303
Epoch 46
Train function
Loss = 1.2407e-03, PNorm = 54.8963, GNorm = 4.7325, lr_0 = 1.0804e-04
Loss = 1.1645e-03, PNorm = 54.9021, GNorm = 1.2897, lr_0 = 1.0804e-04
Loss = 9.3914e-04, PNorm = 54.9071, GNorm = 2.8437, lr_0 = 1.0804e-04
Loss = 8.3106e-04, PNorm = 54.9110, GNorm = 1.1404, lr_0 = 1.0804e-04
Loss = 9.3519e-04, PNorm = 54.9151, GNorm = 1.1660, lr_0 = 1.0804e-04
Loss = 1.1737e-03, PNorm = 54.9221, GNorm = 1.1645, lr_0 = 1.0804e-04
Validation rmse logD = 0.577701
Validation R2 logD = 0.785089
Epoch 47
Train function
Loss = 9.2033e-04, PNorm = 54.9259, GNorm = 3.4753, lr_0 = 1.0804e-04
Loss = 8.4555e-04, PNorm = 54.9308, GNorm = 4.0817, lr_0 = 1.0804e-04
Loss = 1.2971e-03, PNorm = 54.9368, GNorm = 3.9448, lr_0 = 1.0804e-04
Loss = 9.6751e-04, PNorm = 54.9409, GNorm = 1.3374, lr_0 = 1.0804e-04
Loss = 9.2758e-04, PNorm = 54.9456, GNorm = 1.1799, lr_0 = 1.0804e-04
Validation rmse logD = 0.593575
Validation R2 logD = 0.773116
Epoch 48
Train function
Loss = 1.4537e-03, PNorm = 54.9518, GNorm = 4.9808, lr_0 = 1.0804e-04
Loss = 1.1344e-03, PNorm = 54.9565, GNorm = 3.0754, lr_0 = 1.0804e-04
Loss = 1.2366e-03, PNorm = 54.9615, GNorm = 3.2777, lr_0 = 1.0804e-04
Loss = 1.0599e-03, PNorm = 54.9656, GNorm = 3.2467, lr_0 = 1.0804e-04
Loss = 9.4631e-04, PNorm = 54.9711, GNorm = 1.3798, lr_0 = 1.0804e-04
Loss = 9.6737e-04, PNorm = 54.9763, GNorm = 1.6369, lr_0 = 1.0804e-04
Validation rmse logD = 0.584353
Validation R2 logD = 0.780111
Epoch 49
Train function
Loss = 1.0419e-03, PNorm = 54.9822, GNorm = 3.8379, lr_0 = 1.0804e-04
Loss = 7.1078e-04, PNorm = 54.9876, GNorm = 4.3859, lr_0 = 1.0804e-04
Loss = 8.4686e-04, PNorm = 54.9923, GNorm = 6.0289, lr_0 = 1.0804e-04
Loss = 8.9577e-04, PNorm = 54.9971, GNorm = 2.3849, lr_0 = 1.0804e-04
Loss = 1.4235e-03, PNorm = 55.0011, GNorm = 7.5724, lr_0 = 1.0804e-04
Loss = 1.3780e-03, PNorm = 55.0056, GNorm = 2.8978, lr_0 = 1.0804e-04
Validation rmse logD = 0.582031
Validation R2 logD = 0.781855
Epoch 50
Train function
Loss = 1.0729e-03, PNorm = 55.0114, GNorm = 3.9045, lr_0 = 1.0804e-04
Loss = 1.3062e-03, PNorm = 55.0164, GNorm = 5.3983, lr_0 = 1.0804e-04
Loss = 1.2654e-03, PNorm = 55.0203, GNorm = 2.3427, lr_0 = 1.0804e-04
Loss = 1.2423e-03, PNorm = 55.0255, GNorm = 4.3582, lr_0 = 1.0804e-04
Loss = 1.0841e-03, PNorm = 55.0316, GNorm = 1.7822, lr_0 = 1.0804e-04
Validation rmse logD = 0.575469
Validation R2 logD = 0.786747
Epoch 51
Train function
Loss = 1.1622e-03, PNorm = 55.0376, GNorm = 1.8526, lr_0 = 1.0804e-04
Loss = 1.1076e-03, PNorm = 55.0434, GNorm = 2.4894, lr_0 = 1.0804e-04
Loss = 7.2088e-04, PNorm = 55.0472, GNorm = 1.6682, lr_0 = 1.0804e-04
Loss = 7.7397e-04, PNorm = 55.0525, GNorm = 1.1535, lr_0 = 1.0804e-04
Loss = 8.0229e-04, PNorm = 55.0582, GNorm = 1.0183, lr_0 = 1.0804e-04
Loss = 7.8798e-04, PNorm = 55.0613, GNorm = 1.4433, lr_0 = 1.0804e-04
Validation rmse logD = 0.600718
Validation R2 logD = 0.767622
Epoch 52
Train function
Loss = 8.9905e-04, PNorm = 55.0652, GNorm = 1.5511, lr_0 = 1.0804e-04
Loss = 7.8273e-04, PNorm = 55.0691, GNorm = 1.2631, lr_0 = 1.0804e-04
Loss = 6.4033e-04, PNorm = 55.0728, GNorm = 1.5442, lr_0 = 1.0804e-04
Loss = 8.7514e-04, PNorm = 55.0762, GNorm = 2.3205, lr_0 = 1.0804e-04
Loss = 8.5720e-04, PNorm = 55.0801, GNorm = 1.7125, lr_0 = 1.0804e-04
Loss = 1.0978e-03, PNorm = 55.0851, GNorm = 5.0967, lr_0 = 1.0804e-04
Validation rmse logD = 0.589283
Validation R2 logD = 0.776385
Epoch 53
Train function
Loss = 8.6636e-04, PNorm = 55.0905, GNorm = 1.2773, lr_0 = 1.0804e-04
Loss = 9.5704e-04, PNorm = 55.0961, GNorm = 1.1236, lr_0 = 1.0804e-04
Loss = 8.5263e-04, PNorm = 55.1012, GNorm = 1.3556, lr_0 = 1.0804e-04
Loss = 6.8921e-04, PNorm = 55.1061, GNorm = 1.8217, lr_0 = 1.0804e-04
Loss = 8.7165e-04, PNorm = 55.1094, GNorm = 3.4439, lr_0 = 1.0804e-04
Validation rmse logD = 0.571225
Validation R2 logD = 0.789880
Epoch 54
Train function
Loss = 7.0481e-04, PNorm = 55.1143, GNorm = 2.5586, lr_0 = 1.0804e-04
Loss = 6.8336e-04, PNorm = 55.1191, GNorm = 0.9361, lr_0 = 1.0804e-04
Loss = 8.9152e-04, PNorm = 55.1235, GNorm = 1.8953, lr_0 = 1.0804e-04
Loss = 1.0851e-03, PNorm = 55.1272, GNorm = 1.8331, lr_0 = 1.0804e-04
Loss = 8.9567e-04, PNorm = 55.1323, GNorm = 1.6240, lr_0 = 1.0804e-04
Loss = 8.1013e-04, PNorm = 55.1354, GNorm = 2.4634, lr_0 = 1.0804e-04
Validation rmse logD = 0.570921
Validation R2 logD = 0.790104
Epoch 55
Train function
Loss = 1.0651e-03, PNorm = 55.1395, GNorm = 1.8792, lr_0 = 1.0804e-04
Loss = 1.0775e-03, PNorm = 55.1451, GNorm = 6.9120, lr_0 = 1.0804e-04
Loss = 8.7979e-04, PNorm = 55.1493, GNorm = 1.0731, lr_0 = 1.0804e-04
Loss = 7.8686e-04, PNorm = 55.1553, GNorm = 4.8776, lr_0 = 1.0804e-04
Loss = 7.6623e-04, PNorm = 55.1608, GNorm = 2.4651, lr_0 = 1.0804e-04
Loss = 8.4795e-04, PNorm = 55.1657, GNorm = 2.7070, lr_0 = 1.0804e-04
Validation rmse logD = 0.570914
Validation R2 logD = 0.790109
Epoch 56
Train function
Loss = 5.9349e-04, PNorm = 55.1687, GNorm = 1.4369, lr_0 = 1.0804e-04
Loss = 5.8802e-04, PNorm = 55.1731, GNorm = 3.4844, lr_0 = 1.0804e-04
Loss = 6.5333e-04, PNorm = 55.1784, GNorm = 3.5698, lr_0 = 1.0804e-04
Loss = 8.5838e-04, PNorm = 55.1824, GNorm = 2.9443, lr_0 = 1.0804e-04
Loss = 8.5741e-04, PNorm = 55.1858, GNorm = 1.4855, lr_0 = 1.0804e-04
Validation rmse logD = 0.563521
Validation R2 logD = 0.795509
Epoch 57
Train function
Loss = 5.9486e-04, PNorm = 55.1910, GNorm = 1.6773, lr_0 = 1.0804e-04
Loss = 7.9012e-04, PNorm = 55.1939, GNorm = 2.3731, lr_0 = 1.0804e-04
Loss = 1.1028e-03, PNorm = 55.1968, GNorm = 4.2998, lr_0 = 1.0804e-04
Loss = 8.5021e-04, PNorm = 55.1996, GNorm = 6.1665, lr_0 = 1.0804e-04
Loss = 8.4974e-04, PNorm = 55.2054, GNorm = 2.6462, lr_0 = 1.0804e-04
Loss = 6.3812e-04, PNorm = 55.2111, GNorm = 4.0495, lr_0 = 1.0804e-04
Validation rmse logD = 0.566238
Validation R2 logD = 0.793533
Epoch 58
Train function
Loss = 5.4084e-04, PNorm = 55.2163, GNorm = 1.2706, lr_0 = 1.0804e-04
Loss = 5.2503e-04, PNorm = 55.2198, GNorm = 2.1033, lr_0 = 1.0804e-04
Loss = 6.8480e-04, PNorm = 55.2224, GNorm = 2.5074, lr_0 = 1.0804e-04
Loss = 7.3703e-04, PNorm = 55.2279, GNorm = 3.9722, lr_0 = 1.0804e-04
Loss = 6.5890e-04, PNorm = 55.2314, GNorm = 3.1701, lr_0 = 1.0804e-04
Loss = 6.6835e-04, PNorm = 55.2348, GNorm = 1.7405, lr_0 = 1.0804e-04
Validation rmse logD = 0.584841
Validation R2 logD = 0.779744
Epoch 59
Train function
Loss = 7.4185e-04, PNorm = 55.2388, GNorm = 3.3813, lr_0 = 1.0804e-04
Loss = 9.1645e-04, PNorm = 55.2423, GNorm = 5.9859, lr_0 = 1.0804e-04
Loss = 8.3887e-04, PNorm = 55.2473, GNorm = 1.9866, lr_0 = 1.0804e-04
Loss = 8.8022e-04, PNorm = 55.2521, GNorm = 4.5218, lr_0 = 1.0804e-04
Loss = 7.4383e-04, PNorm = 55.2571, GNorm = 2.2977, lr_0 = 1.0804e-04
Validation rmse logD = 0.573605
Validation R2 logD = 0.788126
Epoch 60
Train function
Loss = 5.3881e-04, PNorm = 55.2626, GNorm = 1.7528, lr_0 = 1.0804e-04
Loss = 6.2269e-04, PNorm = 55.2669, GNorm = 2.4122, lr_0 = 1.0804e-04
Loss = 5.5953e-04, PNorm = 55.2694, GNorm = 1.7022, lr_0 = 1.0804e-04
Loss = 6.5259e-04, PNorm = 55.2738, GNorm = 0.8630, lr_0 = 1.0804e-04
Loss = 6.2420e-04, PNorm = 55.2778, GNorm = 2.0498, lr_0 = 1.0804e-04
Loss = 8.4410e-04, PNorm = 55.2803, GNorm = 2.9385, lr_0 = 1.0804e-04
Validation rmse logD = 0.556305
Validation R2 logD = 0.800713
Epoch 61
Train function
Loss = 6.2423e-04, PNorm = 55.2839, GNorm = 1.9951, lr_0 = 1.0804e-04
Loss = 6.1117e-04, PNorm = 55.2878, GNorm = 1.2552, lr_0 = 1.0804e-04
Loss = 6.4781e-04, PNorm = 55.2919, GNorm = 1.0387, lr_0 = 1.0804e-04
Loss = 6.2671e-04, PNorm = 55.2953, GNorm = 2.2163, lr_0 = 1.0804e-04
Loss = 5.8586e-04, PNorm = 55.2994, GNorm = 0.9878, lr_0 = 1.0804e-04
Loss = 5.3591e-04, PNorm = 55.3031, GNorm = 0.9162, lr_0 = 1.0804e-04
Validation rmse logD = 0.559761
Validation R2 logD = 0.798230
Epoch 62
Train function
Loss = 5.1084e-04, PNorm = 55.3076, GNorm = 4.1546, lr_0 = 1.0804e-04
Loss = 4.7404e-04, PNorm = 55.3112, GNorm = 1.1558, lr_0 = 1.0804e-04
Loss = 5.1437e-04, PNorm = 55.3158, GNorm = 2.5481, lr_0 = 1.0804e-04
Loss = 9.3195e-04, PNorm = 55.3191, GNorm = 5.4009, lr_0 = 1.0804e-04
Loss = 7.1468e-04, PNorm = 55.3215, GNorm = 3.9201, lr_0 = 1.0804e-04
Validation rmse logD = 0.595119
Validation R2 logD = 0.771935
Epoch 63
Train function
Loss = 9.1119e-04, PNorm = 55.3265, GNorm = 5.3951, lr_0 = 1.0804e-04
Loss = 7.2402e-04, PNorm = 55.3310, GNorm = 3.2034, lr_0 = 1.0804e-04
Loss = 5.5718e-04, PNorm = 55.3358, GNorm = 1.6102, lr_0 = 1.0804e-04
Loss = 4.9881e-04, PNorm = 55.3403, GNorm = 0.9841, lr_0 = 1.0804e-04
Loss = 6.7284e-04, PNorm = 55.3450, GNorm = 1.6908, lr_0 = 1.0804e-04
Loss = 6.9651e-04, PNorm = 55.3486, GNorm = 1.2604, lr_0 = 1.0804e-04
Validation rmse logD = 0.571731
Validation R2 logD = 0.789508
Epoch 64
Train function
Loss = 5.7624e-04, PNorm = 55.3516, GNorm = 1.8526, lr_0 = 1.0804e-04
Loss = 7.8134e-04, PNorm = 55.3543, GNorm = 3.8694, lr_0 = 1.0804e-04
Loss = 5.4188e-04, PNorm = 55.3581, GNorm = 2.1395, lr_0 = 1.0804e-04
Loss = 7.4087e-04, PNorm = 55.3609, GNorm = 1.0617, lr_0 = 1.0804e-04
Loss = 7.1743e-04, PNorm = 55.3634, GNorm = 2.2112, lr_0 = 1.0804e-04
Loss = 5.2275e-04, PNorm = 55.3685, GNorm = 1.8894, lr_0 = 1.0804e-04
Validation rmse logD = 0.557970
Validation R2 logD = 0.799518
Epoch 65
Train function
Loss = 5.5775e-04, PNorm = 55.3736, GNorm = 2.6104, lr_0 = 1.0804e-04
Loss = 5.5576e-04, PNorm = 55.3791, GNorm = 3.2687, lr_0 = 1.0804e-04
Loss = 6.3599e-04, PNorm = 55.3822, GNorm = 2.0691, lr_0 = 1.0804e-04
Loss = 4.8415e-04, PNorm = 55.3847, GNorm = 1.9118, lr_0 = 1.0804e-04
Loss = 4.9441e-04, PNorm = 55.3885, GNorm = 1.1149, lr_0 = 1.0804e-04
Validation rmse logD = 0.586441
Validation R2 logD = 0.778537
Epoch 66
Train function
Loss = 8.3801e-04, PNorm = 55.3926, GNorm = 5.6833, lr_0 = 1.0804e-04
Loss = 5.1513e-04, PNorm = 55.3965, GNorm = 1.3535, lr_0 = 1.0804e-04
Loss = 5.4930e-04, PNorm = 55.4015, GNorm = 4.4160, lr_0 = 1.0804e-04
Loss = 8.3680e-04, PNorm = 55.4068, GNorm = 5.1796, lr_0 = 1.0804e-04
Loss = 6.3398e-04, PNorm = 55.4104, GNorm = 3.8792, lr_0 = 1.0804e-04
Loss = 6.4645e-04, PNorm = 55.4130, GNorm = 1.6891, lr_0 = 1.0804e-04
Validation rmse logD = 0.560854
Validation R2 logD = 0.797441
Epoch 67
Train function
Loss = 6.7288e-04, PNorm = 55.4175, GNorm = 1.5403, lr_0 = 1.0804e-04
Loss = 5.2682e-04, PNorm = 55.4212, GNorm = 3.1900, lr_0 = 1.0804e-04
Loss = 5.3459e-04, PNorm = 55.4252, GNorm = 2.3073, lr_0 = 1.0804e-04
Loss = 5.5515e-04, PNorm = 55.4288, GNorm = 1.0860, lr_0 = 1.0804e-04
Loss = 5.5741e-04, PNorm = 55.4318, GNorm = 1.9608, lr_0 = 1.0804e-04
Loss = 7.3223e-04, PNorm = 55.4359, GNorm = 2.9688, lr_0 = 1.0804e-04
Validation rmse logD = 0.575684
Validation R2 logD = 0.786587
Epoch 68
Train function
Loss = 6.6544e-04, PNorm = 55.4395, GNorm = 4.2457, lr_0 = 1.0804e-04
Loss = 5.8327e-04, PNorm = 55.4438, GNorm = 1.3395, lr_0 = 1.0804e-04
Loss = 5.0731e-04, PNorm = 55.4471, GNorm = 3.2390, lr_0 = 1.0804e-04
Loss = 5.3859e-04, PNorm = 55.4504, GNorm = 2.6871, lr_0 = 1.0804e-04
Loss = 4.7406e-04, PNorm = 55.4545, GNorm = 1.7769, lr_0 = 1.0804e-04
Validation rmse logD = 0.567389
Validation R2 logD = 0.792693
Epoch 69
Train function
Loss = 3.4964e-04, PNorm = 55.4585, GNorm = 1.3795, lr_0 = 1.0804e-04
Loss = 6.6463e-04, PNorm = 55.4615, GNorm = 6.4527, lr_0 = 1.0804e-04
Loss = 5.9666e-04, PNorm = 55.4652, GNorm = 2.9404, lr_0 = 1.0804e-04
Loss = 5.0424e-04, PNorm = 55.4694, GNorm = 0.9701, lr_0 = 1.0804e-04
Loss = 4.1492e-04, PNorm = 55.4718, GNorm = 0.8010, lr_0 = 1.0804e-04
Loss = 4.6413e-04, PNorm = 55.4745, GNorm = 4.2677, lr_0 = 1.0804e-04
Validation rmse logD = 0.564325
Validation R2 logD = 0.794926
Epoch 70
Train function
Loss = 3.9238e-04, PNorm = 55.4779, GNorm = 1.6766, lr_0 = 1.0804e-04
Loss = 5.2875e-04, PNorm = 55.4807, GNorm = 1.7163, lr_0 = 1.0804e-04
Loss = 4.6820e-04, PNorm = 55.4855, GNorm = 1.7519, lr_0 = 1.0804e-04
Loss = 5.7551e-04, PNorm = 55.4889, GNorm = 1.2091, lr_0 = 1.0804e-04
Loss = 4.9665e-04, PNorm = 55.4919, GNorm = 3.1931, lr_0 = 1.0804e-04
Loss = 4.3299e-04, PNorm = 55.4952, GNorm = 3.2656, lr_0 = 1.0804e-04
Validation rmse logD = 0.557316
Validation R2 logD = 0.799989
Epoch 71
Train function
Loss = 5.6910e-04, PNorm = 55.4978, GNorm = 1.4954, lr_0 = 1.0804e-04
Loss = 4.4925e-04, PNorm = 55.5020, GNorm = 1.3180, lr_0 = 1.0804e-04
Loss = 4.7715e-04, PNorm = 55.5054, GNorm = 1.3968, lr_0 = 1.0804e-04
Loss = 4.0993e-04, PNorm = 55.5087, GNorm = 3.4897, lr_0 = 1.0804e-04
Loss = 3.8184e-04, PNorm = 55.5119, GNorm = 0.7143, lr_0 = 1.0804e-04
Validation rmse logD = 0.566695
Validation R2 logD = 0.793200
Epoch 72
Train function
Loss = 5.0605e-04, PNorm = 55.5158, GNorm = 3.0536, lr_0 = 1.0804e-04
Loss = 4.0246e-04, PNorm = 55.5176, GNorm = 2.8878, lr_0 = 1.0804e-04
Loss = 6.0319e-04, PNorm = 55.5207, GNorm = 4.4154, lr_0 = 1.0804e-04
Loss = 4.4376e-04, PNorm = 55.5251, GNorm = 2.2688, lr_0 = 1.0804e-04
Loss = 5.1115e-04, PNorm = 55.5280, GNorm = 1.4780, lr_0 = 1.0804e-04
Loss = 6.3736e-04, PNorm = 55.5296, GNorm = 5.1545, lr_0 = 1.0804e-04
Validation rmse logD = 0.571037
Validation R2 logD = 0.790019
Epoch 73
Train function
Loss = 6.3478e-04, PNorm = 55.5326, GNorm = 2.1537, lr_0 = 1.0804e-04
Loss = 4.5330e-04, PNorm = 55.5364, GNorm = 1.4563, lr_0 = 1.0804e-04
Loss = 3.8718e-04, PNorm = 55.5400, GNorm = 0.6777, lr_0 = 1.0804e-04
Loss = 3.8084e-04, PNorm = 55.5446, GNorm = 2.6405, lr_0 = 1.0804e-04
Loss = 4.7055e-04, PNorm = 55.5486, GNorm = 1.3811, lr_0 = 1.0804e-04
Loss = 4.5387e-04, PNorm = 55.5519, GNorm = 2.7779, lr_0 = 1.0804e-04
Validation rmse logD = 0.559095
Validation R2 logD = 0.798709
Epoch 74
Train function
Loss = 4.3154e-04, PNorm = 55.5548, GNorm = 4.1132, lr_0 = 1.0804e-04
Loss = 6.6199e-04, PNorm = 55.5566, GNorm = 3.6594, lr_0 = 1.0804e-04
Loss = 4.8719e-04, PNorm = 55.5610, GNorm = 2.1345, lr_0 = 1.0804e-04
Loss = 4.8984e-04, PNorm = 55.5650, GNorm = 1.2243, lr_0 = 1.0804e-04
Loss = 4.7372e-04, PNorm = 55.5676, GNorm = 2.0401, lr_0 = 1.0804e-04
Validation rmse logD = 0.573430
Validation R2 logD = 0.788255
Epoch 75
Train function
Loss = 2.5911e-04, PNorm = 55.5716, GNorm = 1.3084, lr_0 = 1.0804e-04
Loss = 4.6085e-04, PNorm = 55.5743, GNorm = 2.8132, lr_0 = 1.0804e-04
Loss = 6.5109e-04, PNorm = 55.5774, GNorm = 2.4269, lr_0 = 1.0804e-04
Loss = 3.6063e-04, PNorm = 55.5818, GNorm = 1.6734, lr_0 = 1.0804e-04
Loss = 4.5691e-04, PNorm = 55.5862, GNorm = 2.3241, lr_0 = 1.0804e-04
Loss = 6.1989e-04, PNorm = 55.5903, GNorm = 3.2270, lr_0 = 1.0804e-04
Validation rmse logD = 0.567856
Validation R2 logD = 0.792351
Epoch 76
Train function
Loss = 6.0384e-04, PNorm = 55.5929, GNorm = 1.2146, lr_0 = 1.0804e-04
Loss = 5.3681e-04, PNorm = 55.5968, GNorm = 2.5329, lr_0 = 1.0804e-04
Loss = 4.5059e-04, PNorm = 55.6002, GNorm = 1.2291, lr_0 = 1.0804e-04
Loss = 4.3784e-04, PNorm = 55.6042, GNorm = 1.4809, lr_0 = 1.0804e-04
Loss = 4.5782e-04, PNorm = 55.6064, GNorm = 3.0628, lr_0 = 1.0804e-04
Loss = 4.3458e-04, PNorm = 55.6093, GNorm = 2.0287, lr_0 = 1.0804e-04
Validation rmse logD = 0.558941
Validation R2 logD = 0.798820
Epoch 77
Train function
Loss = 3.5296e-04, PNorm = 55.6126, GNorm = 1.1328, lr_0 = 1.0804e-04
Loss = 4.0291e-04, PNorm = 55.6164, GNorm = 3.5284, lr_0 = 1.0804e-04
Loss = 7.3538e-04, PNorm = 55.6181, GNorm = 2.6016, lr_0 = 1.0804e-04
Loss = 5.8184e-04, PNorm = 55.6202, GNorm = 1.9689, lr_0 = 1.0804e-04
Loss = 4.0668e-04, PNorm = 55.6250, GNorm = 1.8827, lr_0 = 1.0804e-04
Validation rmse logD = 0.553669
Validation R2 logD = 0.802597
Epoch 78
Train function
Loss = 3.5982e-04, PNorm = 55.6285, GNorm = 0.8434, lr_0 = 1.0804e-04
Loss = 3.6591e-04, PNorm = 55.6314, GNorm = 1.2023, lr_0 = 1.0804e-04
Loss = 4.9962e-04, PNorm = 55.6351, GNorm = 4.9554, lr_0 = 1.0804e-04
Loss = 3.9361e-04, PNorm = 55.6398, GNorm = 3.9368, lr_0 = 1.0804e-04
Loss = 4.4680e-04, PNorm = 55.6436, GNorm = 1.3980, lr_0 = 1.0804e-04
Loss = 4.5476e-04, PNorm = 55.6463, GNorm = 2.5167, lr_0 = 1.0804e-04
Validation rmse logD = 0.553476
Validation R2 logD = 0.802735
Epoch 79
Train function
Loss = 3.7307e-04, PNorm = 55.6480, GNorm = 1.8920, lr_0 = 1.0804e-04
Loss = 3.3029e-04, PNorm = 55.6508, GNorm = 0.8989, lr_0 = 1.0804e-04
Loss = 4.5161e-04, PNorm = 55.6543, GNorm = 2.7784, lr_0 = 1.0804e-04
Loss = 4.7352e-04, PNorm = 55.6567, GNorm = 1.8608, lr_0 = 1.0804e-04
Loss = 7.5942e-04, PNorm = 55.6596, GNorm = 4.3759, lr_0 = 1.0804e-04
Loss = 8.1201e-04, PNorm = 55.6615, GNorm = 4.4808, lr_0 = 1.0804e-04
Validation rmse logD = 0.586222
Validation R2 logD = 0.778702
Epoch 80
Train function
Loss = 5.9846e-04, PNorm = 55.6657, GNorm = 4.9090, lr_0 = 1.0804e-04
Loss = 8.5412e-04, PNorm = 55.6697, GNorm = 6.3643, lr_0 = 1.0804e-04
Loss = 7.9728e-04, PNorm = 55.6718, GNorm = 4.6637, lr_0 = 1.0804e-04
Loss = 6.4725e-04, PNorm = 55.6775, GNorm = 2.3092, lr_0 = 1.0804e-04
Loss = 6.4436e-04, PNorm = 55.6820, GNorm = 1.5821, lr_0 = 1.0804e-04
Validation rmse logD = 0.565466
Validation R2 logD = 0.794096
Epoch 81
Train function
Loss = 5.4310e-04, PNorm = 55.6878, GNorm = 2.5911, lr_0 = 1.0804e-04
Loss = 4.9931e-04, PNorm = 55.6917, GNorm = 1.5773, lr_0 = 1.0804e-04
Loss = 3.7473e-04, PNorm = 55.6956, GNorm = 1.1217, lr_0 = 1.0804e-04
Loss = 3.3437e-04, PNorm = 55.6986, GNorm = 1.3779, lr_0 = 1.0804e-04
Loss = 3.5231e-04, PNorm = 55.7009, GNorm = 1.0498, lr_0 = 1.0804e-04
Loss = 4.1134e-04, PNorm = 55.7042, GNorm = 2.6101, lr_0 = 1.0804e-04
Validation rmse logD = 0.568589
Validation R2 logD = 0.791815
Epoch 82
Train function
Loss = 3.6847e-04, PNorm = 55.7071, GNorm = 3.3495, lr_0 = 1.0804e-04
Loss = 3.6348e-04, PNorm = 55.7106, GNorm = 1.9734, lr_0 = 1.0804e-04
Loss = 3.5838e-04, PNorm = 55.7147, GNorm = 1.6851, lr_0 = 1.0804e-04
Loss = 3.0009e-04, PNorm = 55.7181, GNorm = 1.8311, lr_0 = 1.0804e-04
Loss = 4.4202e-04, PNorm = 55.7204, GNorm = 1.2250, lr_0 = 1.0804e-04
Loss = 3.4126e-04, PNorm = 55.7232, GNorm = 0.9826, lr_0 = 1.0804e-04
Validation rmse logD = 0.560449
Validation R2 logD = 0.797733
Epoch 83
Train function
Loss = 3.7215e-04, PNorm = 55.7262, GNorm = 2.1413, lr_0 = 1.0804e-04
Loss = 2.9822e-04, PNorm = 55.7285, GNorm = 1.1037, lr_0 = 1.0804e-04
Loss = 3.3263e-04, PNorm = 55.7308, GNorm = 1.3794, lr_0 = 1.0804e-04
Loss = 2.2862e-04, PNorm = 55.7323, GNorm = 0.5674, lr_0 = 1.0804e-04
Loss = 3.1255e-04, PNorm = 55.7346, GNorm = 1.6363, lr_0 = 1.0804e-04
Validation rmse logD = 0.563373
Validation R2 logD = 0.795617
Epoch 84
Train function
Loss = 2.7031e-04, PNorm = 55.7376, GNorm = 1.2808, lr_0 = 1.0804e-04
Loss = 4.1723e-04, PNorm = 55.7398, GNorm = 1.2361, lr_0 = 1.0804e-04
Loss = 5.0021e-04, PNorm = 55.7429, GNorm = 2.5308, lr_0 = 1.0804e-04
Loss = 3.1100e-04, PNorm = 55.7449, GNorm = 1.6931, lr_0 = 1.0804e-04
Loss = 2.7891e-04, PNorm = 55.7476, GNorm = 0.9238, lr_0 = 1.0804e-04
Loss = 3.1521e-04, PNorm = 55.7510, GNorm = 2.5738, lr_0 = 1.0804e-04
Validation rmse logD = 0.564420
Validation R2 logD = 0.794857
Epoch 85
Train function
Loss = 2.7963e-04, PNorm = 55.7538, GNorm = 1.5862, lr_0 = 1.0804e-04
Loss = 3.7622e-04, PNorm = 55.7569, GNorm = 1.8278, lr_0 = 1.0804e-04
Loss = 3.8464e-04, PNorm = 55.7589, GNorm = 1.7043, lr_0 = 1.0804e-04
Loss = 3.2860e-04, PNorm = 55.7604, GNorm = 0.9703, lr_0 = 1.0804e-04
Loss = 3.2820e-04, PNorm = 55.7639, GNorm = 2.3290, lr_0 = 1.0804e-04
Loss = 4.0557e-04, PNorm = 55.7668, GNorm = 1.3049, lr_0 = 1.0804e-04
Validation rmse logD = 0.558490
Validation R2 logD = 0.799144
Epoch 86
Train function
Loss = 2.5741e-04, PNorm = 55.7692, GNorm = 1.1823, lr_0 = 1.0804e-04
Loss = 3.1293e-04, PNorm = 55.7712, GNorm = 1.9325, lr_0 = 1.0804e-04
Loss = 3.5939e-04, PNorm = 55.7744, GNorm = 2.2778, lr_0 = 1.0804e-04
Loss = 3.4490e-04, PNorm = 55.7769, GNorm = 2.5560, lr_0 = 1.0804e-04
Loss = 3.5289e-04, PNorm = 55.7797, GNorm = 1.2736, lr_0 = 1.0804e-04
Validation rmse logD = 0.578708
Validation R2 logD = 0.784339
Epoch 87
Train function
Loss = 7.9484e-04, PNorm = 55.7821, GNorm = 4.8552, lr_0 = 1.0804e-04
Loss = 3.9336e-04, PNorm = 55.7844, GNorm = 2.3932, lr_0 = 1.0804e-04
Loss = 3.3275e-04, PNorm = 55.7874, GNorm = 2.4153, lr_0 = 1.0804e-04
Loss = 4.7896e-04, PNorm = 55.7899, GNorm = 3.8086, lr_0 = 1.0804e-04
Loss = 4.6610e-04, PNorm = 55.7925, GNorm = 2.8989, lr_0 = 1.0804e-04
Loss = 3.7798e-04, PNorm = 55.7958, GNorm = 1.3720, lr_0 = 1.0804e-04
Validation rmse logD = 0.588654
Validation R2 logD = 0.776863
Epoch 88
Train function
Loss = 3.2563e-04, PNorm = 55.7997, GNorm = 3.1704, lr_0 = 1.0804e-04
Loss = 2.6480e-04, PNorm = 55.8031, GNorm = 1.7344, lr_0 = 1.0804e-04
Loss = 2.6861e-04, PNorm = 55.8057, GNorm = 1.0364, lr_0 = 1.0804e-04
Loss = 2.7140e-04, PNorm = 55.8084, GNorm = 1.9542, lr_0 = 1.0804e-04
Loss = 3.1756e-04, PNorm = 55.8108, GNorm = 1.6474, lr_0 = 1.0804e-04
Loss = 2.8462e-04, PNorm = 55.8126, GNorm = 2.7240, lr_0 = 1.0804e-04
Validation rmse logD = 0.560540
Validation R2 logD = 0.797668
Epoch 89
Train function
Loss = 2.8779e-04, PNorm = 55.8154, GNorm = 0.6090, lr_0 = 1.0804e-04
Loss = 2.8099e-04, PNorm = 55.8180, GNorm = 2.0248, lr_0 = 1.0804e-04
Loss = 2.4177e-04, PNorm = 55.8213, GNorm = 1.0283, lr_0 = 1.0804e-04
Loss = 2.8572e-04, PNorm = 55.8237, GNorm = 0.5503, lr_0 = 1.0804e-04
Loss = 2.6124e-04, PNorm = 55.8260, GNorm = 1.3677, lr_0 = 1.0804e-04
Validation rmse logD = 0.559206
Validation R2 logD = 0.798629
Epoch 90
Train function
Loss = 4.1987e-04, PNorm = 55.8291, GNorm = 1.5950, lr_0 = 1.0804e-04
Loss = 2.0306e-04, PNorm = 55.8307, GNorm = 1.4243, lr_0 = 1.0804e-04
Loss = 2.6045e-04, PNorm = 55.8331, GNorm = 1.8729, lr_0 = 1.0804e-04
Loss = 2.5792e-04, PNorm = 55.8342, GNorm = 0.9406, lr_0 = 1.0804e-04
Loss = 2.3645e-04, PNorm = 55.8362, GNorm = 1.5492, lr_0 = 1.0804e-04
Loss = 2.5646e-04, PNorm = 55.8386, GNorm = 1.4064, lr_0 = 1.0804e-04
Validation rmse logD = 0.561842
Validation R2 logD = 0.796727
Epoch 91
Train function
Loss = 1.9653e-04, PNorm = 55.8413, GNorm = 1.2320, lr_0 = 1.0804e-04
Loss = 2.5413e-04, PNorm = 55.8444, GNorm = 0.6504, lr_0 = 1.0804e-04
Loss = 3.0662e-04, PNorm = 55.8465, GNorm = 0.7975, lr_0 = 1.0804e-04
Loss = 2.8762e-04, PNorm = 55.8480, GNorm = 0.8031, lr_0 = 1.0804e-04
Loss = 2.9046e-04, PNorm = 55.8507, GNorm = 0.6995, lr_0 = 1.0804e-04
Loss = 3.0177e-04, PNorm = 55.8535, GNorm = 0.8866, lr_0 = 1.0804e-04
Validation rmse logD = 0.569640
Validation R2 logD = 0.791045
Epoch 92
Train function
Loss = 3.2468e-04, PNorm = 55.8554, GNorm = 2.5485, lr_0 = 1.0804e-04
Loss = 4.8970e-04, PNorm = 55.8579, GNorm = 3.6718, lr_0 = 1.0804e-04
Loss = 3.4987e-04, PNorm = 55.8613, GNorm = 1.1113, lr_0 = 1.0804e-04
Loss = 2.9147e-04, PNorm = 55.8641, GNorm = 2.9472, lr_0 = 1.0804e-04
Loss = 2.8218e-04, PNorm = 55.8686, GNorm = 0.7613, lr_0 = 1.0804e-04
Validation rmse logD = 0.557714
Validation R2 logD = 0.799703
Epoch 93
Train function
Loss = 1.8363e-04, PNorm = 55.8721, GNorm = 0.8973, lr_0 = 1.0804e-04
Loss = 3.4570e-04, PNorm = 55.8737, GNorm = 1.8586, lr_0 = 1.0804e-04
Loss = 3.2517e-04, PNorm = 55.8753, GNorm = 2.6959, lr_0 = 1.0804e-04
Loss = 2.8630e-04, PNorm = 55.8772, GNorm = 1.0341, lr_0 = 1.0804e-04
Loss = 2.6424e-04, PNorm = 55.8799, GNorm = 1.1968, lr_0 = 1.0804e-04
Loss = 2.1686e-04, PNorm = 55.8834, GNorm = 0.9374, lr_0 = 1.0804e-04
Validation rmse logD = 0.558874
Validation R2 logD = 0.798868
Epoch 94
Train function
Loss = 2.3953e-04, PNorm = 55.8867, GNorm = 1.9249, lr_0 = 1.0804e-04
Loss = 3.2825e-04, PNorm = 55.8893, GNorm = 0.7306, lr_0 = 1.0804e-04
Loss = 2.5450e-04, PNorm = 55.8913, GNorm = 0.5785, lr_0 = 1.0804e-04
Loss = 2.6743e-04, PNorm = 55.8946, GNorm = 2.2871, lr_0 = 1.0804e-04
Loss = 2.8684e-04, PNorm = 55.8972, GNorm = 1.9855, lr_0 = 1.0804e-04
Loss = 2.8573e-04, PNorm = 55.9006, GNorm = 2.4115, lr_0 = 1.0804e-04
Validation rmse logD = 0.570876
Validation R2 logD = 0.790137
Epoch 95
Train function
Loss = 2.7325e-04, PNorm = 55.9042, GNorm = 0.7463, lr_0 = 1.0804e-04
Loss = 2.3896e-04, PNorm = 55.9067, GNorm = 3.0779, lr_0 = 1.0804e-04
Loss = 4.2275e-04, PNorm = 55.9083, GNorm = 1.0556, lr_0 = 1.0804e-04
Loss = 2.4496e-04, PNorm = 55.9112, GNorm = 0.7864, lr_0 = 1.0804e-04
Loss = 2.6434e-04, PNorm = 55.9138, GNorm = 1.1031, lr_0 = 1.0804e-04
Validation rmse logD = 0.565592
Validation R2 logD = 0.794004
Epoch 96
Train function
Loss = 1.6728e-04, PNorm = 55.9149, GNorm = 0.5647, lr_0 = 1.0804e-04
Loss = 2.2674e-04, PNorm = 55.9181, GNorm = 1.4869, lr_0 = 1.0804e-04
Loss = 2.1729e-04, PNorm = 55.9210, GNorm = 1.0481, lr_0 = 1.0804e-04
Loss = 3.1300e-04, PNorm = 55.9233, GNorm = 1.9589, lr_0 = 1.0804e-04
Loss = 4.3319e-04, PNorm = 55.9257, GNorm = 2.8486, lr_0 = 1.0804e-04
Loss = 3.5374e-04, PNorm = 55.9288, GNorm = 3.6943, lr_0 = 1.0804e-04
Validation rmse logD = 0.603946
Validation R2 logD = 0.765118
Epoch 97
Train function
Loss = 5.9751e-04, PNorm = 55.9321, GNorm = 3.3927, lr_0 = 1.0804e-04
Loss = 5.0328e-04, PNorm = 55.9325, GNorm = 2.2293, lr_0 = 1.0804e-04
Loss = 3.1572e-04, PNorm = 55.9363, GNorm = 1.6940, lr_0 = 1.0804e-04
Loss = 3.4973e-04, PNorm = 55.9406, GNorm = 2.7956, lr_0 = 1.0804e-04
Loss = 3.8299e-04, PNorm = 55.9432, GNorm = 3.4437, lr_0 = 1.0804e-04
Loss = 4.1711e-04, PNorm = 55.9467, GNorm = 2.0237, lr_0 = 1.0804e-04
Validation rmse logD = 0.555115
Validation R2 logD = 0.801565
Epoch 98
Train function
Loss = 2.9067e-04, PNorm = 55.9498, GNorm = 1.9383, lr_0 = 1.0804e-04
Loss = 3.0427e-04, PNorm = 55.9526, GNorm = 2.3082, lr_0 = 1.0804e-04
Loss = 3.5389e-04, PNorm = 55.9550, GNorm = 4.4338, lr_0 = 1.0804e-04
Loss = 4.6562e-04, PNorm = 55.9587, GNorm = 3.1278, lr_0 = 1.0804e-04
Loss = 4.3266e-04, PNorm = 55.9621, GNorm = 3.7563, lr_0 = 1.0804e-04
Validation rmse logD = 0.561728
Validation R2 logD = 0.796809
Epoch 99
Train function
Loss = 2.5440e-04, PNorm = 55.9658, GNorm = 0.7279, lr_0 = 1.0804e-04
Loss = 3.7234e-04, PNorm = 55.9705, GNorm = 2.3645, lr_0 = 1.0804e-04
Loss = 2.2598e-04, PNorm = 55.9739, GNorm = 0.5696, lr_0 = 1.0804e-04
Loss = 2.8301e-04, PNorm = 55.9754, GNorm = 3.6493, lr_0 = 1.0804e-04
Loss = 2.8252e-04, PNorm = 55.9779, GNorm = 2.0316, lr_0 = 1.0804e-04
Loss = 2.8417e-04, PNorm = 55.9815, GNorm = 0.7846, lr_0 = 1.0804e-04
Validation rmse logD = 0.566720
Validation R2 logD = 0.793181
Model 0 best validation rmse = 0.553476 on epoch 78
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.538159
Model 0 test R2 logD = 0.793276
Ensemble test rmse  logD= 0.538159
Ensemble test R2  logD= 0.793276
Fold 4
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_4',
 'save_smiles_splits': False,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.0344e-02, PNorm = 52.9125, GNorm = 5.6213, lr_0 = 1.0804e-04
Loss = 1.8941e-02, PNorm = 52.9151, GNorm = 3.3038, lr_0 = 1.0804e-04
Loss = 1.6229e-02, PNorm = 52.9187, GNorm = 2.7112, lr_0 = 1.0804e-04
Loss = 1.6144e-02, PNorm = 52.9221, GNorm = 1.8643, lr_0 = 1.0804e-04
Loss = 1.5308e-02, PNorm = 52.9261, GNorm = 14.6685, lr_0 = 1.0804e-04
Validation rmse logD = 1.032871
Validation R2 logD = 0.333528
Epoch 1
Train function
Loss = 1.5036e-02, PNorm = 52.9291, GNorm = 11.5736, lr_0 = 1.0804e-04
Loss = 1.3261e-02, PNorm = 52.9324, GNorm = 2.1837, lr_0 = 1.0804e-04
Loss = 1.5061e-02, PNorm = 52.9359, GNorm = 8.8702, lr_0 = 1.0804e-04
Loss = 1.3047e-02, PNorm = 52.9398, GNorm = 2.6784, lr_0 = 1.0804e-04
Loss = 1.3624e-02, PNorm = 52.9448, GNorm = 4.7279, lr_0 = 1.0804e-04
Loss = 1.4229e-02, PNorm = 52.9502, GNorm = 4.2447, lr_0 = 1.0804e-04
Validation rmse logD = 0.965754
Validation R2 logD = 0.417330
Epoch 2
Train function
Loss = 1.1685e-02, PNorm = 52.9564, GNorm = 4.2655, lr_0 = 1.0804e-04
Loss = 1.2680e-02, PNorm = 52.9626, GNorm = 1.5096, lr_0 = 1.0804e-04
Loss = 1.1851e-02, PNorm = 52.9687, GNorm = 2.6568, lr_0 = 1.0804e-04
Loss = 1.2219e-02, PNorm = 52.9759, GNorm = 2.7544, lr_0 = 1.0804e-04
Loss = 1.0939e-02, PNorm = 52.9840, GNorm = 3.7109, lr_0 = 1.0804e-04
Validation rmse logD = 0.920072
Validation R2 logD = 0.471148
Epoch 3
Train function
Loss = 1.1147e-02, PNorm = 52.9931, GNorm = 2.3242, lr_0 = 1.0804e-04
Loss = 1.0190e-02, PNorm = 53.0005, GNorm = 5.2167, lr_0 = 1.0804e-04
Loss = 1.0437e-02, PNorm = 53.0094, GNorm = 1.6822, lr_0 = 1.0804e-04
Loss = 9.2964e-03, PNorm = 53.0186, GNorm = 2.7495, lr_0 = 1.0804e-04
Loss = 1.1064e-02, PNorm = 53.0276, GNorm = 5.3823, lr_0 = 1.0804e-04
Loss = 1.0444e-02, PNorm = 53.0358, GNorm = 5.5602, lr_0 = 1.0804e-04
Validation rmse logD = 0.883938
Validation R2 logD = 0.511872
Epoch 4
Train function
Loss = 1.0793e-02, PNorm = 53.0439, GNorm = 4.0477, lr_0 = 1.0804e-04
Loss = 1.0445e-02, PNorm = 53.0510, GNorm = 5.3705, lr_0 = 1.0804e-04
Loss = 9.7240e-03, PNorm = 53.0599, GNorm = 6.6685, lr_0 = 1.0804e-04
Loss = 9.4719e-03, PNorm = 53.0681, GNorm = 2.4243, lr_0 = 1.0804e-04
Loss = 8.6776e-03, PNorm = 53.0764, GNorm = 3.1846, lr_0 = 1.0804e-04
Loss = 8.4686e-03, PNorm = 53.0876, GNorm = 1.8810, lr_0 = 1.0804e-04
Validation rmse logD = 0.842361
Validation R2 logD = 0.556711
Epoch 5
Train function
Loss = 8.0873e-03, PNorm = 53.0973, GNorm = 13.2845, lr_0 = 1.0804e-04
Loss = 9.1252e-03, PNorm = 53.1063, GNorm = 3.6430, lr_0 = 1.0804e-04
Loss = 8.3772e-03, PNorm = 53.1163, GNorm = 5.5581, lr_0 = 1.0804e-04
Loss = 6.9442e-03, PNorm = 53.1272, GNorm = 1.8695, lr_0 = 1.0804e-04
Loss = 9.0205e-03, PNorm = 53.1366, GNorm = 2.3686, lr_0 = 1.0804e-04
Validation rmse logD = 0.894730
Validation R2 logD = 0.499881
Epoch 6
Train function
Loss = 1.0364e-02, PNorm = 53.1466, GNorm = 13.7497, lr_0 = 1.0804e-04
Loss = 8.1571e-03, PNorm = 53.1561, GNorm = 2.8500, lr_0 = 1.0804e-04
Loss = 8.2010e-03, PNorm = 53.1663, GNorm = 2.3217, lr_0 = 1.0804e-04
Loss = 7.7912e-03, PNorm = 53.1764, GNorm = 7.6310, lr_0 = 1.0804e-04
Loss = 7.8686e-03, PNorm = 53.1869, GNorm = 9.8416, lr_0 = 1.0804e-04
Loss = 6.4171e-03, PNorm = 53.1961, GNorm = 4.1394, lr_0 = 1.0804e-04
Validation rmse logD = 0.778620
Validation R2 logD = 0.621260
Epoch 7
Train function
Loss = 7.8648e-03, PNorm = 53.2067, GNorm = 2.2248, lr_0 = 1.0804e-04
Loss = 7.8461e-03, PNorm = 53.2185, GNorm = 1.7882, lr_0 = 1.0804e-04
Loss = 7.1333e-03, PNorm = 53.2278, GNorm = 12.7982, lr_0 = 1.0804e-04
Loss = 6.7750e-03, PNorm = 53.2373, GNorm = 4.7794, lr_0 = 1.0804e-04
Loss = 6.7465e-03, PNorm = 53.2462, GNorm = 6.3859, lr_0 = 1.0804e-04
Loss = 6.2412e-03, PNorm = 53.2554, GNorm = 3.5653, lr_0 = 1.0804e-04
Validation rmse logD = 0.784816
Validation R2 logD = 0.615208
Epoch 8
Train function
Loss = 5.7925e-03, PNorm = 53.2625, GNorm = 2.0170, lr_0 = 1.0804e-04
Loss = 5.8177e-03, PNorm = 53.2732, GNorm = 2.1087, lr_0 = 1.0804e-04
Loss = 6.7397e-03, PNorm = 53.2859, GNorm = 2.5594, lr_0 = 1.0804e-04
Loss = 5.5660e-03, PNorm = 53.2955, GNorm = 8.2053, lr_0 = 1.0804e-04
Loss = 6.6565e-03, PNorm = 53.3048, GNorm = 2.0741, lr_0 = 1.0804e-04
Validation rmse logD = 0.760194
Validation R2 logD = 0.638974
Epoch 9
Train function
Loss = 4.1242e-03, PNorm = 53.3149, GNorm = 4.0992, lr_0 = 1.0804e-04
Loss = 5.8289e-03, PNorm = 53.3231, GNorm = 10.3214, lr_0 = 1.0804e-04
Loss = 6.6879e-03, PNorm = 53.3316, GNorm = 5.7281, lr_0 = 1.0804e-04
Loss = 5.9740e-03, PNorm = 53.3422, GNorm = 8.3280, lr_0 = 1.0804e-04
Loss = 6.4856e-03, PNorm = 53.3520, GNorm = 11.1543, lr_0 = 1.0804e-04
Loss = 4.9712e-03, PNorm = 53.3611, GNorm = 1.5694, lr_0 = 1.0804e-04
Validation rmse logD = 0.743436
Validation R2 logD = 0.654716
Epoch 10
Train function
Loss = 5.7849e-03, PNorm = 53.3697, GNorm = 2.8557, lr_0 = 1.0804e-04
Loss = 5.3239e-03, PNorm = 53.3785, GNorm = 1.7555, lr_0 = 1.0804e-04
Loss = 5.0081e-03, PNorm = 53.3880, GNorm = 2.4290, lr_0 = 1.0804e-04
Loss = 6.3603e-03, PNorm = 53.3966, GNorm = 7.8502, lr_0 = 1.0804e-04
Loss = 5.3914e-03, PNorm = 53.4037, GNorm = 6.8987, lr_0 = 1.0804e-04
Loss = 5.8552e-03, PNorm = 53.4128, GNorm = 4.2116, lr_0 = 1.0804e-04
Validation rmse logD = 0.797125
Validation R2 logD = 0.603043
Epoch 11
Train function
Loss = 5.4922e-03, PNorm = 53.4194, GNorm = 1.6929, lr_0 = 1.0804e-04
Loss = 5.5199e-03, PNorm = 53.4285, GNorm = 7.0408, lr_0 = 1.0804e-04
Loss = 5.5383e-03, PNorm = 53.4364, GNorm = 6.1209, lr_0 = 1.0804e-04
Loss = 7.2289e-03, PNorm = 53.4452, GNorm = 4.5361, lr_0 = 1.0804e-04
Loss = 5.4938e-03, PNorm = 53.4545, GNorm = 3.9682, lr_0 = 1.0804e-04
Validation rmse logD = 0.772953
Validation R2 logD = 0.626753
Epoch 12
Train function
Loss = 5.8634e-03, PNorm = 53.4643, GNorm = 7.9049, lr_0 = 1.0804e-04
Loss = 4.9777e-03, PNorm = 53.4738, GNorm = 3.5199, lr_0 = 1.0804e-04
Loss = 5.7941e-03, PNorm = 53.4831, GNorm = 2.2758, lr_0 = 1.0804e-04
Loss = 5.1639e-03, PNorm = 53.4915, GNorm = 4.3890, lr_0 = 1.0804e-04
Loss = 4.6124e-03, PNorm = 53.5003, GNorm = 5.4450, lr_0 = 1.0804e-04
Loss = 4.5386e-03, PNorm = 53.5086, GNorm = 3.7092, lr_0 = 1.0804e-04
Validation rmse logD = 0.743620
Validation R2 logD = 0.654544
Epoch 13
Train function
Loss = 4.3286e-03, PNorm = 53.5151, GNorm = 7.0589, lr_0 = 1.0804e-04
Loss = 4.7633e-03, PNorm = 53.5223, GNorm = 3.0737, lr_0 = 1.0804e-04
Loss = 4.2245e-03, PNorm = 53.5301, GNorm = 3.1305, lr_0 = 1.0804e-04
Loss = 4.5044e-03, PNorm = 53.5398, GNorm = 4.2969, lr_0 = 1.0804e-04
Loss = 4.4605e-03, PNorm = 53.5484, GNorm = 3.1459, lr_0 = 1.0804e-04
Loss = 5.8104e-03, PNorm = 53.5554, GNorm = 5.3139, lr_0 = 1.0804e-04
Validation rmse logD = 0.773719
Validation R2 logD = 0.626013
Epoch 14
Train function
Loss = 4.8391e-03, PNorm = 53.5626, GNorm = 2.7854, lr_0 = 1.0804e-04
Loss = 4.5718e-03, PNorm = 53.5701, GNorm = 7.3779, lr_0 = 1.0804e-04
Loss = 3.6333e-03, PNorm = 53.5790, GNorm = 4.5050, lr_0 = 1.0804e-04
Loss = 4.0380e-03, PNorm = 53.5888, GNorm = 6.7557, lr_0 = 1.0804e-04
Loss = 4.4989e-03, PNorm = 53.5969, GNorm = 2.6472, lr_0 = 1.0804e-04
Validation rmse logD = 0.727606
Validation R2 logD = 0.669263
Epoch 15
Train function
Loss = 3.7025e-03, PNorm = 53.6081, GNorm = 3.9643, lr_0 = 1.0804e-04
Loss = 4.3196e-03, PNorm = 53.6159, GNorm = 2.0057, lr_0 = 1.0804e-04
Loss = 4.2402e-03, PNorm = 53.6248, GNorm = 5.7526, lr_0 = 1.0804e-04
Loss = 3.8792e-03, PNorm = 53.6337, GNorm = 3.4540, lr_0 = 1.0804e-04
Loss = 3.8504e-03, PNorm = 53.6404, GNorm = 3.7400, lr_0 = 1.0804e-04
Loss = 3.9840e-03, PNorm = 53.6478, GNorm = 3.4785, lr_0 = 1.0804e-04
Validation rmse logD = 0.711517
Validation R2 logD = 0.683728
Epoch 16
Train function
Loss = 3.6292e-03, PNorm = 53.6574, GNorm = 5.4562, lr_0 = 1.0804e-04
Loss = 4.0085e-03, PNorm = 53.6652, GNorm = 8.8857, lr_0 = 1.0804e-04
Loss = 3.5812e-03, PNorm = 53.6721, GNorm = 6.2661, lr_0 = 1.0804e-04
Loss = 3.9542e-03, PNorm = 53.6812, GNorm = 1.5104, lr_0 = 1.0804e-04
Loss = 3.6228e-03, PNorm = 53.6898, GNorm = 5.8121, lr_0 = 1.0804e-04
Loss = 4.5042e-03, PNorm = 53.6984, GNorm = 3.4789, lr_0 = 1.0804e-04
Validation rmse logD = 0.695851
Validation R2 logD = 0.697502
Epoch 17
Train function
Loss = 3.4342e-03, PNorm = 53.7063, GNorm = 3.4279, lr_0 = 1.0804e-04
Loss = 4.0936e-03, PNorm = 53.7164, GNorm = 4.6103, lr_0 = 1.0804e-04
Loss = 4.1150e-03, PNorm = 53.7238, GNorm = 2.1933, lr_0 = 1.0804e-04
Loss = 3.8775e-03, PNorm = 53.7315, GNorm = 1.8984, lr_0 = 1.0804e-04
Loss = 4.2460e-03, PNorm = 53.7404, GNorm = 2.6764, lr_0 = 1.0804e-04
Validation rmse logD = 0.694208
Validation R2 logD = 0.698929
Epoch 18
Train function
Loss = 4.0022e-03, PNorm = 53.7497, GNorm = 5.4441, lr_0 = 1.0804e-04
Loss = 3.8397e-03, PNorm = 53.7591, GNorm = 2.6694, lr_0 = 1.0804e-04
Loss = 3.5152e-03, PNorm = 53.7686, GNorm = 1.8023, lr_0 = 1.0804e-04
Loss = 3.3206e-03, PNorm = 53.7775, GNorm = 1.4326, lr_0 = 1.0804e-04
Loss = 3.6079e-03, PNorm = 53.7846, GNorm = 2.2455, lr_0 = 1.0804e-04
Loss = 3.4721e-03, PNorm = 53.7921, GNorm = 1.9478, lr_0 = 1.0804e-04
Validation rmse logD = 0.683073
Validation R2 logD = 0.708510
Epoch 19
Train function
Loss = 2.4883e-03, PNorm = 53.8003, GNorm = 3.9122, lr_0 = 1.0804e-04
Loss = 3.6689e-03, PNorm = 53.8081, GNorm = 5.3011, lr_0 = 1.0804e-04
Loss = 3.5473e-03, PNorm = 53.8157, GNorm = 8.3599, lr_0 = 1.0804e-04
Loss = 3.8849e-03, PNorm = 53.8234, GNorm = 7.0871, lr_0 = 1.0804e-04
Loss = 3.6747e-03, PNorm = 53.8313, GNorm = 5.7937, lr_0 = 1.0804e-04
Loss = 3.7039e-03, PNorm = 53.8402, GNorm = 10.1827, lr_0 = 1.0804e-04
Validation rmse logD = 0.692683
Validation R2 logD = 0.700250
Epoch 20
Train function
Loss = 4.0748e-03, PNorm = 53.8478, GNorm = 10.8848, lr_0 = 1.0804e-04
Loss = 4.5202e-03, PNorm = 53.8546, GNorm = 3.3794, lr_0 = 1.0804e-04
Loss = 4.1363e-03, PNorm = 53.8637, GNorm = 3.7367, lr_0 = 1.0804e-04
Loss = 3.3430e-03, PNorm = 53.8716, GNorm = 3.4056, lr_0 = 1.0804e-04
Loss = 3.0834e-03, PNorm = 53.8807, GNorm = 5.7840, lr_0 = 1.0804e-04
Validation rmse logD = 0.691985
Validation R2 logD = 0.700854
Epoch 21
Train function
Loss = 1.9850e-03, PNorm = 53.8912, GNorm = 2.2335, lr_0 = 1.0804e-04
Loss = 2.9543e-03, PNorm = 53.8975, GNorm = 3.0147, lr_0 = 1.0804e-04
Loss = 2.9154e-03, PNorm = 53.9044, GNorm = 6.5447, lr_0 = 1.0804e-04
Loss = 3.1568e-03, PNorm = 53.9121, GNorm = 3.2945, lr_0 = 1.0804e-04
Loss = 3.4563e-03, PNorm = 53.9198, GNorm = 3.7194, lr_0 = 1.0804e-04
Loss = 3.5555e-03, PNorm = 53.9282, GNorm = 3.2528, lr_0 = 1.0804e-04
Validation rmse logD = 0.682632
Validation R2 logD = 0.708886
Epoch 22
Train function
Loss = 3.5799e-03, PNorm = 53.9351, GNorm = 5.8612, lr_0 = 1.0804e-04
Loss = 3.7509e-03, PNorm = 53.9421, GNorm = 7.6536, lr_0 = 1.0804e-04
Loss = 3.7390e-03, PNorm = 53.9505, GNorm = 5.8340, lr_0 = 1.0804e-04
Loss = 2.7129e-03, PNorm = 53.9598, GNorm = 2.4477, lr_0 = 1.0804e-04
Loss = 3.2470e-03, PNorm = 53.9687, GNorm = 3.6409, lr_0 = 1.0804e-04
Loss = 3.0827e-03, PNorm = 53.9779, GNorm = 5.4305, lr_0 = 1.0804e-04
Validation rmse logD = 0.715641
Validation R2 logD = 0.680052
Epoch 23
Train function
Loss = 3.4666e-03, PNorm = 53.9867, GNorm = 10.4880, lr_0 = 1.0804e-04
Loss = 2.5917e-03, PNorm = 53.9961, GNorm = 9.0192, lr_0 = 1.0804e-04
Loss = 3.2528e-03, PNorm = 54.0036, GNorm = 6.5043, lr_0 = 1.0804e-04
Loss = 2.8758e-03, PNorm = 54.0113, GNorm = 1.9640, lr_0 = 1.0804e-04
Loss = 2.7833e-03, PNorm = 54.0193, GNorm = 5.2643, lr_0 = 1.0804e-04
Validation rmse logD = 0.710201
Validation R2 logD = 0.684897
Epoch 24
Train function
Loss = 3.0134e-03, PNorm = 54.0247, GNorm = 6.1956, lr_0 = 1.0804e-04
Loss = 3.2545e-03, PNorm = 54.0331, GNorm = 2.0474, lr_0 = 1.0804e-04
Loss = 2.9066e-03, PNorm = 54.0425, GNorm = 4.9237, lr_0 = 1.0804e-04
Loss = 3.2048e-03, PNorm = 54.0500, GNorm = 2.5621, lr_0 = 1.0804e-04
Loss = 2.9327e-03, PNorm = 54.0584, GNorm = 4.7152, lr_0 = 1.0804e-04
Loss = 2.5380e-03, PNorm = 54.0669, GNorm = 2.1053, lr_0 = 1.0804e-04
Validation rmse logD = 0.682908
Validation R2 logD = 0.708650
Epoch 25
Train function
Loss = 2.4051e-03, PNorm = 54.0747, GNorm = 1.7788, lr_0 = 1.0804e-04
Loss = 2.5798e-03, PNorm = 54.0823, GNorm = 7.7785, lr_0 = 1.0804e-04
Loss = 2.4474e-03, PNorm = 54.0893, GNorm = 3.8993, lr_0 = 1.0804e-04
Loss = 3.0928e-03, PNorm = 54.0961, GNorm = 2.1682, lr_0 = 1.0804e-04
Loss = 2.6438e-03, PNorm = 54.1048, GNorm = 4.0423, lr_0 = 1.0804e-04
Loss = 2.8995e-03, PNorm = 54.1123, GNorm = 2.7033, lr_0 = 1.0804e-04
Validation rmse logD = 0.689577
Validation R2 logD = 0.702932
Epoch 26
Train function
Loss = 2.6806e-03, PNorm = 54.1204, GNorm = 10.0122, lr_0 = 1.0804e-04
Loss = 2.9921e-03, PNorm = 54.1270, GNorm = 6.2789, lr_0 = 1.0804e-04
Loss = 2.8346e-03, PNorm = 54.1359, GNorm = 7.3686, lr_0 = 1.0804e-04
Loss = 2.5305e-03, PNorm = 54.1437, GNorm = 3.0497, lr_0 = 1.0804e-04
Loss = 2.3511e-03, PNorm = 54.1513, GNorm = 1.5425, lr_0 = 1.0804e-04
Validation rmse logD = 0.685761
Validation R2 logD = 0.706211
Epoch 27
Train function
Loss = 2.5658e-03, PNorm = 54.1604, GNorm = 5.5408, lr_0 = 1.0804e-04
Loss = 2.0809e-03, PNorm = 54.1684, GNorm = 1.7744, lr_0 = 1.0804e-04
Loss = 2.0333e-03, PNorm = 54.1768, GNorm = 7.4323, lr_0 = 1.0804e-04
Loss = 2.4361e-03, PNorm = 54.1838, GNorm = 3.5852, lr_0 = 1.0804e-04
Loss = 2.4806e-03, PNorm = 54.1906, GNorm = 2.0696, lr_0 = 1.0804e-04
Loss = 2.5590e-03, PNorm = 54.1982, GNorm = 3.2485, lr_0 = 1.0804e-04
Validation rmse logD = 0.678768
Validation R2 logD = 0.712172
Epoch 28
Train function
Loss = 2.8638e-03, PNorm = 54.2052, GNorm = 2.5473, lr_0 = 1.0804e-04
Loss = 2.3470e-03, PNorm = 54.2138, GNorm = 2.2976, lr_0 = 1.0804e-04
Loss = 2.2096e-03, PNorm = 54.2223, GNorm = 3.5246, lr_0 = 1.0804e-04
Loss = 2.2547e-03, PNorm = 54.2298, GNorm = 3.2393, lr_0 = 1.0804e-04
Loss = 2.0535e-03, PNorm = 54.2359, GNorm = 1.6563, lr_0 = 1.0804e-04
Loss = 2.1805e-03, PNorm = 54.2423, GNorm = 3.3722, lr_0 = 1.0804e-04
Validation rmse logD = 0.678076
Validation R2 logD = 0.712758
Epoch 29
Train function
Loss = 1.7449e-03, PNorm = 54.2498, GNorm = 1.3567, lr_0 = 1.0804e-04
Loss = 2.0302e-03, PNorm = 54.2566, GNorm = 2.9107, lr_0 = 1.0804e-04
Loss = 2.1473e-03, PNorm = 54.2635, GNorm = 4.3262, lr_0 = 1.0804e-04
Loss = 1.8840e-03, PNorm = 54.2706, GNorm = 4.6190, lr_0 = 1.0804e-04
Loss = 2.3406e-03, PNorm = 54.2784, GNorm = 3.4742, lr_0 = 1.0804e-04
Validation rmse logD = 0.720558
Validation R2 logD = 0.675639
Epoch 30
Train function
Loss = 3.0364e-03, PNorm = 54.2883, GNorm = 9.0211, lr_0 = 1.0804e-04
Loss = 2.2820e-03, PNorm = 54.2958, GNorm = 1.9678, lr_0 = 1.0804e-04
Loss = 2.2302e-03, PNorm = 54.3035, GNorm = 2.0208, lr_0 = 1.0804e-04
Loss = 1.8251e-03, PNorm = 54.3119, GNorm = 2.2838, lr_0 = 1.0804e-04
Loss = 1.9743e-03, PNorm = 54.3192, GNorm = 2.4832, lr_0 = 1.0804e-04
Loss = 2.0383e-03, PNorm = 54.3279, GNorm = 4.1563, lr_0 = 1.0804e-04
Validation rmse logD = 0.701307
Validation R2 logD = 0.692739
Epoch 31
Train function
Loss = 1.9850e-03, PNorm = 54.3357, GNorm = 6.6082, lr_0 = 1.0804e-04
Loss = 1.8807e-03, PNorm = 54.3425, GNorm = 2.4249, lr_0 = 1.0804e-04
Loss = 2.1250e-03, PNorm = 54.3504, GNorm = 2.3458, lr_0 = 1.0804e-04
Loss = 1.8239e-03, PNorm = 54.3584, GNorm = 3.2431, lr_0 = 1.0804e-04
Loss = 1.9281e-03, PNorm = 54.3651, GNorm = 6.7958, lr_0 = 1.0804e-04
Loss = 1.7151e-03, PNorm = 54.3723, GNorm = 2.7456, lr_0 = 1.0804e-04
Validation rmse logD = 0.675379
Validation R2 logD = 0.715040
Epoch 32
Train function
Loss = 1.4947e-03, PNorm = 54.3790, GNorm = 1.9585, lr_0 = 1.0804e-04
Loss = 1.9358e-03, PNorm = 54.3861, GNorm = 3.2774, lr_0 = 1.0804e-04
Loss = 1.7966e-03, PNorm = 54.3924, GNorm = 3.0254, lr_0 = 1.0804e-04
Loss = 2.0365e-03, PNorm = 54.4007, GNorm = 2.1900, lr_0 = 1.0804e-04
Loss = 2.2977e-03, PNorm = 54.4071, GNorm = 8.9716, lr_0 = 1.0804e-04
Validation rmse logD = 0.698676
Validation R2 logD = 0.695041
Epoch 33
Train function
Loss = 1.7200e-03, PNorm = 54.4138, GNorm = 3.2658, lr_0 = 1.0804e-04
Loss = 2.0212e-03, PNorm = 54.4195, GNorm = 2.3451, lr_0 = 1.0804e-04
Loss = 1.8450e-03, PNorm = 54.4261, GNorm = 2.6988, lr_0 = 1.0804e-04
Loss = 1.9506e-03, PNorm = 54.4335, GNorm = 1.9418, lr_0 = 1.0804e-04
Loss = 1.8538e-03, PNorm = 54.4428, GNorm = 4.1500, lr_0 = 1.0804e-04
Loss = 1.9796e-03, PNorm = 54.4489, GNorm = 3.9580, lr_0 = 1.0804e-04
Validation rmse logD = 0.678431
Validation R2 logD = 0.712458
Epoch 34
Train function
Loss = 1.5638e-03, PNorm = 54.4564, GNorm = 1.6602, lr_0 = 1.0804e-04
Loss = 1.5937e-03, PNorm = 54.4634, GNorm = 2.7174, lr_0 = 1.0804e-04
Loss = 2.1584e-03, PNorm = 54.4695, GNorm = 6.7014, lr_0 = 1.0804e-04
Loss = 1.7773e-03, PNorm = 54.4764, GNorm = 1.3639, lr_0 = 1.0804e-04
Loss = 1.6319e-03, PNorm = 54.4836, GNorm = 1.2656, lr_0 = 1.0804e-04
Loss = 1.8318e-03, PNorm = 54.4916, GNorm = 5.6517, lr_0 = 1.0804e-04
Validation rmse logD = 0.683159
Validation R2 logD = 0.708436
Epoch 35
Train function
Loss = 1.9298e-03, PNorm = 54.4992, GNorm = 7.5860, lr_0 = 1.0804e-04
Loss = 2.1256e-03, PNorm = 54.5054, GNorm = 8.2170, lr_0 = 1.0804e-04
Loss = 1.6900e-03, PNorm = 54.5146, GNorm = 2.1343, lr_0 = 1.0804e-04
Loss = 1.6598e-03, PNorm = 54.5232, GNorm = 3.4279, lr_0 = 1.0804e-04
Loss = 1.8708e-03, PNorm = 54.5303, GNorm = 2.1825, lr_0 = 1.0804e-04
Validation rmse logD = 0.684462
Validation R2 logD = 0.707323
Epoch 36
Train function
Loss = 1.6937e-03, PNorm = 54.5377, GNorm = 1.6327, lr_0 = 1.0804e-04
Loss = 1.3335e-03, PNorm = 54.5436, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 1.5577e-03, PNorm = 54.5482, GNorm = 2.8342, lr_0 = 1.0804e-04
Loss = 1.3662e-03, PNorm = 54.5547, GNorm = 1.3589, lr_0 = 1.0804e-04
Loss = 1.5452e-03, PNorm = 54.5610, GNorm = 1.8707, lr_0 = 1.0804e-04
Loss = 2.0141e-03, PNorm = 54.5680, GNorm = 2.5758, lr_0 = 1.0804e-04
Validation rmse logD = 0.692000
Validation R2 logD = 0.700841
Epoch 37
Train function
Loss = 1.6027e-03, PNorm = 54.5759, GNorm = 4.7953, lr_0 = 1.0804e-04
Loss = 1.4183e-03, PNorm = 54.5840, GNorm = 2.2158, lr_0 = 1.0804e-04
Loss = 1.5238e-03, PNorm = 54.5905, GNorm = 4.5465, lr_0 = 1.0804e-04
Loss = 1.7365e-03, PNorm = 54.5976, GNorm = 4.4614, lr_0 = 1.0804e-04
Loss = 1.4288e-03, PNorm = 54.6041, GNorm = 2.5285, lr_0 = 1.0804e-04
Loss = 1.6546e-03, PNorm = 54.6097, GNorm = 4.4969, lr_0 = 1.0804e-04
Validation rmse logD = 0.668590
Validation R2 logD = 0.720739
Epoch 38
Train function
Loss = 1.2978e-03, PNorm = 54.6172, GNorm = 2.7599, lr_0 = 1.0804e-04
Loss = 1.2909e-03, PNorm = 54.6234, GNorm = 2.1790, lr_0 = 1.0804e-04
Loss = 1.2561e-03, PNorm = 54.6303, GNorm = 2.2774, lr_0 = 1.0804e-04
Loss = 1.2394e-03, PNorm = 54.6362, GNorm = 2.9657, lr_0 = 1.0804e-04
Loss = 1.6160e-03, PNorm = 54.6431, GNorm = 2.8796, lr_0 = 1.0804e-04
Validation rmse logD = 0.677160
Validation R2 logD = 0.713534
Epoch 39
Train function
Loss = 1.6507e-03, PNorm = 54.6500, GNorm = 3.2977, lr_0 = 1.0804e-04
Loss = 1.0917e-03, PNorm = 54.6558, GNorm = 1.8195, lr_0 = 1.0804e-04
Loss = 1.1417e-03, PNorm = 54.6623, GNorm = 2.5571, lr_0 = 1.0804e-04
Loss = 1.1413e-03, PNorm = 54.6703, GNorm = 3.1154, lr_0 = 1.0804e-04
Loss = 1.4029e-03, PNorm = 54.6766, GNorm = 6.0892, lr_0 = 1.0804e-04
Loss = 1.4492e-03, PNorm = 54.6815, GNorm = 2.2452, lr_0 = 1.0804e-04
Validation rmse logD = 0.664834
Validation R2 logD = 0.723868
Epoch 40
Train function
Loss = 1.1711e-03, PNorm = 54.6863, GNorm = 4.1613, lr_0 = 1.0804e-04
Loss = 1.3478e-03, PNorm = 54.6926, GNorm = 3.5444, lr_0 = 1.0804e-04
Loss = 1.1338e-03, PNorm = 54.7001, GNorm = 1.6998, lr_0 = 1.0804e-04
Loss = 1.2544e-03, PNorm = 54.7071, GNorm = 1.6081, lr_0 = 1.0804e-04
Loss = 1.1854e-03, PNorm = 54.7131, GNorm = 1.9141, lr_0 = 1.0804e-04
Loss = 1.3799e-03, PNorm = 54.7196, GNorm = 2.6251, lr_0 = 1.0804e-04
Validation rmse logD = 0.694670
Validation R2 logD = 0.698528
Epoch 41
Train function
Loss = 1.3943e-03, PNorm = 54.7272, GNorm = 2.1677, lr_0 = 1.0804e-04
Loss = 1.4510e-03, PNorm = 54.7333, GNorm = 3.5750, lr_0 = 1.0804e-04
Loss = 1.3555e-03, PNorm = 54.7394, GNorm = 3.2416, lr_0 = 1.0804e-04
Loss = 1.2465e-03, PNorm = 54.7460, GNorm = 3.2622, lr_0 = 1.0804e-04
Loss = 1.0596e-03, PNorm = 54.7529, GNorm = 1.5395, lr_0 = 1.0804e-04
Validation rmse logD = 0.671821
Validation R2 logD = 0.718034
Epoch 42
Train function
Loss = 7.0827e-04, PNorm = 54.7606, GNorm = 1.6338, lr_0 = 1.0804e-04
Loss = 1.6027e-03, PNorm = 54.7673, GNorm = 8.2950, lr_0 = 1.0804e-04
Loss = 1.6184e-03, PNorm = 54.7742, GNorm = 7.7914, lr_0 = 1.0804e-04
Loss = 1.6929e-03, PNorm = 54.7808, GNorm = 5.2513, lr_0 = 1.0804e-04
Loss = 1.4459e-03, PNorm = 54.7887, GNorm = 3.0838, lr_0 = 1.0804e-04
Loss = 1.2174e-03, PNorm = 54.7941, GNorm = 6.6639, lr_0 = 1.0804e-04
Validation rmse logD = 0.666526
Validation R2 logD = 0.722461
Epoch 43
Train function
Loss = 1.1856e-03, PNorm = 54.7998, GNorm = 4.2787, lr_0 = 1.0804e-04
Loss = 1.0657e-03, PNorm = 54.8063, GNorm = 1.6800, lr_0 = 1.0804e-04
Loss = 1.4946e-03, PNorm = 54.8119, GNorm = 6.3543, lr_0 = 1.0804e-04
Loss = 1.3284e-03, PNorm = 54.8188, GNorm = 3.4880, lr_0 = 1.0804e-04
Loss = 1.1713e-03, PNorm = 54.8248, GNorm = 1.4487, lr_0 = 1.0804e-04
Loss = 1.1991e-03, PNorm = 54.8328, GNorm = 1.5874, lr_0 = 1.0804e-04
Validation rmse logD = 0.692613
Validation R2 logD = 0.700311
Epoch 44
Train function
Loss = 1.4869e-03, PNorm = 54.8389, GNorm = 5.3142, lr_0 = 1.0804e-04
Loss = 1.2675e-03, PNorm = 54.8440, GNorm = 5.4590, lr_0 = 1.0804e-04
Loss = 1.2154e-03, PNorm = 54.8503, GNorm = 1.5730, lr_0 = 1.0804e-04
Loss = 1.2527e-03, PNorm = 54.8582, GNorm = 1.3236, lr_0 = 1.0804e-04
Loss = 9.5758e-04, PNorm = 54.8640, GNorm = 1.2703, lr_0 = 1.0804e-04
Validation rmse logD = 0.659957
Validation R2 logD = 0.727905
Epoch 45
Train function
Loss = 1.1914e-03, PNorm = 54.8705, GNorm = 3.6497, lr_0 = 1.0804e-04
Loss = 9.9209e-04, PNorm = 54.8773, GNorm = 1.1819, lr_0 = 1.0804e-04
Loss = 1.0550e-03, PNorm = 54.8834, GNorm = 1.8066, lr_0 = 1.0804e-04
Loss = 1.0883e-03, PNorm = 54.8879, GNorm = 1.3260, lr_0 = 1.0804e-04
Loss = 1.0008e-03, PNorm = 54.8930, GNorm = 3.1818, lr_0 = 1.0804e-04
Loss = 9.7585e-04, PNorm = 54.8994, GNorm = 3.5975, lr_0 = 1.0804e-04
Validation rmse logD = 0.671435
Validation R2 logD = 0.718358
Epoch 46
Train function
Loss = 8.4095e-04, PNorm = 54.9053, GNorm = 2.5906, lr_0 = 1.0804e-04
Loss = 1.1728e-03, PNorm = 54.9106, GNorm = 4.5765, lr_0 = 1.0804e-04
Loss = 9.5766e-04, PNorm = 54.9150, GNorm = 1.5720, lr_0 = 1.0804e-04
Loss = 1.0309e-03, PNorm = 54.9208, GNorm = 1.5208, lr_0 = 1.0804e-04
Loss = 9.7386e-04, PNorm = 54.9269, GNorm = 3.4698, lr_0 = 1.0804e-04
Loss = 9.3127e-04, PNorm = 54.9340, GNorm = 1.1446, lr_0 = 1.0804e-04
Validation rmse logD = 0.671675
Validation R2 logD = 0.718157
Epoch 47
Train function
Loss = 7.5206e-04, PNorm = 54.9393, GNorm = 1.5411, lr_0 = 1.0804e-04
Loss = 8.8687e-04, PNorm = 54.9450, GNorm = 3.9491, lr_0 = 1.0804e-04
Loss = 8.9615e-04, PNorm = 54.9518, GNorm = 1.9095, lr_0 = 1.0804e-04
Loss = 1.1148e-03, PNorm = 54.9573, GNorm = 3.5226, lr_0 = 1.0804e-04
Loss = 1.3416e-03, PNorm = 54.9626, GNorm = 7.8969, lr_0 = 1.0804e-04
Validation rmse logD = 0.691050
Validation R2 logD = 0.701661
Epoch 48
Train function
Loss = 1.4328e-03, PNorm = 54.9689, GNorm = 7.7834, lr_0 = 1.0804e-04
Loss = 1.0198e-03, PNorm = 54.9744, GNorm = 2.7303, lr_0 = 1.0804e-04
Loss = 1.1358e-03, PNorm = 54.9808, GNorm = 2.1854, lr_0 = 1.0804e-04
Loss = 1.0313e-03, PNorm = 54.9885, GNorm = 3.0575, lr_0 = 1.0804e-04
Loss = 1.0300e-03, PNorm = 54.9951, GNorm = 2.8465, lr_0 = 1.0804e-04
Loss = 1.0085e-03, PNorm = 55.0007, GNorm = 2.6015, lr_0 = 1.0804e-04
Validation rmse logD = 0.681000
Validation R2 logD = 0.710276
Epoch 49
Train function
Loss = 9.7935e-04, PNorm = 55.0067, GNorm = 3.8754, lr_0 = 1.0804e-04
Loss = 9.5804e-04, PNorm = 55.0116, GNorm = 6.3943, lr_0 = 1.0804e-04
Loss = 9.2755e-04, PNorm = 55.0170, GNorm = 6.0386, lr_0 = 1.0804e-04
Loss = 1.1080e-03, PNorm = 55.0221, GNorm = 1.3259, lr_0 = 1.0804e-04
Loss = 9.4534e-04, PNorm = 55.0264, GNorm = 5.3295, lr_0 = 1.0804e-04
Loss = 1.2784e-03, PNorm = 55.0319, GNorm = 3.7727, lr_0 = 1.0804e-04
Validation rmse logD = 0.687031
Validation R2 logD = 0.705121
Epoch 50
Train function
Loss = 7.7223e-04, PNorm = 55.0375, GNorm = 1.2227, lr_0 = 1.0804e-04
Loss = 9.5265e-04, PNorm = 55.0429, GNorm = 2.1186, lr_0 = 1.0804e-04
Loss = 8.5517e-04, PNorm = 55.0493, GNorm = 4.6479, lr_0 = 1.0804e-04
Loss = 9.4694e-04, PNorm = 55.0549, GNorm = 2.3895, lr_0 = 1.0804e-04
Loss = 7.6828e-04, PNorm = 55.0611, GNorm = 5.2295, lr_0 = 1.0804e-04
Validation rmse logD = 0.669881
Validation R2 logD = 0.719660
Epoch 51
Train function
Loss = 6.2663e-04, PNorm = 55.0656, GNorm = 2.6462, lr_0 = 1.0804e-04
Loss = 8.9001e-04, PNorm = 55.0699, GNorm = 2.5139, lr_0 = 1.0804e-04
Loss = 8.4171e-04, PNorm = 55.0763, GNorm = 5.8431, lr_0 = 1.0804e-04
Loss = 7.4487e-04, PNorm = 55.0817, GNorm = 1.3802, lr_0 = 1.0804e-04
Loss = 7.4619e-04, PNorm = 55.0868, GNorm = 2.4748, lr_0 = 1.0804e-04
Loss = 9.3372e-04, PNorm = 55.0924, GNorm = 4.9036, lr_0 = 1.0804e-04
Validation rmse logD = 0.691914
Validation R2 logD = 0.700915
Epoch 52
Train function
Loss = 8.1809e-04, PNorm = 55.0986, GNorm = 4.9066, lr_0 = 1.0804e-04
Loss = 7.8440e-04, PNorm = 55.1039, GNorm = 1.0767, lr_0 = 1.0804e-04
Loss = 8.2939e-04, PNorm = 55.1087, GNorm = 2.4199, lr_0 = 1.0804e-04
Loss = 8.0894e-04, PNorm = 55.1144, GNorm = 4.5320, lr_0 = 1.0804e-04
Loss = 8.8851e-04, PNorm = 55.1193, GNorm = 2.3416, lr_0 = 1.0804e-04
Loss = 9.0672e-04, PNorm = 55.1244, GNorm = 3.0661, lr_0 = 1.0804e-04
Validation rmse logD = 0.661555
Validation R2 logD = 0.726585
Epoch 53
Train function
Loss = 7.0286e-04, PNorm = 55.1302, GNorm = 2.1209, lr_0 = 1.0804e-04
Loss = 6.7665e-04, PNorm = 55.1348, GNorm = 1.3118, lr_0 = 1.0804e-04
Loss = 7.9652e-04, PNorm = 55.1404, GNorm = 5.0874, lr_0 = 1.0804e-04
Loss = 1.0269e-03, PNorm = 55.1453, GNorm = 6.2012, lr_0 = 1.0804e-04
Loss = 1.1249e-03, PNorm = 55.1497, GNorm = 6.9023, lr_0 = 1.0804e-04
Validation rmse logD = 0.662018
Validation R2 logD = 0.726202
Epoch 54
Train function
Loss = 6.5343e-04, PNorm = 55.1550, GNorm = 0.8906, lr_0 = 1.0804e-04
Loss = 7.5444e-04, PNorm = 55.1603, GNorm = 1.5048, lr_0 = 1.0804e-04
Loss = 8.2319e-04, PNorm = 55.1654, GNorm = 3.2321, lr_0 = 1.0804e-04
Loss = 7.4288e-04, PNorm = 55.1698, GNorm = 3.4382, lr_0 = 1.0804e-04
Loss = 1.0227e-03, PNorm = 55.1738, GNorm = 7.8313, lr_0 = 1.0804e-04
Loss = 1.2044e-03, PNorm = 55.1790, GNorm = 3.2079, lr_0 = 1.0804e-04
Validation rmse logD = 0.670629
Validation R2 logD = 0.719034
Epoch 55
Train function
Loss = 8.4701e-04, PNorm = 55.1856, GNorm = 2.3376, lr_0 = 1.0804e-04
Loss = 7.9580e-04, PNorm = 55.1904, GNorm = 1.6313, lr_0 = 1.0804e-04
Loss = 7.1874e-04, PNorm = 55.1966, GNorm = 2.2131, lr_0 = 1.0804e-04
Loss = 7.4293e-04, PNorm = 55.2007, GNorm = 1.8371, lr_0 = 1.0804e-04
Loss = 6.8447e-04, PNorm = 55.2052, GNorm = 1.5852, lr_0 = 1.0804e-04
Loss = 7.0470e-04, PNorm = 55.2104, GNorm = 1.5630, lr_0 = 1.0804e-04
Validation rmse logD = 0.668204
Validation R2 logD = 0.721062
Epoch 56
Train function
Loss = 5.6415e-04, PNorm = 55.2159, GNorm = 1.3972, lr_0 = 1.0804e-04
Loss = 6.8443e-04, PNorm = 55.2209, GNorm = 5.4813, lr_0 = 1.0804e-04
Loss = 7.1288e-04, PNorm = 55.2246, GNorm = 3.3297, lr_0 = 1.0804e-04
Loss = 8.7588e-04, PNorm = 55.2290, GNorm = 2.4668, lr_0 = 1.0804e-04
Loss = 7.8800e-04, PNorm = 55.2332, GNorm = 1.6921, lr_0 = 1.0804e-04
Validation rmse logD = 0.655868
Validation R2 logD = 0.731266
Epoch 57
Train function
Loss = 8.9520e-04, PNorm = 55.2384, GNorm = 1.3709, lr_0 = 1.0804e-04
Loss = 5.8320e-04, PNorm = 55.2434, GNorm = 3.4675, lr_0 = 1.0804e-04
Loss = 5.7594e-04, PNorm = 55.2478, GNorm = 3.3706, lr_0 = 1.0804e-04
Loss = 7.0781e-04, PNorm = 55.2523, GNorm = 2.1079, lr_0 = 1.0804e-04
Loss = 5.7489e-04, PNorm = 55.2573, GNorm = 0.9723, lr_0 = 1.0804e-04
Loss = 8.4299e-04, PNorm = 55.2613, GNorm = 3.7307, lr_0 = 1.0804e-04
Validation rmse logD = 0.675427
Validation R2 logD = 0.714998
Epoch 58
Train function
Loss = 6.9919e-04, PNorm = 55.2652, GNorm = 2.8811, lr_0 = 1.0804e-04
Loss = 8.3843e-04, PNorm = 55.2711, GNorm = 2.4126, lr_0 = 1.0804e-04
Loss = 7.6034e-04, PNorm = 55.2759, GNorm = 4.4071, lr_0 = 1.0804e-04
Loss = 9.4085e-04, PNorm = 55.2813, GNorm = 7.0578, lr_0 = 1.0804e-04
Loss = 9.3206e-04, PNorm = 55.2853, GNorm = 5.8737, lr_0 = 1.0804e-04
Loss = 7.7399e-04, PNorm = 55.2904, GNorm = 2.0040, lr_0 = 1.0804e-04
Validation rmse logD = 0.664581
Validation R2 logD = 0.724078
Epoch 59
Train function
Loss = 5.3626e-04, PNorm = 55.2968, GNorm = 1.2971, lr_0 = 1.0804e-04
Loss = 6.6434e-04, PNorm = 55.3019, GNorm = 4.8044, lr_0 = 1.0804e-04
Loss = 8.6052e-04, PNorm = 55.3053, GNorm = 4.3813, lr_0 = 1.0804e-04
Loss = 1.0286e-03, PNorm = 55.3089, GNorm = 4.0025, lr_0 = 1.0804e-04
Loss = 6.1497e-04, PNorm = 55.3137, GNorm = 3.2508, lr_0 = 1.0804e-04
Validation rmse logD = 0.675403
Validation R2 logD = 0.715019
Epoch 60
Train function
Loss = 8.0861e-04, PNorm = 55.3186, GNorm = 5.1964, lr_0 = 1.0804e-04
Loss = 5.5810e-04, PNorm = 55.3225, GNorm = 3.5275, lr_0 = 1.0804e-04
Loss = 5.8224e-04, PNorm = 55.3272, GNorm = 1.0966, lr_0 = 1.0804e-04
Loss = 7.1683e-04, PNorm = 55.3319, GNorm = 5.3341, lr_0 = 1.0804e-04
Loss = 7.2729e-04, PNorm = 55.3352, GNorm = 2.2162, lr_0 = 1.0804e-04
Loss = 6.5588e-04, PNorm = 55.3409, GNorm = 2.6254, lr_0 = 1.0804e-04
Validation rmse logD = 0.652898
Validation R2 logD = 0.733694
Epoch 61
Train function
Loss = 7.7636e-04, PNorm = 55.3453, GNorm = 6.8461, lr_0 = 1.0804e-04
Loss = 1.1060e-03, PNorm = 55.3480, GNorm = 4.9667, lr_0 = 1.0804e-04
Loss = 8.8480e-04, PNorm = 55.3534, GNorm = 1.7268, lr_0 = 1.0804e-04
Loss = 9.2365e-04, PNorm = 55.3576, GNorm = 3.3967, lr_0 = 1.0804e-04
Loss = 1.1511e-03, PNorm = 55.3620, GNorm = 6.9591, lr_0 = 1.0804e-04
Loss = 1.1533e-03, PNorm = 55.3682, GNorm = 0.8529, lr_0 = 1.0804e-04
Validation rmse logD = 0.671436
Validation R2 logD = 0.718357
Epoch 62
Train function
Loss = 6.3600e-04, PNorm = 55.3750, GNorm = 3.8168, lr_0 = 1.0804e-04
Loss = 5.3132e-04, PNorm = 55.3797, GNorm = 1.6998, lr_0 = 1.0804e-04
Loss = 5.2208e-04, PNorm = 55.3850, GNorm = 2.8420, lr_0 = 1.0804e-04
Loss = 6.4087e-04, PNorm = 55.3892, GNorm = 3.0505, lr_0 = 1.0804e-04
Loss = 6.5146e-04, PNorm = 55.3936, GNorm = 1.9568, lr_0 = 1.0804e-04
Validation rmse logD = 0.653842
Validation R2 logD = 0.732923
Epoch 63
Train function
Loss = 3.8231e-04, PNorm = 55.3972, GNorm = 0.7749, lr_0 = 1.0804e-04
Loss = 6.2105e-04, PNorm = 55.4010, GNorm = 0.7175, lr_0 = 1.0804e-04
Loss = 3.9934e-04, PNorm = 55.4061, GNorm = 0.7125, lr_0 = 1.0804e-04
Loss = 5.2848e-04, PNorm = 55.4101, GNorm = 2.7968, lr_0 = 1.0804e-04
Loss = 5.5016e-04, PNorm = 55.4136, GNorm = 2.6479, lr_0 = 1.0804e-04
Loss = 6.2412e-04, PNorm = 55.4174, GNorm = 1.4399, lr_0 = 1.0804e-04
Validation rmse logD = 0.661636
Validation R2 logD = 0.726518
Epoch 64
Train function
Loss = 4.8372e-04, PNorm = 55.4216, GNorm = 1.3591, lr_0 = 1.0804e-04
Loss = 6.0044e-04, PNorm = 55.4253, GNorm = 1.8473, lr_0 = 1.0804e-04
Loss = 5.5241e-04, PNorm = 55.4291, GNorm = 1.5684, lr_0 = 1.0804e-04
Loss = 5.3911e-04, PNorm = 55.4347, GNorm = 1.9875, lr_0 = 1.0804e-04
Loss = 4.7022e-04, PNorm = 55.4383, GNorm = 2.2368, lr_0 = 1.0804e-04
Loss = 6.0394e-04, PNorm = 55.4426, GNorm = 0.7996, lr_0 = 1.0804e-04
Validation rmse logD = 0.653210
Validation R2 logD = 0.733439
Epoch 65
Train function
Loss = 4.0383e-04, PNorm = 55.4450, GNorm = 1.3242, lr_0 = 1.0804e-04
Loss = 5.0507e-04, PNorm = 55.4487, GNorm = 2.5314, lr_0 = 1.0804e-04
Loss = 5.0236e-04, PNorm = 55.4535, GNorm = 1.5252, lr_0 = 1.0804e-04
Loss = 4.3068e-04, PNorm = 55.4574, GNorm = 1.9520, lr_0 = 1.0804e-04
Loss = 4.8935e-04, PNorm = 55.4615, GNorm = 1.1935, lr_0 = 1.0804e-04
Validation rmse logD = 0.654157
Validation R2 logD = 0.732666
Epoch 66
Train function
Loss = 3.2860e-04, PNorm = 55.4651, GNorm = 0.8988, lr_0 = 1.0804e-04
Loss = 5.2343e-04, PNorm = 55.4699, GNorm = 3.9012, lr_0 = 1.0804e-04
Loss = 5.7675e-04, PNorm = 55.4740, GNorm = 2.3780, lr_0 = 1.0804e-04
Loss = 4.5633e-04, PNorm = 55.4772, GNorm = 1.6089, lr_0 = 1.0804e-04
Loss = 4.2227e-04, PNorm = 55.4809, GNorm = 2.2244, lr_0 = 1.0804e-04
Loss = 5.4220e-04, PNorm = 55.4844, GNorm = 5.4555, lr_0 = 1.0804e-04
Validation rmse logD = 0.665122
Validation R2 logD = 0.723629
Epoch 67
Train function
Loss = 4.1323e-04, PNorm = 55.4878, GNorm = 1.2420, lr_0 = 1.0804e-04
Loss = 4.1131e-04, PNorm = 55.4914, GNorm = 0.5664, lr_0 = 1.0804e-04
Loss = 4.9428e-04, PNorm = 55.4951, GNorm = 0.9117, lr_0 = 1.0804e-04
Loss = 4.1030e-04, PNorm = 55.4991, GNorm = 1.1130, lr_0 = 1.0804e-04
Loss = 4.1944e-04, PNorm = 55.5027, GNorm = 3.5310, lr_0 = 1.0804e-04
Loss = 5.0278e-04, PNorm = 55.5062, GNorm = 4.9641, lr_0 = 1.0804e-04
Validation rmse logD = 0.676256
Validation R2 logD = 0.714299
Epoch 68
Train function
Loss = 5.7148e-04, PNorm = 55.5107, GNorm = 3.9359, lr_0 = 1.0804e-04
Loss = 5.3084e-04, PNorm = 55.5143, GNorm = 5.0357, lr_0 = 1.0804e-04
Loss = 4.9226e-04, PNorm = 55.5187, GNorm = 0.9617, lr_0 = 1.0804e-04
Loss = 6.2883e-04, PNorm = 55.5224, GNorm = 3.5476, lr_0 = 1.0804e-04
Loss = 5.4891e-04, PNorm = 55.5266, GNorm = 2.5468, lr_0 = 1.0804e-04
Validation rmse logD = 0.659542
Validation R2 logD = 0.728247
Epoch 69
Train function
Loss = 3.4855e-04, PNorm = 55.5301, GNorm = 2.4544, lr_0 = 1.0804e-04
Loss = 6.2020e-04, PNorm = 55.5340, GNorm = 2.4494, lr_0 = 1.0804e-04
Loss = 6.1349e-04, PNorm = 55.5374, GNorm = 7.3342, lr_0 = 1.0804e-04
Loss = 7.0805e-04, PNorm = 55.5431, GNorm = 5.0179, lr_0 = 1.0804e-04
Loss = 4.5630e-04, PNorm = 55.5472, GNorm = 1.3011, lr_0 = 1.0804e-04
Loss = 4.7184e-04, PNorm = 55.5520, GNorm = 1.1709, lr_0 = 1.0804e-04
Validation rmse logD = 0.665091
Validation R2 logD = 0.723655
Epoch 70
Train function
Loss = 4.0057e-04, PNorm = 55.5565, GNorm = 1.0280, lr_0 = 1.0804e-04
Loss = 4.1757e-04, PNorm = 55.5602, GNorm = 3.0130, lr_0 = 1.0804e-04
Loss = 5.3738e-04, PNorm = 55.5634, GNorm = 4.0386, lr_0 = 1.0804e-04
Loss = 4.1150e-04, PNorm = 55.5668, GNorm = 1.2500, lr_0 = 1.0804e-04
Loss = 6.4261e-04, PNorm = 55.5696, GNorm = 3.6504, lr_0 = 1.0804e-04
Loss = 7.0400e-04, PNorm = 55.5705, GNorm = 1.1043, lr_0 = 1.0804e-04
Validation rmse logD = 0.661637
Validation R2 logD = 0.726517
Epoch 71
Train function
Loss = 5.6706e-04, PNorm = 55.5751, GNorm = 4.7917, lr_0 = 1.0804e-04
Loss = 5.3920e-04, PNorm = 55.5801, GNorm = 2.3147, lr_0 = 1.0804e-04
Loss = 7.3107e-04, PNorm = 55.5837, GNorm = 4.8877, lr_0 = 1.0804e-04
Loss = 8.2889e-04, PNorm = 55.5886, GNorm = 2.7416, lr_0 = 1.0804e-04
Loss = 5.3929e-04, PNorm = 55.5939, GNorm = 2.6854, lr_0 = 1.0804e-04
Validation rmse logD = 0.662648
Validation R2 logD = 0.725681
Epoch 72
Train function
Loss = 5.4394e-04, PNorm = 55.5990, GNorm = 3.4419, lr_0 = 1.0804e-04
Loss = 5.4612e-04, PNorm = 55.6034, GNorm = 1.9033, lr_0 = 1.0804e-04
Loss = 4.2920e-04, PNorm = 55.6057, GNorm = 1.4665, lr_0 = 1.0804e-04
Loss = 3.8511e-04, PNorm = 55.6100, GNorm = 2.4147, lr_0 = 1.0804e-04
Loss = 3.9601e-04, PNorm = 55.6144, GNorm = 2.3015, lr_0 = 1.0804e-04
Loss = 4.8804e-04, PNorm = 55.6187, GNorm = 2.6532, lr_0 = 1.0804e-04
Validation rmse logD = 0.651974
Validation R2 logD = 0.734447
Epoch 73
Train function
Loss = 4.6844e-04, PNorm = 55.6217, GNorm = 3.2757, lr_0 = 1.0804e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,166 | train size = 2,832 | val size = 500 | test size = 834
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.1697e-02, PNorm = 52.9124, GNorm = 4.1554, lr_0 = 1.0804e-04
Loss = 1.8384e-02, PNorm = 52.9148, GNorm = 4.9643, lr_0 = 1.0804e-04
Loss = 1.7281e-02, PNorm = 52.9177, GNorm = 3.4420, lr_0 = 1.0804e-04
Loss = 1.8159e-02, PNorm = 52.9211, GNorm = 2.2784, lr_0 = 1.0804e-04
Loss = 1.5113e-02, PNorm = 52.9244, GNorm = 2.1921, lr_0 = 1.0804e-04
Validation rmse logD = 1.098394
Validation R2 logD = 0.232343
Epoch 1
Train function
Loss = 1.5136e-02, PNorm = 52.9282, GNorm = 2.0955, lr_0 = 1.0804e-04
Loss = 1.3759e-02, PNorm = 52.9323, GNorm = 8.0529, lr_0 = 1.0804e-04
Loss = 1.5371e-02, PNorm = 52.9363, GNorm = 4.2659, lr_0 = 1.0804e-04
Loss = 1.4109e-02, PNorm = 52.9413, GNorm = 7.7662, lr_0 = 1.0804e-04
Loss = 1.1450e-02, PNorm = 52.9465, GNorm = 1.9915, lr_0 = 1.0804e-04
Loss = 1.3588e-02, PNorm = 52.9519, GNorm = 2.8633, lr_0 = 1.0804e-04
Validation rmse logD = 1.002233
Validation R2 logD = 0.360872
Epoch 2
Train function
Loss = 1.3907e-02, PNorm = 52.9584, GNorm = 2.8636, lr_0 = 1.0804e-04
Loss = 1.2225e-02, PNorm = 52.9650, GNorm = 5.4042, lr_0 = 1.0804e-04
Loss = 1.2184e-02, PNorm = 52.9708, GNorm = 1.7953, lr_0 = 1.0804e-04
Loss = 1.2605e-02, PNorm = 52.9777, GNorm = 5.5174, lr_0 = 1.0804e-04
Loss = 1.0306e-02, PNorm = 52.9851, GNorm = 1.9824, lr_0 = 1.0804e-04
Validation rmse logD = 0.950140
Validation R2 logD = 0.425585
Epoch 3
Train function
Loss = 6.6862e-03, PNorm = 52.9915, GNorm = 1.2228, lr_0 = 1.0804e-04
Loss = 1.1316e-02, PNorm = 52.9973, GNorm = 3.4938, lr_0 = 1.0804e-04
Loss = 1.1408e-02, PNorm = 53.0059, GNorm = 2.4331, lr_0 = 1.0804e-04
Loss = 9.8432e-03, PNorm = 53.0148, GNorm = 1.6264, lr_0 = 1.0804e-04
Loss = 1.0636e-02, PNorm = 53.0218, GNorm = 2.3426, lr_0 = 1.0804e-04
Loss = 1.0672e-02, PNorm = 53.0292, GNorm = 4.9855, lr_0 = 1.0804e-04
Validation rmse logD = 0.907203
Validation R2 logD = 0.476328
Epoch 4
Train function
Loss = 9.4595e-03, PNorm = 53.0377, GNorm = 6.1992, lr_0 = 1.0804e-04
Loss = 9.4895e-03, PNorm = 53.0462, GNorm = 2.8734, lr_0 = 1.0804e-04
Loss = 1.0029e-02, PNorm = 53.0547, GNorm = 2.2445, lr_0 = 1.0804e-04
Loss = 9.1591e-03, PNorm = 53.0643, GNorm = 3.4652, lr_0 = 1.0804e-04
Loss = 9.6447e-03, PNorm = 53.0737, GNorm = 2.8894, lr_0 = 1.0804e-04
Loss = 9.3602e-03, PNorm = 53.0841, GNorm = 2.5865, lr_0 = 1.0804e-04
Validation rmse logD = 0.830168
Validation R2 logD = 0.561487
Epoch 5
Train function
Loss = 7.8344e-03, PNorm = 53.0953, GNorm = 2.5922, lr_0 = 1.0804e-04
Loss = 9.4912e-03, PNorm = 53.1053, GNorm = 2.8482, lr_0 = 1.0804e-04
Loss = 9.6278e-03, PNorm = 53.1140, GNorm = 6.6490, lr_0 = 1.0804e-04
Loss = 8.5227e-03, PNorm = 53.1236, GNorm = 3.7182, lr_0 = 1.0804e-04
Loss = 9.3226e-03, PNorm = 53.1334, GNorm = 5.9680, lr_0 = 1.0804e-04
Validation rmse logD = 0.877687
Validation R2 logD = 0.509849
Epoch 6
Train function
Loss = 9.1595e-03, PNorm = 53.1437, GNorm = 7.7226, lr_0 = 1.0804e-04
Loss = 9.0054e-03, PNorm = 53.1542, GNorm = 4.4058, lr_0 = 1.0804e-04
Loss = 8.2280e-03, PNorm = 53.1629, GNorm = 1.7751, lr_0 = 1.0804e-04
Loss = 8.0975e-03, PNorm = 53.1728, GNorm = 2.7014, lr_0 = 1.0804e-04
Loss = 8.0007e-03, PNorm = 53.1840, GNorm = 3.6167, lr_0 = 1.0804e-04
Loss = 8.1091e-03, PNorm = 53.1948, GNorm = 1.9940, lr_0 = 1.0804e-04
Validation rmse logD = 0.773988
Validation R2 logD = 0.618830
Epoch 7
Train function
Loss = 9.9216e-03, PNorm = 53.2034, GNorm = 1.5939, lr_0 = 1.0804e-04
Loss = 7.7428e-03, PNorm = 53.2114, GNorm = 5.2074, lr_0 = 1.0804e-04
Loss = 8.0882e-03, PNorm = 53.2209, GNorm = 1.7867, lr_0 = 1.0804e-04
Loss = 6.8366e-03, PNorm = 53.2307, GNorm = 3.4576, lr_0 = 1.0804e-04
Loss = 6.9542e-03, PNorm = 53.2419, GNorm = 1.9160, lr_0 = 1.0804e-04
Loss = 7.4467e-03, PNorm = 53.2544, GNorm = 5.8966, lr_0 = 1.0804e-04
Validation rmse logD = 0.752715
Validation R2 logD = 0.639494
Epoch 8
Train function
Loss = 5.6366e-03, PNorm = 53.2658, GNorm = 2.6937, lr_0 = 1.0804e-04
Loss = 6.8399e-03, PNorm = 53.2773, GNorm = 2.1511, lr_0 = 1.0804e-04
Loss = 7.2242e-03, PNorm = 53.2858, GNorm = 3.9588, lr_0 = 1.0804e-04
Loss = 6.2189e-03, PNorm = 53.2960, GNorm = 2.8095, lr_0 = 1.0804e-04
Loss = 6.0199e-03, PNorm = 53.3078, GNorm = 3.3433, lr_0 = 1.0804e-04
Validation rmse logD = 0.744248
Validation R2 logD = 0.647560
Epoch 9
Train function
Loss = 8.1464e-03, PNorm = 53.3174, GNorm = 6.4731, lr_0 = 1.0804e-04
Loss = 5.9989e-03, PNorm = 53.3301, GNorm = 2.5894, lr_0 = 1.0804e-04
Loss = 5.9044e-03, PNorm = 53.3405, GNorm = 3.4162, lr_0 = 1.0804e-04
Loss = 5.3597e-03, PNorm = 53.3514, GNorm = 3.3182, lr_0 = 1.0804e-04
Loss = 5.8459e-03, PNorm = 53.3616, GNorm = 1.8613, lr_0 = 1.0804e-04
Loss = 6.0145e-03, PNorm = 53.3706, GNorm = 2.2544, lr_0 = 1.0804e-04
Validation rmse logD = 0.737601
Validation R2 logD = 0.653827
Epoch 10
Train function
Loss = 3.7125e-03, PNorm = 53.3801, GNorm = 5.1023, lr_0 = 1.0804e-04
Loss = 5.4721e-03, PNorm = 53.3895, GNorm = 2.4316, lr_0 = 1.0804e-04
Loss = 7.0193e-03, PNorm = 53.3987, GNorm = 3.1528, lr_0 = 1.0804e-04
Loss = 6.7696e-03, PNorm = 53.4065, GNorm = 7.3444, lr_0 = 1.0804e-04
Loss = 6.2459e-03, PNorm = 53.4155, GNorm = 2.0369, lr_0 = 1.0804e-04
Loss = 7.0964e-03, PNorm = 53.4244, GNorm = 10.5064, lr_0 = 1.0804e-04
Validation rmse logD = 0.737672
Validation R2 logD = 0.653760
Epoch 11
Train function
Loss = 4.7317e-03, PNorm = 53.4336, GNorm = 3.0780, lr_0 = 1.0804e-04
Loss = 5.2458e-03, PNorm = 53.4428, GNorm = 2.5228, lr_0 = 1.0804e-04
Loss = 5.8757e-03, PNorm = 53.4526, GNorm = 3.3122, lr_0 = 1.0804e-04
Loss = 4.9145e-03, PNorm = 53.4616, GNorm = 6.8009, lr_0 = 1.0804e-04
Loss = 5.4862e-03, PNorm = 53.4697, GNorm = 3.3434, lr_0 = 1.0804e-04
Validation rmse logD = 0.707228
Validation R2 logD = 0.681749
Epoch 12
Train function
Loss = 4.6468e-03, PNorm = 53.4793, GNorm = 4.2311, lr_0 = 1.0804e-04
Loss = 5.1568e-03, PNorm = 53.4869, GNorm = 4.7182, lr_0 = 1.0804e-04
Loss = 5.4048e-03, PNorm = 53.4973, GNorm = 2.0180, lr_0 = 1.0804e-04
Loss = 4.8761e-03, PNorm = 53.5074, GNorm = 7.7213, lr_0 = 1.0804e-04
Loss = 4.5185e-03, PNorm = 53.5150, GNorm = 7.7031, lr_0 = 1.0804e-04
Loss = 5.1298e-03, PNorm = 53.5218, GNorm = 2.0320, lr_0 = 1.0804e-04
Validation rmse logD = 0.683394
Validation R2 logD = 0.702839
Epoch 13
Train function
Loss = 4.6666e-03, PNorm = 53.5330, GNorm = 3.5177, lr_0 = 1.0804e-04
Loss = 4.9186e-03, PNorm = 53.5416, GNorm = 7.0343, lr_0 = 1.0804e-04
Loss = 5.6563e-03, PNorm = 53.5500, GNorm = 6.0212, lr_0 = 1.0804e-04
Loss = 4.4521e-03, PNorm = 53.5585, GNorm = 5.4769, lr_0 = 1.0804e-04
Loss = 5.1813e-03, PNorm = 53.5678, GNorm = 1.5898, lr_0 = 1.0804e-04
Loss = 4.4815e-03, PNorm = 53.5741, GNorm = 1.8489, lr_0 = 1.0804e-04
Validation rmse logD = 0.649023
Validation R2 logD = 0.731978
Epoch 14
Train function
Loss = 4.5038e-03, PNorm = 53.5841, GNorm = 2.3916, lr_0 = 1.0804e-04
Loss = 3.7746e-03, PNorm = 53.5935, GNorm = 2.6751, lr_0 = 1.0804e-04
Loss = 4.0067e-03, PNorm = 53.6011, GNorm = 1.9331, lr_0 = 1.0804e-04
Loss = 5.0699e-03, PNorm = 53.6090, GNorm = 8.8105, lr_0 = 1.0804e-04
Loss = 4.5556e-03, PNorm = 53.6173, GNorm = 3.5387, lr_0 = 1.0804e-04
Validation rmse logD = 0.680034
Validation R2 logD = 0.705753
Epoch 15
Train function
Loss = 4.6550e-03, PNorm = 53.6259, GNorm = 2.1879, lr_0 = 1.0804e-04
Loss = 4.2723e-03, PNorm = 53.6338, GNorm = 3.7314, lr_0 = 1.0804e-04
Loss = 4.0238e-03, PNorm = 53.6423, GNorm = 2.8269, lr_0 = 1.0804e-04
Loss = 4.5827e-03, PNorm = 53.6516, GNorm = 4.4947, lr_0 = 1.0804e-04
Loss = 4.6895e-03, PNorm = 53.6594, GNorm = 2.3261, lr_0 = 1.0804e-04
Loss = 3.8087e-03, PNorm = 53.6675, GNorm = 2.0386, lr_0 = 1.0804e-04
Validation rmse logD = 0.632611
Validation R2 logD = 0.745362
Epoch 16
Train function
Loss = 4.0322e-03, PNorm = 53.6778, GNorm = 1.8906, lr_0 = 1.0804e-04
Loss = 3.1008e-03, PNorm = 53.6861, GNorm = 7.2268, lr_0 = 1.0804e-04
Loss = 3.9463e-03, PNorm = 53.6934, GNorm = 1.6332, lr_0 = 1.0804e-04
Loss = 3.9942e-03, PNorm = 53.6997, GNorm = 3.4173, lr_0 = 1.0804e-04
Loss = 3.9717e-03, PNorm = 53.7090, GNorm = 6.7637, lr_0 = 1.0804e-04
Loss = 3.8448e-03, PNorm = 53.7167, GNorm = 4.1591, lr_0 = 1.0804e-04
Validation rmse logD = 0.633824
Validation R2 logD = 0.744384
Epoch 17
Train function
Loss = 3.1231e-03, PNorm = 53.7256, GNorm = 2.5498, lr_0 = 1.0804e-04
Loss = 4.0136e-03, PNorm = 53.7333, GNorm = 6.2215, lr_0 = 1.0804e-04
Loss = 3.8761e-03, PNorm = 53.7419, GNorm = 3.8356, lr_0 = 1.0804e-04
Loss = 3.7217e-03, PNorm = 53.7506, GNorm = 2.7242, lr_0 = 1.0804e-04
Loss = 3.5695e-03, PNorm = 53.7589, GNorm = 2.1818, lr_0 = 1.0804e-04
Validation rmse logD = 0.643002
Validation R2 logD = 0.736928
Epoch 18
Train function
Loss = 2.6676e-03, PNorm = 53.7684, GNorm = 4.2398, lr_0 = 1.0804e-04
Loss = 3.4858e-03, PNorm = 53.7765, GNorm = 3.4923, lr_0 = 1.0804e-04
Loss = 3.1792e-03, PNorm = 53.7845, GNorm = 2.1788, lr_0 = 1.0804e-04
Loss = 3.9565e-03, PNorm = 53.7929, GNorm = 7.7211, lr_0 = 1.0804e-04
Loss = 3.3105e-03, PNorm = 53.8011, GNorm = 3.6323, lr_0 = 1.0804e-04
Loss = 3.4232e-03, PNorm = 53.8088, GNorm = 5.6233, lr_0 = 1.0804e-04
Validation rmse logD = 0.618121
Validation R2 logD = 0.756893
Epoch 19
Train function
Loss = 3.6893e-03, PNorm = 53.8159, GNorm = 1.4642, lr_0 = 1.0804e-04
Loss = 3.2486e-03, PNorm = 53.8239, GNorm = 3.8724, lr_0 = 1.0804e-04
Loss = 4.0258e-03, PNorm = 53.8308, GNorm = 4.2323, lr_0 = 1.0804e-04
Loss = 3.2439e-03, PNorm = 53.8391, GNorm = 2.7763, lr_0 = 1.0804e-04
Loss = 3.0405e-03, PNorm = 53.8483, GNorm = 1.8275, lr_0 = 1.0804e-04
Loss = 3.1353e-03, PNorm = 53.8562, GNorm = 2.5945, lr_0 = 1.0804e-04
Validation rmse logD = 0.618683
Validation R2 logD = 0.756451
Epoch 20
Train function
Loss = 2.9873e-03, PNorm = 53.8661, GNorm = 2.7432, lr_0 = 1.0804e-04
Loss = 4.4406e-03, PNorm = 53.8710, GNorm = 10.2167, lr_0 = 1.0804e-04
Loss = 4.3299e-03, PNorm = 53.8781, GNorm = 8.4429, lr_0 = 1.0804e-04
Loss = 3.2176e-03, PNorm = 53.8855, GNorm = 2.3161, lr_0 = 1.0804e-04
Loss = 3.6544e-03, PNorm = 53.8944, GNorm = 6.9482, lr_0 = 1.0804e-04
Validation rmse logD = 0.638799
Validation R2 logD = 0.740355
Epoch 21
Train function
Loss = 3.4798e-03, PNorm = 53.9023, GNorm = 4.9928, lr_0 = 1.0804e-04
Loss = 3.2238e-03, PNorm = 53.9109, GNorm = 7.6144, lr_0 = 1.0804e-04
Loss = 2.7209e-03, PNorm = 53.9186, GNorm = 2.0070, lr_0 = 1.0804e-04
Loss = 2.9506e-03, PNorm = 53.9256, GNorm = 1.9976, lr_0 = 1.0804e-04
Loss = 3.2385e-03, PNorm = 53.9333, GNorm = 5.3065, lr_0 = 1.0804e-04
Loss = 3.3795e-03, PNorm = 53.9413, GNorm = 4.5280, lr_0 = 1.0804e-04
Validation rmse logD = 0.634784
Validation R2 logD = 0.743609
Epoch 22
Train function
Loss = 3.0439e-03, PNorm = 53.9489, GNorm = 6.3140, lr_0 = 1.0804e-04
Loss = 3.4508e-03, PNorm = 53.9543, GNorm = 3.3241, lr_0 = 1.0804e-04
Loss = 3.1459e-03, PNorm = 53.9633, GNorm = 5.6322, lr_0 = 1.0804e-04
Loss = 3.4793e-03, PNorm = 53.9720, GNorm = 4.1293, lr_0 = 1.0804e-04
Loss = 2.7363e-03, PNorm = 53.9812, GNorm = 2.1104, lr_0 = 1.0804e-04
Loss = 3.1407e-03, PNorm = 53.9890, GNorm = 1.6070, lr_0 = 1.0804e-04
Validation rmse logD = 0.673793
Validation R2 logD = 0.711130
Epoch 23
Train function
Loss = 2.9362e-03, PNorm = 53.9946, GNorm = 7.5548, lr_0 = 1.0804e-04
Loss = 2.6947e-03, PNorm = 54.0034, GNorm = 5.2496, lr_0 = 1.0804e-04
Loss = 2.8316e-03, PNorm = 54.0104, GNorm = 4.6575, lr_0 = 1.0804e-04
Loss = 2.7453e-03, PNorm = 54.0169, GNorm = 2.3603, lr_0 = 1.0804e-04
Loss = 3.0898e-03, PNorm = 54.0233, GNorm = 4.0347, lr_0 = 1.0804e-04
Validation rmse logD = 0.607548
Validation R2 logD = 0.765139
Epoch 24
Train function
Loss = 1.9532e-03, PNorm = 54.0306, GNorm = 1.6683, lr_0 = 1.0804e-04
Loss = 2.7092e-03, PNorm = 54.0388, GNorm = 2.3638, lr_0 = 1.0804e-04
Loss = 3.1048e-03, PNorm = 54.0477, GNorm = 11.9114, lr_0 = 1.0804e-04
Loss = 3.1422e-03, PNorm = 54.0543, GNorm = 5.6232, lr_0 = 1.0804e-04
Loss = 3.2914e-03, PNorm = 54.0613, GNorm = 6.4335, lr_0 = 1.0804e-04
Loss = 3.1488e-03, PNorm = 54.0673, GNorm = 3.4325, lr_0 = 1.0804e-04
Validation rmse logD = 0.606181
Validation R2 logD = 0.766194
Epoch 25
Train function
Loss = 2.3588e-03, PNorm = 54.0753, GNorm = 4.2711, lr_0 = 1.0804e-04
Loss = 2.6456e-03, PNorm = 54.0836, GNorm = 2.8741, lr_0 = 1.0804e-04
Loss = 2.7143e-03, PNorm = 54.0890, GNorm = 2.6665, lr_0 = 1.0804e-04
Loss = 2.5753e-03, PNorm = 54.0967, GNorm = 6.8846, lr_0 = 1.0804e-04
Loss = 2.6282e-03, PNorm = 54.1046, GNorm = 3.6537, lr_0 = 1.0804e-04
Loss = 2.5624e-03, PNorm = 54.1110, GNorm = 3.3219, lr_0 = 1.0804e-04
Validation rmse logD = 0.593519
Validation R2 logD = 0.775860
Epoch 26
Train function
Loss = 2.3273e-03, PNorm = 54.1206, GNorm = 7.0795, lr_0 = 1.0804e-04
Loss = 2.3517e-03, PNorm = 54.1277, GNorm = 2.2049, lr_0 = 1.0804e-04
Loss = 2.7951e-03, PNorm = 54.1377, GNorm = 4.8376, lr_0 = 1.0804e-04
Loss = 2.1634e-03, PNorm = 54.1440, GNorm = 3.3151, lr_0 = 1.0804e-04
Loss = 2.4429e-03, PNorm = 54.1501, GNorm = 3.0637, lr_0 = 1.0804e-04
Validation rmse logD = 0.589929
Validation R2 logD = 0.778563
Epoch 27
Train function
Loss = 2.8545e-03, PNorm = 54.1544, GNorm = 4.7824, lr_0 = 1.0804e-04
Loss = 2.9292e-03, PNorm = 54.1601, GNorm = 7.7432, lr_0 = 1.0804e-04
Loss = 2.2708e-03, PNorm = 54.1672, GNorm = 2.1731, lr_0 = 1.0804e-04
Loss = 2.3075e-03, PNorm = 54.1760, GNorm = 3.9981, lr_0 = 1.0804e-04
Loss = 2.1014e-03, PNorm = 54.1833, GNorm = 1.8468, lr_0 = 1.0804e-04
Loss = 1.9967e-03, PNorm = 54.1901, GNorm = 2.0363, lr_0 = 1.0804e-04
Validation rmse logD = 0.577714
Validation R2 logD = 0.787638
Epoch 28
Train function
Loss = 2.1034e-03, PNorm = 54.1962, GNorm = 2.7292, lr_0 = 1.0804e-04
Loss = 2.5822e-03, PNorm = 54.2023, GNorm = 5.2379, lr_0 = 1.0804e-04
Loss = 2.1199e-03, PNorm = 54.2091, GNorm = 1.8152, lr_0 = 1.0804e-04
Loss = 2.3088e-03, PNorm = 54.2168, GNorm = 3.7862, lr_0 = 1.0804e-04
Loss = 2.4398e-03, PNorm = 54.2229, GNorm = 1.4365, lr_0 = 1.0804e-04
Loss = 2.0521e-03, PNorm = 54.2304, GNorm = 1.0654, lr_0 = 1.0804e-04
Validation rmse logD = 0.612382
Validation R2 logD = 0.761387
Epoch 29
Train function
Loss = 2.0894e-03, PNorm = 54.2372, GNorm = 2.2604, lr_0 = 1.0804e-04
Loss = 2.0404e-03, PNorm = 54.2444, GNorm = 3.2898, lr_0 = 1.0804e-04
Loss = 2.5325e-03, PNorm = 54.2524, GNorm = 1.7742, lr_0 = 1.0804e-04
Loss = 1.7477e-03, PNorm = 54.2582, GNorm = 3.5246, lr_0 = 1.0804e-04
Loss = 2.1739e-03, PNorm = 54.2658, GNorm = 10.5125, lr_0 = 1.0804e-04
Validation rmse logD = 0.575256
Validation R2 logD = 0.789442
Epoch 30
Train function
Loss = 1.6387e-03, PNorm = 54.2705, GNorm = 1.1815, lr_0 = 1.0804e-04
Loss = 2.1378e-03, PNorm = 54.2768, GNorm = 2.9895, lr_0 = 1.0804e-04
Loss = 2.2170e-03, PNorm = 54.2859, GNorm = 2.7440, lr_0 = 1.0804e-04
Loss = 1.9110e-03, PNorm = 54.2934, GNorm = 1.8606, lr_0 = 1.0804e-04
Loss = 1.9141e-03, PNorm = 54.3004, GNorm = 5.3065, lr_0 = 1.0804e-04
Loss = 2.2982e-03, PNorm = 54.3071, GNorm = 7.2840, lr_0 = 1.0804e-04
Validation rmse logD = 0.573827
Validation R2 logD = 0.790487
Epoch 31
Train function
Loss = 1.5142e-03, PNorm = 54.3144, GNorm = 1.3446, lr_0 = 1.0804e-04
Loss = 2.0185e-03, PNorm = 54.3211, GNorm = 4.7805, lr_0 = 1.0804e-04
Loss = 1.9811e-03, PNorm = 54.3291, GNorm = 1.4413, lr_0 = 1.0804e-04
Loss = 1.7519e-03, PNorm = 54.3358, GNorm = 1.4683, lr_0 = 1.0804e-04
Loss = 1.7976e-03, PNorm = 54.3421, GNorm = 3.5759, lr_0 = 1.0804e-04
Loss = 2.0539e-03, PNorm = 54.3485, GNorm = 2.0816, lr_0 = 1.0804e-04
Validation rmse logD = 0.570121
Validation R2 logD = 0.793184
Epoch 32
Train function
Loss = 1.5803e-03, PNorm = 54.3556, GNorm = 2.9411, lr_0 = 1.0804e-04
Loss = 1.8307e-03, PNorm = 54.3623, GNorm = 3.4366, lr_0 = 1.0804e-04
Loss = 1.8119e-03, PNorm = 54.3680, GNorm = 1.8895, lr_0 = 1.0804e-04
Loss = 1.6428e-03, PNorm = 54.3736, GNorm = 1.8284, lr_0 = 1.0804e-04
Loss = 2.0735e-03, PNorm = 54.3803, GNorm = 2.7220, lr_0 = 1.0804e-04
Validation rmse logD = 0.576302
Validation R2 logD = 0.788675
Epoch 33
Train function
Loss = 1.6285e-03, PNorm = 54.3868, GNorm = 4.3138, lr_0 = 1.0804e-04
Loss = 2.0218e-03, PNorm = 54.3935, GNorm = 2.1349, lr_0 = 1.0804e-04
Loss = 1.8397e-03, PNorm = 54.3988, GNorm = 1.7017, lr_0 = 1.0804e-04
Loss = 1.9589e-03, PNorm = 54.4047, GNorm = 2.7784, lr_0 = 1.0804e-04
Loss = 1.5639e-03, PNorm = 54.4126, GNorm = 4.2301, lr_0 = 1.0804e-04
Loss = 1.8612e-03, PNorm = 54.4194, GNorm = 2.3238, lr_0 = 1.0804e-04
Validation rmse logD = 0.583148
Validation R2 logD = 0.783625
Epoch 34
Train function
Loss = 1.7035e-03, PNorm = 54.4250, GNorm = 5.1692, lr_0 = 1.0804e-04
Loss = 1.7066e-03, PNorm = 54.4318, GNorm = 2.4662, lr_0 = 1.0804e-04
Loss = 1.6362e-03, PNorm = 54.4378, GNorm = 3.0855, lr_0 = 1.0804e-04
Loss = 1.6645e-03, PNorm = 54.4452, GNorm = 3.7406, lr_0 = 1.0804e-04
Loss = 1.8077e-03, PNorm = 54.4513, GNorm = 2.5519, lr_0 = 1.0804e-04
Loss = 1.9805e-03, PNorm = 54.4580, GNorm = 1.9318, lr_0 = 1.0804e-04
Validation rmse logD = 0.568908
Validation R2 logD = 0.794063
Epoch 35
Train function
Loss = 2.0674e-03, PNorm = 54.4656, GNorm = 1.3365, lr_0 = 1.0804e-04
Loss = 2.4024e-03, PNorm = 54.4697, GNorm = 5.3352, lr_0 = 1.0804e-04
Loss = 2.8298e-03, PNorm = 54.4747, GNorm = 5.2944, lr_0 = 1.0804e-04
Loss = 2.4924e-03, PNorm = 54.4822, GNorm = 7.0104, lr_0 = 1.0804e-04
Loss = 2.2651e-03, PNorm = 54.4889, GNorm = 4.2429, lr_0 = 1.0804e-04
Validation rmse logD = 0.567665
Validation R2 logD = 0.794962
Epoch 36
Train function
Loss = 8.9035e-04, PNorm = 54.4967, GNorm = 1.3254, lr_0 = 1.0804e-04
Loss = 1.6043e-03, PNorm = 54.5045, GNorm = 1.3148, lr_0 = 1.0804e-04
Loss = 1.7790e-03, PNorm = 54.5106, GNorm = 7.5581, lr_0 = 1.0804e-04
Loss = 1.6386e-03, PNorm = 54.5170, GNorm = 1.1326, lr_0 = 1.0804e-04
Loss = 1.6238e-03, PNorm = 54.5230, GNorm = 1.3495, lr_0 = 1.0804e-04
Loss = 1.7318e-03, PNorm = 54.5296, GNorm = 5.7117, lr_0 = 1.0804e-04
Validation rmse logD = 0.578936
Validation R2 logD = 0.786739
Epoch 37
Train function
Loss = 1.6762e-03, PNorm = 54.5370, GNorm = 7.9186, lr_0 = 1.0804e-04
Loss = 1.9144e-03, PNorm = 54.5425, GNorm = 6.9968, lr_0 = 1.0804e-04
Loss = 1.7422e-03, PNorm = 54.5480, GNorm = 3.6655, lr_0 = 1.0804e-04
Loss = 1.9308e-03, PNorm = 54.5549, GNorm = 1.7374, lr_0 = 1.0804e-04
Loss = 1.7166e-03, PNorm = 54.5612, GNorm = 6.3459, lr_0 = 1.0804e-04
Loss = 1.8816e-03, PNorm = 54.5678, GNorm = 3.6924, lr_0 = 1.0804e-04
Validation rmse logD = 0.560394
Validation R2 logD = 0.800181
Epoch 38
Train function
Loss = 1.4100e-03, PNorm = 54.5752, GNorm = 1.5359, lr_0 = 1.0804e-04
Loss = 1.2243e-03, PNorm = 54.5808, GNorm = 4.0260, lr_0 = 1.0804e-04
Loss = 1.4918e-03, PNorm = 54.5861, GNorm = 3.7017, lr_0 = 1.0804e-04
Loss = 1.3589e-03, PNorm = 54.5911, GNorm = 1.2512, lr_0 = 1.0804e-04
Loss = 1.5633e-03, PNorm = 54.5964, GNorm = 3.6247, lr_0 = 1.0804e-04
Validation rmse logD = 0.560164
Validation R2 logD = 0.800345
Epoch 39
Train function
Loss = 1.5756e-03, PNorm = 54.6029, GNorm = 2.6653, lr_0 = 1.0804e-04
Loss = 1.4954e-03, PNorm = 54.6098, GNorm = 8.6370, lr_0 = 1.0804e-04
Loss = 1.3591e-03, PNorm = 54.6163, GNorm = 2.6629, lr_0 = 1.0804e-04
Loss = 1.5929e-03, PNorm = 54.6209, GNorm = 1.2887, lr_0 = 1.0804e-04
Loss = 1.2617e-03, PNorm = 54.6256, GNorm = 1.3869, lr_0 = 1.0804e-04
Loss = 1.5164e-03, PNorm = 54.6318, GNorm = 2.4898, lr_0 = 1.0804e-04
Validation rmse logD = 0.572661
Validation R2 logD = 0.791337
Epoch 40
Train function
Loss = 1.0997e-03, PNorm = 54.6364, GNorm = 1.6715, lr_0 = 1.0804e-04
Loss = 1.4232e-03, PNorm = 54.6400, GNorm = 1.7018, lr_0 = 1.0804e-04
Loss = 1.5851e-03, PNorm = 54.6458, GNorm = 6.0697, lr_0 = 1.0804e-04
Loss = 1.6656e-03, PNorm = 54.6515, GNorm = 2.9069, lr_0 = 1.0804e-04
Loss = 1.3482e-03, PNorm = 54.6597, GNorm = 1.3775, lr_0 = 1.0804e-04
Loss = 1.3534e-03, PNorm = 54.6657, GNorm = 1.8027, lr_0 = 1.0804e-04
Validation rmse logD = 0.550887
Validation R2 logD = 0.806903
Epoch 41
Train function
Loss = 1.0884e-03, PNorm = 54.6710, GNorm = 1.4128, lr_0 = 1.0804e-04
Loss = 1.1262e-03, PNorm = 54.6757, GNorm = 1.3304, lr_0 = 1.0804e-04
Loss = 9.8440e-04, PNorm = 54.6812, GNorm = 1.6772, lr_0 = 1.0804e-04
Loss = 1.3567e-03, PNorm = 54.6870, GNorm = 6.0900, lr_0 = 1.0804e-04
Loss = 1.2322e-03, PNorm = 54.6929, GNorm = 2.6883, lr_0 = 1.0804e-04
Validation rmse logD = 0.561834
Validation R2 logD = 0.799152
Epoch 42
Train function
Loss = 1.3688e-03, PNorm = 54.6973, GNorm = 2.2826, lr_0 = 1.0804e-04
Loss = 1.2766e-03, PNorm = 54.7017, GNorm = 2.7478, lr_0 = 1.0804e-04
Loss = 1.0234e-03, PNorm = 54.7083, GNorm = 3.5597, lr_0 = 1.0804e-04
Loss = 1.2126e-03, PNorm = 54.7127, GNorm = 2.0675, lr_0 = 1.0804e-04
Loss = 1.2803e-03, PNorm = 54.7175, GNorm = 3.9473, lr_0 = 1.0804e-04
Loss = 1.3108e-03, PNorm = 54.7237, GNorm = 1.7482, lr_0 = 1.0804e-04
Validation rmse logD = 0.546537
Validation R2 logD = 0.809941
Epoch 43
Train function
Loss = 7.9532e-04, PNorm = 54.7292, GNorm = 4.2035, lr_0 = 1.0804e-04
Loss = 1.1726e-03, PNorm = 54.7345, GNorm = 3.0602, lr_0 = 1.0804e-04
Loss = 1.1418e-03, PNorm = 54.7403, GNorm = 2.7507, lr_0 = 1.0804e-04
Loss = 1.0094e-03, PNorm = 54.7456, GNorm = 1.3947, lr_0 = 1.0804e-04
Loss = 1.1105e-03, PNorm = 54.7525, GNorm = 2.9340, lr_0 = 1.0804e-04
Loss = 1.0864e-03, PNorm = 54.7580, GNorm = 1.6293, lr_0 = 1.0804e-04
Validation rmse logD = 0.545305
Validation R2 logD = 0.810797
Epoch 44
Train function
Loss = 8.5987e-04, PNorm = 54.7626, GNorm = 2.5271, lr_0 = 1.0804e-04
Loss = 8.6228e-04, PNorm = 54.7669, GNorm = 2.2672, lr_0 = 1.0804e-04
Loss = 9.7181e-04, PNorm = 54.7716, GNorm = 1.3329, lr_0 = 1.0804e-04
Loss = 1.2820e-03, PNorm = 54.7773, GNorm = 3.2839, lr_0 = 1.0804e-04
Loss = 1.8837e-03, PNorm = 54.7818, GNorm = 3.2563, lr_0 = 1.0804e-04
Validation rmse logD = 0.588601
Validation R2 logD = 0.779559
Epoch 45
Train function
Loss = 1.0131e-03, PNorm = 54.7894, GNorm = 4.0062, lr_0 = 1.0804e-04
Loss = 8.7987e-04, PNorm = 54.7938, GNorm = 2.3158, lr_0 = 1.0804e-04
Loss = 1.1315e-03, PNorm = 54.7995, GNorm = 3.2587, lr_0 = 1.0804e-04
Loss = 8.8497e-04, PNorm = 54.8045, GNorm = 1.6290, lr_0 = 1.0804e-04
Loss = 1.2462e-03, PNorm = 54.8087, GNorm = 4.4959, lr_0 = 1.0804e-04
Loss = 1.3822e-03, PNorm = 54.8135, GNorm = 1.2670, lr_0 = 1.0804e-04
Validation rmse logD = 0.542222
Validation R2 logD = 0.812930
Epoch 46
Train function
Loss = 8.7590e-04, PNorm = 54.8208, GNorm = 1.0898, lr_0 = 1.0804e-04
Loss = 1.0497e-03, PNorm = 54.8268, GNorm = 2.7650, lr_0 = 1.0804e-04
Loss = 9.6465e-04, PNorm = 54.8326, GNorm = 0.9121, lr_0 = 1.0804e-04
Loss = 1.0601e-03, PNorm = 54.8381, GNorm = 7.5729, lr_0 = 1.0804e-04
Loss = 1.3785e-03, PNorm = 54.8412, GNorm = 9.0523, lr_0 = 1.0804e-04
Loss = 1.4940e-03, PNorm = 54.8452, GNorm = 1.6377, lr_0 = 1.0804e-04
Validation rmse logD = 0.541642
Validation R2 logD = 0.813330
Epoch 47
Train function
Loss = 1.1553e-03, PNorm = 54.8497, GNorm = 3.3230, lr_0 = 1.0804e-04
Loss = 1.1202e-03, PNorm = 54.8564, GNorm = 4.8470, lr_0 = 1.0804e-04
Loss = 8.9800e-04, PNorm = 54.8618, GNorm = 2.5634, lr_0 = 1.0804e-04
Loss = 9.7331e-04, PNorm = 54.8675, GNorm = 2.2100, lr_0 = 1.0804e-04
Loss = 8.5440e-04, PNorm = 54.8724, GNorm = 1.2540, lr_0 = 1.0804e-04
Validation rmse logD = 0.544335
Validation R2 logD = 0.811469
Epoch 48
Train function
Loss = 7.5143e-04, PNorm = 54.8769, GNorm = 5.7160, lr_0 = 1.0804e-04
Loss = 9.4778e-04, PNorm = 54.8812, GNorm = 4.7688, lr_0 = 1.0804e-04
Loss = 9.5465e-04, PNorm = 54.8862, GNorm = 1.1369, lr_0 = 1.0804e-04
Loss = 8.6767e-04, PNorm = 54.8901, GNorm = 2.1677, lr_0 = 1.0804e-04
Loss = 1.0638e-03, PNorm = 54.8940, GNorm = 5.3451, lr_0 = 1.0804e-04
Loss = 1.0369e-03, PNorm = 54.9003, GNorm = 3.7823, lr_0 = 1.0804e-04
Validation rmse logD = 0.586908
Validation R2 logD = 0.780825
Epoch 49
Train function
Loss = 1.0456e-03, PNorm = 54.9056, GNorm = 1.6009, lr_0 = 1.0804e-04
Loss = 8.4512e-04, PNorm = 54.9112, GNorm = 2.2847, lr_0 = 1.0804e-04
Loss = 7.8828e-04, PNorm = 54.9145, GNorm = 2.4022, lr_0 = 1.0804e-04
Loss = 8.5462e-04, PNorm = 54.9176, GNorm = 3.3193, lr_0 = 1.0804e-04
Loss = 1.0628e-03, PNorm = 54.9236, GNorm = 5.7160, lr_0 = 1.0804e-04
Loss = 1.1362e-03, PNorm = 54.9292, GNorm = 6.9310, lr_0 = 1.0804e-04
Validation rmse logD = 0.555161
Validation R2 logD = 0.803895
Epoch 50
Train function
Loss = 8.3119e-04, PNorm = 54.9326, GNorm = 2.0588, lr_0 = 1.0804e-04
Loss = 9.0187e-04, PNorm = 54.9369, GNorm = 2.4198, lr_0 = 1.0804e-04
Loss = 8.9804e-04, PNorm = 54.9417, GNorm = 2.8478, lr_0 = 1.0804e-04
Loss = 9.8114e-04, PNorm = 54.9472, GNorm = 2.4542, lr_0 = 1.0804e-04
Loss = 1.1761e-03, PNorm = 54.9521, GNorm = 1.6442, lr_0 = 1.0804e-04
Validation rmse logD = 0.542815
Validation R2 logD = 0.812521
Epoch 51
Train function
Loss = 7.9729e-04, PNorm = 54.9578, GNorm = 4.0897, lr_0 = 1.0804e-04
Loss = 8.3217e-04, PNorm = 54.9641, GNorm = 2.7735, lr_0 = 1.0804e-04
Loss = 7.7850e-04, PNorm = 54.9678, GNorm = 1.0869, lr_0 = 1.0804e-04
Loss = 8.0185e-04, PNorm = 54.9703, GNorm = 2.3194, lr_0 = 1.0804e-04
Loss = 9.0362e-04, PNorm = 54.9758, GNorm = 1.2243, lr_0 = 1.0804e-04
Loss = 1.0469e-03, PNorm = 54.9804, GNorm = 7.6117, lr_0 = 1.0804e-04
Validation rmse logD = 0.553017
Validation R2 logD = 0.805407
Epoch 52
Train function
Loss = 9.9177e-04, PNorm = 54.9848, GNorm = 2.9401, lr_0 = 1.0804e-04
Loss = 8.6773e-04, PNorm = 54.9910, GNorm = 1.3778, lr_0 = 1.0804e-04
Loss = 7.9990e-04, PNorm = 54.9967, GNorm = 3.4593, lr_0 = 1.0804e-04
Loss = 9.2838e-04, PNorm = 54.9999, GNorm = 2.6278, lr_0 = 1.0804e-04
Loss = 8.2378e-04, PNorm = 55.0016, GNorm = 4.1097, lr_0 = 1.0804e-04
Loss = 7.4798e-04, PNorm = 55.0069, GNorm = 1.3054, lr_0 = 1.0804e-04
Validation rmse logD = 0.563669
Validation R2 logD = 0.797838
Epoch 53
Train function
Loss = 6.2465e-04, PNorm = 55.0115, GNorm = 1.2288, lr_0 = 1.0804e-04
Loss = 8.5038e-04, PNorm = 55.0153, GNorm = 3.5482, lr_0 = 1.0804e-04
Loss = 8.5812e-04, PNorm = 55.0200, GNorm = 1.2140, lr_0 = 1.0804e-04
Loss = 9.3091e-04, PNorm = 55.0242, GNorm = 2.9778, lr_0 = 1.0804e-04
Loss = 7.0433e-04, PNorm = 55.0285, GNorm = 1.4107, lr_0 = 1.0804e-04
Validation rmse logD = 0.534880
Validation R2 logD = 0.817962
Epoch 54
Train function
Loss = 5.9157e-04, PNorm = 55.0336, GNorm = 2.0573, lr_0 = 1.0804e-04
Loss = 6.8975e-04, PNorm = 55.0386, GNorm = 1.6568, lr_0 = 1.0804e-04
Loss = 7.4070e-04, PNorm = 55.0435, GNorm = 2.1712, lr_0 = 1.0804e-04
Loss = 7.0013e-04, PNorm = 55.0472, GNorm = 1.1054, lr_0 = 1.0804e-04
Loss = 8.3675e-04, PNorm = 55.0516, GNorm = 1.7901, lr_0 = 1.0804e-04
Loss = 7.4517e-04, PNorm = 55.0561, GNorm = 4.2800, lr_0 = 1.0804e-04
Validation rmse logD = 0.538635
Validation R2 logD = 0.815397
Epoch 55
Train function
Loss = 7.5305e-04, PNorm = 55.0608, GNorm = 0.8663, lr_0 = 1.0804e-04
Loss = 6.3351e-04, PNorm = 55.0648, GNorm = 3.3829, lr_0 = 1.0804e-04
Loss = 8.8260e-04, PNorm = 55.0677, GNorm = 2.4983, lr_0 = 1.0804e-04
Loss = 6.9366e-04, PNorm = 55.0714, GNorm = 1.2408, lr_0 = 1.0804e-04
Loss = 9.4029e-04, PNorm = 55.0744, GNorm = 3.0980, lr_0 = 1.0804e-04
Loss = 7.8030e-04, PNorm = 55.0783, GNorm = 1.8142, lr_0 = 1.0804e-04
Validation rmse logD = 0.538337
Validation R2 logD = 0.815601
Epoch 56
Train function
Loss = 8.3030e-04, PNorm = 55.0830, GNorm = 5.0452, lr_0 = 1.0804e-04
Loss = 7.9803e-04, PNorm = 55.0872, GNorm = 4.9883, lr_0 = 1.0804e-04
Loss = 6.1864e-04, PNorm = 55.0902, GNorm = 2.4152, lr_0 = 1.0804e-04
Loss = 6.3956e-04, PNorm = 55.0951, GNorm = 2.2410, lr_0 = 1.0804e-04
Loss = 6.5712e-04, PNorm = 55.1000, GNorm = 2.2400, lr_0 = 1.0804e-04
Validation rmse logD = 0.543648
Validation R2 logD = 0.811945
Epoch 57
Train function
Loss = 8.3040e-04, PNorm = 55.1033, GNorm = 3.2243, lr_0 = 1.0804e-04
Loss = 8.1022e-04, PNorm = 55.1085, GNorm = 3.1661, lr_0 = 1.0804e-04
Loss = 7.0239e-04, PNorm = 55.1125, GNorm = 1.7720, lr_0 = 1.0804e-04
Loss = 7.4052e-04, PNorm = 55.1167, GNorm = 1.1565, lr_0 = 1.0804e-04
Loss = 7.2263e-04, PNorm = 55.1218, GNorm = 2.0202, lr_0 = 1.0804e-04
Loss = 7.4246e-04, PNorm = 55.1255, GNorm = 1.5649, lr_0 = 1.0804e-04
Validation rmse logD = 0.541309
Validation R2 logD = 0.813559
Epoch 58
Train function
Loss = 9.1345e-04, PNorm = 55.1295, GNorm = 4.1925, lr_0 = 1.0804e-04
Loss = 1.0504e-03, PNorm = 55.1337, GNorm = 6.4120, lr_0 = 1.0804e-04
Loss = 9.0807e-04, PNorm = 55.1394, GNorm = 3.8433, lr_0 = 1.0804e-04
Loss = 7.0545e-04, PNorm = 55.1450, GNorm = 1.3705, lr_0 = 1.0804e-04
Loss = 7.1877e-04, PNorm = 55.1484, GNorm = 1.1411, lr_0 = 1.0804e-04
Loss = 6.9448e-04, PNorm = 55.1527, GNorm = 1.4845, lr_0 = 1.0804e-04
Validation rmse logD = 0.535284
Validation R2 logD = 0.817686
Epoch 59
Train function
Loss = 5.5295e-04, PNorm = 55.1570, GNorm = 1.2044, lr_0 = 1.0804e-04
Loss = 6.2284e-04, PNorm = 55.1630, GNorm = 1.7900, lr_0 = 1.0804e-04
Loss = 5.5106e-04, PNorm = 55.1670, GNorm = 1.6177, lr_0 = 1.0804e-04
Loss = 5.9671e-04, PNorm = 55.1716, GNorm = 2.7755, lr_0 = 1.0804e-04
Loss = 6.3398e-04, PNorm = 55.1743, GNorm = 3.0335, lr_0 = 1.0804e-04
Validation rmse logD = 0.542049
Validation R2 logD = 0.813049
Epoch 60
Train function
Loss = 6.4186e-04, PNorm = 55.1796, GNorm = 4.6445, lr_0 = 1.0804e-04
Loss = 7.7860e-04, PNorm = 55.1846, GNorm = 5.3188, lr_0 = 1.0804e-04
Loss = 9.5690e-04, PNorm = 55.1879, GNorm = 4.9368, lr_0 = 1.0804e-04
Loss = 9.9625e-04, PNorm = 55.1926, GNorm = 6.7400, lr_0 = 1.0804e-04
Loss = 9.7857e-04, PNorm = 55.1975, GNorm = 3.7772, lr_0 = 1.0804e-04
Loss = 7.0567e-04, PNorm = 55.2027, GNorm = 3.1257, lr_0 = 1.0804e-04
Validation rmse logD = 0.561603
Validation R2 logD = 0.799318
Epoch 61
Train function
Loss = 7.1373e-04, PNorm = 55.2070, GNorm = 3.7636, lr_0 = 1.0804e-04
Loss = 6.0246e-04, PNorm = 55.2109, GNorm = 2.2270, lr_0 = 1.0804e-04
Loss = 6.9585e-04, PNorm = 55.2154, GNorm = 2.4992, lr_0 = 1.0804e-04
Loss = 6.3761e-04, PNorm = 55.2197, GNorm = 5.7571, lr_0 = 1.0804e-04
Loss = 5.6626e-04, PNorm = 55.2235, GNorm = 0.8686, lr_0 = 1.0804e-04
Loss = 6.3604e-04, PNorm = 55.2274, GNorm = 2.3350, lr_0 = 1.0804e-04
Validation rmse logD = 0.526129
Validation R2 logD = 0.823869
Epoch 62
Train function
Loss = 5.2071e-04, PNorm = 55.2308, GNorm = 1.3670, lr_0 = 1.0804e-04
Loss = 6.0984e-04, PNorm = 55.2342, GNorm = 3.7336, lr_0 = 1.0804e-04
Loss = 5.7258e-04, PNorm = 55.2366, GNorm = 1.3424, lr_0 = 1.0804e-04
Loss = 6.1289e-04, PNorm = 55.2402, GNorm = 2.1696, lr_0 = 1.0804e-04
Loss = 6.2358e-04, PNorm = 55.2434, GNorm = 3.6815, lr_0 = 1.0804e-04
Validation rmse logD = 0.543290
Validation R2 logD = 0.812192
Epoch 63
Train function
Loss = 6.2912e-04, PNorm = 55.2485, GNorm = 2.2541, lr_0 = 1.0804e-04
Loss = 4.2837e-04, PNorm = 55.2519, GNorm = 2.4177, lr_0 = 1.0804e-04
Loss = 5.7524e-04, PNorm = 55.2573, GNorm = 1.2580, lr_0 = 1.0804e-04
Loss = 5.6457e-04, PNorm = 55.2603, GNorm = 1.7463, lr_0 = 1.0804e-04
Loss = 6.4364e-04, PNorm = 55.2644, GNorm = 1.4355, lr_0 = 1.0804e-04
Loss = 8.1844e-04, PNorm = 55.2677, GNorm = 1.4069, lr_0 = 1.0804e-04
Validation rmse logD = 0.583401
Validation R2 logD = 0.783436
Epoch 64
Train function
Loss = 9.2965e-04, PNorm = 55.2714, GNorm = 5.5410, lr_0 = 1.0804e-04
Loss = 8.3563e-04, PNorm = 55.2757, GNorm = 5.0022, lr_0 = 1.0804e-04
Loss = 8.2855e-04, PNorm = 55.2801, GNorm = 5.9023, lr_0 = 1.0804e-04
Loss = 7.8651e-04, PNorm = 55.2851, GNorm = 3.6906, lr_0 = 1.0804e-04
Loss = 9.0971e-04, PNorm = 55.2904, GNorm = 2.7880, lr_0 = 1.0804e-04
Loss = 1.3062e-03, PNorm = 55.2953, GNorm = 2.8258, lr_0 = 1.0804e-04
Validation rmse logD = 0.553269
Validation R2 logD = 0.805229
Epoch 65
Train function
Loss = 7.4017e-04, PNorm = 55.2995, GNorm = 4.0210, lr_0 = 1.0804e-04
Loss = 5.1142e-04, PNorm = 55.3056, GNorm = 2.1229, lr_0 = 1.0804e-04
Loss = 5.0514e-04, PNorm = 55.3110, GNorm = 0.9662, lr_0 = 1.0804e-04
Loss = 5.5886e-04, PNorm = 55.3149, GNorm = 1.9119, lr_0 = 1.0804e-04
Loss = 7.5063e-04, PNorm = 55.3167, GNorm = 2.1168, lr_0 = 1.0804e-04
Validation rmse logD = 0.571260
Validation R2 logD = 0.792357
Epoch 66
Train function
Loss = 8.7896e-04, PNorm = 55.3206, GNorm = 2.4111, lr_0 = 1.0804e-04
Loss = 6.1993e-04, PNorm = 55.3246, GNorm = 1.0759, lr_0 = 1.0804e-04
Loss = 7.4638e-04, PNorm = 55.3286, GNorm = 3.2747, lr_0 = 1.0804e-04
Loss = 7.2536e-04, PNorm = 55.3337, GNorm = 1.8325, lr_0 = 1.0804e-04
Loss = 5.8809e-04, PNorm = 55.3375, GNorm = 1.5523, lr_0 = 1.0804e-04
Loss = 5.9704e-04, PNorm = 55.3407, GNorm = 2.3382, lr_0 = 1.0804e-04
Validation rmse logD = 0.519939
Validation R2 logD = 0.827990
Epoch 67
Train function
Loss = 5.6319e-04, PNorm = 55.3445, GNorm = 6.4135, lr_0 = 1.0804e-04
Loss = 6.1432e-04, PNorm = 55.3472, GNorm = 3.7974, lr_0 = 1.0804e-04
Loss = 5.6578e-04, PNorm = 55.3510, GNorm = 5.8839, lr_0 = 1.0804e-04
Loss = 6.9694e-04, PNorm = 55.3545, GNorm = 3.3648, lr_0 = 1.0804e-04
Loss = 7.8367e-04, PNorm = 55.3580, GNorm = 1.8323, lr_0 = 1.0804e-04
Loss = 6.2857e-04, PNorm = 55.3630, GNorm = 4.3612, lr_0 = 1.0804e-04
Validation rmse logD = 0.533903
Validation R2 logD = 0.818626
Epoch 68
Train function
Loss = 5.9478e-04, PNorm = 55.3672, GNorm = 1.7925, lr_0 = 1.0804e-04
Loss = 4.9224e-04, PNorm = 55.3709, GNorm = 2.5243, lr_0 = 1.0804e-04
Loss = 5.4941e-04, PNorm = 55.3747, GNorm = 3.9238, lr_0 = 1.0804e-04
Loss = 5.3164e-04, PNorm = 55.3769, GNorm = 2.7862, lr_0 = 1.0804e-04
Loss = 5.3768e-04, PNorm = 55.3811, GNorm = 0.9749, lr_0 = 1.0804e-04
Validation rmse logD = 0.531772
Validation R2 logD = 0.820071
Epoch 69
Train function
Loss = 4.8446e-04, PNorm = 55.3847, GNorm = 1.0853, lr_0 = 1.0804e-04
Loss = 5.0670e-04, PNorm = 55.3867, GNorm = 1.4764, lr_0 = 1.0804e-04
Loss = 8.0248e-04, PNorm = 55.3902, GNorm = 0.6378, lr_0 = 1.0804e-04
Loss = 7.7726e-04, PNorm = 55.3942, GNorm = 2.0739, lr_0 = 1.0804e-04
Loss = 7.7726e-04, PNorm = 55.3988, GNorm = 2.0132, lr_0 = 1.0804e-04
Loss = 8.2829e-04, PNorm = 55.4030, GNorm = 6.6262, lr_0 = 1.0804e-04
Validation rmse logD = 0.520002
Validation R2 logD = 0.827948
Epoch 70
Train function
Loss = 9.2387e-04, PNorm = 55.4080, GNorm = 5.0324, lr_0 = 1.0804e-04
Loss = 7.7439e-04, PNorm = 55.4120, GNorm = 6.1282, lr_0 = 1.0804e-04
Loss = 7.2852e-04, PNorm = 55.4163, GNorm = 1.9484, lr_0 = 1.0804e-04
Loss = 6.7276e-04, PNorm = 55.4198, GNorm = 4.5609, lr_0 = 1.0804e-04
Loss = 6.4106e-04, PNorm = 55.4249, GNorm = 3.1780, lr_0 = 1.0804e-04
Loss = 5.5244e-04, PNorm = 55.4291, GNorm = 1.1932, lr_0 = 1.0804e-04
Validation rmse logD = 0.530231
Validation R2 logD = 0.821112
Epoch 71
Train function
Loss = 4.4971e-04, PNorm = 55.4333, GNorm = 1.3498, lr_0 = 1.0804e-04
Loss = 4.6539e-04, PNorm = 55.4367, GNorm = 2.6040, lr_0 = 1.0804e-04
Loss = 4.2742e-04, PNorm = 55.4396, GNorm = 0.8950, lr_0 = 1.0804e-04
Loss = 4.6216e-04, PNorm = 55.4431, GNorm = 2.0704, lr_0 = 1.0804e-04
Loss = 4.9589e-04, PNorm = 55.4471, GNorm = 0.7432, lr_0 = 1.0804e-04
Validation rmse logD = 0.517278
Validation R2 logD = 0.829745
Epoch 72
Train function
Loss = 3.4422e-04, PNorm = 55.4492, GNorm = 0.9151, lr_0 = 1.0804e-04
Loss = 4.7028e-04, PNorm = 55.4522, GNorm = 1.4877, lr_0 = 1.0804e-04
Loss = 3.2030e-04, PNorm = 55.4555, GNorm = 1.5937, lr_0 = 1.0804e-04
Loss = 3.1799e-04, PNorm = 55.4577, GNorm = 1.0809, lr_0 = 1.0804e-04
Loss = 4.5459e-04, PNorm = 55.4594, GNorm = 2.5423, lr_0 = 1.0804e-04
Loss = 6.5513e-04, PNorm = 55.4617, GNorm = 8.2748, lr_0 = 1.0804e-04
Validation rmse logD = 0.523432
Validation R2 logD = 0.825671
Epoch 73
Train function
Loss = 6.4709e-04, PNorm = 55.4647, GNorm = 1.3127, lr_0 = 1.0804e-04
Loss = 5.7618e-04, PNorm = 55.4687, GNorm = 1.0212, lr_0 = 1.0804e-04
Loss = 4.5284e-04, PNorm = 55.4721, GNorm = 0.9642, lr_0 = 1.0804e-04
Loss = 3.8322e-04, PNorm = 55.4758, GNorm = 1.1120, lr_0 = 1.0804e-04
Loss = 4.6096e-04, PNorm = 55.4795, GNorm = 1.2149, lr_0 = 1.0804e-04
Loss = 4.2608e-04, PNorm = 55.4833, GNorm = 1.4172, lr_0 = 1.0804e-04
Validation rmse logD = 0.520182
Validation R2 logD = 0.827829
Epoch 74
Train function
Loss = 3.5485e-04, PNorm = 55.4866, GNorm = 3.1703, lr_0 = 1.0804e-04
Loss = 3.3762e-04, PNorm = 55.4894, GNorm = 3.1161, lr_0 = 1.0804e-04
Loss = 5.1619e-04, PNorm = 55.4924, GNorm = 1.7352, lr_0 = 1.0804e-04
Loss = 4.9339e-04, PNorm = 55.4949, GNorm = 4.4983, lr_0 = 1.0804e-04
Loss = 6.3748e-04, PNorm = 55.4981, GNorm = 1.2732, lr_0 = 1.0804e-04
Validation rmse logD = 0.517349
Validation R2 logD = 0.829699
Epoch 75
Train function
Loss = 2.8468e-04, PNorm = 55.5027, GNorm = 0.8987, lr_0 = 1.0804e-04
Loss = 4.5523e-04, PNorm = 55.5060, GNorm = 2.7522, lr_0 = 1.0804e-04
Loss = 5.4204e-04, PNorm = 55.5095, GNorm = 0.8419, lr_0 = 1.0804e-04
Loss = 3.0993e-04, PNorm = 55.5136, GNorm = 1.4682, lr_0 = 1.0804e-04
Loss = 3.8215e-04, PNorm = 55.5166, GNorm = 1.2977, lr_0 = 1.0804e-04
Loss = 4.0502e-04, PNorm = 55.5192, GNorm = 1.3192, lr_0 = 1.0804e-04
Validation rmse logD = 0.520001
Validation R2 logD = 0.827948
Epoch 76
Train function
Loss = 3.6282e-04, PNorm = 55.5234, GNorm = 1.8406, lr_0 = 1.0804e-04
Loss = 3.6021e-04, PNorm = 55.5268, GNorm = 3.8791, lr_0 = 1.0804e-04
Loss = 5.1781e-04, PNorm = 55.5302, GNorm = 2.0473, lr_0 = 1.0804e-04
Loss = 4.7816e-04, PNorm = 55.5334, GNorm = 1.3722, lr_0 = 1.0804e-04
Loss = 4.1441e-04, PNorm = 55.5361, GNorm = 2.3285, lr_0 = 1.0804e-04
Loss = 3.4971e-04, PNorm = 55.5390, GNorm = 1.2023, lr_0 = 1.0804e-04
Validation rmse logD = 0.507406
Validation R2 logD = 0.836182
Epoch 77
Train function
Loss = 3.5093e-04, PNorm = 55.5422, GNorm = 2.6425, lr_0 = 1.0804e-04
Loss = 3.1331e-04, PNorm = 55.5456, GNorm = 0.8393, lr_0 = 1.0804e-04
Loss = 3.7928e-04, PNorm = 55.5484, GNorm = 1.9454, lr_0 = 1.0804e-04
Loss = 3.6125e-04, PNorm = 55.5504, GNorm = 0.9815, lr_0 = 1.0804e-04
Loss = 5.0690e-04, PNorm = 55.5528, GNorm = 2.4553, lr_0 = 1.0804e-04
Validation rmse logD = 0.531589
Validation R2 logD = 0.820195
Epoch 78
Train function
Loss = 3.3652e-04, PNorm = 55.5560, GNorm = 1.4716, lr_0 = 1.0804e-04
Loss = 3.3736e-04, PNorm = 55.5582, GNorm = 0.8155, lr_0 = 1.0804e-04
Loss = 3.5747e-04, PNorm = 55.5618, GNorm = 1.8410, lr_0 = 1.0804e-04
Loss = 4.0325e-04, PNorm = 55.5662, GNorm = 1.8414, lr_0 = 1.0804e-04
Loss = 4.5265e-04, PNorm = 55.5683, GNorm = 0.7758, lr_0 = 1.0804e-04
Loss = 6.6359e-04, PNorm = 55.5703, GNorm = 5.8707, lr_0 = 1.0804e-04
Validation rmse logD = 0.561743
Validation R2 logD = 0.799218
Epoch 79
Train function
Loss = 5.6846e-04, PNorm = 55.5745, GNorm = 1.0584, lr_0 = 1.0804e-04
Loss = 3.5083e-04, PNorm = 55.5778, GNorm = 2.1153, lr_0 = 1.0804e-04
Loss = 3.8286e-04, PNorm = 55.5807, GNorm = 4.1619, lr_0 = 1.0804e-04
Loss = 4.3736e-04, PNorm = 55.5844, GNorm = 2.3717, lr_0 = 1.0804e-04
Loss = 3.7635e-04, PNorm = 55.5873, GNorm = 0.8488, lr_0 = 1.0804e-04
Loss = 3.8175e-04, PNorm = 55.5906, GNorm = 1.0408, lr_0 = 1.0804e-04
Validation rmse logD = 0.511200
Validation R2 logD = 0.833723
Epoch 80
Train function
Loss = 2.9540e-04, PNorm = 55.5937, GNorm = 0.8267, lr_0 = 1.0804e-04
Loss = 3.2493e-04, PNorm = 55.5966, GNorm = 1.5768, lr_0 = 1.0804e-04
Loss = 3.5743e-04, PNorm = 55.5999, GNorm = 1.0594, lr_0 = 1.0804e-04
Loss = 3.2433e-04, PNorm = 55.6025, GNorm = 3.2412, lr_0 = 1.0804e-04
Loss = 3.9415e-04, PNorm = 55.6045, GNorm = 2.2704, lr_0 = 1.0804e-04
Validation rmse logD = 0.530704
Validation R2 logD = 0.820793
Epoch 81
Train function
Loss = 3.4600e-04, PNorm = 55.6071, GNorm = 3.5982, lr_0 = 1.0804e-04
Loss = 4.1024e-04, PNorm = 55.6089, GNorm = 1.5020, lr_0 = 1.0804e-04
Loss = 3.8277e-04, PNorm = 55.6117, GNorm = 2.8690, lr_0 = 1.0804e-04
Loss = 3.9070e-04, PNorm = 55.6156, GNorm = 1.8665, lr_0 = 1.0804e-04
Loss = 3.1963e-04, PNorm = 55.6187, GNorm = 2.4665, lr_0 = 1.0804e-04
Loss = 3.4277e-04, PNorm = 55.6212, GNorm = 2.3080, lr_0 = 1.0804e-04
Validation rmse logD = 0.538510
Validation R2 logD = 0.815482
Epoch 82
Train function
Loss = 6.0070e-04, PNorm = 55.6267, GNorm = 2.5834, lr_0 = 1.0804e-04
Loss = 4.4015e-04, PNorm = 55.6298, GNorm = 0.5790, lr_0 = 1.0804e-04
Loss = 3.2312e-04, PNorm = 55.6331, GNorm = 1.0829, lr_0 = 1.0804e-04
Loss = 2.4578e-04, PNorm = 55.6359, GNorm = 0.9572, lr_0 = 1.0804e-04
Loss = 3.4568e-04, PNorm = 55.6390, GNorm = 1.9986, lr_0 = 1.0804e-04
Loss = 2.8677e-04, PNorm = 55.6418, GNorm = 1.5525, lr_0 = 1.0804e-04
Validation rmse logD = 0.519950
Validation R2 logD = 0.827982
Epoch 83
Train function
Loss = 2.7030e-04, PNorm = 55.6441, GNorm = 0.5185, lr_0 = 1.0804e-04
Loss = 3.1957e-04, PNorm = 55.6465, GNorm = 3.8619, lr_0 = 1.0804e-04
Loss = 3.1706e-04, PNorm = 55.6486, GNorm = 0.9203, lr_0 = 1.0804e-04
Loss = 3.1048e-04, PNorm = 55.6512, GNorm = 1.7682, lr_0 = 1.0804e-04
Loss = 3.6329e-04, PNorm = 55.6539, GNorm = 0.8332, lr_0 = 1.0804e-04
Validation rmse logD = 0.519226
Validation R2 logD = 0.828461
Epoch 84
Train function
Loss = 3.5316e-04, PNorm = 55.6571, GNorm = 1.4532, lr_0 = 1.0804e-04
Loss = 4.6446e-04, PNorm = 55.6602, GNorm = 3.3673, lr_0 = 1.0804e-04
Loss = 6.1034e-04, PNorm = 55.6637, GNorm = 3.8057, lr_0 = 1.0804e-04
Loss = 3.6631e-04, PNorm = 55.6676, GNorm = 1.0122, lr_0 = 1.0804e-04
Loss = 2.9086e-04, PNorm = 55.6712, GNorm = 2.0788, lr_0 = 1.0804e-04
Loss = 3.7691e-04, PNorm = 55.6752, GNorm = 0.7766, lr_0 = 1.0804e-04
Validation rmse logD = 0.520247
Validation R2 logD = 0.827786
Epoch 85
Train function
Loss = 3.2446e-04, PNorm = 55.6767, GNorm = 2.0872, lr_0 = 1.0804e-04
Loss = 3.0123e-04, PNorm = 55.6800, GNorm = 1.5534, lr_0 = 1.0804e-04
Loss = 2.8801e-04, PNorm = 55.6836, GNorm = 1.0143, lr_0 = 1.0804e-04
Loss = 3.1490e-04, PNorm = 55.6854, GNorm = 1.5296, lr_0 = 1.0804e-04
Loss = 4.1100e-04, PNorm = 55.6885, GNorm = 4.6325, lr_0 = 1.0804e-04
Loss = 4.2417e-04, PNorm = 55.6918, GNorm = 0.6376, lr_0 = 1.0804e-04
Validation rmse logD = 0.518341
Validation R2 logD = 0.829045
Epoch 86
Train function
Loss = 3.1416e-04, PNorm = 55.6955, GNorm = 2.7208, lr_0 = 1.0804e-04
Loss = 3.3130e-04, PNorm = 55.6989, GNorm = 2.3042, lr_0 = 1.0804e-04
Loss = 3.4362e-04, PNorm = 55.7022, GNorm = 0.7809, lr_0 = 1.0804e-04
Loss = 2.7842e-04, PNorm = 55.7051, GNorm = 0.7688, lr_0 = 1.0804e-04
Loss = 3.2300e-04, PNorm = 55.7076, GNorm = 1.2064, lr_0 = 1.0804e-04
Validation rmse logD = 0.515104
Validation R2 logD = 0.831174
Epoch 87
Train function
Loss = 2.2947e-04, PNorm = 55.7101, GNorm = 1.8905, lr_0 = 1.0804e-04
Loss = 3.4064e-04, PNorm = 55.7118, GNorm = 0.9221, lr_0 = 1.0804e-04
Loss = 3.9493e-04, PNorm = 55.7143, GNorm = 2.8975, lr_0 = 1.0804e-04
Loss = 3.1320e-04, PNorm = 55.7182, GNorm = 0.8253, lr_0 = 1.0804e-04
Loss = 3.3237e-04, PNorm = 55.7212, GNorm = 2.9234, lr_0 = 1.0804e-04
Loss = 3.2968e-04, PNorm = 55.7232, GNorm = 0.8104, lr_0 = 1.0804e-04
Validation rmse logD = 0.518921
Validation R2 logD = 0.828662
Epoch 88
Train function
Loss = 5.9938e-04, PNorm = 55.7258, GNorm = 7.0444, lr_0 = 1.0804e-04
Loss = 5.0183e-04, PNorm = 55.7283, GNorm = 1.3850, lr_0 = 1.0804e-04
Loss = 3.4711e-04, PNorm = 55.7330, GNorm = 1.7267, lr_0 = 1.0804e-04
Loss = 2.6654e-04, PNorm = 55.7361, GNorm = 1.8604, lr_0 = 1.0804e-04
Loss = 3.1129e-04, PNorm = 55.7385, GNorm = 0.7214, lr_0 = 1.0804e-04
Loss = 3.4781e-04, PNorm = 55.7399, GNorm = 2.9256, lr_0 = 1.0804e-04
Loss = 6.0474e-04, PNorm = 55.7401, GNorm = 0.9246, lr_0 = 1.0804e-04
Validation rmse logD = 0.514940
Validation R2 logD = 0.831281
Epoch 89
Train function
Loss = 2.4902e-04, PNorm = 55.7432, GNorm = 1.4728, lr_0 = 1.0804e-04
Loss = 2.8316e-04, PNorm = 55.7458, GNorm = 1.6764, lr_0 = 1.0804e-04
Loss = 4.8607e-04, PNorm = 55.7478, GNorm = 4.8292, lr_0 = 1.0804e-04
Loss = 4.9591e-04, PNorm = 55.7500, GNorm = 3.2871, lr_0 = 1.0804e-04
Loss = 7.3790e-04, PNorm = 55.7542, GNorm = 7.1337, lr_0 = 1.0804e-04
Validation rmse logD = 0.523446
Validation R2 logD = 0.825661
Epoch 90
Train function
Loss = 8.7461e-04, PNorm = 55.7560, GNorm = 5.2629, lr_0 = 1.0804e-04
Loss = 6.9352e-04, PNorm = 55.7610, GNorm = 4.1073, lr_0 = 1.0804e-04
Loss = 5.2392e-04, PNorm = 55.7663, GNorm = 3.3248, lr_0 = 1.0804e-04
Loss = 3.9101e-04, PNorm = 55.7720, GNorm = 1.2675, lr_0 = 1.0804e-04
Loss = 3.7726e-04, PNorm = 55.7752, GNorm = 0.9281, lr_0 = 1.0804e-04
Loss = 3.6024e-04, PNorm = 55.7783, GNorm = 1.9390, lr_0 = 1.0804e-04
Validation rmse logD = 0.522497
Validation R2 logD = 0.826293
Epoch 91
Train function
Loss = 2.4335e-04, PNorm = 55.7818, GNorm = 0.7860, lr_0 = 1.0804e-04
Loss = 4.1897e-04, PNorm = 55.7847, GNorm = 3.4069, lr_0 = 1.0804e-04
Loss = 3.9990e-04, PNorm = 55.7877, GNorm = 3.5797, lr_0 = 1.0804e-04
Loss = 4.1853e-04, PNorm = 55.7914, GNorm = 1.6143, lr_0 = 1.0804e-04
Loss = 4.6353e-04, PNorm = 55.7944, GNorm = 3.9856, lr_0 = 1.0804e-04
Loss = 4.4615e-04, PNorm = 55.7979, GNorm = 3.6189, lr_0 = 1.0804e-04
Loss = 7.0806e-04, PNorm = 55.7984, GNorm = 3.0324, lr_0 = 1.0804e-04
Validation rmse logD = 0.527847
Validation R2 logD = 0.822718
Epoch 92
Train function
Loss = 5.2387e-04, PNorm = 55.8008, GNorm = 1.1529, lr_0 = 1.0804e-04
Loss = 4.8300e-04, PNorm = 55.8039, GNorm = 1.7049, lr_0 = 1.0804e-04
Loss = 3.1673e-04, PNorm = 55.8076, GNorm = 0.6208, lr_0 = 1.0804e-04
Loss = 4.4511e-04, PNorm = 55.8108, GNorm = 3.1081, lr_0 = 1.0804e-04
Loss = 4.4705e-04, PNorm = 55.8134, GNorm = 3.9558, lr_0 = 1.0804e-04
Validation rmse logD = 0.517285
Validation R2 logD = 0.829741
Epoch 93
Train function
Loss = 3.0745e-04, PNorm = 55.8163, GNorm = 1.7735, lr_0 = 1.0804e-04
Loss = 3.8216e-04, PNorm = 55.8194, GNorm = 0.8500, lr_0 = 1.0804e-04
Loss = 2.9632e-04, PNorm = 55.8220, GNorm = 0.7043, lr_0 = 1.0804e-04
Loss = 4.0421e-04, PNorm = 55.8235, GNorm = 1.8783, lr_0 = 1.0804e-04
Loss = 4.7786e-04, PNorm = 55.8267, GNorm = 4.2920, lr_0 = 1.0804e-04
Loss = 3.5101e-04, PNorm = 55.8302, GNorm = 2.1978, lr_0 = 1.0804e-04
Validation rmse logD = 0.518370
Validation R2 logD = 0.829026
Epoch 94
Train function
Loss = 3.5308e-04, PNorm = 55.8332, GNorm = 1.7483, lr_0 = 1.0804e-04
Loss = 2.6108e-04, PNorm = 55.8373, GNorm = 0.9218, lr_0 = 1.0804e-04
Loss = 2.7013e-04, PNorm = 55.8401, GNorm = 1.2080, lr_0 = 1.0804e-04
Loss = 2.5421e-04, PNorm = 55.8423, GNorm = 2.1871, lr_0 = 1.0804e-04
Loss = 2.3423e-04, PNorm = 55.8443, GNorm = 0.6310, lr_0 = 1.0804e-04
Loss = 2.3648e-04, PNorm = 55.8469, GNorm = 1.2378, lr_0 = 1.0804e-04
Loss = 4.0176e-04, PNorm = 55.8470, GNorm = 2.4865, lr_0 = 1.0804e-04
Validation rmse logD = 0.510850
Validation R2 logD = 0.833950
Epoch 95
Train function
Loss = 2.3164e-04, PNorm = 55.8480, GNorm = 1.3491, lr_0 = 1.0804e-04
Loss = 2.3384e-04, PNorm = 55.8495, GNorm = 1.0980, lr_0 = 1.0804e-04
Loss = 2.1329e-04, PNorm = 55.8525, GNorm = 0.5590, lr_0 = 1.0804e-04
Loss = 2.4267e-04, PNorm = 55.8545, GNorm = 1.1196, lr_0 = 1.0804e-04
Loss = 2.2641e-04, PNorm = 55.8574, GNorm = 0.6591, lr_0 = 1.0804e-04
Validation rmse logD = 0.512538
Validation R2 logD = 0.832851
Epoch 96
Train function
Loss = 1.6913e-04, PNorm = 55.8593, GNorm = 0.6793, lr_0 = 1.0804e-04
Loss = 1.8644e-04, PNorm = 55.8616, GNorm = 2.0823, lr_0 = 1.0804e-04
Loss = 1.9634e-04, PNorm = 55.8625, GNorm = 1.0696, lr_0 = 1.0804e-04
Loss = 2.1746e-04, PNorm = 55.8639, GNorm = 0.9042, lr_0 = 1.0804e-04
Loss = 2.5203e-04, PNorm = 55.8659, GNorm = 2.5328, lr_0 = 1.0804e-04
Loss = 2.5692e-04, PNorm = 55.8681, GNorm = 1.4217, lr_0 = 1.0804e-04
Validation rmse logD = 0.515902
Validation R2 logD = 0.830650
Epoch 97
Train function
Loss = 1.9288e-04, PNorm = 55.8689, GNorm = 0.4895, lr_0 = 1.0804e-04
Loss = 2.1699e-04, PNorm = 55.8715, GNorm = 3.1949, lr_0 = 1.0804e-04
Loss = 2.0069e-04, PNorm = 55.8742, GNorm = 0.7664, lr_0 = 1.0804e-04
Loss = 2.3119e-04, PNorm = 55.8776, GNorm = 3.5044, lr_0 = 1.0804e-04
Loss = 3.1795e-04, PNorm = 55.8797, GNorm = 2.9700, lr_0 = 1.0804e-04
Loss = 3.0723e-04, PNorm = 55.8818, GNorm = 1.3902, lr_0 = 1.0804e-04
Loss = 3.7509e-04, PNorm = 55.8821, GNorm = 0.9495, lr_0 = 1.0804e-04
Validation rmse logD = 0.511689
Validation R2 logD = 0.833405
Epoch 98
Train function
Loss = 2.8643e-04, PNorm = 55.8841, GNorm = 2.3361, lr_0 = 1.0804e-04
Loss = 2.7559e-04, PNorm = 55.8857, GNorm = 0.6362, lr_0 = 1.0804e-04
Loss = 3.4526e-04, PNorm = 55.8888, GNorm = 3.8225, lr_0 = 1.0804e-04
Loss = 3.8320e-04, PNorm = 55.8917, GNorm = 2.2132, lr_0 = 1.0804e-04
Loss = 3.0422e-04, PNorm = 55.8956, GNorm = 3.6517, lr_0 = 1.0804e-04
Validation rmse logD = 0.519840
Validation R2 logD = 0.828055
Epoch 99
Train function
Loss = 4.6147e-04, PNorm = 55.8964, GNorm = 1.2721, lr_0 = 1.0804e-04
Loss = 4.1527e-04, PNorm = 55.8987, GNorm = 3.2060, lr_0 = 1.0804e-04
Loss = 3.4489e-04, PNorm = 55.9028, GNorm = 2.6546, lr_0 = 1.0804e-04
Loss = 2.6753e-04, PNorm = 55.9062, GNorm = 1.4819, lr_0 = 1.0804e-04
Loss = 2.6199e-04, PNorm = 55.9095, GNorm = 3.7350, lr_0 = 1.0804e-04
Loss = 3.2168e-04, PNorm = 55.9124, GNorm = 1.6874, lr_0 = 1.0804e-04
Validation rmse logD = 0.524947
Validation R2 logD = 0.824660
Model 0 best validation rmse = 0.507406 on epoch 76
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.578928
Model 0 test R2 logD = 0.792505
Ensemble test rmse  logD= 0.578928
Ensemble test R2  logD= 0.792505
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2832,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.3531e-02, PNorm = 52.9125, GNorm = 9.3832, lr_0 = 1.0804e-04
Loss = 1.9336e-02, PNorm = 52.9146, GNorm = 7.5281, lr_0 = 1.0804e-04
Loss = 1.9188e-02, PNorm = 52.9174, GNorm = 2.7782, lr_0 = 1.0804e-04
Loss = 1.6129e-02, PNorm = 52.9201, GNorm = 7.3626, lr_0 = 1.0804e-04
Loss = 1.5184e-02, PNorm = 52.9228, GNorm = 5.7809, lr_0 = 1.0804e-04
Validation rmse logD = 1.033791
Validation R2 logD = 0.275473
Epoch 1
Train function
Loss = 1.2518e-02, PNorm = 52.9267, GNorm = 2.2439, lr_0 = 1.0804e-04
Loss = 1.4781e-02, PNorm = 52.9312, GNorm = 1.7203, lr_0 = 1.0804e-04
Loss = 1.4210e-02, PNorm = 52.9359, GNorm = 2.1848, lr_0 = 1.0804e-04
Loss = 1.3017e-02, PNorm = 52.9408, GNorm = 1.8570, lr_0 = 1.0804e-04
Loss = 1.3044e-02, PNorm = 52.9464, GNorm = 2.2407, lr_0 = 1.0804e-04
Loss = 1.2717e-02, PNorm = 52.9523, GNorm = 8.3287, lr_0 = 1.0804e-04
Validation rmse logD = 0.951274
Validation R2 logD = 0.386520
Epoch 2
Train function
Loss = 1.2323e-02, PNorm = 52.9594, GNorm = 1.5117, lr_0 = 1.0804e-04
Loss = 1.1476e-02, PNorm = 52.9672, GNorm = 6.3409, lr_0 = 1.0804e-04
Loss = 1.1037e-02, PNorm = 52.9745, GNorm = 3.9651, lr_0 = 1.0804e-04
Loss = 1.0968e-02, PNorm = 52.9814, GNorm = 3.2398, lr_0 = 1.0804e-04
Loss = 1.1192e-02, PNorm = 52.9893, GNorm = 2.7242, lr_0 = 1.0804e-04
Validation rmse logD = 0.887990
Validation R2 logD = 0.465430
Epoch 3
Train function
Loss = 9.0634e-03, PNorm = 52.9982, GNorm = 3.4394, lr_0 = 1.0804e-04
Loss = 1.0269e-02, PNorm = 53.0074, GNorm = 3.9442, lr_0 = 1.0804e-04
Loss = 9.5706e-03, PNorm = 53.0146, GNorm = 1.9863, lr_0 = 1.0804e-04
Loss = 1.0153e-02, PNorm = 53.0215, GNorm = 6.8413, lr_0 = 1.0804e-04
Loss = 1.0855e-02, PNorm = 53.0288, GNorm = 10.1031, lr_0 = 1.0804e-04
Loss = 1.0072e-02, PNorm = 53.0368, GNorm = 3.4642, lr_0 = 1.0804e-04
Validation rmse logD = 0.880731
Validation R2 logD = 0.474134
Epoch 4
Train function
Loss = 9.7698e-03, PNorm = 53.0455, GNorm = 2.6637, lr_0 = 1.0804e-04
Loss = 9.1438e-03, PNorm = 53.0546, GNorm = 2.7054, lr_0 = 1.0804e-04
Loss = 1.0379e-02, PNorm = 53.0624, GNorm = 4.6391, lr_0 = 1.0804e-04
Loss = 9.0283e-03, PNorm = 53.0714, GNorm = 3.0073, lr_0 = 1.0804e-04
Loss = 8.5700e-03, PNorm = 53.0816, GNorm = 3.1487, lr_0 = 1.0804e-04
Loss = 8.4043e-03, PNorm = 53.0911, GNorm = 3.0314, lr_0 = 1.0804e-04
Validation rmse logD = 0.829164
Validation R2 logD = 0.533910
Epoch 5
Train function
Loss = 7.5188e-03, PNorm = 53.0991, GNorm = 4.8041, lr_0 = 1.0804e-04
Loss = 8.2282e-03, PNorm = 53.1079, GNorm = 1.8023, lr_0 = 1.0804e-04
Loss = 8.4128e-03, PNorm = 53.1177, GNorm = 3.3370, lr_0 = 1.0804e-04
Loss = 8.9359e-03, PNorm = 53.1265, GNorm = 1.6677, lr_0 = 1.0804e-04
Loss = 8.1715e-03, PNorm = 53.1366, GNorm = 7.5244, lr_0 = 1.0804e-04
Validation rmse logD = 0.817618
Validation R2 logD = 0.546800
Epoch 6
Train function
Loss = 5.1738e-03, PNorm = 53.1484, GNorm = 5.4278, lr_0 = 1.0804e-04
Loss = 8.3898e-03, PNorm = 53.1582, GNorm = 8.0403, lr_0 = 1.0804e-04
Loss = 7.4316e-03, PNorm = 53.1689, GNorm = 2.9076, lr_0 = 1.0804e-04
Loss = 8.6780e-03, PNorm = 53.1801, GNorm = 4.7960, lr_0 = 1.0804e-04
Loss = 7.6853e-03, PNorm = 53.1893, GNorm = 6.0790, lr_0 = 1.0804e-04
Loss = 7.6351e-03, PNorm = 53.1998, GNorm = 2.8001, lr_0 = 1.0804e-04
Validation rmse logD = 0.792414
Validation R2 logD = 0.574310
Epoch 7
Train function
Loss = 5.4487e-03, PNorm = 53.2100, GNorm = 1.2559, lr_0 = 1.0804e-04
Loss = 6.1591e-03, PNorm = 53.2197, GNorm = 3.3666, lr_0 = 1.0804e-04
Loss = 6.7377e-03, PNorm = 53.2317, GNorm = 2.3784, lr_0 = 1.0804e-04
Loss = 6.8932e-03, PNorm = 53.2423, GNorm = 2.6484, lr_0 = 1.0804e-04
Loss = 7.4848e-03, PNorm = 53.2515, GNorm = 4.6159, lr_0 = 1.0804e-04
Loss = 7.2355e-03, PNorm = 53.2601, GNorm = 6.7445, lr_0 = 1.0804e-04
Validation rmse logD = 0.779174
Validation R2 logD = 0.588417
Epoch 8
Train function
Loss = 5.4011e-03, PNorm = 53.2699, GNorm = 2.9646, lr_0 = 1.0804e-04
Loss = 6.7825e-03, PNorm = 53.2799, GNorm = 1.2778, lr_0 = 1.0804e-04
Loss = 5.8532e-03, PNorm = 53.2901, GNorm = 2.1659, lr_0 = 1.0804e-04
Loss = 5.5631e-03, PNorm = 53.3008, GNorm = 3.2875, lr_0 = 1.0804e-04
Loss = 6.7632e-03, PNorm = 53.3085, GNorm = 2.2817, lr_0 = 1.0804e-04
Validation rmse logD = 0.737940
Validation R2 logD = 0.630826
Epoch 9
Train function
Loss = 4.3278e-03, PNorm = 53.3201, GNorm = 2.7287, lr_0 = 1.0804e-04
Loss = 5.9032e-03, PNorm = 53.3314, GNorm = 7.7144, lr_0 = 1.0804e-04
Loss = 6.2660e-03, PNorm = 53.3429, GNorm = 7.1238, lr_0 = 1.0804e-04
Loss = 6.2017e-03, PNorm = 53.3521, GNorm = 6.3693, lr_0 = 1.0804e-04
Loss = 6.2886e-03, PNorm = 53.3609, GNorm = 2.8881, lr_0 = 1.0804e-04
Loss = 6.8003e-03, PNorm = 53.3696, GNorm = 2.9864, lr_0 = 1.0804e-04
Validation rmse logD = 0.714829
Validation R2 logD = 0.653588
Epoch 10
Train function
Loss = 5.9773e-03, PNorm = 53.3787, GNorm = 9.1241, lr_0 = 1.0804e-04
Loss = 6.3059e-03, PNorm = 53.3876, GNorm = 4.0853, lr_0 = 1.0804e-04
Loss = 5.4613e-03, PNorm = 53.3976, GNorm = 6.7661, lr_0 = 1.0804e-04
Loss = 5.1711e-03, PNorm = 53.4081, GNorm = 5.3652, lr_0 = 1.0804e-04
Loss = 4.4507e-03, PNorm = 53.4181, GNorm = 1.6913, lr_0 = 1.0804e-04
Loss = 4.8719e-03, PNorm = 53.4263, GNorm = 3.1130, lr_0 = 1.0804e-04
Validation rmse logD = 0.738739
Validation R2 logD = 0.630026
Epoch 11
Train function
Loss = 5.1444e-03, PNorm = 53.4359, GNorm = 2.6956, lr_0 = 1.0804e-04
Loss = 5.1010e-03, PNorm = 53.4470, GNorm = 9.8748, lr_0 = 1.0804e-04
Loss = 4.4272e-03, PNorm = 53.4537, GNorm = 2.1699, lr_0 = 1.0804e-04
Loss = 4.7618e-03, PNorm = 53.4623, GNorm = 1.6004, lr_0 = 1.0804e-04
Loss = 5.3613e-03, PNorm = 53.4709, GNorm = 5.1817, lr_0 = 1.0804e-04
Validation rmse logD = 0.743963
Validation R2 logD = 0.624775
Epoch 12
Train function
Loss = 1.0042e-02, PNorm = 53.4799, GNorm = 9.7469, lr_0 = 1.0804e-04
Loss = 5.1239e-03, PNorm = 53.4903, GNorm = 12.3457, lr_0 = 1.0804e-04
Loss = 4.9630e-03, PNorm = 53.5000, GNorm = 4.1648, lr_0 = 1.0804e-04
Loss = 4.4585e-03, PNorm = 53.5087, GNorm = 4.4038, lr_0 = 1.0804e-04
Loss = 4.0750e-03, PNorm = 53.5182, GNorm = 3.7540, lr_0 = 1.0804e-04
Loss = 4.7057e-03, PNorm = 53.5261, GNorm = 5.3231, lr_0 = 1.0804e-04
Validation rmse logD = 0.700840
Validation R2 logD = 0.667014
Epoch 13
Train function
Loss = 4.1890e-03, PNorm = 53.5340, GNorm = 2.6712, lr_0 = 1.0804e-04
Loss = 4.4932e-03, PNorm = 53.5432, GNorm = 4.2267, lr_0 = 1.0804e-04
Loss = 4.4915e-03, PNorm = 53.5503, GNorm = 3.5723, lr_0 = 1.0804e-04
Loss = 5.1290e-03, PNorm = 53.5608, GNorm = 3.1712, lr_0 = 1.0804e-04
Loss = 4.3418e-03, PNorm = 53.5700, GNorm = 5.8552, lr_0 = 1.0804e-04
Loss = 3.6436e-03, PNorm = 53.5783, GNorm = 1.9045, lr_0 = 1.0804e-04
Validation rmse logD = 0.666597
Validation R2 logD = 0.698758
Epoch 14
Train function
Loss = 4.2115e-03, PNorm = 53.5856, GNorm = 5.9563, lr_0 = 1.0804e-04
Loss = 4.6691e-03, PNorm = 53.5949, GNorm = 2.4392, lr_0 = 1.0804e-04
Loss = 4.2619e-03, PNorm = 53.6021, GNorm = 4.3134, lr_0 = 1.0804e-04
Loss = 4.2546e-03, PNorm = 53.6108, GNorm = 2.9757, lr_0 = 1.0804e-04
Loss = 4.6556e-03, PNorm = 53.6193, GNorm = 5.6448, lr_0 = 1.0804e-04
Validation rmse logD = 0.712237
Validation R2 logD = 0.656095
Epoch 15
Train function
Loss = 3.3614e-03, PNorm = 53.6278, GNorm = 8.2497, lr_0 = 1.0804e-04
Loss = 4.0419e-03, PNorm = 53.6359, GNorm = 3.6797, lr_0 = 1.0804e-04
Loss = 5.1251e-03, PNorm = 53.6447, GNorm = 7.0192, lr_0 = 1.0804e-04
Loss = 4.4765e-03, PNorm = 53.6517, GNorm = 9.4327, lr_0 = 1.0804e-04
Loss = 3.7197e-03, PNorm = 53.6613, GNorm = 2.4189, lr_0 = 1.0804e-04
Loss = 3.4904e-03, PNorm = 53.6694, GNorm = 5.1169, lr_0 = 1.0804e-04
Validation rmse logD = 0.694917
Validation R2 logD = 0.672618
Epoch 16
Train function
Loss = 3.3176e-03, PNorm = 53.6778, GNorm = 9.9395, lr_0 = 1.0804e-04
Loss = 4.2489e-03, PNorm = 53.6859, GNorm = 1.7055, lr_0 = 1.0804e-04
Loss = 3.8758e-03, PNorm = 53.6961, GNorm = 6.1694, lr_0 = 1.0804e-04
Loss = 3.8036e-03, PNorm = 53.7043, GNorm = 1.8925, lr_0 = 1.0804e-04
Loss = 3.1932e-03, PNorm = 53.7120, GNorm = 3.6979, lr_0 = 1.0804e-04
Loss = 3.4934e-03, PNorm = 53.7183, GNorm = 1.9646, lr_0 = 1.0804e-04
Validation rmse logD = 0.657153
Validation R2 logD = 0.707233
Epoch 17
Train function
Loss = 3.2171e-03, PNorm = 53.7245, GNorm = 7.9873, lr_0 = 1.0804e-04
Loss = 3.5050e-03, PNorm = 53.7322, GNorm = 4.0531, lr_0 = 1.0804e-04
Loss = 3.5030e-03, PNorm = 53.7382, GNorm = 4.4306, lr_0 = 1.0804e-04
Loss = 3.9800e-03, PNorm = 53.7459, GNorm = 2.7844, lr_0 = 1.0804e-04
Loss = 4.2951e-03, PNorm = 53.7561, GNorm = 6.9321, lr_0 = 1.0804e-04
Validation rmse logD = 0.656185
Validation R2 logD = 0.708095
Epoch 18
Train function
Loss = 3.0464e-03, PNorm = 53.7641, GNorm = 3.2004, lr_0 = 1.0804e-04
Loss = 3.2919e-03, PNorm = 53.7731, GNorm = 4.6471, lr_0 = 1.0804e-04
Loss = 3.2595e-03, PNorm = 53.7812, GNorm = 10.7640, lr_0 = 1.0804e-04
Loss = 3.9024e-03, PNorm = 53.7879, GNorm = 2.7057, lr_0 = 1.0804e-04
Loss = 4.4839e-03, PNorm = 53.7959, GNorm = 1.9511, lr_0 = 1.0804e-04
Loss = 5.1060e-03, PNorm = 53.8027, GNorm = 3.1918, lr_0 = 1.0804e-04
Validation rmse logD = 0.648432
Validation R2 logD = 0.714953
Epoch 19
Train function
Loss = 4.0847e-03, PNorm = 53.8103, GNorm = 3.5325, lr_0 = 1.0804e-04
Loss = 3.0050e-03, PNorm = 53.8207, GNorm = 4.0466, lr_0 = 1.0804e-04
Loss = 3.4516e-03, PNorm = 53.8297, GNorm = 4.7746, lr_0 = 1.0804e-04
Loss = 3.4446e-03, PNorm = 53.8362, GNorm = 1.4999, lr_0 = 1.0804e-04
Loss = 3.4501e-03, PNorm = 53.8438, GNorm = 7.3314, lr_0 = 1.0804e-04
Loss = 3.1165e-03, PNorm = 53.8520, GNorm = 6.0428, lr_0 = 1.0804e-04
Validation rmse logD = 0.671870
Validation R2 logD = 0.693973
Epoch 20
Train function
Loss = 3.3074e-03, PNorm = 53.8596, GNorm = 1.4965, lr_0 = 1.0804e-04
Loss = 3.0182e-03, PNorm = 53.8671, GNorm = 4.1295, lr_0 = 1.0804e-04
Loss = 3.1460e-03, PNorm = 53.8745, GNorm = 1.6697, lr_0 = 1.0804e-04
Loss = 2.9056e-03, PNorm = 53.8818, GNorm = 1.5189, lr_0 = 1.0804e-04
Loss = 3.5427e-03, PNorm = 53.8879, GNorm = 8.1721, lr_0 = 1.0804e-04
Validation rmse logD = 0.655990
Validation R2 logD = 0.708268
Epoch 21
Train function
Loss = 2.3575e-03, PNorm = 53.8945, GNorm = 4.0648, lr_0 = 1.0804e-04
Loss = 3.1681e-03, PNorm = 53.9027, GNorm = 5.6225, lr_0 = 1.0804e-04
Loss = 2.7962e-03, PNorm = 53.9093, GNorm = 1.5012, lr_0 = 1.0804e-04
Loss = 2.9044e-03, PNorm = 53.9172, GNorm = 3.1300, lr_0 = 1.0804e-04
Loss = 3.5848e-03, PNorm = 53.9236, GNorm = 3.8968, lr_0 = 1.0804e-04
Loss = 3.1397e-03, PNorm = 53.9324, GNorm = 4.2550, lr_0 = 1.0804e-04
Validation rmse logD = 0.618586
Validation R2 logD = 0.740589
Epoch 22
Train function
Loss = 2.8895e-03, PNorm = 53.9396, GNorm = 1.6213, lr_0 = 1.0804e-04
Loss = 2.9357e-03, PNorm = 53.9481, GNorm = 5.9950, lr_0 = 1.0804e-04
Loss = 2.6226e-03, PNorm = 53.9541, GNorm = 5.4725, lr_0 = 1.0804e-04
Loss = 2.7313e-03, PNorm = 53.9631, GNorm = 3.7326, lr_0 = 1.0804e-04
Loss = 2.2384e-03, PNorm = 53.9692, GNorm = 2.9776, lr_0 = 1.0804e-04
Loss = 3.0212e-03, PNorm = 53.9749, GNorm = 2.6777, lr_0 = 1.0804e-04
Validation rmse logD = 0.622287
Validation R2 logD = 0.737475
Epoch 23
Train function
Loss = 2.4794e-03, PNorm = 53.9813, GNorm = 1.5121, lr_0 = 1.0804e-04
Loss = 2.1227e-03, PNorm = 53.9868, GNorm = 1.6042, lr_0 = 1.0804e-04
Loss = 2.7687e-03, PNorm = 53.9933, GNorm = 6.3855, lr_0 = 1.0804e-04
Loss = 2.6154e-03, PNorm = 54.0014, GNorm = 5.2247, lr_0 = 1.0804e-04
Loss = 2.2989e-03, PNorm = 54.0098, GNorm = 2.2270, lr_0 = 1.0804e-04
Validation rmse logD = 0.627043
Validation R2 logD = 0.733447
Epoch 24
Train function
Loss = 1.9076e-03, PNorm = 54.0182, GNorm = 6.3781, lr_0 = 1.0804e-04
Loss = 2.6651e-03, PNorm = 54.0242, GNorm = 4.2595, lr_0 = 1.0804e-04
Loss = 2.3455e-03, PNorm = 54.0322, GNorm = 1.5796, lr_0 = 1.0804e-04
Loss = 2.4477e-03, PNorm = 54.0399, GNorm = 2.0316, lr_0 = 1.0804e-04
Loss = 2.5416e-03, PNorm = 54.0472, GNorm = 1.4224, lr_0 = 1.0804e-04
Loss = 2.4516e-03, PNorm = 54.0533, GNorm = 4.3299, lr_0 = 1.0804e-04
Validation rmse logD = 0.628360
Validation R2 logD = 0.732326
Epoch 25
Train function
Loss = 2.0629e-03, PNorm = 54.0598, GNorm = 3.9671, lr_0 = 1.0804e-04
Loss = 1.7444e-03, PNorm = 54.0674, GNorm = 2.9078, lr_0 = 1.0804e-04
Loss = 2.8381e-03, PNorm = 54.0752, GNorm = 5.1216, lr_0 = 1.0804e-04
Loss = 2.9031e-03, PNorm = 54.0818, GNorm = 8.4763, lr_0 = 1.0804e-04
Loss = 2.6342e-03, PNorm = 54.0873, GNorm = 1.2938, lr_0 = 1.0804e-04
Loss = 2.6933e-03, PNorm = 54.0954, GNorm = 1.4266, lr_0 = 1.0804e-04
Validation rmse logD = 0.619969
Validation R2 logD = 0.739427
Epoch 26
Train function
Loss = 2.2042e-03, PNorm = 54.1024, GNorm = 2.1554, lr_0 = 1.0804e-04
Loss = 2.5109e-03, PNorm = 54.1088, GNorm = 6.5247, lr_0 = 1.0804e-04
Loss = 3.3273e-03, PNorm = 54.1160, GNorm = 8.0460, lr_0 = 1.0804e-04
Loss = 3.4067e-03, PNorm = 54.1242, GNorm = 6.7751, lr_0 = 1.0804e-04
Loss = 3.3680e-03, PNorm = 54.1318, GNorm = 7.0138, lr_0 = 1.0804e-04
Validation rmse logD = 0.630315
Validation R2 logD = 0.730658
Epoch 27
Train function
Loss = 2.3683e-03, PNorm = 54.1402, GNorm = 2.7868, lr_0 = 1.0804e-04
Loss = 2.2321e-03, PNorm = 54.1494, GNorm = 3.8963, lr_0 = 1.0804e-04
Loss = 2.1485e-03, PNorm = 54.1560, GNorm = 4.1107, lr_0 = 1.0804e-04
Loss = 2.2550e-03, PNorm = 54.1640, GNorm = 5.9033, lr_0 = 1.0804e-04
Loss = 1.9501e-03, PNorm = 54.1717, GNorm = 1.9749, lr_0 = 1.0804e-04
Loss = 2.2079e-03, PNorm = 54.1771, GNorm = 2.4159, lr_0 = 1.0804e-04
Validation rmse logD = 0.631377
Validation R2 logD = 0.729750
Epoch 28
Train function
Loss = 1.9836e-03, PNorm = 54.1830, GNorm = 4.2169, lr_0 = 1.0804e-04
Loss = 1.6854e-03, PNorm = 54.1910, GNorm = 1.9097, lr_0 = 1.0804e-04
Loss = 2.0800e-03, PNorm = 54.1969, GNorm = 3.2252, lr_0 = 1.0804e-04
Loss = 2.6073e-03, PNorm = 54.2019, GNorm = 7.6678, lr_0 = 1.0804e-04
Loss = 2.2789e-03, PNorm = 54.2063, GNorm = 7.2403, lr_0 = 1.0804e-04
Loss = 2.0850e-03, PNorm = 54.2130, GNorm = 1.5030, lr_0 = 1.0804e-04
Validation rmse logD = 0.631739
Validation R2 logD = 0.729440
Epoch 29
Train function
Loss = 1.7306e-03, PNorm = 54.2190, GNorm = 4.1191, lr_0 = 1.0804e-04
Loss = 2.1277e-03, PNorm = 54.2253, GNorm = 2.1371, lr_0 = 1.0804e-04
Loss = 1.9678e-03, PNorm = 54.2317, GNorm = 3.4291, lr_0 = 1.0804e-04
Loss = 1.7364e-03, PNorm = 54.2385, GNorm = 3.2092, lr_0 = 1.0804e-04
Loss = 1.7752e-03, PNorm = 54.2461, GNorm = 2.4167, lr_0 = 1.0804e-04
Validation rmse logD = 0.619584
Validation R2 logD = 0.739751
Epoch 30
Train function
Loss = 1.1807e-03, PNorm = 54.2539, GNorm = 1.8731, lr_0 = 1.0804e-04
Loss = 1.8092e-03, PNorm = 54.2594, GNorm = 1.5080, lr_0 = 1.0804e-04
Loss = 2.0817e-03, PNorm = 54.2660, GNorm = 1.7120, lr_0 = 1.0804e-04
Loss = 1.6771e-03, PNorm = 54.2729, GNorm = 2.6785, lr_0 = 1.0804e-04
Loss = 1.7304e-03, PNorm = 54.2783, GNorm = 2.6505, lr_0 = 1.0804e-04
Loss = 2.0942e-03, PNorm = 54.2843, GNorm = 5.3333, lr_0 = 1.0804e-04
Validation rmse logD = 0.659858
Validation R2 logD = 0.704818
Epoch 31
Train function
Loss = 2.2489e-03, PNorm = 54.2913, GNorm = 5.1996, lr_0 = 1.0804e-04
Loss = 1.5344e-03, PNorm = 54.2974, GNorm = 3.7826, lr_0 = 1.0804e-04
Loss = 1.9421e-03, PNorm = 54.3028, GNorm = 3.3414, lr_0 = 1.0804e-04
Loss = 1.7426e-03, PNorm = 54.3089, GNorm = 7.7093, lr_0 = 1.0804e-04
Loss = 1.9780e-03, PNorm = 54.3135, GNorm = 1.9616, lr_0 = 1.0804e-04
Loss = 1.7849e-03, PNorm = 54.3208, GNorm = 4.1290, lr_0 = 1.0804e-04
Validation rmse logD = 0.601103
Validation R2 logD = 0.755044
Epoch 32
Train function
Loss = 1.8555e-03, PNorm = 54.3290, GNorm = 1.3778, lr_0 = 1.0804e-04
Loss = 1.6586e-03, PNorm = 54.3348, GNorm = 4.1822, lr_0 = 1.0804e-04
Loss = 1.5044e-03, PNorm = 54.3405, GNorm = 2.9354, lr_0 = 1.0804e-04
Loss = 1.5482e-03, PNorm = 54.3454, GNorm = 3.7139, lr_0 = 1.0804e-04
Loss = 1.8546e-03, PNorm = 54.3505, GNorm = 1.7347, lr_0 = 1.0804e-04
Validation rmse logD = 0.598076
Validation R2 logD = 0.757506
Epoch 33
Train function
Loss = 1.9161e-03, PNorm = 54.3572, GNorm = 4.6314, lr_0 = 1.0804e-04
Loss = 1.6018e-03, PNorm = 54.3641, GNorm = 1.4433, lr_0 = 1.0804e-04
Loss = 1.3973e-03, PNorm = 54.3713, GNorm = 3.1249, lr_0 = 1.0804e-04
Loss = 1.7841e-03, PNorm = 54.3783, GNorm = 3.6842, lr_0 = 1.0804e-04
Loss = 1.4940e-03, PNorm = 54.3854, GNorm = 1.7035, lr_0 = 1.0804e-04
Loss = 2.0068e-03, PNorm = 54.3913, GNorm = 2.4109, lr_0 = 1.0804e-04
Validation rmse logD = 0.604979
Validation R2 logD = 0.751876
Epoch 34
Train function
Loss = 2.0640e-03, PNorm = 54.3972, GNorm = 2.7972, lr_0 = 1.0804e-04
Loss = 1.4313e-03, PNorm = 54.4029, GNorm = 1.5362, lr_0 = 1.0804e-04
Loss = 1.5079e-03, PNorm = 54.4088, GNorm = 2.3256, lr_0 = 1.0804e-04
Loss = 1.3632e-03, PNorm = 54.4157, GNorm = 3.2967, lr_0 = 1.0804e-04
Loss = 1.4876e-03, PNorm = 54.4209, GNorm = 2.7267, lr_0 = 1.0804e-04
Loss = 1.4745e-03, PNorm = 54.4265, GNorm = 3.5369, lr_0 = 1.0804e-04
Validation rmse logD = 0.598187
Validation R2 logD = 0.757416
Epoch 35
Train function
Loss = 1.6030e-03, PNorm = 54.4318, GNorm = 2.8291, lr_0 = 1.0804e-04
Loss = 1.3126e-03, PNorm = 54.4393, GNorm = 3.7507, lr_0 = 1.0804e-04
Loss = 1.6587e-03, PNorm = 54.4447, GNorm = 5.5268, lr_0 = 1.0804e-04
Loss = 1.7128e-03, PNorm = 54.4506, GNorm = 3.0038, lr_0 = 1.0804e-04
Loss = 1.5483e-03, PNorm = 54.4547, GNorm = 5.5202, lr_0 = 1.0804e-04
Validation rmse logD = 0.647744
Validation R2 logD = 0.715557
Epoch 36
Train function
Loss = 2.0903e-03, PNorm = 54.4620, GNorm = 7.5059, lr_0 = 1.0804e-04
Loss = 1.2372e-03, PNorm = 54.4688, GNorm = 1.6402, lr_0 = 1.0804e-04
Loss = 1.3137e-03, PNorm = 54.4761, GNorm = 2.2782, lr_0 = 1.0804e-04
Loss = 1.4484e-03, PNorm = 54.4799, GNorm = 1.6048, lr_0 = 1.0804e-04
Loss = 1.2145e-03, PNorm = 54.4848, GNorm = 3.6968, lr_0 = 1.0804e-04
Loss = 1.7264e-03, PNorm = 54.4911, GNorm = 1.8895, lr_0 = 1.0804e-04
Validation rmse logD = 0.594847
Validation R2 logD = 0.760117
Epoch 37
Train function
Loss = 1.2679e-03, PNorm = 54.4974, GNorm = 4.4559, lr_0 = 1.0804e-04
Loss = 1.5651e-03, PNorm = 54.5041, GNorm = 5.8306, lr_0 = 1.0804e-04
Loss = 1.4117e-03, PNorm = 54.5091, GNorm = 2.2766, lr_0 = 1.0804e-04
Loss = 1.5989e-03, PNorm = 54.5144, GNorm = 7.0187, lr_0 = 1.0804e-04
Loss = 1.4459e-03, PNorm = 54.5195, GNorm = 1.7287, lr_0 = 1.0804e-04
Loss = 1.3011e-03, PNorm = 54.5246, GNorm = 2.3110, lr_0 = 1.0804e-04
Validation rmse logD = 0.594228
Validation R2 logD = 0.760616
Epoch 38
Train function
Loss = 1.0464e-03, PNorm = 54.5299, GNorm = 2.2288, lr_0 = 1.0804e-04
Loss = 1.1930e-03, PNorm = 54.5374, GNorm = 2.3646, lr_0 = 1.0804e-04
Loss = 1.2864e-03, PNorm = 54.5423, GNorm = 6.2965, lr_0 = 1.0804e-04
Loss = 1.4894e-03, PNorm = 54.5479, GNorm = 1.5041, lr_0 = 1.0804e-04
Loss = 1.4883e-03, PNorm = 54.5540, GNorm = 1.7067, lr_0 = 1.0804e-04
Validation rmse logD = 0.638851
Validation R2 logD = 0.723313
Epoch 39
Train function
Loss = 3.1097e-03, PNorm = 54.5603, GNorm = 8.5808, lr_0 = 1.0804e-04
Loss = 1.3493e-03, PNorm = 54.5655, GNorm = 2.6464, lr_0 = 1.0804e-04
Loss = 1.2506e-03, PNorm = 54.5709, GNorm = 3.1886, lr_0 = 1.0804e-04
Loss = 1.3545e-03, PNorm = 54.5771, GNorm = 5.0526, lr_0 = 1.0804e-04
Loss = 1.2216e-03, PNorm = 54.5826, GNorm = 4.2764, lr_0 = 1.0804e-04
Loss = 1.2399e-03, PNorm = 54.5877, GNorm = 1.9025, lr_0 = 1.0804e-04
Validation rmse logD = 0.605626
Validation R2 logD = 0.751344
Epoch 40
Train function
Loss = 1.2160e-03, PNorm = 54.5933, GNorm = 1.7281, lr_0 = 1.0804e-04
Loss = 1.3752e-03, PNorm = 54.5988, GNorm = 2.2036, lr_0 = 1.0804e-04
Loss = 1.2744e-03, PNorm = 54.6055, GNorm = 3.8904, lr_0 = 1.0804e-04
Loss = 1.2049e-03, PNorm = 54.6112, GNorm = 6.7204, lr_0 = 1.0804e-04
Loss = 1.0170e-03, PNorm = 54.6143, GNorm = 2.2673, lr_0 = 1.0804e-04
Loss = 1.3118e-03, PNorm = 54.6194, GNorm = 5.3417, lr_0 = 1.0804e-04
Validation rmse logD = 0.594315
Validation R2 logD = 0.760546
Epoch 41
Train function
Loss = 1.2175e-03, PNorm = 54.6269, GNorm = 4.3934, lr_0 = 1.0804e-04
Loss = 8.6305e-04, PNorm = 54.6321, GNorm = 2.6656, lr_0 = 1.0804e-04
Loss = 9.8237e-04, PNorm = 54.6361, GNorm = 3.7596, lr_0 = 1.0804e-04
Loss = 1.0258e-03, PNorm = 54.6415, GNorm = 1.0512, lr_0 = 1.0804e-04
Loss = 1.5902e-03, PNorm = 54.6458, GNorm = 6.2429, lr_0 = 1.0804e-04
Validation rmse logD = 0.591071
Validation R2 logD = 0.763152
Epoch 42
Train function
Loss = 1.2916e-03, PNorm = 54.6505, GNorm = 1.7311, lr_0 = 1.0804e-04
Loss = 1.4020e-03, PNorm = 54.6569, GNorm = 1.3703, lr_0 = 1.0804e-04
Loss = 9.4429e-04, PNorm = 54.6622, GNorm = 1.3145, lr_0 = 1.0804e-04
Loss = 1.0426e-03, PNorm = 54.6681, GNorm = 2.1607, lr_0 = 1.0804e-04
Loss = 1.3592e-03, PNorm = 54.6733, GNorm = 4.4647, lr_0 = 1.0804e-04
Loss = 1.1995e-03, PNorm = 54.6775, GNorm = 1.0537, lr_0 = 1.0804e-04
Validation rmse logD = 0.585864
Validation R2 logD = 0.767308
Epoch 43
Train function
Loss = 1.1270e-03, PNorm = 54.6829, GNorm = 1.8963, lr_0 = 1.0804e-04
Loss = 8.4675e-04, PNorm = 54.6889, GNorm = 1.2138, lr_0 = 1.0804e-04
Loss = 1.0744e-03, PNorm = 54.6951, GNorm = 1.5341, lr_0 = 1.0804e-04
Loss = 1.3681e-03, PNorm = 54.7005, GNorm = 4.3555, lr_0 = 1.0804e-04
Loss = 1.8831e-03, PNorm = 54.7033, GNorm = 11.5137, lr_0 = 1.0804e-04
Loss = 1.6696e-03, PNorm = 54.7089, GNorm = 1.7936, lr_0 = 1.0804e-04
Validation rmse logD = 0.659970
Validation R2 logD = 0.704718
Epoch 44
Train function
Loss = 1.6180e-03, PNorm = 54.7155, GNorm = 6.0387, lr_0 = 1.0804e-04
Loss = 1.0730e-03, PNorm = 54.7218, GNorm = 1.3774, lr_0 = 1.0804e-04
Loss = 1.2022e-03, PNorm = 54.7268, GNorm = 2.9794, lr_0 = 1.0804e-04
Loss = 1.0778e-03, PNorm = 54.7311, GNorm = 3.3596, lr_0 = 1.0804e-04
Loss = 1.2955e-03, PNorm = 54.7365, GNorm = 1.5428, lr_0 = 1.0804e-04
Validation rmse logD = 0.595925
Validation R2 logD = 0.759247
Epoch 45
Train function
Loss = 9.7901e-04, PNorm = 54.7429, GNorm = 1.5584, lr_0 = 1.0804e-04
Loss = 9.4676e-04, PNorm = 54.7484, GNorm = 3.1021, lr_0 = 1.0804e-04
Loss = 1.0250e-03, PNorm = 54.7533, GNorm = 6.7852, lr_0 = 1.0804e-04
Loss = 9.7890e-04, PNorm = 54.7580, GNorm = 3.8964, lr_0 = 1.0804e-04
Loss = 9.9918e-04, PNorm = 54.7624, GNorm = 1.2954, lr_0 = 1.0804e-04
Loss = 1.1385e-03, PNorm = 54.7673, GNorm = 1.3388, lr_0 = 1.0804e-04
Validation rmse logD = 0.584007
Validation R2 logD = 0.768781
Epoch 46
Train function
Loss = 8.4174e-04, PNorm = 54.7723, GNorm = 1.3353, lr_0 = 1.0804e-04
Loss = 8.3952e-04, PNorm = 54.7772, GNorm = 1.3347, lr_0 = 1.0804e-04
Loss = 8.1404e-04, PNorm = 54.7824, GNorm = 2.9481, lr_0 = 1.0804e-04
Loss = 1.0353e-03, PNorm = 54.7859, GNorm = 1.1443, lr_0 = 1.0804e-04
Loss = 9.9748e-04, PNorm = 54.7905, GNorm = 1.5059, lr_0 = 1.0804e-04
Loss = 9.3334e-04, PNorm = 54.7959, GNorm = 2.3802, lr_0 = 1.0804e-04
Validation rmse logD = 0.588258
Validation R2 logD = 0.765402
Epoch 47
Train function
Loss = 7.4509e-04, PNorm = 54.8013, GNorm = 3.3266, lr_0 = 1.0804e-04
Loss = 7.1399e-04, PNorm = 54.8064, GNorm = 1.2759, lr_0 = 1.0804e-04
Loss = 8.3299e-04, PNorm = 54.8118, GNorm = 1.5038, lr_0 = 1.0804e-04
Loss = 9.7391e-04, PNorm = 54.8168, GNorm = 3.2058, lr_0 = 1.0804e-04
Loss = 1.1390e-03, PNorm = 54.8213, GNorm = 1.6564, lr_0 = 1.0804e-04
Validation rmse logD = 0.583088
Validation R2 logD = 0.769508
Epoch 48
Train function
Loss = 5.8827e-04, PNorm = 54.8255, GNorm = 2.8104, lr_0 = 1.0804e-04
Loss = 6.9935e-04, PNorm = 54.8294, GNorm = 2.9885, lr_0 = 1.0804e-04
Loss = 7.9548e-04, PNorm = 54.8340, GNorm = 3.1595, lr_0 = 1.0804e-04
Loss = 8.8100e-04, PNorm = 54.8389, GNorm = 3.0433, lr_0 = 1.0804e-04
Loss = 1.2310e-03, PNorm = 54.8421, GNorm = 3.1711, lr_0 = 1.0804e-04
Loss = 9.9172e-04, PNorm = 54.8476, GNorm = 1.4052, lr_0 = 1.0804e-04
Validation rmse logD = 0.627293
Validation R2 logD = 0.733234
Epoch 49
Train function
Loss = 8.7789e-04, PNorm = 54.8533, GNorm = 2.3243, lr_0 = 1.0804e-04
Loss = 8.0888e-04, PNorm = 54.8576, GNorm = 1.2955, lr_0 = 1.0804e-04
Loss = 8.0084e-04, PNorm = 54.8617, GNorm = 2.5169, lr_0 = 1.0804e-04
Loss = 9.2917e-04, PNorm = 54.8665, GNorm = 1.4802, lr_0 = 1.0804e-04
Loss = 8.7203e-04, PNorm = 54.8705, GNorm = 1.3623, lr_0 = 1.0804e-04
Loss = 1.0997e-03, PNorm = 54.8747, GNorm = 8.0187, lr_0 = 1.0804e-04
Validation rmse logD = 0.584248
Validation R2 logD = 0.768589
Epoch 50
Train function
Loss = 1.0468e-03, PNorm = 54.8786, GNorm = 3.9032, lr_0 = 1.0804e-04
Loss = 9.7129e-04, PNorm = 54.8832, GNorm = 2.3879, lr_0 = 1.0804e-04
Loss = 8.9839e-04, PNorm = 54.8884, GNorm = 0.9371, lr_0 = 1.0804e-04
Loss = 7.6803e-04, PNorm = 54.8936, GNorm = 1.3822, lr_0 = 1.0804e-04
Loss = 8.3259e-04, PNorm = 54.8979, GNorm = 2.3155, lr_0 = 1.0804e-04
Validation rmse logD = 0.587676
Validation R2 logD = 0.765866
Epoch 51
Train function
Loss = 9.4446e-04, PNorm = 54.9016, GNorm = 5.0134, lr_0 = 1.0804e-04
Loss = 7.9724e-04, PNorm = 54.9058, GNorm = 4.2649, lr_0 = 1.0804e-04
Loss = 8.8856e-04, PNorm = 54.9099, GNorm = 4.3902, lr_0 = 1.0804e-04
Loss = 1.2550e-03, PNorm = 54.9145, GNorm = 1.0655, lr_0 = 1.0804e-04
Loss = 1.0542e-03, PNorm = 54.9195, GNorm = 4.0389, lr_0 = 1.0804e-04
Loss = 1.1347e-03, PNorm = 54.9249, GNorm = 6.9704, lr_0 = 1.0804e-04
Validation rmse logD = 0.607782
Validation R2 logD = 0.749571
Epoch 52
Train function
Loss = 7.7798e-04, PNorm = 54.9300, GNorm = 3.2347, lr_0 = 1.0804e-04
Loss = 8.6399e-04, PNorm = 54.9341, GNorm = 1.6920, lr_0 = 1.0804e-04
Loss = 8.7152e-04, PNorm = 54.9394, GNorm = 5.3389, lr_0 = 1.0804e-04
Loss = 1.0233e-03, PNorm = 54.9447, GNorm = 4.4762, lr_0 = 1.0804e-04
Loss = 9.7217e-04, PNorm = 54.9503, GNorm = 1.1195, lr_0 = 1.0804e-04
Loss = 8.2569e-04, PNorm = 54.9555, GNorm = 4.9048, lr_0 = 1.0804e-04
Validation rmse logD = 0.583122
Validation R2 logD = 0.769480
Epoch 53
Train function
Loss = 6.7648e-04, PNorm = 54.9604, GNorm = 1.4100, lr_0 = 1.0804e-04
Loss = 6.0123e-04, PNorm = 54.9637, GNorm = 1.0365, lr_0 = 1.0804e-04
Loss = 6.5824e-04, PNorm = 54.9665, GNorm = 1.3118, lr_0 = 1.0804e-04
Loss = 6.6587e-04, PNorm = 54.9712, GNorm = 1.3414, lr_0 = 1.0804e-04
Loss = 7.3519e-04, PNorm = 54.9765, GNorm = 1.8037, lr_0 = 1.0804e-04
Validation rmse logD = 0.590986
Validation R2 logD = 0.763221
Epoch 54
Train function
Loss = 7.6315e-04, PNorm = 54.9802, GNorm = 2.8424, lr_0 = 1.0804e-04
Loss = 5.9998e-04, PNorm = 54.9843, GNorm = 2.9163, lr_0 = 1.0804e-04
Loss = 7.1048e-04, PNorm = 54.9886, GNorm = 3.0500, lr_0 = 1.0804e-04
Loss = 6.2841e-04, PNorm = 54.9915, GNorm = 1.0937, lr_0 = 1.0804e-04
Loss = 7.1915e-04, PNorm = 54.9953, GNorm = 1.0709, lr_0 = 1.0804e-04
Loss = 5.9987e-04, PNorm = 54.9995, GNorm = 1.3404, lr_0 = 1.0804e-04
Validation rmse logD = 0.589276
Validation R2 logD = 0.764589
Epoch 55
Train function
Loss = 6.9339e-04, PNorm = 55.0023, GNorm = 1.2853, lr_0 = 1.0804e-04
Loss = 8.1012e-04, PNorm = 55.0064, GNorm = 3.6395, lr_0 = 1.0804e-04
Loss = 7.2512e-04, PNorm = 55.0106, GNorm = 2.2407, lr_0 = 1.0804e-04
Loss = 7.2189e-04, PNorm = 55.0138, GNorm = 1.5487, lr_0 = 1.0804e-04
Loss = 8.6310e-04, PNorm = 55.0188, GNorm = 2.4227, lr_0 = 1.0804e-04
Loss = 6.8760e-04, PNorm = 55.0238, GNorm = 2.0993, lr_0 = 1.0804e-04
Validation rmse logD = 0.567974
Validation R2 logD = 0.781301
Epoch 56
Train function
Loss = 5.5467e-04, PNorm = 55.0286, GNorm = 1.7303, lr_0 = 1.0804e-04
Loss = 5.3796e-04, PNorm = 55.0304, GNorm = 2.3590, lr_0 = 1.0804e-04
Loss = 9.0764e-04, PNorm = 55.0353, GNorm = 2.4728, lr_0 = 1.0804e-04
Loss = 7.2176e-04, PNorm = 55.0404, GNorm = 3.0313, lr_0 = 1.0804e-04
Loss = 1.0035e-03, PNorm = 55.0435, GNorm = 7.1474, lr_0 = 1.0804e-04
Validation rmse logD = 0.598970
Validation R2 logD = 0.756780
Epoch 57
Train function
Loss = 6.8496e-04, PNorm = 55.0476, GNorm = 2.5876, lr_0 = 1.0804e-04
Loss = 6.2822e-04, PNorm = 55.0527, GNorm = 2.0049, lr_0 = 1.0804e-04
Loss = 6.2010e-04, PNorm = 55.0569, GNorm = 1.1972, lr_0 = 1.0804e-04
Loss = 7.2933e-04, PNorm = 55.0601, GNorm = 2.5046, lr_0 = 1.0804e-04
Loss = 6.6450e-04, PNorm = 55.0645, GNorm = 1.6611, lr_0 = 1.0804e-04
Loss = 4.6312e-04, PNorm = 55.0692, GNorm = 1.2209, lr_0 = 1.0804e-04
Validation rmse logD = 0.577471
Validation R2 logD = 0.773927
Epoch 58
Train function
Loss = 5.1068e-04, PNorm = 55.0726, GNorm = 3.2083, lr_0 = 1.0804e-04
Loss = 7.4222e-04, PNorm = 55.0753, GNorm = 5.7752, lr_0 = 1.0804e-04
Loss = 8.5550e-04, PNorm = 55.0793, GNorm = 0.9941, lr_0 = 1.0804e-04
Loss = 6.1154e-04, PNorm = 55.0838, GNorm = 2.6533, lr_0 = 1.0804e-04
Loss = 7.1152e-04, PNorm = 55.0881, GNorm = 1.4064, lr_0 = 1.0804e-04
Loss = 5.3805e-04, PNorm = 55.0921, GNorm = 2.3018, lr_0 = 1.0804e-04
Validation rmse logD = 0.576278
Validation R2 logD = 0.774860
Epoch 59
Train function
Loss = 5.1571e-04, PNorm = 55.0959, GNorm = 3.8146, lr_0 = 1.0804e-04
Loss = 7.3614e-04, PNorm = 55.1002, GNorm = 2.5857, lr_0 = 1.0804e-04
Loss = 8.1514e-04, PNorm = 55.1045, GNorm = 3.4613, lr_0 = 1.0804e-04
Loss = 5.7352e-04, PNorm = 55.1090, GNorm = 1.1405, lr_0 = 1.0804e-04
Loss = 6.2384e-04, PNorm = 55.1131, GNorm = 0.8786, lr_0 = 1.0804e-04
Validation rmse logD = 0.587691
Validation R2 logD = 0.765854
Epoch 60
Train function
Loss = 6.7648e-04, PNorm = 55.1166, GNorm = 0.9532, lr_0 = 1.0804e-04
Loss = 4.9381e-04, PNorm = 55.1202, GNorm = 2.0690, lr_0 = 1.0804e-04
Loss = 5.9464e-04, PNorm = 55.1229, GNorm = 0.9672, lr_0 = 1.0804e-04
Loss = 7.2138e-04, PNorm = 55.1264, GNorm = 6.5356, lr_0 = 1.0804e-04
Loss = 5.9298e-04, PNorm = 55.1299, GNorm = 5.0321, lr_0 = 1.0804e-04
Loss = 7.2528e-04, PNorm = 55.1330, GNorm = 2.0443, lr_0 = 1.0804e-04
Validation rmse logD = 0.576241
Validation R2 logD = 0.774888
Epoch 61
Train function
Loss = 6.6433e-04, PNorm = 55.1368, GNorm = 4.0024, lr_0 = 1.0804e-04
Loss = 6.6373e-04, PNorm = 55.1421, GNorm = 3.3031, lr_0 = 1.0804e-04
Loss = 7.0883e-04, PNorm = 55.1455, GNorm = 2.0666, lr_0 = 1.0804e-04
Loss = 6.2164e-04, PNorm = 55.1500, GNorm = 2.3706, lr_0 = 1.0804e-04
Loss = 6.8819e-04, PNorm = 55.1547, GNorm = 1.8705, lr_0 = 1.0804e-04
Loss = 5.5243e-04, PNorm = 55.1580, GNorm = 2.7804, lr_0 = 1.0804e-04
Validation rmse logD = 0.579925
Validation R2 logD = 0.772001
Epoch 62
Train function
Loss = 4.5614e-04, PNorm = 55.1627, GNorm = 2.2148, lr_0 = 1.0804e-04
Loss = 4.6222e-04, PNorm = 55.1657, GNorm = 3.3358, lr_0 = 1.0804e-04
Loss = 4.6629e-04, PNorm = 55.1696, GNorm = 1.7730, lr_0 = 1.0804e-04
Loss = 6.2185e-04, PNorm = 55.1714, GNorm = 1.9553, lr_0 = 1.0804e-04
Loss = 5.1616e-04, PNorm = 55.1747, GNorm = 1.8416, lr_0 = 1.0804e-04
Validation rmse logD = 0.588283
Validation R2 logD = 0.765382
Epoch 63
Train function
Loss = 3.8706e-04, PNorm = 55.1786, GNorm = 1.3771, lr_0 = 1.0804e-04
Loss = 3.7391e-04, PNorm = 55.1812, GNorm = 1.1608, lr_0 = 1.0804e-04
Loss = 5.8131e-04, PNorm = 55.1824, GNorm = 4.4560, lr_0 = 1.0804e-04
Loss = 5.7585e-04, PNorm = 55.1860, GNorm = 1.5646, lr_0 = 1.0804e-04
Loss = 7.3549e-04, PNorm = 55.1903, GNorm = 2.3194, lr_0 = 1.0804e-04
Loss = 6.0478e-04, PNorm = 55.1940, GNorm = 2.1925, lr_0 = 1.0804e-04
Validation rmse logD = 0.589954
Validation R2 logD = 0.764047
Epoch 64
Train function
Loss = 7.3536e-04, PNorm = 55.1980, GNorm = 1.9793, lr_0 = 1.0804e-04
Loss = 3.8219e-04, PNorm = 55.2031, GNorm = 1.2718, lr_0 = 1.0804e-04
Loss = 4.4610e-04, PNorm = 55.2054, GNorm = 1.0604, lr_0 = 1.0804e-04
Loss = 4.8171e-04, PNorm = 55.2086, GNorm = 3.8616, lr_0 = 1.0804e-04
Loss = 6.6729e-04, PNorm = 55.2106, GNorm = 4.7607, lr_0 = 1.0804e-04
Loss = 7.7006e-04, PNorm = 55.2147, GNorm = 3.7467, lr_0 = 1.0804e-04
Validation rmse logD = 0.573519
Validation R2 logD = 0.777010
Epoch 65
Train function
Loss = 5.3983e-04, PNorm = 55.2189, GNorm = 1.3702, lr_0 = 1.0804e-04
Loss = 6.7031e-04, PNorm = 55.2229, GNorm = 2.2605, lr_0 = 1.0804e-04
Loss = 5.8849e-04, PNorm = 55.2260, GNorm = 3.4923, lr_0 = 1.0804e-04
Loss = 8.4165e-04, PNorm = 55.2293, GNorm = 5.6963, lr_0 = 1.0804e-04
Loss = 7.1157e-04, PNorm = 55.2340, GNorm = 1.3786, lr_0 = 1.0804e-04
Validation rmse logD = 0.585490
Validation R2 logD = 0.767604
Epoch 66
Train function
Loss = 5.1328e-04, PNorm = 55.2394, GNorm = 3.2443, lr_0 = 1.0804e-04
Loss = 5.4074e-04, PNorm = 55.2440, GNorm = 2.6678, lr_0 = 1.0804e-04
Loss = 5.4649e-04, PNorm = 55.2479, GNorm = 2.5451, lr_0 = 1.0804e-04
Loss = 4.5791e-04, PNorm = 55.2520, GNorm = 0.9222, lr_0 = 1.0804e-04
Loss = 6.4637e-04, PNorm = 55.2555, GNorm = 1.1984, lr_0 = 1.0804e-04
Loss = 5.1168e-04, PNorm = 55.2588, GNorm = 0.7993, lr_0 = 1.0804e-04
Validation rmse logD = 0.610286
Validation R2 logD = 0.747503
Epoch 67
Train function
Loss = 4.7396e-04, PNorm = 55.2624, GNorm = 2.4084, lr_0 = 1.0804e-04
Loss = 5.7413e-04, PNorm = 55.2653, GNorm = 1.4620, lr_0 = 1.0804e-04
Loss = 5.4760e-04, PNorm = 55.2695, GNorm = 0.5329, lr_0 = 1.0804e-04
Loss = 5.7527e-04, PNorm = 55.2740, GNorm = 1.3366, lr_0 = 1.0804e-04
Loss = 4.0901e-04, PNorm = 55.2777, GNorm = 2.2212, lr_0 = 1.0804e-04
Loss = 7.0084e-04, PNorm = 55.2801, GNorm = 3.9413, lr_0 = 1.0804e-04
Validation rmse logD = 0.574159
Validation R2 logD = 0.776512
Epoch 68
Train function
Loss = 6.8796e-04, PNorm = 55.2845, GNorm = 0.7058, lr_0 = 1.0804e-04
Loss = 4.3109e-04, PNorm = 55.2879, GNorm = 0.9777, lr_0 = 1.0804e-04
Loss = 4.3311e-04, PNorm = 55.2905, GNorm = 1.0332, lr_0 = 1.0804e-04
Loss = 3.7654e-04, PNorm = 55.2946, GNorm = 0.8443, lr_0 = 1.0804e-04
Loss = 5.2160e-04, PNorm = 55.2976, GNorm = 1.4226, lr_0 = 1.0804e-04
Validation rmse logD = 0.579156
Validation R2 logD = 0.772606
Epoch 69
Train function
Loss = 4.4409e-04, PNorm = 55.2999, GNorm = 1.1712, lr_0 = 1.0804e-04
Loss = 4.0085e-04, PNorm = 55.3030, GNorm = 2.2077, lr_0 = 1.0804e-04
Loss = 5.1405e-04, PNorm = 55.3066, GNorm = 1.8034, lr_0 = 1.0804e-04
Loss = 4.6821e-04, PNorm = 55.3122, GNorm = 2.4589, lr_0 = 1.0804e-04
Loss = 4.3052e-04, PNorm = 55.3153, GNorm = 0.7214, lr_0 = 1.0804e-04
Loss = 6.9282e-04, PNorm = 55.3167, GNorm = 6.7122, lr_0 = 1.0804e-04
Validation rmse logD = 0.572683
Validation R2 logD = 0.777660
Epoch 70
Train function
Loss = 6.5295e-04, PNorm = 55.3198, GNorm = 6.4106, lr_0 = 1.0804e-04
Loss = 7.2749e-04, PNorm = 55.3243, GNorm = 4.6631, lr_0 = 1.0804e-04
Loss = 6.3883e-04, PNorm = 55.3276, GNorm = 2.3121, lr_0 = 1.0804e-04
Loss = 8.0347e-04, PNorm = 55.3332, GNorm = 1.1646, lr_0 = 1.0804e-04
Loss = 4.2707e-04, PNorm = 55.3377, GNorm = 1.9350, lr_0 = 1.0804e-04
Loss = 5.4200e-04, PNorm = 55.3408, GNorm = 2.9874, lr_0 = 1.0804e-04
Validation rmse logD = 0.580795
Validation R2 logD = 0.771317
Epoch 71
Train function
Loss = 3.9132e-04, PNorm = 55.3438, GNorm = 1.7980, lr_0 = 1.0804e-04
Loss = 4.0299e-04, PNorm = 55.3475, GNorm = 1.2995, lr_0 = 1.0804e-04
Loss = 3.3008e-04, PNorm = 55.3509, GNorm = 1.3696, lr_0 = 1.0804e-04
Loss = 5.1979e-04, PNorm = 55.3545, GNorm = 1.4306, lr_0 = 1.0804e-04
Loss = 4.3165e-04, PNorm = 55.3583, GNorm = 2.4387, lr_0 = 1.0804e-04
Validation rmse logD = 0.579897
Validation R2 logD = 0.772023
Epoch 72
Train function
Loss = 2.9873e-04, PNorm = 55.3630, GNorm = 1.2398, lr_0 = 1.0804e-04
Loss = 3.6624e-04, PNorm = 55.3647, GNorm = 1.8255, lr_0 = 1.0804e-04
Loss = 5.0981e-04, PNorm = 55.3680, GNorm = 2.4267, lr_0 = 1.0804e-04
Loss = 3.5587e-04, PNorm = 55.3701, GNorm = 0.7484, lr_0 = 1.0804e-04
Loss = 3.3138e-04, PNorm = 55.3724, GNorm = 1.2495, lr_0 = 1.0804e-04
Loss = 5.4626e-04, PNorm = 55.3751, GNorm = 3.9160, lr_0 = 1.0804e-04
Validation rmse logD = 0.572739
Validation R2 logD = 0.777616
Epoch 73
Train function
Loss = 4.5260e-04, PNorm = 55.3783, GNorm = 2.2887, lr_0 = 1.0804e-04
Loss = 4.6452e-04, PNorm = 55.3806, GNorm = 2.3728, lr_0 = 1.0804e-04
Loss = 8.4680e-04, PNorm = 55.3848, GNorm = 1.1455, lr_0 = 1.0804e-04
Loss = 8.3145e-04, PNorm = 55.3891, GNorm = 2.1224, lr_0 = 1.0804e-04
Loss = 6.0544e-04, PNorm = 55.3936, GNorm = 2.1877, lr_0 = 1.0804e-04
Loss = 5.3571e-04, PNorm = 55.3980, GNorm = 2.8023, lr_0 = 1.0804e-04
Validation rmse logD = 0.583600
Validation R2 logD = 0.769103
Epoch 74
Train function
Loss = 3.5187e-04, PNorm = 55.4023, GNorm = 0.7355, lr_0 = 1.0804e-04
Loss = 4.0420e-04, PNorm = 55.4028, GNorm = 2.1031, lr_0 = 1.0804e-04
Loss = 4.4291e-04, PNorm = 55.4057, GNorm = 1.6843, lr_0 = 1.0804e-04
Loss = 6.0260e-04, PNorm = 55.4092, GNorm = 2.4472, lr_0 = 1.0804e-04
Loss = 6.1661e-04, PNorm = 55.4118, GNorm = 1.8215, lr_0 = 1.0804e-04
Validation rmse logD = 0.577038
Validation R2 logD = 0.774265
Epoch 75
Train function
Loss = 7.0070e-04, PNorm = 55.4151, GNorm = 4.3628, lr_0 = 1.0804e-04
Loss = 4.5553e-04, PNorm = 55.4198, GNorm = 1.6217, lr_0 = 1.0804e-04
Loss = 6.6177e-04, PNorm = 55.4224, GNorm = 2.6500, lr_0 = 1.0804e-04
Loss = 7.3186e-04, PNorm = 55.4255, GNorm = 4.2827, lr_0 = 1.0804e-04
Loss = 5.1389e-04, PNorm = 55.4302, GNorm = 5.6101, lr_0 = 1.0804e-04
Loss = 4.8578e-04, PNorm = 55.4350, GNorm = 1.2831, lr_0 = 1.0804e-04
Validation rmse logD = 0.576714
Validation R2 logD = 0.774519
Epoch 76
Train function
Loss = 2.1773e-04, PNorm = 55.4383, GNorm = 1.2341, lr_0 = 1.0804e-04
Loss = 2.7908e-04, PNorm = 55.4405, GNorm = 0.6783, lr_0 = 1.0804e-04
Loss = 3.1348e-04, PNorm = 55.4426, GNorm = 3.1445, lr_0 = 1.0804e-04
Loss = 3.9069e-04, PNorm = 55.4452, GNorm = 1.9587, lr_0 = 1.0804e-04
Loss = 4.6293e-04, PNorm = 55.4478, GNorm = 3.1775, lr_0 = 1.0804e-04
Loss = 4.2280e-04, PNorm = 55.4510, GNorm = 0.9055, lr_0 = 1.0804e-04
Validation rmse logD = 0.579355
Validation R2 logD = 0.772449
Epoch 77
Train function
Loss = 2.6292e-04, PNorm = 55.4545, GNorm = 1.2256, lr_0 = 1.0804e-04
Loss = 2.6069e-04, PNorm = 55.4564, GNorm = 2.2722, lr_0 = 1.0804e-04
Loss = 3.5772e-04, PNorm = 55.4595, GNorm = 2.5087, lr_0 = 1.0804e-04
Loss = 4.0452e-04, PNorm = 55.4633, GNorm = 0.5678, lr_0 = 1.0804e-04
Loss = 2.9158e-04, PNorm = 55.4667, GNorm = 1.8583, lr_0 = 1.0804e-04
Validation rmse logD = 0.587688
Validation R2 logD = 0.765857
Epoch 78
Train function
Loss = 3.3873e-04, PNorm = 55.4692, GNorm = 2.7462, lr_0 = 1.0804e-04
Loss = 2.8290e-04, PNorm = 55.4707, GNorm = 0.9773, lr_0 = 1.0804e-04
Loss = 2.6903e-04, PNorm = 55.4735, GNorm = 2.4024, lr_0 = 1.0804e-04
Loss = 2.7763e-04, PNorm = 55.4757, GNorm = 1.3835, lr_0 = 1.0804e-04
Loss = 3.6485e-04, PNorm = 55.4786, GNorm = 2.4544, lr_0 = 1.0804e-04
Loss = 3.7037e-04, PNorm = 55.4810, GNorm = 2.2774, lr_0 = 1.0804e-04
Validation rmse logD = 0.575821
Validation R2 logD = 0.775216
Epoch 79
Train function
Loss = 3.8543e-04, PNorm = 55.4847, GNorm = 1.8894, lr_0 = 1.0804e-04
Loss = 3.8710e-04, PNorm = 55.4868, GNorm = 3.0769, lr_0 = 1.0804e-04
Loss = 4.2275e-04, PNorm = 55.4901, GNorm = 1.0252, lr_0 = 1.0804e-04
Loss = 3.9584e-04, PNorm = 55.4930, GNorm = 2.5188, lr_0 = 1.0804e-04
Loss = 5.1864e-04, PNorm = 55.4958, GNorm = 4.5051, lr_0 = 1.0804e-04
Loss = 6.0139e-04, PNorm = 55.4990, GNorm = 1.4103, lr_0 = 1.0804e-04
Validation rmse logD = 0.576946
Validation R2 logD = 0.774338
Epoch 80
Train function
Loss = 5.1477e-04, PNorm = 55.5032, GNorm = 5.1725, lr_0 = 1.0804e-04
Loss = 3.8924e-04, PNorm = 55.5082, GNorm = 0.5327, lr_0 = 1.0804e-04
Loss = 3.2107e-04, PNorm = 55.5115, GNorm = 1.7404, lr_0 = 1.0804e-04
Loss = 2.9836e-04, PNorm = 55.5144, GNorm = 1.6146, lr_0 = 1.0804e-04
Loss = 3.1622e-04, PNorm = 55.5171, GNorm = 2.6783, lr_0 = 1.0804e-04
Validation rmse logD = 0.577524
Validation R2 logD = 0.773885
Epoch 81
Train function
Loss = 2.2753e-04, PNorm = 55.5201, GNorm = 1.5535, lr_0 = 1.0804e-04
Loss = 3.8003e-04, PNorm = 55.5219, GNorm = 2.9190, lr_0 = 1.0804e-04
Loss = 3.6219e-04, PNorm = 55.5248, GNorm = 1.6187, lr_0 = 1.0804e-04
Loss = 5.1523e-04, PNorm = 55.5263, GNorm = 4.1642, lr_0 = 1.0804e-04
Loss = 4.4149e-04, PNorm = 55.5303, GNorm = 1.7518, lr_0 = 1.0804e-04
Loss = 4.7022e-04, PNorm = 55.5349, GNorm = 2.6199, lr_0 = 1.0804e-04
Validation rmse logD = 0.578507
Validation R2 logD = 0.773115
Epoch 82
Train function
Loss = 3.5082e-04, PNorm = 55.5389, GNorm = 0.9487, lr_0 = 1.0804e-04
Loss = 3.3968e-04, PNorm = 55.5434, GNorm = 1.1391, lr_0 = 1.0804e-04
Loss = 3.5168e-04, PNorm = 55.5462, GNorm = 2.6565, lr_0 = 1.0804e-04
Loss = 3.4017e-04, PNorm = 55.5491, GNorm = 1.2041, lr_0 = 1.0804e-04
Loss = 2.7600e-04, PNorm = 55.5521, GNorm = 0.7627, lr_0 = 1.0804e-04
Loss = 3.0071e-04, PNorm = 55.5549, GNorm = 1.2438, lr_0 = 1.0804e-04
Validation rmse logD = 0.578303
Validation R2 logD = 0.773275
Epoch 83
Train function
Loss = 3.0808e-04, PNorm = 55.5589, GNorm = 1.0014, lr_0 = 1.0804e-04
Loss = 2.0783e-04, PNorm = 55.5617, GNorm = 2.3855, lr_0 = 1.0804e-04
Loss = 2.7894e-04, PNorm = 55.5635, GNorm = 1.7365, lr_0 = 1.0804e-04
Loss = 3.1535e-04, PNorm = 55.5655, GNorm = 1.0590, lr_0 = 1.0804e-04
Loss = 2.6159e-04, PNorm = 55.5671, GNorm = 0.9089, lr_0 = 1.0804e-04
Validation rmse logD = 0.571159
Validation R2 logD = 0.778842
Epoch 84
Train function
Loss = 1.8681e-04, PNorm = 55.5684, GNorm = 0.7004, lr_0 = 1.0804e-04
Loss = 3.0992e-04, PNorm = 55.5700, GNorm = 1.5279, lr_0 = 1.0804e-04
Loss = 2.5253e-04, PNorm = 55.5720, GNorm = 1.6432, lr_0 = 1.0804e-04
Loss = 4.0074e-04, PNorm = 55.5755, GNorm = 2.4546, lr_0 = 1.0804e-04
Loss = 3.1010e-04, PNorm = 55.5782, GNorm = 2.0407, lr_0 = 1.0804e-04
Loss = 2.5010e-04, PNorm = 55.5818, GNorm = 0.8211, lr_0 = 1.0804e-04
Validation rmse logD = 0.570276
Validation R2 logD = 0.779525
Epoch 85
Train function
Loss = 2.6066e-04, PNorm = 55.5836, GNorm = 1.7442, lr_0 = 1.0804e-04
Loss = 2.7604e-04, PNorm = 55.5854, GNorm = 0.7616, lr_0 = 1.0804e-04
Loss = 3.2902e-04, PNorm = 55.5881, GNorm = 1.2352, lr_0 = 1.0804e-04
Loss = 2.6738e-04, PNorm = 55.5905, GNorm = 0.8896, lr_0 = 1.0804e-04
Loss = 4.2360e-04, PNorm = 55.5930, GNorm = 4.9109, lr_0 = 1.0804e-04
Loss = 7.1874e-04, PNorm = 55.5965, GNorm = 3.5978, lr_0 = 1.0804e-04
Validation rmse logD = 0.575746
Validation R2 logD = 0.775276
Epoch 86
Train function
Loss = 7.7925e-04, PNorm = 55.6022, GNorm = 3.4642, lr_0 = 1.0804e-04
Loss = 5.4828e-04, PNorm = 55.6063, GNorm = 2.8973, lr_0 = 1.0804e-04
Loss = 7.1534e-04, PNorm = 55.6107, GNorm = 3.3477, lr_0 = 1.0804e-04
Loss = 6.0017e-04, PNorm = 55.6149, GNorm = 2.9279, lr_0 = 1.0804e-04
Loss = 4.1103e-04, PNorm = 55.6197, GNorm = 1.3485, lr_0 = 1.0804e-04
Validation rmse logD = 0.581561
Validation R2 logD = 0.770713
Epoch 87
Train function
Loss = 4.6894e-04, PNorm = 55.6244, GNorm = 3.4063, lr_0 = 1.0804e-04
Loss = 4.3001e-04, PNorm = 55.6271, GNorm = 3.9579, lr_0 = 1.0804e-04
Loss = 4.5119e-04, PNorm = 55.6293, GNorm = 3.1508, lr_0 = 1.0804e-04
Loss = 3.8018e-04, PNorm = 55.6331, GNorm = 2.5353, lr_0 = 1.0804e-04
Loss = 3.3976e-04, PNorm = 55.6376, GNorm = 0.8299, lr_0 = 1.0804e-04
Loss = 3.1377e-04, PNorm = 55.6411, GNorm = 0.6196, lr_0 = 1.0804e-04
Validation rmse logD = 0.592970
Validation R2 logD = 0.761628
Epoch 88
Train function
Loss = 4.6456e-04, PNorm = 55.6440, GNorm = 3.4336, lr_0 = 1.0804e-04
Loss = 4.1845e-04, PNorm = 55.6466, GNorm = 1.3435, lr_0 = 1.0804e-04
Loss = 4.3547e-04, PNorm = 55.6500, GNorm = 3.7012, lr_0 = 1.0804e-04
Loss = 3.8434e-04, PNorm = 55.6524, GNorm = 0.9024, lr_0 = 1.0804e-04
Loss = 3.1683e-04, PNorm = 55.6550, GNorm = 0.6858, lr_0 = 1.0804e-04
Loss = 3.5367e-04, PNorm = 55.6577, GNorm = 2.3401, lr_0 = 1.0804e-04
Validation rmse logD = 0.576822
Validation R2 logD = 0.774434
Epoch 89
Train function
Loss = 2.9497e-04, PNorm = 55.6620, GNorm = 1.1939, lr_0 = 1.0804e-04
Loss = 2.4346e-04, PNorm = 55.6641, GNorm = 2.1597, lr_0 = 1.0804e-04
Loss = 2.9619e-04, PNorm = 55.6665, GNorm = 1.1755, lr_0 = 1.0804e-04
Loss = 3.1533e-04, PNorm = 55.6708, GNorm = 0.9477, lr_0 = 1.0804e-04
Loss = 4.0063e-04, PNorm = 55.6735, GNorm = 2.1636, lr_0 = 1.0804e-04
Validation rmse logD = 0.586781
Validation R2 logD = 0.766578
Epoch 90
Train function
Loss = 3.6201e-04, PNorm = 55.6770, GNorm = 1.6231, lr_0 = 1.0804e-04
Loss = 3.4848e-04, PNorm = 55.6802, GNorm = 3.0375, lr_0 = 1.0804e-04
Loss = 4.9017e-04, PNorm = 55.6814, GNorm = 3.0169, lr_0 = 1.0804e-04
Loss = 3.2658e-04, PNorm = 55.6845, GNorm = 1.1129, lr_0 = 1.0804e-04
Loss = 2.6448e-04, PNorm = 55.6878, GNorm = 0.4994, lr_0 = 1.0804e-04
Loss = 3.0305e-04, PNorm = 55.6912, GNorm = 0.6269, lr_0 = 1.0804e-04
Validation rmse logD = 0.579836
Validation R2 logD = 0.772071
Epoch 91
Train function
Loss = 5.1251e-04, PNorm = 55.6932, GNorm = 4.8303, lr_0 = 1.0804e-04
Loss = 3.9529e-04, PNorm = 55.6961, GNorm = 1.1809, lr_0 = 1.0804e-04
Loss = 5.3421e-04, PNorm = 55.6990, GNorm = 4.5456, lr_0 = 1.0804e-04
Loss = 4.1169e-04, PNorm = 55.7029, GNorm = 3.0242, lr_0 = 1.0804e-04
Loss = 2.7884e-04, PNorm = 55.7065, GNorm = 0.7779, lr_0 = 1.0804e-04
Loss = 3.3468e-04, PNorm = 55.7100, GNorm = 2.3114, lr_0 = 1.0804e-04
Validation rmse logD = 0.576645
Validation R2 logD = 0.774573
Epoch 92
Train function
Loss = 2.0596e-04, PNorm = 55.7133, GNorm = 2.8251, lr_0 = 1.0804e-04
Loss = 2.4076e-04, PNorm = 55.7153, GNorm = 0.9867, lr_0 = 1.0804e-04
Loss = 3.0389e-04, PNorm = 55.7170, GNorm = 3.0845, lr_0 = 1.0804e-04
Loss = 3.3933e-04, PNorm = 55.7183, GNorm = 0.8922, lr_0 = 1.0804e-04
Loss = 3.6135e-04, PNorm = 55.7209, GNorm = 0.9370, lr_0 = 1.0804e-04
Validation rmse logD = 0.577055
Validation R2 logD = 0.774252
Epoch 93
Train function
Loss = 3.9122e-04, PNorm = 55.7247, GNorm = 3.4411, lr_0 = 1.0804e-04
Loss = 2.8215e-04, PNorm = 55.7273, GNorm = 0.6794, lr_0 = 1.0804e-04
Loss = 2.9936e-04, PNorm = 55.7297, GNorm = 2.4968, lr_0 = 1.0804e-04
Loss = 3.1965e-04, PNorm = 55.7323, GNorm = 2.4598, lr_0 = 1.0804e-04
Loss = 3.2392e-04, PNorm = 55.7357, GNorm = 3.4135, lr_0 = 1.0804e-04
Loss = 3.1387e-04, PNorm = 55.7392, GNorm = 2.4410, lr_0 = 1.0804e-04
Validation rmse logD = 0.596825
Validation R2 logD = 0.758519
Epoch 94
Train function
Loss = 2.8122e-04, PNorm = 55.7403, GNorm = 2.2428, lr_0 = 1.0804e-04
Loss = 2.1829e-04, PNorm = 55.7433, GNorm = 1.1802, lr_0 = 1.0804e-04
Loss = 3.0943e-04, PNorm = 55.7465, GNorm = 1.9611, lr_0 = 1.0804e-04
Loss = 3.1298e-04, PNorm = 55.7496, GNorm = 1.7547, lr_0 = 1.0804e-04
Loss = 3.1787e-04, PNorm = 55.7523, GNorm = 3.0650, lr_0 = 1.0804e-04
Loss = 2.4726e-04, PNorm = 55.7548, GNorm = 0.6583, lr_0 = 1.0804e-04
Validation rmse logD = 0.586142
Validation R2 logD = 0.767086
Epoch 95
Train function
Loss = 1.9116e-04, PNorm = 55.7560, GNorm = 1.7346, lr_0 = 1.0804e-04
Loss = 3.0846e-04, PNorm = 55.7585, GNorm = 0.3670, lr_0 = 1.0804e-04
Loss = 2.5345e-04, PNorm = 55.7606, GNorm = 1.2406, lr_0 = 1.0804e-04
Loss = 2.4400e-04, PNorm = 55.7623, GNorm = 2.5142, lr_0 = 1.0804e-04
Loss = 3.1003e-04, PNorm = 55.7645, GNorm = 0.6152, lr_0 = 1.0804e-04
Validation rmse logD = 0.581061
Validation R2 logD = 0.771107
Epoch 96
Train function
Loss = 2.1775e-04, PNorm = 55.7664, GNorm = 0.8113, lr_0 = 1.0804e-04
Loss = 2.3167e-04, PNorm = 55.7698, GNorm = 2.2613, lr_0 = 1.0804e-04
Loss = 2.2854e-04, PNorm = 55.7732, GNorm = 1.0431, lr_0 = 1.0804e-04
Loss = 2.0879e-04, PNorm = 55.7754, GNorm = 1.8605, lr_0 = 1.0804e-04
Loss = 3.4345e-04, PNorm = 55.7765, GNorm = 1.9230, lr_0 = 1.0804e-04
Loss = 3.1768e-04, PNorm = 55.7789, GNorm = 1.5532, lr_0 = 1.0804e-04
Validation rmse logD = 0.576089
Validation R2 logD = 0.775007
Epoch 97
Train function
Loss = 1.5994e-04, PNorm = 55.7826, GNorm = 0.7280, lr_0 = 1.0804e-04
Loss = 2.1166e-04, PNorm = 55.7847, GNorm = 1.1692, lr_0 = 1.0804e-04
Loss = 1.9754e-04, PNorm = 55.7860, GNorm = 1.3798, lr_0 = 1.0804e-04
Loss = 3.4872e-04, PNorm = 55.7889, GNorm = 1.4422, lr_0 = 1.0804e-04
Loss = 2.8244e-04, PNorm = 55.7920, GNorm = 1.6652, lr_0 = 1.0804e-04
Loss = 2.4577e-04, PNorm = 55.7943, GNorm = 3.1055, lr_0 = 1.0804e-04
Validation rmse logD = 0.577440
Validation R2 logD = 0.773951
Epoch 98
Train function
Loss = 3.2050e-04, PNorm = 55.7977, GNorm = 2.0137, lr_0 = 1.0804e-04
Loss = 3.6370e-04, PNorm = 55.8001, GNorm = 4.1022, lr_0 = 1.0804e-04
Loss = 4.0583e-04, PNorm = 55.8026, GNorm = 2.4125, lr_0 = 1.0804e-04
Loss = 4.5010e-04, PNorm = 55.8069, GNorm = 0.5482, lr_0 = 1.0804e-04
Loss = 3.6063e-04, PNorm = 55.8111, GNorm = 2.0239, lr_0 = 1.0804e-04
Validation rmse logD = 0.574142
Validation R2 logD = 0.776525
Epoch 99
Train function
Loss = 2.6189e-04, PNorm = 55.8154, GNorm = 1.1590, lr_0 = 1.0804e-04
Loss = 1.7826e-04, PNorm = 55.8177, GNorm = 1.3751, lr_0 = 1.0804e-04
Loss = 2.1034e-04, PNorm = 55.8190, GNorm = 0.7735, lr_0 = 1.0804e-04
Loss = 1.9336e-04, PNorm = 55.8214, GNorm = 0.7452, lr_0 = 1.0804e-04
Loss = 2.7631e-04, PNorm = 55.8228, GNorm = 0.9552, lr_0 = 1.0804e-04
Loss = 2.8652e-04, PNorm = 55.8267, GNorm = 2.5849, lr_0 = 1.0804e-04
Validation rmse logD = 0.573395
Validation R2 logD = 0.777107
Model 0 best validation rmse = 0.567974 on epoch 55
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.529502
Model 0 test R2 logD = 0.780097
Ensemble test rmse  logD= 0.529502
Ensemble test R2  logD= 0.780097
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.1757e-02, PNorm = 52.9125, GNorm = 2.3064, lr_0 = 1.0804e-04
Loss = 2.0725e-02, PNorm = 52.9147, GNorm = 7.5026, lr_0 = 1.0804e-04
Loss = 1.5281e-02, PNorm = 52.9174, GNorm = 9.0374, lr_0 = 1.0804e-04
Loss = 1.4707e-02, PNorm = 52.9209, GNorm = 3.0922, lr_0 = 1.0804e-04
Loss = 1.4976e-02, PNorm = 52.9249, GNorm = 2.8633, lr_0 = 1.0804e-04
Validation rmse logD = 1.027417
Validation R2 logD = 0.284086
Epoch 1
Train function
Loss = 1.2472e-02, PNorm = 52.9298, GNorm = 1.7153, lr_0 = 1.0804e-04
Loss = 1.4045e-02, PNorm = 52.9340, GNorm = 6.0653, lr_0 = 1.0804e-04
Loss = 1.3873e-02, PNorm = 52.9384, GNorm = 2.8258, lr_0 = 1.0804e-04
Loss = 1.3112e-02, PNorm = 52.9440, GNorm = 2.5996, lr_0 = 1.0804e-04
Loss = 1.2554e-02, PNorm = 52.9489, GNorm = 6.0225, lr_0 = 1.0804e-04
Loss = 1.3551e-02, PNorm = 52.9540, GNorm = 3.2794, lr_0 = 1.0804e-04
Validation rmse logD = 0.956077
Validation R2 logD = 0.380055
Epoch 2
Train function
Loss = 1.2260e-02, PNorm = 52.9598, GNorm = 3.7007, lr_0 = 1.0804e-04
Loss = 1.0946e-02, PNorm = 52.9670, GNorm = 3.3816, lr_0 = 1.0804e-04
Loss = 1.1205e-02, PNorm = 52.9732, GNorm = 9.1767, lr_0 = 1.0804e-04
Loss = 1.2948e-02, PNorm = 52.9796, GNorm = 3.5123, lr_0 = 1.0804e-04
Loss = 1.0696e-02, PNorm = 52.9872, GNorm = 2.4243, lr_0 = 1.0804e-04
Validation rmse logD = 0.908415
Validation R2 logD = 0.440325
Epoch 3
Train function
Loss = 7.9108e-03, PNorm = 52.9961, GNorm = 1.4416, lr_0 = 1.0804e-04
Loss = 1.0802e-02, PNorm = 53.0047, GNorm = 3.4728, lr_0 = 1.0804e-04
Loss = 1.0005e-02, PNorm = 53.0125, GNorm = 6.9123, lr_0 = 1.0804e-04
Loss = 1.0271e-02, PNorm = 53.0230, GNorm = 5.7438, lr_0 = 1.0804e-04
Loss = 1.0653e-02, PNorm = 53.0296, GNorm = 7.6636, lr_0 = 1.0804e-04
Loss = 8.3752e-03, PNorm = 53.0366, GNorm = 8.2436, lr_0 = 1.0804e-04
Validation rmse logD = 0.946071
Validation R2 logD = 0.392964
Epoch 4
Train function
Loss = 1.0800e-02, PNorm = 53.0454, GNorm = 5.3209, lr_0 = 1.0804e-04
Loss = 9.7211e-03, PNorm = 53.0546, GNorm = 2.5685, lr_0 = 1.0804e-04
Loss = 7.7078e-03, PNorm = 53.0646, GNorm = 2.2777, lr_0 = 1.0804e-04
Loss = 8.7758e-03, PNorm = 53.0736, GNorm = 6.0572, lr_0 = 1.0804e-04
Loss = 8.6334e-03, PNorm = 53.0817, GNorm = 1.3186, lr_0 = 1.0804e-04
Loss = 9.7861e-03, PNorm = 53.0911, GNorm = 2.9287, lr_0 = 1.0804e-04
Validation rmse logD = 1.007074
Validation R2 logD = 0.312156
Epoch 5
Train function
Loss = 1.2095e-02, PNorm = 53.0995, GNorm = 6.1775, lr_0 = 1.0804e-04
Loss = 8.3611e-03, PNorm = 53.1077, GNorm = 4.0842, lr_0 = 1.0804e-04
Loss = 8.4217e-03, PNorm = 53.1185, GNorm = 2.7437, lr_0 = 1.0804e-04
Loss = 9.5623e-03, PNorm = 53.1287, GNorm = 8.8762, lr_0 = 1.0804e-04
Loss = 8.1933e-03, PNorm = 53.1374, GNorm = 2.8427, lr_0 = 1.0804e-04
Validation rmse logD = 0.851850
Validation R2 logD = 0.507854
Epoch 6
Train function
Loss = 1.1893e-02, PNorm = 53.1483, GNorm = 7.0534, lr_0 = 1.0804e-04
Loss = 7.4254e-03, PNorm = 53.1576, GNorm = 3.6581, lr_0 = 1.0804e-04
Loss = 7.1935e-03, PNorm = 53.1666, GNorm = 6.3736, lr_0 = 1.0804e-04
Loss = 7.8128e-03, PNorm = 53.1769, GNorm = 1.9651, lr_0 = 1.0804e-04
Loss = 6.8237e-03, PNorm = 53.1888, GNorm = 1.6369, lr_0 = 1.0804e-04
Loss = 7.8786e-03, PNorm = 53.2002, GNorm = 2.3868, lr_0 = 1.0804e-04
Validation rmse logD = 0.772152
Validation R2 logD = 0.595636
Epoch 7
Train function
Loss = 6.7595e-03, PNorm = 53.2095, GNorm = 6.2854, lr_0 = 1.0804e-04
Loss = 5.6067e-03, PNorm = 53.2187, GNorm = 1.5186, lr_0 = 1.0804e-04
Loss = 6.7157e-03, PNorm = 53.2287, GNorm = 4.5017, lr_0 = 1.0804e-04
Loss = 6.3735e-03, PNorm = 53.2395, GNorm = 2.3747, lr_0 = 1.0804e-04
Loss = 6.9076e-03, PNorm = 53.2497, GNorm = 3.0683, lr_0 = 1.0804e-04
Loss = 8.2833e-03, PNorm = 53.2597, GNorm = 1.7244, lr_0 = 1.0804e-04
Validation rmse logD = 0.762358
Validation R2 logD = 0.605829
Epoch 8
Train function
Loss = 7.9054e-03, PNorm = 53.2685, GNorm = 5.9921, lr_0 = 1.0804e-04
Loss = 6.0694e-03, PNorm = 53.2789, GNorm = 2.0158, lr_0 = 1.0804e-04
Loss = 6.3870e-03, PNorm = 53.2890, GNorm = 4.1305, lr_0 = 1.0804e-04
Loss = 7.1452e-03, PNorm = 53.2986, GNorm = 2.4077, lr_0 = 1.0804e-04
Loss = 7.5305e-03, PNorm = 53.3072, GNorm = 8.4184, lr_0 = 1.0804e-04
Validation rmse logD = 0.762121
Validation R2 logD = 0.606074
Epoch 9
Train function
Loss = 5.4509e-03, PNorm = 53.3181, GNorm = 7.7539, lr_0 = 1.0804e-04
Loss = 6.3091e-03, PNorm = 53.3273, GNorm = 5.4176, lr_0 = 1.0804e-04
Loss = 6.5951e-03, PNorm = 53.3368, GNorm = 2.3961, lr_0 = 1.0804e-04
Loss = 5.9303e-03, PNorm = 53.3472, GNorm = 7.7428, lr_0 = 1.0804e-04
Loss = 6.1127e-03, PNorm = 53.3571, GNorm = 1.7235, lr_0 = 1.0804e-04
Loss = 5.8230e-03, PNorm = 53.3666, GNorm = 3.0528, lr_0 = 1.0804e-04
Validation rmse logD = 0.693456
Validation R2 logD = 0.673859
Epoch 10
Train function
Loss = 7.1721e-03, PNorm = 53.3738, GNorm = 1.5829, lr_0 = 1.0804e-04
Loss = 6.0005e-03, PNorm = 53.3815, GNorm = 6.6763, lr_0 = 1.0804e-04
Loss = 5.1375e-03, PNorm = 53.3924, GNorm = 3.4570, lr_0 = 1.0804e-04
Loss = 5.3012e-03, PNorm = 53.4025, GNorm = 8.4080, lr_0 = 1.0804e-04
Loss = 5.6741e-03, PNorm = 53.4081, GNorm = 2.2816, lr_0 = 1.0804e-04
Loss = 5.3893e-03, PNorm = 53.4134, GNorm = 7.1152, lr_0 = 1.0804e-04
Validation rmse logD = 0.739095
Validation R2 logD = 0.629517
Epoch 11
Train function
Loss = 6.3461e-03, PNorm = 53.4252, GNorm = 4.5583, lr_0 = 1.0804e-04
Loss = 5.2297e-03, PNorm = 53.4366, GNorm = 5.4594, lr_0 = 1.0804e-04
Loss = 5.8738e-03, PNorm = 53.4455, GNorm = 2.6568, lr_0 = 1.0804e-04
Loss = 4.2636e-03, PNorm = 53.4536, GNorm = 1.4925, lr_0 = 1.0804e-04
Loss = 5.2074e-03, PNorm = 53.4619, GNorm = 7.6678, lr_0 = 1.0804e-04
Validation rmse logD = 0.672376
Validation R2 logD = 0.693386
Epoch 12
Train function
Loss = 7.3402e-03, PNorm = 53.4690, GNorm = 2.8509, lr_0 = 1.0804e-04
Loss = 5.3883e-03, PNorm = 53.4766, GNorm = 7.4013, lr_0 = 1.0804e-04
Loss = 5.3412e-03, PNorm = 53.4842, GNorm = 6.0721, lr_0 = 1.0804e-04
Loss = 5.6865e-03, PNorm = 53.4913, GNorm = 2.3712, lr_0 = 1.0804e-04
Loss = 4.8532e-03, PNorm = 53.4978, GNorm = 4.6186, lr_0 = 1.0804e-04
Loss = 4.9588e-03, PNorm = 53.5070, GNorm = 7.0569, lr_0 = 1.0804e-04
Validation rmse logD = 0.653274
Validation R2 logD = 0.710560
Epoch 13
Train function
Loss = 4.1755e-03, PNorm = 53.5173, GNorm = 4.4955, lr_0 = 1.0804e-04
Loss = 4.2552e-03, PNorm = 53.5275, GNorm = 2.9644, lr_0 = 1.0804e-04
Loss = 5.5658e-03, PNorm = 53.5340, GNorm = 2.1034, lr_0 = 1.0804e-04
Loss = 4.5502e-03, PNorm = 53.5416, GNorm = 2.5290, lr_0 = 1.0804e-04
Loss = 5.4542e-03, PNorm = 53.5477, GNorm = 2.0853, lr_0 = 1.0804e-04
Loss = 4.0894e-03, PNorm = 53.5553, GNorm = 2.1612, lr_0 = 1.0804e-04
Validation rmse logD = 0.641112
Validation R2 logD = 0.721237
Epoch 14
Train function
Loss = 3.8193e-03, PNorm = 53.5649, GNorm = 1.7116, lr_0 = 1.0804e-04
Loss = 4.2594e-03, PNorm = 53.5734, GNorm = 3.5877, lr_0 = 1.0804e-04
Loss = 4.7500e-03, PNorm = 53.5834, GNorm = 4.0846, lr_0 = 1.0804e-04
Loss = 4.0618e-03, PNorm = 53.5927, GNorm = 7.8000, lr_0 = 1.0804e-04
Loss = 4.5867e-03, PNorm = 53.6008, GNorm = 2.4513, lr_0 = 1.0804e-04
Validation rmse logD = 0.627687
Validation R2 logD = 0.732790
Epoch 15
Train function
Loss = 2.2956e-03, PNorm = 53.6087, GNorm = 3.6183, lr_0 = 1.0804e-04
Loss = 3.5701e-03, PNorm = 53.6160, GNorm = 1.6973, lr_0 = 1.0804e-04
Loss = 4.0833e-03, PNorm = 53.6239, GNorm = 2.5209, lr_0 = 1.0804e-04
Loss = 4.3056e-03, PNorm = 53.6320, GNorm = 2.1727, lr_0 = 1.0804e-04
Loss = 4.4353e-03, PNorm = 53.6373, GNorm = 4.8240, lr_0 = 1.0804e-04
Loss = 4.9407e-03, PNorm = 53.6448, GNorm = 2.3041, lr_0 = 1.0804e-04
Validation rmse logD = 0.638104
Validation R2 logD = 0.723847
Epoch 16
Train function
Loss = 5.1858e-03, PNorm = 53.6550, GNorm = 4.4081, lr_0 = 1.0804e-04
Loss = 4.8585e-03, PNorm = 53.6641, GNorm = 9.3524, lr_0 = 1.0804e-04
Loss = 3.8413e-03, PNorm = 53.6735, GNorm = 7.1198, lr_0 = 1.0804e-04
Loss = 4.8789e-03, PNorm = 53.6819, GNorm = 8.8815, lr_0 = 1.0804e-04
Loss = 3.9287e-03, PNorm = 53.6900, GNorm = 2.0564, lr_0 = 1.0804e-04
Loss = 3.7553e-03, PNorm = 53.6973, GNorm = 3.4082, lr_0 = 1.0804e-04
Validation rmse logD = 0.615565
Validation R2 logD = 0.743011
Epoch 17
Train function
Loss = 3.6870e-03, PNorm = 53.7042, GNorm = 7.6245, lr_0 = 1.0804e-04
Loss = 3.8020e-03, PNorm = 53.7124, GNorm = 3.4890, lr_0 = 1.0804e-04
Loss = 3.4863e-03, PNorm = 53.7210, GNorm = 2.2644, lr_0 = 1.0804e-04
Loss = 4.6607e-03, PNorm = 53.7285, GNorm = 8.7790, lr_0 = 1.0804e-04
Loss = 4.7028e-03, PNorm = 53.7365, GNorm = 4.4832, lr_0 = 1.0804e-04
Validation rmse logD = 0.618960
Validation R2 logD = 0.740168
Epoch 18
Train function
Loss = 3.2672e-03, PNorm = 53.7449, GNorm = 2.6174, lr_0 = 1.0804e-04
Loss = 3.6460e-03, PNorm = 53.7526, GNorm = 3.6480, lr_0 = 1.0804e-04
Loss = 3.9178e-03, PNorm = 53.7580, GNorm = 7.2453, lr_0 = 1.0804e-04
Loss = 3.7926e-03, PNorm = 53.7658, GNorm = 5.5981, lr_0 = 1.0804e-04
Loss = 3.6966e-03, PNorm = 53.7747, GNorm = 8.2584, lr_0 = 1.0804e-04
Loss = 3.6445e-03, PNorm = 53.7847, GNorm = 8.8012, lr_0 = 1.0804e-04
Validation rmse logD = 0.636548
Validation R2 logD = 0.725192
Epoch 19
Train function
Loss = 4.4587e-03, PNorm = 53.7927, GNorm = 6.0757, lr_0 = 1.0804e-04
Loss = 3.4208e-03, PNorm = 53.8010, GNorm = 3.6166, lr_0 = 1.0804e-04
Loss = 3.2882e-03, PNorm = 53.8092, GNorm = 4.4004, lr_0 = 1.0804e-04
Loss = 3.7477e-03, PNorm = 53.8173, GNorm = 4.3427, lr_0 = 1.0804e-04
Loss = 3.4897e-03, PNorm = 53.8265, GNorm = 2.6669, lr_0 = 1.0804e-04
Loss = 3.3785e-03, PNorm = 53.8359, GNorm = 2.9360, lr_0 = 1.0804e-04
Validation rmse logD = 0.589023
Validation R2 logD = 0.764695
Epoch 20
Train function
Loss = 3.1465e-03, PNorm = 53.8420, GNorm = 3.7656, lr_0 = 1.0804e-04
Loss = 3.8124e-03, PNorm = 53.8486, GNorm = 7.3553, lr_0 = 1.0804e-04
Loss = 3.5776e-03, PNorm = 53.8568, GNorm = 3.6833, lr_0 = 1.0804e-04
Loss = 2.8725e-03, PNorm = 53.8642, GNorm = 4.5494, lr_0 = 1.0804e-04
Loss = 3.4830e-03, PNorm = 53.8708, GNorm = 5.1668, lr_0 = 1.0804e-04
Validation rmse logD = 0.595852
Validation R2 logD = 0.759207
Epoch 21
Train function
Loss = 1.8215e-03, PNorm = 53.8787, GNorm = 3.8692, lr_0 = 1.0804e-04
Loss = 3.2331e-03, PNorm = 53.8870, GNorm = 4.3437, lr_0 = 1.0804e-04
Loss = 2.7291e-03, PNorm = 53.8965, GNorm = 3.2169, lr_0 = 1.0804e-04
Loss = 3.1480e-03, PNorm = 53.9044, GNorm = 2.0431, lr_0 = 1.0804e-04
Loss = 3.4028e-03, PNorm = 53.9108, GNorm = 8.5127, lr_0 = 1.0804e-04
Loss = 3.6522e-03, PNorm = 53.9188, GNorm = 6.5853, lr_0 = 1.0804e-04
Validation rmse logD = 0.585849
Validation R2 logD = 0.767224
Epoch 22
Train function
Loss = 3.0212e-03, PNorm = 53.9256, GNorm = 2.9113, lr_0 = 1.0804e-04
Loss = 2.8053e-03, PNorm = 53.9335, GNorm = 1.5941, lr_0 = 1.0804e-04
Loss = 2.9418e-03, PNorm = 53.9407, GNorm = 6.5820, lr_0 = 1.0804e-04
Loss = 3.3932e-03, PNorm = 53.9499, GNorm = 6.5903, lr_0 = 1.0804e-04
Loss = 2.9765e-03, PNorm = 53.9582, GNorm = 4.9795, lr_0 = 1.0804e-04
Loss = 2.9958e-03, PNorm = 53.9653, GNorm = 4.5354, lr_0 = 1.0804e-04
Validation rmse logD = 0.578022
Validation R2 logD = 0.773402
Epoch 23
Train function
Loss = 2.6485e-03, PNorm = 53.9730, GNorm = 2.3237, lr_0 = 1.0804e-04
Loss = 2.7913e-03, PNorm = 53.9791, GNorm = 2.1465, lr_0 = 1.0804e-04
Loss = 2.7715e-03, PNorm = 53.9874, GNorm = 4.2620, lr_0 = 1.0804e-04
Loss = 2.6220e-03, PNorm = 53.9946, GNorm = 1.1706, lr_0 = 1.0804e-04
Loss = 2.6279e-03, PNorm = 54.0029, GNorm = 4.6396, lr_0 = 1.0804e-04
Validation rmse logD = 0.595604
Validation R2 logD = 0.759407
Epoch 24
Train function
Loss = 2.7544e-03, PNorm = 54.0100, GNorm = 6.5516, lr_0 = 1.0804e-04
Loss = 2.9016e-03, PNorm = 54.0177, GNorm = 5.2372, lr_0 = 1.0804e-04
Loss = 2.7158e-03, PNorm = 54.0265, GNorm = 3.7516, lr_0 = 1.0804e-04
Loss = 3.0147e-03, PNorm = 54.0341, GNorm = 5.4969, lr_0 = 1.0804e-04
Loss = 3.0452e-03, PNorm = 54.0410, GNorm = 2.3211, lr_0 = 1.0804e-04
Loss = 2.6764e-03, PNorm = 54.0478, GNorm = 2.5335, lr_0 = 1.0804e-04
Validation rmse logD = 0.576076
Validation R2 logD = 0.774925
Epoch 25
Train function
Loss = 2.4021e-03, PNorm = 54.0567, GNorm = 3.7816, lr_0 = 1.0804e-04
Loss = 2.9608e-03, PNorm = 54.0653, GNorm = 2.8780, lr_0 = 1.0804e-04
Loss = 2.4458e-03, PNorm = 54.0723, GNorm = 4.2159, lr_0 = 1.0804e-04
Loss = 2.5557e-03, PNorm = 54.0800, GNorm = 6.7261, lr_0 = 1.0804e-04
Loss = 2.3973e-03, PNorm = 54.0877, GNorm = 5.1847, lr_0 = 1.0804e-04
Loss = 3.2002e-03, PNorm = 54.0929, GNorm = 4.2231, lr_0 = 1.0804e-04
Validation rmse logD = 0.568630
Validation R2 logD = 0.780706
Epoch 26
Train function
Loss = 2.2708e-03, PNorm = 54.1009, GNorm = 1.9281, lr_0 = 1.0804e-04
Loss = 2.5040e-03, PNorm = 54.1089, GNorm = 2.1615, lr_0 = 1.0804e-04
Loss = 2.5615e-03, PNorm = 54.1157, GNorm = 4.0310, lr_0 = 1.0804e-04
Loss = 2.5170e-03, PNorm = 54.1227, GNorm = 5.3112, lr_0 = 1.0804e-04
Loss = 2.5906e-03, PNorm = 54.1310, GNorm = 1.9601, lr_0 = 1.0804e-04
Validation rmse logD = 0.576650
Validation R2 logD = 0.774477
Epoch 27
Train function
Loss = 3.3448e-03, PNorm = 54.1394, GNorm = 4.6652, lr_0 = 1.0804e-04
Loss = 2.2979e-03, PNorm = 54.1448, GNorm = 7.5517, lr_0 = 1.0804e-04
Loss = 2.0226e-03, PNorm = 54.1518, GNorm = 2.8340, lr_0 = 1.0804e-04
Loss = 2.3385e-03, PNorm = 54.1586, GNorm = 1.7180, lr_0 = 1.0804e-04
Loss = 2.1552e-03, PNorm = 54.1664, GNorm = 2.1171, lr_0 = 1.0804e-04
Loss = 2.4080e-03, PNorm = 54.1752, GNorm = 2.4747, lr_0 = 1.0804e-04
Validation rmse logD = 0.604325
Validation R2 logD = 0.752310
Epoch 28
Train function
Loss = 1.9069e-03, PNorm = 54.1816, GNorm = 6.5172, lr_0 = 1.0804e-04
Loss = 2.6188e-03, PNorm = 54.1886, GNorm = 3.4874, lr_0 = 1.0804e-04
Loss = 2.5745e-03, PNorm = 54.1947, GNorm = 2.6021, lr_0 = 1.0804e-04
Loss = 1.8382e-03, PNorm = 54.2014, GNorm = 4.0426, lr_0 = 1.0804e-04
Loss = 2.3686e-03, PNorm = 54.2074, GNorm = 2.4058, lr_0 = 1.0804e-04
Loss = 2.7234e-03, PNorm = 54.2133, GNorm = 4.5693, lr_0 = 1.0804e-04
Validation rmse logD = 0.570803
Validation R2 logD = 0.779027
Epoch 29
Train function
Loss = 1.7465e-03, PNorm = 54.2220, GNorm = 7.0637, lr_0 = 1.0804e-04
Loss = 1.9770e-03, PNorm = 54.2300, GNorm = 1.9011, lr_0 = 1.0804e-04
Loss = 2.3545e-03, PNorm = 54.2370, GNorm = 5.5691, lr_0 = 1.0804e-04
Loss = 2.0785e-03, PNorm = 54.2430, GNorm = 2.2711, lr_0 = 1.0804e-04
Loss = 2.4229e-03, PNorm = 54.2479, GNorm = 3.7827, lr_0 = 1.0804e-04
Validation rmse logD = 0.558295
Validation R2 logD = 0.788605
Epoch 30
Train function
Loss = 1.5214e-03, PNorm = 54.2558, GNorm = 1.4902, lr_0 = 1.0804e-04
Loss = 1.6890e-03, PNorm = 54.2639, GNorm = 2.3257, lr_0 = 1.0804e-04
Loss = 2.0277e-03, PNorm = 54.2703, GNorm = 7.6221, lr_0 = 1.0804e-04
Loss = 2.2927e-03, PNorm = 54.2753, GNorm = 2.0211, lr_0 = 1.0804e-04
Loss = 2.2378e-03, PNorm = 54.2826, GNorm = 6.8075, lr_0 = 1.0804e-04
Loss = 2.6618e-03, PNorm = 54.2886, GNorm = 3.6433, lr_0 = 1.0804e-04
Validation rmse logD = 0.558221
Validation R2 logD = 0.788661
Epoch 31
Train function
Loss = 1.6171e-03, PNorm = 54.2947, GNorm = 4.2792, lr_0 = 1.0804e-04
Loss = 2.4502e-03, PNorm = 54.3020, GNorm = 12.2254, lr_0 = 1.0804e-04
Loss = 2.1560e-03, PNorm = 54.3081, GNorm = 2.8746, lr_0 = 1.0804e-04
Loss = 2.1289e-03, PNorm = 54.3146, GNorm = 5.8856, lr_0 = 1.0804e-04
Loss = 2.4424e-03, PNorm = 54.3229, GNorm = 5.1829, lr_0 = 1.0804e-04
Loss = 1.8844e-03, PNorm = 54.3294, GNorm = 5.0506, lr_0 = 1.0804e-04
Validation rmse logD = 0.548882
Validation R2 logD = 0.795673
Epoch 32
Train function
Loss = 1.8707e-03, PNorm = 54.3357, GNorm = 2.4637, lr_0 = 1.0804e-04
Loss = 1.6519e-03, PNorm = 54.3424, GNorm = 1.7643, lr_0 = 1.0804e-04
Loss = 1.8022e-03, PNorm = 54.3481, GNorm = 2.2654, lr_0 = 1.0804e-04
Loss = 1.9042e-03, PNorm = 54.3564, GNorm = 1.7430, lr_0 = 1.0804e-04
Loss = 1.7914e-03, PNorm = 54.3612, GNorm = 4.9622, lr_0 = 1.0804e-04
Validation rmse logD = 0.579497
Validation R2 logD = 0.772244
Epoch 33
Train function
Loss = 1.2663e-03, PNorm = 54.3675, GNorm = 3.5141, lr_0 = 1.0804e-04
Loss = 1.6733e-03, PNorm = 54.3727, GNorm = 3.7520, lr_0 = 1.0804e-04
Loss = 1.9130e-03, PNorm = 54.3792, GNorm = 3.9147, lr_0 = 1.0804e-04
Loss = 2.1304e-03, PNorm = 54.3858, GNorm = 6.9984, lr_0 = 1.0804e-04
Loss = 1.8453e-03, PNorm = 54.3906, GNorm = 1.8185, lr_0 = 1.0804e-04
Loss = 1.7060e-03, PNorm = 54.3964, GNorm = 2.1018, lr_0 = 1.0804e-04
Validation rmse logD = 0.548848
Validation R2 logD = 0.795698
Epoch 34
Train function
Loss = 1.3698e-03, PNorm = 54.4035, GNorm = 3.5721, lr_0 = 1.0804e-04
Loss = 1.2943e-03, PNorm = 54.4114, GNorm = 2.8062, lr_0 = 1.0804e-04
Loss = 2.0948e-03, PNorm = 54.4163, GNorm = 8.9216, lr_0 = 1.0804e-04
Loss = 1.8720e-03, PNorm = 54.4221, GNorm = 1.5889, lr_0 = 1.0804e-04
Loss = 2.2017e-03, PNorm = 54.4276, GNorm = 5.2120, lr_0 = 1.0804e-04
Loss = 1.9160e-03, PNorm = 54.4325, GNorm = 5.2343, lr_0 = 1.0804e-04
Validation rmse logD = 0.569963
Validation R2 logD = 0.779676
Epoch 35
Train function
Loss = 1.9063e-03, PNorm = 54.4376, GNorm = 1.6503, lr_0 = 1.0804e-04
Loss = 1.7394e-03, PNorm = 54.4447, GNorm = 1.9896, lr_0 = 1.0804e-04
Loss = 1.6956e-03, PNorm = 54.4513, GNorm = 9.0088, lr_0 = 1.0804e-04
Loss = 1.7338e-03, PNorm = 54.4563, GNorm = 2.7259, lr_0 = 1.0804e-04
Loss = 1.6439e-03, PNorm = 54.4626, GNorm = 1.7159, lr_0 = 1.0804e-04
Validation rmse logD = 0.559108
Validation R2 logD = 0.787989
Epoch 36
Train function
Loss = 1.4505e-03, PNorm = 54.4701, GNorm = 1.9811, lr_0 = 1.0804e-04
Loss = 1.5784e-03, PNorm = 54.4763, GNorm = 3.7397, lr_0 = 1.0804e-04
Loss = 1.9825e-03, PNorm = 54.4821, GNorm = 6.8881, lr_0 = 1.0804e-04
Loss = 1.8065e-03, PNorm = 54.4889, GNorm = 2.0148, lr_0 = 1.0804e-04
Loss = 1.4129e-03, PNorm = 54.4958, GNorm = 8.3590, lr_0 = 1.0804e-04
Loss = 1.5112e-03, PNorm = 54.5004, GNorm = 3.5466, lr_0 = 1.0804e-04
Validation rmse logD = 0.551327
Validation R2 logD = 0.793849
Epoch 37
Train function
Loss = 1.4539e-03, PNorm = 54.5082, GNorm = 1.7163, lr_0 = 1.0804e-04
Loss = 1.3872e-03, PNorm = 54.5134, GNorm = 2.7236, lr_0 = 1.0804e-04
Loss = 1.3661e-03, PNorm = 54.5186, GNorm = 4.7420, lr_0 = 1.0804e-04
Loss = 1.3244e-03, PNorm = 54.5256, GNorm = 3.3768, lr_0 = 1.0804e-04
Loss = 1.8992e-03, PNorm = 54.5308, GNorm = 1.4687, lr_0 = 1.0804e-04
Loss = 1.4339e-03, PNorm = 54.5354, GNorm = 1.3299, lr_0 = 1.0804e-04
Validation rmse logD = 0.566870
Validation R2 logD = 0.782061
Epoch 38
Train function
Loss = 1.4944e-03, PNorm = 54.5417, GNorm = 6.6626, lr_0 = 1.0804e-04
Loss = 1.4247e-03, PNorm = 54.5462, GNorm = 1.5827, lr_0 = 1.0804e-04
Loss = 1.4333e-03, PNorm = 54.5522, GNorm = 1.5417, lr_0 = 1.0804e-04
Loss = 1.5479e-03, PNorm = 54.5582, GNorm = 6.0958, lr_0 = 1.0804e-04
Loss = 1.9370e-03, PNorm = 54.5622, GNorm = 4.6927, lr_0 = 1.0804e-04
Validation rmse logD = 0.559551
Validation R2 logD = 0.787653
Epoch 39
Train function
Loss = 1.0804e-03, PNorm = 54.5710, GNorm = 2.3756, lr_0 = 1.0804e-04
Loss = 1.2327e-03, PNorm = 54.5770, GNorm = 5.5349, lr_0 = 1.0804e-04
Loss = 1.1941e-03, PNorm = 54.5820, GNorm = 1.7700, lr_0 = 1.0804e-04
Loss = 1.5586e-03, PNorm = 54.5881, GNorm = 6.8615, lr_0 = 1.0804e-04
Loss = 1.9119e-03, PNorm = 54.5923, GNorm = 5.6151, lr_0 = 1.0804e-04
Loss = 1.5667e-03, PNorm = 54.5983, GNorm = 1.9200, lr_0 = 1.0804e-04
Validation rmse logD = 0.547711
Validation R2 logD = 0.796544
Epoch 40
Train function
Loss = 1.2695e-03, PNorm = 54.6046, GNorm = 1.6753, lr_0 = 1.0804e-04
Loss = 1.2836e-03, PNorm = 54.6113, GNorm = 1.6694, lr_0 = 1.0804e-04
Loss = 1.3997e-03, PNorm = 54.6168, GNorm = 5.6684, lr_0 = 1.0804e-04
Loss = 1.4327e-03, PNorm = 54.6201, GNorm = 1.8146, lr_0 = 1.0804e-04
Loss = 1.4108e-03, PNorm = 54.6266, GNorm = 3.3098, lr_0 = 1.0804e-04
Loss = 1.8390e-03, PNorm = 54.6319, GNorm = 2.7820, lr_0 = 1.0804e-04
Validation rmse logD = 0.554433
Validation R2 logD = 0.791520
Epoch 41
Train function
Loss = 1.0415e-03, PNorm = 54.6387, GNorm = 3.3208, lr_0 = 1.0804e-04
Loss = 1.3811e-03, PNorm = 54.6433, GNorm = 2.4526, lr_0 = 1.0804e-04
Loss = 1.5833e-03, PNorm = 54.6494, GNorm = 1.9550, lr_0 = 1.0804e-04
Loss = 1.0351e-03, PNorm = 54.6542, GNorm = 1.5618, lr_0 = 1.0804e-04
Loss = 9.6037e-04, PNorm = 54.6596, GNorm = 1.9013, lr_0 = 1.0804e-04
Validation rmse logD = 0.589436
Validation R2 logD = 0.764365
Epoch 42
Train function
Loss = 1.1240e-03, PNorm = 54.6653, GNorm = 4.3196, lr_0 = 1.0804e-04
Loss = 1.4811e-03, PNorm = 54.6700, GNorm = 2.0650, lr_0 = 1.0804e-04
Loss = 1.1481e-03, PNorm = 54.6774, GNorm = 1.9481, lr_0 = 1.0804e-04
Loss = 1.4969e-03, PNorm = 54.6827, GNorm = 2.1479, lr_0 = 1.0804e-04
Loss = 1.1587e-03, PNorm = 54.6883, GNorm = 2.5779, lr_0 = 1.0804e-04
Loss = 1.2680e-03, PNorm = 54.6941, GNorm = 1.7032, lr_0 = 1.0804e-04
Validation rmse logD = 0.534391
Validation R2 logD = 0.806320
Epoch 43
Train function
Loss = 1.1093e-03, PNorm = 54.6977, GNorm = 3.0605, lr_0 = 1.0804e-04
Loss = 1.2884e-03, PNorm = 54.7019, GNorm = 2.0140, lr_0 = 1.0804e-04
Loss = 1.2419e-03, PNorm = 54.7077, GNorm = 4.5541, lr_0 = 1.0804e-04
Loss = 1.0952e-03, PNorm = 54.7125, GNorm = 1.7692, lr_0 = 1.0804e-04
Loss = 1.2551e-03, PNorm = 54.7173, GNorm = 1.4324, lr_0 = 1.0804e-04
Loss = 1.1652e-03, PNorm = 54.7225, GNorm = 1.3351, lr_0 = 1.0804e-04
Validation rmse logD = 0.539089
Validation R2 logD = 0.802900
Epoch 44
Train function
Loss = 1.0476e-03, PNorm = 54.7271, GNorm = 3.0847, lr_0 = 1.0804e-04
Loss = 1.0539e-03, PNorm = 54.7318, GNorm = 1.4052, lr_0 = 1.0804e-04
Loss = 9.6301e-04, PNorm = 54.7366, GNorm = 4.7589, lr_0 = 1.0804e-04
Loss = 1.0470e-03, PNorm = 54.7412, GNorm = 3.2911, lr_0 = 1.0804e-04
Loss = 1.2814e-03, PNorm = 54.7453, GNorm = 5.9488, lr_0 = 1.0804e-04
Validation rmse logD = 0.558906
Validation R2 logD = 0.788142
Epoch 45
Train function
Loss = 9.3122e-04, PNorm = 54.7502, GNorm = 2.1630, lr_0 = 1.0804e-04
Loss = 9.6090e-04, PNorm = 54.7556, GNorm = 1.1134, lr_0 = 1.0804e-04
Loss = 1.0222e-03, PNorm = 54.7608, GNorm = 2.8811, lr_0 = 1.0804e-04
Loss = 1.0378e-03, PNorm = 54.7645, GNorm = 2.7944, lr_0 = 1.0804e-04
Loss = 1.1003e-03, PNorm = 54.7698, GNorm = 3.9073, lr_0 = 1.0804e-04
Loss = 1.3042e-03, PNorm = 54.7749, GNorm = 1.9120, lr_0 = 1.0804e-04
Validation rmse logD = 0.557615
Validation R2 logD = 0.789120
Epoch 46
Train function
Loss = 1.2836e-03, PNorm = 54.7800, GNorm = 6.5745, lr_0 = 1.0804e-04
Loss = 1.0912e-03, PNorm = 54.7847, GNorm = 4.1095, lr_0 = 1.0804e-04
Loss = 1.5003e-03, PNorm = 54.7902, GNorm = 2.3537, lr_0 = 1.0804e-04
Loss = 9.8866e-04, PNorm = 54.7968, GNorm = 2.4296, lr_0 = 1.0804e-04
Loss = 1.1871e-03, PNorm = 54.8023, GNorm = 4.2051, lr_0 = 1.0804e-04
Loss = 1.1191e-03, PNorm = 54.8072, GNorm = 2.0506, lr_0 = 1.0804e-04
Validation rmse logD = 0.545139
Validation R2 logD = 0.798450
Epoch 47
Train function
Loss = 8.5934e-04, PNorm = 54.8112, GNorm = 2.5473, lr_0 = 1.0804e-04
Loss = 1.0174e-03, PNorm = 54.8160, GNorm = 4.1187, lr_0 = 1.0804e-04
Loss = 1.1408e-03, PNorm = 54.8197, GNorm = 4.4259, lr_0 = 1.0804e-04
Loss = 1.0289e-03, PNorm = 54.8242, GNorm = 2.0271, lr_0 = 1.0804e-04
Loss = 1.2674e-03, PNorm = 54.8288, GNorm = 6.5678, lr_0 = 1.0804e-04
Validation rmse logD = 0.538599
Validation R2 logD = 0.803257
Epoch 48
Train function
Loss = 7.5893e-04, PNorm = 54.8343, GNorm = 1.6485, lr_0 = 1.0804e-04
Loss = 1.1836e-03, PNorm = 54.8390, GNorm = 6.2934, lr_0 = 1.0804e-04
Loss = 1.3567e-03, PNorm = 54.8447, GNorm = 3.6952, lr_0 = 1.0804e-04
Loss = 1.0015e-03, PNorm = 54.8510, GNorm = 2.4652, lr_0 = 1.0804e-04
Loss = 8.2598e-04, PNorm = 54.8576, GNorm = 1.3939, lr_0 = 1.0804e-04
Loss = 8.5597e-04, PNorm = 54.8620, GNorm = 2.8565, lr_0 = 1.0804e-04
Validation rmse logD = 0.563329
Validation R2 logD = 0.784775
Epoch 49
Train function
Loss = 1.1295e-03, PNorm = 54.8674, GNorm = 1.0651, lr_0 = 1.0804e-04
Loss = 9.2386e-04, PNorm = 54.8721, GNorm = 1.5389, lr_0 = 1.0804e-04
Loss = 8.1316e-04, PNorm = 54.8764, GNorm = 2.9088, lr_0 = 1.0804e-04
Loss = 1.0522e-03, PNorm = 54.8807, GNorm = 6.3397, lr_0 = 1.0804e-04
Loss = 8.3168e-04, PNorm = 54.8831, GNorm = 1.8551, lr_0 = 1.0804e-04
Loss = 1.1642e-03, PNorm = 54.8882, GNorm = 6.0398, lr_0 = 1.0804e-04
Validation rmse logD = 0.565403
Validation R2 logD = 0.783188
Epoch 50
Train function
Loss = 1.1456e-03, PNorm = 54.8918, GNorm = 2.4527, lr_0 = 1.0804e-04
Loss = 9.6406e-04, PNorm = 54.8965, GNorm = 1.3596, lr_0 = 1.0804e-04
Loss = 1.1594e-03, PNorm = 54.9027, GNorm = 8.0477, lr_0 = 1.0804e-04
Loss = 1.1151e-03, PNorm = 54.9080, GNorm = 4.1013, lr_0 = 1.0804e-04
Loss = 1.0936e-03, PNorm = 54.9126, GNorm = 3.3608, lr_0 = 1.0804e-04
Validation rmse logD = 0.525908
Validation R2 logD = 0.812420
Epoch 51
Train function
Loss = 6.2624e-04, PNorm = 54.9175, GNorm = 1.2658, lr_0 = 1.0804e-04
Loss = 7.0264e-04, PNorm = 54.9227, GNorm = 1.6197, lr_0 = 1.0804e-04
Loss = 7.4786e-04, PNorm = 54.9267, GNorm = 4.8289, lr_0 = 1.0804e-04
Loss = 9.9773e-04, PNorm = 54.9317, GNorm = 1.2129, lr_0 = 1.0804e-04
Loss = 8.4554e-04, PNorm = 54.9371, GNorm = 1.6411, lr_0 = 1.0804e-04
Loss = 1.0472e-03, PNorm = 54.9412, GNorm = 1.3753, lr_0 = 1.0804e-04
Validation rmse logD = 0.573109
Validation R2 logD = 0.777237
Epoch 52
Train function
Loss = 1.4497e-03, PNorm = 54.9446, GNorm = 1.2727, lr_0 = 1.0804e-04
Loss = 1.1942e-03, PNorm = 54.9490, GNorm = 4.8027, lr_0 = 1.0804e-04
Loss = 1.3738e-03, PNorm = 54.9547, GNorm = 8.3414, lr_0 = 1.0804e-04
Loss = 1.5586e-03, PNorm = 54.9591, GNorm = 6.3517, lr_0 = 1.0804e-04
Loss = 1.3202e-03, PNorm = 54.9633, GNorm = 1.8666, lr_0 = 1.0804e-04
Loss = 1.0065e-03, PNorm = 54.9703, GNorm = 5.1962, lr_0 = 1.0804e-04
Validation rmse logD = 0.535001
Validation R2 logD = 0.805877
Epoch 53
Train function
Loss = 7.6553e-04, PNorm = 54.9764, GNorm = 2.9975, lr_0 = 1.0804e-04
Loss = 1.1365e-03, PNorm = 54.9812, GNorm = 3.8806, lr_0 = 1.0804e-04
Loss = 1.0008e-03, PNorm = 54.9854, GNorm = 1.9908, lr_0 = 1.0804e-04
Loss = 1.1062e-03, PNorm = 54.9906, GNorm = 7.1033, lr_0 = 1.0804e-04
Loss = 8.7911e-04, PNorm = 54.9941, GNorm = 1.3858, lr_0 = 1.0804e-04
Validation rmse logD = 0.529003
Validation R2 logD = 0.810206
Epoch 54
Train function
Loss = 6.0205e-04, PNorm = 54.9991, GNorm = 2.1286, lr_0 = 1.0804e-04
Loss = 7.7718e-04, PNorm = 55.0048, GNorm = 1.7194, lr_0 = 1.0804e-04
Loss = 7.8176e-04, PNorm = 55.0098, GNorm = 1.1547, lr_0 = 1.0804e-04
Loss = 9.4543e-04, PNorm = 55.0142, GNorm = 6.5613, lr_0 = 1.0804e-04
Loss = 7.8394e-04, PNorm = 55.0178, GNorm = 0.9248, lr_0 = 1.0804e-04
Loss = 7.7846e-04, PNorm = 55.0221, GNorm = 2.3424, lr_0 = 1.0804e-04
Validation rmse logD = 0.527880
Validation R2 logD = 0.811011
Epoch 55
Train function
Loss = 7.0225e-04, PNorm = 55.0261, GNorm = 2.8118, lr_0 = 1.0804e-04
Loss = 8.0262e-04, PNorm = 55.0306, GNorm = 4.8386, lr_0 = 1.0804e-04
Loss = 9.6906e-04, PNorm = 55.0336, GNorm = 6.5176, lr_0 = 1.0804e-04
Loss = 9.1608e-04, PNorm = 55.0376, GNorm = 1.0594, lr_0 = 1.0804e-04
Loss = 7.5692e-04, PNorm = 55.0416, GNorm = 3.5354, lr_0 = 1.0804e-04
Loss = 1.0124e-03, PNorm = 55.0451, GNorm = 1.7447, lr_0 = 1.0804e-04
Validation rmse logD = 0.533170
Validation R2 logD = 0.807204
Epoch 56
Train function
Loss = 6.0931e-04, PNorm = 55.0510, GNorm = 1.2140, lr_0 = 1.0804e-04
Loss = 7.3455e-04, PNorm = 55.0552, GNorm = 2.0629, lr_0 = 1.0804e-04
Loss = 8.7456e-04, PNorm = 55.0595, GNorm = 1.3842, lr_0 = 1.0804e-04
Loss = 8.5914e-04, PNorm = 55.0631, GNorm = 4.2983, lr_0 = 1.0804e-04
Loss = 7.6957e-04, PNorm = 55.0662, GNorm = 4.8153, lr_0 = 1.0804e-04
Validation rmse logD = 0.526528
Validation R2 logD = 0.811977
Epoch 57
Train function
Loss = 5.2742e-04, PNorm = 55.0701, GNorm = 0.9688, lr_0 = 1.0804e-04
Loss = 9.5908e-04, PNorm = 55.0725, GNorm = 4.9698, lr_0 = 1.0804e-04
Loss = 8.9290e-04, PNorm = 55.0766, GNorm = 4.7404, lr_0 = 1.0804e-04
Loss = 9.3419e-04, PNorm = 55.0822, GNorm = 5.4686, lr_0 = 1.0804e-04
Loss = 7.2147e-04, PNorm = 55.0867, GNorm = 1.2456, lr_0 = 1.0804e-04
Loss = 7.2395e-04, PNorm = 55.0907, GNorm = 3.4022, lr_0 = 1.0804e-04
Validation rmse logD = 0.580683
Validation R2 logD = 0.771311
Epoch 58
Train function
Loss = 8.4359e-04, PNorm = 55.0953, GNorm = 4.7543, lr_0 = 1.0804e-04
Loss = 7.5588e-04, PNorm = 55.1003, GNorm = 2.0958, lr_0 = 1.0804e-04
Loss = 5.9927e-04, PNorm = 55.1050, GNorm = 1.3362, lr_0 = 1.0804e-04
Loss = 9.8287e-04, PNorm = 55.1092, GNorm = 1.5010, lr_0 = 1.0804e-04
Loss = 6.0730e-04, PNorm = 55.1136, GNorm = 3.8863, lr_0 = 1.0804e-04
Loss = 8.1508e-04, PNorm = 55.1168, GNorm = 1.2012, lr_0 = 1.0804e-04
Validation rmse logD = 0.534447
Validation R2 logD = 0.806279
Epoch 59
Train function
Loss = 5.7846e-04, PNorm = 55.1206, GNorm = 1.6561, lr_0 = 1.0804e-04
Loss = 5.3563e-04, PNorm = 55.1253, GNorm = 1.1606, lr_0 = 1.0804e-04
Loss = 7.4578e-04, PNorm = 55.1273, GNorm = 4.3247, lr_0 = 1.0804e-04
Loss = 6.9836e-04, PNorm = 55.1305, GNorm = 1.2013, lr_0 = 1.0804e-04
Loss = 6.1356e-04, PNorm = 55.1350, GNorm = 2.1234, lr_0 = 1.0804e-04
Validation rmse logD = 0.544142
Validation R2 logD = 0.799187
Epoch 60
Train function
Loss = 6.2404e-04, PNorm = 55.1379, GNorm = 1.1621, lr_0 = 1.0804e-04
Loss = 5.5470e-04, PNorm = 55.1416, GNorm = 2.0157, lr_0 = 1.0804e-04
Loss = 6.8209e-04, PNorm = 55.1454, GNorm = 5.8614, lr_0 = 1.0804e-04
Loss = 9.4775e-04, PNorm = 55.1480, GNorm = 5.7393, lr_0 = 1.0804e-04
Loss = 8.5395e-04, PNorm = 55.1517, GNorm = 2.5348, lr_0 = 1.0804e-04
Loss = 7.5662e-04, PNorm = 55.1564, GNorm = 2.0154, lr_0 = 1.0804e-04
Validation rmse logD = 0.521630
Validation R2 logD = 0.815459
Epoch 61
Train function
Loss = 1.0167e-03, PNorm = 55.1614, GNorm = 5.5507, lr_0 = 1.0804e-04
Loss = 7.0067e-04, PNorm = 55.1650, GNorm = 5.6700, lr_0 = 1.0804e-04
Loss = 5.8945e-04, PNorm = 55.1690, GNorm = 1.4748, lr_0 = 1.0804e-04
Loss = 5.8750e-04, PNorm = 55.1724, GNorm = 3.1793, lr_0 = 1.0804e-04
Loss = 5.9729e-04, PNorm = 55.1756, GNorm = 1.3462, lr_0 = 1.0804e-04
Loss = 6.4942e-04, PNorm = 55.1798, GNorm = 0.7603, lr_0 = 1.0804e-04
Validation rmse logD = 0.537483
Validation R2 logD = 0.804072
Epoch 62
Train function
Loss = 7.3284e-04, PNorm = 55.1833, GNorm = 3.2025, lr_0 = 1.0804e-04
Loss = 4.7393e-04, PNorm = 55.1867, GNorm = 1.8292, lr_0 = 1.0804e-04
Loss = 6.3396e-04, PNorm = 55.1914, GNorm = 1.4689, lr_0 = 1.0804e-04
Loss = 5.0907e-04, PNorm = 55.1950, GNorm = 1.0804, lr_0 = 1.0804e-04
Loss = 7.4187e-04, PNorm = 55.1988, GNorm = 4.4197, lr_0 = 1.0804e-04
Validation rmse logD = 0.564704
Validation R2 logD = 0.783724
Epoch 63
Train function
Loss = 7.5139e-04, PNorm = 55.2025, GNorm = 5.6208, lr_0 = 1.0804e-04
Loss = 6.9803e-04, PNorm = 55.2056, GNorm = 2.9235, lr_0 = 1.0804e-04
Loss = 6.9382e-04, PNorm = 55.2087, GNorm = 1.0048, lr_0 = 1.0804e-04
Loss = 7.0725e-04, PNorm = 55.2128, GNorm = 1.0069, lr_0 = 1.0804e-04
Loss = 6.0789e-04, PNorm = 55.2173, GNorm = 2.4878, lr_0 = 1.0804e-04
Loss = 9.6662e-04, PNorm = 55.2206, GNorm = 6.5397, lr_0 = 1.0804e-04
Validation rmse logD = 0.533154
Validation R2 logD = 0.807215
Epoch 64
Train function
Loss = 6.8329e-04, PNorm = 55.2261, GNorm = 1.2147, lr_0 = 1.0804e-04
Loss = 5.6643e-04, PNorm = 55.2320, GNorm = 1.8427, lr_0 = 1.0804e-04
Loss = 7.0907e-04, PNorm = 55.2370, GNorm = 5.2209, lr_0 = 1.0804e-04
Loss = 5.6738e-04, PNorm = 55.2400, GNorm = 0.7687, lr_0 = 1.0804e-04
Loss = 5.1842e-04, PNorm = 55.2430, GNorm = 2.3041, lr_0 = 1.0804e-04
Loss = 5.4838e-04, PNorm = 55.2461, GNorm = 4.3912, lr_0 = 1.0804e-04
Validation rmse logD = 0.534511
Validation R2 logD = 0.806233
Epoch 65
Train function
Loss = 6.5685e-04, PNorm = 55.2500, GNorm = 5.2986, lr_0 = 1.0804e-04
Loss = 6.7282e-04, PNorm = 55.2537, GNorm = 4.3664, lr_0 = 1.0804e-04
Loss = 7.6497e-04, PNorm = 55.2581, GNorm = 4.6457, lr_0 = 1.0804e-04
Loss = 8.9113e-04, PNorm = 55.2624, GNorm = 6.3999, lr_0 = 1.0804e-04
Loss = 9.1626e-04, PNorm = 55.2661, GNorm = 2.9768, lr_0 = 1.0804e-04
Validation rmse logD = 0.547273
Validation R2 logD = 0.796869
Epoch 66
Train function
Loss = 1.0529e-03, PNorm = 55.2703, GNorm = 6.2015, lr_0 = 1.0804e-04
Loss = 8.3234e-04, PNorm = 55.2743, GNorm = 5.0003, lr_0 = 1.0804e-04
Loss = 6.9441e-04, PNorm = 55.2785, GNorm = 1.3841, lr_0 = 1.0804e-04
Loss = 7.8039e-04, PNorm = 55.2825, GNorm = 1.1416, lr_0 = 1.0804e-04
Loss = 7.0255e-04, PNorm = 55.2842, GNorm = 1.4406, lr_0 = 1.0804e-04
Loss = 5.7906e-04, PNorm = 55.2877, GNorm = 3.3941, lr_0 = 1.0804e-04
Validation rmse logD = 0.537132
Validation R2 logD = 0.804327
Epoch 67
Train function
Loss = 5.9434e-04, PNorm = 55.2921, GNorm = 1.1182, lr_0 = 1.0804e-04
Loss = 4.4613e-04, PNorm = 55.2966, GNorm = 1.4353, lr_0 = 1.0804e-04
Loss = 6.4898e-04, PNorm = 55.2996, GNorm = 3.4214, lr_0 = 1.0804e-04
Loss = 6.6214e-04, PNorm = 55.3031, GNorm = 2.3013, lr_0 = 1.0804e-04
Loss = 5.3799e-04, PNorm = 55.3058, GNorm = 1.3835, lr_0 = 1.0804e-04
Loss = 5.7538e-04, PNorm = 55.3097, GNorm = 5.5335, lr_0 = 1.0804e-04
Validation rmse logD = 0.527706
Validation R2 logD = 0.811135
Epoch 68
Train function
Loss = 6.4468e-04, PNorm = 55.3135, GNorm = 2.3922, lr_0 = 1.0804e-04
Loss = 8.5448e-04, PNorm = 55.3149, GNorm = 2.7202, lr_0 = 1.0804e-04
Loss = 7.5073e-04, PNorm = 55.3190, GNorm = 3.6312, lr_0 = 1.0804e-04
Loss = 7.5621e-04, PNorm = 55.3238, GNorm = 2.0418, lr_0 = 1.0804e-04
Loss = 7.2218e-04, PNorm = 55.3275, GNorm = 5.9646, lr_0 = 1.0804e-04
Validation rmse logD = 0.538176
Validation R2 logD = 0.803566
Epoch 69
Train function
Loss = 5.4606e-04, PNorm = 55.3327, GNorm = 3.2620, lr_0 = 1.0804e-04
Loss = 4.6355e-04, PNorm = 55.3374, GNorm = 1.9617, lr_0 = 1.0804e-04
Loss = 5.9507e-04, PNorm = 55.3410, GNorm = 1.7681, lr_0 = 1.0804e-04
Loss = 4.8207e-04, PNorm = 55.3445, GNorm = 2.6744, lr_0 = 1.0804e-04
Loss = 5.9836e-04, PNorm = 55.3482, GNorm = 2.4841, lr_0 = 1.0804e-04
Loss = 4.4092e-04, PNorm = 55.3511, GNorm = 1.3026, lr_0 = 1.0804e-04
Validation rmse logD = 0.531999
Validation R2 logD = 0.808050
Epoch 70
Train function
Loss = 3.7842e-04, PNorm = 55.3539, GNorm = 1.2208, lr_0 = 1.0804e-04
Loss = 4.5298e-04, PNorm = 55.3574, GNorm = 1.1837, lr_0 = 1.0804e-04
Loss = 6.7679e-04, PNorm = 55.3608, GNorm = 2.4891, lr_0 = 1.0804e-04
Loss = 4.5649e-04, PNorm = 55.3646, GNorm = 2.7411, lr_0 = 1.0804e-04
Loss = 4.5154e-04, PNorm = 55.3673, GNorm = 0.7971, lr_0 = 1.0804e-04
Loss = 4.1786e-04, PNorm = 55.3704, GNorm = 0.6958, lr_0 = 1.0804e-04
Validation rmse logD = 0.532299
Validation R2 logD = 0.807833
Epoch 71
Train function
Loss = 3.9475e-04, PNorm = 55.3743, GNorm = 1.6506, lr_0 = 1.0804e-04
Loss = 3.9298e-04, PNorm = 55.3776, GNorm = 0.8950, lr_0 = 1.0804e-04
Loss = 4.6031e-04, PNorm = 55.3796, GNorm = 2.0409, lr_0 = 1.0804e-04
Loss = 5.3518e-04, PNorm = 55.3830, GNorm = 2.8705, lr_0 = 1.0804e-04
Loss = 7.6167e-04, PNorm = 55.3844, GNorm = 1.8146, lr_0 = 1.0804e-04
Validation rmse logD = 0.528353
Validation R2 logD = 0.810672
Epoch 72
Train function
Loss = 4.0821e-04, PNorm = 55.3885, GNorm = 0.9541, lr_0 = 1.0804e-04
Loss = 5.5307e-04, PNorm = 55.3921, GNorm = 0.7790, lr_0 = 1.0804e-04
Loss = 5.6733e-04, PNorm = 55.3949, GNorm = 5.1541, lr_0 = 1.0804e-04
Loss = 7.7746e-04, PNorm = 55.3989, GNorm = 5.5673, lr_0 = 1.0804e-04
Loss = 8.4452e-04, PNorm = 55.4028, GNorm = 4.0366, lr_0 = 1.0804e-04
Loss = 9.5043e-04, PNorm = 55.4083, GNorm = 1.0757, lr_0 = 1.0804e-04
Validation rmse logD = 0.525131
Validation R2 logD = 0.812974
Epoch 73
Train function
Loss = 6.6729e-04, PNorm = 55.4127, GNorm = 2.6436, lr_0 = 1.0804e-04
Loss = 6.2940e-04, PNorm = 55.4179, GNorm = 4.4701, lr_0 = 1.0804e-04
Loss = 8.0178e-04, PNorm = 55.4211, GNorm = 5.1244, lr_0 = 1.0804e-04
Loss = 6.3515e-04, PNorm = 55.4234, GNorm = 1.5961, lr_0 = 1.0804e-04
Loss = 6.0100e-04, PNorm = 55.4279, GNorm = 1.0730, lr_0 = 1.0804e-04
Loss = 5.2418e-04, PNorm = 55.4320, GNorm = 3.6470, lr_0 = 1.0804e-04
Validation rmse logD = 0.532503
Validation R2 logD = 0.807686
Epoch 74
Train function
Loss = 3.7698e-04, PNorm = 55.4350, GNorm = 1.9525, lr_0 = 1.0804e-04
Loss = 3.4485e-04, PNorm = 55.4380, GNorm = 3.5699, lr_0 = 1.0804e-04
Loss = 4.2739e-04, PNorm = 55.4410, GNorm = 2.1491, lr_0 = 1.0804e-04
Loss = 3.3825e-04, PNorm = 55.4437, GNorm = 0.9162, lr_0 = 1.0804e-04
Loss = 5.8486e-04, PNorm = 55.4484, GNorm = 0.8221, lr_0 = 1.0804e-04
Validation rmse logD = 0.528506
Validation R2 logD = 0.810562
Epoch 75
Train function
Loss = 3.9262e-04, PNorm = 55.4517, GNorm = 1.1180, lr_0 = 1.0804e-04
Loss = 5.1063e-04, PNorm = 55.4556, GNorm = 1.2929, lr_0 = 1.0804e-04
Loss = 4.5850e-04, PNorm = 55.4572, GNorm = 2.7269, lr_0 = 1.0804e-04
Loss = 4.0679e-04, PNorm = 55.4607, GNorm = 0.7068, lr_0 = 1.0804e-04
Loss = 3.9426e-04, PNorm = 55.4636, GNorm = 1.0653, lr_0 = 1.0804e-04
Loss = 3.9836e-04, PNorm = 55.4665, GNorm = 3.3626, lr_0 = 1.0804e-04
Validation rmse logD = 0.533999
Validation R2 logD = 0.806604
Epoch 76
Train function
Loss = 6.1753e-04, PNorm = 55.4682, GNorm = 1.6155, lr_0 = 1.0804e-04
Loss = 3.9311e-04, PNorm = 55.4714, GNorm = 1.1120, lr_0 = 1.0804e-04
Loss = 5.6635e-04, PNorm = 55.4752, GNorm = 3.8503, lr_0 = 1.0804e-04
Loss = 7.3618e-04, PNorm = 55.4784, GNorm = 1.3871, lr_0 = 1.0804e-04
Loss = 5.2122e-04, PNorm = 55.4835, GNorm = 1.2655, lr_0 = 1.0804e-04
Loss = 4.8470e-04, PNorm = 55.4885, GNorm = 0.9517, lr_0 = 1.0804e-04
Validation rmse logD = 0.522013
Validation R2 logD = 0.815188
Epoch 77
Train function
Loss = 3.0621e-04, PNorm = 55.4922, GNorm = 2.2490, lr_0 = 1.0804e-04
Loss = 5.3528e-04, PNorm = 55.4945, GNorm = 3.4625, lr_0 = 1.0804e-04
Loss = 5.0803e-04, PNorm = 55.4976, GNorm = 3.2608, lr_0 = 1.0804e-04
Loss = 5.9698e-04, PNorm = 55.4997, GNorm = 0.7674, lr_0 = 1.0804e-04
Loss = 6.9560e-04, PNorm = 55.5028, GNorm = 1.8344, lr_0 = 1.0804e-04
Validation rmse logD = 0.526622
Validation R2 logD = 0.811910
Epoch 78
Train function
Loss = 3.8619e-04, PNorm = 55.5066, GNorm = 1.1619, lr_0 = 1.0804e-04
Loss = 4.5656e-04, PNorm = 55.5106, GNorm = 4.1910, lr_0 = 1.0804e-04
Loss = 3.8935e-04, PNorm = 55.5145, GNorm = 1.0068, lr_0 = 1.0804e-04
Loss = 4.6742e-04, PNorm = 55.5159, GNorm = 1.4444, lr_0 = 1.0804e-04
Loss = 4.4870e-04, PNorm = 55.5180, GNorm = 3.1434, lr_0 = 1.0804e-04
Loss = 4.8441e-04, PNorm = 55.5220, GNorm = 0.7768, lr_0 = 1.0804e-04
Validation rmse logD = 0.521042
Validation R2 logD = 0.815875
Epoch 79
Train function
Loss = 1.7482e-04, PNorm = 55.5253, GNorm = 0.7209, lr_0 = 1.0804e-04
Loss = 3.8639e-04, PNorm = 55.5286, GNorm = 0.6711, lr_0 = 1.0804e-04
Loss = 5.2515e-04, PNorm = 55.5312, GNorm = 3.4776, lr_0 = 1.0804e-04
Loss = 5.0542e-04, PNorm = 55.5339, GNorm = 2.8236, lr_0 = 1.0804e-04
Loss = 4.2102e-04, PNorm = 55.5370, GNorm = 0.9727, lr_0 = 1.0804e-04
Loss = 5.5465e-04, PNorm = 55.5393, GNorm = 2.6181, lr_0 = 1.0804e-04
Validation rmse logD = 0.522426
Validation R2 logD = 0.814896
Epoch 80
Train function
Loss = 3.7909e-04, PNorm = 55.5441, GNorm = 2.4939, lr_0 = 1.0804e-04
Loss = 3.5170e-04, PNorm = 55.5467, GNorm = 0.9546, lr_0 = 1.0804e-04
Loss = 3.5340e-04, PNorm = 55.5498, GNorm = 0.9009, lr_0 = 1.0804e-04
Loss = 4.6642e-04, PNorm = 55.5524, GNorm = 2.4489, lr_0 = 1.0804e-04
Loss = 5.6277e-04, PNorm = 55.5551, GNorm = 4.0686, lr_0 = 1.0804e-04
Validation rmse logD = 0.524212
Validation R2 logD = 0.813628
Epoch 81
Train function
Loss = 3.1473e-04, PNorm = 55.5591, GNorm = 2.2674, lr_0 = 1.0804e-04
Loss = 7.3517e-04, PNorm = 55.5623, GNorm = 2.4228, lr_0 = 1.0804e-04
Loss = 8.5277e-04, PNorm = 55.5662, GNorm = 6.9628, lr_0 = 1.0804e-04
Loss = 8.0590e-04, PNorm = 55.5701, GNorm = 6.0333, lr_0 = 1.0804e-04
Loss = 5.9145e-04, PNorm = 55.5749, GNorm = 3.4881, lr_0 = 1.0804e-04
Loss = 5.0882e-04, PNorm = 55.5790, GNorm = 1.0309, lr_0 = 1.0804e-04
Validation rmse logD = 0.539489
Validation R2 logD = 0.802607
Epoch 82
Train function
Loss = 3.9863e-04, PNorm = 55.5827, GNorm = 2.1964, lr_0 = 1.0804e-04
Loss = 4.6458e-04, PNorm = 55.5866, GNorm = 1.2251, lr_0 = 1.0804e-04
Loss = 4.6400e-04, PNorm = 55.5898, GNorm = 1.4633, lr_0 = 1.0804e-04
Loss = 3.3600e-04, PNorm = 55.5925, GNorm = 2.3550, lr_0 = 1.0804e-04
Loss = 3.8362e-04, PNorm = 55.5959, GNorm = 1.5306, lr_0 = 1.0804e-04
Loss = 4.0316e-04, PNorm = 55.5991, GNorm = 1.0029, lr_0 = 1.0804e-04
Validation rmse logD = 0.524967
Validation R2 logD = 0.813090
Epoch 83
Train function
Loss = 2.6205e-04, PNorm = 55.6012, GNorm = 0.5854, lr_0 = 1.0804e-04
Loss = 3.3277e-04, PNorm = 55.6039, GNorm = 1.4177, lr_0 = 1.0804e-04
Loss = 3.0074e-04, PNorm = 55.6055, GNorm = 1.7600, lr_0 = 1.0804e-04
Loss = 5.1097e-04, PNorm = 55.6082, GNorm = 1.5103, lr_0 = 1.0804e-04
Loss = 4.9561e-04, PNorm = 55.6114, GNorm = 3.8775, lr_0 = 1.0804e-04
Validation rmse logD = 0.526783
Validation R2 logD = 0.811795
Epoch 84
Train function
Loss = 3.2012e-04, PNorm = 55.6146, GNorm = 1.3405, lr_0 = 1.0804e-04
Loss = 3.0236e-04, PNorm = 55.6173, GNorm = 2.0437, lr_0 = 1.0804e-04
Loss = 3.8847e-04, PNorm = 55.6210, GNorm = 4.0188, lr_0 = 1.0804e-04
Loss = 4.9156e-04, PNorm = 55.6240, GNorm = 3.0802, lr_0 = 1.0804e-04
Loss = 6.8019e-04, PNorm = 55.6246, GNorm = 0.8840, lr_0 = 1.0804e-04
Loss = 4.8623e-04, PNorm = 55.6270, GNorm = 3.6319, lr_0 = 1.0804e-04
Validation rmse logD = 0.536370
Validation R2 logD = 0.804882
Epoch 85
Train function
Loss = 5.1244e-04, PNorm = 55.6311, GNorm = 2.6264, lr_0 = 1.0804e-04
Loss = 4.6000e-04, PNorm = 55.6351, GNorm = 1.4851, lr_0 = 1.0804e-04
Loss = 5.2552e-04, PNorm = 55.6391, GNorm = 2.0347, lr_0 = 1.0804e-04
Loss = 8.0735e-04, PNorm = 55.6414, GNorm = 7.1747, lr_0 = 1.0804e-04
Loss = 7.4661e-04, PNorm = 55.6444, GNorm = 5.5256, lr_0 = 1.0804e-04
Loss = 5.3483e-04, PNorm = 55.6499, GNorm = 0.7839, lr_0 = 1.0804e-04
Validation rmse logD = 0.575546
Validation R2 logD = 0.775339
Epoch 86
Train function
Loss = 7.6613e-04, PNorm = 55.6536, GNorm = 4.0575, lr_0 = 1.0804e-04
Loss = 5.4481e-04, PNorm = 55.6572, GNorm = 4.1517, lr_0 = 1.0804e-04
Loss = 4.4882e-04, PNorm = 55.6627, GNorm = 0.9535, lr_0 = 1.0804e-04
Loss = 4.3494e-04, PNorm = 55.6657, GNorm = 1.0117, lr_0 = 1.0804e-04
Loss = 4.8708e-04, PNorm = 55.6691, GNorm = 1.9031, lr_0 = 1.0804e-04
Validation rmse logD = 0.521904
Validation R2 logD = 0.815265
Epoch 87
Train function
Loss = 1.4648e-04, PNorm = 55.6723, GNorm = 0.7201, lr_0 = 1.0804e-04
Loss = 3.8216e-04, PNorm = 55.6769, GNorm = 3.0176, lr_0 = 1.0804e-04
Loss = 3.2064e-04, PNorm = 55.6809, GNorm = 1.1674, lr_0 = 1.0804e-04
Loss = 3.2506e-04, PNorm = 55.6836, GNorm = 1.7871, lr_0 = 1.0804e-04
Loss = 4.2631e-04, PNorm = 55.6856, GNorm = 4.9850, lr_0 = 1.0804e-04
Loss = 5.4739e-04, PNorm = 55.6875, GNorm = 3.5032, lr_0 = 1.0804e-04
Validation rmse logD = 0.520854
Validation R2 logD = 0.816008
Epoch 88
Train function
Loss = 3.2551e-04, PNorm = 55.6902, GNorm = 1.4203, lr_0 = 1.0804e-04
Loss = 3.3601e-04, PNorm = 55.6935, GNorm = 0.9986, lr_0 = 1.0804e-04
Loss = 3.1551e-04, PNorm = 55.6963, GNorm = 0.7964, lr_0 = 1.0804e-04
Loss = 2.9680e-04, PNorm = 55.7003, GNorm = 1.3602, lr_0 = 1.0804e-04
Loss = 4.5446e-04, PNorm = 55.7025, GNorm = 2.9258, lr_0 = 1.0804e-04
Loss = 3.6721e-04, PNorm = 55.7050, GNorm = 3.3697, lr_0 = 1.0804e-04
Validation rmse logD = 0.553924
Validation R2 logD = 0.791902
Epoch 89
Train function
Loss = 4.6562e-04, PNorm = 55.7078, GNorm = 1.1093, lr_0 = 1.0804e-04
Loss = 4.8218e-04, PNorm = 55.7106, GNorm = 1.7200, lr_0 = 1.0804e-04
Loss = 5.5787e-04, PNorm = 55.7138, GNorm = 0.9390, lr_0 = 1.0804e-04
Loss = 4.9638e-04, PNorm = 55.7168, GNorm = 3.8888, lr_0 = 1.0804e-04
Loss = 3.4857e-04, PNorm = 55.7198, GNorm = 1.0642, lr_0 = 1.0804e-04
Validation rmse logD = 0.519758
Validation R2 logD = 0.816781
Epoch 90
Train function
Loss = 3.6072e-04, PNorm = 55.7226, GNorm = 0.9463, lr_0 = 1.0804e-04
Loss = 2.8045e-04, PNorm = 55.7255, GNorm = 1.5950, lr_0 = 1.0804e-04
Loss = 3.6173e-04, PNorm = 55.7280, GNorm = 1.0305, lr_0 = 1.0804e-04
Loss = 3.1952e-04, PNorm = 55.7318, GNorm = 1.5628, lr_0 = 1.0804e-04
Loss = 2.5769e-04, PNorm = 55.7353, GNorm = 1.5352, lr_0 = 1.0804e-04
Loss = 3.2964e-04, PNorm = 55.7379, GNorm = 0.5417, lr_0 = 1.0804e-04
Validation rmse logD = 0.519916
Validation R2 logD = 0.816670
Epoch 91
Train function
Loss = 1.9242e-04, PNorm = 55.7410, GNorm = 0.8869, lr_0 = 1.0804e-04
Loss = 2.7477e-04, PNorm = 55.7425, GNorm = 1.7971, lr_0 = 1.0804e-04
Loss = 2.4424e-04, PNorm = 55.7437, GNorm = 0.6817, lr_0 = 1.0804e-04
Loss = 3.8225e-04, PNorm = 55.7454, GNorm = 1.0637, lr_0 = 1.0804e-04
Loss = 3.3626e-04, PNorm = 55.7476, GNorm = 1.5692, lr_0 = 1.0804e-04
Loss = 3.8198e-04, PNorm = 55.7496, GNorm = 3.8937, lr_0 = 1.0804e-04
Validation rmse logD = 0.523650
Validation R2 logD = 0.814027
Epoch 92
Train function
Loss = 2.6858e-04, PNorm = 55.7515, GNorm = 0.7026, lr_0 = 1.0804e-04
Loss = 2.8928e-04, PNorm = 55.7553, GNorm = 1.7482, lr_0 = 1.0804e-04
Loss = 2.5226e-04, PNorm = 55.7574, GNorm = 0.6249, lr_0 = 1.0804e-04
Loss = 3.5677e-04, PNorm = 55.7597, GNorm = 1.5046, lr_0 = 1.0804e-04
Loss = 2.9288e-04, PNorm = 55.7626, GNorm = 1.9752, lr_0 = 1.0804e-04
Validation rmse logD = 0.523343
Validation R2 logD = 0.814245
Epoch 93
Train function
Loss = 1.7147e-04, PNorm = 55.7648, GNorm = 1.1650, lr_0 = 1.0804e-04
Loss = 2.2638e-04, PNorm = 55.7667, GNorm = 1.1932, lr_0 = 1.0804e-04
Loss = 2.7741e-04, PNorm = 55.7686, GNorm = 1.0884, lr_0 = 1.0804e-04
Loss = 2.6327e-04, PNorm = 55.7705, GNorm = 0.7452, lr_0 = 1.0804e-04
Loss = 2.6590e-04, PNorm = 55.7737, GNorm = 0.9371, lr_0 = 1.0804e-04
Loss = 2.8425e-04, PNorm = 55.7755, GNorm = 0.9420, lr_0 = 1.0804e-04
Validation rmse logD = 0.524233
Validation R2 logD = 0.813613
Epoch 94
Train function
Loss = 2.4558e-04, PNorm = 55.7786, GNorm = 1.1196, lr_0 = 1.0804e-04
Loss = 2.3959e-04, PNorm = 55.7817, GNorm = 0.9290, lr_0 = 1.0804e-04
Loss = 2.5181e-04, PNorm = 55.7838, GNorm = 2.1390, lr_0 = 1.0804e-04
Loss = 2.5156e-04, PNorm = 55.7864, GNorm = 0.6405, lr_0 = 1.0804e-04
Loss = 1.8695e-04, PNorm = 55.7877, GNorm = 0.5809, lr_0 = 1.0804e-04
Loss = 4.6451e-04, PNorm = 55.7888, GNorm = 3.3410, lr_0 = 1.0804e-04
Validation rmse logD = 0.525482
Validation R2 logD = 0.812724
Epoch 95
Train function
Loss = 2.6483e-04, PNorm = 55.7923, GNorm = 1.2089, lr_0 = 1.0804e-04
Loss = 3.2588e-04, PNorm = 55.7944, GNorm = 2.4093, lr_0 = 1.0804e-04
Loss = 4.0300e-04, PNorm = 55.7978, GNorm = 3.6393, lr_0 = 1.0804e-04
Loss = 4.9312e-04, PNorm = 55.8005, GNorm = 3.1657, lr_0 = 1.0804e-04
Loss = 3.2906e-04, PNorm = 55.8039, GNorm = 2.6461, lr_0 = 1.0804e-04
Validation rmse logD = 0.520304
Validation R2 logD = 0.816397
Epoch 96
Train function
Loss = 3.9208e-04, PNorm = 55.8074, GNorm = 1.3605, lr_0 = 1.0804e-04
Loss = 3.4303e-04, PNorm = 55.8089, GNorm = 0.6915, lr_0 = 1.0804e-04
Loss = 2.7986e-04, PNorm = 55.8109, GNorm = 0.5331, lr_0 = 1.0804e-04
Loss = 2.5866e-04, PNorm = 55.8134, GNorm = 1.8070, lr_0 = 1.0804e-04
Loss = 2.5281e-04, PNorm = 55.8149, GNorm = 0.4748, lr_0 = 1.0804e-04
Loss = 2.7327e-04, PNorm = 55.8167, GNorm = 0.7677, lr_0 = 1.0804e-04
Validation rmse logD = 0.529068
Validation R2 logD = 0.810159
Epoch 97
Train function
Loss = 3.6728e-04, PNorm = 55.8194, GNorm = 0.4294, lr_0 = 1.0804e-04
Loss = 3.6655e-04, PNorm = 55.8211, GNorm = 5.3759, lr_0 = 1.0804e-04
Loss = 3.7278e-04, PNorm = 55.8232, GNorm = 1.5122, lr_0 = 1.0804e-04
Loss = 3.5912e-04, PNorm = 55.8264, GNorm = 1.3469, lr_0 = 1.0804e-04
Loss = 2.6101e-04, PNorm = 55.8305, GNorm = 2.9895, lr_0 = 1.0804e-04
Loss = 2.2261e-04, PNorm = 55.8341, GNorm = 1.0602, lr_0 = 1.0804e-04
Validation rmse logD = 0.534983
Validation R2 logD = 0.805890
Epoch 98
Train function
Loss = 1.8077e-04, PNorm = 55.8361, GNorm = 0.8781, lr_0 = 1.0804e-04
Loss = 3.1078e-04, PNorm = 55.8380, GNorm = 1.9672, lr_0 = 1.0804e-04
Loss = 2.8818e-04, PNorm = 55.8404, GNorm = 0.4958, lr_0 = 1.0804e-04
Loss = 2.4155e-04, PNorm = 55.8428, GNorm = 0.8863, lr_0 = 1.0804e-04
Loss = 3.0568e-04, PNorm = 55.8450, GNorm = 1.1843, lr_0 = 1.0804e-04
Validation rmse logD = 0.527959
Validation R2 logD = 0.810954
Epoch 99
Train function
Loss = 3.0299e-04, PNorm = 55.8473, GNorm = 2.2167, lr_0 = 1.0804e-04
Loss = 2.6056e-04, PNorm = 55.8492, GNorm = 3.9786, lr_0 = 1.0804e-04
Loss = 3.0033e-04, PNorm = 55.8509, GNorm = 0.7370, lr_0 = 1.0804e-04
Loss = 4.3954e-04, PNorm = 55.8540, GNorm = 2.9317, lr_0 = 1.0804e-04
Loss = 2.6809e-04, PNorm = 55.8581, GNorm = 1.1949, lr_0 = 1.0804e-04
Loss = 2.9503e-04, PNorm = 55.8602, GNorm = 2.6063, lr_0 = 1.0804e-04
Validation rmse logD = 0.520382
Validation R2 logD = 0.816341
Model 0 best validation rmse = 0.519758 on epoch 89
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.555350
Model 0 test R2 logD = 0.790018
Ensemble test rmse  logD= 0.555350
Ensemble test R2  logD= 0.790018
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 1.8856e-02, PNorm = 52.9137, GNorm = 3.0662, lr_0 = 1.0804e-04
Loss = 1.6946e-02, PNorm = 52.9178, GNorm = 2.2094, lr_0 = 1.0804e-04
Loss = 1.7392e-02, PNorm = 52.9214, GNorm = 5.0479, lr_0 = 1.0804e-04
Loss = 1.7064e-02, PNorm = 52.9241, GNorm = 9.0748, lr_0 = 1.0804e-04
Loss = 1.5130e-02, PNorm = 52.9271, GNorm = 1.8464, lr_0 = 1.0804e-04
Validation rmse logD = 1.079251
Validation R2 logD = 0.249938
Epoch 1
Train function
Loss = 1.1675e-02, PNorm = 52.9302, GNorm = 2.6826, lr_0 = 1.0804e-04
Loss = 1.4028e-02, PNorm = 52.9338, GNorm = 7.2533, lr_0 = 1.0804e-04
Loss = 1.3694e-02, PNorm = 52.9381, GNorm = 7.2263, lr_0 = 1.0804e-04
Loss = 1.3963e-02, PNorm = 52.9432, GNorm = 2.9481, lr_0 = 1.0804e-04
Loss = 1.3567e-02, PNorm = 52.9488, GNorm = 3.1451, lr_0 = 1.0804e-04
Loss = 1.2745e-02, PNorm = 52.9546, GNorm = 1.8435, lr_0 = 1.0804e-04
Validation rmse logD = 1.019522
Validation R2 logD = 0.330662
Epoch 2
Train function
Loss = 1.3502e-02, PNorm = 52.9611, GNorm = 2.7891, lr_0 = 1.0804e-04
Loss = 1.3207e-02, PNorm = 52.9675, GNorm = 3.9238, lr_0 = 1.0804e-04
Loss = 1.1280e-02, PNorm = 52.9743, GNorm = 2.3413, lr_0 = 1.0804e-04
Loss = 1.1894e-02, PNorm = 52.9815, GNorm = 1.9976, lr_0 = 1.0804e-04
Loss = 1.1069e-02, PNorm = 52.9899, GNorm = 3.0427, lr_0 = 1.0804e-04
Validation rmse logD = 0.940918
Validation R2 logD = 0.429893
Epoch 3
Train function
Loss = 1.3452e-02, PNorm = 52.9985, GNorm = 1.9386, lr_0 = 1.0804e-04
Loss = 9.9483e-03, PNorm = 53.0064, GNorm = 1.8754, lr_0 = 1.0804e-04
Loss = 1.0125e-02, PNorm = 53.0142, GNorm = 7.2118, lr_0 = 1.0804e-04
Loss = 1.0824e-02, PNorm = 53.0232, GNorm = 3.9306, lr_0 = 1.0804e-04
Loss = 1.1771e-02, PNorm = 53.0326, GNorm = 10.1553, lr_0 = 1.0804e-04
Loss = 9.7032e-03, PNorm = 53.0414, GNorm = 2.0950, lr_0 = 1.0804e-04
Validation rmse logD = 0.888283
Validation R2 logD = 0.491894
Epoch 4
Train function
Loss = 9.2081e-03, PNorm = 53.0480, GNorm = 1.9798, lr_0 = 1.0804e-04
Loss = 8.7427e-03, PNorm = 53.0570, GNorm = 5.3617, lr_0 = 1.0804e-04
Loss = 8.8741e-03, PNorm = 53.0691, GNorm = 3.4268, lr_0 = 1.0804e-04
Loss = 9.9310e-03, PNorm = 53.0773, GNorm = 3.2926, lr_0 = 1.0804e-04
Loss = 9.7182e-03, PNorm = 53.0857, GNorm = 3.0332, lr_0 = 1.0804e-04
Loss = 9.4731e-03, PNorm = 53.0951, GNorm = 4.2940, lr_0 = 1.0804e-04
Validation rmse logD = 0.855245
Validation R2 logD = 0.528986
Epoch 5
Train function
Loss = 8.7747e-03, PNorm = 53.1064, GNorm = 4.9484, lr_0 = 1.0804e-04
Loss = 8.7937e-03, PNorm = 53.1163, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 1.0679e-02, PNorm = 53.1249, GNorm = 8.3002, lr_0 = 1.0804e-04
Loss = 8.3885e-03, PNorm = 53.1331, GNorm = 1.7461, lr_0 = 1.0804e-04
Loss = 8.3168e-03, PNorm = 53.1426, GNorm = 1.7142, lr_0 = 1.0804e-04
Validation rmse logD = 0.818964
Validation R2 logD = 0.568101
Epoch 6
Train function
Loss = 7.8727e-03, PNorm = 53.1544, GNorm = 5.8681, lr_0 = 1.0804e-04
Loss = 7.0385e-03, PNorm = 53.1662, GNorm = 5.1814, lr_0 = 1.0804e-04
Loss = 7.8380e-03, PNorm = 53.1784, GNorm = 7.1594, lr_0 = 1.0804e-04
Loss = 8.4393e-03, PNorm = 53.1896, GNorm = 5.5202, lr_0 = 1.0804e-04
Loss = 9.9087e-03, PNorm = 53.1961, GNorm = 2.9740, lr_0 = 1.0804e-04
Loss = 8.2476e-03, PNorm = 53.2057, GNorm = 3.9510, lr_0 = 1.0804e-04
Validation rmse logD = 0.810037
Validation R2 logD = 0.577465
Epoch 7
Train function
Loss = 8.1421e-03, PNorm = 53.2155, GNorm = 2.1056, lr_0 = 1.0804e-04
Loss = 7.5610e-03, PNorm = 53.2260, GNorm = 4.8445, lr_0 = 1.0804e-04
Loss = 6.5202e-03, PNorm = 53.2363, GNorm = 1.9267, lr_0 = 1.0804e-04
Loss = 7.0200e-03, PNorm = 53.2462, GNorm = 4.3110, lr_0 = 1.0804e-04
Loss = 6.6507e-03, PNorm = 53.2571, GNorm = 1.3608, lr_0 = 1.0804e-04
Loss = 6.5652e-03, PNorm = 53.2676, GNorm = 4.2661, lr_0 = 1.0804e-04
Validation rmse logD = 0.823244
Validation R2 logD = 0.563575
Epoch 8
Train function
Loss = 7.0625e-03, PNorm = 53.2767, GNorm = 9.2397, lr_0 = 1.0804e-04
Loss = 7.3472e-03, PNorm = 53.2859, GNorm = 3.4229, lr_0 = 1.0804e-04
Loss = 6.9351e-03, PNorm = 53.2962, GNorm = 13.2792, lr_0 = 1.0804e-04
Loss = 6.7009e-03, PNorm = 53.3057, GNorm = 1.9284, lr_0 = 1.0804e-04
Loss = 6.6364e-03, PNorm = 53.3169, GNorm = 4.8414, lr_0 = 1.0804e-04
Validation rmse logD = 0.731043
Validation R2 logD = 0.655857
Epoch 9
Train function
Loss = 5.6566e-03, PNorm = 53.3293, GNorm = 2.6316, lr_0 = 1.0804e-04
Loss = 6.5111e-03, PNorm = 53.3402, GNorm = 1.7981, lr_0 = 1.0804e-04
Loss = 5.8410e-03, PNorm = 53.3508, GNorm = 1.7011, lr_0 = 1.0804e-04
Loss = 6.5735e-03, PNorm = 53.3590, GNorm = 5.1968, lr_0 = 1.0804e-04
Loss = 5.9984e-03, PNorm = 53.3694, GNorm = 2.0504, lr_0 = 1.0804e-04
Loss = 6.1052e-03, PNorm = 53.3805, GNorm = 6.2882, lr_0 = 1.0804e-04
Validation rmse logD = 0.722323
Validation R2 logD = 0.664018
Epoch 10
Train function
Loss = 6.4461e-03, PNorm = 53.3892, GNorm = 2.6246, lr_0 = 1.0804e-04
Loss = 6.0017e-03, PNorm = 53.3998, GNorm = 6.0184, lr_0 = 1.0804e-04
Loss = 5.8383e-03, PNorm = 53.4096, GNorm = 3.7141, lr_0 = 1.0804e-04
Loss = 5.5719e-03, PNorm = 53.4166, GNorm = 3.1572, lr_0 = 1.0804e-04
Loss = 5.8389e-03, PNorm = 53.4273, GNorm = 3.5244, lr_0 = 1.0804e-04
Loss = 5.4158e-03, PNorm = 53.4375, GNorm = 8.5281, lr_0 = 1.0804e-04
Validation rmse logD = 0.731626
Validation R2 logD = 0.655309
Epoch 11
Train function
Loss = 5.7652e-03, PNorm = 53.4460, GNorm = 7.3282, lr_0 = 1.0804e-04
Loss = 5.1652e-03, PNorm = 53.4566, GNorm = 3.6690, lr_0 = 1.0804e-04
Loss = 5.7310e-03, PNorm = 53.4648, GNorm = 2.4303, lr_0 = 1.0804e-04
Loss = 5.3781e-03, PNorm = 53.4752, GNorm = 6.6845, lr_0 = 1.0804e-04
Loss = 4.9643e-03, PNorm = 53.4862, GNorm = 7.9753, lr_0 = 1.0804e-04
Validation rmse logD = 0.683858
Validation R2 logD = 0.698849
Epoch 12
Train function
Loss = 3.4096e-03, PNorm = 53.4954, GNorm = 1.3684, lr_0 = 1.0804e-04
Loss = 5.0218e-03, PNorm = 53.5041, GNorm = 3.8704, lr_0 = 1.0804e-04
Loss = 4.6987e-03, PNorm = 53.5134, GNorm = 1.8413, lr_0 = 1.0804e-04
Loss = 4.9241e-03, PNorm = 53.5228, GNorm = 2.6951, lr_0 = 1.0804e-04
Loss = 5.0588e-03, PNorm = 53.5332, GNorm = 7.1846, lr_0 = 1.0804e-04
Loss = 5.1726e-03, PNorm = 53.5425, GNorm = 3.7684, lr_0 = 1.0804e-04
Validation rmse logD = 0.712490
Validation R2 logD = 0.673103
Epoch 13
Train function
Loss = 5.4963e-03, PNorm = 53.5521, GNorm = 6.1399, lr_0 = 1.0804e-04
Loss = 4.5475e-03, PNorm = 53.5620, GNorm = 6.1539, lr_0 = 1.0804e-04
Loss = 4.5832e-03, PNorm = 53.5724, GNorm = 5.7691, lr_0 = 1.0804e-04
Loss = 6.5205e-03, PNorm = 53.5807, GNorm = 10.6760, lr_0 = 1.0804e-04
Loss = 4.9640e-03, PNorm = 53.5902, GNorm = 2.0720, lr_0 = 1.0804e-04
Loss = 5.1093e-03, PNorm = 53.6014, GNorm = 8.3404, lr_0 = 1.0804e-04
Validation rmse logD = 0.683620
Validation R2 logD = 0.699058
Epoch 14
Train function
Loss = 3.7142e-03, PNorm = 53.6109, GNorm = 1.8326, lr_0 = 1.0804e-04
Loss = 4.3748e-03, PNorm = 53.6190, GNorm = 2.0405, lr_0 = 1.0804e-04
Loss = 4.4581e-03, PNorm = 53.6284, GNorm = 2.1494, lr_0 = 1.0804e-04
Loss = 4.5152e-03, PNorm = 53.6384, GNorm = 2.3595, lr_0 = 1.0804e-04
Loss = 4.7012e-03, PNorm = 53.6472, GNorm = 1.4990, lr_0 = 1.0804e-04
Validation rmse logD = 0.669498
Validation R2 logD = 0.711364
Epoch 15
Train function
Loss = 3.8194e-03, PNorm = 53.6561, GNorm = 3.4135, lr_0 = 1.0804e-04
Loss = 3.7635e-03, PNorm = 53.6662, GNorm = 3.4178, lr_0 = 1.0804e-04
Loss = 4.5022e-03, PNorm = 53.6741, GNorm = 8.1283, lr_0 = 1.0804e-04
Loss = 4.6167e-03, PNorm = 53.6826, GNorm = 8.3445, lr_0 = 1.0804e-04
Loss = 4.4580e-03, PNorm = 53.6909, GNorm = 6.7735, lr_0 = 1.0804e-04
Loss = 4.4818e-03, PNorm = 53.7004, GNorm = 2.3985, lr_0 = 1.0804e-04
Validation rmse logD = 0.687940
Validation R2 logD = 0.695243
Epoch 16
Train function
Loss = 3.5086e-03, PNorm = 53.7080, GNorm = 2.2220, lr_0 = 1.0804e-04
Loss = 3.7252e-03, PNorm = 53.7170, GNorm = 5.0861, lr_0 = 1.0804e-04
Loss = 4.3729e-03, PNorm = 53.7248, GNorm = 12.9314, lr_0 = 1.0804e-04
Loss = 4.3754e-03, PNorm = 53.7326, GNorm = 7.1184, lr_0 = 1.0804e-04
Loss = 4.2603e-03, PNorm = 53.7399, GNorm = 2.8208, lr_0 = 1.0804e-04
Loss = 4.2244e-03, PNorm = 53.7484, GNorm = 6.1086, lr_0 = 1.0804e-04
Validation rmse logD = 0.705541
Validation R2 logD = 0.679449
Epoch 17
Train function
Loss = 4.1612e-03, PNorm = 53.7578, GNorm = 10.5244, lr_0 = 1.0804e-04
Loss = 4.5067e-03, PNorm = 53.7654, GNorm = 2.0772, lr_0 = 1.0804e-04
Loss = 3.9528e-03, PNorm = 53.7763, GNorm = 6.1405, lr_0 = 1.0804e-04
Loss = 4.9879e-03, PNorm = 53.7851, GNorm = 1.5912, lr_0 = 1.0804e-04
Loss = 3.6515e-03, PNorm = 53.7937, GNorm = 3.6178, lr_0 = 1.0804e-04
Validation rmse logD = 0.668145
Validation R2 logD = 0.712529
Epoch 18
Train function
Loss = 2.7197e-03, PNorm = 53.8039, GNorm = 2.2395, lr_0 = 1.0804e-04
Loss = 3.7883e-03, PNorm = 53.8125, GNorm = 5.9162, lr_0 = 1.0804e-04
Loss = 3.4010e-03, PNorm = 53.8198, GNorm = 4.6878, lr_0 = 1.0804e-04
Loss = 3.5014e-03, PNorm = 53.8289, GNorm = 3.3035, lr_0 = 1.0804e-04
Loss = 4.0769e-03, PNorm = 53.8390, GNorm = 4.9151, lr_0 = 1.0804e-04
Loss = 3.4111e-03, PNorm = 53.8470, GNorm = 2.4385, lr_0 = 1.0804e-04
Validation rmse logD = 0.679133
Validation R2 logD = 0.702996
Epoch 19
Train function
Loss = 3.3983e-03, PNorm = 53.8548, GNorm = 2.4782, lr_0 = 1.0804e-04
Loss = 3.4920e-03, PNorm = 53.8625, GNorm = 6.0117, lr_0 = 1.0804e-04
Loss = 3.6601e-03, PNorm = 53.8695, GNorm = 2.2107, lr_0 = 1.0804e-04
Loss = 3.7195e-03, PNorm = 53.8798, GNorm = 1.5031, lr_0 = 1.0804e-04
Loss = 2.9442e-03, PNorm = 53.8890, GNorm = 2.6955, lr_0 = 1.0804e-04
Loss = 3.8763e-03, PNorm = 53.8961, GNorm = 2.3544, lr_0 = 1.0804e-04
Validation rmse logD = 0.650799
Validation R2 logD = 0.727262
Epoch 20
Train function
Loss = 3.2653e-03, PNorm = 53.9024, GNorm = 2.1518, lr_0 = 1.0804e-04
Loss = 3.2410e-03, PNorm = 53.9091, GNorm = 7.0499, lr_0 = 1.0804e-04
Loss = 3.0347e-03, PNorm = 53.9180, GNorm = 3.2580, lr_0 = 1.0804e-04
Loss = 3.2819e-03, PNorm = 53.9256, GNorm = 3.5430, lr_0 = 1.0804e-04
Loss = 3.1944e-03, PNorm = 53.9325, GNorm = 3.2740, lr_0 = 1.0804e-04
Validation rmse logD = 0.673719
Validation R2 logD = 0.707712
Epoch 21
Train function
Loss = 3.6787e-03, PNorm = 53.9435, GNorm = 7.0147, lr_0 = 1.0804e-04
Loss = 2.7669e-03, PNorm = 53.9509, GNorm = 1.1283, lr_0 = 1.0804e-04
Loss = 2.9103e-03, PNorm = 53.9584, GNorm = 3.9206, lr_0 = 1.0804e-04
Loss = 3.2413e-03, PNorm = 53.9662, GNorm = 2.1923, lr_0 = 1.0804e-04
Loss = 3.4208e-03, PNorm = 53.9734, GNorm = 4.9675, lr_0 = 1.0804e-04
Loss = 3.2179e-03, PNorm = 53.9809, GNorm = 4.6297, lr_0 = 1.0804e-04
Validation rmse logD = 0.675040
Validation R2 logD = 0.706565
Epoch 22
Train function
Loss = 3.2296e-03, PNorm = 53.9908, GNorm = 8.5607, lr_0 = 1.0804e-04
Loss = 2.8936e-03, PNorm = 53.9996, GNorm = 9.4818, lr_0 = 1.0804e-04
Loss = 3.9039e-03, PNorm = 54.0074, GNorm = 6.5178, lr_0 = 1.0804e-04
Loss = 3.1435e-03, PNorm = 54.0160, GNorm = 7.0073, lr_0 = 1.0804e-04
Loss = 3.4510e-03, PNorm = 54.0239, GNorm = 4.0354, lr_0 = 1.0804e-04
Loss = 3.7330e-03, PNorm = 54.0311, GNorm = 2.3851, lr_0 = 1.0804e-04
Validation rmse logD = 0.628821
Validation R2 logD = 0.745371
Epoch 23
Train function
Loss = 2.7286e-03, PNorm = 54.0397, GNorm = 2.4531, lr_0 = 1.0804e-04
Loss = 2.3594e-03, PNorm = 54.0487, GNorm = 2.6012, lr_0 = 1.0804e-04
Loss = 3.2813e-03, PNorm = 54.0568, GNorm = 6.6403, lr_0 = 1.0804e-04
Loss = 2.8527e-03, PNorm = 54.0656, GNorm = 1.2985, lr_0 = 1.0804e-04
Loss = 2.9270e-03, PNorm = 54.0728, GNorm = 1.6800, lr_0 = 1.0804e-04
Validation rmse logD = 0.624051
Validation R2 logD = 0.749220
Epoch 24
Train function
Loss = 2.2987e-03, PNorm = 54.0811, GNorm = 2.6051, lr_0 = 1.0804e-04
Loss = 3.1072e-03, PNorm = 54.0906, GNorm = 1.7801, lr_0 = 1.0804e-04
Loss = 2.7324e-03, PNorm = 54.0982, GNorm = 3.1583, lr_0 = 1.0804e-04
Loss = 2.9057e-03, PNorm = 54.1057, GNorm = 5.8216, lr_0 = 1.0804e-04
Loss = 2.7651e-03, PNorm = 54.1131, GNorm = 2.8406, lr_0 = 1.0804e-04
Loss = 2.3951e-03, PNorm = 54.1215, GNorm = 6.1762, lr_0 = 1.0804e-04
Validation rmse logD = 0.632202
Validation R2 logD = 0.742626
Epoch 25
Train function
Loss = 2.2383e-03, PNorm = 54.1281, GNorm = 3.7085, lr_0 = 1.0804e-04
Loss = 2.8029e-03, PNorm = 54.1356, GNorm = 3.0053, lr_0 = 1.0804e-04
Loss = 2.7160e-03, PNorm = 54.1430, GNorm = 3.8258, lr_0 = 1.0804e-04
Loss = 2.7074e-03, PNorm = 54.1510, GNorm = 5.5089, lr_0 = 1.0804e-04
Loss = 2.4251e-03, PNorm = 54.1590, GNorm = 3.4407, lr_0 = 1.0804e-04
Loss = 2.4915e-03, PNorm = 54.1674, GNorm = 5.6401, lr_0 = 1.0804e-04
Validation rmse logD = 0.609856
Validation R2 logD = 0.760499
Epoch 26
Train function
Loss = 1.9165e-03, PNorm = 54.1740, GNorm = 2.6891, lr_0 = 1.0804e-04
Loss = 2.0432e-03, PNorm = 54.1787, GNorm = 4.1728, lr_0 = 1.0804e-04
Loss = 2.2408e-03, PNorm = 54.1852, GNorm = 3.5224, lr_0 = 1.0804e-04
Loss = 2.2880e-03, PNorm = 54.1916, GNorm = 2.3571, lr_0 = 1.0804e-04
Loss = 3.1251e-03, PNorm = 54.2008, GNorm = 1.5767, lr_0 = 1.0804e-04
Validation rmse logD = 0.612976
Validation R2 logD = 0.758042
Epoch 27
Train function
Loss = 1.8354e-03, PNorm = 54.2116, GNorm = 1.6897, lr_0 = 1.0804e-04
Loss = 2.3464e-03, PNorm = 54.2198, GNorm = 4.0173, lr_0 = 1.0804e-04
Loss = 2.0851e-03, PNorm = 54.2271, GNorm = 2.1900, lr_0 = 1.0804e-04
Loss = 2.0463e-03, PNorm = 54.2342, GNorm = 6.2388, lr_0 = 1.0804e-04
Loss = 2.9767e-03, PNorm = 54.2435, GNorm = 2.4760, lr_0 = 1.0804e-04
Loss = 2.2569e-03, PNorm = 54.2500, GNorm = 1.5269, lr_0 = 1.0804e-04
Validation rmse logD = 0.611638
Validation R2 logD = 0.759098
Epoch 28
Train function
Loss = 2.3238e-03, PNorm = 54.2566, GNorm = 6.5596, lr_0 = 1.0804e-04
Loss = 2.9778e-03, PNorm = 54.2648, GNorm = 6.5109, lr_0 = 1.0804e-04
Loss = 1.9546e-03, PNorm = 54.2725, GNorm = 1.5514, lr_0 = 1.0804e-04
Loss = 2.1707e-03, PNorm = 54.2801, GNorm = 5.1245, lr_0 = 1.0804e-04
Loss = 2.2868e-03, PNorm = 54.2868, GNorm = 2.7976, lr_0 = 1.0804e-04
Loss = 2.4391e-03, PNorm = 54.2935, GNorm = 4.0336, lr_0 = 1.0804e-04
Validation rmse logD = 0.596100
Validation R2 logD = 0.771182
Epoch 29
Train function
Loss = 2.1266e-03, PNorm = 54.3004, GNorm = 2.0783, lr_0 = 1.0804e-04
Loss = 2.0414e-03, PNorm = 54.3073, GNorm = 3.6838, lr_0 = 1.0804e-04
Loss = 2.1967e-03, PNorm = 54.3150, GNorm = 2.3649, lr_0 = 1.0804e-04
Loss = 2.3457e-03, PNorm = 54.3222, GNorm = 8.0160, lr_0 = 1.0804e-04
Loss = 2.3709e-03, PNorm = 54.3284, GNorm = 1.9445, lr_0 = 1.0804e-04
Validation rmse logD = 0.616758
Validation R2 logD = 0.755048
Epoch 30
Train function
Loss = 1.7287e-03, PNorm = 54.3358, GNorm = 1.5351, lr_0 = 1.0804e-04
Loss = 1.8825e-03, PNorm = 54.3444, GNorm = 4.8512, lr_0 = 1.0804e-04
Loss = 2.1282e-03, PNorm = 54.3530, GNorm = 6.2831, lr_0 = 1.0804e-04
Loss = 2.1090e-03, PNorm = 54.3610, GNorm = 1.5465, lr_0 = 1.0804e-04
Loss = 2.0358e-03, PNorm = 54.3677, GNorm = 6.1552, lr_0 = 1.0804e-04
Loss = 2.5512e-03, PNorm = 54.3729, GNorm = 5.7537, lr_0 = 1.0804e-04
Validation rmse logD = 0.589888
Validation R2 logD = 0.775926
Epoch 31
Train function
Loss = 2.2344e-03, PNorm = 54.3786, GNorm = 1.7988, lr_0 = 1.0804e-04
Loss = 1.6745e-03, PNorm = 54.3859, GNorm = 3.2642, lr_0 = 1.0804e-04
Loss = 1.8461e-03, PNorm = 54.3937, GNorm = 2.0102, lr_0 = 1.0804e-04
Loss = 2.2371e-03, PNorm = 54.4017, GNorm = 5.2840, lr_0 = 1.0804e-04
Loss = 1.8491e-03, PNorm = 54.4092, GNorm = 3.2623, lr_0 = 1.0804e-04
Loss = 1.6769e-03, PNorm = 54.4151, GNorm = 3.5201, lr_0 = 1.0804e-04
Validation rmse logD = 0.627600
Validation R2 logD = 0.746360
Epoch 32
Train function
Loss = 1.6753e-03, PNorm = 54.4211, GNorm = 2.3049, lr_0 = 1.0804e-04
Loss = 1.6498e-03, PNorm = 54.4264, GNorm = 1.7187, lr_0 = 1.0804e-04
Loss = 2.2677e-03, PNorm = 54.4323, GNorm = 4.1443, lr_0 = 1.0804e-04
Loss = 2.1614e-03, PNorm = 54.4397, GNorm = 11.1389, lr_0 = 1.0804e-04
Loss = 2.0494e-03, PNorm = 54.4467, GNorm = 1.4642, lr_0 = 1.0804e-04
Validation rmse logD = 0.601155
Validation R2 logD = 0.767285
Epoch 33
Train function
Loss = 1.6156e-03, PNorm = 54.4551, GNorm = 2.3158, lr_0 = 1.0804e-04
Loss = 1.7930e-03, PNorm = 54.4628, GNorm = 4.0352, lr_0 = 1.0804e-04
Loss = 1.7467e-03, PNorm = 54.4696, GNorm = 2.1495, lr_0 = 1.0804e-04
Loss = 1.7084e-03, PNorm = 54.4760, GNorm = 2.8401, lr_0 = 1.0804e-04
Loss = 2.0133e-03, PNorm = 54.4801, GNorm = 6.0957, lr_0 = 1.0804e-04
Loss = 1.8379e-03, PNorm = 54.4865, GNorm = 1.8605, lr_0 = 1.0804e-04
Validation rmse logD = 0.602795
Validation R2 logD = 0.766013
Epoch 34
Train function
Loss = 1.5655e-03, PNorm = 54.4941, GNorm = 2.2865, lr_0 = 1.0804e-04
Loss = 1.7663e-03, PNorm = 54.5011, GNorm = 3.7378, lr_0 = 1.0804e-04
Loss = 2.1783e-03, PNorm = 54.5071, GNorm = 6.5947, lr_0 = 1.0804e-04
Loss = 2.1967e-03, PNorm = 54.5141, GNorm = 4.9989, lr_0 = 1.0804e-04
Loss = 2.0016e-03, PNorm = 54.5206, GNorm = 9.0910, lr_0 = 1.0804e-04
Loss = 1.6920e-03, PNorm = 54.5274, GNorm = 4.8358, lr_0 = 1.0804e-04
Validation rmse logD = 0.609509
Validation R2 logD = 0.760772
Epoch 35
Train function
Loss = 1.6624e-03, PNorm = 54.5345, GNorm = 1.5792, lr_0 = 1.0804e-04
Loss = 1.4277e-03, PNorm = 54.5427, GNorm = 1.7536, lr_0 = 1.0804e-04
Loss = 1.4808e-03, PNorm = 54.5509, GNorm = 5.4080, lr_0 = 1.0804e-04
Loss = 1.7400e-03, PNorm = 54.5553, GNorm = 4.4296, lr_0 = 1.0804e-04
Loss = 1.8480e-03, PNorm = 54.5613, GNorm = 5.7668, lr_0 = 1.0804e-04
Validation rmse logD = 0.586782
Validation R2 logD = 0.778280
Epoch 36
Train function
Loss = 1.3821e-03, PNorm = 54.5658, GNorm = 2.1356, lr_0 = 1.0804e-04
Loss = 2.1254e-03, PNorm = 54.5720, GNorm = 7.4301, lr_0 = 1.0804e-04
Loss = 1.6889e-03, PNorm = 54.5788, GNorm = 3.3644, lr_0 = 1.0804e-04
Loss = 1.4291e-03, PNorm = 54.5858, GNorm = 1.4550, lr_0 = 1.0804e-04
Loss = 1.4561e-03, PNorm = 54.5938, GNorm = 2.2487, lr_0 = 1.0804e-04
Loss = 1.5946e-03, PNorm = 54.6003, GNorm = 6.6021, lr_0 = 1.0804e-04
Validation rmse logD = 0.599697
Validation R2 logD = 0.768412
Epoch 37
Train function
Loss = 1.1371e-03, PNorm = 54.6057, GNorm = 1.7292, lr_0 = 1.0804e-04
Loss = 1.3522e-03, PNorm = 54.6114, GNorm = 1.4280, lr_0 = 1.0804e-04
Loss = 1.3907e-03, PNorm = 54.6176, GNorm = 2.7137, lr_0 = 1.0804e-04
Loss = 1.8832e-03, PNorm = 54.6219, GNorm = 10.4157, lr_0 = 1.0804e-04
Loss = 2.0032e-03, PNorm = 54.6263, GNorm = 4.9904, lr_0 = 1.0804e-04
Loss = 1.9943e-03, PNorm = 54.6344, GNorm = 6.1905, lr_0 = 1.0804e-04
Validation rmse logD = 0.612106
Validation R2 logD = 0.758729
Epoch 38
Train function
Loss = 1.6409e-03, PNorm = 54.6426, GNorm = 5.1901, lr_0 = 1.0804e-04
Loss = 1.3324e-03, PNorm = 54.6499, GNorm = 1.9804, lr_0 = 1.0804e-04
Loss = 2.0402e-03, PNorm = 54.6559, GNorm = 7.5198, lr_0 = 1.0804e-04
Loss = 1.6865e-03, PNorm = 54.6608, GNorm = 5.2500, lr_0 = 1.0804e-04
Loss = 1.6649e-03, PNorm = 54.6677, GNorm = 4.1867, lr_0 = 1.0804e-04
Validation rmse logD = 0.628408
Validation R2 logD = 0.745706
Epoch 39
Train function
Loss = 1.8073e-03, PNorm = 54.6741, GNorm = 6.1619, lr_0 = 1.0804e-04
Loss = 1.6754e-03, PNorm = 54.6785, GNorm = 3.6915, lr_0 = 1.0804e-04
Loss = 1.6424e-03, PNorm = 54.6850, GNorm = 1.9180, lr_0 = 1.0804e-04
Loss = 1.2208e-03, PNorm = 54.6922, GNorm = 1.5762, lr_0 = 1.0804e-04
Loss = 1.7467e-03, PNorm = 54.6973, GNorm = 3.6863, lr_0 = 1.0804e-04
Loss = 1.1925e-03, PNorm = 54.7025, GNorm = 2.4118, lr_0 = 1.0804e-04
Validation rmse logD = 0.630045
Validation R2 logD = 0.744380
Epoch 40
Train function
Loss = 2.1981e-03, PNorm = 54.7080, GNorm = 7.2325, lr_0 = 1.0804e-04
Loss = 1.5553e-03, PNorm = 54.7131, GNorm = 1.7781, lr_0 = 1.0804e-04
Loss = 1.8104e-03, PNorm = 54.7194, GNorm = 7.2888, lr_0 = 1.0804e-04
Loss = 1.5043e-03, PNorm = 54.7255, GNorm = 1.4124, lr_0 = 1.0804e-04
Loss = 1.3809e-03, PNorm = 54.7341, GNorm = 3.7818, lr_0 = 1.0804e-04
Loss = 1.1849e-03, PNorm = 54.7408, GNorm = 2.2918, lr_0 = 1.0804e-04
Validation rmse logD = 0.572377
Validation R2 logD = 0.789032
Epoch 41
Train function
Loss = 1.3555e-03, PNorm = 54.7478, GNorm = 4.1665, lr_0 = 1.0804e-04
Loss = 1.1945e-03, PNorm = 54.7510, GNorm = 1.3560, lr_0 = 1.0804e-04
Loss = 1.3291e-03, PNorm = 54.7543, GNorm = 7.3648, lr_0 = 1.0804e-04
Loss = 1.3416e-03, PNorm = 54.7594, GNorm = 1.3736, lr_0 = 1.0804e-04
Loss = 1.2807e-03, PNorm = 54.7657, GNorm = 1.1648, lr_0 = 1.0804e-04
Validation rmse logD = 0.576181
Validation R2 logD = 0.786218
Epoch 42
Train function
Loss = 1.1072e-03, PNorm = 54.7734, GNorm = 2.1870, lr_0 = 1.0804e-04
Loss = 1.1610e-03, PNorm = 54.7781, GNorm = 3.9793, lr_0 = 1.0804e-04
Loss = 1.1782e-03, PNorm = 54.7835, GNorm = 2.0008, lr_0 = 1.0804e-04
Loss = 1.2569e-03, PNorm = 54.7886, GNorm = 2.7029, lr_0 = 1.0804e-04
Loss = 1.9215e-03, PNorm = 54.7920, GNorm = 6.9260, lr_0 = 1.0804e-04
Loss = 2.0939e-03, PNorm = 54.7981, GNorm = 5.4150, lr_0 = 1.0804e-04
Validation rmse logD = 0.574187
Validation R2 logD = 0.787696
Epoch 43
Train function
Loss = 1.5288e-03, PNorm = 54.8044, GNorm = 1.2909, lr_0 = 1.0804e-04
Loss = 1.5103e-03, PNorm = 54.8114, GNorm = 1.5347, lr_0 = 1.0804e-04
Loss = 1.5472e-03, PNorm = 54.8170, GNorm = 2.7559, lr_0 = 1.0804e-04
Loss = 1.4969e-03, PNorm = 54.8218, GNorm = 3.2319, lr_0 = 1.0804e-04
Loss = 1.3560e-03, PNorm = 54.8285, GNorm = 1.7185, lr_0 = 1.0804e-04
Loss = 1.4456e-03, PNorm = 54.8356, GNorm = 1.6138, lr_0 = 1.0804e-04
Validation rmse logD = 0.576719
Validation R2 logD = 0.785819
Epoch 44
Train function
Loss = 1.0330e-03, PNorm = 54.8409, GNorm = 1.7608, lr_0 = 1.0804e-04
Loss = 1.1872e-03, PNorm = 54.8467, GNorm = 1.6640, lr_0 = 1.0804e-04
Loss = 1.1337e-03, PNorm = 54.8522, GNorm = 1.3678, lr_0 = 1.0804e-04
Loss = 9.6191e-04, PNorm = 54.8574, GNorm = 1.2273, lr_0 = 1.0804e-04
Loss = 1.1542e-03, PNorm = 54.8633, GNorm = 2.7185, lr_0 = 1.0804e-04
Validation rmse logD = 0.593108
Validation R2 logD = 0.773473
Epoch 45
Train function
Loss = 7.8908e-04, PNorm = 54.8686, GNorm = 2.2523, lr_0 = 1.0804e-04
Loss = 9.6665e-04, PNorm = 54.8726, GNorm = 1.8231, lr_0 = 1.0804e-04
Loss = 8.9079e-04, PNorm = 54.8766, GNorm = 2.2961, lr_0 = 1.0804e-04
Loss = 1.0995e-03, PNorm = 54.8820, GNorm = 1.5219, lr_0 = 1.0804e-04
Loss = 9.6166e-04, PNorm = 54.8864, GNorm = 4.5173, lr_0 = 1.0804e-04
Loss = 1.0925e-03, PNorm = 54.8916, GNorm = 2.3397, lr_0 = 1.0804e-04
Validation rmse logD = 0.631370
Validation R2 logD = 0.743303
Epoch 46
Train function
Loss = 1.2407e-03, PNorm = 54.8963, GNorm = 4.7325, lr_0 = 1.0804e-04
Loss = 1.1645e-03, PNorm = 54.9021, GNorm = 1.2897, lr_0 = 1.0804e-04
Loss = 9.3914e-04, PNorm = 54.9071, GNorm = 2.8437, lr_0 = 1.0804e-04
Loss = 8.3106e-04, PNorm = 54.9110, GNorm = 1.1404, lr_0 = 1.0804e-04
Loss = 9.3519e-04, PNorm = 54.9151, GNorm = 1.1660, lr_0 = 1.0804e-04
Loss = 1.1737e-03, PNorm = 54.9221, GNorm = 1.1645, lr_0 = 1.0804e-04
Validation rmse logD = 0.577701
Validation R2 logD = 0.785089
Epoch 47
Train function
Loss = 9.2033e-04, PNorm = 54.9259, GNorm = 3.4753, lr_0 = 1.0804e-04
Loss = 8.4555e-04, PNorm = 54.9308, GNorm = 4.0817, lr_0 = 1.0804e-04
Loss = 1.2971e-03, PNorm = 54.9368, GNorm = 3.9448, lr_0 = 1.0804e-04
Loss = 9.6751e-04, PNorm = 54.9409, GNorm = 1.3374, lr_0 = 1.0804e-04
Loss = 9.2758e-04, PNorm = 54.9456, GNorm = 1.1799, lr_0 = 1.0804e-04
Validation rmse logD = 0.593575
Validation R2 logD = 0.773116
Epoch 48
Train function
Loss = 1.4537e-03, PNorm = 54.9518, GNorm = 4.9808, lr_0 = 1.0804e-04
Loss = 1.1344e-03, PNorm = 54.9565, GNorm = 3.0754, lr_0 = 1.0804e-04
Loss = 1.2366e-03, PNorm = 54.9615, GNorm = 3.2777, lr_0 = 1.0804e-04
Loss = 1.0599e-03, PNorm = 54.9656, GNorm = 3.2467, lr_0 = 1.0804e-04
Loss = 9.4631e-04, PNorm = 54.9711, GNorm = 1.3798, lr_0 = 1.0804e-04
Loss = 9.6737e-04, PNorm = 54.9763, GNorm = 1.6369, lr_0 = 1.0804e-04
Validation rmse logD = 0.584353
Validation R2 logD = 0.780111
Epoch 49
Train function
Loss = 1.0419e-03, PNorm = 54.9822, GNorm = 3.8379, lr_0 = 1.0804e-04
Loss = 7.1078e-04, PNorm = 54.9876, GNorm = 4.3859, lr_0 = 1.0804e-04
Loss = 8.4686e-04, PNorm = 54.9923, GNorm = 6.0289, lr_0 = 1.0804e-04
Loss = 8.9577e-04, PNorm = 54.9971, GNorm = 2.3849, lr_0 = 1.0804e-04
Loss = 1.4235e-03, PNorm = 55.0011, GNorm = 7.5724, lr_0 = 1.0804e-04
Loss = 1.3780e-03, PNorm = 55.0056, GNorm = 2.8978, lr_0 = 1.0804e-04
Validation rmse logD = 0.582031
Validation R2 logD = 0.781855
Epoch 50
Train function
Loss = 1.0729e-03, PNorm = 55.0114, GNorm = 3.9045, lr_0 = 1.0804e-04
Loss = 1.3062e-03, PNorm = 55.0164, GNorm = 5.3983, lr_0 = 1.0804e-04
Loss = 1.2654e-03, PNorm = 55.0203, GNorm = 2.3427, lr_0 = 1.0804e-04
Loss = 1.2423e-03, PNorm = 55.0255, GNorm = 4.3582, lr_0 = 1.0804e-04
Loss = 1.0841e-03, PNorm = 55.0316, GNorm = 1.7822, lr_0 = 1.0804e-04
Validation rmse logD = 0.575469
Validation R2 logD = 0.786747
Epoch 51
Train function
Loss = 1.1622e-03, PNorm = 55.0376, GNorm = 1.8526, lr_0 = 1.0804e-04
Loss = 1.1076e-03, PNorm = 55.0434, GNorm = 2.4894, lr_0 = 1.0804e-04
Loss = 7.2088e-04, PNorm = 55.0472, GNorm = 1.6682, lr_0 = 1.0804e-04
Loss = 7.7397e-04, PNorm = 55.0525, GNorm = 1.1535, lr_0 = 1.0804e-04
Loss = 8.0229e-04, PNorm = 55.0582, GNorm = 1.0183, lr_0 = 1.0804e-04
Loss = 7.8798e-04, PNorm = 55.0613, GNorm = 1.4433, lr_0 = 1.0804e-04
Validation rmse logD = 0.600718
Validation R2 logD = 0.767622
Epoch 52
Train function
Loss = 8.9905e-04, PNorm = 55.0652, GNorm = 1.5511, lr_0 = 1.0804e-04
Loss = 7.8273e-04, PNorm = 55.0691, GNorm = 1.2631, lr_0 = 1.0804e-04
Loss = 6.4033e-04, PNorm = 55.0728, GNorm = 1.5442, lr_0 = 1.0804e-04
Loss = 8.7514e-04, PNorm = 55.0762, GNorm = 2.3205, lr_0 = 1.0804e-04
Loss = 8.5720e-04, PNorm = 55.0801, GNorm = 1.7125, lr_0 = 1.0804e-04
Loss = 1.0978e-03, PNorm = 55.0851, GNorm = 5.0967, lr_0 = 1.0804e-04
Validation rmse logD = 0.589283
Validation R2 logD = 0.776385
Epoch 53
Train function
Loss = 8.6636e-04, PNorm = 55.0905, GNorm = 1.2773, lr_0 = 1.0804e-04
Loss = 9.5704e-04, PNorm = 55.0961, GNorm = 1.1236, lr_0 = 1.0804e-04
Loss = 8.5263e-04, PNorm = 55.1012, GNorm = 1.3556, lr_0 = 1.0804e-04
Loss = 6.8921e-04, PNorm = 55.1061, GNorm = 1.8217, lr_0 = 1.0804e-04
Loss = 8.7165e-04, PNorm = 55.1094, GNorm = 3.4439, lr_0 = 1.0804e-04
Validation rmse logD = 0.571225
Validation R2 logD = 0.789880
Epoch 54
Train function
Loss = 7.0481e-04, PNorm = 55.1143, GNorm = 2.5586, lr_0 = 1.0804e-04
Loss = 6.8336e-04, PNorm = 55.1191, GNorm = 0.9361, lr_0 = 1.0804e-04
Loss = 8.9152e-04, PNorm = 55.1235, GNorm = 1.8953, lr_0 = 1.0804e-04
Loss = 1.0851e-03, PNorm = 55.1272, GNorm = 1.8331, lr_0 = 1.0804e-04
Loss = 8.9567e-04, PNorm = 55.1323, GNorm = 1.6240, lr_0 = 1.0804e-04
Loss = 8.1013e-04, PNorm = 55.1354, GNorm = 2.4634, lr_0 = 1.0804e-04
Validation rmse logD = 0.570921
Validation R2 logD = 0.790104
Epoch 55
Train function
Loss = 1.0651e-03, PNorm = 55.1395, GNorm = 1.8792, lr_0 = 1.0804e-04
Loss = 1.0775e-03, PNorm = 55.1451, GNorm = 6.9120, lr_0 = 1.0804e-04
Loss = 8.7979e-04, PNorm = 55.1493, GNorm = 1.0731, lr_0 = 1.0804e-04
Loss = 7.8686e-04, PNorm = 55.1553, GNorm = 4.8776, lr_0 = 1.0804e-04
Loss = 7.6623e-04, PNorm = 55.1608, GNorm = 2.4651, lr_0 = 1.0804e-04
Loss = 8.4795e-04, PNorm = 55.1657, GNorm = 2.7070, lr_0 = 1.0804e-04
Validation rmse logD = 0.570914
Validation R2 logD = 0.790109
Epoch 56
Train function
Loss = 5.9349e-04, PNorm = 55.1687, GNorm = 1.4369, lr_0 = 1.0804e-04
Loss = 5.8802e-04, PNorm = 55.1731, GNorm = 3.4844, lr_0 = 1.0804e-04
Loss = 6.5333e-04, PNorm = 55.1784, GNorm = 3.5698, lr_0 = 1.0804e-04
Loss = 8.5838e-04, PNorm = 55.1824, GNorm = 2.9443, lr_0 = 1.0804e-04
Loss = 8.5741e-04, PNorm = 55.1858, GNorm = 1.4855, lr_0 = 1.0804e-04
Validation rmse logD = 0.563521
Validation R2 logD = 0.795509
Epoch 57
Train function
Loss = 5.9486e-04, PNorm = 55.1910, GNorm = 1.6773, lr_0 = 1.0804e-04
Loss = 7.9012e-04, PNorm = 55.1939, GNorm = 2.3731, lr_0 = 1.0804e-04
Loss = 1.1028e-03, PNorm = 55.1968, GNorm = 4.2998, lr_0 = 1.0804e-04
Loss = 8.5021e-04, PNorm = 55.1996, GNorm = 6.1665, lr_0 = 1.0804e-04
Loss = 8.4974e-04, PNorm = 55.2054, GNorm = 2.6462, lr_0 = 1.0804e-04
Loss = 6.3812e-04, PNorm = 55.2111, GNorm = 4.0495, lr_0 = 1.0804e-04
Validation rmse logD = 0.566238
Validation R2 logD = 0.793533
Epoch 58
Train function
Loss = 5.4084e-04, PNorm = 55.2163, GNorm = 1.2706, lr_0 = 1.0804e-04
Loss = 5.2503e-04, PNorm = 55.2198, GNorm = 2.1033, lr_0 = 1.0804e-04
Loss = 6.8480e-04, PNorm = 55.2224, GNorm = 2.5074, lr_0 = 1.0804e-04
Loss = 7.3703e-04, PNorm = 55.2279, GNorm = 3.9722, lr_0 = 1.0804e-04
Loss = 6.5890e-04, PNorm = 55.2314, GNorm = 3.1701, lr_0 = 1.0804e-04
Loss = 6.6835e-04, PNorm = 55.2348, GNorm = 1.7405, lr_0 = 1.0804e-04
Validation rmse logD = 0.584841
Validation R2 logD = 0.779744
Epoch 59
Train function
Loss = 7.4185e-04, PNorm = 55.2388, GNorm = 3.3813, lr_0 = 1.0804e-04
Loss = 9.1645e-04, PNorm = 55.2423, GNorm = 5.9859, lr_0 = 1.0804e-04
Loss = 8.3887e-04, PNorm = 55.2473, GNorm = 1.9866, lr_0 = 1.0804e-04
Loss = 8.8022e-04, PNorm = 55.2521, GNorm = 4.5218, lr_0 = 1.0804e-04
Loss = 7.4383e-04, PNorm = 55.2571, GNorm = 2.2977, lr_0 = 1.0804e-04
Validation rmse logD = 0.573605
Validation R2 logD = 0.788126
Epoch 60
Train function
Loss = 5.3881e-04, PNorm = 55.2626, GNorm = 1.7528, lr_0 = 1.0804e-04
Loss = 6.2269e-04, PNorm = 55.2669, GNorm = 2.4122, lr_0 = 1.0804e-04
Loss = 5.5953e-04, PNorm = 55.2694, GNorm = 1.7022, lr_0 = 1.0804e-04
Loss = 6.5259e-04, PNorm = 55.2738, GNorm = 0.8630, lr_0 = 1.0804e-04
Loss = 6.2420e-04, PNorm = 55.2778, GNorm = 2.0498, lr_0 = 1.0804e-04
Loss = 8.4410e-04, PNorm = 55.2803, GNorm = 2.9385, lr_0 = 1.0804e-04
Validation rmse logD = 0.556305
Validation R2 logD = 0.800713
Epoch 61
Train function
Loss = 6.2423e-04, PNorm = 55.2839, GNorm = 1.9951, lr_0 = 1.0804e-04
Loss = 6.1117e-04, PNorm = 55.2878, GNorm = 1.2552, lr_0 = 1.0804e-04
Loss = 6.4781e-04, PNorm = 55.2919, GNorm = 1.0387, lr_0 = 1.0804e-04
Loss = 6.2671e-04, PNorm = 55.2953, GNorm = 2.2163, lr_0 = 1.0804e-04
Loss = 5.8586e-04, PNorm = 55.2994, GNorm = 0.9878, lr_0 = 1.0804e-04
Loss = 5.3591e-04, PNorm = 55.3031, GNorm = 0.9162, lr_0 = 1.0804e-04
Validation rmse logD = 0.559761
Validation R2 logD = 0.798230
Epoch 62
Train function
Loss = 5.1084e-04, PNorm = 55.3076, GNorm = 4.1546, lr_0 = 1.0804e-04
Loss = 4.7404e-04, PNorm = 55.3112, GNorm = 1.1558, lr_0 = 1.0804e-04
Loss = 5.1437e-04, PNorm = 55.3158, GNorm = 2.5481, lr_0 = 1.0804e-04
Loss = 9.3195e-04, PNorm = 55.3191, GNorm = 5.4009, lr_0 = 1.0804e-04
Loss = 7.1468e-04, PNorm = 55.3215, GNorm = 3.9201, lr_0 = 1.0804e-04
Validation rmse logD = 0.595119
Validation R2 logD = 0.771935
Epoch 63
Train function
Loss = 9.1119e-04, PNorm = 55.3265, GNorm = 5.3951, lr_0 = 1.0804e-04
Loss = 7.2402e-04, PNorm = 55.3310, GNorm = 3.2034, lr_0 = 1.0804e-04
Loss = 5.5718e-04, PNorm = 55.3358, GNorm = 1.6102, lr_0 = 1.0804e-04
Loss = 4.9881e-04, PNorm = 55.3403, GNorm = 0.9841, lr_0 = 1.0804e-04
Loss = 6.7284e-04, PNorm = 55.3450, GNorm = 1.6908, lr_0 = 1.0804e-04
Loss = 6.9651e-04, PNorm = 55.3486, GNorm = 1.2604, lr_0 = 1.0804e-04
Validation rmse logD = 0.571731
Validation R2 logD = 0.789508
Epoch 64
Train function
Loss = 5.7624e-04, PNorm = 55.3516, GNorm = 1.8526, lr_0 = 1.0804e-04
Loss = 7.8134e-04, PNorm = 55.3543, GNorm = 3.8694, lr_0 = 1.0804e-04
Loss = 5.4188e-04, PNorm = 55.3581, GNorm = 2.1395, lr_0 = 1.0804e-04
Loss = 7.4087e-04, PNorm = 55.3609, GNorm = 1.0617, lr_0 = 1.0804e-04
Loss = 7.1743e-04, PNorm = 55.3634, GNorm = 2.2112, lr_0 = 1.0804e-04
Loss = 5.2275e-04, PNorm = 55.3685, GNorm = 1.8894, lr_0 = 1.0804e-04
Validation rmse logD = 0.557970
Validation R2 logD = 0.799518
Epoch 65
Train function
Loss = 5.5775e-04, PNorm = 55.3736, GNorm = 2.6104, lr_0 = 1.0804e-04
Loss = 5.5576e-04, PNorm = 55.3791, GNorm = 3.2687, lr_0 = 1.0804e-04
Loss = 6.3599e-04, PNorm = 55.3822, GNorm = 2.0691, lr_0 = 1.0804e-04
Loss = 4.8415e-04, PNorm = 55.3847, GNorm = 1.9118, lr_0 = 1.0804e-04
Loss = 4.9441e-04, PNorm = 55.3885, GNorm = 1.1149, lr_0 = 1.0804e-04
Validation rmse logD = 0.586441
Validation R2 logD = 0.778537
Epoch 66
Train function
Loss = 8.3801e-04, PNorm = 55.3926, GNorm = 5.6833, lr_0 = 1.0804e-04
Loss = 5.1513e-04, PNorm = 55.3965, GNorm = 1.3535, lr_0 = 1.0804e-04
Loss = 5.4930e-04, PNorm = 55.4015, GNorm = 4.4160, lr_0 = 1.0804e-04
Loss = 8.3680e-04, PNorm = 55.4068, GNorm = 5.1796, lr_0 = 1.0804e-04
Loss = 6.3398e-04, PNorm = 55.4104, GNorm = 3.8792, lr_0 = 1.0804e-04
Loss = 6.4645e-04, PNorm = 55.4130, GNorm = 1.6891, lr_0 = 1.0804e-04
Validation rmse logD = 0.560854
Validation R2 logD = 0.797441
Epoch 67
Train function
Loss = 6.7288e-04, PNorm = 55.4175, GNorm = 1.5403, lr_0 = 1.0804e-04
Loss = 5.2682e-04, PNorm = 55.4212, GNorm = 3.1900, lr_0 = 1.0804e-04
Loss = 5.3459e-04, PNorm = 55.4252, GNorm = 2.3073, lr_0 = 1.0804e-04
Loss = 5.5515e-04, PNorm = 55.4288, GNorm = 1.0860, lr_0 = 1.0804e-04
Loss = 5.5741e-04, PNorm = 55.4318, GNorm = 1.9608, lr_0 = 1.0804e-04
Loss = 7.3223e-04, PNorm = 55.4359, GNorm = 2.9688, lr_0 = 1.0804e-04
Validation rmse logD = 0.575684
Validation R2 logD = 0.786587
Epoch 68
Train function
Loss = 6.6544e-04, PNorm = 55.4395, GNorm = 4.2457, lr_0 = 1.0804e-04
Loss = 5.8327e-04, PNorm = 55.4438, GNorm = 1.3395, lr_0 = 1.0804e-04
Loss = 5.0731e-04, PNorm = 55.4471, GNorm = 3.2390, lr_0 = 1.0804e-04
Loss = 5.3859e-04, PNorm = 55.4504, GNorm = 2.6871, lr_0 = 1.0804e-04
Loss = 4.7406e-04, PNorm = 55.4545, GNorm = 1.7769, lr_0 = 1.0804e-04
Validation rmse logD = 0.567389
Validation R2 logD = 0.792693
Epoch 69
Train function
Loss = 3.4964e-04, PNorm = 55.4585, GNorm = 1.3795, lr_0 = 1.0804e-04
Loss = 6.6463e-04, PNorm = 55.4615, GNorm = 6.4527, lr_0 = 1.0804e-04
Loss = 5.9666e-04, PNorm = 55.4652, GNorm = 2.9404, lr_0 = 1.0804e-04
Loss = 5.0424e-04, PNorm = 55.4694, GNorm = 0.9701, lr_0 = 1.0804e-04
Loss = 4.1492e-04, PNorm = 55.4718, GNorm = 0.8010, lr_0 = 1.0804e-04
Loss = 4.6413e-04, PNorm = 55.4745, GNorm = 4.2677, lr_0 = 1.0804e-04
Validation rmse logD = 0.564325
Validation R2 logD = 0.794926
Epoch 70
Train function
Loss = 3.9238e-04, PNorm = 55.4779, GNorm = 1.6766, lr_0 = 1.0804e-04
Loss = 5.2875e-04, PNorm = 55.4807, GNorm = 1.7163, lr_0 = 1.0804e-04
Loss = 4.6820e-04, PNorm = 55.4855, GNorm = 1.7519, lr_0 = 1.0804e-04
Loss = 5.7551e-04, PNorm = 55.4889, GNorm = 1.2091, lr_0 = 1.0804e-04
Loss = 4.9665e-04, PNorm = 55.4919, GNorm = 3.1931, lr_0 = 1.0804e-04
Loss = 4.3299e-04, PNorm = 55.4952, GNorm = 3.2656, lr_0 = 1.0804e-04
Validation rmse logD = 0.557316
Validation R2 logD = 0.799989
Epoch 71
Train function
Loss = 5.6910e-04, PNorm = 55.4978, GNorm = 1.4954, lr_0 = 1.0804e-04
Loss = 4.4925e-04, PNorm = 55.5020, GNorm = 1.3180, lr_0 = 1.0804e-04
Loss = 4.7715e-04, PNorm = 55.5054, GNorm = 1.3968, lr_0 = 1.0804e-04
Loss = 4.0993e-04, PNorm = 55.5087, GNorm = 3.4897, lr_0 = 1.0804e-04
Loss = 3.8184e-04, PNorm = 55.5119, GNorm = 0.7143, lr_0 = 1.0804e-04
Validation rmse logD = 0.566695
Validation R2 logD = 0.793200
Epoch 72
Train function
Loss = 5.0605e-04, PNorm = 55.5158, GNorm = 3.0536, lr_0 = 1.0804e-04
Loss = 4.0246e-04, PNorm = 55.5176, GNorm = 2.8878, lr_0 = 1.0804e-04
Loss = 6.0319e-04, PNorm = 55.5207, GNorm = 4.4154, lr_0 = 1.0804e-04
Loss = 4.4376e-04, PNorm = 55.5251, GNorm = 2.2688, lr_0 = 1.0804e-04
Loss = 5.1115e-04, PNorm = 55.5280, GNorm = 1.4780, lr_0 = 1.0804e-04
Loss = 6.3736e-04, PNorm = 55.5296, GNorm = 5.1545, lr_0 = 1.0804e-04
Validation rmse logD = 0.571037
Validation R2 logD = 0.790019
Epoch 73
Train function
Loss = 6.3478e-04, PNorm = 55.5326, GNorm = 2.1537, lr_0 = 1.0804e-04
Loss = 4.5330e-04, PNorm = 55.5364, GNorm = 1.4563, lr_0 = 1.0804e-04
Loss = 3.8718e-04, PNorm = 55.5400, GNorm = 0.6777, lr_0 = 1.0804e-04
Loss = 3.8084e-04, PNorm = 55.5446, GNorm = 2.6405, lr_0 = 1.0804e-04
Loss = 4.7055e-04, PNorm = 55.5486, GNorm = 1.3811, lr_0 = 1.0804e-04
Loss = 4.5387e-04, PNorm = 55.5519, GNorm = 2.7779, lr_0 = 1.0804e-04
Validation rmse logD = 0.559095
Validation R2 logD = 0.798709
Epoch 74
Train function
Loss = 4.3154e-04, PNorm = 55.5548, GNorm = 4.1132, lr_0 = 1.0804e-04
Loss = 6.6199e-04, PNorm = 55.5566, GNorm = 3.6594, lr_0 = 1.0804e-04
Loss = 4.8719e-04, PNorm = 55.5610, GNorm = 2.1345, lr_0 = 1.0804e-04
Loss = 4.8984e-04, PNorm = 55.5650, GNorm = 1.2243, lr_0 = 1.0804e-04
Loss = 4.7372e-04, PNorm = 55.5676, GNorm = 2.0401, lr_0 = 1.0804e-04
Validation rmse logD = 0.573430
Validation R2 logD = 0.788255
Epoch 75
Train function
Loss = 2.5911e-04, PNorm = 55.5716, GNorm = 1.3084, lr_0 = 1.0804e-04
Loss = 4.6085e-04, PNorm = 55.5743, GNorm = 2.8132, lr_0 = 1.0804e-04
Loss = 6.5109e-04, PNorm = 55.5774, GNorm = 2.4269, lr_0 = 1.0804e-04
Loss = 3.6063e-04, PNorm = 55.5818, GNorm = 1.6734, lr_0 = 1.0804e-04
Loss = 4.5691e-04, PNorm = 55.5862, GNorm = 2.3241, lr_0 = 1.0804e-04
Loss = 6.1989e-04, PNorm = 55.5903, GNorm = 3.2270, lr_0 = 1.0804e-04
Validation rmse logD = 0.567856
Validation R2 logD = 0.792351
Epoch 76
Train function
Loss = 6.0384e-04, PNorm = 55.5929, GNorm = 1.2146, lr_0 = 1.0804e-04
Loss = 5.3681e-04, PNorm = 55.5968, GNorm = 2.5329, lr_0 = 1.0804e-04
Loss = 4.5059e-04, PNorm = 55.6002, GNorm = 1.2291, lr_0 = 1.0804e-04
Loss = 4.3784e-04, PNorm = 55.6042, GNorm = 1.4809, lr_0 = 1.0804e-04
Loss = 4.5782e-04, PNorm = 55.6064, GNorm = 3.0628, lr_0 = 1.0804e-04
Loss = 4.3458e-04, PNorm = 55.6093, GNorm = 2.0287, lr_0 = 1.0804e-04
Validation rmse logD = 0.558941
Validation R2 logD = 0.798820
Epoch 77
Train function
Loss = 3.5296e-04, PNorm = 55.6126, GNorm = 1.1328, lr_0 = 1.0804e-04
Loss = 4.0291e-04, PNorm = 55.6164, GNorm = 3.5284, lr_0 = 1.0804e-04
Loss = 7.3538e-04, PNorm = 55.6181, GNorm = 2.6016, lr_0 = 1.0804e-04
Loss = 5.8184e-04, PNorm = 55.6202, GNorm = 1.9689, lr_0 = 1.0804e-04
Loss = 4.0668e-04, PNorm = 55.6250, GNorm = 1.8827, lr_0 = 1.0804e-04
Validation rmse logD = 0.553669
Validation R2 logD = 0.802597
Epoch 78
Train function
Loss = 3.5982e-04, PNorm = 55.6285, GNorm = 0.8434, lr_0 = 1.0804e-04
Loss = 3.6591e-04, PNorm = 55.6314, GNorm = 1.2023, lr_0 = 1.0804e-04
Loss = 4.9962e-04, PNorm = 55.6351, GNorm = 4.9554, lr_0 = 1.0804e-04
Loss = 3.9361e-04, PNorm = 55.6398, GNorm = 3.9368, lr_0 = 1.0804e-04
Loss = 4.4680e-04, PNorm = 55.6436, GNorm = 1.3980, lr_0 = 1.0804e-04
Loss = 4.5476e-04, PNorm = 55.6463, GNorm = 2.5167, lr_0 = 1.0804e-04
Validation rmse logD = 0.553476
Validation R2 logD = 0.802735
Epoch 79
Train function
Loss = 3.7307e-04, PNorm = 55.6480, GNorm = 1.8920, lr_0 = 1.0804e-04
Loss = 3.3029e-04, PNorm = 55.6508, GNorm = 0.8989, lr_0 = 1.0804e-04
Loss = 4.5161e-04, PNorm = 55.6543, GNorm = 2.7784, lr_0 = 1.0804e-04
Loss = 4.7352e-04, PNorm = 55.6567, GNorm = 1.8608, lr_0 = 1.0804e-04
Loss = 7.5942e-04, PNorm = 55.6596, GNorm = 4.3759, lr_0 = 1.0804e-04
Loss = 8.1201e-04, PNorm = 55.6615, GNorm = 4.4808, lr_0 = 1.0804e-04
Validation rmse logD = 0.586222
Validation R2 logD = 0.778702
Epoch 80
Train function
Loss = 5.9846e-04, PNorm = 55.6657, GNorm = 4.9090, lr_0 = 1.0804e-04
Loss = 8.5412e-04, PNorm = 55.6697, GNorm = 6.3643, lr_0 = 1.0804e-04
Loss = 7.9728e-04, PNorm = 55.6718, GNorm = 4.6637, lr_0 = 1.0804e-04
Loss = 6.4725e-04, PNorm = 55.6775, GNorm = 2.3092, lr_0 = 1.0804e-04
Loss = 6.4436e-04, PNorm = 55.6820, GNorm = 1.5821, lr_0 = 1.0804e-04
Validation rmse logD = 0.565466
Validation R2 logD = 0.794096
Epoch 81
Train function
Loss = 5.4310e-04, PNorm = 55.6878, GNorm = 2.5911, lr_0 = 1.0804e-04
Loss = 4.9931e-04, PNorm = 55.6917, GNorm = 1.5773, lr_0 = 1.0804e-04
Loss = 3.7473e-04, PNorm = 55.6956, GNorm = 1.1217, lr_0 = 1.0804e-04
Loss = 3.3437e-04, PNorm = 55.6986, GNorm = 1.3779, lr_0 = 1.0804e-04
Loss = 3.5231e-04, PNorm = 55.7009, GNorm = 1.0498, lr_0 = 1.0804e-04
Loss = 4.1134e-04, PNorm = 55.7042, GNorm = 2.6101, lr_0 = 1.0804e-04
Validation rmse logD = 0.568589
Validation R2 logD = 0.791815
Epoch 82
Train function
Loss = 3.6847e-04, PNorm = 55.7071, GNorm = 3.3495, lr_0 = 1.0804e-04
Loss = 3.6348e-04, PNorm = 55.7106, GNorm = 1.9734, lr_0 = 1.0804e-04
Loss = 3.5838e-04, PNorm = 55.7147, GNorm = 1.6851, lr_0 = 1.0804e-04
Loss = 3.0009e-04, PNorm = 55.7181, GNorm = 1.8311, lr_0 = 1.0804e-04
Loss = 4.4202e-04, PNorm = 55.7204, GNorm = 1.2250, lr_0 = 1.0804e-04
Loss = 3.4126e-04, PNorm = 55.7232, GNorm = 0.9826, lr_0 = 1.0804e-04
Validation rmse logD = 0.560449
Validation R2 logD = 0.797733
Epoch 83
Train function
Loss = 3.7215e-04, PNorm = 55.7262, GNorm = 2.1413, lr_0 = 1.0804e-04
Loss = 2.9822e-04, PNorm = 55.7285, GNorm = 1.1037, lr_0 = 1.0804e-04
Loss = 3.3263e-04, PNorm = 55.7308, GNorm = 1.3794, lr_0 = 1.0804e-04
Loss = 2.2862e-04, PNorm = 55.7323, GNorm = 0.5674, lr_0 = 1.0804e-04
Loss = 3.1255e-04, PNorm = 55.7346, GNorm = 1.6363, lr_0 = 1.0804e-04
Validation rmse logD = 0.563373
Validation R2 logD = 0.795617
Epoch 84
Train function
Loss = 2.7031e-04, PNorm = 55.7376, GNorm = 1.2808, lr_0 = 1.0804e-04
Loss = 4.1723e-04, PNorm = 55.7398, GNorm = 1.2361, lr_0 = 1.0804e-04
Loss = 5.0021e-04, PNorm = 55.7429, GNorm = 2.5308, lr_0 = 1.0804e-04
Loss = 3.1100e-04, PNorm = 55.7449, GNorm = 1.6931, lr_0 = 1.0804e-04
Loss = 2.7891e-04, PNorm = 55.7476, GNorm = 0.9238, lr_0 = 1.0804e-04
Loss = 3.1521e-04, PNorm = 55.7510, GNorm = 2.5738, lr_0 = 1.0804e-04
Validation rmse logD = 0.564420
Validation R2 logD = 0.794857
Epoch 85
Train function
Loss = 2.7963e-04, PNorm = 55.7538, GNorm = 1.5862, lr_0 = 1.0804e-04
Loss = 3.7622e-04, PNorm = 55.7569, GNorm = 1.8278, lr_0 = 1.0804e-04
Loss = 3.8464e-04, PNorm = 55.7589, GNorm = 1.7043, lr_0 = 1.0804e-04
Loss = 3.2860e-04, PNorm = 55.7604, GNorm = 0.9703, lr_0 = 1.0804e-04
Loss = 3.2820e-04, PNorm = 55.7639, GNorm = 2.3290, lr_0 = 1.0804e-04
Loss = 4.0557e-04, PNorm = 55.7668, GNorm = 1.3049, lr_0 = 1.0804e-04
Validation rmse logD = 0.558490
Validation R2 logD = 0.799144
Epoch 86
Train function
Loss = 2.5741e-04, PNorm = 55.7692, GNorm = 1.1823, lr_0 = 1.0804e-04
Loss = 3.1293e-04, PNorm = 55.7712, GNorm = 1.9325, lr_0 = 1.0804e-04
Loss = 3.5939e-04, PNorm = 55.7744, GNorm = 2.2778, lr_0 = 1.0804e-04
Loss = 3.4490e-04, PNorm = 55.7769, GNorm = 2.5560, lr_0 = 1.0804e-04
Loss = 3.5289e-04, PNorm = 55.7797, GNorm = 1.2736, lr_0 = 1.0804e-04
Validation rmse logD = 0.578708
Validation R2 logD = 0.784339
Epoch 87
Train function
Loss = 7.9484e-04, PNorm = 55.7821, GNorm = 4.8552, lr_0 = 1.0804e-04
Loss = 3.9336e-04, PNorm = 55.7844, GNorm = 2.3932, lr_0 = 1.0804e-04
Loss = 3.3275e-04, PNorm = 55.7874, GNorm = 2.4153, lr_0 = 1.0804e-04
Loss = 4.7896e-04, PNorm = 55.7899, GNorm = 3.8086, lr_0 = 1.0804e-04
Loss = 4.6610e-04, PNorm = 55.7925, GNorm = 2.8989, lr_0 = 1.0804e-04
Loss = 3.7798e-04, PNorm = 55.7958, GNorm = 1.3720, lr_0 = 1.0804e-04
Validation rmse logD = 0.588654
Validation R2 logD = 0.776863
Epoch 88
Train function
Loss = 3.2563e-04, PNorm = 55.7997, GNorm = 3.1704, lr_0 = 1.0804e-04
Loss = 2.6480e-04, PNorm = 55.8031, GNorm = 1.7344, lr_0 = 1.0804e-04
Loss = 2.6861e-04, PNorm = 55.8057, GNorm = 1.0364, lr_0 = 1.0804e-04
Loss = 2.7140e-04, PNorm = 55.8084, GNorm = 1.9542, lr_0 = 1.0804e-04
Loss = 3.1756e-04, PNorm = 55.8108, GNorm = 1.6474, lr_0 = 1.0804e-04
Loss = 2.8462e-04, PNorm = 55.8126, GNorm = 2.7240, lr_0 = 1.0804e-04
Validation rmse logD = 0.560540
Validation R2 logD = 0.797668
Epoch 89
Train function
Loss = 2.8779e-04, PNorm = 55.8154, GNorm = 0.6090, lr_0 = 1.0804e-04
Loss = 2.8099e-04, PNorm = 55.8180, GNorm = 2.0248, lr_0 = 1.0804e-04
Loss = 2.4177e-04, PNorm = 55.8213, GNorm = 1.0283, lr_0 = 1.0804e-04
Loss = 2.8572e-04, PNorm = 55.8237, GNorm = 0.5503, lr_0 = 1.0804e-04
Loss = 2.6124e-04, PNorm = 55.8260, GNorm = 1.3677, lr_0 = 1.0804e-04
Validation rmse logD = 0.559206
Validation R2 logD = 0.798629
Epoch 90
Train function
Loss = 4.1987e-04, PNorm = 55.8291, GNorm = 1.5950, lr_0 = 1.0804e-04
Loss = 2.0306e-04, PNorm = 55.8307, GNorm = 1.4243, lr_0 = 1.0804e-04
Loss = 2.6045e-04, PNorm = 55.8331, GNorm = 1.8729, lr_0 = 1.0804e-04
Loss = 2.5792e-04, PNorm = 55.8342, GNorm = 0.9406, lr_0 = 1.0804e-04
Loss = 2.3645e-04, PNorm = 55.8362, GNorm = 1.5492, lr_0 = 1.0804e-04
Loss = 2.5646e-04, PNorm = 55.8386, GNorm = 1.4064, lr_0 = 1.0804e-04
Validation rmse logD = 0.561842
Validation R2 logD = 0.796727
Epoch 91
Train function
Loss = 1.9653e-04, PNorm = 55.8413, GNorm = 1.2320, lr_0 = 1.0804e-04
Loss = 2.5413e-04, PNorm = 55.8444, GNorm = 0.6504, lr_0 = 1.0804e-04
Loss = 3.0662e-04, PNorm = 55.8465, GNorm = 0.7975, lr_0 = 1.0804e-04
Loss = 2.8762e-04, PNorm = 55.8480, GNorm = 0.8031, lr_0 = 1.0804e-04
Loss = 2.9046e-04, PNorm = 55.8507, GNorm = 0.6995, lr_0 = 1.0804e-04
Loss = 3.0177e-04, PNorm = 55.8535, GNorm = 0.8866, lr_0 = 1.0804e-04
Validation rmse logD = 0.569640
Validation R2 logD = 0.791045
Epoch 92
Train function
Loss = 3.2468e-04, PNorm = 55.8554, GNorm = 2.5485, lr_0 = 1.0804e-04
Loss = 4.8970e-04, PNorm = 55.8579, GNorm = 3.6718, lr_0 = 1.0804e-04
Loss = 3.4987e-04, PNorm = 55.8613, GNorm = 1.1113, lr_0 = 1.0804e-04
Loss = 2.9147e-04, PNorm = 55.8641, GNorm = 2.9472, lr_0 = 1.0804e-04
Loss = 2.8218e-04, PNorm = 55.8686, GNorm = 0.7613, lr_0 = 1.0804e-04
Validation rmse logD = 0.557714
Validation R2 logD = 0.799703
Epoch 93
Train function
Loss = 1.8363e-04, PNorm = 55.8721, GNorm = 0.8973, lr_0 = 1.0804e-04
Loss = 3.4570e-04, PNorm = 55.8737, GNorm = 1.8586, lr_0 = 1.0804e-04
Loss = 3.2517e-04, PNorm = 55.8753, GNorm = 2.6959, lr_0 = 1.0804e-04
Loss = 2.8630e-04, PNorm = 55.8772, GNorm = 1.0341, lr_0 = 1.0804e-04
Loss = 2.6424e-04, PNorm = 55.8799, GNorm = 1.1968, lr_0 = 1.0804e-04
Loss = 2.1686e-04, PNorm = 55.8834, GNorm = 0.9374, lr_0 = 1.0804e-04
Validation rmse logD = 0.558874
Validation R2 logD = 0.798868
Epoch 94
Train function
Loss = 2.3953e-04, PNorm = 55.8867, GNorm = 1.9249, lr_0 = 1.0804e-04
Loss = 3.2825e-04, PNorm = 55.8893, GNorm = 0.7306, lr_0 = 1.0804e-04
Loss = 2.5450e-04, PNorm = 55.8913, GNorm = 0.5785, lr_0 = 1.0804e-04
Loss = 2.6743e-04, PNorm = 55.8946, GNorm = 2.2871, lr_0 = 1.0804e-04
Loss = 2.8684e-04, PNorm = 55.8972, GNorm = 1.9855, lr_0 = 1.0804e-04
Loss = 2.8573e-04, PNorm = 55.9006, GNorm = 2.4115, lr_0 = 1.0804e-04
Validation rmse logD = 0.570876
Validation R2 logD = 0.790137
Epoch 95
Train function
Loss = 2.7325e-04, PNorm = 55.9042, GNorm = 0.7463, lr_0 = 1.0804e-04
Loss = 2.3896e-04, PNorm = 55.9067, GNorm = 3.0779, lr_0 = 1.0804e-04
Loss = 4.2275e-04, PNorm = 55.9083, GNorm = 1.0556, lr_0 = 1.0804e-04
Loss = 2.4496e-04, PNorm = 55.9112, GNorm = 0.7864, lr_0 = 1.0804e-04
Loss = 2.6434e-04, PNorm = 55.9138, GNorm = 1.1031, lr_0 = 1.0804e-04
Validation rmse logD = 0.565592
Validation R2 logD = 0.794004
Epoch 96
Train function
Loss = 1.6728e-04, PNorm = 55.9149, GNorm = 0.5647, lr_0 = 1.0804e-04
Loss = 2.2674e-04, PNorm = 55.9181, GNorm = 1.4869, lr_0 = 1.0804e-04
Loss = 2.1729e-04, PNorm = 55.9210, GNorm = 1.0481, lr_0 = 1.0804e-04
Loss = 3.1300e-04, PNorm = 55.9233, GNorm = 1.9589, lr_0 = 1.0804e-04
Loss = 4.3319e-04, PNorm = 55.9257, GNorm = 2.8486, lr_0 = 1.0804e-04
Loss = 3.5374e-04, PNorm = 55.9288, GNorm = 3.6943, lr_0 = 1.0804e-04
Validation rmse logD = 0.603946
Validation R2 logD = 0.765118
Epoch 97
Train function
Loss = 5.9751e-04, PNorm = 55.9321, GNorm = 3.3927, lr_0 = 1.0804e-04
Loss = 5.0328e-04, PNorm = 55.9325, GNorm = 2.2293, lr_0 = 1.0804e-04
Loss = 3.1572e-04, PNorm = 55.9363, GNorm = 1.6940, lr_0 = 1.0804e-04
Loss = 3.4973e-04, PNorm = 55.9406, GNorm = 2.7956, lr_0 = 1.0804e-04
Loss = 3.8299e-04, PNorm = 55.9432, GNorm = 3.4437, lr_0 = 1.0804e-04
Loss = 4.1711e-04, PNorm = 55.9467, GNorm = 2.0237, lr_0 = 1.0804e-04
Validation rmse logD = 0.555115
Validation R2 logD = 0.801565
Epoch 98
Train function
Loss = 2.9067e-04, PNorm = 55.9498, GNorm = 1.9383, lr_0 = 1.0804e-04
Loss = 3.0427e-04, PNorm = 55.9526, GNorm = 2.3082, lr_0 = 1.0804e-04
Loss = 3.5389e-04, PNorm = 55.9550, GNorm = 4.4338, lr_0 = 1.0804e-04
Loss = 4.6562e-04, PNorm = 55.9587, GNorm = 3.1278, lr_0 = 1.0804e-04
Loss = 4.3266e-04, PNorm = 55.9621, GNorm = 3.7563, lr_0 = 1.0804e-04
Validation rmse logD = 0.561728
Validation R2 logD = 0.796809
Epoch 99
Train function
Loss = 2.5440e-04, PNorm = 55.9658, GNorm = 0.7279, lr_0 = 1.0804e-04
Loss = 3.7234e-04, PNorm = 55.9705, GNorm = 2.3645, lr_0 = 1.0804e-04
Loss = 2.2598e-04, PNorm = 55.9739, GNorm = 0.5696, lr_0 = 1.0804e-04
Loss = 2.8301e-04, PNorm = 55.9754, GNorm = 3.6493, lr_0 = 1.0804e-04
Loss = 2.8252e-04, PNorm = 55.9779, GNorm = 2.0316, lr_0 = 1.0804e-04
Loss = 2.8417e-04, PNorm = 55.9815, GNorm = 0.7846, lr_0 = 1.0804e-04
Validation rmse logD = 0.566720
Validation R2 logD = 0.793181
Model 0 best validation rmse = 0.553476 on epoch 78
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.538159
Model 0 test R2 logD = 0.793276
Ensemble test rmse  logD= 0.538159
Ensemble test R2  logD= 0.793276
Fold 4
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_353/folds/fold_4',
 'save_smiles_splits': False,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=999, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,305,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.0344e-02, PNorm = 52.9125, GNorm = 5.6213, lr_0 = 1.0804e-04
Loss = 1.8941e-02, PNorm = 52.9151, GNorm = 3.3038, lr_0 = 1.0804e-04
Loss = 1.6229e-02, PNorm = 52.9187, GNorm = 2.7112, lr_0 = 1.0804e-04
Loss = 1.6144e-02, PNorm = 52.9221, GNorm = 1.8643, lr_0 = 1.0804e-04
Loss = 1.5308e-02, PNorm = 52.9261, GNorm = 14.6685, lr_0 = 1.0804e-04
Validation rmse logD = 1.032871
Validation R2 logD = 0.333528
Epoch 1
Train function
Loss = 1.5036e-02, PNorm = 52.9291, GNorm = 11.5736, lr_0 = 1.0804e-04
Loss = 1.3261e-02, PNorm = 52.9324, GNorm = 2.1837, lr_0 = 1.0804e-04
Loss = 1.5061e-02, PNorm = 52.9359, GNorm = 8.8702, lr_0 = 1.0804e-04
Loss = 1.3047e-02, PNorm = 52.9398, GNorm = 2.6784, lr_0 = 1.0804e-04
Loss = 1.3624e-02, PNorm = 52.9448, GNorm = 4.7279, lr_0 = 1.0804e-04
Loss = 1.4229e-02, PNorm = 52.9502, GNorm = 4.2447, lr_0 = 1.0804e-04
Validation rmse logD = 0.965754
Validation R2 logD = 0.417330
Epoch 2
Train function
Loss = 1.1685e-02, PNorm = 52.9564, GNorm = 4.2655, lr_0 = 1.0804e-04
Loss = 1.2680e-02, PNorm = 52.9626, GNorm = 1.5096, lr_0 = 1.0804e-04
Loss = 1.1851e-02, PNorm = 52.9687, GNorm = 2.6568, lr_0 = 1.0804e-04
Loss = 1.2219e-02, PNorm = 52.9759, GNorm = 2.7544, lr_0 = 1.0804e-04
Loss = 1.0939e-02, PNorm = 52.9840, GNorm = 3.7109, lr_0 = 1.0804e-04
Validation rmse logD = 0.920072
Validation R2 logD = 0.471148
Epoch 3
Train function
Loss = 1.1147e-02, PNorm = 52.9931, GNorm = 2.3242, lr_0 = 1.0804e-04
Loss = 1.0190e-02, PNorm = 53.0005, GNorm = 5.2167, lr_0 = 1.0804e-04
Loss = 1.0437e-02, PNorm = 53.0094, GNorm = 1.6822, lr_0 = 1.0804e-04
Loss = 9.2964e-03, PNorm = 53.0186, GNorm = 2.7495, lr_0 = 1.0804e-04
Loss = 1.1064e-02, PNorm = 53.0276, GNorm = 5.3823, lr_0 = 1.0804e-04
Loss = 1.0444e-02, PNorm = 53.0358, GNorm = 5.5602, lr_0 = 1.0804e-04
Validation rmse logD = 0.883938
Validation R2 logD = 0.511872
Epoch 4
Train function
Loss = 1.0793e-02, PNorm = 53.0439, GNorm = 4.0477, lr_0 = 1.0804e-04
Loss = 1.0445e-02, PNorm = 53.0510, GNorm = 5.3705, lr_0 = 1.0804e-04
Loss = 9.7240e-03, PNorm = 53.0599, GNorm = 6.6685, lr_0 = 1.0804e-04
Loss = 9.4719e-03, PNorm = 53.0681, GNorm = 2.4243, lr_0 = 1.0804e-04
Loss = 8.6776e-03, PNorm = 53.0764, GNorm = 3.1846, lr_0 = 1.0804e-04
Loss = 8.4686e-03, PNorm = 53.0876, GNorm = 1.8810, lr_0 = 1.0804e-04
Validation rmse logD = 0.842361
Validation R2 logD = 0.556711
Epoch 5
Train function
Loss = 8.0873e-03, PNorm = 53.0973, GNorm = 13.2845, lr_0 = 1.0804e-04
Loss = 9.1252e-03, PNorm = 53.1063, GNorm = 3.6430, lr_0 = 1.0804e-04
Loss = 8.3772e-03, PNorm = 53.1163, GNorm = 5.5581, lr_0 = 1.0804e-04
Loss = 6.9442e-03, PNorm = 53.1272, GNorm = 1.8695, lr_0 = 1.0804e-04
Loss = 9.0205e-03, PNorm = 53.1366, GNorm = 2.3686, lr_0 = 1.0804e-04
Validation rmse logD = 0.894730
Validation R2 logD = 0.499881
Epoch 6
Train function
Loss = 1.0364e-02, PNorm = 53.1466, GNorm = 13.7497, lr_0 = 1.0804e-04
Loss = 8.1571e-03, PNorm = 53.1561, GNorm = 2.8500, lr_0 = 1.0804e-04
Loss = 8.2010e-03, PNorm = 53.1663, GNorm = 2.3217, lr_0 = 1.0804e-04
Loss = 7.7912e-03, PNorm = 53.1764, GNorm = 7.6310, lr_0 = 1.0804e-04
Loss = 7.8686e-03, PNorm = 53.1869, GNorm = 9.8416, lr_0 = 1.0804e-04
Loss = 6.4171e-03, PNorm = 53.1961, GNorm = 4.1394, lr_0 = 1.0804e-04
Validation rmse logD = 0.778620
Validation R2 logD = 0.621260
Epoch 7
Train function
Loss = 7.8648e-03, PNorm = 53.2067, GNorm = 2.2248, lr_0 = 1.0804e-04
Loss = 7.8461e-03, PNorm = 53.2185, GNorm = 1.7882, lr_0 = 1.0804e-04
Loss = 7.1333e-03, PNorm = 53.2278, GNorm = 12.7982, lr_0 = 1.0804e-04
Loss = 6.7750e-03, PNorm = 53.2373, GNorm = 4.7794, lr_0 = 1.0804e-04
Loss = 6.7465e-03, PNorm = 53.2462, GNorm = 6.3859, lr_0 = 1.0804e-04
Loss = 6.2412e-03, PNorm = 53.2554, GNorm = 3.5653, lr_0 = 1.0804e-04
Validation rmse logD = 0.784816
Validation R2 logD = 0.615208
Epoch 8
Train function
Loss = 5.7925e-03, PNorm = 53.2625, GNorm = 2.0170, lr_0 = 1.0804e-04
Loss = 5.8177e-03, PNorm = 53.2732, GNorm = 2.1087, lr_0 = 1.0804e-04
Loss = 6.7397e-03, PNorm = 53.2859, GNorm = 2.5594, lr_0 = 1.0804e-04
Loss = 5.5660e-03, PNorm = 53.2955, GNorm = 8.2053, lr_0 = 1.0804e-04
Loss = 6.6565e-03, PNorm = 53.3048, GNorm = 2.0741, lr_0 = 1.0804e-04
Validation rmse logD = 0.760194
Validation R2 logD = 0.638974
Epoch 9
Train function
Loss = 4.1242e-03, PNorm = 53.3149, GNorm = 4.0992, lr_0 = 1.0804e-04
Loss = 5.8289e-03, PNorm = 53.3231, GNorm = 10.3214, lr_0 = 1.0804e-04
Loss = 6.6879e-03, PNorm = 53.3316, GNorm = 5.7281, lr_0 = 1.0804e-04
Loss = 5.9740e-03, PNorm = 53.3422, GNorm = 8.3280, lr_0 = 1.0804e-04
Loss = 6.4856e-03, PNorm = 53.3520, GNorm = 11.1543, lr_0 = 1.0804e-04
Loss = 4.9712e-03, PNorm = 53.3611, GNorm = 1.5694, lr_0 = 1.0804e-04
Validation rmse logD = 0.743436
Validation R2 logD = 0.654716
Epoch 10
Train function
Loss = 5.7849e-03, PNorm = 53.3697, GNorm = 2.8557, lr_0 = 1.0804e-04
Loss = 5.3239e-03, PNorm = 53.3785, GNorm = 1.7555, lr_0 = 1.0804e-04
Loss = 5.0081e-03, PNorm = 53.3880, GNorm = 2.4290, lr_0 = 1.0804e-04
Loss = 6.3603e-03, PNorm = 53.3966, GNorm = 7.8502, lr_0 = 1.0804e-04
Loss = 5.3914e-03, PNorm = 53.4037, GNorm = 6.8987, lr_0 = 1.0804e-04
Loss = 5.8552e-03, PNorm = 53.4128, GNorm = 4.2116, lr_0 = 1.0804e-04
Validation rmse logD = 0.797125
Validation R2 logD = 0.603043
Epoch 11
Train function
Loss = 5.4922e-03, PNorm = 53.4194, GNorm = 1.6929, lr_0 = 1.0804e-04
Loss = 5.5199e-03, PNorm = 53.4285, GNorm = 7.0408, lr_0 = 1.0804e-04
Loss = 5.5383e-03, PNorm = 53.4364, GNorm = 6.1209, lr_0 = 1.0804e-04
Loss = 7.2289e-03, PNorm = 53.4452, GNorm = 4.5361, lr_0 = 1.0804e-04
Loss = 5.4938e-03, PNorm = 53.4545, GNorm = 3.9682, lr_0 = 1.0804e-04
Validation rmse logD = 0.772953
Validation R2 logD = 0.626753
Epoch 12
Train function
Loss = 5.8634e-03, PNorm = 53.4643, GNorm = 7.9049, lr_0 = 1.0804e-04
Loss = 4.9777e-03, PNorm = 53.4738, GNorm = 3.5199, lr_0 = 1.0804e-04
Loss = 5.7941e-03, PNorm = 53.4831, GNorm = 2.2758, lr_0 = 1.0804e-04
Loss = 5.1639e-03, PNorm = 53.4915, GNorm = 4.3890, lr_0 = 1.0804e-04
Loss = 4.6124e-03, PNorm = 53.5003, GNorm = 5.4450, lr_0 = 1.0804e-04
Loss = 4.5386e-03, PNorm = 53.5086, GNorm = 3.7092, lr_0 = 1.0804e-04
Validation rmse logD = 0.743620
Validation R2 logD = 0.654544
Epoch 13
Train function
Loss = 4.3286e-03, PNorm = 53.5151, GNorm = 7.0589, lr_0 = 1.0804e-04
Loss = 4.7633e-03, PNorm = 53.5223, GNorm = 3.0737, lr_0 = 1.0804e-04
Loss = 4.2245e-03, PNorm = 53.5301, GNorm = 3.1305, lr_0 = 1.0804e-04
Loss = 4.5044e-03, PNorm = 53.5398, GNorm = 4.2969, lr_0 = 1.0804e-04
Loss = 4.4605e-03, PNorm = 53.5484, GNorm = 3.1459, lr_0 = 1.0804e-04
Loss = 5.8104e-03, PNorm = 53.5554, GNorm = 5.3139, lr_0 = 1.0804e-04
Validation rmse logD = 0.773719
Validation R2 logD = 0.626013
Epoch 14
Train function
Loss = 4.8391e-03, PNorm = 53.5626, GNorm = 2.7854, lr_0 = 1.0804e-04
Loss = 4.5718e-03, PNorm = 53.5701, GNorm = 7.3779, lr_0 = 1.0804e-04
Loss = 3.6333e-03, PNorm = 53.5790, GNorm = 4.5050, lr_0 = 1.0804e-04
Loss = 4.0380e-03, PNorm = 53.5888, GNorm = 6.7557, lr_0 = 1.0804e-04
Loss = 4.4989e-03, PNorm = 53.5969, GNorm = 2.6472, lr_0 = 1.0804e-04
Validation rmse logD = 0.727606
Validation R2 logD = 0.669263
Epoch 15
Train function
Loss = 3.7025e-03, PNorm = 53.6081, GNorm = 3.9643, lr_0 = 1.0804e-04
Loss = 4.3196e-03, PNorm = 53.6159, GNorm = 2.0057, lr_0 = 1.0804e-04
Loss = 4.2402e-03, PNorm = 53.6248, GNorm = 5.7526, lr_0 = 1.0804e-04
Loss = 3.8792e-03, PNorm = 53.6337, GNorm = 3.4540, lr_0 = 1.0804e-04
Loss = 3.8504e-03, PNorm = 53.6404, GNorm = 3.7400, lr_0 = 1.0804e-04
Loss = 3.9840e-03, PNorm = 53.6478, GNorm = 3.4785, lr_0 = 1.0804e-04
Validation rmse logD = 0.711517
Validation R2 logD = 0.683728
Epoch 16
Train function
Loss = 3.6292e-03, PNorm = 53.6574, GNorm = 5.4562, lr_0 = 1.0804e-04
Loss = 4.0085e-03, PNorm = 53.6652, GNorm = 8.8857, lr_0 = 1.0804e-04
Loss = 3.5812e-03, PNorm = 53.6721, GNorm = 6.2661, lr_0 = 1.0804e-04
Loss = 3.9542e-03, PNorm = 53.6812, GNorm = 1.5104, lr_0 = 1.0804e-04
Loss = 3.6228e-03, PNorm = 53.6898, GNorm = 5.8121, lr_0 = 1.0804e-04
Loss = 4.5042e-03, PNorm = 53.6984, GNorm = 3.4789, lr_0 = 1.0804e-04
Validation rmse logD = 0.695851
Validation R2 logD = 0.697502
Epoch 17
Train function
Loss = 3.4342e-03, PNorm = 53.7063, GNorm = 3.4279, lr_0 = 1.0804e-04
Loss = 4.0936e-03, PNorm = 53.7164, GNorm = 4.6103, lr_0 = 1.0804e-04
Loss = 4.1150e-03, PNorm = 53.7238, GNorm = 2.1933, lr_0 = 1.0804e-04
Loss = 3.8775e-03, PNorm = 53.7315, GNorm = 1.8984, lr_0 = 1.0804e-04
Loss = 4.2460e-03, PNorm = 53.7404, GNorm = 2.6764, lr_0 = 1.0804e-04
Validation rmse logD = 0.694208
Validation R2 logD = 0.698929
Epoch 18
Train function
Loss = 4.0022e-03, PNorm = 53.7497, GNorm = 5.4441, lr_0 = 1.0804e-04
Loss = 3.8397e-03, PNorm = 53.7591, GNorm = 2.6694, lr_0 = 1.0804e-04
Loss = 3.5152e-03, PNorm = 53.7686, GNorm = 1.8023, lr_0 = 1.0804e-04
Loss = 3.3206e-03, PNorm = 53.7775, GNorm = 1.4326, lr_0 = 1.0804e-04
Loss = 3.6079e-03, PNorm = 53.7846, GNorm = 2.2455, lr_0 = 1.0804e-04
Loss = 3.4721e-03, PNorm = 53.7921, GNorm = 1.9478, lr_0 = 1.0804e-04
Validation rmse logD = 0.683073
Validation R2 logD = 0.708510
Epoch 19
Train function
Loss = 2.4883e-03, PNorm = 53.8003, GNorm = 3.9122, lr_0 = 1.0804e-04
Loss = 3.6689e-03, PNorm = 53.8081, GNorm = 5.3011, lr_0 = 1.0804e-04
Loss = 3.5473e-03, PNorm = 53.8157, GNorm = 8.3599, lr_0 = 1.0804e-04
Loss = 3.8849e-03, PNorm = 53.8234, GNorm = 7.0871, lr_0 = 1.0804e-04
Loss = 3.6747e-03, PNorm = 53.8313, GNorm = 5.7937, lr_0 = 1.0804e-04
Loss = 3.7039e-03, PNorm = 53.8402, GNorm = 10.1827, lr_0 = 1.0804e-04
Validation rmse logD = 0.692683
Validation R2 logD = 0.700250
Epoch 20
Train function
Loss = 4.0748e-03, PNorm = 53.8478, GNorm = 10.8848, lr_0 = 1.0804e-04
Loss = 4.5202e-03, PNorm = 53.8546, GNorm = 3.3794, lr_0 = 1.0804e-04
Loss = 4.1363e-03, PNorm = 53.8637, GNorm = 3.7367, lr_0 = 1.0804e-04
Loss = 3.3430e-03, PNorm = 53.8716, GNorm = 3.4056, lr_0 = 1.0804e-04
Loss = 3.0834e-03, PNorm = 53.8807, GNorm = 5.7840, lr_0 = 1.0804e-04
Validation rmse logD = 0.691985
Validation R2 logD = 0.700854
Epoch 21
Train function
Loss = 1.9850e-03, PNorm = 53.8912, GNorm = 2.2335, lr_0 = 1.0804e-04
Loss = 2.9543e-03, PNorm = 53.8975, GNorm = 3.0147, lr_0 = 1.0804e-04
Loss = 2.9154e-03, PNorm = 53.9044, GNorm = 6.5447, lr_0 = 1.0804e-04
Loss = 3.1568e-03, PNorm = 53.9121, GNorm = 3.2945, lr_0 = 1.0804e-04
Loss = 3.4563e-03, PNorm = 53.9198, GNorm = 3.7194, lr_0 = 1.0804e-04
Loss = 3.5555e-03, PNorm = 53.9282, GNorm = 3.2528, lr_0 = 1.0804e-04
Validation rmse logD = 0.682632
Validation R2 logD = 0.708886
Epoch 22
Train function
Loss = 3.5799e-03, PNorm = 53.9351, GNorm = 5.8612, lr_0 = 1.0804e-04
Loss = 3.7509e-03, PNorm = 53.9421, GNorm = 7.6536, lr_0 = 1.0804e-04
Loss = 3.7390e-03, PNorm = 53.9505, GNorm = 5.8340, lr_0 = 1.0804e-04
Loss = 2.7129e-03, PNorm = 53.9598, GNorm = 2.4477, lr_0 = 1.0804e-04
Loss = 3.2470e-03, PNorm = 53.9687, GNorm = 3.6409, lr_0 = 1.0804e-04
Loss = 3.0827e-03, PNorm = 53.9779, GNorm = 5.4305, lr_0 = 1.0804e-04
Validation rmse logD = 0.715641
Validation R2 logD = 0.680052
Epoch 23
Train function
Loss = 3.4666e-03, PNorm = 53.9867, GNorm = 10.4880, lr_0 = 1.0804e-04
Loss = 2.5917e-03, PNorm = 53.9961, GNorm = 9.0192, lr_0 = 1.0804e-04
Loss = 3.2528e-03, PNorm = 54.0036, GNorm = 6.5043, lr_0 = 1.0804e-04
Loss = 2.8758e-03, PNorm = 54.0113, GNorm = 1.9640, lr_0 = 1.0804e-04
Loss = 2.7833e-03, PNorm = 54.0193, GNorm = 5.2643, lr_0 = 1.0804e-04
Validation rmse logD = 0.710201
Validation R2 logD = 0.684897
Epoch 24
Train function
Loss = 3.0134e-03, PNorm = 54.0247, GNorm = 6.1956, lr_0 = 1.0804e-04
Loss = 3.2545e-03, PNorm = 54.0331, GNorm = 2.0474, lr_0 = 1.0804e-04
Loss = 2.9066e-03, PNorm = 54.0425, GNorm = 4.9237, lr_0 = 1.0804e-04
Loss = 3.2048e-03, PNorm = 54.0500, GNorm = 2.5621, lr_0 = 1.0804e-04
Loss = 2.9327e-03, PNorm = 54.0584, GNorm = 4.7152, lr_0 = 1.0804e-04
Loss = 2.5380e-03, PNorm = 54.0669, GNorm = 2.1053, lr_0 = 1.0804e-04
Validation rmse logD = 0.682908
Validation R2 logD = 0.708650
Epoch 25
Train function
Loss = 2.4051e-03, PNorm = 54.0747, GNorm = 1.7788, lr_0 = 1.0804e-04
Loss = 2.5798e-03, PNorm = 54.0823, GNorm = 7.7785, lr_0 = 1.0804e-04
Loss = 2.4474e-03, PNorm = 54.0893, GNorm = 3.8993, lr_0 = 1.0804e-04
Loss = 3.0928e-03, PNorm = 54.0961, GNorm = 2.1682, lr_0 = 1.0804e-04
Loss = 2.6438e-03, PNorm = 54.1048, GNorm = 4.0423, lr_0 = 1.0804e-04
Loss = 2.8995e-03, PNorm = 54.1123, GNorm = 2.7033, lr_0 = 1.0804e-04
Validation rmse logD = 0.689577
Validation R2 logD = 0.702932
Epoch 26
Train function
Loss = 2.6806e-03, PNorm = 54.1204, GNorm = 10.0122, lr_0 = 1.0804e-04
Loss = 2.9921e-03, PNorm = 54.1270, GNorm = 6.2789, lr_0 = 1.0804e-04
Loss = 2.8346e-03, PNorm = 54.1359, GNorm = 7.3686, lr_0 = 1.0804e-04
Loss = 2.5305e-03, PNorm = 54.1437, GNorm = 3.0497, lr_0 = 1.0804e-04
Loss = 2.3511e-03, PNorm = 54.1513, GNorm = 1.5425, lr_0 = 1.0804e-04
Validation rmse logD = 0.685761
Validation R2 logD = 0.706211
Epoch 27
Train function
Loss = 2.5658e-03, PNorm = 54.1604, GNorm = 5.5408, lr_0 = 1.0804e-04
Loss = 2.0809e-03, PNorm = 54.1684, GNorm = 1.7744, lr_0 = 1.0804e-04
Loss = 2.0333e-03, PNorm = 54.1768, GNorm = 7.4323, lr_0 = 1.0804e-04
Loss = 2.4361e-03, PNorm = 54.1838, GNorm = 3.5852, lr_0 = 1.0804e-04
Loss = 2.4806e-03, PNorm = 54.1906, GNorm = 2.0696, lr_0 = 1.0804e-04
Loss = 2.5590e-03, PNorm = 54.1982, GNorm = 3.2485, lr_0 = 1.0804e-04
Validation rmse logD = 0.678768
Validation R2 logD = 0.712172
Epoch 28
Train function
Loss = 2.8638e-03, PNorm = 54.2052, GNorm = 2.5473, lr_0 = 1.0804e-04
Loss = 2.3470e-03, PNorm = 54.2138, GNorm = 2.2976, lr_0 = 1.0804e-04
Loss = 2.2096e-03, PNorm = 54.2223, GNorm = 3.5246, lr_0 = 1.0804e-04
Loss = 2.2547e-03, PNorm = 54.2298, GNorm = 3.2393, lr_0 = 1.0804e-04
Loss = 2.0535e-03, PNorm = 54.2359, GNorm = 1.6563, lr_0 = 1.0804e-04
Loss = 2.1805e-03, PNorm = 54.2423, GNorm = 3.3722, lr_0 = 1.0804e-04
Validation rmse logD = 0.678076
Validation R2 logD = 0.712758
Epoch 29
Train function
Loss = 1.7449e-03, PNorm = 54.2498, GNorm = 1.3567, lr_0 = 1.0804e-04
Loss = 2.0302e-03, PNorm = 54.2566, GNorm = 2.9107, lr_0 = 1.0804e-04
Loss = 2.1473e-03, PNorm = 54.2635, GNorm = 4.3262, lr_0 = 1.0804e-04
Loss = 1.8840e-03, PNorm = 54.2706, GNorm = 4.6190, lr_0 = 1.0804e-04
Loss = 2.3406e-03, PNorm = 54.2784, GNorm = 3.4742, lr_0 = 1.0804e-04
Validation rmse logD = 0.720558
Validation R2 logD = 0.675639
Epoch 30
Train function
Loss = 3.0364e-03, PNorm = 54.2883, GNorm = 9.0211, lr_0 = 1.0804e-04
Loss = 2.2820e-03, PNorm = 54.2958, GNorm = 1.9678, lr_0 = 1.0804e-04
Loss = 2.2302e-03, PNorm = 54.3035, GNorm = 2.0208, lr_0 = 1.0804e-04
Loss = 1.8251e-03, PNorm = 54.3119, GNorm = 2.2838, lr_0 = 1.0804e-04
Loss = 1.9743e-03, PNorm = 54.3192, GNorm = 2.4832, lr_0 = 1.0804e-04
Loss = 2.0383e-03, PNorm = 54.3279, GNorm = 4.1563, lr_0 = 1.0804e-04
Validation rmse logD = 0.701307
Validation R2 logD = 0.692739
Epoch 31
Train function
Loss = 1.9850e-03, PNorm = 54.3357, GNorm = 6.6082, lr_0 = 1.0804e-04
Loss = 1.8807e-03, PNorm = 54.3425, GNorm = 2.4249, lr_0 = 1.0804e-04
Loss = 2.1250e-03, PNorm = 54.3504, GNorm = 2.3458, lr_0 = 1.0804e-04
Loss = 1.8239e-03, PNorm = 54.3584, GNorm = 3.2431, lr_0 = 1.0804e-04
Loss = 1.9281e-03, PNorm = 54.3651, GNorm = 6.7958, lr_0 = 1.0804e-04
Loss = 1.7151e-03, PNorm = 54.3723, GNorm = 2.7456, lr_0 = 1.0804e-04
Validation rmse logD = 0.675379
Validation R2 logD = 0.715040
Epoch 32
Train function
Loss = 1.4947e-03, PNorm = 54.3790, GNorm = 1.9585, lr_0 = 1.0804e-04
Loss = 1.9358e-03, PNorm = 54.3861, GNorm = 3.2774, lr_0 = 1.0804e-04
Loss = 1.7966e-03, PNorm = 54.3924, GNorm = 3.0254, lr_0 = 1.0804e-04
Loss = 2.0365e-03, PNorm = 54.4007, GNorm = 2.1900, lr_0 = 1.0804e-04
Loss = 2.2977e-03, PNorm = 54.4071, GNorm = 8.9716, lr_0 = 1.0804e-04
Validation rmse logD = 0.698676
Validation R2 logD = 0.695041
Epoch 33
Train function
Loss = 1.7200e-03, PNorm = 54.4138, GNorm = 3.2658, lr_0 = 1.0804e-04
Loss = 2.0212e-03, PNorm = 54.4195, GNorm = 2.3451, lr_0 = 1.0804e-04
Loss = 1.8450e-03, PNorm = 54.4261, GNorm = 2.6988, lr_0 = 1.0804e-04
Loss = 1.9506e-03, PNorm = 54.4335, GNorm = 1.9418, lr_0 = 1.0804e-04
Loss = 1.8538e-03, PNorm = 54.4428, GNorm = 4.1500, lr_0 = 1.0804e-04
Loss = 1.9796e-03, PNorm = 54.4489, GNorm = 3.9580, lr_0 = 1.0804e-04
Validation rmse logD = 0.678431
Validation R2 logD = 0.712458
Epoch 34
Train function
Loss = 1.5638e-03, PNorm = 54.4564, GNorm = 1.6602, lr_0 = 1.0804e-04
Loss = 1.5937e-03, PNorm = 54.4634, GNorm = 2.7174, lr_0 = 1.0804e-04
Loss = 2.1584e-03, PNorm = 54.4695, GNorm = 6.7014, lr_0 = 1.0804e-04
Loss = 1.7773e-03, PNorm = 54.4764, GNorm = 1.3639, lr_0 = 1.0804e-04
Loss = 1.6319e-03, PNorm = 54.4836, GNorm = 1.2656, lr_0 = 1.0804e-04
Loss = 1.8318e-03, PNorm = 54.4916, GNorm = 5.6517, lr_0 = 1.0804e-04
Validation rmse logD = 0.683159
Validation R2 logD = 0.708436
Epoch 35
Train function
Loss = 1.9298e-03, PNorm = 54.4992, GNorm = 7.5860, lr_0 = 1.0804e-04
Loss = 2.1256e-03, PNorm = 54.5054, GNorm = 8.2170, lr_0 = 1.0804e-04
Loss = 1.6900e-03, PNorm = 54.5146, GNorm = 2.1343, lr_0 = 1.0804e-04
Loss = 1.6598e-03, PNorm = 54.5232, GNorm = 3.4279, lr_0 = 1.0804e-04
Loss = 1.8708e-03, PNorm = 54.5303, GNorm = 2.1825, lr_0 = 1.0804e-04
Validation rmse logD = 0.684462
Validation R2 logD = 0.707323
Epoch 36
Train function
Loss = 1.6937e-03, PNorm = 54.5377, GNorm = 1.6327, lr_0 = 1.0804e-04
Loss = 1.3335e-03, PNorm = 54.5436, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 1.5577e-03, PNorm = 54.5482, GNorm = 2.8342, lr_0 = 1.0804e-04
Loss = 1.3662e-03, PNorm = 54.5547, GNorm = 1.3589, lr_0 = 1.0804e-04
Loss = 1.5452e-03, PNorm = 54.5610, GNorm = 1.8707, lr_0 = 1.0804e-04
Loss = 2.0141e-03, PNorm = 54.5680, GNorm = 2.5758, lr_0 = 1.0804e-04
Validation rmse logD = 0.692000
Validation R2 logD = 0.700841
Epoch 37
Train function
Loss = 1.6027e-03, PNorm = 54.5759, GNorm = 4.7953, lr_0 = 1.0804e-04
Loss = 1.4183e-03, PNorm = 54.5840, GNorm = 2.2158, lr_0 = 1.0804e-04
Loss = 1.5238e-03, PNorm = 54.5905, GNorm = 4.5465, lr_0 = 1.0804e-04
Loss = 1.7365e-03, PNorm = 54.5976, GNorm = 4.4614, lr_0 = 1.0804e-04
Loss = 1.4288e-03, PNorm = 54.6041, GNorm = 2.5285, lr_0 = 1.0804e-04
Loss = 1.6546e-03, PNorm = 54.6097, GNorm = 4.4969, lr_0 = 1.0804e-04
Validation rmse logD = 0.668590
Validation R2 logD = 0.720739
Epoch 38
Train function
Loss = 1.2978e-03, PNorm = 54.6172, GNorm = 2.7599, lr_0 = 1.0804e-04
Loss = 1.2909e-03, PNorm = 54.6234, GNorm = 2.1790, lr_0 = 1.0804e-04
Loss = 1.2561e-03, PNorm = 54.6303, GNorm = 2.2774, lr_0 = 1.0804e-04
Loss = 1.2394e-03, PNorm = 54.6362, GNorm = 2.9657, lr_0 = 1.0804e-04
Loss = 1.6160e-03, PNorm = 54.6431, GNorm = 2.8796, lr_0 = 1.0804e-04
Validation rmse logD = 0.677160
Validation R2 logD = 0.713534
Epoch 39
Train function
Loss = 1.6507e-03, PNorm = 54.6500, GNorm = 3.2977, lr_0 = 1.0804e-04
Loss = 1.0917e-03, PNorm = 54.6558, GNorm = 1.8195, lr_0 = 1.0804e-04
Loss = 1.1417e-03, PNorm = 54.6623, GNorm = 2.5571, lr_0 = 1.0804e-04
Loss = 1.1413e-03, PNorm = 54.6703, GNorm = 3.1154, lr_0 = 1.0804e-04
Loss = 1.4029e-03, PNorm = 54.6766, GNorm = 6.0892, lr_0 = 1.0804e-04
Loss = 1.4492e-03, PNorm = 54.6815, GNorm = 2.2452, lr_0 = 1.0804e-04
Validation rmse logD = 0.664834
Validation R2 logD = 0.723868
Epoch 40
Train function
Loss = 1.1711e-03, PNorm = 54.6863, GNorm = 4.1613, lr_0 = 1.0804e-04
Loss = 1.3478e-03, PNorm = 54.6926, GNorm = 3.5444, lr_0 = 1.0804e-04
Loss = 1.1338e-03, PNorm = 54.7001, GNorm = 1.6998, lr_0 = 1.0804e-04
Loss = 1.2544e-03, PNorm = 54.7071, GNorm = 1.6081, lr_0 = 1.0804e-04
Loss = 1.1854e-03, PNorm = 54.7131, GNorm = 1.9141, lr_0 = 1.0804e-04
Loss = 1.3799e-03, PNorm = 54.7196, GNorm = 2.6251, lr_0 = 1.0804e-04
Validation rmse logD = 0.694670
Validation R2 logD = 0.698528
Epoch 41
Train function
Loss = 1.3943e-03, PNorm = 54.7272, GNorm = 2.1677, lr_0 = 1.0804e-04
Loss = 1.4510e-03, PNorm = 54.7333, GNorm = 3.5750, lr_0 = 1.0804e-04
Loss = 1.3555e-03, PNorm = 54.7394, GNorm = 3.2416, lr_0 = 1.0804e-04
Loss = 1.2465e-03, PNorm = 54.7460, GNorm = 3.2622, lr_0 = 1.0804e-04
Loss = 1.0596e-03, PNorm = 54.7529, GNorm = 1.5395, lr_0 = 1.0804e-04
Validation rmse logD = 0.671821
Validation R2 logD = 0.718034
Epoch 42
Train function
Loss = 7.0827e-04, PNorm = 54.7606, GNorm = 1.6338, lr_0 = 1.0804e-04
Loss = 1.6027e-03, PNorm = 54.7673, GNorm = 8.2950, lr_0 = 1.0804e-04
Loss = 1.6184e-03, PNorm = 54.7742, GNorm = 7.7914, lr_0 = 1.0804e-04
Loss = 1.6929e-03, PNorm = 54.7808, GNorm = 5.2513, lr_0 = 1.0804e-04
Loss = 1.4459e-03, PNorm = 54.7887, GNorm = 3.0838, lr_0 = 1.0804e-04
Loss = 1.2174e-03, PNorm = 54.7941, GNorm = 6.6639, lr_0 = 1.0804e-04
Validation rmse logD = 0.666526
Validation R2 logD = 0.722461
Epoch 43
Train function
Loss = 1.1856e-03, PNorm = 54.7998, GNorm = 4.2787, lr_0 = 1.0804e-04
Loss = 1.0657e-03, PNorm = 54.8063, GNorm = 1.6800, lr_0 = 1.0804e-04
Loss = 1.4946e-03, PNorm = 54.8119, GNorm = 6.3543, lr_0 = 1.0804e-04
Loss = 1.3284e-03, PNorm = 54.8188, GNorm = 3.4880, lr_0 = 1.0804e-04
Loss = 1.1713e-03, PNorm = 54.8248, GNorm = 1.4487, lr_0 = 1.0804e-04
Loss = 1.1991e-03, PNorm = 54.8328, GNorm = 1.5874, lr_0 = 1.0804e-04
Validation rmse logD = 0.692613
Validation R2 logD = 0.700311
Epoch 44
Train function
Loss = 1.4869e-03, PNorm = 54.8389, GNorm = 5.3142, lr_0 = 1.0804e-04
Loss = 1.2675e-03, PNorm = 54.8440, GNorm = 5.4590, lr_0 = 1.0804e-04
Loss = 1.2154e-03, PNorm = 54.8503, GNorm = 1.5730, lr_0 = 1.0804e-04
Loss = 1.2527e-03, PNorm = 54.8582, GNorm = 1.3236, lr_0 = 1.0804e-04
Loss = 9.5758e-04, PNorm = 54.8640, GNorm = 1.2703, lr_0 = 1.0804e-04
Validation rmse logD = 0.659957
Validation R2 logD = 0.727905
Epoch 45
Train function
Loss = 1.1914e-03, PNorm = 54.8705, GNorm = 3.6497, lr_0 = 1.0804e-04
Loss = 9.9209e-04, PNorm = 54.8773, GNorm = 1.1819, lr_0 = 1.0804e-04
Loss = 1.0550e-03, PNorm = 54.8834, GNorm = 1.8066, lr_0 = 1.0804e-04
Loss = 1.0883e-03, PNorm = 54.8879, GNorm = 1.3260, lr_0 = 1.0804e-04
Loss = 1.0008e-03, PNorm = 54.8930, GNorm = 3.1818, lr_0 = 1.0804e-04
Loss = 9.7585e-04, PNorm = 54.8994, GNorm = 3.5975, lr_0 = 1.0804e-04
Validation rmse logD = 0.671435
Validation R2 logD = 0.718358
Epoch 46
Train function
Loss = 8.4095e-04, PNorm = 54.9053, GNorm = 2.5906, lr_0 = 1.0804e-04
Loss = 1.1728e-03, PNorm = 54.9106, GNorm = 4.5765, lr_0 = 1.0804e-04
Loss = 9.5766e-04, PNorm = 54.9150, GNorm = 1.5720, lr_0 = 1.0804e-04
Loss = 1.0309e-03, PNorm = 54.9208, GNorm = 1.5208, lr_0 = 1.0804e-04
Loss = 9.7386e-04, PNorm = 54.9269, GNorm = 3.4698, lr_0 = 1.0804e-04
Loss = 9.3127e-04, PNorm = 54.9340, GNorm = 1.1446, lr_0 = 1.0804e-04
Validation rmse logD = 0.671675
Validation R2 logD = 0.718157
Epoch 47
Train function
Loss = 7.5206e-04, PNorm = 54.9393, GNorm = 1.5411, lr_0 = 1.0804e-04
Loss = 8.8687e-04, PNorm = 54.9450, GNorm = 3.9491, lr_0 = 1.0804e-04
Loss = 8.9615e-04, PNorm = 54.9518, GNorm = 1.9095, lr_0 = 1.0804e-04
Loss = 1.1148e-03, PNorm = 54.9573, GNorm = 3.5226, lr_0 = 1.0804e-04
Loss = 1.3416e-03, PNorm = 54.9626, GNorm = 7.8969, lr_0 = 1.0804e-04
Validation rmse logD = 0.691050
Validation R2 logD = 0.701661
Epoch 48
Train function
Loss = 1.4328e-03, PNorm = 54.9689, GNorm = 7.7834, lr_0 = 1.0804e-04
Loss = 1.0198e-03, PNorm = 54.9744, GNorm = 2.7303, lr_0 = 1.0804e-04
Loss = 1.1358e-03, PNorm = 54.9808, GNorm = 2.1854, lr_0 = 1.0804e-04
Loss = 1.0313e-03, PNorm = 54.9885, GNorm = 3.0575, lr_0 = 1.0804e-04
Loss = 1.0300e-03, PNorm = 54.9951, GNorm = 2.8465, lr_0 = 1.0804e-04
Loss = 1.0085e-03, PNorm = 55.0007, GNorm = 2.6015, lr_0 = 1.0804e-04
Validation rmse logD = 0.681000
Validation R2 logD = 0.710276
Epoch 49
Train function
Loss = 9.7935e-04, PNorm = 55.0067, GNorm = 3.8754, lr_0 = 1.0804e-04
Loss = 9.5804e-04, PNorm = 55.0116, GNorm = 6.3943, lr_0 = 1.0804e-04
Loss = 9.2755e-04, PNorm = 55.0170, GNorm = 6.0386, lr_0 = 1.0804e-04
Loss = 1.1080e-03, PNorm = 55.0221, GNorm = 1.3259, lr_0 = 1.0804e-04
Loss = 9.4534e-04, PNorm = 55.0264, GNorm = 5.3295, lr_0 = 1.0804e-04
Loss = 1.2784e-03, PNorm = 55.0319, GNorm = 3.7727, lr_0 = 1.0804e-04
Validation rmse logD = 0.687031
Validation R2 logD = 0.705121
Epoch 50
Train function
Loss = 7.7223e-04, PNorm = 55.0375, GNorm = 1.2227, lr_0 = 1.0804e-04
Loss = 9.5265e-04, PNorm = 55.0429, GNorm = 2.1186, lr_0 = 1.0804e-04
Loss = 8.5517e-04, PNorm = 55.0493, GNorm = 4.6479, lr_0 = 1.0804e-04
Loss = 9.4694e-04, PNorm = 55.0549, GNorm = 2.3895, lr_0 = 1.0804e-04
Loss = 7.6828e-04, PNorm = 55.0611, GNorm = 5.2295, lr_0 = 1.0804e-04
Validation rmse logD = 0.669881
Validation R2 logD = 0.719660
Epoch 51
Train function
Loss = 6.2663e-04, PNorm = 55.0656, GNorm = 2.6462, lr_0 = 1.0804e-04
Loss = 8.9001e-04, PNorm = 55.0699, GNorm = 2.5139, lr_0 = 1.0804e-04
Loss = 8.4171e-04, PNorm = 55.0763, GNorm = 5.8431, lr_0 = 1.0804e-04
Loss = 7.4487e-04, PNorm = 55.0817, GNorm = 1.3802, lr_0 = 1.0804e-04
Loss = 7.4619e-04, PNorm = 55.0868, GNorm = 2.4748, lr_0 = 1.0804e-04
Loss = 9.3372e-04, PNorm = 55.0924, GNorm = 4.9036, lr_0 = 1.0804e-04
Validation rmse logD = 0.691914
Validation R2 logD = 0.700915
Epoch 52
Train function
Loss = 8.1809e-04, PNorm = 55.0986, GNorm = 4.9066, lr_0 = 1.0804e-04
Loss = 7.8440e-04, PNorm = 55.1039, GNorm = 1.0767, lr_0 = 1.0804e-04
Loss = 8.2939e-04, PNorm = 55.1087, GNorm = 2.4199, lr_0 = 1.0804e-04
Loss = 8.0894e-04, PNorm = 55.1144, GNorm = 4.5320, lr_0 = 1.0804e-04
Loss = 8.8851e-04, PNorm = 55.1193, GNorm = 2.3416, lr_0 = 1.0804e-04
Loss = 9.0672e-04, PNorm = 55.1244, GNorm = 3.0661, lr_0 = 1.0804e-04
Validation rmse logD = 0.661555
Validation R2 logD = 0.726585
Epoch 53
Train function
Loss = 7.0286e-04, PNorm = 55.1302, GNorm = 2.1209, lr_0 = 1.0804e-04
Loss = 6.7665e-04, PNorm = 55.1348, GNorm = 1.3118, lr_0 = 1.0804e-04
Loss = 7.9652e-04, PNorm = 55.1404, GNorm = 5.0874, lr_0 = 1.0804e-04
Loss = 1.0269e-03, PNorm = 55.1453, GNorm = 6.2012, lr_0 = 1.0804e-04
Loss = 1.1249e-03, PNorm = 55.1497, GNorm = 6.9023, lr_0 = 1.0804e-04
Validation rmse logD = 0.662018
Validation R2 logD = 0.726202
Epoch 54
Train function
Loss = 6.5343e-04, PNorm = 55.1550, GNorm = 0.8906, lr_0 = 1.0804e-04
Loss = 7.5444e-04, PNorm = 55.1603, GNorm = 1.5048, lr_0 = 1.0804e-04
Loss = 8.2319e-04, PNorm = 55.1654, GNorm = 3.2321, lr_0 = 1.0804e-04
Loss = 7.4288e-04, PNorm = 55.1698, GNorm = 3.4382, lr_0 = 1.0804e-04
Loss = 1.0227e-03, PNorm = 55.1738, GNorm = 7.8313, lr_0 = 1.0804e-04
Loss = 1.2044e-03, PNorm = 55.1790, GNorm = 3.2079, lr_0 = 1.0804e-04
Validation rmse logD = 0.670629
Validation R2 logD = 0.719034
Epoch 55
Train function
Loss = 8.4701e-04, PNorm = 55.1856, GNorm = 2.3376, lr_0 = 1.0804e-04
Loss = 7.9580e-04, PNorm = 55.1904, GNorm = 1.6313, lr_0 = 1.0804e-04
Loss = 7.1874e-04, PNorm = 55.1966, GNorm = 2.2131, lr_0 = 1.0804e-04
Loss = 7.4293e-04, PNorm = 55.2007, GNorm = 1.8371, lr_0 = 1.0804e-04
Loss = 6.8447e-04, PNorm = 55.2052, GNorm = 1.5852, lr_0 = 1.0804e-04
Loss = 7.0470e-04, PNorm = 55.2104, GNorm = 1.5630, lr_0 = 1.0804e-04
Validation rmse logD = 0.668204
Validation R2 logD = 0.721062
Epoch 56
Train function
Loss = 5.6415e-04, PNorm = 55.2159, GNorm = 1.3972, lr_0 = 1.0804e-04
Loss = 6.8443e-04, PNorm = 55.2209, GNorm = 5.4813, lr_0 = 1.0804e-04
Loss = 7.1288e-04, PNorm = 55.2246, GNorm = 3.3297, lr_0 = 1.0804e-04
Loss = 8.7588e-04, PNorm = 55.2290, GNorm = 2.4668, lr_0 = 1.0804e-04
Loss = 7.8800e-04, PNorm = 55.2332, GNorm = 1.6921, lr_0 = 1.0804e-04
Validation rmse logD = 0.655868
Validation R2 logD = 0.731266
Epoch 57
Train function
Loss = 8.9520e-04, PNorm = 55.2384, GNorm = 1.3709, lr_0 = 1.0804e-04
Loss = 5.8320e-04, PNorm = 55.2434, GNorm = 3.4675, lr_0 = 1.0804e-04
Loss = 5.7594e-04, PNorm = 55.2478, GNorm = 3.3706, lr_0 = 1.0804e-04
Loss = 7.0781e-04, PNorm = 55.2523, GNorm = 2.1079, lr_0 = 1.0804e-04
Loss = 5.7489e-04, PNorm = 55.2573, GNorm = 0.9723, lr_0 = 1.0804e-04
Loss = 8.4299e-04, PNorm = 55.2613, GNorm = 3.7307, lr_0 = 1.0804e-04
Validation rmse logD = 0.675427
Validation R2 logD = 0.714998
Epoch 58
Train function
Loss = 6.9919e-04, PNorm = 55.2652, GNorm = 2.8811, lr_0 = 1.0804e-04
Loss = 8.3843e-04, PNorm = 55.2711, GNorm = 2.4126, lr_0 = 1.0804e-04
Loss = 7.6034e-04, PNorm = 55.2759, GNorm = 4.4071, lr_0 = 1.0804e-04
Loss = 9.4085e-04, PNorm = 55.2813, GNorm = 7.0578, lr_0 = 1.0804e-04
Loss = 9.3206e-04, PNorm = 55.2853, GNorm = 5.8737, lr_0 = 1.0804e-04
Loss = 7.7399e-04, PNorm = 55.2904, GNorm = 2.0040, lr_0 = 1.0804e-04
Validation rmse logD = 0.664581
Validation R2 logD = 0.724078
Epoch 59
Train function
Loss = 5.3626e-04, PNorm = 55.2968, GNorm = 1.2971, lr_0 = 1.0804e-04
Loss = 6.6434e-04, PNorm = 55.3019, GNorm = 4.8044, lr_0 = 1.0804e-04
Loss = 8.6052e-04, PNorm = 55.3053, GNorm = 4.3813, lr_0 = 1.0804e-04
Loss = 1.0286e-03, PNorm = 55.3089, GNorm = 4.0025, lr_0 = 1.0804e-04
Loss = 6.1497e-04, PNorm = 55.3137, GNorm = 3.2508, lr_0 = 1.0804e-04
Validation rmse logD = 0.675403
Validation R2 logD = 0.715019
Epoch 60
Train function
Loss = 8.0861e-04, PNorm = 55.3186, GNorm = 5.1964, lr_0 = 1.0804e-04
Loss = 5.5810e-04, PNorm = 55.3225, GNorm = 3.5275, lr_0 = 1.0804e-04
Loss = 5.8224e-04, PNorm = 55.3272, GNorm = 1.0966, lr_0 = 1.0804e-04
Loss = 7.1683e-04, PNorm = 55.3319, GNorm = 5.3341, lr_0 = 1.0804e-04
Loss = 7.2729e-04, PNorm = 55.3352, GNorm = 2.2162, lr_0 = 1.0804e-04
Loss = 6.5588e-04, PNorm = 55.3409, GNorm = 2.6254, lr_0 = 1.0804e-04
Validation rmse logD = 0.652898
Validation R2 logD = 0.733694
Epoch 61
Train function
Loss = 7.7636e-04, PNorm = 55.3453, GNorm = 6.8461, lr_0 = 1.0804e-04
Loss = 1.1060e-03, PNorm = 55.3480, GNorm = 4.9667, lr_0 = 1.0804e-04
Loss = 8.8480e-04, PNorm = 55.3534, GNorm = 1.7268, lr_0 = 1.0804e-04
Loss = 9.2365e-04, PNorm = 55.3576, GNorm = 3.3967, lr_0 = 1.0804e-04
Loss = 1.1511e-03, PNorm = 55.3620, GNorm = 6.9591, lr_0 = 1.0804e-04
Loss = 1.1533e-03, PNorm = 55.3682, GNorm = 0.8529, lr_0 = 1.0804e-04
Validation rmse logD = 0.671436
Validation R2 logD = 0.718357
Epoch 62
Train function
Loss = 6.3600e-04, PNorm = 55.3750, GNorm = 3.8168, lr_0 = 1.0804e-04
Loss = 5.3132e-04, PNorm = 55.3797, GNorm = 1.6998, lr_0 = 1.0804e-04
Loss = 5.2208e-04, PNorm = 55.3850, GNorm = 2.8420, lr_0 = 1.0804e-04
Loss = 6.4087e-04, PNorm = 55.3892, GNorm = 3.0505, lr_0 = 1.0804e-04
Loss = 6.5146e-04, PNorm = 55.3936, GNorm = 1.9568, lr_0 = 1.0804e-04
Validation rmse logD = 0.653842
Validation R2 logD = 0.732923
Epoch 63
Train function
Loss = 3.8231e-04, PNorm = 55.3972, GNorm = 0.7749, lr_0 = 1.0804e-04
Loss = 6.2105e-04, PNorm = 55.4010, GNorm = 0.7175, lr_0 = 1.0804e-04
Loss = 3.9934e-04, PNorm = 55.4061, GNorm = 0.7125, lr_0 = 1.0804e-04
Loss = 5.2848e-04, PNorm = 55.4101, GNorm = 2.7968, lr_0 = 1.0804e-04
Loss = 5.5016e-04, PNorm = 55.4136, GNorm = 2.6479, lr_0 = 1.0804e-04
Loss = 6.2412e-04, PNorm = 55.4174, GNorm = 1.4399, lr_0 = 1.0804e-04
Validation rmse logD = 0.661636
Validation R2 logD = 0.726518
Epoch 64
Train function
Loss = 4.8372e-04, PNorm = 55.4216, GNorm = 1.3591, lr_0 = 1.0804e-04
Loss = 6.0044e-04, PNorm = 55.4253, GNorm = 1.8473, lr_0 = 1.0804e-04
Loss = 5.5241e-04, PNorm = 55.4291, GNorm = 1.5684, lr_0 = 1.0804e-04
Loss = 5.3911e-04, PNorm = 55.4347, GNorm = 1.9875, lr_0 = 1.0804e-04
Loss = 4.7022e-04, PNorm = 55.4383, GNorm = 2.2368, lr_0 = 1.0804e-04
Loss = 6.0394e-04, PNorm = 55.4426, GNorm = 0.7996, lr_0 = 1.0804e-04
Validation rmse logD = 0.653210
Validation R2 logD = 0.733439
Epoch 65
Train function
Loss = 4.0383e-04, PNorm = 55.4450, GNorm = 1.3242, lr_0 = 1.0804e-04
Loss = 5.0507e-04, PNorm = 55.4487, GNorm = 2.5314, lr_0 = 1.0804e-04
Loss = 5.0236e-04, PNorm = 55.4535, GNorm = 1.5252, lr_0 = 1.0804e-04
Loss = 4.3068e-04, PNorm = 55.4574, GNorm = 1.9520, lr_0 = 1.0804e-04
Loss = 4.8935e-04, PNorm = 55.4615, GNorm = 1.1935, lr_0 = 1.0804e-04
Validation rmse logD = 0.654157
Validation R2 logD = 0.732666
Epoch 66
Train function
Loss = 3.2860e-04, PNorm = 55.4651, GNorm = 0.8988, lr_0 = 1.0804e-04
Loss = 5.2343e-04, PNorm = 55.4699, GNorm = 3.9012, lr_0 = 1.0804e-04
Loss = 5.7675e-04, PNorm = 55.4740, GNorm = 2.3780, lr_0 = 1.0804e-04
Loss = 4.5633e-04, PNorm = 55.4772, GNorm = 1.6089, lr_0 = 1.0804e-04
Loss = 4.2227e-04, PNorm = 55.4809, GNorm = 2.2244, lr_0 = 1.0804e-04
Loss = 5.4220e-04, PNorm = 55.4844, GNorm = 5.4555, lr_0 = 1.0804e-04
Validation rmse logD = 0.665122
Validation R2 logD = 0.723629
Epoch 67
Train function
Loss = 4.1323e-04, PNorm = 55.4878, GNorm = 1.2420, lr_0 = 1.0804e-04
Loss = 4.1131e-04, PNorm = 55.4914, GNorm = 0.5664, lr_0 = 1.0804e-04
Loss = 4.9428e-04, PNorm = 55.4951, GNorm = 0.9117, lr_0 = 1.0804e-04
Loss = 4.1030e-04, PNorm = 55.4991, GNorm = 1.1130, lr_0 = 1.0804e-04
Loss = 4.1944e-04, PNorm = 55.5027, GNorm = 3.5310, lr_0 = 1.0804e-04
Loss = 5.0278e-04, PNorm = 55.5062, GNorm = 4.9641, lr_0 = 1.0804e-04
Validation rmse logD = 0.676256
Validation R2 logD = 0.714299
Epoch 68
Train function
Loss = 5.7148e-04, PNorm = 55.5107, GNorm = 3.9359, lr_0 = 1.0804e-04
Loss = 5.3084e-04, PNorm = 55.5143, GNorm = 5.0357, lr_0 = 1.0804e-04
Loss = 4.9226e-04, PNorm = 55.5187, GNorm = 0.9617, lr_0 = 1.0804e-04
Loss = 6.2883e-04, PNorm = 55.5224, GNorm = 3.5476, lr_0 = 1.0804e-04
Loss = 5.4891e-04, PNorm = 55.5266, GNorm = 2.5468, lr_0 = 1.0804e-04
Validation rmse logD = 0.659542
Validation R2 logD = 0.728247
Epoch 69
Train function
Loss = 3.4855e-04, PNorm = 55.5301, GNorm = 2.4544, lr_0 = 1.0804e-04
Loss = 6.2020e-04, PNorm = 55.5340, GNorm = 2.4494, lr_0 = 1.0804e-04
Loss = 6.1349e-04, PNorm = 55.5374, GNorm = 7.3342, lr_0 = 1.0804e-04
Loss = 7.0805e-04, PNorm = 55.5431, GNorm = 5.0179, lr_0 = 1.0804e-04
Loss = 4.5630e-04, PNorm = 55.5472, GNorm = 1.3011, lr_0 = 1.0804e-04
Loss = 4.7184e-04, PNorm = 55.5520, GNorm = 1.1709, lr_0 = 1.0804e-04
Validation rmse logD = 0.665091
Validation R2 logD = 0.723655
Epoch 70
Train function
Loss = 4.0057e-04, PNorm = 55.5565, GNorm = 1.0280, lr_0 = 1.0804e-04
Loss = 4.1757e-04, PNorm = 55.5602, GNorm = 3.0130, lr_0 = 1.0804e-04
Loss = 5.3738e-04, PNorm = 55.5634, GNorm = 4.0386, lr_0 = 1.0804e-04
Loss = 4.1150e-04, PNorm = 55.5668, GNorm = 1.2500, lr_0 = 1.0804e-04
Loss = 6.4261e-04, PNorm = 55.5696, GNorm = 3.6504, lr_0 = 1.0804e-04
Loss = 7.0400e-04, PNorm = 55.5705, GNorm = 1.1043, lr_0 = 1.0804e-04
Validation rmse logD = 0.661637
Validation R2 logD = 0.726517
Epoch 71
Train function
Loss = 5.6706e-04, PNorm = 55.5751, GNorm = 4.7917, lr_0 = 1.0804e-04
Loss = 5.3920e-04, PNorm = 55.5801, GNorm = 2.3147, lr_0 = 1.0804e-04
Loss = 7.3107e-04, PNorm = 55.5837, GNorm = 4.8877, lr_0 = 1.0804e-04
Loss = 8.2889e-04, PNorm = 55.5886, GNorm = 2.7416, lr_0 = 1.0804e-04
Loss = 5.3929e-04, PNorm = 55.5939, GNorm = 2.6854, lr_0 = 1.0804e-04
Validation rmse logD = 0.662648
Validation R2 logD = 0.725681
Epoch 72
Train function
Loss = 5.4394e-04, PNorm = 55.5990, GNorm = 3.4419, lr_0 = 1.0804e-04
Loss = 5.4612e-04, PNorm = 55.6034, GNorm = 1.9033, lr_0 = 1.0804e-04
Loss = 4.2920e-04, PNorm = 55.6057, GNorm = 1.4665, lr_0 = 1.0804e-04
Loss = 3.8511e-04, PNorm = 55.6100, GNorm = 2.4147, lr_0 = 1.0804e-04
Loss = 3.9601e-04, PNorm = 55.6144, GNorm = 2.3015, lr_0 = 1.0804e-04
Loss = 4.8804e-04, PNorm = 55.6187, GNorm = 2.6532, lr_0 = 1.0804e-04
Validation rmse logD = 0.651974
Validation R2 logD = 0.734447
Epoch 73
Train function
Loss = 4.6844e-04, PNorm = 55.6217, GNorm = 3.2757, lr_0 = 1.0804e-04
Loss = 4.9775e-04, PNorm = 55.6254, GNorm = 1.4610, lr_0 = 1.0804e-04
Loss = 4.9457e-04, PNorm = 55.6288, GNorm = 2.3813, lr_0 = 1.0804e-04
Loss = 4.1849e-04, PNorm = 55.6327, GNorm = 2.6109, lr_0 = 1.0804e-04
Loss = 4.3395e-04, PNorm = 55.6361, GNorm = 1.9057, lr_0 = 1.0804e-04
Loss = 6.4453e-04, PNorm = 55.6393, GNorm = 5.2412, lr_0 = 1.0804e-04
Validation rmse logD = 0.656109
Validation R2 logD = 0.731069
Epoch 74
Train function
Loss = 6.8210e-04, PNorm = 55.6437, GNorm = 2.4653, lr_0 = 1.0804e-04
Loss = 6.3826e-04, PNorm = 55.6474, GNorm = 5.1344, lr_0 = 1.0804e-04
Loss = 5.4485e-04, PNorm = 55.6524, GNorm = 1.8709, lr_0 = 1.0804e-04
Loss = 4.3933e-04, PNorm = 55.6582, GNorm = 1.1227, lr_0 = 1.0804e-04
Loss = 6.9138e-04, PNorm = 55.6620, GNorm = 6.0374, lr_0 = 1.0804e-04
Validation rmse logD = 0.675694
Validation R2 logD = 0.714774
Epoch 75
Train function
Loss = 9.8212e-04, PNorm = 55.6657, GNorm = 6.1960, lr_0 = 1.0804e-04
Loss = 7.3044e-04, PNorm = 55.6697, GNorm = 6.4844, lr_0 = 1.0804e-04
Loss = 4.9924e-04, PNorm = 55.6733, GNorm = 2.4320, lr_0 = 1.0804e-04
Loss = 5.9293e-04, PNorm = 55.6769, GNorm = 1.8314, lr_0 = 1.0804e-04
Loss = 6.3078e-04, PNorm = 55.6813, GNorm = 2.1975, lr_0 = 1.0804e-04
Loss = 5.0380e-04, PNorm = 55.6853, GNorm = 2.5253, lr_0 = 1.0804e-04
Validation rmse logD = 0.648163
Validation R2 logD = 0.737543
Epoch 76
Train function
Loss = 3.2407e-04, PNorm = 55.6894, GNorm = 0.9517, lr_0 = 1.0804e-04
Loss = 2.8286e-04, PNorm = 55.6936, GNorm = 1.1017, lr_0 = 1.0804e-04
Loss = 3.5718e-04, PNorm = 55.6971, GNorm = 0.8981, lr_0 = 1.0804e-04
Loss = 4.1652e-04, PNorm = 55.7002, GNorm = 1.1204, lr_0 = 1.0804e-04
Loss = 5.0635e-04, PNorm = 55.7034, GNorm = 4.3689, lr_0 = 1.0804e-04
Loss = 6.2595e-04, PNorm = 55.7048, GNorm = 3.0214, lr_0 = 1.0804e-04
Validation rmse logD = 0.657645
Validation R2 logD = 0.729808
Epoch 77
Train function
Loss = 6.1580e-04, PNorm = 55.7091, GNorm = 5.6063, lr_0 = 1.0804e-04
Loss = 5.7214e-04, PNorm = 55.7136, GNorm = 5.8161, lr_0 = 1.0804e-04
Loss = 8.8612e-04, PNorm = 55.7175, GNorm = 7.8044, lr_0 = 1.0804e-04
Loss = 6.7722e-04, PNorm = 55.7212, GNorm = 1.6067, lr_0 = 1.0804e-04
Loss = 5.0032e-04, PNorm = 55.7255, GNorm = 1.9590, lr_0 = 1.0804e-04
Validation rmse logD = 0.654926
Validation R2 logD = 0.732037
Epoch 78
Train function
Loss = 3.0193e-04, PNorm = 55.7297, GNorm = 0.9594, lr_0 = 1.0804e-04
Loss = 3.6137e-04, PNorm = 55.7333, GNorm = 1.0223, lr_0 = 1.0804e-04
Loss = 3.5906e-04, PNorm = 55.7362, GNorm = 0.8067, lr_0 = 1.0804e-04
Loss = 3.8513e-04, PNorm = 55.7392, GNorm = 1.0899, lr_0 = 1.0804e-04
Loss = 3.7965e-04, PNorm = 55.7428, GNorm = 1.7342, lr_0 = 1.0804e-04
Loss = 3.9907e-04, PNorm = 55.7468, GNorm = 0.8994, lr_0 = 1.0804e-04
Validation rmse logD = 0.679480
Validation R2 logD = 0.711568
Epoch 79
Train function
Loss = 4.8706e-04, PNorm = 55.7489, GNorm = 3.0019, lr_0 = 1.0804e-04
Loss = 3.5231e-04, PNorm = 55.7516, GNorm = 1.9313, lr_0 = 1.0804e-04
Loss = 3.0232e-04, PNorm = 55.7555, GNorm = 3.5912, lr_0 = 1.0804e-04
Loss = 3.8745e-04, PNorm = 55.7580, GNorm = 3.8523, lr_0 = 1.0804e-04
Loss = 4.6694e-04, PNorm = 55.7615, GNorm = 1.0958, lr_0 = 1.0804e-04
Loss = 3.5027e-04, PNorm = 55.7653, GNorm = 1.7938, lr_0 = 1.0804e-04
Validation rmse logD = 0.655078
Validation R2 logD = 0.731913
Epoch 80
Train function
Loss = 4.7966e-04, PNorm = 55.7676, GNorm = 2.5958, lr_0 = 1.0804e-04
Loss = 4.2342e-04, PNorm = 55.7711, GNorm = 2.2046, lr_0 = 1.0804e-04
Loss = 3.4418e-04, PNorm = 55.7745, GNorm = 1.5473, lr_0 = 1.0804e-04
Loss = 2.8615e-04, PNorm = 55.7779, GNorm = 1.2295, lr_0 = 1.0804e-04
Loss = 3.1100e-04, PNorm = 55.7808, GNorm = 1.4092, lr_0 = 1.0804e-04
Validation rmse logD = 0.655371
Validation R2 logD = 0.731673
Epoch 81
Train function
Loss = 2.4832e-04, PNorm = 55.7846, GNorm = 2.5138, lr_0 = 1.0804e-04
Loss = 3.6280e-04, PNorm = 55.7871, GNorm = 2.2744, lr_0 = 1.0804e-04
Loss = 2.7670e-04, PNorm = 55.7901, GNorm = 0.7100, lr_0 = 1.0804e-04
Loss = 2.8609e-04, PNorm = 55.7934, GNorm = 1.5264, lr_0 = 1.0804e-04
Loss = 3.8275e-04, PNorm = 55.7957, GNorm = 1.0105, lr_0 = 1.0804e-04
Loss = 3.4583e-04, PNorm = 55.7995, GNorm = 2.1883, lr_0 = 1.0804e-04
Validation rmse logD = 0.646176
Validation R2 logD = 0.739150
Epoch 82
Train function
Loss = 2.5052e-04, PNorm = 55.8024, GNorm = 1.8559, lr_0 = 1.0804e-04
Loss = 3.7095e-04, PNorm = 55.8048, GNorm = 3.0559, lr_0 = 1.0804e-04
Loss = 3.4802e-04, PNorm = 55.8080, GNorm = 0.9436, lr_0 = 1.0804e-04
Loss = 2.5926e-04, PNorm = 55.8117, GNorm = 0.5923, lr_0 = 1.0804e-04
Loss = 3.1441e-04, PNorm = 55.8153, GNorm = 1.6845, lr_0 = 1.0804e-04
Loss = 2.8897e-04, PNorm = 55.8187, GNorm = 1.9396, lr_0 = 1.0804e-04
Validation rmse logD = 0.651362
Validation R2 logD = 0.734945
Epoch 83
Train function
Loss = 2.4670e-04, PNorm = 55.8216, GNorm = 0.8800, lr_0 = 1.0804e-04
Loss = 2.3019e-04, PNorm = 55.8237, GNorm = 0.9873, lr_0 = 1.0804e-04
Loss = 2.3500e-04, PNorm = 55.8256, GNorm = 0.7730, lr_0 = 1.0804e-04
Loss = 2.7523e-04, PNorm = 55.8283, GNorm = 1.9959, lr_0 = 1.0804e-04
Loss = 2.9399e-04, PNorm = 55.8313, GNorm = 0.9030, lr_0 = 1.0804e-04
Validation rmse logD = 0.659562
Validation R2 logD = 0.728231
Epoch 84
Train function
Loss = 2.5201e-04, PNorm = 55.8346, GNorm = 0.6676, lr_0 = 1.0804e-04
Loss = 2.0279e-04, PNorm = 55.8371, GNorm = 1.3769, lr_0 = 1.0804e-04
Loss = 3.2504e-04, PNorm = 55.8392, GNorm = 0.8965, lr_0 = 1.0804e-04
Loss = 4.7701e-04, PNorm = 55.8419, GNorm = 3.6074, lr_0 = 1.0804e-04
Loss = 2.9523e-04, PNorm = 55.8452, GNorm = 0.9320, lr_0 = 1.0804e-04
Loss = 4.0232e-04, PNorm = 55.8483, GNorm = 2.2162, lr_0 = 1.0804e-04
Validation rmse logD = 0.651321
Validation R2 logD = 0.734979
Epoch 85
Train function
Loss = 3.3176e-04, PNorm = 55.8514, GNorm = 1.9022, lr_0 = 1.0804e-04
Loss = 3.6572e-04, PNorm = 55.8540, GNorm = 3.5358, lr_0 = 1.0804e-04
Loss = 2.9794e-04, PNorm = 55.8564, GNorm = 3.0366, lr_0 = 1.0804e-04
Loss = 3.6436e-04, PNorm = 55.8591, GNorm = 1.8752, lr_0 = 1.0804e-04
Loss = 2.6400e-04, PNorm = 55.8627, GNorm = 1.8288, lr_0 = 1.0804e-04
Loss = 2.6836e-04, PNorm = 55.8647, GNorm = 1.2516, lr_0 = 1.0804e-04
Validation rmse logD = 0.648544
Validation R2 logD = 0.737234
Epoch 86
Train function
Loss = 3.6538e-04, PNorm = 55.8669, GNorm = 2.1520, lr_0 = 1.0804e-04
Loss = 4.8261e-04, PNorm = 55.8703, GNorm = 3.2993, lr_0 = 1.0804e-04
Loss = 3.2283e-04, PNorm = 55.8745, GNorm = 4.0481, lr_0 = 1.0804e-04
Loss = 3.0744e-04, PNorm = 55.8776, GNorm = 3.2256, lr_0 = 1.0804e-04
Loss = 2.6937e-04, PNorm = 55.8823, GNorm = 1.0815, lr_0 = 1.0804e-04
Validation rmse logD = 0.648733
Validation R2 logD = 0.737081
Epoch 87
Train function
Loss = 2.8611e-04, PNorm = 55.8859, GNorm = 2.4941, lr_0 = 1.0804e-04
Loss = 2.7169e-04, PNorm = 55.8884, GNorm = 0.7215, lr_0 = 1.0804e-04
Loss = 3.1829e-04, PNorm = 55.8910, GNorm = 3.8455, lr_0 = 1.0804e-04
Loss = 3.5923e-04, PNorm = 55.8934, GNorm = 2.0212, lr_0 = 1.0804e-04
Loss = 3.2506e-04, PNorm = 55.8962, GNorm = 0.6143, lr_0 = 1.0804e-04
Loss = 3.0748e-04, PNorm = 55.8998, GNorm = 0.9197, lr_0 = 1.0804e-04
Validation rmse logD = 0.667279
Validation R2 logD = 0.721834
Epoch 88
Train function
Loss = 2.6440e-04, PNorm = 55.9009, GNorm = 0.7398, lr_0 = 1.0804e-04
Loss = 3.0488e-04, PNorm = 55.9038, GNorm = 2.3854, lr_0 = 1.0804e-04
Loss = 2.6649e-04, PNorm = 55.9067, GNorm = 3.3271, lr_0 = 1.0804e-04
Loss = 4.6278e-04, PNorm = 55.9102, GNorm = 3.7655, lr_0 = 1.0804e-04
Loss = 4.4876e-04, PNorm = 55.9138, GNorm = 2.1335, lr_0 = 1.0804e-04
Loss = 3.3505e-04, PNorm = 55.9175, GNorm = 0.6561, lr_0 = 1.0804e-04
Validation rmse logD = 0.664584
Validation R2 logD = 0.724075
Epoch 89
Train function
Loss = 3.5912e-04, PNorm = 55.9201, GNorm = 1.8283, lr_0 = 1.0804e-04
Loss = 2.5482e-04, PNorm = 55.9244, GNorm = 0.6347, lr_0 = 1.0804e-04
Loss = 2.7593e-04, PNorm = 55.9279, GNorm = 0.6388, lr_0 = 1.0804e-04
Loss = 2.3207e-04, PNorm = 55.9297, GNorm = 1.7272, lr_0 = 1.0804e-04
Loss = 2.2045e-04, PNorm = 55.9326, GNorm = 1.2590, lr_0 = 1.0804e-04
Validation rmse logD = 0.655754
Validation R2 logD = 0.731359
Epoch 90
Train function
Loss = 3.0891e-04, PNorm = 55.9352, GNorm = 3.2644, lr_0 = 1.0804e-04
Loss = 2.5671e-04, PNorm = 55.9364, GNorm = 2.2873, lr_0 = 1.0804e-04
Loss = 3.0143e-04, PNorm = 55.9382, GNorm = 2.1767, lr_0 = 1.0804e-04
Loss = 2.4887e-04, PNorm = 55.9416, GNorm = 1.0535, lr_0 = 1.0804e-04
Loss = 2.4745e-04, PNorm = 55.9445, GNorm = 0.8231, lr_0 = 1.0804e-04
Loss = 2.9746e-04, PNorm = 55.9475, GNorm = 1.7167, lr_0 = 1.0804e-04
Validation rmse logD = 0.653258
Validation R2 logD = 0.733400
Epoch 91
Train function
Loss = 2.1348e-04, PNorm = 55.9503, GNorm = 0.8801, lr_0 = 1.0804e-04
Loss = 2.3894e-04, PNorm = 55.9521, GNorm = 1.5738, lr_0 = 1.0804e-04
Loss = 2.9508e-04, PNorm = 55.9541, GNorm = 0.6530, lr_0 = 1.0804e-04
Loss = 2.1927e-04, PNorm = 55.9577, GNorm = 0.7998, lr_0 = 1.0804e-04
Loss = 2.1464e-04, PNorm = 55.9598, GNorm = 0.8209, lr_0 = 1.0804e-04
Loss = 2.3845e-04, PNorm = 55.9629, GNorm = 1.5213, lr_0 = 1.0804e-04
Validation rmse logD = 0.647262
Validation R2 logD = 0.738272
Epoch 92
Train function
Loss = 2.4174e-04, PNorm = 55.9653, GNorm = 2.0289, lr_0 = 1.0804e-04
Loss = 2.9543e-04, PNorm = 55.9681, GNorm = 3.5130, lr_0 = 1.0804e-04
Loss = 4.2690e-04, PNorm = 55.9705, GNorm = 3.9078, lr_0 = 1.0804e-04
Loss = 3.2627e-04, PNorm = 55.9726, GNorm = 1.2492, lr_0 = 1.0804e-04
Loss = 3.3393e-04, PNorm = 55.9755, GNorm = 2.1225, lr_0 = 1.0804e-04
Validation rmse logD = 0.656572
Validation R2 logD = 0.730689
Epoch 93
Train function
Loss = 1.3734e-04, PNorm = 55.9789, GNorm = 0.8801, lr_0 = 1.0804e-04
Loss = 2.7562e-04, PNorm = 55.9825, GNorm = 2.4068, lr_0 = 1.0804e-04
Loss = 4.3325e-04, PNorm = 55.9846, GNorm = 0.8486, lr_0 = 1.0804e-04
Loss = 5.2516e-04, PNorm = 55.9877, GNorm = 3.1798, lr_0 = 1.0804e-04
Loss = 5.1913e-04, PNorm = 55.9911, GNorm = 1.6751, lr_0 = 1.0804e-04
Loss = 3.8242e-04, PNorm = 55.9953, GNorm = 3.1084, lr_0 = 1.0804e-04
Validation rmse logD = 0.647924
Validation R2 logD = 0.737737
Epoch 94
Train function
Loss = 2.7529e-04, PNorm = 55.9996, GNorm = 0.9313, lr_0 = 1.0804e-04
Loss = 2.7460e-04, PNorm = 56.0034, GNorm = 1.3346, lr_0 = 1.0804e-04
Loss = 2.1188e-04, PNorm = 56.0061, GNorm = 1.3834, lr_0 = 1.0804e-04
Loss = 2.7958e-04, PNorm = 56.0080, GNorm = 1.8325, lr_0 = 1.0804e-04
Loss = 2.6431e-04, PNorm = 56.0109, GNorm = 1.7891, lr_0 = 1.0804e-04
Loss = 2.6452e-04, PNorm = 56.0141, GNorm = 1.7993, lr_0 = 1.0804e-04
Validation rmse logD = 0.653881
Validation R2 logD = 0.732891
Epoch 95
Train function
Loss = 2.5010e-04, PNorm = 56.0181, GNorm = 3.5465, lr_0 = 1.0804e-04
Loss = 2.6594e-04, PNorm = 56.0219, GNorm = 1.3342, lr_0 = 1.0804e-04
Loss = 2.7586e-04, PNorm = 56.0236, GNorm = 1.9215, lr_0 = 1.0804e-04
Loss = 3.9608e-04, PNorm = 56.0255, GNorm = 3.7250, lr_0 = 1.0804e-04
Loss = 4.2644e-04, PNorm = 56.0283, GNorm = 1.3223, lr_0 = 1.0804e-04
Validation rmse logD = 0.644394
Validation R2 logD = 0.740586
Epoch 96
Train function
Loss = 1.3013e-04, PNorm = 56.0318, GNorm = 1.6053, lr_0 = 1.0804e-04
Loss = 3.1021e-04, PNorm = 56.0353, GNorm = 2.6738, lr_0 = 1.0804e-04
Loss = 3.0730e-04, PNorm = 56.0389, GNorm = 1.7077, lr_0 = 1.0804e-04
Loss = 2.7670e-04, PNorm = 56.0425, GNorm = 0.9015, lr_0 = 1.0804e-04
Loss = 2.2567e-04, PNorm = 56.0452, GNorm = 0.7251, lr_0 = 1.0804e-04
Loss = 2.2953e-04, PNorm = 56.0487, GNorm = 1.8689, lr_0 = 1.0804e-04
Validation rmse logD = 0.647743
Validation R2 logD = 0.737883
Epoch 97
Train function
Loss = 3.1106e-04, PNorm = 56.0508, GNorm = 3.4691, lr_0 = 1.0804e-04
Loss = 3.1210e-04, PNorm = 56.0527, GNorm = 1.5491, lr_0 = 1.0804e-04
Loss = 2.7774e-04, PNorm = 56.0561, GNorm = 0.9085, lr_0 = 1.0804e-04
Loss = 2.3477e-04, PNorm = 56.0588, GNorm = 1.6263, lr_0 = 1.0804e-04
Loss = 2.7544e-04, PNorm = 56.0611, GNorm = 0.8879, lr_0 = 1.0804e-04
Loss = 2.1400e-04, PNorm = 56.0632, GNorm = 0.9567, lr_0 = 1.0804e-04
Validation rmse logD = 0.658245
Validation R2 logD = 0.729315
Epoch 98
Train function
Loss = 2.5291e-04, PNorm = 56.0653, GNorm = 3.1780, lr_0 = 1.0804e-04
Loss = 2.0864e-04, PNorm = 56.0673, GNorm = 1.1908, lr_0 = 1.0804e-04
Loss = 2.2569e-04, PNorm = 56.0699, GNorm = 2.0586, lr_0 = 1.0804e-04
Loss = 2.3023e-04, PNorm = 56.0728, GNorm = 1.1465, lr_0 = 1.0804e-04
Loss = 2.0466e-04, PNorm = 56.0765, GNorm = 3.3019, lr_0 = 1.0804e-04
Validation rmse logD = 0.649999
Validation R2 logD = 0.736054
Epoch 99
Train function
Loss = 1.6384e-04, PNorm = 56.0782, GNorm = 2.2939, lr_0 = 1.0804e-04
Loss = 1.8983e-04, PNorm = 56.0810, GNorm = 0.8743, lr_0 = 1.0804e-04
Loss = 2.4504e-04, PNorm = 56.0833, GNorm = 2.8636, lr_0 = 1.0804e-04
Loss = 1.8622e-04, PNorm = 56.0861, GNorm = 0.8078, lr_0 = 1.0804e-04
Loss = 2.3378e-04, PNorm = 56.0881, GNorm = 0.8617, lr_0 = 1.0804e-04
Loss = 2.3533e-04, PNorm = 56.0906, GNorm = 1.1716, lr_0 = 1.0804e-04
Validation rmse logD = 0.648178
Validation R2 logD = 0.737531
Model 0 best validation rmse = 0.644394 on epoch 95
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.553967
Model 0 test R2 logD = 0.785456
Ensemble test rmse  logD= 0.553967
Ensemble test R2  logD= 0.785456
5-fold cross validation
	Seed 0 ==> test rmse = 0.578928
	Seed 0 ==> test R2 = 0.792505
	Seed 1 ==> test rmse = 0.529502
	Seed 1 ==> test R2 = 0.780097
	Seed 2 ==> test rmse = 0.555350
	Seed 2 ==> test R2 = 0.790018
	Seed 3 ==> test rmse = 0.538159
	Seed 3 ==> test R2 = 0.793276
	Seed 4 ==> test rmse = 0.553967
	Seed 4 ==> test R2 = 0.785456
Overall val rmse logD= 0.558602 +/- 0.048175
Overall val R2 logD = 0.795517 +/- 0.032794
Overall test rmse logD = 0.551181 +/- 0.016939
Overall test R2 logD = 0.788270 +/- 0.004915
Elapsed time = 5:53:55
