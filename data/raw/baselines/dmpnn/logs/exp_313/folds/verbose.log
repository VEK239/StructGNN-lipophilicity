Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_313/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.2935e-02, PNorm = 55.5559, GNorm = 3.5272, lr_0 = 1.9340e-04
Loss = 1.7258e-02, PNorm = 55.5629, GNorm = 4.6523, lr_0 = 2.7830e-04
Loss = 1.7571e-02, PNorm = 55.5752, GNorm = 1.1913, lr_0 = 3.6321e-04
Loss = 1.5618e-02, PNorm = 55.5963, GNorm = 3.2353, lr_0 = 4.4811e-04
Loss = 1.3736e-02, PNorm = 55.6237, GNorm = 1.5065, lr_0 = 5.3302e-04
Validation rmse logD = 1.089487
Validation R2 logD = 0.084636
Epoch 1
Train function
Loss = 1.4312e-02, PNorm = 55.6719, GNorm = 4.1547, lr_0 = 6.2642e-04
Loss = 1.4015e-02, PNorm = 55.7322, GNorm = 2.1298, lr_0 = 7.1132e-04
Loss = 1.2312e-02, PNorm = 55.8103, GNorm = 5.6379, lr_0 = 7.9623e-04
Loss = 1.3884e-02, PNorm = 55.8803, GNorm = 2.2789, lr_0 = 8.8113e-04
Loss = 1.4844e-02, PNorm = 55.9836, GNorm = 2.0517, lr_0 = 9.6604e-04
Validation rmse logD = 1.237934
Validation R2 logD = -0.181801
Epoch 2
Train function
Loss = 1.7299e-02, PNorm = 56.1092, GNorm = 3.0687, lr_0 = 9.9690e-04
Loss = 1.3882e-02, PNorm = 56.2206, GNorm = 2.2477, lr_0 = 9.9249e-04
Loss = 1.1517e-02, PNorm = 56.3237, GNorm = 1.4357, lr_0 = 9.8810e-04
Loss = 1.0543e-02, PNorm = 56.4076, GNorm = 2.6681, lr_0 = 9.8373e-04
Loss = 1.1880e-02, PNorm = 56.4906, GNorm = 4.3652, lr_0 = 9.7938e-04
Validation rmse logD = 0.826993
Validation R2 logD = 0.472585
Epoch 3
Train function
Loss = 5.7366e-03, PNorm = 56.5857, GNorm = 0.8134, lr_0 = 9.7462e-04
Loss = 7.9953e-03, PNorm = 56.6344, GNorm = 2.6154, lr_0 = 9.7030e-04
Loss = 9.2140e-03, PNorm = 56.6942, GNorm = 1.9069, lr_0 = 9.6601e-04
Loss = 9.7184e-03, PNorm = 56.7608, GNorm = 2.8207, lr_0 = 9.6174e-04
Loss = 9.7051e-03, PNorm = 56.8382, GNorm = 1.1222, lr_0 = 9.5749e-04
Loss = 9.6412e-03, PNorm = 56.9314, GNorm = 2.0586, lr_0 = 9.5325e-04
Validation rmse logD = 0.987391
Validation R2 logD = 0.248156
Epoch 4
Train function
Loss = 9.3640e-03, PNorm = 56.9851, GNorm = 1.6729, lr_0 = 9.4861e-04
Loss = 8.6046e-03, PNorm = 57.0839, GNorm = 2.7313, lr_0 = 9.4442e-04
Loss = 8.1978e-03, PNorm = 57.1610, GNorm = 3.3493, lr_0 = 9.4024e-04
Loss = 8.2922e-03, PNorm = 57.2379, GNorm = 2.9815, lr_0 = 9.3608e-04
Loss = 8.7841e-03, PNorm = 57.3173, GNorm = 2.3933, lr_0 = 9.3194e-04
Validation rmse logD = 0.776963
Validation R2 logD = 0.534467
Epoch 5
Train function
Loss = 7.1353e-03, PNorm = 57.4075, GNorm = 3.3624, lr_0 = 9.2741e-04
Loss = 7.0817e-03, PNorm = 57.5011, GNorm = 1.5233, lr_0 = 9.2330e-04
Loss = 6.9609e-03, PNorm = 57.5822, GNorm = 1.4104, lr_0 = 9.1922e-04
Loss = 7.6449e-03, PNorm = 57.6657, GNorm = 2.6592, lr_0 = 9.1515e-04
Loss = 6.5605e-03, PNorm = 57.7399, GNorm = 1.0479, lr_0 = 9.1111e-04
Validation rmse logD = 0.735043
Validation R2 logD = 0.583346
Epoch 6
Train function
Loss = 5.1324e-03, PNorm = 57.8219, GNorm = 0.8675, lr_0 = 9.0667e-04
Loss = 6.3003e-03, PNorm = 57.9000, GNorm = 3.7640, lr_0 = 9.0266e-04
Loss = 6.9456e-03, PNorm = 57.9997, GNorm = 0.9385, lr_0 = 8.9867e-04
Loss = 6.4125e-03, PNorm = 58.0860, GNorm = 2.1192, lr_0 = 8.9469e-04
Loss = 6.1987e-03, PNorm = 58.1754, GNorm = 2.3392, lr_0 = 8.9074e-04
Loss = 5.9902e-03, PNorm = 58.2583, GNorm = 1.3169, lr_0 = 8.8680e-04
Validation rmse logD = 0.733020
Validation R2 logD = 0.585637
Epoch 7
Train function
Loss = 5.5282e-03, PNorm = 58.3325, GNorm = 2.4401, lr_0 = 8.8248e-04
Loss = 5.6573e-03, PNorm = 58.4228, GNorm = 0.8049, lr_0 = 8.7858e-04
Loss = 5.4396e-03, PNorm = 58.5148, GNorm = 2.8465, lr_0 = 8.7469e-04
Loss = 5.8133e-03, PNorm = 58.5933, GNorm = 1.8251, lr_0 = 8.7082e-04
Loss = 6.9394e-03, PNorm = 58.6757, GNorm = 3.1758, lr_0 = 8.6697e-04
Validation rmse logD = 0.704047
Validation R2 logD = 0.617746
Epoch 8
Train function
Loss = 5.1930e-03, PNorm = 58.7815, GNorm = 1.3903, lr_0 = 8.6276e-04
Loss = 4.5612e-03, PNorm = 58.8597, GNorm = 0.9750, lr_0 = 8.5894e-04
Loss = 4.7106e-03, PNorm = 58.9442, GNorm = 1.3891, lr_0 = 8.5514e-04
Loss = 4.8458e-03, PNorm = 59.0037, GNorm = 1.2370, lr_0 = 8.5136e-04
Loss = 4.6483e-03, PNorm = 59.0861, GNorm = 3.3131, lr_0 = 8.4759e-04
Validation rmse logD = 0.771645
Validation R2 logD = 0.540819
Epoch 9
Train function
Loss = 6.1549e-03, PNorm = 59.1896, GNorm = 1.9873, lr_0 = 8.4347e-04
Loss = 5.2020e-03, PNorm = 59.2898, GNorm = 1.1945, lr_0 = 8.3974e-04
Loss = 4.8220e-03, PNorm = 59.3888, GNorm = 0.8672, lr_0 = 8.3602e-04
Loss = 4.2256e-03, PNorm = 59.4834, GNorm = 1.7620, lr_0 = 8.3232e-04
Loss = 5.1491e-03, PNorm = 59.5872, GNorm = 1.2981, lr_0 = 8.2864e-04
Loss = 4.1233e-03, PNorm = 59.6455, GNorm = 0.8642, lr_0 = 8.2498e-04
Validation rmse logD = 0.675047
Validation R2 logD = 0.648588
Epoch 10
Train function
Loss = 4.1430e-03, PNorm = 59.7282, GNorm = 1.3303, lr_0 = 8.2133e-04
Loss = 4.4228e-03, PNorm = 59.8224, GNorm = 0.7997, lr_0 = 8.1770e-04
Loss = 4.2951e-03, PNorm = 59.9124, GNorm = 1.5565, lr_0 = 8.1408e-04
Loss = 3.6039e-03, PNorm = 60.0016, GNorm = 2.7291, lr_0 = 8.1048e-04
Loss = 3.6132e-03, PNorm = 60.0768, GNorm = 2.1861, lr_0 = 8.0689e-04
Validation rmse logD = 0.659540
Validation R2 logD = 0.664547
Epoch 11
Train function
Loss = 3.6329e-03, PNorm = 60.1395, GNorm = 1.9709, lr_0 = 8.0297e-04
Loss = 3.5487e-03, PNorm = 60.2164, GNorm = 2.3923, lr_0 = 7.9942e-04
Loss = 3.4719e-03, PNorm = 60.2922, GNorm = 0.9731, lr_0 = 7.9588e-04
Loss = 3.5185e-03, PNorm = 60.3676, GNorm = 2.0585, lr_0 = 7.9236e-04
Loss = 4.6340e-03, PNorm = 60.4471, GNorm = 2.9294, lr_0 = 7.8885e-04
Validation rmse logD = 0.634350
Validation R2 logD = 0.689682
Epoch 12
Train function
Loss = 3.5320e-03, PNorm = 60.5290, GNorm = 1.2982, lr_0 = 7.8502e-04
Loss = 2.6428e-03, PNorm = 60.6058, GNorm = 1.7449, lr_0 = 7.8154e-04
Loss = 2.9993e-03, PNorm = 60.6648, GNorm = 1.1208, lr_0 = 7.7809e-04
Loss = 3.1342e-03, PNorm = 60.7450, GNorm = 1.9369, lr_0 = 7.7465e-04
Loss = 2.6564e-03, PNorm = 60.8147, GNorm = 1.4272, lr_0 = 7.7122e-04
Loss = 3.1421e-03, PNorm = 60.8789, GNorm = 1.3040, lr_0 = 7.6781e-04
Loss = 9.7887e-03, PNorm = 60.8872, GNorm = 2.3269, lr_0 = 7.6747e-04
Validation rmse logD = 0.640947
Validation R2 logD = 0.683194
Epoch 13
Train function
Loss = 2.7529e-03, PNorm = 60.9604, GNorm = 0.9258, lr_0 = 7.6407e-04
Loss = 2.9179e-03, PNorm = 61.0508, GNorm = 1.2311, lr_0 = 7.6069e-04
Loss = 2.9951e-03, PNorm = 61.1228, GNorm = 1.1045, lr_0 = 7.5733e-04
Loss = 2.4336e-03, PNorm = 61.1773, GNorm = 0.7996, lr_0 = 7.5398e-04
Loss = 2.4599e-03, PNorm = 61.2488, GNorm = 1.0470, lr_0 = 7.5064e-04
Validation rmse logD = 0.700265
Validation R2 logD = 0.621842
Epoch 14
Train function
Loss = 4.5374e-03, PNorm = 61.3213, GNorm = 3.5104, lr_0 = 7.4699e-04
Loss = 3.0388e-03, PNorm = 61.4379, GNorm = 1.2440, lr_0 = 7.4369e-04
Loss = 2.6789e-03, PNorm = 61.5309, GNorm = 1.9103, lr_0 = 7.4040e-04
Loss = 2.9450e-03, PNorm = 61.6077, GNorm = 2.5940, lr_0 = 7.3712e-04
Loss = 2.3265e-03, PNorm = 61.6712, GNorm = 0.8408, lr_0 = 7.3386e-04
Validation rmse logD = 0.612394
Validation R2 logD = 0.710791
Epoch 15
Train function
Loss = 2.3693e-03, PNorm = 61.7375, GNorm = 0.7084, lr_0 = 7.3029e-04
Loss = 2.6488e-03, PNorm = 61.8190, GNorm = 1.4364, lr_0 = 7.2706e-04
Loss = 2.5965e-03, PNorm = 61.8957, GNorm = 1.4596, lr_0 = 7.2385e-04
Loss = 2.6825e-03, PNorm = 61.9614, GNorm = 2.0945, lr_0 = 7.2064e-04
Loss = 2.1685e-03, PNorm = 62.0116, GNorm = 2.3822, lr_0 = 7.1746e-04
Validation rmse logD = 0.614511
Validation R2 logD = 0.708789
Epoch 16
Train function
Loss = 2.5890e-03, PNorm = 62.0690, GNorm = 0.8169, lr_0 = 7.1397e-04
Loss = 1.7643e-03, PNorm = 62.1350, GNorm = 0.5288, lr_0 = 7.1081e-04
Loss = 1.6291e-03, PNorm = 62.1855, GNorm = 1.2519, lr_0 = 7.0766e-04
Loss = 1.9277e-03, PNorm = 62.2347, GNorm = 1.8323, lr_0 = 7.0453e-04
Loss = 1.8770e-03, PNorm = 62.2818, GNorm = 1.4510, lr_0 = 7.0142e-04
Loss = 2.3678e-03, PNorm = 62.3383, GNorm = 3.0180, lr_0 = 6.9831e-04
Validation rmse logD = 0.660696
Validation R2 logD = 0.663370
Epoch 17
Train function
Loss = 2.0631e-03, PNorm = 62.4014, GNorm = 1.9222, lr_0 = 6.9492e-04
Loss = 1.6783e-03, PNorm = 62.4519, GNorm = 1.2781, lr_0 = 6.9184e-04
Loss = 1.8528e-03, PNorm = 62.5054, GNorm = 0.6188, lr_0 = 6.8878e-04
Loss = 1.6328e-03, PNorm = 62.5583, GNorm = 1.0344, lr_0 = 6.8574e-04
Loss = 1.6590e-03, PNorm = 62.5996, GNorm = 0.5162, lr_0 = 6.8270e-04
Validation rmse logD = 0.608908
Validation R2 logD = 0.714075
Epoch 18
Train function
Loss = 1.2476e-03, PNorm = 62.6587, GNorm = 1.3343, lr_0 = 6.7938e-04
Loss = 1.7254e-03, PNorm = 62.7140, GNorm = 0.5858, lr_0 = 6.7638e-04
Loss = 1.4976e-03, PNorm = 62.7649, GNorm = 0.6547, lr_0 = 6.7338e-04
Loss = 1.4325e-03, PNorm = 62.8115, GNorm = 0.9666, lr_0 = 6.7041e-04
Loss = 1.5927e-03, PNorm = 62.8535, GNorm = 1.2534, lr_0 = 6.6744e-04
Validation rmse logD = 0.726444
Validation R2 logD = 0.593039
Epoch 19
Train function
Loss = 3.2142e-03, PNorm = 62.9073, GNorm = 3.2972, lr_0 = 6.6419e-04
Loss = 1.7992e-03, PNorm = 62.9815, GNorm = 1.3697, lr_0 = 6.6126e-04
Loss = 1.7662e-03, PNorm = 63.0448, GNorm = 0.6282, lr_0 = 6.5833e-04
Loss = 1.6691e-03, PNorm = 63.0876, GNorm = 1.0708, lr_0 = 6.5542e-04
Loss = 1.3420e-03, PNorm = 63.1390, GNorm = 0.4603, lr_0 = 6.5252e-04
Loss = 1.5369e-03, PNorm = 63.1868, GNorm = 0.7299, lr_0 = 6.4963e-04
Validation rmse logD = 0.656017
Validation R2 logD = 0.668121
Epoch 20
Train function
Loss = 1.4544e-03, PNorm = 63.2349, GNorm = 1.7235, lr_0 = 6.4676e-04
Loss = 1.3996e-03, PNorm = 63.2803, GNorm = 0.7738, lr_0 = 6.4390e-04
Loss = 1.3838e-03, PNorm = 63.3244, GNorm = 1.2015, lr_0 = 6.4105e-04
Loss = 1.4396e-03, PNorm = 63.3585, GNorm = 1.0132, lr_0 = 6.3822e-04
Loss = 1.3816e-03, PNorm = 63.3987, GNorm = 0.6872, lr_0 = 6.3539e-04
Validation rmse logD = 0.593704
Validation R2 logD = 0.728175
Epoch 21
Train function
Loss = 9.6510e-04, PNorm = 63.4435, GNorm = 0.7147, lr_0 = 6.3230e-04
Loss = 1.0530e-03, PNorm = 63.4879, GNorm = 1.1975, lr_0 = 6.2950e-04
Loss = 8.5899e-04, PNorm = 63.5268, GNorm = 0.4578, lr_0 = 6.2672e-04
Loss = 1.0615e-03, PNorm = 63.5514, GNorm = 0.6142, lr_0 = 6.2395e-04
Loss = 1.0794e-03, PNorm = 63.5860, GNorm = 0.5809, lr_0 = 6.2119e-04
Validation rmse logD = 0.591548
Validation R2 logD = 0.730146
Epoch 22
Train function
Loss = 8.0261e-04, PNorm = 63.6160, GNorm = 0.3713, lr_0 = 6.1817e-04
Loss = 1.2552e-03, PNorm = 63.6547, GNorm = 3.3087, lr_0 = 6.1543e-04
Loss = 1.2518e-03, PNorm = 63.6930, GNorm = 2.3151, lr_0 = 6.1271e-04
Loss = 1.0852e-03, PNorm = 63.7379, GNorm = 0.4718, lr_0 = 6.1000e-04
Loss = 1.0019e-03, PNorm = 63.7708, GNorm = 0.9352, lr_0 = 6.0730e-04
Loss = 9.0824e-04, PNorm = 63.8042, GNorm = 0.4845, lr_0 = 6.0461e-04
Validation rmse logD = 0.595387
Validation R2 logD = 0.726632
Epoch 23
Train function
Loss = 8.7256e-04, PNorm = 63.8430, GNorm = 0.9646, lr_0 = 6.0167e-04
Loss = 9.0641e-04, PNorm = 63.8756, GNorm = 0.4665, lr_0 = 5.9901e-04
Loss = 7.9096e-04, PNorm = 63.9031, GNorm = 0.6975, lr_0 = 5.9636e-04
Loss = 8.6134e-04, PNorm = 63.9417, GNorm = 0.5018, lr_0 = 5.9372e-04
Loss = 8.2351e-04, PNorm = 63.9685, GNorm = 0.4163, lr_0 = 5.9110e-04
Validation rmse logD = 0.619067
Validation R2 logD = 0.704455
Epoch 24
Train function
Loss = 1.0806e-03, PNorm = 63.9917, GNorm = 0.6655, lr_0 = 5.8822e-04
Loss = 1.0258e-03, PNorm = 64.0361, GNorm = 0.6484, lr_0 = 5.8562e-04
Loss = 9.3031e-04, PNorm = 64.0806, GNorm = 0.6868, lr_0 = 5.8303e-04
Loss = 8.0451e-04, PNorm = 64.1174, GNorm = 1.1239, lr_0 = 5.8045e-04
Loss = 9.5438e-04, PNorm = 64.1487, GNorm = 1.0690, lr_0 = 5.7788e-04
Validation rmse logD = 0.626391
Validation R2 logD = 0.697420
Epoch 25
Train function
Loss = 1.0382e-03, PNorm = 64.1849, GNorm = 1.4440, lr_0 = 5.7507e-04
Loss = 9.1026e-04, PNorm = 64.2283, GNorm = 1.7862, lr_0 = 5.7253e-04
Loss = 9.1487e-04, PNorm = 64.2585, GNorm = 0.7583, lr_0 = 5.7000e-04
Loss = 7.9767e-04, PNorm = 64.2871, GNorm = 1.2394, lr_0 = 5.6748e-04
Loss = 7.7848e-04, PNorm = 64.3117, GNorm = 0.8504, lr_0 = 5.6497e-04
Loss = 8.5068e-04, PNorm = 64.3450, GNorm = 0.5510, lr_0 = 5.6247e-04
Loss = 6.3405e-04, PNorm = 64.3475, GNorm = 0.5065, lr_0 = 5.6222e-04
Validation rmse logD = 0.593048
Validation R2 logD = 0.728775
Epoch 26
Train function
Loss = 6.1070e-04, PNorm = 64.3680, GNorm = 0.7437, lr_0 = 5.5973e-04
Loss = 7.7753e-04, PNorm = 64.3916, GNorm = 0.5210, lr_0 = 5.5725e-04
Loss = 7.0082e-04, PNorm = 64.4252, GNorm = 0.9887, lr_0 = 5.5479e-04
Loss = 6.3705e-04, PNorm = 64.4477, GNorm = 0.7120, lr_0 = 5.5233e-04
Loss = 7.3019e-04, PNorm = 64.4718, GNorm = 0.4306, lr_0 = 5.4989e-04
Validation rmse logD = 0.606580
Validation R2 logD = 0.716257
Epoch 27
Train function
Loss = 6.6230e-04, PNorm = 64.4975, GNorm = 0.9246, lr_0 = 5.4722e-04
Loss = 5.9602e-04, PNorm = 64.5278, GNorm = 0.5193, lr_0 = 5.4480e-04
Loss = 6.3742e-04, PNorm = 64.5493, GNorm = 0.5411, lr_0 = 5.4239e-04
Loss = 6.0024e-04, PNorm = 64.5754, GNorm = 0.6876, lr_0 = 5.3999e-04
Loss = 6.4167e-04, PNorm = 64.6011, GNorm = 0.5020, lr_0 = 5.3760e-04
Validation rmse logD = 0.589968
Validation R2 logD = 0.731585
Epoch 28
Train function
Loss = 5.4047e-04, PNorm = 64.6273, GNorm = 0.3443, lr_0 = 5.3498e-04
Loss = 5.1264e-04, PNorm = 64.6551, GNorm = 0.7335, lr_0 = 5.3262e-04
Loss = 4.5930e-04, PNorm = 64.6774, GNorm = 0.3595, lr_0 = 5.3026e-04
Loss = 5.7947e-04, PNorm = 64.6973, GNorm = 1.6696, lr_0 = 5.2792e-04
Loss = 5.2289e-04, PNorm = 64.7166, GNorm = 1.0145, lr_0 = 5.2558e-04
Validation rmse logD = 0.603398
Validation R2 logD = 0.719226
Epoch 29
Train function
Loss = 5.3474e-04, PNorm = 64.7372, GNorm = 1.2672, lr_0 = 5.2302e-04
Loss = 8.4203e-04, PNorm = 64.7707, GNorm = 1.1040, lr_0 = 5.2071e-04
Loss = 6.2405e-04, PNorm = 64.8066, GNorm = 0.4933, lr_0 = 5.1841e-04
Loss = 5.3421e-04, PNorm = 64.8323, GNorm = 0.5430, lr_0 = 5.1611e-04
Loss = 5.2844e-04, PNorm = 64.8520, GNorm = 0.6937, lr_0 = 5.1383e-04
Loss = 4.9898e-04, PNorm = 64.8693, GNorm = 0.5320, lr_0 = 5.1156e-04
Validation rmse logD = 0.593650
Validation R2 logD = 0.728225
Epoch 30
Train function
Loss = 4.4670e-04, PNorm = 64.8849, GNorm = 0.3545, lr_0 = 5.0930e-04
Loss = 4.6988e-04, PNorm = 64.9060, GNorm = 0.3842, lr_0 = 5.0704e-04
Loss = 4.6805e-04, PNorm = 64.9249, GNorm = 0.7845, lr_0 = 5.0480e-04
Loss = 3.9750e-04, PNorm = 64.9413, GNorm = 0.6915, lr_0 = 5.0257e-04
Loss = 4.2776e-04, PNorm = 64.9576, GNorm = 0.3656, lr_0 = 5.0034e-04
Validation rmse logD = 0.611788
Validation R2 logD = 0.711364
Epoch 31
Train function
Loss = 5.0922e-04, PNorm = 64.9774, GNorm = 1.1837, lr_0 = 4.9791e-04
Loss = 4.6431e-04, PNorm = 64.9979, GNorm = 0.4413, lr_0 = 4.9571e-04
Loss = 3.6700e-04, PNorm = 65.0166, GNorm = 0.9971, lr_0 = 4.9351e-04
Loss = 4.0107e-04, PNorm = 65.0326, GNorm = 0.3863, lr_0 = 4.9133e-04
Loss = 4.9351e-04, PNorm = 65.0547, GNorm = 0.4776, lr_0 = 4.8916e-04
Validation rmse logD = 0.605699
Validation R2 logD = 0.717080
Epoch 32
Train function
Loss = 4.1142e-04, PNorm = 65.0814, GNorm = 1.2188, lr_0 = 4.8678e-04
Loss = 4.9402e-04, PNorm = 65.1019, GNorm = 1.1344, lr_0 = 4.8463e-04
Loss = 5.5463e-04, PNorm = 65.1224, GNorm = 0.4904, lr_0 = 4.8248e-04
Loss = 3.5694e-04, PNorm = 65.1466, GNorm = 0.6404, lr_0 = 4.8035e-04
Loss = 3.6678e-04, PNorm = 65.1609, GNorm = 0.2676, lr_0 = 4.7822e-04
Loss = 3.7523e-04, PNorm = 65.1727, GNorm = 0.7066, lr_0 = 4.7611e-04
Validation rmse logD = 0.586614
Validation R2 logD = 0.734629
Epoch 33
Train function
Loss = 3.2647e-04, PNorm = 65.1935, GNorm = 1.0979, lr_0 = 4.7379e-04
Loss = 3.0035e-04, PNorm = 65.2100, GNorm = 0.5824, lr_0 = 4.7170e-04
Loss = 4.0351e-04, PNorm = 65.2255, GNorm = 0.7964, lr_0 = 4.6961e-04
Loss = 3.3841e-04, PNorm = 65.2384, GNorm = 0.7648, lr_0 = 4.6753e-04
Loss = 3.9337e-04, PNorm = 65.2553, GNorm = 0.6898, lr_0 = 4.6546e-04
Validation rmse logD = 0.600787
Validation R2 logD = 0.721651
Epoch 34
Train function
Loss = 3.3437e-04, PNorm = 65.2777, GNorm = 0.4362, lr_0 = 4.6320e-04
Loss = 3.4780e-04, PNorm = 65.2922, GNorm = 0.3306, lr_0 = 4.6115e-04
Loss = 3.1234e-04, PNorm = 65.3073, GNorm = 0.3977, lr_0 = 4.5911e-04
Loss = 2.9161e-04, PNorm = 65.3205, GNorm = 0.2382, lr_0 = 4.5708e-04
Loss = 3.4874e-04, PNorm = 65.3334, GNorm = 0.4404, lr_0 = 4.5506e-04
Validation rmse logD = 0.587293
Validation R2 logD = 0.734014
Epoch 35
Train function
Loss = 2.4935e-04, PNorm = 65.3513, GNorm = 0.2937, lr_0 = 4.5284e-04
Loss = 2.6537e-04, PNorm = 65.3655, GNorm = 0.2598, lr_0 = 4.5084e-04
Loss = 2.2088e-04, PNorm = 65.3786, GNorm = 0.3026, lr_0 = 4.4885e-04
Loss = 3.0501e-04, PNorm = 65.3905, GNorm = 0.5454, lr_0 = 4.4686e-04
Loss = 2.5037e-04, PNorm = 65.4021, GNorm = 0.3756, lr_0 = 4.4489e-04
Loss = 2.9485e-04, PNorm = 65.4164, GNorm = 0.3466, lr_0 = 4.4292e-04
Validation rmse logD = 0.583685
Validation R2 logD = 0.737272
Epoch 36
Train function
Loss = 3.0132e-04, PNorm = 65.4371, GNorm = 0.7544, lr_0 = 4.4076e-04
Loss = 3.1335e-04, PNorm = 65.4501, GNorm = 0.5761, lr_0 = 4.3881e-04
Loss = 2.2160e-04, PNorm = 65.4632, GNorm = 0.1961, lr_0 = 4.3687e-04
Loss = 2.6584e-04, PNorm = 65.4741, GNorm = 1.0162, lr_0 = 4.3494e-04
Loss = 3.7595e-04, PNorm = 65.4848, GNorm = 0.7034, lr_0 = 4.3302e-04
Validation rmse logD = 0.587835
Validation R2 logD = 0.733523
Epoch 37
Train function
Loss = 2.0601e-04, PNorm = 65.4967, GNorm = 0.2613, lr_0 = 4.3091e-04
Loss = 2.5523e-04, PNorm = 65.5112, GNorm = 0.4652, lr_0 = 4.2900e-04
Loss = 1.9832e-04, PNorm = 65.5260, GNorm = 0.2923, lr_0 = 4.2711e-04
Loss = 2.3077e-04, PNorm = 65.5398, GNorm = 0.2903, lr_0 = 4.2522e-04
Loss = 2.5122e-04, PNorm = 65.5520, GNorm = 0.2330, lr_0 = 4.2334e-04
Validation rmse logD = 0.591390
Validation R2 logD = 0.730290
Epoch 38
Train function
Loss = 3.5157e-04, PNorm = 65.5650, GNorm = 1.2136, lr_0 = 4.2128e-04
Loss = 4.5321e-04, PNorm = 65.5875, GNorm = 1.4178, lr_0 = 4.1941e-04
Loss = 3.0169e-04, PNorm = 65.6091, GNorm = 0.5711, lr_0 = 4.1756e-04
Loss = 2.7535e-04, PNorm = 65.6226, GNorm = 0.3292, lr_0 = 4.1571e-04
Loss = 2.9069e-04, PNorm = 65.6388, GNorm = 0.3870, lr_0 = 4.1387e-04
Loss = 2.7637e-04, PNorm = 65.6546, GNorm = 0.2975, lr_0 = 4.1204e-04
Loss = 4.0198e-03, PNorm = 65.6557, GNorm = 1.6612, lr_0 = 4.1186e-04
Validation rmse logD = 0.590206
Validation R2 logD = 0.731369
Epoch 39
Train function
Loss = 2.4438e-04, PNorm = 65.6703, GNorm = 1.2674, lr_0 = 4.1004e-04
Loss = 3.5900e-04, PNorm = 65.6915, GNorm = 1.0648, lr_0 = 4.0822e-04
Loss = 3.1392e-04, PNorm = 65.7069, GNorm = 0.4947, lr_0 = 4.0642e-04
Loss = 2.1403e-04, PNorm = 65.7194, GNorm = 0.2398, lr_0 = 4.0462e-04
Loss = 2.6764e-04, PNorm = 65.7286, GNorm = 0.3179, lr_0 = 4.0283e-04
Validation rmse logD = 0.587530
Validation R2 logD = 0.733799
Epoch 40
Train function
Loss = 1.9564e-04, PNorm = 65.7436, GNorm = 0.7657, lr_0 = 4.0105e-04
Loss = 2.4878e-04, PNorm = 65.7554, GNorm = 0.2777, lr_0 = 3.9927e-04
Loss = 2.2768e-04, PNorm = 65.7648, GNorm = 0.2793, lr_0 = 3.9751e-04
Loss = 2.2065e-04, PNorm = 65.7757, GNorm = 0.7588, lr_0 = 3.9575e-04
Loss = 2.0790e-04, PNorm = 65.7851, GNorm = 0.2239, lr_0 = 3.9400e-04
Validation rmse logD = 0.591063
Validation R2 logD = 0.730588
Epoch 41
Train function
Loss = 1.8566e-04, PNorm = 65.7959, GNorm = 0.2158, lr_0 = 3.9208e-04
Loss = 2.0584e-04, PNorm = 65.8041, GNorm = 0.4446, lr_0 = 3.9035e-04
Loss = 2.2358e-04, PNorm = 65.8123, GNorm = 0.3275, lr_0 = 3.8862e-04
Loss = 1.7795e-04, PNorm = 65.8240, GNorm = 0.1967, lr_0 = 3.8690e-04
Loss = 2.1036e-04, PNorm = 65.8334, GNorm = 0.5157, lr_0 = 3.8519e-04
Loss = 1.7142e-04, PNorm = 65.8451, GNorm = 0.2647, lr_0 = 3.8349e-04
Loss = 2.0632e-03, PNorm = 65.8468, GNorm = 0.8281, lr_0 = 3.8332e-04
Validation rmse logD = 0.587766
Validation R2 logD = 0.733585
Epoch 42
Train function
Loss = 1.4173e-04, PNorm = 65.8580, GNorm = 0.1225, lr_0 = 3.8162e-04
Loss = 1.7889e-04, PNorm = 65.8674, GNorm = 0.2902, lr_0 = 3.7993e-04
Loss = 1.8839e-04, PNorm = 65.8752, GNorm = 0.2643, lr_0 = 3.7825e-04
Loss = 2.3481e-04, PNorm = 65.8867, GNorm = 0.2422, lr_0 = 3.7658e-04
Loss = 1.5236e-04, PNorm = 65.8965, GNorm = 0.3694, lr_0 = 3.7491e-04
Validation rmse logD = 0.592298
Validation R2 logD = 0.729461
Epoch 43
Train function
Loss = 1.0680e-04, PNorm = 65.9052, GNorm = 0.1692, lr_0 = 3.7309e-04
Loss = 1.3971e-04, PNorm = 65.9135, GNorm = 0.2848, lr_0 = 3.7144e-04
Loss = 1.4588e-04, PNorm = 65.9214, GNorm = 0.3508, lr_0 = 3.6980e-04
Loss = 1.4380e-04, PNorm = 65.9287, GNorm = 0.1767, lr_0 = 3.6816e-04
Loss = 1.5816e-04, PNorm = 65.9357, GNorm = 0.2182, lr_0 = 3.6653e-04
Validation rmse logD = 0.590938
Validation R2 logD = 0.730702
Epoch 44
Train function
Loss = 9.0962e-05, PNorm = 65.9433, GNorm = 0.3134, lr_0 = 3.6475e-04
Loss = 1.2718e-04, PNorm = 65.9479, GNorm = 0.2141, lr_0 = 3.6314e-04
Loss = 1.2836e-04, PNorm = 65.9548, GNorm = 0.3076, lr_0 = 3.6153e-04
Loss = 1.3146e-04, PNorm = 65.9632, GNorm = 0.2906, lr_0 = 3.5993e-04
Loss = 1.4669e-04, PNorm = 65.9732, GNorm = 0.4233, lr_0 = 3.5834e-04
Validation rmse logD = 0.590670
Validation R2 logD = 0.730946
Epoch 45
Train function
Loss = 9.2944e-05, PNorm = 65.9820, GNorm = 0.4532, lr_0 = 3.5660e-04
Loss = 1.1987e-04, PNorm = 65.9869, GNorm = 0.1450, lr_0 = 3.5502e-04
Loss = 1.1507e-04, PNorm = 65.9940, GNorm = 0.1912, lr_0 = 3.5345e-04
Loss = 1.2930e-04, PNorm = 66.0022, GNorm = 0.3659, lr_0 = 3.5188e-04
Loss = 1.2835e-04, PNorm = 66.0099, GNorm = 0.2000, lr_0 = 3.5033e-04
Loss = 1.1761e-04, PNorm = 66.0179, GNorm = 0.1982, lr_0 = 3.4878e-04
Validation rmse logD = 0.589501
Validation R2 logD = 0.732010
Epoch 46
Train function
Loss = 9.5890e-05, PNorm = 66.0261, GNorm = 0.3830, lr_0 = 3.4708e-04
Loss = 1.1678e-04, PNorm = 66.0342, GNorm = 0.2331, lr_0 = 3.4555e-04
Loss = 1.0811e-04, PNorm = 66.0402, GNorm = 0.2219, lr_0 = 3.4402e-04
Loss = 1.4259e-04, PNorm = 66.0451, GNorm = 0.3135, lr_0 = 3.4250e-04
Loss = 1.3430e-04, PNorm = 66.0549, GNorm = 0.3393, lr_0 = 3.4098e-04
Validation rmse logD = 0.588243
Validation R2 logD = 0.733153
Epoch 47
Train function
Loss = 1.2161e-04, PNorm = 66.0610, GNorm = 0.1843, lr_0 = 3.3932e-04
Loss = 1.0527e-04, PNorm = 66.0711, GNorm = 0.2695, lr_0 = 3.3782e-04
Loss = 9.5786e-05, PNorm = 66.0787, GNorm = 0.1800, lr_0 = 3.3633e-04
Loss = 1.0868e-04, PNorm = 66.0875, GNorm = 0.3240, lr_0 = 3.3484e-04
Loss = 1.1417e-04, PNorm = 66.0920, GNorm = 0.2368, lr_0 = 3.3336e-04
Validation rmse logD = 0.613784
Validation R2 logD = 0.709477
Epoch 48
Train function
Loss = 5.3558e-04, PNorm = 66.1004, GNorm = 2.3126, lr_0 = 3.3174e-04
Loss = 3.9296e-04, PNorm = 66.1083, GNorm = 0.9581, lr_0 = 3.3027e-04
Loss = 2.7897e-04, PNorm = 66.1259, GNorm = 1.0950, lr_0 = 3.2881e-04
Loss = 1.5775e-04, PNorm = 66.1397, GNorm = 0.6010, lr_0 = 3.2735e-04
Loss = 1.9412e-04, PNorm = 66.1495, GNorm = 0.7915, lr_0 = 3.2591e-04
Loss = 1.6886e-04, PNorm = 66.1615, GNorm = 0.1903, lr_0 = 3.2446e-04
Validation rmse logD = 0.588923
Validation R2 logD = 0.732535
Epoch 49
Train function
Loss = 1.5102e-04, PNorm = 66.1731, GNorm = 0.8653, lr_0 = 3.2289e-04
Loss = 1.4470e-04, PNorm = 66.1833, GNorm = 0.5664, lr_0 = 3.2146e-04
Loss = 1.7175e-04, PNorm = 66.1886, GNorm = 0.7811, lr_0 = 3.2004e-04
Loss = 1.4665e-04, PNorm = 66.1962, GNorm = 0.5149, lr_0 = 3.1862e-04
Loss = 1.2369e-04, PNorm = 66.2048, GNorm = 0.2084, lr_0 = 3.1721e-04
Validation rmse logD = 0.596893
Validation R2 logD = 0.725247
Epoch 50
Train function
Loss = 9.9581e-05, PNorm = 66.2128, GNorm = 0.4145, lr_0 = 3.1581e-04
Loss = 9.8121e-05, PNorm = 66.2176, GNorm = 0.1143, lr_0 = 3.1441e-04
Loss = 9.3280e-05, PNorm = 66.2247, GNorm = 0.2027, lr_0 = 3.1302e-04
Loss = 1.2703e-04, PNorm = 66.2316, GNorm = 0.4871, lr_0 = 3.1164e-04
Loss = 9.5478e-05, PNorm = 66.2373, GNorm = 0.2598, lr_0 = 3.1026e-04
Validation rmse logD = 0.595638
Validation R2 logD = 0.726401
Epoch 51
Train function
Loss = 1.2622e-04, PNorm = 66.2442, GNorm = 0.6291, lr_0 = 3.0875e-04
Loss = 1.3298e-04, PNorm = 66.2494, GNorm = 0.4781, lr_0 = 3.0738e-04
Loss = 1.5042e-04, PNorm = 66.2577, GNorm = 0.2668, lr_0 = 3.0602e-04
Loss = 1.0271e-04, PNorm = 66.2630, GNorm = 0.1743, lr_0 = 3.0467e-04
Loss = 1.0104e-04, PNorm = 66.2723, GNorm = 0.2780, lr_0 = 3.0332e-04
Loss = 9.4465e-05, PNorm = 66.2779, GNorm = 0.2150, lr_0 = 3.0198e-04
Validation rmse logD = 0.591403
Validation R2 logD = 0.730278
Epoch 52
Train function
Loss = 1.1444e-04, PNorm = 66.2839, GNorm = 0.2861, lr_0 = 3.0051e-04
Loss = 1.3383e-04, PNorm = 66.2932, GNorm = 0.2887, lr_0 = 2.9918e-04
Loss = 1.6111e-04, PNorm = 66.3023, GNorm = 0.1546, lr_0 = 2.9786e-04
Loss = 1.6165e-04, PNorm = 66.3117, GNorm = 0.2948, lr_0 = 2.9654e-04
Loss = 1.4547e-04, PNorm = 66.3214, GNorm = 0.2004, lr_0 = 2.9523e-04
Validation rmse logD = 0.595007
Validation R2 logD = 0.726981
Epoch 53
Train function
Loss = 7.2532e-05, PNorm = 66.3279, GNorm = 0.2583, lr_0 = 2.9379e-04
Loss = 9.8728e-05, PNorm = 66.3350, GNorm = 0.3807, lr_0 = 2.9249e-04
Loss = 8.3544e-05, PNorm = 66.3388, GNorm = 0.1235, lr_0 = 2.9120e-04
Loss = 8.0388e-05, PNorm = 66.3433, GNorm = 0.2878, lr_0 = 2.8991e-04
Loss = 1.0365e-04, PNorm = 66.3448, GNorm = 0.2821, lr_0 = 2.8863e-04
Validation rmse logD = 0.588673
Validation R2 logD = 0.732763
Epoch 54
Train function
Loss = 8.1229e-05, PNorm = 66.3519, GNorm = 0.3203, lr_0 = 2.8722e-04
Loss = 1.0561e-04, PNorm = 66.3571, GNorm = 0.2078, lr_0 = 2.8595e-04
Loss = 9.5586e-05, PNorm = 66.3627, GNorm = 0.2889, lr_0 = 2.8469e-04
Loss = 7.7268e-05, PNorm = 66.3671, GNorm = 0.4142, lr_0 = 2.8343e-04
Loss = 6.3335e-05, PNorm = 66.3713, GNorm = 0.1232, lr_0 = 2.8218e-04
Loss = 6.2789e-05, PNorm = 66.3756, GNorm = 0.1328, lr_0 = 2.8093e-04
Loss = 1.2348e-03, PNorm = 66.3764, GNorm = 0.9113, lr_0 = 2.8080e-04
Validation rmse logD = 0.590731
Validation R2 logD = 0.730891
Epoch 55
Train function
Loss = 8.5990e-05, PNorm = 66.3839, GNorm = 0.3385, lr_0 = 2.7956e-04
Loss = 6.4571e-05, PNorm = 66.3856, GNorm = 0.2818, lr_0 = 2.7832e-04
Loss = 6.5682e-05, PNorm = 66.3897, GNorm = 0.1704, lr_0 = 2.7709e-04
Loss = 7.6011e-05, PNorm = 66.3944, GNorm = 0.3403, lr_0 = 2.7587e-04
Loss = 5.0210e-05, PNorm = 66.3979, GNorm = 0.1195, lr_0 = 2.7465e-04
Validation rmse logD = 0.595487
Validation R2 logD = 0.726540
Epoch 56
Train function
Loss = 6.6398e-05, PNorm = 66.4022, GNorm = 0.1398, lr_0 = 2.7331e-04
Loss = 5.5468e-05, PNorm = 66.4048, GNorm = 0.1343, lr_0 = 2.7210e-04
Loss = 6.3708e-05, PNorm = 66.4093, GNorm = 0.1279, lr_0 = 2.7090e-04
Loss = 6.5890e-05, PNorm = 66.4130, GNorm = 0.1507, lr_0 = 2.6970e-04
Loss = 4.9040e-05, PNorm = 66.4179, GNorm = 0.1474, lr_0 = 2.6851e-04
Validation rmse logD = 0.591160
Validation R2 logD = 0.730500
Epoch 57
Train function
Loss = 7.9681e-05, PNorm = 66.4217, GNorm = 0.1736, lr_0 = 2.6720e-04
Loss = 7.3472e-05, PNorm = 66.4278, GNorm = 0.1948, lr_0 = 2.6602e-04
Loss = 8.7709e-05, PNorm = 66.4322, GNorm = 0.1530, lr_0 = 2.6484e-04
Loss = 5.2982e-05, PNorm = 66.4364, GNorm = 0.1162, lr_0 = 2.6367e-04
Loss = 7.7724e-05, PNorm = 66.4413, GNorm = 0.3710, lr_0 = 2.6250e-04
Validation rmse logD = 0.592849
Validation R2 logD = 0.728958
Epoch 58
Train function
Loss = 7.1386e-05, PNorm = 66.4475, GNorm = 0.4612, lr_0 = 2.6123e-04
Loss = 7.8589e-05, PNorm = 66.4514, GNorm = 0.2182, lr_0 = 2.6007e-04
Loss = 5.5467e-05, PNorm = 66.4563, GNorm = 0.1038, lr_0 = 2.5892e-04
Loss = 5.5173e-05, PNorm = 66.4601, GNorm = 0.2031, lr_0 = 2.5778e-04
Loss = 4.8746e-05, PNorm = 66.4646, GNorm = 0.2361, lr_0 = 2.5664e-04
Loss = 6.6323e-05, PNorm = 66.4687, GNorm = 0.1672, lr_0 = 2.5550e-04
Validation rmse logD = 0.592365
Validation R2 logD = 0.729400
Epoch 59
Train function
Loss = 5.4040e-05, PNorm = 66.4722, GNorm = 0.2428, lr_0 = 2.5426e-04
Loss = 4.1100e-05, PNorm = 66.4738, GNorm = 0.1140, lr_0 = 2.5313e-04
Loss = 3.9793e-05, PNorm = 66.4756, GNorm = 0.1139, lr_0 = 2.5201e-04
Loss = 5.0722e-05, PNorm = 66.4808, GNorm = 0.1265, lr_0 = 2.5090e-04
Loss = 5.0302e-05, PNorm = 66.4857, GNorm = 0.1564, lr_0 = 2.4979e-04
Validation rmse logD = 0.593722
Validation R2 logD = 0.728159
Epoch 60
Train function
Loss = 4.5825e-05, PNorm = 66.4873, GNorm = 0.1147, lr_0 = 2.4868e-04
Loss = 7.1174e-05, PNorm = 66.4914, GNorm = 0.1258, lr_0 = 2.4758e-04
Loss = 4.8662e-05, PNorm = 66.4946, GNorm = 0.1350, lr_0 = 2.4649e-04
Loss = 5.0207e-05, PNorm = 66.4979, GNorm = 0.1267, lr_0 = 2.4540e-04
Loss = 4.8732e-05, PNorm = 66.5037, GNorm = 0.1644, lr_0 = 2.4431e-04
Validation rmse logD = 0.592536
Validation R2 logD = 0.729244
Epoch 61
Train function
Loss = 3.3726e-05, PNorm = 66.5078, GNorm = 0.1932, lr_0 = 2.4313e-04
Loss = 3.4679e-05, PNorm = 66.5109, GNorm = 0.0925, lr_0 = 2.4205e-04
Loss = 4.4100e-05, PNorm = 66.5137, GNorm = 0.2217, lr_0 = 2.4098e-04
Loss = 4.1505e-05, PNorm = 66.5174, GNorm = 0.1063, lr_0 = 2.3991e-04
Loss = 3.6620e-05, PNorm = 66.5195, GNorm = 0.1889, lr_0 = 2.3885e-04
Loss = 4.7185e-05, PNorm = 66.5223, GNorm = 0.1731, lr_0 = 2.3780e-04
Validation rmse logD = 0.594601
Validation R2 logD = 0.727353
Epoch 62
Train function
Loss = 5.3314e-05, PNorm = 66.5259, GNorm = 0.3657, lr_0 = 2.3664e-04
Loss = 5.8740e-05, PNorm = 66.5302, GNorm = 0.3708, lr_0 = 2.3559e-04
Loss = 4.8053e-05, PNorm = 66.5345, GNorm = 0.2972, lr_0 = 2.3455e-04
Loss = 5.3264e-05, PNorm = 66.5375, GNorm = 0.2535, lr_0 = 2.3351e-04
Loss = 3.6545e-05, PNorm = 66.5405, GNorm = 0.0928, lr_0 = 2.3248e-04
Validation rmse logD = 0.592649
Validation R2 logD = 0.729141
Epoch 63
Train function
Loss = 3.6132e-05, PNorm = 66.5441, GNorm = 0.3189, lr_0 = 2.3135e-04
Loss = 3.4982e-05, PNorm = 66.5465, GNorm = 0.1189, lr_0 = 2.3033e-04
Loss = 3.3941e-05, PNorm = 66.5489, GNorm = 0.1511, lr_0 = 2.2931e-04
Loss = 4.3697e-05, PNorm = 66.5521, GNorm = 0.0987, lr_0 = 2.2829e-04
Loss = 3.9384e-05, PNorm = 66.5554, GNorm = 0.1094, lr_0 = 2.2728e-04
Validation rmse logD = 0.591889
Validation R2 logD = 0.729834
Epoch 64
Train function
Loss = 3.3330e-05, PNorm = 66.5574, GNorm = 0.4065, lr_0 = 2.2618e-04
Loss = 4.6756e-05, PNorm = 66.5608, GNorm = 0.2754, lr_0 = 2.2518e-04
Loss = 4.1490e-05, PNorm = 66.5633, GNorm = 0.1532, lr_0 = 2.2418e-04
Loss = 4.3119e-05, PNorm = 66.5673, GNorm = 0.3728, lr_0 = 2.2319e-04
Loss = 4.7027e-05, PNorm = 66.5682, GNorm = 0.5056, lr_0 = 2.2220e-04
Loss = 5.0007e-05, PNorm = 66.5714, GNorm = 0.4497, lr_0 = 2.2122e-04
Validation rmse logD = 0.594828
Validation R2 logD = 0.727145
Epoch 65
Train function
Loss = 5.1921e-05, PNorm = 66.5752, GNorm = 0.2424, lr_0 = 2.2014e-04
Loss = 4.2948e-05, PNorm = 66.5796, GNorm = 0.2991, lr_0 = 2.1917e-04
Loss = 4.0313e-05, PNorm = 66.5828, GNorm = 0.0916, lr_0 = 2.1820e-04
Loss = 3.9125e-05, PNorm = 66.5877, GNorm = 0.1291, lr_0 = 2.1723e-04
Loss = 3.8199e-05, PNorm = 66.5900, GNorm = 0.1370, lr_0 = 2.1627e-04
Validation rmse logD = 0.593113
Validation R2 logD = 0.728716
Epoch 66
Train function
Loss = 3.1091e-05, PNorm = 66.5916, GNorm = 0.1904, lr_0 = 2.1522e-04
Loss = 3.2609e-05, PNorm = 66.5941, GNorm = 0.2004, lr_0 = 2.1427e-04
Loss = 3.2277e-05, PNorm = 66.5975, GNorm = 0.1284, lr_0 = 2.1332e-04
Loss = 2.7306e-05, PNorm = 66.6004, GNorm = 0.1120, lr_0 = 2.1238e-04
Loss = 4.5812e-05, PNorm = 66.6023, GNorm = 0.4775, lr_0 = 2.1144e-04
Validation rmse logD = 0.593608
Validation R2 logD = 0.728263
Epoch 67
Train function
Loss = 3.9233e-05, PNorm = 66.6062, GNorm = 0.1309, lr_0 = 2.1041e-04
Loss = 2.9277e-05, PNorm = 66.6099, GNorm = 0.1041, lr_0 = 2.0948e-04
Loss = 2.4811e-05, PNorm = 66.6130, GNorm = 0.0970, lr_0 = 2.0855e-04
Loss = 2.4911e-05, PNorm = 66.6161, GNorm = 0.1995, lr_0 = 2.0763e-04
Loss = 3.4960e-05, PNorm = 66.6168, GNorm = 0.3536, lr_0 = 2.0671e-04
Loss = 3.3909e-05, PNorm = 66.6187, GNorm = 0.1667, lr_0 = 2.0580e-04
Loss = 1.0933e-04, PNorm = 66.6189, GNorm = 0.2435, lr_0 = 2.0571e-04
Validation rmse logD = 0.595291
Validation R2 logD = 0.726720
Epoch 68
Train function
Loss = 2.7311e-05, PNorm = 66.6224, GNorm = 0.0669, lr_0 = 2.0480e-04
Loss = 3.0847e-05, PNorm = 66.6236, GNorm = 0.2438, lr_0 = 2.0389e-04
Loss = 3.1564e-05, PNorm = 66.6248, GNorm = 0.1272, lr_0 = 2.0299e-04
Loss = 2.8296e-05, PNorm = 66.6258, GNorm = 0.0780, lr_0 = 2.0209e-04
Loss = 3.2102e-05, PNorm = 66.6276, GNorm = 0.1008, lr_0 = 2.0120e-04
Validation rmse logD = 0.592386
Validation R2 logD = 0.729381
Epoch 69
Train function
Loss = 2.4903e-05, PNorm = 66.6323, GNorm = 0.1582, lr_0 = 2.0022e-04
Loss = 2.5523e-05, PNorm = 66.6333, GNorm = 0.1307, lr_0 = 1.9933e-04
Loss = 2.0603e-05, PNorm = 66.6351, GNorm = 0.0711, lr_0 = 1.9845e-04
Loss = 2.7714e-05, PNorm = 66.6380, GNorm = 0.2373, lr_0 = 1.9757e-04
Loss = 2.5854e-05, PNorm = 66.6407, GNorm = 0.0878, lr_0 = 1.9670e-04
Validation rmse logD = 0.595321
Validation R2 logD = 0.726693
Epoch 70
Train function
Loss = 2.8615e-05, PNorm = 66.6417, GNorm = 0.0855, lr_0 = 1.9583e-04
Loss = 2.8471e-05, PNorm = 66.6431, GNorm = 0.1034, lr_0 = 1.9496e-04
Loss = 3.5914e-05, PNorm = 66.6469, GNorm = 0.1863, lr_0 = 1.9410e-04
Loss = 3.1341e-05, PNorm = 66.6499, GNorm = 0.1271, lr_0 = 1.9324e-04
Loss = 2.7451e-05, PNorm = 66.6524, GNorm = 0.1135, lr_0 = 1.9239e-04
Loss = 2.4139e-05, PNorm = 66.6548, GNorm = 0.2388, lr_0 = 1.9154e-04
Loss = 1.1430e-04, PNorm = 66.6548, GNorm = 0.2381, lr_0 = 1.9145e-04
Validation rmse logD = 0.592389
Validation R2 logD = 0.729378
Epoch 71
Train function
Loss = 2.8251e-05, PNorm = 66.6570, GNorm = 0.0776, lr_0 = 1.9060e-04
Loss = 2.0623e-05, PNorm = 66.6586, GNorm = 0.0826, lr_0 = 1.8976e-04
Loss = 2.8346e-05, PNorm = 66.6603, GNorm = 0.1470, lr_0 = 1.8892e-04
Loss = 2.2411e-05, PNorm = 66.6630, GNorm = 0.0823, lr_0 = 1.8809e-04
Loss = 2.4431e-05, PNorm = 66.6661, GNorm = 0.1262, lr_0 = 1.8725e-04
Validation rmse logD = 0.595492
Validation R2 logD = 0.726535
Epoch 72
Train function
Loss = 2.1647e-05, PNorm = 66.6682, GNorm = 0.1508, lr_0 = 1.8634e-04
Loss = 2.5451e-05, PNorm = 66.6709, GNorm = 0.1204, lr_0 = 1.8552e-04
Loss = 3.0692e-05, PNorm = 66.6738, GNorm = 0.1652, lr_0 = 1.8470e-04
Loss = 3.4446e-05, PNorm = 66.6765, GNorm = 0.1058, lr_0 = 1.8388e-04
Loss = 2.1042e-05, PNorm = 66.6791, GNorm = 0.0984, lr_0 = 1.8307e-04
Validation rmse logD = 0.594796
Validation R2 logD = 0.727174
Epoch 73
Train function
Loss = 1.4482e-05, PNorm = 66.6805, GNorm = 0.0911, lr_0 = 1.8218e-04
Loss = 1.6788e-05, PNorm = 66.6808, GNorm = 0.0966, lr_0 = 1.8137e-04
Loss = 1.7414e-05, PNorm = 66.6821, GNorm = 0.1662, lr_0 = 1.8057e-04
Loss = 2.7011e-05, PNorm = 66.6839, GNorm = 0.0606, lr_0 = 1.7977e-04
Loss = 2.9354e-05, PNorm = 66.6855, GNorm = 0.1779, lr_0 = 1.7897e-04
Validation rmse logD = 0.594282
Validation R2 logD = 0.727646
Epoch 74
Train function
Loss = 2.6520e-05, PNorm = 66.6877, GNorm = 0.1682, lr_0 = 1.7810e-04
Loss = 2.4253e-05, PNorm = 66.6903, GNorm = 0.3326, lr_0 = 1.7732e-04
Loss = 2.8277e-05, PNorm = 66.6906, GNorm = 0.2734, lr_0 = 1.7653e-04
Loss = 2.3957e-05, PNorm = 66.6933, GNorm = 0.1789, lr_0 = 1.7575e-04
Loss = 1.7329e-05, PNorm = 66.6957, GNorm = 0.1120, lr_0 = 1.7497e-04
Loss = 2.2406e-05, PNorm = 66.6972, GNorm = 0.1248, lr_0 = 1.7420e-04
Validation rmse logD = 0.594009
Validation R2 logD = 0.727896
Epoch 75
Train function
Loss = 2.8454e-05, PNorm = 66.7004, GNorm = 0.1843, lr_0 = 1.7335e-04
Loss = 2.5317e-05, PNorm = 66.7028, GNorm = 0.1279, lr_0 = 1.7259e-04
Loss = 2.6550e-05, PNorm = 66.7060, GNorm = 0.2298, lr_0 = 1.7182e-04
Loss = 2.2663e-05, PNorm = 66.7072, GNorm = 0.2110, lr_0 = 1.7106e-04
Loss = 2.0820e-05, PNorm = 66.7085, GNorm = 0.1858, lr_0 = 1.7031e-04
Validation rmse logD = 0.594413
Validation R2 logD = 0.727526
Epoch 76
Train function
Loss = 1.8389e-05, PNorm = 66.7104, GNorm = 0.0923, lr_0 = 1.6948e-04
Loss = 1.8190e-05, PNorm = 66.7122, GNorm = 0.1263, lr_0 = 1.6873e-04
Loss = 1.4879e-05, PNorm = 66.7136, GNorm = 0.1269, lr_0 = 1.6798e-04
Loss = 1.3140e-05, PNorm = 66.7151, GNorm = 0.1268, lr_0 = 1.6724e-04
Loss = 2.2489e-05, PNorm = 66.7164, GNorm = 0.3797, lr_0 = 1.6650e-04
Validation rmse logD = 0.596517
Validation R2 logD = 0.725593
Epoch 77
Train function
Loss = 4.4889e-05, PNorm = 66.7186, GNorm = 0.4336, lr_0 = 1.6569e-04
Loss = 3.9929e-05, PNorm = 66.7211, GNorm = 0.1388, lr_0 = 1.6496e-04
Loss = 3.1548e-05, PNorm = 66.7248, GNorm = 0.0976, lr_0 = 1.6423e-04
Loss = 2.6139e-05, PNorm = 66.7266, GNorm = 0.2013, lr_0 = 1.6350e-04
Loss = 1.8850e-05, PNorm = 66.7298, GNorm = 0.0734, lr_0 = 1.6278e-04
Loss = 2.2088e-05, PNorm = 66.7313, GNorm = 0.0824, lr_0 = 1.6206e-04
Validation rmse logD = 0.594007
Validation R2 logD = 0.727898
Epoch 78
Train function
Loss = 2.1755e-05, PNorm = 66.7335, GNorm = 0.1574, lr_0 = 1.6127e-04
Loss = 1.7474e-05, PNorm = 66.7351, GNorm = 0.2828, lr_0 = 1.6055e-04
Loss = 2.0261e-05, PNorm = 66.7360, GNorm = 0.1032, lr_0 = 1.5984e-04
Loss = 2.1759e-05, PNorm = 66.7377, GNorm = 0.1012, lr_0 = 1.5914e-04
Loss = 1.8430e-05, PNorm = 66.7389, GNorm = 0.0451, lr_0 = 1.5843e-04
Validation rmse logD = 0.594262
Validation R2 logD = 0.727664
Epoch 79
Train function
Loss = 1.7146e-05, PNorm = 66.7410, GNorm = 0.2680, lr_0 = 1.5766e-04
Loss = 3.0413e-05, PNorm = 66.7432, GNorm = 0.2586, lr_0 = 1.5697e-04
Loss = 2.0879e-05, PNorm = 66.7453, GNorm = 0.1310, lr_0 = 1.5627e-04
Loss = 1.8241e-05, PNorm = 66.7461, GNorm = 0.0946, lr_0 = 1.5558e-04
Loss = 1.9648e-05, PNorm = 66.7475, GNorm = 0.0902, lr_0 = 1.5489e-04
Validation rmse logD = 0.595954
Validation R2 logD = 0.726111
Epoch 80
Train function
Loss = 1.3527e-05, PNorm = 66.7490, GNorm = 0.1338, lr_0 = 1.5421e-04
Loss = 2.0481e-05, PNorm = 66.7509, GNorm = 0.1475, lr_0 = 1.5352e-04
Loss = 1.5528e-05, PNorm = 66.7518, GNorm = 0.2036, lr_0 = 1.5284e-04
Loss = 2.1644e-05, PNorm = 66.7539, GNorm = 0.2906, lr_0 = 1.5217e-04
Loss = 1.9581e-05, PNorm = 66.7557, GNorm = 0.3137, lr_0 = 1.5150e-04
Loss = 1.9123e-05, PNorm = 66.7576, GNorm = 0.0651, lr_0 = 1.5083e-04
Validation rmse logD = 0.595194
Validation R2 logD = 0.726809
Epoch 81
Train function
Loss = 2.1433e-05, PNorm = 66.7600, GNorm = 0.0818, lr_0 = 1.5009e-04
Loss = 1.6126e-05, PNorm = 66.7606, GNorm = 0.1298, lr_0 = 1.4943e-04
Loss = 1.4590e-05, PNorm = 66.7621, GNorm = 0.1036, lr_0 = 1.4877e-04
Loss = 1.6857e-05, PNorm = 66.7639, GNorm = 0.1370, lr_0 = 1.4811e-04
Loss = 1.6278e-05, PNorm = 66.7647, GNorm = 0.1081, lr_0 = 1.4745e-04
Validation rmse logD = 0.595703
Validation R2 logD = 0.726342
Epoch 82
Train function
Loss = 1.9098e-05, PNorm = 66.7668, GNorm = 0.2011, lr_0 = 1.4674e-04
Loss = 2.3431e-05, PNorm = 66.7684, GNorm = 0.0995, lr_0 = 1.4609e-04
Loss = 1.9374e-05, PNorm = 66.7697, GNorm = 0.0830, lr_0 = 1.4544e-04
Loss = 1.9750e-05, PNorm = 66.7718, GNorm = 0.0717, lr_0 = 1.4480e-04
Loss = 1.1115e-05, PNorm = 66.7720, GNorm = 0.0810, lr_0 = 1.4416e-04
Validation rmse logD = 0.594556
Validation R2 logD = 0.727394
Epoch 83
Train function
Loss = 1.2757e-05, PNorm = 66.7736, GNorm = 0.1365, lr_0 = 1.4346e-04
Loss = 1.4436e-05, PNorm = 66.7754, GNorm = 0.1353, lr_0 = 1.4282e-04
Loss = 1.3173e-05, PNorm = 66.7770, GNorm = 0.1559, lr_0 = 1.4219e-04
Loss = 1.2612e-05, PNorm = 66.7789, GNorm = 0.2040, lr_0 = 1.4156e-04
Loss = 1.1759e-05, PNorm = 66.7795, GNorm = 0.0386, lr_0 = 1.4093e-04
Loss = 1.6293e-05, PNorm = 66.7807, GNorm = 0.0508, lr_0 = 1.4031e-04
Loss = 5.7072e-05, PNorm = 66.7809, GNorm = 0.1757, lr_0 = 1.4025e-04
Validation rmse logD = 0.594439
Validation R2 logD = 0.727502
Epoch 84
Train function
Loss = 1.0525e-05, PNorm = 66.7826, GNorm = 0.0673, lr_0 = 1.3963e-04
Loss = 1.1879e-05, PNorm = 66.7839, GNorm = 0.0662, lr_0 = 1.3901e-04
Loss = 1.0959e-05, PNorm = 66.7845, GNorm = 0.1038, lr_0 = 1.3840e-04
Loss = 1.1354e-05, PNorm = 66.7856, GNorm = 0.1031, lr_0 = 1.3778e-04
Loss = 1.4372e-05, PNorm = 66.7866, GNorm = 0.1793, lr_0 = 1.3717e-04
Validation rmse logD = 0.595837
Validation R2 logD = 0.726218
Epoch 85
Train function
Loss = 9.8685e-06, PNorm = 66.7874, GNorm = 0.1457, lr_0 = 1.3651e-04
Loss = 9.4072e-06, PNorm = 66.7885, GNorm = 0.0549, lr_0 = 1.3590e-04
Loss = 1.1638e-05, PNorm = 66.7899, GNorm = 0.0588, lr_0 = 1.3530e-04
Loss = 1.2593e-05, PNorm = 66.7918, GNorm = 0.1717, lr_0 = 1.3470e-04
Loss = 1.2151e-05, PNorm = 66.7932, GNorm = 0.0517, lr_0 = 1.3411e-04
Validation rmse logD = 0.593448
Validation R2 logD = 0.728409
Epoch 86
Train function
Loss = 1.1386e-05, PNorm = 66.7940, GNorm = 0.0797, lr_0 = 1.3346e-04
Loss = 1.2287e-05, PNorm = 66.7946, GNorm = 0.1115, lr_0 = 1.3287e-04
Loss = 1.2611e-05, PNorm = 66.7965, GNorm = 0.0648, lr_0 = 1.3228e-04
Loss = 1.2187e-05, PNorm = 66.7977, GNorm = 0.0728, lr_0 = 1.3169e-04
Loss = 9.3970e-06, PNorm = 66.7987, GNorm = 0.0584, lr_0 = 1.3111e-04
Validation rmse logD = 0.594503
Validation R2 logD = 0.727443
Epoch 87
Train function
Loss = 7.6144e-06, PNorm = 66.7998, GNorm = 0.1637, lr_0 = 1.3047e-04
Loss = 7.9103e-06, PNorm = 66.8003, GNorm = 0.1637, lr_0 = 1.2990e-04
Loss = 9.2927e-06, PNorm = 66.8017, GNorm = 0.0486, lr_0 = 1.2932e-04
Loss = 1.1436e-05, PNorm = 66.8031, GNorm = 0.0822, lr_0 = 1.2875e-04
Loss = 8.2755e-06, PNorm = 66.8044, GNorm = 0.0542, lr_0 = 1.2818e-04
Loss = 1.0375e-05, PNorm = 66.8052, GNorm = 0.0500, lr_0 = 1.2761e-04
Validation rmse logD = 0.596095
Validation R2 logD = 0.725982
Epoch 88
Train function
Loss = 2.0876e-05, PNorm = 66.8058, GNorm = 0.3024, lr_0 = 1.2699e-04
Loss = 2.4360e-05, PNorm = 66.8077, GNorm = 0.1502, lr_0 = 1.2643e-04
Loss = 1.5226e-05, PNorm = 66.8087, GNorm = 0.0802, lr_0 = 1.2587e-04
Loss = 1.0686e-05, PNorm = 66.8096, GNorm = 0.1858, lr_0 = 1.2531e-04
Loss = 1.3926e-05, PNorm = 66.8113, GNorm = 0.1595, lr_0 = 1.2476e-04
Validation rmse logD = 0.596435
Validation R2 logD = 0.725669
Epoch 89
Train function
Loss = 1.2829e-05, PNorm = 66.8115, GNorm = 0.2191, lr_0 = 1.2415e-04
Loss = 1.6464e-05, PNorm = 66.8132, GNorm = 0.1435, lr_0 = 1.2360e-04
Loss = 1.1128e-05, PNorm = 66.8141, GNorm = 0.0786, lr_0 = 1.2306e-04
Loss = 1.4468e-05, PNorm = 66.8160, GNorm = 0.1297, lr_0 = 1.2251e-04
Loss = 1.4691e-05, PNorm = 66.8172, GNorm = 0.1164, lr_0 = 1.2197e-04
Validation rmse logD = 0.595376
Validation R2 logD = 0.726642
Epoch 90
Train function
Loss = 1.8939e-05, PNorm = 66.8192, GNorm = 0.1121, lr_0 = 1.2143e-04
Loss = 1.5470e-05, PNorm = 66.8204, GNorm = 0.2137, lr_0 = 1.2089e-04
Loss = 1.2867e-05, PNorm = 66.8205, GNorm = 0.1249, lr_0 = 1.2036e-04
Loss = 9.9074e-06, PNorm = 66.8218, GNorm = 0.0453, lr_0 = 1.1983e-04
Loss = 9.2463e-06, PNorm = 66.8230, GNorm = 0.0634, lr_0 = 1.1930e-04
Loss = 1.0606e-05, PNorm = 66.8242, GNorm = 0.1129, lr_0 = 1.1877e-04
Validation rmse logD = 0.595654
Validation R2 logD = 0.726387
Epoch 91
Train function
Loss = 1.3378e-05, PNorm = 66.8254, GNorm = 0.0681, lr_0 = 1.1819e-04
Loss = 1.0617e-05, PNorm = 66.8265, GNorm = 0.0903, lr_0 = 1.1767e-04
Loss = 1.1489e-05, PNorm = 66.8275, GNorm = 0.1001, lr_0 = 1.1715e-04
Loss = 1.2822e-05, PNorm = 66.8281, GNorm = 0.2271, lr_0 = 1.1663e-04
Loss = 1.1429e-05, PNorm = 66.8292, GNorm = 0.1482, lr_0 = 1.1611e-04
Validation rmse logD = 0.595293
Validation R2 logD = 0.726719
Epoch 92
Train function
Loss = 9.2422e-06, PNorm = 66.8302, GNorm = 0.0888, lr_0 = 1.1555e-04
Loss = 1.9815e-05, PNorm = 66.8315, GNorm = 0.2220, lr_0 = 1.1504e-04
Loss = 1.6361e-05, PNorm = 66.8321, GNorm = 0.1484, lr_0 = 1.1453e-04
Loss = 1.3489e-05, PNorm = 66.8327, GNorm = 0.0484, lr_0 = 1.1402e-04
Loss = 9.7124e-06, PNorm = 66.8339, GNorm = 0.0525, lr_0 = 1.1352e-04
Validation rmse logD = 0.595959
Validation R2 logD = 0.726106
Epoch 93
Train function
Loss = 8.1120e-06, PNorm = 66.8343, GNorm = 0.0662, lr_0 = 1.1297e-04
Loss = 7.6761e-06, PNorm = 66.8353, GNorm = 0.0516, lr_0 = 1.1247e-04
Loss = 7.9662e-06, PNorm = 66.8361, GNorm = 0.0568, lr_0 = 1.1197e-04
Loss = 9.3947e-06, PNorm = 66.8370, GNorm = 0.0615, lr_0 = 1.1147e-04
Loss = 1.0927e-05, PNorm = 66.8380, GNorm = 0.1983, lr_0 = 1.1098e-04
Loss = 1.6929e-05, PNorm = 66.8400, GNorm = 0.2329, lr_0 = 1.1049e-04
Validation rmse logD = 0.596662
Validation R2 logD = 0.725460
Epoch 94
Train function
Loss = 1.5965e-05, PNorm = 66.8414, GNorm = 0.1756, lr_0 = 1.0995e-04
Loss = 1.2496e-05, PNorm = 66.8424, GNorm = 0.0595, lr_0 = 1.0947e-04
Loss = 1.2210e-05, PNorm = 66.8440, GNorm = 0.1577, lr_0 = 1.0898e-04
Loss = 1.4557e-05, PNorm = 66.8450, GNorm = 0.2006, lr_0 = 1.0850e-04
Loss = 1.1959e-05, PNorm = 66.8469, GNorm = 0.0868, lr_0 = 1.0802e-04
Validation rmse logD = 0.596717
Validation R2 logD = 0.725409
Epoch 95
Train function
Loss = 9.6060e-06, PNorm = 66.8476, GNorm = 0.0634, lr_0 = 1.0749e-04
Loss = 7.5475e-06, PNorm = 66.8486, GNorm = 0.0453, lr_0 = 1.0702e-04
Loss = 1.1011e-05, PNorm = 66.8486, GNorm = 0.0443, lr_0 = 1.0654e-04
Loss = 9.4748e-06, PNorm = 66.8502, GNorm = 0.0600, lr_0 = 1.0607e-04
Loss = 1.0394e-05, PNorm = 66.8515, GNorm = 0.0798, lr_0 = 1.0560e-04
Validation rmse logD = 0.595621
Validation R2 logD = 0.726417
Epoch 96
Train function
Loss = 9.6804e-06, PNorm = 66.8522, GNorm = 0.0483, lr_0 = 1.0509e-04
Loss = 9.4904e-06, PNorm = 66.8529, GNorm = 0.0692, lr_0 = 1.0463e-04
Loss = 7.4280e-06, PNorm = 66.8534, GNorm = 0.0620, lr_0 = 1.0416e-04
Loss = 6.9957e-06, PNorm = 66.8543, GNorm = 0.0780, lr_0 = 1.0370e-04
Loss = 8.2547e-06, PNorm = 66.8553, GNorm = 0.0477, lr_0 = 1.0324e-04
Loss = 6.9704e-06, PNorm = 66.8561, GNorm = 0.1287, lr_0 = 1.0279e-04
Loss = 5.4263e-06, PNorm = 66.8562, GNorm = 0.0398, lr_0 = 1.0274e-04
Validation rmse logD = 0.595947
Validation R2 logD = 0.726117
Epoch 97
Train function
Loss = 5.4637e-06, PNorm = 66.8568, GNorm = 0.0375, lr_0 = 1.0229e-04
Loss = 7.9475e-06, PNorm = 66.8571, GNorm = 0.0957, lr_0 = 1.0183e-04
Loss = 7.2070e-06, PNorm = 66.8578, GNorm = 0.0728, lr_0 = 1.0138e-04
Loss = 8.1591e-06, PNorm = 66.8591, GNorm = 0.0443, lr_0 = 1.0094e-04
Loss = 7.3204e-06, PNorm = 66.8596, GNorm = 0.0943, lr_0 = 1.0049e-04
Validation rmse logD = 0.596668
Validation R2 logD = 0.725454
Epoch 98
Train function
Loss = 4.9555e-06, PNorm = 66.8605, GNorm = 0.0537, lr_0 = 1.0000e-04
Loss = 4.1792e-06, PNorm = 66.8606, GNorm = 0.0520, lr_0 = 1.0000e-04
Loss = 6.7777e-06, PNorm = 66.8615, GNorm = 0.1391, lr_0 = 1.0000e-04
Loss = 6.6266e-06, PNorm = 66.8626, GNorm = 0.0801, lr_0 = 1.0000e-04
Loss = 9.5550e-06, PNorm = 66.8632, GNorm = 0.1087, lr_0 = 1.0000e-04
Validation rmse logD = 0.594868
Validation R2 logD = 0.727108
Epoch 99
Train function
Loss = 6.5940e-06, PNorm = 66.8642, GNorm = 0.1509, lr_0 = 1.0000e-04
Loss = 9.7284e-06, PNorm = 66.8649, GNorm = 0.2165, lr_0 = 1.0000e-04
Loss = 1.2804e-05, PNorm = 66.8662, GNorm = 0.0990, lr_0 = 1.0000e-04
Loss = 7.5522e-06, PNorm = 66.8667, GNorm = 0.1055, lr_0 = 1.0000e-04
Loss = 9.8008e-06, PNorm = 66.8676, GNorm = 0.0510, lr_0 = 1.0000e-04
Loss = 1.2252e-05, PNorm = 66.8681, GNorm = 0.2521, lr_0 = 1.0000e-04
Validation rmse logD = 0.594930
Validation R2 logD = 0.727051
Model 0 best validation rmse = 0.583685 on epoch 35
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.571694
Model 0 test R2 logD = 0.773955
Ensemble test rmse  logD= 0.571694
Ensemble test R2  logD= 0.773955
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_313/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 1.9837e-02, PNorm = 55.5553, GNorm = 3.7873, lr_0 = 1.9340e-04
Loss = 1.8351e-02, PNorm = 55.5629, GNorm = 3.0891, lr_0 = 2.7830e-04
Loss = 1.8425e-02, PNorm = 55.5739, GNorm = 6.4572, lr_0 = 3.6321e-04
Loss = 1.6596e-02, PNorm = 55.5930, GNorm = 5.2121, lr_0 = 4.4811e-04
Loss = 1.4523e-02, PNorm = 55.6198, GNorm = 2.3855, lr_0 = 5.3302e-04
Validation rmse logD = 1.049170
Validation R2 logD = 0.273645
Epoch 1
Train function
Loss = 1.7792e-02, PNorm = 55.6671, GNorm = 3.8598, lr_0 = 6.2642e-04
Loss = 1.5615e-02, PNorm = 55.7250, GNorm = 1.5810, lr_0 = 7.1132e-04
Loss = 1.2225e-02, PNorm = 55.7907, GNorm = 2.7829, lr_0 = 7.9623e-04
Loss = 1.3286e-02, PNorm = 55.8640, GNorm = 6.1380, lr_0 = 8.8113e-04
Loss = 1.6634e-02, PNorm = 55.9466, GNorm = 5.2374, lr_0 = 9.6604e-04
Validation rmse logD = 1.074963
Validation R2 logD = 0.237492
Epoch 2
Train function
Loss = 1.4144e-02, PNorm = 56.0555, GNorm = 1.3026, lr_0 = 9.9690e-04
Loss = 1.1370e-02, PNorm = 56.1800, GNorm = 0.8862, lr_0 = 9.9249e-04
Loss = 1.2288e-02, PNorm = 56.2711, GNorm = 3.3202, lr_0 = 9.8810e-04
Loss = 1.0698e-02, PNorm = 56.3611, GNorm = 1.7562, lr_0 = 9.8373e-04
Loss = 1.1964e-02, PNorm = 56.4620, GNorm = 6.0971, lr_0 = 9.7938e-04
Validation rmse logD = 0.878803
Validation R2 logD = 0.490387
Epoch 3
Train function
Loss = 8.9123e-03, PNorm = 56.5634, GNorm = 1.9523, lr_0 = 9.7462e-04
Loss = 1.0492e-02, PNorm = 56.6385, GNorm = 3.5820, lr_0 = 9.7030e-04
Loss = 1.0641e-02, PNorm = 56.7246, GNorm = 5.4371, lr_0 = 9.6601e-04
Loss = 9.6295e-03, PNorm = 56.8236, GNorm = 1.5990, lr_0 = 9.6174e-04
Loss = 9.4964e-03, PNorm = 56.9217, GNorm = 2.6523, lr_0 = 9.5749e-04
Loss = 9.8605e-03, PNorm = 57.0240, GNorm = 0.8645, lr_0 = 9.5325e-04
Validation rmse logD = 0.888070
Validation R2 logD = 0.479583
Epoch 4
Train function
Loss = 9.2417e-03, PNorm = 57.1004, GNorm = 2.3171, lr_0 = 9.4861e-04
Loss = 8.2160e-03, PNorm = 57.1833, GNorm = 5.2153, lr_0 = 9.4442e-04
Loss = 8.7131e-03, PNorm = 57.2851, GNorm = 0.9971, lr_0 = 9.4024e-04
Loss = 8.1894e-03, PNorm = 57.3807, GNorm = 2.0889, lr_0 = 9.3608e-04
Loss = 8.2526e-03, PNorm = 57.4689, GNorm = 2.5812, lr_0 = 9.3194e-04
Validation rmse logD = 0.808045
Validation R2 logD = 0.569148
Epoch 5
Train function
Loss = 8.0034e-03, PNorm = 57.5784, GNorm = 1.0102, lr_0 = 9.2741e-04
Loss = 6.8045e-03, PNorm = 57.6864, GNorm = 1.5581, lr_0 = 9.2330e-04
Loss = 8.0270e-03, PNorm = 57.7638, GNorm = 1.2550, lr_0 = 9.1922e-04
Loss = 6.1341e-03, PNorm = 57.8650, GNorm = 1.2255, lr_0 = 9.1515e-04
Loss = 7.9028e-03, PNorm = 57.9387, GNorm = 2.3505, lr_0 = 9.1111e-04
Validation rmse logD = 0.877440
Validation R2 logD = 0.491967
Epoch 6
Train function
Loss = 1.0081e-02, PNorm = 58.0307, GNorm = 5.2646, lr_0 = 9.0667e-04
Loss = 7.8188e-03, PNorm = 58.1307, GNorm = 1.4526, lr_0 = 9.0266e-04
Loss = 7.1215e-03, PNorm = 58.2421, GNorm = 1.5291, lr_0 = 8.9867e-04
Loss = 4.9989e-03, PNorm = 58.3315, GNorm = 0.5840, lr_0 = 8.9469e-04
Loss = 6.3743e-03, PNorm = 58.4174, GNorm = 1.1270, lr_0 = 8.9074e-04
Loss = 7.8051e-03, PNorm = 58.4964, GNorm = 1.6473, lr_0 = 8.8680e-04
Validation rmse logD = 0.709033
Validation R2 logD = 0.668266
Epoch 7
Train function
Loss = 6.8069e-03, PNorm = 58.5787, GNorm = 1.5366, lr_0 = 8.8248e-04
Loss = 5.9308e-03, PNorm = 58.6911, GNorm = 1.8207, lr_0 = 8.7858e-04
Loss = 6.7718e-03, PNorm = 58.7928, GNorm = 1.4305, lr_0 = 8.7469e-04
Loss = 5.7714e-03, PNorm = 58.9040, GNorm = 1.9469, lr_0 = 8.7082e-04
Loss = 5.5975e-03, PNorm = 58.9950, GNorm = 1.9888, lr_0 = 8.6697e-04
Validation rmse logD = 0.782114
Validation R2 logD = 0.596357
Epoch 8
Train function
Loss = 6.4381e-03, PNorm = 59.0850, GNorm = 2.5511, lr_0 = 8.6276e-04
Loss = 5.0422e-03, PNorm = 59.1905, GNorm = 1.1665, lr_0 = 8.5894e-04
Loss = 4.8169e-03, PNorm = 59.2777, GNorm = 1.3330, lr_0 = 8.5514e-04
Loss = 5.0168e-03, PNorm = 59.3671, GNorm = 1.7713, lr_0 = 8.5136e-04
Loss = 5.8195e-03, PNorm = 59.4398, GNorm = 1.4432, lr_0 = 8.4759e-04
Validation rmse logD = 0.745091
Validation R2 logD = 0.633667
Epoch 9
Train function
Loss = 4.1875e-03, PNorm = 59.5284, GNorm = 1.6777, lr_0 = 8.4384e-04
Loss = 4.7294e-03, PNorm = 59.6029, GNorm = 2.5866, lr_0 = 8.4011e-04
Loss = 4.2030e-03, PNorm = 59.6956, GNorm = 0.5640, lr_0 = 8.3639e-04
Loss = 4.4980e-03, PNorm = 59.7995, GNorm = 0.7123, lr_0 = 8.3269e-04
Loss = 4.6057e-03, PNorm = 59.8917, GNorm = 1.8051, lr_0 = 8.2901e-04
Loss = 5.1871e-03, PNorm = 59.9679, GNorm = 1.8786, lr_0 = 8.2534e-04
Validation rmse logD = 0.691246
Validation R2 logD = 0.684701
Epoch 10
Train function
Loss = 4.9177e-03, PNorm = 60.0595, GNorm = 2.4246, lr_0 = 8.2133e-04
Loss = 4.6110e-03, PNorm = 60.1560, GNorm = 0.6957, lr_0 = 8.1770e-04
Loss = 4.3822e-03, PNorm = 60.2352, GNorm = 1.5372, lr_0 = 8.1408e-04
Loss = 3.4028e-03, PNorm = 60.3070, GNorm = 0.6038, lr_0 = 8.1048e-04
Loss = 3.6982e-03, PNorm = 60.3800, GNorm = 1.5525, lr_0 = 8.0689e-04
Validation rmse logD = 0.656027
Validation R2 logD = 0.716011
Epoch 11
Train function
Loss = 5.3202e-03, PNorm = 60.4968, GNorm = 2.7876, lr_0 = 8.0297e-04
Loss = 3.4276e-03, PNorm = 60.6165, GNorm = 1.3114, lr_0 = 7.9942e-04
Loss = 4.0009e-03, PNorm = 60.7109, GNorm = 0.7680, lr_0 = 7.9588e-04
Loss = 4.6075e-03, PNorm = 60.8127, GNorm = 0.8511, lr_0 = 7.9236e-04
Loss = 3.0680e-03, PNorm = 60.9111, GNorm = 1.1661, lr_0 = 7.8885e-04
Validation rmse logD = 0.647977
Validation R2 logD = 0.722938
Epoch 12
Train function
Loss = 3.2988e-03, PNorm = 61.0047, GNorm = 1.0938, lr_0 = 7.8502e-04
Loss = 3.4603e-03, PNorm = 61.0932, GNorm = 1.7219, lr_0 = 7.8154e-04
Loss = 2.9452e-03, PNorm = 61.1689, GNorm = 2.9505, lr_0 = 7.7809e-04
Loss = 3.5458e-03, PNorm = 61.2484, GNorm = 1.2098, lr_0 = 7.7465e-04
Loss = 3.1819e-03, PNorm = 61.3181, GNorm = 0.9399, lr_0 = 7.7122e-04
Loss = 3.3085e-03, PNorm = 61.3939, GNorm = 0.9162, lr_0 = 7.6781e-04
Loss = 1.7757e-02, PNorm = 61.4035, GNorm = 3.0004, lr_0 = 7.6747e-04
Validation rmse logD = 0.657659
Validation R2 logD = 0.714597
Epoch 13
Train function
Loss = 3.0713e-03, PNorm = 61.4648, GNorm = 0.5644, lr_0 = 7.6407e-04
Loss = 2.8960e-03, PNorm = 61.5437, GNorm = 1.6528, lr_0 = 7.6069e-04
Loss = 2.6774e-03, PNorm = 61.6180, GNorm = 1.0767, lr_0 = 7.5733e-04
Loss = 3.1071e-03, PNorm = 61.6815, GNorm = 0.8067, lr_0 = 7.5398e-04
Loss = 2.5767e-03, PNorm = 61.7407, GNorm = 1.3343, lr_0 = 7.5064e-04
Validation rmse logD = 0.662982
Validation R2 logD = 0.709958
Epoch 14
Train function
Loss = 4.9798e-03, PNorm = 61.8185, GNorm = 3.0728, lr_0 = 7.4699e-04
Loss = 3.6826e-03, PNorm = 61.9161, GNorm = 2.2160, lr_0 = 7.4369e-04
Loss = 2.7892e-03, PNorm = 61.9833, GNorm = 1.3149, lr_0 = 7.4040e-04
Loss = 2.6942e-03, PNorm = 62.0661, GNorm = 0.7364, lr_0 = 7.3712e-04
Loss = 2.2838e-03, PNorm = 62.1344, GNorm = 0.8126, lr_0 = 7.3386e-04
Validation rmse logD = 0.631578
Validation R2 logD = 0.736785
Epoch 15
Train function
Loss = 2.3102e-03, PNorm = 62.1906, GNorm = 1.5007, lr_0 = 7.3029e-04
Loss = 2.2096e-03, PNorm = 62.2549, GNorm = 0.6790, lr_0 = 7.2706e-04
Loss = 1.8616e-03, PNorm = 62.3049, GNorm = 1.2160, lr_0 = 7.2385e-04
Loss = 2.0944e-03, PNorm = 62.3671, GNorm = 1.1368, lr_0 = 7.2064e-04
Loss = 1.9671e-03, PNorm = 62.4190, GNorm = 0.6560, lr_0 = 7.1746e-04
Validation rmse logD = 0.629389
Validation R2 logD = 0.738606
Epoch 16
Train function
Loss = 1.5273e-03, PNorm = 62.4743, GNorm = 1.8861, lr_0 = 7.1397e-04
Loss = 1.8713e-03, PNorm = 62.5271, GNorm = 0.4545, lr_0 = 7.1081e-04
Loss = 1.8768e-03, PNorm = 62.5757, GNorm = 1.3515, lr_0 = 7.0766e-04
Loss = 1.8891e-03, PNorm = 62.6259, GNorm = 0.7169, lr_0 = 7.0453e-04
Loss = 1.8326e-03, PNorm = 62.6690, GNorm = 0.9232, lr_0 = 7.0142e-04
Loss = 1.9727e-03, PNorm = 62.7142, GNorm = 0.7437, lr_0 = 6.9831e-04
Validation rmse logD = 0.636488
Validation R2 logD = 0.732676
Epoch 17
Train function
Loss = 1.7679e-03, PNorm = 62.7791, GNorm = 1.6531, lr_0 = 6.9523e-04
Loss = 1.8517e-03, PNorm = 62.8325, GNorm = 1.8368, lr_0 = 6.9215e-04
Loss = 1.6799e-03, PNorm = 62.8782, GNorm = 0.8647, lr_0 = 6.8909e-04
Loss = 1.6241e-03, PNorm = 62.9368, GNorm = 0.9251, lr_0 = 6.8604e-04
Loss = 1.9616e-03, PNorm = 62.9857, GNorm = 1.4203, lr_0 = 6.8301e-04
Validation rmse logD = 0.598149
Validation R2 logD = 0.763911
Epoch 18
Train function
Loss = 1.3664e-03, PNorm = 63.0471, GNorm = 0.8180, lr_0 = 6.7968e-04
Loss = 1.3393e-03, PNorm = 63.0989, GNorm = 0.6130, lr_0 = 6.7668e-04
Loss = 1.2308e-03, PNorm = 63.1370, GNorm = 0.4750, lr_0 = 6.7368e-04
Loss = 1.5749e-03, PNorm = 63.1775, GNorm = 0.6959, lr_0 = 6.7070e-04
Loss = 1.5025e-03, PNorm = 63.2275, GNorm = 0.8073, lr_0 = 6.6774e-04
Validation rmse logD = 0.612616
Validation R2 logD = 0.752352
Epoch 19
Train function
Loss = 7.8501e-04, PNorm = 63.2716, GNorm = 0.4079, lr_0 = 6.6449e-04
Loss = 1.5797e-03, PNorm = 63.3174, GNorm = 1.3762, lr_0 = 6.6155e-04
Loss = 1.3696e-03, PNorm = 63.3640, GNorm = 0.8138, lr_0 = 6.5862e-04
Loss = 1.2487e-03, PNorm = 63.4058, GNorm = 0.6761, lr_0 = 6.5571e-04
Loss = 1.3475e-03, PNorm = 63.4493, GNorm = 0.7929, lr_0 = 6.5281e-04
Loss = 1.3149e-03, PNorm = 63.4822, GNorm = 0.5293, lr_0 = 6.4992e-04
Validation rmse logD = 0.597728
Validation R2 logD = 0.764243
Epoch 20
Train function
Loss = 1.0885e-03, PNorm = 63.5260, GNorm = 0.9166, lr_0 = 6.4676e-04
Loss = 1.0977e-03, PNorm = 63.5657, GNorm = 1.1983, lr_0 = 6.4390e-04
Loss = 1.2361e-03, PNorm = 63.6043, GNorm = 1.3081, lr_0 = 6.4105e-04
Loss = 1.2140e-03, PNorm = 63.6542, GNorm = 0.5596, lr_0 = 6.3822e-04
Loss = 1.3219e-03, PNorm = 63.7007, GNorm = 1.4492, lr_0 = 6.3539e-04
Validation rmse logD = 0.611833
Validation R2 logD = 0.752985
Epoch 21
Train function
Loss = 1.0064e-03, PNorm = 63.7305, GNorm = 0.9555, lr_0 = 6.3230e-04
Loss = 1.2004e-03, PNorm = 63.7712, GNorm = 0.6326, lr_0 = 6.2950e-04
Loss = 1.0557e-03, PNorm = 63.8090, GNorm = 0.6560, lr_0 = 6.2672e-04
Loss = 1.1649e-03, PNorm = 63.8512, GNorm = 1.6448, lr_0 = 6.2395e-04
Loss = 9.7606e-04, PNorm = 63.8892, GNorm = 1.0386, lr_0 = 6.2119e-04
Validation rmse logD = 0.602047
Validation R2 logD = 0.760824
Epoch 22
Train function
Loss = 1.1544e-03, PNorm = 63.9266, GNorm = 1.3376, lr_0 = 6.1817e-04
Loss = 8.5760e-04, PNorm = 63.9670, GNorm = 1.1121, lr_0 = 6.1543e-04
Loss = 8.7904e-04, PNorm = 63.9970, GNorm = 0.6852, lr_0 = 6.1271e-04
Loss = 8.0521e-04, PNorm = 64.0276, GNorm = 0.5556, lr_0 = 6.1000e-04
Loss = 1.0530e-03, PNorm = 64.0510, GNorm = 1.3436, lr_0 = 6.0730e-04
Loss = 1.1581e-03, PNorm = 64.0940, GNorm = 1.8859, lr_0 = 6.0461e-04
Validation rmse logD = 0.619621
Validation R2 logD = 0.746657
Epoch 23
Train function
Loss = 8.8334e-04, PNorm = 64.1302, GNorm = 0.9090, lr_0 = 6.0167e-04
Loss = 9.7641e-04, PNorm = 64.1688, GNorm = 0.7047, lr_0 = 5.9901e-04
Loss = 9.8087e-04, PNorm = 64.2076, GNorm = 0.7627, lr_0 = 5.9636e-04
Loss = 8.8318e-04, PNorm = 64.2447, GNorm = 0.5427, lr_0 = 5.9372e-04
Loss = 8.7193e-04, PNorm = 64.2740, GNorm = 0.6547, lr_0 = 5.9110e-04
Validation rmse logD = 0.619023
Validation R2 logD = 0.747145
Epoch 24
Train function
Loss = 6.8472e-04, PNorm = 64.3071, GNorm = 0.4355, lr_0 = 5.8822e-04
Loss = 6.7823e-04, PNorm = 64.3349, GNorm = 0.6528, lr_0 = 5.8562e-04
Loss = 6.9282e-04, PNorm = 64.3472, GNorm = 0.5041, lr_0 = 5.8303e-04
Loss = 8.4161e-04, PNorm = 64.3698, GNorm = 1.0165, lr_0 = 5.8045e-04
Loss = 7.9484e-04, PNorm = 64.4066, GNorm = 0.5418, lr_0 = 5.7788e-04
Validation rmse logD = 0.622892
Validation R2 logD = 0.743975
Epoch 25
Train function
Loss = 9.0219e-04, PNorm = 64.4468, GNorm = 1.5794, lr_0 = 5.7533e-04
Loss = 6.6769e-04, PNorm = 64.4697, GNorm = 0.5855, lr_0 = 5.7278e-04
Loss = 6.0044e-04, PNorm = 64.4978, GNorm = 0.7658, lr_0 = 5.7025e-04
Loss = 5.9393e-04, PNorm = 64.5167, GNorm = 0.4820, lr_0 = 5.6773e-04
Loss = 5.9651e-04, PNorm = 64.5354, GNorm = 0.3204, lr_0 = 5.6522e-04
Loss = 7.2143e-04, PNorm = 64.5575, GNorm = 0.4822, lr_0 = 5.6272e-04
Validation rmse logD = 0.606620
Validation R2 logD = 0.757176
Epoch 26
Train function
Loss = 7.3851e-04, PNorm = 64.5882, GNorm = 1.2071, lr_0 = 5.5998e-04
Loss = 6.5456e-04, PNorm = 64.6223, GNorm = 0.8905, lr_0 = 5.5750e-04
Loss = 6.5457e-04, PNorm = 64.6504, GNorm = 1.2838, lr_0 = 5.5503e-04
Loss = 5.5914e-04, PNorm = 64.6744, GNorm = 1.0234, lr_0 = 5.5258e-04
Loss = 6.7053e-04, PNorm = 64.6980, GNorm = 0.6302, lr_0 = 5.5014e-04
Validation rmse logD = 0.605232
Validation R2 logD = 0.758287
Epoch 27
Train function
Loss = 4.8562e-04, PNorm = 64.7205, GNorm = 0.6243, lr_0 = 5.4746e-04
Loss = 6.0599e-04, PNorm = 64.7442, GNorm = 0.3396, lr_0 = 5.4504e-04
Loss = 4.9349e-04, PNorm = 64.7655, GNorm = 0.5089, lr_0 = 5.4263e-04
Loss = 4.6993e-04, PNorm = 64.7898, GNorm = 0.4244, lr_0 = 5.4023e-04
Loss = 5.9787e-04, PNorm = 64.8074, GNorm = 0.7426, lr_0 = 5.3784e-04
Validation rmse logD = 0.627412
Validation R2 logD = 0.740245
Epoch 28
Train function
Loss = 6.2485e-04, PNorm = 64.8344, GNorm = 0.3605, lr_0 = 5.3522e-04
Loss = 5.1178e-04, PNorm = 64.8562, GNorm = 0.8123, lr_0 = 5.3285e-04
Loss = 4.8162e-04, PNorm = 64.8782, GNorm = 0.4905, lr_0 = 5.3050e-04
Loss = 4.9436e-04, PNorm = 64.8938, GNorm = 0.4999, lr_0 = 5.2815e-04
Loss = 5.3322e-04, PNorm = 64.9171, GNorm = 0.5928, lr_0 = 5.2581e-04
Loss = 5.1665e-04, PNorm = 64.9310, GNorm = 0.4354, lr_0 = 5.2349e-04
Loss = 3.9474e-03, PNorm = 64.9319, GNorm = 1.6003, lr_0 = 5.2326e-04
Validation rmse logD = 0.600080
Validation R2 logD = 0.762384
Epoch 29
Train function
Loss = 4.1908e-04, PNorm = 64.9513, GNorm = 0.4962, lr_0 = 5.2094e-04
Loss = 4.5335e-04, PNorm = 64.9651, GNorm = 0.4505, lr_0 = 5.1864e-04
Loss = 4.7561e-04, PNorm = 64.9841, GNorm = 0.4194, lr_0 = 5.1634e-04
Loss = 4.7122e-04, PNorm = 65.0050, GNorm = 0.5480, lr_0 = 5.1406e-04
Loss = 5.8555e-04, PNorm = 65.0238, GNorm = 0.2921, lr_0 = 5.1178e-04
Validation rmse logD = 0.606459
Validation R2 logD = 0.757306
Epoch 30
Train function
Loss = 3.7765e-04, PNorm = 65.0508, GNorm = 0.7062, lr_0 = 5.0930e-04
Loss = 5.0438e-04, PNorm = 65.0746, GNorm = 0.8974, lr_0 = 5.0704e-04
Loss = 4.4292e-04, PNorm = 65.0994, GNorm = 0.4568, lr_0 = 5.0480e-04
Loss = 4.1157e-04, PNorm = 65.1152, GNorm = 0.9428, lr_0 = 5.0257e-04
Loss = 5.0277e-04, PNorm = 65.1294, GNorm = 1.1341, lr_0 = 5.0034e-04
Validation rmse logD = 0.630119
Validation R2 logD = 0.737999
Epoch 31
Train function
Loss = 4.7280e-04, PNorm = 65.1515, GNorm = 0.9576, lr_0 = 4.9791e-04
Loss = 4.4956e-04, PNorm = 65.1691, GNorm = 1.1402, lr_0 = 4.9571e-04
Loss = 4.3177e-04, PNorm = 65.1905, GNorm = 0.6836, lr_0 = 4.9351e-04
Loss = 4.2999e-04, PNorm = 65.2136, GNorm = 0.2772, lr_0 = 4.9133e-04
Loss = 3.5869e-04, PNorm = 65.2319, GNorm = 0.2940, lr_0 = 4.8916e-04
Validation rmse logD = 0.600665
Validation R2 logD = 0.761921
Epoch 32
Train function
Loss = 1.8010e-04, PNorm = 65.2496, GNorm = 0.3434, lr_0 = 4.8678e-04
Loss = 4.1038e-04, PNorm = 65.2715, GNorm = 0.3906, lr_0 = 4.8463e-04
Loss = 4.3125e-04, PNorm = 65.2903, GNorm = 0.3972, lr_0 = 4.8248e-04
Loss = 5.2460e-04, PNorm = 65.3060, GNorm = 1.2921, lr_0 = 4.8035e-04
Loss = 4.3255e-04, PNorm = 65.3221, GNorm = 0.6866, lr_0 = 4.7822e-04
Loss = 3.7239e-04, PNorm = 65.3418, GNorm = 0.3238, lr_0 = 4.7611e-04
Validation rmse logD = 0.618304
Validation R2 logD = 0.747733
Epoch 33
Train function
Loss = 5.1463e-04, PNorm = 65.3646, GNorm = 0.9843, lr_0 = 4.7379e-04
Loss = 5.2285e-04, PNorm = 65.3757, GNorm = 0.3210, lr_0 = 4.7170e-04
Loss = 4.2310e-04, PNorm = 65.3955, GNorm = 0.3872, lr_0 = 4.6961e-04
Loss = 3.6357e-04, PNorm = 65.4097, GNorm = 0.6294, lr_0 = 4.6753e-04
Loss = 3.0802e-04, PNorm = 65.4236, GNorm = 0.4961, lr_0 = 4.6546e-04
Validation rmse logD = 0.601586
Validation R2 logD = 0.761190
Epoch 34
Train function
Loss = 3.7595e-04, PNorm = 65.4397, GNorm = 0.5639, lr_0 = 4.6341e-04
Loss = 3.3539e-04, PNorm = 65.4531, GNorm = 0.2692, lr_0 = 4.6136e-04
Loss = 3.4336e-04, PNorm = 65.4657, GNorm = 0.3908, lr_0 = 4.5931e-04
Loss = 3.0148e-04, PNorm = 65.4848, GNorm = 0.2548, lr_0 = 4.5728e-04
Loss = 3.1042e-04, PNorm = 65.4996, GNorm = 0.3172, lr_0 = 4.5526e-04
Validation rmse logD = 0.617273
Validation R2 logD = 0.748573
Epoch 35
Train function
Loss = 1.2415e-04, PNorm = 65.5125, GNorm = 0.3030, lr_0 = 4.5305e-04
Loss = 2.8203e-04, PNorm = 65.5260, GNorm = 0.4082, lr_0 = 4.5104e-04
Loss = 2.5612e-04, PNorm = 65.5370, GNorm = 0.9572, lr_0 = 4.4905e-04
Loss = 2.7299e-04, PNorm = 65.5486, GNorm = 0.7502, lr_0 = 4.4706e-04
Loss = 3.0728e-04, PNorm = 65.5649, GNorm = 0.2302, lr_0 = 4.4508e-04
Loss = 2.9205e-04, PNorm = 65.5785, GNorm = 0.3699, lr_0 = 4.4311e-04
Validation rmse logD = 0.612464
Validation R2 logD = 0.752475
Epoch 36
Train function
Loss = 2.1799e-04, PNorm = 65.5887, GNorm = 0.4445, lr_0 = 4.4096e-04
Loss = 2.7828e-04, PNorm = 65.5954, GNorm = 0.3034, lr_0 = 4.3901e-04
Loss = 2.8056e-04, PNorm = 65.6089, GNorm = 0.5579, lr_0 = 4.3707e-04
Loss = 2.3588e-04, PNorm = 65.6233, GNorm = 0.8243, lr_0 = 4.3513e-04
Loss = 2.2392e-04, PNorm = 65.6318, GNorm = 0.4409, lr_0 = 4.3321e-04
Validation rmse logD = 0.615071
Validation R2 logD = 0.750363
Epoch 37
Train function
Loss = 2.4918e-04, PNorm = 65.6476, GNorm = 0.5345, lr_0 = 4.3110e-04
Loss = 1.9091e-04, PNorm = 65.6577, GNorm = 0.2321, lr_0 = 4.2919e-04
Loss = 2.0644e-04, PNorm = 65.6755, GNorm = 0.1862, lr_0 = 4.2729e-04
Loss = 2.1536e-04, PNorm = 65.6865, GNorm = 0.2590, lr_0 = 4.2540e-04
Loss = 2.5638e-04, PNorm = 65.6934, GNorm = 0.7349, lr_0 = 4.2352e-04
Validation rmse logD = 0.602582
Validation R2 logD = 0.760398
Epoch 38
Train function
Loss = 2.1713e-04, PNorm = 65.7041, GNorm = 0.3698, lr_0 = 4.2146e-04
Loss = 2.6163e-04, PNorm = 65.7172, GNorm = 0.4236, lr_0 = 4.1960e-04
Loss = 3.0440e-04, PNorm = 65.7301, GNorm = 0.2839, lr_0 = 4.1774e-04
Loss = 2.8448e-04, PNorm = 65.7397, GNorm = 0.2665, lr_0 = 4.1589e-04
Loss = 2.7708e-04, PNorm = 65.7545, GNorm = 0.2174, lr_0 = 4.1406e-04
Loss = 2.5582e-04, PNorm = 65.7710, GNorm = 0.3290, lr_0 = 4.1222e-04
Validation rmse logD = 0.608606
Validation R2 logD = 0.755584
Epoch 39
Train function
Loss = 2.7133e-04, PNorm = 65.7847, GNorm = 0.4091, lr_0 = 4.1022e-04
Loss = 2.2368e-04, PNorm = 65.7988, GNorm = 0.4790, lr_0 = 4.0840e-04
Loss = 2.5899e-04, PNorm = 65.8079, GNorm = 0.5331, lr_0 = 4.0660e-04
Loss = 2.2328e-04, PNorm = 65.8186, GNorm = 0.3263, lr_0 = 4.0480e-04
Loss = 2.3988e-04, PNorm = 65.8271, GNorm = 0.3639, lr_0 = 4.0301e-04
Validation rmse logD = 0.610568
Validation R2 logD = 0.754005
Epoch 40
Train function
Loss = 2.4643e-04, PNorm = 65.8405, GNorm = 0.6963, lr_0 = 4.0105e-04
Loss = 3.1279e-04, PNorm = 65.8557, GNorm = 0.4762, lr_0 = 3.9927e-04
Loss = 2.1875e-04, PNorm = 65.8670, GNorm = 0.5992, lr_0 = 3.9751e-04
Loss = 2.7260e-04, PNorm = 65.8788, GNorm = 0.6065, lr_0 = 3.9575e-04
Loss = 2.3408e-04, PNorm = 65.8935, GNorm = 0.8322, lr_0 = 3.9400e-04
Validation rmse logD = 0.611076
Validation R2 logD = 0.753596
Epoch 41
Train function
Loss = 1.9438e-04, PNorm = 65.9054, GNorm = 0.6545, lr_0 = 3.9208e-04
Loss = 1.9065e-04, PNorm = 65.9155, GNorm = 0.6835, lr_0 = 3.9035e-04
Loss = 2.1917e-04, PNorm = 65.9262, GNorm = 0.5254, lr_0 = 3.8862e-04
Loss = 1.6920e-04, PNorm = 65.9359, GNorm = 0.3142, lr_0 = 3.8690e-04
Loss = 1.5234e-04, PNorm = 65.9432, GNorm = 0.4118, lr_0 = 3.8519e-04
Loss = 1.5434e-04, PNorm = 65.9482, GNorm = 0.1643, lr_0 = 3.8349e-04
Validation rmse logD = 0.608936
Validation R2 logD = 0.755319
Epoch 42
Train function
Loss = 1.5667e-04, PNorm = 65.9538, GNorm = 0.1955, lr_0 = 3.8179e-04
Loss = 1.4834e-04, PNorm = 65.9626, GNorm = 0.3873, lr_0 = 3.8010e-04
Loss = 1.4925e-04, PNorm = 65.9715, GNorm = 0.2542, lr_0 = 3.7842e-04
Loss = 1.6897e-04, PNorm = 65.9767, GNorm = 0.4467, lr_0 = 3.7675e-04
Loss = 1.5169e-04, PNorm = 65.9867, GNorm = 0.3122, lr_0 = 3.7508e-04
Validation rmse logD = 0.607032
Validation R2 logD = 0.756847
Epoch 43
Train function
Loss = 1.1996e-04, PNorm = 65.9954, GNorm = 0.1650, lr_0 = 3.7326e-04
Loss = 1.3300e-04, PNorm = 66.0008, GNorm = 0.2237, lr_0 = 3.7160e-04
Loss = 1.2413e-04, PNorm = 66.0051, GNorm = 0.2509, lr_0 = 3.6996e-04
Loss = 1.3936e-04, PNorm = 66.0106, GNorm = 0.4914, lr_0 = 3.6832e-04
Loss = 1.5169e-04, PNorm = 66.0173, GNorm = 0.3131, lr_0 = 3.6669e-04
Validation rmse logD = 0.604847
Validation R2 logD = 0.758594
Epoch 44
Train function
Loss = 1.2085e-04, PNorm = 66.0274, GNorm = 0.1966, lr_0 = 3.6491e-04
Loss = 1.4386e-04, PNorm = 66.0320, GNorm = 0.5821, lr_0 = 3.6330e-04
Loss = 1.3115e-04, PNorm = 66.0372, GNorm = 0.2761, lr_0 = 3.6169e-04
Loss = 1.3190e-04, PNorm = 66.0442, GNorm = 0.1762, lr_0 = 3.6009e-04
Loss = 1.5531e-04, PNorm = 66.0519, GNorm = 0.1946, lr_0 = 3.5850e-04
Loss = 1.2454e-04, PNorm = 66.0609, GNorm = 0.5461, lr_0 = 3.5691e-04
Loss = 9.3859e-04, PNorm = 66.0614, GNorm = 0.6263, lr_0 = 3.5675e-04
Validation rmse logD = 0.606689
Validation R2 logD = 0.757121
Epoch 45
Train function
Loss = 1.0781e-04, PNorm = 66.0655, GNorm = 0.2553, lr_0 = 3.5518e-04
Loss = 1.2023e-04, PNorm = 66.0715, GNorm = 0.3655, lr_0 = 3.5360e-04
Loss = 1.2009e-04, PNorm = 66.0768, GNorm = 0.2389, lr_0 = 3.5204e-04
Loss = 1.3660e-04, PNorm = 66.0867, GNorm = 0.5141, lr_0 = 3.5048e-04
Loss = 1.4910e-04, PNorm = 66.0930, GNorm = 0.4933, lr_0 = 3.4893e-04
Validation rmse logD = 0.611300
Validation R2 logD = 0.753415
Epoch 46
Train function
Loss = 1.2964e-04, PNorm = 66.0991, GNorm = 0.3928, lr_0 = 3.4724e-04
Loss = 1.2326e-04, PNorm = 66.1057, GNorm = 0.1804, lr_0 = 3.4570e-04
Loss = 1.2386e-04, PNorm = 66.1117, GNorm = 0.2307, lr_0 = 3.4417e-04
Loss = 1.3430e-04, PNorm = 66.1176, GNorm = 0.3394, lr_0 = 3.4265e-04
Loss = 9.9968e-05, PNorm = 66.1259, GNorm = 0.2104, lr_0 = 3.4113e-04
Validation rmse logD = 0.606334
Validation R2 logD = 0.757405
Epoch 47
Train function
Loss = 7.6500e-05, PNorm = 66.1327, GNorm = 0.1809, lr_0 = 3.3947e-04
Loss = 9.5045e-05, PNorm = 66.1387, GNorm = 0.3289, lr_0 = 3.3797e-04
Loss = 1.4615e-04, PNorm = 66.1439, GNorm = 0.1945, lr_0 = 3.3648e-04
Loss = 1.2668e-04, PNorm = 66.1492, GNorm = 0.4998, lr_0 = 3.3499e-04
Loss = 1.1925e-04, PNorm = 66.1558, GNorm = 0.6230, lr_0 = 3.3351e-04
Validation rmse logD = 0.610134
Validation R2 logD = 0.754355
Epoch 48
Train function
Loss = 1.0191e-04, PNorm = 66.1596, GNorm = 0.4073, lr_0 = 3.3188e-04
Loss = 1.0042e-04, PNorm = 66.1681, GNorm = 0.7660, lr_0 = 3.3042e-04
Loss = 1.2206e-04, PNorm = 66.1759, GNorm = 0.2658, lr_0 = 3.2895e-04
Loss = 8.7133e-05, PNorm = 66.1811, GNorm = 0.4982, lr_0 = 3.2750e-04
Loss = 1.1599e-04, PNorm = 66.1899, GNorm = 0.5198, lr_0 = 3.2605e-04
Loss = 1.1844e-04, PNorm = 66.1945, GNorm = 0.1221, lr_0 = 3.2461e-04
Validation rmse logD = 0.608418
Validation R2 logD = 0.755735
Epoch 49
Train function
Loss = 1.1441e-04, PNorm = 66.2006, GNorm = 0.2853, lr_0 = 3.2303e-04
Loss = 1.0581e-04, PNorm = 66.2070, GNorm = 0.2058, lr_0 = 3.2160e-04
Loss = 1.1058e-04, PNorm = 66.2136, GNorm = 0.1575, lr_0 = 3.2018e-04
Loss = 1.1068e-04, PNorm = 66.2203, GNorm = 0.3969, lr_0 = 3.1876e-04
Loss = 1.0164e-04, PNorm = 66.2247, GNorm = 0.2556, lr_0 = 3.1735e-04
Validation rmse logD = 0.607923
Validation R2 logD = 0.756132
Epoch 50
Train function
Loss = 1.0448e-04, PNorm = 66.2294, GNorm = 0.4025, lr_0 = 3.1595e-04
Loss = 8.0258e-05, PNorm = 66.2353, GNorm = 0.1314, lr_0 = 3.1455e-04
Loss = 1.0083e-04, PNorm = 66.2394, GNorm = 0.4966, lr_0 = 3.1316e-04
Loss = 8.2017e-05, PNorm = 66.2433, GNorm = 0.1622, lr_0 = 3.1177e-04
Loss = 1.0399e-04, PNorm = 66.2505, GNorm = 0.2481, lr_0 = 3.1039e-04
Validation rmse logD = 0.610135
Validation R2 logD = 0.754355
Epoch 51
Train function
Loss = 5.5803e-05, PNorm = 66.2580, GNorm = 0.1183, lr_0 = 3.0888e-04
Loss = 6.6457e-05, PNorm = 66.2650, GNorm = 0.2102, lr_0 = 3.0752e-04
Loss = 7.9593e-05, PNorm = 66.2711, GNorm = 0.2168, lr_0 = 3.0616e-04
Loss = 8.8877e-05, PNorm = 66.2768, GNorm = 0.1886, lr_0 = 3.0480e-04
Loss = 7.5216e-05, PNorm = 66.2810, GNorm = 0.2392, lr_0 = 3.0346e-04
Loss = 9.1024e-05, PNorm = 66.2875, GNorm = 0.3467, lr_0 = 3.0211e-04
Validation rmse logD = 0.607384
Validation R2 logD = 0.756565
Epoch 52
Train function
Loss = 6.9945e-05, PNorm = 66.2880, GNorm = 0.2307, lr_0 = 3.0064e-04
Loss = 7.9044e-05, PNorm = 66.2887, GNorm = 0.1955, lr_0 = 2.9931e-04
Loss = 9.3308e-05, PNorm = 66.2954, GNorm = 0.2835, lr_0 = 2.9799e-04
Loss = 1.0772e-04, PNorm = 66.3007, GNorm = 0.2454, lr_0 = 2.9667e-04
Loss = 1.0864e-04, PNorm = 66.3104, GNorm = 0.5575, lr_0 = 2.9536e-04
Validation rmse logD = 0.610275
Validation R2 logD = 0.754242
Epoch 53
Train function
Loss = 1.0168e-04, PNorm = 66.3187, GNorm = 0.2743, lr_0 = 2.9392e-04
Loss = 1.0335e-04, PNorm = 66.3221, GNorm = 0.2163, lr_0 = 2.9262e-04
Loss = 9.1872e-05, PNorm = 66.3287, GNorm = 0.3173, lr_0 = 2.9133e-04
Loss = 9.4108e-05, PNorm = 66.3339, GNorm = 0.5859, lr_0 = 2.9004e-04
Loss = 7.6728e-05, PNorm = 66.3394, GNorm = 0.3033, lr_0 = 2.8876e-04
Validation rmse logD = 0.611412
Validation R2 logD = 0.753325
Epoch 54
Train function
Loss = 9.8052e-05, PNorm = 66.3433, GNorm = 0.5029, lr_0 = 2.8735e-04
Loss = 8.2831e-05, PNorm = 66.3468, GNorm = 0.1479, lr_0 = 2.8608e-04
Loss = 8.4670e-05, PNorm = 66.3543, GNorm = 0.1803, lr_0 = 2.8482e-04
Loss = 8.4410e-05, PNorm = 66.3583, GNorm = 0.2475, lr_0 = 2.8356e-04
Loss = 9.3107e-05, PNorm = 66.3641, GNorm = 0.2061, lr_0 = 2.8230e-04
Loss = 5.8873e-05, PNorm = 66.3684, GNorm = 0.1927, lr_0 = 2.8105e-04
Validation rmse logD = 0.610710
Validation R2 logD = 0.753891
Epoch 55
Train function
Loss = 6.8868e-05, PNorm = 66.3703, GNorm = 0.5125, lr_0 = 2.7969e-04
Loss = 9.2992e-05, PNorm = 66.3745, GNorm = 0.2378, lr_0 = 2.7845e-04
Loss = 6.0659e-05, PNorm = 66.3790, GNorm = 0.3498, lr_0 = 2.7722e-04
Loss = 8.5050e-05, PNorm = 66.3836, GNorm = 0.1419, lr_0 = 2.7599e-04
Loss = 7.5252e-05, PNorm = 66.3887, GNorm = 0.1975, lr_0 = 2.7477e-04
Validation rmse logD = 0.608342
Validation R2 logD = 0.755796
Epoch 56
Train function
Loss = 7.1102e-05, PNorm = 66.3945, GNorm = 0.4586, lr_0 = 2.7343e-04
Loss = 8.9870e-05, PNorm = 66.3986, GNorm = 0.1454, lr_0 = 2.7222e-04
Loss = 6.1473e-05, PNorm = 66.4014, GNorm = 0.1932, lr_0 = 2.7102e-04
Loss = 6.3665e-05, PNorm = 66.4040, GNorm = 0.3157, lr_0 = 2.6982e-04
Loss = 6.0375e-05, PNorm = 66.4092, GNorm = 0.2279, lr_0 = 2.6863e-04
Validation rmse logD = 0.614642
Validation R2 logD = 0.750711
Epoch 57
Train function
Loss = 1.1577e-04, PNorm = 66.4153, GNorm = 0.1954, lr_0 = 2.6732e-04
Loss = 9.8510e-05, PNorm = 66.4183, GNorm = 0.3501, lr_0 = 2.6614e-04
Loss = 8.5950e-05, PNorm = 66.4225, GNorm = 0.5492, lr_0 = 2.6496e-04
Loss = 6.9154e-05, PNorm = 66.4264, GNorm = 0.6975, lr_0 = 2.6379e-04
Loss = 9.2759e-05, PNorm = 66.4324, GNorm = 0.7296, lr_0 = 2.6262e-04
Loss = 6.1478e-05, PNorm = 66.4367, GNorm = 0.1163, lr_0 = 2.6146e-04
Loss = 1.7013e-03, PNorm = 66.4376, GNorm = 1.0476, lr_0 = 2.6134e-04
Validation rmse logD = 0.612567
Validation R2 logD = 0.752392
Epoch 58
Train function
Loss = 1.2249e-04, PNorm = 66.4422, GNorm = 0.2904, lr_0 = 2.6019e-04
Loss = 1.3571e-04, PNorm = 66.4475, GNorm = 0.4959, lr_0 = 2.5904e-04
Loss = 1.0225e-04, PNorm = 66.4546, GNorm = 0.3727, lr_0 = 2.5789e-04
Loss = 1.0946e-04, PNorm = 66.4610, GNorm = 0.3487, lr_0 = 2.5675e-04
Loss = 7.2591e-05, PNorm = 66.4660, GNorm = 0.1204, lr_0 = 2.5561e-04
Validation rmse logD = 0.609163
Validation R2 logD = 0.755137
Epoch 59
Train function
Loss = 6.9576e-05, PNorm = 66.4710, GNorm = 0.2826, lr_0 = 2.5448e-04
Loss = 7.7027e-05, PNorm = 66.4731, GNorm = 0.4325, lr_0 = 2.5336e-04
Loss = 8.5025e-05, PNorm = 66.4755, GNorm = 0.6236, lr_0 = 2.5224e-04
Loss = 7.5935e-05, PNorm = 66.4799, GNorm = 0.1395, lr_0 = 2.5112e-04
Loss = 8.0294e-05, PNorm = 66.4833, GNorm = 0.3141, lr_0 = 2.5001e-04
Validation rmse logD = 0.607537
Validation R2 logD = 0.756442
Epoch 60
Train function
Loss = 6.0623e-05, PNorm = 66.4874, GNorm = 0.1625, lr_0 = 2.4879e-04
Loss = 5.7257e-05, PNorm = 66.4911, GNorm = 0.1437, lr_0 = 2.4769e-04
Loss = 6.4530e-05, PNorm = 66.4956, GNorm = 0.1967, lr_0 = 2.4660e-04
Loss = 5.7880e-05, PNorm = 66.5006, GNorm = 0.1546, lr_0 = 2.4551e-04
Loss = 5.9245e-05, PNorm = 66.5049, GNorm = 0.3195, lr_0 = 2.4442e-04
Loss = 7.2561e-05, PNorm = 66.5089, GNorm = 0.1853, lr_0 = 2.4334e-04
Loss = 6.7308e-04, PNorm = 66.5092, GNorm = 0.5554, lr_0 = 2.4323e-04
Validation rmse logD = 0.607650
Validation R2 logD = 0.756351
Epoch 61
Train function
Loss = 4.4518e-05, PNorm = 66.5116, GNorm = 0.1329, lr_0 = 2.4216e-04
Loss = 5.2166e-05, PNorm = 66.5159, GNorm = 0.1899, lr_0 = 2.4109e-04
Loss = 5.0813e-05, PNorm = 66.5188, GNorm = 0.1464, lr_0 = 2.4002e-04
Loss = 4.8959e-05, PNorm = 66.5209, GNorm = 0.1452, lr_0 = 2.3896e-04
Loss = 5.3278e-05, PNorm = 66.5223, GNorm = 0.3112, lr_0 = 2.3790e-04
Validation rmse logD = 0.610190
Validation R2 logD = 0.754310
Epoch 62
Train function
Loss = 3.9268e-05, PNorm = 66.5250, GNorm = 0.3048, lr_0 = 2.3674e-04
Loss = 6.6373e-05, PNorm = 66.5288, GNorm = 0.5099, lr_0 = 2.3570e-04
Loss = 6.1208e-05, PNorm = 66.5318, GNorm = 0.2781, lr_0 = 2.3465e-04
Loss = 4.7045e-05, PNorm = 66.5354, GNorm = 0.1322, lr_0 = 2.3362e-04
Loss = 4.8538e-05, PNorm = 66.5399, GNorm = 0.1338, lr_0 = 2.3258e-04
Validation rmse logD = 0.611048
Validation R2 logD = 0.753619
Epoch 63
Train function
Loss = 4.9480e-05, PNorm = 66.5442, GNorm = 0.4951, lr_0 = 2.3145e-04
Loss = 5.3331e-05, PNorm = 66.5461, GNorm = 0.1947, lr_0 = 2.3043e-04
Loss = 5.5785e-05, PNorm = 66.5497, GNorm = 0.2074, lr_0 = 2.2941e-04
Loss = 4.4911e-05, PNorm = 66.5516, GNorm = 0.1126, lr_0 = 2.2839e-04
Loss = 3.7772e-05, PNorm = 66.5545, GNorm = 0.1386, lr_0 = 2.2738e-04
Validation rmse logD = 0.612359
Validation R2 logD = 0.752560
Epoch 64
Train function
Loss = 9.2205e-05, PNorm = 66.5568, GNorm = 0.4950, lr_0 = 2.2628e-04
Loss = 3.7123e-05, PNorm = 66.5590, GNorm = 0.1017, lr_0 = 2.2528e-04
Loss = 3.8778e-05, PNorm = 66.5615, GNorm = 0.2466, lr_0 = 2.2428e-04
Loss = 4.0700e-05, PNorm = 66.5629, GNorm = 0.2580, lr_0 = 2.2329e-04
Loss = 4.3652e-05, PNorm = 66.5667, GNorm = 0.1496, lr_0 = 2.2230e-04
Loss = 4.5272e-05, PNorm = 66.5705, GNorm = 0.0991, lr_0 = 2.2132e-04
Validation rmse logD = 0.611532
Validation R2 logD = 0.753228
Epoch 65
Train function
Loss = 3.9648e-05, PNorm = 66.5724, GNorm = 0.1841, lr_0 = 2.2024e-04
Loss = 4.1470e-05, PNorm = 66.5752, GNorm = 0.1522, lr_0 = 2.1927e-04
Loss = 3.6270e-05, PNorm = 66.5769, GNorm = 0.0872, lr_0 = 2.1830e-04
Loss = 5.5079e-05, PNorm = 66.5786, GNorm = 0.2576, lr_0 = 2.1733e-04
Loss = 4.9818e-05, PNorm = 66.5825, GNorm = 0.3985, lr_0 = 2.1637e-04
Validation rmse logD = 0.612391
Validation R2 logD = 0.752535
Epoch 66
Train function
Loss = 2.8900e-05, PNorm = 66.5858, GNorm = 0.1155, lr_0 = 2.1532e-04
Loss = 2.9553e-05, PNorm = 66.5891, GNorm = 0.0794, lr_0 = 2.1436e-04
Loss = 4.0579e-05, PNorm = 66.5922, GNorm = 0.1148, lr_0 = 2.1342e-04
Loss = 3.0374e-05, PNorm = 66.5943, GNorm = 0.0815, lr_0 = 2.1247e-04
Loss = 3.8617e-05, PNorm = 66.5963, GNorm = 0.1137, lr_0 = 2.1153e-04
Validation rmse logD = 0.611245
Validation R2 logD = 0.753460
Epoch 67
Train function
Loss = 2.5244e-05, PNorm = 66.5988, GNorm = 0.2052, lr_0 = 2.1060e-04
Loss = 3.2594e-05, PNorm = 66.6009, GNorm = 0.1081, lr_0 = 2.0966e-04
Loss = 2.8968e-05, PNorm = 66.6012, GNorm = 0.0999, lr_0 = 2.0874e-04
Loss = 3.0802e-05, PNorm = 66.6052, GNorm = 0.1072, lr_0 = 2.0781e-04
Loss = 3.3406e-05, PNorm = 66.6061, GNorm = 0.2584, lr_0 = 2.0689e-04
Loss = 3.0028e-05, PNorm = 66.6078, GNorm = 0.0793, lr_0 = 2.0598e-04
Validation rmse logD = 0.608714
Validation R2 logD = 0.755497
Epoch 68
Train function
Loss = 3.1252e-05, PNorm = 66.6106, GNorm = 0.3540, lr_0 = 2.0498e-04
Loss = 3.1446e-05, PNorm = 66.6125, GNorm = 0.0912, lr_0 = 2.0407e-04
Loss = 2.9617e-05, PNorm = 66.6145, GNorm = 0.1712, lr_0 = 2.0317e-04
Loss = 4.1392e-05, PNorm = 66.6176, GNorm = 0.0843, lr_0 = 2.0227e-04
Loss = 2.8376e-05, PNorm = 66.6196, GNorm = 0.0817, lr_0 = 2.0137e-04
Validation rmse logD = 0.609063
Validation R2 logD = 0.755217
Epoch 69
Train function
Loss = 2.8252e-05, PNorm = 66.6224, GNorm = 0.1334, lr_0 = 2.0039e-04
Loss = 4.3629e-05, PNorm = 66.6253, GNorm = 0.3184, lr_0 = 1.9951e-04
Loss = 4.3347e-05, PNorm = 66.6281, GNorm = 0.0959, lr_0 = 1.9863e-04
Loss = 3.3866e-05, PNorm = 66.6297, GNorm = 0.1817, lr_0 = 1.9775e-04
Loss = 4.2704e-05, PNorm = 66.6321, GNorm = 0.2289, lr_0 = 1.9687e-04
Validation rmse logD = 0.611256
Validation R2 logD = 0.753451
Epoch 70
Train function
Loss = 5.4177e-05, PNorm = 66.6346, GNorm = 0.2563, lr_0 = 1.9592e-04
Loss = 4.1082e-05, PNorm = 66.6373, GNorm = 0.3141, lr_0 = 1.9505e-04
Loss = 4.1207e-05, PNorm = 66.6409, GNorm = 0.3922, lr_0 = 1.9419e-04
Loss = 4.0881e-05, PNorm = 66.6439, GNorm = 0.2604, lr_0 = 1.9333e-04
Loss = 3.9834e-05, PNorm = 66.6465, GNorm = 0.1392, lr_0 = 1.9247e-04
Loss = 3.5609e-05, PNorm = 66.6499, GNorm = 0.1664, lr_0 = 1.9162e-04
Validation rmse logD = 0.610847
Validation R2 logD = 0.753780
Epoch 71
Train function
Loss = 3.0737e-05, PNorm = 66.6523, GNorm = 0.0825, lr_0 = 1.9069e-04
Loss = 2.8452e-05, PNorm = 66.6540, GNorm = 0.2070, lr_0 = 1.8984e-04
Loss = 2.4517e-05, PNorm = 66.6567, GNorm = 0.0863, lr_0 = 1.8900e-04
Loss = 4.3572e-05, PNorm = 66.6583, GNorm = 0.2088, lr_0 = 1.8817e-04
Loss = 3.5925e-05, PNorm = 66.6596, GNorm = 0.3408, lr_0 = 1.8734e-04
Validation rmse logD = 0.610862
Validation R2 logD = 0.753768
Epoch 72
Train function
Loss = 3.2412e-05, PNorm = 66.6621, GNorm = 0.1975, lr_0 = 1.8643e-04
Loss = 3.4644e-05, PNorm = 66.6644, GNorm = 0.3816, lr_0 = 1.8560e-04
Loss = 3.3596e-05, PNorm = 66.6658, GNorm = 0.2131, lr_0 = 1.8478e-04
Loss = 2.4754e-05, PNorm = 66.6672, GNorm = 0.1357, lr_0 = 1.8396e-04
Loss = 2.9124e-05, PNorm = 66.6696, GNorm = 0.1620, lr_0 = 1.8315e-04
Validation rmse logD = 0.610522
Validation R2 logD = 0.754042
Epoch 73
Train function
Loss = 2.2286e-05, PNorm = 66.6727, GNorm = 0.1353, lr_0 = 1.8226e-04
Loss = 3.4693e-05, PNorm = 66.6757, GNorm = 0.0767, lr_0 = 1.8145e-04
Loss = 2.6161e-05, PNorm = 66.6767, GNorm = 0.0884, lr_0 = 1.8065e-04
Loss = 2.6676e-05, PNorm = 66.6784, GNorm = 0.1761, lr_0 = 1.7985e-04
Loss = 2.3227e-05, PNorm = 66.6798, GNorm = 0.0742, lr_0 = 1.7905e-04
Loss = 3.3339e-05, PNorm = 66.6820, GNorm = 0.1296, lr_0 = 1.7826e-04
Loss = 5.9357e-05, PNorm = 66.6822, GNorm = 0.1439, lr_0 = 1.7818e-04
Validation rmse logD = 0.611866
Validation R2 logD = 0.752959
Epoch 74
Train function
Loss = 1.9949e-05, PNorm = 66.6837, GNorm = 0.1025, lr_0 = 1.7739e-04
Loss = 2.0462e-05, PNorm = 66.6854, GNorm = 0.0756, lr_0 = 1.7661e-04
Loss = 1.7556e-05, PNorm = 66.6872, GNorm = 0.0684, lr_0 = 1.7583e-04
Loss = 2.3278e-05, PNorm = 66.6890, GNorm = 0.2171, lr_0 = 1.7505e-04
Loss = 2.5927e-05, PNorm = 66.6903, GNorm = 0.2770, lr_0 = 1.7428e-04
Validation rmse logD = 0.611470
Validation R2 logD = 0.753278
Epoch 75
Train function
Loss = 2.5259e-05, PNorm = 66.6917, GNorm = 0.2067, lr_0 = 1.7351e-04
Loss = 2.3626e-05, PNorm = 66.6933, GNorm = 0.0632, lr_0 = 1.7274e-04
Loss = 1.9172e-05, PNorm = 66.6958, GNorm = 0.0929, lr_0 = 1.7197e-04
Loss = 2.0661e-05, PNorm = 66.6981, GNorm = 0.1052, lr_0 = 1.7121e-04
Loss = 2.0379e-05, PNorm = 66.7002, GNorm = 0.0888, lr_0 = 1.7046e-04
Validation rmse logD = 0.610502
Validation R2 logD = 0.754059
Epoch 76
Train function
Loss = 2.3591e-05, PNorm = 66.7025, GNorm = 0.1162, lr_0 = 1.6963e-04
Loss = 1.9233e-05, PNorm = 66.7042, GNorm = 0.1677, lr_0 = 1.6888e-04
Loss = 1.8742e-05, PNorm = 66.7045, GNorm = 0.1081, lr_0 = 1.6813e-04
Loss = 1.7465e-05, PNorm = 66.7059, GNorm = 0.0684, lr_0 = 1.6739e-04
Loss = 1.6742e-05, PNorm = 66.7079, GNorm = 0.1495, lr_0 = 1.6665e-04
Loss = 1.9111e-05, PNorm = 66.7094, GNorm = 0.1437, lr_0 = 1.6591e-04
Loss = 9.3213e-05, PNorm = 66.7093, GNorm = 0.2259, lr_0 = 1.6584e-04
Validation rmse logD = 0.611770
Validation R2 logD = 0.753036
Epoch 77
Train function
Loss = 1.5018e-05, PNorm = 66.7099, GNorm = 0.0579, lr_0 = 1.6510e-04
Loss = 1.4999e-05, PNorm = 66.7115, GNorm = 0.0947, lr_0 = 1.6437e-04
Loss = 1.9171e-05, PNorm = 66.7122, GNorm = 0.1438, lr_0 = 1.6364e-04
Loss = 1.2300e-05, PNorm = 66.7141, GNorm = 0.0590, lr_0 = 1.6292e-04
Loss = 1.6577e-05, PNorm = 66.7160, GNorm = 0.1744, lr_0 = 1.6220e-04
Validation rmse logD = 0.610506
Validation R2 logD = 0.754055
Epoch 78
Train function
Loss = 2.9850e-05, PNorm = 66.7192, GNorm = 0.0799, lr_0 = 1.6141e-04
Loss = 2.4857e-05, PNorm = 66.7201, GNorm = 0.1699, lr_0 = 1.6070e-04
Loss = 2.6990e-05, PNorm = 66.7226, GNorm = 0.0894, lr_0 = 1.5999e-04
Loss = 1.5804e-05, PNorm = 66.7251, GNorm = 0.0758, lr_0 = 1.5928e-04
Loss = 2.0625e-05, PNorm = 66.7262, GNorm = 0.1483, lr_0 = 1.5857e-04
Validation rmse logD = 0.611665
Validation R2 logD = 0.753121
Epoch 79
Train function
Loss = 2.1554e-05, PNorm = 66.7270, GNorm = 0.1731, lr_0 = 1.5780e-04
Loss = 2.5918e-05, PNorm = 66.7281, GNorm = 0.1066, lr_0 = 1.5710e-04
Loss = 2.4143e-05, PNorm = 66.7295, GNorm = 0.2027, lr_0 = 1.5641e-04
Loss = 1.7261e-05, PNorm = 66.7310, GNorm = 0.0713, lr_0 = 1.5572e-04
Loss = 1.6597e-05, PNorm = 66.7321, GNorm = 0.0558, lr_0 = 1.5503e-04
Validation rmse logD = 0.611885
Validation R2 logD = 0.752943
Epoch 80
Train function
Loss = 2.2724e-05, PNorm = 66.7337, GNorm = 0.2068, lr_0 = 1.5427e-04
Loss = 1.7279e-05, PNorm = 66.7356, GNorm = 0.2070, lr_0 = 1.5359e-04
Loss = 1.9520e-05, PNorm = 66.7381, GNorm = 0.1243, lr_0 = 1.5291e-04
Loss = 1.6287e-05, PNorm = 66.7397, GNorm = 0.1514, lr_0 = 1.5224e-04
Loss = 1.8712e-05, PNorm = 66.7404, GNorm = 0.2762, lr_0 = 1.5156e-04
Loss = 2.1565e-05, PNorm = 66.7408, GNorm = 0.2249, lr_0 = 1.5089e-04
Validation rmse logD = 0.610921
Validation R2 logD = 0.753721
Epoch 81
Train function
Loss = 3.3475e-05, PNorm = 66.7439, GNorm = 0.3723, lr_0 = 1.5016e-04
Loss = 3.7465e-05, PNorm = 66.7462, GNorm = 0.3190, lr_0 = 1.4949e-04
Loss = 6.0927e-05, PNorm = 66.7495, GNorm = 0.1215, lr_0 = 1.4883e-04
Loss = 3.2149e-05, PNorm = 66.7521, GNorm = 0.2055, lr_0 = 1.4817e-04
Loss = 2.0447e-05, PNorm = 66.7540, GNorm = 0.1183, lr_0 = 1.4752e-04
Validation rmse logD = 0.613513
Validation R2 logD = 0.751627
Epoch 82
Train function
Loss = 3.1013e-05, PNorm = 66.7562, GNorm = 0.3498, lr_0 = 1.4680e-04
Loss = 3.1154e-05, PNorm = 66.7580, GNorm = 0.1770, lr_0 = 1.4615e-04
Loss = 1.9890e-05, PNorm = 66.7589, GNorm = 0.0783, lr_0 = 1.4551e-04
Loss = 2.2053e-05, PNorm = 66.7614, GNorm = 0.0753, lr_0 = 1.4486e-04
Loss = 2.2024e-05, PNorm = 66.7629, GNorm = 0.2558, lr_0 = 1.4422e-04
Validation rmse logD = 0.608932
Validation R2 logD = 0.755322
Epoch 83
Train function
Loss = 1.2878e-05, PNorm = 66.7636, GNorm = 0.0690, lr_0 = 1.4352e-04
Loss = 1.5355e-05, PNorm = 66.7652, GNorm = 0.0600, lr_0 = 1.4288e-04
Loss = 1.6028e-05, PNorm = 66.7666, GNorm = 0.0936, lr_0 = 1.4225e-04
Loss = 1.4193e-05, PNorm = 66.7681, GNorm = 0.1078, lr_0 = 1.4162e-04
Loss = 1.7290e-05, PNorm = 66.7705, GNorm = 0.0809, lr_0 = 1.4100e-04
Loss = 1.5771e-05, PNorm = 66.7715, GNorm = 0.2167, lr_0 = 1.4037e-04
Validation rmse logD = 0.610628
Validation R2 logD = 0.753957
Epoch 84
Train function
Loss = 1.3613e-05, PNorm = 66.7728, GNorm = 0.0686, lr_0 = 1.3975e-04
Loss = 1.0462e-05, PNorm = 66.7732, GNorm = 0.0734, lr_0 = 1.3913e-04
Loss = 1.1234e-05, PNorm = 66.7732, GNorm = 0.0988, lr_0 = 1.3852e-04
Loss = 1.5615e-05, PNorm = 66.7739, GNorm = 0.1707, lr_0 = 1.3791e-04
Loss = 1.3464e-05, PNorm = 66.7754, GNorm = 0.1273, lr_0 = 1.3730e-04
Validation rmse logD = 0.611084
Validation R2 logD = 0.753590
Epoch 85
Train function
Loss = 1.0658e-05, PNorm = 66.7769, GNorm = 0.0758, lr_0 = 1.3663e-04
Loss = 1.2256e-05, PNorm = 66.7782, GNorm = 0.0704, lr_0 = 1.3602e-04
Loss = 1.1417e-05, PNorm = 66.7788, GNorm = 0.1163, lr_0 = 1.3542e-04
Loss = 1.1812e-05, PNorm = 66.7804, GNorm = 0.0642, lr_0 = 1.3482e-04
Loss = 1.5000e-05, PNorm = 66.7809, GNorm = 0.0909, lr_0 = 1.3423e-04
Validation rmse logD = 0.611505
Validation R2 logD = 0.753250
Epoch 86
Train function
Loss = 7.5431e-06, PNorm = 66.7822, GNorm = 0.1663, lr_0 = 1.3357e-04
Loss = 1.2640e-05, PNorm = 66.7829, GNorm = 0.0928, lr_0 = 1.3298e-04
Loss = 1.2615e-05, PNorm = 66.7840, GNorm = 0.1805, lr_0 = 1.3239e-04
Loss = 1.3066e-05, PNorm = 66.7853, GNorm = 0.0835, lr_0 = 1.3181e-04
Loss = 1.0345e-05, PNorm = 66.7868, GNorm = 0.0733, lr_0 = 1.3123e-04
Loss = 9.7286e-06, PNorm = 66.7872, GNorm = 0.0558, lr_0 = 1.3065e-04
Validation rmse logD = 0.612197
Validation R2 logD = 0.752691
Epoch 87
Train function
Loss = 1.1679e-05, PNorm = 66.7888, GNorm = 0.1307, lr_0 = 1.3001e-04
Loss = 1.5372e-05, PNorm = 66.7899, GNorm = 0.0638, lr_0 = 1.2944e-04
Loss = 1.5350e-05, PNorm = 66.7910, GNorm = 0.1367, lr_0 = 1.2886e-04
Loss = 1.7099e-05, PNorm = 66.7910, GNorm = 0.1004, lr_0 = 1.2829e-04
Loss = 1.2515e-05, PNorm = 66.7927, GNorm = 0.0687, lr_0 = 1.2773e-04
Validation rmse logD = 0.612470
Validation R2 logD = 0.752470
Epoch 88
Train function
Loss = 1.2544e-05, PNorm = 66.7941, GNorm = 0.0642, lr_0 = 1.2710e-04
Loss = 1.1235e-05, PNorm = 66.7947, GNorm = 0.0755, lr_0 = 1.2654e-04
Loss = 1.3272e-05, PNorm = 66.7951, GNorm = 0.2231, lr_0 = 1.2598e-04
Loss = 1.0662e-05, PNorm = 66.7968, GNorm = 0.0521, lr_0 = 1.2542e-04
Loss = 1.1276e-05, PNorm = 66.7976, GNorm = 0.0933, lr_0 = 1.2487e-04
Validation rmse logD = 0.614115
Validation R2 logD = 0.751139
Epoch 89
Train function
Loss = 3.1545e-05, PNorm = 66.7994, GNorm = 0.1011, lr_0 = 1.2426e-04
Loss = 2.4437e-05, PNorm = 66.7997, GNorm = 0.1227, lr_0 = 1.2371e-04
Loss = 1.8377e-05, PNorm = 66.8010, GNorm = 0.2990, lr_0 = 1.2317e-04
Loss = 1.3551e-05, PNorm = 66.8022, GNorm = 0.2077, lr_0 = 1.2262e-04
Loss = 1.5117e-05, PNorm = 66.8037, GNorm = 0.1815, lr_0 = 1.2208e-04
Loss = 1.2156e-05, PNorm = 66.8049, GNorm = 0.1951, lr_0 = 1.2154e-04
Loss = 3.5814e-05, PNorm = 66.8051, GNorm = 0.1208, lr_0 = 1.2148e-04
Validation rmse logD = 0.611209
Validation R2 logD = 0.753488
Epoch 90
Train function
Loss = 9.3336e-06, PNorm = 66.8063, GNorm = 0.0537, lr_0 = 1.2095e-04
Loss = 1.0552e-05, PNorm = 66.8071, GNorm = 0.2096, lr_0 = 1.2041e-04
Loss = 1.5079e-05, PNorm = 66.8084, GNorm = 0.1475, lr_0 = 1.1988e-04
Loss = 1.2409e-05, PNorm = 66.8096, GNorm = 0.0928, lr_0 = 1.1935e-04
Loss = 1.2510e-05, PNorm = 66.8106, GNorm = 0.1088, lr_0 = 1.1882e-04
Validation rmse logD = 0.611748
Validation R2 logD = 0.753054
Epoch 91
Train function
Loss = 1.3034e-05, PNorm = 66.8121, GNorm = 0.1829, lr_0 = 1.1824e-04
Loss = 1.1659e-05, PNorm = 66.8130, GNorm = 0.1133, lr_0 = 1.1772e-04
Loss = 2.0308e-05, PNorm = 66.8133, GNorm = 0.1188, lr_0 = 1.1720e-04
Loss = 2.1466e-05, PNorm = 66.8144, GNorm = 0.0823, lr_0 = 1.1668e-04
Loss = 2.3218e-05, PNorm = 66.8149, GNorm = 0.4011, lr_0 = 1.1616e-04
Validation rmse logD = 0.610696
Validation R2 logD = 0.753902
Epoch 92
Train function
Loss = 2.2015e-05, PNorm = 66.8168, GNorm = 0.1698, lr_0 = 1.1565e-04
Loss = 2.1256e-05, PNorm = 66.8176, GNorm = 0.0839, lr_0 = 1.1514e-04
Loss = 1.8913e-05, PNorm = 66.8187, GNorm = 0.1437, lr_0 = 1.1463e-04
Loss = 1.6995e-05, PNorm = 66.8197, GNorm = 0.1488, lr_0 = 1.1412e-04
Loss = 1.5876e-05, PNorm = 66.8214, GNorm = 0.0707, lr_0 = 1.1362e-04
Loss = 1.2590e-05, PNorm = 66.8224, GNorm = 0.0759, lr_0 = 1.1312e-04
Loss = 7.2016e-05, PNorm = 66.8225, GNorm = 0.2277, lr_0 = 1.1307e-04
Validation rmse logD = 0.611659
Validation R2 logD = 0.753126
Epoch 93
Train function
Loss = 1.0651e-05, PNorm = 66.8230, GNorm = 0.0704, lr_0 = 1.1257e-04
Loss = 1.0675e-05, PNorm = 66.8236, GNorm = 0.0980, lr_0 = 1.1207e-04
Loss = 1.1316e-05, PNorm = 66.8250, GNorm = 0.1005, lr_0 = 1.1157e-04
Loss = 1.2402e-05, PNorm = 66.8258, GNorm = 0.0507, lr_0 = 1.1108e-04
Loss = 1.1081e-05, PNorm = 66.8264, GNorm = 0.1009, lr_0 = 1.1059e-04
Validation rmse logD = 0.612539
Validation R2 logD = 0.752415
Epoch 94
Train function
Loss = 1.0939e-05, PNorm = 66.8269, GNorm = 0.0412, lr_0 = 1.1005e-04
Loss = 8.4272e-06, PNorm = 66.8273, GNorm = 0.0538, lr_0 = 1.0956e-04
Loss = 9.5633e-06, PNorm = 66.8284, GNorm = 0.1945, lr_0 = 1.0908e-04
Loss = 1.0691e-05, PNorm = 66.8294, GNorm = 0.1387, lr_0 = 1.0860e-04
Loss = 1.1104e-05, PNorm = 66.8306, GNorm = 0.0855, lr_0 = 1.0811e-04
Validation rmse logD = 0.611123
Validation R2 logD = 0.753558
Epoch 95
Train function
Loss = 8.5408e-06, PNorm = 66.8312, GNorm = 0.0424, lr_0 = 1.0759e-04
Loss = 7.3768e-06, PNorm = 66.8324, GNorm = 0.0634, lr_0 = 1.0711e-04
Loss = 6.6668e-06, PNorm = 66.8330, GNorm = 0.0422, lr_0 = 1.0664e-04
Loss = 6.2338e-06, PNorm = 66.8338, GNorm = 0.0644, lr_0 = 1.0617e-04
Loss = 8.9996e-06, PNorm = 66.8352, GNorm = 0.0693, lr_0 = 1.0570e-04
Validation rmse logD = 0.612609
Validation R2 logD = 0.752358
Epoch 96
Train function
Loss = 3.9689e-06, PNorm = 66.8359, GNorm = 0.0793, lr_0 = 1.0518e-04
Loss = 8.2233e-06, PNorm = 66.8370, GNorm = 0.0457, lr_0 = 1.0472e-04
Loss = 6.2027e-06, PNorm = 66.8372, GNorm = 0.1233, lr_0 = 1.0426e-04
Loss = 5.9996e-06, PNorm = 66.8373, GNorm = 0.1011, lr_0 = 1.0379e-04
Loss = 9.1587e-06, PNorm = 66.8382, GNorm = 0.0984, lr_0 = 1.0333e-04
Loss = 8.3666e-06, PNorm = 66.8387, GNorm = 0.0552, lr_0 = 1.0288e-04
Validation rmse logD = 0.611239
Validation R2 logD = 0.753465
Epoch 97
Train function
Loss = 9.6081e-06, PNorm = 66.8390, GNorm = 0.1371, lr_0 = 1.0238e-04
Loss = 9.9086e-06, PNorm = 66.8398, GNorm = 0.0849, lr_0 = 1.0192e-04
Loss = 6.6115e-06, PNorm = 66.8402, GNorm = 0.0874, lr_0 = 1.0147e-04
Loss = 8.9163e-06, PNorm = 66.8412, GNorm = 0.0416, lr_0 = 1.0102e-04
Loss = 7.8895e-06, PNorm = 66.8423, GNorm = 0.0400, lr_0 = 1.0058e-04
Validation rmse logD = 0.612192
Validation R2 logD = 0.752695
Epoch 98
Train function
Loss = 8.5283e-06, PNorm = 66.8437, GNorm = 0.1164, lr_0 = 1.0009e-04
Loss = 1.0860e-05, PNorm = 66.8438, GNorm = 0.2195, lr_0 = 1.0000e-04
Loss = 8.9599e-06, PNorm = 66.8446, GNorm = 0.0531, lr_0 = 1.0000e-04
Loss = 8.1880e-06, PNorm = 66.8453, GNorm = 0.1103, lr_0 = 1.0000e-04
Loss = 9.0357e-06, PNorm = 66.8458, GNorm = 0.1279, lr_0 = 1.0000e-04
Validation rmse logD = 0.611900
Validation R2 logD = 0.752931
Epoch 99
Train function
Loss = 4.3026e-06, PNorm = 66.8460, GNorm = 0.0481, lr_0 = 1.0000e-04
Loss = 5.6269e-06, PNorm = 66.8468, GNorm = 0.0789, lr_0 = 1.0000e-04
Loss = 6.2341e-06, PNorm = 66.8472, GNorm = 0.0539, lr_0 = 1.0000e-04
Loss = 7.6744e-06, PNorm = 66.8476, GNorm = 0.1887, lr_0 = 1.0000e-04
Loss = 1.0426e-05, PNorm = 66.8483, GNorm = 0.1348, lr_0 = 1.0000e-04
Loss = 1.0650e-05, PNorm = 66.8490, GNorm = 0.0959, lr_0 = 1.0000e-04
Validation rmse logD = 0.611128
Validation R2 logD = 0.753554
Model 0 best validation rmse = 0.597728 on epoch 19
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.593103
Model 0 test R2 logD = 0.756708
Ensemble test rmse  logD= 0.593103
Ensemble test R2  logD= 0.756708
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_313/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.4097e-02, PNorm = 55.5556, GNorm = 6.7246, lr_0 = 1.9340e-04
Loss = 1.9043e-02, PNorm = 55.5638, GNorm = 6.9584, lr_0 = 2.7830e-04
Loss = 1.7039e-02, PNorm = 55.5773, GNorm = 3.7282, lr_0 = 3.6321e-04
Loss = 1.5822e-02, PNorm = 55.5942, GNorm = 5.6926, lr_0 = 4.4811e-04
Loss = 1.4936e-02, PNorm = 55.6174, GNorm = 1.0746, lr_0 = 5.3302e-04
Validation rmse logD = 1.048675
Validation R2 logD = 0.261778
Epoch 1
Train function
Loss = 1.6463e-02, PNorm = 55.6644, GNorm = 6.6761, lr_0 = 6.2642e-04
Loss = 1.3617e-02, PNorm = 55.7297, GNorm = 2.0693, lr_0 = 7.1132e-04
Loss = 1.1592e-02, PNorm = 55.8025, GNorm = 4.5676, lr_0 = 7.9623e-04
Loss = 1.2763e-02, PNorm = 55.8772, GNorm = 3.0090, lr_0 = 8.8113e-04
Loss = 1.2801e-02, PNorm = 55.9859, GNorm = 0.9418, lr_0 = 9.6604e-04
Validation rmse logD = 0.911669
Validation R2 logD = 0.442071
Epoch 2
Train function
Loss = 1.1581e-02, PNorm = 56.1144, GNorm = 2.7105, lr_0 = 9.9690e-04
Loss = 1.1085e-02, PNorm = 56.2110, GNorm = 4.6611, lr_0 = 9.9249e-04
Loss = 1.0507e-02, PNorm = 56.3309, GNorm = 3.5696, lr_0 = 9.8810e-04
Loss = 1.0655e-02, PNorm = 56.4422, GNorm = 8.1107, lr_0 = 9.8373e-04
Loss = 1.1362e-02, PNorm = 56.5627, GNorm = 2.3289, lr_0 = 9.7938e-04
Validation rmse logD = 0.942652
Validation R2 logD = 0.403504
Epoch 3
Train function
Loss = 1.3684e-02, PNorm = 56.6816, GNorm = 4.0993, lr_0 = 9.7462e-04
Loss = 8.3514e-03, PNorm = 56.7684, GNorm = 1.2746, lr_0 = 9.7030e-04
Loss = 7.8200e-03, PNorm = 56.8626, GNorm = 1.0778, lr_0 = 9.6601e-04
Loss = 8.3575e-03, PNorm = 56.9635, GNorm = 0.9769, lr_0 = 9.6174e-04
Loss = 9.8802e-03, PNorm = 57.0691, GNorm = 5.6697, lr_0 = 9.5749e-04
Loss = 8.5689e-03, PNorm = 57.1530, GNorm = 2.4717, lr_0 = 9.5325e-04
Validation rmse logD = 0.785288
Validation R2 logD = 0.586036
Epoch 4
Train function
Loss = 7.2153e-03, PNorm = 57.2410, GNorm = 1.5937, lr_0 = 9.4861e-04
Loss = 8.5427e-03, PNorm = 57.3275, GNorm = 2.0904, lr_0 = 9.4442e-04
Loss = 8.4021e-03, PNorm = 57.4335, GNorm = 1.9171, lr_0 = 9.4024e-04
Loss = 8.0366e-03, PNorm = 57.5349, GNorm = 2.1141, lr_0 = 9.3608e-04
Loss = 9.8580e-03, PNorm = 57.6140, GNorm = 3.3560, lr_0 = 9.3194e-04
Validation rmse logD = 1.054754
Validation R2 logD = 0.253195
Epoch 5
Train function
Loss = 8.6440e-03, PNorm = 57.7078, GNorm = 4.3295, lr_0 = 9.2741e-04
Loss = 8.9380e-03, PNorm = 57.7780, GNorm = 5.1462, lr_0 = 9.2330e-04
Loss = 7.7603e-03, PNorm = 57.8596, GNorm = 0.9006, lr_0 = 9.1922e-04
Loss = 7.3171e-03, PNorm = 57.9413, GNorm = 0.8049, lr_0 = 9.1515e-04
Loss = 7.9325e-03, PNorm = 58.0205, GNorm = 3.6168, lr_0 = 9.1111e-04
Validation rmse logD = 0.744620
Validation R2 logD = 0.627802
Epoch 6
Train function
Loss = 6.1249e-03, PNorm = 58.1057, GNorm = 1.3117, lr_0 = 9.0667e-04
Loss = 6.1508e-03, PNorm = 58.1807, GNorm = 1.9487, lr_0 = 9.0266e-04
Loss = 5.7416e-03, PNorm = 58.2454, GNorm = 0.7905, lr_0 = 8.9867e-04
Loss = 5.7102e-03, PNorm = 58.3223, GNorm = 1.9809, lr_0 = 8.9469e-04
Loss = 7.3029e-03, PNorm = 58.3953, GNorm = 4.2123, lr_0 = 8.9074e-04
Loss = 6.0552e-03, PNorm = 58.4628, GNorm = 0.9069, lr_0 = 8.8680e-04
Validation rmse logD = 0.748570
Validation R2 logD = 0.623843
Epoch 7
Train function
Loss = 7.3052e-03, PNorm = 58.5488, GNorm = 1.3687, lr_0 = 8.8248e-04
Loss = 5.5403e-03, PNorm = 58.6328, GNorm = 1.9459, lr_0 = 8.7858e-04
Loss = 4.7650e-03, PNorm = 58.7097, GNorm = 1.0910, lr_0 = 8.7469e-04
Loss = 4.8779e-03, PNorm = 58.7754, GNorm = 1.2192, lr_0 = 8.7082e-04
Loss = 5.6704e-03, PNorm = 58.8490, GNorm = 2.5852, lr_0 = 8.6697e-04
Validation rmse logD = 0.682394
Validation R2 logD = 0.687410
Epoch 8
Train function
Loss = 4.8077e-03, PNorm = 58.9404, GNorm = 1.1432, lr_0 = 8.6276e-04
Loss = 4.3409e-03, PNorm = 59.0211, GNorm = 2.0434, lr_0 = 8.5894e-04
Loss = 4.9827e-03, PNorm = 59.0972, GNorm = 0.7034, lr_0 = 8.5514e-04
Loss = 4.6740e-03, PNorm = 59.1828, GNorm = 2.1186, lr_0 = 8.5136e-04
Loss = 4.5789e-03, PNorm = 59.2589, GNorm = 2.5293, lr_0 = 8.4759e-04
Validation rmse logD = 0.686310
Validation R2 logD = 0.683812
Epoch 9
Train function
Loss = 4.3328e-03, PNorm = 59.3332, GNorm = 3.2020, lr_0 = 8.4384e-04
Loss = 3.8712e-03, PNorm = 59.3982, GNorm = 0.6962, lr_0 = 8.4011e-04
Loss = 4.3276e-03, PNorm = 59.4953, GNorm = 1.0142, lr_0 = 8.3639e-04
Loss = 3.9297e-03, PNorm = 59.5829, GNorm = 1.9154, lr_0 = 8.3269e-04
Loss = 4.2582e-03, PNorm = 59.6640, GNorm = 2.3862, lr_0 = 8.2901e-04
Loss = 4.8462e-03, PNorm = 59.7336, GNorm = 1.2959, lr_0 = 8.2534e-04
Validation rmse logD = 0.648857
Validation R2 logD = 0.717380
Epoch 10
Train function
Loss = 3.8445e-03, PNorm = 59.8161, GNorm = 1.8194, lr_0 = 8.2133e-04
Loss = 3.9054e-03, PNorm = 59.8880, GNorm = 2.5206, lr_0 = 8.1770e-04
Loss = 3.7637e-03, PNorm = 59.9678, GNorm = 1.4153, lr_0 = 8.1408e-04
Loss = 3.8364e-03, PNorm = 60.0228, GNorm = 1.9087, lr_0 = 8.1048e-04
Loss = 3.3715e-03, PNorm = 60.0884, GNorm = 0.9386, lr_0 = 8.0689e-04
Validation rmse logD = 0.659732
Validation R2 logD = 0.707827
Epoch 11
Train function
Loss = 3.6047e-03, PNorm = 60.1755, GNorm = 3.2313, lr_0 = 8.0297e-04
Loss = 3.3611e-03, PNorm = 60.2590, GNorm = 3.5058, lr_0 = 7.9942e-04
Loss = 3.4152e-03, PNorm = 60.3273, GNorm = 2.7197, lr_0 = 7.9588e-04
Loss = 3.1230e-03, PNorm = 60.3894, GNorm = 2.6444, lr_0 = 7.9236e-04
Loss = 3.3309e-03, PNorm = 60.4555, GNorm = 0.8805, lr_0 = 7.8885e-04
Validation rmse logD = 0.631282
Validation R2 logD = 0.732482
Epoch 12
Train function
Loss = 3.5396e-03, PNorm = 60.5173, GNorm = 1.1945, lr_0 = 7.8502e-04
Loss = 2.6385e-03, PNorm = 60.5776, GNorm = 0.8643, lr_0 = 7.8154e-04
Loss = 2.4787e-03, PNorm = 60.6257, GNorm = 0.7868, lr_0 = 7.7809e-04
Loss = 2.5386e-03, PNorm = 60.6760, GNorm = 1.3328, lr_0 = 7.7465e-04
Loss = 2.7739e-03, PNorm = 60.7322, GNorm = 0.8027, lr_0 = 7.7122e-04
Loss = 2.9641e-03, PNorm = 60.7869, GNorm = 2.2694, lr_0 = 7.6781e-04
Loss = 1.8972e-02, PNorm = 60.7950, GNorm = 1.8827, lr_0 = 7.6747e-04
Validation rmse logD = 0.626454
Validation R2 logD = 0.736559
Epoch 13
Train function
Loss = 2.2562e-03, PNorm = 60.8556, GNorm = 1.2072, lr_0 = 7.6407e-04
Loss = 2.8859e-03, PNorm = 60.9160, GNorm = 1.9626, lr_0 = 7.6069e-04
Loss = 2.7194e-03, PNorm = 60.9840, GNorm = 0.7705, lr_0 = 7.5733e-04
Loss = 2.7290e-03, PNorm = 61.0522, GNorm = 0.8859, lr_0 = 7.5398e-04
Loss = 2.6754e-03, PNorm = 61.1227, GNorm = 0.9238, lr_0 = 7.5064e-04
Validation rmse logD = 0.719279
Validation R2 logD = 0.652704
Epoch 14
Train function
Loss = 2.8580e-03, PNorm = 61.1908, GNorm = 1.4007, lr_0 = 7.4699e-04
Loss = 1.9047e-03, PNorm = 61.2444, GNorm = 0.6770, lr_0 = 7.4369e-04
Loss = 2.0117e-03, PNorm = 61.2987, GNorm = 1.1769, lr_0 = 7.4040e-04
Loss = 1.9535e-03, PNorm = 61.3475, GNorm = 0.7973, lr_0 = 7.3712e-04
Loss = 2.3854e-03, PNorm = 61.3889, GNorm = 1.2070, lr_0 = 7.3386e-04
Validation rmse logD = 0.612826
Validation R2 logD = 0.747897
Epoch 15
Train function
Loss = 2.5810e-03, PNorm = 61.4628, GNorm = 1.1403, lr_0 = 7.3029e-04
Loss = 2.3196e-03, PNorm = 61.5253, GNorm = 0.6653, lr_0 = 7.2706e-04
Loss = 2.1951e-03, PNorm = 61.5935, GNorm = 1.8963, lr_0 = 7.2385e-04
Loss = 2.3731e-03, PNorm = 61.6520, GNorm = 2.0590, lr_0 = 7.2064e-04
Loss = 2.0363e-03, PNorm = 61.7059, GNorm = 2.1695, lr_0 = 7.1746e-04
Validation rmse logD = 0.640362
Validation R2 logD = 0.724731
Epoch 16
Train function
Loss = 2.6336e-03, PNorm = 61.7781, GNorm = 1.6340, lr_0 = 7.1397e-04
Loss = 2.8671e-03, PNorm = 61.8346, GNorm = 3.0161, lr_0 = 7.1081e-04
Loss = 2.1073e-03, PNorm = 61.8965, GNorm = 1.3641, lr_0 = 7.0766e-04
Loss = 1.7888e-03, PNorm = 61.9423, GNorm = 1.2880, lr_0 = 7.0453e-04
Loss = 1.9153e-03, PNorm = 61.9915, GNorm = 0.9174, lr_0 = 7.0142e-04
Loss = 1.6001e-03, PNorm = 62.0260, GNorm = 1.0247, lr_0 = 6.9831e-04
Validation rmse logD = 0.635864
Validation R2 logD = 0.728586
Epoch 17
Train function
Loss = 1.6064e-03, PNorm = 62.0694, GNorm = 1.6375, lr_0 = 6.9523e-04
Loss = 1.4139e-03, PNorm = 62.1100, GNorm = 0.8059, lr_0 = 6.9215e-04
Loss = 1.6676e-03, PNorm = 62.1409, GNorm = 1.6482, lr_0 = 6.8909e-04
Loss = 1.7077e-03, PNorm = 62.1800, GNorm = 1.7721, lr_0 = 6.8604e-04
Loss = 1.8214e-03, PNorm = 62.2362, GNorm = 1.5379, lr_0 = 6.8301e-04
Validation rmse logD = 0.620080
Validation R2 logD = 0.741893
Epoch 18
Train function
Loss = 1.2985e-03, PNorm = 62.2874, GNorm = 1.7407, lr_0 = 6.7968e-04
Loss = 1.5620e-03, PNorm = 62.3373, GNorm = 1.0753, lr_0 = 6.7668e-04
Loss = 1.3948e-03, PNorm = 62.3758, GNorm = 1.6742, lr_0 = 6.7368e-04
Loss = 1.3269e-03, PNorm = 62.4194, GNorm = 1.3864, lr_0 = 6.7070e-04
Loss = 1.6060e-03, PNorm = 62.4634, GNorm = 0.8952, lr_0 = 6.6774e-04
Validation rmse logD = 0.605089
Validation R2 logD = 0.754222
Epoch 19
Train function
Loss = 1.2453e-03, PNorm = 62.5028, GNorm = 0.6959, lr_0 = 6.6449e-04
Loss = 1.4801e-03, PNorm = 62.5353, GNorm = 0.6946, lr_0 = 6.6155e-04
Loss = 1.3535e-03, PNorm = 62.5838, GNorm = 0.8562, lr_0 = 6.5862e-04
Loss = 1.2229e-03, PNorm = 62.6176, GNorm = 1.3235, lr_0 = 6.5571e-04
Loss = 1.6471e-03, PNorm = 62.6568, GNorm = 2.3755, lr_0 = 6.5281e-04
Loss = 1.0892e-03, PNorm = 62.7001, GNorm = 0.5758, lr_0 = 6.4992e-04
Validation rmse logD = 0.595912
Validation R2 logD = 0.761620
Epoch 20
Train function
Loss = 1.0396e-03, PNorm = 62.7356, GNorm = 1.0510, lr_0 = 6.4676e-04
Loss = 1.2519e-03, PNorm = 62.7671, GNorm = 1.0401, lr_0 = 6.4390e-04
Loss = 1.0670e-03, PNorm = 62.8004, GNorm = 1.0896, lr_0 = 6.4105e-04
Loss = 1.0117e-03, PNorm = 62.8323, GNorm = 1.3651, lr_0 = 6.3822e-04
Loss = 1.0959e-03, PNorm = 62.8631, GNorm = 1.5365, lr_0 = 6.3539e-04
Validation rmse logD = 0.599409
Validation R2 logD = 0.758814
Epoch 21
Train function
Loss = 9.6295e-04, PNorm = 62.9065, GNorm = 0.8221, lr_0 = 6.3230e-04
Loss = 1.1245e-03, PNorm = 62.9437, GNorm = 1.2731, lr_0 = 6.2950e-04
Loss = 9.0739e-04, PNorm = 62.9683, GNorm = 0.9161, lr_0 = 6.2672e-04
Loss = 1.1611e-03, PNorm = 62.9916, GNorm = 0.7462, lr_0 = 6.2395e-04
Loss = 1.1097e-03, PNorm = 63.0359, GNorm = 0.5165, lr_0 = 6.2119e-04
Validation rmse logD = 0.615487
Validation R2 logD = 0.745702
Epoch 22
Train function
Loss = 9.5863e-04, PNorm = 63.0609, GNorm = 0.4833, lr_0 = 6.1817e-04
Loss = 1.3098e-03, PNorm = 63.0968, GNorm = 0.8235, lr_0 = 6.1543e-04
Loss = 1.4063e-03, PNorm = 63.1342, GNorm = 0.8848, lr_0 = 6.1271e-04
Loss = 1.1147e-03, PNorm = 63.1788, GNorm = 0.9525, lr_0 = 6.1000e-04
Loss = 1.0961e-03, PNorm = 63.2162, GNorm = 2.0629, lr_0 = 6.0730e-04
Loss = 9.0236e-04, PNorm = 63.2498, GNorm = 1.2684, lr_0 = 6.0461e-04
Validation rmse logD = 0.610744
Validation R2 logD = 0.749606
Epoch 23
Train function
Loss = 1.0065e-03, PNorm = 63.2736, GNorm = 0.9676, lr_0 = 6.0167e-04
Loss = 9.8754e-04, PNorm = 63.3077, GNorm = 0.6617, lr_0 = 5.9901e-04
Loss = 7.9089e-04, PNorm = 63.3382, GNorm = 1.1237, lr_0 = 5.9636e-04
Loss = 8.5352e-04, PNorm = 63.3610, GNorm = 1.2281, lr_0 = 5.9372e-04
Loss = 9.7984e-04, PNorm = 63.3884, GNorm = 0.4114, lr_0 = 5.9110e-04
Validation rmse logD = 0.596246
Validation R2 logD = 0.761353
Epoch 24
Train function
Loss = 7.4483e-04, PNorm = 63.4166, GNorm = 0.4410, lr_0 = 5.8822e-04
Loss = 6.8157e-04, PNorm = 63.4383, GNorm = 0.3112, lr_0 = 5.8562e-04
Loss = 6.2042e-04, PNorm = 63.4620, GNorm = 0.5040, lr_0 = 5.8303e-04
Loss = 8.8894e-04, PNorm = 63.4816, GNorm = 0.6214, lr_0 = 5.8045e-04
Loss = 9.1590e-04, PNorm = 63.4994, GNorm = 0.5760, lr_0 = 5.7788e-04
Validation rmse logD = 0.607588
Validation R2 logD = 0.752188
Epoch 25
Train function
Loss = 6.5992e-04, PNorm = 63.5264, GNorm = 0.7632, lr_0 = 5.7533e-04
Loss = 6.9872e-04, PNorm = 63.5520, GNorm = 0.4267, lr_0 = 5.7278e-04
Loss = 6.8561e-04, PNorm = 63.5717, GNorm = 0.5326, lr_0 = 5.7025e-04
Loss = 5.4053e-04, PNorm = 63.5973, GNorm = 0.6076, lr_0 = 5.6773e-04
Loss = 7.2593e-04, PNorm = 63.6130, GNorm = 0.6618, lr_0 = 5.6522e-04
Loss = 7.3905e-04, PNorm = 63.6364, GNorm = 1.0011, lr_0 = 5.6272e-04
Validation rmse logD = 0.595490
Validation R2 logD = 0.761958
Epoch 26
Train function
Loss = 5.1894e-04, PNorm = 63.6585, GNorm = 0.4747, lr_0 = 5.5998e-04
Loss = 6.5252e-04, PNorm = 63.6780, GNorm = 0.4545, lr_0 = 5.5750e-04
Loss = 6.8538e-04, PNorm = 63.7001, GNorm = 0.8374, lr_0 = 5.5503e-04
Loss = 7.4119e-04, PNorm = 63.7189, GNorm = 2.7161, lr_0 = 5.5258e-04
Loss = 9.6821e-04, PNorm = 63.7516, GNorm = 1.5015, lr_0 = 5.5014e-04
Validation rmse logD = 0.602202
Validation R2 logD = 0.756561
Epoch 27
Train function
Loss = 5.0333e-04, PNorm = 63.7820, GNorm = 0.3872, lr_0 = 5.4746e-04
Loss = 7.8550e-04, PNorm = 63.8004, GNorm = 0.6523, lr_0 = 5.4504e-04
Loss = 6.2010e-04, PNorm = 63.8219, GNorm = 0.4757, lr_0 = 5.4263e-04
Loss = 5.3159e-04, PNorm = 63.8456, GNorm = 0.7556, lr_0 = 5.4023e-04
Loss = 5.5196e-04, PNorm = 63.8633, GNorm = 1.2833, lr_0 = 5.3784e-04
Validation rmse logD = 0.596599
Validation R2 logD = 0.761071
Epoch 28
Train function
Loss = 5.6683e-04, PNorm = 63.8832, GNorm = 1.0011, lr_0 = 5.3522e-04
Loss = 5.4816e-04, PNorm = 63.9003, GNorm = 1.0752, lr_0 = 5.3285e-04
Loss = 7.4317e-04, PNorm = 63.9150, GNorm = 0.5533, lr_0 = 5.3050e-04
Loss = 5.5298e-04, PNorm = 63.9360, GNorm = 0.6566, lr_0 = 5.2815e-04
Loss = 5.9496e-04, PNorm = 63.9575, GNorm = 0.5621, lr_0 = 5.2581e-04
Loss = 6.9421e-04, PNorm = 63.9792, GNorm = 1.2066, lr_0 = 5.2349e-04
Loss = 2.9714e-03, PNorm = 63.9807, GNorm = 1.4473, lr_0 = 5.2326e-04
Validation rmse logD = 0.603456
Validation R2 logD = 0.755547
Epoch 29
Train function
Loss = 5.3406e-04, PNorm = 64.0004, GNorm = 0.2868, lr_0 = 5.2094e-04
Loss = 6.0932e-04, PNorm = 64.0256, GNorm = 0.8916, lr_0 = 5.1864e-04
Loss = 5.1306e-04, PNorm = 64.0469, GNorm = 1.4604, lr_0 = 5.1634e-04
Loss = 7.7803e-04, PNorm = 64.0670, GNorm = 1.7205, lr_0 = 5.1406e-04
Loss = 5.6888e-04, PNorm = 64.0903, GNorm = 0.8912, lr_0 = 5.1178e-04
Validation rmse logD = 0.602781
Validation R2 logD = 0.756093
Epoch 30
Train function
Loss = 5.4668e-04, PNorm = 64.1091, GNorm = 0.5110, lr_0 = 5.0930e-04
Loss = 5.8455e-04, PNorm = 64.1306, GNorm = 1.6255, lr_0 = 5.0704e-04
Loss = 5.2056e-04, PNorm = 64.1466, GNorm = 1.1161, lr_0 = 5.0480e-04
Loss = 4.5447e-04, PNorm = 64.1632, GNorm = 1.1268, lr_0 = 5.0257e-04
Loss = 4.6478e-04, PNorm = 64.1786, GNorm = 0.9683, lr_0 = 5.0034e-04
Validation rmse logD = 0.601913
Validation R2 logD = 0.756795
Epoch 31
Train function
Loss = 4.3745e-04, PNorm = 64.2043, GNorm = 0.6205, lr_0 = 4.9791e-04
Loss = 3.6891e-04, PNorm = 64.2188, GNorm = 0.8126, lr_0 = 4.9571e-04
Loss = 4.7340e-04, PNorm = 64.2322, GNorm = 0.5280, lr_0 = 4.9351e-04
Loss = 4.0981e-04, PNorm = 64.2456, GNorm = 0.5210, lr_0 = 4.9133e-04
Loss = 4.8057e-04, PNorm = 64.2599, GNorm = 0.3136, lr_0 = 4.8916e-04
Validation rmse logD = 0.598413
Validation R2 logD = 0.759615
Epoch 32
Train function
Loss = 7.1400e-04, PNorm = 64.2809, GNorm = 1.1124, lr_0 = 4.8678e-04
Loss = 4.2366e-04, PNorm = 64.2993, GNorm = 1.0496, lr_0 = 4.8463e-04
Loss = 3.3619e-04, PNorm = 64.3119, GNorm = 0.5934, lr_0 = 4.8248e-04
Loss = 4.1745e-04, PNorm = 64.3252, GNorm = 0.6102, lr_0 = 4.8035e-04
Loss = 3.0712e-04, PNorm = 64.3387, GNorm = 0.2427, lr_0 = 4.7822e-04
Loss = 3.7132e-04, PNorm = 64.3507, GNorm = 0.4481, lr_0 = 4.7611e-04
Validation rmse logD = 0.608034
Validation R2 logD = 0.751823
Epoch 33
Train function
Loss = 4.0181e-04, PNorm = 64.3675, GNorm = 0.2770, lr_0 = 4.7379e-04
Loss = 4.0703e-04, PNorm = 64.3835, GNorm = 0.3676, lr_0 = 4.7170e-04
Loss = 4.2631e-04, PNorm = 64.3990, GNorm = 1.3684, lr_0 = 4.6961e-04
Loss = 4.0678e-04, PNorm = 64.4178, GNorm = 0.7090, lr_0 = 4.6753e-04
Loss = 3.8287e-04, PNorm = 64.4289, GNorm = 0.8254, lr_0 = 4.6546e-04
Validation rmse logD = 0.597660
Validation R2 logD = 0.760220
Epoch 34
Train function
Loss = 3.1215e-04, PNorm = 64.4401, GNorm = 0.3134, lr_0 = 4.6341e-04
Loss = 2.8155e-04, PNorm = 64.4527, GNorm = 0.3273, lr_0 = 4.6136e-04
Loss = 2.8039e-04, PNorm = 64.4652, GNorm = 0.3713, lr_0 = 4.5931e-04
Loss = 2.5761e-04, PNorm = 64.4736, GNorm = 0.6652, lr_0 = 4.5728e-04
Loss = 3.1208e-04, PNorm = 64.4877, GNorm = 0.4879, lr_0 = 4.5526e-04
Validation rmse logD = 0.594566
Validation R2 logD = 0.762696
Epoch 35
Train function
Loss = 1.6020e-04, PNorm = 64.5059, GNorm = 0.6256, lr_0 = 4.5305e-04
Loss = 3.0351e-04, PNorm = 64.5218, GNorm = 0.5308, lr_0 = 4.5104e-04
Loss = 2.9919e-04, PNorm = 64.5305, GNorm = 0.3492, lr_0 = 4.4905e-04
Loss = 2.7583e-04, PNorm = 64.5409, GNorm = 0.4631, lr_0 = 4.4706e-04
Loss = 2.7323e-04, PNorm = 64.5527, GNorm = 0.3058, lr_0 = 4.4508e-04
Loss = 3.3126e-04, PNorm = 64.5659, GNorm = 0.4170, lr_0 = 4.4311e-04
Validation rmse logD = 0.595891
Validation R2 logD = 0.761637
Epoch 36
Train function
Loss = 3.0882e-04, PNorm = 64.5753, GNorm = 0.8142, lr_0 = 4.4096e-04
Loss = 2.4588e-04, PNorm = 64.5920, GNorm = 0.8672, lr_0 = 4.3901e-04
Loss = 2.6753e-04, PNorm = 64.6062, GNorm = 0.4568, lr_0 = 4.3707e-04
Loss = 2.9396e-04, PNorm = 64.6186, GNorm = 0.4282, lr_0 = 4.3513e-04
Loss = 2.6386e-04, PNorm = 64.6296, GNorm = 0.9191, lr_0 = 4.3321e-04
Validation rmse logD = 0.601565
Validation R2 logD = 0.757076
Epoch 37
Train function
Loss = 3.8845e-04, PNorm = 64.6434, GNorm = 1.4759, lr_0 = 4.3110e-04
Loss = 3.1364e-04, PNorm = 64.6606, GNorm = 0.3530, lr_0 = 4.2919e-04
Loss = 3.2264e-04, PNorm = 64.6715, GNorm = 0.3261, lr_0 = 4.2729e-04
Loss = 3.0133e-04, PNorm = 64.6872, GNorm = 0.2980, lr_0 = 4.2540e-04
Loss = 2.7526e-04, PNorm = 64.6992, GNorm = 0.4824, lr_0 = 4.2352e-04
Validation rmse logD = 0.595738
Validation R2 logD = 0.761760
Epoch 38
Train function
Loss = 3.0755e-04, PNorm = 64.7079, GNorm = 0.7195, lr_0 = 4.2146e-04
Loss = 2.1994e-04, PNorm = 64.7213, GNorm = 0.3680, lr_0 = 4.1960e-04
Loss = 2.3883e-04, PNorm = 64.7307, GNorm = 0.1679, lr_0 = 4.1774e-04
Loss = 2.6917e-04, PNorm = 64.7413, GNorm = 0.6826, lr_0 = 4.1589e-04
Loss = 2.4198e-04, PNorm = 64.7536, GNorm = 1.3085, lr_0 = 4.1406e-04
Loss = 2.7990e-04, PNorm = 64.7649, GNorm = 0.4924, lr_0 = 4.1222e-04
Validation rmse logD = 0.602995
Validation R2 logD = 0.755920
Epoch 39
Train function
Loss = 2.5582e-04, PNorm = 64.7764, GNorm = 0.3507, lr_0 = 4.1022e-04
Loss = 2.0734e-04, PNorm = 64.7840, GNorm = 0.2381, lr_0 = 4.0840e-04
Loss = 2.1695e-04, PNorm = 64.7952, GNorm = 0.2417, lr_0 = 4.0660e-04
Loss = 2.0326e-04, PNorm = 64.8073, GNorm = 0.4408, lr_0 = 4.0480e-04
Loss = 2.1886e-04, PNorm = 64.8140, GNorm = 0.9717, lr_0 = 4.0301e-04
Validation rmse logD = 0.607230
Validation R2 logD = 0.752479
Epoch 40
Train function
Loss = 2.8031e-04, PNorm = 64.8241, GNorm = 0.4089, lr_0 = 4.0105e-04
Loss = 1.6986e-04, PNorm = 64.8364, GNorm = 0.3351, lr_0 = 3.9927e-04
Loss = 2.2626e-04, PNorm = 64.8474, GNorm = 0.5254, lr_0 = 3.9751e-04
Loss = 2.4547e-04, PNorm = 64.8559, GNorm = 0.3606, lr_0 = 3.9575e-04
Loss = 2.0006e-04, PNorm = 64.8655, GNorm = 0.3440, lr_0 = 3.9400e-04
Validation rmse logD = 0.594958
Validation R2 logD = 0.762383
Epoch 41
Train function
Loss = 2.1171e-04, PNorm = 64.8761, GNorm = 0.5576, lr_0 = 3.9208e-04
Loss = 1.8584e-04, PNorm = 64.8849, GNorm = 0.7687, lr_0 = 3.9035e-04
Loss = 1.9032e-04, PNorm = 64.8956, GNorm = 0.8305, lr_0 = 3.8862e-04
Loss = 1.6998e-04, PNorm = 64.9042, GNorm = 0.2885, lr_0 = 3.8690e-04
Loss = 1.6633e-04, PNorm = 64.9096, GNorm = 0.3897, lr_0 = 3.8519e-04
Loss = 1.7441e-04, PNorm = 64.9194, GNorm = 0.6092, lr_0 = 3.8349e-04
Validation rmse logD = 0.605241
Validation R2 logD = 0.754099
Epoch 42
Train function
Loss = 2.0190e-04, PNorm = 64.9291, GNorm = 0.3150, lr_0 = 3.8179e-04
Loss = 1.8478e-04, PNorm = 64.9380, GNorm = 0.5872, lr_0 = 3.8010e-04
Loss = 1.9991e-04, PNorm = 64.9467, GNorm = 0.3409, lr_0 = 3.7842e-04
Loss = 2.0981e-04, PNorm = 64.9564, GNorm = 0.2916, lr_0 = 3.7675e-04
Loss = 1.4620e-04, PNorm = 64.9609, GNorm = 0.2431, lr_0 = 3.7508e-04
Validation rmse logD = 0.597638
Validation R2 logD = 0.760238
Epoch 43
Train function
Loss = 1.6756e-04, PNorm = 64.9708, GNorm = 0.5534, lr_0 = 3.7326e-04
Loss = 1.5898e-04, PNorm = 64.9780, GNorm = 0.2976, lr_0 = 3.7160e-04
Loss = 1.5931e-04, PNorm = 64.9887, GNorm = 0.1967, lr_0 = 3.6996e-04
Loss = 1.6945e-04, PNorm = 64.9968, GNorm = 0.2371, lr_0 = 3.6832e-04
Loss = 1.4417e-04, PNorm = 65.0033, GNorm = 0.1990, lr_0 = 3.6669e-04
Validation rmse logD = 0.600300
Validation R2 logD = 0.758096
Epoch 44
Train function
Loss = 1.1098e-04, PNorm = 65.0134, GNorm = 0.4014, lr_0 = 3.6491e-04
Loss = 1.3787e-04, PNorm = 65.0217, GNorm = 0.5519, lr_0 = 3.6330e-04
Loss = 1.5264e-04, PNorm = 65.0277, GNorm = 0.1857, lr_0 = 3.6169e-04
Loss = 1.4160e-04, PNorm = 65.0370, GNorm = 0.2388, lr_0 = 3.6009e-04
Loss = 1.4895e-04, PNorm = 65.0432, GNorm = 0.2848, lr_0 = 3.5850e-04
Loss = 1.9855e-04, PNorm = 65.0519, GNorm = 0.5181, lr_0 = 3.5691e-04
Loss = 6.6753e-04, PNorm = 65.0525, GNorm = 0.4719, lr_0 = 3.5675e-04
Validation rmse logD = 0.599538
Validation R2 logD = 0.758711
Epoch 45
Train function
Loss = 1.2405e-04, PNorm = 65.0588, GNorm = 0.4935, lr_0 = 3.5518e-04
Loss = 1.6097e-04, PNorm = 65.0674, GNorm = 0.5841, lr_0 = 3.5360e-04
Loss = 1.7490e-04, PNorm = 65.0787, GNorm = 0.2721, lr_0 = 3.5204e-04
Loss = 1.2948e-04, PNorm = 65.0851, GNorm = 0.2285, lr_0 = 3.5048e-04
Loss = 1.0507e-04, PNorm = 65.0907, GNorm = 0.2094, lr_0 = 3.4893e-04
Validation rmse logD = 0.601502
Validation R2 logD = 0.757127
Epoch 46
Train function
Loss = 1.8975e-04, PNorm = 65.0997, GNorm = 0.1950, lr_0 = 3.4724e-04
Loss = 1.6680e-04, PNorm = 65.1079, GNorm = 0.3810, lr_0 = 3.4570e-04
Loss = 1.4344e-04, PNorm = 65.1161, GNorm = 0.3704, lr_0 = 3.4417e-04
Loss = 1.1960e-04, PNorm = 65.1234, GNorm = 0.1479, lr_0 = 3.4265e-04
Loss = 1.2940e-04, PNorm = 65.1300, GNorm = 0.7088, lr_0 = 3.4113e-04
Validation rmse logD = 0.593560
Validation R2 logD = 0.763499
Epoch 47
Train function
Loss = 1.1734e-04, PNorm = 65.1375, GNorm = 0.3780, lr_0 = 3.3947e-04
Loss = 1.2491e-04, PNorm = 65.1413, GNorm = 0.1964, lr_0 = 3.3797e-04
Loss = 1.4967e-04, PNorm = 65.1449, GNorm = 0.6470, lr_0 = 3.3648e-04
Loss = 1.0630e-04, PNorm = 65.1536, GNorm = 0.3052, lr_0 = 3.3499e-04
Loss = 1.4714e-04, PNorm = 65.1611, GNorm = 0.2172, lr_0 = 3.3351e-04
Validation rmse logD = 0.595075
Validation R2 logD = 0.762290
Epoch 48
Train function
Loss = 8.5499e-05, PNorm = 65.1687, GNorm = 0.4112, lr_0 = 3.3188e-04
Loss = 1.3019e-04, PNorm = 65.1760, GNorm = 0.7705, lr_0 = 3.3042e-04
Loss = 1.1694e-04, PNorm = 65.1831, GNorm = 0.1756, lr_0 = 3.2895e-04
Loss = 9.4279e-05, PNorm = 65.1876, GNorm = 0.1902, lr_0 = 3.2750e-04
Loss = 1.1008e-04, PNorm = 65.1934, GNorm = 0.2142, lr_0 = 3.2605e-04
Loss = 1.1001e-04, PNorm = 65.1983, GNorm = 0.2079, lr_0 = 3.2461e-04
Validation rmse logD = 0.593920
Validation R2 logD = 0.763212
Epoch 49
Train function
Loss = 1.0531e-04, PNorm = 65.2067, GNorm = 0.2366, lr_0 = 3.2303e-04
Loss = 1.3150e-04, PNorm = 65.2096, GNorm = 0.2826, lr_0 = 3.2160e-04
Loss = 1.0571e-04, PNorm = 65.2155, GNorm = 0.3672, lr_0 = 3.2018e-04
Loss = 8.9886e-05, PNorm = 65.2218, GNorm = 0.3495, lr_0 = 3.1876e-04
Loss = 1.1100e-04, PNorm = 65.2261, GNorm = 0.2174, lr_0 = 3.1735e-04
Validation rmse logD = 0.596593
Validation R2 logD = 0.761075
Epoch 50
Train function
Loss = 7.3755e-05, PNorm = 65.2326, GNorm = 0.1531, lr_0 = 3.1595e-04
Loss = 9.2363e-05, PNorm = 65.2381, GNorm = 0.2150, lr_0 = 3.1455e-04
Loss = 8.8664e-05, PNorm = 65.2440, GNorm = 0.4266, lr_0 = 3.1316e-04
Loss = 1.0407e-04, PNorm = 65.2497, GNorm = 0.2506, lr_0 = 3.1177e-04
Loss = 9.2342e-05, PNorm = 65.2548, GNorm = 0.2834, lr_0 = 3.1039e-04
Validation rmse logD = 0.596988
Validation R2 logD = 0.760759
Epoch 51
Train function
Loss = 3.9241e-05, PNorm = 65.2638, GNorm = 0.1485, lr_0 = 3.0888e-04
Loss = 9.6722e-05, PNorm = 65.2713, GNorm = 0.1999, lr_0 = 3.0752e-04
Loss = 7.9746e-05, PNorm = 65.2770, GNorm = 0.1649, lr_0 = 3.0616e-04
Loss = 7.8132e-05, PNorm = 65.2818, GNorm = 0.1487, lr_0 = 3.0480e-04
Loss = 7.7907e-05, PNorm = 65.2867, GNorm = 0.5462, lr_0 = 3.0346e-04
Loss = 1.0553e-04, PNorm = 65.2896, GNorm = 0.7273, lr_0 = 3.0211e-04
Validation rmse logD = 0.604650
Validation R2 logD = 0.754578
Epoch 52
Train function
Loss = 9.0073e-05, PNorm = 65.2966, GNorm = 0.1822, lr_0 = 3.0064e-04
Loss = 7.7837e-05, PNorm = 65.3022, GNorm = 0.2644, lr_0 = 2.9931e-04
Loss = 8.8555e-05, PNorm = 65.3066, GNorm = 0.2326, lr_0 = 2.9799e-04
Loss = 8.2583e-05, PNorm = 65.3115, GNorm = 0.1801, lr_0 = 2.9667e-04
Loss = 7.6794e-05, PNorm = 65.3166, GNorm = 0.6773, lr_0 = 2.9536e-04
Validation rmse logD = 0.598120
Validation R2 logD = 0.759851
Epoch 53
Train function
Loss = 1.0926e-04, PNorm = 65.3210, GNorm = 0.1698, lr_0 = 2.9392e-04
Loss = 9.5285e-05, PNorm = 65.3251, GNorm = 0.4777, lr_0 = 2.9262e-04
Loss = 6.9399e-05, PNorm = 65.3293, GNorm = 0.1800, lr_0 = 2.9133e-04
Loss = 6.3689e-05, PNorm = 65.3333, GNorm = 0.2832, lr_0 = 2.9004e-04
Loss = 7.2071e-05, PNorm = 65.3369, GNorm = 0.1404, lr_0 = 2.8876e-04
Validation rmse logD = 0.597525
Validation R2 logD = 0.760328
Epoch 54
Train function
Loss = 4.7934e-05, PNorm = 65.3398, GNorm = 0.1323, lr_0 = 2.8735e-04
Loss = 6.3380e-05, PNorm = 65.3429, GNorm = 0.2194, lr_0 = 2.8608e-04
Loss = 1.0101e-04, PNorm = 65.3489, GNorm = 0.1487, lr_0 = 2.8482e-04
Loss = 9.7071e-05, PNorm = 65.3548, GNorm = 0.3277, lr_0 = 2.8356e-04
Loss = 8.3393e-05, PNorm = 65.3582, GNorm = 0.3751, lr_0 = 2.8230e-04
Loss = 8.1359e-05, PNorm = 65.3666, GNorm = 0.1976, lr_0 = 2.8105e-04
Validation rmse logD = 0.598869
Validation R2 logD = 0.759249
Epoch 55
Train function
Loss = 5.2684e-05, PNorm = 65.3726, GNorm = 0.2048, lr_0 = 2.7969e-04
Loss = 7.2497e-05, PNorm = 65.3758, GNorm = 0.1204, lr_0 = 2.7845e-04
Loss = 7.6156e-05, PNorm = 65.3795, GNorm = 0.1986, lr_0 = 2.7722e-04
Loss = 9.8966e-05, PNorm = 65.3835, GNorm = 0.5282, lr_0 = 2.7599e-04
Loss = 7.2094e-05, PNorm = 65.3880, GNorm = 0.3543, lr_0 = 2.7477e-04
Validation rmse logD = 0.599158
Validation R2 logD = 0.759016
Epoch 56
Train function
Loss = 6.0587e-05, PNorm = 65.3932, GNorm = 0.1204, lr_0 = 2.7343e-04
Loss = 5.4476e-05, PNorm = 65.3978, GNorm = 0.2537, lr_0 = 2.7222e-04
Loss = 6.3129e-05, PNorm = 65.4007, GNorm = 0.1491, lr_0 = 2.7102e-04
Loss = 6.5635e-05, PNorm = 65.4041, GNorm = 0.4380, lr_0 = 2.6982e-04
Loss = 6.9935e-05, PNorm = 65.4081, GNorm = 0.1896, lr_0 = 2.6863e-04
Validation rmse logD = 0.600129
Validation R2 logD = 0.758234
Epoch 57
Train function
Loss = 9.8876e-05, PNorm = 65.4140, GNorm = 0.7463, lr_0 = 2.6732e-04
Loss = 6.9768e-05, PNorm = 65.4186, GNorm = 0.2617, lr_0 = 2.6614e-04
Loss = 6.7440e-05, PNorm = 65.4242, GNorm = 0.3686, lr_0 = 2.6496e-04
Loss = 8.1858e-05, PNorm = 65.4278, GNorm = 0.5540, lr_0 = 2.6379e-04
Loss = 6.4650e-05, PNorm = 65.4328, GNorm = 0.1772, lr_0 = 2.6262e-04
Loss = 6.5990e-05, PNorm = 65.4365, GNorm = 0.2489, lr_0 = 2.6146e-04
Loss = 8.8928e-05, PNorm = 65.4370, GNorm = 0.2041, lr_0 = 2.6134e-04
Validation rmse logD = 0.602842
Validation R2 logD = 0.756044
Epoch 58
Train function
Loss = 5.9219e-05, PNorm = 65.4423, GNorm = 0.1536, lr_0 = 2.6019e-04
Loss = 5.4747e-05, PNorm = 65.4449, GNorm = 0.1286, lr_0 = 2.5904e-04
Loss = 6.2915e-05, PNorm = 65.4483, GNorm = 0.2981, lr_0 = 2.5789e-04
Loss = 5.1829e-05, PNorm = 65.4507, GNorm = 0.1406, lr_0 = 2.5675e-04
Loss = 4.8921e-05, PNorm = 65.4540, GNorm = 0.1155, lr_0 = 2.5561e-04
Validation rmse logD = 0.598065
Validation R2 logD = 0.759895
Epoch 59
Train function
Loss = 5.6229e-05, PNorm = 65.4572, GNorm = 0.2187, lr_0 = 2.5448e-04
Loss = 4.6327e-05, PNorm = 65.4605, GNorm = 0.1972, lr_0 = 2.5336e-04
Loss = 4.2646e-05, PNorm = 65.4632, GNorm = 0.1006, lr_0 = 2.5224e-04
Loss = 4.5216e-05, PNorm = 65.4650, GNorm = 0.1363, lr_0 = 2.5112e-04
Loss = 5.4624e-05, PNorm = 65.4688, GNorm = 0.1131, lr_0 = 2.5001e-04
Validation rmse logD = 0.597696
Validation R2 logD = 0.760191
Epoch 60
Train function
Loss = 2.2966e-05, PNorm = 65.4719, GNorm = 0.1162, lr_0 = 2.4879e-04
Loss = 4.5873e-05, PNorm = 65.4759, GNorm = 0.3048, lr_0 = 2.4769e-04
Loss = 4.8413e-05, PNorm = 65.4780, GNorm = 0.1463, lr_0 = 2.4660e-04
Loss = 5.4050e-05, PNorm = 65.4816, GNorm = 0.1815, lr_0 = 2.4551e-04
Loss = 4.8443e-05, PNorm = 65.4849, GNorm = 0.3081, lr_0 = 2.4442e-04
Loss = 6.0042e-05, PNorm = 65.4910, GNorm = 0.1669, lr_0 = 2.4334e-04
Loss = 1.0058e-04, PNorm = 65.4913, GNorm = 0.1881, lr_0 = 2.4323e-04
Validation rmse logD = 0.602119
Validation R2 logD = 0.756629
Epoch 61
Train function
Loss = 4.1172e-05, PNorm = 65.4931, GNorm = 0.1075, lr_0 = 2.4216e-04
Loss = 3.5218e-05, PNorm = 65.4948, GNorm = 0.3046, lr_0 = 2.4109e-04
Loss = 4.8190e-05, PNorm = 65.4961, GNorm = 0.1191, lr_0 = 2.4002e-04
Loss = 3.2255e-05, PNorm = 65.4984, GNorm = 0.1998, lr_0 = 2.3896e-04
Loss = 4.4484e-05, PNorm = 65.5007, GNorm = 0.2784, lr_0 = 2.3790e-04
Validation rmse logD = 0.601312
Validation R2 logD = 0.757280
Epoch 62
Train function
Loss = 3.9680e-05, PNorm = 65.5021, GNorm = 0.1148, lr_0 = 2.3674e-04
Loss = 4.5839e-05, PNorm = 65.5063, GNorm = 0.1244, lr_0 = 2.3570e-04
Loss = 4.1489e-05, PNorm = 65.5088, GNorm = 0.3154, lr_0 = 2.3465e-04
Loss = 5.1149e-05, PNorm = 65.5143, GNorm = 0.2556, lr_0 = 2.3362e-04
Loss = 4.1156e-05, PNorm = 65.5191, GNorm = 0.1897, lr_0 = 2.3258e-04
Validation rmse logD = 0.600850
Validation R2 logD = 0.757653
Epoch 63
Train function
Loss = 3.0194e-05, PNorm = 65.5223, GNorm = 0.1775, lr_0 = 2.3145e-04
Loss = 5.1817e-05, PNorm = 65.5220, GNorm = 0.1072, lr_0 = 2.3043e-04
Loss = 4.5111e-05, PNorm = 65.5244, GNorm = 0.2835, lr_0 = 2.2941e-04
Loss = 5.1356e-05, PNorm = 65.5296, GNorm = 0.3152, lr_0 = 2.2839e-04
Loss = 5.3019e-05, PNorm = 65.5312, GNorm = 0.2628, lr_0 = 2.2738e-04
Validation rmse logD = 0.600001
Validation R2 logD = 0.758338
Epoch 64
Train function
Loss = 2.7285e-05, PNorm = 65.5365, GNorm = 0.1619, lr_0 = 2.2628e-04
Loss = 4.4200e-05, PNorm = 65.5397, GNorm = 0.3534, lr_0 = 2.2528e-04
Loss = 6.7110e-05, PNorm = 65.5430, GNorm = 0.3542, lr_0 = 2.2428e-04
Loss = 6.1369e-05, PNorm = 65.5467, GNorm = 0.3586, lr_0 = 2.2329e-04
Loss = 6.1881e-05, PNorm = 65.5498, GNorm = 0.2147, lr_0 = 2.2230e-04
Loss = 6.6853e-05, PNorm = 65.5538, GNorm = 0.1068, lr_0 = 2.2132e-04
Validation rmse logD = 0.600618
Validation R2 logD = 0.757841
Epoch 65
Train function
Loss = 5.7914e-05, PNorm = 65.5569, GNorm = 0.2869, lr_0 = 2.2024e-04
Loss = 5.3576e-05, PNorm = 65.5597, GNorm = 0.2389, lr_0 = 2.1927e-04
Loss = 4.8276e-05, PNorm = 65.5628, GNorm = 0.2392, lr_0 = 2.1830e-04
Loss = 4.6550e-05, PNorm = 65.5675, GNorm = 0.1823, lr_0 = 2.1733e-04
Loss = 4.2152e-05, PNorm = 65.5696, GNorm = 0.1514, lr_0 = 2.1637e-04
Validation rmse logD = 0.605404
Validation R2 logD = 0.753966
Epoch 66
Train function
Loss = 4.6051e-05, PNorm = 65.5739, GNorm = 0.1854, lr_0 = 2.1532e-04
Loss = 4.7096e-05, PNorm = 65.5749, GNorm = 0.4827, lr_0 = 2.1436e-04
Loss = 3.9209e-05, PNorm = 65.5777, GNorm = 0.1329, lr_0 = 2.1342e-04
Loss = 3.6276e-05, PNorm = 65.5799, GNorm = 0.2928, lr_0 = 2.1247e-04
Loss = 3.8959e-05, PNorm = 65.5819, GNorm = 0.2841, lr_0 = 2.1153e-04
Validation rmse logD = 0.600411
Validation R2 logD = 0.758008
Epoch 67
Train function
Loss = 3.0220e-05, PNorm = 65.5853, GNorm = 0.3259, lr_0 = 2.1060e-04
Loss = 3.9353e-05, PNorm = 65.5866, GNorm = 0.1317, lr_0 = 2.0966e-04
Loss = 3.1237e-05, PNorm = 65.5893, GNorm = 0.2172, lr_0 = 2.0874e-04
Loss = 4.1920e-05, PNorm = 65.5919, GNorm = 0.0997, lr_0 = 2.0781e-04
Loss = 2.9587e-05, PNorm = 65.5944, GNorm = 0.2264, lr_0 = 2.0689e-04
Loss = 2.9044e-05, PNorm = 65.5964, GNorm = 0.1186, lr_0 = 2.0598e-04
Validation rmse logD = 0.600668
Validation R2 logD = 0.757800
Epoch 68
Train function
Loss = 2.3418e-05, PNorm = 65.5987, GNorm = 0.1055, lr_0 = 2.0498e-04
Loss = 2.3166e-05, PNorm = 65.6009, GNorm = 0.1895, lr_0 = 2.0407e-04
Loss = 2.0385e-05, PNorm = 65.6032, GNorm = 0.1320, lr_0 = 2.0317e-04
Loss = 2.1969e-05, PNorm = 65.6051, GNorm = 0.1052, lr_0 = 2.0227e-04
Loss = 4.3965e-05, PNorm = 65.6070, GNorm = 0.2064, lr_0 = 2.0137e-04
Validation rmse logD = 0.600262
Validation R2 logD = 0.758128
Epoch 69
Train function
Loss = 3.2689e-05, PNorm = 65.6119, GNorm = 0.3000, lr_0 = 2.0039e-04
Loss = 3.8685e-05, PNorm = 65.6147, GNorm = 0.3094, lr_0 = 1.9951e-04
Loss = 4.1784e-05, PNorm = 65.6166, GNorm = 0.4769, lr_0 = 1.9863e-04
Loss = 3.3470e-05, PNorm = 65.6188, GNorm = 0.1477, lr_0 = 1.9775e-04
Loss = 2.5530e-05, PNorm = 65.6206, GNorm = 0.1085, lr_0 = 1.9687e-04
Validation rmse logD = 0.599740
Validation R2 logD = 0.758548
Epoch 70
Train function
Loss = 1.8066e-05, PNorm = 65.6228, GNorm = 0.0709, lr_0 = 1.9592e-04
Loss = 1.8334e-05, PNorm = 65.6248, GNorm = 0.0879, lr_0 = 1.9505e-04
Loss = 2.4738e-05, PNorm = 65.6281, GNorm = 0.0867, lr_0 = 1.9419e-04
Loss = 2.1593e-05, PNorm = 65.6285, GNorm = 0.2906, lr_0 = 1.9333e-04
Loss = 3.0774e-05, PNorm = 65.6304, GNorm = 0.1794, lr_0 = 1.9247e-04
Loss = 2.2312e-05, PNorm = 65.6320, GNorm = 0.0669, lr_0 = 1.9162e-04
Validation rmse logD = 0.601533
Validation R2 logD = 0.757102
Epoch 71
Train function
Loss = 2.1389e-05, PNorm = 65.6333, GNorm = 0.1186, lr_0 = 1.9069e-04
Loss = 1.9688e-05, PNorm = 65.6355, GNorm = 0.1715, lr_0 = 1.8984e-04
Loss = 2.6809e-05, PNorm = 65.6367, GNorm = 0.0736, lr_0 = 1.8900e-04
Loss = 1.9206e-05, PNorm = 65.6386, GNorm = 0.1742, lr_0 = 1.8817e-04
Loss = 2.3046e-05, PNorm = 65.6414, GNorm = 0.0565, lr_0 = 1.8734e-04
Validation rmse logD = 0.600447
Validation R2 logD = 0.757978
Epoch 72
Train function
Loss = 2.7695e-05, PNorm = 65.6428, GNorm = 0.0738, lr_0 = 1.8643e-04
Loss = 2.2997e-05, PNorm = 65.6444, GNorm = 0.1601, lr_0 = 1.8560e-04
Loss = 2.8144e-05, PNorm = 65.6459, GNorm = 0.0808, lr_0 = 1.8478e-04
Loss = 2.1463e-05, PNorm = 65.6478, GNorm = 0.0634, lr_0 = 1.8396e-04
Loss = 2.7690e-05, PNorm = 65.6497, GNorm = 0.1787, lr_0 = 1.8315e-04
Validation rmse logD = 0.600867
Validation R2 logD = 0.757640
Epoch 73
Train function
Loss = 3.0278e-05, PNorm = 65.6509, GNorm = 0.3071, lr_0 = 1.8226e-04
Loss = 2.2050e-05, PNorm = 65.6508, GNorm = 0.1239, lr_0 = 1.8145e-04
Loss = 2.2895e-05, PNorm = 65.6525, GNorm = 0.1225, lr_0 = 1.8065e-04
Loss = 2.6377e-05, PNorm = 65.6547, GNorm = 0.0735, lr_0 = 1.7985e-04
Loss = 1.9507e-05, PNorm = 65.6573, GNorm = 0.1094, lr_0 = 1.7905e-04
Loss = 2.2669e-05, PNorm = 65.6599, GNorm = 0.0900, lr_0 = 1.7826e-04
Loss = 8.3457e-05, PNorm = 65.6601, GNorm = 0.1521, lr_0 = 1.7818e-04
Validation rmse logD = 0.602341
Validation R2 logD = 0.756449
Epoch 74
Train function
Loss = 1.8384e-05, PNorm = 65.6612, GNorm = 0.0812, lr_0 = 1.7739e-04
Loss = 1.9964e-05, PNorm = 65.6620, GNorm = 0.0930, lr_0 = 1.7661e-04
Loss = 2.5038e-05, PNorm = 65.6636, GNorm = 0.0596, lr_0 = 1.7583e-04
Loss = 1.6293e-05, PNorm = 65.6660, GNorm = 0.0716, lr_0 = 1.7505e-04
Loss = 1.8585e-05, PNorm = 65.6677, GNorm = 0.0641, lr_0 = 1.7428e-04
Validation rmse logD = 0.600945
Validation R2 logD = 0.757577
Epoch 75
Train function
Loss = 1.8548e-05, PNorm = 65.6688, GNorm = 0.2336, lr_0 = 1.7351e-04
Loss = 1.9935e-05, PNorm = 65.6702, GNorm = 0.1522, lr_0 = 1.7274e-04
Loss = 1.7600e-05, PNorm = 65.6718, GNorm = 0.0972, lr_0 = 1.7197e-04
Loss = 1.5596e-05, PNorm = 65.6733, GNorm = 0.1605, lr_0 = 1.7121e-04
Loss = 1.3238e-05, PNorm = 65.6746, GNorm = 0.0703, lr_0 = 1.7046e-04
Validation rmse logD = 0.602100
Validation R2 logD = 0.756644
Epoch 76
Train function
Loss = 1.3855e-05, PNorm = 65.6767, GNorm = 0.1481, lr_0 = 1.6963e-04
Loss = 2.0617e-05, PNorm = 65.6786, GNorm = 0.2839, lr_0 = 1.6888e-04
Loss = 2.4125e-05, PNorm = 65.6794, GNorm = 0.1846, lr_0 = 1.6813e-04
Loss = 2.4585e-05, PNorm = 65.6808, GNorm = 0.0875, lr_0 = 1.6739e-04
Loss = 2.1522e-05, PNorm = 65.6836, GNorm = 0.1960, lr_0 = 1.6665e-04
Loss = 1.7065e-05, PNorm = 65.6855, GNorm = 0.2751, lr_0 = 1.6591e-04
Loss = 1.7455e-04, PNorm = 65.6854, GNorm = 0.3075, lr_0 = 1.6584e-04
Validation rmse logD = 0.604270
Validation R2 logD = 0.754886
Epoch 77
Train function
Loss = 2.5561e-05, PNorm = 65.6873, GNorm = 0.1205, lr_0 = 1.6510e-04
Loss = 2.3972e-05, PNorm = 65.6890, GNorm = 0.2049, lr_0 = 1.6437e-04
Loss = 1.8981e-05, PNorm = 65.6901, GNorm = 0.2236, lr_0 = 1.6364e-04
Loss = 2.8401e-05, PNorm = 65.6917, GNorm = 0.1216, lr_0 = 1.6292e-04
Loss = 2.1282e-05, PNorm = 65.6942, GNorm = 0.0693, lr_0 = 1.6220e-04
Validation rmse logD = 0.602439
Validation R2 logD = 0.756370
Epoch 78
Train function
Loss = 5.3156e-05, PNorm = 65.6947, GNorm = 0.3095, lr_0 = 1.6141e-04
Loss = 7.6340e-05, PNorm = 65.7003, GNorm = 0.4544, lr_0 = 1.6070e-04
Loss = 4.5839e-05, PNorm = 65.7046, GNorm = 0.2545, lr_0 = 1.5999e-04
Loss = 4.1947e-05, PNorm = 65.7080, GNorm = 0.1913, lr_0 = 1.5928e-04
Loss = 7.0452e-05, PNorm = 65.7131, GNorm = 0.2375, lr_0 = 1.5857e-04
Validation rmse logD = 0.597455
Validation R2 logD = 0.760384
Epoch 79
Train function
Loss = 5.9739e-05, PNorm = 65.7152, GNorm = 0.2118, lr_0 = 1.5780e-04
Loss = 6.8858e-05, PNorm = 65.7188, GNorm = 0.2204, lr_0 = 1.5710e-04
Loss = 5.1703e-05, PNorm = 65.7221, GNorm = 0.1755, lr_0 = 1.5641e-04
Loss = 4.3545e-05, PNorm = 65.7262, GNorm = 0.1835, lr_0 = 1.5572e-04
Loss = 3.8676e-05, PNorm = 65.7287, GNorm = 0.1748, lr_0 = 1.5503e-04
Validation rmse logD = 0.601645
Validation R2 logD = 0.757011
Epoch 80
Train function
Loss = 3.3837e-05, PNorm = 65.7321, GNorm = 0.2133, lr_0 = 1.5427e-04
Loss = 2.7547e-05, PNorm = 65.7330, GNorm = 0.1365, lr_0 = 1.5359e-04
Loss = 2.8447e-05, PNorm = 65.7337, GNorm = 0.1405, lr_0 = 1.5291e-04
Loss = 2.7201e-05, PNorm = 65.7360, GNorm = 0.2822, lr_0 = 1.5224e-04
Loss = 2.8666e-05, PNorm = 65.7376, GNorm = 0.2112, lr_0 = 1.5156e-04
Loss = 2.3115e-05, PNorm = 65.7399, GNorm = 0.1524, lr_0 = 1.5089e-04
Validation rmse logD = 0.599312
Validation R2 logD = 0.758892
Epoch 81
Train function
Loss = 3.2239e-05, PNorm = 65.7407, GNorm = 0.1869, lr_0 = 1.5016e-04
Loss = 2.8700e-05, PNorm = 65.7425, GNorm = 0.1782, lr_0 = 1.4949e-04
Loss = 2.6203e-05, PNorm = 65.7450, GNorm = 0.1046, lr_0 = 1.4883e-04
Loss = 2.1368e-05, PNorm = 65.7472, GNorm = 0.0672, lr_0 = 1.4817e-04
Loss = 3.9688e-05, PNorm = 65.7498, GNorm = 0.1661, lr_0 = 1.4752e-04
Validation rmse logD = 0.600548
Validation R2 logD = 0.757897
Epoch 82
Train function
Loss = 2.1689e-05, PNorm = 65.7515, GNorm = 0.0976, lr_0 = 1.4680e-04
Loss = 1.8884e-05, PNorm = 65.7536, GNorm = 0.0670, lr_0 = 1.4615e-04
Loss = 1.9573e-05, PNorm = 65.7551, GNorm = 0.0583, lr_0 = 1.4551e-04
Loss = 1.5098e-05, PNorm = 65.7563, GNorm = 0.0708, lr_0 = 1.4486e-04
Loss = 2.1303e-05, PNorm = 65.7573, GNorm = 0.1723, lr_0 = 1.4422e-04
Validation rmse logD = 0.600217
Validation R2 logD = 0.758164
Epoch 83
Train function
Loss = 1.7605e-05, PNorm = 65.7582, GNorm = 0.2271, lr_0 = 1.4352e-04
Loss = 1.8247e-05, PNorm = 65.7588, GNorm = 0.1006, lr_0 = 1.4288e-04
Loss = 1.6200e-05, PNorm = 65.7590, GNorm = 0.0580, lr_0 = 1.4225e-04
Loss = 2.0968e-05, PNorm = 65.7604, GNorm = 0.2741, lr_0 = 1.4162e-04
Loss = 2.6950e-05, PNorm = 65.7621, GNorm = 0.0926, lr_0 = 1.4100e-04
Loss = 2.5547e-05, PNorm = 65.7643, GNorm = 0.1824, lr_0 = 1.4037e-04
Validation rmse logD = 0.600445
Validation R2 logD = 0.757980
Epoch 84
Train function
Loss = 1.5255e-05, PNorm = 65.7653, GNorm = 0.2047, lr_0 = 1.3975e-04
Loss = 1.5778e-05, PNorm = 65.7660, GNorm = 0.2425, lr_0 = 1.3913e-04
Loss = 1.7570e-05, PNorm = 65.7674, GNorm = 0.1190, lr_0 = 1.3852e-04
Loss = 1.5412e-05, PNorm = 65.7688, GNorm = 0.2200, lr_0 = 1.3791e-04
Loss = 1.4871e-05, PNorm = 65.7705, GNorm = 0.0785, lr_0 = 1.3730e-04
Validation rmse logD = 0.601466
Validation R2 logD = 0.757156
Epoch 85
Train function
Loss = 1.1688e-05, PNorm = 65.7708, GNorm = 0.0938, lr_0 = 1.3663e-04
Loss = 1.2723e-05, PNorm = 65.7719, GNorm = 0.1523, lr_0 = 1.3602e-04
Loss = 1.1193e-05, PNorm = 65.7726, GNorm = 0.0870, lr_0 = 1.3542e-04
Loss = 1.3087e-05, PNorm = 65.7739, GNorm = 0.0639, lr_0 = 1.3482e-04
Loss = 1.3758e-05, PNorm = 65.7749, GNorm = 0.0833, lr_0 = 1.3423e-04
Validation rmse logD = 0.601734
Validation R2 logD = 0.756939
Epoch 86
Train function
Loss = 1.0160e-05, PNorm = 65.7768, GNorm = 0.0617, lr_0 = 1.3357e-04
Loss = 1.0783e-05, PNorm = 65.7777, GNorm = 0.0731, lr_0 = 1.3298e-04
Loss = 1.3729e-05, PNorm = 65.7784, GNorm = 0.1307, lr_0 = 1.3239e-04
Loss = 1.3189e-05, PNorm = 65.7800, GNorm = 0.1846, lr_0 = 1.3181e-04
Loss = 9.3959e-06, PNorm = 65.7812, GNorm = 0.1983, lr_0 = 1.3123e-04
Loss = 1.7131e-05, PNorm = 65.7824, GNorm = 0.0758, lr_0 = 1.3065e-04
Validation rmse logD = 0.602504
Validation R2 logD = 0.756317
Epoch 87
Train function
Loss = 1.1497e-05, PNorm = 65.7833, GNorm = 0.1479, lr_0 = 1.3001e-04
Loss = 1.1611e-05, PNorm = 65.7840, GNorm = 0.1146, lr_0 = 1.2944e-04
Loss = 1.1476e-05, PNorm = 65.7849, GNorm = 0.1016, lr_0 = 1.2886e-04
Loss = 1.2070e-05, PNorm = 65.7855, GNorm = 0.0926, lr_0 = 1.2829e-04
Loss = 1.2690e-05, PNorm = 65.7869, GNorm = 0.1008, lr_0 = 1.2773e-04
Validation rmse logD = 0.600790
Validation R2 logD = 0.757702
Epoch 88
Train function
Loss = 1.3577e-05, PNorm = 65.7877, GNorm = 0.2187, lr_0 = 1.2710e-04
Loss = 2.1668e-05, PNorm = 65.7878, GNorm = 0.3429, lr_0 = 1.2654e-04
Loss = 1.7376e-05, PNorm = 65.7893, GNorm = 0.1588, lr_0 = 1.2598e-04
Loss = 2.4057e-05, PNorm = 65.7901, GNorm = 0.3284, lr_0 = 1.2542e-04
Loss = 2.0086e-05, PNorm = 65.7925, GNorm = 0.1698, lr_0 = 1.2487e-04
Validation rmse logD = 0.600134
Validation R2 logD = 0.758230
Epoch 89
Train function
Loss = 1.2190e-05, PNorm = 65.7938, GNorm = 0.1930, lr_0 = 1.2426e-04
Loss = 1.8611e-05, PNorm = 65.7956, GNorm = 0.1353, lr_0 = 1.2371e-04
Loss = 1.7554e-05, PNorm = 65.7960, GNorm = 0.2418, lr_0 = 1.2317e-04
Loss = 1.9929e-05, PNorm = 65.7981, GNorm = 0.2379, lr_0 = 1.2262e-04
Loss = 1.2178e-05, PNorm = 65.7982, GNorm = 0.0795, lr_0 = 1.2208e-04
Loss = 1.3213e-05, PNorm = 65.7987, GNorm = 0.0982, lr_0 = 1.2154e-04
Loss = 7.6126e-05, PNorm = 65.7988, GNorm = 0.1322, lr_0 = 1.2148e-04
Validation rmse logD = 0.601012
Validation R2 logD = 0.757523
Epoch 90
Train function
Loss = 9.0418e-06, PNorm = 65.7994, GNorm = 0.0575, lr_0 = 1.2095e-04
Loss = 1.4066e-05, PNorm = 65.8002, GNorm = 0.1665, lr_0 = 1.2041e-04
Loss = 1.3035e-05, PNorm = 65.8015, GNorm = 0.0910, lr_0 = 1.1988e-04
Loss = 8.4014e-06, PNorm = 65.8031, GNorm = 0.1496, lr_0 = 1.1935e-04
Loss = 1.1138e-05, PNorm = 65.8042, GNorm = 0.0831, lr_0 = 1.1882e-04
Validation rmse logD = 0.600252
Validation R2 logD = 0.758136
Epoch 91
Train function
Loss = 1.0424e-05, PNorm = 65.8049, GNorm = 0.1117, lr_0 = 1.1824e-04
Loss = 1.2143e-05, PNorm = 65.8058, GNorm = 0.1543, lr_0 = 1.1772e-04
Loss = 1.1817e-05, PNorm = 65.8068, GNorm = 0.1558, lr_0 = 1.1720e-04
Loss = 1.2797e-05, PNorm = 65.8075, GNorm = 0.1978, lr_0 = 1.1668e-04
Loss = 1.2496e-05, PNorm = 65.8077, GNorm = 0.0880, lr_0 = 1.1616e-04
Validation rmse logD = 0.601461
Validation R2 logD = 0.757160
Epoch 92
Train function
Loss = 7.8850e-06, PNorm = 65.8084, GNorm = 0.0991, lr_0 = 1.1565e-04
Loss = 1.3211e-05, PNorm = 65.8099, GNorm = 0.2127, lr_0 = 1.1514e-04
Loss = 1.3365e-05, PNorm = 65.8107, GNorm = 0.0866, lr_0 = 1.1463e-04
Loss = 1.8911e-05, PNorm = 65.8120, GNorm = 0.1853, lr_0 = 1.1412e-04
Loss = 1.2612e-05, PNorm = 65.8127, GNorm = 0.0868, lr_0 = 1.1362e-04
Loss = 8.9394e-06, PNorm = 65.8132, GNorm = 0.0914, lr_0 = 1.1312e-04
Loss = 9.7804e-05, PNorm = 65.8133, GNorm = 0.1786, lr_0 = 1.1307e-04
Validation rmse logD = 0.601986
Validation R2 logD = 0.756736
Epoch 93
Train function
Loss = 1.2420e-05, PNorm = 65.8146, GNorm = 0.0631, lr_0 = 1.1257e-04
Loss = 8.8873e-06, PNorm = 65.8156, GNorm = 0.1106, lr_0 = 1.1207e-04
Loss = 1.0908e-05, PNorm = 65.8164, GNorm = 0.0400, lr_0 = 1.1157e-04
Loss = 6.4978e-06, PNorm = 65.8165, GNorm = 0.0533, lr_0 = 1.1108e-04
Loss = 9.1149e-06, PNorm = 65.8170, GNorm = 0.0661, lr_0 = 1.1059e-04
Validation rmse logD = 0.602177
Validation R2 logD = 0.756582
Epoch 94
Train function
Loss = 6.5560e-06, PNorm = 65.8184, GNorm = 0.0845, lr_0 = 1.1005e-04
Loss = 8.0803e-06, PNorm = 65.8190, GNorm = 0.0936, lr_0 = 1.0956e-04
Loss = 7.7518e-06, PNorm = 65.8195, GNorm = 0.1197, lr_0 = 1.0908e-04
Loss = 1.5553e-05, PNorm = 65.8199, GNorm = 0.1766, lr_0 = 1.0860e-04
Loss = 1.0936e-05, PNorm = 65.8211, GNorm = 0.0594, lr_0 = 1.0811e-04
Validation rmse logD = 0.601641
Validation R2 logD = 0.757015
Epoch 95
Train function
Loss = 8.1079e-06, PNorm = 65.8214, GNorm = 0.0676, lr_0 = 1.0759e-04
Loss = 6.5943e-06, PNorm = 65.8226, GNorm = 0.1092, lr_0 = 1.0711e-04
Loss = 1.0827e-05, PNorm = 65.8230, GNorm = 0.0783, lr_0 = 1.0664e-04
Loss = 9.0676e-06, PNorm = 65.8236, GNorm = 0.1239, lr_0 = 1.0617e-04
Loss = 8.5011e-06, PNorm = 65.8242, GNorm = 0.0634, lr_0 = 1.0570e-04
Validation rmse logD = 0.602057
Validation R2 logD = 0.756679
Epoch 96
Train function
Loss = 9.5150e-06, PNorm = 65.8252, GNorm = 0.0675, lr_0 = 1.0518e-04
Loss = 5.9513e-06, PNorm = 65.8259, GNorm = 0.1035, lr_0 = 1.0472e-04
Loss = 7.0288e-06, PNorm = 65.8271, GNorm = 0.0477, lr_0 = 1.0426e-04
Loss = 8.4949e-06, PNorm = 65.8278, GNorm = 0.1065, lr_0 = 1.0379e-04
Loss = 8.5210e-06, PNorm = 65.8290, GNorm = 0.0643, lr_0 = 1.0333e-04
Loss = 5.1773e-06, PNorm = 65.8288, GNorm = 0.0629, lr_0 = 1.0288e-04
Validation rmse logD = 0.601913
Validation R2 logD = 0.756795
Epoch 97
Train function
Loss = 6.8125e-06, PNorm = 65.8292, GNorm = 0.0679, lr_0 = 1.0238e-04
Loss = 5.7613e-06, PNorm = 65.8298, GNorm = 0.0599, lr_0 = 1.0192e-04
Loss = 4.3338e-06, PNorm = 65.8299, GNorm = 0.0850, lr_0 = 1.0147e-04
Loss = 7.0656e-06, PNorm = 65.8304, GNorm = 0.0394, lr_0 = 1.0102e-04
Loss = 6.1693e-06, PNorm = 65.8311, GNorm = 0.1284, lr_0 = 1.0058e-04
Validation rmse logD = 0.602313
Validation R2 logD = 0.756472
Epoch 98
Train function
Loss = 6.4225e-06, PNorm = 65.8319, GNorm = 0.0472, lr_0 = 1.0009e-04
Loss = 8.9787e-06, PNorm = 65.8327, GNorm = 0.1686, lr_0 = 1.0000e-04
Loss = 5.6997e-06, PNorm = 65.8332, GNorm = 0.0662, lr_0 = 1.0000e-04
Loss = 7.6751e-06, PNorm = 65.8338, GNorm = 0.0656, lr_0 = 1.0000e-04
Loss = 6.6228e-06, PNorm = 65.8347, GNorm = 0.0458, lr_0 = 1.0000e-04
Validation rmse logD = 0.602459
Validation R2 logD = 0.756353
Epoch 99
Train function
Loss = 4.0062e-06, PNorm = 65.8361, GNorm = 0.0959, lr_0 = 1.0000e-04
Loss = 6.4423e-06, PNorm = 65.8373, GNorm = 0.0712, lr_0 = 1.0000e-04
Loss = 8.1125e-06, PNorm = 65.8371, GNorm = 0.1503, lr_0 = 1.0000e-04
Loss = 5.6605e-06, PNorm = 65.8372, GNorm = 0.0902, lr_0 = 1.0000e-04
Loss = 9.1040e-06, PNorm = 65.8377, GNorm = 0.1683, lr_0 = 1.0000e-04
Loss = 8.9340e-06, PNorm = 65.8386, GNorm = 0.0867, lr_0 = 1.0000e-04
Validation rmse logD = 0.601586
Validation R2 logD = 0.757059
Model 0 best validation rmse = 0.593560 on epoch 46
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.611301
Model 0 test R2 logD = 0.741549
Ensemble test rmse  logD= 0.611301
Ensemble test R2  logD= 0.741549
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_313/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 1.9948e-02, PNorm = 55.5556, GNorm = 1.9187, lr_0 = 1.9340e-04
Loss = 1.6604e-02, PNorm = 55.5642, GNorm = 2.1142, lr_0 = 2.7830e-04
Loss = 1.6627e-02, PNorm = 55.5799, GNorm = 4.8115, lr_0 = 3.6321e-04
Loss = 1.7755e-02, PNorm = 55.5966, GNorm = 5.1372, lr_0 = 4.4811e-04
Loss = 1.5483e-02, PNorm = 55.6232, GNorm = 2.3478, lr_0 = 5.3302e-04
Validation rmse logD = 1.020584
Validation R2 logD = 0.274595
Epoch 1
Train function
Loss = 1.3226e-02, PNorm = 55.6712, GNorm = 1.3078, lr_0 = 6.2642e-04
Loss = 1.4648e-02, PNorm = 55.7419, GNorm = 3.0062, lr_0 = 7.1132e-04
Loss = 1.2263e-02, PNorm = 55.8359, GNorm = 2.2654, lr_0 = 7.9623e-04
Loss = 1.4316e-02, PNorm = 55.9091, GNorm = 2.9989, lr_0 = 8.8113e-04
Loss = 1.3175e-02, PNorm = 55.9965, GNorm = 5.9388, lr_0 = 9.6604e-04
Validation rmse logD = 0.882978
Validation R2 logD = 0.457021
Epoch 2
Train function
Loss = 8.6296e-03, PNorm = 56.1296, GNorm = 3.8909, lr_0 = 9.9690e-04
Loss = 1.1035e-02, PNorm = 56.2377, GNorm = 6.8207, lr_0 = 9.9249e-04
Loss = 1.0628e-02, PNorm = 56.3371, GNorm = 1.2046, lr_0 = 9.8810e-04
Loss = 8.7462e-03, PNorm = 56.4365, GNorm = 1.1756, lr_0 = 9.8373e-04
Loss = 9.4753e-03, PNorm = 56.5393, GNorm = 2.0882, lr_0 = 9.7938e-04
Validation rmse logD = 0.817335
Validation R2 logD = 0.534753
Epoch 3
Train function
Loss = 9.9458e-03, PNorm = 56.6343, GNorm = 2.5071, lr_0 = 9.7462e-04
Loss = 9.4261e-03, PNorm = 56.7229, GNorm = 4.3199, lr_0 = 9.7030e-04
Loss = 8.7112e-03, PNorm = 56.8231, GNorm = 2.5693, lr_0 = 9.6601e-04
Loss = 9.8668e-03, PNorm = 56.8852, GNorm = 2.4021, lr_0 = 9.6174e-04
Loss = 8.0830e-03, PNorm = 56.9786, GNorm = 1.4414, lr_0 = 9.5749e-04
Loss = 8.1743e-03, PNorm = 57.0727, GNorm = 1.4448, lr_0 = 9.5325e-04
Validation rmse logD = 0.803882
Validation R2 logD = 0.549943
Epoch 4
Train function
Loss = 7.4685e-03, PNorm = 57.1486, GNorm = 1.2615, lr_0 = 9.4861e-04
Loss = 8.0837e-03, PNorm = 57.2310, GNorm = 5.1340, lr_0 = 9.4442e-04
Loss = 8.0562e-03, PNorm = 57.2989, GNorm = 5.5367, lr_0 = 9.4024e-04
Loss = 7.8021e-03, PNorm = 57.3890, GNorm = 3.4140, lr_0 = 9.3608e-04
Loss = 7.0470e-03, PNorm = 57.4681, GNorm = 2.7680, lr_0 = 9.3194e-04
Validation rmse logD = 0.726081
Validation R2 logD = 0.632841
Epoch 5
Train function
Loss = 6.5565e-03, PNorm = 57.5528, GNorm = 1.3247, lr_0 = 9.2741e-04
Loss = 5.8400e-03, PNorm = 57.6344, GNorm = 1.4554, lr_0 = 9.2330e-04
Loss = 5.6570e-03, PNorm = 57.7259, GNorm = 5.1751, lr_0 = 9.1922e-04
Loss = 7.5133e-03, PNorm = 57.7928, GNorm = 1.6021, lr_0 = 9.1515e-04
Loss = 7.2108e-03, PNorm = 57.8771, GNorm = 2.5582, lr_0 = 9.1111e-04
Validation rmse logD = 0.797181
Validation R2 logD = 0.557415
Epoch 6
Train function
Loss = 8.2665e-03, PNorm = 57.9561, GNorm = 4.3806, lr_0 = 9.0667e-04
Loss = 6.0731e-03, PNorm = 58.0669, GNorm = 1.0405, lr_0 = 9.0266e-04
Loss = 5.2250e-03, PNorm = 58.1513, GNorm = 0.6704, lr_0 = 8.9867e-04
Loss = 5.3349e-03, PNorm = 58.2284, GNorm = 0.6631, lr_0 = 8.9469e-04
Loss = 6.4903e-03, PNorm = 58.3120, GNorm = 4.2685, lr_0 = 8.9074e-04
Loss = 5.7534e-03, PNorm = 58.3895, GNorm = 1.8915, lr_0 = 8.8680e-04
Validation rmse logD = 0.709132
Validation R2 logD = 0.649783
Epoch 7
Train function
Loss = 4.6570e-03, PNorm = 58.4803, GNorm = 2.2464, lr_0 = 8.8248e-04
Loss = 5.2842e-03, PNorm = 58.5731, GNorm = 1.0851, lr_0 = 8.7858e-04
Loss = 5.4118e-03, PNorm = 58.6629, GNorm = 1.1944, lr_0 = 8.7469e-04
Loss = 4.8429e-03, PNorm = 58.7408, GNorm = 1.6792, lr_0 = 8.7082e-04
Loss = 4.5906e-03, PNorm = 58.8184, GNorm = 1.7383, lr_0 = 8.6697e-04
Validation rmse logD = 0.726237
Validation R2 logD = 0.632684
Epoch 8
Train function
Loss = 4.5481e-03, PNorm = 58.9130, GNorm = 1.1641, lr_0 = 8.6276e-04
Loss = 4.7600e-03, PNorm = 59.0095, GNorm = 3.2630, lr_0 = 8.5894e-04
Loss = 4.4354e-03, PNorm = 59.0978, GNorm = 0.9617, lr_0 = 8.5514e-04
Loss = 4.5821e-03, PNorm = 59.1848, GNorm = 1.6633, lr_0 = 8.5136e-04
Loss = 4.4437e-03, PNorm = 59.2579, GNorm = 0.7874, lr_0 = 8.4759e-04
Validation rmse logD = 0.625520
Validation R2 logD = 0.727500
Epoch 9
Train function
Loss = 2.9066e-03, PNorm = 59.3358, GNorm = 0.7004, lr_0 = 8.4384e-04
Loss = 3.7357e-03, PNorm = 59.4113, GNorm = 1.0848, lr_0 = 8.4011e-04
Loss = 5.3518e-03, PNorm = 59.4905, GNorm = 4.4275, lr_0 = 8.3639e-04
Loss = 4.2746e-03, PNorm = 59.5733, GNorm = 2.6331, lr_0 = 8.3269e-04
Loss = 3.1774e-03, PNorm = 59.6630, GNorm = 0.8057, lr_0 = 8.2901e-04
Loss = 4.1230e-03, PNorm = 59.7272, GNorm = 1.4305, lr_0 = 8.2534e-04
Validation rmse logD = 0.653795
Validation R2 logD = 0.702309
Epoch 10
Train function
Loss = 3.8098e-03, PNorm = 59.8016, GNorm = 1.3111, lr_0 = 8.2133e-04
Loss = 3.3919e-03, PNorm = 59.8618, GNorm = 1.1510, lr_0 = 8.1770e-04
Loss = 3.1731e-03, PNorm = 59.9290, GNorm = 0.6995, lr_0 = 8.1408e-04
Loss = 3.8802e-03, PNorm = 60.0171, GNorm = 2.9278, lr_0 = 8.1048e-04
Loss = 3.3039e-03, PNorm = 60.0964, GNorm = 2.1241, lr_0 = 8.0689e-04
Validation rmse logD = 0.612355
Validation R2 logD = 0.738850
Epoch 11
Train function
Loss = 2.8347e-03, PNorm = 60.1672, GNorm = 3.1921, lr_0 = 8.0297e-04
Loss = 3.1907e-03, PNorm = 60.2442, GNorm = 1.7117, lr_0 = 7.9942e-04
Loss = 2.7231e-03, PNorm = 60.3075, GNorm = 1.6847, lr_0 = 7.9588e-04
Loss = 2.8950e-03, PNorm = 60.3708, GNorm = 1.1353, lr_0 = 7.9236e-04
Loss = 3.4583e-03, PNorm = 60.4299, GNorm = 3.4618, lr_0 = 7.8885e-04
Validation rmse logD = 0.685226
Validation R2 logD = 0.672998
Epoch 12
Train function
Loss = 4.1874e-03, PNorm = 60.5133, GNorm = 1.9405, lr_0 = 7.8502e-04
Loss = 3.2981e-03, PNorm = 60.5763, GNorm = 2.9764, lr_0 = 7.8154e-04
Loss = 2.8485e-03, PNorm = 60.6509, GNorm = 1.9746, lr_0 = 7.7809e-04
Loss = 2.3927e-03, PNorm = 60.7104, GNorm = 2.2260, lr_0 = 7.7465e-04
Loss = 2.4537e-03, PNorm = 60.7684, GNorm = 2.3577, lr_0 = 7.7122e-04
Loss = 2.8654e-03, PNorm = 60.8230, GNorm = 3.0378, lr_0 = 7.6781e-04
Loss = 2.1978e-02, PNorm = 60.8266, GNorm = 4.7729, lr_0 = 7.6747e-04
Validation rmse logD = 0.597102
Validation R2 logD = 0.751698
Epoch 13
Train function
Loss = 3.1129e-03, PNorm = 60.8966, GNorm = 3.4901, lr_0 = 7.6407e-04
Loss = 2.8681e-03, PNorm = 60.9737, GNorm = 1.8007, lr_0 = 7.6069e-04
Loss = 3.0760e-03, PNorm = 61.0392, GNorm = 3.1924, lr_0 = 7.5733e-04
Loss = 2.7565e-03, PNorm = 61.1045, GNorm = 0.7775, lr_0 = 7.5398e-04
Loss = 2.7354e-03, PNorm = 61.1705, GNorm = 1.5401, lr_0 = 7.5064e-04
Validation rmse logD = 0.595700
Validation R2 logD = 0.752863
Epoch 14
Train function
Loss = 2.2737e-03, PNorm = 61.2267, GNorm = 1.3020, lr_0 = 7.4699e-04
Loss = 2.4107e-03, PNorm = 61.2801, GNorm = 1.0943, lr_0 = 7.4369e-04
Loss = 2.1055e-03, PNorm = 61.3353, GNorm = 3.0566, lr_0 = 7.4040e-04
Loss = 2.1221e-03, PNorm = 61.3931, GNorm = 0.8990, lr_0 = 7.3712e-04
Loss = 2.3063e-03, PNorm = 61.4370, GNorm = 2.3363, lr_0 = 7.3386e-04
Validation rmse logD = 0.607389
Validation R2 logD = 0.743068
Epoch 15
Train function
Loss = 2.0451e-03, PNorm = 61.4896, GNorm = 2.0498, lr_0 = 7.3029e-04
Loss = 2.1947e-03, PNorm = 61.5389, GNorm = 2.6147, lr_0 = 7.2706e-04
Loss = 1.8353e-03, PNorm = 61.6014, GNorm = 2.5431, lr_0 = 7.2385e-04
Loss = 1.7551e-03, PNorm = 61.6420, GNorm = 0.5897, lr_0 = 7.2064e-04
Loss = 2.0004e-03, PNorm = 61.6924, GNorm = 0.7498, lr_0 = 7.1746e-04
Validation rmse logD = 0.571338
Validation R2 logD = 0.772664
Epoch 16
Train function
Loss = 1.5791e-03, PNorm = 61.7349, GNorm = 0.6474, lr_0 = 7.1397e-04
Loss = 1.5896e-03, PNorm = 61.7723, GNorm = 2.1090, lr_0 = 7.1081e-04
Loss = 1.7253e-03, PNorm = 61.8180, GNorm = 1.0897, lr_0 = 7.0766e-04
Loss = 1.6924e-03, PNorm = 61.8601, GNorm = 1.3118, lr_0 = 7.0453e-04
Loss = 1.5438e-03, PNorm = 61.9067, GNorm = 0.9071, lr_0 = 7.0142e-04
Loss = 1.7688e-03, PNorm = 61.9498, GNorm = 0.5319, lr_0 = 6.9831e-04
Validation rmse logD = 0.580715
Validation R2 logD = 0.765140
Epoch 17
Train function
Loss = 1.5683e-03, PNorm = 61.9961, GNorm = 0.8479, lr_0 = 6.9523e-04
Loss = 1.9872e-03, PNorm = 62.0477, GNorm = 1.0899, lr_0 = 6.9215e-04
Loss = 1.4448e-03, PNorm = 62.1121, GNorm = 2.6647, lr_0 = 6.8909e-04
Loss = 1.6634e-03, PNorm = 62.1515, GNorm = 0.8296, lr_0 = 6.8604e-04
Loss = 1.5539e-03, PNorm = 62.1897, GNorm = 0.5328, lr_0 = 6.8301e-04
Validation rmse logD = 0.589243
Validation R2 logD = 0.758191
Epoch 18
Train function
Loss = 1.4648e-03, PNorm = 62.2417, GNorm = 3.2513, lr_0 = 6.7968e-04
Loss = 1.5649e-03, PNorm = 62.2914, GNorm = 0.9542, lr_0 = 6.7668e-04
Loss = 1.3140e-03, PNorm = 62.3275, GNorm = 1.8088, lr_0 = 6.7368e-04
Loss = 1.5008e-03, PNorm = 62.3726, GNorm = 1.7302, lr_0 = 6.7070e-04
Loss = 1.2516e-03, PNorm = 62.4161, GNorm = 1.7911, lr_0 = 6.6774e-04
Validation rmse logD = 0.588233
Validation R2 logD = 0.759019
Epoch 19
Train function
Loss = 1.0517e-03, PNorm = 62.4531, GNorm = 0.8820, lr_0 = 6.6449e-04
Loss = 1.3335e-03, PNorm = 62.4958, GNorm = 2.2738, lr_0 = 6.6155e-04
Loss = 1.3245e-03, PNorm = 62.5403, GNorm = 2.0947, lr_0 = 6.5862e-04
Loss = 1.1264e-03, PNorm = 62.5785, GNorm = 1.3056, lr_0 = 6.5571e-04
Loss = 1.2411e-03, PNorm = 62.6121, GNorm = 0.7305, lr_0 = 6.5281e-04
Loss = 1.2275e-03, PNorm = 62.6463, GNorm = 0.7178, lr_0 = 6.4992e-04
Validation rmse logD = 0.614984
Validation R2 logD = 0.736603
Epoch 20
Train function
Loss = 1.6829e-03, PNorm = 62.6901, GNorm = 2.6159, lr_0 = 6.4676e-04
Loss = 1.3222e-03, PNorm = 62.7370, GNorm = 0.7677, lr_0 = 6.4390e-04
Loss = 1.4971e-03, PNorm = 62.7881, GNorm = 0.8195, lr_0 = 6.4105e-04
Loss = 1.0741e-03, PNorm = 62.8175, GNorm = 0.7744, lr_0 = 6.3822e-04
Loss = 1.2575e-03, PNorm = 62.8586, GNorm = 1.9650, lr_0 = 6.3539e-04
Validation rmse logD = 0.602400
Validation R2 logD = 0.747272
Epoch 21
Train function
Loss = 1.2078e-03, PNorm = 62.8890, GNorm = 2.1152, lr_0 = 6.3230e-04
Loss = 1.2557e-03, PNorm = 62.9327, GNorm = 1.8037, lr_0 = 6.2950e-04
Loss = 1.2514e-03, PNorm = 62.9612, GNorm = 2.0650, lr_0 = 6.2672e-04
Loss = 1.3459e-03, PNorm = 62.9964, GNorm = 1.1259, lr_0 = 6.2395e-04
Loss = 1.3199e-03, PNorm = 63.0232, GNorm = 0.4882, lr_0 = 6.2119e-04
Validation rmse logD = 0.570148
Validation R2 logD = 0.773609
Epoch 22
Train function
Loss = 1.5611e-03, PNorm = 63.0728, GNorm = 1.3855, lr_0 = 6.1817e-04
Loss = 9.5969e-04, PNorm = 63.1157, GNorm = 0.5069, lr_0 = 6.1543e-04
Loss = 1.1059e-03, PNorm = 63.1520, GNorm = 1.4957, lr_0 = 6.1271e-04
Loss = 1.0213e-03, PNorm = 63.1850, GNorm = 0.8277, lr_0 = 6.1000e-04
Loss = 9.8862e-04, PNorm = 63.2207, GNorm = 0.3366, lr_0 = 6.0730e-04
Loss = 8.3855e-04, PNorm = 63.2486, GNorm = 1.6562, lr_0 = 6.0461e-04
Validation rmse logD = 0.616110
Validation R2 logD = 0.735638
Epoch 23
Train function
Loss = 1.2254e-03, PNorm = 63.2777, GNorm = 1.0897, lr_0 = 6.0167e-04
Loss = 8.3463e-04, PNorm = 63.3099, GNorm = 0.5040, lr_0 = 5.9901e-04
Loss = 9.4088e-04, PNorm = 63.3368, GNorm = 0.6281, lr_0 = 5.9636e-04
Loss = 9.8474e-04, PNorm = 63.3697, GNorm = 0.4739, lr_0 = 5.9372e-04
Loss = 8.6904e-04, PNorm = 63.3949, GNorm = 0.7772, lr_0 = 5.9110e-04
Validation rmse logD = 0.554186
Validation R2 logD = 0.786108
Epoch 24
Train function
Loss = 8.2659e-04, PNorm = 63.4271, GNorm = 1.5357, lr_0 = 5.8822e-04
Loss = 9.7625e-04, PNorm = 63.4524, GNorm = 2.7630, lr_0 = 5.8562e-04
Loss = 1.1003e-03, PNorm = 63.4877, GNorm = 2.9656, lr_0 = 5.8303e-04
Loss = 1.0706e-03, PNorm = 63.5184, GNorm = 2.5106, lr_0 = 5.8045e-04
Loss = 9.5327e-04, PNorm = 63.5501, GNorm = 0.5238, lr_0 = 5.7788e-04
Validation rmse logD = 0.601069
Validation R2 logD = 0.748387
Epoch 25
Train function
Loss = 8.0938e-04, PNorm = 63.5830, GNorm = 1.3232, lr_0 = 5.7533e-04
Loss = 9.0655e-04, PNorm = 63.6114, GNorm = 0.7169, lr_0 = 5.7278e-04
Loss = 7.5775e-04, PNorm = 63.6486, GNorm = 0.6240, lr_0 = 5.7025e-04
Loss = 7.7015e-04, PNorm = 63.6788, GNorm = 1.3863, lr_0 = 5.6773e-04
Loss = 8.1986e-04, PNorm = 63.6983, GNorm = 0.7168, lr_0 = 5.6522e-04
Loss = 7.7255e-04, PNorm = 63.7211, GNorm = 0.4189, lr_0 = 5.6272e-04
Validation rmse logD = 0.564508
Validation R2 logD = 0.778066
Epoch 26
Train function
Loss = 5.6395e-04, PNorm = 63.7409, GNorm = 0.4309, lr_0 = 5.5998e-04
Loss = 5.8874e-04, PNorm = 63.7654, GNorm = 1.2546, lr_0 = 5.5750e-04
Loss = 6.0021e-04, PNorm = 63.7856, GNorm = 0.3747, lr_0 = 5.5503e-04
Loss = 6.5666e-04, PNorm = 63.8064, GNorm = 0.3249, lr_0 = 5.5258e-04
Loss = 6.4741e-04, PNorm = 63.8253, GNorm = 0.5597, lr_0 = 5.5014e-04
Validation rmse logD = 0.582435
Validation R2 logD = 0.763746
Epoch 27
Train function
Loss = 9.8707e-04, PNorm = 63.8560, GNorm = 0.5508, lr_0 = 5.4746e-04
Loss = 8.6481e-04, PNorm = 63.8836, GNorm = 1.3337, lr_0 = 5.4504e-04
Loss = 7.5711e-04, PNorm = 63.9121, GNorm = 0.6706, lr_0 = 5.4263e-04
Loss = 6.0287e-04, PNorm = 63.9351, GNorm = 0.7004, lr_0 = 5.4023e-04
Loss = 5.6250e-04, PNorm = 63.9514, GNorm = 0.6034, lr_0 = 5.3784e-04
Validation rmse logD = 0.559423
Validation R2 logD = 0.782046
Epoch 28
Train function
Loss = 6.9930e-04, PNorm = 63.9747, GNorm = 1.7157, lr_0 = 5.3522e-04
Loss = 7.2285e-04, PNorm = 63.9969, GNorm = 1.6296, lr_0 = 5.3285e-04
Loss = 6.5381e-04, PNorm = 64.0239, GNorm = 0.4570, lr_0 = 5.3050e-04
Loss = 6.0873e-04, PNorm = 64.0488, GNorm = 0.5730, lr_0 = 5.2815e-04
Loss = 6.8478e-04, PNorm = 64.0687, GNorm = 0.3426, lr_0 = 5.2581e-04
Loss = 5.2706e-04, PNorm = 64.0884, GNorm = 0.8667, lr_0 = 5.2349e-04
Loss = 1.3409e-03, PNorm = 64.0903, GNorm = 0.6944, lr_0 = 5.2326e-04
Validation rmse logD = 0.558568
Validation R2 logD = 0.782712
Epoch 29
Train function
Loss = 5.6839e-04, PNorm = 64.1120, GNorm = 0.3427, lr_0 = 5.2094e-04
Loss = 4.9700e-04, PNorm = 64.1288, GNorm = 1.2159, lr_0 = 5.1864e-04
Loss = 5.2665e-04, PNorm = 64.1469, GNorm = 1.2848, lr_0 = 5.1634e-04
Loss = 5.1297e-04, PNorm = 64.1667, GNorm = 1.7167, lr_0 = 5.1406e-04
Loss = 5.0293e-04, PNorm = 64.1808, GNorm = 0.3587, lr_0 = 5.1178e-04
Validation rmse logD = 0.561146
Validation R2 logD = 0.780702
Epoch 30
Train function
Loss = 3.8661e-04, PNorm = 64.2003, GNorm = 0.3344, lr_0 = 5.0930e-04
Loss = 4.5502e-04, PNorm = 64.2178, GNorm = 0.3297, lr_0 = 5.0704e-04
Loss = 4.6203e-04, PNorm = 64.2342, GNorm = 0.6869, lr_0 = 5.0480e-04
Loss = 4.4356e-04, PNorm = 64.2460, GNorm = 0.4507, lr_0 = 5.0257e-04
Loss = 5.7850e-04, PNorm = 64.2671, GNorm = 0.6925, lr_0 = 5.0034e-04
Validation rmse logD = 0.565479
Validation R2 logD = 0.777302
Epoch 31
Train function
Loss = 4.2037e-04, PNorm = 64.2856, GNorm = 0.9836, lr_0 = 4.9791e-04
Loss = 4.8855e-04, PNorm = 64.3020, GNorm = 0.3384, lr_0 = 4.9571e-04
Loss = 4.6527e-04, PNorm = 64.3197, GNorm = 0.6260, lr_0 = 4.9351e-04
Loss = 3.4710e-04, PNorm = 64.3368, GNorm = 0.3846, lr_0 = 4.9133e-04
Loss = 4.3628e-04, PNorm = 64.3525, GNorm = 1.0770, lr_0 = 4.8916e-04
Validation rmse logD = 0.560093
Validation R2 logD = 0.781524
Epoch 32
Train function
Loss = 2.7761e-04, PNorm = 64.3671, GNorm = 0.5383, lr_0 = 4.8678e-04
Loss = 4.3833e-04, PNorm = 64.3867, GNorm = 0.4494, lr_0 = 4.8463e-04
Loss = 3.9646e-04, PNorm = 64.4016, GNorm = 0.2461, lr_0 = 4.8248e-04
Loss = 4.4276e-04, PNorm = 64.4198, GNorm = 0.4106, lr_0 = 4.8035e-04
Loss = 3.5193e-04, PNorm = 64.4273, GNorm = 0.6461, lr_0 = 4.7822e-04
Loss = 5.4861e-04, PNorm = 64.4457, GNorm = 0.3536, lr_0 = 4.7611e-04
Validation rmse logD = 0.563182
Validation R2 logD = 0.779108
Epoch 33
Train function
Loss = 3.2612e-04, PNorm = 64.4645, GNorm = 0.5079, lr_0 = 4.7379e-04
Loss = 2.9975e-04, PNorm = 64.4822, GNorm = 0.4450, lr_0 = 4.7170e-04
Loss = 3.5982e-04, PNorm = 64.4982, GNorm = 0.2742, lr_0 = 4.6961e-04
Loss = 3.9753e-04, PNorm = 64.5088, GNorm = 0.3690, lr_0 = 4.6753e-04
Loss = 5.4635e-04, PNorm = 64.5276, GNorm = 0.3571, lr_0 = 4.6546e-04
Validation rmse logD = 0.568076
Validation R2 logD = 0.775252
Epoch 34
Train function
Loss = 3.8340e-04, PNorm = 64.5435, GNorm = 0.6738, lr_0 = 4.6341e-04
Loss = 4.1906e-04, PNorm = 64.5592, GNorm = 0.3356, lr_0 = 4.6136e-04
Loss = 3.1103e-04, PNorm = 64.5717, GNorm = 0.2400, lr_0 = 4.5931e-04
Loss = 3.3563e-04, PNorm = 64.5879, GNorm = 0.6673, lr_0 = 4.5728e-04
Loss = 3.6534e-04, PNorm = 64.6055, GNorm = 0.3691, lr_0 = 4.5526e-04
Validation rmse logD = 0.556305
Validation R2 logD = 0.784470
Epoch 35
Train function
Loss = 2.9732e-04, PNorm = 64.6198, GNorm = 0.8111, lr_0 = 4.5305e-04
Loss = 2.5270e-04, PNorm = 64.6308, GNorm = 0.6425, lr_0 = 4.5104e-04
Loss = 2.2507e-04, PNorm = 64.6403, GNorm = 0.2329, lr_0 = 4.4905e-04
Loss = 2.8939e-04, PNorm = 64.6530, GNorm = 0.2302, lr_0 = 4.4706e-04
Loss = 3.0416e-04, PNorm = 64.6644, GNorm = 0.7651, lr_0 = 4.4508e-04
Loss = 2.5992e-04, PNorm = 64.6779, GNorm = 0.8220, lr_0 = 4.4311e-04
Validation rmse logD = 0.555337
Validation R2 logD = 0.785218
Epoch 36
Train function
Loss = 2.1429e-04, PNorm = 64.6948, GNorm = 0.2409, lr_0 = 4.4096e-04
Loss = 2.6729e-04, PNorm = 64.7046, GNorm = 0.6281, lr_0 = 4.3901e-04
Loss = 3.7044e-04, PNorm = 64.7210, GNorm = 1.4271, lr_0 = 4.3707e-04
Loss = 2.5518e-04, PNorm = 64.7325, GNorm = 0.5759, lr_0 = 4.3513e-04
Loss = 2.5439e-04, PNorm = 64.7433, GNorm = 0.3752, lr_0 = 4.3321e-04
Validation rmse logD = 0.559324
Validation R2 logD = 0.782124
Epoch 37
Train function
Loss = 1.7102e-04, PNorm = 64.7560, GNorm = 0.4362, lr_0 = 4.3110e-04
Loss = 2.2110e-04, PNorm = 64.7653, GNorm = 0.2117, lr_0 = 4.2919e-04
Loss = 2.8057e-04, PNorm = 64.7789, GNorm = 0.8784, lr_0 = 4.2729e-04
Loss = 2.3812e-04, PNorm = 64.7923, GNorm = 0.4591, lr_0 = 4.2540e-04
Loss = 2.1204e-04, PNorm = 64.8000, GNorm = 0.2434, lr_0 = 4.2352e-04
Validation rmse logD = 0.559885
Validation R2 logD = 0.781687
Epoch 38
Train function
Loss = 2.0571e-04, PNorm = 64.8136, GNorm = 0.5427, lr_0 = 4.2146e-04
Loss = 2.5009e-04, PNorm = 64.8252, GNorm = 0.4588, lr_0 = 4.1960e-04
Loss = 2.0264e-04, PNorm = 64.8396, GNorm = 0.2381, lr_0 = 4.1774e-04
Loss = 2.1678e-04, PNorm = 64.8501, GNorm = 0.2393, lr_0 = 4.1589e-04
Loss = 1.7792e-04, PNorm = 64.8560, GNorm = 0.4623, lr_0 = 4.1406e-04
Loss = 2.5419e-04, PNorm = 64.8639, GNorm = 0.2893, lr_0 = 4.1222e-04
Validation rmse logD = 0.566873
Validation R2 logD = 0.776203
Epoch 39
Train function
Loss = 2.5904e-04, PNorm = 64.8783, GNorm = 0.3465, lr_0 = 4.1022e-04
Loss = 2.4225e-04, PNorm = 64.8884, GNorm = 0.7649, lr_0 = 4.0840e-04
Loss = 2.0402e-04, PNorm = 64.9002, GNorm = 0.7520, lr_0 = 4.0660e-04
Loss = 2.6016e-04, PNorm = 64.9101, GNorm = 0.3383, lr_0 = 4.0480e-04
Loss = 2.5740e-04, PNorm = 64.9247, GNorm = 0.5589, lr_0 = 4.0301e-04
Validation rmse logD = 0.556671
Validation R2 logD = 0.784186
Epoch 40
Train function
Loss = 1.5531e-04, PNorm = 64.9350, GNorm = 0.4840, lr_0 = 4.0105e-04
Loss = 2.0106e-04, PNorm = 64.9467, GNorm = 1.0561, lr_0 = 3.9927e-04
Loss = 1.9122e-04, PNorm = 64.9561, GNorm = 0.1563, lr_0 = 3.9751e-04
Loss = 3.1558e-04, PNorm = 64.9658, GNorm = 1.0088, lr_0 = 3.9575e-04
Loss = 1.6816e-04, PNorm = 64.9769, GNorm = 0.1558, lr_0 = 3.9400e-04
Validation rmse logD = 0.559593
Validation R2 logD = 0.781914
Epoch 41
Train function
Loss = 2.4131e-04, PNorm = 64.9882, GNorm = 0.4169, lr_0 = 3.9208e-04
Loss = 1.9833e-04, PNorm = 64.9996, GNorm = 0.4719, lr_0 = 3.9035e-04
Loss = 2.4221e-04, PNorm = 65.0116, GNorm = 0.2328, lr_0 = 3.8862e-04
Loss = 1.8990e-04, PNorm = 65.0234, GNorm = 0.2750, lr_0 = 3.8690e-04
Loss = 2.0002e-04, PNorm = 65.0363, GNorm = 0.2541, lr_0 = 3.8519e-04
Loss = 2.7181e-04, PNorm = 65.0453, GNorm = 0.6418, lr_0 = 3.8349e-04
Validation rmse logD = 0.561593
Validation R2 logD = 0.780352
Epoch 42
Train function
Loss = 1.5315e-04, PNorm = 65.0523, GNorm = 0.4745, lr_0 = 3.8179e-04
Loss = 1.7987e-04, PNorm = 65.0617, GNorm = 0.4417, lr_0 = 3.8010e-04
Loss = 1.6541e-04, PNorm = 65.0697, GNorm = 0.1707, lr_0 = 3.7842e-04
Loss = 1.8608e-04, PNorm = 65.0790, GNorm = 0.3601, lr_0 = 3.7675e-04
Loss = 1.7446e-04, PNorm = 65.0874, GNorm = 0.7971, lr_0 = 3.7508e-04
Validation rmse logD = 0.555854
Validation R2 logD = 0.784819
Epoch 43
Train function
Loss = 1.0573e-04, PNorm = 65.0970, GNorm = 0.3030, lr_0 = 3.7326e-04
Loss = 1.6380e-04, PNorm = 65.1038, GNorm = 0.3717, lr_0 = 3.7160e-04
Loss = 1.7942e-04, PNorm = 65.1105, GNorm = 0.3304, lr_0 = 3.6996e-04
Loss = 1.9365e-04, PNorm = 65.1180, GNorm = 0.7006, lr_0 = 3.6832e-04
Loss = 1.6655e-04, PNorm = 65.1294, GNorm = 0.6495, lr_0 = 3.6669e-04
Validation rmse logD = 0.559270
Validation R2 logD = 0.782166
Epoch 44
Train function
Loss = 1.7636e-04, PNorm = 65.1419, GNorm = 0.3207, lr_0 = 3.6491e-04
Loss = 1.2235e-04, PNorm = 65.1502, GNorm = 0.1998, lr_0 = 3.6330e-04
Loss = 1.4844e-04, PNorm = 65.1563, GNorm = 0.1434, lr_0 = 3.6169e-04
Loss = 1.7148e-04, PNorm = 65.1638, GNorm = 0.2046, lr_0 = 3.6009e-04
Loss = 1.4802e-04, PNorm = 65.1727, GNorm = 0.2967, lr_0 = 3.5850e-04
Loss = 1.2543e-04, PNorm = 65.1777, GNorm = 0.2681, lr_0 = 3.5691e-04
Loss = 1.2292e-03, PNorm = 65.1779, GNorm = 0.5998, lr_0 = 3.5675e-04
Validation rmse logD = 0.558274
Validation R2 logD = 0.782941
Epoch 45
Train function
Loss = 1.4055e-04, PNorm = 65.1835, GNorm = 0.4934, lr_0 = 3.5518e-04
Loss = 1.5465e-04, PNorm = 65.1924, GNorm = 0.3795, lr_0 = 3.5360e-04
Loss = 1.3773e-04, PNorm = 65.1987, GNorm = 0.2712, lr_0 = 3.5204e-04
Loss = 1.1891e-04, PNorm = 65.2042, GNorm = 0.2064, lr_0 = 3.5048e-04
Loss = 1.6472e-04, PNorm = 65.2107, GNorm = 0.3549, lr_0 = 3.4893e-04
Validation rmse logD = 0.567114
Validation R2 logD = 0.776012
Epoch 46
Train function
Loss = 1.1863e-04, PNorm = 65.2220, GNorm = 0.5490, lr_0 = 3.4724e-04
Loss = 1.3687e-04, PNorm = 65.2305, GNorm = 0.7088, lr_0 = 3.4570e-04
Loss = 1.0985e-04, PNorm = 65.2387, GNorm = 0.1227, lr_0 = 3.4417e-04
Loss = 1.2806e-04, PNorm = 65.2446, GNorm = 0.2186, lr_0 = 3.4265e-04
Loss = 1.1492e-04, PNorm = 65.2523, GNorm = 0.3270, lr_0 = 3.4113e-04
Validation rmse logD = 0.552227
Validation R2 logD = 0.787618
Epoch 47
Train function
Loss = 1.2214e-04, PNorm = 65.2611, GNorm = 0.4678, lr_0 = 3.3947e-04
Loss = 1.3079e-04, PNorm = 65.2693, GNorm = 0.3710, lr_0 = 3.3797e-04
Loss = 1.5373e-04, PNorm = 65.2729, GNorm = 0.3593, lr_0 = 3.3648e-04
Loss = 1.1542e-04, PNorm = 65.2786, GNorm = 0.4353, lr_0 = 3.3499e-04
Loss = 1.2157e-04, PNorm = 65.2838, GNorm = 0.5673, lr_0 = 3.3351e-04
Validation rmse logD = 0.573317
Validation R2 logD = 0.771086
Epoch 48
Train function
Loss = 2.3724e-04, PNorm = 65.2941, GNorm = 1.0945, lr_0 = 3.3188e-04
Loss = 1.5209e-04, PNorm = 65.2990, GNorm = 0.8501, lr_0 = 3.3042e-04
Loss = 1.2551e-04, PNorm = 65.3057, GNorm = 0.4306, lr_0 = 3.2895e-04
Loss = 1.2976e-04, PNorm = 65.3146, GNorm = 0.3033, lr_0 = 3.2750e-04
Loss = 1.3024e-04, PNorm = 65.3241, GNorm = 0.6491, lr_0 = 3.2605e-04
Loss = 1.6517e-04, PNorm = 65.3314, GNorm = 0.8734, lr_0 = 3.2461e-04
Validation rmse logD = 0.560260
Validation R2 logD = 0.781394
Epoch 49
Train function
Loss = 1.4144e-04, PNorm = 65.3420, GNorm = 0.6838, lr_0 = 3.2303e-04
Loss = 1.2801e-04, PNorm = 65.3489, GNorm = 0.1772, lr_0 = 3.2160e-04
Loss = 1.0922e-04, PNorm = 65.3562, GNorm = 0.2118, lr_0 = 3.2018e-04
Loss = 1.4999e-04, PNorm = 65.3633, GNorm = 0.3470, lr_0 = 3.1876e-04
Loss = 1.1883e-04, PNorm = 65.3692, GNorm = 0.3898, lr_0 = 3.1735e-04
Validation rmse logD = 0.562860
Validation R2 logD = 0.779360
Epoch 50
Train function
Loss = 1.6473e-04, PNorm = 65.3761, GNorm = 0.7328, lr_0 = 3.1595e-04
Loss = 1.8642e-04, PNorm = 65.3846, GNorm = 0.8608, lr_0 = 3.1455e-04
Loss = 1.4435e-04, PNorm = 65.3942, GNorm = 0.6761, lr_0 = 3.1316e-04
Loss = 1.3326e-04, PNorm = 65.4024, GNorm = 0.4083, lr_0 = 3.1177e-04
Loss = 1.0032e-04, PNorm = 65.4108, GNorm = 0.3988, lr_0 = 3.1039e-04
Validation rmse logD = 0.556799
Validation R2 logD = 0.784086
Epoch 51
Train function
Loss = 1.0061e-04, PNorm = 65.4161, GNorm = 0.4375, lr_0 = 3.0888e-04
Loss = 1.1716e-04, PNorm = 65.4226, GNorm = 0.2062, lr_0 = 3.0752e-04
Loss = 1.0688e-04, PNorm = 65.4279, GNorm = 0.2934, lr_0 = 3.0616e-04
Loss = 1.0792e-04, PNorm = 65.4358, GNorm = 0.3799, lr_0 = 3.0480e-04
Loss = 1.0324e-04, PNorm = 65.4423, GNorm = 0.3244, lr_0 = 3.0346e-04
Loss = 8.8874e-05, PNorm = 65.4469, GNorm = 0.9399, lr_0 = 3.0211e-04
Validation rmse logD = 0.561650
Validation R2 logD = 0.780308
Epoch 52
Train function
Loss = 1.0629e-04, PNorm = 65.4522, GNorm = 0.4092, lr_0 = 3.0064e-04
Loss = 1.2846e-04, PNorm = 65.4560, GNorm = 0.6102, lr_0 = 2.9931e-04
Loss = 1.0936e-04, PNorm = 65.4646, GNorm = 0.5186, lr_0 = 2.9799e-04
Loss = 8.7503e-05, PNorm = 65.4715, GNorm = 0.3079, lr_0 = 2.9667e-04
Loss = 8.1470e-05, PNorm = 65.4776, GNorm = 0.1813, lr_0 = 2.9536e-04
Validation rmse logD = 0.560013
Validation R2 logD = 0.781586
Epoch 53
Train function
Loss = 8.4290e-05, PNorm = 65.4819, GNorm = 0.2848, lr_0 = 2.9392e-04
Loss = 9.2761e-05, PNorm = 65.4892, GNorm = 0.2754, lr_0 = 2.9262e-04
Loss = 7.6899e-05, PNorm = 65.4941, GNorm = 0.7562, lr_0 = 2.9133e-04
Loss = 9.8398e-05, PNorm = 65.5007, GNorm = 0.2205, lr_0 = 2.9004e-04
Loss = 8.2617e-05, PNorm = 65.5053, GNorm = 0.2208, lr_0 = 2.8876e-04
Validation rmse logD = 0.557099
Validation R2 logD = 0.783853
Epoch 54
Train function
Loss = 7.0441e-05, PNorm = 65.5120, GNorm = 0.2719, lr_0 = 2.8735e-04
Loss = 7.0173e-05, PNorm = 65.5162, GNorm = 0.2052, lr_0 = 2.8608e-04
Loss = 5.2218e-05, PNorm = 65.5178, GNorm = 0.1847, lr_0 = 2.8482e-04
Loss = 7.0981e-05, PNorm = 65.5202, GNorm = 0.2829, lr_0 = 2.8356e-04
Loss = 9.3982e-05, PNorm = 65.5264, GNorm = 0.1897, lr_0 = 2.8230e-04
Loss = 6.9762e-05, PNorm = 65.5300, GNorm = 0.1379, lr_0 = 2.8105e-04
Validation rmse logD = 0.558861
Validation R2 logD = 0.782484
Epoch 55
Train function
Loss = 5.6538e-05, PNorm = 65.5343, GNorm = 0.2510, lr_0 = 2.7969e-04
Loss = 4.9985e-05, PNorm = 65.5376, GNorm = 0.4722, lr_0 = 2.7845e-04
Loss = 6.0142e-05, PNorm = 65.5403, GNorm = 0.3198, lr_0 = 2.7722e-04
Loss = 7.3312e-05, PNorm = 65.5431, GNorm = 0.2842, lr_0 = 2.7599e-04
Loss = 9.0121e-05, PNorm = 65.5498, GNorm = 0.1684, lr_0 = 2.7477e-04
Validation rmse logD = 0.560685
Validation R2 logD = 0.781062
Epoch 56
Train function
Loss = 1.0606e-04, PNorm = 65.5576, GNorm = 0.2725, lr_0 = 2.7343e-04
Loss = 8.2877e-05, PNorm = 65.5629, GNorm = 0.1835, lr_0 = 2.7222e-04
Loss = 1.0474e-04, PNorm = 65.5662, GNorm = 0.2191, lr_0 = 2.7102e-04
Loss = 8.0583e-05, PNorm = 65.5689, GNorm = 0.5241, lr_0 = 2.6982e-04
Loss = 8.5928e-05, PNorm = 65.5741, GNorm = 0.1852, lr_0 = 2.6863e-04
Validation rmse logD = 0.558218
Validation R2 logD = 0.782985
Epoch 57
Train function
Loss = 5.4151e-05, PNorm = 65.5815, GNorm = 0.2503, lr_0 = 2.6732e-04
Loss = 1.0077e-04, PNorm = 65.5855, GNorm = 0.1601, lr_0 = 2.6614e-04
Loss = 7.0549e-05, PNorm = 65.5917, GNorm = 0.1577, lr_0 = 2.6496e-04
Loss = 8.1746e-05, PNorm = 65.5948, GNorm = 0.2448, lr_0 = 2.6379e-04
Loss = 7.1601e-05, PNorm = 65.5991, GNorm = 0.2083, lr_0 = 2.6262e-04
Loss = 5.0581e-05, PNorm = 65.6028, GNorm = 0.2760, lr_0 = 2.6146e-04
Loss = 1.9322e-04, PNorm = 65.6027, GNorm = 0.2234, lr_0 = 2.6134e-04
Validation rmse logD = 0.559618
Validation R2 logD = 0.781894
Epoch 58
Train function
Loss = 6.9651e-05, PNorm = 65.6050, GNorm = 0.4866, lr_0 = 2.6019e-04
Loss = 6.0029e-05, PNorm = 65.6106, GNorm = 0.1054, lr_0 = 2.5904e-04
Loss = 5.0788e-05, PNorm = 65.6148, GNorm = 0.1801, lr_0 = 2.5789e-04
Loss = 4.6749e-05, PNorm = 65.6202, GNorm = 0.1181, lr_0 = 2.5675e-04
Loss = 7.7931e-05, PNorm = 65.6251, GNorm = 0.1618, lr_0 = 2.5561e-04
Validation rmse logD = 0.558667
Validation R2 logD = 0.782635
Epoch 59
Train function
Loss = 5.7589e-05, PNorm = 65.6298, GNorm = 0.3623, lr_0 = 2.5448e-04
Loss = 5.2248e-05, PNorm = 65.6315, GNorm = 0.3412, lr_0 = 2.5336e-04
Loss = 4.8714e-05, PNorm = 65.6337, GNorm = 0.2465, lr_0 = 2.5224e-04
Loss = 6.4247e-05, PNorm = 65.6361, GNorm = 0.2972, lr_0 = 2.5112e-04
Loss = 5.2756e-05, PNorm = 65.6400, GNorm = 0.3084, lr_0 = 2.5001e-04
Validation rmse logD = 0.555694
Validation R2 logD = 0.784942
Epoch 60
Train function
Loss = 4.7076e-05, PNorm = 65.6432, GNorm = 0.2864, lr_0 = 2.4879e-04
Loss = 4.5580e-05, PNorm = 65.6488, GNorm = 0.1957, lr_0 = 2.4769e-04
Loss = 4.7253e-05, PNorm = 65.6513, GNorm = 0.1815, lr_0 = 2.4660e-04
Loss = 5.8751e-05, PNorm = 65.6554, GNorm = 0.1571, lr_0 = 2.4551e-04
Loss = 4.4055e-05, PNorm = 65.6569, GNorm = 0.1334, lr_0 = 2.4442e-04
Loss = 4.3451e-05, PNorm = 65.6600, GNorm = 0.1022, lr_0 = 2.4334e-04
Loss = 8.4330e-05, PNorm = 65.6602, GNorm = 0.2322, lr_0 = 2.4323e-04
Validation rmse logD = 0.559859
Validation R2 logD = 0.781706
Epoch 61
Train function
Loss = 3.0125e-05, PNorm = 65.6622, GNorm = 0.1131, lr_0 = 2.4216e-04
Loss = 4.7060e-05, PNorm = 65.6666, GNorm = 0.5114, lr_0 = 2.4109e-04
Loss = 4.4957e-05, PNorm = 65.6695, GNorm = 0.2096, lr_0 = 2.4002e-04
Loss = 6.6320e-05, PNorm = 65.6747, GNorm = 0.1623, lr_0 = 2.3896e-04
Loss = 5.0738e-05, PNorm = 65.6777, GNorm = 0.2814, lr_0 = 2.3790e-04
Validation rmse logD = 0.559646
Validation R2 logD = 0.781873
Epoch 62
Train function
Loss = 5.8328e-05, PNorm = 65.6803, GNorm = 0.3219, lr_0 = 2.3674e-04
Loss = 4.3854e-05, PNorm = 65.6823, GNorm = 0.3026, lr_0 = 2.3570e-04
Loss = 6.2973e-05, PNorm = 65.6863, GNorm = 0.3135, lr_0 = 2.3465e-04
Loss = 5.7990e-05, PNorm = 65.6905, GNorm = 0.3661, lr_0 = 2.3362e-04
Loss = 4.2282e-05, PNorm = 65.6943, GNorm = 0.1045, lr_0 = 2.3258e-04
Validation rmse logD = 0.559124
Validation R2 logD = 0.782280
Epoch 63
Train function
Loss = 3.5339e-05, PNorm = 65.6981, GNorm = 0.2550, lr_0 = 2.3145e-04
Loss = 3.9382e-05, PNorm = 65.7006, GNorm = 0.0981, lr_0 = 2.3043e-04
Loss = 4.0046e-05, PNorm = 65.7027, GNorm = 0.2616, lr_0 = 2.2941e-04
Loss = 4.9895e-05, PNorm = 65.7068, GNorm = 0.1960, lr_0 = 2.2839e-04
Loss = 5.1010e-05, PNorm = 65.7096, GNorm = 0.2357, lr_0 = 2.2738e-04
Validation rmse logD = 0.558965
Validation R2 logD = 0.782403
Epoch 64
Train function
Loss = 4.4569e-05, PNorm = 65.7127, GNorm = 0.2192, lr_0 = 2.2628e-04
Loss = 5.9998e-05, PNorm = 65.7164, GNorm = 0.1842, lr_0 = 2.2528e-04
Loss = 3.9812e-05, PNorm = 65.7209, GNorm = 0.2125, lr_0 = 2.2428e-04
Loss = 3.4518e-05, PNorm = 65.7229, GNorm = 0.3827, lr_0 = 2.2329e-04
Loss = 4.4259e-05, PNorm = 65.7266, GNorm = 0.2269, lr_0 = 2.2230e-04
Loss = 4.7811e-05, PNorm = 65.7307, GNorm = 0.1354, lr_0 = 2.2132e-04
Validation rmse logD = 0.560320
Validation R2 logD = 0.781347
Epoch 65
Train function
Loss = 3.2337e-05, PNorm = 65.7346, GNorm = 0.1327, lr_0 = 2.2024e-04
Loss = 4.6888e-05, PNorm = 65.7372, GNorm = 0.3618, lr_0 = 2.1927e-04
Loss = 4.6320e-05, PNorm = 65.7396, GNorm = 0.3537, lr_0 = 2.1830e-04
Loss = 5.6807e-05, PNorm = 65.7440, GNorm = 0.1372, lr_0 = 2.1733e-04
Loss = 5.6277e-05, PNorm = 65.7464, GNorm = 0.3425, lr_0 = 2.1637e-04
Validation rmse logD = 0.558459
Validation R2 logD = 0.782797
Epoch 66
Train function
Loss = 6.4823e-05, PNorm = 65.7522, GNorm = 0.4500, lr_0 = 2.1532e-04
Loss = 5.5136e-05, PNorm = 65.7552, GNorm = 0.1839, lr_0 = 2.1436e-04
Loss = 5.1307e-05, PNorm = 65.7562, GNorm = 0.1006, lr_0 = 2.1342e-04
Loss = 5.4609e-05, PNorm = 65.7583, GNorm = 0.1508, lr_0 = 2.1247e-04
Loss = 3.5806e-05, PNorm = 65.7616, GNorm = 0.1513, lr_0 = 2.1153e-04
Validation rmse logD = 0.557158
Validation R2 logD = 0.783808
Epoch 67
Train function
Loss = 1.6634e-05, PNorm = 65.7656, GNorm = 0.0716, lr_0 = 2.1060e-04
Loss = 3.4060e-05, PNorm = 65.7707, GNorm = 0.1415, lr_0 = 2.0966e-04
Loss = 4.7163e-05, PNorm = 65.7726, GNorm = 0.2198, lr_0 = 2.0874e-04
Loss = 4.5145e-05, PNorm = 65.7762, GNorm = 0.1483, lr_0 = 2.0781e-04
Loss = 5.6565e-05, PNorm = 65.7802, GNorm = 0.3696, lr_0 = 2.0689e-04
Loss = 5.5615e-05, PNorm = 65.7822, GNorm = 0.4438, lr_0 = 2.0598e-04
Validation rmse logD = 0.567609
Validation R2 logD = 0.775621
Epoch 68
Train function
Loss = 6.9760e-05, PNorm = 65.7861, GNorm = 0.5362, lr_0 = 2.0498e-04
Loss = 5.3993e-05, PNorm = 65.7899, GNorm = 0.2435, lr_0 = 2.0407e-04
Loss = 4.6158e-05, PNorm = 65.7919, GNorm = 0.2773, lr_0 = 2.0317e-04
Loss = 4.9863e-05, PNorm = 65.7974, GNorm = 0.1744, lr_0 = 2.0227e-04
Loss = 4.1997e-05, PNorm = 65.8002, GNorm = 0.1359, lr_0 = 2.0137e-04
Validation rmse logD = 0.559286
Validation R2 logD = 0.782154
Epoch 69
Train function
Loss = 5.1732e-05, PNorm = 65.8022, GNorm = 0.2113, lr_0 = 2.0039e-04
Loss = 5.2780e-05, PNorm = 65.8030, GNorm = 0.1536, lr_0 = 1.9951e-04
Loss = 5.9024e-05, PNorm = 65.8054, GNorm = 0.1497, lr_0 = 1.9863e-04
Loss = 5.6681e-05, PNorm = 65.8087, GNorm = 0.6248, lr_0 = 1.9775e-04
Loss = 5.7692e-05, PNorm = 65.8107, GNorm = 0.4536, lr_0 = 1.9687e-04
Validation rmse logD = 0.560911
Validation R2 logD = 0.780886
Epoch 70
Train function
Loss = 3.2440e-05, PNorm = 65.8146, GNorm = 0.2095, lr_0 = 1.9592e-04
Loss = 3.7452e-05, PNorm = 65.8171, GNorm = 0.2471, lr_0 = 1.9505e-04
Loss = 4.8520e-05, PNorm = 65.8208, GNorm = 0.3956, lr_0 = 1.9419e-04
Loss = 6.4639e-05, PNorm = 65.8254, GNorm = 0.2778, lr_0 = 1.9333e-04
Loss = 5.4493e-05, PNorm = 65.8280, GNorm = 0.2851, lr_0 = 1.9247e-04
Loss = 3.4062e-05, PNorm = 65.8290, GNorm = 0.2093, lr_0 = 1.9162e-04
Validation rmse logD = 0.558408
Validation R2 logD = 0.782836
Epoch 71
Train function
Loss = 4.1946e-05, PNorm = 65.8307, GNorm = 0.1317, lr_0 = 1.9069e-04
Loss = 4.7163e-05, PNorm = 65.8330, GNorm = 0.5423, lr_0 = 1.8984e-04
Loss = 5.5757e-05, PNorm = 65.8363, GNorm = 0.4029, lr_0 = 1.8900e-04
Loss = 4.8147e-05, PNorm = 65.8399, GNorm = 0.1601, lr_0 = 1.8817e-04
Loss = 4.4965e-05, PNorm = 65.8434, GNorm = 0.3565, lr_0 = 1.8734e-04
Validation rmse logD = 0.557041
Validation R2 logD = 0.783898
Epoch 72
Train function
Loss = 2.4654e-05, PNorm = 65.8458, GNorm = 0.1069, lr_0 = 1.8643e-04
Loss = 3.0182e-05, PNorm = 65.8484, GNorm = 0.2369, lr_0 = 1.8560e-04
Loss = 2.6354e-05, PNorm = 65.8500, GNorm = 0.1380, lr_0 = 1.8478e-04
Loss = 2.9733e-05, PNorm = 65.8519, GNorm = 0.0700, lr_0 = 1.8396e-04
Loss = 3.3086e-05, PNorm = 65.8533, GNorm = 0.3096, lr_0 = 1.8315e-04
Validation rmse logD = 0.557514
Validation R2 logD = 0.783531
Epoch 73
Train function
Loss = 2.0246e-05, PNorm = 65.8557, GNorm = 0.2469, lr_0 = 1.8226e-04
Loss = 3.1295e-05, PNorm = 65.8581, GNorm = 0.1938, lr_0 = 1.8145e-04
Loss = 2.6649e-05, PNorm = 65.8599, GNorm = 0.1334, lr_0 = 1.8065e-04
Loss = 2.8910e-05, PNorm = 65.8617, GNorm = 0.2957, lr_0 = 1.7985e-04
Loss = 2.7507e-05, PNorm = 65.8631, GNorm = 0.3023, lr_0 = 1.7905e-04
Loss = 2.3985e-05, PNorm = 65.8646, GNorm = 0.2398, lr_0 = 1.7826e-04
Loss = 8.9825e-05, PNorm = 65.8649, GNorm = 0.1617, lr_0 = 1.7818e-04
Validation rmse logD = 0.561559
Validation R2 logD = 0.780379
Epoch 74
Train function
Loss = 3.5217e-05, PNorm = 65.8670, GNorm = 0.0917, lr_0 = 1.7739e-04
Loss = 2.4573e-05, PNorm = 65.8700, GNorm = 0.2464, lr_0 = 1.7661e-04
Loss = 1.9212e-05, PNorm = 65.8719, GNorm = 0.0730, lr_0 = 1.7583e-04
Loss = 1.9683e-05, PNorm = 65.8740, GNorm = 0.1579, lr_0 = 1.7505e-04
Loss = 1.6090e-05, PNorm = 65.8749, GNorm = 0.0747, lr_0 = 1.7428e-04
Validation rmse logD = 0.560467
Validation R2 logD = 0.781232
Epoch 75
Train function
Loss = 1.3682e-05, PNorm = 65.8763, GNorm = 0.0725, lr_0 = 1.7351e-04
Loss = 2.6035e-05, PNorm = 65.8765, GNorm = 0.1275, lr_0 = 1.7274e-04
Loss = 1.9065e-05, PNorm = 65.8781, GNorm = 0.2284, lr_0 = 1.7197e-04
Loss = 2.0919e-05, PNorm = 65.8795, GNorm = 0.2590, lr_0 = 1.7121e-04
Loss = 2.1855e-05, PNorm = 65.8807, GNorm = 0.1696, lr_0 = 1.7046e-04
Validation rmse logD = 0.559457
Validation R2 logD = 0.782020
Epoch 76
Train function
Loss = 1.4377e-05, PNorm = 65.8821, GNorm = 0.1186, lr_0 = 1.6963e-04
Loss = 1.5519e-05, PNorm = 65.8839, GNorm = 0.1151, lr_0 = 1.6888e-04
Loss = 2.8021e-05, PNorm = 65.8855, GNorm = 0.2401, lr_0 = 1.6813e-04
Loss = 1.9851e-05, PNorm = 65.8872, GNorm = 0.1462, lr_0 = 1.6739e-04
Loss = 2.0306e-05, PNorm = 65.8882, GNorm = 0.0991, lr_0 = 1.6665e-04
Loss = 1.5528e-05, PNorm = 65.8897, GNorm = 0.1394, lr_0 = 1.6591e-04
Loss = 2.3113e-04, PNorm = 65.8897, GNorm = 0.3761, lr_0 = 1.6584e-04
Validation rmse logD = 0.558959
Validation R2 logD = 0.782408
Epoch 77
Train function
Loss = 2.0215e-05, PNorm = 65.8913, GNorm = 0.1032, lr_0 = 1.6510e-04
Loss = 1.8443e-05, PNorm = 65.8923, GNorm = 0.0853, lr_0 = 1.6437e-04
Loss = 3.4729e-05, PNorm = 65.8932, GNorm = 0.2096, lr_0 = 1.6364e-04
Loss = 3.3006e-05, PNorm = 65.8945, GNorm = 0.2771, lr_0 = 1.6292e-04
Loss = 2.9801e-05, PNorm = 65.8978, GNorm = 0.1396, lr_0 = 1.6220e-04
Validation rmse logD = 0.559506
Validation R2 logD = 0.781982
Epoch 78
Train function
Loss = 2.3056e-05, PNorm = 65.8993, GNorm = 0.0909, lr_0 = 1.6141e-04
Loss = 2.5491e-05, PNorm = 65.9012, GNorm = 0.1369, lr_0 = 1.6070e-04
Loss = 2.2501e-05, PNorm = 65.9032, GNorm = 0.0953, lr_0 = 1.5999e-04
Loss = 2.1358e-05, PNorm = 65.9054, GNorm = 0.0727, lr_0 = 1.5928e-04
Loss = 2.7479e-05, PNorm = 65.9067, GNorm = 0.2898, lr_0 = 1.5857e-04
Validation rmse logD = 0.558966
Validation R2 logD = 0.782403
Epoch 79
Train function
Loss = 1.6613e-05, PNorm = 65.9079, GNorm = 0.0936, lr_0 = 1.5780e-04
Loss = 1.5566e-05, PNorm = 65.9091, GNorm = 0.1589, lr_0 = 1.5710e-04
Loss = 1.4109e-05, PNorm = 65.9106, GNorm = 0.0449, lr_0 = 1.5641e-04
Loss = 2.0085e-05, PNorm = 65.9120, GNorm = 0.1138, lr_0 = 1.5572e-04
Loss = 1.6818e-05, PNorm = 65.9131, GNorm = 0.1647, lr_0 = 1.5503e-04
Validation rmse logD = 0.559487
Validation R2 logD = 0.781997
Epoch 80
Train function
Loss = 2.7365e-05, PNorm = 65.9160, GNorm = 0.2066, lr_0 = 1.5427e-04
Loss = 1.9051e-05, PNorm = 65.9177, GNorm = 0.1529, lr_0 = 1.5359e-04
Loss = 1.9677e-05, PNorm = 65.9193, GNorm = 0.1587, lr_0 = 1.5291e-04
Loss = 1.9525e-05, PNorm = 65.9209, GNorm = 0.0518, lr_0 = 1.5224e-04
Loss = 1.3544e-05, PNorm = 65.9225, GNorm = 0.1104, lr_0 = 1.5156e-04
Loss = 1.5653e-05, PNorm = 65.9230, GNorm = 0.0987, lr_0 = 1.5089e-04
Validation rmse logD = 0.558938
Validation R2 logD = 0.782424
Epoch 81
Train function
Loss = 1.4532e-05, PNorm = 65.9245, GNorm = 0.0722, lr_0 = 1.5016e-04
Loss = 1.3988e-05, PNorm = 65.9259, GNorm = 0.1178, lr_0 = 1.4949e-04
Loss = 1.6500e-05, PNorm = 65.9273, GNorm = 0.1272, lr_0 = 1.4883e-04
Loss = 1.8717e-05, PNorm = 65.9284, GNorm = 0.1433, lr_0 = 1.4817e-04
Loss = 1.9228e-05, PNorm = 65.9295, GNorm = 0.1433, lr_0 = 1.4752e-04
Validation rmse logD = 0.560362
Validation R2 logD = 0.781314
Epoch 82
Train function
Loss = 1.3271e-05, PNorm = 65.9311, GNorm = 0.1573, lr_0 = 1.4680e-04
Loss = 1.6873e-05, PNorm = 65.9321, GNorm = 0.2183, lr_0 = 1.4615e-04
Loss = 1.3460e-05, PNorm = 65.9336, GNorm = 0.0936, lr_0 = 1.4551e-04
Loss = 1.4348e-05, PNorm = 65.9346, GNorm = 0.0698, lr_0 = 1.4486e-04
Loss = 1.8907e-05, PNorm = 65.9355, GNorm = 0.2646, lr_0 = 1.4422e-04
Validation rmse logD = 0.561665
Validation R2 logD = 0.780296
Epoch 83
Train function
Loss = 2.1464e-05, PNorm = 65.9373, GNorm = 0.3597, lr_0 = 1.4352e-04
Loss = 2.4472e-05, PNorm = 65.9384, GNorm = 0.2081, lr_0 = 1.4288e-04
Loss = 2.4226e-05, PNorm = 65.9390, GNorm = 0.0953, lr_0 = 1.4225e-04
Loss = 2.0014e-05, PNorm = 65.9403, GNorm = 0.1847, lr_0 = 1.4162e-04
Loss = 2.0764e-05, PNorm = 65.9415, GNorm = 0.0865, lr_0 = 1.4100e-04
Loss = 1.4763e-05, PNorm = 65.9433, GNorm = 0.0926, lr_0 = 1.4037e-04
Validation rmse logD = 0.560834
Validation R2 logD = 0.780946
Epoch 84
Train function
Loss = 1.8192e-05, PNorm = 65.9448, GNorm = 0.1128, lr_0 = 1.3975e-04
Loss = 1.1708e-05, PNorm = 65.9459, GNorm = 0.0649, lr_0 = 1.3913e-04
Loss = 1.1404e-05, PNorm = 65.9474, GNorm = 0.0786, lr_0 = 1.3852e-04
Loss = 1.3076e-05, PNorm = 65.9483, GNorm = 0.1321, lr_0 = 1.3791e-04
Loss = 1.6956e-05, PNorm = 65.9499, GNorm = 0.3114, lr_0 = 1.3730e-04
Validation rmse logD = 0.561344
Validation R2 logD = 0.780547
Epoch 85
Train function
Loss = 1.2850e-05, PNorm = 65.9516, GNorm = 0.1339, lr_0 = 1.3663e-04
Loss = 1.2681e-05, PNorm = 65.9526, GNorm = 0.0612, lr_0 = 1.3602e-04
Loss = 1.2365e-05, PNorm = 65.9540, GNorm = 0.0918, lr_0 = 1.3542e-04
Loss = 1.3195e-05, PNorm = 65.9550, GNorm = 0.1035, lr_0 = 1.3482e-04
Loss = 1.1981e-05, PNorm = 65.9567, GNorm = 0.1809, lr_0 = 1.3423e-04
Validation rmse logD = 0.559683
Validation R2 logD = 0.781844
Epoch 86
Train function
Loss = 8.8403e-06, PNorm = 65.9582, GNorm = 0.0788, lr_0 = 1.3357e-04
Loss = 1.1167e-05, PNorm = 65.9594, GNorm = 0.1225, lr_0 = 1.3298e-04
Loss = 1.0855e-05, PNorm = 65.9612, GNorm = 0.0436, lr_0 = 1.3239e-04
Loss = 1.1404e-05, PNorm = 65.9619, GNorm = 0.0590, lr_0 = 1.3181e-04
Loss = 1.4768e-05, PNorm = 65.9635, GNorm = 0.1602, lr_0 = 1.3123e-04
Loss = 1.4270e-05, PNorm = 65.9652, GNorm = 0.2726, lr_0 = 1.3065e-04
Validation rmse logD = 0.559240
Validation R2 logD = 0.782189
Epoch 87
Train function
Loss = 2.2995e-05, PNorm = 65.9671, GNorm = 0.0925, lr_0 = 1.3001e-04
Loss = 1.5842e-05, PNorm = 65.9679, GNorm = 0.0768, lr_0 = 1.2944e-04
Loss = 2.2303e-05, PNorm = 65.9680, GNorm = 0.1247, lr_0 = 1.2886e-04
Loss = 2.4893e-05, PNorm = 65.9692, GNorm = 0.2874, lr_0 = 1.2829e-04
Loss = 1.6279e-05, PNorm = 65.9713, GNorm = 0.1072, lr_0 = 1.2773e-04
Validation rmse logD = 0.560750
Validation R2 logD = 0.781012
Epoch 88
Train function
Loss = 1.1739e-05, PNorm = 65.9724, GNorm = 0.0709, lr_0 = 1.2710e-04
Loss = 1.1463e-05, PNorm = 65.9736, GNorm = 0.1221, lr_0 = 1.2654e-04
Loss = 1.4553e-05, PNorm = 65.9751, GNorm = 0.1369, lr_0 = 1.2598e-04
Loss = 2.2537e-05, PNorm = 65.9757, GNorm = 0.2003, lr_0 = 1.2542e-04
Loss = 1.4810e-05, PNorm = 65.9771, GNorm = 0.0989, lr_0 = 1.2487e-04
Validation rmse logD = 0.558904
Validation R2 logD = 0.782451
Epoch 89
Train function
Loss = 1.2421e-05, PNorm = 65.9786, GNorm = 0.2145, lr_0 = 1.2426e-04
Loss = 1.5615e-05, PNorm = 65.9798, GNorm = 0.1577, lr_0 = 1.2371e-04
Loss = 1.1648e-05, PNorm = 65.9807, GNorm = 0.1475, lr_0 = 1.2317e-04
Loss = 1.2635e-05, PNorm = 65.9817, GNorm = 0.0954, lr_0 = 1.2262e-04
Loss = 1.6414e-05, PNorm = 65.9822, GNorm = 0.1166, lr_0 = 1.2208e-04
Loss = 1.2922e-05, PNorm = 65.9839, GNorm = 0.0544, lr_0 = 1.2154e-04
Loss = 4.5505e-05, PNorm = 65.9841, GNorm = 0.1318, lr_0 = 1.2148e-04
Validation rmse logD = 0.559621
Validation R2 logD = 0.781892
Epoch 90
Train function
Loss = 9.6678e-06, PNorm = 65.9855, GNorm = 0.0913, lr_0 = 1.2095e-04
Loss = 1.5999e-05, PNorm = 65.9865, GNorm = 0.1779, lr_0 = 1.2041e-04
Loss = 1.4717e-05, PNorm = 65.9886, GNorm = 0.0926, lr_0 = 1.1988e-04
Loss = 1.0357e-05, PNorm = 65.9898, GNorm = 0.0514, lr_0 = 1.1935e-04
Loss = 1.0870e-05, PNorm = 65.9905, GNorm = 0.1571, lr_0 = 1.1882e-04
Validation rmse logD = 0.559383
Validation R2 logD = 0.782078
Epoch 91
Train function
Loss = 8.1974e-06, PNorm = 65.9911, GNorm = 0.1040, lr_0 = 1.1824e-04
Loss = 9.4426e-06, PNorm = 65.9919, GNorm = 0.0869, lr_0 = 1.1772e-04
Loss = 1.1233e-05, PNorm = 65.9933, GNorm = 0.0776, lr_0 = 1.1720e-04
Loss = 1.7479e-05, PNorm = 65.9940, GNorm = 0.2746, lr_0 = 1.1668e-04
Loss = 8.0641e-06, PNorm = 65.9948, GNorm = 0.0668, lr_0 = 1.1616e-04
Validation rmse logD = 0.558681
Validation R2 logD = 0.782624
Epoch 92
Train function
Loss = 9.6192e-06, PNorm = 65.9959, GNorm = 0.0883, lr_0 = 1.1565e-04
Loss = 1.1831e-05, PNorm = 65.9969, GNorm = 0.0678, lr_0 = 1.1514e-04
Loss = 8.8641e-06, PNorm = 65.9980, GNorm = 0.0580, lr_0 = 1.1463e-04
Loss = 1.3458e-05, PNorm = 65.9987, GNorm = 0.0834, lr_0 = 1.1412e-04
Loss = 1.0537e-05, PNorm = 65.9997, GNorm = 0.2755, lr_0 = 1.1362e-04
Loss = 1.0644e-05, PNorm = 66.0002, GNorm = 0.1001, lr_0 = 1.1312e-04
Loss = 6.3103e-05, PNorm = 66.0002, GNorm = 0.1379, lr_0 = 1.1307e-04
Validation rmse logD = 0.559590
Validation R2 logD = 0.781916
Epoch 93
Train function
Loss = 1.0786e-05, PNorm = 66.0015, GNorm = 0.1065, lr_0 = 1.1257e-04
Loss = 8.8223e-06, PNorm = 66.0026, GNorm = 0.0862, lr_0 = 1.1207e-04
Loss = 1.0005e-05, PNorm = 66.0030, GNorm = 0.1086, lr_0 = 1.1157e-04
Loss = 1.2201e-05, PNorm = 66.0037, GNorm = 0.1546, lr_0 = 1.1108e-04
Loss = 7.6943e-06, PNorm = 66.0041, GNorm = 0.0562, lr_0 = 1.1059e-04
Validation rmse logD = 0.559610
Validation R2 logD = 0.781901
Epoch 94
Train function
Loss = 1.0415e-05, PNorm = 66.0043, GNorm = 0.0816, lr_0 = 1.1005e-04
Loss = 8.2374e-06, PNorm = 66.0052, GNorm = 0.0832, lr_0 = 1.0956e-04
Loss = 7.4492e-06, PNorm = 66.0067, GNorm = 0.1836, lr_0 = 1.0908e-04
Loss = 9.6130e-06, PNorm = 66.0079, GNorm = 0.0685, lr_0 = 1.0860e-04
Loss = 8.4084e-06, PNorm = 66.0087, GNorm = 0.0588, lr_0 = 1.0811e-04
Validation rmse logD = 0.559055
Validation R2 logD = 0.782333
Epoch 95
Train function
Loss = 5.6274e-06, PNorm = 66.0095, GNorm = 0.0516, lr_0 = 1.0759e-04
Loss = 6.1724e-06, PNorm = 66.0098, GNorm = 0.1116, lr_0 = 1.0711e-04
Loss = 1.0814e-05, PNorm = 66.0108, GNorm = 0.0853, lr_0 = 1.0664e-04
Loss = 8.2696e-06, PNorm = 66.0116, GNorm = 0.0997, lr_0 = 1.0617e-04
Loss = 8.0041e-06, PNorm = 66.0120, GNorm = 0.0972, lr_0 = 1.0570e-04
Validation rmse logD = 0.559904
Validation R2 logD = 0.781672
Epoch 96
Train function
Loss = 8.2911e-06, PNorm = 66.0131, GNorm = 0.0506, lr_0 = 1.0518e-04
Loss = 1.0092e-05, PNorm = 66.0143, GNorm = 0.0879, lr_0 = 1.0472e-04
Loss = 6.0705e-06, PNorm = 66.0144, GNorm = 0.0441, lr_0 = 1.0426e-04
Loss = 6.0410e-06, PNorm = 66.0149, GNorm = 0.0372, lr_0 = 1.0379e-04
Loss = 7.1023e-06, PNorm = 66.0154, GNorm = 0.0425, lr_0 = 1.0333e-04
Loss = 1.1091e-05, PNorm = 66.0170, GNorm = 0.1590, lr_0 = 1.0288e-04
Validation rmse logD = 0.559347
Validation R2 logD = 0.782106
Epoch 97
Train function
Loss = 7.0062e-06, PNorm = 66.0186, GNorm = 0.0726, lr_0 = 1.0238e-04
Loss = 8.7939e-06, PNorm = 66.0197, GNorm = 0.0457, lr_0 = 1.0192e-04
Loss = 6.6636e-06, PNorm = 66.0202, GNorm = 0.0419, lr_0 = 1.0147e-04
Loss = 1.3515e-05, PNorm = 66.0205, GNorm = 0.1184, lr_0 = 1.0102e-04
Loss = 1.0563e-05, PNorm = 66.0217, GNorm = 0.1047, lr_0 = 1.0058e-04
Validation rmse logD = 0.561160
Validation R2 logD = 0.780691
Epoch 98
Train function
Loss = 5.9512e-06, PNorm = 66.0218, GNorm = 0.0727, lr_0 = 1.0009e-04
Loss = 7.9452e-06, PNorm = 66.0227, GNorm = 0.1027, lr_0 = 1.0000e-04
Loss = 6.9132e-06, PNorm = 66.0234, GNorm = 0.0533, lr_0 = 1.0000e-04
Loss = 1.0221e-05, PNorm = 66.0244, GNorm = 0.0525, lr_0 = 1.0000e-04
Loss = 6.6762e-06, PNorm = 66.0247, GNorm = 0.0409, lr_0 = 1.0000e-04
Validation rmse logD = 0.559343
Validation R2 logD = 0.782109
Epoch 99
Train function
Loss = 8.8216e-06, PNorm = 66.0257, GNorm = 0.2580, lr_0 = 1.0000e-04
Loss = 1.4554e-05, PNorm = 66.0271, GNorm = 0.0457, lr_0 = 1.0000e-04
Loss = 8.0772e-06, PNorm = 66.0283, GNorm = 0.0548, lr_0 = 1.0000e-04
Loss = 1.0048e-05, PNorm = 66.0291, GNorm = 0.1377, lr_0 = 1.0000e-04
Loss = 7.3013e-06, PNorm = 66.0290, GNorm = 0.0995, lr_0 = 1.0000e-04
Loss = 1.0493e-05, PNorm = 66.0292, GNorm = 0.0728, lr_0 = 1.0000e-04
Validation rmse logD = 0.559100
Validation R2 logD = 0.782298
Model 0 best validation rmse = 0.552227 on epoch 46
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.589051
Model 0 test R2 logD = 0.760021
Ensemble test rmse  logD= 0.589051
Ensemble test R2  logD= 0.760021
4-fold cross validation
	Seed 0 ==> test rmse = 0.571694
	Seed 0 ==> test R2 = 0.773955
	Seed 1 ==> test rmse = 0.593103
	Seed 1 ==> test R2 = 0.756708
	Seed 2 ==> test rmse = 0.611301
	Seed 2 ==> test R2 = 0.741549
	Seed 3 ==> test rmse = 0.589051
	Seed 3 ==> test R2 = 0.760021
Overall val rmse logD= 0.581800 +/- 0.017819
Overall val R2 logD = 0.763158 +/- 0.017816
Overall test rmse logD = 0.591287 +/- 0.014078
Overall test R2 logD = 0.758058 +/- 0.011521
Elapsed time = 2:41:27
