Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_301/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=125, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,500,201
Moving model to cuda
Epoch 0
Train function
Loss = 1.5754e-02, PNorm = 55.2153, GNorm = 4.7234, lr_0 = 1.2829e-04
Loss = 1.4927e-02, PNorm = 55.2222, GNorm = 1.8946, lr_0 = 1.5400e-04
Loss = 1.1110e-02, PNorm = 55.2325, GNorm = 7.0668, lr_0 = 1.7971e-04
Loss = 7.1820e-03, PNorm = 55.2459, GNorm = 2.0269, lr_0 = 2.0543e-04
Loss = 8.6683e-03, PNorm = 55.2589, GNorm = 6.7965, lr_0 = 2.3114e-04
Loss = 9.1211e-03, PNorm = 55.2728, GNorm = 3.9118, lr_0 = 2.5686e-04
Loss = 7.1385e-03, PNorm = 55.2929, GNorm = 4.5205, lr_0 = 2.8257e-04
Loss = 6.2752e-03, PNorm = 55.3131, GNorm = 2.6712, lr_0 = 3.0829e-04
Loss = 6.1749e-03, PNorm = 55.3356, GNorm = 1.7792, lr_0 = 3.3400e-04
Loss = 4.2747e-03, PNorm = 55.3602, GNorm = 2.2100, lr_0 = 3.5971e-04
Loss = 3.8994e-03, PNorm = 55.3841, GNorm = 3.0327, lr_0 = 3.8543e-04
Loss = 4.4436e-03, PNorm = 55.4082, GNorm = 7.3050, lr_0 = 4.1114e-04
Loss = 3.9264e-03, PNorm = 55.4302, GNorm = 1.6469, lr_0 = 4.3686e-04
Loss = 4.1396e-03, PNorm = 55.4615, GNorm = 5.9138, lr_0 = 4.6257e-04
Loss = 5.5014e-03, PNorm = 55.4899, GNorm = 1.3022, lr_0 = 4.8829e-04
Loss = 4.5161e-03, PNorm = 55.5340, GNorm = 1.0186, lr_0 = 5.1400e-04
Loss = 4.5254e-03, PNorm = 55.5774, GNorm = 2.4365, lr_0 = 5.3971e-04
Validation rmse logP = 0.828612
Validation R2 logP = 0.798493
Epoch 1
Train function
Loss = 2.9631e-03, PNorm = 55.6218, GNorm = 1.3742, lr_0 = 5.6800e-04
Loss = 3.0868e-03, PNorm = 55.6596, GNorm = 1.4754, lr_0 = 5.9371e-04
Loss = 3.0890e-03, PNorm = 55.7021, GNorm = 2.0800, lr_0 = 6.1943e-04
Loss = 3.5485e-03, PNorm = 55.7463, GNorm = 2.7444, lr_0 = 6.4514e-04
Loss = 3.7596e-03, PNorm = 55.7911, GNorm = 4.7214, lr_0 = 6.7086e-04
Loss = 4.1487e-03, PNorm = 55.8519, GNorm = 1.7201, lr_0 = 6.9657e-04
Loss = 3.2398e-03, PNorm = 55.9117, GNorm = 2.4108, lr_0 = 7.2229e-04
Loss = 3.4083e-03, PNorm = 55.9778, GNorm = 1.3173, lr_0 = 7.4800e-04
Loss = 2.7644e-03, PNorm = 56.0217, GNorm = 1.4940, lr_0 = 7.7371e-04
Loss = 2.9233e-03, PNorm = 56.0687, GNorm = 3.0706, lr_0 = 7.9943e-04
Loss = 2.9535e-03, PNorm = 56.1310, GNorm = 1.7686, lr_0 = 8.2514e-04
Loss = 3.9831e-03, PNorm = 56.1816, GNorm = 2.4912, lr_0 = 8.5086e-04
Loss = 2.7608e-03, PNorm = 56.2440, GNorm = 3.6969, lr_0 = 8.7657e-04
Loss = 3.3023e-03, PNorm = 56.2986, GNorm = 2.3323, lr_0 = 9.0229e-04
Loss = 3.3683e-03, PNorm = 56.3682, GNorm = 4.0916, lr_0 = 9.2800e-04
Loss = 2.9536e-03, PNorm = 56.4255, GNorm = 1.9025, lr_0 = 9.5371e-04
Loss = 2.8885e-03, PNorm = 56.4840, GNorm = 1.8377, lr_0 = 9.7943e-04
Loss = 2.6441e-03, PNorm = 56.5459, GNorm = 2.0497, lr_0 = 9.9973e-04
Validation rmse logP = 0.734619
Validation R2 logP = 0.841616
Epoch 2
Train function
Loss = 3.2153e-03, PNorm = 56.6052, GNorm = 3.0639, lr_0 = 9.9839e-04
Loss = 2.7742e-03, PNorm = 56.6946, GNorm = 3.7987, lr_0 = 9.9705e-04
Loss = 2.3578e-03, PNorm = 56.7518, GNorm = 1.9653, lr_0 = 9.9571e-04
Loss = 2.4522e-03, PNorm = 56.8132, GNorm = 0.9964, lr_0 = 9.9438e-04
Loss = 2.4264e-03, PNorm = 56.8834, GNorm = 1.7833, lr_0 = 9.9304e-04
Loss = 2.3273e-03, PNorm = 56.9458, GNorm = 1.8044, lr_0 = 9.9171e-04
Loss = 2.1954e-03, PNorm = 56.9964, GNorm = 0.6220, lr_0 = 9.9038e-04
Loss = 2.4188e-03, PNorm = 57.0531, GNorm = 3.5754, lr_0 = 9.8905e-04
Loss = 2.4230e-03, PNorm = 57.1093, GNorm = 1.9697, lr_0 = 9.8772e-04
Loss = 2.3570e-03, PNorm = 57.1711, GNorm = 1.0580, lr_0 = 9.8640e-04
Loss = 2.5911e-03, PNorm = 57.2189, GNorm = 1.7314, lr_0 = 9.8508e-04
Loss = 2.0738e-03, PNorm = 57.2899, GNorm = 1.0964, lr_0 = 9.8375e-04
Loss = 2.1251e-03, PNorm = 57.3445, GNorm = 1.2802, lr_0 = 9.8243e-04
Loss = 2.0919e-03, PNorm = 57.4012, GNorm = 0.7858, lr_0 = 9.8112e-04
Loss = 2.3873e-03, PNorm = 57.4467, GNorm = 2.6452, lr_0 = 9.7980e-04
Loss = 2.3615e-03, PNorm = 57.5117, GNorm = 1.2139, lr_0 = 9.7848e-04
Loss = 2.1765e-03, PNorm = 57.5583, GNorm = 2.0941, lr_0 = 9.7717e-04
Validation rmse logP = 0.665377
Validation R2 logP = 0.870066
Epoch 3
Train function
Loss = 2.4421e-03, PNorm = 57.6185, GNorm = 0.6408, lr_0 = 9.7573e-04
Loss = 2.5392e-03, PNorm = 57.6768, GNorm = 0.8149, lr_0 = 9.7442e-04
Loss = 2.2208e-03, PNorm = 57.7497, GNorm = 0.6018, lr_0 = 9.7311e-04
Loss = 2.0320e-03, PNorm = 57.8235, GNorm = 0.5513, lr_0 = 9.7181e-04
Loss = 2.1053e-03, PNorm = 57.8643, GNorm = 1.0400, lr_0 = 9.7050e-04
Loss = 1.8930e-03, PNorm = 57.9044, GNorm = 0.6232, lr_0 = 9.6920e-04
Loss = 3.1199e-03, PNorm = 57.9581, GNorm = 2.1751, lr_0 = 9.6790e-04
Loss = 2.7422e-03, PNorm = 58.0370, GNorm = 0.8775, lr_0 = 9.6660e-04
Loss = 2.3320e-03, PNorm = 58.0939, GNorm = 0.8383, lr_0 = 9.6531e-04
Loss = 1.8782e-03, PNorm = 58.1653, GNorm = 1.6993, lr_0 = 9.6401e-04
Loss = 1.4786e-03, PNorm = 58.2277, GNorm = 0.5617, lr_0 = 9.6272e-04
Loss = 1.6989e-03, PNorm = 58.2956, GNorm = 0.5849, lr_0 = 9.6143e-04
Loss = 1.7876e-03, PNorm = 58.3544, GNorm = 0.6460, lr_0 = 9.6014e-04
Loss = 1.5778e-03, PNorm = 58.3952, GNorm = 1.0019, lr_0 = 9.5885e-04
Loss = 1.8797e-03, PNorm = 58.4296, GNorm = 0.7449, lr_0 = 9.5756e-04
Loss = 1.5623e-03, PNorm = 58.4909, GNorm = 0.4467, lr_0 = 9.5628e-04
Loss = 2.2267e-03, PNorm = 58.5228, GNorm = 0.4773, lr_0 = 9.5499e-04
Loss = 1.8825e-03, PNorm = 58.5758, GNorm = 0.5886, lr_0 = 9.5371e-04
Validation rmse logP = 0.613630
Validation R2 logP = 0.889490
Epoch 4
Train function
Loss = 1.8540e-03, PNorm = 58.6307, GNorm = 1.3729, lr_0 = 9.5243e-04
Loss = 1.6018e-03, PNorm = 58.6866, GNorm = 1.2051, lr_0 = 9.5115e-04
Loss = 1.5091e-03, PNorm = 58.7420, GNorm = 0.3942, lr_0 = 9.4988e-04
Loss = 1.7353e-03, PNorm = 58.7834, GNorm = 0.5484, lr_0 = 9.4860e-04
Loss = 1.7054e-03, PNorm = 58.8257, GNorm = 0.5987, lr_0 = 9.4733e-04
Loss = 1.2790e-03, PNorm = 58.8718, GNorm = 0.3512, lr_0 = 9.4606e-04
Loss = 1.4392e-03, PNorm = 58.9217, GNorm = 0.7516, lr_0 = 9.4479e-04
Loss = 1.7326e-03, PNorm = 58.9815, GNorm = 0.5357, lr_0 = 9.4352e-04
Loss = 1.6155e-03, PNorm = 59.0463, GNorm = 0.8320, lr_0 = 9.4226e-04
Loss = 1.5414e-03, PNorm = 59.0899, GNorm = 0.6452, lr_0 = 9.4099e-04
Loss = 1.4513e-03, PNorm = 59.1308, GNorm = 0.6826, lr_0 = 9.3973e-04
Loss = 1.1391e-03, PNorm = 59.1716, GNorm = 0.6213, lr_0 = 9.3847e-04
Loss = 1.4179e-03, PNorm = 59.2058, GNorm = 0.5145, lr_0 = 9.3721e-04
Loss = 1.7598e-03, PNorm = 59.2498, GNorm = 0.3772, lr_0 = 9.3595e-04
Loss = 1.6339e-03, PNorm = 59.3002, GNorm = 0.5631, lr_0 = 9.3470e-04
Loss = 1.4249e-03, PNorm = 59.3451, GNorm = 0.4177, lr_0 = 9.3344e-04
Loss = 1.2093e-03, PNorm = 59.3919, GNorm = 1.2357, lr_0 = 9.3219e-04
Validation rmse logP = 0.588643
Validation R2 logP = 0.898307
Epoch 5
Train function
Loss = 2.3029e-03, PNorm = 59.4389, GNorm = 1.3449, lr_0 = 9.3094e-04
Loss = 1.3438e-03, PNorm = 59.5169, GNorm = 1.0069, lr_0 = 9.2969e-04
Loss = 1.2020e-03, PNorm = 59.5676, GNorm = 0.5996, lr_0 = 9.2844e-04
Loss = 1.0995e-03, PNorm = 59.6116, GNorm = 0.4948, lr_0 = 9.2720e-04
Loss = 1.2863e-03, PNorm = 59.6721, GNorm = 0.6734, lr_0 = 9.2595e-04
Loss = 1.0881e-03, PNorm = 59.7232, GNorm = 0.4018, lr_0 = 9.2471e-04
Loss = 1.2745e-03, PNorm = 59.7737, GNorm = 0.9810, lr_0 = 9.2347e-04
Loss = 1.0168e-03, PNorm = 59.8096, GNorm = 0.5077, lr_0 = 9.2223e-04
Loss = 1.4699e-03, PNorm = 59.8542, GNorm = 0.7044, lr_0 = 9.2099e-04
Loss = 1.4609e-03, PNorm = 59.8931, GNorm = 0.4409, lr_0 = 9.1976e-04
Loss = 1.5064e-03, PNorm = 59.9478, GNorm = 2.0240, lr_0 = 9.1852e-04
Loss = 1.7133e-03, PNorm = 60.0037, GNorm = 0.8738, lr_0 = 9.1729e-04
Loss = 1.3800e-03, PNorm = 60.0483, GNorm = 0.6989, lr_0 = 9.1606e-04
Loss = 1.5116e-03, PNorm = 60.0886, GNorm = 1.7759, lr_0 = 9.1483e-04
Loss = 1.4847e-03, PNorm = 60.1459, GNorm = 1.3559, lr_0 = 9.1360e-04
Loss = 1.8103e-03, PNorm = 60.1868, GNorm = 0.8649, lr_0 = 9.1238e-04
Loss = 1.4658e-03, PNorm = 60.2487, GNorm = 0.9588, lr_0 = 9.1115e-04
Loss = 1.4358e-03, PNorm = 60.3008, GNorm = 0.7626, lr_0 = 9.0993e-04
Validation rmse logP = 0.524106
Validation R2 logP = 0.919383
Epoch 6
Train function
Loss = 1.1460e-03, PNorm = 60.3601, GNorm = 0.3343, lr_0 = 9.0859e-04
Loss = 1.0884e-03, PNorm = 60.4076, GNorm = 0.3385, lr_0 = 9.0737e-04
Loss = 9.1939e-04, PNorm = 60.4555, GNorm = 0.9208, lr_0 = 9.0615e-04
Loss = 1.2690e-03, PNorm = 60.5045, GNorm = 1.1371, lr_0 = 9.0494e-04
Loss = 1.0736e-03, PNorm = 60.5652, GNorm = 0.6163, lr_0 = 9.0372e-04
Loss = 1.1142e-03, PNorm = 60.6130, GNorm = 0.7602, lr_0 = 9.0251e-04
Loss = 1.4666e-03, PNorm = 60.6695, GNorm = 1.5553, lr_0 = 9.0130e-04
Loss = 1.2234e-03, PNorm = 60.7244, GNorm = 0.7201, lr_0 = 9.0009e-04
Loss = 1.1787e-03, PNorm = 60.7769, GNorm = 1.4427, lr_0 = 8.9888e-04
Loss = 1.0540e-03, PNorm = 60.8270, GNorm = 0.6930, lr_0 = 8.9768e-04
Loss = 1.1410e-03, PNorm = 60.8775, GNorm = 0.9929, lr_0 = 8.9647e-04
Loss = 1.1890e-03, PNorm = 60.9112, GNorm = 0.6295, lr_0 = 8.9527e-04
Loss = 9.9652e-04, PNorm = 60.9539, GNorm = 1.1044, lr_0 = 8.9407e-04
Loss = 1.2175e-03, PNorm = 60.9873, GNorm = 0.6239, lr_0 = 8.9287e-04
Loss = 8.3680e-04, PNorm = 61.0314, GNorm = 0.6561, lr_0 = 8.9167e-04
Loss = 1.4979e-03, PNorm = 61.0600, GNorm = 0.7340, lr_0 = 8.9047e-04
Loss = 1.3322e-03, PNorm = 61.1114, GNorm = 0.8945, lr_0 = 8.8928e-04
Validation rmse logP = 0.550408
Validation R2 logP = 0.911089
Epoch 7
Train function
Loss = 1.0509e-03, PNorm = 61.1560, GNorm = 1.1298, lr_0 = 8.8809e-04
Loss = 9.0227e-04, PNorm = 61.2022, GNorm = 0.7731, lr_0 = 8.8689e-04
Loss = 1.1026e-03, PNorm = 61.2471, GNorm = 0.6337, lr_0 = 8.8570e-04
Loss = 9.5065e-04, PNorm = 61.3023, GNorm = 0.5910, lr_0 = 8.8452e-04
Loss = 9.3095e-04, PNorm = 61.3396, GNorm = 0.4953, lr_0 = 8.8333e-04
Loss = 1.1167e-03, PNorm = 61.3864, GNorm = 0.7029, lr_0 = 8.8214e-04
Loss = 1.0881e-03, PNorm = 61.4339, GNorm = 0.3496, lr_0 = 8.8096e-04
Loss = 1.0386e-03, PNorm = 61.4937, GNorm = 1.3126, lr_0 = 8.7978e-04
Loss = 1.0989e-03, PNorm = 61.5494, GNorm = 0.9404, lr_0 = 8.7860e-04
Loss = 8.6000e-04, PNorm = 61.5933, GNorm = 0.4579, lr_0 = 8.7742e-04
Loss = 1.5663e-03, PNorm = 61.6420, GNorm = 0.5741, lr_0 = 8.7624e-04
Loss = 1.2532e-03, PNorm = 61.6805, GNorm = 0.8538, lr_0 = 8.7507e-04
Loss = 1.4183e-03, PNorm = 61.7295, GNorm = 1.2719, lr_0 = 8.7389e-04
Loss = 1.0023e-03, PNorm = 61.7890, GNorm = 0.5022, lr_0 = 8.7272e-04
Loss = 9.9927e-04, PNorm = 61.8397, GNorm = 0.8878, lr_0 = 8.7155e-04
Loss = 9.3847e-04, PNorm = 61.8782, GNorm = 0.4131, lr_0 = 8.7038e-04
Loss = 1.0275e-03, PNorm = 61.9179, GNorm = 1.2635, lr_0 = 8.6921e-04
Loss = 1.0564e-03, PNorm = 61.9567, GNorm = 0.3046, lr_0 = 8.6805e-04
Validation rmse logP = 0.499121
Validation R2 logP = 0.926886
Epoch 8
Train function
Loss = 9.4103e-04, PNorm = 61.9963, GNorm = 0.4113, lr_0 = 8.6688e-04
Loss = 9.7374e-04, PNorm = 62.0416, GNorm = 0.6393, lr_0 = 8.6572e-04
Loss = 8.4673e-04, PNorm = 62.0947, GNorm = 1.1297, lr_0 = 8.6456e-04
Loss = 9.5649e-04, PNorm = 62.1499, GNorm = 0.7461, lr_0 = 8.6340e-04
Loss = 9.4249e-04, PNorm = 62.1997, GNorm = 0.8386, lr_0 = 8.6224e-04
Loss = 9.4526e-04, PNorm = 62.2380, GNorm = 0.5417, lr_0 = 8.6108e-04
Loss = 1.0741e-03, PNorm = 62.2694, GNorm = 1.5366, lr_0 = 8.5993e-04
Loss = 1.0182e-03, PNorm = 62.3117, GNorm = 0.2410, lr_0 = 8.5877e-04
Loss = 9.1970e-04, PNorm = 62.3500, GNorm = 0.5966, lr_0 = 8.5762e-04
Loss = 8.6001e-04, PNorm = 62.4046, GNorm = 0.3748, lr_0 = 8.5647e-04
Loss = 7.4238e-04, PNorm = 62.4435, GNorm = 0.3625, lr_0 = 8.5532e-04
Loss = 9.5016e-04, PNorm = 62.4820, GNorm = 0.3445, lr_0 = 8.5417e-04
Loss = 7.4415e-04, PNorm = 62.5193, GNorm = 0.3392, lr_0 = 8.5303e-04
Loss = 6.3610e-04, PNorm = 62.5507, GNorm = 0.4255, lr_0 = 8.5188e-04
Loss = 8.2233e-04, PNorm = 62.5780, GNorm = 0.8099, lr_0 = 8.5074e-04
Loss = 8.7421e-04, PNorm = 62.6137, GNorm = 0.7477, lr_0 = 8.4960e-04
Loss = 8.3222e-04, PNorm = 62.6450, GNorm = 0.5708, lr_0 = 8.4846e-04
Loss = 1.0470e-03, PNorm = 62.6747, GNorm = 1.1094, lr_0 = 8.4732e-04
Loss = 1.5076e-03, PNorm = 62.6768, GNorm = 0.5259, lr_0 = 8.4720e-04
Validation rmse logP = 0.524318
Validation R2 logP = 0.919318
Epoch 9
Train function
Loss = 7.7532e-04, PNorm = 62.7190, GNorm = 0.6701, lr_0 = 8.4607e-04
Loss = 7.2390e-04, PNorm = 62.7563, GNorm = 0.6094, lr_0 = 8.4493e-04
Loss = 6.7140e-04, PNorm = 62.7907, GNorm = 0.3917, lr_0 = 8.4380e-04
Loss = 7.1604e-04, PNorm = 62.8332, GNorm = 0.3918, lr_0 = 8.4267e-04
Loss = 6.0093e-04, PNorm = 62.8772, GNorm = 0.5568, lr_0 = 8.4154e-04
Loss = 7.0523e-04, PNorm = 62.9100, GNorm = 0.6505, lr_0 = 8.4041e-04
Loss = 7.2730e-04, PNorm = 62.9348, GNorm = 0.2786, lr_0 = 8.3928e-04
Loss = 7.5737e-04, PNorm = 62.9804, GNorm = 0.4276, lr_0 = 8.3815e-04
Loss = 7.6459e-04, PNorm = 63.0222, GNorm = 0.3675, lr_0 = 8.3703e-04
Loss = 6.7814e-04, PNorm = 63.0659, GNorm = 0.6993, lr_0 = 8.3591e-04
Loss = 9.0186e-04, PNorm = 63.0962, GNorm = 0.4122, lr_0 = 8.3478e-04
Loss = 7.7812e-04, PNorm = 63.1311, GNorm = 0.5522, lr_0 = 8.3366e-04
Loss = 7.8934e-04, PNorm = 63.1785, GNorm = 0.6118, lr_0 = 8.3255e-04
Loss = 7.4303e-04, PNorm = 63.2102, GNorm = 0.4400, lr_0 = 8.3143e-04
Loss = 8.8679e-04, PNorm = 63.2604, GNorm = 0.2327, lr_0 = 8.3031e-04
Loss = 9.2813e-04, PNorm = 63.3070, GNorm = 0.3333, lr_0 = 8.2920e-04
Loss = 1.1211e-03, PNorm = 63.3553, GNorm = 0.7527, lr_0 = 8.2809e-04
Validation rmse logP = 0.480610
Validation R2 logP = 0.932209
Epoch 10
Train function
Loss = 8.9414e-04, PNorm = 63.4196, GNorm = 0.5285, lr_0 = 8.2698e-04
Loss = 8.2311e-04, PNorm = 63.4649, GNorm = 0.4190, lr_0 = 8.2587e-04
Loss = 7.5429e-04, PNorm = 63.5135, GNorm = 0.7084, lr_0 = 8.2476e-04
Loss = 7.6314e-04, PNorm = 63.5584, GNorm = 1.2802, lr_0 = 8.2365e-04
Loss = 7.3433e-04, PNorm = 63.5948, GNorm = 0.8455, lr_0 = 8.2255e-04
Loss = 8.0991e-04, PNorm = 63.6331, GNorm = 0.6563, lr_0 = 8.2144e-04
Loss = 1.0172e-03, PNorm = 63.6752, GNorm = 0.5905, lr_0 = 8.2034e-04
Loss = 7.2493e-04, PNorm = 63.7297, GNorm = 0.6157, lr_0 = 8.1924e-04
Loss = 6.4982e-04, PNorm = 63.7829, GNorm = 0.3934, lr_0 = 8.1814e-04
Loss = 5.9795e-04, PNorm = 63.8230, GNorm = 0.4490, lr_0 = 8.1704e-04
Loss = 6.7514e-04, PNorm = 63.8546, GNorm = 0.6243, lr_0 = 8.1595e-04
Loss = 4.7648e-04, PNorm = 63.8769, GNorm = 0.5029, lr_0 = 8.1485e-04
Loss = 8.6124e-04, PNorm = 63.9165, GNorm = 0.3351, lr_0 = 8.1376e-04
Loss = 8.2457e-04, PNorm = 63.9571, GNorm = 0.7473, lr_0 = 8.1267e-04
Loss = 6.4774e-04, PNorm = 63.9937, GNorm = 0.4207, lr_0 = 8.1158e-04
Loss = 6.8495e-04, PNorm = 64.0379, GNorm = 0.4069, lr_0 = 8.1049e-04
Loss = 7.0426e-04, PNorm = 64.0741, GNorm = 0.3013, lr_0 = 8.0940e-04
Loss = 6.8974e-04, PNorm = 64.1167, GNorm = 0.3683, lr_0 = 8.0831e-04
Validation rmse logP = 0.488984
Validation R2 logP = 0.929826
Epoch 11
Train function
Loss = 7.9283e-04, PNorm = 64.1590, GNorm = 1.0136, lr_0 = 8.0723e-04
Loss = 6.7774e-04, PNorm = 64.1940, GNorm = 0.5450, lr_0 = 8.0615e-04
Loss = 5.9824e-04, PNorm = 64.2337, GNorm = 0.7566, lr_0 = 8.0506e-04
Loss = 5.8878e-04, PNorm = 64.2715, GNorm = 0.4299, lr_0 = 8.0398e-04
Loss = 5.5829e-04, PNorm = 64.3056, GNorm = 0.1989, lr_0 = 8.0291e-04
Loss = 5.9025e-04, PNorm = 64.3462, GNorm = 0.3604, lr_0 = 8.0183e-04
Loss = 7.0699e-04, PNorm = 64.3803, GNorm = 0.2708, lr_0 = 8.0075e-04
Loss = 5.4272e-04, PNorm = 64.4116, GNorm = 0.4048, lr_0 = 7.9968e-04
Loss = 4.9509e-04, PNorm = 64.4417, GNorm = 0.5208, lr_0 = 7.9861e-04
Loss = 7.0325e-04, PNorm = 64.4693, GNorm = 0.6516, lr_0 = 7.9753e-04
Loss = 6.4032e-04, PNorm = 64.5109, GNorm = 0.3605, lr_0 = 7.9646e-04
Loss = 6.2497e-04, PNorm = 64.5439, GNorm = 0.2695, lr_0 = 7.9540e-04
Loss = 5.8780e-04, PNorm = 64.5696, GNorm = 0.6037, lr_0 = 7.9433e-04
Loss = 7.0297e-04, PNorm = 64.5980, GNorm = 1.0066, lr_0 = 7.9326e-04
Loss = 7.2340e-04, PNorm = 64.6474, GNorm = 0.4895, lr_0 = 7.9220e-04
Loss = 6.1235e-04, PNorm = 64.6858, GNorm = 0.2230, lr_0 = 7.9114e-04
Loss = 6.3191e-04, PNorm = 64.7202, GNorm = 0.3689, lr_0 = 7.9007e-04
Validation rmse logP = 0.502970
Validation R2 logP = 0.925754
Epoch 12
Train function
Loss = 7.2017e-04, PNorm = 64.7675, GNorm = 0.9434, lr_0 = 7.8891e-04
Loss = 6.2790e-04, PNorm = 64.8122, GNorm = 0.4444, lr_0 = 7.8785e-04
Loss = 5.5129e-04, PNorm = 64.8541, GNorm = 0.9292, lr_0 = 7.8679e-04
Loss = 6.2730e-04, PNorm = 64.9085, GNorm = 0.6242, lr_0 = 7.8574e-04
Loss = 6.3400e-04, PNorm = 64.9388, GNorm = 0.2927, lr_0 = 7.8468e-04
Loss = 5.1826e-04, PNorm = 64.9723, GNorm = 0.6147, lr_0 = 7.8363e-04
Loss = 5.3775e-04, PNorm = 65.0073, GNorm = 0.3599, lr_0 = 7.8258e-04
Loss = 7.2847e-04, PNorm = 65.0295, GNorm = 0.6116, lr_0 = 7.8153e-04
Loss = 7.2629e-04, PNorm = 65.0813, GNorm = 0.7573, lr_0 = 7.8048e-04
Loss = 5.6233e-04, PNorm = 65.1259, GNorm = 0.8021, lr_0 = 7.7943e-04
Loss = 5.0320e-04, PNorm = 65.1640, GNorm = 0.2012, lr_0 = 7.7839e-04
Loss = 4.9508e-04, PNorm = 65.1974, GNorm = 0.2602, lr_0 = 7.7734e-04
Loss = 6.5372e-04, PNorm = 65.2292, GNorm = 0.3473, lr_0 = 7.7630e-04
Loss = 5.7268e-04, PNorm = 65.2709, GNorm = 0.6737, lr_0 = 7.7526e-04
Loss = 6.6029e-04, PNorm = 65.3097, GNorm = 0.2817, lr_0 = 7.7422e-04
Loss = 5.0091e-04, PNorm = 65.3423, GNorm = 0.7278, lr_0 = 7.7318e-04
Loss = 5.8163e-04, PNorm = 65.3715, GNorm = 0.2941, lr_0 = 7.7214e-04
Loss = 5.2653e-04, PNorm = 65.3949, GNorm = 0.3426, lr_0 = 7.7111e-04
Validation rmse logP = 0.464198
Validation R2 logP = 0.936760
Epoch 13
Train function
Loss = 5.3596e-04, PNorm = 65.4272, GNorm = 0.4486, lr_0 = 7.7007e-04
Loss = 4.4975e-04, PNorm = 65.4575, GNorm = 0.9026, lr_0 = 7.6904e-04
Loss = 4.2221e-04, PNorm = 65.4896, GNorm = 0.5536, lr_0 = 7.6801e-04
Loss = 4.3784e-04, PNorm = 65.5117, GNorm = 0.3075, lr_0 = 7.6698e-04
Loss = 5.0766e-04, PNorm = 65.5402, GNorm = 0.4439, lr_0 = 7.6595e-04
Loss = 4.4252e-04, PNorm = 65.5720, GNorm = 0.3449, lr_0 = 7.6492e-04
Loss = 4.8315e-04, PNorm = 65.6032, GNorm = 0.2426, lr_0 = 7.6389e-04
Loss = 4.7398e-04, PNorm = 65.6406, GNorm = 0.6686, lr_0 = 7.6287e-04
Loss = 4.5109e-04, PNorm = 65.6685, GNorm = 0.7276, lr_0 = 7.6184e-04
Loss = 5.1899e-04, PNorm = 65.6969, GNorm = 0.2043, lr_0 = 7.6082e-04
Loss = 4.5378e-04, PNorm = 65.7347, GNorm = 0.4579, lr_0 = 7.5980e-04
Loss = 4.2453e-04, PNorm = 65.7616, GNorm = 0.2701, lr_0 = 7.5878e-04
Loss = 4.7557e-04, PNorm = 65.7859, GNorm = 0.4911, lr_0 = 7.5776e-04
Loss = 4.5205e-04, PNorm = 65.8034, GNorm = 0.2677, lr_0 = 7.5675e-04
Loss = 4.5428e-04, PNorm = 65.8304, GNorm = 0.3579, lr_0 = 7.5573e-04
Loss = 5.6065e-04, PNorm = 65.8596, GNorm = 0.9556, lr_0 = 7.5472e-04
Loss = 5.7508e-04, PNorm = 65.8918, GNorm = 0.2535, lr_0 = 7.5370e-04
Validation rmse logP = 0.487490
Validation R2 logP = 0.930254
Epoch 14
Train function
Loss = 4.5771e-04, PNorm = 65.9341, GNorm = 0.6476, lr_0 = 7.5259e-04
Loss = 4.8741e-04, PNorm = 65.9694, GNorm = 0.9458, lr_0 = 7.5158e-04
Loss = 4.2680e-04, PNorm = 66.0053, GNorm = 0.3293, lr_0 = 7.5057e-04
Loss = 4.3058e-04, PNorm = 66.0292, GNorm = 0.4047, lr_0 = 7.4957e-04
Loss = 5.1336e-04, PNorm = 66.0601, GNorm = 0.2366, lr_0 = 7.4856e-04
Loss = 4.5549e-04, PNorm = 66.0983, GNorm = 0.2639, lr_0 = 7.4756e-04
Loss = 5.3404e-04, PNorm = 66.1317, GNorm = 0.7130, lr_0 = 7.4655e-04
Loss = 5.1510e-04, PNorm = 66.1642, GNorm = 0.3004, lr_0 = 7.4555e-04
Loss = 5.1201e-04, PNorm = 66.2012, GNorm = 0.2427, lr_0 = 7.4455e-04
Loss = 4.2332e-04, PNorm = 66.2321, GNorm = 0.3243, lr_0 = 7.4355e-04
Loss = 4.9746e-04, PNorm = 66.2553, GNorm = 0.4351, lr_0 = 7.4256e-04
Loss = 4.4242e-04, PNorm = 66.2878, GNorm = 0.5873, lr_0 = 7.4156e-04
Loss = 4.5192e-04, PNorm = 66.3264, GNorm = 0.7307, lr_0 = 7.4056e-04
Loss = 3.9689e-04, PNorm = 66.3538, GNorm = 0.1938, lr_0 = 7.3957e-04
Loss = 4.5378e-04, PNorm = 66.3785, GNorm = 0.4655, lr_0 = 7.3858e-04
Loss = 4.5433e-04, PNorm = 66.4050, GNorm = 0.4087, lr_0 = 7.3759e-04
Loss = 4.2908e-04, PNorm = 66.4310, GNorm = 0.6748, lr_0 = 7.3660e-04
Loss = 5.9481e-04, PNorm = 66.4570, GNorm = 0.8500, lr_0 = 7.3561e-04
Validation rmse logP = 0.454321
Validation R2 logP = 0.939422
Epoch 15
Train function
Loss = 3.1535e-04, PNorm = 66.4889, GNorm = 0.2954, lr_0 = 7.3462e-04
Loss = 3.3983e-04, PNorm = 66.5231, GNorm = 0.2961, lr_0 = 7.3364e-04
Loss = 3.3158e-04, PNorm = 66.5431, GNorm = 0.3991, lr_0 = 7.3265e-04
Loss = 3.4980e-04, PNorm = 66.5736, GNorm = 0.3209, lr_0 = 7.3167e-04
Loss = 3.2374e-04, PNorm = 66.5939, GNorm = 0.3477, lr_0 = 7.3069e-04
Loss = 3.6918e-04, PNorm = 66.6165, GNorm = 0.2126, lr_0 = 7.2971e-04
Loss = 3.8082e-04, PNorm = 66.6450, GNorm = 0.5389, lr_0 = 7.2873e-04
Loss = 4.7659e-04, PNorm = 66.6685, GNorm = 0.2776, lr_0 = 7.2775e-04
Loss = 4.7056e-04, PNorm = 66.6816, GNorm = 0.4327, lr_0 = 7.2677e-04
Loss = 3.3078e-04, PNorm = 66.7022, GNorm = 0.2993, lr_0 = 7.2580e-04
Loss = 3.5851e-04, PNorm = 66.7328, GNorm = 0.3797, lr_0 = 7.2483e-04
Loss = 4.3258e-04, PNorm = 66.7645, GNorm = 0.2732, lr_0 = 7.2385e-04
Loss = 4.7372e-04, PNorm = 66.7962, GNorm = 0.4752, lr_0 = 7.2288e-04
Loss = 5.3709e-04, PNorm = 66.8172, GNorm = 0.2910, lr_0 = 7.2191e-04
Loss = 4.3776e-04, PNorm = 66.8494, GNorm = 0.3486, lr_0 = 7.2094e-04
Loss = 3.6081e-04, PNorm = 66.8850, GNorm = 0.1866, lr_0 = 7.1998e-04
Loss = 4.3256e-04, PNorm = 66.9198, GNorm = 0.4205, lr_0 = 7.1901e-04
Loss = 3.2701e-04, PNorm = 66.9436, GNorm = 0.3001, lr_0 = 7.1804e-04
Validation rmse logP = 0.465827
Validation R2 logP = 0.936315
Epoch 16
Train function
Loss = 3.1764e-04, PNorm = 66.9711, GNorm = 0.3693, lr_0 = 7.1708e-04
Loss = 3.4598e-04, PNorm = 66.9974, GNorm = 0.6149, lr_0 = 7.1612e-04
Loss = 3.2041e-04, PNorm = 67.0302, GNorm = 0.5956, lr_0 = 7.1516e-04
Loss = 4.1532e-04, PNorm = 67.0557, GNorm = 0.3630, lr_0 = 7.1420e-04
Loss = 4.0222e-04, PNorm = 67.0844, GNorm = 0.3997, lr_0 = 7.1324e-04
Loss = 3.2247e-04, PNorm = 67.1043, GNorm = 0.4115, lr_0 = 7.1228e-04
Loss = 3.3959e-04, PNorm = 67.1396, GNorm = 0.2605, lr_0 = 7.1133e-04
Loss = 3.6128e-04, PNorm = 67.1682, GNorm = 0.4123, lr_0 = 7.1037e-04
Loss = 4.6021e-04, PNorm = 67.1939, GNorm = 0.4784, lr_0 = 7.0942e-04
Loss = 4.7240e-04, PNorm = 67.2300, GNorm = 0.6329, lr_0 = 7.0847e-04
Loss = 4.0919e-04, PNorm = 67.2673, GNorm = 0.4731, lr_0 = 7.0752e-04
Loss = 3.7020e-04, PNorm = 67.2896, GNorm = 0.5156, lr_0 = 7.0657e-04
Loss = 3.9001e-04, PNorm = 67.3091, GNorm = 0.2976, lr_0 = 7.0562e-04
Loss = 3.8469e-04, PNorm = 67.3394, GNorm = 0.4540, lr_0 = 7.0467e-04
Loss = 4.3238e-04, PNorm = 67.3606, GNorm = 0.5931, lr_0 = 7.0373e-04
Loss = 3.3720e-04, PNorm = 67.3867, GNorm = 0.1742, lr_0 = 7.0278e-04
Loss = 4.4831e-04, PNorm = 67.4181, GNorm = 0.3402, lr_0 = 7.0184e-04
Validation rmse logP = 0.476031
Validation R2 logP = 0.933494
Epoch 17
Train function
Loss = 2.9818e-04, PNorm = 67.4632, GNorm = 0.3107, lr_0 = 7.0081e-04
Loss = 3.5618e-04, PNorm = 67.4923, GNorm = 0.5233, lr_0 = 6.9987e-04
Loss = 3.5230e-04, PNorm = 67.5169, GNorm = 0.5427, lr_0 = 6.9893e-04
Loss = 3.1495e-04, PNorm = 67.5421, GNorm = 0.3678, lr_0 = 6.9799e-04
Loss = 3.3586e-04, PNorm = 67.5730, GNorm = 0.1932, lr_0 = 6.9705e-04
Loss = 4.1059e-04, PNorm = 67.5997, GNorm = 0.5193, lr_0 = 6.9612e-04
Loss = 3.6635e-04, PNorm = 67.6234, GNorm = 0.4912, lr_0 = 6.9518e-04
Loss = 5.3957e-04, PNorm = 67.6593, GNorm = 0.2923, lr_0 = 6.9425e-04
Loss = 3.8252e-04, PNorm = 67.6987, GNorm = 0.2993, lr_0 = 6.9332e-04
Loss = 3.4491e-04, PNorm = 67.7304, GNorm = 0.2884, lr_0 = 6.9239e-04
Loss = 3.1220e-04, PNorm = 67.7643, GNorm = 0.3974, lr_0 = 6.9146e-04
Loss = 3.1455e-04, PNorm = 67.7894, GNorm = 0.4508, lr_0 = 6.9053e-04
Loss = 3.9700e-04, PNorm = 67.7968, GNorm = 0.2104, lr_0 = 6.8961e-04
Loss = 4.0055e-04, PNorm = 67.8274, GNorm = 0.5867, lr_0 = 6.8868e-04
Loss = 3.6674e-04, PNorm = 67.8577, GNorm = 0.4273, lr_0 = 6.8776e-04
Loss = 3.8559e-04, PNorm = 67.8850, GNorm = 0.4965, lr_0 = 6.8683e-04
Loss = 4.6670e-04, PNorm = 67.9240, GNorm = 0.4497, lr_0 = 6.8591e-04
Loss = 4.1014e-04, PNorm = 67.9619, GNorm = 0.3358, lr_0 = 6.8499e-04
Validation rmse logP = 0.470932
Validation R2 logP = 0.934912
Epoch 18
Train function
Loss = 3.1312e-04, PNorm = 67.9780, GNorm = 0.1742, lr_0 = 6.8407e-04
Loss = 3.0871e-04, PNorm = 68.0000, GNorm = 0.2473, lr_0 = 6.8315e-04
Loss = 4.0020e-04, PNorm = 68.0252, GNorm = 0.3518, lr_0 = 6.8224e-04
Loss = 3.2614e-04, PNorm = 68.0486, GNorm = 0.2638, lr_0 = 6.8132e-04
Loss = 3.2499e-04, PNorm = 68.0823, GNorm = 0.3334, lr_0 = 6.8041e-04
Loss = 3.1437e-04, PNorm = 68.1115, GNorm = 0.5709, lr_0 = 6.7950e-04
Loss = 3.0029e-04, PNorm = 68.1305, GNorm = 0.2814, lr_0 = 6.7858e-04
Loss = 2.5902e-04, PNorm = 68.1503, GNorm = 0.2360, lr_0 = 6.7767e-04
Loss = 3.6991e-04, PNorm = 68.1787, GNorm = 0.3325, lr_0 = 6.7676e-04
Loss = 4.8230e-04, PNorm = 68.2067, GNorm = 0.8604, lr_0 = 6.7586e-04
Loss = 3.7455e-04, PNorm = 68.2478, GNorm = 0.4630, lr_0 = 6.7495e-04
Loss = 4.0765e-04, PNorm = 68.2671, GNorm = 0.5880, lr_0 = 6.7404e-04
Loss = 4.5686e-04, PNorm = 68.3033, GNorm = 0.3827, lr_0 = 6.7314e-04
Loss = 3.9076e-04, PNorm = 68.3374, GNorm = 0.3036, lr_0 = 6.7224e-04
Loss = 4.2426e-04, PNorm = 68.3827, GNorm = 0.4762, lr_0 = 6.7133e-04
Loss = 3.6209e-04, PNorm = 68.4164, GNorm = 0.2866, lr_0 = 6.7043e-04
Loss = 3.3435e-04, PNorm = 68.4427, GNorm = 0.2191, lr_0 = 6.6953e-04
Validation rmse logP = 0.478432
Validation R2 logP = 0.932822
Epoch 19
Train function
Loss = 3.7731e-04, PNorm = 68.4625, GNorm = 0.2992, lr_0 = 6.6864e-04
Loss = 2.8373e-04, PNorm = 68.4983, GNorm = 0.3817, lr_0 = 6.6774e-04
Loss = 3.3421e-04, PNorm = 68.5162, GNorm = 0.5646, lr_0 = 6.6684e-04
Loss = 2.9003e-04, PNorm = 68.5512, GNorm = 0.1735, lr_0 = 6.6595e-04
Loss = 2.4780e-04, PNorm = 68.5783, GNorm = 0.4127, lr_0 = 6.6505e-04
Loss = 3.8231e-04, PNorm = 68.6018, GNorm = 0.5683, lr_0 = 6.6416e-04
Loss = 3.1850e-04, PNorm = 68.6290, GNorm = 0.8089, lr_0 = 6.6327e-04
Loss = 2.5948e-04, PNorm = 68.6466, GNorm = 0.4208, lr_0 = 6.6238e-04
Loss = 2.7376e-04, PNorm = 68.6748, GNorm = 0.3313, lr_0 = 6.6149e-04
Loss = 3.5500e-04, PNorm = 68.7000, GNorm = 0.1907, lr_0 = 6.6060e-04
Loss = 2.8604e-04, PNorm = 68.7210, GNorm = 0.5237, lr_0 = 6.5972e-04
Loss = 2.8378e-04, PNorm = 68.7377, GNorm = 0.1960, lr_0 = 6.5883e-04
Loss = 2.6685e-04, PNorm = 68.7501, GNorm = 0.1610, lr_0 = 6.5795e-04
Loss = 2.5147e-04, PNorm = 68.7681, GNorm = 0.2383, lr_0 = 6.5707e-04
Loss = 2.8514e-04, PNorm = 68.7937, GNorm = 0.4464, lr_0 = 6.5618e-04
Loss = 2.5520e-04, PNorm = 68.8181, GNorm = 0.3183, lr_0 = 6.5530e-04
Loss = 3.9315e-04, PNorm = 68.8467, GNorm = 0.2121, lr_0 = 6.5443e-04
Loss = 3.5475e-04, PNorm = 68.8684, GNorm = 0.6430, lr_0 = 6.5355e-04
Validation rmse logP = 0.460818
Validation R2 logP = 0.937677
Epoch 20
Train function
Loss = 3.3269e-04, PNorm = 68.8975, GNorm = 0.4700, lr_0 = 6.5258e-04
Loss = 2.9876e-04, PNorm = 68.9120, GNorm = 0.3107, lr_0 = 6.5171e-04
Loss = 2.9230e-04, PNorm = 68.9374, GNorm = 0.5781, lr_0 = 6.5083e-04
Loss = 2.9636e-04, PNorm = 68.9607, GNorm = 0.5661, lr_0 = 6.4996e-04
Loss = 3.7351e-04, PNorm = 68.9841, GNorm = 0.5712, lr_0 = 6.4909e-04
Loss = 2.9313e-04, PNorm = 69.0196, GNorm = 0.3518, lr_0 = 6.4822e-04
Loss = 2.6055e-04, PNorm = 69.0462, GNorm = 0.2415, lr_0 = 6.4735e-04
Loss = 2.6969e-04, PNorm = 69.0669, GNorm = 0.3699, lr_0 = 6.4648e-04
Loss = 3.1681e-04, PNorm = 69.0850, GNorm = 0.2148, lr_0 = 6.4561e-04
Loss = 3.2558e-04, PNorm = 69.1145, GNorm = 0.3762, lr_0 = 6.4474e-04
Loss = 2.7500e-04, PNorm = 69.1467, GNorm = 0.1654, lr_0 = 6.4388e-04
Loss = 3.2025e-04, PNorm = 69.1653, GNorm = 0.3190, lr_0 = 6.4302e-04
Loss = 3.2431e-04, PNorm = 69.1910, GNorm = 0.4039, lr_0 = 6.4215e-04
Loss = 3.8962e-04, PNorm = 69.2226, GNorm = 0.3389, lr_0 = 6.4129e-04
Loss = 2.6745e-04, PNorm = 69.2421, GNorm = 0.2051, lr_0 = 6.4043e-04
Loss = 2.8810e-04, PNorm = 69.2777, GNorm = 0.6060, lr_0 = 6.3957e-04
Loss = 3.5866e-04, PNorm = 69.3014, GNorm = 0.9753, lr_0 = 6.3871e-04
Validation rmse logP = 0.453681
Validation R2 logP = 0.939593
Epoch 21
Train function
Loss = 1.8018e-04, PNorm = 69.3262, GNorm = 0.1767, lr_0 = 6.3786e-04
Loss = 2.2367e-04, PNorm = 69.3482, GNorm = 0.4061, lr_0 = 6.3700e-04
Loss = 2.4544e-04, PNorm = 69.3638, GNorm = 0.3598, lr_0 = 6.3615e-04
Loss = 1.8913e-04, PNorm = 69.3808, GNorm = 0.1905, lr_0 = 6.3529e-04
Loss = 2.0025e-04, PNorm = 69.3960, GNorm = 0.1798, lr_0 = 6.3444e-04
Loss = 2.1596e-04, PNorm = 69.4142, GNorm = 0.2765, lr_0 = 6.3359e-04
Loss = 2.7759e-04, PNorm = 69.4339, GNorm = 0.4806, lr_0 = 6.3274e-04
Loss = 2.5775e-04, PNorm = 69.4587, GNorm = 0.2777, lr_0 = 6.3189e-04
Loss = 3.0168e-04, PNorm = 69.4822, GNorm = 0.3731, lr_0 = 6.3104e-04
Loss = 3.4858e-04, PNorm = 69.5051, GNorm = 0.2981, lr_0 = 6.3020e-04
Loss = 3.5577e-04, PNorm = 69.5309, GNorm = 0.2684, lr_0 = 6.2935e-04
Loss = 2.2044e-04, PNorm = 69.5515, GNorm = 0.3551, lr_0 = 6.2851e-04
Loss = 2.4530e-04, PNorm = 69.5686, GNorm = 0.2409, lr_0 = 6.2766e-04
Loss = 2.3225e-04, PNorm = 69.5896, GNorm = 0.1970, lr_0 = 6.2682e-04
Loss = 3.1848e-04, PNorm = 69.6064, GNorm = 0.6276, lr_0 = 6.2598e-04
Loss = 3.0848e-04, PNorm = 69.6345, GNorm = 0.3075, lr_0 = 6.2514e-04
Loss = 2.4741e-04, PNorm = 69.6611, GNorm = 0.3763, lr_0 = 6.2430e-04
Loss = 2.9032e-04, PNorm = 69.6910, GNorm = 0.2691, lr_0 = 6.2346e-04
Validation rmse logP = 0.478075
Validation R2 logP = 0.932922
Epoch 22
Train function
Loss = 2.5218e-04, PNorm = 69.7183, GNorm = 0.1628, lr_0 = 6.2263e-04
Loss = 2.1430e-04, PNorm = 69.7414, GNorm = 0.2799, lr_0 = 6.2179e-04
Loss = 1.9091e-04, PNorm = 69.7538, GNorm = 0.1961, lr_0 = 6.2096e-04
Loss = 2.6628e-04, PNorm = 69.7746, GNorm = 0.6089, lr_0 = 6.2012e-04
Loss = 2.6566e-04, PNorm = 69.7937, GNorm = 0.2186, lr_0 = 6.1929e-04
Loss = 2.1936e-04, PNorm = 69.8043, GNorm = 0.1595, lr_0 = 6.1846e-04
Loss = 2.3640e-04, PNorm = 69.8221, GNorm = 0.3200, lr_0 = 6.1763e-04
Loss = 2.5917e-04, PNorm = 69.8410, GNorm = 0.2445, lr_0 = 6.1680e-04
Loss = 2.4341e-04, PNorm = 69.8557, GNorm = 0.5710, lr_0 = 6.1597e-04
Loss = 2.4252e-04, PNorm = 69.8829, GNorm = 0.2743, lr_0 = 6.1515e-04
Loss = 2.5870e-04, PNorm = 69.9069, GNorm = 0.2376, lr_0 = 6.1432e-04
Loss = 1.8420e-04, PNorm = 69.9234, GNorm = 0.1375, lr_0 = 6.1350e-04
Loss = 1.8696e-04, PNorm = 69.9363, GNorm = 0.3431, lr_0 = 6.1268e-04
Loss = 2.2549e-04, PNorm = 69.9519, GNorm = 0.5168, lr_0 = 6.1185e-04
Loss = 2.2913e-04, PNorm = 69.9716, GNorm = 0.1373, lr_0 = 6.1103e-04
Loss = 2.4282e-04, PNorm = 69.9901, GNorm = 0.3630, lr_0 = 6.1021e-04
Loss = 2.1747e-04, PNorm = 70.0128, GNorm = 0.2612, lr_0 = 6.0939e-04
Validation rmse logP = 0.454833
Validation R2 logP = 0.939286
Epoch 23
Train function
Loss = 1.6741e-04, PNorm = 70.0380, GNorm = 0.1827, lr_0 = 6.0849e-04
Loss = 2.6898e-04, PNorm = 70.0575, GNorm = 0.2836, lr_0 = 6.0768e-04
Loss = 2.5818e-04, PNorm = 70.0780, GNorm = 0.8019, lr_0 = 6.0686e-04
Loss = 2.2013e-04, PNorm = 70.0941, GNorm = 0.4861, lr_0 = 6.0605e-04
Loss = 1.7760e-04, PNorm = 70.1126, GNorm = 0.2760, lr_0 = 6.0524e-04
Loss = 1.7817e-04, PNorm = 70.1332, GNorm = 0.1845, lr_0 = 6.0442e-04
Loss = 1.9027e-04, PNorm = 70.1538, GNorm = 0.1689, lr_0 = 6.0361e-04
Loss = 2.3469e-04, PNorm = 70.1727, GNorm = 0.2443, lr_0 = 6.0280e-04
Loss = 2.0406e-04, PNorm = 70.1946, GNorm = 0.1621, lr_0 = 6.0199e-04
Loss = 1.6895e-04, PNorm = 70.2192, GNorm = 0.2585, lr_0 = 6.0119e-04
Loss = 1.9772e-04, PNorm = 70.2295, GNorm = 0.1567, lr_0 = 6.0038e-04
Loss = 2.1304e-04, PNorm = 70.2434, GNorm = 0.3621, lr_0 = 5.9957e-04
Loss = 2.1617e-04, PNorm = 70.2599, GNorm = 0.2851, lr_0 = 5.9877e-04
Loss = 1.7729e-04, PNorm = 70.2762, GNorm = 0.1867, lr_0 = 5.9797e-04
Loss = 1.9823e-04, PNorm = 70.2961, GNorm = 0.4337, lr_0 = 5.9716e-04
Loss = 3.7060e-04, PNorm = 70.3200, GNorm = 0.2441, lr_0 = 5.9636e-04
Loss = 2.2445e-04, PNorm = 70.3457, GNorm = 0.3079, lr_0 = 5.9556e-04
Loss = 2.6627e-04, PNorm = 70.3730, GNorm = 0.6322, lr_0 = 5.9476e-04
Validation rmse logP = 0.456794
Validation R2 logP = 0.938761
Epoch 24
Train function
Loss = 1.7866e-04, PNorm = 70.3889, GNorm = 0.1541, lr_0 = 5.9397e-04
Loss = 1.7052e-04, PNorm = 70.4041, GNorm = 0.2370, lr_0 = 5.9317e-04
Loss = 1.8918e-04, PNorm = 70.4135, GNorm = 0.2583, lr_0 = 5.9237e-04
Loss = 2.2952e-04, PNorm = 70.4320, GNorm = 0.1631, lr_0 = 5.9158e-04
Loss = 1.9489e-04, PNorm = 70.4573, GNorm = 0.2398, lr_0 = 5.9078e-04
Loss = 1.7595e-04, PNorm = 70.4778, GNorm = 0.1598, lr_0 = 5.8999e-04
Loss = 1.6318e-04, PNorm = 70.4975, GNorm = 0.1829, lr_0 = 5.8920e-04
Loss = 1.7095e-04, PNorm = 70.5081, GNorm = 0.3281, lr_0 = 5.8841e-04
Loss = 2.5202e-04, PNorm = 70.5281, GNorm = 0.3012, lr_0 = 5.8762e-04
Loss = 2.3924e-04, PNorm = 70.5427, GNorm = 0.2343, lr_0 = 5.8683e-04
Loss = 1.8919e-04, PNorm = 70.5571, GNorm = 0.3170, lr_0 = 5.8604e-04
Loss = 2.1617e-04, PNorm = 70.5760, GNorm = 0.4207, lr_0 = 5.8526e-04
Loss = 1.9193e-04, PNorm = 70.5906, GNorm = 0.1782, lr_0 = 5.8447e-04
Loss = 2.4686e-04, PNorm = 70.6132, GNorm = 0.1767, lr_0 = 5.8369e-04
Loss = 1.7542e-04, PNorm = 70.6356, GNorm = 0.2314, lr_0 = 5.8290e-04
Loss = 2.1555e-04, PNorm = 70.6554, GNorm = 0.3645, lr_0 = 5.8212e-04
Loss = 1.9148e-04, PNorm = 70.6780, GNorm = 0.3465, lr_0 = 5.8134e-04
Loss = 2.2500e-04, PNorm = 70.6815, GNorm = 0.3872, lr_0 = 5.8056e-04
Validation rmse logP = 0.456930
Validation R2 logP = 0.938725
Epoch 25
Train function
Loss = 1.9260e-04, PNorm = 70.7046, GNorm = 0.2544, lr_0 = 5.7978e-04
Loss = 1.9206e-04, PNorm = 70.7219, GNorm = 0.1618, lr_0 = 5.7900e-04
Loss = 1.8907e-04, PNorm = 70.7465, GNorm = 0.3221, lr_0 = 5.7823e-04
Loss = 1.9969e-04, PNorm = 70.7654, GNorm = 0.3446, lr_0 = 5.7745e-04
Loss = 1.7049e-04, PNorm = 70.7845, GNorm = 0.2490, lr_0 = 5.7668e-04
Loss = 1.7590e-04, PNorm = 70.8029, GNorm = 0.1220, lr_0 = 5.7590e-04
Loss = 1.8233e-04, PNorm = 70.8174, GNorm = 0.3165, lr_0 = 5.7513e-04
Loss = 1.5733e-04, PNorm = 70.8318, GNorm = 0.4413, lr_0 = 5.7436e-04
Loss = 2.0233e-04, PNorm = 70.8490, GNorm = 0.1635, lr_0 = 5.7359e-04
Loss = 2.1247e-04, PNorm = 70.8677, GNorm = 0.1673, lr_0 = 5.7282e-04
Loss = 1.8067e-04, PNorm = 70.8876, GNorm = 0.3314, lr_0 = 5.7205e-04
Loss = 1.9575e-04, PNorm = 70.8994, GNorm = 0.4567, lr_0 = 5.7128e-04
Loss = 3.0214e-04, PNorm = 70.9187, GNorm = 0.7474, lr_0 = 5.7052e-04
Loss = 2.2248e-04, PNorm = 70.9450, GNorm = 0.5743, lr_0 = 5.6975e-04
Loss = 2.5559e-04, PNorm = 70.9742, GNorm = 0.1614, lr_0 = 5.6899e-04
Loss = 2.4183e-04, PNorm = 70.9962, GNorm = 0.1308, lr_0 = 5.6822e-04
Loss = 2.5812e-04, PNorm = 71.0205, GNorm = 0.4755, lr_0 = 5.6746e-04
Validation rmse logP = 0.464875
Validation R2 logP = 0.936575
Epoch 26
Train function
Loss = 2.3183e-04, PNorm = 71.0431, GNorm = 0.3094, lr_0 = 5.6662e-04
Loss = 1.7006e-04, PNorm = 71.0651, GNorm = 0.1726, lr_0 = 5.6586e-04
Loss = 2.0745e-04, PNorm = 71.0886, GNorm = 0.4588, lr_0 = 5.6510e-04
Loss = 2.2216e-04, PNorm = 71.1110, GNorm = 0.2453, lr_0 = 5.6435e-04
Loss = 1.9769e-04, PNorm = 71.1332, GNorm = 0.3687, lr_0 = 5.6359e-04
Loss = 1.7410e-04, PNorm = 71.1515, GNorm = 0.4842, lr_0 = 5.6283e-04
Loss = 1.5514e-04, PNorm = 71.1652, GNorm = 0.2078, lr_0 = 5.6208e-04
Loss = 2.3827e-04, PNorm = 71.1705, GNorm = 0.3988, lr_0 = 5.6132e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_301/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=125, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,500,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.2465e-02, PNorm = 55.2162, GNorm = 12.7118, lr_0 = 1.9340e-04
Loss = 1.8378e-02, PNorm = 55.2230, GNorm = 6.4693, lr_0 = 2.7830e-04
Loss = 1.7782e-02, PNorm = 55.2387, GNorm = 1.9655, lr_0 = 3.6321e-04
Loss = 1.6174e-02, PNorm = 55.2648, GNorm = 3.9339, lr_0 = 4.4811e-04
Loss = 1.5217e-02, PNorm = 55.2973, GNorm = 5.5043, lr_0 = 5.3302e-04
Validation rmse logD = 0.973717
Validation R2 logD = 0.268836
Epoch 1
Train function
Loss = 1.3893e-02, PNorm = 55.3493, GNorm = 3.1547, lr_0 = 6.2642e-04
Loss = 1.4540e-02, PNorm = 55.4181, GNorm = 0.8063, lr_0 = 7.1132e-04
Loss = 1.2858e-02, PNorm = 55.5049, GNorm = 4.8507, lr_0 = 7.9623e-04
Loss = 1.2098e-02, PNorm = 55.5931, GNorm = 1.1924, lr_0 = 8.8113e-04
Loss = 1.4512e-02, PNorm = 55.7061, GNorm = 2.3054, lr_0 = 9.6604e-04
Validation rmse logD = 1.107535
Validation R2 logD = 0.054059
Epoch 2
Train function
Loss = 1.6661e-02, PNorm = 55.8455, GNorm = 0.9334, lr_0 = 9.9690e-04
Loss = 1.3152e-02, PNorm = 55.9714, GNorm = 0.8775, lr_0 = 9.9249e-04
Loss = 1.1531e-02, PNorm = 56.0915, GNorm = 2.5403, lr_0 = 9.8810e-04
Loss = 1.0704e-02, PNorm = 56.1984, GNorm = 1.9527, lr_0 = 9.8373e-04
Loss = 1.1749e-02, PNorm = 56.3180, GNorm = 3.3615, lr_0 = 9.7938e-04
Validation rmse logD = 0.831160
Validation R2 logD = 0.467257
Epoch 3
Train function
Loss = 5.7708e-03, PNorm = 56.4547, GNorm = 1.0670, lr_0 = 9.7462e-04
Loss = 8.2412e-03, PNorm = 56.5176, GNorm = 2.7022, lr_0 = 9.7030e-04
Loss = 9.5067e-03, PNorm = 56.5851, GNorm = 1.5471, lr_0 = 9.6601e-04
Loss = 1.0060e-02, PNorm = 56.6605, GNorm = 3.1934, lr_0 = 9.6174e-04
Loss = 1.0635e-02, PNorm = 56.7510, GNorm = 2.7977, lr_0 = 9.5749e-04
Loss = 1.0129e-02, PNorm = 56.8580, GNorm = 1.0031, lr_0 = 9.5325e-04
Validation rmse logD = 0.929374
Validation R2 logD = 0.333914
Epoch 4
Train function
Loss = 9.3912e-03, PNorm = 56.9349, GNorm = 1.9636, lr_0 = 9.4861e-04
Loss = 8.4371e-03, PNorm = 57.0548, GNorm = 2.1210, lr_0 = 9.4442e-04
Loss = 8.2466e-03, PNorm = 57.1515, GNorm = 3.1647, lr_0 = 9.4024e-04
Loss = 8.5150e-03, PNorm = 57.2506, GNorm = 2.8995, lr_0 = 9.3608e-04
Loss = 9.2255e-03, PNorm = 57.3615, GNorm = 2.9116, lr_0 = 9.3194e-04
Validation rmse logD = 0.757813
Validation R2 logD = 0.557133
Epoch 5
Train function
Loss = 6.8721e-03, PNorm = 57.4902, GNorm = 2.3550, lr_0 = 9.2741e-04
Loss = 6.7995e-03, PNorm = 57.6080, GNorm = 2.2218, lr_0 = 9.2330e-04
Loss = 7.0663e-03, PNorm = 57.7169, GNorm = 0.9440, lr_0 = 9.1922e-04
Loss = 7.6020e-03, PNorm = 57.8289, GNorm = 3.2632, lr_0 = 9.1515e-04
Loss = 6.9294e-03, PNorm = 57.9278, GNorm = 1.0383, lr_0 = 9.1111e-04
Validation rmse logD = 0.732623
Validation R2 logD = 0.586086
Epoch 6
Train function
Loss = 4.8579e-03, PNorm = 58.0411, GNorm = 0.7718, lr_0 = 9.0667e-04
Loss = 6.1372e-03, PNorm = 58.1397, GNorm = 3.8977, lr_0 = 9.0266e-04
Loss = 6.7653e-03, PNorm = 58.2646, GNorm = 1.2237, lr_0 = 8.9867e-04
Loss = 6.1141e-03, PNorm = 58.3746, GNorm = 1.1510, lr_0 = 8.9469e-04
Loss = 6.1803e-03, PNorm = 58.4838, GNorm = 4.1772, lr_0 = 8.9074e-04
Loss = 5.7943e-03, PNorm = 58.5927, GNorm = 1.1654, lr_0 = 8.8680e-04
Validation rmse logD = 0.714387
Validation R2 logD = 0.606435
Epoch 7
Train function
Loss = 5.2258e-03, PNorm = 58.6851, GNorm = 0.9688, lr_0 = 8.8248e-04
Loss = 4.9461e-03, PNorm = 58.7927, GNorm = 0.6228, lr_0 = 8.7858e-04
Loss = 5.4949e-03, PNorm = 58.8999, GNorm = 2.7055, lr_0 = 8.7469e-04
Loss = 5.9610e-03, PNorm = 58.9947, GNorm = 2.8222, lr_0 = 8.7082e-04
Loss = 7.3173e-03, PNorm = 59.1007, GNorm = 2.6679, lr_0 = 8.6697e-04
Validation rmse logD = 0.762819
Validation R2 logD = 0.551262
Epoch 8
Train function
Loss = 5.6552e-03, PNorm = 59.2478, GNorm = 2.5161, lr_0 = 8.6276e-04
Loss = 4.7129e-03, PNorm = 59.3495, GNorm = 1.5003, lr_0 = 8.5894e-04
Loss = 4.7325e-03, PNorm = 59.4475, GNorm = 1.8475, lr_0 = 8.5514e-04
Loss = 4.9070e-03, PNorm = 59.5309, GNorm = 1.0833, lr_0 = 8.5136e-04
Loss = 4.5390e-03, PNorm = 59.6228, GNorm = 3.3758, lr_0 = 8.4759e-04
Validation rmse logD = 0.794817
Validation R2 logD = 0.512827
Epoch 9
Train function
Loss = 5.6092e-03, PNorm = 59.7212, GNorm = 1.1475, lr_0 = 8.4347e-04
Loss = 4.9850e-03, PNorm = 59.8280, GNorm = 0.7492, lr_0 = 8.3974e-04
Loss = 4.5052e-03, PNorm = 59.9342, GNorm = 0.7224, lr_0 = 8.3602e-04
Loss = 3.8678e-03, PNorm = 60.0287, GNorm = 1.6435, lr_0 = 8.3232e-04
Loss = 4.9348e-03, PNorm = 60.1303, GNorm = 1.2991, lr_0 = 8.2864e-04
Loss = 3.9097e-03, PNorm = 60.1865, GNorm = 1.2038, lr_0 = 8.2498e-04
Validation rmse logD = 0.663895
Validation R2 logD = 0.660102
Epoch 10
Train function
Loss = 3.6747e-03, PNorm = 60.2643, GNorm = 0.5982, lr_0 = 8.2133e-04
Loss = 4.0828e-03, PNorm = 60.3583, GNorm = 1.2353, lr_0 = 8.1770e-04
Loss = 4.2696e-03, PNorm = 60.4563, GNorm = 1.7850, lr_0 = 8.1408e-04
Loss = 3.4134e-03, PNorm = 60.5476, GNorm = 2.9653, lr_0 = 8.1048e-04
Loss = 3.7724e-03, PNorm = 60.6145, GNorm = 2.9374, lr_0 = 8.0689e-04
Validation rmse logD = 0.645469
Validation R2 logD = 0.678708
Epoch 11
Train function
Loss = 3.3062e-03, PNorm = 60.6725, GNorm = 1.4676, lr_0 = 8.0297e-04
Loss = 3.0215e-03, PNorm = 60.7461, GNorm = 1.0592, lr_0 = 7.9942e-04
Loss = 3.2417e-03, PNorm = 60.8047, GNorm = 1.8471, lr_0 = 7.9588e-04
Loss = 3.2351e-03, PNorm = 60.8717, GNorm = 1.0221, lr_0 = 7.9236e-04
Loss = 3.9804e-03, PNorm = 60.9606, GNorm = 3.0313, lr_0 = 7.8885e-04
Validation rmse logD = 0.650468
Validation R2 logD = 0.673712
Epoch 12
Train function
Loss = 4.0145e-03, PNorm = 61.0402, GNorm = 1.6181, lr_0 = 7.8502e-04
Loss = 2.6135e-03, PNorm = 61.1232, GNorm = 1.0118, lr_0 = 7.8154e-04
Loss = 2.8192e-03, PNorm = 61.1780, GNorm = 1.0228, lr_0 = 7.7809e-04
Loss = 2.7748e-03, PNorm = 61.2434, GNorm = 1.3230, lr_0 = 7.7465e-04
Loss = 2.4045e-03, PNorm = 61.3028, GNorm = 1.5077, lr_0 = 7.7122e-04
Loss = 2.6476e-03, PNorm = 61.3533, GNorm = 1.3016, lr_0 = 7.6781e-04
Loss = 8.3805e-03, PNorm = 61.3599, GNorm = 2.0637, lr_0 = 7.6747e-04
Validation rmse logD = 0.636214
Validation R2 logD = 0.687855
Epoch 13
Train function
Loss = 2.5195e-03, PNorm = 61.4183, GNorm = 0.7733, lr_0 = 7.6407e-04
Loss = 2.5801e-03, PNorm = 61.5041, GNorm = 1.1328, lr_0 = 7.6069e-04
Loss = 2.6180e-03, PNorm = 61.5680, GNorm = 1.3892, lr_0 = 7.5733e-04
Loss = 2.2811e-03, PNorm = 61.6148, GNorm = 0.7695, lr_0 = 7.5398e-04
Loss = 1.9926e-03, PNorm = 61.6923, GNorm = 0.6851, lr_0 = 7.5064e-04
Validation rmse logD = 0.678899
Validation R2 logD = 0.644565
Epoch 14
Train function
Loss = 3.6240e-03, PNorm = 61.7860, GNorm = 3.2040, lr_0 = 7.4699e-04
Loss = 2.5627e-03, PNorm = 61.9000, GNorm = 0.9495, lr_0 = 7.4369e-04
Loss = 2.5608e-03, PNorm = 61.9876, GNorm = 1.5547, lr_0 = 7.4040e-04
Loss = 2.9260e-03, PNorm = 62.0581, GNorm = 2.7514, lr_0 = 7.3712e-04
Loss = 2.3322e-03, PNorm = 62.1168, GNorm = 0.9665, lr_0 = 7.3386e-04
Validation rmse logD = 0.624545
Validation R2 logD = 0.699201
Epoch 15
Train function
Loss = 1.8631e-03, PNorm = 62.1868, GNorm = 0.4897, lr_0 = 7.3029e-04
Loss = 2.2906e-03, PNorm = 62.2627, GNorm = 1.5244, lr_0 = 7.2706e-04
Loss = 2.3800e-03, PNorm = 62.3392, GNorm = 1.2845, lr_0 = 7.2385e-04
Loss = 2.4393e-03, PNorm = 62.4015, GNorm = 1.9811, lr_0 = 7.2064e-04
Loss = 1.9876e-03, PNorm = 62.4508, GNorm = 1.9067, lr_0 = 7.1746e-04
Validation rmse logD = 0.647846
Validation R2 logD = 0.676337
Epoch 16
Train function
Loss = 2.3224e-03, PNorm = 62.5046, GNorm = 1.6606, lr_0 = 7.1397e-04
Loss = 1.7047e-03, PNorm = 62.5640, GNorm = 0.7805, lr_0 = 7.1081e-04
Loss = 1.5397e-03, PNorm = 62.6144, GNorm = 0.8267, lr_0 = 7.0766e-04
Loss = 1.8263e-03, PNorm = 62.6611, GNorm = 1.4156, lr_0 = 7.0453e-04
Loss = 1.6371e-03, PNorm = 62.6984, GNorm = 0.9549, lr_0 = 7.0142e-04
Loss = 2.0749e-03, PNorm = 62.7419, GNorm = 3.0817, lr_0 = 6.9831e-04
Validation rmse logD = 0.637025
Validation R2 logD = 0.687060
Epoch 17
Train function
Loss = 1.7275e-03, PNorm = 62.7959, GNorm = 1.2672, lr_0 = 6.9492e-04
Loss = 1.6325e-03, PNorm = 62.8514, GNorm = 0.7364, lr_0 = 6.9184e-04
Loss = 1.5323e-03, PNorm = 62.9047, GNorm = 0.9865, lr_0 = 6.8878e-04
Loss = 1.4624e-03, PNorm = 62.9457, GNorm = 0.5324, lr_0 = 6.8574e-04
Loss = 1.6084e-03, PNorm = 62.9816, GNorm = 0.6011, lr_0 = 6.8270e-04
Validation rmse logD = 0.622647
Validation R2 logD = 0.701026
Epoch 18
Train function
Loss = 1.1719e-03, PNorm = 63.0269, GNorm = 1.4382, lr_0 = 6.7938e-04
Loss = 1.4634e-03, PNorm = 63.0815, GNorm = 0.6608, lr_0 = 6.7638e-04
Loss = 1.4484e-03, PNorm = 63.1220, GNorm = 0.6725, lr_0 = 6.7338e-04
Loss = 1.3823e-03, PNorm = 63.1653, GNorm = 1.1333, lr_0 = 6.7041e-04
Loss = 1.5286e-03, PNorm = 63.2056, GNorm = 0.6061, lr_0 = 6.6744e-04
Validation rmse logD = 0.681099
Validation R2 logD = 0.642258
Epoch 19
Train function
Loss = 2.0783e-03, PNorm = 63.2553, GNorm = 1.6494, lr_0 = 6.6419e-04
Loss = 1.6671e-03, PNorm = 63.3109, GNorm = 1.4408, lr_0 = 6.6126e-04
Loss = 1.6529e-03, PNorm = 63.3691, GNorm = 0.9236, lr_0 = 6.5833e-04
Loss = 1.5461e-03, PNorm = 63.4081, GNorm = 1.4308, lr_0 = 6.5542e-04
Loss = 1.2433e-03, PNorm = 63.4600, GNorm = 1.0639, lr_0 = 6.5252e-04
Loss = 1.2058e-03, PNorm = 63.5054, GNorm = 1.3574, lr_0 = 6.4963e-04
Validation rmse logD = 0.664657
Validation R2 logD = 0.659321
Epoch 20
Train function
Loss = 1.5576e-03, PNorm = 63.5588, GNorm = 1.8378, lr_0 = 6.4676e-04
Loss = 1.2353e-03, PNorm = 63.6040, GNorm = 0.7884, lr_0 = 6.4390e-04
Loss = 1.0751e-03, PNorm = 63.6469, GNorm = 0.7381, lr_0 = 6.4105e-04
Loss = 1.2144e-03, PNorm = 63.6803, GNorm = 0.8523, lr_0 = 6.3822e-04
Loss = 1.3345e-03, PNorm = 63.7167, GNorm = 1.1199, lr_0 = 6.3539e-04
Validation rmse logD = 0.595994
Validation R2 logD = 0.726074
Epoch 21
Train function
Loss = 7.9600e-04, PNorm = 63.7578, GNorm = 0.7087, lr_0 = 6.3230e-04
Loss = 9.2680e-04, PNorm = 63.7922, GNorm = 1.5409, lr_0 = 6.2950e-04
Loss = 8.5749e-04, PNorm = 63.8226, GNorm = 0.3538, lr_0 = 6.2672e-04
Loss = 9.3044e-04, PNorm = 63.8492, GNorm = 0.4889, lr_0 = 6.2395e-04
Loss = 1.0104e-03, PNorm = 63.8826, GNorm = 0.6717, lr_0 = 6.2119e-04
Validation rmse logD = 0.592220
Validation R2 logD = 0.729532
Epoch 22
Train function
Loss = 8.6623e-04, PNorm = 63.9036, GNorm = 0.6771, lr_0 = 6.1817e-04
Loss = 1.1432e-03, PNorm = 63.9405, GNorm = 3.5578, lr_0 = 6.1543e-04
Loss = 1.3720e-03, PNorm = 63.9793, GNorm = 2.9003, lr_0 = 6.1271e-04
Loss = 1.1516e-03, PNorm = 64.0310, GNorm = 0.8273, lr_0 = 6.1000e-04
Loss = 9.4175e-04, PNorm = 64.0711, GNorm = 0.7501, lr_0 = 6.0730e-04
Loss = 8.4828e-04, PNorm = 64.1025, GNorm = 0.6900, lr_0 = 6.0461e-04
Validation rmse logD = 0.605051
Validation R2 logD = 0.717685
Epoch 23
Train function
Loss = 7.9933e-04, PNorm = 64.1331, GNorm = 1.1103, lr_0 = 6.0167e-04
Loss = 8.4640e-04, PNorm = 64.1607, GNorm = 0.3868, lr_0 = 5.9901e-04
Loss = 7.6716e-04, PNorm = 64.1837, GNorm = 0.7545, lr_0 = 5.9636e-04
Loss = 7.9138e-04, PNorm = 64.2166, GNorm = 0.4973, lr_0 = 5.9372e-04
Loss = 7.8921e-04, PNorm = 64.2411, GNorm = 0.3804, lr_0 = 5.9110e-04
Validation rmse logD = 0.600864
Validation R2 logD = 0.721579
Epoch 24
Train function
Loss = 7.5780e-04, PNorm = 64.2603, GNorm = 0.5326, lr_0 = 5.8822e-04
Loss = 6.8307e-04, PNorm = 64.2898, GNorm = 0.5344, lr_0 = 5.8562e-04
Loss = 6.7824e-04, PNorm = 64.3222, GNorm = 0.4244, lr_0 = 5.8303e-04
Loss = 6.2131e-04, PNorm = 64.3454, GNorm = 0.5857, lr_0 = 5.8045e-04
Loss = 7.8094e-04, PNorm = 64.3650, GNorm = 1.3869, lr_0 = 5.7788e-04
Validation rmse logD = 0.627630
Validation R2 logD = 0.696222
Epoch 25
Train function
Loss = 8.2289e-04, PNorm = 64.3943, GNorm = 1.4917, lr_0 = 5.7507e-04
Loss = 7.4538e-04, PNorm = 64.4254, GNorm = 1.0976, lr_0 = 5.7253e-04
Loss = 6.4989e-04, PNorm = 64.4440, GNorm = 0.5380, lr_0 = 5.7000e-04
Loss = 6.1424e-04, PNorm = 64.4635, GNorm = 0.8347, lr_0 = 5.6748e-04
Loss = 5.8933e-04, PNorm = 64.4899, GNorm = 0.5639, lr_0 = 5.6497e-04
Loss = 6.9995e-04, PNorm = 64.5137, GNorm = 0.4545, lr_0 = 5.6247e-04
Loss = 4.3889e-04, PNorm = 64.5158, GNorm = 0.3430, lr_0 = 5.6222e-04
Validation rmse logD = 0.597689
Validation R2 logD = 0.724514
Epoch 26
Train function
Loss = 5.2073e-04, PNorm = 64.5344, GNorm = 1.0831, lr_0 = 5.5973e-04
Loss = 6.9647e-04, PNorm = 64.5542, GNorm = 1.2783, lr_0 = 5.5725e-04
Loss = 6.2664e-04, PNorm = 64.5822, GNorm = 0.7172, lr_0 = 5.5479e-04
Loss = 6.1767e-04, PNorm = 64.6008, GNorm = 0.4708, lr_0 = 5.5233e-04
Loss = 6.0946e-04, PNorm = 64.6217, GNorm = 0.6483, lr_0 = 5.4989e-04
Validation rmse logD = 0.591289
Validation R2 logD = 0.730382
Epoch 27
Train function
Loss = 5.7264e-04, PNorm = 64.6400, GNorm = 1.0180, lr_0 = 5.4722e-04
Loss = 5.7583e-04, PNorm = 64.6699, GNorm = 1.0358, lr_0 = 5.4480e-04
Loss = 5.6234e-04, PNorm = 64.6950, GNorm = 0.6304, lr_0 = 5.4239e-04
Loss = 6.0440e-04, PNorm = 64.7166, GNorm = 0.4140, lr_0 = 5.3999e-04
Loss = 5.8297e-04, PNorm = 64.7352, GNorm = 0.6913, lr_0 = 5.3760e-04
Validation rmse logD = 0.592119
Validation R2 logD = 0.729624
Epoch 28
Train function
Loss = 5.0649e-04, PNorm = 64.7618, GNorm = 0.3476, lr_0 = 5.3498e-04
Loss = 4.4829e-04, PNorm = 64.7841, GNorm = 0.6544, lr_0 = 5.3262e-04
Loss = 4.7781e-04, PNorm = 64.8003, GNorm = 0.2546, lr_0 = 5.3026e-04
Loss = 5.2425e-04, PNorm = 64.8111, GNorm = 1.3345, lr_0 = 5.2792e-04
Loss = 4.8932e-04, PNorm = 64.8307, GNorm = 1.0961, lr_0 = 5.2558e-04
Validation rmse logD = 0.594349
Validation R2 logD = 0.727584
Epoch 29
Train function
Loss = 4.0636e-04, PNorm = 64.8481, GNorm = 0.9625, lr_0 = 5.2302e-04
Loss = 6.4267e-04, PNorm = 64.8762, GNorm = 0.7998, lr_0 = 5.2071e-04
Loss = 4.9424e-04, PNorm = 64.9085, GNorm = 0.3136, lr_0 = 5.1841e-04
Loss = 5.1073e-04, PNorm = 64.9300, GNorm = 0.9444, lr_0 = 5.1611e-04
Loss = 4.9274e-04, PNorm = 64.9425, GNorm = 0.5606, lr_0 = 5.1383e-04
Loss = 4.8079e-04, PNorm = 64.9584, GNorm = 0.5622, lr_0 = 5.1156e-04
Validation rmse logD = 0.591704
Validation R2 logD = 0.730004
Epoch 30
Train function
Loss = 4.3769e-04, PNorm = 64.9772, GNorm = 0.3499, lr_0 = 5.0930e-04
Loss = 4.4721e-04, PNorm = 64.9959, GNorm = 0.3170, lr_0 = 5.0704e-04
Loss = 4.5201e-04, PNorm = 65.0129, GNorm = 0.5824, lr_0 = 5.0480e-04
Loss = 3.9972e-04, PNorm = 65.0303, GNorm = 0.6597, lr_0 = 5.0257e-04
Loss = 3.5087e-04, PNorm = 65.0490, GNorm = 0.4730, lr_0 = 5.0034e-04
Validation rmse logD = 0.599508
Validation R2 logD = 0.722835
Epoch 31
Train function
Loss = 4.1884e-04, PNorm = 65.0648, GNorm = 0.8666, lr_0 = 4.9791e-04
Loss = 4.1935e-04, PNorm = 65.0843, GNorm = 0.3655, lr_0 = 4.9571e-04
Loss = 3.9300e-04, PNorm = 65.0958, GNorm = 0.7410, lr_0 = 4.9351e-04
Loss = 3.7760e-04, PNorm = 65.1093, GNorm = 0.2160, lr_0 = 4.9133e-04
Loss = 4.6651e-04, PNorm = 65.1259, GNorm = 0.6959, lr_0 = 4.8916e-04
Validation rmse logD = 0.620995
Validation R2 logD = 0.702611
Epoch 32
Train function
Loss = 6.7619e-04, PNorm = 65.1482, GNorm = 1.7942, lr_0 = 4.8678e-04
Loss = 7.3078e-04, PNorm = 65.1752, GNorm = 0.9782, lr_0 = 4.8463e-04
Loss = 7.5386e-04, PNorm = 65.2037, GNorm = 1.0220, lr_0 = 4.8248e-04
Loss = 4.7559e-04, PNorm = 65.2303, GNorm = 0.7819, lr_0 = 4.8035e-04
Loss = 4.8579e-04, PNorm = 65.2496, GNorm = 0.8648, lr_0 = 4.7822e-04
Loss = 3.9471e-04, PNorm = 65.2658, GNorm = 0.3407, lr_0 = 4.7611e-04
Validation rmse logD = 0.589896
Validation R2 logD = 0.731651
Epoch 33
Train function
Loss = 3.5135e-04, PNorm = 65.2865, GNorm = 0.6689, lr_0 = 4.7379e-04
Loss = 2.7902e-04, PNorm = 65.2983, GNorm = 0.4192, lr_0 = 4.7170e-04
Loss = 3.9293e-04, PNorm = 65.3101, GNorm = 1.0294, lr_0 = 4.6961e-04
Loss = 3.3148e-04, PNorm = 65.3221, GNorm = 0.9811, lr_0 = 4.6753e-04
Loss = 3.4567e-04, PNorm = 65.3381, GNorm = 0.8880, lr_0 = 4.6546e-04
Validation rmse logD = 0.589937
Validation R2 logD = 0.731614
Epoch 34
Train function
Loss = 2.6612e-04, PNorm = 65.3614, GNorm = 0.5878, lr_0 = 4.6320e-04
Loss = 3.1435e-04, PNorm = 65.3757, GNorm = 0.4373, lr_0 = 4.6115e-04
Loss = 2.9565e-04, PNorm = 65.3859, GNorm = 0.3496, lr_0 = 4.5911e-04
Loss = 3.0156e-04, PNorm = 65.3946, GNorm = 0.3449, lr_0 = 4.5708e-04
Loss = 3.4185e-04, PNorm = 65.4061, GNorm = 0.4878, lr_0 = 4.5506e-04
Validation rmse logD = 0.592618
Validation R2 logD = 0.729169
Epoch 35
Train function
Loss = 3.0536e-04, PNorm = 65.4244, GNorm = 0.4332, lr_0 = 4.5284e-04
Loss = 2.9692e-04, PNorm = 65.4322, GNorm = 0.4071, lr_0 = 4.5084e-04
Loss = 2.7737e-04, PNorm = 65.4478, GNorm = 0.7201, lr_0 = 4.4885e-04
Loss = 2.9723e-04, PNorm = 65.4592, GNorm = 0.4543, lr_0 = 4.4686e-04
Loss = 2.7877e-04, PNorm = 65.4679, GNorm = 0.3465, lr_0 = 4.4489e-04
Loss = 3.1795e-04, PNorm = 65.4801, GNorm = 0.4070, lr_0 = 4.4292e-04
Validation rmse logD = 0.581935
Validation R2 logD = 0.738845
Epoch 36
Train function
Loss = 2.8498e-04, PNorm = 65.4994, GNorm = 0.2909, lr_0 = 4.4076e-04
Loss = 2.9177e-04, PNorm = 65.5089, GNorm = 0.2172, lr_0 = 4.3881e-04
Loss = 2.2560e-04, PNorm = 65.5188, GNorm = 0.7098, lr_0 = 4.3687e-04
Loss = 2.3937e-04, PNorm = 65.5279, GNorm = 0.6924, lr_0 = 4.3494e-04
Loss = 3.1834e-04, PNorm = 65.5398, GNorm = 0.4889, lr_0 = 4.3302e-04
Validation rmse logD = 0.589541
Validation R2 logD = 0.731974
Epoch 37
Train function
Loss = 2.1209e-04, PNorm = 65.5472, GNorm = 0.3888, lr_0 = 4.3091e-04
Loss = 2.3485e-04, PNorm = 65.5613, GNorm = 0.2939, lr_0 = 4.2900e-04
Loss = 2.3966e-04, PNorm = 65.5692, GNorm = 0.2858, lr_0 = 4.2711e-04
Loss = 2.4476e-04, PNorm = 65.5772, GNorm = 0.2790, lr_0 = 4.2522e-04
Loss = 2.4924e-04, PNorm = 65.5844, GNorm = 0.1945, lr_0 = 4.2334e-04
Validation rmse logD = 0.593851
Validation R2 logD = 0.728040
Epoch 38
Train function
Loss = 3.0695e-04, PNorm = 65.5923, GNorm = 1.0181, lr_0 = 4.2128e-04
Loss = 3.7468e-04, PNorm = 65.6101, GNorm = 1.2754, lr_0 = 4.1941e-04
Loss = 2.5260e-04, PNorm = 65.6265, GNorm = 0.4275, lr_0 = 4.1756e-04
Loss = 2.1612e-04, PNorm = 65.6369, GNorm = 0.5362, lr_0 = 4.1571e-04
Loss = 2.6617e-04, PNorm = 65.6483, GNorm = 0.5331, lr_0 = 4.1387e-04
Loss = 2.3157e-04, PNorm = 65.6609, GNorm = 0.1775, lr_0 = 4.1204e-04
Loss = 1.7224e-03, PNorm = 65.6617, GNorm = 1.0868, lr_0 = 4.1186e-04
Validation rmse logD = 0.592417
Validation R2 logD = 0.729353
Epoch 39
Train function
Loss = 2.1803e-04, PNorm = 65.6734, GNorm = 1.0711, lr_0 = 4.1004e-04
Loss = 2.3852e-04, PNorm = 65.6880, GNorm = 0.4902, lr_0 = 4.0822e-04
Loss = 2.2613e-04, PNorm = 65.6980, GNorm = 0.3625, lr_0 = 4.0642e-04
Loss = 1.9075e-04, PNorm = 65.7069, GNorm = 0.4132, lr_0 = 4.0462e-04
Loss = 2.1840e-04, PNorm = 65.7147, GNorm = 0.3769, lr_0 = 4.0283e-04
Validation rmse logD = 0.590353
Validation R2 logD = 0.731235
Epoch 40
Train function
Loss = 1.7928e-04, PNorm = 65.7221, GNorm = 0.6399, lr_0 = 4.0105e-04
Loss = 2.0237e-04, PNorm = 65.7283, GNorm = 0.4346, lr_0 = 3.9927e-04
Loss = 2.0230e-04, PNorm = 65.7381, GNorm = 0.3072, lr_0 = 3.9751e-04
Loss = 1.9402e-04, PNorm = 65.7477, GNorm = 0.6348, lr_0 = 3.9575e-04
Loss = 2.0315e-04, PNorm = 65.7560, GNorm = 0.3775, lr_0 = 3.9400e-04
Validation rmse logD = 0.595695
Validation R2 logD = 0.726349
Epoch 41
Train function
Loss = 1.6764e-04, PNorm = 65.7646, GNorm = 0.1866, lr_0 = 3.9208e-04
Loss = 1.9023e-04, PNorm = 65.7749, GNorm = 0.7123, lr_0 = 3.9035e-04
Loss = 1.7994e-04, PNorm = 65.7832, GNorm = 0.3284, lr_0 = 3.8862e-04
Loss = 1.6334e-04, PNorm = 65.7916, GNorm = 0.2493, lr_0 = 3.8690e-04
Loss = 1.5995e-04, PNorm = 65.7980, GNorm = 0.3168, lr_0 = 3.8519e-04
Loss = 1.6841e-04, PNorm = 65.8067, GNorm = 0.2898, lr_0 = 3.8349e-04
Loss = 1.3778e-03, PNorm = 65.8074, GNorm = 0.6197, lr_0 = 3.8332e-04
Validation rmse logD = 0.591338
Validation R2 logD = 0.730337
Epoch 42
Train function
Loss = 1.2791e-04, PNorm = 65.8157, GNorm = 0.3181, lr_0 = 3.8162e-04
Loss = 1.4732e-04, PNorm = 65.8241, GNorm = 0.2843, lr_0 = 3.7993e-04
Loss = 1.7507e-04, PNorm = 65.8315, GNorm = 0.2309, lr_0 = 3.7825e-04
Loss = 2.3066e-04, PNorm = 65.8395, GNorm = 0.2912, lr_0 = 3.7658e-04
Loss = 1.2710e-04, PNorm = 65.8496, GNorm = 0.1891, lr_0 = 3.7491e-04
Validation rmse logD = 0.597608
Validation R2 logD = 0.724588
Epoch 43
Train function
Loss = 1.1032e-04, PNorm = 65.8563, GNorm = 0.1982, lr_0 = 3.7309e-04
Loss = 1.4198e-04, PNorm = 65.8643, GNorm = 0.1813, lr_0 = 3.7144e-04
Loss = 1.4228e-04, PNorm = 65.8698, GNorm = 0.3437, lr_0 = 3.6980e-04
Loss = 1.4367e-04, PNorm = 65.8766, GNorm = 0.3248, lr_0 = 3.6816e-04
Loss = 1.6942e-04, PNorm = 65.8823, GNorm = 0.3277, lr_0 = 3.6653e-04
Validation rmse logD = 0.596206
Validation R2 logD = 0.725879
Epoch 44
Train function
Loss = 1.0085e-04, PNorm = 65.8900, GNorm = 0.2822, lr_0 = 3.6475e-04
Loss = 1.1704e-04, PNorm = 65.8966, GNorm = 0.1671, lr_0 = 3.6314e-04
Loss = 1.3530e-04, PNorm = 65.9053, GNorm = 0.2313, lr_0 = 3.6153e-04
Loss = 1.5403e-04, PNorm = 65.9118, GNorm = 0.4186, lr_0 = 3.5993e-04
Loss = 1.4616e-04, PNorm = 65.9190, GNorm = 0.2339, lr_0 = 3.5834e-04
Validation rmse logD = 0.594632
Validation R2 logD = 0.727324
Epoch 45
Train function
Loss = 8.8896e-05, PNorm = 65.9266, GNorm = 0.5542, lr_0 = 3.5660e-04
Loss = 1.2570e-04, PNorm = 65.9340, GNorm = 0.3515, lr_0 = 3.5502e-04
Loss = 1.3879e-04, PNorm = 65.9407, GNorm = 0.4551, lr_0 = 3.5345e-04
Loss = 1.5043e-04, PNorm = 65.9475, GNorm = 0.4650, lr_0 = 3.5188e-04
Loss = 1.3827e-04, PNorm = 65.9548, GNorm = 0.1451, lr_0 = 3.5033e-04
Loss = 1.2807e-04, PNorm = 65.9617, GNorm = 0.2298, lr_0 = 3.4878e-04
Validation rmse logD = 0.596083
Validation R2 logD = 0.725992
Epoch 46
Train function
Loss = 1.2433e-04, PNorm = 65.9695, GNorm = 0.5914, lr_0 = 3.4708e-04
Loss = 1.2667e-04, PNorm = 65.9752, GNorm = 0.3575, lr_0 = 3.4555e-04
Loss = 1.1196e-04, PNorm = 65.9808, GNorm = 0.3743, lr_0 = 3.4402e-04
Loss = 1.4646e-04, PNorm = 65.9855, GNorm = 0.1743, lr_0 = 3.4250e-04
Loss = 1.4851e-04, PNorm = 65.9941, GNorm = 0.6402, lr_0 = 3.4098e-04
Validation rmse logD = 0.595098
Validation R2 logD = 0.726897
Epoch 47
Train function
Loss = 1.4061e-04, PNorm = 66.0008, GNorm = 0.3567, lr_0 = 3.3932e-04
Loss = 1.3809e-04, PNorm = 66.0108, GNorm = 0.2021, lr_0 = 3.3782e-04
Loss = 1.0577e-04, PNorm = 66.0163, GNorm = 0.2330, lr_0 = 3.3633e-04
Loss = 1.1077e-04, PNorm = 66.0224, GNorm = 0.1892, lr_0 = 3.3484e-04
Loss = 1.0849e-04, PNorm = 66.0276, GNorm = 0.1993, lr_0 = 3.3336e-04
Validation rmse logD = 0.620661
Validation R2 logD = 0.702931
Epoch 48
Train function
Loss = 4.4823e-04, PNorm = 66.0353, GNorm = 1.9403, lr_0 = 3.3174e-04
Loss = 3.4428e-04, PNorm = 66.0436, GNorm = 0.6903, lr_0 = 3.3027e-04
Loss = 2.0241e-04, PNorm = 66.0561, GNorm = 0.5921, lr_0 = 3.2881e-04
Loss = 1.2583e-04, PNorm = 66.0645, GNorm = 0.3304, lr_0 = 3.2735e-04
Loss = 1.4698e-04, PNorm = 66.0732, GNorm = 0.6266, lr_0 = 3.2591e-04
Loss = 1.3772e-04, PNorm = 66.0812, GNorm = 0.3111, lr_0 = 3.2446e-04
Validation rmse logD = 0.592843
Validation R2 logD = 0.728963
Epoch 49
Train function
Loss = 1.4765e-04, PNorm = 66.0914, GNorm = 0.8829, lr_0 = 3.2289e-04
Loss = 1.6089e-04, PNorm = 66.1032, GNorm = 0.7100, lr_0 = 3.2146e-04
Loss = 1.8841e-04, PNorm = 66.1077, GNorm = 0.1444, lr_0 = 3.2004e-04
Loss = 1.1629e-04, PNorm = 66.1113, GNorm = 0.3913, lr_0 = 3.1862e-04
Loss = 1.1235e-04, PNorm = 66.1179, GNorm = 0.1891, lr_0 = 3.1721e-04
Validation rmse logD = 0.606258
Validation R2 logD = 0.716558
Epoch 50
Train function
Loss = 1.3186e-04, PNorm = 66.1243, GNorm = 0.7551, lr_0 = 3.1581e-04
Loss = 1.0409e-04, PNorm = 66.1297, GNorm = 0.5671, lr_0 = 3.1441e-04
Loss = 1.2492e-04, PNorm = 66.1353, GNorm = 0.2807, lr_0 = 3.1302e-04
Loss = 1.3773e-04, PNorm = 66.1423, GNorm = 0.4805, lr_0 = 3.1164e-04
Loss = 1.2209e-04, PNorm = 66.1511, GNorm = 0.1982, lr_0 = 3.1026e-04
Validation rmse logD = 0.601110
Validation R2 logD = 0.721351
Epoch 51
Train function
Loss = 2.0594e-04, PNorm = 66.1585, GNorm = 0.9450, lr_0 = 3.0875e-04
Loss = 1.4505e-04, PNorm = 66.1649, GNorm = 0.4084, lr_0 = 3.0738e-04
Loss = 1.5006e-04, PNorm = 66.1739, GNorm = 0.2211, lr_0 = 3.0602e-04
Loss = 1.1279e-04, PNorm = 66.1780, GNorm = 0.2450, lr_0 = 3.0467e-04
Loss = 1.0947e-04, PNorm = 66.1837, GNorm = 0.2778, lr_0 = 3.0332e-04
Loss = 9.1945e-05, PNorm = 66.1911, GNorm = 0.2447, lr_0 = 3.0198e-04
Validation rmse logD = 0.592736
Validation R2 logD = 0.729061
Epoch 52
Train function
Loss = 9.5746e-05, PNorm = 66.1963, GNorm = 0.1692, lr_0 = 3.0051e-04
Loss = 1.1513e-04, PNorm = 66.2057, GNorm = 0.2190, lr_0 = 2.9918e-04
Loss = 1.5421e-04, PNorm = 66.2118, GNorm = 0.2032, lr_0 = 2.9786e-04
Loss = 1.2909e-04, PNorm = 66.2187, GNorm = 0.2943, lr_0 = 2.9654e-04
Loss = 1.1923e-04, PNorm = 66.2245, GNorm = 0.3182, lr_0 = 2.9523e-04
Validation rmse logD = 0.600869
Validation R2 logD = 0.721575
Epoch 53
Train function
Loss = 7.3349e-05, PNorm = 66.2297, GNorm = 0.2506, lr_0 = 2.9379e-04
Loss = 9.5375e-05, PNorm = 66.2357, GNorm = 0.4644, lr_0 = 2.9249e-04
Loss = 1.0303e-04, PNorm = 66.2428, GNorm = 0.1430, lr_0 = 2.9120e-04
Loss = 7.0361e-05, PNorm = 66.2478, GNorm = 0.1188, lr_0 = 2.8991e-04
Loss = 8.8978e-05, PNorm = 66.2510, GNorm = 0.1865, lr_0 = 2.8863e-04
Validation rmse logD = 0.595018
Validation R2 logD = 0.726970
Epoch 54
Train function
Loss = 8.2436e-05, PNorm = 66.2556, GNorm = 0.4423, lr_0 = 2.8722e-04
Loss = 1.2238e-04, PNorm = 66.2613, GNorm = 0.2310, lr_0 = 2.8595e-04
Loss = 9.9021e-05, PNorm = 66.2646, GNorm = 0.3584, lr_0 = 2.8469e-04
Loss = 8.7822e-05, PNorm = 66.2691, GNorm = 0.3173, lr_0 = 2.8343e-04
Loss = 6.2946e-05, PNorm = 66.2739, GNorm = 0.1489, lr_0 = 2.8218e-04
Loss = 8.1296e-05, PNorm = 66.2771, GNorm = 0.1840, lr_0 = 2.8093e-04
Loss = 1.0634e-03, PNorm = 66.2782, GNorm = 1.0577, lr_0 = 2.8080e-04
Validation rmse logD = 0.597111
Validation R2 logD = 0.725046
Epoch 55
Train function
Loss = 1.1354e-04, PNorm = 66.2837, GNorm = 0.2503, lr_0 = 2.7956e-04
Loss = 7.5737e-05, PNorm = 66.2882, GNorm = 0.2658, lr_0 = 2.7832e-04
Loss = 5.8892e-05, PNorm = 66.2932, GNorm = 0.1601, lr_0 = 2.7709e-04
Loss = 6.3834e-05, PNorm = 66.2970, GNorm = 0.2777, lr_0 = 2.7587e-04
Loss = 5.6764e-05, PNorm = 66.2998, GNorm = 0.2566, lr_0 = 2.7465e-04
Validation rmse logD = 0.599873
Validation R2 logD = 0.722497
Epoch 56
Train function
Loss = 8.2533e-05, PNorm = 66.3045, GNorm = 0.1305, lr_0 = 2.7331e-04
Loss = 6.7334e-05, PNorm = 66.3077, GNorm = 0.2415, lr_0 = 2.7210e-04
Loss = 5.7245e-05, PNorm = 66.3128, GNorm = 0.1729, lr_0 = 2.7090e-04
Loss = 7.6175e-05, PNorm = 66.3167, GNorm = 0.2960, lr_0 = 2.6970e-04
Loss = 6.3723e-05, PNorm = 66.3200, GNorm = 0.1922, lr_0 = 2.6851e-04
Validation rmse logD = 0.596138
Validation R2 logD = 0.725942
Epoch 57
Train function
Loss = 9.0158e-05, PNorm = 66.3235, GNorm = 0.1781, lr_0 = 2.6720e-04
Loss = 8.9474e-05, PNorm = 66.3308, GNorm = 0.2409, lr_0 = 2.6602e-04
Loss = 7.9428e-05, PNorm = 66.3332, GNorm = 0.3297, lr_0 = 2.6484e-04
Loss = 5.1776e-05, PNorm = 66.3366, GNorm = 0.1195, lr_0 = 2.6367e-04
Loss = 5.9511e-05, PNorm = 66.3394, GNorm = 0.2737, lr_0 = 2.6250e-04
Validation rmse logD = 0.598080
Validation R2 logD = 0.724153
Epoch 58
Train function
Loss = 4.4209e-05, PNorm = 66.3440, GNorm = 0.2567, lr_0 = 2.6123e-04
Loss = 6.5298e-05, PNorm = 66.3483, GNorm = 0.2948, lr_0 = 2.6007e-04
Loss = 5.8769e-05, PNorm = 66.3524, GNorm = 0.1235, lr_0 = 2.5892e-04
Loss = 4.9689e-05, PNorm = 66.3562, GNorm = 0.1125, lr_0 = 2.5778e-04
Loss = 4.5477e-05, PNorm = 66.3592, GNorm = 0.1580, lr_0 = 2.5664e-04
Loss = 6.1622e-05, PNorm = 66.3628, GNorm = 0.1886, lr_0 = 2.5550e-04
Validation rmse logD = 0.598585
Validation R2 logD = 0.723687
Epoch 59
Train function
Loss = 7.1364e-05, PNorm = 66.3654, GNorm = 0.4746, lr_0 = 2.5426e-04
Loss = 6.6486e-05, PNorm = 66.3676, GNorm = 0.3757, lr_0 = 2.5313e-04
Loss = 5.4660e-05, PNorm = 66.3719, GNorm = 0.3342, lr_0 = 2.5201e-04
Loss = 7.0576e-05, PNorm = 66.3775, GNorm = 0.3013, lr_0 = 2.5090e-04
Loss = 5.7188e-05, PNorm = 66.3829, GNorm = 0.1552, lr_0 = 2.4979e-04
Validation rmse logD = 0.596004
Validation R2 logD = 0.726065
Epoch 60
Train function
Loss = 6.4442e-05, PNorm = 66.3864, GNorm = 0.3116, lr_0 = 2.4868e-04
Loss = 9.6154e-05, PNorm = 66.3912, GNorm = 0.1923, lr_0 = 2.4758e-04
Loss = 5.9238e-05, PNorm = 66.3942, GNorm = 0.1181, lr_0 = 2.4649e-04
Loss = 5.4864e-05, PNorm = 66.3978, GNorm = 0.1451, lr_0 = 2.4540e-04
Loss = 6.3147e-05, PNorm = 66.4024, GNorm = 0.2001, lr_0 = 2.4431e-04
Validation rmse logD = 0.600930
Validation R2 logD = 0.721518
Epoch 61
Train function
Loss = 6.7175e-05, PNorm = 66.4051, GNorm = 0.4016, lr_0 = 2.4313e-04
Loss = 4.8757e-05, PNorm = 66.4086, GNorm = 0.2429, lr_0 = 2.4205e-04
Loss = 5.2082e-05, PNorm = 66.4125, GNorm = 0.5147, lr_0 = 2.4098e-04
Loss = 4.3503e-05, PNorm = 66.4157, GNorm = 0.1583, lr_0 = 2.3991e-04
Loss = 4.0945e-05, PNorm = 66.4171, GNorm = 0.2926, lr_0 = 2.3885e-04
Loss = 4.6825e-05, PNorm = 66.4197, GNorm = 0.0989, lr_0 = 2.3780e-04
Validation rmse logD = 0.599783
Validation R2 logD = 0.722580
Epoch 62
Train function
Loss = 5.1381e-05, PNorm = 66.4240, GNorm = 0.2331, lr_0 = 2.3664e-04
Loss = 6.2215e-05, PNorm = 66.4292, GNorm = 0.3390, lr_0 = 2.3559e-04
Loss = 5.0108e-05, PNorm = 66.4320, GNorm = 0.2636, lr_0 = 2.3455e-04
Loss = 5.8052e-05, PNorm = 66.4344, GNorm = 0.1610, lr_0 = 2.3351e-04
Loss = 4.0066e-05, PNorm = 66.4370, GNorm = 0.0857, lr_0 = 2.3248e-04
Validation rmse logD = 0.596730
Validation R2 logD = 0.725397
Epoch 63
Train function
Loss = 5.6389e-05, PNorm = 66.4410, GNorm = 0.3480, lr_0 = 2.3135e-04
Loss = 5.8092e-05, PNorm = 66.4456, GNorm = 0.5599, lr_0 = 2.3033e-04
Loss = 5.5936e-05, PNorm = 66.4477, GNorm = 0.1017, lr_0 = 2.2931e-04
Loss = 5.0637e-05, PNorm = 66.4504, GNorm = 0.0804, lr_0 = 2.2829e-04
Loss = 5.1983e-05, PNorm = 66.4528, GNorm = 0.1019, lr_0 = 2.2728e-04
Validation rmse logD = 0.597070
Validation R2 logD = 0.725085
Epoch 64
Train function
Loss = 3.3820e-05, PNorm = 66.4545, GNorm = 0.1202, lr_0 = 2.2618e-04
Loss = 4.0441e-05, PNorm = 66.4563, GNorm = 0.1173, lr_0 = 2.2518e-04
Loss = 3.6888e-05, PNorm = 66.4587, GNorm = 0.1755, lr_0 = 2.2418e-04
Loss = 3.9641e-05, PNorm = 66.4621, GNorm = 0.2289, lr_0 = 2.2319e-04
Loss = 4.7263e-05, PNorm = 66.4633, GNorm = 0.4930, lr_0 = 2.2220e-04
Loss = 4.9629e-05, PNorm = 66.4666, GNorm = 0.4856, lr_0 = 2.2122e-04
Validation rmse logD = 0.599531
Validation R2 logD = 0.722813
Epoch 65
Train function
Loss = 6.2769e-05, PNorm = 66.4703, GNorm = 0.2959, lr_0 = 2.2014e-04
Loss = 4.6115e-05, PNorm = 66.4754, GNorm = 0.1823, lr_0 = 2.1917e-04
Loss = 3.0727e-05, PNorm = 66.4774, GNorm = 0.1283, lr_0 = 2.1820e-04
Loss = 4.6470e-05, PNorm = 66.4804, GNorm = 0.1622, lr_0 = 2.1723e-04
Loss = 3.6520e-05, PNorm = 66.4818, GNorm = 0.2343, lr_0 = 2.1627e-04
Validation rmse logD = 0.596964
Validation R2 logD = 0.725182
Epoch 66
Train function
Loss = 4.8755e-05, PNorm = 66.4857, GNorm = 0.2318, lr_0 = 2.1522e-04
Loss = 4.7710e-05, PNorm = 66.4889, GNorm = 0.1790, lr_0 = 2.1427e-04
Loss = 4.1829e-05, PNorm = 66.4924, GNorm = 0.1084, lr_0 = 2.1332e-04
Loss = 3.6474e-05, PNorm = 66.4948, GNorm = 0.1405, lr_0 = 2.1238e-04
Loss = 4.6064e-05, PNorm = 66.4974, GNorm = 0.3177, lr_0 = 2.1144e-04
Validation rmse logD = 0.598659
Validation R2 logD = 0.723619
Epoch 67
Train function
Loss = 4.2587e-05, PNorm = 66.5011, GNorm = 0.1548, lr_0 = 2.1041e-04
Loss = 3.4418e-05, PNorm = 66.5033, GNorm = 0.1152, lr_0 = 2.0948e-04
Loss = 2.7855e-05, PNorm = 66.5046, GNorm = 0.3367, lr_0 = 2.0855e-04
Loss = 3.5435e-05, PNorm = 66.5069, GNorm = 0.3186, lr_0 = 2.0763e-04
Loss = 3.6978e-05, PNorm = 66.5084, GNorm = 0.3990, lr_0 = 2.0671e-04
Loss = 4.5106e-05, PNorm = 66.5114, GNorm = 0.3812, lr_0 = 2.0580e-04
Loss = 3.1725e-04, PNorm = 66.5114, GNorm = 0.5239, lr_0 = 2.0571e-04
Validation rmse logD = 0.602313
Validation R2 logD = 0.720235
Epoch 68
Train function
Loss = 4.6334e-05, PNorm = 66.5142, GNorm = 0.1988, lr_0 = 2.0480e-04
Loss = 4.4308e-05, PNorm = 66.5156, GNorm = 0.3378, lr_0 = 2.0389e-04
Loss = 3.6285e-05, PNorm = 66.5170, GNorm = 0.1206, lr_0 = 2.0299e-04
Loss = 3.8421e-05, PNorm = 66.5192, GNorm = 0.0961, lr_0 = 2.0209e-04
Loss = 3.8083e-05, PNorm = 66.5219, GNorm = 0.1343, lr_0 = 2.0120e-04
Validation rmse logD = 0.599617
Validation R2 logD = 0.722734
Epoch 69
Train function
Loss = 2.8107e-05, PNorm = 66.5259, GNorm = 0.0907, lr_0 = 2.0022e-04
Loss = 3.0134e-05, PNorm = 66.5270, GNorm = 0.0995, lr_0 = 1.9933e-04
Loss = 2.9223e-05, PNorm = 66.5290, GNorm = 0.1102, lr_0 = 1.9845e-04
Loss = 3.0124e-05, PNorm = 66.5325, GNorm = 0.1373, lr_0 = 1.9757e-04
Loss = 2.8713e-05, PNorm = 66.5341, GNorm = 0.1809, lr_0 = 1.9670e-04
Validation rmse logD = 0.600717
Validation R2 logD = 0.721715
Epoch 70
Train function
Loss = 5.3690e-05, PNorm = 66.5356, GNorm = 0.1733, lr_0 = 1.9583e-04
Loss = 4.3238e-05, PNorm = 66.5369, GNorm = 0.0942, lr_0 = 1.9496e-04
Loss = 5.3004e-05, PNorm = 66.5404, GNorm = 0.2906, lr_0 = 1.9410e-04
Loss = 4.8109e-05, PNorm = 66.5435, GNorm = 0.2019, lr_0 = 1.9324e-04
Loss = 3.4773e-05, PNorm = 66.5458, GNorm = 0.0704, lr_0 = 1.9239e-04
Loss = 3.4400e-05, PNorm = 66.5483, GNorm = 0.2344, lr_0 = 1.9154e-04
Loss = 1.8894e-04, PNorm = 66.5482, GNorm = 0.2785, lr_0 = 1.9145e-04
Validation rmse logD = 0.602996
Validation R2 logD = 0.719600
Epoch 71
Train function
Loss = 4.2511e-05, PNorm = 66.5503, GNorm = 0.0974, lr_0 = 1.9060e-04
Loss = 3.1281e-05, PNorm = 66.5530, GNorm = 0.1350, lr_0 = 1.8976e-04
Loss = 3.5131e-05, PNorm = 66.5561, GNorm = 0.1240, lr_0 = 1.8892e-04
Loss = 2.5033e-05, PNorm = 66.5594, GNorm = 0.2130, lr_0 = 1.8809e-04
Loss = 3.1080e-05, PNorm = 66.5614, GNorm = 0.2384, lr_0 = 1.8725e-04
Validation rmse logD = 0.601905
Validation R2 logD = 0.720614
Epoch 72
Train function
Loss = 2.9216e-05, PNorm = 66.5632, GNorm = 0.0875, lr_0 = 1.8634e-04
Loss = 3.5222e-05, PNorm = 66.5645, GNorm = 0.2418, lr_0 = 1.8552e-04
Loss = 3.3258e-05, PNorm = 66.5663, GNorm = 0.3569, lr_0 = 1.8470e-04
Loss = 3.1379e-05, PNorm = 66.5688, GNorm = 0.1976, lr_0 = 1.8388e-04
Loss = 2.2211e-05, PNorm = 66.5717, GNorm = 0.1119, lr_0 = 1.8307e-04
Validation rmse logD = 0.602326
Validation R2 logD = 0.720223
Epoch 73
Train function
Loss = 1.5579e-05, PNorm = 66.5724, GNorm = 0.0853, lr_0 = 1.8218e-04
Loss = 1.6647e-05, PNorm = 66.5736, GNorm = 0.0630, lr_0 = 1.8137e-04
Loss = 2.0667e-05, PNorm = 66.5748, GNorm = 0.1307, lr_0 = 1.8057e-04
Loss = 2.9217e-05, PNorm = 66.5773, GNorm = 0.1074, lr_0 = 1.7977e-04
Loss = 2.1008e-05, PNorm = 66.5791, GNorm = 0.2145, lr_0 = 1.7897e-04
Validation rmse logD = 0.600485
Validation R2 logD = 0.721930
Epoch 74
Train function
Loss = 2.4766e-05, PNorm = 66.5824, GNorm = 0.1576, lr_0 = 1.7810e-04
Loss = 1.9488e-05, PNorm = 66.5849, GNorm = 0.1596, lr_0 = 1.7732e-04
Loss = 1.9295e-05, PNorm = 66.5849, GNorm = 0.1607, lr_0 = 1.7653e-04
Loss = 2.3862e-05, PNorm = 66.5859, GNorm = 0.2947, lr_0 = 1.7575e-04
Loss = 1.9136e-05, PNorm = 66.5873, GNorm = 0.1182, lr_0 = 1.7497e-04
Loss = 2.1357e-05, PNorm = 66.5888, GNorm = 0.1352, lr_0 = 1.7420e-04
Validation rmse logD = 0.600769
Validation R2 logD = 0.721668
Epoch 75
Train function
Loss = 3.0710e-05, PNorm = 66.5907, GNorm = 0.1495, lr_0 = 1.7335e-04
Loss = 2.4664e-05, PNorm = 66.5930, GNorm = 0.1343, lr_0 = 1.7259e-04
Loss = 1.7438e-05, PNorm = 66.5954, GNorm = 0.0869, lr_0 = 1.7182e-04
Loss = 2.8423e-05, PNorm = 66.5967, GNorm = 0.3436, lr_0 = 1.7106e-04
Loss = 2.1101e-05, PNorm = 66.5982, GNorm = 0.1904, lr_0 = 1.7031e-04
Validation rmse logD = 0.600802
Validation R2 logD = 0.721636
Epoch 76
Train function
Loss = 2.1625e-05, PNorm = 66.6003, GNorm = 0.1825, lr_0 = 1.6948e-04
Loss = 2.1287e-05, PNorm = 66.6025, GNorm = 0.0708, lr_0 = 1.6873e-04
Loss = 1.8689e-05, PNorm = 66.6041, GNorm = 0.0768, lr_0 = 1.6798e-04
Loss = 1.7786e-05, PNorm = 66.6051, GNorm = 0.1893, lr_0 = 1.6724e-04
Loss = 2.9259e-05, PNorm = 66.6060, GNorm = 0.4356, lr_0 = 1.6650e-04
Validation rmse logD = 0.599505
Validation R2 logD = 0.722837
Epoch 77
Train function
Loss = 4.1043e-05, PNorm = 66.6079, GNorm = 0.3840, lr_0 = 1.6569e-04
Loss = 3.3851e-05, PNorm = 66.6092, GNorm = 0.2108, lr_0 = 1.6496e-04
Loss = 2.9508e-05, PNorm = 66.6114, GNorm = 0.2874, lr_0 = 1.6423e-04
Loss = 3.3003e-05, PNorm = 66.6130, GNorm = 0.0805, lr_0 = 1.6350e-04
Loss = 3.3517e-05, PNorm = 66.6158, GNorm = 0.0775, lr_0 = 1.6278e-04
Loss = 2.5563e-05, PNorm = 66.6174, GNorm = 0.0878, lr_0 = 1.6206e-04
Validation rmse logD = 0.599243
Validation R2 logD = 0.723079
Epoch 78
Train function
Loss = 2.3484e-05, PNorm = 66.6186, GNorm = 0.0861, lr_0 = 1.6127e-04
Loss = 2.1042e-05, PNorm = 66.6188, GNorm = 0.1886, lr_0 = 1.6055e-04
Loss = 1.9381e-05, PNorm = 66.6203, GNorm = 0.0739, lr_0 = 1.5984e-04
Loss = 2.3097e-05, PNorm = 66.6221, GNorm = 0.1082, lr_0 = 1.5914e-04
Loss = 1.8573e-05, PNorm = 66.6237, GNorm = 0.1070, lr_0 = 1.5843e-04
Validation rmse logD = 0.599831
Validation R2 logD = 0.722536
Epoch 79
Train function
Loss = 1.5323e-05, PNorm = 66.6262, GNorm = 0.1353, lr_0 = 1.5766e-04
Loss = 2.6955e-05, PNorm = 66.6282, GNorm = 0.0990, lr_0 = 1.5697e-04
Loss = 2.1413e-05, PNorm = 66.6293, GNorm = 0.0866, lr_0 = 1.5627e-04
Loss = 2.0687e-05, PNorm = 66.6302, GNorm = 0.1129, lr_0 = 1.5558e-04
Loss = 2.2995e-05, PNorm = 66.6315, GNorm = 0.1194, lr_0 = 1.5489e-04
Validation rmse logD = 0.600769
Validation R2 logD = 0.721667
Epoch 80
Train function
Loss = 1.8436e-05, PNorm = 66.6334, GNorm = 0.2123, lr_0 = 1.5421e-04
Loss = 1.8412e-05, PNorm = 66.6350, GNorm = 0.1158, lr_0 = 1.5352e-04
Loss = 1.4880e-05, PNorm = 66.6361, GNorm = 0.2603, lr_0 = 1.5284e-04
Loss = 2.4074e-05, PNorm = 66.6380, GNorm = 0.2834, lr_0 = 1.5217e-04
Loss = 2.1114e-05, PNorm = 66.6403, GNorm = 0.3353, lr_0 = 1.5150e-04
Loss = 2.2420e-05, PNorm = 66.6416, GNorm = 0.0519, lr_0 = 1.5083e-04
Validation rmse logD = 0.600827
Validation R2 logD = 0.721613
Epoch 81
Train function
Loss = 2.6294e-05, PNorm = 66.6432, GNorm = 0.1753, lr_0 = 1.5009e-04
Loss = 2.0643e-05, PNorm = 66.6438, GNorm = 0.1584, lr_0 = 1.4943e-04
Loss = 1.4819e-05, PNorm = 66.6453, GNorm = 0.1855, lr_0 = 1.4877e-04
Loss = 2.4763e-05, PNorm = 66.6469, GNorm = 0.3191, lr_0 = 1.4811e-04
Loss = 2.4577e-05, PNorm = 66.6481, GNorm = 0.2973, lr_0 = 1.4745e-04
Validation rmse logD = 0.600411
Validation R2 logD = 0.721999
Epoch 82
Train function
Loss = 1.6078e-05, PNorm = 66.6490, GNorm = 0.1922, lr_0 = 1.4674e-04
Loss = 1.8105e-05, PNorm = 66.6504, GNorm = 0.1752, lr_0 = 1.4609e-04
Loss = 1.9981e-05, PNorm = 66.6512, GNorm = 0.1826, lr_0 = 1.4544e-04
Loss = 2.3344e-05, PNorm = 66.6529, GNorm = 0.0878, lr_0 = 1.4480e-04
Loss = 1.4600e-05, PNorm = 66.6541, GNorm = 0.1591, lr_0 = 1.4416e-04
Validation rmse logD = 0.601549
Validation R2 logD = 0.720944
Epoch 83
Train function
Loss = 1.0193e-05, PNorm = 66.6559, GNorm = 0.0896, lr_0 = 1.4346e-04
Loss = 1.4749e-05, PNorm = 66.6575, GNorm = 0.1113, lr_0 = 1.4282e-04
Loss = 1.3869e-05, PNorm = 66.6593, GNorm = 0.1125, lr_0 = 1.4219e-04
Loss = 1.2342e-05, PNorm = 66.6606, GNorm = 0.1788, lr_0 = 1.4156e-04
Loss = 1.0806e-05, PNorm = 66.6618, GNorm = 0.0433, lr_0 = 1.4093e-04
Loss = 2.2404e-05, PNorm = 66.6631, GNorm = 0.0619, lr_0 = 1.4031e-04
Loss = 5.3177e-05, PNorm = 66.6633, GNorm = 0.1194, lr_0 = 1.4025e-04
Validation rmse logD = 0.601095
Validation R2 logD = 0.721365
Epoch 84
Train function
Loss = 1.1297e-05, PNorm = 66.6642, GNorm = 0.0715, lr_0 = 1.3963e-04
Loss = 1.0283e-05, PNorm = 66.6655, GNorm = 0.0634, lr_0 = 1.3901e-04
Loss = 1.1286e-05, PNorm = 66.6666, GNorm = 0.0480, lr_0 = 1.3840e-04
Loss = 1.6974e-05, PNorm = 66.6682, GNorm = 0.0852, lr_0 = 1.3778e-04
Loss = 1.4866e-05, PNorm = 66.6688, GNorm = 0.1079, lr_0 = 1.3717e-04
Validation rmse logD = 0.601537
Validation R2 logD = 0.720956
Epoch 85
Train function
Loss = 1.4177e-05, PNorm = 66.6699, GNorm = 0.1454, lr_0 = 1.3651e-04
Loss = 1.6058e-05, PNorm = 66.6722, GNorm = 0.1127, lr_0 = 1.3590e-04
Loss = 1.2093e-05, PNorm = 66.6737, GNorm = 0.0756, lr_0 = 1.3530e-04
Loss = 1.3785e-05, PNorm = 66.6742, GNorm = 0.1605, lr_0 = 1.3470e-04
Loss = 1.3922e-05, PNorm = 66.6752, GNorm = 0.1170, lr_0 = 1.3411e-04
Validation rmse logD = 0.600484
Validation R2 logD = 0.721931
Epoch 86
Train function
Loss = 1.1501e-05, PNorm = 66.6764, GNorm = 0.1249, lr_0 = 1.3346e-04
Loss = 1.4801e-05, PNorm = 66.6779, GNorm = 0.0986, lr_0 = 1.3287e-04
Loss = 1.4565e-05, PNorm = 66.6793, GNorm = 0.0996, lr_0 = 1.3228e-04
Loss = 1.3387e-05, PNorm = 66.6798, GNorm = 0.1048, lr_0 = 1.3169e-04
Loss = 1.2728e-05, PNorm = 66.6809, GNorm = 0.0808, lr_0 = 1.3111e-04
Validation rmse logD = 0.601925
Validation R2 logD = 0.720595
Epoch 87
Train function
Loss = 9.9776e-06, PNorm = 66.6820, GNorm = 0.2054, lr_0 = 1.3047e-04
Loss = 1.0389e-05, PNorm = 66.6824, GNorm = 0.1406, lr_0 = 1.2990e-04
Loss = 1.2931e-05, PNorm = 66.6835, GNorm = 0.0971, lr_0 = 1.2932e-04
Loss = 1.2964e-05, PNorm = 66.6853, GNorm = 0.0866, lr_0 = 1.2875e-04
Loss = 1.0977e-05, PNorm = 66.6862, GNorm = 0.0537, lr_0 = 1.2818e-04
Loss = 1.4819e-05, PNorm = 66.6869, GNorm = 0.0629, lr_0 = 1.2761e-04
Validation rmse logD = 0.602954
Validation R2 logD = 0.719639
Epoch 88
Train function
Loss = 1.7145e-05, PNorm = 66.6878, GNorm = 0.2047, lr_0 = 1.2699e-04
Loss = 1.8408e-05, PNorm = 66.6889, GNorm = 0.1398, lr_0 = 1.2643e-04
Loss = 1.2601e-05, PNorm = 66.6895, GNorm = 0.0773, lr_0 = 1.2587e-04
Loss = 1.2874e-05, PNorm = 66.6908, GNorm = 0.0837, lr_0 = 1.2531e-04
Loss = 1.5864e-05, PNorm = 66.6931, GNorm = 0.0632, lr_0 = 1.2476e-04
Validation rmse logD = 0.602820
Validation R2 logD = 0.719764
Epoch 89
Train function
Loss = 1.3446e-05, PNorm = 66.6933, GNorm = 0.1940, lr_0 = 1.2415e-04
Loss = 1.5600e-05, PNorm = 66.6946, GNorm = 0.1716, lr_0 = 1.2360e-04
Loss = 1.1488e-05, PNorm = 66.6954, GNorm = 0.0698, lr_0 = 1.2306e-04
Loss = 1.2739e-05, PNorm = 66.6973, GNorm = 0.0575, lr_0 = 1.2251e-04
Loss = 8.7406e-06, PNorm = 66.6981, GNorm = 0.0805, lr_0 = 1.2197e-04
Validation rmse logD = 0.600691
Validation R2 logD = 0.721739
Epoch 90
Train function
Loss = 2.0435e-05, PNorm = 66.6990, GNorm = 0.1360, lr_0 = 1.2143e-04
Loss = 1.5099e-05, PNorm = 66.7003, GNorm = 0.1311, lr_0 = 1.2089e-04
Loss = 1.2661e-05, PNorm = 66.7008, GNorm = 0.0978, lr_0 = 1.2036e-04
Loss = 9.2229e-06, PNorm = 66.7014, GNorm = 0.0804, lr_0 = 1.1983e-04
Loss = 8.4315e-06, PNorm = 66.7029, GNorm = 0.0883, lr_0 = 1.1930e-04
Loss = 1.2811e-05, PNorm = 66.7041, GNorm = 0.0825, lr_0 = 1.1877e-04
Validation rmse logD = 0.602858
Validation R2 logD = 0.719728
Epoch 91
Train function
Loss = 1.5112e-05, PNorm = 66.7041, GNorm = 0.0960, lr_0 = 1.1819e-04
Loss = 1.1908e-05, PNorm = 66.7059, GNorm = 0.0770, lr_0 = 1.1767e-04
Loss = 1.3081e-05, PNorm = 66.7065, GNorm = 0.1285, lr_0 = 1.1715e-04
Loss = 1.2446e-05, PNorm = 66.7073, GNorm = 0.1592, lr_0 = 1.1663e-04
Loss = 1.0956e-05, PNorm = 66.7089, GNorm = 0.1442, lr_0 = 1.1611e-04
Validation rmse logD = 0.601531
Validation R2 logD = 0.720960
Epoch 92
Train function
Loss = 1.1470e-05, PNorm = 66.7098, GNorm = 0.1054, lr_0 = 1.1555e-04
Loss = 1.0768e-05, PNorm = 66.7109, GNorm = 0.1941, lr_0 = 1.1504e-04
Loss = 1.4060e-05, PNorm = 66.7119, GNorm = 0.0994, lr_0 = 1.1453e-04
Loss = 1.4614e-05, PNorm = 66.7130, GNorm = 0.0750, lr_0 = 1.1402e-04
Loss = 1.1298e-05, PNorm = 66.7139, GNorm = 0.0989, lr_0 = 1.1352e-04
Validation rmse logD = 0.602308
Validation R2 logD = 0.720239
Epoch 93
Train function
Loss = 9.8800e-06, PNorm = 66.7152, GNorm = 0.0748, lr_0 = 1.1297e-04
Loss = 9.1567e-06, PNorm = 66.7164, GNorm = 0.0664, lr_0 = 1.1247e-04
Loss = 7.3996e-06, PNorm = 66.7167, GNorm = 0.0414, lr_0 = 1.1197e-04
Loss = 9.9414e-06, PNorm = 66.7175, GNorm = 0.1698, lr_0 = 1.1147e-04
Loss = 1.3660e-05, PNorm = 66.7183, GNorm = 0.2286, lr_0 = 1.1098e-04
Loss = 1.8017e-05, PNorm = 66.7198, GNorm = 0.1745, lr_0 = 1.1049e-04
Validation rmse logD = 0.603052
Validation R2 logD = 0.719547
Epoch 94
Train function
Loss = 1.9390e-05, PNorm = 66.7211, GNorm = 0.1927, lr_0 = 1.0995e-04
Loss = 1.4934e-05, PNorm = 66.7226, GNorm = 0.1284, lr_0 = 1.0947e-04
Loss = 1.3454e-05, PNorm = 66.7242, GNorm = 0.1108, lr_0 = 1.0898e-04
Loss = 1.6982e-05, PNorm = 66.7250, GNorm = 0.2145, lr_0 = 1.0850e-04
Loss = 1.6440e-05, PNorm = 66.7267, GNorm = 0.1421, lr_0 = 1.0802e-04
Validation rmse logD = 0.602721
Validation R2 logD = 0.719855
Epoch 95
Train function
Loss = 1.1437e-05, PNorm = 66.7280, GNorm = 0.0923, lr_0 = 1.0749e-04
Loss = 8.8745e-06, PNorm = 66.7289, GNorm = 0.0648, lr_0 = 1.0702e-04
Loss = 1.4231e-05, PNorm = 66.7292, GNorm = 0.0930, lr_0 = 1.0654e-04
Loss = 1.2447e-05, PNorm = 66.7306, GNorm = 0.0608, lr_0 = 1.0607e-04
Loss = 1.1417e-05, PNorm = 66.7319, GNorm = 0.1145, lr_0 = 1.0560e-04
Validation rmse logD = 0.601203
Validation R2 logD = 0.721265
Epoch 96
Train function
Loss = 1.4534e-05, PNorm = 66.7324, GNorm = 0.0649, lr_0 = 1.0509e-04
Loss = 1.1045e-05, PNorm = 66.7330, GNorm = 0.0478, lr_0 = 1.0463e-04
Loss = 1.0193e-05, PNorm = 66.7334, GNorm = 0.0478, lr_0 = 1.0416e-04
Loss = 9.2495e-06, PNorm = 66.7336, GNorm = 0.0336, lr_0 = 1.0370e-04
Loss = 1.0403e-05, PNorm = 66.7352, GNorm = 0.0653, lr_0 = 1.0324e-04
Loss = 7.8175e-06, PNorm = 66.7362, GNorm = 0.1097, lr_0 = 1.0279e-04
Loss = 1.1563e-05, PNorm = 66.7363, GNorm = 0.0869, lr_0 = 1.0274e-04
Validation rmse logD = 0.602581
Validation R2 logD = 0.719986
Epoch 97
Train function
Loss = 7.2503e-06, PNorm = 66.7368, GNorm = 0.0506, lr_0 = 1.0229e-04
Loss = 8.7518e-06, PNorm = 66.7372, GNorm = 0.0944, lr_0 = 1.0183e-04
Loss = 8.2991e-06, PNorm = 66.7380, GNorm = 0.0629, lr_0 = 1.0138e-04
Loss = 1.1377e-05, PNorm = 66.7393, GNorm = 0.1167, lr_0 = 1.0094e-04
Loss = 9.7233e-06, PNorm = 66.7394, GNorm = 0.0493, lr_0 = 1.0049e-04
Validation rmse logD = 0.603103
Validation R2 logD = 0.719501
Epoch 98
Train function
Loss = 7.9763e-06, PNorm = 66.7397, GNorm = 0.0582, lr_0 = 1.0000e-04
Loss = 7.6788e-06, PNorm = 66.7407, GNorm = 0.1256, lr_0 = 1.0000e-04
Loss = 1.4091e-05, PNorm = 66.7417, GNorm = 0.2260, lr_0 = 1.0000e-04
Loss = 1.2799e-05, PNorm = 66.7433, GNorm = 0.0666, lr_0 = 1.0000e-04
Loss = 9.7378e-06, PNorm = 66.7440, GNorm = 0.0325, lr_0 = 1.0000e-04
Validation rmse logD = 0.601367
Validation R2 logD = 0.721113
Epoch 99
Train function
Loss = 7.2996e-06, PNorm = 66.7451, GNorm = 0.1349, lr_0 = 1.0000e-04
Loss = 9.9935e-06, PNorm = 66.7460, GNorm = 0.2200, lr_0 = 1.0000e-04
Loss = 1.2950e-05, PNorm = 66.7468, GNorm = 0.1205, lr_0 = 1.0000e-04
Loss = 8.8198e-06, PNorm = 66.7476, GNorm = 0.0521, lr_0 = 1.0000e-04
Loss = 9.8828e-06, PNorm = 66.7491, GNorm = 0.0948, lr_0 = 1.0000e-04
Loss = 1.4308e-05, PNorm = 66.7499, GNorm = 0.1824, lr_0 = 1.0000e-04
Validation rmse logD = 0.600797
Validation R2 logD = 0.721641
Model 0 best validation rmse = 0.581935 on epoch 35
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.593836
Model 0 test R2 logD = 0.756106
Ensemble test rmse  logD= 0.593836
Ensemble test R2  logD= 0.756106
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_301/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=125, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,500,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1497e-02, PNorm = 55.2141, GNorm = 1.4134, lr_0 = 1.9340e-04
Loss = 1.8759e-02, PNorm = 55.2217, GNorm = 1.6854, lr_0 = 2.7830e-04
Loss = 1.8010e-02, PNorm = 55.2365, GNorm = 2.3473, lr_0 = 3.6321e-04
Loss = 1.6341e-02, PNorm = 55.2647, GNorm = 6.4599, lr_0 = 4.4811e-04
Loss = 1.4700e-02, PNorm = 55.2999, GNorm = 6.4375, lr_0 = 5.3302e-04
Validation rmse logD = 1.038599
Validation R2 logD = 0.288208
Epoch 1
Train function
Loss = 1.8319e-02, PNorm = 55.3566, GNorm = 6.1969, lr_0 = 6.2642e-04
Loss = 1.5050e-02, PNorm = 55.4329, GNorm = 1.1703, lr_0 = 7.1132e-04
Loss = 1.3355e-02, PNorm = 55.5131, GNorm = 6.1424, lr_0 = 7.9623e-04
Loss = 1.2220e-02, PNorm = 55.6050, GNorm = 3.7098, lr_0 = 8.8113e-04
Loss = 1.5595e-02, PNorm = 55.7040, GNorm = 5.7029, lr_0 = 9.6604e-04
Validation rmse logD = 1.036418
Validation R2 logD = 0.291194
Epoch 2
Train function
Loss = 1.3311e-02, PNorm = 55.8293, GNorm = 1.4763, lr_0 = 9.9690e-04
Loss = 1.0565e-02, PNorm = 55.9650, GNorm = 2.0131, lr_0 = 9.9249e-04
Loss = 1.1594e-02, PNorm = 56.0735, GNorm = 1.3058, lr_0 = 9.8810e-04
Loss = 9.9558e-03, PNorm = 56.1744, GNorm = 1.6676, lr_0 = 9.8373e-04
Loss = 1.0598e-02, PNorm = 56.3057, GNorm = 5.1651, lr_0 = 9.7938e-04
Validation rmse logD = 0.854451
Validation R2 logD = 0.518239
Epoch 3
Train function
Loss = 8.3758e-03, PNorm = 56.3962, GNorm = 1.3855, lr_0 = 9.7462e-04
Loss = 9.5644e-03, PNorm = 56.4838, GNorm = 1.5858, lr_0 = 9.7030e-04
Loss = 9.4595e-03, PNorm = 56.5818, GNorm = 3.4142, lr_0 = 9.6601e-04
Loss = 8.7701e-03, PNorm = 56.6968, GNorm = 4.1774, lr_0 = 9.6174e-04
Loss = 8.2437e-03, PNorm = 56.7925, GNorm = 1.5747, lr_0 = 9.5749e-04
Loss = 1.0102e-02, PNorm = 56.9099, GNorm = 1.7061, lr_0 = 9.5325e-04
Validation rmse logD = 0.842913
Validation R2 logD = 0.531162
Epoch 4
Train function
Loss = 9.1161e-03, PNorm = 57.0177, GNorm = 1.2852, lr_0 = 9.4861e-04
Loss = 7.7227e-03, PNorm = 57.1056, GNorm = 3.3739, lr_0 = 9.4442e-04
Loss = 8.1342e-03, PNorm = 57.2057, GNorm = 3.1133, lr_0 = 9.4024e-04
Loss = 7.8767e-03, PNorm = 57.3019, GNorm = 1.5058, lr_0 = 9.3608e-04
Loss = 7.9808e-03, PNorm = 57.3918, GNorm = 3.4270, lr_0 = 9.3194e-04
Validation rmse logD = 0.766837
Validation R2 logD = 0.611971
Epoch 5
Train function
Loss = 6.8997e-03, PNorm = 57.4945, GNorm = 0.9094, lr_0 = 9.2741e-04
Loss = 6.5637e-03, PNorm = 57.5935, GNorm = 1.1786, lr_0 = 9.2330e-04
Loss = 7.1123e-03, PNorm = 57.6756, GNorm = 2.7212, lr_0 = 9.1922e-04
Loss = 5.5258e-03, PNorm = 57.7665, GNorm = 1.2454, lr_0 = 9.1515e-04
Loss = 6.9877e-03, PNorm = 57.8504, GNorm = 1.4089, lr_0 = 9.1111e-04
Validation rmse logD = 0.743969
Validation R2 logD = 0.634770
Epoch 6
Train function
Loss = 8.2876e-03, PNorm = 57.9534, GNorm = 5.7005, lr_0 = 9.0667e-04
Loss = 7.2812e-03, PNorm = 58.0788, GNorm = 4.8751, lr_0 = 9.0266e-04
Loss = 7.7717e-03, PNorm = 58.1935, GNorm = 1.1751, lr_0 = 8.9867e-04
Loss = 5.1973e-03, PNorm = 58.3137, GNorm = 1.6226, lr_0 = 8.9469e-04
Loss = 6.1300e-03, PNorm = 58.4202, GNorm = 2.0577, lr_0 = 8.9074e-04
Loss = 7.0958e-03, PNorm = 58.5146, GNorm = 1.2341, lr_0 = 8.8680e-04
Validation rmse logD = 0.683201
Validation R2 logD = 0.691997
Epoch 7
Train function
Loss = 6.5311e-03, PNorm = 58.5979, GNorm = 1.0327, lr_0 = 8.8248e-04
Loss = 5.8143e-03, PNorm = 58.7201, GNorm = 1.5169, lr_0 = 8.7858e-04
Loss = 6.3311e-03, PNorm = 58.8355, GNorm = 0.7404, lr_0 = 8.7469e-04
Loss = 5.2518e-03, PNorm = 58.9423, GNorm = 1.1420, lr_0 = 8.7082e-04
Loss = 5.2378e-03, PNorm = 59.0292, GNorm = 2.5734, lr_0 = 8.6697e-04
Validation rmse logD = 0.824544
Validation R2 logD = 0.551374
Epoch 8
Train function
Loss = 6.1760e-03, PNorm = 59.1260, GNorm = 1.5672, lr_0 = 8.6276e-04
Loss = 4.8179e-03, PNorm = 59.2233, GNorm = 1.3887, lr_0 = 8.5894e-04
Loss = 4.3172e-03, PNorm = 59.3080, GNorm = 1.4082, lr_0 = 8.5514e-04
Loss = 4.5673e-03, PNorm = 59.3973, GNorm = 1.7514, lr_0 = 8.5136e-04
Loss = 5.2327e-03, PNorm = 59.4710, GNorm = 1.8798, lr_0 = 8.4759e-04
Validation rmse logD = 0.676888
Validation R2 logD = 0.697663
Epoch 9
Train function
Loss = 3.0018e-03, PNorm = 59.5521, GNorm = 1.0840, lr_0 = 8.4384e-04
Loss = 4.1639e-03, PNorm = 59.6282, GNorm = 0.9181, lr_0 = 8.4011e-04
Loss = 3.9517e-03, PNorm = 59.7201, GNorm = 0.6585, lr_0 = 8.3639e-04
Loss = 4.2509e-03, PNorm = 59.8051, GNorm = 0.7535, lr_0 = 8.3269e-04
Loss = 4.6175e-03, PNorm = 59.8893, GNorm = 1.1323, lr_0 = 8.2901e-04
Loss = 4.3180e-03, PNorm = 59.9629, GNorm = 1.2601, lr_0 = 8.2534e-04
Validation rmse logD = 0.630067
Validation R2 logD = 0.738042
Epoch 10
Train function
Loss = 4.4712e-03, PNorm = 60.0544, GNorm = 2.2283, lr_0 = 8.2133e-04
Loss = 4.1580e-03, PNorm = 60.1464, GNorm = 2.0725, lr_0 = 8.1770e-04
Loss = 4.0019e-03, PNorm = 60.2418, GNorm = 0.9243, lr_0 = 8.1408e-04
Loss = 3.3006e-03, PNorm = 60.3162, GNorm = 1.0107, lr_0 = 8.1048e-04
Loss = 3.3534e-03, PNorm = 60.3885, GNorm = 0.9007, lr_0 = 8.0689e-04
Validation rmse logD = 0.647423
Validation R2 logD = 0.723412
Epoch 11
Train function
Loss = 4.6816e-03, PNorm = 60.5092, GNorm = 1.8760, lr_0 = 8.0297e-04
Loss = 3.4937e-03, PNorm = 60.6198, GNorm = 1.2215, lr_0 = 7.9942e-04
Loss = 3.4651e-03, PNorm = 60.7202, GNorm = 1.2251, lr_0 = 7.9588e-04
Loss = 4.3679e-03, PNorm = 60.8304, GNorm = 2.2490, lr_0 = 7.9236e-04
Loss = 3.2546e-03, PNorm = 60.9343, GNorm = 1.5143, lr_0 = 7.8885e-04
Validation rmse logD = 0.617905
Validation R2 logD = 0.748058
Epoch 12
Train function
Loss = 2.6978e-03, PNorm = 61.0235, GNorm = 0.7145, lr_0 = 7.8502e-04
Loss = 3.4746e-03, PNorm = 61.1012, GNorm = 1.5260, lr_0 = 7.8154e-04
Loss = 2.8436e-03, PNorm = 61.1652, GNorm = 2.6921, lr_0 = 7.7809e-04
Loss = 3.0204e-03, PNorm = 61.2431, GNorm = 1.2308, lr_0 = 7.7465e-04
Loss = 2.8161e-03, PNorm = 61.3118, GNorm = 0.7545, lr_0 = 7.7122e-04
Loss = 2.9814e-03, PNorm = 61.3752, GNorm = 1.1533, lr_0 = 7.6781e-04
Loss = 2.1307e-02, PNorm = 61.3839, GNorm = 3.1532, lr_0 = 7.6747e-04
Validation rmse logD = 0.639392
Validation R2 logD = 0.730232
Epoch 13
Train function
Loss = 2.9858e-03, PNorm = 61.4448, GNorm = 0.6943, lr_0 = 7.6407e-04
Loss = 2.6556e-03, PNorm = 61.5250, GNorm = 1.5884, lr_0 = 7.6069e-04
Loss = 2.5813e-03, PNorm = 61.5896, GNorm = 1.1317, lr_0 = 7.5733e-04
Loss = 2.9599e-03, PNorm = 61.6514, GNorm = 0.7067, lr_0 = 7.5398e-04
Loss = 2.5087e-03, PNorm = 61.7136, GNorm = 1.4170, lr_0 = 7.5064e-04
Validation rmse logD = 0.651459
Validation R2 logD = 0.719953
Epoch 14
Train function
Loss = 4.3286e-03, PNorm = 61.7957, GNorm = 2.3863, lr_0 = 7.4699e-04
Loss = 3.1844e-03, PNorm = 61.8844, GNorm = 2.7113, lr_0 = 7.4369e-04
Loss = 2.4851e-03, PNorm = 61.9516, GNorm = 1.6784, lr_0 = 7.4040e-04
Loss = 2.3088e-03, PNorm = 62.0203, GNorm = 0.8398, lr_0 = 7.3712e-04
Loss = 2.2926e-03, PNorm = 62.0766, GNorm = 1.2044, lr_0 = 7.3386e-04
Validation rmse logD = 0.630501
Validation R2 logD = 0.737681
Epoch 15
Train function
Loss = 2.2443e-03, PNorm = 62.1322, GNorm = 2.0840, lr_0 = 7.3029e-04
Loss = 2.1923e-03, PNorm = 62.1919, GNorm = 0.6175, lr_0 = 7.2706e-04
Loss = 1.6456e-03, PNorm = 62.2432, GNorm = 1.1683, lr_0 = 7.2385e-04
Loss = 1.9183e-03, PNorm = 62.3026, GNorm = 1.4870, lr_0 = 7.2064e-04
Loss = 1.9586e-03, PNorm = 62.3480, GNorm = 0.7775, lr_0 = 7.1746e-04
Validation rmse logD = 0.598544
Validation R2 logD = 0.763599
Epoch 16
Train function
Loss = 1.1246e-03, PNorm = 62.3971, GNorm = 1.2971, lr_0 = 7.1397e-04
Loss = 1.6311e-03, PNorm = 62.4442, GNorm = 1.0741, lr_0 = 7.1081e-04
Loss = 1.7012e-03, PNorm = 62.4895, GNorm = 1.1856, lr_0 = 7.0766e-04
Loss = 1.8224e-03, PNorm = 62.5402, GNorm = 0.8019, lr_0 = 7.0453e-04
Loss = 1.8378e-03, PNorm = 62.5734, GNorm = 1.2383, lr_0 = 7.0142e-04
Loss = 1.9860e-03, PNorm = 62.6197, GNorm = 1.0901, lr_0 = 6.9831e-04
Validation rmse logD = 0.588757
Validation R2 logD = 0.771267
Epoch 17
Train function
Loss = 1.6127e-03, PNorm = 62.6877, GNorm = 1.9439, lr_0 = 6.9523e-04
Loss = 1.6779e-03, PNorm = 62.7417, GNorm = 1.6208, lr_0 = 6.9215e-04
Loss = 1.6280e-03, PNorm = 62.7871, GNorm = 0.8379, lr_0 = 6.8909e-04
Loss = 1.6806e-03, PNorm = 62.8456, GNorm = 0.5266, lr_0 = 6.8604e-04
Loss = 1.8443e-03, PNorm = 62.8986, GNorm = 0.7262, lr_0 = 6.8301e-04
Validation rmse logD = 0.600421
Validation R2 logD = 0.762114
Epoch 18
Train function
Loss = 1.3853e-03, PNorm = 62.9510, GNorm = 0.5976, lr_0 = 6.7968e-04
Loss = 1.2590e-03, PNorm = 63.0072, GNorm = 0.8912, lr_0 = 6.7668e-04
Loss = 1.0706e-03, PNorm = 63.0426, GNorm = 0.4323, lr_0 = 6.7368e-04
Loss = 1.4114e-03, PNorm = 63.0766, GNorm = 0.6166, lr_0 = 6.7070e-04
Loss = 1.4397e-03, PNorm = 63.1191, GNorm = 0.7069, lr_0 = 6.6774e-04
Validation rmse logD = 0.581694
Validation R2 logD = 0.776722
Epoch 19
Train function
Loss = 6.9598e-04, PNorm = 63.1531, GNorm = 0.7199, lr_0 = 6.6449e-04
Loss = 1.2953e-03, PNorm = 63.1883, GNorm = 1.6514, lr_0 = 6.6155e-04
Loss = 1.2672e-03, PNorm = 63.2384, GNorm = 0.6692, lr_0 = 6.5862e-04
Loss = 1.2622e-03, PNorm = 63.2790, GNorm = 0.6489, lr_0 = 6.5571e-04
Loss = 1.5532e-03, PNorm = 63.3264, GNorm = 0.6970, lr_0 = 6.5281e-04
Loss = 1.4871e-03, PNorm = 63.3709, GNorm = 1.3330, lr_0 = 6.4992e-04
Validation rmse logD = 0.591091
Validation R2 logD = 0.769450
Epoch 20
Train function
Loss = 1.2565e-03, PNorm = 63.4145, GNorm = 1.4616, lr_0 = 6.4676e-04
Loss = 1.2464e-03, PNorm = 63.4555, GNorm = 1.8790, lr_0 = 6.4390e-04
Loss = 1.1356e-03, PNorm = 63.4942, GNorm = 1.3017, lr_0 = 6.4105e-04
Loss = 1.0348e-03, PNorm = 63.5397, GNorm = 0.3468, lr_0 = 6.3822e-04
Loss = 1.1243e-03, PNorm = 63.5797, GNorm = 1.4999, lr_0 = 6.3539e-04
Validation rmse logD = 0.586944
Validation R2 logD = 0.772673
Epoch 21
Train function
Loss = 7.6817e-04, PNorm = 63.6075, GNorm = 0.4101, lr_0 = 6.3230e-04
Loss = 8.7042e-04, PNorm = 63.6396, GNorm = 0.4171, lr_0 = 6.2950e-04
Loss = 9.0013e-04, PNorm = 63.6709, GNorm = 0.6114, lr_0 = 6.2672e-04
Loss = 1.0504e-03, PNorm = 63.7014, GNorm = 1.0901, lr_0 = 6.2395e-04
Loss = 8.8841e-04, PNorm = 63.7336, GNorm = 0.7799, lr_0 = 6.2119e-04
Validation rmse logD = 0.608000
Validation R2 logD = 0.756070
Epoch 22
Train function
Loss = 1.5408e-03, PNorm = 63.7607, GNorm = 2.9474, lr_0 = 6.1817e-04
Loss = 1.1183e-03, PNorm = 63.8061, GNorm = 2.1433, lr_0 = 6.1543e-04
Loss = 9.9330e-04, PNorm = 63.8474, GNorm = 0.5336, lr_0 = 6.1271e-04
Loss = 9.0295e-04, PNorm = 63.8858, GNorm = 0.3136, lr_0 = 6.1000e-04
Loss = 1.1023e-03, PNorm = 63.9152, GNorm = 1.7150, lr_0 = 6.0730e-04
Loss = 1.1743e-03, PNorm = 63.9623, GNorm = 2.6571, lr_0 = 6.0461e-04
Validation rmse logD = 0.619238
Validation R2 logD = 0.746970
Epoch 23
Train function
Loss = 1.0304e-03, PNorm = 64.0060, GNorm = 0.5924, lr_0 = 6.0167e-04
Loss = 8.4209e-04, PNorm = 64.0424, GNorm = 0.4932, lr_0 = 5.9901e-04
Loss = 9.4471e-04, PNorm = 64.0773, GNorm = 0.7109, lr_0 = 5.9636e-04
Loss = 8.2781e-04, PNorm = 64.1031, GNorm = 0.4680, lr_0 = 5.9372e-04
Loss = 7.4231e-04, PNorm = 64.1313, GNorm = 0.8332, lr_0 = 5.9110e-04
Validation rmse logD = 0.589460
Validation R2 logD = 0.770720
Epoch 24
Train function
Loss = 6.3204e-04, PNorm = 64.1593, GNorm = 0.4843, lr_0 = 5.8822e-04
Loss = 6.0043e-04, PNorm = 64.1868, GNorm = 0.6227, lr_0 = 5.8562e-04
Loss = 5.6551e-04, PNorm = 64.2022, GNorm = 0.5498, lr_0 = 5.8303e-04
Loss = 8.0532e-04, PNorm = 64.2187, GNorm = 0.9326, lr_0 = 5.8045e-04
Loss = 7.2621e-04, PNorm = 64.2496, GNorm = 0.7002, lr_0 = 5.7788e-04
Validation rmse logD = 0.612353
Validation R2 logD = 0.752565
Epoch 25
Train function
Loss = 1.0557e-03, PNorm = 64.2885, GNorm = 2.3818, lr_0 = 5.7533e-04
Loss = 7.5088e-04, PNorm = 64.3129, GNorm = 1.2232, lr_0 = 5.7278e-04
Loss = 6.7248e-04, PNorm = 64.3431, GNorm = 1.1628, lr_0 = 5.7025e-04
Loss = 5.3981e-04, PNorm = 64.3673, GNorm = 0.5438, lr_0 = 5.6773e-04
Loss = 6.0258e-04, PNorm = 64.3886, GNorm = 0.6445, lr_0 = 5.6522e-04
Loss = 7.4800e-04, PNorm = 64.4109, GNorm = 0.7364, lr_0 = 5.6272e-04
Validation rmse logD = 0.589339
Validation R2 logD = 0.770814
Epoch 26
Train function
Loss = 6.0622e-04, PNorm = 64.4394, GNorm = 1.0223, lr_0 = 5.5998e-04
Loss = 6.5530e-04, PNorm = 64.4627, GNorm = 0.7767, lr_0 = 5.5750e-04
Loss = 6.2058e-04, PNorm = 64.4909, GNorm = 0.8442, lr_0 = 5.5503e-04
Loss = 4.9944e-04, PNorm = 64.5100, GNorm = 1.0459, lr_0 = 5.5258e-04
Loss = 6.6801e-04, PNorm = 64.5317, GNorm = 0.9801, lr_0 = 5.5014e-04
Validation rmse logD = 0.586892
Validation R2 logD = 0.772713
Epoch 27
Train function
Loss = 5.0651e-04, PNorm = 64.5566, GNorm = 0.3471, lr_0 = 5.4746e-04
Loss = 6.0292e-04, PNorm = 64.5800, GNorm = 0.4589, lr_0 = 5.4504e-04
Loss = 4.8426e-04, PNorm = 64.6015, GNorm = 0.3698, lr_0 = 5.4263e-04
Loss = 4.6164e-04, PNorm = 64.6192, GNorm = 0.5603, lr_0 = 5.4023e-04
Loss = 6.1711e-04, PNorm = 64.6344, GNorm = 0.8362, lr_0 = 5.3784e-04
Validation rmse logD = 0.602941
Validation R2 logD = 0.760113
Epoch 28
Train function
Loss = 6.2795e-04, PNorm = 64.6629, GNorm = 0.3461, lr_0 = 5.3522e-04
Loss = 4.9963e-04, PNorm = 64.6846, GNorm = 0.9930, lr_0 = 5.3285e-04
Loss = 4.4598e-04, PNorm = 64.7065, GNorm = 0.4502, lr_0 = 5.3050e-04
Loss = 4.5242e-04, PNorm = 64.7238, GNorm = 0.6134, lr_0 = 5.2815e-04
Loss = 4.6397e-04, PNorm = 64.7441, GNorm = 0.4323, lr_0 = 5.2581e-04
Loss = 4.6854e-04, PNorm = 64.7572, GNorm = 0.3858, lr_0 = 5.2349e-04
Loss = 1.5234e-03, PNorm = 64.7583, GNorm = 0.6831, lr_0 = 5.2326e-04
Validation rmse logD = 0.579205
Validation R2 logD = 0.778628
Epoch 29
Train function
Loss = 3.7060e-04, PNorm = 64.7722, GNorm = 0.3851, lr_0 = 5.2094e-04
Loss = 3.8275e-04, PNorm = 64.7855, GNorm = 0.4425, lr_0 = 5.1864e-04
Loss = 4.1710e-04, PNorm = 64.8063, GNorm = 0.4340, lr_0 = 5.1634e-04
Loss = 3.8176e-04, PNorm = 64.8275, GNorm = 0.3806, lr_0 = 5.1406e-04
Loss = 4.5826e-04, PNorm = 64.8410, GNorm = 0.3970, lr_0 = 5.1178e-04
Validation rmse logD = 0.584497
Validation R2 logD = 0.774565
Epoch 30
Train function
Loss = 3.2337e-04, PNorm = 64.8609, GNorm = 0.5261, lr_0 = 5.0930e-04
Loss = 4.3920e-04, PNorm = 64.8774, GNorm = 0.6490, lr_0 = 5.0704e-04
Loss = 3.9546e-04, PNorm = 64.9023, GNorm = 0.4114, lr_0 = 5.0480e-04
Loss = 3.7828e-04, PNorm = 64.9187, GNorm = 0.7259, lr_0 = 5.0257e-04
Loss = 4.5429e-04, PNorm = 64.9325, GNorm = 0.7846, lr_0 = 5.0034e-04
Validation rmse logD = 0.593507
Validation R2 logD = 0.767561
Epoch 31
Train function
Loss = 4.0083e-04, PNorm = 64.9577, GNorm = 0.4450, lr_0 = 4.9791e-04
Loss = 3.5270e-04, PNorm = 64.9758, GNorm = 0.3522, lr_0 = 4.9571e-04
Loss = 3.3069e-04, PNorm = 64.9925, GNorm = 0.3283, lr_0 = 4.9351e-04
Loss = 3.1131e-04, PNorm = 65.0146, GNorm = 0.9448, lr_0 = 4.9133e-04
Loss = 3.6810e-04, PNorm = 65.0315, GNorm = 0.3963, lr_0 = 4.8916e-04
Validation rmse logD = 0.581944
Validation R2 logD = 0.776530
Epoch 32
Train function
Loss = 2.3348e-04, PNorm = 65.0459, GNorm = 0.3506, lr_0 = 4.8678e-04
Loss = 4.4852e-04, PNorm = 65.0648, GNorm = 0.5072, lr_0 = 4.8463e-04
Loss = 4.1375e-04, PNorm = 65.0826, GNorm = 0.3864, lr_0 = 4.8248e-04
Loss = 4.2477e-04, PNorm = 65.1009, GNorm = 1.3053, lr_0 = 4.8035e-04
Loss = 4.0894e-04, PNorm = 65.1177, GNorm = 0.7743, lr_0 = 4.7822e-04
Loss = 3.5667e-04, PNorm = 65.1364, GNorm = 0.4478, lr_0 = 4.7611e-04
Validation rmse logD = 0.585060
Validation R2 logD = 0.774130
Epoch 33
Train function
Loss = 3.8869e-04, PNorm = 65.1557, GNorm = 0.6981, lr_0 = 4.7379e-04
Loss = 4.1867e-04, PNorm = 65.1671, GNorm = 0.4845, lr_0 = 4.7170e-04
Loss = 3.7896e-04, PNorm = 65.1832, GNorm = 0.4673, lr_0 = 4.6961e-04
Loss = 4.0110e-04, PNorm = 65.1992, GNorm = 0.8590, lr_0 = 4.6753e-04
Loss = 2.6643e-04, PNorm = 65.2168, GNorm = 0.3805, lr_0 = 4.6546e-04
Validation rmse logD = 0.580701
Validation R2 logD = 0.777483
Epoch 34
Train function
Loss = 3.3144e-04, PNorm = 65.2336, GNorm = 0.8527, lr_0 = 4.6341e-04
Loss = 3.0013e-04, PNorm = 65.2457, GNorm = 0.3585, lr_0 = 4.6136e-04
Loss = 2.4959e-04, PNorm = 65.2568, GNorm = 0.2449, lr_0 = 4.5931e-04
Loss = 2.3886e-04, PNorm = 65.2715, GNorm = 0.4161, lr_0 = 4.5728e-04
Loss = 3.3562e-04, PNorm = 65.2824, GNorm = 0.6395, lr_0 = 4.5526e-04
Validation rmse logD = 0.597581
Validation R2 logD = 0.764359
Epoch 35
Train function
Loss = 1.9319e-04, PNorm = 65.2964, GNorm = 0.8083, lr_0 = 4.5305e-04
Loss = 3.5568e-04, PNorm = 65.3102, GNorm = 0.8711, lr_0 = 4.5104e-04
Loss = 3.0030e-04, PNorm = 65.3303, GNorm = 0.9222, lr_0 = 4.4905e-04
Loss = 2.5835e-04, PNorm = 65.3450, GNorm = 0.8424, lr_0 = 4.4706e-04
Loss = 2.8356e-04, PNorm = 65.3604, GNorm = 0.4160, lr_0 = 4.4508e-04
Loss = 2.6026e-04, PNorm = 65.3734, GNorm = 0.3896, lr_0 = 4.4311e-04
Validation rmse logD = 0.584783
Validation R2 logD = 0.774344
Epoch 36
Train function
Loss = 2.0379e-04, PNorm = 65.3834, GNorm = 0.3820, lr_0 = 4.4096e-04
Loss = 2.6822e-04, PNorm = 65.3915, GNorm = 0.2510, lr_0 = 4.3901e-04
Loss = 2.6127e-04, PNorm = 65.4061, GNorm = 0.4088, lr_0 = 4.3707e-04
Loss = 2.9307e-04, PNorm = 65.4209, GNorm = 1.1125, lr_0 = 4.3513e-04
Loss = 2.4814e-04, PNorm = 65.4335, GNorm = 0.3441, lr_0 = 4.3321e-04
Validation rmse logD = 0.585593
Validation R2 logD = 0.773719
Epoch 37
Train function
Loss = 2.8144e-04, PNorm = 65.4516, GNorm = 0.4172, lr_0 = 4.3110e-04
Loss = 2.1168e-04, PNorm = 65.4608, GNorm = 0.4374, lr_0 = 4.2919e-04
Loss = 3.2468e-04, PNorm = 65.4718, GNorm = 0.4970, lr_0 = 4.2729e-04
Loss = 2.9137e-04, PNorm = 65.4837, GNorm = 0.7823, lr_0 = 4.2540e-04
Loss = 2.7398e-04, PNorm = 65.4986, GNorm = 0.7634, lr_0 = 4.2352e-04
Validation rmse logD = 0.580326
Validation R2 logD = 0.777770
Epoch 38
Train function
Loss = 2.7870e-04, PNorm = 65.5145, GNorm = 0.4774, lr_0 = 4.2146e-04
Loss = 3.5087e-04, PNorm = 65.5379, GNorm = 0.5571, lr_0 = 4.1960e-04
Loss = 3.6980e-04, PNorm = 65.5560, GNorm = 0.4735, lr_0 = 4.1774e-04
Loss = 2.4448e-04, PNorm = 65.5689, GNorm = 0.6418, lr_0 = 4.1589e-04
Loss = 2.2427e-04, PNorm = 65.5793, GNorm = 0.2749, lr_0 = 4.1406e-04
Loss = 2.6829e-04, PNorm = 65.5925, GNorm = 0.3435, lr_0 = 4.1222e-04
Validation rmse logD = 0.584567
Validation R2 logD = 0.774511
Epoch 39
Train function
Loss = 2.7209e-04, PNorm = 65.6046, GNorm = 0.2568, lr_0 = 4.1022e-04
Loss = 2.3154e-04, PNorm = 65.6192, GNorm = 0.1985, lr_0 = 4.0840e-04
Loss = 2.7639e-04, PNorm = 65.6279, GNorm = 0.5239, lr_0 = 4.0660e-04
Loss = 2.1201e-04, PNorm = 65.6355, GNorm = 0.2526, lr_0 = 4.0480e-04
Loss = 2.4144e-04, PNorm = 65.6444, GNorm = 0.5939, lr_0 = 4.0301e-04
Validation rmse logD = 0.595576
Validation R2 logD = 0.765938
Epoch 40
Train function
Loss = 3.3243e-04, PNorm = 65.6591, GNorm = 0.8016, lr_0 = 4.0105e-04
Loss = 4.1539e-04, PNorm = 65.6728, GNorm = 0.3452, lr_0 = 3.9927e-04
Loss = 2.8732e-04, PNorm = 65.6854, GNorm = 0.4522, lr_0 = 3.9751e-04
Loss = 3.2534e-04, PNorm = 65.6981, GNorm = 0.7364, lr_0 = 3.9575e-04
Loss = 2.7577e-04, PNorm = 65.7147, GNorm = 0.6070, lr_0 = 3.9400e-04
Validation rmse logD = 0.589477
Validation R2 logD = 0.770707
Epoch 41
Train function
Loss = 2.0290e-04, PNorm = 65.7325, GNorm = 0.3022, lr_0 = 3.9208e-04
Loss = 2.5869e-04, PNorm = 65.7395, GNorm = 0.4982, lr_0 = 3.9035e-04
Loss = 2.6021e-04, PNorm = 65.7491, GNorm = 0.3132, lr_0 = 3.8862e-04
Loss = 2.3456e-04, PNorm = 65.7587, GNorm = 0.4641, lr_0 = 3.8690e-04
Loss = 1.6983e-04, PNorm = 65.7679, GNorm = 0.3963, lr_0 = 3.8519e-04
Loss = 1.6442e-04, PNorm = 65.7722, GNorm = 0.2906, lr_0 = 3.8349e-04
Validation rmse logD = 0.582803
Validation R2 logD = 0.775869
Epoch 42
Train function
Loss = 1.8256e-04, PNorm = 65.7813, GNorm = 0.3783, lr_0 = 3.8179e-04
Loss = 1.4516e-04, PNorm = 65.7909, GNorm = 0.1640, lr_0 = 3.8010e-04
Loss = 1.4977e-04, PNorm = 65.7979, GNorm = 0.5258, lr_0 = 3.7842e-04
Loss = 1.7476e-04, PNorm = 65.8038, GNorm = 0.5636, lr_0 = 3.7675e-04
Loss = 1.4395e-04, PNorm = 65.8128, GNorm = 0.5811, lr_0 = 3.7508e-04
Validation rmse logD = 0.580556
Validation R2 logD = 0.777595
Epoch 43
Train function
Loss = 1.3672e-04, PNorm = 65.8210, GNorm = 0.3605, lr_0 = 3.7326e-04
Loss = 1.3896e-04, PNorm = 65.8287, GNorm = 0.2587, lr_0 = 3.7160e-04
Loss = 1.2358e-04, PNorm = 65.8346, GNorm = 0.3555, lr_0 = 3.6996e-04
Loss = 1.2716e-04, PNorm = 65.8400, GNorm = 0.3120, lr_0 = 3.6832e-04
Loss = 1.6339e-04, PNorm = 65.8457, GNorm = 0.3171, lr_0 = 3.6669e-04
Validation rmse logD = 0.582858
Validation R2 logD = 0.775827
Epoch 44
Train function
Loss = 1.3862e-04, PNorm = 65.8517, GNorm = 0.2379, lr_0 = 3.6491e-04
Loss = 1.2567e-04, PNorm = 65.8550, GNorm = 0.5153, lr_0 = 3.6330e-04
Loss = 1.3865e-04, PNorm = 65.8604, GNorm = 0.2716, lr_0 = 3.6169e-04
Loss = 1.2339e-04, PNorm = 65.8686, GNorm = 0.4471, lr_0 = 3.6009e-04
Loss = 1.5230e-04, PNorm = 65.8760, GNorm = 0.2270, lr_0 = 3.5850e-04
Loss = 1.2605e-04, PNorm = 65.8869, GNorm = 0.5890, lr_0 = 3.5691e-04
Loss = 6.2465e-04, PNorm = 65.8879, GNorm = 0.5786, lr_0 = 3.5675e-04
Validation rmse logD = 0.579679
Validation R2 logD = 0.778266
Epoch 45
Train function
Loss = 1.0094e-04, PNorm = 65.8937, GNorm = 0.1779, lr_0 = 3.5518e-04
Loss = 1.1687e-04, PNorm = 65.8974, GNorm = 0.6458, lr_0 = 3.5360e-04
Loss = 1.2737e-04, PNorm = 65.9025, GNorm = 0.5718, lr_0 = 3.5204e-04
Loss = 1.4010e-04, PNorm = 65.9120, GNorm = 0.6123, lr_0 = 3.5048e-04
Loss = 1.5595e-04, PNorm = 65.9185, GNorm = 0.4673, lr_0 = 3.4893e-04
Validation rmse logD = 0.584879
Validation R2 logD = 0.774270
Epoch 46
Train function
Loss = 1.2241e-04, PNorm = 65.9251, GNorm = 0.2097, lr_0 = 3.4724e-04
Loss = 1.0938e-04, PNorm = 65.9306, GNorm = 0.1945, lr_0 = 3.4570e-04
Loss = 1.1548e-04, PNorm = 65.9364, GNorm = 0.1593, lr_0 = 3.4417e-04
Loss = 1.0650e-04, PNorm = 65.9412, GNorm = 0.2189, lr_0 = 3.4265e-04
Loss = 1.0264e-04, PNorm = 65.9493, GNorm = 0.2644, lr_0 = 3.4113e-04
Validation rmse logD = 0.581199
Validation R2 logD = 0.777102
Epoch 47
Train function
Loss = 9.3093e-05, PNorm = 65.9546, GNorm = 0.1993, lr_0 = 3.3947e-04
Loss = 9.3157e-05, PNorm = 65.9609, GNorm = 0.2421, lr_0 = 3.3797e-04
Loss = 1.3242e-04, PNorm = 65.9683, GNorm = 0.3763, lr_0 = 3.3648e-04
Loss = 1.0555e-04, PNorm = 65.9741, GNorm = 0.5343, lr_0 = 3.3499e-04
Loss = 1.0612e-04, PNorm = 65.9818, GNorm = 0.6005, lr_0 = 3.3351e-04
Validation rmse logD = 0.580209
Validation R2 logD = 0.777860
Epoch 48
Train function
Loss = 1.4877e-04, PNorm = 65.9858, GNorm = 0.1772, lr_0 = 3.3188e-04
Loss = 1.0238e-04, PNorm = 65.9924, GNorm = 0.4299, lr_0 = 3.3042e-04
Loss = 1.1855e-04, PNorm = 65.9978, GNorm = 0.2419, lr_0 = 3.2895e-04
Loss = 1.3542e-04, PNorm = 66.0038, GNorm = 1.1535, lr_0 = 3.2750e-04
Loss = 1.3147e-04, PNorm = 66.0111, GNorm = 0.6434, lr_0 = 3.2605e-04
Loss = 1.3439e-04, PNorm = 66.0186, GNorm = 0.5133, lr_0 = 3.2461e-04
Validation rmse logD = 0.580941
Validation R2 logD = 0.777299
Epoch 49
Train function
Loss = 1.5661e-04, PNorm = 66.0254, GNorm = 0.4016, lr_0 = 3.2303e-04
Loss = 1.0341e-04, PNorm = 66.0324, GNorm = 0.1657, lr_0 = 3.2160e-04
Loss = 1.1878e-04, PNorm = 66.0395, GNorm = 0.2700, lr_0 = 3.2018e-04
Loss = 1.4647e-04, PNorm = 66.0467, GNorm = 0.4317, lr_0 = 3.1876e-04
Loss = 1.2570e-04, PNorm = 66.0542, GNorm = 0.2200, lr_0 = 3.1735e-04
Validation rmse logD = 0.579203
Validation R2 logD = 0.778630
Epoch 50
Train function
Loss = 1.2667e-04, PNorm = 66.0578, GNorm = 0.1908, lr_0 = 3.1595e-04
Loss = 1.3182e-04, PNorm = 66.0609, GNorm = 0.5978, lr_0 = 3.1455e-04
Loss = 1.0624e-04, PNorm = 66.0666, GNorm = 0.6926, lr_0 = 3.1316e-04
Loss = 9.2449e-05, PNorm = 66.0733, GNorm = 0.1643, lr_0 = 3.1177e-04
Loss = 1.2383e-04, PNorm = 66.0804, GNorm = 0.4421, lr_0 = 3.1039e-04
Validation rmse logD = 0.582587
Validation R2 logD = 0.776036
Epoch 51
Train function
Loss = 6.2249e-05, PNorm = 66.0898, GNorm = 0.1873, lr_0 = 3.0888e-04
Loss = 7.9043e-05, PNorm = 66.0966, GNorm = 0.4877, lr_0 = 3.0752e-04
Loss = 1.1011e-04, PNorm = 66.1013, GNorm = 0.8465, lr_0 = 3.0616e-04
Loss = 1.0397e-04, PNorm = 66.1067, GNorm = 0.1870, lr_0 = 3.0480e-04
Loss = 9.2707e-05, PNorm = 66.1107, GNorm = 0.1864, lr_0 = 3.0346e-04
Loss = 8.9252e-05, PNorm = 66.1158, GNorm = 0.2930, lr_0 = 3.0211e-04
Validation rmse logD = 0.581872
Validation R2 logD = 0.776585
Epoch 52
Train function
Loss = 7.8272e-05, PNorm = 66.1191, GNorm = 0.1903, lr_0 = 3.0064e-04
Loss = 9.4256e-05, PNorm = 66.1224, GNorm = 0.2342, lr_0 = 2.9931e-04
Loss = 9.8893e-05, PNorm = 66.1279, GNorm = 0.3339, lr_0 = 2.9799e-04
Loss = 1.1027e-04, PNorm = 66.1323, GNorm = 0.2242, lr_0 = 2.9667e-04
Loss = 9.5302e-05, PNorm = 66.1405, GNorm = 0.4798, lr_0 = 2.9536e-04
Validation rmse logD = 0.585162
Validation R2 logD = 0.774051
Epoch 53
Train function
Loss = 9.3224e-05, PNorm = 66.1491, GNorm = 0.3541, lr_0 = 2.9392e-04
Loss = 9.0645e-05, PNorm = 66.1532, GNorm = 0.3330, lr_0 = 2.9262e-04
Loss = 8.6646e-05, PNorm = 66.1595, GNorm = 0.2521, lr_0 = 2.9133e-04
Loss = 9.1654e-05, PNorm = 66.1624, GNorm = 0.3267, lr_0 = 2.9004e-04
Loss = 1.0362e-04, PNorm = 66.1671, GNorm = 0.7472, lr_0 = 2.8876e-04
Validation rmse logD = 0.584712
Validation R2 logD = 0.774399
Epoch 54
Train function
Loss = 9.8201e-05, PNorm = 66.1717, GNorm = 0.6290, lr_0 = 2.8735e-04
Loss = 9.1470e-05, PNorm = 66.1765, GNorm = 0.3157, lr_0 = 2.8608e-04
Loss = 1.0706e-04, PNorm = 66.1836, GNorm = 0.8245, lr_0 = 2.8482e-04
Loss = 9.8475e-05, PNorm = 66.1883, GNorm = 0.6947, lr_0 = 2.8356e-04
Loss = 1.2379e-04, PNorm = 66.1940, GNorm = 0.3604, lr_0 = 2.8230e-04
Loss = 6.7955e-05, PNorm = 66.1992, GNorm = 0.1169, lr_0 = 2.8105e-04
Validation rmse logD = 0.581766
Validation R2 logD = 0.776667
Epoch 55
Train function
Loss = 7.2929e-05, PNorm = 66.2028, GNorm = 0.2023, lr_0 = 2.7969e-04
Loss = 7.5005e-05, PNorm = 66.2069, GNorm = 0.2086, lr_0 = 2.7845e-04
Loss = 5.4901e-05, PNorm = 66.2110, GNorm = 0.2386, lr_0 = 2.7722e-04
Loss = 8.0415e-05, PNorm = 66.2145, GNorm = 0.2168, lr_0 = 2.7599e-04
Loss = 8.1121e-05, PNorm = 66.2182, GNorm = 0.1688, lr_0 = 2.7477e-04
Validation rmse logD = 0.582193
Validation R2 logD = 0.776338
Epoch 56
Train function
Loss = 6.0947e-05, PNorm = 66.2249, GNorm = 0.4993, lr_0 = 2.7343e-04
Loss = 8.0743e-05, PNorm = 66.2284, GNorm = 0.2813, lr_0 = 2.7222e-04
Loss = 5.9996e-05, PNorm = 66.2299, GNorm = 0.2285, lr_0 = 2.7102e-04
Loss = 8.3490e-05, PNorm = 66.2334, GNorm = 0.2598, lr_0 = 2.6982e-04
Loss = 7.1020e-05, PNorm = 66.2383, GNorm = 0.2656, lr_0 = 2.6863e-04
Validation rmse logD = 0.589129
Validation R2 logD = 0.770977
Epoch 57
Train function
Loss = 1.2983e-04, PNorm = 66.2429, GNorm = 0.1677, lr_0 = 2.6732e-04
Loss = 8.7523e-05, PNorm = 66.2491, GNorm = 0.3435, lr_0 = 2.6614e-04
Loss = 8.2647e-05, PNorm = 66.2538, GNorm = 0.1326, lr_0 = 2.6496e-04
Loss = 6.1449e-05, PNorm = 66.2569, GNorm = 0.1987, lr_0 = 2.6379e-04
Loss = 7.4516e-05, PNorm = 66.2624, GNorm = 0.2355, lr_0 = 2.6262e-04
Loss = 6.5792e-05, PNorm = 66.2655, GNorm = 0.2200, lr_0 = 2.6146e-04
Loss = 2.0284e-03, PNorm = 66.2660, GNorm = 1.2491, lr_0 = 2.6134e-04
Validation rmse logD = 0.586144
Validation R2 logD = 0.773293
Epoch 58
Train function
Loss = 1.1553e-04, PNorm = 66.2693, GNorm = 0.6135, lr_0 = 2.6019e-04
Loss = 1.3905e-04, PNorm = 66.2721, GNorm = 0.3689, lr_0 = 2.5904e-04
Loss = 1.1482e-04, PNorm = 66.2783, GNorm = 0.2243, lr_0 = 2.5789e-04
Loss = 9.0962e-05, PNorm = 66.2862, GNorm = 0.1673, lr_0 = 2.5675e-04
Loss = 8.1127e-05, PNorm = 66.2913, GNorm = 0.2176, lr_0 = 2.5561e-04
Validation rmse logD = 0.584296
Validation R2 logD = 0.774720
Epoch 59
Train function
Loss = 7.2914e-05, PNorm = 66.2962, GNorm = 0.3343, lr_0 = 2.5448e-04
Loss = 6.9619e-05, PNorm = 66.2993, GNorm = 0.3413, lr_0 = 2.5336e-04
Loss = 8.3914e-05, PNorm = 66.3006, GNorm = 0.5975, lr_0 = 2.5224e-04
Loss = 7.6482e-05, PNorm = 66.3037, GNorm = 0.1590, lr_0 = 2.5112e-04
Loss = 7.6968e-05, PNorm = 66.3074, GNorm = 0.5182, lr_0 = 2.5001e-04
Validation rmse logD = 0.580852
Validation R2 logD = 0.777367
Epoch 60
Train function
Loss = 6.6845e-05, PNorm = 66.3114, GNorm = 0.1527, lr_0 = 2.4879e-04
Loss = 4.7957e-05, PNorm = 66.3148, GNorm = 0.1267, lr_0 = 2.4769e-04
Loss = 5.8921e-05, PNorm = 66.3198, GNorm = 0.1129, lr_0 = 2.4660e-04
Loss = 5.1995e-05, PNorm = 66.3236, GNorm = 0.1125, lr_0 = 2.4551e-04
Loss = 5.3821e-05, PNorm = 66.3276, GNorm = 0.3257, lr_0 = 2.4442e-04
Loss = 6.7661e-05, PNorm = 66.3313, GNorm = 0.1575, lr_0 = 2.4334e-04
Loss = 1.6588e-04, PNorm = 66.3315, GNorm = 0.3451, lr_0 = 2.4323e-04
Validation rmse logD = 0.579381
Validation R2 logD = 0.778494
Epoch 61
Train function
Loss = 4.0321e-05, PNorm = 66.3349, GNorm = 0.1437, lr_0 = 2.4216e-04
Loss = 4.3995e-05, PNorm = 66.3386, GNorm = 0.1668, lr_0 = 2.4109e-04
Loss = 4.3312e-05, PNorm = 66.3401, GNorm = 0.1404, lr_0 = 2.4002e-04
Loss = 4.8739e-05, PNorm = 66.3420, GNorm = 0.2577, lr_0 = 2.3896e-04
Loss = 5.0039e-05, PNorm = 66.3431, GNorm = 0.1915, lr_0 = 2.3790e-04
Validation rmse logD = 0.579162
Validation R2 logD = 0.778661
Epoch 62
Train function
Loss = 4.3736e-05, PNorm = 66.3453, GNorm = 0.1911, lr_0 = 2.3674e-04
Loss = 7.3701e-05, PNorm = 66.3491, GNorm = 0.3714, lr_0 = 2.3570e-04
Loss = 6.2259e-05, PNorm = 66.3524, GNorm = 0.2818, lr_0 = 2.3465e-04
Loss = 4.1397e-05, PNorm = 66.3554, GNorm = 0.1422, lr_0 = 2.3362e-04
Loss = 4.3948e-05, PNorm = 66.3589, GNorm = 0.1063, lr_0 = 2.3258e-04
Validation rmse logD = 0.583773
Validation R2 logD = 0.775123
Epoch 63
Train function
Loss = 4.8015e-05, PNorm = 66.3638, GNorm = 0.4075, lr_0 = 2.3145e-04
Loss = 4.3773e-05, PNorm = 66.3656, GNorm = 0.1606, lr_0 = 2.3043e-04
Loss = 4.8955e-05, PNorm = 66.3687, GNorm = 0.1575, lr_0 = 2.2941e-04
Loss = 4.0462e-05, PNorm = 66.3695, GNorm = 0.1147, lr_0 = 2.2839e-04
Loss = 3.6876e-05, PNorm = 66.3721, GNorm = 0.3661, lr_0 = 2.2738e-04
Validation rmse logD = 0.581289
Validation R2 logD = 0.777032
Epoch 64
Train function
Loss = 7.4287e-05, PNorm = 66.3744, GNorm = 0.2820, lr_0 = 2.2628e-04
Loss = 3.3439e-05, PNorm = 66.3772, GNorm = 0.0965, lr_0 = 2.2528e-04
Loss = 4.1581e-05, PNorm = 66.3798, GNorm = 0.3541, lr_0 = 2.2428e-04
Loss = 4.5041e-05, PNorm = 66.3813, GNorm = 0.3788, lr_0 = 2.2329e-04
Loss = 4.3435e-05, PNorm = 66.3845, GNorm = 0.1812, lr_0 = 2.2230e-04
Loss = 4.7382e-05, PNorm = 66.3876, GNorm = 0.2015, lr_0 = 2.2132e-04
Validation rmse logD = 0.583869
Validation R2 logD = 0.775049
Epoch 65
Train function
Loss = 3.5994e-05, PNorm = 66.3905, GNorm = 0.1245, lr_0 = 2.2024e-04
Loss = 4.3594e-05, PNorm = 66.3939, GNorm = 0.1121, lr_0 = 2.1927e-04
Loss = 4.2820e-05, PNorm = 66.3973, GNorm = 0.2869, lr_0 = 2.1830e-04
Loss = 4.0965e-05, PNorm = 66.3994, GNorm = 0.2181, lr_0 = 2.1733e-04
Loss = 4.7854e-05, PNorm = 66.4028, GNorm = 0.2202, lr_0 = 2.1637e-04
Validation rmse logD = 0.583523
Validation R2 logD = 0.775315
Epoch 66
Train function
Loss = 3.5243e-05, PNorm = 66.4034, GNorm = 0.1272, lr_0 = 2.1532e-04
Loss = 3.0149e-05, PNorm = 66.4065, GNorm = 0.1732, lr_0 = 2.1436e-04
Loss = 3.9723e-05, PNorm = 66.4082, GNorm = 0.0862, lr_0 = 2.1342e-04
Loss = 3.6456e-05, PNorm = 66.4102, GNorm = 0.2213, lr_0 = 2.1247e-04
Loss = 3.9705e-05, PNorm = 66.4115, GNorm = 0.1122, lr_0 = 2.1153e-04
Validation rmse logD = 0.582768
Validation R2 logD = 0.775897
Epoch 67
Train function
Loss = 2.0495e-05, PNorm = 66.4140, GNorm = 0.2264, lr_0 = 2.1060e-04
Loss = 3.1524e-05, PNorm = 66.4164, GNorm = 0.1230, lr_0 = 2.0966e-04
Loss = 2.6873e-05, PNorm = 66.4177, GNorm = 0.1051, lr_0 = 2.0874e-04
Loss = 3.4466e-05, PNorm = 66.4212, GNorm = 0.2101, lr_0 = 2.0781e-04
Loss = 3.2081e-05, PNorm = 66.4229, GNorm = 0.1464, lr_0 = 2.0689e-04
Loss = 3.3484e-05, PNorm = 66.4254, GNorm = 0.0919, lr_0 = 2.0598e-04
Validation rmse logD = 0.581254
Validation R2 logD = 0.777059
Epoch 68
Train function
Loss = 3.7842e-05, PNorm = 66.4277, GNorm = 0.4748, lr_0 = 2.0498e-04
Loss = 2.9023e-05, PNorm = 66.4282, GNorm = 0.2655, lr_0 = 2.0407e-04
Loss = 3.8442e-05, PNorm = 66.4301, GNorm = 0.1415, lr_0 = 2.0317e-04
Loss = 5.0856e-05, PNorm = 66.4330, GNorm = 0.0718, lr_0 = 2.0227e-04
Loss = 2.7210e-05, PNorm = 66.4360, GNorm = 0.1838, lr_0 = 2.0137e-04
Validation rmse logD = 0.582441
Validation R2 logD = 0.776148
Epoch 69
Train function
Loss = 2.5283e-05, PNorm = 66.4380, GNorm = 0.0903, lr_0 = 2.0039e-04
Loss = 3.6301e-05, PNorm = 66.4402, GNorm = 0.2866, lr_0 = 1.9951e-04
Loss = 3.5033e-05, PNorm = 66.4414, GNorm = 0.1117, lr_0 = 1.9863e-04
Loss = 3.3685e-05, PNorm = 66.4417, GNorm = 0.1796, lr_0 = 1.9775e-04
Loss = 4.0393e-05, PNorm = 66.4438, GNorm = 0.1010, lr_0 = 1.9687e-04
Validation rmse logD = 0.582092
Validation R2 logD = 0.776416
Epoch 70
Train function
Loss = 4.4008e-05, PNorm = 66.4469, GNorm = 0.1463, lr_0 = 1.9592e-04
Loss = 3.3701e-05, PNorm = 66.4495, GNorm = 0.3625, lr_0 = 1.9505e-04
Loss = 3.7559e-05, PNorm = 66.4521, GNorm = 0.4584, lr_0 = 1.9419e-04
Loss = 4.7228e-05, PNorm = 66.4557, GNorm = 0.3716, lr_0 = 1.9333e-04
Loss = 3.5660e-05, PNorm = 66.4592, GNorm = 0.1172, lr_0 = 1.9247e-04
Loss = 3.2929e-05, PNorm = 66.4607, GNorm = 0.2649, lr_0 = 1.9162e-04
Validation rmse logD = 0.583355
Validation R2 logD = 0.775445
Epoch 71
Train function
Loss = 3.3014e-05, PNorm = 66.4614, GNorm = 0.1048, lr_0 = 1.9069e-04
Loss = 3.1441e-05, PNorm = 66.4645, GNorm = 0.2002, lr_0 = 1.8984e-04
Loss = 2.6686e-05, PNorm = 66.4674, GNorm = 0.1212, lr_0 = 1.8900e-04
Loss = 4.9152e-05, PNorm = 66.4692, GNorm = 0.1310, lr_0 = 1.8817e-04
Loss = 3.6220e-05, PNorm = 66.4715, GNorm = 0.1329, lr_0 = 1.8734e-04
Validation rmse logD = 0.584438
Validation R2 logD = 0.774610
Epoch 72
Train function
Loss = 3.2179e-05, PNorm = 66.4722, GNorm = 0.1594, lr_0 = 1.8643e-04
Loss = 2.8676e-05, PNorm = 66.4732, GNorm = 0.2647, lr_0 = 1.8560e-04
Loss = 2.5694e-05, PNorm = 66.4745, GNorm = 0.0952, lr_0 = 1.8478e-04
Loss = 2.4341e-05, PNorm = 66.4764, GNorm = 0.1213, lr_0 = 1.8396e-04
Loss = 2.6332e-05, PNorm = 66.4782, GNorm = 0.1672, lr_0 = 1.8315e-04
Validation rmse logD = 0.584700
Validation R2 logD = 0.774408
Epoch 73
Train function
Loss = 3.5448e-05, PNorm = 66.4803, GNorm = 0.1097, lr_0 = 1.8226e-04
Loss = 3.9724e-05, PNorm = 66.4829, GNorm = 0.2499, lr_0 = 1.8145e-04
Loss = 2.6946e-05, PNorm = 66.4837, GNorm = 0.1919, lr_0 = 1.8065e-04
Loss = 2.4016e-05, PNorm = 66.4858, GNorm = 0.0878, lr_0 = 1.7985e-04
Loss = 2.8668e-05, PNorm = 66.4881, GNorm = 0.1341, lr_0 = 1.7905e-04
Loss = 4.0480e-05, PNorm = 66.4901, GNorm = 0.1389, lr_0 = 1.7826e-04
Loss = 3.4638e-05, PNorm = 66.4903, GNorm = 0.0977, lr_0 = 1.7818e-04
Validation rmse logD = 0.583122
Validation R2 logD = 0.775624
Epoch 74
Train function
Loss = 2.6954e-05, PNorm = 66.4914, GNorm = 0.1524, lr_0 = 1.7739e-04
Loss = 2.9125e-05, PNorm = 66.4934, GNorm = 0.0993, lr_0 = 1.7661e-04
Loss = 2.2323e-05, PNorm = 66.4946, GNorm = 0.1266, lr_0 = 1.7583e-04
Loss = 2.6419e-05, PNorm = 66.4970, GNorm = 0.2082, lr_0 = 1.7505e-04
Loss = 2.6664e-05, PNorm = 66.4995, GNorm = 0.2460, lr_0 = 1.7428e-04
Validation rmse logD = 0.582713
Validation R2 logD = 0.775939
Epoch 75
Train function
Loss = 1.9671e-05, PNorm = 66.5018, GNorm = 0.1724, lr_0 = 1.7351e-04
Loss = 2.0913e-05, PNorm = 66.5031, GNorm = 0.1058, lr_0 = 1.7274e-04
Loss = 2.0804e-05, PNorm = 66.5049, GNorm = 0.1052, lr_0 = 1.7197e-04
Loss = 2.5371e-05, PNorm = 66.5068, GNorm = 0.1678, lr_0 = 1.7121e-04
Loss = 2.2635e-05, PNorm = 66.5087, GNorm = 0.1101, lr_0 = 1.7046e-04
Validation rmse logD = 0.583080
Validation R2 logD = 0.775657
Epoch 76
Train function
Loss = 2.5666e-05, PNorm = 66.5108, GNorm = 0.1016, lr_0 = 1.6963e-04
Loss = 2.6678e-05, PNorm = 66.5120, GNorm = 0.1717, lr_0 = 1.6888e-04
Loss = 1.8656e-05, PNorm = 66.5134, GNorm = 0.0690, lr_0 = 1.6813e-04
Loss = 1.7881e-05, PNorm = 66.5146, GNorm = 0.0633, lr_0 = 1.6739e-04
Loss = 1.7139e-05, PNorm = 66.5156, GNorm = 0.1269, lr_0 = 1.6665e-04
Loss = 2.0589e-05, PNorm = 66.5173, GNorm = 0.0983, lr_0 = 1.6591e-04
Loss = 5.9623e-05, PNorm = 66.5175, GNorm = 0.1783, lr_0 = 1.6584e-04
Validation rmse logD = 0.583196
Validation R2 logD = 0.775567
Epoch 77
Train function
Loss = 1.4054e-05, PNorm = 66.5179, GNorm = 0.0830, lr_0 = 1.6510e-04
Loss = 1.4443e-05, PNorm = 66.5192, GNorm = 0.0961, lr_0 = 1.6437e-04
Loss = 2.1356e-05, PNorm = 66.5204, GNorm = 0.2180, lr_0 = 1.6364e-04
Loss = 1.5700e-05, PNorm = 66.5216, GNorm = 0.2201, lr_0 = 1.6292e-04
Loss = 2.5331e-05, PNorm = 66.5231, GNorm = 0.2582, lr_0 = 1.6220e-04
Validation rmse logD = 0.581032
Validation R2 logD = 0.777230
Epoch 78
Train function
Loss = 3.2516e-05, PNorm = 66.5264, GNorm = 0.1458, lr_0 = 1.6141e-04
Loss = 2.9209e-05, PNorm = 66.5275, GNorm = 0.1064, lr_0 = 1.6070e-04
Loss = 2.5169e-05, PNorm = 66.5287, GNorm = 0.1020, lr_0 = 1.5999e-04
Loss = 1.7824e-05, PNorm = 66.5312, GNorm = 0.0830, lr_0 = 1.5928e-04
Loss = 2.1297e-05, PNorm = 66.5316, GNorm = 0.1135, lr_0 = 1.5857e-04
Validation rmse logD = 0.583241
Validation R2 logD = 0.775532
Epoch 79
Train function
Loss = 2.2158e-05, PNorm = 66.5328, GNorm = 0.0972, lr_0 = 1.5780e-04
Loss = 2.5257e-05, PNorm = 66.5338, GNorm = 0.1168, lr_0 = 1.5710e-04
Loss = 2.5445e-05, PNorm = 66.5350, GNorm = 0.1848, lr_0 = 1.5641e-04
Loss = 1.6973e-05, PNorm = 66.5366, GNorm = 0.0862, lr_0 = 1.5572e-04
Loss = 2.0407e-05, PNorm = 66.5376, GNorm = 0.0958, lr_0 = 1.5503e-04
Validation rmse logD = 0.584107
Validation R2 logD = 0.774865
Epoch 80
Train function
Loss = 3.1350e-05, PNorm = 66.5393, GNorm = 0.1318, lr_0 = 1.5427e-04
Loss = 1.8643e-05, PNorm = 66.5412, GNorm = 0.1637, lr_0 = 1.5359e-04
Loss = 1.9810e-05, PNorm = 66.5436, GNorm = 0.1627, lr_0 = 1.5291e-04
Loss = 1.7833e-05, PNorm = 66.5439, GNorm = 0.1158, lr_0 = 1.5224e-04
Loss = 2.0641e-05, PNorm = 66.5444, GNorm = 0.2000, lr_0 = 1.5156e-04
Loss = 1.9607e-05, PNorm = 66.5458, GNorm = 0.2449, lr_0 = 1.5089e-04
Validation rmse logD = 0.584115
Validation R2 logD = 0.774859
Epoch 81
Train function
Loss = 2.9058e-05, PNorm = 66.5483, GNorm = 0.3389, lr_0 = 1.5016e-04
Loss = 3.1192e-05, PNorm = 66.5493, GNorm = 0.2604, lr_0 = 1.4949e-04
Loss = 5.0132e-05, PNorm = 66.5513, GNorm = 0.1563, lr_0 = 1.4883e-04
Loss = 3.0393e-05, PNorm = 66.5534, GNorm = 0.1627, lr_0 = 1.4817e-04
Loss = 1.8966e-05, PNorm = 66.5549, GNorm = 0.0583, lr_0 = 1.4752e-04
Validation rmse logD = 0.585193
Validation R2 logD = 0.774027
Epoch 82
Train function
Loss = 3.6189e-05, PNorm = 66.5564, GNorm = 0.4024, lr_0 = 1.4680e-04
Loss = 3.9749e-05, PNorm = 66.5613, GNorm = 0.3276, lr_0 = 1.4615e-04
Loss = 3.3536e-05, PNorm = 66.5645, GNorm = 0.1598, lr_0 = 1.4551e-04
Loss = 7.0415e-05, PNorm = 66.5678, GNorm = 0.1371, lr_0 = 1.4486e-04
Loss = 2.7851e-05, PNorm = 66.5699, GNorm = 0.1386, lr_0 = 1.4422e-04
Validation rmse logD = 0.582088
Validation R2 logD = 0.776419
Epoch 83
Train function
Loss = 1.8086e-05, PNorm = 66.5700, GNorm = 0.0921, lr_0 = 1.4352e-04
Loss = 1.8867e-05, PNorm = 66.5714, GNorm = 0.0797, lr_0 = 1.4288e-04
Loss = 2.9817e-05, PNorm = 66.5726, GNorm = 0.0960, lr_0 = 1.4225e-04
Loss = 2.3314e-05, PNorm = 66.5734, GNorm = 0.0716, lr_0 = 1.4162e-04
Loss = 2.0160e-05, PNorm = 66.5760, GNorm = 0.0720, lr_0 = 1.4100e-04
Loss = 2.0043e-05, PNorm = 66.5772, GNorm = 0.2025, lr_0 = 1.4037e-04
Validation rmse logD = 0.582118
Validation R2 logD = 0.776396
Epoch 84
Train function
Loss = 1.7602e-05, PNorm = 66.5778, GNorm = 0.1773, lr_0 = 1.3975e-04
Loss = 2.0222e-05, PNorm = 66.5780, GNorm = 0.0772, lr_0 = 1.3913e-04
Loss = 1.5217e-05, PNorm = 66.5789, GNorm = 0.1257, lr_0 = 1.3852e-04
Loss = 2.0333e-05, PNorm = 66.5797, GNorm = 0.1352, lr_0 = 1.3791e-04
Loss = 1.4667e-05, PNorm = 66.5811, GNorm = 0.1197, lr_0 = 1.3730e-04
Validation rmse logD = 0.582868
Validation R2 logD = 0.775820
Epoch 85
Train function
Loss = 1.5568e-05, PNorm = 66.5830, GNorm = 0.0467, lr_0 = 1.3663e-04
Loss = 1.4180e-05, PNorm = 66.5838, GNorm = 0.0668, lr_0 = 1.3602e-04
Loss = 1.3171e-05, PNorm = 66.5846, GNorm = 0.1114, lr_0 = 1.3542e-04
Loss = 1.4799e-05, PNorm = 66.5862, GNorm = 0.1229, lr_0 = 1.3482e-04
Loss = 1.7179e-05, PNorm = 66.5864, GNorm = 0.0836, lr_0 = 1.3423e-04
Validation rmse logD = 0.583179
Validation R2 logD = 0.775581
Epoch 86
Train function
Loss = 8.6023e-06, PNorm = 66.5867, GNorm = 0.1285, lr_0 = 1.3357e-04
Loss = 1.5818e-05, PNorm = 66.5878, GNorm = 0.0726, lr_0 = 1.3298e-04
Loss = 1.5945e-05, PNorm = 66.5897, GNorm = 0.3465, lr_0 = 1.3239e-04
Loss = 1.5984e-05, PNorm = 66.5911, GNorm = 0.1261, lr_0 = 1.3181e-04
Loss = 1.0448e-05, PNorm = 66.5923, GNorm = 0.0598, lr_0 = 1.3123e-04
Loss = 1.0684e-05, PNorm = 66.5933, GNorm = 0.1038, lr_0 = 1.3065e-04
Validation rmse logD = 0.583063
Validation R2 logD = 0.775669
Epoch 87
Train function
Loss = 1.2510e-05, PNorm = 66.5941, GNorm = 0.1094, lr_0 = 1.3001e-04
Loss = 1.6398e-05, PNorm = 66.5949, GNorm = 0.0762, lr_0 = 1.2944e-04
Loss = 1.6928e-05, PNorm = 66.5956, GNorm = 0.1173, lr_0 = 1.2886e-04
Loss = 1.3864e-05, PNorm = 66.5966, GNorm = 0.0951, lr_0 = 1.2829e-04
Loss = 1.2132e-05, PNorm = 66.5981, GNorm = 0.0435, lr_0 = 1.2773e-04
Validation rmse logD = 0.583787
Validation R2 logD = 0.775112
Epoch 88
Train function
Loss = 1.6764e-05, PNorm = 66.5997, GNorm = 0.1520, lr_0 = 1.2710e-04
Loss = 1.3177e-05, PNorm = 66.6009, GNorm = 0.0660, lr_0 = 1.2654e-04
Loss = 1.3232e-05, PNorm = 66.6019, GNorm = 0.1046, lr_0 = 1.2598e-04
Loss = 1.2128e-05, PNorm = 66.6033, GNorm = 0.0826, lr_0 = 1.2542e-04
Loss = 1.0143e-05, PNorm = 66.6049, GNorm = 0.0608, lr_0 = 1.2487e-04
Validation rmse logD = 0.584980
Validation R2 logD = 0.774192
Epoch 89
Train function
Loss = 2.6926e-05, PNorm = 66.6063, GNorm = 0.0922, lr_0 = 1.2426e-04
Loss = 1.9308e-05, PNorm = 66.6065, GNorm = 0.0618, lr_0 = 1.2371e-04
Loss = 1.6894e-05, PNorm = 66.6073, GNorm = 0.1966, lr_0 = 1.2317e-04
Loss = 1.4432e-05, PNorm = 66.6079, GNorm = 0.2188, lr_0 = 1.2262e-04
Loss = 1.2154e-05, PNorm = 66.6087, GNorm = 0.1291, lr_0 = 1.2208e-04
Loss = 1.1782e-05, PNorm = 66.6093, GNorm = 0.1199, lr_0 = 1.2154e-04
Loss = 1.5522e-05, PNorm = 66.6093, GNorm = 0.0922, lr_0 = 1.2148e-04
Validation rmse logD = 0.582925
Validation R2 logD = 0.775776
Epoch 90
Train function
Loss = 8.7262e-06, PNorm = 66.6104, GNorm = 0.0926, lr_0 = 1.2095e-04
Loss = 9.6033e-06, PNorm = 66.6115, GNorm = 0.1789, lr_0 = 1.2041e-04
Loss = 1.4297e-05, PNorm = 66.6127, GNorm = 0.2118, lr_0 = 1.1988e-04
Loss = 1.1829e-05, PNorm = 66.6143, GNorm = 0.0576, lr_0 = 1.1935e-04
Loss = 1.2727e-05, PNorm = 66.6155, GNorm = 0.0962, lr_0 = 1.1882e-04
Validation rmse logD = 0.582307
Validation R2 logD = 0.776251
Epoch 91
Train function
Loss = 1.3511e-05, PNorm = 66.6160, GNorm = 0.2738, lr_0 = 1.1824e-04
Loss = 1.3717e-05, PNorm = 66.6172, GNorm = 0.1182, lr_0 = 1.1772e-04
Loss = 1.2221e-05, PNorm = 66.6176, GNorm = 0.0817, lr_0 = 1.1720e-04
Loss = 1.5319e-05, PNorm = 66.6186, GNorm = 0.0805, lr_0 = 1.1668e-04
Loss = 1.5066e-05, PNorm = 66.6193, GNorm = 0.2530, lr_0 = 1.1616e-04
Validation rmse logD = 0.582979
Validation R2 logD = 0.775734
Epoch 92
Train function
Loss = 1.4087e-05, PNorm = 66.6207, GNorm = 0.0828, lr_0 = 1.1565e-04
Loss = 1.2743e-05, PNorm = 66.6217, GNorm = 0.0815, lr_0 = 1.1514e-04
Loss = 1.3456e-05, PNorm = 66.6224, GNorm = 0.0997, lr_0 = 1.1463e-04
Loss = 1.2220e-05, PNorm = 66.6232, GNorm = 0.0658, lr_0 = 1.1412e-04
Loss = 1.1174e-05, PNorm = 66.6242, GNorm = 0.2211, lr_0 = 1.1362e-04
Loss = 1.2840e-05, PNorm = 66.6248, GNorm = 0.1902, lr_0 = 1.1312e-04
Loss = 4.8800e-05, PNorm = 66.6250, GNorm = 0.1552, lr_0 = 1.1307e-04
Validation rmse logD = 0.583327
Validation R2 logD = 0.775467
Epoch 93
Train function
Loss = 1.0172e-05, PNorm = 66.6261, GNorm = 0.0685, lr_0 = 1.1257e-04
Loss = 8.7558e-06, PNorm = 66.6265, GNorm = 0.0743, lr_0 = 1.1207e-04
Loss = 1.1740e-05, PNorm = 66.6274, GNorm = 0.0854, lr_0 = 1.1157e-04
Loss = 1.1540e-05, PNorm = 66.6286, GNorm = 0.0795, lr_0 = 1.1108e-04
Loss = 8.6429e-06, PNorm = 66.6295, GNorm = 0.1226, lr_0 = 1.1059e-04
Validation rmse logD = 0.584867
Validation R2 logD = 0.774279
Epoch 94
Train function
Loss = 8.9952e-06, PNorm = 66.6306, GNorm = 0.0605, lr_0 = 1.1005e-04
Loss = 9.4516e-06, PNorm = 66.6311, GNorm = 0.1247, lr_0 = 1.0956e-04
Loss = 9.0040e-06, PNorm = 66.6320, GNorm = 0.0995, lr_0 = 1.0908e-04
Loss = 9.5533e-06, PNorm = 66.6329, GNorm = 0.0576, lr_0 = 1.0860e-04
Loss = 8.4131e-06, PNorm = 66.6338, GNorm = 0.0551, lr_0 = 1.0811e-04
Validation rmse logD = 0.583713
Validation R2 logD = 0.775169
Epoch 95
Train function
Loss = 1.0091e-05, PNorm = 66.6344, GNorm = 0.0715, lr_0 = 1.0759e-04
Loss = 7.6344e-06, PNorm = 66.6351, GNorm = 0.0868, lr_0 = 1.0711e-04
Loss = 7.0914e-06, PNorm = 66.6352, GNorm = 0.0680, lr_0 = 1.0664e-04
Loss = 6.7752e-06, PNorm = 66.6360, GNorm = 0.0795, lr_0 = 1.0617e-04
Loss = 1.0771e-05, PNorm = 66.6366, GNorm = 0.0723, lr_0 = 1.0570e-04
Validation rmse logD = 0.584043
Validation R2 logD = 0.774914
Epoch 96
Train function
Loss = 4.5911e-06, PNorm = 66.6377, GNorm = 0.0545, lr_0 = 1.0518e-04
Loss = 8.0643e-06, PNorm = 66.6384, GNorm = 0.0835, lr_0 = 1.0472e-04
Loss = 7.4175e-06, PNorm = 66.6389, GNorm = 0.2182, lr_0 = 1.0426e-04
Loss = 9.0641e-06, PNorm = 66.6400, GNorm = 0.1627, lr_0 = 1.0379e-04
Loss = 1.0314e-05, PNorm = 66.6411, GNorm = 0.0458, lr_0 = 1.0333e-04
Loss = 9.0727e-06, PNorm = 66.6419, GNorm = 0.0550, lr_0 = 1.0288e-04
Validation rmse logD = 0.582867
Validation R2 logD = 0.775820
Epoch 97
Train function
Loss = 1.0515e-05, PNorm = 66.6422, GNorm = 0.1601, lr_0 = 1.0238e-04
Loss = 1.1302e-05, PNorm = 66.6430, GNorm = 0.1597, lr_0 = 1.0192e-04
Loss = 1.0087e-05, PNorm = 66.6432, GNorm = 0.0806, lr_0 = 1.0147e-04
Loss = 1.1130e-05, PNorm = 66.6447, GNorm = 0.0790, lr_0 = 1.0102e-04
Loss = 1.0274e-05, PNorm = 66.6462, GNorm = 0.0447, lr_0 = 1.0058e-04
Validation rmse logD = 0.582739
Validation R2 logD = 0.775918
Epoch 98
Train function
Loss = 1.0326e-05, PNorm = 66.6469, GNorm = 0.1291, lr_0 = 1.0009e-04
Loss = 1.1062e-05, PNorm = 66.6467, GNorm = 0.1189, lr_0 = 1.0000e-04
Loss = 8.7437e-06, PNorm = 66.6478, GNorm = 0.1012, lr_0 = 1.0000e-04
Loss = 7.0393e-06, PNorm = 66.6482, GNorm = 0.0556, lr_0 = 1.0000e-04
Loss = 6.4908e-06, PNorm = 66.6485, GNorm = 0.0440, lr_0 = 1.0000e-04
Validation rmse logD = 0.583092
Validation R2 logD = 0.775647
Epoch 99
Train function
Loss = 4.1366e-06, PNorm = 66.6486, GNorm = 0.0402, lr_0 = 1.0000e-04
Loss = 5.4798e-06, PNorm = 66.6492, GNorm = 0.0977, lr_0 = 1.0000e-04
Loss = 5.7352e-06, PNorm = 66.6499, GNorm = 0.0573, lr_0 = 1.0000e-04
Loss = 6.9137e-06, PNorm = 66.6502, GNorm = 0.0762, lr_0 = 1.0000e-04
Loss = 8.9550e-06, PNorm = 66.6505, GNorm = 0.1303, lr_0 = 1.0000e-04
Loss = 1.0253e-05, PNorm = 66.6517, GNorm = 0.0662, lr_0 = 1.0000e-04
Validation rmse logD = 0.582638
Validation R2 logD = 0.775996
Model 0 best validation rmse = 0.579162 on epoch 61
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.588149
Model 0 test R2 logD = 0.760755
Ensemble test rmse  logD= 0.588149
Ensemble test R2  logD= 0.760755
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_301/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=125, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,500,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.4166e-02, PNorm = 55.2146, GNorm = 9.1807, lr_0 = 1.9340e-04
Loss = 1.9611e-02, PNorm = 55.2228, GNorm = 6.7994, lr_0 = 2.7830e-04
Loss = 1.7205e-02, PNorm = 55.2384, GNorm = 5.0232, lr_0 = 3.6321e-04
Loss = 1.5059e-02, PNorm = 55.2617, GNorm = 3.1619, lr_0 = 4.4811e-04
Loss = 1.4504e-02, PNorm = 55.2966, GNorm = 3.9928, lr_0 = 5.3302e-04
Validation rmse logD = 1.030949
Validation R2 logD = 0.286524
Epoch 1
Train function
Loss = 1.5065e-02, PNorm = 55.3622, GNorm = 6.0480, lr_0 = 6.2642e-04
Loss = 1.3068e-02, PNorm = 55.4456, GNorm = 1.8329, lr_0 = 7.1132e-04
Loss = 1.1653e-02, PNorm = 55.5238, GNorm = 3.6970, lr_0 = 7.9623e-04
Loss = 1.2268e-02, PNorm = 55.6114, GNorm = 1.1775, lr_0 = 8.8113e-04
Loss = 1.2696e-02, PNorm = 55.7403, GNorm = 1.9640, lr_0 = 9.6604e-04
Validation rmse logD = 0.904173
Validation R2 logD = 0.451208
Epoch 2
Train function
Loss = 1.1539e-02, PNorm = 55.8812, GNorm = 0.9503, lr_0 = 9.9690e-04
Loss = 1.1143e-02, PNorm = 55.9961, GNorm = 3.5447, lr_0 = 9.9249e-04
Loss = 1.0168e-02, PNorm = 56.1319, GNorm = 2.6111, lr_0 = 9.8810e-04
Loss = 9.9747e-03, PNorm = 56.2412, GNorm = 6.4257, lr_0 = 9.8373e-04
Loss = 1.0916e-02, PNorm = 56.3653, GNorm = 1.7611, lr_0 = 9.7938e-04
Validation rmse logD = 0.840604
Validation R2 logD = 0.525662
Epoch 3
Train function
Loss = 1.0737e-02, PNorm = 56.4698, GNorm = 1.4112, lr_0 = 9.7462e-04
Loss = 7.9963e-03, PNorm = 56.5765, GNorm = 2.6575, lr_0 = 9.7030e-04
Loss = 7.4139e-03, PNorm = 56.6836, GNorm = 1.2185, lr_0 = 9.6601e-04
Loss = 7.7521e-03, PNorm = 56.7999, GNorm = 1.1966, lr_0 = 9.6174e-04
Loss = 9.5571e-03, PNorm = 56.9139, GNorm = 3.6486, lr_0 = 9.5749e-04
Loss = 8.8353e-03, PNorm = 57.0228, GNorm = 1.2646, lr_0 = 9.5325e-04
Validation rmse logD = 0.833100
Validation R2 logD = 0.534093
Epoch 4
Train function
Loss = 8.2430e-03, PNorm = 57.1308, GNorm = 3.5413, lr_0 = 9.4861e-04
Loss = 8.6345e-03, PNorm = 57.2296, GNorm = 1.6250, lr_0 = 9.4442e-04
Loss = 7.6275e-03, PNorm = 57.3310, GNorm = 2.3741, lr_0 = 9.4024e-04
Loss = 7.5987e-03, PNorm = 57.4312, GNorm = 1.7061, lr_0 = 9.3608e-04
Loss = 9.5803e-03, PNorm = 57.5211, GNorm = 3.1125, lr_0 = 9.3194e-04
Validation rmse logD = 1.013650
Validation R2 logD = 0.310266
Epoch 5
Train function
Loss = 7.6816e-03, PNorm = 57.6261, GNorm = 4.0737, lr_0 = 9.2741e-04
Loss = 7.6636e-03, PNorm = 57.7160, GNorm = 2.8911, lr_0 = 9.2330e-04
Loss = 7.2446e-03, PNorm = 57.7890, GNorm = 2.8971, lr_0 = 9.1922e-04
Loss = 6.6555e-03, PNorm = 57.8877, GNorm = 1.7959, lr_0 = 9.1515e-04
Loss = 7.0979e-03, PNorm = 57.9758, GNorm = 2.2068, lr_0 = 9.1111e-04
Validation rmse logD = 0.723159
Validation R2 logD = 0.648948
Epoch 6
Train function
Loss = 4.7767e-03, PNorm = 58.0602, GNorm = 0.9092, lr_0 = 9.0667e-04
Loss = 5.9513e-03, PNorm = 58.1433, GNorm = 1.0826, lr_0 = 9.0266e-04
Loss = 5.4212e-03, PNorm = 58.2227, GNorm = 1.2398, lr_0 = 8.9867e-04
Loss = 5.6316e-03, PNorm = 58.3026, GNorm = 3.6976, lr_0 = 8.9469e-04
Loss = 5.9507e-03, PNorm = 58.3913, GNorm = 1.9239, lr_0 = 8.9074e-04
Loss = 5.2178e-03, PNorm = 58.4643, GNorm = 1.8022, lr_0 = 8.8680e-04
Validation rmse logD = 0.732195
Validation R2 logD = 0.640119
Epoch 7
Train function
Loss = 6.4660e-03, PNorm = 58.5598, GNorm = 5.0289, lr_0 = 8.8248e-04
Loss = 4.9371e-03, PNorm = 58.6653, GNorm = 2.9658, lr_0 = 8.7858e-04
Loss = 4.3004e-03, PNorm = 58.7553, GNorm = 1.3324, lr_0 = 8.7469e-04
Loss = 4.3588e-03, PNorm = 58.8282, GNorm = 3.0245, lr_0 = 8.7082e-04
Loss = 5.2495e-03, PNorm = 58.9087, GNorm = 2.2611, lr_0 = 8.6697e-04
Validation rmse logD = 0.649451
Validation R2 logD = 0.716863
Epoch 8
Train function
Loss = 4.3058e-03, PNorm = 59.0083, GNorm = 1.9402, lr_0 = 8.6276e-04
Loss = 3.8257e-03, PNorm = 59.0905, GNorm = 0.9839, lr_0 = 8.5894e-04
Loss = 4.7454e-03, PNorm = 59.1581, GNorm = 4.9145, lr_0 = 8.5514e-04
Loss = 4.6489e-03, PNorm = 59.2497, GNorm = 0.8760, lr_0 = 8.5136e-04
Loss = 4.2602e-03, PNorm = 59.3303, GNorm = 3.1636, lr_0 = 8.4759e-04
Validation rmse logD = 0.644353
Validation R2 logD = 0.721290
Epoch 9
Train function
Loss = 3.5867e-03, PNorm = 59.4175, GNorm = 2.4131, lr_0 = 8.4384e-04
Loss = 3.8718e-03, PNorm = 59.4811, GNorm = 0.8213, lr_0 = 8.4011e-04
Loss = 4.0855e-03, PNorm = 59.5752, GNorm = 1.1571, lr_0 = 8.3639e-04
Loss = 3.6798e-03, PNorm = 59.6580, GNorm = 2.0822, lr_0 = 8.3269e-04
Loss = 3.8388e-03, PNorm = 59.7427, GNorm = 2.6252, lr_0 = 8.2901e-04
Loss = 4.4810e-03, PNorm = 59.8028, GNorm = 1.5661, lr_0 = 8.2534e-04
Validation rmse logD = 0.626305
Validation R2 logD = 0.736684
Epoch 10
Train function
Loss = 3.7590e-03, PNorm = 59.8867, GNorm = 1.5102, lr_0 = 8.2133e-04
Loss = 3.7500e-03, PNorm = 59.9683, GNorm = 2.3740, lr_0 = 8.1770e-04
Loss = 3.5037e-03, PNorm = 60.0524, GNorm = 1.9493, lr_0 = 8.1408e-04
Loss = 3.5119e-03, PNorm = 60.1086, GNorm = 0.9154, lr_0 = 8.1048e-04
Loss = 3.2202e-03, PNorm = 60.1817, GNorm = 1.0945, lr_0 = 8.0689e-04
Validation rmse logD = 0.634602
Validation R2 logD = 0.729662
Epoch 11
Train function
Loss = 3.6994e-03, PNorm = 60.2774, GNorm = 3.3433, lr_0 = 8.0297e-04
Loss = 3.2476e-03, PNorm = 60.3575, GNorm = 1.8626, lr_0 = 7.9942e-04
Loss = 3.2859e-03, PNorm = 60.4385, GNorm = 1.1491, lr_0 = 7.9588e-04
Loss = 2.8702e-03, PNorm = 60.5056, GNorm = 1.6232, lr_0 = 7.9236e-04
Loss = 3.1172e-03, PNorm = 60.5721, GNorm = 1.3571, lr_0 = 7.8885e-04
Validation rmse logD = 0.617177
Validation R2 logD = 0.744304
Epoch 12
Train function
Loss = 3.3970e-03, PNorm = 60.6254, GNorm = 1.0033, lr_0 = 7.8502e-04
Loss = 2.6844e-03, PNorm = 60.6916, GNorm = 0.8332, lr_0 = 7.8154e-04
Loss = 2.3059e-03, PNorm = 60.7475, GNorm = 1.7804, lr_0 = 7.7809e-04
Loss = 2.5625e-03, PNorm = 60.8031, GNorm = 1.4672, lr_0 = 7.7465e-04
Loss = 2.6469e-03, PNorm = 60.8643, GNorm = 0.8139, lr_0 = 7.7122e-04
Loss = 2.7128e-03, PNorm = 60.9275, GNorm = 1.2719, lr_0 = 7.6781e-04
Loss = 1.7816e-02, PNorm = 60.9350, GNorm = 1.7847, lr_0 = 7.6747e-04
Validation rmse logD = 0.601182
Validation R2 logD = 0.757386
Epoch 13
Train function
Loss = 2.0021e-03, PNorm = 60.9899, GNorm = 0.9955, lr_0 = 7.6407e-04
Loss = 2.4538e-03, PNorm = 61.0464, GNorm = 2.6044, lr_0 = 7.6069e-04
Loss = 2.4786e-03, PNorm = 61.1167, GNorm = 1.2235, lr_0 = 7.5733e-04
Loss = 2.2559e-03, PNorm = 61.1812, GNorm = 1.0750, lr_0 = 7.5398e-04
Loss = 2.3260e-03, PNorm = 61.2476, GNorm = 0.8583, lr_0 = 7.5064e-04
Validation rmse logD = 0.634170
Validation R2 logD = 0.730029
Epoch 14
Train function
Loss = 2.8384e-03, PNorm = 61.3107, GNorm = 0.8122, lr_0 = 7.4699e-04
Loss = 2.2025e-03, PNorm = 61.3602, GNorm = 0.6890, lr_0 = 7.4369e-04
Loss = 2.2550e-03, PNorm = 61.4271, GNorm = 0.8504, lr_0 = 7.4040e-04
Loss = 2.0805e-03, PNorm = 61.4781, GNorm = 0.6380, lr_0 = 7.3712e-04
Loss = 2.0885e-03, PNorm = 61.5308, GNorm = 0.9811, lr_0 = 7.3386e-04
Validation rmse logD = 0.595375
Validation R2 logD = 0.762050
Epoch 15
Train function
Loss = 2.2844e-03, PNorm = 61.6053, GNorm = 0.9102, lr_0 = 7.3029e-04
Loss = 1.9977e-03, PNorm = 61.6704, GNorm = 0.6941, lr_0 = 7.2706e-04
Loss = 1.9435e-03, PNorm = 61.7389, GNorm = 1.1237, lr_0 = 7.2385e-04
Loss = 2.2218e-03, PNorm = 61.8102, GNorm = 2.3250, lr_0 = 7.2064e-04
Loss = 2.0659e-03, PNorm = 61.8732, GNorm = 2.2026, lr_0 = 7.1746e-04
Validation rmse logD = 0.627378
Validation R2 logD = 0.735781
Epoch 16
Train function
Loss = 2.2199e-03, PNorm = 61.9361, GNorm = 2.6293, lr_0 = 7.1397e-04
Loss = 2.8963e-03, PNorm = 61.9854, GNorm = 3.7187, lr_0 = 7.1081e-04
Loss = 2.2996e-03, PNorm = 62.0581, GNorm = 2.2336, lr_0 = 7.0766e-04
Loss = 1.9329e-03, PNorm = 62.1204, GNorm = 0.6795, lr_0 = 7.0453e-04
Loss = 1.8016e-03, PNorm = 62.1849, GNorm = 0.7588, lr_0 = 7.0142e-04
Loss = 1.5225e-03, PNorm = 62.2229, GNorm = 1.4058, lr_0 = 6.9831e-04
Validation rmse logD = 0.603052
Validation R2 logD = 0.755874
Epoch 17
Train function
Loss = 1.5478e-03, PNorm = 62.2685, GNorm = 0.8007, lr_0 = 6.9523e-04
Loss = 1.4010e-03, PNorm = 62.3145, GNorm = 0.5902, lr_0 = 6.9215e-04
Loss = 1.8677e-03, PNorm = 62.3504, GNorm = 2.1257, lr_0 = 6.8909e-04
Loss = 1.8572e-03, PNorm = 62.3979, GNorm = 2.6748, lr_0 = 6.8604e-04
Loss = 1.9103e-03, PNorm = 62.4638, GNorm = 2.0856, lr_0 = 6.8301e-04
Validation rmse logD = 0.589721
Validation R2 logD = 0.766547
Epoch 18
Train function
Loss = 1.0875e-03, PNorm = 62.5242, GNorm = 1.5393, lr_0 = 6.7968e-04
Loss = 1.5576e-03, PNorm = 62.5670, GNorm = 0.6635, lr_0 = 6.7668e-04
Loss = 1.3082e-03, PNorm = 62.5928, GNorm = 1.0509, lr_0 = 6.7368e-04
Loss = 1.2222e-03, PNorm = 62.6309, GNorm = 1.6296, lr_0 = 6.7070e-04
Loss = 1.4230e-03, PNorm = 62.6725, GNorm = 0.5690, lr_0 = 6.6774e-04
Validation rmse logD = 0.624209
Validation R2 logD = 0.738444
Epoch 19
Train function
Loss = 1.6894e-03, PNorm = 62.7090, GNorm = 2.5534, lr_0 = 6.6449e-04
Loss = 1.3044e-03, PNorm = 62.7481, GNorm = 0.9766, lr_0 = 6.6155e-04
Loss = 1.4502e-03, PNorm = 62.7957, GNorm = 0.6702, lr_0 = 6.5862e-04
Loss = 1.0601e-03, PNorm = 62.8360, GNorm = 1.8450, lr_0 = 6.5571e-04
Loss = 1.5297e-03, PNorm = 62.8692, GNorm = 2.2342, lr_0 = 6.5281e-04
Loss = 9.9530e-04, PNorm = 62.9070, GNorm = 0.4505, lr_0 = 6.4992e-04
Validation rmse logD = 0.580352
Validation R2 logD = 0.773906
Epoch 20
Train function
Loss = 9.9313e-04, PNorm = 62.9375, GNorm = 1.4700, lr_0 = 6.4676e-04
Loss = 1.1012e-03, PNorm = 62.9667, GNorm = 0.7870, lr_0 = 6.4390e-04
Loss = 9.5049e-04, PNorm = 62.9946, GNorm = 0.7011, lr_0 = 6.4105e-04
Loss = 8.4696e-04, PNorm = 63.0238, GNorm = 0.5695, lr_0 = 6.3822e-04
Loss = 9.5450e-04, PNorm = 63.0582, GNorm = 1.1689, lr_0 = 6.3539e-04
Validation rmse logD = 0.575215
Validation R2 logD = 0.777891
Epoch 21
Train function
Loss = 7.0590e-04, PNorm = 63.0911, GNorm = 1.1767, lr_0 = 6.3230e-04
Loss = 9.2049e-04, PNorm = 63.1162, GNorm = 0.8349, lr_0 = 6.2950e-04
Loss = 7.6057e-04, PNorm = 63.1394, GNorm = 0.6040, lr_0 = 6.2672e-04
Loss = 9.8063e-04, PNorm = 63.1626, GNorm = 0.5108, lr_0 = 6.2395e-04
Loss = 1.0443e-03, PNorm = 63.2013, GNorm = 0.6827, lr_0 = 6.2119e-04
Validation rmse logD = 0.580507
Validation R2 logD = 0.773786
Epoch 22
Train function
Loss = 7.5517e-04, PNorm = 63.2268, GNorm = 0.5668, lr_0 = 6.1817e-04
Loss = 1.1632e-03, PNorm = 63.2627, GNorm = 0.5565, lr_0 = 6.1543e-04
Loss = 1.3672e-03, PNorm = 63.2997, GNorm = 1.4716, lr_0 = 6.1271e-04
Loss = 1.0808e-03, PNorm = 63.3330, GNorm = 1.0163, lr_0 = 6.1000e-04
Loss = 1.0232e-03, PNorm = 63.3705, GNorm = 1.9805, lr_0 = 6.0730e-04
Loss = 8.7853e-04, PNorm = 63.4106, GNorm = 0.8903, lr_0 = 6.0461e-04
Validation rmse logD = 0.591507
Validation R2 logD = 0.765132
Epoch 23
Train function
Loss = 9.6945e-04, PNorm = 63.4393, GNorm = 0.6258, lr_0 = 6.0167e-04
Loss = 8.7088e-04, PNorm = 63.4735, GNorm = 0.8022, lr_0 = 5.9901e-04
Loss = 7.0042e-04, PNorm = 63.5022, GNorm = 0.4299, lr_0 = 5.9636e-04
Loss = 7.3672e-04, PNorm = 63.5273, GNorm = 0.3438, lr_0 = 5.9372e-04
Loss = 9.1271e-04, PNorm = 63.5520, GNorm = 0.6435, lr_0 = 5.9110e-04
Validation rmse logD = 0.565781
Validation R2 logD = 0.785117
Epoch 24
Train function
Loss = 7.6538e-04, PNorm = 63.5773, GNorm = 0.4371, lr_0 = 5.8822e-04
Loss = 7.3160e-04, PNorm = 63.6009, GNorm = 0.8293, lr_0 = 5.8562e-04
Loss = 6.5076e-04, PNorm = 63.6244, GNorm = 1.0566, lr_0 = 5.8303e-04
Loss = 8.2639e-04, PNorm = 63.6509, GNorm = 0.5700, lr_0 = 5.8045e-04
Loss = 8.4979e-04, PNorm = 63.6670, GNorm = 1.0562, lr_0 = 5.7788e-04
Validation rmse logD = 0.572076
Validation R2 logD = 0.780309
Epoch 25
Train function
Loss = 4.9835e-04, PNorm = 63.6984, GNorm = 0.6472, lr_0 = 5.7533e-04
Loss = 7.4802e-04, PNorm = 63.7303, GNorm = 0.8588, lr_0 = 5.7278e-04
Loss = 7.0744e-04, PNorm = 63.7564, GNorm = 0.6005, lr_0 = 5.7025e-04
Loss = 4.9807e-04, PNorm = 63.7811, GNorm = 0.7524, lr_0 = 5.6773e-04
Loss = 7.7660e-04, PNorm = 63.7935, GNorm = 0.5156, lr_0 = 5.6522e-04
Loss = 8.3730e-04, PNorm = 63.8235, GNorm = 0.8597, lr_0 = 5.6272e-04
Validation rmse logD = 0.573845
Validation R2 logD = 0.778948
Epoch 26
Train function
Loss = 6.3393e-04, PNorm = 63.8477, GNorm = 0.3929, lr_0 = 5.5998e-04
Loss = 7.3534e-04, PNorm = 63.8733, GNorm = 0.4275, lr_0 = 5.5750e-04
Loss = 6.7958e-04, PNorm = 63.8961, GNorm = 0.3914, lr_0 = 5.5503e-04
Loss = 7.4380e-04, PNorm = 63.9176, GNorm = 2.1130, lr_0 = 5.5258e-04
Loss = 7.7256e-04, PNorm = 63.9469, GNorm = 1.0128, lr_0 = 5.5014e-04
Validation rmse logD = 0.567321
Validation R2 logD = 0.783946
Epoch 27
Train function
Loss = 4.4808e-04, PNorm = 63.9743, GNorm = 0.6960, lr_0 = 5.4746e-04
Loss = 7.5550e-04, PNorm = 63.9926, GNorm = 0.4600, lr_0 = 5.4504e-04
Loss = 5.7245e-04, PNorm = 64.0106, GNorm = 0.3274, lr_0 = 5.4263e-04
Loss = 5.5341e-04, PNorm = 64.0323, GNorm = 0.7415, lr_0 = 5.4023e-04
Loss = 5.8845e-04, PNorm = 64.0475, GNorm = 1.2828, lr_0 = 5.3784e-04
Validation rmse logD = 0.570147
Validation R2 logD = 0.781788
Epoch 28
Train function
Loss = 5.4681e-04, PNorm = 64.0691, GNorm = 0.3068, lr_0 = 5.3522e-04
Loss = 4.9026e-04, PNorm = 64.0900, GNorm = 0.5417, lr_0 = 5.3285e-04
Loss = 6.5905e-04, PNorm = 64.1065, GNorm = 0.4950, lr_0 = 5.3050e-04
Loss = 5.9700e-04, PNorm = 64.1311, GNorm = 0.7122, lr_0 = 5.2815e-04
Loss = 5.8687e-04, PNorm = 64.1515, GNorm = 0.4515, lr_0 = 5.2581e-04
Loss = 6.9823e-04, PNorm = 64.1743, GNorm = 1.0894, lr_0 = 5.2349e-04
Loss = 3.6757e-03, PNorm = 64.1755, GNorm = 1.7644, lr_0 = 5.2326e-04
Validation rmse logD = 0.575565
Validation R2 logD = 0.777621
Epoch 29
Train function
Loss = 5.3232e-04, PNorm = 64.1929, GNorm = 0.3778, lr_0 = 5.2094e-04
Loss = 6.7382e-04, PNorm = 64.2218, GNorm = 0.5269, lr_0 = 5.1864e-04
Loss = 4.5923e-04, PNorm = 64.2449, GNorm = 0.7377, lr_0 = 5.1634e-04
Loss = 7.1281e-04, PNorm = 64.2669, GNorm = 2.2481, lr_0 = 5.1406e-04
Loss = 6.4300e-04, PNorm = 64.2946, GNorm = 1.2927, lr_0 = 5.1178e-04
Validation rmse logD = 0.624438
Validation R2 logD = 0.738252
Epoch 30
Train function
Loss = 9.2231e-04, PNorm = 64.3141, GNorm = 0.7142, lr_0 = 5.0930e-04
Loss = 7.8941e-04, PNorm = 64.3478, GNorm = 1.7367, lr_0 = 5.0704e-04
Loss = 6.4858e-04, PNorm = 64.3698, GNorm = 1.0814, lr_0 = 5.0480e-04
Loss = 4.9305e-04, PNorm = 64.3903, GNorm = 0.8492, lr_0 = 5.0257e-04
Loss = 4.9089e-04, PNorm = 64.4075, GNorm = 0.6605, lr_0 = 5.0034e-04
Validation rmse logD = 0.565484
Validation R2 logD = 0.785342
Epoch 31
Train function
Loss = 4.5315e-04, PNorm = 64.4348, GNorm = 0.2637, lr_0 = 4.9791e-04
Loss = 4.2175e-04, PNorm = 64.4498, GNorm = 0.2802, lr_0 = 4.9571e-04
Loss = 4.3826e-04, PNorm = 64.4655, GNorm = 0.5167, lr_0 = 4.9351e-04
Loss = 4.5937e-04, PNorm = 64.4788, GNorm = 0.4827, lr_0 = 4.9133e-04
Loss = 5.2622e-04, PNorm = 64.4967, GNorm = 0.2839, lr_0 = 4.8916e-04
Validation rmse logD = 0.557338
Validation R2 logD = 0.791483
Epoch 32
Train function
Loss = 4.7886e-04, PNorm = 64.5180, GNorm = 0.3345, lr_0 = 4.8678e-04
Loss = 4.0775e-04, PNorm = 64.5366, GNorm = 0.7774, lr_0 = 4.8463e-04
Loss = 3.3644e-04, PNorm = 64.5514, GNorm = 0.2638, lr_0 = 4.8248e-04
Loss = 4.2185e-04, PNorm = 64.5657, GNorm = 0.2967, lr_0 = 4.8035e-04
Loss = 3.2978e-04, PNorm = 64.5814, GNorm = 0.3118, lr_0 = 4.7822e-04
Loss = 3.7896e-04, PNorm = 64.5920, GNorm = 0.3293, lr_0 = 4.7611e-04
Validation rmse logD = 0.577233
Validation R2 logD = 0.776330
Epoch 33
Train function
Loss = 4.1443e-04, PNorm = 64.6057, GNorm = 0.2164, lr_0 = 4.7379e-04
Loss = 3.7863e-04, PNorm = 64.6199, GNorm = 0.3664, lr_0 = 4.7170e-04
Loss = 3.5530e-04, PNorm = 64.6362, GNorm = 1.1091, lr_0 = 4.6961e-04
Loss = 3.2419e-04, PNorm = 64.6515, GNorm = 0.7092, lr_0 = 4.6753e-04
Loss = 3.5362e-04, PNorm = 64.6640, GNorm = 0.6025, lr_0 = 4.6546e-04
Validation rmse logD = 0.562933
Validation R2 logD = 0.787275
Epoch 34
Train function
Loss = 2.9925e-04, PNorm = 64.6753, GNorm = 0.4662, lr_0 = 4.6341e-04
Loss = 3.0386e-04, PNorm = 64.6863, GNorm = 0.7303, lr_0 = 4.6136e-04
Loss = 2.5639e-04, PNorm = 64.6962, GNorm = 0.6249, lr_0 = 4.5931e-04
Loss = 3.1464e-04, PNorm = 64.7065, GNorm = 1.5089, lr_0 = 4.5728e-04
Loss = 3.4394e-04, PNorm = 64.7193, GNorm = 0.7650, lr_0 = 4.5526e-04
Validation rmse logD = 0.558843
Validation R2 logD = 0.790355
Epoch 35
Train function
Loss = 1.3698e-04, PNorm = 64.7373, GNorm = 0.2269, lr_0 = 4.5305e-04
Loss = 3.5911e-04, PNorm = 64.7517, GNorm = 0.5489, lr_0 = 4.5104e-04
Loss = 3.4489e-04, PNorm = 64.7607, GNorm = 0.5352, lr_0 = 4.4905e-04
Loss = 2.9359e-04, PNorm = 64.7767, GNorm = 0.6589, lr_0 = 4.4706e-04
Loss = 3.1395e-04, PNorm = 64.7939, GNorm = 0.4923, lr_0 = 4.4508e-04
Loss = 3.8207e-04, PNorm = 64.8099, GNorm = 0.9007, lr_0 = 4.4311e-04
Validation rmse logD = 0.563004
Validation R2 logD = 0.787221
Epoch 36
Train function
Loss = 3.5350e-04, PNorm = 64.8226, GNorm = 0.7909, lr_0 = 4.4096e-04
Loss = 2.6760e-04, PNorm = 64.8405, GNorm = 0.2795, lr_0 = 4.3901e-04
Loss = 2.8616e-04, PNorm = 64.8563, GNorm = 0.4408, lr_0 = 4.3707e-04
Loss = 2.9935e-04, PNorm = 64.8683, GNorm = 0.1748, lr_0 = 4.3513e-04
Loss = 2.8716e-04, PNorm = 64.8785, GNorm = 0.6333, lr_0 = 4.3321e-04
Validation rmse logD = 0.563344
Validation R2 logD = 0.786964
Epoch 37
Train function
Loss = 2.6832e-04, PNorm = 64.8922, GNorm = 1.0463, lr_0 = 4.3110e-04
Loss = 3.0015e-04, PNorm = 64.9034, GNorm = 0.2051, lr_0 = 4.2919e-04
Loss = 3.1952e-04, PNorm = 64.9121, GNorm = 0.2787, lr_0 = 4.2729e-04
Loss = 3.1148e-04, PNorm = 64.9272, GNorm = 0.3038, lr_0 = 4.2540e-04
Loss = 2.8112e-04, PNorm = 64.9427, GNorm = 0.6715, lr_0 = 4.2352e-04
Validation rmse logD = 0.562950
Validation R2 logD = 0.787262
Epoch 38
Train function
Loss = 2.6906e-04, PNorm = 64.9534, GNorm = 0.2950, lr_0 = 4.2146e-04
Loss = 1.9342e-04, PNorm = 64.9659, GNorm = 0.4411, lr_0 = 4.1960e-04
Loss = 2.3190e-04, PNorm = 64.9748, GNorm = 0.2783, lr_0 = 4.1774e-04
Loss = 2.6261e-04, PNorm = 64.9845, GNorm = 0.3782, lr_0 = 4.1589e-04
Loss = 2.4785e-04, PNorm = 64.9954, GNorm = 1.0090, lr_0 = 4.1406e-04
Loss = 3.0670e-04, PNorm = 65.0053, GNorm = 0.8093, lr_0 = 4.1222e-04
Validation rmse logD = 0.569993
Validation R2 logD = 0.781906
Epoch 39
Train function
Loss = 2.9844e-04, PNorm = 65.0209, GNorm = 0.4503, lr_0 = 4.1022e-04
Loss = 1.9899e-04, PNorm = 65.0298, GNorm = 0.4586, lr_0 = 4.0840e-04
Loss = 2.2781e-04, PNorm = 65.0407, GNorm = 0.7540, lr_0 = 4.0660e-04
Loss = 2.1156e-04, PNorm = 65.0513, GNorm = 0.3909, lr_0 = 4.0480e-04
Loss = 2.8422e-04, PNorm = 65.0587, GNorm = 1.5190, lr_0 = 4.0301e-04
Validation rmse logD = 0.590823
Validation R2 logD = 0.765674
Epoch 40
Train function
Loss = 4.5368e-04, PNorm = 65.0728, GNorm = 0.8855, lr_0 = 4.0105e-04
Loss = 2.5762e-04, PNorm = 65.0912, GNorm = 0.3102, lr_0 = 3.9927e-04
Loss = 2.8466e-04, PNorm = 65.1061, GNorm = 0.7642, lr_0 = 3.9751e-04
Loss = 2.5641e-04, PNorm = 65.1186, GNorm = 0.6167, lr_0 = 3.9575e-04
Loss = 2.1226e-04, PNorm = 65.1305, GNorm = 0.2642, lr_0 = 3.9400e-04
Validation rmse logD = 0.561401
Validation R2 logD = 0.788431
Epoch 41
Train function
Loss = 2.1400e-04, PNorm = 65.1401, GNorm = 0.3478, lr_0 = 3.9208e-04
Loss = 1.6785e-04, PNorm = 65.1486, GNorm = 0.3431, lr_0 = 3.9035e-04
Loss = 1.5404e-04, PNorm = 65.1575, GNorm = 0.2395, lr_0 = 3.8862e-04
Loss = 1.7150e-04, PNorm = 65.1627, GNorm = 0.2610, lr_0 = 3.8690e-04
Loss = 2.0378e-04, PNorm = 65.1669, GNorm = 0.2347, lr_0 = 3.8519e-04
Loss = 1.6771e-04, PNorm = 65.1756, GNorm = 0.3040, lr_0 = 3.8349e-04
Validation rmse logD = 0.567436
Validation R2 logD = 0.783858
Epoch 42
Train function
Loss = 1.9975e-04, PNorm = 65.1829, GNorm = 0.1894, lr_0 = 3.8179e-04
Loss = 1.8342e-04, PNorm = 65.1908, GNorm = 0.3585, lr_0 = 3.8010e-04
Loss = 1.6552e-04, PNorm = 65.2001, GNorm = 0.3169, lr_0 = 3.7842e-04
Loss = 2.0599e-04, PNorm = 65.2123, GNorm = 0.5386, lr_0 = 3.7675e-04
Loss = 1.5388e-04, PNorm = 65.2178, GNorm = 0.4889, lr_0 = 3.7508e-04
Validation rmse logD = 0.561790
Validation R2 logD = 0.788138
Epoch 43
Train function
Loss = 1.5980e-04, PNorm = 65.2269, GNorm = 0.5301, lr_0 = 3.7326e-04
Loss = 1.4115e-04, PNorm = 65.2359, GNorm = 0.2713, lr_0 = 3.7160e-04
Loss = 1.6988e-04, PNorm = 65.2468, GNorm = 0.2224, lr_0 = 3.6996e-04
Loss = 1.7702e-04, PNorm = 65.2555, GNorm = 0.3727, lr_0 = 3.6832e-04
Loss = 1.4643e-04, PNorm = 65.2620, GNorm = 0.4015, lr_0 = 3.6669e-04
Validation rmse logD = 0.562436
Validation R2 logD = 0.787650
Epoch 44
Train function
Loss = 1.2901e-04, PNorm = 65.2717, GNorm = 0.3403, lr_0 = 3.6491e-04
Loss = 1.4172e-04, PNorm = 65.2803, GNorm = 0.4207, lr_0 = 3.6330e-04
Loss = 1.5709e-04, PNorm = 65.2857, GNorm = 0.1796, lr_0 = 3.6169e-04
Loss = 1.3986e-04, PNorm = 65.2926, GNorm = 0.4749, lr_0 = 3.6009e-04
Loss = 1.4925e-04, PNorm = 65.2994, GNorm = 0.4597, lr_0 = 3.5850e-04
Loss = 1.8755e-04, PNorm = 65.3080, GNorm = 0.5395, lr_0 = 3.5691e-04
Loss = 1.3697e-03, PNorm = 65.3085, GNorm = 1.1235, lr_0 = 3.5675e-04
Validation rmse logD = 0.562000
Validation R2 logD = 0.787980
Epoch 45
Train function
Loss = 1.5187e-04, PNorm = 65.3117, GNorm = 0.4074, lr_0 = 3.5518e-04
Loss = 1.7197e-04, PNorm = 65.3192, GNorm = 0.7165, lr_0 = 3.5360e-04
Loss = 1.9852e-04, PNorm = 65.3315, GNorm = 0.4250, lr_0 = 3.5204e-04
Loss = 1.3969e-04, PNorm = 65.3410, GNorm = 0.2329, lr_0 = 3.5048e-04
Loss = 1.1945e-04, PNorm = 65.3467, GNorm = 0.2853, lr_0 = 3.4893e-04
Validation rmse logD = 0.565551
Validation R2 logD = 0.785292
Epoch 46
Train function
Loss = 1.5768e-04, PNorm = 65.3557, GNorm = 0.2836, lr_0 = 3.4724e-04
Loss = 1.5548e-04, PNorm = 65.3651, GNorm = 0.8005, lr_0 = 3.4570e-04
Loss = 1.9219e-04, PNorm = 65.3754, GNorm = 0.9239, lr_0 = 3.4417e-04
Loss = 1.3337e-04, PNorm = 65.3867, GNorm = 0.1927, lr_0 = 3.4265e-04
Loss = 1.4641e-04, PNorm = 65.3933, GNorm = 0.7960, lr_0 = 3.4113e-04
Validation rmse logD = 0.558119
Validation R2 logD = 0.790898
Epoch 47
Train function
Loss = 1.2176e-04, PNorm = 65.4028, GNorm = 0.3115, lr_0 = 3.3947e-04
Loss = 1.3060e-04, PNorm = 65.4086, GNorm = 0.3632, lr_0 = 3.3797e-04
Loss = 1.4905e-04, PNorm = 65.4119, GNorm = 0.3156, lr_0 = 3.3648e-04
Loss = 1.1365e-04, PNorm = 65.4195, GNorm = 0.2458, lr_0 = 3.3499e-04
Loss = 1.7834e-04, PNorm = 65.4269, GNorm = 0.6135, lr_0 = 3.3351e-04
Validation rmse logD = 0.561629
Validation R2 logD = 0.788259
Epoch 48
Train function
Loss = 1.3024e-04, PNorm = 65.4349, GNorm = 0.6331, lr_0 = 3.3188e-04
Loss = 1.3467e-04, PNorm = 65.4426, GNorm = 0.7081, lr_0 = 3.3042e-04
Loss = 1.1878e-04, PNorm = 65.4492, GNorm = 0.2927, lr_0 = 3.2895e-04
Loss = 9.0116e-05, PNorm = 65.4540, GNorm = 0.1311, lr_0 = 3.2750e-04
Loss = 1.1353e-04, PNorm = 65.4595, GNorm = 0.1362, lr_0 = 3.2605e-04
Loss = 1.0766e-04, PNorm = 65.4634, GNorm = 0.4949, lr_0 = 3.2461e-04
Validation rmse logD = 0.562267
Validation R2 logD = 0.787778
Epoch 49
Train function
Loss = 9.3283e-05, PNorm = 65.4706, GNorm = 0.1496, lr_0 = 3.2303e-04
Loss = 1.3256e-04, PNorm = 65.4748, GNorm = 0.2963, lr_0 = 3.2160e-04
Loss = 1.0635e-04, PNorm = 65.4820, GNorm = 0.3196, lr_0 = 3.2018e-04
Loss = 9.2982e-05, PNorm = 65.4868, GNorm = 0.4122, lr_0 = 3.1876e-04
Loss = 1.0888e-04, PNorm = 65.4915, GNorm = 0.1911, lr_0 = 3.1735e-04
Validation rmse logD = 0.562627
Validation R2 logD = 0.787507
Epoch 50
Train function
Loss = 8.3003e-05, PNorm = 65.4970, GNorm = 0.1386, lr_0 = 3.1595e-04
Loss = 9.4703e-05, PNorm = 65.5022, GNorm = 0.3538, lr_0 = 3.1455e-04
Loss = 1.0202e-04, PNorm = 65.5078, GNorm = 0.5627, lr_0 = 3.1316e-04
Loss = 1.2770e-04, PNorm = 65.5140, GNorm = 0.1800, lr_0 = 3.1177e-04
Loss = 1.0011e-04, PNorm = 65.5227, GNorm = 0.1709, lr_0 = 3.1039e-04
Validation rmse logD = 0.563977
Validation R2 logD = 0.786485
Epoch 51
Train function
Loss = 5.7365e-05, PNorm = 65.5314, GNorm = 0.3052, lr_0 = 3.0888e-04
Loss = 1.0093e-04, PNorm = 65.5379, GNorm = 0.1938, lr_0 = 3.0752e-04
Loss = 1.0336e-04, PNorm = 65.5420, GNorm = 0.2849, lr_0 = 3.0616e-04
Loss = 8.4120e-05, PNorm = 65.5470, GNorm = 0.1536, lr_0 = 3.0480e-04
Loss = 7.7454e-05, PNorm = 65.5532, GNorm = 0.3820, lr_0 = 3.0346e-04
Loss = 8.5891e-05, PNorm = 65.5565, GNorm = 0.4153, lr_0 = 3.0211e-04
Validation rmse logD = 0.564202
Validation R2 logD = 0.786315
Epoch 52
Train function
Loss = 9.4441e-05, PNorm = 65.5638, GNorm = 0.1543, lr_0 = 3.0064e-04
Loss = 9.0064e-05, PNorm = 65.5678, GNorm = 0.1995, lr_0 = 2.9931e-04
Loss = 9.4367e-05, PNorm = 65.5732, GNorm = 0.1856, lr_0 = 2.9799e-04
Loss = 9.1079e-05, PNorm = 65.5780, GNorm = 0.2670, lr_0 = 2.9667e-04
Loss = 1.0015e-04, PNorm = 65.5847, GNorm = 0.5544, lr_0 = 2.9536e-04
Validation rmse logD = 0.559685
Validation R2 logD = 0.789723
Epoch 53
Train function
Loss = 1.0278e-04, PNorm = 65.5905, GNorm = 0.2951, lr_0 = 2.9392e-04
Loss = 9.2148e-05, PNorm = 65.5964, GNorm = 0.6601, lr_0 = 2.9262e-04
Loss = 8.5294e-05, PNorm = 65.6029, GNorm = 0.2870, lr_0 = 2.9133e-04
Loss = 8.3281e-05, PNorm = 65.6090, GNorm = 0.3276, lr_0 = 2.9004e-04
Loss = 8.5289e-05, PNorm = 65.6149, GNorm = 0.2047, lr_0 = 2.8876e-04
Validation rmse logD = 0.562074
Validation R2 logD = 0.787924
Epoch 54
Train function
Loss = 6.5442e-05, PNorm = 65.6185, GNorm = 0.1886, lr_0 = 2.8735e-04
Loss = 7.2729e-05, PNorm = 65.6231, GNorm = 0.1953, lr_0 = 2.8608e-04
Loss = 9.3312e-05, PNorm = 65.6264, GNorm = 0.2245, lr_0 = 2.8482e-04
Loss = 7.0989e-05, PNorm = 65.6313, GNorm = 0.3312, lr_0 = 2.8356e-04
Loss = 7.6185e-05, PNorm = 65.6356, GNorm = 0.2190, lr_0 = 2.8230e-04
Loss = 7.8579e-05, PNorm = 65.6417, GNorm = 0.0949, lr_0 = 2.8105e-04
Validation rmse logD = 0.561759
Validation R2 logD = 0.788161
Epoch 55
Train function
Loss = 5.2127e-05, PNorm = 65.6465, GNorm = 0.1605, lr_0 = 2.7969e-04
Loss = 6.4330e-05, PNorm = 65.6499, GNorm = 0.1216, lr_0 = 2.7845e-04
Loss = 6.1650e-05, PNorm = 65.6539, GNorm = 0.4008, lr_0 = 2.7722e-04
Loss = 7.1819e-05, PNorm = 65.6580, GNorm = 0.3821, lr_0 = 2.7599e-04
Loss = 6.4559e-05, PNorm = 65.6602, GNorm = 0.1755, lr_0 = 2.7477e-04
Validation rmse logD = 0.562304
Validation R2 logD = 0.787750
Epoch 56
Train function
Loss = 5.9642e-05, PNorm = 65.6650, GNorm = 0.1666, lr_0 = 2.7343e-04
Loss = 6.5970e-05, PNorm = 65.6706, GNorm = 0.5645, lr_0 = 2.7222e-04
Loss = 6.9446e-05, PNorm = 65.6748, GNorm = 0.2709, lr_0 = 2.7102e-04
Loss = 7.4589e-05, PNorm = 65.6793, GNorm = 0.6339, lr_0 = 2.6982e-04
Loss = 9.5985e-05, PNorm = 65.6856, GNorm = 0.2434, lr_0 = 2.6863e-04
Validation rmse logD = 0.564786
Validation R2 logD = 0.785872
Epoch 57
Train function
Loss = 1.0715e-04, PNorm = 65.6933, GNorm = 0.5595, lr_0 = 2.6732e-04
Loss = 7.7964e-05, PNorm = 65.6976, GNorm = 0.1792, lr_0 = 2.6614e-04
Loss = 7.6467e-05, PNorm = 65.7016, GNorm = 0.3927, lr_0 = 2.6496e-04
Loss = 9.0796e-05, PNorm = 65.7059, GNorm = 0.1413, lr_0 = 2.6379e-04
Loss = 7.5734e-05, PNorm = 65.7121, GNorm = 0.4740, lr_0 = 2.6262e-04
Loss = 7.0423e-05, PNorm = 65.7171, GNorm = 0.1707, lr_0 = 2.6146e-04
Loss = 2.2812e-04, PNorm = 65.7176, GNorm = 0.3954, lr_0 = 2.6134e-04
Validation rmse logD = 0.564884
Validation R2 logD = 0.785798
Epoch 58
Train function
Loss = 7.3738e-05, PNorm = 65.7238, GNorm = 0.3057, lr_0 = 2.6019e-04
Loss = 5.9197e-05, PNorm = 65.7268, GNorm = 0.2515, lr_0 = 2.5904e-04
Loss = 7.2759e-05, PNorm = 65.7307, GNorm = 0.6443, lr_0 = 2.5789e-04
Loss = 7.3777e-05, PNorm = 65.7333, GNorm = 0.2307, lr_0 = 2.5675e-04
Loss = 6.3005e-05, PNorm = 65.7370, GNorm = 0.2262, lr_0 = 2.5561e-04
Validation rmse logD = 0.563797
Validation R2 logD = 0.786622
Epoch 59
Train function
Loss = 7.6675e-05, PNorm = 65.7394, GNorm = 0.1847, lr_0 = 2.5448e-04
Loss = 7.4067e-05, PNorm = 65.7435, GNorm = 0.4110, lr_0 = 2.5336e-04
Loss = 4.4834e-05, PNorm = 65.7487, GNorm = 0.1217, lr_0 = 2.5224e-04
Loss = 5.4274e-05, PNorm = 65.7528, GNorm = 0.1540, lr_0 = 2.5112e-04
Loss = 6.5086e-05, PNorm = 65.7574, GNorm = 0.2694, lr_0 = 2.5001e-04
Validation rmse logD = 0.563287
Validation R2 logD = 0.787007
Epoch 60
Train function
Loss = 3.1253e-05, PNorm = 65.7606, GNorm = 0.1023, lr_0 = 2.4879e-04
Loss = 4.9744e-05, PNorm = 65.7630, GNorm = 0.3466, lr_0 = 2.4769e-04
Loss = 4.7008e-05, PNorm = 65.7660, GNorm = 0.1101, lr_0 = 2.4660e-04
Loss = 7.3607e-05, PNorm = 65.7697, GNorm = 0.4502, lr_0 = 2.4551e-04
Loss = 5.3107e-05, PNorm = 65.7749, GNorm = 0.2068, lr_0 = 2.4442e-04
Loss = 5.7844e-05, PNorm = 65.7782, GNorm = 0.3535, lr_0 = 2.4334e-04
Loss = 2.7724e-04, PNorm = 65.7786, GNorm = 0.3381, lr_0 = 2.4323e-04
Validation rmse logD = 0.566299
Validation R2 logD = 0.784724
Epoch 61
Train function
Loss = 5.2809e-05, PNorm = 65.7811, GNorm = 0.4605, lr_0 = 2.4216e-04
Loss = 3.8742e-05, PNorm = 65.7851, GNorm = 0.1047, lr_0 = 2.4109e-04
Loss = 5.9244e-05, PNorm = 65.7886, GNorm = 0.3101, lr_0 = 2.4002e-04
Loss = 4.1077e-05, PNorm = 65.7927, GNorm = 0.0993, lr_0 = 2.3896e-04
Loss = 5.8579e-05, PNorm = 65.7960, GNorm = 0.1672, lr_0 = 2.3790e-04
Validation rmse logD = 0.566720
Validation R2 logD = 0.784403
Epoch 62
Train function
Loss = 4.6555e-05, PNorm = 65.7980, GNorm = 0.1671, lr_0 = 2.3674e-04
Loss = 4.7113e-05, PNorm = 65.8020, GNorm = 0.1424, lr_0 = 2.3570e-04
Loss = 4.2614e-05, PNorm = 65.8041, GNorm = 0.2097, lr_0 = 2.3465e-04
Loss = 6.0435e-05, PNorm = 65.8099, GNorm = 0.2036, lr_0 = 2.3362e-04
Loss = 4.1013e-05, PNorm = 65.8147, GNorm = 0.1037, lr_0 = 2.3258e-04
Validation rmse logD = 0.564680
Validation R2 logD = 0.785953
Epoch 63
Train function
Loss = 3.8325e-05, PNorm = 65.8171, GNorm = 0.1271, lr_0 = 2.3145e-04
Loss = 4.2294e-05, PNorm = 65.8179, GNorm = 0.2314, lr_0 = 2.3043e-04
Loss = 4.8391e-05, PNorm = 65.8197, GNorm = 0.4371, lr_0 = 2.2941e-04
Loss = 6.1850e-05, PNorm = 65.8247, GNorm = 0.1561, lr_0 = 2.2839e-04
Loss = 6.1206e-05, PNorm = 65.8263, GNorm = 0.3863, lr_0 = 2.2738e-04
Validation rmse logD = 0.567213
Validation R2 logD = 0.784028
Epoch 64
Train function
Loss = 4.6481e-05, PNorm = 65.8307, GNorm = 0.3058, lr_0 = 2.2628e-04
Loss = 6.5986e-05, PNorm = 65.8348, GNorm = 0.4749, lr_0 = 2.2528e-04
Loss = 8.1887e-05, PNorm = 65.8388, GNorm = 0.3210, lr_0 = 2.2428e-04
Loss = 6.4621e-05, PNorm = 65.8422, GNorm = 0.2074, lr_0 = 2.2329e-04
Loss = 7.8235e-05, PNorm = 65.8472, GNorm = 0.2584, lr_0 = 2.2230e-04
Loss = 8.3390e-05, PNorm = 65.8518, GNorm = 0.3929, lr_0 = 2.2132e-04
Validation rmse logD = 0.564009
Validation R2 logD = 0.786461
Epoch 65
Train function
Loss = 1.0002e-04, PNorm = 65.8563, GNorm = 0.4526, lr_0 = 2.2024e-04
Loss = 6.7742e-05, PNorm = 65.8605, GNorm = 0.3736, lr_0 = 2.1927e-04
Loss = 6.1568e-05, PNorm = 65.8642, GNorm = 0.3814, lr_0 = 2.1830e-04
Loss = 5.4729e-05, PNorm = 65.8685, GNorm = 0.2556, lr_0 = 2.1733e-04
Loss = 4.4397e-05, PNorm = 65.8701, GNorm = 0.2106, lr_0 = 2.1637e-04
Validation rmse logD = 0.568799
Validation R2 logD = 0.782818
Epoch 66
Train function
Loss = 5.2837e-05, PNorm = 65.8761, GNorm = 0.2037, lr_0 = 2.1532e-04
Loss = 5.0844e-05, PNorm = 65.8794, GNorm = 0.3495, lr_0 = 2.1436e-04
Loss = 4.3600e-05, PNorm = 65.8837, GNorm = 0.1710, lr_0 = 2.1342e-04
Loss = 4.2199e-05, PNorm = 65.8855, GNorm = 0.2732, lr_0 = 2.1247e-04
Loss = 3.7553e-05, PNorm = 65.8880, GNorm = 0.2111, lr_0 = 2.1153e-04
Validation rmse logD = 0.564944
Validation R2 logD = 0.785753
Epoch 67
Train function
Loss = 2.9516e-05, PNorm = 65.8899, GNorm = 0.3093, lr_0 = 2.1060e-04
Loss = 3.6453e-05, PNorm = 65.8920, GNorm = 0.1048, lr_0 = 2.0966e-04
Loss = 3.6777e-05, PNorm = 65.8943, GNorm = 0.1389, lr_0 = 2.0874e-04
Loss = 5.0873e-05, PNorm = 65.8960, GNorm = 0.2520, lr_0 = 2.0781e-04
Loss = 3.2861e-05, PNorm = 65.8987, GNorm = 0.0706, lr_0 = 2.0689e-04
Loss = 3.3510e-05, PNorm = 65.9012, GNorm = 0.2615, lr_0 = 2.0598e-04
Validation rmse logD = 0.563415
Validation R2 logD = 0.786910
Epoch 68
Train function
Loss = 2.0529e-05, PNorm = 65.9025, GNorm = 0.0938, lr_0 = 2.0498e-04
Loss = 2.6979e-05, PNorm = 65.9063, GNorm = 0.1846, lr_0 = 2.0407e-04
Loss = 2.7499e-05, PNorm = 65.9093, GNorm = 0.1037, lr_0 = 2.0317e-04
Loss = 2.6334e-05, PNorm = 65.9110, GNorm = 0.1403, lr_0 = 2.0227e-04
Loss = 4.1464e-05, PNorm = 65.9132, GNorm = 0.1540, lr_0 = 2.0137e-04
Validation rmse logD = 0.565381
Validation R2 logD = 0.785421
Epoch 69
Train function
Loss = 3.8614e-05, PNorm = 65.9161, GNorm = 0.3916, lr_0 = 2.0039e-04
Loss = 3.9685e-05, PNorm = 65.9187, GNorm = 0.3436, lr_0 = 1.9951e-04
Loss = 3.8293e-05, PNorm = 65.9204, GNorm = 0.5061, lr_0 = 1.9863e-04
Loss = 3.9640e-05, PNorm = 65.9231, GNorm = 0.0904, lr_0 = 1.9775e-04
Loss = 3.4697e-05, PNorm = 65.9257, GNorm = 0.2556, lr_0 = 1.9687e-04
Validation rmse logD = 0.562367
Validation R2 logD = 0.787702
Epoch 70
Train function
Loss = 2.4964e-05, PNorm = 65.9289, GNorm = 0.0852, lr_0 = 1.9592e-04
Loss = 2.4542e-05, PNorm = 65.9320, GNorm = 0.1581, lr_0 = 1.9505e-04
Loss = 2.9797e-05, PNorm = 65.9339, GNorm = 0.0625, lr_0 = 1.9419e-04
Loss = 3.4437e-05, PNorm = 65.9356, GNorm = 0.4556, lr_0 = 1.9333e-04
Loss = 4.2403e-05, PNorm = 65.9371, GNorm = 0.2263, lr_0 = 1.9247e-04
Loss = 3.3157e-05, PNorm = 65.9400, GNorm = 0.1512, lr_0 = 1.9162e-04
Validation rmse logD = 0.562823
Validation R2 logD = 0.787358
Epoch 71
Train function
Loss = 2.9723e-05, PNorm = 65.9421, GNorm = 0.2513, lr_0 = 1.9069e-04
Loss = 2.8868e-05, PNorm = 65.9441, GNorm = 0.3418, lr_0 = 1.8984e-04
Loss = 3.8381e-05, PNorm = 65.9455, GNorm = 0.0965, lr_0 = 1.8900e-04
Loss = 2.6190e-05, PNorm = 65.9478, GNorm = 0.1662, lr_0 = 1.8817e-04
Loss = 2.7472e-05, PNorm = 65.9503, GNorm = 0.0790, lr_0 = 1.8734e-04
Validation rmse logD = 0.563739
Validation R2 logD = 0.786666
Epoch 72
Train function
Loss = 2.9340e-05, PNorm = 65.9517, GNorm = 0.1275, lr_0 = 1.8643e-04
Loss = 2.2970e-05, PNorm = 65.9529, GNorm = 0.1861, lr_0 = 1.8560e-04
Loss = 2.6722e-05, PNorm = 65.9549, GNorm = 0.2542, lr_0 = 1.8478e-04
Loss = 2.2640e-05, PNorm = 65.9571, GNorm = 0.1817, lr_0 = 1.8396e-04
Loss = 2.9565e-05, PNorm = 65.9596, GNorm = 0.2034, lr_0 = 1.8315e-04
Validation rmse logD = 0.563253
Validation R2 logD = 0.787033
Epoch 73
Train function
Loss = 1.7124e-05, PNorm = 65.9613, GNorm = 0.0709, lr_0 = 1.8226e-04
Loss = 1.9126e-05, PNorm = 65.9623, GNorm = 0.1001, lr_0 = 1.8145e-04
Loss = 2.1346e-05, PNorm = 65.9633, GNorm = 0.0592, lr_0 = 1.8065e-04
Loss = 2.6667e-05, PNorm = 65.9653, GNorm = 0.0830, lr_0 = 1.7985e-04
Loss = 2.1967e-05, PNorm = 65.9676, GNorm = 0.0962, lr_0 = 1.7905e-04
Loss = 2.3423e-05, PNorm = 65.9701, GNorm = 0.1718, lr_0 = 1.7826e-04
Loss = 8.2016e-05, PNorm = 65.9703, GNorm = 0.1602, lr_0 = 1.7818e-04
Validation rmse logD = 0.565216
Validation R2 logD = 0.785546
Epoch 74
Train function
Loss = 2.2690e-05, PNorm = 65.9713, GNorm = 0.2246, lr_0 = 1.7739e-04
Loss = 1.9536e-05, PNorm = 65.9731, GNorm = 0.2556, lr_0 = 1.7661e-04
Loss = 3.4101e-05, PNorm = 65.9757, GNorm = 0.1012, lr_0 = 1.7583e-04
Loss = 2.0401e-05, PNorm = 65.9779, GNorm = 0.1882, lr_0 = 1.7505e-04
Loss = 2.2446e-05, PNorm = 65.9799, GNorm = 0.0448, lr_0 = 1.7428e-04
Validation rmse logD = 0.564879
Validation R2 logD = 0.785802
Epoch 75
Train function
Loss = 2.6424e-05, PNorm = 65.9811, GNorm = 0.2465, lr_0 = 1.7351e-04
Loss = 3.4566e-05, PNorm = 65.9826, GNorm = 0.1727, lr_0 = 1.7274e-04
Loss = 2.3678e-05, PNorm = 65.9854, GNorm = 0.0925, lr_0 = 1.7197e-04
Loss = 2.9192e-05, PNorm = 65.9875, GNorm = 0.1845, lr_0 = 1.7121e-04
Loss = 1.9218e-05, PNorm = 65.9896, GNorm = 0.0828, lr_0 = 1.7046e-04
Validation rmse logD = 0.565323
Validation R2 logD = 0.785465
Epoch 76
Train function
Loss = 2.4501e-05, PNorm = 65.9930, GNorm = 0.1616, lr_0 = 1.6963e-04
Loss = 2.2647e-05, PNorm = 65.9945, GNorm = 0.1148, lr_0 = 1.6888e-04
Loss = 2.9203e-05, PNorm = 65.9967, GNorm = 0.1737, lr_0 = 1.6813e-04
Loss = 2.7148e-05, PNorm = 65.9984, GNorm = 0.0673, lr_0 = 1.6739e-04
Loss = 2.2103e-05, PNorm = 66.0005, GNorm = 0.1564, lr_0 = 1.6665e-04
Loss = 1.9797e-05, PNorm = 66.0025, GNorm = 0.1491, lr_0 = 1.6591e-04
Loss = 6.6270e-05, PNorm = 66.0026, GNorm = 0.1570, lr_0 = 1.6584e-04
Validation rmse logD = 0.565641
Validation R2 logD = 0.785223
Epoch 77
Train function
Loss = 1.7763e-05, PNorm = 66.0043, GNorm = 0.0762, lr_0 = 1.6510e-04
Loss = 1.8800e-05, PNorm = 66.0054, GNorm = 0.1234, lr_0 = 1.6437e-04
Loss = 1.9451e-05, PNorm = 66.0063, GNorm = 0.1400, lr_0 = 1.6364e-04
Loss = 2.7266e-05, PNorm = 66.0091, GNorm = 0.1762, lr_0 = 1.6292e-04
Loss = 2.3457e-05, PNorm = 66.0111, GNorm = 0.1131, lr_0 = 1.6220e-04
Validation rmse logD = 0.569780
Validation R2 logD = 0.782069
Epoch 78
Train function
Loss = 2.4281e-05, PNorm = 66.0127, GNorm = 0.2839, lr_0 = 1.6141e-04
Loss = 2.6992e-05, PNorm = 66.0149, GNorm = 0.2312, lr_0 = 1.6070e-04
Loss = 2.1368e-05, PNorm = 66.0170, GNorm = 0.3333, lr_0 = 1.5999e-04
Loss = 1.8213e-05, PNorm = 66.0180, GNorm = 0.2499, lr_0 = 1.5928e-04
Loss = 3.6031e-05, PNorm = 66.0200, GNorm = 0.0894, lr_0 = 1.5857e-04
Validation rmse logD = 0.564659
Validation R2 logD = 0.785969
Epoch 79
Train function
Loss = 3.2289e-05, PNorm = 66.0213, GNorm = 0.2655, lr_0 = 1.5780e-04
Loss = 3.1544e-05, PNorm = 66.0229, GNorm = 0.1399, lr_0 = 1.5710e-04
Loss = 3.1227e-05, PNorm = 66.0245, GNorm = 0.1376, lr_0 = 1.5641e-04
Loss = 2.6888e-05, PNorm = 66.0269, GNorm = 0.1633, lr_0 = 1.5572e-04
Loss = 2.7761e-05, PNorm = 66.0285, GNorm = 0.2213, lr_0 = 1.5503e-04
Validation rmse logD = 0.566499
Validation R2 logD = 0.784572
Epoch 80
Train function
Loss = 3.6814e-05, PNorm = 66.0295, GNorm = 0.3789, lr_0 = 1.5427e-04
Loss = 2.5358e-05, PNorm = 66.0324, GNorm = 0.1041, lr_0 = 1.5359e-04
Loss = 2.2092e-05, PNorm = 66.0341, GNorm = 0.0790, lr_0 = 1.5291e-04
Loss = 2.0202e-05, PNorm = 66.0359, GNorm = 0.0888, lr_0 = 1.5224e-04
Loss = 2.0192e-05, PNorm = 66.0371, GNorm = 0.1087, lr_0 = 1.5156e-04
Loss = 2.2958e-05, PNorm = 66.0393, GNorm = 0.1466, lr_0 = 1.5089e-04
Validation rmse logD = 0.564850
Validation R2 logD = 0.785824
Epoch 81
Train function
Loss = 1.6404e-05, PNorm = 66.0409, GNorm = 0.1058, lr_0 = 1.5016e-04
Loss = 1.8324e-05, PNorm = 66.0432, GNorm = 0.1176, lr_0 = 1.4949e-04
Loss = 1.8490e-05, PNorm = 66.0454, GNorm = 0.1184, lr_0 = 1.4883e-04
Loss = 1.7201e-05, PNorm = 66.0467, GNorm = 0.0941, lr_0 = 1.4817e-04
Loss = 2.3692e-05, PNorm = 66.0479, GNorm = 0.0612, lr_0 = 1.4752e-04
Validation rmse logD = 0.565539
Validation R2 logD = 0.785301
Epoch 82
Train function
Loss = 1.7462e-05, PNorm = 66.0487, GNorm = 0.1221, lr_0 = 1.4680e-04
Loss = 1.8143e-05, PNorm = 66.0498, GNorm = 0.1342, lr_0 = 1.4615e-04
Loss = 1.8027e-05, PNorm = 66.0514, GNorm = 0.1374, lr_0 = 1.4551e-04
Loss = 1.4136e-05, PNorm = 66.0538, GNorm = 0.0647, lr_0 = 1.4486e-04
Loss = 1.9964e-05, PNorm = 66.0554, GNorm = 0.0501, lr_0 = 1.4422e-04
Validation rmse logD = 0.566432
Validation R2 logD = 0.784623
Epoch 83
Train function
Loss = 1.1372e-05, PNorm = 66.0563, GNorm = 0.0932, lr_0 = 1.4352e-04
Loss = 1.5189e-05, PNorm = 66.0572, GNorm = 0.1468, lr_0 = 1.4288e-04
Loss = 1.1714e-05, PNorm = 66.0579, GNorm = 0.1306, lr_0 = 1.4225e-04
Loss = 1.8384e-05, PNorm = 66.0592, GNorm = 0.2404, lr_0 = 1.4162e-04
Loss = 1.6678e-05, PNorm = 66.0612, GNorm = 0.1046, lr_0 = 1.4100e-04
Loss = 2.1364e-05, PNorm = 66.0626, GNorm = 0.2114, lr_0 = 1.4037e-04
Validation rmse logD = 0.565172
Validation R2 logD = 0.785580
Epoch 84
Train function
Loss = 1.0982e-05, PNorm = 66.0638, GNorm = 0.0521, lr_0 = 1.3975e-04
Loss = 1.0159e-05, PNorm = 66.0646, GNorm = 0.0761, lr_0 = 1.3913e-04
Loss = 1.8279e-05, PNorm = 66.0654, GNorm = 0.1585, lr_0 = 1.3852e-04
Loss = 1.4844e-05, PNorm = 66.0670, GNorm = 0.0872, lr_0 = 1.3791e-04
Loss = 1.4357e-05, PNorm = 66.0683, GNorm = 0.0630, lr_0 = 1.3730e-04
Validation rmse logD = 0.566148
Validation R2 logD = 0.784838
Epoch 85
Train function
Loss = 1.1362e-05, PNorm = 66.0696, GNorm = 0.0720, lr_0 = 1.3663e-04
Loss = 1.1910e-05, PNorm = 66.0712, GNorm = 0.1413, lr_0 = 1.3602e-04
Loss = 1.2901e-05, PNorm = 66.0729, GNorm = 0.0572, lr_0 = 1.3542e-04
Loss = 1.3394e-05, PNorm = 66.0742, GNorm = 0.0648, lr_0 = 1.3482e-04
Loss = 1.4011e-05, PNorm = 66.0745, GNorm = 0.0978, lr_0 = 1.3423e-04
Validation rmse logD = 0.567198
Validation R2 logD = 0.784039
Epoch 86
Train function
Loss = 1.4960e-05, PNorm = 66.0762, GNorm = 0.2807, lr_0 = 1.3357e-04
Loss = 1.9776e-05, PNorm = 66.0774, GNorm = 0.1488, lr_0 = 1.3298e-04
Loss = 1.7416e-05, PNorm = 66.0781, GNorm = 0.0726, lr_0 = 1.3239e-04
Loss = 1.5778e-05, PNorm = 66.0793, GNorm = 0.1757, lr_0 = 1.3181e-04
Loss = 9.8154e-06, PNorm = 66.0801, GNorm = 0.1593, lr_0 = 1.3123e-04
Loss = 1.8964e-05, PNorm = 66.0819, GNorm = 0.0994, lr_0 = 1.3065e-04
Validation rmse logD = 0.565442
Validation R2 logD = 0.785375
Epoch 87
Train function
Loss = 1.4202e-05, PNorm = 66.0833, GNorm = 0.0853, lr_0 = 1.3001e-04
Loss = 1.1495e-05, PNorm = 66.0847, GNorm = 0.0604, lr_0 = 1.2944e-04
Loss = 1.2950e-05, PNorm = 66.0861, GNorm = 0.0760, lr_0 = 1.2886e-04
Loss = 1.3712e-05, PNorm = 66.0870, GNorm = 0.1427, lr_0 = 1.2829e-04
Loss = 1.4461e-05, PNorm = 66.0881, GNorm = 0.1464, lr_0 = 1.2773e-04
Validation rmse logD = 0.564818
Validation R2 logD = 0.785848
Epoch 88
Train function
Loss = 1.2998e-05, PNorm = 66.0890, GNorm = 0.1420, lr_0 = 1.2710e-04
Loss = 2.0447e-05, PNorm = 66.0894, GNorm = 0.2226, lr_0 = 1.2654e-04
Loss = 1.7344e-05, PNorm = 66.0913, GNorm = 0.0720, lr_0 = 1.2598e-04
Loss = 1.7810e-05, PNorm = 66.0917, GNorm = 0.1720, lr_0 = 1.2542e-04
Loss = 1.4162e-05, PNorm = 66.0938, GNorm = 0.0811, lr_0 = 1.2487e-04
Validation rmse logD = 0.563537
Validation R2 logD = 0.786818
Epoch 89
Train function
Loss = 1.0913e-05, PNorm = 66.0952, GNorm = 0.1498, lr_0 = 1.2426e-04
Loss = 1.5788e-05, PNorm = 66.0968, GNorm = 0.1194, lr_0 = 1.2371e-04
Loss = 1.3231e-05, PNorm = 66.0980, GNorm = 0.1593, lr_0 = 1.2317e-04
Loss = 1.6914e-05, PNorm = 66.0996, GNorm = 0.0769, lr_0 = 1.2262e-04
Loss = 1.3270e-05, PNorm = 66.1007, GNorm = 0.1317, lr_0 = 1.2208e-04
Loss = 1.4872e-05, PNorm = 66.1018, GNorm = 0.1855, lr_0 = 1.2154e-04
Loss = 2.7978e-05, PNorm = 66.1019, GNorm = 0.0873, lr_0 = 1.2148e-04
Validation rmse logD = 0.565764
Validation R2 logD = 0.785130
Epoch 90
Train function
Loss = 1.1338e-05, PNorm = 66.1023, GNorm = 0.0534, lr_0 = 1.2095e-04
Loss = 1.2060e-05, PNorm = 66.1034, GNorm = 0.1015, lr_0 = 1.2041e-04
Loss = 1.1148e-05, PNorm = 66.1043, GNorm = 0.0693, lr_0 = 1.1988e-04
Loss = 8.4423e-06, PNorm = 66.1056, GNorm = 0.1695, lr_0 = 1.1935e-04
Loss = 1.1428e-05, PNorm = 66.1065, GNorm = 0.1250, lr_0 = 1.1882e-04
Validation rmse logD = 0.564791
Validation R2 logD = 0.785868
Epoch 91
Train function
Loss = 8.8678e-06, PNorm = 66.1076, GNorm = 0.0921, lr_0 = 1.1824e-04
Loss = 1.1923e-05, PNorm = 66.1085, GNorm = 0.1046, lr_0 = 1.1772e-04
Loss = 1.2167e-05, PNorm = 66.1098, GNorm = 0.0925, lr_0 = 1.1720e-04
Loss = 1.2462e-05, PNorm = 66.1113, GNorm = 0.0765, lr_0 = 1.1668e-04
Loss = 1.3045e-05, PNorm = 66.1120, GNorm = 0.1073, lr_0 = 1.1616e-04
Validation rmse logD = 0.565605
Validation R2 logD = 0.785251
Epoch 92
Train function
Loss = 1.1786e-05, PNorm = 66.1129, GNorm = 0.0575, lr_0 = 1.1565e-04
Loss = 1.7633e-05, PNorm = 66.1141, GNorm = 0.1072, lr_0 = 1.1514e-04
Loss = 1.7097e-05, PNorm = 66.1150, GNorm = 0.1503, lr_0 = 1.1463e-04
Loss = 2.2906e-05, PNorm = 66.1167, GNorm = 0.0708, lr_0 = 1.1412e-04
Loss = 1.5846e-05, PNorm = 66.1175, GNorm = 0.2292, lr_0 = 1.1362e-04
Loss = 1.3622e-05, PNorm = 66.1189, GNorm = 0.0639, lr_0 = 1.1312e-04
Loss = 2.8504e-04, PNorm = 66.1191, GNorm = 0.3103, lr_0 = 1.1307e-04
Validation rmse logD = 0.568375
Validation R2 logD = 0.783142
Epoch 93
Train function
Loss = 2.0128e-05, PNorm = 66.1202, GNorm = 0.1285, lr_0 = 1.1257e-04
Loss = 1.7769e-05, PNorm = 66.1217, GNorm = 0.2387, lr_0 = 1.1207e-04
Loss = 1.8112e-05, PNorm = 66.1223, GNorm = 0.1312, lr_0 = 1.1157e-04
Loss = 1.1828e-05, PNorm = 66.1235, GNorm = 0.1928, lr_0 = 1.1108e-04
Loss = 1.4465e-05, PNorm = 66.1241, GNorm = 0.1693, lr_0 = 1.1059e-04
Validation rmse logD = 0.564840
Validation R2 logD = 0.785831
Epoch 94
Train function
Loss = 1.0791e-05, PNorm = 66.1259, GNorm = 0.1888, lr_0 = 1.1005e-04
Loss = 1.4050e-05, PNorm = 66.1266, GNorm = 0.0663, lr_0 = 1.0956e-04
Loss = 9.2588e-06, PNorm = 66.1272, GNorm = 0.1372, lr_0 = 1.0908e-04
Loss = 1.5165e-05, PNorm = 66.1276, GNorm = 0.1748, lr_0 = 1.0860e-04
Loss = 9.9429e-06, PNorm = 66.1284, GNorm = 0.0649, lr_0 = 1.0811e-04
Validation rmse logD = 0.566238
Validation R2 logD = 0.784770
Epoch 95
Train function
Loss = 9.0243e-06, PNorm = 66.1296, GNorm = 0.0945, lr_0 = 1.0759e-04
Loss = 9.8565e-06, PNorm = 66.1310, GNorm = 0.1434, lr_0 = 1.0711e-04
Loss = 1.3242e-05, PNorm = 66.1318, GNorm = 0.2546, lr_0 = 1.0664e-04
Loss = 1.3424e-05, PNorm = 66.1324, GNorm = 0.1364, lr_0 = 1.0617e-04
Loss = 1.1695e-05, PNorm = 66.1331, GNorm = 0.0848, lr_0 = 1.0570e-04
Validation rmse logD = 0.566405
Validation R2 logD = 0.784643
Epoch 96
Train function
Loss = 1.2247e-05, PNorm = 66.1347, GNorm = 0.0723, lr_0 = 1.0518e-04
Loss = 8.4727e-06, PNorm = 66.1352, GNorm = 0.0904, lr_0 = 1.0472e-04
Loss = 8.5770e-06, PNorm = 66.1360, GNorm = 0.1020, lr_0 = 1.0426e-04
Loss = 1.0487e-05, PNorm = 66.1368, GNorm = 0.1229, lr_0 = 1.0379e-04
Loss = 1.2501e-05, PNorm = 66.1382, GNorm = 0.0845, lr_0 = 1.0333e-04
Loss = 8.1989e-06, PNorm = 66.1393, GNorm = 0.0382, lr_0 = 1.0288e-04
Validation rmse logD = 0.567349
Validation R2 logD = 0.783925
Epoch 97
Train function
Loss = 8.6098e-06, PNorm = 66.1406, GNorm = 0.0848, lr_0 = 1.0238e-04
Loss = 8.4931e-06, PNorm = 66.1411, GNorm = 0.0779, lr_0 = 1.0192e-04
Loss = 6.4014e-06, PNorm = 66.1408, GNorm = 0.0848, lr_0 = 1.0147e-04
Loss = 8.5725e-06, PNorm = 66.1412, GNorm = 0.0397, lr_0 = 1.0102e-04
Loss = 9.0536e-06, PNorm = 66.1420, GNorm = 0.2044, lr_0 = 1.0058e-04
Validation rmse logD = 0.566526
Validation R2 logD = 0.784551
Epoch 98
Train function
Loss = 1.1000e-05, PNorm = 66.1431, GNorm = 0.2285, lr_0 = 1.0009e-04
Loss = 1.1373e-05, PNorm = 66.1439, GNorm = 0.0973, lr_0 = 1.0000e-04
Loss = 8.0854e-06, PNorm = 66.1449, GNorm = 0.0578, lr_0 = 1.0000e-04
Loss = 9.6680e-06, PNorm = 66.1458, GNorm = 0.0750, lr_0 = 1.0000e-04
Loss = 8.9262e-06, PNorm = 66.1463, GNorm = 0.0494, lr_0 = 1.0000e-04
Validation rmse logD = 0.567408
Validation R2 logD = 0.783879
Epoch 99
Train function
Loss = 5.0610e-06, PNorm = 66.1478, GNorm = 0.0341, lr_0 = 1.0000e-04
Loss = 7.1144e-06, PNorm = 66.1486, GNorm = 0.1070, lr_0 = 1.0000e-04
Loss = 6.7588e-06, PNorm = 66.1490, GNorm = 0.1700, lr_0 = 1.0000e-04
Loss = 7.3878e-06, PNorm = 66.1493, GNorm = 0.1153, lr_0 = 1.0000e-04
Loss = 1.1077e-05, PNorm = 66.1501, GNorm = 0.1614, lr_0 = 1.0000e-04
Loss = 1.1994e-05, PNorm = 66.1512, GNorm = 0.2077, lr_0 = 1.0000e-04
Validation rmse logD = 0.565148
Validation R2 logD = 0.785598
Model 0 best validation rmse = 0.557338 on epoch 31
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.614422
Model 0 test R2 logD = 0.738903
Ensemble test rmse  logD= 0.614422
Ensemble test R2  logD= 0.738903
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_301/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=125, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,500,201
Moving model to cuda
Epoch 0
Train function
Loss = 1.9870e-02, PNorm = 55.2142, GNorm = 2.9412, lr_0 = 1.9340e-04
Loss = 1.7485e-02, PNorm = 55.2232, GNorm = 6.4892, lr_0 = 2.7830e-04
Loss = 1.7586e-02, PNorm = 55.2418, GNorm = 6.6587, lr_0 = 3.6321e-04
Loss = 1.7418e-02, PNorm = 55.2653, GNorm = 3.8382, lr_0 = 4.4811e-04
Loss = 1.4669e-02, PNorm = 55.3003, GNorm = 3.1935, lr_0 = 5.3302e-04
Validation rmse logD = 1.090204
Validation R2 logD = 0.172252
Epoch 1
Train function
Loss = 1.4095e-02, PNorm = 55.3604, GNorm = 1.9176, lr_0 = 6.2642e-04
Loss = 1.4490e-02, PNorm = 55.4457, GNorm = 1.4250, lr_0 = 7.1132e-04
Loss = 1.2032e-02, PNorm = 55.5607, GNorm = 1.5898, lr_0 = 7.9623e-04
Loss = 1.3887e-02, PNorm = 55.6514, GNorm = 2.7992, lr_0 = 8.8113e-04
Loss = 1.2387e-02, PNorm = 55.7572, GNorm = 5.3350, lr_0 = 9.6604e-04
Validation rmse logD = 0.872555
Validation R2 logD = 0.469764
Epoch 2
Train function
Loss = 8.4424e-03, PNorm = 55.9039, GNorm = 4.4853, lr_0 = 9.9690e-04
Loss = 1.1018e-02, PNorm = 56.0118, GNorm = 5.9743, lr_0 = 9.9249e-04
Loss = 1.0439e-02, PNorm = 56.1174, GNorm = 1.7114, lr_0 = 9.8810e-04
Loss = 8.8934e-03, PNorm = 56.2179, GNorm = 0.9154, lr_0 = 9.8373e-04
Loss = 9.9426e-03, PNorm = 56.3325, GNorm = 4.2155, lr_0 = 9.7938e-04
Validation rmse logD = 0.808991
Validation R2 logD = 0.544204
Epoch 3
Train function
Loss = 9.2014e-03, PNorm = 56.4653, GNorm = 0.9187, lr_0 = 9.7462e-04
Loss = 9.2324e-03, PNorm = 56.6003, GNorm = 1.9374, lr_0 = 9.7030e-04
Loss = 8.5797e-03, PNorm = 56.7290, GNorm = 2.5174, lr_0 = 9.6601e-04
Loss = 9.7237e-03, PNorm = 56.7997, GNorm = 2.2994, lr_0 = 9.6174e-04
Loss = 7.8549e-03, PNorm = 56.9032, GNorm = 1.2482, lr_0 = 9.5749e-04
Loss = 8.4081e-03, PNorm = 57.0142, GNorm = 2.9535, lr_0 = 9.5325e-04
Validation rmse logD = 0.766768
Validation R2 logD = 0.590541
Epoch 4
Train function
Loss = 7.2118e-03, PNorm = 57.1125, GNorm = 3.4194, lr_0 = 9.4861e-04
Loss = 8.2027e-03, PNorm = 57.1943, GNorm = 5.9896, lr_0 = 9.4442e-04
Loss = 8.4133e-03, PNorm = 57.2806, GNorm = 6.1039, lr_0 = 9.4024e-04
Loss = 7.8661e-03, PNorm = 57.3853, GNorm = 3.2756, lr_0 = 9.3608e-04
Loss = 6.8940e-03, PNorm = 57.4696, GNorm = 2.7000, lr_0 = 9.3194e-04
Validation rmse logD = 0.726253
Validation R2 logD = 0.632667
Epoch 5
Train function
Loss = 6.5396e-03, PNorm = 57.5563, GNorm = 1.9877, lr_0 = 9.2741e-04
Loss = 5.9205e-03, PNorm = 57.6537, GNorm = 1.1553, lr_0 = 9.2330e-04
Loss = 5.8620e-03, PNorm = 57.7558, GNorm = 5.7168, lr_0 = 9.1922e-04
Loss = 7.4631e-03, PNorm = 57.8239, GNorm = 2.0055, lr_0 = 9.1515e-04
Loss = 7.5919e-03, PNorm = 57.9254, GNorm = 2.4447, lr_0 = 9.1111e-04
Validation rmse logD = 0.754720
Validation R2 logD = 0.603307
Epoch 6
Train function
Loss = 7.8016e-03, PNorm = 58.0201, GNorm = 3.0054, lr_0 = 9.0667e-04
Loss = 6.0630e-03, PNorm = 58.1340, GNorm = 1.2159, lr_0 = 9.0266e-04
Loss = 5.2103e-03, PNorm = 58.2250, GNorm = 1.4982, lr_0 = 8.9867e-04
Loss = 5.2697e-03, PNorm = 58.3047, GNorm = 0.6706, lr_0 = 8.9469e-04
Loss = 6.4957e-03, PNorm = 58.3851, GNorm = 4.2108, lr_0 = 8.9074e-04
Loss = 5.6101e-03, PNorm = 58.4675, GNorm = 1.5699, lr_0 = 8.8680e-04
Validation rmse logD = 0.692892
Validation R2 logD = 0.665640
Epoch 7
Train function
Loss = 4.2739e-03, PNorm = 58.5606, GNorm = 2.7777, lr_0 = 8.8248e-04
Loss = 5.5029e-03, PNorm = 58.6374, GNorm = 0.8902, lr_0 = 8.7858e-04
Loss = 5.3558e-03, PNorm = 58.7298, GNorm = 1.4524, lr_0 = 8.7469e-04
Loss = 4.9953e-03, PNorm = 58.8060, GNorm = 2.1337, lr_0 = 8.7082e-04
Loss = 4.5054e-03, PNorm = 58.8830, GNorm = 0.7718, lr_0 = 8.6697e-04
Validation rmse logD = 0.695787
Validation R2 logD = 0.662840
Epoch 8
Train function
Loss = 4.3423e-03, PNorm = 58.9804, GNorm = 1.3643, lr_0 = 8.6276e-04
Loss = 4.7620e-03, PNorm = 59.0746, GNorm = 3.1165, lr_0 = 8.5894e-04
Loss = 4.2198e-03, PNorm = 59.1680, GNorm = 0.9918, lr_0 = 8.5514e-04
Loss = 4.5840e-03, PNorm = 59.2478, GNorm = 2.4587, lr_0 = 8.5136e-04
Loss = 4.3574e-03, PNorm = 59.3291, GNorm = 1.4823, lr_0 = 8.4759e-04
Validation rmse logD = 0.623214
Validation R2 logD = 0.729506
Epoch 9
Train function
Loss = 2.8337e-03, PNorm = 59.3983, GNorm = 1.2994, lr_0 = 8.4384e-04
Loss = 3.9360e-03, PNorm = 59.4670, GNorm = 1.3427, lr_0 = 8.4011e-04
Loss = 4.8494e-03, PNorm = 59.5555, GNorm = 4.1772, lr_0 = 8.3639e-04
Loss = 4.1361e-03, PNorm = 59.6224, GNorm = 1.3415, lr_0 = 8.3269e-04
Loss = 3.4301e-03, PNorm = 59.7127, GNorm = 2.0068, lr_0 = 8.2901e-04
Loss = 3.7712e-03, PNorm = 59.7802, GNorm = 0.7791, lr_0 = 8.2534e-04
Validation rmse logD = 0.601395
Validation R2 logD = 0.748115
Epoch 10
Train function
Loss = 3.3913e-03, PNorm = 59.8564, GNorm = 2.1643, lr_0 = 8.2133e-04
Loss = 3.2765e-03, PNorm = 59.9127, GNorm = 1.3045, lr_0 = 8.1770e-04
Loss = 3.1593e-03, PNorm = 59.9787, GNorm = 0.9609, lr_0 = 8.1408e-04
Loss = 3.8996e-03, PNorm = 60.0668, GNorm = 3.2502, lr_0 = 8.1048e-04
Loss = 3.4532e-03, PNorm = 60.1598, GNorm = 1.5685, lr_0 = 8.0689e-04
Validation rmse logD = 0.609559
Validation R2 logD = 0.741230
Epoch 11
Train function
Loss = 3.0975e-03, PNorm = 60.2361, GNorm = 2.9972, lr_0 = 8.0297e-04
Loss = 3.2045e-03, PNorm = 60.3158, GNorm = 1.2057, lr_0 = 7.9942e-04
Loss = 2.6880e-03, PNorm = 60.3800, GNorm = 1.6120, lr_0 = 7.9588e-04
Loss = 3.0287e-03, PNorm = 60.4500, GNorm = 2.4231, lr_0 = 7.9236e-04
Loss = 3.6484e-03, PNorm = 60.5067, GNorm = 3.4273, lr_0 = 7.8885e-04
Validation rmse logD = 0.663678
Validation R2 logD = 0.693240
Epoch 12
Train function
Loss = 4.0060e-03, PNorm = 60.5947, GNorm = 3.1960, lr_0 = 7.8502e-04
Loss = 3.2722e-03, PNorm = 60.6622, GNorm = 3.2104, lr_0 = 7.8154e-04
Loss = 3.0515e-03, PNorm = 60.7383, GNorm = 2.6006, lr_0 = 7.7809e-04
Loss = 2.5227e-03, PNorm = 60.8028, GNorm = 2.9132, lr_0 = 7.7465e-04
Loss = 2.3193e-03, PNorm = 60.8619, GNorm = 0.9882, lr_0 = 7.7122e-04
Loss = 2.6488e-03, PNorm = 60.9130, GNorm = 2.6897, lr_0 = 7.6781e-04
Loss = 1.8783e-02, PNorm = 60.9173, GNorm = 4.0293, lr_0 = 7.6747e-04
Validation rmse logD = 0.585890
Validation R2 logD = 0.760936
Epoch 13
Train function
Loss = 3.0327e-03, PNorm = 60.9790, GNorm = 4.1776, lr_0 = 7.6407e-04
Loss = 2.8127e-03, PNorm = 61.0486, GNorm = 1.4337, lr_0 = 7.6069e-04
Loss = 2.6681e-03, PNorm = 61.1125, GNorm = 2.7754, lr_0 = 7.5733e-04
Loss = 2.3883e-03, PNorm = 61.1772, GNorm = 1.3739, lr_0 = 7.5398e-04
Loss = 2.7587e-03, PNorm = 61.2354, GNorm = 1.1832, lr_0 = 7.5064e-04
Validation rmse logD = 0.586699
Validation R2 logD = 0.760274
Epoch 14
Train function
Loss = 2.1391e-03, PNorm = 61.2948, GNorm = 1.3505, lr_0 = 7.4699e-04
Loss = 2.0887e-03, PNorm = 61.3590, GNorm = 0.6089, lr_0 = 7.4369e-04
Loss = 1.9684e-03, PNorm = 61.4098, GNorm = 3.5107, lr_0 = 7.4040e-04
Loss = 2.4686e-03, PNorm = 61.4582, GNorm = 0.9162, lr_0 = 7.3712e-04
Loss = 2.4320e-03, PNorm = 61.5058, GNorm = 1.7246, lr_0 = 7.3386e-04
Validation rmse logD = 0.653796
Validation R2 logD = 0.702307
Epoch 15
Train function
Loss = 2.8131e-03, PNorm = 61.5700, GNorm = 2.9095, lr_0 = 7.3029e-04
Loss = 2.5500e-03, PNorm = 61.6348, GNorm = 1.0621, lr_0 = 7.2706e-04
Loss = 2.2419e-03, PNorm = 61.7064, GNorm = 0.6761, lr_0 = 7.2385e-04
Loss = 2.0193e-03, PNorm = 61.7603, GNorm = 2.3294, lr_0 = 7.2064e-04
Loss = 2.3832e-03, PNorm = 61.8105, GNorm = 1.7869, lr_0 = 7.1746e-04
Validation rmse logD = 0.590397
Validation R2 logD = 0.757243
Epoch 16
Train function
Loss = 1.5004e-03, PNorm = 61.8686, GNorm = 1.7203, lr_0 = 7.1397e-04
Loss = 1.8375e-03, PNorm = 61.9201, GNorm = 0.7965, lr_0 = 7.1081e-04
Loss = 1.8536e-03, PNorm = 61.9648, GNorm = 1.3542, lr_0 = 7.0766e-04
Loss = 1.9456e-03, PNorm = 62.0095, GNorm = 2.6816, lr_0 = 7.0453e-04
Loss = 1.7288e-03, PNorm = 62.0574, GNorm = 0.9927, lr_0 = 7.0142e-04
Loss = 1.9260e-03, PNorm = 62.1137, GNorm = 0.9115, lr_0 = 6.9831e-04
Validation rmse logD = 0.573325
Validation R2 logD = 0.771080
Epoch 17
Train function
Loss = 1.3682e-03, PNorm = 62.1527, GNorm = 0.5738, lr_0 = 6.9523e-04
Loss = 1.5606e-03, PNorm = 62.1902, GNorm = 0.8337, lr_0 = 6.9215e-04
Loss = 1.3979e-03, PNorm = 62.2362, GNorm = 2.8236, lr_0 = 6.8909e-04
Loss = 1.5493e-03, PNorm = 62.2700, GNorm = 1.0422, lr_0 = 6.8604e-04
Loss = 1.5490e-03, PNorm = 62.3099, GNorm = 0.7939, lr_0 = 6.8301e-04
Validation rmse logD = 0.585159
Validation R2 logD = 0.761532
Epoch 18
Train function
Loss = 1.5674e-03, PNorm = 62.3617, GNorm = 3.0676, lr_0 = 6.7968e-04
Loss = 1.8605e-03, PNorm = 62.4136, GNorm = 1.9654, lr_0 = 6.7668e-04
Loss = 1.2509e-03, PNorm = 62.4640, GNorm = 0.9044, lr_0 = 6.7368e-04
Loss = 1.4364e-03, PNorm = 62.5070, GNorm = 1.0477, lr_0 = 6.7070e-04
Loss = 1.2964e-03, PNorm = 62.5474, GNorm = 1.4805, lr_0 = 6.6774e-04
Validation rmse logD = 0.580131
Validation R2 logD = 0.765612
Epoch 19
Train function
Loss = 1.0204e-03, PNorm = 62.5799, GNorm = 0.8736, lr_0 = 6.6449e-04
Loss = 1.6502e-03, PNorm = 62.6157, GNorm = 1.7820, lr_0 = 6.6155e-04
Loss = 1.6184e-03, PNorm = 62.6686, GNorm = 1.7073, lr_0 = 6.5862e-04
Loss = 1.3135e-03, PNorm = 62.7141, GNorm = 0.9423, lr_0 = 6.5571e-04
Loss = 1.3010e-03, PNorm = 62.7559, GNorm = 0.6286, lr_0 = 6.5281e-04
Loss = 1.2912e-03, PNorm = 62.7896, GNorm = 1.0284, lr_0 = 6.4992e-04
Validation rmse logD = 0.584187
Validation R2 logD = 0.762323
Epoch 20
Train function
Loss = 1.7205e-03, PNorm = 62.8402, GNorm = 2.5332, lr_0 = 6.4676e-04
Loss = 1.1389e-03, PNorm = 62.8882, GNorm = 0.4923, lr_0 = 6.4390e-04
Loss = 1.3483e-03, PNorm = 62.9315, GNorm = 1.1334, lr_0 = 6.4105e-04
Loss = 9.8035e-04, PNorm = 62.9526, GNorm = 0.7879, lr_0 = 6.3822e-04
Loss = 1.1681e-03, PNorm = 62.9894, GNorm = 1.7190, lr_0 = 6.3539e-04
Validation rmse logD = 0.582776
Validation R2 logD = 0.763470
Epoch 21
Train function
Loss = 1.1753e-03, PNorm = 63.0173, GNorm = 2.2311, lr_0 = 6.3230e-04
Loss = 1.2021e-03, PNorm = 63.0538, GNorm = 1.5144, lr_0 = 6.2950e-04
Loss = 1.1128e-03, PNorm = 63.0857, GNorm = 0.8512, lr_0 = 6.2672e-04
Loss = 1.4098e-03, PNorm = 63.1183, GNorm = 1.9753, lr_0 = 6.2395e-04
Loss = 1.1641e-03, PNorm = 63.1408, GNorm = 1.4234, lr_0 = 6.2119e-04
Validation rmse logD = 0.567649
Validation R2 logD = 0.775590
Epoch 22
Train function
Loss = 1.5789e-03, PNorm = 63.1795, GNorm = 0.4901, lr_0 = 6.1817e-04
Loss = 9.4129e-04, PNorm = 63.2183, GNorm = 0.9390, lr_0 = 6.1543e-04
Loss = 9.8287e-04, PNorm = 63.2485, GNorm = 0.6768, lr_0 = 6.1271e-04
Loss = 8.7861e-04, PNorm = 63.2790, GNorm = 1.0433, lr_0 = 6.1000e-04
Loss = 9.8640e-04, PNorm = 63.3044, GNorm = 0.3672, lr_0 = 6.0730e-04
Loss = 7.5913e-04, PNorm = 63.3320, GNorm = 1.0172, lr_0 = 6.0461e-04
Validation rmse logD = 0.588181
Validation R2 logD = 0.759062
Epoch 23
Train function
Loss = 1.1644e-03, PNorm = 63.3634, GNorm = 0.7271, lr_0 = 6.0167e-04
Loss = 8.2825e-04, PNorm = 63.4006, GNorm = 0.3969, lr_0 = 5.9901e-04
Loss = 9.6063e-04, PNorm = 63.4281, GNorm = 0.6827, lr_0 = 5.9636e-04
Loss = 9.3021e-04, PNorm = 63.4592, GNorm = 0.4317, lr_0 = 5.9372e-04
Loss = 8.3640e-04, PNorm = 63.4839, GNorm = 0.5873, lr_0 = 5.9110e-04
Validation rmse logD = 0.549686
Validation R2 logD = 0.789568
Epoch 24
Train function
Loss = 1.1161e-03, PNorm = 63.5162, GNorm = 2.3637, lr_0 = 5.8822e-04
Loss = 9.8182e-04, PNorm = 63.5547, GNorm = 2.5942, lr_0 = 5.8562e-04
Loss = 1.0901e-03, PNorm = 63.5916, GNorm = 2.8644, lr_0 = 5.8303e-04
Loss = 1.0360e-03, PNorm = 63.6214, GNorm = 2.2905, lr_0 = 5.8045e-04
Loss = 1.1369e-03, PNorm = 63.6564, GNorm = 0.6482, lr_0 = 5.7788e-04
Validation rmse logD = 0.597800
Validation R2 logD = 0.751117
Epoch 25
Train function
Loss = 1.1051e-03, PNorm = 63.6901, GNorm = 1.8150, lr_0 = 5.7533e-04
Loss = 9.9870e-04, PNorm = 63.7218, GNorm = 1.3008, lr_0 = 5.7278e-04
Loss = 8.6876e-04, PNorm = 63.7618, GNorm = 0.6929, lr_0 = 5.7025e-04
Loss = 9.2412e-04, PNorm = 63.7891, GNorm = 1.0974, lr_0 = 5.6773e-04
Loss = 9.2135e-04, PNorm = 63.8102, GNorm = 0.5984, lr_0 = 5.6522e-04
Loss = 8.4035e-04, PNorm = 63.8384, GNorm = 0.5599, lr_0 = 5.6272e-04
Validation rmse logD = 0.565820
Validation R2 logD = 0.777033
Epoch 26
Train function
Loss = 6.3298e-04, PNorm = 63.8622, GNorm = 0.5725, lr_0 = 5.5998e-04
Loss = 5.6929e-04, PNorm = 63.8900, GNorm = 0.6791, lr_0 = 5.5750e-04
Loss = 6.3048e-04, PNorm = 63.9133, GNorm = 0.5414, lr_0 = 5.5503e-04
Loss = 7.8154e-04, PNorm = 63.9391, GNorm = 0.7476, lr_0 = 5.5258e-04
Loss = 7.3771e-04, PNorm = 63.9566, GNorm = 1.0780, lr_0 = 5.5014e-04
Validation rmse logD = 0.575919
Validation R2 logD = 0.769003
Epoch 27
Train function
Loss = 1.1366e-03, PNorm = 63.9870, GNorm = 0.5723, lr_0 = 5.4746e-04
Loss = 8.7716e-04, PNorm = 64.0142, GNorm = 1.9688, lr_0 = 5.4504e-04
Loss = 8.9976e-04, PNorm = 64.0436, GNorm = 1.4512, lr_0 = 5.4263e-04
Loss = 6.9050e-04, PNorm = 64.0694, GNorm = 1.2807, lr_0 = 5.4023e-04
Loss = 5.6617e-04, PNorm = 64.0899, GNorm = 0.9230, lr_0 = 5.3784e-04
Validation rmse logD = 0.553138
Validation R2 logD = 0.786916
Epoch 28
Train function
Loss = 7.3291e-04, PNorm = 64.1115, GNorm = 1.5373, lr_0 = 5.3522e-04
Loss = 5.4147e-04, PNorm = 64.1352, GNorm = 1.0713, lr_0 = 5.3285e-04
Loss = 6.2155e-04, PNorm = 64.1490, GNorm = 0.8680, lr_0 = 5.3050e-04
Loss = 5.9909e-04, PNorm = 64.1668, GNorm = 0.5599, lr_0 = 5.2815e-04
Loss = 6.4595e-04, PNorm = 64.1858, GNorm = 0.3064, lr_0 = 5.2581e-04
Loss = 5.7829e-04, PNorm = 64.2054, GNorm = 0.3675, lr_0 = 5.2349e-04
Loss = 1.4982e-03, PNorm = 64.2079, GNorm = 1.0504, lr_0 = 5.2326e-04
Validation rmse logD = 0.551160
Validation R2 logD = 0.788438
Epoch 29
Train function
Loss = 5.0587e-04, PNorm = 64.2265, GNorm = 0.5086, lr_0 = 5.2094e-04
Loss = 5.0638e-04, PNorm = 64.2417, GNorm = 0.8176, lr_0 = 5.1864e-04
Loss = 5.4813e-04, PNorm = 64.2559, GNorm = 1.2952, lr_0 = 5.1634e-04
Loss = 6.0880e-04, PNorm = 64.2747, GNorm = 1.4461, lr_0 = 5.1406e-04
Loss = 6.4437e-04, PNorm = 64.2924, GNorm = 0.5936, lr_0 = 5.1178e-04
Validation rmse logD = 0.561305
Validation R2 logD = 0.780577
Epoch 30
Train function
Loss = 4.9194e-04, PNorm = 64.3117, GNorm = 0.3920, lr_0 = 5.0930e-04
Loss = 6.0309e-04, PNorm = 64.3339, GNorm = 0.3878, lr_0 = 5.0704e-04
Loss = 5.0392e-04, PNorm = 64.3539, GNorm = 0.4019, lr_0 = 5.0480e-04
Loss = 4.5917e-04, PNorm = 64.3696, GNorm = 0.7109, lr_0 = 5.0257e-04
Loss = 6.0570e-04, PNorm = 64.3861, GNorm = 0.4843, lr_0 = 5.0034e-04
Validation rmse logD = 0.558782
Validation R2 logD = 0.782545
Epoch 31
Train function
Loss = 3.3274e-04, PNorm = 64.4019, GNorm = 0.5875, lr_0 = 4.9791e-04
Loss = 5.1263e-04, PNorm = 64.4147, GNorm = 0.6603, lr_0 = 4.9571e-04
Loss = 5.0045e-04, PNorm = 64.4323, GNorm = 0.9579, lr_0 = 4.9351e-04
Loss = 3.7751e-04, PNorm = 64.4485, GNorm = 0.3728, lr_0 = 4.9133e-04
Loss = 4.2862e-04, PNorm = 64.4619, GNorm = 0.6941, lr_0 = 4.8916e-04
Validation rmse logD = 0.551418
Validation R2 logD = 0.788240
Epoch 32
Train function
Loss = 2.0529e-04, PNorm = 64.4772, GNorm = 0.2371, lr_0 = 4.8678e-04
Loss = 3.5855e-04, PNorm = 64.4964, GNorm = 0.5584, lr_0 = 4.8463e-04
Loss = 3.9190e-04, PNorm = 64.5095, GNorm = 0.6517, lr_0 = 4.8248e-04
Loss = 4.6476e-04, PNorm = 64.5238, GNorm = 0.4082, lr_0 = 4.8035e-04
Loss = 3.6922e-04, PNorm = 64.5366, GNorm = 0.5804, lr_0 = 4.7822e-04
Loss = 5.3145e-04, PNorm = 64.5540, GNorm = 0.2532, lr_0 = 4.7611e-04
Validation rmse logD = 0.556510
Validation R2 logD = 0.784311
Epoch 33
Train function
Loss = 3.8540e-04, PNorm = 64.5711, GNorm = 0.6492, lr_0 = 4.7379e-04
Loss = 3.3027e-04, PNorm = 64.5855, GNorm = 0.4447, lr_0 = 4.7170e-04
Loss = 3.4963e-04, PNorm = 64.6003, GNorm = 0.5272, lr_0 = 4.6961e-04
Loss = 3.7278e-04, PNorm = 64.6116, GNorm = 0.4074, lr_0 = 4.6753e-04
Loss = 5.7038e-04, PNorm = 64.6306, GNorm = 0.3809, lr_0 = 4.6546e-04
Validation rmse logD = 0.562567
Validation R2 logD = 0.779590
Epoch 34
Train function
Loss = 4.0038e-04, PNorm = 64.6429, GNorm = 0.8949, lr_0 = 4.6341e-04
Loss = 5.0712e-04, PNorm = 64.6578, GNorm = 0.8978, lr_0 = 4.6136e-04
Loss = 3.2184e-04, PNorm = 64.6747, GNorm = 0.3000, lr_0 = 4.5931e-04
Loss = 3.8066e-04, PNorm = 64.6911, GNorm = 0.5402, lr_0 = 4.5728e-04
Loss = 4.2005e-04, PNorm = 64.7073, GNorm = 0.5485, lr_0 = 4.5526e-04
Validation rmse logD = 0.557952
Validation R2 logD = 0.783191
Epoch 35
Train function
Loss = 3.5598e-04, PNorm = 64.7223, GNorm = 0.9458, lr_0 = 4.5305e-04
Loss = 2.7461e-04, PNorm = 64.7297, GNorm = 0.6045, lr_0 = 4.5104e-04
Loss = 2.5593e-04, PNorm = 64.7396, GNorm = 0.3622, lr_0 = 4.4905e-04
Loss = 3.1624e-04, PNorm = 64.7497, GNorm = 0.2113, lr_0 = 4.4706e-04
Loss = 3.3736e-04, PNorm = 64.7585, GNorm = 0.9859, lr_0 = 4.4508e-04
Loss = 2.9597e-04, PNorm = 64.7725, GNorm = 0.6309, lr_0 = 4.4311e-04
Validation rmse logD = 0.554772
Validation R2 logD = 0.785656
Epoch 36
Train function
Loss = 3.8479e-04, PNorm = 64.7974, GNorm = 0.5664, lr_0 = 4.4096e-04
Loss = 4.2946e-04, PNorm = 64.8133, GNorm = 1.1482, lr_0 = 4.3901e-04
Loss = 5.1564e-04, PNorm = 64.8376, GNorm = 1.2130, lr_0 = 4.3707e-04
Loss = 3.5492e-04, PNorm = 64.8528, GNorm = 0.9992, lr_0 = 4.3513e-04
Loss = 3.4535e-04, PNorm = 64.8686, GNorm = 0.4718, lr_0 = 4.3321e-04
Validation rmse logD = 0.553423
Validation R2 logD = 0.786697
Epoch 37
Train function
Loss = 2.3034e-04, PNorm = 64.8836, GNorm = 0.4011, lr_0 = 4.3110e-04
Loss = 2.8649e-04, PNorm = 64.8912, GNorm = 0.2570, lr_0 = 4.2919e-04
Loss = 3.6592e-04, PNorm = 64.9036, GNorm = 0.4104, lr_0 = 4.2729e-04
Loss = 2.5767e-04, PNorm = 64.9179, GNorm = 0.4590, lr_0 = 4.2540e-04
Loss = 2.5563e-04, PNorm = 64.9272, GNorm = 0.3265, lr_0 = 4.2352e-04
Validation rmse logD = 0.554930
Validation R2 logD = 0.785533
Epoch 38
Train function
Loss = 2.0145e-04, PNorm = 64.9411, GNorm = 0.2996, lr_0 = 4.2146e-04
Loss = 2.6043e-04, PNorm = 64.9502, GNorm = 0.4057, lr_0 = 4.1960e-04
Loss = 2.1756e-04, PNorm = 64.9603, GNorm = 0.2478, lr_0 = 4.1774e-04
Loss = 2.5917e-04, PNorm = 64.9725, GNorm = 0.2483, lr_0 = 4.1589e-04
Loss = 2.0014e-04, PNorm = 64.9822, GNorm = 0.2364, lr_0 = 4.1406e-04
Loss = 2.6690e-04, PNorm = 64.9903, GNorm = 0.4288, lr_0 = 4.1222e-04
Validation rmse logD = 0.559266
Validation R2 logD = 0.782168
Epoch 39
Train function
Loss = 2.3954e-04, PNorm = 65.0040, GNorm = 0.3702, lr_0 = 4.1022e-04
Loss = 2.8880e-04, PNorm = 65.0138, GNorm = 0.5465, lr_0 = 4.0840e-04
Loss = 2.1172e-04, PNorm = 65.0231, GNorm = 0.6516, lr_0 = 4.0660e-04
Loss = 2.5153e-04, PNorm = 65.0373, GNorm = 0.2417, lr_0 = 4.0480e-04
Loss = 2.8582e-04, PNorm = 65.0516, GNorm = 0.2933, lr_0 = 4.0301e-04
Validation rmse logD = 0.547965
Validation R2 logD = 0.790883
Epoch 40
Train function
Loss = 1.5764e-04, PNorm = 65.0615, GNorm = 0.4849, lr_0 = 4.0105e-04
Loss = 2.6386e-04, PNorm = 65.0743, GNorm = 0.9621, lr_0 = 3.9927e-04
Loss = 2.3435e-04, PNorm = 65.0817, GNorm = 0.8516, lr_0 = 3.9751e-04
Loss = 3.1100e-04, PNorm = 65.0913, GNorm = 0.3200, lr_0 = 3.9575e-04
Loss = 1.7984e-04, PNorm = 65.1035, GNorm = 0.5339, lr_0 = 3.9400e-04
Validation rmse logD = 0.556253
Validation R2 logD = 0.784510
Epoch 41
Train function
Loss = 2.9758e-04, PNorm = 65.1149, GNorm = 0.6448, lr_0 = 3.9208e-04
Loss = 2.1619e-04, PNorm = 65.1269, GNorm = 0.2653, lr_0 = 3.9035e-04
Loss = 3.0049e-04, PNorm = 65.1383, GNorm = 0.4164, lr_0 = 3.8862e-04
Loss = 2.0441e-04, PNorm = 65.1482, GNorm = 0.4252, lr_0 = 3.8690e-04
Loss = 2.4894e-04, PNorm = 65.1619, GNorm = 0.3029, lr_0 = 3.8519e-04
Loss = 3.1266e-04, PNorm = 65.1735, GNorm = 0.6114, lr_0 = 3.8349e-04
Validation rmse logD = 0.556165
Validation R2 logD = 0.784578
Epoch 42
Train function
Loss = 1.8636e-04, PNorm = 65.1810, GNorm = 0.6425, lr_0 = 3.8179e-04
Loss = 2.0968e-04, PNorm = 65.1915, GNorm = 0.2964, lr_0 = 3.8010e-04
Loss = 2.1655e-04, PNorm = 65.2015, GNorm = 0.3118, lr_0 = 3.7842e-04
Loss = 2.1152e-04, PNorm = 65.2101, GNorm = 0.3898, lr_0 = 3.7675e-04
Loss = 2.2898e-04, PNorm = 65.2189, GNorm = 0.7141, lr_0 = 3.7508e-04
Validation rmse logD = 0.550170
Validation R2 logD = 0.789197
Epoch 43
Train function
Loss = 1.3267e-04, PNorm = 65.2296, GNorm = 0.5617, lr_0 = 3.7326e-04
Loss = 1.8981e-04, PNorm = 65.2384, GNorm = 0.1672, lr_0 = 3.7160e-04
Loss = 2.1035e-04, PNorm = 65.2445, GNorm = 0.2378, lr_0 = 3.6996e-04
Loss = 1.7982e-04, PNorm = 65.2505, GNorm = 0.6429, lr_0 = 3.6832e-04
Loss = 1.6356e-04, PNorm = 65.2594, GNorm = 0.6458, lr_0 = 3.6669e-04
Validation rmse logD = 0.552924
Validation R2 logD = 0.787081
Epoch 44
Train function
Loss = 1.4644e-04, PNorm = 65.2691, GNorm = 0.2880, lr_0 = 3.6491e-04
Loss = 1.3419e-04, PNorm = 65.2781, GNorm = 0.2575, lr_0 = 3.6330e-04
Loss = 1.6016e-04, PNorm = 65.2842, GNorm = 0.1898, lr_0 = 3.6169e-04
Loss = 1.9625e-04, PNorm = 65.2911, GNorm = 0.2497, lr_0 = 3.6009e-04
Loss = 1.9076e-04, PNorm = 65.3024, GNorm = 0.1730, lr_0 = 3.5850e-04
Loss = 1.3744e-04, PNorm = 65.3083, GNorm = 0.2740, lr_0 = 3.5691e-04
Loss = 6.8467e-04, PNorm = 65.3084, GNorm = 0.4522, lr_0 = 3.5675e-04
Validation rmse logD = 0.551213
Validation R2 logD = 0.788397
Epoch 45
Train function
Loss = 1.3495e-04, PNorm = 65.3156, GNorm = 0.2289, lr_0 = 3.5518e-04
Loss = 1.2943e-04, PNorm = 65.3235, GNorm = 0.3108, lr_0 = 3.5360e-04
Loss = 1.4335e-04, PNorm = 65.3317, GNorm = 0.3751, lr_0 = 3.5204e-04
Loss = 1.2679e-04, PNorm = 65.3373, GNorm = 0.2469, lr_0 = 3.5048e-04
Loss = 1.9286e-04, PNorm = 65.3426, GNorm = 0.1989, lr_0 = 3.4893e-04
Validation rmse logD = 0.557107
Validation R2 logD = 0.783847
Epoch 46
Train function
Loss = 1.1524e-04, PNorm = 65.3536, GNorm = 0.4934, lr_0 = 3.4724e-04
Loss = 1.7379e-04, PNorm = 65.3636, GNorm = 0.5512, lr_0 = 3.4570e-04
Loss = 1.0670e-04, PNorm = 65.3727, GNorm = 0.1785, lr_0 = 3.4417e-04
Loss = 1.2546e-04, PNorm = 65.3792, GNorm = 0.2460, lr_0 = 3.4265e-04
Loss = 1.0852e-04, PNorm = 65.3848, GNorm = 0.2713, lr_0 = 3.4113e-04
Validation rmse logD = 0.544158
Validation R2 logD = 0.793779
Epoch 47
Train function
Loss = 1.2725e-04, PNorm = 65.3892, GNorm = 0.3428, lr_0 = 3.3947e-04
Loss = 1.2834e-04, PNorm = 65.3956, GNorm = 0.3618, lr_0 = 3.3797e-04
Loss = 1.8676e-04, PNorm = 65.3999, GNorm = 0.6484, lr_0 = 3.3648e-04
Loss = 1.0362e-04, PNorm = 65.4063, GNorm = 0.2213, lr_0 = 3.3499e-04
Loss = 1.6335e-04, PNorm = 65.4124, GNorm = 0.6810, lr_0 = 3.3351e-04
Validation rmse logD = 0.574840
Validation R2 logD = 0.769868
Epoch 48
Train function
Loss = 3.8879e-04, PNorm = 65.4212, GNorm = 1.5267, lr_0 = 3.3188e-04
Loss = 2.3200e-04, PNorm = 65.4304, GNorm = 1.2180, lr_0 = 3.3042e-04
Loss = 1.5308e-04, PNorm = 65.4411, GNorm = 0.4281, lr_0 = 3.2895e-04
Loss = 1.3956e-04, PNorm = 65.4510, GNorm = 0.3614, lr_0 = 3.2750e-04
Loss = 1.6540e-04, PNorm = 65.4621, GNorm = 0.4944, lr_0 = 3.2605e-04
Loss = 1.7104e-04, PNorm = 65.4720, GNorm = 0.6744, lr_0 = 3.2461e-04
Validation rmse logD = 0.550806
Validation R2 logD = 0.788709
Epoch 49
Train function
Loss = 1.8815e-04, PNorm = 65.4839, GNorm = 1.0549, lr_0 = 3.2303e-04
Loss = 1.4526e-04, PNorm = 65.4901, GNorm = 0.2757, lr_0 = 3.2160e-04
Loss = 1.3646e-04, PNorm = 65.4990, GNorm = 0.2907, lr_0 = 3.2018e-04
Loss = 1.8351e-04, PNorm = 65.5050, GNorm = 0.5506, lr_0 = 3.1876e-04
Loss = 1.3907e-04, PNorm = 65.5106, GNorm = 0.5763, lr_0 = 3.1735e-04
Validation rmse logD = 0.549871
Validation R2 logD = 0.789426
Epoch 50
Train function
Loss = 1.0623e-04, PNorm = 65.5165, GNorm = 0.2403, lr_0 = 3.1595e-04
Loss = 1.5207e-04, PNorm = 65.5253, GNorm = 0.3285, lr_0 = 3.1455e-04
Loss = 1.4457e-04, PNorm = 65.5341, GNorm = 0.2932, lr_0 = 3.1316e-04
Loss = 1.6612e-04, PNorm = 65.5397, GNorm = 0.4856, lr_0 = 3.1177e-04
Loss = 1.0498e-04, PNorm = 65.5446, GNorm = 0.1940, lr_0 = 3.1039e-04
Validation rmse logD = 0.549718
Validation R2 logD = 0.789543
Epoch 51
Train function
Loss = 1.2448e-04, PNorm = 65.5514, GNorm = 0.2316, lr_0 = 3.0888e-04
Loss = 1.3434e-04, PNorm = 65.5573, GNorm = 0.3378, lr_0 = 3.0752e-04
Loss = 1.1145e-04, PNorm = 65.5623, GNorm = 0.4502, lr_0 = 3.0616e-04
Loss = 1.0494e-04, PNorm = 65.5669, GNorm = 0.2193, lr_0 = 3.0480e-04
Loss = 1.3060e-04, PNorm = 65.5735, GNorm = 0.8141, lr_0 = 3.0346e-04
Loss = 1.6769e-04, PNorm = 65.5797, GNorm = 1.3485, lr_0 = 3.0211e-04
Validation rmse logD = 0.558217
Validation R2 logD = 0.782985
Epoch 52
Train function
Loss = 1.5861e-04, PNorm = 65.5884, GNorm = 0.3325, lr_0 = 3.0064e-04
Loss = 1.5325e-04, PNorm = 65.5967, GNorm = 0.2892, lr_0 = 2.9931e-04
Loss = 1.3780e-04, PNorm = 65.6054, GNorm = 0.1437, lr_0 = 2.9799e-04
Loss = 1.1552e-04, PNorm = 65.6123, GNorm = 0.2365, lr_0 = 2.9667e-04
Loss = 9.8011e-05, PNorm = 65.6172, GNorm = 0.4203, lr_0 = 2.9536e-04
Validation rmse logD = 0.548549
Validation R2 logD = 0.790437
Epoch 53
Train function
Loss = 1.1345e-04, PNorm = 65.6225, GNorm = 0.2473, lr_0 = 2.9392e-04
Loss = 1.1775e-04, PNorm = 65.6315, GNorm = 0.5169, lr_0 = 2.9262e-04
Loss = 1.2748e-04, PNorm = 65.6354, GNorm = 0.7609, lr_0 = 2.9133e-04
Loss = 1.2355e-04, PNorm = 65.6429, GNorm = 0.2398, lr_0 = 2.9004e-04
Loss = 1.2265e-04, PNorm = 65.6471, GNorm = 0.3207, lr_0 = 2.8876e-04
Validation rmse logD = 0.553609
Validation R2 logD = 0.786553
Epoch 54
Train function
Loss = 1.0293e-04, PNorm = 65.6549, GNorm = 0.1798, lr_0 = 2.8735e-04
Loss = 7.3197e-05, PNorm = 65.6599, GNorm = 0.1378, lr_0 = 2.8608e-04
Loss = 7.0064e-05, PNorm = 65.6644, GNorm = 0.1921, lr_0 = 2.8482e-04
Loss = 8.4678e-05, PNorm = 65.6682, GNorm = 0.4960, lr_0 = 2.8356e-04
Loss = 1.2718e-04, PNorm = 65.6753, GNorm = 0.4262, lr_0 = 2.8230e-04
Loss = 9.8011e-05, PNorm = 65.6791, GNorm = 0.2899, lr_0 = 2.8105e-04
Validation rmse logD = 0.551403
Validation R2 logD = 0.788251
Epoch 55
Train function
Loss = 9.1719e-05, PNorm = 65.6860, GNorm = 0.3642, lr_0 = 2.7969e-04
Loss = 8.6635e-05, PNorm = 65.6912, GNorm = 0.5811, lr_0 = 2.7845e-04
Loss = 9.3359e-05, PNorm = 65.6956, GNorm = 0.2855, lr_0 = 2.7722e-04
Loss = 1.6091e-04, PNorm = 65.6991, GNorm = 0.5738, lr_0 = 2.7599e-04
Loss = 1.2165e-04, PNorm = 65.7049, GNorm = 0.3233, lr_0 = 2.7477e-04
Validation rmse logD = 0.556877
Validation R2 logD = 0.784026
Epoch 56
Train function
Loss = 9.6914e-05, PNorm = 65.7134, GNorm = 0.2428, lr_0 = 2.7343e-04
Loss = 8.1000e-05, PNorm = 65.7186, GNorm = 0.1775, lr_0 = 2.7222e-04
Loss = 9.2353e-05, PNorm = 65.7239, GNorm = 0.1598, lr_0 = 2.7102e-04
Loss = 7.0666e-05, PNorm = 65.7276, GNorm = 0.3992, lr_0 = 2.6982e-04
Loss = 1.1152e-04, PNorm = 65.7306, GNorm = 0.1808, lr_0 = 2.6863e-04
Validation rmse logD = 0.550063
Validation R2 logD = 0.789279
Epoch 57
Train function
Loss = 8.7964e-05, PNorm = 65.7365, GNorm = 0.2361, lr_0 = 2.6732e-04
Loss = 8.4343e-05, PNorm = 65.7416, GNorm = 0.1248, lr_0 = 2.6614e-04
Loss = 7.0435e-05, PNorm = 65.7473, GNorm = 0.1672, lr_0 = 2.6496e-04
Loss = 8.3107e-05, PNorm = 65.7515, GNorm = 0.2203, lr_0 = 2.6379e-04
Loss = 8.0898e-05, PNorm = 65.7561, GNorm = 0.3179, lr_0 = 2.6262e-04
Loss = 5.7585e-05, PNorm = 65.7612, GNorm = 0.1739, lr_0 = 2.6146e-04
Loss = 4.8497e-04, PNorm = 65.7613, GNorm = 0.4590, lr_0 = 2.6134e-04
Validation rmse logD = 0.555217
Validation R2 logD = 0.785311
Epoch 58
Train function
Loss = 6.9846e-05, PNorm = 65.7635, GNorm = 0.2659, lr_0 = 2.6019e-04
Loss = 6.3498e-05, PNorm = 65.7684, GNorm = 0.3157, lr_0 = 2.5904e-04
Loss = 5.7706e-05, PNorm = 65.7730, GNorm = 0.1919, lr_0 = 2.5789e-04
Loss = 4.8132e-05, PNorm = 65.7778, GNorm = 0.1538, lr_0 = 2.5675e-04
Loss = 8.8124e-05, PNorm = 65.7826, GNorm = 0.2082, lr_0 = 2.5561e-04
Validation rmse logD = 0.556712
Validation R2 logD = 0.784153
Epoch 59
Train function
Loss = 7.0184e-05, PNorm = 65.7879, GNorm = 0.3585, lr_0 = 2.5448e-04
Loss = 7.0453e-05, PNorm = 65.7911, GNorm = 0.1942, lr_0 = 2.5336e-04
Loss = 6.6283e-05, PNorm = 65.7958, GNorm = 0.2136, lr_0 = 2.5224e-04
Loss = 8.6655e-05, PNorm = 65.8000, GNorm = 0.3640, lr_0 = 2.5112e-04
Loss = 5.5802e-05, PNorm = 65.8041, GNorm = 0.3315, lr_0 = 2.5001e-04
Validation rmse logD = 0.552587
Validation R2 logD = 0.787340
Epoch 60
Train function
Loss = 7.1600e-05, PNorm = 65.8076, GNorm = 0.2865, lr_0 = 2.4879e-04
Loss = 5.2213e-05, PNorm = 65.8115, GNorm = 0.2471, lr_0 = 2.4769e-04
Loss = 5.5298e-05, PNorm = 65.8145, GNorm = 0.1090, lr_0 = 2.4660e-04
Loss = 6.1784e-05, PNorm = 65.8190, GNorm = 0.2208, lr_0 = 2.4551e-04
Loss = 4.6132e-05, PNorm = 65.8212, GNorm = 0.1542, lr_0 = 2.4442e-04
Loss = 5.2161e-05, PNorm = 65.8243, GNorm = 0.1722, lr_0 = 2.4334e-04
Loss = 1.1832e-05, PNorm = 65.8244, GNorm = 0.0584, lr_0 = 2.4323e-04
Validation rmse logD = 0.554391
Validation R2 logD = 0.785950
Epoch 61
Train function
Loss = 3.4978e-05, PNorm = 65.8273, GNorm = 0.2311, lr_0 = 2.4216e-04
Loss = 3.1292e-05, PNorm = 65.8309, GNorm = 0.2540, lr_0 = 2.4109e-04
Loss = 4.6249e-05, PNorm = 65.8341, GNorm = 0.1218, lr_0 = 2.4002e-04
Loss = 6.3166e-05, PNorm = 65.8386, GNorm = 0.1527, lr_0 = 2.3896e-04
Loss = 4.8186e-05, PNorm = 65.8424, GNorm = 0.2141, lr_0 = 2.3790e-04
Validation rmse logD = 0.555364
Validation R2 logD = 0.785198
Epoch 62
Train function
Loss = 5.8754e-05, PNorm = 65.8453, GNorm = 0.4444, lr_0 = 2.3674e-04
Loss = 4.0668e-05, PNorm = 65.8486, GNorm = 0.1570, lr_0 = 2.3570e-04
Loss = 6.6134e-05, PNorm = 65.8530, GNorm = 0.1723, lr_0 = 2.3465e-04
Loss = 7.1615e-05, PNorm = 65.8571, GNorm = 0.3438, lr_0 = 2.3362e-04
Loss = 4.7772e-05, PNorm = 65.8610, GNorm = 0.1589, lr_0 = 2.3258e-04
Validation rmse logD = 0.554579
Validation R2 logD = 0.785805
Epoch 63
Train function
Loss = 3.9538e-05, PNorm = 65.8634, GNorm = 0.1322, lr_0 = 2.3145e-04
Loss = 4.2290e-05, PNorm = 65.8659, GNorm = 0.1493, lr_0 = 2.3043e-04
Loss = 4.7928e-05, PNorm = 65.8678, GNorm = 0.1830, lr_0 = 2.2941e-04
Loss = 6.1008e-05, PNorm = 65.8718, GNorm = 0.1601, lr_0 = 2.2839e-04
Loss = 5.8980e-05, PNorm = 65.8761, GNorm = 0.1719, lr_0 = 2.2738e-04
Validation rmse logD = 0.554357
Validation R2 logD = 0.785976
Epoch 64
Train function
Loss = 5.6008e-05, PNorm = 65.8797, GNorm = 0.1328, lr_0 = 2.2628e-04
Loss = 7.5868e-05, PNorm = 65.8837, GNorm = 0.2318, lr_0 = 2.2528e-04
Loss = 4.7311e-05, PNorm = 65.8879, GNorm = 0.2601, lr_0 = 2.2428e-04
Loss = 4.4379e-05, PNorm = 65.8909, GNorm = 0.4211, lr_0 = 2.2329e-04
Loss = 5.3575e-05, PNorm = 65.8952, GNorm = 0.3013, lr_0 = 2.2230e-04
Loss = 6.5737e-05, PNorm = 65.8989, GNorm = 0.2978, lr_0 = 2.2132e-04
Validation rmse logD = 0.553143
Validation R2 logD = 0.786912
Epoch 65
Train function
Loss = 4.2097e-05, PNorm = 65.9025, GNorm = 0.1119, lr_0 = 2.2024e-04
Loss = 5.8101e-05, PNorm = 65.9058, GNorm = 0.3788, lr_0 = 2.1927e-04
Loss = 6.0894e-05, PNorm = 65.9095, GNorm = 0.6324, lr_0 = 2.1830e-04
Loss = 6.3971e-05, PNorm = 65.9136, GNorm = 0.1915, lr_0 = 2.1733e-04
Loss = 5.0440e-05, PNorm = 65.9156, GNorm = 0.1403, lr_0 = 2.1637e-04
Validation rmse logD = 0.552244
Validation R2 logD = 0.787604
Epoch 66
Train function
Loss = 7.1956e-05, PNorm = 65.9203, GNorm = 0.4077, lr_0 = 2.1532e-04
Loss = 5.4059e-05, PNorm = 65.9228, GNorm = 0.2924, lr_0 = 2.1436e-04
Loss = 5.1509e-05, PNorm = 65.9240, GNorm = 0.0811, lr_0 = 2.1342e-04
Loss = 4.8703e-05, PNorm = 65.9269, GNorm = 0.1008, lr_0 = 2.1247e-04
Loss = 4.5827e-05, PNorm = 65.9303, GNorm = 0.1882, lr_0 = 2.1153e-04
Validation rmse logD = 0.556527
Validation R2 logD = 0.784297
Epoch 67
Train function
Loss = 3.3955e-05, PNorm = 65.9362, GNorm = 0.3516, lr_0 = 2.1060e-04
Loss = 4.8515e-05, PNorm = 65.9433, GNorm = 0.5945, lr_0 = 2.0966e-04
Loss = 5.4553e-05, PNorm = 65.9461, GNorm = 0.2478, lr_0 = 2.0874e-04
Loss = 4.9215e-05, PNorm = 65.9493, GNorm = 0.2396, lr_0 = 2.0781e-04
Loss = 5.1800e-05, PNorm = 65.9525, GNorm = 0.1167, lr_0 = 2.0689e-04
Loss = 5.6062e-05, PNorm = 65.9543, GNorm = 0.2099, lr_0 = 2.0598e-04
Validation rmse logD = 0.559091
Validation R2 logD = 0.782305
Epoch 68
Train function
Loss = 6.4123e-05, PNorm = 65.9583, GNorm = 0.6222, lr_0 = 2.0498e-04
Loss = 4.8972e-05, PNorm = 65.9615, GNorm = 0.3924, lr_0 = 2.0407e-04
Loss = 4.5170e-05, PNorm = 65.9637, GNorm = 0.1762, lr_0 = 2.0317e-04
Loss = 5.0079e-05, PNorm = 65.9680, GNorm = 0.1215, lr_0 = 2.0227e-04
Loss = 3.9920e-05, PNorm = 65.9710, GNorm = 0.1758, lr_0 = 2.0137e-04
Validation rmse logD = 0.553904
Validation R2 logD = 0.786325
Epoch 69
Train function
Loss = 4.4539e-05, PNorm = 65.9746, GNorm = 0.2213, lr_0 = 2.0039e-04
Loss = 4.7972e-05, PNorm = 65.9772, GNorm = 0.3385, lr_0 = 1.9951e-04
Loss = 4.7542e-05, PNorm = 65.9804, GNorm = 0.4736, lr_0 = 1.9863e-04
Loss = 4.7086e-05, PNorm = 65.9817, GNorm = 0.1483, lr_0 = 1.9775e-04
Loss = 3.8028e-05, PNorm = 65.9834, GNorm = 0.1339, lr_0 = 1.9687e-04
Validation rmse logD = 0.553723
Validation R2 logD = 0.786466
Epoch 70
Train function
Loss = 2.8939e-05, PNorm = 65.9867, GNorm = 0.2953, lr_0 = 1.9592e-04
Loss = 3.3635e-05, PNorm = 65.9880, GNorm = 0.2277, lr_0 = 1.9505e-04
Loss = 4.0020e-05, PNorm = 65.9910, GNorm = 0.1474, lr_0 = 1.9419e-04
Loss = 3.5734e-05, PNorm = 65.9930, GNorm = 0.0660, lr_0 = 1.9333e-04
Loss = 3.7090e-05, PNorm = 65.9930, GNorm = 0.1939, lr_0 = 1.9247e-04
Loss = 2.8842e-05, PNorm = 65.9937, GNorm = 0.1611, lr_0 = 1.9162e-04
Validation rmse logD = 0.556210
Validation R2 logD = 0.784543
Epoch 71
Train function
Loss = 3.6588e-05, PNorm = 65.9971, GNorm = 0.1780, lr_0 = 1.9069e-04
Loss = 3.4448e-05, PNorm = 66.0004, GNorm = 0.3237, lr_0 = 1.8984e-04
Loss = 5.4368e-05, PNorm = 66.0030, GNorm = 0.4173, lr_0 = 1.8900e-04
Loss = 4.6114e-05, PNorm = 66.0058, GNorm = 0.2068, lr_0 = 1.8817e-04
Loss = 4.6597e-05, PNorm = 66.0099, GNorm = 0.3330, lr_0 = 1.8734e-04
Validation rmse logD = 0.557102
Validation R2 logD = 0.783851
Epoch 72
Train function
Loss = 2.9691e-05, PNorm = 66.0123, GNorm = 0.1570, lr_0 = 1.8643e-04
Loss = 2.7040e-05, PNorm = 66.0143, GNorm = 0.1016, lr_0 = 1.8560e-04
Loss = 2.9660e-05, PNorm = 66.0164, GNorm = 0.0948, lr_0 = 1.8478e-04
Loss = 3.0613e-05, PNorm = 66.0174, GNorm = 0.1430, lr_0 = 1.8396e-04
Loss = 3.6368e-05, PNorm = 66.0177, GNorm = 0.2295, lr_0 = 1.8315e-04
Validation rmse logD = 0.553748
Validation R2 logD = 0.786446
Epoch 73
Train function
Loss = 3.2058e-05, PNorm = 66.0206, GNorm = 0.2452, lr_0 = 1.8226e-04
Loss = 3.3551e-05, PNorm = 66.0226, GNorm = 0.1597, lr_0 = 1.8145e-04
Loss = 3.2838e-05, PNorm = 66.0249, GNorm = 0.1735, lr_0 = 1.8065e-04
Loss = 3.7877e-05, PNorm = 66.0265, GNorm = 0.3380, lr_0 = 1.7985e-04
Loss = 3.1247e-05, PNorm = 66.0287, GNorm = 0.3342, lr_0 = 1.7905e-04
Loss = 2.8344e-05, PNorm = 66.0306, GNorm = 0.3138, lr_0 = 1.7826e-04
Loss = 7.8281e-05, PNorm = 66.0307, GNorm = 0.1789, lr_0 = 1.7818e-04
Validation rmse logD = 0.556905
Validation R2 logD = 0.784005
Epoch 74
Train function
Loss = 3.0697e-05, PNorm = 66.0324, GNorm = 0.0845, lr_0 = 1.7739e-04
Loss = 2.4177e-05, PNorm = 66.0345, GNorm = 0.1021, lr_0 = 1.7661e-04
Loss = 2.1262e-05, PNorm = 66.0357, GNorm = 0.1280, lr_0 = 1.7583e-04
Loss = 2.3364e-05, PNorm = 66.0379, GNorm = 0.1551, lr_0 = 1.7505e-04
Loss = 1.6873e-05, PNorm = 66.0390, GNorm = 0.0809, lr_0 = 1.7428e-04
Validation rmse logD = 0.557975
Validation R2 logD = 0.783173
Epoch 75
Train function
Loss = 1.6548e-05, PNorm = 66.0413, GNorm = 0.0681, lr_0 = 1.7351e-04
Loss = 2.6496e-05, PNorm = 66.0427, GNorm = 0.0780, lr_0 = 1.7274e-04
Loss = 1.8711e-05, PNorm = 66.0443, GNorm = 0.0643, lr_0 = 1.7197e-04
Loss = 1.7769e-05, PNorm = 66.0450, GNorm = 0.2287, lr_0 = 1.7121e-04
Loss = 2.1152e-05, PNorm = 66.0464, GNorm = 0.2200, lr_0 = 1.7046e-04
Validation rmse logD = 0.555575
Validation R2 logD = 0.785034
Epoch 76
Train function
Loss = 1.1823e-05, PNorm = 66.0473, GNorm = 0.1054, lr_0 = 1.6963e-04
Loss = 1.9197e-05, PNorm = 66.0487, GNorm = 0.0778, lr_0 = 1.6888e-04
Loss = 3.3492e-05, PNorm = 66.0511, GNorm = 0.2074, lr_0 = 1.6813e-04
Loss = 2.5483e-05, PNorm = 66.0523, GNorm = 0.1621, lr_0 = 1.6739e-04
Loss = 2.0612e-05, PNorm = 66.0537, GNorm = 0.0958, lr_0 = 1.6665e-04
Loss = 1.6483e-05, PNorm = 66.0561, GNorm = 0.0866, lr_0 = 1.6591e-04
Loss = 1.2004e-04, PNorm = 66.0563, GNorm = 0.2294, lr_0 = 1.6584e-04
Validation rmse logD = 0.556750
Validation R2 logD = 0.784125
Epoch 77
Train function
Loss = 2.0192e-05, PNorm = 66.0575, GNorm = 0.0552, lr_0 = 1.6510e-04
Loss = 1.7956e-05, PNorm = 66.0584, GNorm = 0.0676, lr_0 = 1.6437e-04
Loss = 2.2720e-05, PNorm = 66.0590, GNorm = 0.0722, lr_0 = 1.6364e-04
Loss = 2.7403e-05, PNorm = 66.0601, GNorm = 0.0922, lr_0 = 1.6292e-04
Loss = 2.6469e-05, PNorm = 66.0625, GNorm = 0.0958, lr_0 = 1.6220e-04
Validation rmse logD = 0.556753
Validation R2 logD = 0.784122
Epoch 78
Train function
Loss = 2.2270e-05, PNorm = 66.0635, GNorm = 0.1160, lr_0 = 1.6141e-04
Loss = 2.1006e-05, PNorm = 66.0645, GNorm = 0.0941, lr_0 = 1.6070e-04
Loss = 1.6964e-05, PNorm = 66.0666, GNorm = 0.0651, lr_0 = 1.5999e-04
Loss = 2.0877e-05, PNorm = 66.0680, GNorm = 0.0810, lr_0 = 1.5928e-04
Loss = 2.6275e-05, PNorm = 66.0692, GNorm = 0.3212, lr_0 = 1.5857e-04
Validation rmse logD = 0.555439
Validation R2 logD = 0.785140
Epoch 79
Train function
Loss = 1.1960e-05, PNorm = 66.0713, GNorm = 0.0723, lr_0 = 1.5780e-04
Loss = 1.6349e-05, PNorm = 66.0731, GNorm = 0.0901, lr_0 = 1.5710e-04
Loss = 1.5101e-05, PNorm = 66.0747, GNorm = 0.0548, lr_0 = 1.5641e-04
Loss = 1.8659e-05, PNorm = 66.0761, GNorm = 0.0787, lr_0 = 1.5572e-04
Loss = 1.5792e-05, PNorm = 66.0776, GNorm = 0.1707, lr_0 = 1.5503e-04
Validation rmse logD = 0.555686
Validation R2 logD = 0.784948
Epoch 80
Train function
Loss = 2.4797e-05, PNorm = 66.0791, GNorm = 0.0973, lr_0 = 1.5427e-04
Loss = 1.6121e-05, PNorm = 66.0806, GNorm = 0.1986, lr_0 = 1.5359e-04
Loss = 1.9374e-05, PNorm = 66.0823, GNorm = 0.1316, lr_0 = 1.5291e-04
Loss = 2.0911e-05, PNorm = 66.0844, GNorm = 0.0705, lr_0 = 1.5224e-04
Loss = 1.6327e-05, PNorm = 66.0859, GNorm = 0.2271, lr_0 = 1.5156e-04
Loss = 1.8486e-05, PNorm = 66.0870, GNorm = 0.1119, lr_0 = 1.5089e-04
Validation rmse logD = 0.555433
Validation R2 logD = 0.785144
Epoch 81
Train function
Loss = 1.8186e-05, PNorm = 66.0879, GNorm = 0.1533, lr_0 = 1.5016e-04
Loss = 1.4155e-05, PNorm = 66.0888, GNorm = 0.1269, lr_0 = 1.4949e-04
Loss = 1.7150e-05, PNorm = 66.0899, GNorm = 0.1502, lr_0 = 1.4883e-04
Loss = 2.0565e-05, PNorm = 66.0906, GNorm = 0.1398, lr_0 = 1.4817e-04
Loss = 1.8366e-05, PNorm = 66.0923, GNorm = 0.2223, lr_0 = 1.4752e-04
Validation rmse logD = 0.555661
Validation R2 logD = 0.784968
Epoch 82
Train function
Loss = 1.7599e-05, PNorm = 66.0937, GNorm = 0.1406, lr_0 = 1.4680e-04
Loss = 2.3129e-05, PNorm = 66.0949, GNorm = 0.3081, lr_0 = 1.4615e-04
Loss = 1.7464e-05, PNorm = 66.0966, GNorm = 0.0855, lr_0 = 1.4551e-04
Loss = 1.7910e-05, PNorm = 66.0972, GNorm = 0.0693, lr_0 = 1.4486e-04
Loss = 2.3759e-05, PNorm = 66.0982, GNorm = 0.1675, lr_0 = 1.4422e-04
Validation rmse logD = 0.559334
Validation R2 logD = 0.782116
Epoch 83
Train function
Loss = 2.9999e-05, PNorm = 66.1004, GNorm = 0.4141, lr_0 = 1.4352e-04
Loss = 2.8356e-05, PNorm = 66.1022, GNorm = 0.2360, lr_0 = 1.4288e-04
Loss = 2.7001e-05, PNorm = 66.1032, GNorm = 0.1199, lr_0 = 1.4225e-04
Loss = 2.1185e-05, PNorm = 66.1048, GNorm = 0.1319, lr_0 = 1.4162e-04
Loss = 2.4388e-05, PNorm = 66.1064, GNorm = 0.1397, lr_0 = 1.4100e-04
Loss = 1.6894e-05, PNorm = 66.1081, GNorm = 0.0801, lr_0 = 1.4037e-04
Validation rmse logD = 0.556116
Validation R2 logD = 0.784615
Epoch 84
Train function
Loss = 1.9710e-05, PNorm = 66.1090, GNorm = 0.1427, lr_0 = 1.3975e-04
Loss = 1.2751e-05, PNorm = 66.1104, GNorm = 0.0729, lr_0 = 1.3913e-04
Loss = 1.4862e-05, PNorm = 66.1118, GNorm = 0.0694, lr_0 = 1.3852e-04
Loss = 1.7822e-05, PNorm = 66.1125, GNorm = 0.0620, lr_0 = 1.3791e-04
Loss = 1.9309e-05, PNorm = 66.1140, GNorm = 0.3340, lr_0 = 1.3730e-04
Validation rmse logD = 0.558280
Validation R2 logD = 0.782936
Epoch 85
Train function
Loss = 1.5785e-05, PNorm = 66.1155, GNorm = 0.0910, lr_0 = 1.3663e-04
Loss = 1.5808e-05, PNorm = 66.1161, GNorm = 0.0669, lr_0 = 1.3602e-04
Loss = 1.4039e-05, PNorm = 66.1177, GNorm = 0.0917, lr_0 = 1.3542e-04
Loss = 1.6133e-05, PNorm = 66.1185, GNorm = 0.1216, lr_0 = 1.3482e-04
Loss = 1.2205e-05, PNorm = 66.1203, GNorm = 0.1488, lr_0 = 1.3423e-04
Validation rmse logD = 0.555327
Validation R2 logD = 0.785226
Epoch 86
Train function
Loss = 9.1361e-06, PNorm = 66.1206, GNorm = 0.0602, lr_0 = 1.3357e-04
Loss = 1.1083e-05, PNorm = 66.1220, GNorm = 0.0945, lr_0 = 1.3298e-04
Loss = 1.3904e-05, PNorm = 66.1238, GNorm = 0.2734, lr_0 = 1.3239e-04
Loss = 1.3445e-05, PNorm = 66.1242, GNorm = 0.0551, lr_0 = 1.3181e-04
Loss = 1.9991e-05, PNorm = 66.1250, GNorm = 0.1818, lr_0 = 1.3123e-04
Loss = 1.6362e-05, PNorm = 66.1261, GNorm = 0.3074, lr_0 = 1.3065e-04
Validation rmse logD = 0.555987
Validation R2 logD = 0.784715
Epoch 87
Train function
Loss = 2.6098e-05, PNorm = 66.1271, GNorm = 0.2264, lr_0 = 1.3001e-04
Loss = 2.2588e-05, PNorm = 66.1283, GNorm = 0.2135, lr_0 = 1.2944e-04
Loss = 2.6775e-05, PNorm = 66.1294, GNorm = 0.1112, lr_0 = 1.2886e-04
Loss = 2.7053e-05, PNorm = 66.1305, GNorm = 0.1790, lr_0 = 1.2829e-04
Loss = 2.2402e-05, PNorm = 66.1326, GNorm = 0.2460, lr_0 = 1.2773e-04
Validation rmse logD = 0.557252
Validation R2 logD = 0.783735
Epoch 88
Train function
Loss = 1.6708e-05, PNorm = 66.1335, GNorm = 0.1052, lr_0 = 1.2710e-04
Loss = 1.4002e-05, PNorm = 66.1348, GNorm = 0.0971, lr_0 = 1.2654e-04
Loss = 1.7192e-05, PNorm = 66.1364, GNorm = 0.0886, lr_0 = 1.2598e-04
Loss = 1.8602e-05, PNorm = 66.1379, GNorm = 0.0867, lr_0 = 1.2542e-04
Loss = 1.4483e-05, PNorm = 66.1392, GNorm = 0.0900, lr_0 = 1.2487e-04
Validation rmse logD = 0.556197
Validation R2 logD = 0.784553
Epoch 89
Train function
Loss = 1.1945e-05, PNorm = 66.1412, GNorm = 0.1966, lr_0 = 1.2426e-04
Loss = 1.5777e-05, PNorm = 66.1419, GNorm = 0.0794, lr_0 = 1.2371e-04
Loss = 1.3043e-05, PNorm = 66.1427, GNorm = 0.1361, lr_0 = 1.2317e-04
Loss = 1.3434e-05, PNorm = 66.1429, GNorm = 0.1599, lr_0 = 1.2262e-04
Loss = 2.0060e-05, PNorm = 66.1434, GNorm = 0.0928, lr_0 = 1.2208e-04
Loss = 1.5651e-05, PNorm = 66.1452, GNorm = 0.0526, lr_0 = 1.2154e-04
Loss = 4.4741e-05, PNorm = 66.1453, GNorm = 0.1316, lr_0 = 1.2148e-04
Validation rmse logD = 0.556786
Validation R2 logD = 0.784096
Epoch 90
Train function
Loss = 1.1300e-05, PNorm = 66.1464, GNorm = 0.0814, lr_0 = 1.2095e-04
Loss = 1.7434e-05, PNorm = 66.1473, GNorm = 0.2544, lr_0 = 1.2041e-04
Loss = 1.7040e-05, PNorm = 66.1490, GNorm = 0.0844, lr_0 = 1.1988e-04
Loss = 1.2457e-05, PNorm = 66.1499, GNorm = 0.0621, lr_0 = 1.1935e-04
Loss = 1.3804e-05, PNorm = 66.1504, GNorm = 0.0743, lr_0 = 1.1882e-04
Validation rmse logD = 0.555550
Validation R2 logD = 0.785054
Epoch 91
Train function
Loss = 1.0098e-05, PNorm = 66.1522, GNorm = 0.1664, lr_0 = 1.1824e-04
Loss = 1.1234e-05, PNorm = 66.1534, GNorm = 0.1299, lr_0 = 1.1772e-04
Loss = 1.6060e-05, PNorm = 66.1546, GNorm = 0.0703, lr_0 = 1.1720e-04
Loss = 2.2286e-05, PNorm = 66.1549, GNorm = 0.2600, lr_0 = 1.1668e-04
Loss = 9.8150e-06, PNorm = 66.1561, GNorm = 0.0746, lr_0 = 1.1616e-04
Validation rmse logD = 0.556448
Validation R2 logD = 0.784358
Epoch 92
Train function
Loss = 1.0274e-05, PNorm = 66.1574, GNorm = 0.0711, lr_0 = 1.1565e-04
Loss = 1.3007e-05, PNorm = 66.1590, GNorm = 0.0808, lr_0 = 1.1514e-04
Loss = 9.3525e-06, PNorm = 66.1596, GNorm = 0.0622, lr_0 = 1.1463e-04
Loss = 1.3182e-05, PNorm = 66.1604, GNorm = 0.0886, lr_0 = 1.1412e-04
Loss = 1.0136e-05, PNorm = 66.1614, GNorm = 0.0801, lr_0 = 1.1362e-04
Loss = 1.0630e-05, PNorm = 66.1621, GNorm = 0.1237, lr_0 = 1.1312e-04
Loss = 9.8925e-05, PNorm = 66.1621, GNorm = 0.1703, lr_0 = 1.1307e-04
Validation rmse logD = 0.556117
Validation R2 logD = 0.784615
Epoch 93
Train function
Loss = 1.0138e-05, PNorm = 66.1628, GNorm = 0.0478, lr_0 = 1.1257e-04
Loss = 1.0335e-05, PNorm = 66.1634, GNorm = 0.0665, lr_0 = 1.1207e-04
Loss = 1.1336e-05, PNorm = 66.1637, GNorm = 0.0765, lr_0 = 1.1157e-04
Loss = 1.2042e-05, PNorm = 66.1644, GNorm = 0.0856, lr_0 = 1.1108e-04
Loss = 1.1240e-05, PNorm = 66.1648, GNorm = 0.1340, lr_0 = 1.1059e-04
Validation rmse logD = 0.557038
Validation R2 logD = 0.783901
Epoch 94
Train function
Loss = 8.7688e-06, PNorm = 66.1649, GNorm = 0.0532, lr_0 = 1.1005e-04
Loss = 1.2437e-05, PNorm = 66.1659, GNorm = 0.1025, lr_0 = 1.0956e-04
Loss = 9.9851e-06, PNorm = 66.1670, GNorm = 0.1905, lr_0 = 1.0908e-04
Loss = 1.1509e-05, PNorm = 66.1678, GNorm = 0.0944, lr_0 = 1.0860e-04
Loss = 1.1015e-05, PNorm = 66.1685, GNorm = 0.0653, lr_0 = 1.0811e-04
Validation rmse logD = 0.556228
Validation R2 logD = 0.784529
Epoch 95
Train function
Loss = 9.0067e-06, PNorm = 66.1690, GNorm = 0.1366, lr_0 = 1.0759e-04
Loss = 7.8687e-06, PNorm = 66.1698, GNorm = 0.0872, lr_0 = 1.0711e-04
Loss = 1.1407e-05, PNorm = 66.1708, GNorm = 0.0654, lr_0 = 1.0664e-04
Loss = 8.8476e-06, PNorm = 66.1715, GNorm = 0.0847, lr_0 = 1.0617e-04
Loss = 1.0553e-05, PNorm = 66.1721, GNorm = 0.1560, lr_0 = 1.0570e-04
Validation rmse logD = 0.556738
Validation R2 logD = 0.784134
Epoch 96
Train function
Loss = 1.5429e-05, PNorm = 66.1737, GNorm = 0.1180, lr_0 = 1.0518e-04
Loss = 1.3674e-05, PNorm = 66.1745, GNorm = 0.1120, lr_0 = 1.0472e-04
Loss = 8.5653e-06, PNorm = 66.1744, GNorm = 0.0683, lr_0 = 1.0426e-04
Loss = 8.2797e-06, PNorm = 66.1752, GNorm = 0.0569, lr_0 = 1.0379e-04
Loss = 9.4197e-06, PNorm = 66.1760, GNorm = 0.0606, lr_0 = 1.0333e-04
Loss = 1.1221e-05, PNorm = 66.1770, GNorm = 0.0953, lr_0 = 1.0288e-04
Validation rmse logD = 0.556709
Validation R2 logD = 0.784156
Epoch 97
Train function
Loss = 7.6965e-06, PNorm = 66.1780, GNorm = 0.0883, lr_0 = 1.0238e-04
Loss = 8.6687e-06, PNorm = 66.1793, GNorm = 0.0668, lr_0 = 1.0192e-04
Loss = 6.1710e-06, PNorm = 66.1800, GNorm = 0.0715, lr_0 = 1.0147e-04
Loss = 1.4400e-05, PNorm = 66.1804, GNorm = 0.2048, lr_0 = 1.0102e-04
Loss = 1.1595e-05, PNorm = 66.1815, GNorm = 0.1625, lr_0 = 1.0058e-04
Validation rmse logD = 0.559067
Validation R2 logD = 0.782324
Epoch 98
Train function
Loss = 8.2519e-06, PNorm = 66.1818, GNorm = 0.1161, lr_0 = 1.0009e-04
Loss = 9.2312e-06, PNorm = 66.1830, GNorm = 0.1175, lr_0 = 1.0000e-04
Loss = 7.4461e-06, PNorm = 66.1834, GNorm = 0.0524, lr_0 = 1.0000e-04
Loss = 1.0944e-05, PNorm = 66.1843, GNorm = 0.0457, lr_0 = 1.0000e-04
Loss = 6.1914e-06, PNorm = 66.1846, GNorm = 0.0437, lr_0 = 1.0000e-04
Validation rmse logD = 0.557018
Validation R2 logD = 0.783917
Epoch 99
Train function
Loss = 1.6217e-05, PNorm = 66.1854, GNorm = 0.3831, lr_0 = 1.0000e-04
Loss = 2.2268e-05, PNorm = 66.1869, GNorm = 0.2060, lr_0 = 1.0000e-04
Loss = 1.5562e-05, PNorm = 66.1883, GNorm = 0.1252, lr_0 = 1.0000e-04
Loss = 1.5110e-05, PNorm = 66.1896, GNorm = 0.0855, lr_0 = 1.0000e-04
Loss = 8.5682e-06, PNorm = 66.1893, GNorm = 0.0636, lr_0 = 1.0000e-04
Loss = 1.4651e-05, PNorm = 66.1900, GNorm = 0.0684, lr_0 = 1.0000e-04
Validation rmse logD = 0.557800
Validation R2 logD = 0.783309
Model 0 best validation rmse = 0.544158 on epoch 46
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.591893
Model 0 test R2 logD = 0.757699
Ensemble test rmse  logD= 0.591893
Ensemble test R2  logD= 0.757699
4-fold cross validation
	Seed 0 ==> test rmse = 0.593836
	Seed 0 ==> test R2 = 0.756106
	Seed 1 ==> test rmse = 0.588149
	Seed 1 ==> test R2 = 0.760755
	Seed 2 ==> test rmse = 0.614422
	Seed 2 ==> test R2 = 0.738903
	Seed 3 ==> test rmse = 0.591893
	Seed 3 ==> test R2 = 0.757699
Overall val rmse logD= 0.565648 +/- 0.015642
Overall val R2 logD = 0.775692 +/- 0.022040
Overall test rmse logD = 0.597075 +/- 0.010222
Overall test R2 logD = 0.753366 +/- 0.008516
Elapsed time = 2:32:31
