Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 1.8261e-02, PNorm = 55.5691, GNorm = 2.9764, lr_0 = 1.9340e-04
Loss = 1.6218e-02, PNorm = 55.5797, GNorm = 2.2998, lr_0 = 2.7830e-04
Loss = 1.8018e-02, PNorm = 55.5933, GNorm = 7.7997, lr_0 = 3.6321e-04
Loss = 1.8704e-02, PNorm = 55.6138, GNorm = 10.4904, lr_0 = 4.4811e-04
Loss = 1.8208e-02, PNorm = 55.6491, GNorm = 3.6742, lr_0 = 5.3302e-04
Validation rmse logD = 1.020501
Validation R2 logD = 0.261632
Validation rmse logP = 1.234757
Validation R2 logP = 0.343201
Epoch 1
Train function
Loss = 1.5672e-02, PNorm = 55.7026, GNorm = 2.3373, lr_0 = 6.2642e-04
Loss = 1.4533e-02, PNorm = 55.7669, GNorm = 4.7898, lr_0 = 7.1132e-04
Loss = 1.4194e-02, PNorm = 55.8392, GNorm = 4.1665, lr_0 = 7.9623e-04
Loss = 1.2409e-02, PNorm = 55.9177, GNorm = 2.5527, lr_0 = 8.8113e-04
Loss = 1.2427e-02, PNorm = 56.0233, GNorm = 2.6255, lr_0 = 9.6604e-04
Validation rmse logD = 0.864739
Validation R2 logD = 0.469829
Validation rmse logP = 0.972756
Validation R2 logP = 0.592359
Epoch 2
Train function
Loss = 1.0016e-02, PNorm = 56.1573, GNorm = 1.2814, lr_0 = 9.9690e-04
Loss = 1.0394e-02, PNorm = 56.2929, GNorm = 8.2518, lr_0 = 9.9249e-04
Loss = 1.0698e-02, PNorm = 56.3973, GNorm = 1.8299, lr_0 = 9.8810e-04
Loss = 1.2345e-02, PNorm = 56.5032, GNorm = 1.1778, lr_0 = 9.8373e-04
Loss = 1.0881e-02, PNorm = 56.6252, GNorm = 1.0194, lr_0 = 9.7938e-04
Validation rmse logD = 0.908291
Validation R2 logD = 0.415081
Validation rmse logP = 0.922014
Validation R2 logP = 0.633777
Epoch 3
Train function
Loss = 1.6166e-02, PNorm = 56.7365, GNorm = 6.0648, lr_0 = 9.7462e-04
Loss = 1.0433e-02, PNorm = 56.8504, GNorm = 1.3863, lr_0 = 9.7030e-04
Loss = 1.0100e-02, PNorm = 56.9863, GNorm = 1.4134, lr_0 = 9.6601e-04
Loss = 8.3562e-03, PNorm = 57.0844, GNorm = 1.4959, lr_0 = 9.6174e-04
Loss = 8.3131e-03, PNorm = 57.1723, GNorm = 3.0462, lr_0 = 9.5749e-04
Loss = 7.4821e-03, PNorm = 57.2661, GNorm = 3.6493, lr_0 = 9.5325e-04
Validation rmse logD = 0.736807
Validation R2 logD = 0.615095
Validation rmse logP = 0.827771
Validation R2 logP = 0.704818
Epoch 4
Train function
Loss = 8.3885e-03, PNorm = 57.3713, GNorm = 4.6013, lr_0 = 9.4861e-04
Loss = 7.8442e-03, PNorm = 57.4638, GNorm = 1.1337, lr_0 = 9.4442e-04
Loss = 6.9682e-03, PNorm = 57.5657, GNorm = 1.5452, lr_0 = 9.4024e-04
Loss = 7.5225e-03, PNorm = 57.6761, GNorm = 2.4440, lr_0 = 9.3608e-04
Loss = 8.8821e-03, PNorm = 57.7626, GNorm = 4.2287, lr_0 = 9.3194e-04
Validation rmse logD = 0.932902
Validation R2 logD = 0.382954
Validation rmse logP = 0.777652
Validation R2 logP = 0.739481
Epoch 5
Train function
Loss = 1.1484e-02, PNorm = 57.8547, GNorm = 2.3327, lr_0 = 9.2741e-04
Loss = 1.0925e-02, PNorm = 57.9920, GNorm = 9.5028, lr_0 = 9.2330e-04
Loss = 7.0238e-03, PNorm = 58.1566, GNorm = 1.4800, lr_0 = 9.1922e-04
Loss = 8.0406e-03, PNorm = 58.2848, GNorm = 2.6845, lr_0 = 9.1515e-04
Loss = 7.4624e-03, PNorm = 58.3889, GNorm = 1.9424, lr_0 = 9.1111e-04
Validation rmse logD = 0.743625
Validation R2 logD = 0.607938
Validation rmse logP = 0.756471
Validation R2 logP = 0.753479
Epoch 6
Train function
Loss = 5.9523e-03, PNorm = 58.4746, GNorm = 1.8702, lr_0 = 9.0667e-04
Loss = 6.7815e-03, PNorm = 58.5752, GNorm = 1.4099, lr_0 = 9.0266e-04
Loss = 6.2013e-03, PNorm = 58.6574, GNorm = 0.9582, lr_0 = 8.9867e-04
Loss = 7.1806e-03, PNorm = 58.7289, GNorm = 3.7252, lr_0 = 8.9469e-04
Loss = 6.3173e-03, PNorm = 58.8154, GNorm = 1.3434, lr_0 = 8.9074e-04
Loss = 6.5032e-03, PNorm = 58.9044, GNorm = 0.8459, lr_0 = 8.8680e-04
Validation rmse logD = 0.678710
Validation R2 logD = 0.673401
Validation rmse logP = 0.731289
Validation R2 logP = 0.769619
Epoch 7
Train function
Loss = 6.4031e-03, PNorm = 59.0387, GNorm = 4.0656, lr_0 = 8.8248e-04
Loss = 6.6334e-03, PNorm = 59.1177, GNorm = 1.3041, lr_0 = 8.7858e-04
Loss = 5.6910e-03, PNorm = 59.2162, GNorm = 1.2000, lr_0 = 8.7469e-04
Loss = 5.2707e-03, PNorm = 59.3225, GNorm = 1.5299, lr_0 = 8.7082e-04
Loss = 6.0681e-03, PNorm = 59.4153, GNorm = 1.9748, lr_0 = 8.6697e-04
Validation rmse logD = 0.652202
Validation R2 logD = 0.698415
Validation rmse logP = 0.687693
Validation R2 logP = 0.796268
Epoch 8
Train function
Loss = 4.4904e-03, PNorm = 59.5182, GNorm = 0.6380, lr_0 = 8.6276e-04
Loss = 5.3853e-03, PNorm = 59.6058, GNorm = 0.7381, lr_0 = 8.5894e-04
Loss = 5.2968e-03, PNorm = 59.7001, GNorm = 2.1716, lr_0 = 8.5514e-04
Loss = 4.8572e-03, PNorm = 59.7935, GNorm = 2.7988, lr_0 = 8.5136e-04
Loss = 6.1447e-03, PNorm = 59.8818, GNorm = 1.9523, lr_0 = 8.4759e-04
Validation rmse logD = 0.724447
Validation R2 logD = 0.627900
Validation rmse logP = 0.768630
Validation R2 logP = 0.745490
Epoch 9
Train function
Loss = 6.2350e-03, PNorm = 59.9730, GNorm = 3.2854, lr_0 = 8.4347e-04
Loss = 5.3370e-03, PNorm = 60.0632, GNorm = 1.9418, lr_0 = 8.3974e-04
Loss = 5.1806e-03, PNorm = 60.1664, GNorm = 1.1703, lr_0 = 8.3602e-04
Loss = 4.3186e-03, PNorm = 60.2661, GNorm = 3.0793, lr_0 = 8.3232e-04
Loss = 4.7860e-03, PNorm = 60.3420, GNorm = 3.1024, lr_0 = 8.2864e-04
Loss = 4.6165e-03, PNorm = 60.4433, GNorm = 0.6884, lr_0 = 8.2498e-04
Validation rmse logD = 0.642458
Validation R2 logD = 0.707359
Validation rmse logP = 0.654047
Validation R2 logP = 0.815716
Epoch 10
Train function
Loss = 3.8660e-03, PNorm = 60.5258, GNorm = 1.3737, lr_0 = 8.2133e-04
Loss = 4.7249e-03, PNorm = 60.6143, GNorm = 1.3796, lr_0 = 8.1770e-04
Loss = 4.0077e-03, PNorm = 60.6884, GNorm = 1.5220, lr_0 = 8.1408e-04
Loss = 3.7788e-03, PNorm = 60.7726, GNorm = 1.9591, lr_0 = 8.1048e-04
Loss = 3.6854e-03, PNorm = 60.8460, GNorm = 1.5121, lr_0 = 8.0689e-04
Validation rmse logD = 0.621813
Validation R2 logD = 0.725864
Validation rmse logP = 0.702593
Validation R2 logP = 0.787344
Epoch 11
Train function
Loss = 3.6268e-03, PNorm = 60.9505, GNorm = 1.7157, lr_0 = 8.0297e-04
Loss = 3.9422e-03, PNorm = 61.0377, GNorm = 1.2525, lr_0 = 7.9942e-04
Loss = 3.6399e-03, PNorm = 61.1307, GNorm = 1.9335, lr_0 = 7.9588e-04
Loss = 3.4323e-03, PNorm = 61.2133, GNorm = 2.1395, lr_0 = 7.9236e-04
Loss = 3.8830e-03, PNorm = 61.2986, GNorm = 1.9482, lr_0 = 7.8885e-04
Validation rmse logD = 0.617884
Validation R2 logD = 0.729317
Validation rmse logP = 0.649478
Validation R2 logP = 0.818282
Epoch 12
Train function
Loss = 2.1757e-03, PNorm = 61.3907, GNorm = 0.6419, lr_0 = 7.8502e-04
Loss = 3.4685e-03, PNorm = 61.4722, GNorm = 1.7227, lr_0 = 7.8154e-04
Loss = 3.1508e-03, PNorm = 61.5631, GNorm = 0.6849, lr_0 = 7.7809e-04
Loss = 2.7672e-03, PNorm = 61.6447, GNorm = 1.5311, lr_0 = 7.7465e-04
Loss = 2.7531e-03, PNorm = 61.7068, GNorm = 2.3318, lr_0 = 7.7122e-04
Loss = 3.7373e-03, PNorm = 61.7782, GNorm = 0.8485, lr_0 = 7.6781e-04
Loss = 3.0859e-03, PNorm = 61.7837, GNorm = 0.6627, lr_0 = 7.6747e-04
Validation rmse logD = 0.584965
Validation R2 logD = 0.757392
Validation rmse logP = 0.639482
Validation R2 logP = 0.823832
Epoch 13
Train function
Loss = 2.1012e-03, PNorm = 61.8603, GNorm = 0.8693, lr_0 = 7.6407e-04
Loss = 2.5378e-03, PNorm = 61.9349, GNorm = 0.7084, lr_0 = 7.6069e-04
Loss = 2.8616e-03, PNorm = 61.9988, GNorm = 1.1122, lr_0 = 7.5733e-04
Loss = 2.8354e-03, PNorm = 62.0683, GNorm = 0.9991, lr_0 = 7.5398e-04
Loss = 2.5547e-03, PNorm = 62.1513, GNorm = 1.4673, lr_0 = 7.5064e-04
Validation rmse logD = 0.593207
Validation R2 logD = 0.750507
Validation rmse logP = 0.644015
Validation R2 logP = 0.821326
Epoch 14
Train function
Loss = 1.9803e-03, PNorm = 62.2285, GNorm = 2.4972, lr_0 = 7.4699e-04
Loss = 2.5503e-03, PNorm = 62.3114, GNorm = 2.5914, lr_0 = 7.4369e-04
Loss = 2.5327e-03, PNorm = 62.3852, GNorm = 1.5455, lr_0 = 7.4040e-04
Loss = 2.9114e-03, PNorm = 62.4752, GNorm = 2.2127, lr_0 = 7.3712e-04
Loss = 2.4579e-03, PNorm = 62.5545, GNorm = 1.4449, lr_0 = 7.3386e-04
Validation rmse logD = 0.571917
Validation R2 logD = 0.768094
Validation rmse logP = 0.608003
Validation R2 logP = 0.840749
Epoch 15
Train function
Loss = 1.7261e-03, PNorm = 62.6493, GNorm = 1.1141, lr_0 = 7.3029e-04
Loss = 1.9783e-03, PNorm = 62.7042, GNorm = 0.9321, lr_0 = 7.2706e-04
Loss = 2.4770e-03, PNorm = 62.7686, GNorm = 0.8254, lr_0 = 7.2385e-04
Loss = 2.2301e-03, PNorm = 62.8486, GNorm = 2.0411, lr_0 = 7.2064e-04
Loss = 2.0966e-03, PNorm = 62.9197, GNorm = 1.5263, lr_0 = 7.1746e-04
Validation rmse logD = 0.572367
Validation R2 logD = 0.767729
Validation rmse logP = 0.621993
Validation R2 logP = 0.833336
Epoch 16
Train function
Loss = 1.8108e-03, PNorm = 62.9844, GNorm = 1.3127, lr_0 = 7.1397e-04
Loss = 1.8039e-03, PNorm = 63.0508, GNorm = 1.1451, lr_0 = 7.1081e-04
Loss = 1.7427e-03, PNorm = 63.1176, GNorm = 1.0108, lr_0 = 7.0766e-04
Loss = 1.8567e-03, PNorm = 63.1782, GNorm = 0.8901, lr_0 = 7.0453e-04
Loss = 1.9411e-03, PNorm = 63.2337, GNorm = 2.3394, lr_0 = 7.0142e-04
Loss = 1.6703e-03, PNorm = 63.2896, GNorm = 1.0404, lr_0 = 6.9831e-04
Validation rmse logD = 0.664879
Validation R2 logD = 0.686577
Validation rmse logP = 0.602076
Validation R2 logP = 0.843839
Epoch 17
Train function
Loss = 2.1684e-03, PNorm = 63.3709, GNorm = 0.8475, lr_0 = 6.9492e-04
Loss = 3.1686e-03, PNorm = 63.4575, GNorm = 2.0091, lr_0 = 6.9184e-04
Loss = 2.4162e-03, PNorm = 63.5478, GNorm = 2.0655, lr_0 = 6.8878e-04
Loss = 2.0385e-03, PNorm = 63.6435, GNorm = 0.5125, lr_0 = 6.8574e-04
Loss = 1.9946e-03, PNorm = 63.6971, GNorm = 0.6568, lr_0 = 6.8270e-04
Validation rmse logD = 0.611840
Validation R2 logD = 0.734587
Validation rmse logP = 0.632763
Validation R2 logP = 0.827515
Epoch 18
Train function
Loss = 1.8748e-03, PNorm = 63.7653, GNorm = 0.6937, lr_0 = 6.7938e-04
Loss = 1.3672e-03, PNorm = 63.8329, GNorm = 0.6655, lr_0 = 6.7638e-04
Loss = 1.4653e-03, PNorm = 63.8819, GNorm = 0.4948, lr_0 = 6.7338e-04
Loss = 1.6028e-03, PNorm = 63.9270, GNorm = 0.6083, lr_0 = 6.7041e-04
Loss = 1.7166e-03, PNorm = 63.9734, GNorm = 1.8919, lr_0 = 6.6744e-04
Validation rmse logD = 0.571093
Validation R2 logD = 0.768762
Validation rmse logP = 0.588570
Validation R2 logP = 0.850766
Epoch 19
Train function
Loss = 8.8998e-04, PNorm = 64.0261, GNorm = 1.2469, lr_0 = 6.6419e-04
Loss = 1.6922e-03, PNorm = 64.0766, GNorm = 2.7923, lr_0 = 6.6126e-04
Loss = 1.6592e-03, PNorm = 64.1415, GNorm = 1.2984, lr_0 = 6.5833e-04
Loss = 1.5873e-03, PNorm = 64.1991, GNorm = 1.5009, lr_0 = 6.5542e-04
Loss = 1.5722e-03, PNorm = 64.2519, GNorm = 2.5120, lr_0 = 6.5252e-04
Loss = 1.5251e-03, PNorm = 64.3135, GNorm = 0.6587, lr_0 = 6.4963e-04
Validation rmse logD = 0.565557
Validation R2 logD = 0.773223
Validation rmse logP = 0.637089
Validation R2 logP = 0.825148
Epoch 20
Train function
Loss = 1.3565e-03, PNorm = 64.3742, GNorm = 0.7709, lr_0 = 6.4676e-04
Loss = 1.3417e-03, PNorm = 64.4236, GNorm = 0.6121, lr_0 = 6.4390e-04
Loss = 1.2396e-03, PNorm = 64.4720, GNorm = 0.5093, lr_0 = 6.4105e-04
Loss = 1.2789e-03, PNorm = 64.5132, GNorm = 0.5927, lr_0 = 6.3822e-04
Loss = 1.1893e-03, PNorm = 64.5470, GNorm = 0.4897, lr_0 = 6.3539e-04
Validation rmse logD = 0.565400
Validation R2 logD = 0.773349
Validation rmse logP = 0.618913
Validation R2 logP = 0.834983
Epoch 21
Train function
Loss = 1.1673e-03, PNorm = 64.5820, GNorm = 0.9159, lr_0 = 6.3230e-04
Loss = 1.0582e-03, PNorm = 64.6192, GNorm = 0.3930, lr_0 = 6.2950e-04
Loss = 1.1626e-03, PNorm = 64.6693, GNorm = 0.8019, lr_0 = 6.2672e-04
Loss = 1.1389e-03, PNorm = 64.7075, GNorm = 0.5501, lr_0 = 6.2395e-04
Loss = 1.1435e-03, PNorm = 64.7446, GNorm = 1.1818, lr_0 = 6.2119e-04
Validation rmse logD = 0.562397
Validation R2 logD = 0.775750
Validation rmse logP = 0.637411
Validation R2 logP = 0.824972
Epoch 22
Train function
Loss = 7.8163e-04, PNorm = 64.7887, GNorm = 1.1971, lr_0 = 6.1817e-04
Loss = 9.1523e-04, PNorm = 64.8294, GNorm = 0.5199, lr_0 = 6.1543e-04
Loss = 9.1103e-04, PNorm = 64.8663, GNorm = 1.2619, lr_0 = 6.1271e-04
Loss = 8.8736e-04, PNorm = 64.9023, GNorm = 0.9519, lr_0 = 6.1000e-04
Loss = 9.9319e-04, PNorm = 64.9289, GNorm = 1.3246, lr_0 = 6.0730e-04
Loss = 1.0658e-03, PNorm = 64.9623, GNorm = 1.6862, lr_0 = 6.0461e-04
Validation rmse logD = 0.597936
Validation R2 logD = 0.746513
Validation rmse logP = 0.604521
Validation R2 logP = 0.842568
Epoch 23
Train function
Loss = 1.1812e-03, PNorm = 65.0149, GNorm = 1.4831, lr_0 = 6.0167e-04
Loss = 9.4161e-04, PNorm = 65.0571, GNorm = 0.6664, lr_0 = 5.9901e-04
Loss = 7.6279e-04, PNorm = 65.0958, GNorm = 0.8447, lr_0 = 5.9636e-04
Loss = 9.8924e-04, PNorm = 65.1222, GNorm = 0.8369, lr_0 = 5.9372e-04
Loss = 9.6570e-04, PNorm = 65.1577, GNorm = 0.7067, lr_0 = 5.9110e-04
Validation rmse logD = 0.562082
Validation R2 logD = 0.776001
Validation rmse logP = 0.605674
Validation R2 logP = 0.841967
Epoch 24
Train function
Loss = 8.3392e-04, PNorm = 65.1920, GNorm = 0.6124, lr_0 = 5.8822e-04
Loss = 8.9852e-04, PNorm = 65.2271, GNorm = 1.4015, lr_0 = 5.8562e-04
Loss = 7.7352e-04, PNorm = 65.2593, GNorm = 1.0189, lr_0 = 5.8303e-04
Loss = 7.2931e-04, PNorm = 65.3004, GNorm = 0.3662, lr_0 = 5.8045e-04
Loss = 8.0517e-04, PNorm = 65.3367, GNorm = 0.4436, lr_0 = 5.7788e-04
Validation rmse logD = 0.558061
Validation R2 logD = 0.779195
Validation rmse logP = 0.609630
Validation R2 logP = 0.839896
Epoch 25
Train function
Loss = 6.0565e-04, PNorm = 65.3654, GNorm = 0.6479, lr_0 = 5.7507e-04
Loss = 9.2271e-04, PNorm = 65.4030, GNorm = 0.6686, lr_0 = 5.7253e-04
Loss = 1.0366e-03, PNorm = 65.4405, GNorm = 1.0522, lr_0 = 5.7000e-04
Loss = 7.3252e-04, PNorm = 65.4819, GNorm = 0.6126, lr_0 = 5.6748e-04
Loss = 8.0314e-04, PNorm = 65.5173, GNorm = 1.0141, lr_0 = 5.6497e-04
Loss = 6.6843e-04, PNorm = 65.5454, GNorm = 0.4395, lr_0 = 5.6247e-04
Loss = 8.0193e-03, PNorm = 65.5476, GNorm = 1.3135, lr_0 = 5.6222e-04
Validation rmse logD = 0.581591
Validation R2 logD = 0.760182
Validation rmse logP = 0.645151
Validation R2 logP = 0.820695
Epoch 26
Train function
Loss = 7.4230e-04, PNorm = 65.5744, GNorm = 1.0305, lr_0 = 5.5973e-04
Loss = 6.2869e-04, PNorm = 65.6025, GNorm = 0.5369, lr_0 = 5.5725e-04
Loss = 7.3514e-04, PNorm = 65.6309, GNorm = 1.1027, lr_0 = 5.5479e-04
Loss = 6.0859e-04, PNorm = 65.6584, GNorm = 1.3229, lr_0 = 5.5233e-04
Loss = 8.5350e-04, PNorm = 65.6934, GNorm = 0.7077, lr_0 = 5.4989e-04
Validation rmse logD = 0.551717
Validation R2 logD = 0.784186
Validation rmse logP = 0.589491
Validation R2 logP = 0.850299
Epoch 27
Train function
Loss = 4.8196e-04, PNorm = 65.7332, GNorm = 0.3654, lr_0 = 5.4722e-04
Loss = 4.9162e-04, PNorm = 65.7555, GNorm = 0.4232, lr_0 = 5.4480e-04
Loss = 5.0412e-04, PNorm = 65.7729, GNorm = 0.4255, lr_0 = 5.4239e-04
Loss = 5.9730e-04, PNorm = 65.7974, GNorm = 0.8472, lr_0 = 5.3999e-04
Loss = 5.8106e-04, PNorm = 65.8215, GNorm = 0.2622, lr_0 = 5.3760e-04
Validation rmse logD = 0.575115
Validation R2 logD = 0.765493
Validation rmse logP = 0.628123
Validation R2 logP = 0.830035
Epoch 28
Train function
Loss = 6.4519e-04, PNorm = 65.8500, GNorm = 0.4545, lr_0 = 5.3498e-04
Loss = 4.2243e-04, PNorm = 65.8727, GNorm = 0.4698, lr_0 = 5.3262e-04
Loss = 5.3675e-04, PNorm = 65.8916, GNorm = 1.0445, lr_0 = 5.3026e-04
Loss = 5.0020e-04, PNorm = 65.9211, GNorm = 0.6072, lr_0 = 5.2792e-04
Loss = 4.9745e-04, PNorm = 65.9433, GNorm = 1.0989, lr_0 = 5.2558e-04
Validation rmse logD = 0.577764
Validation R2 logD = 0.763328
Validation rmse logP = 0.592021
Validation R2 logP = 0.849012
Epoch 29
Train function
Loss = 5.9706e-04, PNorm = 65.9712, GNorm = 1.4819, lr_0 = 5.2302e-04
Loss = 4.6075e-04, PNorm = 65.9952, GNorm = 0.6580, lr_0 = 5.2071e-04
Loss = 4.5664e-04, PNorm = 66.0139, GNorm = 0.4988, lr_0 = 5.1841e-04
Loss = 4.1956e-04, PNorm = 66.0304, GNorm = 0.3593, lr_0 = 5.1611e-04
Loss = 4.5166e-04, PNorm = 66.0509, GNorm = 0.4846, lr_0 = 5.1383e-04
Loss = 4.4321e-04, PNorm = 66.0695, GNorm = 0.3921, lr_0 = 5.1156e-04
Validation rmse logD = 0.551156
Validation R2 logD = 0.784625
Validation rmse logP = 0.605936
Validation R2 logP = 0.841830
Epoch 30
Train function
Loss = 5.4575e-04, PNorm = 66.0881, GNorm = 0.3968, lr_0 = 5.0930e-04
Loss = 4.7067e-04, PNorm = 66.1110, GNorm = 0.3087, lr_0 = 5.0704e-04
Loss = 5.2712e-04, PNorm = 66.1333, GNorm = 0.9211, lr_0 = 5.0480e-04
Loss = 4.7858e-04, PNorm = 66.1532, GNorm = 0.3028, lr_0 = 5.0257e-04
Loss = 4.3775e-04, PNorm = 66.1752, GNorm = 0.4584, lr_0 = 5.0034e-04
Validation rmse logD = 0.560754
Validation R2 logD = 0.777059
Validation rmse logP = 0.614999
Validation R2 logP = 0.837063
Epoch 31
Train function
Loss = 5.1804e-04, PNorm = 66.2036, GNorm = 1.5206, lr_0 = 4.9791e-04
Loss = 4.7808e-04, PNorm = 66.2222, GNorm = 1.2123, lr_0 = 4.9571e-04
Loss = 4.0406e-04, PNorm = 66.2405, GNorm = 0.4500, lr_0 = 4.9351e-04
Loss = 3.7876e-04, PNorm = 66.2559, GNorm = 0.7627, lr_0 = 4.9133e-04
Loss = 4.3588e-04, PNorm = 66.2745, GNorm = 0.8657, lr_0 = 4.8916e-04
Validation rmse logD = 0.554811
Validation R2 logD = 0.781759
Validation rmse logP = 0.595849
Validation R2 logP = 0.847052
Epoch 32
Train function
Loss = 3.7961e-04, PNorm = 66.2943, GNorm = 0.6365, lr_0 = 4.8678e-04
Loss = 2.6955e-04, PNorm = 66.3061, GNorm = 0.2366, lr_0 = 4.8463e-04
Loss = 3.6703e-04, PNorm = 66.3238, GNorm = 0.4493, lr_0 = 4.8248e-04
Loss = 3.6636e-04, PNorm = 66.3377, GNorm = 0.5021, lr_0 = 4.8035e-04
Loss = 3.7603e-04, PNorm = 66.3561, GNorm = 0.7799, lr_0 = 4.7822e-04
Loss = 3.4759e-04, PNorm = 66.3709, GNorm = 0.4304, lr_0 = 4.7611e-04
Validation rmse logD = 0.548402
Validation R2 logD = 0.786772
Validation rmse logP = 0.592635
Validation R2 logP = 0.848698
Epoch 33
Train function
Loss = 3.0299e-04, PNorm = 66.3903, GNorm = 0.6520, lr_0 = 4.7379e-04
Loss = 4.9479e-04, PNorm = 66.4027, GNorm = 0.3195, lr_0 = 4.7170e-04
Loss = 3.1497e-04, PNorm = 66.4189, GNorm = 0.5733, lr_0 = 4.6961e-04
Loss = 3.5727e-04, PNorm = 66.4370, GNorm = 0.4101, lr_0 = 4.6753e-04
Loss = 3.2041e-04, PNorm = 66.4539, GNorm = 0.7733, lr_0 = 4.6546e-04
Validation rmse logD = 0.555093
Validation R2 logD = 0.781537
Validation rmse logP = 0.614535
Validation R2 logP = 0.837309
Epoch 34
Train function
Loss = 2.9417e-04, PNorm = 66.4752, GNorm = 0.5022, lr_0 = 4.6320e-04
Loss = 3.5618e-04, PNorm = 66.4955, GNorm = 0.5823, lr_0 = 4.6115e-04
Loss = 2.9454e-04, PNorm = 66.5117, GNorm = 0.4546, lr_0 = 4.5911e-04
Loss = 3.4588e-04, PNorm = 66.5290, GNorm = 0.3881, lr_0 = 4.5708e-04
Loss = 3.4131e-04, PNorm = 66.5459, GNorm = 1.3462, lr_0 = 4.5506e-04
Validation rmse logD = 0.568519
Validation R2 logD = 0.770842
Validation rmse logP = 0.610922
Validation R2 logP = 0.839217
Epoch 35
Train function
Loss = 4.2754e-04, PNorm = 66.5610, GNorm = 1.0764, lr_0 = 4.5284e-04
Loss = 3.7341e-04, PNorm = 66.5804, GNorm = 1.0583, lr_0 = 4.5084e-04
Loss = 3.8759e-04, PNorm = 66.5940, GNorm = 1.3896, lr_0 = 4.4885e-04
Loss = 2.9917e-04, PNorm = 66.6141, GNorm = 0.8722, lr_0 = 4.4686e-04
Loss = 3.1063e-04, PNorm = 66.6296, GNorm = 0.3214, lr_0 = 4.4489e-04
Loss = 3.2895e-04, PNorm = 66.6445, GNorm = 0.9758, lr_0 = 4.4292e-04
Validation rmse logD = 0.549055
Validation R2 logD = 0.786264
Validation rmse logP = 0.596439
Validation R2 logP = 0.846750
Epoch 36
Train function
Loss = 3.1806e-04, PNorm = 66.6593, GNorm = 0.5007, lr_0 = 4.4076e-04
Loss = 4.3312e-04, PNorm = 66.6782, GNorm = 0.7589, lr_0 = 4.3881e-04
Loss = 3.5197e-04, PNorm = 66.6937, GNorm = 0.3937, lr_0 = 4.3687e-04
Loss = 3.4414e-04, PNorm = 66.7073, GNorm = 1.4495, lr_0 = 4.3494e-04
Loss = 3.3742e-04, PNorm = 66.7258, GNorm = 0.4633, lr_0 = 4.3302e-04
Validation rmse logD = 0.550623
Validation R2 logD = 0.785042
Validation rmse logP = 0.614872
Validation R2 logP = 0.837131
Epoch 37
Train function
Loss = 2.7476e-04, PNorm = 66.7402, GNorm = 0.3455, lr_0 = 4.3091e-04
Loss = 3.3618e-04, PNorm = 66.7592, GNorm = 0.3333, lr_0 = 4.2900e-04
Loss = 3.7228e-04, PNorm = 66.7740, GNorm = 0.8098, lr_0 = 4.2711e-04
Loss = 2.8119e-04, PNorm = 66.7935, GNorm = 0.2811, lr_0 = 4.2522e-04
Loss = 2.5232e-04, PNorm = 66.8040, GNorm = 0.4740, lr_0 = 4.2334e-04
Validation rmse logD = 0.550300
Validation R2 logD = 0.785293
Validation rmse logP = 0.611798
Validation R2 logP = 0.838755
Epoch 38
Train function
Loss = 2.3026e-04, PNorm = 66.8150, GNorm = 0.6763, lr_0 = 4.2128e-04
Loss = 2.5280e-04, PNorm = 66.8265, GNorm = 0.5469, lr_0 = 4.1941e-04
Loss = 2.3060e-04, PNorm = 66.8411, GNorm = 0.2439, lr_0 = 4.1756e-04
Loss = 2.4164e-04, PNorm = 66.8508, GNorm = 0.8340, lr_0 = 4.1571e-04
Loss = 2.3112e-04, PNorm = 66.8619, GNorm = 0.6213, lr_0 = 4.1387e-04
Loss = 2.1446e-04, PNorm = 66.8679, GNorm = 0.2446, lr_0 = 4.1204e-04
Loss = 1.0541e-03, PNorm = 66.8690, GNorm = 0.5093, lr_0 = 4.1186e-04
Validation rmse logD = 0.550981
Validation R2 logD = 0.784762
Validation rmse logP = 0.595110
Validation R2 logP = 0.847432
Epoch 39
Train function
Loss = 1.5392e-04, PNorm = 66.8826, GNorm = 0.2515, lr_0 = 4.1004e-04
Loss = 1.8953e-04, PNorm = 66.8948, GNorm = 0.3064, lr_0 = 4.0822e-04
Loss = 2.1140e-04, PNorm = 66.9027, GNorm = 0.7105, lr_0 = 4.0642e-04
Loss = 1.8005e-04, PNorm = 66.9102, GNorm = 0.2938, lr_0 = 4.0462e-04
Loss = 1.9779e-04, PNorm = 66.9195, GNorm = 0.2879, lr_0 = 4.0283e-04
Validation rmse logD = 0.568100
Validation R2 logD = 0.771179
Validation rmse logP = 0.590314
Validation R2 logP = 0.849881
Epoch 40
Train function
Loss = 3.9808e-04, PNorm = 66.9330, GNorm = 1.0240, lr_0 = 4.0105e-04
Loss = 2.7980e-04, PNorm = 66.9494, GNorm = 0.5528, lr_0 = 3.9927e-04
Loss = 2.3692e-04, PNorm = 66.9605, GNorm = 0.8981, lr_0 = 3.9751e-04
Loss = 1.8830e-04, PNorm = 66.9696, GNorm = 0.2102, lr_0 = 3.9575e-04
Loss = 1.8308e-04, PNorm = 66.9791, GNorm = 0.2594, lr_0 = 3.9400e-04
Validation rmse logD = 0.554489
Validation R2 logD = 0.782013
Validation rmse logP = 0.592315
Validation R2 logP = 0.848862
Epoch 41
Train function
Loss = 2.0644e-04, PNorm = 66.9910, GNorm = 0.2988, lr_0 = 3.9208e-04
Loss = 2.2806e-04, PNorm = 67.0010, GNorm = 0.5469, lr_0 = 3.9035e-04
Loss = 2.2696e-04, PNorm = 67.0120, GNorm = 0.7214, lr_0 = 3.8862e-04
Loss = 1.7587e-04, PNorm = 67.0232, GNorm = 0.2861, lr_0 = 3.8690e-04
Loss = 1.9304e-04, PNorm = 67.0353, GNorm = 0.5458, lr_0 = 3.8519e-04
Loss = 1.7640e-04, PNorm = 67.0436, GNorm = 0.3744, lr_0 = 3.8349e-04
Loss = 2.2579e-04, PNorm = 67.0445, GNorm = 0.4832, lr_0 = 3.8332e-04
Validation rmse logD = 0.552467
Validation R2 logD = 0.783599
Validation rmse logP = 0.604258
Validation R2 logP = 0.842705
Epoch 42
Train function
Loss = 1.6437e-04, PNorm = 67.0534, GNorm = 0.3204, lr_0 = 3.8162e-04
Loss = 1.6479e-04, PNorm = 67.0620, GNorm = 0.2002, lr_0 = 3.7993e-04
Loss = 1.5336e-04, PNorm = 67.0673, GNorm = 0.4230, lr_0 = 3.7825e-04
Loss = 1.4460e-04, PNorm = 67.0753, GNorm = 0.2782, lr_0 = 3.7658e-04
Loss = 1.2015e-04, PNorm = 67.0814, GNorm = 0.2462, lr_0 = 3.7491e-04
Validation rmse logD = 0.555886
Validation R2 logD = 0.780912
Validation rmse logP = 0.589799
Validation R2 logP = 0.850143
Epoch 43
Train function
Loss = 1.6433e-04, PNorm = 67.0908, GNorm = 0.1911, lr_0 = 3.7309e-04
Loss = 1.7895e-04, PNorm = 67.0967, GNorm = 0.2905, lr_0 = 3.7144e-04
Loss = 1.7604e-04, PNorm = 67.1056, GNorm = 0.5505, lr_0 = 3.6980e-04
Loss = 1.5126e-04, PNorm = 67.1138, GNorm = 0.4200, lr_0 = 3.6816e-04
Loss = 1.5949e-04, PNorm = 67.1234, GNorm = 0.3415, lr_0 = 3.6653e-04
Validation rmse logD = 0.551228
Validation R2 logD = 0.784569
Validation rmse logP = 0.602631
Validation R2 logP = 0.843551
Epoch 44
Train function
Loss = 1.1595e-04, PNorm = 67.1370, GNorm = 0.3867, lr_0 = 3.6475e-04
Loss = 1.1520e-04, PNorm = 67.1437, GNorm = 0.2315, lr_0 = 3.6314e-04
Loss = 1.3831e-04, PNorm = 67.1482, GNorm = 0.4299, lr_0 = 3.6153e-04
Loss = 1.2671e-04, PNorm = 67.1562, GNorm = 0.3584, lr_0 = 3.5993e-04
Loss = 1.1922e-04, PNorm = 67.1634, GNorm = 0.4237, lr_0 = 3.5834e-04
Validation rmse logD = 0.549663
Validation R2 logD = 0.785790
Validation rmse logP = 0.584329
Validation R2 logP = 0.852909
Epoch 45
Train function
Loss = 6.1897e-05, PNorm = 67.1699, GNorm = 0.1263, lr_0 = 3.5660e-04
Loss = 1.0911e-04, PNorm = 67.1778, GNorm = 0.1564, lr_0 = 3.5502e-04
Loss = 1.1603e-04, PNorm = 67.1851, GNorm = 0.1838, lr_0 = 3.5345e-04
Loss = 1.1985e-04, PNorm = 67.1929, GNorm = 0.4393, lr_0 = 3.5188e-04
Loss = 1.2743e-04, PNorm = 67.2003, GNorm = 0.3380, lr_0 = 3.5033e-04
Loss = 1.3325e-04, PNorm = 67.2092, GNorm = 0.2938, lr_0 = 3.4878e-04
Validation rmse logD = 0.549370
Validation R2 logD = 0.786018
Validation rmse logP = 0.597116
Validation R2 logP = 0.846401
Epoch 46
Train function
Loss = 1.1121e-04, PNorm = 67.2168, GNorm = 0.2063, lr_0 = 3.4708e-04
Loss = 1.1294e-04, PNorm = 67.2215, GNorm = 0.1928, lr_0 = 3.4555e-04
Loss = 1.0672e-04, PNorm = 67.2264, GNorm = 0.2179, lr_0 = 3.4402e-04
Loss = 1.0964e-04, PNorm = 67.2331, GNorm = 0.1937, lr_0 = 3.4250e-04
Loss = 9.1906e-05, PNorm = 67.2391, GNorm = 0.2791, lr_0 = 3.4098e-04
Validation rmse logD = 0.548587
Validation R2 logD = 0.786628
Validation rmse logP = 0.598220
Validation R2 logP = 0.845833
Epoch 47
Train function
Loss = 9.5780e-05, PNorm = 67.2477, GNorm = 0.4415, lr_0 = 3.3932e-04
Loss = 9.1550e-05, PNorm = 67.2513, GNorm = 0.2448, lr_0 = 3.3782e-04
Loss = 1.0766e-04, PNorm = 67.2577, GNorm = 0.2180, lr_0 = 3.3633e-04
Loss = 9.4610e-05, PNorm = 67.2637, GNorm = 0.1834, lr_0 = 3.3484e-04
Loss = 7.6938e-05, PNorm = 67.2686, GNorm = 0.2446, lr_0 = 3.3336e-04
Validation rmse logD = 0.552291
Validation R2 logD = 0.783737
Validation rmse logP = 0.605940
Validation R2 logP = 0.841828
Epoch 48
Train function
Loss = 7.8430e-05, PNorm = 67.2746, GNorm = 0.2051, lr_0 = 3.3174e-04
Loss = 1.0233e-04, PNorm = 67.2817, GNorm = 0.3101, lr_0 = 3.3027e-04
Loss = 9.1095e-05, PNorm = 67.2874, GNorm = 0.1936, lr_0 = 3.2881e-04
Loss = 1.0753e-04, PNorm = 67.2934, GNorm = 0.4781, lr_0 = 3.2735e-04
Loss = 1.0248e-04, PNorm = 67.2989, GNorm = 0.3681, lr_0 = 3.2591e-04
Loss = 1.1028e-04, PNorm = 67.3038, GNorm = 0.2044, lr_0 = 3.2446e-04
Validation rmse logD = 0.550325
Validation R2 logD = 0.785274
Validation rmse logP = 0.595104
Validation R2 logP = 0.847435
Epoch 49
Train function
Loss = 8.6804e-05, PNorm = 67.3132, GNorm = 0.2499, lr_0 = 3.2289e-04
Loss = 8.0891e-05, PNorm = 67.3206, GNorm = 0.4364, lr_0 = 3.2146e-04
Loss = 9.2083e-05, PNorm = 67.3242, GNorm = 0.2345, lr_0 = 3.2004e-04
Loss = 9.9946e-05, PNorm = 67.3286, GNorm = 0.1567, lr_0 = 3.1862e-04
Loss = 1.0779e-04, PNorm = 67.3338, GNorm = 0.2355, lr_0 = 3.1721e-04
Validation rmse logD = 0.551305
Validation R2 logD = 0.784509
Validation rmse logP = 0.607363
Validation R2 logP = 0.841084
Epoch 50
Train function
Loss = 1.0012e-04, PNorm = 67.3394, GNorm = 0.2106, lr_0 = 3.1581e-04
Loss = 1.1529e-04, PNorm = 67.3488, GNorm = 0.3056, lr_0 = 3.1441e-04
Loss = 9.7817e-05, PNorm = 67.3558, GNorm = 0.3356, lr_0 = 3.1302e-04
Loss = 9.8734e-05, PNorm = 67.3608, GNorm = 0.3775, lr_0 = 3.1164e-04
Loss = 9.1091e-05, PNorm = 67.3665, GNorm = 0.2735, lr_0 = 3.1026e-04
Validation rmse logD = 0.557632
Validation R2 logD = 0.779534
Validation rmse logP = 0.608099
Validation R2 logP = 0.840699
Epoch 51
Train function
Loss = 1.1394e-04, PNorm = 67.3718, GNorm = 0.9384, lr_0 = 3.0875e-04
Loss = 1.9455e-04, PNorm = 67.3776, GNorm = 0.4250, lr_0 = 3.0738e-04
Loss = 1.2852e-04, PNorm = 67.3833, GNorm = 0.3730, lr_0 = 3.0602e-04
Loss = 1.3944e-04, PNorm = 67.3927, GNorm = 0.2697, lr_0 = 3.0467e-04
Loss = 1.1693e-04, PNorm = 67.4011, GNorm = 0.3027, lr_0 = 3.0332e-04
Loss = 1.3772e-04, PNorm = 67.4103, GNorm = 0.5010, lr_0 = 3.0198e-04
Validation rmse logD = 0.558587
Validation R2 logD = 0.778779
Validation rmse logP = 0.593373
Validation R2 logP = 0.848321
Epoch 52
Train function
Loss = 1.2804e-04, PNorm = 67.4147, GNorm = 0.2789, lr_0 = 3.0051e-04
Loss = 9.4493e-05, PNorm = 67.4208, GNorm = 0.2644, lr_0 = 2.9918e-04
Loss = 9.0841e-05, PNorm = 67.4267, GNorm = 0.2089, lr_0 = 2.9786e-04
Loss = 8.0945e-05, PNorm = 67.4324, GNorm = 0.1613, lr_0 = 2.9654e-04
Loss = 8.9867e-05, PNorm = 67.4358, GNorm = 0.4331, lr_0 = 2.9523e-04
Validation rmse logD = 0.552330
Validation R2 logD = 0.783706
Validation rmse logP = 0.595718
Validation R2 logP = 0.847120
Epoch 53
Train function
Loss = 8.6033e-05, PNorm = 67.4426, GNorm = 0.3040, lr_0 = 2.9379e-04
Loss = 8.1669e-05, PNorm = 67.4484, GNorm = 0.3912, lr_0 = 2.9249e-04
Loss = 6.3770e-05, PNorm = 67.4521, GNorm = 0.1757, lr_0 = 2.9120e-04
Loss = 7.7745e-05, PNorm = 67.4575, GNorm = 0.1174, lr_0 = 2.8991e-04
Loss = 9.1109e-05, PNorm = 67.4634, GNorm = 0.4800, lr_0 = 2.8863e-04
Validation rmse logD = 0.556727
Validation R2 logD = 0.780249
Validation rmse logP = 0.598829
Validation R2 logP = 0.845519
Epoch 54
Train function
Loss = 1.0607e-04, PNorm = 67.4716, GNorm = 0.3672, lr_0 = 2.8722e-04
Loss = 6.6654e-05, PNorm = 67.4772, GNorm = 0.1999, lr_0 = 2.8595e-04
Loss = 6.7809e-05, PNorm = 67.4792, GNorm = 0.2090, lr_0 = 2.8469e-04
Loss = 6.9473e-05, PNorm = 67.4815, GNorm = 0.1960, lr_0 = 2.8343e-04
Loss = 5.7061e-05, PNorm = 67.4856, GNorm = 0.1540, lr_0 = 2.8218e-04
Loss = 7.1706e-05, PNorm = 67.4896, GNorm = 0.2051, lr_0 = 2.8093e-04
Loss = 3.7671e-04, PNorm = 67.4900, GNorm = 0.4013, lr_0 = 2.8080e-04
Validation rmse logD = 0.550376
Validation R2 logD = 0.785235
Validation rmse logP = 0.602155
Validation R2 logP = 0.843798
Epoch 55
Train function
Loss = 8.0014e-05, PNorm = 67.4946, GNorm = 0.3036, lr_0 = 2.7956e-04
Loss = 6.9723e-05, PNorm = 67.4995, GNorm = 0.1509, lr_0 = 2.7832e-04
Loss = 7.0821e-05, PNorm = 67.5043, GNorm = 0.2014, lr_0 = 2.7709e-04
Loss = 6.5155e-05, PNorm = 67.5086, GNorm = 0.1196, lr_0 = 2.7587e-04
Loss = 7.1761e-05, PNorm = 67.5132, GNorm = 0.2955, lr_0 = 2.7465e-04
Validation rmse logD = 0.552802
Validation R2 logD = 0.783337
Validation rmse logP = 0.597473
Validation R2 logP = 0.846217
Epoch 56
Train function
Loss = 5.2976e-05, PNorm = 67.5183, GNorm = 0.1258, lr_0 = 2.7331e-04
Loss = 6.1702e-05, PNorm = 67.5232, GNorm = 0.1302, lr_0 = 2.7210e-04
Loss = 6.4519e-05, PNorm = 67.5268, GNorm = 0.1964, lr_0 = 2.7090e-04
Loss = 6.1674e-05, PNorm = 67.5315, GNorm = 0.2943, lr_0 = 2.6970e-04
Loss = 5.9479e-05, PNorm = 67.5352, GNorm = 0.2266, lr_0 = 2.6851e-04
Validation rmse logD = 0.552444
Validation R2 logD = 0.783618
Validation rmse logP = 0.599300
Validation R2 logP = 0.845275
Epoch 57
Train function
Loss = 6.2770e-05, PNorm = 67.5417, GNorm = 0.2859, lr_0 = 2.6720e-04
Loss = 9.1880e-05, PNorm = 67.5474, GNorm = 0.3286, lr_0 = 2.6602e-04
Loss = 6.8119e-05, PNorm = 67.5524, GNorm = 0.3552, lr_0 = 2.6484e-04
Loss = 5.6686e-05, PNorm = 67.5554, GNorm = 0.0999, lr_0 = 2.6367e-04
Loss = 5.6362e-05, PNorm = 67.5594, GNorm = 0.1606, lr_0 = 2.6250e-04
Validation rmse logD = 0.554127
Validation R2 logD = 0.782297
Validation rmse logP = 0.598285
Validation R2 logP = 0.845800
Epoch 58
Train function
Loss = 5.0824e-05, PNorm = 67.5641, GNorm = 0.1649, lr_0 = 2.6123e-04
Loss = 6.3095e-05, PNorm = 67.5680, GNorm = 0.2113, lr_0 = 2.6007e-04
Loss = 6.5666e-05, PNorm = 67.5707, GNorm = 0.1713, lr_0 = 2.5892e-04
Loss = 5.9699e-05, PNorm = 67.5756, GNorm = 0.2071, lr_0 = 2.5778e-04
Loss = 6.0557e-05, PNorm = 67.5783, GNorm = 0.1100, lr_0 = 2.5664e-04
Loss = 5.6595e-05, PNorm = 67.5818, GNorm = 0.1450, lr_0 = 2.5550e-04
Validation rmse logD = 0.555935
Validation R2 logD = 0.780874
Validation rmse logP = 0.601667
Validation R2 logP = 0.844051
Epoch 59
Train function
Loss = 8.2277e-05, PNorm = 67.5857, GNorm = 0.6898, lr_0 = 2.5426e-04
Loss = 5.9736e-05, PNorm = 67.5895, GNorm = 0.2971, lr_0 = 2.5313e-04
Loss = 5.7686e-05, PNorm = 67.5936, GNorm = 0.2570, lr_0 = 2.5201e-04
Loss = 5.9603e-05, PNorm = 67.5992, GNorm = 0.3365, lr_0 = 2.5090e-04
Loss = 8.1623e-05, PNorm = 67.6030, GNorm = 0.6179, lr_0 = 2.4979e-04
Validation rmse logD = 0.556285
Validation R2 logD = 0.780598
Validation rmse logP = 0.601552
Validation R2 logP = 0.844111
Epoch 60
Train function
Loss = 1.0153e-04, PNorm = 67.6066, GNorm = 0.3889, lr_0 = 2.4868e-04
Loss = 9.5783e-05, PNorm = 67.6098, GNorm = 0.2399, lr_0 = 2.4758e-04
Loss = 8.9570e-05, PNorm = 67.6140, GNorm = 0.4489, lr_0 = 2.4649e-04
Loss = 8.3407e-05, PNorm = 67.6198, GNorm = 0.5098, lr_0 = 2.4540e-04
Loss = 7.7443e-05, PNorm = 67.6267, GNorm = 0.3187, lr_0 = 2.4431e-04
Validation rmse logD = 0.549177
Validation R2 logD = 0.786169
Validation rmse logP = 0.601861
Validation R2 logP = 0.843950
Epoch 61
Train function
Loss = 4.9958e-05, PNorm = 67.6316, GNorm = 0.1230, lr_0 = 2.4313e-04
Loss = 9.2093e-05, PNorm = 67.6344, GNorm = 0.4290, lr_0 = 2.4205e-04
Loss = 7.9842e-05, PNorm = 67.6390, GNorm = 0.3853, lr_0 = 2.4098e-04
Loss = 7.8939e-05, PNorm = 67.6419, GNorm = 0.1357, lr_0 = 2.3991e-04
Loss = 5.6840e-05, PNorm = 67.6465, GNorm = 0.4128, lr_0 = 2.3885e-04
Loss = 5.4419e-05, PNorm = 67.6495, GNorm = 0.1830, lr_0 = 2.3780e-04
Validation rmse logD = 0.551229
Validation R2 logD = 0.784568
Validation rmse logP = 0.596461
Validation R2 logP = 0.846738
Epoch 62
Train function
Loss = 4.7536e-05, PNorm = 67.6542, GNorm = 0.1118, lr_0 = 2.3664e-04
Loss = 4.5703e-05, PNorm = 67.6572, GNorm = 0.1775, lr_0 = 2.3559e-04
Loss = 5.1759e-05, PNorm = 67.6587, GNorm = 0.2162, lr_0 = 2.3455e-04
Loss = 4.4372e-05, PNorm = 67.6620, GNorm = 0.1280, lr_0 = 2.3351e-04
Loss = 4.4897e-05, PNorm = 67.6654, GNorm = 0.1992, lr_0 = 2.3248e-04
Validation rmse logD = 0.552208
Validation R2 logD = 0.783802
Validation rmse logP = 0.598897
Validation R2 logP = 0.845484
Epoch 63
Train function
Loss = 5.2561e-05, PNorm = 67.6702, GNorm = 0.3365, lr_0 = 2.3135e-04
Loss = 3.6053e-05, PNorm = 67.6724, GNorm = 0.1217, lr_0 = 2.3033e-04
Loss = 5.6247e-05, PNorm = 67.6746, GNorm = 0.1043, lr_0 = 2.2931e-04
Loss = 4.3872e-05, PNorm = 67.6790, GNorm = 0.3071, lr_0 = 2.2829e-04
Loss = 4.4845e-05, PNorm = 67.6844, GNorm = 0.1166, lr_0 = 2.2728e-04
Validation rmse logD = 0.553721
Validation R2 logD = 0.782615
Validation rmse logP = 0.602759
Validation R2 logP = 0.843484
Epoch 64
Train function
Loss = 3.7496e-05, PNorm = 67.6876, GNorm = 0.1324, lr_0 = 2.2618e-04
Loss = 4.1673e-05, PNorm = 67.6902, GNorm = 0.2520, lr_0 = 2.2518e-04
Loss = 3.9636e-05, PNorm = 67.6931, GNorm = 0.3215, lr_0 = 2.2418e-04
Loss = 3.3274e-05, PNorm = 67.6950, GNorm = 0.1086, lr_0 = 2.2319e-04
Loss = 3.3181e-05, PNorm = 67.6956, GNorm = 0.2885, lr_0 = 2.2220e-04
Loss = 5.0475e-05, PNorm = 67.6970, GNorm = 0.0906, lr_0 = 2.2122e-04
Validation rmse logD = 0.553294
Validation R2 logD = 0.782951
Validation rmse logP = 0.605345
Validation R2 logP = 0.842139
Epoch 65
Train function
Loss = 2.9710e-05, PNorm = 67.7001, GNorm = 0.0558, lr_0 = 2.2014e-04
Loss = 3.1783e-05, PNorm = 67.7033, GNorm = 0.0864, lr_0 = 2.1917e-04
Loss = 3.1102e-05, PNorm = 67.7077, GNorm = 0.1142, lr_0 = 2.1820e-04
Loss = 3.1511e-05, PNorm = 67.7089, GNorm = 0.2246, lr_0 = 2.1723e-04
Loss = 2.9753e-05, PNorm = 67.7120, GNorm = 0.1337, lr_0 = 2.1627e-04
Validation rmse logD = 0.554484
Validation R2 logD = 0.782016
Validation rmse logP = 0.598069
Validation R2 logP = 0.845911
Epoch 66
Train function
Loss = 2.7573e-05, PNorm = 67.7151, GNorm = 0.1084, lr_0 = 2.1522e-04
Loss = 3.4612e-05, PNorm = 67.7163, GNorm = 0.1166, lr_0 = 2.1427e-04
Loss = 2.5066e-05, PNorm = 67.7198, GNorm = 0.0769, lr_0 = 2.1332e-04
Loss = 2.5664e-05, PNorm = 67.7217, GNorm = 0.1667, lr_0 = 2.1238e-04
Loss = 2.9287e-05, PNorm = 67.7239, GNorm = 0.1308, lr_0 = 2.1144e-04
Validation rmse logD = 0.552535
Validation R2 logD = 0.783546
Validation rmse logP = 0.602783
Validation R2 logP = 0.843472
Epoch 67
Train function
Loss = 3.1236e-05, PNorm = 67.7253, GNorm = 0.1665, lr_0 = 2.1041e-04
Loss = 2.6123e-05, PNorm = 67.7277, GNorm = 0.1602, lr_0 = 2.0948e-04
Loss = 4.4514e-05, PNorm = 67.7297, GNorm = 0.0672, lr_0 = 2.0855e-04
Loss = 3.1168e-05, PNorm = 67.7311, GNorm = 0.2568, lr_0 = 2.0763e-04
Loss = 3.9965e-05, PNorm = 67.7339, GNorm = 0.1841, lr_0 = 2.0671e-04
Loss = 3.9358e-05, PNorm = 67.7361, GNorm = 0.2615, lr_0 = 2.0580e-04
Loss = 5.4583e-04, PNorm = 67.7370, GNorm = 0.7549, lr_0 = 2.0571e-04
Validation rmse logD = 0.555120
Validation R2 logD = 0.781516
Validation rmse logP = 0.594129
Validation R2 logP = 0.847934
Epoch 68
Train function
Loss = 6.0530e-05, PNorm = 67.7398, GNorm = 0.2960, lr_0 = 2.0480e-04
Loss = 3.5357e-05, PNorm = 67.7431, GNorm = 0.1022, lr_0 = 2.0389e-04
Loss = 3.3153e-05, PNorm = 67.7444, GNorm = 0.1375, lr_0 = 2.0299e-04
Loss = 2.9582e-05, PNorm = 67.7458, GNorm = 0.2334, lr_0 = 2.0209e-04
Loss = 4.1113e-05, PNorm = 67.7500, GNorm = 0.2994, lr_0 = 2.0120e-04
Validation rmse logD = 0.554802
Validation R2 logD = 0.781766
Validation rmse logP = 0.596515
Validation R2 logP = 0.846711
Epoch 69
Train function
Loss = 3.0851e-05, PNorm = 67.7536, GNorm = 0.0982, lr_0 = 2.0022e-04
Loss = 2.4308e-05, PNorm = 67.7565, GNorm = 0.1299, lr_0 = 1.9933e-04
Loss = 2.2161e-05, PNorm = 67.7587, GNorm = 0.1030, lr_0 = 1.9845e-04
Loss = 3.0357e-05, PNorm = 67.7605, GNorm = 0.1178, lr_0 = 1.9757e-04
Loss = 2.8524e-05, PNorm = 67.7623, GNorm = 0.1758, lr_0 = 1.9670e-04
Validation rmse logD = 0.556275
Validation R2 logD = 0.780606
Validation rmse logP = 0.604877
Validation R2 logP = 0.842383
Epoch 70
Train function
Loss = 2.4231e-05, PNorm = 67.7658, GNorm = 0.1418, lr_0 = 1.9583e-04
Loss = 3.3898e-05, PNorm = 67.7681, GNorm = 0.1714, lr_0 = 1.9496e-04
Loss = 3.2024e-05, PNorm = 67.7690, GNorm = 0.2657, lr_0 = 1.9410e-04
Loss = 3.2733e-05, PNorm = 67.7714, GNorm = 0.1399, lr_0 = 1.9324e-04
Loss = 2.5585e-05, PNorm = 67.7743, GNorm = 0.0921, lr_0 = 1.9239e-04
Loss = 2.9983e-05, PNorm = 67.7764, GNorm = 0.2413, lr_0 = 1.9154e-04
Loss = 2.4326e-04, PNorm = 67.7765, GNorm = 0.3809, lr_0 = 1.9145e-04
Validation rmse logD = 0.553830
Validation R2 logD = 0.782530
Validation rmse logP = 0.602551
Validation R2 logP = 0.843593
Epoch 71
Train function
Loss = 2.7165e-05, PNorm = 67.7795, GNorm = 0.1651, lr_0 = 1.9060e-04
Loss = 2.4481e-05, PNorm = 67.7818, GNorm = 0.2138, lr_0 = 1.8976e-04
Loss = 2.7279e-05, PNorm = 67.7826, GNorm = 0.2654, lr_0 = 1.8892e-04
Loss = 2.7264e-05, PNorm = 67.7856, GNorm = 0.3715, lr_0 = 1.8809e-04
Loss = 3.4551e-05, PNorm = 67.7874, GNorm = 0.2999, lr_0 = 1.8725e-04
Validation rmse logD = 0.554584
Validation R2 logD = 0.781938
Validation rmse logP = 0.598856
Validation R2 logP = 0.845505
Epoch 72
Train function
Loss = 2.9810e-05, PNorm = 67.7895, GNorm = 0.1626, lr_0 = 1.8634e-04
Loss = 3.0007e-05, PNorm = 67.7923, GNorm = 0.1035, lr_0 = 1.8552e-04
Loss = 2.6232e-05, PNorm = 67.7946, GNorm = 0.0859, lr_0 = 1.8470e-04
Loss = 2.1784e-05, PNorm = 67.7964, GNorm = 0.0982, lr_0 = 1.8388e-04
Loss = 2.0911e-05, PNorm = 67.7981, GNorm = 0.0889, lr_0 = 1.8307e-04
Validation rmse logD = 0.553677
Validation R2 logD = 0.782651
Validation rmse logP = 0.599111
Validation R2 logP = 0.845373
Epoch 73
Train function
Loss = 2.1852e-05, PNorm = 67.8001, GNorm = 0.3121, lr_0 = 1.8218e-04
Loss = 1.5723e-05, PNorm = 67.8016, GNorm = 0.1471, lr_0 = 1.8137e-04
Loss = 2.1560e-05, PNorm = 67.8031, GNorm = 0.1803, lr_0 = 1.8057e-04
Loss = 1.9034e-05, PNorm = 67.8043, GNorm = 0.0972, lr_0 = 1.7977e-04
Loss = 2.4052e-05, PNorm = 67.8070, GNorm = 0.0747, lr_0 = 1.7897e-04
Validation rmse logD = 0.556447
Validation R2 logD = 0.780470
Validation rmse logP = 0.604703
Validation R2 logP = 0.842473
Epoch 74
Train function
Loss = 2.5723e-05, PNorm = 67.8096, GNorm = 0.2927, lr_0 = 1.7810e-04
Loss = 3.9665e-05, PNorm = 67.8116, GNorm = 0.2910, lr_0 = 1.7732e-04
Loss = 2.5347e-05, PNorm = 67.8137, GNorm = 0.0969, lr_0 = 1.7653e-04
Loss = 2.5617e-05, PNorm = 67.8165, GNorm = 0.1041, lr_0 = 1.7575e-04
Loss = 2.2642e-05, PNorm = 67.8198, GNorm = 0.1077, lr_0 = 1.7497e-04
Loss = 2.0119e-05, PNorm = 67.8222, GNorm = 0.0759, lr_0 = 1.7420e-04
Validation rmse logD = 0.554459
Validation R2 logD = 0.782036
Validation rmse logP = 0.601196
Validation R2 logP = 0.844295
Epoch 75
Train function
Loss = 1.6970e-05, PNorm = 67.8244, GNorm = 0.1279, lr_0 = 1.7335e-04
Loss = 1.5760e-05, PNorm = 67.8260, GNorm = 0.1004, lr_0 = 1.7259e-04
Loss = 1.6239e-05, PNorm = 67.8266, GNorm = 0.1376, lr_0 = 1.7182e-04
Loss = 1.9603e-05, PNorm = 67.8278, GNorm = 0.1283, lr_0 = 1.7106e-04
Loss = 2.0244e-05, PNorm = 67.8286, GNorm = 0.0855, lr_0 = 1.7031e-04
Validation rmse logD = 0.554831
Validation R2 logD = 0.781743
Validation rmse logP = 0.606459
Validation R2 logP = 0.841557
Epoch 76
Train function
Loss = 1.5828e-05, PNorm = 67.8302, GNorm = 0.2269, lr_0 = 1.6948e-04
Loss = 1.7065e-05, PNorm = 67.8321, GNorm = 0.0888, lr_0 = 1.6873e-04
Loss = 1.4241e-05, PNorm = 67.8344, GNorm = 0.0735, lr_0 = 1.6798e-04
Loss = 1.4405e-05, PNorm = 67.8345, GNorm = 0.0699, lr_0 = 1.6724e-04
Loss = 1.6502e-05, PNorm = 67.8368, GNorm = 0.1903, lr_0 = 1.6650e-04
Validation rmse logD = 0.555119
Validation R2 logD = 0.781517
Validation rmse logP = 0.603606
Validation R2 logP = 0.843044
Epoch 77
Train function
Loss = 2.3545e-05, PNorm = 67.8394, GNorm = 0.0898, lr_0 = 1.6569e-04
Loss = 1.3054e-05, PNorm = 67.8415, GNorm = 0.0843, lr_0 = 1.6496e-04
Loss = 1.8269e-05, PNorm = 67.8425, GNorm = 0.1948, lr_0 = 1.6423e-04
Loss = 2.0801e-05, PNorm = 67.8438, GNorm = 0.0965, lr_0 = 1.6350e-04
Loss = 1.7254e-05, PNorm = 67.8452, GNorm = 0.1809, lr_0 = 1.6278e-04
Loss = 1.7471e-05, PNorm = 67.8470, GNorm = 0.0974, lr_0 = 1.6206e-04
Validation rmse logD = 0.554940
Validation R2 logD = 0.781658
Validation rmse logP = 0.601834
Validation R2 logP = 0.843964
Epoch 78
Train function
Loss = 1.9205e-05, PNorm = 67.8483, GNorm = 0.0692, lr_0 = 1.6127e-04
Loss = 1.5058e-05, PNorm = 67.8499, GNorm = 0.0496, lr_0 = 1.6055e-04
Loss = 1.6439e-05, PNorm = 67.8509, GNorm = 0.0504, lr_0 = 1.5984e-04
Loss = 1.9720e-05, PNorm = 67.8522, GNorm = 0.0962, lr_0 = 1.5914e-04
Loss = 1.1821e-05, PNorm = 67.8535, GNorm = 0.1695, lr_0 = 1.5843e-04
Validation rmse logD = 0.554255
Validation R2 logD = 0.782196
Validation rmse logP = 0.602214
Validation R2 logP = 0.843767
Epoch 79
Train function
Loss = 1.7470e-05, PNorm = 67.8551, GNorm = 0.2386, lr_0 = 1.5766e-04
Loss = 1.8798e-05, PNorm = 67.8564, GNorm = 0.0950, lr_0 = 1.5697e-04
Loss = 3.0774e-05, PNorm = 67.8584, GNorm = 0.0693, lr_0 = 1.5627e-04
Loss = 2.0330e-05, PNorm = 67.8609, GNorm = 0.2625, lr_0 = 1.5558e-04
Loss = 1.9952e-05, PNorm = 67.8635, GNorm = 0.0862, lr_0 = 1.5489e-04
Validation rmse logD = 0.554682
Validation R2 logD = 0.781861
Validation rmse logP = 0.603659
Validation R2 logP = 0.843017
Epoch 80
Train function
Loss = 1.4598e-05, PNorm = 67.8654, GNorm = 0.2179, lr_0 = 1.5421e-04
Loss = 2.3407e-05, PNorm = 67.8675, GNorm = 0.3982, lr_0 = 1.5352e-04
Loss = 2.1337e-05, PNorm = 67.8678, GNorm = 0.2873, lr_0 = 1.5284e-04
Loss = 2.3978e-05, PNorm = 67.8688, GNorm = 0.2738, lr_0 = 1.5217e-04
Loss = 1.6167e-05, PNorm = 67.8700, GNorm = 0.1826, lr_0 = 1.5150e-04
Loss = 1.9744e-05, PNorm = 67.8717, GNorm = 0.0431, lr_0 = 1.5083e-04
Validation rmse logD = 0.554910
Validation R2 logD = 0.781681
Validation rmse logP = 0.603515
Validation R2 logP = 0.843092
Epoch 81
Train function
Loss = 1.6357e-05, PNorm = 67.8739, GNorm = 0.0756, lr_0 = 1.5009e-04
Loss = 1.7238e-05, PNorm = 67.8761, GNorm = 0.0896, lr_0 = 1.4943e-04
Loss = 1.3942e-05, PNorm = 67.8771, GNorm = 0.1278, lr_0 = 1.4877e-04
Loss = 1.9008e-05, PNorm = 67.8792, GNorm = 0.0561, lr_0 = 1.4811e-04
Loss = 1.4444e-05, PNorm = 67.8809, GNorm = 0.1053, lr_0 = 1.4745e-04
Validation rmse logD = 0.554790
Validation R2 logD = 0.781776
Validation rmse logP = 0.599876
Validation R2 logP = 0.844978
Epoch 82
Train function
Loss = 1.2917e-05, PNorm = 67.8818, GNorm = 0.0674, lr_0 = 1.4674e-04
Loss = 1.1388e-05, PNorm = 67.8827, GNorm = 0.0744, lr_0 = 1.4609e-04
Loss = 1.1219e-05, PNorm = 67.8833, GNorm = 0.0635, lr_0 = 1.4544e-04
Loss = 1.6874e-05, PNorm = 67.8839, GNorm = 0.1164, lr_0 = 1.4480e-04
Loss = 1.3892e-05, PNorm = 67.8858, GNorm = 0.1672, lr_0 = 1.4416e-04
Validation rmse logD = 0.554823
Validation R2 logD = 0.781750
Validation rmse logP = 0.600266
Validation R2 logP = 0.844776
Epoch 83
Train function
Loss = 8.7995e-06, PNorm = 67.8864, GNorm = 0.1863, lr_0 = 1.4346e-04
Loss = 1.0269e-05, PNorm = 67.8879, GNorm = 0.1311, lr_0 = 1.4282e-04
Loss = 1.0654e-05, PNorm = 67.8899, GNorm = 0.0359, lr_0 = 1.4219e-04
Loss = 1.2681e-05, PNorm = 67.8910, GNorm = 0.0746, lr_0 = 1.4156e-04
Loss = 1.5517e-05, PNorm = 67.8924, GNorm = 0.2556, lr_0 = 1.4093e-04
Loss = 1.6705e-05, PNorm = 67.8936, GNorm = 0.1354, lr_0 = 1.4031e-04
Loss = 4.0165e-05, PNorm = 67.8936, GNorm = 0.1116, lr_0 = 1.4025e-04
Validation rmse logD = 0.556521
Validation R2 logD = 0.780412
Validation rmse logP = 0.604412
Validation R2 logP = 0.842625
Epoch 84
Train function
Loss = 1.1689e-05, PNorm = 67.8945, GNorm = 0.0556, lr_0 = 1.3963e-04
Loss = 1.2727e-05, PNorm = 67.8965, GNorm = 0.0448, lr_0 = 1.3901e-04
Loss = 1.2729e-05, PNorm = 67.8980, GNorm = 0.0570, lr_0 = 1.3840e-04
Loss = 9.6842e-06, PNorm = 67.8987, GNorm = 0.0582, lr_0 = 1.3778e-04
Loss = 1.0996e-05, PNorm = 67.9001, GNorm = 0.0467, lr_0 = 1.3717e-04
Validation rmse logD = 0.555077
Validation R2 logD = 0.781550
Validation rmse logP = 0.599561
Validation R2 logP = 0.845141
Epoch 85
Train function
Loss = 1.0613e-05, PNorm = 67.9007, GNorm = 0.1017, lr_0 = 1.3651e-04
Loss = 1.4349e-05, PNorm = 67.9022, GNorm = 0.0818, lr_0 = 1.3590e-04
Loss = 1.1380e-05, PNorm = 67.9034, GNorm = 0.0629, lr_0 = 1.3530e-04
Loss = 1.2294e-05, PNorm = 67.9045, GNorm = 0.0670, lr_0 = 1.3470e-04
Loss = 1.0890e-05, PNorm = 67.9058, GNorm = 0.0686, lr_0 = 1.3411e-04
Validation rmse logD = 0.554805
Validation R2 logD = 0.781764
Validation rmse logP = 0.602201
Validation R2 logP = 0.843774
Epoch 86
Train function
Loss = 7.9847e-06, PNorm = 67.9069, GNorm = 0.1205, lr_0 = 1.3346e-04
Loss = 1.0827e-05, PNorm = 67.9081, GNorm = 0.1622, lr_0 = 1.3287e-04
Loss = 1.3901e-05, PNorm = 67.9093, GNorm = 0.1279, lr_0 = 1.3228e-04
Loss = 1.1003e-05, PNorm = 67.9108, GNorm = 0.0482, lr_0 = 1.3169e-04
Loss = 1.0788e-05, PNorm = 67.9114, GNorm = 0.1202, lr_0 = 1.3111e-04
Validation rmse logD = 0.554836
Validation R2 logD = 0.781740
Validation rmse logP = 0.600321
Validation R2 logP = 0.844748
Epoch 87
Train function
Loss = 9.4185e-06, PNorm = 67.9125, GNorm = 0.1434, lr_0 = 1.3047e-04
Loss = 7.7049e-06, PNorm = 67.9135, GNorm = 0.1028, lr_0 = 1.2990e-04
Loss = 8.7650e-06, PNorm = 67.9143, GNorm = 0.0804, lr_0 = 1.2932e-04
Loss = 9.0155e-06, PNorm = 67.9151, GNorm = 0.0586, lr_0 = 1.2875e-04
Loss = 8.8217e-06, PNorm = 67.9160, GNorm = 0.0881, lr_0 = 1.2818e-04
Loss = 1.7715e-05, PNorm = 67.9177, GNorm = 0.1750, lr_0 = 1.2761e-04
Validation rmse logD = 0.555206
Validation R2 logD = 0.781448
Validation rmse logP = 0.603487
Validation R2 logP = 0.843106
Epoch 88
Train function
Loss = 6.6564e-06, PNorm = 67.9181, GNorm = 0.0622, lr_0 = 1.2699e-04
Loss = 1.1495e-05, PNorm = 67.9191, GNorm = 0.1238, lr_0 = 1.2643e-04
Loss = 1.1536e-05, PNorm = 67.9202, GNorm = 0.0483, lr_0 = 1.2587e-04
Loss = 1.1712e-05, PNorm = 67.9212, GNorm = 0.0514, lr_0 = 1.2531e-04
Loss = 6.9291e-06, PNorm = 67.9221, GNorm = 0.0876, lr_0 = 1.2476e-04
Validation rmse logD = 0.554737
Validation R2 logD = 0.781818
Validation rmse logP = 0.602888
Validation R2 logP = 0.843418
Epoch 89
Train function
Loss = 9.5917e-06, PNorm = 67.9230, GNorm = 0.2103, lr_0 = 1.2415e-04
Loss = 1.4393e-05, PNorm = 67.9233, GNorm = 0.1063, lr_0 = 1.2360e-04
Loss = 7.1687e-06, PNorm = 67.9244, GNorm = 0.0436, lr_0 = 1.2306e-04
Loss = 8.8572e-06, PNorm = 67.9255, GNorm = 0.0429, lr_0 = 1.2251e-04
Loss = 8.4566e-06, PNorm = 67.9270, GNorm = 0.0566, lr_0 = 1.2197e-04
Validation rmse logD = 0.556272
Validation R2 logD = 0.780609
Validation rmse logP = 0.603079
Validation R2 logP = 0.843318
Epoch 90
Train function
Loss = 6.3297e-06, PNorm = 67.9287, GNorm = 0.0674, lr_0 = 1.2143e-04
Loss = 9.5299e-06, PNorm = 67.9299, GNorm = 0.0956, lr_0 = 1.2089e-04
Loss = 9.1613e-06, PNorm = 67.9306, GNorm = 0.1169, lr_0 = 1.2036e-04
Loss = 7.8219e-06, PNorm = 67.9307, GNorm = 0.0472, lr_0 = 1.1983e-04
Loss = 1.2123e-05, PNorm = 67.9322, GNorm = 0.1440, lr_0 = 1.1930e-04
Loss = 8.9576e-06, PNorm = 67.9339, GNorm = 0.1140, lr_0 = 1.1877e-04
Validation rmse logD = 0.556528
Validation R2 logD = 0.780406
Validation rmse logP = 0.601976
Validation R2 logP = 0.843891
Epoch 91
Train function
Loss = 8.9150e-06, PNorm = 67.9354, GNorm = 0.1789, lr_0 = 1.1819e-04
Loss = 9.2388e-06, PNorm = 67.9363, GNorm = 0.1582, lr_0 = 1.1767e-04
Loss = 8.1430e-06, PNorm = 67.9364, GNorm = 0.0712, lr_0 = 1.1715e-04
Loss = 9.9080e-06, PNorm = 67.9377, GNorm = 0.2155, lr_0 = 1.1663e-04
Loss = 9.8065e-06, PNorm = 67.9388, GNorm = 0.1203, lr_0 = 1.1611e-04
Validation rmse logD = 0.555593
Validation R2 logD = 0.781144
Validation rmse logP = 0.604093
Validation R2 logP = 0.842791
Epoch 92
Train function
Loss = 7.7040e-06, PNorm = 67.9397, GNorm = 0.1516, lr_0 = 1.1555e-04
Loss = 9.6532e-06, PNorm = 67.9408, GNorm = 0.1238, lr_0 = 1.1504e-04
Loss = 8.3609e-06, PNorm = 67.9417, GNorm = 0.1687, lr_0 = 1.1453e-04
Loss = 6.6583e-06, PNorm = 67.9425, GNorm = 0.0385, lr_0 = 1.1402e-04
Loss = 9.7293e-06, PNorm = 67.9430, GNorm = 0.0742, lr_0 = 1.1352e-04
Validation rmse logD = 0.555665
Validation R2 logD = 0.781087
Validation rmse logP = 0.599978
Validation R2 logP = 0.844925
Epoch 93
Train function
Loss = 6.2766e-06, PNorm = 67.9431, GNorm = 0.0908, lr_0 = 1.1297e-04
Loss = 8.0177e-06, PNorm = 67.9445, GNorm = 0.0338, lr_0 = 1.1247e-04
Loss = 7.2767e-06, PNorm = 67.9460, GNorm = 0.0428, lr_0 = 1.1197e-04
Loss = 9.0677e-06, PNorm = 67.9477, GNorm = 0.0588, lr_0 = 1.1147e-04
Loss = 7.2309e-06, PNorm = 67.9480, GNorm = 0.0343, lr_0 = 1.1098e-04
Loss = 7.5084e-06, PNorm = 67.9484, GNorm = 0.0767, lr_0 = 1.1049e-04
Validation rmse logD = 0.555805
Validation R2 logD = 0.780977
Validation rmse logP = 0.600163
Validation R2 logP = 0.844830
Epoch 94
Train function
Loss = 6.6992e-06, PNorm = 67.9493, GNorm = 0.0925, lr_0 = 1.0995e-04
Loss = 8.6556e-06, PNorm = 67.9501, GNorm = 0.0808, lr_0 = 1.0947e-04
Loss = 6.1799e-06, PNorm = 67.9511, GNorm = 0.0389, lr_0 = 1.0898e-04
Loss = 8.2949e-06, PNorm = 67.9516, GNorm = 0.0653, lr_0 = 1.0850e-04
Loss = 7.6429e-06, PNorm = 67.9526, GNorm = 0.0542, lr_0 = 1.0802e-04
Validation rmse logD = 0.555568
Validation R2 logD = 0.781163
Validation rmse logP = 0.602306
Validation R2 logP = 0.843720
Epoch 95
Train function
Loss = 1.1703e-05, PNorm = 67.9540, GNorm = 0.1436, lr_0 = 1.0749e-04
Loss = 1.5577e-05, PNorm = 67.9547, GNorm = 0.1417, lr_0 = 1.0702e-04
Loss = 9.5751e-06, PNorm = 67.9548, GNorm = 0.1227, lr_0 = 1.0654e-04
Loss = 1.1718e-05, PNorm = 67.9553, GNorm = 0.2719, lr_0 = 1.0607e-04
Loss = 7.5828e-06, PNorm = 67.9564, GNorm = 0.0821, lr_0 = 1.0560e-04
Validation rmse logD = 0.556157
Validation R2 logD = 0.780699
Validation rmse logP = 0.603815
Validation R2 logP = 0.842936
Epoch 96
Train function
Loss = 8.1826e-06, PNorm = 67.9572, GNorm = 0.1216, lr_0 = 1.0509e-04
Loss = 7.0348e-06, PNorm = 67.9585, GNorm = 0.0471, lr_0 = 1.0463e-04
Loss = 1.0146e-05, PNorm = 67.9603, GNorm = 0.0856, lr_0 = 1.0416e-04
Loss = 9.6567e-06, PNorm = 67.9615, GNorm = 0.1311, lr_0 = 1.0370e-04
Loss = 8.5379e-06, PNorm = 67.9622, GNorm = 0.1277, lr_0 = 1.0324e-04
Loss = 9.7635e-06, PNorm = 67.9634, GNorm = 0.1671, lr_0 = 1.0279e-04
Loss = 4.6841e-05, PNorm = 67.9634, GNorm = 0.1638, lr_0 = 1.0274e-04
Validation rmse logD = 0.556151
Validation R2 logD = 0.780704
Validation rmse logP = 0.600417
Validation R2 logP = 0.844698
Epoch 97
Train function
Loss = 1.1353e-05, PNorm = 67.9649, GNorm = 0.1458, lr_0 = 1.0229e-04
Loss = 7.1363e-06, PNorm = 67.9660, GNorm = 0.0762, lr_0 = 1.0183e-04
Loss = 8.0666e-06, PNorm = 67.9669, GNorm = 0.0445, lr_0 = 1.0138e-04
Loss = 7.0220e-06, PNorm = 67.9685, GNorm = 0.0636, lr_0 = 1.0094e-04
Loss = 9.0660e-06, PNorm = 67.9695, GNorm = 0.1078, lr_0 = 1.0049e-04
Validation rmse logD = 0.556608
Validation R2 logD = 0.780343
Validation rmse logP = 0.601868
Validation R2 logP = 0.843947
Epoch 98
Train function
Loss = 7.3505e-06, PNorm = 67.9697, GNorm = 0.0543, lr_0 = 1.0000e-04
Loss = 6.7788e-06, PNorm = 67.9699, GNorm = 0.0470, lr_0 = 1.0000e-04
Loss = 7.8526e-06, PNorm = 67.9706, GNorm = 0.0807, lr_0 = 1.0000e-04
Loss = 7.9660e-06, PNorm = 67.9716, GNorm = 0.0628, lr_0 = 1.0000e-04
Loss = 7.6287e-06, PNorm = 67.9726, GNorm = 0.1062, lr_0 = 1.0000e-04
Validation rmse logD = 0.556817
Validation R2 logD = 0.780178
Validation rmse logP = 0.599464
Validation R2 logP = 0.845191
Epoch 99
Train function
Loss = 6.3769e-06, PNorm = 67.9733, GNorm = 0.1032, lr_0 = 1.0000e-04
Loss = 9.2017e-06, PNorm = 67.9735, GNorm = 0.0489, lr_0 = 1.0000e-04
Loss = 7.3923e-06, PNorm = 67.9741, GNorm = 0.1550, lr_0 = 1.0000e-04
Loss = 8.7968e-06, PNorm = 67.9750, GNorm = 0.0685, lr_0 = 1.0000e-04
Loss = 6.1315e-06, PNorm = 67.9757, GNorm = 0.1214, lr_0 = 1.0000e-04
Loss = 6.5057e-06, PNorm = 67.9767, GNorm = 0.1323, lr_0 = 1.0000e-04
Validation rmse logD = 0.555478
Validation R2 logD = 0.781234
Validation rmse logP = 0.602958
Validation R2 logP = 0.843381
Model 0 best validation rmse = 0.566996 on epoch 44
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.587634
Model 0 test R2 logD = 0.757478
Model 0 test rmse logP = 0.715431
Model 0 test R2 logP = 0.778984
Ensemble test rmse  logD= 0.587634
Ensemble test R2  logD= 0.757478
Ensemble test rmse  logP= 0.715431
Ensemble test R2  logP= 0.778984
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.0504e-02, PNorm = 55.5679, GNorm = 2.3133, lr_0 = 1.9340e-04
Loss = 1.7809e-02, PNorm = 55.5773, GNorm = 1.4919, lr_0 = 2.7830e-04
Loss = 1.5525e-02, PNorm = 55.5937, GNorm = 4.0029, lr_0 = 3.6321e-04
Loss = 1.5060e-02, PNorm = 55.6177, GNorm = 3.1713, lr_0 = 4.4811e-04
Loss = 1.3970e-02, PNorm = 55.6524, GNorm = 2.4623, lr_0 = 5.3302e-04
Validation rmse logD = 1.227140
Validation R2 logD = -0.009485
Validation rmse logP = 1.364664
Validation R2 logP = 0.374891
Epoch 1
Train function
Loss = 1.9792e-02, PNorm = 55.7066, GNorm = 7.7630, lr_0 = 6.2642e-04
Loss = 1.5210e-02, PNorm = 55.7781, GNorm = 1.8759, lr_0 = 7.1132e-04
Loss = 1.3110e-02, PNorm = 55.8745, GNorm = 1.0940, lr_0 = 7.9623e-04
Loss = 1.2019e-02, PNorm = 55.9666, GNorm = 1.1014, lr_0 = 8.8113e-04
Loss = 1.3199e-02, PNorm = 56.0696, GNorm = 1.4020, lr_0 = 9.6604e-04
Validation rmse logD = 0.944619
Validation R2 logD = 0.401830
Validation rmse logP = 1.418295
Validation R2 logP = 0.324792
Epoch 2
Train function
Loss = 1.1700e-02, PNorm = 56.1835, GNorm = 1.1148, lr_0 = 9.9690e-04
Loss = 9.8490e-03, PNorm = 56.2878, GNorm = 2.5362, lr_0 = 9.9249e-04
Loss = 1.0961e-02, PNorm = 56.3773, GNorm = 1.9731, lr_0 = 9.8810e-04
Loss = 1.0449e-02, PNorm = 56.4893, GNorm = 2.2123, lr_0 = 9.8373e-04
Loss = 9.8863e-03, PNorm = 56.5979, GNorm = 2.3620, lr_0 = 9.7938e-04
Validation rmse logD = 0.843441
Validation R2 logD = 0.523107
Validation rmse logP = 1.119658
Validation R2 logP = 0.579201
Epoch 3
Train function
Loss = 7.9758e-03, PNorm = 56.7141, GNorm = 1.0623, lr_0 = 9.7462e-04
Loss = 9.5675e-03, PNorm = 56.8251, GNorm = 1.5639, lr_0 = 9.7030e-04
Loss = 7.9440e-03, PNorm = 56.9208, GNorm = 0.7717, lr_0 = 9.6601e-04
Loss = 8.9790e-03, PNorm = 57.0318, GNorm = 3.4984, lr_0 = 9.6174e-04
Loss = 8.3072e-03, PNorm = 57.1524, GNorm = 1.5759, lr_0 = 9.5749e-04
Loss = 8.4634e-03, PNorm = 57.2465, GNorm = 2.1227, lr_0 = 9.5325e-04
Validation rmse logD = 0.867919
Validation R2 logD = 0.495025
Validation rmse logP = 0.939105
Validation R2 logP = 0.703972
Epoch 4
Train function
Loss = 7.5579e-03, PNorm = 57.3530, GNorm = 2.9551, lr_0 = 9.4861e-04
Loss = 9.0734e-03, PNorm = 57.4661, GNorm = 3.2421, lr_0 = 9.4442e-04
Loss = 7.5589e-03, PNorm = 57.5908, GNorm = 4.1979, lr_0 = 9.4024e-04
Loss = 7.5443e-03, PNorm = 57.6843, GNorm = 0.9851, lr_0 = 9.3608e-04
Loss = 7.2445e-03, PNorm = 57.7919, GNorm = 1.4656, lr_0 = 9.3194e-04
Validation rmse logD = 0.769558
Validation R2 logD = 0.602997
Validation rmse logP = 1.045234
Validation R2 logP = 0.633283
Epoch 5
Train function
Loss = 6.7912e-03, PNorm = 57.8816, GNorm = 1.3992, lr_0 = 9.2741e-04
Loss = 7.3015e-03, PNorm = 57.9773, GNorm = 1.0548, lr_0 = 9.2330e-04
Loss = 6.4444e-03, PNorm = 58.0832, GNorm = 3.1046, lr_0 = 9.1922e-04
Loss = 6.1291e-03, PNorm = 58.1595, GNorm = 3.4163, lr_0 = 9.1515e-04
Loss = 6.5026e-03, PNorm = 58.2581, GNorm = 4.5830, lr_0 = 9.1111e-04
Validation rmse logD = 0.794026
Validation R2 logD = 0.577350
Validation rmse logP = 0.868418
Validation R2 logP = 0.746860
Epoch 6
Train function
Loss = 7.0563e-03, PNorm = 58.3697, GNorm = 2.2016, lr_0 = 9.0667e-04
Loss = 5.9617e-03, PNorm = 58.4495, GNorm = 3.5081, lr_0 = 9.0266e-04
Loss = 6.4673e-03, PNorm = 58.5482, GNorm = 1.2030, lr_0 = 8.9867e-04
Loss = 5.3871e-03, PNorm = 58.6385, GNorm = 1.7517, lr_0 = 8.9469e-04
Loss = 5.6966e-03, PNorm = 58.7235, GNorm = 1.1488, lr_0 = 8.9074e-04
Loss = 6.4373e-03, PNorm = 58.8461, GNorm = 1.2137, lr_0 = 8.8680e-04
Validation rmse logD = 0.706921
Validation R2 logD = 0.664993
Validation rmse logP = 0.799455
Validation R2 logP = 0.785468
Epoch 7
Train function
Loss = 4.6813e-03, PNorm = 58.9523, GNorm = 1.0551, lr_0 = 8.8248e-04
Loss = 6.2447e-03, PNorm = 59.0455, GNorm = 1.7163, lr_0 = 8.7858e-04
Loss = 5.5998e-03, PNorm = 59.1377, GNorm = 1.2623, lr_0 = 8.7469e-04
Loss = 5.4298e-03, PNorm = 59.2414, GNorm = 0.7787, lr_0 = 8.7082e-04
Loss = 5.1867e-03, PNorm = 59.3334, GNorm = 1.5406, lr_0 = 8.6697e-04
Validation rmse logD = 0.694552
Validation R2 logD = 0.676614
Validation rmse logP = 0.834014
Validation R2 logP = 0.766519
Epoch 8
Train function
Loss = 4.6415e-03, PNorm = 59.4383, GNorm = 1.7904, lr_0 = 8.6276e-04
Loss = 5.3104e-03, PNorm = 59.5389, GNorm = 4.2156, lr_0 = 8.5894e-04
Loss = 5.6816e-03, PNorm = 59.6450, GNorm = 1.2914, lr_0 = 8.5514e-04
Loss = 5.2721e-03, PNorm = 59.7470, GNorm = 1.0687, lr_0 = 8.5136e-04
Loss = 4.0834e-03, PNorm = 59.8276, GNorm = 1.0744, lr_0 = 8.4759e-04
Validation rmse logD = 0.782171
Validation R2 logD = 0.589877
Validation rmse logP = 0.852076
Validation R2 logP = 0.756297
Epoch 9
Train function
Loss = 5.9997e-03, PNorm = 59.9341, GNorm = 3.4310, lr_0 = 8.4384e-04
Loss = 5.2000e-03, PNorm = 60.0491, GNorm = 2.9255, lr_0 = 8.4011e-04
Loss = 4.7325e-03, PNorm = 60.1730, GNorm = 2.9151, lr_0 = 8.3639e-04
Loss = 4.4818e-03, PNorm = 60.2829, GNorm = 1.5384, lr_0 = 8.3269e-04
Loss = 4.1455e-03, PNorm = 60.3810, GNorm = 1.3027, lr_0 = 8.2901e-04
Loss = 3.5498e-03, PNorm = 60.4627, GNorm = 1.6659, lr_0 = 8.2534e-04
Validation rmse logD = 0.636992
Validation R2 logD = 0.727993
Validation rmse logP = 0.810434
Validation R2 logP = 0.779535
Epoch 10
Train function
Loss = 3.2364e-03, PNorm = 60.5458, GNorm = 1.8497, lr_0 = 8.2133e-04
Loss = 4.1461e-03, PNorm = 60.6213, GNorm = 2.3074, lr_0 = 8.1770e-04
Loss = 3.6707e-03, PNorm = 60.7219, GNorm = 0.8418, lr_0 = 8.1408e-04
Loss = 3.6001e-03, PNorm = 60.8086, GNorm = 1.1651, lr_0 = 8.1048e-04
Loss = 3.5480e-03, PNorm = 60.8868, GNorm = 2.6992, lr_0 = 8.0689e-04
Validation rmse logD = 0.677051
Validation R2 logD = 0.692705
Validation rmse logP = 0.861430
Validation R2 logP = 0.750917
Epoch 11
Train function
Loss = 3.1103e-03, PNorm = 60.9804, GNorm = 0.9381, lr_0 = 8.0297e-04
Loss = 3.2539e-03, PNorm = 61.0674, GNorm = 1.9167, lr_0 = 7.9942e-04
Loss = 3.2471e-03, PNorm = 61.1438, GNorm = 1.5794, lr_0 = 7.9588e-04
Loss = 3.4129e-03, PNorm = 61.2232, GNorm = 0.9381, lr_0 = 7.9236e-04
Loss = 3.3228e-03, PNorm = 61.3009, GNorm = 1.0418, lr_0 = 7.8885e-04
Validation rmse logD = 0.641330
Validation R2 logD = 0.724276
Validation rmse logP = 0.840544
Validation R2 logP = 0.762849
Epoch 12
Train function
Loss = 2.9814e-03, PNorm = 61.3833, GNorm = 0.9498, lr_0 = 7.8502e-04
Loss = 3.0099e-03, PNorm = 61.4731, GNorm = 0.7951, lr_0 = 7.8154e-04
Loss = 2.8596e-03, PNorm = 61.5529, GNorm = 1.1589, lr_0 = 7.7809e-04
Loss = 3.2229e-03, PNorm = 61.6293, GNorm = 0.8925, lr_0 = 7.7465e-04
Loss = 2.8967e-03, PNorm = 61.7167, GNorm = 1.7706, lr_0 = 7.7122e-04
Loss = 3.0650e-03, PNorm = 61.8036, GNorm = 0.8220, lr_0 = 7.6781e-04
Loss = 3.5448e-02, PNorm = 61.8102, GNorm = 5.7621, lr_0 = 7.6747e-04
Validation rmse logD = 0.617997
Validation R2 logD = 0.743974
Validation rmse logP = 0.764167
Validation R2 logP = 0.803989
Epoch 13
Train function
Loss = 2.7363e-03, PNorm = 61.9047, GNorm = 1.4433, lr_0 = 7.6407e-04
Loss = 2.2725e-03, PNorm = 61.9961, GNorm = 1.1292, lr_0 = 7.6069e-04
Loss = 2.4100e-03, PNorm = 62.0498, GNorm = 1.9759, lr_0 = 7.5733e-04
Loss = 2.6398e-03, PNorm = 62.1269, GNorm = 0.6849, lr_0 = 7.5398e-04
Loss = 2.8718e-03, PNorm = 62.1969, GNorm = 0.8903, lr_0 = 7.5064e-04
Validation rmse logD = 0.617177
Validation R2 logD = 0.744653
Validation rmse logP = 0.774221
Validation R2 logP = 0.798797
Epoch 14
Train function
Loss = 2.2269e-03, PNorm = 62.2762, GNorm = 0.9070, lr_0 = 7.4699e-04
Loss = 2.1301e-03, PNorm = 62.3448, GNorm = 1.0131, lr_0 = 7.4369e-04
Loss = 1.9003e-03, PNorm = 62.4114, GNorm = 0.9052, lr_0 = 7.4040e-04
Loss = 2.0802e-03, PNorm = 62.4681, GNorm = 0.6976, lr_0 = 7.3712e-04
Loss = 1.7743e-03, PNorm = 62.5307, GNorm = 0.7582, lr_0 = 7.3386e-04
Validation rmse logD = 0.598502
Validation R2 logD = 0.759872
Validation rmse logP = 0.767963
Validation R2 logP = 0.802037
Epoch 15
Train function
Loss = 2.0114e-03, PNorm = 62.6009, GNorm = 0.8795, lr_0 = 7.3029e-04
Loss = 1.6261e-03, PNorm = 62.6723, GNorm = 0.8611, lr_0 = 7.2706e-04
Loss = 1.6239e-03, PNorm = 62.7437, GNorm = 0.9542, lr_0 = 7.2385e-04
Loss = 1.6495e-03, PNorm = 62.7963, GNorm = 0.6301, lr_0 = 7.2064e-04
Loss = 1.6436e-03, PNorm = 62.8512, GNorm = 1.0719, lr_0 = 7.1746e-04
Validation rmse logD = 0.622739
Validation R2 logD = 0.740030
Validation rmse logP = 0.821226
Validation R2 logP = 0.773625
Epoch 16
Train function
Loss = 1.9655e-03, PNorm = 62.9167, GNorm = 2.5216, lr_0 = 7.1397e-04
Loss = 3.4172e-03, PNorm = 63.0257, GNorm = 1.0750, lr_0 = 7.1081e-04
Loss = 3.0715e-03, PNorm = 63.1414, GNorm = 2.1484, lr_0 = 7.0766e-04
Loss = 2.2554e-03, PNorm = 63.2455, GNorm = 1.1255, lr_0 = 7.0453e-04
Loss = 1.8986e-03, PNorm = 63.3261, GNorm = 0.7236, lr_0 = 7.0142e-04
Loss = 2.1094e-03, PNorm = 63.3920, GNorm = 2.1126, lr_0 = 6.9831e-04
Validation rmse logD = 0.606395
Validation R2 logD = 0.753496
Validation rmse logP = 0.775889
Validation R2 logP = 0.797929
Epoch 17
Train function
Loss = 1.5528e-03, PNorm = 63.4542, GNorm = 0.7620, lr_0 = 6.9523e-04
Loss = 1.9334e-03, PNorm = 63.5118, GNorm = 1.0326, lr_0 = 6.9215e-04
Loss = 1.9439e-03, PNorm = 63.5663, GNorm = 1.1072, lr_0 = 6.8909e-04
Loss = 1.7101e-03, PNorm = 63.6295, GNorm = 0.8018, lr_0 = 6.8604e-04
Loss = 1.4891e-03, PNorm = 63.6900, GNorm = 0.5431, lr_0 = 6.8301e-04
Validation rmse logD = 0.582971
Validation R2 logD = 0.772173
Validation rmse logP = 0.794304
Validation R2 logP = 0.788223
Epoch 18
Train function
Loss = 1.0332e-03, PNorm = 63.7326, GNorm = 0.5590, lr_0 = 6.7968e-04
Loss = 1.4072e-03, PNorm = 63.7747, GNorm = 0.5469, lr_0 = 6.7668e-04
Loss = 1.3433e-03, PNorm = 63.8131, GNorm = 1.4432, lr_0 = 6.7368e-04
Loss = 1.4568e-03, PNorm = 63.8712, GNorm = 1.0387, lr_0 = 6.7070e-04
Loss = 1.3118e-03, PNorm = 63.9152, GNorm = 0.9834, lr_0 = 6.6774e-04
Validation rmse logD = 0.585419
Validation R2 logD = 0.770256
Validation rmse logP = 0.760694
Validation R2 logP = 0.805767
Epoch 19
Train function
Loss = 9.0098e-04, PNorm = 63.9528, GNorm = 1.2048, lr_0 = 6.6449e-04
Loss = 1.2962e-03, PNorm = 63.9962, GNorm = 0.8713, lr_0 = 6.6155e-04
Loss = 1.2166e-03, PNorm = 64.0369, GNorm = 0.5037, lr_0 = 6.5862e-04
Loss = 1.2655e-03, PNorm = 64.0744, GNorm = 1.3166, lr_0 = 6.5571e-04
Loss = 1.1020e-03, PNorm = 64.1178, GNorm = 0.5445, lr_0 = 6.5281e-04
Loss = 9.7420e-04, PNorm = 64.1536, GNorm = 0.6176, lr_0 = 6.4992e-04
Validation rmse logD = 0.592550
Validation R2 logD = 0.764624
Validation rmse logP = 0.790044
Validation R2 logP = 0.790489
Epoch 20
Train function
Loss = 8.7254e-04, PNorm = 64.2106, GNorm = 1.1059, lr_0 = 6.4676e-04
Loss = 1.1885e-03, PNorm = 64.2629, GNorm = 0.9788, lr_0 = 6.4390e-04
Loss = 8.9659e-04, PNorm = 64.3081, GNorm = 0.5921, lr_0 = 6.4105e-04
Loss = 1.0915e-03, PNorm = 64.3409, GNorm = 1.2515, lr_0 = 6.3822e-04
Loss = 1.1673e-03, PNorm = 64.3609, GNorm = 1.0128, lr_0 = 6.3539e-04
Validation rmse logD = 0.585685
Validation R2 logD = 0.770047
Validation rmse logP = 0.764350
Validation R2 logP = 0.803895
Epoch 21
Train function
Loss = 8.8024e-04, PNorm = 64.4101, GNorm = 0.5341, lr_0 = 6.3230e-04
Loss = 1.0104e-03, PNorm = 64.4520, GNorm = 0.5755, lr_0 = 6.2950e-04
Loss = 1.0353e-03, PNorm = 64.4853, GNorm = 0.4769, lr_0 = 6.2672e-04
Loss = 1.0122e-03, PNorm = 64.5224, GNorm = 1.3994, lr_0 = 6.2395e-04
Loss = 8.4697e-04, PNorm = 64.5572, GNorm = 1.2445, lr_0 = 6.2119e-04
Validation rmse logD = 0.605842
Validation R2 logD = 0.753946
Validation rmse logP = 0.774128
Validation R2 logP = 0.798846
Epoch 22
Train function
Loss = 1.0601e-03, PNorm = 64.5949, GNorm = 1.4078, lr_0 = 6.1817e-04
Loss = 7.4530e-04, PNorm = 64.6202, GNorm = 0.4507, lr_0 = 6.1543e-04
Loss = 9.1429e-04, PNorm = 64.6515, GNorm = 1.2339, lr_0 = 6.1271e-04
Loss = 9.3529e-04, PNorm = 64.6699, GNorm = 1.1365, lr_0 = 6.1000e-04
Loss = 7.8420e-04, PNorm = 64.6930, GNorm = 0.5115, lr_0 = 6.0730e-04
Loss = 8.6072e-04, PNorm = 64.7274, GNorm = 0.9953, lr_0 = 6.0461e-04
Validation rmse logD = 0.585629
Validation R2 logD = 0.770091
Validation rmse logP = 0.746946
Validation R2 logP = 0.812724
Epoch 23
Train function
Loss = 7.0727e-04, PNorm = 64.7541, GNorm = 0.5214, lr_0 = 6.0167e-04
Loss = 8.2154e-04, PNorm = 64.7803, GNorm = 1.5386, lr_0 = 5.9901e-04
Loss = 7.9959e-04, PNorm = 64.8138, GNorm = 1.3122, lr_0 = 5.9636e-04
Loss = 7.1328e-04, PNorm = 64.8392, GNorm = 0.6168, lr_0 = 5.9372e-04
Loss = 7.6176e-04, PNorm = 64.8633, GNorm = 0.3119, lr_0 = 5.9110e-04
Validation rmse logD = 0.591385
Validation R2 logD = 0.765549
Validation rmse logP = 0.745061
Validation R2 logP = 0.813668
Epoch 24
Train function
Loss = 1.1188e-03, PNorm = 64.9043, GNorm = 1.4946, lr_0 = 5.8822e-04
Loss = 9.1337e-04, PNorm = 64.9425, GNorm = 1.1036, lr_0 = 5.8562e-04
Loss = 1.0027e-03, PNorm = 64.9781, GNorm = 0.5669, lr_0 = 5.8303e-04
Loss = 1.0327e-03, PNorm = 65.0106, GNorm = 0.6604, lr_0 = 5.8045e-04
Loss = 6.5166e-04, PNorm = 65.0404, GNorm = 0.4279, lr_0 = 5.7788e-04
Validation rmse logD = 0.579167
Validation R2 logD = 0.775137
Validation rmse logP = 0.760040
Validation R2 logP = 0.806101
Epoch 25
Train function
Loss = 4.8852e-04, PNorm = 65.0593, GNorm = 0.4134, lr_0 = 5.7533e-04
Loss = 7.6452e-04, PNorm = 65.0888, GNorm = 0.2799, lr_0 = 5.7278e-04
Loss = 6.4421e-04, PNorm = 65.1124, GNorm = 1.5014, lr_0 = 5.7025e-04
Loss = 6.7834e-04, PNorm = 65.1426, GNorm = 0.3413, lr_0 = 5.6773e-04
Loss = 6.2662e-04, PNorm = 65.1731, GNorm = 0.3780, lr_0 = 5.6522e-04
Loss = 6.2492e-04, PNorm = 65.1978, GNorm = 1.5129, lr_0 = 5.6272e-04
Validation rmse logD = 0.593565
Validation R2 logD = 0.763817
Validation rmse logP = 0.741506
Validation R2 logP = 0.815442
Epoch 26
Train function
Loss = 5.4819e-04, PNorm = 65.2222, GNorm = 0.5363, lr_0 = 5.5998e-04
Loss = 6.3359e-04, PNorm = 65.2405, GNorm = 0.4878, lr_0 = 5.5750e-04
Loss = 5.7799e-04, PNorm = 65.2611, GNorm = 0.4755, lr_0 = 5.5503e-04
Loss = 4.8151e-04, PNorm = 65.2820, GNorm = 0.3581, lr_0 = 5.5258e-04
Loss = 5.2942e-04, PNorm = 65.3025, GNorm = 0.6869, lr_0 = 5.5014e-04
Validation rmse logD = 0.588855
Validation R2 logD = 0.767551
Validation rmse logP = 0.766541
Validation R2 logP = 0.802769
Epoch 27
Train function
Loss = 6.5335e-04, PNorm = 65.3207, GNorm = 0.7744, lr_0 = 5.4746e-04
Loss = 4.4471e-04, PNorm = 65.3386, GNorm = 0.6323, lr_0 = 5.4504e-04
Loss = 4.8031e-04, PNorm = 65.3605, GNorm = 0.9018, lr_0 = 5.4263e-04
Loss = 7.1544e-04, PNorm = 65.3871, GNorm = 1.4020, lr_0 = 5.4023e-04
Loss = 5.7672e-04, PNorm = 65.4163, GNorm = 0.4827, lr_0 = 5.3784e-04
Validation rmse logD = 0.580537
Validation R2 logD = 0.774071
Validation rmse logP = 0.717937
Validation R2 logP = 0.826988
Epoch 28
Train function
Loss = 4.1899e-04, PNorm = 65.4363, GNorm = 0.9945, lr_0 = 5.3522e-04
Loss = 6.3883e-04, PNorm = 65.4624, GNorm = 0.5265, lr_0 = 5.3285e-04
Loss = 4.8834e-04, PNorm = 65.4968, GNorm = 0.4329, lr_0 = 5.3050e-04
Loss = 3.8983e-04, PNorm = 65.5172, GNorm = 0.3491, lr_0 = 5.2815e-04
Loss = 4.5965e-04, PNorm = 65.5269, GNorm = 0.4399, lr_0 = 5.2581e-04
Loss = 5.4579e-04, PNorm = 65.5509, GNorm = 0.9601, lr_0 = 5.2349e-04
Loss = 1.6405e-03, PNorm = 65.5524, GNorm = 0.8906, lr_0 = 5.2326e-04
Validation rmse logD = 0.588651
Validation R2 logD = 0.767712
Validation rmse logP = 0.755104
Validation R2 logP = 0.808610
Epoch 29
Train function
Loss = 4.5983e-04, PNorm = 65.5723, GNorm = 0.7388, lr_0 = 5.2094e-04
Loss = 4.7720e-04, PNorm = 65.5896, GNorm = 0.3542, lr_0 = 5.1864e-04
Loss = 4.0204e-04, PNorm = 65.6101, GNorm = 0.3620, lr_0 = 5.1634e-04
Loss = 5.4272e-04, PNorm = 65.6296, GNorm = 0.4243, lr_0 = 5.1406e-04
Loss = 3.8370e-04, PNorm = 65.6474, GNorm = 0.2899, lr_0 = 5.1178e-04
Validation rmse logD = 0.579615
Validation R2 logD = 0.774788
Validation rmse logP = 0.762424
Validation R2 logP = 0.804882
Epoch 30
Train function
Loss = 3.5024e-04, PNorm = 65.6700, GNorm = 0.4897, lr_0 = 5.0930e-04
Loss = 2.9926e-04, PNorm = 65.6842, GNorm = 0.3466, lr_0 = 5.0704e-04
Loss = 4.7942e-04, PNorm = 65.6976, GNorm = 0.3530, lr_0 = 5.0480e-04
Loss = 3.5996e-04, PNorm = 65.7151, GNorm = 0.4497, lr_0 = 5.0257e-04
Loss = 4.6655e-04, PNorm = 65.7322, GNorm = 0.7685, lr_0 = 5.0034e-04
Validation rmse logD = 0.599210
Validation R2 logD = 0.759303
Validation rmse logP = 0.757005
Validation R2 logP = 0.807646
Epoch 31
Train function
Loss = 4.4962e-04, PNorm = 65.7525, GNorm = 1.7427, lr_0 = 4.9791e-04
Loss = 4.1186e-04, PNorm = 65.7701, GNorm = 1.4213, lr_0 = 4.9571e-04
Loss = 4.5524e-04, PNorm = 65.7911, GNorm = 0.5712, lr_0 = 4.9351e-04
Loss = 3.8694e-04, PNorm = 65.8156, GNorm = 0.8894, lr_0 = 4.9133e-04
Loss = 3.7857e-04, PNorm = 65.8334, GNorm = 0.4034, lr_0 = 4.8916e-04
Validation rmse logD = 0.580345
Validation R2 logD = 0.774221
Validation rmse logP = 0.734281
Validation R2 logP = 0.819021
Epoch 32
Train function
Loss = 4.5791e-04, PNorm = 65.8557, GNorm = 0.5207, lr_0 = 4.8678e-04
Loss = 3.2582e-04, PNorm = 65.8740, GNorm = 0.2584, lr_0 = 4.8463e-04
Loss = 3.9518e-04, PNorm = 65.8880, GNorm = 0.5149, lr_0 = 4.8248e-04
Loss = 3.5222e-04, PNorm = 65.9093, GNorm = 1.0097, lr_0 = 4.8035e-04
Loss = 3.6491e-04, PNorm = 65.9237, GNorm = 0.4799, lr_0 = 4.7822e-04
Loss = 2.9010e-04, PNorm = 65.9342, GNorm = 0.5813, lr_0 = 4.7611e-04
Validation rmse logD = 0.578114
Validation R2 logD = 0.775953
Validation rmse logP = 0.749780
Validation R2 logP = 0.811300
Epoch 33
Train function
Loss = 3.5638e-04, PNorm = 65.9488, GNorm = 0.8599, lr_0 = 4.7379e-04
Loss = 2.8177e-04, PNorm = 65.9638, GNorm = 0.5807, lr_0 = 4.7170e-04
Loss = 3.3388e-04, PNorm = 65.9805, GNorm = 0.6788, lr_0 = 4.6961e-04
Loss = 3.1952e-04, PNorm = 65.9974, GNorm = 0.6555, lr_0 = 4.6753e-04
Loss = 3.3265e-04, PNorm = 66.0135, GNorm = 0.8495, lr_0 = 4.6546e-04
Validation rmse logD = 0.576042
Validation R2 logD = 0.777556
Validation rmse logP = 0.746770
Validation R2 logP = 0.812812
Epoch 34
Train function
Loss = 2.2288e-04, PNorm = 66.0224, GNorm = 0.4514, lr_0 = 4.6341e-04
Loss = 2.2662e-04, PNorm = 66.0358, GNorm = 0.2630, lr_0 = 4.6136e-04
Loss = 3.2564e-04, PNorm = 66.0522, GNorm = 0.2639, lr_0 = 4.5931e-04
Loss = 2.8420e-04, PNorm = 66.0682, GNorm = 0.6724, lr_0 = 4.5728e-04
Loss = 2.8618e-04, PNorm = 66.0777, GNorm = 0.2728, lr_0 = 4.5526e-04
Validation rmse logD = 0.577544
Validation R2 logD = 0.776394
Validation rmse logP = 0.732646
Validation R2 logP = 0.819826
Epoch 35
Train function
Loss = 1.6308e-04, PNorm = 66.0929, GNorm = 0.3009, lr_0 = 4.5305e-04
Loss = 2.6491e-04, PNorm = 66.1021, GNorm = 0.5759, lr_0 = 4.5104e-04
Loss = 2.6618e-04, PNorm = 66.1146, GNorm = 0.6164, lr_0 = 4.4905e-04
Loss = 2.5147e-04, PNorm = 66.1305, GNorm = 0.2445, lr_0 = 4.4706e-04
Loss = 2.8418e-04, PNorm = 66.1461, GNorm = 0.5845, lr_0 = 4.4508e-04
Loss = 2.9383e-04, PNorm = 66.1619, GNorm = 0.4971, lr_0 = 4.4311e-04
Validation rmse logD = 0.585909
Validation R2 logD = 0.769870
Validation rmse logP = 0.745777
Validation R2 logP = 0.813309
Epoch 36
Train function
Loss = 3.7184e-04, PNorm = 66.1811, GNorm = 0.6590, lr_0 = 4.4096e-04
Loss = 2.4395e-04, PNorm = 66.1931, GNorm = 0.8589, lr_0 = 4.3901e-04
Loss = 2.8518e-04, PNorm = 66.2103, GNorm = 0.2789, lr_0 = 4.3707e-04
Loss = 3.1915e-04, PNorm = 66.2240, GNorm = 0.7295, lr_0 = 4.3513e-04
Loss = 2.5015e-04, PNorm = 66.2351, GNorm = 0.3356, lr_0 = 4.3321e-04
Validation rmse logD = 0.578864
Validation R2 logD = 0.775371
Validation rmse logP = 0.731360
Validation R2 logP = 0.820458
Epoch 37
Train function
Loss = 3.3696e-04, PNorm = 66.2513, GNorm = 1.0155, lr_0 = 4.3110e-04
Loss = 2.7532e-04, PNorm = 66.2715, GNorm = 0.3480, lr_0 = 4.2919e-04
Loss = 2.6647e-04, PNorm = 66.2849, GNorm = 0.6126, lr_0 = 4.2729e-04
Loss = 2.7235e-04, PNorm = 66.2938, GNorm = 0.6365, lr_0 = 4.2540e-04
Loss = 2.4717e-04, PNorm = 66.3064, GNorm = 0.4729, lr_0 = 4.2352e-04
Validation rmse logD = 0.572627
Validation R2 logD = 0.780186
Validation rmse logP = 0.756763
Validation R2 logP = 0.807768
Epoch 38
Train function
Loss = 1.8497e-04, PNorm = 66.3233, GNorm = 0.1789, lr_0 = 4.2146e-04
Loss = 2.1132e-04, PNorm = 66.3344, GNorm = 0.3901, lr_0 = 4.1960e-04
Loss = 2.0221e-04, PNorm = 66.3385, GNorm = 0.5935, lr_0 = 4.1774e-04
Loss = 2.4035e-04, PNorm = 66.3453, GNorm = 0.2370, lr_0 = 4.1589e-04
Loss = 2.3736e-04, PNorm = 66.3557, GNorm = 0.2670, lr_0 = 4.1406e-04
Loss = 2.1336e-04, PNorm = 66.3672, GNorm = 0.2713, lr_0 = 4.1222e-04
Validation rmse logD = 0.578212
Validation R2 logD = 0.775877
Validation rmse logP = 0.743978
Validation R2 logP = 0.814209
Epoch 39
Train function
Loss = 1.9764e-04, PNorm = 66.3847, GNorm = 0.9037, lr_0 = 4.1022e-04
Loss = 1.9812e-04, PNorm = 66.3970, GNorm = 0.3058, lr_0 = 4.0840e-04
Loss = 1.7788e-04, PNorm = 66.4077, GNorm = 0.1995, lr_0 = 4.0660e-04
Loss = 2.6371e-04, PNorm = 66.4172, GNorm = 0.3644, lr_0 = 4.0480e-04
Loss = 1.9230e-04, PNorm = 66.4312, GNorm = 0.2135, lr_0 = 4.0301e-04
Validation rmse logD = 0.578040
Validation R2 logD = 0.776011
Validation rmse logP = 0.735402
Validation R2 logP = 0.818468
Epoch 40
Train function
Loss = 2.0646e-04, PNorm = 66.4408, GNorm = 0.3760, lr_0 = 4.0105e-04
Loss = 1.9682e-04, PNorm = 66.4483, GNorm = 0.1685, lr_0 = 3.9927e-04
Loss = 2.2257e-04, PNorm = 66.4569, GNorm = 0.6053, lr_0 = 3.9751e-04
Loss = 1.9677e-04, PNorm = 66.4681, GNorm = 0.3439, lr_0 = 3.9575e-04
Loss = 2.0839e-04, PNorm = 66.4812, GNorm = 0.3518, lr_0 = 3.9400e-04
Validation rmse logD = 0.585392
Validation R2 logD = 0.770276
Validation rmse logP = 0.747530
Validation R2 logP = 0.812431
Epoch 41
Train function
Loss = 2.5392e-04, PNorm = 66.4931, GNorm = 0.5869, lr_0 = 3.9208e-04
Loss = 1.9633e-04, PNorm = 66.5015, GNorm = 0.3623, lr_0 = 3.9035e-04
Loss = 1.9586e-04, PNorm = 66.5124, GNorm = 0.3856, lr_0 = 3.8862e-04
Loss = 1.5624e-04, PNorm = 66.5206, GNorm = 0.5234, lr_0 = 3.8690e-04
Loss = 2.6077e-04, PNorm = 66.5306, GNorm = 0.1910, lr_0 = 3.8519e-04
Loss = 2.3895e-04, PNorm = 66.5430, GNorm = 0.6649, lr_0 = 3.8349e-04
Validation rmse logD = 0.576534
Validation R2 logD = 0.777176
Validation rmse logP = 0.735979
Validation R2 logP = 0.818183
Epoch 42
Train function
Loss = 1.9798e-04, PNorm = 66.5520, GNorm = 0.4864, lr_0 = 3.8179e-04
Loss = 1.8844e-04, PNorm = 66.5656, GNorm = 0.2743, lr_0 = 3.8010e-04
Loss = 1.7457e-04, PNorm = 66.5786, GNorm = 0.3498, lr_0 = 3.7842e-04
Loss = 1.4679e-04, PNorm = 66.5885, GNorm = 0.4100, lr_0 = 3.7675e-04
Loss = 1.7284e-04, PNorm = 66.5961, GNorm = 0.3156, lr_0 = 3.7508e-04
Validation rmse logD = 0.579293
Validation R2 logD = 0.775038
Validation rmse logP = 0.746641
Validation R2 logP = 0.812877
Epoch 43
Train function
Loss = 1.7342e-04, PNorm = 66.6065, GNorm = 0.4104, lr_0 = 3.7326e-04
Loss = 1.8224e-04, PNorm = 66.6173, GNorm = 0.1519, lr_0 = 3.7160e-04
Loss = 1.7905e-04, PNorm = 66.6216, GNorm = 0.1581, lr_0 = 3.6996e-04
Loss = 1.4297e-04, PNorm = 66.6305, GNorm = 0.2304, lr_0 = 3.6832e-04
Loss = 1.7080e-04, PNorm = 66.6412, GNorm = 0.3117, lr_0 = 3.6669e-04
Validation rmse logD = 0.575768
Validation R2 logD = 0.777768
Validation rmse logP = 0.744286
Validation R2 logP = 0.814055
Epoch 44
Train function
Loss = 9.6425e-05, PNorm = 66.6497, GNorm = 0.3643, lr_0 = 3.6491e-04
Loss = 1.4112e-04, PNorm = 66.6573, GNorm = 0.6478, lr_0 = 3.6330e-04
Loss = 1.3708e-04, PNorm = 66.6662, GNorm = 0.4061, lr_0 = 3.6169e-04
Loss = 1.1923e-04, PNorm = 66.6736, GNorm = 0.1969, lr_0 = 3.6009e-04
Loss = 1.4719e-04, PNorm = 66.6813, GNorm = 0.5435, lr_0 = 3.5850e-04
Loss = 1.6220e-04, PNorm = 66.6903, GNorm = 0.3636, lr_0 = 3.5691e-04
Loss = 4.2298e-03, PNorm = 66.6903, GNorm = 2.2317, lr_0 = 3.5675e-04
Validation rmse logD = 0.577990
Validation R2 logD = 0.776049
Validation rmse logP = 0.745561
Validation R2 logP = 0.813418
Epoch 45
Train function
Loss = 2.1200e-04, PNorm = 66.6993, GNorm = 0.4326, lr_0 = 3.5518e-04
Loss = 1.4474e-04, PNorm = 66.7091, GNorm = 0.1795, lr_0 = 3.5360e-04
Loss = 1.4594e-04, PNorm = 66.7177, GNorm = 0.5636, lr_0 = 3.5204e-04
Loss = 1.5724e-04, PNorm = 66.7251, GNorm = 0.5219, lr_0 = 3.5048e-04
Loss = 1.0763e-04, PNorm = 66.7337, GNorm = 0.3443, lr_0 = 3.4893e-04
Validation rmse logD = 0.575506
Validation R2 logD = 0.777970
Validation rmse logP = 0.733593
Validation R2 logP = 0.819360
Epoch 46
Train function
Loss = 1.0266e-04, PNorm = 66.7414, GNorm = 0.3568, lr_0 = 3.4724e-04
Loss = 1.1443e-04, PNorm = 66.7471, GNorm = 0.4450, lr_0 = 3.4570e-04
Loss = 1.0316e-04, PNorm = 66.7532, GNorm = 0.2227, lr_0 = 3.4417e-04
Loss = 1.3604e-04, PNorm = 66.7601, GNorm = 0.5552, lr_0 = 3.4265e-04
Loss = 1.3464e-04, PNorm = 66.7668, GNorm = 0.6345, lr_0 = 3.4113e-04
Validation rmse logD = 0.577422
Validation R2 logD = 0.776489
Validation rmse logP = 0.740651
Validation R2 logP = 0.815867
Epoch 47
Train function
Loss = 1.3178e-04, PNorm = 66.7752, GNorm = 0.2977, lr_0 = 3.3947e-04
Loss = 1.5659e-04, PNorm = 66.7845, GNorm = 0.3023, lr_0 = 3.3797e-04
Loss = 1.0816e-04, PNorm = 66.7907, GNorm = 0.2492, lr_0 = 3.3648e-04
Loss = 1.5680e-04, PNorm = 66.7965, GNorm = 0.2809, lr_0 = 3.3499e-04
Loss = 1.1330e-04, PNorm = 66.8037, GNorm = 0.5102, lr_0 = 3.3351e-04
Validation rmse logD = 0.578972
Validation R2 logD = 0.775288
Validation rmse logP = 0.747602
Validation R2 logP = 0.812395
Epoch 48
Train function
Loss = 1.3588e-04, PNorm = 66.8111, GNorm = 0.5808, lr_0 = 3.3188e-04
Loss = 1.3091e-04, PNorm = 66.8196, GNorm = 0.4361, lr_0 = 3.3042e-04
Loss = 1.0765e-04, PNorm = 66.8294, GNorm = 0.2148, lr_0 = 3.2895e-04
Loss = 1.1388e-04, PNorm = 66.8352, GNorm = 0.4404, lr_0 = 3.2750e-04
Loss = 1.3145e-04, PNorm = 66.8394, GNorm = 0.6016, lr_0 = 3.2605e-04
Loss = 1.1071e-04, PNorm = 66.8450, GNorm = 0.3781, lr_0 = 3.2461e-04
Validation rmse logD = 0.578124
Validation R2 logD = 0.775946
Validation rmse logP = 0.744357
Validation R2 logP = 0.814020
Epoch 49
Train function
Loss = 1.1853e-04, PNorm = 66.8493, GNorm = 0.7326, lr_0 = 3.2303e-04
Loss = 1.1071e-04, PNorm = 66.8543, GNorm = 0.1617, lr_0 = 3.2160e-04
Loss = 9.6205e-05, PNorm = 66.8615, GNorm = 0.2625, lr_0 = 3.2018e-04
Loss = 1.3218e-04, PNorm = 66.8672, GNorm = 0.1434, lr_0 = 3.1876e-04
Loss = 8.4191e-05, PNorm = 66.8742, GNorm = 0.1861, lr_0 = 3.1735e-04
Validation rmse logD = 0.576117
Validation R2 logD = 0.777499
Validation rmse logP = 0.742621
Validation R2 logP = 0.814886
Epoch 50
Train function
Loss = 8.0310e-05, PNorm = 66.8805, GNorm = 0.1379, lr_0 = 3.1595e-04
Loss = 7.1792e-05, PNorm = 66.8863, GNorm = 0.2055, lr_0 = 3.1455e-04
Loss = 8.9865e-05, PNorm = 66.8909, GNorm = 0.2551, lr_0 = 3.1316e-04
Loss = 6.6971e-05, PNorm = 66.8961, GNorm = 0.2159, lr_0 = 3.1177e-04
Loss = 6.9399e-05, PNorm = 66.9016, GNorm = 0.1387, lr_0 = 3.1039e-04
Validation rmse logD = 0.584389
Validation R2 logD = 0.771063
Validation rmse logP = 0.740996
Validation R2 logP = 0.815695
Epoch 51
Train function
Loss = 1.3688e-04, PNorm = 66.9066, GNorm = 0.7995, lr_0 = 3.0888e-04
Loss = 1.0034e-04, PNorm = 66.9150, GNorm = 0.1489, lr_0 = 3.0752e-04
Loss = 9.5750e-05, PNorm = 66.9210, GNorm = 0.1847, lr_0 = 3.0616e-04
Loss = 1.0185e-04, PNorm = 66.9281, GNorm = 0.2961, lr_0 = 3.0480e-04
Loss = 8.1457e-05, PNorm = 66.9343, GNorm = 0.2819, lr_0 = 3.0346e-04
Loss = 8.4154e-05, PNorm = 66.9392, GNorm = 0.1518, lr_0 = 3.0211e-04
Validation rmse logD = 0.582198
Validation R2 logD = 0.772777
Validation rmse logP = 0.744551
Validation R2 logP = 0.813923
Epoch 52
Train function
Loss = 8.6756e-05, PNorm = 66.9434, GNorm = 0.1579, lr_0 = 3.0064e-04
Loss = 7.3277e-05, PNorm = 66.9454, GNorm = 0.2025, lr_0 = 2.9931e-04
Loss = 9.0859e-05, PNorm = 66.9519, GNorm = 0.1484, lr_0 = 2.9799e-04
Loss = 8.3812e-05, PNorm = 66.9568, GNorm = 0.2400, lr_0 = 2.9667e-04
Loss = 7.2239e-05, PNorm = 66.9617, GNorm = 0.1171, lr_0 = 2.9536e-04
Validation rmse logD = 0.578321
Validation R2 logD = 0.775793
Validation rmse logP = 0.740717
Validation R2 logP = 0.815834
Epoch 53
Train function
Loss = 5.8445e-05, PNorm = 66.9669, GNorm = 0.4696, lr_0 = 2.9392e-04
Loss = 7.1422e-05, PNorm = 66.9706, GNorm = 0.3423, lr_0 = 2.9262e-04
Loss = 9.1434e-05, PNorm = 66.9773, GNorm = 0.1381, lr_0 = 2.9133e-04
Loss = 7.8209e-05, PNorm = 66.9816, GNorm = 0.3245, lr_0 = 2.9004e-04
Loss = 7.9228e-05, PNorm = 66.9884, GNorm = 0.3243, lr_0 = 2.8876e-04
Validation rmse logD = 0.576336
Validation R2 logD = 0.777330
Validation rmse logP = 0.737428
Validation R2 logP = 0.817466
Epoch 54
Train function
Loss = 4.2474e-05, PNorm = 66.9934, GNorm = 0.1036, lr_0 = 2.8735e-04
Loss = 6.7543e-05, PNorm = 66.9993, GNorm = 0.3092, lr_0 = 2.8608e-04
Loss = 7.4448e-05, PNorm = 67.0049, GNorm = 0.2124, lr_0 = 2.8482e-04
Loss = 6.9287e-05, PNorm = 67.0054, GNorm = 0.1877, lr_0 = 2.8356e-04
Loss = 7.6903e-05, PNorm = 67.0086, GNorm = 0.3135, lr_0 = 2.8230e-04
Loss = 6.4808e-05, PNorm = 67.0135, GNorm = 0.4548, lr_0 = 2.8105e-04
Validation rmse logD = 0.581431
Validation R2 logD = 0.773375
Validation rmse logP = 0.752989
Validation R2 logP = 0.809682
Epoch 55
Train function
Loss = 5.8883e-05, PNorm = 67.0173, GNorm = 0.1290, lr_0 = 2.7969e-04
Loss = 6.9745e-05, PNorm = 67.0214, GNorm = 0.2126, lr_0 = 2.7845e-04
Loss = 5.6771e-05, PNorm = 67.0274, GNorm = 0.2735, lr_0 = 2.7722e-04
Loss = 5.9060e-05, PNorm = 67.0324, GNorm = 0.2452, lr_0 = 2.7599e-04
Loss = 7.6146e-05, PNorm = 67.0366, GNorm = 0.3561, lr_0 = 2.7477e-04
Validation rmse logD = 0.583407
Validation R2 logD = 0.771832
Validation rmse logP = 0.745521
Validation R2 logP = 0.813438
Epoch 56
Train function
Loss = 5.1074e-05, PNorm = 67.0389, GNorm = 0.1778, lr_0 = 2.7343e-04
Loss = 5.2178e-05, PNorm = 67.0413, GNorm = 0.1518, lr_0 = 2.7222e-04
Loss = 7.1512e-05, PNorm = 67.0457, GNorm = 0.4498, lr_0 = 2.7102e-04
Loss = 7.0050e-05, PNorm = 67.0497, GNorm = 0.5191, lr_0 = 2.6982e-04
Loss = 7.2438e-05, PNorm = 67.0535, GNorm = 0.5777, lr_0 = 2.6863e-04
Validation rmse logD = 0.584023
Validation R2 logD = 0.771350
Validation rmse logP = 0.749744
Validation R2 logP = 0.811318
Epoch 57
Train function
Loss = 6.3750e-05, PNorm = 67.0594, GNorm = 0.2602, lr_0 = 2.6732e-04
Loss = 7.6882e-05, PNorm = 67.0637, GNorm = 0.1188, lr_0 = 2.6614e-04
Loss = 6.5756e-05, PNorm = 67.0685, GNorm = 0.1951, lr_0 = 2.6496e-04
Loss = 5.1721e-05, PNorm = 67.0725, GNorm = 0.2398, lr_0 = 2.6379e-04
Loss = 4.2615e-05, PNorm = 67.0774, GNorm = 0.1243, lr_0 = 2.6262e-04
Loss = 7.3405e-05, PNorm = 67.0808, GNorm = 0.2397, lr_0 = 2.6146e-04
Loss = 1.9048e-04, PNorm = 67.0813, GNorm = 0.2367, lr_0 = 2.6134e-04
Validation rmse logD = 0.576142
Validation R2 logD = 0.777479
Validation rmse logP = 0.751145
Validation R2 logP = 0.810612
Epoch 58
Train function
Loss = 5.6780e-05, PNorm = 67.0860, GNorm = 0.3913, lr_0 = 2.6019e-04
Loss = 5.4761e-05, PNorm = 67.0894, GNorm = 0.3808, lr_0 = 2.5904e-04
Loss = 4.7377e-05, PNorm = 67.0912, GNorm = 0.1231, lr_0 = 2.5789e-04
Loss = 6.0227e-05, PNorm = 67.0937, GNorm = 0.1625, lr_0 = 2.5675e-04
Loss = 4.8297e-05, PNorm = 67.0965, GNorm = 0.1028, lr_0 = 2.5561e-04
Validation rmse logD = 0.579553
Validation R2 logD = 0.774837
Validation rmse logP = 0.745692
Validation R2 logP = 0.813352
Epoch 59
Train function
Loss = 3.0403e-05, PNorm = 67.0987, GNorm = 0.1668, lr_0 = 2.5448e-04
Loss = 3.8262e-05, PNorm = 67.1010, GNorm = 0.1756, lr_0 = 2.5336e-04
Loss = 3.5030e-05, PNorm = 67.1043, GNorm = 0.1318, lr_0 = 2.5224e-04
Loss = 3.9183e-05, PNorm = 67.1064, GNorm = 0.1996, lr_0 = 2.5112e-04
Loss = 3.7397e-05, PNorm = 67.1101, GNorm = 0.1378, lr_0 = 2.5001e-04
Validation rmse logD = 0.580135
Validation R2 logD = 0.774384
Validation rmse logP = 0.747213
Validation R2 logP = 0.812590
Epoch 60
Train function
Loss = 5.1005e-05, PNorm = 67.1144, GNorm = 0.2852, lr_0 = 2.4879e-04
Loss = 8.2993e-05, PNorm = 67.1209, GNorm = 0.4828, lr_0 = 2.4769e-04
Loss = 6.5455e-05, PNorm = 67.1224, GNorm = 0.3732, lr_0 = 2.4660e-04
Loss = 4.7069e-05, PNorm = 67.1260, GNorm = 0.1204, lr_0 = 2.4551e-04
Loss = 4.8506e-05, PNorm = 67.1299, GNorm = 0.1255, lr_0 = 2.4442e-04
Loss = 4.0666e-05, PNorm = 67.1323, GNorm = 0.1048, lr_0 = 2.4334e-04
Loss = 2.5475e-04, PNorm = 67.1327, GNorm = 0.2982, lr_0 = 2.4323e-04
Validation rmse logD = 0.580203
Validation R2 logD = 0.774331
Validation rmse logP = 0.747445
Validation R2 logP = 0.812473
Epoch 61
Train function
Loss = 3.1842e-05, PNorm = 67.1348, GNorm = 0.2158, lr_0 = 2.4216e-04
Loss = 2.9336e-05, PNorm = 67.1384, GNorm = 0.1022, lr_0 = 2.4109e-04
Loss = 3.1956e-05, PNorm = 67.1427, GNorm = 0.0946, lr_0 = 2.4002e-04
Loss = 3.9778e-05, PNorm = 67.1465, GNorm = 0.0959, lr_0 = 2.3896e-04
Loss = 4.4414e-05, PNorm = 67.1489, GNorm = 0.1871, lr_0 = 2.3790e-04
Validation rmse logD = 0.581446
Validation R2 logD = 0.773363
Validation rmse logP = 0.747113
Validation R2 logP = 0.812640
Epoch 62
Train function
Loss = 3.1986e-05, PNorm = 67.1519, GNorm = 0.1044, lr_0 = 2.3674e-04
Loss = 4.2196e-05, PNorm = 67.1551, GNorm = 0.1553, lr_0 = 2.3570e-04
Loss = 3.6162e-05, PNorm = 67.1590, GNorm = 0.1959, lr_0 = 2.3465e-04
Loss = 4.6125e-05, PNorm = 67.1624, GNorm = 0.4294, lr_0 = 2.3362e-04
Loss = 5.8283e-05, PNorm = 67.1649, GNorm = 0.5289, lr_0 = 2.3258e-04
Validation rmse logD = 0.580145
Validation R2 logD = 0.774376
Validation rmse logP = 0.750539
Validation R2 logP = 0.810918
Epoch 63
Train function
Loss = 4.1337e-05, PNorm = 67.1663, GNorm = 0.2599, lr_0 = 2.3145e-04
Loss = 5.1501e-05, PNorm = 67.1707, GNorm = 0.1702, lr_0 = 2.3043e-04
Loss = 6.0859e-05, PNorm = 67.1748, GNorm = 0.2416, lr_0 = 2.2941e-04
Loss = 4.9380e-05, PNorm = 67.1771, GNorm = 0.2213, lr_0 = 2.2839e-04
Loss = 4.1347e-05, PNorm = 67.1807, GNorm = 0.2289, lr_0 = 2.2738e-04
Validation rmse logD = 0.580289
Validation R2 logD = 0.774264
Validation rmse logP = 0.753028
Validation R2 logP = 0.809661
Epoch 64
Train function
Loss = 2.6955e-05, PNorm = 67.1853, GNorm = 0.2940, lr_0 = 2.2628e-04
Loss = 4.3204e-05, PNorm = 67.1870, GNorm = 0.1622, lr_0 = 2.2528e-04
Loss = 3.7959e-05, PNorm = 67.1879, GNorm = 0.1975, lr_0 = 2.2428e-04
Loss = 3.1589e-05, PNorm = 67.1905, GNorm = 0.1153, lr_0 = 2.2329e-04
Loss = 3.8962e-05, PNorm = 67.1928, GNorm = 0.1791, lr_0 = 2.2230e-04
Loss = 4.5663e-05, PNorm = 67.1963, GNorm = 0.2703, lr_0 = 2.2132e-04
Validation rmse logD = 0.579050
Validation R2 logD = 0.775227
Validation rmse logP = 0.747734
Validation R2 logP = 0.812328
Epoch 65
Train function
Loss = 4.5413e-05, PNorm = 67.1995, GNorm = 0.1730, lr_0 = 2.2024e-04
Loss = 3.8167e-05, PNorm = 67.2021, GNorm = 0.2791, lr_0 = 2.1927e-04
Loss = 3.9571e-05, PNorm = 67.2045, GNorm = 0.0795, lr_0 = 2.1830e-04
Loss = 4.0559e-05, PNorm = 67.2075, GNorm = 0.1816, lr_0 = 2.1733e-04
Loss = 3.6890e-05, PNorm = 67.2099, GNorm = 0.1483, lr_0 = 2.1637e-04
Validation rmse logD = 0.579033
Validation R2 logD = 0.775240
Validation rmse logP = 0.751611
Validation R2 logP = 0.810377
Epoch 66
Train function
Loss = 4.9809e-05, PNorm = 67.2122, GNorm = 0.5531, lr_0 = 2.1532e-04
Loss = 5.0036e-05, PNorm = 67.2158, GNorm = 0.3967, lr_0 = 2.1436e-04
Loss = 4.2142e-05, PNorm = 67.2181, GNorm = 0.2271, lr_0 = 2.1342e-04
Loss = 3.6088e-05, PNorm = 67.2215, GNorm = 0.0917, lr_0 = 2.1247e-04
Loss = 3.0124e-05, PNorm = 67.2235, GNorm = 0.1108, lr_0 = 2.1153e-04
Validation rmse logD = 0.579876
Validation R2 logD = 0.774585
Validation rmse logP = 0.740574
Validation R2 logP = 0.815905
Epoch 67
Train function
Loss = 2.1340e-05, PNorm = 67.2268, GNorm = 0.2301, lr_0 = 2.1060e-04
Loss = 3.3031e-05, PNorm = 67.2297, GNorm = 0.2799, lr_0 = 2.0966e-04
Loss = 3.8175e-05, PNorm = 67.2327, GNorm = 0.1008, lr_0 = 2.0874e-04
Loss = 2.8537e-05, PNorm = 67.2335, GNorm = 0.1225, lr_0 = 2.0781e-04
Loss = 3.1293e-05, PNorm = 67.2364, GNorm = 0.2527, lr_0 = 2.0689e-04
Loss = 2.8835e-05, PNorm = 67.2395, GNorm = 0.1375, lr_0 = 2.0598e-04
Validation rmse logD = 0.578489
Validation R2 logD = 0.775662
Validation rmse logP = 0.748415
Validation R2 logP = 0.811986
Epoch 68
Train function
Loss = 3.8017e-05, PNorm = 67.2430, GNorm = 0.1877, lr_0 = 2.0498e-04
Loss = 3.6038e-05, PNorm = 67.2450, GNorm = 0.1398, lr_0 = 2.0407e-04
Loss = 2.7247e-05, PNorm = 67.2468, GNorm = 0.1381, lr_0 = 2.0317e-04
Loss = 2.1455e-05, PNorm = 67.2483, GNorm = 0.1064, lr_0 = 2.0227e-04
Loss = 2.4106e-05, PNorm = 67.2513, GNorm = 0.0898, lr_0 = 2.0137e-04
Validation rmse logD = 0.581243
Validation R2 logD = 0.773522
Validation rmse logP = 0.751555
Validation R2 logP = 0.810405
Epoch 69
Train function
Loss = 1.8254e-05, PNorm = 67.2538, GNorm = 0.1211, lr_0 = 2.0039e-04
Loss = 2.0635e-05, PNorm = 67.2549, GNorm = 0.1008, lr_0 = 1.9951e-04
Loss = 1.8903e-05, PNorm = 67.2572, GNorm = 0.2048, lr_0 = 1.9863e-04
Loss = 2.7647e-05, PNorm = 67.2586, GNorm = 0.0926, lr_0 = 1.9775e-04
Loss = 2.5052e-05, PNorm = 67.2593, GNorm = 0.1153, lr_0 = 1.9687e-04
Validation rmse logD = 0.578861
Validation R2 logD = 0.775374
Validation rmse logP = 0.747413
Validation R2 logP = 0.812489
Epoch 70
Train function
Loss = 2.2056e-05, PNorm = 67.2614, GNorm = 0.0966, lr_0 = 1.9592e-04
Loss = 2.9308e-05, PNorm = 67.2648, GNorm = 0.0688, lr_0 = 1.9505e-04
Loss = 2.4094e-05, PNorm = 67.2672, GNorm = 0.1194, lr_0 = 1.9419e-04
Loss = 2.4160e-05, PNorm = 67.2694, GNorm = 0.3631, lr_0 = 1.9333e-04
Loss = 2.1667e-05, PNorm = 67.2702, GNorm = 0.1242, lr_0 = 1.9247e-04
Loss = 1.9378e-05, PNorm = 67.2722, GNorm = 0.0902, lr_0 = 1.9162e-04
Validation rmse logD = 0.579526
Validation R2 logD = 0.774858
Validation rmse logP = 0.750031
Validation R2 logP = 0.811174
Epoch 71
Train function
Loss = 1.5590e-05, PNorm = 67.2736, GNorm = 0.1054, lr_0 = 1.9069e-04
Loss = 1.6487e-05, PNorm = 67.2749, GNorm = 0.0639, lr_0 = 1.8984e-04
Loss = 1.6552e-05, PNorm = 67.2761, GNorm = 0.0578, lr_0 = 1.8900e-04
Loss = 1.8436e-05, PNorm = 67.2779, GNorm = 0.1724, lr_0 = 1.8817e-04
Loss = 2.3873e-05, PNorm = 67.2798, GNorm = 0.2582, lr_0 = 1.8734e-04
Validation rmse logD = 0.581339
Validation R2 logD = 0.773447
Validation rmse logP = 0.751525
Validation R2 logP = 0.810421
Epoch 72
Train function
Loss = 1.3347e-05, PNorm = 67.2834, GNorm = 0.2150, lr_0 = 1.8643e-04
Loss = 1.8236e-05, PNorm = 67.2852, GNorm = 0.1177, lr_0 = 1.8560e-04
Loss = 1.4114e-05, PNorm = 67.2866, GNorm = 0.0544, lr_0 = 1.8478e-04
Loss = 1.3618e-05, PNorm = 67.2877, GNorm = 0.1078, lr_0 = 1.8396e-04
Loss = 1.8045e-05, PNorm = 67.2887, GNorm = 0.0957, lr_0 = 1.8315e-04
Validation rmse logD = 0.580373
Validation R2 logD = 0.774199
Validation rmse logP = 0.750195
Validation R2 logP = 0.811091
Epoch 73
Train function
Loss = 1.0287e-05, PNorm = 67.2913, GNorm = 0.0752, lr_0 = 1.8226e-04
Loss = 1.2095e-05, PNorm = 67.2923, GNorm = 0.1278, lr_0 = 1.8145e-04
Loss = 1.2667e-05, PNorm = 67.2931, GNorm = 0.0751, lr_0 = 1.8065e-04
Loss = 1.9915e-05, PNorm = 67.2950, GNorm = 0.0584, lr_0 = 1.7985e-04
Loss = 1.7099e-05, PNorm = 67.2977, GNorm = 0.2271, lr_0 = 1.7905e-04
Loss = 2.7188e-05, PNorm = 67.2995, GNorm = 0.5940, lr_0 = 1.7826e-04
Loss = 8.0006e-05, PNorm = 67.2994, GNorm = 0.1611, lr_0 = 1.7818e-04
Validation rmse logD = 0.583223
Validation R2 logD = 0.771976
Validation rmse logP = 0.749084
Validation R2 logP = 0.811650
Epoch 74
Train function
Loss = 3.1224e-05, PNorm = 67.3010, GNorm = 0.3012, lr_0 = 1.7739e-04
Loss = 3.3977e-05, PNorm = 67.3019, GNorm = 0.4907, lr_0 = 1.7661e-04
Loss = 2.5185e-05, PNorm = 67.3047, GNorm = 0.3616, lr_0 = 1.7583e-04
Loss = 2.2744e-05, PNorm = 67.3064, GNorm = 0.1962, lr_0 = 1.7505e-04
Loss = 1.9357e-05, PNorm = 67.3084, GNorm = 0.2940, lr_0 = 1.7428e-04
Validation rmse logD = 0.580797
Validation R2 logD = 0.773869
Validation rmse logP = 0.749848
Validation R2 logP = 0.811266
Epoch 75
Train function
Loss = 3.0093e-05, PNorm = 67.3105, GNorm = 0.0977, lr_0 = 1.7351e-04
Loss = 2.6023e-05, PNorm = 67.3128, GNorm = 0.1061, lr_0 = 1.7274e-04
Loss = 2.1759e-05, PNorm = 67.3144, GNorm = 0.1487, lr_0 = 1.7197e-04
Loss = 1.6542e-05, PNorm = 67.3150, GNorm = 0.0795, lr_0 = 1.7121e-04
Loss = 2.5590e-05, PNorm = 67.3167, GNorm = 0.2091, lr_0 = 1.7046e-04
Validation rmse logD = 0.581029
Validation R2 logD = 0.773688
Validation rmse logP = 0.752424
Validation R2 logP = 0.809967
Epoch 76
Train function
Loss = 1.9735e-05, PNorm = 67.3183, GNorm = 0.1309, lr_0 = 1.6963e-04
Loss = 1.9127e-05, PNorm = 67.3191, GNorm = 0.0836, lr_0 = 1.6888e-04
Loss = 1.7733e-05, PNorm = 67.3214, GNorm = 0.0782, lr_0 = 1.6813e-04
Loss = 1.3370e-05, PNorm = 67.3225, GNorm = 0.0629, lr_0 = 1.6739e-04
Loss = 1.3894e-05, PNorm = 67.3246, GNorm = 0.1271, lr_0 = 1.6665e-04
Loss = 1.6790e-05, PNorm = 67.3268, GNorm = 0.0954, lr_0 = 1.6591e-04
Loss = 2.1090e-04, PNorm = 67.3269, GNorm = 0.2766, lr_0 = 1.6584e-04
Validation rmse logD = 0.580243
Validation R2 logD = 0.774300
Validation rmse logP = 0.749808
Validation R2 logP = 0.811286
Epoch 77
Train function
Loss = 1.7720e-05, PNorm = 67.3287, GNorm = 0.0983, lr_0 = 1.6510e-04
Loss = 1.6370e-05, PNorm = 67.3291, GNorm = 0.1042, lr_0 = 1.6437e-04
Loss = 1.2910e-05, PNorm = 67.3302, GNorm = 0.0571, lr_0 = 1.6364e-04
Loss = 1.6974e-05, PNorm = 67.3316, GNorm = 0.0661, lr_0 = 1.6292e-04
Loss = 1.3908e-05, PNorm = 67.3332, GNorm = 0.1015, lr_0 = 1.6220e-04
Validation rmse logD = 0.579907
Validation R2 logD = 0.774561
Validation rmse logP = 0.748849
Validation R2 logP = 0.811768
Epoch 78
Train function
Loss = 1.9429e-05, PNorm = 67.3351, GNorm = 0.1543, lr_0 = 1.6141e-04
Loss = 1.4489e-05, PNorm = 67.3373, GNorm = 0.1435, lr_0 = 1.6070e-04
Loss = 1.0939e-05, PNorm = 67.3382, GNorm = 0.1708, lr_0 = 1.5999e-04
Loss = 1.3926e-05, PNorm = 67.3392, GNorm = 0.0590, lr_0 = 1.5928e-04
Loss = 1.2805e-05, PNorm = 67.3405, GNorm = 0.0956, lr_0 = 1.5857e-04
Validation rmse logD = 0.581519
Validation R2 logD = 0.773306
Validation rmse logP = 0.750647
Validation R2 logP = 0.810863
Epoch 79
Train function
Loss = 1.0419e-05, PNorm = 67.3411, GNorm = 0.0426, lr_0 = 1.5780e-04
Loss = 1.1053e-05, PNorm = 67.3421, GNorm = 0.0821, lr_0 = 1.5710e-04
Loss = 1.3641e-05, PNorm = 67.3436, GNorm = 0.1007, lr_0 = 1.5641e-04
Loss = 1.0294e-05, PNorm = 67.3444, GNorm = 0.1140, lr_0 = 1.5572e-04
Loss = 1.9925e-05, PNorm = 67.3465, GNorm = 0.1883, lr_0 = 1.5503e-04
Validation rmse logD = 0.580441
Validation R2 logD = 0.774146
Validation rmse logP = 0.749760
Validation R2 logP = 0.811310
Epoch 80
Train function
Loss = 8.3380e-06, PNorm = 67.3484, GNorm = 0.0872, lr_0 = 1.5427e-04
Loss = 1.2893e-05, PNorm = 67.3479, GNorm = 0.0773, lr_0 = 1.5359e-04
Loss = 1.6181e-05, PNorm = 67.3505, GNorm = 0.0502, lr_0 = 1.5291e-04
Loss = 1.1882e-05, PNorm = 67.3520, GNorm = 0.1376, lr_0 = 1.5224e-04
Loss = 1.3847e-05, PNorm = 67.3528, GNorm = 0.1342, lr_0 = 1.5156e-04
Loss = 1.5881e-05, PNorm = 67.3543, GNorm = 0.0652, lr_0 = 1.5089e-04
Validation rmse logD = 0.583018
Validation R2 logD = 0.772136
Validation rmse logP = 0.746990
Validation R2 logP = 0.812702
Epoch 81
Train function
Loss = 2.9918e-05, PNorm = 67.3559, GNorm = 0.3065, lr_0 = 1.5016e-04
Loss = 2.9359e-05, PNorm = 67.3575, GNorm = 0.1486, lr_0 = 1.4949e-04
Loss = 4.4979e-05, PNorm = 67.3580, GNorm = 0.1093, lr_0 = 1.4883e-04
Loss = 2.5344e-05, PNorm = 67.3616, GNorm = 0.1687, lr_0 = 1.4817e-04
Loss = 2.8863e-05, PNorm = 67.3646, GNorm = 0.3246, lr_0 = 1.4752e-04
Validation rmse logD = 0.581781
Validation R2 logD = 0.773102
Validation rmse logP = 0.746123
Validation R2 logP = 0.813136
Epoch 82
Train function
Loss = 2.3810e-05, PNorm = 67.3665, GNorm = 0.0989, lr_0 = 1.4680e-04
Loss = 2.8736e-05, PNorm = 67.3673, GNorm = 0.2811, lr_0 = 1.4615e-04
Loss = 2.9062e-05, PNorm = 67.3703, GNorm = 0.2611, lr_0 = 1.4551e-04
Loss = 2.4356e-05, PNorm = 67.3727, GNorm = 0.3402, lr_0 = 1.4486e-04
Loss = 1.8980e-05, PNorm = 67.3732, GNorm = 0.0892, lr_0 = 1.4422e-04
Validation rmse logD = 0.580896
Validation R2 logD = 0.773792
Validation rmse logP = 0.748022
Validation R2 logP = 0.812184
Epoch 83
Train function
Loss = 1.3512e-05, PNorm = 67.3763, GNorm = 0.0995, lr_0 = 1.4352e-04
Loss = 1.4353e-05, PNorm = 67.3777, GNorm = 0.1063, lr_0 = 1.4288e-04
Loss = 1.8216e-05, PNorm = 67.3785, GNorm = 0.2023, lr_0 = 1.4225e-04
Loss = 1.5775e-05, PNorm = 67.3793, GNorm = 0.0816, lr_0 = 1.4162e-04
Loss = 1.5795e-05, PNorm = 67.3797, GNorm = 0.1586, lr_0 = 1.4100e-04
Loss = 1.8927e-05, PNorm = 67.3807, GNorm = 0.2416, lr_0 = 1.4037e-04
Validation rmse logD = 0.580043
Validation R2 logD = 0.774455
Validation rmse logP = 0.747318
Validation R2 logP = 0.812537
Epoch 84
Train function
Loss = 1.9758e-05, PNorm = 67.3817, GNorm = 0.1848, lr_0 = 1.3975e-04
Loss = 1.7449e-05, PNorm = 67.3834, GNorm = 0.1234, lr_0 = 1.3913e-04
Loss = 1.4059e-05, PNorm = 67.3846, GNorm = 0.1067, lr_0 = 1.3852e-04
Loss = 1.6128e-05, PNorm = 67.3859, GNorm = 0.0621, lr_0 = 1.3791e-04
Loss = 1.1793e-05, PNorm = 67.3870, GNorm = 0.1359, lr_0 = 1.3730e-04
Validation rmse logD = 0.580698
Validation R2 logD = 0.773946
Validation rmse logP = 0.750509
Validation R2 logP = 0.810933
Epoch 85
Train function
Loss = 1.3783e-05, PNorm = 67.3884, GNorm = 0.2026, lr_0 = 1.3663e-04
Loss = 1.3164e-05, PNorm = 67.3899, GNorm = 0.0668, lr_0 = 1.3602e-04
Loss = 1.0637e-05, PNorm = 67.3906, GNorm = 0.1417, lr_0 = 1.3542e-04
Loss = 1.6292e-05, PNorm = 67.3914, GNorm = 0.1905, lr_0 = 1.3482e-04
Loss = 1.3037e-05, PNorm = 67.3919, GNorm = 0.1634, lr_0 = 1.3423e-04
Validation rmse logD = 0.578244
Validation R2 logD = 0.775852
Validation rmse logP = 0.745793
Validation R2 logP = 0.813302
Epoch 86
Train function
Loss = 1.0335e-05, PNorm = 67.3922, GNorm = 0.1576, lr_0 = 1.3357e-04
Loss = 1.2813e-05, PNorm = 67.3936, GNorm = 0.1393, lr_0 = 1.3298e-04
Loss = 1.4003e-05, PNorm = 67.3954, GNorm = 0.0578, lr_0 = 1.3239e-04
Loss = 9.2562e-06, PNorm = 67.3966, GNorm = 0.0933, lr_0 = 1.3181e-04
Loss = 1.2537e-05, PNorm = 67.3979, GNorm = 0.1028, lr_0 = 1.3123e-04
Loss = 8.7294e-06, PNorm = 67.3989, GNorm = 0.0447, lr_0 = 1.3065e-04
Validation rmse logD = 0.579244
Validation R2 logD = 0.775076
Validation rmse logP = 0.751826
Validation R2 logP = 0.810269
Epoch 87
Train function
Loss = 1.3212e-05, PNorm = 67.4004, GNorm = 0.1679, lr_0 = 1.3001e-04
Loss = 9.8432e-06, PNorm = 67.4021, GNorm = 0.1368, lr_0 = 1.2944e-04
Loss = 9.6101e-06, PNorm = 67.4031, GNorm = 0.0711, lr_0 = 1.2886e-04
Loss = 1.3033e-05, PNorm = 67.4039, GNorm = 0.1625, lr_0 = 1.2829e-04
Loss = 1.0898e-05, PNorm = 67.4031, GNorm = 0.1314, lr_0 = 1.2773e-04
Validation rmse logD = 0.579191
Validation R2 logD = 0.775118
Validation rmse logP = 0.748704
Validation R2 logP = 0.811841
Epoch 88
Train function
Loss = 9.1109e-06, PNorm = 67.4044, GNorm = 0.1749, lr_0 = 1.2710e-04
Loss = 1.1057e-05, PNorm = 67.4055, GNorm = 0.2233, lr_0 = 1.2654e-04
Loss = 9.1512e-06, PNorm = 67.4061, GNorm = 0.0591, lr_0 = 1.2598e-04
Loss = 7.7844e-06, PNorm = 67.4073, GNorm = 0.0463, lr_0 = 1.2542e-04
Loss = 1.1980e-05, PNorm = 67.4083, GNorm = 0.1290, lr_0 = 1.2487e-04
Validation rmse logD = 0.581465
Validation R2 logD = 0.773348
Validation rmse logP = 0.746859
Validation R2 logP = 0.812767
Epoch 89
Train function
Loss = 8.4055e-06, PNorm = 67.4097, GNorm = 0.1232, lr_0 = 1.2426e-04
Loss = 9.3609e-06, PNorm = 67.4096, GNorm = 0.0943, lr_0 = 1.2371e-04
Loss = 1.2238e-05, PNorm = 67.4111, GNorm = 0.1881, lr_0 = 1.2317e-04
Loss = 8.5245e-06, PNorm = 67.4127, GNorm = 0.2481, lr_0 = 1.2262e-04
Loss = 1.1073e-05, PNorm = 67.4135, GNorm = 0.1206, lr_0 = 1.2208e-04
Loss = 9.4573e-06, PNorm = 67.4136, GNorm = 0.1188, lr_0 = 1.2154e-04
Loss = 1.3926e-04, PNorm = 67.4137, GNorm = 0.2916, lr_0 = 1.2148e-04
Validation rmse logD = 0.579359
Validation R2 logD = 0.774987
Validation rmse logP = 0.748816
Validation R2 logP = 0.811785
Epoch 90
Train function
Loss = 1.1514e-05, PNorm = 67.4146, GNorm = 0.0429, lr_0 = 1.2095e-04
Loss = 7.8853e-06, PNorm = 67.4162, GNorm = 0.0633, lr_0 = 1.2041e-04
Loss = 8.0407e-06, PNorm = 67.4176, GNorm = 0.0941, lr_0 = 1.1988e-04
Loss = 7.0808e-06, PNorm = 67.4183, GNorm = 0.1438, lr_0 = 1.1935e-04
Loss = 1.0278e-05, PNorm = 67.4192, GNorm = 0.0823, lr_0 = 1.1882e-04
Validation rmse logD = 0.579554
Validation R2 logD = 0.774836
Validation rmse logP = 0.745037
Validation R2 logP = 0.813680
Epoch 91
Train function
Loss = 7.6466e-06, PNorm = 67.4202, GNorm = 0.0607, lr_0 = 1.1824e-04
Loss = 8.7937e-06, PNorm = 67.4212, GNorm = 0.1310, lr_0 = 1.1772e-04
Loss = 1.5537e-05, PNorm = 67.4217, GNorm = 0.1341, lr_0 = 1.1720e-04
Loss = 1.1986e-05, PNorm = 67.4225, GNorm = 0.1022, lr_0 = 1.1668e-04
Loss = 1.1626e-05, PNorm = 67.4236, GNorm = 0.2062, lr_0 = 1.1616e-04
Validation rmse logD = 0.581653
Validation R2 logD = 0.773202
Validation rmse logP = 0.747116
Validation R2 logP = 0.812639
Epoch 92
Train function
Loss = 9.0107e-06, PNorm = 67.4250, GNorm = 0.1376, lr_0 = 1.1565e-04
Loss = 1.3098e-05, PNorm = 67.4257, GNorm = 0.2108, lr_0 = 1.1514e-04
Loss = 7.9053e-06, PNorm = 67.4263, GNorm = 0.0605, lr_0 = 1.1463e-04
Loss = 7.9809e-06, PNorm = 67.4273, GNorm = 0.0492, lr_0 = 1.1412e-04
Loss = 7.8851e-06, PNorm = 67.4278, GNorm = 0.1537, lr_0 = 1.1362e-04
Loss = 7.6959e-06, PNorm = 67.4284, GNorm = 0.1383, lr_0 = 1.1312e-04
Loss = 4.9383e-05, PNorm = 67.4285, GNorm = 0.1512, lr_0 = 1.1307e-04
Validation rmse logD = 0.579709
Validation R2 logD = 0.774715
Validation rmse logP = 0.752785
Validation R2 logP = 0.809784
Epoch 93
Train function
Loss = 9.0351e-06, PNorm = 67.4302, GNorm = 0.0866, lr_0 = 1.1257e-04
Loss = 5.2139e-06, PNorm = 67.4310, GNorm = 0.0324, lr_0 = 1.1207e-04
Loss = 5.3363e-06, PNorm = 67.4319, GNorm = 0.0592, lr_0 = 1.1157e-04
Loss = 6.4052e-06, PNorm = 67.4321, GNorm = 0.0710, lr_0 = 1.1108e-04
Loss = 7.6511e-06, PNorm = 67.4335, GNorm = 0.0471, lr_0 = 1.1059e-04
Validation rmse logD = 0.581380
Validation R2 logD = 0.773414
Validation rmse logP = 0.748680
Validation R2 logP = 0.811853
Epoch 94
Train function
Loss = 6.7248e-06, PNorm = 67.4347, GNorm = 0.1399, lr_0 = 1.1005e-04
Loss = 7.6746e-06, PNorm = 67.4355, GNorm = 0.1289, lr_0 = 1.0956e-04
Loss = 7.0295e-06, PNorm = 67.4363, GNorm = 0.0809, lr_0 = 1.0908e-04
Loss = 7.2076e-06, PNorm = 67.4371, GNorm = 0.1556, lr_0 = 1.0860e-04
Loss = 5.7783e-06, PNorm = 67.4370, GNorm = 0.0318, lr_0 = 1.0811e-04
Validation rmse logD = 0.580506
Validation R2 logD = 0.774095
Validation rmse logP = 0.748646
Validation R2 logP = 0.811870
Epoch 95
Train function
Loss = 7.0352e-06, PNorm = 67.4384, GNorm = 0.2123, lr_0 = 1.0759e-04
Loss = 8.7025e-06, PNorm = 67.4388, GNorm = 0.2018, lr_0 = 1.0711e-04
Loss = 8.3373e-06, PNorm = 67.4398, GNorm = 0.0557, lr_0 = 1.0664e-04
Loss = 5.7803e-06, PNorm = 67.4401, GNorm = 0.0869, lr_0 = 1.0617e-04
Loss = 1.1822e-05, PNorm = 67.4410, GNorm = 0.2505, lr_0 = 1.0570e-04
Validation rmse logD = 0.582541
Validation R2 logD = 0.772509
Validation rmse logP = 0.749387
Validation R2 logP = 0.811498
Epoch 96
Train function
Loss = 9.5419e-06, PNorm = 67.4424, GNorm = 0.1854, lr_0 = 1.0518e-04
Loss = 5.2246e-06, PNorm = 67.4433, GNorm = 0.0930, lr_0 = 1.0472e-04
Loss = 1.0080e-05, PNorm = 67.4439, GNorm = 0.1727, lr_0 = 1.0426e-04
Loss = 7.0018e-06, PNorm = 67.4443, GNorm = 0.1124, lr_0 = 1.0379e-04
Loss = 7.0969e-06, PNorm = 67.4451, GNorm = 0.0631, lr_0 = 1.0333e-04
Loss = 6.3001e-06, PNorm = 67.4457, GNorm = 0.0952, lr_0 = 1.0288e-04
Validation rmse logD = 0.580447
Validation R2 logD = 0.774141
Validation rmse logP = 0.749370
Validation R2 logP = 0.811506
Epoch 97
Train function
Loss = 8.9075e-06, PNorm = 67.4463, GNorm = 0.1132, lr_0 = 1.0238e-04
Loss = 6.0126e-06, PNorm = 67.4472, GNorm = 0.0574, lr_0 = 1.0192e-04
Loss = 6.4786e-06, PNorm = 67.4483, GNorm = 0.0386, lr_0 = 1.0147e-04
Loss = 5.9325e-06, PNorm = 67.4490, GNorm = 0.0752, lr_0 = 1.0102e-04
Loss = 5.3255e-06, PNorm = 67.4494, GNorm = 0.0581, lr_0 = 1.0058e-04
Validation rmse logD = 0.580934
Validation R2 logD = 0.773762
Validation rmse logP = 0.751145
Validation R2 logP = 0.810612
Epoch 98
Train function
Loss = 5.5992e-06, PNorm = 67.4496, GNorm = 0.0427, lr_0 = 1.0009e-04
Loss = 7.0472e-06, PNorm = 67.4510, GNorm = 0.0659, lr_0 = 1.0000e-04
Loss = 1.0163e-05, PNorm = 67.4518, GNorm = 0.2316, lr_0 = 1.0000e-04
Loss = 9.1502e-06, PNorm = 67.4523, GNorm = 0.0987, lr_0 = 1.0000e-04
Loss = 6.9841e-06, PNorm = 67.4529, GNorm = 0.0865, lr_0 = 1.0000e-04
Validation rmse logD = 0.579865
Validation R2 logD = 0.774594
Validation rmse logP = 0.750297
Validation R2 logP = 0.811040
Epoch 99
Train function
Loss = 5.0072e-06, PNorm = 67.4537, GNorm = 0.0396, lr_0 = 1.0000e-04
Loss = 6.3742e-06, PNorm = 67.4545, GNorm = 0.0727, lr_0 = 1.0000e-04
Loss = 4.7147e-06, PNorm = 67.4550, GNorm = 0.0364, lr_0 = 1.0000e-04
Loss = 6.6994e-06, PNorm = 67.4559, GNorm = 0.0415, lr_0 = 1.0000e-04
Loss = 9.0025e-06, PNorm = 67.4563, GNorm = 0.0864, lr_0 = 1.0000e-04
Loss = 7.2953e-06, PNorm = 67.4571, GNorm = 0.0316, lr_0 = 1.0000e-04
Validation rmse logD = 0.580719
Validation R2 logD = 0.773930
Validation rmse logP = 0.747427
Validation R2 logP = 0.812482
Model 0 best validation rmse = 0.649237 on epoch 27
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.609168
Model 0 test R2 logD = 0.739378
Model 0 test rmse logP = 0.787788
Model 0 test R2 logP = 0.732017
Ensemble test rmse  logD= 0.609168
Ensemble test R2  logD= 0.739378
Ensemble test rmse  logP= 0.787788
Ensemble test R2  logP= 0.732017
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.0169e-02, PNorm = 55.5666, GNorm = 3.5365, lr_0 = 1.9340e-04
Loss = 1.9360e-02, PNorm = 55.5759, GNorm = 2.6759, lr_0 = 2.7830e-04
Loss = 1.6526e-02, PNorm = 55.5914, GNorm = 3.2396, lr_0 = 3.6321e-04
Loss = 1.5238e-02, PNorm = 55.6137, GNorm = 1.7066, lr_0 = 4.4811e-04
Loss = 1.6576e-02, PNorm = 55.6471, GNorm = 6.2520, lr_0 = 5.3302e-04
Validation rmse logD = 1.060129
Validation R2 logD = 0.240641
Validation rmse logP = 1.051014
Validation R2 logP = 0.318989
Epoch 1
Train function
Loss = 1.5115e-02, PNorm = 55.7116, GNorm = 2.5637, lr_0 = 6.2642e-04
Loss = 1.5534e-02, PNorm = 55.7889, GNorm = 1.1323, lr_0 = 7.1132e-04
Loss = 1.2486e-02, PNorm = 55.8855, GNorm = 2.2611, lr_0 = 7.9623e-04
Loss = 1.3568e-02, PNorm = 55.9778, GNorm = 6.3041, lr_0 = 8.8113e-04
Loss = 1.3037e-02, PNorm = 56.0732, GNorm = 1.6781, lr_0 = 9.6604e-04
Validation rmse logD = 0.935423
Validation R2 logD = 0.408784
Validation rmse logP = 0.988009
Validation R2 logP = 0.398190
Epoch 2
Train function
Loss = 1.1343e-02, PNorm = 56.1865, GNorm = 4.6462, lr_0 = 9.9690e-04
Loss = 1.2603e-02, PNorm = 56.3101, GNorm = 3.3470, lr_0 = 9.9249e-04
Loss = 1.0495e-02, PNorm = 56.4126, GNorm = 2.3766, lr_0 = 9.8810e-04
Loss = 9.7596e-03, PNorm = 56.5084, GNorm = 3.4800, lr_0 = 9.8373e-04
Loss = 1.0485e-02, PNorm = 56.6010, GNorm = 1.3179, lr_0 = 9.7938e-04
Validation rmse logD = 0.840994
Validation R2 logD = 0.522124
Validation rmse logP = 0.980701
Validation R2 logP = 0.407060
Epoch 3
Train function
Loss = 1.0981e-02, PNorm = 56.6830, GNorm = 1.4122, lr_0 = 9.7462e-04
Loss = 9.9359e-03, PNorm = 56.7752, GNorm = 2.5393, lr_0 = 9.7030e-04
Loss = 7.5953e-03, PNorm = 56.8586, GNorm = 0.8408, lr_0 = 9.6601e-04
Loss = 8.6354e-03, PNorm = 56.9456, GNorm = 2.3890, lr_0 = 9.6174e-04
Loss = 7.8845e-03, PNorm = 57.0445, GNorm = 1.2567, lr_0 = 9.5749e-04
Loss = 7.5775e-03, PNorm = 57.1417, GNorm = 1.0023, lr_0 = 9.5325e-04
Validation rmse logD = 0.826451
Validation R2 logD = 0.538507
Validation rmse logP = 0.727543
Validation R2 logP = 0.673672
Epoch 4
Train function
Loss = 8.0956e-03, PNorm = 57.2449, GNorm = 1.7219, lr_0 = 9.4861e-04
Loss = 7.7863e-03, PNorm = 57.3402, GNorm = 1.5742, lr_0 = 9.4442e-04
Loss = 7.9089e-03, PNorm = 57.4695, GNorm = 4.1603, lr_0 = 9.4024e-04
Loss = 8.5407e-03, PNorm = 57.5909, GNorm = 4.8605, lr_0 = 9.3608e-04
Loss = 8.3814e-03, PNorm = 57.6754, GNorm = 1.0545, lr_0 = 9.3194e-04
Validation rmse logD = 0.793803
Validation R2 logD = 0.574249
Validation rmse logP = 0.770930
Validation R2 logP = 0.633590
Epoch 5
Train function
Loss = 6.3220e-03, PNorm = 57.7860, GNorm = 3.6526, lr_0 = 9.2741e-04
Loss = 7.9892e-03, PNorm = 57.8696, GNorm = 2.8335, lr_0 = 9.2330e-04
Loss = 7.0876e-03, PNorm = 57.9583, GNorm = 1.2735, lr_0 = 9.1922e-04
Loss = 6.2100e-03, PNorm = 58.0575, GNorm = 3.8047, lr_0 = 9.1515e-04
Loss = 6.2690e-03, PNorm = 58.1357, GNorm = 2.0581, lr_0 = 9.1111e-04
Validation rmse logD = 0.765932
Validation R2 logD = 0.603621
Validation rmse logP = 0.759966
Validation R2 logP = 0.643938
Epoch 6
Train function
Loss = 6.4773e-03, PNorm = 58.2338, GNorm = 2.6834, lr_0 = 9.0667e-04
Loss = 6.5602e-03, PNorm = 58.3341, GNorm = 1.7556, lr_0 = 9.0266e-04
Loss = 5.8167e-03, PNorm = 58.4378, GNorm = 2.9156, lr_0 = 8.9867e-04
Loss = 6.0147e-03, PNorm = 58.5299, GNorm = 1.4301, lr_0 = 8.9469e-04
Loss = 6.3674e-03, PNorm = 58.6451, GNorm = 2.0440, lr_0 = 8.9074e-04
Loss = 6.3721e-03, PNorm = 58.7352, GNorm = 3.4566, lr_0 = 8.8680e-04
Validation rmse logD = 0.781578
Validation R2 logD = 0.587261
Validation rmse logP = 0.718439
Validation R2 logP = 0.681788
Epoch 7
Train function
Loss = 5.7754e-03, PNorm = 58.8367, GNorm = 1.4410, lr_0 = 8.8248e-04
Loss = 5.1029e-03, PNorm = 58.9445, GNorm = 3.5769, lr_0 = 8.7858e-04
Loss = 6.8872e-03, PNorm = 59.0270, GNorm = 1.0558, lr_0 = 8.7469e-04
Loss = 5.2061e-03, PNorm = 59.1270, GNorm = 1.0155, lr_0 = 8.7082e-04
Loss = 4.6361e-03, PNorm = 59.2208, GNorm = 1.4154, lr_0 = 8.6697e-04
Validation rmse logD = 0.726786
Validation R2 logD = 0.643102
Validation rmse logP = 0.675821
Validation R2 logP = 0.718421
Epoch 8
Train function
Loss = 4.8416e-03, PNorm = 59.3327, GNorm = 1.5554, lr_0 = 8.6276e-04
Loss = 4.6462e-03, PNorm = 59.4146, GNorm = 2.2785, lr_0 = 8.5894e-04
Loss = 4.7124e-03, PNorm = 59.4959, GNorm = 0.8702, lr_0 = 8.5514e-04
Loss = 4.6193e-03, PNorm = 59.5754, GNorm = 1.4275, lr_0 = 8.5136e-04
Loss = 4.4822e-03, PNorm = 59.6443, GNorm = 1.0042, lr_0 = 8.4759e-04
Validation rmse logD = 0.738683
Validation R2 logD = 0.631323
Validation rmse logP = 0.632480
Validation R2 logP = 0.753379
Epoch 9
Train function
Loss = 4.8348e-03, PNorm = 59.7183, GNorm = 1.1938, lr_0 = 8.4384e-04
Loss = 4.2608e-03, PNorm = 59.8048, GNorm = 0.8379, lr_0 = 8.4011e-04
Loss = 3.6419e-03, PNorm = 59.8865, GNorm = 1.1037, lr_0 = 8.3639e-04
Loss = 4.0952e-03, PNorm = 59.9715, GNorm = 1.1272, lr_0 = 8.3269e-04
Loss = 4.2603e-03, PNorm = 60.0669, GNorm = 2.5447, lr_0 = 8.2901e-04
Loss = 4.2461e-03, PNorm = 60.1564, GNorm = 0.9484, lr_0 = 8.2534e-04
Validation rmse logD = 0.767587
Validation R2 logD = 0.601906
Validation rmse logP = 0.668841
Validation R2 logP = 0.724207
Epoch 10
Train function
Loss = 4.3231e-03, PNorm = 60.2604, GNorm = 2.3186, lr_0 = 8.2133e-04
Loss = 4.7395e-03, PNorm = 60.3580, GNorm = 1.0755, lr_0 = 8.1770e-04
Loss = 4.2730e-03, PNorm = 60.4474, GNorm = 1.4014, lr_0 = 8.1408e-04
Loss = 3.6973e-03, PNorm = 60.5474, GNorm = 1.7821, lr_0 = 8.1048e-04
Loss = 3.8183e-03, PNorm = 60.6254, GNorm = 1.4923, lr_0 = 8.0689e-04
Validation rmse logD = 0.684261
Validation R2 logD = 0.683646
Validation rmse logP = 0.723877
Validation R2 logP = 0.676953
Epoch 11
Train function
Loss = 3.0721e-03, PNorm = 60.7107, GNorm = 1.1803, lr_0 = 8.0297e-04
Loss = 3.0082e-03, PNorm = 60.7824, GNorm = 0.8016, lr_0 = 7.9942e-04
Loss = 2.6242e-03, PNorm = 60.8645, GNorm = 2.3954, lr_0 = 7.9588e-04
Loss = 3.6831e-03, PNorm = 60.9201, GNorm = 1.0018, lr_0 = 7.9236e-04
Loss = 3.2329e-03, PNorm = 60.9967, GNorm = 1.3019, lr_0 = 7.8885e-04
Validation rmse logD = 0.668319
Validation R2 logD = 0.698215
Validation rmse logP = 0.646077
Validation R2 logP = 0.742661
Epoch 12
Train function
Loss = 2.0806e-03, PNorm = 61.0715, GNorm = 0.4898, lr_0 = 7.8502e-04
Loss = 2.8118e-03, PNorm = 61.1516, GNorm = 1.0821, lr_0 = 7.8154e-04
Loss = 2.6537e-03, PNorm = 61.2227, GNorm = 1.4820, lr_0 = 7.7809e-04
Loss = 2.5904e-03, PNorm = 61.3103, GNorm = 0.9618, lr_0 = 7.7465e-04
Loss = 3.0323e-03, PNorm = 61.3764, GNorm = 2.9623, lr_0 = 7.7122e-04
Loss = 3.5320e-03, PNorm = 61.4492, GNorm = 2.7331, lr_0 = 7.6781e-04
Loss = 2.7139e-02, PNorm = 61.4540, GNorm = 3.2147, lr_0 = 7.6747e-04
Validation rmse logD = 0.652803
Validation R2 logD = 0.712065
Validation rmse logP = 0.628564
Validation R2 logP = 0.756423
Epoch 13
Train function
Loss = 3.4400e-03, PNorm = 61.5460, GNorm = 3.2568, lr_0 = 7.6407e-04
Loss = 3.2519e-03, PNorm = 61.6507, GNorm = 1.3521, lr_0 = 7.6069e-04
Loss = 2.2728e-03, PNorm = 61.7330, GNorm = 0.6698, lr_0 = 7.5733e-04
Loss = 2.3931e-03, PNorm = 61.8086, GNorm = 0.5471, lr_0 = 7.5398e-04
Loss = 2.8717e-03, PNorm = 61.8799, GNorm = 0.7859, lr_0 = 7.5064e-04
Validation rmse logD = 0.698307
Validation R2 logD = 0.670524
Validation rmse logP = 0.620182
Validation R2 logP = 0.762876
Epoch 14
Train function
Loss = 2.5227e-03, PNorm = 61.9684, GNorm = 1.9616, lr_0 = 7.4699e-04
Loss = 2.8846e-03, PNorm = 62.0586, GNorm = 1.0860, lr_0 = 7.4369e-04
Loss = 2.1718e-03, PNorm = 62.1362, GNorm = 0.6975, lr_0 = 7.4040e-04
Loss = 1.9113e-03, PNorm = 62.1978, GNorm = 0.7299, lr_0 = 7.3712e-04
Loss = 2.3784e-03, PNorm = 62.2624, GNorm = 0.6965, lr_0 = 7.3386e-04
Validation rmse logD = 0.625879
Validation R2 logD = 0.735326
Validation rmse logP = 0.677208
Validation R2 logP = 0.717263
Epoch 15
Train function
Loss = 1.9670e-03, PNorm = 62.3243, GNorm = 1.0579, lr_0 = 7.3029e-04
Loss = 2.2356e-03, PNorm = 62.3953, GNorm = 0.5795, lr_0 = 7.2706e-04
Loss = 2.1523e-03, PNorm = 62.4706, GNorm = 0.8539, lr_0 = 7.2385e-04
Loss = 2.1645e-03, PNorm = 62.5541, GNorm = 0.6475, lr_0 = 7.2064e-04
Loss = 2.1981e-03, PNorm = 62.6109, GNorm = 2.4891, lr_0 = 7.1746e-04
Validation rmse logD = 0.620610
Validation R2 logD = 0.739764
Validation rmse logP = 0.639710
Validation R2 logP = 0.747708
Epoch 16
Train function
Loss = 1.2188e-03, PNorm = 62.6816, GNorm = 1.3494, lr_0 = 7.1397e-04
Loss = 1.8664e-03, PNorm = 62.7574, GNorm = 0.5882, lr_0 = 7.1081e-04
Loss = 1.6395e-03, PNorm = 62.8081, GNorm = 0.7752, lr_0 = 7.0766e-04
Loss = 1.7067e-03, PNorm = 62.8559, GNorm = 1.3054, lr_0 = 7.0453e-04
Loss = 2.0714e-03, PNorm = 62.9050, GNorm = 1.1756, lr_0 = 7.0142e-04
Loss = 1.5082e-03, PNorm = 62.9589, GNorm = 1.3708, lr_0 = 6.9831e-04
Validation rmse logD = 0.608281
Validation R2 logD = 0.750000
Validation rmse logP = 0.693218
Validation R2 logP = 0.703737
Epoch 17
Train function
Loss = 1.5890e-03, PNorm = 63.0176, GNorm = 0.8021, lr_0 = 6.9523e-04
Loss = 1.4849e-03, PNorm = 63.0796, GNorm = 0.5762, lr_0 = 6.9215e-04
Loss = 1.5663e-03, PNorm = 63.1360, GNorm = 0.4399, lr_0 = 6.8909e-04
Loss = 1.5059e-03, PNorm = 63.1991, GNorm = 1.3689, lr_0 = 6.8604e-04
Loss = 1.6797e-03, PNorm = 63.2499, GNorm = 0.8524, lr_0 = 6.8301e-04
Validation rmse logD = 0.608509
Validation R2 logD = 0.749813
Validation rmse logP = 0.613750
Validation R2 logP = 0.767769
Epoch 18
Train function
Loss = 1.4399e-03, PNorm = 63.3088, GNorm = 0.9277, lr_0 = 6.7968e-04
Loss = 1.6870e-03, PNorm = 63.3602, GNorm = 0.5565, lr_0 = 6.7668e-04
Loss = 1.3242e-03, PNorm = 63.4236, GNorm = 1.1119, lr_0 = 6.7368e-04
Loss = 1.5490e-03, PNorm = 63.4778, GNorm = 0.7378, lr_0 = 6.7070e-04
Loss = 1.1550e-03, PNorm = 63.5326, GNorm = 0.5285, lr_0 = 6.6774e-04
Validation rmse logD = 0.602093
Validation R2 logD = 0.755061
Validation rmse logP = 0.639222
Validation R2 logP = 0.748093
Epoch 19
Train function
Loss = 1.0940e-03, PNorm = 63.5799, GNorm = 1.5788, lr_0 = 6.6449e-04
Loss = 1.1290e-03, PNorm = 63.6361, GNorm = 1.1895, lr_0 = 6.6155e-04
Loss = 1.1990e-03, PNorm = 63.6849, GNorm = 0.5739, lr_0 = 6.5862e-04
Loss = 1.2159e-03, PNorm = 63.7345, GNorm = 0.9810, lr_0 = 6.5571e-04
Loss = 1.3684e-03, PNorm = 63.7766, GNorm = 1.5568, lr_0 = 6.5281e-04
Loss = 1.2702e-03, PNorm = 63.8161, GNorm = 1.7068, lr_0 = 6.4992e-04
Validation rmse logD = 0.612192
Validation R2 logD = 0.746776
Validation rmse logP = 0.621855
Validation R2 logP = 0.761595
Epoch 20
Train function
Loss = 1.9676e-03, PNorm = 63.8746, GNorm = 2.0033, lr_0 = 6.4676e-04
Loss = 1.6531e-03, PNorm = 63.9461, GNorm = 0.8604, lr_0 = 6.4390e-04
Loss = 1.1990e-03, PNorm = 64.0058, GNorm = 1.3641, lr_0 = 6.4105e-04
Loss = 1.2211e-03, PNorm = 64.0591, GNorm = 0.5578, lr_0 = 6.3822e-04
Loss = 9.9910e-04, PNorm = 64.1080, GNorm = 0.4416, lr_0 = 6.3539e-04
Validation rmse logD = 0.601113
Validation R2 logD = 0.755858
Validation rmse logP = 0.635510
Validation R2 logP = 0.751010
Epoch 21
Train function
Loss = 8.6723e-04, PNorm = 64.1488, GNorm = 0.4206, lr_0 = 6.3230e-04
Loss = 9.0750e-04, PNorm = 64.1905, GNorm = 0.5824, lr_0 = 6.2950e-04
Loss = 1.0488e-03, PNorm = 64.2271, GNorm = 0.7039, lr_0 = 6.2672e-04
Loss = 1.0292e-03, PNorm = 64.2667, GNorm = 0.5949, lr_0 = 6.2395e-04
Loss = 1.4134e-03, PNorm = 64.3054, GNorm = 1.3481, lr_0 = 6.2119e-04
Validation rmse logD = 0.637219
Validation R2 logD = 0.725648
Validation rmse logP = 0.627767
Validation R2 logP = 0.757040
Epoch 22
Train function
Loss = 8.5135e-04, PNorm = 64.3533, GNorm = 1.0818, lr_0 = 6.1817e-04
Loss = 1.0331e-03, PNorm = 64.4082, GNorm = 0.9880, lr_0 = 6.1543e-04
Loss = 8.3979e-04, PNorm = 64.4446, GNorm = 1.8657, lr_0 = 6.1271e-04
Loss = 1.1134e-03, PNorm = 64.4851, GNorm = 0.4143, lr_0 = 6.1000e-04
Loss = 8.5237e-04, PNorm = 64.5243, GNorm = 0.7036, lr_0 = 6.0730e-04
Loss = 1.1143e-03, PNorm = 64.5677, GNorm = 0.7555, lr_0 = 6.0461e-04
Validation rmse logD = 0.592397
Validation R2 logD = 0.762886
Validation rmse logP = 0.648411
Validation R2 logP = 0.740798
Epoch 23
Train function
Loss = 6.0300e-04, PNorm = 64.6085, GNorm = 0.4818, lr_0 = 6.0167e-04
Loss = 7.4685e-04, PNorm = 64.6336, GNorm = 0.4195, lr_0 = 5.9901e-04
Loss = 6.5898e-04, PNorm = 64.6653, GNorm = 0.4834, lr_0 = 5.9636e-04
Loss = 7.1632e-04, PNorm = 64.7022, GNorm = 0.7783, lr_0 = 5.9372e-04
Loss = 8.2905e-04, PNorm = 64.7369, GNorm = 0.6437, lr_0 = 5.9110e-04
Validation rmse logD = 0.600492
Validation R2 logD = 0.756363
Validation rmse logP = 0.639828
Validation R2 logP = 0.747615
Epoch 24
Train function
Loss = 5.5811e-04, PNorm = 64.7746, GNorm = 0.5903, lr_0 = 5.8822e-04
Loss = 7.3569e-04, PNorm = 64.8099, GNorm = 0.3647, lr_0 = 5.8562e-04
Loss = 6.0583e-04, PNorm = 64.8454, GNorm = 0.5027, lr_0 = 5.8303e-04
Loss = 7.0816e-04, PNorm = 64.8782, GNorm = 0.6271, lr_0 = 5.8045e-04
Loss = 8.5587e-04, PNorm = 64.9055, GNorm = 0.6011, lr_0 = 5.7788e-04
Validation rmse logD = 0.637499
Validation R2 logD = 0.725408
Validation rmse logP = 0.625496
Validation R2 logP = 0.758795
Epoch 25
Train function
Loss = 1.1812e-03, PNorm = 64.9388, GNorm = 0.7244, lr_0 = 5.7533e-04
Loss = 6.1986e-04, PNorm = 64.9740, GNorm = 0.4796, lr_0 = 5.7278e-04
Loss = 5.9532e-04, PNorm = 64.9989, GNorm = 0.4931, lr_0 = 5.7025e-04
Loss = 7.2505e-04, PNorm = 65.0290, GNorm = 1.4351, lr_0 = 5.6773e-04
Loss = 7.9863e-04, PNorm = 65.0587, GNorm = 0.5533, lr_0 = 5.6522e-04
Loss = 7.9240e-04, PNorm = 65.0987, GNorm = 1.4853, lr_0 = 5.6272e-04
Validation rmse logD = 0.596339
Validation R2 logD = 0.759721
Validation rmse logP = 0.630988
Validation R2 logP = 0.754541
Epoch 26
Train function
Loss = 6.4628e-04, PNorm = 65.1392, GNorm = 1.0815, lr_0 = 5.5998e-04
Loss = 6.0852e-04, PNorm = 65.1643, GNorm = 0.4242, lr_0 = 5.5750e-04
Loss = 7.2041e-04, PNorm = 65.1940, GNorm = 0.7460, lr_0 = 5.5503e-04
Loss = 7.0127e-04, PNorm = 65.2288, GNorm = 0.6191, lr_0 = 5.5258e-04
Loss = 6.6338e-04, PNorm = 65.2590, GNorm = 1.0853, lr_0 = 5.5014e-04
Validation rmse logD = 0.612743
Validation R2 logD = 0.746320
Validation rmse logP = 0.606940
Validation R2 logP = 0.772894
Epoch 27
Train function
Loss = 8.4461e-04, PNorm = 65.2989, GNorm = 1.6232, lr_0 = 5.4746e-04
Loss = 7.1874e-04, PNorm = 65.3452, GNorm = 1.0379, lr_0 = 5.4504e-04
Loss = 9.5031e-04, PNorm = 65.3833, GNorm = 0.5453, lr_0 = 5.4263e-04
Loss = 6.1607e-04, PNorm = 65.4095, GNorm = 0.5390, lr_0 = 5.4023e-04
Loss = 5.5517e-04, PNorm = 65.4367, GNorm = 0.5731, lr_0 = 5.3784e-04
Validation rmse logD = 0.593433
Validation R2 logD = 0.762057
Validation rmse logP = 0.619604
Validation R2 logP = 0.763318
Epoch 28
Train function
Loss = 4.6171e-04, PNorm = 65.4714, GNorm = 0.9792, lr_0 = 5.3522e-04
Loss = 5.6244e-04, PNorm = 65.5040, GNorm = 0.4275, lr_0 = 5.3285e-04
Loss = 5.9331e-04, PNorm = 65.5282, GNorm = 0.5296, lr_0 = 5.3050e-04
Loss = 6.0588e-04, PNorm = 65.5556, GNorm = 0.7236, lr_0 = 5.2815e-04
Loss = 7.2094e-04, PNorm = 65.5862, GNorm = 0.5283, lr_0 = 5.2581e-04
Loss = 7.2362e-04, PNorm = 65.6152, GNorm = 0.3902, lr_0 = 5.2349e-04
Loss = 1.4410e-02, PNorm = 65.6202, GNorm = 3.1285, lr_0 = 5.2326e-04
Validation rmse logD = 0.600363
Validation R2 logD = 0.756467
Validation rmse logP = 0.627561
Validation R2 logP = 0.757200
Epoch 29
Train function
Loss = 6.9643e-04, PNorm = 65.6493, GNorm = 0.7010, lr_0 = 5.2094e-04
Loss = 6.6866e-04, PNorm = 65.6732, GNorm = 1.0196, lr_0 = 5.1864e-04
Loss = 5.1927e-04, PNorm = 65.7075, GNorm = 0.5144, lr_0 = 5.1634e-04
Loss = 4.5542e-04, PNorm = 65.7281, GNorm = 0.4952, lr_0 = 5.1406e-04
Loss = 4.7341e-04, PNorm = 65.7518, GNorm = 0.6132, lr_0 = 5.1178e-04
Validation rmse logD = 0.587310
Validation R2 logD = 0.766941
Validation rmse logP = 0.619877
Validation R2 logP = 0.763109
Epoch 30
Train function
Loss = 3.3890e-04, PNorm = 65.7776, GNorm = 0.5907, lr_0 = 5.0930e-04
Loss = 4.4245e-04, PNorm = 65.7980, GNorm = 0.3349, lr_0 = 5.0704e-04
Loss = 4.2945e-04, PNorm = 65.8180, GNorm = 0.8154, lr_0 = 5.0480e-04
Loss = 4.7205e-04, PNorm = 65.8361, GNorm = 0.5203, lr_0 = 5.0257e-04
Loss = 4.2832e-04, PNorm = 65.8547, GNorm = 0.5546, lr_0 = 5.0034e-04
Validation rmse logD = 0.600028
Validation R2 logD = 0.756739
Validation rmse logP = 0.654805
Validation R2 logP = 0.735661
Epoch 31
Train function
Loss = 4.2902e-04, PNorm = 65.8798, GNorm = 0.7148, lr_0 = 4.9791e-04
Loss = 4.3605e-04, PNorm = 65.9078, GNorm = 0.7379, lr_0 = 4.9571e-04
Loss = 3.7218e-04, PNorm = 65.9275, GNorm = 0.8133, lr_0 = 4.9351e-04
Loss = 3.7485e-04, PNorm = 65.9480, GNorm = 0.5106, lr_0 = 4.9133e-04
Loss = 5.0220e-04, PNorm = 65.9645, GNorm = 0.4126, lr_0 = 4.8916e-04
Validation rmse logD = 0.586948
Validation R2 logD = 0.767229
Validation rmse logP = 0.622012
Validation R2 logP = 0.761474
Epoch 32
Train function
Loss = 3.3771e-04, PNorm = 65.9886, GNorm = 0.3492, lr_0 = 4.8678e-04
Loss = 3.7172e-04, PNorm = 66.0088, GNorm = 0.2998, lr_0 = 4.8463e-04
Loss = 3.2286e-04, PNorm = 66.0270, GNorm = 0.5735, lr_0 = 4.8248e-04
Loss = 4.2179e-04, PNorm = 66.0448, GNorm = 0.2853, lr_0 = 4.8035e-04
Loss = 3.2503e-04, PNorm = 66.0637, GNorm = 0.5388, lr_0 = 4.7822e-04
Loss = 3.3515e-04, PNorm = 66.0791, GNorm = 0.6305, lr_0 = 4.7611e-04
Validation rmse logD = 0.589576
Validation R2 logD = 0.765140
Validation rmse logP = 0.624966
Validation R2 logP = 0.759204
Epoch 33
Train function
Loss = 3.4292e-04, PNorm = 66.0944, GNorm = 0.3744, lr_0 = 4.7379e-04
Loss = 3.3324e-04, PNorm = 66.1147, GNorm = 0.8023, lr_0 = 4.7170e-04
Loss = 2.8231e-04, PNorm = 66.1305, GNorm = 0.3293, lr_0 = 4.6961e-04
Loss = 2.4101e-04, PNorm = 66.1457, GNorm = 0.4193, lr_0 = 4.6753e-04
Loss = 2.6610e-04, PNorm = 66.1620, GNorm = 0.2410, lr_0 = 4.6546e-04
Validation rmse logD = 0.582574
Validation R2 logD = 0.770685
Validation rmse logP = 0.617080
Validation R2 logP = 0.765242
Epoch 34
Train function
Loss = 2.2594e-04, PNorm = 66.1766, GNorm = 0.5565, lr_0 = 4.6341e-04
Loss = 3.0548e-04, PNorm = 66.1934, GNorm = 0.7429, lr_0 = 4.6136e-04
Loss = 2.9745e-04, PNorm = 66.2086, GNorm = 0.3665, lr_0 = 4.5931e-04
Loss = 2.4408e-04, PNorm = 66.2247, GNorm = 0.2452, lr_0 = 4.5728e-04
Loss = 2.5552e-04, PNorm = 66.2386, GNorm = 0.2721, lr_0 = 4.5526e-04
Validation rmse logD = 0.593469
Validation R2 logD = 0.762028
Validation rmse logP = 0.630045
Validation R2 logP = 0.755274
Epoch 35
Train function
Loss = 1.2652e-04, PNorm = 66.2524, GNorm = 0.2006, lr_0 = 4.5305e-04
Loss = 3.2393e-04, PNorm = 66.2714, GNorm = 0.2945, lr_0 = 4.5104e-04
Loss = 2.5781e-04, PNorm = 66.2909, GNorm = 0.3665, lr_0 = 4.4905e-04
Loss = 2.1348e-04, PNorm = 66.3070, GNorm = 0.6145, lr_0 = 4.4706e-04
Loss = 2.4978e-04, PNorm = 66.3209, GNorm = 0.2869, lr_0 = 4.4508e-04
Loss = 2.6315e-04, PNorm = 66.3264, GNorm = 0.2800, lr_0 = 4.4311e-04
Validation rmse logD = 0.598577
Validation R2 logD = 0.757913
Validation rmse logP = 0.621786
Validation R2 logP = 0.761648
Epoch 36
Train function
Loss = 3.1879e-04, PNorm = 66.3379, GNorm = 0.6669, lr_0 = 4.4096e-04
Loss = 2.7654e-04, PNorm = 66.3528, GNorm = 0.4602, lr_0 = 4.3901e-04
Loss = 2.6444e-04, PNorm = 66.3660, GNorm = 0.6078, lr_0 = 4.3707e-04
Loss = 2.1612e-04, PNorm = 66.3840, GNorm = 0.2432, lr_0 = 4.3513e-04
Loss = 2.7890e-04, PNorm = 66.4024, GNorm = 0.8115, lr_0 = 4.3321e-04
Validation rmse logD = 0.587273
Validation R2 logD = 0.766971
Validation rmse logP = 0.628367
Validation R2 logP = 0.756575
Epoch 37
Train function
Loss = 1.7168e-04, PNorm = 66.4212, GNorm = 0.3901, lr_0 = 4.3110e-04
Loss = 2.5433e-04, PNorm = 66.4338, GNorm = 0.2448, lr_0 = 4.2919e-04
Loss = 2.5663e-04, PNorm = 66.4456, GNorm = 0.3787, lr_0 = 4.2729e-04
Loss = 2.3986e-04, PNorm = 66.4593, GNorm = 0.4143, lr_0 = 4.2540e-04
Loss = 2.4236e-04, PNorm = 66.4747, GNorm = 0.2474, lr_0 = 4.2352e-04
Validation rmse logD = 0.588192
Validation R2 logD = 0.766241
Validation rmse logP = 0.612246
Validation R2 logP = 0.768906
Epoch 38
Train function
Loss = 1.3146e-04, PNorm = 66.4835, GNorm = 0.2610, lr_0 = 4.2146e-04
Loss = 2.2067e-04, PNorm = 66.4967, GNorm = 0.4338, lr_0 = 4.1960e-04
Loss = 2.1299e-04, PNorm = 66.5090, GNorm = 0.3645, lr_0 = 4.1774e-04
Loss = 2.5412e-04, PNorm = 66.5225, GNorm = 0.6007, lr_0 = 4.1589e-04
Loss = 1.7376e-04, PNorm = 66.5372, GNorm = 0.2141, lr_0 = 4.1406e-04
Loss = 2.0789e-04, PNorm = 66.5522, GNorm = 0.2724, lr_0 = 4.1222e-04
Validation rmse logD = 0.595373
Validation R2 logD = 0.760498
Validation rmse logP = 0.619167
Validation R2 logP = 0.763652
Epoch 39
Train function
Loss = 2.8305e-04, PNorm = 66.5724, GNorm = 0.5737, lr_0 = 4.1022e-04
Loss = 3.1546e-04, PNorm = 66.5828, GNorm = 0.4547, lr_0 = 4.0840e-04
Loss = 1.9559e-04, PNorm = 66.5986, GNorm = 0.2854, lr_0 = 4.0660e-04
Loss = 2.1524e-04, PNorm = 66.6171, GNorm = 0.2274, lr_0 = 4.0480e-04
Loss = 2.1029e-04, PNorm = 66.6315, GNorm = 0.2734, lr_0 = 4.0301e-04
Validation rmse logD = 0.583787
Validation R2 logD = 0.769730
Validation rmse logP = 0.612298
Validation R2 logP = 0.768867
Epoch 40
Train function
Loss = 2.3991e-04, PNorm = 66.6502, GNorm = 0.5960, lr_0 = 4.0105e-04
Loss = 1.7348e-04, PNorm = 66.6628, GNorm = 0.2906, lr_0 = 3.9927e-04
Loss = 1.9067e-04, PNorm = 66.6721, GNorm = 0.6313, lr_0 = 3.9751e-04
Loss = 2.5701e-04, PNorm = 66.6812, GNorm = 0.9556, lr_0 = 3.9575e-04
Loss = 2.0904e-04, PNorm = 66.6912, GNorm = 0.2399, lr_0 = 3.9400e-04
Validation rmse logD = 0.614644
Validation R2 logD = 0.744743
Validation rmse logP = 0.636795
Validation R2 logP = 0.750002
Epoch 41
Train function
Loss = 3.3486e-04, PNorm = 66.7016, GNorm = 0.3838, lr_0 = 3.9208e-04
Loss = 3.9508e-04, PNorm = 66.7185, GNorm = 0.6232, lr_0 = 3.9035e-04
Loss = 3.6656e-04, PNorm = 66.7385, GNorm = 0.4308, lr_0 = 3.8862e-04
Loss = 2.1930e-04, PNorm = 66.7596, GNorm = 0.3774, lr_0 = 3.8690e-04
Loss = 1.9936e-04, PNorm = 66.7767, GNorm = 0.3910, lr_0 = 3.8519e-04
Loss = 1.9273e-04, PNorm = 66.7928, GNorm = 0.4913, lr_0 = 3.8349e-04
Validation rmse logD = 0.583758
Validation R2 logD = 0.769752
Validation rmse logP = 0.611722
Validation R2 logP = 0.769301
Epoch 42
Train function
Loss = 1.8841e-04, PNorm = 66.8029, GNorm = 0.3505, lr_0 = 3.8179e-04
Loss = 1.4083e-04, PNorm = 66.8077, GNorm = 0.2088, lr_0 = 3.8010e-04
Loss = 1.8188e-04, PNorm = 66.8159, GNorm = 0.4034, lr_0 = 3.7842e-04
Loss = 1.5025e-04, PNorm = 66.8221, GNorm = 0.1859, lr_0 = 3.7675e-04
Loss = 1.7003e-04, PNorm = 66.8276, GNorm = 0.3678, lr_0 = 3.7508e-04
Validation rmse logD = 0.582120
Validation R2 logD = 0.771042
Validation rmse logP = 0.616517
Validation R2 logP = 0.765671
Epoch 43
Train function
Loss = 1.1219e-04, PNorm = 66.8408, GNorm = 0.3370, lr_0 = 3.7326e-04
Loss = 1.6142e-04, PNorm = 66.8512, GNorm = 0.6369, lr_0 = 3.7160e-04
Loss = 1.1777e-04, PNorm = 66.8607, GNorm = 0.4161, lr_0 = 3.6996e-04
Loss = 1.2937e-04, PNorm = 66.8674, GNorm = 0.1944, lr_0 = 3.6832e-04
Loss = 1.4812e-04, PNorm = 66.8764, GNorm = 0.2970, lr_0 = 3.6669e-04
Validation rmse logD = 0.587602
Validation R2 logD = 0.766710
Validation rmse logP = 0.608904
Validation R2 logP = 0.771422
Epoch 44
Train function
Loss = 1.0370e-04, PNorm = 66.8867, GNorm = 0.1731, lr_0 = 3.6491e-04
Loss = 1.6909e-04, PNorm = 66.8956, GNorm = 0.4280, lr_0 = 3.6330e-04
Loss = 1.4882e-04, PNorm = 66.9044, GNorm = 0.1682, lr_0 = 3.6169e-04
Loss = 1.7278e-04, PNorm = 66.9134, GNorm = 0.7535, lr_0 = 3.6009e-04
Loss = 1.4545e-04, PNorm = 66.9232, GNorm = 0.2048, lr_0 = 3.5850e-04
Loss = 1.6512e-04, PNorm = 66.9286, GNorm = 0.6955, lr_0 = 3.5691e-04
Loss = 9.5974e-04, PNorm = 66.9294, GNorm = 0.5737, lr_0 = 3.5675e-04
Validation rmse logD = 0.588954
Validation R2 logD = 0.765635
Validation rmse logP = 0.619799
Validation R2 logP = 0.763169
Epoch 45
Train function
Loss = 1.3334e-04, PNorm = 66.9386, GNorm = 0.3143, lr_0 = 3.5518e-04
Loss = 1.4684e-04, PNorm = 66.9490, GNorm = 0.1885, lr_0 = 3.5360e-04
Loss = 1.0663e-04, PNorm = 66.9581, GNorm = 0.2457, lr_0 = 3.5204e-04
Loss = 9.2114e-05, PNorm = 66.9665, GNorm = 0.2170, lr_0 = 3.5048e-04
Loss = 1.4420e-04, PNorm = 66.9740, GNorm = 0.2169, lr_0 = 3.4893e-04
Validation rmse logD = 0.591612
Validation R2 logD = 0.763515
Validation rmse logP = 0.620103
Validation R2 logP = 0.762936
Epoch 46
Train function
Loss = 7.9929e-05, PNorm = 66.9829, GNorm = 0.2981, lr_0 = 3.4724e-04
Loss = 9.0140e-05, PNorm = 66.9866, GNorm = 0.2246, lr_0 = 3.4570e-04
Loss = 8.9595e-05, PNorm = 66.9924, GNorm = 0.1805, lr_0 = 3.4417e-04
Loss = 1.2877e-04, PNorm = 67.0007, GNorm = 0.5758, lr_0 = 3.4265e-04
Loss = 1.0624e-04, PNorm = 67.0081, GNorm = 0.3956, lr_0 = 3.4113e-04
Validation rmse logD = 0.591706
Validation R2 logD = 0.763440
Validation rmse logP = 0.627596
Validation R2 logP = 0.757172
Epoch 47
Train function
Loss = 1.0491e-04, PNorm = 67.0168, GNorm = 0.5084, lr_0 = 3.3947e-04
Loss = 1.2306e-04, PNorm = 67.0260, GNorm = 0.4083, lr_0 = 3.3797e-04
Loss = 8.8350e-05, PNorm = 67.0349, GNorm = 0.1969, lr_0 = 3.3648e-04
Loss = 7.8347e-05, PNorm = 67.0405, GNorm = 0.1523, lr_0 = 3.3499e-04
Loss = 1.0931e-04, PNorm = 67.0443, GNorm = 0.1892, lr_0 = 3.3351e-04
Validation rmse logD = 0.592281
Validation R2 logD = 0.762980
Validation rmse logP = 0.617332
Validation R2 logP = 0.765051
Epoch 48
Train function
Loss = 4.0702e-05, PNorm = 67.0508, GNorm = 0.3264, lr_0 = 3.3188e-04
Loss = 9.8022e-05, PNorm = 67.0569, GNorm = 0.3062, lr_0 = 3.3042e-04
Loss = 7.5075e-05, PNorm = 67.0616, GNorm = 0.1997, lr_0 = 3.2895e-04
Loss = 1.0411e-04, PNorm = 67.0685, GNorm = 0.1782, lr_0 = 3.2750e-04
Loss = 8.2418e-05, PNorm = 67.0751, GNorm = 0.3404, lr_0 = 3.2605e-04
Loss = 8.8660e-05, PNorm = 67.0808, GNorm = 0.4440, lr_0 = 3.2461e-04
Validation rmse logD = 0.590455
Validation R2 logD = 0.764439
Validation rmse logP = 0.631276
Validation R2 logP = 0.754316
Epoch 49
Train function
Loss = 1.0009e-04, PNorm = 67.0866, GNorm = 0.2315, lr_0 = 3.2303e-04
Loss = 1.4248e-04, PNorm = 67.0944, GNorm = 0.5654, lr_0 = 3.2160e-04
Loss = 1.3673e-04, PNorm = 67.1042, GNorm = 0.2619, lr_0 = 3.2018e-04
Loss = 9.1392e-05, PNorm = 67.1102, GNorm = 0.6715, lr_0 = 3.1876e-04
Loss = 8.7379e-05, PNorm = 67.1169, GNorm = 0.2681, lr_0 = 3.1735e-04
Validation rmse logD = 0.590058
Validation R2 logD = 0.764755
Validation rmse logP = 0.625852
Validation R2 logP = 0.758520
Epoch 50
Train function
Loss = 1.2658e-04, PNorm = 67.1229, GNorm = 0.5238, lr_0 = 3.1595e-04
Loss = 9.8473e-05, PNorm = 67.1295, GNorm = 0.1748, lr_0 = 3.1455e-04
Loss = 1.0225e-04, PNorm = 67.1377, GNorm = 0.3659, lr_0 = 3.1316e-04
Loss = 7.8099e-05, PNorm = 67.1459, GNorm = 0.1453, lr_0 = 3.1177e-04
Loss = 7.6928e-05, PNorm = 67.1522, GNorm = 0.1121, lr_0 = 3.1039e-04
Validation rmse logD = 0.587813
Validation R2 logD = 0.766542
Validation rmse logP = 0.618673
Validation R2 logP = 0.764028
Epoch 51
Train function
Loss = 1.2167e-04, PNorm = 67.1602, GNorm = 0.6235, lr_0 = 3.0888e-04
Loss = 1.0693e-04, PNorm = 67.1679, GNorm = 0.2658, lr_0 = 3.0752e-04
Loss = 9.1844e-05, PNorm = 67.1724, GNorm = 0.2889, lr_0 = 3.0616e-04
Loss = 9.4665e-05, PNorm = 67.1772, GNorm = 0.5252, lr_0 = 3.0480e-04
Loss = 1.2396e-04, PNorm = 67.1831, GNorm = 0.7916, lr_0 = 3.0346e-04
Loss = 1.1071e-04, PNorm = 67.1896, GNorm = 0.6429, lr_0 = 3.0211e-04
Validation rmse logD = 0.589429
Validation R2 logD = 0.765257
Validation rmse logP = 0.619255
Validation R2 logP = 0.763584
Epoch 52
Train function
Loss = 1.1962e-04, PNorm = 67.2000, GNorm = 0.1393, lr_0 = 3.0064e-04
Loss = 1.5157e-04, PNorm = 67.2108, GNorm = 0.5832, lr_0 = 2.9931e-04
Loss = 1.0558e-04, PNorm = 67.2185, GNorm = 0.5802, lr_0 = 2.9799e-04
Loss = 1.1684e-04, PNorm = 67.2265, GNorm = 0.5183, lr_0 = 2.9667e-04
Loss = 1.0371e-04, PNorm = 67.2325, GNorm = 0.1707, lr_0 = 2.9536e-04
Validation rmse logD = 0.586154
Validation R2 logD = 0.767858
Validation rmse logP = 0.616937
Validation R2 logP = 0.765351
Epoch 53
Train function
Loss = 9.4580e-05, PNorm = 67.2392, GNorm = 0.5727, lr_0 = 2.9392e-04
Loss = 1.1965e-04, PNorm = 67.2458, GNorm = 0.9388, lr_0 = 2.9262e-04
Loss = 1.3523e-04, PNorm = 67.2534, GNorm = 0.5015, lr_0 = 2.9133e-04
Loss = 8.1844e-05, PNorm = 67.2585, GNorm = 0.5184, lr_0 = 2.9004e-04
Loss = 9.2235e-05, PNorm = 67.2642, GNorm = 0.2535, lr_0 = 2.8876e-04
Validation rmse logD = 0.586648
Validation R2 logD = 0.767467
Validation rmse logP = 0.618789
Validation R2 logP = 0.763940
Epoch 54
Train function
Loss = 7.5765e-05, PNorm = 67.2668, GNorm = 0.2410, lr_0 = 2.8735e-04
Loss = 7.0449e-05, PNorm = 67.2685, GNorm = 0.0967, lr_0 = 2.8608e-04
Loss = 1.0557e-04, PNorm = 67.2741, GNorm = 0.4208, lr_0 = 2.8482e-04
Loss = 1.1069e-04, PNorm = 67.2790, GNorm = 0.2733, lr_0 = 2.8356e-04
Loss = 6.3140e-05, PNorm = 67.2850, GNorm = 0.1708, lr_0 = 2.8230e-04
Loss = 5.3447e-05, PNorm = 67.2893, GNorm = 0.3250, lr_0 = 2.8105e-04
Validation rmse logD = 0.585879
Validation R2 logD = 0.768076
Validation rmse logP = 0.619319
Validation R2 logP = 0.763536
Epoch 55
Train function
Loss = 7.2323e-05, PNorm = 67.2940, GNorm = 0.4323, lr_0 = 2.7969e-04
Loss = 8.0858e-05, PNorm = 67.2996, GNorm = 0.2878, lr_0 = 2.7845e-04
Loss = 5.4352e-05, PNorm = 67.3064, GNorm = 0.3621, lr_0 = 2.7722e-04
Loss = 6.5807e-05, PNorm = 67.3105, GNorm = 0.3690, lr_0 = 2.7599e-04
Loss = 7.4973e-05, PNorm = 67.3158, GNorm = 0.2426, lr_0 = 2.7477e-04
Validation rmse logD = 0.588659
Validation R2 logD = 0.765870
Validation rmse logP = 0.615891
Validation R2 logP = 0.766146
Epoch 56
Train function
Loss = 5.3497e-05, PNorm = 67.3199, GNorm = 0.1204, lr_0 = 2.7343e-04
Loss = 5.0425e-05, PNorm = 67.3234, GNorm = 0.2883, lr_0 = 2.7222e-04
Loss = 5.8442e-05, PNorm = 67.3268, GNorm = 0.1340, lr_0 = 2.7102e-04
Loss = 4.9336e-05, PNorm = 67.3292, GNorm = 0.3190, lr_0 = 2.6982e-04
Loss = 6.4316e-05, PNorm = 67.3336, GNorm = 0.2234, lr_0 = 2.6863e-04
Validation rmse logD = 0.588209
Validation R2 logD = 0.766227
Validation rmse logP = 0.628331
Validation R2 logP = 0.756603
Epoch 57
Train function
Loss = 4.8242e-05, PNorm = 67.3392, GNorm = 0.1568, lr_0 = 2.6732e-04
Loss = 4.5030e-05, PNorm = 67.3418, GNorm = 0.1236, lr_0 = 2.6614e-04
Loss = 4.3678e-05, PNorm = 67.3450, GNorm = 0.1045, lr_0 = 2.6496e-04
Loss = 4.0209e-05, PNorm = 67.3495, GNorm = 0.2065, lr_0 = 2.6379e-04
Loss = 6.2893e-05, PNorm = 67.3535, GNorm = 0.4062, lr_0 = 2.6262e-04
Loss = 7.9625e-05, PNorm = 67.3582, GNorm = 0.1075, lr_0 = 2.6146e-04
Loss = 1.8378e-04, PNorm = 67.3588, GNorm = 0.2777, lr_0 = 2.6134e-04
Validation rmse logD = 0.589170
Validation R2 logD = 0.765463
Validation rmse logP = 0.615331
Validation R2 logP = 0.766571
Epoch 58
Train function
Loss = 5.7459e-05, PNorm = 67.3641, GNorm = 0.2144, lr_0 = 2.6019e-04
Loss = 5.0907e-05, PNorm = 67.3673, GNorm = 0.5208, lr_0 = 2.5904e-04
Loss = 4.9067e-05, PNorm = 67.3706, GNorm = 0.1891, lr_0 = 2.5789e-04
Loss = 4.7946e-05, PNorm = 67.3761, GNorm = 0.1354, lr_0 = 2.5675e-04
Loss = 5.6249e-05, PNorm = 67.3814, GNorm = 0.1967, lr_0 = 2.5561e-04
Validation rmse logD = 0.587736
Validation R2 logD = 0.766603
Validation rmse logP = 0.624960
Validation R2 logP = 0.759208
Epoch 59
Train function
Loss = 4.9306e-05, PNorm = 67.3861, GNorm = 0.2390, lr_0 = 2.5448e-04
Loss = 5.3048e-05, PNorm = 67.3880, GNorm = 0.4967, lr_0 = 2.5336e-04
Loss = 5.2001e-05, PNorm = 67.3911, GNorm = 0.2685, lr_0 = 2.5224e-04
Loss = 4.1626e-05, PNorm = 67.3948, GNorm = 0.1763, lr_0 = 2.5112e-04
Loss = 5.7786e-05, PNorm = 67.3969, GNorm = 0.1829, lr_0 = 2.5001e-04
Validation rmse logD = 0.584722
Validation R2 logD = 0.768991
Validation rmse logP = 0.627293
Validation R2 logP = 0.757407
Epoch 60
Train function
Loss = 4.6386e-05, PNorm = 67.3982, GNorm = 0.1579, lr_0 = 2.4879e-04
Loss = 5.0006e-05, PNorm = 67.4021, GNorm = 0.1910, lr_0 = 2.4769e-04
Loss = 4.1960e-05, PNorm = 67.4076, GNorm = 0.1470, lr_0 = 2.4660e-04
Loss = 5.6061e-05, PNorm = 67.4141, GNorm = 0.1430, lr_0 = 2.4551e-04
Loss = 4.3522e-05, PNorm = 67.4172, GNorm = 0.2802, lr_0 = 2.4442e-04
Loss = 4.2343e-05, PNorm = 67.4213, GNorm = 0.3052, lr_0 = 2.4334e-04
Loss = 1.0929e-03, PNorm = 67.4213, GNorm = 0.4651, lr_0 = 2.4323e-04
Validation rmse logD = 0.587122
Validation R2 logD = 0.767091
Validation rmse logP = 0.623088
Validation R2 logP = 0.760648
Epoch 61
Train function
Loss = 5.0161e-05, PNorm = 67.4225, GNorm = 0.5348, lr_0 = 2.4216e-04
Loss = 8.5324e-05, PNorm = 67.4272, GNorm = 0.3964, lr_0 = 2.4109e-04
Loss = 6.4872e-05, PNorm = 67.4334, GNorm = 0.2551, lr_0 = 2.4002e-04
Loss = 5.0170e-05, PNorm = 67.4358, GNorm = 0.2925, lr_0 = 2.3896e-04
Loss = 5.3487e-05, PNorm = 67.4411, GNorm = 0.2849, lr_0 = 2.3790e-04
Validation rmse logD = 0.585430
Validation R2 logD = 0.768431
Validation rmse logP = 0.624999
Validation R2 logP = 0.759178
Epoch 62
Train function
Loss = 7.9562e-05, PNorm = 67.4473, GNorm = 0.4178, lr_0 = 2.3674e-04
Loss = 7.3026e-05, PNorm = 67.4494, GNorm = 0.4043, lr_0 = 2.3570e-04
Loss = 7.0655e-05, PNorm = 67.4552, GNorm = 0.2955, lr_0 = 2.3465e-04
Loss = 4.4707e-05, PNorm = 67.4593, GNorm = 0.1510, lr_0 = 2.3362e-04
Loss = 5.6494e-05, PNorm = 67.4614, GNorm = 0.1203, lr_0 = 2.3258e-04
Validation rmse logD = 0.588933
Validation R2 logD = 0.765652
Validation rmse logP = 0.613474
Validation R2 logP = 0.767978
Epoch 63
Train function
Loss = 4.1897e-05, PNorm = 67.4631, GNorm = 0.1572, lr_0 = 2.3145e-04
Loss = 3.6793e-05, PNorm = 67.4671, GNorm = 0.1218, lr_0 = 2.3043e-04
Loss = 4.4751e-05, PNorm = 67.4716, GNorm = 0.1396, lr_0 = 2.2941e-04
Loss = 3.7092e-05, PNorm = 67.4741, GNorm = 0.1489, lr_0 = 2.2839e-04
Loss = 3.9719e-05, PNorm = 67.4775, GNorm = 0.0904, lr_0 = 2.2738e-04
Validation rmse logD = 0.586973
Validation R2 logD = 0.767209
Validation rmse logP = 0.621945
Validation R2 logP = 0.761526
Epoch 64
Train function
Loss = 2.2575e-05, PNorm = 67.4803, GNorm = 0.1101, lr_0 = 2.2628e-04
Loss = 2.5869e-05, PNorm = 67.4817, GNorm = 0.1034, lr_0 = 2.2528e-04
Loss = 3.3225e-05, PNorm = 67.4853, GNorm = 0.4094, lr_0 = 2.2428e-04
Loss = 3.2900e-05, PNorm = 67.4876, GNorm = 0.1422, lr_0 = 2.2329e-04
Loss = 3.3778e-05, PNorm = 67.4887, GNorm = 0.1016, lr_0 = 2.2230e-04
Loss = 4.1751e-05, PNorm = 67.4903, GNorm = 0.1467, lr_0 = 2.2132e-04
Validation rmse logD = 0.586534
Validation R2 logD = 0.767557
Validation rmse logP = 0.626756
Validation R2 logP = 0.757822
Epoch 65
Train function
Loss = 2.7926e-05, PNorm = 67.4930, GNorm = 0.0759, lr_0 = 2.2024e-04
Loss = 2.7315e-05, PNorm = 67.4941, GNorm = 0.0768, lr_0 = 2.1927e-04
Loss = 2.0699e-05, PNorm = 67.4966, GNorm = 0.0693, lr_0 = 2.1830e-04
Loss = 2.5708e-05, PNorm = 67.4986, GNorm = 0.0720, lr_0 = 2.1733e-04
Loss = 3.1294e-05, PNorm = 67.5020, GNorm = 0.1785, lr_0 = 2.1637e-04
Validation rmse logD = 0.584918
Validation R2 logD = 0.768836
Validation rmse logP = 0.624651
Validation R2 logP = 0.759446
Epoch 66
Train function
Loss = 2.3949e-05, PNorm = 67.5053, GNorm = 0.1618, lr_0 = 2.1532e-04
Loss = 3.3298e-05, PNorm = 67.5076, GNorm = 0.1196, lr_0 = 2.1436e-04
Loss = 4.2302e-05, PNorm = 67.5087, GNorm = 0.1898, lr_0 = 2.1342e-04
Loss = 2.2134e-05, PNorm = 67.5117, GNorm = 0.1484, lr_0 = 2.1247e-04
Loss = 3.3175e-05, PNorm = 67.5152, GNorm = 0.3033, lr_0 = 2.1153e-04
Validation rmse logD = 0.587051
Validation R2 logD = 0.767147
Validation rmse logP = 0.622191
Validation R2 logP = 0.761337
Epoch 67
Train function
Loss = 3.3474e-05, PNorm = 67.5185, GNorm = 0.2544, lr_0 = 2.1060e-04
Loss = 2.4754e-05, PNorm = 67.5215, GNorm = 0.1327, lr_0 = 2.0966e-04
Loss = 3.2658e-05, PNorm = 67.5234, GNorm = 0.0932, lr_0 = 2.0874e-04
Loss = 2.2944e-05, PNorm = 67.5256, GNorm = 0.1538, lr_0 = 2.0781e-04
Loss = 2.4234e-05, PNorm = 67.5281, GNorm = 0.2552, lr_0 = 2.0689e-04
Loss = 3.0924e-05, PNorm = 67.5302, GNorm = 0.0996, lr_0 = 2.0598e-04
Validation rmse logD = 0.588164
Validation R2 logD = 0.766263
Validation rmse logP = 0.626716
Validation R2 logP = 0.757853
Epoch 68
Train function
Loss = 2.2443e-05, PNorm = 67.5327, GNorm = 0.1146, lr_0 = 2.0498e-04
Loss = 4.0225e-05, PNorm = 67.5335, GNorm = 0.4906, lr_0 = 2.0407e-04
Loss = 2.7919e-05, PNorm = 67.5340, GNorm = 0.1877, lr_0 = 2.0317e-04
Loss = 2.8786e-05, PNorm = 67.5368, GNorm = 0.1016, lr_0 = 2.0227e-04
Loss = 3.1751e-05, PNorm = 67.5401, GNorm = 0.0990, lr_0 = 2.0137e-04
Validation rmse logD = 0.586948
Validation R2 logD = 0.767229
Validation rmse logP = 0.624199
Validation R2 logP = 0.759795
Epoch 69
Train function
Loss = 2.5437e-05, PNorm = 67.5431, GNorm = 0.2969, lr_0 = 2.0039e-04
Loss = 2.7758e-05, PNorm = 67.5439, GNorm = 0.1188, lr_0 = 1.9951e-04
Loss = 2.8476e-05, PNorm = 67.5469, GNorm = 0.0951, lr_0 = 1.9863e-04
Loss = 2.2794e-05, PNorm = 67.5499, GNorm = 0.0928, lr_0 = 1.9775e-04
Loss = 1.7821e-05, PNorm = 67.5518, GNorm = 0.1313, lr_0 = 1.9687e-04
Validation rmse logD = 0.588702
Validation R2 logD = 0.765836
Validation rmse logP = 0.625616
Validation R2 logP = 0.758703
Epoch 70
Train function
Loss = 3.1645e-05, PNorm = 67.5545, GNorm = 0.4404, lr_0 = 1.9592e-04
Loss = 3.7766e-05, PNorm = 67.5570, GNorm = 0.2158, lr_0 = 1.9505e-04
Loss = 4.3929e-05, PNorm = 67.5595, GNorm = 0.1847, lr_0 = 1.9419e-04
Loss = 2.4783e-05, PNorm = 67.5630, GNorm = 0.1654, lr_0 = 1.9333e-04
Loss = 3.0971e-05, PNorm = 67.5661, GNorm = 0.1215, lr_0 = 1.9247e-04
Loss = 2.1278e-05, PNorm = 67.5684, GNorm = 0.1475, lr_0 = 1.9162e-04
Validation rmse logD = 0.587825
Validation R2 logD = 0.766533
Validation rmse logP = 0.620662
Validation R2 logP = 0.762509
Epoch 71
Train function
Loss = 2.2631e-05, PNorm = 67.5713, GNorm = 0.1349, lr_0 = 1.9069e-04
Loss = 3.3447e-05, PNorm = 67.5739, GNorm = 0.2524, lr_0 = 1.8984e-04
Loss = 2.2043e-05, PNorm = 67.5758, GNorm = 0.0871, lr_0 = 1.8900e-04
Loss = 2.7764e-05, PNorm = 67.5773, GNorm = 0.1824, lr_0 = 1.8817e-04
Loss = 3.0270e-05, PNorm = 67.5790, GNorm = 0.1081, lr_0 = 1.8734e-04
Validation rmse logD = 0.588043
Validation R2 logD = 0.766359
Validation rmse logP = 0.628320
Validation R2 logP = 0.756612
Epoch 72
Train function
Loss = 2.7056e-05, PNorm = 67.5800, GNorm = 0.1669, lr_0 = 1.8643e-04
Loss = 2.7992e-05, PNorm = 67.5817, GNorm = 0.0754, lr_0 = 1.8560e-04
Loss = 2.6392e-05, PNorm = 67.5833, GNorm = 0.0970, lr_0 = 1.8478e-04
Loss = 2.4046e-05, PNorm = 67.5851, GNorm = 0.0948, lr_0 = 1.8396e-04
Loss = 2.4805e-05, PNorm = 67.5871, GNorm = 0.0996, lr_0 = 1.8315e-04
Validation rmse logD = 0.586161
Validation R2 logD = 0.767852
Validation rmse logP = 0.623202
Validation R2 logP = 0.760561
Epoch 73
Train function
Loss = 2.3153e-05, PNorm = 67.5899, GNorm = 0.1065, lr_0 = 1.8226e-04
Loss = 1.7558e-05, PNorm = 67.5925, GNorm = 0.0813, lr_0 = 1.8145e-04
Loss = 1.6776e-05, PNorm = 67.5934, GNorm = 0.1659, lr_0 = 1.8065e-04
Loss = 1.8045e-05, PNorm = 67.5945, GNorm = 0.1723, lr_0 = 1.7985e-04
Loss = 3.0390e-05, PNorm = 67.5963, GNorm = 0.3715, lr_0 = 1.7905e-04
Loss = 2.6306e-05, PNorm = 67.5987, GNorm = 0.1535, lr_0 = 1.7826e-04
Loss = 2.2992e-04, PNorm = 67.5994, GNorm = 0.3189, lr_0 = 1.7818e-04
Validation rmse logD = 0.587426
Validation R2 logD = 0.766849
Validation rmse logP = 0.628239
Validation R2 logP = 0.756675
Epoch 74
Train function
Loss = 1.8231e-05, PNorm = 67.6024, GNorm = 0.0736, lr_0 = 1.7739e-04
Loss = 2.0644e-05, PNorm = 67.6052, GNorm = 0.1896, lr_0 = 1.7661e-04
Loss = 2.2858e-05, PNorm = 67.6063, GNorm = 0.1464, lr_0 = 1.7583e-04
Loss = 3.5838e-05, PNorm = 67.6056, GNorm = 0.0966, lr_0 = 1.7505e-04
Loss = 2.4980e-05, PNorm = 67.6082, GNorm = 0.1126, lr_0 = 1.7428e-04
Validation rmse logD = 0.585367
Validation R2 logD = 0.768481
Validation rmse logP = 0.625236
Validation R2 logP = 0.758996
Epoch 75
Train function
Loss = 2.1680e-05, PNorm = 67.6099, GNorm = 0.0835, lr_0 = 1.7351e-04
Loss = 2.2488e-05, PNorm = 67.6120, GNorm = 0.0680, lr_0 = 1.7274e-04
Loss = 2.4346e-05, PNorm = 67.6145, GNorm = 0.0701, lr_0 = 1.7197e-04
Loss = 2.2223e-05, PNorm = 67.6171, GNorm = 0.1295, lr_0 = 1.7121e-04
Loss = 1.9349e-05, PNorm = 67.6184, GNorm = 0.1050, lr_0 = 1.7046e-04
Validation rmse logD = 0.586517
Validation R2 logD = 0.767570
Validation rmse logP = 0.627547
Validation R2 logP = 0.757210
Epoch 76
Train function
Loss = 1.9637e-05, PNorm = 67.6206, GNorm = 0.2012, lr_0 = 1.6963e-04
Loss = 2.3838e-05, PNorm = 67.6218, GNorm = 0.1961, lr_0 = 1.6888e-04
Loss = 2.5874e-05, PNorm = 67.6236, GNorm = 0.0954, lr_0 = 1.6813e-04
Loss = 2.5687e-05, PNorm = 67.6249, GNorm = 0.1704, lr_0 = 1.6739e-04
Loss = 2.5396e-05, PNorm = 67.6263, GNorm = 0.1242, lr_0 = 1.6665e-04
Loss = 2.4119e-05, PNorm = 67.6291, GNorm = 0.2069, lr_0 = 1.6591e-04
Loss = 3.0923e-04, PNorm = 67.6295, GNorm = 0.3556, lr_0 = 1.6584e-04
Validation rmse logD = 0.586819
Validation R2 logD = 0.767331
Validation rmse logP = 0.625283
Validation R2 logP = 0.758959
Epoch 77
Train function
Loss = 2.0058e-05, PNorm = 67.6319, GNorm = 0.1429, lr_0 = 1.6510e-04
Loss = 2.5468e-05, PNorm = 67.6315, GNorm = 0.1510, lr_0 = 1.6437e-04
Loss = 2.1678e-05, PNorm = 67.6322, GNorm = 0.2011, lr_0 = 1.6364e-04
Loss = 2.0747e-05, PNorm = 67.6348, GNorm = 0.0756, lr_0 = 1.6292e-04
Loss = 2.2030e-05, PNorm = 67.6377, GNorm = 0.1374, lr_0 = 1.6220e-04
Validation rmse logD = 0.587390
Validation R2 logD = 0.766878
Validation rmse logP = 0.629929
Validation R2 logP = 0.755364
Epoch 78
Train function
Loss = 2.6124e-05, PNorm = 67.6403, GNorm = 0.1658, lr_0 = 1.6141e-04
Loss = 2.4005e-05, PNorm = 67.6437, GNorm = 0.0862, lr_0 = 1.6070e-04
Loss = 2.2160e-05, PNorm = 67.6449, GNorm = 0.1040, lr_0 = 1.5999e-04
Loss = 2.7434e-05, PNorm = 67.6466, GNorm = 0.1502, lr_0 = 1.5928e-04
Loss = 2.2896e-05, PNorm = 67.6486, GNorm = 0.1776, lr_0 = 1.5857e-04
Validation rmse logD = 0.589125
Validation R2 logD = 0.765498
Validation rmse logP = 0.634441
Validation R2 logP = 0.751847
Epoch 79
Train function
Loss = 2.1122e-05, PNorm = 67.6498, GNorm = 0.0786, lr_0 = 1.5780e-04
Loss = 2.3880e-05, PNorm = 67.6518, GNorm = 0.0859, lr_0 = 1.5710e-04
Loss = 2.0389e-05, PNorm = 67.6536, GNorm = 0.0859, lr_0 = 1.5641e-04
Loss = 1.7487e-05, PNorm = 67.6542, GNorm = 0.1196, lr_0 = 1.5572e-04
Loss = 2.3246e-05, PNorm = 67.6558, GNorm = 0.1758, lr_0 = 1.5503e-04
Validation rmse logD = 0.586934
Validation R2 logD = 0.767240
Validation rmse logP = 0.626195
Validation R2 logP = 0.758255
Epoch 80
Train function
Loss = 1.4928e-05, PNorm = 67.6577, GNorm = 0.1019, lr_0 = 1.5427e-04
Loss = 2.2600e-05, PNorm = 67.6604, GNorm = 0.0925, lr_0 = 1.5359e-04
Loss = 1.3997e-05, PNorm = 67.6616, GNorm = 0.0726, lr_0 = 1.5291e-04
Loss = 1.3731e-05, PNorm = 67.6626, GNorm = 0.0667, lr_0 = 1.5224e-04
Loss = 1.7394e-05, PNorm = 67.6648, GNorm = 0.0982, lr_0 = 1.5156e-04
Loss = 2.0460e-05, PNorm = 67.6667, GNorm = 0.0579, lr_0 = 1.5089e-04
Validation rmse logD = 0.586973
Validation R2 logD = 0.767209
Validation rmse logP = 0.624783
Validation R2 logP = 0.759344
Epoch 81
Train function
Loss = 1.4549e-05, PNorm = 67.6667, GNorm = 0.1015, lr_0 = 1.5016e-04
Loss = 1.1368e-05, PNorm = 67.6682, GNorm = 0.1153, lr_0 = 1.4949e-04
Loss = 1.4009e-05, PNorm = 67.6692, GNorm = 0.0902, lr_0 = 1.4883e-04
Loss = 1.2025e-05, PNorm = 67.6709, GNorm = 0.0670, lr_0 = 1.4817e-04
Loss = 1.2104e-05, PNorm = 67.6719, GNorm = 0.1107, lr_0 = 1.4752e-04
Validation rmse logD = 0.586891
Validation R2 logD = 0.767274
Validation rmse logP = 0.625320
Validation R2 logP = 0.758931
Epoch 82
Train function
Loss = 1.2632e-05, PNorm = 67.6726, GNorm = 0.1629, lr_0 = 1.4680e-04
Loss = 1.3806e-05, PNorm = 67.6737, GNorm = 0.1014, lr_0 = 1.4615e-04
Loss = 7.3235e-06, PNorm = 67.6750, GNorm = 0.1330, lr_0 = 1.4551e-04
Loss = 1.7078e-05, PNorm = 67.6764, GNorm = 0.0677, lr_0 = 1.4486e-04
Loss = 1.4474e-05, PNorm = 67.6780, GNorm = 0.2311, lr_0 = 1.4422e-04
Validation rmse logD = 0.585766
Validation R2 logD = 0.768165
Validation rmse logP = 0.628615
Validation R2 logP = 0.756384
Epoch 83
Train function
Loss = 2.9817e-05, PNorm = 67.6805, GNorm = 0.0918, lr_0 = 1.4352e-04
Loss = 1.2289e-05, PNorm = 67.6814, GNorm = 0.0754, lr_0 = 1.4288e-04
Loss = 1.2411e-05, PNorm = 67.6828, GNorm = 0.1053, lr_0 = 1.4225e-04
Loss = 1.0438e-05, PNorm = 67.6834, GNorm = 0.0596, lr_0 = 1.4162e-04
Loss = 1.3456e-05, PNorm = 67.6852, GNorm = 0.0576, lr_0 = 1.4100e-04
Loss = 1.2658e-05, PNorm = 67.6858, GNorm = 0.1610, lr_0 = 1.4037e-04
Validation rmse logD = 0.585668
Validation R2 logD = 0.768243
Validation rmse logP = 0.623181
Validation R2 logP = 0.760577
Epoch 84
Train function
Loss = 1.2890e-05, PNorm = 67.6870, GNorm = 0.0889, lr_0 = 1.3975e-04
Loss = 1.5064e-05, PNorm = 67.6890, GNorm = 0.0780, lr_0 = 1.3913e-04
Loss = 1.6222e-05, PNorm = 67.6900, GNorm = 0.1062, lr_0 = 1.3852e-04
Loss = 1.8241e-05, PNorm = 67.6912, GNorm = 0.1437, lr_0 = 1.3791e-04
Loss = 2.0198e-05, PNorm = 67.6920, GNorm = 0.2524, lr_0 = 1.3730e-04
Validation rmse logD = 0.588436
Validation R2 logD = 0.766047
Validation rmse logP = 0.631553
Validation R2 logP = 0.754101
Epoch 85
Train function
Loss = 1.2065e-05, PNorm = 67.6931, GNorm = 0.0614, lr_0 = 1.3663e-04
Loss = 1.2277e-05, PNorm = 67.6950, GNorm = 0.1185, lr_0 = 1.3602e-04
Loss = 1.5837e-05, PNorm = 67.6962, GNorm = 0.1361, lr_0 = 1.3542e-04
Loss = 1.3619e-05, PNorm = 67.6973, GNorm = 0.1744, lr_0 = 1.3482e-04
Loss = 1.5785e-05, PNorm = 67.6991, GNorm = 0.1983, lr_0 = 1.3423e-04
Validation rmse logD = 0.586905
Validation R2 logD = 0.767263
Validation rmse logP = 0.626448
Validation R2 logP = 0.758061
Epoch 86
Train function
Loss = 1.2703e-05, PNorm = 67.6996, GNorm = 0.0952, lr_0 = 1.3357e-04
Loss = 1.3192e-05, PNorm = 67.7007, GNorm = 0.0805, lr_0 = 1.3298e-04
Loss = 1.4052e-05, PNorm = 67.7018, GNorm = 0.1191, lr_0 = 1.3239e-04
Loss = 1.1529e-05, PNorm = 67.7030, GNorm = 0.0437, lr_0 = 1.3181e-04
Loss = 1.3404e-05, PNorm = 67.7040, GNorm = 0.0582, lr_0 = 1.3123e-04
Loss = 1.3468e-05, PNorm = 67.7054, GNorm = 0.0841, lr_0 = 1.3065e-04
Validation rmse logD = 0.586543
Validation R2 logD = 0.767550
Validation rmse logP = 0.627667
Validation R2 logP = 0.757118
Epoch 87
Train function
Loss = 1.0344e-05, PNorm = 67.7058, GNorm = 0.0983, lr_0 = 1.3001e-04
Loss = 1.3011e-05, PNorm = 67.7070, GNorm = 0.0970, lr_0 = 1.2944e-04
Loss = 1.0641e-05, PNorm = 67.7077, GNorm = 0.0945, lr_0 = 1.2886e-04
Loss = 1.2653e-05, PNorm = 67.7086, GNorm = 0.0831, lr_0 = 1.2829e-04
Loss = 1.1111e-05, PNorm = 67.7098, GNorm = 0.0674, lr_0 = 1.2773e-04
Validation rmse logD = 0.587257
Validation R2 logD = 0.766983
Validation rmse logP = 0.629061
Validation R2 logP = 0.756037
Epoch 88
Train function
Loss = 1.1174e-05, PNorm = 67.7112, GNorm = 0.1336, lr_0 = 1.2710e-04
Loss = 8.1040e-06, PNorm = 67.7130, GNorm = 0.0420, lr_0 = 1.2654e-04
Loss = 1.4322e-05, PNorm = 67.7139, GNorm = 0.0684, lr_0 = 1.2598e-04
Loss = 9.0256e-06, PNorm = 67.7149, GNorm = 0.0588, lr_0 = 1.2542e-04
Loss = 1.0459e-05, PNorm = 67.7151, GNorm = 0.2099, lr_0 = 1.2487e-04
Validation rmse logD = 0.587571
Validation R2 logD = 0.766735
Validation rmse logP = 0.624586
Validation R2 logP = 0.759496
Epoch 89
Train function
Loss = 1.5558e-05, PNorm = 67.7157, GNorm = 0.0617, lr_0 = 1.2426e-04
Loss = 1.2071e-05, PNorm = 67.7171, GNorm = 0.0462, lr_0 = 1.2371e-04
Loss = 1.0817e-05, PNorm = 67.7181, GNorm = 0.1331, lr_0 = 1.2317e-04
Loss = 8.9389e-06, PNorm = 67.7190, GNorm = 0.1113, lr_0 = 1.2262e-04
Loss = 9.7025e-06, PNorm = 67.7200, GNorm = 0.0409, lr_0 = 1.2208e-04
Loss = 9.4742e-06, PNorm = 67.7214, GNorm = 0.1614, lr_0 = 1.2154e-04
Loss = 1.0215e-04, PNorm = 67.7217, GNorm = 0.2826, lr_0 = 1.2148e-04
Validation rmse logD = 0.587398
Validation R2 logD = 0.766872
Validation rmse logP = 0.627360
Validation R2 logP = 0.757355
Epoch 90
Train function
Loss = 1.0332e-05, PNorm = 67.7226, GNorm = 0.1518, lr_0 = 1.2095e-04
Loss = 1.0627e-05, PNorm = 67.7242, GNorm = 0.1777, lr_0 = 1.2041e-04
Loss = 9.7562e-06, PNorm = 67.7244, GNorm = 0.0687, lr_0 = 1.1988e-04
Loss = 9.4868e-06, PNorm = 67.7251, GNorm = 0.1245, lr_0 = 1.1935e-04
Loss = 7.3368e-06, PNorm = 67.7257, GNorm = 0.0892, lr_0 = 1.1882e-04
Validation rmse logD = 0.587022
Validation R2 logD = 0.767170
Validation rmse logP = 0.624180
Validation R2 logP = 0.759809
Epoch 91
Train function
Loss = 7.4811e-06, PNorm = 67.7265, GNorm = 0.0655, lr_0 = 1.1824e-04
Loss = 6.5956e-06, PNorm = 67.7274, GNorm = 0.0515, lr_0 = 1.1772e-04
Loss = 8.3779e-06, PNorm = 67.7282, GNorm = 0.0635, lr_0 = 1.1720e-04
Loss = 8.7358e-06, PNorm = 67.7293, GNorm = 0.0686, lr_0 = 1.1668e-04
Loss = 7.8702e-06, PNorm = 67.7299, GNorm = 0.0724, lr_0 = 1.1616e-04
Validation rmse logD = 0.586429
Validation R2 logD = 0.767640
Validation rmse logP = 0.625142
Validation R2 logP = 0.759068
Epoch 92
Train function
Loss = 1.3311e-05, PNorm = 67.7306, GNorm = 0.0613, lr_0 = 1.1565e-04
Loss = 9.5737e-06, PNorm = 67.7312, GNorm = 0.1491, lr_0 = 1.1514e-04
Loss = 1.1682e-05, PNorm = 67.7325, GNorm = 0.1508, lr_0 = 1.1463e-04
Loss = 8.5347e-06, PNorm = 67.7334, GNorm = 0.1376, lr_0 = 1.1412e-04
Loss = 1.3775e-05, PNorm = 67.7352, GNorm = 0.1499, lr_0 = 1.1362e-04
Loss = 8.3363e-06, PNorm = 67.7365, GNorm = 0.0602, lr_0 = 1.1312e-04
Loss = 5.3153e-05, PNorm = 67.7366, GNorm = 0.1470, lr_0 = 1.1307e-04
Validation rmse logD = 0.586322
Validation R2 logD = 0.767725
Validation rmse logP = 0.625842
Validation R2 logP = 0.758528
Epoch 93
Train function
Loss = 5.9724e-06, PNorm = 67.7375, GNorm = 0.0578, lr_0 = 1.1257e-04
Loss = 7.3799e-06, PNorm = 67.7378, GNorm = 0.0684, lr_0 = 1.1207e-04
Loss = 9.0313e-06, PNorm = 67.7381, GNorm = 0.0724, lr_0 = 1.1157e-04
Loss = 6.2225e-06, PNorm = 67.7389, GNorm = 0.0502, lr_0 = 1.1108e-04
Loss = 1.1351e-05, PNorm = 67.7396, GNorm = 0.1095, lr_0 = 1.1059e-04
Validation rmse logD = 0.587026
Validation R2 logD = 0.767167
Validation rmse logP = 0.626962
Validation R2 logP = 0.757663
Epoch 94
Train function
Loss = 5.9938e-06, PNorm = 67.7403, GNorm = 0.0862, lr_0 = 1.1005e-04
Loss = 1.0919e-05, PNorm = 67.7422, GNorm = 0.0602, lr_0 = 1.0956e-04
Loss = 1.0110e-05, PNorm = 67.7425, GNorm = 0.0970, lr_0 = 1.0908e-04
Loss = 7.7632e-06, PNorm = 67.7433, GNorm = 0.0355, lr_0 = 1.0860e-04
Loss = 7.6636e-06, PNorm = 67.7436, GNorm = 0.0481, lr_0 = 1.0811e-04
Validation rmse logD = 0.587252
Validation R2 logD = 0.766988
Validation rmse logP = 0.628896
Validation R2 logP = 0.756166
Epoch 95
Train function
Loss = 7.3596e-06, PNorm = 67.7448, GNorm = 0.1669, lr_0 = 1.0759e-04
Loss = 1.0219e-05, PNorm = 67.7461, GNorm = 0.0442, lr_0 = 1.0711e-04
Loss = 9.3617e-06, PNorm = 67.7466, GNorm = 0.0993, lr_0 = 1.0664e-04
Loss = 6.8907e-06, PNorm = 67.7479, GNorm = 0.0434, lr_0 = 1.0617e-04
Loss = 6.5856e-06, PNorm = 67.7492, GNorm = 0.0520, lr_0 = 1.0570e-04
Validation rmse logD = 0.589413
Validation R2 logD = 0.765270
Validation rmse logP = 0.629868
Validation R2 logP = 0.755411
Epoch 96
Train function
Loss = 1.0577e-05, PNorm = 67.7504, GNorm = 0.1967, lr_0 = 1.0518e-04
Loss = 1.2805e-05, PNorm = 67.7510, GNorm = 0.1920, lr_0 = 1.0472e-04
Loss = 8.7443e-06, PNorm = 67.7515, GNorm = 0.0957, lr_0 = 1.0426e-04
Loss = 1.4245e-05, PNorm = 67.7523, GNorm = 0.1022, lr_0 = 1.0379e-04
Loss = 9.1483e-06, PNorm = 67.7538, GNorm = 0.1340, lr_0 = 1.0333e-04
Loss = 1.1636e-05, PNorm = 67.7546, GNorm = 0.2197, lr_0 = 1.0288e-04
Validation rmse logD = 0.587294
Validation R2 logD = 0.766954
Validation rmse logP = 0.625776
Validation R2 logP = 0.758579
Epoch 97
Train function
Loss = 9.0717e-06, PNorm = 67.7556, GNorm = 0.0904, lr_0 = 1.0238e-04
Loss = 8.4734e-06, PNorm = 67.7565, GNorm = 0.0709, lr_0 = 1.0192e-04
Loss = 8.3870e-06, PNorm = 67.7563, GNorm = 0.2093, lr_0 = 1.0147e-04
Loss = 7.4983e-06, PNorm = 67.7569, GNorm = 0.0546, lr_0 = 1.0102e-04
Loss = 1.0910e-05, PNorm = 67.7578, GNorm = 0.1078, lr_0 = 1.0058e-04
Validation rmse logD = 0.586312
Validation R2 logD = 0.767733
Validation rmse logP = 0.626543
Validation R2 logP = 0.757987
Epoch 98
Train function
Loss = 1.3229e-05, PNorm = 67.7596, GNorm = 0.1549, lr_0 = 1.0009e-04
Loss = 8.9192e-06, PNorm = 67.7604, GNorm = 0.1166, lr_0 = 1.0000e-04
Loss = 1.1409e-05, PNorm = 67.7619, GNorm = 0.0578, lr_0 = 1.0000e-04
Loss = 6.7049e-06, PNorm = 67.7633, GNorm = 0.0658, lr_0 = 1.0000e-04
Loss = 9.6700e-06, PNorm = 67.7640, GNorm = 0.0891, lr_0 = 1.0000e-04
Validation rmse logD = 0.587688
Validation R2 logD = 0.766642
Validation rmse logP = 0.627061
Validation R2 logP = 0.757587
Epoch 99
Train function
Loss = 5.5126e-06, PNorm = 67.7649, GNorm = 0.0916, lr_0 = 1.0000e-04
Loss = 8.8458e-06, PNorm = 67.7658, GNorm = 0.0338, lr_0 = 1.0000e-04
Loss = 6.4276e-06, PNorm = 67.7670, GNorm = 0.0573, lr_0 = 1.0000e-04
Loss = 7.0918e-06, PNorm = 67.7671, GNorm = 0.0422, lr_0 = 1.0000e-04
Loss = 8.8926e-06, PNorm = 67.7680, GNorm = 0.1014, lr_0 = 1.0000e-04
Loss = 5.0015e-06, PNorm = 67.7684, GNorm = 0.0565, lr_0 = 1.0000e-04
Validation rmse logD = 0.587036
Validation R2 logD = 0.767159
Validation rmse logP = 0.626359
Validation R2 logP = 0.758129
Model 0 best validation rmse = 0.597740 on epoch 41
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.634488
Model 0 test R2 logD = 0.717262
Model 0 test rmse logP = 0.804256
Model 0 test R2 logP = 0.720696
Ensemble test rmse  logD= 0.634488
Ensemble test R2  logD= 0.717262
Ensemble test rmse  logP= 0.804256
Ensemble test R2  logP= 0.720696
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.1765e-02, PNorm = 55.5679, GNorm = 11.7307, lr_0 = 1.9340e-04
Loss = 1.9364e-02, PNorm = 55.5754, GNorm = 1.2873, lr_0 = 2.7830e-04
Loss = 1.7093e-02, PNorm = 55.5892, GNorm = 8.9079, lr_0 = 3.6321e-04
Loss = 1.5545e-02, PNorm = 55.6122, GNorm = 4.3203, lr_0 = 4.4811e-04
Loss = 1.4604e-02, PNorm = 55.6500, GNorm = 1.7645, lr_0 = 5.3302e-04
Validation rmse logD = 1.099156
Validation R2 logD = 0.126485
Validation rmse logP = 1.180541
Validation R2 logP = 0.291712
Epoch 1
Train function
Loss = 1.6183e-02, PNorm = 55.7036, GNorm = 1.8710, lr_0 = 6.2642e-04
Loss = 1.3962e-02, PNorm = 55.7738, GNorm = 3.6767, lr_0 = 7.1132e-04
Loss = 1.5224e-02, PNorm = 55.8601, GNorm = 3.3012, lr_0 = 7.9623e-04
Loss = 1.2220e-02, PNorm = 55.9724, GNorm = 2.4838, lr_0 = 8.8113e-04
Loss = 1.0614e-02, PNorm = 56.0904, GNorm = 2.3181, lr_0 = 9.6604e-04
Validation rmse logD = 1.097716
Validation R2 logD = 0.128772
Validation rmse logP = 1.263485
Validation R2 logP = 0.188688
Epoch 2
Train function
Loss = 1.1911e-02, PNorm = 56.2052, GNorm = 7.5587, lr_0 = 9.9690e-04
Loss = 1.2548e-02, PNorm = 56.3276, GNorm = 4.6413, lr_0 = 9.9249e-04
Loss = 1.1198e-02, PNorm = 56.4387, GNorm = 3.3841, lr_0 = 9.8810e-04
Loss = 1.1095e-02, PNorm = 56.5446, GNorm = 3.7923, lr_0 = 9.8373e-04
Loss = 1.1247e-02, PNorm = 56.6670, GNorm = 1.4266, lr_0 = 9.7938e-04
Validation rmse logD = 0.809134
Validation R2 logD = 0.526638
Validation rmse logP = 0.938907
Validation R2 logP = 0.551984
Epoch 3
Train function
Loss = 1.2322e-02, PNorm = 56.7951, GNorm = 1.4489, lr_0 = 9.7462e-04
Loss = 1.0153e-02, PNorm = 56.9068, GNorm = 1.6030, lr_0 = 9.7030e-04
Loss = 9.7906e-03, PNorm = 57.0405, GNorm = 2.9202, lr_0 = 9.6601e-04
Loss = 8.0479e-03, PNorm = 57.1603, GNorm = 3.2235, lr_0 = 9.6174e-04
Loss = 7.9524e-03, PNorm = 57.2474, GNorm = 1.4404, lr_0 = 9.5749e-04
Loss = 8.9027e-03, PNorm = 57.3291, GNorm = 3.9397, lr_0 = 9.5325e-04
Validation rmse logD = 0.871141
Validation R2 logD = 0.451308
Validation rmse logP = 0.899223
Validation R2 logP = 0.589056
Epoch 4
Train function
Loss = 8.4515e-03, PNorm = 57.4453, GNorm = 2.6228, lr_0 = 9.4861e-04
Loss = 8.8877e-03, PNorm = 57.5616, GNorm = 2.9535, lr_0 = 9.4442e-04
Loss = 7.4432e-03, PNorm = 57.6560, GNorm = 2.1902, lr_0 = 9.4024e-04
Loss = 8.2443e-03, PNorm = 57.7704, GNorm = 1.7653, lr_0 = 9.3608e-04
Loss = 7.6059e-03, PNorm = 57.8537, GNorm = 3.6235, lr_0 = 9.3194e-04
Validation rmse logD = 0.798208
Validation R2 logD = 0.539336
Validation rmse logP = 0.893079
Validation R2 logP = 0.594652
Epoch 5
Train function
Loss = 8.9818e-03, PNorm = 57.9461, GNorm = 3.2599, lr_0 = 9.2741e-04
Loss = 6.4197e-03, PNorm = 58.0671, GNorm = 1.6599, lr_0 = 9.2330e-04
Loss = 6.4017e-03, PNorm = 58.1450, GNorm = 0.8046, lr_0 = 9.1922e-04
Loss = 6.8948e-03, PNorm = 58.2392, GNorm = 0.9574, lr_0 = 9.1515e-04
Loss = 5.9462e-03, PNorm = 58.3273, GNorm = 1.9701, lr_0 = 9.1111e-04
Validation rmse logD = 0.758335
Validation R2 logD = 0.584210
Validation rmse logP = 0.847688
Validation R2 logP = 0.634809
Epoch 6
Train function
Loss = 6.5604e-03, PNorm = 58.4254, GNorm = 1.1584, lr_0 = 9.0667e-04
Loss = 6.9181e-03, PNorm = 58.5220, GNorm = 2.2929, lr_0 = 9.0266e-04
Loss = 5.6007e-03, PNorm = 58.6482, GNorm = 1.2026, lr_0 = 8.9867e-04
Loss = 6.8021e-03, PNorm = 58.7507, GNorm = 2.2314, lr_0 = 8.9469e-04
Loss = 5.7786e-03, PNorm = 58.8407, GNorm = 2.4755, lr_0 = 8.9074e-04
Loss = 6.0617e-03, PNorm = 58.9378, GNorm = 0.8334, lr_0 = 8.8680e-04
Validation rmse logD = 0.693696
Validation R2 logD = 0.652071
Validation rmse logP = 0.818996
Validation R2 logP = 0.659112
Epoch 7
Train function
Loss = 5.6447e-03, PNorm = 59.0428, GNorm = 1.9029, lr_0 = 8.8248e-04
Loss = 5.4556e-03, PNorm = 59.1525, GNorm = 1.1622, lr_0 = 8.7858e-04
Loss = 4.7515e-03, PNorm = 59.2386, GNorm = 2.1892, lr_0 = 8.7469e-04
Loss = 6.1681e-03, PNorm = 59.3199, GNorm = 1.7180, lr_0 = 8.7082e-04
Loss = 4.8892e-03, PNorm = 59.4131, GNorm = 0.9953, lr_0 = 8.6697e-04
Validation rmse logD = 0.676626
Validation R2 logD = 0.668983
Validation rmse logP = 0.818601
Validation R2 logP = 0.659441
Epoch 8
Train function
Loss = 4.1353e-03, PNorm = 59.5102, GNorm = 3.2323, lr_0 = 8.6276e-04
Loss = 4.7490e-03, PNorm = 59.6179, GNorm = 5.0504, lr_0 = 8.5894e-04
Loss = 6.0718e-03, PNorm = 59.7168, GNorm = 2.9465, lr_0 = 8.5514e-04
Loss = 5.2427e-03, PNorm = 59.8347, GNorm = 0.9480, lr_0 = 8.5136e-04
Loss = 4.3980e-03, PNorm = 59.9211, GNorm = 1.4765, lr_0 = 8.4759e-04
Validation rmse logD = 0.706157
Validation R2 logD = 0.639459
Validation rmse logP = 0.807801
Validation R2 logP = 0.668367
Epoch 9
Train function
Loss = 3.8481e-03, PNorm = 59.9826, GNorm = 2.3809, lr_0 = 8.4384e-04
Loss = 4.4262e-03, PNorm = 60.0483, GNorm = 3.4961, lr_0 = 8.4011e-04
Loss = 4.4990e-03, PNorm = 60.1352, GNorm = 0.6967, lr_0 = 8.3639e-04
Loss = 4.1999e-03, PNorm = 60.2285, GNorm = 1.1020, lr_0 = 8.3269e-04
Loss = 3.5619e-03, PNorm = 60.3268, GNorm = 1.5763, lr_0 = 8.2901e-04
Loss = 3.8631e-03, PNorm = 60.4020, GNorm = 0.6640, lr_0 = 8.2534e-04
Validation rmse logD = 0.634066
Validation R2 logD = 0.709316
Validation rmse logP = 0.763153
Validation R2 logP = 0.704013
Epoch 10
Train function
Loss = 3.5472e-03, PNorm = 60.4828, GNorm = 1.1041, lr_0 = 8.2133e-04
Loss = 3.4245e-03, PNorm = 60.5692, GNorm = 0.7979, lr_0 = 8.1770e-04
Loss = 3.4023e-03, PNorm = 60.6646, GNorm = 1.2020, lr_0 = 8.1408e-04
Loss = 4.2424e-03, PNorm = 60.7438, GNorm = 1.1575, lr_0 = 8.1048e-04
Loss = 3.4317e-03, PNorm = 60.8399, GNorm = 0.7044, lr_0 = 8.0689e-04
Validation rmse logD = 0.635488
Validation R2 logD = 0.708011
Validation rmse logP = 0.880457
Validation R2 logP = 0.606028
Epoch 11
Train function
Loss = 3.0034e-03, PNorm = 60.9381, GNorm = 0.8440, lr_0 = 8.0297e-04
Loss = 3.2178e-03, PNorm = 60.9965, GNorm = 2.6674, lr_0 = 7.9942e-04
Loss = 3.4289e-03, PNorm = 61.0810, GNorm = 3.4186, lr_0 = 7.9588e-04
Loss = 3.3325e-03, PNorm = 61.1735, GNorm = 1.6325, lr_0 = 7.9236e-04
Loss = 2.6571e-03, PNorm = 61.2496, GNorm = 1.8948, lr_0 = 7.8885e-04
Validation rmse logD = 0.655992
Validation R2 logD = 0.688865
Validation rmse logP = 0.737744
Validation R2 logP = 0.723396
Epoch 12
Train function
Loss = 2.4484e-03, PNorm = 61.3457, GNorm = 1.2106, lr_0 = 7.8502e-04
Loss = 2.7018e-03, PNorm = 61.4240, GNorm = 0.9862, lr_0 = 7.8154e-04
Loss = 3.0699e-03, PNorm = 61.4965, GNorm = 1.6232, lr_0 = 7.7809e-04
Loss = 3.3101e-03, PNorm = 61.5807, GNorm = 0.7113, lr_0 = 7.7465e-04
Loss = 2.9467e-03, PNorm = 61.6634, GNorm = 0.9497, lr_0 = 7.7122e-04
Loss = 2.4911e-03, PNorm = 61.7405, GNorm = 1.7594, lr_0 = 7.6781e-04
Loss = 1.7348e-02, PNorm = 61.7457, GNorm = 3.9851, lr_0 = 7.6747e-04
Validation rmse logD = 0.641120
Validation R2 logD = 0.702812
Validation rmse logP = 0.761976
Validation R2 logP = 0.704926
Epoch 13
Train function
Loss = 2.3759e-03, PNorm = 61.8222, GNorm = 1.2688, lr_0 = 7.6407e-04
Loss = 2.0878e-03, PNorm = 61.9027, GNorm = 1.2902, lr_0 = 7.6069e-04
Loss = 2.4193e-03, PNorm = 61.9711, GNorm = 2.2229, lr_0 = 7.5733e-04
Loss = 2.5439e-03, PNorm = 62.0252, GNorm = 1.4195, lr_0 = 7.5398e-04
Loss = 2.0743e-03, PNorm = 62.0860, GNorm = 0.9774, lr_0 = 7.5064e-04
Validation rmse logD = 0.663893
Validation R2 logD = 0.681325
Validation rmse logP = 0.715796
Validation R2 logP = 0.739609
Epoch 14
Train function
Loss = 2.2234e-03, PNorm = 62.1828, GNorm = 1.7769, lr_0 = 7.4699e-04
Loss = 2.2525e-03, PNorm = 62.2600, GNorm = 2.1361, lr_0 = 7.4369e-04
Loss = 2.2692e-03, PNorm = 62.3368, GNorm = 0.5640, lr_0 = 7.4040e-04
Loss = 2.2726e-03, PNorm = 62.4098, GNorm = 0.7140, lr_0 = 7.3712e-04
Loss = 1.9449e-03, PNorm = 62.4720, GNorm = 1.6638, lr_0 = 7.3386e-04
Validation rmse logD = 0.688299
Validation R2 logD = 0.657464
Validation rmse logP = 0.716792
Validation R2 logP = 0.738884
Epoch 15
Train function
Loss = 2.7064e-03, PNorm = 62.5571, GNorm = 1.9828, lr_0 = 7.3029e-04
Loss = 1.8015e-03, PNorm = 62.6167, GNorm = 1.0027, lr_0 = 7.2706e-04
Loss = 1.9167e-03, PNorm = 62.6839, GNorm = 1.4195, lr_0 = 7.2385e-04
Loss = 2.0361e-03, PNorm = 62.7376, GNorm = 0.5157, lr_0 = 7.2064e-04
Loss = 1.9994e-03, PNorm = 62.8053, GNorm = 0.6603, lr_0 = 7.1746e-04
Validation rmse logD = 0.670165
Validation R2 logD = 0.675275
Validation rmse logP = 0.710024
Validation R2 logP = 0.743791
Epoch 16
Train function
Loss = 1.6332e-03, PNorm = 62.8740, GNorm = 2.6328, lr_0 = 7.1397e-04
Loss = 1.6659e-03, PNorm = 62.9540, GNorm = 0.6951, lr_0 = 7.1081e-04
Loss = 1.4460e-03, PNorm = 63.0202, GNorm = 0.9424, lr_0 = 7.0766e-04
Loss = 1.6997e-03, PNorm = 63.0758, GNorm = 0.7872, lr_0 = 7.0453e-04
Loss = 1.3291e-03, PNorm = 63.1198, GNorm = 0.7181, lr_0 = 7.0142e-04
Loss = 1.5597e-03, PNorm = 63.1576, GNorm = 1.3587, lr_0 = 6.9831e-04
Validation rmse logD = 0.634655
Validation R2 logD = 0.708776
Validation rmse logP = 0.705001
Validation R2 logP = 0.747403
Epoch 17
Train function
Loss = 1.8567e-03, PNorm = 63.2103, GNorm = 2.0134, lr_0 = 6.9523e-04
Loss = 1.7335e-03, PNorm = 63.2721, GNorm = 1.6719, lr_0 = 6.9215e-04
Loss = 1.6096e-03, PNorm = 63.3425, GNorm = 2.2972, lr_0 = 6.8909e-04
Loss = 1.4913e-03, PNorm = 63.4147, GNorm = 1.5458, lr_0 = 6.8604e-04
Loss = 1.6257e-03, PNorm = 63.4622, GNorm = 0.6506, lr_0 = 6.8301e-04
Validation rmse logD = 0.612882
Validation R2 logD = 0.728415
Validation rmse logP = 0.732971
Validation R2 logP = 0.726963
Epoch 18
Train function
Loss = 1.3475e-03, PNorm = 63.5186, GNorm = 0.9941, lr_0 = 6.7968e-04
Loss = 1.3003e-03, PNorm = 63.5830, GNorm = 1.0579, lr_0 = 6.7668e-04
Loss = 1.3889e-03, PNorm = 63.6387, GNorm = 2.3979, lr_0 = 6.7368e-04
Loss = 1.5999e-03, PNorm = 63.6846, GNorm = 2.6382, lr_0 = 6.7070e-04
Loss = 1.4737e-03, PNorm = 63.7265, GNorm = 1.4101, lr_0 = 6.6774e-04
Validation rmse logD = 0.665626
Validation R2 logD = 0.679659
Validation rmse logP = 0.773065
Validation R2 logP = 0.696275
Epoch 19
Train function
Loss = 2.3893e-03, PNorm = 63.7748, GNorm = 2.5712, lr_0 = 6.6449e-04
Loss = 1.3876e-03, PNorm = 63.8393, GNorm = 0.9311, lr_0 = 6.6155e-04
Loss = 1.1391e-03, PNorm = 63.8958, GNorm = 2.0272, lr_0 = 6.5862e-04
Loss = 1.0414e-03, PNorm = 63.9431, GNorm = 1.0611, lr_0 = 6.5571e-04
Loss = 1.0472e-03, PNorm = 63.9717, GNorm = 1.1000, lr_0 = 6.5281e-04
Loss = 1.1331e-03, PNorm = 64.0060, GNorm = 0.4748, lr_0 = 6.4992e-04
Validation rmse logD = 0.637886
Validation R2 logD = 0.705804
Validation rmse logP = 0.706461
Validation R2 logP = 0.746356
Epoch 20
Train function
Loss = 1.4202e-03, PNorm = 64.0438, GNorm = 0.9535, lr_0 = 6.4676e-04
Loss = 1.6019e-03, PNorm = 64.1071, GNorm = 1.2996, lr_0 = 6.4390e-04
Loss = 1.0976e-03, PNorm = 64.1544, GNorm = 0.7019, lr_0 = 6.4105e-04
Loss = 9.2919e-04, PNorm = 64.1881, GNorm = 0.7954, lr_0 = 6.3822e-04
Loss = 1.1092e-03, PNorm = 64.2269, GNorm = 1.5667, lr_0 = 6.3539e-04
Validation rmse logD = 0.630223
Validation R2 logD = 0.712829
Validation rmse logP = 0.713834
Validation R2 logP = 0.741034
Epoch 21
Train function
Loss = 9.1532e-04, PNorm = 64.2692, GNorm = 1.1746, lr_0 = 6.3230e-04
Loss = 9.1479e-04, PNorm = 64.3038, GNorm = 0.6254, lr_0 = 6.2950e-04
Loss = 8.0326e-04, PNorm = 64.3429, GNorm = 0.5237, lr_0 = 6.2672e-04
Loss = 1.0438e-03, PNorm = 64.3787, GNorm = 1.8250, lr_0 = 6.2395e-04
Loss = 8.5957e-04, PNorm = 64.4030, GNorm = 1.2275, lr_0 = 6.2119e-04
Validation rmse logD = 0.670049
Validation R2 logD = 0.675388
Validation rmse logP = 0.698953
Validation R2 logP = 0.751719
Epoch 22
Train function
Loss = 1.9042e-03, PNorm = 64.4375, GNorm = 1.8893, lr_0 = 6.1817e-04
Loss = 1.0860e-03, PNorm = 64.4839, GNorm = 1.4151, lr_0 = 6.1543e-04
Loss = 8.5306e-04, PNorm = 64.5348, GNorm = 0.6630, lr_0 = 6.1271e-04
Loss = 9.4741e-04, PNorm = 64.5683, GNorm = 0.4464, lr_0 = 6.1000e-04
Loss = 8.9245e-04, PNorm = 64.6045, GNorm = 0.4116, lr_0 = 6.0730e-04
Loss = 8.5625e-04, PNorm = 64.6321, GNorm = 0.5554, lr_0 = 6.0461e-04
Validation rmse logD = 0.624843
Validation R2 logD = 0.717711
Validation rmse logP = 0.688181
Validation R2 logP = 0.759312
Epoch 23
Train function
Loss = 7.9852e-04, PNorm = 64.6691, GNorm = 0.4563, lr_0 = 6.0167e-04
Loss = 7.2774e-04, PNorm = 64.6960, GNorm = 0.8523, lr_0 = 5.9901e-04
Loss = 7.3848e-04, PNorm = 64.7229, GNorm = 0.6027, lr_0 = 5.9636e-04
Loss = 9.1390e-04, PNorm = 64.7374, GNorm = 0.8150, lr_0 = 5.9372e-04
Loss = 8.4741e-04, PNorm = 64.7710, GNorm = 1.7640, lr_0 = 5.9110e-04
Validation rmse logD = 0.616697
Validation R2 logD = 0.725024
Validation rmse logP = 0.701235
Validation R2 logP = 0.750095
Epoch 24
Train function
Loss = 8.0066e-04, PNorm = 64.8154, GNorm = 0.8557, lr_0 = 5.8822e-04
Loss = 6.2175e-04, PNorm = 64.8462, GNorm = 0.8803, lr_0 = 5.8562e-04
Loss = 7.5964e-04, PNorm = 64.8824, GNorm = 1.4945, lr_0 = 5.8303e-04
Loss = 7.1693e-04, PNorm = 64.9055, GNorm = 0.6888, lr_0 = 5.8045e-04
Loss = 6.0538e-04, PNorm = 64.9241, GNorm = 0.5473, lr_0 = 5.7788e-04
Validation rmse logD = 0.635450
Validation R2 logD = 0.708046
Validation rmse logP = 0.693758
Validation R2 logP = 0.755396
Epoch 25
Train function
Loss = 8.8369e-04, PNorm = 64.9428, GNorm = 1.1535, lr_0 = 5.7533e-04
Loss = 6.1859e-04, PNorm = 64.9737, GNorm = 1.2486, lr_0 = 5.7278e-04
Loss = 6.7278e-04, PNorm = 64.9977, GNorm = 1.6026, lr_0 = 5.7025e-04
Loss = 6.5735e-04, PNorm = 65.0239, GNorm = 1.1996, lr_0 = 5.6773e-04
Loss = 5.4845e-04, PNorm = 65.0517, GNorm = 0.7186, lr_0 = 5.6522e-04
Loss = 6.3911e-04, PNorm = 65.0700, GNorm = 0.4806, lr_0 = 5.6272e-04
Validation rmse logD = 0.619467
Validation R2 logD = 0.722548
Validation rmse logP = 0.698244
Validation R2 logP = 0.752222
Epoch 26
Train function
Loss = 6.8450e-04, PNorm = 65.0992, GNorm = 1.0252, lr_0 = 5.5998e-04
Loss = 7.6621e-04, PNorm = 65.1284, GNorm = 0.7551, lr_0 = 5.5750e-04
Loss = 6.7521e-04, PNorm = 65.1631, GNorm = 0.8672, lr_0 = 5.5503e-04
Loss = 5.7333e-04, PNorm = 65.1934, GNorm = 1.0087, lr_0 = 5.5258e-04
Loss = 4.9951e-04, PNorm = 65.2141, GNorm = 0.4374, lr_0 = 5.5014e-04
Validation rmse logD = 0.624241
Validation R2 logD = 0.718255
Validation rmse logP = 0.683647
Validation R2 logP = 0.762474
Epoch 27
Train function
Loss = 4.0673e-04, PNorm = 65.2315, GNorm = 0.7050, lr_0 = 5.4746e-04
Loss = 4.9655e-04, PNorm = 65.2549, GNorm = 0.6194, lr_0 = 5.4504e-04
Loss = 5.7829e-04, PNorm = 65.2764, GNorm = 0.3818, lr_0 = 5.4263e-04
Loss = 4.8499e-04, PNorm = 65.3009, GNorm = 0.5378, lr_0 = 5.4023e-04
Loss = 5.5432e-04, PNorm = 65.3232, GNorm = 0.4623, lr_0 = 5.3784e-04
Validation rmse logD = 0.627101
Validation R2 logD = 0.715667
Validation rmse logP = 0.697246
Validation R2 logP = 0.752930
Epoch 28
Train function
Loss = 4.3632e-04, PNorm = 65.3486, GNorm = 0.4131, lr_0 = 5.3522e-04
Loss = 4.2061e-04, PNorm = 65.3700, GNorm = 0.5144, lr_0 = 5.3285e-04
Loss = 4.6337e-04, PNorm = 65.3858, GNorm = 0.9733, lr_0 = 5.3050e-04
Loss = 4.4990e-04, PNorm = 65.4098, GNorm = 0.8493, lr_0 = 5.2815e-04
Loss = 4.7946e-04, PNorm = 65.4308, GNorm = 0.6688, lr_0 = 5.2581e-04
Loss = 4.4127e-04, PNorm = 65.4582, GNorm = 0.4772, lr_0 = 5.2349e-04
Loss = 2.8474e-03, PNorm = 65.4598, GNorm = 0.8775, lr_0 = 5.2326e-04
Validation rmse logD = 0.637535
Validation R2 logD = 0.706127
Validation rmse logP = 0.681437
Validation R2 logP = 0.764007
Epoch 29
Train function
Loss = 4.6321e-04, PNorm = 65.4801, GNorm = 1.0285, lr_0 = 5.2094e-04
Loss = 4.7977e-04, PNorm = 65.5045, GNorm = 0.6993, lr_0 = 5.1864e-04
Loss = 5.5790e-04, PNorm = 65.5275, GNorm = 0.4488, lr_0 = 5.1634e-04
Loss = 4.8219e-04, PNorm = 65.5491, GNorm = 0.5173, lr_0 = 5.1406e-04
Loss = 3.8045e-04, PNorm = 65.5646, GNorm = 0.3434, lr_0 = 5.1178e-04
Validation rmse logD = 0.616729
Validation R2 logD = 0.724995
Validation rmse logP = 0.673662
Validation R2 logP = 0.769361
Epoch 30
Train function
Loss = 3.4924e-04, PNorm = 65.5839, GNorm = 0.2526, lr_0 = 5.0930e-04
Loss = 3.0785e-04, PNorm = 65.6002, GNorm = 0.4016, lr_0 = 5.0704e-04
Loss = 3.5789e-04, PNorm = 65.6189, GNorm = 0.7283, lr_0 = 5.0480e-04
Loss = 4.2660e-04, PNorm = 65.6377, GNorm = 0.2441, lr_0 = 5.0257e-04
Loss = 3.9609e-04, PNorm = 65.6559, GNorm = 0.2795, lr_0 = 5.0034e-04
Validation rmse logD = 0.616394
Validation R2 logD = 0.725293
Validation rmse logP = 0.678473
Validation R2 logP = 0.766055
Epoch 31
Train function
Loss = 3.4708e-04, PNorm = 65.6713, GNorm = 0.4606, lr_0 = 4.9791e-04
Loss = 3.5963e-04, PNorm = 65.6935, GNorm = 0.3030, lr_0 = 4.9571e-04
Loss = 3.1526e-04, PNorm = 65.7131, GNorm = 0.2801, lr_0 = 4.9351e-04
Loss = 3.7132e-04, PNorm = 65.7248, GNorm = 0.4678, lr_0 = 4.9133e-04
Loss = 3.3357e-04, PNorm = 65.7412, GNorm = 0.4518, lr_0 = 4.8916e-04
Validation rmse logD = 0.624298
Validation R2 logD = 0.718203
Validation rmse logP = 0.689731
Validation R2 logP = 0.758227
Epoch 32
Train function
Loss = 3.2434e-04, PNorm = 65.7589, GNorm = 0.6424, lr_0 = 4.8678e-04
Loss = 3.7772e-04, PNorm = 65.7807, GNorm = 0.8665, lr_0 = 4.8463e-04
Loss = 3.6706e-04, PNorm = 65.7966, GNorm = 1.3434, lr_0 = 4.8248e-04
Loss = 2.7875e-04, PNorm = 65.8121, GNorm = 0.3668, lr_0 = 4.8035e-04
Loss = 3.2370e-04, PNorm = 65.8285, GNorm = 0.3646, lr_0 = 4.7822e-04
Loss = 3.5182e-04, PNorm = 65.8371, GNorm = 0.5337, lr_0 = 4.7611e-04
Validation rmse logD = 0.624496
Validation R2 logD = 0.718024
Validation rmse logP = 0.687417
Validation R2 logP = 0.759847
Epoch 33
Train function
Loss = 3.1098e-04, PNorm = 65.8563, GNorm = 0.7884, lr_0 = 4.7379e-04
Loss = 3.0624e-04, PNorm = 65.8775, GNorm = 0.7457, lr_0 = 4.7170e-04
Loss = 3.4497e-04, PNorm = 65.8939, GNorm = 0.4335, lr_0 = 4.6961e-04
Loss = 2.7632e-04, PNorm = 65.9057, GNorm = 0.3628, lr_0 = 4.6753e-04
Loss = 3.1919e-04, PNorm = 65.9153, GNorm = 0.8853, lr_0 = 4.6546e-04
Validation rmse logD = 0.631003
Validation R2 logD = 0.712118
Validation rmse logP = 0.697409
Validation R2 logP = 0.752814
Epoch 34
Train function
Loss = 3.2355e-04, PNorm = 65.9291, GNorm = 0.5130, lr_0 = 4.6341e-04
Loss = 3.2984e-04, PNorm = 65.9451, GNorm = 0.9901, lr_0 = 4.6136e-04
Loss = 2.7988e-04, PNorm = 65.9587, GNorm = 0.4032, lr_0 = 4.5931e-04
Loss = 2.5735e-04, PNorm = 65.9711, GNorm = 0.7428, lr_0 = 4.5728e-04
Loss = 2.5084e-04, PNorm = 65.9831, GNorm = 0.2746, lr_0 = 4.5526e-04
Validation rmse logD = 0.625339
Validation R2 logD = 0.717263
Validation rmse logP = 0.691720
Validation R2 logP = 0.756830
Epoch 35
Train function
Loss = 2.1105e-04, PNorm = 65.9982, GNorm = 0.3152, lr_0 = 4.5305e-04
Loss = 2.4430e-04, PNorm = 66.0126, GNorm = 0.3119, lr_0 = 4.5104e-04
Loss = 1.9864e-04, PNorm = 66.0250, GNorm = 0.3774, lr_0 = 4.4905e-04
Loss = 2.0576e-04, PNorm = 66.0348, GNorm = 0.1705, lr_0 = 4.4706e-04
Loss = 2.2058e-04, PNorm = 66.0462, GNorm = 0.2470, lr_0 = 4.4508e-04
Loss = 2.7510e-04, PNorm = 66.0578, GNorm = 0.7416, lr_0 = 4.4311e-04
Validation rmse logD = 0.632169
Validation R2 logD = 0.711053
Validation rmse logP = 0.679623
Validation R2 logP = 0.765261
Epoch 36
Train function
Loss = 3.1234e-04, PNorm = 66.0731, GNorm = 0.6168, lr_0 = 4.4096e-04
Loss = 3.0239e-04, PNorm = 66.0830, GNorm = 0.4177, lr_0 = 4.3901e-04
Loss = 2.3841e-04, PNorm = 66.0934, GNorm = 0.7458, lr_0 = 4.3707e-04
Loss = 3.1233e-04, PNorm = 66.1113, GNorm = 0.3871, lr_0 = 4.3513e-04
Loss = 2.5289e-04, PNorm = 66.1236, GNorm = 0.2040, lr_0 = 4.3321e-04
Validation rmse logD = 0.617795
Validation R2 logD = 0.724044
Validation rmse logP = 0.692023
Validation R2 logP = 0.756617
Epoch 37
Train function
Loss = 2.6109e-04, PNorm = 66.1451, GNorm = 0.3776, lr_0 = 4.3110e-04
Loss = 2.3158e-04, PNorm = 66.1603, GNorm = 0.3489, lr_0 = 4.2919e-04
Loss = 2.1048e-04, PNorm = 66.1685, GNorm = 0.3206, lr_0 = 4.2729e-04
Loss = 2.4059e-04, PNorm = 66.1823, GNorm = 0.6433, lr_0 = 4.2540e-04
Loss = 2.1308e-04, PNorm = 66.1951, GNorm = 0.6449, lr_0 = 4.2352e-04
Validation rmse logD = 0.621795
Validation R2 logD = 0.720458
Validation rmse logP = 0.694892
Validation R2 logP = 0.754595
Epoch 38
Train function
Loss = 2.0205e-04, PNorm = 66.2099, GNorm = 0.3141, lr_0 = 4.2146e-04
Loss = 1.7309e-04, PNorm = 66.2209, GNorm = 0.2152, lr_0 = 4.1960e-04
Loss = 1.8213e-04, PNorm = 66.2282, GNorm = 0.1638, lr_0 = 4.1774e-04
Loss = 2.0232e-04, PNorm = 66.2383, GNorm = 0.3617, lr_0 = 4.1589e-04
Loss = 2.0264e-04, PNorm = 66.2477, GNorm = 0.2399, lr_0 = 4.1406e-04
Loss = 1.8709e-04, PNorm = 66.2583, GNorm = 0.1728, lr_0 = 4.1222e-04
Validation rmse logD = 0.620095
Validation R2 logD = 0.721985
Validation rmse logP = 0.690625
Validation R2 logP = 0.757600
Epoch 39
Train function
Loss = 1.3747e-04, PNorm = 66.2666, GNorm = 0.1855, lr_0 = 4.1022e-04
Loss = 1.7112e-04, PNorm = 66.2770, GNorm = 0.5602, lr_0 = 4.0840e-04
Loss = 1.7142e-04, PNorm = 66.2841, GNorm = 0.3471, lr_0 = 4.0660e-04
Loss = 1.5632e-04, PNorm = 66.2914, GNorm = 0.2954, lr_0 = 4.0480e-04
Loss = 2.0620e-04, PNorm = 66.3018, GNorm = 0.7134, lr_0 = 4.0301e-04
Validation rmse logD = 0.630550
Validation R2 logD = 0.712531
Validation rmse logP = 0.676588
Validation R2 logP = 0.767353
Epoch 40
Train function
Loss = 2.7039e-04, PNorm = 66.3115, GNorm = 0.3083, lr_0 = 4.0105e-04
Loss = 2.5578e-04, PNorm = 66.3292, GNorm = 0.3854, lr_0 = 3.9927e-04
Loss = 2.2046e-04, PNorm = 66.3396, GNorm = 0.3500, lr_0 = 3.9751e-04
Loss = 2.2099e-04, PNorm = 66.3526, GNorm = 0.2138, lr_0 = 3.9575e-04
Loss = 1.6406e-04, PNorm = 66.3661, GNorm = 0.3349, lr_0 = 3.9400e-04
Validation rmse logD = 0.619399
Validation R2 logD = 0.722609
Validation rmse logP = 0.683740
Validation R2 logP = 0.762409
Epoch 41
Train function
Loss = 2.3718e-04, PNorm = 66.3776, GNorm = 1.0657, lr_0 = 3.9208e-04
Loss = 1.9576e-04, PNorm = 66.3887, GNorm = 0.3122, lr_0 = 3.9035e-04
Loss = 1.8725e-04, PNorm = 66.3985, GNorm = 0.3180, lr_0 = 3.8862e-04
Loss = 1.4393e-04, PNorm = 66.4081, GNorm = 0.2427, lr_0 = 3.8690e-04
Loss = 1.7909e-04, PNorm = 66.4188, GNorm = 0.3707, lr_0 = 3.8519e-04
Loss = 1.6644e-04, PNorm = 66.4269, GNorm = 0.2015, lr_0 = 3.8349e-04
Validation rmse logD = 0.616000
Validation R2 logD = 0.725644
Validation rmse logP = 0.675650
Validation R2 logP = 0.767998
Epoch 42
Train function
Loss = 1.5661e-04, PNorm = 66.4394, GNorm = 0.3563, lr_0 = 3.8179e-04
Loss = 1.2921e-04, PNorm = 66.4506, GNorm = 0.3699, lr_0 = 3.8010e-04
Loss = 1.5426e-04, PNorm = 66.4526, GNorm = 0.6634, lr_0 = 3.7842e-04
Loss = 1.6237e-04, PNorm = 66.4604, GNorm = 0.4583, lr_0 = 3.7675e-04
Loss = 1.6999e-04, PNorm = 66.4702, GNorm = 0.6743, lr_0 = 3.7508e-04
Validation rmse logD = 0.629514
Validation R2 logD = 0.713475
Validation rmse logP = 0.677082
Validation R2 logP = 0.767014
Epoch 43
Train function
Loss = 1.5423e-04, PNorm = 66.4824, GNorm = 0.5438, lr_0 = 3.7326e-04
Loss = 1.5356e-04, PNorm = 66.4928, GNorm = 0.3358, lr_0 = 3.7160e-04
Loss = 1.3436e-04, PNorm = 66.5005, GNorm = 0.4915, lr_0 = 3.6996e-04
Loss = 1.6661e-04, PNorm = 66.5065, GNorm = 0.8898, lr_0 = 3.6832e-04
Loss = 1.7837e-04, PNorm = 66.5193, GNorm = 0.7351, lr_0 = 3.6669e-04
Validation rmse logD = 0.617610
Validation R2 logD = 0.724209
Validation rmse logP = 0.679288
Validation R2 logP = 0.765493
Epoch 44
Train function
Loss = 1.1888e-04, PNorm = 66.5292, GNorm = 0.4543, lr_0 = 3.6491e-04
Loss = 1.2438e-04, PNorm = 66.5360, GNorm = 0.1388, lr_0 = 3.6330e-04
Loss = 1.4644e-04, PNorm = 66.5406, GNorm = 0.3106, lr_0 = 3.6169e-04
Loss = 1.2145e-04, PNorm = 66.5473, GNorm = 0.2383, lr_0 = 3.6009e-04
Loss = 1.3706e-04, PNorm = 66.5547, GNorm = 0.6014, lr_0 = 3.5850e-04
Loss = 1.5277e-04, PNorm = 66.5622, GNorm = 0.2943, lr_0 = 3.5691e-04
Loss = 2.2709e-03, PNorm = 66.5633, GNorm = 0.7560, lr_0 = 3.5675e-04
Validation rmse logD = 0.622217
Validation R2 logD = 0.720079
Validation rmse logP = 0.676916
Validation R2 logP = 0.767127
Epoch 45
Train function
Loss = 1.0866e-04, PNorm = 66.5715, GNorm = 0.1888, lr_0 = 3.5518e-04
Loss = 1.1552e-04, PNorm = 66.5802, GNorm = 0.2309, lr_0 = 3.5360e-04
Loss = 1.3862e-04, PNorm = 66.5881, GNorm = 0.3844, lr_0 = 3.5204e-04
Loss = 1.1456e-04, PNorm = 66.5968, GNorm = 0.5661, lr_0 = 3.5048e-04
Loss = 1.6145e-04, PNorm = 66.6035, GNorm = 0.6388, lr_0 = 3.4893e-04
Validation rmse logD = 0.624632
Validation R2 logD = 0.717902
Validation rmse logP = 0.687820
Validation R2 logP = 0.759565
Epoch 46
Train function
Loss = 1.1582e-04, PNorm = 66.6104, GNorm = 0.6156, lr_0 = 3.4724e-04
Loss = 9.8841e-05, PNorm = 66.6183, GNorm = 0.2756, lr_0 = 3.4570e-04
Loss = 1.0278e-04, PNorm = 66.6260, GNorm = 0.3046, lr_0 = 3.4417e-04
Loss = 1.1255e-04, PNorm = 66.6328, GNorm = 0.4663, lr_0 = 3.4265e-04
Loss = 1.3941e-04, PNorm = 66.6425, GNorm = 0.3205, lr_0 = 3.4113e-04
Validation rmse logD = 0.629606
Validation R2 logD = 0.713391
Validation rmse logP = 0.681280
Validation R2 logP = 0.764115
Epoch 47
Train function
Loss = 1.2863e-04, PNorm = 66.6516, GNorm = 0.5356, lr_0 = 3.3947e-04
Loss = 1.2119e-04, PNorm = 66.6566, GNorm = 0.6198, lr_0 = 3.3797e-04
Loss = 1.0619e-04, PNorm = 66.6666, GNorm = 0.2173, lr_0 = 3.3648e-04
Loss = 9.3448e-05, PNorm = 66.6746, GNorm = 0.1249, lr_0 = 3.3499e-04
Loss = 9.7207e-05, PNorm = 66.6799, GNorm = 0.4081, lr_0 = 3.3351e-04
Validation rmse logD = 0.622017
Validation R2 logD = 0.720259
Validation rmse logP = 0.676673
Validation R2 logP = 0.767295
Epoch 48
Train function
Loss = 1.0125e-04, PNorm = 66.6873, GNorm = 0.3084, lr_0 = 3.3188e-04
Loss = 8.0974e-05, PNorm = 66.6920, GNorm = 0.1423, lr_0 = 3.3042e-04
Loss = 9.8603e-05, PNorm = 66.6991, GNorm = 0.2788, lr_0 = 3.2895e-04
Loss = 1.0402e-04, PNorm = 66.7035, GNorm = 0.4272, lr_0 = 3.2750e-04
Loss = 9.5185e-05, PNorm = 66.7098, GNorm = 0.4184, lr_0 = 3.2605e-04
Loss = 1.0084e-04, PNorm = 66.7131, GNorm = 0.4365, lr_0 = 3.2461e-04
Validation rmse logD = 0.624250
Validation R2 logD = 0.718247
Validation rmse logP = 0.685038
Validation R2 logP = 0.761506
Epoch 49
Train function
Loss = 9.7969e-05, PNorm = 66.7213, GNorm = 0.2496, lr_0 = 3.2303e-04
Loss = 1.1564e-04, PNorm = 66.7287, GNorm = 0.3281, lr_0 = 3.2160e-04
Loss = 9.5960e-05, PNorm = 66.7328, GNorm = 0.1337, lr_0 = 3.2018e-04
Loss = 8.1364e-05, PNorm = 66.7396, GNorm = 0.1948, lr_0 = 3.1876e-04
Loss = 1.0190e-04, PNorm = 66.7466, GNorm = 0.6341, lr_0 = 3.1735e-04
Validation rmse logD = 0.623846
Validation R2 logD = 0.718611
Validation rmse logP = 0.682042
Validation R2 logP = 0.763588
Epoch 50
Train function
Loss = 6.4315e-05, PNorm = 66.7519, GNorm = 0.3354, lr_0 = 3.1595e-04
Loss = 9.8584e-05, PNorm = 66.7583, GNorm = 0.3410, lr_0 = 3.1455e-04
Loss = 8.2447e-05, PNorm = 66.7628, GNorm = 0.1943, lr_0 = 3.1316e-04
Loss = 6.0853e-05, PNorm = 66.7680, GNorm = 0.1423, lr_0 = 3.1177e-04
Loss = 8.1263e-05, PNorm = 66.7758, GNorm = 0.1960, lr_0 = 3.1039e-04
Validation rmse logD = 0.619895
Validation R2 logD = 0.722164
Validation rmse logP = 0.677769
Validation R2 logP = 0.766540
Epoch 51
Train function
Loss = 9.2330e-05, PNorm = 66.7822, GNorm = 0.4586, lr_0 = 3.0888e-04
Loss = 1.2362e-04, PNorm = 66.7902, GNorm = 0.4301, lr_0 = 3.0752e-04
Loss = 9.4735e-05, PNorm = 66.7989, GNorm = 0.4103, lr_0 = 3.0616e-04
Loss = 1.1542e-04, PNorm = 66.8040, GNorm = 0.5955, lr_0 = 3.0480e-04
Loss = 9.3177e-05, PNorm = 66.8084, GNorm = 0.2164, lr_0 = 3.0346e-04
Loss = 1.1165e-04, PNorm = 66.8165, GNorm = 0.1510, lr_0 = 3.0211e-04
Validation rmse logD = 0.626538
Validation R2 logD = 0.716177
Validation rmse logP = 0.685542
Validation R2 logP = 0.761155
Epoch 52
Train function
Loss = 9.3057e-05, PNorm = 66.8238, GNorm = 0.5957, lr_0 = 3.0064e-04
Loss = 1.2567e-04, PNorm = 66.8283, GNorm = 0.2568, lr_0 = 2.9931e-04
Loss = 6.4465e-05, PNorm = 66.8344, GNorm = 0.1328, lr_0 = 2.9799e-04
Loss = 8.3942e-05, PNorm = 66.8409, GNorm = 0.4417, lr_0 = 2.9667e-04
Loss = 8.2036e-05, PNorm = 66.8477, GNorm = 0.6905, lr_0 = 2.9536e-04
Validation rmse logD = 0.622124
Validation R2 logD = 0.720163
Validation rmse logP = 0.684810
Validation R2 logP = 0.761665
Epoch 53
Train function
Loss = 1.0634e-04, PNorm = 66.8519, GNorm = 0.5806, lr_0 = 2.9392e-04
Loss = 6.2434e-05, PNorm = 66.8579, GNorm = 0.2742, lr_0 = 2.9262e-04
Loss = 8.9162e-05, PNorm = 66.8641, GNorm = 0.1787, lr_0 = 2.9133e-04
Loss = 8.0393e-05, PNorm = 66.8683, GNorm = 0.2459, lr_0 = 2.9004e-04
Loss = 6.9453e-05, PNorm = 66.8717, GNorm = 0.1470, lr_0 = 2.8876e-04
Validation rmse logD = 0.631093
Validation R2 logD = 0.712036
Validation rmse logP = 0.683156
Validation R2 logP = 0.762814
Epoch 54
Train function
Loss = 1.1564e-04, PNorm = 66.8785, GNorm = 0.7304, lr_0 = 2.8735e-04
Loss = 7.9277e-05, PNorm = 66.8812, GNorm = 0.2352, lr_0 = 2.8608e-04
Loss = 7.8563e-05, PNorm = 66.8845, GNorm = 0.3466, lr_0 = 2.8482e-04
Loss = 6.5901e-05, PNorm = 66.8896, GNorm = 0.1278, lr_0 = 2.8356e-04
Loss = 7.1422e-05, PNorm = 66.8947, GNorm = 0.3776, lr_0 = 2.8230e-04
Loss = 8.6015e-05, PNorm = 66.9010, GNorm = 0.1691, lr_0 = 2.8105e-04
Validation rmse logD = 0.619617
Validation R2 logD = 0.722414
Validation rmse logP = 0.680685
Validation R2 logP = 0.764528
Epoch 55
Train function
Loss = 7.1844e-05, PNorm = 66.9064, GNorm = 0.4096, lr_0 = 2.7969e-04
Loss = 9.4347e-05, PNorm = 66.9109, GNorm = 0.2411, lr_0 = 2.7845e-04
Loss = 1.1156e-04, PNorm = 66.9179, GNorm = 0.7675, lr_0 = 2.7722e-04
Loss = 1.0333e-04, PNorm = 66.9215, GNorm = 0.4941, lr_0 = 2.7599e-04
Loss = 8.5548e-05, PNorm = 66.9284, GNorm = 0.1024, lr_0 = 2.7477e-04
Validation rmse logD = 0.622828
Validation R2 logD = 0.719529
Validation rmse logP = 0.679388
Validation R2 logP = 0.765424
Epoch 56
Train function
Loss = 6.5249e-05, PNorm = 66.9350, GNorm = 0.3500, lr_0 = 2.7343e-04
Loss = 7.7610e-05, PNorm = 66.9403, GNorm = 0.4072, lr_0 = 2.7222e-04
Loss = 6.7655e-05, PNorm = 66.9455, GNorm = 0.2375, lr_0 = 2.7102e-04
Loss = 5.3897e-05, PNorm = 66.9520, GNorm = 0.2687, lr_0 = 2.6982e-04
Loss = 5.6777e-05, PNorm = 66.9556, GNorm = 0.1543, lr_0 = 2.6863e-04
Validation rmse logD = 0.623190
Validation R2 logD = 0.719203
Validation rmse logP = 0.683297
Validation R2 logP = 0.762717
Epoch 57
Train function
Loss = 3.3660e-05, PNorm = 66.9577, GNorm = 0.1413, lr_0 = 2.6732e-04
Loss = 6.9764e-05, PNorm = 66.9629, GNorm = 0.3327, lr_0 = 2.6614e-04
Loss = 4.9766e-05, PNorm = 66.9667, GNorm = 0.1184, lr_0 = 2.6496e-04
Loss = 4.6081e-05, PNorm = 66.9701, GNorm = 0.0999, lr_0 = 2.6379e-04
Loss = 4.6059e-05, PNorm = 66.9733, GNorm = 0.3196, lr_0 = 2.6262e-04
Loss = 6.0013e-05, PNorm = 66.9763, GNorm = 0.1226, lr_0 = 2.6146e-04
Loss = 4.8427e-04, PNorm = 66.9763, GNorm = 0.6017, lr_0 = 2.6134e-04
Validation rmse logD = 0.625626
Validation R2 logD = 0.717003
Validation rmse logP = 0.684317
Validation R2 logP = 0.762008
Epoch 58
Train function
Loss = 6.0493e-05, PNorm = 66.9819, GNorm = 0.2266, lr_0 = 2.6019e-04
Loss = 5.8654e-05, PNorm = 66.9851, GNorm = 0.3717, lr_0 = 2.5904e-04
Loss = 4.9693e-05, PNorm = 66.9890, GNorm = 0.1975, lr_0 = 2.5789e-04
Loss = 5.6537e-05, PNorm = 66.9915, GNorm = 0.2137, lr_0 = 2.5675e-04
Loss = 4.2178e-05, PNorm = 66.9950, GNorm = 0.1180, lr_0 = 2.5561e-04
Validation rmse logD = 0.625950
Validation R2 logD = 0.716710
Validation rmse logP = 0.685620
Validation R2 logP = 0.761100
Epoch 59
Train function
Loss = 4.2418e-05, PNorm = 66.9970, GNorm = 0.1659, lr_0 = 2.5448e-04
Loss = 4.3425e-05, PNorm = 67.0003, GNorm = 0.1938, lr_0 = 2.5336e-04
Loss = 4.2338e-05, PNorm = 67.0036, GNorm = 0.1844, lr_0 = 2.5224e-04
Loss = 3.6507e-05, PNorm = 67.0072, GNorm = 0.1834, lr_0 = 2.5112e-04
Loss = 5.3496e-05, PNorm = 67.0114, GNorm = 0.1739, lr_0 = 2.5001e-04
Validation rmse logD = 0.625576
Validation R2 logD = 0.717048
Validation rmse logP = 0.679139
Validation R2 logP = 0.765596
Epoch 60
Train function
Loss = 4.7078e-05, PNorm = 67.0167, GNorm = 0.1617, lr_0 = 2.4879e-04
Loss = 4.7676e-05, PNorm = 67.0194, GNorm = 0.1078, lr_0 = 2.4769e-04
Loss = 5.7017e-05, PNorm = 67.0223, GNorm = 0.1568, lr_0 = 2.4660e-04
Loss = 4.3474e-05, PNorm = 67.0274, GNorm = 0.1087, lr_0 = 2.4551e-04
Loss = 3.6921e-05, PNorm = 67.0336, GNorm = 0.1949, lr_0 = 2.4442e-04
Loss = 4.0715e-05, PNorm = 67.0364, GNorm = 0.4200, lr_0 = 2.4334e-04
Loss = 7.6701e-05, PNorm = 67.0366, GNorm = 0.1756, lr_0 = 2.4323e-04
Validation rmse logD = 0.623677
Validation R2 logD = 0.718764
Validation rmse logP = 0.686326
Validation R2 logP = 0.760608
Epoch 61
Train function
Loss = 4.3007e-05, PNorm = 67.0393, GNorm = 0.2329, lr_0 = 2.4216e-04
Loss = 4.1954e-05, PNorm = 67.0420, GNorm = 0.1546, lr_0 = 2.4109e-04
Loss = 3.5100e-05, PNorm = 67.0444, GNorm = 0.1603, lr_0 = 2.4002e-04
Loss = 3.9833e-05, PNorm = 67.0478, GNorm = 0.3021, lr_0 = 2.3896e-04
Loss = 4.5092e-05, PNorm = 67.0502, GNorm = 0.1887, lr_0 = 2.3790e-04
Validation rmse logD = 0.625251
Validation R2 logD = 0.717343
Validation rmse logP = 0.684164
Validation R2 logP = 0.762114
Epoch 62
Train function
Loss = 4.7245e-05, PNorm = 67.0544, GNorm = 0.3969, lr_0 = 2.3674e-04
Loss = 4.5286e-05, PNorm = 67.0567, GNorm = 0.0939, lr_0 = 2.3570e-04
Loss = 4.1449e-05, PNorm = 67.0605, GNorm = 0.2269, lr_0 = 2.3465e-04
Loss = 4.9538e-05, PNorm = 67.0627, GNorm = 0.3264, lr_0 = 2.3362e-04
Loss = 4.5881e-05, PNorm = 67.0657, GNorm = 0.2988, lr_0 = 2.3258e-04
Validation rmse logD = 0.620169
Validation R2 logD = 0.721919
Validation rmse logP = 0.686013
Validation R2 logP = 0.760827
Epoch 63
Train function
Loss = 3.8152e-05, PNorm = 67.0694, GNorm = 0.1841, lr_0 = 2.3145e-04
Loss = 4.9279e-05, PNorm = 67.0718, GNorm = 0.2084, lr_0 = 2.3043e-04
Loss = 4.3910e-05, PNorm = 67.0750, GNorm = 0.1223, lr_0 = 2.2941e-04
Loss = 3.3011e-05, PNorm = 67.0768, GNorm = 0.1132, lr_0 = 2.2839e-04
Loss = 4.0597e-05, PNorm = 67.0810, GNorm = 0.2221, lr_0 = 2.2738e-04
Validation rmse logD = 0.624635
Validation R2 logD = 0.717899
Validation rmse logP = 0.687613
Validation R2 logP = 0.759709
Epoch 64
Train function
Loss = 7.8821e-05, PNorm = 67.0848, GNorm = 0.6757, lr_0 = 2.2628e-04
Loss = 5.7833e-05, PNorm = 67.0880, GNorm = 0.5034, lr_0 = 2.2528e-04
Loss = 5.5964e-05, PNorm = 67.0908, GNorm = 0.0936, lr_0 = 2.2428e-04
Loss = 5.5099e-05, PNorm = 67.0952, GNorm = 0.2840, lr_0 = 2.2329e-04
Loss = 4.1300e-05, PNorm = 67.0991, GNorm = 0.2243, lr_0 = 2.2230e-04
Loss = 4.6740e-05, PNorm = 67.1029, GNorm = 0.1514, lr_0 = 2.2132e-04
Validation rmse logD = 0.623553
Validation R2 logD = 0.718876
Validation rmse logP = 0.680753
Validation R2 logP = 0.764481
Epoch 65
Train function
Loss = 4.8777e-05, PNorm = 67.1067, GNorm = 0.2057, lr_0 = 2.2024e-04
Loss = 4.7674e-05, PNorm = 67.1105, GNorm = 0.2388, lr_0 = 2.1927e-04
Loss = 4.4593e-05, PNorm = 67.1132, GNorm = 0.1789, lr_0 = 2.1830e-04
Loss = 3.6180e-05, PNorm = 67.1161, GNorm = 0.1236, lr_0 = 2.1733e-04
Loss = 6.7751e-05, PNorm = 67.1172, GNorm = 0.2968, lr_0 = 2.1637e-04
Validation rmse logD = 0.624100
Validation R2 logD = 0.718382
Validation rmse logP = 0.686078
Validation R2 logP = 0.760781
Epoch 66
Train function
Loss = 3.4003e-05, PNorm = 67.1210, GNorm = 0.1485, lr_0 = 2.1532e-04
Loss = 4.0451e-05, PNorm = 67.1234, GNorm = 0.1793, lr_0 = 2.1436e-04
Loss = 3.8454e-05, PNorm = 67.1268, GNorm = 0.2241, lr_0 = 2.1342e-04
Loss = 5.1297e-05, PNorm = 67.1311, GNorm = 0.2264, lr_0 = 2.1247e-04
Loss = 4.2639e-05, PNorm = 67.1342, GNorm = 0.3525, lr_0 = 2.1153e-04
Validation rmse logD = 0.619531
Validation R2 logD = 0.722490
Validation rmse logP = 0.688315
Validation R2 logP = 0.759219
Epoch 67
Train function
Loss = 2.2702e-05, PNorm = 67.1371, GNorm = 0.1207, lr_0 = 2.1060e-04
Loss = 3.8087e-05, PNorm = 67.1417, GNorm = 0.5358, lr_0 = 2.0966e-04
Loss = 3.6845e-05, PNorm = 67.1426, GNorm = 0.1155, lr_0 = 2.0874e-04
Loss = 3.5595e-05, PNorm = 67.1456, GNorm = 0.1052, lr_0 = 2.0781e-04
Loss = 4.1481e-05, PNorm = 67.1489, GNorm = 0.2977, lr_0 = 2.0689e-04
Loss = 4.5750e-05, PNorm = 67.1514, GNorm = 0.4270, lr_0 = 2.0598e-04
Validation rmse logD = 0.623609
Validation R2 logD = 0.718825
Validation rmse logP = 0.687108
Validation R2 logP = 0.760063
Epoch 68
Train function
Loss = 3.1900e-05, PNorm = 67.1558, GNorm = 0.1035, lr_0 = 2.0498e-04
Loss = 2.9844e-05, PNorm = 67.1571, GNorm = 0.3220, lr_0 = 2.0407e-04
Loss = 2.8539e-05, PNorm = 67.1585, GNorm = 0.2101, lr_0 = 2.0317e-04
Loss = 2.4005e-05, PNorm = 67.1608, GNorm = 0.1930, lr_0 = 2.0227e-04
Loss = 3.3896e-05, PNorm = 67.1641, GNorm = 0.2372, lr_0 = 2.0137e-04
Validation rmse logD = 0.624767
Validation R2 logD = 0.717779
Validation rmse logP = 0.683259
Validation R2 logP = 0.762743
Epoch 69
Train function
Loss = 4.2616e-05, PNorm = 67.1681, GNorm = 0.1380, lr_0 = 2.0039e-04
Loss = 4.1589e-05, PNorm = 67.1707, GNorm = 0.1107, lr_0 = 1.9951e-04
Loss = 3.8290e-05, PNorm = 67.1735, GNorm = 0.2893, lr_0 = 1.9863e-04
Loss = 4.3703e-05, PNorm = 67.1757, GNorm = 0.3335, lr_0 = 1.9775e-04
Loss = 3.6567e-05, PNorm = 67.1775, GNorm = 0.1410, lr_0 = 1.9687e-04
Validation rmse logD = 0.623016
Validation R2 logD = 0.719360
Validation rmse logP = 0.682061
Validation R2 logP = 0.763574
Epoch 70
Train function
Loss = 2.7271e-05, PNorm = 67.1828, GNorm = 0.1534, lr_0 = 1.9592e-04
Loss = 2.8545e-05, PNorm = 67.1856, GNorm = 0.2139, lr_0 = 1.9505e-04
Loss = 2.9875e-05, PNorm = 67.1864, GNorm = 0.0910, lr_0 = 1.9419e-04
Loss = 3.8268e-05, PNorm = 67.1891, GNorm = 0.2932, lr_0 = 1.9333e-04
Loss = 3.3441e-05, PNorm = 67.1920, GNorm = 0.0981, lr_0 = 1.9247e-04
Loss = 3.6690e-05, PNorm = 67.1960, GNorm = 0.1179, lr_0 = 1.9162e-04
Validation rmse logD = 0.621737
Validation R2 logD = 0.720511
Validation rmse logP = 0.681429
Validation R2 logP = 0.764013
Epoch 71
Train function
Loss = 3.0886e-05, PNorm = 67.1969, GNorm = 0.3528, lr_0 = 1.9069e-04
Loss = 3.3697e-05, PNorm = 67.2005, GNorm = 0.1264, lr_0 = 1.8984e-04
Loss = 2.3984e-05, PNorm = 67.2029, GNorm = 0.0603, lr_0 = 1.8900e-04
Loss = 2.3990e-05, PNorm = 67.2043, GNorm = 0.1275, lr_0 = 1.8817e-04
Loss = 2.3878e-05, PNorm = 67.2069, GNorm = 0.2025, lr_0 = 1.8734e-04
Validation rmse logD = 0.623854
Validation R2 logD = 0.718604
Validation rmse logP = 0.686207
Validation R2 logP = 0.760691
Epoch 72
Train function
Loss = 4.3513e-05, PNorm = 67.2091, GNorm = 0.2341, lr_0 = 1.8643e-04
Loss = 4.9802e-05, PNorm = 67.2117, GNorm = 0.1127, lr_0 = 1.8560e-04
Loss = 8.1602e-05, PNorm = 67.2130, GNorm = 0.5057, lr_0 = 1.8478e-04
Loss = 4.5858e-05, PNorm = 67.2178, GNorm = 0.2465, lr_0 = 1.8396e-04
Loss = 3.9585e-05, PNorm = 67.2215, GNorm = 0.1210, lr_0 = 1.8315e-04
Validation rmse logD = 0.626357
Validation R2 logD = 0.716342
Validation rmse logP = 0.680406
Validation R2 logP = 0.764720
Epoch 73
Train function
Loss = 5.3899e-05, PNorm = 67.2243, GNorm = 0.3235, lr_0 = 1.8226e-04
Loss = 5.0478e-05, PNorm = 67.2264, GNorm = 0.3806, lr_0 = 1.8145e-04
Loss = 4.2157e-05, PNorm = 67.2293, GNorm = 0.2056, lr_0 = 1.8065e-04
Loss = 2.7966e-05, PNorm = 67.2325, GNorm = 0.0702, lr_0 = 1.7985e-04
Loss = 4.2004e-05, PNorm = 67.2350, GNorm = 0.1840, lr_0 = 1.7905e-04
Loss = 4.0722e-05, PNorm = 67.2383, GNorm = 0.2210, lr_0 = 1.7826e-04
Loss = 4.9893e-04, PNorm = 67.2378, GNorm = 0.5965, lr_0 = 1.7818e-04
Validation rmse logD = 0.626248
Validation R2 logD = 0.716440
Validation rmse logP = 0.683649
Validation R2 logP = 0.762472
Epoch 74
Train function
Loss = 5.7371e-05, PNorm = 67.2393, GNorm = 0.1459, lr_0 = 1.7739e-04
Loss = 4.0793e-05, PNorm = 67.2414, GNorm = 0.1884, lr_0 = 1.7661e-04
Loss = 6.3206e-05, PNorm = 67.2447, GNorm = 0.1108, lr_0 = 1.7583e-04
Loss = 4.7428e-05, PNorm = 67.2488, GNorm = 0.4033, lr_0 = 1.7505e-04
Loss = 3.5343e-05, PNorm = 67.2531, GNorm = 0.1017, lr_0 = 1.7428e-04
Validation rmse logD = 0.622378
Validation R2 logD = 0.719934
Validation rmse logP = 0.686362
Validation R2 logP = 0.760583
Epoch 75
Train function
Loss = 4.1500e-05, PNorm = 67.2565, GNorm = 0.1774, lr_0 = 1.7351e-04
Loss = 3.9203e-05, PNorm = 67.2584, GNorm = 0.1590, lr_0 = 1.7274e-04
Loss = 4.2897e-05, PNorm = 67.2599, GNorm = 0.0790, lr_0 = 1.7197e-04
Loss = 3.3531e-05, PNorm = 67.2618, GNorm = 0.0693, lr_0 = 1.7121e-04
Loss = 2.6233e-05, PNorm = 67.2637, GNorm = 0.1149, lr_0 = 1.7046e-04
Validation rmse logD = 0.625069
Validation R2 logD = 0.717507
Validation rmse logP = 0.682510
Validation R2 logP = 0.763263
Epoch 76
Train function
Loss = 2.6584e-05, PNorm = 67.2658, GNorm = 0.1706, lr_0 = 1.6963e-04
Loss = 2.5722e-05, PNorm = 67.2677, GNorm = 0.0795, lr_0 = 1.6888e-04
Loss = 1.9122e-05, PNorm = 67.2705, GNorm = 0.1590, lr_0 = 1.6813e-04
Loss = 2.3042e-05, PNorm = 67.2718, GNorm = 0.1942, lr_0 = 1.6739e-04
Loss = 2.4898e-05, PNorm = 67.2741, GNorm = 0.1741, lr_0 = 1.6665e-04
Loss = 2.2437e-05, PNorm = 67.2766, GNorm = 0.0667, lr_0 = 1.6591e-04
Loss = 1.2529e-04, PNorm = 67.2766, GNorm = 0.3669, lr_0 = 1.6584e-04
Validation rmse logD = 0.622465
Validation R2 logD = 0.719856
Validation rmse logP = 0.681393
Validation R2 logP = 0.764037
Epoch 77
Train function
Loss = 2.1014e-05, PNorm = 67.2794, GNorm = 0.0614, lr_0 = 1.6510e-04
Loss = 1.7505e-05, PNorm = 67.2803, GNorm = 0.0688, lr_0 = 1.6437e-04
Loss = 2.7159e-05, PNorm = 67.2814, GNorm = 0.4688, lr_0 = 1.6364e-04
Loss = 2.2067e-05, PNorm = 67.2823, GNorm = 0.1501, lr_0 = 1.6292e-04
Loss = 2.1890e-05, PNorm = 67.2843, GNorm = 0.0971, lr_0 = 1.6220e-04
Validation rmse logD = 0.624494
Validation R2 logD = 0.718026
Validation rmse logP = 0.685370
Validation R2 logP = 0.761275
Epoch 78
Train function
Loss = 1.4596e-05, PNorm = 67.2864, GNorm = 0.1525, lr_0 = 1.6141e-04
Loss = 1.5462e-05, PNorm = 67.2882, GNorm = 0.1237, lr_0 = 1.6070e-04
Loss = 1.6116e-05, PNorm = 67.2895, GNorm = 0.0876, lr_0 = 1.5999e-04
Loss = 1.5104e-05, PNorm = 67.2905, GNorm = 0.0806, lr_0 = 1.5928e-04
Loss = 1.8550e-05, PNorm = 67.2920, GNorm = 0.1334, lr_0 = 1.5857e-04
Validation rmse logD = 0.623511
Validation R2 logD = 0.718914
Validation rmse logP = 0.683182
Validation R2 logP = 0.762796
Epoch 79
Train function
Loss = 1.3711e-05, PNorm = 67.2939, GNorm = 0.0612, lr_0 = 1.5780e-04
Loss = 1.0891e-05, PNorm = 67.2960, GNorm = 0.0682, lr_0 = 1.5710e-04
Loss = 1.4077e-05, PNorm = 67.2970, GNorm = 0.1984, lr_0 = 1.5641e-04
Loss = 1.6293e-05, PNorm = 67.2974, GNorm = 0.1009, lr_0 = 1.5572e-04
Loss = 1.6545e-05, PNorm = 67.2995, GNorm = 0.0821, lr_0 = 1.5503e-04
Validation rmse logD = 0.623704
Validation R2 logD = 0.718740
Validation rmse logP = 0.685877
Validation R2 logP = 0.760922
Epoch 80
Train function
Loss = 2.1747e-05, PNorm = 67.3012, GNorm = 0.2558, lr_0 = 1.5427e-04
Loss = 1.6785e-05, PNorm = 67.3031, GNorm = 0.0909, lr_0 = 1.5359e-04
Loss = 1.0761e-05, PNorm = 67.3043, GNorm = 0.0889, lr_0 = 1.5291e-04
Loss = 1.0574e-05, PNorm = 67.3052, GNorm = 0.0964, lr_0 = 1.5224e-04
Loss = 9.8833e-06, PNorm = 67.3062, GNorm = 0.0486, lr_0 = 1.5156e-04
Loss = 1.2587e-05, PNorm = 67.3082, GNorm = 0.0949, lr_0 = 1.5089e-04
Validation rmse logD = 0.624355
Validation R2 logD = 0.718152
Validation rmse logP = 0.685293
Validation R2 logP = 0.761328
Epoch 81
Train function
Loss = 8.3767e-06, PNorm = 67.3090, GNorm = 0.0912, lr_0 = 1.5016e-04
Loss = 1.1560e-05, PNorm = 67.3106, GNorm = 0.0551, lr_0 = 1.4949e-04
Loss = 1.3599e-05, PNorm = 67.3117, GNorm = 0.0876, lr_0 = 1.4883e-04
Loss = 1.0765e-05, PNorm = 67.3137, GNorm = 0.1032, lr_0 = 1.4817e-04
Loss = 1.6159e-05, PNorm = 67.3146, GNorm = 0.0785, lr_0 = 1.4752e-04
Validation rmse logD = 0.623005
Validation R2 logD = 0.719370
Validation rmse logP = 0.683917
Validation R2 logP = 0.762286
Epoch 82
Train function
Loss = 1.1171e-05, PNorm = 67.3169, GNorm = 0.0555, lr_0 = 1.4680e-04
Loss = 1.4233e-05, PNorm = 67.3173, GNorm = 0.0503, lr_0 = 1.4615e-04
Loss = 1.2932e-05, PNorm = 67.3187, GNorm = 0.2774, lr_0 = 1.4551e-04
Loss = 1.3764e-05, PNorm = 67.3196, GNorm = 0.0662, lr_0 = 1.4486e-04
Loss = 1.5048e-05, PNorm = 67.3210, GNorm = 0.1390, lr_0 = 1.4422e-04
Validation rmse logD = 0.623859
Validation R2 logD = 0.718599
Validation rmse logP = 0.685339
Validation R2 logP = 0.761296
Epoch 83
Train function
Loss = 1.0804e-05, PNorm = 67.3225, GNorm = 0.1378, lr_0 = 1.4352e-04
Loss = 1.0904e-05, PNorm = 67.3233, GNorm = 0.1437, lr_0 = 1.4288e-04
Loss = 1.1117e-05, PNorm = 67.3242, GNorm = 0.0671, lr_0 = 1.4225e-04
Loss = 1.0800e-05, PNorm = 67.3250, GNorm = 0.0560, lr_0 = 1.4162e-04
Loss = 1.4130e-05, PNorm = 67.3265, GNorm = 0.1732, lr_0 = 1.4100e-04
Loss = 1.2290e-05, PNorm = 67.3277, GNorm = 0.0676, lr_0 = 1.4037e-04
Validation rmse logD = 0.624306
Validation R2 logD = 0.718196
Validation rmse logP = 0.683231
Validation R2 logP = 0.762762
Epoch 84
Train function
Loss = 1.9418e-05, PNorm = 67.3294, GNorm = 0.3835, lr_0 = 1.3975e-04
Loss = 1.6029e-05, PNorm = 67.3308, GNorm = 0.1706, lr_0 = 1.3913e-04
Loss = 1.6497e-05, PNorm = 67.3310, GNorm = 0.0715, lr_0 = 1.3852e-04
Loss = 1.7146e-05, PNorm = 67.3330, GNorm = 0.2497, lr_0 = 1.3791e-04
Loss = 1.3420e-05, PNorm = 67.3344, GNorm = 0.0934, lr_0 = 1.3730e-04
Validation rmse logD = 0.624281
Validation R2 logD = 0.718219
Validation rmse logP = 0.684446
Validation R2 logP = 0.761918
Epoch 85
Train function
Loss = 1.1604e-05, PNorm = 67.3358, GNorm = 0.2220, lr_0 = 1.3663e-04
Loss = 1.1820e-05, PNorm = 67.3369, GNorm = 0.0605, lr_0 = 1.3602e-04
Loss = 1.2223e-05, PNorm = 67.3382, GNorm = 0.0585, lr_0 = 1.3542e-04
Loss = 9.7380e-06, PNorm = 67.3392, GNorm = 0.0667, lr_0 = 1.3482e-04
Loss = 1.2446e-05, PNorm = 67.3401, GNorm = 0.1387, lr_0 = 1.3423e-04
Validation rmse logD = 0.624381
Validation R2 logD = 0.718128
Validation rmse logP = 0.680751
Validation R2 logP = 0.764481
Epoch 86
Train function
Loss = 7.2378e-06, PNorm = 67.3412, GNorm = 0.1169, lr_0 = 1.3357e-04
Loss = 8.9794e-06, PNorm = 67.3426, GNorm = 0.0991, lr_0 = 1.3298e-04
Loss = 8.4154e-06, PNorm = 67.3438, GNorm = 0.0460, lr_0 = 1.3239e-04
Loss = 1.1649e-05, PNorm = 67.3452, GNorm = 0.1035, lr_0 = 1.3181e-04
Loss = 1.3095e-05, PNorm = 67.3460, GNorm = 0.1276, lr_0 = 1.3123e-04
Loss = 1.4725e-05, PNorm = 67.3471, GNorm = 0.0971, lr_0 = 1.3065e-04
Validation rmse logD = 0.625366
Validation R2 logD = 0.717238
Validation rmse logP = 0.683334
Validation R2 logP = 0.762691
Epoch 87
Train function
Loss = 1.2061e-05, PNorm = 67.3477, GNorm = 0.1050, lr_0 = 1.3001e-04
Loss = 1.0005e-05, PNorm = 67.3493, GNorm = 0.1341, lr_0 = 1.2944e-04
Loss = 1.0458e-05, PNorm = 67.3501, GNorm = 0.1416, lr_0 = 1.2886e-04
Loss = 1.2646e-05, PNorm = 67.3513, GNorm = 0.1551, lr_0 = 1.2829e-04
Loss = 1.1276e-05, PNorm = 67.3523, GNorm = 0.1895, lr_0 = 1.2773e-04
Validation rmse logD = 0.623327
Validation R2 logD = 0.719079
Validation rmse logP = 0.681075
Validation R2 logP = 0.764257
Epoch 88
Train function
Loss = 8.4499e-06, PNorm = 67.3530, GNorm = 0.0817, lr_0 = 1.2710e-04
Loss = 1.0586e-05, PNorm = 67.3537, GNorm = 0.0710, lr_0 = 1.2654e-04
Loss = 9.5758e-06, PNorm = 67.3548, GNorm = 0.1577, lr_0 = 1.2598e-04
Loss = 7.0678e-06, PNorm = 67.3556, GNorm = 0.0914, lr_0 = 1.2542e-04
Loss = 9.2078e-06, PNorm = 67.3566, GNorm = 0.0669, lr_0 = 1.2487e-04
Validation rmse logD = 0.624136
Validation R2 logD = 0.718349
Validation rmse logP = 0.682697
Validation R2 logP = 0.763133
Epoch 89
Train function
Loss = 1.2017e-05, PNorm = 67.3578, GNorm = 0.1037, lr_0 = 1.2426e-04
Loss = 1.4180e-05, PNorm = 67.3600, GNorm = 0.1335, lr_0 = 1.2371e-04
Loss = 1.4679e-05, PNorm = 67.3606, GNorm = 0.0646, lr_0 = 1.2317e-04
Loss = 1.1256e-05, PNorm = 67.3626, GNorm = 0.1518, lr_0 = 1.2262e-04
Loss = 7.7686e-06, PNorm = 67.3631, GNorm = 0.0562, lr_0 = 1.2208e-04
Loss = 1.0724e-05, PNorm = 67.3641, GNorm = 0.0629, lr_0 = 1.2154e-04
Loss = 2.4875e-05, PNorm = 67.3641, GNorm = 0.1566, lr_0 = 1.2148e-04
Validation rmse logD = 0.624128
Validation R2 logD = 0.718357
Validation rmse logP = 0.683290
Validation R2 logP = 0.762721
Epoch 90
Train function
Loss = 1.0336e-05, PNorm = 67.3654, GNorm = 0.0871, lr_0 = 1.2095e-04
Loss = 9.2467e-06, PNorm = 67.3656, GNorm = 0.0391, lr_0 = 1.2041e-04
Loss = 8.4320e-06, PNorm = 67.3667, GNorm = 0.1577, lr_0 = 1.1988e-04
Loss = 9.6050e-06, PNorm = 67.3675, GNorm = 0.0785, lr_0 = 1.1935e-04
Loss = 6.7522e-06, PNorm = 67.3679, GNorm = 0.0461, lr_0 = 1.1882e-04
Validation rmse logD = 0.625225
Validation R2 logD = 0.717366
Validation rmse logP = 0.684029
Validation R2 logP = 0.762208
Epoch 91
Train function
Loss = 6.8189e-06, PNorm = 67.3697, GNorm = 0.0407, lr_0 = 1.1824e-04
Loss = 6.7383e-06, PNorm = 67.3713, GNorm = 0.0409, lr_0 = 1.1772e-04
Loss = 6.5996e-06, PNorm = 67.3723, GNorm = 0.1132, lr_0 = 1.1720e-04
Loss = 7.8941e-06, PNorm = 67.3727, GNorm = 0.1598, lr_0 = 1.1668e-04
Loss = 9.7726e-06, PNorm = 67.3737, GNorm = 0.1066, lr_0 = 1.1616e-04
Validation rmse logD = 0.622982
Validation R2 logD = 0.719390
Validation rmse logP = 0.681823
Validation R2 logP = 0.763739
Epoch 92
Train function
Loss = 5.6132e-06, PNorm = 67.3748, GNorm = 0.0626, lr_0 = 1.1565e-04
Loss = 7.6786e-06, PNorm = 67.3762, GNorm = 0.0745, lr_0 = 1.1514e-04
Loss = 9.0709e-06, PNorm = 67.3773, GNorm = 0.0394, lr_0 = 1.1463e-04
Loss = 9.4275e-06, PNorm = 67.3772, GNorm = 0.2049, lr_0 = 1.1412e-04
Loss = 5.0515e-06, PNorm = 67.3778, GNorm = 0.0871, lr_0 = 1.1362e-04
Loss = 6.1954e-06, PNorm = 67.3786, GNorm = 0.1816, lr_0 = 1.1312e-04
Loss = 7.6629e-05, PNorm = 67.3788, GNorm = 0.1792, lr_0 = 1.1307e-04
Validation rmse logD = 0.624650
Validation R2 logD = 0.717886
Validation rmse logP = 0.684170
Validation R2 logP = 0.762110
Epoch 93
Train function
Loss = 6.5955e-06, PNorm = 67.3792, GNorm = 0.0620, lr_0 = 1.1257e-04
Loss = 6.7687e-06, PNorm = 67.3808, GNorm = 0.0504, lr_0 = 1.1207e-04
Loss = 1.1034e-05, PNorm = 67.3813, GNorm = 0.0678, lr_0 = 1.1157e-04
Loss = 7.2968e-06, PNorm = 67.3819, GNorm = 0.1111, lr_0 = 1.1108e-04
Loss = 8.2352e-06, PNorm = 67.3830, GNorm = 0.0458, lr_0 = 1.1059e-04
Validation rmse logD = 0.624458
Validation R2 logD = 0.718059
Validation rmse logP = 0.683626
Validation R2 logP = 0.762488
Epoch 94
Train function
Loss = 8.5523e-06, PNorm = 67.3845, GNorm = 0.1825, lr_0 = 1.1005e-04
Loss = 8.8968e-06, PNorm = 67.3854, GNorm = 0.2207, lr_0 = 1.0956e-04
Loss = 8.6169e-06, PNorm = 67.3865, GNorm = 0.0707, lr_0 = 1.0908e-04
Loss = 6.7656e-06, PNorm = 67.3871, GNorm = 0.0319, lr_0 = 1.0860e-04
Loss = 6.3088e-06, PNorm = 67.3877, GNorm = 0.0559, lr_0 = 1.0811e-04
Validation rmse logD = 0.623897
Validation R2 logD = 0.718566
Validation rmse logP = 0.684818
Validation R2 logP = 0.761659
Epoch 95
Train function
Loss = 4.3640e-06, PNorm = 67.3890, GNorm = 0.0960, lr_0 = 1.0759e-04
Loss = 6.4022e-06, PNorm = 67.3906, GNorm = 0.0373, lr_0 = 1.0711e-04
Loss = 6.9506e-06, PNorm = 67.3911, GNorm = 0.0441, lr_0 = 1.0664e-04
Loss = 6.1326e-06, PNorm = 67.3916, GNorm = 0.0572, lr_0 = 1.0617e-04
Loss = 5.5269e-06, PNorm = 67.3926, GNorm = 0.0514, lr_0 = 1.0570e-04
Validation rmse logD = 0.625206
Validation R2 logD = 0.717383
Validation rmse logP = 0.684151
Validation R2 logP = 0.762123
Epoch 96
Train function
Loss = 5.5105e-06, PNorm = 67.3930, GNorm = 0.0886, lr_0 = 1.0518e-04
Loss = 6.3861e-06, PNorm = 67.3931, GNorm = 0.0730, lr_0 = 1.0472e-04
Loss = 9.9768e-06, PNorm = 67.3941, GNorm = 0.0602, lr_0 = 1.0426e-04
Loss = 7.2401e-06, PNorm = 67.3955, GNorm = 0.0748, lr_0 = 1.0379e-04
Loss = 7.3510e-06, PNorm = 67.3964, GNorm = 0.2241, lr_0 = 1.0333e-04
Loss = 7.1424e-06, PNorm = 67.3974, GNorm = 0.0517, lr_0 = 1.0288e-04
Validation rmse logD = 0.625655
Validation R2 logD = 0.716977
Validation rmse logP = 0.683947
Validation R2 logP = 0.762265
Epoch 97
Train function
Loss = 6.6761e-06, PNorm = 67.3986, GNorm = 0.1003, lr_0 = 1.0238e-04
Loss = 5.1613e-06, PNorm = 67.3992, GNorm = 0.0420, lr_0 = 1.0192e-04
Loss = 5.8757e-06, PNorm = 67.4004, GNorm = 0.0345, lr_0 = 1.0147e-04
Loss = 6.8948e-06, PNorm = 67.4015, GNorm = 0.0886, lr_0 = 1.0102e-04
Loss = 7.2558e-06, PNorm = 67.4019, GNorm = 0.1977, lr_0 = 1.0058e-04
Validation rmse logD = 0.625785
Validation R2 logD = 0.716859
Validation rmse logP = 0.684334
Validation R2 logP = 0.761996
Epoch 98
Train function
Loss = 6.8148e-06, PNorm = 67.4028, GNorm = 0.0749, lr_0 = 1.0009e-04
Loss = 6.8548e-06, PNorm = 67.4033, GNorm = 0.0608, lr_0 = 1.0000e-04
Loss = 6.7810e-06, PNorm = 67.4041, GNorm = 0.0457, lr_0 = 1.0000e-04
Loss = 7.3802e-06, PNorm = 67.4050, GNorm = 0.1559, lr_0 = 1.0000e-04
Loss = 9.1073e-06, PNorm = 67.4056, GNorm = 0.0925, lr_0 = 1.0000e-04
Validation rmse logD = 0.624588
Validation R2 logD = 0.717942
Validation rmse logP = 0.683080
Validation R2 logP = 0.762868
Epoch 99
Train function
Loss = 4.5269e-06, PNorm = 67.4063, GNorm = 0.0899, lr_0 = 1.0000e-04
Loss = 4.8452e-06, PNorm = 67.4070, GNorm = 0.0441, lr_0 = 1.0000e-04
Loss = 5.3050e-06, PNorm = 67.4080, GNorm = 0.0469, lr_0 = 1.0000e-04
Loss = 5.1760e-06, PNorm = 67.4086, GNorm = 0.0598, lr_0 = 1.0000e-04
Loss = 6.6506e-06, PNorm = 67.4098, GNorm = 0.0808, lr_0 = 1.0000e-04
Loss = 5.8135e-06, PNorm = 67.4099, GNorm = 0.0506, lr_0 = 1.0000e-04
Validation rmse logD = 0.625786
Validation R2 logD = 0.716858
Validation rmse logP = 0.684354
Validation R2 logP = 0.761982
Model 0 best validation rmse = 0.645196 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.657971
Model 0 test R2 logD = 0.695946
Model 0 test rmse logP = 0.941697
Model 0 test R2 logP = 0.617078
Ensemble test rmse  logD= 0.657971
Ensemble test R2  logD= 0.695946
Ensemble test rmse  logP= 0.941697
Ensemble test R2  logP= 0.617078
4-fold cross validation
	Seed 0 ==> test rmse = 0.651533
	Seed 0 ==> test R2 = 0.768231
	Seed 1 ==> test rmse = 0.698478
	Seed 1 ==> test R2 = 0.735698
	Seed 2 ==> test rmse = 0.719372
	Seed 2 ==> test R2 = 0.718979
	Seed 3 ==> test rmse = 0.799834
	Seed 3 ==> test R2 = 0.656512
Overall val rmse logD= 0.582672 +/- 0.023744
Overall val R2 logD = 0.763652 +/- 0.023077
Overall test rmse logD = 0.622315 +/- 0.026435
Overall test R2 logD = 0.727516 +/- 0.023131
Overall val rmse logP= 0.646912 +/- 0.052238
Overall val R2 logP = 0.804640 +/- 0.036479
Overall test rmse logP = 0.812293 +/- 0.081842
Overall test R2 logP = 0.712194 +/- 0.059104
Elapsed time = 5:28:15
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.2304e-02, PNorm = 55.5683, GNorm = 7.1812, lr_0 = 1.9340e-04
Loss = 1.9878e-02, PNorm = 55.5773, GNorm = 2.6835, lr_0 = 2.7830e-04
Loss = 1.4634e-02, PNorm = 55.5924, GNorm = 2.8083, lr_0 = 3.6321e-04
Loss = 1.6070e-02, PNorm = 55.6143, GNorm = 1.6372, lr_0 = 4.4811e-04
Loss = 1.3765e-02, PNorm = 55.6503, GNorm = 2.0442, lr_0 = 5.3302e-04
Validation rmse logD = 1.016192
Validation R2 logD = 0.251492
Validation rmse logP = 1.152814
Validation R2 logP = 0.365316
Epoch 1
Train function
Loss = 1.4812e-02, PNorm = 55.7012, GNorm = 2.7373, lr_0 = 6.2642e-04
Loss = 1.3886e-02, PNorm = 55.7702, GNorm = 1.6146, lr_0 = 7.1132e-04
Loss = 1.2523e-02, PNorm = 55.8540, GNorm = 1.8251, lr_0 = 7.9623e-04
Loss = 1.2499e-02, PNorm = 55.9515, GNorm = 2.9546, lr_0 = 8.8113e-04
Loss = 1.2864e-02, PNorm = 56.0704, GNorm = 1.7217, lr_0 = 9.6604e-04
Validation rmse logD = 0.878058
Validation R2 logD = 0.441155
Validation rmse logP = 1.255231
Validation R2 logP = 0.247534
Epoch 2
Train function
Loss = 1.2096e-02, PNorm = 56.2069, GNorm = 5.9852, lr_0 = 9.9690e-04
Loss = 1.0477e-02, PNorm = 56.3467, GNorm = 2.9766, lr_0 = 9.9249e-04
Loss = 1.4111e-02, PNorm = 56.4545, GNorm = 1.1736, lr_0 = 9.8810e-04
Loss = 1.2302e-02, PNorm = 56.5444, GNorm = 4.9393, lr_0 = 9.8373e-04
Loss = 1.0738e-02, PNorm = 56.6369, GNorm = 1.3109, lr_0 = 9.7938e-04
Validation rmse logD = 0.876248
Validation R2 logD = 0.443457
Validation rmse logP = 0.962550
Validation R2 logP = 0.557528
Epoch 3
Train function
Loss = 9.4793e-03, PNorm = 56.7275, GNorm = 1.5988, lr_0 = 9.7462e-04
Loss = 1.2065e-02, PNorm = 56.8100, GNorm = 4.5413, lr_0 = 9.7030e-04
Loss = 1.0086e-02, PNorm = 56.9029, GNorm = 4.4163, lr_0 = 9.6601e-04
Loss = 9.4557e-03, PNorm = 57.0042, GNorm = 0.8352, lr_0 = 9.6174e-04
Loss = 9.2082e-03, PNorm = 57.0971, GNorm = 2.7173, lr_0 = 9.5749e-04
Loss = 8.4580e-03, PNorm = 57.1857, GNorm = 3.3457, lr_0 = 9.5325e-04
Validation rmse logD = 0.820280
Validation R2 logD = 0.512281
Validation rmse logP = 0.903553
Validation R2 logP = 0.610106
Epoch 4
Train function
Loss = 9.1055e-03, PNorm = 57.2403, GNorm = 1.4647, lr_0 = 9.4861e-04
Loss = 8.3308e-03, PNorm = 57.3469, GNorm = 1.4042, lr_0 = 9.4442e-04
Loss = 8.3706e-03, PNorm = 57.4336, GNorm = 0.7652, lr_0 = 9.4024e-04
Loss = 8.2657e-03, PNorm = 57.5391, GNorm = 1.7139, lr_0 = 9.3608e-04
Loss = 8.8905e-03, PNorm = 57.6125, GNorm = 1.3340, lr_0 = 9.3194e-04
Validation rmse logD = 0.843796
Validation R2 logD = 0.483916
Validation rmse logP = 0.972521
Validation R2 logP = 0.548313
Epoch 5
Train function
Loss = 8.8817e-03, PNorm = 57.7185, GNorm = 1.3167, lr_0 = 9.2741e-04
Loss = 8.3513e-03, PNorm = 57.7972, GNorm = 3.4991, lr_0 = 9.2330e-04
Loss = 6.7786e-03, PNorm = 57.8896, GNorm = 3.4724, lr_0 = 9.1922e-04
Loss = 7.5553e-03, PNorm = 57.9906, GNorm = 0.6919, lr_0 = 9.1515e-04
Loss = 6.2343e-03, PNorm = 58.0804, GNorm = 0.9884, lr_0 = 9.1111e-04
Validation rmse logD = 0.903246
Validation R2 logD = 0.408633
Validation rmse logP = 0.830750
Validation R2 logP = 0.670405
Epoch 6
Train function
Loss = 1.1047e-02, PNorm = 58.1854, GNorm = 6.9053, lr_0 = 9.0667e-04
Loss = 7.0299e-03, PNorm = 58.2824, GNorm = 0.7252, lr_0 = 9.0266e-04
Loss = 6.7154e-03, PNorm = 58.3880, GNorm = 0.8588, lr_0 = 8.9867e-04
Loss = 6.8673e-03, PNorm = 58.4640, GNorm = 0.9816, lr_0 = 8.9469e-04
Loss = 6.2164e-03, PNorm = 58.5470, GNorm = 0.8321, lr_0 = 8.9074e-04
Loss = 7.1651e-03, PNorm = 58.6313, GNorm = 4.2072, lr_0 = 8.8680e-04
Validation rmse logD = 0.792187
Validation R2 logD = 0.545116
Validation rmse logP = 0.805078
Validation R2 logP = 0.690461
Epoch 7
Train function
Loss = 6.5829e-03, PNorm = 58.7145, GNorm = 2.0667, lr_0 = 8.8248e-04
Loss = 6.1794e-03, PNorm = 58.8135, GNorm = 0.9902, lr_0 = 8.7858e-04
Loss = 5.3899e-03, PNorm = 58.8989, GNorm = 1.0825, lr_0 = 8.7469e-04
Loss = 6.5314e-03, PNorm = 58.9941, GNorm = 1.5382, lr_0 = 8.7082e-04
Loss = 6.7651e-03, PNorm = 59.0803, GNorm = 1.5782, lr_0 = 8.6697e-04
Validation rmse logD = 0.689968
Validation R2 logD = 0.654934
Validation rmse logP = 0.812879
Validation R2 logP = 0.684433
Epoch 8
Train function
Loss = 5.0963e-03, PNorm = 59.1894, GNorm = 2.3142, lr_0 = 8.6276e-04
Loss = 6.0391e-03, PNorm = 59.2682, GNorm = 1.1150, lr_0 = 8.5894e-04
Loss = 5.4414e-03, PNorm = 59.3665, GNorm = 1.8662, lr_0 = 8.5514e-04
Loss = 4.5855e-03, PNorm = 59.4385, GNorm = 0.6731, lr_0 = 8.5136e-04
Loss = 5.3472e-03, PNorm = 59.5165, GNorm = 2.0291, lr_0 = 8.4759e-04
Validation rmse logD = 0.658913
Validation R2 logD = 0.685296
Validation rmse logP = 0.801643
Validation R2 logP = 0.693097
Epoch 9
Train function
Loss = 5.0180e-03, PNorm = 59.5955, GNorm = 0.8821, lr_0 = 8.4347e-04
Loss = 4.3039e-03, PNorm = 59.6859, GNorm = 1.9149, lr_0 = 8.3974e-04
Loss = 4.1281e-03, PNorm = 59.7845, GNorm = 1.1708, lr_0 = 8.3602e-04
Loss = 4.3749e-03, PNorm = 59.8757, GNorm = 1.9261, lr_0 = 8.3232e-04
Loss = 4.7379e-03, PNorm = 59.9587, GNorm = 1.5095, lr_0 = 8.2864e-04
Loss = 4.7575e-03, PNorm = 60.0397, GNorm = 0.9814, lr_0 = 8.2498e-04
Validation rmse logD = 0.690739
Validation R2 logD = 0.654162
Validation rmse logP = 0.787725
Validation R2 logP = 0.703661
Epoch 10
Train function
Loss = 4.7587e-03, PNorm = 60.1564, GNorm = 1.9917, lr_0 = 8.2133e-04
Loss = 4.2337e-03, PNorm = 60.2544, GNorm = 0.8491, lr_0 = 8.1770e-04
Loss = 4.4686e-03, PNorm = 60.3464, GNorm = 1.8353, lr_0 = 8.1408e-04
Loss = 4.0520e-03, PNorm = 60.4286, GNorm = 1.3427, lr_0 = 8.1048e-04
Loss = 3.6533e-03, PNorm = 60.4996, GNorm = 0.5552, lr_0 = 8.0689e-04
Validation rmse logD = 0.632573
Validation R2 logD = 0.709954
Validation rmse logP = 0.877229
Validation R2 logP = 0.632493
Epoch 11
Train function
Loss = 3.8293e-03, PNorm = 60.6024, GNorm = 1.7666, lr_0 = 8.0297e-04
Loss = 3.8042e-03, PNorm = 60.6893, GNorm = 0.7734, lr_0 = 7.9942e-04
Loss = 3.5153e-03, PNorm = 60.7849, GNorm = 0.6789, lr_0 = 7.9588e-04
Loss = 3.6630e-03, PNorm = 60.8711, GNorm = 2.6286, lr_0 = 7.9236e-04
Loss = 3.5876e-03, PNorm = 60.9458, GNorm = 0.6421, lr_0 = 7.8885e-04
Validation rmse logD = 0.664041
Validation R2 logD = 0.680379
Validation rmse logP = 0.786458
Validation R2 logP = 0.704613
Epoch 12
Train function
Loss = 4.3064e-03, PNorm = 61.0304, GNorm = 2.8082, lr_0 = 7.8502e-04
Loss = 4.0938e-03, PNorm = 61.1360, GNorm = 3.0393, lr_0 = 7.8154e-04
Loss = 3.0683e-03, PNorm = 61.2281, GNorm = 0.8616, lr_0 = 7.7809e-04
Loss = 3.1773e-03, PNorm = 61.3040, GNorm = 1.0103, lr_0 = 7.7465e-04
Loss = 3.5211e-03, PNorm = 61.3817, GNorm = 2.0083, lr_0 = 7.7122e-04
Loss = 3.2877e-03, PNorm = 61.4588, GNorm = 0.8220, lr_0 = 7.6781e-04
Loss = 7.0513e-02, PNorm = 61.4639, GNorm = 6.7897, lr_0 = 7.6747e-04
Validation rmse logD = 0.817757
Validation R2 logD = 0.515277
Validation rmse logP = 0.798588
Validation R2 logP = 0.695431
Epoch 13
Train function
Loss = 4.7813e-03, PNorm = 61.5598, GNorm = 1.8384, lr_0 = 7.6407e-04
Loss = 3.1871e-03, PNorm = 61.6826, GNorm = 2.0489, lr_0 = 7.6069e-04
Loss = 3.2672e-03, PNorm = 61.7685, GNorm = 1.2530, lr_0 = 7.5733e-04
Loss = 3.0968e-03, PNorm = 61.8419, GNorm = 1.1242, lr_0 = 7.5398e-04
Loss = 3.0255e-03, PNorm = 61.9207, GNorm = 2.3105, lr_0 = 7.5064e-04
Validation rmse logD = 0.649150
Validation R2 logD = 0.694553
Validation rmse logP = 0.869652
Validation R2 logP = 0.638815
Epoch 14
Train function
Loss = 2.8527e-03, PNorm = 61.9990, GNorm = 1.2383, lr_0 = 7.4699e-04
Loss = 2.1955e-03, PNorm = 62.0844, GNorm = 0.7007, lr_0 = 7.4369e-04
Loss = 2.5339e-03, PNorm = 62.1410, GNorm = 0.9319, lr_0 = 7.4040e-04
Loss = 2.3441e-03, PNorm = 62.2161, GNorm = 1.5652, lr_0 = 7.3712e-04
Loss = 2.2993e-03, PNorm = 62.2772, GNorm = 1.3902, lr_0 = 7.3386e-04
Validation rmse logD = 0.591784
Validation R2 logD = 0.746153
Validation rmse logP = 0.765995
Validation R2 logP = 0.719785
Epoch 15
Train function
Loss = 2.9585e-03, PNorm = 62.3441, GNorm = 0.9460, lr_0 = 7.3029e-04
Loss = 2.6542e-03, PNorm = 62.4142, GNorm = 0.7622, lr_0 = 7.2706e-04
Loss = 2.2302e-03, PNorm = 62.4919, GNorm = 0.6514, lr_0 = 7.2385e-04
Loss = 1.9013e-03, PNorm = 62.5725, GNorm = 0.5905, lr_0 = 7.2064e-04
Loss = 2.2815e-03, PNorm = 62.6370, GNorm = 0.9278, lr_0 = 7.1746e-04
Validation rmse logD = 0.584712
Validation R2 logD = 0.752184
Validation rmse logP = 0.828600
Validation R2 logP = 0.672109
Epoch 16
Train function
Loss = 1.9376e-03, PNorm = 62.7237, GNorm = 1.3111, lr_0 = 7.1397e-04
Loss = 2.3682e-03, PNorm = 62.8066, GNorm = 1.8935, lr_0 = 7.1081e-04
Loss = 2.1888e-03, PNorm = 62.8799, GNorm = 1.9248, lr_0 = 7.0766e-04
Loss = 1.7955e-03, PNorm = 62.9494, GNorm = 0.8646, lr_0 = 7.0453e-04
Loss = 2.1844e-03, PNorm = 62.9974, GNorm = 0.9412, lr_0 = 7.0142e-04
Loss = 1.9397e-03, PNorm = 63.0498, GNorm = 0.9953, lr_0 = 6.9831e-04
Validation rmse logD = 0.586637
Validation R2 logD = 0.750549
Validation rmse logP = 0.782353
Validation R2 logP = 0.707689
Epoch 17
Train function
Loss = 1.4308e-03, PNorm = 63.1182, GNorm = 0.7014, lr_0 = 6.9492e-04
Loss = 1.6475e-03, PNorm = 63.1820, GNorm = 0.5157, lr_0 = 6.9184e-04
Loss = 1.6004e-03, PNorm = 63.2400, GNorm = 0.4059, lr_0 = 6.8878e-04
Loss = 1.8097e-03, PNorm = 63.2830, GNorm = 1.1564, lr_0 = 6.8574e-04
Loss = 1.5522e-03, PNorm = 63.3425, GNorm = 0.4680, lr_0 = 6.8270e-04
Validation rmse logD = 0.699023
Validation R2 logD = 0.645817
Validation rmse logP = 0.798005
Validation R2 logP = 0.695876
Epoch 18
Train function
Loss = 2.3811e-03, PNorm = 63.4012, GNorm = 2.5465, lr_0 = 6.7938e-04
Loss = 2.3550e-03, PNorm = 63.4835, GNorm = 1.7911, lr_0 = 6.7638e-04
Loss = 2.0677e-03, PNorm = 63.5698, GNorm = 1.2608, lr_0 = 6.7338e-04
Loss = 1.9810e-03, PNorm = 63.6438, GNorm = 2.2837, lr_0 = 6.7041e-04
Loss = 1.9988e-03, PNorm = 63.6990, GNorm = 1.5232, lr_0 = 6.6744e-04
Validation rmse logD = 0.617150
Validation R2 logD = 0.723926
Validation rmse logP = 0.806049
Validation R2 logP = 0.689714
Epoch 19
Train function
Loss = 1.9487e-03, PNorm = 63.7752, GNorm = 1.0417, lr_0 = 6.6419e-04
Loss = 1.6862e-03, PNorm = 63.8432, GNorm = 0.7761, lr_0 = 6.6126e-04
Loss = 1.4544e-03, PNorm = 63.8862, GNorm = 0.9428, lr_0 = 6.5833e-04
Loss = 1.3230e-03, PNorm = 63.9324, GNorm = 0.7913, lr_0 = 6.5542e-04
Loss = 1.4740e-03, PNorm = 63.9700, GNorm = 0.5641, lr_0 = 6.5252e-04
Loss = 1.6815e-03, PNorm = 64.0115, GNorm = 1.2544, lr_0 = 6.4963e-04
Validation rmse logD = 0.579494
Validation R2 logD = 0.756587
Validation rmse logP = 0.799914
Validation R2 logP = 0.694419
Epoch 20
Train function
Loss = 1.2615e-03, PNorm = 64.0698, GNorm = 1.1288, lr_0 = 6.4676e-04
Loss = 1.4657e-03, PNorm = 64.1266, GNorm = 0.8336, lr_0 = 6.4390e-04
Loss = 1.2669e-03, PNorm = 64.1575, GNorm = 0.5783, lr_0 = 6.4105e-04
Loss = 1.4034e-03, PNorm = 64.2004, GNorm = 1.4369, lr_0 = 6.3822e-04
Loss = 1.4143e-03, PNorm = 64.2434, GNorm = 0.6986, lr_0 = 6.3539e-04
Validation rmse logD = 0.587841
Validation R2 logD = 0.749525
Validation rmse logP = 0.801396
Validation R2 logP = 0.693286
Epoch 21
Train function
Loss = 1.2041e-03, PNorm = 64.2905, GNorm = 1.9561, lr_0 = 6.3230e-04
Loss = 1.3709e-03, PNorm = 64.3331, GNorm = 0.7429, lr_0 = 6.2950e-04
Loss = 9.6718e-04, PNorm = 64.3772, GNorm = 0.5894, lr_0 = 6.2672e-04
Loss = 1.0921e-03, PNorm = 64.4114, GNorm = 0.4080, lr_0 = 6.2395e-04
Loss = 1.1639e-03, PNorm = 64.4529, GNorm = 1.0283, lr_0 = 6.2119e-04
Validation rmse logD = 0.588307
Validation R2 logD = 0.749128
Validation rmse logP = 0.834340
Validation R2 logP = 0.667550
Epoch 22
Train function
Loss = 1.1308e-03, PNorm = 64.4917, GNorm = 0.6592, lr_0 = 6.1817e-04
Loss = 8.4930e-04, PNorm = 64.5277, GNorm = 0.9559, lr_0 = 6.1543e-04
Loss = 9.5508e-04, PNorm = 64.5605, GNorm = 0.8176, lr_0 = 6.1271e-04
Loss = 1.0521e-03, PNorm = 64.5996, GNorm = 0.5699, lr_0 = 6.1000e-04
Loss = 8.5992e-04, PNorm = 64.6355, GNorm = 0.4317, lr_0 = 6.0730e-04
Loss = 9.4224e-04, PNorm = 64.6740, GNorm = 0.8381, lr_0 = 6.0461e-04
Validation rmse logD = 0.583013
Validation R2 logD = 0.753622
Validation rmse logP = 0.836298
Validation R2 logP = 0.665988
Epoch 23
Train function
Loss = 1.0965e-03, PNorm = 64.7157, GNorm = 1.0507, lr_0 = 6.0167e-04
Loss = 8.8326e-04, PNorm = 64.7635, GNorm = 0.8789, lr_0 = 5.9901e-04
Loss = 8.8250e-04, PNorm = 64.8050, GNorm = 0.5196, lr_0 = 5.9636e-04
Loss = 8.8870e-04, PNorm = 64.8334, GNorm = 2.2716, lr_0 = 5.9372e-04
Loss = 8.7294e-04, PNorm = 64.8719, GNorm = 0.5448, lr_0 = 5.9110e-04
Validation rmse logD = 0.570969
Validation R2 logD = 0.763696
Validation rmse logP = 0.824864
Validation R2 logP = 0.675059
Epoch 24
Train function
Loss = 9.1374e-04, PNorm = 64.9087, GNorm = 1.3838, lr_0 = 5.8822e-04
Loss = 7.8960e-04, PNorm = 64.9485, GNorm = 0.5163, lr_0 = 5.8562e-04
Loss = 7.0330e-04, PNorm = 64.9787, GNorm = 0.6845, lr_0 = 5.8303e-04
Loss = 7.3581e-04, PNorm = 65.0078, GNorm = 0.4498, lr_0 = 5.8045e-04
Loss = 9.0571e-04, PNorm = 65.0434, GNorm = 0.7233, lr_0 = 5.7788e-04
Validation rmse logD = 0.569209
Validation R2 logD = 0.765151
Validation rmse logP = 0.818451
Validation R2 logP = 0.680092
Epoch 25
Train function
Loss = 6.2853e-04, PNorm = 65.0730, GNorm = 0.5282, lr_0 = 5.7507e-04
Loss = 6.8014e-04, PNorm = 65.0983, GNorm = 0.4670, lr_0 = 5.7253e-04
Loss = 6.0354e-04, PNorm = 65.1257, GNorm = 0.5298, lr_0 = 5.7000e-04
Loss = 7.0201e-04, PNorm = 65.1555, GNorm = 0.5047, lr_0 = 5.6748e-04
Loss = 5.9187e-04, PNorm = 65.1760, GNorm = 0.5633, lr_0 = 5.6497e-04
Loss = 6.8090e-04, PNorm = 65.2053, GNorm = 0.6329, lr_0 = 5.6247e-04
Loss = 4.0124e-03, PNorm = 65.2090, GNorm = 1.0900, lr_0 = 5.6222e-04
Validation rmse logD = 0.564012
Validation R2 logD = 0.769420
Validation rmse logP = 0.823191
Validation R2 logP = 0.676376
Epoch 26
Train function
Loss = 5.5959e-04, PNorm = 65.2385, GNorm = 0.6379, lr_0 = 5.5973e-04
Loss = 6.3588e-04, PNorm = 65.2701, GNorm = 0.5479, lr_0 = 5.5725e-04
Loss = 6.3731e-04, PNorm = 65.2944, GNorm = 0.4336, lr_0 = 5.5479e-04
Loss = 7.6942e-04, PNorm = 65.3235, GNorm = 0.5730, lr_0 = 5.5233e-04
Loss = 6.3800e-04, PNorm = 65.3493, GNorm = 0.8312, lr_0 = 5.4989e-04
Validation rmse logD = 0.573118
Validation R2 logD = 0.761915
Validation rmse logP = 0.833934
Validation R2 logP = 0.667874
Epoch 27
Train function
Loss = 6.1074e-04, PNorm = 65.3737, GNorm = 1.0519, lr_0 = 5.4722e-04
Loss = 6.4482e-04, PNorm = 65.4013, GNorm = 0.5128, lr_0 = 5.4480e-04
Loss = 5.3571e-04, PNorm = 65.4241, GNorm = 0.3418, lr_0 = 5.4239e-04
Loss = 6.7986e-04, PNorm = 65.4588, GNorm = 0.6856, lr_0 = 5.3999e-04
Loss = 8.2523e-04, PNorm = 65.4881, GNorm = 1.5982, lr_0 = 5.3760e-04
Validation rmse logD = 0.569997
Validation R2 logD = 0.764500
Validation rmse logP = 0.831625
Validation R2 logP = 0.669711
Epoch 28
Train function
Loss = 6.1111e-04, PNorm = 65.5173, GNorm = 0.9913, lr_0 = 5.3498e-04
Loss = 6.9672e-04, PNorm = 65.5483, GNorm = 1.0565, lr_0 = 5.3262e-04
Loss = 8.1826e-04, PNorm = 65.5747, GNorm = 0.4575, lr_0 = 5.3026e-04
Loss = 6.5292e-04, PNorm = 65.6057, GNorm = 0.5596, lr_0 = 5.2792e-04
Loss = 6.3780e-04, PNorm = 65.6406, GNorm = 0.7337, lr_0 = 5.2558e-04
Validation rmse logD = 0.621006
Validation R2 logD = 0.720464
Validation rmse logP = 0.836629
Validation R2 logP = 0.665724
Epoch 29
Train function
Loss = 1.1102e-03, PNorm = 65.6641, GNorm = 2.1384, lr_0 = 5.2302e-04
Loss = 1.1248e-03, PNorm = 65.7044, GNorm = 0.7860, lr_0 = 5.2071e-04
Loss = 1.0400e-03, PNorm = 65.7426, GNorm = 0.7796, lr_0 = 5.1841e-04
Loss = 6.8806e-04, PNorm = 65.7743, GNorm = 1.0343, lr_0 = 5.1611e-04
Loss = 7.9413e-04, PNorm = 65.8138, GNorm = 1.2416, lr_0 = 5.1383e-04
Loss = 6.3857e-04, PNorm = 65.8525, GNorm = 0.4456, lr_0 = 5.1156e-04
Validation rmse logD = 0.558001
Validation R2 logD = 0.774309
Validation rmse logP = 0.842414
Validation R2 logP = 0.661085
Epoch 30
Train function
Loss = 5.5390e-04, PNorm = 65.8768, GNorm = 1.1227, lr_0 = 5.0930e-04
Loss = 5.6213e-04, PNorm = 65.9033, GNorm = 1.0058, lr_0 = 5.0704e-04
Loss = 6.7114e-04, PNorm = 65.9329, GNorm = 0.6032, lr_0 = 5.0480e-04
Loss = 5.0631e-04, PNorm = 65.9623, GNorm = 0.6934, lr_0 = 5.0257e-04
Loss = 5.9549e-04, PNorm = 65.9816, GNorm = 0.2873, lr_0 = 5.0034e-04
Validation rmse logD = 0.560235
Validation R2 logD = 0.772497
Validation rmse logP = 0.820907
Validation R2 logP = 0.678169
Epoch 31
Train function
Loss = 3.8483e-04, PNorm = 66.0073, GNorm = 0.8030, lr_0 = 4.9791e-04
Loss = 4.2230e-04, PNorm = 66.0296, GNorm = 0.2495, lr_0 = 4.9571e-04
Loss = 4.2249e-04, PNorm = 66.0498, GNorm = 0.2657, lr_0 = 4.9351e-04
Loss = 4.2928e-04, PNorm = 66.0634, GNorm = 0.2904, lr_0 = 4.9133e-04
Loss = 3.8351e-04, PNorm = 66.0786, GNorm = 0.2646, lr_0 = 4.8916e-04
Validation rmse logD = 0.561128
Validation R2 logD = 0.771772
Validation rmse logP = 0.807501
Validation R2 logP = 0.688595
Epoch 32
Train function
Loss = 3.7228e-04, PNorm = 66.0981, GNorm = 0.7534, lr_0 = 4.8678e-04
Loss = 3.6880e-04, PNorm = 66.1160, GNorm = 0.8009, lr_0 = 4.8463e-04
Loss = 4.0789e-04, PNorm = 66.1349, GNorm = 0.2272, lr_0 = 4.8248e-04
Loss = 3.6532e-04, PNorm = 66.1493, GNorm = 0.3481, lr_0 = 4.8035e-04
Loss = 3.2353e-04, PNorm = 66.1636, GNorm = 0.2831, lr_0 = 4.7822e-04
Loss = 3.7081e-04, PNorm = 66.1738, GNorm = 0.4441, lr_0 = 4.7611e-04
Validation rmse logD = 0.560424
Validation R2 logD = 0.772344
Validation rmse logP = 0.794319
Validation R2 logP = 0.698679
Epoch 33
Train function
Loss = 2.8810e-04, PNorm = 66.1919, GNorm = 0.4017, lr_0 = 4.7379e-04
Loss = 2.9675e-04, PNorm = 66.2103, GNorm = 0.5939, lr_0 = 4.7170e-04
Loss = 3.6590e-04, PNorm = 66.2238, GNorm = 0.6032, lr_0 = 4.6961e-04
Loss = 2.7375e-04, PNorm = 66.2388, GNorm = 0.2772, lr_0 = 4.6753e-04
Loss = 2.9435e-04, PNorm = 66.2533, GNorm = 0.3524, lr_0 = 4.6546e-04
Validation rmse logD = 0.556751
Validation R2 logD = 0.775318
Validation rmse logP = 0.826237
Validation R2 logP = 0.673976
Epoch 34
Train function
Loss = 2.5280e-04, PNorm = 66.2688, GNorm = 0.3297, lr_0 = 4.6320e-04
Loss = 2.4306e-04, PNorm = 66.2878, GNorm = 0.2488, lr_0 = 4.6115e-04
Loss = 2.7031e-04, PNorm = 66.2999, GNorm = 0.2820, lr_0 = 4.5911e-04
Loss = 3.4705e-04, PNorm = 66.3116, GNorm = 1.0983, lr_0 = 4.5708e-04
Loss = 3.3680e-04, PNorm = 66.3273, GNorm = 0.3381, lr_0 = 4.5506e-04
Validation rmse logD = 0.566571
Validation R2 logD = 0.767323
Validation rmse logP = 0.804714
Validation R2 logP = 0.690740
Epoch 35
Train function
Loss = 3.1382e-04, PNorm = 66.3399, GNorm = 0.6417, lr_0 = 4.5284e-04
Loss = 2.9510e-04, PNorm = 66.3547, GNorm = 0.4801, lr_0 = 4.5084e-04
Loss = 2.7591e-04, PNorm = 66.3707, GNorm = 0.2503, lr_0 = 4.4885e-04
Loss = 3.2162e-04, PNorm = 66.3862, GNorm = 0.9970, lr_0 = 4.4686e-04
Loss = 3.1930e-04, PNorm = 66.3997, GNorm = 0.4550, lr_0 = 4.4489e-04
Loss = 2.1375e-04, PNorm = 66.4157, GNorm = 0.2112, lr_0 = 4.4292e-04
Validation rmse logD = 0.560300
Validation R2 logD = 0.772445
Validation rmse logP = 0.805631
Validation R2 logP = 0.690036
Epoch 36
Train function
Loss = 2.4879e-04, PNorm = 66.4315, GNorm = 0.3350, lr_0 = 4.4076e-04
Loss = 2.9147e-04, PNorm = 66.4435, GNorm = 0.2701, lr_0 = 4.3881e-04
Loss = 3.1110e-04, PNorm = 66.4658, GNorm = 0.5120, lr_0 = 4.3687e-04
Loss = 2.9884e-04, PNorm = 66.4756, GNorm = 0.8249, lr_0 = 4.3494e-04
Loss = 3.2438e-04, PNorm = 66.4902, GNorm = 0.5420, lr_0 = 4.3302e-04
Validation rmse logD = 0.559081
Validation R2 logD = 0.773434
Validation rmse logP = 0.813128
Validation R2 logP = 0.684239
Epoch 37
Train function
Loss = 2.0582e-04, PNorm = 66.5083, GNorm = 0.4744, lr_0 = 4.3091e-04
Loss = 2.1183e-04, PNorm = 66.5210, GNorm = 0.2504, lr_0 = 4.2900e-04
Loss = 2.3468e-04, PNorm = 66.5354, GNorm = 0.4711, lr_0 = 4.2711e-04
Loss = 2.3075e-04, PNorm = 66.5443, GNorm = 0.5058, lr_0 = 4.2522e-04
Loss = 2.1006e-04, PNorm = 66.5524, GNorm = 0.2513, lr_0 = 4.2334e-04
Validation rmse logD = 0.561700
Validation R2 logD = 0.771307
Validation rmse logP = 0.811538
Validation R2 logP = 0.685474
Epoch 38
Train function
Loss = 2.4585e-04, PNorm = 66.5613, GNorm = 0.3120, lr_0 = 4.2128e-04
Loss = 1.9744e-04, PNorm = 66.5777, GNorm = 0.3154, lr_0 = 4.1941e-04
Loss = 2.9454e-04, PNorm = 66.5881, GNorm = 0.3482, lr_0 = 4.1756e-04
Loss = 2.5264e-04, PNorm = 66.6040, GNorm = 0.4972, lr_0 = 4.1571e-04
Loss = 2.2202e-04, PNorm = 66.6184, GNorm = 0.2320, lr_0 = 4.1387e-04
Loss = 2.2014e-04, PNorm = 66.6311, GNorm = 0.2900, lr_0 = 4.1204e-04
Loss = 5.6020e-03, PNorm = 66.6343, GNorm = 1.4920, lr_0 = 4.1186e-04
Validation rmse logD = 0.559235
Validation R2 logD = 0.773309
Validation rmse logP = 0.805612
Validation R2 logP = 0.690051
Epoch 39
Train function
Loss = 2.4719e-04, PNorm = 66.6532, GNorm = 0.2141, lr_0 = 4.1004e-04
Loss = 2.2145e-04, PNorm = 66.6670, GNorm = 0.2410, lr_0 = 4.0822e-04
Loss = 2.5017e-04, PNorm = 66.6793, GNorm = 0.5040, lr_0 = 4.0642e-04
Loss = 2.0409e-04, PNorm = 66.6899, GNorm = 0.1853, lr_0 = 4.0462e-04
Loss = 2.2260e-04, PNorm = 66.7013, GNorm = 0.3798, lr_0 = 4.0283e-04
Validation rmse logD = 0.559566
Validation R2 logD = 0.773041
Validation rmse logP = 0.818207
Validation R2 logP = 0.680283
Epoch 40
Train function
Loss = 2.0518e-04, PNorm = 66.7071, GNorm = 0.2443, lr_0 = 4.0105e-04
Loss = 1.9167e-04, PNorm = 66.7165, GNorm = 0.2383, lr_0 = 3.9927e-04
Loss = 2.0396e-04, PNorm = 66.7293, GNorm = 0.7831, lr_0 = 3.9751e-04
Loss = 1.9248e-04, PNorm = 66.7382, GNorm = 0.2378, lr_0 = 3.9575e-04
Loss = 1.6651e-04, PNorm = 66.7475, GNorm = 0.1659, lr_0 = 3.9400e-04
Validation rmse logD = 0.559726
Validation R2 logD = 0.772911
Validation rmse logP = 0.805688
Validation R2 logP = 0.689992
Epoch 41
Train function
Loss = 1.6031e-04, PNorm = 66.7574, GNorm = 0.2273, lr_0 = 3.9208e-04
Loss = 1.6069e-04, PNorm = 66.7678, GNorm = 0.5341, lr_0 = 3.9035e-04
Loss = 1.3925e-04, PNorm = 66.7742, GNorm = 0.2834, lr_0 = 3.8862e-04
Loss = 1.5952e-04, PNorm = 66.7821, GNorm = 0.1633, lr_0 = 3.8690e-04
Loss = 1.5723e-04, PNorm = 66.7914, GNorm = 0.3702, lr_0 = 3.8519e-04
Loss = 2.0371e-04, PNorm = 66.8007, GNorm = 0.5317, lr_0 = 3.8349e-04
Loss = 1.5282e-03, PNorm = 66.8018, GNorm = 0.6350, lr_0 = 3.8332e-04
Validation rmse logD = 0.560757
Validation R2 logD = 0.772074
Validation rmse logP = 0.809194
Validation R2 logP = 0.687288
Epoch 42
Train function
Loss = 1.7541e-04, PNorm = 66.8148, GNorm = 0.4066, lr_0 = 3.8162e-04
Loss = 2.0100e-04, PNorm = 66.8187, GNorm = 0.2714, lr_0 = 3.7993e-04
Loss = 1.7840e-04, PNorm = 66.8285, GNorm = 0.1997, lr_0 = 3.7825e-04
Loss = 1.6981e-04, PNorm = 66.8393, GNorm = 0.4758, lr_0 = 3.7658e-04
Loss = 1.7471e-04, PNorm = 66.8509, GNorm = 0.2311, lr_0 = 3.7491e-04
Validation rmse logD = 0.562220
Validation R2 logD = 0.770883
Validation rmse logP = 0.826284
Validation R2 logP = 0.673939
Epoch 43
Train function
Loss = 1.9353e-04, PNorm = 66.8614, GNorm = 0.2713, lr_0 = 3.7309e-04
Loss = 2.6243e-04, PNorm = 66.8696, GNorm = 0.2937, lr_0 = 3.7144e-04
Loss = 1.8772e-04, PNorm = 66.8875, GNorm = 0.2238, lr_0 = 3.6980e-04
Loss = 1.6247e-04, PNorm = 66.8978, GNorm = 0.2424, lr_0 = 3.6816e-04
Loss = 1.6444e-04, PNorm = 66.9072, GNorm = 0.2790, lr_0 = 3.6653e-04
Validation rmse logD = 0.555246
Validation R2 logD = 0.776532
Validation rmse logP = 0.818637
Validation R2 logP = 0.679946
Epoch 44
Train function
Loss = 1.0973e-04, PNorm = 66.9176, GNorm = 0.2166, lr_0 = 3.6475e-04
Loss = 1.5225e-04, PNorm = 66.9273, GNorm = 0.2029, lr_0 = 3.6314e-04
Loss = 1.2884e-04, PNorm = 66.9328, GNorm = 0.2874, lr_0 = 3.6153e-04
Loss = 1.2983e-04, PNorm = 66.9395, GNorm = 0.7672, lr_0 = 3.5993e-04
Loss = 1.7503e-04, PNorm = 66.9499, GNorm = 0.3275, lr_0 = 3.5834e-04
Validation rmse logD = 0.557732
Validation R2 logD = 0.774526
Validation rmse logP = 0.811464
Validation R2 logP = 0.685531
Epoch 45
Train function
Loss = 7.8216e-05, PNorm = 66.9588, GNorm = 0.1339, lr_0 = 3.5660e-04
Loss = 1.3471e-04, PNorm = 66.9637, GNorm = 0.5066, lr_0 = 3.5502e-04
Loss = 1.4428e-04, PNorm = 66.9731, GNorm = 0.2642, lr_0 = 3.5345e-04
Loss = 1.2292e-04, PNorm = 66.9819, GNorm = 0.3782, lr_0 = 3.5188e-04
Loss = 1.3902e-04, PNorm = 66.9886, GNorm = 0.5545, lr_0 = 3.5033e-04
Loss = 1.2748e-04, PNorm = 66.9971, GNorm = 0.2332, lr_0 = 3.4878e-04
Validation rmse logD = 0.575576
Validation R2 logD = 0.759868
Validation rmse logP = 0.806265
Validation R2 logP = 0.689547
Epoch 46
Train function
Loss = 2.6142e-04, PNorm = 67.0067, GNorm = 1.2074, lr_0 = 3.4708e-04
Loss = 1.4442e-04, PNorm = 67.0179, GNorm = 0.2344, lr_0 = 3.4555e-04
Loss = 1.6043e-04, PNorm = 67.0245, GNorm = 0.2263, lr_0 = 3.4402e-04
Loss = 1.2254e-04, PNorm = 67.0335, GNorm = 0.2397, lr_0 = 3.4250e-04
Loss = 1.5176e-04, PNorm = 67.0438, GNorm = 0.2057, lr_0 = 3.4098e-04
Validation rmse logD = 0.562085
Validation R2 logD = 0.770993
Validation rmse logP = 0.811396
Validation R2 logP = 0.685584
Epoch 47
Train function
Loss = 1.2944e-04, PNorm = 67.0534, GNorm = 0.4368, lr_0 = 3.3932e-04
Loss = 1.4989e-04, PNorm = 67.0615, GNorm = 0.6354, lr_0 = 3.3782e-04
Loss = 1.3016e-04, PNorm = 67.0694, GNorm = 0.1582, lr_0 = 3.3633e-04
Loss = 1.1873e-04, PNorm = 67.0717, GNorm = 0.6916, lr_0 = 3.3484e-04
Loss = 1.7709e-04, PNorm = 67.0809, GNorm = 0.4660, lr_0 = 3.3336e-04
Validation rmse logD = 0.564540
Validation R2 logD = 0.768988
Validation rmse logP = 0.820899
Validation R2 logP = 0.678176
Epoch 48
Train function
Loss = 1.0228e-04, PNorm = 67.0904, GNorm = 0.1307, lr_0 = 3.3174e-04
Loss = 1.2481e-04, PNorm = 67.0976, GNorm = 0.3916, lr_0 = 3.3027e-04
Loss = 9.6587e-05, PNorm = 67.1027, GNorm = 0.1929, lr_0 = 3.2881e-04
Loss = 9.8740e-05, PNorm = 67.1087, GNorm = 0.4512, lr_0 = 3.2735e-04
Loss = 1.1362e-04, PNorm = 67.1150, GNorm = 0.3088, lr_0 = 3.2591e-04
Loss = 1.0108e-04, PNorm = 67.1244, GNorm = 0.3633, lr_0 = 3.2446e-04
Validation rmse logD = 0.564255
Validation R2 logD = 0.769221
Validation rmse logP = 0.823148
Validation R2 logP = 0.676410
Epoch 49
Train function
Loss = 1.2076e-04, PNorm = 67.1311, GNorm = 0.2615, lr_0 = 3.2289e-04
Loss = 8.8710e-05, PNorm = 67.1380, GNorm = 0.1299, lr_0 = 3.2146e-04
Loss = 1.1661e-04, PNorm = 67.1453, GNorm = 0.5713, lr_0 = 3.2004e-04
Loss = 1.0376e-04, PNorm = 67.1493, GNorm = 0.1505, lr_0 = 3.1862e-04
Loss = 9.5295e-05, PNorm = 67.1548, GNorm = 0.2058, lr_0 = 3.1721e-04
Validation rmse logD = 0.560763
Validation R2 logD = 0.772069
Validation rmse logP = 0.818234
Validation R2 logP = 0.680262
Epoch 50
Train function
Loss = 7.5530e-05, PNorm = 67.1587, GNorm = 0.3804, lr_0 = 3.1581e-04
Loss = 8.2610e-05, PNorm = 67.1647, GNorm = 0.2048, lr_0 = 3.1441e-04
Loss = 9.8440e-05, PNorm = 67.1720, GNorm = 0.3690, lr_0 = 3.1302e-04
Loss = 1.2666e-04, PNorm = 67.1760, GNorm = 0.1743, lr_0 = 3.1164e-04
Loss = 8.8056e-05, PNorm = 67.1818, GNorm = 0.1177, lr_0 = 3.1026e-04
Validation rmse logD = 0.556424
Validation R2 logD = 0.775582
Validation rmse logP = 0.821007
Validation R2 logP = 0.678091
Epoch 51
Train function
Loss = 7.5132e-05, PNorm = 67.1880, GNorm = 0.2456, lr_0 = 3.0875e-04
Loss = 6.5133e-05, PNorm = 67.1932, GNorm = 0.1256, lr_0 = 3.0738e-04
Loss = 8.5883e-05, PNorm = 67.1942, GNorm = 0.2633, lr_0 = 3.0602e-04
Loss = 1.1174e-04, PNorm = 67.1993, GNorm = 0.1932, lr_0 = 3.0467e-04
Loss = 9.4201e-05, PNorm = 67.2061, GNorm = 0.1682, lr_0 = 3.0332e-04
Loss = 7.5809e-05, PNorm = 67.2119, GNorm = 0.2364, lr_0 = 3.0198e-04
Validation rmse logD = 0.559416
Validation R2 logD = 0.773163
Validation rmse logP = 0.813380
Validation R2 logP = 0.684044
Epoch 52
Train function
Loss = 9.5438e-05, PNorm = 67.2185, GNorm = 0.1780, lr_0 = 3.0051e-04
Loss = 9.1751e-05, PNorm = 67.2251, GNorm = 0.3218, lr_0 = 2.9918e-04
Loss = 1.0718e-04, PNorm = 67.2334, GNorm = 0.3740, lr_0 = 2.9786e-04
Loss = 9.0078e-05, PNorm = 67.2400, GNorm = 0.1656, lr_0 = 2.9654e-04
Loss = 1.0028e-04, PNorm = 67.2415, GNorm = 0.1864, lr_0 = 2.9523e-04
Validation rmse logD = 0.558263
Validation R2 logD = 0.774096
Validation rmse logP = 0.815343
Validation R2 logP = 0.682517
Epoch 53
Train function
Loss = 1.0076e-04, PNorm = 67.2448, GNorm = 0.2940, lr_0 = 2.9379e-04
Loss = 8.2228e-05, PNorm = 67.2513, GNorm = 0.2270, lr_0 = 2.9249e-04
Loss = 9.8161e-05, PNorm = 67.2582, GNorm = 0.5024, lr_0 = 2.9120e-04
Loss = 6.7282e-05, PNorm = 67.2629, GNorm = 0.1901, lr_0 = 2.8991e-04
Loss = 8.8877e-05, PNorm = 67.2680, GNorm = 0.1075, lr_0 = 2.8863e-04
Validation rmse logD = 0.563843
Validation R2 logD = 0.769558
Validation rmse logP = 0.814431
Validation R2 logP = 0.683227
Epoch 54
Train function
Loss = 8.3674e-05, PNorm = 67.2774, GNorm = 0.3325, lr_0 = 2.8722e-04
Loss = 7.6084e-05, PNorm = 67.2835, GNorm = 0.4313, lr_0 = 2.8595e-04
Loss = 7.9967e-05, PNorm = 67.2891, GNorm = 0.1347, lr_0 = 2.8469e-04
Loss = 7.4169e-05, PNorm = 67.2933, GNorm = 0.1767, lr_0 = 2.8343e-04
Loss = 7.7375e-05, PNorm = 67.2986, GNorm = 0.3343, lr_0 = 2.8218e-04
Loss = 1.0984e-04, PNorm = 67.3043, GNorm = 0.6004, lr_0 = 2.8093e-04
Loss = 5.8559e-04, PNorm = 67.3057, GNorm = 0.5442, lr_0 = 2.8080e-04
Validation rmse logD = 0.559649
Validation R2 logD = 0.772973
Validation rmse logP = 0.814758
Validation R2 logP = 0.682973
Epoch 55
Train function
Loss = 9.4581e-05, PNorm = 67.3107, GNorm = 0.1668, lr_0 = 2.7956e-04
Loss = 9.1134e-05, PNorm = 67.3159, GNorm = 0.3991, lr_0 = 2.7832e-04
Loss = 1.0002e-04, PNorm = 67.3233, GNorm = 0.6397, lr_0 = 2.7709e-04
Loss = 8.9499e-05, PNorm = 67.3292, GNorm = 0.4541, lr_0 = 2.7587e-04
Loss = 7.0951e-05, PNorm = 67.3339, GNorm = 0.0906, lr_0 = 2.7465e-04
Validation rmse logD = 0.562939
Validation R2 logD = 0.770296
Validation rmse logP = 0.818321
Validation R2 logP = 0.680194
Epoch 56
Train function
Loss = 6.1050e-05, PNorm = 67.3402, GNorm = 0.2855, lr_0 = 2.7331e-04
Loss = 7.3072e-05, PNorm = 67.3434, GNorm = 0.2307, lr_0 = 2.7210e-04
Loss = 8.8916e-05, PNorm = 67.3454, GNorm = 0.2785, lr_0 = 2.7090e-04
Loss = 6.3991e-05, PNorm = 67.3499, GNorm = 0.4848, lr_0 = 2.6970e-04
Loss = 7.4985e-05, PNorm = 67.3546, GNorm = 0.2632, lr_0 = 2.6851e-04
Validation rmse logD = 0.560620
Validation R2 logD = 0.772184
Validation rmse logP = 0.806998
Validation R2 logP = 0.688983
Epoch 57
Train function
Loss = 5.2940e-05, PNorm = 67.3601, GNorm = 0.1401, lr_0 = 2.6720e-04
Loss = 5.0404e-05, PNorm = 67.3631, GNorm = 0.1228, lr_0 = 2.6602e-04
Loss = 5.7080e-05, PNorm = 67.3680, GNorm = 0.2032, lr_0 = 2.6484e-04
Loss = 6.6169e-05, PNorm = 67.3737, GNorm = 0.1520, lr_0 = 2.6367e-04
Loss = 4.9885e-05, PNorm = 67.3766, GNorm = 0.4685, lr_0 = 2.6250e-04
Validation rmse logD = 0.562139
Validation R2 logD = 0.770948
Validation rmse logP = 0.825372
Validation R2 logP = 0.674659
Epoch 58
Train function
Loss = 5.2462e-05, PNorm = 67.3803, GNorm = 0.4172, lr_0 = 2.6123e-04
Loss = 1.0878e-04, PNorm = 67.3852, GNorm = 0.2440, lr_0 = 2.6007e-04
Loss = 8.3646e-05, PNorm = 67.3874, GNorm = 0.1810, lr_0 = 2.5892e-04
Loss = 7.9848e-05, PNorm = 67.3949, GNorm = 0.1322, lr_0 = 2.5778e-04
Loss = 5.3478e-05, PNorm = 67.4019, GNorm = 0.1544, lr_0 = 2.5664e-04
Loss = 4.7884e-05, PNorm = 67.4077, GNorm = 0.2025, lr_0 = 2.5550e-04
Validation rmse logD = 0.562211
Validation R2 logD = 0.770890
Validation rmse logP = 0.820376
Validation R2 logP = 0.678586
Epoch 59
Train function
Loss = 4.2064e-05, PNorm = 67.4110, GNorm = 0.3394, lr_0 = 2.5426e-04
Loss = 6.2543e-05, PNorm = 67.4129, GNorm = 0.2401, lr_0 = 2.5313e-04
Loss = 5.1556e-05, PNorm = 67.4156, GNorm = 0.2192, lr_0 = 2.5201e-04
Loss = 5.2380e-05, PNorm = 67.4205, GNorm = 0.2938, lr_0 = 2.5090e-04
Loss = 5.1886e-05, PNorm = 67.4235, GNorm = 0.4089, lr_0 = 2.4979e-04
Validation rmse logD = 0.562377
Validation R2 logD = 0.770755
Validation rmse logP = 0.817097
Validation R2 logP = 0.681150
Epoch 60
Train function
Loss = 5.7921e-05, PNorm = 67.4255, GNorm = 0.3186, lr_0 = 2.4868e-04
Loss = 5.8509e-05, PNorm = 67.4286, GNorm = 0.5925, lr_0 = 2.4758e-04
Loss = 4.8372e-05, PNorm = 67.4328, GNorm = 0.1123, lr_0 = 2.4649e-04
Loss = 5.2150e-05, PNorm = 67.4366, GNorm = 0.2552, lr_0 = 2.4540e-04
Loss = 4.5396e-05, PNorm = 67.4384, GNorm = 0.3150, lr_0 = 2.4431e-04
Validation rmse logD = 0.558003
Validation R2 logD = 0.774307
Validation rmse logP = 0.819181
Validation R2 logP = 0.679521
Epoch 61
Train function
Loss = 3.0914e-05, PNorm = 67.4424, GNorm = 0.1602, lr_0 = 2.4313e-04
Loss = 4.4103e-05, PNorm = 67.4462, GNorm = 0.1195, lr_0 = 2.4205e-04
Loss = 4.2834e-05, PNorm = 67.4488, GNorm = 0.0946, lr_0 = 2.4098e-04
Loss = 4.6572e-05, PNorm = 67.4517, GNorm = 0.1395, lr_0 = 2.3991e-04
Loss = 4.4719e-05, PNorm = 67.4558, GNorm = 0.1303, lr_0 = 2.3885e-04
Loss = 4.5088e-05, PNorm = 67.4599, GNorm = 0.1467, lr_0 = 2.3780e-04
Validation rmse logD = 0.563529
Validation R2 logD = 0.769814
Validation rmse logP = 0.821131
Validation R2 logP = 0.677993
Epoch 62
Train function
Loss = 3.8019e-05, PNorm = 67.4642, GNorm = 0.2353, lr_0 = 2.3664e-04
Loss = 4.7617e-05, PNorm = 67.4670, GNorm = 0.4288, lr_0 = 2.3559e-04
Loss = 5.5972e-05, PNorm = 67.4686, GNorm = 0.5820, lr_0 = 2.3455e-04
Loss = 5.0242e-05, PNorm = 67.4713, GNorm = 0.3051, lr_0 = 2.3351e-04
Loss = 3.8876e-05, PNorm = 67.4746, GNorm = 0.2292, lr_0 = 2.3248e-04
Validation rmse logD = 0.563509
Validation R2 logD = 0.769831
Validation rmse logP = 0.820647
Validation R2 logP = 0.678373
Epoch 63
Train function
Loss = 6.8131e-05, PNorm = 67.4782, GNorm = 0.3832, lr_0 = 2.3135e-04
Loss = 6.5623e-05, PNorm = 67.4842, GNorm = 0.1209, lr_0 = 2.3033e-04
Loss = 3.6395e-05, PNorm = 67.4881, GNorm = 0.1941, lr_0 = 2.2931e-04
Loss = 3.5275e-05, PNorm = 67.4914, GNorm = 0.1609, lr_0 = 2.2829e-04
Loss = 6.2853e-05, PNorm = 67.4942, GNorm = 0.4463, lr_0 = 2.2728e-04
Validation rmse logD = 0.561470
Validation R2 logD = 0.771494
Validation rmse logP = 0.820948
Validation R2 logP = 0.678137
Epoch 64
Train function
Loss = 2.9297e-05, PNorm = 67.4979, GNorm = 0.2571, lr_0 = 2.2618e-04
Loss = 3.7435e-05, PNorm = 67.4991, GNorm = 0.0921, lr_0 = 2.2518e-04
Loss = 3.8393e-05, PNorm = 67.5026, GNorm = 0.1451, lr_0 = 2.2418e-04
Loss = 3.2589e-05, PNorm = 67.5052, GNorm = 0.1352, lr_0 = 2.2319e-04
Loss = 3.6867e-05, PNorm = 67.5076, GNorm = 0.0921, lr_0 = 2.2220e-04
Loss = 3.1165e-05, PNorm = 67.5093, GNorm = 0.2947, lr_0 = 2.2122e-04
Validation rmse logD = 0.559882
Validation R2 logD = 0.772784
Validation rmse logP = 0.812858
Validation R2 logP = 0.684449
Epoch 65
Train function
Loss = 3.9195e-05, PNorm = 67.5130, GNorm = 0.1487, lr_0 = 2.2014e-04
Loss = 3.4234e-05, PNorm = 67.5146, GNorm = 0.1382, lr_0 = 2.1917e-04
Loss = 3.2677e-05, PNorm = 67.5178, GNorm = 0.1191, lr_0 = 2.1820e-04
Loss = 3.7514e-05, PNorm = 67.5195, GNorm = 0.2796, lr_0 = 2.1723e-04
Loss = 4.0952e-05, PNorm = 67.5233, GNorm = 0.3517, lr_0 = 2.1627e-04
Validation rmse logD = 0.563619
Validation R2 logD = 0.769741
Validation rmse logP = 0.816991
Validation R2 logP = 0.681232
Epoch 66
Train function
Loss = 2.7024e-05, PNorm = 67.5264, GNorm = 0.0643, lr_0 = 2.1522e-04
Loss = 2.9670e-05, PNorm = 67.5281, GNorm = 0.1149, lr_0 = 2.1427e-04
Loss = 3.0609e-05, PNorm = 67.5316, GNorm = 0.2534, lr_0 = 2.1332e-04
Loss = 2.5512e-05, PNorm = 67.5321, GNorm = 0.1963, lr_0 = 2.1238e-04
Loss = 3.1125e-05, PNorm = 67.5345, GNorm = 0.3220, lr_0 = 2.1144e-04
Validation rmse logD = 0.561920
Validation R2 logD = 0.771127
Validation rmse logP = 0.817916
Validation R2 logP = 0.680510
Epoch 67
Train function
Loss = 3.5735e-05, PNorm = 67.5373, GNorm = 0.1604, lr_0 = 2.1041e-04
Loss = 3.2468e-05, PNorm = 67.5386, GNorm = 0.0840, lr_0 = 2.0948e-04
Loss = 3.1656e-05, PNorm = 67.5424, GNorm = 0.1438, lr_0 = 2.0855e-04
Loss = 3.1184e-05, PNorm = 67.5439, GNorm = 0.1428, lr_0 = 2.0763e-04
Loss = 3.5387e-05, PNorm = 67.5480, GNorm = 0.1760, lr_0 = 2.0671e-04
Loss = 2.5291e-05, PNorm = 67.5510, GNorm = 0.1374, lr_0 = 2.0580e-04
Loss = 2.1465e-04, PNorm = 67.5513, GNorm = 0.2540, lr_0 = 2.0571e-04
Validation rmse logD = 0.563754
Validation R2 logD = 0.769631
Validation rmse logP = 0.812267
Validation R2 logP = 0.684908
Epoch 68
Train function
Loss = 3.0408e-05, PNorm = 67.5538, GNorm = 0.2525, lr_0 = 2.0480e-04
Loss = 3.3032e-05, PNorm = 67.5565, GNorm = 0.2220, lr_0 = 2.0389e-04
Loss = 2.4238e-05, PNorm = 67.5589, GNorm = 0.0992, lr_0 = 2.0299e-04
Loss = 3.1857e-05, PNorm = 67.5619, GNorm = 0.2863, lr_0 = 2.0209e-04
Loss = 3.4113e-05, PNorm = 67.5633, GNorm = 0.3177, lr_0 = 2.0120e-04
Validation rmse logD = 0.561287
Validation R2 logD = 0.771643
Validation rmse logP = 0.817668
Validation R2 logP = 0.680704
Epoch 69
Train function
Loss = 5.4369e-05, PNorm = 67.5653, GNorm = 0.2521, lr_0 = 2.0022e-04
Loss = 4.0955e-05, PNorm = 67.5703, GNorm = 0.1635, lr_0 = 1.9933e-04
Loss = 4.2064e-05, PNorm = 67.5736, GNorm = 0.2937, lr_0 = 1.9845e-04
Loss = 3.7080e-05, PNorm = 67.5768, GNorm = 0.3536, lr_0 = 1.9757e-04
Loss = 5.4389e-05, PNorm = 67.5796, GNorm = 0.4932, lr_0 = 1.9670e-04
Validation rmse logD = 0.562765
Validation R2 logD = 0.770438
Validation rmse logP = 0.814986
Validation R2 logP = 0.682795
Epoch 70
Train function
Loss = 3.1492e-05, PNorm = 67.5840, GNorm = 0.2465, lr_0 = 1.9583e-04
Loss = 3.6953e-05, PNorm = 67.5860, GNorm = 0.2205, lr_0 = 1.9496e-04
Loss = 4.8282e-05, PNorm = 67.5871, GNorm = 0.1076, lr_0 = 1.9410e-04
Loss = 3.5276e-05, PNorm = 67.5898, GNorm = 0.0995, lr_0 = 1.9324e-04
Loss = 4.0543e-05, PNorm = 67.5922, GNorm = 0.1729, lr_0 = 1.9239e-04
Loss = 3.9327e-05, PNorm = 67.5948, GNorm = 0.2392, lr_0 = 1.9154e-04
Loss = 2.0158e-04, PNorm = 67.5951, GNorm = 0.2881, lr_0 = 1.9145e-04
Validation rmse logD = 0.561921
Validation R2 logD = 0.771126
Validation rmse logP = 0.818925
Validation R2 logP = 0.679721
Epoch 71
Train function
Loss = 2.3974e-05, PNorm = 67.5977, GNorm = 0.2007, lr_0 = 1.9060e-04
Loss = 2.7994e-05, PNorm = 67.6000, GNorm = 0.1441, lr_0 = 1.8976e-04
Loss = 2.3517e-05, PNorm = 67.6017, GNorm = 0.1145, lr_0 = 1.8892e-04
Loss = 2.2649e-05, PNorm = 67.6027, GNorm = 0.0931, lr_0 = 1.8809e-04
Loss = 2.7439e-05, PNorm = 67.6040, GNorm = 0.1632, lr_0 = 1.8725e-04
Validation rmse logD = 0.563203
Validation R2 logD = 0.770081
Validation rmse logP = 0.816872
Validation R2 logP = 0.681325
Epoch 72
Train function
Loss = 1.7599e-05, PNorm = 67.6051, GNorm = 0.0764, lr_0 = 1.8634e-04
Loss = 1.9479e-05, PNorm = 67.6063, GNorm = 0.0777, lr_0 = 1.8552e-04
Loss = 2.2345e-05, PNorm = 67.6081, GNorm = 0.1979, lr_0 = 1.8470e-04
Loss = 1.8010e-05, PNorm = 67.6115, GNorm = 0.1455, lr_0 = 1.8388e-04
Loss = 2.2027e-05, PNorm = 67.6132, GNorm = 0.1106, lr_0 = 1.8307e-04
Validation rmse logD = 0.560552
Validation R2 logD = 0.772240
Validation rmse logP = 0.818680
Validation R2 logP = 0.679913
Epoch 73
Train function
Loss = 1.5984e-05, PNorm = 67.6157, GNorm = 0.1100, lr_0 = 1.8218e-04
Loss = 2.4373e-05, PNorm = 67.6183, GNorm = 0.0948, lr_0 = 1.8137e-04
Loss = 1.6514e-05, PNorm = 67.6192, GNorm = 0.0801, lr_0 = 1.8057e-04
Loss = 1.5586e-05, PNorm = 67.6204, GNorm = 0.1344, lr_0 = 1.7977e-04
Loss = 1.9158e-05, PNorm = 67.6222, GNorm = 0.0515, lr_0 = 1.7897e-04
Validation rmse logD = 0.563591
Validation R2 logD = 0.769764
Validation rmse logP = 0.819027
Validation R2 logP = 0.679641
Epoch 74
Train function
Loss = 1.8641e-05, PNorm = 67.6237, GNorm = 0.1901, lr_0 = 1.7810e-04
Loss = 1.5419e-05, PNorm = 67.6243, GNorm = 0.0750, lr_0 = 1.7732e-04
Loss = 1.8896e-05, PNorm = 67.6259, GNorm = 0.0748, lr_0 = 1.7653e-04
Loss = 2.8346e-05, PNorm = 67.6292, GNorm = 0.1653, lr_0 = 1.7575e-04
Loss = 1.4068e-05, PNorm = 67.6313, GNorm = 0.1177, lr_0 = 1.7497e-04
Loss = 1.6760e-05, PNorm = 67.6327, GNorm = 0.0903, lr_0 = 1.7420e-04
Validation rmse logD = 0.562329
Validation R2 logD = 0.770794
Validation rmse logP = 0.814709
Validation R2 logP = 0.683010
Epoch 75
Train function
Loss = 1.4971e-05, PNorm = 67.6347, GNorm = 0.1122, lr_0 = 1.7335e-04
Loss = 1.9976e-05, PNorm = 67.6367, GNorm = 0.1847, lr_0 = 1.7259e-04
Loss = 1.5684e-05, PNorm = 67.6374, GNorm = 0.1376, lr_0 = 1.7182e-04
Loss = 1.8082e-05, PNorm = 67.6388, GNorm = 0.0822, lr_0 = 1.7106e-04
Loss = 1.9643e-05, PNorm = 67.6402, GNorm = 0.1616, lr_0 = 1.7031e-04
Validation rmse logD = 0.561253
Validation R2 logD = 0.771670
Validation rmse logP = 0.813212
Validation R2 logP = 0.684174
Epoch 76
Train function
Loss = 1.8136e-05, PNorm = 67.6416, GNorm = 0.1529, lr_0 = 1.6948e-04
Loss = 2.6232e-05, PNorm = 67.6435, GNorm = 0.2130, lr_0 = 1.6873e-04
Loss = 1.3938e-05, PNorm = 67.6458, GNorm = 0.1122, lr_0 = 1.6798e-04
Loss = 1.8063e-05, PNorm = 67.6475, GNorm = 0.0706, lr_0 = 1.6724e-04
Loss = 1.2660e-05, PNorm = 67.6486, GNorm = 0.0944, lr_0 = 1.6650e-04
Validation rmse logD = 0.562425
Validation R2 logD = 0.770716
Validation rmse logP = 0.818056
Validation R2 logP = 0.680401
Epoch 77
Train function
Loss = 8.9507e-06, PNorm = 67.6496, GNorm = 0.0631, lr_0 = 1.6569e-04
Loss = 1.7833e-05, PNorm = 67.6514, GNorm = 0.1188, lr_0 = 1.6496e-04
Loss = 1.6978e-05, PNorm = 67.6525, GNorm = 0.1425, lr_0 = 1.6423e-04
Loss = 2.0206e-05, PNorm = 67.6541, GNorm = 0.0817, lr_0 = 1.6350e-04
Loss = 1.3454e-05, PNorm = 67.6553, GNorm = 0.0752, lr_0 = 1.6278e-04
Loss = 1.2176e-05, PNorm = 67.6566, GNorm = 0.0819, lr_0 = 1.6206e-04
Validation rmse logD = 0.563706
Validation R2 logD = 0.769670
Validation rmse logP = 0.814379
Validation R2 logP = 0.683268
Epoch 78
Train function
Loss = 1.3039e-05, PNorm = 67.6585, GNorm = 0.1313, lr_0 = 1.6127e-04
Loss = 1.5610e-05, PNorm = 67.6606, GNorm = 0.1151, lr_0 = 1.6055e-04
Loss = 1.6664e-05, PNorm = 67.6616, GNorm = 0.1398, lr_0 = 1.5984e-04
Loss = 1.2303e-05, PNorm = 67.6632, GNorm = 0.0867, lr_0 = 1.5914e-04
Loss = 1.4268e-05, PNorm = 67.6638, GNorm = 0.0625, lr_0 = 1.5843e-04
Validation rmse logD = 0.563184
Validation R2 logD = 0.770096
Validation rmse logP = 0.817444
Validation R2 logP = 0.680879
Epoch 79
Train function
Loss = 1.2200e-05, PNorm = 67.6654, GNorm = 0.0781, lr_0 = 1.5766e-04
Loss = 1.2631e-05, PNorm = 67.6664, GNorm = 0.1417, lr_0 = 1.5697e-04
Loss = 1.6328e-05, PNorm = 67.6682, GNorm = 0.1665, lr_0 = 1.5627e-04
Loss = 1.5352e-05, PNorm = 67.6705, GNorm = 0.1105, lr_0 = 1.5558e-04
Loss = 1.3047e-05, PNorm = 67.6714, GNorm = 0.1212, lr_0 = 1.5489e-04
Validation rmse logD = 0.563019
Validation R2 logD = 0.770231
Validation rmse logP = 0.814873
Validation R2 logP = 0.682883
Epoch 80
Train function
Loss = 8.3895e-06, PNorm = 67.6730, GNorm = 0.1087, lr_0 = 1.5421e-04
Loss = 1.1629e-05, PNorm = 67.6745, GNorm = 0.0549, lr_0 = 1.5352e-04
Loss = 9.6597e-06, PNorm = 67.6759, GNorm = 0.1378, lr_0 = 1.5284e-04
Loss = 1.2856e-05, PNorm = 67.6771, GNorm = 0.0679, lr_0 = 1.5217e-04
Loss = 1.1667e-05, PNorm = 67.6775, GNorm = 0.1912, lr_0 = 1.5150e-04
Loss = 1.1965e-05, PNorm = 67.6786, GNorm = 0.0964, lr_0 = 1.5083e-04
Validation rmse logD = 0.564683
Validation R2 logD = 0.768871
Validation rmse logP = 0.812343
Validation R2 logP = 0.684849
Epoch 81
Train function
Loss = 1.7206e-05, PNorm = 67.6809, GNorm = 0.2305, lr_0 = 1.5009e-04
Loss = 2.3385e-05, PNorm = 67.6807, GNorm = 0.3870, lr_0 = 1.4943e-04
Loss = 1.7144e-05, PNorm = 67.6820, GNorm = 0.2049, lr_0 = 1.4877e-04
Loss = 1.6563e-05, PNorm = 67.6832, GNorm = 0.0804, lr_0 = 1.4811e-04
Loss = 1.5484e-05, PNorm = 67.6853, GNorm = 0.0634, lr_0 = 1.4745e-04
Validation rmse logD = 0.562956
Validation R2 logD = 0.770282
Validation rmse logP = 0.815213
Validation R2 logP = 0.682618
Epoch 82
Train function
Loss = 1.4995e-05, PNorm = 67.6881, GNorm = 0.2063, lr_0 = 1.4674e-04
Loss = 1.3318e-05, PNorm = 67.6889, GNorm = 0.0715, lr_0 = 1.4609e-04
Loss = 1.3158e-05, PNorm = 67.6903, GNorm = 0.0474, lr_0 = 1.4544e-04
Loss = 1.1238e-05, PNorm = 67.6912, GNorm = 0.0553, lr_0 = 1.4480e-04
Loss = 1.2342e-05, PNorm = 67.6930, GNorm = 0.0981, lr_0 = 1.4416e-04
Validation rmse logD = 0.564296
Validation R2 logD = 0.769187
Validation rmse logP = 0.813821
Validation R2 logP = 0.683701
Epoch 83
Train function
Loss = 1.2778e-05, PNorm = 67.6936, GNorm = 0.0522, lr_0 = 1.4346e-04
Loss = 1.3620e-05, PNorm = 67.6947, GNorm = 0.0587, lr_0 = 1.4282e-04
Loss = 1.1264e-05, PNorm = 67.6967, GNorm = 0.0698, lr_0 = 1.4219e-04
Loss = 1.4596e-05, PNorm = 67.6976, GNorm = 0.2211, lr_0 = 1.4156e-04
Loss = 1.5460e-05, PNorm = 67.6988, GNorm = 0.2279, lr_0 = 1.4093e-04
Loss = 2.0440e-05, PNorm = 67.7003, GNorm = 0.0489, lr_0 = 1.4031e-04
Loss = 5.6882e-04, PNorm = 67.7003, GNorm = 0.3503, lr_0 = 1.4025e-04
Validation rmse logD = 0.564880
Validation R2 logD = 0.768710
Validation rmse logP = 0.816586
Validation R2 logP = 0.681548
Epoch 84
Train function
Loss = 2.0763e-05, PNorm = 67.7019, GNorm = 0.0833, lr_0 = 1.3963e-04
Loss = 1.7653e-05, PNorm = 67.7041, GNorm = 0.0761, lr_0 = 1.3901e-04
Loss = 1.8700e-05, PNorm = 67.7055, GNorm = 0.0839, lr_0 = 1.3840e-04
Loss = 2.2744e-05, PNorm = 67.7071, GNorm = 0.1844, lr_0 = 1.3778e-04
Loss = 1.5115e-05, PNorm = 67.7095, GNorm = 0.0845, lr_0 = 1.3717e-04
Validation rmse logD = 0.564527
Validation R2 logD = 0.768998
Validation rmse logP = 0.815342
Validation R2 logP = 0.682518
Epoch 85
Train function
Loss = 1.1945e-05, PNorm = 67.7099, GNorm = 0.1397, lr_0 = 1.3651e-04
Loss = 1.2420e-05, PNorm = 67.7110, GNorm = 0.0793, lr_0 = 1.3590e-04
Loss = 1.4785e-05, PNorm = 67.7134, GNorm = 0.0908, lr_0 = 1.3530e-04
Loss = 1.2865e-05, PNorm = 67.7144, GNorm = 0.1410, lr_0 = 1.3470e-04
Loss = 1.3305e-05, PNorm = 67.7150, GNorm = 0.0800, lr_0 = 1.3411e-04
Validation rmse logD = 0.563017
Validation R2 logD = 0.770233
Validation rmse logP = 0.812859
Validation R2 logP = 0.684448
Epoch 86
Train function
Loss = 9.4389e-06, PNorm = 67.7161, GNorm = 0.1940, lr_0 = 1.3346e-04
Loss = 9.2576e-06, PNorm = 67.7171, GNorm = 0.1451, lr_0 = 1.3287e-04
Loss = 1.1138e-05, PNorm = 67.7177, GNorm = 0.1134, lr_0 = 1.3228e-04
Loss = 1.0576e-05, PNorm = 67.7189, GNorm = 0.0862, lr_0 = 1.3169e-04
Loss = 1.0950e-05, PNorm = 67.7199, GNorm = 0.0823, lr_0 = 1.3111e-04
Validation rmse logD = 0.563511
Validation R2 logD = 0.769829
Validation rmse logP = 0.817239
Validation R2 logP = 0.681039
Epoch 87
Train function
Loss = 1.0195e-05, PNorm = 67.7209, GNorm = 0.1618, lr_0 = 1.3047e-04
Loss = 9.7988e-06, PNorm = 67.7222, GNorm = 0.1242, lr_0 = 1.2990e-04
Loss = 8.0587e-06, PNorm = 67.7231, GNorm = 0.1045, lr_0 = 1.2932e-04
Loss = 7.8543e-06, PNorm = 67.7244, GNorm = 0.0551, lr_0 = 1.2875e-04
Loss = 1.0971e-05, PNorm = 67.7251, GNorm = 0.0891, lr_0 = 1.2818e-04
Loss = 9.8543e-06, PNorm = 67.7257, GNorm = 0.0531, lr_0 = 1.2761e-04
Validation rmse logD = 0.561605
Validation R2 logD = 0.771384
Validation rmse logP = 0.816320
Validation R2 logP = 0.681756
Epoch 88
Train function
Loss = 8.6200e-06, PNorm = 67.7263, GNorm = 0.1121, lr_0 = 1.2699e-04
Loss = 8.2068e-06, PNorm = 67.7281, GNorm = 0.0754, lr_0 = 1.2643e-04
Loss = 7.2943e-06, PNorm = 67.7293, GNorm = 0.0595, lr_0 = 1.2587e-04
Loss = 1.1591e-05, PNorm = 67.7303, GNorm = 0.1025, lr_0 = 1.2531e-04
Loss = 1.0157e-05, PNorm = 67.7316, GNorm = 0.0519, lr_0 = 1.2476e-04
Validation rmse logD = 0.562905
Validation R2 logD = 0.770324
Validation rmse logP = 0.815595
Validation R2 logP = 0.682321
Epoch 89
Train function
Loss = 8.6281e-06, PNorm = 67.7323, GNorm = 0.2027, lr_0 = 1.2415e-04
Loss = 8.1269e-06, PNorm = 67.7330, GNorm = 0.1964, lr_0 = 1.2360e-04
Loss = 8.5979e-06, PNorm = 67.7333, GNorm = 0.2094, lr_0 = 1.2306e-04
Loss = 7.1450e-06, PNorm = 67.7345, GNorm = 0.0632, lr_0 = 1.2251e-04
Loss = 7.9148e-06, PNorm = 67.7356, GNorm = 0.0335, lr_0 = 1.2197e-04
Validation rmse logD = 0.563274
Validation R2 logD = 0.770023
Validation rmse logP = 0.816430
Validation R2 logP = 0.681670
Epoch 90
Train function
Loss = 5.8322e-06, PNorm = 67.7361, GNorm = 0.0561, lr_0 = 1.2143e-04
Loss = 9.1036e-06, PNorm = 67.7369, GNorm = 0.0599, lr_0 = 1.2089e-04
Loss = 4.8144e-06, PNorm = 67.7372, GNorm = 0.1052, lr_0 = 1.2036e-04
Loss = 5.9686e-06, PNorm = 67.7379, GNorm = 0.1048, lr_0 = 1.1983e-04
Loss = 1.0272e-05, PNorm = 67.7388, GNorm = 0.0665, lr_0 = 1.1930e-04
Loss = 8.9052e-06, PNorm = 67.7394, GNorm = 0.0547, lr_0 = 1.1877e-04
Validation rmse logD = 0.564713
Validation R2 logD = 0.768846
Validation rmse logP = 0.816089
Validation R2 logP = 0.681936
Epoch 91
Train function
Loss = 5.4652e-06, PNorm = 67.7407, GNorm = 0.0415, lr_0 = 1.1819e-04
Loss = 7.0614e-06, PNorm = 67.7421, GNorm = 0.1737, lr_0 = 1.1767e-04
Loss = 7.7709e-06, PNorm = 67.7435, GNorm = 0.1715, lr_0 = 1.1715e-04
Loss = 7.1615e-06, PNorm = 67.7437, GNorm = 0.1104, lr_0 = 1.1663e-04
Loss = 7.7014e-06, PNorm = 67.7438, GNorm = 0.0673, lr_0 = 1.1611e-04
Validation rmse logD = 0.562572
Validation R2 logD = 0.770595
Validation rmse logP = 0.817267
Validation R2 logP = 0.681017
Epoch 92
Train function
Loss = 7.4232e-06, PNorm = 67.7444, GNorm = 0.0814, lr_0 = 1.1555e-04
Loss = 1.1521e-05, PNorm = 67.7457, GNorm = 0.1474, lr_0 = 1.1504e-04
Loss = 6.8459e-06, PNorm = 67.7466, GNorm = 0.0855, lr_0 = 1.1453e-04
Loss = 8.9386e-06, PNorm = 67.7473, GNorm = 0.0966, lr_0 = 1.1402e-04
Loss = 1.0912e-05, PNorm = 67.7478, GNorm = 0.0969, lr_0 = 1.1352e-04
Validation rmse logD = 0.563638
Validation R2 logD = 0.769726
Validation rmse logP = 0.817164
Validation R2 logP = 0.681097
Epoch 93
Train function
Loss = 8.3484e-06, PNorm = 67.7488, GNorm = 0.1573, lr_0 = 1.1297e-04
Loss = 7.5890e-06, PNorm = 67.7493, GNorm = 0.0450, lr_0 = 1.1247e-04
Loss = 5.8925e-06, PNorm = 67.7499, GNorm = 0.0630, lr_0 = 1.1197e-04
Loss = 6.7404e-06, PNorm = 67.7509, GNorm = 0.0506, lr_0 = 1.1147e-04
Loss = 9.4855e-06, PNorm = 67.7522, GNorm = 0.0456, lr_0 = 1.1098e-04
Loss = 5.0297e-06, PNorm = 67.7530, GNorm = 0.0475, lr_0 = 1.1049e-04
Validation rmse logD = 0.563513
Validation R2 logD = 0.769828
Validation rmse logP = 0.816583
Validation R2 logP = 0.681551
Epoch 94
Train function
Loss = 7.0673e-06, PNorm = 67.7540, GNorm = 0.0495, lr_0 = 1.0995e-04
Loss = 8.8365e-06, PNorm = 67.7546, GNorm = 0.1289, lr_0 = 1.0947e-04
Loss = 7.2305e-06, PNorm = 67.7562, GNorm = 0.0485, lr_0 = 1.0898e-04
Loss = 1.1690e-05, PNorm = 67.7565, GNorm = 0.1083, lr_0 = 1.0850e-04
Loss = 8.3996e-06, PNorm = 67.7583, GNorm = 0.0716, lr_0 = 1.0802e-04
Validation rmse logD = 0.562876
Validation R2 logD = 0.770347
Validation rmse logP = 0.814366
Validation R2 logP = 0.683278
Epoch 95
Train function
Loss = 1.0843e-05, PNorm = 67.7588, GNorm = 0.2548, lr_0 = 1.0749e-04
Loss = 1.0456e-05, PNorm = 67.7603, GNorm = 0.0907, lr_0 = 1.0702e-04
Loss = 8.6297e-06, PNorm = 67.7605, GNorm = 0.1108, lr_0 = 1.0654e-04
Loss = 9.5722e-06, PNorm = 67.7611, GNorm = 0.1074, lr_0 = 1.0607e-04
Loss = 7.8902e-06, PNorm = 67.7620, GNorm = 0.1917, lr_0 = 1.0560e-04
Validation rmse logD = 0.562813
Validation R2 logD = 0.770399
Validation rmse logP = 0.813826
Validation R2 logP = 0.683697
Epoch 96
Train function
Loss = 6.2312e-06, PNorm = 67.7631, GNorm = 0.0580, lr_0 = 1.0509e-04
Loss = 6.9893e-06, PNorm = 67.7639, GNorm = 0.0615, lr_0 = 1.0463e-04
Loss = 6.1965e-06, PNorm = 67.7645, GNorm = 0.0502, lr_0 = 1.0416e-04
Loss = 6.3041e-06, PNorm = 67.7645, GNorm = 0.0538, lr_0 = 1.0370e-04
Loss = 5.9040e-06, PNorm = 67.7657, GNorm = 0.0854, lr_0 = 1.0324e-04
Loss = 6.1802e-06, PNorm = 67.7658, GNorm = 0.1322, lr_0 = 1.0279e-04
Loss = 5.1234e-05, PNorm = 67.7660, GNorm = 0.1136, lr_0 = 1.0274e-04
Validation rmse logD = 0.563277
Validation R2 logD = 0.770020
Validation rmse logP = 0.815804
Validation R2 logP = 0.682158
Epoch 97
Train function
Loss = 5.1244e-06, PNorm = 67.7667, GNorm = 0.0380, lr_0 = 1.0229e-04
Loss = 4.8550e-06, PNorm = 67.7671, GNorm = 0.0444, lr_0 = 1.0183e-04
Loss = 4.6481e-06, PNorm = 67.7679, GNorm = 0.0918, lr_0 = 1.0138e-04
Loss = 5.1667e-06, PNorm = 67.7683, GNorm = 0.0414, lr_0 = 1.0094e-04
Loss = 6.7745e-06, PNorm = 67.7693, GNorm = 0.0423, lr_0 = 1.0049e-04
Validation rmse logD = 0.562183
Validation R2 logD = 0.770913
Validation rmse logP = 0.814662
Validation R2 logP = 0.683047
Epoch 98
Train function
Loss = 4.5865e-06, PNorm = 67.7705, GNorm = 0.0265, lr_0 = 1.0000e-04
Loss = 5.5480e-06, PNorm = 67.7716, GNorm = 0.0380, lr_0 = 1.0000e-04
Loss = 4.4311e-06, PNorm = 67.7719, GNorm = 0.0415, lr_0 = 1.0000e-04
Loss = 4.2566e-06, PNorm = 67.7725, GNorm = 0.0323, lr_0 = 1.0000e-04
Loss = 6.1006e-06, PNorm = 67.7731, GNorm = 0.0365, lr_0 = 1.0000e-04
Validation rmse logD = 0.563517
Validation R2 logD = 0.769824
Validation rmse logP = 0.815836
Validation R2 logP = 0.682133
Epoch 99
Train function
Loss = 4.2799e-06, PNorm = 67.7740, GNorm = 0.0751, lr_0 = 1.0000e-04
Loss = 3.5893e-06, PNorm = 67.7743, GNorm = 0.0236, lr_0 = 1.0000e-04
Loss = 5.5964e-06, PNorm = 67.7748, GNorm = 0.1227, lr_0 = 1.0000e-04
Loss = 4.7086e-06, PNorm = 67.7754, GNorm = 0.0361, lr_0 = 1.0000e-04
Loss = 5.6677e-06, PNorm = 67.7757, GNorm = 0.0364, lr_0 = 1.0000e-04
Loss = 3.8873e-06, PNorm = 67.7761, GNorm = 0.0700, lr_0 = 1.0000e-04
Validation rmse logD = 0.563227
Validation R2 logD = 0.770061
Validation rmse logP = 0.814336
Validation R2 logP = 0.683301
Model 0 best validation rmse = 0.677371 on epoch 32
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.628230
Model 0 test R2 logD = 0.722812
Model 0 test rmse logP = 0.783910
Model 0 test R2 logP = 0.734649
Ensemble test rmse  logD= 0.628230
Ensemble test R2  logD= 0.722812
Ensemble test rmse  logP= 0.783910
Ensemble test R2  logP= 0.734649
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2655,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 1.9735e-02, PNorm = 55.5671, GNorm = 7.2435, lr_0 = 1.9340e-04
Loss = 1.8497e-02, PNorm = 55.5771, GNorm = 3.7551, lr_0 = 2.7830e-04
Loss = 1.7021e-02, PNorm = 55.5942, GNorm = 6.6771, lr_0 = 3.6321e-04
Loss = 1.5841e-02, PNorm = 55.6146, GNorm = 5.0473, lr_0 = 4.4811e-04
Loss = 1.7747e-02, PNorm = 55.6439, GNorm = 6.0155, lr_0 = 5.3302e-04
Validation rmse logD = 1.055961
Validation R2 logD = 0.235435
Validation rmse logP = 1.302800
Validation R2 logP = 0.164543
Epoch 1
Train function
Loss = 1.4465e-02, PNorm = 55.6871, GNorm = 4.9260, lr_0 = 6.2642e-04
Loss = 1.3472e-02, PNorm = 55.7398, GNorm = 1.6917, lr_0 = 7.1132e-04
Loss = 1.3690e-02, PNorm = 55.8142, GNorm = 4.7818, lr_0 = 7.9623e-04
Loss = 1.4875e-02, PNorm = 55.8982, GNorm = 5.5382, lr_0 = 8.8113e-04
Loss = 1.4991e-02, PNorm = 56.0058, GNorm = 1.5034, lr_0 = 9.6604e-04
Validation rmse logD = 0.940566
Validation R2 logD = 0.393408
Validation rmse logP = 1.351435
Validation R2 logP = 0.101001
Epoch 2
Train function
Loss = 1.2672e-02, PNorm = 56.1480, GNorm = 1.7627, lr_0 = 9.9690e-04
Loss = 1.0616e-02, PNorm = 56.2784, GNorm = 0.8488, lr_0 = 9.9249e-04
Loss = 1.0239e-02, PNorm = 56.3858, GNorm = 4.4419, lr_0 = 9.8810e-04
Loss = 1.0531e-02, PNorm = 56.4975, GNorm = 2.1434, lr_0 = 9.8373e-04
Loss = 1.0985e-02, PNorm = 56.5983, GNorm = 1.6591, lr_0 = 9.7938e-04
Validation rmse logD = 0.879057
Validation R2 logD = 0.470151
Validation rmse logP = 0.891582
Validation R2 logP = 0.608716
Epoch 3
Train function
Loss = 6.2930e-03, PNorm = 56.7164, GNorm = 1.8467, lr_0 = 9.7462e-04
Loss = 1.0350e-02, PNorm = 56.8269, GNorm = 2.5926, lr_0 = 9.7030e-04
Loss = 8.9835e-03, PNorm = 56.9269, GNorm = 1.1694, lr_0 = 9.6601e-04
Loss = 8.7011e-03, PNorm = 57.0324, GNorm = 1.4545, lr_0 = 9.6174e-04
Loss = 8.6395e-03, PNorm = 57.1325, GNorm = 2.3094, lr_0 = 9.5749e-04
Loss = 8.9491e-03, PNorm = 57.2348, GNorm = 0.9073, lr_0 = 9.5325e-04
Validation rmse logD = 0.810006
Validation R2 logD = 0.550121
Validation rmse logP = 0.867038
Validation R2 logP = 0.629963
Epoch 4
Train function
Loss = 7.6298e-03, PNorm = 57.3250, GNorm = 2.3907, lr_0 = 9.4861e-04
Loss = 7.7178e-03, PNorm = 57.4165, GNorm = 0.8769, lr_0 = 9.4442e-04
Loss = 7.9772e-03, PNorm = 57.5057, GNorm = 1.5281, lr_0 = 9.4024e-04
Loss = 7.3589e-03, PNorm = 57.5936, GNorm = 1.0314, lr_0 = 9.3608e-04
Loss = 6.4854e-03, PNorm = 57.6850, GNorm = 1.8148, lr_0 = 9.3194e-04
Validation rmse logD = 0.958915
Validation R2 logD = 0.369509
Validation rmse logP = 0.890180
Validation R2 logP = 0.609946
Epoch 5
Train function
Loss = 8.7975e-03, PNorm = 57.7713, GNorm = 5.8092, lr_0 = 9.2741e-04
Loss = 7.8662e-03, PNorm = 57.8586, GNorm = 0.8485, lr_0 = 9.2330e-04
Loss = 7.2117e-03, PNorm = 57.9599, GNorm = 3.6403, lr_0 = 9.1922e-04
Loss = 6.4475e-03, PNorm = 58.0617, GNorm = 1.1200, lr_0 = 9.1515e-04
Loss = 6.6645e-03, PNorm = 58.1343, GNorm = 1.2468, lr_0 = 9.1111e-04
Validation rmse logD = 0.736688
Validation R2 logD = 0.627877
Validation rmse logP = 0.781139
Validation R2 logP = 0.699652
Epoch 6
Train function
Loss = 6.0938e-03, PNorm = 58.2377, GNorm = 1.9000, lr_0 = 9.0667e-04
Loss = 5.2515e-03, PNorm = 58.3375, GNorm = 1.1014, lr_0 = 9.0266e-04
Loss = 6.1213e-03, PNorm = 58.4098, GNorm = 3.1684, lr_0 = 8.9867e-04
Loss = 5.7126e-03, PNorm = 58.4930, GNorm = 4.0345, lr_0 = 8.9469e-04
Loss = 5.7056e-03, PNorm = 58.5790, GNorm = 0.9137, lr_0 = 8.9074e-04
Loss = 6.7234e-03, PNorm = 58.6801, GNorm = 1.0641, lr_0 = 8.8680e-04
Validation rmse logD = 0.741793
Validation R2 logD = 0.622702
Validation rmse logP = 0.763331
Validation R2 logP = 0.713190
Epoch 7
Train function
Loss = 6.1909e-03, PNorm = 58.7911, GNorm = 2.1388, lr_0 = 8.8248e-04
Loss = 6.1231e-03, PNorm = 58.8905, GNorm = 4.5487, lr_0 = 8.7858e-04
Loss = 5.2961e-03, PNorm = 58.9813, GNorm = 0.9117, lr_0 = 8.7469e-04
Loss = 5.2678e-03, PNorm = 59.0719, GNorm = 1.2950, lr_0 = 8.7082e-04
Loss = 4.8361e-03, PNorm = 59.1564, GNorm = 1.4404, lr_0 = 8.6697e-04
Validation rmse logD = 0.748118
Validation R2 logD = 0.616241
Validation rmse logP = 0.741345
Validation R2 logP = 0.729474
Epoch 8
Train function
Loss = 4.0896e-03, PNorm = 59.2693, GNorm = 1.5902, lr_0 = 8.6276e-04
Loss = 4.4994e-03, PNorm = 59.3702, GNorm = 1.4247, lr_0 = 8.5894e-04
Loss = 4.5142e-03, PNorm = 59.4433, GNorm = 3.3758, lr_0 = 8.5514e-04
Loss = 3.8167e-03, PNorm = 59.5216, GNorm = 1.0288, lr_0 = 8.5136e-04
Loss = 5.2349e-03, PNorm = 59.6059, GNorm = 2.2741, lr_0 = 8.4759e-04
Validation rmse logD = 0.688548
Validation R2 logD = 0.674923
Validation rmse logP = 0.734106
Validation R2 logP = 0.734731
Epoch 9
Train function
Loss = 3.5778e-03, PNorm = 59.7204, GNorm = 1.3569, lr_0 = 8.4384e-04
Loss = 3.9660e-03, PNorm = 59.8229, GNorm = 1.2281, lr_0 = 8.4011e-04
Loss = 3.6815e-03, PNorm = 59.9131, GNorm = 1.0677, lr_0 = 8.3639e-04
Loss = 4.1178e-03, PNorm = 60.0092, GNorm = 2.7483, lr_0 = 8.3269e-04
Loss = 3.9533e-03, PNorm = 60.0935, GNorm = 2.8836, lr_0 = 8.2901e-04
Loss = 4.8032e-03, PNorm = 60.1775, GNorm = 0.8870, lr_0 = 8.2534e-04
Validation rmse logD = 0.701524
Validation R2 logD = 0.662554
Validation rmse logP = 0.742343
Validation R2 logP = 0.728745
Epoch 10
Train function
Loss = 4.4051e-03, PNorm = 60.2794, GNorm = 2.2608, lr_0 = 8.2133e-04
Loss = 3.8920e-03, PNorm = 60.3788, GNorm = 1.2879, lr_0 = 8.1770e-04
Loss = 3.4370e-03, PNorm = 60.4749, GNorm = 1.1250, lr_0 = 8.1408e-04
Loss = 3.2624e-03, PNorm = 60.5581, GNorm = 2.0984, lr_0 = 8.1048e-04
Loss = 3.5794e-03, PNorm = 60.6377, GNorm = 2.3648, lr_0 = 8.0689e-04
Validation rmse logD = 0.650078
Validation R2 logD = 0.710233
Validation rmse logP = 0.792091
Validation R2 logP = 0.691170
Epoch 11
Train function
Loss = 3.1723e-03, PNorm = 60.7297, GNorm = 3.0393, lr_0 = 8.0297e-04
Loss = 3.0486e-03, PNorm = 60.8007, GNorm = 1.3330, lr_0 = 7.9942e-04
Loss = 2.7576e-03, PNorm = 60.8850, GNorm = 0.6246, lr_0 = 7.9588e-04
Loss = 2.7578e-03, PNorm = 60.9601, GNorm = 0.7177, lr_0 = 7.9236e-04
Loss = 3.5617e-03, PNorm = 61.0238, GNorm = 3.0067, lr_0 = 7.8885e-04
Validation rmse logD = 0.664592
Validation R2 logD = 0.697150
Validation rmse logP = 0.711931
Validation R2 logP = 0.750515
Epoch 12
Train function
Loss = 2.4909e-03, PNorm = 61.1179, GNorm = 0.8026, lr_0 = 7.8502e-04
Loss = 2.4160e-03, PNorm = 61.1850, GNorm = 0.8851, lr_0 = 7.8154e-04
Loss = 2.2334e-03, PNorm = 61.2636, GNorm = 0.6558, lr_0 = 7.7809e-04
Loss = 2.8174e-03, PNorm = 61.3469, GNorm = 0.8979, lr_0 = 7.7465e-04
Loss = 2.7453e-03, PNorm = 61.4276, GNorm = 0.8399, lr_0 = 7.7122e-04
Loss = 2.7962e-03, PNorm = 61.5191, GNorm = 0.7587, lr_0 = 7.6781e-04
Loss = 2.4615e-02, PNorm = 61.5282, GNorm = 3.9877, lr_0 = 7.6747e-04
Validation rmse logD = 0.640568
Validation R2 logD = 0.718649
Validation rmse logP = 0.725977
Validation R2 logP = 0.740573
Epoch 13
Train function
Loss = 2.2414e-03, PNorm = 61.6070, GNorm = 0.6820, lr_0 = 7.6407e-04
Loss = 2.9538e-03, PNorm = 61.6888, GNorm = 4.1070, lr_0 = 7.6069e-04
Loss = 3.0722e-03, PNorm = 61.7646, GNorm = 1.7737, lr_0 = 7.5733e-04
Loss = 2.2950e-03, PNorm = 61.8423, GNorm = 2.7430, lr_0 = 7.5398e-04
Loss = 2.4132e-03, PNorm = 61.9099, GNorm = 0.8526, lr_0 = 7.5064e-04
Validation rmse logD = 0.637767
Validation R2 logD = 0.721104
Validation rmse logP = 0.696157
Validation R2 logP = 0.761448
Epoch 14
Train function
Loss = 1.9722e-03, PNorm = 61.9949, GNorm = 0.7370, lr_0 = 7.4699e-04
Loss = 2.3415e-03, PNorm = 62.0631, GNorm = 0.7341, lr_0 = 7.4369e-04
Loss = 1.8635e-03, PNorm = 62.1245, GNorm = 1.5691, lr_0 = 7.4040e-04
Loss = 2.1449e-03, PNorm = 62.1886, GNorm = 1.2322, lr_0 = 7.3712e-04
Loss = 2.3389e-03, PNorm = 62.2483, GNorm = 1.1562, lr_0 = 7.3386e-04
Validation rmse logD = 0.647587
Validation R2 logD = 0.712449
Validation rmse logP = 0.686158
Validation R2 logP = 0.768252
Epoch 15
Train function
Loss = 1.5703e-03, PNorm = 62.3147, GNorm = 2.0577, lr_0 = 7.3029e-04
Loss = 1.7975e-03, PNorm = 62.3718, GNorm = 1.0847, lr_0 = 7.2706e-04
Loss = 1.8984e-03, PNorm = 62.4431, GNorm = 1.3371, lr_0 = 7.2385e-04
Loss = 1.7442e-03, PNorm = 62.5008, GNorm = 0.8152, lr_0 = 7.2064e-04
Loss = 2.2072e-03, PNorm = 62.5605, GNorm = 0.9201, lr_0 = 7.1746e-04
Validation rmse logD = 0.629484
Validation R2 logD = 0.728301
Validation rmse logP = 0.716745
Validation R2 logP = 0.747129
Epoch 16
Train function
Loss = 1.8713e-03, PNorm = 62.6320, GNorm = 2.4729, lr_0 = 7.1397e-04
Loss = 1.3741e-03, PNorm = 62.6945, GNorm = 0.8674, lr_0 = 7.1081e-04
Loss = 1.6890e-03, PNorm = 62.7537, GNorm = 1.5749, lr_0 = 7.0766e-04
Loss = 1.6364e-03, PNorm = 62.8031, GNorm = 1.3322, lr_0 = 7.0453e-04
Loss = 1.7794e-03, PNorm = 62.8626, GNorm = 1.6822, lr_0 = 7.0142e-04
Loss = 1.7125e-03, PNorm = 62.9256, GNorm = 1.1653, lr_0 = 6.9831e-04
Validation rmse logD = 0.635466
Validation R2 logD = 0.723112
Validation rmse logP = 0.718998
Validation R2 logP = 0.745538
Epoch 17
Train function
Loss = 1.2901e-03, PNorm = 62.9807, GNorm = 0.7761, lr_0 = 6.9523e-04
Loss = 1.3047e-03, PNorm = 63.0304, GNorm = 1.5877, lr_0 = 6.9215e-04
Loss = 1.3387e-03, PNorm = 63.0883, GNorm = 0.5512, lr_0 = 6.8909e-04
Loss = 1.3920e-03, PNorm = 63.1374, GNorm = 0.8890, lr_0 = 6.8604e-04
Loss = 1.3796e-03, PNorm = 63.1800, GNorm = 0.7627, lr_0 = 6.8301e-04
Validation rmse logD = 0.650890
Validation R2 logD = 0.709508
Validation rmse logP = 0.664417
Validation R2 logP = 0.782705
Epoch 18
Train function
Loss = 1.3740e-03, PNorm = 63.2423, GNorm = 1.5113, lr_0 = 6.7968e-04
Loss = 1.4685e-03, PNorm = 63.3037, GNorm = 1.3064, lr_0 = 6.7668e-04
Loss = 1.2261e-03, PNorm = 63.3627, GNorm = 0.7793, lr_0 = 6.7368e-04
Loss = 1.3043e-03, PNorm = 63.4111, GNorm = 1.9080, lr_0 = 6.7070e-04
Loss = 1.1758e-03, PNorm = 63.4565, GNorm = 0.5441, lr_0 = 6.6774e-04
Validation rmse logD = 0.625466
Validation R2 logD = 0.731758
Validation rmse logP = 0.725577
Validation R2 logP = 0.740859
Epoch 19
Train function
Loss = 1.5895e-03, PNorm = 63.4998, GNorm = 1.3531, lr_0 = 6.6449e-04
Loss = 9.7831e-04, PNorm = 63.5388, GNorm = 0.5738, lr_0 = 6.6155e-04
Loss = 1.0922e-03, PNorm = 63.5842, GNorm = 1.7141, lr_0 = 6.5862e-04
Loss = 1.4513e-03, PNorm = 63.6147, GNorm = 1.5522, lr_0 = 6.5571e-04
Loss = 1.2318e-03, PNorm = 63.6666, GNorm = 0.7305, lr_0 = 6.5281e-04
Loss = 1.1303e-03, PNorm = 63.7180, GNorm = 0.7182, lr_0 = 6.4992e-04
Validation rmse logD = 0.612616
Validation R2 logD = 0.742668
Validation rmse logP = 0.704202
Validation R2 logP = 0.755903
Epoch 20
Train function
Loss = 1.0354e-03, PNorm = 63.7649, GNorm = 0.8473, lr_0 = 6.4676e-04
Loss = 1.0452e-03, PNorm = 63.8053, GNorm = 0.7834, lr_0 = 6.4390e-04
Loss = 1.0653e-03, PNorm = 63.8466, GNorm = 1.0907, lr_0 = 6.4105e-04
Loss = 1.1790e-03, PNorm = 63.8880, GNorm = 2.0654, lr_0 = 6.3822e-04
Loss = 1.2708e-03, PNorm = 63.9376, GNorm = 3.1980, lr_0 = 6.3539e-04
Validation rmse logD = 0.609219
Validation R2 logD = 0.745513
Validation rmse logP = 0.673202
Validation R2 logP = 0.776921
Epoch 21
Train function
Loss = 8.3207e-04, PNorm = 63.9877, GNorm = 0.8830, lr_0 = 6.3230e-04
Loss = 1.0156e-03, PNorm = 64.0420, GNorm = 0.8920, lr_0 = 6.2950e-04
Loss = 9.7272e-04, PNorm = 64.0758, GNorm = 0.4085, lr_0 = 6.2672e-04
Loss = 8.9145e-04, PNorm = 64.1143, GNorm = 0.7907, lr_0 = 6.2395e-04
Loss = 1.0825e-03, PNorm = 64.1542, GNorm = 1.1896, lr_0 = 6.2119e-04
Validation rmse logD = 0.619554
Validation R2 logD = 0.736805
Validation rmse logP = 0.674420
Validation R2 logP = 0.776113
Epoch 22
Train function
Loss = 9.8531e-04, PNorm = 64.1974, GNorm = 1.0306, lr_0 = 6.1817e-04
Loss = 9.5659e-04, PNorm = 64.2496, GNorm = 0.4027, lr_0 = 6.1543e-04
Loss = 7.4728e-04, PNorm = 64.2826, GNorm = 0.8960, lr_0 = 6.1271e-04
Loss = 8.4369e-04, PNorm = 64.3106, GNorm = 0.9324, lr_0 = 6.1000e-04
Loss = 8.4485e-04, PNorm = 64.3394, GNorm = 0.9444, lr_0 = 6.0730e-04
Loss = 9.4820e-04, PNorm = 64.3784, GNorm = 2.3295, lr_0 = 6.0461e-04
Validation rmse logD = 0.641941
Validation R2 logD = 0.717441
Validation rmse logP = 0.714307
Validation R2 logP = 0.748847
Epoch 23
Train function
Loss = 1.1292e-03, PNorm = 64.4278, GNorm = 0.7323, lr_0 = 6.0167e-04
Loss = 1.0787e-03, PNorm = 64.4703, GNorm = 0.4083, lr_0 = 5.9901e-04
Loss = 9.8233e-04, PNorm = 64.5058, GNorm = 1.4405, lr_0 = 5.9636e-04
Loss = 9.4970e-04, PNorm = 64.5480, GNorm = 1.2672, lr_0 = 5.9372e-04
Loss = 8.4926e-04, PNorm = 64.5885, GNorm = 1.0640, lr_0 = 5.9110e-04
Validation rmse logD = 0.638095
Validation R2 logD = 0.720817
Validation rmse logP = 0.691035
Validation R2 logP = 0.764945
Epoch 24
Train function
Loss = 1.0669e-03, PNorm = 64.6188, GNorm = 0.7719, lr_0 = 5.8822e-04
Loss = 7.3438e-04, PNorm = 64.6525, GNorm = 1.2322, lr_0 = 5.8562e-04
Loss = 7.4447e-04, PNorm = 64.6826, GNorm = 1.2412, lr_0 = 5.8303e-04
Loss = 7.1727e-04, PNorm = 64.7130, GNorm = 0.6910, lr_0 = 5.8045e-04
Loss = 6.5476e-04, PNorm = 64.7388, GNorm = 1.4519, lr_0 = 5.7788e-04
Validation rmse logD = 0.605454
Validation R2 logD = 0.748649
Validation rmse logP = 0.697829
Validation R2 logP = 0.760300
Epoch 25
Train function
Loss = 4.4454e-04, PNorm = 64.7634, GNorm = 0.6862, lr_0 = 5.7533e-04
Loss = 5.8442e-04, PNorm = 64.7951, GNorm = 0.4628, lr_0 = 5.7278e-04
Loss = 5.3575e-04, PNorm = 64.8237, GNorm = 0.4314, lr_0 = 5.7025e-04
Loss = 5.3196e-04, PNorm = 64.8471, GNorm = 0.3343, lr_0 = 5.6773e-04
Loss = 7.2034e-04, PNorm = 64.8612, GNorm = 0.4317, lr_0 = 5.6522e-04
Loss = 7.2147e-04, PNorm = 64.8881, GNorm = 0.4645, lr_0 = 5.6272e-04
Validation rmse logD = 0.610322
Validation R2 logD = 0.744591
Validation rmse logP = 0.710131
Validation R2 logP = 0.751775
Epoch 26
Train function
Loss = 5.0222e-04, PNorm = 64.9120, GNorm = 0.9651, lr_0 = 5.5998e-04
Loss = 5.3566e-04, PNorm = 64.9418, GNorm = 1.0043, lr_0 = 5.5750e-04
Loss = 5.4778e-04, PNorm = 64.9678, GNorm = 0.4938, lr_0 = 5.5503e-04
Loss = 6.3024e-04, PNorm = 64.9920, GNorm = 1.3049, lr_0 = 5.5258e-04
Loss = 6.0036e-04, PNorm = 65.0234, GNorm = 0.3599, lr_0 = 5.5014e-04
Validation rmse logD = 0.606027
Validation R2 logD = 0.748173
Validation rmse logP = 0.676861
Validation R2 logP = 0.774489
Epoch 27
Train function
Loss = 5.4763e-04, PNorm = 65.0464, GNorm = 1.0496, lr_0 = 5.4746e-04
Loss = 5.1186e-04, PNorm = 65.0644, GNorm = 0.4814, lr_0 = 5.4504e-04
Loss = 4.1521e-04, PNorm = 65.0883, GNorm = 0.7358, lr_0 = 5.4263e-04
Loss = 5.0304e-04, PNorm = 65.1147, GNorm = 1.5395, lr_0 = 5.4023e-04
Loss = 6.3795e-04, PNorm = 65.1390, GNorm = 1.7724, lr_0 = 5.3784e-04
Validation rmse logD = 0.617962
Validation R2 logD = 0.738156
Validation rmse logP = 0.693645
Validation R2 logP = 0.763166
Epoch 28
Train function
Loss = 7.5917e-04, PNorm = 65.1719, GNorm = 1.4190, lr_0 = 5.3522e-04
Loss = 7.7418e-04, PNorm = 65.2068, GNorm = 1.1231, lr_0 = 5.3285e-04
Loss = 6.2792e-04, PNorm = 65.2406, GNorm = 0.7319, lr_0 = 5.3050e-04
Loss = 7.7183e-04, PNorm = 65.2660, GNorm = 1.2992, lr_0 = 5.2815e-04
Loss = 6.2202e-04, PNorm = 65.2929, GNorm = 1.2124, lr_0 = 5.2581e-04
Loss = 6.0678e-04, PNorm = 65.3276, GNorm = 1.2961, lr_0 = 5.2349e-04
Loss = 2.1898e-03, PNorm = 65.3302, GNorm = 0.7692, lr_0 = 5.2326e-04
Validation rmse logD = 0.603082
Validation R2 logD = 0.750614
Validation rmse logP = 0.644320
Validation R2 logP = 0.795651
Epoch 29
Train function
Loss = 4.7636e-04, PNorm = 65.3569, GNorm = 0.6742, lr_0 = 5.2094e-04
Loss = 4.4989e-04, PNorm = 65.3737, GNorm = 0.5294, lr_0 = 5.1864e-04
Loss = 5.8000e-04, PNorm = 65.3952, GNorm = 0.3588, lr_0 = 5.1634e-04
Loss = 4.1392e-04, PNorm = 65.4181, GNorm = 0.3528, lr_0 = 5.1406e-04
Loss = 3.6642e-04, PNorm = 65.4373, GNorm = 0.7584, lr_0 = 5.1178e-04
Validation rmse logD = 0.606827
Validation R2 logD = 0.747507
Validation rmse logP = 0.697806
Validation R2 logP = 0.760317
Epoch 30
Train function
Loss = 3.5862e-04, PNorm = 65.4639, GNorm = 0.5265, lr_0 = 5.0930e-04
Loss = 3.8136e-04, PNorm = 65.4802, GNorm = 0.4835, lr_0 = 5.0704e-04
Loss = 5.0471e-04, PNorm = 65.5004, GNorm = 1.0007, lr_0 = 5.0480e-04
Loss = 5.1280e-04, PNorm = 65.5226, GNorm = 0.8373, lr_0 = 5.0257e-04
Loss = 3.6317e-04, PNorm = 65.5425, GNorm = 0.3102, lr_0 = 5.0034e-04
Validation rmse logD = 0.599295
Validation R2 logD = 0.753736
Validation rmse logP = 0.684086
Validation R2 logP = 0.769649
Epoch 31
Train function
Loss = 3.3536e-04, PNorm = 65.5571, GNorm = 0.3130, lr_0 = 4.9791e-04
Loss = 3.8080e-04, PNorm = 65.5735, GNorm = 0.3590, lr_0 = 4.9571e-04
Loss = 2.7897e-04, PNorm = 65.5881, GNorm = 0.2644, lr_0 = 4.9351e-04
Loss = 3.6214e-04, PNorm = 65.6101, GNorm = 0.3320, lr_0 = 4.9133e-04
Loss = 3.1227e-04, PNorm = 65.6228, GNorm = 0.2099, lr_0 = 4.8916e-04
Validation rmse logD = 0.598155
Validation R2 logD = 0.754672
Validation rmse logP = 0.691926
Validation R2 logP = 0.764339
Epoch 32
Train function
Loss = 2.6380e-04, PNorm = 65.6336, GNorm = 0.4624, lr_0 = 4.8678e-04
Loss = 3.2139e-04, PNorm = 65.6514, GNorm = 0.2544, lr_0 = 4.8463e-04
Loss = 2.7845e-04, PNorm = 65.6700, GNorm = 0.3259, lr_0 = 4.8248e-04
Loss = 3.0899e-04, PNorm = 65.6823, GNorm = 0.2606, lr_0 = 4.8035e-04
Loss = 3.2062e-04, PNorm = 65.6966, GNorm = 0.4544, lr_0 = 4.7822e-04
Loss = 3.1663e-04, PNorm = 65.7134, GNorm = 0.4953, lr_0 = 4.7611e-04
Validation rmse logD = 0.604789
Validation R2 logD = 0.749200
Validation rmse logP = 0.688796
Validation R2 logP = 0.766466
Epoch 33
Train function
Loss = 3.2199e-04, PNorm = 65.7287, GNorm = 1.0326, lr_0 = 4.7379e-04
Loss = 3.1989e-04, PNorm = 65.7515, GNorm = 0.4419, lr_0 = 4.7170e-04
Loss = 3.7738e-04, PNorm = 65.7712, GNorm = 0.2548, lr_0 = 4.6961e-04
Loss = 2.8317e-04, PNorm = 65.7879, GNorm = 0.3137, lr_0 = 4.6753e-04
Loss = 3.5910e-04, PNorm = 65.8001, GNorm = 0.3058, lr_0 = 4.6546e-04
Validation rmse logD = 0.593467
Validation R2 logD = 0.758503
Validation rmse logP = 0.677167
Validation R2 logP = 0.774285
Epoch 34
Train function
Loss = 2.6178e-04, PNorm = 65.8151, GNorm = 0.5483, lr_0 = 4.6341e-04
Loss = 2.4388e-04, PNorm = 65.8283, GNorm = 0.2938, lr_0 = 4.6136e-04
Loss = 2.6059e-04, PNorm = 65.8397, GNorm = 0.2717, lr_0 = 4.5931e-04
Loss = 2.3899e-04, PNorm = 65.8500, GNorm = 0.4849, lr_0 = 4.5728e-04
Loss = 2.2417e-04, PNorm = 65.8592, GNorm = 0.6612, lr_0 = 4.5526e-04
Validation rmse logD = 0.601808
Validation R2 logD = 0.751667
Validation rmse logP = 0.693389
Validation R2 logP = 0.763341
Epoch 35
Train function
Loss = 1.1857e-04, PNorm = 65.8705, GNorm = 0.1747, lr_0 = 4.5305e-04
Loss = 1.8555e-04, PNorm = 65.8826, GNorm = 0.2747, lr_0 = 4.5104e-04
Loss = 2.4460e-04, PNorm = 65.8932, GNorm = 1.0300, lr_0 = 4.4905e-04
Loss = 1.7696e-04, PNorm = 65.9067, GNorm = 0.2788, lr_0 = 4.4706e-04
Loss = 2.3048e-04, PNorm = 65.9183, GNorm = 0.4549, lr_0 = 4.4508e-04
Loss = 2.4636e-04, PNorm = 65.9324, GNorm = 0.3525, lr_0 = 4.4311e-04
Validation rmse logD = 0.601300
Validation R2 logD = 0.752086
Validation rmse logP = 0.682376
Validation R2 logP = 0.770799
Epoch 36
Train function
Loss = 1.5821e-04, PNorm = 65.9468, GNorm = 0.3448, lr_0 = 4.4096e-04
Loss = 2.2030e-04, PNorm = 65.9619, GNorm = 0.9193, lr_0 = 4.3901e-04
Loss = 2.5672e-04, PNorm = 65.9683, GNorm = 0.5404, lr_0 = 4.3707e-04
Loss = 2.5694e-04, PNorm = 65.9850, GNorm = 0.7788, lr_0 = 4.3513e-04
Loss = 2.2195e-04, PNorm = 65.9951, GNorm = 0.6590, lr_0 = 4.3321e-04
Validation rmse logD = 0.601782
Validation R2 logD = 0.751688
Validation rmse logP = 0.682667
Validation R2 logP = 0.770604
Epoch 37
Train function
Loss = 3.3701e-04, PNorm = 66.0130, GNorm = 0.9343, lr_0 = 4.3110e-04
Loss = 3.3976e-04, PNorm = 66.0350, GNorm = 0.9874, lr_0 = 4.2919e-04
Loss = 2.5633e-04, PNorm = 66.0487, GNorm = 0.2732, lr_0 = 4.2729e-04
Loss = 2.6533e-04, PNorm = 66.0634, GNorm = 0.8015, lr_0 = 4.2540e-04
Loss = 2.3335e-04, PNorm = 66.0781, GNorm = 0.2728, lr_0 = 4.2352e-04
Validation rmse logD = 0.600478
Validation R2 logD = 0.752764
Validation rmse logP = 0.679395
Validation R2 logP = 0.772798
Epoch 38
Train function
Loss = 1.9443e-04, PNorm = 66.0964, GNorm = 0.2391, lr_0 = 4.2146e-04
Loss = 1.5857e-04, PNorm = 66.1090, GNorm = 0.2732, lr_0 = 4.1960e-04
Loss = 1.8176e-04, PNorm = 66.1177, GNorm = 0.3411, lr_0 = 4.1774e-04
Loss = 1.8955e-04, PNorm = 66.1264, GNorm = 0.6941, lr_0 = 4.1589e-04
Loss = 1.9680e-04, PNorm = 66.1345, GNorm = 0.2497, lr_0 = 4.1406e-04
Loss = 2.5689e-04, PNorm = 66.1425, GNorm = 0.6970, lr_0 = 4.1222e-04
Validation rmse logD = 0.601523
Validation R2 logD = 0.751902
Validation rmse logP = 0.684826
Validation R2 logP = 0.769150
Epoch 39
Train function
Loss = 2.1960e-04, PNorm = 66.1583, GNorm = 0.2755, lr_0 = 4.1022e-04
Loss = 2.7491e-04, PNorm = 66.1715, GNorm = 0.4383, lr_0 = 4.0840e-04
Loss = 2.5987e-04, PNorm = 66.1842, GNorm = 0.2123, lr_0 = 4.0660e-04
Loss = 2.0003e-04, PNorm = 66.1993, GNorm = 0.4204, lr_0 = 4.0480e-04
Loss = 2.1342e-04, PNorm = 66.2117, GNorm = 0.2458, lr_0 = 4.0301e-04
Validation rmse logD = 0.602094
Validation R2 logD = 0.751431
Validation rmse logP = 0.686019
Validation R2 logP = 0.768345
Epoch 40
Train function
Loss = 1.6973e-04, PNorm = 66.2201, GNorm = 0.2242, lr_0 = 4.0105e-04
Loss = 1.7611e-04, PNorm = 66.2300, GNorm = 0.2445, lr_0 = 3.9927e-04
Loss = 1.7447e-04, PNorm = 66.2392, GNorm = 0.2512, lr_0 = 3.9751e-04
Loss = 1.9069e-04, PNorm = 66.2501, GNorm = 0.8795, lr_0 = 3.9575e-04
Loss = 2.1423e-04, PNorm = 66.2609, GNorm = 0.7169, lr_0 = 3.9400e-04
Validation rmse logD = 0.622073
Validation R2 logD = 0.734661
Validation rmse logP = 0.697191
Validation R2 logP = 0.760738
Epoch 41
Train function
Loss = 2.6197e-04, PNorm = 66.2720, GNorm = 0.1951, lr_0 = 3.9208e-04
Loss = 2.3072e-04, PNorm = 66.2869, GNorm = 0.4408, lr_0 = 3.9035e-04
Loss = 2.1872e-04, PNorm = 66.2955, GNorm = 0.1407, lr_0 = 3.8862e-04
Loss = 1.9555e-04, PNorm = 66.3087, GNorm = 0.2244, lr_0 = 3.8690e-04
Loss = 1.6537e-04, PNorm = 66.3194, GNorm = 0.4460, lr_0 = 3.8519e-04
Loss = 1.9083e-04, PNorm = 66.3295, GNorm = 0.3296, lr_0 = 3.8349e-04
Validation rmse logD = 0.601920
Validation R2 logD = 0.751575
Validation rmse logP = 0.681857
Validation R2 logP = 0.771148
Epoch 42
Train function
Loss = 1.6540e-04, PNorm = 66.3384, GNorm = 0.5331, lr_0 = 3.8179e-04
Loss = 1.8534e-04, PNorm = 66.3456, GNorm = 0.4831, lr_0 = 3.8010e-04
Loss = 1.5831e-04, PNorm = 66.3550, GNorm = 0.3705, lr_0 = 3.7842e-04
Loss = 1.7363e-04, PNorm = 66.3628, GNorm = 0.3121, lr_0 = 3.7675e-04
Loss = 1.9105e-04, PNorm = 66.3712, GNorm = 0.9965, lr_0 = 3.7508e-04
Validation rmse logD = 0.599975
Validation R2 logD = 0.753178
Validation rmse logP = 0.690638
Validation R2 logP = 0.765216
Epoch 43
Train function
Loss = 1.2669e-04, PNorm = 66.3799, GNorm = 0.4677, lr_0 = 3.7326e-04
Loss = 1.3004e-04, PNorm = 66.3883, GNorm = 0.4184, lr_0 = 3.7160e-04
Loss = 1.3421e-04, PNorm = 66.3962, GNorm = 0.1992, lr_0 = 3.6996e-04
Loss = 1.1761e-04, PNorm = 66.4041, GNorm = 0.1682, lr_0 = 3.6832e-04
Loss = 1.4440e-04, PNorm = 66.4100, GNorm = 0.1824, lr_0 = 3.6669e-04
Validation rmse logD = 0.600032
Validation R2 logD = 0.753131
Validation rmse logP = 0.688649
Validation R2 logP = 0.766566
Epoch 44
Train function
Loss = 1.4306e-04, PNorm = 66.4196, GNorm = 0.3253, lr_0 = 3.6491e-04
Loss = 1.0839e-04, PNorm = 66.4289, GNorm = 0.2637, lr_0 = 3.6330e-04
Loss = 1.3622e-04, PNorm = 66.4358, GNorm = 0.1846, lr_0 = 3.6169e-04
Loss = 1.1056e-04, PNorm = 66.4426, GNorm = 0.1660, lr_0 = 3.6009e-04
Loss = 1.3717e-04, PNorm = 66.4472, GNorm = 0.2133, lr_0 = 3.5850e-04
Loss = 1.4200e-04, PNorm = 66.4568, GNorm = 0.1920, lr_0 = 3.5691e-04
Loss = 5.3890e-04, PNorm = 66.4575, GNorm = 0.6290, lr_0 = 3.5675e-04
Validation rmse logD = 0.601026
Validation R2 logD = 0.752312
Validation rmse logP = 0.678221
Validation R2 logP = 0.773582
Epoch 45
Train function
Loss = 1.0404e-04, PNorm = 66.4663, GNorm = 0.1303, lr_0 = 3.5518e-04
Loss = 1.1126e-04, PNorm = 66.4712, GNorm = 0.3297, lr_0 = 3.5360e-04
Loss = 1.1335e-04, PNorm = 66.4758, GNorm = 0.2058, lr_0 = 3.5204e-04
Loss = 1.2791e-04, PNorm = 66.4825, GNorm = 0.2005, lr_0 = 3.5048e-04
Loss = 1.0342e-04, PNorm = 66.4886, GNorm = 0.6637, lr_0 = 3.4893e-04
Validation rmse logD = 0.599440
Validation R2 logD = 0.753618
Validation rmse logP = 0.687616
Validation R2 logP = 0.767266
Epoch 46
Train function
Loss = 1.3945e-04, PNorm = 66.4988, GNorm = 0.1907, lr_0 = 3.4724e-04
Loss = 1.3774e-04, PNorm = 66.5100, GNorm = 0.2842, lr_0 = 3.4570e-04
Loss = 9.6307e-05, PNorm = 66.5181, GNorm = 0.3021, lr_0 = 3.4417e-04
Loss = 1.0470e-04, PNorm = 66.5273, GNorm = 0.2919, lr_0 = 3.4265e-04
Loss = 1.2279e-04, PNorm = 66.5354, GNorm = 0.4986, lr_0 = 3.4113e-04
Validation rmse logD = 0.598814
Validation R2 logD = 0.754132
Validation rmse logP = 0.683732
Validation R2 logP = 0.769887
Epoch 47
Train function
Loss = 8.9108e-05, PNorm = 66.5408, GNorm = 0.3658, lr_0 = 3.3947e-04
Loss = 1.0818e-04, PNorm = 66.5484, GNorm = 0.4500, lr_0 = 3.3797e-04
Loss = 8.6863e-05, PNorm = 66.5505, GNorm = 0.2953, lr_0 = 3.3648e-04
Loss = 9.5740e-05, PNorm = 66.5552, GNorm = 0.5087, lr_0 = 3.3499e-04
Loss = 9.6411e-05, PNorm = 66.5640, GNorm = 0.3323, lr_0 = 3.3351e-04
Validation rmse logD = 0.600245
Validation R2 logD = 0.752956
Validation rmse logP = 0.685505
Validation R2 logP = 0.768692
Epoch 48
Train function
Loss = 7.5122e-05, PNorm = 66.5727, GNorm = 0.2280, lr_0 = 3.3188e-04
Loss = 1.4880e-04, PNorm = 66.5812, GNorm = 0.2932, lr_0 = 3.3042e-04
Loss = 1.8446e-04, PNorm = 66.5872, GNorm = 1.1007, lr_0 = 3.2895e-04
Loss = 1.5793e-04, PNorm = 66.5976, GNorm = 0.4273, lr_0 = 3.2750e-04
Loss = 1.2782e-04, PNorm = 66.6076, GNorm = 0.2450, lr_0 = 3.2605e-04
Loss = 1.0176e-04, PNorm = 66.6160, GNorm = 0.2813, lr_0 = 3.2461e-04
Validation rmse logD = 0.600621
Validation R2 logD = 0.752645
Validation rmse logP = 0.687977
Validation R2 logP = 0.767021
Epoch 49
Train function
Loss = 1.0365e-04, PNorm = 66.6242, GNorm = 0.5298, lr_0 = 3.2303e-04
Loss = 8.8059e-05, PNorm = 66.6300, GNorm = 0.4416, lr_0 = 3.2160e-04
Loss = 1.1272e-04, PNorm = 66.6379, GNorm = 0.4162, lr_0 = 3.2018e-04
Loss = 1.0101e-04, PNorm = 66.6422, GNorm = 0.3839, lr_0 = 3.1876e-04
Loss = 1.0312e-04, PNorm = 66.6480, GNorm = 0.2286, lr_0 = 3.1735e-04
Validation rmse logD = 0.608939
Validation R2 logD = 0.745747
Validation rmse logP = 0.691551
Validation R2 logP = 0.764594
Epoch 50
Train function
Loss = 1.3046e-04, PNorm = 66.6531, GNorm = 0.4684, lr_0 = 3.1595e-04
Loss = 1.5877e-04, PNorm = 66.6601, GNorm = 0.4835, lr_0 = 3.1455e-04
Loss = 1.2086e-04, PNorm = 66.6707, GNorm = 0.2211, lr_0 = 3.1316e-04
Loss = 1.1797e-04, PNorm = 66.6756, GNorm = 0.3329, lr_0 = 3.1177e-04
Loss = 1.2806e-04, PNorm = 66.6807, GNorm = 0.3197, lr_0 = 3.1039e-04
Validation rmse logD = 0.600350
Validation R2 logD = 0.752869
Validation rmse logP = 0.689058
Validation R2 logP = 0.766289
Epoch 51
Train function
Loss = 1.0971e-04, PNorm = 66.6865, GNorm = 0.5638, lr_0 = 3.0888e-04
Loss = 1.0777e-04, PNorm = 66.6922, GNorm = 0.1820, lr_0 = 3.0752e-04
Loss = 1.6634e-04, PNorm = 66.6970, GNorm = 0.3516, lr_0 = 3.0616e-04
Loss = 9.0876e-05, PNorm = 66.7016, GNorm = 0.1288, lr_0 = 3.0480e-04
Loss = 1.0221e-04, PNorm = 66.7086, GNorm = 0.1894, lr_0 = 3.0346e-04
Loss = 9.2452e-05, PNorm = 66.7187, GNorm = 0.1922, lr_0 = 3.0211e-04
Validation rmse logD = 0.600747
Validation R2 logD = 0.752542
Validation rmse logP = 0.691336
Validation R2 logP = 0.764741
Epoch 52
Train function
Loss = 7.8894e-05, PNorm = 66.7244, GNorm = 0.3889, lr_0 = 3.0064e-04
Loss = 7.7958e-05, PNorm = 66.7262, GNorm = 0.2930, lr_0 = 2.9931e-04
Loss = 8.8776e-05, PNorm = 66.7318, GNorm = 0.6379, lr_0 = 2.9799e-04
Loss = 6.3485e-05, PNorm = 66.7380, GNorm = 0.2837, lr_0 = 2.9667e-04
Loss = 8.1759e-05, PNorm = 66.7431, GNorm = 0.1958, lr_0 = 2.9536e-04
Validation rmse logD = 0.603151
Validation R2 logD = 0.750558
Validation rmse logP = 0.694317
Validation R2 logP = 0.762707
Epoch 53
Train function
Loss = 7.2424e-05, PNorm = 66.7483, GNorm = 0.1892, lr_0 = 2.9392e-04
Loss = 7.2320e-05, PNorm = 66.7512, GNorm = 0.1820, lr_0 = 2.9262e-04
Loss = 7.4659e-05, PNorm = 66.7567, GNorm = 0.3571, lr_0 = 2.9133e-04
Loss = 6.1309e-05, PNorm = 66.7600, GNorm = 0.1235, lr_0 = 2.9004e-04
Loss = 6.8108e-05, PNorm = 66.7625, GNorm = 0.2558, lr_0 = 2.8876e-04
Validation rmse logD = 0.604011
Validation R2 logD = 0.749846
Validation rmse logP = 0.686513
Validation R2 logP = 0.768012
Epoch 54
Train function
Loss = 8.5961e-05, PNorm = 66.7674, GNorm = 0.5094, lr_0 = 2.8735e-04
Loss = 7.9229e-05, PNorm = 66.7725, GNorm = 0.1952, lr_0 = 2.8608e-04
Loss = 1.1032e-04, PNorm = 66.7785, GNorm = 0.4918, lr_0 = 2.8482e-04
Loss = 9.2113e-05, PNorm = 66.7860, GNorm = 0.3311, lr_0 = 2.8356e-04
Loss = 6.9005e-05, PNorm = 66.7928, GNorm = 0.1706, lr_0 = 2.8230e-04
Loss = 7.3617e-05, PNorm = 66.7957, GNorm = 0.1353, lr_0 = 2.8105e-04
Validation rmse logD = 0.599821
Validation R2 logD = 0.753304
Validation rmse logP = 0.703814
Validation R2 logP = 0.756171
Epoch 55
Train function
Loss = 6.2523e-05, PNorm = 66.8009, GNorm = 0.1652, lr_0 = 2.7969e-04
Loss = 6.5935e-05, PNorm = 66.8052, GNorm = 0.2366, lr_0 = 2.7845e-04
Loss = 5.8234e-05, PNorm = 66.8075, GNorm = 0.3072, lr_0 = 2.7722e-04
Loss = 5.5747e-05, PNorm = 66.8100, GNorm = 0.5097, lr_0 = 2.7599e-04
Loss = 6.2485e-05, PNorm = 66.8136, GNorm = 0.1020, lr_0 = 2.7477e-04
Validation rmse logD = 0.601629
Validation R2 logD = 0.751815
Validation rmse logP = 0.692665
Validation R2 logP = 0.763835
Epoch 56
Train function
Loss = 7.2340e-05, PNorm = 66.8185, GNorm = 0.2284, lr_0 = 2.7343e-04
Loss = 5.7988e-05, PNorm = 66.8241, GNorm = 0.1600, lr_0 = 2.7222e-04
Loss = 5.7794e-05, PNorm = 66.8278, GNorm = 0.5380, lr_0 = 2.7102e-04
Loss = 8.1401e-05, PNorm = 66.8307, GNorm = 0.1746, lr_0 = 2.6982e-04
Loss = 8.3775e-05, PNorm = 66.8358, GNorm = 0.1802, lr_0 = 2.6863e-04
Validation rmse logD = 0.603824
Validation R2 logD = 0.750000
Validation rmse logP = 0.692636
Validation R2 logP = 0.763855
Epoch 57
Train function
Loss = 5.5060e-05, PNorm = 66.8404, GNorm = 0.4396, lr_0 = 2.6732e-04
Loss = 5.2762e-05, PNorm = 66.8427, GNorm = 0.2160, lr_0 = 2.6614e-04
Loss = 5.6907e-05, PNorm = 66.8483, GNorm = 0.1082, lr_0 = 2.6496e-04
Loss = 5.1943e-05, PNorm = 66.8514, GNorm = 0.1404, lr_0 = 2.6379e-04
Loss = 6.2188e-05, PNorm = 66.8553, GNorm = 0.1490, lr_0 = 2.6262e-04
Loss = 5.4779e-05, PNorm = 66.8602, GNorm = 0.1883, lr_0 = 2.6146e-04
Loss = 3.9906e-04, PNorm = 66.8606, GNorm = 0.4996, lr_0 = 2.6134e-04
Validation rmse logD = 0.600427
Validation R2 logD = 0.752805
Validation rmse logP = 0.692906
Validation R2 logP = 0.763671
Epoch 58
Train function
Loss = 6.9369e-05, PNorm = 66.8629, GNorm = 0.2006, lr_0 = 2.6019e-04
Loss = 6.2465e-05, PNorm = 66.8668, GNorm = 0.2078, lr_0 = 2.5904e-04
Loss = 5.3330e-05, PNorm = 66.8717, GNorm = 0.3253, lr_0 = 2.5789e-04
Loss = 4.6487e-05, PNorm = 66.8753, GNorm = 0.0753, lr_0 = 2.5675e-04
Loss = 4.8319e-05, PNorm = 66.8774, GNorm = 0.2347, lr_0 = 2.5561e-04
Validation rmse logD = 0.601061
Validation R2 logD = 0.752283
Validation rmse logP = 0.691679
Validation R2 logP = 0.764507
Epoch 59
Train function
Loss = 5.9903e-05, PNorm = 66.8809, GNorm = 0.5435, lr_0 = 2.5448e-04
Loss = 5.1699e-05, PNorm = 66.8850, GNorm = 0.3405, lr_0 = 2.5336e-04
Loss = 4.6267e-05, PNorm = 66.8878, GNorm = 0.1544, lr_0 = 2.5224e-04
Loss = 4.2343e-05, PNorm = 66.8907, GNorm = 0.2274, lr_0 = 2.5112e-04
Loss = 4.2276e-05, PNorm = 66.8944, GNorm = 0.0815, lr_0 = 2.5001e-04
Validation rmse logD = 0.603488
Validation R2 logD = 0.750279
Validation rmse logP = 0.694466
Validation R2 logP = 0.762605
Epoch 60
Train function
Loss = 4.4972e-05, PNorm = 66.8997, GNorm = 0.2126, lr_0 = 2.4879e-04
Loss = 4.6741e-05, PNorm = 66.9012, GNorm = 0.1516, lr_0 = 2.4769e-04
Loss = 4.7374e-05, PNorm = 66.9037, GNorm = 0.1282, lr_0 = 2.4660e-04
Loss = 4.1218e-05, PNorm = 66.9066, GNorm = 0.2089, lr_0 = 2.4551e-04
Loss = 4.4696e-05, PNorm = 66.9090, GNorm = 0.1978, lr_0 = 2.4442e-04
Loss = 4.8419e-05, PNorm = 66.9102, GNorm = 0.1666, lr_0 = 2.4334e-04
Loss = 4.3031e-04, PNorm = 66.9105, GNorm = 0.4442, lr_0 = 2.4323e-04
Validation rmse logD = 0.603424
Validation R2 logD = 0.750332
Validation rmse logP = 0.697214
Validation R2 logP = 0.760723
Epoch 61
Train function
Loss = 4.2275e-05, PNorm = 66.9154, GNorm = 0.1201, lr_0 = 2.4216e-04
Loss = 4.1284e-05, PNorm = 66.9182, GNorm = 0.1119, lr_0 = 2.4109e-04
Loss = 4.2076e-05, PNorm = 66.9221, GNorm = 0.1761, lr_0 = 2.4002e-04
Loss = 4.7285e-05, PNorm = 66.9265, GNorm = 0.3557, lr_0 = 2.3896e-04
Loss = 3.9220e-05, PNorm = 66.9300, GNorm = 0.1302, lr_0 = 2.3790e-04
Validation rmse logD = 0.603961
Validation R2 logD = 0.749887
Validation rmse logP = 0.687748
Validation R2 logP = 0.767176
Epoch 62
Train function
Loss = 3.3159e-05, PNorm = 66.9330, GNorm = 0.1500, lr_0 = 2.3674e-04
Loss = 4.7397e-05, PNorm = 66.9351, GNorm = 0.1262, lr_0 = 2.3570e-04
Loss = 4.0239e-05, PNorm = 66.9389, GNorm = 0.1807, lr_0 = 2.3465e-04
Loss = 3.6672e-05, PNorm = 66.9420, GNorm = 0.1603, lr_0 = 2.3362e-04
Loss = 4.8343e-05, PNorm = 66.9452, GNorm = 0.5310, lr_0 = 2.3258e-04
Validation rmse logD = 0.603249
Validation R2 logD = 0.750477
Validation rmse logP = 0.684303
Validation R2 logP = 0.769503
Epoch 63
Train function
Loss = 3.5949e-05, PNorm = 66.9487, GNorm = 0.2960, lr_0 = 2.3145e-04
Loss = 3.7329e-05, PNorm = 66.9517, GNorm = 0.1748, lr_0 = 2.3043e-04
Loss = 3.0123e-05, PNorm = 66.9543, GNorm = 0.2298, lr_0 = 2.2941e-04
Loss = 3.7330e-05, PNorm = 66.9568, GNorm = 0.1777, lr_0 = 2.2839e-04
Loss = 3.6941e-05, PNorm = 66.9586, GNorm = 0.1825, lr_0 = 2.2738e-04
Validation rmse logD = 0.603806
Validation R2 logD = 0.750015
Validation rmse logP = 0.695856
Validation R2 logP = 0.761654
Epoch 64
Train function
Loss = 4.6089e-05, PNorm = 66.9621, GNorm = 0.4586, lr_0 = 2.2628e-04
Loss = 4.3740e-05, PNorm = 66.9651, GNorm = 0.3559, lr_0 = 2.2528e-04
Loss = 5.0941e-05, PNorm = 66.9665, GNorm = 0.4837, lr_0 = 2.2428e-04
Loss = 4.6636e-05, PNorm = 66.9704, GNorm = 0.4709, lr_0 = 2.2329e-04
Loss = 4.3387e-05, PNorm = 66.9731, GNorm = 0.1440, lr_0 = 2.2230e-04
Loss = 4.0432e-05, PNorm = 66.9761, GNorm = 0.1728, lr_0 = 2.2132e-04
Validation rmse logD = 0.602735
Validation R2 logD = 0.750901
Validation rmse logP = 0.697737
Validation R2 logP = 0.760364
Epoch 65
Train function
Loss = 4.3661e-05, PNorm = 66.9781, GNorm = 0.1662, lr_0 = 2.2024e-04
Loss = 4.9555e-05, PNorm = 66.9820, GNorm = 0.3888, lr_0 = 2.1927e-04
Loss = 4.4815e-05, PNorm = 66.9847, GNorm = 0.2049, lr_0 = 2.1830e-04
Loss = 3.8642e-05, PNorm = 66.9872, GNorm = 0.1046, lr_0 = 2.1733e-04
Loss = 4.2650e-05, PNorm = 66.9902, GNorm = 0.2176, lr_0 = 2.1637e-04
Validation rmse logD = 0.601506
Validation R2 logD = 0.751916
Validation rmse logP = 0.689749
Validation R2 logP = 0.765819
Epoch 66
Train function
Loss = 3.6459e-05, PNorm = 66.9943, GNorm = 0.2607, lr_0 = 2.1532e-04
Loss = 3.7722e-05, PNorm = 66.9981, GNorm = 0.5307, lr_0 = 2.1436e-04
Loss = 3.6630e-05, PNorm = 67.0003, GNorm = 0.1620, lr_0 = 2.1342e-04
Loss = 4.0523e-05, PNorm = 67.0024, GNorm = 0.0865, lr_0 = 2.1247e-04
Loss = 4.1849e-05, PNorm = 67.0042, GNorm = 0.1457, lr_0 = 2.1153e-04
Validation rmse logD = 0.600658
Validation R2 logD = 0.752615
Validation rmse logP = 0.694225
Validation R2 logP = 0.762770
Epoch 67
Train function
Loss = 3.0440e-05, PNorm = 67.0058, GNorm = 0.1836, lr_0 = 2.1060e-04
Loss = 2.6310e-05, PNorm = 67.0075, GNorm = 0.0829, lr_0 = 2.0966e-04
Loss = 3.6979e-05, PNorm = 67.0102, GNorm = 0.3848, lr_0 = 2.0874e-04
Loss = 3.2277e-05, PNorm = 67.0140, GNorm = 0.1355, lr_0 = 2.0781e-04
Loss = 3.7107e-05, PNorm = 67.0179, GNorm = 0.2364, lr_0 = 2.0689e-04
Loss = 3.4922e-05, PNorm = 67.0192, GNorm = 0.1862, lr_0 = 2.0598e-04
Validation rmse logD = 0.601511
Validation R2 logD = 0.751912
Validation rmse logP = 0.689414
Validation R2 logP = 0.766047
Epoch 68
Train function
Loss = 3.7974e-05, PNorm = 67.0214, GNorm = 0.2892, lr_0 = 2.0498e-04
Loss = 3.4736e-05, PNorm = 67.0265, GNorm = 0.2310, lr_0 = 2.0407e-04
Loss = 3.4096e-05, PNorm = 67.0278, GNorm = 0.1984, lr_0 = 2.0317e-04
Loss = 3.1909e-05, PNorm = 67.0308, GNorm = 0.2362, lr_0 = 2.0227e-04
Loss = 3.9962e-05, PNorm = 67.0342, GNorm = 0.1296, lr_0 = 2.0137e-04
Validation rmse logD = 0.601898
Validation R2 logD = 0.751593
Validation rmse logP = 0.697576
Validation R2 logP = 0.760474
Epoch 69
Train function
Loss = 3.1365e-05, PNorm = 67.0362, GNorm = 0.4741, lr_0 = 2.0039e-04
Loss = 3.4308e-05, PNorm = 67.0381, GNorm = 0.2178, lr_0 = 1.9951e-04
Loss = 3.4066e-05, PNorm = 67.0414, GNorm = 0.1098, lr_0 = 1.9863e-04
Loss = 2.7584e-05, PNorm = 67.0430, GNorm = 0.0885, lr_0 = 1.9775e-04
Loss = 3.2092e-05, PNorm = 67.0447, GNorm = 0.0941, lr_0 = 1.9687e-04
Validation rmse logD = 0.602019
Validation R2 logD = 0.751493
Validation rmse logP = 0.693924
Validation R2 logP = 0.762976
Epoch 70
Train function
Loss = 2.1905e-05, PNorm = 67.0480, GNorm = 0.2724, lr_0 = 1.9592e-04
Loss = 2.2524e-05, PNorm = 67.0490, GNorm = 0.1518, lr_0 = 1.9505e-04
Loss = 3.1468e-05, PNorm = 67.0512, GNorm = 0.2248, lr_0 = 1.9419e-04
Loss = 3.3117e-05, PNorm = 67.0539, GNorm = 0.1060, lr_0 = 1.9333e-04
Loss = 2.3632e-05, PNorm = 67.0549, GNorm = 0.1024, lr_0 = 1.9247e-04
Loss = 2.3843e-05, PNorm = 67.0577, GNorm = 0.1717, lr_0 = 1.9162e-04
Validation rmse logD = 0.601091
Validation R2 logD = 0.752258
Validation rmse logP = 0.695514
Validation R2 logP = 0.761889
Epoch 71
Train function
Loss = 1.6450e-05, PNorm = 67.0605, GNorm = 0.1310, lr_0 = 1.9069e-04
Loss = 2.4567e-05, PNorm = 67.0620, GNorm = 0.1088, lr_0 = 1.8984e-04
Loss = 2.3775e-05, PNorm = 67.0642, GNorm = 0.3332, lr_0 = 1.8900e-04
Loss = 2.9300e-05, PNorm = 67.0663, GNorm = 0.3477, lr_0 = 1.8817e-04
Loss = 2.7241e-05, PNorm = 67.0686, GNorm = 0.1174, lr_0 = 1.8734e-04
Validation rmse logD = 0.601827
Validation R2 logD = 0.751651
Validation rmse logP = 0.688135
Validation R2 logP = 0.766914
Epoch 72
Train function
Loss = 2.1442e-05, PNorm = 67.0714, GNorm = 0.0973, lr_0 = 1.8643e-04
Loss = 2.4163e-05, PNorm = 67.0730, GNorm = 0.1151, lr_0 = 1.8560e-04
Loss = 3.1589e-05, PNorm = 67.0761, GNorm = 0.2944, lr_0 = 1.8478e-04
Loss = 2.8046e-05, PNorm = 67.0784, GNorm = 0.1940, lr_0 = 1.8396e-04
Loss = 2.5784e-05, PNorm = 67.0796, GNorm = 0.1175, lr_0 = 1.8315e-04
Validation rmse logD = 0.599579
Validation R2 logD = 0.753503
Validation rmse logP = 0.696723
Validation R2 logP = 0.761060
Epoch 73
Train function
Loss = 1.6451e-05, PNorm = 67.0816, GNorm = 0.1365, lr_0 = 1.8226e-04
Loss = 2.7373e-05, PNorm = 67.0844, GNorm = 0.0783, lr_0 = 1.8145e-04
Loss = 2.5594e-05, PNorm = 67.0865, GNorm = 0.2213, lr_0 = 1.8065e-04
Loss = 2.6636e-05, PNorm = 67.0874, GNorm = 0.4232, lr_0 = 1.7985e-04
Loss = 2.9002e-05, PNorm = 67.0898, GNorm = 0.2851, lr_0 = 1.7905e-04
Loss = 2.6740e-05, PNorm = 67.0914, GNorm = 0.2332, lr_0 = 1.7826e-04
Loss = 7.0510e-05, PNorm = 67.0918, GNorm = 0.1493, lr_0 = 1.7818e-04
Validation rmse logD = 0.602541
Validation R2 logD = 0.751061
Validation rmse logP = 0.696148
Validation R2 logP = 0.761454
Epoch 74
Train function
Loss = 2.8913e-05, PNorm = 67.0937, GNorm = 0.2600, lr_0 = 1.7739e-04
Loss = 2.4022e-05, PNorm = 67.0954, GNorm = 0.1460, lr_0 = 1.7661e-04
Loss = 2.0415e-05, PNorm = 67.0970, GNorm = 0.0866, lr_0 = 1.7583e-04
Loss = 1.9055e-05, PNorm = 67.0975, GNorm = 0.1460, lr_0 = 1.7505e-04
Loss = 2.5726e-05, PNorm = 67.1000, GNorm = 0.1040, lr_0 = 1.7428e-04
Validation rmse logD = 0.601031
Validation R2 logD = 0.752308
Validation rmse logP = 0.689891
Validation R2 logP = 0.765723
Epoch 75
Train function
Loss = 2.6087e-05, PNorm = 67.1023, GNorm = 0.1053, lr_0 = 1.7351e-04
Loss = 4.8858e-05, PNorm = 67.1043, GNorm = 0.2211, lr_0 = 1.7274e-04
Loss = 4.1593e-05, PNorm = 67.1068, GNorm = 0.1492, lr_0 = 1.7197e-04
Loss = 3.1861e-05, PNorm = 67.1100, GNorm = 0.0871, lr_0 = 1.7121e-04
Loss = 2.9180e-05, PNorm = 67.1123, GNorm = 0.2370, lr_0 = 1.7046e-04
Validation rmse logD = 0.603303
Validation R2 logD = 0.750432
Validation rmse logP = 0.694249
Validation R2 logP = 0.762754
Epoch 76
Train function
Loss = 3.0397e-05, PNorm = 67.1137, GNorm = 0.0747, lr_0 = 1.6963e-04
Loss = 2.8441e-05, PNorm = 67.1165, GNorm = 0.1227, lr_0 = 1.6888e-04
Loss = 2.0312e-05, PNorm = 67.1181, GNorm = 0.1121, lr_0 = 1.6813e-04
Loss = 1.7549e-05, PNorm = 67.1192, GNorm = 0.0852, lr_0 = 1.6739e-04
Loss = 2.4415e-05, PNorm = 67.1223, GNorm = 0.2286, lr_0 = 1.6665e-04
Loss = 2.8954e-05, PNorm = 67.1236, GNorm = 0.5121, lr_0 = 1.6591e-04
Loss = 2.3234e-04, PNorm = 67.1235, GNorm = 0.3148, lr_0 = 1.6584e-04
Validation rmse logD = 0.601143
Validation R2 logD = 0.752216
Validation rmse logP = 0.693888
Validation R2 logP = 0.763000
Epoch 77
Train function
Loss = 2.3586e-05, PNorm = 67.1252, GNorm = 0.1497, lr_0 = 1.6510e-04
Loss = 2.3812e-05, PNorm = 67.1269, GNorm = 0.1182, lr_0 = 1.6437e-04
Loss = 2.3011e-05, PNorm = 67.1294, GNorm = 0.1912, lr_0 = 1.6364e-04
Loss = 2.6617e-05, PNorm = 67.1314, GNorm = 0.0882, lr_0 = 1.6292e-04
Loss = 1.9410e-05, PNorm = 67.1322, GNorm = 0.3110, lr_0 = 1.6220e-04
Validation rmse logD = 0.601919
Validation R2 logD = 0.751575
Validation rmse logP = 0.693953
Validation R2 logP = 0.762956
Epoch 78
Train function
Loss = 2.7826e-05, PNorm = 67.1348, GNorm = 0.2147, lr_0 = 1.6141e-04
Loss = 2.3536e-05, PNorm = 67.1358, GNorm = 0.2719, lr_0 = 1.6070e-04
Loss = 1.8820e-05, PNorm = 67.1368, GNorm = 0.1588, lr_0 = 1.5999e-04
Loss = 1.9012e-05, PNorm = 67.1383, GNorm = 0.1974, lr_0 = 1.5928e-04
Loss = 1.9657e-05, PNorm = 67.1404, GNorm = 0.2620, lr_0 = 1.5857e-04
Validation rmse logD = 0.604152
Validation R2 logD = 0.749729
Validation rmse logP = 0.690295
Validation R2 logP = 0.765449
Epoch 79
Train function
Loss = 1.8294e-05, PNorm = 67.1440, GNorm = 0.0697, lr_0 = 1.5780e-04
Loss = 2.7394e-05, PNorm = 67.1462, GNorm = 0.3301, lr_0 = 1.5710e-04
Loss = 2.1160e-05, PNorm = 67.1480, GNorm = 0.1453, lr_0 = 1.5641e-04
Loss = 1.9827e-05, PNorm = 67.1493, GNorm = 0.2090, lr_0 = 1.5572e-04
Loss = 3.3233e-05, PNorm = 67.1514, GNorm = 0.0796, lr_0 = 1.5503e-04
Validation rmse logD = 0.601629
Validation R2 logD = 0.751815
Validation rmse logP = 0.692787
Validation R2 logP = 0.763752
Epoch 80
Train function
Loss = 1.7480e-05, PNorm = 67.1541, GNorm = 0.1559, lr_0 = 1.5427e-04
Loss = 2.3262e-05, PNorm = 67.1559, GNorm = 0.1651, lr_0 = 1.5359e-04
Loss = 2.0857e-05, PNorm = 67.1573, GNorm = 0.1600, lr_0 = 1.5291e-04
Loss = 1.7106e-05, PNorm = 67.1589, GNorm = 0.1061, lr_0 = 1.5224e-04
Loss = 1.8496e-05, PNorm = 67.1598, GNorm = 0.1485, lr_0 = 1.5156e-04
Loss = 2.0893e-05, PNorm = 67.1610, GNorm = 0.1349, lr_0 = 1.5089e-04
Validation rmse logD = 0.601972
Validation R2 logD = 0.751531
Validation rmse logP = 0.688862
Validation R2 logP = 0.766421
Epoch 81
Train function
Loss = 2.0155e-05, PNorm = 67.1608, GNorm = 0.1681, lr_0 = 1.5016e-04
Loss = 1.8089e-05, PNorm = 67.1612, GNorm = 0.1126, lr_0 = 1.4949e-04
Loss = 1.3874e-05, PNorm = 67.1625, GNorm = 0.0601, lr_0 = 1.4883e-04
Loss = 1.4363e-05, PNorm = 67.1648, GNorm = 0.2364, lr_0 = 1.4817e-04
Loss = 1.6852e-05, PNorm = 67.1668, GNorm = 0.0792, lr_0 = 1.4752e-04
Validation rmse logD = 0.603343
Validation R2 logD = 0.750399
Validation rmse logP = 0.693269
Validation R2 logP = 0.763423
Epoch 82
Train function
Loss = 1.8963e-05, PNorm = 67.1705, GNorm = 0.2514, lr_0 = 1.4680e-04
Loss = 2.2419e-05, PNorm = 67.1726, GNorm = 0.0703, lr_0 = 1.4615e-04
Loss = 1.6886e-05, PNorm = 67.1732, GNorm = 0.1370, lr_0 = 1.4551e-04
Loss = 2.4083e-05, PNorm = 67.1735, GNorm = 0.1085, lr_0 = 1.4486e-04
Loss = 1.8332e-05, PNorm = 67.1748, GNorm = 0.1539, lr_0 = 1.4422e-04
Validation rmse logD = 0.601986
Validation R2 logD = 0.751520
Validation rmse logP = 0.693014
Validation R2 logP = 0.763597
Epoch 83
Train function
Loss = 1.1807e-05, PNorm = 67.1768, GNorm = 0.0997, lr_0 = 1.4352e-04
Loss = 1.7714e-05, PNorm = 67.1782, GNorm = 0.0931, lr_0 = 1.4288e-04
Loss = 1.6023e-05, PNorm = 67.1800, GNorm = 0.1468, lr_0 = 1.4225e-04
Loss = 1.8260e-05, PNorm = 67.1809, GNorm = 0.0845, lr_0 = 1.4162e-04
Loss = 1.4199e-05, PNorm = 67.1827, GNorm = 0.1288, lr_0 = 1.4100e-04
Loss = 1.4381e-05, PNorm = 67.1842, GNorm = 0.1481, lr_0 = 1.4037e-04
Validation rmse logD = 0.602349
Validation R2 logD = 0.751220
Validation rmse logP = 0.690991
Validation R2 logP = 0.764975
Epoch 84
Train function
Loss = 1.7426e-05, PNorm = 67.1874, GNorm = 0.3233, lr_0 = 1.3975e-04
Loss = 1.7283e-05, PNorm = 67.1879, GNorm = 0.1988, lr_0 = 1.3913e-04
Loss = 1.9805e-05, PNorm = 67.1889, GNorm = 0.0665, lr_0 = 1.3852e-04
Loss = 1.4937e-05, PNorm = 67.1894, GNorm = 0.1023, lr_0 = 1.3791e-04
Loss = 1.5243e-05, PNorm = 67.1911, GNorm = 0.0732, lr_0 = 1.3730e-04
Validation rmse logD = 0.602717
Validation R2 logD = 0.750916
Validation rmse logP = 0.695704
Validation R2 logP = 0.761759
Epoch 85
Train function
Loss = 1.3566e-05, PNorm = 67.1919, GNorm = 0.0912, lr_0 = 1.3663e-04
Loss = 1.3732e-05, PNorm = 67.1936, GNorm = 0.2458, lr_0 = 1.3602e-04
Loss = 1.4857e-05, PNorm = 67.1951, GNorm = 0.1174, lr_0 = 1.3542e-04
Loss = 1.1203e-05, PNorm = 67.1959, GNorm = 0.0620, lr_0 = 1.3482e-04
Loss = 1.5354e-05, PNorm = 67.1970, GNorm = 0.0833, lr_0 = 1.3423e-04
Validation rmse logD = 0.602564
Validation R2 logD = 0.751043
Validation rmse logP = 0.694751
Validation R2 logP = 0.762411
Epoch 86
Train function
Loss = 1.2345e-05, PNorm = 67.1987, GNorm = 0.0657, lr_0 = 1.3357e-04
Loss = 1.3966e-05, PNorm = 67.1989, GNorm = 0.0741, lr_0 = 1.3298e-04
Loss = 1.3060e-05, PNorm = 67.1996, GNorm = 0.0626, lr_0 = 1.3239e-04
Loss = 1.1945e-05, PNorm = 67.2018, GNorm = 0.0981, lr_0 = 1.3181e-04
Loss = 1.2168e-05, PNorm = 67.2030, GNorm = 0.1827, lr_0 = 1.3123e-04
Loss = 1.3390e-05, PNorm = 67.2050, GNorm = 0.0718, lr_0 = 1.3065e-04
Validation rmse logD = 0.602086
Validation R2 logD = 0.751438
Validation rmse logP = 0.694957
Validation R2 logP = 0.762270
Epoch 87
Train function
Loss = 1.3164e-05, PNorm = 67.2059, GNorm = 0.1048, lr_0 = 1.3001e-04
Loss = 2.0253e-05, PNorm = 67.2073, GNorm = 0.2374, lr_0 = 1.2944e-04
Loss = 1.3348e-05, PNorm = 67.2090, GNorm = 0.1242, lr_0 = 1.2886e-04
Loss = 1.3421e-05, PNorm = 67.2107, GNorm = 0.0730, lr_0 = 1.2829e-04
Loss = 1.3622e-05, PNorm = 67.2114, GNorm = 0.1584, lr_0 = 1.2773e-04
Validation rmse logD = 0.601935
Validation R2 logD = 0.751562
Validation rmse logP = 0.696325
Validation R2 logP = 0.761333
Epoch 88
Train function
Loss = 1.1628e-05, PNorm = 67.2127, GNorm = 0.1000, lr_0 = 1.2710e-04
Loss = 9.7822e-06, PNorm = 67.2130, GNorm = 0.1830, lr_0 = 1.2654e-04
Loss = 1.4896e-05, PNorm = 67.2137, GNorm = 0.1427, lr_0 = 1.2598e-04
Loss = 1.1362e-05, PNorm = 67.2155, GNorm = 0.1609, lr_0 = 1.2542e-04
Loss = 1.2712e-05, PNorm = 67.2172, GNorm = 0.1045, lr_0 = 1.2487e-04
Validation rmse logD = 0.601544
Validation R2 logD = 0.751884
Validation rmse logP = 0.692502
Validation R2 logP = 0.763946
Epoch 89
Train function
Loss = 1.1106e-05, PNorm = 67.2184, GNorm = 0.1116, lr_0 = 1.2426e-04
Loss = 1.0681e-05, PNorm = 67.2194, GNorm = 0.0585, lr_0 = 1.2371e-04
Loss = 9.2518e-06, PNorm = 67.2200, GNorm = 0.0738, lr_0 = 1.2317e-04
Loss = 8.0737e-06, PNorm = 67.2201, GNorm = 0.1492, lr_0 = 1.2262e-04
Loss = 1.0295e-05, PNorm = 67.2217, GNorm = 0.1579, lr_0 = 1.2208e-04
Loss = 1.1579e-05, PNorm = 67.2224, GNorm = 0.1337, lr_0 = 1.2154e-04
Loss = 1.5719e-04, PNorm = 67.2226, GNorm = 0.3180, lr_0 = 1.2148e-04
Validation rmse logD = 0.602448
Validation R2 logD = 0.751138
Validation rmse logP = 0.694616
Validation R2 logP = 0.762503
Epoch 90
Train function
Loss = 1.1964e-05, PNorm = 67.2233, GNorm = 0.1372, lr_0 = 1.2095e-04
Loss = 1.2684e-05, PNorm = 67.2243, GNorm = 0.0714, lr_0 = 1.2041e-04
Loss = 2.2346e-05, PNorm = 67.2255, GNorm = 0.1630, lr_0 = 1.1988e-04
Loss = 1.3852e-05, PNorm = 67.2268, GNorm = 0.0788, lr_0 = 1.1935e-04
Loss = 1.2944e-05, PNorm = 67.2288, GNorm = 0.0910, lr_0 = 1.1882e-04
Validation rmse logD = 0.602283
Validation R2 logD = 0.751275
Validation rmse logP = 0.695869
Validation R2 logP = 0.761645
Epoch 91
Train function
Loss = 1.1664e-05, PNorm = 67.2305, GNorm = 0.0889, lr_0 = 1.1824e-04
Loss = 9.2307e-06, PNorm = 67.2314, GNorm = 0.0680, lr_0 = 1.1772e-04
Loss = 1.1991e-05, PNorm = 67.2324, GNorm = 0.0650, lr_0 = 1.1720e-04
Loss = 8.9990e-06, PNorm = 67.2337, GNorm = 0.0392, lr_0 = 1.1668e-04
Loss = 1.0064e-05, PNorm = 67.2339, GNorm = 0.0289, lr_0 = 1.1616e-04
Validation rmse logD = 0.602613
Validation R2 logD = 0.751002
Validation rmse logP = 0.692877
Validation R2 logP = 0.763690
Epoch 92
Train function
Loss = 9.5207e-06, PNorm = 67.2348, GNorm = 0.1083, lr_0 = 1.1565e-04
Loss = 1.0399e-05, PNorm = 67.2351, GNorm = 0.0864, lr_0 = 1.1514e-04
Loss = 8.8678e-06, PNorm = 67.2367, GNorm = 0.1940, lr_0 = 1.1463e-04
Loss = 1.0249e-05, PNorm = 67.2377, GNorm = 0.1277, lr_0 = 1.1412e-04
Loss = 9.5725e-06, PNorm = 67.2389, GNorm = 0.0799, lr_0 = 1.1362e-04
Loss = 1.0034e-05, PNorm = 67.2393, GNorm = 0.1430, lr_0 = 1.1312e-04
Loss = 4.8419e-04, PNorm = 67.2395, GNorm = 0.3495, lr_0 = 1.1307e-04
Validation rmse logD = 0.601459
Validation R2 logD = 0.751955
Validation rmse logP = 0.692997
Validation R2 logP = 0.763609
Epoch 93
Train function
Loss = 1.7005e-05, PNorm = 67.2406, GNorm = 0.0752, lr_0 = 1.1257e-04
Loss = 1.0718e-05, PNorm = 67.2403, GNorm = 0.1027, lr_0 = 1.1207e-04
Loss = 1.3298e-05, PNorm = 67.2426, GNorm = 0.0718, lr_0 = 1.1157e-04
Loss = 9.5724e-06, PNorm = 67.2438, GNorm = 0.0361, lr_0 = 1.1108e-04
Loss = 8.4702e-06, PNorm = 67.2446, GNorm = 0.0361, lr_0 = 1.1059e-04
Validation rmse logD = 0.601944
Validation R2 logD = 0.751555
Validation rmse logP = 0.693623
Validation R2 logP = 0.763181
Epoch 94
Train function
Loss = 8.4561e-06, PNorm = 67.2452, GNorm = 0.0732, lr_0 = 1.1005e-04
Loss = 6.2087e-06, PNorm = 67.2465, GNorm = 0.0538, lr_0 = 1.0956e-04
Loss = 1.1484e-05, PNorm = 67.2474, GNorm = 0.1295, lr_0 = 1.0908e-04
Loss = 9.8928e-06, PNorm = 67.2483, GNorm = 0.1100, lr_0 = 1.0860e-04
Loss = 1.0124e-05, PNorm = 67.2490, GNorm = 0.1009, lr_0 = 1.0811e-04
Validation rmse logD = 0.602619
Validation R2 logD = 0.750997
Validation rmse logP = 0.695272
Validation R2 logP = 0.762054
Epoch 95
Train function
Loss = 5.9664e-06, PNorm = 67.2504, GNorm = 0.0446, lr_0 = 1.0759e-04
Loss = 8.3355e-06, PNorm = 67.2510, GNorm = 0.0814, lr_0 = 1.0711e-04
Loss = 6.1857e-06, PNorm = 67.2513, GNorm = 0.0820, lr_0 = 1.0664e-04
Loss = 7.2484e-06, PNorm = 67.2520, GNorm = 0.0385, lr_0 = 1.0617e-04
Loss = 8.3283e-06, PNorm = 67.2527, GNorm = 0.0533, lr_0 = 1.0570e-04
Validation rmse logD = 0.602870
Validation R2 logD = 0.750790
Validation rmse logP = 0.695595
Validation R2 logP = 0.761833
Epoch 96
Train function
Loss = 4.7641e-06, PNorm = 67.2536, GNorm = 0.0569, lr_0 = 1.0518e-04
Loss = 9.9898e-06, PNorm = 67.2545, GNorm = 0.0568, lr_0 = 1.0472e-04
Loss = 9.9256e-06, PNorm = 67.2557, GNorm = 0.1379, lr_0 = 1.0426e-04
Loss = 9.1691e-06, PNorm = 67.2564, GNorm = 0.1851, lr_0 = 1.0379e-04
Loss = 9.9326e-06, PNorm = 67.2577, GNorm = 0.0774, lr_0 = 1.0333e-04
Loss = 7.6361e-06, PNorm = 67.2581, GNorm = 0.0356, lr_0 = 1.0288e-04
Validation rmse logD = 0.603208
Validation R2 logD = 0.750510
Validation rmse logP = 0.691970
Validation R2 logP = 0.764309
Epoch 97
Train function
Loss = 7.7805e-06, PNorm = 67.2585, GNorm = 0.0771, lr_0 = 1.0238e-04
Loss = 8.2778e-06, PNorm = 67.2595, GNorm = 0.1246, lr_0 = 1.0192e-04
Loss = 7.0870e-06, PNorm = 67.2605, GNorm = 0.0833, lr_0 = 1.0147e-04
Loss = 6.6707e-06, PNorm = 67.2613, GNorm = 0.0655, lr_0 = 1.0102e-04
Loss = 1.1359e-05, PNorm = 67.2629, GNorm = 0.2176, lr_0 = 1.0058e-04
Validation rmse logD = 0.603986
Validation R2 logD = 0.749867
Validation rmse logP = 0.692900
Validation R2 logP = 0.763675
Epoch 98
Train function
Loss = 1.2801e-05, PNorm = 67.2634, GNorm = 0.2294, lr_0 = 1.0009e-04
Loss = 1.1981e-05, PNorm = 67.2642, GNorm = 0.2071, lr_0 = 1.0000e-04
Loss = 1.1942e-05, PNorm = 67.2654, GNorm = 0.0659, lr_0 = 1.0000e-04
Loss = 1.2128e-05, PNorm = 67.2660, GNorm = 0.1236, lr_0 = 1.0000e-04
Loss = 1.1164e-05, PNorm = 67.2678, GNorm = 0.1252, lr_0 = 1.0000e-04
Validation rmse logD = 0.602853
Validation R2 logD = 0.750804
Validation rmse logP = 0.695100
Validation R2 logP = 0.762172
Epoch 99
Train function
Loss = 7.5789e-06, PNorm = 67.2692, GNorm = 0.0674, lr_0 = 1.0000e-04
Loss = 9.9029e-06, PNorm = 67.2700, GNorm = 0.0586, lr_0 = 1.0000e-04
Loss = 8.4787e-06, PNorm = 67.2708, GNorm = 0.0400, lr_0 = 1.0000e-04
Loss = 6.4121e-06, PNorm = 67.2716, GNorm = 0.0580, lr_0 = 1.0000e-04
Loss = 8.0970e-06, PNorm = 67.2721, GNorm = 0.2234, lr_0 = 1.0000e-04
Loss = 1.0911e-05, PNorm = 67.2724, GNorm = 0.0598, lr_0 = 1.0000e-04
Validation rmse logD = 0.602768
Validation R2 logD = 0.750874
Validation rmse logP = 0.691625
Validation R2 logP = 0.764544
Model 0 best validation rmse = 0.623701 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.578511
Model 0 test R2 logD = 0.764950
Model 0 test rmse logP = 0.942120
Model 0 test R2 logP = 0.616734
Ensemble test rmse  logD= 0.578511
Ensemble test R2  logD= 0.764950
Ensemble test rmse  logP= 0.942120
Ensemble test R2  logP= 0.616734
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.0494e-02, PNorm = 55.5675, GNorm = 5.1485, lr_0 = 1.9340e-04
Loss = 1.7300e-02, PNorm = 55.5761, GNorm = 1.5292, lr_0 = 2.7830e-04
Loss = 1.7518e-02, PNorm = 55.5897, GNorm = 9.1345, lr_0 = 3.6321e-04
Loss = 1.8394e-02, PNorm = 55.6119, GNorm = 6.6163, lr_0 = 4.4811e-04
Loss = 1.5708e-02, PNorm = 55.6480, GNorm = 1.1527, lr_0 = 5.3302e-04
Validation rmse logD = 1.080457
Validation R2 logD = 0.252175
Validation rmse logP = 1.158090
Validation R2 logP = 0.418000
Epoch 1
Train function
Loss = 1.4486e-02, PNorm = 55.7070, GNorm = 2.9026, lr_0 = 6.2642e-04
Loss = 1.4220e-02, PNorm = 55.7761, GNorm = 1.5711, lr_0 = 7.1132e-04
Loss = 1.4810e-02, PNorm = 55.8444, GNorm = 8.0316, lr_0 = 7.9623e-04
Loss = 1.5015e-02, PNorm = 55.9267, GNorm = 1.2986, lr_0 = 8.8113e-04
Loss = 1.1703e-02, PNorm = 56.0425, GNorm = 1.3799, lr_0 = 9.6604e-04
Validation rmse logD = 0.965665
Validation R2 logD = 0.402638
Validation rmse logP = 1.149900
Validation R2 logP = 0.426203
Epoch 2
Train function
Loss = 1.2270e-02, PNorm = 56.1840, GNorm = 1.4580, lr_0 = 9.9690e-04
Loss = 1.2189e-02, PNorm = 56.3043, GNorm = 0.9283, lr_0 = 9.9249e-04
Loss = 1.0659e-02, PNorm = 56.4302, GNorm = 1.1693, lr_0 = 9.8810e-04
Loss = 8.8639e-03, PNorm = 56.5480, GNorm = 1.2982, lr_0 = 9.8373e-04
Loss = 9.5843e-03, PNorm = 56.6280, GNorm = 1.2634, lr_0 = 9.7938e-04
Validation rmse logD = 0.865258
Validation R2 logD = 0.520403
Validation rmse logP = 0.802055
Validation R2 logP = 0.720844
Epoch 3
Train function
Loss = 7.2077e-03, PNorm = 56.7422, GNorm = 1.9086, lr_0 = 9.7462e-04
Loss = 8.1451e-03, PNorm = 56.8439, GNorm = 1.1058, lr_0 = 9.7030e-04
Loss = 1.0620e-02, PNorm = 56.9374, GNorm = 2.0917, lr_0 = 9.6601e-04
Loss = 8.9280e-03, PNorm = 57.0481, GNorm = 1.7157, lr_0 = 9.6174e-04
Loss = 8.7768e-03, PNorm = 57.1475, GNorm = 5.9805, lr_0 = 9.5749e-04
Loss = 8.4601e-03, PNorm = 57.2361, GNorm = 1.7864, lr_0 = 9.5325e-04
Validation rmse logD = 0.875566
Validation R2 logD = 0.508908
Validation rmse logP = 0.792100
Validation R2 logP = 0.727731
Epoch 4
Train function
Loss = 8.4085e-03, PNorm = 57.3485, GNorm = 1.4191, lr_0 = 9.4861e-04
Loss = 8.3857e-03, PNorm = 57.4405, GNorm = 3.4714, lr_0 = 9.4442e-04
Loss = 7.2621e-03, PNorm = 57.5309, GNorm = 3.1478, lr_0 = 9.4024e-04
Loss = 9.3520e-03, PNorm = 57.6602, GNorm = 2.7545, lr_0 = 9.3608e-04
Loss = 7.7927e-03, PNorm = 57.7563, GNorm = 2.8684, lr_0 = 9.3194e-04
Validation rmse logD = 0.825031
Validation R2 logD = 0.563961
Validation rmse logP = 0.814403
Validation R2 logP = 0.712182
Epoch 5
Train function
Loss = 6.6708e-03, PNorm = 57.8795, GNorm = 4.3989, lr_0 = 9.2741e-04
Loss = 7.0560e-03, PNorm = 57.9849, GNorm = 2.6571, lr_0 = 9.2330e-04
Loss = 7.0944e-03, PNorm = 58.0929, GNorm = 0.9144, lr_0 = 9.1922e-04
Loss = 7.0774e-03, PNorm = 58.1916, GNorm = 1.2774, lr_0 = 9.1515e-04
Loss = 7.3149e-03, PNorm = 58.2787, GNorm = 0.7830, lr_0 = 9.1111e-04
Validation rmse logD = 0.798003
Validation R2 logD = 0.592062
Validation rmse logP = 0.732895
Validation R2 logP = 0.766911
Epoch 6
Train function
Loss = 7.7441e-03, PNorm = 58.3734, GNorm = 4.0962, lr_0 = 9.0667e-04
Loss = 5.8443e-03, PNorm = 58.4744, GNorm = 1.6642, lr_0 = 9.0266e-04
Loss = 5.5340e-03, PNorm = 58.5591, GNorm = 3.2518, lr_0 = 8.9867e-04
Loss = 6.2476e-03, PNorm = 58.6645, GNorm = 2.0506, lr_0 = 8.9469e-04
Loss = 5.4164e-03, PNorm = 58.7619, GNorm = 1.2116, lr_0 = 8.9074e-04
Loss = 4.9985e-03, PNorm = 58.8712, GNorm = 1.2355, lr_0 = 8.8680e-04
Validation rmse logD = 0.739878
Validation R2 logD = 0.649325
Validation rmse logP = 0.751111
Validation R2 logP = 0.755180
Epoch 7
Train function
Loss = 5.8473e-03, PNorm = 58.9779, GNorm = 1.1939, lr_0 = 8.8248e-04
Loss = 4.8305e-03, PNorm = 59.0821, GNorm = 3.1970, lr_0 = 8.7858e-04
Loss = 4.5386e-03, PNorm = 59.1977, GNorm = 2.1347, lr_0 = 8.7469e-04
Loss = 4.9168e-03, PNorm = 59.2930, GNorm = 1.0358, lr_0 = 8.7082e-04
Loss = 6.1934e-03, PNorm = 59.4053, GNorm = 3.5184, lr_0 = 8.6697e-04
Validation rmse logD = 0.682907
Validation R2 logD = 0.701250
Validation rmse logP = 0.686017
Validation R2 logP = 0.795776
Epoch 8
Train function
Loss = 5.5223e-03, PNorm = 59.5271, GNorm = 4.0700, lr_0 = 8.6276e-04
Loss = 4.8533e-03, PNorm = 59.6424, GNorm = 2.1801, lr_0 = 8.5894e-04
Loss = 4.6491e-03, PNorm = 59.7379, GNorm = 1.0461, lr_0 = 8.5514e-04
Loss = 4.2888e-03, PNorm = 59.8325, GNorm = 2.7382, lr_0 = 8.5136e-04
Loss = 4.8288e-03, PNorm = 59.9095, GNorm = 0.9066, lr_0 = 8.4759e-04
Validation rmse logD = 0.752528
Validation R2 logD = 0.637231
Validation rmse logP = 0.665122
Validation R2 logP = 0.808027
Epoch 9
Train function
Loss = 5.5476e-03, PNorm = 59.9905, GNorm = 5.5855, lr_0 = 8.4384e-04
Loss = 5.3183e-03, PNorm = 60.0863, GNorm = 5.7637, lr_0 = 8.4011e-04
Loss = 5.5484e-03, PNorm = 60.2058, GNorm = 2.2243, lr_0 = 8.3639e-04
Loss = 5.4606e-03, PNorm = 60.3183, GNorm = 0.8160, lr_0 = 8.3269e-04
Loss = 4.7631e-03, PNorm = 60.4236, GNorm = 1.0032, lr_0 = 8.2901e-04
Loss = 4.3273e-03, PNorm = 60.5123, GNorm = 1.3272, lr_0 = 8.2534e-04
Validation rmse logD = 0.673915
Validation R2 logD = 0.709065
Validation rmse logP = 0.635301
Validation R2 logP = 0.824855
Epoch 10
Train function
Loss = 3.5781e-03, PNorm = 60.6023, GNorm = 2.1469, lr_0 = 8.2133e-04
Loss = 3.7323e-03, PNorm = 60.6747, GNorm = 1.6841, lr_0 = 8.1770e-04
Loss = 3.3229e-03, PNorm = 60.7539, GNorm = 0.7440, lr_0 = 8.1408e-04
Loss = 3.2898e-03, PNorm = 60.8411, GNorm = 0.7141, lr_0 = 8.1048e-04
Loss = 3.9472e-03, PNorm = 60.9316, GNorm = 1.0724, lr_0 = 8.0689e-04
Validation rmse logD = 0.655269
Validation R2 logD = 0.724942
Validation rmse logP = 0.637997
Validation R2 logP = 0.823366
Epoch 11
Train function
Loss = 3.1771e-03, PNorm = 61.0194, GNorm = 1.2355, lr_0 = 8.0297e-04
Loss = 3.5797e-03, PNorm = 61.1027, GNorm = 3.0696, lr_0 = 7.9942e-04
Loss = 3.7676e-03, PNorm = 61.2002, GNorm = 2.7238, lr_0 = 7.9588e-04
Loss = 3.6850e-03, PNorm = 61.2922, GNorm = 0.8262, lr_0 = 7.9236e-04
Loss = 2.9431e-03, PNorm = 61.3614, GNorm = 1.1063, lr_0 = 7.8885e-04
Validation rmse logD = 0.650238
Validation R2 logD = 0.729149
Validation rmse logP = 0.630740
Validation R2 logP = 0.827361
Epoch 12
Train function
Loss = 2.0952e-03, PNorm = 61.4331, GNorm = 0.5988, lr_0 = 7.8502e-04
Loss = 2.9582e-03, PNorm = 61.5100, GNorm = 0.7064, lr_0 = 7.8154e-04
Loss = 2.4764e-03, PNorm = 61.5840, GNorm = 1.0843, lr_0 = 7.7809e-04
Loss = 2.5527e-03, PNorm = 61.6571, GNorm = 1.0344, lr_0 = 7.7465e-04
Loss = 3.1372e-03, PNorm = 61.7417, GNorm = 1.2020, lr_0 = 7.7122e-04
Loss = 4.0722e-03, PNorm = 61.8253, GNorm = 1.3903, lr_0 = 7.6781e-04
Loss = 3.0966e-02, PNorm = 61.8311, GNorm = 2.8877, lr_0 = 7.6747e-04
Validation rmse logD = 0.683148
Validation R2 logD = 0.701039
Validation rmse logP = 0.648776
Validation R2 logP = 0.817346
Epoch 13
Train function
Loss = 2.7966e-03, PNorm = 61.9174, GNorm = 0.7700, lr_0 = 7.6407e-04
Loss = 2.7140e-03, PNorm = 62.0132, GNorm = 0.8292, lr_0 = 7.6069e-04
Loss = 2.3536e-03, PNorm = 62.0906, GNorm = 0.8196, lr_0 = 7.5733e-04
Loss = 2.3284e-03, PNorm = 62.1557, GNorm = 1.1977, lr_0 = 7.5398e-04
Loss = 2.6860e-03, PNorm = 62.2237, GNorm = 0.7050, lr_0 = 7.5064e-04
Validation rmse logD = 0.630351
Validation R2 logD = 0.745464
Validation rmse logP = 0.634658
Validation R2 logP = 0.825210
Epoch 14
Train function
Loss = 2.2189e-03, PNorm = 62.3127, GNorm = 1.1071, lr_0 = 7.4699e-04
Loss = 2.4583e-03, PNorm = 62.3847, GNorm = 0.8629, lr_0 = 7.4369e-04
Loss = 1.9441e-03, PNorm = 62.4610, GNorm = 1.4132, lr_0 = 7.4040e-04
Loss = 2.3296e-03, PNorm = 62.5327, GNorm = 0.8650, lr_0 = 7.3712e-04
Loss = 2.6152e-03, PNorm = 62.5906, GNorm = 1.6475, lr_0 = 7.3386e-04
Validation rmse logD = 0.614469
Validation R2 logD = 0.758128
Validation rmse logP = 0.628486
Validation R2 logP = 0.828592
Epoch 15
Train function
Loss = 2.3027e-03, PNorm = 62.6637, GNorm = 0.5929, lr_0 = 7.3029e-04
Loss = 1.6017e-03, PNorm = 62.7289, GNorm = 0.5636, lr_0 = 7.2706e-04
Loss = 1.7484e-03, PNorm = 62.7924, GNorm = 0.6534, lr_0 = 7.2385e-04
Loss = 1.8741e-03, PNorm = 62.8465, GNorm = 0.7468, lr_0 = 7.2064e-04
Loss = 2.4838e-03, PNorm = 62.9067, GNorm = 0.9883, lr_0 = 7.1746e-04
Validation rmse logD = 0.639817
Validation R2 logD = 0.737761
Validation rmse logP = 0.631698
Validation R2 logP = 0.826836
Epoch 16
Train function
Loss = 1.6616e-03, PNorm = 62.9679, GNorm = 1.4535, lr_0 = 7.1397e-04
Loss = 1.5704e-03, PNorm = 63.0356, GNorm = 0.4934, lr_0 = 7.1081e-04
Loss = 1.6653e-03, PNorm = 63.0844, GNorm = 0.6911, lr_0 = 7.0766e-04
Loss = 2.3164e-03, PNorm = 63.1509, GNorm = 1.9413, lr_0 = 7.0453e-04
Loss = 1.7831e-03, PNorm = 63.2153, GNorm = 2.0269, lr_0 = 7.0142e-04
Loss = 1.7304e-03, PNorm = 63.2806, GNorm = 0.6850, lr_0 = 6.9831e-04
Validation rmse logD = 0.641835
Validation R2 logD = 0.736105
Validation rmse logP = 0.626619
Validation R2 logP = 0.829609
Epoch 17
Train function
Loss = 1.7735e-03, PNorm = 63.3421, GNorm = 0.6762, lr_0 = 6.9523e-04
Loss = 1.6094e-03, PNorm = 63.3997, GNorm = 1.9052, lr_0 = 6.9215e-04
Loss = 2.1079e-03, PNorm = 63.4634, GNorm = 2.6769, lr_0 = 6.8909e-04
Loss = 2.1095e-03, PNorm = 63.5272, GNorm = 2.2575, lr_0 = 6.8604e-04
Loss = 1.7265e-03, PNorm = 63.5895, GNorm = 1.4233, lr_0 = 6.8301e-04
Validation rmse logD = 0.597736
Validation R2 logD = 0.771122
Validation rmse logP = 0.624602
Validation R2 logP = 0.830705
Epoch 18
Train function
Loss = 1.6344e-03, PNorm = 63.6668, GNorm = 0.7892, lr_0 = 6.7968e-04
Loss = 1.7650e-03, PNorm = 63.7409, GNorm = 1.0884, lr_0 = 6.7668e-04
Loss = 1.8793e-03, PNorm = 63.8146, GNorm = 1.0342, lr_0 = 6.7368e-04
Loss = 1.6115e-03, PNorm = 63.8783, GNorm = 0.8070, lr_0 = 6.7070e-04
Loss = 1.7836e-03, PNorm = 63.9358, GNorm = 1.8298, lr_0 = 6.6774e-04
Validation rmse logD = 0.615877
Validation R2 logD = 0.757018
Validation rmse logP = 0.609291
Validation R2 logP = 0.838903
Epoch 19
Train function
Loss = 1.3283e-03, PNorm = 63.9956, GNorm = 1.6108, lr_0 = 6.6449e-04
Loss = 1.2445e-03, PNorm = 64.0473, GNorm = 0.7640, lr_0 = 6.6155e-04
Loss = 1.4685e-03, PNorm = 64.0945, GNorm = 1.1072, lr_0 = 6.5862e-04
Loss = 1.5571e-03, PNorm = 64.1498, GNorm = 1.3406, lr_0 = 6.5571e-04
Loss = 1.3706e-03, PNorm = 64.1880, GNorm = 0.4923, lr_0 = 6.5281e-04
Loss = 1.3263e-03, PNorm = 64.2270, GNorm = 0.5815, lr_0 = 6.4992e-04
Validation rmse logD = 0.602866
Validation R2 logD = 0.767176
Validation rmse logP = 0.617972
Validation R2 logP = 0.834280
Epoch 20
Train function
Loss = 1.2371e-03, PNorm = 64.2728, GNorm = 0.7222, lr_0 = 6.4676e-04
Loss = 1.0379e-03, PNorm = 64.3137, GNorm = 0.7022, lr_0 = 6.4390e-04
Loss = 1.2937e-03, PNorm = 64.3613, GNorm = 0.6592, lr_0 = 6.4105e-04
Loss = 1.0857e-03, PNorm = 64.3953, GNorm = 1.6709, lr_0 = 6.3822e-04
Loss = 1.2214e-03, PNorm = 64.4295, GNorm = 0.8899, lr_0 = 6.3539e-04
Validation rmse logD = 0.597012
Validation R2 logD = 0.771676
Validation rmse logP = 0.675851
Validation R2 logP = 0.801783
Epoch 21
Train function
Loss = 1.1249e-03, PNorm = 64.4850, GNorm = 0.6082, lr_0 = 6.3230e-04
Loss = 1.0931e-03, PNorm = 64.5255, GNorm = 1.4754, lr_0 = 6.2950e-04
Loss = 1.0821e-03, PNorm = 64.5653, GNorm = 0.7529, lr_0 = 6.2672e-04
Loss = 8.3276e-04, PNorm = 64.6042, GNorm = 0.6254, lr_0 = 6.2395e-04
Loss = 1.1755e-03, PNorm = 64.6426, GNorm = 1.0857, lr_0 = 6.2119e-04
Validation rmse logD = 0.607823
Validation R2 logD = 0.763332
Validation rmse logP = 0.632043
Validation R2 logP = 0.826647
Epoch 22
Train function
Loss = 1.3253e-03, PNorm = 64.6781, GNorm = 0.6724, lr_0 = 6.1817e-04
Loss = 8.1450e-04, PNorm = 64.7219, GNorm = 1.0124, lr_0 = 6.1543e-04
Loss = 6.9682e-04, PNorm = 64.7595, GNorm = 0.5222, lr_0 = 6.1271e-04
Loss = 9.4936e-04, PNorm = 64.7809, GNorm = 0.6971, lr_0 = 6.1000e-04
Loss = 9.1090e-04, PNorm = 64.8122, GNorm = 0.5870, lr_0 = 6.0730e-04
Loss = 8.2198e-04, PNorm = 64.8408, GNorm = 0.4206, lr_0 = 6.0461e-04
Validation rmse logD = 0.597295
Validation R2 logD = 0.771460
Validation rmse logP = 0.638225
Validation R2 logP = 0.823239
Epoch 23
Train function
Loss = 8.1225e-04, PNorm = 64.8707, GNorm = 0.9833, lr_0 = 6.0167e-04
Loss = 7.8132e-04, PNorm = 64.9032, GNorm = 0.3710, lr_0 = 5.9901e-04
Loss = 6.6064e-04, PNorm = 64.9340, GNorm = 1.2513, lr_0 = 5.9636e-04
Loss = 9.0100e-04, PNorm = 64.9685, GNorm = 1.4222, lr_0 = 5.9372e-04
Loss = 1.0600e-03, PNorm = 65.0081, GNorm = 0.9489, lr_0 = 5.9110e-04
Validation rmse logD = 0.588267
Validation R2 logD = 0.778316
Validation rmse logP = 0.637547
Validation R2 logP = 0.823615
Epoch 24
Train function
Loss = 6.9470e-04, PNorm = 65.0476, GNorm = 0.7739, lr_0 = 5.8822e-04
Loss = 8.3028e-04, PNorm = 65.0858, GNorm = 1.3792, lr_0 = 5.8562e-04
Loss = 1.0554e-03, PNorm = 65.1282, GNorm = 1.6857, lr_0 = 5.8303e-04
Loss = 1.0672e-03, PNorm = 65.1592, GNorm = 1.8805, lr_0 = 5.8045e-04
Loss = 9.3497e-04, PNorm = 65.2079, GNorm = 0.7066, lr_0 = 5.7788e-04
Validation rmse logD = 0.620915
Validation R2 logD = 0.753027
Validation rmse logP = 0.635322
Validation R2 logP = 0.824844
Epoch 25
Train function
Loss = 1.0130e-03, PNorm = 65.2450, GNorm = 1.4639, lr_0 = 5.7533e-04
Loss = 7.5288e-04, PNorm = 65.2753, GNorm = 0.8620, lr_0 = 5.7278e-04
Loss = 6.6728e-04, PNorm = 65.3130, GNorm = 0.5300, lr_0 = 5.7025e-04
Loss = 6.3063e-04, PNorm = 65.3366, GNorm = 0.5607, lr_0 = 5.6773e-04
Loss = 7.0409e-04, PNorm = 65.3637, GNorm = 0.5714, lr_0 = 5.6522e-04
Loss = 7.3129e-04, PNorm = 65.3919, GNorm = 0.8046, lr_0 = 5.6272e-04
Validation rmse logD = 0.588737
Validation R2 logD = 0.777962
Validation rmse logP = 0.612870
Validation R2 logP = 0.837005
Epoch 26
Train function
Loss = 6.3003e-04, PNorm = 65.4308, GNorm = 0.6455, lr_0 = 5.5998e-04
Loss = 6.3447e-04, PNorm = 65.4587, GNorm = 0.5625, lr_0 = 5.5750e-04
Loss = 7.9875e-04, PNorm = 65.4788, GNorm = 0.7266, lr_0 = 5.5503e-04
Loss = 6.3346e-04, PNorm = 65.5068, GNorm = 0.4689, lr_0 = 5.5258e-04
Loss = 6.6987e-04, PNorm = 65.5316, GNorm = 0.3380, lr_0 = 5.5014e-04
Validation rmse logD = 0.591608
Validation R2 logD = 0.775791
Validation rmse logP = 0.625085
Validation R2 logP = 0.830442
Epoch 27
Train function
Loss = 4.9869e-04, PNorm = 65.5630, GNorm = 0.3761, lr_0 = 5.4746e-04
Loss = 6.5245e-04, PNorm = 65.5885, GNorm = 0.8945, lr_0 = 5.4504e-04
Loss = 4.7738e-04, PNorm = 65.6137, GNorm = 0.5530, lr_0 = 5.4263e-04
Loss = 5.3967e-04, PNorm = 65.6342, GNorm = 0.4303, lr_0 = 5.4023e-04
Loss = 4.6324e-04, PNorm = 65.6519, GNorm = 0.4004, lr_0 = 5.3784e-04
Validation rmse logD = 0.588438
Validation R2 logD = 0.778188
Validation rmse logP = 0.615611
Validation R2 logP = 0.835543
Epoch 28
Train function
Loss = 5.0601e-04, PNorm = 65.6800, GNorm = 0.7247, lr_0 = 5.3522e-04
Loss = 5.5941e-04, PNorm = 65.6970, GNorm = 0.8745, lr_0 = 5.3285e-04
Loss = 4.8416e-04, PNorm = 65.7182, GNorm = 0.8697, lr_0 = 5.3050e-04
Loss = 5.6740e-04, PNorm = 65.7441, GNorm = 0.5699, lr_0 = 5.2815e-04
Loss = 4.3702e-04, PNorm = 65.7676, GNorm = 0.3817, lr_0 = 5.2581e-04
Loss = 4.5877e-04, PNorm = 65.7854, GNorm = 0.3491, lr_0 = 5.2349e-04
Loss = 2.5543e-03, PNorm = 65.7877, GNorm = 1.1909, lr_0 = 5.2326e-04
Validation rmse logD = 0.580500
Validation R2 logD = 0.784131
Validation rmse logP = 0.614996
Validation R2 logP = 0.835872
Epoch 29
Train function
Loss = 4.1793e-04, PNorm = 65.8058, GNorm = 0.5081, lr_0 = 5.2094e-04
Loss = 3.5122e-04, PNorm = 65.8195, GNorm = 0.6830, lr_0 = 5.1864e-04
Loss = 3.5973e-04, PNorm = 65.8350, GNorm = 0.4619, lr_0 = 5.1634e-04
Loss = 4.3909e-04, PNorm = 65.8563, GNorm = 0.7050, lr_0 = 5.1406e-04
Loss = 4.2044e-04, PNorm = 65.8758, GNorm = 0.4895, lr_0 = 5.1178e-04
Validation rmse logD = 0.593125
Validation R2 logD = 0.774639
Validation rmse logP = 0.612475
Validation R2 logP = 0.837215
Epoch 30
Train function
Loss = 3.9566e-04, PNorm = 65.8905, GNorm = 0.4832, lr_0 = 5.0930e-04
Loss = 4.7829e-04, PNorm = 65.9095, GNorm = 0.5545, lr_0 = 5.0704e-04
Loss = 4.3792e-04, PNorm = 65.9337, GNorm = 0.6142, lr_0 = 5.0480e-04
Loss = 4.1035e-04, PNorm = 65.9569, GNorm = 0.7546, lr_0 = 5.0257e-04
Loss = 5.2705e-04, PNorm = 65.9759, GNorm = 0.9717, lr_0 = 5.0034e-04
Validation rmse logD = 0.583870
Validation R2 logD = 0.781618
Validation rmse logP = 0.607203
Validation R2 logP = 0.840005
Epoch 31
Train function
Loss = 3.1300e-04, PNorm = 65.9962, GNorm = 0.2534, lr_0 = 4.9791e-04
Loss = 2.8614e-04, PNorm = 66.0177, GNorm = 0.2347, lr_0 = 4.9571e-04
Loss = 2.9882e-04, PNorm = 66.0364, GNorm = 0.2453, lr_0 = 4.9351e-04
Loss = 3.5784e-04, PNorm = 66.0511, GNorm = 0.2753, lr_0 = 4.9133e-04
Loss = 3.7262e-04, PNorm = 66.0678, GNorm = 0.5544, lr_0 = 4.8916e-04
Validation rmse logD = 0.589810
Validation R2 logD = 0.777152
Validation rmse logP = 0.617962
Validation R2 logP = 0.834285
Epoch 32
Train function
Loss = 3.8482e-04, PNorm = 66.0870, GNorm = 1.1512, lr_0 = 4.8678e-04
Loss = 3.7050e-04, PNorm = 66.1087, GNorm = 0.6718, lr_0 = 4.8463e-04
Loss = 2.9333e-04, PNorm = 66.1235, GNorm = 0.3232, lr_0 = 4.8248e-04
Loss = 3.5205e-04, PNorm = 66.1389, GNorm = 0.3638, lr_0 = 4.8035e-04
Loss = 2.7263e-04, PNorm = 66.1549, GNorm = 0.8337, lr_0 = 4.7822e-04
Loss = 3.0879e-04, PNorm = 66.1700, GNorm = 0.4163, lr_0 = 4.7611e-04
Validation rmse logD = 0.584547
Validation R2 logD = 0.781111
Validation rmse logP = 0.607986
Validation R2 logP = 0.839592
Epoch 33
Train function
Loss = 2.3620e-04, PNorm = 66.1880, GNorm = 0.4738, lr_0 = 4.7379e-04
Loss = 2.5226e-04, PNorm = 66.2017, GNorm = 0.4599, lr_0 = 4.7170e-04
Loss = 3.5978e-04, PNorm = 66.2137, GNorm = 0.3969, lr_0 = 4.6961e-04
Loss = 2.7715e-04, PNorm = 66.2262, GNorm = 0.4296, lr_0 = 4.6753e-04
Loss = 2.9865e-04, PNorm = 66.2399, GNorm = 0.4920, lr_0 = 4.6546e-04
Validation rmse logD = 0.581310
Validation R2 logD = 0.783529
Validation rmse logP = 0.610887
Validation R2 logP = 0.838058
Epoch 34
Train function
Loss = 2.9717e-04, PNorm = 66.2556, GNorm = 0.4304, lr_0 = 4.6341e-04
Loss = 2.4945e-04, PNorm = 66.2719, GNorm = 0.6979, lr_0 = 4.6136e-04
Loss = 2.1498e-04, PNorm = 66.2829, GNorm = 0.2712, lr_0 = 4.5931e-04
Loss = 2.4100e-04, PNorm = 66.2960, GNorm = 0.5171, lr_0 = 4.5728e-04
Loss = 2.4167e-04, PNorm = 66.3111, GNorm = 0.3197, lr_0 = 4.5526e-04
Validation rmse logD = 0.582996
Validation R2 logD = 0.782271
Validation rmse logP = 0.601667
Validation R2 logP = 0.842909
Epoch 35
Train function
Loss = 3.1608e-04, PNorm = 66.3272, GNorm = 0.3683, lr_0 = 4.5305e-04
Loss = 1.9595e-04, PNorm = 66.3396, GNorm = 0.7547, lr_0 = 4.5104e-04
Loss = 2.5446e-04, PNorm = 66.3534, GNorm = 0.4330, lr_0 = 4.4905e-04
Loss = 2.5277e-04, PNorm = 66.3633, GNorm = 0.1899, lr_0 = 4.4706e-04
Loss = 2.3453e-04, PNorm = 66.3764, GNorm = 0.3157, lr_0 = 4.4508e-04
Loss = 2.4630e-04, PNorm = 66.3917, GNorm = 0.3113, lr_0 = 4.4311e-04
Validation rmse logD = 0.577670
Validation R2 logD = 0.786231
Validation rmse logP = 0.614619
Validation R2 logP = 0.836073
Epoch 36
Train function
Loss = 1.7812e-04, PNorm = 66.4058, GNorm = 0.3182, lr_0 = 4.4096e-04
Loss = 2.0715e-04, PNorm = 66.4166, GNorm = 0.5641, lr_0 = 4.3901e-04
Loss = 2.2681e-04, PNorm = 66.4266, GNorm = 0.4600, lr_0 = 4.3707e-04
Loss = 2.1521e-04, PNorm = 66.4371, GNorm = 0.3897, lr_0 = 4.3513e-04
Loss = 2.3371e-04, PNorm = 66.4509, GNorm = 0.5160, lr_0 = 4.3321e-04
Validation rmse logD = 0.584729
Validation R2 logD = 0.780975
Validation rmse logP = 0.599629
Validation R2 logP = 0.843972
Epoch 37
Train function
Loss = 2.0160e-04, PNorm = 66.4652, GNorm = 0.3057, lr_0 = 4.3110e-04
Loss = 2.0281e-04, PNorm = 66.4790, GNorm = 1.0039, lr_0 = 4.2919e-04
Loss = 1.8416e-04, PNorm = 66.4911, GNorm = 0.2647, lr_0 = 4.2729e-04
Loss = 2.1150e-04, PNorm = 66.5045, GNorm = 0.5541, lr_0 = 4.2540e-04
Loss = 2.3354e-04, PNorm = 66.5183, GNorm = 1.1150, lr_0 = 4.2352e-04
Validation rmse logD = 0.589408
Validation R2 logD = 0.777455
Validation rmse logP = 0.595747
Validation R2 logP = 0.845985
Epoch 38
Train function
Loss = 1.4016e-04, PNorm = 66.5314, GNorm = 0.2222, lr_0 = 4.2146e-04
Loss = 1.8000e-04, PNorm = 66.5425, GNorm = 0.3312, lr_0 = 4.1960e-04
Loss = 2.3144e-04, PNorm = 66.5538, GNorm = 0.3651, lr_0 = 4.1774e-04
Loss = 2.0533e-04, PNorm = 66.5626, GNorm = 0.2505, lr_0 = 4.1589e-04
Loss = 1.8841e-04, PNorm = 66.5766, GNorm = 0.5828, lr_0 = 4.1406e-04
Loss = 1.7494e-04, PNorm = 66.5889, GNorm = 0.6215, lr_0 = 4.1222e-04
Validation rmse logD = 0.582922
Validation R2 logD = 0.782327
Validation rmse logP = 0.606945
Validation R2 logP = 0.840141
Epoch 39
Train function
Loss = 1.6901e-04, PNorm = 66.6041, GNorm = 0.2379, lr_0 = 4.1022e-04
Loss = 1.7051e-04, PNorm = 66.6149, GNorm = 0.2522, lr_0 = 4.0840e-04
Loss = 1.5016e-04, PNorm = 66.6226, GNorm = 0.2628, lr_0 = 4.0660e-04
Loss = 2.6518e-04, PNorm = 66.6352, GNorm = 0.5703, lr_0 = 4.0480e-04
Loss = 1.9798e-04, PNorm = 66.6467, GNorm = 0.3965, lr_0 = 4.0301e-04
Validation rmse logD = 0.586162
Validation R2 logD = 0.779900
Validation rmse logP = 0.604822
Validation R2 logP = 0.841257
Epoch 40
Train function
Loss = 2.0741e-04, PNorm = 66.6619, GNorm = 0.4649, lr_0 = 4.0105e-04
Loss = 2.0634e-04, PNorm = 66.6716, GNorm = 0.6092, lr_0 = 3.9927e-04
Loss = 1.4956e-04, PNorm = 66.6853, GNorm = 0.5005, lr_0 = 3.9751e-04
Loss = 1.9521e-04, PNorm = 66.6974, GNorm = 0.2980, lr_0 = 3.9575e-04
Loss = 1.4632e-04, PNorm = 66.7090, GNorm = 0.2502, lr_0 = 3.9400e-04
Validation rmse logD = 0.581146
Validation R2 logD = 0.783651
Validation rmse logP = 0.595799
Validation R2 logP = 0.845958
Epoch 41
Train function
Loss = 1.1385e-04, PNorm = 66.7213, GNorm = 0.4517, lr_0 = 3.9208e-04
Loss = 1.8834e-04, PNorm = 66.7328, GNorm = 0.5550, lr_0 = 3.9035e-04
Loss = 1.9395e-04, PNorm = 66.7439, GNorm = 0.4316, lr_0 = 3.8862e-04
Loss = 2.2667e-04, PNorm = 66.7531, GNorm = 0.4947, lr_0 = 3.8690e-04
Loss = 2.0542e-04, PNorm = 66.7668, GNorm = 0.3866, lr_0 = 3.8519e-04
Loss = 1.8333e-04, PNorm = 66.7807, GNorm = 0.3299, lr_0 = 3.8349e-04
Validation rmse logD = 0.587204
Validation R2 logD = 0.779116
Validation rmse logP = 0.607161
Validation R2 logP = 0.840027
Epoch 42
Train function
Loss = 1.8299e-04, PNorm = 66.7942, GNorm = 0.4480, lr_0 = 3.8179e-04
Loss = 1.6216e-04, PNorm = 66.8067, GNorm = 0.4012, lr_0 = 3.8010e-04
Loss = 1.3015e-04, PNorm = 66.8173, GNorm = 0.2056, lr_0 = 3.7842e-04
Loss = 1.5001e-04, PNorm = 66.8230, GNorm = 0.3067, lr_0 = 3.7675e-04
Loss = 1.5089e-04, PNorm = 66.8314, GNorm = 0.2395, lr_0 = 3.7508e-04
Validation rmse logD = 0.576741
Validation R2 logD = 0.786918
Validation rmse logP = 0.587395
Validation R2 logP = 0.850273
Epoch 43
Train function
Loss = 1.0826e-04, PNorm = 66.8412, GNorm = 0.1780, lr_0 = 3.7326e-04
Loss = 1.0298e-04, PNorm = 66.8483, GNorm = 0.3095, lr_0 = 3.7160e-04
Loss = 1.1854e-04, PNorm = 66.8547, GNorm = 0.6230, lr_0 = 3.6996e-04
Loss = 1.3248e-04, PNorm = 66.8594, GNorm = 0.7365, lr_0 = 3.6832e-04
Loss = 1.7133e-04, PNorm = 66.8658, GNorm = 0.5940, lr_0 = 3.6669e-04
Validation rmse logD = 0.581673
Validation R2 logD = 0.783258
Validation rmse logP = 0.591858
Validation R2 logP = 0.847990
Epoch 44
Train function
Loss = 1.8542e-04, PNorm = 66.8785, GNorm = 0.4703, lr_0 = 3.6491e-04
Loss = 2.2305e-04, PNorm = 66.8930, GNorm = 0.4612, lr_0 = 3.6330e-04
Loss = 1.9641e-04, PNorm = 66.9054, GNorm = 0.5921, lr_0 = 3.6169e-04
Loss = 1.4504e-04, PNorm = 66.9173, GNorm = 0.1842, lr_0 = 3.6009e-04
Loss = 1.7612e-04, PNorm = 66.9269, GNorm = 0.7411, lr_0 = 3.5850e-04
Loss = 1.7125e-04, PNorm = 66.9355, GNorm = 0.6802, lr_0 = 3.5691e-04
Loss = 1.0078e-03, PNorm = 66.9371, GNorm = 0.5463, lr_0 = 3.5675e-04
Validation rmse logD = 0.585669
Validation R2 logD = 0.780270
Validation rmse logP = 0.601082
Validation R2 logP = 0.843214
Epoch 45
Train function
Loss = 1.4000e-04, PNorm = 66.9470, GNorm = 0.3910, lr_0 = 3.5518e-04
Loss = 1.3564e-04, PNorm = 66.9545, GNorm = 0.5404, lr_0 = 3.5360e-04
Loss = 1.2872e-04, PNorm = 66.9628, GNorm = 0.5548, lr_0 = 3.5204e-04
Loss = 1.2289e-04, PNorm = 66.9707, GNorm = 0.4012, lr_0 = 3.5048e-04
Loss = 1.1943e-04, PNorm = 66.9784, GNorm = 0.2996, lr_0 = 3.4893e-04
Validation rmse logD = 0.587163
Validation R2 logD = 0.779147
Validation rmse logP = 0.585240
Validation R2 logP = 0.851370
Epoch 46
Train function
Loss = 1.4006e-04, PNorm = 66.9876, GNorm = 0.5324, lr_0 = 3.4724e-04
Loss = 1.2485e-04, PNorm = 66.9919, GNorm = 0.5790, lr_0 = 3.4570e-04
Loss = 1.1859e-04, PNorm = 67.0021, GNorm = 0.2165, lr_0 = 3.4417e-04
Loss = 1.2792e-04, PNorm = 67.0090, GNorm = 0.1735, lr_0 = 3.4265e-04
Loss = 1.0529e-04, PNorm = 67.0150, GNorm = 0.4784, lr_0 = 3.4113e-04
Validation rmse logD = 0.581810
Validation R2 logD = 0.783156
Validation rmse logP = 0.598711
Validation R2 logP = 0.844449
Epoch 47
Train function
Loss = 9.8694e-05, PNorm = 67.0210, GNorm = 0.3024, lr_0 = 3.3947e-04
Loss = 1.1843e-04, PNorm = 67.0288, GNorm = 0.1982, lr_0 = 3.3797e-04
Loss = 1.2160e-04, PNorm = 67.0344, GNorm = 0.2067, lr_0 = 3.3648e-04
Loss = 1.1175e-04, PNorm = 67.0404, GNorm = 0.2238, lr_0 = 3.3499e-04
Loss = 1.0384e-04, PNorm = 67.0469, GNorm = 0.1371, lr_0 = 3.3351e-04
Validation rmse logD = 0.582328
Validation R2 logD = 0.782770
Validation rmse logP = 0.589853
Validation R2 logP = 0.849018
Epoch 48
Train function
Loss = 1.0916e-04, PNorm = 67.0543, GNorm = 0.2342, lr_0 = 3.3188e-04
Loss = 8.6090e-05, PNorm = 67.0596, GNorm = 0.1293, lr_0 = 3.3042e-04
Loss = 8.3170e-05, PNorm = 67.0648, GNorm = 0.1089, lr_0 = 3.2895e-04
Loss = 6.8239e-05, PNorm = 67.0713, GNorm = 0.1424, lr_0 = 3.2750e-04
Loss = 8.9159e-05, PNorm = 67.0799, GNorm = 0.1141, lr_0 = 3.2605e-04
Loss = 8.2854e-05, PNorm = 67.0835, GNorm = 0.1537, lr_0 = 3.2461e-04
Validation rmse logD = 0.582538
Validation R2 logD = 0.782613
Validation rmse logP = 0.587251
Validation R2 logP = 0.850347
Epoch 49
Train function
Loss = 8.1212e-05, PNorm = 67.0901, GNorm = 0.7002, lr_0 = 3.2303e-04
Loss = 7.4938e-05, PNorm = 67.0962, GNorm = 0.2436, lr_0 = 3.2160e-04
Loss = 6.7325e-05, PNorm = 67.1013, GNorm = 0.1826, lr_0 = 3.2018e-04
Loss = 8.2927e-05, PNorm = 67.1062, GNorm = 0.1500, lr_0 = 3.1876e-04
Loss = 7.6270e-05, PNorm = 67.1122, GNorm = 0.4099, lr_0 = 3.1735e-04
Validation rmse logD = 0.582270
Validation R2 logD = 0.782813
Validation rmse logP = 0.586677
Validation R2 logP = 0.850639
Epoch 50
Train function
Loss = 5.6568e-05, PNorm = 67.1168, GNorm = 0.2395, lr_0 = 3.1595e-04
Loss = 8.3851e-05, PNorm = 67.1221, GNorm = 0.1415, lr_0 = 3.1455e-04
Loss = 7.4564e-05, PNorm = 67.1298, GNorm = 0.2978, lr_0 = 3.1316e-04
Loss = 6.8754e-05, PNorm = 67.1360, GNorm = 0.1468, lr_0 = 3.1177e-04
Loss = 7.0462e-05, PNorm = 67.1392, GNorm = 0.2018, lr_0 = 3.1039e-04
Validation rmse logD = 0.581020
Validation R2 logD = 0.783745
Validation rmse logP = 0.583415
Validation R2 logP = 0.852295
Epoch 51
Train function
Loss = 5.6010e-05, PNorm = 67.1429, GNorm = 0.1381, lr_0 = 3.0888e-04
Loss = 8.4740e-05, PNorm = 67.1470, GNorm = 0.1764, lr_0 = 3.0752e-04
Loss = 9.1464e-05, PNorm = 67.1545, GNorm = 0.2143, lr_0 = 3.0616e-04
Loss = 8.8745e-05, PNorm = 67.1606, GNorm = 0.4103, lr_0 = 3.0480e-04
Loss = 8.1513e-05, PNorm = 67.1675, GNorm = 0.2422, lr_0 = 3.0346e-04
Loss = 7.6455e-05, PNorm = 67.1745, GNorm = 0.4472, lr_0 = 3.0211e-04
Validation rmse logD = 0.582447
Validation R2 logD = 0.782681
Validation rmse logP = 0.591129
Validation R2 logP = 0.848364
Epoch 52
Train function
Loss = 9.1284e-05, PNorm = 67.1808, GNorm = 0.1496, lr_0 = 3.0064e-04
Loss = 8.6109e-05, PNorm = 67.1841, GNorm = 0.4129, lr_0 = 2.9931e-04
Loss = 8.6094e-05, PNorm = 67.1911, GNorm = 0.1962, lr_0 = 2.9799e-04
Loss = 6.8615e-05, PNorm = 67.1960, GNorm = 0.1832, lr_0 = 2.9667e-04
Loss = 8.1066e-05, PNorm = 67.2033, GNorm = 0.1751, lr_0 = 2.9536e-04
Validation rmse logD = 0.583184
Validation R2 logD = 0.782130
Validation rmse logP = 0.587751
Validation R2 logP = 0.850092
Epoch 53
Train function
Loss = 6.8417e-05, PNorm = 67.2113, GNorm = 0.2526, lr_0 = 2.9392e-04
Loss = 7.2100e-05, PNorm = 67.2141, GNorm = 0.1462, lr_0 = 2.9262e-04
Loss = 7.4730e-05, PNorm = 67.2181, GNorm = 0.2053, lr_0 = 2.9133e-04
Loss = 9.4626e-05, PNorm = 67.2249, GNorm = 0.4969, lr_0 = 2.9004e-04
Loss = 6.6763e-05, PNorm = 67.2301, GNorm = 0.4398, lr_0 = 2.8876e-04
Validation rmse logD = 0.581687
Validation R2 logD = 0.783248
Validation rmse logP = 0.595327
Validation R2 logP = 0.846202
Epoch 54
Train function
Loss = 4.0095e-05, PNorm = 67.2355, GNorm = 0.2194, lr_0 = 2.8735e-04
Loss = 7.0418e-05, PNorm = 67.2403, GNorm = 0.4884, lr_0 = 2.8608e-04
Loss = 6.9928e-05, PNorm = 67.2457, GNorm = 0.4213, lr_0 = 2.8482e-04
Loss = 7.3388e-05, PNorm = 67.2502, GNorm = 0.1973, lr_0 = 2.8356e-04
Loss = 7.4311e-05, PNorm = 67.2552, GNorm = 0.1528, lr_0 = 2.8230e-04
Loss = 1.1089e-04, PNorm = 67.2581, GNorm = 0.4846, lr_0 = 2.8105e-04
Validation rmse logD = 0.581698
Validation R2 logD = 0.783239
Validation rmse logP = 0.588124
Validation R2 logP = 0.849902
Epoch 55
Train function
Loss = 9.4563e-05, PNorm = 67.2628, GNorm = 0.3046, lr_0 = 2.7969e-04
Loss = 7.3466e-05, PNorm = 67.2689, GNorm = 0.1610, lr_0 = 2.7845e-04
Loss = 5.5689e-05, PNorm = 67.2740, GNorm = 0.3144, lr_0 = 2.7722e-04
Loss = 6.4242e-05, PNorm = 67.2804, GNorm = 0.2221, lr_0 = 2.7599e-04
Loss = 6.2559e-05, PNorm = 67.2860, GNorm = 0.3749, lr_0 = 2.7477e-04
Validation rmse logD = 0.588691
Validation R2 logD = 0.777996
Validation rmse logP = 0.590258
Validation R2 logP = 0.848811
Epoch 56
Train function
Loss = 9.1240e-05, PNorm = 67.2909, GNorm = 0.5055, lr_0 = 2.7343e-04
Loss = 1.1427e-04, PNorm = 67.2949, GNorm = 0.2390, lr_0 = 2.7222e-04
Loss = 7.4718e-05, PNorm = 67.3013, GNorm = 0.1262, lr_0 = 2.7102e-04
Loss = 6.5076e-05, PNorm = 67.3056, GNorm = 0.2429, lr_0 = 2.6982e-04
Loss = 5.6218e-05, PNorm = 67.3090, GNorm = 0.1701, lr_0 = 2.6863e-04
Validation rmse logD = 0.579967
Validation R2 logD = 0.784528
Validation rmse logP = 0.598946
Validation R2 logP = 0.844327
Epoch 57
Train function
Loss = 4.3661e-05, PNorm = 67.3139, GNorm = 0.2320, lr_0 = 2.6732e-04
Loss = 5.6359e-05, PNorm = 67.3212, GNorm = 0.3417, lr_0 = 2.6614e-04
Loss = 5.5221e-05, PNorm = 67.3249, GNorm = 0.2692, lr_0 = 2.6496e-04
Loss = 5.0663e-05, PNorm = 67.3289, GNorm = 0.1353, lr_0 = 2.6379e-04
Loss = 5.3094e-05, PNorm = 67.3335, GNorm = 0.1582, lr_0 = 2.6262e-04
Loss = 5.7612e-05, PNorm = 67.3357, GNorm = 0.1942, lr_0 = 2.6146e-04
Loss = 2.8680e-04, PNorm = 67.3361, GNorm = 0.3098, lr_0 = 2.6134e-04
Validation rmse logD = 0.581266
Validation R2 logD = 0.783561
Validation rmse logP = 0.577978
Validation R2 logP = 0.855036
Epoch 58
Train function
Loss = 3.4242e-05, PNorm = 67.3389, GNorm = 0.1135, lr_0 = 2.6019e-04
Loss = 4.2155e-05, PNorm = 67.3428, GNorm = 0.2121, lr_0 = 2.5904e-04
Loss = 4.3550e-05, PNorm = 67.3470, GNorm = 0.1397, lr_0 = 2.5789e-04
Loss = 4.6869e-05, PNorm = 67.3491, GNorm = 0.1136, lr_0 = 2.5675e-04
Loss = 4.0048e-05, PNorm = 67.3530, GNorm = 0.1634, lr_0 = 2.5561e-04
Validation rmse logD = 0.583571
Validation R2 logD = 0.781841
Validation rmse logP = 0.586412
Validation R2 logP = 0.850774
Epoch 59
Train function
Loss = 4.1699e-05, PNorm = 67.3562, GNorm = 0.1302, lr_0 = 2.5448e-04
Loss = 4.7156e-05, PNorm = 67.3595, GNorm = 0.1485, lr_0 = 2.5336e-04
Loss = 5.0399e-05, PNorm = 67.3625, GNorm = 0.1335, lr_0 = 2.5224e-04
Loss = 3.7440e-05, PNorm = 67.3657, GNorm = 0.1118, lr_0 = 2.5112e-04
Loss = 3.6037e-05, PNorm = 67.3690, GNorm = 0.2251, lr_0 = 2.5001e-04
Validation rmse logD = 0.583310
Validation R2 logD = 0.782037
Validation rmse logP = 0.586586
Validation R2 logP = 0.850686
Epoch 60
Train function
Loss = 6.2713e-05, PNorm = 67.3741, GNorm = 0.0883, lr_0 = 2.4879e-04
Loss = 5.3801e-05, PNorm = 67.3768, GNorm = 0.2093, lr_0 = 2.4769e-04
Loss = 3.9847e-05, PNorm = 67.3811, GNorm = 0.2824, lr_0 = 2.4660e-04
Loss = 5.6194e-05, PNorm = 67.3844, GNorm = 0.5257, lr_0 = 2.4551e-04
Loss = 4.2592e-05, PNorm = 67.3878, GNorm = 0.5021, lr_0 = 2.4442e-04
Loss = 4.5263e-05, PNorm = 67.3914, GNorm = 0.3002, lr_0 = 2.4334e-04
Loss = 6.1292e-04, PNorm = 67.3920, GNorm = 0.4178, lr_0 = 2.4323e-04
Validation rmse logD = 0.581260
Validation R2 logD = 0.783565
Validation rmse logP = 0.583837
Validation R2 logP = 0.852082
Epoch 61
Train function
Loss = 4.6263e-05, PNorm = 67.3954, GNorm = 0.1118, lr_0 = 2.4216e-04
Loss = 5.1508e-05, PNorm = 67.4003, GNorm = 0.3478, lr_0 = 2.4109e-04
Loss = 4.5276e-05, PNorm = 67.4031, GNorm = 0.3553, lr_0 = 2.4002e-04
Loss = 4.4183e-05, PNorm = 67.4065, GNorm = 0.1334, lr_0 = 2.3896e-04
Loss = 4.4269e-05, PNorm = 67.4106, GNorm = 0.1528, lr_0 = 2.3790e-04
Validation rmse logD = 0.583012
Validation R2 logD = 0.782259
Validation rmse logP = 0.591031
Validation R2 logP = 0.848414
Epoch 62
Train function
Loss = 3.7764e-05, PNorm = 67.4146, GNorm = 0.2926, lr_0 = 2.3674e-04
Loss = 3.0417e-05, PNorm = 67.4171, GNorm = 0.1230, lr_0 = 2.3570e-04
Loss = 3.2489e-05, PNorm = 67.4200, GNorm = 0.1030, lr_0 = 2.3465e-04
Loss = 4.0729e-05, PNorm = 67.4220, GNorm = 0.1578, lr_0 = 2.3362e-04
Loss = 3.4722e-05, PNorm = 67.4257, GNorm = 0.1096, lr_0 = 2.3258e-04
Validation rmse logD = 0.582110
Validation R2 logD = 0.782933
Validation rmse logP = 0.587653
Validation R2 logP = 0.850142
Epoch 63
Train function
Loss = 2.8828e-05, PNorm = 67.4303, GNorm = 0.1620, lr_0 = 2.3145e-04
Loss = 3.9300e-05, PNorm = 67.4338, GNorm = 0.2882, lr_0 = 2.3043e-04
Loss = 3.7736e-05, PNorm = 67.4382, GNorm = 0.1611, lr_0 = 2.2941e-04
Loss = 3.3254e-05, PNorm = 67.4402, GNorm = 0.1812, lr_0 = 2.2839e-04
Loss = 3.4496e-05, PNorm = 67.4435, GNorm = 0.1021, lr_0 = 2.2738e-04
Validation rmse logD = 0.580993
Validation R2 logD = 0.783765
Validation rmse logP = 0.588877
Validation R2 logP = 0.849517
Epoch 64
Train function
Loss = 2.5385e-05, PNorm = 67.4454, GNorm = 0.1073, lr_0 = 2.2628e-04
Loss = 2.9823e-05, PNorm = 67.4488, GNorm = 0.0995, lr_0 = 2.2528e-04
Loss = 3.0959e-05, PNorm = 67.4512, GNorm = 0.0948, lr_0 = 2.2428e-04
Loss = 3.1066e-05, PNorm = 67.4541, GNorm = 0.1379, lr_0 = 2.2329e-04
Loss = 3.2981e-05, PNorm = 67.4561, GNorm = 0.0886, lr_0 = 2.2230e-04
Loss = 2.9206e-05, PNorm = 67.4587, GNorm = 0.1317, lr_0 = 2.2132e-04
Validation rmse logD = 0.583876
Validation R2 logD = 0.781614
Validation rmse logP = 0.584995
Validation R2 logP = 0.851494
Epoch 65
Train function
Loss = 3.2534e-05, PNorm = 67.4618, GNorm = 0.2394, lr_0 = 2.2024e-04
Loss = 2.7008e-05, PNorm = 67.4630, GNorm = 0.1847, lr_0 = 2.1927e-04
Loss = 3.3150e-05, PNorm = 67.4667, GNorm = 0.0994, lr_0 = 2.1830e-04
Loss = 3.3192e-05, PNorm = 67.4695, GNorm = 0.1314, lr_0 = 2.1733e-04
Loss = 2.5261e-05, PNorm = 67.4715, GNorm = 0.0893, lr_0 = 2.1637e-04
Validation rmse logD = 0.582872
Validation R2 logD = 0.782364
Validation rmse logP = 0.588988
Validation R2 logP = 0.849460
Epoch 66
Train function
Loss = 2.3664e-05, PNorm = 67.4751, GNorm = 0.1014, lr_0 = 2.1532e-04
Loss = 3.0515e-05, PNorm = 67.4787, GNorm = 0.1242, lr_0 = 2.1436e-04
Loss = 3.2067e-05, PNorm = 67.4800, GNorm = 0.1493, lr_0 = 2.1342e-04
Loss = 3.0464e-05, PNorm = 67.4815, GNorm = 0.0855, lr_0 = 2.1247e-04
Loss = 3.3514e-05, PNorm = 67.4848, GNorm = 0.1028, lr_0 = 2.1153e-04
Validation rmse logD = 0.582463
Validation R2 logD = 0.782669
Validation rmse logP = 0.588124
Validation R2 logP = 0.849901
Epoch 67
Train function
Loss = 2.2402e-05, PNorm = 67.4866, GNorm = 0.1203, lr_0 = 2.1060e-04
Loss = 2.6081e-05, PNorm = 67.4879, GNorm = 0.2236, lr_0 = 2.0966e-04
Loss = 2.4272e-05, PNorm = 67.4887, GNorm = 0.1788, lr_0 = 2.0874e-04
Loss = 3.4051e-05, PNorm = 67.4907, GNorm = 0.1807, lr_0 = 2.0781e-04
Loss = 2.5656e-05, PNorm = 67.4945, GNorm = 0.1535, lr_0 = 2.0689e-04
Loss = 2.6251e-05, PNorm = 67.4969, GNorm = 0.1434, lr_0 = 2.0598e-04
Validation rmse logD = 0.580485
Validation R2 logD = 0.784142
Validation rmse logP = 0.581460
Validation R2 logP = 0.853284
Epoch 68
Train function
Loss = 2.1979e-05, PNorm = 67.5002, GNorm = 0.1758, lr_0 = 2.0498e-04
Loss = 1.8185e-05, PNorm = 67.5026, GNorm = 0.1953, lr_0 = 2.0407e-04
Loss = 2.6638e-05, PNorm = 67.5036, GNorm = 0.1079, lr_0 = 2.0317e-04
Loss = 2.2752e-05, PNorm = 67.5060, GNorm = 0.1360, lr_0 = 2.0227e-04
Loss = 2.7163e-05, PNorm = 67.5085, GNorm = 0.0969, lr_0 = 2.0137e-04
Validation rmse logD = 0.584107
Validation R2 logD = 0.781440
Validation rmse logP = 0.587171
Validation R2 logP = 0.850387
Epoch 69
Train function
Loss = 2.9238e-05, PNorm = 67.5120, GNorm = 0.1383, lr_0 = 2.0039e-04
Loss = 2.4872e-05, PNorm = 67.5139, GNorm = 0.1503, lr_0 = 1.9951e-04
Loss = 3.8618e-05, PNorm = 67.5165, GNorm = 0.1142, lr_0 = 1.9863e-04
Loss = 2.3358e-05, PNorm = 67.5184, GNorm = 0.1143, lr_0 = 1.9775e-04
Loss = 2.1483e-05, PNorm = 67.5213, GNorm = 0.1337, lr_0 = 1.9687e-04
Validation rmse logD = 0.582088
Validation R2 logD = 0.782949
Validation rmse logP = 0.585915
Validation R2 logP = 0.851027
Epoch 70
Train function
Loss = 2.9519e-05, PNorm = 67.5239, GNorm = 0.1724, lr_0 = 1.9592e-04
Loss = 2.1297e-05, PNorm = 67.5250, GNorm = 0.1289, lr_0 = 1.9505e-04
Loss = 1.8800e-05, PNorm = 67.5268, GNorm = 0.1118, lr_0 = 1.9419e-04
Loss = 2.0664e-05, PNorm = 67.5289, GNorm = 0.0850, lr_0 = 1.9333e-04
Loss = 2.0789e-05, PNorm = 67.5308, GNorm = 0.1091, lr_0 = 1.9247e-04
Loss = 2.0269e-05, PNorm = 67.5335, GNorm = 0.1228, lr_0 = 1.9162e-04
Validation rmse logD = 0.583883
Validation R2 logD = 0.781608
Validation rmse logP = 0.582981
Validation R2 logP = 0.852515
Epoch 71
Train function
Loss = 1.7750e-05, PNorm = 67.5351, GNorm = 0.1471, lr_0 = 1.9069e-04
Loss = 1.5060e-05, PNorm = 67.5359, GNorm = 0.1053, lr_0 = 1.8984e-04
Loss = 1.4251e-05, PNorm = 67.5375, GNorm = 0.0655, lr_0 = 1.8900e-04
Loss = 2.0665e-05, PNorm = 67.5385, GNorm = 0.2483, lr_0 = 1.8817e-04
Loss = 1.7574e-05, PNorm = 67.5404, GNorm = 0.1898, lr_0 = 1.8734e-04
Validation rmse logD = 0.582507
Validation R2 logD = 0.782636
Validation rmse logP = 0.587190
Validation R2 logP = 0.850378
Epoch 72
Train function
Loss = 2.3271e-05, PNorm = 67.5435, GNorm = 0.1175, lr_0 = 1.8643e-04
Loss = 1.9966e-05, PNorm = 67.5449, GNorm = 0.2023, lr_0 = 1.8560e-04
Loss = 2.4694e-05, PNorm = 67.5473, GNorm = 0.2819, lr_0 = 1.8478e-04
Loss = 2.0944e-05, PNorm = 67.5497, GNorm = 0.0959, lr_0 = 1.8396e-04
Loss = 2.4323e-05, PNorm = 67.5511, GNorm = 0.1089, lr_0 = 1.8315e-04
Validation rmse logD = 0.581386
Validation R2 logD = 0.783472
Validation rmse logP = 0.586232
Validation R2 logP = 0.850866
Epoch 73
Train function
Loss = 1.7231e-05, PNorm = 67.5532, GNorm = 0.1064, lr_0 = 1.8226e-04
Loss = 1.7306e-05, PNorm = 67.5560, GNorm = 0.2135, lr_0 = 1.8145e-04
Loss = 1.4967e-05, PNorm = 67.5579, GNorm = 0.0676, lr_0 = 1.8065e-04
Loss = 1.5378e-05, PNorm = 67.5597, GNorm = 0.0853, lr_0 = 1.7985e-04
Loss = 2.1841e-05, PNorm = 67.5619, GNorm = 0.0675, lr_0 = 1.7905e-04
Loss = 2.2353e-05, PNorm = 67.5622, GNorm = 0.1847, lr_0 = 1.7826e-04
Loss = 3.0190e-05, PNorm = 67.5623, GNorm = 0.1026, lr_0 = 1.7818e-04
Validation rmse logD = 0.583976
Validation R2 logD = 0.781538
Validation rmse logP = 0.589253
Validation R2 logP = 0.849325
Epoch 74
Train function
Loss = 3.0276e-05, PNorm = 67.5648, GNorm = 0.3112, lr_0 = 1.7739e-04
Loss = 1.8151e-05, PNorm = 67.5674, GNorm = 0.0587, lr_0 = 1.7661e-04
Loss = 1.6680e-05, PNorm = 67.5698, GNorm = 0.0610, lr_0 = 1.7583e-04
Loss = 1.8468e-05, PNorm = 67.5705, GNorm = 0.1523, lr_0 = 1.7505e-04
Loss = 1.6980e-05, PNorm = 67.5715, GNorm = 0.0673, lr_0 = 1.7428e-04
Validation rmse logD = 0.582719
Validation R2 logD = 0.782477
Validation rmse logP = 0.586237
Validation R2 logP = 0.850863
Epoch 75
Train function
Loss = 1.8864e-05, PNorm = 67.5733, GNorm = 0.1263, lr_0 = 1.7351e-04
Loss = 1.8273e-05, PNorm = 67.5752, GNorm = 0.0669, lr_0 = 1.7274e-04
Loss = 1.9234e-05, PNorm = 67.5766, GNorm = 0.1068, lr_0 = 1.7197e-04
Loss = 1.5562e-05, PNorm = 67.5782, GNorm = 0.0566, lr_0 = 1.7121e-04
Loss = 1.8975e-05, PNorm = 67.5800, GNorm = 0.0670, lr_0 = 1.7046e-04
Validation rmse logD = 0.582631
Validation R2 logD = 0.782543
Validation rmse logP = 0.584672
Validation R2 logP = 0.851658
Epoch 76
Train function
Loss = 2.1673e-05, PNorm = 67.5818, GNorm = 0.1309, lr_0 = 1.6963e-04
Loss = 1.8226e-05, PNorm = 67.5832, GNorm = 0.0692, lr_0 = 1.6888e-04
Loss = 1.7390e-05, PNorm = 67.5844, GNorm = 0.1651, lr_0 = 1.6813e-04
Loss = 2.0136e-05, PNorm = 67.5866, GNorm = 0.1127, lr_0 = 1.6739e-04
Loss = 1.6564e-05, PNorm = 67.5894, GNorm = 0.0710, lr_0 = 1.6665e-04
Loss = 1.5134e-05, PNorm = 67.5917, GNorm = 0.0739, lr_0 = 1.6591e-04
Loss = 4.4153e-05, PNorm = 67.5919, GNorm = 0.1657, lr_0 = 1.6584e-04
Validation rmse logD = 0.582411
Validation R2 logD = 0.782708
Validation rmse logP = 0.584897
Validation R2 logP = 0.851544
Epoch 77
Train function
Loss = 1.3108e-05, PNorm = 67.5940, GNorm = 0.0730, lr_0 = 1.6510e-04
Loss = 1.7588e-05, PNorm = 67.5945, GNorm = 0.1688, lr_0 = 1.6437e-04
Loss = 1.7300e-05, PNorm = 67.5963, GNorm = 0.0830, lr_0 = 1.6364e-04
Loss = 1.0826e-05, PNorm = 67.5972, GNorm = 0.0709, lr_0 = 1.6292e-04
Loss = 1.6261e-05, PNorm = 67.5988, GNorm = 0.0872, lr_0 = 1.6220e-04
Validation rmse logD = 0.582349
Validation R2 logD = 0.782754
Validation rmse logP = 0.586264
Validation R2 logP = 0.850850
Epoch 78
Train function
Loss = 2.6875e-05, PNorm = 67.6006, GNorm = 0.3007, lr_0 = 1.6141e-04
Loss = 1.7543e-05, PNorm = 67.6033, GNorm = 0.1379, lr_0 = 1.6070e-04
Loss = 1.6181e-05, PNorm = 67.6049, GNorm = 0.1909, lr_0 = 1.5999e-04
Loss = 1.4445e-05, PNorm = 67.6059, GNorm = 0.0747, lr_0 = 1.5928e-04
Loss = 1.3223e-05, PNorm = 67.6066, GNorm = 0.1456, lr_0 = 1.5857e-04
Validation rmse logD = 0.583354
Validation R2 logD = 0.782004
Validation rmse logP = 0.585651
Validation R2 logP = 0.851161
Epoch 79
Train function
Loss = 1.0419e-05, PNorm = 67.6076, GNorm = 0.1821, lr_0 = 1.5780e-04
Loss = 1.2493e-05, PNorm = 67.6086, GNorm = 0.0632, lr_0 = 1.5710e-04
Loss = 1.2043e-05, PNorm = 67.6095, GNorm = 0.0613, lr_0 = 1.5641e-04
Loss = 1.3526e-05, PNorm = 67.6114, GNorm = 0.0626, lr_0 = 1.5572e-04
Loss = 1.1180e-05, PNorm = 67.6130, GNorm = 0.0904, lr_0 = 1.5503e-04
Validation rmse logD = 0.582798
Validation R2 logD = 0.782419
Validation rmse logP = 0.582585
Validation R2 logP = 0.852715
Epoch 80
Train function
Loss = 4.3663e-06, PNorm = 67.6149, GNorm = 0.0570, lr_0 = 1.5427e-04
Loss = 1.2867e-05, PNorm = 67.6154, GNorm = 0.0805, lr_0 = 1.5359e-04
Loss = 1.1364e-05, PNorm = 67.6156, GNorm = 0.1645, lr_0 = 1.5291e-04
Loss = 1.4197e-05, PNorm = 67.6175, GNorm = 0.0630, lr_0 = 1.5224e-04
Loss = 1.1659e-05, PNorm = 67.6193, GNorm = 0.0984, lr_0 = 1.5156e-04
Loss = 1.5425e-05, PNorm = 67.6196, GNorm = 0.0528, lr_0 = 1.5089e-04
Validation rmse logD = 0.583530
Validation R2 logD = 0.781872
Validation rmse logP = 0.584981
Validation R2 logP = 0.851501
Epoch 81
Train function
Loss = 1.2210e-05, PNorm = 67.6211, GNorm = 0.0587, lr_0 = 1.5016e-04
Loss = 1.5020e-05, PNorm = 67.6224, GNorm = 0.1074, lr_0 = 1.4949e-04
Loss = 1.6437e-05, PNorm = 67.6244, GNorm = 0.2049, lr_0 = 1.4883e-04
Loss = 1.7007e-05, PNorm = 67.6254, GNorm = 0.2249, lr_0 = 1.4817e-04
Loss = 1.1716e-05, PNorm = 67.6269, GNorm = 0.0500, lr_0 = 1.4752e-04
Validation rmse logD = 0.583751
Validation R2 logD = 0.781707
Validation rmse logP = 0.588869
Validation R2 logP = 0.849521
Epoch 82
Train function
Loss = 9.2326e-06, PNorm = 67.6284, GNorm = 0.0444, lr_0 = 1.4680e-04
Loss = 1.1051e-05, PNorm = 67.6296, GNorm = 0.0500, lr_0 = 1.4615e-04
Loss = 1.0504e-05, PNorm = 67.6310, GNorm = 0.0868, lr_0 = 1.4551e-04
Loss = 1.3021e-05, PNorm = 67.6317, GNorm = 0.1860, lr_0 = 1.4486e-04
Loss = 1.5220e-05, PNorm = 67.6331, GNorm = 0.0578, lr_0 = 1.4422e-04
Validation rmse logD = 0.584068
Validation R2 logD = 0.781469
Validation rmse logP = 0.586472
Validation R2 logP = 0.850743
Epoch 83
Train function
Loss = 1.2585e-05, PNorm = 67.6344, GNorm = 0.2044, lr_0 = 1.4352e-04
Loss = 1.0222e-05, PNorm = 67.6358, GNorm = 0.0767, lr_0 = 1.4288e-04
Loss = 9.8877e-06, PNorm = 67.6375, GNorm = 0.1345, lr_0 = 1.4225e-04
Loss = 1.7872e-05, PNorm = 67.6388, GNorm = 0.1189, lr_0 = 1.4162e-04
Loss = 1.6084e-05, PNorm = 67.6399, GNorm = 0.0691, lr_0 = 1.4100e-04
Loss = 1.1590e-05, PNorm = 67.6406, GNorm = 0.0746, lr_0 = 1.4037e-04
Validation rmse logD = 0.582684
Validation R2 logD = 0.782504
Validation rmse logP = 0.583118
Validation R2 logP = 0.852446
Epoch 84
Train function
Loss = 1.0496e-05, PNorm = 67.6423, GNorm = 0.1306, lr_0 = 1.3975e-04
Loss = 9.4016e-06, PNorm = 67.6443, GNorm = 0.0606, lr_0 = 1.3913e-04
Loss = 1.4084e-05, PNorm = 67.6446, GNorm = 0.1705, lr_0 = 1.3852e-04
Loss = 1.1179e-05, PNorm = 67.6455, GNorm = 0.1448, lr_0 = 1.3791e-04
Loss = 9.2710e-06, PNorm = 67.6462, GNorm = 0.1267, lr_0 = 1.3730e-04
Validation rmse logD = 0.582703
Validation R2 logD = 0.782490
Validation rmse logP = 0.587876
Validation R2 logP = 0.850028
Epoch 85
Train function
Loss = 2.0244e-05, PNorm = 67.6481, GNorm = 0.2500, lr_0 = 1.3663e-04
Loss = 1.8638e-05, PNorm = 67.6507, GNorm = 0.2827, lr_0 = 1.3602e-04
Loss = 2.6807e-05, PNorm = 67.6524, GNorm = 0.1298, lr_0 = 1.3542e-04
Loss = 1.5203e-05, PNorm = 67.6527, GNorm = 0.1090, lr_0 = 1.3482e-04
Loss = 1.5096e-05, PNorm = 67.6543, GNorm = 0.2463, lr_0 = 1.3423e-04
Validation rmse logD = 0.584065
Validation R2 logD = 0.781472
Validation rmse logP = 0.587434
Validation R2 logP = 0.850253
Epoch 86
Train function
Loss = 1.2581e-05, PNorm = 67.6558, GNorm = 0.1623, lr_0 = 1.3357e-04
Loss = 1.3600e-05, PNorm = 67.6565, GNorm = 0.0757, lr_0 = 1.3298e-04
Loss = 1.1579e-05, PNorm = 67.6582, GNorm = 0.0602, lr_0 = 1.3239e-04
Loss = 1.3758e-05, PNorm = 67.6590, GNorm = 0.0615, lr_0 = 1.3181e-04
Loss = 1.6232e-05, PNorm = 67.6599, GNorm = 0.0778, lr_0 = 1.3123e-04
Loss = 1.6357e-05, PNorm = 67.6616, GNorm = 0.2122, lr_0 = 1.3065e-04
Validation rmse logD = 0.583687
Validation R2 logD = 0.781754
Validation rmse logP = 0.585626
Validation R2 logP = 0.851174
Epoch 87
Train function
Loss = 1.8439e-05, PNorm = 67.6635, GNorm = 0.2356, lr_0 = 1.3001e-04
Loss = 1.3011e-05, PNorm = 67.6648, GNorm = 0.0572, lr_0 = 1.2944e-04
Loss = 1.1410e-05, PNorm = 67.6663, GNorm = 0.1358, lr_0 = 1.2886e-04
Loss = 1.1107e-05, PNorm = 67.6677, GNorm = 0.0544, lr_0 = 1.2829e-04
Loss = 1.0404e-05, PNorm = 67.6680, GNorm = 0.0564, lr_0 = 1.2773e-04
Validation rmse logD = 0.583193
Validation R2 logD = 0.782124
Validation rmse logP = 0.586058
Validation R2 logP = 0.850954
Epoch 88
Train function
Loss = 8.4963e-06, PNorm = 67.6691, GNorm = 0.0733, lr_0 = 1.2710e-04
Loss = 7.7920e-06, PNorm = 67.6697, GNorm = 0.0615, lr_0 = 1.2654e-04
Loss = 1.3118e-05, PNorm = 67.6707, GNorm = 0.1095, lr_0 = 1.2598e-04
Loss = 1.2612e-05, PNorm = 67.6719, GNorm = 0.0787, lr_0 = 1.2542e-04
Loss = 1.1455e-05, PNorm = 67.6724, GNorm = 0.1225, lr_0 = 1.2487e-04
Validation rmse logD = 0.582253
Validation R2 logD = 0.782825
Validation rmse logP = 0.591164
Validation R2 logP = 0.848346
Epoch 89
Train function
Loss = 8.6817e-06, PNorm = 67.6732, GNorm = 0.0450, lr_0 = 1.2426e-04
Loss = 1.1610e-05, PNorm = 67.6749, GNorm = 0.2175, lr_0 = 1.2371e-04
Loss = 8.9526e-06, PNorm = 67.6758, GNorm = 0.1203, lr_0 = 1.2317e-04
Loss = 1.2347e-05, PNorm = 67.6780, GNorm = 0.1449, lr_0 = 1.2262e-04
Loss = 1.0222e-05, PNorm = 67.6785, GNorm = 0.1223, lr_0 = 1.2208e-04
Loss = 8.7051e-06, PNorm = 67.6790, GNorm = 0.0795, lr_0 = 1.2154e-04
Loss = 4.0983e-05, PNorm = 67.6790, GNorm = 0.1029, lr_0 = 1.2148e-04
Validation rmse logD = 0.582480
Validation R2 logD = 0.782656
Validation rmse logP = 0.586248
Validation R2 logP = 0.850858
Epoch 90
Train function
Loss = 7.0738e-06, PNorm = 67.6799, GNorm = 0.0519, lr_0 = 1.2095e-04
Loss = 1.1751e-05, PNorm = 67.6807, GNorm = 0.1795, lr_0 = 1.2041e-04
Loss = 9.6936e-06, PNorm = 67.6811, GNorm = 0.1518, lr_0 = 1.1988e-04
Loss = 1.0235e-05, PNorm = 67.6821, GNorm = 0.1395, lr_0 = 1.1935e-04
Loss = 1.0351e-05, PNorm = 67.6828, GNorm = 0.0621, lr_0 = 1.1882e-04
Validation rmse logD = 0.583897
Validation R2 logD = 0.781598
Validation rmse logP = 0.582777
Validation R2 logP = 0.852618
Epoch 91
Train function
Loss = 8.2957e-06, PNorm = 67.6843, GNorm = 0.0498, lr_0 = 1.1824e-04
Loss = 9.6411e-06, PNorm = 67.6854, GNorm = 0.0917, lr_0 = 1.1772e-04
Loss = 8.2554e-06, PNorm = 67.6862, GNorm = 0.0697, lr_0 = 1.1720e-04
Loss = 8.3406e-06, PNorm = 67.6867, GNorm = 0.1171, lr_0 = 1.1668e-04
Loss = 7.1131e-06, PNorm = 67.6878, GNorm = 0.0462, lr_0 = 1.1616e-04
Validation rmse logD = 0.582432
Validation R2 logD = 0.782692
Validation rmse logP = 0.584568
Validation R2 logP = 0.851711
Epoch 92
Train function
Loss = 5.7036e-06, PNorm = 67.6885, GNorm = 0.0653, lr_0 = 1.1565e-04
Loss = 7.3555e-06, PNorm = 67.6897, GNorm = 0.0770, lr_0 = 1.1514e-04
Loss = 7.3703e-06, PNorm = 67.6904, GNorm = 0.0616, lr_0 = 1.1463e-04
Loss = 8.5227e-06, PNorm = 67.6916, GNorm = 0.0632, lr_0 = 1.1412e-04
Loss = 7.4375e-06, PNorm = 67.6925, GNorm = 0.1352, lr_0 = 1.1362e-04
Loss = 7.5990e-06, PNorm = 67.6929, GNorm = 0.0448, lr_0 = 1.1312e-04
Loss = 2.5340e-05, PNorm = 67.6930, GNorm = 0.0816, lr_0 = 1.1307e-04
Validation rmse logD = 0.582917
Validation R2 logD = 0.782330
Validation rmse logP = 0.587481
Validation R2 logP = 0.850230
Epoch 93
Train function
Loss = 7.9906e-06, PNorm = 67.6937, GNorm = 0.0607, lr_0 = 1.1257e-04
Loss = 8.1189e-06, PNorm = 67.6939, GNorm = 0.0387, lr_0 = 1.1207e-04
Loss = 6.9090e-06, PNorm = 67.6948, GNorm = 0.1856, lr_0 = 1.1157e-04
Loss = 5.9193e-06, PNorm = 67.6963, GNorm = 0.1057, lr_0 = 1.1108e-04
Loss = 5.2101e-06, PNorm = 67.6969, GNorm = 0.0556, lr_0 = 1.1059e-04
Validation rmse logD = 0.582769
Validation R2 logD = 0.782440
Validation rmse logP = 0.584342
Validation R2 logP = 0.851826
Epoch 94
Train function
Loss = 6.2580e-06, PNorm = 67.6982, GNorm = 0.0953, lr_0 = 1.1005e-04
Loss = 4.9671e-06, PNorm = 67.6991, GNorm = 0.0583, lr_0 = 1.0956e-04
Loss = 6.7452e-06, PNorm = 67.6994, GNorm = 0.0481, lr_0 = 1.0908e-04
Loss = 6.7701e-06, PNorm = 67.6998, GNorm = 0.0562, lr_0 = 1.0860e-04
Loss = 5.7694e-06, PNorm = 67.7002, GNorm = 0.0754, lr_0 = 1.0811e-04
Validation rmse logD = 0.583389
Validation R2 logD = 0.781977
Validation rmse logP = 0.587182
Validation R2 logP = 0.850382
Epoch 95
Train function
Loss = 6.6657e-06, PNorm = 67.7012, GNorm = 0.0830, lr_0 = 1.0759e-04
Loss = 7.3249e-06, PNorm = 67.7019, GNorm = 0.1498, lr_0 = 1.0711e-04
Loss = 8.7324e-06, PNorm = 67.7030, GNorm = 0.1814, lr_0 = 1.0664e-04
Loss = 9.6577e-06, PNorm = 67.7041, GNorm = 0.1592, lr_0 = 1.0617e-04
Loss = 8.5077e-06, PNorm = 67.7043, GNorm = 0.1712, lr_0 = 1.0570e-04
Validation rmse logD = 0.583824
Validation R2 logD = 0.781652
Validation rmse logP = 0.586907
Validation R2 logP = 0.850522
Epoch 96
Train function
Loss = 1.3393e-05, PNorm = 67.7051, GNorm = 0.2495, lr_0 = 1.0518e-04
Loss = 7.9778e-06, PNorm = 67.7056, GNorm = 0.0853, lr_0 = 1.0472e-04
Loss = 7.1505e-06, PNorm = 67.7066, GNorm = 0.0309, lr_0 = 1.0426e-04
Loss = 8.0029e-06, PNorm = 67.7070, GNorm = 0.0648, lr_0 = 1.0379e-04
Loss = 8.6736e-06, PNorm = 67.7069, GNorm = 0.1576, lr_0 = 1.0333e-04
Loss = 8.0617e-06, PNorm = 67.7086, GNorm = 0.0406, lr_0 = 1.0288e-04
Validation rmse logD = 0.583957
Validation R2 logD = 0.781552
Validation rmse logP = 0.586230
Validation R2 logP = 0.850867
Epoch 97
Train function
Loss = 6.5415e-06, PNorm = 67.7103, GNorm = 0.1014, lr_0 = 1.0238e-04
Loss = 6.0741e-06, PNorm = 67.7109, GNorm = 0.1064, lr_0 = 1.0192e-04
Loss = 5.5796e-06, PNorm = 67.7120, GNorm = 0.0405, lr_0 = 1.0147e-04
Loss = 5.8709e-06, PNorm = 67.7127, GNorm = 0.1112, lr_0 = 1.0102e-04
Loss = 7.8711e-06, PNorm = 67.7133, GNorm = 0.1176, lr_0 = 1.0058e-04
Validation rmse logD = 0.583215
Validation R2 logD = 0.782108
Validation rmse logP = 0.587843
Validation R2 logP = 0.850045
Epoch 98
Train function
Loss = 8.5271e-06, PNorm = 67.7148, GNorm = 0.0636, lr_0 = 1.0009e-04
Loss = 8.3869e-06, PNorm = 67.7150, GNorm = 0.0524, lr_0 = 1.0000e-04
Loss = 9.4510e-06, PNorm = 67.7161, GNorm = 0.0434, lr_0 = 1.0000e-04
Loss = 9.5230e-06, PNorm = 67.7164, GNorm = 0.1161, lr_0 = 1.0000e-04
Loss = 9.8193e-06, PNorm = 67.7175, GNorm = 0.0786, lr_0 = 1.0000e-04
Validation rmse logD = 0.583127
Validation R2 logD = 0.782173
Validation rmse logP = 0.585034
Validation R2 logP = 0.851475
Epoch 99
Train function
Loss = 5.6845e-06, PNorm = 67.7181, GNorm = 0.1001, lr_0 = 1.0000e-04
Loss = 1.6995e-05, PNorm = 67.7183, GNorm = 0.2501, lr_0 = 1.0000e-04
Loss = 1.1644e-05, PNorm = 67.7192, GNorm = 0.1218, lr_0 = 1.0000e-04
Loss = 7.4088e-06, PNorm = 67.7203, GNorm = 0.0486, lr_0 = 1.0000e-04
Loss = 8.1290e-06, PNorm = 67.7213, GNorm = 0.0361, lr_0 = 1.0000e-04
Loss = 8.3759e-06, PNorm = 67.7222, GNorm = 0.1356, lr_0 = 1.0000e-04
Validation rmse logD = 0.582811
Validation R2 logD = 0.782409
Validation rmse logP = 0.585696
Validation R2 logP = 0.851138
Model 0 best validation rmse = 0.579622 on epoch 57
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.608559
Model 0 test R2 logD = 0.739899
Model 0 test rmse logP = 0.814019
Model 0 test R2 logP = 0.713874
Ensemble test rmse  logD= 0.608559
Ensemble test R2  logD= 0.739899
Ensemble test rmse  logP= 0.814019
Ensemble test R2  logP= 0.713874
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_258_Logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_319/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_258_Logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2656,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 3,541 | train size = 2,656 | val size = 885 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=2, bias=True)
  )
)
Number of parameters = 2,513,002
Moving model to cuda
Epoch 0
Train function
Loss = 2.2956e-02, PNorm = 55.5666, GNorm = 4.3830, lr_0 = 1.9340e-04
Loss = 1.7119e-02, PNorm = 55.5771, GNorm = 8.1465, lr_0 = 2.7830e-04
Loss = 1.5682e-02, PNorm = 55.5953, GNorm = 2.0995, lr_0 = 3.6321e-04
Loss = 1.5722e-02, PNorm = 55.6202, GNorm = 8.9794, lr_0 = 4.4811e-04
Loss = 1.7620e-02, PNorm = 55.6465, GNorm = 1.5374, lr_0 = 5.3302e-04
Validation rmse logD = 1.003622
Validation R2 logD = 0.261222
Validation rmse logP = 1.387477
Validation R2 logP = 0.269526
Epoch 1
Train function
Loss = 1.5060e-02, PNorm = 55.6956, GNorm = 1.1602, lr_0 = 6.2642e-04
Loss = 1.1569e-02, PNorm = 55.7602, GNorm = 4.2388, lr_0 = 7.1132e-04
Loss = 1.2669e-02, PNorm = 55.8326, GNorm = 1.9621, lr_0 = 7.9623e-04
Loss = 1.2777e-02, PNorm = 55.9291, GNorm = 3.0830, lr_0 = 8.8113e-04
Loss = 1.1967e-02, PNorm = 56.0535, GNorm = 6.2975, lr_0 = 9.6604e-04
Validation rmse logD = 0.870986
Validation R2 logD = 0.443589
Validation rmse logP = 1.379040
Validation R2 logP = 0.278383
Epoch 2
Train function
Loss = 9.6914e-03, PNorm = 56.1886, GNorm = 4.4744, lr_0 = 9.9690e-04
Loss = 1.1639e-02, PNorm = 56.3212, GNorm = 2.7825, lr_0 = 9.9249e-04
Loss = 1.1110e-02, PNorm = 56.4437, GNorm = 7.9395, lr_0 = 9.8810e-04
Loss = 1.0656e-02, PNorm = 56.5599, GNorm = 1.0775, lr_0 = 9.8373e-04
Loss = 9.9127e-03, PNorm = 56.6500, GNorm = 0.7818, lr_0 = 9.7938e-04
Validation rmse logD = 0.837844
Validation R2 logD = 0.485128
Validation rmse logP = 0.923385
Validation R2 logP = 0.676467
Epoch 3
Train function
Loss = 1.0980e-02, PNorm = 56.7458, GNorm = 5.0589, lr_0 = 9.7462e-04
Loss = 8.7265e-03, PNorm = 56.8272, GNorm = 1.3131, lr_0 = 9.7030e-04
Loss = 9.4391e-03, PNorm = 56.9231, GNorm = 3.6567, lr_0 = 9.6601e-04
Loss = 8.5682e-03, PNorm = 57.0437, GNorm = 2.2502, lr_0 = 9.6174e-04
Loss = 7.1679e-03, PNorm = 57.1416, GNorm = 2.1386, lr_0 = 9.5749e-04
Loss = 8.7575e-03, PNorm = 57.2579, GNorm = 2.2858, lr_0 = 9.5325e-04
Validation rmse logD = 0.870446
Validation R2 logD = 0.444280
Validation rmse logP = 0.838188
Validation R2 logP = 0.733415
Epoch 4
Train function
Loss = 1.1637e-02, PNorm = 57.3745, GNorm = 1.5161, lr_0 = 9.4861e-04
Loss = 9.6637e-03, PNorm = 57.5351, GNorm = 1.7435, lr_0 = 9.4442e-04
Loss = 8.9138e-03, PNorm = 57.6632, GNorm = 3.7972, lr_0 = 9.4024e-04
Loss = 8.9486e-03, PNorm = 57.7775, GNorm = 4.5489, lr_0 = 9.3608e-04
Loss = 8.4956e-03, PNorm = 57.8911, GNorm = 1.2728, lr_0 = 9.3194e-04
Validation rmse logD = 0.756211
Validation R2 logD = 0.580570
Validation rmse logP = 0.754196
Validation R2 logP = 0.784165
Epoch 5
Train function
Loss = 9.6837e-03, PNorm = 58.0175, GNorm = 1.8803, lr_0 = 9.2741e-04
Loss = 7.0106e-03, PNorm = 58.1203, GNorm = 2.8282, lr_0 = 9.2330e-04
Loss = 6.7099e-03, PNorm = 58.2307, GNorm = 0.6806, lr_0 = 9.1922e-04
Loss = 6.1836e-03, PNorm = 58.3094, GNorm = 0.8478, lr_0 = 9.1515e-04
Loss = 7.2915e-03, PNorm = 58.3857, GNorm = 1.4617, lr_0 = 9.1111e-04
Validation rmse logD = 0.742721
Validation R2 logD = 0.595401
Validation rmse logP = 0.823634
Validation R2 logP = 0.742592
Epoch 6
Train function
Loss = 5.8936e-03, PNorm = 58.4765, GNorm = 4.6234, lr_0 = 9.0667e-04
Loss = 6.5070e-03, PNorm = 58.5589, GNorm = 2.3312, lr_0 = 9.0266e-04
Loss = 5.7953e-03, PNorm = 58.6568, GNorm = 1.5502, lr_0 = 8.9867e-04
Loss = 6.1053e-03, PNorm = 58.7397, GNorm = 0.8870, lr_0 = 8.9469e-04
Loss = 6.4981e-03, PNorm = 58.8294, GNorm = 1.0494, lr_0 = 8.9074e-04
Loss = 5.9230e-03, PNorm = 58.9131, GNorm = 1.6438, lr_0 = 8.8680e-04
Validation rmse logD = 0.671972
Validation R2 logD = 0.668811
Validation rmse logP = 0.723700
Validation R2 logP = 0.801267
Epoch 7
Train function
Loss = 5.2601e-03, PNorm = 58.9962, GNorm = 2.1563, lr_0 = 8.8248e-04
Loss = 4.5580e-03, PNorm = 59.1032, GNorm = 1.0357, lr_0 = 8.7858e-04
Loss = 5.6077e-03, PNorm = 59.1848, GNorm = 2.6762, lr_0 = 8.7469e-04
Loss = 6.0136e-03, PNorm = 59.2690, GNorm = 1.2492, lr_0 = 8.7082e-04
Loss = 5.4353e-03, PNorm = 59.3653, GNorm = 0.6861, lr_0 = 8.6697e-04
Validation rmse logD = 0.778817
Validation R2 logD = 0.555119
Validation rmse logP = 0.742246
Validation R2 logP = 0.790951
Epoch 8
Train function
Loss = 6.8891e-03, PNorm = 59.4622, GNorm = 2.9044, lr_0 = 8.6276e-04
Loss = 5.5610e-03, PNorm = 59.5896, GNorm = 4.3897, lr_0 = 8.5894e-04
Loss = 4.8899e-03, PNorm = 59.6748, GNorm = 0.7177, lr_0 = 8.5514e-04
Loss = 4.4513e-03, PNorm = 59.7493, GNorm = 2.2588, lr_0 = 8.5136e-04
Loss = 4.7490e-03, PNorm = 59.8380, GNorm = 1.4119, lr_0 = 8.4759e-04
Validation rmse logD = 0.679599
Validation R2 logD = 0.661251
Validation rmse logP = 0.673990
Validation R2 logP = 0.827630
Epoch 9
Train function
Loss = 4.4692e-03, PNorm = 59.9366, GNorm = 2.0250, lr_0 = 8.4384e-04
Loss = 4.2423e-03, PNorm = 60.0297, GNorm = 1.4916, lr_0 = 8.4011e-04
Loss = 4.2778e-03, PNorm = 60.1072, GNorm = 0.6381, lr_0 = 8.3639e-04
Loss = 4.1695e-03, PNorm = 60.1901, GNorm = 0.6902, lr_0 = 8.3269e-04
Loss = 4.5405e-03, PNorm = 60.2849, GNorm = 1.7131, lr_0 = 8.2901e-04
Loss = 4.3321e-03, PNorm = 60.3782, GNorm = 2.6785, lr_0 = 8.2534e-04
Validation rmse logD = 0.725228
Validation R2 logD = 0.614235
Validation rmse logP = 0.675731
Validation R2 logP = 0.826739
Epoch 10
Train function
Loss = 4.3362e-03, PNorm = 60.4972, GNorm = 2.3944, lr_0 = 8.2133e-04
Loss = 4.3682e-03, PNorm = 60.5958, GNorm = 1.1065, lr_0 = 8.1770e-04
Loss = 3.8440e-03, PNorm = 60.6862, GNorm = 0.9886, lr_0 = 8.1408e-04
Loss = 3.4165e-03, PNorm = 60.7596, GNorm = 1.6138, lr_0 = 8.1048e-04
Loss = 4.4185e-03, PNorm = 60.8474, GNorm = 1.1081, lr_0 = 8.0689e-04
Validation rmse logD = 0.631557
Validation R2 logD = 0.707451
Validation rmse logP = 0.706497
Validation R2 logP = 0.810603
Epoch 11
Train function
Loss = 3.4025e-03, PNorm = 60.9289, GNorm = 1.4755, lr_0 = 8.0297e-04
Loss = 4.0596e-03, PNorm = 61.0149, GNorm = 3.6257, lr_0 = 7.9942e-04
Loss = 3.2180e-03, PNorm = 61.1080, GNorm = 0.7634, lr_0 = 7.9588e-04
Loss = 3.7842e-03, PNorm = 61.1890, GNorm = 1.9339, lr_0 = 7.9236e-04
Loss = 3.5141e-03, PNorm = 61.2639, GNorm = 2.1625, lr_0 = 7.8885e-04
Validation rmse logD = 0.620589
Validation R2 logD = 0.717524
Validation rmse logP = 0.692957
Validation R2 logP = 0.817793
Epoch 12
Train function
Loss = 4.1700e-03, PNorm = 61.3404, GNorm = 2.0133, lr_0 = 7.8502e-04
Loss = 3.0259e-03, PNorm = 61.4221, GNorm = 0.9076, lr_0 = 7.8154e-04
Loss = 2.6273e-03, PNorm = 61.5027, GNorm = 0.7312, lr_0 = 7.7809e-04
Loss = 3.1199e-03, PNorm = 61.5638, GNorm = 0.7807, lr_0 = 7.7465e-04
Loss = 2.9755e-03, PNorm = 61.6505, GNorm = 0.6770, lr_0 = 7.7122e-04
Loss = 3.2983e-03, PNorm = 61.7101, GNorm = 1.5198, lr_0 = 7.6781e-04
Loss = 1.7203e-02, PNorm = 61.7129, GNorm = 1.8077, lr_0 = 7.6747e-04
Validation rmse logD = 0.715300
Validation R2 logD = 0.624726
Validation rmse logP = 0.705327
Validation R2 logP = 0.811230
Epoch 13
Train function
Loss = 3.6217e-03, PNorm = 61.7886, GNorm = 3.2203, lr_0 = 7.6407e-04
Loss = 3.7797e-03, PNorm = 61.8907, GNorm = 1.2188, lr_0 = 7.6069e-04
Loss = 2.7955e-03, PNorm = 61.9779, GNorm = 1.2562, lr_0 = 7.5733e-04
Loss = 2.7544e-03, PNorm = 62.0605, GNorm = 0.7623, lr_0 = 7.5398e-04
Loss = 2.9149e-03, PNorm = 62.1377, GNorm = 1.0154, lr_0 = 7.5064e-04
Validation rmse logD = 0.600345
Validation R2 logD = 0.735653
Validation rmse logP = 0.662876
Validation R2 logP = 0.833269
Epoch 14
Train function
Loss = 2.9145e-03, PNorm = 62.2236, GNorm = 1.8901, lr_0 = 7.4699e-04
Loss = 2.4671e-03, PNorm = 62.3141, GNorm = 0.9079, lr_0 = 7.4369e-04
Loss = 2.7273e-03, PNorm = 62.4054, GNorm = 0.5766, lr_0 = 7.4040e-04
Loss = 2.2142e-03, PNorm = 62.4783, GNorm = 1.0180, lr_0 = 7.3712e-04
Loss = 2.6109e-03, PNorm = 62.5429, GNorm = 2.9994, lr_0 = 7.3386e-04
Validation rmse logD = 0.588725
Validation R2 logD = 0.745787
Validation rmse logP = 0.663191
Validation R2 logP = 0.833110
Epoch 15
Train function
Loss = 2.3932e-03, PNorm = 62.6123, GNorm = 2.6191, lr_0 = 7.3029e-04
Loss = 2.3598e-03, PNorm = 62.6901, GNorm = 1.8077, lr_0 = 7.2706e-04
Loss = 2.0813e-03, PNorm = 62.7670, GNorm = 0.8507, lr_0 = 7.2385e-04
Loss = 2.3477e-03, PNorm = 62.8255, GNorm = 1.7573, lr_0 = 7.2064e-04
Loss = 2.2580e-03, PNorm = 62.8813, GNorm = 0.6978, lr_0 = 7.1746e-04
Validation rmse logD = 0.583583
Validation R2 logD = 0.750208
Validation rmse logP = 0.733664
Validation R2 logP = 0.795757
Epoch 16
Train function
Loss = 1.1210e-03, PNorm = 62.9500, GNorm = 0.6526, lr_0 = 7.1397e-04
Loss = 1.8379e-03, PNorm = 63.0052, GNorm = 0.6525, lr_0 = 7.1081e-04
Loss = 2.1986e-03, PNorm = 63.0660, GNorm = 1.2815, lr_0 = 7.0766e-04
Loss = 1.7219e-03, PNorm = 63.1205, GNorm = 0.8051, lr_0 = 7.0453e-04
Loss = 1.5859e-03, PNorm = 63.1726, GNorm = 0.5782, lr_0 = 7.0142e-04
Loss = 1.7089e-03, PNorm = 63.2211, GNorm = 1.4175, lr_0 = 6.9831e-04
Validation rmse logD = 0.637477
Validation R2 logD = 0.701941
Validation rmse logP = 0.716100
Validation R2 logP = 0.805419
Epoch 17
Train function
Loss = 2.0894e-03, PNorm = 63.2849, GNorm = 2.1411, lr_0 = 6.9523e-04
Loss = 1.7510e-03, PNorm = 63.3400, GNorm = 0.7097, lr_0 = 6.9215e-04
Loss = 1.7460e-03, PNorm = 63.4029, GNorm = 1.2018, lr_0 = 6.8909e-04
Loss = 1.7890e-03, PNorm = 63.4596, GNorm = 0.5782, lr_0 = 6.8604e-04
Loss = 1.7447e-03, PNorm = 63.5158, GNorm = 0.5421, lr_0 = 6.8301e-04
Validation rmse logD = 0.676771
Validation R2 logD = 0.664064
Validation rmse logP = 0.709009
Validation R2 logP = 0.809253
Epoch 18
Train function
Loss = 2.2427e-03, PNorm = 63.5885, GNorm = 2.7087, lr_0 = 6.7968e-04
Loss = 1.7477e-03, PNorm = 63.6350, GNorm = 1.2569, lr_0 = 6.7668e-04
Loss = 1.4766e-03, PNorm = 63.6915, GNorm = 0.9215, lr_0 = 6.7368e-04
Loss = 1.4787e-03, PNorm = 63.7383, GNorm = 0.7418, lr_0 = 6.7070e-04
Loss = 1.3777e-03, PNorm = 63.7833, GNorm = 1.7717, lr_0 = 6.6774e-04
Validation rmse logD = 0.578492
Validation R2 logD = 0.754548
Validation rmse logP = 0.706730
Validation R2 logP = 0.810478
Epoch 19
Train function
Loss = 1.1443e-03, PNorm = 63.8397, GNorm = 0.8899, lr_0 = 6.6449e-04
Loss = 1.4644e-03, PNorm = 63.8874, GNorm = 0.9822, lr_0 = 6.6155e-04
Loss = 1.4113e-03, PNorm = 63.9426, GNorm = 1.0964, lr_0 = 6.5862e-04
Loss = 1.4627e-03, PNorm = 63.9925, GNorm = 1.6898, lr_0 = 6.5571e-04
Loss = 1.3476e-03, PNorm = 64.0385, GNorm = 0.8981, lr_0 = 6.5281e-04
Loss = 1.3051e-03, PNorm = 64.0908, GNorm = 1.4897, lr_0 = 6.4992e-04
Validation rmse logD = 0.628555
Validation R2 logD = 0.710226
Validation rmse logP = 0.702519
Validation R2 logP = 0.812729
Epoch 20
Train function
Loss = 1.4277e-03, PNorm = 64.1557, GNorm = 1.6405, lr_0 = 6.4676e-04
Loss = 1.8686e-03, PNorm = 64.2098, GNorm = 1.2939, lr_0 = 6.4390e-04
Loss = 1.5604e-03, PNorm = 64.2755, GNorm = 1.2516, lr_0 = 6.4105e-04
Loss = 1.7309e-03, PNorm = 64.3310, GNorm = 1.6238, lr_0 = 6.3822e-04
Loss = 1.3489e-03, PNorm = 64.3820, GNorm = 1.2810, lr_0 = 6.3539e-04
Validation rmse logD = 0.572778
Validation R2 logD = 0.759372
Validation rmse logP = 0.690404
Validation R2 logP = 0.819133
Epoch 21
Train function
Loss = 1.1374e-03, PNorm = 64.4261, GNorm = 0.5264, lr_0 = 6.3230e-04
Loss = 9.0966e-04, PNorm = 64.4647, GNorm = 0.3852, lr_0 = 6.2950e-04
Loss = 8.8718e-04, PNorm = 64.4984, GNorm = 0.7639, lr_0 = 6.2672e-04
Loss = 9.4135e-04, PNorm = 64.5246, GNorm = 0.4589, lr_0 = 6.2395e-04
Loss = 1.1341e-03, PNorm = 64.5582, GNorm = 0.7033, lr_0 = 6.2119e-04
Validation rmse logD = 0.588825
Validation R2 logD = 0.745701
Validation rmse logP = 0.734475
Validation R2 logP = 0.795305
Epoch 22
Train function
Loss = 9.3950e-04, PNorm = 64.5966, GNorm = 1.1856, lr_0 = 6.1817e-04
Loss = 1.2359e-03, PNorm = 64.6352, GNorm = 0.9180, lr_0 = 6.1543e-04
Loss = 1.0700e-03, PNorm = 64.6829, GNorm = 0.4533, lr_0 = 6.1271e-04
Loss = 1.2014e-03, PNorm = 64.7399, GNorm = 0.5533, lr_0 = 6.1000e-04
Loss = 9.9717e-04, PNorm = 64.7803, GNorm = 0.9531, lr_0 = 6.0730e-04
Loss = 9.8534e-04, PNorm = 64.8065, GNorm = 1.1274, lr_0 = 6.0461e-04
Validation rmse logD = 0.577112
Validation R2 logD = 0.755717
Validation rmse logP = 0.703229
Validation R2 logP = 0.812351
Epoch 23
Train function
Loss = 1.0132e-03, PNorm = 64.8458, GNorm = 0.7626, lr_0 = 6.0167e-04
Loss = 1.0086e-03, PNorm = 64.8813, GNorm = 0.5020, lr_0 = 5.9901e-04
Loss = 8.1089e-04, PNorm = 64.9165, GNorm = 0.6835, lr_0 = 5.9636e-04
Loss = 7.9221e-04, PNorm = 64.9489, GNorm = 0.4798, lr_0 = 5.9372e-04
Loss = 8.9865e-04, PNorm = 64.9796, GNorm = 0.4213, lr_0 = 5.9110e-04
Validation rmse logD = 0.565513
Validation R2 logD = 0.765438
Validation rmse logP = 0.713074
Validation R2 logP = 0.807060
Epoch 24
Train function
Loss = 6.2535e-04, PNorm = 65.0072, GNorm = 1.0449, lr_0 = 5.8822e-04
Loss = 6.6493e-04, PNorm = 65.0305, GNorm = 0.8504, lr_0 = 5.8562e-04
Loss = 9.2351e-04, PNorm = 65.0551, GNorm = 0.5482, lr_0 = 5.8303e-04
Loss = 8.9288e-04, PNorm = 65.0911, GNorm = 0.9974, lr_0 = 5.8045e-04
Loss = 7.8319e-04, PNorm = 65.1230, GNorm = 1.4641, lr_0 = 5.7788e-04
Validation rmse logD = 0.569945
Validation R2 logD = 0.761746
Validation rmse logP = 0.713114
Validation R2 logP = 0.807038
Epoch 25
Train function
Loss = 6.0548e-04, PNorm = 65.1520, GNorm = 0.8996, lr_0 = 5.7533e-04
Loss = 7.6103e-04, PNorm = 65.1839, GNorm = 0.5455, lr_0 = 5.7278e-04
Loss = 7.2002e-04, PNorm = 65.2106, GNorm = 1.7824, lr_0 = 5.7025e-04
Loss = 5.0914e-04, PNorm = 65.2328, GNorm = 0.9513, lr_0 = 5.6773e-04
Loss = 7.5988e-04, PNorm = 65.2635, GNorm = 0.4478, lr_0 = 5.6522e-04
Loss = 7.4321e-04, PNorm = 65.2886, GNorm = 0.6849, lr_0 = 5.6272e-04
Validation rmse logD = 0.589237
Validation R2 logD = 0.745345
Validation rmse logP = 0.709569
Validation R2 logP = 0.808952
Epoch 26
Train function
Loss = 8.2929e-04, PNorm = 65.3250, GNorm = 1.2332, lr_0 = 5.5998e-04
Loss = 7.1170e-04, PNorm = 65.3621, GNorm = 0.5042, lr_0 = 5.5750e-04
Loss = 6.4851e-04, PNorm = 65.3933, GNorm = 1.0123, lr_0 = 5.5503e-04
Loss = 6.3140e-04, PNorm = 65.4100, GNorm = 1.2080, lr_0 = 5.5258e-04
Loss = 7.2566e-04, PNorm = 65.4359, GNorm = 1.4406, lr_0 = 5.5014e-04
Validation rmse logD = 0.569882
Validation R2 logD = 0.761800
Validation rmse logP = 0.719357
Validation R2 logP = 0.803645
Epoch 27
Train function
Loss = 6.7722e-04, PNorm = 65.4663, GNorm = 1.2538, lr_0 = 5.4746e-04
Loss = 6.7541e-04, PNorm = 65.4970, GNorm = 0.3982, lr_0 = 5.4504e-04
Loss = 7.5277e-04, PNorm = 65.5224, GNorm = 1.6400, lr_0 = 5.4263e-04
Loss = 6.1074e-04, PNorm = 65.5531, GNorm = 0.3815, lr_0 = 5.4023e-04
Loss = 5.6519e-04, PNorm = 65.5827, GNorm = 0.6254, lr_0 = 5.3784e-04
Validation rmse logD = 0.573473
Validation R2 logD = 0.758788
Validation rmse logP = 0.742184
Validation R2 logP = 0.790986
Epoch 28
Train function
Loss = 5.6066e-04, PNorm = 65.6063, GNorm = 0.3921, lr_0 = 5.3522e-04
Loss = 5.3135e-04, PNorm = 65.6264, GNorm = 0.7850, lr_0 = 5.3285e-04
Loss = 5.4397e-04, PNorm = 65.6434, GNorm = 1.2575, lr_0 = 5.3050e-04
Loss = 5.7927e-04, PNorm = 65.6678, GNorm = 0.8765, lr_0 = 5.2815e-04
Loss = 5.4211e-04, PNorm = 65.6939, GNorm = 0.7385, lr_0 = 5.2581e-04
Loss = 4.8725e-04, PNorm = 65.7151, GNorm = 0.4548, lr_0 = 5.2349e-04
Loss = 1.8529e-03, PNorm = 65.7172, GNorm = 0.7025, lr_0 = 5.2326e-04
Validation rmse logD = 0.572184
Validation R2 logD = 0.759871
Validation rmse logP = 0.711095
Validation R2 logP = 0.808129
Epoch 29
Train function
Loss = 4.7017e-04, PNorm = 65.7382, GNorm = 0.2280, lr_0 = 5.2094e-04
Loss = 5.5125e-04, PNorm = 65.7575, GNorm = 0.3928, lr_0 = 5.1864e-04
Loss = 4.6152e-04, PNorm = 65.7748, GNorm = 0.4145, lr_0 = 5.1634e-04
Loss = 3.3398e-04, PNorm = 65.7960, GNorm = 0.2845, lr_0 = 5.1406e-04
Loss = 3.4718e-04, PNorm = 65.8142, GNorm = 0.3780, lr_0 = 5.1178e-04
Validation rmse logD = 0.591421
Validation R2 logD = 0.743454
Validation rmse logP = 0.720165
Validation R2 logP = 0.803204
Epoch 30
Train function
Loss = 6.0270e-04, PNorm = 65.8322, GNorm = 0.4921, lr_0 = 5.0930e-04
Loss = 6.8530e-04, PNorm = 65.8523, GNorm = 0.4128, lr_0 = 5.0704e-04
Loss = 5.6922e-04, PNorm = 65.8805, GNorm = 0.7890, lr_0 = 5.0480e-04
Loss = 4.7078e-04, PNorm = 65.9050, GNorm = 0.5018, lr_0 = 5.0257e-04
Loss = 5.1069e-04, PNorm = 65.9282, GNorm = 0.4618, lr_0 = 5.0034e-04
Validation rmse logD = 0.574577
Validation R2 logD = 0.757858
Validation rmse logP = 0.696185
Validation R2 logP = 0.816091
Epoch 31
Train function
Loss = 4.9404e-04, PNorm = 65.9459, GNorm = 0.4627, lr_0 = 4.9791e-04
Loss = 3.8737e-04, PNorm = 65.9653, GNorm = 0.2896, lr_0 = 4.9571e-04
Loss = 3.2827e-04, PNorm = 65.9853, GNorm = 0.4227, lr_0 = 4.9351e-04
Loss = 4.8510e-04, PNorm = 66.0019, GNorm = 0.6101, lr_0 = 4.9133e-04
Loss = 4.0755e-04, PNorm = 66.0142, GNorm = 0.2895, lr_0 = 4.8916e-04
Validation rmse logD = 0.573124
Validation R2 logD = 0.759081
Validation rmse logP = 0.709391
Validation R2 logP = 0.809048
Epoch 32
Train function
Loss = 3.9261e-04, PNorm = 66.0409, GNorm = 1.1498, lr_0 = 4.8678e-04
Loss = 4.8178e-04, PNorm = 66.0648, GNorm = 0.7824, lr_0 = 4.8463e-04
Loss = 3.7689e-04, PNorm = 66.0801, GNorm = 0.6453, lr_0 = 4.8248e-04
Loss = 3.7346e-04, PNorm = 66.0951, GNorm = 0.3716, lr_0 = 4.8035e-04
Loss = 4.3597e-04, PNorm = 66.1121, GNorm = 0.6428, lr_0 = 4.7822e-04
Loss = 3.6894e-04, PNorm = 66.1287, GNorm = 0.4020, lr_0 = 4.7611e-04
Validation rmse logD = 0.565772
Validation R2 logD = 0.765223
Validation rmse logP = 0.727500
Validation R2 logP = 0.799174
Epoch 33
Train function
Loss = 3.3954e-04, PNorm = 66.1490, GNorm = 0.2965, lr_0 = 4.7379e-04
Loss = 3.9117e-04, PNorm = 66.1663, GNorm = 0.7812, lr_0 = 4.7170e-04
Loss = 4.0280e-04, PNorm = 66.1825, GNorm = 0.3374, lr_0 = 4.6961e-04
Loss = 3.8883e-04, PNorm = 66.2023, GNorm = 0.5026, lr_0 = 4.6753e-04
Loss = 3.7482e-04, PNorm = 66.2170, GNorm = 0.3467, lr_0 = 4.6546e-04
Validation rmse logD = 0.584417
Validation R2 logD = 0.749494
Validation rmse logP = 0.716201
Validation R2 logP = 0.805364
Epoch 34
Train function
Loss = 2.4351e-04, PNorm = 66.2346, GNorm = 0.4393, lr_0 = 4.6341e-04
Loss = 3.3479e-04, PNorm = 66.2466, GNorm = 0.7934, lr_0 = 4.6136e-04
Loss = 3.0374e-04, PNorm = 66.2631, GNorm = 0.6612, lr_0 = 4.5931e-04
Loss = 3.4721e-04, PNorm = 66.2814, GNorm = 0.5434, lr_0 = 4.5728e-04
Loss = 3.2125e-04, PNorm = 66.2950, GNorm = 0.6461, lr_0 = 4.5526e-04
Validation rmse logD = 0.570074
Validation R2 logD = 0.761639
Validation rmse logP = 0.697402
Validation R2 logP = 0.815448
Epoch 35
Train function
Loss = 2.8150e-04, PNorm = 66.3122, GNorm = 0.3139, lr_0 = 4.5305e-04
Loss = 2.3204e-04, PNorm = 66.3266, GNorm = 0.2653, lr_0 = 4.5104e-04
Loss = 2.1835e-04, PNorm = 66.3373, GNorm = 0.5526, lr_0 = 4.4905e-04
Loss = 2.7938e-04, PNorm = 66.3464, GNorm = 0.2818, lr_0 = 4.4706e-04
Loss = 2.2531e-04, PNorm = 66.3575, GNorm = 0.2979, lr_0 = 4.4508e-04
Loss = 3.2825e-04, PNorm = 66.3701, GNorm = 0.2823, lr_0 = 4.4311e-04
Validation rmse logD = 0.572675
Validation R2 logD = 0.759459
Validation rmse logP = 0.706148
Validation R2 logP = 0.810790
Epoch 36
Train function
Loss = 2.2210e-04, PNorm = 66.3861, GNorm = 0.4397, lr_0 = 4.4096e-04
Loss = 2.2750e-04, PNorm = 66.4025, GNorm = 0.2358, lr_0 = 4.3901e-04
Loss = 2.9209e-04, PNorm = 66.4147, GNorm = 0.2240, lr_0 = 4.3707e-04
Loss = 2.3420e-04, PNorm = 66.4241, GNorm = 0.4565, lr_0 = 4.3513e-04
Loss = 2.5455e-04, PNorm = 66.4289, GNorm = 0.2116, lr_0 = 4.3321e-04
Validation rmse logD = 0.565558
Validation R2 logD = 0.765401
Validation rmse logP = 0.700817
Validation R2 logP = 0.813636
Epoch 37
Train function
Loss = 2.3442e-04, PNorm = 66.4441, GNorm = 0.1948, lr_0 = 4.3110e-04
Loss = 2.2242e-04, PNorm = 66.4551, GNorm = 0.2443, lr_0 = 4.2919e-04
Loss = 2.2531e-04, PNorm = 66.4653, GNorm = 0.3043, lr_0 = 4.2729e-04
Loss = 1.9355e-04, PNorm = 66.4765, GNorm = 0.4605, lr_0 = 4.2540e-04
Loss = 2.5405e-04, PNorm = 66.4874, GNorm = 0.1830, lr_0 = 4.2352e-04
Validation rmse logD = 0.567685
Validation R2 logD = 0.763633
Validation rmse logP = 0.700796
Validation R2 logP = 0.813647
Epoch 38
Train function
Loss = 1.3872e-04, PNorm = 66.4977, GNorm = 0.3448, lr_0 = 4.2146e-04
Loss = 1.7170e-04, PNorm = 66.5069, GNorm = 0.2381, lr_0 = 4.1960e-04
Loss = 2.0485e-04, PNorm = 66.5169, GNorm = 0.1980, lr_0 = 4.1774e-04
Loss = 1.6516e-04, PNorm = 66.5274, GNorm = 0.2847, lr_0 = 4.1589e-04
Loss = 2.1428e-04, PNorm = 66.5375, GNorm = 0.7822, lr_0 = 4.1406e-04
Loss = 2.1998e-04, PNorm = 66.5512, GNorm = 0.6680, lr_0 = 4.1222e-04
Validation rmse logD = 0.574728
Validation R2 logD = 0.757731
Validation rmse logP = 0.695830
Validation R2 logP = 0.816279
Epoch 39
Train function
Loss = 1.6150e-04, PNorm = 66.5647, GNorm = 0.2719, lr_0 = 4.1022e-04
Loss = 1.7756e-04, PNorm = 66.5736, GNorm = 0.4123, lr_0 = 4.0840e-04
Loss = 1.9690e-04, PNorm = 66.5839, GNorm = 0.2396, lr_0 = 4.0660e-04
Loss = 1.6854e-04, PNorm = 66.5928, GNorm = 0.3808, lr_0 = 4.0480e-04
Loss = 2.1262e-04, PNorm = 66.6008, GNorm = 0.2238, lr_0 = 4.0301e-04
Validation rmse logD = 0.576702
Validation R2 logD = 0.756064
Validation rmse logP = 0.697295
Validation R2 logP = 0.815504
Epoch 40
Train function
Loss = 1.7598e-04, PNorm = 66.6138, GNorm = 0.6326, lr_0 = 4.0105e-04
Loss = 1.9200e-04, PNorm = 66.6212, GNorm = 0.5050, lr_0 = 3.9927e-04
Loss = 1.9962e-04, PNorm = 66.6320, GNorm = 0.4560, lr_0 = 3.9751e-04
Loss = 2.3471e-04, PNorm = 66.6408, GNorm = 0.3826, lr_0 = 3.9575e-04
Loss = 2.2799e-04, PNorm = 66.6523, GNorm = 0.2203, lr_0 = 3.9400e-04
Validation rmse logD = 0.566069
Validation R2 logD = 0.764976
Validation rmse logP = 0.690357
Validation R2 logP = 0.819157
Epoch 41
Train function
Loss = 2.7238e-04, PNorm = 66.6660, GNorm = 0.5827, lr_0 = 3.9208e-04
Loss = 1.8381e-04, PNorm = 66.6785, GNorm = 0.1709, lr_0 = 3.9035e-04
Loss = 1.8157e-04, PNorm = 66.6870, GNorm = 0.5029, lr_0 = 3.8862e-04
Loss = 2.2294e-04, PNorm = 66.7019, GNorm = 0.4669, lr_0 = 3.8690e-04
Loss = 2.2865e-04, PNorm = 66.7154, GNorm = 0.4652, lr_0 = 3.8519e-04
Loss = 1.7002e-04, PNorm = 66.7260, GNorm = 0.6531, lr_0 = 3.8349e-04
Validation rmse logD = 0.568236
Validation R2 logD = 0.763174
Validation rmse logP = 0.691447
Validation R2 logP = 0.818586
Epoch 42
Train function
Loss = 1.3153e-04, PNorm = 66.7380, GNorm = 0.2585, lr_0 = 3.8179e-04
Loss = 1.6166e-04, PNorm = 66.7486, GNorm = 0.2997, lr_0 = 3.8010e-04
Loss = 1.4848e-04, PNorm = 66.7584, GNorm = 0.5126, lr_0 = 3.7842e-04
Loss = 1.6658e-04, PNorm = 66.7659, GNorm = 0.6555, lr_0 = 3.7675e-04
Loss = 2.0009e-04, PNorm = 66.7750, GNorm = 0.4769, lr_0 = 3.7508e-04
Validation rmse logD = 0.568672
Validation R2 logD = 0.762810
Validation rmse logP = 0.689948
Validation R2 logP = 0.819372
Epoch 43
Train function
Loss = 1.1234e-04, PNorm = 66.7833, GNorm = 0.6561, lr_0 = 3.7326e-04
Loss = 1.3780e-04, PNorm = 66.7928, GNorm = 0.2559, lr_0 = 3.7160e-04
Loss = 1.3352e-04, PNorm = 66.8005, GNorm = 0.2600, lr_0 = 3.6996e-04
Loss = 1.5568e-04, PNorm = 66.8077, GNorm = 0.2758, lr_0 = 3.6832e-04
Loss = 1.4241e-04, PNorm = 66.8144, GNorm = 0.5721, lr_0 = 3.6669e-04
Validation rmse logD = 0.582352
Validation R2 logD = 0.751260
Validation rmse logP = 0.691939
Validation R2 logP = 0.818328
Epoch 44
Train function
Loss = 1.8342e-04, PNorm = 66.8312, GNorm = 0.5192, lr_0 = 3.6491e-04
Loss = 2.8451e-04, PNorm = 66.8519, GNorm = 0.8533, lr_0 = 3.6330e-04
Loss = 3.5400e-04, PNorm = 66.8653, GNorm = 0.4658, lr_0 = 3.6169e-04
Loss = 2.4704e-04, PNorm = 66.8821, GNorm = 0.7258, lr_0 = 3.6009e-04
Loss = 2.4790e-04, PNorm = 66.8985, GNorm = 0.7629, lr_0 = 3.5850e-04
Loss = 2.2883e-04, PNorm = 66.9110, GNorm = 0.2112, lr_0 = 3.5691e-04
Loss = 3.9283e-04, PNorm = 66.9125, GNorm = 0.5825, lr_0 = 3.5675e-04
Validation rmse logD = 0.565374
Validation R2 logD = 0.765553
Validation rmse logP = 0.699210
Validation R2 logP = 0.814489
Epoch 45
Train function
Loss = 1.6189e-04, PNorm = 66.9252, GNorm = 0.4958, lr_0 = 3.5518e-04
Loss = 1.4490e-04, PNorm = 66.9323, GNorm = 0.3433, lr_0 = 3.5360e-04
Loss = 1.7103e-04, PNorm = 66.9396, GNorm = 0.2955, lr_0 = 3.5204e-04
Loss = 2.2058e-04, PNorm = 66.9502, GNorm = 0.9212, lr_0 = 3.5048e-04
Loss = 1.5176e-04, PNorm = 66.9608, GNorm = 0.4867, lr_0 = 3.4893e-04
Validation rmse logD = 0.573487
Validation R2 logD = 0.758776
Validation rmse logP = 0.685585
Validation R2 logP = 0.821649
Epoch 46
Train function
Loss = 1.0667e-04, PNorm = 66.9643, GNorm = 0.4774, lr_0 = 3.4724e-04
Loss = 1.3189e-04, PNorm = 66.9707, GNorm = 0.4325, lr_0 = 3.4570e-04
Loss = 1.6187e-04, PNorm = 66.9794, GNorm = 0.2188, lr_0 = 3.4417e-04
Loss = 1.5597e-04, PNorm = 66.9902, GNorm = 0.4062, lr_0 = 3.4265e-04
Loss = 1.3518e-04, PNorm = 66.9968, GNorm = 0.2297, lr_0 = 3.4113e-04
Validation rmse logD = 0.571352
Validation R2 logD = 0.760569
Validation rmse logP = 0.695307
Validation R2 logP = 0.816555
Epoch 47
Train function
Loss = 1.0536e-04, PNorm = 67.0050, GNorm = 0.1696, lr_0 = 3.3947e-04
Loss = 1.0900e-04, PNorm = 67.0118, GNorm = 0.1862, lr_0 = 3.3797e-04
Loss = 9.2629e-05, PNorm = 67.0166, GNorm = 0.3727, lr_0 = 3.3648e-04
Loss = 1.1506e-04, PNorm = 67.0217, GNorm = 0.3406, lr_0 = 3.3499e-04
Loss = 1.0921e-04, PNorm = 67.0285, GNorm = 0.2303, lr_0 = 3.3351e-04
Validation rmse logD = 0.577285
Validation R2 logD = 0.755571
Validation rmse logP = 0.689089
Validation R2 logP = 0.819821
Epoch 48
Train function
Loss = 2.2173e-04, PNorm = 67.0356, GNorm = 0.9259, lr_0 = 3.3188e-04
Loss = 1.1798e-04, PNorm = 67.0411, GNorm = 0.3781, lr_0 = 3.3042e-04
Loss = 1.1828e-04, PNorm = 67.0490, GNorm = 0.4462, lr_0 = 3.2895e-04
Loss = 1.1612e-04, PNorm = 67.0541, GNorm = 0.2823, lr_0 = 3.2750e-04
Loss = 8.1134e-05, PNorm = 67.0592, GNorm = 0.2649, lr_0 = 3.2605e-04
Loss = 7.8153e-05, PNorm = 67.0664, GNorm = 0.2246, lr_0 = 3.2461e-04
Validation rmse logD = 0.573173
Validation R2 logD = 0.759040
Validation rmse logP = 0.690029
Validation R2 logP = 0.819329
Epoch 49
Train function
Loss = 7.4941e-05, PNorm = 67.0720, GNorm = 0.1620, lr_0 = 3.2303e-04
Loss = 8.6972e-05, PNorm = 67.0770, GNorm = 0.3972, lr_0 = 3.2160e-04
Loss = 1.0042e-04, PNorm = 67.0812, GNorm = 0.2569, lr_0 = 3.2018e-04
Loss = 9.6971e-05, PNorm = 67.0870, GNorm = 0.5069, lr_0 = 3.1876e-04
Loss = 1.0009e-04, PNorm = 67.0931, GNorm = 0.2917, lr_0 = 3.1735e-04
Validation rmse logD = 0.572412
Validation R2 logD = 0.759679
Validation rmse logP = 0.685592
Validation R2 logP = 0.821645
Epoch 50
Train function
Loss = 8.5080e-05, PNorm = 67.0980, GNorm = 0.1505, lr_0 = 3.1595e-04
Loss = 9.4153e-05, PNorm = 67.1028, GNorm = 0.2018, lr_0 = 3.1455e-04
Loss = 9.2995e-05, PNorm = 67.1063, GNorm = 0.2433, lr_0 = 3.1316e-04
Loss = 7.2402e-05, PNorm = 67.1119, GNorm = 0.1116, lr_0 = 3.1177e-04
Loss = 1.1689e-04, PNorm = 67.1174, GNorm = 0.5022, lr_0 = 3.1039e-04
Validation rmse logD = 0.573979
Validation R2 logD = 0.758362
Validation rmse logP = 0.694626
Validation R2 logP = 0.816914
Epoch 51
Train function
Loss = 1.3729e-04, PNorm = 67.1259, GNorm = 0.2442, lr_0 = 3.0888e-04
Loss = 1.1804e-04, PNorm = 67.1353, GNorm = 0.1555, lr_0 = 3.0752e-04
Loss = 1.2603e-04, PNorm = 67.1410, GNorm = 0.2716, lr_0 = 3.0616e-04
Loss = 1.0178e-04, PNorm = 67.1477, GNorm = 0.3833, lr_0 = 3.0480e-04
Loss = 8.6241e-05, PNorm = 67.1511, GNorm = 0.3692, lr_0 = 3.0346e-04
Loss = 8.3797e-05, PNorm = 67.1547, GNorm = 0.4146, lr_0 = 3.0211e-04
Validation rmse logD = 0.571444
Validation R2 logD = 0.760492
Validation rmse logP = 0.678818
Validation R2 logP = 0.825152
Epoch 52
Train function
Loss = 9.9433e-05, PNorm = 67.1634, GNorm = 0.2569, lr_0 = 3.0064e-04
Loss = 1.2923e-04, PNorm = 67.1722, GNorm = 0.3419, lr_0 = 2.9931e-04
Loss = 1.1492e-04, PNorm = 67.1789, GNorm = 0.3052, lr_0 = 2.9799e-04
Loss = 9.0814e-05, PNorm = 67.1845, GNorm = 0.3603, lr_0 = 2.9667e-04
Loss = 9.7677e-05, PNorm = 67.1895, GNorm = 0.2043, lr_0 = 2.9536e-04
Validation rmse logD = 0.575652
Validation R2 logD = 0.756951
Validation rmse logP = 0.686734
Validation R2 logP = 0.821051
Epoch 53
Train function
Loss = 9.3442e-05, PNorm = 67.1955, GNorm = 0.4666, lr_0 = 2.9392e-04
Loss = 9.7682e-05, PNorm = 67.1972, GNorm = 0.7109, lr_0 = 2.9262e-04
Loss = 1.1318e-04, PNorm = 67.2008, GNorm = 0.3531, lr_0 = 2.9133e-04
Loss = 9.2012e-05, PNorm = 67.2073, GNorm = 0.2286, lr_0 = 2.9004e-04
Loss = 8.5692e-05, PNorm = 67.2113, GNorm = 0.2167, lr_0 = 2.8876e-04
Validation rmse logD = 0.578144
Validation R2 logD = 0.754842
Validation rmse logP = 0.679861
Validation R2 logP = 0.824615
Epoch 54
Train function
Loss = 9.6809e-05, PNorm = 67.2187, GNorm = 0.3425, lr_0 = 2.8735e-04
Loss = 8.3781e-05, PNorm = 67.2242, GNorm = 0.1981, lr_0 = 2.8608e-04
Loss = 6.4221e-05, PNorm = 67.2297, GNorm = 0.3018, lr_0 = 2.8482e-04
Loss = 7.1606e-05, PNorm = 67.2345, GNorm = 0.1598, lr_0 = 2.8356e-04
Loss = 1.0123e-04, PNorm = 67.2377, GNorm = 0.5915, lr_0 = 2.8230e-04
Loss = 1.0200e-04, PNorm = 67.2442, GNorm = 0.3812, lr_0 = 2.8105e-04
Validation rmse logD = 0.572350
Validation R2 logD = 0.759732
Validation rmse logP = 0.679743
Validation R2 logP = 0.824675
Epoch 55
Train function
Loss = 6.9729e-05, PNorm = 67.2484, GNorm = 0.2213, lr_0 = 2.7969e-04
Loss = 5.7486e-05, PNorm = 67.2542, GNorm = 0.1795, lr_0 = 2.7845e-04
Loss = 6.4547e-05, PNorm = 67.2567, GNorm = 0.2226, lr_0 = 2.7722e-04
Loss = 6.0457e-05, PNorm = 67.2587, GNorm = 0.1884, lr_0 = 2.7599e-04
Loss = 6.2835e-05, PNorm = 67.2623, GNorm = 0.2519, lr_0 = 2.7477e-04
Validation rmse logD = 0.573138
Validation R2 logD = 0.759070
Validation rmse logP = 0.681011
Validation R2 logP = 0.824021
Epoch 56
Train function
Loss = 5.5108e-05, PNorm = 67.2672, GNorm = 0.3005, lr_0 = 2.7343e-04
Loss = 7.2231e-05, PNorm = 67.2709, GNorm = 0.5677, lr_0 = 2.7222e-04
Loss = 7.2651e-05, PNorm = 67.2750, GNorm = 0.5516, lr_0 = 2.7102e-04
Loss = 6.5575e-05, PNorm = 67.2801, GNorm = 0.0877, lr_0 = 2.6982e-04
Loss = 8.2743e-05, PNorm = 67.2845, GNorm = 0.4865, lr_0 = 2.6863e-04
Validation rmse logD = 0.572497
Validation R2 logD = 0.759608
Validation rmse logP = 0.679389
Validation R2 logP = 0.824858
Epoch 57
Train function
Loss = 7.2902e-05, PNorm = 67.2891, GNorm = 0.5896, lr_0 = 2.6732e-04
Loss = 7.6330e-05, PNorm = 67.2935, GNorm = 0.2459, lr_0 = 2.6614e-04
Loss = 5.5961e-05, PNorm = 67.2978, GNorm = 0.5407, lr_0 = 2.6496e-04
Loss = 7.1214e-05, PNorm = 67.3029, GNorm = 0.5389, lr_0 = 2.6379e-04
Loss = 5.8087e-05, PNorm = 67.3068, GNorm = 0.1207, lr_0 = 2.6262e-04
Loss = 6.8454e-05, PNorm = 67.3117, GNorm = 0.1972, lr_0 = 2.6146e-04
Loss = 2.5704e-04, PNorm = 67.3120, GNorm = 0.2547, lr_0 = 2.6134e-04
Validation rmse logD = 0.575895
Validation R2 logD = 0.756746
Validation rmse logP = 0.673841
Validation R2 logP = 0.827707
Epoch 58
Train function
Loss = 4.6794e-05, PNorm = 67.3130, GNorm = 0.1294, lr_0 = 2.6019e-04
Loss = 5.2684e-05, PNorm = 67.3180, GNorm = 0.2692, lr_0 = 2.5904e-04
Loss = 4.8624e-05, PNorm = 67.3222, GNorm = 0.1268, lr_0 = 2.5789e-04
Loss = 6.7563e-05, PNorm = 67.3274, GNorm = 0.2634, lr_0 = 2.5675e-04
Loss = 4.2970e-05, PNorm = 67.3317, GNorm = 0.1696, lr_0 = 2.5561e-04
Validation rmse logD = 0.575856
Validation R2 logD = 0.756779
Validation rmse logP = 0.678698
Validation R2 logP = 0.825214
Epoch 59
Train function
Loss = 1.1737e-04, PNorm = 67.3354, GNorm = 0.2941, lr_0 = 2.5448e-04
Loss = 7.2260e-05, PNorm = 67.3383, GNorm = 0.1099, lr_0 = 2.5336e-04
Loss = 9.0031e-05, PNorm = 67.3420, GNorm = 0.2277, lr_0 = 2.5224e-04
Loss = 6.1133e-05, PNorm = 67.3459, GNorm = 0.3876, lr_0 = 2.5112e-04
Loss = 6.5655e-05, PNorm = 67.3517, GNorm = 0.4163, lr_0 = 2.5001e-04
Validation rmse logD = 0.579494
Validation R2 logD = 0.753696
Validation rmse logP = 0.674884
Validation R2 logP = 0.827173
Epoch 60
Train function
Loss = 1.1217e-04, PNorm = 67.3572, GNorm = 0.3866, lr_0 = 2.4879e-04
Loss = 9.6218e-05, PNorm = 67.3622, GNorm = 0.1555, lr_0 = 2.4769e-04
Loss = 8.3888e-05, PNorm = 67.3629, GNorm = 0.2351, lr_0 = 2.4660e-04
Loss = 7.6696e-05, PNorm = 67.3666, GNorm = 0.4379, lr_0 = 2.4551e-04
Loss = 5.9371e-05, PNorm = 67.3719, GNorm = 0.0958, lr_0 = 2.4442e-04
Loss = 4.7689e-05, PNorm = 67.3771, GNorm = 0.4338, lr_0 = 2.4334e-04
Loss = 4.6784e-04, PNorm = 67.3778, GNorm = 0.4821, lr_0 = 2.4323e-04
Validation rmse logD = 0.573021
Validation R2 logD = 0.759168
Validation rmse logP = 0.678251
Validation R2 logP = 0.825444
Epoch 61
Train function
Loss = 4.5655e-05, PNorm = 67.3839, GNorm = 0.2209, lr_0 = 2.4216e-04
Loss = 4.6630e-05, PNorm = 67.3860, GNorm = 0.2911, lr_0 = 2.4109e-04
Loss = 5.3586e-05, PNorm = 67.3890, GNorm = 0.3060, lr_0 = 2.4002e-04
Loss = 5.1197e-05, PNorm = 67.3920, GNorm = 0.1288, lr_0 = 2.3896e-04
Loss = 4.9063e-05, PNorm = 67.3951, GNorm = 0.3115, lr_0 = 2.3790e-04
Validation rmse logD = 0.573117
Validation R2 logD = 0.759088
Validation rmse logP = 0.673830
Validation R2 logP = 0.827713
Epoch 62
Train function
Loss = 4.6160e-05, PNorm = 67.3986, GNorm = 0.1759, lr_0 = 2.3674e-04
Loss = 5.1743e-05, PNorm = 67.4005, GNorm = 0.1292, lr_0 = 2.3570e-04
Loss = 4.4348e-05, PNorm = 67.4033, GNorm = 0.1362, lr_0 = 2.3465e-04
Loss = 3.5744e-05, PNorm = 67.4058, GNorm = 0.1213, lr_0 = 2.3362e-04
Loss = 4.2071e-05, PNorm = 67.4096, GNorm = 0.2208, lr_0 = 2.3258e-04
Validation rmse logD = 0.572477
Validation R2 logD = 0.759625
Validation rmse logP = 0.676564
Validation R2 logP = 0.826312
Epoch 63
Train function
Loss = 4.8376e-05, PNorm = 67.4127, GNorm = 0.3242, lr_0 = 2.3145e-04
Loss = 3.1773e-05, PNorm = 67.4145, GNorm = 0.1148, lr_0 = 2.3043e-04
Loss = 3.0861e-05, PNorm = 67.4163, GNorm = 0.2285, lr_0 = 2.2941e-04
Loss = 3.5089e-05, PNorm = 67.4189, GNorm = 0.1934, lr_0 = 2.2839e-04
Loss = 3.5297e-05, PNorm = 67.4221, GNorm = 0.1536, lr_0 = 2.2738e-04
Validation rmse logD = 0.575888
Validation R2 logD = 0.756752
Validation rmse logP = 0.673319
Validation R2 logP = 0.827974
Epoch 64
Train function
Loss = 2.7985e-05, PNorm = 67.4245, GNorm = 0.1271, lr_0 = 2.2628e-04
Loss = 3.6591e-05, PNorm = 67.4264, GNorm = 0.0792, lr_0 = 2.2528e-04
Loss = 3.4349e-05, PNorm = 67.4287, GNorm = 0.1274, lr_0 = 2.2428e-04
Loss = 3.5330e-05, PNorm = 67.4319, GNorm = 0.3466, lr_0 = 2.2329e-04
Loss = 2.8945e-05, PNorm = 67.4347, GNorm = 0.1526, lr_0 = 2.2230e-04
Loss = 3.4424e-05, PNorm = 67.4379, GNorm = 0.1531, lr_0 = 2.2132e-04
Validation rmse logD = 0.573132
Validation R2 logD = 0.759075
Validation rmse logP = 0.672941
Validation R2 logP = 0.828167
Epoch 65
Train function
Loss = 3.5571e-05, PNorm = 67.4420, GNorm = 0.1026, lr_0 = 2.2024e-04
Loss = 3.2525e-05, PNorm = 67.4443, GNorm = 0.0948, lr_0 = 2.1927e-04
Loss = 2.5717e-05, PNorm = 67.4472, GNorm = 0.1560, lr_0 = 2.1830e-04
Loss = 2.3781e-05, PNorm = 67.4493, GNorm = 0.1304, lr_0 = 2.1733e-04
Loss = 3.4595e-05, PNorm = 67.4526, GNorm = 0.1140, lr_0 = 2.1637e-04
Validation rmse logD = 0.574354
Validation R2 logD = 0.758046
Validation rmse logP = 0.672291
Validation R2 logP = 0.828498
Epoch 66
Train function
Loss = 7.0843e-05, PNorm = 67.4536, GNorm = 0.6637, lr_0 = 2.1532e-04
Loss = 6.7531e-05, PNorm = 67.4576, GNorm = 0.4416, lr_0 = 2.1436e-04
Loss = 6.4298e-05, PNorm = 67.4606, GNorm = 0.2927, lr_0 = 2.1342e-04
Loss = 4.7737e-05, PNorm = 67.4652, GNorm = 0.1636, lr_0 = 2.1247e-04
Loss = 3.6830e-05, PNorm = 67.4666, GNorm = 0.2965, lr_0 = 2.1153e-04
Validation rmse logD = 0.576600
Validation R2 logD = 0.756151
Validation rmse logP = 0.672061
Validation R2 logP = 0.828616
Epoch 67
Train function
Loss = 6.9130e-05, PNorm = 67.4679, GNorm = 0.5995, lr_0 = 2.1060e-04
Loss = 5.4565e-05, PNorm = 67.4714, GNorm = 0.1783, lr_0 = 2.0966e-04
Loss = 3.7736e-05, PNorm = 67.4748, GNorm = 0.1610, lr_0 = 2.0874e-04
Loss = 3.8247e-05, PNorm = 67.4786, GNorm = 0.1701, lr_0 = 2.0781e-04
Loss = 4.2094e-05, PNorm = 67.4814, GNorm = 0.1369, lr_0 = 2.0689e-04
Loss = 3.9612e-05, PNorm = 67.4838, GNorm = 0.1413, lr_0 = 2.0598e-04
Validation rmse logD = 0.575924
Validation R2 logD = 0.756722
Validation rmse logP = 0.675757
Validation R2 logP = 0.826726
Epoch 68
Train function
Loss = 4.6932e-05, PNorm = 67.4872, GNorm = 0.1307, lr_0 = 2.0498e-04
Loss = 3.3194e-05, PNorm = 67.4920, GNorm = 0.1274, lr_0 = 2.0407e-04
Loss = 3.5343e-05, PNorm = 67.4952, GNorm = 0.1572, lr_0 = 2.0317e-04
Loss = 2.9951e-05, PNorm = 67.4970, GNorm = 0.1422, lr_0 = 2.0227e-04
Loss = 3.2138e-05, PNorm = 67.4993, GNorm = 0.1913, lr_0 = 2.0137e-04
Validation rmse logD = 0.574981
Validation R2 logD = 0.757518
Validation rmse logP = 0.678227
Validation R2 logP = 0.825457
Epoch 69
Train function
Loss = 2.2865e-05, PNorm = 67.5006, GNorm = 0.0897, lr_0 = 2.0039e-04
Loss = 2.5773e-05, PNorm = 67.5025, GNorm = 0.0838, lr_0 = 1.9951e-04
Loss = 2.5481e-05, PNorm = 67.5055, GNorm = 0.1615, lr_0 = 1.9863e-04
Loss = 2.7656e-05, PNorm = 67.5076, GNorm = 0.1701, lr_0 = 1.9775e-04
Loss = 2.4540e-05, PNorm = 67.5089, GNorm = 0.1116, lr_0 = 1.9687e-04
Validation rmse logD = 0.576486
Validation R2 logD = 0.756247
Validation rmse logP = 0.677609
Validation R2 logP = 0.825775
Epoch 70
Train function
Loss = 2.8132e-05, PNorm = 67.5104, GNorm = 0.0881, lr_0 = 1.9592e-04
Loss = 3.5272e-05, PNorm = 67.5112, GNorm = 0.3198, lr_0 = 1.9505e-04
Loss = 3.3875e-05, PNorm = 67.5138, GNorm = 0.2390, lr_0 = 1.9419e-04
Loss = 3.0186e-05, PNorm = 67.5171, GNorm = 0.2333, lr_0 = 1.9333e-04
Loss = 2.8308e-05, PNorm = 67.5184, GNorm = 0.3048, lr_0 = 1.9247e-04
Loss = 2.4163e-05, PNorm = 67.5205, GNorm = 0.1296, lr_0 = 1.9162e-04
Validation rmse logD = 0.575393
Validation R2 logD = 0.757170
Validation rmse logP = 0.673952
Validation R2 logP = 0.827650
Epoch 71
Train function
Loss = 2.5326e-05, PNorm = 67.5219, GNorm = 0.4165, lr_0 = 1.9069e-04
Loss = 2.3583e-05, PNorm = 67.5222, GNorm = 0.1981, lr_0 = 1.8984e-04
Loss = 2.3289e-05, PNorm = 67.5240, GNorm = 0.1545, lr_0 = 1.8900e-04
Loss = 2.4896e-05, PNorm = 67.5266, GNorm = 0.0684, lr_0 = 1.8817e-04
Loss = 3.0342e-05, PNorm = 67.5276, GNorm = 0.0805, lr_0 = 1.8734e-04
Validation rmse logD = 0.572728
Validation R2 logD = 0.759414
Validation rmse logP = 0.674117
Validation R2 logP = 0.827566
Epoch 72
Train function
Loss = 2.4840e-05, PNorm = 67.5317, GNorm = 0.1017, lr_0 = 1.8643e-04
Loss = 2.6943e-05, PNorm = 67.5339, GNorm = 0.1376, lr_0 = 1.8560e-04
Loss = 2.9808e-05, PNorm = 67.5367, GNorm = 0.1378, lr_0 = 1.8478e-04
Loss = 2.3748e-05, PNorm = 67.5365, GNorm = 0.2169, lr_0 = 1.8396e-04
Loss = 2.3697e-05, PNorm = 67.5389, GNorm = 0.1060, lr_0 = 1.8315e-04
Validation rmse logD = 0.573600
Validation R2 logD = 0.758681
Validation rmse logP = 0.673706
Validation R2 logP = 0.827776
Epoch 73
Train function
Loss = 1.8167e-05, PNorm = 67.5401, GNorm = 0.0700, lr_0 = 1.8226e-04
Loss = 1.8444e-05, PNorm = 67.5425, GNorm = 0.1280, lr_0 = 1.8145e-04
Loss = 1.7868e-05, PNorm = 67.5436, GNorm = 0.1865, lr_0 = 1.8065e-04
Loss = 1.9208e-05, PNorm = 67.5447, GNorm = 0.0796, lr_0 = 1.7985e-04
Loss = 2.1373e-05, PNorm = 67.5466, GNorm = 0.2021, lr_0 = 1.7905e-04
Loss = 1.8209e-05, PNorm = 67.5486, GNorm = 0.0749, lr_0 = 1.7826e-04
Loss = 1.3449e-04, PNorm = 67.5488, GNorm = 0.1750, lr_0 = 1.7818e-04
Validation rmse logD = 0.575034
Validation R2 logD = 0.757473
Validation rmse logP = 0.677644
Validation R2 logP = 0.825757
Epoch 74
Train function
Loss = 1.9598e-05, PNorm = 67.5507, GNorm = 0.1414, lr_0 = 1.7739e-04
Loss = 2.0592e-05, PNorm = 67.5521, GNorm = 0.2834, lr_0 = 1.7661e-04
Loss = 2.1321e-05, PNorm = 67.5536, GNorm = 0.2293, lr_0 = 1.7583e-04
Loss = 1.2970e-05, PNorm = 67.5549, GNorm = 0.1277, lr_0 = 1.7505e-04
Loss = 1.9268e-05, PNorm = 67.5557, GNorm = 0.2290, lr_0 = 1.7428e-04
Validation rmse logD = 0.575123
Validation R2 logD = 0.757398
Validation rmse logP = 0.675075
Validation R2 logP = 0.827075
Epoch 75
Train function
Loss = 2.2263e-05, PNorm = 67.5577, GNorm = 0.1091, lr_0 = 1.7351e-04
Loss = 1.9131e-05, PNorm = 67.5589, GNorm = 0.3135, lr_0 = 1.7274e-04
Loss = 1.9186e-05, PNorm = 67.5598, GNorm = 0.1106, lr_0 = 1.7197e-04
Loss = 1.3567e-05, PNorm = 67.5608, GNorm = 0.0773, lr_0 = 1.7121e-04
Loss = 1.8586e-05, PNorm = 67.5624, GNorm = 0.1532, lr_0 = 1.7046e-04
Validation rmse logD = 0.573403
Validation R2 logD = 0.758847
Validation rmse logP = 0.671636
Validation R2 logP = 0.828833
Epoch 76
Train function
Loss = 1.0986e-05, PNorm = 67.5636, GNorm = 0.0669, lr_0 = 1.6963e-04
Loss = 1.4531e-05, PNorm = 67.5646, GNorm = 0.0789, lr_0 = 1.6888e-04
Loss = 1.4482e-05, PNorm = 67.5656, GNorm = 0.2108, lr_0 = 1.6813e-04
Loss = 1.2703e-05, PNorm = 67.5667, GNorm = 0.1530, lr_0 = 1.6739e-04
Loss = 2.0057e-05, PNorm = 67.5685, GNorm = 0.1080, lr_0 = 1.6665e-04
Loss = 1.8130e-05, PNorm = 67.5700, GNorm = 0.0801, lr_0 = 1.6591e-04
Loss = 1.4098e-04, PNorm = 67.5701, GNorm = 0.2244, lr_0 = 1.6584e-04
Validation rmse logD = 0.574368
Validation R2 logD = 0.758034
Validation rmse logP = 0.676548
Validation R2 logP = 0.826320
Epoch 77
Train function
Loss = 1.7137e-05, PNorm = 67.5719, GNorm = 0.0800, lr_0 = 1.6510e-04
Loss = 1.8346e-05, PNorm = 67.5733, GNorm = 0.0709, lr_0 = 1.6437e-04
Loss = 1.7177e-05, PNorm = 67.5746, GNorm = 0.0647, lr_0 = 1.6364e-04
Loss = 2.0135e-05, PNorm = 67.5762, GNorm = 0.0863, lr_0 = 1.6292e-04
Loss = 1.2655e-05, PNorm = 67.5781, GNorm = 0.0691, lr_0 = 1.6220e-04
Validation rmse logD = 0.575384
Validation R2 logD = 0.757177
Validation rmse logP = 0.674300
Validation R2 logP = 0.827472
Epoch 78
Train function
Loss = 1.3786e-05, PNorm = 67.5799, GNorm = 0.1240, lr_0 = 1.6141e-04
Loss = 1.4004e-05, PNorm = 67.5812, GNorm = 0.0962, lr_0 = 1.6070e-04
Loss = 1.7436e-05, PNorm = 67.5831, GNorm = 0.0874, lr_0 = 1.5999e-04
Loss = 1.4368e-05, PNorm = 67.5852, GNorm = 0.0547, lr_0 = 1.5928e-04
Loss = 2.4773e-05, PNorm = 67.5864, GNorm = 0.2634, lr_0 = 1.5857e-04
Validation rmse logD = 0.574736
Validation R2 logD = 0.757724
Validation rmse logP = 0.670535
Validation R2 logP = 0.829393
Epoch 79
Train function
Loss = 1.8802e-05, PNorm = 67.5876, GNorm = 0.2185, lr_0 = 1.5780e-04
Loss = 1.6162e-05, PNorm = 67.5890, GNorm = 0.1418, lr_0 = 1.5710e-04
Loss = 2.0643e-05, PNorm = 67.5898, GNorm = 0.0912, lr_0 = 1.5641e-04
Loss = 1.9940e-05, PNorm = 67.5913, GNorm = 0.1038, lr_0 = 1.5572e-04
Loss = 1.9082e-05, PNorm = 67.5922, GNorm = 0.1310, lr_0 = 1.5503e-04
Validation rmse logD = 0.575874
Validation R2 logD = 0.756764
Validation rmse logP = 0.673755
Validation R2 logP = 0.827751
Epoch 80
Train function
Loss = 7.1648e-06, PNorm = 67.5937, GNorm = 0.0651, lr_0 = 1.5427e-04
Loss = 1.6339e-05, PNorm = 67.5959, GNorm = 0.1841, lr_0 = 1.5359e-04
Loss = 1.4036e-05, PNorm = 67.5982, GNorm = 0.1373, lr_0 = 1.5291e-04
Loss = 1.3450e-05, PNorm = 67.5995, GNorm = 0.2599, lr_0 = 1.5224e-04
Loss = 1.2571e-05, PNorm = 67.6001, GNorm = 0.1281, lr_0 = 1.5156e-04
Loss = 1.1891e-05, PNorm = 67.6017, GNorm = 0.0550, lr_0 = 1.5089e-04
Validation rmse logD = 0.575133
Validation R2 logD = 0.757390
Validation rmse logP = 0.672448
Validation R2 logP = 0.828418
Epoch 81
Train function
Loss = 9.2397e-06, PNorm = 67.6032, GNorm = 0.1619, lr_0 = 1.5016e-04
Loss = 1.3477e-05, PNorm = 67.6029, GNorm = 0.1632, lr_0 = 1.4949e-04
Loss = 1.6233e-05, PNorm = 67.6032, GNorm = 0.1185, lr_0 = 1.4883e-04
Loss = 1.1360e-05, PNorm = 67.6045, GNorm = 0.0631, lr_0 = 1.4817e-04
Loss = 1.4570e-05, PNorm = 67.6047, GNorm = 0.0627, lr_0 = 1.4752e-04
Validation rmse logD = 0.576163
Validation R2 logD = 0.756520
Validation rmse logP = 0.672500
Validation R2 logP = 0.828392
Epoch 82
Train function
Loss = 1.5412e-05, PNorm = 67.6065, GNorm = 0.0842, lr_0 = 1.4680e-04
Loss = 2.1349e-05, PNorm = 67.6087, GNorm = 0.2466, lr_0 = 1.4615e-04
Loss = 1.2493e-05, PNorm = 67.6094, GNorm = 0.1292, lr_0 = 1.4551e-04
Loss = 1.3983e-05, PNorm = 67.6103, GNorm = 0.1610, lr_0 = 1.4486e-04
Loss = 1.1978e-05, PNorm = 67.6111, GNorm = 0.1367, lr_0 = 1.4422e-04
Validation rmse logD = 0.574379
Validation R2 logD = 0.758025
Validation rmse logP = 0.673326
Validation R2 logP = 0.827970
Epoch 83
Train function
Loss = 6.3320e-06, PNorm = 67.6118, GNorm = 0.0552, lr_0 = 1.4352e-04
Loss = 1.2440e-05, PNorm = 67.6132, GNorm = 0.1034, lr_0 = 1.4288e-04
Loss = 1.1633e-05, PNorm = 67.6143, GNorm = 0.0905, lr_0 = 1.4225e-04
Loss = 1.2010e-05, PNorm = 67.6154, GNorm = 0.1984, lr_0 = 1.4162e-04
Loss = 1.2119e-05, PNorm = 67.6164, GNorm = 0.0649, lr_0 = 1.4100e-04
Loss = 1.4830e-05, PNorm = 67.6173, GNorm = 0.0932, lr_0 = 1.4037e-04
Validation rmse logD = 0.574405
Validation R2 logD = 0.758003
Validation rmse logP = 0.669089
Validation R2 logP = 0.830129
Epoch 84
Train function
Loss = 1.8712e-05, PNorm = 67.6190, GNorm = 0.1275, lr_0 = 1.3975e-04
Loss = 2.2120e-05, PNorm = 67.6196, GNorm = 0.2668, lr_0 = 1.3913e-04
Loss = 2.1845e-05, PNorm = 67.6216, GNorm = 0.0761, lr_0 = 1.3852e-04
Loss = 1.5615e-05, PNorm = 67.6234, GNorm = 0.1328, lr_0 = 1.3791e-04
Loss = 1.0428e-05, PNorm = 67.6249, GNorm = 0.0793, lr_0 = 1.3730e-04
Validation rmse logD = 0.576029
Validation R2 logD = 0.756633
Validation rmse logP = 0.675092
Validation R2 logP = 0.827066
Epoch 85
Train function
Loss = 9.4671e-06, PNorm = 67.6255, GNorm = 0.0980, lr_0 = 1.3663e-04
Loss = 1.5376e-05, PNorm = 67.6272, GNorm = 0.1968, lr_0 = 1.3602e-04
Loss = 1.2912e-05, PNorm = 67.6277, GNorm = 0.1072, lr_0 = 1.3542e-04
Loss = 1.6964e-05, PNorm = 67.6293, GNorm = 0.2401, lr_0 = 1.3482e-04
Loss = 1.7180e-05, PNorm = 67.6303, GNorm = 0.0965, lr_0 = 1.3423e-04
Validation rmse logD = 0.575860
Validation R2 logD = 0.756776
Validation rmse logP = 0.674361
Validation R2 logP = 0.827441
Epoch 86
Train function
Loss = 1.6200e-05, PNorm = 67.6324, GNorm = 0.1489, lr_0 = 1.3357e-04
Loss = 1.9347e-05, PNorm = 67.6343, GNorm = 0.1034, lr_0 = 1.3298e-04
Loss = 1.5645e-05, PNorm = 67.6364, GNorm = 0.2227, lr_0 = 1.3239e-04
Loss = 1.4332e-05, PNorm = 67.6372, GNorm = 0.1291, lr_0 = 1.3181e-04
Loss = 1.1590e-05, PNorm = 67.6381, GNorm = 0.1097, lr_0 = 1.3123e-04
Loss = 1.4963e-05, PNorm = 67.6389, GNorm = 0.2001, lr_0 = 1.3065e-04
Validation rmse logD = 0.575529
Validation R2 logD = 0.757055
Validation rmse logP = 0.673053
Validation R2 logP = 0.828110
Epoch 87
Train function
Loss = 1.5521e-05, PNorm = 67.6404, GNorm = 0.1038, lr_0 = 1.3001e-04
Loss = 1.2453e-05, PNorm = 67.6409, GNorm = 0.0519, lr_0 = 1.2944e-04
Loss = 9.6790e-06, PNorm = 67.6419, GNorm = 0.0510, lr_0 = 1.2886e-04
Loss = 8.5049e-06, PNorm = 67.6427, GNorm = 0.0626, lr_0 = 1.2829e-04
Loss = 9.2159e-06, PNorm = 67.6438, GNorm = 0.1584, lr_0 = 1.2773e-04
Validation rmse logD = 0.576098
Validation R2 logD = 0.756575
Validation rmse logP = 0.672388
Validation R2 logP = 0.828449
Epoch 88
Train function
Loss = 1.5456e-05, PNorm = 67.6449, GNorm = 0.0441, lr_0 = 1.2710e-04
Loss = 1.7164e-05, PNorm = 67.6457, GNorm = 0.0731, lr_0 = 1.2654e-04
Loss = 1.0034e-05, PNorm = 67.6473, GNorm = 0.0927, lr_0 = 1.2598e-04
Loss = 1.0062e-05, PNorm = 67.6487, GNorm = 0.0464, lr_0 = 1.2542e-04
Loss = 8.6269e-06, PNorm = 67.6491, GNorm = 0.0505, lr_0 = 1.2487e-04
Validation rmse logD = 0.575447
Validation R2 logD = 0.757125
Validation rmse logP = 0.673106
Validation R2 logP = 0.828082
Epoch 89
Train function
Loss = 8.8742e-06, PNorm = 67.6497, GNorm = 0.0792, lr_0 = 1.2426e-04
Loss = 7.0352e-06, PNorm = 67.6506, GNorm = 0.0489, lr_0 = 1.2371e-04
Loss = 9.1281e-06, PNorm = 67.6518, GNorm = 0.1215, lr_0 = 1.2317e-04
Loss = 8.8858e-06, PNorm = 67.6525, GNorm = 0.0802, lr_0 = 1.2262e-04
Loss = 8.7412e-06, PNorm = 67.6529, GNorm = 0.0565, lr_0 = 1.2208e-04
Loss = 9.5980e-06, PNorm = 67.6535, GNorm = 0.0892, lr_0 = 1.2154e-04
Loss = 1.4045e-04, PNorm = 67.6536, GNorm = 0.2040, lr_0 = 1.2148e-04
Validation rmse logD = 0.575036
Validation R2 logD = 0.757471
Validation rmse logP = 0.668693
Validation R2 logP = 0.830329
Epoch 90
Train function
Loss = 1.0964e-05, PNorm = 67.6544, GNorm = 0.2228, lr_0 = 1.2095e-04
Loss = 1.2358e-05, PNorm = 67.6550, GNorm = 0.0769, lr_0 = 1.2041e-04
Loss = 1.0150e-05, PNorm = 67.6552, GNorm = 0.0474, lr_0 = 1.1988e-04
Loss = 8.4491e-06, PNorm = 67.6565, GNorm = 0.0649, lr_0 = 1.1935e-04
Loss = 8.6106e-06, PNorm = 67.6578, GNorm = 0.0527, lr_0 = 1.1882e-04
Validation rmse logD = 0.575730
Validation R2 logD = 0.756886
Validation rmse logP = 0.668006
Validation R2 logP = 0.830678
Epoch 91
Train function
Loss = 9.9588e-06, PNorm = 67.6585, GNorm = 0.0691, lr_0 = 1.1824e-04
Loss = 1.1586e-05, PNorm = 67.6587, GNorm = 0.0888, lr_0 = 1.1772e-04
Loss = 1.1228e-05, PNorm = 67.6589, GNorm = 0.1505, lr_0 = 1.1720e-04
Loss = 8.2536e-06, PNorm = 67.6604, GNorm = 0.0752, lr_0 = 1.1668e-04
Loss = 8.5165e-06, PNorm = 67.6610, GNorm = 0.1635, lr_0 = 1.1616e-04
Validation rmse logD = 0.575367
Validation R2 logD = 0.757192
Validation rmse logP = 0.669830
Validation R2 logP = 0.829752
Epoch 92
Train function
Loss = 9.8338e-06, PNorm = 67.6629, GNorm = 0.0469, lr_0 = 1.1565e-04
Loss = 8.0944e-06, PNorm = 67.6642, GNorm = 0.0559, lr_0 = 1.1514e-04
Loss = 7.4413e-06, PNorm = 67.6645, GNorm = 0.1468, lr_0 = 1.1463e-04
Loss = 8.8258e-06, PNorm = 67.6654, GNorm = 0.1425, lr_0 = 1.1412e-04
Loss = 8.8789e-06, PNorm = 67.6657, GNorm = 0.0422, lr_0 = 1.1362e-04
Loss = 8.7612e-06, PNorm = 67.6668, GNorm = 0.0509, lr_0 = 1.1312e-04
Loss = 5.5643e-05, PNorm = 67.6668, GNorm = 0.2363, lr_0 = 1.1307e-04
Validation rmse logD = 0.575355
Validation R2 logD = 0.757202
Validation rmse logP = 0.666185
Validation R2 logP = 0.831600
Epoch 93
Train function
Loss = 7.8961e-06, PNorm = 67.6670, GNorm = 0.1730, lr_0 = 1.1257e-04
Loss = 9.1186e-06, PNorm = 67.6674, GNorm = 0.0809, lr_0 = 1.1207e-04
Loss = 9.2811e-06, PNorm = 67.6679, GNorm = 0.0736, lr_0 = 1.1157e-04
Loss = 9.0744e-06, PNorm = 67.6693, GNorm = 0.1597, lr_0 = 1.1108e-04
Loss = 6.5324e-06, PNorm = 67.6705, GNorm = 0.0522, lr_0 = 1.1059e-04
Validation rmse logD = 0.576085
Validation R2 logD = 0.756585
Validation rmse logP = 0.669187
Validation R2 logP = 0.830079
Epoch 94
Train function
Loss = 5.2696e-06, PNorm = 67.6714, GNorm = 0.0453, lr_0 = 1.1005e-04
Loss = 5.3764e-06, PNorm = 67.6720, GNorm = 0.1088, lr_0 = 1.0956e-04
Loss = 7.1415e-06, PNorm = 67.6726, GNorm = 0.0723, lr_0 = 1.0908e-04
Loss = 7.9107e-06, PNorm = 67.6731, GNorm = 0.0435, lr_0 = 1.0860e-04
Loss = 6.0208e-06, PNorm = 67.6738, GNorm = 0.0748, lr_0 = 1.0811e-04
Validation rmse logD = 0.576381
Validation R2 logD = 0.756335
Validation rmse logP = 0.670640
Validation R2 logP = 0.829340
Epoch 95
Train function
Loss = 5.6180e-06, PNorm = 67.6741, GNorm = 0.0533, lr_0 = 1.0759e-04
Loss = 6.2741e-06, PNorm = 67.6749, GNorm = 0.0449, lr_0 = 1.0711e-04
Loss = 6.5315e-06, PNorm = 67.6754, GNorm = 0.1078, lr_0 = 1.0664e-04
Loss = 5.5323e-06, PNorm = 67.6764, GNorm = 0.0590, lr_0 = 1.0617e-04
Loss = 6.8801e-06, PNorm = 67.6772, GNorm = 0.0797, lr_0 = 1.0570e-04
Validation rmse logD = 0.576915
Validation R2 logD = 0.755884
Validation rmse logP = 0.668876
Validation R2 logP = 0.830237
Epoch 96
Train function
Loss = 1.1425e-05, PNorm = 67.6774, GNorm = 0.2025, lr_0 = 1.0518e-04
Loss = 7.2093e-06, PNorm = 67.6778, GNorm = 0.1538, lr_0 = 1.0472e-04
Loss = 4.8443e-06, PNorm = 67.6784, GNorm = 0.0437, lr_0 = 1.0426e-04
Loss = 4.8724e-06, PNorm = 67.6791, GNorm = 0.0533, lr_0 = 1.0379e-04
Loss = 6.5467e-06, PNorm = 67.6798, GNorm = 0.0696, lr_0 = 1.0333e-04
Loss = 4.8110e-06, PNorm = 67.6808, GNorm = 0.0418, lr_0 = 1.0288e-04
Validation rmse logD = 0.576125
Validation R2 logD = 0.756552
Validation rmse logP = 0.668432
Validation R2 logP = 0.830462
Epoch 97
Train function
Loss = 6.5299e-06, PNorm = 67.6817, GNorm = 0.0311, lr_0 = 1.0238e-04
Loss = 4.5869e-06, PNorm = 67.6820, GNorm = 0.0523, lr_0 = 1.0192e-04
Loss = 4.8745e-06, PNorm = 67.6831, GNorm = 0.1429, lr_0 = 1.0147e-04
Loss = 7.0150e-06, PNorm = 67.6843, GNorm = 0.0403, lr_0 = 1.0102e-04
Loss = 8.1188e-06, PNorm = 67.6846, GNorm = 0.1626, lr_0 = 1.0058e-04
Validation rmse logD = 0.576993
Validation R2 logD = 0.755818
Validation rmse logP = 0.669383
Validation R2 logP = 0.829979
Epoch 98
Train function
Loss = 1.0173e-05, PNorm = 67.6854, GNorm = 0.2224, lr_0 = 1.0009e-04
Loss = 8.2647e-06, PNorm = 67.6865, GNorm = 0.0608, lr_0 = 1.0000e-04
Loss = 6.3695e-06, PNorm = 67.6866, GNorm = 0.0298, lr_0 = 1.0000e-04
Loss = 6.6179e-06, PNorm = 67.6870, GNorm = 0.1015, lr_0 = 1.0000e-04
Loss = 4.5093e-06, PNorm = 67.6873, GNorm = 0.0846, lr_0 = 1.0000e-04
Validation rmse logD = 0.576649
Validation R2 logD = 0.756108
Validation rmse logP = 0.669804
Validation R2 logP = 0.829765
Epoch 99
Train function
Loss = 3.4003e-06, PNorm = 67.6879, GNorm = 0.0396, lr_0 = 1.0000e-04
Loss = 5.4831e-06, PNorm = 67.6887, GNorm = 0.0699, lr_0 = 1.0000e-04
Loss = 4.5249e-06, PNorm = 67.6891, GNorm = 0.0409, lr_0 = 1.0000e-04
Loss = 5.1240e-06, PNorm = 67.6893, GNorm = 0.0415, lr_0 = 1.0000e-04
Loss = 7.3211e-06, PNorm = 67.6901, GNorm = 0.1426, lr_0 = 1.0000e-04
Loss = 5.3144e-06, PNorm = 67.6909, GNorm = 0.1276, lr_0 = 1.0000e-04
Validation rmse logD = 0.577370
Validation R2 logD = 0.755498
Validation rmse logP = 0.670836
Validation R2 logP = 0.829240
Model 0 best validation rmse = 0.620770 on epoch 92
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.636100
Model 0 test R2 logD = 0.715824
Model 0 test rmse logP = 0.817825
Model 0 test R2 logP = 0.711192
Ensemble test rmse  logD= 0.636100
Ensemble test R2  logD= 0.715824
Ensemble test rmse  logP= 0.817825
Ensemble test R2  logP= 0.711192
4-fold cross validation
	Seed 0 ==> test rmse = 0.706070
	Seed 0 ==> test R2 = 0.728731
	Seed 1 ==> test rmse = 0.760316
	Seed 1 ==> test R2 = 0.690842
	Seed 2 ==> test rmse = 0.711289
	Seed 2 ==> test R2 = 0.726887
	Seed 3 ==> test rmse = 0.726962
	Seed 3 ==> test R2 = 0.713508
Overall val rmse logD= 0.580032 +/- 0.015323
Overall val R2 logD = 0.765931 +/- 0.012872
Overall test rmse logD = 0.612850 +/- 0.022218
Overall test R2 logD = 0.735871 +/- 0.018935
Overall val rmse logP= 0.670701 +/- 0.078414
Overall val R2 logP = 0.795241 +/- 0.059627
Overall test rmse logP = 0.839468 +/- 0.060705
Overall test R2 logP = 0.694112 +/- 0.045588
Elapsed time = 6:53:48
