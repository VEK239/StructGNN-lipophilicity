Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,166 | train size = 2,832 | val size = 500 | test size = 834
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1555e-02, PNorm = 55.5548, GNorm = 4.2225, lr_0 = 1.0804e-04
Loss = 1.8967e-02, PNorm = 55.5571, GNorm = 5.3966, lr_0 = 1.0804e-04
Loss = 1.7628e-02, PNorm = 55.5599, GNorm = 6.2471, lr_0 = 1.0804e-04
Loss = 1.8561e-02, PNorm = 55.5636, GNorm = 1.3013, lr_0 = 1.0804e-04
Loss = 1.5577e-02, PNorm = 55.5673, GNorm = 1.6232, lr_0 = 1.0804e-04
Validation rmse logD = 1.138604
Validation R2 logD = 0.175111
Epoch 1
Train function
Loss = 1.5666e-02, PNorm = 55.5718, GNorm = 1.4557, lr_0 = 1.0804e-04
Loss = 1.5337e-02, PNorm = 55.5766, GNorm = 8.8675, lr_0 = 1.0804e-04
Loss = 1.6492e-02, PNorm = 55.5817, GNorm = 3.3705, lr_0 = 1.0804e-04
Loss = 1.5866e-02, PNorm = 55.5876, GNorm = 6.2631, lr_0 = 1.0804e-04
Loss = 1.2677e-02, PNorm = 55.5943, GNorm = 1.4519, lr_0 = 1.0804e-04
Loss = 1.5387e-02, PNorm = 55.6017, GNorm = 4.0915, lr_0 = 1.0804e-04
Validation rmse logD = 1.071458
Validation R2 logD = 0.269533
Epoch 2
Train function
Loss = 1.5938e-02, PNorm = 55.6104, GNorm = 2.3883, lr_0 = 1.0804e-04
Loss = 1.3902e-02, PNorm = 55.6199, GNorm = 5.9953, lr_0 = 1.0804e-04
Loss = 1.3871e-02, PNorm = 55.6290, GNorm = 3.4278, lr_0 = 1.0804e-04
Loss = 1.4310e-02, PNorm = 55.6389, GNorm = 7.9563, lr_0 = 1.0804e-04
Loss = 1.1797e-02, PNorm = 55.6499, GNorm = 1.6897, lr_0 = 1.0804e-04
Validation rmse logD = 1.018672
Validation R2 logD = 0.339734
Epoch 3
Train function
Loss = 8.5149e-03, PNorm = 55.6596, GNorm = 1.2556, lr_0 = 1.0804e-04
Loss = 1.2653e-02, PNorm = 55.6689, GNorm = 3.6006, lr_0 = 1.0804e-04
Loss = 1.3227e-02, PNorm = 55.6818, GNorm = 2.7030, lr_0 = 1.0804e-04
Loss = 1.1350e-02, PNorm = 55.6934, GNorm = 2.0040, lr_0 = 1.0804e-04
Loss = 1.1766e-02, PNorm = 55.7036, GNorm = 2.0118, lr_0 = 1.0804e-04
Loss = 1.2349e-02, PNorm = 55.7133, GNorm = 6.6256, lr_0 = 1.0804e-04
Validation rmse logD = 0.961611
Validation R2 logD = 0.411632
Epoch 4
Train function
Loss = 1.1440e-02, PNorm = 55.7239, GNorm = 6.3921, lr_0 = 1.0804e-04
Loss = 1.0851e-02, PNorm = 55.7354, GNorm = 2.8002, lr_0 = 1.0804e-04
Loss = 1.1663e-02, PNorm = 55.7477, GNorm = 2.5348, lr_0 = 1.0804e-04
Loss = 1.0452e-02, PNorm = 55.7613, GNorm = 3.8348, lr_0 = 1.0804e-04
Loss = 1.0745e-02, PNorm = 55.7725, GNorm = 1.6572, lr_0 = 1.0804e-04
Loss = 1.0560e-02, PNorm = 55.7859, GNorm = 2.7456, lr_0 = 1.0804e-04
Validation rmse logD = 0.880986
Validation R2 logD = 0.506158
Epoch 5
Train function
Loss = 8.8266e-03, PNorm = 55.8007, GNorm = 3.8410, lr_0 = 1.0804e-04
Loss = 1.0855e-02, PNorm = 55.8128, GNorm = 2.2744, lr_0 = 1.0804e-04
Loss = 1.0675e-02, PNorm = 55.8243, GNorm = 5.8883, lr_0 = 1.0804e-04
Loss = 9.8574e-03, PNorm = 55.8369, GNorm = 2.7627, lr_0 = 1.0804e-04
Loss = 1.0417e-02, PNorm = 55.8493, GNorm = 3.7765, lr_0 = 1.0804e-04
Validation rmse logD = 0.990030
Validation R2 logD = 0.376341
Epoch 6
Train function
Loss = 1.1968e-02, PNorm = 55.8623, GNorm = 9.8957, lr_0 = 1.0804e-04
Loss = 1.1201e-02, PNorm = 55.8739, GNorm = 9.5698, lr_0 = 1.0804e-04
Loss = 1.0196e-02, PNorm = 55.8847, GNorm = 8.5445, lr_0 = 1.0804e-04
Loss = 1.0242e-02, PNorm = 55.8951, GNorm = 7.9130, lr_0 = 1.0804e-04
Loss = 9.1535e-03, PNorm = 55.9077, GNorm = 3.5639, lr_0 = 1.0804e-04
Loss = 9.2879e-03, PNorm = 55.9217, GNorm = 1.9493, lr_0 = 1.0804e-04
Validation rmse logD = 0.829191
Validation R2 logD = 0.562519
Epoch 7
Train function
Loss = 1.0874e-02, PNorm = 55.9333, GNorm = 4.6661, lr_0 = 1.0804e-04
Loss = 8.6377e-03, PNorm = 55.9443, GNorm = 1.8067, lr_0 = 1.0804e-04
Loss = 8.6075e-03, PNorm = 55.9564, GNorm = 5.6804, lr_0 = 1.0804e-04
Loss = 7.6437e-03, PNorm = 55.9677, GNorm = 2.1056, lr_0 = 1.0804e-04
Loss = 7.9557e-03, PNorm = 55.9794, GNorm = 2.1057, lr_0 = 1.0804e-04
Loss = 7.9871e-03, PNorm = 55.9928, GNorm = 3.3500, lr_0 = 1.0804e-04
Validation rmse logD = 0.771707
Validation R2 logD = 0.621073
Epoch 8
Train function
Loss = 6.5682e-03, PNorm = 56.0077, GNorm = 4.8740, lr_0 = 1.0804e-04
Loss = 7.9162e-03, PNorm = 56.0203, GNorm = 4.7277, lr_0 = 1.0804e-04
Loss = 7.8972e-03, PNorm = 56.0305, GNorm = 3.8374, lr_0 = 1.0804e-04
Loss = 7.1586e-03, PNorm = 56.0412, GNorm = 3.6383, lr_0 = 1.0804e-04
Loss = 6.9920e-03, PNorm = 56.0541, GNorm = 3.0731, lr_0 = 1.0804e-04
Validation rmse logD = 0.776753
Validation R2 logD = 0.616102
Epoch 9
Train function
Loss = 8.7482e-03, PNorm = 56.0648, GNorm = 5.2395, lr_0 = 1.0804e-04
Loss = 6.9797e-03, PNorm = 56.0785, GNorm = 2.3958, lr_0 = 1.0804e-04
Loss = 7.1008e-03, PNorm = 56.0881, GNorm = 2.3506, lr_0 = 1.0804e-04
Loss = 6.8291e-03, PNorm = 56.0999, GNorm = 5.4721, lr_0 = 1.0804e-04
Loss = 6.5017e-03, PNorm = 56.1105, GNorm = 2.8957, lr_0 = 1.0804e-04
Loss = 7.1236e-03, PNorm = 56.1204, GNorm = 2.9296, lr_0 = 1.0804e-04
Validation rmse logD = 0.755395
Validation R2 logD = 0.636924
Epoch 10
Train function
Loss = 4.6507e-03, PNorm = 56.1297, GNorm = 1.7833, lr_0 = 1.0804e-04
Loss = 6.9504e-03, PNorm = 56.1402, GNorm = 1.4705, lr_0 = 1.0804e-04
Loss = 7.3473e-03, PNorm = 56.1522, GNorm = 2.3413, lr_0 = 1.0804e-04
Loss = 6.6943e-03, PNorm = 56.1603, GNorm = 6.1253, lr_0 = 1.0804e-04
Loss = 6.3835e-03, PNorm = 56.1715, GNorm = 1.5431, lr_0 = 1.0804e-04
Loss = 6.6923e-03, PNorm = 56.1814, GNorm = 5.7138, lr_0 = 1.0804e-04
Validation rmse logD = 0.712235
Validation R2 logD = 0.677227
Epoch 11
Train function
Loss = 5.7166e-03, PNorm = 56.1914, GNorm = 5.3108, lr_0 = 1.0804e-04
Loss = 5.8650e-03, PNorm = 56.2008, GNorm = 1.7010, lr_0 = 1.0804e-04
Loss = 6.6855e-03, PNorm = 56.2131, GNorm = 3.8971, lr_0 = 1.0804e-04
Loss = 5.5161e-03, PNorm = 56.2227, GNorm = 5.0471, lr_0 = 1.0804e-04
Loss = 6.2044e-03, PNorm = 56.2296, GNorm = 4.2656, lr_0 = 1.0804e-04
Validation rmse logD = 0.698699
Validation R2 logD = 0.689379
Epoch 12
Train function
Loss = 4.4191e-03, PNorm = 56.2409, GNorm = 1.8777, lr_0 = 1.0804e-04
Loss = 6.1384e-03, PNorm = 56.2477, GNorm = 3.6529, lr_0 = 1.0804e-04
Loss = 6.3019e-03, PNorm = 56.2588, GNorm = 3.6743, lr_0 = 1.0804e-04
Loss = 5.9724e-03, PNorm = 56.2694, GNorm = 7.0760, lr_0 = 1.0804e-04
Loss = 5.3717e-03, PNorm = 56.2782, GNorm = 3.7470, lr_0 = 1.0804e-04
Loss = 6.0957e-03, PNorm = 56.2859, GNorm = 7.5568, lr_0 = 1.0804e-04
Validation rmse logD = 0.732554
Validation R2 logD = 0.658548
Epoch 13
Train function
Loss = 5.3528e-03, PNorm = 56.2967, GNorm = 3.7909, lr_0 = 1.0804e-04
Loss = 5.5057e-03, PNorm = 56.3072, GNorm = 9.1937, lr_0 = 1.0804e-04
Loss = 6.2519e-03, PNorm = 56.3149, GNorm = 5.1685, lr_0 = 1.0804e-04
Loss = 4.7433e-03, PNorm = 56.3242, GNorm = 6.8884, lr_0 = 1.0804e-04
Loss = 5.4450e-03, PNorm = 56.3342, GNorm = 2.1703, lr_0 = 1.0804e-04
Loss = 4.9966e-03, PNorm = 56.3412, GNorm = 2.3668, lr_0 = 1.0804e-04
Validation rmse logD = 0.665154
Validation R2 logD = 0.718489
Epoch 14
Train function
Loss = 5.2968e-03, PNorm = 56.3518, GNorm = 2.9433, lr_0 = 1.0804e-04
Loss = 4.4352e-03, PNorm = 56.3607, GNorm = 2.2732, lr_0 = 1.0804e-04
Loss = 4.4971e-03, PNorm = 56.3674, GNorm = 3.4066, lr_0 = 1.0804e-04
Loss = 5.7586e-03, PNorm = 56.3768, GNorm = 9.7517, lr_0 = 1.0804e-04
Loss = 5.0310e-03, PNorm = 56.3858, GNorm = 3.9311, lr_0 = 1.0804e-04
Validation rmse logD = 0.673040
Validation R2 logD = 0.711775
Epoch 15
Train function
Loss = 4.8406e-03, PNorm = 56.3938, GNorm = 1.8688, lr_0 = 1.0804e-04
Loss = 4.6405e-03, PNorm = 56.4018, GNorm = 4.2955, lr_0 = 1.0804e-04
Loss = 4.3554e-03, PNorm = 56.4093, GNorm = 3.2405, lr_0 = 1.0804e-04
Loss = 5.2028e-03, PNorm = 56.4173, GNorm = 3.7781, lr_0 = 1.0804e-04
Loss = 5.3291e-03, PNorm = 56.4259, GNorm = 2.2149, lr_0 = 1.0804e-04
Loss = 4.2168e-03, PNorm = 56.4342, GNorm = 2.5134, lr_0 = 1.0804e-04
Validation rmse logD = 0.644688
Validation R2 logD = 0.735546
Epoch 16
Train function
Loss = 4.2359e-03, PNorm = 56.4439, GNorm = 1.6258, lr_0 = 1.0804e-04
Loss = 3.5083e-03, PNorm = 56.4525, GNorm = 8.6561, lr_0 = 1.0804e-04
Loss = 4.5246e-03, PNorm = 56.4600, GNorm = 1.8276, lr_0 = 1.0804e-04
Loss = 4.7479e-03, PNorm = 56.4664, GNorm = 2.0634, lr_0 = 1.0804e-04
Loss = 4.6358e-03, PNorm = 56.4744, GNorm = 7.7917, lr_0 = 1.0804e-04
Loss = 4.5567e-03, PNorm = 56.4817, GNorm = 3.9762, lr_0 = 1.0804e-04
Validation rmse logD = 0.641530
Validation R2 logD = 0.738131
Epoch 17
Train function
Loss = 3.4113e-03, PNorm = 56.4912, GNorm = 3.7315, lr_0 = 1.0804e-04
Loss = 4.7131e-03, PNorm = 56.4991, GNorm = 5.2468, lr_0 = 1.0804e-04
Loss = 4.3380e-03, PNorm = 56.5080, GNorm = 4.0933, lr_0 = 1.0804e-04
Loss = 4.2851e-03, PNorm = 56.5172, GNorm = 2.6717, lr_0 = 1.0804e-04
Loss = 4.1195e-03, PNorm = 56.5246, GNorm = 3.6465, lr_0 = 1.0804e-04
Validation rmse logD = 0.634083
Validation R2 logD = 0.744175
Epoch 18
Train function
Loss = 3.3817e-03, PNorm = 56.5331, GNorm = 3.6703, lr_0 = 1.0804e-04
Loss = 4.2325e-03, PNorm = 56.5412, GNorm = 5.5728, lr_0 = 1.0804e-04
Loss = 3.4836e-03, PNorm = 56.5485, GNorm = 3.3865, lr_0 = 1.0804e-04
Loss = 4.2365e-03, PNorm = 56.5573, GNorm = 6.0652, lr_0 = 1.0804e-04
Loss = 3.5905e-03, PNorm = 56.5664, GNorm = 2.0337, lr_0 = 1.0804e-04
Loss = 3.8333e-03, PNorm = 56.5729, GNorm = 6.2729, lr_0 = 1.0804e-04
Validation rmse logD = 0.635641
Validation R2 logD = 0.742917
Epoch 19
Train function
Loss = 3.8756e-03, PNorm = 56.5791, GNorm = 1.9736, lr_0 = 1.0804e-04
Loss = 3.6438e-03, PNorm = 56.5881, GNorm = 2.0717, lr_0 = 1.0804e-04
Loss = 4.4027e-03, PNorm = 56.5940, GNorm = 4.6145, lr_0 = 1.0804e-04
Loss = 3.3587e-03, PNorm = 56.6020, GNorm = 2.9125, lr_0 = 1.0804e-04
Loss = 3.5712e-03, PNorm = 56.6107, GNorm = 2.3351, lr_0 = 1.0804e-04
Loss = 3.4229e-03, PNorm = 56.6187, GNorm = 2.7715, lr_0 = 1.0804e-04
Validation rmse logD = 0.618226
Validation R2 logD = 0.756810
Epoch 20
Train function
Loss = 3.4243e-03, PNorm = 56.6283, GNorm = 3.9180, lr_0 = 1.0804e-04
Loss = 4.6767e-03, PNorm = 56.6331, GNorm = 11.9945, lr_0 = 1.0804e-04
Loss = 5.0809e-03, PNorm = 56.6398, GNorm = 8.8158, lr_0 = 1.0804e-04
Loss = 3.5124e-03, PNorm = 56.6468, GNorm = 2.4010, lr_0 = 1.0804e-04
Loss = 4.1972e-03, PNorm = 56.6560, GNorm = 8.2208, lr_0 = 1.0804e-04
Validation rmse logD = 0.695042
Validation R2 logD = 0.692622
Epoch 21
Train function
Loss = 5.1822e-03, PNorm = 56.6650, GNorm = 7.8639, lr_0 = 1.0804e-04
Loss = 3.8393e-03, PNorm = 56.6730, GNorm = 7.7444, lr_0 = 1.0804e-04
Loss = 3.1770e-03, PNorm = 56.6800, GNorm = 2.9724, lr_0 = 1.0804e-04
Loss = 3.1785e-03, PNorm = 56.6877, GNorm = 1.8253, lr_0 = 1.0804e-04
Loss = 3.6730e-03, PNorm = 56.6954, GNorm = 6.1614, lr_0 = 1.0804e-04
Loss = 3.4424e-03, PNorm = 56.7049, GNorm = 3.5130, lr_0 = 1.0804e-04
Validation rmse logD = 0.653227
Validation R2 logD = 0.728495
Epoch 22
Train function
Loss = 3.5004e-03, PNorm = 56.7120, GNorm = 6.4477, lr_0 = 1.0804e-04
Loss = 3.5999e-03, PNorm = 56.7181, GNorm = 3.6841, lr_0 = 1.0804e-04
Loss = 3.2087e-03, PNorm = 56.7263, GNorm = 2.3179, lr_0 = 1.0804e-04
Loss = 3.9004e-03, PNorm = 56.7348, GNorm = 9.4672, lr_0 = 1.0804e-04
Loss = 3.2764e-03, PNorm = 56.7422, GNorm = 4.2321, lr_0 = 1.0804e-04
Loss = 3.7338e-03, PNorm = 56.7506, GNorm = 3.2951, lr_0 = 1.0804e-04
Validation rmse logD = 0.687170
Validation R2 logD = 0.699545
Epoch 23
Train function
Loss = 3.3211e-03, PNorm = 56.7577, GNorm = 8.1430, lr_0 = 1.0804e-04
Loss = 3.0016e-03, PNorm = 56.7666, GNorm = 6.1111, lr_0 = 1.0804e-04
Loss = 3.1605e-03, PNorm = 56.7738, GNorm = 4.1125, lr_0 = 1.0804e-04
Loss = 3.0620e-03, PNorm = 56.7802, GNorm = 3.1028, lr_0 = 1.0804e-04
Loss = 3.6450e-03, PNorm = 56.7871, GNorm = 2.5770, lr_0 = 1.0804e-04
Validation rmse logD = 0.610731
Validation R2 logD = 0.762672
Epoch 24
Train function
Loss = 2.0337e-03, PNorm = 56.7944, GNorm = 2.2537, lr_0 = 1.0804e-04
Loss = 3.4597e-03, PNorm = 56.8017, GNorm = 4.7521, lr_0 = 1.0804e-04
Loss = 3.3217e-03, PNorm = 56.8103, GNorm = 9.8106, lr_0 = 1.0804e-04
Loss = 3.0491e-03, PNorm = 56.8182, GNorm = 5.4808, lr_0 = 1.0804e-04
Loss = 3.4437e-03, PNorm = 56.8255, GNorm = 8.5484, lr_0 = 1.0804e-04
Loss = 3.8128e-03, PNorm = 56.8312, GNorm = 5.3573, lr_0 = 1.0804e-04
Validation rmse logD = 0.634939
Validation R2 logD = 0.743484
Epoch 25
Train function
Loss = 2.9835e-03, PNorm = 56.8389, GNorm = 5.9232, lr_0 = 1.0804e-04
Loss = 3.0677e-03, PNorm = 56.8470, GNorm = 1.9353, lr_0 = 1.0804e-04
Loss = 2.8582e-03, PNorm = 56.8530, GNorm = 1.4514, lr_0 = 1.0804e-04
Loss = 2.7918e-03, PNorm = 56.8606, GNorm = 4.1765, lr_0 = 1.0804e-04
Loss = 2.9413e-03, PNorm = 56.8686, GNorm = 6.7731, lr_0 = 1.0804e-04
Loss = 2.9465e-03, PNorm = 56.8756, GNorm = 2.4700, lr_0 = 1.0804e-04
Validation rmse logD = 0.597280
Validation R2 logD = 0.773010
Epoch 26
Train function
Loss = 2.5681e-03, PNorm = 56.8842, GNorm = 7.2804, lr_0 = 1.0804e-04
Loss = 2.6529e-03, PNorm = 56.8917, GNorm = 2.3348, lr_0 = 1.0804e-04
Loss = 3.0969e-03, PNorm = 56.9009, GNorm = 4.9532, lr_0 = 1.0804e-04
Loss = 2.4167e-03, PNorm = 56.9081, GNorm = 5.7585, lr_0 = 1.0804e-04
Loss = 2.6752e-03, PNorm = 56.9146, GNorm = 3.3096, lr_0 = 1.0804e-04
Validation rmse logD = 0.624309
Validation R2 logD = 0.752002
Epoch 27
Train function
Loss = 3.5740e-03, PNorm = 56.9172, GNorm = 7.1991, lr_0 = 1.0804e-04
Loss = 3.3603e-03, PNorm = 56.9221, GNorm = 8.8335, lr_0 = 1.0804e-04
Loss = 2.5525e-03, PNorm = 56.9300, GNorm = 3.4068, lr_0 = 1.0804e-04
Loss = 2.7737e-03, PNorm = 56.9396, GNorm = 5.4791, lr_0 = 1.0804e-04
Loss = 2.3725e-03, PNorm = 56.9470, GNorm = 4.1709, lr_0 = 1.0804e-04
Loss = 2.4132e-03, PNorm = 56.9533, GNorm = 2.1123, lr_0 = 1.0804e-04
Validation rmse logD = 0.596038
Validation R2 logD = 0.773953
Epoch 28
Train function
Loss = 2.5447e-03, PNorm = 56.9594, GNorm = 3.1408, lr_0 = 1.0804e-04
Loss = 2.8650e-03, PNorm = 56.9661, GNorm = 8.1029, lr_0 = 1.0804e-04
Loss = 2.4297e-03, PNorm = 56.9720, GNorm = 3.0162, lr_0 = 1.0804e-04
Loss = 2.5929e-03, PNorm = 56.9798, GNorm = 5.7270, lr_0 = 1.0804e-04
Loss = 2.6454e-03, PNorm = 56.9885, GNorm = 3.1676, lr_0 = 1.0804e-04
Loss = 2.5774e-03, PNorm = 56.9965, GNorm = 1.3519, lr_0 = 1.0804e-04
Validation rmse logD = 0.601688
Validation R2 logD = 0.769647
Epoch 29
Train function
Loss = 2.1561e-03, PNorm = 57.0026, GNorm = 1.9913, lr_0 = 1.0804e-04
Loss = 2.3604e-03, PNorm = 57.0087, GNorm = 3.0088, lr_0 = 1.0804e-04
Loss = 2.9143e-03, PNorm = 57.0146, GNorm = 2.0204, lr_0 = 1.0804e-04
Loss = 2.0049e-03, PNorm = 57.0208, GNorm = 2.1434, lr_0 = 1.0804e-04
Loss = 2.4048e-03, PNorm = 57.0284, GNorm = 10.6303, lr_0 = 1.0804e-04
Validation rmse logD = 0.614982
Validation R2 logD = 0.759356
Epoch 30
Train function
Loss = 2.3560e-03, PNorm = 57.0337, GNorm = 5.4398, lr_0 = 1.0804e-04
Loss = 2.4534e-03, PNorm = 57.0388, GNorm = 6.1097, lr_0 = 1.0804e-04
Loss = 2.3885e-03, PNorm = 57.0466, GNorm = 2.0981, lr_0 = 1.0804e-04
Loss = 2.2955e-03, PNorm = 57.0538, GNorm = 2.1621, lr_0 = 1.0804e-04
Loss = 2.3582e-03, PNorm = 57.0600, GNorm = 5.0526, lr_0 = 1.0804e-04
Loss = 2.4854e-03, PNorm = 57.0664, GNorm = 5.8226, lr_0 = 1.0804e-04
Validation rmse logD = 0.600830
Validation R2 logD = 0.770304
Epoch 31
Train function
Loss = 1.8129e-03, PNorm = 57.0733, GNorm = 1.9925, lr_0 = 1.0804e-04
Loss = 2.1706e-03, PNorm = 57.0804, GNorm = 3.0720, lr_0 = 1.0804e-04
Loss = 2.1420e-03, PNorm = 57.0880, GNorm = 1.3060, lr_0 = 1.0804e-04
Loss = 2.0388e-03, PNorm = 57.0948, GNorm = 3.0993, lr_0 = 1.0804e-04
Loss = 2.0612e-03, PNorm = 57.1010, GNorm = 4.9035, lr_0 = 1.0804e-04
Loss = 2.2944e-03, PNorm = 57.1071, GNorm = 2.7973, lr_0 = 1.0804e-04
Validation rmse logD = 0.580670
Validation R2 logD = 0.785459
Epoch 32
Train function
Loss = 1.7888e-03, PNorm = 57.1143, GNorm = 2.9119, lr_0 = 1.0804e-04
Loss = 2.0017e-03, PNorm = 57.1213, GNorm = 5.1178, lr_0 = 1.0804e-04
Loss = 2.2058e-03, PNorm = 57.1270, GNorm = 3.3760, lr_0 = 1.0804e-04
Loss = 2.1502e-03, PNorm = 57.1313, GNorm = 2.4765, lr_0 = 1.0804e-04
Loss = 2.8272e-03, PNorm = 57.1377, GNorm = 6.7240, lr_0 = 1.0804e-04
Validation rmse logD = 0.585745
Validation R2 logD = 0.781693
Epoch 33
Train function
Loss = 1.8568e-03, PNorm = 57.1449, GNorm = 2.6799, lr_0 = 1.0804e-04
Loss = 2.2891e-03, PNorm = 57.1519, GNorm = 3.4314, lr_0 = 1.0804e-04
Loss = 2.0803e-03, PNorm = 57.1583, GNorm = 2.9500, lr_0 = 1.0804e-04
Loss = 2.3281e-03, PNorm = 57.1641, GNorm = 5.2686, lr_0 = 1.0804e-04
Loss = 1.9650e-03, PNorm = 57.1709, GNorm = 2.0998, lr_0 = 1.0804e-04
Loss = 2.2097e-03, PNorm = 57.1781, GNorm = 3.9942, lr_0 = 1.0804e-04
Validation rmse logD = 0.584169
Validation R2 logD = 0.782866
Epoch 34
Train function
Loss = 1.8909e-03, PNorm = 57.1845, GNorm = 4.9554, lr_0 = 1.0804e-04
Loss = 1.8973e-03, PNorm = 57.1905, GNorm = 1.6016, lr_0 = 1.0804e-04
Loss = 1.8118e-03, PNorm = 57.1970, GNorm = 1.5735, lr_0 = 1.0804e-04
Loss = 1.7009e-03, PNorm = 57.2042, GNorm = 4.1328, lr_0 = 1.0804e-04
Loss = 1.9925e-03, PNorm = 57.2094, GNorm = 1.9513, lr_0 = 1.0804e-04
Loss = 2.2279e-03, PNorm = 57.2155, GNorm = 1.6266, lr_0 = 1.0804e-04
Validation rmse logD = 0.579281
Validation R2 logD = 0.786485
Epoch 35
Train function
Loss = 2.4141e-03, PNorm = 57.2229, GNorm = 6.0146, lr_0 = 1.0804e-04
Loss = 2.5771e-03, PNorm = 57.2272, GNorm = 5.3637, lr_0 = 1.0804e-04
Loss = 2.9280e-03, PNorm = 57.2331, GNorm = 6.7645, lr_0 = 1.0804e-04
Loss = 2.8302e-03, PNorm = 57.2397, GNorm = 7.3094, lr_0 = 1.0804e-04
Loss = 2.3823e-03, PNorm = 57.2461, GNorm = 2.4957, lr_0 = 1.0804e-04
Validation rmse logD = 0.565499
Validation R2 logD = 0.796524
Epoch 36
Train function
Loss = 1.2691e-03, PNorm = 57.2548, GNorm = 4.4312, lr_0 = 1.0804e-04
Loss = 1.8248e-03, PNorm = 57.2639, GNorm = 1.8535, lr_0 = 1.0804e-04
Loss = 2.0203e-03, PNorm = 57.2687, GNorm = 7.2827, lr_0 = 1.0804e-04
Loss = 1.7200e-03, PNorm = 57.2740, GNorm = 1.4460, lr_0 = 1.0804e-04
Loss = 1.8584e-03, PNorm = 57.2787, GNorm = 1.9044, lr_0 = 1.0804e-04
Loss = 1.9254e-03, PNorm = 57.2860, GNorm = 5.1085, lr_0 = 1.0804e-04
Validation rmse logD = 0.577288
Validation R2 logD = 0.787951
Epoch 37
Train function
Loss = 1.9148e-03, PNorm = 57.2933, GNorm = 9.4346, lr_0 = 1.0804e-04
Loss = 1.9169e-03, PNorm = 57.2987, GNorm = 5.4406, lr_0 = 1.0804e-04
Loss = 1.8517e-03, PNorm = 57.3044, GNorm = 1.0101, lr_0 = 1.0804e-04
Loss = 1.9295e-03, PNorm = 57.3116, GNorm = 3.8249, lr_0 = 1.0804e-04
Loss = 1.9766e-03, PNorm = 57.3170, GNorm = 8.4655, lr_0 = 1.0804e-04
Loss = 2.1995e-03, PNorm = 57.3230, GNorm = 2.7972, lr_0 = 1.0804e-04
Validation rmse logD = 0.569133
Validation R2 logD = 0.793900
Epoch 38
Train function
Loss = 1.6925e-03, PNorm = 57.3291, GNorm = 1.5194, lr_0 = 1.0804e-04
Loss = 1.6043e-03, PNorm = 57.3355, GNorm = 5.9111, lr_0 = 1.0804e-04
Loss = 1.8553e-03, PNorm = 57.3414, GNorm = 5.2433, lr_0 = 1.0804e-04
Loss = 1.7117e-03, PNorm = 57.3462, GNorm = 1.7961, lr_0 = 1.0804e-04
Loss = 1.9148e-03, PNorm = 57.3508, GNorm = 1.3231, lr_0 = 1.0804e-04
Validation rmse logD = 0.570148
Validation R2 logD = 0.793165
Epoch 39
Train function
Loss = 1.8265e-03, PNorm = 57.3586, GNorm = 2.2030, lr_0 = 1.0804e-04
Loss = 1.7368e-03, PNorm = 57.3655, GNorm = 7.6016, lr_0 = 1.0804e-04
Loss = 1.5481e-03, PNorm = 57.3723, GNorm = 2.3056, lr_0 = 1.0804e-04
Loss = 1.7534e-03, PNorm = 57.3762, GNorm = 1.5440, lr_0 = 1.0804e-04
Loss = 1.4344e-03, PNorm = 57.3805, GNorm = 3.4827, lr_0 = 1.0804e-04
Loss = 1.6410e-03, PNorm = 57.3868, GNorm = 1.7287, lr_0 = 1.0804e-04
Validation rmse logD = 0.594707
Validation R2 logD = 0.774961
Epoch 40
Train function
Loss = 1.3889e-03, PNorm = 57.3922, GNorm = 5.8498, lr_0 = 1.0804e-04
Loss = 1.4736e-03, PNorm = 57.3971, GNorm = 1.2033, lr_0 = 1.0804e-04
Loss = 1.5448e-03, PNorm = 57.4025, GNorm = 3.9680, lr_0 = 1.0804e-04
Loss = 1.6989e-03, PNorm = 57.4074, GNorm = 2.0009, lr_0 = 1.0804e-04
Loss = 1.3797e-03, PNorm = 57.4148, GNorm = 1.5449, lr_0 = 1.0804e-04
Loss = 1.5069e-03, PNorm = 57.4215, GNorm = 2.3091, lr_0 = 1.0804e-04
Validation rmse logD = 0.541409
Validation R2 logD = 0.813490
Epoch 41
Train function
Loss = 1.2940e-03, PNorm = 57.4259, GNorm = 3.6576, lr_0 = 1.0804e-04
Loss = 1.3827e-03, PNorm = 57.4309, GNorm = 1.4018, lr_0 = 1.0804e-04
Loss = 1.2755e-03, PNorm = 57.4360, GNorm = 1.3701, lr_0 = 1.0804e-04
Loss = 1.6906e-03, PNorm = 57.4423, GNorm = 6.3175, lr_0 = 1.0804e-04
Loss = 1.6066e-03, PNorm = 57.4491, GNorm = 3.6885, lr_0 = 1.0804e-04
Validation rmse logD = 0.556482
Validation R2 logD = 0.802961
Epoch 42
Train function
Loss = 1.6693e-03, PNorm = 57.4541, GNorm = 1.5228, lr_0 = 1.0804e-04
Loss = 1.4071e-03, PNorm = 57.4598, GNorm = 3.0500, lr_0 = 1.0804e-04
Loss = 1.1850e-03, PNorm = 57.4658, GNorm = 4.2689, lr_0 = 1.0804e-04
Loss = 1.5484e-03, PNorm = 57.4700, GNorm = 3.9267, lr_0 = 1.0804e-04
Loss = 1.5063e-03, PNorm = 57.4746, GNorm = 4.6361, lr_0 = 1.0804e-04
Loss = 1.6712e-03, PNorm = 57.4815, GNorm = 1.6981, lr_0 = 1.0804e-04
Validation rmse logD = 0.549506
Validation R2 logD = 0.807870
Epoch 43
Train function
Loss = 1.0650e-03, PNorm = 57.4871, GNorm = 4.8130, lr_0 = 1.0804e-04
Loss = 1.4214e-03, PNorm = 57.4927, GNorm = 2.3654, lr_0 = 1.0804e-04
Loss = 1.4224e-03, PNorm = 57.4997, GNorm = 3.5136, lr_0 = 1.0804e-04
Loss = 1.2594e-03, PNorm = 57.5042, GNorm = 1.6076, lr_0 = 1.0804e-04
Loss = 1.2889e-03, PNorm = 57.5108, GNorm = 3.0072, lr_0 = 1.0804e-04
Loss = 1.2600e-03, PNorm = 57.5163, GNorm = 3.5155, lr_0 = 1.0804e-04
Validation rmse logD = 0.541594
Validation R2 logD = 0.813363
Epoch 44
Train function
Loss = 1.0597e-03, PNorm = 57.5211, GNorm = 1.7349, lr_0 = 1.0804e-04
Loss = 1.0636e-03, PNorm = 57.5252, GNorm = 2.0511, lr_0 = 1.0804e-04
Loss = 1.1849e-03, PNorm = 57.5297, GNorm = 2.8803, lr_0 = 1.0804e-04
Loss = 1.2885e-03, PNorm = 57.5349, GNorm = 1.3363, lr_0 = 1.0804e-04
Loss = 1.7458e-03, PNorm = 57.5399, GNorm = 2.4113, lr_0 = 1.0804e-04
Validation rmse logD = 0.560843
Validation R2 logD = 0.799860
Epoch 45
Train function
Loss = 9.7178e-04, PNorm = 57.5464, GNorm = 3.5722, lr_0 = 1.0804e-04
Loss = 1.1343e-03, PNorm = 57.5507, GNorm = 2.3121, lr_0 = 1.0804e-04
Loss = 1.2555e-03, PNorm = 57.5573, GNorm = 3.4576, lr_0 = 1.0804e-04
Loss = 1.1446e-03, PNorm = 57.5621, GNorm = 2.3975, lr_0 = 1.0804e-04
Loss = 1.5201e-03, PNorm = 57.5666, GNorm = 4.5229, lr_0 = 1.0804e-04
Loss = 1.4903e-03, PNorm = 57.5722, GNorm = 1.7646, lr_0 = 1.0804e-04
Validation rmse logD = 0.534848
Validation R2 logD = 0.817983
Epoch 46
Train function
Loss = 1.0475e-03, PNorm = 57.5791, GNorm = 2.4064, lr_0 = 1.0804e-04
Loss = 1.2468e-03, PNorm = 57.5843, GNorm = 3.3806, lr_0 = 1.0804e-04
Loss = 1.1121e-03, PNorm = 57.5889, GNorm = 2.3243, lr_0 = 1.0804e-04
Loss = 1.2592e-03, PNorm = 57.5946, GNorm = 7.8734, lr_0 = 1.0804e-04
Loss = 1.6822e-03, PNorm = 57.5994, GNorm = 9.0511, lr_0 = 1.0804e-04
Loss = 1.9040e-03, PNorm = 57.6031, GNorm = 2.8079, lr_0 = 1.0804e-04
Validation rmse logD = 0.536307
Validation R2 logD = 0.816989
Epoch 47
Train function
Loss = 1.3012e-03, PNorm = 57.6079, GNorm = 5.0017, lr_0 = 1.0804e-04
Loss = 1.3534e-03, PNorm = 57.6147, GNorm = 3.9316, lr_0 = 1.0804e-04
Loss = 1.1116e-03, PNorm = 57.6214, GNorm = 2.7837, lr_0 = 1.0804e-04
Loss = 1.1771e-03, PNorm = 57.6269, GNorm = 3.8177, lr_0 = 1.0804e-04
Loss = 9.9236e-04, PNorm = 57.6318, GNorm = 2.7167, lr_0 = 1.0804e-04
Validation rmse logD = 0.534596
Validation R2 logD = 0.818155
Epoch 48
Train function
Loss = 7.4165e-04, PNorm = 57.6364, GNorm = 4.9388, lr_0 = 1.0804e-04
Loss = 1.0624e-03, PNorm = 57.6422, GNorm = 3.1678, lr_0 = 1.0804e-04
Loss = 1.1677e-03, PNorm = 57.6476, GNorm = 3.2701, lr_0 = 1.0804e-04
Loss = 1.1214e-03, PNorm = 57.6519, GNorm = 1.3416, lr_0 = 1.0804e-04
Loss = 1.2929e-03, PNorm = 57.6564, GNorm = 8.2815, lr_0 = 1.0804e-04
Loss = 1.2948e-03, PNorm = 57.6623, GNorm = 5.2081, lr_0 = 1.0804e-04
Validation rmse logD = 0.593833
Validation R2 logD = 0.775623
Epoch 49
Train function
Loss = 1.3373e-03, PNorm = 57.6677, GNorm = 4.3707, lr_0 = 1.0804e-04
Loss = 1.2363e-03, PNorm = 57.6730, GNorm = 3.3012, lr_0 = 1.0804e-04
Loss = 1.1305e-03, PNorm = 57.6768, GNorm = 4.7248, lr_0 = 1.0804e-04
Loss = 1.0264e-03, PNorm = 57.6808, GNorm = 3.6035, lr_0 = 1.0804e-04
Loss = 1.1540e-03, PNorm = 57.6871, GNorm = 3.2157, lr_0 = 1.0804e-04
Loss = 1.3029e-03, PNorm = 57.6936, GNorm = 4.6495, lr_0 = 1.0804e-04
Validation rmse logD = 0.538282
Validation R2 logD = 0.815639
Epoch 50
Train function
Loss = 1.0154e-03, PNorm = 57.6978, GNorm = 2.0041, lr_0 = 1.0804e-04
Loss = 1.0408e-03, PNorm = 57.7020, GNorm = 2.2598, lr_0 = 1.0804e-04
Loss = 1.1473e-03, PNorm = 57.7070, GNorm = 4.0337, lr_0 = 1.0804e-04
Loss = 1.1448e-03, PNorm = 57.7123, GNorm = 3.1053, lr_0 = 1.0804e-04
Loss = 1.2667e-03, PNorm = 57.7172, GNorm = 1.9636, lr_0 = 1.0804e-04
Validation rmse logD = 0.540745
Validation R2 logD = 0.813947
Epoch 51
Train function
Loss = 1.1033e-03, PNorm = 57.7226, GNorm = 6.3582, lr_0 = 1.0804e-04
Loss = 1.0512e-03, PNorm = 57.7293, GNorm = 1.4560, lr_0 = 1.0804e-04
Loss = 9.8717e-04, PNorm = 57.7328, GNorm = 1.8427, lr_0 = 1.0804e-04
Loss = 1.0762e-03, PNorm = 57.7354, GNorm = 3.5993, lr_0 = 1.0804e-04
Loss = 1.2087e-03, PNorm = 57.7401, GNorm = 2.4091, lr_0 = 1.0804e-04
Loss = 1.2550e-03, PNorm = 57.7453, GNorm = 8.9543, lr_0 = 1.0804e-04
Validation rmse logD = 0.537939
Validation R2 logD = 0.815874
Epoch 52
Train function
Loss = 1.0387e-03, PNorm = 57.7509, GNorm = 2.6945, lr_0 = 1.0804e-04
Loss = 1.0044e-03, PNorm = 57.7568, GNorm = 1.1432, lr_0 = 1.0804e-04
Loss = 9.0848e-04, PNorm = 57.7628, GNorm = 3.7850, lr_0 = 1.0804e-04
Loss = 1.0563e-03, PNorm = 57.7665, GNorm = 3.5263, lr_0 = 1.0804e-04
Loss = 9.8725e-04, PNorm = 57.7683, GNorm = 3.7785, lr_0 = 1.0804e-04
Loss = 9.1764e-04, PNorm = 57.7735, GNorm = 2.1640, lr_0 = 1.0804e-04
Validation rmse logD = 0.540189
Validation R2 logD = 0.814330
Epoch 53
Train function
Loss = 7.0001e-04, PNorm = 57.7784, GNorm = 1.1322, lr_0 = 1.0804e-04
Loss = 9.4046e-04, PNorm = 57.7810, GNorm = 1.6925, lr_0 = 1.0804e-04
Loss = 1.0794e-03, PNorm = 57.7848, GNorm = 3.5596, lr_0 = 1.0804e-04
Loss = 1.0920e-03, PNorm = 57.7894, GNorm = 1.7391, lr_0 = 1.0804e-04
Loss = 8.7918e-04, PNorm = 57.7943, GNorm = 2.2380, lr_0 = 1.0804e-04
Validation rmse logD = 0.538892
Validation R2 logD = 0.815220
Epoch 54
Train function
Loss = 7.3751e-04, PNorm = 57.7999, GNorm = 2.2825, lr_0 = 1.0804e-04
Loss = 9.0500e-04, PNorm = 57.8048, GNorm = 2.9416, lr_0 = 1.0804e-04
Loss = 9.5002e-04, PNorm = 57.8086, GNorm = 1.5769, lr_0 = 1.0804e-04
Loss = 8.9662e-04, PNorm = 57.8126, GNorm = 2.4465, lr_0 = 1.0804e-04
Loss = 9.9201e-04, PNorm = 57.8179, GNorm = 3.4386, lr_0 = 1.0804e-04
Loss = 9.4181e-04, PNorm = 57.8238, GNorm = 4.8182, lr_0 = 1.0804e-04
Validation rmse logD = 0.532703
Validation R2 logD = 0.819440
Epoch 55
Train function
Loss = 9.8273e-04, PNorm = 57.8290, GNorm = 1.2645, lr_0 = 1.0804e-04
Loss = 8.4145e-04, PNorm = 57.8329, GNorm = 1.6018, lr_0 = 1.0804e-04
Loss = 1.0341e-03, PNorm = 57.8358, GNorm = 1.8360, lr_0 = 1.0804e-04
Loss = 8.8753e-04, PNorm = 57.8399, GNorm = 1.4332, lr_0 = 1.0804e-04
Loss = 1.0780e-03, PNorm = 57.8441, GNorm = 4.7739, lr_0 = 1.0804e-04
Loss = 9.1302e-04, PNorm = 57.8496, GNorm = 1.8882, lr_0 = 1.0804e-04
Validation rmse logD = 0.530689
Validation R2 logD = 0.820803
Epoch 56
Train function
Loss = 9.2358e-04, PNorm = 57.8558, GNorm = 3.0906, lr_0 = 1.0804e-04
Loss = 8.9332e-04, PNorm = 57.8602, GNorm = 3.8044, lr_0 = 1.0804e-04
Loss = 6.6454e-04, PNorm = 57.8635, GNorm = 2.1781, lr_0 = 1.0804e-04
Loss = 7.7811e-04, PNorm = 57.8688, GNorm = 1.7094, lr_0 = 1.0804e-04
Loss = 8.2151e-04, PNorm = 57.8726, GNorm = 4.1515, lr_0 = 1.0804e-04
Validation rmse logD = 0.521153
Validation R2 logD = 0.827186
Epoch 57
Train function
Loss = 7.7134e-04, PNorm = 57.8755, GNorm = 2.8779, lr_0 = 1.0804e-04
Loss = 7.3612e-04, PNorm = 57.8810, GNorm = 2.6379, lr_0 = 1.0804e-04
Loss = 9.0038e-04, PNorm = 57.8856, GNorm = 1.5045, lr_0 = 1.0804e-04
Loss = 8.5713e-04, PNorm = 57.8907, GNorm = 1.7834, lr_0 = 1.0804e-04
Loss = 8.2994e-04, PNorm = 57.8950, GNorm = 4.3387, lr_0 = 1.0804e-04
Loss = 8.9215e-04, PNorm = 57.8988, GNorm = 1.5383, lr_0 = 1.0804e-04
Validation rmse logD = 0.538201
Validation R2 logD = 0.815694
Epoch 58
Train function
Loss = 1.0486e-03, PNorm = 57.9028, GNorm = 5.4213, lr_0 = 1.0804e-04
Loss = 1.0771e-03, PNorm = 57.9062, GNorm = 4.7302, lr_0 = 1.0804e-04
Loss = 1.0661e-03, PNorm = 57.9110, GNorm = 3.9170, lr_0 = 1.0804e-04
Loss = 9.9660e-04, PNorm = 57.9155, GNorm = 1.6024, lr_0 = 1.0804e-04
Loss = 7.8665e-04, PNorm = 57.9210, GNorm = 1.9450, lr_0 = 1.0804e-04
Loss = 7.9262e-04, PNorm = 57.9252, GNorm = 2.5105, lr_0 = 1.0804e-04
Validation rmse logD = 0.539251
Validation R2 logD = 0.814974
Epoch 59
Train function
Loss = 6.4253e-04, PNorm = 57.9294, GNorm = 1.4353, lr_0 = 1.0804e-04
Loss = 8.1304e-04, PNorm = 57.9353, GNorm = 2.8664, lr_0 = 1.0804e-04
Loss = 7.1237e-04, PNorm = 57.9388, GNorm = 0.9083, lr_0 = 1.0804e-04
Loss = 7.0009e-04, PNorm = 57.9430, GNorm = 1.2911, lr_0 = 1.0804e-04
Loss = 8.1869e-04, PNorm = 57.9455, GNorm = 3.3530, lr_0 = 1.0804e-04
Validation rmse logD = 0.532631
Validation R2 logD = 0.819489
Epoch 60
Train function
Loss = 7.1674e-04, PNorm = 57.9510, GNorm = 2.8097, lr_0 = 1.0804e-04
Loss = 8.6562e-04, PNorm = 57.9575, GNorm = 4.4629, lr_0 = 1.0804e-04
Loss = 1.0702e-03, PNorm = 57.9614, GNorm = 5.0970, lr_0 = 1.0804e-04
Loss = 1.3670e-03, PNorm = 57.9661, GNorm = 8.7633, lr_0 = 1.0804e-04
Loss = 1.1703e-03, PNorm = 57.9706, GNorm = 3.8995, lr_0 = 1.0804e-04
Loss = 1.0099e-03, PNorm = 57.9765, GNorm = 5.0748, lr_0 = 1.0804e-04
Validation rmse logD = 0.538487
Validation R2 logD = 0.815498
Epoch 61
Train function
Loss = 7.5578e-04, PNorm = 57.9823, GNorm = 0.9145, lr_0 = 1.0804e-04
Loss = 6.4485e-04, PNorm = 57.9858, GNorm = 0.9594, lr_0 = 1.0804e-04
Loss = 7.6261e-04, PNorm = 57.9896, GNorm = 2.1588, lr_0 = 1.0804e-04
Loss = 8.1540e-04, PNorm = 57.9938, GNorm = 6.4787, lr_0 = 1.0804e-04
Loss = 8.0862e-04, PNorm = 57.9977, GNorm = 1.8624, lr_0 = 1.0804e-04
Loss = 8.4392e-04, PNorm = 58.0021, GNorm = 4.6773, lr_0 = 1.0804e-04
Validation rmse logD = 0.538026
Validation R2 logD = 0.815814
Epoch 62
Train function
Loss = 8.1735e-04, PNorm = 58.0058, GNorm = 3.9697, lr_0 = 1.0804e-04
Loss = 9.6047e-04, PNorm = 58.0095, GNorm = 1.6045, lr_0 = 1.0804e-04
Loss = 7.3522e-04, PNorm = 58.0134, GNorm = 3.1077, lr_0 = 1.0804e-04
Loss = 8.2156e-04, PNorm = 58.0185, GNorm = 1.9237, lr_0 = 1.0804e-04
Loss = 7.6878e-04, PNorm = 58.0224, GNorm = 3.6109, lr_0 = 1.0804e-04
Validation rmse logD = 0.533757
Validation R2 logD = 0.818725
Epoch 63
Train function
Loss = 8.7444e-04, PNorm = 58.0283, GNorm = 4.7293, lr_0 = 1.0804e-04
Loss = 5.7489e-04, PNorm = 58.0319, GNorm = 1.3108, lr_0 = 1.0804e-04
Loss = 6.7137e-04, PNorm = 58.0372, GNorm = 1.1384, lr_0 = 1.0804e-04
Loss = 5.8296e-04, PNorm = 58.0403, GNorm = 1.4265, lr_0 = 1.0804e-04
Loss = 8.1454e-04, PNorm = 58.0444, GNorm = 4.1062, lr_0 = 1.0804e-04
Loss = 1.1224e-03, PNorm = 58.0478, GNorm = 4.7149, lr_0 = 1.0804e-04
Validation rmse logD = 0.574479
Validation R2 logD = 0.790010
Epoch 64
Train function
Loss = 1.2672e-03, PNorm = 58.0521, GNorm = 5.2342, lr_0 = 1.0804e-04
Loss = 1.0911e-03, PNorm = 58.0578, GNorm = 3.9944, lr_0 = 1.0804e-04
Loss = 9.3306e-04, PNorm = 58.0627, GNorm = 4.9699, lr_0 = 1.0804e-04
Loss = 8.2092e-04, PNorm = 58.0677, GNorm = 3.3803, lr_0 = 1.0804e-04
Loss = 1.0328e-03, PNorm = 58.0722, GNorm = 1.4418, lr_0 = 1.0804e-04
Loss = 1.3046e-03, PNorm = 58.0779, GNorm = 2.3917, lr_0 = 1.0804e-04
Validation rmse logD = 0.560937
Validation R2 logD = 0.799794
Epoch 65
Train function
Loss = 8.2477e-04, PNorm = 58.0815, GNorm = 4.0429, lr_0 = 1.0804e-04
Loss = 6.2300e-04, PNorm = 58.0871, GNorm = 2.9617, lr_0 = 1.0804e-04
Loss = 7.6892e-04, PNorm = 58.0924, GNorm = 1.1809, lr_0 = 1.0804e-04
Loss = 8.1458e-04, PNorm = 58.0977, GNorm = 2.5095, lr_0 = 1.0804e-04
Loss = 9.8580e-04, PNorm = 58.0995, GNorm = 1.0949, lr_0 = 1.0804e-04
Validation rmse logD = 0.549412
Validation R2 logD = 0.807935
Epoch 66
Train function
Loss = 8.4287e-04, PNorm = 58.1038, GNorm = 1.3050, lr_0 = 1.0804e-04
Loss = 6.7186e-04, PNorm = 58.1086, GNorm = 2.4293, lr_0 = 1.0804e-04
Loss = 7.6622e-04, PNorm = 58.1123, GNorm = 1.2161, lr_0 = 1.0804e-04
Loss = 8.3063e-04, PNorm = 58.1175, GNorm = 1.8977, lr_0 = 1.0804e-04
Loss = 7.0913e-04, PNorm = 58.1212, GNorm = 1.1371, lr_0 = 1.0804e-04
Loss = 6.5155e-04, PNorm = 58.1243, GNorm = 2.7272, lr_0 = 1.0804e-04
Validation rmse logD = 0.513474
Validation R2 logD = 0.832240
Epoch 67
Train function
Loss = 5.3316e-04, PNorm = 58.1282, GNorm = 5.7322, lr_0 = 1.0804e-04
Loss = 6.1100e-04, PNorm = 58.1313, GNorm = 2.6257, lr_0 = 1.0804e-04
Loss = 5.8224e-04, PNorm = 58.1346, GNorm = 2.6135, lr_0 = 1.0804e-04
Loss = 6.5483e-04, PNorm = 58.1385, GNorm = 1.4792, lr_0 = 1.0804e-04
Loss = 8.2857e-04, PNorm = 58.1415, GNorm = 1.3709, lr_0 = 1.0804e-04
Loss = 7.9065e-04, PNorm = 58.1462, GNorm = 3.8365, lr_0 = 1.0804e-04
Validation rmse logD = 0.534263
Validation R2 logD = 0.818381
Epoch 68
Train function
Loss = 7.3390e-04, PNorm = 58.1498, GNorm = 2.8226, lr_0 = 1.0804e-04
Loss = 6.4961e-04, PNorm = 58.1534, GNorm = 1.1553, lr_0 = 1.0804e-04
Loss = 7.3393e-04, PNorm = 58.1572, GNorm = 5.6788, lr_0 = 1.0804e-04
Loss = 7.7244e-04, PNorm = 58.1613, GNorm = 3.6717, lr_0 = 1.0804e-04
Loss = 6.8238e-04, PNorm = 58.1660, GNorm = 1.9509, lr_0 = 1.0804e-04
Validation rmse logD = 0.527234
Validation R2 logD = 0.823129
Epoch 69
Train function
Loss = 6.8214e-04, PNorm = 58.1694, GNorm = 1.7478, lr_0 = 1.0804e-04
Loss = 5.5989e-04, PNorm = 58.1729, GNorm = 1.1984, lr_0 = 1.0804e-04
Loss = 7.1108e-04, PNorm = 58.1768, GNorm = 1.4350, lr_0 = 1.0804e-04
Loss = 6.9373e-04, PNorm = 58.1805, GNorm = 1.3526, lr_0 = 1.0804e-04
Loss = 8.5384e-04, PNorm = 58.1843, GNorm = 1.9851, lr_0 = 1.0804e-04
Loss = 8.3299e-04, PNorm = 58.1877, GNorm = 4.2928, lr_0 = 1.0804e-04
Validation rmse logD = 0.526387
Validation R2 logD = 0.823696
Epoch 70
Train function
Loss = 6.4528e-04, PNorm = 58.1923, GNorm = 1.5734, lr_0 = 1.0804e-04
Loss = 5.7734e-04, PNorm = 58.1963, GNorm = 3.1602, lr_0 = 1.0804e-04
Loss = 6.2323e-04, PNorm = 58.1997, GNorm = 2.3959, lr_0 = 1.0804e-04
Loss = 5.6370e-04, PNorm = 58.2025, GNorm = 2.9465, lr_0 = 1.0804e-04
Loss = 5.7239e-04, PNorm = 58.2062, GNorm = 3.2627, lr_0 = 1.0804e-04
Loss = 7.5189e-04, PNorm = 58.2083, GNorm = 5.2226, lr_0 = 1.0804e-04
Validation rmse logD = 0.547402
Validation R2 logD = 0.809338
Epoch 71
Train function
Loss = 5.5513e-04, PNorm = 58.2114, GNorm = 2.3927, lr_0 = 1.0804e-04
Loss = 5.4026e-04, PNorm = 58.2152, GNorm = 1.7929, lr_0 = 1.0804e-04
Loss = 5.0820e-04, PNorm = 58.2193, GNorm = 2.2025, lr_0 = 1.0804e-04
Loss = 5.4970e-04, PNorm = 58.2226, GNorm = 1.6449, lr_0 = 1.0804e-04
Loss = 6.2857e-04, PNorm = 58.2264, GNorm = 1.2186, lr_0 = 1.0804e-04
Validation rmse logD = 0.529809
Validation R2 logD = 0.821397
Epoch 72
Train function
Loss = 5.5192e-04, PNorm = 58.2291, GNorm = 3.0778, lr_0 = 1.0804e-04
Loss = 7.9344e-04, PNorm = 58.2324, GNorm = 5.0586, lr_0 = 1.0804e-04
Loss = 4.8534e-04, PNorm = 58.2364, GNorm = 1.2940, lr_0 = 1.0804e-04
Loss = 4.4257e-04, PNorm = 58.2392, GNorm = 0.8733, lr_0 = 1.0804e-04
Loss = 5.8504e-04, PNorm = 58.2419, GNorm = 3.2885, lr_0 = 1.0804e-04
Loss = 7.6032e-04, PNorm = 58.2446, GNorm = 9.6984, lr_0 = 1.0804e-04
Validation rmse logD = 0.544336
Validation R2 logD = 0.811469
Epoch 73
Train function
Loss = 8.4869e-04, PNorm = 58.2487, GNorm = 3.5820, lr_0 = 1.0804e-04
Loss = 8.3645e-04, PNorm = 58.2532, GNorm = 5.9445, lr_0 = 1.0804e-04
Loss = 6.2188e-04, PNorm = 58.2568, GNorm = 4.1343, lr_0 = 1.0804e-04
Loss = 5.1247e-04, PNorm = 58.2611, GNorm = 1.1580, lr_0 = 1.0804e-04
Loss = 5.7883e-04, PNorm = 58.2660, GNorm = 1.0204, lr_0 = 1.0804e-04
Loss = 6.5138e-04, PNorm = 58.2699, GNorm = 4.4937, lr_0 = 1.0804e-04
Validation rmse logD = 0.518999
Validation R2 logD = 0.828611
Epoch 74
Train function
Loss = 4.5629e-04, PNorm = 58.2729, GNorm = 4.0110, lr_0 = 1.0804e-04
Loss = 5.1904e-04, PNorm = 58.2754, GNorm = 4.6382, lr_0 = 1.0804e-04
Loss = 7.3532e-04, PNorm = 58.2787, GNorm = 3.4395, lr_0 = 1.0804e-04
Loss = 8.2345e-04, PNorm = 58.2814, GNorm = 5.8354, lr_0 = 1.0804e-04
Loss = 8.0617e-04, PNorm = 58.2868, GNorm = 1.7808, lr_0 = 1.0804e-04
Validation rmse logD = 0.512295
Validation R2 logD = 0.833010
Epoch 75
Train function
Loss = 5.8036e-04, PNorm = 58.2924, GNorm = 4.9257, lr_0 = 1.0804e-04
Loss = 5.3886e-04, PNorm = 58.2958, GNorm = 1.7412, lr_0 = 1.0804e-04
Loss = 6.6446e-04, PNorm = 58.2992, GNorm = 0.8095, lr_0 = 1.0804e-04
Loss = 4.2013e-04, PNorm = 58.3030, GNorm = 1.7726, lr_0 = 1.0804e-04
Loss = 5.7539e-04, PNorm = 58.3055, GNorm = 1.7108, lr_0 = 1.0804e-04
Loss = 6.1835e-04, PNorm = 58.3081, GNorm = 2.3254, lr_0 = 1.0804e-04
Validation rmse logD = 0.526151
Validation R2 logD = 0.823855
Epoch 76
Train function
Loss = 5.0237e-04, PNorm = 58.3118, GNorm = 2.1229, lr_0 = 1.0804e-04
Loss = 4.6669e-04, PNorm = 58.3150, GNorm = 2.7853, lr_0 = 1.0804e-04
Loss = 6.6218e-04, PNorm = 58.3183, GNorm = 2.8325, lr_0 = 1.0804e-04
Loss = 6.2366e-04, PNorm = 58.3223, GNorm = 1.1760, lr_0 = 1.0804e-04
Loss = 5.3398e-04, PNorm = 58.3256, GNorm = 1.7763, lr_0 = 1.0804e-04
Loss = 5.2562e-04, PNorm = 58.3293, GNorm = 1.8641, lr_0 = 1.0804e-04
Validation rmse logD = 0.511818
Validation R2 logD = 0.833321
Epoch 77
Train function
Loss = 4.8325e-04, PNorm = 58.3328, GNorm = 1.5575, lr_0 = 1.0804e-04
Loss = 3.9796e-04, PNorm = 58.3361, GNorm = 2.3009, lr_0 = 1.0804e-04
Loss = 5.1766e-04, PNorm = 58.3392, GNorm = 3.5365, lr_0 = 1.0804e-04
Loss = 5.0606e-04, PNorm = 58.3417, GNorm = 2.0429, lr_0 = 1.0804e-04
Loss = 7.3671e-04, PNorm = 58.3449, GNorm = 4.2062, lr_0 = 1.0804e-04
Validation rmse logD = 0.519703
Validation R2 logD = 0.828146
Epoch 78
Train function
Loss = 4.0494e-04, PNorm = 58.3487, GNorm = 2.0776, lr_0 = 1.0804e-04
Loss = 4.0699e-04, PNorm = 58.3513, GNorm = 1.0337, lr_0 = 1.0804e-04
Loss = 4.6592e-04, PNorm = 58.3549, GNorm = 0.9862, lr_0 = 1.0804e-04
Loss = 4.9217e-04, PNorm = 58.3597, GNorm = 1.2818, lr_0 = 1.0804e-04
Loss = 7.3427e-04, PNorm = 58.3634, GNorm = 2.6588, lr_0 = 1.0804e-04
Loss = 6.0650e-04, PNorm = 58.3677, GNorm = 1.9642, lr_0 = 1.0804e-04
Validation rmse logD = 0.536964
Validation R2 logD = 0.816540
Epoch 79
Train function
Loss = 4.5889e-04, PNorm = 58.3723, GNorm = 1.5324, lr_0 = 1.0804e-04
Loss = 3.7904e-04, PNorm = 58.3749, GNorm = 2.1881, lr_0 = 1.0804e-04
Loss = 4.7285e-04, PNorm = 58.3783, GNorm = 4.5329, lr_0 = 1.0804e-04
Loss = 6.1374e-04, PNorm = 58.3814, GNorm = 5.1290, lr_0 = 1.0804e-04
Loss = 6.7218e-04, PNorm = 58.3843, GNorm = 3.2485, lr_0 = 1.0804e-04
Loss = 6.0398e-04, PNorm = 58.3883, GNorm = 2.1443, lr_0 = 1.0804e-04
Validation rmse logD = 0.511178
Validation R2 logD = 0.833737
Epoch 80
Train function
Loss = 4.1646e-04, PNorm = 58.3913, GNorm = 1.0864, lr_0 = 1.0804e-04
Loss = 4.6553e-04, PNorm = 58.3937, GNorm = 2.7654, lr_0 = 1.0804e-04
Loss = 4.4705e-04, PNorm = 58.3969, GNorm = 1.6796, lr_0 = 1.0804e-04
Loss = 4.4866e-04, PNorm = 58.4003, GNorm = 1.7949, lr_0 = 1.0804e-04
Loss = 4.4893e-04, PNorm = 58.4031, GNorm = 1.6112, lr_0 = 1.0804e-04
Validation rmse logD = 0.522258
Validation R2 logD = 0.826451
Epoch 81
Train function
Loss = 4.0841e-04, PNorm = 58.4049, GNorm = 3.2094, lr_0 = 1.0804e-04
Loss = 4.8553e-04, PNorm = 58.4074, GNorm = 1.4888, lr_0 = 1.0804e-04
Loss = 5.8272e-04, PNorm = 58.4115, GNorm = 0.8655, lr_0 = 1.0804e-04
Loss = 4.0431e-04, PNorm = 58.4149, GNorm = 0.8337, lr_0 = 1.0804e-04
Loss = 3.4334e-04, PNorm = 58.4177, GNorm = 2.4215, lr_0 = 1.0804e-04
Loss = 3.7042e-04, PNorm = 58.4201, GNorm = 1.4106, lr_0 = 1.0804e-04
Validation rmse logD = 0.525374
Validation R2 logD = 0.824375
Epoch 82
Train function
Loss = 7.1348e-04, PNorm = 58.4243, GNorm = 4.0295, lr_0 = 1.0804e-04
Loss = 4.8089e-04, PNorm = 58.4276, GNorm = 2.0707, lr_0 = 1.0804e-04
Loss = 4.6447e-04, PNorm = 58.4313, GNorm = 2.8170, lr_0 = 1.0804e-04
Loss = 3.9030e-04, PNorm = 58.4350, GNorm = 3.1000, lr_0 = 1.0804e-04
Loss = 5.3069e-04, PNorm = 58.4382, GNorm = 2.6234, lr_0 = 1.0804e-04
Loss = 4.9282e-04, PNorm = 58.4411, GNorm = 3.9319, lr_0 = 1.0804e-04
Validation rmse logD = 0.520771
Validation R2 logD = 0.827439
Epoch 83
Train function
Loss = 3.4741e-04, PNorm = 58.4435, GNorm = 0.6977, lr_0 = 1.0804e-04
Loss = 3.8586e-04, PNorm = 58.4462, GNorm = 3.7639, lr_0 = 1.0804e-04
Loss = 3.7617e-04, PNorm = 58.4486, GNorm = 3.0485, lr_0 = 1.0804e-04
Loss = 4.3514e-04, PNorm = 58.4522, GNorm = 3.0490, lr_0 = 1.0804e-04
Loss = 4.7778e-04, PNorm = 58.4549, GNorm = 1.8505, lr_0 = 1.0804e-04
Validation rmse logD = 0.521726
Validation R2 logD = 0.826805
Epoch 84
Train function
Loss = 4.1593e-04, PNorm = 58.4575, GNorm = 1.8275, lr_0 = 1.0804e-04
Loss = 4.0978e-04, PNorm = 58.4613, GNorm = 2.7059, lr_0 = 1.0804e-04
Loss = 6.3744e-04, PNorm = 58.4648, GNorm = 3.2874, lr_0 = 1.0804e-04
Loss = 4.3405e-04, PNorm = 58.4679, GNorm = 0.9597, lr_0 = 1.0804e-04
Loss = 4.1945e-04, PNorm = 58.4718, GNorm = 1.4114, lr_0 = 1.0804e-04
Loss = 4.1254e-04, PNorm = 58.4761, GNorm = 1.0014, lr_0 = 1.0804e-04
Validation rmse logD = 0.515406
Validation R2 logD = 0.830976
Epoch 85
Train function
Loss = 4.6963e-04, PNorm = 58.4777, GNorm = 2.4253, lr_0 = 1.0804e-04
Loss = 3.7401e-04, PNorm = 58.4809, GNorm = 1.1530, lr_0 = 1.0804e-04
Loss = 4.1132e-04, PNorm = 58.4850, GNorm = 1.1218, lr_0 = 1.0804e-04
Loss = 3.6146e-04, PNorm = 58.4872, GNorm = 1.7024, lr_0 = 1.0804e-04
Loss = 5.5886e-04, PNorm = 58.4906, GNorm = 7.0131, lr_0 = 1.0804e-04
Loss = 6.4410e-04, PNorm = 58.4941, GNorm = 1.5274, lr_0 = 1.0804e-04
Validation rmse logD = 0.521479
Validation R2 logD = 0.826969
Epoch 86
Train function
Loss = 4.2063e-04, PNorm = 58.4988, GNorm = 1.4686, lr_0 = 1.0804e-04
Loss = 3.9806e-04, PNorm = 58.5024, GNorm = 2.5277, lr_0 = 1.0804e-04
Loss = 4.5225e-04, PNorm = 58.5056, GNorm = 2.1063, lr_0 = 1.0804e-04
Loss = 3.4937e-04, PNorm = 58.5088, GNorm = 1.6502, lr_0 = 1.0804e-04
Loss = 4.3148e-04, PNorm = 58.5117, GNorm = 0.8450, lr_0 = 1.0804e-04
Validation rmse logD = 0.507991
Validation R2 logD = 0.835804
Epoch 87
Train function
Loss = 3.4454e-04, PNorm = 58.5138, GNorm = 1.0168, lr_0 = 1.0804e-04
Loss = 3.9384e-04, PNorm = 58.5157, GNorm = 1.7132, lr_0 = 1.0804e-04
Loss = 4.9159e-04, PNorm = 58.5184, GNorm = 5.0743, lr_0 = 1.0804e-04
Loss = 4.8865e-04, PNorm = 58.5218, GNorm = 0.9972, lr_0 = 1.0804e-04
Loss = 4.4891e-04, PNorm = 58.5251, GNorm = 4.2298, lr_0 = 1.0804e-04
Loss = 4.8392e-04, PNorm = 58.5276, GNorm = 1.0475, lr_0 = 1.0804e-04
Validation rmse logD = 0.517744
Validation R2 logD = 0.829439
Epoch 88
Train function
Loss = 7.0045e-04, PNorm = 58.5306, GNorm = 8.1436, lr_0 = 1.0804e-04
Loss = 6.9396e-04, PNorm = 58.5334, GNorm = 1.1031, lr_0 = 1.0804e-04
Loss = 4.5506e-04, PNorm = 58.5390, GNorm = 1.5167, lr_0 = 1.0804e-04
Loss = 3.4890e-04, PNorm = 58.5430, GNorm = 0.8551, lr_0 = 1.0804e-04
Loss = 3.4761e-04, PNorm = 58.5466, GNorm = 1.1506, lr_0 = 1.0804e-04
Loss = 3.4104e-04, PNorm = 58.5488, GNorm = 1.9056, lr_0 = 1.0804e-04
Loss = 9.7237e-04, PNorm = 58.5491, GNorm = 1.5150, lr_0 = 1.0804e-04
Validation rmse logD = 0.510710
Validation R2 logD = 0.834042
Epoch 89
Train function
Loss = 2.6764e-04, PNorm = 58.5514, GNorm = 2.2329, lr_0 = 1.0804e-04
Loss = 3.3943e-04, PNorm = 58.5544, GNorm = 3.2742, lr_0 = 1.0804e-04
Loss = 6.8802e-04, PNorm = 58.5570, GNorm = 5.2352, lr_0 = 1.0804e-04
Loss = 7.5357e-04, PNorm = 58.5593, GNorm = 2.2371, lr_0 = 1.0804e-04
Loss = 8.4710e-04, PNorm = 58.5642, GNorm = 7.0259, lr_0 = 1.0804e-04
Validation rmse logD = 0.551785
Validation R2 logD = 0.806273
Epoch 90
Train function
Loss = 9.6901e-04, PNorm = 58.5676, GNorm = 6.9048, lr_0 = 1.0804e-04
Loss = 6.6885e-04, PNorm = 58.5718, GNorm = 3.9125, lr_0 = 1.0804e-04
Loss = 5.0745e-04, PNorm = 58.5777, GNorm = 3.3218, lr_0 = 1.0804e-04
Loss = 4.4494e-04, PNorm = 58.5826, GNorm = 1.6265, lr_0 = 1.0804e-04
Loss = 4.6326e-04, PNorm = 58.5857, GNorm = 1.9455, lr_0 = 1.0804e-04
Loss = 4.9845e-04, PNorm = 58.5894, GNorm = 3.2027, lr_0 = 1.0804e-04
Validation rmse logD = 0.520341
Validation R2 logD = 0.827723
Epoch 91
Train function
Loss = 3.3960e-04, PNorm = 58.5928, GNorm = 1.4146, lr_0 = 1.0804e-04
Loss = 6.0377e-04, PNorm = 58.5958, GNorm = 5.3068, lr_0 = 1.0804e-04
Loss = 6.2225e-04, PNorm = 58.5990, GNorm = 6.1204, lr_0 = 1.0804e-04
Loss = 5.1527e-04, PNorm = 58.6030, GNorm = 1.3254, lr_0 = 1.0804e-04
Loss = 6.3387e-04, PNorm = 58.6066, GNorm = 4.5627, lr_0 = 1.0804e-04
Loss = 6.2611e-04, PNorm = 58.6110, GNorm = 5.5140, lr_0 = 1.0804e-04
Loss = 7.1215e-04, PNorm = 58.6115, GNorm = 2.5956, lr_0 = 1.0804e-04
Validation rmse logD = 0.531340
Validation R2 logD = 0.820363
Epoch 92
Train function
Loss = 5.8944e-04, PNorm = 58.6142, GNorm = 2.3991, lr_0 = 1.0804e-04
Loss = 5.4003e-04, PNorm = 58.6176, GNorm = 1.3926, lr_0 = 1.0804e-04
Loss = 4.3383e-04, PNorm = 58.6210, GNorm = 0.9825, lr_0 = 1.0804e-04
Loss = 5.4053e-04, PNorm = 58.6247, GNorm = 2.6799, lr_0 = 1.0804e-04
Loss = 6.6461e-04, PNorm = 58.6269, GNorm = 4.8479, lr_0 = 1.0804e-04
Validation rmse logD = 0.538875
Validation R2 logD = 0.815232
Epoch 93
Train function
Loss = 5.5096e-04, PNorm = 58.6297, GNorm = 2.1620, lr_0 = 1.0804e-04
Loss = 4.0122e-04, PNorm = 58.6341, GNorm = 1.5698, lr_0 = 1.0804e-04
Loss = 3.4356e-04, PNorm = 58.6375, GNorm = 1.8277, lr_0 = 1.0804e-04
Loss = 6.6088e-04, PNorm = 58.6399, GNorm = 2.6605, lr_0 = 1.0804e-04
Loss = 5.9874e-04, PNorm = 58.6433, GNorm = 2.5707, lr_0 = 1.0804e-04
Loss = 4.8366e-04, PNorm = 58.6467, GNorm = 1.9126, lr_0 = 1.0804e-04
Validation rmse logD = 0.518209
Validation R2 logD = 0.829132
Epoch 94
Train function
Loss = 5.0265e-04, PNorm = 58.6504, GNorm = 1.7087, lr_0 = 1.0804e-04
Loss = 4.3858e-04, PNorm = 58.6554, GNorm = 4.3442, lr_0 = 1.0804e-04
Loss = 4.3425e-04, PNorm = 58.6592, GNorm = 1.9110, lr_0 = 1.0804e-04
Loss = 4.2231e-04, PNorm = 58.6622, GNorm = 2.4096, lr_0 = 1.0804e-04
Loss = 3.5637e-04, PNorm = 58.6652, GNorm = 1.2329, lr_0 = 1.0804e-04
Loss = 3.5042e-04, PNorm = 58.6688, GNorm = 2.1836, lr_0 = 1.0804e-04
Loss = 4.0143e-04, PNorm = 58.6690, GNorm = 2.1587, lr_0 = 1.0804e-04
Validation rmse logD = 0.503439
Validation R2 logD = 0.838734
Epoch 95
Train function
Loss = 3.1387e-04, PNorm = 58.6707, GNorm = 0.8092, lr_0 = 1.0804e-04
Loss = 3.5292e-04, PNorm = 58.6720, GNorm = 1.3059, lr_0 = 1.0804e-04
Loss = 2.9091e-04, PNorm = 58.6749, GNorm = 1.3832, lr_0 = 1.0804e-04
Loss = 2.8736e-04, PNorm = 58.6763, GNorm = 0.8594, lr_0 = 1.0804e-04
Loss = 2.8967e-04, PNorm = 58.6797, GNorm = 0.8785, lr_0 = 1.0804e-04
Validation rmse logD = 0.506456
Validation R2 logD = 0.836795
Epoch 96
Train function
Loss = 2.3758e-04, PNorm = 58.6813, GNorm = 1.1401, lr_0 = 1.0804e-04
Loss = 2.6517e-04, PNorm = 58.6835, GNorm = 1.1447, lr_0 = 1.0804e-04
Loss = 2.9386e-04, PNorm = 58.6853, GNorm = 2.1047, lr_0 = 1.0804e-04
Loss = 3.7894e-04, PNorm = 58.6870, GNorm = 1.1238, lr_0 = 1.0804e-04
Loss = 3.6292e-04, PNorm = 58.6895, GNorm = 2.7006, lr_0 = 1.0804e-04
Loss = 3.9871e-04, PNorm = 58.6928, GNorm = 3.0635, lr_0 = 1.0804e-04
Validation rmse logD = 0.509701
Validation R2 logD = 0.834697
Epoch 97
Train function
Loss = 3.6063e-04, PNorm = 58.6940, GNorm = 0.9442, lr_0 = 1.0804e-04
Loss = 3.6446e-04, PNorm = 58.6962, GNorm = 3.5589, lr_0 = 1.0804e-04
Loss = 2.8851e-04, PNorm = 58.6999, GNorm = 0.6540, lr_0 = 1.0804e-04
Loss = 3.3854e-04, PNorm = 58.7029, GNorm = 3.6743, lr_0 = 1.0804e-04
Loss = 5.0211e-04, PNorm = 58.7058, GNorm = 5.1163, lr_0 = 1.0804e-04
Loss = 4.8345e-04, PNorm = 58.7091, GNorm = 2.9549, lr_0 = 1.0804e-04
Loss = 7.1738e-04, PNorm = 58.7093, GNorm = 1.5087, lr_0 = 1.0804e-04
Validation rmse logD = 0.522109
Validation R2 logD = 0.826550
Epoch 98
Train function
Loss = 3.3822e-04, PNorm = 58.7124, GNorm = 1.5649, lr_0 = 1.0804e-04
Loss = 2.9626e-04, PNorm = 58.7157, GNorm = 1.9726, lr_0 = 1.0804e-04
Loss = 3.8080e-04, PNorm = 58.7175, GNorm = 3.8495, lr_0 = 1.0804e-04
Loss = 4.6885e-04, PNorm = 58.7194, GNorm = 3.7527, lr_0 = 1.0804e-04
Loss = 4.0227e-04, PNorm = 58.7225, GNorm = 3.9945, lr_0 = 1.0804e-04
Validation rmse logD = 0.509810
Validation R2 logD = 0.834626
Epoch 99
Train function
Loss = 5.1348e-04, PNorm = 58.7245, GNorm = 0.9223, lr_0 = 1.0804e-04
Loss = 3.9110e-04, PNorm = 58.7270, GNorm = 3.4431, lr_0 = 1.0804e-04
Loss = 4.0918e-04, PNorm = 58.7302, GNorm = 1.0488, lr_0 = 1.0804e-04
Loss = 2.9378e-04, PNorm = 58.7330, GNorm = 1.3916, lr_0 = 1.0804e-04
Loss = 3.1233e-04, PNorm = 58.7359, GNorm = 2.7486, lr_0 = 1.0804e-04
Loss = 3.2634e-04, PNorm = 58.7387, GNorm = 2.2860, lr_0 = 1.0804e-04
Validation rmse logD = 0.506178
Validation R2 logD = 0.836974
Model 0 best validation rmse = 0.503439 on epoch 94
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.584713
Model 0 test R2 logD = 0.788337
Ensemble test rmse  logD= 0.584713
Ensemble test R2  logD= 0.788337
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2832,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.0400e-02, PNorm = 55.5555, GNorm = 3.7385, lr_0 = 1.0804e-04
Loss = 1.8360e-02, PNorm = 55.5582, GNorm = 2.6442, lr_0 = 1.0804e-04
Loss = 1.8396e-02, PNorm = 55.5612, GNorm = 3.4408, lr_0 = 1.0804e-04
Loss = 1.5440e-02, PNorm = 55.5643, GNorm = 2.2422, lr_0 = 1.0804e-04
Loss = 1.5795e-02, PNorm = 55.5679, GNorm = 2.2788, lr_0 = 1.0804e-04
Validation rmse logD = 1.055304
Validation R2 logD = 0.245005
Epoch 1
Train function
Loss = 1.3651e-02, PNorm = 55.5729, GNorm = 4.5173, lr_0 = 1.0804e-04
Loss = 1.6034e-02, PNorm = 55.5782, GNorm = 1.2692, lr_0 = 1.0804e-04
Loss = 1.5432e-02, PNorm = 55.5841, GNorm = 1.9766, lr_0 = 1.0804e-04
Loss = 1.4430e-02, PNorm = 55.5904, GNorm = 1.5475, lr_0 = 1.0804e-04
Loss = 1.4317e-02, PNorm = 55.5979, GNorm = 2.0433, lr_0 = 1.0804e-04
Loss = 1.4474e-02, PNorm = 55.6059, GNorm = 8.1136, lr_0 = 1.0804e-04
Validation rmse logD = 1.003032
Validation R2 logD = 0.317946
Epoch 2
Train function
Loss = 1.3799e-02, PNorm = 55.6157, GNorm = 1.2503, lr_0 = 1.0804e-04
Loss = 1.3188e-02, PNorm = 55.6264, GNorm = 6.7693, lr_0 = 1.0804e-04
Loss = 1.2004e-02, PNorm = 55.6366, GNorm = 1.8254, lr_0 = 1.0804e-04
Loss = 1.2390e-02, PNorm = 55.6467, GNorm = 5.0079, lr_0 = 1.0804e-04
Loss = 1.2918e-02, PNorm = 55.6581, GNorm = 4.4975, lr_0 = 1.0804e-04
Validation rmse logD = 0.937296
Validation R2 logD = 0.404417
Epoch 3
Train function
Loss = 1.1868e-02, PNorm = 55.6709, GNorm = 4.7437, lr_0 = 1.0804e-04
Loss = 1.1921e-02, PNorm = 55.6836, GNorm = 3.5882, lr_0 = 1.0804e-04
Loss = 1.0766e-02, PNorm = 55.6934, GNorm = 2.9910, lr_0 = 1.0804e-04
Loss = 1.2119e-02, PNorm = 55.7022, GNorm = 7.8303, lr_0 = 1.0804e-04
Loss = 1.2599e-02, PNorm = 55.7125, GNorm = 11.8637, lr_0 = 1.0804e-04
Loss = 1.1842e-02, PNorm = 55.7253, GNorm = 6.0421, lr_0 = 1.0804e-04
Validation rmse logD = 0.897857
Validation R2 logD = 0.453483
Epoch 4
Train function
Loss = 1.1579e-02, PNorm = 55.7378, GNorm = 4.6526, lr_0 = 1.0804e-04
Loss = 1.1196e-02, PNorm = 55.7493, GNorm = 1.7407, lr_0 = 1.0804e-04
Loss = 1.2665e-02, PNorm = 55.7601, GNorm = 5.4354, lr_0 = 1.0804e-04
Loss = 1.1329e-02, PNorm = 55.7721, GNorm = 2.1708, lr_0 = 1.0804e-04
Loss = 1.0148e-02, PNorm = 55.7847, GNorm = 2.7527, lr_0 = 1.0804e-04
Loss = 9.4296e-03, PNorm = 55.7973, GNorm = 2.0330, lr_0 = 1.0804e-04
Validation rmse logD = 0.871702
Validation R2 logD = 0.484860
Epoch 5
Train function
Loss = 9.0347e-03, PNorm = 55.8083, GNorm = 5.0058, lr_0 = 1.0804e-04
Loss = 9.7422e-03, PNorm = 55.8197, GNorm = 2.5155, lr_0 = 1.0804e-04
Loss = 9.8263e-03, PNorm = 55.8324, GNorm = 3.9916, lr_0 = 1.0804e-04
Loss = 1.0227e-02, PNorm = 55.8437, GNorm = 5.5275, lr_0 = 1.0804e-04
Loss = 9.0867e-03, PNorm = 55.8575, GNorm = 6.3348, lr_0 = 1.0804e-04
Validation rmse logD = 0.845398
Validation R2 logD = 0.515481
Epoch 6
Train function
Loss = 5.4400e-03, PNorm = 55.8735, GNorm = 4.9425, lr_0 = 1.0804e-04
Loss = 9.8893e-03, PNorm = 55.8875, GNorm = 6.9357, lr_0 = 1.0804e-04
Loss = 8.3257e-03, PNorm = 55.9010, GNorm = 5.5084, lr_0 = 1.0804e-04
Loss = 1.0096e-02, PNorm = 55.9147, GNorm = 5.9082, lr_0 = 1.0804e-04
Loss = 9.3306e-03, PNorm = 55.9254, GNorm = 6.3028, lr_0 = 1.0804e-04
Loss = 8.7811e-03, PNorm = 55.9369, GNorm = 2.3388, lr_0 = 1.0804e-04
Validation rmse logD = 0.880983
Validation R2 logD = 0.473833
Epoch 7
Train function
Loss = 6.5410e-03, PNorm = 55.9491, GNorm = 1.5171, lr_0 = 1.0804e-04
Loss = 7.5027e-03, PNorm = 55.9602, GNorm = 2.8294, lr_0 = 1.0804e-04
Loss = 7.8215e-03, PNorm = 55.9749, GNorm = 2.2327, lr_0 = 1.0804e-04
Loss = 7.8228e-03, PNorm = 55.9886, GNorm = 4.0561, lr_0 = 1.0804e-04
Loss = 9.0502e-03, PNorm = 55.9990, GNorm = 9.1181, lr_0 = 1.0804e-04
Loss = 9.1615e-03, PNorm = 56.0094, GNorm = 2.0819, lr_0 = 1.0804e-04
Validation rmse logD = 0.938960
Validation R2 logD = 0.402300
Epoch 8
Train function
Loss = 7.1166e-03, PNorm = 56.0210, GNorm = 2.0500, lr_0 = 1.0804e-04
Loss = 8.0815e-03, PNorm = 56.0325, GNorm = 1.1600, lr_0 = 1.0804e-04
Loss = 7.2298e-03, PNorm = 56.0446, GNorm = 1.5816, lr_0 = 1.0804e-04
Loss = 6.6058e-03, PNorm = 56.0584, GNorm = 3.0243, lr_0 = 1.0804e-04
Loss = 7.8368e-03, PNorm = 56.0682, GNorm = 5.5182, lr_0 = 1.0804e-04
Validation rmse logD = 0.778051
Validation R2 logD = 0.589602
Epoch 9
Train function
Loss = 4.6225e-03, PNorm = 56.0802, GNorm = 1.1768, lr_0 = 1.0804e-04
Loss = 6.5423e-03, PNorm = 56.0936, GNorm = 4.1554, lr_0 = 1.0804e-04
Loss = 7.0291e-03, PNorm = 56.1067, GNorm = 7.9225, lr_0 = 1.0804e-04
Loss = 7.7932e-03, PNorm = 56.1168, GNorm = 2.3722, lr_0 = 1.0804e-04
Loss = 7.0773e-03, PNorm = 56.1287, GNorm = 4.0093, lr_0 = 1.0804e-04
Loss = 7.4349e-03, PNorm = 56.1394, GNorm = 3.1568, lr_0 = 1.0804e-04
Validation rmse logD = 0.742064
Validation R2 logD = 0.626689
Epoch 10
Train function
Loss = 6.2767e-03, PNorm = 56.1474, GNorm = 4.4201, lr_0 = 1.0804e-04
Loss = 6.9412e-03, PNorm = 56.1572, GNorm = 2.7794, lr_0 = 1.0804e-04
Loss = 6.5314e-03, PNorm = 56.1693, GNorm = 8.7333, lr_0 = 1.0804e-04
Loss = 6.2780e-03, PNorm = 56.1809, GNorm = 2.2259, lr_0 = 1.0804e-04
Loss = 4.9421e-03, PNorm = 56.1929, GNorm = 3.3589, lr_0 = 1.0804e-04
Loss = 5.7515e-03, PNorm = 56.2020, GNorm = 3.0665, lr_0 = 1.0804e-04
Validation rmse logD = 0.762767
Validation R2 logD = 0.605567
Epoch 11
Train function
Loss = 5.8630e-03, PNorm = 56.2130, GNorm = 3.9759, lr_0 = 1.0804e-04
Loss = 5.8637e-03, PNorm = 56.2254, GNorm = 7.0851, lr_0 = 1.0804e-04
Loss = 5.6597e-03, PNorm = 56.2337, GNorm = 6.5861, lr_0 = 1.0804e-04
Loss = 5.2914e-03, PNorm = 56.2440, GNorm = 1.6093, lr_0 = 1.0804e-04
Loss = 6.3695e-03, PNorm = 56.2519, GNorm = 2.3905, lr_0 = 1.0804e-04
Validation rmse logD = 0.709859
Validation R2 logD = 0.658388
Epoch 12
Train function
Loss = 9.4332e-03, PNorm = 56.2622, GNorm = 3.7337, lr_0 = 1.0804e-04
Loss = 5.2648e-03, PNorm = 56.2750, GNorm = 8.4102, lr_0 = 1.0804e-04
Loss = 5.3806e-03, PNorm = 56.2865, GNorm = 2.8988, lr_0 = 1.0804e-04
Loss = 4.8341e-03, PNorm = 56.2953, GNorm = 4.5253, lr_0 = 1.0804e-04
Loss = 4.5038e-03, PNorm = 56.3039, GNorm = 2.2230, lr_0 = 1.0804e-04
Loss = 5.2807e-03, PNorm = 56.3130, GNorm = 8.5574, lr_0 = 1.0804e-04
Validation rmse logD = 0.699275
Validation R2 logD = 0.668499
Epoch 13
Train function
Loss = 4.1768e-03, PNorm = 56.3239, GNorm = 1.5512, lr_0 = 1.0804e-04
Loss = 5.0205e-03, PNorm = 56.3333, GNorm = 2.4023, lr_0 = 1.0804e-04
Loss = 5.2218e-03, PNorm = 56.3405, GNorm = 1.9589, lr_0 = 1.0804e-04
Loss = 6.0158e-03, PNorm = 56.3519, GNorm = 1.5658, lr_0 = 1.0804e-04
Loss = 5.0972e-03, PNorm = 56.3619, GNorm = 8.7823, lr_0 = 1.0804e-04
Loss = 4.4316e-03, PNorm = 56.3711, GNorm = 2.4634, lr_0 = 1.0804e-04
Validation rmse logD = 0.698879
Validation R2 logD = 0.668874
Epoch 14
Train function
Loss = 4.7431e-03, PNorm = 56.3803, GNorm = 7.3198, lr_0 = 1.0804e-04
Loss = 5.1945e-03, PNorm = 56.3913, GNorm = 3.3803, lr_0 = 1.0804e-04
Loss = 4.2731e-03, PNorm = 56.3999, GNorm = 2.4494, lr_0 = 1.0804e-04
Loss = 4.3880e-03, PNorm = 56.4098, GNorm = 1.8993, lr_0 = 1.0804e-04
Loss = 5.0487e-03, PNorm = 56.4179, GNorm = 5.8311, lr_0 = 1.0804e-04
Validation rmse logD = 0.736832
Validation R2 logD = 0.631934
Epoch 15
Train function
Loss = 3.9330e-03, PNorm = 56.4274, GNorm = 8.7534, lr_0 = 1.0804e-04
Loss = 4.3605e-03, PNorm = 56.4357, GNorm = 4.0651, lr_0 = 1.0804e-04
Loss = 5.8020e-03, PNorm = 56.4450, GNorm = 6.1879, lr_0 = 1.0804e-04
Loss = 4.9317e-03, PNorm = 56.4535, GNorm = 8.3499, lr_0 = 1.0804e-04
Loss = 4.2085e-03, PNorm = 56.4642, GNorm = 1.8823, lr_0 = 1.0804e-04
Loss = 3.8304e-03, PNorm = 56.4737, GNorm = 4.6352, lr_0 = 1.0804e-04
Validation rmse logD = 0.687786
Validation R2 logD = 0.679303
Epoch 16
Train function
Loss = 3.4332e-03, PNorm = 56.4825, GNorm = 8.0236, lr_0 = 1.0804e-04
Loss = 4.5281e-03, PNorm = 56.4916, GNorm = 1.9695, lr_0 = 1.0804e-04
Loss = 4.4226e-03, PNorm = 56.5004, GNorm = 4.4137, lr_0 = 1.0804e-04
Loss = 4.1426e-03, PNorm = 56.5092, GNorm = 2.5160, lr_0 = 1.0804e-04
Loss = 3.6235e-03, PNorm = 56.5178, GNorm = 2.9675, lr_0 = 1.0804e-04
Loss = 4.0296e-03, PNorm = 56.5261, GNorm = 2.0879, lr_0 = 1.0804e-04
Validation rmse logD = 0.671533
Validation R2 logD = 0.694280
Epoch 17
Train function
Loss = 3.6679e-03, PNorm = 56.5341, GNorm = 7.9808, lr_0 = 1.0804e-04
Loss = 3.8878e-03, PNorm = 56.5429, GNorm = 3.7353, lr_0 = 1.0804e-04
Loss = 3.5449e-03, PNorm = 56.5493, GNorm = 4.2001, lr_0 = 1.0804e-04
Loss = 4.3046e-03, PNorm = 56.5582, GNorm = 1.8163, lr_0 = 1.0804e-04
Loss = 4.5654e-03, PNorm = 56.5675, GNorm = 5.2135, lr_0 = 1.0804e-04
Validation rmse logD = 0.659139
Validation R2 logD = 0.705461
Epoch 18
Train function
Loss = 2.8803e-03, PNorm = 56.5771, GNorm = 3.8554, lr_0 = 1.0804e-04
Loss = 3.6721e-03, PNorm = 56.5856, GNorm = 3.5356, lr_0 = 1.0804e-04
Loss = 3.4762e-03, PNorm = 56.5948, GNorm = 9.2440, lr_0 = 1.0804e-04
Loss = 4.4931e-03, PNorm = 56.6019, GNorm = 4.5787, lr_0 = 1.0804e-04
Loss = 4.7401e-03, PNorm = 56.6087, GNorm = 1.8083, lr_0 = 1.0804e-04
Loss = 5.4508e-03, PNorm = 56.6159, GNorm = 3.8587, lr_0 = 1.0804e-04
Validation rmse logD = 0.659023
Validation R2 logD = 0.705565
Epoch 19
Train function
Loss = 4.4316e-03, PNorm = 56.6243, GNorm = 3.0274, lr_0 = 1.0804e-04
Loss = 3.1617e-03, PNorm = 56.6351, GNorm = 1.9649, lr_0 = 1.0804e-04
Loss = 3.6519e-03, PNorm = 56.6453, GNorm = 2.2647, lr_0 = 1.0804e-04
Loss = 3.8558e-03, PNorm = 56.6524, GNorm = 2.5393, lr_0 = 1.0804e-04
Loss = 4.0156e-03, PNorm = 56.6587, GNorm = 6.6073, lr_0 = 1.0804e-04
Loss = 3.2271e-03, PNorm = 56.6661, GNorm = 5.7859, lr_0 = 1.0804e-04
Validation rmse logD = 0.678822
Validation R2 logD = 0.687607
Epoch 20
Train function
Loss = 3.4944e-03, PNorm = 56.6737, GNorm = 1.7752, lr_0 = 1.0804e-04
Loss = 3.2599e-03, PNorm = 56.6821, GNorm = 3.5132, lr_0 = 1.0804e-04
Loss = 3.6803e-03, PNorm = 56.6906, GNorm = 2.4763, lr_0 = 1.0804e-04
Loss = 3.2039e-03, PNorm = 56.6992, GNorm = 3.2831, lr_0 = 1.0804e-04
Loss = 4.1164e-03, PNorm = 56.7053, GNorm = 6.2647, lr_0 = 1.0804e-04
Validation rmse logD = 0.653971
Validation R2 logD = 0.710061
Epoch 21
Train function
Loss = 2.6805e-03, PNorm = 56.7113, GNorm = 1.8185, lr_0 = 1.0804e-04
Loss = 3.4960e-03, PNorm = 56.7199, GNorm = 4.7210, lr_0 = 1.0804e-04
Loss = 3.1015e-03, PNorm = 56.7269, GNorm = 1.7139, lr_0 = 1.0804e-04
Loss = 3.5120e-03, PNorm = 56.7360, GNorm = 3.1103, lr_0 = 1.0804e-04
Loss = 3.7637e-03, PNorm = 56.7446, GNorm = 2.4769, lr_0 = 1.0804e-04
Loss = 3.4358e-03, PNorm = 56.7527, GNorm = 5.2144, lr_0 = 1.0804e-04
Validation rmse logD = 0.638427
Validation R2 logD = 0.723681
Epoch 22
Train function
Loss = 3.1796e-03, PNorm = 56.7592, GNorm = 2.4463, lr_0 = 1.0804e-04
Loss = 3.2504e-03, PNorm = 56.7680, GNorm = 5.5871, lr_0 = 1.0804e-04
Loss = 2.8415e-03, PNorm = 56.7738, GNorm = 5.9948, lr_0 = 1.0804e-04
Loss = 3.1047e-03, PNorm = 56.7821, GNorm = 5.3705, lr_0 = 1.0804e-04
Loss = 2.6200e-03, PNorm = 56.7880, GNorm = 3.5886, lr_0 = 1.0804e-04
Loss = 3.3469e-03, PNorm = 56.7936, GNorm = 2.4908, lr_0 = 1.0804e-04
Validation rmse logD = 0.636845
Validation R2 logD = 0.725049
Epoch 23
Train function
Loss = 2.6533e-03, PNorm = 56.8014, GNorm = 1.5195, lr_0 = 1.0804e-04
Loss = 2.3237e-03, PNorm = 56.8083, GNorm = 2.0992, lr_0 = 1.0804e-04
Loss = 3.0755e-03, PNorm = 56.8150, GNorm = 6.5767, lr_0 = 1.0804e-04
Loss = 2.9314e-03, PNorm = 56.8221, GNorm = 5.4629, lr_0 = 1.0804e-04
Loss = 2.4591e-03, PNorm = 56.8298, GNorm = 3.1452, lr_0 = 1.0804e-04
Validation rmse logD = 0.632907
Validation R2 logD = 0.728438
Epoch 24
Train function
Loss = 1.6516e-03, PNorm = 56.8390, GNorm = 3.5708, lr_0 = 1.0804e-04
Loss = 2.8344e-03, PNorm = 56.8448, GNorm = 4.0231, lr_0 = 1.0804e-04
Loss = 2.6022e-03, PNorm = 56.8518, GNorm = 1.7665, lr_0 = 1.0804e-04
Loss = 2.8024e-03, PNorm = 56.8588, GNorm = 1.8961, lr_0 = 1.0804e-04
Loss = 2.9234e-03, PNorm = 56.8652, GNorm = 1.3141, lr_0 = 1.0804e-04
Loss = 3.1409e-03, PNorm = 56.8717, GNorm = 5.1010, lr_0 = 1.0804e-04
Validation rmse logD = 0.623851
Validation R2 logD = 0.736154
Epoch 25
Train function
Loss = 2.3376e-03, PNorm = 56.8788, GNorm = 1.5193, lr_0 = 1.0804e-04
Loss = 2.0691e-03, PNorm = 56.8860, GNorm = 3.2378, lr_0 = 1.0804e-04
Loss = 2.7698e-03, PNorm = 56.8941, GNorm = 2.4451, lr_0 = 1.0804e-04
Loss = 3.1906e-03, PNorm = 56.9015, GNorm = 8.4381, lr_0 = 1.0804e-04
Loss = 2.7451e-03, PNorm = 56.9067, GNorm = 1.4622, lr_0 = 1.0804e-04
Loss = 2.6300e-03, PNorm = 56.9154, GNorm = 3.5268, lr_0 = 1.0804e-04
Validation rmse logD = 0.648922
Validation R2 logD = 0.714521
Epoch 26
Train function
Loss = 2.2489e-03, PNorm = 56.9232, GNorm = 4.6836, lr_0 = 1.0804e-04
Loss = 2.6663e-03, PNorm = 56.9288, GNorm = 8.2030, lr_0 = 1.0804e-04
Loss = 3.6785e-03, PNorm = 56.9354, GNorm = 10.4356, lr_0 = 1.0804e-04
Loss = 3.6566e-03, PNorm = 56.9440, GNorm = 9.0329, lr_0 = 1.0804e-04
Loss = 3.6544e-03, PNorm = 56.9520, GNorm = 6.7895, lr_0 = 1.0804e-04
Validation rmse logD = 0.647389
Validation R2 logD = 0.715868
Epoch 27
Train function
Loss = 2.6356e-03, PNorm = 56.9600, GNorm = 2.3411, lr_0 = 1.0804e-04
Loss = 2.3760e-03, PNorm = 56.9695, GNorm = 2.5448, lr_0 = 1.0804e-04
Loss = 2.3599e-03, PNorm = 56.9773, GNorm = 3.3132, lr_0 = 1.0804e-04
Loss = 2.4931e-03, PNorm = 56.9857, GNorm = 8.0421, lr_0 = 1.0804e-04
Loss = 2.3496e-03, PNorm = 56.9932, GNorm = 2.8285, lr_0 = 1.0804e-04
Loss = 2.5845e-03, PNorm = 56.9982, GNorm = 2.4722, lr_0 = 1.0804e-04
Validation rmse logD = 0.638809
Validation R2 logD = 0.723349
Epoch 28
Train function
Loss = 2.2125e-03, PNorm = 57.0047, GNorm = 3.3115, lr_0 = 1.0804e-04
Loss = 1.8072e-03, PNorm = 57.0120, GNorm = 1.7106, lr_0 = 1.0804e-04
Loss = 2.2688e-03, PNorm = 57.0175, GNorm = 4.6314, lr_0 = 1.0804e-04
Loss = 2.8409e-03, PNorm = 57.0228, GNorm = 8.5968, lr_0 = 1.0804e-04
Loss = 2.4027e-03, PNorm = 57.0276, GNorm = 7.3060, lr_0 = 1.0804e-04
Loss = 2.2918e-03, PNorm = 57.0350, GNorm = 1.6034, lr_0 = 1.0804e-04
Validation rmse logD = 0.638572
Validation R2 logD = 0.723555
Epoch 29
Train function
Loss = 1.7703e-03, PNorm = 57.0417, GNorm = 4.8505, lr_0 = 1.0804e-04
Loss = 2.4530e-03, PNorm = 57.0479, GNorm = 2.3755, lr_0 = 1.0804e-04
Loss = 2.3963e-03, PNorm = 57.0546, GNorm = 5.1906, lr_0 = 1.0804e-04
Loss = 2.0503e-03, PNorm = 57.0605, GNorm = 2.5082, lr_0 = 1.0804e-04
Loss = 1.8947e-03, PNorm = 57.0678, GNorm = 2.0353, lr_0 = 1.0804e-04
Validation rmse logD = 0.636301
Validation R2 logD = 0.725518
Epoch 30
Train function
Loss = 1.4772e-03, PNorm = 57.0767, GNorm = 2.4705, lr_0 = 1.0804e-04
Loss = 2.1557e-03, PNorm = 57.0833, GNorm = 2.2878, lr_0 = 1.0804e-04
Loss = 2.3110e-03, PNorm = 57.0903, GNorm = 2.8392, lr_0 = 1.0804e-04
Loss = 1.8706e-03, PNorm = 57.0971, GNorm = 1.6160, lr_0 = 1.0804e-04
Loss = 1.8727e-03, PNorm = 57.1017, GNorm = 4.4476, lr_0 = 1.0804e-04
Loss = 2.5455e-03, PNorm = 57.1068, GNorm = 6.7691, lr_0 = 1.0804e-04
Validation rmse logD = 0.713382
Validation R2 logD = 0.654989
Epoch 31
Train function
Loss = 2.7199e-03, PNorm = 57.1137, GNorm = 5.9990, lr_0 = 1.0804e-04
Loss = 1.7911e-03, PNorm = 57.1207, GNorm = 4.2923, lr_0 = 1.0804e-04
Loss = 2.3232e-03, PNorm = 57.1267, GNorm = 5.0115, lr_0 = 1.0804e-04
Loss = 1.9678e-03, PNorm = 57.1330, GNorm = 6.3877, lr_0 = 1.0804e-04
Loss = 1.9836e-03, PNorm = 57.1383, GNorm = 1.8398, lr_0 = 1.0804e-04
Loss = 1.8180e-03, PNorm = 57.1452, GNorm = 3.1887, lr_0 = 1.0804e-04
Validation rmse logD = 0.625126
Validation R2 logD = 0.735074
Epoch 32
Train function
Loss = 2.1643e-03, PNorm = 57.1526, GNorm = 1.4791, lr_0 = 1.0804e-04
Loss = 1.6788e-03, PNorm = 57.1579, GNorm = 5.3077, lr_0 = 1.0804e-04
Loss = 1.6532e-03, PNorm = 57.1635, GNorm = 2.0961, lr_0 = 1.0804e-04
Loss = 1.8429e-03, PNorm = 57.1687, GNorm = 3.6843, lr_0 = 1.0804e-04
Loss = 2.0292e-03, PNorm = 57.1731, GNorm = 2.6165, lr_0 = 1.0804e-04
Validation rmse logD = 0.612723
Validation R2 logD = 0.745482
Epoch 33
Train function
Loss = 1.9976e-03, PNorm = 57.1802, GNorm = 5.7036, lr_0 = 1.0804e-04
Loss = 1.9012e-03, PNorm = 57.1874, GNorm = 1.7654, lr_0 = 1.0804e-04
Loss = 1.6541e-03, PNorm = 57.1937, GNorm = 3.3011, lr_0 = 1.0804e-04
Loss = 2.0186e-03, PNorm = 57.2003, GNorm = 2.7798, lr_0 = 1.0804e-04
Loss = 1.6229e-03, PNorm = 57.2071, GNorm = 2.4870, lr_0 = 1.0804e-04
Loss = 2.1371e-03, PNorm = 57.2128, GNorm = 2.5479, lr_0 = 1.0804e-04
Validation rmse logD = 0.606965
Validation R2 logD = 0.750244
Epoch 34
Train function
Loss = 2.4451e-03, PNorm = 57.2183, GNorm = 2.7865, lr_0 = 1.0804e-04
Loss = 1.6226e-03, PNorm = 57.2225, GNorm = 1.5082, lr_0 = 1.0804e-04
Loss = 1.7128e-03, PNorm = 57.2285, GNorm = 1.6548, lr_0 = 1.0804e-04
Loss = 1.4355e-03, PNorm = 57.2358, GNorm = 1.8250, lr_0 = 1.0804e-04
Loss = 1.6513e-03, PNorm = 57.2405, GNorm = 3.5730, lr_0 = 1.0804e-04
Loss = 1.6456e-03, PNorm = 57.2460, GNorm = 4.0285, lr_0 = 1.0804e-04
Validation rmse logD = 0.604501
Validation R2 logD = 0.752267
Epoch 35
Train function
Loss = 1.6676e-03, PNorm = 57.2524, GNorm = 2.3137, lr_0 = 1.0804e-04
Loss = 1.4043e-03, PNorm = 57.2599, GNorm = 3.3308, lr_0 = 1.0804e-04
Loss = 1.8458e-03, PNorm = 57.2661, GNorm = 4.6807, lr_0 = 1.0804e-04
Loss = 1.9400e-03, PNorm = 57.2716, GNorm = 3.0577, lr_0 = 1.0804e-04
Loss = 1.8273e-03, PNorm = 57.2750, GNorm = 5.6343, lr_0 = 1.0804e-04
Validation rmse logD = 0.691537
Validation R2 logD = 0.675795
Epoch 36
Train function
Loss = 2.7501e-03, PNorm = 57.2816, GNorm = 9.3948, lr_0 = 1.0804e-04
Loss = 1.4483e-03, PNorm = 57.2879, GNorm = 1.6938, lr_0 = 1.0804e-04
Loss = 1.4005e-03, PNorm = 57.2951, GNorm = 1.5793, lr_0 = 1.0804e-04
Loss = 1.5950e-03, PNorm = 57.2995, GNorm = 2.4765, lr_0 = 1.0804e-04
Loss = 1.2499e-03, PNorm = 57.3043, GNorm = 2.3820, lr_0 = 1.0804e-04
Loss = 1.9499e-03, PNorm = 57.3109, GNorm = 1.6189, lr_0 = 1.0804e-04
Validation rmse logD = 0.616753
Validation R2 logD = 0.742124
Epoch 37
Train function
Loss = 1.4926e-03, PNorm = 57.3162, GNorm = 6.7315, lr_0 = 1.0804e-04
Loss = 1.8364e-03, PNorm = 57.3219, GNorm = 4.6053, lr_0 = 1.0804e-04
Loss = 1.7008e-03, PNorm = 57.3269, GNorm = 3.3561, lr_0 = 1.0804e-04
Loss = 1.7686e-03, PNorm = 57.3321, GNorm = 7.1910, lr_0 = 1.0804e-04
Loss = 1.5497e-03, PNorm = 57.3381, GNorm = 1.7611, lr_0 = 1.0804e-04
Loss = 1.4775e-03, PNorm = 57.3436, GNorm = 1.3169, lr_0 = 1.0804e-04
Validation rmse logD = 0.606599
Validation R2 logD = 0.750545
Epoch 38
Train function
Loss = 1.2386e-03, PNorm = 57.3485, GNorm = 3.6939, lr_0 = 1.0804e-04
Loss = 1.4895e-03, PNorm = 57.3546, GNorm = 4.4498, lr_0 = 1.0804e-04
Loss = 1.6234e-03, PNorm = 57.3590, GNorm = 8.3100, lr_0 = 1.0804e-04
Loss = 1.6622e-03, PNorm = 57.3648, GNorm = 1.8367, lr_0 = 1.0804e-04
Loss = 1.7081e-03, PNorm = 57.3706, GNorm = 1.7713, lr_0 = 1.0804e-04
Validation rmse logD = 0.616997
Validation R2 logD = 0.741919
Epoch 39
Train function
Loss = 3.1900e-03, PNorm = 57.3759, GNorm = 8.0812, lr_0 = 1.0804e-04
Loss = 1.5569e-03, PNorm = 57.3810, GNorm = 4.0671, lr_0 = 1.0804e-04
Loss = 1.3305e-03, PNorm = 57.3861, GNorm = 3.4593, lr_0 = 1.0804e-04
Loss = 1.5367e-03, PNorm = 57.3919, GNorm = 5.8058, lr_0 = 1.0804e-04
Loss = 1.2795e-03, PNorm = 57.3984, GNorm = 4.6912, lr_0 = 1.0804e-04
Loss = 1.4207e-03, PNorm = 57.4043, GNorm = 2.2953, lr_0 = 1.0804e-04
Validation rmse logD = 0.626987
Validation R2 logD = 0.733494
Epoch 40
Train function
Loss = 1.5905e-03, PNorm = 57.4094, GNorm = 2.7589, lr_0 = 1.0804e-04
Loss = 1.7216e-03, PNorm = 57.4147, GNorm = 3.2457, lr_0 = 1.0804e-04
Loss = 1.7901e-03, PNorm = 57.4212, GNorm = 4.5659, lr_0 = 1.0804e-04
Loss = 1.5278e-03, PNorm = 57.4283, GNorm = 5.2882, lr_0 = 1.0804e-04
Loss = 1.3109e-03, PNorm = 57.4334, GNorm = 3.8717, lr_0 = 1.0804e-04
Loss = 1.6357e-03, PNorm = 57.4385, GNorm = 6.5730, lr_0 = 1.0804e-04
Validation rmse logD = 0.597920
Validation R2 logD = 0.757632
Epoch 41
Train function
Loss = 1.4353e-03, PNorm = 57.4454, GNorm = 1.4800, lr_0 = 1.0804e-04
Loss = 1.0552e-03, PNorm = 57.4507, GNorm = 2.3314, lr_0 = 1.0804e-04
Loss = 1.0918e-03, PNorm = 57.4558, GNorm = 1.4404, lr_0 = 1.0804e-04
Loss = 1.1452e-03, PNorm = 57.4613, GNorm = 2.5900, lr_0 = 1.0804e-04
Loss = 1.7896e-03, PNorm = 57.4644, GNorm = 7.5421, lr_0 = 1.0804e-04
Validation rmse logD = 0.588630
Validation R2 logD = 0.765105
Epoch 42
Train function
Loss = 1.5316e-03, PNorm = 57.4699, GNorm = 3.7218, lr_0 = 1.0804e-04
Loss = 1.3341e-03, PNorm = 57.4770, GNorm = 2.2820, lr_0 = 1.0804e-04
Loss = 1.0956e-03, PNorm = 57.4827, GNorm = 2.0647, lr_0 = 1.0804e-04
Loss = 1.1461e-03, PNorm = 57.4871, GNorm = 3.8746, lr_0 = 1.0804e-04
Loss = 1.5129e-03, PNorm = 57.4913, GNorm = 4.0355, lr_0 = 1.0804e-04
Loss = 1.4693e-03, PNorm = 57.4957, GNorm = 4.4771, lr_0 = 1.0804e-04
Validation rmse logD = 0.583215
Validation R2 logD = 0.769407
Epoch 43
Train function
Loss = 1.2849e-03, PNorm = 57.5009, GNorm = 2.4474, lr_0 = 1.0804e-04
Loss = 9.8774e-04, PNorm = 57.5066, GNorm = 2.0866, lr_0 = 1.0804e-04
Loss = 1.1772e-03, PNorm = 57.5123, GNorm = 2.4823, lr_0 = 1.0804e-04
Loss = 1.6254e-03, PNorm = 57.5172, GNorm = 5.0616, lr_0 = 1.0804e-04
Loss = 1.8864e-03, PNorm = 57.5207, GNorm = 10.5983, lr_0 = 1.0804e-04
Loss = 1.6133e-03, PNorm = 57.5267, GNorm = 1.2246, lr_0 = 1.0804e-04
Validation rmse logD = 0.708894
Validation R2 logD = 0.659316
Epoch 44
Train function
Loss = 1.9100e-03, PNorm = 57.5326, GNorm = 6.6153, lr_0 = 1.0804e-04
Loss = 1.3542e-03, PNorm = 57.5383, GNorm = 1.4445, lr_0 = 1.0804e-04
Loss = 1.4231e-03, PNorm = 57.5436, GNorm = 3.8081, lr_0 = 1.0804e-04
Loss = 1.2247e-03, PNorm = 57.5469, GNorm = 3.9806, lr_0 = 1.0804e-04
Loss = 1.5183e-03, PNorm = 57.5521, GNorm = 2.4299, lr_0 = 1.0804e-04
Validation rmse logD = 0.610097
Validation R2 logD = 0.747659
Epoch 45
Train function
Loss = 1.0478e-03, PNorm = 57.5588, GNorm = 1.9494, lr_0 = 1.0804e-04
Loss = 1.0519e-03, PNorm = 57.5642, GNorm = 3.0100, lr_0 = 1.0804e-04
Loss = 1.1644e-03, PNorm = 57.5688, GNorm = 8.0758, lr_0 = 1.0804e-04
Loss = 1.1746e-03, PNorm = 57.5731, GNorm = 4.0567, lr_0 = 1.0804e-04
Loss = 1.1854e-03, PNorm = 57.5781, GNorm = 1.3345, lr_0 = 1.0804e-04
Loss = 1.2871e-03, PNorm = 57.5829, GNorm = 1.4229, lr_0 = 1.0804e-04
Validation rmse logD = 0.594034
Validation R2 logD = 0.760773
Epoch 46
Train function
Loss = 1.1352e-03, PNorm = 57.5873, GNorm = 1.9440, lr_0 = 1.0804e-04
Loss = 9.8779e-04, PNorm = 57.5913, GNorm = 1.3864, lr_0 = 1.0804e-04
Loss = 1.0303e-03, PNorm = 57.5955, GNorm = 3.6810, lr_0 = 1.0804e-04
Loss = 1.3118e-03, PNorm = 57.5996, GNorm = 3.2213, lr_0 = 1.0804e-04
Loss = 1.2950e-03, PNorm = 57.6052, GNorm = 3.3091, lr_0 = 1.0804e-04
Loss = 1.1145e-03, PNorm = 57.6106, GNorm = 1.8750, lr_0 = 1.0804e-04
Validation rmse logD = 0.591899
Validation R2 logD = 0.762488
Epoch 47
Train function
Loss = 8.7027e-04, PNorm = 57.6162, GNorm = 5.3474, lr_0 = 1.0804e-04
Loss = 9.6923e-04, PNorm = 57.6206, GNorm = 3.0714, lr_0 = 1.0804e-04
Loss = 9.3795e-04, PNorm = 57.6258, GNorm = 2.5494, lr_0 = 1.0804e-04
Loss = 1.1812e-03, PNorm = 57.6301, GNorm = 1.9317, lr_0 = 1.0804e-04
Loss = 1.2229e-03, PNorm = 57.6344, GNorm = 1.8316, lr_0 = 1.0804e-04
Validation rmse logD = 0.588003
Validation R2 logD = 0.765605
Epoch 48
Train function
Loss = 7.5231e-04, PNorm = 57.6370, GNorm = 1.5445, lr_0 = 1.0804e-04
Loss = 9.0321e-04, PNorm = 57.6425, GNorm = 3.5802, lr_0 = 1.0804e-04
Loss = 8.5412e-04, PNorm = 57.6478, GNorm = 1.3342, lr_0 = 1.0804e-04
Loss = 9.8107e-04, PNorm = 57.6517, GNorm = 1.2864, lr_0 = 1.0804e-04
Loss = 1.3880e-03, PNorm = 57.6549, GNorm = 1.9340, lr_0 = 1.0804e-04
Loss = 1.0540e-03, PNorm = 57.6604, GNorm = 3.7954, lr_0 = 1.0804e-04
Validation rmse logD = 0.669493
Validation R2 logD = 0.696134
Epoch 49
Train function
Loss = 1.1978e-03, PNorm = 57.6656, GNorm = 3.9356, lr_0 = 1.0804e-04
Loss = 1.0322e-03, PNorm = 57.6703, GNorm = 3.0418, lr_0 = 1.0804e-04
Loss = 8.9542e-04, PNorm = 57.6744, GNorm = 4.2408, lr_0 = 1.0804e-04
Loss = 1.0836e-03, PNorm = 57.6787, GNorm = 2.4883, lr_0 = 1.0804e-04
Loss = 9.9787e-04, PNorm = 57.6827, GNorm = 1.8422, lr_0 = 1.0804e-04
Loss = 9.8344e-04, PNorm = 57.6871, GNorm = 4.6870, lr_0 = 1.0804e-04
Validation rmse logD = 0.585342
Validation R2 logD = 0.767722
Epoch 50
Train function
Loss = 9.5456e-04, PNorm = 57.6912, GNorm = 3.2251, lr_0 = 1.0804e-04
Loss = 9.4843e-04, PNorm = 57.6959, GNorm = 1.2483, lr_0 = 1.0804e-04
Loss = 1.0143e-03, PNorm = 57.7001, GNorm = 1.3849, lr_0 = 1.0804e-04
Loss = 8.0935e-04, PNorm = 57.7051, GNorm = 1.0206, lr_0 = 1.0804e-04
Loss = 9.3207e-04, PNorm = 57.7091, GNorm = 2.0257, lr_0 = 1.0804e-04
Validation rmse logD = 0.574063
Validation R2 logD = 0.776587
Epoch 51
Train function
Loss = 8.6096e-04, PNorm = 57.7132, GNorm = 3.2647, lr_0 = 1.0804e-04
Loss = 7.5085e-04, PNorm = 57.7168, GNorm = 1.5380, lr_0 = 1.0804e-04
Loss = 7.7356e-04, PNorm = 57.7207, GNorm = 1.0701, lr_0 = 1.0804e-04
Loss = 1.3498e-03, PNorm = 57.7245, GNorm = 3.6106, lr_0 = 1.0804e-04
Loss = 1.2122e-03, PNorm = 57.7292, GNorm = 1.8635, lr_0 = 1.0804e-04
Loss = 1.2461e-03, PNorm = 57.7339, GNorm = 7.3400, lr_0 = 1.0804e-04
Validation rmse logD = 0.630622
Validation R2 logD = 0.730396
Epoch 52
Train function
Loss = 9.2277e-04, PNorm = 57.7387, GNorm = 4.4010, lr_0 = 1.0804e-04
Loss = 9.2543e-04, PNorm = 57.7430, GNorm = 1.5244, lr_0 = 1.0804e-04
Loss = 9.3127e-04, PNorm = 57.7480, GNorm = 3.0781, lr_0 = 1.0804e-04
Loss = 1.0160e-03, PNorm = 57.7527, GNorm = 3.7703, lr_0 = 1.0804e-04
Loss = 1.0968e-03, PNorm = 57.7569, GNorm = 1.7441, lr_0 = 1.0804e-04
Loss = 1.1538e-03, PNorm = 57.7614, GNorm = 7.2555, lr_0 = 1.0804e-04
Validation rmse logD = 0.581643
Validation R2 logD = 0.770648
Epoch 53
Train function
Loss = 8.3579e-04, PNorm = 57.7665, GNorm = 2.5782, lr_0 = 1.0804e-04
Loss = 7.4358e-04, PNorm = 57.7703, GNorm = 2.2426, lr_0 = 1.0804e-04
Loss = 7.7233e-04, PNorm = 57.7741, GNorm = 1.4433, lr_0 = 1.0804e-04
Loss = 8.0048e-04, PNorm = 57.7794, GNorm = 1.2296, lr_0 = 1.0804e-04
Loss = 8.4289e-04, PNorm = 57.7840, GNorm = 2.1136, lr_0 = 1.0804e-04
Validation rmse logD = 0.599968
Validation R2 logD = 0.755969
Epoch 54
Train function
Loss = 9.5364e-04, PNorm = 57.7886, GNorm = 3.4911, lr_0 = 1.0804e-04
Loss = 7.5888e-04, PNorm = 57.7933, GNorm = 3.9526, lr_0 = 1.0804e-04
Loss = 6.9634e-04, PNorm = 57.7969, GNorm = 2.0058, lr_0 = 1.0804e-04
Loss = 6.7825e-04, PNorm = 57.8001, GNorm = 0.7700, lr_0 = 1.0804e-04
Loss = 8.0341e-04, PNorm = 57.8044, GNorm = 1.5638, lr_0 = 1.0804e-04
Loss = 7.2720e-04, PNorm = 57.8085, GNorm = 1.7516, lr_0 = 1.0804e-04
Validation rmse logD = 0.585703
Validation R2 logD = 0.767436
Epoch 55
Train function
Loss = 8.3618e-04, PNorm = 57.8127, GNorm = 1.1292, lr_0 = 1.0804e-04
Loss = 9.8622e-04, PNorm = 57.8173, GNorm = 3.4661, lr_0 = 1.0804e-04
Loss = 8.9055e-04, PNorm = 57.8207, GNorm = 2.0834, lr_0 = 1.0804e-04
Loss = 8.8567e-04, PNorm = 57.8232, GNorm = 3.5697, lr_0 = 1.0804e-04
Loss = 1.0313e-03, PNorm = 57.8279, GNorm = 2.4789, lr_0 = 1.0804e-04
Loss = 7.9828e-04, PNorm = 57.8332, GNorm = 1.9213, lr_0 = 1.0804e-04
Validation rmse logD = 0.568724
Validation R2 logD = 0.780724
Epoch 56
Train function
Loss = 7.4991e-04, PNorm = 57.8374, GNorm = 1.2093, lr_0 = 1.0804e-04
Loss = 6.9764e-04, PNorm = 57.8396, GNorm = 4.1152, lr_0 = 1.0804e-04
Loss = 1.2227e-03, PNorm = 57.8437, GNorm = 1.3801, lr_0 = 1.0804e-04
Loss = 9.4520e-04, PNorm = 57.8490, GNorm = 2.2049, lr_0 = 1.0804e-04
Loss = 1.1147e-03, PNorm = 57.8521, GNorm = 1.5439, lr_0 = 1.0804e-04
Validation rmse logD = 0.582774
Validation R2 logD = 0.769755
Epoch 57
Train function
Loss = 6.3510e-04, PNorm = 57.8575, GNorm = 1.5006, lr_0 = 1.0804e-04
Loss = 6.6584e-04, PNorm = 57.8624, GNorm = 1.0153, lr_0 = 1.0804e-04
Loss = 6.3049e-04, PNorm = 57.8669, GNorm = 1.3166, lr_0 = 1.0804e-04
Loss = 7.3855e-04, PNorm = 57.8700, GNorm = 1.5329, lr_0 = 1.0804e-04
Loss = 7.3744e-04, PNorm = 57.8742, GNorm = 2.3745, lr_0 = 1.0804e-04
Loss = 5.8985e-04, PNorm = 57.8784, GNorm = 3.2326, lr_0 = 1.0804e-04
Validation rmse logD = 0.581557
Validation R2 logD = 0.770716
Epoch 58
Train function
Loss = 6.1434e-04, PNorm = 57.8811, GNorm = 5.3934, lr_0 = 1.0804e-04
Loss = 9.6557e-04, PNorm = 57.8837, GNorm = 7.4550, lr_0 = 1.0804e-04
Loss = 9.9483e-04, PNorm = 57.8876, GNorm = 2.4984, lr_0 = 1.0804e-04
Loss = 6.3538e-04, PNorm = 57.8917, GNorm = 1.7145, lr_0 = 1.0804e-04
Loss = 7.5831e-04, PNorm = 57.8962, GNorm = 1.2493, lr_0 = 1.0804e-04
Loss = 6.4528e-04, PNorm = 57.8997, GNorm = 2.4937, lr_0 = 1.0804e-04
Validation rmse logD = 0.576111
Validation R2 logD = 0.774990
Epoch 59
Train function
Loss = 6.0246e-04, PNorm = 57.9029, GNorm = 2.2305, lr_0 = 1.0804e-04
Loss = 7.5518e-04, PNorm = 57.9072, GNorm = 3.4335, lr_0 = 1.0804e-04
Loss = 9.0054e-04, PNorm = 57.9121, GNorm = 2.6033, lr_0 = 1.0804e-04
Loss = 5.2738e-04, PNorm = 57.9164, GNorm = 2.0456, lr_0 = 1.0804e-04
Loss = 6.9498e-04, PNorm = 57.9201, GNorm = 1.4959, lr_0 = 1.0804e-04
Validation rmse logD = 0.591114
Validation R2 logD = 0.763118
Epoch 60
Train function
Loss = 7.9674e-04, PNorm = 57.9233, GNorm = 1.3060, lr_0 = 1.0804e-04
Loss = 5.3821e-04, PNorm = 57.9270, GNorm = 1.9005, lr_0 = 1.0804e-04
Loss = 6.5102e-04, PNorm = 57.9295, GNorm = 0.9749, lr_0 = 1.0804e-04
Loss = 1.0161e-03, PNorm = 57.9328, GNorm = 7.0734, lr_0 = 1.0804e-04
Loss = 6.7109e-04, PNorm = 57.9371, GNorm = 4.9903, lr_0 = 1.0804e-04
Loss = 8.6373e-04, PNorm = 57.9414, GNorm = 2.0250, lr_0 = 1.0804e-04
Validation rmse logD = 0.580383
Validation R2 logD = 0.771641
Epoch 61
Train function
Loss = 7.8972e-04, PNorm = 57.9450, GNorm = 4.1461, lr_0 = 1.0804e-04
Loss = 7.9842e-04, PNorm = 57.9504, GNorm = 4.1729, lr_0 = 1.0804e-04
Loss = 9.3952e-04, PNorm = 57.9539, GNorm = 1.8816, lr_0 = 1.0804e-04
Loss = 7.6608e-04, PNorm = 57.9591, GNorm = 3.2640, lr_0 = 1.0804e-04
Loss = 7.9331e-04, PNorm = 57.9640, GNorm = 2.7294, lr_0 = 1.0804e-04
Loss = 6.6006e-04, PNorm = 57.9673, GNorm = 3.0548, lr_0 = 1.0804e-04
Validation rmse logD = 0.585652
Validation R2 logD = 0.767476
Epoch 62
Train function
Loss = 6.0765e-04, PNorm = 57.9724, GNorm = 0.9278, lr_0 = 1.0804e-04
Loss = 5.6793e-04, PNorm = 57.9752, GNorm = 1.3187, lr_0 = 1.0804e-04
Loss = 6.0677e-04, PNorm = 57.9796, GNorm = 1.8350, lr_0 = 1.0804e-04
Loss = 8.0431e-04, PNorm = 57.9798, GNorm = 3.1742, lr_0 = 1.0804e-04
Loss = 6.3061e-04, PNorm = 57.9839, GNorm = 2.8687, lr_0 = 1.0804e-04
Validation rmse logD = 0.590729
Validation R2 logD = 0.763426
Epoch 63
Train function
Loss = 4.7781e-04, PNorm = 57.9878, GNorm = 1.0315, lr_0 = 1.0804e-04
Loss = 4.7944e-04, PNorm = 57.9914, GNorm = 0.9296, lr_0 = 1.0804e-04
Loss = 6.5289e-04, PNorm = 57.9929, GNorm = 4.6772, lr_0 = 1.0804e-04
Loss = 5.7506e-04, PNorm = 57.9961, GNorm = 1.3422, lr_0 = 1.0804e-04
Loss = 7.6165e-04, PNorm = 57.9996, GNorm = 2.9567, lr_0 = 1.0804e-04
Loss = 7.3259e-04, PNorm = 58.0022, GNorm = 2.0475, lr_0 = 1.0804e-04
Validation rmse logD = 0.589832
Validation R2 logD = 0.764145
Epoch 64
Train function
Loss = 1.0394e-03, PNorm = 58.0056, GNorm = 3.3723, lr_0 = 1.0804e-04
Loss = 5.2018e-04, PNorm = 58.0104, GNorm = 2.5661, lr_0 = 1.0804e-04
Loss = 5.1646e-04, PNorm = 58.0131, GNorm = 0.8427, lr_0 = 1.0804e-04
Loss = 5.4313e-04, PNorm = 58.0169, GNorm = 3.2927, lr_0 = 1.0804e-04
Loss = 7.2023e-04, PNorm = 58.0192, GNorm = 3.5390, lr_0 = 1.0804e-04
Loss = 8.7849e-04, PNorm = 58.0233, GNorm = 2.0188, lr_0 = 1.0804e-04
Validation rmse logD = 0.570766
Validation R2 logD = 0.779146
Epoch 65
Train function
Loss = 5.4699e-04, PNorm = 58.0274, GNorm = 1.4368, lr_0 = 1.0804e-04
Loss = 6.8113e-04, PNorm = 58.0317, GNorm = 3.6771, lr_0 = 1.0804e-04
Loss = 5.9919e-04, PNorm = 58.0347, GNorm = 1.5296, lr_0 = 1.0804e-04
Loss = 7.8407e-04, PNorm = 58.0385, GNorm = 1.4983, lr_0 = 1.0804e-04
Loss = 7.4544e-04, PNorm = 58.0436, GNorm = 3.6106, lr_0 = 1.0804e-04
Validation rmse logD = 0.592384
Validation R2 logD = 0.762099
Epoch 66
Train function
Loss = 3.5597e-04, PNorm = 58.0485, GNorm = 0.9814, lr_0 = 1.0804e-04
Loss = 5.4497e-04, PNorm = 58.0510, GNorm = 4.2686, lr_0 = 1.0804e-04
Loss = 7.3792e-04, PNorm = 58.0533, GNorm = 4.1355, lr_0 = 1.0804e-04
Loss = 5.3638e-04, PNorm = 58.0581, GNorm = 0.8064, lr_0 = 1.0804e-04
Loss = 8.6436e-04, PNorm = 58.0623, GNorm = 1.0459, lr_0 = 1.0804e-04
Loss = 6.0230e-04, PNorm = 58.0659, GNorm = 0.8180, lr_0 = 1.0804e-04
Validation rmse logD = 0.605568
Validation R2 logD = 0.751392
Epoch 67
Train function
Loss = 4.7735e-04, PNorm = 58.0694, GNorm = 0.8297, lr_0 = 1.0804e-04
Loss = 6.3750e-04, PNorm = 58.0728, GNorm = 4.1836, lr_0 = 1.0804e-04
Loss = 5.8763e-04, PNorm = 58.0760, GNorm = 3.7435, lr_0 = 1.0804e-04
Loss = 6.7838e-04, PNorm = 58.0790, GNorm = 2.5879, lr_0 = 1.0804e-04
Loss = 5.4401e-04, PNorm = 58.0819, GNorm = 2.7973, lr_0 = 1.0804e-04
Loss = 9.2186e-04, PNorm = 58.0844, GNorm = 5.5984, lr_0 = 1.0804e-04
Validation rmse logD = 0.567086
Validation R2 logD = 0.781984
Epoch 68
Train function
Loss = 8.2949e-04, PNorm = 58.0896, GNorm = 0.8914, lr_0 = 1.0804e-04
Loss = 5.2585e-04, PNorm = 58.0942, GNorm = 1.8178, lr_0 = 1.0804e-04
Loss = 5.2552e-04, PNorm = 58.0967, GNorm = 1.4584, lr_0 = 1.0804e-04
Loss = 4.8543e-04, PNorm = 58.1007, GNorm = 1.1315, lr_0 = 1.0804e-04
Loss = 7.3764e-04, PNorm = 58.1030, GNorm = 1.3665, lr_0 = 1.0804e-04
Validation rmse logD = 0.571464
Validation R2 logD = 0.778605
Epoch 69
Train function
Loss = 5.5937e-04, PNorm = 58.1063, GNorm = 1.6854, lr_0 = 1.0804e-04
Loss = 5.3445e-04, PNorm = 58.1100, GNorm = 1.3863, lr_0 = 1.0804e-04
Loss = 6.4299e-04, PNorm = 58.1128, GNorm = 2.4028, lr_0 = 1.0804e-04
Loss = 4.6395e-04, PNorm = 58.1174, GNorm = 1.0508, lr_0 = 1.0804e-04
Loss = 4.2285e-04, PNorm = 58.1209, GNorm = 1.4347, lr_0 = 1.0804e-04
Loss = 5.6232e-04, PNorm = 58.1228, GNorm = 5.7275, lr_0 = 1.0804e-04
Validation rmse logD = 0.578361
Validation R2 logD = 0.773229
Epoch 70
Train function
Loss = 6.0270e-04, PNorm = 58.1260, GNorm = 4.3438, lr_0 = 1.0804e-04
Loss = 6.8771e-04, PNorm = 58.1291, GNorm = 1.7917, lr_0 = 1.0804e-04
Loss = 7.3386e-04, PNorm = 58.1313, GNorm = 3.0015, lr_0 = 1.0804e-04
Loss = 8.5072e-04, PNorm = 58.1361, GNorm = 4.4648, lr_0 = 1.0804e-04
Loss = 7.6884e-04, PNorm = 58.1400, GNorm = 5.8656, lr_0 = 1.0804e-04
Loss = 1.0795e-03, PNorm = 58.1428, GNorm = 4.8203, lr_0 = 1.0804e-04
Validation rmse logD = 0.581909
Validation R2 logD = 0.770439
Epoch 71
Train function
Loss = 5.7188e-04, PNorm = 58.1478, GNorm = 2.1433, lr_0 = 1.0804e-04
Loss = 5.8100e-04, PNorm = 58.1531, GNorm = 2.0918, lr_0 = 1.0804e-04
Loss = 4.3982e-04, PNorm = 58.1577, GNorm = 2.8455, lr_0 = 1.0804e-04
Loss = 7.0674e-04, PNorm = 58.1607, GNorm = 1.1063, lr_0 = 1.0804e-04
Loss = 6.7166e-04, PNorm = 58.1639, GNorm = 4.0003, lr_0 = 1.0804e-04
Validation rmse logD = 0.574134
Validation R2 logD = 0.776532
Epoch 72
Train function
Loss = 3.3308e-04, PNorm = 58.1684, GNorm = 0.7231, lr_0 = 1.0804e-04
Loss = 4.3853e-04, PNorm = 58.1710, GNorm = 1.6965, lr_0 = 1.0804e-04
Loss = 6.0024e-04, PNorm = 58.1737, GNorm = 2.5420, lr_0 = 1.0804e-04
Loss = 4.7096e-04, PNorm = 58.1763, GNorm = 1.6926, lr_0 = 1.0804e-04
Loss = 3.8363e-04, PNorm = 58.1793, GNorm = 0.8611, lr_0 = 1.0804e-04
Loss = 5.8169e-04, PNorm = 58.1825, GNorm = 3.6417, lr_0 = 1.0804e-04
Validation rmse logD = 0.567312
Validation R2 logD = 0.781811
Epoch 73
Train function
Loss = 4.3811e-04, PNorm = 58.1853, GNorm = 1.2256, lr_0 = 1.0804e-04
Loss = 4.0743e-04, PNorm = 58.1875, GNorm = 1.2731, lr_0 = 1.0804e-04
Loss = 6.3566e-04, PNorm = 58.1907, GNorm = 1.5310, lr_0 = 1.0804e-04
Loss = 5.7048e-04, PNorm = 58.1938, GNorm = 2.3626, lr_0 = 1.0804e-04
Loss = 4.8034e-04, PNorm = 58.1981, GNorm = 3.6248, lr_0 = 1.0804e-04
Loss = 4.6887e-04, PNorm = 58.2008, GNorm = 2.0174, lr_0 = 1.0804e-04
Validation rmse logD = 0.583640
Validation R2 logD = 0.769070
Epoch 74
Train function
Loss = 5.1126e-04, PNorm = 58.2036, GNorm = 2.0718, lr_0 = 1.0804e-04
Loss = 4.4279e-04, PNorm = 58.2049, GNorm = 1.7855, lr_0 = 1.0804e-04
Loss = 4.9900e-04, PNorm = 58.2084, GNorm = 2.7486, lr_0 = 1.0804e-04
Loss = 6.6950e-04, PNorm = 58.2118, GNorm = 5.7070, lr_0 = 1.0804e-04
Loss = 9.5891e-04, PNorm = 58.2138, GNorm = 1.6958, lr_0 = 1.0804e-04
Validation rmse logD = 0.582128
Validation R2 logD = 0.770266
Epoch 75
Train function
Loss = 1.2328e-03, PNorm = 58.2186, GNorm = 6.7587, lr_0 = 1.0804e-04
Loss = 6.2234e-04, PNorm = 58.2251, GNorm = 2.3342, lr_0 = 1.0804e-04
Loss = 7.1257e-04, PNorm = 58.2276, GNorm = 4.3760, lr_0 = 1.0804e-04
Loss = 7.9812e-04, PNorm = 58.2310, GNorm = 4.0229, lr_0 = 1.0804e-04
Loss = 6.2028e-04, PNorm = 58.2348, GNorm = 6.0861, lr_0 = 1.0804e-04
Loss = 6.9005e-04, PNorm = 58.2391, GNorm = 3.8228, lr_0 = 1.0804e-04
Validation rmse logD = 0.575782
Validation R2 logD = 0.775247
Epoch 76
Train function
Loss = 3.2594e-04, PNorm = 58.2426, GNorm = 1.8531, lr_0 = 1.0804e-04
Loss = 3.3879e-04, PNorm = 58.2459, GNorm = 0.7182, lr_0 = 1.0804e-04
Loss = 3.6833e-04, PNorm = 58.2488, GNorm = 2.6431, lr_0 = 1.0804e-04
Loss = 5.7026e-04, PNorm = 58.2507, GNorm = 1.4487, lr_0 = 1.0804e-04
Loss = 6.0084e-04, PNorm = 58.2536, GNorm = 1.8795, lr_0 = 1.0804e-04
Loss = 5.4040e-04, PNorm = 58.2567, GNorm = 1.5927, lr_0 = 1.0804e-04
Validation rmse logD = 0.587009
Validation R2 logD = 0.766397
Epoch 77
Train function
Loss = 3.6130e-04, PNorm = 58.2594, GNorm = 2.8678, lr_0 = 1.0804e-04
Loss = 2.9055e-04, PNorm = 58.2621, GNorm = 1.1623, lr_0 = 1.0804e-04
Loss = 4.3552e-04, PNorm = 58.2639, GNorm = 0.8861, lr_0 = 1.0804e-04
Loss = 6.1425e-04, PNorm = 58.2681, GNorm = 2.1331, lr_0 = 1.0804e-04
Loss = 4.4671e-04, PNorm = 58.2717, GNorm = 3.6317, lr_0 = 1.0804e-04
Validation rmse logD = 0.586469
Validation R2 logD = 0.766827
Epoch 78
Train function
Loss = 4.5575e-04, PNorm = 58.2749, GNorm = 3.3663, lr_0 = 1.0804e-04
Loss = 3.8719e-04, PNorm = 58.2761, GNorm = 0.9714, lr_0 = 1.0804e-04
Loss = 3.7353e-04, PNorm = 58.2792, GNorm = 2.7262, lr_0 = 1.0804e-04
Loss = 3.6127e-04, PNorm = 58.2823, GNorm = 1.4945, lr_0 = 1.0804e-04
Loss = 4.9552e-04, PNorm = 58.2844, GNorm = 3.4541, lr_0 = 1.0804e-04
Loss = 4.7699e-04, PNorm = 58.2863, GNorm = 3.2208, lr_0 = 1.0804e-04
Validation rmse logD = 0.579300
Validation R2 logD = 0.772493
Epoch 79
Train function
Loss = 6.8932e-04, PNorm = 58.2899, GNorm = 3.2145, lr_0 = 1.0804e-04
Loss = 7.9170e-04, PNorm = 58.2919, GNorm = 5.4469, lr_0 = 1.0804e-04
Loss = 6.2909e-04, PNorm = 58.2961, GNorm = 3.1294, lr_0 = 1.0804e-04
Loss = 5.6107e-04, PNorm = 58.3004, GNorm = 2.0477, lr_0 = 1.0804e-04
Loss = 8.5143e-04, PNorm = 58.3044, GNorm = 6.8830, lr_0 = 1.0804e-04
Loss = 7.4234e-04, PNorm = 58.3093, GNorm = 3.2468, lr_0 = 1.0804e-04
Validation rmse logD = 0.572493
Validation R2 logD = 0.777807
Epoch 80
Train function
Loss = 5.0995e-04, PNorm = 58.3154, GNorm = 3.6562, lr_0 = 1.0804e-04
Loss = 3.8287e-04, PNorm = 58.3192, GNorm = 0.8723, lr_0 = 1.0804e-04
Loss = 3.8081e-04, PNorm = 58.3223, GNorm = 1.3902, lr_0 = 1.0804e-04
Loss = 3.4591e-04, PNorm = 58.3240, GNorm = 0.8872, lr_0 = 1.0804e-04
Loss = 4.1528e-04, PNorm = 58.3270, GNorm = 3.5392, lr_0 = 1.0804e-04
Validation rmse logD = 0.571187
Validation R2 logD = 0.778820
Epoch 81
Train function
Loss = 1.8307e-04, PNorm = 58.3295, GNorm = 1.7739, lr_0 = 1.0804e-04
Loss = 4.3137e-04, PNorm = 58.3310, GNorm = 2.2747, lr_0 = 1.0804e-04
Loss = 2.8816e-04, PNorm = 58.3336, GNorm = 1.0922, lr_0 = 1.0804e-04
Loss = 3.5356e-04, PNorm = 58.3358, GNorm = 1.1889, lr_0 = 1.0804e-04
Loss = 3.5910e-04, PNorm = 58.3386, GNorm = 1.6434, lr_0 = 1.0804e-04
Loss = 4.1726e-04, PNorm = 58.3412, GNorm = 3.2451, lr_0 = 1.0804e-04
Validation rmse logD = 0.576740
Validation R2 logD = 0.774498
Epoch 82
Train function
Loss = 4.4967e-04, PNorm = 58.3438, GNorm = 1.0608, lr_0 = 1.0804e-04
Loss = 4.1807e-04, PNorm = 58.3472, GNorm = 2.6493, lr_0 = 1.0804e-04
Loss = 5.8297e-04, PNorm = 58.3499, GNorm = 6.3269, lr_0 = 1.0804e-04
Loss = 5.6740e-04, PNorm = 58.3536, GNorm = 1.3100, lr_0 = 1.0804e-04
Loss = 5.6796e-04, PNorm = 58.3565, GNorm = 2.7671, lr_0 = 1.0804e-04
Loss = 5.6988e-04, PNorm = 58.3603, GNorm = 3.4827, lr_0 = 1.0804e-04
Validation rmse logD = 0.573722
Validation R2 logD = 0.776853
Epoch 83
Train function
Loss = 5.0262e-04, PNorm = 58.3647, GNorm = 1.5631, lr_0 = 1.0804e-04
Loss = 3.4630e-04, PNorm = 58.3680, GNorm = 3.7713, lr_0 = 1.0804e-04
Loss = 3.7609e-04, PNorm = 58.3709, GNorm = 2.3824, lr_0 = 1.0804e-04
Loss = 4.1439e-04, PNorm = 58.3731, GNorm = 0.8911, lr_0 = 1.0804e-04
Loss = 3.3711e-04, PNorm = 58.3755, GNorm = 0.7910, lr_0 = 1.0804e-04
Validation rmse logD = 0.568328
Validation R2 logD = 0.781029
Epoch 84
Train function
Loss = 2.0039e-04, PNorm = 58.3778, GNorm = 0.6843, lr_0 = 1.0804e-04
Loss = 4.2526e-04, PNorm = 58.3803, GNorm = 3.2644, lr_0 = 1.0804e-04
Loss = 3.9719e-04, PNorm = 58.3823, GNorm = 3.2543, lr_0 = 1.0804e-04
Loss = 4.7508e-04, PNorm = 58.3866, GNorm = 0.8172, lr_0 = 1.0804e-04
Loss = 4.1618e-04, PNorm = 58.3892, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 3.3517e-04, PNorm = 58.3920, GNorm = 2.1220, lr_0 = 1.0804e-04
Validation rmse logD = 0.567874
Validation R2 logD = 0.781378
Epoch 85
Train function
Loss = 3.7285e-04, PNorm = 58.3943, GNorm = 1.6779, lr_0 = 1.0804e-04
Loss = 3.4658e-04, PNorm = 58.3964, GNorm = 1.1746, lr_0 = 1.0804e-04
Loss = 3.9732e-04, PNorm = 58.3987, GNorm = 0.9384, lr_0 = 1.0804e-04
Loss = 3.2535e-04, PNorm = 58.4003, GNorm = 1.5289, lr_0 = 1.0804e-04
Loss = 5.0822e-04, PNorm = 58.4031, GNorm = 5.2856, lr_0 = 1.0804e-04
Loss = 8.5766e-04, PNorm = 58.4068, GNorm = 2.4843, lr_0 = 1.0804e-04
Validation rmse logD = 0.590854
Validation R2 logD = 0.763326
Epoch 86
Train function
Loss = 9.5884e-04, PNorm = 58.4107, GNorm = 1.8095, lr_0 = 1.0804e-04
Loss = 7.7603e-04, PNorm = 58.4146, GNorm = 0.9692, lr_0 = 1.0804e-04
Loss = 8.7752e-04, PNorm = 58.4199, GNorm = 0.9885, lr_0 = 1.0804e-04
Loss = 7.2013e-04, PNorm = 58.4238, GNorm = 1.4594, lr_0 = 1.0804e-04
Loss = 4.5894e-04, PNorm = 58.4293, GNorm = 1.5944, lr_0 = 1.0804e-04
Validation rmse logD = 0.579090
Validation R2 logD = 0.772657
Epoch 87
Train function
Loss = 4.0031e-04, PNorm = 58.4335, GNorm = 1.2490, lr_0 = 1.0804e-04
Loss = 3.4883e-04, PNorm = 58.4363, GNorm = 2.0715, lr_0 = 1.0804e-04
Loss = 4.1478e-04, PNorm = 58.4384, GNorm = 2.4719, lr_0 = 1.0804e-04
Loss = 4.1207e-04, PNorm = 58.4409, GNorm = 2.0708, lr_0 = 1.0804e-04
Loss = 3.7299e-04, PNorm = 58.4440, GNorm = 2.3910, lr_0 = 1.0804e-04
Loss = 3.2385e-04, PNorm = 58.4460, GNorm = 1.6814, lr_0 = 1.0804e-04
Validation rmse logD = 0.585482
Validation R2 logD = 0.767611
Epoch 88
Train function
Loss = 4.8889e-04, PNorm = 58.4489, GNorm = 3.1683, lr_0 = 1.0804e-04
Loss = 4.1105e-04, PNorm = 58.4512, GNorm = 0.8404, lr_0 = 1.0804e-04
Loss = 4.3257e-04, PNorm = 58.4544, GNorm = 1.8268, lr_0 = 1.0804e-04
Loss = 3.5527e-04, PNorm = 58.4571, GNorm = 0.7633, lr_0 = 1.0804e-04
Loss = 3.5675e-04, PNorm = 58.4596, GNorm = 1.1327, lr_0 = 1.0804e-04
Loss = 4.2556e-04, PNorm = 58.4614, GNorm = 4.9925, lr_0 = 1.0804e-04
Validation rmse logD = 0.585265
Validation R2 logD = 0.767783
Epoch 89
Train function
Loss = 3.5972e-04, PNorm = 58.4648, GNorm = 1.7883, lr_0 = 1.0804e-04
Loss = 3.6486e-04, PNorm = 58.4668, GNorm = 3.5016, lr_0 = 1.0804e-04
Loss = 4.3129e-04, PNorm = 58.4700, GNorm = 1.7191, lr_0 = 1.0804e-04
Loss = 4.1276e-04, PNorm = 58.4741, GNorm = 2.6546, lr_0 = 1.0804e-04
Loss = 5.0026e-04, PNorm = 58.4761, GNorm = 1.6720, lr_0 = 1.0804e-04
Validation rmse logD = 0.611569
Validation R2 logD = 0.746440
Epoch 90
Train function
Loss = 5.8194e-04, PNorm = 58.4794, GNorm = 3.5596, lr_0 = 1.0804e-04
Loss = 3.9535e-04, PNorm = 58.4827, GNorm = 3.8926, lr_0 = 1.0804e-04
Loss = 4.9332e-04, PNorm = 58.4836, GNorm = 0.8665, lr_0 = 1.0804e-04
Loss = 4.0007e-04, PNorm = 58.4860, GNorm = 1.8907, lr_0 = 1.0804e-04
Loss = 3.5088e-04, PNorm = 58.4888, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 4.8315e-04, PNorm = 58.4917, GNorm = 1.8402, lr_0 = 1.0804e-04
Validation rmse logD = 0.569175
Validation R2 logD = 0.780375
Epoch 91
Train function
Loss = 6.6087e-04, PNorm = 58.4950, GNorm = 4.9377, lr_0 = 1.0804e-04
Loss = 5.5976e-04, PNorm = 58.4990, GNorm = 3.0438, lr_0 = 1.0804e-04
Loss = 5.6000e-04, PNorm = 58.5033, GNorm = 4.7460, lr_0 = 1.0804e-04
Loss = 4.0685e-04, PNorm = 58.5064, GNorm = 3.1827, lr_0 = 1.0804e-04
Loss = 3.0521e-04, PNorm = 58.5090, GNorm = 1.0026, lr_0 = 1.0804e-04
Loss = 3.7407e-04, PNorm = 58.5117, GNorm = 3.0846, lr_0 = 1.0804e-04
Validation rmse logD = 0.581482
Validation R2 logD = 0.770776
Epoch 92
Train function
Loss = 3.0330e-04, PNorm = 58.5147, GNorm = 4.7305, lr_0 = 1.0804e-04
Loss = 3.6585e-04, PNorm = 58.5167, GNorm = 1.0260, lr_0 = 1.0804e-04
Loss = 4.4002e-04, PNorm = 58.5183, GNorm = 3.7988, lr_0 = 1.0804e-04
Loss = 4.5256e-04, PNorm = 58.5205, GNorm = 1.0385, lr_0 = 1.0804e-04
Loss = 4.4042e-04, PNorm = 58.5235, GNorm = 0.8780, lr_0 = 1.0804e-04
Validation rmse logD = 0.572095
Validation R2 logD = 0.778116
Epoch 93
Train function
Loss = 2.2626e-04, PNorm = 58.5275, GNorm = 1.2162, lr_0 = 1.0804e-04
Loss = 2.7589e-04, PNorm = 58.5304, GNorm = 1.1642, lr_0 = 1.0804e-04
Loss = 2.7822e-04, PNorm = 58.5319, GNorm = 3.4771, lr_0 = 1.0804e-04
Loss = 4.4048e-04, PNorm = 58.5339, GNorm = 2.8650, lr_0 = 1.0804e-04
Loss = 5.0301e-04, PNorm = 58.5371, GNorm = 4.6362, lr_0 = 1.0804e-04
Loss = 3.6419e-04, PNorm = 58.5403, GNorm = 2.5914, lr_0 = 1.0804e-04
Validation rmse logD = 0.588151
Validation R2 logD = 0.765487
Epoch 94
Train function
Loss = 3.0042e-04, PNorm = 58.5411, GNorm = 1.3724, lr_0 = 1.0804e-04
Loss = 2.8294e-04, PNorm = 58.5432, GNorm = 1.3072, lr_0 = 1.0804e-04
Loss = 3.2571e-04, PNorm = 58.5458, GNorm = 1.1155, lr_0 = 1.0804e-04
Loss = 3.7072e-04, PNorm = 58.5488, GNorm = 1.0188, lr_0 = 1.0804e-04
Loss = 3.7115e-04, PNorm = 58.5515, GNorm = 4.7213, lr_0 = 1.0804e-04
Loss = 2.9282e-04, PNorm = 58.5548, GNorm = 1.2452, lr_0 = 1.0804e-04
Validation rmse logD = 0.571562
Validation R2 logD = 0.778530
Epoch 95
Train function
Loss = 2.3613e-04, PNorm = 58.5571, GNorm = 0.7387, lr_0 = 1.0804e-04
Loss = 4.8166e-04, PNorm = 58.5587, GNorm = 4.0674, lr_0 = 1.0804e-04
Loss = 4.2740e-04, PNorm = 58.5621, GNorm = 0.6409, lr_0 = 1.0804e-04
Loss = 4.6188e-04, PNorm = 58.5655, GNorm = 3.8012, lr_0 = 1.0804e-04
Loss = 4.7091e-04, PNorm = 58.5682, GNorm = 2.5780, lr_0 = 1.0804e-04
Validation rmse logD = 0.577705
Validation R2 logD = 0.773744
Epoch 96
Train function
Loss = 4.1622e-04, PNorm = 58.5706, GNorm = 1.0145, lr_0 = 1.0804e-04
Loss = 3.5910e-04, PNorm = 58.5747, GNorm = 2.6784, lr_0 = 1.0804e-04
Loss = 3.5667e-04, PNorm = 58.5773, GNorm = 1.1190, lr_0 = 1.0804e-04
Loss = 3.0612e-04, PNorm = 58.5798, GNorm = 0.7011, lr_0 = 1.0804e-04
Loss = 3.6148e-04, PNorm = 58.5810, GNorm = 0.8883, lr_0 = 1.0804e-04
Loss = 3.7971e-04, PNorm = 58.5835, GNorm = 2.5190, lr_0 = 1.0804e-04
Validation rmse logD = 0.567584
Validation R2 logD = 0.781602
Epoch 97
Train function
Loss = 2.5356e-04, PNorm = 58.5871, GNorm = 2.4021, lr_0 = 1.0804e-04
Loss = 2.7900e-04, PNorm = 58.5890, GNorm = 1.9929, lr_0 = 1.0804e-04
Loss = 2.7920e-04, PNorm = 58.5916, GNorm = 2.0918, lr_0 = 1.0804e-04
Loss = 5.6528e-04, PNorm = 58.5947, GNorm = 1.7823, lr_0 = 1.0804e-04
Loss = 6.5067e-04, PNorm = 58.5969, GNorm = 5.2015, lr_0 = 1.0804e-04
Loss = 4.3607e-04, PNorm = 58.5993, GNorm = 3.0504, lr_0 = 1.0804e-04
Validation rmse logD = 0.566548
Validation R2 logD = 0.782398
Epoch 98
Train function
Loss = 3.3821e-04, PNorm = 58.6029, GNorm = 2.6503, lr_0 = 1.0804e-04
Loss = 3.2083e-04, PNorm = 58.6048, GNorm = 2.3503, lr_0 = 1.0804e-04
Loss = 4.4692e-04, PNorm = 58.6077, GNorm = 4.6822, lr_0 = 1.0804e-04
Loss = 5.2448e-04, PNorm = 58.6114, GNorm = 0.6281, lr_0 = 1.0804e-04
Loss = 4.0084e-04, PNorm = 58.6149, GNorm = 0.8492, lr_0 = 1.0804e-04
Validation rmse logD = 0.576664
Validation R2 logD = 0.774558
Epoch 99
Train function
Loss = 2.9454e-04, PNorm = 58.6182, GNorm = 1.4647, lr_0 = 1.0804e-04
Loss = 2.6169e-04, PNorm = 58.6204, GNorm = 1.5529, lr_0 = 1.0804e-04
Loss = 2.6926e-04, PNorm = 58.6219, GNorm = 0.7239, lr_0 = 1.0804e-04
Loss = 2.5767e-04, PNorm = 58.6244, GNorm = 0.8688, lr_0 = 1.0804e-04
Loss = 4.1749e-04, PNorm = 58.6260, GNorm = 1.1519, lr_0 = 1.0804e-04
Loss = 3.6687e-04, PNorm = 58.6296, GNorm = 3.1254, lr_0 = 1.0804e-04
Validation rmse logD = 0.568645
Validation R2 logD = 0.780785
Model 0 best validation rmse = 0.566548 on epoch 97
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.548613
Model 0 test R2 logD = 0.763937
Ensemble test rmse  logD= 0.548613
Ensemble test R2  logD= 0.763937
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1855e-02, PNorm = 55.5547, GNorm = 2.6645, lr_0 = 1.0804e-04
Loss = 2.0620e-02, PNorm = 55.5566, GNorm = 6.7757, lr_0 = 1.0804e-04
Loss = 1.5897e-02, PNorm = 55.5592, GNorm = 9.1500, lr_0 = 1.0804e-04
Loss = 1.5769e-02, PNorm = 55.5621, GNorm = 3.0829, lr_0 = 1.0804e-04
Loss = 1.6211e-02, PNorm = 55.5659, GNorm = 2.6876, lr_0 = 1.0804e-04
Validation rmse logD = 1.072468
Validation R2 logD = 0.219926
Epoch 1
Train function
Loss = 1.3740e-02, PNorm = 55.5713, GNorm = 1.4388, lr_0 = 1.0804e-04
Loss = 1.5553e-02, PNorm = 55.5763, GNorm = 5.7282, lr_0 = 1.0804e-04
Loss = 1.5824e-02, PNorm = 55.5817, GNorm = 2.4614, lr_0 = 1.0804e-04
Loss = 1.4576e-02, PNorm = 55.5889, GNorm = 3.4259, lr_0 = 1.0804e-04
Loss = 1.4645e-02, PNorm = 55.5948, GNorm = 5.5750, lr_0 = 1.0804e-04
Loss = 1.5914e-02, PNorm = 55.6013, GNorm = 2.6194, lr_0 = 1.0804e-04
Validation rmse logD = 1.029277
Validation R2 logD = 0.281491
Epoch 2
Train function
Loss = 1.4327e-02, PNorm = 55.6086, GNorm = 1.8406, lr_0 = 1.0804e-04
Loss = 1.3172e-02, PNorm = 55.6178, GNorm = 1.9307, lr_0 = 1.0804e-04
Loss = 1.3011e-02, PNorm = 55.6264, GNorm = 7.1002, lr_0 = 1.0804e-04
Loss = 1.4672e-02, PNorm = 55.6353, GNorm = 3.0704, lr_0 = 1.0804e-04
Loss = 1.2679e-02, PNorm = 55.6457, GNorm = 3.3264, lr_0 = 1.0804e-04
Validation rmse logD = 0.972401
Validation R2 logD = 0.358705
Epoch 3
Train function
Loss = 9.2099e-03, PNorm = 55.6575, GNorm = 1.3305, lr_0 = 1.0804e-04
Loss = 1.2724e-02, PNorm = 55.6685, GNorm = 3.0880, lr_0 = 1.0804e-04
Loss = 1.1506e-02, PNorm = 55.6792, GNorm = 4.3207, lr_0 = 1.0804e-04
Loss = 1.1961e-02, PNorm = 55.6940, GNorm = 4.9770, lr_0 = 1.0804e-04
Loss = 1.2832e-02, PNorm = 55.7030, GNorm = 9.1143, lr_0 = 1.0804e-04
Loss = 9.1661e-03, PNorm = 55.7132, GNorm = 5.4211, lr_0 = 1.0804e-04
Validation rmse logD = 0.984551
Validation R2 logD = 0.342579
Epoch 4
Train function
Loss = 1.1833e-02, PNorm = 55.7261, GNorm = 2.4312, lr_0 = 1.0804e-04
Loss = 1.1621e-02, PNorm = 55.7393, GNorm = 1.6722, lr_0 = 1.0804e-04
Loss = 8.9000e-03, PNorm = 55.7527, GNorm = 2.9534, lr_0 = 1.0804e-04
Loss = 1.0041e-02, PNorm = 55.7639, GNorm = 6.4780, lr_0 = 1.0804e-04
Loss = 9.8939e-03, PNorm = 55.7740, GNorm = 1.2956, lr_0 = 1.0804e-04
Loss = 1.1345e-02, PNorm = 55.7861, GNorm = 1.9783, lr_0 = 1.0804e-04
Validation rmse logD = 1.000726
Validation R2 logD = 0.320801
Epoch 5
Train function
Loss = 1.2795e-02, PNorm = 55.7978, GNorm = 6.9735, lr_0 = 1.0804e-04
Loss = 9.4828e-03, PNorm = 55.8086, GNorm = 4.9896, lr_0 = 1.0804e-04
Loss = 1.0100e-02, PNorm = 55.8214, GNorm = 1.6689, lr_0 = 1.0804e-04
Loss = 1.0605e-02, PNorm = 55.8334, GNorm = 6.2210, lr_0 = 1.0804e-04
Loss = 9.0907e-03, PNorm = 55.8460, GNorm = 4.1776, lr_0 = 1.0804e-04
Validation rmse logD = 0.919602
Validation R2 logD = 0.426455
Epoch 6
Train function
Loss = 1.2521e-02, PNorm = 55.8598, GNorm = 8.5337, lr_0 = 1.0804e-04
Loss = 8.4413e-03, PNorm = 55.8705, GNorm = 4.7847, lr_0 = 1.0804e-04
Loss = 8.2108e-03, PNorm = 55.8818, GNorm = 5.8523, lr_0 = 1.0804e-04
Loss = 8.7963e-03, PNorm = 55.8949, GNorm = 2.4148, lr_0 = 1.0804e-04
Loss = 8.5153e-03, PNorm = 55.9081, GNorm = 1.8354, lr_0 = 1.0804e-04
Loss = 9.1320e-03, PNorm = 55.9208, GNorm = 2.6442, lr_0 = 1.0804e-04
Validation rmse logD = 0.803728
Validation R2 logD = 0.561888
Epoch 7
Train function
Loss = 7.9525e-03, PNorm = 55.9322, GNorm = 6.1893, lr_0 = 1.0804e-04
Loss = 6.5204e-03, PNorm = 55.9445, GNorm = 4.6879, lr_0 = 1.0804e-04
Loss = 8.2526e-03, PNorm = 55.9556, GNorm = 6.6910, lr_0 = 1.0804e-04
Loss = 7.5141e-03, PNorm = 55.9679, GNorm = 2.2598, lr_0 = 1.0804e-04
Loss = 8.2033e-03, PNorm = 55.9784, GNorm = 6.5065, lr_0 = 1.0804e-04
Loss = 9.0944e-03, PNorm = 55.9898, GNorm = 5.4880, lr_0 = 1.0804e-04
Validation rmse logD = 0.756791
Validation R2 logD = 0.611564
Epoch 8
Train function
Loss = 8.1469e-03, PNorm = 56.0010, GNorm = 4.9140, lr_0 = 1.0804e-04
Loss = 6.6736e-03, PNorm = 56.0136, GNorm = 2.7020, lr_0 = 1.0804e-04
Loss = 7.0836e-03, PNorm = 56.0243, GNorm = 5.9759, lr_0 = 1.0804e-04
Loss = 7.5392e-03, PNorm = 56.0345, GNorm = 3.4260, lr_0 = 1.0804e-04
Loss = 8.4689e-03, PNorm = 56.0450, GNorm = 5.2947, lr_0 = 1.0804e-04
Validation rmse logD = 0.777645
Validation R2 logD = 0.589862
Epoch 9
Train function
Loss = 7.4359e-03, PNorm = 56.0558, GNorm = 8.1384, lr_0 = 1.0804e-04
Loss = 6.8671e-03, PNorm = 56.0665, GNorm = 1.6052, lr_0 = 1.0804e-04
Loss = 7.4897e-03, PNorm = 56.0789, GNorm = 2.9995, lr_0 = 1.0804e-04
Loss = 6.7686e-03, PNorm = 56.0909, GNorm = 9.4932, lr_0 = 1.0804e-04
Loss = 6.9110e-03, PNorm = 56.1022, GNorm = 2.1783, lr_0 = 1.0804e-04
Loss = 6.3892e-03, PNorm = 56.1126, GNorm = 2.4383, lr_0 = 1.0804e-04
Validation rmse logD = 0.716918
Validation R2 logD = 0.651417
Epoch 10
Train function
Loss = 7.0256e-03, PNorm = 56.1215, GNorm = 1.4477, lr_0 = 1.0804e-04
Loss = 6.7464e-03, PNorm = 56.1315, GNorm = 4.4697, lr_0 = 1.0804e-04
Loss = 6.2113e-03, PNorm = 56.1431, GNorm = 5.2316, lr_0 = 1.0804e-04
Loss = 5.4458e-03, PNorm = 56.1540, GNorm = 6.1995, lr_0 = 1.0804e-04
Loss = 6.4911e-03, PNorm = 56.1608, GNorm = 5.2436, lr_0 = 1.0804e-04
Loss = 5.8030e-03, PNorm = 56.1669, GNorm = 4.7978, lr_0 = 1.0804e-04
Validation rmse logD = 0.744754
Validation R2 logD = 0.623822
Epoch 11
Train function
Loss = 7.1552e-03, PNorm = 56.1798, GNorm = 2.0763, lr_0 = 1.0804e-04
Loss = 6.5353e-03, PNorm = 56.1908, GNorm = 2.1973, lr_0 = 1.0804e-04
Loss = 6.8228e-03, PNorm = 56.2012, GNorm = 6.2583, lr_0 = 1.0804e-04
Loss = 5.0123e-03, PNorm = 56.2113, GNorm = 1.7500, lr_0 = 1.0804e-04
Loss = 5.5108e-03, PNorm = 56.2191, GNorm = 8.5741, lr_0 = 1.0804e-04
Validation rmse logD = 0.697822
Validation R2 logD = 0.669740
Epoch 12
Train function
Loss = 8.0126e-03, PNorm = 56.2279, GNorm = 3.6251, lr_0 = 1.0804e-04
Loss = 5.7593e-03, PNorm = 56.2372, GNorm = 6.7597, lr_0 = 1.0804e-04
Loss = 6.0606e-03, PNorm = 56.2453, GNorm = 7.3063, lr_0 = 1.0804e-04
Loss = 6.2617e-03, PNorm = 56.2529, GNorm = 2.0349, lr_0 = 1.0804e-04
Loss = 5.7532e-03, PNorm = 56.2596, GNorm = 7.2381, lr_0 = 1.0804e-04
Loss = 5.9853e-03, PNorm = 56.2690, GNorm = 8.4475, lr_0 = 1.0804e-04
Validation rmse logD = 0.691130
Validation R2 logD = 0.676043
Epoch 13
Train function
Loss = 5.0731e-03, PNorm = 56.2796, GNorm = 3.2644, lr_0 = 1.0804e-04
Loss = 4.6168e-03, PNorm = 56.2902, GNorm = 3.8015, lr_0 = 1.0804e-04
Loss = 5.9045e-03, PNorm = 56.2975, GNorm = 1.2399, lr_0 = 1.0804e-04
Loss = 4.9203e-03, PNorm = 56.3056, GNorm = 2.2057, lr_0 = 1.0804e-04
Loss = 5.7198e-03, PNorm = 56.3120, GNorm = 2.2198, lr_0 = 1.0804e-04
Loss = 4.5375e-03, PNorm = 56.3185, GNorm = 1.4632, lr_0 = 1.0804e-04
Validation rmse logD = 0.674168
Validation R2 logD = 0.691749
Epoch 14
Train function
Loss = 4.3904e-03, PNorm = 56.3283, GNorm = 1.3305, lr_0 = 1.0804e-04
Loss = 4.7808e-03, PNorm = 56.3372, GNorm = 5.2595, lr_0 = 1.0804e-04
Loss = 4.9102e-03, PNorm = 56.3476, GNorm = 3.1861, lr_0 = 1.0804e-04
Loss = 4.2250e-03, PNorm = 56.3559, GNorm = 6.0493, lr_0 = 1.0804e-04
Loss = 5.2680e-03, PNorm = 56.3643, GNorm = 6.4820, lr_0 = 1.0804e-04
Validation rmse logD = 0.638322
Validation R2 logD = 0.723658
Epoch 15
Train function
Loss = 2.3426e-03, PNorm = 56.3731, GNorm = 1.4384, lr_0 = 1.0804e-04
Loss = 3.6305e-03, PNorm = 56.3814, GNorm = 5.0539, lr_0 = 1.0804e-04
Loss = 4.5674e-03, PNorm = 56.3878, GNorm = 2.3214, lr_0 = 1.0804e-04
Loss = 4.7444e-03, PNorm = 56.3958, GNorm = 2.0310, lr_0 = 1.0804e-04
Loss = 4.7304e-03, PNorm = 56.4012, GNorm = 6.7775, lr_0 = 1.0804e-04
Loss = 5.3852e-03, PNorm = 56.4097, GNorm = 2.5973, lr_0 = 1.0804e-04
Validation rmse logD = 0.653334
Validation R2 logD = 0.710507
Epoch 16
Train function
Loss = 5.1905e-03, PNorm = 56.4199, GNorm = 4.3438, lr_0 = 1.0804e-04
Loss = 5.3624e-03, PNorm = 56.4300, GNorm = 11.1671, lr_0 = 1.0804e-04
Loss = 4.4369e-03, PNorm = 56.4385, GNorm = 8.1134, lr_0 = 1.0804e-04
Loss = 5.7003e-03, PNorm = 56.4468, GNorm = 6.4534, lr_0 = 1.0804e-04
Loss = 4.5352e-03, PNorm = 56.4547, GNorm = 2.1262, lr_0 = 1.0804e-04
Loss = 4.2504e-03, PNorm = 56.4625, GNorm = 2.5205, lr_0 = 1.0804e-04
Validation rmse logD = 0.629185
Validation R2 logD = 0.731513
Epoch 17
Train function
Loss = 4.0334e-03, PNorm = 56.4703, GNorm = 6.2125, lr_0 = 1.0804e-04
Loss = 4.0042e-03, PNorm = 56.4790, GNorm = 3.2099, lr_0 = 1.0804e-04
Loss = 3.7234e-03, PNorm = 56.4877, GNorm = 1.9543, lr_0 = 1.0804e-04
Loss = 4.7830e-03, PNorm = 56.4951, GNorm = 7.7389, lr_0 = 1.0804e-04
Loss = 4.9805e-03, PNorm = 56.5034, GNorm = 6.8444, lr_0 = 1.0804e-04
Validation rmse logD = 0.640478
Validation R2 logD = 0.721788
Epoch 18
Train function
Loss = 4.1835e-03, PNorm = 56.5117, GNorm = 3.5275, lr_0 = 1.0804e-04
Loss = 3.7374e-03, PNorm = 56.5192, GNorm = 2.0581, lr_0 = 1.0804e-04
Loss = 3.8026e-03, PNorm = 56.5246, GNorm = 1.5243, lr_0 = 1.0804e-04
Loss = 4.3124e-03, PNorm = 56.5324, GNorm = 2.5747, lr_0 = 1.0804e-04
Loss = 4.1150e-03, PNorm = 56.5402, GNorm = 3.8167, lr_0 = 1.0804e-04
Loss = 3.6436e-03, PNorm = 56.5502, GNorm = 5.8516, lr_0 = 1.0804e-04
Validation rmse logD = 0.610506
Validation R2 logD = 0.747217
Epoch 19
Train function
Loss = 4.6935e-03, PNorm = 56.5568, GNorm = 3.1710, lr_0 = 1.0804e-04
Loss = 3.9225e-03, PNorm = 56.5648, GNorm = 2.6916, lr_0 = 1.0804e-04
Loss = 3.7975e-03, PNorm = 56.5720, GNorm = 6.9788, lr_0 = 1.0804e-04
Loss = 4.0870e-03, PNorm = 56.5791, GNorm = 6.7532, lr_0 = 1.0804e-04
Loss = 4.2680e-03, PNorm = 56.5896, GNorm = 4.2063, lr_0 = 1.0804e-04
Loss = 4.0615e-03, PNorm = 56.5989, GNorm = 2.0123, lr_0 = 1.0804e-04
Validation rmse logD = 0.610741
Validation R2 logD = 0.747023
Epoch 20
Train function
Loss = 3.1133e-03, PNorm = 56.6052, GNorm = 5.4244, lr_0 = 1.0804e-04
Loss = 4.1842e-03, PNorm = 56.6128, GNorm = 7.9839, lr_0 = 1.0804e-04
Loss = 3.7886e-03, PNorm = 56.6201, GNorm = 4.3043, lr_0 = 1.0804e-04
Loss = 3.2970e-03, PNorm = 56.6282, GNorm = 5.1371, lr_0 = 1.0804e-04
Loss = 3.6654e-03, PNorm = 56.6351, GNorm = 6.3730, lr_0 = 1.0804e-04
Validation rmse logD = 0.610993
Validation R2 logD = 0.746814
Epoch 21
Train function
Loss = 2.1603e-03, PNorm = 56.6422, GNorm = 5.4941, lr_0 = 1.0804e-04
Loss = 3.4866e-03, PNorm = 56.6501, GNorm = 3.1706, lr_0 = 1.0804e-04
Loss = 3.0890e-03, PNorm = 56.6596, GNorm = 2.8975, lr_0 = 1.0804e-04
Loss = 3.3938e-03, PNorm = 56.6682, GNorm = 1.8310, lr_0 = 1.0804e-04
Loss = 3.9252e-03, PNorm = 56.6729, GNorm = 8.0833, lr_0 = 1.0804e-04
Loss = 4.0741e-03, PNorm = 56.6809, GNorm = 2.8463, lr_0 = 1.0804e-04
Validation rmse logD = 0.618666
Validation R2 logD = 0.740415
Epoch 22
Train function
Loss = 3.4199e-03, PNorm = 56.6878, GNorm = 1.7615, lr_0 = 1.0804e-04
Loss = 3.2023e-03, PNorm = 56.6954, GNorm = 3.0109, lr_0 = 1.0804e-04
Loss = 3.2952e-03, PNorm = 56.7033, GNorm = 4.6713, lr_0 = 1.0804e-04
Loss = 3.8545e-03, PNorm = 56.7128, GNorm = 3.1544, lr_0 = 1.0804e-04
Loss = 3.0909e-03, PNorm = 56.7215, GNorm = 2.8251, lr_0 = 1.0804e-04
Loss = 2.9525e-03, PNorm = 56.7286, GNorm = 3.8197, lr_0 = 1.0804e-04
Validation rmse logD = 0.596398
Validation R2 logD = 0.758765
Epoch 23
Train function
Loss = 3.0424e-03, PNorm = 56.7357, GNorm = 2.4022, lr_0 = 1.0804e-04
Loss = 2.9329e-03, PNorm = 56.7420, GNorm = 3.0588, lr_0 = 1.0804e-04
Loss = 2.9448e-03, PNorm = 56.7504, GNorm = 2.6005, lr_0 = 1.0804e-04
Loss = 2.7219e-03, PNorm = 56.7567, GNorm = 1.8202, lr_0 = 1.0804e-04
Loss = 2.9243e-03, PNorm = 56.7653, GNorm = 3.4047, lr_0 = 1.0804e-04
Validation rmse logD = 0.579955
Validation R2 logD = 0.771884
Epoch 24
Train function
Loss = 3.1345e-03, PNorm = 56.7722, GNorm = 5.3119, lr_0 = 1.0804e-04
Loss = 3.4927e-03, PNorm = 56.7780, GNorm = 10.4560, lr_0 = 1.0804e-04
Loss = 3.0589e-03, PNorm = 56.7860, GNorm = 3.8835, lr_0 = 1.0804e-04
Loss = 3.3045e-03, PNorm = 56.7929, GNorm = 6.0777, lr_0 = 1.0804e-04
Loss = 3.1446e-03, PNorm = 56.8006, GNorm = 1.7750, lr_0 = 1.0804e-04
Loss = 2.9143e-03, PNorm = 56.8073, GNorm = 1.6219, lr_0 = 1.0804e-04
Validation rmse logD = 0.577433
Validation R2 logD = 0.773864
Epoch 25
Train function
Loss = 2.5957e-03, PNorm = 56.8155, GNorm = 4.4611, lr_0 = 1.0804e-04
Loss = 3.1253e-03, PNorm = 56.8237, GNorm = 4.8654, lr_0 = 1.0804e-04
Loss = 2.7831e-03, PNorm = 56.8297, GNorm = 5.0265, lr_0 = 1.0804e-04
Loss = 3.0242e-03, PNorm = 56.8356, GNorm = 6.2659, lr_0 = 1.0804e-04
Loss = 2.4973e-03, PNorm = 56.8426, GNorm = 3.1718, lr_0 = 1.0804e-04
Loss = 3.4545e-03, PNorm = 56.8501, GNorm = 5.9793, lr_0 = 1.0804e-04
Validation rmse logD = 0.584470
Validation R2 logD = 0.768319
Epoch 26
Train function
Loss = 2.3370e-03, PNorm = 56.8582, GNorm = 2.0196, lr_0 = 1.0804e-04
Loss = 2.6733e-03, PNorm = 56.8655, GNorm = 2.5535, lr_0 = 1.0804e-04
Loss = 2.6930e-03, PNorm = 56.8710, GNorm = 2.5413, lr_0 = 1.0804e-04
Loss = 2.8754e-03, PNorm = 56.8774, GNorm = 9.6368, lr_0 = 1.0804e-04
Loss = 3.0832e-03, PNorm = 56.8859, GNorm = 1.6010, lr_0 = 1.0804e-04
Validation rmse logD = 0.603482
Validation R2 logD = 0.753001
Epoch 27
Train function
Loss = 4.6064e-03, PNorm = 56.8935, GNorm = 7.1614, lr_0 = 1.0804e-04
Loss = 2.5790e-03, PNorm = 56.8997, GNorm = 4.6635, lr_0 = 1.0804e-04
Loss = 2.2615e-03, PNorm = 56.9080, GNorm = 2.9345, lr_0 = 1.0804e-04
Loss = 2.6242e-03, PNorm = 56.9135, GNorm = 2.5275, lr_0 = 1.0804e-04
Loss = 2.3533e-03, PNorm = 56.9210, GNorm = 2.5142, lr_0 = 1.0804e-04
Loss = 2.7039e-03, PNorm = 56.9296, GNorm = 2.7720, lr_0 = 1.0804e-04
Validation rmse logD = 0.612163
Validation R2 logD = 0.745843
Epoch 28
Train function
Loss = 2.1779e-03, PNorm = 56.9374, GNorm = 7.6023, lr_0 = 1.0804e-04
Loss = 2.5086e-03, PNorm = 56.9436, GNorm = 1.7543, lr_0 = 1.0804e-04
Loss = 2.6202e-03, PNorm = 56.9490, GNorm = 2.6072, lr_0 = 1.0804e-04
Loss = 2.1448e-03, PNorm = 56.9551, GNorm = 2.1608, lr_0 = 1.0804e-04
Loss = 2.3796e-03, PNorm = 56.9612, GNorm = 2.2997, lr_0 = 1.0804e-04
Loss = 2.5983e-03, PNorm = 56.9682, GNorm = 3.1622, lr_0 = 1.0804e-04
Validation rmse logD = 0.575636
Validation R2 logD = 0.775269
Epoch 29
Train function
Loss = 1.6874e-03, PNorm = 56.9764, GNorm = 3.8860, lr_0 = 1.0804e-04
Loss = 2.5119e-03, PNorm = 56.9839, GNorm = 1.9574, lr_0 = 1.0804e-04
Loss = 2.3302e-03, PNorm = 56.9913, GNorm = 1.7899, lr_0 = 1.0804e-04
Loss = 2.0367e-03, PNorm = 56.9974, GNorm = 1.8067, lr_0 = 1.0804e-04
Loss = 2.6750e-03, PNorm = 57.0023, GNorm = 2.4301, lr_0 = 1.0804e-04
Validation rmse logD = 0.566858
Validation R2 logD = 0.782071
Epoch 30
Train function
Loss = 1.6616e-03, PNorm = 57.0096, GNorm = 3.2728, lr_0 = 1.0804e-04
Loss = 1.8227e-03, PNorm = 57.0175, GNorm = 1.7173, lr_0 = 1.0804e-04
Loss = 2.2381e-03, PNorm = 57.0226, GNorm = 9.8364, lr_0 = 1.0804e-04
Loss = 2.7634e-03, PNorm = 57.0283, GNorm = 2.7493, lr_0 = 1.0804e-04
Loss = 2.1936e-03, PNorm = 57.0362, GNorm = 3.8522, lr_0 = 1.0804e-04
Loss = 3.2463e-03, PNorm = 57.0421, GNorm = 4.2354, lr_0 = 1.0804e-04
Validation rmse logD = 0.566838
Validation R2 logD = 0.782086
Epoch 31
Train function
Loss = 1.6683e-03, PNorm = 57.0472, GNorm = 2.7129, lr_0 = 1.0804e-04
Loss = 2.6053e-03, PNorm = 57.0541, GNorm = 11.8967, lr_0 = 1.0804e-04
Loss = 2.6350e-03, PNorm = 57.0606, GNorm = 2.9328, lr_0 = 1.0804e-04
Loss = 2.3160e-03, PNorm = 57.0665, GNorm = 6.7384, lr_0 = 1.0804e-04
Loss = 2.8690e-03, PNorm = 57.0753, GNorm = 5.5035, lr_0 = 1.0804e-04
Loss = 2.0178e-03, PNorm = 57.0818, GNorm = 4.3764, lr_0 = 1.0804e-04
Validation rmse logD = 0.559402
Validation R2 logD = 0.787766
Epoch 32
Train function
Loss = 2.2082e-03, PNorm = 57.0875, GNorm = 4.5165, lr_0 = 1.0804e-04
Loss = 1.7765e-03, PNorm = 57.0945, GNorm = 1.5437, lr_0 = 1.0804e-04
Loss = 1.8728e-03, PNorm = 57.1008, GNorm = 2.0563, lr_0 = 1.0804e-04
Loss = 2.0641e-03, PNorm = 57.1079, GNorm = 3.2343, lr_0 = 1.0804e-04
Loss = 1.9080e-03, PNorm = 57.1122, GNorm = 3.5224, lr_0 = 1.0804e-04
Validation rmse logD = 0.634742
Validation R2 logD = 0.726749
Epoch 33
Train function
Loss = 2.0408e-03, PNorm = 57.1186, GNorm = 7.1668, lr_0 = 1.0804e-04
Loss = 1.9104e-03, PNorm = 57.1243, GNorm = 1.9336, lr_0 = 1.0804e-04
Loss = 2.3564e-03, PNorm = 57.1311, GNorm = 4.2691, lr_0 = 1.0804e-04
Loss = 2.4278e-03, PNorm = 57.1383, GNorm = 6.9122, lr_0 = 1.0804e-04
Loss = 2.0072e-03, PNorm = 57.1431, GNorm = 1.7672, lr_0 = 1.0804e-04
Loss = 2.0419e-03, PNorm = 57.1487, GNorm = 4.4753, lr_0 = 1.0804e-04
Validation rmse logD = 0.561603
Validation R2 logD = 0.786093
Epoch 34
Train function
Loss = 1.4749e-03, PNorm = 57.1554, GNorm = 2.7776, lr_0 = 1.0804e-04
Loss = 1.4513e-03, PNorm = 57.1632, GNorm = 1.8109, lr_0 = 1.0804e-04
Loss = 2.2309e-03, PNorm = 57.1682, GNorm = 4.8289, lr_0 = 1.0804e-04
Loss = 1.7316e-03, PNorm = 57.1746, GNorm = 2.1985, lr_0 = 1.0804e-04
Loss = 2.0676e-03, PNorm = 57.1800, GNorm = 4.0763, lr_0 = 1.0804e-04
Loss = 1.7961e-03, PNorm = 57.1839, GNorm = 2.7269, lr_0 = 1.0804e-04
Validation rmse logD = 0.598845
Validation R2 logD = 0.756782
Epoch 35
Train function
Loss = 2.2129e-03, PNorm = 57.1899, GNorm = 2.7615, lr_0 = 1.0804e-04
Loss = 2.0715e-03, PNorm = 57.1971, GNorm = 7.9359, lr_0 = 1.0804e-04
Loss = 2.6238e-03, PNorm = 57.2019, GNorm = 9.1286, lr_0 = 1.0804e-04
Loss = 2.1801e-03, PNorm = 57.2081, GNorm = 3.4305, lr_0 = 1.0804e-04
Loss = 1.7932e-03, PNorm = 57.2146, GNorm = 1.6352, lr_0 = 1.0804e-04
Validation rmse logD = 0.554100
Validation R2 logD = 0.791770
Epoch 36
Train function
Loss = 1.5329e-03, PNorm = 57.2221, GNorm = 1.9429, lr_0 = 1.0804e-04
Loss = 1.6169e-03, PNorm = 57.2295, GNorm = 1.8958, lr_0 = 1.0804e-04
Loss = 2.0732e-03, PNorm = 57.2354, GNorm = 2.8020, lr_0 = 1.0804e-04
Loss = 2.0272e-03, PNorm = 57.2412, GNorm = 2.9637, lr_0 = 1.0804e-04
Loss = 1.4713e-03, PNorm = 57.2475, GNorm = 7.7775, lr_0 = 1.0804e-04
Loss = 1.7127e-03, PNorm = 57.2524, GNorm = 4.8353, lr_0 = 1.0804e-04
Validation rmse logD = 0.562811
Validation R2 logD = 0.785171
Epoch 37
Train function
Loss = 1.6006e-03, PNorm = 57.2591, GNorm = 2.0353, lr_0 = 1.0804e-04
Loss = 1.6271e-03, PNorm = 57.2644, GNorm = 6.3593, lr_0 = 1.0804e-04
Loss = 1.6773e-03, PNorm = 57.2699, GNorm = 6.0117, lr_0 = 1.0804e-04
Loss = 1.5110e-03, PNorm = 57.2773, GNorm = 3.9566, lr_0 = 1.0804e-04
Loss = 2.0429e-03, PNorm = 57.2828, GNorm = 2.7360, lr_0 = 1.0804e-04
Loss = 1.4441e-03, PNorm = 57.2871, GNorm = 1.8048, lr_0 = 1.0804e-04
Validation rmse logD = 0.581097
Validation R2 logD = 0.770984
Epoch 38
Train function
Loss = 1.6080e-03, PNorm = 57.2916, GNorm = 7.7825, lr_0 = 1.0804e-04
Loss = 1.4806e-03, PNorm = 57.2957, GNorm = 2.6363, lr_0 = 1.0804e-04
Loss = 1.7774e-03, PNorm = 57.3024, GNorm = 1.9225, lr_0 = 1.0804e-04
Loss = 1.7858e-03, PNorm = 57.3087, GNorm = 6.7429, lr_0 = 1.0804e-04
Loss = 2.1880e-03, PNorm = 57.3123, GNorm = 3.3011, lr_0 = 1.0804e-04
Validation rmse logD = 0.585837
Validation R2 logD = 0.767233
Epoch 39
Train function
Loss = 1.5177e-03, PNorm = 57.3199, GNorm = 5.8870, lr_0 = 1.0804e-04
Loss = 1.6733e-03, PNorm = 57.3252, GNorm = 9.9716, lr_0 = 1.0804e-04
Loss = 1.5353e-03, PNorm = 57.3303, GNorm = 3.2470, lr_0 = 1.0804e-04
Loss = 2.0294e-03, PNorm = 57.3363, GNorm = 9.9856, lr_0 = 1.0804e-04
Loss = 2.2568e-03, PNorm = 57.3404, GNorm = 4.2094, lr_0 = 1.0804e-04
Loss = 1.6361e-03, PNorm = 57.3478, GNorm = 3.7534, lr_0 = 1.0804e-04
Validation rmse logD = 0.546858
Validation R2 logD = 0.797177
Epoch 40
Train function
Loss = 1.2419e-03, PNorm = 57.3539, GNorm = 1.7102, lr_0 = 1.0804e-04
Loss = 1.4050e-03, PNorm = 57.3595, GNorm = 3.9978, lr_0 = 1.0804e-04
Loss = 1.4813e-03, PNorm = 57.3657, GNorm = 6.5927, lr_0 = 1.0804e-04
Loss = 1.7038e-03, PNorm = 57.3690, GNorm = 4.7888, lr_0 = 1.0804e-04
Loss = 1.8640e-03, PNorm = 57.3739, GNorm = 7.5525, lr_0 = 1.0804e-04
Loss = 2.3274e-03, PNorm = 57.3806, GNorm = 3.5092, lr_0 = 1.0804e-04
Validation rmse logD = 0.572783
Validation R2 logD = 0.777491
Epoch 41
Train function
Loss = 1.4491e-03, PNorm = 57.3876, GNorm = 4.4548, lr_0 = 1.0804e-04
Loss = 1.7699e-03, PNorm = 57.3934, GNorm = 1.7522, lr_0 = 1.0804e-04
Loss = 1.7468e-03, PNorm = 57.4003, GNorm = 3.2523, lr_0 = 1.0804e-04
Loss = 1.2571e-03, PNorm = 57.4066, GNorm = 3.3074, lr_0 = 1.0804e-04
Loss = 1.2059e-03, PNorm = 57.4116, GNorm = 3.1396, lr_0 = 1.0804e-04
Validation rmse logD = 0.597020
Validation R2 logD = 0.758262
Epoch 42
Train function
Loss = 1.4059e-03, PNorm = 57.4170, GNorm = 5.4761, lr_0 = 1.0804e-04
Loss = 1.6310e-03, PNorm = 57.4219, GNorm = 2.2489, lr_0 = 1.0804e-04
Loss = 1.4648e-03, PNorm = 57.4290, GNorm = 2.0362, lr_0 = 1.0804e-04
Loss = 1.7103e-03, PNorm = 57.4345, GNorm = 1.2349, lr_0 = 1.0804e-04
Loss = 1.2925e-03, PNorm = 57.4401, GNorm = 4.0755, lr_0 = 1.0804e-04
Loss = 1.4966e-03, PNorm = 57.4459, GNorm = 2.8195, lr_0 = 1.0804e-04
Validation rmse logD = 0.535156
Validation R2 logD = 0.805765
Epoch 43
Train function
Loss = 1.2475e-03, PNorm = 57.4492, GNorm = 3.1614, lr_0 = 1.0804e-04
Loss = 1.6269e-03, PNorm = 57.4532, GNorm = 3.9519, lr_0 = 1.0804e-04
Loss = 1.3570e-03, PNorm = 57.4586, GNorm = 4.0368, lr_0 = 1.0804e-04
Loss = 1.2962e-03, PNorm = 57.4632, GNorm = 1.9145, lr_0 = 1.0804e-04
Loss = 1.4102e-03, PNorm = 57.4689, GNorm = 1.3955, lr_0 = 1.0804e-04
Loss = 1.1441e-03, PNorm = 57.4743, GNorm = 2.7932, lr_0 = 1.0804e-04
Validation rmse logD = 0.548684
Validation R2 logD = 0.795821
Epoch 44
Train function
Loss = 1.2022e-03, PNorm = 57.4779, GNorm = 2.8391, lr_0 = 1.0804e-04
Loss = 1.1561e-03, PNorm = 57.4814, GNorm = 1.6685, lr_0 = 1.0804e-04
Loss = 1.1509e-03, PNorm = 57.4859, GNorm = 3.5871, lr_0 = 1.0804e-04
Loss = 1.1982e-03, PNorm = 57.4915, GNorm = 4.8610, lr_0 = 1.0804e-04
Loss = 1.4783e-03, PNorm = 57.4965, GNorm = 6.5724, lr_0 = 1.0804e-04
Validation rmse logD = 0.554784
Validation R2 logD = 0.791255
Epoch 45
Train function
Loss = 8.3750e-04, PNorm = 57.5025, GNorm = 1.5400, lr_0 = 1.0804e-04
Loss = 1.0248e-03, PNorm = 57.5086, GNorm = 1.9675, lr_0 = 1.0804e-04
Loss = 1.0955e-03, PNorm = 57.5130, GNorm = 2.2205, lr_0 = 1.0804e-04
Loss = 1.2119e-03, PNorm = 57.5161, GNorm = 3.1920, lr_0 = 1.0804e-04
Loss = 1.2498e-03, PNorm = 57.5212, GNorm = 5.2660, lr_0 = 1.0804e-04
Loss = 1.5284e-03, PNorm = 57.5265, GNorm = 3.3584, lr_0 = 1.0804e-04
Validation rmse logD = 0.583142
Validation R2 logD = 0.769370
Epoch 46
Train function
Loss = 1.5752e-03, PNorm = 57.5317, GNorm = 8.3175, lr_0 = 1.0804e-04
Loss = 1.2267e-03, PNorm = 57.5359, GNorm = 2.6611, lr_0 = 1.0804e-04
Loss = 1.8438e-03, PNorm = 57.5414, GNorm = 1.9077, lr_0 = 1.0804e-04
Loss = 1.0176e-03, PNorm = 57.5479, GNorm = 1.7420, lr_0 = 1.0804e-04
Loss = 1.3052e-03, PNorm = 57.5520, GNorm = 4.3560, lr_0 = 1.0804e-04
Loss = 1.3526e-03, PNorm = 57.5566, GNorm = 2.6227, lr_0 = 1.0804e-04
Validation rmse logD = 0.554599
Validation R2 logD = 0.791395
Epoch 47
Train function
Loss = 1.1070e-03, PNorm = 57.5598, GNorm = 2.7347, lr_0 = 1.0804e-04
Loss = 1.1577e-03, PNorm = 57.5641, GNorm = 3.7677, lr_0 = 1.0804e-04
Loss = 1.2834e-03, PNorm = 57.5682, GNorm = 7.0536, lr_0 = 1.0804e-04
Loss = 1.2610e-03, PNorm = 57.5726, GNorm = 3.8106, lr_0 = 1.0804e-04
Loss = 1.3036e-03, PNorm = 57.5778, GNorm = 5.8347, lr_0 = 1.0804e-04
Validation rmse logD = 0.539887
Validation R2 logD = 0.802315
Epoch 48
Train function
Loss = 7.8433e-04, PNorm = 57.5832, GNorm = 1.5906, lr_0 = 1.0804e-04
Loss = 1.2935e-03, PNorm = 57.5867, GNorm = 6.1342, lr_0 = 1.0804e-04
Loss = 1.6571e-03, PNorm = 57.5932, GNorm = 2.1221, lr_0 = 1.0804e-04
Loss = 1.0283e-03, PNorm = 57.5992, GNorm = 1.8398, lr_0 = 1.0804e-04
Loss = 9.6900e-04, PNorm = 57.6043, GNorm = 2.0217, lr_0 = 1.0804e-04
Loss = 9.8526e-04, PNorm = 57.6087, GNorm = 3.5145, lr_0 = 1.0804e-04
Validation rmse logD = 0.564468
Validation R2 logD = 0.783904
Epoch 49
Train function
Loss = 1.2229e-03, PNorm = 57.6137, GNorm = 2.2315, lr_0 = 1.0804e-04
Loss = 1.1686e-03, PNorm = 57.6187, GNorm = 5.6963, lr_0 = 1.0804e-04
Loss = 1.0998e-03, PNorm = 57.6230, GNorm = 7.0700, lr_0 = 1.0804e-04
Loss = 1.5160e-03, PNorm = 57.6273, GNorm = 6.7551, lr_0 = 1.0804e-04
Loss = 1.0726e-03, PNorm = 57.6303, GNorm = 4.4348, lr_0 = 1.0804e-04
Loss = 1.4774e-03, PNorm = 57.6350, GNorm = 1.8168, lr_0 = 1.0804e-04
Validation rmse logD = 0.591786
Validation R2 logD = 0.762482
Epoch 50
Train function
Loss = 1.2943e-03, PNorm = 57.6392, GNorm = 2.6072, lr_0 = 1.0804e-04
Loss = 1.2231e-03, PNorm = 57.6452, GNorm = 4.2440, lr_0 = 1.0804e-04
Loss = 1.5279e-03, PNorm = 57.6512, GNorm = 10.8746, lr_0 = 1.0804e-04
Loss = 1.4145e-03, PNorm = 57.6564, GNorm = 4.8453, lr_0 = 1.0804e-04
Loss = 1.2680e-03, PNorm = 57.6612, GNorm = 3.0239, lr_0 = 1.0804e-04
Validation rmse logD = 0.538145
Validation R2 logD = 0.803589
Epoch 51
Train function
Loss = 7.1990e-04, PNorm = 57.6663, GNorm = 1.6096, lr_0 = 1.0804e-04
Loss = 9.0944e-04, PNorm = 57.6707, GNorm = 1.3713, lr_0 = 1.0804e-04
Loss = 1.0268e-03, PNorm = 57.6749, GNorm = 8.5104, lr_0 = 1.0804e-04
Loss = 1.2037e-03, PNorm = 57.6801, GNorm = 3.2911, lr_0 = 1.0804e-04
Loss = 1.1178e-03, PNorm = 57.6856, GNorm = 1.9941, lr_0 = 1.0804e-04
Loss = 1.3135e-03, PNorm = 57.6894, GNorm = 3.7811, lr_0 = 1.0804e-04
Validation rmse logD = 0.619811
Validation R2 logD = 0.739453
Epoch 52
Train function
Loss = 1.8077e-03, PNorm = 57.6929, GNorm = 3.8490, lr_0 = 1.0804e-04
Loss = 1.0415e-03, PNorm = 57.6971, GNorm = 4.8548, lr_0 = 1.0804e-04
Loss = 1.3379e-03, PNorm = 57.7024, GNorm = 6.8865, lr_0 = 1.0804e-04
Loss = 1.6300e-03, PNorm = 57.7066, GNorm = 8.3639, lr_0 = 1.0804e-04
Loss = 1.5302e-03, PNorm = 57.7109, GNorm = 2.6941, lr_0 = 1.0804e-04
Loss = 1.1519e-03, PNorm = 57.7186, GNorm = 5.2368, lr_0 = 1.0804e-04
Validation rmse logD = 0.562711
Validation R2 logD = 0.785248
Epoch 53
Train function
Loss = 9.6041e-04, PNorm = 57.7239, GNorm = 2.0197, lr_0 = 1.0804e-04
Loss = 1.0627e-03, PNorm = 57.7285, GNorm = 2.0897, lr_0 = 1.0804e-04
Loss = 9.7226e-04, PNorm = 57.7327, GNorm = 1.5102, lr_0 = 1.0804e-04
Loss = 1.0472e-03, PNorm = 57.7368, GNorm = 5.5324, lr_0 = 1.0804e-04
Loss = 1.0083e-03, PNorm = 57.7395, GNorm = 4.0137, lr_0 = 1.0804e-04
Validation rmse logD = 0.532853
Validation R2 logD = 0.807433
Epoch 54
Train function
Loss = 6.9784e-04, PNorm = 57.7441, GNorm = 2.9110, lr_0 = 1.0804e-04
Loss = 1.0686e-03, PNorm = 57.7485, GNorm = 3.3428, lr_0 = 1.0804e-04
Loss = 1.0043e-03, PNorm = 57.7530, GNorm = 1.2258, lr_0 = 1.0804e-04
Loss = 1.1226e-03, PNorm = 57.7575, GNorm = 7.9894, lr_0 = 1.0804e-04
Loss = 8.5251e-04, PNorm = 57.7612, GNorm = 1.5995, lr_0 = 1.0804e-04
Loss = 8.7704e-04, PNorm = 57.7657, GNorm = 1.5314, lr_0 = 1.0804e-04
Validation rmse logD = 0.532193
Validation R2 logD = 0.807909
Epoch 55
Train function
Loss = 7.7558e-04, PNorm = 57.7694, GNorm = 1.4396, lr_0 = 1.0804e-04
Loss = 9.9298e-04, PNorm = 57.7736, GNorm = 5.6435, lr_0 = 1.0804e-04
Loss = 8.4574e-04, PNorm = 57.7775, GNorm = 4.6731, lr_0 = 1.0804e-04
Loss = 1.0129e-03, PNorm = 57.7821, GNorm = 1.5493, lr_0 = 1.0804e-04
Loss = 8.3042e-04, PNorm = 57.7862, GNorm = 2.6696, lr_0 = 1.0804e-04
Loss = 1.1054e-03, PNorm = 57.7894, GNorm = 2.0771, lr_0 = 1.0804e-04
Validation rmse logD = 0.538113
Validation R2 logD = 0.803613
Epoch 56
Train function
Loss = 7.7183e-04, PNorm = 57.7939, GNorm = 1.8352, lr_0 = 1.0804e-04
Loss = 8.8286e-04, PNorm = 57.7983, GNorm = 1.1329, lr_0 = 1.0804e-04
Loss = 1.0378e-03, PNorm = 57.8022, GNorm = 1.4210, lr_0 = 1.0804e-04
Loss = 9.4390e-04, PNorm = 57.8064, GNorm = 3.6659, lr_0 = 1.0804e-04
Loss = 9.3601e-04, PNorm = 57.8100, GNorm = 3.1541, lr_0 = 1.0804e-04
Validation rmse logD = 0.536512
Validation R2 logD = 0.804779
Epoch 57
Train function
Loss = 7.6624e-04, PNorm = 57.8136, GNorm = 3.8957, lr_0 = 1.0804e-04
Loss = 9.2766e-04, PNorm = 57.8160, GNorm = 3.5397, lr_0 = 1.0804e-04
Loss = 9.2134e-04, PNorm = 57.8204, GNorm = 1.5623, lr_0 = 1.0804e-04
Loss = 1.0121e-03, PNorm = 57.8247, GNorm = 1.3206, lr_0 = 1.0804e-04
Loss = 1.0496e-03, PNorm = 57.8291, GNorm = 2.6908, lr_0 = 1.0804e-04
Loss = 8.6292e-04, PNorm = 57.8324, GNorm = 2.7209, lr_0 = 1.0804e-04
Validation rmse logD = 0.574040
Validation R2 logD = 0.776514
Epoch 58
Train function
Loss = 8.9736e-04, PNorm = 57.8369, GNorm = 3.7008, lr_0 = 1.0804e-04
Loss = 9.3149e-04, PNorm = 57.8417, GNorm = 3.3438, lr_0 = 1.0804e-04
Loss = 6.8955e-04, PNorm = 57.8462, GNorm = 1.2271, lr_0 = 1.0804e-04
Loss = 1.1931e-03, PNorm = 57.8497, GNorm = 1.5065, lr_0 = 1.0804e-04
Loss = 7.3470e-04, PNorm = 57.8531, GNorm = 3.2783, lr_0 = 1.0804e-04
Loss = 9.5221e-04, PNorm = 57.8574, GNorm = 1.8952, lr_0 = 1.0804e-04
Validation rmse logD = 0.531604
Validation R2 logD = 0.808334
Epoch 59
Train function
Loss = 7.9291e-04, PNorm = 57.8611, GNorm = 3.6212, lr_0 = 1.0804e-04
Loss = 8.3851e-04, PNorm = 57.8657, GNorm = 1.6415, lr_0 = 1.0804e-04
Loss = 8.3179e-04, PNorm = 57.8687, GNorm = 4.4118, lr_0 = 1.0804e-04
Loss = 9.1904e-04, PNorm = 57.8721, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 8.0159e-04, PNorm = 57.8760, GNorm = 1.3399, lr_0 = 1.0804e-04
Validation rmse logD = 0.550201
Validation R2 logD = 0.794690
Epoch 60
Train function
Loss = 9.2377e-04, PNorm = 57.8802, GNorm = 2.1308, lr_0 = 1.0804e-04
Loss = 6.7181e-04, PNorm = 57.8831, GNorm = 2.2689, lr_0 = 1.0804e-04
Loss = 7.7131e-04, PNorm = 57.8864, GNorm = 3.8643, lr_0 = 1.0804e-04
Loss = 1.0069e-03, PNorm = 57.8896, GNorm = 3.4489, lr_0 = 1.0804e-04
Loss = 9.2824e-04, PNorm = 57.8937, GNorm = 1.5203, lr_0 = 1.0804e-04
Loss = 8.7425e-04, PNorm = 57.8989, GNorm = 3.1332, lr_0 = 1.0804e-04
Validation rmse logD = 0.524125
Validation R2 logD = 0.813690
Epoch 61
Train function
Loss = 1.1533e-03, PNorm = 57.9028, GNorm = 5.3523, lr_0 = 1.0804e-04
Loss = 7.8036e-04, PNorm = 57.9067, GNorm = 5.6854, lr_0 = 1.0804e-04
Loss = 6.9317e-04, PNorm = 57.9113, GNorm = 1.9225, lr_0 = 1.0804e-04
Loss = 7.5363e-04, PNorm = 57.9154, GNorm = 4.2136, lr_0 = 1.0804e-04
Loss = 8.3828e-04, PNorm = 57.9184, GNorm = 2.0604, lr_0 = 1.0804e-04
Loss = 7.8170e-04, PNorm = 57.9222, GNorm = 0.8417, lr_0 = 1.0804e-04
Validation rmse logD = 0.530080
Validation R2 logD = 0.809432
Epoch 62
Train function
Loss = 9.5039e-04, PNorm = 57.9251, GNorm = 6.3487, lr_0 = 1.0804e-04
Loss = 6.9056e-04, PNorm = 57.9291, GNorm = 1.0965, lr_0 = 1.0804e-04
Loss = 7.7073e-04, PNorm = 57.9338, GNorm = 0.9992, lr_0 = 1.0804e-04
Loss = 6.4518e-04, PNorm = 57.9379, GNorm = 1.3103, lr_0 = 1.0804e-04
Loss = 8.5873e-04, PNorm = 57.9415, GNorm = 3.7076, lr_0 = 1.0804e-04
Validation rmse logD = 0.552914
Validation R2 logD = 0.792660
Epoch 63
Train function
Loss = 7.3286e-04, PNorm = 57.9458, GNorm = 4.9038, lr_0 = 1.0804e-04
Loss = 7.4564e-04, PNorm = 57.9483, GNorm = 2.0980, lr_0 = 1.0804e-04
Loss = 8.6258e-04, PNorm = 57.9502, GNorm = 3.6235, lr_0 = 1.0804e-04
Loss = 1.0402e-03, PNorm = 57.9543, GNorm = 6.1647, lr_0 = 1.0804e-04
Loss = 7.7400e-04, PNorm = 57.9587, GNorm = 1.3402, lr_0 = 1.0804e-04
Loss = 8.4167e-04, PNorm = 57.9632, GNorm = 4.9874, lr_0 = 1.0804e-04
Validation rmse logD = 0.531238
Validation R2 logD = 0.808599
Epoch 64
Train function
Loss = 8.0388e-04, PNorm = 57.9685, GNorm = 2.9096, lr_0 = 1.0804e-04
Loss = 7.5568e-04, PNorm = 57.9731, GNorm = 1.2265, lr_0 = 1.0804e-04
Loss = 8.8130e-04, PNorm = 57.9777, GNorm = 7.1432, lr_0 = 1.0804e-04
Loss = 7.3509e-04, PNorm = 57.9801, GNorm = 1.8010, lr_0 = 1.0804e-04
Loss = 6.5337e-04, PNorm = 57.9830, GNorm = 1.1799, lr_0 = 1.0804e-04
Loss = 8.0803e-04, PNorm = 57.9865, GNorm = 6.8003, lr_0 = 1.0804e-04
Validation rmse logD = 0.530063
Validation R2 logD = 0.809444
Epoch 65
Train function
Loss = 8.8848e-04, PNorm = 57.9905, GNorm = 5.7781, lr_0 = 1.0804e-04
Loss = 8.3606e-04, PNorm = 57.9944, GNorm = 4.8264, lr_0 = 1.0804e-04
Loss = 8.4294e-04, PNorm = 57.9985, GNorm = 6.1449, lr_0 = 1.0804e-04
Loss = 9.6374e-04, PNorm = 58.0038, GNorm = 7.3038, lr_0 = 1.0804e-04
Loss = 1.1308e-03, PNorm = 58.0065, GNorm = 5.7458, lr_0 = 1.0804e-04
Validation rmse logD = 0.571132
Validation R2 logD = 0.778772
Epoch 66
Train function
Loss = 1.6602e-03, PNorm = 58.0102, GNorm = 8.1162, lr_0 = 1.0804e-04
Loss = 1.0777e-03, PNorm = 58.0139, GNorm = 5.2124, lr_0 = 1.0804e-04
Loss = 8.2500e-04, PNorm = 58.0182, GNorm = 1.7725, lr_0 = 1.0804e-04
Loss = 1.0837e-03, PNorm = 58.0223, GNorm = 2.2243, lr_0 = 1.0804e-04
Loss = 9.8608e-04, PNorm = 58.0235, GNorm = 1.7271, lr_0 = 1.0804e-04
Loss = 7.5292e-04, PNorm = 58.0278, GNorm = 3.2762, lr_0 = 1.0804e-04
Validation rmse logD = 0.534785
Validation R2 logD = 0.806034
Epoch 67
Train function
Loss = 7.7950e-04, PNorm = 58.0327, GNorm = 1.0577, lr_0 = 1.0804e-04
Loss = 5.8575e-04, PNorm = 58.0372, GNorm = 1.6836, lr_0 = 1.0804e-04
Loss = 7.4032e-04, PNorm = 58.0405, GNorm = 2.8739, lr_0 = 1.0804e-04
Loss = 7.2299e-04, PNorm = 58.0445, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 6.3466e-04, PNorm = 58.0476, GNorm = 3.1066, lr_0 = 1.0804e-04
Loss = 7.7029e-04, PNorm = 58.0523, GNorm = 7.5550, lr_0 = 1.0804e-04
Validation rmse logD = 0.532346
Validation R2 logD = 0.807800
Epoch 68
Train function
Loss = 7.2614e-04, PNorm = 58.0565, GNorm = 2.6143, lr_0 = 1.0804e-04
Loss = 8.2833e-04, PNorm = 58.0587, GNorm = 0.9845, lr_0 = 1.0804e-04
Loss = 8.3117e-04, PNorm = 58.0635, GNorm = 5.1190, lr_0 = 1.0804e-04
Loss = 9.8147e-04, PNorm = 58.0672, GNorm = 1.3217, lr_0 = 1.0804e-04
Loss = 8.2990e-04, PNorm = 58.0699, GNorm = 5.8809, lr_0 = 1.0804e-04
Validation rmse logD = 0.536861
Validation R2 logD = 0.804525
Epoch 69
Train function
Loss = 7.8050e-04, PNorm = 58.0741, GNorm = 3.4282, lr_0 = 1.0804e-04
Loss = 5.6521e-04, PNorm = 58.0795, GNorm = 2.6761, lr_0 = 1.0804e-04
Loss = 7.8856e-04, PNorm = 58.0833, GNorm = 2.0874, lr_0 = 1.0804e-04
Loss = 6.0929e-04, PNorm = 58.0866, GNorm = 3.8031, lr_0 = 1.0804e-04
Loss = 8.0237e-04, PNorm = 58.0900, GNorm = 1.7038, lr_0 = 1.0804e-04
Loss = 5.8414e-04, PNorm = 58.0921, GNorm = 1.1121, lr_0 = 1.0804e-04
Validation rmse logD = 0.532892
Validation R2 logD = 0.807405
Epoch 70
Train function
Loss = 4.4873e-04, PNorm = 58.0951, GNorm = 1.3129, lr_0 = 1.0804e-04
Loss = 5.1858e-04, PNorm = 58.0989, GNorm = 1.3605, lr_0 = 1.0804e-04
Loss = 8.3799e-04, PNorm = 58.1027, GNorm = 2.1818, lr_0 = 1.0804e-04
Loss = 5.3309e-04, PNorm = 58.1060, GNorm = 3.0483, lr_0 = 1.0804e-04
Loss = 5.9429e-04, PNorm = 58.1081, GNorm = 1.0731, lr_0 = 1.0804e-04
Loss = 5.4356e-04, PNorm = 58.1111, GNorm = 2.2293, lr_0 = 1.0804e-04
Validation rmse logD = 0.530971
Validation R2 logD = 0.808791
Epoch 71
Train function
Loss = 5.0689e-04, PNorm = 58.1149, GNorm = 0.9983, lr_0 = 1.0804e-04
Loss = 4.8515e-04, PNorm = 58.1176, GNorm = 3.2407, lr_0 = 1.0804e-04
Loss = 5.7569e-04, PNorm = 58.1204, GNorm = 2.5404, lr_0 = 1.0804e-04
Loss = 5.7420e-04, PNorm = 58.1242, GNorm = 3.6546, lr_0 = 1.0804e-04
Loss = 8.9859e-04, PNorm = 58.1267, GNorm = 1.7856, lr_0 = 1.0804e-04
Validation rmse logD = 0.525921
Validation R2 logD = 0.812411
Epoch 72
Train function
Loss = 4.6981e-04, PNorm = 58.1302, GNorm = 1.0752, lr_0 = 1.0804e-04
Loss = 5.7735e-04, PNorm = 58.1330, GNorm = 1.8322, lr_0 = 1.0804e-04
Loss = 6.0574e-04, PNorm = 58.1362, GNorm = 6.2431, lr_0 = 1.0804e-04
Loss = 1.0860e-03, PNorm = 58.1388, GNorm = 8.0936, lr_0 = 1.0804e-04
Loss = 1.2192e-03, PNorm = 58.1418, GNorm = 6.2147, lr_0 = 1.0804e-04
Loss = 1.3473e-03, PNorm = 58.1468, GNorm = 1.0715, lr_0 = 1.0804e-04
Validation rmse logD = 0.535863
Validation R2 logD = 0.805251
Epoch 73
Train function
Loss = 8.1997e-04, PNorm = 58.1519, GNorm = 3.0503, lr_0 = 1.0804e-04
Loss = 8.2375e-04, PNorm = 58.1571, GNorm = 3.6457, lr_0 = 1.0804e-04
Loss = 1.0311e-03, PNorm = 58.1608, GNorm = 6.0479, lr_0 = 1.0804e-04
Loss = 9.9649e-04, PNorm = 58.1639, GNorm = 1.4865, lr_0 = 1.0804e-04
Loss = 7.3215e-04, PNorm = 58.1690, GNorm = 0.7000, lr_0 = 1.0804e-04
Loss = 7.7771e-04, PNorm = 58.1741, GNorm = 5.3212, lr_0 = 1.0804e-04
Validation rmse logD = 0.534566
Validation R2 logD = 0.806193
Epoch 74
Train function
Loss = 6.3384e-04, PNorm = 58.1783, GNorm = 4.5895, lr_0 = 1.0804e-04
Loss = 5.7464e-04, PNorm = 58.1816, GNorm = 5.9911, lr_0 = 1.0804e-04
Loss = 6.1010e-04, PNorm = 58.1850, GNorm = 4.1076, lr_0 = 1.0804e-04
Loss = 4.7663e-04, PNorm = 58.1877, GNorm = 1.4264, lr_0 = 1.0804e-04
Loss = 7.2779e-04, PNorm = 58.1919, GNorm = 1.9227, lr_0 = 1.0804e-04
Validation rmse logD = 0.534429
Validation R2 logD = 0.806292
Epoch 75
Train function
Loss = 4.7057e-04, PNorm = 58.1951, GNorm = 1.6867, lr_0 = 1.0804e-04
Loss = 7.1798e-04, PNorm = 58.1992, GNorm = 1.6477, lr_0 = 1.0804e-04
Loss = 5.6447e-04, PNorm = 58.2023, GNorm = 1.0499, lr_0 = 1.0804e-04
Loss = 5.1004e-04, PNorm = 58.2058, GNorm = 1.1355, lr_0 = 1.0804e-04
Loss = 4.9808e-04, PNorm = 58.2085, GNorm = 1.1843, lr_0 = 1.0804e-04
Loss = 5.4064e-04, PNorm = 58.2110, GNorm = 3.0749, lr_0 = 1.0804e-04
Validation rmse logD = 0.534275
Validation R2 logD = 0.806404
Epoch 76
Train function
Loss = 7.8088e-04, PNorm = 58.2123, GNorm = 1.7917, lr_0 = 1.0804e-04
Loss = 5.2807e-04, PNorm = 58.2159, GNorm = 1.5595, lr_0 = 1.0804e-04
Loss = 7.2364e-04, PNorm = 58.2187, GNorm = 5.1611, lr_0 = 1.0804e-04
Loss = 1.1352e-03, PNorm = 58.2217, GNorm = 3.1654, lr_0 = 1.0804e-04
Loss = 7.9531e-04, PNorm = 58.2264, GNorm = 4.1927, lr_0 = 1.0804e-04
Loss = 6.3344e-04, PNorm = 58.2322, GNorm = 1.5493, lr_0 = 1.0804e-04
Validation rmse logD = 0.521826
Validation R2 logD = 0.815321
Epoch 77
Train function
Loss = 4.4553e-04, PNorm = 58.2369, GNorm = 3.2647, lr_0 = 1.0804e-04
Loss = 6.7160e-04, PNorm = 58.2395, GNorm = 1.7674, lr_0 = 1.0804e-04
Loss = 5.1160e-04, PNorm = 58.2423, GNorm = 2.7456, lr_0 = 1.0804e-04
Loss = 5.8451e-04, PNorm = 58.2453, GNorm = 1.9262, lr_0 = 1.0804e-04
Loss = 7.7825e-04, PNorm = 58.2483, GNorm = 3.0195, lr_0 = 1.0804e-04
Validation rmse logD = 0.526531
Validation R2 logD = 0.811975
Epoch 78
Train function
Loss = 5.8105e-04, PNorm = 58.2513, GNorm = 2.3061, lr_0 = 1.0804e-04
Loss = 5.6941e-04, PNorm = 58.2541, GNorm = 6.6509, lr_0 = 1.0804e-04
Loss = 5.8191e-04, PNorm = 58.2572, GNorm = 3.2667, lr_0 = 1.0804e-04
Loss = 5.4899e-04, PNorm = 58.2593, GNorm = 2.5886, lr_0 = 1.0804e-04
Loss = 7.3787e-04, PNorm = 58.2612, GNorm = 3.8165, lr_0 = 1.0804e-04
Loss = 6.5154e-04, PNorm = 58.2653, GNorm = 1.0092, lr_0 = 1.0804e-04
Validation rmse logD = 0.520923
Validation R2 logD = 0.815959
Epoch 79
Train function
Loss = 2.3490e-04, PNorm = 58.2691, GNorm = 2.0667, lr_0 = 1.0804e-04
Loss = 4.5378e-04, PNorm = 58.2726, GNorm = 0.8662, lr_0 = 1.0804e-04
Loss = 6.2699e-04, PNorm = 58.2749, GNorm = 4.4855, lr_0 = 1.0804e-04
Loss = 7.0710e-04, PNorm = 58.2766, GNorm = 3.9253, lr_0 = 1.0804e-04
Loss = 6.0381e-04, PNorm = 58.2805, GNorm = 2.2243, lr_0 = 1.0804e-04
Loss = 6.5283e-04, PNorm = 58.2838, GNorm = 1.3119, lr_0 = 1.0804e-04
Validation rmse logD = 0.526508
Validation R2 logD = 0.811991
Epoch 80
Train function
Loss = 3.9284e-04, PNorm = 58.2887, GNorm = 3.5145, lr_0 = 1.0804e-04
Loss = 4.0679e-04, PNorm = 58.2909, GNorm = 1.3575, lr_0 = 1.0804e-04
Loss = 4.1045e-04, PNorm = 58.2940, GNorm = 1.0396, lr_0 = 1.0804e-04
Loss = 6.2242e-04, PNorm = 58.2964, GNorm = 4.7740, lr_0 = 1.0804e-04
Loss = 7.9667e-04, PNorm = 58.2981, GNorm = 8.4045, lr_0 = 1.0804e-04
Validation rmse logD = 0.556231
Validation R2 logD = 0.790165
Epoch 81
Train function
Loss = 1.4876e-03, PNorm = 58.3014, GNorm = 7.8237, lr_0 = 1.0804e-04
Loss = 1.2042e-03, PNorm = 58.3047, GNorm = 3.0803, lr_0 = 1.0804e-04
Loss = 1.0164e-03, PNorm = 58.3101, GNorm = 1.5393, lr_0 = 1.0804e-04
Loss = 5.3237e-04, PNorm = 58.3159, GNorm = 2.2964, lr_0 = 1.0804e-04
Loss = 4.7030e-04, PNorm = 58.3199, GNorm = 1.0860, lr_0 = 1.0804e-04
Loss = 5.9319e-04, PNorm = 58.3236, GNorm = 2.6620, lr_0 = 1.0804e-04
Validation rmse logD = 0.545420
Validation R2 logD = 0.798243
Epoch 82
Train function
Loss = 5.7701e-04, PNorm = 58.3272, GNorm = 5.1344, lr_0 = 1.0804e-04
Loss = 7.1847e-04, PNorm = 58.3294, GNorm = 6.2380, lr_0 = 1.0804e-04
Loss = 5.3743e-04, PNorm = 58.3328, GNorm = 1.3676, lr_0 = 1.0804e-04
Loss = 3.9089e-04, PNorm = 58.3356, GNorm = 2.0100, lr_0 = 1.0804e-04
Loss = 4.7989e-04, PNorm = 58.3388, GNorm = 1.2826, lr_0 = 1.0804e-04
Loss = 5.8816e-04, PNorm = 58.3420, GNorm = 2.2849, lr_0 = 1.0804e-04
Validation rmse logD = 0.539612
Validation R2 logD = 0.802517
Epoch 83
Train function
Loss = 3.4431e-04, PNorm = 58.3452, GNorm = 1.2473, lr_0 = 1.0804e-04
Loss = 5.1358e-04, PNorm = 58.3475, GNorm = 2.8406, lr_0 = 1.0804e-04
Loss = 4.3782e-04, PNorm = 58.3501, GNorm = 2.7727, lr_0 = 1.0804e-04
Loss = 5.7788e-04, PNorm = 58.3541, GNorm = 1.5838, lr_0 = 1.0804e-04
Loss = 5.2624e-04, PNorm = 58.3577, GNorm = 2.6637, lr_0 = 1.0804e-04
Validation rmse logD = 0.526738
Validation R2 logD = 0.811827
Epoch 84
Train function
Loss = 3.0940e-04, PNorm = 58.3609, GNorm = 1.1308, lr_0 = 1.0804e-04
Loss = 3.4285e-04, PNorm = 58.3628, GNorm = 0.7882, lr_0 = 1.0804e-04
Loss = 4.2426e-04, PNorm = 58.3652, GNorm = 3.4910, lr_0 = 1.0804e-04
Loss = 5.4265e-04, PNorm = 58.3669, GNorm = 2.6031, lr_0 = 1.0804e-04
Loss = 8.1422e-04, PNorm = 58.3675, GNorm = 1.5643, lr_0 = 1.0804e-04
Loss = 5.1164e-04, PNorm = 58.3699, GNorm = 2.0622, lr_0 = 1.0804e-04
Validation rmse logD = 0.534158
Validation R2 logD = 0.806489
Epoch 85
Train function
Loss = 5.4121e-04, PNorm = 58.3742, GNorm = 1.9883, lr_0 = 1.0804e-04
Loss = 5.6462e-04, PNorm = 58.3782, GNorm = 1.5838, lr_0 = 1.0804e-04
Loss = 6.9657e-04, PNorm = 58.3814, GNorm = 1.8140, lr_0 = 1.0804e-04
Loss = 9.9888e-04, PNorm = 58.3835, GNorm = 6.9073, lr_0 = 1.0804e-04
Loss = 8.0699e-04, PNorm = 58.3870, GNorm = 6.5087, lr_0 = 1.0804e-04
Loss = 5.5738e-04, PNorm = 58.3929, GNorm = 1.4949, lr_0 = 1.0804e-04
Validation rmse logD = 0.543769
Validation R2 logD = 0.799463
Epoch 86
Train function
Loss = 6.8387e-04, PNorm = 58.3967, GNorm = 1.2641, lr_0 = 1.0804e-04
Loss = 5.1555e-04, PNorm = 58.4002, GNorm = 2.4604, lr_0 = 1.0804e-04
Loss = 3.8599e-04, PNorm = 58.4042, GNorm = 1.2329, lr_0 = 1.0804e-04
Loss = 4.7699e-04, PNorm = 58.4074, GNorm = 2.6840, lr_0 = 1.0804e-04
Loss = 4.7978e-04, PNorm = 58.4100, GNorm = 2.2963, lr_0 = 1.0804e-04
Validation rmse logD = 0.526856
Validation R2 logD = 0.811743
Epoch 87
Train function
Loss = 1.8264e-04, PNorm = 58.4127, GNorm = 0.9372, lr_0 = 1.0804e-04
Loss = 4.2650e-04, PNorm = 58.4157, GNorm = 2.9100, lr_0 = 1.0804e-04
Loss = 3.9648e-04, PNorm = 58.4198, GNorm = 1.6962, lr_0 = 1.0804e-04
Loss = 4.1159e-04, PNorm = 58.4217, GNorm = 1.7711, lr_0 = 1.0804e-04
Loss = 5.7102e-04, PNorm = 58.4234, GNorm = 5.7352, lr_0 = 1.0804e-04
Loss = 7.3822e-04, PNorm = 58.4259, GNorm = 5.4026, lr_0 = 1.0804e-04
Validation rmse logD = 0.527066
Validation R2 logD = 0.811593
Epoch 88
Train function
Loss = 6.7133e-04, PNorm = 58.4293, GNorm = 2.0859, lr_0 = 1.0804e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,166 | train size = 2,832 | val size = 500 | test size = 834
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1555e-02, PNorm = 55.5548, GNorm = 4.2225, lr_0 = 1.0804e-04
Loss = 1.8967e-02, PNorm = 55.5571, GNorm = 5.3966, lr_0 = 1.0804e-04
Loss = 1.7628e-02, PNorm = 55.5599, GNorm = 6.2471, lr_0 = 1.0804e-04
Loss = 1.8561e-02, PNorm = 55.5636, GNorm = 1.3013, lr_0 = 1.0804e-04
Loss = 1.5577e-02, PNorm = 55.5673, GNorm = 1.6232, lr_0 = 1.0804e-04
Validation rmse logD = 1.138604
Validation R2 logD = 0.175111
Epoch 1
Train function
Loss = 1.5666e-02, PNorm = 55.5718, GNorm = 1.4557, lr_0 = 1.0804e-04
Loss = 1.5337e-02, PNorm = 55.5766, GNorm = 8.8675, lr_0 = 1.0804e-04
Loss = 1.6492e-02, PNorm = 55.5817, GNorm = 3.3705, lr_0 = 1.0804e-04
Loss = 1.5866e-02, PNorm = 55.5876, GNorm = 6.2631, lr_0 = 1.0804e-04
Loss = 1.2677e-02, PNorm = 55.5943, GNorm = 1.4519, lr_0 = 1.0804e-04
Loss = 1.5387e-02, PNorm = 55.6017, GNorm = 4.0915, lr_0 = 1.0804e-04
Validation rmse logD = 1.071458
Validation R2 logD = 0.269533
Epoch 2
Train function
Loss = 1.5938e-02, PNorm = 55.6104, GNorm = 2.3883, lr_0 = 1.0804e-04
Loss = 1.3902e-02, PNorm = 55.6199, GNorm = 5.9953, lr_0 = 1.0804e-04
Loss = 1.3871e-02, PNorm = 55.6290, GNorm = 3.4278, lr_0 = 1.0804e-04
Loss = 1.4310e-02, PNorm = 55.6389, GNorm = 7.9563, lr_0 = 1.0804e-04
Loss = 1.1797e-02, PNorm = 55.6499, GNorm = 1.6897, lr_0 = 1.0804e-04
Validation rmse logD = 1.018672
Validation R2 logD = 0.339734
Epoch 3
Train function
Loss = 8.5149e-03, PNorm = 55.6596, GNorm = 1.2556, lr_0 = 1.0804e-04
Loss = 1.2653e-02, PNorm = 55.6689, GNorm = 3.6006, lr_0 = 1.0804e-04
Loss = 1.3227e-02, PNorm = 55.6818, GNorm = 2.7030, lr_0 = 1.0804e-04
Loss = 1.1350e-02, PNorm = 55.6934, GNorm = 2.0040, lr_0 = 1.0804e-04
Loss = 1.1766e-02, PNorm = 55.7036, GNorm = 2.0118, lr_0 = 1.0804e-04
Loss = 1.2349e-02, PNorm = 55.7133, GNorm = 6.6256, lr_0 = 1.0804e-04
Validation rmse logD = 0.961611
Validation R2 logD = 0.411632
Epoch 4
Train function
Loss = 1.1440e-02, PNorm = 55.7239, GNorm = 6.3921, lr_0 = 1.0804e-04
Loss = 1.0851e-02, PNorm = 55.7354, GNorm = 2.8002, lr_0 = 1.0804e-04
Loss = 1.1663e-02, PNorm = 55.7477, GNorm = 2.5348, lr_0 = 1.0804e-04
Loss = 1.0452e-02, PNorm = 55.7613, GNorm = 3.8348, lr_0 = 1.0804e-04
Loss = 1.0745e-02, PNorm = 55.7725, GNorm = 1.6572, lr_0 = 1.0804e-04
Loss = 1.0560e-02, PNorm = 55.7859, GNorm = 2.7456, lr_0 = 1.0804e-04
Validation rmse logD = 0.880986
Validation R2 logD = 0.506158
Epoch 5
Train function
Loss = 8.8266e-03, PNorm = 55.8007, GNorm = 3.8410, lr_0 = 1.0804e-04
Loss = 1.0855e-02, PNorm = 55.8128, GNorm = 2.2744, lr_0 = 1.0804e-04
Loss = 1.0675e-02, PNorm = 55.8243, GNorm = 5.8883, lr_0 = 1.0804e-04
Loss = 9.8574e-03, PNorm = 55.8369, GNorm = 2.7627, lr_0 = 1.0804e-04
Loss = 1.0417e-02, PNorm = 55.8493, GNorm = 3.7765, lr_0 = 1.0804e-04
Validation rmse logD = 0.990030
Validation R2 logD = 0.376341
Epoch 6
Train function
Loss = 1.1968e-02, PNorm = 55.8623, GNorm = 9.8957, lr_0 = 1.0804e-04
Loss = 1.1201e-02, PNorm = 55.8739, GNorm = 9.5698, lr_0 = 1.0804e-04
Loss = 1.0196e-02, PNorm = 55.8847, GNorm = 8.5445, lr_0 = 1.0804e-04
Loss = 1.0242e-02, PNorm = 55.8951, GNorm = 7.9130, lr_0 = 1.0804e-04
Loss = 9.1535e-03, PNorm = 55.9077, GNorm = 3.5639, lr_0 = 1.0804e-04
Loss = 9.2879e-03, PNorm = 55.9217, GNorm = 1.9493, lr_0 = 1.0804e-04
Validation rmse logD = 0.829191
Validation R2 logD = 0.562519
Epoch 7
Train function
Loss = 1.0874e-02, PNorm = 55.9333, GNorm = 4.6661, lr_0 = 1.0804e-04
Loss = 8.6377e-03, PNorm = 55.9443, GNorm = 1.8067, lr_0 = 1.0804e-04
Loss = 8.6075e-03, PNorm = 55.9564, GNorm = 5.6804, lr_0 = 1.0804e-04
Loss = 7.6437e-03, PNorm = 55.9677, GNorm = 2.1056, lr_0 = 1.0804e-04
Loss = 7.9557e-03, PNorm = 55.9794, GNorm = 2.1057, lr_0 = 1.0804e-04
Loss = 7.9871e-03, PNorm = 55.9928, GNorm = 3.3500, lr_0 = 1.0804e-04
Validation rmse logD = 0.771707
Validation R2 logD = 0.621073
Epoch 8
Train function
Loss = 6.5682e-03, PNorm = 56.0077, GNorm = 4.8740, lr_0 = 1.0804e-04
Loss = 7.9162e-03, PNorm = 56.0203, GNorm = 4.7277, lr_0 = 1.0804e-04
Loss = 7.8972e-03, PNorm = 56.0305, GNorm = 3.8374, lr_0 = 1.0804e-04
Loss = 7.1586e-03, PNorm = 56.0412, GNorm = 3.6383, lr_0 = 1.0804e-04
Loss = 6.9920e-03, PNorm = 56.0541, GNorm = 3.0731, lr_0 = 1.0804e-04
Validation rmse logD = 0.776753
Validation R2 logD = 0.616102
Epoch 9
Train function
Loss = 8.7482e-03, PNorm = 56.0648, GNorm = 5.2395, lr_0 = 1.0804e-04
Loss = 6.9797e-03, PNorm = 56.0785, GNorm = 2.3958, lr_0 = 1.0804e-04
Loss = 7.1008e-03, PNorm = 56.0881, GNorm = 2.3506, lr_0 = 1.0804e-04
Loss = 6.8291e-03, PNorm = 56.0999, GNorm = 5.4721, lr_0 = 1.0804e-04
Loss = 6.5017e-03, PNorm = 56.1105, GNorm = 2.8957, lr_0 = 1.0804e-04
Loss = 7.1236e-03, PNorm = 56.1204, GNorm = 2.9296, lr_0 = 1.0804e-04
Validation rmse logD = 0.755395
Validation R2 logD = 0.636924
Epoch 10
Train function
Loss = 4.6507e-03, PNorm = 56.1297, GNorm = 1.7833, lr_0 = 1.0804e-04
Loss = 6.9504e-03, PNorm = 56.1402, GNorm = 1.4705, lr_0 = 1.0804e-04
Loss = 7.3473e-03, PNorm = 56.1522, GNorm = 2.3413, lr_0 = 1.0804e-04
Loss = 6.6943e-03, PNorm = 56.1603, GNorm = 6.1253, lr_0 = 1.0804e-04
Loss = 6.3835e-03, PNorm = 56.1715, GNorm = 1.5431, lr_0 = 1.0804e-04
Loss = 6.6923e-03, PNorm = 56.1814, GNorm = 5.7138, lr_0 = 1.0804e-04
Validation rmse logD = 0.712235
Validation R2 logD = 0.677227
Epoch 11
Train function
Loss = 5.7166e-03, PNorm = 56.1914, GNorm = 5.3108, lr_0 = 1.0804e-04
Loss = 5.8650e-03, PNorm = 56.2008, GNorm = 1.7010, lr_0 = 1.0804e-04
Loss = 6.6855e-03, PNorm = 56.2131, GNorm = 3.8971, lr_0 = 1.0804e-04
Loss = 5.5161e-03, PNorm = 56.2227, GNorm = 5.0471, lr_0 = 1.0804e-04
Loss = 6.2044e-03, PNorm = 56.2296, GNorm = 4.2656, lr_0 = 1.0804e-04
Validation rmse logD = 0.698699
Validation R2 logD = 0.689379
Epoch 12
Train function
Loss = 4.4191e-03, PNorm = 56.2409, GNorm = 1.8777, lr_0 = 1.0804e-04
Loss = 6.1384e-03, PNorm = 56.2477, GNorm = 3.6529, lr_0 = 1.0804e-04
Loss = 6.3019e-03, PNorm = 56.2588, GNorm = 3.6743, lr_0 = 1.0804e-04
Loss = 5.9724e-03, PNorm = 56.2694, GNorm = 7.0760, lr_0 = 1.0804e-04
Loss = 5.3717e-03, PNorm = 56.2782, GNorm = 3.7470, lr_0 = 1.0804e-04
Loss = 6.0957e-03, PNorm = 56.2859, GNorm = 7.5568, lr_0 = 1.0804e-04
Validation rmse logD = 0.732554
Validation R2 logD = 0.658548
Epoch 13
Train function
Loss = 5.3528e-03, PNorm = 56.2967, GNorm = 3.7909, lr_0 = 1.0804e-04
Loss = 5.5057e-03, PNorm = 56.3072, GNorm = 9.1937, lr_0 = 1.0804e-04
Loss = 6.2519e-03, PNorm = 56.3149, GNorm = 5.1685, lr_0 = 1.0804e-04
Loss = 4.7433e-03, PNorm = 56.3242, GNorm = 6.8884, lr_0 = 1.0804e-04
Loss = 5.4450e-03, PNorm = 56.3342, GNorm = 2.1703, lr_0 = 1.0804e-04
Loss = 4.9966e-03, PNorm = 56.3412, GNorm = 2.3668, lr_0 = 1.0804e-04
Validation rmse logD = 0.665154
Validation R2 logD = 0.718489
Epoch 14
Train function
Loss = 5.2968e-03, PNorm = 56.3518, GNorm = 2.9433, lr_0 = 1.0804e-04
Loss = 4.4352e-03, PNorm = 56.3607, GNorm = 2.2732, lr_0 = 1.0804e-04
Loss = 4.4971e-03, PNorm = 56.3674, GNorm = 3.4066, lr_0 = 1.0804e-04
Loss = 5.7586e-03, PNorm = 56.3768, GNorm = 9.7517, lr_0 = 1.0804e-04
Loss = 5.0310e-03, PNorm = 56.3858, GNorm = 3.9311, lr_0 = 1.0804e-04
Validation rmse logD = 0.673040
Validation R2 logD = 0.711775
Epoch 15
Train function
Loss = 4.8406e-03, PNorm = 56.3938, GNorm = 1.8688, lr_0 = 1.0804e-04
Loss = 4.6405e-03, PNorm = 56.4018, GNorm = 4.2955, lr_0 = 1.0804e-04
Loss = 4.3554e-03, PNorm = 56.4093, GNorm = 3.2405, lr_0 = 1.0804e-04
Loss = 5.2028e-03, PNorm = 56.4173, GNorm = 3.7781, lr_0 = 1.0804e-04
Loss = 5.3291e-03, PNorm = 56.4259, GNorm = 2.2149, lr_0 = 1.0804e-04
Loss = 4.2168e-03, PNorm = 56.4342, GNorm = 2.5134, lr_0 = 1.0804e-04
Validation rmse logD = 0.644688
Validation R2 logD = 0.735546
Epoch 16
Train function
Loss = 4.2359e-03, PNorm = 56.4439, GNorm = 1.6258, lr_0 = 1.0804e-04
Loss = 3.5083e-03, PNorm = 56.4525, GNorm = 8.6561, lr_0 = 1.0804e-04
Loss = 4.5246e-03, PNorm = 56.4600, GNorm = 1.8276, lr_0 = 1.0804e-04
Loss = 4.7479e-03, PNorm = 56.4664, GNorm = 2.0634, lr_0 = 1.0804e-04
Loss = 4.6358e-03, PNorm = 56.4744, GNorm = 7.7917, lr_0 = 1.0804e-04
Loss = 4.5567e-03, PNorm = 56.4817, GNorm = 3.9762, lr_0 = 1.0804e-04
Validation rmse logD = 0.641530
Validation R2 logD = 0.738131
Epoch 17
Train function
Loss = 3.4113e-03, PNorm = 56.4912, GNorm = 3.7315, lr_0 = 1.0804e-04
Loss = 4.7131e-03, PNorm = 56.4991, GNorm = 5.2468, lr_0 = 1.0804e-04
Loss = 4.3380e-03, PNorm = 56.5080, GNorm = 4.0933, lr_0 = 1.0804e-04
Loss = 4.2851e-03, PNorm = 56.5172, GNorm = 2.6717, lr_0 = 1.0804e-04
Loss = 4.1195e-03, PNorm = 56.5246, GNorm = 3.6465, lr_0 = 1.0804e-04
Validation rmse logD = 0.634083
Validation R2 logD = 0.744175
Epoch 18
Train function
Loss = 3.3817e-03, PNorm = 56.5331, GNorm = 3.6703, lr_0 = 1.0804e-04
Loss = 4.2325e-03, PNorm = 56.5412, GNorm = 5.5728, lr_0 = 1.0804e-04
Loss = 3.4836e-03, PNorm = 56.5485, GNorm = 3.3865, lr_0 = 1.0804e-04
Loss = 4.2365e-03, PNorm = 56.5573, GNorm = 6.0652, lr_0 = 1.0804e-04
Loss = 3.5905e-03, PNorm = 56.5664, GNorm = 2.0337, lr_0 = 1.0804e-04
Loss = 3.8333e-03, PNorm = 56.5729, GNorm = 6.2729, lr_0 = 1.0804e-04
Validation rmse logD = 0.635641
Validation R2 logD = 0.742917
Epoch 19
Train function
Loss = 3.8756e-03, PNorm = 56.5791, GNorm = 1.9736, lr_0 = 1.0804e-04
Loss = 3.6438e-03, PNorm = 56.5881, GNorm = 2.0717, lr_0 = 1.0804e-04
Loss = 4.4027e-03, PNorm = 56.5940, GNorm = 4.6145, lr_0 = 1.0804e-04
Loss = 3.3587e-03, PNorm = 56.6020, GNorm = 2.9125, lr_0 = 1.0804e-04
Loss = 3.5712e-03, PNorm = 56.6107, GNorm = 2.3351, lr_0 = 1.0804e-04
Loss = 3.4229e-03, PNorm = 56.6187, GNorm = 2.7715, lr_0 = 1.0804e-04
Validation rmse logD = 0.618226
Validation R2 logD = 0.756810
Epoch 20
Train function
Loss = 3.4243e-03, PNorm = 56.6283, GNorm = 3.9180, lr_0 = 1.0804e-04
Loss = 4.6767e-03, PNorm = 56.6331, GNorm = 11.9945, lr_0 = 1.0804e-04
Loss = 5.0809e-03, PNorm = 56.6398, GNorm = 8.8158, lr_0 = 1.0804e-04
Loss = 3.5124e-03, PNorm = 56.6468, GNorm = 2.4010, lr_0 = 1.0804e-04
Loss = 4.1972e-03, PNorm = 56.6560, GNorm = 8.2208, lr_0 = 1.0804e-04
Validation rmse logD = 0.695042
Validation R2 logD = 0.692622
Epoch 21
Train function
Loss = 5.1822e-03, PNorm = 56.6650, GNorm = 7.8639, lr_0 = 1.0804e-04
Loss = 3.8393e-03, PNorm = 56.6730, GNorm = 7.7444, lr_0 = 1.0804e-04
Loss = 3.1770e-03, PNorm = 56.6800, GNorm = 2.9724, lr_0 = 1.0804e-04
Loss = 3.1785e-03, PNorm = 56.6877, GNorm = 1.8253, lr_0 = 1.0804e-04
Loss = 3.6730e-03, PNorm = 56.6954, GNorm = 6.1614, lr_0 = 1.0804e-04
Loss = 3.4424e-03, PNorm = 56.7049, GNorm = 3.5130, lr_0 = 1.0804e-04
Validation rmse logD = 0.653227
Validation R2 logD = 0.728495
Epoch 22
Train function
Loss = 3.5004e-03, PNorm = 56.7120, GNorm = 6.4477, lr_0 = 1.0804e-04
Loss = 3.5999e-03, PNorm = 56.7181, GNorm = 3.6841, lr_0 = 1.0804e-04
Loss = 3.2087e-03, PNorm = 56.7263, GNorm = 2.3179, lr_0 = 1.0804e-04
Loss = 3.9004e-03, PNorm = 56.7348, GNorm = 9.4672, lr_0 = 1.0804e-04
Loss = 3.2764e-03, PNorm = 56.7422, GNorm = 4.2321, lr_0 = 1.0804e-04
Loss = 3.7338e-03, PNorm = 56.7506, GNorm = 3.2951, lr_0 = 1.0804e-04
Validation rmse logD = 0.687170
Validation R2 logD = 0.699545
Epoch 23
Train function
Loss = 3.3211e-03, PNorm = 56.7577, GNorm = 8.1430, lr_0 = 1.0804e-04
Loss = 3.0016e-03, PNorm = 56.7666, GNorm = 6.1111, lr_0 = 1.0804e-04
Loss = 3.1605e-03, PNorm = 56.7738, GNorm = 4.1125, lr_0 = 1.0804e-04
Loss = 3.0620e-03, PNorm = 56.7802, GNorm = 3.1028, lr_0 = 1.0804e-04
Loss = 3.6450e-03, PNorm = 56.7871, GNorm = 2.5770, lr_0 = 1.0804e-04
Validation rmse logD = 0.610731
Validation R2 logD = 0.762672
Epoch 24
Train function
Loss = 2.0337e-03, PNorm = 56.7944, GNorm = 2.2537, lr_0 = 1.0804e-04
Loss = 3.4597e-03, PNorm = 56.8017, GNorm = 4.7521, lr_0 = 1.0804e-04
Loss = 3.3217e-03, PNorm = 56.8103, GNorm = 9.8106, lr_0 = 1.0804e-04
Loss = 3.0491e-03, PNorm = 56.8182, GNorm = 5.4808, lr_0 = 1.0804e-04
Loss = 3.4437e-03, PNorm = 56.8255, GNorm = 8.5484, lr_0 = 1.0804e-04
Loss = 3.8128e-03, PNorm = 56.8312, GNorm = 5.3573, lr_0 = 1.0804e-04
Validation rmse logD = 0.634939
Validation R2 logD = 0.743484
Epoch 25
Train function
Loss = 2.9835e-03, PNorm = 56.8389, GNorm = 5.9232, lr_0 = 1.0804e-04
Loss = 3.0677e-03, PNorm = 56.8470, GNorm = 1.9353, lr_0 = 1.0804e-04
Loss = 2.8582e-03, PNorm = 56.8530, GNorm = 1.4514, lr_0 = 1.0804e-04
Loss = 2.7918e-03, PNorm = 56.8606, GNorm = 4.1765, lr_0 = 1.0804e-04
Loss = 2.9413e-03, PNorm = 56.8686, GNorm = 6.7731, lr_0 = 1.0804e-04
Loss = 2.9465e-03, PNorm = 56.8756, GNorm = 2.4700, lr_0 = 1.0804e-04
Validation rmse logD = 0.597280
Validation R2 logD = 0.773010
Epoch 26
Train function
Loss = 2.5681e-03, PNorm = 56.8842, GNorm = 7.2804, lr_0 = 1.0804e-04
Loss = 2.6529e-03, PNorm = 56.8917, GNorm = 2.3348, lr_0 = 1.0804e-04
Loss = 3.0969e-03, PNorm = 56.9009, GNorm = 4.9532, lr_0 = 1.0804e-04
Loss = 2.4167e-03, PNorm = 56.9081, GNorm = 5.7585, lr_0 = 1.0804e-04
Loss = 2.6752e-03, PNorm = 56.9146, GNorm = 3.3096, lr_0 = 1.0804e-04
Validation rmse logD = 0.624309
Validation R2 logD = 0.752002
Epoch 27
Train function
Loss = 3.5740e-03, PNorm = 56.9172, GNorm = 7.1991, lr_0 = 1.0804e-04
Loss = 3.3603e-03, PNorm = 56.9221, GNorm = 8.8335, lr_0 = 1.0804e-04
Loss = 2.5525e-03, PNorm = 56.9300, GNorm = 3.4068, lr_0 = 1.0804e-04
Loss = 2.7737e-03, PNorm = 56.9396, GNorm = 5.4791, lr_0 = 1.0804e-04
Loss = 2.3725e-03, PNorm = 56.9470, GNorm = 4.1709, lr_0 = 1.0804e-04
Loss = 2.4132e-03, PNorm = 56.9533, GNorm = 2.1123, lr_0 = 1.0804e-04
Validation rmse logD = 0.596038
Validation R2 logD = 0.773953
Epoch 28
Train function
Loss = 2.5447e-03, PNorm = 56.9594, GNorm = 3.1408, lr_0 = 1.0804e-04
Loss = 2.8650e-03, PNorm = 56.9661, GNorm = 8.1029, lr_0 = 1.0804e-04
Loss = 2.4297e-03, PNorm = 56.9720, GNorm = 3.0162, lr_0 = 1.0804e-04
Loss = 2.5929e-03, PNorm = 56.9798, GNorm = 5.7270, lr_0 = 1.0804e-04
Loss = 2.6454e-03, PNorm = 56.9885, GNorm = 3.1676, lr_0 = 1.0804e-04
Loss = 2.5774e-03, PNorm = 56.9965, GNorm = 1.3519, lr_0 = 1.0804e-04
Validation rmse logD = 0.601688
Validation R2 logD = 0.769647
Epoch 29
Train function
Loss = 2.1561e-03, PNorm = 57.0026, GNorm = 1.9913, lr_0 = 1.0804e-04
Loss = 2.3604e-03, PNorm = 57.0087, GNorm = 3.0088, lr_0 = 1.0804e-04
Loss = 2.9143e-03, PNorm = 57.0146, GNorm = 2.0204, lr_0 = 1.0804e-04
Loss = 2.0049e-03, PNorm = 57.0208, GNorm = 2.1434, lr_0 = 1.0804e-04
Loss = 2.4048e-03, PNorm = 57.0284, GNorm = 10.6303, lr_0 = 1.0804e-04
Validation rmse logD = 0.614982
Validation R2 logD = 0.759356
Epoch 30
Train function
Loss = 2.3560e-03, PNorm = 57.0337, GNorm = 5.4398, lr_0 = 1.0804e-04
Loss = 2.4534e-03, PNorm = 57.0388, GNorm = 6.1097, lr_0 = 1.0804e-04
Loss = 2.3885e-03, PNorm = 57.0466, GNorm = 2.0981, lr_0 = 1.0804e-04
Loss = 2.2955e-03, PNorm = 57.0538, GNorm = 2.1621, lr_0 = 1.0804e-04
Loss = 2.3582e-03, PNorm = 57.0600, GNorm = 5.0526, lr_0 = 1.0804e-04
Loss = 2.4854e-03, PNorm = 57.0664, GNorm = 5.8226, lr_0 = 1.0804e-04
Validation rmse logD = 0.600830
Validation R2 logD = 0.770304
Epoch 31
Train function
Loss = 1.8129e-03, PNorm = 57.0733, GNorm = 1.9925, lr_0 = 1.0804e-04
Loss = 2.1706e-03, PNorm = 57.0804, GNorm = 3.0720, lr_0 = 1.0804e-04
Loss = 2.1420e-03, PNorm = 57.0880, GNorm = 1.3060, lr_0 = 1.0804e-04
Loss = 2.0388e-03, PNorm = 57.0948, GNorm = 3.0993, lr_0 = 1.0804e-04
Loss = 2.0612e-03, PNorm = 57.1010, GNorm = 4.9035, lr_0 = 1.0804e-04
Loss = 2.2944e-03, PNorm = 57.1071, GNorm = 2.7973, lr_0 = 1.0804e-04
Validation rmse logD = 0.580670
Validation R2 logD = 0.785459
Epoch 32
Train function
Loss = 1.7888e-03, PNorm = 57.1143, GNorm = 2.9119, lr_0 = 1.0804e-04
Loss = 2.0017e-03, PNorm = 57.1213, GNorm = 5.1178, lr_0 = 1.0804e-04
Loss = 2.2058e-03, PNorm = 57.1270, GNorm = 3.3760, lr_0 = 1.0804e-04
Loss = 2.1502e-03, PNorm = 57.1313, GNorm = 2.4765, lr_0 = 1.0804e-04
Loss = 2.8272e-03, PNorm = 57.1377, GNorm = 6.7240, lr_0 = 1.0804e-04
Validation rmse logD = 0.585745
Validation R2 logD = 0.781693
Epoch 33
Train function
Loss = 1.8568e-03, PNorm = 57.1449, GNorm = 2.6799, lr_0 = 1.0804e-04
Loss = 2.2891e-03, PNorm = 57.1519, GNorm = 3.4314, lr_0 = 1.0804e-04
Loss = 2.0803e-03, PNorm = 57.1583, GNorm = 2.9500, lr_0 = 1.0804e-04
Loss = 2.3281e-03, PNorm = 57.1641, GNorm = 5.2686, lr_0 = 1.0804e-04
Loss = 1.9650e-03, PNorm = 57.1709, GNorm = 2.0998, lr_0 = 1.0804e-04
Loss = 2.2097e-03, PNorm = 57.1781, GNorm = 3.9942, lr_0 = 1.0804e-04
Validation rmse logD = 0.584169
Validation R2 logD = 0.782866
Epoch 34
Train function
Loss = 1.8909e-03, PNorm = 57.1845, GNorm = 4.9554, lr_0 = 1.0804e-04
Loss = 1.8973e-03, PNorm = 57.1905, GNorm = 1.6016, lr_0 = 1.0804e-04
Loss = 1.8118e-03, PNorm = 57.1970, GNorm = 1.5735, lr_0 = 1.0804e-04
Loss = 1.7009e-03, PNorm = 57.2042, GNorm = 4.1328, lr_0 = 1.0804e-04
Loss = 1.9925e-03, PNorm = 57.2094, GNorm = 1.9513, lr_0 = 1.0804e-04
Loss = 2.2279e-03, PNorm = 57.2155, GNorm = 1.6266, lr_0 = 1.0804e-04
Validation rmse logD = 0.579281
Validation R2 logD = 0.786485
Epoch 35
Train function
Loss = 2.4141e-03, PNorm = 57.2229, GNorm = 6.0146, lr_0 = 1.0804e-04
Loss = 2.5771e-03, PNorm = 57.2272, GNorm = 5.3637, lr_0 = 1.0804e-04
Loss = 2.9280e-03, PNorm = 57.2331, GNorm = 6.7645, lr_0 = 1.0804e-04
Loss = 2.8302e-03, PNorm = 57.2397, GNorm = 7.3094, lr_0 = 1.0804e-04
Loss = 2.3823e-03, PNorm = 57.2461, GNorm = 2.4957, lr_0 = 1.0804e-04
Validation rmse logD = 0.565499
Validation R2 logD = 0.796524
Epoch 36
Train function
Loss = 1.2691e-03, PNorm = 57.2548, GNorm = 4.4312, lr_0 = 1.0804e-04
Loss = 1.8248e-03, PNorm = 57.2639, GNorm = 1.8535, lr_0 = 1.0804e-04
Loss = 2.0203e-03, PNorm = 57.2687, GNorm = 7.2827, lr_0 = 1.0804e-04
Loss = 1.7200e-03, PNorm = 57.2740, GNorm = 1.4460, lr_0 = 1.0804e-04
Loss = 1.8584e-03, PNorm = 57.2787, GNorm = 1.9044, lr_0 = 1.0804e-04
Loss = 1.9254e-03, PNorm = 57.2860, GNorm = 5.1085, lr_0 = 1.0804e-04
Validation rmse logD = 0.577288
Validation R2 logD = 0.787951
Epoch 37
Train function
Loss = 1.9148e-03, PNorm = 57.2933, GNorm = 9.4346, lr_0 = 1.0804e-04
Loss = 1.9169e-03, PNorm = 57.2987, GNorm = 5.4406, lr_0 = 1.0804e-04
Loss = 1.8517e-03, PNorm = 57.3044, GNorm = 1.0101, lr_0 = 1.0804e-04
Loss = 1.9295e-03, PNorm = 57.3116, GNorm = 3.8249, lr_0 = 1.0804e-04
Loss = 1.9766e-03, PNorm = 57.3170, GNorm = 8.4655, lr_0 = 1.0804e-04
Loss = 2.1995e-03, PNorm = 57.3230, GNorm = 2.7972, lr_0 = 1.0804e-04
Validation rmse logD = 0.569133
Validation R2 logD = 0.793900
Epoch 38
Train function
Loss = 1.6925e-03, PNorm = 57.3291, GNorm = 1.5194, lr_0 = 1.0804e-04
Loss = 1.6043e-03, PNorm = 57.3355, GNorm = 5.9111, lr_0 = 1.0804e-04
Loss = 1.8553e-03, PNorm = 57.3414, GNorm = 5.2433, lr_0 = 1.0804e-04
Loss = 1.7117e-03, PNorm = 57.3462, GNorm = 1.7961, lr_0 = 1.0804e-04
Loss = 1.9148e-03, PNorm = 57.3508, GNorm = 1.3231, lr_0 = 1.0804e-04
Validation rmse logD = 0.570148
Validation R2 logD = 0.793165
Epoch 39
Train function
Loss = 1.8265e-03, PNorm = 57.3586, GNorm = 2.2030, lr_0 = 1.0804e-04
Loss = 1.7368e-03, PNorm = 57.3655, GNorm = 7.6016, lr_0 = 1.0804e-04
Loss = 1.5481e-03, PNorm = 57.3723, GNorm = 2.3056, lr_0 = 1.0804e-04
Loss = 1.7534e-03, PNorm = 57.3762, GNorm = 1.5440, lr_0 = 1.0804e-04
Loss = 1.4344e-03, PNorm = 57.3805, GNorm = 3.4827, lr_0 = 1.0804e-04
Loss = 1.6410e-03, PNorm = 57.3868, GNorm = 1.7287, lr_0 = 1.0804e-04
Validation rmse logD = 0.594707
Validation R2 logD = 0.774961
Epoch 40
Train function
Loss = 1.3889e-03, PNorm = 57.3922, GNorm = 5.8498, lr_0 = 1.0804e-04
Loss = 1.4736e-03, PNorm = 57.3971, GNorm = 1.2033, lr_0 = 1.0804e-04
Loss = 1.5448e-03, PNorm = 57.4025, GNorm = 3.9680, lr_0 = 1.0804e-04
Loss = 1.6989e-03, PNorm = 57.4074, GNorm = 2.0009, lr_0 = 1.0804e-04
Loss = 1.3797e-03, PNorm = 57.4148, GNorm = 1.5449, lr_0 = 1.0804e-04
Loss = 1.5069e-03, PNorm = 57.4215, GNorm = 2.3091, lr_0 = 1.0804e-04
Validation rmse logD = 0.541409
Validation R2 logD = 0.813490
Epoch 41
Train function
Loss = 1.2940e-03, PNorm = 57.4259, GNorm = 3.6576, lr_0 = 1.0804e-04
Loss = 1.3827e-03, PNorm = 57.4309, GNorm = 1.4018, lr_0 = 1.0804e-04
Loss = 1.2755e-03, PNorm = 57.4360, GNorm = 1.3701, lr_0 = 1.0804e-04
Loss = 1.6906e-03, PNorm = 57.4423, GNorm = 6.3175, lr_0 = 1.0804e-04
Loss = 1.6066e-03, PNorm = 57.4491, GNorm = 3.6885, lr_0 = 1.0804e-04
Validation rmse logD = 0.556482
Validation R2 logD = 0.802961
Epoch 42
Train function
Loss = 1.6693e-03, PNorm = 57.4541, GNorm = 1.5228, lr_0 = 1.0804e-04
Loss = 1.4071e-03, PNorm = 57.4598, GNorm = 3.0500, lr_0 = 1.0804e-04
Loss = 1.1850e-03, PNorm = 57.4658, GNorm = 4.2689, lr_0 = 1.0804e-04
Loss = 1.5484e-03, PNorm = 57.4700, GNorm = 3.9267, lr_0 = 1.0804e-04
Loss = 1.5063e-03, PNorm = 57.4746, GNorm = 4.6361, lr_0 = 1.0804e-04
Loss = 1.6712e-03, PNorm = 57.4815, GNorm = 1.6981, lr_0 = 1.0804e-04
Validation rmse logD = 0.549506
Validation R2 logD = 0.807870
Epoch 43
Train function
Loss = 1.0650e-03, PNorm = 57.4871, GNorm = 4.8130, lr_0 = 1.0804e-04
Loss = 1.4214e-03, PNorm = 57.4927, GNorm = 2.3654, lr_0 = 1.0804e-04
Loss = 1.4224e-03, PNorm = 57.4997, GNorm = 3.5136, lr_0 = 1.0804e-04
Loss = 1.2594e-03, PNorm = 57.5042, GNorm = 1.6076, lr_0 = 1.0804e-04
Loss = 1.2889e-03, PNorm = 57.5108, GNorm = 3.0072, lr_0 = 1.0804e-04
Loss = 1.2600e-03, PNorm = 57.5163, GNorm = 3.5155, lr_0 = 1.0804e-04
Validation rmse logD = 0.541594
Validation R2 logD = 0.813363
Epoch 44
Train function
Loss = 1.0597e-03, PNorm = 57.5211, GNorm = 1.7349, lr_0 = 1.0804e-04
Loss = 1.0636e-03, PNorm = 57.5252, GNorm = 2.0511, lr_0 = 1.0804e-04
Loss = 1.1849e-03, PNorm = 57.5297, GNorm = 2.8803, lr_0 = 1.0804e-04
Loss = 1.2885e-03, PNorm = 57.5349, GNorm = 1.3363, lr_0 = 1.0804e-04
Loss = 1.7458e-03, PNorm = 57.5399, GNorm = 2.4113, lr_0 = 1.0804e-04
Validation rmse logD = 0.560843
Validation R2 logD = 0.799860
Epoch 45
Train function
Loss = 9.7178e-04, PNorm = 57.5464, GNorm = 3.5722, lr_0 = 1.0804e-04
Loss = 1.1343e-03, PNorm = 57.5507, GNorm = 2.3121, lr_0 = 1.0804e-04
Loss = 1.2555e-03, PNorm = 57.5573, GNorm = 3.4576, lr_0 = 1.0804e-04
Loss = 1.1446e-03, PNorm = 57.5621, GNorm = 2.3975, lr_0 = 1.0804e-04
Loss = 1.5201e-03, PNorm = 57.5666, GNorm = 4.5229, lr_0 = 1.0804e-04
Loss = 1.4903e-03, PNorm = 57.5722, GNorm = 1.7646, lr_0 = 1.0804e-04
Validation rmse logD = 0.534848
Validation R2 logD = 0.817983
Epoch 46
Train function
Loss = 1.0475e-03, PNorm = 57.5791, GNorm = 2.4064, lr_0 = 1.0804e-04
Loss = 1.2468e-03, PNorm = 57.5843, GNorm = 3.3806, lr_0 = 1.0804e-04
Loss = 1.1121e-03, PNorm = 57.5889, GNorm = 2.3243, lr_0 = 1.0804e-04
Loss = 1.2592e-03, PNorm = 57.5946, GNorm = 7.8734, lr_0 = 1.0804e-04
Loss = 1.6822e-03, PNorm = 57.5994, GNorm = 9.0511, lr_0 = 1.0804e-04
Loss = 1.9040e-03, PNorm = 57.6031, GNorm = 2.8079, lr_0 = 1.0804e-04
Validation rmse logD = 0.536307
Validation R2 logD = 0.816989
Epoch 47
Train function
Loss = 1.3012e-03, PNorm = 57.6079, GNorm = 5.0017, lr_0 = 1.0804e-04
Loss = 1.3534e-03, PNorm = 57.6147, GNorm = 3.9316, lr_0 = 1.0804e-04
Loss = 1.1116e-03, PNorm = 57.6214, GNorm = 2.7837, lr_0 = 1.0804e-04
Loss = 1.1771e-03, PNorm = 57.6269, GNorm = 3.8177, lr_0 = 1.0804e-04
Loss = 9.9236e-04, PNorm = 57.6318, GNorm = 2.7167, lr_0 = 1.0804e-04
Validation rmse logD = 0.534596
Validation R2 logD = 0.818155
Epoch 48
Train function
Loss = 7.4165e-04, PNorm = 57.6364, GNorm = 4.9388, lr_0 = 1.0804e-04
Loss = 1.0624e-03, PNorm = 57.6422, GNorm = 3.1678, lr_0 = 1.0804e-04
Loss = 1.1677e-03, PNorm = 57.6476, GNorm = 3.2701, lr_0 = 1.0804e-04
Loss = 1.1214e-03, PNorm = 57.6519, GNorm = 1.3416, lr_0 = 1.0804e-04
Loss = 1.2929e-03, PNorm = 57.6564, GNorm = 8.2815, lr_0 = 1.0804e-04
Loss = 1.2948e-03, PNorm = 57.6623, GNorm = 5.2081, lr_0 = 1.0804e-04
Validation rmse logD = 0.593833
Validation R2 logD = 0.775623
Epoch 49
Train function
Loss = 1.3373e-03, PNorm = 57.6677, GNorm = 4.3707, lr_0 = 1.0804e-04
Loss = 1.2363e-03, PNorm = 57.6730, GNorm = 3.3012, lr_0 = 1.0804e-04
Loss = 1.1305e-03, PNorm = 57.6768, GNorm = 4.7248, lr_0 = 1.0804e-04
Loss = 1.0264e-03, PNorm = 57.6808, GNorm = 3.6035, lr_0 = 1.0804e-04
Loss = 1.1540e-03, PNorm = 57.6871, GNorm = 3.2157, lr_0 = 1.0804e-04
Loss = 1.3029e-03, PNorm = 57.6936, GNorm = 4.6495, lr_0 = 1.0804e-04
Validation rmse logD = 0.538282
Validation R2 logD = 0.815639
Epoch 50
Train function
Loss = 1.0154e-03, PNorm = 57.6978, GNorm = 2.0041, lr_0 = 1.0804e-04
Loss = 1.0408e-03, PNorm = 57.7020, GNorm = 2.2598, lr_0 = 1.0804e-04
Loss = 1.1473e-03, PNorm = 57.7070, GNorm = 4.0337, lr_0 = 1.0804e-04
Loss = 1.1448e-03, PNorm = 57.7123, GNorm = 3.1053, lr_0 = 1.0804e-04
Loss = 1.2667e-03, PNorm = 57.7172, GNorm = 1.9636, lr_0 = 1.0804e-04
Validation rmse logD = 0.540745
Validation R2 logD = 0.813947
Epoch 51
Train function
Loss = 1.1033e-03, PNorm = 57.7226, GNorm = 6.3582, lr_0 = 1.0804e-04
Loss = 1.0512e-03, PNorm = 57.7293, GNorm = 1.4560, lr_0 = 1.0804e-04
Loss = 9.8717e-04, PNorm = 57.7328, GNorm = 1.8427, lr_0 = 1.0804e-04
Loss = 1.0762e-03, PNorm = 57.7354, GNorm = 3.5993, lr_0 = 1.0804e-04
Loss = 1.2087e-03, PNorm = 57.7401, GNorm = 2.4091, lr_0 = 1.0804e-04
Loss = 1.2550e-03, PNorm = 57.7453, GNorm = 8.9543, lr_0 = 1.0804e-04
Validation rmse logD = 0.537939
Validation R2 logD = 0.815874
Epoch 52
Train function
Loss = 1.0387e-03, PNorm = 57.7509, GNorm = 2.6945, lr_0 = 1.0804e-04
Loss = 1.0044e-03, PNorm = 57.7568, GNorm = 1.1432, lr_0 = 1.0804e-04
Loss = 9.0848e-04, PNorm = 57.7628, GNorm = 3.7850, lr_0 = 1.0804e-04
Loss = 1.0563e-03, PNorm = 57.7665, GNorm = 3.5263, lr_0 = 1.0804e-04
Loss = 9.8725e-04, PNorm = 57.7683, GNorm = 3.7785, lr_0 = 1.0804e-04
Loss = 9.1764e-04, PNorm = 57.7735, GNorm = 2.1640, lr_0 = 1.0804e-04
Validation rmse logD = 0.540189
Validation R2 logD = 0.814330
Epoch 53
Train function
Loss = 7.0001e-04, PNorm = 57.7784, GNorm = 1.1322, lr_0 = 1.0804e-04
Loss = 9.4046e-04, PNorm = 57.7810, GNorm = 1.6925, lr_0 = 1.0804e-04
Loss = 1.0794e-03, PNorm = 57.7848, GNorm = 3.5596, lr_0 = 1.0804e-04
Loss = 1.0920e-03, PNorm = 57.7894, GNorm = 1.7391, lr_0 = 1.0804e-04
Loss = 8.7918e-04, PNorm = 57.7943, GNorm = 2.2380, lr_0 = 1.0804e-04
Validation rmse logD = 0.538892
Validation R2 logD = 0.815220
Epoch 54
Train function
Loss = 7.3751e-04, PNorm = 57.7999, GNorm = 2.2825, lr_0 = 1.0804e-04
Loss = 9.0500e-04, PNorm = 57.8048, GNorm = 2.9416, lr_0 = 1.0804e-04
Loss = 9.5002e-04, PNorm = 57.8086, GNorm = 1.5769, lr_0 = 1.0804e-04
Loss = 8.9662e-04, PNorm = 57.8126, GNorm = 2.4465, lr_0 = 1.0804e-04
Loss = 9.9201e-04, PNorm = 57.8179, GNorm = 3.4386, lr_0 = 1.0804e-04
Loss = 9.4181e-04, PNorm = 57.8238, GNorm = 4.8182, lr_0 = 1.0804e-04
Validation rmse logD = 0.532703
Validation R2 logD = 0.819440
Epoch 55
Train function
Loss = 9.8273e-04, PNorm = 57.8290, GNorm = 1.2645, lr_0 = 1.0804e-04
Loss = 8.4145e-04, PNorm = 57.8329, GNorm = 1.6018, lr_0 = 1.0804e-04
Loss = 1.0341e-03, PNorm = 57.8358, GNorm = 1.8360, lr_0 = 1.0804e-04
Loss = 8.8753e-04, PNorm = 57.8399, GNorm = 1.4332, lr_0 = 1.0804e-04
Loss = 1.0780e-03, PNorm = 57.8441, GNorm = 4.7739, lr_0 = 1.0804e-04
Loss = 9.1302e-04, PNorm = 57.8496, GNorm = 1.8882, lr_0 = 1.0804e-04
Validation rmse logD = 0.530689
Validation R2 logD = 0.820803
Epoch 56
Train function
Loss = 9.2358e-04, PNorm = 57.8558, GNorm = 3.0906, lr_0 = 1.0804e-04
Loss = 8.9332e-04, PNorm = 57.8602, GNorm = 3.8044, lr_0 = 1.0804e-04
Loss = 6.6454e-04, PNorm = 57.8635, GNorm = 2.1781, lr_0 = 1.0804e-04
Loss = 7.7811e-04, PNorm = 57.8688, GNorm = 1.7094, lr_0 = 1.0804e-04
Loss = 8.2151e-04, PNorm = 57.8726, GNorm = 4.1515, lr_0 = 1.0804e-04
Validation rmse logD = 0.521153
Validation R2 logD = 0.827186
Epoch 57
Train function
Loss = 7.7134e-04, PNorm = 57.8755, GNorm = 2.8779, lr_0 = 1.0804e-04
Loss = 7.3612e-04, PNorm = 57.8810, GNorm = 2.6379, lr_0 = 1.0804e-04
Loss = 9.0038e-04, PNorm = 57.8856, GNorm = 1.5045, lr_0 = 1.0804e-04
Loss = 8.5713e-04, PNorm = 57.8907, GNorm = 1.7834, lr_0 = 1.0804e-04
Loss = 8.2994e-04, PNorm = 57.8950, GNorm = 4.3387, lr_0 = 1.0804e-04
Loss = 8.9215e-04, PNorm = 57.8988, GNorm = 1.5383, lr_0 = 1.0804e-04
Validation rmse logD = 0.538201
Validation R2 logD = 0.815694
Epoch 58
Train function
Loss = 1.0486e-03, PNorm = 57.9028, GNorm = 5.4213, lr_0 = 1.0804e-04
Loss = 1.0771e-03, PNorm = 57.9062, GNorm = 4.7302, lr_0 = 1.0804e-04
Loss = 1.0661e-03, PNorm = 57.9110, GNorm = 3.9170, lr_0 = 1.0804e-04
Loss = 9.9660e-04, PNorm = 57.9155, GNorm = 1.6024, lr_0 = 1.0804e-04
Loss = 7.8665e-04, PNorm = 57.9210, GNorm = 1.9450, lr_0 = 1.0804e-04
Loss = 7.9262e-04, PNorm = 57.9252, GNorm = 2.5105, lr_0 = 1.0804e-04
Validation rmse logD = 0.539251
Validation R2 logD = 0.814974
Epoch 59
Train function
Loss = 6.4253e-04, PNorm = 57.9294, GNorm = 1.4353, lr_0 = 1.0804e-04
Loss = 8.1304e-04, PNorm = 57.9353, GNorm = 2.8664, lr_0 = 1.0804e-04
Loss = 7.1237e-04, PNorm = 57.9388, GNorm = 0.9083, lr_0 = 1.0804e-04
Loss = 7.0009e-04, PNorm = 57.9430, GNorm = 1.2911, lr_0 = 1.0804e-04
Loss = 8.1869e-04, PNorm = 57.9455, GNorm = 3.3530, lr_0 = 1.0804e-04
Validation rmse logD = 0.532631
Validation R2 logD = 0.819489
Epoch 60
Train function
Loss = 7.1674e-04, PNorm = 57.9510, GNorm = 2.8097, lr_0 = 1.0804e-04
Loss = 8.6562e-04, PNorm = 57.9575, GNorm = 4.4629, lr_0 = 1.0804e-04
Loss = 1.0702e-03, PNorm = 57.9614, GNorm = 5.0970, lr_0 = 1.0804e-04
Loss = 1.3670e-03, PNorm = 57.9661, GNorm = 8.7633, lr_0 = 1.0804e-04
Loss = 1.1703e-03, PNorm = 57.9706, GNorm = 3.8995, lr_0 = 1.0804e-04
Loss = 1.0099e-03, PNorm = 57.9765, GNorm = 5.0748, lr_0 = 1.0804e-04
Validation rmse logD = 0.538487
Validation R2 logD = 0.815498
Epoch 61
Train function
Loss = 7.5578e-04, PNorm = 57.9823, GNorm = 0.9145, lr_0 = 1.0804e-04
Loss = 6.4485e-04, PNorm = 57.9858, GNorm = 0.9594, lr_0 = 1.0804e-04
Loss = 7.6261e-04, PNorm = 57.9896, GNorm = 2.1588, lr_0 = 1.0804e-04
Loss = 8.1540e-04, PNorm = 57.9938, GNorm = 6.4787, lr_0 = 1.0804e-04
Loss = 8.0862e-04, PNorm = 57.9977, GNorm = 1.8624, lr_0 = 1.0804e-04
Loss = 8.4392e-04, PNorm = 58.0021, GNorm = 4.6773, lr_0 = 1.0804e-04
Validation rmse logD = 0.538026
Validation R2 logD = 0.815814
Epoch 62
Train function
Loss = 8.1735e-04, PNorm = 58.0058, GNorm = 3.9697, lr_0 = 1.0804e-04
Loss = 9.6047e-04, PNorm = 58.0095, GNorm = 1.6045, lr_0 = 1.0804e-04
Loss = 7.3522e-04, PNorm = 58.0134, GNorm = 3.1077, lr_0 = 1.0804e-04
Loss = 8.2156e-04, PNorm = 58.0185, GNorm = 1.9237, lr_0 = 1.0804e-04
Loss = 7.6878e-04, PNorm = 58.0224, GNorm = 3.6109, lr_0 = 1.0804e-04
Validation rmse logD = 0.533757
Validation R2 logD = 0.818725
Epoch 63
Train function
Loss = 8.7444e-04, PNorm = 58.0283, GNorm = 4.7293, lr_0 = 1.0804e-04
Loss = 5.7489e-04, PNorm = 58.0319, GNorm = 1.3108, lr_0 = 1.0804e-04
Loss = 6.7137e-04, PNorm = 58.0372, GNorm = 1.1384, lr_0 = 1.0804e-04
Loss = 5.8296e-04, PNorm = 58.0403, GNorm = 1.4265, lr_0 = 1.0804e-04
Loss = 8.1454e-04, PNorm = 58.0444, GNorm = 4.1062, lr_0 = 1.0804e-04
Loss = 1.1224e-03, PNorm = 58.0478, GNorm = 4.7149, lr_0 = 1.0804e-04
Validation rmse logD = 0.574479
Validation R2 logD = 0.790010
Epoch 64
Train function
Loss = 1.2672e-03, PNorm = 58.0521, GNorm = 5.2342, lr_0 = 1.0804e-04
Loss = 1.0911e-03, PNorm = 58.0578, GNorm = 3.9944, lr_0 = 1.0804e-04
Loss = 9.3306e-04, PNorm = 58.0627, GNorm = 4.9699, lr_0 = 1.0804e-04
Loss = 8.2092e-04, PNorm = 58.0677, GNorm = 3.3803, lr_0 = 1.0804e-04
Loss = 1.0328e-03, PNorm = 58.0722, GNorm = 1.4418, lr_0 = 1.0804e-04
Loss = 1.3046e-03, PNorm = 58.0779, GNorm = 2.3917, lr_0 = 1.0804e-04
Validation rmse logD = 0.560937
Validation R2 logD = 0.799794
Epoch 65
Train function
Loss = 8.2477e-04, PNorm = 58.0815, GNorm = 4.0429, lr_0 = 1.0804e-04
Loss = 6.2300e-04, PNorm = 58.0871, GNorm = 2.9617, lr_0 = 1.0804e-04
Loss = 7.6892e-04, PNorm = 58.0924, GNorm = 1.1809, lr_0 = 1.0804e-04
Loss = 8.1458e-04, PNorm = 58.0977, GNorm = 2.5095, lr_0 = 1.0804e-04
Loss = 9.8580e-04, PNorm = 58.0995, GNorm = 1.0949, lr_0 = 1.0804e-04
Validation rmse logD = 0.549412
Validation R2 logD = 0.807935
Epoch 66
Train function
Loss = 8.4287e-04, PNorm = 58.1038, GNorm = 1.3050, lr_0 = 1.0804e-04
Loss = 6.7186e-04, PNorm = 58.1086, GNorm = 2.4293, lr_0 = 1.0804e-04
Loss = 7.6622e-04, PNorm = 58.1123, GNorm = 1.2161, lr_0 = 1.0804e-04
Loss = 8.3063e-04, PNorm = 58.1175, GNorm = 1.8977, lr_0 = 1.0804e-04
Loss = 7.0913e-04, PNorm = 58.1212, GNorm = 1.1371, lr_0 = 1.0804e-04
Loss = 6.5155e-04, PNorm = 58.1243, GNorm = 2.7272, lr_0 = 1.0804e-04
Validation rmse logD = 0.513474
Validation R2 logD = 0.832240
Epoch 67
Train function
Loss = 5.3316e-04, PNorm = 58.1282, GNorm = 5.7322, lr_0 = 1.0804e-04
Loss = 6.1100e-04, PNorm = 58.1313, GNorm = 2.6257, lr_0 = 1.0804e-04
Loss = 5.8224e-04, PNorm = 58.1346, GNorm = 2.6135, lr_0 = 1.0804e-04
Loss = 6.5483e-04, PNorm = 58.1385, GNorm = 1.4792, lr_0 = 1.0804e-04
Loss = 8.2857e-04, PNorm = 58.1415, GNorm = 1.3709, lr_0 = 1.0804e-04
Loss = 7.9065e-04, PNorm = 58.1462, GNorm = 3.8365, lr_0 = 1.0804e-04
Validation rmse logD = 0.534263
Validation R2 logD = 0.818381
Epoch 68
Train function
Loss = 7.3390e-04, PNorm = 58.1498, GNorm = 2.8226, lr_0 = 1.0804e-04
Loss = 6.4961e-04, PNorm = 58.1534, GNorm = 1.1553, lr_0 = 1.0804e-04
Loss = 7.3393e-04, PNorm = 58.1572, GNorm = 5.6788, lr_0 = 1.0804e-04
Loss = 7.7244e-04, PNorm = 58.1613, GNorm = 3.6717, lr_0 = 1.0804e-04
Loss = 6.8238e-04, PNorm = 58.1660, GNorm = 1.9509, lr_0 = 1.0804e-04
Validation rmse logD = 0.527234
Validation R2 logD = 0.823129
Epoch 69
Train function
Loss = 6.8214e-04, PNorm = 58.1694, GNorm = 1.7478, lr_0 = 1.0804e-04
Loss = 5.5989e-04, PNorm = 58.1729, GNorm = 1.1984, lr_0 = 1.0804e-04
Loss = 7.1108e-04, PNorm = 58.1768, GNorm = 1.4350, lr_0 = 1.0804e-04
Loss = 6.9373e-04, PNorm = 58.1805, GNorm = 1.3526, lr_0 = 1.0804e-04
Loss = 8.5384e-04, PNorm = 58.1843, GNorm = 1.9851, lr_0 = 1.0804e-04
Loss = 8.3299e-04, PNorm = 58.1877, GNorm = 4.2928, lr_0 = 1.0804e-04
Validation rmse logD = 0.526387
Validation R2 logD = 0.823696
Epoch 70
Train function
Loss = 6.4528e-04, PNorm = 58.1923, GNorm = 1.5734, lr_0 = 1.0804e-04
Loss = 5.7734e-04, PNorm = 58.1963, GNorm = 3.1602, lr_0 = 1.0804e-04
Loss = 6.2323e-04, PNorm = 58.1997, GNorm = 2.3959, lr_0 = 1.0804e-04
Loss = 5.6370e-04, PNorm = 58.2025, GNorm = 2.9465, lr_0 = 1.0804e-04
Loss = 5.7239e-04, PNorm = 58.2062, GNorm = 3.2627, lr_0 = 1.0804e-04
Loss = 7.5189e-04, PNorm = 58.2083, GNorm = 5.2226, lr_0 = 1.0804e-04
Validation rmse logD = 0.547402
Validation R2 logD = 0.809338
Epoch 71
Train function
Loss = 5.5513e-04, PNorm = 58.2114, GNorm = 2.3927, lr_0 = 1.0804e-04
Loss = 5.4026e-04, PNorm = 58.2152, GNorm = 1.7929, lr_0 = 1.0804e-04
Loss = 5.0820e-04, PNorm = 58.2193, GNorm = 2.2025, lr_0 = 1.0804e-04
Loss = 5.4970e-04, PNorm = 58.2226, GNorm = 1.6449, lr_0 = 1.0804e-04
Loss = 6.2857e-04, PNorm = 58.2264, GNorm = 1.2186, lr_0 = 1.0804e-04
Validation rmse logD = 0.529809
Validation R2 logD = 0.821397
Epoch 72
Train function
Loss = 5.5192e-04, PNorm = 58.2291, GNorm = 3.0778, lr_0 = 1.0804e-04
Loss = 7.9344e-04, PNorm = 58.2324, GNorm = 5.0586, lr_0 = 1.0804e-04
Loss = 4.8534e-04, PNorm = 58.2364, GNorm = 1.2940, lr_0 = 1.0804e-04
Loss = 4.4257e-04, PNorm = 58.2392, GNorm = 0.8733, lr_0 = 1.0804e-04
Loss = 5.8504e-04, PNorm = 58.2419, GNorm = 3.2885, lr_0 = 1.0804e-04
Loss = 7.6032e-04, PNorm = 58.2446, GNorm = 9.6984, lr_0 = 1.0804e-04
Validation rmse logD = 0.544336
Validation R2 logD = 0.811469
Epoch 73
Train function
Loss = 8.4869e-04, PNorm = 58.2487, GNorm = 3.5820, lr_0 = 1.0804e-04
Loss = 8.3645e-04, PNorm = 58.2532, GNorm = 5.9445, lr_0 = 1.0804e-04
Loss = 6.2188e-04, PNorm = 58.2568, GNorm = 4.1343, lr_0 = 1.0804e-04
Loss = 5.1247e-04, PNorm = 58.2611, GNorm = 1.1580, lr_0 = 1.0804e-04
Loss = 5.7883e-04, PNorm = 58.2660, GNorm = 1.0204, lr_0 = 1.0804e-04
Loss = 6.5138e-04, PNorm = 58.2699, GNorm = 4.4937, lr_0 = 1.0804e-04
Validation rmse logD = 0.518999
Validation R2 logD = 0.828611
Epoch 74
Train function
Loss = 4.5629e-04, PNorm = 58.2729, GNorm = 4.0110, lr_0 = 1.0804e-04
Loss = 5.1904e-04, PNorm = 58.2754, GNorm = 4.6382, lr_0 = 1.0804e-04
Loss = 7.3532e-04, PNorm = 58.2787, GNorm = 3.4395, lr_0 = 1.0804e-04
Loss = 8.2345e-04, PNorm = 58.2814, GNorm = 5.8354, lr_0 = 1.0804e-04
Loss = 8.0617e-04, PNorm = 58.2868, GNorm = 1.7808, lr_0 = 1.0804e-04
Validation rmse logD = 0.512295
Validation R2 logD = 0.833010
Epoch 75
Train function
Loss = 5.8036e-04, PNorm = 58.2924, GNorm = 4.9257, lr_0 = 1.0804e-04
Loss = 5.3886e-04, PNorm = 58.2958, GNorm = 1.7412, lr_0 = 1.0804e-04
Loss = 6.6446e-04, PNorm = 58.2992, GNorm = 0.8095, lr_0 = 1.0804e-04
Loss = 4.2013e-04, PNorm = 58.3030, GNorm = 1.7726, lr_0 = 1.0804e-04
Loss = 5.7539e-04, PNorm = 58.3055, GNorm = 1.7108, lr_0 = 1.0804e-04
Loss = 6.1835e-04, PNorm = 58.3081, GNorm = 2.3254, lr_0 = 1.0804e-04
Validation rmse logD = 0.526151
Validation R2 logD = 0.823855
Epoch 76
Train function
Loss = 5.0237e-04, PNorm = 58.3118, GNorm = 2.1229, lr_0 = 1.0804e-04
Loss = 4.6669e-04, PNorm = 58.3150, GNorm = 2.7853, lr_0 = 1.0804e-04
Loss = 6.6218e-04, PNorm = 58.3183, GNorm = 2.8325, lr_0 = 1.0804e-04
Loss = 6.2366e-04, PNorm = 58.3223, GNorm = 1.1760, lr_0 = 1.0804e-04
Loss = 5.3398e-04, PNorm = 58.3256, GNorm = 1.7763, lr_0 = 1.0804e-04
Loss = 5.2562e-04, PNorm = 58.3293, GNorm = 1.8641, lr_0 = 1.0804e-04
Validation rmse logD = 0.511818
Validation R2 logD = 0.833321
Epoch 77
Train function
Loss = 4.8325e-04, PNorm = 58.3328, GNorm = 1.5575, lr_0 = 1.0804e-04
Loss = 3.9796e-04, PNorm = 58.3361, GNorm = 2.3009, lr_0 = 1.0804e-04
Loss = 5.1766e-04, PNorm = 58.3392, GNorm = 3.5365, lr_0 = 1.0804e-04
Loss = 5.0606e-04, PNorm = 58.3417, GNorm = 2.0429, lr_0 = 1.0804e-04
Loss = 7.3671e-04, PNorm = 58.3449, GNorm = 4.2062, lr_0 = 1.0804e-04
Validation rmse logD = 0.519703
Validation R2 logD = 0.828146
Epoch 78
Train function
Loss = 4.0494e-04, PNorm = 58.3487, GNorm = 2.0776, lr_0 = 1.0804e-04
Loss = 4.0699e-04, PNorm = 58.3513, GNorm = 1.0337, lr_0 = 1.0804e-04
Loss = 4.6592e-04, PNorm = 58.3549, GNorm = 0.9862, lr_0 = 1.0804e-04
Loss = 4.9217e-04, PNorm = 58.3597, GNorm = 1.2818, lr_0 = 1.0804e-04
Loss = 7.3427e-04, PNorm = 58.3634, GNorm = 2.6588, lr_0 = 1.0804e-04
Loss = 6.0650e-04, PNorm = 58.3677, GNorm = 1.9642, lr_0 = 1.0804e-04
Validation rmse logD = 0.536964
Validation R2 logD = 0.816540
Epoch 79
Train function
Loss = 4.5889e-04, PNorm = 58.3723, GNorm = 1.5324, lr_0 = 1.0804e-04
Loss = 3.7904e-04, PNorm = 58.3749, GNorm = 2.1881, lr_0 = 1.0804e-04
Loss = 4.7285e-04, PNorm = 58.3783, GNorm = 4.5329, lr_0 = 1.0804e-04
Loss = 6.1374e-04, PNorm = 58.3814, GNorm = 5.1290, lr_0 = 1.0804e-04
Loss = 6.7218e-04, PNorm = 58.3843, GNorm = 3.2485, lr_0 = 1.0804e-04
Loss = 6.0398e-04, PNorm = 58.3883, GNorm = 2.1443, lr_0 = 1.0804e-04
Validation rmse logD = 0.511178
Validation R2 logD = 0.833737
Epoch 80
Train function
Loss = 4.1646e-04, PNorm = 58.3913, GNorm = 1.0864, lr_0 = 1.0804e-04
Loss = 4.6553e-04, PNorm = 58.3937, GNorm = 2.7654, lr_0 = 1.0804e-04
Loss = 4.4705e-04, PNorm = 58.3969, GNorm = 1.6796, lr_0 = 1.0804e-04
Loss = 4.4866e-04, PNorm = 58.4003, GNorm = 1.7949, lr_0 = 1.0804e-04
Loss = 4.4893e-04, PNorm = 58.4031, GNorm = 1.6112, lr_0 = 1.0804e-04
Validation rmse logD = 0.522258
Validation R2 logD = 0.826451
Epoch 81
Train function
Loss = 4.0841e-04, PNorm = 58.4049, GNorm = 3.2094, lr_0 = 1.0804e-04
Loss = 4.8553e-04, PNorm = 58.4074, GNorm = 1.4888, lr_0 = 1.0804e-04
Loss = 5.8272e-04, PNorm = 58.4115, GNorm = 0.8655, lr_0 = 1.0804e-04
Loss = 4.0431e-04, PNorm = 58.4149, GNorm = 0.8337, lr_0 = 1.0804e-04
Loss = 3.4334e-04, PNorm = 58.4177, GNorm = 2.4215, lr_0 = 1.0804e-04
Loss = 3.7042e-04, PNorm = 58.4201, GNorm = 1.4106, lr_0 = 1.0804e-04
Validation rmse logD = 0.525374
Validation R2 logD = 0.824375
Epoch 82
Train function
Loss = 7.1348e-04, PNorm = 58.4243, GNorm = 4.0295, lr_0 = 1.0804e-04
Loss = 4.8089e-04, PNorm = 58.4276, GNorm = 2.0707, lr_0 = 1.0804e-04
Loss = 4.6447e-04, PNorm = 58.4313, GNorm = 2.8170, lr_0 = 1.0804e-04
Loss = 3.9030e-04, PNorm = 58.4350, GNorm = 3.1000, lr_0 = 1.0804e-04
Loss = 5.3069e-04, PNorm = 58.4382, GNorm = 2.6234, lr_0 = 1.0804e-04
Loss = 4.9282e-04, PNorm = 58.4411, GNorm = 3.9319, lr_0 = 1.0804e-04
Validation rmse logD = 0.520771
Validation R2 logD = 0.827439
Epoch 83
Train function
Loss = 3.4741e-04, PNorm = 58.4435, GNorm = 0.6977, lr_0 = 1.0804e-04
Loss = 3.8586e-04, PNorm = 58.4462, GNorm = 3.7639, lr_0 = 1.0804e-04
Loss = 3.7617e-04, PNorm = 58.4486, GNorm = 3.0485, lr_0 = 1.0804e-04
Loss = 4.3514e-04, PNorm = 58.4522, GNorm = 3.0490, lr_0 = 1.0804e-04
Loss = 4.7778e-04, PNorm = 58.4549, GNorm = 1.8505, lr_0 = 1.0804e-04
Validation rmse logD = 0.521726
Validation R2 logD = 0.826805
Epoch 84
Train function
Loss = 4.1593e-04, PNorm = 58.4575, GNorm = 1.8275, lr_0 = 1.0804e-04
Loss = 4.0978e-04, PNorm = 58.4613, GNorm = 2.7059, lr_0 = 1.0804e-04
Loss = 6.3744e-04, PNorm = 58.4648, GNorm = 3.2874, lr_0 = 1.0804e-04
Loss = 4.3405e-04, PNorm = 58.4679, GNorm = 0.9597, lr_0 = 1.0804e-04
Loss = 4.1945e-04, PNorm = 58.4718, GNorm = 1.4114, lr_0 = 1.0804e-04
Loss = 4.1254e-04, PNorm = 58.4761, GNorm = 1.0014, lr_0 = 1.0804e-04
Validation rmse logD = 0.515406
Validation R2 logD = 0.830976
Epoch 85
Train function
Loss = 4.6963e-04, PNorm = 58.4777, GNorm = 2.4253, lr_0 = 1.0804e-04
Loss = 3.7401e-04, PNorm = 58.4809, GNorm = 1.1530, lr_0 = 1.0804e-04
Loss = 4.1132e-04, PNorm = 58.4850, GNorm = 1.1218, lr_0 = 1.0804e-04
Loss = 3.6146e-04, PNorm = 58.4872, GNorm = 1.7024, lr_0 = 1.0804e-04
Loss = 5.5886e-04, PNorm = 58.4906, GNorm = 7.0131, lr_0 = 1.0804e-04
Loss = 6.4410e-04, PNorm = 58.4941, GNorm = 1.5274, lr_0 = 1.0804e-04
Validation rmse logD = 0.521479
Validation R2 logD = 0.826969
Epoch 86
Train function
Loss = 4.2063e-04, PNorm = 58.4988, GNorm = 1.4686, lr_0 = 1.0804e-04
Loss = 3.9806e-04, PNorm = 58.5024, GNorm = 2.5277, lr_0 = 1.0804e-04
Loss = 4.5225e-04, PNorm = 58.5056, GNorm = 2.1063, lr_0 = 1.0804e-04
Loss = 3.4937e-04, PNorm = 58.5088, GNorm = 1.6502, lr_0 = 1.0804e-04
Loss = 4.3148e-04, PNorm = 58.5117, GNorm = 0.8450, lr_0 = 1.0804e-04
Validation rmse logD = 0.507991
Validation R2 logD = 0.835804
Epoch 87
Train function
Loss = 3.4454e-04, PNorm = 58.5138, GNorm = 1.0168, lr_0 = 1.0804e-04
Loss = 3.9384e-04, PNorm = 58.5157, GNorm = 1.7132, lr_0 = 1.0804e-04
Loss = 4.9159e-04, PNorm = 58.5184, GNorm = 5.0743, lr_0 = 1.0804e-04
Loss = 4.8865e-04, PNorm = 58.5218, GNorm = 0.9972, lr_0 = 1.0804e-04
Loss = 4.4891e-04, PNorm = 58.5251, GNorm = 4.2298, lr_0 = 1.0804e-04
Loss = 4.8392e-04, PNorm = 58.5276, GNorm = 1.0475, lr_0 = 1.0804e-04
Validation rmse logD = 0.517744
Validation R2 logD = 0.829439
Epoch 88
Train function
Loss = 7.0045e-04, PNorm = 58.5306, GNorm = 8.1436, lr_0 = 1.0804e-04
Loss = 6.9396e-04, PNorm = 58.5334, GNorm = 1.1031, lr_0 = 1.0804e-04
Loss = 4.5506e-04, PNorm = 58.5390, GNorm = 1.5167, lr_0 = 1.0804e-04
Loss = 3.4890e-04, PNorm = 58.5430, GNorm = 0.8551, lr_0 = 1.0804e-04
Loss = 3.4761e-04, PNorm = 58.5466, GNorm = 1.1506, lr_0 = 1.0804e-04
Loss = 3.4104e-04, PNorm = 58.5488, GNorm = 1.9056, lr_0 = 1.0804e-04
Loss = 9.7237e-04, PNorm = 58.5491, GNorm = 1.5150, lr_0 = 1.0804e-04
Validation rmse logD = 0.510710
Validation R2 logD = 0.834042
Epoch 89
Train function
Loss = 2.6764e-04, PNorm = 58.5514, GNorm = 2.2329, lr_0 = 1.0804e-04
Loss = 3.3943e-04, PNorm = 58.5544, GNorm = 3.2742, lr_0 = 1.0804e-04
Loss = 6.8802e-04, PNorm = 58.5570, GNorm = 5.2352, lr_0 = 1.0804e-04
Loss = 7.5357e-04, PNorm = 58.5593, GNorm = 2.2371, lr_0 = 1.0804e-04
Loss = 8.4710e-04, PNorm = 58.5642, GNorm = 7.0259, lr_0 = 1.0804e-04
Validation rmse logD = 0.551785
Validation R2 logD = 0.806273
Epoch 90
Train function
Loss = 9.6901e-04, PNorm = 58.5676, GNorm = 6.9048, lr_0 = 1.0804e-04
Loss = 6.6885e-04, PNorm = 58.5718, GNorm = 3.9125, lr_0 = 1.0804e-04
Loss = 5.0745e-04, PNorm = 58.5777, GNorm = 3.3218, lr_0 = 1.0804e-04
Loss = 4.4494e-04, PNorm = 58.5826, GNorm = 1.6265, lr_0 = 1.0804e-04
Loss = 4.6326e-04, PNorm = 58.5857, GNorm = 1.9455, lr_0 = 1.0804e-04
Loss = 4.9845e-04, PNorm = 58.5894, GNorm = 3.2027, lr_0 = 1.0804e-04
Validation rmse logD = 0.520341
Validation R2 logD = 0.827723
Epoch 91
Train function
Loss = 3.3960e-04, PNorm = 58.5928, GNorm = 1.4146, lr_0 = 1.0804e-04
Loss = 6.0377e-04, PNorm = 58.5958, GNorm = 5.3068, lr_0 = 1.0804e-04
Loss = 6.2225e-04, PNorm = 58.5990, GNorm = 6.1204, lr_0 = 1.0804e-04
Loss = 5.1527e-04, PNorm = 58.6030, GNorm = 1.3254, lr_0 = 1.0804e-04
Loss = 6.3387e-04, PNorm = 58.6066, GNorm = 4.5627, lr_0 = 1.0804e-04
Loss = 6.2611e-04, PNorm = 58.6110, GNorm = 5.5140, lr_0 = 1.0804e-04
Loss = 7.1215e-04, PNorm = 58.6115, GNorm = 2.5956, lr_0 = 1.0804e-04
Validation rmse logD = 0.531340
Validation R2 logD = 0.820363
Epoch 92
Train function
Loss = 5.8944e-04, PNorm = 58.6142, GNorm = 2.3991, lr_0 = 1.0804e-04
Loss = 5.4003e-04, PNorm = 58.6176, GNorm = 1.3926, lr_0 = 1.0804e-04
Loss = 4.3383e-04, PNorm = 58.6210, GNorm = 0.9825, lr_0 = 1.0804e-04
Loss = 5.4053e-04, PNorm = 58.6247, GNorm = 2.6799, lr_0 = 1.0804e-04
Loss = 6.6461e-04, PNorm = 58.6269, GNorm = 4.8479, lr_0 = 1.0804e-04
Validation rmse logD = 0.538875
Validation R2 logD = 0.815232
Epoch 93
Train function
Loss = 5.5096e-04, PNorm = 58.6297, GNorm = 2.1620, lr_0 = 1.0804e-04
Loss = 4.0122e-04, PNorm = 58.6341, GNorm = 1.5698, lr_0 = 1.0804e-04
Loss = 3.4356e-04, PNorm = 58.6375, GNorm = 1.8277, lr_0 = 1.0804e-04
Loss = 6.6088e-04, PNorm = 58.6399, GNorm = 2.6605, lr_0 = 1.0804e-04
Loss = 5.9874e-04, PNorm = 58.6433, GNorm = 2.5707, lr_0 = 1.0804e-04
Loss = 4.8366e-04, PNorm = 58.6467, GNorm = 1.9126, lr_0 = 1.0804e-04
Validation rmse logD = 0.518209
Validation R2 logD = 0.829132
Epoch 94
Train function
Loss = 5.0265e-04, PNorm = 58.6504, GNorm = 1.7087, lr_0 = 1.0804e-04
Loss = 4.3858e-04, PNorm = 58.6554, GNorm = 4.3442, lr_0 = 1.0804e-04
Loss = 4.3425e-04, PNorm = 58.6592, GNorm = 1.9110, lr_0 = 1.0804e-04
Loss = 4.2231e-04, PNorm = 58.6622, GNorm = 2.4096, lr_0 = 1.0804e-04
Loss = 3.5637e-04, PNorm = 58.6652, GNorm = 1.2329, lr_0 = 1.0804e-04
Loss = 3.5042e-04, PNorm = 58.6688, GNorm = 2.1836, lr_0 = 1.0804e-04
Loss = 4.0143e-04, PNorm = 58.6690, GNorm = 2.1587, lr_0 = 1.0804e-04
Validation rmse logD = 0.503439
Validation R2 logD = 0.838734
Epoch 95
Train function
Loss = 3.1387e-04, PNorm = 58.6707, GNorm = 0.8092, lr_0 = 1.0804e-04
Loss = 3.5292e-04, PNorm = 58.6720, GNorm = 1.3059, lr_0 = 1.0804e-04
Loss = 2.9091e-04, PNorm = 58.6749, GNorm = 1.3832, lr_0 = 1.0804e-04
Loss = 2.8736e-04, PNorm = 58.6763, GNorm = 0.8594, lr_0 = 1.0804e-04
Loss = 2.8967e-04, PNorm = 58.6797, GNorm = 0.8785, lr_0 = 1.0804e-04
Validation rmse logD = 0.506456
Validation R2 logD = 0.836795
Epoch 96
Train function
Loss = 2.3758e-04, PNorm = 58.6813, GNorm = 1.1401, lr_0 = 1.0804e-04
Loss = 2.6517e-04, PNorm = 58.6835, GNorm = 1.1447, lr_0 = 1.0804e-04
Loss = 2.9386e-04, PNorm = 58.6853, GNorm = 2.1047, lr_0 = 1.0804e-04
Loss = 3.7894e-04, PNorm = 58.6870, GNorm = 1.1238, lr_0 = 1.0804e-04
Loss = 3.6292e-04, PNorm = 58.6895, GNorm = 2.7006, lr_0 = 1.0804e-04
Loss = 3.9871e-04, PNorm = 58.6928, GNorm = 3.0635, lr_0 = 1.0804e-04
Validation rmse logD = 0.509701
Validation R2 logD = 0.834697
Epoch 97
Train function
Loss = 3.6063e-04, PNorm = 58.6940, GNorm = 0.9442, lr_0 = 1.0804e-04
Loss = 3.6446e-04, PNorm = 58.6962, GNorm = 3.5589, lr_0 = 1.0804e-04
Loss = 2.8851e-04, PNorm = 58.6999, GNorm = 0.6540, lr_0 = 1.0804e-04
Loss = 3.3854e-04, PNorm = 58.7029, GNorm = 3.6743, lr_0 = 1.0804e-04
Loss = 5.0211e-04, PNorm = 58.7058, GNorm = 5.1163, lr_0 = 1.0804e-04
Loss = 4.8345e-04, PNorm = 58.7091, GNorm = 2.9549, lr_0 = 1.0804e-04
Loss = 7.1738e-04, PNorm = 58.7093, GNorm = 1.5087, lr_0 = 1.0804e-04
Validation rmse logD = 0.522109
Validation R2 logD = 0.826550
Epoch 98
Train function
Loss = 3.3822e-04, PNorm = 58.7124, GNorm = 1.5649, lr_0 = 1.0804e-04
Loss = 2.9626e-04, PNorm = 58.7157, GNorm = 1.9726, lr_0 = 1.0804e-04
Loss = 3.8080e-04, PNorm = 58.7175, GNorm = 3.8495, lr_0 = 1.0804e-04
Loss = 4.6885e-04, PNorm = 58.7194, GNorm = 3.7527, lr_0 = 1.0804e-04
Loss = 4.0227e-04, PNorm = 58.7225, GNorm = 3.9945, lr_0 = 1.0804e-04
Validation rmse logD = 0.509810
Validation R2 logD = 0.834626
Epoch 99
Train function
Loss = 5.1348e-04, PNorm = 58.7245, GNorm = 0.9223, lr_0 = 1.0804e-04
Loss = 3.9110e-04, PNorm = 58.7270, GNorm = 3.4431, lr_0 = 1.0804e-04
Loss = 4.0918e-04, PNorm = 58.7302, GNorm = 1.0488, lr_0 = 1.0804e-04
Loss = 2.9378e-04, PNorm = 58.7330, GNorm = 1.3916, lr_0 = 1.0804e-04
Loss = 3.1233e-04, PNorm = 58.7359, GNorm = 2.7486, lr_0 = 1.0804e-04
Loss = 3.2634e-04, PNorm = 58.7387, GNorm = 2.2860, lr_0 = 1.0804e-04
Validation rmse logD = 0.506178
Validation R2 logD = 0.836974
Model 0 best validation rmse = 0.503439 on epoch 94
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.584713
Model 0 test R2 logD = 0.788337
Ensemble test rmse  logD= 0.584713
Ensemble test R2  logD= 0.788337
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2832,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.0400e-02, PNorm = 55.5555, GNorm = 3.7385, lr_0 = 1.0804e-04
Loss = 1.8360e-02, PNorm = 55.5582, GNorm = 2.6442, lr_0 = 1.0804e-04
Loss = 1.8396e-02, PNorm = 55.5612, GNorm = 3.4408, lr_0 = 1.0804e-04
Loss = 1.5440e-02, PNorm = 55.5643, GNorm = 2.2422, lr_0 = 1.0804e-04
Loss = 1.5795e-02, PNorm = 55.5679, GNorm = 2.2788, lr_0 = 1.0804e-04
Validation rmse logD = 1.055304
Validation R2 logD = 0.245005
Epoch 1
Train function
Loss = 1.3651e-02, PNorm = 55.5729, GNorm = 4.5173, lr_0 = 1.0804e-04
Loss = 1.6034e-02, PNorm = 55.5782, GNorm = 1.2692, lr_0 = 1.0804e-04
Loss = 1.5432e-02, PNorm = 55.5841, GNorm = 1.9766, lr_0 = 1.0804e-04
Loss = 1.4430e-02, PNorm = 55.5904, GNorm = 1.5475, lr_0 = 1.0804e-04
Loss = 1.4317e-02, PNorm = 55.5979, GNorm = 2.0433, lr_0 = 1.0804e-04
Loss = 1.4474e-02, PNorm = 55.6059, GNorm = 8.1136, lr_0 = 1.0804e-04
Validation rmse logD = 1.003032
Validation R2 logD = 0.317946
Epoch 2
Train function
Loss = 1.3799e-02, PNorm = 55.6157, GNorm = 1.2503, lr_0 = 1.0804e-04
Loss = 1.3188e-02, PNorm = 55.6264, GNorm = 6.7693, lr_0 = 1.0804e-04
Loss = 1.2004e-02, PNorm = 55.6366, GNorm = 1.8254, lr_0 = 1.0804e-04
Loss = 1.2390e-02, PNorm = 55.6467, GNorm = 5.0079, lr_0 = 1.0804e-04
Loss = 1.2918e-02, PNorm = 55.6581, GNorm = 4.4975, lr_0 = 1.0804e-04
Validation rmse logD = 0.937296
Validation R2 logD = 0.404417
Epoch 3
Train function
Loss = 1.1868e-02, PNorm = 55.6709, GNorm = 4.7437, lr_0 = 1.0804e-04
Loss = 1.1921e-02, PNorm = 55.6836, GNorm = 3.5882, lr_0 = 1.0804e-04
Loss = 1.0766e-02, PNorm = 55.6934, GNorm = 2.9910, lr_0 = 1.0804e-04
Loss = 1.2119e-02, PNorm = 55.7022, GNorm = 7.8303, lr_0 = 1.0804e-04
Loss = 1.2599e-02, PNorm = 55.7125, GNorm = 11.8637, lr_0 = 1.0804e-04
Loss = 1.1842e-02, PNorm = 55.7253, GNorm = 6.0421, lr_0 = 1.0804e-04
Validation rmse logD = 0.897857
Validation R2 logD = 0.453483
Epoch 4
Train function
Loss = 1.1579e-02, PNorm = 55.7378, GNorm = 4.6526, lr_0 = 1.0804e-04
Loss = 1.1196e-02, PNorm = 55.7493, GNorm = 1.7407, lr_0 = 1.0804e-04
Loss = 1.2665e-02, PNorm = 55.7601, GNorm = 5.4354, lr_0 = 1.0804e-04
Loss = 1.1329e-02, PNorm = 55.7721, GNorm = 2.1708, lr_0 = 1.0804e-04
Loss = 1.0148e-02, PNorm = 55.7847, GNorm = 2.7527, lr_0 = 1.0804e-04
Loss = 9.4296e-03, PNorm = 55.7973, GNorm = 2.0330, lr_0 = 1.0804e-04
Validation rmse logD = 0.871702
Validation R2 logD = 0.484860
Epoch 5
Train function
Loss = 9.0347e-03, PNorm = 55.8083, GNorm = 5.0058, lr_0 = 1.0804e-04
Loss = 9.7422e-03, PNorm = 55.8197, GNorm = 2.5155, lr_0 = 1.0804e-04
Loss = 9.8263e-03, PNorm = 55.8324, GNorm = 3.9916, lr_0 = 1.0804e-04
Loss = 1.0227e-02, PNorm = 55.8437, GNorm = 5.5275, lr_0 = 1.0804e-04
Loss = 9.0867e-03, PNorm = 55.8575, GNorm = 6.3348, lr_0 = 1.0804e-04
Validation rmse logD = 0.845398
Validation R2 logD = 0.515481
Epoch 6
Train function
Loss = 5.4400e-03, PNorm = 55.8735, GNorm = 4.9425, lr_0 = 1.0804e-04
Loss = 9.8893e-03, PNorm = 55.8875, GNorm = 6.9357, lr_0 = 1.0804e-04
Loss = 8.3257e-03, PNorm = 55.9010, GNorm = 5.5084, lr_0 = 1.0804e-04
Loss = 1.0096e-02, PNorm = 55.9147, GNorm = 5.9082, lr_0 = 1.0804e-04
Loss = 9.3306e-03, PNorm = 55.9254, GNorm = 6.3028, lr_0 = 1.0804e-04
Loss = 8.7811e-03, PNorm = 55.9369, GNorm = 2.3388, lr_0 = 1.0804e-04
Validation rmse logD = 0.880983
Validation R2 logD = 0.473833
Epoch 7
Train function
Loss = 6.5410e-03, PNorm = 55.9491, GNorm = 1.5171, lr_0 = 1.0804e-04
Loss = 7.5027e-03, PNorm = 55.9602, GNorm = 2.8294, lr_0 = 1.0804e-04
Loss = 7.8215e-03, PNorm = 55.9749, GNorm = 2.2327, lr_0 = 1.0804e-04
Loss = 7.8228e-03, PNorm = 55.9886, GNorm = 4.0561, lr_0 = 1.0804e-04
Loss = 9.0502e-03, PNorm = 55.9990, GNorm = 9.1181, lr_0 = 1.0804e-04
Loss = 9.1615e-03, PNorm = 56.0094, GNorm = 2.0819, lr_0 = 1.0804e-04
Validation rmse logD = 0.938960
Validation R2 logD = 0.402300
Epoch 8
Train function
Loss = 7.1166e-03, PNorm = 56.0210, GNorm = 2.0500, lr_0 = 1.0804e-04
Loss = 8.0815e-03, PNorm = 56.0325, GNorm = 1.1600, lr_0 = 1.0804e-04
Loss = 7.2298e-03, PNorm = 56.0446, GNorm = 1.5816, lr_0 = 1.0804e-04
Loss = 6.6058e-03, PNorm = 56.0584, GNorm = 3.0243, lr_0 = 1.0804e-04
Loss = 7.8368e-03, PNorm = 56.0682, GNorm = 5.5182, lr_0 = 1.0804e-04
Validation rmse logD = 0.778051
Validation R2 logD = 0.589602
Epoch 9
Train function
Loss = 4.6225e-03, PNorm = 56.0802, GNorm = 1.1768, lr_0 = 1.0804e-04
Loss = 6.5423e-03, PNorm = 56.0936, GNorm = 4.1554, lr_0 = 1.0804e-04
Loss = 7.0291e-03, PNorm = 56.1067, GNorm = 7.9225, lr_0 = 1.0804e-04
Loss = 7.7932e-03, PNorm = 56.1168, GNorm = 2.3722, lr_0 = 1.0804e-04
Loss = 7.0773e-03, PNorm = 56.1287, GNorm = 4.0093, lr_0 = 1.0804e-04
Loss = 7.4349e-03, PNorm = 56.1394, GNorm = 3.1568, lr_0 = 1.0804e-04
Validation rmse logD = 0.742064
Validation R2 logD = 0.626689
Epoch 10
Train function
Loss = 6.2767e-03, PNorm = 56.1474, GNorm = 4.4201, lr_0 = 1.0804e-04
Loss = 6.9412e-03, PNorm = 56.1572, GNorm = 2.7794, lr_0 = 1.0804e-04
Loss = 6.5314e-03, PNorm = 56.1693, GNorm = 8.7333, lr_0 = 1.0804e-04
Loss = 6.2780e-03, PNorm = 56.1809, GNorm = 2.2259, lr_0 = 1.0804e-04
Loss = 4.9421e-03, PNorm = 56.1929, GNorm = 3.3589, lr_0 = 1.0804e-04
Loss = 5.7515e-03, PNorm = 56.2020, GNorm = 3.0665, lr_0 = 1.0804e-04
Validation rmse logD = 0.762767
Validation R2 logD = 0.605567
Epoch 11
Train function
Loss = 5.8630e-03, PNorm = 56.2130, GNorm = 3.9759, lr_0 = 1.0804e-04
Loss = 5.8637e-03, PNorm = 56.2254, GNorm = 7.0851, lr_0 = 1.0804e-04
Loss = 5.6597e-03, PNorm = 56.2337, GNorm = 6.5861, lr_0 = 1.0804e-04
Loss = 5.2914e-03, PNorm = 56.2440, GNorm = 1.6093, lr_0 = 1.0804e-04
Loss = 6.3695e-03, PNorm = 56.2519, GNorm = 2.3905, lr_0 = 1.0804e-04
Validation rmse logD = 0.709859
Validation R2 logD = 0.658388
Epoch 12
Train function
Loss = 9.4332e-03, PNorm = 56.2622, GNorm = 3.7337, lr_0 = 1.0804e-04
Loss = 5.2648e-03, PNorm = 56.2750, GNorm = 8.4102, lr_0 = 1.0804e-04
Loss = 5.3806e-03, PNorm = 56.2865, GNorm = 2.8988, lr_0 = 1.0804e-04
Loss = 4.8341e-03, PNorm = 56.2953, GNorm = 4.5253, lr_0 = 1.0804e-04
Loss = 4.5038e-03, PNorm = 56.3039, GNorm = 2.2230, lr_0 = 1.0804e-04
Loss = 5.2807e-03, PNorm = 56.3130, GNorm = 8.5574, lr_0 = 1.0804e-04
Validation rmse logD = 0.699275
Validation R2 logD = 0.668499
Epoch 13
Train function
Loss = 4.1768e-03, PNorm = 56.3239, GNorm = 1.5512, lr_0 = 1.0804e-04
Loss = 5.0205e-03, PNorm = 56.3333, GNorm = 2.4023, lr_0 = 1.0804e-04
Loss = 5.2218e-03, PNorm = 56.3405, GNorm = 1.9589, lr_0 = 1.0804e-04
Loss = 6.0158e-03, PNorm = 56.3519, GNorm = 1.5658, lr_0 = 1.0804e-04
Loss = 5.0972e-03, PNorm = 56.3619, GNorm = 8.7823, lr_0 = 1.0804e-04
Loss = 4.4316e-03, PNorm = 56.3711, GNorm = 2.4634, lr_0 = 1.0804e-04
Validation rmse logD = 0.698879
Validation R2 logD = 0.668874
Epoch 14
Train function
Loss = 4.7431e-03, PNorm = 56.3803, GNorm = 7.3198, lr_0 = 1.0804e-04
Loss = 5.1945e-03, PNorm = 56.3913, GNorm = 3.3803, lr_0 = 1.0804e-04
Loss = 4.2731e-03, PNorm = 56.3999, GNorm = 2.4494, lr_0 = 1.0804e-04
Loss = 4.3880e-03, PNorm = 56.4098, GNorm = 1.8993, lr_0 = 1.0804e-04
Loss = 5.0487e-03, PNorm = 56.4179, GNorm = 5.8311, lr_0 = 1.0804e-04
Validation rmse logD = 0.736832
Validation R2 logD = 0.631934
Epoch 15
Train function
Loss = 3.9330e-03, PNorm = 56.4274, GNorm = 8.7534, lr_0 = 1.0804e-04
Loss = 4.3605e-03, PNorm = 56.4357, GNorm = 4.0651, lr_0 = 1.0804e-04
Loss = 5.8020e-03, PNorm = 56.4450, GNorm = 6.1879, lr_0 = 1.0804e-04
Loss = 4.9317e-03, PNorm = 56.4535, GNorm = 8.3499, lr_0 = 1.0804e-04
Loss = 4.2085e-03, PNorm = 56.4642, GNorm = 1.8823, lr_0 = 1.0804e-04
Loss = 3.8304e-03, PNorm = 56.4737, GNorm = 4.6352, lr_0 = 1.0804e-04
Validation rmse logD = 0.687786
Validation R2 logD = 0.679303
Epoch 16
Train function
Loss = 3.4332e-03, PNorm = 56.4825, GNorm = 8.0236, lr_0 = 1.0804e-04
Loss = 4.5281e-03, PNorm = 56.4916, GNorm = 1.9695, lr_0 = 1.0804e-04
Loss = 4.4226e-03, PNorm = 56.5004, GNorm = 4.4137, lr_0 = 1.0804e-04
Loss = 4.1426e-03, PNorm = 56.5092, GNorm = 2.5160, lr_0 = 1.0804e-04
Loss = 3.6235e-03, PNorm = 56.5178, GNorm = 2.9675, lr_0 = 1.0804e-04
Loss = 4.0296e-03, PNorm = 56.5261, GNorm = 2.0879, lr_0 = 1.0804e-04
Validation rmse logD = 0.671533
Validation R2 logD = 0.694280
Epoch 17
Train function
Loss = 3.6679e-03, PNorm = 56.5341, GNorm = 7.9808, lr_0 = 1.0804e-04
Loss = 3.8878e-03, PNorm = 56.5429, GNorm = 3.7353, lr_0 = 1.0804e-04
Loss = 3.5449e-03, PNorm = 56.5493, GNorm = 4.2001, lr_0 = 1.0804e-04
Loss = 4.3046e-03, PNorm = 56.5582, GNorm = 1.8163, lr_0 = 1.0804e-04
Loss = 4.5654e-03, PNorm = 56.5675, GNorm = 5.2135, lr_0 = 1.0804e-04
Validation rmse logD = 0.659139
Validation R2 logD = 0.705461
Epoch 18
Train function
Loss = 2.8803e-03, PNorm = 56.5771, GNorm = 3.8554, lr_0 = 1.0804e-04
Loss = 3.6721e-03, PNorm = 56.5856, GNorm = 3.5356, lr_0 = 1.0804e-04
Loss = 3.4762e-03, PNorm = 56.5948, GNorm = 9.2440, lr_0 = 1.0804e-04
Loss = 4.4931e-03, PNorm = 56.6019, GNorm = 4.5787, lr_0 = 1.0804e-04
Loss = 4.7401e-03, PNorm = 56.6087, GNorm = 1.8083, lr_0 = 1.0804e-04
Loss = 5.4508e-03, PNorm = 56.6159, GNorm = 3.8587, lr_0 = 1.0804e-04
Validation rmse logD = 0.659023
Validation R2 logD = 0.705565
Epoch 19
Train function
Loss = 4.4316e-03, PNorm = 56.6243, GNorm = 3.0274, lr_0 = 1.0804e-04
Loss = 3.1617e-03, PNorm = 56.6351, GNorm = 1.9649, lr_0 = 1.0804e-04
Loss = 3.6519e-03, PNorm = 56.6453, GNorm = 2.2647, lr_0 = 1.0804e-04
Loss = 3.8558e-03, PNorm = 56.6524, GNorm = 2.5393, lr_0 = 1.0804e-04
Loss = 4.0156e-03, PNorm = 56.6587, GNorm = 6.6073, lr_0 = 1.0804e-04
Loss = 3.2271e-03, PNorm = 56.6661, GNorm = 5.7859, lr_0 = 1.0804e-04
Validation rmse logD = 0.678822
Validation R2 logD = 0.687607
Epoch 20
Train function
Loss = 3.4944e-03, PNorm = 56.6737, GNorm = 1.7752, lr_0 = 1.0804e-04
Loss = 3.2599e-03, PNorm = 56.6821, GNorm = 3.5132, lr_0 = 1.0804e-04
Loss = 3.6803e-03, PNorm = 56.6906, GNorm = 2.4763, lr_0 = 1.0804e-04
Loss = 3.2039e-03, PNorm = 56.6992, GNorm = 3.2831, lr_0 = 1.0804e-04
Loss = 4.1164e-03, PNorm = 56.7053, GNorm = 6.2647, lr_0 = 1.0804e-04
Validation rmse logD = 0.653971
Validation R2 logD = 0.710061
Epoch 21
Train function
Loss = 2.6805e-03, PNorm = 56.7113, GNorm = 1.8185, lr_0 = 1.0804e-04
Loss = 3.4960e-03, PNorm = 56.7199, GNorm = 4.7210, lr_0 = 1.0804e-04
Loss = 3.1015e-03, PNorm = 56.7269, GNorm = 1.7139, lr_0 = 1.0804e-04
Loss = 3.5120e-03, PNorm = 56.7360, GNorm = 3.1103, lr_0 = 1.0804e-04
Loss = 3.7637e-03, PNorm = 56.7446, GNorm = 2.4769, lr_0 = 1.0804e-04
Loss = 3.4358e-03, PNorm = 56.7527, GNorm = 5.2144, lr_0 = 1.0804e-04
Validation rmse logD = 0.638427
Validation R2 logD = 0.723681
Epoch 22
Train function
Loss = 3.1796e-03, PNorm = 56.7592, GNorm = 2.4463, lr_0 = 1.0804e-04
Loss = 3.2504e-03, PNorm = 56.7680, GNorm = 5.5871, lr_0 = 1.0804e-04
Loss = 2.8415e-03, PNorm = 56.7738, GNorm = 5.9948, lr_0 = 1.0804e-04
Loss = 3.1047e-03, PNorm = 56.7821, GNorm = 5.3705, lr_0 = 1.0804e-04
Loss = 2.6200e-03, PNorm = 56.7880, GNorm = 3.5886, lr_0 = 1.0804e-04
Loss = 3.3469e-03, PNorm = 56.7936, GNorm = 2.4908, lr_0 = 1.0804e-04
Validation rmse logD = 0.636845
Validation R2 logD = 0.725049
Epoch 23
Train function
Loss = 2.6533e-03, PNorm = 56.8014, GNorm = 1.5195, lr_0 = 1.0804e-04
Loss = 2.3237e-03, PNorm = 56.8083, GNorm = 2.0992, lr_0 = 1.0804e-04
Loss = 3.0755e-03, PNorm = 56.8150, GNorm = 6.5767, lr_0 = 1.0804e-04
Loss = 2.9314e-03, PNorm = 56.8221, GNorm = 5.4629, lr_0 = 1.0804e-04
Loss = 2.4591e-03, PNorm = 56.8298, GNorm = 3.1452, lr_0 = 1.0804e-04
Validation rmse logD = 0.632907
Validation R2 logD = 0.728438
Epoch 24
Train function
Loss = 1.6516e-03, PNorm = 56.8390, GNorm = 3.5708, lr_0 = 1.0804e-04
Loss = 2.8344e-03, PNorm = 56.8448, GNorm = 4.0231, lr_0 = 1.0804e-04
Loss = 2.6022e-03, PNorm = 56.8518, GNorm = 1.7665, lr_0 = 1.0804e-04
Loss = 2.8024e-03, PNorm = 56.8588, GNorm = 1.8961, lr_0 = 1.0804e-04
Loss = 2.9234e-03, PNorm = 56.8652, GNorm = 1.3141, lr_0 = 1.0804e-04
Loss = 3.1409e-03, PNorm = 56.8717, GNorm = 5.1010, lr_0 = 1.0804e-04
Validation rmse logD = 0.623851
Validation R2 logD = 0.736154
Epoch 25
Train function
Loss = 2.3376e-03, PNorm = 56.8788, GNorm = 1.5193, lr_0 = 1.0804e-04
Loss = 2.0691e-03, PNorm = 56.8860, GNorm = 3.2378, lr_0 = 1.0804e-04
Loss = 2.7698e-03, PNorm = 56.8941, GNorm = 2.4451, lr_0 = 1.0804e-04
Loss = 3.1906e-03, PNorm = 56.9015, GNorm = 8.4381, lr_0 = 1.0804e-04
Loss = 2.7451e-03, PNorm = 56.9067, GNorm = 1.4622, lr_0 = 1.0804e-04
Loss = 2.6300e-03, PNorm = 56.9154, GNorm = 3.5268, lr_0 = 1.0804e-04
Validation rmse logD = 0.648922
Validation R2 logD = 0.714521
Epoch 26
Train function
Loss = 2.2489e-03, PNorm = 56.9232, GNorm = 4.6836, lr_0 = 1.0804e-04
Loss = 2.6663e-03, PNorm = 56.9288, GNorm = 8.2030, lr_0 = 1.0804e-04
Loss = 3.6785e-03, PNorm = 56.9354, GNorm = 10.4356, lr_0 = 1.0804e-04
Loss = 3.6566e-03, PNorm = 56.9440, GNorm = 9.0329, lr_0 = 1.0804e-04
Loss = 3.6544e-03, PNorm = 56.9520, GNorm = 6.7895, lr_0 = 1.0804e-04
Validation rmse logD = 0.647389
Validation R2 logD = 0.715868
Epoch 27
Train function
Loss = 2.6356e-03, PNorm = 56.9600, GNorm = 2.3411, lr_0 = 1.0804e-04
Loss = 2.3760e-03, PNorm = 56.9695, GNorm = 2.5448, lr_0 = 1.0804e-04
Loss = 2.3599e-03, PNorm = 56.9773, GNorm = 3.3132, lr_0 = 1.0804e-04
Loss = 2.4931e-03, PNorm = 56.9857, GNorm = 8.0421, lr_0 = 1.0804e-04
Loss = 2.3496e-03, PNorm = 56.9932, GNorm = 2.8285, lr_0 = 1.0804e-04
Loss = 2.5845e-03, PNorm = 56.9982, GNorm = 2.4722, lr_0 = 1.0804e-04
Validation rmse logD = 0.638809
Validation R2 logD = 0.723349
Epoch 28
Train function
Loss = 2.2125e-03, PNorm = 57.0047, GNorm = 3.3115, lr_0 = 1.0804e-04
Loss = 1.8072e-03, PNorm = 57.0120, GNorm = 1.7106, lr_0 = 1.0804e-04
Loss = 2.2688e-03, PNorm = 57.0175, GNorm = 4.6314, lr_0 = 1.0804e-04
Loss = 2.8409e-03, PNorm = 57.0228, GNorm = 8.5968, lr_0 = 1.0804e-04
Loss = 2.4027e-03, PNorm = 57.0276, GNorm = 7.3060, lr_0 = 1.0804e-04
Loss = 2.2918e-03, PNorm = 57.0350, GNorm = 1.6034, lr_0 = 1.0804e-04
Validation rmse logD = 0.638572
Validation R2 logD = 0.723555
Epoch 29
Train function
Loss = 1.7703e-03, PNorm = 57.0417, GNorm = 4.8505, lr_0 = 1.0804e-04
Loss = 2.4530e-03, PNorm = 57.0479, GNorm = 2.3755, lr_0 = 1.0804e-04
Loss = 2.3963e-03, PNorm = 57.0546, GNorm = 5.1906, lr_0 = 1.0804e-04
Loss = 2.0503e-03, PNorm = 57.0605, GNorm = 2.5082, lr_0 = 1.0804e-04
Loss = 1.8947e-03, PNorm = 57.0678, GNorm = 2.0353, lr_0 = 1.0804e-04
Validation rmse logD = 0.636301
Validation R2 logD = 0.725518
Epoch 30
Train function
Loss = 1.4772e-03, PNorm = 57.0767, GNorm = 2.4705, lr_0 = 1.0804e-04
Loss = 2.1557e-03, PNorm = 57.0833, GNorm = 2.2878, lr_0 = 1.0804e-04
Loss = 2.3110e-03, PNorm = 57.0903, GNorm = 2.8392, lr_0 = 1.0804e-04
Loss = 1.8706e-03, PNorm = 57.0971, GNorm = 1.6160, lr_0 = 1.0804e-04
Loss = 1.8727e-03, PNorm = 57.1017, GNorm = 4.4476, lr_0 = 1.0804e-04
Loss = 2.5455e-03, PNorm = 57.1068, GNorm = 6.7691, lr_0 = 1.0804e-04
Validation rmse logD = 0.713382
Validation R2 logD = 0.654989
Epoch 31
Train function
Loss = 2.7199e-03, PNorm = 57.1137, GNorm = 5.9990, lr_0 = 1.0804e-04
Loss = 1.7911e-03, PNorm = 57.1207, GNorm = 4.2923, lr_0 = 1.0804e-04
Loss = 2.3232e-03, PNorm = 57.1267, GNorm = 5.0115, lr_0 = 1.0804e-04
Loss = 1.9678e-03, PNorm = 57.1330, GNorm = 6.3877, lr_0 = 1.0804e-04
Loss = 1.9836e-03, PNorm = 57.1383, GNorm = 1.8398, lr_0 = 1.0804e-04
Loss = 1.8180e-03, PNorm = 57.1452, GNorm = 3.1887, lr_0 = 1.0804e-04
Validation rmse logD = 0.625126
Validation R2 logD = 0.735074
Epoch 32
Train function
Loss = 2.1643e-03, PNorm = 57.1526, GNorm = 1.4791, lr_0 = 1.0804e-04
Loss = 1.6788e-03, PNorm = 57.1579, GNorm = 5.3077, lr_0 = 1.0804e-04
Loss = 1.6532e-03, PNorm = 57.1635, GNorm = 2.0961, lr_0 = 1.0804e-04
Loss = 1.8429e-03, PNorm = 57.1687, GNorm = 3.6843, lr_0 = 1.0804e-04
Loss = 2.0292e-03, PNorm = 57.1731, GNorm = 2.6165, lr_0 = 1.0804e-04
Validation rmse logD = 0.612723
Validation R2 logD = 0.745482
Epoch 33
Train function
Loss = 1.9976e-03, PNorm = 57.1802, GNorm = 5.7036, lr_0 = 1.0804e-04
Loss = 1.9012e-03, PNorm = 57.1874, GNorm = 1.7654, lr_0 = 1.0804e-04
Loss = 1.6541e-03, PNorm = 57.1937, GNorm = 3.3011, lr_0 = 1.0804e-04
Loss = 2.0186e-03, PNorm = 57.2003, GNorm = 2.7798, lr_0 = 1.0804e-04
Loss = 1.6229e-03, PNorm = 57.2071, GNorm = 2.4870, lr_0 = 1.0804e-04
Loss = 2.1371e-03, PNorm = 57.2128, GNorm = 2.5479, lr_0 = 1.0804e-04
Validation rmse logD = 0.606965
Validation R2 logD = 0.750244
Epoch 34
Train function
Loss = 2.4451e-03, PNorm = 57.2183, GNorm = 2.7865, lr_0 = 1.0804e-04
Loss = 1.6226e-03, PNorm = 57.2225, GNorm = 1.5082, lr_0 = 1.0804e-04
Loss = 1.7128e-03, PNorm = 57.2285, GNorm = 1.6548, lr_0 = 1.0804e-04
Loss = 1.4355e-03, PNorm = 57.2358, GNorm = 1.8250, lr_0 = 1.0804e-04
Loss = 1.6513e-03, PNorm = 57.2405, GNorm = 3.5730, lr_0 = 1.0804e-04
Loss = 1.6456e-03, PNorm = 57.2460, GNorm = 4.0285, lr_0 = 1.0804e-04
Validation rmse logD = 0.604501
Validation R2 logD = 0.752267
Epoch 35
Train function
Loss = 1.6676e-03, PNorm = 57.2524, GNorm = 2.3137, lr_0 = 1.0804e-04
Loss = 1.4043e-03, PNorm = 57.2599, GNorm = 3.3308, lr_0 = 1.0804e-04
Loss = 1.8458e-03, PNorm = 57.2661, GNorm = 4.6807, lr_0 = 1.0804e-04
Loss = 1.9400e-03, PNorm = 57.2716, GNorm = 3.0577, lr_0 = 1.0804e-04
Loss = 1.8273e-03, PNorm = 57.2750, GNorm = 5.6343, lr_0 = 1.0804e-04
Validation rmse logD = 0.691537
Validation R2 logD = 0.675795
Epoch 36
Train function
Loss = 2.7501e-03, PNorm = 57.2816, GNorm = 9.3948, lr_0 = 1.0804e-04
Loss = 1.4483e-03, PNorm = 57.2879, GNorm = 1.6938, lr_0 = 1.0804e-04
Loss = 1.4005e-03, PNorm = 57.2951, GNorm = 1.5793, lr_0 = 1.0804e-04
Loss = 1.5950e-03, PNorm = 57.2995, GNorm = 2.4765, lr_0 = 1.0804e-04
Loss = 1.2499e-03, PNorm = 57.3043, GNorm = 2.3820, lr_0 = 1.0804e-04
Loss = 1.9499e-03, PNorm = 57.3109, GNorm = 1.6189, lr_0 = 1.0804e-04
Validation rmse logD = 0.616753
Validation R2 logD = 0.742124
Epoch 37
Train function
Loss = 1.4926e-03, PNorm = 57.3162, GNorm = 6.7315, lr_0 = 1.0804e-04
Loss = 1.8364e-03, PNorm = 57.3219, GNorm = 4.6053, lr_0 = 1.0804e-04
Loss = 1.7008e-03, PNorm = 57.3269, GNorm = 3.3561, lr_0 = 1.0804e-04
Loss = 1.7686e-03, PNorm = 57.3321, GNorm = 7.1910, lr_0 = 1.0804e-04
Loss = 1.5497e-03, PNorm = 57.3381, GNorm = 1.7611, lr_0 = 1.0804e-04
Loss = 1.4775e-03, PNorm = 57.3436, GNorm = 1.3169, lr_0 = 1.0804e-04
Validation rmse logD = 0.606599
Validation R2 logD = 0.750545
Epoch 38
Train function
Loss = 1.2386e-03, PNorm = 57.3485, GNorm = 3.6939, lr_0 = 1.0804e-04
Loss = 1.4895e-03, PNorm = 57.3546, GNorm = 4.4498, lr_0 = 1.0804e-04
Loss = 1.6234e-03, PNorm = 57.3590, GNorm = 8.3100, lr_0 = 1.0804e-04
Loss = 1.6622e-03, PNorm = 57.3648, GNorm = 1.8367, lr_0 = 1.0804e-04
Loss = 1.7081e-03, PNorm = 57.3706, GNorm = 1.7713, lr_0 = 1.0804e-04
Validation rmse logD = 0.616997
Validation R2 logD = 0.741919
Epoch 39
Train function
Loss = 3.1900e-03, PNorm = 57.3759, GNorm = 8.0812, lr_0 = 1.0804e-04
Loss = 1.5569e-03, PNorm = 57.3810, GNorm = 4.0671, lr_0 = 1.0804e-04
Loss = 1.3305e-03, PNorm = 57.3861, GNorm = 3.4593, lr_0 = 1.0804e-04
Loss = 1.5367e-03, PNorm = 57.3919, GNorm = 5.8058, lr_0 = 1.0804e-04
Loss = 1.2795e-03, PNorm = 57.3984, GNorm = 4.6912, lr_0 = 1.0804e-04
Loss = 1.4207e-03, PNorm = 57.4043, GNorm = 2.2953, lr_0 = 1.0804e-04
Validation rmse logD = 0.626987
Validation R2 logD = 0.733494
Epoch 40
Train function
Loss = 1.5905e-03, PNorm = 57.4094, GNorm = 2.7589, lr_0 = 1.0804e-04
Loss = 1.7216e-03, PNorm = 57.4147, GNorm = 3.2457, lr_0 = 1.0804e-04
Loss = 1.7901e-03, PNorm = 57.4212, GNorm = 4.5659, lr_0 = 1.0804e-04
Loss = 1.5278e-03, PNorm = 57.4283, GNorm = 5.2882, lr_0 = 1.0804e-04
Loss = 1.3109e-03, PNorm = 57.4334, GNorm = 3.8717, lr_0 = 1.0804e-04
Loss = 1.6357e-03, PNorm = 57.4385, GNorm = 6.5730, lr_0 = 1.0804e-04
Validation rmse logD = 0.597920
Validation R2 logD = 0.757632
Epoch 41
Train function
Loss = 1.4353e-03, PNorm = 57.4454, GNorm = 1.4800, lr_0 = 1.0804e-04
Loss = 1.0552e-03, PNorm = 57.4507, GNorm = 2.3314, lr_0 = 1.0804e-04
Loss = 1.0918e-03, PNorm = 57.4558, GNorm = 1.4404, lr_0 = 1.0804e-04
Loss = 1.1452e-03, PNorm = 57.4613, GNorm = 2.5900, lr_0 = 1.0804e-04
Loss = 1.7896e-03, PNorm = 57.4644, GNorm = 7.5421, lr_0 = 1.0804e-04
Validation rmse logD = 0.588630
Validation R2 logD = 0.765105
Epoch 42
Train function
Loss = 1.5316e-03, PNorm = 57.4699, GNorm = 3.7218, lr_0 = 1.0804e-04
Loss = 1.3341e-03, PNorm = 57.4770, GNorm = 2.2820, lr_0 = 1.0804e-04
Loss = 1.0956e-03, PNorm = 57.4827, GNorm = 2.0647, lr_0 = 1.0804e-04
Loss = 1.1461e-03, PNorm = 57.4871, GNorm = 3.8746, lr_0 = 1.0804e-04
Loss = 1.5129e-03, PNorm = 57.4913, GNorm = 4.0355, lr_0 = 1.0804e-04
Loss = 1.4693e-03, PNorm = 57.4957, GNorm = 4.4771, lr_0 = 1.0804e-04
Validation rmse logD = 0.583215
Validation R2 logD = 0.769407
Epoch 43
Train function
Loss = 1.2849e-03, PNorm = 57.5009, GNorm = 2.4474, lr_0 = 1.0804e-04
Loss = 9.8774e-04, PNorm = 57.5066, GNorm = 2.0866, lr_0 = 1.0804e-04
Loss = 1.1772e-03, PNorm = 57.5123, GNorm = 2.4823, lr_0 = 1.0804e-04
Loss = 1.6254e-03, PNorm = 57.5172, GNorm = 5.0616, lr_0 = 1.0804e-04
Loss = 1.8864e-03, PNorm = 57.5207, GNorm = 10.5983, lr_0 = 1.0804e-04
Loss = 1.6133e-03, PNorm = 57.5267, GNorm = 1.2246, lr_0 = 1.0804e-04
Validation rmse logD = 0.708894
Validation R2 logD = 0.659316
Epoch 44
Train function
Loss = 1.9100e-03, PNorm = 57.5326, GNorm = 6.6153, lr_0 = 1.0804e-04
Loss = 1.3542e-03, PNorm = 57.5383, GNorm = 1.4445, lr_0 = 1.0804e-04
Loss = 1.4231e-03, PNorm = 57.5436, GNorm = 3.8081, lr_0 = 1.0804e-04
Loss = 1.2247e-03, PNorm = 57.5469, GNorm = 3.9806, lr_0 = 1.0804e-04
Loss = 1.5183e-03, PNorm = 57.5521, GNorm = 2.4299, lr_0 = 1.0804e-04
Validation rmse logD = 0.610097
Validation R2 logD = 0.747659
Epoch 45
Train function
Loss = 1.0478e-03, PNorm = 57.5588, GNorm = 1.9494, lr_0 = 1.0804e-04
Loss = 1.0519e-03, PNorm = 57.5642, GNorm = 3.0100, lr_0 = 1.0804e-04
Loss = 1.1644e-03, PNorm = 57.5688, GNorm = 8.0758, lr_0 = 1.0804e-04
Loss = 1.1746e-03, PNorm = 57.5731, GNorm = 4.0567, lr_0 = 1.0804e-04
Loss = 1.1854e-03, PNorm = 57.5781, GNorm = 1.3345, lr_0 = 1.0804e-04
Loss = 1.2871e-03, PNorm = 57.5829, GNorm = 1.4229, lr_0 = 1.0804e-04
Validation rmse logD = 0.594034
Validation R2 logD = 0.760773
Epoch 46
Train function
Loss = 1.1352e-03, PNorm = 57.5873, GNorm = 1.9440, lr_0 = 1.0804e-04
Loss = 9.8779e-04, PNorm = 57.5913, GNorm = 1.3864, lr_0 = 1.0804e-04
Loss = 1.0303e-03, PNorm = 57.5955, GNorm = 3.6810, lr_0 = 1.0804e-04
Loss = 1.3118e-03, PNorm = 57.5996, GNorm = 3.2213, lr_0 = 1.0804e-04
Loss = 1.2950e-03, PNorm = 57.6052, GNorm = 3.3091, lr_0 = 1.0804e-04
Loss = 1.1145e-03, PNorm = 57.6106, GNorm = 1.8750, lr_0 = 1.0804e-04
Validation rmse logD = 0.591899
Validation R2 logD = 0.762488
Epoch 47
Train function
Loss = 8.7027e-04, PNorm = 57.6162, GNorm = 5.3474, lr_0 = 1.0804e-04
Loss = 9.6923e-04, PNorm = 57.6206, GNorm = 3.0714, lr_0 = 1.0804e-04
Loss = 9.3795e-04, PNorm = 57.6258, GNorm = 2.5494, lr_0 = 1.0804e-04
Loss = 1.1812e-03, PNorm = 57.6301, GNorm = 1.9317, lr_0 = 1.0804e-04
Loss = 1.2229e-03, PNorm = 57.6344, GNorm = 1.8316, lr_0 = 1.0804e-04
Validation rmse logD = 0.588003
Validation R2 logD = 0.765605
Epoch 48
Train function
Loss = 7.5231e-04, PNorm = 57.6370, GNorm = 1.5445, lr_0 = 1.0804e-04
Loss = 9.0321e-04, PNorm = 57.6425, GNorm = 3.5802, lr_0 = 1.0804e-04
Loss = 8.5412e-04, PNorm = 57.6478, GNorm = 1.3342, lr_0 = 1.0804e-04
Loss = 9.8107e-04, PNorm = 57.6517, GNorm = 1.2864, lr_0 = 1.0804e-04
Loss = 1.3880e-03, PNorm = 57.6549, GNorm = 1.9340, lr_0 = 1.0804e-04
Loss = 1.0540e-03, PNorm = 57.6604, GNorm = 3.7954, lr_0 = 1.0804e-04
Validation rmse logD = 0.669493
Validation R2 logD = 0.696134
Epoch 49
Train function
Loss = 1.1978e-03, PNorm = 57.6656, GNorm = 3.9356, lr_0 = 1.0804e-04
Loss = 1.0322e-03, PNorm = 57.6703, GNorm = 3.0418, lr_0 = 1.0804e-04
Loss = 8.9542e-04, PNorm = 57.6744, GNorm = 4.2408, lr_0 = 1.0804e-04
Loss = 1.0836e-03, PNorm = 57.6787, GNorm = 2.4883, lr_0 = 1.0804e-04
Loss = 9.9787e-04, PNorm = 57.6827, GNorm = 1.8422, lr_0 = 1.0804e-04
Loss = 9.8344e-04, PNorm = 57.6871, GNorm = 4.6870, lr_0 = 1.0804e-04
Validation rmse logD = 0.585342
Validation R2 logD = 0.767722
Epoch 50
Train function
Loss = 9.5456e-04, PNorm = 57.6912, GNorm = 3.2251, lr_0 = 1.0804e-04
Loss = 9.4843e-04, PNorm = 57.6959, GNorm = 1.2483, lr_0 = 1.0804e-04
Loss = 1.0143e-03, PNorm = 57.7001, GNorm = 1.3849, lr_0 = 1.0804e-04
Loss = 8.0935e-04, PNorm = 57.7051, GNorm = 1.0206, lr_0 = 1.0804e-04
Loss = 9.3207e-04, PNorm = 57.7091, GNorm = 2.0257, lr_0 = 1.0804e-04
Validation rmse logD = 0.574063
Validation R2 logD = 0.776587
Epoch 51
Train function
Loss = 8.6096e-04, PNorm = 57.7132, GNorm = 3.2647, lr_0 = 1.0804e-04
Loss = 7.5085e-04, PNorm = 57.7168, GNorm = 1.5380, lr_0 = 1.0804e-04
Loss = 7.7356e-04, PNorm = 57.7207, GNorm = 1.0701, lr_0 = 1.0804e-04
Loss = 1.3498e-03, PNorm = 57.7245, GNorm = 3.6106, lr_0 = 1.0804e-04
Loss = 1.2122e-03, PNorm = 57.7292, GNorm = 1.8635, lr_0 = 1.0804e-04
Loss = 1.2461e-03, PNorm = 57.7339, GNorm = 7.3400, lr_0 = 1.0804e-04
Validation rmse logD = 0.630622
Validation R2 logD = 0.730396
Epoch 52
Train function
Loss = 9.2277e-04, PNorm = 57.7387, GNorm = 4.4010, lr_0 = 1.0804e-04
Loss = 9.2543e-04, PNorm = 57.7430, GNorm = 1.5244, lr_0 = 1.0804e-04
Loss = 9.3127e-04, PNorm = 57.7480, GNorm = 3.0781, lr_0 = 1.0804e-04
Loss = 1.0160e-03, PNorm = 57.7527, GNorm = 3.7703, lr_0 = 1.0804e-04
Loss = 1.0968e-03, PNorm = 57.7569, GNorm = 1.7441, lr_0 = 1.0804e-04
Loss = 1.1538e-03, PNorm = 57.7614, GNorm = 7.2555, lr_0 = 1.0804e-04
Validation rmse logD = 0.581643
Validation R2 logD = 0.770648
Epoch 53
Train function
Loss = 8.3579e-04, PNorm = 57.7665, GNorm = 2.5782, lr_0 = 1.0804e-04
Loss = 7.4358e-04, PNorm = 57.7703, GNorm = 2.2426, lr_0 = 1.0804e-04
Loss = 7.7233e-04, PNorm = 57.7741, GNorm = 1.4433, lr_0 = 1.0804e-04
Loss = 8.0048e-04, PNorm = 57.7794, GNorm = 1.2296, lr_0 = 1.0804e-04
Loss = 8.4289e-04, PNorm = 57.7840, GNorm = 2.1136, lr_0 = 1.0804e-04
Validation rmse logD = 0.599968
Validation R2 logD = 0.755969
Epoch 54
Train function
Loss = 9.5364e-04, PNorm = 57.7886, GNorm = 3.4911, lr_0 = 1.0804e-04
Loss = 7.5888e-04, PNorm = 57.7933, GNorm = 3.9526, lr_0 = 1.0804e-04
Loss = 6.9634e-04, PNorm = 57.7969, GNorm = 2.0058, lr_0 = 1.0804e-04
Loss = 6.7825e-04, PNorm = 57.8001, GNorm = 0.7700, lr_0 = 1.0804e-04
Loss = 8.0341e-04, PNorm = 57.8044, GNorm = 1.5638, lr_0 = 1.0804e-04
Loss = 7.2720e-04, PNorm = 57.8085, GNorm = 1.7516, lr_0 = 1.0804e-04
Validation rmse logD = 0.585703
Validation R2 logD = 0.767436
Epoch 55
Train function
Loss = 8.3618e-04, PNorm = 57.8127, GNorm = 1.1292, lr_0 = 1.0804e-04
Loss = 9.8622e-04, PNorm = 57.8173, GNorm = 3.4661, lr_0 = 1.0804e-04
Loss = 8.9055e-04, PNorm = 57.8207, GNorm = 2.0834, lr_0 = 1.0804e-04
Loss = 8.8567e-04, PNorm = 57.8232, GNorm = 3.5697, lr_0 = 1.0804e-04
Loss = 1.0313e-03, PNorm = 57.8279, GNorm = 2.4789, lr_0 = 1.0804e-04
Loss = 7.9828e-04, PNorm = 57.8332, GNorm = 1.9213, lr_0 = 1.0804e-04
Validation rmse logD = 0.568724
Validation R2 logD = 0.780724
Epoch 56
Train function
Loss = 7.4991e-04, PNorm = 57.8374, GNorm = 1.2093, lr_0 = 1.0804e-04
Loss = 6.9764e-04, PNorm = 57.8396, GNorm = 4.1152, lr_0 = 1.0804e-04
Loss = 1.2227e-03, PNorm = 57.8437, GNorm = 1.3801, lr_0 = 1.0804e-04
Loss = 9.4520e-04, PNorm = 57.8490, GNorm = 2.2049, lr_0 = 1.0804e-04
Loss = 1.1147e-03, PNorm = 57.8521, GNorm = 1.5439, lr_0 = 1.0804e-04
Validation rmse logD = 0.582774
Validation R2 logD = 0.769755
Epoch 57
Train function
Loss = 6.3510e-04, PNorm = 57.8575, GNorm = 1.5006, lr_0 = 1.0804e-04
Loss = 6.6584e-04, PNorm = 57.8624, GNorm = 1.0153, lr_0 = 1.0804e-04
Loss = 6.3049e-04, PNorm = 57.8669, GNorm = 1.3166, lr_0 = 1.0804e-04
Loss = 7.3855e-04, PNorm = 57.8700, GNorm = 1.5329, lr_0 = 1.0804e-04
Loss = 7.3744e-04, PNorm = 57.8742, GNorm = 2.3745, lr_0 = 1.0804e-04
Loss = 5.8985e-04, PNorm = 57.8784, GNorm = 3.2326, lr_0 = 1.0804e-04
Validation rmse logD = 0.581557
Validation R2 logD = 0.770716
Epoch 58
Train function
Loss = 6.1434e-04, PNorm = 57.8811, GNorm = 5.3934, lr_0 = 1.0804e-04
Loss = 9.6557e-04, PNorm = 57.8837, GNorm = 7.4550, lr_0 = 1.0804e-04
Loss = 9.9483e-04, PNorm = 57.8876, GNorm = 2.4984, lr_0 = 1.0804e-04
Loss = 6.3538e-04, PNorm = 57.8917, GNorm = 1.7145, lr_0 = 1.0804e-04
Loss = 7.5831e-04, PNorm = 57.8962, GNorm = 1.2493, lr_0 = 1.0804e-04
Loss = 6.4528e-04, PNorm = 57.8997, GNorm = 2.4937, lr_0 = 1.0804e-04
Validation rmse logD = 0.576111
Validation R2 logD = 0.774990
Epoch 59
Train function
Loss = 6.0246e-04, PNorm = 57.9029, GNorm = 2.2305, lr_0 = 1.0804e-04
Loss = 7.5518e-04, PNorm = 57.9072, GNorm = 3.4335, lr_0 = 1.0804e-04
Loss = 9.0054e-04, PNorm = 57.9121, GNorm = 2.6033, lr_0 = 1.0804e-04
Loss = 5.2738e-04, PNorm = 57.9164, GNorm = 2.0456, lr_0 = 1.0804e-04
Loss = 6.9498e-04, PNorm = 57.9201, GNorm = 1.4959, lr_0 = 1.0804e-04
Validation rmse logD = 0.591114
Validation R2 logD = 0.763118
Epoch 60
Train function
Loss = 7.9674e-04, PNorm = 57.9233, GNorm = 1.3060, lr_0 = 1.0804e-04
Loss = 5.3821e-04, PNorm = 57.9270, GNorm = 1.9005, lr_0 = 1.0804e-04
Loss = 6.5102e-04, PNorm = 57.9295, GNorm = 0.9749, lr_0 = 1.0804e-04
Loss = 1.0161e-03, PNorm = 57.9328, GNorm = 7.0734, lr_0 = 1.0804e-04
Loss = 6.7109e-04, PNorm = 57.9371, GNorm = 4.9903, lr_0 = 1.0804e-04
Loss = 8.6373e-04, PNorm = 57.9414, GNorm = 2.0250, lr_0 = 1.0804e-04
Validation rmse logD = 0.580383
Validation R2 logD = 0.771641
Epoch 61
Train function
Loss = 7.8972e-04, PNorm = 57.9450, GNorm = 4.1461, lr_0 = 1.0804e-04
Loss = 7.9842e-04, PNorm = 57.9504, GNorm = 4.1729, lr_0 = 1.0804e-04
Loss = 9.3952e-04, PNorm = 57.9539, GNorm = 1.8816, lr_0 = 1.0804e-04
Loss = 7.6608e-04, PNorm = 57.9591, GNorm = 3.2640, lr_0 = 1.0804e-04
Loss = 7.9331e-04, PNorm = 57.9640, GNorm = 2.7294, lr_0 = 1.0804e-04
Loss = 6.6006e-04, PNorm = 57.9673, GNorm = 3.0548, lr_0 = 1.0804e-04
Validation rmse logD = 0.585652
Validation R2 logD = 0.767476
Epoch 62
Train function
Loss = 6.0765e-04, PNorm = 57.9724, GNorm = 0.9278, lr_0 = 1.0804e-04
Loss = 5.6793e-04, PNorm = 57.9752, GNorm = 1.3187, lr_0 = 1.0804e-04
Loss = 6.0677e-04, PNorm = 57.9796, GNorm = 1.8350, lr_0 = 1.0804e-04
Loss = 8.0431e-04, PNorm = 57.9798, GNorm = 3.1742, lr_0 = 1.0804e-04
Loss = 6.3061e-04, PNorm = 57.9839, GNorm = 2.8687, lr_0 = 1.0804e-04
Validation rmse logD = 0.590729
Validation R2 logD = 0.763426
Epoch 63
Train function
Loss = 4.7781e-04, PNorm = 57.9878, GNorm = 1.0315, lr_0 = 1.0804e-04
Loss = 4.7944e-04, PNorm = 57.9914, GNorm = 0.9296, lr_0 = 1.0804e-04
Loss = 6.5289e-04, PNorm = 57.9929, GNorm = 4.6772, lr_0 = 1.0804e-04
Loss = 5.7506e-04, PNorm = 57.9961, GNorm = 1.3422, lr_0 = 1.0804e-04
Loss = 7.6165e-04, PNorm = 57.9996, GNorm = 2.9567, lr_0 = 1.0804e-04
Loss = 7.3259e-04, PNorm = 58.0022, GNorm = 2.0475, lr_0 = 1.0804e-04
Validation rmse logD = 0.589832
Validation R2 logD = 0.764145
Epoch 64
Train function
Loss = 1.0394e-03, PNorm = 58.0056, GNorm = 3.3723, lr_0 = 1.0804e-04
Loss = 5.2018e-04, PNorm = 58.0104, GNorm = 2.5661, lr_0 = 1.0804e-04
Loss = 5.1646e-04, PNorm = 58.0131, GNorm = 0.8427, lr_0 = 1.0804e-04
Loss = 5.4313e-04, PNorm = 58.0169, GNorm = 3.2927, lr_0 = 1.0804e-04
Loss = 7.2023e-04, PNorm = 58.0192, GNorm = 3.5390, lr_0 = 1.0804e-04
Loss = 8.7849e-04, PNorm = 58.0233, GNorm = 2.0188, lr_0 = 1.0804e-04
Validation rmse logD = 0.570766
Validation R2 logD = 0.779146
Epoch 65
Train function
Loss = 5.4699e-04, PNorm = 58.0274, GNorm = 1.4368, lr_0 = 1.0804e-04
Loss = 6.8113e-04, PNorm = 58.0317, GNorm = 3.6771, lr_0 = 1.0804e-04
Loss = 5.9919e-04, PNorm = 58.0347, GNorm = 1.5296, lr_0 = 1.0804e-04
Loss = 7.8407e-04, PNorm = 58.0385, GNorm = 1.4983, lr_0 = 1.0804e-04
Loss = 7.4544e-04, PNorm = 58.0436, GNorm = 3.6106, lr_0 = 1.0804e-04
Validation rmse logD = 0.592384
Validation R2 logD = 0.762099
Epoch 66
Train function
Loss = 3.5597e-04, PNorm = 58.0485, GNorm = 0.9814, lr_0 = 1.0804e-04
Loss = 5.4497e-04, PNorm = 58.0510, GNorm = 4.2686, lr_0 = 1.0804e-04
Loss = 7.3792e-04, PNorm = 58.0533, GNorm = 4.1355, lr_0 = 1.0804e-04
Loss = 5.3638e-04, PNorm = 58.0581, GNorm = 0.8064, lr_0 = 1.0804e-04
Loss = 8.6436e-04, PNorm = 58.0623, GNorm = 1.0459, lr_0 = 1.0804e-04
Loss = 6.0230e-04, PNorm = 58.0659, GNorm = 0.8180, lr_0 = 1.0804e-04
Validation rmse logD = 0.605568
Validation R2 logD = 0.751392
Epoch 67
Train function
Loss = 4.7735e-04, PNorm = 58.0694, GNorm = 0.8297, lr_0 = 1.0804e-04
Loss = 6.3750e-04, PNorm = 58.0728, GNorm = 4.1836, lr_0 = 1.0804e-04
Loss = 5.8763e-04, PNorm = 58.0760, GNorm = 3.7435, lr_0 = 1.0804e-04
Loss = 6.7838e-04, PNorm = 58.0790, GNorm = 2.5879, lr_0 = 1.0804e-04
Loss = 5.4401e-04, PNorm = 58.0819, GNorm = 2.7973, lr_0 = 1.0804e-04
Loss = 9.2186e-04, PNorm = 58.0844, GNorm = 5.5984, lr_0 = 1.0804e-04
Validation rmse logD = 0.567086
Validation R2 logD = 0.781984
Epoch 68
Train function
Loss = 8.2949e-04, PNorm = 58.0896, GNorm = 0.8914, lr_0 = 1.0804e-04
Loss = 5.2585e-04, PNorm = 58.0942, GNorm = 1.8178, lr_0 = 1.0804e-04
Loss = 5.2552e-04, PNorm = 58.0967, GNorm = 1.4584, lr_0 = 1.0804e-04
Loss = 4.8543e-04, PNorm = 58.1007, GNorm = 1.1315, lr_0 = 1.0804e-04
Loss = 7.3764e-04, PNorm = 58.1030, GNorm = 1.3665, lr_0 = 1.0804e-04
Validation rmse logD = 0.571464
Validation R2 logD = 0.778605
Epoch 69
Train function
Loss = 5.5937e-04, PNorm = 58.1063, GNorm = 1.6854, lr_0 = 1.0804e-04
Loss = 5.3445e-04, PNorm = 58.1100, GNorm = 1.3863, lr_0 = 1.0804e-04
Loss = 6.4299e-04, PNorm = 58.1128, GNorm = 2.4028, lr_0 = 1.0804e-04
Loss = 4.6395e-04, PNorm = 58.1174, GNorm = 1.0508, lr_0 = 1.0804e-04
Loss = 4.2285e-04, PNorm = 58.1209, GNorm = 1.4347, lr_0 = 1.0804e-04
Loss = 5.6232e-04, PNorm = 58.1228, GNorm = 5.7275, lr_0 = 1.0804e-04
Validation rmse logD = 0.578361
Validation R2 logD = 0.773229
Epoch 70
Train function
Loss = 6.0270e-04, PNorm = 58.1260, GNorm = 4.3438, lr_0 = 1.0804e-04
Loss = 6.8771e-04, PNorm = 58.1291, GNorm = 1.7917, lr_0 = 1.0804e-04
Loss = 7.3386e-04, PNorm = 58.1313, GNorm = 3.0015, lr_0 = 1.0804e-04
Loss = 8.5072e-04, PNorm = 58.1361, GNorm = 4.4648, lr_0 = 1.0804e-04
Loss = 7.6884e-04, PNorm = 58.1400, GNorm = 5.8656, lr_0 = 1.0804e-04
Loss = 1.0795e-03, PNorm = 58.1428, GNorm = 4.8203, lr_0 = 1.0804e-04
Validation rmse logD = 0.581909
Validation R2 logD = 0.770439
Epoch 71
Train function
Loss = 5.7188e-04, PNorm = 58.1478, GNorm = 2.1433, lr_0 = 1.0804e-04
Loss = 5.8100e-04, PNorm = 58.1531, GNorm = 2.0918, lr_0 = 1.0804e-04
Loss = 4.3982e-04, PNorm = 58.1577, GNorm = 2.8455, lr_0 = 1.0804e-04
Loss = 7.0674e-04, PNorm = 58.1607, GNorm = 1.1063, lr_0 = 1.0804e-04
Loss = 6.7166e-04, PNorm = 58.1639, GNorm = 4.0003, lr_0 = 1.0804e-04
Validation rmse logD = 0.574134
Validation R2 logD = 0.776532
Epoch 72
Train function
Loss = 3.3308e-04, PNorm = 58.1684, GNorm = 0.7231, lr_0 = 1.0804e-04
Loss = 4.3853e-04, PNorm = 58.1710, GNorm = 1.6965, lr_0 = 1.0804e-04
Loss = 6.0024e-04, PNorm = 58.1737, GNorm = 2.5420, lr_0 = 1.0804e-04
Loss = 4.7096e-04, PNorm = 58.1763, GNorm = 1.6926, lr_0 = 1.0804e-04
Loss = 3.8363e-04, PNorm = 58.1793, GNorm = 0.8611, lr_0 = 1.0804e-04
Loss = 5.8169e-04, PNorm = 58.1825, GNorm = 3.6417, lr_0 = 1.0804e-04
Validation rmse logD = 0.567312
Validation R2 logD = 0.781811
Epoch 73
Train function
Loss = 4.3811e-04, PNorm = 58.1853, GNorm = 1.2256, lr_0 = 1.0804e-04
Loss = 4.0743e-04, PNorm = 58.1875, GNorm = 1.2731, lr_0 = 1.0804e-04
Loss = 6.3566e-04, PNorm = 58.1907, GNorm = 1.5310, lr_0 = 1.0804e-04
Loss = 5.7048e-04, PNorm = 58.1938, GNorm = 2.3626, lr_0 = 1.0804e-04
Loss = 4.8034e-04, PNorm = 58.1981, GNorm = 3.6248, lr_0 = 1.0804e-04
Loss = 4.6887e-04, PNorm = 58.2008, GNorm = 2.0174, lr_0 = 1.0804e-04
Validation rmse logD = 0.583640
Validation R2 logD = 0.769070
Epoch 74
Train function
Loss = 5.1126e-04, PNorm = 58.2036, GNorm = 2.0718, lr_0 = 1.0804e-04
Loss = 4.4279e-04, PNorm = 58.2049, GNorm = 1.7855, lr_0 = 1.0804e-04
Loss = 4.9900e-04, PNorm = 58.2084, GNorm = 2.7486, lr_0 = 1.0804e-04
Loss = 6.6950e-04, PNorm = 58.2118, GNorm = 5.7070, lr_0 = 1.0804e-04
Loss = 9.5891e-04, PNorm = 58.2138, GNorm = 1.6958, lr_0 = 1.0804e-04
Validation rmse logD = 0.582128
Validation R2 logD = 0.770266
Epoch 75
Train function
Loss = 1.2328e-03, PNorm = 58.2186, GNorm = 6.7587, lr_0 = 1.0804e-04
Loss = 6.2234e-04, PNorm = 58.2251, GNorm = 2.3342, lr_0 = 1.0804e-04
Loss = 7.1257e-04, PNorm = 58.2276, GNorm = 4.3760, lr_0 = 1.0804e-04
Loss = 7.9812e-04, PNorm = 58.2310, GNorm = 4.0229, lr_0 = 1.0804e-04
Loss = 6.2028e-04, PNorm = 58.2348, GNorm = 6.0861, lr_0 = 1.0804e-04
Loss = 6.9005e-04, PNorm = 58.2391, GNorm = 3.8228, lr_0 = 1.0804e-04
Validation rmse logD = 0.575782
Validation R2 logD = 0.775247
Epoch 76
Train function
Loss = 3.2594e-04, PNorm = 58.2426, GNorm = 1.8531, lr_0 = 1.0804e-04
Loss = 3.3879e-04, PNorm = 58.2459, GNorm = 0.7182, lr_0 = 1.0804e-04
Loss = 3.6833e-04, PNorm = 58.2488, GNorm = 2.6431, lr_0 = 1.0804e-04
Loss = 5.7026e-04, PNorm = 58.2507, GNorm = 1.4487, lr_0 = 1.0804e-04
Loss = 6.0084e-04, PNorm = 58.2536, GNorm = 1.8795, lr_0 = 1.0804e-04
Loss = 5.4040e-04, PNorm = 58.2567, GNorm = 1.5927, lr_0 = 1.0804e-04
Validation rmse logD = 0.587009
Validation R2 logD = 0.766397
Epoch 77
Train function
Loss = 3.6130e-04, PNorm = 58.2594, GNorm = 2.8678, lr_0 = 1.0804e-04
Loss = 2.9055e-04, PNorm = 58.2621, GNorm = 1.1623, lr_0 = 1.0804e-04
Loss = 4.3552e-04, PNorm = 58.2639, GNorm = 0.8861, lr_0 = 1.0804e-04
Loss = 6.1425e-04, PNorm = 58.2681, GNorm = 2.1331, lr_0 = 1.0804e-04
Loss = 4.4671e-04, PNorm = 58.2717, GNorm = 3.6317, lr_0 = 1.0804e-04
Validation rmse logD = 0.586469
Validation R2 logD = 0.766827
Epoch 78
Train function
Loss = 4.5575e-04, PNorm = 58.2749, GNorm = 3.3663, lr_0 = 1.0804e-04
Loss = 3.8719e-04, PNorm = 58.2761, GNorm = 0.9714, lr_0 = 1.0804e-04
Loss = 3.7353e-04, PNorm = 58.2792, GNorm = 2.7262, lr_0 = 1.0804e-04
Loss = 3.6127e-04, PNorm = 58.2823, GNorm = 1.4945, lr_0 = 1.0804e-04
Loss = 4.9552e-04, PNorm = 58.2844, GNorm = 3.4541, lr_0 = 1.0804e-04
Loss = 4.7699e-04, PNorm = 58.2863, GNorm = 3.2208, lr_0 = 1.0804e-04
Validation rmse logD = 0.579300
Validation R2 logD = 0.772493
Epoch 79
Train function
Loss = 6.8932e-04, PNorm = 58.2899, GNorm = 3.2145, lr_0 = 1.0804e-04
Loss = 7.9170e-04, PNorm = 58.2919, GNorm = 5.4469, lr_0 = 1.0804e-04
Loss = 6.2909e-04, PNorm = 58.2961, GNorm = 3.1294, lr_0 = 1.0804e-04
Loss = 5.6107e-04, PNorm = 58.3004, GNorm = 2.0477, lr_0 = 1.0804e-04
Loss = 8.5143e-04, PNorm = 58.3044, GNorm = 6.8830, lr_0 = 1.0804e-04
Loss = 7.4234e-04, PNorm = 58.3093, GNorm = 3.2468, lr_0 = 1.0804e-04
Validation rmse logD = 0.572493
Validation R2 logD = 0.777807
Epoch 80
Train function
Loss = 5.0995e-04, PNorm = 58.3154, GNorm = 3.6562, lr_0 = 1.0804e-04
Loss = 3.8287e-04, PNorm = 58.3192, GNorm = 0.8723, lr_0 = 1.0804e-04
Loss = 3.8081e-04, PNorm = 58.3223, GNorm = 1.3902, lr_0 = 1.0804e-04
Loss = 3.4591e-04, PNorm = 58.3240, GNorm = 0.8872, lr_0 = 1.0804e-04
Loss = 4.1528e-04, PNorm = 58.3270, GNorm = 3.5392, lr_0 = 1.0804e-04
Validation rmse logD = 0.571187
Validation R2 logD = 0.778820
Epoch 81
Train function
Loss = 1.8307e-04, PNorm = 58.3295, GNorm = 1.7739, lr_0 = 1.0804e-04
Loss = 4.3137e-04, PNorm = 58.3310, GNorm = 2.2747, lr_0 = 1.0804e-04
Loss = 2.8816e-04, PNorm = 58.3336, GNorm = 1.0922, lr_0 = 1.0804e-04
Loss = 3.5356e-04, PNorm = 58.3358, GNorm = 1.1889, lr_0 = 1.0804e-04
Loss = 3.5910e-04, PNorm = 58.3386, GNorm = 1.6434, lr_0 = 1.0804e-04
Loss = 4.1726e-04, PNorm = 58.3412, GNorm = 3.2451, lr_0 = 1.0804e-04
Validation rmse logD = 0.576740
Validation R2 logD = 0.774498
Epoch 82
Train function
Loss = 4.4967e-04, PNorm = 58.3438, GNorm = 1.0608, lr_0 = 1.0804e-04
Loss = 4.1807e-04, PNorm = 58.3472, GNorm = 2.6493, lr_0 = 1.0804e-04
Loss = 5.8297e-04, PNorm = 58.3499, GNorm = 6.3269, lr_0 = 1.0804e-04
Loss = 5.6740e-04, PNorm = 58.3536, GNorm = 1.3100, lr_0 = 1.0804e-04
Loss = 5.6796e-04, PNorm = 58.3565, GNorm = 2.7671, lr_0 = 1.0804e-04
Loss = 5.6988e-04, PNorm = 58.3603, GNorm = 3.4827, lr_0 = 1.0804e-04
Validation rmse logD = 0.573722
Validation R2 logD = 0.776853
Epoch 83
Train function
Loss = 5.0262e-04, PNorm = 58.3647, GNorm = 1.5631, lr_0 = 1.0804e-04
Loss = 3.4630e-04, PNorm = 58.3680, GNorm = 3.7713, lr_0 = 1.0804e-04
Loss = 3.7609e-04, PNorm = 58.3709, GNorm = 2.3824, lr_0 = 1.0804e-04
Loss = 4.1439e-04, PNorm = 58.3731, GNorm = 0.8911, lr_0 = 1.0804e-04
Loss = 3.3711e-04, PNorm = 58.3755, GNorm = 0.7910, lr_0 = 1.0804e-04
Validation rmse logD = 0.568328
Validation R2 logD = 0.781029
Epoch 84
Train function
Loss = 2.0039e-04, PNorm = 58.3778, GNorm = 0.6843, lr_0 = 1.0804e-04
Loss = 4.2526e-04, PNorm = 58.3803, GNorm = 3.2644, lr_0 = 1.0804e-04
Loss = 3.9719e-04, PNorm = 58.3823, GNorm = 3.2543, lr_0 = 1.0804e-04
Loss = 4.7508e-04, PNorm = 58.3866, GNorm = 0.8172, lr_0 = 1.0804e-04
Loss = 4.1618e-04, PNorm = 58.3892, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 3.3517e-04, PNorm = 58.3920, GNorm = 2.1220, lr_0 = 1.0804e-04
Validation rmse logD = 0.567874
Validation R2 logD = 0.781378
Epoch 85
Train function
Loss = 3.7285e-04, PNorm = 58.3943, GNorm = 1.6779, lr_0 = 1.0804e-04
Loss = 3.4658e-04, PNorm = 58.3964, GNorm = 1.1746, lr_0 = 1.0804e-04
Loss = 3.9732e-04, PNorm = 58.3987, GNorm = 0.9384, lr_0 = 1.0804e-04
Loss = 3.2535e-04, PNorm = 58.4003, GNorm = 1.5289, lr_0 = 1.0804e-04
Loss = 5.0822e-04, PNorm = 58.4031, GNorm = 5.2856, lr_0 = 1.0804e-04
Loss = 8.5766e-04, PNorm = 58.4068, GNorm = 2.4843, lr_0 = 1.0804e-04
Validation rmse logD = 0.590854
Validation R2 logD = 0.763326
Epoch 86
Train function
Loss = 9.5884e-04, PNorm = 58.4107, GNorm = 1.8095, lr_0 = 1.0804e-04
Loss = 7.7603e-04, PNorm = 58.4146, GNorm = 0.9692, lr_0 = 1.0804e-04
Loss = 8.7752e-04, PNorm = 58.4199, GNorm = 0.9885, lr_0 = 1.0804e-04
Loss = 7.2013e-04, PNorm = 58.4238, GNorm = 1.4594, lr_0 = 1.0804e-04
Loss = 4.5894e-04, PNorm = 58.4293, GNorm = 1.5944, lr_0 = 1.0804e-04
Validation rmse logD = 0.579090
Validation R2 logD = 0.772657
Epoch 87
Train function
Loss = 4.0031e-04, PNorm = 58.4335, GNorm = 1.2490, lr_0 = 1.0804e-04
Loss = 3.4883e-04, PNorm = 58.4363, GNorm = 2.0715, lr_0 = 1.0804e-04
Loss = 4.1478e-04, PNorm = 58.4384, GNorm = 2.4719, lr_0 = 1.0804e-04
Loss = 4.1207e-04, PNorm = 58.4409, GNorm = 2.0708, lr_0 = 1.0804e-04
Loss = 3.7299e-04, PNorm = 58.4440, GNorm = 2.3910, lr_0 = 1.0804e-04
Loss = 3.2385e-04, PNorm = 58.4460, GNorm = 1.6814, lr_0 = 1.0804e-04
Validation rmse logD = 0.585482
Validation R2 logD = 0.767611
Epoch 88
Train function
Loss = 4.8889e-04, PNorm = 58.4489, GNorm = 3.1683, lr_0 = 1.0804e-04
Loss = 4.1105e-04, PNorm = 58.4512, GNorm = 0.8404, lr_0 = 1.0804e-04
Loss = 4.3257e-04, PNorm = 58.4544, GNorm = 1.8268, lr_0 = 1.0804e-04
Loss = 3.5527e-04, PNorm = 58.4571, GNorm = 0.7633, lr_0 = 1.0804e-04
Loss = 3.5675e-04, PNorm = 58.4596, GNorm = 1.1327, lr_0 = 1.0804e-04
Loss = 4.2556e-04, PNorm = 58.4614, GNorm = 4.9925, lr_0 = 1.0804e-04
Validation rmse logD = 0.585265
Validation R2 logD = 0.767783
Epoch 89
Train function
Loss = 3.5972e-04, PNorm = 58.4648, GNorm = 1.7883, lr_0 = 1.0804e-04
Loss = 3.6486e-04, PNorm = 58.4668, GNorm = 3.5016, lr_0 = 1.0804e-04
Loss = 4.3129e-04, PNorm = 58.4700, GNorm = 1.7191, lr_0 = 1.0804e-04
Loss = 4.1276e-04, PNorm = 58.4741, GNorm = 2.6546, lr_0 = 1.0804e-04
Loss = 5.0026e-04, PNorm = 58.4761, GNorm = 1.6720, lr_0 = 1.0804e-04
Validation rmse logD = 0.611569
Validation R2 logD = 0.746440
Epoch 90
Train function
Loss = 5.8194e-04, PNorm = 58.4794, GNorm = 3.5596, lr_0 = 1.0804e-04
Loss = 3.9535e-04, PNorm = 58.4827, GNorm = 3.8926, lr_0 = 1.0804e-04
Loss = 4.9332e-04, PNorm = 58.4836, GNorm = 0.8665, lr_0 = 1.0804e-04
Loss = 4.0007e-04, PNorm = 58.4860, GNorm = 1.8907, lr_0 = 1.0804e-04
Loss = 3.5088e-04, PNorm = 58.4888, GNorm = 2.1014, lr_0 = 1.0804e-04
Loss = 4.8315e-04, PNorm = 58.4917, GNorm = 1.8402, lr_0 = 1.0804e-04
Validation rmse logD = 0.569175
Validation R2 logD = 0.780375
Epoch 91
Train function
Loss = 6.6087e-04, PNorm = 58.4950, GNorm = 4.9377, lr_0 = 1.0804e-04
Loss = 5.5976e-04, PNorm = 58.4990, GNorm = 3.0438, lr_0 = 1.0804e-04
Loss = 5.6000e-04, PNorm = 58.5033, GNorm = 4.7460, lr_0 = 1.0804e-04
Loss = 4.0685e-04, PNorm = 58.5064, GNorm = 3.1827, lr_0 = 1.0804e-04
Loss = 3.0521e-04, PNorm = 58.5090, GNorm = 1.0026, lr_0 = 1.0804e-04
Loss = 3.7407e-04, PNorm = 58.5117, GNorm = 3.0846, lr_0 = 1.0804e-04
Validation rmse logD = 0.581482
Validation R2 logD = 0.770776
Epoch 92
Train function
Loss = 3.0330e-04, PNorm = 58.5147, GNorm = 4.7305, lr_0 = 1.0804e-04
Loss = 3.6585e-04, PNorm = 58.5167, GNorm = 1.0260, lr_0 = 1.0804e-04
Loss = 4.4002e-04, PNorm = 58.5183, GNorm = 3.7988, lr_0 = 1.0804e-04
Loss = 4.5256e-04, PNorm = 58.5205, GNorm = 1.0385, lr_0 = 1.0804e-04
Loss = 4.4042e-04, PNorm = 58.5235, GNorm = 0.8780, lr_0 = 1.0804e-04
Validation rmse logD = 0.572095
Validation R2 logD = 0.778116
Epoch 93
Train function
Loss = 2.2626e-04, PNorm = 58.5275, GNorm = 1.2162, lr_0 = 1.0804e-04
Loss = 2.7589e-04, PNorm = 58.5304, GNorm = 1.1642, lr_0 = 1.0804e-04
Loss = 2.7822e-04, PNorm = 58.5319, GNorm = 3.4771, lr_0 = 1.0804e-04
Loss = 4.4048e-04, PNorm = 58.5339, GNorm = 2.8650, lr_0 = 1.0804e-04
Loss = 5.0301e-04, PNorm = 58.5371, GNorm = 4.6362, lr_0 = 1.0804e-04
Loss = 3.6419e-04, PNorm = 58.5403, GNorm = 2.5914, lr_0 = 1.0804e-04
Validation rmse logD = 0.588151
Validation R2 logD = 0.765487
Epoch 94
Train function
Loss = 3.0042e-04, PNorm = 58.5411, GNorm = 1.3724, lr_0 = 1.0804e-04
Loss = 2.8294e-04, PNorm = 58.5432, GNorm = 1.3072, lr_0 = 1.0804e-04
Loss = 3.2571e-04, PNorm = 58.5458, GNorm = 1.1155, lr_0 = 1.0804e-04
Loss = 3.7072e-04, PNorm = 58.5488, GNorm = 1.0188, lr_0 = 1.0804e-04
Loss = 3.7115e-04, PNorm = 58.5515, GNorm = 4.7213, lr_0 = 1.0804e-04
Loss = 2.9282e-04, PNorm = 58.5548, GNorm = 1.2452, lr_0 = 1.0804e-04
Validation rmse logD = 0.571562
Validation R2 logD = 0.778530
Epoch 95
Train function
Loss = 2.3613e-04, PNorm = 58.5571, GNorm = 0.7387, lr_0 = 1.0804e-04
Loss = 4.8166e-04, PNorm = 58.5587, GNorm = 4.0674, lr_0 = 1.0804e-04
Loss = 4.2740e-04, PNorm = 58.5621, GNorm = 0.6409, lr_0 = 1.0804e-04
Loss = 4.6188e-04, PNorm = 58.5655, GNorm = 3.8012, lr_0 = 1.0804e-04
Loss = 4.7091e-04, PNorm = 58.5682, GNorm = 2.5780, lr_0 = 1.0804e-04
Validation rmse logD = 0.577705
Validation R2 logD = 0.773744
Epoch 96
Train function
Loss = 4.1622e-04, PNorm = 58.5706, GNorm = 1.0145, lr_0 = 1.0804e-04
Loss = 3.5910e-04, PNorm = 58.5747, GNorm = 2.6784, lr_0 = 1.0804e-04
Loss = 3.5667e-04, PNorm = 58.5773, GNorm = 1.1190, lr_0 = 1.0804e-04
Loss = 3.0612e-04, PNorm = 58.5798, GNorm = 0.7011, lr_0 = 1.0804e-04
Loss = 3.6148e-04, PNorm = 58.5810, GNorm = 0.8883, lr_0 = 1.0804e-04
Loss = 3.7971e-04, PNorm = 58.5835, GNorm = 2.5190, lr_0 = 1.0804e-04
Validation rmse logD = 0.567584
Validation R2 logD = 0.781602
Epoch 97
Train function
Loss = 2.5356e-04, PNorm = 58.5871, GNorm = 2.4021, lr_0 = 1.0804e-04
Loss = 2.7900e-04, PNorm = 58.5890, GNorm = 1.9929, lr_0 = 1.0804e-04
Loss = 2.7920e-04, PNorm = 58.5916, GNorm = 2.0918, lr_0 = 1.0804e-04
Loss = 5.6528e-04, PNorm = 58.5947, GNorm = 1.7823, lr_0 = 1.0804e-04
Loss = 6.5067e-04, PNorm = 58.5969, GNorm = 5.2015, lr_0 = 1.0804e-04
Loss = 4.3607e-04, PNorm = 58.5993, GNorm = 3.0504, lr_0 = 1.0804e-04
Validation rmse logD = 0.566548
Validation R2 logD = 0.782398
Epoch 98
Train function
Loss = 3.3821e-04, PNorm = 58.6029, GNorm = 2.6503, lr_0 = 1.0804e-04
Loss = 3.2083e-04, PNorm = 58.6048, GNorm = 2.3503, lr_0 = 1.0804e-04
Loss = 4.4692e-04, PNorm = 58.6077, GNorm = 4.6822, lr_0 = 1.0804e-04
Loss = 5.2448e-04, PNorm = 58.6114, GNorm = 0.6281, lr_0 = 1.0804e-04
Loss = 4.0084e-04, PNorm = 58.6149, GNorm = 0.8492, lr_0 = 1.0804e-04
Validation rmse logD = 0.576664
Validation R2 logD = 0.774558
Epoch 99
Train function
Loss = 2.9454e-04, PNorm = 58.6182, GNorm = 1.4647, lr_0 = 1.0804e-04
Loss = 2.6169e-04, PNorm = 58.6204, GNorm = 1.5529, lr_0 = 1.0804e-04
Loss = 2.6926e-04, PNorm = 58.6219, GNorm = 0.7239, lr_0 = 1.0804e-04
Loss = 2.5767e-04, PNorm = 58.6244, GNorm = 0.8688, lr_0 = 1.0804e-04
Loss = 4.1749e-04, PNorm = 58.6260, GNorm = 1.1519, lr_0 = 1.0804e-04
Loss = 3.6687e-04, PNorm = 58.6296, GNorm = 3.1254, lr_0 = 1.0804e-04
Validation rmse logD = 0.568645
Validation R2 logD = 0.780785
Model 0 best validation rmse = 0.566548 on epoch 97
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.548613
Model 0 test R2 logD = 0.763937
Ensemble test rmse  logD= 0.548613
Ensemble test R2  logD= 0.763937
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1855e-02, PNorm = 55.5547, GNorm = 2.6645, lr_0 = 1.0804e-04
Loss = 2.0620e-02, PNorm = 55.5566, GNorm = 6.7757, lr_0 = 1.0804e-04
Loss = 1.5897e-02, PNorm = 55.5592, GNorm = 9.1500, lr_0 = 1.0804e-04
Loss = 1.5769e-02, PNorm = 55.5621, GNorm = 3.0829, lr_0 = 1.0804e-04
Loss = 1.6211e-02, PNorm = 55.5659, GNorm = 2.6876, lr_0 = 1.0804e-04
Validation rmse logD = 1.072468
Validation R2 logD = 0.219926
Epoch 1
Train function
Loss = 1.3740e-02, PNorm = 55.5713, GNorm = 1.4388, lr_0 = 1.0804e-04
Loss = 1.5553e-02, PNorm = 55.5763, GNorm = 5.7282, lr_0 = 1.0804e-04
Loss = 1.5824e-02, PNorm = 55.5817, GNorm = 2.4614, lr_0 = 1.0804e-04
Loss = 1.4576e-02, PNorm = 55.5889, GNorm = 3.4259, lr_0 = 1.0804e-04
Loss = 1.4645e-02, PNorm = 55.5948, GNorm = 5.5750, lr_0 = 1.0804e-04
Loss = 1.5914e-02, PNorm = 55.6013, GNorm = 2.6194, lr_0 = 1.0804e-04
Validation rmse logD = 1.029277
Validation R2 logD = 0.281491
Epoch 2
Train function
Loss = 1.4327e-02, PNorm = 55.6086, GNorm = 1.8406, lr_0 = 1.0804e-04
Loss = 1.3172e-02, PNorm = 55.6178, GNorm = 1.9307, lr_0 = 1.0804e-04
Loss = 1.3011e-02, PNorm = 55.6264, GNorm = 7.1002, lr_0 = 1.0804e-04
Loss = 1.4672e-02, PNorm = 55.6353, GNorm = 3.0704, lr_0 = 1.0804e-04
Loss = 1.2679e-02, PNorm = 55.6457, GNorm = 3.3264, lr_0 = 1.0804e-04
Validation rmse logD = 0.972401
Validation R2 logD = 0.358705
Epoch 3
Train function
Loss = 9.2099e-03, PNorm = 55.6575, GNorm = 1.3305, lr_0 = 1.0804e-04
Loss = 1.2724e-02, PNorm = 55.6685, GNorm = 3.0880, lr_0 = 1.0804e-04
Loss = 1.1506e-02, PNorm = 55.6792, GNorm = 4.3207, lr_0 = 1.0804e-04
Loss = 1.1961e-02, PNorm = 55.6940, GNorm = 4.9770, lr_0 = 1.0804e-04
Loss = 1.2832e-02, PNorm = 55.7030, GNorm = 9.1143, lr_0 = 1.0804e-04
Loss = 9.1661e-03, PNorm = 55.7132, GNorm = 5.4211, lr_0 = 1.0804e-04
Validation rmse logD = 0.984551
Validation R2 logD = 0.342579
Epoch 4
Train function
Loss = 1.1833e-02, PNorm = 55.7261, GNorm = 2.4312, lr_0 = 1.0804e-04
Loss = 1.1621e-02, PNorm = 55.7393, GNorm = 1.6722, lr_0 = 1.0804e-04
Loss = 8.9000e-03, PNorm = 55.7527, GNorm = 2.9534, lr_0 = 1.0804e-04
Loss = 1.0041e-02, PNorm = 55.7639, GNorm = 6.4780, lr_0 = 1.0804e-04
Loss = 9.8939e-03, PNorm = 55.7740, GNorm = 1.2956, lr_0 = 1.0804e-04
Loss = 1.1345e-02, PNorm = 55.7861, GNorm = 1.9783, lr_0 = 1.0804e-04
Validation rmse logD = 1.000726
Validation R2 logD = 0.320801
Epoch 5
Train function
Loss = 1.2795e-02, PNorm = 55.7978, GNorm = 6.9735, lr_0 = 1.0804e-04
Loss = 9.4828e-03, PNorm = 55.8086, GNorm = 4.9896, lr_0 = 1.0804e-04
Loss = 1.0100e-02, PNorm = 55.8214, GNorm = 1.6689, lr_0 = 1.0804e-04
Loss = 1.0605e-02, PNorm = 55.8334, GNorm = 6.2210, lr_0 = 1.0804e-04
Loss = 9.0907e-03, PNorm = 55.8460, GNorm = 4.1776, lr_0 = 1.0804e-04
Validation rmse logD = 0.919602
Validation R2 logD = 0.426455
Epoch 6
Train function
Loss = 1.2521e-02, PNorm = 55.8598, GNorm = 8.5337, lr_0 = 1.0804e-04
Loss = 8.4413e-03, PNorm = 55.8705, GNorm = 4.7847, lr_0 = 1.0804e-04
Loss = 8.2108e-03, PNorm = 55.8818, GNorm = 5.8523, lr_0 = 1.0804e-04
Loss = 8.7963e-03, PNorm = 55.8949, GNorm = 2.4148, lr_0 = 1.0804e-04
Loss = 8.5153e-03, PNorm = 55.9081, GNorm = 1.8354, lr_0 = 1.0804e-04
Loss = 9.1320e-03, PNorm = 55.9208, GNorm = 2.6442, lr_0 = 1.0804e-04
Validation rmse logD = 0.803728
Validation R2 logD = 0.561888
Epoch 7
Train function
Loss = 7.9525e-03, PNorm = 55.9322, GNorm = 6.1893, lr_0 = 1.0804e-04
Loss = 6.5204e-03, PNorm = 55.9445, GNorm = 4.6879, lr_0 = 1.0804e-04
Loss = 8.2526e-03, PNorm = 55.9556, GNorm = 6.6910, lr_0 = 1.0804e-04
Loss = 7.5141e-03, PNorm = 55.9679, GNorm = 2.2598, lr_0 = 1.0804e-04
Loss = 8.2033e-03, PNorm = 55.9784, GNorm = 6.5065, lr_0 = 1.0804e-04
Loss = 9.0944e-03, PNorm = 55.9898, GNorm = 5.4880, lr_0 = 1.0804e-04
Validation rmse logD = 0.756791
Validation R2 logD = 0.611564
Epoch 8
Train function
Loss = 8.1469e-03, PNorm = 56.0010, GNorm = 4.9140, lr_0 = 1.0804e-04
Loss = 6.6736e-03, PNorm = 56.0136, GNorm = 2.7020, lr_0 = 1.0804e-04
Loss = 7.0836e-03, PNorm = 56.0243, GNorm = 5.9759, lr_0 = 1.0804e-04
Loss = 7.5392e-03, PNorm = 56.0345, GNorm = 3.4260, lr_0 = 1.0804e-04
Loss = 8.4689e-03, PNorm = 56.0450, GNorm = 5.2947, lr_0 = 1.0804e-04
Validation rmse logD = 0.777645
Validation R2 logD = 0.589862
Epoch 9
Train function
Loss = 7.4359e-03, PNorm = 56.0558, GNorm = 8.1384, lr_0 = 1.0804e-04
Loss = 6.8671e-03, PNorm = 56.0665, GNorm = 1.6052, lr_0 = 1.0804e-04
Loss = 7.4897e-03, PNorm = 56.0789, GNorm = 2.9995, lr_0 = 1.0804e-04
Loss = 6.7686e-03, PNorm = 56.0909, GNorm = 9.4932, lr_0 = 1.0804e-04
Loss = 6.9110e-03, PNorm = 56.1022, GNorm = 2.1783, lr_0 = 1.0804e-04
Loss = 6.3892e-03, PNorm = 56.1126, GNorm = 2.4383, lr_0 = 1.0804e-04
Validation rmse logD = 0.716918
Validation R2 logD = 0.651417
Epoch 10
Train function
Loss = 7.0256e-03, PNorm = 56.1215, GNorm = 1.4477, lr_0 = 1.0804e-04
Loss = 6.7464e-03, PNorm = 56.1315, GNorm = 4.4697, lr_0 = 1.0804e-04
Loss = 6.2113e-03, PNorm = 56.1431, GNorm = 5.2316, lr_0 = 1.0804e-04
Loss = 5.4458e-03, PNorm = 56.1540, GNorm = 6.1995, lr_0 = 1.0804e-04
Loss = 6.4911e-03, PNorm = 56.1608, GNorm = 5.2436, lr_0 = 1.0804e-04
Loss = 5.8030e-03, PNorm = 56.1669, GNorm = 4.7978, lr_0 = 1.0804e-04
Validation rmse logD = 0.744754
Validation R2 logD = 0.623822
Epoch 11
Train function
Loss = 7.1552e-03, PNorm = 56.1798, GNorm = 2.0763, lr_0 = 1.0804e-04
Loss = 6.5353e-03, PNorm = 56.1908, GNorm = 2.1973, lr_0 = 1.0804e-04
Loss = 6.8228e-03, PNorm = 56.2012, GNorm = 6.2583, lr_0 = 1.0804e-04
Loss = 5.0123e-03, PNorm = 56.2113, GNorm = 1.7500, lr_0 = 1.0804e-04
Loss = 5.5108e-03, PNorm = 56.2191, GNorm = 8.5741, lr_0 = 1.0804e-04
Validation rmse logD = 0.697822
Validation R2 logD = 0.669740
Epoch 12
Train function
Loss = 8.0126e-03, PNorm = 56.2279, GNorm = 3.6251, lr_0 = 1.0804e-04
Loss = 5.7593e-03, PNorm = 56.2372, GNorm = 6.7597, lr_0 = 1.0804e-04
Loss = 6.0606e-03, PNorm = 56.2453, GNorm = 7.3063, lr_0 = 1.0804e-04
Loss = 6.2617e-03, PNorm = 56.2529, GNorm = 2.0349, lr_0 = 1.0804e-04
Loss = 5.7532e-03, PNorm = 56.2596, GNorm = 7.2381, lr_0 = 1.0804e-04
Loss = 5.9853e-03, PNorm = 56.2690, GNorm = 8.4475, lr_0 = 1.0804e-04
Validation rmse logD = 0.691130
Validation R2 logD = 0.676043
Epoch 13
Train function
Loss = 5.0731e-03, PNorm = 56.2796, GNorm = 3.2644, lr_0 = 1.0804e-04
Loss = 4.6168e-03, PNorm = 56.2902, GNorm = 3.8015, lr_0 = 1.0804e-04
Loss = 5.9045e-03, PNorm = 56.2975, GNorm = 1.2399, lr_0 = 1.0804e-04
Loss = 4.9203e-03, PNorm = 56.3056, GNorm = 2.2057, lr_0 = 1.0804e-04
Loss = 5.7198e-03, PNorm = 56.3120, GNorm = 2.2198, lr_0 = 1.0804e-04
Loss = 4.5375e-03, PNorm = 56.3185, GNorm = 1.4632, lr_0 = 1.0804e-04
Validation rmse logD = 0.674168
Validation R2 logD = 0.691749
Epoch 14
Train function
Loss = 4.3904e-03, PNorm = 56.3283, GNorm = 1.3305, lr_0 = 1.0804e-04
Loss = 4.7808e-03, PNorm = 56.3372, GNorm = 5.2595, lr_0 = 1.0804e-04
Loss = 4.9102e-03, PNorm = 56.3476, GNorm = 3.1861, lr_0 = 1.0804e-04
Loss = 4.2250e-03, PNorm = 56.3559, GNorm = 6.0493, lr_0 = 1.0804e-04
Loss = 5.2680e-03, PNorm = 56.3643, GNorm = 6.4820, lr_0 = 1.0804e-04
Validation rmse logD = 0.638322
Validation R2 logD = 0.723658
Epoch 15
Train function
Loss = 2.3426e-03, PNorm = 56.3731, GNorm = 1.4384, lr_0 = 1.0804e-04
Loss = 3.6305e-03, PNorm = 56.3814, GNorm = 5.0539, lr_0 = 1.0804e-04
Loss = 4.5674e-03, PNorm = 56.3878, GNorm = 2.3214, lr_0 = 1.0804e-04
Loss = 4.7444e-03, PNorm = 56.3958, GNorm = 2.0310, lr_0 = 1.0804e-04
Loss = 4.7304e-03, PNorm = 56.4012, GNorm = 6.7775, lr_0 = 1.0804e-04
Loss = 5.3852e-03, PNorm = 56.4097, GNorm = 2.5973, lr_0 = 1.0804e-04
Validation rmse logD = 0.653334
Validation R2 logD = 0.710507
Epoch 16
Train function
Loss = 5.1905e-03, PNorm = 56.4199, GNorm = 4.3438, lr_0 = 1.0804e-04
Loss = 5.3624e-03, PNorm = 56.4300, GNorm = 11.1671, lr_0 = 1.0804e-04
Loss = 4.4369e-03, PNorm = 56.4385, GNorm = 8.1134, lr_0 = 1.0804e-04
Loss = 5.7003e-03, PNorm = 56.4468, GNorm = 6.4534, lr_0 = 1.0804e-04
Loss = 4.5352e-03, PNorm = 56.4547, GNorm = 2.1262, lr_0 = 1.0804e-04
Loss = 4.2504e-03, PNorm = 56.4625, GNorm = 2.5205, lr_0 = 1.0804e-04
Validation rmse logD = 0.629185
Validation R2 logD = 0.731513
Epoch 17
Train function
Loss = 4.0334e-03, PNorm = 56.4703, GNorm = 6.2125, lr_0 = 1.0804e-04
Loss = 4.0042e-03, PNorm = 56.4790, GNorm = 3.2099, lr_0 = 1.0804e-04
Loss = 3.7234e-03, PNorm = 56.4877, GNorm = 1.9543, lr_0 = 1.0804e-04
Loss = 4.7830e-03, PNorm = 56.4951, GNorm = 7.7389, lr_0 = 1.0804e-04
Loss = 4.9805e-03, PNorm = 56.5034, GNorm = 6.8444, lr_0 = 1.0804e-04
Validation rmse logD = 0.640478
Validation R2 logD = 0.721788
Epoch 18
Train function
Loss = 4.1835e-03, PNorm = 56.5117, GNorm = 3.5275, lr_0 = 1.0804e-04
Loss = 3.7374e-03, PNorm = 56.5192, GNorm = 2.0581, lr_0 = 1.0804e-04
Loss = 3.8026e-03, PNorm = 56.5246, GNorm = 1.5243, lr_0 = 1.0804e-04
Loss = 4.3124e-03, PNorm = 56.5324, GNorm = 2.5747, lr_0 = 1.0804e-04
Loss = 4.1150e-03, PNorm = 56.5402, GNorm = 3.8167, lr_0 = 1.0804e-04
Loss = 3.6436e-03, PNorm = 56.5502, GNorm = 5.8516, lr_0 = 1.0804e-04
Validation rmse logD = 0.610506
Validation R2 logD = 0.747217
Epoch 19
Train function
Loss = 4.6935e-03, PNorm = 56.5568, GNorm = 3.1710, lr_0 = 1.0804e-04
Loss = 3.9225e-03, PNorm = 56.5648, GNorm = 2.6916, lr_0 = 1.0804e-04
Loss = 3.7975e-03, PNorm = 56.5720, GNorm = 6.9788, lr_0 = 1.0804e-04
Loss = 4.0870e-03, PNorm = 56.5791, GNorm = 6.7532, lr_0 = 1.0804e-04
Loss = 4.2680e-03, PNorm = 56.5896, GNorm = 4.2063, lr_0 = 1.0804e-04
Loss = 4.0615e-03, PNorm = 56.5989, GNorm = 2.0123, lr_0 = 1.0804e-04
Validation rmse logD = 0.610741
Validation R2 logD = 0.747023
Epoch 20
Train function
Loss = 3.1133e-03, PNorm = 56.6052, GNorm = 5.4244, lr_0 = 1.0804e-04
Loss = 4.1842e-03, PNorm = 56.6128, GNorm = 7.9839, lr_0 = 1.0804e-04
Loss = 3.7886e-03, PNorm = 56.6201, GNorm = 4.3043, lr_0 = 1.0804e-04
Loss = 3.2970e-03, PNorm = 56.6282, GNorm = 5.1371, lr_0 = 1.0804e-04
Loss = 3.6654e-03, PNorm = 56.6351, GNorm = 6.3730, lr_0 = 1.0804e-04
Validation rmse logD = 0.610993
Validation R2 logD = 0.746814
Epoch 21
Train function
Loss = 2.1603e-03, PNorm = 56.6422, GNorm = 5.4941, lr_0 = 1.0804e-04
Loss = 3.4866e-03, PNorm = 56.6501, GNorm = 3.1706, lr_0 = 1.0804e-04
Loss = 3.0890e-03, PNorm = 56.6596, GNorm = 2.8975, lr_0 = 1.0804e-04
Loss = 3.3938e-03, PNorm = 56.6682, GNorm = 1.8310, lr_0 = 1.0804e-04
Loss = 3.9252e-03, PNorm = 56.6729, GNorm = 8.0833, lr_0 = 1.0804e-04
Loss = 4.0741e-03, PNorm = 56.6809, GNorm = 2.8463, lr_0 = 1.0804e-04
Validation rmse logD = 0.618666
Validation R2 logD = 0.740415
Epoch 22
Train function
Loss = 3.4199e-03, PNorm = 56.6878, GNorm = 1.7615, lr_0 = 1.0804e-04
Loss = 3.2023e-03, PNorm = 56.6954, GNorm = 3.0109, lr_0 = 1.0804e-04
Loss = 3.2952e-03, PNorm = 56.7033, GNorm = 4.6713, lr_0 = 1.0804e-04
Loss = 3.8545e-03, PNorm = 56.7128, GNorm = 3.1544, lr_0 = 1.0804e-04
Loss = 3.0909e-03, PNorm = 56.7215, GNorm = 2.8251, lr_0 = 1.0804e-04
Loss = 2.9525e-03, PNorm = 56.7286, GNorm = 3.8197, lr_0 = 1.0804e-04
Validation rmse logD = 0.596398
Validation R2 logD = 0.758765
Epoch 23
Train function
Loss = 3.0424e-03, PNorm = 56.7357, GNorm = 2.4022, lr_0 = 1.0804e-04
Loss = 2.9329e-03, PNorm = 56.7420, GNorm = 3.0588, lr_0 = 1.0804e-04
Loss = 2.9448e-03, PNorm = 56.7504, GNorm = 2.6005, lr_0 = 1.0804e-04
Loss = 2.7219e-03, PNorm = 56.7567, GNorm = 1.8202, lr_0 = 1.0804e-04
Loss = 2.9243e-03, PNorm = 56.7653, GNorm = 3.4047, lr_0 = 1.0804e-04
Validation rmse logD = 0.579955
Validation R2 logD = 0.771884
Epoch 24
Train function
Loss = 3.1345e-03, PNorm = 56.7722, GNorm = 5.3119, lr_0 = 1.0804e-04
Loss = 3.4927e-03, PNorm = 56.7780, GNorm = 10.4560, lr_0 = 1.0804e-04
Loss = 3.0589e-03, PNorm = 56.7860, GNorm = 3.8835, lr_0 = 1.0804e-04
Loss = 3.3045e-03, PNorm = 56.7929, GNorm = 6.0777, lr_0 = 1.0804e-04
Loss = 3.1446e-03, PNorm = 56.8006, GNorm = 1.7750, lr_0 = 1.0804e-04
Loss = 2.9143e-03, PNorm = 56.8073, GNorm = 1.6219, lr_0 = 1.0804e-04
Validation rmse logD = 0.577433
Validation R2 logD = 0.773864
Epoch 25
Train function
Loss = 2.5957e-03, PNorm = 56.8155, GNorm = 4.4611, lr_0 = 1.0804e-04
Loss = 3.1253e-03, PNorm = 56.8237, GNorm = 4.8654, lr_0 = 1.0804e-04
Loss = 2.7831e-03, PNorm = 56.8297, GNorm = 5.0265, lr_0 = 1.0804e-04
Loss = 3.0242e-03, PNorm = 56.8356, GNorm = 6.2659, lr_0 = 1.0804e-04
Loss = 2.4973e-03, PNorm = 56.8426, GNorm = 3.1718, lr_0 = 1.0804e-04
Loss = 3.4545e-03, PNorm = 56.8501, GNorm = 5.9793, lr_0 = 1.0804e-04
Validation rmse logD = 0.584470
Validation R2 logD = 0.768319
Epoch 26
Train function
Loss = 2.3370e-03, PNorm = 56.8582, GNorm = 2.0196, lr_0 = 1.0804e-04
Loss = 2.6733e-03, PNorm = 56.8655, GNorm = 2.5535, lr_0 = 1.0804e-04
Loss = 2.6930e-03, PNorm = 56.8710, GNorm = 2.5413, lr_0 = 1.0804e-04
Loss = 2.8754e-03, PNorm = 56.8774, GNorm = 9.6368, lr_0 = 1.0804e-04
Loss = 3.0832e-03, PNorm = 56.8859, GNorm = 1.6010, lr_0 = 1.0804e-04
Validation rmse logD = 0.603482
Validation R2 logD = 0.753001
Epoch 27
Train function
Loss = 4.6064e-03, PNorm = 56.8935, GNorm = 7.1614, lr_0 = 1.0804e-04
Loss = 2.5790e-03, PNorm = 56.8997, GNorm = 4.6635, lr_0 = 1.0804e-04
Loss = 2.2615e-03, PNorm = 56.9080, GNorm = 2.9345, lr_0 = 1.0804e-04
Loss = 2.6242e-03, PNorm = 56.9135, GNorm = 2.5275, lr_0 = 1.0804e-04
Loss = 2.3533e-03, PNorm = 56.9210, GNorm = 2.5142, lr_0 = 1.0804e-04
Loss = 2.7039e-03, PNorm = 56.9296, GNorm = 2.7720, lr_0 = 1.0804e-04
Validation rmse logD = 0.612163
Validation R2 logD = 0.745843
Epoch 28
Train function
Loss = 2.1779e-03, PNorm = 56.9374, GNorm = 7.6023, lr_0 = 1.0804e-04
Loss = 2.5086e-03, PNorm = 56.9436, GNorm = 1.7543, lr_0 = 1.0804e-04
Loss = 2.6202e-03, PNorm = 56.9490, GNorm = 2.6072, lr_0 = 1.0804e-04
Loss = 2.1448e-03, PNorm = 56.9551, GNorm = 2.1608, lr_0 = 1.0804e-04
Loss = 2.3796e-03, PNorm = 56.9612, GNorm = 2.2997, lr_0 = 1.0804e-04
Loss = 2.5983e-03, PNorm = 56.9682, GNorm = 3.1622, lr_0 = 1.0804e-04
Validation rmse logD = 0.575636
Validation R2 logD = 0.775269
Epoch 29
Train function
Loss = 1.6874e-03, PNorm = 56.9764, GNorm = 3.8860, lr_0 = 1.0804e-04
Loss = 2.5119e-03, PNorm = 56.9839, GNorm = 1.9574, lr_0 = 1.0804e-04
Loss = 2.3302e-03, PNorm = 56.9913, GNorm = 1.7899, lr_0 = 1.0804e-04
Loss = 2.0367e-03, PNorm = 56.9974, GNorm = 1.8067, lr_0 = 1.0804e-04
Loss = 2.6750e-03, PNorm = 57.0023, GNorm = 2.4301, lr_0 = 1.0804e-04
Validation rmse logD = 0.566858
Validation R2 logD = 0.782071
Epoch 30
Train function
Loss = 1.6616e-03, PNorm = 57.0096, GNorm = 3.2728, lr_0 = 1.0804e-04
Loss = 1.8227e-03, PNorm = 57.0175, GNorm = 1.7173, lr_0 = 1.0804e-04
Loss = 2.2381e-03, PNorm = 57.0226, GNorm = 9.8364, lr_0 = 1.0804e-04
Loss = 2.7634e-03, PNorm = 57.0283, GNorm = 2.7493, lr_0 = 1.0804e-04
Loss = 2.1936e-03, PNorm = 57.0362, GNorm = 3.8522, lr_0 = 1.0804e-04
Loss = 3.2463e-03, PNorm = 57.0421, GNorm = 4.2354, lr_0 = 1.0804e-04
Validation rmse logD = 0.566838
Validation R2 logD = 0.782086
Epoch 31
Train function
Loss = 1.6683e-03, PNorm = 57.0472, GNorm = 2.7129, lr_0 = 1.0804e-04
Loss = 2.6053e-03, PNorm = 57.0541, GNorm = 11.8967, lr_0 = 1.0804e-04
Loss = 2.6350e-03, PNorm = 57.0606, GNorm = 2.9328, lr_0 = 1.0804e-04
Loss = 2.3160e-03, PNorm = 57.0665, GNorm = 6.7384, lr_0 = 1.0804e-04
Loss = 2.8690e-03, PNorm = 57.0753, GNorm = 5.5035, lr_0 = 1.0804e-04
Loss = 2.0178e-03, PNorm = 57.0818, GNorm = 4.3764, lr_0 = 1.0804e-04
Validation rmse logD = 0.559402
Validation R2 logD = 0.787766
Epoch 32
Train function
Loss = 2.2082e-03, PNorm = 57.0875, GNorm = 4.5165, lr_0 = 1.0804e-04
Loss = 1.7765e-03, PNorm = 57.0945, GNorm = 1.5437, lr_0 = 1.0804e-04
Loss = 1.8728e-03, PNorm = 57.1008, GNorm = 2.0563, lr_0 = 1.0804e-04
Loss = 2.0641e-03, PNorm = 57.1079, GNorm = 3.2343, lr_0 = 1.0804e-04
Loss = 1.9080e-03, PNorm = 57.1122, GNorm = 3.5224, lr_0 = 1.0804e-04
Validation rmse logD = 0.634742
Validation R2 logD = 0.726749
Epoch 33
Train function
Loss = 2.0408e-03, PNorm = 57.1186, GNorm = 7.1668, lr_0 = 1.0804e-04
Loss = 1.9104e-03, PNorm = 57.1243, GNorm = 1.9336, lr_0 = 1.0804e-04
Loss = 2.3564e-03, PNorm = 57.1311, GNorm = 4.2691, lr_0 = 1.0804e-04
Loss = 2.4278e-03, PNorm = 57.1383, GNorm = 6.9122, lr_0 = 1.0804e-04
Loss = 2.0072e-03, PNorm = 57.1431, GNorm = 1.7672, lr_0 = 1.0804e-04
Loss = 2.0419e-03, PNorm = 57.1487, GNorm = 4.4753, lr_0 = 1.0804e-04
Validation rmse logD = 0.561603
Validation R2 logD = 0.786093
Epoch 34
Train function
Loss = 1.4749e-03, PNorm = 57.1554, GNorm = 2.7776, lr_0 = 1.0804e-04
Loss = 1.4513e-03, PNorm = 57.1632, GNorm = 1.8109, lr_0 = 1.0804e-04
Loss = 2.2309e-03, PNorm = 57.1682, GNorm = 4.8289, lr_0 = 1.0804e-04
Loss = 1.7316e-03, PNorm = 57.1746, GNorm = 2.1985, lr_0 = 1.0804e-04
Loss = 2.0676e-03, PNorm = 57.1800, GNorm = 4.0763, lr_0 = 1.0804e-04
Loss = 1.7961e-03, PNorm = 57.1839, GNorm = 2.7269, lr_0 = 1.0804e-04
Validation rmse logD = 0.598845
Validation R2 logD = 0.756782
Epoch 35
Train function
Loss = 2.2129e-03, PNorm = 57.1899, GNorm = 2.7615, lr_0 = 1.0804e-04
Loss = 2.0715e-03, PNorm = 57.1971, GNorm = 7.9359, lr_0 = 1.0804e-04
Loss = 2.6238e-03, PNorm = 57.2019, GNorm = 9.1286, lr_0 = 1.0804e-04
Loss = 2.1801e-03, PNorm = 57.2081, GNorm = 3.4305, lr_0 = 1.0804e-04
Loss = 1.7932e-03, PNorm = 57.2146, GNorm = 1.6352, lr_0 = 1.0804e-04
Validation rmse logD = 0.554100
Validation R2 logD = 0.791770
Epoch 36
Train function
Loss = 1.5329e-03, PNorm = 57.2221, GNorm = 1.9429, lr_0 = 1.0804e-04
Loss = 1.6169e-03, PNorm = 57.2295, GNorm = 1.8958, lr_0 = 1.0804e-04
Loss = 2.0732e-03, PNorm = 57.2354, GNorm = 2.8020, lr_0 = 1.0804e-04
Loss = 2.0272e-03, PNorm = 57.2412, GNorm = 2.9637, lr_0 = 1.0804e-04
Loss = 1.4713e-03, PNorm = 57.2475, GNorm = 7.7775, lr_0 = 1.0804e-04
Loss = 1.7127e-03, PNorm = 57.2524, GNorm = 4.8353, lr_0 = 1.0804e-04
Validation rmse logD = 0.562811
Validation R2 logD = 0.785171
Epoch 37
Train function
Loss = 1.6006e-03, PNorm = 57.2591, GNorm = 2.0353, lr_0 = 1.0804e-04
Loss = 1.6271e-03, PNorm = 57.2644, GNorm = 6.3593, lr_0 = 1.0804e-04
Loss = 1.6773e-03, PNorm = 57.2699, GNorm = 6.0117, lr_0 = 1.0804e-04
Loss = 1.5110e-03, PNorm = 57.2773, GNorm = 3.9566, lr_0 = 1.0804e-04
Loss = 2.0429e-03, PNorm = 57.2828, GNorm = 2.7360, lr_0 = 1.0804e-04
Loss = 1.4441e-03, PNorm = 57.2871, GNorm = 1.8048, lr_0 = 1.0804e-04
Validation rmse logD = 0.581097
Validation R2 logD = 0.770984
Epoch 38
Train function
Loss = 1.6080e-03, PNorm = 57.2916, GNorm = 7.7825, lr_0 = 1.0804e-04
Loss = 1.4806e-03, PNorm = 57.2957, GNorm = 2.6363, lr_0 = 1.0804e-04
Loss = 1.7774e-03, PNorm = 57.3024, GNorm = 1.9225, lr_0 = 1.0804e-04
Loss = 1.7858e-03, PNorm = 57.3087, GNorm = 6.7429, lr_0 = 1.0804e-04
Loss = 2.1880e-03, PNorm = 57.3123, GNorm = 3.3011, lr_0 = 1.0804e-04
Validation rmse logD = 0.585837
Validation R2 logD = 0.767233
Epoch 39
Train function
Loss = 1.5177e-03, PNorm = 57.3199, GNorm = 5.8870, lr_0 = 1.0804e-04
Loss = 1.6733e-03, PNorm = 57.3252, GNorm = 9.9716, lr_0 = 1.0804e-04
Loss = 1.5353e-03, PNorm = 57.3303, GNorm = 3.2470, lr_0 = 1.0804e-04
Loss = 2.0294e-03, PNorm = 57.3363, GNorm = 9.9856, lr_0 = 1.0804e-04
Loss = 2.2568e-03, PNorm = 57.3404, GNorm = 4.2094, lr_0 = 1.0804e-04
Loss = 1.6361e-03, PNorm = 57.3478, GNorm = 3.7534, lr_0 = 1.0804e-04
Validation rmse logD = 0.546858
Validation R2 logD = 0.797177
Epoch 40
Train function
Loss = 1.2419e-03, PNorm = 57.3539, GNorm = 1.7102, lr_0 = 1.0804e-04
Loss = 1.4050e-03, PNorm = 57.3595, GNorm = 3.9978, lr_0 = 1.0804e-04
Loss = 1.4813e-03, PNorm = 57.3657, GNorm = 6.5927, lr_0 = 1.0804e-04
Loss = 1.7038e-03, PNorm = 57.3690, GNorm = 4.7888, lr_0 = 1.0804e-04
Loss = 1.8640e-03, PNorm = 57.3739, GNorm = 7.5525, lr_0 = 1.0804e-04
Loss = 2.3274e-03, PNorm = 57.3806, GNorm = 3.5092, lr_0 = 1.0804e-04
Validation rmse logD = 0.572783
Validation R2 logD = 0.777491
Epoch 41
Train function
Loss = 1.4491e-03, PNorm = 57.3876, GNorm = 4.4548, lr_0 = 1.0804e-04
Loss = 1.7699e-03, PNorm = 57.3934, GNorm = 1.7522, lr_0 = 1.0804e-04
Loss = 1.7468e-03, PNorm = 57.4003, GNorm = 3.2523, lr_0 = 1.0804e-04
Loss = 1.2571e-03, PNorm = 57.4066, GNorm = 3.3074, lr_0 = 1.0804e-04
Loss = 1.2059e-03, PNorm = 57.4116, GNorm = 3.1396, lr_0 = 1.0804e-04
Validation rmse logD = 0.597020
Validation R2 logD = 0.758262
Epoch 42
Train function
Loss = 1.4059e-03, PNorm = 57.4170, GNorm = 5.4761, lr_0 = 1.0804e-04
Loss = 1.6310e-03, PNorm = 57.4219, GNorm = 2.2489, lr_0 = 1.0804e-04
Loss = 1.4648e-03, PNorm = 57.4290, GNorm = 2.0362, lr_0 = 1.0804e-04
Loss = 1.7103e-03, PNorm = 57.4345, GNorm = 1.2349, lr_0 = 1.0804e-04
Loss = 1.2925e-03, PNorm = 57.4401, GNorm = 4.0755, lr_0 = 1.0804e-04
Loss = 1.4966e-03, PNorm = 57.4459, GNorm = 2.8195, lr_0 = 1.0804e-04
Validation rmse logD = 0.535156
Validation R2 logD = 0.805765
Epoch 43
Train function
Loss = 1.2475e-03, PNorm = 57.4492, GNorm = 3.1614, lr_0 = 1.0804e-04
Loss = 1.6269e-03, PNorm = 57.4532, GNorm = 3.9519, lr_0 = 1.0804e-04
Loss = 1.3570e-03, PNorm = 57.4586, GNorm = 4.0368, lr_0 = 1.0804e-04
Loss = 1.2962e-03, PNorm = 57.4632, GNorm = 1.9145, lr_0 = 1.0804e-04
Loss = 1.4102e-03, PNorm = 57.4689, GNorm = 1.3955, lr_0 = 1.0804e-04
Loss = 1.1441e-03, PNorm = 57.4743, GNorm = 2.7932, lr_0 = 1.0804e-04
Validation rmse logD = 0.548684
Validation R2 logD = 0.795821
Epoch 44
Train function
Loss = 1.2022e-03, PNorm = 57.4779, GNorm = 2.8391, lr_0 = 1.0804e-04
Loss = 1.1561e-03, PNorm = 57.4814, GNorm = 1.6685, lr_0 = 1.0804e-04
Loss = 1.1509e-03, PNorm = 57.4859, GNorm = 3.5871, lr_0 = 1.0804e-04
Loss = 1.1982e-03, PNorm = 57.4915, GNorm = 4.8610, lr_0 = 1.0804e-04
Loss = 1.4783e-03, PNorm = 57.4965, GNorm = 6.5724, lr_0 = 1.0804e-04
Validation rmse logD = 0.554784
Validation R2 logD = 0.791255
Epoch 45
Train function
Loss = 8.3750e-04, PNorm = 57.5025, GNorm = 1.5400, lr_0 = 1.0804e-04
Loss = 1.0248e-03, PNorm = 57.5086, GNorm = 1.9675, lr_0 = 1.0804e-04
Loss = 1.0955e-03, PNorm = 57.5130, GNorm = 2.2205, lr_0 = 1.0804e-04
Loss = 1.2119e-03, PNorm = 57.5161, GNorm = 3.1920, lr_0 = 1.0804e-04
Loss = 1.2498e-03, PNorm = 57.5212, GNorm = 5.2660, lr_0 = 1.0804e-04
Loss = 1.5284e-03, PNorm = 57.5265, GNorm = 3.3584, lr_0 = 1.0804e-04
Validation rmse logD = 0.583142
Validation R2 logD = 0.769370
Epoch 46
Train function
Loss = 1.5752e-03, PNorm = 57.5317, GNorm = 8.3175, lr_0 = 1.0804e-04
Loss = 1.2267e-03, PNorm = 57.5359, GNorm = 2.6611, lr_0 = 1.0804e-04
Loss = 1.8438e-03, PNorm = 57.5414, GNorm = 1.9077, lr_0 = 1.0804e-04
Loss = 1.0176e-03, PNorm = 57.5479, GNorm = 1.7420, lr_0 = 1.0804e-04
Loss = 1.3052e-03, PNorm = 57.5520, GNorm = 4.3560, lr_0 = 1.0804e-04
Loss = 1.3526e-03, PNorm = 57.5566, GNorm = 2.6227, lr_0 = 1.0804e-04
Validation rmse logD = 0.554599
Validation R2 logD = 0.791395
Epoch 47
Train function
Loss = 1.1070e-03, PNorm = 57.5598, GNorm = 2.7347, lr_0 = 1.0804e-04
Loss = 1.1577e-03, PNorm = 57.5641, GNorm = 3.7677, lr_0 = 1.0804e-04
Loss = 1.2834e-03, PNorm = 57.5682, GNorm = 7.0536, lr_0 = 1.0804e-04
Loss = 1.2610e-03, PNorm = 57.5726, GNorm = 3.8106, lr_0 = 1.0804e-04
Loss = 1.3036e-03, PNorm = 57.5778, GNorm = 5.8347, lr_0 = 1.0804e-04
Validation rmse logD = 0.539887
Validation R2 logD = 0.802315
Epoch 48
Train function
Loss = 7.8433e-04, PNorm = 57.5832, GNorm = 1.5906, lr_0 = 1.0804e-04
Loss = 1.2935e-03, PNorm = 57.5867, GNorm = 6.1342, lr_0 = 1.0804e-04
Loss = 1.6571e-03, PNorm = 57.5932, GNorm = 2.1221, lr_0 = 1.0804e-04
Loss = 1.0283e-03, PNorm = 57.5992, GNorm = 1.8398, lr_0 = 1.0804e-04
Loss = 9.6900e-04, PNorm = 57.6043, GNorm = 2.0217, lr_0 = 1.0804e-04
Loss = 9.8526e-04, PNorm = 57.6087, GNorm = 3.5145, lr_0 = 1.0804e-04
Validation rmse logD = 0.564468
Validation R2 logD = 0.783904
Epoch 49
Train function
Loss = 1.2229e-03, PNorm = 57.6137, GNorm = 2.2315, lr_0 = 1.0804e-04
Loss = 1.1686e-03, PNorm = 57.6187, GNorm = 5.6963, lr_0 = 1.0804e-04
Loss = 1.0998e-03, PNorm = 57.6230, GNorm = 7.0700, lr_0 = 1.0804e-04
Loss = 1.5160e-03, PNorm = 57.6273, GNorm = 6.7551, lr_0 = 1.0804e-04
Loss = 1.0726e-03, PNorm = 57.6303, GNorm = 4.4348, lr_0 = 1.0804e-04
Loss = 1.4774e-03, PNorm = 57.6350, GNorm = 1.8168, lr_0 = 1.0804e-04
Validation rmse logD = 0.591786
Validation R2 logD = 0.762482
Epoch 50
Train function
Loss = 1.2943e-03, PNorm = 57.6392, GNorm = 2.6072, lr_0 = 1.0804e-04
Loss = 1.2231e-03, PNorm = 57.6452, GNorm = 4.2440, lr_0 = 1.0804e-04
Loss = 1.5279e-03, PNorm = 57.6512, GNorm = 10.8746, lr_0 = 1.0804e-04
Loss = 1.4145e-03, PNorm = 57.6564, GNorm = 4.8453, lr_0 = 1.0804e-04
Loss = 1.2680e-03, PNorm = 57.6612, GNorm = 3.0239, lr_0 = 1.0804e-04
Validation rmse logD = 0.538145
Validation R2 logD = 0.803589
Epoch 51
Train function
Loss = 7.1990e-04, PNorm = 57.6663, GNorm = 1.6096, lr_0 = 1.0804e-04
Loss = 9.0944e-04, PNorm = 57.6707, GNorm = 1.3713, lr_0 = 1.0804e-04
Loss = 1.0268e-03, PNorm = 57.6749, GNorm = 8.5104, lr_0 = 1.0804e-04
Loss = 1.2037e-03, PNorm = 57.6801, GNorm = 3.2911, lr_0 = 1.0804e-04
Loss = 1.1178e-03, PNorm = 57.6856, GNorm = 1.9941, lr_0 = 1.0804e-04
Loss = 1.3135e-03, PNorm = 57.6894, GNorm = 3.7811, lr_0 = 1.0804e-04
Validation rmse logD = 0.619811
Validation R2 logD = 0.739453
Epoch 52
Train function
Loss = 1.8077e-03, PNorm = 57.6929, GNorm = 3.8490, lr_0 = 1.0804e-04
Loss = 1.0415e-03, PNorm = 57.6971, GNorm = 4.8548, lr_0 = 1.0804e-04
Loss = 1.3379e-03, PNorm = 57.7024, GNorm = 6.8865, lr_0 = 1.0804e-04
Loss = 1.6300e-03, PNorm = 57.7066, GNorm = 8.3639, lr_0 = 1.0804e-04
Loss = 1.5302e-03, PNorm = 57.7109, GNorm = 2.6941, lr_0 = 1.0804e-04
Loss = 1.1519e-03, PNorm = 57.7186, GNorm = 5.2368, lr_0 = 1.0804e-04
Validation rmse logD = 0.562711
Validation R2 logD = 0.785248
Epoch 53
Train function
Loss = 9.6041e-04, PNorm = 57.7239, GNorm = 2.0197, lr_0 = 1.0804e-04
Loss = 1.0627e-03, PNorm = 57.7285, GNorm = 2.0897, lr_0 = 1.0804e-04
Loss = 9.7226e-04, PNorm = 57.7327, GNorm = 1.5102, lr_0 = 1.0804e-04
Loss = 1.0472e-03, PNorm = 57.7368, GNorm = 5.5324, lr_0 = 1.0804e-04
Loss = 1.0083e-03, PNorm = 57.7395, GNorm = 4.0137, lr_0 = 1.0804e-04
Validation rmse logD = 0.532853
Validation R2 logD = 0.807433
Epoch 54
Train function
Loss = 6.9784e-04, PNorm = 57.7441, GNorm = 2.9110, lr_0 = 1.0804e-04
Loss = 1.0686e-03, PNorm = 57.7485, GNorm = 3.3428, lr_0 = 1.0804e-04
Loss = 1.0043e-03, PNorm = 57.7530, GNorm = 1.2258, lr_0 = 1.0804e-04
Loss = 1.1226e-03, PNorm = 57.7575, GNorm = 7.9894, lr_0 = 1.0804e-04
Loss = 8.5251e-04, PNorm = 57.7612, GNorm = 1.5995, lr_0 = 1.0804e-04
Loss = 8.7704e-04, PNorm = 57.7657, GNorm = 1.5314, lr_0 = 1.0804e-04
Validation rmse logD = 0.532193
Validation R2 logD = 0.807909
Epoch 55
Train function
Loss = 7.7558e-04, PNorm = 57.7694, GNorm = 1.4396, lr_0 = 1.0804e-04
Loss = 9.9298e-04, PNorm = 57.7736, GNorm = 5.6435, lr_0 = 1.0804e-04
Loss = 8.4574e-04, PNorm = 57.7775, GNorm = 4.6731, lr_0 = 1.0804e-04
Loss = 1.0129e-03, PNorm = 57.7821, GNorm = 1.5493, lr_0 = 1.0804e-04
Loss = 8.3042e-04, PNorm = 57.7862, GNorm = 2.6696, lr_0 = 1.0804e-04
Loss = 1.1054e-03, PNorm = 57.7894, GNorm = 2.0771, lr_0 = 1.0804e-04
Validation rmse logD = 0.538113
Validation R2 logD = 0.803613
Epoch 56
Train function
Loss = 7.7183e-04, PNorm = 57.7939, GNorm = 1.8352, lr_0 = 1.0804e-04
Loss = 8.8286e-04, PNorm = 57.7983, GNorm = 1.1329, lr_0 = 1.0804e-04
Loss = 1.0378e-03, PNorm = 57.8022, GNorm = 1.4210, lr_0 = 1.0804e-04
Loss = 9.4390e-04, PNorm = 57.8064, GNorm = 3.6659, lr_0 = 1.0804e-04
Loss = 9.3601e-04, PNorm = 57.8100, GNorm = 3.1541, lr_0 = 1.0804e-04
Validation rmse logD = 0.536512
Validation R2 logD = 0.804779
Epoch 57
Train function
Loss = 7.6624e-04, PNorm = 57.8136, GNorm = 3.8957, lr_0 = 1.0804e-04
Loss = 9.2766e-04, PNorm = 57.8160, GNorm = 3.5397, lr_0 = 1.0804e-04
Loss = 9.2134e-04, PNorm = 57.8204, GNorm = 1.5623, lr_0 = 1.0804e-04
Loss = 1.0121e-03, PNorm = 57.8247, GNorm = 1.3206, lr_0 = 1.0804e-04
Loss = 1.0496e-03, PNorm = 57.8291, GNorm = 2.6908, lr_0 = 1.0804e-04
Loss = 8.6292e-04, PNorm = 57.8324, GNorm = 2.7209, lr_0 = 1.0804e-04
Validation rmse logD = 0.574040
Validation R2 logD = 0.776514
Epoch 58
Train function
Loss = 8.9736e-04, PNorm = 57.8369, GNorm = 3.7008, lr_0 = 1.0804e-04
Loss = 9.3149e-04, PNorm = 57.8417, GNorm = 3.3438, lr_0 = 1.0804e-04
Loss = 6.8955e-04, PNorm = 57.8462, GNorm = 1.2271, lr_0 = 1.0804e-04
Loss = 1.1931e-03, PNorm = 57.8497, GNorm = 1.5065, lr_0 = 1.0804e-04
Loss = 7.3470e-04, PNorm = 57.8531, GNorm = 3.2783, lr_0 = 1.0804e-04
Loss = 9.5221e-04, PNorm = 57.8574, GNorm = 1.8952, lr_0 = 1.0804e-04
Validation rmse logD = 0.531604
Validation R2 logD = 0.808334
Epoch 59
Train function
Loss = 7.9291e-04, PNorm = 57.8611, GNorm = 3.6212, lr_0 = 1.0804e-04
Loss = 8.3851e-04, PNorm = 57.8657, GNorm = 1.6415, lr_0 = 1.0804e-04
Loss = 8.3179e-04, PNorm = 57.8687, GNorm = 4.4118, lr_0 = 1.0804e-04
Loss = 9.1904e-04, PNorm = 57.8721, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 8.0159e-04, PNorm = 57.8760, GNorm = 1.3399, lr_0 = 1.0804e-04
Validation rmse logD = 0.550201
Validation R2 logD = 0.794690
Epoch 60
Train function
Loss = 9.2377e-04, PNorm = 57.8802, GNorm = 2.1308, lr_0 = 1.0804e-04
Loss = 6.7181e-04, PNorm = 57.8831, GNorm = 2.2689, lr_0 = 1.0804e-04
Loss = 7.7131e-04, PNorm = 57.8864, GNorm = 3.8643, lr_0 = 1.0804e-04
Loss = 1.0069e-03, PNorm = 57.8896, GNorm = 3.4489, lr_0 = 1.0804e-04
Loss = 9.2824e-04, PNorm = 57.8937, GNorm = 1.5203, lr_0 = 1.0804e-04
Loss = 8.7425e-04, PNorm = 57.8989, GNorm = 3.1332, lr_0 = 1.0804e-04
Validation rmse logD = 0.524125
Validation R2 logD = 0.813690
Epoch 61
Train function
Loss = 1.1533e-03, PNorm = 57.9028, GNorm = 5.3523, lr_0 = 1.0804e-04
Loss = 7.8036e-04, PNorm = 57.9067, GNorm = 5.6854, lr_0 = 1.0804e-04
Loss = 6.9317e-04, PNorm = 57.9113, GNorm = 1.9225, lr_0 = 1.0804e-04
Loss = 7.5363e-04, PNorm = 57.9154, GNorm = 4.2136, lr_0 = 1.0804e-04
Loss = 8.3828e-04, PNorm = 57.9184, GNorm = 2.0604, lr_0 = 1.0804e-04
Loss = 7.8170e-04, PNorm = 57.9222, GNorm = 0.8417, lr_0 = 1.0804e-04
Validation rmse logD = 0.530080
Validation R2 logD = 0.809432
Epoch 62
Train function
Loss = 9.5039e-04, PNorm = 57.9251, GNorm = 6.3487, lr_0 = 1.0804e-04
Loss = 6.9056e-04, PNorm = 57.9291, GNorm = 1.0965, lr_0 = 1.0804e-04
Loss = 7.7073e-04, PNorm = 57.9338, GNorm = 0.9992, lr_0 = 1.0804e-04
Loss = 6.4518e-04, PNorm = 57.9379, GNorm = 1.3103, lr_0 = 1.0804e-04
Loss = 8.5873e-04, PNorm = 57.9415, GNorm = 3.7076, lr_0 = 1.0804e-04
Validation rmse logD = 0.552914
Validation R2 logD = 0.792660
Epoch 63
Train function
Loss = 7.3286e-04, PNorm = 57.9458, GNorm = 4.9038, lr_0 = 1.0804e-04
Loss = 7.4564e-04, PNorm = 57.9483, GNorm = 2.0980, lr_0 = 1.0804e-04
Loss = 8.6258e-04, PNorm = 57.9502, GNorm = 3.6235, lr_0 = 1.0804e-04
Loss = 1.0402e-03, PNorm = 57.9543, GNorm = 6.1647, lr_0 = 1.0804e-04
Loss = 7.7400e-04, PNorm = 57.9587, GNorm = 1.3402, lr_0 = 1.0804e-04
Loss = 8.4167e-04, PNorm = 57.9632, GNorm = 4.9874, lr_0 = 1.0804e-04
Validation rmse logD = 0.531238
Validation R2 logD = 0.808599
Epoch 64
Train function
Loss = 8.0388e-04, PNorm = 57.9685, GNorm = 2.9096, lr_0 = 1.0804e-04
Loss = 7.5568e-04, PNorm = 57.9731, GNorm = 1.2265, lr_0 = 1.0804e-04
Loss = 8.8130e-04, PNorm = 57.9777, GNorm = 7.1432, lr_0 = 1.0804e-04
Loss = 7.3509e-04, PNorm = 57.9801, GNorm = 1.8010, lr_0 = 1.0804e-04
Loss = 6.5337e-04, PNorm = 57.9830, GNorm = 1.1799, lr_0 = 1.0804e-04
Loss = 8.0803e-04, PNorm = 57.9865, GNorm = 6.8003, lr_0 = 1.0804e-04
Validation rmse logD = 0.530063
Validation R2 logD = 0.809444
Epoch 65
Train function
Loss = 8.8848e-04, PNorm = 57.9905, GNorm = 5.7781, lr_0 = 1.0804e-04
Loss = 8.3606e-04, PNorm = 57.9944, GNorm = 4.8264, lr_0 = 1.0804e-04
Loss = 8.4294e-04, PNorm = 57.9985, GNorm = 6.1449, lr_0 = 1.0804e-04
Loss = 9.6374e-04, PNorm = 58.0038, GNorm = 7.3038, lr_0 = 1.0804e-04
Loss = 1.1308e-03, PNorm = 58.0065, GNorm = 5.7458, lr_0 = 1.0804e-04
Validation rmse logD = 0.571132
Validation R2 logD = 0.778772
Epoch 66
Train function
Loss = 1.6602e-03, PNorm = 58.0102, GNorm = 8.1162, lr_0 = 1.0804e-04
Loss = 1.0777e-03, PNorm = 58.0139, GNorm = 5.2124, lr_0 = 1.0804e-04
Loss = 8.2500e-04, PNorm = 58.0182, GNorm = 1.7725, lr_0 = 1.0804e-04
Loss = 1.0837e-03, PNorm = 58.0223, GNorm = 2.2243, lr_0 = 1.0804e-04
Loss = 9.8608e-04, PNorm = 58.0235, GNorm = 1.7271, lr_0 = 1.0804e-04
Loss = 7.5292e-04, PNorm = 58.0278, GNorm = 3.2762, lr_0 = 1.0804e-04
Validation rmse logD = 0.534785
Validation R2 logD = 0.806034
Epoch 67
Train function
Loss = 7.7950e-04, PNorm = 58.0327, GNorm = 1.0577, lr_0 = 1.0804e-04
Loss = 5.8575e-04, PNorm = 58.0372, GNorm = 1.6836, lr_0 = 1.0804e-04
Loss = 7.4032e-04, PNorm = 58.0405, GNorm = 2.8739, lr_0 = 1.0804e-04
Loss = 7.2299e-04, PNorm = 58.0445, GNorm = 1.6199, lr_0 = 1.0804e-04
Loss = 6.3466e-04, PNorm = 58.0476, GNorm = 3.1066, lr_0 = 1.0804e-04
Loss = 7.7029e-04, PNorm = 58.0523, GNorm = 7.5550, lr_0 = 1.0804e-04
Validation rmse logD = 0.532346
Validation R2 logD = 0.807800
Epoch 68
Train function
Loss = 7.2614e-04, PNorm = 58.0565, GNorm = 2.6143, lr_0 = 1.0804e-04
Loss = 8.2833e-04, PNorm = 58.0587, GNorm = 0.9845, lr_0 = 1.0804e-04
Loss = 8.3117e-04, PNorm = 58.0635, GNorm = 5.1190, lr_0 = 1.0804e-04
Loss = 9.8147e-04, PNorm = 58.0672, GNorm = 1.3217, lr_0 = 1.0804e-04
Loss = 8.2990e-04, PNorm = 58.0699, GNorm = 5.8809, lr_0 = 1.0804e-04
Validation rmse logD = 0.536861
Validation R2 logD = 0.804525
Epoch 69
Train function
Loss = 7.8050e-04, PNorm = 58.0741, GNorm = 3.4282, lr_0 = 1.0804e-04
Loss = 5.6521e-04, PNorm = 58.0795, GNorm = 2.6761, lr_0 = 1.0804e-04
Loss = 7.8856e-04, PNorm = 58.0833, GNorm = 2.0874, lr_0 = 1.0804e-04
Loss = 6.0929e-04, PNorm = 58.0866, GNorm = 3.8031, lr_0 = 1.0804e-04
Loss = 8.0237e-04, PNorm = 58.0900, GNorm = 1.7038, lr_0 = 1.0804e-04
Loss = 5.8414e-04, PNorm = 58.0921, GNorm = 1.1121, lr_0 = 1.0804e-04
Validation rmse logD = 0.532892
Validation R2 logD = 0.807405
Epoch 70
Train function
Loss = 4.4873e-04, PNorm = 58.0951, GNorm = 1.3129, lr_0 = 1.0804e-04
Loss = 5.1858e-04, PNorm = 58.0989, GNorm = 1.3605, lr_0 = 1.0804e-04
Loss = 8.3799e-04, PNorm = 58.1027, GNorm = 2.1818, lr_0 = 1.0804e-04
Loss = 5.3309e-04, PNorm = 58.1060, GNorm = 3.0483, lr_0 = 1.0804e-04
Loss = 5.9429e-04, PNorm = 58.1081, GNorm = 1.0731, lr_0 = 1.0804e-04
Loss = 5.4356e-04, PNorm = 58.1111, GNorm = 2.2293, lr_0 = 1.0804e-04
Validation rmse logD = 0.530971
Validation R2 logD = 0.808791
Epoch 71
Train function
Loss = 5.0689e-04, PNorm = 58.1149, GNorm = 0.9983, lr_0 = 1.0804e-04
Loss = 4.8515e-04, PNorm = 58.1176, GNorm = 3.2407, lr_0 = 1.0804e-04
Loss = 5.7569e-04, PNorm = 58.1204, GNorm = 2.5404, lr_0 = 1.0804e-04
Loss = 5.7420e-04, PNorm = 58.1242, GNorm = 3.6546, lr_0 = 1.0804e-04
Loss = 8.9859e-04, PNorm = 58.1267, GNorm = 1.7856, lr_0 = 1.0804e-04
Validation rmse logD = 0.525921
Validation R2 logD = 0.812411
Epoch 72
Train function
Loss = 4.6981e-04, PNorm = 58.1302, GNorm = 1.0752, lr_0 = 1.0804e-04
Loss = 5.7735e-04, PNorm = 58.1330, GNorm = 1.8322, lr_0 = 1.0804e-04
Loss = 6.0574e-04, PNorm = 58.1362, GNorm = 6.2431, lr_0 = 1.0804e-04
Loss = 1.0860e-03, PNorm = 58.1388, GNorm = 8.0936, lr_0 = 1.0804e-04
Loss = 1.2192e-03, PNorm = 58.1418, GNorm = 6.2147, lr_0 = 1.0804e-04
Loss = 1.3473e-03, PNorm = 58.1468, GNorm = 1.0715, lr_0 = 1.0804e-04
Validation rmse logD = 0.535863
Validation R2 logD = 0.805251
Epoch 73
Train function
Loss = 8.1997e-04, PNorm = 58.1519, GNorm = 3.0503, lr_0 = 1.0804e-04
Loss = 8.2375e-04, PNorm = 58.1571, GNorm = 3.6457, lr_0 = 1.0804e-04
Loss = 1.0311e-03, PNorm = 58.1608, GNorm = 6.0479, lr_0 = 1.0804e-04
Loss = 9.9649e-04, PNorm = 58.1639, GNorm = 1.4865, lr_0 = 1.0804e-04
Loss = 7.3215e-04, PNorm = 58.1690, GNorm = 0.7000, lr_0 = 1.0804e-04
Loss = 7.7771e-04, PNorm = 58.1741, GNorm = 5.3212, lr_0 = 1.0804e-04
Validation rmse logD = 0.534566
Validation R2 logD = 0.806193
Epoch 74
Train function
Loss = 6.3384e-04, PNorm = 58.1783, GNorm = 4.5895, lr_0 = 1.0804e-04
Loss = 5.7464e-04, PNorm = 58.1816, GNorm = 5.9911, lr_0 = 1.0804e-04
Loss = 6.1010e-04, PNorm = 58.1850, GNorm = 4.1076, lr_0 = 1.0804e-04
Loss = 4.7663e-04, PNorm = 58.1877, GNorm = 1.4264, lr_0 = 1.0804e-04
Loss = 7.2779e-04, PNorm = 58.1919, GNorm = 1.9227, lr_0 = 1.0804e-04
Validation rmse logD = 0.534429
Validation R2 logD = 0.806292
Epoch 75
Train function
Loss = 4.7057e-04, PNorm = 58.1951, GNorm = 1.6867, lr_0 = 1.0804e-04
Loss = 7.1798e-04, PNorm = 58.1992, GNorm = 1.6477, lr_0 = 1.0804e-04
Loss = 5.6447e-04, PNorm = 58.2023, GNorm = 1.0499, lr_0 = 1.0804e-04
Loss = 5.1004e-04, PNorm = 58.2058, GNorm = 1.1355, lr_0 = 1.0804e-04
Loss = 4.9808e-04, PNorm = 58.2085, GNorm = 1.1843, lr_0 = 1.0804e-04
Loss = 5.4064e-04, PNorm = 58.2110, GNorm = 3.0749, lr_0 = 1.0804e-04
Validation rmse logD = 0.534275
Validation R2 logD = 0.806404
Epoch 76
Train function
Loss = 7.8088e-04, PNorm = 58.2123, GNorm = 1.7917, lr_0 = 1.0804e-04
Loss = 5.2807e-04, PNorm = 58.2159, GNorm = 1.5595, lr_0 = 1.0804e-04
Loss = 7.2364e-04, PNorm = 58.2187, GNorm = 5.1611, lr_0 = 1.0804e-04
Loss = 1.1352e-03, PNorm = 58.2217, GNorm = 3.1654, lr_0 = 1.0804e-04
Loss = 7.9531e-04, PNorm = 58.2264, GNorm = 4.1927, lr_0 = 1.0804e-04
Loss = 6.3344e-04, PNorm = 58.2322, GNorm = 1.5493, lr_0 = 1.0804e-04
Validation rmse logD = 0.521826
Validation R2 logD = 0.815321
Epoch 77
Train function
Loss = 4.4553e-04, PNorm = 58.2369, GNorm = 3.2647, lr_0 = 1.0804e-04
Loss = 6.7160e-04, PNorm = 58.2395, GNorm = 1.7674, lr_0 = 1.0804e-04
Loss = 5.1160e-04, PNorm = 58.2423, GNorm = 2.7456, lr_0 = 1.0804e-04
Loss = 5.8451e-04, PNorm = 58.2453, GNorm = 1.9262, lr_0 = 1.0804e-04
Loss = 7.7825e-04, PNorm = 58.2483, GNorm = 3.0195, lr_0 = 1.0804e-04
Validation rmse logD = 0.526531
Validation R2 logD = 0.811975
Epoch 78
Train function
Loss = 5.8105e-04, PNorm = 58.2513, GNorm = 2.3061, lr_0 = 1.0804e-04
Loss = 5.6941e-04, PNorm = 58.2541, GNorm = 6.6509, lr_0 = 1.0804e-04
Loss = 5.8191e-04, PNorm = 58.2572, GNorm = 3.2667, lr_0 = 1.0804e-04
Loss = 5.4899e-04, PNorm = 58.2593, GNorm = 2.5886, lr_0 = 1.0804e-04
Loss = 7.3787e-04, PNorm = 58.2612, GNorm = 3.8165, lr_0 = 1.0804e-04
Loss = 6.5154e-04, PNorm = 58.2653, GNorm = 1.0092, lr_0 = 1.0804e-04
Validation rmse logD = 0.520923
Validation R2 logD = 0.815959
Epoch 79
Train function
Loss = 2.3490e-04, PNorm = 58.2691, GNorm = 2.0667, lr_0 = 1.0804e-04
Loss = 4.5378e-04, PNorm = 58.2726, GNorm = 0.8662, lr_0 = 1.0804e-04
Loss = 6.2699e-04, PNorm = 58.2749, GNorm = 4.4855, lr_0 = 1.0804e-04
Loss = 7.0710e-04, PNorm = 58.2766, GNorm = 3.9253, lr_0 = 1.0804e-04
Loss = 6.0381e-04, PNorm = 58.2805, GNorm = 2.2243, lr_0 = 1.0804e-04
Loss = 6.5283e-04, PNorm = 58.2838, GNorm = 1.3119, lr_0 = 1.0804e-04
Validation rmse logD = 0.526508
Validation R2 logD = 0.811991
Epoch 80
Train function
Loss = 3.9284e-04, PNorm = 58.2887, GNorm = 3.5145, lr_0 = 1.0804e-04
Loss = 4.0679e-04, PNorm = 58.2909, GNorm = 1.3575, lr_0 = 1.0804e-04
Loss = 4.1045e-04, PNorm = 58.2940, GNorm = 1.0396, lr_0 = 1.0804e-04
Loss = 6.2242e-04, PNorm = 58.2964, GNorm = 4.7740, lr_0 = 1.0804e-04
Loss = 7.9667e-04, PNorm = 58.2981, GNorm = 8.4045, lr_0 = 1.0804e-04
Validation rmse logD = 0.556231
Validation R2 logD = 0.790165
Epoch 81
Train function
Loss = 1.4876e-03, PNorm = 58.3014, GNorm = 7.8237, lr_0 = 1.0804e-04
Loss = 1.2042e-03, PNorm = 58.3047, GNorm = 3.0803, lr_0 = 1.0804e-04
Loss = 1.0164e-03, PNorm = 58.3101, GNorm = 1.5393, lr_0 = 1.0804e-04
Loss = 5.3237e-04, PNorm = 58.3159, GNorm = 2.2964, lr_0 = 1.0804e-04
Loss = 4.7030e-04, PNorm = 58.3199, GNorm = 1.0860, lr_0 = 1.0804e-04
Loss = 5.9319e-04, PNorm = 58.3236, GNorm = 2.6620, lr_0 = 1.0804e-04
Validation rmse logD = 0.545420
Validation R2 logD = 0.798243
Epoch 82
Train function
Loss = 5.7701e-04, PNorm = 58.3272, GNorm = 5.1344, lr_0 = 1.0804e-04
Loss = 7.1847e-04, PNorm = 58.3294, GNorm = 6.2380, lr_0 = 1.0804e-04
Loss = 5.3743e-04, PNorm = 58.3328, GNorm = 1.3676, lr_0 = 1.0804e-04
Loss = 3.9089e-04, PNorm = 58.3356, GNorm = 2.0100, lr_0 = 1.0804e-04
Loss = 4.7989e-04, PNorm = 58.3388, GNorm = 1.2826, lr_0 = 1.0804e-04
Loss = 5.8816e-04, PNorm = 58.3420, GNorm = 2.2849, lr_0 = 1.0804e-04
Validation rmse logD = 0.539612
Validation R2 logD = 0.802517
Epoch 83
Train function
Loss = 3.4431e-04, PNorm = 58.3452, GNorm = 1.2473, lr_0 = 1.0804e-04
Loss = 5.1358e-04, PNorm = 58.3475, GNorm = 2.8406, lr_0 = 1.0804e-04
Loss = 4.3782e-04, PNorm = 58.3501, GNorm = 2.7727, lr_0 = 1.0804e-04
Loss = 5.7788e-04, PNorm = 58.3541, GNorm = 1.5838, lr_0 = 1.0804e-04
Loss = 5.2624e-04, PNorm = 58.3577, GNorm = 2.6637, lr_0 = 1.0804e-04
Validation rmse logD = 0.526738
Validation R2 logD = 0.811827
Epoch 84
Train function
Loss = 3.0940e-04, PNorm = 58.3609, GNorm = 1.1308, lr_0 = 1.0804e-04
Loss = 3.4285e-04, PNorm = 58.3628, GNorm = 0.7882, lr_0 = 1.0804e-04
Loss = 4.2426e-04, PNorm = 58.3652, GNorm = 3.4910, lr_0 = 1.0804e-04
Loss = 5.4265e-04, PNorm = 58.3669, GNorm = 2.6031, lr_0 = 1.0804e-04
Loss = 8.1422e-04, PNorm = 58.3675, GNorm = 1.5643, lr_0 = 1.0804e-04
Loss = 5.1164e-04, PNorm = 58.3699, GNorm = 2.0622, lr_0 = 1.0804e-04
Validation rmse logD = 0.534158
Validation R2 logD = 0.806489
Epoch 85
Train function
Loss = 5.4121e-04, PNorm = 58.3742, GNorm = 1.9883, lr_0 = 1.0804e-04
Loss = 5.6462e-04, PNorm = 58.3782, GNorm = 1.5838, lr_0 = 1.0804e-04
Loss = 6.9657e-04, PNorm = 58.3814, GNorm = 1.8140, lr_0 = 1.0804e-04
Loss = 9.9888e-04, PNorm = 58.3835, GNorm = 6.9073, lr_0 = 1.0804e-04
Loss = 8.0699e-04, PNorm = 58.3870, GNorm = 6.5087, lr_0 = 1.0804e-04
Loss = 5.5738e-04, PNorm = 58.3929, GNorm = 1.4949, lr_0 = 1.0804e-04
Validation rmse logD = 0.543769
Validation R2 logD = 0.799463
Epoch 86
Train function
Loss = 6.8387e-04, PNorm = 58.3967, GNorm = 1.2641, lr_0 = 1.0804e-04
Loss = 5.1555e-04, PNorm = 58.4002, GNorm = 2.4604, lr_0 = 1.0804e-04
Loss = 3.8599e-04, PNorm = 58.4042, GNorm = 1.2329, lr_0 = 1.0804e-04
Loss = 4.7699e-04, PNorm = 58.4074, GNorm = 2.6840, lr_0 = 1.0804e-04
Loss = 4.7978e-04, PNorm = 58.4100, GNorm = 2.2963, lr_0 = 1.0804e-04
Validation rmse logD = 0.526856
Validation R2 logD = 0.811743
Epoch 87
Train function
Loss = 1.8264e-04, PNorm = 58.4127, GNorm = 0.9372, lr_0 = 1.0804e-04
Loss = 4.2650e-04, PNorm = 58.4157, GNorm = 2.9100, lr_0 = 1.0804e-04
Loss = 3.9648e-04, PNorm = 58.4198, GNorm = 1.6962, lr_0 = 1.0804e-04
Loss = 4.1159e-04, PNorm = 58.4217, GNorm = 1.7711, lr_0 = 1.0804e-04
Loss = 5.7102e-04, PNorm = 58.4234, GNorm = 5.7352, lr_0 = 1.0804e-04
Loss = 7.3822e-04, PNorm = 58.4259, GNorm = 5.4026, lr_0 = 1.0804e-04
Validation rmse logD = 0.527066
Validation R2 logD = 0.811593
Epoch 88
Train function
Loss = 6.7133e-04, PNorm = 58.4293, GNorm = 2.0859, lr_0 = 1.0804e-04
Loss = 6.0976e-04, PNorm = 58.4325, GNorm = 1.5573, lr_0 = 1.0804e-04
Loss = 5.1566e-04, PNorm = 58.4375, GNorm = 1.3691, lr_0 = 1.0804e-04
Loss = 4.8605e-04, PNorm = 58.4406, GNorm = 1.4683, lr_0 = 1.0804e-04
Loss = 5.5517e-04, PNorm = 58.4436, GNorm = 3.0762, lr_0 = 1.0804e-04
Loss = 5.1303e-04, PNorm = 58.4469, GNorm = 5.6951, lr_0 = 1.0804e-04
Validation rmse logD = 0.554679
Validation R2 logD = 0.791334
Epoch 89
Train function
Loss = 6.6655e-04, PNorm = 58.4505, GNorm = 1.4286, lr_0 = 1.0804e-04
Loss = 5.7565e-04, PNorm = 58.4533, GNorm = 3.3820, lr_0 = 1.0804e-04
Loss = 7.1220e-04, PNorm = 58.4570, GNorm = 2.7887, lr_0 = 1.0804e-04
Loss = 6.8626e-04, PNorm = 58.4599, GNorm = 7.1364, lr_0 = 1.0804e-04
Loss = 5.4157e-04, PNorm = 58.4641, GNorm = 2.0745, lr_0 = 1.0804e-04
Validation rmse logD = 0.518513
Validation R2 logD = 0.817658
Epoch 90
Train function
Loss = 4.3149e-04, PNorm = 58.4674, GNorm = 1.4547, lr_0 = 1.0804e-04
Loss = 3.9431e-04, PNorm = 58.4696, GNorm = 1.1028, lr_0 = 1.0804e-04
Loss = 5.4422e-04, PNorm = 58.4715, GNorm = 2.3060, lr_0 = 1.0804e-04
Loss = 4.8218e-04, PNorm = 58.4754, GNorm = 1.7110, lr_0 = 1.0804e-04
Loss = 4.3091e-04, PNorm = 58.4784, GNorm = 1.7086, lr_0 = 1.0804e-04
Loss = 4.8444e-04, PNorm = 58.4818, GNorm = 0.7748, lr_0 = 1.0804e-04
Validation rmse logD = 0.519567
Validation R2 logD = 0.816916
Epoch 91
Train function
Loss = 2.4087e-04, PNorm = 58.4851, GNorm = 0.9524, lr_0 = 1.0804e-04
Loss = 3.8677e-04, PNorm = 58.4876, GNorm = 4.8389, lr_0 = 1.0804e-04
Loss = 4.8195e-04, PNorm = 58.4888, GNorm = 2.3410, lr_0 = 1.0804e-04
Loss = 7.1188e-04, PNorm = 58.4912, GNorm = 2.7688, lr_0 = 1.0804e-04
Loss = 6.0812e-04, PNorm = 58.4952, GNorm = 1.6080, lr_0 = 1.0804e-04
Loss = 4.9713e-04, PNorm = 58.4984, GNorm = 3.3288, lr_0 = 1.0804e-04
Validation rmse logD = 0.529591
Validation R2 logD = 0.809784
Epoch 92
Train function
Loss = 3.2890e-04, PNorm = 58.5011, GNorm = 3.0898, lr_0 = 1.0804e-04
Loss = 4.2967e-04, PNorm = 58.5036, GNorm = 2.2221, lr_0 = 1.0804e-04
Loss = 3.8079e-04, PNorm = 58.5054, GNorm = 2.1283, lr_0 = 1.0804e-04
Loss = 5.3598e-04, PNorm = 58.5078, GNorm = 2.9865, lr_0 = 1.0804e-04
Loss = 3.6267e-04, PNorm = 58.5111, GNorm = 0.5980, lr_0 = 1.0804e-04
Validation rmse logD = 0.527611
Validation R2 logD = 0.811203
Epoch 93
Train function
Loss = 2.3493e-04, PNorm = 58.5128, GNorm = 1.9442, lr_0 = 1.0804e-04
Loss = 3.1091e-04, PNorm = 58.5153, GNorm = 1.1592, lr_0 = 1.0804e-04
Loss = 3.9405e-04, PNorm = 58.5171, GNorm = 0.8420, lr_0 = 1.0804e-04
Loss = 3.4211e-04, PNorm = 58.5193, GNorm = 0.9145, lr_0 = 1.0804e-04
Loss = 3.5586e-04, PNorm = 58.5230, GNorm = 1.9215, lr_0 = 1.0804e-04
Loss = 3.0206e-04, PNorm = 58.5249, GNorm = 0.6029, lr_0 = 1.0804e-04
Validation rmse logD = 0.535660
Validation R2 logD = 0.805398
Epoch 94
Train function
Loss = 3.6935e-04, PNorm = 58.5277, GNorm = 3.2332, lr_0 = 1.0804e-04
Loss = 3.2914e-04, PNorm = 58.5302, GNorm = 0.9935, lr_0 = 1.0804e-04
Loss = 2.8740e-04, PNorm = 58.5327, GNorm = 1.3321, lr_0 = 1.0804e-04
Loss = 3.4555e-04, PNorm = 58.5359, GNorm = 0.9479, lr_0 = 1.0804e-04
Loss = 2.2614e-04, PNorm = 58.5377, GNorm = 0.5060, lr_0 = 1.0804e-04
Loss = 6.3979e-04, PNorm = 58.5395, GNorm = 3.8540, lr_0 = 1.0804e-04
Validation rmse logD = 0.520366
Validation R2 logD = 0.816352
Epoch 95
Train function
Loss = 3.5003e-04, PNorm = 58.5432, GNorm = 1.2990, lr_0 = 1.0804e-04
Loss = 3.9244e-04, PNorm = 58.5453, GNorm = 0.8219, lr_0 = 1.0804e-04
Loss = 4.6303e-04, PNorm = 58.5482, GNorm = 2.3396, lr_0 = 1.0804e-04
Loss = 6.1469e-04, PNorm = 58.5514, GNorm = 4.6165, lr_0 = 1.0804e-04
Loss = 4.4852e-04, PNorm = 58.5552, GNorm = 2.4570, lr_0 = 1.0804e-04
Validation rmse logD = 0.519175
Validation R2 logD = 0.817192
Epoch 96
Train function
Loss = 4.9376e-04, PNorm = 58.5573, GNorm = 2.3926, lr_0 = 1.0804e-04
Loss = 5.1073e-04, PNorm = 58.5590, GNorm = 1.3375, lr_0 = 1.0804e-04
Loss = 3.7136e-04, PNorm = 58.5612, GNorm = 1.3977, lr_0 = 1.0804e-04
Loss = 3.5596e-04, PNorm = 58.5640, GNorm = 1.4656, lr_0 = 1.0804e-04
Loss = 3.9755e-04, PNorm = 58.5659, GNorm = 3.4961, lr_0 = 1.0804e-04
Loss = 3.1427e-04, PNorm = 58.5678, GNorm = 1.2181, lr_0 = 1.0804e-04
Validation rmse logD = 0.527135
Validation R2 logD = 0.811544
Epoch 97
Train function
Loss = 5.0128e-04, PNorm = 58.5717, GNorm = 0.7292, lr_0 = 1.0804e-04
Loss = 3.5254e-04, PNorm = 58.5749, GNorm = 4.5890, lr_0 = 1.0804e-04
Loss = 4.0561e-04, PNorm = 58.5774, GNorm = 0.7040, lr_0 = 1.0804e-04
Loss = 4.0738e-04, PNorm = 58.5797, GNorm = 1.1227, lr_0 = 1.0804e-04
Loss = 3.3575e-04, PNorm = 58.5838, GNorm = 3.4146, lr_0 = 1.0804e-04
Loss = 2.9011e-04, PNorm = 58.5855, GNorm = 1.7135, lr_0 = 1.0804e-04
Validation rmse logD = 0.545383
Validation R2 logD = 0.798270
Epoch 98
Train function
Loss = 2.9592e-04, PNorm = 58.5878, GNorm = 0.8692, lr_0 = 1.0804e-04
Loss = 4.5386e-04, PNorm = 58.5906, GNorm = 1.7379, lr_0 = 1.0804e-04
Loss = 3.9340e-04, PNorm = 58.5942, GNorm = 0.6133, lr_0 = 1.0804e-04
Loss = 3.6999e-04, PNorm = 58.5968, GNorm = 3.2163, lr_0 = 1.0804e-04
Loss = 3.8850e-04, PNorm = 58.5986, GNorm = 0.9002, lr_0 = 1.0804e-04
Validation rmse logD = 0.524375
Validation R2 logD = 0.813512
Epoch 99
Train function
Loss = 2.4216e-04, PNorm = 58.6016, GNorm = 0.6931, lr_0 = 1.0804e-04
Loss = 2.4445e-04, PNorm = 58.6032, GNorm = 3.4948, lr_0 = 1.0804e-04
Loss = 3.2599e-04, PNorm = 58.6042, GNorm = 0.6219, lr_0 = 1.0804e-04
Loss = 5.3825e-04, PNorm = 58.6065, GNorm = 2.7527, lr_0 = 1.0804e-04
Loss = 3.8410e-04, PNorm = 58.6103, GNorm = 2.3514, lr_0 = 1.0804e-04
Loss = 3.9417e-04, PNorm = 58.6134, GNorm = 3.1665, lr_0 = 1.0804e-04
Validation rmse logD = 0.521544
Validation R2 logD = 0.815520
Model 0 best validation rmse = 0.518513 on epoch 89
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.566694
Model 0 test R2 logD = 0.781351
Ensemble test rmse  logD= 0.566694
Ensemble test R2  logD= 0.781351
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.2437e-02, PNorm = 55.5545, GNorm = 6.7669, lr_0 = 1.0804e-04
Loss = 1.8671e-02, PNorm = 55.5570, GNorm = 4.3145, lr_0 = 1.0804e-04
Loss = 1.8287e-02, PNorm = 55.5602, GNorm = 2.6187, lr_0 = 1.0804e-04
Loss = 1.8186e-02, PNorm = 55.5633, GNorm = 2.8329, lr_0 = 1.0804e-04
Loss = 1.6452e-02, PNorm = 55.5670, GNorm = 1.4308, lr_0 = 1.0804e-04
Validation rmse logD = 1.120664
Validation R2 logD = 0.191271
Epoch 1
Train function
Loss = 1.2744e-02, PNorm = 55.5708, GNorm = 3.7954, lr_0 = 1.0804e-04
Loss = 1.5381e-02, PNorm = 55.5749, GNorm = 3.9335, lr_0 = 1.0804e-04
Loss = 1.5845e-02, PNorm = 55.5794, GNorm = 8.5277, lr_0 = 1.0804e-04
Loss = 1.6161e-02, PNorm = 55.5853, GNorm = 2.6622, lr_0 = 1.0804e-04
Loss = 1.6096e-02, PNorm = 55.5916, GNorm = 5.2210, lr_0 = 1.0804e-04
Loss = 1.4684e-02, PNorm = 55.5988, GNorm = 1.7129, lr_0 = 1.0804e-04
Validation rmse logD = 1.071394
Validation R2 logD = 0.260818
Epoch 2
Train function
Loss = 1.5800e-02, PNorm = 55.6075, GNorm = 3.3606, lr_0 = 1.0804e-04
Loss = 1.4757e-02, PNorm = 55.6161, GNorm = 1.6541, lr_0 = 1.0804e-04
Loss = 1.2558e-02, PNorm = 55.6250, GNorm = 1.9665, lr_0 = 1.0804e-04
Loss = 1.4594e-02, PNorm = 55.6341, GNorm = 2.9557, lr_0 = 1.0804e-04
Loss = 1.3009e-02, PNorm = 55.6449, GNorm = 2.9935, lr_0 = 1.0804e-04
Validation rmse logD = 1.011613
Validation R2 logD = 0.341007
Epoch 3
Train function
Loss = 1.3972e-02, PNorm = 55.6569, GNorm = 1.4398, lr_0 = 1.0804e-04
Loss = 1.1929e-02, PNorm = 55.6674, GNorm = 1.0274, lr_0 = 1.0804e-04
Loss = 1.2136e-02, PNorm = 55.6776, GNorm = 6.7913, lr_0 = 1.0804e-04
Loss = 1.2570e-02, PNorm = 55.6893, GNorm = 2.0796, lr_0 = 1.0804e-04
Loss = 1.3361e-02, PNorm = 55.7016, GNorm = 9.1384, lr_0 = 1.0804e-04
Loss = 1.1772e-02, PNorm = 55.7123, GNorm = 2.8162, lr_0 = 1.0804e-04
Validation rmse logD = 0.950083
Validation R2 logD = 0.418734
Epoch 4
Train function
Loss = 9.9968e-03, PNorm = 55.7210, GNorm = 1.7737, lr_0 = 1.0804e-04
Loss = 1.0220e-02, PNorm = 55.7322, GNorm = 6.8374, lr_0 = 1.0804e-04
Loss = 1.0171e-02, PNorm = 55.7459, GNorm = 5.8527, lr_0 = 1.0804e-04
Loss = 1.1218e-02, PNorm = 55.7569, GNorm = 2.8660, lr_0 = 1.0804e-04
Loss = 1.1333e-02, PNorm = 55.7674, GNorm = 3.5843, lr_0 = 1.0804e-04
Loss = 1.0918e-02, PNorm = 55.7801, GNorm = 4.6769, lr_0 = 1.0804e-04
Validation rmse logD = 0.908774
Validation R2 logD = 0.468181
Epoch 5
Train function
Loss = 9.8982e-03, PNorm = 55.7945, GNorm = 4.9341, lr_0 = 1.0804e-04
Loss = 9.9001e-03, PNorm = 55.8057, GNorm = 2.6934, lr_0 = 1.0804e-04
Loss = 1.2344e-02, PNorm = 55.8163, GNorm = 8.0456, lr_0 = 1.0804e-04
Loss = 9.9406e-03, PNorm = 55.8267, GNorm = 2.9305, lr_0 = 1.0804e-04
Loss = 9.5497e-03, PNorm = 55.8381, GNorm = 1.8755, lr_0 = 1.0804e-04
Validation rmse logD = 0.841955
Validation R2 logD = 0.543511
Epoch 6
Train function
Loss = 8.3122e-03, PNorm = 55.8509, GNorm = 2.5543, lr_0 = 1.0804e-04
Loss = 8.5484e-03, PNorm = 55.8637, GNorm = 3.1388, lr_0 = 1.0804e-04
Loss = 9.2963e-03, PNorm = 55.8757, GNorm = 3.1520, lr_0 = 1.0804e-04
Loss = 9.4956e-03, PNorm = 55.8896, GNorm = 2.6161, lr_0 = 1.0804e-04
Loss = 9.4273e-03, PNorm = 55.9004, GNorm = 3.9196, lr_0 = 1.0804e-04
Loss = 9.2568e-03, PNorm = 55.9121, GNorm = 5.6724, lr_0 = 1.0804e-04
Validation rmse logD = 0.811032
Validation R2 logD = 0.576426
Epoch 7
Train function
Loss = 8.7813e-03, PNorm = 55.9231, GNorm = 2.8767, lr_0 = 1.0804e-04
Loss = 8.1096e-03, PNorm = 55.9350, GNorm = 3.6807, lr_0 = 1.0804e-04
Loss = 7.4357e-03, PNorm = 55.9460, GNorm = 2.3844, lr_0 = 1.0804e-04
Loss = 7.8778e-03, PNorm = 55.9574, GNorm = 3.6626, lr_0 = 1.0804e-04
Loss = 7.6552e-03, PNorm = 55.9696, GNorm = 3.4480, lr_0 = 1.0804e-04
Loss = 7.6721e-03, PNorm = 55.9809, GNorm = 5.0252, lr_0 = 1.0804e-04
Validation rmse logD = 0.842474
Validation R2 logD = 0.542948
Epoch 8
Train function
Loss = 7.5962e-03, PNorm = 55.9908, GNorm = 8.1539, lr_0 = 1.0804e-04
Loss = 7.9577e-03, PNorm = 56.0015, GNorm = 4.2731, lr_0 = 1.0804e-04
Loss = 8.0906e-03, PNorm = 56.0137, GNorm = 10.6664, lr_0 = 1.0804e-04
Loss = 7.3744e-03, PNorm = 56.0249, GNorm = 1.9003, lr_0 = 1.0804e-04
Loss = 7.2305e-03, PNorm = 56.0366, GNorm = 3.5399, lr_0 = 1.0804e-04
Validation rmse logD = 0.739803
Validation R2 logD = 0.647561
Epoch 9
Train function
Loss = 7.0661e-03, PNorm = 56.0480, GNorm = 2.0080, lr_0 = 1.0804e-04
Loss = 7.2705e-03, PNorm = 56.0595, GNorm = 1.6227, lr_0 = 1.0804e-04
Loss = 6.4674e-03, PNorm = 56.0698, GNorm = 1.5885, lr_0 = 1.0804e-04
Loss = 7.3848e-03, PNorm = 56.0779, GNorm = 3.4559, lr_0 = 1.0804e-04
Loss = 6.2713e-03, PNorm = 56.0879, GNorm = 2.1012, lr_0 = 1.0804e-04
Loss = 6.9504e-03, PNorm = 56.0987, GNorm = 5.1747, lr_0 = 1.0804e-04
Validation rmse logD = 0.747122
Validation R2 logD = 0.640553
Epoch 10
Train function
Loss = 6.4693e-03, PNorm = 56.1079, GNorm = 2.1704, lr_0 = 1.0804e-04
Loss = 6.4425e-03, PNorm = 56.1177, GNorm = 5.8417, lr_0 = 1.0804e-04
Loss = 6.3611e-03, PNorm = 56.1277, GNorm = 2.9282, lr_0 = 1.0804e-04
Loss = 6.5922e-03, PNorm = 56.1364, GNorm = 4.8122, lr_0 = 1.0804e-04
Loss = 6.4494e-03, PNorm = 56.1476, GNorm = 6.0595, lr_0 = 1.0804e-04
Loss = 6.3900e-03, PNorm = 56.1581, GNorm = 8.2802, lr_0 = 1.0804e-04
Validation rmse logD = 0.734105
Validation R2 logD = 0.652968
Epoch 11
Train function
Loss = 6.6906e-03, PNorm = 56.1653, GNorm = 9.2703, lr_0 = 1.0804e-04
Loss = 5.7222e-03, PNorm = 56.1772, GNorm = 2.3752, lr_0 = 1.0804e-04
Loss = 5.8858e-03, PNorm = 56.1848, GNorm = 1.9083, lr_0 = 1.0804e-04
Loss = 6.0229e-03, PNorm = 56.1946, GNorm = 6.9014, lr_0 = 1.0804e-04
Loss = 5.4353e-03, PNorm = 56.2063, GNorm = 11.6437, lr_0 = 1.0804e-04
Validation rmse logD = 0.693369
Validation R2 logD = 0.690414
Epoch 12
Train function
Loss = 3.6466e-03, PNorm = 56.2145, GNorm = 1.3513, lr_0 = 1.0804e-04
Loss = 5.6348e-03, PNorm = 56.2235, GNorm = 3.0433, lr_0 = 1.0804e-04
Loss = 5.0062e-03, PNorm = 56.2323, GNorm = 1.9983, lr_0 = 1.0804e-04
Loss = 5.3121e-03, PNorm = 56.2409, GNorm = 3.1736, lr_0 = 1.0804e-04
Loss = 5.8598e-03, PNorm = 56.2504, GNorm = 4.0652, lr_0 = 1.0804e-04
Loss = 5.2628e-03, PNorm = 56.2584, GNorm = 2.2362, lr_0 = 1.0804e-04
Validation rmse logD = 0.710665
Validation R2 logD = 0.674776
Epoch 13
Train function
Loss = 5.7369e-03, PNorm = 56.2674, GNorm = 3.9551, lr_0 = 1.0804e-04
Loss = 4.4853e-03, PNorm = 56.2773, GNorm = 4.2037, lr_0 = 1.0804e-04
Loss = 4.4603e-03, PNorm = 56.2874, GNorm = 4.8571, lr_0 = 1.0804e-04
Loss = 6.3864e-03, PNorm = 56.2944, GNorm = 8.0297, lr_0 = 1.0804e-04
Loss = 5.4507e-03, PNorm = 56.3022, GNorm = 6.2183, lr_0 = 1.0804e-04
Loss = 5.8797e-03, PNorm = 56.3115, GNorm = 2.1329, lr_0 = 1.0804e-04
Validation rmse logD = 0.689365
Validation R2 logD = 0.693979
Epoch 14
Train function
Loss = 3.9351e-03, PNorm = 56.3213, GNorm = 2.2989, lr_0 = 1.0804e-04
Loss = 4.6276e-03, PNorm = 56.3285, GNorm = 2.0709, lr_0 = 1.0804e-04
Loss = 4.6843e-03, PNorm = 56.3361, GNorm = 2.4212, lr_0 = 1.0804e-04
Loss = 4.7035e-03, PNorm = 56.3450, GNorm = 3.8445, lr_0 = 1.0804e-04
Loss = 4.1954e-03, PNorm = 56.3539, GNorm = 6.6945, lr_0 = 1.0804e-04
Validation rmse logD = 0.668500
Validation R2 logD = 0.712224
Epoch 15
Train function
Loss = 3.0903e-03, PNorm = 56.3617, GNorm = 2.4380, lr_0 = 1.0804e-04
Loss = 4.1514e-03, PNorm = 56.3689, GNorm = 1.9285, lr_0 = 1.0804e-04
Loss = 4.8766e-03, PNorm = 56.3764, GNorm = 3.7571, lr_0 = 1.0804e-04
Loss = 4.6026e-03, PNorm = 56.3841, GNorm = 9.0404, lr_0 = 1.0804e-04
Loss = 5.9335e-03, PNorm = 56.3925, GNorm = 8.8229, lr_0 = 1.0804e-04
Loss = 5.6551e-03, PNorm = 56.4007, GNorm = 4.1637, lr_0 = 1.0804e-04
Validation rmse logD = 0.689742
Validation R2 logD = 0.693645
Epoch 16
Train function
Loss = 3.6255e-03, PNorm = 56.4093, GNorm = 2.4154, lr_0 = 1.0804e-04
Loss = 4.1282e-03, PNorm = 56.4187, GNorm = 3.5682, lr_0 = 1.0804e-04
Loss = 4.6874e-03, PNorm = 56.4261, GNorm = 12.1924, lr_0 = 1.0804e-04
Loss = 4.7738e-03, PNorm = 56.4325, GNorm = 9.0960, lr_0 = 1.0804e-04
Loss = 4.7675e-03, PNorm = 56.4399, GNorm = 2.7070, lr_0 = 1.0804e-04
Loss = 4.4088e-03, PNorm = 56.4472, GNorm = 5.3006, lr_0 = 1.0804e-04
Validation rmse logD = 0.708536
Validation R2 logD = 0.676722
Epoch 17
Train function
Loss = 4.6755e-03, PNorm = 56.4551, GNorm = 12.2886, lr_0 = 1.0804e-04
Loss = 4.6267e-03, PNorm = 56.4619, GNorm = 6.9215, lr_0 = 1.0804e-04
Loss = 4.3231e-03, PNorm = 56.4723, GNorm = 3.5339, lr_0 = 1.0804e-04
Loss = 5.4446e-03, PNorm = 56.4795, GNorm = 1.9801, lr_0 = 1.0804e-04
Loss = 4.1156e-03, PNorm = 56.4872, GNorm = 3.4909, lr_0 = 1.0804e-04
Validation rmse logD = 0.659020
Validation R2 logD = 0.720328
Epoch 18
Train function
Loss = 3.0394e-03, PNorm = 56.4955, GNorm = 1.8818, lr_0 = 1.0804e-04
Loss = 4.4329e-03, PNorm = 56.5034, GNorm = 6.4856, lr_0 = 1.0804e-04
Loss = 3.6586e-03, PNorm = 56.5105, GNorm = 4.9161, lr_0 = 1.0804e-04
Loss = 3.8333e-03, PNorm = 56.5175, GNorm = 2.9000, lr_0 = 1.0804e-04
Loss = 4.2812e-03, PNorm = 56.5253, GNorm = 5.2967, lr_0 = 1.0804e-04
Loss = 3.8237e-03, PNorm = 56.5341, GNorm = 2.0568, lr_0 = 1.0804e-04
Validation rmse logD = 0.658754
Validation R2 logD = 0.720553
Epoch 19
Train function
Loss = 3.7554e-03, PNorm = 56.5401, GNorm = 2.1387, lr_0 = 1.0804e-04
Loss = 3.8124e-03, PNorm = 56.5455, GNorm = 7.8605, lr_0 = 1.0804e-04
Loss = 3.8728e-03, PNorm = 56.5513, GNorm = 2.8722, lr_0 = 1.0804e-04
Loss = 3.8292e-03, PNorm = 56.5605, GNorm = 3.3785, lr_0 = 1.0804e-04
Loss = 3.3653e-03, PNorm = 56.5685, GNorm = 4.6104, lr_0 = 1.0804e-04
Loss = 4.0105e-03, PNorm = 56.5742, GNorm = 1.9796, lr_0 = 1.0804e-04
Validation rmse logD = 0.643711
Validation R2 logD = 0.733170
Epoch 20
Train function
Loss = 3.7800e-03, PNorm = 56.5811, GNorm = 2.1914, lr_0 = 1.0804e-04
Loss = 3.6555e-03, PNorm = 56.5869, GNorm = 9.9972, lr_0 = 1.0804e-04
Loss = 3.3287e-03, PNorm = 56.5940, GNorm = 4.9880, lr_0 = 1.0804e-04
Loss = 3.3982e-03, PNorm = 56.6010, GNorm = 4.3837, lr_0 = 1.0804e-04
Loss = 3.4591e-03, PNorm = 56.6071, GNorm = 2.7213, lr_0 = 1.0804e-04
Validation rmse logD = 0.657756
Validation R2 logD = 0.721400
Epoch 21
Train function
Loss = 3.7444e-03, PNorm = 56.6166, GNorm = 7.0085, lr_0 = 1.0804e-04
Loss = 3.0375e-03, PNorm = 56.6220, GNorm = 3.3914, lr_0 = 1.0804e-04
Loss = 3.3351e-03, PNorm = 56.6273, GNorm = 4.0370, lr_0 = 1.0804e-04
Loss = 3.5379e-03, PNorm = 56.6340, GNorm = 2.3391, lr_0 = 1.0804e-04
Loss = 3.5527e-03, PNorm = 56.6403, GNorm = 3.0964, lr_0 = 1.0804e-04
Loss = 3.5371e-03, PNorm = 56.6470, GNorm = 6.4577, lr_0 = 1.0804e-04
Validation rmse logD = 0.703547
Validation R2 logD = 0.681259
Epoch 22
Train function
Loss = 3.5318e-03, PNorm = 56.6549, GNorm = 9.0619, lr_0 = 1.0804e-04
Loss = 3.1688e-03, PNorm = 56.6622, GNorm = 8.3855, lr_0 = 1.0804e-04
Loss = 4.5573e-03, PNorm = 56.6688, GNorm = 7.0059, lr_0 = 1.0804e-04
Loss = 3.7693e-03, PNorm = 56.6766, GNorm = 7.6370, lr_0 = 1.0804e-04
Loss = 3.3919e-03, PNorm = 56.6838, GNorm = 2.3532, lr_0 = 1.0804e-04
Loss = 4.1040e-03, PNorm = 56.6909, GNorm = 3.2701, lr_0 = 1.0804e-04
Validation rmse logD = 0.633067
Validation R2 logD = 0.741922
Epoch 23
Train function
Loss = 3.1503e-03, PNorm = 56.6965, GNorm = 4.9526, lr_0 = 1.0804e-04
Loss = 2.7537e-03, PNorm = 56.7037, GNorm = 2.0099, lr_0 = 1.0804e-04
Loss = 3.3643e-03, PNorm = 56.7108, GNorm = 4.2993, lr_0 = 1.0804e-04
Loss = 3.0798e-03, PNorm = 56.7181, GNorm = 3.7863, lr_0 = 1.0804e-04
Loss = 3.1804e-03, PNorm = 56.7234, GNorm = 1.6365, lr_0 = 1.0804e-04
Validation rmse logD = 0.629329
Validation R2 logD = 0.744960
Epoch 24
Train function
Loss = 2.5428e-03, PNorm = 56.7307, GNorm = 1.8659, lr_0 = 1.0804e-04
Loss = 3.1604e-03, PNorm = 56.7388, GNorm = 1.6141, lr_0 = 1.0804e-04
Loss = 2.8089e-03, PNorm = 56.7450, GNorm = 1.4496, lr_0 = 1.0804e-04
Loss = 3.1801e-03, PNorm = 56.7513, GNorm = 5.0328, lr_0 = 1.0804e-04
Loss = 3.0750e-03, PNorm = 56.7570, GNorm = 4.3359, lr_0 = 1.0804e-04
Loss = 2.7234e-03, PNorm = 56.7638, GNorm = 3.4596, lr_0 = 1.0804e-04
Validation rmse logD = 0.642502
Validation R2 logD = 0.734172
Epoch 25
Train function
Loss = 2.7535e-03, PNorm = 56.7696, GNorm = 5.1341, lr_0 = 1.0804e-04
Loss = 3.0299e-03, PNorm = 56.7762, GNorm = 2.1794, lr_0 = 1.0804e-04
Loss = 3.0891e-03, PNorm = 56.7830, GNorm = 4.7289, lr_0 = 1.0804e-04
Loss = 2.9946e-03, PNorm = 56.7898, GNorm = 4.2222, lr_0 = 1.0804e-04
Loss = 2.7016e-03, PNorm = 56.7956, GNorm = 3.8044, lr_0 = 1.0804e-04
Loss = 2.7277e-03, PNorm = 56.8013, GNorm = 4.8149, lr_0 = 1.0804e-04
Validation rmse logD = 0.601777
Validation R2 logD = 0.766802
Epoch 26
Train function
Loss = 2.0378e-03, PNorm = 56.8063, GNorm = 1.7123, lr_0 = 1.0804e-04
Loss = 2.2762e-03, PNorm = 56.8109, GNorm = 5.4540, lr_0 = 1.0804e-04
Loss = 2.6637e-03, PNorm = 56.8164, GNorm = 6.6512, lr_0 = 1.0804e-04
Loss = 2.5557e-03, PNorm = 56.8224, GNorm = 3.5496, lr_0 = 1.0804e-04
Loss = 3.3653e-03, PNorm = 56.8300, GNorm = 4.4605, lr_0 = 1.0804e-04
Validation rmse logD = 0.622979
Validation R2 logD = 0.750081
Epoch 27
Train function
Loss = 1.9804e-03, PNorm = 56.8385, GNorm = 3.4910, lr_0 = 1.0804e-04
Loss = 2.6400e-03, PNorm = 56.8453, GNorm = 5.7468, lr_0 = 1.0804e-04
Loss = 2.3490e-03, PNorm = 56.8499, GNorm = 2.8935, lr_0 = 1.0804e-04
Loss = 2.2983e-03, PNorm = 56.8562, GNorm = 8.2914, lr_0 = 1.0804e-04
Loss = 3.1686e-03, PNorm = 56.8642, GNorm = 2.1832, lr_0 = 1.0804e-04
Loss = 2.5019e-03, PNorm = 56.8707, GNorm = 1.2448, lr_0 = 1.0804e-04
Validation rmse logD = 0.626470
Validation R2 logD = 0.747272
Epoch 28
Train function
Loss = 2.5546e-03, PNorm = 56.8774, GNorm = 6.6770, lr_0 = 1.0804e-04
Loss = 3.0630e-03, PNorm = 56.8838, GNorm = 5.7988, lr_0 = 1.0804e-04
Loss = 2.0697e-03, PNorm = 56.8904, GNorm = 1.3230, lr_0 = 1.0804e-04
Loss = 2.3969e-03, PNorm = 56.8967, GNorm = 6.4529, lr_0 = 1.0804e-04
Loss = 2.4662e-03, PNorm = 56.9024, GNorm = 1.4446, lr_0 = 1.0804e-04
Loss = 2.6827e-03, PNorm = 56.9072, GNorm = 5.1237, lr_0 = 1.0804e-04
Validation rmse logD = 0.592290
Validation R2 logD = 0.774098
Epoch 29
Train function
Loss = 2.4881e-03, PNorm = 56.9125, GNorm = 2.2106, lr_0 = 1.0804e-04
Loss = 2.2050e-03, PNorm = 56.9178, GNorm = 2.7631, lr_0 = 1.0804e-04
Loss = 2.3044e-03, PNorm = 56.9244, GNorm = 2.6350, lr_0 = 1.0804e-04
Loss = 2.6305e-03, PNorm = 56.9297, GNorm = 6.8778, lr_0 = 1.0804e-04
Loss = 2.6130e-03, PNorm = 56.9348, GNorm = 3.4551, lr_0 = 1.0804e-04
Validation rmse logD = 0.612826
Validation R2 logD = 0.758161
Epoch 30
Train function
Loss = 2.1053e-03, PNorm = 56.9420, GNorm = 2.0061, lr_0 = 1.0804e-04
Loss = 2.1505e-03, PNorm = 56.9488, GNorm = 7.3369, lr_0 = 1.0804e-04
Loss = 2.4998e-03, PNorm = 56.9548, GNorm = 3.6498, lr_0 = 1.0804e-04
Loss = 2.1826e-03, PNorm = 56.9617, GNorm = 3.8723, lr_0 = 1.0804e-04
Loss = 1.9464e-03, PNorm = 56.9673, GNorm = 5.2280, lr_0 = 1.0804e-04
Loss = 2.6244e-03, PNorm = 56.9712, GNorm = 2.1632, lr_0 = 1.0804e-04
Validation rmse logD = 0.606280
Validation R2 logD = 0.763299
Epoch 31
Train function
Loss = 2.5382e-03, PNorm = 56.9762, GNorm = 3.3940, lr_0 = 1.0804e-04
Loss = 1.6465e-03, PNorm = 56.9819, GNorm = 1.5428, lr_0 = 1.0804e-04
Loss = 1.9073e-03, PNorm = 56.9874, GNorm = 4.9083, lr_0 = 1.0804e-04
Loss = 2.6082e-03, PNorm = 56.9931, GNorm = 6.8399, lr_0 = 1.0804e-04
Loss = 2.0363e-03, PNorm = 57.0001, GNorm = 3.5719, lr_0 = 1.0804e-04
Loss = 1.9892e-03, PNorm = 57.0055, GNorm = 2.8952, lr_0 = 1.0804e-04
Validation rmse logD = 0.618040
Validation R2 logD = 0.754028
Epoch 32
Train function
Loss = 1.7936e-03, PNorm = 57.0110, GNorm = 1.8824, lr_0 = 1.0804e-04
Loss = 1.6966e-03, PNorm = 57.0161, GNorm = 3.3864, lr_0 = 1.0804e-04
Loss = 1.8781e-03, PNorm = 57.0214, GNorm = 2.4999, lr_0 = 1.0804e-04
Loss = 2.5107e-03, PNorm = 57.0270, GNorm = 11.8774, lr_0 = 1.0804e-04
Loss = 2.5682e-03, PNorm = 57.0328, GNorm = 5.4173, lr_0 = 1.0804e-04
Validation rmse logD = 0.613794
Validation R2 logD = 0.757396
Epoch 33
Train function
Loss = 2.1728e-03, PNorm = 57.0398, GNorm = 4.7103, lr_0 = 1.0804e-04
Loss = 1.8775e-03, PNorm = 57.0473, GNorm = 3.2055, lr_0 = 1.0804e-04
Loss = 1.9500e-03, PNorm = 57.0547, GNorm = 7.1798, lr_0 = 1.0804e-04
Loss = 1.8043e-03, PNorm = 57.0597, GNorm = 4.4341, lr_0 = 1.0804e-04
Loss = 2.0992e-03, PNorm = 57.0637, GNorm = 5.9488, lr_0 = 1.0804e-04
Loss = 2.1348e-03, PNorm = 57.0688, GNorm = 4.2488, lr_0 = 1.0804e-04
Validation rmse logD = 0.590189
Validation R2 logD = 0.775697
Epoch 34
Train function
Loss = 1.6372e-03, PNorm = 57.0738, GNorm = 1.6638, lr_0 = 1.0804e-04
Loss = 1.8387e-03, PNorm = 57.0797, GNorm = 4.5254, lr_0 = 1.0804e-04
Loss = 1.8816e-03, PNorm = 57.0851, GNorm = 2.8340, lr_0 = 1.0804e-04
Loss = 2.2580e-03, PNorm = 57.0903, GNorm = 1.6121, lr_0 = 1.0804e-04
Loss = 1.8291e-03, PNorm = 57.0955, GNorm = 2.3730, lr_0 = 1.0804e-04
Loss = 1.5270e-03, PNorm = 57.1018, GNorm = 2.5620, lr_0 = 1.0804e-04
Validation rmse logD = 0.591853
Validation R2 logD = 0.774431
Epoch 35
Train function
Loss = 1.7900e-03, PNorm = 57.1081, GNorm = 4.8408, lr_0 = 1.0804e-04
Loss = 1.7321e-03, PNorm = 57.1127, GNorm = 4.6449, lr_0 = 1.0804e-04
Loss = 1.5412e-03, PNorm = 57.1188, GNorm = 5.8237, lr_0 = 1.0804e-04
Loss = 2.0049e-03, PNorm = 57.1230, GNorm = 2.2116, lr_0 = 1.0804e-04
Loss = 1.8506e-03, PNorm = 57.1280, GNorm = 4.1932, lr_0 = 1.0804e-04
Validation rmse logD = 0.594316
Validation R2 logD = 0.772549
Epoch 36
Train function
Loss = 1.9640e-03, PNorm = 57.1320, GNorm = 4.3876, lr_0 = 1.0804e-04
Loss = 2.2770e-03, PNorm = 57.1359, GNorm = 2.8787, lr_0 = 1.0804e-04
Loss = 2.6327e-03, PNorm = 57.1395, GNorm = 6.0400, lr_0 = 1.0804e-04
Loss = 2.2736e-03, PNorm = 57.1457, GNorm = 3.0039, lr_0 = 1.0804e-04
Loss = 1.7070e-03, PNorm = 57.1539, GNorm = 2.1122, lr_0 = 1.0804e-04
Loss = 1.7516e-03, PNorm = 57.1597, GNorm = 7.6032, lr_0 = 1.0804e-04
Validation rmse logD = 0.602166
Validation R2 logD = 0.766501
Epoch 37
Train function
Loss = 1.4533e-03, PNorm = 57.1649, GNorm = 4.0157, lr_0 = 1.0804e-04
Loss = 1.5585e-03, PNorm = 57.1701, GNorm = 2.5749, lr_0 = 1.0804e-04
Loss = 1.5155e-03, PNorm = 57.1755, GNorm = 4.8434, lr_0 = 1.0804e-04
Loss = 1.8554e-03, PNorm = 57.1802, GNorm = 9.0570, lr_0 = 1.0804e-04
Loss = 2.1873e-03, PNorm = 57.1843, GNorm = 12.0511, lr_0 = 1.0804e-04
Loss = 2.1058e-03, PNorm = 57.1916, GNorm = 3.6468, lr_0 = 1.0804e-04
Validation rmse logD = 0.575778
Validation R2 logD = 0.786517
Epoch 38
Train function
Loss = 1.5645e-03, PNorm = 57.1993, GNorm = 4.1254, lr_0 = 1.0804e-04
Loss = 1.2580e-03, PNorm = 57.2060, GNorm = 2.7231, lr_0 = 1.0804e-04
Loss = 2.0771e-03, PNorm = 57.2107, GNorm = 8.0358, lr_0 = 1.0804e-04
Loss = 1.8827e-03, PNorm = 57.2144, GNorm = 2.9918, lr_0 = 1.0804e-04
Loss = 1.9164e-03, PNorm = 57.2196, GNorm = 4.3006, lr_0 = 1.0804e-04
Validation rmse logD = 0.649843
Validation R2 logD = 0.728062
Epoch 39
Train function
Loss = 2.1016e-03, PNorm = 57.2238, GNorm = 8.0013, lr_0 = 1.0804e-04
Loss = 1.8904e-03, PNorm = 57.2286, GNorm = 1.7959, lr_0 = 1.0804e-04
Loss = 2.2447e-03, PNorm = 57.2336, GNorm = 1.9037, lr_0 = 1.0804e-04
Loss = 1.5392e-03, PNorm = 57.2398, GNorm = 4.2827, lr_0 = 1.0804e-04
Loss = 1.9061e-03, PNorm = 57.2451, GNorm = 4.7607, lr_0 = 1.0804e-04
Loss = 1.3357e-03, PNorm = 57.2494, GNorm = 2.4530, lr_0 = 1.0804e-04
Validation rmse logD = 0.599213
Validation R2 logD = 0.768786
Epoch 40
Train function
Loss = 2.1443e-03, PNorm = 57.2547, GNorm = 4.9666, lr_0 = 1.0804e-04
Loss = 1.5789e-03, PNorm = 57.2588, GNorm = 6.5635, lr_0 = 1.0804e-04
Loss = 1.9390e-03, PNorm = 57.2627, GNorm = 5.0118, lr_0 = 1.0804e-04
Loss = 1.9485e-03, PNorm = 57.2667, GNorm = 4.0263, lr_0 = 1.0804e-04
Loss = 1.6837e-03, PNorm = 57.2753, GNorm = 1.7094, lr_0 = 1.0804e-04
Loss = 1.4731e-03, PNorm = 57.2813, GNorm = 3.3698, lr_0 = 1.0804e-04
Validation rmse logD = 0.575471
Validation R2 logD = 0.786745
Epoch 41
Train function
Loss = 1.8276e-03, PNorm = 57.2877, GNorm = 7.5798, lr_0 = 1.0804e-04
Loss = 1.7740e-03, PNorm = 57.2901, GNorm = 1.2875, lr_0 = 1.0804e-04
Loss = 2.0131e-03, PNorm = 57.2931, GNorm = 10.6106, lr_0 = 1.0804e-04
Loss = 1.7684e-03, PNorm = 57.2976, GNorm = 6.8094, lr_0 = 1.0804e-04
Loss = 1.6389e-03, PNorm = 57.3037, GNorm = 1.9988, lr_0 = 1.0804e-04
Validation rmse logD = 0.578825
Validation R2 logD = 0.784252
Epoch 42
Train function
Loss = 1.4522e-03, PNorm = 57.3102, GNorm = 4.2429, lr_0 = 1.0804e-04
Loss = 1.1811e-03, PNorm = 57.3152, GNorm = 2.2045, lr_0 = 1.0804e-04
Loss = 1.4737e-03, PNorm = 57.3205, GNorm = 1.3251, lr_0 = 1.0804e-04
Loss = 1.3147e-03, PNorm = 57.3250, GNorm = 1.3227, lr_0 = 1.0804e-04
Loss = 1.6849e-03, PNorm = 57.3288, GNorm = 5.2699, lr_0 = 1.0804e-04
Loss = 1.8985e-03, PNorm = 57.3340, GNorm = 2.2812, lr_0 = 1.0804e-04
Validation rmse logD = 0.626078
Validation R2 logD = 0.747589
Epoch 43
Train function
Loss = 1.3836e-03, PNorm = 57.3372, GNorm = 5.2886, lr_0 = 1.0804e-04
Loss = 1.2795e-03, PNorm = 57.3430, GNorm = 2.3855, lr_0 = 1.0804e-04
Loss = 1.3552e-03, PNorm = 57.3472, GNorm = 2.3152, lr_0 = 1.0804e-04
Loss = 1.1735e-03, PNorm = 57.3514, GNorm = 1.7419, lr_0 = 1.0804e-04
Loss = 1.2335e-03, PNorm = 57.3561, GNorm = 4.8501, lr_0 = 1.0804e-04
Loss = 1.6650e-03, PNorm = 57.3611, GNorm = 3.1700, lr_0 = 1.0804e-04
Validation rmse logD = 0.575233
Validation R2 logD = 0.786922
Epoch 44
Train function
Loss = 1.1301e-03, PNorm = 57.3644, GNorm = 2.7936, lr_0 = 1.0804e-04
Loss = 1.4268e-03, PNorm = 57.3683, GNorm = 2.9615, lr_0 = 1.0804e-04
Loss = 1.2060e-03, PNorm = 57.3734, GNorm = 1.5729, lr_0 = 1.0804e-04
Loss = 1.1444e-03, PNorm = 57.3782, GNorm = 1.4157, lr_0 = 1.0804e-04
Loss = 1.3151e-03, PNorm = 57.3822, GNorm = 1.8843, lr_0 = 1.0804e-04
Validation rmse logD = 0.582810
Validation R2 logD = 0.781271
Epoch 45
Train function
Loss = 1.0114e-03, PNorm = 57.3863, GNorm = 3.6039, lr_0 = 1.0804e-04
Loss = 1.2244e-03, PNorm = 57.3895, GNorm = 4.6288, lr_0 = 1.0804e-04
Loss = 1.0932e-03, PNorm = 57.3930, GNorm = 3.3793, lr_0 = 1.0804e-04
Loss = 1.3441e-03, PNorm = 57.3974, GNorm = 2.3848, lr_0 = 1.0804e-04
Loss = 1.0982e-03, PNorm = 57.4021, GNorm = 2.8793, lr_0 = 1.0804e-04
Loss = 1.2314e-03, PNorm = 57.4062, GNorm = 3.6319, lr_0 = 1.0804e-04
Validation rmse logD = 0.614909
Validation R2 logD = 0.756514
Epoch 46
Train function
Loss = 1.2747e-03, PNorm = 57.4106, GNorm = 2.9972, lr_0 = 1.0804e-04
Loss = 1.1961e-03, PNorm = 57.4153, GNorm = 3.1854, lr_0 = 1.0804e-04
Loss = 1.0259e-03, PNorm = 57.4189, GNorm = 2.0621, lr_0 = 1.0804e-04
Loss = 9.4733e-04, PNorm = 57.4215, GNorm = 1.4921, lr_0 = 1.0804e-04
Loss = 1.0581e-03, PNorm = 57.4256, GNorm = 1.6177, lr_0 = 1.0804e-04
Loss = 1.4036e-03, PNorm = 57.4319, GNorm = 2.1090, lr_0 = 1.0804e-04
Validation rmse logD = 0.576568
Validation R2 logD = 0.785931
Epoch 47
Train function
Loss = 1.1009e-03, PNorm = 57.4364, GNorm = 1.7846, lr_0 = 1.0804e-04
Loss = 1.0135e-03, PNorm = 57.4404, GNorm = 3.2200, lr_0 = 1.0804e-04
Loss = 1.4982e-03, PNorm = 57.4450, GNorm = 2.5628, lr_0 = 1.0804e-04
Loss = 1.0617e-03, PNorm = 57.4487, GNorm = 1.9536, lr_0 = 1.0804e-04
Loss = 1.1023e-03, PNorm = 57.4524, GNorm = 2.5569, lr_0 = 1.0804e-04
Validation rmse logD = 0.624876
Validation R2 logD = 0.748557
Epoch 48
Train function
Loss = 2.6625e-03, PNorm = 57.4566, GNorm = 9.8988, lr_0 = 1.0804e-04
Loss = 1.9559e-03, PNorm = 57.4609, GNorm = 5.6901, lr_0 = 1.0804e-04
Loss = 1.9384e-03, PNorm = 57.4664, GNorm = 6.7673, lr_0 = 1.0804e-04
Loss = 1.5425e-03, PNorm = 57.4714, GNorm = 2.3260, lr_0 = 1.0804e-04
Loss = 1.2462e-03, PNorm = 57.4764, GNorm = 2.8534, lr_0 = 1.0804e-04
Loss = 1.1526e-03, PNorm = 57.4810, GNorm = 1.4536, lr_0 = 1.0804e-04
Validation rmse logD = 0.575022
Validation R2 logD = 0.787078
Epoch 49
Train function
Loss = 1.2037e-03, PNorm = 57.4871, GNorm = 5.1959, lr_0 = 1.0804e-04
Loss = 9.2402e-04, PNorm = 57.4907, GNorm = 7.1348, lr_0 = 1.0804e-04
Loss = 1.0684e-03, PNorm = 57.4944, GNorm = 7.3938, lr_0 = 1.0804e-04
Loss = 1.2130e-03, PNorm = 57.4988, GNorm = 3.7305, lr_0 = 1.0804e-04
Loss = 1.6516e-03, PNorm = 57.5032, GNorm = 10.6039, lr_0 = 1.0804e-04
Loss = 1.7413e-03, PNorm = 57.5072, GNorm = 2.4856, lr_0 = 1.0804e-04
Validation rmse logD = 0.578163
Validation R2 logD = 0.784745
Epoch 50
Train function
Loss = 1.1283e-03, PNorm = 57.5125, GNorm = 4.6494, lr_0 = 1.0804e-04
Loss = 1.2847e-03, PNorm = 57.5170, GNorm = 4.1134, lr_0 = 1.0804e-04
Loss = 1.1650e-03, PNorm = 57.5204, GNorm = 4.1993, lr_0 = 1.0804e-04
Loss = 1.1931e-03, PNorm = 57.5248, GNorm = 1.2807, lr_0 = 1.0804e-04
Loss = 1.1996e-03, PNorm = 57.5292, GNorm = 1.3411, lr_0 = 1.0804e-04
Validation rmse logD = 0.569608
Validation R2 logD = 0.791068
Epoch 51
Train function
Loss = 1.4439e-03, PNorm = 57.5338, GNorm = 4.1638, lr_0 = 1.0804e-04
Loss = 1.4013e-03, PNorm = 57.5390, GNorm = 1.4938, lr_0 = 1.0804e-04
Loss = 8.4265e-04, PNorm = 57.5430, GNorm = 2.7679, lr_0 = 1.0804e-04
Loss = 9.5847e-04, PNorm = 57.5475, GNorm = 2.1359, lr_0 = 1.0804e-04
Loss = 9.6919e-04, PNorm = 57.5516, GNorm = 1.8829, lr_0 = 1.0804e-04
Loss = 9.3727e-04, PNorm = 57.5543, GNorm = 1.4712, lr_0 = 1.0804e-04
Validation rmse logD = 0.608024
Validation R2 logD = 0.761936
Epoch 52
Train function
Loss = 1.0583e-03, PNorm = 57.5584, GNorm = 3.1382, lr_0 = 1.0804e-04
Loss = 9.4563e-04, PNorm = 57.5616, GNorm = 2.6427, lr_0 = 1.0804e-04
Loss = 8.2247e-04, PNorm = 57.5646, GNorm = 1.4420, lr_0 = 1.0804e-04
Loss = 1.0684e-03, PNorm = 57.5682, GNorm = 2.5002, lr_0 = 1.0804e-04
Loss = 1.0241e-03, PNorm = 57.5723, GNorm = 1.8111, lr_0 = 1.0804e-04
Loss = 1.3777e-03, PNorm = 57.5762, GNorm = 1.7698, lr_0 = 1.0804e-04
Validation rmse logD = 0.617176
Validation R2 logD = 0.754715
Epoch 53
Train function
Loss = 1.1342e-03, PNorm = 57.5809, GNorm = 4.9346, lr_0 = 1.0804e-04
Loss = 1.2532e-03, PNorm = 57.5857, GNorm = 3.8738, lr_0 = 1.0804e-04
Loss = 1.0246e-03, PNorm = 57.5896, GNorm = 1.7570, lr_0 = 1.0804e-04
Loss = 7.1913e-04, PNorm = 57.5938, GNorm = 2.3890, lr_0 = 1.0804e-04
Loss = 1.0593e-03, PNorm = 57.5980, GNorm = 3.0726, lr_0 = 1.0804e-04
Validation rmse logD = 0.560618
Validation R2 logD = 0.797611
Epoch 54
Train function
Loss = 6.3690e-04, PNorm = 57.6018, GNorm = 1.1653, lr_0 = 1.0804e-04
Loss = 7.6125e-04, PNorm = 57.6053, GNorm = 2.8268, lr_0 = 1.0804e-04
Loss = 9.5254e-04, PNorm = 57.6093, GNorm = 5.9387, lr_0 = 1.0804e-04
Loss = 1.1585e-03, PNorm = 57.6123, GNorm = 6.0137, lr_0 = 1.0804e-04
Loss = 9.6320e-04, PNorm = 57.6164, GNorm = 3.4823, lr_0 = 1.0804e-04
Loss = 8.7699e-04, PNorm = 57.6199, GNorm = 1.7738, lr_0 = 1.0804e-04
Validation rmse logD = 0.580721
Validation R2 logD = 0.782836
Epoch 55
Train function
Loss = 1.4102e-03, PNorm = 57.6240, GNorm = 6.5641, lr_0 = 1.0804e-04
Loss = 1.4979e-03, PNorm = 57.6282, GNorm = 2.0883, lr_0 = 1.0804e-04
Loss = 1.0753e-03, PNorm = 57.6328, GNorm = 7.3615, lr_0 = 1.0804e-04
Loss = 1.2464e-03, PNorm = 57.6368, GNorm = 11.0249, lr_0 = 1.0804e-04
Loss = 1.1746e-03, PNorm = 57.6417, GNorm = 3.3071, lr_0 = 1.0804e-04
Loss = 1.2015e-03, PNorm = 57.6460, GNorm = 2.7843, lr_0 = 1.0804e-04
Validation rmse logD = 0.592689
Validation R2 logD = 0.773793
Epoch 56
Train function
Loss = 7.8301e-04, PNorm = 57.6506, GNorm = 1.1550, lr_0 = 1.0804e-04
Loss = 7.8294e-04, PNorm = 57.6553, GNorm = 2.2718, lr_0 = 1.0804e-04
Loss = 9.4288e-04, PNorm = 57.6611, GNorm = 4.8288, lr_0 = 1.0804e-04
Loss = 1.1298e-03, PNorm = 57.6645, GNorm = 4.9916, lr_0 = 1.0804e-04
Loss = 9.9135e-04, PNorm = 57.6670, GNorm = 1.2603, lr_0 = 1.0804e-04
Validation rmse logD = 0.563948
Validation R2 logD = 0.795199
Epoch 57
Train function
Loss = 5.8027e-04, PNorm = 57.6711, GNorm = 2.1281, lr_0 = 1.0804e-04
Loss = 8.3864e-04, PNorm = 57.6738, GNorm = 1.7009, lr_0 = 1.0804e-04
Loss = 1.3078e-03, PNorm = 57.6773, GNorm = 6.2194, lr_0 = 1.0804e-04
Loss = 9.0353e-04, PNorm = 57.6800, GNorm = 5.4370, lr_0 = 1.0804e-04
Loss = 1.1105e-03, PNorm = 57.6853, GNorm = 3.9013, lr_0 = 1.0804e-04
Loss = 7.0760e-04, PNorm = 57.6906, GNorm = 2.9149, lr_0 = 1.0804e-04
Validation rmse logD = 0.566204
Validation R2 logD = 0.793558
Epoch 58
Train function
Loss = 6.2174e-04, PNorm = 57.6946, GNorm = 1.4924, lr_0 = 1.0804e-04
Loss = 6.2531e-04, PNorm = 57.6976, GNorm = 1.5657, lr_0 = 1.0804e-04
Loss = 8.6443e-04, PNorm = 57.6997, GNorm = 3.4993, lr_0 = 1.0804e-04
Loss = 1.0366e-03, PNorm = 57.7039, GNorm = 6.4058, lr_0 = 1.0804e-04
Loss = 8.7202e-04, PNorm = 57.7070, GNorm = 5.1224, lr_0 = 1.0804e-04
Loss = 7.7609e-04, PNorm = 57.7107, GNorm = 1.5033, lr_0 = 1.0804e-04
Validation rmse logD = 0.592486
Validation R2 logD = 0.773948
Epoch 59
Train function
Loss = 9.1604e-04, PNorm = 57.7143, GNorm = 4.9740, lr_0 = 1.0804e-04
Loss = 1.0573e-03, PNorm = 57.7182, GNorm = 7.9791, lr_0 = 1.0804e-04
Loss = 1.0918e-03, PNorm = 57.7222, GNorm = 2.7235, lr_0 = 1.0804e-04
Loss = 1.0503e-03, PNorm = 57.7261, GNorm = 7.3381, lr_0 = 1.0804e-04
Loss = 8.9706e-04, PNorm = 57.7304, GNorm = 1.6653, lr_0 = 1.0804e-04
Validation rmse logD = 0.566366
Validation R2 logD = 0.793440
Epoch 60
Train function
Loss = 5.2497e-04, PNorm = 57.7352, GNorm = 1.3288, lr_0 = 1.0804e-04
Loss = 6.8726e-04, PNorm = 57.7395, GNorm = 4.5582, lr_0 = 1.0804e-04
Loss = 6.8869e-04, PNorm = 57.7423, GNorm = 1.6129, lr_0 = 1.0804e-04
Loss = 9.6134e-04, PNorm = 57.7460, GNorm = 3.2000, lr_0 = 1.0804e-04
Loss = 8.8253e-04, PNorm = 57.7492, GNorm = 3.5669, lr_0 = 1.0804e-04
Loss = 1.0281e-03, PNorm = 57.7517, GNorm = 4.6210, lr_0 = 1.0804e-04
Validation rmse logD = 0.556217
Validation R2 logD = 0.800776
Epoch 61
Train function
Loss = 9.1437e-04, PNorm = 57.7548, GNorm = 6.3861, lr_0 = 1.0804e-04
Loss = 8.6490e-04, PNorm = 57.7584, GNorm = 4.7346, lr_0 = 1.0804e-04
Loss = 9.4251e-04, PNorm = 57.7624, GNorm = 2.3221, lr_0 = 1.0804e-04
Loss = 7.9777e-04, PNorm = 57.7666, GNorm = 1.8884, lr_0 = 1.0804e-04
Loss = 6.8432e-04, PNorm = 57.7707, GNorm = 1.1636, lr_0 = 1.0804e-04
Loss = 8.4017e-04, PNorm = 57.7737, GNorm = 2.6118, lr_0 = 1.0804e-04
Validation rmse logD = 0.558081
Validation R2 logD = 0.799439
Epoch 62
Train function
Loss = 5.9234e-04, PNorm = 57.7777, GNorm = 3.5207, lr_0 = 1.0804e-04
Loss = 5.8518e-04, PNorm = 57.7808, GNorm = 1.3691, lr_0 = 1.0804e-04
Loss = 6.4282e-04, PNorm = 57.7843, GNorm = 3.7254, lr_0 = 1.0804e-04
Loss = 1.1371e-03, PNorm = 57.7876, GNorm = 5.1761, lr_0 = 1.0804e-04
Loss = 8.6447e-04, PNorm = 57.7906, GNorm = 4.9079, lr_0 = 1.0804e-04
Validation rmse logD = 0.599237
Validation R2 logD = 0.768767
Epoch 63
Train function
Loss = 1.2241e-03, PNorm = 57.7945, GNorm = 6.2311, lr_0 = 1.0804e-04
Loss = 9.0510e-04, PNorm = 57.7993, GNorm = 3.6598, lr_0 = 1.0804e-04
Loss = 7.2095e-04, PNorm = 57.8039, GNorm = 1.5315, lr_0 = 1.0804e-04
Loss = 7.3022e-04, PNorm = 57.8069, GNorm = 2.6039, lr_0 = 1.0804e-04
Loss = 7.9521e-04, PNorm = 57.8110, GNorm = 1.2692, lr_0 = 1.0804e-04
Loss = 7.8518e-04, PNorm = 57.8134, GNorm = 1.6011, lr_0 = 1.0804e-04
Validation rmse logD = 0.561966
Validation R2 logD = 0.796637
Epoch 64
Train function
Loss = 7.6065e-04, PNorm = 57.8169, GNorm = 2.2228, lr_0 = 1.0804e-04
Loss = 1.0084e-03, PNorm = 57.8199, GNorm = 4.5332, lr_0 = 1.0804e-04
Loss = 6.3912e-04, PNorm = 57.8231, GNorm = 1.0079, lr_0 = 1.0804e-04
Loss = 7.8602e-04, PNorm = 57.8257, GNorm = 1.3029, lr_0 = 1.0804e-04
Loss = 7.5739e-04, PNorm = 57.8285, GNorm = 2.7603, lr_0 = 1.0804e-04
Loss = 6.4336e-04, PNorm = 57.8312, GNorm = 2.5694, lr_0 = 1.0804e-04
Validation rmse logD = 0.563740
Validation R2 logD = 0.795351
Epoch 65
Train function
Loss = 6.5690e-04, PNorm = 57.8351, GNorm = 3.2693, lr_0 = 1.0804e-04
Loss = 6.4669e-04, PNorm = 57.8394, GNorm = 2.9073, lr_0 = 1.0804e-04
Loss = 8.0326e-04, PNorm = 57.8430, GNorm = 1.1992, lr_0 = 1.0804e-04
Loss = 7.0917e-04, PNorm = 57.8464, GNorm = 4.3122, lr_0 = 1.0804e-04
Loss = 6.9616e-04, PNorm = 57.8499, GNorm = 4.2275, lr_0 = 1.0804e-04
Validation rmse logD = 0.589104
Validation R2 logD = 0.776522
Epoch 66
Train function
Loss = 1.3090e-03, PNorm = 57.8529, GNorm = 7.6451, lr_0 = 1.0804e-04
Loss = 6.0151e-04, PNorm = 57.8570, GNorm = 1.6908, lr_0 = 1.0804e-04
Loss = 6.8295e-04, PNorm = 57.8611, GNorm = 6.1691, lr_0 = 1.0804e-04
Loss = 9.2308e-04, PNorm = 57.8655, GNorm = 4.1837, lr_0 = 1.0804e-04
Loss = 7.0979e-04, PNorm = 57.8694, GNorm = 4.0107, lr_0 = 1.0804e-04
Loss = 6.4212e-04, PNorm = 57.8717, GNorm = 1.7337, lr_0 = 1.0804e-04
Validation rmse logD = 0.552936
Validation R2 logD = 0.803119
Epoch 67
Train function
Loss = 8.2853e-04, PNorm = 57.8755, GNorm = 1.0390, lr_0 = 1.0804e-04
Loss = 5.8453e-04, PNorm = 57.8788, GNorm = 3.2904, lr_0 = 1.0804e-04
Loss = 6.0770e-04, PNorm = 57.8823, GNorm = 2.6009, lr_0 = 1.0804e-04
Loss = 7.2879e-04, PNorm = 57.8848, GNorm = 2.6953, lr_0 = 1.0804e-04
Loss = 7.4356e-04, PNorm = 57.8872, GNorm = 5.1546, lr_0 = 1.0804e-04
Loss = 7.7579e-04, PNorm = 57.8908, GNorm = 2.1991, lr_0 = 1.0804e-04
Validation rmse logD = 0.575414
Validation R2 logD = 0.786787
Epoch 68
Train function
Loss = 8.4211e-04, PNorm = 57.8940, GNorm = 4.4145, lr_0 = 1.0804e-04
Loss = 7.3172e-04, PNorm = 57.8981, GNorm = 2.4770, lr_0 = 1.0804e-04
Loss = 5.7390e-04, PNorm = 57.9004, GNorm = 2.6709, lr_0 = 1.0804e-04
Loss = 6.9461e-04, PNorm = 57.9023, GNorm = 3.3552, lr_0 = 1.0804e-04
Loss = 6.5613e-04, PNorm = 57.9067, GNorm = 2.2643, lr_0 = 1.0804e-04
Validation rmse logD = 0.572864
Validation R2 logD = 0.788673
Epoch 69
Train function
Loss = 4.0347e-04, PNorm = 57.9106, GNorm = 1.8955, lr_0 = 1.0804e-04
Loss = 1.0630e-03, PNorm = 57.9129, GNorm = 9.6303, lr_0 = 1.0804e-04
Loss = 8.7626e-04, PNorm = 57.9164, GNorm = 6.1548, lr_0 = 1.0804e-04
Loss = 6.8682e-04, PNorm = 57.9208, GNorm = 1.6962, lr_0 = 1.0804e-04
Loss = 5.4775e-04, PNorm = 57.9231, GNorm = 2.8461, lr_0 = 1.0804e-04
Loss = 6.0527e-04, PNorm = 57.9260, GNorm = 3.6718, lr_0 = 1.0804e-04
Validation rmse logD = 0.556054
Validation R2 logD = 0.800893
Epoch 70
Train function
Loss = 4.5483e-04, PNorm = 57.9294, GNorm = 2.0227, lr_0 = 1.0804e-04
Loss = 5.3822e-04, PNorm = 57.9330, GNorm = 2.6918, lr_0 = 1.0804e-04
Loss = 5.9497e-04, PNorm = 57.9375, GNorm = 1.2797, lr_0 = 1.0804e-04
Loss = 8.1440e-04, PNorm = 57.9402, GNorm = 2.9877, lr_0 = 1.0804e-04
Loss = 6.6311e-04, PNorm = 57.9426, GNorm = 3.9158, lr_0 = 1.0804e-04
Loss = 5.5984e-04, PNorm = 57.9456, GNorm = 4.8013, lr_0 = 1.0804e-04
Validation rmse logD = 0.562271
Validation R2 logD = 0.796416
Epoch 71
Train function
Loss = 6.9013e-04, PNorm = 57.9474, GNorm = 2.2361, lr_0 = 1.0804e-04
Loss = 6.5381e-04, PNorm = 57.9527, GNorm = 1.8496, lr_0 = 1.0804e-04
Loss = 7.0917e-04, PNorm = 57.9562, GNorm = 2.3109, lr_0 = 1.0804e-04
Loss = 5.1406e-04, PNorm = 57.9593, GNorm = 2.7004, lr_0 = 1.0804e-04
Loss = 5.5096e-04, PNorm = 57.9618, GNorm = 3.9980, lr_0 = 1.0804e-04
Validation rmse logD = 0.551951
Validation R2 logD = 0.803820
Epoch 72
Train function
Loss = 5.5281e-04, PNorm = 57.9655, GNorm = 3.0856, lr_0 = 1.0804e-04
Loss = 4.9229e-04, PNorm = 57.9684, GNorm = 4.2421, lr_0 = 1.0804e-04
Loss = 6.8140e-04, PNorm = 57.9722, GNorm = 4.7306, lr_0 = 1.0804e-04
Loss = 5.4044e-04, PNorm = 57.9750, GNorm = 4.9629, lr_0 = 1.0804e-04
Loss = 7.5233e-04, PNorm = 57.9774, GNorm = 2.3361, lr_0 = 1.0804e-04
Loss = 9.1258e-04, PNorm = 57.9787, GNorm = 8.8912, lr_0 = 1.0804e-04
Validation rmse logD = 0.597886
Validation R2 logD = 0.769808
Epoch 73
Train function
Loss = 1.2645e-03, PNorm = 57.9815, GNorm = 6.5442, lr_0 = 1.0804e-04
Loss = 6.8511e-04, PNorm = 57.9852, GNorm = 2.4589, lr_0 = 1.0804e-04
Loss = 5.9632e-04, PNorm = 57.9898, GNorm = 1.1311, lr_0 = 1.0804e-04
Loss = 5.5146e-04, PNorm = 57.9949, GNorm = 3.6323, lr_0 = 1.0804e-04
Loss = 6.6811e-04, PNorm = 57.9986, GNorm = 2.2754, lr_0 = 1.0804e-04
Loss = 6.2425e-04, PNorm = 58.0021, GNorm = 2.8165, lr_0 = 1.0804e-04
Validation rmse logD = 0.557051
Validation R2 logD = 0.800179
Epoch 74
Train function
Loss = 6.8983e-04, PNorm = 58.0055, GNorm = 5.8377, lr_0 = 1.0804e-04
Loss = 1.0488e-03, PNorm = 58.0081, GNorm = 1.7403, lr_0 = 1.0804e-04
Loss = 6.9914e-04, PNorm = 58.0130, GNorm = 2.2029, lr_0 = 1.0804e-04
Loss = 6.7122e-04, PNorm = 58.0167, GNorm = 1.7308, lr_0 = 1.0804e-04
Loss = 6.7224e-04, PNorm = 58.0183, GNorm = 4.2084, lr_0 = 1.0804e-04
Validation rmse logD = 0.564323
Validation R2 logD = 0.794927
Epoch 75
Train function
Loss = 3.2843e-04, PNorm = 58.0212, GNorm = 1.2297, lr_0 = 1.0804e-04
Loss = 6.8143e-04, PNorm = 58.0236, GNorm = 5.0294, lr_0 = 1.0804e-04
Loss = 6.0833e-04, PNorm = 58.0270, GNorm = 2.1785, lr_0 = 1.0804e-04
Loss = 5.0704e-04, PNorm = 58.0302, GNorm = 2.7976, lr_0 = 1.0804e-04
Loss = 6.1972e-04, PNorm = 58.0345, GNorm = 4.0810, lr_0 = 1.0804e-04
Loss = 9.0579e-04, PNorm = 58.0384, GNorm = 4.1792, lr_0 = 1.0804e-04
Validation rmse logD = 0.563141
Validation R2 logD = 0.795785
Epoch 76
Train function
Loss = 6.5173e-04, PNorm = 58.0418, GNorm = 2.4688, lr_0 = 1.0804e-04
Loss = 4.5372e-04, PNorm = 58.0455, GNorm = 1.1720, lr_0 = 1.0804e-04
Loss = 4.9247e-04, PNorm = 58.0485, GNorm = 1.5828, lr_0 = 1.0804e-04
Loss = 6.0478e-04, PNorm = 58.0509, GNorm = 3.2770, lr_0 = 1.0804e-04
Loss = 5.4182e-04, PNorm = 58.0529, GNorm = 0.6685, lr_0 = 1.0804e-04
Loss = 4.8926e-04, PNorm = 58.0560, GNorm = 2.6456, lr_0 = 1.0804e-04
Validation rmse logD = 0.562960
Validation R2 logD = 0.795916
Epoch 77
Train function
Loss = 4.7511e-04, PNorm = 58.0585, GNorm = 1.0223, lr_0 = 1.0804e-04
Loss = 6.0196e-04, PNorm = 58.0609, GNorm = 5.9561, lr_0 = 1.0804e-04
Loss = 1.0074e-03, PNorm = 58.0629, GNorm = 3.0176, lr_0 = 1.0804e-04
Loss = 8.5602e-04, PNorm = 58.0650, GNorm = 3.3836, lr_0 = 1.0804e-04
Loss = 5.6530e-04, PNorm = 58.0702, GNorm = 4.9565, lr_0 = 1.0804e-04
Validation rmse logD = 0.554182
Validation R2 logD = 0.802231
Epoch 78
Train function
Loss = 4.3456e-04, PNorm = 58.0732, GNorm = 2.3181, lr_0 = 1.0804e-04
Loss = 7.2880e-04, PNorm = 58.0757, GNorm = 2.0238, lr_0 = 1.0804e-04
Loss = 8.8456e-04, PNorm = 58.0799, GNorm = 1.6047, lr_0 = 1.0804e-04
Loss = 7.9967e-04, PNorm = 58.0831, GNorm = 1.3210, lr_0 = 1.0804e-04
Loss = 5.3888e-04, PNorm = 58.0885, GNorm = 0.9086, lr_0 = 1.0804e-04
Loss = 4.6903e-04, PNorm = 58.0926, GNorm = 1.5592, lr_0 = 1.0804e-04
Validation rmse logD = 0.550735
Validation R2 logD = 0.804684
Epoch 79
Train function
Loss = 3.9941e-04, PNorm = 58.0947, GNorm = 1.0883, lr_0 = 1.0804e-04
Loss = 4.3079e-04, PNorm = 58.0966, GNorm = 2.2565, lr_0 = 1.0804e-04
Loss = 4.2682e-04, PNorm = 58.0995, GNorm = 2.9798, lr_0 = 1.0804e-04
Loss = 5.3662e-04, PNorm = 58.1013, GNorm = 1.5246, lr_0 = 1.0804e-04
Loss = 8.1490e-04, PNorm = 58.1027, GNorm = 2.2816, lr_0 = 1.0804e-04
Loss = 1.1107e-03, PNorm = 58.1040, GNorm = 2.6002, lr_0 = 1.0804e-04
Validation rmse logD = 0.654095
Validation R2 logD = 0.724492
Epoch 80
Train function
Loss = 1.0832e-03, PNorm = 58.1066, GNorm = 4.8648, lr_0 = 1.0804e-04
Loss = 1.1665e-03, PNorm = 58.1104, GNorm = 3.1408, lr_0 = 1.0804e-04
Loss = 7.1563e-04, PNorm = 58.1159, GNorm = 0.9812, lr_0 = 1.0804e-04
Loss = 5.2473e-04, PNorm = 58.1219, GNorm = 1.4839, lr_0 = 1.0804e-04
Loss = 5.8343e-04, PNorm = 58.1259, GNorm = 1.4666, lr_0 = 1.0804e-04
Validation rmse logD = 0.566854
Validation R2 logD = 0.793084
Epoch 81
Train function
Loss = 8.5972e-04, PNorm = 58.1288, GNorm = 4.5714, lr_0 = 1.0804e-04
Loss = 4.7536e-04, PNorm = 58.1319, GNorm = 3.5406, lr_0 = 1.0804e-04
Loss = 4.5150e-04, PNorm = 58.1354, GNorm = 1.3942, lr_0 = 1.0804e-04
Loss = 4.0691e-04, PNorm = 58.1381, GNorm = 0.7410, lr_0 = 1.0804e-04
Loss = 4.8738e-04, PNorm = 58.1403, GNorm = 1.8060, lr_0 = 1.0804e-04
Loss = 5.8351e-04, PNorm = 58.1440, GNorm = 4.3163, lr_0 = 1.0804e-04
Validation rmse logD = 0.558926
Validation R2 logD = 0.798831
Epoch 82
Train function
Loss = 4.1182e-04, PNorm = 58.1474, GNorm = 2.6158, lr_0 = 1.0804e-04
Loss = 5.4462e-04, PNorm = 58.1500, GNorm = 3.5788, lr_0 = 1.0804e-04
Loss = 4.3014e-04, PNorm = 58.1531, GNorm = 0.9059, lr_0 = 1.0804e-04
Loss = 3.6704e-04, PNorm = 58.1559, GNorm = 1.2947, lr_0 = 1.0804e-04
Loss = 4.4040e-04, PNorm = 58.1581, GNorm = 2.4998, lr_0 = 1.0804e-04
Loss = 4.1000e-04, PNorm = 58.1604, GNorm = 1.8232, lr_0 = 1.0804e-04
Validation rmse logD = 0.553783
Validation R2 logD = 0.802516
Epoch 83
Train function
Loss = 4.2670e-04, PNorm = 58.1630, GNorm = 3.0678, lr_0 = 1.0804e-04
Loss = 3.8816e-04, PNorm = 58.1647, GNorm = 0.9087, lr_0 = 1.0804e-04
Loss = 4.3549e-04, PNorm = 58.1673, GNorm = 2.6369, lr_0 = 1.0804e-04
Loss = 3.4699e-04, PNorm = 58.1691, GNorm = 0.8625, lr_0 = 1.0804e-04
Loss = 4.4032e-04, PNorm = 58.1715, GNorm = 1.6763, lr_0 = 1.0804e-04
Validation rmse logD = 0.563816
Validation R2 logD = 0.795295
Epoch 84
Train function
Loss = 3.4558e-04, PNorm = 58.1746, GNorm = 1.9624, lr_0 = 1.0804e-04
Loss = 5.6894e-04, PNorm = 58.1766, GNorm = 3.0806, lr_0 = 1.0804e-04
Loss = 7.8361e-04, PNorm = 58.1802, GNorm = 4.6917, lr_0 = 1.0804e-04
Loss = 4.9577e-04, PNorm = 58.1812, GNorm = 3.1502, lr_0 = 1.0804e-04
Loss = 4.2793e-04, PNorm = 58.1839, GNorm = 0.7664, lr_0 = 1.0804e-04
Loss = 4.4612e-04, PNorm = 58.1876, GNorm = 3.6887, lr_0 = 1.0804e-04
Validation rmse logD = 0.558008
Validation R2 logD = 0.799491
Epoch 85
Train function
Loss = 4.2253e-04, PNorm = 58.1915, GNorm = 1.4834, lr_0 = 1.0804e-04
Loss = 4.1999e-04, PNorm = 58.1940, GNorm = 1.7316, lr_0 = 1.0804e-04
Loss = 4.8358e-04, PNorm = 58.1963, GNorm = 2.4398, lr_0 = 1.0804e-04
Loss = 4.4855e-04, PNorm = 58.1982, GNorm = 2.4186, lr_0 = 1.0804e-04
Loss = 4.3535e-04, PNorm = 58.2013, GNorm = 3.9551, lr_0 = 1.0804e-04
Loss = 6.0525e-04, PNorm = 58.2047, GNorm = 1.4701, lr_0 = 1.0804e-04
Validation rmse logD = 0.550390
Validation R2 logD = 0.804928
Epoch 86
Train function
Loss = 3.1932e-04, PNorm = 58.2081, GNorm = 1.0971, lr_0 = 1.0804e-04
Loss = 4.1933e-04, PNorm = 58.2105, GNorm = 0.8831, lr_0 = 1.0804e-04
Loss = 4.1868e-04, PNorm = 58.2128, GNorm = 3.4095, lr_0 = 1.0804e-04
Loss = 4.7544e-04, PNorm = 58.2142, GNorm = 1.8371, lr_0 = 1.0804e-04
Loss = 4.1661e-04, PNorm = 58.2171, GNorm = 1.2507, lr_0 = 1.0804e-04
Validation rmse logD = 0.564855
Validation R2 logD = 0.794540
Epoch 87
Train function
Loss = 7.0389e-04, PNorm = 58.2198, GNorm = 4.3741, lr_0 = 1.0804e-04
Loss = 4.0968e-04, PNorm = 58.2215, GNorm = 0.9650, lr_0 = 1.0804e-04
Loss = 3.9451e-04, PNorm = 58.2239, GNorm = 3.6071, lr_0 = 1.0804e-04
Loss = 5.3978e-04, PNorm = 58.2267, GNorm = 4.5088, lr_0 = 1.0804e-04
Loss = 6.1437e-04, PNorm = 58.2293, GNorm = 3.3286, lr_0 = 1.0804e-04
Loss = 4.5876e-04, PNorm = 58.2320, GNorm = 1.1038, lr_0 = 1.0804e-04
Validation rmse logD = 0.571943
Validation R2 logD = 0.789352
Epoch 88
Train function
Loss = 3.5477e-04, PNorm = 58.2348, GNorm = 2.9510, lr_0 = 1.0804e-04
Loss = 3.3605e-04, PNorm = 58.2374, GNorm = 0.7654, lr_0 = 1.0804e-04
Loss = 3.6910e-04, PNorm = 58.2404, GNorm = 2.0806, lr_0 = 1.0804e-04
Loss = 3.6307e-04, PNorm = 58.2431, GNorm = 1.6184, lr_0 = 1.0804e-04
Loss = 4.3055e-04, PNorm = 58.2457, GNorm = 1.6465, lr_0 = 1.0804e-04
Loss = 3.5520e-04, PNorm = 58.2480, GNorm = 1.7550, lr_0 = 1.0804e-04
Validation rmse logD = 0.554926
Validation R2 logD = 0.801700
Epoch 89
Train function
Loss = 3.7412e-04, PNorm = 58.2499, GNorm = 1.3514, lr_0 = 1.0804e-04
Loss = 4.5442e-04, PNorm = 58.2512, GNorm = 4.0068, lr_0 = 1.0804e-04
Loss = 3.4552e-04, PNorm = 58.2546, GNorm = 0.8875, lr_0 = 1.0804e-04
Loss = 4.3729e-04, PNorm = 58.2575, GNorm = 1.1289, lr_0 = 1.0804e-04
Loss = 3.6713e-04, PNorm = 58.2595, GNorm = 1.0649, lr_0 = 1.0804e-04
Validation rmse logD = 0.551546
Validation R2 logD = 0.804108
Epoch 90
Train function
Loss = 4.7654e-04, PNorm = 58.2623, GNorm = 1.6762, lr_0 = 1.0804e-04
Loss = 2.7504e-04, PNorm = 58.2641, GNorm = 2.2983, lr_0 = 1.0804e-04
Loss = 3.7798e-04, PNorm = 58.2669, GNorm = 3.3134, lr_0 = 1.0804e-04
Loss = 3.4916e-04, PNorm = 58.2681, GNorm = 1.2871, lr_0 = 1.0804e-04
Loss = 3.4172e-04, PNorm = 58.2700, GNorm = 1.0864, lr_0 = 1.0804e-04
Loss = 3.5861e-04, PNorm = 58.2717, GNorm = 3.5393, lr_0 = 1.0804e-04
Validation rmse logD = 0.553419
Validation R2 logD = 0.802775
Epoch 91
Train function
Loss = 2.4819e-04, PNorm = 58.2746, GNorm = 0.7585, lr_0 = 1.0804e-04
Loss = 3.0984e-04, PNorm = 58.2775, GNorm = 0.7235, lr_0 = 1.0804e-04
Loss = 4.7065e-04, PNorm = 58.2797, GNorm = 2.8358, lr_0 = 1.0804e-04
Loss = 4.1533e-04, PNorm = 58.2826, GNorm = 0.7313, lr_0 = 1.0804e-04
Loss = 3.7931e-04, PNorm = 58.2851, GNorm = 0.9439, lr_0 = 1.0804e-04
Loss = 5.0688e-04, PNorm = 58.2866, GNorm = 2.3846, lr_0 = 1.0804e-04
Validation rmse logD = 0.586683
Validation R2 logD = 0.778354
Epoch 92
Train function
Loss = 6.0342e-04, PNorm = 58.2881, GNorm = 5.7107, lr_0 = 1.0804e-04
Loss = 7.0603e-04, PNorm = 58.2911, GNorm = 4.7770, lr_0 = 1.0804e-04
Loss = 4.8923e-04, PNorm = 58.2955, GNorm = 0.8030, lr_0 = 1.0804e-04
Loss = 4.5231e-04, PNorm = 58.2990, GNorm = 3.2460, lr_0 = 1.0804e-04
Loss = 4.7887e-04, PNorm = 58.3025, GNorm = 3.1201, lr_0 = 1.0804e-04
Validation rmse logD = 0.553966
Validation R2 logD = 0.802386
Epoch 93
Train function
Loss = 3.0448e-04, PNorm = 58.3058, GNorm = 0.9125, lr_0 = 1.0804e-04
Loss = 4.2691e-04, PNorm = 58.3088, GNorm = 2.7334, lr_0 = 1.0804e-04
Loss = 3.6456e-04, PNorm = 58.3110, GNorm = 1.7891, lr_0 = 1.0804e-04
Loss = 3.7000e-04, PNorm = 58.3141, GNorm = 1.6041, lr_0 = 1.0804e-04
Loss = 3.6129e-04, PNorm = 58.3165, GNorm = 0.9141, lr_0 = 1.0804e-04
Loss = 3.2338e-04, PNorm = 58.3197, GNorm = 1.3647, lr_0 = 1.0804e-04
Validation rmse logD = 0.560376
Validation R2 logD = 0.797786
Epoch 94
Train function
Loss = 3.4955e-04, PNorm = 58.3224, GNorm = 1.5001, lr_0 = 1.0804e-04
Loss = 3.9832e-04, PNorm = 58.3246, GNorm = 1.2068, lr_0 = 1.0804e-04
Loss = 2.9118e-04, PNorm = 58.3270, GNorm = 0.7384, lr_0 = 1.0804e-04
Loss = 3.1382e-04, PNorm = 58.3294, GNorm = 2.0885, lr_0 = 1.0804e-04
Loss = 3.4294e-04, PNorm = 58.3321, GNorm = 1.8063, lr_0 = 1.0804e-04
Loss = 3.5560e-04, PNorm = 58.3347, GNorm = 4.5156, lr_0 = 1.0804e-04
Validation rmse logD = 0.558559
Validation R2 logD = 0.799095
Epoch 95
Train function
Loss = 3.5859e-04, PNorm = 58.3378, GNorm = 1.6146, lr_0 = 1.0804e-04
Loss = 3.9320e-04, PNorm = 58.3404, GNorm = 5.5109, lr_0 = 1.0804e-04
Loss = 6.1603e-04, PNorm = 58.3433, GNorm = 1.5496, lr_0 = 1.0804e-04
Loss = 3.0922e-04, PNorm = 58.3457, GNorm = 1.1133, lr_0 = 1.0804e-04
Loss = 3.5161e-04, PNorm = 58.3478, GNorm = 2.7266, lr_0 = 1.0804e-04
Validation rmse logD = 0.555571
Validation R2 logD = 0.801239
Epoch 96
Train function
Loss = 2.3993e-04, PNorm = 58.3494, GNorm = 1.4620, lr_0 = 1.0804e-04
Loss = 3.2442e-04, PNorm = 58.3514, GNorm = 2.1436, lr_0 = 1.0804e-04
Loss = 2.5784e-04, PNorm = 58.3544, GNorm = 0.4679, lr_0 = 1.0804e-04
Loss = 3.8065e-04, PNorm = 58.3571, GNorm = 4.4462, lr_0 = 1.0804e-04
Loss = 5.1562e-04, PNorm = 58.3600, GNorm = 3.1789, lr_0 = 1.0804e-04
Loss = 3.2350e-04, PNorm = 58.3631, GNorm = 3.4926, lr_0 = 1.0804e-04
Validation rmse logD = 0.572701
Validation R2 logD = 0.788793
Epoch 97
Train function
Loss = 4.9163e-04, PNorm = 58.3650, GNorm = 0.8824, lr_0 = 1.0804e-04
Loss = 4.7101e-04, PNorm = 58.3662, GNorm = 3.5746, lr_0 = 1.0804e-04
Loss = 3.3409e-04, PNorm = 58.3697, GNorm = 2.8961, lr_0 = 1.0804e-04
Loss = 5.3360e-04, PNorm = 58.3729, GNorm = 5.6504, lr_0 = 1.0804e-04
Loss = 5.8535e-04, PNorm = 58.3754, GNorm = 3.6736, lr_0 = 1.0804e-04
Loss = 4.8080e-04, PNorm = 58.3798, GNorm = 1.8429, lr_0 = 1.0804e-04
Validation rmse logD = 0.551882
Validation R2 logD = 0.803870
Epoch 98
Train function
Loss = 3.2522e-04, PNorm = 58.3827, GNorm = 1.0682, lr_0 = 1.0804e-04
Loss = 4.3999e-04, PNorm = 58.3857, GNorm = 4.3498, lr_0 = 1.0804e-04
Loss = 4.8677e-04, PNorm = 58.3886, GNorm = 4.0977, lr_0 = 1.0804e-04
Loss = 4.6650e-04, PNorm = 58.3919, GNorm = 2.5150, lr_0 = 1.0804e-04
Loss = 4.3730e-04, PNorm = 58.3950, GNorm = 4.4533, lr_0 = 1.0804e-04
Validation rmse logD = 0.558758
Validation R2 logD = 0.798952
Epoch 99
Train function
Loss = 2.6026e-04, PNorm = 58.3980, GNorm = 0.7863, lr_0 = 1.0804e-04
Loss = 3.4621e-04, PNorm = 58.4006, GNorm = 1.7057, lr_0 = 1.0804e-04
Loss = 2.5913e-04, PNorm = 58.4026, GNorm = 2.7717, lr_0 = 1.0804e-04
Loss = 3.1079e-04, PNorm = 58.4042, GNorm = 3.3864, lr_0 = 1.0804e-04
Loss = 3.5361e-04, PNorm = 58.4067, GNorm = 4.6304, lr_0 = 1.0804e-04
Loss = 3.8031e-04, PNorm = 58.4093, GNorm = 1.0979, lr_0 = 1.0804e-04
Validation rmse logD = 0.573880
Validation R2 logD = 0.787923
Model 0 best validation rmse = 0.550390 on epoch 85
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.539622
Model 0 test R2 logD = 0.792151
Ensemble test rmse  logD= 0.539622
Ensemble test R2  logD= 0.792151
Fold 4
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': True,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_wo_fragments_and_counts'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 95,
 'ffn_hidden_size': 800,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 800,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_352/folds/fold_4',
 'save_smiles_splits': False,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=800, bias=False)
      (W_h): Linear(in_features=800, out_features=800, bias=False)
      (W_o): Linear(in_features=933, out_features=800, bias=True)
    )
  )
  (substructures_encoder): SubstructureLayer(
    (encoder): SubstructureEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_o): Linear(in_features=165, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=1195, out_features=800, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=800, out_features=1, bias=True)
  )
)
Number of parameters = 2,512,201
Moving model to cuda
Epoch 0
Train function
Loss = 2.1037e-02, PNorm = 55.5550, GNorm = 8.7580, lr_0 = 1.0804e-04
Loss = 2.0262e-02, PNorm = 55.5565, GNorm = 3.6754, lr_0 = 1.0804e-04
Loss = 1.7440e-02, PNorm = 55.5590, GNorm = 2.4319, lr_0 = 1.0804e-04
Loss = 1.7709e-02, PNorm = 55.5625, GNorm = 2.9658, lr_0 = 1.0804e-04
Loss = 1.7648e-02, PNorm = 55.5664, GNorm = 1.4465, lr_0 = 1.0804e-04
Validation rmse logD = 1.100183
Validation R2 logD = 0.243829
Epoch 1
Train function
Loss = 1.6378e-02, PNorm = 55.5704, GNorm = 1.9408, lr_0 = 1.0804e-04
Loss = 1.4479e-02, PNorm = 55.5743, GNorm = 2.6809, lr_0 = 1.0804e-04
Loss = 1.5968e-02, PNorm = 55.5790, GNorm = 7.2989, lr_0 = 1.0804e-04
Loss = 1.4287e-02, PNorm = 55.5844, GNorm = 1.6686, lr_0 = 1.0804e-04
Loss = 1.5494e-02, PNorm = 55.5908, GNorm = 4.3240, lr_0 = 1.0804e-04
Loss = 1.6375e-02, PNorm = 55.5977, GNorm = 3.3229, lr_0 = 1.0804e-04
Validation rmse logD = 1.039540
Validation R2 logD = 0.324894
Epoch 2
Train function
Loss = 1.3407e-02, PNorm = 55.6064, GNorm = 3.7256, lr_0 = 1.0804e-04
Loss = 1.4652e-02, PNorm = 55.6149, GNorm = 1.6204, lr_0 = 1.0804e-04
Loss = 1.4042e-02, PNorm = 55.6243, GNorm = 2.7848, lr_0 = 1.0804e-04
Loss = 1.4251e-02, PNorm = 55.6360, GNorm = 2.4405, lr_0 = 1.0804e-04
Loss = 1.3213e-02, PNorm = 55.6490, GNorm = 3.7142, lr_0 = 1.0804e-04
Validation rmse logD = 0.985961
Validation R2 logD = 0.392692
Epoch 3
Train function
Loss = 1.2350e-02, PNorm = 55.6638, GNorm = 1.9910, lr_0 = 1.0804e-04
Loss = 1.2746e-02, PNorm = 55.6757, GNorm = 4.2994, lr_0 = 1.0804e-04
Loss = 1.2164e-02, PNorm = 55.6906, GNorm = 1.2397, lr_0 = 1.0804e-04
Loss = 1.1044e-02, PNorm = 55.7046, GNorm = 2.5629, lr_0 = 1.0804e-04
Loss = 1.2256e-02, PNorm = 55.7178, GNorm = 4.7044, lr_0 = 1.0804e-04
Loss = 1.2271e-02, PNorm = 55.7295, GNorm = 6.7888, lr_0 = 1.0804e-04
Validation rmse logD = 0.945082
Validation R2 logD = 0.442007
Epoch 4
Train function
Loss = 1.2793e-02, PNorm = 55.7407, GNorm = 5.4400, lr_0 = 1.0804e-04
Loss = 1.1337e-02, PNorm = 55.7515, GNorm = 2.4936, lr_0 = 1.0804e-04
Loss = 1.0896e-02, PNorm = 55.7659, GNorm = 7.0982, lr_0 = 1.0804e-04
Loss = 1.1114e-02, PNorm = 55.7777, GNorm = 3.3000, lr_0 = 1.0804e-04
Loss = 9.5991e-03, PNorm = 55.7900, GNorm = 3.2141, lr_0 = 1.0804e-04
Loss = 1.0188e-02, PNorm = 55.8064, GNorm = 3.0804, lr_0 = 1.0804e-04
Validation rmse logD = 0.914153
Validation R2 logD = 0.477931
Epoch 5
Train function
Loss = 9.7413e-03, PNorm = 55.8206, GNorm = 7.6901, lr_0 = 1.0804e-04
Loss = 1.0272e-02, PNorm = 55.8334, GNorm = 1.4095, lr_0 = 1.0804e-04
Loss = 9.1300e-03, PNorm = 55.8469, GNorm = 5.0819, lr_0 = 1.0804e-04
Loss = 8.0533e-03, PNorm = 55.8620, GNorm = 4.1665, lr_0 = 1.0804e-04
Loss = 1.0728e-02, PNorm = 55.8761, GNorm = 3.5355, lr_0 = 1.0804e-04
Validation rmse logD = 0.864764
Validation R2 logD = 0.532819
Epoch 6
Train function
Loss = 8.3342e-03, PNorm = 55.8896, GNorm = 5.0675, lr_0 = 1.0804e-04
Loss = 8.6546e-03, PNorm = 55.9031, GNorm = 2.0128, lr_0 = 1.0804e-04
Loss = 8.7895e-03, PNorm = 55.9149, GNorm = 4.9223, lr_0 = 1.0804e-04
Loss = 9.2496e-03, PNorm = 55.9267, GNorm = 9.9462, lr_0 = 1.0804e-04
Loss = 9.4804e-03, PNorm = 55.9409, GNorm = 5.1673, lr_0 = 1.0804e-04
Loss = 7.1412e-03, PNorm = 55.9530, GNorm = 2.1372, lr_0 = 1.0804e-04
Validation rmse logD = 0.848815
Validation R2 logD = 0.549893
Epoch 7
Train function
Loss = 8.3951e-03, PNorm = 55.9664, GNorm = 2.8801, lr_0 = 1.0804e-04
Loss = 8.5344e-03, PNorm = 55.9816, GNorm = 3.3984, lr_0 = 1.0804e-04
Loss = 8.0165e-03, PNorm = 55.9929, GNorm = 9.3838, lr_0 = 1.0804e-04
Loss = 7.5472e-03, PNorm = 56.0045, GNorm = 7.0739, lr_0 = 1.0804e-04
Loss = 7.0986e-03, PNorm = 56.0150, GNorm = 8.0097, lr_0 = 1.0804e-04
Loss = 7.2547e-03, PNorm = 56.0262, GNorm = 3.0421, lr_0 = 1.0804e-04
Validation rmse logD = 0.831942
Validation R2 logD = 0.567609
Epoch 8
Train function
Loss = 6.9841e-03, PNorm = 56.0337, GNorm = 2.7389, lr_0 = 1.0804e-04
Loss = 6.2953e-03, PNorm = 56.0458, GNorm = 1.3808, lr_0 = 1.0804e-04
Loss = 7.9207e-03, PNorm = 56.0600, GNorm = 2.9931, lr_0 = 1.0804e-04
Loss = 6.2138e-03, PNorm = 56.0709, GNorm = 2.1020, lr_0 = 1.0804e-04
Loss = 6.9572e-03, PNorm = 56.0812, GNorm = 5.4022, lr_0 = 1.0804e-04
Validation rmse logD = 0.835044
Validation R2 logD = 0.564379
Epoch 9
Train function
Loss = 5.2319e-03, PNorm = 56.0924, GNorm = 6.3770, lr_0 = 1.0804e-04
Loss = 6.8095e-03, PNorm = 56.1034, GNorm = 5.8795, lr_0 = 1.0804e-04
Loss = 7.0239e-03, PNorm = 56.1147, GNorm = 5.0291, lr_0 = 1.0804e-04
Loss = 6.5913e-03, PNorm = 56.1261, GNorm = 5.7217, lr_0 = 1.0804e-04
Loss = 6.7063e-03, PNorm = 56.1373, GNorm = 9.7669, lr_0 = 1.0804e-04
Loss = 5.3078e-03, PNorm = 56.1473, GNorm = 1.2324, lr_0 = 1.0804e-04
Validation rmse logD = 0.794593
Validation R2 logD = 0.605561
Epoch 10
Train function
Loss = 6.2458e-03, PNorm = 56.1552, GNorm = 3.7075, lr_0 = 1.0804e-04
Loss = 6.0077e-03, PNorm = 56.1635, GNorm = 2.2795, lr_0 = 1.0804e-04
Loss = 5.4365e-03, PNorm = 56.1734, GNorm = 1.7449, lr_0 = 1.0804e-04
Loss = 6.8121e-03, PNorm = 56.1837, GNorm = 9.8104, lr_0 = 1.0804e-04
Loss = 5.9698e-03, PNorm = 56.1923, GNorm = 7.0674, lr_0 = 1.0804e-04
Loss = 6.6875e-03, PNorm = 56.2025, GNorm = 2.0416, lr_0 = 1.0804e-04
Validation rmse logD = 0.807590
Validation R2 logD = 0.592552
Epoch 11
Train function
Loss = 5.8995e-03, PNorm = 56.2100, GNorm = 2.9774, lr_0 = 1.0804e-04
Loss = 5.5569e-03, PNorm = 56.2184, GNorm = 4.2509, lr_0 = 1.0804e-04
Loss = 5.4894e-03, PNorm = 56.2269, GNorm = 6.4151, lr_0 = 1.0804e-04
Loss = 6.8470e-03, PNorm = 56.2366, GNorm = 7.0240, lr_0 = 1.0804e-04
Loss = 6.1909e-03, PNorm = 56.2474, GNorm = 2.7695, lr_0 = 1.0804e-04
Validation rmse logD = 0.790563
Validation R2 logD = 0.609552
Epoch 12
Train function
Loss = 5.3271e-03, PNorm = 56.2568, GNorm = 3.9531, lr_0 = 1.0804e-04
Loss = 5.3246e-03, PNorm = 56.2663, GNorm = 2.4316, lr_0 = 1.0804e-04
Loss = 5.6942e-03, PNorm = 56.2765, GNorm = 4.7633, lr_0 = 1.0804e-04
Loss = 5.7167e-03, PNorm = 56.2845, GNorm = 6.4050, lr_0 = 1.0804e-04
Loss = 4.8900e-03, PNorm = 56.2924, GNorm = 3.3791, lr_0 = 1.0804e-04
Loss = 4.8969e-03, PNorm = 56.3005, GNorm = 3.8251, lr_0 = 1.0804e-04
Validation rmse logD = 0.771003
Validation R2 logD = 0.628634
Epoch 13
Train function
Loss = 4.0397e-03, PNorm = 56.3075, GNorm = 4.9624, lr_0 = 1.0804e-04
Loss = 4.7109e-03, PNorm = 56.3147, GNorm = 1.9271, lr_0 = 1.0804e-04
Loss = 4.3294e-03, PNorm = 56.3229, GNorm = 1.9573, lr_0 = 1.0804e-04
Loss = 4.7230e-03, PNorm = 56.3329, GNorm = 6.8904, lr_0 = 1.0804e-04
Loss = 4.8677e-03, PNorm = 56.3409, GNorm = 2.8408, lr_0 = 1.0804e-04
Loss = 5.9970e-03, PNorm = 56.3500, GNorm = 3.6185, lr_0 = 1.0804e-04
Validation rmse logD = 0.790401
Validation R2 logD = 0.609712
Epoch 14
Train function
Loss = 5.2998e-03, PNorm = 56.3568, GNorm = 3.3924, lr_0 = 1.0804e-04
Loss = 5.4218e-03, PNorm = 56.3657, GNorm = 7.6096, lr_0 = 1.0804e-04
Loss = 4.0162e-03, PNorm = 56.3727, GNorm = 3.9226, lr_0 = 1.0804e-04
Loss = 4.5164e-03, PNorm = 56.3822, GNorm = 9.5001, lr_0 = 1.0804e-04
Loss = 4.8282e-03, PNorm = 56.3916, GNorm = 2.8773, lr_0 = 1.0804e-04
Validation rmse logD = 0.792338
Validation R2 logD = 0.607797
Epoch 15
Train function
Loss = 4.2612e-03, PNorm = 56.4027, GNorm = 5.4703, lr_0 = 1.0804e-04
Loss = 4.6742e-03, PNorm = 56.4092, GNorm = 1.8335, lr_0 = 1.0804e-04
Loss = 4.4010e-03, PNorm = 56.4175, GNorm = 6.7225, lr_0 = 1.0804e-04
Loss = 4.0941e-03, PNorm = 56.4236, GNorm = 2.6870, lr_0 = 1.0804e-04
Loss = 4.1121e-03, PNorm = 56.4290, GNorm = 3.7393, lr_0 = 1.0804e-04
Loss = 4.4348e-03, PNorm = 56.4365, GNorm = 4.0730, lr_0 = 1.0804e-04
Validation rmse logD = 0.771215
Validation R2 logD = 0.628430
Epoch 16
Train function
Loss = 3.7990e-03, PNorm = 56.4473, GNorm = 5.3290, lr_0 = 1.0804e-04
Loss = 4.1056e-03, PNorm = 56.4555, GNorm = 11.8343, lr_0 = 1.0804e-04
Loss = 3.8771e-03, PNorm = 56.4610, GNorm = 5.3914, lr_0 = 1.0804e-04
Loss = 4.4679e-03, PNorm = 56.4683, GNorm = 1.8724, lr_0 = 1.0804e-04
Loss = 4.2760e-03, PNorm = 56.4771, GNorm = 4.3577, lr_0 = 1.0804e-04
Loss = 5.0502e-03, PNorm = 56.4854, GNorm = 3.6006, lr_0 = 1.0804e-04
Validation rmse logD = 0.746753
Validation R2 logD = 0.651627
Epoch 17
Train function
Loss = 3.8517e-03, PNorm = 56.4935, GNorm = 2.9039, lr_0 = 1.0804e-04
Loss = 4.4313e-03, PNorm = 56.5038, GNorm = 3.8038, lr_0 = 1.0804e-04
Loss = 4.6464e-03, PNorm = 56.5091, GNorm = 3.9324, lr_0 = 1.0804e-04
Loss = 4.0429e-03, PNorm = 56.5158, GNorm = 2.5640, lr_0 = 1.0804e-04
Loss = 4.2465e-03, PNorm = 56.5245, GNorm = 5.0704, lr_0 = 1.0804e-04
Validation rmse logD = 0.753076
Validation R2 logD = 0.645703
Epoch 18
Train function
Loss = 3.2735e-03, PNorm = 56.5334, GNorm = 4.1739, lr_0 = 1.0804e-04
Loss = 3.9085e-03, PNorm = 56.5433, GNorm = 3.3449, lr_0 = 1.0804e-04
Loss = 3.8324e-03, PNorm = 56.5513, GNorm = 1.6935, lr_0 = 1.0804e-04
Loss = 3.6100e-03, PNorm = 56.5585, GNorm = 1.6385, lr_0 = 1.0804e-04
Loss = 3.8291e-03, PNorm = 56.5649, GNorm = 2.6266, lr_0 = 1.0804e-04
Loss = 3.7451e-03, PNorm = 56.5711, GNorm = 4.0230, lr_0 = 1.0804e-04
Validation rmse logD = 0.750521
Validation R2 logD = 0.648103
Epoch 19
Train function
Loss = 2.8400e-03, PNorm = 56.5786, GNorm = 2.0039, lr_0 = 1.0804e-04
Loss = 4.1661e-03, PNorm = 56.5865, GNorm = 6.5501, lr_0 = 1.0804e-04
Loss = 4.2954e-03, PNorm = 56.5912, GNorm = 11.6553, lr_0 = 1.0804e-04
Loss = 4.6585e-03, PNorm = 56.5984, GNorm = 7.5449, lr_0 = 1.0804e-04
Loss = 3.8241e-03, PNorm = 56.6073, GNorm = 5.6605, lr_0 = 1.0804e-04
Loss = 3.6395e-03, PNorm = 56.6157, GNorm = 7.1443, lr_0 = 1.0804e-04
Validation rmse logD = 0.736642
Validation R2 logD = 0.660997
Epoch 20
Train function
Loss = 3.8567e-03, PNorm = 56.6224, GNorm = 8.9619, lr_0 = 1.0804e-04
Loss = 4.4576e-03, PNorm = 56.6284, GNorm = 6.9793, lr_0 = 1.0804e-04
Loss = 4.2101e-03, PNorm = 56.6367, GNorm = 1.3424, lr_0 = 1.0804e-04
Loss = 3.4130e-03, PNorm = 56.6435, GNorm = 2.0340, lr_0 = 1.0804e-04
Loss = 3.2220e-03, PNorm = 56.6527, GNorm = 5.8178, lr_0 = 1.0804e-04
Validation rmse logD = 0.751789
Validation R2 logD = 0.646913
Epoch 21
Train function
Loss = 1.8575e-03, PNorm = 56.6615, GNorm = 2.0541, lr_0 = 1.0804e-04
Loss = 4.0034e-03, PNorm = 56.6660, GNorm = 2.7772, lr_0 = 1.0804e-04
Loss = 3.4409e-03, PNorm = 56.6716, GNorm = 3.7912, lr_0 = 1.0804e-04
Loss = 3.4117e-03, PNorm = 56.6798, GNorm = 3.2793, lr_0 = 1.0804e-04
Loss = 3.3725e-03, PNorm = 56.6881, GNorm = 2.0975, lr_0 = 1.0804e-04
Loss = 3.6515e-03, PNorm = 56.6947, GNorm = 1.8761, lr_0 = 1.0804e-04
Validation rmse logD = 0.731620
Validation R2 logD = 0.665604
Epoch 22
Train function
Loss = 4.2909e-03, PNorm = 56.7005, GNorm = 5.6642, lr_0 = 1.0804e-04
Loss = 4.3666e-03, PNorm = 56.7072, GNorm = 8.5772, lr_0 = 1.0804e-04
Loss = 4.0846e-03, PNorm = 56.7152, GNorm = 5.8386, lr_0 = 1.0804e-04
Loss = 2.8314e-03, PNorm = 56.7240, GNorm = 1.7741, lr_0 = 1.0804e-04
Loss = 3.4412e-03, PNorm = 56.7331, GNorm = 3.7344, lr_0 = 1.0804e-04
Loss = 3.1376e-03, PNorm = 56.7412, GNorm = 6.3199, lr_0 = 1.0804e-04
Validation rmse logD = 0.755640
Validation R2 logD = 0.643287
Epoch 23
Train function
Loss = 3.3689e-03, PNorm = 56.7476, GNorm = 9.2514, lr_0 = 1.0804e-04
Loss = 2.8231e-03, PNorm = 56.7551, GNorm = 11.0428, lr_0 = 1.0804e-04
Loss = 3.7227e-03, PNorm = 56.7607, GNorm = 9.1893, lr_0 = 1.0804e-04
Loss = 3.5722e-03, PNorm = 56.7676, GNorm = 3.8752, lr_0 = 1.0804e-04
Loss = 3.3125e-03, PNorm = 56.7753, GNorm = 10.4492, lr_0 = 1.0804e-04
Validation rmse logD = 0.745427
Validation R2 logD = 0.652863
Epoch 24
Train function
Loss = 2.7013e-03, PNorm = 56.7820, GNorm = 3.8264, lr_0 = 1.0804e-04
Loss = 3.1179e-03, PNorm = 56.7895, GNorm = 1.9720, lr_0 = 1.0804e-04
Loss = 2.8732e-03, PNorm = 56.7978, GNorm = 5.7842, lr_0 = 1.0804e-04
Loss = 3.2494e-03, PNorm = 56.8043, GNorm = 1.4794, lr_0 = 1.0804e-04
Loss = 3.2437e-03, PNorm = 56.8121, GNorm = 3.7066, lr_0 = 1.0804e-04
Loss = 2.7993e-03, PNorm = 56.8192, GNorm = 2.4362, lr_0 = 1.0804e-04
Validation rmse logD = 0.763850
Validation R2 logD = 0.635493
Epoch 25
Train function
Loss = 2.3645e-03, PNorm = 56.8264, GNorm = 2.3556, lr_0 = 1.0804e-04
Loss = 2.8968e-03, PNorm = 56.8319, GNorm = 9.1548, lr_0 = 1.0804e-04
Loss = 2.7573e-03, PNorm = 56.8378, GNorm = 6.1816, lr_0 = 1.0804e-04
Loss = 3.4171e-03, PNorm = 56.8446, GNorm = 1.8934, lr_0 = 1.0804e-04
Loss = 2.8750e-03, PNorm = 56.8513, GNorm = 4.9091, lr_0 = 1.0804e-04
Loss = 3.2769e-03, PNorm = 56.8589, GNorm = 2.7310, lr_0 = 1.0804e-04
Validation rmse logD = 0.759185
Validation R2 logD = 0.639932
Epoch 26
Train function
Loss = 2.8889e-03, PNorm = 56.8660, GNorm = 10.4131, lr_0 = 1.0804e-04
Loss = 2.8746e-03, PNorm = 56.8722, GNorm = 6.5038, lr_0 = 1.0804e-04
Loss = 2.8719e-03, PNorm = 56.8800, GNorm = 6.7846, lr_0 = 1.0804e-04
Loss = 2.5362e-03, PNorm = 56.8869, GNorm = 2.8868, lr_0 = 1.0804e-04
Loss = 2.6049e-03, PNorm = 56.8942, GNorm = 1.5608, lr_0 = 1.0804e-04
Validation rmse logD = 0.750778
Validation R2 logD = 0.647862
Epoch 27
Train function
Loss = 2.2907e-03, PNorm = 56.9009, GNorm = 5.5628, lr_0 = 1.0804e-04
Loss = 2.3319e-03, PNorm = 56.9062, GNorm = 2.9534, lr_0 = 1.0804e-04
Loss = 2.1488e-03, PNorm = 56.9140, GNorm = 7.5112, lr_0 = 1.0804e-04
Loss = 2.4527e-03, PNorm = 56.9197, GNorm = 4.0096, lr_0 = 1.0804e-04
Loss = 2.6765e-03, PNorm = 56.9252, GNorm = 1.8647, lr_0 = 1.0804e-04
Loss = 2.7850e-03, PNorm = 56.9314, GNorm = 2.6996, lr_0 = 1.0804e-04
Validation rmse logD = 0.735693
Validation R2 logD = 0.661870
Epoch 28
Train function
Loss = 3.0959e-03, PNorm = 56.9375, GNorm = 3.3707, lr_0 = 1.0804e-04
Loss = 2.5602e-03, PNorm = 56.9459, GNorm = 3.6599, lr_0 = 1.0804e-04
Loss = 2.3702e-03, PNorm = 56.9531, GNorm = 2.2589, lr_0 = 1.0804e-04
Loss = 2.4223e-03, PNorm = 56.9599, GNorm = 2.1129, lr_0 = 1.0804e-04
Loss = 2.2709e-03, PNorm = 56.9653, GNorm = 1.5041, lr_0 = 1.0804e-04
Loss = 2.3681e-03, PNorm = 56.9711, GNorm = 3.2983, lr_0 = 1.0804e-04
Validation rmse logD = 0.735469
Validation R2 logD = 0.662076
Epoch 29
Train function
Loss = 2.0962e-03, PNorm = 56.9791, GNorm = 2.8198, lr_0 = 1.0804e-04
Loss = 2.2211e-03, PNorm = 56.9857, GNorm = 5.9790, lr_0 = 1.0804e-04
Loss = 2.3207e-03, PNorm = 56.9910, GNorm = 3.1971, lr_0 = 1.0804e-04
Loss = 1.9897e-03, PNorm = 56.9968, GNorm = 5.9860, lr_0 = 1.0804e-04
Loss = 2.5710e-03, PNorm = 57.0037, GNorm = 4.8729, lr_0 = 1.0804e-04
Validation rmse logD = 0.776495
Validation R2 logD = 0.623325
Epoch 30
Train function
Loss = 3.3378e-03, PNorm = 57.0115, GNorm = 10.7425, lr_0 = 1.0804e-04
Loss = 2.6068e-03, PNorm = 57.0192, GNorm = 1.4348, lr_0 = 1.0804e-04
Loss = 2.6186e-03, PNorm = 57.0257, GNorm = 3.6599, lr_0 = 1.0804e-04
Loss = 2.1207e-03, PNorm = 57.0321, GNorm = 3.8512, lr_0 = 1.0804e-04
Loss = 2.1214e-03, PNorm = 57.0389, GNorm = 2.4440, lr_0 = 1.0804e-04
Loss = 2.1079e-03, PNorm = 57.0466, GNorm = 5.2065, lr_0 = 1.0804e-04
Validation rmse logD = 0.743992
Validation R2 logD = 0.654198
Epoch 31
Train function
Loss = 2.0900e-03, PNorm = 57.0539, GNorm = 7.2694, lr_0 = 1.0804e-04
Loss = 1.9068e-03, PNorm = 57.0598, GNorm = 2.3662, lr_0 = 1.0804e-04
Loss = 2.3001e-03, PNorm = 57.0659, GNorm = 2.0249, lr_0 = 1.0804e-04
Loss = 2.0198e-03, PNorm = 57.0718, GNorm = 5.4259, lr_0 = 1.0804e-04
Loss = 2.0766e-03, PNorm = 57.0785, GNorm = 6.0895, lr_0 = 1.0804e-04
Loss = 2.0018e-03, PNorm = 57.0852, GNorm = 1.2983, lr_0 = 1.0804e-04
Validation rmse logD = 0.736703
Validation R2 logD = 0.660941
Epoch 32
Train function
Loss = 1.7256e-03, PNorm = 57.0910, GNorm = 2.5377, lr_0 = 1.0804e-04
Loss = 1.8411e-03, PNorm = 57.0981, GNorm = 3.5895, lr_0 = 1.0804e-04
Loss = 1.8841e-03, PNorm = 57.1033, GNorm = 2.4202, lr_0 = 1.0804e-04
Loss = 2.1070e-03, PNorm = 57.1101, GNorm = 1.9206, lr_0 = 1.0804e-04
Loss = 2.4333e-03, PNorm = 57.1162, GNorm = 9.2010, lr_0 = 1.0804e-04
Validation rmse logD = 0.756628
Validation R2 logD = 0.642353
Epoch 33
Train function
Loss = 1.9693e-03, PNorm = 57.1230, GNorm = 2.1325, lr_0 = 1.0804e-04
Loss = 1.9640e-03, PNorm = 57.1279, GNorm = 3.1981, lr_0 = 1.0804e-04
Loss = 1.7495e-03, PNorm = 57.1330, GNorm = 1.8383, lr_0 = 1.0804e-04
Loss = 2.0260e-03, PNorm = 57.1387, GNorm = 2.0317, lr_0 = 1.0804e-04
Loss = 1.8130e-03, PNorm = 57.1472, GNorm = 3.9835, lr_0 = 1.0804e-04
Loss = 2.0184e-03, PNorm = 57.1520, GNorm = 3.0311, lr_0 = 1.0804e-04
Validation rmse logD = 0.714246
Validation R2 logD = 0.681297
Epoch 34
Train function
Loss = 1.7576e-03, PNorm = 57.1581, GNorm = 1.3342, lr_0 = 1.0804e-04
Loss = 1.7514e-03, PNorm = 57.1639, GNorm = 7.8157, lr_0 = 1.0804e-04
Loss = 2.4892e-03, PNorm = 57.1695, GNorm = 4.9472, lr_0 = 1.0804e-04
Loss = 2.2861e-03, PNorm = 57.1755, GNorm = 3.4110, lr_0 = 1.0804e-04
Loss = 2.1081e-03, PNorm = 57.1817, GNorm = 2.4768, lr_0 = 1.0804e-04
Loss = 1.9932e-03, PNorm = 57.1891, GNorm = 5.3740, lr_0 = 1.0804e-04
Validation rmse logD = 0.746315
Validation R2 logD = 0.652036
Epoch 35
Train function
Loss = 2.1542e-03, PNorm = 57.1947, GNorm = 9.4890, lr_0 = 1.0804e-04
Loss = 2.3781e-03, PNorm = 57.1985, GNorm = 8.5957, lr_0 = 1.0804e-04
Loss = 1.8976e-03, PNorm = 57.2054, GNorm = 1.4637, lr_0 = 1.0804e-04
Loss = 1.8023e-03, PNorm = 57.2132, GNorm = 5.4371, lr_0 = 1.0804e-04
Loss = 2.2527e-03, PNorm = 57.2209, GNorm = 2.6187, lr_0 = 1.0804e-04
Validation rmse logD = 0.732098
Validation R2 logD = 0.665167
Epoch 36
Train function
Loss = 1.8006e-03, PNorm = 57.2277, GNorm = 1.6303, lr_0 = 1.0804e-04
Loss = 1.5001e-03, PNorm = 57.2343, GNorm = 1.5063, lr_0 = 1.0804e-04
Loss = 1.5915e-03, PNorm = 57.2388, GNorm = 1.9817, lr_0 = 1.0804e-04
Loss = 1.6245e-03, PNorm = 57.2445, GNorm = 1.5119, lr_0 = 1.0804e-04
Loss = 1.7192e-03, PNorm = 57.2501, GNorm = 4.1242, lr_0 = 1.0804e-04
Loss = 1.8445e-03, PNorm = 57.2567, GNorm = 2.2755, lr_0 = 1.0804e-04
Validation rmse logD = 0.719831
Validation R2 logD = 0.676293
Epoch 37
Train function
Loss = 1.5173e-03, PNorm = 57.2637, GNorm = 1.6443, lr_0 = 1.0804e-04
Loss = 1.7066e-03, PNorm = 57.2700, GNorm = 1.7894, lr_0 = 1.0804e-04
Loss = 1.9152e-03, PNorm = 57.2755, GNorm = 6.9155, lr_0 = 1.0804e-04
Loss = 2.1160e-03, PNorm = 57.2833, GNorm = 5.2075, lr_0 = 1.0804e-04
Loss = 1.6306e-03, PNorm = 57.2901, GNorm = 1.4691, lr_0 = 1.0804e-04
Loss = 1.6573e-03, PNorm = 57.2948, GNorm = 2.9321, lr_0 = 1.0804e-04
Validation rmse logD = 0.731038
Validation R2 logD = 0.666136
Epoch 38
Train function
Loss = 1.2893e-03, PNorm = 57.3016, GNorm = 1.4294, lr_0 = 1.0804e-04
Loss = 1.3759e-03, PNorm = 57.3077, GNorm = 4.1885, lr_0 = 1.0804e-04
Loss = 1.5393e-03, PNorm = 57.3128, GNorm = 1.7912, lr_0 = 1.0804e-04
Loss = 1.3596e-03, PNorm = 57.3184, GNorm = 2.5541, lr_0 = 1.0804e-04
Loss = 1.7057e-03, PNorm = 57.3250, GNorm = 3.8179, lr_0 = 1.0804e-04
Validation rmse logD = 0.717682
Validation R2 logD = 0.678224
Epoch 39
Train function
Loss = 1.6475e-03, PNorm = 57.3294, GNorm = 2.3647, lr_0 = 1.0804e-04
Loss = 1.5658e-03, PNorm = 57.3334, GNorm = 3.2629, lr_0 = 1.0804e-04
Loss = 1.6562e-03, PNorm = 57.3389, GNorm = 6.9553, lr_0 = 1.0804e-04
Loss = 1.4343e-03, PNorm = 57.3472, GNorm = 2.9155, lr_0 = 1.0804e-04
Loss = 1.5824e-03, PNorm = 57.3524, GNorm = 3.8900, lr_0 = 1.0804e-04
Loss = 1.5906e-03, PNorm = 57.3566, GNorm = 1.5661, lr_0 = 1.0804e-04
Validation rmse logD = 0.722055
Validation R2 logD = 0.674291
Epoch 40
Train function
Loss = 1.4602e-03, PNorm = 57.3620, GNorm = 6.5971, lr_0 = 1.0804e-04
Loss = 1.5292e-03, PNorm = 57.3676, GNorm = 5.3326, lr_0 = 1.0804e-04
Loss = 1.4007e-03, PNorm = 57.3741, GNorm = 2.0174, lr_0 = 1.0804e-04
Loss = 1.5207e-03, PNorm = 57.3812, GNorm = 2.6632, lr_0 = 1.0804e-04
Loss = 1.4280e-03, PNorm = 57.3857, GNorm = 3.1225, lr_0 = 1.0804e-04
Loss = 1.8135e-03, PNorm = 57.3904, GNorm = 1.7354, lr_0 = 1.0804e-04
Validation rmse logD = 0.749958
Validation R2 logD = 0.648631
Epoch 41
Train function
Loss = 1.6284e-03, PNorm = 57.3973, GNorm = 3.7957, lr_0 = 1.0804e-04
Loss = 1.4474e-03, PNorm = 57.4034, GNorm = 4.5356, lr_0 = 1.0804e-04
Loss = 1.5879e-03, PNorm = 57.4077, GNorm = 2.2881, lr_0 = 1.0804e-04
Loss = 1.3167e-03, PNorm = 57.4134, GNorm = 1.8263, lr_0 = 1.0804e-04
Loss = 1.1333e-03, PNorm = 57.4191, GNorm = 1.6050, lr_0 = 1.0804e-04
Validation rmse logD = 0.717192
Validation R2 logD = 0.678663
Epoch 42
Train function
Loss = 9.0608e-04, PNorm = 57.4249, GNorm = 3.5459, lr_0 = 1.0804e-04
Loss = 1.4299e-03, PNorm = 57.4312, GNorm = 7.7909, lr_0 = 1.0804e-04
Loss = 1.6821e-03, PNorm = 57.4370, GNorm = 7.4749, lr_0 = 1.0804e-04
Loss = 1.7525e-03, PNorm = 57.4420, GNorm = 7.4902, lr_0 = 1.0804e-04
Loss = 1.5746e-03, PNorm = 57.4488, GNorm = 2.4503, lr_0 = 1.0804e-04
Loss = 1.3475e-03, PNorm = 57.4530, GNorm = 4.8573, lr_0 = 1.0804e-04
Validation rmse logD = 0.707394
Validation R2 logD = 0.687383
Epoch 43
Train function
Loss = 1.1373e-03, PNorm = 57.4579, GNorm = 3.5301, lr_0 = 1.0804e-04
Loss = 1.1087e-03, PNorm = 57.4633, GNorm = 4.9296, lr_0 = 1.0804e-04
Loss = 1.6768e-03, PNorm = 57.4677, GNorm = 7.6155, lr_0 = 1.0804e-04
Loss = 1.4023e-03, PNorm = 57.4733, GNorm = 4.2059, lr_0 = 1.0804e-04
Loss = 1.2457e-03, PNorm = 57.4785, GNorm = 1.3041, lr_0 = 1.0804e-04
Loss = 1.3922e-03, PNorm = 57.4854, GNorm = 1.8043, lr_0 = 1.0804e-04
Validation rmse logD = 0.751204
Validation R2 logD = 0.647463
Epoch 44
Train function
Loss = 1.7328e-03, PNorm = 57.4907, GNorm = 6.0547, lr_0 = 1.0804e-04
Loss = 1.6533e-03, PNorm = 57.4937, GNorm = 7.0279, lr_0 = 1.0804e-04
Loss = 1.5490e-03, PNorm = 57.4991, GNorm = 1.2374, lr_0 = 1.0804e-04
Loss = 1.5447e-03, PNorm = 57.5059, GNorm = 1.7619, lr_0 = 1.0804e-04
Loss = 1.1317e-03, PNorm = 57.5109, GNorm = 3.9143, lr_0 = 1.0804e-04
Validation rmse logD = 0.729305
Validation R2 logD = 0.667717
Epoch 45
Train function
Loss = 1.7012e-03, PNorm = 57.5174, GNorm = 7.2717, lr_0 = 1.0804e-04
Loss = 1.2274e-03, PNorm = 57.5238, GNorm = 1.4192, lr_0 = 1.0804e-04
Loss = 1.1385e-03, PNorm = 57.5303, GNorm = 1.9608, lr_0 = 1.0804e-04
Loss = 1.2412e-03, PNorm = 57.5345, GNorm = 1.0803, lr_0 = 1.0804e-04
Loss = 1.1317e-03, PNorm = 57.5385, GNorm = 1.7478, lr_0 = 1.0804e-04
Loss = 1.0845e-03, PNorm = 57.5436, GNorm = 3.9735, lr_0 = 1.0804e-04
Validation rmse logD = 0.720864
Validation R2 logD = 0.675364
Epoch 46
Train function
Loss = 9.8946e-04, PNorm = 57.5485, GNorm = 1.5705, lr_0 = 1.0804e-04
Loss = 1.3427e-03, PNorm = 57.5524, GNorm = 4.1720, lr_0 = 1.0804e-04
Loss = 1.1860e-03, PNorm = 57.5568, GNorm = 1.9287, lr_0 = 1.0804e-04
Loss = 1.1903e-03, PNorm = 57.5615, GNorm = 1.7179, lr_0 = 1.0804e-04
Loss = 1.2340e-03, PNorm = 57.5664, GNorm = 5.5619, lr_0 = 1.0804e-04
Loss = 1.1219e-03, PNorm = 57.5733, GNorm = 4.2823, lr_0 = 1.0804e-04
Validation rmse logD = 0.712125
Validation R2 logD = 0.683187
Epoch 47
Train function
Loss = 9.4064e-04, PNorm = 57.5790, GNorm = 2.1933, lr_0 = 1.0804e-04
Loss = 9.9431e-04, PNorm = 57.5841, GNorm = 1.9419, lr_0 = 1.0804e-04
Loss = 9.7277e-04, PNorm = 57.5907, GNorm = 2.0006, lr_0 = 1.0804e-04
Loss = 1.1935e-03, PNorm = 57.5954, GNorm = 2.5213, lr_0 = 1.0804e-04
Loss = 1.2427e-03, PNorm = 57.5995, GNorm = 5.0828, lr_0 = 1.0804e-04
Validation rmse logD = 0.702713
Validation R2 logD = 0.691507
Epoch 48
Train function
Loss = 6.5105e-04, PNorm = 57.6038, GNorm = 2.9409, lr_0 = 1.0804e-04
Loss = 9.8514e-04, PNorm = 57.6087, GNorm = 1.3913, lr_0 = 1.0804e-04
Loss = 1.2991e-03, PNorm = 57.6135, GNorm = 2.5457, lr_0 = 1.0804e-04
Loss = 1.2944e-03, PNorm = 57.6198, GNorm = 1.4824, lr_0 = 1.0804e-04
Loss = 1.1363e-03, PNorm = 57.6254, GNorm = 1.7431, lr_0 = 1.0804e-04
Loss = 1.0115e-03, PNorm = 57.6300, GNorm = 1.8922, lr_0 = 1.0804e-04
Validation rmse logD = 0.735109
Validation R2 logD = 0.662407
Epoch 49
Train function
Loss = 1.1257e-03, PNorm = 57.6348, GNorm = 5.0326, lr_0 = 1.0804e-04
Loss = 1.1312e-03, PNorm = 57.6386, GNorm = 9.4664, lr_0 = 1.0804e-04
Loss = 1.1940e-03, PNorm = 57.6434, GNorm = 6.8147, lr_0 = 1.0804e-04
Loss = 1.3490e-03, PNorm = 57.6487, GNorm = 1.4037, lr_0 = 1.0804e-04
Loss = 1.0828e-03, PNorm = 57.6533, GNorm = 5.4320, lr_0 = 1.0804e-04
Loss = 1.3162e-03, PNorm = 57.6583, GNorm = 4.4059, lr_0 = 1.0804e-04
Validation rmse logD = 0.725618
Validation R2 logD = 0.671068
Epoch 50
Train function
Loss = 7.9327e-04, PNorm = 57.6633, GNorm = 1.9633, lr_0 = 1.0804e-04
Loss = 8.8477e-04, PNorm = 57.6686, GNorm = 1.2460, lr_0 = 1.0804e-04
Loss = 1.0148e-03, PNorm = 57.6737, GNorm = 2.8588, lr_0 = 1.0804e-04
Loss = 1.0311e-03, PNorm = 57.6783, GNorm = 2.7177, lr_0 = 1.0804e-04
Loss = 1.0024e-03, PNorm = 57.6829, GNorm = 7.4892, lr_0 = 1.0804e-04
Validation rmse logD = 0.698415
Validation R2 logD = 0.695269
Epoch 51
Train function
Loss = 6.9801e-04, PNorm = 57.6878, GNorm = 2.4063, lr_0 = 1.0804e-04
Loss = 9.3076e-04, PNorm = 57.6920, GNorm = 4.0963, lr_0 = 1.0804e-04
Loss = 9.7138e-04, PNorm = 57.6968, GNorm = 7.4008, lr_0 = 1.0804e-04
Loss = 8.9033e-04, PNorm = 57.7016, GNorm = 1.8241, lr_0 = 1.0804e-04
Loss = 8.2190e-04, PNorm = 57.7065, GNorm = 2.2407, lr_0 = 1.0804e-04
Loss = 1.0934e-03, PNorm = 57.7117, GNorm = 4.8900, lr_0 = 1.0804e-04
Validation rmse logD = 0.742624
Validation R2 logD = 0.655469
Epoch 52
Train function
Loss = 8.5485e-04, PNorm = 57.7177, GNorm = 4.0716, lr_0 = 1.0804e-04
Loss = 9.2030e-04, PNorm = 57.7221, GNorm = 1.3271, lr_0 = 1.0804e-04
Loss = 1.0032e-03, PNorm = 57.7257, GNorm = 1.7981, lr_0 = 1.0804e-04
Loss = 8.3386e-04, PNorm = 57.7298, GNorm = 2.5706, lr_0 = 1.0804e-04
Loss = 9.3189e-04, PNorm = 57.7344, GNorm = 1.3747, lr_0 = 1.0804e-04
Loss = 1.0473e-03, PNorm = 57.7395, GNorm = 4.8236, lr_0 = 1.0804e-04
Validation rmse logD = 0.709876
Validation R2 logD = 0.685185
Epoch 53
Train function
Loss = 9.0455e-04, PNorm = 57.7455, GNorm = 6.4724, lr_0 = 1.0804e-04
Loss = 9.9941e-04, PNorm = 57.7490, GNorm = 2.5031, lr_0 = 1.0804e-04
Loss = 1.0022e-03, PNorm = 57.7538, GNorm = 3.9294, lr_0 = 1.0804e-04
Loss = 1.1925e-03, PNorm = 57.7591, GNorm = 8.3513, lr_0 = 1.0804e-04
Loss = 1.2378e-03, PNorm = 57.7623, GNorm = 5.8556, lr_0 = 1.0804e-04
Validation rmse logD = 0.713604
Validation R2 logD = 0.681870
Epoch 54
Train function
Loss = 1.0190e-03, PNorm = 57.7674, GNorm = 1.3761, lr_0 = 1.0804e-04
Loss = 9.5689e-04, PNorm = 57.7725, GNorm = 0.8136, lr_0 = 1.0804e-04
Loss = 1.0665e-03, PNorm = 57.7772, GNorm = 6.3744, lr_0 = 1.0804e-04
Loss = 1.0697e-03, PNorm = 57.7807, GNorm = 7.0153, lr_0 = 1.0804e-04
Loss = 1.5827e-03, PNorm = 57.7847, GNorm = 10.7980, lr_0 = 1.0804e-04
Loss = 1.5465e-03, PNorm = 57.7893, GNorm = 1.8598, lr_0 = 1.0804e-04
Validation rmse logD = 0.725882
Validation R2 logD = 0.670828
Epoch 55
Train function
Loss = 1.1651e-03, PNorm = 57.7950, GNorm = 6.1722, lr_0 = 1.0804e-04
Loss = 9.7897e-04, PNorm = 57.7994, GNorm = 1.9655, lr_0 = 1.0804e-04
Loss = 9.5102e-04, PNorm = 57.8054, GNorm = 4.1652, lr_0 = 1.0804e-04
Loss = 9.3636e-04, PNorm = 57.8100, GNorm = 2.8207, lr_0 = 1.0804e-04
Loss = 8.6566e-04, PNorm = 57.8144, GNorm = 2.4627, lr_0 = 1.0804e-04
Loss = 9.1172e-04, PNorm = 57.8191, GNorm = 1.4452, lr_0 = 1.0804e-04
Validation rmse logD = 0.711751
Validation R2 logD = 0.683520
Epoch 56
Train function
Loss = 6.9998e-04, PNorm = 57.8241, GNorm = 1.9189, lr_0 = 1.0804e-04
Loss = 7.3913e-04, PNorm = 57.8291, GNorm = 4.8046, lr_0 = 1.0804e-04
Loss = 7.4999e-04, PNorm = 57.8324, GNorm = 3.0012, lr_0 = 1.0804e-04
Loss = 9.1262e-04, PNorm = 57.8359, GNorm = 1.3758, lr_0 = 1.0804e-04
Loss = 8.4950e-04, PNorm = 57.8390, GNorm = 1.4756, lr_0 = 1.0804e-04
Validation rmse logD = 0.704966
Validation R2 logD = 0.689526
Epoch 57
Train function
Loss = 7.7305e-04, PNorm = 57.8434, GNorm = 0.9629, lr_0 = 1.0804e-04
Loss = 7.0231e-04, PNorm = 57.8467, GNorm = 6.1136, lr_0 = 1.0804e-04
Loss = 6.8096e-04, PNorm = 57.8501, GNorm = 4.7260, lr_0 = 1.0804e-04
Loss = 8.2471e-04, PNorm = 57.8545, GNorm = 3.1609, lr_0 = 1.0804e-04
Loss = 7.1234e-04, PNorm = 57.8584, GNorm = 2.2874, lr_0 = 1.0804e-04
Loss = 8.6796e-04, PNorm = 57.8620, GNorm = 2.7434, lr_0 = 1.0804e-04
Validation rmse logD = 0.709802
Validation R2 logD = 0.685251
Epoch 58
Train function
Loss = 7.7589e-04, PNorm = 57.8664, GNorm = 3.7591, lr_0 = 1.0804e-04
Loss = 1.0118e-03, PNorm = 57.8711, GNorm = 2.5562, lr_0 = 1.0804e-04
Loss = 1.0840e-03, PNorm = 57.8756, GNorm = 6.9927, lr_0 = 1.0804e-04
Loss = 1.3325e-03, PNorm = 57.8809, GNorm = 11.0342, lr_0 = 1.0804e-04
Loss = 1.1834e-03, PNorm = 57.8844, GNorm = 7.4764, lr_0 = 1.0804e-04
Loss = 1.0568e-03, PNorm = 57.8905, GNorm = 1.7809, lr_0 = 1.0804e-04
Validation rmse logD = 0.711617
Validation R2 logD = 0.683639
Epoch 59
Train function
Loss = 6.3315e-04, PNorm = 57.8967, GNorm = 1.5397, lr_0 = 1.0804e-04
Loss = 8.3653e-04, PNorm = 57.9013, GNorm = 3.7907, lr_0 = 1.0804e-04
Loss = 9.1443e-04, PNorm = 57.9042, GNorm = 5.3356, lr_0 = 1.0804e-04
Loss = 1.2742e-03, PNorm = 57.9076, GNorm = 7.1257, lr_0 = 1.0804e-04
Loss = 8.7353e-04, PNorm = 57.9116, GNorm = 3.7522, lr_0 = 1.0804e-04
Validation rmse logD = 0.710169
Validation R2 logD = 0.684926
Epoch 60
Train function
Loss = 8.1615e-04, PNorm = 57.9154, GNorm = 4.4223, lr_0 = 1.0804e-04
Loss = 6.4702e-04, PNorm = 57.9190, GNorm = 2.8054, lr_0 = 1.0804e-04
Loss = 6.4261e-04, PNorm = 57.9236, GNorm = 2.0259, lr_0 = 1.0804e-04
Loss = 7.6325e-04, PNorm = 57.9279, GNorm = 4.2511, lr_0 = 1.0804e-04
Loss = 8.6040e-04, PNorm = 57.9313, GNorm = 2.4458, lr_0 = 1.0804e-04
Loss = 7.6264e-04, PNorm = 57.9356, GNorm = 2.9457, lr_0 = 1.0804e-04
Validation rmse logD = 0.704371
Validation R2 logD = 0.690049
Epoch 61
Train function
Loss = 8.6364e-04, PNorm = 57.9398, GNorm = 7.3344, lr_0 = 1.0804e-04
Loss = 1.1373e-03, PNorm = 57.9427, GNorm = 4.9105, lr_0 = 1.0804e-04
Loss = 7.6168e-04, PNorm = 57.9476, GNorm = 1.0588, lr_0 = 1.0804e-04
Loss = 9.0071e-04, PNorm = 57.9516, GNorm = 2.7241, lr_0 = 1.0804e-04
Loss = 9.8583e-04, PNorm = 57.9563, GNorm = 4.5952, lr_0 = 1.0804e-04
Loss = 1.0121e-03, PNorm = 57.9619, GNorm = 2.1197, lr_0 = 1.0804e-04
Validation rmse logD = 0.718890
Validation R2 logD = 0.677140
Epoch 62
Train function
Loss = 5.5730e-04, PNorm = 57.9672, GNorm = 1.0386, lr_0 = 1.0804e-04
Loss = 6.1346e-04, PNorm = 57.9711, GNorm = 1.0844, lr_0 = 1.0804e-04
Loss = 6.0358e-04, PNorm = 57.9747, GNorm = 3.4314, lr_0 = 1.0804e-04
Loss = 8.4667e-04, PNorm = 57.9781, GNorm = 4.5776, lr_0 = 1.0804e-04
Loss = 9.1543e-04, PNorm = 57.9823, GNorm = 2.9529, lr_0 = 1.0804e-04
Validation rmse logD = 0.691968
Validation R2 logD = 0.700868
Epoch 63
Train function
Loss = 5.7966e-04, PNorm = 57.9860, GNorm = 1.3660, lr_0 = 1.0804e-04
Loss = 7.8414e-04, PNorm = 57.9901, GNorm = 1.3701, lr_0 = 1.0804e-04
Loss = 5.5790e-04, PNorm = 57.9953, GNorm = 2.2930, lr_0 = 1.0804e-04
Loss = 6.5010e-04, PNorm = 57.9989, GNorm = 3.7585, lr_0 = 1.0804e-04
Loss = 6.4931e-04, PNorm = 58.0021, GNorm = 3.1030, lr_0 = 1.0804e-04
Loss = 7.6290e-04, PNorm = 58.0060, GNorm = 1.5910, lr_0 = 1.0804e-04
Validation rmse logD = 0.704606
Validation R2 logD = 0.689842
Epoch 64
Train function
Loss = 6.8682e-04, PNorm = 58.0097, GNorm = 2.4579, lr_0 = 1.0804e-04
Loss = 6.8495e-04, PNorm = 58.0126, GNorm = 2.6759, lr_0 = 1.0804e-04
Loss = 7.4295e-04, PNorm = 58.0159, GNorm = 1.8955, lr_0 = 1.0804e-04
Loss = 8.0399e-04, PNorm = 58.0205, GNorm = 2.5256, lr_0 = 1.0804e-04
Loss = 7.9373e-04, PNorm = 58.0239, GNorm = 4.9032, lr_0 = 1.0804e-04
Loss = 7.6381e-04, PNorm = 58.0291, GNorm = 2.5623, lr_0 = 1.0804e-04
Validation rmse logD = 0.712203
Validation R2 logD = 0.683118
Epoch 65
Train function
Loss = 6.6734e-04, PNorm = 58.0333, GNorm = 1.7472, lr_0 = 1.0804e-04
Loss = 7.5852e-04, PNorm = 58.0374, GNorm = 2.5367, lr_0 = 1.0804e-04
Loss = 6.8835e-04, PNorm = 58.0415, GNorm = 1.2599, lr_0 = 1.0804e-04
Loss = 5.8915e-04, PNorm = 58.0454, GNorm = 3.7992, lr_0 = 1.0804e-04
Loss = 5.4643e-04, PNorm = 58.0489, GNorm = 1.4594, lr_0 = 1.0804e-04
Validation rmse logD = 0.702943
Validation R2 logD = 0.691305
Epoch 66
Train function
Loss = 4.5018e-04, PNorm = 58.0514, GNorm = 2.0538, lr_0 = 1.0804e-04
Loss = 6.7398e-04, PNorm = 58.0549, GNorm = 2.9484, lr_0 = 1.0804e-04
Loss = 6.1470e-04, PNorm = 58.0593, GNorm = 1.4195, lr_0 = 1.0804e-04
Loss = 5.5248e-04, PNorm = 58.0619, GNorm = 2.3962, lr_0 = 1.0804e-04
Loss = 5.3478e-04, PNorm = 58.0657, GNorm = 2.1685, lr_0 = 1.0804e-04
Loss = 5.8656e-04, PNorm = 58.0695, GNorm = 4.3941, lr_0 = 1.0804e-04
Validation rmse logD = 0.703873
Validation R2 logD = 0.690487
Epoch 67
Train function
Loss = 4.4432e-04, PNorm = 58.0719, GNorm = 1.0657, lr_0 = 1.0804e-04
Loss = 4.5974e-04, PNorm = 58.0755, GNorm = 0.8416, lr_0 = 1.0804e-04
Loss = 6.1200e-04, PNorm = 58.0788, GNorm = 1.4314, lr_0 = 1.0804e-04
Loss = 5.1878e-04, PNorm = 58.0818, GNorm = 2.3636, lr_0 = 1.0804e-04
Loss = 5.7090e-04, PNorm = 58.0849, GNorm = 5.5765, lr_0 = 1.0804e-04
Loss = 6.7636e-04, PNorm = 58.0887, GNorm = 6.2575, lr_0 = 1.0804e-04
Validation rmse logD = 0.735757
Validation R2 logD = 0.661811
Epoch 68
Train function
Loss = 6.3288e-04, PNorm = 58.0930, GNorm = 3.0958, lr_0 = 1.0804e-04
Loss = 6.5098e-04, PNorm = 58.0966, GNorm = 6.5235, lr_0 = 1.0804e-04
Loss = 6.5221e-04, PNorm = 58.1006, GNorm = 1.1446, lr_0 = 1.0804e-04
Loss = 8.6571e-04, PNorm = 58.1027, GNorm = 3.9024, lr_0 = 1.0804e-04
Loss = 7.2465e-04, PNorm = 58.1068, GNorm = 2.2756, lr_0 = 1.0804e-04
Validation rmse logD = 0.714480
Validation R2 logD = 0.681089
Epoch 69
Train function
Loss = 3.4682e-04, PNorm = 58.1110, GNorm = 2.4530, lr_0 = 1.0804e-04
Loss = 7.4876e-04, PNorm = 58.1151, GNorm = 3.7604, lr_0 = 1.0804e-04
Loss = 7.4545e-04, PNorm = 58.1187, GNorm = 7.1189, lr_0 = 1.0804e-04
Loss = 8.7994e-04, PNorm = 58.1236, GNorm = 6.3795, lr_0 = 1.0804e-04
Loss = 6.0198e-04, PNorm = 58.1278, GNorm = 1.1564, lr_0 = 1.0804e-04
Loss = 6.1264e-04, PNorm = 58.1316, GNorm = 2.2400, lr_0 = 1.0804e-04
Validation rmse logD = 0.702498
Validation R2 logD = 0.691696
Epoch 70
Train function
Loss = 5.4678e-04, PNorm = 58.1354, GNorm = 1.9857, lr_0 = 1.0804e-04
Loss = 6.0425e-04, PNorm = 58.1385, GNorm = 3.6174, lr_0 = 1.0804e-04
Loss = 9.5720e-04, PNorm = 58.1409, GNorm = 6.4964, lr_0 = 1.0804e-04
Loss = 6.9817e-04, PNorm = 58.1446, GNorm = 1.8271, lr_0 = 1.0804e-04
Loss = 6.7817e-04, PNorm = 58.1471, GNorm = 4.2560, lr_0 = 1.0804e-04
Loss = 7.6485e-04, PNorm = 58.1489, GNorm = 1.0849, lr_0 = 1.0804e-04
Validation rmse logD = 0.712624
Validation R2 logD = 0.682743
Epoch 71
Train function
Loss = 6.6265e-04, PNorm = 58.1544, GNorm = 5.3467, lr_0 = 1.0804e-04
Loss = 6.0746e-04, PNorm = 58.1593, GNorm = 1.5309, lr_0 = 1.0804e-04
Loss = 8.2005e-04, PNorm = 58.1625, GNorm = 6.0517, lr_0 = 1.0804e-04
Loss = 8.5015e-04, PNorm = 58.1665, GNorm = 1.9571, lr_0 = 1.0804e-04
Loss = 5.5330e-04, PNorm = 58.1707, GNorm = 0.9294, lr_0 = 1.0804e-04
Validation rmse logD = 0.706496
Validation R2 logD = 0.688176
Epoch 72
Train function
Loss = 3.8689e-04, PNorm = 58.1752, GNorm = 1.5704, lr_0 = 1.0804e-04
Loss = 4.9238e-04, PNorm = 58.1785, GNorm = 0.8767, lr_0 = 1.0804e-04
Loss = 4.7969e-04, PNorm = 58.1805, GNorm = 1.7039, lr_0 = 1.0804e-04
Loss = 4.6165e-04, PNorm = 58.1834, GNorm = 1.0880, lr_0 = 1.0804e-04
Loss = 4.9176e-04, PNorm = 58.1876, GNorm = 3.4749, lr_0 = 1.0804e-04
Loss = 6.4048e-04, PNorm = 58.1912, GNorm = 1.4828, lr_0 = 1.0804e-04
Validation rmse logD = 0.702387
Validation R2 logD = 0.691793
Epoch 73
Train function
Loss = 4.6023e-04, PNorm = 58.1933, GNorm = 2.8794, lr_0 = 1.0804e-04
Loss = 6.1160e-04, PNorm = 58.1970, GNorm = 0.9172, lr_0 = 1.0804e-04
Loss = 5.8072e-04, PNorm = 58.1996, GNorm = 1.5953, lr_0 = 1.0804e-04
Loss = 4.9541e-04, PNorm = 58.2033, GNorm = 1.8991, lr_0 = 1.0804e-04
Loss = 5.8079e-04, PNorm = 58.2065, GNorm = 2.7401, lr_0 = 1.0804e-04
Loss = 9.4855e-04, PNorm = 58.2093, GNorm = 5.8503, lr_0 = 1.0804e-04
Validation rmse logD = 0.702768
Validation R2 logD = 0.691458
Epoch 74
Train function
Loss = 7.9307e-04, PNorm = 58.2138, GNorm = 2.0920, lr_0 = 1.0804e-04
Loss = 7.7288e-04, PNorm = 58.2173, GNorm = 3.0793, lr_0 = 1.0804e-04
Loss = 6.1172e-04, PNorm = 58.2227, GNorm = 1.2089, lr_0 = 1.0804e-04
Loss = 5.7201e-04, PNorm = 58.2277, GNorm = 2.3762, lr_0 = 1.0804e-04
Loss = 8.1750e-04, PNorm = 58.2316, GNorm = 6.3138, lr_0 = 1.0804e-04
Validation rmse logD = 0.714129
Validation R2 logD = 0.681402
Epoch 75
Train function
Loss = 8.6051e-04, PNorm = 58.2349, GNorm = 5.5647, lr_0 = 1.0804e-04
Loss = 7.4489e-04, PNorm = 58.2383, GNorm = 7.1239, lr_0 = 1.0804e-04
Loss = 5.3839e-04, PNorm = 58.2413, GNorm = 4.4703, lr_0 = 1.0804e-04
Loss = 5.5140e-04, PNorm = 58.2448, GNorm = 1.8320, lr_0 = 1.0804e-04
Loss = 5.1956e-04, PNorm = 58.2490, GNorm = 2.5858, lr_0 = 1.0804e-04
Loss = 5.6841e-04, PNorm = 58.2528, GNorm = 4.5567, lr_0 = 1.0804e-04
Validation rmse logD = 0.697754
Validation R2 logD = 0.695845
Epoch 76
Train function
Loss = 3.8402e-04, PNorm = 58.2558, GNorm = 0.9772, lr_0 = 1.0804e-04
Loss = 3.7568e-04, PNorm = 58.2586, GNorm = 1.4637, lr_0 = 1.0804e-04
Loss = 4.1686e-04, PNorm = 58.2623, GNorm = 2.2244, lr_0 = 1.0804e-04
Loss = 4.9281e-04, PNorm = 58.2653, GNorm = 0.9999, lr_0 = 1.0804e-04
Loss = 4.9247e-04, PNorm = 58.2689, GNorm = 4.1532, lr_0 = 1.0804e-04
Loss = 7.1121e-04, PNorm = 58.2704, GNorm = 5.4735, lr_0 = 1.0804e-04
Validation rmse logD = 0.690665
Validation R2 logD = 0.701994
Epoch 77
Train function
Loss = 6.4316e-04, PNorm = 58.2744, GNorm = 4.7540, lr_0 = 1.0804e-04
Loss = 5.1608e-04, PNorm = 58.2796, GNorm = 2.5918, lr_0 = 1.0804e-04
Loss = 6.3088e-04, PNorm = 58.2823, GNorm = 5.7858, lr_0 = 1.0804e-04
Loss = 6.2265e-04, PNorm = 58.2856, GNorm = 1.4538, lr_0 = 1.0804e-04
Loss = 6.7144e-04, PNorm = 58.2899, GNorm = 1.6864, lr_0 = 1.0804e-04
Validation rmse logD = 0.699918
Validation R2 logD = 0.693956
Epoch 78
Train function
Loss = 3.4452e-04, PNorm = 58.2926, GNorm = 0.9681, lr_0 = 1.0804e-04
Loss = 6.5179e-04, PNorm = 58.2958, GNorm = 1.5419, lr_0 = 1.0804e-04
Loss = 5.2896e-04, PNorm = 58.2992, GNorm = 1.7270, lr_0 = 1.0804e-04
Loss = 4.8469e-04, PNorm = 58.3032, GNorm = 1.8166, lr_0 = 1.0804e-04
Loss = 4.9937e-04, PNorm = 58.3068, GNorm = 2.9069, lr_0 = 1.0804e-04
Loss = 4.5825e-04, PNorm = 58.3110, GNorm = 1.1261, lr_0 = 1.0804e-04
Validation rmse logD = 0.708049
Validation R2 logD = 0.686803
Epoch 79
Train function
Loss = 6.9099e-04, PNorm = 58.3129, GNorm = 4.4474, lr_0 = 1.0804e-04
Loss = 4.9493e-04, PNorm = 58.3159, GNorm = 2.6588, lr_0 = 1.0804e-04
Loss = 3.4971e-04, PNorm = 58.3195, GNorm = 2.0674, lr_0 = 1.0804e-04
Loss = 4.6347e-04, PNorm = 58.3214, GNorm = 2.2428, lr_0 = 1.0804e-04
Loss = 6.3961e-04, PNorm = 58.3240, GNorm = 2.3297, lr_0 = 1.0804e-04
Loss = 6.1233e-04, PNorm = 58.3271, GNorm = 4.2556, lr_0 = 1.0804e-04
Validation rmse logD = 0.690188
Validation R2 logD = 0.702406
Epoch 80
Train function
Loss = 6.2198e-04, PNorm = 58.3301, GNorm = 1.8301, lr_0 = 1.0804e-04
Loss = 5.7022e-04, PNorm = 58.3341, GNorm = 3.2716, lr_0 = 1.0804e-04
Loss = 5.4866e-04, PNorm = 58.3374, GNorm = 3.2484, lr_0 = 1.0804e-04
Loss = 4.6091e-04, PNorm = 58.3412, GNorm = 3.0247, lr_0 = 1.0804e-04
Loss = 4.2773e-04, PNorm = 58.3443, GNorm = 1.9239, lr_0 = 1.0804e-04
Validation rmse logD = 0.708834
Validation R2 logD = 0.686109
Epoch 81
Train function
Loss = 2.9580e-04, PNorm = 58.3482, GNorm = 2.8959, lr_0 = 1.0804e-04
Loss = 4.1773e-04, PNorm = 58.3513, GNorm = 0.9954, lr_0 = 1.0804e-04
Loss = 3.4582e-04, PNorm = 58.3538, GNorm = 0.7493, lr_0 = 1.0804e-04
Loss = 3.8270e-04, PNorm = 58.3556, GNorm = 1.1218, lr_0 = 1.0804e-04
Loss = 4.2808e-04, PNorm = 58.3582, GNorm = 1.7589, lr_0 = 1.0804e-04
Loss = 3.9326e-04, PNorm = 58.3612, GNorm = 2.7946, lr_0 = 1.0804e-04
Validation rmse logD = 0.695758
Validation R2 logD = 0.697583
Epoch 82
Train function
Loss = 2.3067e-04, PNorm = 58.3643, GNorm = 0.9294, lr_0 = 1.0804e-04
Loss = 3.4030e-04, PNorm = 58.3671, GNorm = 1.1641, lr_0 = 1.0804e-04
Loss = 4.2499e-04, PNorm = 58.3694, GNorm = 0.9143, lr_0 = 1.0804e-04
Loss = 3.5958e-04, PNorm = 58.3721, GNorm = 1.7914, lr_0 = 1.0804e-04
Loss = 4.2636e-04, PNorm = 58.3753, GNorm = 1.9578, lr_0 = 1.0804e-04
Loss = 2.9654e-04, PNorm = 58.3784, GNorm = 0.9017, lr_0 = 1.0804e-04
Validation rmse logD = 0.695005
Validation R2 logD = 0.698237
Epoch 83
Train function
Loss = 3.3685e-04, PNorm = 58.3807, GNorm = 1.8060, lr_0 = 1.0804e-04
Loss = 3.4496e-04, PNorm = 58.3822, GNorm = 2.4090, lr_0 = 1.0804e-04
Loss = 3.3428e-04, PNorm = 58.3843, GNorm = 1.6402, lr_0 = 1.0804e-04
Loss = 3.3706e-04, PNorm = 58.3876, GNorm = 2.2358, lr_0 = 1.0804e-04
Loss = 3.4856e-04, PNorm = 58.3906, GNorm = 1.6182, lr_0 = 1.0804e-04
Validation rmse logD = 0.701487
Validation R2 logD = 0.692582
Epoch 84
Train function
Loss = 2.9701e-04, PNorm = 58.3936, GNorm = 1.2259, lr_0 = 1.0804e-04
Loss = 2.8623e-04, PNorm = 58.3967, GNorm = 4.3150, lr_0 = 1.0804e-04
Loss = 6.1954e-04, PNorm = 58.3985, GNorm = 2.2020, lr_0 = 1.0804e-04
Loss = 7.5974e-04, PNorm = 58.4014, GNorm = 4.8573, lr_0 = 1.0804e-04
Loss = 4.5000e-04, PNorm = 58.4055, GNorm = 1.0324, lr_0 = 1.0804e-04
Loss = 7.0205e-04, PNorm = 58.4087, GNorm = 3.3181, lr_0 = 1.0804e-04
Validation rmse logD = 0.714265
Validation R2 logD = 0.681280
Epoch 85
Train function
Loss = 4.6968e-04, PNorm = 58.4129, GNorm = 1.1468, lr_0 = 1.0804e-04
Loss = 5.8591e-04, PNorm = 58.4158, GNorm = 6.5522, lr_0 = 1.0804e-04
Loss = 4.8795e-04, PNorm = 58.4180, GNorm = 3.6303, lr_0 = 1.0804e-04
Loss = 5.1713e-04, PNorm = 58.4207, GNorm = 1.6985, lr_0 = 1.0804e-04
Loss = 3.7615e-04, PNorm = 58.4248, GNorm = 2.0524, lr_0 = 1.0804e-04
Loss = 3.4724e-04, PNorm = 58.4278, GNorm = 1.2895, lr_0 = 1.0804e-04
Validation rmse logD = 0.696678
Validation R2 logD = 0.696783
Epoch 86
Train function
Loss = 3.7266e-04, PNorm = 58.4306, GNorm = 1.5362, lr_0 = 1.0804e-04
Loss = 4.0616e-04, PNorm = 58.4335, GNorm = 1.5194, lr_0 = 1.0804e-04
Loss = 3.4982e-04, PNorm = 58.4360, GNorm = 2.3008, lr_0 = 1.0804e-04
Loss = 3.1291e-04, PNorm = 58.4382, GNorm = 2.0044, lr_0 = 1.0804e-04
Loss = 3.3443e-04, PNorm = 58.4414, GNorm = 0.9770, lr_0 = 1.0804e-04
Validation rmse logD = 0.693818
Validation R2 logD = 0.699267
Epoch 87
Train function
Loss = 2.9577e-04, PNorm = 58.4447, GNorm = 1.3801, lr_0 = 1.0804e-04
Loss = 3.8243e-04, PNorm = 58.4476, GNorm = 1.5956, lr_0 = 1.0804e-04
Loss = 3.5826e-04, PNorm = 58.4502, GNorm = 3.3501, lr_0 = 1.0804e-04
Loss = 4.0664e-04, PNorm = 58.4534, GNorm = 1.3278, lr_0 = 1.0804e-04
Loss = 3.7007e-04, PNorm = 58.4562, GNorm = 1.3263, lr_0 = 1.0804e-04
Loss = 4.0886e-04, PNorm = 58.4590, GNorm = 2.0633, lr_0 = 1.0804e-04
Validation rmse logD = 0.714794
Validation R2 logD = 0.680808
Epoch 88
Train function
Loss = 3.3239e-04, PNorm = 58.4605, GNorm = 1.9836, lr_0 = 1.0804e-04
Loss = 4.1751e-04, PNorm = 58.4632, GNorm = 1.2960, lr_0 = 1.0804e-04
Loss = 2.9850e-04, PNorm = 58.4661, GNorm = 1.7391, lr_0 = 1.0804e-04
Loss = 3.9174e-04, PNorm = 58.4691, GNorm = 2.0208, lr_0 = 1.0804e-04
Loss = 3.9040e-04, PNorm = 58.4719, GNorm = 1.8040, lr_0 = 1.0804e-04
Loss = 3.9786e-04, PNorm = 58.4743, GNorm = 1.2084, lr_0 = 1.0804e-04
Validation rmse logD = 0.722844
Validation R2 logD = 0.673579
Epoch 89
Train function
Loss = 4.3859e-04, PNorm = 58.4761, GNorm = 1.5160, lr_0 = 1.0804e-04
Loss = 3.4922e-04, PNorm = 58.4798, GNorm = 1.0203, lr_0 = 1.0804e-04
Loss = 3.2228e-04, PNorm = 58.4825, GNorm = 0.6886, lr_0 = 1.0804e-04
Loss = 2.8843e-04, PNorm = 58.4847, GNorm = 1.7792, lr_0 = 1.0804e-04
Loss = 3.3672e-04, PNorm = 58.4872, GNorm = 2.0422, lr_0 = 1.0804e-04
Validation rmse logD = 0.696789
Validation R2 logD = 0.696686
Epoch 90
Train function
Loss = 4.5333e-04, PNorm = 58.4895, GNorm = 4.1708, lr_0 = 1.0804e-04
Loss = 3.3325e-04, PNorm = 58.4921, GNorm = 2.9669, lr_0 = 1.0804e-04
Loss = 4.3205e-04, PNorm = 58.4946, GNorm = 3.2619, lr_0 = 1.0804e-04
Loss = 3.3554e-04, PNorm = 58.4979, GNorm = 2.0986, lr_0 = 1.0804e-04
Loss = 3.4994e-04, PNorm = 58.5004, GNorm = 1.7464, lr_0 = 1.0804e-04
Loss = 3.7203e-04, PNorm = 58.5037, GNorm = 1.0891, lr_0 = 1.0804e-04
Validation rmse logD = 0.702778
Validation R2 logD = 0.691449
Epoch 91
Train function
Loss = 2.3435e-04, PNorm = 58.5066, GNorm = 0.7097, lr_0 = 1.0804e-04
Loss = 3.1802e-04, PNorm = 58.5084, GNorm = 2.2461, lr_0 = 1.0804e-04
Loss = 3.8681e-04, PNorm = 58.5111, GNorm = 0.7907, lr_0 = 1.0804e-04
Loss = 3.2145e-04, PNorm = 58.5146, GNorm = 2.2498, lr_0 = 1.0804e-04
Loss = 3.4684e-04, PNorm = 58.5170, GNorm = 1.5618, lr_0 = 1.0804e-04
Loss = 3.1865e-04, PNorm = 58.5204, GNorm = 2.5277, lr_0 = 1.0804e-04
Validation rmse logD = 0.702445
Validation R2 logD = 0.691742
Epoch 92
Train function
Loss = 3.1624e-04, PNorm = 58.5228, GNorm = 2.0546, lr_0 = 1.0804e-04
Loss = 3.7972e-04, PNorm = 58.5259, GNorm = 3.6599, lr_0 = 1.0804e-04
Loss = 5.3237e-04, PNorm = 58.5282, GNorm = 6.7057, lr_0 = 1.0804e-04
Loss = 5.1230e-04, PNorm = 58.5301, GNorm = 4.1032, lr_0 = 1.0804e-04
Loss = 3.1720e-04, PNorm = 58.5340, GNorm = 0.9856, lr_0 = 1.0804e-04
Validation rmse logD = 0.700114
Validation R2 logD = 0.693784
Epoch 93
Train function
Loss = 1.2282e-04, PNorm = 58.5376, GNorm = 0.6022, lr_0 = 1.0804e-04
Loss = 3.0306e-04, PNorm = 58.5407, GNorm = 1.6180, lr_0 = 1.0804e-04
Loss = 4.0893e-04, PNorm = 58.5423, GNorm = 1.5524, lr_0 = 1.0804e-04
Loss = 4.2132e-04, PNorm = 58.5442, GNorm = 1.4273, lr_0 = 1.0804e-04
Loss = 4.9939e-04, PNorm = 58.5470, GNorm = 1.9286, lr_0 = 1.0804e-04
Loss = 4.4600e-04, PNorm = 58.5508, GNorm = 2.0287, lr_0 = 1.0804e-04
Validation rmse logD = 0.716964
Validation R2 logD = 0.678867
Epoch 94
Train function
Loss = 4.3619e-04, PNorm = 58.5542, GNorm = 4.1420, lr_0 = 1.0804e-04
Loss = 4.8723e-04, PNorm = 58.5571, GNorm = 4.6820, lr_0 = 1.0804e-04
Loss = 3.3797e-04, PNorm = 58.5604, GNorm = 1.9574, lr_0 = 1.0804e-04
Loss = 3.3762e-04, PNorm = 58.5631, GNorm = 2.0317, lr_0 = 1.0804e-04
Loss = 3.3099e-04, PNorm = 58.5671, GNorm = 0.6864, lr_0 = 1.0804e-04
Loss = 3.4977e-04, PNorm = 58.5696, GNorm = 2.9427, lr_0 = 1.0804e-04
Validation rmse logD = 0.703679
Validation R2 logD = 0.690658
Epoch 95
Train function
Loss = 3.4495e-04, PNorm = 58.5731, GNorm = 4.3967, lr_0 = 1.0804e-04
Loss = 3.3140e-04, PNorm = 58.5763, GNorm = 1.6239, lr_0 = 1.0804e-04
Loss = 2.3778e-04, PNorm = 58.5788, GNorm = 1.7005, lr_0 = 1.0804e-04
Loss = 3.7682e-04, PNorm = 58.5805, GNorm = 1.9793, lr_0 = 1.0804e-04
Loss = 4.4811e-04, PNorm = 58.5836, GNorm = 2.3233, lr_0 = 1.0804e-04
Validation rmse logD = 0.713770
Validation R2 logD = 0.681722
Epoch 96
Train function
Loss = 2.7508e-04, PNorm = 58.5873, GNorm = 3.5722, lr_0 = 1.0804e-04
Loss = 3.1345e-04, PNorm = 58.5902, GNorm = 3.0979, lr_0 = 1.0804e-04
Loss = 4.1652e-04, PNorm = 58.5930, GNorm = 3.0032, lr_0 = 1.0804e-04
Loss = 3.3861e-04, PNorm = 58.5958, GNorm = 0.5829, lr_0 = 1.0804e-04
Loss = 3.1718e-04, PNorm = 58.5981, GNorm = 0.7545, lr_0 = 1.0804e-04
Loss = 3.0196e-04, PNorm = 58.6008, GNorm = 1.5310, lr_0 = 1.0804e-04
Validation rmse logD = 0.688501
Validation R2 logD = 0.703858
Epoch 97
Train function
Loss = 2.7939e-04, PNorm = 58.6037, GNorm = 2.9301, lr_0 = 1.0804e-04
Loss = 3.1468e-04, PNorm = 58.6043, GNorm = 0.9448, lr_0 = 1.0804e-04
Loss = 2.4667e-04, PNorm = 58.6069, GNorm = 0.8824, lr_0 = 1.0804e-04
Loss = 2.4306e-04, PNorm = 58.6096, GNorm = 0.8737, lr_0 = 1.0804e-04
Loss = 2.6982e-04, PNorm = 58.6124, GNorm = 1.8679, lr_0 = 1.0804e-04
Loss = 2.8707e-04, PNorm = 58.6149, GNorm = 2.1162, lr_0 = 1.0804e-04
Validation rmse logD = 0.698455
Validation R2 logD = 0.695234
Epoch 98
Train function
Loss = 6.2431e-04, PNorm = 58.6156, GNorm = 8.0023, lr_0 = 1.0804e-04
Loss = 5.8074e-04, PNorm = 58.6176, GNorm = 2.8534, lr_0 = 1.0804e-04
Loss = 3.9261e-04, PNorm = 58.6206, GNorm = 0.8380, lr_0 = 1.0804e-04
Loss = 3.3792e-04, PNorm = 58.6256, GNorm = 0.9975, lr_0 = 1.0804e-04
Loss = 2.9024e-04, PNorm = 58.6305, GNorm = 2.7973, lr_0 = 1.0804e-04
Validation rmse logD = 0.692768
Validation R2 logD = 0.700176
Epoch 99
Train function
Loss = 4.8429e-04, PNorm = 58.6323, GNorm = 4.5802, lr_0 = 1.0804e-04
Loss = 3.7272e-04, PNorm = 58.6342, GNorm = 2.8759, lr_0 = 1.0804e-04
Loss = 2.9855e-04, PNorm = 58.6372, GNorm = 3.4636, lr_0 = 1.0804e-04
Loss = 2.4174e-04, PNorm = 58.6406, GNorm = 0.8072, lr_0 = 1.0804e-04
Loss = 2.8741e-04, PNorm = 58.6420, GNorm = 1.6134, lr_0 = 1.0804e-04
Loss = 3.6690e-04, PNorm = 58.6451, GNorm = 4.2156, lr_0 = 1.0804e-04
Validation rmse logD = 0.700450
Validation R2 logD = 0.693490
Model 0 best validation rmse = 0.688501 on epoch 96
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "substructures_encoder.encoder.cached_zero_vector".
Loading pretrained parameter "substructures_encoder.encoder.W_o.weight".
Loading pretrained parameter "substructures_encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.546762
Model 0 test R2 logD = 0.791000
Ensemble test rmse  logD= 0.546762
Ensemble test R2  logD= 0.791000
5-fold cross validation
	Seed 0 ==> test rmse = 0.584713
	Seed 0 ==> test R2 = 0.788337
	Seed 1 ==> test rmse = 0.548613
	Seed 1 ==> test R2 = 0.763937
	Seed 2 ==> test rmse = 0.566694
	Seed 2 ==> test R2 = 0.781351
	Seed 3 ==> test rmse = 0.539622
	Seed 3 ==> test R2 = 0.792151
	Seed 4 ==> test rmse = 0.546762
	Seed 4 ==> test R2 = 0.791000
Overall val rmse logD= 0.565478 +/- 0.065449
Overall val R2 logD = 0.789515 +/- 0.046561
Overall test rmse logD = 0.557281 +/- 0.016363
Overall test R2 logD = 0.783355 +/- 0.010409
Elapsed time = 10:11:23
