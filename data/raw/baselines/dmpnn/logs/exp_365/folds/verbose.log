Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_365/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 4,166 | train size = 2,832 | val size = 500 | test size = 834
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.4886e-02, PNorm = 35.0056, GNorm = 9.4292, lr_0 = 1.0804e-04
Loss = 1.9587e-02, PNorm = 35.0053, GNorm = 7.2512, lr_0 = 1.0804e-04
Loss = 1.8261e-02, PNorm = 35.0061, GNorm = 5.4414, lr_0 = 1.0804e-04
Loss = 1.9358e-02, PNorm = 35.0075, GNorm = 1.7945, lr_0 = 1.0804e-04
Loss = 1.6629e-02, PNorm = 35.0092, GNorm = 3.2686, lr_0 = 1.0804e-04
Validation rmse logD = 1.134041
Validation R2 logD = 0.181709
Epoch 1
Train function
Loss = 1.4670e-02, PNorm = 35.0117, GNorm = 2.3019, lr_0 = 1.0804e-04
Loss = 1.5808e-02, PNorm = 35.0139, GNorm = 5.2084, lr_0 = 1.0804e-04
Loss = 1.6924e-02, PNorm = 35.0159, GNorm = 1.7550, lr_0 = 1.0804e-04
Loss = 1.4916e-02, PNorm = 35.0186, GNorm = 2.0684, lr_0 = 1.0804e-04
Loss = 1.2606e-02, PNorm = 35.0218, GNorm = 2.6634, lr_0 = 1.0804e-04
Loss = 1.5264e-02, PNorm = 35.0253, GNorm = 5.2691, lr_0 = 1.0804e-04
Validation rmse logD = 1.058181
Validation R2 logD = 0.287524
Epoch 2
Train function
Loss = 1.5649e-02, PNorm = 35.0280, GNorm = 1.9646, lr_0 = 1.0804e-04
Loss = 1.3873e-02, PNorm = 35.0312, GNorm = 6.7329, lr_0 = 1.0804e-04
Loss = 1.3706e-02, PNorm = 35.0341, GNorm = 2.1254, lr_0 = 1.0804e-04
Loss = 1.4196e-02, PNorm = 35.0376, GNorm = 5.5312, lr_0 = 1.0804e-04
Loss = 1.2016e-02, PNorm = 35.0422, GNorm = 4.5901, lr_0 = 1.0804e-04
Validation rmse logD = 1.010449
Validation R2 logD = 0.350350
Epoch 3
Train function
Loss = 9.5624e-03, PNorm = 35.0453, GNorm = 4.5076, lr_0 = 1.0804e-04
Loss = 1.2373e-02, PNorm = 35.0488, GNorm = 2.3403, lr_0 = 1.0804e-04
Loss = 1.3643e-02, PNorm = 35.0527, GNorm = 6.2790, lr_0 = 1.0804e-04
Loss = 1.1231e-02, PNorm = 35.0562, GNorm = 1.3949, lr_0 = 1.0804e-04
Loss = 1.2009e-02, PNorm = 35.0600, GNorm = 2.0809, lr_0 = 1.0804e-04
Loss = 1.2143e-02, PNorm = 35.0637, GNorm = 3.9145, lr_0 = 1.0804e-04
Validation rmse logD = 0.967553
Validation R2 logD = 0.404339
Epoch 4
Train function
Loss = 1.1243e-02, PNorm = 35.0684, GNorm = 1.8050, lr_0 = 1.0804e-04
Loss = 1.0751e-02, PNorm = 35.0733, GNorm = 1.2880, lr_0 = 1.0804e-04
Loss = 1.1396e-02, PNorm = 35.0776, GNorm = 1.1789, lr_0 = 1.0804e-04
Loss = 1.0597e-02, PNorm = 35.0830, GNorm = 2.9310, lr_0 = 1.0804e-04
Loss = 1.1749e-02, PNorm = 35.0879, GNorm = 2.4519, lr_0 = 1.0804e-04
Loss = 1.1290e-02, PNorm = 35.0926, GNorm = 2.6772, lr_0 = 1.0804e-04
Validation rmse logD = 0.931876
Validation R2 logD = 0.447457
Epoch 5
Train function
Loss = 1.0107e-02, PNorm = 35.0977, GNorm = 2.7200, lr_0 = 1.0804e-04
Loss = 1.0696e-02, PNorm = 35.1032, GNorm = 7.4659, lr_0 = 1.0804e-04
Loss = 1.0676e-02, PNorm = 35.1087, GNorm = 2.0343, lr_0 = 1.0804e-04
Loss = 1.0514e-02, PNorm = 35.1132, GNorm = 2.4679, lr_0 = 1.0804e-04
Loss = 1.1657e-02, PNorm = 35.1173, GNorm = 6.5415, lr_0 = 1.0804e-04
Validation rmse logD = 0.908482
Validation R2 logD = 0.474850
Epoch 6
Train function
Loss = 1.0432e-02, PNorm = 35.1226, GNorm = 3.4273, lr_0 = 1.0804e-04
Loss = 1.0633e-02, PNorm = 35.1286, GNorm = 2.4423, lr_0 = 1.0804e-04
Loss = 9.9323e-03, PNorm = 35.1340, GNorm = 1.7303, lr_0 = 1.0804e-04
Loss = 1.0651e-02, PNorm = 35.1387, GNorm = 1.8430, lr_0 = 1.0804e-04
Loss = 9.9413e-03, PNorm = 35.1440, GNorm = 1.9981, lr_0 = 1.0804e-04
Loss = 1.0207e-02, PNorm = 35.1494, GNorm = 3.4511, lr_0 = 1.0804e-04
Validation rmse logD = 0.881461
Validation R2 logD = 0.505625
Epoch 7
Train function
Loss = 1.1080e-02, PNorm = 35.1547, GNorm = 1.8331, lr_0 = 1.0804e-04
Loss = 9.3747e-03, PNorm = 35.1605, GNorm = 2.6156, lr_0 = 1.0804e-04
Loss = 1.0125e-02, PNorm = 35.1666, GNorm = 7.3297, lr_0 = 1.0804e-04
Loss = 8.7426e-03, PNorm = 35.1716, GNorm = 2.4513, lr_0 = 1.0804e-04
Loss = 9.9385e-03, PNorm = 35.1765, GNorm = 1.7317, lr_0 = 1.0804e-04
Loss = 1.0110e-02, PNorm = 35.1821, GNorm = 1.4635, lr_0 = 1.0804e-04
Validation rmse logD = 0.900691
Validation R2 logD = 0.483819
Epoch 8
Train function
Loss = 8.7358e-03, PNorm = 35.1883, GNorm = 1.8243, lr_0 = 1.0804e-04
Loss = 9.7169e-03, PNorm = 35.1948, GNorm = 1.2031, lr_0 = 1.0804e-04
Loss = 9.6368e-03, PNorm = 35.2003, GNorm = 4.7421, lr_0 = 1.0804e-04
Loss = 8.4451e-03, PNorm = 35.2063, GNorm = 2.5367, lr_0 = 1.0804e-04
Loss = 9.1146e-03, PNorm = 35.2125, GNorm = 2.0139, lr_0 = 1.0804e-04
Validation rmse logD = 0.844042
Validation R2 logD = 0.546708
Epoch 9
Train function
Loss = 9.9306e-03, PNorm = 35.2190, GNorm = 2.7967, lr_0 = 1.0804e-04
Loss = 9.0146e-03, PNorm = 35.2259, GNorm = 3.3243, lr_0 = 1.0804e-04
Loss = 8.5267e-03, PNorm = 35.2333, GNorm = 4.6230, lr_0 = 1.0804e-04
Loss = 8.5297e-03, PNorm = 35.2392, GNorm = 5.5621, lr_0 = 1.0804e-04
Loss = 8.3614e-03, PNorm = 35.2445, GNorm = 1.6561, lr_0 = 1.0804e-04
Loss = 9.3241e-03, PNorm = 35.2508, GNorm = 6.8238, lr_0 = 1.0804e-04
Validation rmse logD = 0.840070
Validation R2 logD = 0.550964
Epoch 10
Train function
Loss = 6.3892e-03, PNorm = 35.2573, GNorm = 1.6730, lr_0 = 1.0804e-04
Loss = 8.7308e-03, PNorm = 35.2636, GNorm = 4.8111, lr_0 = 1.0804e-04
Loss = 9.1364e-03, PNorm = 35.2711, GNorm = 1.8859, lr_0 = 1.0804e-04
Loss = 8.5060e-03, PNorm = 35.2776, GNorm = 1.1639, lr_0 = 1.0804e-04
Loss = 8.8677e-03, PNorm = 35.2845, GNorm = 5.2326, lr_0 = 1.0804e-04
Loss = 8.5613e-03, PNorm = 35.2900, GNorm = 3.2596, lr_0 = 1.0804e-04
Validation rmse logD = 0.822019
Validation R2 logD = 0.570054
Epoch 11
Train function
Loss = 7.0980e-03, PNorm = 35.2960, GNorm = 1.5490, lr_0 = 1.0804e-04
Loss = 8.3927e-03, PNorm = 35.3035, GNorm = 1.2340, lr_0 = 1.0804e-04
Loss = 8.7373e-03, PNorm = 35.3113, GNorm = 1.9010, lr_0 = 1.0804e-04
Loss = 7.4407e-03, PNorm = 35.3179, GNorm = 2.1803, lr_0 = 1.0804e-04
Loss = 8.2225e-03, PNorm = 35.3242, GNorm = 3.3652, lr_0 = 1.0804e-04
Validation rmse logD = 0.806589
Validation R2 logD = 0.586043
Epoch 12
Train function
Loss = 7.1712e-03, PNorm = 35.3313, GNorm = 2.8545, lr_0 = 1.0804e-04
Loss = 8.1644e-03, PNorm = 35.3370, GNorm = 3.9317, lr_0 = 1.0804e-04
Loss = 8.1124e-03, PNorm = 35.3440, GNorm = 2.8359, lr_0 = 1.0804e-04
Loss = 7.9117e-03, PNorm = 35.3510, GNorm = 3.1573, lr_0 = 1.0804e-04
Loss = 6.8304e-03, PNorm = 35.3588, GNorm = 4.5845, lr_0 = 1.0804e-04
Loss = 8.1845e-03, PNorm = 35.3669, GNorm = 5.5367, lr_0 = 1.0804e-04
Validation rmse logD = 0.786399
Validation R2 logD = 0.606507
Epoch 13
Train function
Loss = 8.0743e-03, PNorm = 35.3743, GNorm = 2.0590, lr_0 = 1.0804e-04
Loss = 8.1336e-03, PNorm = 35.3817, GNorm = 8.3284, lr_0 = 1.0804e-04
Loss = 8.6165e-03, PNorm = 35.3882, GNorm = 2.9499, lr_0 = 1.0804e-04
Loss = 7.2134e-03, PNorm = 35.3936, GNorm = 2.1873, lr_0 = 1.0804e-04
Loss = 7.3861e-03, PNorm = 35.4008, GNorm = 3.6883, lr_0 = 1.0804e-04
Loss = 6.8939e-03, PNorm = 35.4078, GNorm = 7.2140, lr_0 = 1.0804e-04
Validation rmse logD = 0.830137
Validation R2 logD = 0.561520
Epoch 14
Train function
Loss = 7.2506e-03, PNorm = 35.4151, GNorm = 2.2157, lr_0 = 1.0804e-04
Loss = 7.3266e-03, PNorm = 35.4213, GNorm = 2.3642, lr_0 = 1.0804e-04
Loss = 7.1665e-03, PNorm = 35.4271, GNorm = 3.5781, lr_0 = 1.0804e-04
Loss = 9.2199e-03, PNorm = 35.4325, GNorm = 14.1012, lr_0 = 1.0804e-04
Loss = 7.7004e-03, PNorm = 35.4386, GNorm = 6.4783, lr_0 = 1.0804e-04
Validation rmse logD = 0.812872
Validation R2 logD = 0.579569
Epoch 15
Train function
Loss = 1.1243e-02, PNorm = 35.4453, GNorm = 11.2044, lr_0 = 1.0804e-04
Loss = 7.5801e-03, PNorm = 35.4515, GNorm = 3.1304, lr_0 = 1.0804e-04
Loss = 7.7877e-03, PNorm = 35.4577, GNorm = 3.6489, lr_0 = 1.0804e-04
Loss = 7.4526e-03, PNorm = 35.4645, GNorm = 6.0852, lr_0 = 1.0804e-04
Loss = 7.5986e-03, PNorm = 35.4709, GNorm = 2.3796, lr_0 = 1.0804e-04
Loss = 6.1799e-03, PNorm = 35.4771, GNorm = 1.6606, lr_0 = 1.0804e-04
Validation rmse logD = 0.755231
Validation R2 logD = 0.637081
Epoch 16
Train function
Loss = 7.0914e-03, PNorm = 35.4840, GNorm = 4.9369, lr_0 = 1.0804e-04
Loss = 6.2876e-03, PNorm = 35.4914, GNorm = 4.2120, lr_0 = 1.0804e-04
Loss = 7.0101e-03, PNorm = 35.4983, GNorm = 6.4584, lr_0 = 1.0804e-04
Loss = 6.8617e-03, PNorm = 35.5042, GNorm = 1.7584, lr_0 = 1.0804e-04
Loss = 7.0560e-03, PNorm = 35.5102, GNorm = 2.2980, lr_0 = 1.0804e-04
Loss = 7.0175e-03, PNorm = 35.5166, GNorm = 4.4592, lr_0 = 1.0804e-04
Validation rmse logD = 0.749605
Validation R2 logD = 0.642468
Epoch 17
Train function
Loss = 5.7436e-03, PNorm = 35.5232, GNorm = 2.3541, lr_0 = 1.0804e-04
Loss = 7.0197e-03, PNorm = 35.5303, GNorm = 8.1728, lr_0 = 1.0804e-04
Loss = 6.7884e-03, PNorm = 35.5366, GNorm = 3.5278, lr_0 = 1.0804e-04
Loss = 6.1504e-03, PNorm = 35.5432, GNorm = 2.1344, lr_0 = 1.0804e-04
Loss = 6.6161e-03, PNorm = 35.5510, GNorm = 1.6057, lr_0 = 1.0804e-04
Validation rmse logD = 0.734416
Validation R2 logD = 0.656810
Epoch 18
Train function
Loss = 6.3090e-03, PNorm = 35.5585, GNorm = 1.7641, lr_0 = 1.0804e-04
Loss = 6.8113e-03, PNorm = 35.5666, GNorm = 5.4879, lr_0 = 1.0804e-04
Loss = 6.1664e-03, PNorm = 35.5736, GNorm = 1.7411, lr_0 = 1.0804e-04
Loss = 6.7096e-03, PNorm = 35.5811, GNorm = 3.4101, lr_0 = 1.0804e-04
Loss = 6.2147e-03, PNorm = 35.5874, GNorm = 7.5292, lr_0 = 1.0804e-04
Loss = 6.6574e-03, PNorm = 35.5936, GNorm = 10.9036, lr_0 = 1.0804e-04
Validation rmse logD = 0.726121
Validation R2 logD = 0.664519
Epoch 19
Train function
Loss = 6.6006e-03, PNorm = 35.5999, GNorm = 3.5051, lr_0 = 1.0804e-04
Loss = 5.9049e-03, PNorm = 35.6075, GNorm = 2.8989, lr_0 = 1.0804e-04
Loss = 7.0707e-03, PNorm = 35.6142, GNorm = 4.9402, lr_0 = 1.0804e-04
Loss = 6.5261e-03, PNorm = 35.6197, GNorm = 8.4507, lr_0 = 1.0804e-04
Loss = 6.4280e-03, PNorm = 35.6250, GNorm = 5.9273, lr_0 = 1.0804e-04
Loss = 5.7417e-03, PNorm = 35.6309, GNorm = 3.0205, lr_0 = 1.0804e-04
Validation rmse logD = 0.735518
Validation R2 logD = 0.655780
Epoch 20
Train function
Loss = 6.3738e-03, PNorm = 35.6394, GNorm = 4.6503, lr_0 = 1.0804e-04
Loss = 6.3954e-03, PNorm = 35.6465, GNorm = 4.4203, lr_0 = 1.0804e-04
Loss = 6.0834e-03, PNorm = 35.6546, GNorm = 3.1585, lr_0 = 1.0804e-04
Loss = 5.5713e-03, PNorm = 35.6613, GNorm = 1.8166, lr_0 = 1.0804e-04
Loss = 6.4516e-03, PNorm = 35.6672, GNorm = 1.5282, lr_0 = 1.0804e-04
Validation rmse logD = 0.718835
Validation R2 logD = 0.671217
Epoch 21
Train function
Loss = 6.5115e-03, PNorm = 35.6731, GNorm = 6.5488, lr_0 = 1.0804e-04
Loss = 6.1373e-03, PNorm = 35.6799, GNorm = 2.7983, lr_0 = 1.0804e-04
Loss = 5.1005e-03, PNorm = 35.6867, GNorm = 7.6584, lr_0 = 1.0804e-04
Loss = 5.6348e-03, PNorm = 35.6942, GNorm = 2.5700, lr_0 = 1.0804e-04
Loss = 6.9338e-03, PNorm = 35.7006, GNorm = 7.0547, lr_0 = 1.0804e-04
Loss = 5.6437e-03, PNorm = 35.7059, GNorm = 5.5169, lr_0 = 1.0804e-04
Validation rmse logD = 0.749831
Validation R2 logD = 0.642253
Epoch 22
Train function
Loss = 6.0084e-03, PNorm = 35.7125, GNorm = 9.2827, lr_0 = 1.0804e-04
Loss = 6.0353e-03, PNorm = 35.7191, GNorm = 4.6133, lr_0 = 1.0804e-04
Loss = 6.2845e-03, PNorm = 35.7262, GNorm = 4.7135, lr_0 = 1.0804e-04
Loss = 6.0050e-03, PNorm = 35.7330, GNorm = 2.4837, lr_0 = 1.0804e-04
Loss = 5.2927e-03, PNorm = 35.7401, GNorm = 2.2376, lr_0 = 1.0804e-04
Loss = 5.5405e-03, PNorm = 35.7465, GNorm = 8.0785, lr_0 = 1.0804e-04
Validation rmse logD = 0.714170
Validation R2 logD = 0.675471
Epoch 23
Train function
Loss = 4.9676e-03, PNorm = 35.7528, GNorm = 5.6735, lr_0 = 1.0804e-04
Loss = 5.5739e-03, PNorm = 35.7592, GNorm = 2.9993, lr_0 = 1.0804e-04
Loss = 6.0322e-03, PNorm = 35.7653, GNorm = 4.5796, lr_0 = 1.0804e-04
Loss = 5.1785e-03, PNorm = 35.7715, GNorm = 1.9359, lr_0 = 1.0804e-04
Loss = 5.8582e-03, PNorm = 35.7782, GNorm = 5.1011, lr_0 = 1.0804e-04
Validation rmse logD = 0.709604
Validation R2 logD = 0.679607
Epoch 24
Train function
Loss = 3.3131e-03, PNorm = 35.7848, GNorm = 1.9183, lr_0 = 1.0804e-04
Loss = 5.8616e-03, PNorm = 35.7912, GNorm = 2.1004, lr_0 = 1.0804e-04
Loss = 5.8753e-03, PNorm = 35.7980, GNorm = 8.0830, lr_0 = 1.0804e-04
Loss = 5.7210e-03, PNorm = 35.8053, GNorm = 8.1062, lr_0 = 1.0804e-04
Loss = 5.4541e-03, PNorm = 35.8123, GNorm = 11.4665, lr_0 = 1.0804e-04
Loss = 5.6699e-03, PNorm = 35.8172, GNorm = 2.4942, lr_0 = 1.0804e-04
Validation rmse logD = 0.690792
Validation R2 logD = 0.696370
Epoch 25
Train function
Loss = 5.0797e-03, PNorm = 35.8233, GNorm = 4.9914, lr_0 = 1.0804e-04
Loss = 5.6277e-03, PNorm = 35.8302, GNorm = 1.8386, lr_0 = 1.0804e-04
Loss = 4.7606e-03, PNorm = 35.8361, GNorm = 3.0448, lr_0 = 1.0804e-04
Loss = 5.5478e-03, PNorm = 35.8412, GNorm = 2.8139, lr_0 = 1.0804e-04
Loss = 6.0294e-03, PNorm = 35.8479, GNorm = 10.0515, lr_0 = 1.0804e-04
Loss = 5.5089e-03, PNorm = 35.8535, GNorm = 6.8222, lr_0 = 1.0804e-04
Validation rmse logD = 0.688557
Validation R2 logD = 0.698332
Epoch 26
Train function
Loss = 4.9986e-03, PNorm = 35.8609, GNorm = 4.7598, lr_0 = 1.0804e-04
Loss = 5.2265e-03, PNorm = 35.8676, GNorm = 8.3588, lr_0 = 1.0804e-04
Loss = 6.1181e-03, PNorm = 35.8752, GNorm = 1.4312, lr_0 = 1.0804e-04
Loss = 4.5847e-03, PNorm = 35.8816, GNorm = 2.5947, lr_0 = 1.0804e-04
Loss = 5.2562e-03, PNorm = 35.8875, GNorm = 3.9723, lr_0 = 1.0804e-04
Validation rmse logD = 0.676090
Validation R2 logD = 0.709156
Epoch 27
Train function
Loss = 5.5934e-03, PNorm = 35.8922, GNorm = 2.8930, lr_0 = 1.0804e-04
Loss = 5.1045e-03, PNorm = 35.8963, GNorm = 1.8291, lr_0 = 1.0804e-04
Loss = 4.8874e-03, PNorm = 35.9022, GNorm = 2.5542, lr_0 = 1.0804e-04
Loss = 5.1622e-03, PNorm = 35.9097, GNorm = 2.0910, lr_0 = 1.0804e-04
Loss = 4.7893e-03, PNorm = 35.9166, GNorm = 6.5047, lr_0 = 1.0804e-04
Loss = 5.4235e-03, PNorm = 35.9223, GNorm = 3.9633, lr_0 = 1.0804e-04
Validation rmse logD = 0.686985
Validation R2 logD = 0.699707
Epoch 28
Train function
Loss = 5.0338e-03, PNorm = 35.9287, GNorm = 2.5770, lr_0 = 1.0804e-04
Loss = 4.8089e-03, PNorm = 35.9340, GNorm = 2.5938, lr_0 = 1.0804e-04
Loss = 4.6048e-03, PNorm = 35.9400, GNorm = 2.1173, lr_0 = 1.0804e-04
Loss = 5.1176e-03, PNorm = 35.9460, GNorm = 8.0002, lr_0 = 1.0804e-04
Loss = 5.1130e-03, PNorm = 35.9519, GNorm = 2.6880, lr_0 = 1.0804e-04
Loss = 4.9723e-03, PNorm = 35.9576, GNorm = 4.4287, lr_0 = 1.0804e-04
Validation rmse logD = 0.672334
Validation R2 logD = 0.712379
Epoch 29
Train function
Loss = 5.0190e-03, PNorm = 35.9651, GNorm = 4.0321, lr_0 = 1.0804e-04
Loss = 4.6967e-03, PNorm = 35.9726, GNorm = 3.8832, lr_0 = 1.0804e-04
Loss = 5.1096e-03, PNorm = 35.9784, GNorm = 3.2799, lr_0 = 1.0804e-04
Loss = 4.4775e-03, PNorm = 35.9841, GNorm = 5.7937, lr_0 = 1.0804e-04
Loss = 4.8064e-03, PNorm = 35.9904, GNorm = 2.0125, lr_0 = 1.0804e-04
Validation rmse logD = 0.665383
Validation R2 logD = 0.718295
Epoch 30
Train function
Loss = 4.8708e-03, PNorm = 35.9961, GNorm = 5.4022, lr_0 = 1.0804e-04
Loss = 4.8348e-03, PNorm = 36.0026, GNorm = 5.9383, lr_0 = 1.0804e-04
Loss = 4.8988e-03, PNorm = 36.0084, GNorm = 5.3073, lr_0 = 1.0804e-04
Loss = 4.5540e-03, PNorm = 36.0146, GNorm = 3.2687, lr_0 = 1.0804e-04
Loss = 4.6573e-03, PNorm = 36.0214, GNorm = 1.6789, lr_0 = 1.0804e-04
Loss = 4.5472e-03, PNorm = 36.0275, GNorm = 3.8713, lr_0 = 1.0804e-04
Validation rmse logD = 0.658486
Validation R2 logD = 0.724105
Epoch 31
Train function
Loss = 3.9555e-03, PNorm = 36.0326, GNorm = 3.4492, lr_0 = 1.0804e-04
Loss = 4.5967e-03, PNorm = 36.0383, GNorm = 2.0154, lr_0 = 1.0804e-04
Loss = 4.3456e-03, PNorm = 36.0437, GNorm = 1.9064, lr_0 = 1.0804e-04
Loss = 4.6662e-03, PNorm = 36.0499, GNorm = 1.5610, lr_0 = 1.0804e-04
Loss = 4.2216e-03, PNorm = 36.0565, GNorm = 3.4694, lr_0 = 1.0804e-04
Loss = 4.7776e-03, PNorm = 36.0633, GNorm = 3.2696, lr_0 = 1.0804e-04
Validation rmse logD = 0.676947
Validation R2 logD = 0.708419
Epoch 32
Train function
Loss = 3.9755e-03, PNorm = 36.0677, GNorm = 5.6054, lr_0 = 1.0804e-04
Loss = 4.7243e-03, PNorm = 36.0735, GNorm = 3.7819, lr_0 = 1.0804e-04
Loss = 3.9579e-03, PNorm = 36.0792, GNorm = 4.4745, lr_0 = 1.0804e-04
Loss = 4.3606e-03, PNorm = 36.0836, GNorm = 6.6159, lr_0 = 1.0804e-04
Loss = 4.6978e-03, PNorm = 36.0882, GNorm = 8.0284, lr_0 = 1.0804e-04
Validation rmse logD = 0.647178
Validation R2 logD = 0.733500
Epoch 33
Train function
Loss = 2.8893e-03, PNorm = 36.0939, GNorm = 1.9681, lr_0 = 1.0804e-04
Loss = 4.7362e-03, PNorm = 36.1008, GNorm = 5.2693, lr_0 = 1.0804e-04
Loss = 3.8766e-03, PNorm = 36.1081, GNorm = 2.1749, lr_0 = 1.0804e-04
Loss = 4.4081e-03, PNorm = 36.1149, GNorm = 1.8018, lr_0 = 1.0804e-04
Loss = 4.5344e-03, PNorm = 36.1211, GNorm = 3.8903, lr_0 = 1.0804e-04
Loss = 4.2135e-03, PNorm = 36.1254, GNorm = 3.8630, lr_0 = 1.0804e-04
Validation rmse logD = 0.650452
Validation R2 logD = 0.730796
Epoch 34
Train function
Loss = 3.6505e-03, PNorm = 36.1302, GNorm = 1.3718, lr_0 = 1.0804e-04
Loss = 3.8351e-03, PNorm = 36.1362, GNorm = 1.7553, lr_0 = 1.0804e-04
Loss = 3.7529e-03, PNorm = 36.1417, GNorm = 1.6366, lr_0 = 1.0804e-04
Loss = 4.0791e-03, PNorm = 36.1472, GNorm = 1.9017, lr_0 = 1.0804e-04
Loss = 4.3622e-03, PNorm = 36.1529, GNorm = 2.2630, lr_0 = 1.0804e-04
Loss = 4.5666e-03, PNorm = 36.1568, GNorm = 6.6434, lr_0 = 1.0804e-04
Validation rmse logD = 0.652902
Validation R2 logD = 0.728764
Epoch 35
Train function
Loss = 3.9844e-03, PNorm = 36.1633, GNorm = 3.4924, lr_0 = 1.0804e-04
Loss = 4.1116e-03, PNorm = 36.1685, GNorm = 8.2992, lr_0 = 1.0804e-04
Loss = 4.5795e-03, PNorm = 36.1738, GNorm = 5.3020, lr_0 = 1.0804e-04
Loss = 4.4007e-03, PNorm = 36.1790, GNorm = 1.7648, lr_0 = 1.0804e-04
Loss = 5.1670e-03, PNorm = 36.1842, GNorm = 7.8137, lr_0 = 1.0804e-04
Validation rmse logD = 0.652397
Validation R2 logD = 0.729184
Epoch 36
Train function
Loss = 4.1723e-03, PNorm = 36.1895, GNorm = 2.6537, lr_0 = 1.0804e-04
Loss = 3.9622e-03, PNorm = 36.1957, GNorm = 5.5053, lr_0 = 1.0804e-04
Loss = 4.1590e-03, PNorm = 36.2007, GNorm = 2.9783, lr_0 = 1.0804e-04
Loss = 4.0003e-03, PNorm = 36.2055, GNorm = 1.8891, lr_0 = 1.0804e-04
Loss = 4.2833e-03, PNorm = 36.2100, GNorm = 1.9667, lr_0 = 1.0804e-04
Loss = 4.7595e-03, PNorm = 36.2158, GNorm = 4.7543, lr_0 = 1.0804e-04
Validation rmse logD = 0.650539
Validation R2 logD = 0.730725
Epoch 37
Train function
Loss = 3.4786e-03, PNorm = 36.2220, GNorm = 8.1057, lr_0 = 1.0804e-04
Loss = 4.0479e-03, PNorm = 36.2271, GNorm = 1.3871, lr_0 = 1.0804e-04
Loss = 3.4530e-03, PNorm = 36.2322, GNorm = 3.4770, lr_0 = 1.0804e-04
Loss = 4.7255e-03, PNorm = 36.2384, GNorm = 2.8146, lr_0 = 1.0804e-04
Loss = 3.4854e-03, PNorm = 36.2440, GNorm = 1.7894, lr_0 = 1.0804e-04
Loss = 4.1100e-03, PNorm = 36.2489, GNorm = 1.6342, lr_0 = 1.0804e-04
Validation rmse logD = 0.637617
Validation R2 logD = 0.741316
Epoch 38
Train function
Loss = 3.8140e-03, PNorm = 36.2564, GNorm = 1.5039, lr_0 = 1.0804e-04
Loss = 3.4150e-03, PNorm = 36.2627, GNorm = 3.7919, lr_0 = 1.0804e-04
Loss = 3.7587e-03, PNorm = 36.2677, GNorm = 7.5892, lr_0 = 1.0804e-04
Loss = 3.6306e-03, PNorm = 36.2728, GNorm = 6.3585, lr_0 = 1.0804e-04
Loss = 4.1703e-03, PNorm = 36.2785, GNorm = 5.1169, lr_0 = 1.0804e-04
Validation rmse logD = 0.669411
Validation R2 logD = 0.714874
Epoch 39
Train function
Loss = 3.9767e-03, PNorm = 36.2838, GNorm = 6.4080, lr_0 = 1.0804e-04
Loss = 4.2030e-03, PNorm = 36.2885, GNorm = 10.1394, lr_0 = 1.0804e-04
Loss = 3.6423e-03, PNorm = 36.2941, GNorm = 3.8045, lr_0 = 1.0804e-04
Loss = 3.5722e-03, PNorm = 36.2996, GNorm = 1.9737, lr_0 = 1.0804e-04
Loss = 3.6542e-03, PNorm = 36.3040, GNorm = 5.6890, lr_0 = 1.0804e-04
Loss = 4.1778e-03, PNorm = 36.3090, GNorm = 2.4252, lr_0 = 1.0804e-04
Validation rmse logD = 0.709322
Validation R2 logD = 0.679862
Epoch 40
Train function
Loss = 3.6777e-03, PNorm = 36.3145, GNorm = 6.3142, lr_0 = 1.0804e-04
Loss = 3.8813e-03, PNorm = 36.3192, GNorm = 4.3944, lr_0 = 1.0804e-04
Loss = 3.9288e-03, PNorm = 36.3241, GNorm = 4.2666, lr_0 = 1.0804e-04
Loss = 3.7818e-03, PNorm = 36.3302, GNorm = 6.2676, lr_0 = 1.0804e-04
Loss = 4.1105e-03, PNorm = 36.3358, GNorm = 2.8610, lr_0 = 1.0804e-04
Loss = 3.7756e-03, PNorm = 36.3406, GNorm = 3.0848, lr_0 = 1.0804e-04
Validation rmse logD = 0.631171
Validation R2 logD = 0.746520
Epoch 41
Train function
Loss = 3.4078e-03, PNorm = 36.3458, GNorm = 1.9304, lr_0 = 1.0804e-04
Loss = 3.6360e-03, PNorm = 36.3502, GNorm = 1.5447, lr_0 = 1.0804e-04
Loss = 4.0813e-03, PNorm = 36.3552, GNorm = 2.2968, lr_0 = 1.0804e-04
Loss = 3.8981e-03, PNorm = 36.3613, GNorm = 4.6673, lr_0 = 1.0804e-04
Loss = 3.7440e-03, PNorm = 36.3676, GNorm = 2.8697, lr_0 = 1.0804e-04
Validation rmse logD = 0.665617
Validation R2 logD = 0.718097
Epoch 42
Train function
Loss = 3.7543e-03, PNorm = 36.3727, GNorm = 6.8582, lr_0 = 1.0804e-04
Loss = 3.8569e-03, PNorm = 36.3766, GNorm = 3.9230, lr_0 = 1.0804e-04
Loss = 3.4927e-03, PNorm = 36.3821, GNorm = 3.3500, lr_0 = 1.0804e-04
Loss = 3.4397e-03, PNorm = 36.3871, GNorm = 4.2269, lr_0 = 1.0804e-04
Loss = 3.3384e-03, PNorm = 36.3915, GNorm = 2.3183, lr_0 = 1.0804e-04
Loss = 3.5082e-03, PNorm = 36.3967, GNorm = 4.0448, lr_0 = 1.0804e-04
Validation rmse logD = 0.640298
Validation R2 logD = 0.739136
Epoch 43
Train function
Loss = 3.1713e-03, PNorm = 36.4035, GNorm = 5.8714, lr_0 = 1.0804e-04
Loss = 3.6985e-03, PNorm = 36.4103, GNorm = 10.5540, lr_0 = 1.0804e-04
Loss = 3.6129e-03, PNorm = 36.4148, GNorm = 1.6136, lr_0 = 1.0804e-04
Loss = 3.2115e-03, PNorm = 36.4189, GNorm = 4.4582, lr_0 = 1.0804e-04
Loss = 3.8389e-03, PNorm = 36.4240, GNorm = 2.7248, lr_0 = 1.0804e-04
Loss = 3.3860e-03, PNorm = 36.4289, GNorm = 1.8089, lr_0 = 1.0804e-04
Validation rmse logD = 0.624925
Validation R2 logD = 0.751511
Epoch 44
Train function
Loss = 3.4935e-03, PNorm = 36.4330, GNorm = 2.7324, lr_0 = 1.0804e-04
Loss = 2.8624e-03, PNorm = 36.4375, GNorm = 4.7127, lr_0 = 1.0804e-04
Loss = 3.8285e-03, PNorm = 36.4423, GNorm = 7.6607, lr_0 = 1.0804e-04
Loss = 3.5373e-03, PNorm = 36.4475, GNorm = 1.5558, lr_0 = 1.0804e-04
Loss = 3.6885e-03, PNorm = 36.4537, GNorm = 2.2719, lr_0 = 1.0804e-04
Validation rmse logD = 0.626491
Validation R2 logD = 0.750265
Epoch 45
Train function
Loss = 2.6230e-03, PNorm = 36.4597, GNorm = 2.1665, lr_0 = 1.0804e-04
Loss = 3.0271e-03, PNorm = 36.4650, GNorm = 3.3566, lr_0 = 1.0804e-04
Loss = 3.5339e-03, PNorm = 36.4701, GNorm = 3.3875, lr_0 = 1.0804e-04
Loss = 3.2051e-03, PNorm = 36.4750, GNorm = 4.3418, lr_0 = 1.0804e-04
Loss = 3.5569e-03, PNorm = 36.4782, GNorm = 7.4736, lr_0 = 1.0804e-04
Loss = 3.9858e-03, PNorm = 36.4815, GNorm = 3.3731, lr_0 = 1.0804e-04
Validation rmse logD = 0.655158
Validation R2 logD = 0.726887
Epoch 46
Train function
Loss = 3.4863e-03, PNorm = 36.4860, GNorm = 2.8054, lr_0 = 1.0804e-04
Loss = 3.4174e-03, PNorm = 36.4907, GNorm = 2.7030, lr_0 = 1.0804e-04
Loss = 3.6624e-03, PNorm = 36.4960, GNorm = 8.0557, lr_0 = 1.0804e-04
Loss = 3.5886e-03, PNorm = 36.5015, GNorm = 1.8388, lr_0 = 1.0804e-04
Loss = 3.2049e-03, PNorm = 36.5066, GNorm = 4.1412, lr_0 = 1.0804e-04
Loss = 3.0921e-03, PNorm = 36.5119, GNorm = 2.2191, lr_0 = 1.0804e-04
Validation rmse logD = 0.617735
Validation R2 logD = 0.757196
Epoch 47
Train function
Loss = 3.3983e-03, PNorm = 36.5158, GNorm = 2.2269, lr_0 = 1.0804e-04
Loss = 3.1378e-03, PNorm = 36.5210, GNorm = 5.8327, lr_0 = 1.0804e-04
Loss = 3.0452e-03, PNorm = 36.5260, GNorm = 1.5496, lr_0 = 1.0804e-04
Loss = 3.3491e-03, PNorm = 36.5313, GNorm = 1.7166, lr_0 = 1.0804e-04
Loss = 2.7797e-03, PNorm = 36.5371, GNorm = 2.0689, lr_0 = 1.0804e-04
Validation rmse logD = 0.639356
Validation R2 logD = 0.739903
Epoch 48
Train function
Loss = 2.5260e-03, PNorm = 36.5426, GNorm = 1.4939, lr_0 = 1.0804e-04
Loss = 3.1861e-03, PNorm = 36.5478, GNorm = 2.8274, lr_0 = 1.0804e-04
Loss = 3.6100e-03, PNorm = 36.5531, GNorm = 5.0834, lr_0 = 1.0804e-04
Loss = 3.0094e-03, PNorm = 36.5568, GNorm = 6.0680, lr_0 = 1.0804e-04
Loss = 3.4047e-03, PNorm = 36.5609, GNorm = 5.8271, lr_0 = 1.0804e-04
Loss = 3.3851e-03, PNorm = 36.5663, GNorm = 2.4658, lr_0 = 1.0804e-04
Validation rmse logD = 0.629476
Validation R2 logD = 0.747879
Epoch 49
Train function
Loss = 3.4071e-03, PNorm = 36.5711, GNorm = 3.9285, lr_0 = 1.0804e-04
Loss = 3.0761e-03, PNorm = 36.5749, GNorm = 3.0632, lr_0 = 1.0804e-04
Loss = 2.9150e-03, PNorm = 36.5795, GNorm = 6.0319, lr_0 = 1.0804e-04
Loss = 2.8349e-03, PNorm = 36.5844, GNorm = 1.9105, lr_0 = 1.0804e-04
Loss = 3.7084e-03, PNorm = 36.5891, GNorm = 3.4730, lr_0 = 1.0804e-04
Loss = 3.2863e-03, PNorm = 36.5943, GNorm = 1.8310, lr_0 = 1.0804e-04
Validation rmse logD = 0.632609
Validation R2 logD = 0.745363
Epoch 50
Train function
Loss = 2.8127e-03, PNorm = 36.5994, GNorm = 2.4580, lr_0 = 1.0804e-04
Loss = 2.9372e-03, PNorm = 36.6044, GNorm = 2.2071, lr_0 = 1.0804e-04
Loss = 3.0739e-03, PNorm = 36.6095, GNorm = 2.0104, lr_0 = 1.0804e-04
Loss = 2.9384e-03, PNorm = 36.6142, GNorm = 4.5376, lr_0 = 1.0804e-04
Loss = 3.5673e-03, PNorm = 36.6193, GNorm = 5.6769, lr_0 = 1.0804e-04
Validation rmse logD = 0.610361
Validation R2 logD = 0.762959
Epoch 51
Train function
Loss = 3.2568e-03, PNorm = 36.6249, GNorm = 2.7778, lr_0 = 1.0804e-04
Loss = 3.2517e-03, PNorm = 36.6307, GNorm = 1.7465, lr_0 = 1.0804e-04
Loss = 2.2730e-03, PNorm = 36.6355, GNorm = 3.4464, lr_0 = 1.0804e-04
Loss = 2.8420e-03, PNorm = 36.6393, GNorm = 6.5975, lr_0 = 1.0804e-04
Loss = 3.2783e-03, PNorm = 36.6428, GNorm = 6.5520, lr_0 = 1.0804e-04
Loss = 3.1617e-03, PNorm = 36.6477, GNorm = 3.4550, lr_0 = 1.0804e-04
Validation rmse logD = 0.615792
Validation R2 logD = 0.758722
Epoch 52
Train function
Loss = 2.6059e-03, PNorm = 36.6536, GNorm = 1.0537, lr_0 = 1.0804e-04
Loss = 3.4540e-03, PNorm = 36.6587, GNorm = 5.6839, lr_0 = 1.0804e-04
Loss = 2.8743e-03, PNorm = 36.6647, GNorm = 5.3081, lr_0 = 1.0804e-04
Loss = 3.0699e-03, PNorm = 36.6691, GNorm = 3.1035, lr_0 = 1.0804e-04
Loss = 2.8179e-03, PNorm = 36.6737, GNorm = 3.3411, lr_0 = 1.0804e-04
Loss = 2.9027e-03, PNorm = 36.6783, GNorm = 4.4000, lr_0 = 1.0804e-04
Validation rmse logD = 0.631292
Validation R2 logD = 0.746422
Epoch 53
Train function
Loss = 3.2373e-03, PNorm = 36.6824, GNorm = 5.5264, lr_0 = 1.0804e-04
Loss = 3.1998e-03, PNorm = 36.6863, GNorm = 7.9550, lr_0 = 1.0804e-04
Loss = 3.1565e-03, PNorm = 36.6900, GNorm = 2.3063, lr_0 = 1.0804e-04
Loss = 3.1044e-03, PNorm = 36.6950, GNorm = 1.4704, lr_0 = 1.0804e-04
Loss = 2.6279e-03, PNorm = 36.6998, GNorm = 1.9243, lr_0 = 1.0804e-04
Validation rmse logD = 0.614547
Validation R2 logD = 0.759697
Epoch 54
Train function
Loss = 2.0891e-03, PNorm = 36.7055, GNorm = 2.0359, lr_0 = 1.0804e-04
Loss = 2.9052e-03, PNorm = 36.7103, GNorm = 3.6072, lr_0 = 1.0804e-04
Loss = 2.8790e-03, PNorm = 36.7139, GNorm = 4.0237, lr_0 = 1.0804e-04
Loss = 3.0839e-03, PNorm = 36.7189, GNorm = 4.1526, lr_0 = 1.0804e-04
Loss = 2.8534e-03, PNorm = 36.7228, GNorm = 1.3995, lr_0 = 1.0804e-04
Loss = 2.9132e-03, PNorm = 36.7273, GNorm = 5.2826, lr_0 = 1.0804e-04
Validation rmse logD = 0.633078
Validation R2 logD = 0.744986
Epoch 55
Train function
Loss = 2.8915e-03, PNorm = 36.7331, GNorm = 3.0948, lr_0 = 1.0804e-04
Loss = 2.6894e-03, PNorm = 36.7386, GNorm = 5.5375, lr_0 = 1.0804e-04
Loss = 2.8719e-03, PNorm = 36.7437, GNorm = 5.8607, lr_0 = 1.0804e-04
Loss = 2.9400e-03, PNorm = 36.7477, GNorm = 2.8718, lr_0 = 1.0804e-04
Loss = 3.2635e-03, PNorm = 36.7510, GNorm = 7.7101, lr_0 = 1.0804e-04
Loss = 3.3823e-03, PNorm = 36.7548, GNorm = 1.1428, lr_0 = 1.0804e-04
Validation rmse logD = 0.606340
Validation R2 logD = 0.766072
Epoch 56
Train function
Loss = 2.7567e-03, PNorm = 36.7603, GNorm = 3.1226, lr_0 = 1.0804e-04
Loss = 3.3066e-03, PNorm = 36.7644, GNorm = 10.3785, lr_0 = 1.0804e-04
Loss = 3.2958e-03, PNorm = 36.7688, GNorm = 2.5839, lr_0 = 1.0804e-04
Loss = 3.0530e-03, PNorm = 36.7730, GNorm = 1.1043, lr_0 = 1.0804e-04
Loss = 2.8909e-03, PNorm = 36.7777, GNorm = 1.8987, lr_0 = 1.0804e-04
Validation rmse logD = 0.613412
Validation R2 logD = 0.760583
Epoch 57
Train function
Loss = 2.7574e-03, PNorm = 36.7825, GNorm = 4.8308, lr_0 = 1.0804e-04
Loss = 2.6868e-03, PNorm = 36.7869, GNorm = 1.8541, lr_0 = 1.0804e-04
Loss = 2.9687e-03, PNorm = 36.7912, GNorm = 2.9663, lr_0 = 1.0804e-04
Loss = 3.0566e-03, PNorm = 36.7956, GNorm = 4.3444, lr_0 = 1.0804e-04
Loss = 3.0338e-03, PNorm = 36.8001, GNorm = 1.7314, lr_0 = 1.0804e-04
Loss = 2.9484e-03, PNorm = 36.8040, GNorm = 9.1816, lr_0 = 1.0804e-04
Validation rmse logD = 0.614125
Validation R2 logD = 0.760026
Epoch 58
Train function
Loss = 3.4990e-03, PNorm = 36.8085, GNorm = 2.9776, lr_0 = 1.0804e-04
Loss = 2.4629e-03, PNorm = 36.8134, GNorm = 3.3725, lr_0 = 1.0804e-04
Loss = 2.9471e-03, PNorm = 36.8181, GNorm = 7.5959, lr_0 = 1.0804e-04
Loss = 2.4232e-03, PNorm = 36.8226, GNorm = 2.1320, lr_0 = 1.0804e-04
Loss = 2.5962e-03, PNorm = 36.8272, GNorm = 3.1335, lr_0 = 1.0804e-04
Loss = 2.3926e-03, PNorm = 36.8313, GNorm = 2.0759, lr_0 = 1.0804e-04
Validation rmse logD = 0.606070
Validation R2 logD = 0.766280
Epoch 59
Train function
Loss = 2.4406e-03, PNorm = 36.8363, GNorm = 5.9589, lr_0 = 1.0804e-04
Loss = 2.4467e-03, PNorm = 36.8414, GNorm = 1.9730, lr_0 = 1.0804e-04
Loss = 2.9802e-03, PNorm = 36.8455, GNorm = 6.3457, lr_0 = 1.0804e-04
Loss = 2.6876e-03, PNorm = 36.8490, GNorm = 6.9470, lr_0 = 1.0804e-04
Loss = 2.8928e-03, PNorm = 36.8524, GNorm = 2.2906, lr_0 = 1.0804e-04
Validation rmse logD = 0.614532
Validation R2 logD = 0.759708
Epoch 60
Train function
Loss = 2.5505e-03, PNorm = 36.8564, GNorm = 1.3218, lr_0 = 1.0804e-04
Loss = 2.3918e-03, PNorm = 36.8613, GNorm = 3.3418, lr_0 = 1.0804e-04
Loss = 2.6738e-03, PNorm = 36.8660, GNorm = 3.1652, lr_0 = 1.0804e-04
Loss = 2.8188e-03, PNorm = 36.8711, GNorm = 2.2976, lr_0 = 1.0804e-04
Loss = 2.5155e-03, PNorm = 36.8753, GNorm = 2.6116, lr_0 = 1.0804e-04
Loss = 3.1211e-03, PNorm = 36.8790, GNorm = 9.2208, lr_0 = 1.0804e-04
Validation rmse logD = 0.640991
Validation R2 logD = 0.738571
Epoch 61
Train function
Loss = 2.8359e-03, PNorm = 36.8823, GNorm = 4.6067, lr_0 = 1.0804e-04
Loss = 2.9156e-03, PNorm = 36.8857, GNorm = 6.2300, lr_0 = 1.0804e-04
Loss = 2.6798e-03, PNorm = 36.8898, GNorm = 2.0109, lr_0 = 1.0804e-04
Loss = 2.4852e-03, PNorm = 36.8942, GNorm = 1.7846, lr_0 = 1.0804e-04
Loss = 2.9049e-03, PNorm = 36.8995, GNorm = 7.5814, lr_0 = 1.0804e-04
Loss = 2.4239e-03, PNorm = 36.9034, GNorm = 3.0410, lr_0 = 1.0804e-04
Validation rmse logD = 0.617990
Validation R2 logD = 0.756996
Epoch 62
Train function
Loss = 2.8826e-03, PNorm = 36.9089, GNorm = 2.8181, lr_0 = 1.0804e-04
Loss = 2.6315e-03, PNorm = 36.9137, GNorm = 2.9246, lr_0 = 1.0804e-04
Loss = 2.2857e-03, PNorm = 36.9175, GNorm = 3.0814, lr_0 = 1.0804e-04
Loss = 2.5259e-03, PNorm = 36.9207, GNorm = 1.3255, lr_0 = 1.0804e-04
Loss = 2.3744e-03, PNorm = 36.9244, GNorm = 2.6001, lr_0 = 1.0804e-04
Validation rmse logD = 0.603785
Validation R2 logD = 0.768039
Epoch 63
Train function
Loss = 4.2636e-03, PNorm = 36.9298, GNorm = 3.3353, lr_0 = 1.0804e-04
Loss = 2.2347e-03, PNorm = 36.9348, GNorm = 5.8202, lr_0 = 1.0804e-04
Loss = 2.6912e-03, PNorm = 36.9390, GNorm = 3.4223, lr_0 = 1.0804e-04
Loss = 2.2845e-03, PNorm = 36.9426, GNorm = 1.7921, lr_0 = 1.0804e-04
Loss = 2.6992e-03, PNorm = 36.9482, GNorm = 8.0324, lr_0 = 1.0804e-04
Loss = 2.3814e-03, PNorm = 36.9526, GNorm = 2.9973, lr_0 = 1.0804e-04
Validation rmse logD = 0.608561
Validation R2 logD = 0.764355
Epoch 64
Train function
Loss = 2.5044e-03, PNorm = 36.9564, GNorm = 3.1631, lr_0 = 1.0804e-04
Loss = 2.4563e-03, PNorm = 36.9605, GNorm = 2.4666, lr_0 = 1.0804e-04
Loss = 2.3964e-03, PNorm = 36.9654, GNorm = 1.4519, lr_0 = 1.0804e-04
Loss = 2.5956e-03, PNorm = 36.9701, GNorm = 2.2546, lr_0 = 1.0804e-04
Loss = 2.1094e-03, PNorm = 36.9742, GNorm = 2.7342, lr_0 = 1.0804e-04
Loss = 2.4046e-03, PNorm = 36.9778, GNorm = 2.6524, lr_0 = 1.0804e-04
Validation rmse logD = 0.600436
Validation R2 logD = 0.770605
Epoch 65
Train function
Loss = 2.1105e-03, PNorm = 36.9818, GNorm = 3.4722, lr_0 = 1.0804e-04
Loss = 2.3554e-03, PNorm = 36.9863, GNorm = 2.0441, lr_0 = 1.0804e-04
Loss = 2.5222e-03, PNorm = 36.9907, GNorm = 3.2370, lr_0 = 1.0804e-04
Loss = 2.3381e-03, PNorm = 36.9952, GNorm = 2.2650, lr_0 = 1.0804e-04
Loss = 2.4559e-03, PNorm = 36.9993, GNorm = 5.4606, lr_0 = 1.0804e-04
Validation rmse logD = 0.605398
Validation R2 logD = 0.766798
Epoch 66
Train function
Loss = 3.2470e-03, PNorm = 37.0029, GNorm = 3.3011, lr_0 = 1.0804e-04
Loss = 2.4076e-03, PNorm = 37.0067, GNorm = 7.7595, lr_0 = 1.0804e-04
Loss = 2.6106e-03, PNorm = 37.0106, GNorm = 4.0321, lr_0 = 1.0804e-04
Loss = 2.3782e-03, PNorm = 37.0148, GNorm = 2.4441, lr_0 = 1.0804e-04
Loss = 2.5748e-03, PNorm = 37.0196, GNorm = 5.9612, lr_0 = 1.0804e-04
Loss = 2.7255e-03, PNorm = 37.0232, GNorm = 4.3560, lr_0 = 1.0804e-04
Validation rmse logD = 0.648898
Validation R2 logD = 0.732081
Epoch 67
Train function
Loss = 2.6655e-03, PNorm = 37.0281, GNorm = 7.1748, lr_0 = 1.0804e-04
Loss = 2.5346e-03, PNorm = 37.0309, GNorm = 1.6743, lr_0 = 1.0804e-04
Loss = 2.3742e-03, PNorm = 37.0351, GNorm = 1.7236, lr_0 = 1.0804e-04
Loss = 2.3611e-03, PNorm = 37.0396, GNorm = 1.2814, lr_0 = 1.0804e-04
Loss = 2.2810e-03, PNorm = 37.0446, GNorm = 2.6886, lr_0 = 1.0804e-04
Loss = 2.4056e-03, PNorm = 37.0491, GNorm = 7.6562, lr_0 = 1.0804e-04
Validation rmse logD = 0.610699
Validation R2 logD = 0.762696
Epoch 68
Train function
Loss = 2.1907e-03, PNorm = 37.0536, GNorm = 2.1197, lr_0 = 1.0804e-04
Loss = 2.2151e-03, PNorm = 37.0570, GNorm = 2.1030, lr_0 = 1.0804e-04
Loss = 2.3661e-03, PNorm = 37.0607, GNorm = 4.1386, lr_0 = 1.0804e-04
Loss = 2.2917e-03, PNorm = 37.0646, GNorm = 1.8562, lr_0 = 1.0804e-04
Loss = 2.2477e-03, PNorm = 37.0691, GNorm = 2.0067, lr_0 = 1.0804e-04
Validation rmse logD = 0.595344
Validation R2 logD = 0.774479
Epoch 69
Train function
Loss = 2.3109e-03, PNorm = 37.0733, GNorm = 2.7973, lr_0 = 1.0804e-04
Loss = 1.9646e-03, PNorm = 37.0778, GNorm = 2.2929, lr_0 = 1.0804e-04
Loss = 2.4465e-03, PNorm = 37.0830, GNorm = 1.4997, lr_0 = 1.0804e-04
Loss = 2.1493e-03, PNorm = 37.0869, GNorm = 5.7473, lr_0 = 1.0804e-04
Loss = 1.9854e-03, PNorm = 37.0910, GNorm = 1.3160, lr_0 = 1.0804e-04
Loss = 2.4240e-03, PNorm = 37.0949, GNorm = 7.4458, lr_0 = 1.0804e-04
Validation rmse logD = 0.643745
Validation R2 logD = 0.736320
Epoch 70
Train function
Loss = 2.6256e-03, PNorm = 37.0994, GNorm = 5.4410, lr_0 = 1.0804e-04
Loss = 2.4118e-03, PNorm = 37.1039, GNorm = 3.3893, lr_0 = 1.0804e-04
Loss = 2.1964e-03, PNorm = 37.1088, GNorm = 5.0443, lr_0 = 1.0804e-04
Loss = 2.0320e-03, PNorm = 37.1126, GNorm = 9.6849, lr_0 = 1.0804e-04
Loss = 2.1618e-03, PNorm = 37.1162, GNorm = 1.9187, lr_0 = 1.0804e-04
Loss = 2.1470e-03, PNorm = 37.1198, GNorm = 2.0623, lr_0 = 1.0804e-04
Validation rmse logD = 0.607009
Validation R2 logD = 0.765555
Epoch 71
Train function
Loss = 1.7356e-03, PNorm = 37.1233, GNorm = 1.4695, lr_0 = 1.0804e-04
Loss = 2.1168e-03, PNorm = 37.1272, GNorm = 2.3106, lr_0 = 1.0804e-04
Loss = 2.2195e-03, PNorm = 37.1315, GNorm = 5.3031, lr_0 = 1.0804e-04
Loss = 2.3041e-03, PNorm = 37.1360, GNorm = 2.3040, lr_0 = 1.0804e-04
Loss = 2.1235e-03, PNorm = 37.1414, GNorm = 1.7475, lr_0 = 1.0804e-04
Validation rmse logD = 0.643082
Validation R2 logD = 0.736863
Epoch 72
Train function
Loss = 3.1609e-03, PNorm = 37.1454, GNorm = 1.8127, lr_0 = 1.0804e-04
Loss = 2.2090e-03, PNorm = 37.1493, GNorm = 8.4969, lr_0 = 1.0804e-04
Loss = 2.0503e-03, PNorm = 37.1529, GNorm = 1.6571, lr_0 = 1.0804e-04
Loss = 2.0195e-03, PNorm = 37.1574, GNorm = 1.7502, lr_0 = 1.0804e-04
Loss = 2.0541e-03, PNorm = 37.1617, GNorm = 2.8366, lr_0 = 1.0804e-04
Loss = 1.9789e-03, PNorm = 37.1658, GNorm = 2.7981, lr_0 = 1.0804e-04
Validation rmse logD = 0.606887
Validation R2 logD = 0.765649
Epoch 73
Train function
Loss = 2.2054e-03, PNorm = 37.1709, GNorm = 2.5381, lr_0 = 1.0804e-04
Loss = 1.9869e-03, PNorm = 37.1749, GNorm = 3.3246, lr_0 = 1.0804e-04
Loss = 1.9538e-03, PNorm = 37.1795, GNorm = 1.5685, lr_0 = 1.0804e-04
Loss = 2.1752e-03, PNorm = 37.1830, GNorm = 2.0858, lr_0 = 1.0804e-04
Loss = 2.0619e-03, PNorm = 37.1875, GNorm = 8.0193, lr_0 = 1.0804e-04
Loss = 2.3028e-03, PNorm = 37.1925, GNorm = 3.1356, lr_0 = 1.0804e-04
Validation rmse logD = 0.589522
Validation R2 logD = 0.778869
Epoch 74
Train function
Loss = 1.7916e-03, PNorm = 37.1963, GNorm = 1.4370, lr_0 = 1.0804e-04
Loss = 2.1605e-03, PNorm = 37.1994, GNorm = 1.6886, lr_0 = 1.0804e-04
Loss = 2.3958e-03, PNorm = 37.2025, GNorm = 4.0766, lr_0 = 1.0804e-04
Loss = 1.9064e-03, PNorm = 37.2060, GNorm = 1.6049, lr_0 = 1.0804e-04
Loss = 2.5011e-03, PNorm = 37.2107, GNorm = 2.7688, lr_0 = 1.0804e-04
Validation rmse logD = 0.587623
Validation R2 logD = 0.780291
Epoch 75
Train function
Loss = 1.6182e-03, PNorm = 37.2163, GNorm = 3.0277, lr_0 = 1.0804e-04
Loss = 1.9147e-03, PNorm = 37.2217, GNorm = 2.1444, lr_0 = 1.0804e-04
Loss = 2.3247e-03, PNorm = 37.2250, GNorm = 3.0218, lr_0 = 1.0804e-04
Loss = 1.9317e-03, PNorm = 37.2283, GNorm = 5.3846, lr_0 = 1.0804e-04
Loss = 1.9995e-03, PNorm = 37.2316, GNorm = 1.9306, lr_0 = 1.0804e-04
Loss = 2.1174e-03, PNorm = 37.2356, GNorm = 6.6541, lr_0 = 1.0804e-04
Validation rmse logD = 0.599834
Validation R2 logD = 0.771065
Epoch 76
Train function
Loss = 1.9646e-03, PNorm = 37.2407, GNorm = 3.5678, lr_0 = 1.0804e-04
Loss = 1.6428e-03, PNorm = 37.2450, GNorm = 2.3012, lr_0 = 1.0804e-04
Loss = 1.9205e-03, PNorm = 37.2487, GNorm = 3.1504, lr_0 = 1.0804e-04
Loss = 2.1546e-03, PNorm = 37.2525, GNorm = 1.6110, lr_0 = 1.0804e-04
Loss = 2.0313e-03, PNorm = 37.2560, GNorm = 1.7155, lr_0 = 1.0804e-04
Loss = 2.3407e-03, PNorm = 37.2600, GNorm = 5.3200, lr_0 = 1.0804e-04
Validation rmse logD = 0.603236
Validation R2 logD = 0.768461
Epoch 77
Train function
Loss = 1.9966e-03, PNorm = 37.2651, GNorm = 4.8252, lr_0 = 1.0804e-04
Loss = 1.9562e-03, PNorm = 37.2691, GNorm = 1.8372, lr_0 = 1.0804e-04
Loss = 1.8807e-03, PNorm = 37.2731, GNorm = 4.1245, lr_0 = 1.0804e-04
Loss = 2.1678e-03, PNorm = 37.2768, GNorm = 4.4607, lr_0 = 1.0804e-04
Loss = 2.3474e-03, PNorm = 37.2801, GNorm = 4.8586, lr_0 = 1.0804e-04
Validation rmse logD = 0.594215
Validation R2 logD = 0.775334
Epoch 78
Train function
Loss = 1.6786e-03, PNorm = 37.2839, GNorm = 7.6051, lr_0 = 1.0804e-04
Loss = 1.8810e-03, PNorm = 37.2878, GNorm = 1.2600, lr_0 = 1.0804e-04
Loss = 1.8566e-03, PNorm = 37.2915, GNorm = 3.6479, lr_0 = 1.0804e-04
Loss = 1.9559e-03, PNorm = 37.2957, GNorm = 2.0468, lr_0 = 1.0804e-04
Loss = 1.8915e-03, PNorm = 37.2995, GNorm = 1.4189, lr_0 = 1.0804e-04
Loss = 1.9712e-03, PNorm = 37.3037, GNorm = 2.8758, lr_0 = 1.0804e-04
Validation rmse logD = 0.595036
Validation R2 logD = 0.774713
Epoch 79
Train function
Loss = 1.8050e-03, PNorm = 37.3088, GNorm = 4.9718, lr_0 = 1.0804e-04
Loss = 1.7632e-03, PNorm = 37.3128, GNorm = 5.8780, lr_0 = 1.0804e-04
Loss = 1.9594e-03, PNorm = 37.3157, GNorm = 4.9626, lr_0 = 1.0804e-04
Loss = 1.9399e-03, PNorm = 37.3205, GNorm = 2.0833, lr_0 = 1.0804e-04
Loss = 1.9724e-03, PNorm = 37.3254, GNorm = 2.2850, lr_0 = 1.0804e-04
Loss = 1.8868e-03, PNorm = 37.3300, GNorm = 1.5170, lr_0 = 1.0804e-04
Validation rmse logD = 0.591771
Validation R2 logD = 0.777178
Epoch 80
Train function
Loss = 1.6491e-03, PNorm = 37.3335, GNorm = 1.6162, lr_0 = 1.0804e-04
Loss = 1.7171e-03, PNorm = 37.3371, GNorm = 2.9481, lr_0 = 1.0804e-04
Loss = 1.8749e-03, PNorm = 37.3406, GNorm = 2.4003, lr_0 = 1.0804e-04
Loss = 2.3138e-03, PNorm = 37.3451, GNorm = 5.0928, lr_0 = 1.0804e-04
Loss = 2.0853e-03, PNorm = 37.3505, GNorm = 2.7776, lr_0 = 1.0804e-04
Validation rmse logD = 0.612614
Validation R2 logD = 0.761206
Epoch 81
Train function
Loss = 2.0041e-03, PNorm = 37.3540, GNorm = 8.5269, lr_0 = 1.0804e-04
Loss = 1.9931e-03, PNorm = 37.3579, GNorm = 7.5591, lr_0 = 1.0804e-04
Loss = 2.0671e-03, PNorm = 37.3615, GNorm = 4.1207, lr_0 = 1.0804e-04
Loss = 2.2793e-03, PNorm = 37.3658, GNorm = 3.5587, lr_0 = 1.0804e-04
Loss = 1.7130e-03, PNorm = 37.3688, GNorm = 5.2651, lr_0 = 1.0804e-04
Loss = 2.0009e-03, PNorm = 37.3721, GNorm = 2.1948, lr_0 = 1.0804e-04
Validation rmse logD = 0.621548
Validation R2 logD = 0.754190
Epoch 82
Train function
Loss = 2.0593e-03, PNorm = 37.3767, GNorm = 2.9733, lr_0 = 1.0804e-04
Loss = 1.9624e-03, PNorm = 37.3823, GNorm = 2.1043, lr_0 = 1.0804e-04
Loss = 1.5294e-03, PNorm = 37.3861, GNorm = 3.2112, lr_0 = 1.0804e-04
Loss = 1.8335e-03, PNorm = 37.3902, GNorm = 1.7990, lr_0 = 1.0804e-04
Loss = 1.6990e-03, PNorm = 37.3936, GNorm = 1.2215, lr_0 = 1.0804e-04
Loss = 1.7583e-03, PNorm = 37.3968, GNorm = 2.9555, lr_0 = 1.0804e-04
Validation rmse logD = 0.607016
Validation R2 logD = 0.765550
Epoch 83
Train function
Loss = 1.5651e-03, PNorm = 37.3988, GNorm = 1.8038, lr_0 = 1.0804e-04
Loss = 1.9621e-03, PNorm = 37.4023, GNorm = 1.4713, lr_0 = 1.0804e-04
Loss = 1.5981e-03, PNorm = 37.4065, GNorm = 2.0590, lr_0 = 1.0804e-04
Loss = 1.8266e-03, PNorm = 37.4113, GNorm = 3.6022, lr_0 = 1.0804e-04
Loss = 1.7826e-03, PNorm = 37.4157, GNorm = 4.7597, lr_0 = 1.0804e-04
Validation rmse logD = 0.586676
Validation R2 logD = 0.780998
Epoch 84
Train function
Loss = 1.6164e-03, PNorm = 37.4205, GNorm = 3.0602, lr_0 = 1.0804e-04
Loss = 1.6187e-03, PNorm = 37.4235, GNorm = 1.7195, lr_0 = 1.0804e-04
Loss = 1.7107e-03, PNorm = 37.4266, GNorm = 1.6400, lr_0 = 1.0804e-04
Loss = 1.8819e-03, PNorm = 37.4301, GNorm = 2.0380, lr_0 = 1.0804e-04
Loss = 1.5582e-03, PNorm = 37.4336, GNorm = 3.6941, lr_0 = 1.0804e-04
Loss = 1.8382e-03, PNorm = 37.4382, GNorm = 3.0305, lr_0 = 1.0804e-04
Validation rmse logD = 0.589683
Validation R2 logD = 0.778748
Epoch 85
Train function
Loss = 1.6698e-03, PNorm = 37.4420, GNorm = 2.7390, lr_0 = 1.0804e-04
Loss = 1.6793e-03, PNorm = 37.4463, GNorm = 3.3770, lr_0 = 1.0804e-04
Loss = 1.8908e-03, PNorm = 37.4501, GNorm = 3.5146, lr_0 = 1.0804e-04
Loss = 1.8929e-03, PNorm = 37.4541, GNorm = 6.7175, lr_0 = 1.0804e-04
Loss = 1.9859e-03, PNorm = 37.4594, GNorm = 5.6246, lr_0 = 1.0804e-04
Loss = 1.7675e-03, PNorm = 37.4626, GNorm = 2.7218, lr_0 = 1.0804e-04
Validation rmse logD = 0.592360
Validation R2 logD = 0.776735
Epoch 86
Train function
Loss = 1.8901e-03, PNorm = 37.4654, GNorm = 2.1698, lr_0 = 1.0804e-04
Loss = 1.4603e-03, PNorm = 37.4687, GNorm = 2.7389, lr_0 = 1.0804e-04
Loss = 2.0228e-03, PNorm = 37.4722, GNorm = 1.8676, lr_0 = 1.0804e-04
Loss = 1.7138e-03, PNorm = 37.4760, GNorm = 1.3027, lr_0 = 1.0804e-04
Loss = 1.8964e-03, PNorm = 37.4800, GNorm = 1.6396, lr_0 = 1.0804e-04
Validation rmse logD = 0.588485
Validation R2 logD = 0.779646
Epoch 87
Train function
Loss = 1.6684e-03, PNorm = 37.4846, GNorm = 4.5693, lr_0 = 1.0804e-04
Loss = 1.7608e-03, PNorm = 37.4875, GNorm = 3.4594, lr_0 = 1.0804e-04
Loss = 1.6325e-03, PNorm = 37.4918, GNorm = 3.0866, lr_0 = 1.0804e-04
Loss = 1.7465e-03, PNorm = 37.4960, GNorm = 1.9787, lr_0 = 1.0804e-04
Loss = 1.7208e-03, PNorm = 37.5009, GNorm = 1.6058, lr_0 = 1.0804e-04
Loss = 1.6442e-03, PNorm = 37.5048, GNorm = 2.4825, lr_0 = 1.0804e-04
Validation rmse logD = 0.597578
Validation R2 logD = 0.772783
Epoch 88
Train function
Loss = 1.5610e-03, PNorm = 37.5085, GNorm = 6.3312, lr_0 = 1.0804e-04
Loss = 1.7279e-03, PNorm = 37.5114, GNorm = 3.5942, lr_0 = 1.0804e-04
Loss = 1.9013e-03, PNorm = 37.5148, GNorm = 2.6680, lr_0 = 1.0804e-04
Loss = 1.4314e-03, PNorm = 37.5182, GNorm = 2.7533, lr_0 = 1.0804e-04
Loss = 1.4377e-03, PNorm = 37.5222, GNorm = 2.4681, lr_0 = 1.0804e-04
Loss = 1.7551e-03, PNorm = 37.5262, GNorm = 3.6530, lr_0 = 1.0804e-04
Loss = 2.9490e-03, PNorm = 37.5267, GNorm = 2.3000, lr_0 = 1.0804e-04
Validation rmse logD = 0.624743
Validation R2 logD = 0.751657
Epoch 89
Train function
Loss = 1.6400e-03, PNorm = 37.5299, GNorm = 2.3735, lr_0 = 1.0804e-04
Loss = 1.8487e-03, PNorm = 37.5336, GNorm = 3.3537, lr_0 = 1.0804e-04
Loss = 1.7809e-03, PNorm = 37.5369, GNorm = 4.6024, lr_0 = 1.0804e-04
Loss = 1.6209e-03, PNorm = 37.5403, GNorm = 3.8039, lr_0 = 1.0804e-04
Loss = 1.7162e-03, PNorm = 37.5436, GNorm = 3.3601, lr_0 = 1.0804e-04
Validation rmse logD = 0.579137
Validation R2 logD = 0.786591
Epoch 90
Train function
Loss = 1.3708e-03, PNorm = 37.5474, GNorm = 3.4059, lr_0 = 1.0804e-04
Loss = 1.6855e-03, PNorm = 37.5511, GNorm = 6.9546, lr_0 = 1.0804e-04
Loss = 1.9349e-03, PNorm = 37.5542, GNorm = 2.2784, lr_0 = 1.0804e-04
Loss = 1.5639e-03, PNorm = 37.5585, GNorm = 3.3653, lr_0 = 1.0804e-04
Loss = 1.4821e-03, PNorm = 37.5624, GNorm = 1.7980, lr_0 = 1.0804e-04
Loss = 1.5764e-03, PNorm = 37.5663, GNorm = 1.6167, lr_0 = 1.0804e-04
Validation rmse logD = 0.609588
Validation R2 logD = 0.763559
Epoch 91
Train function
Loss = 1.5389e-03, PNorm = 37.5689, GNorm = 7.3523, lr_0 = 1.0804e-04
Loss = 1.8373e-03, PNorm = 37.5730, GNorm = 2.2578, lr_0 = 1.0804e-04
Loss = 1.5584e-03, PNorm = 37.5768, GNorm = 2.2794, lr_0 = 1.0804e-04
Loss = 1.5362e-03, PNorm = 37.5800, GNorm = 1.3385, lr_0 = 1.0804e-04
Loss = 1.4980e-03, PNorm = 37.5831, GNorm = 3.2135, lr_0 = 1.0804e-04
Loss = 1.5023e-03, PNorm = 37.5865, GNorm = 1.7297, lr_0 = 1.0804e-04
Loss = 1.4484e-03, PNorm = 37.5869, GNorm = 1.2159, lr_0 = 1.0804e-04
Validation rmse logD = 0.582254
Validation R2 logD = 0.784287
Epoch 92
Train function
Loss = 1.2627e-03, PNorm = 37.5906, GNorm = 5.7348, lr_0 = 1.0804e-04
Loss = 1.6867e-03, PNorm = 37.5936, GNorm = 2.7985, lr_0 = 1.0804e-04
Loss = 1.6590e-03, PNorm = 37.5964, GNorm = 3.5572, lr_0 = 1.0804e-04
Loss = 1.8591e-03, PNorm = 37.5999, GNorm = 1.9533, lr_0 = 1.0804e-04
Loss = 1.4467e-03, PNorm = 37.6046, GNorm = 1.3757, lr_0 = 1.0804e-04
Validation rmse logD = 0.633105
Validation R2 logD = 0.744963
Epoch 93
Train function
Loss = 1.7672e-03, PNorm = 37.6090, GNorm = 1.6112, lr_0 = 1.0804e-04
Loss = 1.6871e-03, PNorm = 37.6132, GNorm = 2.3618, lr_0 = 1.0804e-04
Loss = 1.8466e-03, PNorm = 37.6152, GNorm = 5.4571, lr_0 = 1.0804e-04
Loss = 1.8529e-03, PNorm = 37.6177, GNorm = 6.8948, lr_0 = 1.0804e-04
Loss = 1.5519e-03, PNorm = 37.6218, GNorm = 2.0444, lr_0 = 1.0804e-04
Loss = 1.3511e-03, PNorm = 37.6250, GNorm = 3.2036, lr_0 = 1.0804e-04
Validation rmse logD = 0.602083
Validation R2 logD = 0.769345
Epoch 94
Train function
Loss = 1.4089e-03, PNorm = 37.6291, GNorm = 2.4044, lr_0 = 1.0804e-04
Loss = 1.6203e-03, PNorm = 37.6329, GNorm = 2.2322, lr_0 = 1.0804e-04
Loss = 1.7459e-03, PNorm = 37.6371, GNorm = 1.2858, lr_0 = 1.0804e-04
Loss = 1.5261e-03, PNorm = 37.6412, GNorm = 4.1839, lr_0 = 1.0804e-04
Loss = 1.5365e-03, PNorm = 37.6451, GNorm = 3.7541, lr_0 = 1.0804e-04
Loss = 1.3610e-03, PNorm = 37.6486, GNorm = 4.0490, lr_0 = 1.0804e-04
Loss = 1.4286e-03, PNorm = 37.6488, GNorm = 1.3070, lr_0 = 1.0804e-04
Validation rmse logD = 0.584017
Validation R2 logD = 0.782979
Epoch 95
Train function
Loss = 1.4693e-03, PNorm = 37.6514, GNorm = 5.3263, lr_0 = 1.0804e-04
Loss = 1.7948e-03, PNorm = 37.6533, GNorm = 8.9147, lr_0 = 1.0804e-04
Loss = 1.8315e-03, PNorm = 37.6566, GNorm = 8.1311, lr_0 = 1.0804e-04
Loss = 1.6029e-03, PNorm = 37.6601, GNorm = 2.0617, lr_0 = 1.0804e-04
Loss = 1.6692e-03, PNorm = 37.6648, GNorm = 4.3711, lr_0 = 1.0804e-04
Validation rmse logD = 0.596725
Validation R2 logD = 0.773432
Epoch 96
Train function
Loss = 1.0963e-03, PNorm = 37.6687, GNorm = 2.7586, lr_0 = 1.0804e-04
Loss = 1.5418e-03, PNorm = 37.6725, GNorm = 2.7651, lr_0 = 1.0804e-04
Loss = 1.4637e-03, PNorm = 37.6765, GNorm = 2.5463, lr_0 = 1.0804e-04
Loss = 1.6203e-03, PNorm = 37.6803, GNorm = 4.2732, lr_0 = 1.0804e-04
Loss = 1.5626e-03, PNorm = 37.6833, GNorm = 4.7055, lr_0 = 1.0804e-04
Loss = 1.3811e-03, PNorm = 37.6861, GNorm = 2.5456, lr_0 = 1.0804e-04
Validation rmse logD = 0.584174
Validation R2 logD = 0.782863
Epoch 97
Train function
Loss = 1.2953e-03, PNorm = 37.6890, GNorm = 4.7410, lr_0 = 1.0804e-04
Loss = 1.5491e-03, PNorm = 37.6923, GNorm = 6.3601, lr_0 = 1.0804e-04
Loss = 1.4256e-03, PNorm = 37.6961, GNorm = 3.1151, lr_0 = 1.0804e-04
Loss = 1.5928e-03, PNorm = 37.6994, GNorm = 2.0986, lr_0 = 1.0804e-04
Loss = 1.4089e-03, PNorm = 37.7038, GNorm = 2.7473, lr_0 = 1.0804e-04
Loss = 1.6111e-03, PNorm = 37.7082, GNorm = 1.8345, lr_0 = 1.0804e-04
Loss = 3.3755e-03, PNorm = 37.7083, GNorm = 7.0306, lr_0 = 1.0804e-04
Validation rmse logD = 0.591302
Validation R2 logD = 0.777531
Epoch 98
Train function
Loss = 1.4680e-03, PNorm = 37.7107, GNorm = 5.2936, lr_0 = 1.0804e-04
Loss = 1.6227e-03, PNorm = 37.7145, GNorm = 1.6404, lr_0 = 1.0804e-04
Loss = 1.2435e-03, PNorm = 37.7183, GNorm = 4.3447, lr_0 = 1.0804e-04
Loss = 1.6124e-03, PNorm = 37.7212, GNorm = 1.6540, lr_0 = 1.0804e-04
Loss = 1.3960e-03, PNorm = 37.7246, GNorm = 2.2511, lr_0 = 1.0804e-04
Validation rmse logD = 0.575526
Validation R2 logD = 0.789244
Epoch 99
Train function
Loss = 1.0920e-03, PNorm = 37.7275, GNorm = 4.5074, lr_0 = 1.0804e-04
Loss = 1.2071e-03, PNorm = 37.7310, GNorm = 1.7832, lr_0 = 1.0804e-04
Loss = 1.4502e-03, PNorm = 37.7341, GNorm = 2.4996, lr_0 = 1.0804e-04
Loss = 1.4805e-03, PNorm = 37.7383, GNorm = 3.8148, lr_0 = 1.0804e-04
Loss = 1.5582e-03, PNorm = 37.7414, GNorm = 4.0942, lr_0 = 1.0804e-04
Loss = 1.5670e-03, PNorm = 37.7445, GNorm = 2.2166, lr_0 = 1.0804e-04
Validation rmse logD = 0.608330
Validation R2 logD = 0.764534
Model 0 best validation rmse = 0.575526 on epoch 98
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.615328
Model 0 test R2 logD = 0.765592
Ensemble test rmse  logD= 0.615328
Ensemble test R2  logD= 0.765592
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_365/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2832,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.4169e-02, PNorm = 35.0058, GNorm = 4.7732, lr_0 = 1.0804e-04
Loss = 1.9789e-02, PNorm = 35.0060, GNorm = 2.9308, lr_0 = 1.0804e-04
Loss = 1.9278e-02, PNorm = 35.0072, GNorm = 2.2767, lr_0 = 1.0804e-04
Loss = 1.5378e-02, PNorm = 35.0090, GNorm = 3.1177, lr_0 = 1.0804e-04
Loss = 1.5535e-02, PNorm = 35.0110, GNorm = 3.0306, lr_0 = 1.0804e-04
Validation rmse logD = 1.076390
Validation R2 logD = 0.214532
Epoch 1
Train function
Loss = 1.3010e-02, PNorm = 35.0136, GNorm = 4.3412, lr_0 = 1.0804e-04
Loss = 1.5238e-02, PNorm = 35.0162, GNorm = 1.4932, lr_0 = 1.0804e-04
Loss = 1.5280e-02, PNorm = 35.0189, GNorm = 2.6804, lr_0 = 1.0804e-04
Loss = 1.4320e-02, PNorm = 35.0217, GNorm = 3.2831, lr_0 = 1.0804e-04
Loss = 1.4032e-02, PNorm = 35.0242, GNorm = 2.9601, lr_0 = 1.0804e-04
Loss = 1.4269e-02, PNorm = 35.0278, GNorm = 2.7217, lr_0 = 1.0804e-04
Validation rmse logD = 1.017004
Validation R2 logD = 0.298813
Epoch 2
Train function
Loss = 1.3424e-02, PNorm = 35.0312, GNorm = 2.5346, lr_0 = 1.0804e-04
Loss = 1.3044e-02, PNorm = 35.0347, GNorm = 5.3125, lr_0 = 1.0804e-04
Loss = 1.2258e-02, PNorm = 35.0380, GNorm = 5.1016, lr_0 = 1.0804e-04
Loss = 1.2266e-02, PNorm = 35.0414, GNorm = 2.5007, lr_0 = 1.0804e-04
Loss = 1.3158e-02, PNorm = 35.0451, GNorm = 4.4826, lr_0 = 1.0804e-04
Validation rmse logD = 0.954161
Validation R2 logD = 0.382790
Epoch 3
Train function
Loss = 1.1357e-02, PNorm = 35.0496, GNorm = 3.9452, lr_0 = 1.0804e-04
Loss = 1.2317e-02, PNorm = 35.0543, GNorm = 3.6466, lr_0 = 1.0804e-04
Loss = 1.0674e-02, PNorm = 35.0574, GNorm = 5.4975, lr_0 = 1.0804e-04
Loss = 1.1342e-02, PNorm = 35.0605, GNorm = 4.2540, lr_0 = 1.0804e-04
Loss = 1.1891e-02, PNorm = 35.0646, GNorm = 6.8730, lr_0 = 1.0804e-04
Loss = 1.1616e-02, PNorm = 35.0699, GNorm = 2.2195, lr_0 = 1.0804e-04
Validation rmse logD = 0.919653
Validation R2 logD = 0.426628
Epoch 4
Train function
Loss = 1.0763e-02, PNorm = 35.0753, GNorm = 2.1000, lr_0 = 1.0804e-04
Loss = 1.0911e-02, PNorm = 35.0799, GNorm = 3.1894, lr_0 = 1.0804e-04
Loss = 1.2341e-02, PNorm = 35.0840, GNorm = 3.8642, lr_0 = 1.0804e-04
Loss = 1.0601e-02, PNorm = 35.0886, GNorm = 4.2436, lr_0 = 1.0804e-04
Loss = 1.0211e-02, PNorm = 35.0939, GNorm = 3.3062, lr_0 = 1.0804e-04
Loss = 9.7232e-03, PNorm = 35.0988, GNorm = 2.1156, lr_0 = 1.0804e-04
Validation rmse logD = 0.893913
Validation R2 logD = 0.458274
Epoch 5
Train function
Loss = 9.0539e-03, PNorm = 35.1038, GNorm = 2.8643, lr_0 = 1.0804e-04
Loss = 1.0144e-02, PNorm = 35.1088, GNorm = 3.2367, lr_0 = 1.0804e-04
Loss = 1.0148e-02, PNorm = 35.1144, GNorm = 1.9398, lr_0 = 1.0804e-04
Loss = 1.0785e-02, PNorm = 35.1197, GNorm = 2.0381, lr_0 = 1.0804e-04
Loss = 9.9714e-03, PNorm = 35.1248, GNorm = 2.1174, lr_0 = 1.0804e-04
Validation rmse logD = 0.907475
Validation R2 logD = 0.441712
Epoch 6
Train function
Loss = 6.5941e-03, PNorm = 35.1310, GNorm = 2.3674, lr_0 = 1.0804e-04
Loss = 9.9269e-03, PNorm = 35.1374, GNorm = 3.4007, lr_0 = 1.0804e-04
Loss = 9.3081e-03, PNorm = 35.1445, GNorm = 2.2518, lr_0 = 1.0804e-04
Loss = 9.9045e-03, PNorm = 35.1509, GNorm = 1.3643, lr_0 = 1.0804e-04
Loss = 1.0047e-02, PNorm = 35.1557, GNorm = 7.0067, lr_0 = 1.0804e-04
Loss = 9.7082e-03, PNorm = 35.1594, GNorm = 3.4925, lr_0 = 1.0804e-04
Validation rmse logD = 0.869011
Validation R2 logD = 0.488036
Epoch 7
Train function
Loss = 6.9373e-03, PNorm = 35.1640, GNorm = 1.7224, lr_0 = 1.0804e-04
Loss = 8.7414e-03, PNorm = 35.1691, GNorm = 1.8081, lr_0 = 1.0804e-04
Loss = 9.3439e-03, PNorm = 35.1752, GNorm = 2.3983, lr_0 = 1.0804e-04
Loss = 9.0913e-03, PNorm = 35.1820, GNorm = 4.7792, lr_0 = 1.0804e-04
Loss = 9.8356e-03, PNorm = 35.1879, GNorm = 2.1436, lr_0 = 1.0804e-04
Loss = 9.5456e-03, PNorm = 35.1933, GNorm = 1.3504, lr_0 = 1.0804e-04
Validation rmse logD = 0.911978
Validation R2 logD = 0.436158
Epoch 8
Train function
Loss = 8.1665e-03, PNorm = 35.1993, GNorm = 3.7085, lr_0 = 1.0804e-04
Loss = 9.4040e-03, PNorm = 35.2044, GNorm = 2.5826, lr_0 = 1.0804e-04
Loss = 9.1825e-03, PNorm = 35.2110, GNorm = 3.2623, lr_0 = 1.0804e-04
Loss = 8.7005e-03, PNorm = 35.2178, GNorm = 8.4169, lr_0 = 1.0804e-04
Loss = 9.8982e-03, PNorm = 35.2221, GNorm = 6.3877, lr_0 = 1.0804e-04
Validation rmse logD = 0.925305
Validation R2 logD = 0.419557
Epoch 9
Train function
Loss = 7.9713e-03, PNorm = 35.2267, GNorm = 7.1473, lr_0 = 1.0804e-04
Loss = 8.7529e-03, PNorm = 35.2322, GNorm = 2.7189, lr_0 = 1.0804e-04
Loss = 1.0183e-02, PNorm = 35.2390, GNorm = 4.9765, lr_0 = 1.0804e-04
Loss = 8.4783e-03, PNorm = 35.2448, GNorm = 2.3217, lr_0 = 1.0804e-04
Loss = 7.8343e-03, PNorm = 35.2517, GNorm = 1.2748, lr_0 = 1.0804e-04
Loss = 8.8098e-03, PNorm = 35.2568, GNorm = 3.7239, lr_0 = 1.0804e-04
Validation rmse logD = 0.828495
Validation R2 logD = 0.534662
Epoch 10
Train function
Loss = 8.9086e-03, PNorm = 35.2612, GNorm = 7.5887, lr_0 = 1.0804e-04
Loss = 9.0710e-03, PNorm = 35.2660, GNorm = 1.9233, lr_0 = 1.0804e-04
Loss = 8.2165e-03, PNorm = 35.2721, GNorm = 1.6257, lr_0 = 1.0804e-04
Loss = 8.3637e-03, PNorm = 35.2789, GNorm = 1.2409, lr_0 = 1.0804e-04
Loss = 6.9005e-03, PNorm = 35.2869, GNorm = 3.9994, lr_0 = 1.0804e-04
Loss = 7.4564e-03, PNorm = 35.2940, GNorm = 3.5940, lr_0 = 1.0804e-04
Validation rmse logD = 0.927163
Validation R2 logD = 0.417224
Epoch 11
Train function
Loss = 9.3296e-03, PNorm = 35.3000, GNorm = 7.4186, lr_0 = 1.0804e-04
Loss = 8.2593e-03, PNorm = 35.3057, GNorm = 4.8395, lr_0 = 1.0804e-04
Loss = 7.2987e-03, PNorm = 35.3115, GNorm = 1.9852, lr_0 = 1.0804e-04
Loss = 8.4935e-03, PNorm = 35.3176, GNorm = 4.1879, lr_0 = 1.0804e-04
Loss = 7.5994e-03, PNorm = 35.3236, GNorm = 1.3723, lr_0 = 1.0804e-04
Validation rmse logD = 0.813179
Validation R2 logD = 0.551708
Epoch 12
Train function
Loss = 1.0750e-02, PNorm = 35.3298, GNorm = 3.5693, lr_0 = 1.0804e-04
Loss = 7.4998e-03, PNorm = 35.3361, GNorm = 2.7863, lr_0 = 1.0804e-04
Loss = 7.7077e-03, PNorm = 35.3433, GNorm = 1.6886, lr_0 = 1.0804e-04
Loss = 7.4982e-03, PNorm = 35.3503, GNorm = 3.6736, lr_0 = 1.0804e-04
Loss = 7.1514e-03, PNorm = 35.3574, GNorm = 4.9780, lr_0 = 1.0804e-04
Loss = 7.2900e-03, PNorm = 35.3638, GNorm = 1.3890, lr_0 = 1.0804e-04
Validation rmse logD = 0.797762
Validation R2 logD = 0.568545
Epoch 13
Train function
Loss = 6.0329e-03, PNorm = 35.3707, GNorm = 3.3775, lr_0 = 1.0804e-04
Loss = 7.7548e-03, PNorm = 35.3779, GNorm = 6.3990, lr_0 = 1.0804e-04
Loss = 7.1438e-03, PNorm = 35.3847, GNorm = 4.2055, lr_0 = 1.0804e-04
Loss = 8.0227e-03, PNorm = 35.3920, GNorm = 1.2921, lr_0 = 1.0804e-04
Loss = 7.1032e-03, PNorm = 35.3981, GNorm = 1.6624, lr_0 = 1.0804e-04
Loss = 6.5638e-03, PNorm = 35.4055, GNorm = 1.7578, lr_0 = 1.0804e-04
Validation rmse logD = 0.812472
Validation R2 logD = 0.552487
Epoch 14
Train function
Loss = 7.3671e-03, PNorm = 35.4128, GNorm = 1.9635, lr_0 = 1.0804e-04
Loss = 7.1518e-03, PNorm = 35.4210, GNorm = 5.6703, lr_0 = 1.0804e-04
Loss = 6.3514e-03, PNorm = 35.4283, GNorm = 1.5279, lr_0 = 1.0804e-04
Loss = 6.4572e-03, PNorm = 35.4355, GNorm = 1.9930, lr_0 = 1.0804e-04
Loss = 7.2398e-03, PNorm = 35.4428, GNorm = 4.6149, lr_0 = 1.0804e-04
Validation rmse logD = 0.781638
Validation R2 logD = 0.585809
Epoch 15
Train function
Loss = 2.8955e-03, PNorm = 35.4510, GNorm = 2.2775, lr_0 = 1.0804e-04
Loss = 6.8077e-03, PNorm = 35.4575, GNorm = 1.4864, lr_0 = 1.0804e-04
Loss = 7.7631e-03, PNorm = 35.4646, GNorm = 9.0630, lr_0 = 1.0804e-04
Loss = 7.1331e-03, PNorm = 35.4711, GNorm = 2.8810, lr_0 = 1.0804e-04
Loss = 6.2923e-03, PNorm = 35.4774, GNorm = 3.9991, lr_0 = 1.0804e-04
Loss = 6.7179e-03, PNorm = 35.4837, GNorm = 2.9515, lr_0 = 1.0804e-04
Validation rmse logD = 0.789917
Validation R2 logD = 0.576988
Epoch 16
Train function
Loss = 6.0925e-03, PNorm = 35.4914, GNorm = 1.7540, lr_0 = 1.0804e-04
Loss = 7.6196e-03, PNorm = 35.4994, GNorm = 2.2183, lr_0 = 1.0804e-04
Loss = 6.7703e-03, PNorm = 35.5063, GNorm = 2.7745, lr_0 = 1.0804e-04
Loss = 6.5173e-03, PNorm = 35.5134, GNorm = 1.5716, lr_0 = 1.0804e-04
Loss = 5.7413e-03, PNorm = 35.5212, GNorm = 4.7955, lr_0 = 1.0804e-04
Loss = 5.8809e-03, PNorm = 35.5284, GNorm = 4.1484, lr_0 = 1.0804e-04
Validation rmse logD = 0.765907
Validation R2 logD = 0.602314
Epoch 17
Train function
Loss = 5.9583e-03, PNorm = 35.5352, GNorm = 2.4531, lr_0 = 1.0804e-04
Loss = 6.1448e-03, PNorm = 35.5435, GNorm = 2.6497, lr_0 = 1.0804e-04
Loss = 5.6239e-03, PNorm = 35.5513, GNorm = 2.8307, lr_0 = 1.0804e-04
Loss = 7.2185e-03, PNorm = 35.5576, GNorm = 5.2056, lr_0 = 1.0804e-04
Loss = 7.8721e-03, PNorm = 35.5644, GNorm = 3.1849, lr_0 = 1.0804e-04
Validation rmse logD = 0.804642
Validation R2 logD = 0.561071
Epoch 18
Train function
Loss = 4.4051e-03, PNorm = 35.5711, GNorm = 3.0920, lr_0 = 1.0804e-04
Loss = 6.5958e-03, PNorm = 35.5774, GNorm = 1.5956, lr_0 = 1.0804e-04
Loss = 5.9650e-03, PNorm = 35.5845, GNorm = 7.9196, lr_0 = 1.0804e-04
Loss = 6.1815e-03, PNorm = 35.5916, GNorm = 1.6547, lr_0 = 1.0804e-04
Loss = 6.4031e-03, PNorm = 35.5992, GNorm = 5.2634, lr_0 = 1.0804e-04
Loss = 5.4642e-03, PNorm = 35.6072, GNorm = 1.4951, lr_0 = 1.0804e-04
Validation rmse logD = 0.773123
Validation R2 logD = 0.594785
Epoch 19
Train function
Loss = 6.7450e-03, PNorm = 35.6137, GNorm = 2.5365, lr_0 = 1.0804e-04
Loss = 5.8377e-03, PNorm = 35.6209, GNorm = 7.2508, lr_0 = 1.0804e-04
Loss = 7.0014e-03, PNorm = 35.6288, GNorm = 7.0960, lr_0 = 1.0804e-04
Loss = 5.6326e-03, PNorm = 35.6351, GNorm = 3.5715, lr_0 = 1.0804e-04
Loss = 5.7633e-03, PNorm = 35.6426, GNorm = 1.8233, lr_0 = 1.0804e-04
Loss = 5.0454e-03, PNorm = 35.6497, GNorm = 2.6907, lr_0 = 1.0804e-04
Validation rmse logD = 0.757270
Validation R2 logD = 0.611232
Epoch 20
Train function
Loss = 5.4103e-03, PNorm = 35.6571, GNorm = 3.1378, lr_0 = 1.0804e-04
Loss = 5.6953e-03, PNorm = 35.6648, GNorm = 2.5861, lr_0 = 1.0804e-04
Loss = 5.5522e-03, PNorm = 35.6712, GNorm = 1.5909, lr_0 = 1.0804e-04
Loss = 5.2588e-03, PNorm = 35.6780, GNorm = 5.0937, lr_0 = 1.0804e-04
Loss = 5.8843e-03, PNorm = 35.6855, GNorm = 3.1971, lr_0 = 1.0804e-04
Validation rmse logD = 0.757339
Validation R2 logD = 0.611161
Epoch 21
Train function
Loss = 5.1094e-03, PNorm = 35.6929, GNorm = 1.7810, lr_0 = 1.0804e-04
Loss = 5.6951e-03, PNorm = 35.7005, GNorm = 4.8672, lr_0 = 1.0804e-04
Loss = 5.0079e-03, PNorm = 35.7075, GNorm = 4.9863, lr_0 = 1.0804e-04
Loss = 5.9483e-03, PNorm = 35.7156, GNorm = 8.3851, lr_0 = 1.0804e-04
Loss = 5.6001e-03, PNorm = 35.7221, GNorm = 2.6498, lr_0 = 1.0804e-04
Loss = 5.7139e-03, PNorm = 35.7274, GNorm = 6.3980, lr_0 = 1.0804e-04
Validation rmse logD = 0.748572
Validation R2 logD = 0.620112
Epoch 22
Train function
Loss = 5.8341e-03, PNorm = 35.7336, GNorm = 3.5420, lr_0 = 1.0804e-04
Loss = 5.5094e-03, PNorm = 35.7403, GNorm = 2.6654, lr_0 = 1.0804e-04
Loss = 4.8623e-03, PNorm = 35.7467, GNorm = 3.1173, lr_0 = 1.0804e-04
Loss = 5.5463e-03, PNorm = 35.7534, GNorm = 3.0752, lr_0 = 1.0804e-04
Loss = 4.2566e-03, PNorm = 35.7598, GNorm = 1.2860, lr_0 = 1.0804e-04
Loss = 5.9020e-03, PNorm = 35.7669, GNorm = 7.1615, lr_0 = 1.0804e-04
Validation rmse logD = 0.762260
Validation R2 logD = 0.606091
Epoch 23
Train function
Loss = 5.3756e-03, PNorm = 35.7732, GNorm = 7.0024, lr_0 = 1.0804e-04
Loss = 4.8681e-03, PNorm = 35.7779, GNorm = 5.6197, lr_0 = 1.0804e-04
Loss = 5.1501e-03, PNorm = 35.7835, GNorm = 1.5444, lr_0 = 1.0804e-04
Loss = 5.6864e-03, PNorm = 35.7893, GNorm = 1.3582, lr_0 = 1.0804e-04
Loss = 4.8094e-03, PNorm = 35.7968, GNorm = 2.5942, lr_0 = 1.0804e-04
Validation rmse logD = 0.723967
Validation R2 logD = 0.644674
Epoch 24
Train function
Loss = 4.0373e-03, PNorm = 35.8047, GNorm = 3.0896, lr_0 = 1.0804e-04
Loss = 4.8345e-03, PNorm = 35.8110, GNorm = 2.4483, lr_0 = 1.0804e-04
Loss = 5.4081e-03, PNorm = 35.8180, GNorm = 2.7782, lr_0 = 1.0804e-04
Loss = 5.4832e-03, PNorm = 35.8242, GNorm = 7.8573, lr_0 = 1.0804e-04
Loss = 4.9782e-03, PNorm = 35.8303, GNorm = 5.3520, lr_0 = 1.0804e-04
Loss = 4.6539e-03, PNorm = 35.8363, GNorm = 3.1613, lr_0 = 1.0804e-04
Validation rmse logD = 0.753590
Validation R2 logD = 0.615001
Epoch 25
Train function
Loss = 4.3580e-03, PNorm = 35.8426, GNorm = 1.3360, lr_0 = 1.0804e-04
Loss = 4.2141e-03, PNorm = 35.8500, GNorm = 3.0563, lr_0 = 1.0804e-04
Loss = 5.9467e-03, PNorm = 35.8569, GNorm = 2.4448, lr_0 = 1.0804e-04
Loss = 5.1513e-03, PNorm = 35.8626, GNorm = 2.0104, lr_0 = 1.0804e-04
Loss = 4.7353e-03, PNorm = 35.8674, GNorm = 7.2634, lr_0 = 1.0804e-04
Loss = 4.4873e-03, PNorm = 35.8731, GNorm = 3.4208, lr_0 = 1.0804e-04
Validation rmse logD = 0.743173
Validation R2 logD = 0.625572
Epoch 26
Train function
Loss = 4.3508e-03, PNorm = 35.8812, GNorm = 6.3153, lr_0 = 1.0804e-04
Loss = 5.0729e-03, PNorm = 35.8867, GNorm = 6.3043, lr_0 = 1.0804e-04
Loss = 5.1063e-03, PNorm = 35.8936, GNorm = 1.7654, lr_0 = 1.0804e-04
Loss = 4.9082e-03, PNorm = 35.8999, GNorm = 1.3038, lr_0 = 1.0804e-04
Loss = 4.7325e-03, PNorm = 35.9058, GNorm = 2.3736, lr_0 = 1.0804e-04
Validation rmse logD = 0.724338
Validation R2 logD = 0.644310
Epoch 27
Train function
Loss = 6.3455e-03, PNorm = 35.9117, GNorm = 5.2511, lr_0 = 1.0804e-04
Loss = 4.8444e-03, PNorm = 35.9172, GNorm = 3.9251, lr_0 = 1.0804e-04
Loss = 4.7001e-03, PNorm = 35.9218, GNorm = 4.0480, lr_0 = 1.0804e-04
Loss = 4.9293e-03, PNorm = 35.9281, GNorm = 1.9398, lr_0 = 1.0804e-04
Loss = 4.4136e-03, PNorm = 35.9360, GNorm = 3.1560, lr_0 = 1.0804e-04
Loss = 4.4018e-03, PNorm = 35.9419, GNorm = 2.0641, lr_0 = 1.0804e-04
Validation rmse logD = 0.716541
Validation R2 logD = 0.651926
Epoch 28
Train function
Loss = 4.8415e-03, PNorm = 35.9480, GNorm = 4.9068, lr_0 = 1.0804e-04
Loss = 4.1802e-03, PNorm = 35.9552, GNorm = 5.7584, lr_0 = 1.0804e-04
Loss = 4.6687e-03, PNorm = 35.9606, GNorm = 8.3577, lr_0 = 1.0804e-04
Loss = 5.3151e-03, PNorm = 35.9650, GNorm = 5.8170, lr_0 = 1.0804e-04
Loss = 3.9662e-03, PNorm = 35.9709, GNorm = 3.6257, lr_0 = 1.0804e-04
Loss = 4.5103e-03, PNorm = 35.9760, GNorm = 1.7018, lr_0 = 1.0804e-04
Validation rmse logD = 0.737989
Validation R2 logD = 0.630777
Epoch 29
Train function
Loss = 3.8091e-03, PNorm = 35.9808, GNorm = 1.6617, lr_0 = 1.0804e-04
Loss = 4.7307e-03, PNorm = 35.9861, GNorm = 4.6374, lr_0 = 1.0804e-04
Loss = 4.5789e-03, PNorm = 35.9909, GNorm = 2.9261, lr_0 = 1.0804e-04
Loss = 3.9790e-03, PNorm = 35.9976, GNorm = 1.7857, lr_0 = 1.0804e-04
Loss = 4.4340e-03, PNorm = 36.0031, GNorm = 6.3603, lr_0 = 1.0804e-04
Validation rmse logD = 0.700571
Validation R2 logD = 0.667269
Epoch 30
Train function
Loss = 4.0629e-03, PNorm = 36.0101, GNorm = 6.1599, lr_0 = 1.0804e-04
Loss = 4.2703e-03, PNorm = 36.0162, GNorm = 2.2186, lr_0 = 1.0804e-04
Loss = 4.8675e-03, PNorm = 36.0216, GNorm = 4.3672, lr_0 = 1.0804e-04
Loss = 3.8090e-03, PNorm = 36.0283, GNorm = 3.7463, lr_0 = 1.0804e-04
Loss = 3.5984e-03, PNorm = 36.0348, GNorm = 1.6861, lr_0 = 1.0804e-04
Loss = 5.2958e-03, PNorm = 36.0389, GNorm = 12.3966, lr_0 = 1.0804e-04
Validation rmse logD = 0.699912
Validation R2 logD = 0.667895
Epoch 31
Train function
Loss = 5.4103e-03, PNorm = 36.0438, GNorm = 4.8463, lr_0 = 1.0804e-04
Loss = 3.9536e-03, PNorm = 36.0498, GNorm = 2.5187, lr_0 = 1.0804e-04
Loss = 4.6053e-03, PNorm = 36.0569, GNorm = 2.8255, lr_0 = 1.0804e-04
Loss = 4.1181e-03, PNorm = 36.0626, GNorm = 7.6427, lr_0 = 1.0804e-04
Loss = 3.7783e-03, PNorm = 36.0661, GNorm = 4.1228, lr_0 = 1.0804e-04
Loss = 4.4597e-03, PNorm = 36.0698, GNorm = 1.6445, lr_0 = 1.0804e-04
Validation rmse logD = 0.705154
Validation R2 logD = 0.662901
Epoch 32
Train function
Loss = 4.6825e-03, PNorm = 36.0749, GNorm = 2.9740, lr_0 = 1.0804e-04
Loss = 3.6471e-03, PNorm = 36.0818, GNorm = 2.1648, lr_0 = 1.0804e-04
Loss = 4.2309e-03, PNorm = 36.0880, GNorm = 7.2133, lr_0 = 1.0804e-04
Loss = 3.6986e-03, PNorm = 36.0931, GNorm = 3.9807, lr_0 = 1.0804e-04
Loss = 4.5928e-03, PNorm = 36.0973, GNorm = 7.0795, lr_0 = 1.0804e-04
Validation rmse logD = 0.698890
Validation R2 logD = 0.668864
Epoch 33
Train function
Loss = 3.2571e-03, PNorm = 36.1013, GNorm = 1.2973, lr_0 = 1.0804e-04
Loss = 4.3924e-03, PNorm = 36.1073, GNorm = 3.7316, lr_0 = 1.0804e-04
Loss = 3.8786e-03, PNorm = 36.1130, GNorm = 2.6899, lr_0 = 1.0804e-04
Loss = 4.1008e-03, PNorm = 36.1187, GNorm = 5.1323, lr_0 = 1.0804e-04
Loss = 3.5498e-03, PNorm = 36.1246, GNorm = 2.2337, lr_0 = 1.0804e-04
Loss = 4.1952e-03, PNorm = 36.1296, GNorm = 1.5645, lr_0 = 1.0804e-04
Validation rmse logD = 0.699478
Validation R2 logD = 0.668306
Epoch 34
Train function
Loss = 4.4059e-03, PNorm = 36.1348, GNorm = 2.0668, lr_0 = 1.0804e-04
Loss = 3.8705e-03, PNorm = 36.1394, GNorm = 7.9144, lr_0 = 1.0804e-04
Loss = 4.2491e-03, PNorm = 36.1453, GNorm = 5.2061, lr_0 = 1.0804e-04
Loss = 3.9036e-03, PNorm = 36.1515, GNorm = 5.7767, lr_0 = 1.0804e-04
Loss = 3.7629e-03, PNorm = 36.1570, GNorm = 1.2661, lr_0 = 1.0804e-04
Loss = 3.5880e-03, PNorm = 36.1616, GNorm = 4.3808, lr_0 = 1.0804e-04
Validation rmse logD = 0.701474
Validation R2 logD = 0.666411
Epoch 35
Train function
Loss = 3.9316e-03, PNorm = 36.1653, GNorm = 2.4457, lr_0 = 1.0804e-04
Loss = 3.6471e-03, PNorm = 36.1709, GNorm = 2.8892, lr_0 = 1.0804e-04
Loss = 4.2756e-03, PNorm = 36.1751, GNorm = 3.9769, lr_0 = 1.0804e-04
Loss = 3.6035e-03, PNorm = 36.1787, GNorm = 1.7472, lr_0 = 1.0804e-04
Loss = 3.7391e-03, PNorm = 36.1835, GNorm = 5.1720, lr_0 = 1.0804e-04
Validation rmse logD = 0.691701
Validation R2 logD = 0.675641
Epoch 36
Train function
Loss = 3.0941e-03, PNorm = 36.1896, GNorm = 3.9702, lr_0 = 1.0804e-04
Loss = 3.4974e-03, PNorm = 36.1946, GNorm = 2.0228, lr_0 = 1.0804e-04
Loss = 3.9326e-03, PNorm = 36.1996, GNorm = 3.3719, lr_0 = 1.0804e-04
Loss = 3.5911e-03, PNorm = 36.2058, GNorm = 1.2316, lr_0 = 1.0804e-04
Loss = 3.1407e-03, PNorm = 36.2108, GNorm = 2.7265, lr_0 = 1.0804e-04
Loss = 4.7984e-03, PNorm = 36.2163, GNorm = 1.9135, lr_0 = 1.0804e-04
Validation rmse logD = 0.682096
Validation R2 logD = 0.684586
Epoch 37
Train function
Loss = 3.4362e-03, PNorm = 36.2203, GNorm = 1.2412, lr_0 = 1.0804e-04
Loss = 3.7508e-03, PNorm = 36.2252, GNorm = 2.8009, lr_0 = 1.0804e-04
Loss = 4.1111e-03, PNorm = 36.2300, GNorm = 3.8018, lr_0 = 1.0804e-04
Loss = 3.5468e-03, PNorm = 36.2351, GNorm = 3.4431, lr_0 = 1.0804e-04
Loss = 3.6167e-03, PNorm = 36.2400, GNorm = 5.8893, lr_0 = 1.0804e-04
Loss = 3.7179e-03, PNorm = 36.2444, GNorm = 1.4707, lr_0 = 1.0804e-04
Validation rmse logD = 0.680455
Validation R2 logD = 0.686102
Epoch 38
Train function
Loss = 3.2185e-03, PNorm = 36.2496, GNorm = 1.8000, lr_0 = 1.0804e-04
Loss = 3.6854e-03, PNorm = 36.2546, GNorm = 7.7678, lr_0 = 1.0804e-04
Loss = 3.4367e-03, PNorm = 36.2596, GNorm = 2.8494, lr_0 = 1.0804e-04
Loss = 3.8161e-03, PNorm = 36.2641, GNorm = 4.8295, lr_0 = 1.0804e-04
Loss = 4.2109e-03, PNorm = 36.2678, GNorm = 3.6778, lr_0 = 1.0804e-04
Validation rmse logD = 0.691792
Validation R2 logD = 0.675556
Epoch 39
Train function
Loss = 5.4880e-03, PNorm = 36.2727, GNorm = 7.1180, lr_0 = 1.0804e-04
Loss = 3.6473e-03, PNorm = 36.2780, GNorm = 2.0991, lr_0 = 1.0804e-04
Loss = 3.3419e-03, PNorm = 36.2828, GNorm = 3.9591, lr_0 = 1.0804e-04
Loss = 3.4239e-03, PNorm = 36.2884, GNorm = 2.1884, lr_0 = 1.0804e-04
Loss = 3.5683e-03, PNorm = 36.2932, GNorm = 3.1496, lr_0 = 1.0804e-04
Loss = 3.5504e-03, PNorm = 36.2977, GNorm = 4.3427, lr_0 = 1.0804e-04
Validation rmse logD = 0.722080
Validation R2 logD = 0.646524
Epoch 40
Train function
Loss = 4.0991e-03, PNorm = 36.3027, GNorm = 6.5782, lr_0 = 1.0804e-04
Loss = 3.6072e-03, PNorm = 36.3068, GNorm = 4.2270, lr_0 = 1.0804e-04
Loss = 4.1751e-03, PNorm = 36.3118, GNorm = 6.6271, lr_0 = 1.0804e-04
Loss = 3.3943e-03, PNorm = 36.3161, GNorm = 4.3075, lr_0 = 1.0804e-04
Loss = 2.7269e-03, PNorm = 36.3199, GNorm = 1.1822, lr_0 = 1.0804e-04
Loss = 3.5703e-03, PNorm = 36.3240, GNorm = 1.7911, lr_0 = 1.0804e-04
Validation rmse logD = 0.676986
Validation R2 logD = 0.689295
Epoch 41
Train function
Loss = 3.9057e-03, PNorm = 36.3304, GNorm = 4.5757, lr_0 = 1.0804e-04
Loss = 3.1609e-03, PNorm = 36.3365, GNorm = 4.2531, lr_0 = 1.0804e-04
Loss = 3.1252e-03, PNorm = 36.3401, GNorm = 4.5801, lr_0 = 1.0804e-04
Loss = 3.4367e-03, PNorm = 36.3443, GNorm = 1.8993, lr_0 = 1.0804e-04
Loss = 3.8000e-03, PNorm = 36.3486, GNorm = 8.1691, lr_0 = 1.0804e-04
Validation rmse logD = 0.670760
Validation R2 logD = 0.694983
Epoch 42
Train function
Loss = 4.0743e-03, PNorm = 36.3532, GNorm = 7.2922, lr_0 = 1.0804e-04
Loss = 3.8865e-03, PNorm = 36.3579, GNorm = 6.8745, lr_0 = 1.0804e-04
Loss = 3.5751e-03, PNorm = 36.3632, GNorm = 8.5749, lr_0 = 1.0804e-04
Loss = 3.3570e-03, PNorm = 36.3667, GNorm = 5.2033, lr_0 = 1.0804e-04
Loss = 3.3868e-03, PNorm = 36.3713, GNorm = 1.5773, lr_0 = 1.0804e-04
Loss = 3.0812e-03, PNorm = 36.3766, GNorm = 2.0153, lr_0 = 1.0804e-04
Validation rmse logD = 0.683280
Validation R2 logD = 0.683491
Epoch 43
Train function
Loss = 3.4325e-03, PNorm = 36.3808, GNorm = 5.8631, lr_0 = 1.0804e-04
Loss = 3.2723e-03, PNorm = 36.3838, GNorm = 6.0149, lr_0 = 1.0804e-04
Loss = 3.7764e-03, PNorm = 36.3874, GNorm = 5.8225, lr_0 = 1.0804e-04
Loss = 3.6716e-03, PNorm = 36.3915, GNorm = 1.2236, lr_0 = 1.0804e-04
Loss = 3.2321e-03, PNorm = 36.3966, GNorm = 2.0398, lr_0 = 1.0804e-04
Loss = 3.2959e-03, PNorm = 36.4025, GNorm = 1.9537, lr_0 = 1.0804e-04
Validation rmse logD = 0.665155
Validation R2 logD = 0.700060
Epoch 44
Train function
Loss = 3.0468e-03, PNorm = 36.4076, GNorm = 1.9327, lr_0 = 1.0804e-04
Loss = 3.0493e-03, PNorm = 36.4125, GNorm = 5.8654, lr_0 = 1.0804e-04
Loss = 2.6898e-03, PNorm = 36.4164, GNorm = 1.7032, lr_0 = 1.0804e-04
Loss = 3.0382e-03, PNorm = 36.4211, GNorm = 2.8139, lr_0 = 1.0804e-04
Loss = 3.8922e-03, PNorm = 36.4243, GNorm = 1.4445, lr_0 = 1.0804e-04
Validation rmse logD = 0.679728
Validation R2 logD = 0.686773
Epoch 45
Train function
Loss = 3.2189e-03, PNorm = 36.4284, GNorm = 3.3268, lr_0 = 1.0804e-04
Loss = 2.8897e-03, PNorm = 36.4325, GNorm = 2.2101, lr_0 = 1.0804e-04
Loss = 3.0672e-03, PNorm = 36.4372, GNorm = 1.6206, lr_0 = 1.0804e-04
Loss = 3.3761e-03, PNorm = 36.4431, GNorm = 1.7152, lr_0 = 1.0804e-04
Loss = 3.0845e-03, PNorm = 36.4471, GNorm = 5.0210, lr_0 = 1.0804e-04
Loss = 3.4140e-03, PNorm = 36.4506, GNorm = 4.4052, lr_0 = 1.0804e-04
Validation rmse logD = 0.687884
Validation R2 logD = 0.679211
Epoch 46
Train function
Loss = 3.5848e-03, PNorm = 36.4555, GNorm = 2.8706, lr_0 = 1.0804e-04
Loss = 3.0670e-03, PNorm = 36.4599, GNorm = 2.2043, lr_0 = 1.0804e-04
Loss = 3.0303e-03, PNorm = 36.4640, GNorm = 7.6089, lr_0 = 1.0804e-04
Loss = 3.9587e-03, PNorm = 36.4665, GNorm = 2.8733, lr_0 = 1.0804e-04
Loss = 2.9578e-03, PNorm = 36.4694, GNorm = 2.1084, lr_0 = 1.0804e-04
Loss = 3.0854e-03, PNorm = 36.4751, GNorm = 4.9498, lr_0 = 1.0804e-04
Validation rmse logD = 0.664633
Validation R2 logD = 0.700531
Epoch 47
Train function
Loss = 2.7742e-03, PNorm = 36.4810, GNorm = 2.9849, lr_0 = 1.0804e-04
Loss = 3.1667e-03, PNorm = 36.4853, GNorm = 2.4507, lr_0 = 1.0804e-04
Loss = 3.3828e-03, PNorm = 36.4899, GNorm = 3.0410, lr_0 = 1.0804e-04
Loss = 3.7698e-03, PNorm = 36.4937, GNorm = 3.1309, lr_0 = 1.0804e-04
Loss = 3.1045e-03, PNorm = 36.4994, GNorm = 1.6731, lr_0 = 1.0804e-04
Validation rmse logD = 0.659023
Validation R2 logD = 0.705565
Epoch 48
Train function
Loss = 2.3955e-03, PNorm = 36.5047, GNorm = 3.2908, lr_0 = 1.0804e-04
Loss = 2.9644e-03, PNorm = 36.5080, GNorm = 2.2501, lr_0 = 1.0804e-04
Loss = 2.9258e-03, PNorm = 36.5121, GNorm = 1.9369, lr_0 = 1.0804e-04
Loss = 2.9169e-03, PNorm = 36.5179, GNorm = 3.8593, lr_0 = 1.0804e-04
Loss = 2.6530e-03, PNorm = 36.5214, GNorm = 1.4500, lr_0 = 1.0804e-04
Loss = 3.1778e-03, PNorm = 36.5259, GNorm = 4.9949, lr_0 = 1.0804e-04
Validation rmse logD = 0.677464
Validation R2 logD = 0.688856
Epoch 49
Train function
Loss = 2.8196e-03, PNorm = 36.5306, GNorm = 1.0698, lr_0 = 1.0804e-04
Loss = 2.8296e-03, PNorm = 36.5337, GNorm = 4.2460, lr_0 = 1.0804e-04
Loss = 2.9176e-03, PNorm = 36.5369, GNorm = 2.6204, lr_0 = 1.0804e-04
Loss = 3.2467e-03, PNorm = 36.5423, GNorm = 1.6220, lr_0 = 1.0804e-04
Loss = 3.9840e-03, PNorm = 36.5479, GNorm = 9.2271, lr_0 = 1.0804e-04
Loss = 3.1516e-03, PNorm = 36.5519, GNorm = 2.7885, lr_0 = 1.0804e-04
Validation rmse logD = 0.663734
Validation R2 logD = 0.701340
Epoch 50
Train function
Loss = 3.1936e-03, PNorm = 36.5558, GNorm = 2.4205, lr_0 = 1.0804e-04
Loss = 2.7495e-03, PNorm = 36.5598, GNorm = 2.4226, lr_0 = 1.0804e-04
Loss = 3.1809e-03, PNorm = 36.5636, GNorm = 2.4186, lr_0 = 1.0804e-04
Loss = 2.8191e-03, PNorm = 36.5667, GNorm = 2.1421, lr_0 = 1.0804e-04
Loss = 3.0905e-03, PNorm = 36.5713, GNorm = 1.8113, lr_0 = 1.0804e-04
Validation rmse logD = 0.661187
Validation R2 logD = 0.703628
Epoch 51
Train function
Loss = 2.4931e-03, PNorm = 36.5765, GNorm = 2.3771, lr_0 = 1.0804e-04
Loss = 2.4943e-03, PNorm = 36.5807, GNorm = 1.7442, lr_0 = 1.0804e-04
Loss = 2.8137e-03, PNorm = 36.5851, GNorm = 3.1489, lr_0 = 1.0804e-04
Loss = 3.3798e-03, PNorm = 36.5893, GNorm = 2.2199, lr_0 = 1.0804e-04
Loss = 2.7476e-03, PNorm = 36.5932, GNorm = 2.1334, lr_0 = 1.0804e-04
Loss = 2.9254e-03, PNorm = 36.5981, GNorm = 5.7985, lr_0 = 1.0804e-04
Validation rmse logD = 0.656786
Validation R2 logD = 0.707560
Epoch 52
Train function
Loss = 2.2750e-03, PNorm = 36.6020, GNorm = 2.4574, lr_0 = 1.0804e-04
Loss = 2.7597e-03, PNorm = 36.6053, GNorm = 3.8767, lr_0 = 1.0804e-04
Loss = 3.0026e-03, PNorm = 36.6093, GNorm = 2.5026, lr_0 = 1.0804e-04
Loss = 2.5595e-03, PNorm = 36.6141, GNorm = 1.8983, lr_0 = 1.0804e-04
Loss = 3.4197e-03, PNorm = 36.6195, GNorm = 6.5052, lr_0 = 1.0804e-04
Loss = 2.4765e-03, PNorm = 36.6230, GNorm = 1.8357, lr_0 = 1.0804e-04
Validation rmse logD = 0.652794
Validation R2 logD = 0.711104
Epoch 53
Train function
Loss = 2.3267e-03, PNorm = 36.6274, GNorm = 3.1925, lr_0 = 1.0804e-04
Loss = 2.3221e-03, PNorm = 36.6313, GNorm = 3.1729, lr_0 = 1.0804e-04
Loss = 2.2186e-03, PNorm = 36.6350, GNorm = 3.7692, lr_0 = 1.0804e-04
Loss = 2.8400e-03, PNorm = 36.6393, GNorm = 1.5985, lr_0 = 1.0804e-04
Loss = 3.6150e-03, PNorm = 36.6437, GNorm = 4.4660, lr_0 = 1.0804e-04
Validation rmse logD = 0.651718
Validation R2 logD = 0.712056
Epoch 54
Train function
Loss = 2.6065e-03, PNorm = 36.6476, GNorm = 2.6365, lr_0 = 1.0804e-04
Loss = 2.7048e-03, PNorm = 36.6520, GNorm = 2.1402, lr_0 = 1.0804e-04
Loss = 2.4303e-03, PNorm = 36.6574, GNorm = 1.7115, lr_0 = 1.0804e-04
Loss = 2.4627e-03, PNorm = 36.6625, GNorm = 3.3131, lr_0 = 1.0804e-04
Loss = 3.1408e-03, PNorm = 36.6661, GNorm = 1.4418, lr_0 = 1.0804e-04
Loss = 2.5430e-03, PNorm = 36.6691, GNorm = 6.3060, lr_0 = 1.0804e-04
Validation rmse logD = 0.662103
Validation R2 logD = 0.702806
Epoch 55
Train function
Loss = 2.1730e-03, PNorm = 36.6721, GNorm = 2.6544, lr_0 = 1.0804e-04
Loss = 2.5305e-03, PNorm = 36.6760, GNorm = 1.6904, lr_0 = 1.0804e-04
Loss = 2.4892e-03, PNorm = 36.6796, GNorm = 3.5222, lr_0 = 1.0804e-04
Loss = 2.2256e-03, PNorm = 36.6832, GNorm = 2.1172, lr_0 = 1.0804e-04
Loss = 3.7027e-03, PNorm = 36.6878, GNorm = 3.1762, lr_0 = 1.0804e-04
Loss = 2.9714e-03, PNorm = 36.6925, GNorm = 6.6669, lr_0 = 1.0804e-04
Validation rmse logD = 0.706421
Validation R2 logD = 0.661689
Epoch 56
Train function
Loss = 2.8253e-03, PNorm = 36.6958, GNorm = 6.2656, lr_0 = 1.0804e-04
Loss = 2.1736e-03, PNorm = 36.6991, GNorm = 1.5733, lr_0 = 1.0804e-04
Loss = 2.8128e-03, PNorm = 36.7036, GNorm = 4.8934, lr_0 = 1.0804e-04
Loss = 3.1705e-03, PNorm = 36.7088, GNorm = 9.0887, lr_0 = 1.0804e-04
Loss = 2.9926e-03, PNorm = 36.7125, GNorm = 2.3517, lr_0 = 1.0804e-04
Validation rmse logD = 0.661136
Validation R2 logD = 0.703673
Epoch 57
Train function
Loss = 3.5419e-03, PNorm = 36.7166, GNorm = 1.6004, lr_0 = 1.0804e-04
Loss = 2.4117e-03, PNorm = 36.7217, GNorm = 4.6733, lr_0 = 1.0804e-04
Loss = 2.7055e-03, PNorm = 36.7261, GNorm = 4.7578, lr_0 = 1.0804e-04
Loss = 2.5819e-03, PNorm = 36.7300, GNorm = 2.4101, lr_0 = 1.0804e-04
Loss = 3.0630e-03, PNorm = 36.7343, GNorm = 2.1595, lr_0 = 1.0804e-04
Loss = 2.1470e-03, PNorm = 36.7387, GNorm = 2.4494, lr_0 = 1.0804e-04
Validation rmse logD = 0.646445
Validation R2 logD = 0.716696
Epoch 58
Train function
Loss = 2.5370e-03, PNorm = 36.7427, GNorm = 5.5601, lr_0 = 1.0804e-04
Loss = 2.0750e-03, PNorm = 36.7469, GNorm = 3.3210, lr_0 = 1.0804e-04
Loss = 2.7905e-03, PNorm = 36.7506, GNorm = 1.5770, lr_0 = 1.0804e-04
Loss = 2.3160e-03, PNorm = 36.7545, GNorm = 1.5632, lr_0 = 1.0804e-04
Loss = 2.7380e-03, PNorm = 36.7589, GNorm = 1.7346, lr_0 = 1.0804e-04
Loss = 2.6271e-03, PNorm = 36.7629, GNorm = 3.0876, lr_0 = 1.0804e-04
Validation rmse logD = 0.650364
Validation R2 logD = 0.713251
Epoch 59
Train function
Loss = 2.3651e-03, PNorm = 36.7665, GNorm = 2.1993, lr_0 = 1.0804e-04
Loss = 2.6489e-03, PNorm = 36.7704, GNorm = 10.0435, lr_0 = 1.0804e-04
Loss = 3.0945e-03, PNorm = 36.7744, GNorm = 2.0205, lr_0 = 1.0804e-04
Loss = 2.4474e-03, PNorm = 36.7772, GNorm = 1.9523, lr_0 = 1.0804e-04
Loss = 2.5654e-03, PNorm = 36.7812, GNorm = 3.9118, lr_0 = 1.0804e-04
Validation rmse logD = 0.639649
Validation R2 logD = 0.722622
Epoch 60
Train function
Loss = 2.5645e-03, PNorm = 36.7859, GNorm = 2.7072, lr_0 = 1.0804e-04
Loss = 2.2556e-03, PNorm = 36.7904, GNorm = 1.4827, lr_0 = 1.0804e-04
Loss = 2.3748e-03, PNorm = 36.7944, GNorm = 2.3448, lr_0 = 1.0804e-04
Loss = 2.7833e-03, PNorm = 36.7993, GNorm = 3.4696, lr_0 = 1.0804e-04
Loss = 2.0013e-03, PNorm = 36.8042, GNorm = 1.8849, lr_0 = 1.0804e-04
Loss = 2.5909e-03, PNorm = 36.8069, GNorm = 4.3302, lr_0 = 1.0804e-04
Validation rmse logD = 0.650867
Validation R2 logD = 0.712807
Epoch 61
Train function
Loss = 2.1446e-03, PNorm = 36.8105, GNorm = 1.9023, lr_0 = 1.0804e-04
Loss = 2.1294e-03, PNorm = 36.8145, GNorm = 2.6712, lr_0 = 1.0804e-04
Loss = 2.3020e-03, PNorm = 36.8184, GNorm = 3.7941, lr_0 = 1.0804e-04
Loss = 2.2534e-03, PNorm = 36.8221, GNorm = 3.5023, lr_0 = 1.0804e-04
Loss = 2.8378e-03, PNorm = 36.8263, GNorm = 7.5022, lr_0 = 1.0804e-04
Loss = 2.7349e-03, PNorm = 36.8305, GNorm = 8.1842, lr_0 = 1.0804e-04
Validation rmse logD = 0.705906
Validation R2 logD = 0.662182
Epoch 62
Train function
Loss = 2.8172e-03, PNorm = 36.8337, GNorm = 1.3030, lr_0 = 1.0804e-04
Loss = 2.5299e-03, PNorm = 36.8366, GNorm = 5.6159, lr_0 = 1.0804e-04
Loss = 2.5186e-03, PNorm = 36.8399, GNorm = 5.5235, lr_0 = 1.0804e-04
Loss = 2.5033e-03, PNorm = 36.8443, GNorm = 4.1733, lr_0 = 1.0804e-04
Loss = 2.2413e-03, PNorm = 36.8485, GNorm = 1.5600, lr_0 = 1.0804e-04
Validation rmse logD = 0.645499
Validation R2 logD = 0.717525
Epoch 63
Train function
Loss = 3.1111e-03, PNorm = 36.8529, GNorm = 1.3975, lr_0 = 1.0804e-04
Loss = 2.4005e-03, PNorm = 36.8568, GNorm = 9.5748, lr_0 = 1.0804e-04
Loss = 3.0638e-03, PNorm = 36.8599, GNorm = 12.2246, lr_0 = 1.0804e-04
Loss = 3.3050e-03, PNorm = 36.8627, GNorm = 4.0964, lr_0 = 1.0804e-04
Loss = 2.6398e-03, PNorm = 36.8657, GNorm = 3.0043, lr_0 = 1.0804e-04
Loss = 2.6116e-03, PNorm = 36.8699, GNorm = 4.0702, lr_0 = 1.0804e-04
Validation rmse logD = 0.658652
Validation R2 logD = 0.705896
Epoch 64
Train function
Loss = 3.9628e-03, PNorm = 36.8742, GNorm = 6.4487, lr_0 = 1.0804e-04
Loss = 2.1546e-03, PNorm = 36.8789, GNorm = 3.9068, lr_0 = 1.0804e-04
Loss = 2.1427e-03, PNorm = 36.8826, GNorm = 8.0230, lr_0 = 1.0804e-04
Loss = 2.4947e-03, PNorm = 36.8860, GNorm = 3.5688, lr_0 = 1.0804e-04
Loss = 2.5738e-03, PNorm = 36.8905, GNorm = 1.6116, lr_0 = 1.0804e-04
Loss = 2.5351e-03, PNorm = 36.8949, GNorm = 5.1657, lr_0 = 1.0804e-04
Validation rmse logD = 0.653073
Validation R2 logD = 0.710857
Epoch 65
Train function
Loss = 1.8942e-03, PNorm = 36.8982, GNorm = 4.3768, lr_0 = 1.0804e-04
Loss = 2.0190e-03, PNorm = 36.9019, GNorm = 2.8903, lr_0 = 1.0804e-04
Loss = 2.4101e-03, PNorm = 36.9056, GNorm = 1.5428, lr_0 = 1.0804e-04
Loss = 2.9715e-03, PNorm = 36.9080, GNorm = 8.6681, lr_0 = 1.0804e-04
Loss = 2.8939e-03, PNorm = 36.9101, GNorm = 3.4808, lr_0 = 1.0804e-04
Validation rmse logD = 0.640954
Validation R2 logD = 0.721489
Epoch 66
Train function
Loss = 1.3304e-03, PNorm = 36.9143, GNorm = 3.1074, lr_0 = 1.0804e-04
Loss = 1.9530e-03, PNorm = 36.9186, GNorm = 1.2171, lr_0 = 1.0804e-04
Loss = 1.9109e-03, PNorm = 36.9222, GNorm = 1.5642, lr_0 = 1.0804e-04
Loss = 2.2049e-03, PNorm = 36.9264, GNorm = 1.9027, lr_0 = 1.0804e-04
Loss = 2.5305e-03, PNorm = 36.9304, GNorm = 1.4444, lr_0 = 1.0804e-04
Loss = 2.4515e-03, PNorm = 36.9341, GNorm = 2.0299, lr_0 = 1.0804e-04
Validation rmse logD = 0.656542
Validation R2 logD = 0.707777
Epoch 67
Train function
Loss = 1.6032e-03, PNorm = 36.9379, GNorm = 1.7446, lr_0 = 1.0804e-04
Loss = 2.3741e-03, PNorm = 36.9418, GNorm = 4.2726, lr_0 = 1.0804e-04
Loss = 2.0832e-03, PNorm = 36.9468, GNorm = 2.3419, lr_0 = 1.0804e-04
Loss = 2.5502e-03, PNorm = 36.9499, GNorm = 4.2614, lr_0 = 1.0804e-04
Loss = 2.2262e-03, PNorm = 36.9533, GNorm = 5.6332, lr_0 = 1.0804e-04
Loss = 2.1751e-03, PNorm = 36.9573, GNorm = 2.4105, lr_0 = 1.0804e-04
Validation rmse logD = 0.634837
Validation R2 logD = 0.726779
Epoch 68
Train function
Loss = 2.4277e-03, PNorm = 36.9622, GNorm = 1.3863, lr_0 = 1.0804e-04
Loss = 2.2003e-03, PNorm = 36.9666, GNorm = 3.6843, lr_0 = 1.0804e-04
Loss = 1.8125e-03, PNorm = 36.9697, GNorm = 3.5893, lr_0 = 1.0804e-04
Loss = 2.2327e-03, PNorm = 36.9735, GNorm = 8.6430, lr_0 = 1.0804e-04
Loss = 2.4912e-03, PNorm = 36.9769, GNorm = 5.1894, lr_0 = 1.0804e-04
Validation rmse logD = 0.636255
Validation R2 logD = 0.725558
Epoch 69
Train function
Loss = 2.0841e-03, PNorm = 36.9804, GNorm = 1.9603, lr_0 = 1.0804e-04
Loss = 2.1389e-03, PNorm = 36.9843, GNorm = 5.0826, lr_0 = 1.0804e-04
Loss = 2.1921e-03, PNorm = 36.9864, GNorm = 2.9857, lr_0 = 1.0804e-04
Loss = 2.4277e-03, PNorm = 36.9905, GNorm = 6.3245, lr_0 = 1.0804e-04
Loss = 2.5522e-03, PNorm = 36.9937, GNorm = 5.7922, lr_0 = 1.0804e-04
Loss = 2.0783e-03, PNorm = 36.9967, GNorm = 2.4115, lr_0 = 1.0804e-04
Validation rmse logD = 0.642137
Validation R2 logD = 0.720460
Epoch 70
Train function
Loss = 2.1191e-03, PNorm = 37.0003, GNorm = 6.9675, lr_0 = 1.0804e-04
Loss = 1.8920e-03, PNorm = 37.0032, GNorm = 2.3353, lr_0 = 1.0804e-04
Loss = 1.9118e-03, PNorm = 37.0071, GNorm = 1.0961, lr_0 = 1.0804e-04
Loss = 2.3505e-03, PNorm = 37.0114, GNorm = 1.0234, lr_0 = 1.0804e-04
Loss = 2.0655e-03, PNorm = 37.0156, GNorm = 3.7294, lr_0 = 1.0804e-04
Loss = 2.1929e-03, PNorm = 37.0181, GNorm = 2.0555, lr_0 = 1.0804e-04
Validation rmse logD = 0.655601
Validation R2 logD = 0.708614
Epoch 71
Train function
Loss = 1.8517e-03, PNorm = 37.0221, GNorm = 2.6126, lr_0 = 1.0804e-04
Loss = 2.4118e-03, PNorm = 37.0271, GNorm = 2.0700, lr_0 = 1.0804e-04
Loss = 1.8368e-03, PNorm = 37.0316, GNorm = 2.1544, lr_0 = 1.0804e-04
Loss = 2.1086e-03, PNorm = 37.0350, GNorm = 1.9591, lr_0 = 1.0804e-04
Loss = 2.0698e-03, PNorm = 37.0379, GNorm = 1.7992, lr_0 = 1.0804e-04
Validation rmse logD = 0.641811
Validation R2 logD = 0.720743
Epoch 72
Train function
Loss = 1.5959e-03, PNorm = 37.0412, GNorm = 1.4323, lr_0 = 1.0804e-04
Loss = 1.9356e-03, PNorm = 37.0451, GNorm = 2.8451, lr_0 = 1.0804e-04
Loss = 2.0380e-03, PNorm = 37.0482, GNorm = 4.9898, lr_0 = 1.0804e-04
Loss = 1.9512e-03, PNorm = 37.0522, GNorm = 3.6720, lr_0 = 1.0804e-04
Loss = 2.2223e-03, PNorm = 37.0566, GNorm = 8.1412, lr_0 = 1.0804e-04
Loss = 2.6064e-03, PNorm = 37.0594, GNorm = 3.1254, lr_0 = 1.0804e-04
Validation rmse logD = 0.656547
Validation R2 logD = 0.707773
Epoch 73
Train function
Loss = 2.0148e-03, PNorm = 37.0627, GNorm = 1.5787, lr_0 = 1.0804e-04
Loss = 2.3107e-03, PNorm = 37.0649, GNorm = 5.6607, lr_0 = 1.0804e-04
Loss = 2.2065e-03, PNorm = 37.0674, GNorm = 7.2170, lr_0 = 1.0804e-04
Loss = 2.2495e-03, PNorm = 37.0709, GNorm = 3.8427, lr_0 = 1.0804e-04
Loss = 2.3978e-03, PNorm = 37.0759, GNorm = 4.8516, lr_0 = 1.0804e-04
Loss = 1.9621e-03, PNorm = 37.0810, GNorm = 3.8215, lr_0 = 1.0804e-04
Validation rmse logD = 0.665027
Validation R2 logD = 0.700175
Epoch 74
Train function
Loss = 1.9507e-03, PNorm = 37.0856, GNorm = 2.9824, lr_0 = 1.0804e-04
Loss = 1.8436e-03, PNorm = 37.0890, GNorm = 2.4545, lr_0 = 1.0804e-04
Loss = 1.9677e-03, PNorm = 37.0922, GNorm = 6.4729, lr_0 = 1.0804e-04
Loss = 2.0405e-03, PNorm = 37.0952, GNorm = 2.2461, lr_0 = 1.0804e-04
Loss = 1.7874e-03, PNorm = 37.0986, GNorm = 3.3227, lr_0 = 1.0804e-04
Validation rmse logD = 0.634818
Validation R2 logD = 0.726796
Epoch 75
Train function
Loss = 1.3317e-03, PNorm = 37.1035, GNorm = 2.1267, lr_0 = 1.0804e-04
Loss = 1.9142e-03, PNorm = 37.1086, GNorm = 1.7959, lr_0 = 1.0804e-04
Loss = 1.6904e-03, PNorm = 37.1123, GNorm = 1.4986, lr_0 = 1.0804e-04
Loss = 2.2930e-03, PNorm = 37.1145, GNorm = 1.6818, lr_0 = 1.0804e-04
Loss = 1.6883e-03, PNorm = 37.1175, GNorm = 4.6804, lr_0 = 1.0804e-04
Loss = 1.7866e-03, PNorm = 37.1216, GNorm = 2.7901, lr_0 = 1.0804e-04
Validation rmse logD = 0.634856
Validation R2 logD = 0.726763
Epoch 76
Train function
Loss = 1.2921e-03, PNorm = 37.1251, GNorm = 2.2276, lr_0 = 1.0804e-04
Loss = 1.7342e-03, PNorm = 37.1295, GNorm = 1.7470, lr_0 = 1.0804e-04
Loss = 1.6798e-03, PNorm = 37.1327, GNorm = 1.8749, lr_0 = 1.0804e-04
Loss = 2.2604e-03, PNorm = 37.1370, GNorm = 1.3141, lr_0 = 1.0804e-04
Loss = 1.9944e-03, PNorm = 37.1400, GNorm = 1.3937, lr_0 = 1.0804e-04
Loss = 2.0722e-03, PNorm = 37.1431, GNorm = 1.7134, lr_0 = 1.0804e-04
Validation rmse logD = 0.626728
Validation R2 logD = 0.733715
Epoch 77
Train function
Loss = 1.9894e-03, PNorm = 37.1467, GNorm = 2.9627, lr_0 = 1.0804e-04
Loss = 2.0112e-03, PNorm = 37.1505, GNorm = 2.2260, lr_0 = 1.0804e-04
Loss = 2.0004e-03, PNorm = 37.1537, GNorm = 3.8896, lr_0 = 1.0804e-04
Loss = 2.2711e-03, PNorm = 37.1572, GNorm = 4.9366, lr_0 = 1.0804e-04
Loss = 1.4913e-03, PNorm = 37.1613, GNorm = 1.3004, lr_0 = 1.0804e-04
Validation rmse logD = 0.654641
Validation R2 logD = 0.709467
Epoch 78
Train function
Loss = 1.9582e-03, PNorm = 37.1641, GNorm = 7.5556, lr_0 = 1.0804e-04
Loss = 1.9363e-03, PNorm = 37.1686, GNorm = 6.1480, lr_0 = 1.0804e-04
Loss = 1.7230e-03, PNorm = 37.1718, GNorm = 1.3819, lr_0 = 1.0804e-04
Loss = 1.8919e-03, PNorm = 37.1752, GNorm = 3.7953, lr_0 = 1.0804e-04
Loss = 1.7794e-03, PNorm = 37.1787, GNorm = 5.6220, lr_0 = 1.0804e-04
Loss = 1.9098e-03, PNorm = 37.1819, GNorm = 3.9036, lr_0 = 1.0804e-04
Validation rmse logD = 0.629586
Validation R2 logD = 0.731281
Epoch 79
Train function
Loss = 1.5722e-03, PNorm = 37.1857, GNorm = 1.7303, lr_0 = 1.0804e-04
Loss = 1.5890e-03, PNorm = 37.1888, GNorm = 2.7864, lr_0 = 1.0804e-04
Loss = 1.7545e-03, PNorm = 37.1920, GNorm = 1.8745, lr_0 = 1.0804e-04
Loss = 1.7257e-03, PNorm = 37.1960, GNorm = 2.3921, lr_0 = 1.0804e-04
Loss = 1.8944e-03, PNorm = 37.1988, GNorm = 1.9488, lr_0 = 1.0804e-04
Loss = 2.1497e-03, PNorm = 37.2017, GNorm = 2.9726, lr_0 = 1.0804e-04
Validation rmse logD = 0.635554
Validation R2 logD = 0.726161
Epoch 80
Train function
Loss = 1.7905e-03, PNorm = 37.2056, GNorm = 2.4577, lr_0 = 1.0804e-04
Loss = 1.7133e-03, PNorm = 37.2082, GNorm = 1.8558, lr_0 = 1.0804e-04
Loss = 1.6135e-03, PNorm = 37.2123, GNorm = 3.7478, lr_0 = 1.0804e-04
Loss = 1.7275e-03, PNorm = 37.2166, GNorm = 4.8382, lr_0 = 1.0804e-04
Loss = 1.9520e-03, PNorm = 37.2201, GNorm = 4.3199, lr_0 = 1.0804e-04
Validation rmse logD = 0.629328
Validation R2 logD = 0.731501
Epoch 81
Train function
Loss = 1.2664e-03, PNorm = 37.2235, GNorm = 5.0645, lr_0 = 1.0804e-04
Loss = 1.9837e-03, PNorm = 37.2268, GNorm = 2.8954, lr_0 = 1.0804e-04
Loss = 1.7753e-03, PNorm = 37.2310, GNorm = 5.2751, lr_0 = 1.0804e-04
Loss = 1.6250e-03, PNorm = 37.2352, GNorm = 4.5466, lr_0 = 1.0804e-04
Loss = 1.9759e-03, PNorm = 37.2393, GNorm = 3.9631, lr_0 = 1.0804e-04
Loss = 1.6860e-03, PNorm = 37.2435, GNorm = 2.5903, lr_0 = 1.0804e-04
Validation rmse logD = 0.626042
Validation R2 logD = 0.734297
Epoch 82
Train function
Loss = 1.8634e-03, PNorm = 37.2460, GNorm = 4.7846, lr_0 = 1.0804e-04
Loss = 1.9855e-03, PNorm = 37.2488, GNorm = 7.4522, lr_0 = 1.0804e-04
Loss = 1.6549e-03, PNorm = 37.2524, GNorm = 1.5941, lr_0 = 1.0804e-04
Loss = 1.7522e-03, PNorm = 37.2557, GNorm = 3.0226, lr_0 = 1.0804e-04
Loss = 1.6498e-03, PNorm = 37.2599, GNorm = 1.5393, lr_0 = 1.0804e-04
Loss = 1.8236e-03, PNorm = 37.2637, GNorm = 4.3984, lr_0 = 1.0804e-04
Validation rmse logD = 0.652401
Validation R2 logD = 0.711452
Epoch 83
Train function
Loss = 1.9352e-03, PNorm = 37.2688, GNorm = 5.8113, lr_0 = 1.0804e-04
Loss = 1.7293e-03, PNorm = 37.2724, GNorm = 1.4800, lr_0 = 1.0804e-04
Loss = 1.7435e-03, PNorm = 37.2756, GNorm = 2.2037, lr_0 = 1.0804e-04
Loss = 1.7596e-03, PNorm = 37.2790, GNorm = 1.1300, lr_0 = 1.0804e-04
Loss = 1.7343e-03, PNorm = 37.2825, GNorm = 9.3409, lr_0 = 1.0804e-04
Validation rmse logD = 0.633138
Validation R2 logD = 0.728240
Epoch 84
Train function
Loss = 1.5155e-03, PNorm = 37.2858, GNorm = 1.9412, lr_0 = 1.0804e-04
Loss = 1.5384e-03, PNorm = 37.2901, GNorm = 6.3282, lr_0 = 1.0804e-04
Loss = 1.6768e-03, PNorm = 37.2938, GNorm = 3.1146, lr_0 = 1.0804e-04
Loss = 1.9565e-03, PNorm = 37.2971, GNorm = 2.8877, lr_0 = 1.0804e-04
Loss = 1.6035e-03, PNorm = 37.2997, GNorm = 2.1921, lr_0 = 1.0804e-04
Loss = 1.6482e-03, PNorm = 37.3030, GNorm = 1.7769, lr_0 = 1.0804e-04
Validation rmse logD = 0.630705
Validation R2 logD = 0.730324
Epoch 85
Train function
Loss = 1.9007e-03, PNorm = 37.3060, GNorm = 3.9154, lr_0 = 1.0804e-04
Loss = 1.5779e-03, PNorm = 37.3088, GNorm = 1.0231, lr_0 = 1.0804e-04
Loss = 1.7567e-03, PNorm = 37.3110, GNorm = 3.6609, lr_0 = 1.0804e-04
Loss = 1.6847e-03, PNorm = 37.3139, GNorm = 4.5325, lr_0 = 1.0804e-04
Loss = 1.6959e-03, PNorm = 37.3177, GNorm = 2.2946, lr_0 = 1.0804e-04
Loss = 1.8564e-03, PNorm = 37.3221, GNorm = 2.1076, lr_0 = 1.0804e-04
Validation rmse logD = 0.625194
Validation R2 logD = 0.735016
Epoch 86
Train function
Loss = 1.8052e-03, PNorm = 37.3267, GNorm = 2.7751, lr_0 = 1.0804e-04
Loss = 1.6351e-03, PNorm = 37.3305, GNorm = 2.3184, lr_0 = 1.0804e-04
Loss = 1.7399e-03, PNorm = 37.3344, GNorm = 6.3847, lr_0 = 1.0804e-04
Loss = 1.9676e-03, PNorm = 37.3383, GNorm = 5.0257, lr_0 = 1.0804e-04
Loss = 1.6541e-03, PNorm = 37.3410, GNorm = 1.9658, lr_0 = 1.0804e-04
Validation rmse logD = 0.628006
Validation R2 logD = 0.732627
Epoch 87
Train function
Loss = 1.1886e-03, PNorm = 37.3441, GNorm = 1.6535, lr_0 = 1.0804e-04
Loss = 1.3097e-03, PNorm = 37.3468, GNorm = 4.5037, lr_0 = 1.0804e-04
Loss = 1.5798e-03, PNorm = 37.3489, GNorm = 8.2298, lr_0 = 1.0804e-04
Loss = 1.6721e-03, PNorm = 37.3525, GNorm = 2.9718, lr_0 = 1.0804e-04
Loss = 1.9533e-03, PNorm = 37.3571, GNorm = 2.1602, lr_0 = 1.0804e-04
Loss = 1.7473e-03, PNorm = 37.3613, GNorm = 5.9580, lr_0 = 1.0804e-04
Validation rmse logD = 0.636833
Validation R2 logD = 0.725058
Epoch 88
Train function
Loss = 1.2966e-03, PNorm = 37.3643, GNorm = 4.0975, lr_0 = 1.0804e-04
Loss = 1.3882e-03, PNorm = 37.3670, GNorm = 1.9347, lr_0 = 1.0804e-04
Loss = 1.7783e-03, PNorm = 37.3703, GNorm = 1.1111, lr_0 = 1.0804e-04
Loss = 1.7890e-03, PNorm = 37.3739, GNorm = 5.8920, lr_0 = 1.0804e-04
Loss = 1.4887e-03, PNorm = 37.3765, GNorm = 1.6725, lr_0 = 1.0804e-04
Loss = 1.8051e-03, PNorm = 37.3801, GNorm = 4.9540, lr_0 = 1.0804e-04
Validation rmse logD = 0.623844
Validation R2 logD = 0.736160
Epoch 89
Train function
Loss = 1.3823e-03, PNorm = 37.3851, GNorm = 1.6869, lr_0 = 1.0804e-04
Loss = 1.5176e-03, PNorm = 37.3899, GNorm = 1.4614, lr_0 = 1.0804e-04
Loss = 1.7967e-03, PNorm = 37.3920, GNorm = 1.6484, lr_0 = 1.0804e-04
Loss = 1.6521e-03, PNorm = 37.3951, GNorm = 1.4266, lr_0 = 1.0804e-04
Loss = 1.7256e-03, PNorm = 37.3980, GNorm = 2.2452, lr_0 = 1.0804e-04
Validation rmse logD = 0.625588
Validation R2 logD = 0.734683
Epoch 90
Train function
Loss = 2.0453e-03, PNorm = 37.4008, GNorm = 1.2521, lr_0 = 1.0804e-04
Loss = 1.6257e-03, PNorm = 37.4049, GNorm = 3.7992, lr_0 = 1.0804e-04
Loss = 1.5020e-03, PNorm = 37.4091, GNorm = 4.4908, lr_0 = 1.0804e-04
Loss = 1.7051e-03, PNorm = 37.4118, GNorm = 4.4034, lr_0 = 1.0804e-04
Loss = 1.4287e-03, PNorm = 37.4146, GNorm = 1.3563, lr_0 = 1.0804e-04
Loss = 1.3970e-03, PNorm = 37.4191, GNorm = 1.5494, lr_0 = 1.0804e-04
Validation rmse logD = 0.653591
Validation R2 logD = 0.710398
Epoch 91
Train function
Loss = 1.5734e-03, PNorm = 37.4224, GNorm = 3.9545, lr_0 = 1.0804e-04
Loss = 1.6812e-03, PNorm = 37.4256, GNorm = 5.6524, lr_0 = 1.0804e-04
Loss = 2.0179e-03, PNorm = 37.4279, GNorm = 6.3248, lr_0 = 1.0804e-04
Loss = 1.6532e-03, PNorm = 37.4309, GNorm = 2.1021, lr_0 = 1.0804e-04
Loss = 1.5532e-03, PNorm = 37.4348, GNorm = 4.1046, lr_0 = 1.0804e-04
Loss = 1.8010e-03, PNorm = 37.4376, GNorm = 1.9169, lr_0 = 1.0804e-04
Validation rmse logD = 0.641101
Validation R2 logD = 0.721361
Epoch 92
Train function
Loss = 1.4987e-03, PNorm = 37.4416, GNorm = 4.1103, lr_0 = 1.0804e-04
Loss = 1.4656e-03, PNorm = 37.4455, GNorm = 3.3516, lr_0 = 1.0804e-04
Loss = 1.5511e-03, PNorm = 37.4493, GNorm = 1.5847, lr_0 = 1.0804e-04
Loss = 1.5494e-03, PNorm = 37.4516, GNorm = 3.5429, lr_0 = 1.0804e-04
Loss = 1.7249e-03, PNorm = 37.4534, GNorm = 3.8682, lr_0 = 1.0804e-04
Validation rmse logD = 0.623134
Validation R2 logD = 0.736760
Epoch 93
Train function
Loss = 1.4972e-03, PNorm = 37.4574, GNorm = 5.8381, lr_0 = 1.0804e-04
Loss = 1.5121e-03, PNorm = 37.4609, GNorm = 1.5622, lr_0 = 1.0804e-04
Loss = 1.5846e-03, PNorm = 37.4645, GNorm = 1.5686, lr_0 = 1.0804e-04
Loss = 1.7058e-03, PNorm = 37.4681, GNorm = 2.6414, lr_0 = 1.0804e-04
Loss = 1.6436e-03, PNorm = 37.4719, GNorm = 9.2841, lr_0 = 1.0804e-04
Loss = 1.6382e-03, PNorm = 37.4754, GNorm = 5.0987, lr_0 = 1.0804e-04
Validation rmse logD = 0.620682
Validation R2 logD = 0.738828
Epoch 94
Train function
Loss = 1.4469e-03, PNorm = 37.4786, GNorm = 1.3522, lr_0 = 1.0804e-04
Loss = 1.3024e-03, PNorm = 37.4818, GNorm = 3.8519, lr_0 = 1.0804e-04
Loss = 1.6674e-03, PNorm = 37.4859, GNorm = 4.7631, lr_0 = 1.0804e-04
Loss = 1.9269e-03, PNorm = 37.4896, GNorm = 8.0499, lr_0 = 1.0804e-04
Loss = 1.7282e-03, PNorm = 37.4919, GNorm = 6.8525, lr_0 = 1.0804e-04
Loss = 1.5780e-03, PNorm = 37.4947, GNorm = 0.9555, lr_0 = 1.0804e-04
Validation rmse logD = 0.634717
Validation R2 logD = 0.726883
Epoch 95
Train function
Loss = 1.5480e-03, PNorm = 37.4979, GNorm = 3.2943, lr_0 = 1.0804e-04
Loss = 1.5339e-03, PNorm = 37.5004, GNorm = 1.3925, lr_0 = 1.0804e-04
Loss = 1.2503e-03, PNorm = 37.5033, GNorm = 1.7483, lr_0 = 1.0804e-04
Loss = 1.4057e-03, PNorm = 37.5060, GNorm = 3.4361, lr_0 = 1.0804e-04
Loss = 1.5269e-03, PNorm = 37.5093, GNorm = 4.5436, lr_0 = 1.0804e-04
Validation rmse logD = 0.622524
Validation R2 logD = 0.737275
Epoch 96
Train function
Loss = 1.5472e-03, PNorm = 37.5130, GNorm = 4.4295, lr_0 = 1.0804e-04
Loss = 1.4369e-03, PNorm = 37.5163, GNorm = 4.9410, lr_0 = 1.0804e-04
Loss = 1.4852e-03, PNorm = 37.5198, GNorm = 1.3241, lr_0 = 1.0804e-04
Loss = 1.4947e-03, PNorm = 37.5226, GNorm = 2.7613, lr_0 = 1.0804e-04
Loss = 1.4269e-03, PNorm = 37.5259, GNorm = 3.5574, lr_0 = 1.0804e-04
Loss = 1.5680e-03, PNorm = 37.5285, GNorm = 6.9674, lr_0 = 1.0804e-04
Validation rmse logD = 0.631204
Validation R2 logD = 0.729897
Epoch 97
Train function
Loss = 1.0917e-03, PNorm = 37.5319, GNorm = 1.1818, lr_0 = 1.0804e-04
Loss = 1.2671e-03, PNorm = 37.5346, GNorm = 1.2297, lr_0 = 1.0804e-04
Loss = 1.3017e-03, PNorm = 37.5377, GNorm = 1.1964, lr_0 = 1.0804e-04
Loss = 1.6761e-03, PNorm = 37.5420, GNorm = 1.4230, lr_0 = 1.0804e-04
Loss = 1.4159e-03, PNorm = 37.5456, GNorm = 4.4378, lr_0 = 1.0804e-04
Loss = 1.3060e-03, PNorm = 37.5485, GNorm = 4.4042, lr_0 = 1.0804e-04
Validation rmse logD = 0.622031
Validation R2 logD = 0.737691
Epoch 98
Train function
Loss = 1.3828e-03, PNorm = 37.5519, GNorm = 4.5991, lr_0 = 1.0804e-04
Loss = 1.0891e-03, PNorm = 37.5555, GNorm = 1.8635, lr_0 = 1.0804e-04
Loss = 1.3325e-03, PNorm = 37.5585, GNorm = 1.7364, lr_0 = 1.0804e-04
Loss = 1.7698e-03, PNorm = 37.5616, GNorm = 1.2353, lr_0 = 1.0804e-04
Loss = 1.8102e-03, PNorm = 37.5646, GNorm = 7.2187, lr_0 = 1.0804e-04
Validation rmse logD = 0.614127
Validation R2 logD = 0.744315
Epoch 99
Train function
Loss = 1.2473e-03, PNorm = 37.5680, GNorm = 2.3967, lr_0 = 1.0804e-04
Loss = 1.2622e-03, PNorm = 37.5702, GNorm = 5.8827, lr_0 = 1.0804e-04
Loss = 1.3157e-03, PNorm = 37.5734, GNorm = 5.1411, lr_0 = 1.0804e-04
Loss = 1.7782e-03, PNorm = 37.5766, GNorm = 3.8866, lr_0 = 1.0804e-04
Loss = 1.5908e-03, PNorm = 37.5800, GNorm = 4.8816, lr_0 = 1.0804e-04
Loss = 1.4613e-03, PNorm = 37.5840, GNorm = 4.0636, lr_0 = 1.0804e-04
Validation rmse logD = 0.616746
Validation R2 logD = 0.742130
Model 0 best validation rmse = 0.614127 on epoch 98
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.567807
Model 0 test R2 logD = 0.747130
Ensemble test rmse  logD= 0.567807
Ensemble test R2  logD= 0.747130
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_365/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.4056e-02, PNorm = 35.0055, GNorm = 5.5275, lr_0 = 1.0804e-04
Loss = 2.0614e-02, PNorm = 35.0055, GNorm = 3.7805, lr_0 = 1.0804e-04
Loss = 1.6017e-02, PNorm = 35.0067, GNorm = 7.2970, lr_0 = 1.0804e-04
Loss = 1.5668e-02, PNorm = 35.0081, GNorm = 2.1834, lr_0 = 1.0804e-04
Loss = 1.6256e-02, PNorm = 35.0101, GNorm = 2.1905, lr_0 = 1.0804e-04
Validation rmse logD = 1.066937
Validation R2 logD = 0.227952
Epoch 1
Train function
Loss = 1.3880e-02, PNorm = 35.0129, GNorm = 1.7054, lr_0 = 1.0804e-04
Loss = 1.5232e-02, PNorm = 35.0154, GNorm = 2.2021, lr_0 = 1.0804e-04
Loss = 1.4822e-02, PNorm = 35.0182, GNorm = 1.7393, lr_0 = 1.0804e-04
Loss = 1.4614e-02, PNorm = 35.0209, GNorm = 3.9035, lr_0 = 1.0804e-04
Loss = 1.3272e-02, PNorm = 35.0236, GNorm = 3.2748, lr_0 = 1.0804e-04
Loss = 1.4995e-02, PNorm = 35.0265, GNorm = 3.4838, lr_0 = 1.0804e-04
Validation rmse logD = 1.048826
Validation R2 logD = 0.253939
Epoch 2
Train function
Loss = 1.3957e-02, PNorm = 35.0293, GNorm = 1.5234, lr_0 = 1.0804e-04
Loss = 1.2815e-02, PNorm = 35.0326, GNorm = 4.2762, lr_0 = 1.0804e-04
Loss = 1.2428e-02, PNorm = 35.0353, GNorm = 7.0048, lr_0 = 1.0804e-04
Loss = 1.4510e-02, PNorm = 35.0391, GNorm = 2.1329, lr_0 = 1.0804e-04
Loss = 1.2267e-02, PNorm = 35.0423, GNorm = 2.5104, lr_0 = 1.0804e-04
Validation rmse logD = 0.993596
Validation R2 logD = 0.330444
Epoch 3
Train function
Loss = 8.7894e-03, PNorm = 35.0458, GNorm = 3.6438, lr_0 = 1.0804e-04
Loss = 1.2793e-02, PNorm = 35.0494, GNorm = 3.1639, lr_0 = 1.0804e-04
Loss = 1.1890e-02, PNorm = 35.0533, GNorm = 4.5387, lr_0 = 1.0804e-04
Loss = 1.2236e-02, PNorm = 35.0582, GNorm = 1.7820, lr_0 = 1.0804e-04
Loss = 1.1644e-02, PNorm = 35.0624, GNorm = 2.5840, lr_0 = 1.0804e-04
Loss = 1.0017e-02, PNorm = 35.0664, GNorm = 1.7166, lr_0 = 1.0804e-04
Validation rmse logD = 0.986755
Validation R2 logD = 0.339632
Epoch 4
Train function
Loss = 1.2454e-02, PNorm = 35.0708, GNorm = 5.5685, lr_0 = 1.0804e-04
Loss = 1.2052e-02, PNorm = 35.0747, GNorm = 3.4105, lr_0 = 1.0804e-04
Loss = 1.0906e-02, PNorm = 35.0784, GNorm = 7.1228, lr_0 = 1.0804e-04
Loss = 1.1022e-02, PNorm = 35.0831, GNorm = 1.9164, lr_0 = 1.0804e-04
Loss = 1.0275e-02, PNorm = 35.0873, GNorm = 5.7474, lr_0 = 1.0804e-04
Loss = 1.1720e-02, PNorm = 35.0908, GNorm = 4.2890, lr_0 = 1.0804e-04
Validation rmse logD = 0.910017
Validation R2 logD = 0.438350
Epoch 5
Train function
Loss = 1.1107e-02, PNorm = 35.0954, GNorm = 3.6682, lr_0 = 1.0804e-04
Loss = 9.4993e-03, PNorm = 35.1001, GNorm = 2.0036, lr_0 = 1.0804e-04
Loss = 1.0334e-02, PNorm = 35.1053, GNorm = 4.0034, lr_0 = 1.0804e-04
Loss = 1.1214e-02, PNorm = 35.1103, GNorm = 1.5408, lr_0 = 1.0804e-04
Loss = 9.7162e-03, PNorm = 35.1148, GNorm = 1.4310, lr_0 = 1.0804e-04
Validation rmse logD = 0.883913
Validation R2 logD = 0.470110
Epoch 6
Train function
Loss = 1.4329e-02, PNorm = 35.1206, GNorm = 2.0032, lr_0 = 1.0804e-04
Loss = 9.2958e-03, PNorm = 35.1262, GNorm = 1.4694, lr_0 = 1.0804e-04
Loss = 9.1142e-03, PNorm = 35.1313, GNorm = 6.4328, lr_0 = 1.0804e-04
Loss = 1.0069e-02, PNorm = 35.1362, GNorm = 1.6482, lr_0 = 1.0804e-04
Loss = 9.8988e-03, PNorm = 35.1424, GNorm = 7.5989, lr_0 = 1.0804e-04
Loss = 1.0504e-02, PNorm = 35.1477, GNorm = 5.8622, lr_0 = 1.0804e-04
Validation rmse logD = 0.871157
Validation R2 logD = 0.485293
Epoch 7
Train function
Loss = 9.7708e-03, PNorm = 35.1523, GNorm = 2.8078, lr_0 = 1.0804e-04
Loss = 8.7296e-03, PNorm = 35.1574, GNorm = 4.9263, lr_0 = 1.0804e-04
Loss = 9.0830e-03, PNorm = 35.1614, GNorm = 4.2957, lr_0 = 1.0804e-04
Loss = 9.0594e-03, PNorm = 35.1670, GNorm = 3.4927, lr_0 = 1.0804e-04
Loss = 9.5234e-03, PNorm = 35.1727, GNorm = 6.1495, lr_0 = 1.0804e-04
Loss = 1.0495e-02, PNorm = 35.1784, GNorm = 5.3248, lr_0 = 1.0804e-04
Validation rmse logD = 0.875297
Validation R2 logD = 0.480389
Epoch 8
Train function
Loss = 1.0108e-02, PNorm = 35.1836, GNorm = 4.3688, lr_0 = 1.0804e-04
Loss = 7.9977e-03, PNorm = 35.1897, GNorm = 1.7986, lr_0 = 1.0804e-04
Loss = 9.1963e-03, PNorm = 35.1948, GNorm = 7.6327, lr_0 = 1.0804e-04
Loss = 9.0953e-03, PNorm = 35.2005, GNorm = 4.3585, lr_0 = 1.0804e-04
Loss = 8.8895e-03, PNorm = 35.2065, GNorm = 1.4458, lr_0 = 1.0804e-04
Validation rmse logD = 0.837128
Validation R2 logD = 0.524719
Epoch 9
Train function
Loss = 6.2048e-03, PNorm = 35.2124, GNorm = 1.6794, lr_0 = 1.0804e-04
Loss = 7.9854e-03, PNorm = 35.2184, GNorm = 2.4190, lr_0 = 1.0804e-04
Loss = 9.2472e-03, PNorm = 35.2258, GNorm = 5.5220, lr_0 = 1.0804e-04
Loss = 9.2473e-03, PNorm = 35.2324, GNorm = 6.8923, lr_0 = 1.0804e-04
Loss = 9.0218e-03, PNorm = 35.2386, GNorm = 5.4281, lr_0 = 1.0804e-04
Loss = 8.8255e-03, PNorm = 35.2443, GNorm = 4.5961, lr_0 = 1.0804e-04
Validation rmse logD = 0.820226
Validation R2 logD = 0.543717
Epoch 10
Train function
Loss = 9.2840e-03, PNorm = 35.2492, GNorm = 1.8112, lr_0 = 1.0804e-04
Loss = 8.7126e-03, PNorm = 35.2551, GNorm = 4.8148, lr_0 = 1.0804e-04
Loss = 8.8157e-03, PNorm = 35.2619, GNorm = 4.8386, lr_0 = 1.0804e-04
Loss = 8.0912e-03, PNorm = 35.2688, GNorm = 2.0862, lr_0 = 1.0804e-04
Loss = 8.0854e-03, PNorm = 35.2754, GNorm = 2.3203, lr_0 = 1.0804e-04
Loss = 7.4139e-03, PNorm = 35.2809, GNorm = 1.8014, lr_0 = 1.0804e-04
Validation rmse logD = 0.804322
Validation R2 logD = 0.561239
Epoch 11
Train function
Loss = 9.2847e-03, PNorm = 35.2865, GNorm = 5.8550, lr_0 = 1.0804e-04
Loss = 7.4755e-03, PNorm = 35.2925, GNorm = 1.9694, lr_0 = 1.0804e-04
Loss = 8.2159e-03, PNorm = 35.2985, GNorm = 2.3002, lr_0 = 1.0804e-04
Loss = 6.7375e-03, PNorm = 35.3050, GNorm = 1.9024, lr_0 = 1.0804e-04
Loss = 7.9840e-03, PNorm = 35.3117, GNorm = 2.0695, lr_0 = 1.0804e-04
Validation rmse logD = 0.796688
Validation R2 logD = 0.569530
Epoch 12
Train function
Loss = 1.1719e-02, PNorm = 35.3200, GNorm = 2.5004, lr_0 = 1.0804e-04
Loss = 7.5511e-03, PNorm = 35.3278, GNorm = 1.5531, lr_0 = 1.0804e-04
Loss = 7.1219e-03, PNorm = 35.3348, GNorm = 2.8841, lr_0 = 1.0804e-04
Loss = 8.0643e-03, PNorm = 35.3416, GNorm = 6.0344, lr_0 = 1.0804e-04
Loss = 7.0821e-03, PNorm = 35.3481, GNorm = 5.6869, lr_0 = 1.0804e-04
Loss = 7.5443e-03, PNorm = 35.3545, GNorm = 1.9111, lr_0 = 1.0804e-04
Validation rmse logD = 0.780914
Validation R2 logD = 0.586407
Epoch 13
Train function
Loss = 7.6441e-03, PNorm = 35.3617, GNorm = 3.4936, lr_0 = 1.0804e-04
Loss = 7.0780e-03, PNorm = 35.3696, GNorm = 2.3572, lr_0 = 1.0804e-04
Loss = 7.6970e-03, PNorm = 35.3769, GNorm = 4.0212, lr_0 = 1.0804e-04
Loss = 7.2703e-03, PNorm = 35.3838, GNorm = 7.7549, lr_0 = 1.0804e-04
Loss = 7.8349e-03, PNorm = 35.3899, GNorm = 3.3517, lr_0 = 1.0804e-04
Loss = 6.7843e-03, PNorm = 35.3952, GNorm = 2.1376, lr_0 = 1.0804e-04
Validation rmse logD = 0.785077
Validation R2 logD = 0.581985
Epoch 14
Train function
Loss = 7.1050e-03, PNorm = 35.4008, GNorm = 5.6102, lr_0 = 1.0804e-04
Loss = 7.1806e-03, PNorm = 35.4068, GNorm = 10.6165, lr_0 = 1.0804e-04
Loss = 7.5747e-03, PNorm = 35.4131, GNorm = 3.5815, lr_0 = 1.0804e-04
Loss = 7.0568e-03, PNorm = 35.4202, GNorm = 1.3951, lr_0 = 1.0804e-04
Loss = 7.0165e-03, PNorm = 35.4286, GNorm = 2.6670, lr_0 = 1.0804e-04
Validation rmse logD = 0.763161
Validation R2 logD = 0.604997
Epoch 15
Train function
Loss = 5.7278e-03, PNorm = 35.4375, GNorm = 5.1064, lr_0 = 1.0804e-04
Loss = 5.9703e-03, PNorm = 35.4454, GNorm = 4.3727, lr_0 = 1.0804e-04
Loss = 6.9795e-03, PNorm = 35.4528, GNorm = 2.1769, lr_0 = 1.0804e-04
Loss = 7.4500e-03, PNorm = 35.4597, GNorm = 10.1295, lr_0 = 1.0804e-04
Loss = 6.2165e-03, PNorm = 35.4654, GNorm = 1.1574, lr_0 = 1.0804e-04
Loss = 7.5972e-03, PNorm = 35.4721, GNorm = 6.7160, lr_0 = 1.0804e-04
Validation rmse logD = 0.772456
Validation R2 logD = 0.595317
Epoch 16
Train function
Loss = 7.3344e-03, PNorm = 35.4793, GNorm = 3.2050, lr_0 = 1.0804e-04
Loss = 7.3282e-03, PNorm = 35.4869, GNorm = 2.4841, lr_0 = 1.0804e-04
Loss = 6.4670e-03, PNorm = 35.4948, GNorm = 7.3214, lr_0 = 1.0804e-04
Loss = 7.8613e-03, PNorm = 35.5016, GNorm = 9.8667, lr_0 = 1.0804e-04
Loss = 6.9591e-03, PNorm = 35.5083, GNorm = 3.1129, lr_0 = 1.0804e-04
Loss = 6.4381e-03, PNorm = 35.5142, GNorm = 3.3570, lr_0 = 1.0804e-04
Validation rmse logD = 0.752925
Validation R2 logD = 0.615523
Epoch 17
Train function
Loss = 6.7716e-03, PNorm = 35.5208, GNorm = 1.4655, lr_0 = 1.0804e-04
Loss = 6.0459e-03, PNorm = 35.5283, GNorm = 1.6061, lr_0 = 1.0804e-04
Loss = 5.8358e-03, PNorm = 35.5359, GNorm = 2.0196, lr_0 = 1.0804e-04
Loss = 6.8279e-03, PNorm = 35.5426, GNorm = 2.7596, lr_0 = 1.0804e-04
Loss = 6.8226e-03, PNorm = 35.5494, GNorm = 1.7423, lr_0 = 1.0804e-04
Validation rmse logD = 0.756697
Validation R2 logD = 0.611661
Epoch 18
Train function
Loss = 5.6752e-03, PNorm = 35.5574, GNorm = 3.7362, lr_0 = 1.0804e-04
Loss = 5.7857e-03, PNorm = 35.5642, GNorm = 3.2355, lr_0 = 1.0804e-04
Loss = 6.2434e-03, PNorm = 35.5702, GNorm = 8.1971, lr_0 = 1.0804e-04
Loss = 6.3551e-03, PNorm = 35.5765, GNorm = 2.0713, lr_0 = 1.0804e-04
Loss = 6.6516e-03, PNorm = 35.5820, GNorm = 5.5630, lr_0 = 1.0804e-04
Loss = 6.8510e-03, PNorm = 35.5889, GNorm = 4.4286, lr_0 = 1.0804e-04
Validation rmse logD = 0.746112
Validation R2 logD = 0.622449
Epoch 19
Train function
Loss = 6.7120e-03, PNorm = 35.5954, GNorm = 1.7659, lr_0 = 1.0804e-04
Loss = 6.0651e-03, PNorm = 35.6026, GNorm = 3.3625, lr_0 = 1.0804e-04
Loss = 6.3219e-03, PNorm = 35.6095, GNorm = 4.4039, lr_0 = 1.0804e-04
Loss = 5.8756e-03, PNorm = 35.6160, GNorm = 3.3709, lr_0 = 1.0804e-04
Loss = 6.5835e-03, PNorm = 35.6239, GNorm = 4.8781, lr_0 = 1.0804e-04
Loss = 5.7752e-03, PNorm = 35.6317, GNorm = 5.4319, lr_0 = 1.0804e-04
Validation rmse logD = 0.716965
Validation R2 logD = 0.651372
Epoch 20
Train function
Loss = 5.9952e-03, PNorm = 35.6384, GNorm = 7.7919, lr_0 = 1.0804e-04
Loss = 6.1771e-03, PNorm = 35.6437, GNorm = 2.8098, lr_0 = 1.0804e-04
Loss = 5.8809e-03, PNorm = 35.6498, GNorm = 6.0708, lr_0 = 1.0804e-04
Loss = 5.5079e-03, PNorm = 35.6572, GNorm = 2.4765, lr_0 = 1.0804e-04
Loss = 5.9631e-03, PNorm = 35.6649, GNorm = 1.4407, lr_0 = 1.0804e-04
Validation rmse logD = 0.704868
Validation R2 logD = 0.663037
Epoch 21
Train function
Loss = 3.5308e-03, PNorm = 35.6715, GNorm = 2.0220, lr_0 = 1.0804e-04
Loss = 4.9042e-03, PNorm = 35.6781, GNorm = 1.3733, lr_0 = 1.0804e-04
Loss = 5.6884e-03, PNorm = 35.6856, GNorm = 2.6021, lr_0 = 1.0804e-04
Loss = 5.9747e-03, PNorm = 35.6928, GNorm = 2.6726, lr_0 = 1.0804e-04
Loss = 5.5271e-03, PNorm = 35.6998, GNorm = 1.7484, lr_0 = 1.0804e-04
Loss = 6.4833e-03, PNorm = 35.7077, GNorm = 2.1435, lr_0 = 1.0804e-04
Validation rmse logD = 0.706535
Validation R2 logD = 0.661441
Epoch 22
Train function
Loss = 5.7664e-03, PNorm = 35.7134, GNorm = 5.0254, lr_0 = 1.0804e-04
Loss = 5.5535e-03, PNorm = 35.7181, GNorm = 4.5753, lr_0 = 1.0804e-04
Loss = 5.4833e-03, PNorm = 35.7242, GNorm = 2.5379, lr_0 = 1.0804e-04
Loss = 6.2205e-03, PNorm = 35.7312, GNorm = 2.7821, lr_0 = 1.0804e-04
Loss = 5.4890e-03, PNorm = 35.7387, GNorm = 2.6325, lr_0 = 1.0804e-04
Loss = 5.4779e-03, PNorm = 35.7456, GNorm = 1.2881, lr_0 = 1.0804e-04
Validation rmse logD = 0.699347
Validation R2 logD = 0.668295
Epoch 23
Train function
Loss = 5.6367e-03, PNorm = 35.7518, GNorm = 3.1214, lr_0 = 1.0804e-04
Loss = 5.4734e-03, PNorm = 35.7576, GNorm = 4.0108, lr_0 = 1.0804e-04
Loss = 5.7516e-03, PNorm = 35.7634, GNorm = 1.2126, lr_0 = 1.0804e-04
Loss = 5.5975e-03, PNorm = 35.7701, GNorm = 1.6400, lr_0 = 1.0804e-04
Loss = 5.4401e-03, PNorm = 35.7765, GNorm = 2.8807, lr_0 = 1.0804e-04
Validation rmse logD = 0.681122
Validation R2 logD = 0.685358
Epoch 24
Train function
Loss = 3.0791e-03, PNorm = 35.7835, GNorm = 1.1060, lr_0 = 1.0804e-04
Loss = 5.0036e-03, PNorm = 35.7913, GNorm = 2.6499, lr_0 = 1.0804e-04
Loss = 5.3491e-03, PNorm = 35.7977, GNorm = 1.9125, lr_0 = 1.0804e-04
Loss = 5.2914e-03, PNorm = 35.8037, GNorm = 2.0716, lr_0 = 1.0804e-04
Loss = 5.2339e-03, PNorm = 35.8093, GNorm = 2.4265, lr_0 = 1.0804e-04
Loss = 5.2660e-03, PNorm = 35.8145, GNorm = 4.1457, lr_0 = 1.0804e-04
Validation rmse logD = 0.674661
Validation R2 logD = 0.691298
Epoch 25
Train function
Loss = 4.7056e-03, PNorm = 35.8213, GNorm = 1.5485, lr_0 = 1.0804e-04
Loss = 5.3353e-03, PNorm = 35.8276, GNorm = 4.0596, lr_0 = 1.0804e-04
Loss = 4.9892e-03, PNorm = 35.8339, GNorm = 1.8277, lr_0 = 1.0804e-04
Loss = 5.0276e-03, PNorm = 35.8403, GNorm = 3.8535, lr_0 = 1.0804e-04
Loss = 4.4425e-03, PNorm = 35.8471, GNorm = 1.4683, lr_0 = 1.0804e-04
Loss = 5.4308e-03, PNorm = 35.8532, GNorm = 5.8068, lr_0 = 1.0804e-04
Validation rmse logD = 0.671049
Validation R2 logD = 0.694596
Epoch 26
Train function
Loss = 4.4513e-03, PNorm = 35.8598, GNorm = 2.7936, lr_0 = 1.0804e-04
Loss = 5.1117e-03, PNorm = 35.8662, GNorm = 1.7681, lr_0 = 1.0804e-04
Loss = 4.4471e-03, PNorm = 35.8729, GNorm = 2.6182, lr_0 = 1.0804e-04
Loss = 5.0449e-03, PNorm = 35.8795, GNorm = 7.7514, lr_0 = 1.0804e-04
Loss = 5.0259e-03, PNorm = 35.8862, GNorm = 2.4270, lr_0 = 1.0804e-04
Validation rmse logD = 0.658095
Validation R2 logD = 0.706273
Epoch 27
Train function
Loss = 6.0135e-03, PNorm = 35.8917, GNorm = 2.1970, lr_0 = 1.0804e-04
Loss = 4.3451e-03, PNorm = 35.8960, GNorm = 1.8816, lr_0 = 1.0804e-04
Loss = 4.2446e-03, PNorm = 35.9010, GNorm = 1.8795, lr_0 = 1.0804e-04
Loss = 4.8416e-03, PNorm = 35.9068, GNorm = 1.6584, lr_0 = 1.0804e-04
Loss = 4.9363e-03, PNorm = 35.9135, GNorm = 2.7662, lr_0 = 1.0804e-04
Loss = 5.1667e-03, PNorm = 35.9197, GNorm = 8.7365, lr_0 = 1.0804e-04
Validation rmse logD = 0.659925
Validation R2 logD = 0.704636
Epoch 28
Train function
Loss = 4.0876e-03, PNorm = 35.9254, GNorm = 4.6508, lr_0 = 1.0804e-04
Loss = 4.9646e-03, PNorm = 35.9316, GNorm = 9.0861, lr_0 = 1.0804e-04
Loss = 5.4301e-03, PNorm = 35.9373, GNorm = 2.2533, lr_0 = 1.0804e-04
Loss = 4.8761e-03, PNorm = 35.9430, GNorm = 6.1769, lr_0 = 1.0804e-04
Loss = 4.1947e-03, PNorm = 35.9483, GNorm = 1.5236, lr_0 = 1.0804e-04
Loss = 5.0579e-03, PNorm = 35.9545, GNorm = 5.6822, lr_0 = 1.0804e-04
Validation rmse logD = 0.678301
Validation R2 logD = 0.687959
Epoch 29
Train function
Loss = 4.5894e-03, PNorm = 35.9603, GNorm = 8.2591, lr_0 = 1.0804e-04
Loss = 4.4743e-03, PNorm = 35.9651, GNorm = 1.7700, lr_0 = 1.0804e-04
Loss = 4.7126e-03, PNorm = 35.9710, GNorm = 1.5028, lr_0 = 1.0804e-04
Loss = 4.5859e-03, PNorm = 35.9761, GNorm = 4.1989, lr_0 = 1.0804e-04
Loss = 4.9261e-03, PNorm = 35.9805, GNorm = 2.1102, lr_0 = 1.0804e-04
Validation rmse logD = 0.658841
Validation R2 logD = 0.705606
Epoch 30
Train function
Loss = 4.2447e-03, PNorm = 35.9858, GNorm = 2.1951, lr_0 = 1.0804e-04
Loss = 4.6440e-03, PNorm = 35.9923, GNorm = 8.7940, lr_0 = 1.0804e-04
Loss = 4.1136e-03, PNorm = 35.9993, GNorm = 1.0537, lr_0 = 1.0804e-04
Loss = 4.8902e-03, PNorm = 36.0052, GNorm = 4.4151, lr_0 = 1.0804e-04
Loss = 4.7771e-03, PNorm = 36.0092, GNorm = 4.4990, lr_0 = 1.0804e-04
Loss = 4.9666e-03, PNorm = 36.0136, GNorm = 7.1766, lr_0 = 1.0804e-04
Validation rmse logD = 0.675714
Validation R2 logD = 0.690334
Epoch 31
Train function
Loss = 4.1442e-03, PNorm = 36.0176, GNorm = 4.6725, lr_0 = 1.0804e-04
Loss = 4.8736e-03, PNorm = 36.0224, GNorm = 2.3258, lr_0 = 1.0804e-04
Loss = 4.5269e-03, PNorm = 36.0281, GNorm = 2.4682, lr_0 = 1.0804e-04
Loss = 4.2429e-03, PNorm = 36.0334, GNorm = 2.4140, lr_0 = 1.0804e-04
Loss = 5.2555e-03, PNorm = 36.0390, GNorm = 5.0619, lr_0 = 1.0804e-04
Loss = 3.8962e-03, PNorm = 36.0447, GNorm = 2.4816, lr_0 = 1.0804e-04
Validation rmse logD = 0.650557
Validation R2 logD = 0.712963
Epoch 32
Train function
Loss = 4.4587e-03, PNorm = 36.0503, GNorm = 1.1379, lr_0 = 1.0804e-04
Loss = 4.2723e-03, PNorm = 36.0557, GNorm = 4.0653, lr_0 = 1.0804e-04
Loss = 4.4167e-03, PNorm = 36.0606, GNorm = 4.6153, lr_0 = 1.0804e-04
Loss = 4.4610e-03, PNorm = 36.0659, GNorm = 2.0122, lr_0 = 1.0804e-04
Loss = 4.2875e-03, PNorm = 36.0702, GNorm = 1.7354, lr_0 = 1.0804e-04
Validation rmse logD = 0.643067
Validation R2 logD = 0.719534
Epoch 33
Train function
Loss = 2.3008e-03, PNorm = 36.0765, GNorm = 2.1400, lr_0 = 1.0804e-04
Loss = 3.7110e-03, PNorm = 36.0826, GNorm = 4.8386, lr_0 = 1.0804e-04
Loss = 3.9854e-03, PNorm = 36.0890, GNorm = 3.6303, lr_0 = 1.0804e-04
Loss = 4.9461e-03, PNorm = 36.0942, GNorm = 2.6634, lr_0 = 1.0804e-04
Loss = 3.9861e-03, PNorm = 36.0994, GNorm = 4.3104, lr_0 = 1.0804e-04
Loss = 4.6691e-03, PNorm = 36.1040, GNorm = 3.4148, lr_0 = 1.0804e-04
Validation rmse logD = 0.640451
Validation R2 logD = 0.721812
Epoch 34
Train function
Loss = 4.2906e-03, PNorm = 36.1092, GNorm = 1.5265, lr_0 = 1.0804e-04
Loss = 4.0093e-03, PNorm = 36.1164, GNorm = 6.3446, lr_0 = 1.0804e-04
Loss = 5.1005e-03, PNorm = 36.1212, GNorm = 9.1305, lr_0 = 1.0804e-04
Loss = 3.7370e-03, PNorm = 36.1250, GNorm = 3.1855, lr_0 = 1.0804e-04
Loss = 4.5092e-03, PNorm = 36.1296, GNorm = 2.8714, lr_0 = 1.0804e-04
Loss = 3.6782e-03, PNorm = 36.1339, GNorm = 5.0713, lr_0 = 1.0804e-04
Validation rmse logD = 0.635191
Validation R2 logD = 0.726362
Epoch 35
Train function
Loss = 4.0137e-03, PNorm = 36.1389, GNorm = 1.3547, lr_0 = 1.0804e-04
Loss = 3.9090e-03, PNorm = 36.1449, GNorm = 2.6867, lr_0 = 1.0804e-04
Loss = 3.2964e-03, PNorm = 36.1491, GNorm = 1.4861, lr_0 = 1.0804e-04
Loss = 4.5089e-03, PNorm = 36.1533, GNorm = 4.9279, lr_0 = 1.0804e-04
Loss = 4.0385e-03, PNorm = 36.1582, GNorm = 2.0577, lr_0 = 1.0804e-04
Validation rmse logD = 0.641155
Validation R2 logD = 0.721200
Epoch 36
Train function
Loss = 3.6139e-03, PNorm = 36.1640, GNorm = 2.9042, lr_0 = 1.0804e-04
Loss = 3.8374e-03, PNorm = 36.1696, GNorm = 3.7564, lr_0 = 1.0804e-04
Loss = 4.0999e-03, PNorm = 36.1742, GNorm = 2.0268, lr_0 = 1.0804e-04
Loss = 4.2302e-03, PNorm = 36.1788, GNorm = 4.5439, lr_0 = 1.0804e-04
Loss = 3.4130e-03, PNorm = 36.1839, GNorm = 8.8567, lr_0 = 1.0804e-04
Loss = 4.0324e-03, PNorm = 36.1878, GNorm = 9.3896, lr_0 = 1.0804e-04
Validation rmse logD = 0.628148
Validation R2 logD = 0.732397
Epoch 37
Train function
Loss = 3.9342e-03, PNorm = 36.1931, GNorm = 1.7531, lr_0 = 1.0804e-04
Loss = 3.8806e-03, PNorm = 36.1987, GNorm = 6.9041, lr_0 = 1.0804e-04
Loss = 3.8760e-03, PNorm = 36.2034, GNorm = 6.3985, lr_0 = 1.0804e-04
Loss = 4.0031e-03, PNorm = 36.2087, GNorm = 6.1184, lr_0 = 1.0804e-04
Loss = 4.0826e-03, PNorm = 36.2141, GNorm = 3.0979, lr_0 = 1.0804e-04
Loss = 3.6285e-03, PNorm = 36.2197, GNorm = 3.6143, lr_0 = 1.0804e-04
Validation rmse logD = 0.624236
Validation R2 logD = 0.735720
Epoch 38
Train function
Loss = 3.7934e-03, PNorm = 36.2238, GNorm = 5.6136, lr_0 = 1.0804e-04
Loss = 3.5579e-03, PNorm = 36.2290, GNorm = 2.8235, lr_0 = 1.0804e-04
Loss = 3.8035e-03, PNorm = 36.2342, GNorm = 2.4069, lr_0 = 1.0804e-04
Loss = 3.8008e-03, PNorm = 36.2377, GNorm = 1.3652, lr_0 = 1.0804e-04
Loss = 4.0879e-03, PNorm = 36.2421, GNorm = 1.3698, lr_0 = 1.0804e-04
Validation rmse logD = 0.626005
Validation R2 logD = 0.734220
Epoch 39
Train function
Loss = 2.8123e-03, PNorm = 36.2473, GNorm = 1.4763, lr_0 = 1.0804e-04
Loss = 3.4870e-03, PNorm = 36.2532, GNorm = 1.7945, lr_0 = 1.0804e-04
Loss = 3.8854e-03, PNorm = 36.2584, GNorm = 3.6111, lr_0 = 1.0804e-04
Loss = 4.0038e-03, PNorm = 36.2623, GNorm = 2.2128, lr_0 = 1.0804e-04
Loss = 3.9568e-03, PNorm = 36.2656, GNorm = 8.2637, lr_0 = 1.0804e-04
Loss = 3.8009e-03, PNorm = 36.2705, GNorm = 2.9615, lr_0 = 1.0804e-04
Validation rmse logD = 0.621120
Validation R2 logD = 0.738352
Epoch 40
Train function
Loss = 2.9467e-03, PNorm = 36.2747, GNorm = 3.2446, lr_0 = 1.0804e-04
Loss = 3.7020e-03, PNorm = 36.2794, GNorm = 1.8305, lr_0 = 1.0804e-04
Loss = 3.6915e-03, PNorm = 36.2848, GNorm = 4.5524, lr_0 = 1.0804e-04
Loss = 3.7105e-03, PNorm = 36.2894, GNorm = 2.9485, lr_0 = 1.0804e-04
Loss = 3.7936e-03, PNorm = 36.2937, GNorm = 5.2646, lr_0 = 1.0804e-04
Loss = 3.6782e-03, PNorm = 36.2983, GNorm = 4.2644, lr_0 = 1.0804e-04
Validation rmse logD = 0.636276
Validation R2 logD = 0.725427
Epoch 41
Train function
Loss = 3.1802e-03, PNorm = 36.3024, GNorm = 3.4392, lr_0 = 1.0804e-04
Loss = 3.4785e-03, PNorm = 36.3070, GNorm = 2.4748, lr_0 = 1.0804e-04
Loss = 4.3575e-03, PNorm = 36.3116, GNorm = 3.0539, lr_0 = 1.0804e-04
Loss = 3.6260e-03, PNorm = 36.3160, GNorm = 7.2603, lr_0 = 1.0804e-04
Loss = 3.2812e-03, PNorm = 36.3205, GNorm = 2.9700, lr_0 = 1.0804e-04
Validation rmse logD = 0.616854
Validation R2 logD = 0.741934
Epoch 42
Train function
Loss = 4.1727e-03, PNorm = 36.3265, GNorm = 4.4302, lr_0 = 1.0804e-04
Loss = 4.1206e-03, PNorm = 36.3326, GNorm = 5.8345, lr_0 = 1.0804e-04
Loss = 3.7049e-03, PNorm = 36.3374, GNorm = 2.7950, lr_0 = 1.0804e-04
Loss = 3.6265e-03, PNorm = 36.3425, GNorm = 1.6462, lr_0 = 1.0804e-04
Loss = 3.2024e-03, PNorm = 36.3473, GNorm = 2.5775, lr_0 = 1.0804e-04
Loss = 3.1295e-03, PNorm = 36.3524, GNorm = 1.9891, lr_0 = 1.0804e-04
Validation rmse logD = 0.620642
Validation R2 logD = 0.738754
Epoch 43
Train function
Loss = 3.4086e-03, PNorm = 36.3556, GNorm = 6.5835, lr_0 = 1.0804e-04
Loss = 3.8742e-03, PNorm = 36.3583, GNorm = 2.5764, lr_0 = 1.0804e-04
Loss = 4.4394e-03, PNorm = 36.3609, GNorm = 7.2269, lr_0 = 1.0804e-04
Loss = 3.9364e-03, PNorm = 36.3640, GNorm = 4.5451, lr_0 = 1.0804e-04
Loss = 4.1401e-03, PNorm = 36.3683, GNorm = 3.5913, lr_0 = 1.0804e-04
Loss = 3.0561e-03, PNorm = 36.3751, GNorm = 2.1131, lr_0 = 1.0804e-04
Validation rmse logD = 0.629900
Validation R2 logD = 0.730902
Epoch 44
Train function
Loss = 3.0066e-03, PNorm = 36.3805, GNorm = 4.4631, lr_0 = 1.0804e-04
Loss = 3.1768e-03, PNorm = 36.3859, GNorm = 2.9272, lr_0 = 1.0804e-04
Loss = 3.3605e-03, PNorm = 36.3895, GNorm = 5.2281, lr_0 = 1.0804e-04
Loss = 3.6155e-03, PNorm = 36.3935, GNorm = 1.6606, lr_0 = 1.0804e-04
Loss = 3.7832e-03, PNorm = 36.3974, GNorm = 1.6537, lr_0 = 1.0804e-04
Validation rmse logD = 0.620362
Validation R2 logD = 0.738990
Epoch 45
Train function
Loss = 3.8549e-03, PNorm = 36.4021, GNorm = 2.6813, lr_0 = 1.0804e-04
Loss = 3.3315e-03, PNorm = 36.4064, GNorm = 1.5926, lr_0 = 1.0804e-04
Loss = 3.3810e-03, PNorm = 36.4114, GNorm = 6.9129, lr_0 = 1.0804e-04
Loss = 2.8781e-03, PNorm = 36.4161, GNorm = 6.5585, lr_0 = 1.0804e-04
Loss = 3.4374e-03, PNorm = 36.4209, GNorm = 1.8045, lr_0 = 1.0804e-04
Loss = 4.2221e-03, PNorm = 36.4251, GNorm = 11.4433, lr_0 = 1.0804e-04
Validation rmse logD = 0.623626
Validation R2 logD = 0.736236
Epoch 46
Train function
Loss = 3.1984e-03, PNorm = 36.4281, GNorm = 5.7794, lr_0 = 1.0804e-04
Loss = 2.8911e-03, PNorm = 36.4315, GNorm = 1.5750, lr_0 = 1.0804e-04
Loss = 4.0244e-03, PNorm = 36.4359, GNorm = 2.6283, lr_0 = 1.0804e-04
Loss = 3.1309e-03, PNorm = 36.4409, GNorm = 2.5384, lr_0 = 1.0804e-04
Loss = 3.2187e-03, PNorm = 36.4451, GNorm = 1.8764, lr_0 = 1.0804e-04
Loss = 3.4745e-03, PNorm = 36.4491, GNorm = 4.9336, lr_0 = 1.0804e-04
Validation rmse logD = 0.622622
Validation R2 logD = 0.737084
Epoch 47
Train function
Loss = 3.0452e-03, PNorm = 36.4528, GNorm = 8.4203, lr_0 = 1.0804e-04
Loss = 3.2814e-03, PNorm = 36.4561, GNorm = 2.0093, lr_0 = 1.0804e-04
Loss = 3.2752e-03, PNorm = 36.4601, GNorm = 3.0132, lr_0 = 1.0804e-04
Loss = 3.2738e-03, PNorm = 36.4652, GNorm = 2.0937, lr_0 = 1.0804e-04
Loss = 3.4934e-03, PNorm = 36.4697, GNorm = 2.1292, lr_0 = 1.0804e-04
Validation rmse logD = 0.611269
Validation R2 logD = 0.746585
Epoch 48
Train function
Loss = 2.8171e-03, PNorm = 36.4750, GNorm = 2.3463, lr_0 = 1.0804e-04
Loss = 2.8140e-03, PNorm = 36.4797, GNorm = 2.7765, lr_0 = 1.0804e-04
Loss = 3.8307e-03, PNorm = 36.4842, GNorm = 5.3579, lr_0 = 1.0804e-04
Loss = 3.4039e-03, PNorm = 36.4880, GNorm = 6.1754, lr_0 = 1.0804e-04
Loss = 3.1502e-03, PNorm = 36.4920, GNorm = 6.7394, lr_0 = 1.0804e-04
Loss = 3.3039e-03, PNorm = 36.4960, GNorm = 2.8211, lr_0 = 1.0804e-04
Validation rmse logD = 0.605647
Validation R2 logD = 0.751225
Epoch 49
Train function
Loss = 3.9787e-03, PNorm = 36.5015, GNorm = 3.9919, lr_0 = 1.0804e-04
Loss = 3.0606e-03, PNorm = 36.5071, GNorm = 3.7219, lr_0 = 1.0804e-04
Loss = 2.9011e-03, PNorm = 36.5105, GNorm = 2.8266, lr_0 = 1.0804e-04
Loss = 2.8735e-03, PNorm = 36.5137, GNorm = 2.6244, lr_0 = 1.0804e-04
Loss = 2.7862e-03, PNorm = 36.5184, GNorm = 2.5362, lr_0 = 1.0804e-04
Loss = 3.4206e-03, PNorm = 36.5239, GNorm = 6.6406, lr_0 = 1.0804e-04
Validation rmse logD = 0.617385
Validation R2 logD = 0.741489
Epoch 50
Train function
Loss = 2.8787e-03, PNorm = 36.5281, GNorm = 1.2157, lr_0 = 1.0804e-04
Loss = 2.8907e-03, PNorm = 36.5325, GNorm = 2.6378, lr_0 = 1.0804e-04
Loss = 3.6124e-03, PNorm = 36.5365, GNorm = 1.5892, lr_0 = 1.0804e-04
Loss = 2.8600e-03, PNorm = 36.5405, GNorm = 3.3889, lr_0 = 1.0804e-04
Loss = 2.8723e-03, PNorm = 36.5445, GNorm = 1.3475, lr_0 = 1.0804e-04
Validation rmse logD = 0.613911
Validation R2 logD = 0.744390
Epoch 51
Train function
Loss = 2.5946e-03, PNorm = 36.5493, GNorm = 3.4854, lr_0 = 1.0804e-04
Loss = 2.8481e-03, PNorm = 36.5541, GNorm = 1.4747, lr_0 = 1.0804e-04
Loss = 3.1286e-03, PNorm = 36.5573, GNorm = 8.1254, lr_0 = 1.0804e-04
Loss = 3.2497e-03, PNorm = 36.5617, GNorm = 1.7850, lr_0 = 1.0804e-04
Loss = 3.0673e-03, PNorm = 36.5657, GNorm = 2.8494, lr_0 = 1.0804e-04
Loss = 3.0832e-03, PNorm = 36.5699, GNorm = 5.0654, lr_0 = 1.0804e-04
Validation rmse logD = 0.633601
Validation R2 logD = 0.727730
Epoch 52
Train function
Loss = 2.8340e-03, PNorm = 36.5735, GNorm = 1.9592, lr_0 = 1.0804e-04
Loss = 2.8207e-03, PNorm = 36.5763, GNorm = 7.1494, lr_0 = 1.0804e-04
Loss = 3.1521e-03, PNorm = 36.5806, GNorm = 4.0495, lr_0 = 1.0804e-04
Loss = 2.8118e-03, PNorm = 36.5849, GNorm = 1.2847, lr_0 = 1.0804e-04
Loss = 3.3991e-03, PNorm = 36.5877, GNorm = 4.8464, lr_0 = 1.0804e-04
Loss = 3.0128e-03, PNorm = 36.5923, GNorm = 1.9424, lr_0 = 1.0804e-04
Validation rmse logD = 0.604161
Validation R2 logD = 0.752444
Epoch 53
Train function
Loss = 2.5386e-03, PNorm = 36.5966, GNorm = 7.2639, lr_0 = 1.0804e-04
Loss = 3.3107e-03, PNorm = 36.6009, GNorm = 4.5488, lr_0 = 1.0804e-04
Loss = 2.8480e-03, PNorm = 36.6056, GNorm = 1.8039, lr_0 = 1.0804e-04
Loss = 2.9018e-03, PNorm = 36.6097, GNorm = 1.8168, lr_0 = 1.0804e-04
Loss = 2.6135e-03, PNorm = 36.6126, GNorm = 4.5607, lr_0 = 1.0804e-04
Validation rmse logD = 0.599053
Validation R2 logD = 0.756613
Epoch 54
Train function
Loss = 2.7402e-03, PNorm = 36.6174, GNorm = 2.7135, lr_0 = 1.0804e-04
Loss = 2.9257e-03, PNorm = 36.6226, GNorm = 4.4922, lr_0 = 1.0804e-04
Loss = 3.1950e-03, PNorm = 36.6275, GNorm = 7.0670, lr_0 = 1.0804e-04
Loss = 2.9118e-03, PNorm = 36.6317, GNorm = 2.6210, lr_0 = 1.0804e-04
Loss = 2.9257e-03, PNorm = 36.6350, GNorm = 4.3980, lr_0 = 1.0804e-04
Loss = 2.9722e-03, PNorm = 36.6391, GNorm = 5.2335, lr_0 = 1.0804e-04
Validation rmse logD = 0.597095
Validation R2 logD = 0.758201
Epoch 55
Train function
Loss = 2.6445e-03, PNorm = 36.6440, GNorm = 2.8177, lr_0 = 1.0804e-04
Loss = 3.3947e-03, PNorm = 36.6484, GNorm = 3.4970, lr_0 = 1.0804e-04
Loss = 2.6953e-03, PNorm = 36.6527, GNorm = 2.5471, lr_0 = 1.0804e-04
Loss = 3.0171e-03, PNorm = 36.6561, GNorm = 2.0845, lr_0 = 1.0804e-04
Loss = 3.1876e-03, PNorm = 36.6600, GNorm = 6.9838, lr_0 = 1.0804e-04
Loss = 2.7075e-03, PNorm = 36.6635, GNorm = 4.0277, lr_0 = 1.0804e-04
Validation rmse logD = 0.601946
Validation R2 logD = 0.754256
Epoch 56
Train function
Loss = 2.9935e-03, PNorm = 36.6680, GNorm = 7.3747, lr_0 = 1.0804e-04
Loss = 2.7712e-03, PNorm = 36.6716, GNorm = 1.2509, lr_0 = 1.0804e-04
Loss = 3.3199e-03, PNorm = 36.6759, GNorm = 3.1733, lr_0 = 1.0804e-04
Loss = 2.8919e-03, PNorm = 36.6808, GNorm = 2.5691, lr_0 = 1.0804e-04
Loss = 2.5183e-03, PNorm = 36.6843, GNorm = 1.9700, lr_0 = 1.0804e-04
Validation rmse logD = 0.613744
Validation R2 logD = 0.744529
Epoch 57
Train function
Loss = 2.5404e-03, PNorm = 36.6875, GNorm = 6.3670, lr_0 = 1.0804e-04
Loss = 3.0992e-03, PNorm = 36.6910, GNorm = 2.0546, lr_0 = 1.0804e-04
Loss = 3.5434e-03, PNorm = 36.6942, GNorm = 8.7948, lr_0 = 1.0804e-04
Loss = 2.9843e-03, PNorm = 36.6983, GNorm = 3.5304, lr_0 = 1.0804e-04
Loss = 2.6809e-03, PNorm = 36.7020, GNorm = 2.2186, lr_0 = 1.0804e-04
Loss = 2.9668e-03, PNorm = 36.7054, GNorm = 8.4517, lr_0 = 1.0804e-04
Validation rmse logD = 0.604020
Validation R2 logD = 0.752560
Epoch 58
Train function
Loss = 2.9183e-03, PNorm = 36.7096, GNorm = 4.8224, lr_0 = 1.0804e-04
Loss = 2.7376e-03, PNorm = 36.7131, GNorm = 5.1291, lr_0 = 1.0804e-04
Loss = 2.3376e-03, PNorm = 36.7164, GNorm = 2.2318, lr_0 = 1.0804e-04
Loss = 2.9905e-03, PNorm = 36.7200, GNorm = 4.3214, lr_0 = 1.0804e-04
Loss = 2.7238e-03, PNorm = 36.7245, GNorm = 3.8537, lr_0 = 1.0804e-04
Loss = 2.6738e-03, PNorm = 36.7296, GNorm = 2.8659, lr_0 = 1.0804e-04
Validation rmse logD = 0.613396
Validation R2 logD = 0.744819
Epoch 59
Train function
Loss = 2.1819e-03, PNorm = 36.7341, GNorm = 1.1933, lr_0 = 1.0804e-04
Loss = 2.8007e-03, PNorm = 36.7374, GNorm = 7.3697, lr_0 = 1.0804e-04
Loss = 3.0512e-03, PNorm = 36.7403, GNorm = 1.2209, lr_0 = 1.0804e-04
Loss = 2.7462e-03, PNorm = 36.7446, GNorm = 6.7078, lr_0 = 1.0804e-04
Loss = 2.9406e-03, PNorm = 36.7486, GNorm = 1.8980, lr_0 = 1.0804e-04
Validation rmse logD = 0.595893
Validation R2 logD = 0.759174
Epoch 60
Train function
Loss = 3.8272e-03, PNorm = 36.7522, GNorm = 2.3564, lr_0 = 1.0804e-04
Loss = 2.5498e-03, PNorm = 36.7561, GNorm = 1.6310, lr_0 = 1.0804e-04
Loss = 2.4558e-03, PNorm = 36.7606, GNorm = 2.0518, lr_0 = 1.0804e-04
Loss = 2.5744e-03, PNorm = 36.7654, GNorm = 1.7248, lr_0 = 1.0804e-04
Loss = 2.4663e-03, PNorm = 36.7691, GNorm = 5.2633, lr_0 = 1.0804e-04
Loss = 2.9136e-03, PNorm = 36.7724, GNorm = 2.6326, lr_0 = 1.0804e-04
Validation rmse logD = 0.591237
Validation R2 logD = 0.762922
Epoch 61
Train function
Loss = 3.2545e-03, PNorm = 36.7754, GNorm = 8.6587, lr_0 = 1.0804e-04
Loss = 2.3357e-03, PNorm = 36.7794, GNorm = 2.5278, lr_0 = 1.0804e-04
Loss = 2.9047e-03, PNorm = 36.7832, GNorm = 5.2446, lr_0 = 1.0804e-04
Loss = 2.7129e-03, PNorm = 36.7871, GNorm = 3.1949, lr_0 = 1.0804e-04
Loss = 2.8004e-03, PNorm = 36.7915, GNorm = 3.5376, lr_0 = 1.0804e-04
Loss = 2.4112e-03, PNorm = 36.7953, GNorm = 3.0647, lr_0 = 1.0804e-04
Validation rmse logD = 0.594131
Validation R2 logD = 0.760596
Epoch 62
Train function
Loss = 2.5931e-03, PNorm = 36.7993, GNorm = 5.4917, lr_0 = 1.0804e-04
Loss = 2.2883e-03, PNorm = 36.8030, GNorm = 2.8525, lr_0 = 1.0804e-04
Loss = 2.8016e-03, PNorm = 36.8069, GNorm = 5.8771, lr_0 = 1.0804e-04
Loss = 2.7206e-03, PNorm = 36.8104, GNorm = 2.7803, lr_0 = 1.0804e-04
Loss = 2.7625e-03, PNorm = 36.8143, GNorm = 5.5715, lr_0 = 1.0804e-04
Validation rmse logD = 0.592722
Validation R2 logD = 0.761730
Epoch 63
Train function
Loss = 2.3262e-03, PNorm = 36.8191, GNorm = 2.7959, lr_0 = 1.0804e-04
Loss = 2.1737e-03, PNorm = 36.8236, GNorm = 3.4698, lr_0 = 1.0804e-04
Loss = 2.3493e-03, PNorm = 36.8282, GNorm = 3.9859, lr_0 = 1.0804e-04
Loss = 2.5133e-03, PNorm = 36.8320, GNorm = 4.8084, lr_0 = 1.0804e-04
Loss = 2.3512e-03, PNorm = 36.8353, GNorm = 1.9677, lr_0 = 1.0804e-04
Loss = 2.7278e-03, PNorm = 36.8388, GNorm = 2.4333, lr_0 = 1.0804e-04
Validation rmse logD = 0.590195
Validation R2 logD = 0.763757
Epoch 64
Train function
Loss = 2.9206e-03, PNorm = 36.8424, GNorm = 3.2062, lr_0 = 1.0804e-04
Loss = 2.3899e-03, PNorm = 36.8473, GNorm = 2.0013, lr_0 = 1.0804e-04
Loss = 2.7676e-03, PNorm = 36.8521, GNorm = 6.1822, lr_0 = 1.0804e-04
Loss = 1.9529e-03, PNorm = 36.8560, GNorm = 1.7531, lr_0 = 1.0804e-04
Loss = 2.5637e-03, PNorm = 36.8588, GNorm = 4.8469, lr_0 = 1.0804e-04
Loss = 2.7646e-03, PNorm = 36.8615, GNorm = 5.6498, lr_0 = 1.0804e-04
Validation rmse logD = 0.602980
Validation R2 logD = 0.753412
Epoch 65
Train function
Loss = 2.8249e-03, PNorm = 36.8648, GNorm = 3.5441, lr_0 = 1.0804e-04
Loss = 2.0137e-03, PNorm = 36.8677, GNorm = 2.0666, lr_0 = 1.0804e-04
Loss = 2.4926e-03, PNorm = 36.8727, GNorm = 2.6645, lr_0 = 1.0804e-04
Loss = 2.1778e-03, PNorm = 36.8774, GNorm = 4.0034, lr_0 = 1.0804e-04
Loss = 2.7368e-03, PNorm = 36.8801, GNorm = 4.7163, lr_0 = 1.0804e-04
Validation rmse logD = 0.596288
Validation R2 logD = 0.758855
Epoch 66
Train function
Loss = 2.5855e-03, PNorm = 36.8832, GNorm = 5.9393, lr_0 = 1.0804e-04
Loss = 2.8957e-03, PNorm = 36.8876, GNorm = 2.0603, lr_0 = 1.0804e-04
Loss = 2.2975e-03, PNorm = 36.8916, GNorm = 1.3202, lr_0 = 1.0804e-04
Loss = 2.8188e-03, PNorm = 36.8955, GNorm = 1.5960, lr_0 = 1.0804e-04
Loss = 2.2508e-03, PNorm = 36.8996, GNorm = 1.7988, lr_0 = 1.0804e-04
Loss = 2.1156e-03, PNorm = 36.9033, GNorm = 3.4219, lr_0 = 1.0804e-04
Validation rmse logD = 0.591804
Validation R2 logD = 0.762468
Epoch 67
Train function
Loss = 2.4031e-03, PNorm = 36.9065, GNorm = 1.2978, lr_0 = 1.0804e-04
Loss = 2.2290e-03, PNorm = 36.9105, GNorm = 3.1707, lr_0 = 1.0804e-04
Loss = 2.4943e-03, PNorm = 36.9132, GNorm = 6.0325, lr_0 = 1.0804e-04
Loss = 2.4383e-03, PNorm = 36.9159, GNorm = 6.4209, lr_0 = 1.0804e-04
Loss = 2.3074e-03, PNorm = 36.9193, GNorm = 1.3406, lr_0 = 1.0804e-04
Loss = 2.2654e-03, PNorm = 36.9242, GNorm = 2.6819, lr_0 = 1.0804e-04
Validation rmse logD = 0.591960
Validation R2 logD = 0.762343
Epoch 68
Train function
Loss = 2.3973e-03, PNorm = 36.9293, GNorm = 5.4460, lr_0 = 1.0804e-04
Loss = 2.0300e-03, PNorm = 36.9331, GNorm = 4.4664, lr_0 = 1.0804e-04
Loss = 2.3601e-03, PNorm = 36.9379, GNorm = 2.5303, lr_0 = 1.0804e-04
Loss = 2.2817e-03, PNorm = 36.9416, GNorm = 4.1871, lr_0 = 1.0804e-04
Loss = 2.0490e-03, PNorm = 36.9442, GNorm = 7.7786, lr_0 = 1.0804e-04
Validation rmse logD = 0.587513
Validation R2 logD = 0.765900
Epoch 69
Train function
Loss = 2.2421e-03, PNorm = 36.9476, GNorm = 2.3139, lr_0 = 1.0804e-04
Loss = 2.3390e-03, PNorm = 36.9508, GNorm = 8.2299, lr_0 = 1.0804e-04
Loss = 2.8327e-03, PNorm = 36.9535, GNorm = 5.8546, lr_0 = 1.0804e-04
Loss = 2.2667e-03, PNorm = 36.9570, GNorm = 3.0171, lr_0 = 1.0804e-04
Loss = 2.4474e-03, PNorm = 36.9608, GNorm = 4.3294, lr_0 = 1.0804e-04
Loss = 2.1004e-03, PNorm = 36.9655, GNorm = 1.9129, lr_0 = 1.0804e-04
Validation rmse logD = 0.587779
Validation R2 logD = 0.765687
Epoch 70
Train function
Loss = 1.9637e-03, PNorm = 36.9701, GNorm = 1.8906, lr_0 = 1.0804e-04
Loss = 1.9338e-03, PNorm = 36.9737, GNorm = 2.1412, lr_0 = 1.0804e-04
Loss = 2.6408e-03, PNorm = 36.9773, GNorm = 5.6589, lr_0 = 1.0804e-04
Loss = 2.1079e-03, PNorm = 36.9815, GNorm = 1.5346, lr_0 = 1.0804e-04
Loss = 2.0590e-03, PNorm = 36.9855, GNorm = 2.6452, lr_0 = 1.0804e-04
Loss = 2.1428e-03, PNorm = 36.9888, GNorm = 3.3467, lr_0 = 1.0804e-04
Validation rmse logD = 0.586650
Validation R2 logD = 0.766587
Epoch 71
Train function
Loss = 2.2092e-03, PNorm = 36.9929, GNorm = 2.4519, lr_0 = 1.0804e-04
Loss = 2.1341e-03, PNorm = 36.9969, GNorm = 4.2329, lr_0 = 1.0804e-04
Loss = 1.7763e-03, PNorm = 36.9992, GNorm = 4.1283, lr_0 = 1.0804e-04
Loss = 2.0125e-03, PNorm = 37.0027, GNorm = 1.0665, lr_0 = 1.0804e-04
Loss = 2.6818e-03, PNorm = 37.0069, GNorm = 4.5022, lr_0 = 1.0804e-04
Validation rmse logD = 0.600259
Validation R2 logD = 0.755632
Epoch 72
Train function
Loss = 1.7573e-03, PNorm = 37.0108, GNorm = 4.2861, lr_0 = 1.0804e-04
Loss = 2.2086e-03, PNorm = 37.0144, GNorm = 6.4626, lr_0 = 1.0804e-04
Loss = 2.4017e-03, PNorm = 37.0180, GNorm = 5.2406, lr_0 = 1.0804e-04
Loss = 2.3950e-03, PNorm = 37.0215, GNorm = 4.8589, lr_0 = 1.0804e-04
Loss = 2.3350e-03, PNorm = 37.0262, GNorm = 8.6148, lr_0 = 1.0804e-04
Loss = 2.2629e-03, PNorm = 37.0295, GNorm = 2.1288, lr_0 = 1.0804e-04
Validation rmse logD = 0.598312
Validation R2 logD = 0.757214
Epoch 73
Train function
Loss = 2.6029e-03, PNorm = 37.0320, GNorm = 4.2650, lr_0 = 1.0804e-04
Loss = 2.6782e-03, PNorm = 37.0355, GNorm = 5.1700, lr_0 = 1.0804e-04
Loss = 2.2828e-03, PNorm = 37.0396, GNorm = 3.3756, lr_0 = 1.0804e-04
Loss = 1.9742e-03, PNorm = 37.0439, GNorm = 2.3417, lr_0 = 1.0804e-04
Loss = 1.8234e-03, PNorm = 37.0473, GNorm = 5.5397, lr_0 = 1.0804e-04
Loss = 2.0621e-03, PNorm = 37.0511, GNorm = 1.7326, lr_0 = 1.0804e-04
Validation rmse logD = 0.597138
Validation R2 logD = 0.758166
Epoch 74
Train function
Loss = 2.0802e-03, PNorm = 37.0551, GNorm = 4.5074, lr_0 = 1.0804e-04
Loss = 1.9502e-03, PNorm = 37.0581, GNorm = 3.1153, lr_0 = 1.0804e-04
Loss = 1.8654e-03, PNorm = 37.0608, GNorm = 3.0457, lr_0 = 1.0804e-04
Loss = 1.9655e-03, PNorm = 37.0646, GNorm = 1.2088, lr_0 = 1.0804e-04
Loss = 2.5565e-03, PNorm = 37.0692, GNorm = 3.0023, lr_0 = 1.0804e-04
Validation rmse logD = 0.593742
Validation R2 logD = 0.760909
Epoch 75
Train function
Loss = 1.8571e-03, PNorm = 37.0731, GNorm = 4.4979, lr_0 = 1.0804e-04
Loss = 2.3955e-03, PNorm = 37.0765, GNorm = 2.6745, lr_0 = 1.0804e-04
Loss = 2.2343e-03, PNorm = 37.0806, GNorm = 2.2291, lr_0 = 1.0804e-04
Loss = 1.9956e-03, PNorm = 37.0845, GNorm = 2.0274, lr_0 = 1.0804e-04
Loss = 1.8097e-03, PNorm = 37.0877, GNorm = 1.3355, lr_0 = 1.0804e-04
Loss = 2.0303e-03, PNorm = 37.0919, GNorm = 2.0708, lr_0 = 1.0804e-04
Validation rmse logD = 0.584308
Validation R2 logD = 0.768447
Epoch 76
Train function
Loss = 2.4872e-03, PNorm = 37.0958, GNorm = 4.2334, lr_0 = 1.0804e-04
Loss = 2.0855e-03, PNorm = 37.0982, GNorm = 5.5047, lr_0 = 1.0804e-04
Loss = 1.9854e-03, PNorm = 37.1012, GNorm = 2.2978, lr_0 = 1.0804e-04
Loss = 2.0447e-03, PNorm = 37.1046, GNorm = 5.8678, lr_0 = 1.0804e-04
Loss = 2.0274e-03, PNorm = 37.1096, GNorm = 3.8113, lr_0 = 1.0804e-04
Loss = 1.9575e-03, PNorm = 37.1130, GNorm = 3.3097, lr_0 = 1.0804e-04
Validation rmse logD = 0.579891
Validation R2 logD = 0.771934
Epoch 77
Train function
Loss = 1.9561e-03, PNorm = 37.1164, GNorm = 3.2478, lr_0 = 1.0804e-04
Loss = 1.9530e-03, PNorm = 37.1196, GNorm = 6.7213, lr_0 = 1.0804e-04
Loss = 2.1232e-03, PNorm = 37.1231, GNorm = 2.4170, lr_0 = 1.0804e-04
Loss = 1.9794e-03, PNorm = 37.1270, GNorm = 1.7002, lr_0 = 1.0804e-04
Loss = 2.2460e-03, PNorm = 37.1317, GNorm = 4.1116, lr_0 = 1.0804e-04
Validation rmse logD = 0.583692
Validation R2 logD = 0.768935
Epoch 78
Train function
Loss = 2.4226e-03, PNorm = 37.1352, GNorm = 1.9950, lr_0 = 1.0804e-04
Loss = 1.9588e-03, PNorm = 37.1397, GNorm = 2.5243, lr_0 = 1.0804e-04
Loss = 1.7903e-03, PNorm = 37.1450, GNorm = 3.7596, lr_0 = 1.0804e-04
Loss = 1.9116e-03, PNorm = 37.1476, GNorm = 1.9644, lr_0 = 1.0804e-04
Loss = 2.1102e-03, PNorm = 37.1495, GNorm = 4.5767, lr_0 = 1.0804e-04
Loss = 2.1347e-03, PNorm = 37.1528, GNorm = 1.9575, lr_0 = 1.0804e-04
Validation rmse logD = 0.580680
Validation R2 logD = 0.771314
Epoch 79
Train function
Loss = 1.4308e-03, PNorm = 37.1568, GNorm = 2.2249, lr_0 = 1.0804e-04
Loss = 1.6807e-03, PNorm = 37.1607, GNorm = 2.1659, lr_0 = 1.0804e-04
Loss = 2.1020e-03, PNorm = 37.1640, GNorm = 3.6517, lr_0 = 1.0804e-04
Loss = 1.9741e-03, PNorm = 37.1681, GNorm = 5.7337, lr_0 = 1.0804e-04
Loss = 2.1192e-03, PNorm = 37.1708, GNorm = 6.9221, lr_0 = 1.0804e-04
Loss = 2.3563e-03, PNorm = 37.1734, GNorm = 1.7133, lr_0 = 1.0804e-04
Validation rmse logD = 0.583858
Validation R2 logD = 0.768803
Epoch 80
Train function
Loss = 1.9778e-03, PNorm = 37.1771, GNorm = 1.9658, lr_0 = 1.0804e-04
Loss = 2.0422e-03, PNorm = 37.1804, GNorm = 3.5836, lr_0 = 1.0804e-04
Loss = 2.0428e-03, PNorm = 37.1834, GNorm = 1.4704, lr_0 = 1.0804e-04
Loss = 2.3408e-03, PNorm = 37.1880, GNorm = 1.8403, lr_0 = 1.0804e-04
Loss = 2.7945e-03, PNorm = 37.1913, GNorm = 5.3401, lr_0 = 1.0804e-04
Validation rmse logD = 0.575532
Validation R2 logD = 0.775350
Epoch 81
Train function
Loss = 1.7965e-03, PNorm = 37.1950, GNorm = 5.2633, lr_0 = 1.0804e-04
Loss = 1.6391e-03, PNorm = 37.1993, GNorm = 1.1235, lr_0 = 1.0804e-04
Loss = 2.3682e-03, PNorm = 37.2047, GNorm = 5.2257, lr_0 = 1.0804e-04
Loss = 1.6080e-03, PNorm = 37.2089, GNorm = 2.5772, lr_0 = 1.0804e-04
Loss = 1.7748e-03, PNorm = 37.2117, GNorm = 3.3462, lr_0 = 1.0804e-04
Loss = 2.1278e-03, PNorm = 37.2147, GNorm = 1.7961, lr_0 = 1.0804e-04
Validation rmse logD = 0.580979
Validation R2 logD = 0.771078
Epoch 82
Train function
Loss = 1.7793e-03, PNorm = 37.2175, GNorm = 2.1780, lr_0 = 1.0804e-04
Loss = 1.6015e-03, PNorm = 37.2206, GNorm = 1.7031, lr_0 = 1.0804e-04
Loss = 1.9205e-03, PNorm = 37.2241, GNorm = 2.0528, lr_0 = 1.0804e-04
Loss = 1.5845e-03, PNorm = 37.2275, GNorm = 3.2321, lr_0 = 1.0804e-04
Loss = 2.1360e-03, PNorm = 37.2310, GNorm = 2.0388, lr_0 = 1.0804e-04
Loss = 2.0796e-03, PNorm = 37.2349, GNorm = 2.9611, lr_0 = 1.0804e-04
Validation rmse logD = 0.585036
Validation R2 logD = 0.767870
Epoch 83
Train function
Loss = 1.4550e-03, PNorm = 37.2386, GNorm = 1.1906, lr_0 = 1.0804e-04
Loss = 1.6045e-03, PNorm = 37.2422, GNorm = 2.2856, lr_0 = 1.0804e-04
Loss = 1.6235e-03, PNorm = 37.2460, GNorm = 3.7507, lr_0 = 1.0804e-04
Loss = 2.1977e-03, PNorm = 37.2496, GNorm = 7.2151, lr_0 = 1.0804e-04
Loss = 2.5056e-03, PNorm = 37.2533, GNorm = 3.4169, lr_0 = 1.0804e-04
Validation rmse logD = 0.605881
Validation R2 logD = 0.751033
Epoch 84
Train function
Loss = 2.0347e-03, PNorm = 37.2561, GNorm = 6.0429, lr_0 = 1.0804e-04
Loss = 1.9601e-03, PNorm = 37.2592, GNorm = 3.0051, lr_0 = 1.0804e-04
Loss = 1.8275e-03, PNorm = 37.2631, GNorm = 8.6363, lr_0 = 1.0804e-04
Loss = 1.8530e-03, PNorm = 37.2678, GNorm = 2.1253, lr_0 = 1.0804e-04
Loss = 1.7151e-03, PNorm = 37.2717, GNorm = 2.7880, lr_0 = 1.0804e-04
Loss = 2.1466e-03, PNorm = 37.2746, GNorm = 9.3901, lr_0 = 1.0804e-04
Validation rmse logD = 0.614326
Validation R2 logD = 0.744044
Epoch 85
Train function
Loss = 1.6631e-03, PNorm = 37.2774, GNorm = 4.2608, lr_0 = 1.0804e-04
Loss = 1.8166e-03, PNorm = 37.2822, GNorm = 3.3571, lr_0 = 1.0804e-04
Loss = 1.8639e-03, PNorm = 37.2858, GNorm = 2.4763, lr_0 = 1.0804e-04
Loss = 2.0887e-03, PNorm = 37.2883, GNorm = 2.0333, lr_0 = 1.0804e-04
Loss = 1.8673e-03, PNorm = 37.2904, GNorm = 5.1367, lr_0 = 1.0804e-04
Loss = 1.8286e-03, PNorm = 37.2932, GNorm = 1.4062, lr_0 = 1.0804e-04
Validation rmse logD = 0.579273
Validation R2 logD = 0.772420
Epoch 86
Train function
Loss = 1.8850e-03, PNorm = 37.2977, GNorm = 9.2954, lr_0 = 1.0804e-04
Loss = 1.6291e-03, PNorm = 37.3016, GNorm = 2.9357, lr_0 = 1.0804e-04
Loss = 1.7919e-03, PNorm = 37.3051, GNorm = 2.6094, lr_0 = 1.0804e-04
Loss = 1.7026e-03, PNorm = 37.3093, GNorm = 2.2648, lr_0 = 1.0804e-04
Loss = 1.4942e-03, PNorm = 37.3126, GNorm = 1.3517, lr_0 = 1.0804e-04
Validation rmse logD = 0.596656
Validation R2 logD = 0.758556
Epoch 87
Train function
Loss = 1.4629e-03, PNorm = 37.3150, GNorm = 5.3876, lr_0 = 1.0804e-04
Loss = 1.6900e-03, PNorm = 37.3172, GNorm = 4.7396, lr_0 = 1.0804e-04
Loss = 1.6135e-03, PNorm = 37.3211, GNorm = 4.6179, lr_0 = 1.0804e-04
Loss = 1.7613e-03, PNorm = 37.3245, GNorm = 2.3881, lr_0 = 1.0804e-04
Loss = 1.8605e-03, PNorm = 37.3285, GNorm = 1.4287, lr_0 = 1.0804e-04
Loss = 1.9557e-03, PNorm = 37.3321, GNorm = 6.3302, lr_0 = 1.0804e-04
Validation rmse logD = 0.655332
Validation R2 logD = 0.708733
Epoch 88
Train function
Loss = 2.0757e-03, PNorm = 37.3352, GNorm = 1.6960, lr_0 = 1.0804e-04
Loss = 1.9286e-03, PNorm = 37.3383, GNorm = 1.9563, lr_0 = 1.0804e-04
Loss = 1.6899e-03, PNorm = 37.3419, GNorm = 4.8780, lr_0 = 1.0804e-04
Loss = 1.8635e-03, PNorm = 37.3451, GNorm = 1.4396, lr_0 = 1.0804e-04
Loss = 1.7285e-03, PNorm = 37.3487, GNorm = 5.4682, lr_0 = 1.0804e-04
Loss = 1.7207e-03, PNorm = 37.3513, GNorm = 1.4334, lr_0 = 1.0804e-04
Validation rmse logD = 0.575276
Validation R2 logD = 0.775550
Epoch 89
Train function
Loss = 1.5734e-03, PNorm = 37.3544, GNorm = 2.3766, lr_0 = 1.0804e-04
Loss = 1.4238e-03, PNorm = 37.3584, GNorm = 3.6174, lr_0 = 1.0804e-04
Loss = 1.9155e-03, PNorm = 37.3610, GNorm = 4.8794, lr_0 = 1.0804e-04
Loss = 1.7121e-03, PNorm = 37.3634, GNorm = 2.9406, lr_0 = 1.0804e-04
Loss = 1.7297e-03, PNorm = 37.3666, GNorm = 3.6416, lr_0 = 1.0804e-04
Validation rmse logD = 0.586129
Validation R2 logD = 0.767001
Epoch 90
Train function
Loss = 1.9591e-03, PNorm = 37.3701, GNorm = 2.8608, lr_0 = 1.0804e-04
Loss = 1.6610e-03, PNorm = 37.3735, GNorm = 2.2667, lr_0 = 1.0804e-04
Loss = 1.5051e-03, PNorm = 37.3758, GNorm = 2.1425, lr_0 = 1.0804e-04
Loss = 1.8413e-03, PNorm = 37.3795, GNorm = 2.2520, lr_0 = 1.0804e-04
Loss = 1.7350e-03, PNorm = 37.3835, GNorm = 1.8220, lr_0 = 1.0804e-04
Loss = 1.9629e-03, PNorm = 37.3860, GNorm = 1.8715, lr_0 = 1.0804e-04
Validation rmse logD = 0.574844
Validation R2 logD = 0.775887
Epoch 91
Train function
Loss = 1.7775e-03, PNorm = 37.3879, GNorm = 2.1400, lr_0 = 1.0804e-04
Loss = 1.4615e-03, PNorm = 37.3921, GNorm = 4.4026, lr_0 = 1.0804e-04
Loss = 1.5504e-03, PNorm = 37.3953, GNorm = 3.2790, lr_0 = 1.0804e-04
Loss = 1.9145e-03, PNorm = 37.3989, GNorm = 2.3392, lr_0 = 1.0804e-04
Loss = 1.7196e-03, PNorm = 37.4015, GNorm = 4.0936, lr_0 = 1.0804e-04
Loss = 1.5331e-03, PNorm = 37.4041, GNorm = 3.9783, lr_0 = 1.0804e-04
Validation rmse logD = 0.578486
Validation R2 logD = 0.773039
Epoch 92
Train function
Loss = 1.3149e-03, PNorm = 37.4080, GNorm = 4.1914, lr_0 = 1.0804e-04
Loss = 1.7569e-03, PNorm = 37.4122, GNorm = 1.4740, lr_0 = 1.0804e-04
Loss = 1.6273e-03, PNorm = 37.4149, GNorm = 2.4767, lr_0 = 1.0804e-04
Loss = 1.7984e-03, PNorm = 37.4167, GNorm = 2.9270, lr_0 = 1.0804e-04
Loss = 1.7773e-03, PNorm = 37.4201, GNorm = 1.5434, lr_0 = 1.0804e-04
Validation rmse logD = 0.588388
Validation R2 logD = 0.765202
Epoch 93
Train function
Loss = 9.3379e-04, PNorm = 37.4242, GNorm = 2.9956, lr_0 = 1.0804e-04
Loss = 1.4363e-03, PNorm = 37.4281, GNorm = 2.2954, lr_0 = 1.0804e-04
Loss = 1.5842e-03, PNorm = 37.4313, GNorm = 2.3672, lr_0 = 1.0804e-04
Loss = 1.6577e-03, PNorm = 37.4341, GNorm = 4.3023, lr_0 = 1.0804e-04
Loss = 2.1225e-03, PNorm = 37.4359, GNorm = 4.0364, lr_0 = 1.0804e-04
Loss = 1.7963e-03, PNorm = 37.4388, GNorm = 7.9946, lr_0 = 1.0804e-04
Validation rmse logD = 0.587113
Validation R2 logD = 0.766219
Epoch 94
Train function
Loss = 1.6500e-03, PNorm = 37.4422, GNorm = 1.3981, lr_0 = 1.0804e-04
Loss = 1.4063e-03, PNorm = 37.4460, GNorm = 3.2342, lr_0 = 1.0804e-04
Loss = 1.5190e-03, PNorm = 37.4494, GNorm = 2.5255, lr_0 = 1.0804e-04
Loss = 1.7231e-03, PNorm = 37.4524, GNorm = 5.1923, lr_0 = 1.0804e-04
Loss = 1.4916e-03, PNorm = 37.4563, GNorm = 3.4216, lr_0 = 1.0804e-04
Loss = 1.9189e-03, PNorm = 37.4588, GNorm = 2.4281, lr_0 = 1.0804e-04
Validation rmse logD = 0.576975
Validation R2 logD = 0.774222
Epoch 95
Train function
Loss = 1.5260e-03, PNorm = 37.4621, GNorm = 1.7415, lr_0 = 1.0804e-04
Loss = 1.8608e-03, PNorm = 37.4645, GNorm = 6.5205, lr_0 = 1.0804e-04
Loss = 1.7116e-03, PNorm = 37.4672, GNorm = 4.7102, lr_0 = 1.0804e-04
Loss = 1.6329e-03, PNorm = 37.4704, GNorm = 2.9594, lr_0 = 1.0804e-04
Loss = 1.4933e-03, PNorm = 37.4735, GNorm = 1.8581, lr_0 = 1.0804e-04
Validation rmse logD = 0.575141
Validation R2 logD = 0.775656
Epoch 96
Train function
Loss = 1.0937e-03, PNorm = 37.4764, GNorm = 2.3650, lr_0 = 1.0804e-04
Loss = 1.5895e-03, PNorm = 37.4786, GNorm = 2.3077, lr_0 = 1.0804e-04
Loss = 1.6506e-03, PNorm = 37.4819, GNorm = 3.6448, lr_0 = 1.0804e-04
Loss = 1.4092e-03, PNorm = 37.4861, GNorm = 2.3187, lr_0 = 1.0804e-04
Loss = 1.4358e-03, PNorm = 37.4893, GNorm = 1.5317, lr_0 = 1.0804e-04
Loss = 1.6209e-03, PNorm = 37.4925, GNorm = 4.7531, lr_0 = 1.0804e-04
Validation rmse logD = 0.590211
Validation R2 logD = 0.763745
Epoch 97
Train function
Loss = 1.7777e-03, PNorm = 37.4955, GNorm = 3.5852, lr_0 = 1.0804e-04
Loss = 1.3959e-03, PNorm = 37.4984, GNorm = 3.0120, lr_0 = 1.0804e-04
Loss = 1.6769e-03, PNorm = 37.5014, GNorm = 4.5153, lr_0 = 1.0804e-04
Loss = 1.4121e-03, PNorm = 37.5047, GNorm = 4.3707, lr_0 = 1.0804e-04
Loss = 1.6952e-03, PNorm = 37.5085, GNorm = 2.0411, lr_0 = 1.0804e-04
Loss = 1.4184e-03, PNorm = 37.5122, GNorm = 1.5691, lr_0 = 1.0804e-04
Validation rmse logD = 0.574973
Validation R2 logD = 0.775786
Epoch 98
Train function
Loss = 1.2633e-03, PNorm = 37.5156, GNorm = 1.3208, lr_0 = 1.0804e-04
Loss = 1.7703e-03, PNorm = 37.5181, GNorm = 3.6948, lr_0 = 1.0804e-04
Loss = 1.6803e-03, PNorm = 37.5212, GNorm = 7.3754, lr_0 = 1.0804e-04
Loss = 1.4529e-03, PNorm = 37.5255, GNorm = 4.2573, lr_0 = 1.0804e-04
Loss = 1.6106e-03, PNorm = 37.5282, GNorm = 1.9032, lr_0 = 1.0804e-04
Validation rmse logD = 0.582040
Validation R2 logD = 0.770241
Epoch 99
Train function
Loss = 1.1157e-03, PNorm = 37.5304, GNorm = 3.0797, lr_0 = 1.0804e-04
Loss = 1.4178e-03, PNorm = 37.5341, GNorm = 1.5398, lr_0 = 1.0804e-04
Loss = 1.2442e-03, PNorm = 37.5369, GNorm = 4.3917, lr_0 = 1.0804e-04
Loss = 1.6125e-03, PNorm = 37.5392, GNorm = 3.6069, lr_0 = 1.0804e-04
Loss = 1.4762e-03, PNorm = 37.5426, GNorm = 2.3810, lr_0 = 1.0804e-04
Loss = 1.6826e-03, PNorm = 37.5459, GNorm = 1.9887, lr_0 = 1.0804e-04
Validation rmse logD = 0.587861
Validation R2 logD = 0.765622
Model 0 best validation rmse = 0.574844 on epoch 90
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.585928
Model 0 test R2 logD = 0.766258
Ensemble test rmse  logD= 0.585928
Ensemble test R2  logD= 0.766258
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_365/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.4649e-02, PNorm = 35.0057, GNorm = 6.4983, lr_0 = 1.0804e-04
Loss = 2.0490e-02, PNorm = 35.0050, GNorm = 4.8766, lr_0 = 1.0804e-04
Loss = 1.8655e-02, PNorm = 35.0058, GNorm = 2.3052, lr_0 = 1.0804e-04
Loss = 1.8374e-02, PNorm = 35.0072, GNorm = 4.3960, lr_0 = 1.0804e-04
Loss = 1.6722e-02, PNorm = 35.0093, GNorm = 2.9935, lr_0 = 1.0804e-04
Validation rmse logD = 1.138872
Validation R2 logD = 0.164777
Epoch 1
Train function
Loss = 1.2632e-02, PNorm = 35.0114, GNorm = 1.8801, lr_0 = 1.0804e-04
Loss = 1.4707e-02, PNorm = 35.0135, GNorm = 2.9745, lr_0 = 1.0804e-04
Loss = 1.5049e-02, PNorm = 35.0155, GNorm = 5.9015, lr_0 = 1.0804e-04
Loss = 1.5499e-02, PNorm = 35.0184, GNorm = 4.5044, lr_0 = 1.0804e-04
Loss = 1.5491e-02, PNorm = 35.0205, GNorm = 1.8743, lr_0 = 1.0804e-04
Loss = 1.4353e-02, PNorm = 35.0237, GNorm = 3.1386, lr_0 = 1.0804e-04
Validation rmse logD = 1.052243
Validation R2 logD = 0.287008
Epoch 2
Train function
Loss = 1.4979e-02, PNorm = 35.0267, GNorm = 2.7591, lr_0 = 1.0804e-04
Loss = 1.3894e-02, PNorm = 35.0302, GNorm = 1.5222, lr_0 = 1.0804e-04
Loss = 1.2447e-02, PNorm = 35.0340, GNorm = 1.9325, lr_0 = 1.0804e-04
Loss = 1.3348e-02, PNorm = 35.0377, GNorm = 1.7672, lr_0 = 1.0804e-04
Loss = 1.2535e-02, PNorm = 35.0415, GNorm = 2.2975, lr_0 = 1.0804e-04
Validation rmse logD = 0.993191
Validation R2 logD = 0.364789
Epoch 3
Train function
Loss = 1.3439e-02, PNorm = 35.0457, GNorm = 2.4194, lr_0 = 1.0804e-04
Loss = 1.1507e-02, PNorm = 35.0493, GNorm = 3.5151, lr_0 = 1.0804e-04
Loss = 1.1405e-02, PNorm = 35.0535, GNorm = 1.3338, lr_0 = 1.0804e-04
Loss = 1.3002e-02, PNorm = 35.0577, GNorm = 4.7015, lr_0 = 1.0804e-04
Loss = 1.4325e-02, PNorm = 35.0616, GNorm = 3.0294, lr_0 = 1.0804e-04
Loss = 1.1064e-02, PNorm = 35.0662, GNorm = 1.7309, lr_0 = 1.0804e-04
Validation rmse logD = 0.969656
Validation R2 logD = 0.394537
Epoch 4
Train function
Loss = 1.0786e-02, PNorm = 35.0698, GNorm = 4.8506, lr_0 = 1.0804e-04
Loss = 1.1445e-02, PNorm = 35.0734, GNorm = 1.5873, lr_0 = 1.0804e-04
Loss = 1.1951e-02, PNorm = 35.0772, GNorm = 4.0865, lr_0 = 1.0804e-04
Loss = 1.2206e-02, PNorm = 35.0811, GNorm = 4.6024, lr_0 = 1.0804e-04
Loss = 1.1872e-02, PNorm = 35.0850, GNorm = 4.4929, lr_0 = 1.0804e-04
Loss = 1.1332e-02, PNorm = 35.0890, GNorm = 1.7242, lr_0 = 1.0804e-04
Validation rmse logD = 0.937470
Validation R2 logD = 0.434064
Epoch 5
Train function
Loss = 1.0892e-02, PNorm = 35.0946, GNorm = 2.8694, lr_0 = 1.0804e-04
Loss = 1.0492e-02, PNorm = 35.0998, GNorm = 1.6795, lr_0 = 1.0804e-04
Loss = 1.1165e-02, PNorm = 35.1053, GNorm = 1.7419, lr_0 = 1.0804e-04
Loss = 9.6509e-03, PNorm = 35.1109, GNorm = 3.5369, lr_0 = 1.0804e-04
Loss = 1.0020e-02, PNorm = 35.1160, GNorm = 1.1830, lr_0 = 1.0804e-04
Validation rmse logD = 0.904504
Validation R2 logD = 0.473167
Epoch 6
Train function
Loss = 7.9684e-03, PNorm = 35.1212, GNorm = 2.6242, lr_0 = 1.0804e-04
Loss = 9.6543e-03, PNorm = 35.1270, GNorm = 2.7080, lr_0 = 1.0804e-04
Loss = 1.0294e-02, PNorm = 35.1334, GNorm = 2.3905, lr_0 = 1.0804e-04
Loss = 1.0117e-02, PNorm = 35.1399, GNorm = 5.0761, lr_0 = 1.0804e-04
Loss = 1.0108e-02, PNorm = 35.1447, GNorm = 2.5759, lr_0 = 1.0804e-04
Loss = 9.7709e-03, PNorm = 35.1497, GNorm = 1.7979, lr_0 = 1.0804e-04
Validation rmse logD = 0.881037
Validation R2 logD = 0.500149
Epoch 7
Train function
Loss = 1.0081e-02, PNorm = 35.1549, GNorm = 4.1708, lr_0 = 1.0804e-04
Loss = 9.5433e-03, PNorm = 35.1605, GNorm = 1.8356, lr_0 = 1.0804e-04
Loss = 8.8396e-03, PNorm = 35.1665, GNorm = 3.1621, lr_0 = 1.0804e-04
Loss = 9.6066e-03, PNorm = 35.1730, GNorm = 1.9252, lr_0 = 1.0804e-04
Loss = 9.5212e-03, PNorm = 35.1790, GNorm = 1.4637, lr_0 = 1.0804e-04
Loss = 9.4367e-03, PNorm = 35.1850, GNorm = 4.2492, lr_0 = 1.0804e-04
Validation rmse logD = 0.874758
Validation R2 logD = 0.507248
Epoch 8
Train function
Loss = 8.9923e-03, PNorm = 35.1903, GNorm = 9.0629, lr_0 = 1.0804e-04
Loss = 9.8204e-03, PNorm = 35.1962, GNorm = 7.3754, lr_0 = 1.0804e-04
Loss = 8.3853e-03, PNorm = 35.2022, GNorm = 3.2453, lr_0 = 1.0804e-04
Loss = 9.0644e-03, PNorm = 35.2079, GNorm = 3.8824, lr_0 = 1.0804e-04
Loss = 9.1104e-03, PNorm = 35.2138, GNorm = 6.6368, lr_0 = 1.0804e-04
Validation rmse logD = 0.873237
Validation R2 logD = 0.508960
Epoch 9
Train function
Loss = 8.4764e-03, PNorm = 35.2202, GNorm = 4.8142, lr_0 = 1.0804e-04
Loss = 9.5195e-03, PNorm = 35.2264, GNorm = 1.6353, lr_0 = 1.0804e-04
Loss = 9.0986e-03, PNorm = 35.2331, GNorm = 8.4341, lr_0 = 1.0804e-04
Loss = 8.5117e-03, PNorm = 35.2391, GNorm = 3.1676, lr_0 = 1.0804e-04
Loss = 8.0521e-03, PNorm = 35.2451, GNorm = 1.5759, lr_0 = 1.0804e-04
Loss = 8.5752e-03, PNorm = 35.2527, GNorm = 2.4397, lr_0 = 1.0804e-04
Validation rmse logD = 0.838749
Validation R2 logD = 0.546981
Epoch 10
Train function
Loss = 8.3948e-03, PNorm = 35.2594, GNorm = 2.7610, lr_0 = 1.0804e-04
Loss = 8.4832e-03, PNorm = 35.2661, GNorm = 2.3670, lr_0 = 1.0804e-04
Loss = 8.1034e-03, PNorm = 35.2736, GNorm = 2.9611, lr_0 = 1.0804e-04
Loss = 8.2738e-03, PNorm = 35.2798, GNorm = 6.2109, lr_0 = 1.0804e-04
Loss = 9.1070e-03, PNorm = 35.2869, GNorm = 6.1787, lr_0 = 1.0804e-04
Loss = 8.2140e-03, PNorm = 35.2932, GNorm = 2.6621, lr_0 = 1.0804e-04
Validation rmse logD = 0.819629
Validation R2 logD = 0.567400
Epoch 11
Train function
Loss = 8.4557e-03, PNorm = 35.2990, GNorm = 2.9947, lr_0 = 1.0804e-04
Loss = 7.9162e-03, PNorm = 35.3065, GNorm = 4.2774, lr_0 = 1.0804e-04
Loss = 8.0132e-03, PNorm = 35.3129, GNorm = 2.3858, lr_0 = 1.0804e-04
Loss = 8.1299e-03, PNorm = 35.3198, GNorm = 3.3409, lr_0 = 1.0804e-04
Loss = 8.0922e-03, PNorm = 35.3268, GNorm = 5.7236, lr_0 = 1.0804e-04
Validation rmse logD = 0.807530
Validation R2 logD = 0.580077
Epoch 12
Train function
Loss = 4.2270e-03, PNorm = 35.3340, GNorm = 1.3936, lr_0 = 1.0804e-04
Loss = 7.4831e-03, PNorm = 35.3402, GNorm = 5.4521, lr_0 = 1.0804e-04
Loss = 7.9759e-03, PNorm = 35.3465, GNorm = 2.4507, lr_0 = 1.0804e-04
Loss = 8.0218e-03, PNorm = 35.3528, GNorm = 1.9375, lr_0 = 1.0804e-04
Loss = 7.9504e-03, PNorm = 35.3598, GNorm = 2.1255, lr_0 = 1.0804e-04
Loss = 8.1152e-03, PNorm = 35.3682, GNorm = 2.1250, lr_0 = 1.0804e-04
Validation rmse logD = 0.808453
Validation R2 logD = 0.579117
Epoch 13
Train function
Loss = 7.6900e-03, PNorm = 35.3768, GNorm = 5.6771, lr_0 = 1.0804e-04
Loss = 7.1745e-03, PNorm = 35.3843, GNorm = 3.9215, lr_0 = 1.0804e-04
Loss = 6.8707e-03, PNorm = 35.3919, GNorm = 3.1273, lr_0 = 1.0804e-04
Loss = 8.0822e-03, PNorm = 35.3993, GNorm = 2.0402, lr_0 = 1.0804e-04
Loss = 6.3284e-03, PNorm = 35.4064, GNorm = 3.0969, lr_0 = 1.0804e-04
Loss = 7.7020e-03, PNorm = 35.4136, GNorm = 3.7278, lr_0 = 1.0804e-04
Validation rmse logD = 0.790222
Validation R2 logD = 0.597885
Epoch 14
Train function
Loss = 6.1640e-03, PNorm = 35.4211, GNorm = 1.3957, lr_0 = 1.0804e-04
Loss = 6.6833e-03, PNorm = 35.4281, GNorm = 3.0926, lr_0 = 1.0804e-04
Loss = 7.3982e-03, PNorm = 35.4354, GNorm = 4.4124, lr_0 = 1.0804e-04
Loss = 7.1142e-03, PNorm = 35.4438, GNorm = 9.2107, lr_0 = 1.0804e-04
Loss = 6.4629e-03, PNorm = 35.4512, GNorm = 6.3254, lr_0 = 1.0804e-04
Validation rmse logD = 0.791944
Validation R2 logD = 0.596130
Epoch 15
Train function
Loss = 7.1305e-03, PNorm = 35.4586, GNorm = 4.4774, lr_0 = 1.0804e-04
Loss = 7.2071e-03, PNorm = 35.4656, GNorm = 2.8469, lr_0 = 1.0804e-04
Loss = 8.2263e-03, PNorm = 35.4717, GNorm = 5.7990, lr_0 = 1.0804e-04
Loss = 7.1328e-03, PNorm = 35.4784, GNorm = 5.0792, lr_0 = 1.0804e-04
Loss = 6.6501e-03, PNorm = 35.4854, GNorm = 2.5603, lr_0 = 1.0804e-04
Loss = 6.5920e-03, PNorm = 35.4934, GNorm = 2.0772, lr_0 = 1.0804e-04
Validation rmse logD = 0.771380
Validation R2 logD = 0.616832
Epoch 16
Train function
Loss = 5.4400e-03, PNorm = 35.5015, GNorm = 6.8324, lr_0 = 1.0804e-04
Loss = 7.0432e-03, PNorm = 35.5103, GNorm = 4.9610, lr_0 = 1.0804e-04
Loss = 6.2965e-03, PNorm = 35.5183, GNorm = 6.0690, lr_0 = 1.0804e-04
Loss = 6.4186e-03, PNorm = 35.5253, GNorm = 5.9487, lr_0 = 1.0804e-04
Loss = 6.4721e-03, PNorm = 35.5317, GNorm = 4.7878, lr_0 = 1.0804e-04
Loss = 7.1645e-03, PNorm = 35.5384, GNorm = 3.8302, lr_0 = 1.0804e-04
Validation rmse logD = 0.758110
Validation R2 logD = 0.629902
Epoch 17
Train function
Loss = 5.6157e-03, PNorm = 35.5457, GNorm = 3.3329, lr_0 = 1.0804e-04
Loss = 6.8150e-03, PNorm = 35.5520, GNorm = 1.4564, lr_0 = 1.0804e-04
Loss = 6.0810e-03, PNorm = 35.5609, GNorm = 3.2736, lr_0 = 1.0804e-04
Loss = 7.0497e-03, PNorm = 35.5680, GNorm = 3.2377, lr_0 = 1.0804e-04
Loss = 6.1123e-03, PNorm = 35.5749, GNorm = 9.3425, lr_0 = 1.0804e-04
Validation rmse logD = 0.753580
Validation R2 logD = 0.634312
Epoch 18
Train function
Loss = 5.0118e-03, PNorm = 35.5833, GNorm = 2.4910, lr_0 = 1.0804e-04
Loss = 5.8309e-03, PNorm = 35.5920, GNorm = 3.1966, lr_0 = 1.0804e-04
Loss = 5.2942e-03, PNorm = 35.5977, GNorm = 2.1861, lr_0 = 1.0804e-04
Loss = 6.4290e-03, PNorm = 35.6039, GNorm = 6.5108, lr_0 = 1.0804e-04
Loss = 6.8342e-03, PNorm = 35.6118, GNorm = 8.6292, lr_0 = 1.0804e-04
Loss = 6.0985e-03, PNorm = 35.6197, GNorm = 3.8443, lr_0 = 1.0804e-04
Validation rmse logD = 0.742656
Validation R2 logD = 0.644837
Epoch 19
Train function
Loss = 5.6050e-03, PNorm = 35.6273, GNorm = 3.5249, lr_0 = 1.0804e-04
Loss = 5.8006e-03, PNorm = 35.6343, GNorm = 5.3812, lr_0 = 1.0804e-04
Loss = 6.2434e-03, PNorm = 35.6403, GNorm = 2.1593, lr_0 = 1.0804e-04
Loss = 6.2691e-03, PNorm = 35.6482, GNorm = 1.5537, lr_0 = 1.0804e-04
Loss = 5.8459e-03, PNorm = 35.6570, GNorm = 4.7130, lr_0 = 1.0804e-04
Loss = 5.9338e-03, PNorm = 35.6632, GNorm = 1.6509, lr_0 = 1.0804e-04
Validation rmse logD = 0.729881
Validation R2 logD = 0.656951
Epoch 20
Train function
Loss = 5.6305e-03, PNorm = 35.6690, GNorm = 2.1810, lr_0 = 1.0804e-04
Loss = 5.8508e-03, PNorm = 35.6758, GNorm = 3.0293, lr_0 = 1.0804e-04
Loss = 5.0982e-03, PNorm = 35.6831, GNorm = 1.2023, lr_0 = 1.0804e-04
Loss = 5.4639e-03, PNorm = 35.6909, GNorm = 1.5126, lr_0 = 1.0804e-04
Loss = 5.8434e-03, PNorm = 35.6981, GNorm = 2.4515, lr_0 = 1.0804e-04
Validation rmse logD = 0.733227
Validation R2 logD = 0.653798
Epoch 21
Train function
Loss = 4.7599e-03, PNorm = 35.7065, GNorm = 3.6768, lr_0 = 1.0804e-04
Loss = 4.9696e-03, PNorm = 35.7140, GNorm = 5.3484, lr_0 = 1.0804e-04
Loss = 5.3704e-03, PNorm = 35.7214, GNorm = 6.6290, lr_0 = 1.0804e-04
Loss = 5.7990e-03, PNorm = 35.7285, GNorm = 3.8670, lr_0 = 1.0804e-04
Loss = 6.1090e-03, PNorm = 35.7344, GNorm = 9.9574, lr_0 = 1.0804e-04
Loss = 5.7386e-03, PNorm = 35.7399, GNorm = 1.4969, lr_0 = 1.0804e-04
Validation rmse logD = 0.713273
Validation R2 logD = 0.672385
Epoch 22
Train function
Loss = 5.3228e-03, PNorm = 35.7485, GNorm = 5.9549, lr_0 = 1.0804e-04
Loss = 5.5243e-03, PNorm = 35.7561, GNorm = 6.1860, lr_0 = 1.0804e-04
Loss = 5.1547e-03, PNorm = 35.7625, GNorm = 3.8140, lr_0 = 1.0804e-04
Loss = 4.8524e-03, PNorm = 35.7701, GNorm = 1.9680, lr_0 = 1.0804e-04
Loss = 5.6783e-03, PNorm = 35.7767, GNorm = 6.7105, lr_0 = 1.0804e-04
Loss = 6.1208e-03, PNorm = 35.7825, GNorm = 3.6538, lr_0 = 1.0804e-04
Validation rmse logD = 0.730753
Validation R2 logD = 0.656131
Epoch 23
Train function
Loss = 5.6083e-03, PNorm = 35.7892, GNorm = 3.9038, lr_0 = 1.0804e-04
Loss = 4.9691e-03, PNorm = 35.7963, GNorm = 6.3456, lr_0 = 1.0804e-04
Loss = 5.9963e-03, PNorm = 35.8024, GNorm = 3.1209, lr_0 = 1.0804e-04
Loss = 5.3825e-03, PNorm = 35.8103, GNorm = 5.2393, lr_0 = 1.0804e-04
Loss = 5.3050e-03, PNorm = 35.8164, GNorm = 2.8799, lr_0 = 1.0804e-04
Validation rmse logD = 0.708169
Validation R2 logD = 0.677057
Epoch 24
Train function
Loss = 4.6366e-03, PNorm = 35.8234, GNorm = 6.1591, lr_0 = 1.0804e-04
Loss = 5.7946e-03, PNorm = 35.8304, GNorm = 4.6301, lr_0 = 1.0804e-04
Loss = 4.8585e-03, PNorm = 35.8372, GNorm = 1.8247, lr_0 = 1.0804e-04
Loss = 5.2600e-03, PNorm = 35.8431, GNorm = 7.2275, lr_0 = 1.0804e-04
Loss = 4.9045e-03, PNorm = 35.8497, GNorm = 5.7304, lr_0 = 1.0804e-04
Loss = 4.8899e-03, PNorm = 35.8559, GNorm = 6.1042, lr_0 = 1.0804e-04
Validation rmse logD = 0.719642
Validation R2 logD = 0.666508
Epoch 25
Train function
Loss = 3.9458e-03, PNorm = 35.8625, GNorm = 5.9485, lr_0 = 1.0804e-04
Loss = 5.2781e-03, PNorm = 35.8691, GNorm = 6.1410, lr_0 = 1.0804e-04
Loss = 5.2531e-03, PNorm = 35.8754, GNorm = 2.3625, lr_0 = 1.0804e-04
Loss = 5.1895e-03, PNorm = 35.8823, GNorm = 4.2071, lr_0 = 1.0804e-04
Loss = 4.6539e-03, PNorm = 35.8890, GNorm = 2.1909, lr_0 = 1.0804e-04
Loss = 4.9435e-03, PNorm = 35.8945, GNorm = 8.9066, lr_0 = 1.0804e-04
Validation rmse logD = 0.744402
Validation R2 logD = 0.643165
Epoch 26
Train function
Loss = 5.0002e-03, PNorm = 35.9005, GNorm = 3.7088, lr_0 = 1.0804e-04
Loss = 4.5145e-03, PNorm = 35.9047, GNorm = 3.0189, lr_0 = 1.0804e-04
Loss = 5.4119e-03, PNorm = 35.9099, GNorm = 9.2471, lr_0 = 1.0804e-04
Loss = 4.9054e-03, PNorm = 35.9160, GNorm = 3.6306, lr_0 = 1.0804e-04
Loss = 6.6034e-03, PNorm = 35.9230, GNorm = 10.7829, lr_0 = 1.0804e-04
Validation rmse logD = 0.700897
Validation R2 logD = 0.683655
Epoch 27
Train function
Loss = 3.8743e-03, PNorm = 35.9303, GNorm = 3.2040, lr_0 = 1.0804e-04
Loss = 4.7906e-03, PNorm = 35.9369, GNorm = 7.0585, lr_0 = 1.0804e-04
Loss = 4.2112e-03, PNorm = 35.9443, GNorm = 1.5106, lr_0 = 1.0804e-04
Loss = 4.9947e-03, PNorm = 35.9499, GNorm = 3.4836, lr_0 = 1.0804e-04
Loss = 5.8883e-03, PNorm = 35.9556, GNorm = 1.4823, lr_0 = 1.0804e-04
Loss = 4.3725e-03, PNorm = 35.9608, GNorm = 1.9332, lr_0 = 1.0804e-04
Validation rmse logD = 0.691860
Validation R2 logD = 0.691760
Epoch 28
Train function
Loss = 5.6519e-03, PNorm = 35.9667, GNorm = 7.5895, lr_0 = 1.0804e-04
Loss = 4.7057e-03, PNorm = 35.9747, GNorm = 2.1649, lr_0 = 1.0804e-04
Loss = 4.1403e-03, PNorm = 35.9810, GNorm = 2.4913, lr_0 = 1.0804e-04
Loss = 4.3622e-03, PNorm = 35.9865, GNorm = 2.6702, lr_0 = 1.0804e-04
Loss = 4.6093e-03, PNorm = 35.9917, GNorm = 2.2933, lr_0 = 1.0804e-04
Loss = 4.5676e-03, PNorm = 35.9962, GNorm = 2.9510, lr_0 = 1.0804e-04
Validation rmse logD = 0.684013
Validation R2 logD = 0.698712
Epoch 29
Train function
Loss = 4.4488e-03, PNorm = 36.0018, GNorm = 4.0145, lr_0 = 1.0804e-04
Loss = 3.6491e-03, PNorm = 36.0069, GNorm = 2.5274, lr_0 = 1.0804e-04
Loss = 4.6111e-03, PNorm = 36.0128, GNorm = 6.0680, lr_0 = 1.0804e-04
Loss = 4.7411e-03, PNorm = 36.0192, GNorm = 3.5202, lr_0 = 1.0804e-04
Loss = 4.4246e-03, PNorm = 36.0242, GNorm = 1.7878, lr_0 = 1.0804e-04
Validation rmse logD = 0.719240
Validation R2 logD = 0.666881
Epoch 30
Train function
Loss = 3.3322e-03, PNorm = 36.0294, GNorm = 5.2839, lr_0 = 1.0804e-04
Loss = 4.8364e-03, PNorm = 36.0335, GNorm = 4.2853, lr_0 = 1.0804e-04
Loss = 5.3535e-03, PNorm = 36.0402, GNorm = 6.3215, lr_0 = 1.0804e-04
Loss = 4.6195e-03, PNorm = 36.0460, GNorm = 6.1398, lr_0 = 1.0804e-04
Loss = 4.3933e-03, PNorm = 36.0526, GNorm = 3.3653, lr_0 = 1.0804e-04
Loss = 4.5681e-03, PNorm = 36.0574, GNorm = 3.9316, lr_0 = 1.0804e-04
Validation rmse logD = 0.683797
Validation R2 logD = 0.698902
Epoch 31
Train function
Loss = 4.6182e-03, PNorm = 36.0618, GNorm = 1.6660, lr_0 = 1.0804e-04
Loss = 3.6909e-03, PNorm = 36.0663, GNorm = 3.9730, lr_0 = 1.0804e-04
Loss = 4.3101e-03, PNorm = 36.0719, GNorm = 1.8926, lr_0 = 1.0804e-04
Loss = 5.1108e-03, PNorm = 36.0777, GNorm = 6.6109, lr_0 = 1.0804e-04
Loss = 4.2461e-03, PNorm = 36.0837, GNorm = 1.5179, lr_0 = 1.0804e-04
Loss = 3.7720e-03, PNorm = 36.0898, GNorm = 3.5154, lr_0 = 1.0804e-04
Validation rmse logD = 0.685197
Validation R2 logD = 0.697669
Epoch 32
Train function
Loss = 3.7456e-03, PNorm = 36.0954, GNorm = 3.7696, lr_0 = 1.0804e-04
Loss = 3.8142e-03, PNorm = 36.1005, GNorm = 3.2035, lr_0 = 1.0804e-04
Loss = 4.5035e-03, PNorm = 36.1057, GNorm = 1.2955, lr_0 = 1.0804e-04
Loss = 4.4136e-03, PNorm = 36.1119, GNorm = 5.0369, lr_0 = 1.0804e-04
Loss = 4.0218e-03, PNorm = 36.1169, GNorm = 2.3052, lr_0 = 1.0804e-04
Validation rmse logD = 0.694936
Validation R2 logD = 0.689013
Epoch 33
Train function
Loss = 4.4471e-03, PNorm = 36.1229, GNorm = 6.3548, lr_0 = 1.0804e-04
Loss = 4.8238e-03, PNorm = 36.1296, GNorm = 4.2604, lr_0 = 1.0804e-04
Loss = 3.6977e-03, PNorm = 36.1358, GNorm = 1.9363, lr_0 = 1.0804e-04
Loss = 3.7825e-03, PNorm = 36.1411, GNorm = 4.8268, lr_0 = 1.0804e-04
Loss = 4.0943e-03, PNorm = 36.1466, GNorm = 5.7678, lr_0 = 1.0804e-04
Loss = 4.5995e-03, PNorm = 36.1511, GNorm = 4.1192, lr_0 = 1.0804e-04
Validation rmse logD = 0.677281
Validation R2 logD = 0.704614
Epoch 34
Train function
Loss = 4.4172e-03, PNorm = 36.1550, GNorm = 2.1388, lr_0 = 1.0804e-04
Loss = 3.8845e-03, PNorm = 36.1602, GNorm = 2.4285, lr_0 = 1.0804e-04
Loss = 4.3180e-03, PNorm = 36.1658, GNorm = 7.7878, lr_0 = 1.0804e-04
Loss = 4.1424e-03, PNorm = 36.1714, GNorm = 1.9592, lr_0 = 1.0804e-04
Loss = 3.9073e-03, PNorm = 36.1767, GNorm = 2.3446, lr_0 = 1.0804e-04
Loss = 3.9311e-03, PNorm = 36.1814, GNorm = 7.6780, lr_0 = 1.0804e-04
Validation rmse logD = 0.674922
Validation R2 logD = 0.706668
Epoch 35
Train function
Loss = 3.8430e-03, PNorm = 36.1877, GNorm = 4.3686, lr_0 = 1.0804e-04
Loss = 4.0233e-03, PNorm = 36.1936, GNorm = 7.9361, lr_0 = 1.0804e-04
Loss = 3.8205e-03, PNorm = 36.2001, GNorm = 3.4821, lr_0 = 1.0804e-04
Loss = 4.3291e-03, PNorm = 36.2051, GNorm = 5.2545, lr_0 = 1.0804e-04
Loss = 4.0311e-03, PNorm = 36.2104, GNorm = 8.2637, lr_0 = 1.0804e-04
Validation rmse logD = 0.677042
Validation R2 logD = 0.704823
Epoch 36
Train function
Loss = 3.4554e-03, PNorm = 36.2140, GNorm = 4.8400, lr_0 = 1.0804e-04
Loss = 4.2113e-03, PNorm = 36.2179, GNorm = 3.6673, lr_0 = 1.0804e-04
Loss = 3.5593e-03, PNorm = 36.2220, GNorm = 4.0542, lr_0 = 1.0804e-04
Loss = 3.7883e-03, PNorm = 36.2268, GNorm = 2.5728, lr_0 = 1.0804e-04
Loss = 3.8505e-03, PNorm = 36.2324, GNorm = 5.8006, lr_0 = 1.0804e-04
Loss = 4.2506e-03, PNorm = 36.2379, GNorm = 2.5814, lr_0 = 1.0804e-04
Validation rmse logD = 0.664264
Validation R2 logD = 0.715859
Epoch 37
Train function
Loss = 3.1645e-03, PNorm = 36.2427, GNorm = 4.3102, lr_0 = 1.0804e-04
Loss = 3.4958e-03, PNorm = 36.2481, GNorm = 5.3514, lr_0 = 1.0804e-04
Loss = 4.4369e-03, PNorm = 36.2529, GNorm = 4.0543, lr_0 = 1.0804e-04
Loss = 3.8443e-03, PNorm = 36.2573, GNorm = 2.3593, lr_0 = 1.0804e-04
Loss = 3.7856e-03, PNorm = 36.2622, GNorm = 3.5389, lr_0 = 1.0804e-04
Loss = 3.8521e-03, PNorm = 36.2663, GNorm = 2.9254, lr_0 = 1.0804e-04
Validation rmse logD = 0.666604
Validation R2 logD = 0.713854
Epoch 38
Train function
Loss = 3.7534e-03, PNorm = 36.2721, GNorm = 1.2379, lr_0 = 1.0804e-04
Loss = 3.6968e-03, PNorm = 36.2785, GNorm = 7.4559, lr_0 = 1.0804e-04
Loss = 4.4551e-03, PNorm = 36.2834, GNorm = 7.2111, lr_0 = 1.0804e-04
Loss = 3.5106e-03, PNorm = 36.2884, GNorm = 2.6386, lr_0 = 1.0804e-04
Loss = 3.5108e-03, PNorm = 36.2937, GNorm = 2.3319, lr_0 = 1.0804e-04
Validation rmse logD = 0.656170
Validation R2 logD = 0.722741
Epoch 39
Train function
Loss = 3.3784e-03, PNorm = 36.2981, GNorm = 3.9050, lr_0 = 1.0804e-04
Loss = 3.2808e-03, PNorm = 36.3029, GNorm = 3.5719, lr_0 = 1.0804e-04
Loss = 3.7781e-03, PNorm = 36.3079, GNorm = 5.1233, lr_0 = 1.0804e-04
Loss = 3.7154e-03, PNorm = 36.3127, GNorm = 4.8781, lr_0 = 1.0804e-04
Loss = 4.2176e-03, PNorm = 36.3162, GNorm = 7.6521, lr_0 = 1.0804e-04
Loss = 3.6357e-03, PNorm = 36.3196, GNorm = 3.4126, lr_0 = 1.0804e-04
Validation rmse logD = 0.675616
Validation R2 logD = 0.706064
Epoch 40
Train function
Loss = 4.3116e-03, PNorm = 36.3241, GNorm = 8.1742, lr_0 = 1.0804e-04
Loss = 3.9942e-03, PNorm = 36.3285, GNorm = 5.3787, lr_0 = 1.0804e-04
Loss = 4.1534e-03, PNorm = 36.3324, GNorm = 6.5752, lr_0 = 1.0804e-04
Loss = 3.9867e-03, PNorm = 36.3364, GNorm = 8.5625, lr_0 = 1.0804e-04
Loss = 3.8301e-03, PNorm = 36.3420, GNorm = 6.2360, lr_0 = 1.0804e-04
Loss = 3.5420e-03, PNorm = 36.3468, GNorm = 3.5325, lr_0 = 1.0804e-04
Validation rmse logD = 0.672933
Validation R2 logD = 0.708394
Epoch 41
Train function
Loss = 3.6993e-03, PNorm = 36.3516, GNorm = 5.9596, lr_0 = 1.0804e-04
Loss = 3.5306e-03, PNorm = 36.3579, GNorm = 1.5658, lr_0 = 1.0804e-04
Loss = 3.4684e-03, PNorm = 36.3634, GNorm = 2.9002, lr_0 = 1.0804e-04
Loss = 3.4146e-03, PNorm = 36.3669, GNorm = 3.0416, lr_0 = 1.0804e-04
Loss = 3.9737e-03, PNorm = 36.3701, GNorm = 5.0272, lr_0 = 1.0804e-04
Validation rmse logD = 0.679892
Validation R2 logD = 0.702332
Epoch 42
Train function
Loss = 5.3798e-03, PNorm = 36.3752, GNorm = 6.2971, lr_0 = 1.0804e-04
Loss = 3.6175e-03, PNorm = 36.3801, GNorm = 4.2403, lr_0 = 1.0804e-04
Loss = 3.7627e-03, PNorm = 36.3847, GNorm = 2.3009, lr_0 = 1.0804e-04
Loss = 3.0903e-03, PNorm = 36.3896, GNorm = 5.3787, lr_0 = 1.0804e-04
Loss = 3.6268e-03, PNorm = 36.3937, GNorm = 1.8595, lr_0 = 1.0804e-04
Loss = 3.6188e-03, PNorm = 36.3977, GNorm = 3.4679, lr_0 = 1.0804e-04
Validation rmse logD = 0.655572
Validation R2 logD = 0.723246
Epoch 43
Train function
Loss = 3.2628e-03, PNorm = 36.4029, GNorm = 4.4374, lr_0 = 1.0804e-04
Loss = 2.9721e-03, PNorm = 36.4063, GNorm = 4.3770, lr_0 = 1.0804e-04
Loss = 2.9617e-03, PNorm = 36.4106, GNorm = 3.4588, lr_0 = 1.0804e-04
Loss = 3.4855e-03, PNorm = 36.4156, GNorm = 3.5318, lr_0 = 1.0804e-04
Loss = 3.4889e-03, PNorm = 36.4201, GNorm = 1.4600, lr_0 = 1.0804e-04
Loss = 3.6792e-03, PNorm = 36.4264, GNorm = 1.7189, lr_0 = 1.0804e-04
Validation rmse logD = 0.659512
Validation R2 logD = 0.719909
Epoch 44
Train function
Loss = 2.9003e-03, PNorm = 36.4308, GNorm = 2.1821, lr_0 = 1.0804e-04
Loss = 3.1915e-03, PNorm = 36.4357, GNorm = 1.9543, lr_0 = 1.0804e-04
Loss = 3.4428e-03, PNorm = 36.4404, GNorm = 9.5060, lr_0 = 1.0804e-04
Loss = 3.4135e-03, PNorm = 36.4439, GNorm = 10.1926, lr_0 = 1.0804e-04
Loss = 3.9330e-03, PNorm = 36.4478, GNorm = 8.4386, lr_0 = 1.0804e-04
Validation rmse logD = 0.670072
Validation R2 logD = 0.710868
Epoch 45
Train function
Loss = 3.1227e-03, PNorm = 36.4505, GNorm = 4.8689, lr_0 = 1.0804e-04
Loss = 3.2829e-03, PNorm = 36.4546, GNorm = 2.3047, lr_0 = 1.0804e-04
Loss = 3.3095e-03, PNorm = 36.4596, GNorm = 6.0354, lr_0 = 1.0804e-04
Loss = 3.7871e-03, PNorm = 36.4642, GNorm = 1.9675, lr_0 = 1.0804e-04
Loss = 3.1542e-03, PNorm = 36.4685, GNorm = 1.9368, lr_0 = 1.0804e-04
Loss = 3.5115e-03, PNorm = 36.4736, GNorm = 4.4807, lr_0 = 1.0804e-04
Validation rmse logD = 0.650787
Validation R2 logD = 0.727271
Epoch 46
Train function
Loss = 2.9019e-03, PNorm = 36.4789, GNorm = 1.7932, lr_0 = 1.0804e-04
Loss = 3.3900e-03, PNorm = 36.4845, GNorm = 3.9110, lr_0 = 1.0804e-04
Loss = 2.9863e-03, PNorm = 36.4890, GNorm = 1.9738, lr_0 = 1.0804e-04
Loss = 2.4865e-03, PNorm = 36.4923, GNorm = 6.0759, lr_0 = 1.0804e-04
Loss = 3.6974e-03, PNorm = 36.4957, GNorm = 3.7374, lr_0 = 1.0804e-04
Loss = 3.8226e-03, PNorm = 36.4995, GNorm = 2.9381, lr_0 = 1.0804e-04
Validation rmse logD = 0.660319
Validation R2 logD = 0.719224
Epoch 47
Train function
Loss = 3.6848e-03, PNorm = 36.5043, GNorm = 2.5399, lr_0 = 1.0804e-04
Loss = 2.8231e-03, PNorm = 36.5086, GNorm = 6.6332, lr_0 = 1.0804e-04
Loss = 3.7808e-03, PNorm = 36.5133, GNorm = 6.1778, lr_0 = 1.0804e-04
Loss = 2.9283e-03, PNorm = 36.5172, GNorm = 6.7073, lr_0 = 1.0804e-04
Loss = 2.9049e-03, PNorm = 36.5218, GNorm = 4.3918, lr_0 = 1.0804e-04
Validation rmse logD = 0.661117
Validation R2 logD = 0.718545
Epoch 48
Train function
Loss = 3.5754e-03, PNorm = 36.5263, GNorm = 5.8761, lr_0 = 1.0804e-04
Loss = 2.5905e-03, PNorm = 36.5308, GNorm = 4.3621, lr_0 = 1.0804e-04
Loss = 3.1583e-03, PNorm = 36.5360, GNorm = 4.0845, lr_0 = 1.0804e-04
Loss = 3.0163e-03, PNorm = 36.5395, GNorm = 1.4164, lr_0 = 1.0804e-04
Loss = 3.4104e-03, PNorm = 36.5428, GNorm = 6.3150, lr_0 = 1.0804e-04
Loss = 3.4939e-03, PNorm = 36.5466, GNorm = 1.8487, lr_0 = 1.0804e-04
Validation rmse logD = 0.656948
Validation R2 logD = 0.722084
Epoch 49
Train function
Loss = 3.0231e-03, PNorm = 36.5513, GNorm = 7.0143, lr_0 = 1.0804e-04
Loss = 3.2882e-03, PNorm = 36.5560, GNorm = 1.7086, lr_0 = 1.0804e-04
Loss = 2.5824e-03, PNorm = 36.5609, GNorm = 2.6908, lr_0 = 1.0804e-04
Loss = 3.0812e-03, PNorm = 36.5646, GNorm = 2.1579, lr_0 = 1.0804e-04
Loss = 3.4062e-03, PNorm = 36.5679, GNorm = 4.8595, lr_0 = 1.0804e-04
Loss = 3.3525e-03, PNorm = 36.5724, GNorm = 3.2946, lr_0 = 1.0804e-04
Validation rmse logD = 0.649827
Validation R2 logD = 0.728076
Epoch 50
Train function
Loss = 2.8416e-03, PNorm = 36.5772, GNorm = 4.9303, lr_0 = 1.0804e-04
Loss = 2.7490e-03, PNorm = 36.5812, GNorm = 1.0238, lr_0 = 1.0804e-04
Loss = 3.1937e-03, PNorm = 36.5846, GNorm = 3.1538, lr_0 = 1.0804e-04
Loss = 3.0182e-03, PNorm = 36.5893, GNorm = 1.9459, lr_0 = 1.0804e-04
Loss = 3.0812e-03, PNorm = 36.5940, GNorm = 3.8068, lr_0 = 1.0804e-04
Validation rmse logD = 0.645782
Validation R2 logD = 0.731450
Epoch 51
Train function
Loss = 3.2121e-03, PNorm = 36.5990, GNorm = 3.5999, lr_0 = 1.0804e-04
Loss = 3.3035e-03, PNorm = 36.6023, GNorm = 1.1977, lr_0 = 1.0804e-04
Loss = 2.3714e-03, PNorm = 36.6059, GNorm = 1.8134, lr_0 = 1.0804e-04
Loss = 3.5916e-03, PNorm = 36.6108, GNorm = 3.1195, lr_0 = 1.0804e-04
Loss = 2.8560e-03, PNorm = 36.6163, GNorm = 3.7940, lr_0 = 1.0804e-04
Loss = 2.8050e-03, PNorm = 36.6201, GNorm = 1.5814, lr_0 = 1.0804e-04
Validation rmse logD = 0.645332
Validation R2 logD = 0.731825
Epoch 52
Train function
Loss = 2.4454e-03, PNorm = 36.6236, GNorm = 3.2334, lr_0 = 1.0804e-04
Loss = 2.7859e-03, PNorm = 36.6275, GNorm = 5.4286, lr_0 = 1.0804e-04
Loss = 3.0021e-03, PNorm = 36.6319, GNorm = 12.6725, lr_0 = 1.0804e-04
Loss = 2.8190e-03, PNorm = 36.6363, GNorm = 1.7459, lr_0 = 1.0804e-04
Loss = 2.7267e-03, PNorm = 36.6406, GNorm = 2.1179, lr_0 = 1.0804e-04
Loss = 3.4370e-03, PNorm = 36.6442, GNorm = 2.3293, lr_0 = 1.0804e-04
Validation rmse logD = 0.646949
Validation R2 logD = 0.730479
Epoch 53
Train function
Loss = 2.6906e-03, PNorm = 36.6488, GNorm = 2.8361, lr_0 = 1.0804e-04
Loss = 2.9094e-03, PNorm = 36.6531, GNorm = 7.5723, lr_0 = 1.0804e-04
Loss = 2.7896e-03, PNorm = 36.6562, GNorm = 3.7483, lr_0 = 1.0804e-04
Loss = 2.4209e-03, PNorm = 36.6601, GNorm = 3.9888, lr_0 = 1.0804e-04
Loss = 3.3318e-03, PNorm = 36.6651, GNorm = 10.1162, lr_0 = 1.0804e-04
Validation rmse logD = 0.643688
Validation R2 logD = 0.733190
Epoch 54
Train function
Loss = 2.8587e-03, PNorm = 36.6693, GNorm = 3.3353, lr_0 = 1.0804e-04
Loss = 3.0592e-03, PNorm = 36.6738, GNorm = 2.6386, lr_0 = 1.0804e-04
Loss = 2.6780e-03, PNorm = 36.6787, GNorm = 1.8906, lr_0 = 1.0804e-04
Loss = 2.6816e-03, PNorm = 36.6828, GNorm = 2.8735, lr_0 = 1.0804e-04
Loss = 2.9873e-03, PNorm = 36.6867, GNorm = 3.1249, lr_0 = 1.0804e-04
Loss = 2.5807e-03, PNorm = 36.6902, GNorm = 8.9339, lr_0 = 1.0804e-04
Validation rmse logD = 0.645665
Validation R2 logD = 0.731548
Epoch 55
Train function
Loss = 2.8542e-03, PNorm = 36.6938, GNorm = 1.5653, lr_0 = 1.0804e-04
Loss = 3.4783e-03, PNorm = 36.6982, GNorm = 5.9187, lr_0 = 1.0804e-04
Loss = 2.9760e-03, PNorm = 36.7032, GNorm = 4.5082, lr_0 = 1.0804e-04
Loss = 3.1280e-03, PNorm = 36.7075, GNorm = 2.5918, lr_0 = 1.0804e-04
Loss = 2.8531e-03, PNorm = 36.7115, GNorm = 2.0684, lr_0 = 1.0804e-04
Loss = 2.1994e-03, PNorm = 36.7152, GNorm = 3.0508, lr_0 = 1.0804e-04
Validation rmse logD = 0.634821
Validation R2 logD = 0.740489
Epoch 56
Train function
Loss = 2.4289e-03, PNorm = 36.7206, GNorm = 2.6403, lr_0 = 1.0804e-04
Loss = 2.2042e-03, PNorm = 36.7241, GNorm = 2.0062, lr_0 = 1.0804e-04
Loss = 3.1187e-03, PNorm = 36.7284, GNorm = 2.6965, lr_0 = 1.0804e-04
Loss = 2.8215e-03, PNorm = 36.7330, GNorm = 2.6781, lr_0 = 1.0804e-04
Loss = 2.9581e-03, PNorm = 36.7364, GNorm = 9.7819, lr_0 = 1.0804e-04
Validation rmse logD = 0.658802
Validation R2 logD = 0.720512
Epoch 57
Train function
Loss = 2.5708e-03, PNorm = 36.7404, GNorm = 2.8815, lr_0 = 1.0804e-04
Loss = 3.1469e-03, PNorm = 36.7434, GNorm = 7.1356, lr_0 = 1.0804e-04
Loss = 3.4098e-03, PNorm = 36.7468, GNorm = 6.2755, lr_0 = 1.0804e-04
Loss = 2.0420e-03, PNorm = 36.7509, GNorm = 1.7526, lr_0 = 1.0804e-04
Loss = 3.5239e-03, PNorm = 36.7561, GNorm = 9.8191, lr_0 = 1.0804e-04
Loss = 2.8428e-03, PNorm = 36.7597, GNorm = 3.1809, lr_0 = 1.0804e-04
Validation rmse logD = 0.650517
Validation R2 logD = 0.727498
Epoch 58
Train function
Loss = 2.5893e-03, PNorm = 36.7636, GNorm = 8.1148, lr_0 = 1.0804e-04
Loss = 2.5888e-03, PNorm = 36.7676, GNorm = 2.2950, lr_0 = 1.0804e-04
Loss = 3.0689e-03, PNorm = 36.7709, GNorm = 6.6096, lr_0 = 1.0804e-04
Loss = 3.4328e-03, PNorm = 36.7752, GNorm = 5.0072, lr_0 = 1.0804e-04
Loss = 2.9782e-03, PNorm = 36.7797, GNorm = 5.8223, lr_0 = 1.0804e-04
Loss = 2.7695e-03, PNorm = 36.7841, GNorm = 2.7617, lr_0 = 1.0804e-04
Validation rmse logD = 0.636755
Validation R2 logD = 0.738906
Epoch 59
Train function
Loss = 2.2795e-03, PNorm = 36.7885, GNorm = 2.2467, lr_0 = 1.0804e-04
Loss = 2.7119e-03, PNorm = 36.7930, GNorm = 1.9059, lr_0 = 1.0804e-04
Loss = 2.4080e-03, PNorm = 36.7964, GNorm = 1.6895, lr_0 = 1.0804e-04
Loss = 3.1689e-03, PNorm = 36.7996, GNorm = 2.7817, lr_0 = 1.0804e-04
Loss = 2.4608e-03, PNorm = 36.8034, GNorm = 1.0947, lr_0 = 1.0804e-04
Validation rmse logD = 0.653953
Validation R2 logD = 0.724612
Epoch 60
Train function
Loss = 3.0321e-03, PNorm = 36.8080, GNorm = 3.9746, lr_0 = 1.0804e-04
Loss = 2.9899e-03, PNorm = 36.8122, GNorm = 2.9629, lr_0 = 1.0804e-04
Loss = 2.6060e-03, PNorm = 36.8148, GNorm = 1.0445, lr_0 = 1.0804e-04
Loss = 3.0181e-03, PNorm = 36.8177, GNorm = 6.2902, lr_0 = 1.0804e-04
Loss = 2.8607e-03, PNorm = 36.8222, GNorm = 4.9210, lr_0 = 1.0804e-04
Loss = 2.6873e-03, PNorm = 36.8261, GNorm = 3.2819, lr_0 = 1.0804e-04
Validation rmse logD = 0.629552
Validation R2 logD = 0.744780
Epoch 61
Train function
Loss = 2.4336e-03, PNorm = 36.8309, GNorm = 1.7119, lr_0 = 1.0804e-04
Loss = 2.4288e-03, PNorm = 36.8347, GNorm = 3.3741, lr_0 = 1.0804e-04
Loss = 2.8166e-03, PNorm = 36.8385, GNorm = 5.0122, lr_0 = 1.0804e-04
Loss = 2.8825e-03, PNorm = 36.8418, GNorm = 4.0870, lr_0 = 1.0804e-04
Loss = 2.0790e-03, PNorm = 36.8454, GNorm = 5.0221, lr_0 = 1.0804e-04
Loss = 2.2754e-03, PNorm = 36.8502, GNorm = 4.1819, lr_0 = 1.0804e-04
Validation rmse logD = 0.641149
Validation R2 logD = 0.735290
Epoch 62
Train function
Loss = 2.0537e-03, PNorm = 36.8552, GNorm = 5.1867, lr_0 = 1.0804e-04
Loss = 2.5648e-03, PNorm = 36.8578, GNorm = 6.1346, lr_0 = 1.0804e-04
Loss = 3.0136e-03, PNorm = 36.8610, GNorm = 10.4376, lr_0 = 1.0804e-04
Loss = 3.0635e-03, PNorm = 36.8639, GNorm = 3.7018, lr_0 = 1.0804e-04
Loss = 2.2154e-03, PNorm = 36.8675, GNorm = 3.1800, lr_0 = 1.0804e-04
Validation rmse logD = 0.632886
Validation R2 logD = 0.742069
Epoch 63
Train function
Loss = 1.7096e-03, PNorm = 36.8713, GNorm = 1.3304, lr_0 = 1.0804e-04
Loss = 2.8654e-03, PNorm = 36.8747, GNorm = 10.4092, lr_0 = 1.0804e-04
Loss = 2.5904e-03, PNorm = 36.8791, GNorm = 2.2537, lr_0 = 1.0804e-04
Loss = 2.3725e-03, PNorm = 36.8832, GNorm = 1.6634, lr_0 = 1.0804e-04
Loss = 2.6465e-03, PNorm = 36.8865, GNorm = 2.3474, lr_0 = 1.0804e-04
Loss = 2.1892e-03, PNorm = 36.8906, GNorm = 1.9880, lr_0 = 1.0804e-04
Validation rmse logD = 0.627289
Validation R2 logD = 0.746611
Epoch 64
Train function
Loss = 2.8231e-03, PNorm = 36.8942, GNorm = 5.2706, lr_0 = 1.0804e-04
Loss = 2.3297e-03, PNorm = 36.8977, GNorm = 5.3901, lr_0 = 1.0804e-04
Loss = 2.3321e-03, PNorm = 36.9008, GNorm = 3.5180, lr_0 = 1.0804e-04
Loss = 2.2928e-03, PNorm = 36.9042, GNorm = 2.2854, lr_0 = 1.0804e-04
Loss = 2.2067e-03, PNorm = 36.9077, GNorm = 1.9715, lr_0 = 1.0804e-04
Loss = 2.4627e-03, PNorm = 36.9116, GNorm = 1.5897, lr_0 = 1.0804e-04
Validation rmse logD = 0.641425
Validation R2 logD = 0.735062
Epoch 65
Train function
Loss = 2.3993e-03, PNorm = 36.9163, GNorm = 2.9242, lr_0 = 1.0804e-04
Loss = 2.0497e-03, PNorm = 36.9200, GNorm = 1.1318, lr_0 = 1.0804e-04
Loss = 2.4566e-03, PNorm = 36.9231, GNorm = 4.6731, lr_0 = 1.0804e-04
Loss = 2.8128e-03, PNorm = 36.9257, GNorm = 9.7998, lr_0 = 1.0804e-04
Loss = 2.8465e-03, PNorm = 36.9298, GNorm = 2.5564, lr_0 = 1.0804e-04
Validation rmse logD = 0.651282
Validation R2 logD = 0.726857
Epoch 66
Train function
Loss = 2.6528e-03, PNorm = 36.9329, GNorm = 8.0373, lr_0 = 1.0804e-04
Loss = 2.4011e-03, PNorm = 36.9365, GNorm = 3.0860, lr_0 = 1.0804e-04
Loss = 2.9179e-03, PNorm = 36.9406, GNorm = 6.1941, lr_0 = 1.0804e-04
Loss = 2.7438e-03, PNorm = 36.9440, GNorm = 2.6278, lr_0 = 1.0804e-04
Loss = 2.6808e-03, PNorm = 36.9482, GNorm = 6.1809, lr_0 = 1.0804e-04
Loss = 2.2685e-03, PNorm = 36.9509, GNorm = 2.8079, lr_0 = 1.0804e-04
Validation rmse logD = 0.636102
Validation R2 logD = 0.739441
Epoch 67
Train function
Loss = 2.7866e-03, PNorm = 36.9531, GNorm = 5.9339, lr_0 = 1.0804e-04
Loss = 2.3454e-03, PNorm = 36.9568, GNorm = 1.8575, lr_0 = 1.0804e-04
Loss = 2.3500e-03, PNorm = 36.9611, GNorm = 8.5531, lr_0 = 1.0804e-04
Loss = 2.9745e-03, PNorm = 36.9653, GNorm = 2.6245, lr_0 = 1.0804e-04
Loss = 2.0283e-03, PNorm = 36.9684, GNorm = 5.4944, lr_0 = 1.0804e-04
Loss = 2.4404e-03, PNorm = 36.9713, GNorm = 2.0851, lr_0 = 1.0804e-04
Validation rmse logD = 0.632085
Validation R2 logD = 0.742722
Epoch 68
Train function
Loss = 2.3632e-03, PNorm = 36.9760, GNorm = 5.6005, lr_0 = 1.0804e-04
Loss = 2.1391e-03, PNorm = 36.9800, GNorm = 1.5146, lr_0 = 1.0804e-04
Loss = 1.9409e-03, PNorm = 36.9828, GNorm = 2.2796, lr_0 = 1.0804e-04
Loss = 2.0678e-03, PNorm = 36.9852, GNorm = 4.0256, lr_0 = 1.0804e-04
Loss = 2.1733e-03, PNorm = 36.9897, GNorm = 1.6648, lr_0 = 1.0804e-04
Validation rmse logD = 0.638310
Validation R2 logD = 0.737629
Epoch 69
Train function
Loss = 1.8478e-03, PNorm = 36.9942, GNorm = 5.3871, lr_0 = 1.0804e-04
Loss = 2.2473e-03, PNorm = 36.9979, GNorm = 1.6142, lr_0 = 1.0804e-04
Loss = 2.3292e-03, PNorm = 37.0010, GNorm = 2.5716, lr_0 = 1.0804e-04
Loss = 2.4007e-03, PNorm = 37.0049, GNorm = 5.0048, lr_0 = 1.0804e-04
Loss = 2.0787e-03, PNorm = 37.0078, GNorm = 4.8628, lr_0 = 1.0804e-04
Loss = 2.0867e-03, PNorm = 37.0109, GNorm = 1.3141, lr_0 = 1.0804e-04
Validation rmse logD = 0.622539
Validation R2 logD = 0.750434
Epoch 70
Train function
Loss = 2.3212e-03, PNorm = 37.0143, GNorm = 3.1281, lr_0 = 1.0804e-04
Loss = 2.0771e-03, PNorm = 37.0178, GNorm = 1.8481, lr_0 = 1.0804e-04
Loss = 2.5365e-03, PNorm = 37.0213, GNorm = 7.2874, lr_0 = 1.0804e-04
Loss = 2.7460e-03, PNorm = 37.0233, GNorm = 2.5989, lr_0 = 1.0804e-04
Loss = 2.6321e-03, PNorm = 37.0270, GNorm = 5.2190, lr_0 = 1.0804e-04
Loss = 2.2015e-03, PNorm = 37.0310, GNorm = 2.1181, lr_0 = 1.0804e-04
Validation rmse logD = 0.624803
Validation R2 logD = 0.748615
Epoch 71
Train function
Loss = 2.1671e-03, PNorm = 37.0347, GNorm = 3.8227, lr_0 = 1.0804e-04
Loss = 1.9546e-03, PNorm = 37.0394, GNorm = 3.7229, lr_0 = 1.0804e-04
Loss = 2.2280e-03, PNorm = 37.0430, GNorm = 2.8056, lr_0 = 1.0804e-04
Loss = 2.3666e-03, PNorm = 37.0458, GNorm = 6.1775, lr_0 = 1.0804e-04
Loss = 2.1175e-03, PNorm = 37.0487, GNorm = 1.5902, lr_0 = 1.0804e-04
Validation rmse logD = 0.630487
Validation R2 logD = 0.744020
Epoch 72
Train function
Loss = 2.6358e-03, PNorm = 37.0523, GNorm = 1.4576, lr_0 = 1.0804e-04
Loss = 1.8533e-03, PNorm = 37.0562, GNorm = 2.1532, lr_0 = 1.0804e-04
Loss = 2.1021e-03, PNorm = 37.0596, GNorm = 2.7089, lr_0 = 1.0804e-04
Loss = 2.2457e-03, PNorm = 37.0630, GNorm = 2.8478, lr_0 = 1.0804e-04
Loss = 2.4713e-03, PNorm = 37.0670, GNorm = 1.3795, lr_0 = 1.0804e-04
Loss = 2.2808e-03, PNorm = 37.0716, GNorm = 1.3518, lr_0 = 1.0804e-04
Validation rmse logD = 0.625848
Validation R2 logD = 0.747774
Epoch 73
Train function
Loss = 2.3881e-03, PNorm = 37.0752, GNorm = 7.4142, lr_0 = 1.0804e-04
Loss = 2.0934e-03, PNorm = 37.0780, GNorm = 1.5722, lr_0 = 1.0804e-04
Loss = 1.9288e-03, PNorm = 37.0810, GNorm = 3.0520, lr_0 = 1.0804e-04
Loss = 2.0969e-03, PNorm = 37.0848, GNorm = 7.1077, lr_0 = 1.0804e-04
Loss = 2.7509e-03, PNorm = 37.0875, GNorm = 2.8232, lr_0 = 1.0804e-04
Loss = 2.2890e-03, PNorm = 37.0890, GNorm = 3.8383, lr_0 = 1.0804e-04
Validation rmse logD = 0.619839
Validation R2 logD = 0.752594
Epoch 74
Train function
Loss = 2.3194e-03, PNorm = 37.0936, GNorm = 2.3007, lr_0 = 1.0804e-04
Loss = 2.0157e-03, PNorm = 37.0957, GNorm = 2.0786, lr_0 = 1.0804e-04
Loss = 2.2874e-03, PNorm = 37.0987, GNorm = 3.5013, lr_0 = 1.0804e-04
Loss = 1.9999e-03, PNorm = 37.1025, GNorm = 4.4513, lr_0 = 1.0804e-04
Loss = 2.1283e-03, PNorm = 37.1068, GNorm = 3.0005, lr_0 = 1.0804e-04
Validation rmse logD = 0.627834
Validation R2 logD = 0.746170
Epoch 75
Train function
Loss = 1.5842e-03, PNorm = 37.1116, GNorm = 2.5599, lr_0 = 1.0804e-04
Loss = 1.8039e-03, PNorm = 37.1147, GNorm = 2.4968, lr_0 = 1.0804e-04
Loss = 1.8867e-03, PNorm = 37.1175, GNorm = 3.5057, lr_0 = 1.0804e-04
Loss = 2.2158e-03, PNorm = 37.1202, GNorm = 3.1712, lr_0 = 1.0804e-04
Loss = 2.4480e-03, PNorm = 37.1249, GNorm = 4.5477, lr_0 = 1.0804e-04
Loss = 2.3588e-03, PNorm = 37.1285, GNorm = 1.3790, lr_0 = 1.0804e-04
Validation rmse logD = 0.623873
Validation R2 logD = 0.749363
Epoch 76
Train function
Loss = 1.6159e-03, PNorm = 37.1320, GNorm = 2.3220, lr_0 = 1.0804e-04
Loss = 1.5885e-03, PNorm = 37.1356, GNorm = 1.3845, lr_0 = 1.0804e-04
Loss = 2.1481e-03, PNorm = 37.1395, GNorm = 5.1238, lr_0 = 1.0804e-04
Loss = 2.4067e-03, PNorm = 37.1431, GNorm = 9.2016, lr_0 = 1.0804e-04
Loss = 2.3951e-03, PNorm = 37.1446, GNorm = 6.5034, lr_0 = 1.0804e-04
Loss = 2.1967e-03, PNorm = 37.1474, GNorm = 3.3067, lr_0 = 1.0804e-04
Validation rmse logD = 0.640939
Validation R2 logD = 0.735463
Epoch 77
Train function
Loss = 1.9886e-03, PNorm = 37.1510, GNorm = 6.0644, lr_0 = 1.0804e-04
Loss = 1.9501e-03, PNorm = 37.1542, GNorm = 1.0865, lr_0 = 1.0804e-04
Loss = 2.5755e-03, PNorm = 37.1569, GNorm = 7.0744, lr_0 = 1.0804e-04
Loss = 2.2791e-03, PNorm = 37.1606, GNorm = 3.0007, lr_0 = 1.0804e-04
Loss = 2.1294e-03, PNorm = 37.1640, GNorm = 7.1971, lr_0 = 1.0804e-04
Validation rmse logD = 0.614654
Validation R2 logD = 0.756716
Epoch 78
Train function
Loss = 1.6270e-03, PNorm = 37.1673, GNorm = 2.9443, lr_0 = 1.0804e-04
Loss = 2.0276e-03, PNorm = 37.1710, GNorm = 1.7873, lr_0 = 1.0804e-04
Loss = 1.9439e-03, PNorm = 37.1742, GNorm = 3.0648, lr_0 = 1.0804e-04
Loss = 2.0697e-03, PNorm = 37.1776, GNorm = 2.3669, lr_0 = 1.0804e-04
Loss = 2.1547e-03, PNorm = 37.1821, GNorm = 4.3511, lr_0 = 1.0804e-04
Loss = 1.6324e-03, PNorm = 37.1862, GNorm = 4.7935, lr_0 = 1.0804e-04
Validation rmse logD = 0.639211
Validation R2 logD = 0.736888
Epoch 79
Train function
Loss = 1.8586e-03, PNorm = 37.1886, GNorm = 2.2195, lr_0 = 1.0804e-04
Loss = 1.9715e-03, PNorm = 37.1901, GNorm = 5.4768, lr_0 = 1.0804e-04
Loss = 2.0052e-03, PNorm = 37.1937, GNorm = 6.3125, lr_0 = 1.0804e-04
Loss = 2.0885e-03, PNorm = 37.1975, GNorm = 2.0923, lr_0 = 1.0804e-04
Loss = 2.0352e-03, PNorm = 37.2010, GNorm = 6.4886, lr_0 = 1.0804e-04
Loss = 2.3593e-03, PNorm = 37.2058, GNorm = 6.1374, lr_0 = 1.0804e-04
Validation rmse logD = 0.624703
Validation R2 logD = 0.748696
Epoch 80
Train function
Loss = 1.8666e-03, PNorm = 37.2107, GNorm = 1.5793, lr_0 = 1.0804e-04
Loss = 1.8070e-03, PNorm = 37.2136, GNorm = 1.9161, lr_0 = 1.0804e-04
Loss = 1.6752e-03, PNorm = 37.2165, GNorm = 3.4332, lr_0 = 1.0804e-04
Loss = 1.9161e-03, PNorm = 37.2202, GNorm = 7.7432, lr_0 = 1.0804e-04
Loss = 1.9479e-03, PNorm = 37.2225, GNorm = 5.0020, lr_0 = 1.0804e-04
Validation rmse logD = 0.614474
Validation R2 logD = 0.756858
Epoch 81
Train function
Loss = 2.0194e-03, PNorm = 37.2260, GNorm = 2.0168, lr_0 = 1.0804e-04
Loss = 1.6923e-03, PNorm = 37.2292, GNorm = 3.4783, lr_0 = 1.0804e-04
Loss = 1.9160e-03, PNorm = 37.2323, GNorm = 2.5177, lr_0 = 1.0804e-04
Loss = 1.8462e-03, PNorm = 37.2358, GNorm = 7.4542, lr_0 = 1.0804e-04
Loss = 1.9172e-03, PNorm = 37.2391, GNorm = 1.5402, lr_0 = 1.0804e-04
Loss = 2.2596e-03, PNorm = 37.2429, GNorm = 7.1539, lr_0 = 1.0804e-04
Validation rmse logD = 0.634995
Validation R2 logD = 0.740347
Epoch 82
Train function
Loss = 1.5443e-03, PNorm = 37.2463, GNorm = 7.6406, lr_0 = 1.0804e-04
Loss = 1.7277e-03, PNorm = 37.2500, GNorm = 1.8216, lr_0 = 1.0804e-04
Loss = 2.2671e-03, PNorm = 37.2535, GNorm = 2.0526, lr_0 = 1.0804e-04
Loss = 2.1411e-03, PNorm = 37.2567, GNorm = 9.0791, lr_0 = 1.0804e-04
Loss = 2.0501e-03, PNorm = 37.2598, GNorm = 1.4141, lr_0 = 1.0804e-04
Loss = 2.3064e-03, PNorm = 37.2625, GNorm = 6.0167, lr_0 = 1.0804e-04
Validation rmse logD = 0.625888
Validation R2 logD = 0.747742
Epoch 83
Train function
Loss = 1.9689e-03, PNorm = 37.2647, GNorm = 5.2631, lr_0 = 1.0804e-04
Loss = 1.5693e-03, PNorm = 37.2676, GNorm = 1.8898, lr_0 = 1.0804e-04
Loss = 1.6688e-03, PNorm = 37.2710, GNorm = 1.8985, lr_0 = 1.0804e-04
Loss = 1.6855e-03, PNorm = 37.2752, GNorm = 4.4301, lr_0 = 1.0804e-04
Loss = 2.0736e-03, PNorm = 37.2790, GNorm = 2.7709, lr_0 = 1.0804e-04
Validation rmse logD = 0.619689
Validation R2 logD = 0.752713
Epoch 84
Train function
Loss = 1.1047e-03, PNorm = 37.2821, GNorm = 2.2317, lr_0 = 1.0804e-04
Loss = 1.6405e-03, PNorm = 37.2854, GNorm = 3.0020, lr_0 = 1.0804e-04
Loss = 1.8351e-03, PNorm = 37.2890, GNorm = 3.1407, lr_0 = 1.0804e-04
Loss = 1.6215e-03, PNorm = 37.2917, GNorm = 1.1917, lr_0 = 1.0804e-04
Loss = 1.7231e-03, PNorm = 37.2940, GNorm = 2.1996, lr_0 = 1.0804e-04
Loss = 2.1923e-03, PNorm = 37.2980, GNorm = 5.8735, lr_0 = 1.0804e-04
Validation rmse logD = 0.626637
Validation R2 logD = 0.747137
Epoch 85
Train function
Loss = 1.6565e-03, PNorm = 37.3004, GNorm = 2.4049, lr_0 = 1.0804e-04
Loss = 1.6708e-03, PNorm = 37.3028, GNorm = 1.6089, lr_0 = 1.0804e-04
Loss = 1.5512e-03, PNorm = 37.3065, GNorm = 7.9526, lr_0 = 1.0804e-04
Loss = 1.8189e-03, PNorm = 37.3099, GNorm = 1.6943, lr_0 = 1.0804e-04
Loss = 1.9803e-03, PNorm = 37.3138, GNorm = 4.0910, lr_0 = 1.0804e-04
Loss = 1.8286e-03, PNorm = 37.3168, GNorm = 2.1309, lr_0 = 1.0804e-04
Validation rmse logD = 0.620827
Validation R2 logD = 0.751805
Epoch 86
Train function
Loss = 1.4905e-03, PNorm = 37.3203, GNorm = 2.0022, lr_0 = 1.0804e-04
Loss = 1.7752e-03, PNorm = 37.3240, GNorm = 2.4622, lr_0 = 1.0804e-04
Loss = 1.9253e-03, PNorm = 37.3263, GNorm = 4.3467, lr_0 = 1.0804e-04
Loss = 1.9081e-03, PNorm = 37.3297, GNorm = 3.9698, lr_0 = 1.0804e-04
Loss = 1.5616e-03, PNorm = 37.3328, GNorm = 2.8960, lr_0 = 1.0804e-04
Validation rmse logD = 0.623607
Validation R2 logD = 0.749577
Epoch 87
Train function
Loss = 2.2812e-03, PNorm = 37.3362, GNorm = 8.0993, lr_0 = 1.0804e-04
Loss = 1.7471e-03, PNorm = 37.3397, GNorm = 7.1561, lr_0 = 1.0804e-04
Loss = 1.6848e-03, PNorm = 37.3437, GNorm = 3.9153, lr_0 = 1.0804e-04
Loss = 1.6293e-03, PNorm = 37.3472, GNorm = 1.3496, lr_0 = 1.0804e-04
Loss = 2.0170e-03, PNorm = 37.3501, GNorm = 4.5558, lr_0 = 1.0804e-04
Loss = 1.7190e-03, PNorm = 37.3527, GNorm = 4.3402, lr_0 = 1.0804e-04
Validation rmse logD = 0.613547
Validation R2 logD = 0.757591
Epoch 88
Train function
Loss = 1.3862e-03, PNorm = 37.3551, GNorm = 5.7350, lr_0 = 1.0804e-04
Loss = 1.6377e-03, PNorm = 37.3586, GNorm = 5.1574, lr_0 = 1.0804e-04
Loss = 1.7566e-03, PNorm = 37.3625, GNorm = 1.4959, lr_0 = 1.0804e-04
Loss = 1.4312e-03, PNorm = 37.3661, GNorm = 1.7480, lr_0 = 1.0804e-04
Loss = 1.7550e-03, PNorm = 37.3688, GNorm = 2.0556, lr_0 = 1.0804e-04
Loss = 1.7211e-03, PNorm = 37.3718, GNorm = 2.1612, lr_0 = 1.0804e-04
Validation rmse logD = 0.610767
Validation R2 logD = 0.759783
Epoch 89
Train function
Loss = 1.6866e-03, PNorm = 37.3748, GNorm = 2.9107, lr_0 = 1.0804e-04
Loss = 1.6814e-03, PNorm = 37.3777, GNorm = 1.9656, lr_0 = 1.0804e-04
Loss = 1.8427e-03, PNorm = 37.3812, GNorm = 6.0254, lr_0 = 1.0804e-04
Loss = 1.9378e-03, PNorm = 37.3850, GNorm = 1.8859, lr_0 = 1.0804e-04
Loss = 1.6371e-03, PNorm = 37.3883, GNorm = 2.2704, lr_0 = 1.0804e-04
Validation rmse logD = 0.615512
Validation R2 logD = 0.756036
Epoch 90
Train function
Loss = 2.2426e-03, PNorm = 37.3912, GNorm = 1.9702, lr_0 = 1.0804e-04
Loss = 1.3504e-03, PNorm = 37.3942, GNorm = 1.4866, lr_0 = 1.0804e-04
Loss = 1.7532e-03, PNorm = 37.3986, GNorm = 2.0318, lr_0 = 1.0804e-04
Loss = 1.5812e-03, PNorm = 37.4013, GNorm = 3.2159, lr_0 = 1.0804e-04
Loss = 1.6190e-03, PNorm = 37.4038, GNorm = 1.4203, lr_0 = 1.0804e-04
Loss = 1.7092e-03, PNorm = 37.4070, GNorm = 3.2282, lr_0 = 1.0804e-04
Validation rmse logD = 0.625646
Validation R2 logD = 0.747936
Epoch 91
Train function
Loss = 1.7347e-03, PNorm = 37.4091, GNorm = 5.3836, lr_0 = 1.0804e-04
Loss = 1.7831e-03, PNorm = 37.4127, GNorm = 6.7970, lr_0 = 1.0804e-04
Loss = 2.1769e-03, PNorm = 37.4168, GNorm = 2.5972, lr_0 = 1.0804e-04
Loss = 1.5740e-03, PNorm = 37.4194, GNorm = 4.1274, lr_0 = 1.0804e-04
Loss = 1.6404e-03, PNorm = 37.4224, GNorm = 2.8171, lr_0 = 1.0804e-04
Loss = 1.6696e-03, PNorm = 37.4250, GNorm = 1.7987, lr_0 = 1.0804e-04
Validation rmse logD = 0.613766
Validation R2 logD = 0.757418
Epoch 92
Train function
Loss = 1.3591e-03, PNorm = 37.4280, GNorm = 2.3116, lr_0 = 1.0804e-04
Loss = 1.3777e-03, PNorm = 37.4305, GNorm = 1.6777, lr_0 = 1.0804e-04
Loss = 1.6327e-03, PNorm = 37.4335, GNorm = 4.9553, lr_0 = 1.0804e-04
Loss = 1.7498e-03, PNorm = 37.4370, GNorm = 5.3473, lr_0 = 1.0804e-04
Loss = 1.7661e-03, PNorm = 37.4414, GNorm = 2.0081, lr_0 = 1.0804e-04
Validation rmse logD = 0.621855
Validation R2 logD = 0.750982
Epoch 93
Train function
Loss = 1.3287e-03, PNorm = 37.4441, GNorm = 5.0498, lr_0 = 1.0804e-04
Loss = 1.5682e-03, PNorm = 37.4470, GNorm = 5.3383, lr_0 = 1.0804e-04
Loss = 1.6059e-03, PNorm = 37.4503, GNorm = 1.7715, lr_0 = 1.0804e-04
Loss = 1.8303e-03, PNorm = 37.4534, GNorm = 7.9372, lr_0 = 1.0804e-04
Loss = 1.8923e-03, PNorm = 37.4545, GNorm = 2.1527, lr_0 = 1.0804e-04
Loss = 1.7998e-03, PNorm = 37.4576, GNorm = 6.3214, lr_0 = 1.0804e-04
Validation rmse logD = 0.643000
Validation R2 logD = 0.733759
Epoch 94
Train function
Loss = 1.9238e-03, PNorm = 37.4615, GNorm = 8.9730, lr_0 = 1.0804e-04
Loss = 2.1172e-03, PNorm = 37.4639, GNorm = 1.9737, lr_0 = 1.0804e-04
Loss = 1.8840e-03, PNorm = 37.4675, GNorm = 7.0058, lr_0 = 1.0804e-04
Loss = 1.7256e-03, PNorm = 37.4724, GNorm = 1.4137, lr_0 = 1.0804e-04
Loss = 1.6831e-03, PNorm = 37.4761, GNorm = 4.4329, lr_0 = 1.0804e-04
Loss = 1.5305e-03, PNorm = 37.4780, GNorm = 2.2913, lr_0 = 1.0804e-04
Validation rmse logD = 0.621086
Validation R2 logD = 0.751597
Epoch 95
Train function
Loss = 2.0989e-03, PNorm = 37.4805, GNorm = 2.9581, lr_0 = 1.0804e-04
Loss = 1.6768e-03, PNorm = 37.4832, GNorm = 3.2791, lr_0 = 1.0804e-04
Loss = 1.6636e-03, PNorm = 37.4860, GNorm = 1.8135, lr_0 = 1.0804e-04
Loss = 2.1861e-03, PNorm = 37.4888, GNorm = 8.6843, lr_0 = 1.0804e-04
Loss = 1.6814e-03, PNorm = 37.4918, GNorm = 3.4939, lr_0 = 1.0804e-04
Validation rmse logD = 0.622698
Validation R2 logD = 0.750306
Epoch 96
Train function
Loss = 1.6674e-03, PNorm = 37.4956, GNorm = 1.3136, lr_0 = 1.0804e-04
Loss = 1.5971e-03, PNorm = 37.4985, GNorm = 1.3317, lr_0 = 1.0804e-04
Loss = 1.3459e-03, PNorm = 37.5022, GNorm = 2.1962, lr_0 = 1.0804e-04
Loss = 1.7178e-03, PNorm = 37.5060, GNorm = 5.6337, lr_0 = 1.0804e-04
Loss = 1.5175e-03, PNorm = 37.5097, GNorm = 3.8956, lr_0 = 1.0804e-04
Loss = 1.4353e-03, PNorm = 37.5129, GNorm = 1.7120, lr_0 = 1.0804e-04
Validation rmse logD = 0.610694
Validation R2 logD = 0.759841
Epoch 97
Train function
Loss = 1.7039e-03, PNorm = 37.5154, GNorm = 2.5123, lr_0 = 1.0804e-04
Loss = 1.3146e-03, PNorm = 37.5185, GNorm = 1.5733, lr_0 = 1.0804e-04
Loss = 1.4582e-03, PNorm = 37.5217, GNorm = 5.6924, lr_0 = 1.0804e-04
Loss = 1.3846e-03, PNorm = 37.5249, GNorm = 2.1056, lr_0 = 1.0804e-04
Loss = 1.6381e-03, PNorm = 37.5286, GNorm = 6.1453, lr_0 = 1.0804e-04
Loss = 1.7175e-03, PNorm = 37.5325, GNorm = 4.2312, lr_0 = 1.0804e-04
Validation rmse logD = 0.611764
Validation R2 logD = 0.758998
Epoch 98
Train function
Loss = 1.2713e-03, PNorm = 37.5346, GNorm = 1.6767, lr_0 = 1.0804e-04
Loss = 1.6864e-03, PNorm = 37.5368, GNorm = 2.4632, lr_0 = 1.0804e-04
Loss = 1.5108e-03, PNorm = 37.5391, GNorm = 4.9194, lr_0 = 1.0804e-04
Loss = 1.4510e-03, PNorm = 37.5424, GNorm = 2.2769, lr_0 = 1.0804e-04
Loss = 1.5766e-03, PNorm = 37.5452, GNorm = 2.9859, lr_0 = 1.0804e-04
Validation rmse logD = 0.611623
Validation R2 logD = 0.759109
Epoch 99
Train function
Loss = 1.7130e-03, PNorm = 37.5491, GNorm = 2.6745, lr_0 = 1.0804e-04
Loss = 1.2873e-03, PNorm = 37.5541, GNorm = 3.5546, lr_0 = 1.0804e-04
Loss = 1.5422e-03, PNorm = 37.5571, GNorm = 1.9733, lr_0 = 1.0804e-04
Loss = 1.5755e-03, PNorm = 37.5589, GNorm = 4.1000, lr_0 = 1.0804e-04
Loss = 1.5168e-03, PNorm = 37.5608, GNorm = 1.5920, lr_0 = 1.0804e-04
Loss = 1.5841e-03, PNorm = 37.5635, GNorm = 1.8769, lr_0 = 1.0804e-04
Validation rmse logD = 0.614108
Validation R2 logD = 0.757148
Model 0 best validation rmse = 0.610694 on epoch 96
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.572041
Model 0 test R2 logD = 0.766427
Ensemble test rmse  logD= 0.572041
Ensemble test R2  logD= 0.766427
Fold 4
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/3_final_data/logd_Lip_wo_averaging.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_365/folds/fold_4',
 'save_smiles_splits': False,
 'seed': 4,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 2833,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 4
Total size = 4,166 | train size = 2,833 | val size = 500 | test size = 833
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.2358e-02, PNorm = 35.0058, GNorm = 8.0854, lr_0 = 1.0804e-04
Loss = 2.0050e-02, PNorm = 35.0055, GNorm = 2.7156, lr_0 = 1.0804e-04
Loss = 1.7551e-02, PNorm = 35.0064, GNorm = 2.5087, lr_0 = 1.0804e-04
Loss = 1.7809e-02, PNorm = 35.0079, GNorm = 2.4795, lr_0 = 1.0804e-04
Loss = 1.7467e-02, PNorm = 35.0102, GNorm = 2.1650, lr_0 = 1.0804e-04
Validation rmse logD = 1.108879
Validation R2 logD = 0.231828
Epoch 1
Train function
Loss = 1.5656e-02, PNorm = 35.0123, GNorm = 5.7506, lr_0 = 1.0804e-04
Loss = 1.4685e-02, PNorm = 35.0143, GNorm = 5.5467, lr_0 = 1.0804e-04
Loss = 1.5448e-02, PNorm = 35.0161, GNorm = 4.1236, lr_0 = 1.0804e-04
Loss = 1.3423e-02, PNorm = 35.0184, GNorm = 2.4287, lr_0 = 1.0804e-04
Loss = 1.4690e-02, PNorm = 35.0212, GNorm = 2.8568, lr_0 = 1.0804e-04
Loss = 1.5794e-02, PNorm = 35.0246, GNorm = 9.5495, lr_0 = 1.0804e-04
Validation rmse logD = 1.033683
Validation R2 logD = 0.332479
Epoch 2
Train function
Loss = 1.2777e-02, PNorm = 35.0280, GNorm = 5.0950, lr_0 = 1.0804e-04
Loss = 1.4357e-02, PNorm = 35.0307, GNorm = 4.2575, lr_0 = 1.0804e-04
Loss = 1.2901e-02, PNorm = 35.0336, GNorm = 3.9913, lr_0 = 1.0804e-04
Loss = 1.3741e-02, PNorm = 35.0374, GNorm = 2.0195, lr_0 = 1.0804e-04
Loss = 1.2604e-02, PNorm = 35.0419, GNorm = 1.8040, lr_0 = 1.0804e-04
Validation rmse logD = 0.982555
Validation R2 logD = 0.396880
Epoch 3
Train function
Loss = 1.2824e-02, PNorm = 35.0473, GNorm = 4.7745, lr_0 = 1.0804e-04
Loss = 1.2323e-02, PNorm = 35.0514, GNorm = 1.4562, lr_0 = 1.0804e-04
Loss = 1.1819e-02, PNorm = 35.0562, GNorm = 2.3304, lr_0 = 1.0804e-04
Loss = 1.1101e-02, PNorm = 35.0608, GNorm = 7.1254, lr_0 = 1.0804e-04
Loss = 1.2754e-02, PNorm = 35.0651, GNorm = 4.3412, lr_0 = 1.0804e-04
Loss = 1.1868e-02, PNorm = 35.0699, GNorm = 1.6194, lr_0 = 1.0804e-04
Validation rmse logD = 0.949526
Validation R2 logD = 0.436746
Epoch 4
Train function
Loss = 1.1505e-02, PNorm = 35.0748, GNorm = 5.3371, lr_0 = 1.0804e-04
Loss = 1.1458e-02, PNorm = 35.0793, GNorm = 2.3897, lr_0 = 1.0804e-04
Loss = 1.1564e-02, PNorm = 35.0840, GNorm = 2.2275, lr_0 = 1.0804e-04
Loss = 1.0515e-02, PNorm = 35.0885, GNorm = 4.0897, lr_0 = 1.0804e-04
Loss = 1.0120e-02, PNorm = 35.0937, GNorm = 2.4851, lr_0 = 1.0804e-04
Loss = 1.1061e-02, PNorm = 35.0989, GNorm = 2.8649, lr_0 = 1.0804e-04
Validation rmse logD = 0.930287
Validation R2 logD = 0.459341
Epoch 5
Train function
Loss = 9.9600e-03, PNorm = 35.1040, GNorm = 1.5915, lr_0 = 1.0804e-04
Loss = 1.0642e-02, PNorm = 35.1094, GNorm = 1.3221, lr_0 = 1.0804e-04
Loss = 1.0478e-02, PNorm = 35.1149, GNorm = 1.6828, lr_0 = 1.0804e-04
Loss = 8.9751e-03, PNorm = 35.1205, GNorm = 2.7485, lr_0 = 1.0804e-04
Loss = 1.0951e-02, PNorm = 35.1266, GNorm = 1.3894, lr_0 = 1.0804e-04
Validation rmse logD = 0.903140
Validation R2 logD = 0.490434
Epoch 6
Train function
Loss = 8.4648e-03, PNorm = 35.1336, GNorm = 3.5574, lr_0 = 1.0804e-04
Loss = 1.0164e-02, PNorm = 35.1414, GNorm = 2.5804, lr_0 = 1.0804e-04
Loss = 9.9930e-03, PNorm = 35.1478, GNorm = 2.3459, lr_0 = 1.0804e-04
Loss = 9.4621e-03, PNorm = 35.1532, GNorm = 4.0855, lr_0 = 1.0804e-04
Loss = 9.9564e-03, PNorm = 35.1583, GNorm = 5.5461, lr_0 = 1.0804e-04
Loss = 8.4191e-03, PNorm = 35.1639, GNorm = 2.3132, lr_0 = 1.0804e-04
Validation rmse logD = 0.878972
Validation R2 logD = 0.517341
Epoch 7
Train function
Loss = 1.0942e-02, PNorm = 35.1706, GNorm = 2.5376, lr_0 = 1.0804e-04
Loss = 9.9335e-03, PNorm = 35.1782, GNorm = 2.8672, lr_0 = 1.0804e-04
Loss = 8.8117e-03, PNorm = 35.1841, GNorm = 7.7681, lr_0 = 1.0804e-04
Loss = 9.2958e-03, PNorm = 35.1903, GNorm = 10.0602, lr_0 = 1.0804e-04
Loss = 8.4474e-03, PNorm = 35.1964, GNorm = 4.3138, lr_0 = 1.0804e-04
Loss = 8.4040e-03, PNorm = 35.2021, GNorm = 1.3825, lr_0 = 1.0804e-04
Validation rmse logD = 0.878192
Validation R2 logD = 0.518197
Epoch 8
Train function
Loss = 8.2466e-03, PNorm = 35.2067, GNorm = 1.4479, lr_0 = 1.0804e-04
Loss = 8.6860e-03, PNorm = 35.2129, GNorm = 4.2708, lr_0 = 1.0804e-04
Loss = 9.6895e-03, PNorm = 35.2187, GNorm = 5.2000, lr_0 = 1.0804e-04
Loss = 7.6682e-03, PNorm = 35.2246, GNorm = 8.0612, lr_0 = 1.0804e-04
Loss = 9.1697e-03, PNorm = 35.2310, GNorm = 9.5777, lr_0 = 1.0804e-04
Validation rmse logD = 0.866655
Validation R2 logD = 0.530773
Epoch 9
Train function
Loss = 5.7938e-03, PNorm = 35.2384, GNorm = 1.6938, lr_0 = 1.0804e-04
Loss = 8.3153e-03, PNorm = 35.2456, GNorm = 5.2815, lr_0 = 1.0804e-04
Loss = 9.0676e-03, PNorm = 35.2524, GNorm = 1.4445, lr_0 = 1.0804e-04
Loss = 8.5089e-03, PNorm = 35.2589, GNorm = 5.9991, lr_0 = 1.0804e-04
Loss = 8.6464e-03, PNorm = 35.2653, GNorm = 1.6404, lr_0 = 1.0804e-04
Loss = 7.4340e-03, PNorm = 35.2717, GNorm = 1.1524, lr_0 = 1.0804e-04
Validation rmse logD = 0.850206
Validation R2 logD = 0.548417
Epoch 10
Train function
Loss = 8.7435e-03, PNorm = 35.2786, GNorm = 3.7854, lr_0 = 1.0804e-04
Loss = 7.9112e-03, PNorm = 35.2853, GNorm = 4.7293, lr_0 = 1.0804e-04
Loss = 8.0423e-03, PNorm = 35.2911, GNorm = 2.7804, lr_0 = 1.0804e-04
Loss = 8.4812e-03, PNorm = 35.2984, GNorm = 2.2406, lr_0 = 1.0804e-04
Loss = 7.4730e-03, PNorm = 35.3060, GNorm = 1.9235, lr_0 = 1.0804e-04
Loss = 8.2437e-03, PNorm = 35.3126, GNorm = 7.7369, lr_0 = 1.0804e-04
Validation rmse logD = 0.854396
Validation R2 logD = 0.543954
Epoch 11
Train function
Loss = 7.2233e-03, PNorm = 35.3183, GNorm = 4.3420, lr_0 = 1.0804e-04
Loss = 8.1303e-03, PNorm = 35.3237, GNorm = 5.4141, lr_0 = 1.0804e-04
Loss = 8.0407e-03, PNorm = 35.3296, GNorm = 3.9932, lr_0 = 1.0804e-04
Loss = 9.1583e-03, PNorm = 35.3357, GNorm = 2.3175, lr_0 = 1.0804e-04
Loss = 7.3168e-03, PNorm = 35.3419, GNorm = 2.4640, lr_0 = 1.0804e-04
Validation rmse logD = 0.883006
Validation R2 logD = 0.512901
Epoch 12
Train function
Loss = 9.1242e-03, PNorm = 35.3497, GNorm = 8.2788, lr_0 = 1.0804e-04
Loss = 7.6299e-03, PNorm = 35.3574, GNorm = 5.0334, lr_0 = 1.0804e-04
Loss = 8.1338e-03, PNorm = 35.3655, GNorm = 7.1635, lr_0 = 1.0804e-04
Loss = 7.5453e-03, PNorm = 35.3722, GNorm = 4.4445, lr_0 = 1.0804e-04
Loss = 6.9171e-03, PNorm = 35.3788, GNorm = 4.6680, lr_0 = 1.0804e-04
Loss = 6.9095e-03, PNorm = 35.3859, GNorm = 3.8047, lr_0 = 1.0804e-04
Validation rmse logD = 0.813726
Validation R2 logD = 0.586337
Epoch 13
Train function
Loss = 6.9377e-03, PNorm = 35.3918, GNorm = 2.4636, lr_0 = 1.0804e-04
Loss = 7.1476e-03, PNorm = 35.3975, GNorm = 6.5234, lr_0 = 1.0804e-04
Loss = 7.1767e-03, PNorm = 35.4034, GNorm = 8.3718, lr_0 = 1.0804e-04
Loss = 7.0858e-03, PNorm = 35.4113, GNorm = 3.9787, lr_0 = 1.0804e-04
Loss = 6.8600e-03, PNorm = 35.4191, GNorm = 2.0870, lr_0 = 1.0804e-04
Loss = 7.8700e-03, PNorm = 35.4258, GNorm = 1.8829, lr_0 = 1.0804e-04
Validation rmse logD = 0.812497
Validation R2 logD = 0.587586
Epoch 14
Train function
Loss = 6.9360e-03, PNorm = 35.4332, GNorm = 1.9057, lr_0 = 1.0804e-04
Loss = 7.6934e-03, PNorm = 35.4398, GNorm = 1.7911, lr_0 = 1.0804e-04
Loss = 6.3976e-03, PNorm = 35.4449, GNorm = 9.5657, lr_0 = 1.0804e-04
Loss = 7.5045e-03, PNorm = 35.4516, GNorm = 4.0621, lr_0 = 1.0804e-04
Loss = 7.0387e-03, PNorm = 35.4580, GNorm = 3.6493, lr_0 = 1.0804e-04
Validation rmse logD = 0.813166
Validation R2 logD = 0.586906
Epoch 15
Train function
Loss = 6.0528e-03, PNorm = 35.4664, GNorm = 6.0366, lr_0 = 1.0804e-04
Loss = 6.7771e-03, PNorm = 35.4740, GNorm = 2.3435, lr_0 = 1.0804e-04
Loss = 7.3927e-03, PNorm = 35.4813, GNorm = 4.7677, lr_0 = 1.0804e-04
Loss = 6.3429e-03, PNorm = 35.4880, GNorm = 8.0434, lr_0 = 1.0804e-04
Loss = 6.4830e-03, PNorm = 35.4950, GNorm = 3.0575, lr_0 = 1.0804e-04
Loss = 6.4560e-03, PNorm = 35.5021, GNorm = 2.3405, lr_0 = 1.0804e-04
Validation rmse logD = 0.799179
Validation R2 logD = 0.600995
Epoch 16
Train function
Loss = 6.2854e-03, PNorm = 35.5098, GNorm = 2.2428, lr_0 = 1.0804e-04
Loss = 6.7251e-03, PNorm = 35.5172, GNorm = 3.7044, lr_0 = 1.0804e-04
Loss = 5.9155e-03, PNorm = 35.5228, GNorm = 2.4297, lr_0 = 1.0804e-04
Loss = 7.0950e-03, PNorm = 35.5301, GNorm = 1.7414, lr_0 = 1.0804e-04
Loss = 6.2768e-03, PNorm = 35.5381, GNorm = 8.1820, lr_0 = 1.0804e-04
Loss = 6.0983e-03, PNorm = 35.5447, GNorm = 2.7751, lr_0 = 1.0804e-04
Validation rmse logD = 0.781303
Validation R2 logD = 0.618646
Epoch 17
Train function
Loss = 6.2065e-03, PNorm = 35.5518, GNorm = 6.1960, lr_0 = 1.0804e-04
Loss = 7.2099e-03, PNorm = 35.5593, GNorm = 6.7090, lr_0 = 1.0804e-04
Loss = 6.1395e-03, PNorm = 35.5666, GNorm = 3.3137, lr_0 = 1.0804e-04
Loss = 6.8013e-03, PNorm = 35.5724, GNorm = 5.3708, lr_0 = 1.0804e-04
Loss = 6.1972e-03, PNorm = 35.5785, GNorm = 3.7912, lr_0 = 1.0804e-04
Validation rmse logD = 0.791810
Validation R2 logD = 0.608320
Epoch 18
Train function
Loss = 7.7384e-03, PNorm = 35.5856, GNorm = 9.1373, lr_0 = 1.0804e-04
Loss = 6.0250e-03, PNorm = 35.5927, GNorm = 2.9819, lr_0 = 1.0804e-04
Loss = 6.2508e-03, PNorm = 35.5995, GNorm = 2.5003, lr_0 = 1.0804e-04
Loss = 5.6785e-03, PNorm = 35.6060, GNorm = 1.7743, lr_0 = 1.0804e-04
Loss = 5.9866e-03, PNorm = 35.6127, GNorm = 2.8907, lr_0 = 1.0804e-04
Loss = 6.6530e-03, PNorm = 35.6191, GNorm = 3.6183, lr_0 = 1.0804e-04
Validation rmse logD = 0.817379
Validation R2 logD = 0.582615
Epoch 19
Train function
Loss = 4.9936e-03, PNorm = 35.6250, GNorm = 4.3419, lr_0 = 1.0804e-04
Loss = 6.7436e-03, PNorm = 35.6312, GNorm = 5.9077, lr_0 = 1.0804e-04
Loss = 5.9881e-03, PNorm = 35.6368, GNorm = 5.9411, lr_0 = 1.0804e-04
Loss = 5.9406e-03, PNorm = 35.6434, GNorm = 2.6972, lr_0 = 1.0804e-04
Loss = 6.4723e-03, PNorm = 35.6504, GNorm = 10.0713, lr_0 = 1.0804e-04
Loss = 5.8784e-03, PNorm = 35.6570, GNorm = 8.8189, lr_0 = 1.0804e-04
Validation rmse logD = 0.777921
Validation R2 logD = 0.621940
Epoch 20
Train function
Loss = 5.5539e-03, PNorm = 35.6628, GNorm = 1.6951, lr_0 = 1.0804e-04
Loss = 6.3974e-03, PNorm = 35.6697, GNorm = 3.4626, lr_0 = 1.0804e-04
Loss = 6.0731e-03, PNorm = 35.6762, GNorm = 1.5900, lr_0 = 1.0804e-04
Loss = 5.6355e-03, PNorm = 35.6817, GNorm = 3.4911, lr_0 = 1.0804e-04
Loss = 5.3415e-03, PNorm = 35.6873, GNorm = 3.9341, lr_0 = 1.0804e-04
Validation rmse logD = 0.776908
Validation R2 logD = 0.622924
Epoch 21
Train function
Loss = 3.6162e-03, PNorm = 35.6947, GNorm = 3.9086, lr_0 = 1.0804e-04
Loss = 5.1279e-03, PNorm = 35.7013, GNorm = 2.0915, lr_0 = 1.0804e-04
Loss = 5.3632e-03, PNorm = 35.7072, GNorm = 8.8627, lr_0 = 1.0804e-04
Loss = 6.2336e-03, PNorm = 35.7133, GNorm = 10.0548, lr_0 = 1.0804e-04
Loss = 6.7528e-03, PNorm = 35.7179, GNorm = 10.9886, lr_0 = 1.0804e-04
Loss = 6.1721e-03, PNorm = 35.7236, GNorm = 4.2709, lr_0 = 1.0804e-04
Validation rmse logD = 0.765314
Validation R2 logD = 0.634094
Epoch 22
Train function
Loss = 4.4094e-03, PNorm = 35.7292, GNorm = 1.3673, lr_0 = 1.0804e-04
Loss = 5.3153e-03, PNorm = 35.7349, GNorm = 2.5695, lr_0 = 1.0804e-04
Loss = 5.4747e-03, PNorm = 35.7416, GNorm = 1.2765, lr_0 = 1.0804e-04
Loss = 4.7010e-03, PNorm = 35.7487, GNorm = 4.7726, lr_0 = 1.0804e-04
Loss = 5.9843e-03, PNorm = 35.7548, GNorm = 4.9413, lr_0 = 1.0804e-04
Loss = 6.2502e-03, PNorm = 35.7609, GNorm = 4.2903, lr_0 = 1.0804e-04
Validation rmse logD = 0.759905
Validation R2 logD = 0.639248
Epoch 23
Train function
Loss = 6.2578e-03, PNorm = 35.7674, GNorm = 5.2576, lr_0 = 1.0804e-04
Loss = 5.0887e-03, PNorm = 35.7741, GNorm = 9.4779, lr_0 = 1.0804e-04
Loss = 5.2280e-03, PNorm = 35.7795, GNorm = 2.1508, lr_0 = 1.0804e-04
Loss = 5.4212e-03, PNorm = 35.7847, GNorm = 5.7100, lr_0 = 1.0804e-04
Loss = 4.9913e-03, PNorm = 35.7926, GNorm = 7.4229, lr_0 = 1.0804e-04
Validation rmse logD = 0.757879
Validation R2 logD = 0.641169
Epoch 24
Train function
Loss = 3.8524e-03, PNorm = 35.8001, GNorm = 2.0410, lr_0 = 1.0804e-04
Loss = 5.5495e-03, PNorm = 35.8067, GNorm = 4.5007, lr_0 = 1.0804e-04
Loss = 5.1385e-03, PNorm = 35.8129, GNorm = 2.3341, lr_0 = 1.0804e-04
Loss = 5.7884e-03, PNorm = 35.8179, GNorm = 8.4692, lr_0 = 1.0804e-04
Loss = 5.3302e-03, PNorm = 35.8233, GNorm = 5.0592, lr_0 = 1.0804e-04
Loss = 5.5564e-03, PNorm = 35.8285, GNorm = 5.0376, lr_0 = 1.0804e-04
Validation rmse logD = 0.762688
Validation R2 logD = 0.636601
Epoch 25
Train function
Loss = 5.2200e-03, PNorm = 35.8340, GNorm = 3.3001, lr_0 = 1.0804e-04
Loss = 4.8383e-03, PNorm = 35.8396, GNorm = 1.9142, lr_0 = 1.0804e-04
Loss = 4.8721e-03, PNorm = 35.8446, GNorm = 8.1833, lr_0 = 1.0804e-04
Loss = 4.9816e-03, PNorm = 35.8504, GNorm = 2.8482, lr_0 = 1.0804e-04
Loss = 5.2450e-03, PNorm = 35.8571, GNorm = 11.8136, lr_0 = 1.0804e-04
Loss = 5.8578e-03, PNorm = 35.8624, GNorm = 4.1094, lr_0 = 1.0804e-04
Validation rmse logD = 0.753479
Validation R2 logD = 0.645324
Epoch 26
Train function
Loss = 4.7921e-03, PNorm = 35.8687, GNorm = 2.4359, lr_0 = 1.0804e-04
Loss = 4.7149e-03, PNorm = 35.8741, GNorm = 3.5763, lr_0 = 1.0804e-04
Loss = 4.6295e-03, PNorm = 35.8800, GNorm = 3.6587, lr_0 = 1.0804e-04
Loss = 5.3755e-03, PNorm = 35.8855, GNorm = 8.4952, lr_0 = 1.0804e-04
Loss = 4.7661e-03, PNorm = 35.8901, GNorm = 6.2088, lr_0 = 1.0804e-04
Validation rmse logD = 0.754194
Validation R2 logD = 0.644650
Epoch 27
Train function
Loss = 3.8795e-03, PNorm = 35.8966, GNorm = 3.8035, lr_0 = 1.0804e-04
Loss = 4.6096e-03, PNorm = 35.9037, GNorm = 6.1143, lr_0 = 1.0804e-04
Loss = 4.6465e-03, PNorm = 35.9111, GNorm = 2.2875, lr_0 = 1.0804e-04
Loss = 4.7403e-03, PNorm = 35.9178, GNorm = 4.8447, lr_0 = 1.0804e-04
Loss = 4.9920e-03, PNorm = 35.9228, GNorm = 1.5463, lr_0 = 1.0804e-04
Loss = 5.0502e-03, PNorm = 35.9272, GNorm = 3.5873, lr_0 = 1.0804e-04
Validation rmse logD = 0.750228
Validation R2 logD = 0.648377
Epoch 28
Train function
Loss = 5.7478e-03, PNorm = 35.9325, GNorm = 5.5302, lr_0 = 1.0804e-04
Loss = 4.4696e-03, PNorm = 35.9384, GNorm = 3.4152, lr_0 = 1.0804e-04
Loss = 4.8951e-03, PNorm = 35.9450, GNorm = 2.1743, lr_0 = 1.0804e-04
Loss = 5.8429e-03, PNorm = 35.9502, GNorm = 16.1458, lr_0 = 1.0804e-04
Loss = 5.2216e-03, PNorm = 35.9539, GNorm = 5.0996, lr_0 = 1.0804e-04
Loss = 4.9076e-03, PNorm = 35.9587, GNorm = 2.4738, lr_0 = 1.0804e-04
Validation rmse logD = 0.752991
Validation R2 logD = 0.645783
Epoch 29
Train function
Loss = 4.4751e-03, PNorm = 35.9639, GNorm = 1.5479, lr_0 = 1.0804e-04
Loss = 4.3687e-03, PNorm = 35.9699, GNorm = 3.2244, lr_0 = 1.0804e-04
Loss = 4.4451e-03, PNorm = 35.9761, GNorm = 4.0023, lr_0 = 1.0804e-04
Loss = 4.2282e-03, PNorm = 35.9818, GNorm = 5.6769, lr_0 = 1.0804e-04
Loss = 4.6115e-03, PNorm = 35.9865, GNorm = 2.9212, lr_0 = 1.0804e-04
Validation rmse logD = 0.760022
Validation R2 logD = 0.639137
Epoch 30
Train function
Loss = 3.8011e-03, PNorm = 35.9935, GNorm = 5.9577, lr_0 = 1.0804e-04
Loss = 4.0155e-03, PNorm = 35.9996, GNorm = 2.6427, lr_0 = 1.0804e-04
Loss = 4.8787e-03, PNorm = 36.0049, GNorm = 2.7425, lr_0 = 1.0804e-04
Loss = 4.1909e-03, PNorm = 36.0101, GNorm = 1.4323, lr_0 = 1.0804e-04
Loss = 4.3883e-03, PNorm = 36.0160, GNorm = 3.8100, lr_0 = 1.0804e-04
Loss = 4.8309e-03, PNorm = 36.0225, GNorm = 6.4074, lr_0 = 1.0804e-04
Validation rmse logD = 0.764073
Validation R2 logD = 0.635280
Epoch 31
Train function
Loss = 5.1217e-03, PNorm = 36.0282, GNorm = 4.2171, lr_0 = 1.0804e-04
Loss = 3.8976e-03, PNorm = 36.0330, GNorm = 5.1674, lr_0 = 1.0804e-04
Loss = 4.7381e-03, PNorm = 36.0383, GNorm = 2.0256, lr_0 = 1.0804e-04
Loss = 4.5561e-03, PNorm = 36.0444, GNorm = 3.7292, lr_0 = 1.0804e-04
Loss = 4.3097e-03, PNorm = 36.0503, GNorm = 7.9825, lr_0 = 1.0804e-04
Loss = 4.1654e-03, PNorm = 36.0557, GNorm = 5.8358, lr_0 = 1.0804e-04
Validation rmse logD = 0.783949
Validation R2 logD = 0.616058
Epoch 32
Train function
Loss = 3.8952e-03, PNorm = 36.0588, GNorm = 5.9470, lr_0 = 1.0804e-04
Loss = 4.5083e-03, PNorm = 36.0635, GNorm = 3.0009, lr_0 = 1.0804e-04
Loss = 4.5435e-03, PNorm = 36.0691, GNorm = 3.3604, lr_0 = 1.0804e-04
Loss = 4.8303e-03, PNorm = 36.0752, GNorm = 5.7457, lr_0 = 1.0804e-04
Loss = 4.7629e-03, PNorm = 36.0794, GNorm = 9.4308, lr_0 = 1.0804e-04
Validation rmse logD = 0.747438
Validation R2 logD = 0.650988
Epoch 33
Train function
Loss = 3.7816e-03, PNorm = 36.0831, GNorm = 2.3234, lr_0 = 1.0804e-04
Loss = 3.7756e-03, PNorm = 36.0890, GNorm = 2.4585, lr_0 = 1.0804e-04
Loss = 4.4669e-03, PNorm = 36.0942, GNorm = 6.3047, lr_0 = 1.0804e-04
Loss = 4.8670e-03, PNorm = 36.0991, GNorm = 6.2910, lr_0 = 1.0804e-04
Loss = 4.2953e-03, PNorm = 36.1057, GNorm = 4.1743, lr_0 = 1.0804e-04
Loss = 4.0759e-03, PNorm = 36.1109, GNorm = 5.4622, lr_0 = 1.0804e-04
Validation rmse logD = 0.753991
Validation R2 logD = 0.644841
Epoch 34
Train function
Loss = 3.8228e-03, PNorm = 36.1156, GNorm = 2.6938, lr_0 = 1.0804e-04
Loss = 3.6719e-03, PNorm = 36.1201, GNorm = 1.8752, lr_0 = 1.0804e-04
Loss = 3.9708e-03, PNorm = 36.1254, GNorm = 2.9431, lr_0 = 1.0804e-04
Loss = 3.9325e-03, PNorm = 36.1305, GNorm = 2.6214, lr_0 = 1.0804e-04
Loss = 4.2889e-03, PNorm = 36.1351, GNorm = 2.4908, lr_0 = 1.0804e-04
Loss = 4.6543e-03, PNorm = 36.1396, GNorm = 1.7589, lr_0 = 1.0804e-04
Validation rmse logD = 0.763653
Validation R2 logD = 0.635681
Epoch 35
Train function
Loss = 3.9617e-03, PNorm = 36.1450, GNorm = 8.7352, lr_0 = 1.0804e-04
Loss = 3.9833e-03, PNorm = 36.1506, GNorm = 1.9264, lr_0 = 1.0804e-04
Loss = 4.0239e-03, PNorm = 36.1563, GNorm = 7.1221, lr_0 = 1.0804e-04
Loss = 3.9854e-03, PNorm = 36.1621, GNorm = 2.8687, lr_0 = 1.0804e-04
Loss = 4.4710e-03, PNorm = 36.1683, GNorm = 5.2950, lr_0 = 1.0804e-04
Validation rmse logD = 0.760430
Validation R2 logD = 0.638749
Epoch 36
Train function
Loss = 4.8940e-03, PNorm = 36.1717, GNorm = 8.3361, lr_0 = 1.0804e-04
Loss = 3.4718e-03, PNorm = 36.1761, GNorm = 1.5496, lr_0 = 1.0804e-04
Loss = 3.4248e-03, PNorm = 36.1800, GNorm = 1.7862, lr_0 = 1.0804e-04
Loss = 3.7088e-03, PNorm = 36.1842, GNorm = 4.7659, lr_0 = 1.0804e-04
Loss = 4.2877e-03, PNorm = 36.1891, GNorm = 2.1486, lr_0 = 1.0804e-04
Loss = 5.1924e-03, PNorm = 36.1947, GNorm = 4.0332, lr_0 = 1.0804e-04
Validation rmse logD = 0.749977
Validation R2 logD = 0.648613
Epoch 37
Train function
Loss = 5.0512e-03, PNorm = 36.1989, GNorm = 8.9452, lr_0 = 1.0804e-04
Loss = 4.0481e-03, PNorm = 36.2036, GNorm = 2.9482, lr_0 = 1.0804e-04
Loss = 3.7477e-03, PNorm = 36.2080, GNorm = 2.1285, lr_0 = 1.0804e-04
Loss = 4.3175e-03, PNorm = 36.2132, GNorm = 8.0818, lr_0 = 1.0804e-04
Loss = 3.4588e-03, PNorm = 36.2181, GNorm = 2.8829, lr_0 = 1.0804e-04
Loss = 3.7468e-03, PNorm = 36.2230, GNorm = 9.3724, lr_0 = 1.0804e-04
Validation rmse logD = 0.793376
Validation R2 logD = 0.606769
Epoch 38
Train function
Loss = 3.7835e-03, PNorm = 36.2288, GNorm = 3.9073, lr_0 = 1.0804e-04
Loss = 3.0227e-03, PNorm = 36.2338, GNorm = 6.1488, lr_0 = 1.0804e-04
Loss = 4.1122e-03, PNorm = 36.2382, GNorm = 5.4310, lr_0 = 1.0804e-04
Loss = 4.1181e-03, PNorm = 36.2423, GNorm = 6.0144, lr_0 = 1.0804e-04
Loss = 4.2139e-03, PNorm = 36.2480, GNorm = 1.9720, lr_0 = 1.0804e-04
Validation rmse logD = 0.771321
Validation R2 logD = 0.628328
Epoch 39
Train function
Loss = 5.2970e-03, PNorm = 36.2545, GNorm = 8.5560, lr_0 = 1.0804e-04
Loss = 3.3782e-03, PNorm = 36.2599, GNorm = 4.9357, lr_0 = 1.0804e-04
Loss = 3.7144e-03, PNorm = 36.2656, GNorm = 5.3319, lr_0 = 1.0804e-04
Loss = 3.5521e-03, PNorm = 36.2719, GNorm = 2.6500, lr_0 = 1.0804e-04
Loss = 4.3538e-03, PNorm = 36.2774, GNorm = 3.1092, lr_0 = 1.0804e-04
Loss = 4.2706e-03, PNorm = 36.2801, GNorm = 10.9389, lr_0 = 1.0804e-04
Validation rmse logD = 0.752307
Validation R2 logD = 0.646426
Epoch 40
Train function
Loss = 3.5432e-03, PNorm = 36.2824, GNorm = 1.6966, lr_0 = 1.0804e-04
Loss = 4.2121e-03, PNorm = 36.2869, GNorm = 6.0132, lr_0 = 1.0804e-04
Loss = 3.4895e-03, PNorm = 36.2911, GNorm = 4.5768, lr_0 = 1.0804e-04
Loss = 3.7523e-03, PNorm = 36.2964, GNorm = 1.6810, lr_0 = 1.0804e-04
Loss = 3.9967e-03, PNorm = 36.3010, GNorm = 8.2800, lr_0 = 1.0804e-04
Loss = 4.2547e-03, PNorm = 36.3052, GNorm = 6.3614, lr_0 = 1.0804e-04
Validation rmse logD = 0.761515
Validation R2 logD = 0.637718
Epoch 41
Train function
Loss = 3.5825e-03, PNorm = 36.3100, GNorm = 2.6048, lr_0 = 1.0804e-04
Loss = 3.7783e-03, PNorm = 36.3154, GNorm = 2.6599, lr_0 = 1.0804e-04
Loss = 3.6185e-03, PNorm = 36.3216, GNorm = 4.2863, lr_0 = 1.0804e-04
Loss = 3.3597e-03, PNorm = 36.3265, GNorm = 1.3725, lr_0 = 1.0804e-04
Loss = 3.5737e-03, PNorm = 36.3307, GNorm = 1.6776, lr_0 = 1.0804e-04
Validation rmse logD = 0.816113
Validation R2 logD = 0.583907
Epoch 42
Train function
Loss = 6.6625e-03, PNorm = 36.3352, GNorm = 14.3982, lr_0 = 1.0804e-04
Loss = 3.9074e-03, PNorm = 36.3386, GNorm = 5.6751, lr_0 = 1.0804e-04
Loss = 3.6971e-03, PNorm = 36.3424, GNorm = 1.9807, lr_0 = 1.0804e-04
Loss = 3.7058e-03, PNorm = 36.3475, GNorm = 1.6393, lr_0 = 1.0804e-04
Loss = 3.9388e-03, PNorm = 36.3531, GNorm = 4.0573, lr_0 = 1.0804e-04
Loss = 3.0289e-03, PNorm = 36.3589, GNorm = 3.7901, lr_0 = 1.0804e-04
Validation rmse logD = 0.773872
Validation R2 logD = 0.625865
Epoch 43
Train function
Loss = 3.6357e-03, PNorm = 36.3634, GNorm = 1.8437, lr_0 = 1.0804e-04
Loss = 3.4488e-03, PNorm = 36.3679, GNorm = 3.0394, lr_0 = 1.0804e-04
Loss = 3.7711e-03, PNorm = 36.3721, GNorm = 4.2652, lr_0 = 1.0804e-04
Loss = 3.6817e-03, PNorm = 36.3765, GNorm = 7.4829, lr_0 = 1.0804e-04
Loss = 3.5213e-03, PNorm = 36.3805, GNorm = 1.8280, lr_0 = 1.0804e-04
Loss = 3.6752e-03, PNorm = 36.3854, GNorm = 3.8262, lr_0 = 1.0804e-04
Validation rmse logD = 0.773932
Validation R2 logD = 0.625807
Epoch 44
Train function
Loss = 3.9319e-03, PNorm = 36.3906, GNorm = 3.7646, lr_0 = 1.0804e-04
Loss = 3.1868e-03, PNorm = 36.3945, GNorm = 2.6380, lr_0 = 1.0804e-04
Loss = 3.4474e-03, PNorm = 36.3995, GNorm = 5.1505, lr_0 = 1.0804e-04
Loss = 3.7839e-03, PNorm = 36.4044, GNorm = 1.6865, lr_0 = 1.0804e-04
Loss = 2.9048e-03, PNorm = 36.4091, GNorm = 4.8740, lr_0 = 1.0804e-04
Validation rmse logD = 0.753339
Validation R2 logD = 0.645455
Epoch 45
Train function
Loss = 2.6465e-03, PNorm = 36.4140, GNorm = 1.7376, lr_0 = 1.0804e-04
Loss = 3.2982e-03, PNorm = 36.4193, GNorm = 5.3709, lr_0 = 1.0804e-04
Loss = 3.2265e-03, PNorm = 36.4244, GNorm = 3.4294, lr_0 = 1.0804e-04
Loss = 3.0443e-03, PNorm = 36.4285, GNorm = 4.9068, lr_0 = 1.0804e-04
Loss = 3.4864e-03, PNorm = 36.4325, GNorm = 3.1280, lr_0 = 1.0804e-04
Loss = 3.2492e-03, PNorm = 36.4370, GNorm = 2.6184, lr_0 = 1.0804e-04
Validation rmse logD = 0.759906
Validation R2 logD = 0.639247
Epoch 46
Train function
Loss = 3.0874e-03, PNorm = 36.4422, GNorm = 2.5520, lr_0 = 1.0804e-04
Loss = 3.0833e-03, PNorm = 36.4463, GNorm = 3.0777, lr_0 = 1.0804e-04
Loss = 3.3616e-03, PNorm = 36.4507, GNorm = 4.5943, lr_0 = 1.0804e-04
Loss = 3.6516e-03, PNorm = 36.4544, GNorm = 3.4478, lr_0 = 1.0804e-04
Loss = 3.1147e-03, PNorm = 36.4581, GNorm = 8.9290, lr_0 = 1.0804e-04
Loss = 3.7248e-03, PNorm = 36.4634, GNorm = 4.8708, lr_0 = 1.0804e-04
Validation rmse logD = 0.777522
Validation R2 logD = 0.622327
Epoch 47
Train function
Loss = 3.3853e-03, PNorm = 36.4685, GNorm = 5.0701, lr_0 = 1.0804e-04
Loss = 3.9650e-03, PNorm = 36.4727, GNorm = 6.3368, lr_0 = 1.0804e-04
Loss = 3.1815e-03, PNorm = 36.4783, GNorm = 4.0928, lr_0 = 1.0804e-04
Loss = 3.7103e-03, PNorm = 36.4841, GNorm = 3.4934, lr_0 = 1.0804e-04
Loss = 3.0549e-03, PNorm = 36.4872, GNorm = 5.8374, lr_0 = 1.0804e-04
Validation rmse logD = 0.759773
Validation R2 logD = 0.639373
Epoch 48
Train function
Loss = 1.6654e-03, PNorm = 36.4911, GNorm = 1.7627, lr_0 = 1.0804e-04
Loss = 3.2368e-03, PNorm = 36.4966, GNorm = 3.0418, lr_0 = 1.0804e-04
Loss = 3.3547e-03, PNorm = 36.5009, GNorm = 1.8668, lr_0 = 1.0804e-04
Loss = 3.1382e-03, PNorm = 36.5063, GNorm = 1.0920, lr_0 = 1.0804e-04
Loss = 3.4715e-03, PNorm = 36.5116, GNorm = 11.2957, lr_0 = 1.0804e-04
Loss = 3.3094e-03, PNorm = 36.5148, GNorm = 5.8547, lr_0 = 1.0804e-04
Validation rmse logD = 0.836295
Validation R2 logD = 0.563073
Epoch 49
Train function
Loss = 4.4359e-03, PNorm = 36.5186, GNorm = 9.0015, lr_0 = 1.0804e-04
Loss = 3.9802e-03, PNorm = 36.5235, GNorm = 10.0251, lr_0 = 1.0804e-04
Loss = 3.6166e-03, PNorm = 36.5282, GNorm = 5.4456, lr_0 = 1.0804e-04
Loss = 3.3880e-03, PNorm = 36.5319, GNorm = 3.8943, lr_0 = 1.0804e-04
Loss = 3.5644e-03, PNorm = 36.5361, GNorm = 6.9192, lr_0 = 1.0804e-04
Loss = 3.0201e-03, PNorm = 36.5395, GNorm = 5.1262, lr_0 = 1.0804e-04
Validation rmse logD = 0.760232
Validation R2 logD = 0.638938
Epoch 50
Train function
Loss = 2.9464e-03, PNorm = 36.5432, GNorm = 3.2897, lr_0 = 1.0804e-04
Loss = 3.1172e-03, PNorm = 36.5480, GNorm = 5.9918, lr_0 = 1.0804e-04
Loss = 2.8707e-03, PNorm = 36.5523, GNorm = 5.3483, lr_0 = 1.0804e-04
Loss = 3.5097e-03, PNorm = 36.5575, GNorm = 5.8389, lr_0 = 1.0804e-04
Loss = 3.1256e-03, PNorm = 36.5633, GNorm = 2.9884, lr_0 = 1.0804e-04
Validation rmse logD = 0.760957
Validation R2 logD = 0.638248
Epoch 51
Train function
Loss = 2.5820e-03, PNorm = 36.5679, GNorm = 2.2459, lr_0 = 1.0804e-04
Loss = 2.6828e-03, PNorm = 36.5722, GNorm = 3.0083, lr_0 = 1.0804e-04
Loss = 3.0236e-03, PNorm = 36.5772, GNorm = 3.7022, lr_0 = 1.0804e-04
Loss = 2.8099e-03, PNorm = 36.5814, GNorm = 4.8563, lr_0 = 1.0804e-04
Loss = 2.7590e-03, PNorm = 36.5855, GNorm = 4.4869, lr_0 = 1.0804e-04
Loss = 3.1068e-03, PNorm = 36.5890, GNorm = 8.3491, lr_0 = 1.0804e-04
Validation rmse logD = 0.779360
Validation R2 logD = 0.620540
Epoch 52
Train function
Loss = 3.6048e-03, PNorm = 36.5939, GNorm = 6.7933, lr_0 = 1.0804e-04
Loss = 2.7126e-03, PNorm = 36.5985, GNorm = 3.5633, lr_0 = 1.0804e-04
Loss = 3.1568e-03, PNorm = 36.6019, GNorm = 2.3626, lr_0 = 1.0804e-04
Loss = 2.5879e-03, PNorm = 36.6060, GNorm = 3.4708, lr_0 = 1.0804e-04
Loss = 3.2098e-03, PNorm = 36.6112, GNorm = 6.4685, lr_0 = 1.0804e-04
Loss = 3.2714e-03, PNorm = 36.6150, GNorm = 9.3755, lr_0 = 1.0804e-04
Validation rmse logD = 0.777574
Validation R2 logD = 0.622277
Epoch 53
Train function
Loss = 2.7787e-03, PNorm = 36.6191, GNorm = 2.1508, lr_0 = 1.0804e-04
Loss = 2.8614e-03, PNorm = 36.6231, GNorm = 2.8748, lr_0 = 1.0804e-04
Loss = 2.7518e-03, PNorm = 36.6281, GNorm = 2.6421, lr_0 = 1.0804e-04
Loss = 2.9105e-03, PNorm = 36.6324, GNorm = 4.1989, lr_0 = 1.0804e-04
Loss = 3.0325e-03, PNorm = 36.6371, GNorm = 6.6943, lr_0 = 1.0804e-04
Validation rmse logD = 0.765066
Validation R2 logD = 0.634331
Epoch 54
Train function
Loss = 4.1680e-03, PNorm = 36.6417, GNorm = 3.6948, lr_0 = 1.0804e-04
Loss = 2.9310e-03, PNorm = 36.6457, GNorm = 4.0239, lr_0 = 1.0804e-04
Loss = 3.2189e-03, PNorm = 36.6499, GNorm = 1.6796, lr_0 = 1.0804e-04
Loss = 2.7540e-03, PNorm = 36.6541, GNorm = 6.4869, lr_0 = 1.0804e-04
Loss = 3.0812e-03, PNorm = 36.6592, GNorm = 7.9987, lr_0 = 1.0804e-04
Loss = 3.0079e-03, PNorm = 36.6630, GNorm = 2.3931, lr_0 = 1.0804e-04
Validation rmse logD = 0.764349
Validation R2 logD = 0.635016
Epoch 55
Train function
Loss = 3.2598e-03, PNorm = 36.6668, GNorm = 8.9515, lr_0 = 1.0804e-04
Loss = 2.4773e-03, PNorm = 36.6706, GNorm = 1.5555, lr_0 = 1.0804e-04
Loss = 2.7722e-03, PNorm = 36.6751, GNorm = 2.1700, lr_0 = 1.0804e-04
Loss = 2.8040e-03, PNorm = 36.6802, GNorm = 2.6879, lr_0 = 1.0804e-04
Loss = 3.1553e-03, PNorm = 36.6846, GNorm = 1.4348, lr_0 = 1.0804e-04
Loss = 2.9465e-03, PNorm = 36.6879, GNorm = 3.8830, lr_0 = 1.0804e-04
Validation rmse logD = 0.774701
Validation R2 logD = 0.625063
Epoch 56
Train function
Loss = 3.3384e-03, PNorm = 36.6923, GNorm = 2.7429, lr_0 = 1.0804e-04
Loss = 2.6620e-03, PNorm = 36.6969, GNorm = 1.7397, lr_0 = 1.0804e-04
Loss = 2.6653e-03, PNorm = 36.7008, GNorm = 2.8307, lr_0 = 1.0804e-04
Loss = 3.1690e-03, PNorm = 36.7047, GNorm = 11.3829, lr_0 = 1.0804e-04
Loss = 2.7743e-03, PNorm = 36.7085, GNorm = 3.5373, lr_0 = 1.0804e-04
Validation rmse logD = 0.784951
Validation R2 logD = 0.615076
Epoch 57
Train function
Loss = 2.2725e-03, PNorm = 36.7128, GNorm = 4.7317, lr_0 = 1.0804e-04
Loss = 3.1726e-03, PNorm = 36.7162, GNorm = 5.5873, lr_0 = 1.0804e-04
Loss = 2.6639e-03, PNorm = 36.7199, GNorm = 7.1217, lr_0 = 1.0804e-04
Loss = 2.7433e-03, PNorm = 36.7260, GNorm = 2.4182, lr_0 = 1.0804e-04
Loss = 2.6443e-03, PNorm = 36.7309, GNorm = 3.0207, lr_0 = 1.0804e-04
Loss = 3.7159e-03, PNorm = 36.7351, GNorm = 6.2508, lr_0 = 1.0804e-04
Validation rmse logD = 0.783701
Validation R2 logD = 0.616301
Epoch 58
Train function
Loss = 3.2683e-03, PNorm = 36.7383, GNorm = 7.0990, lr_0 = 1.0804e-04
Loss = 2.9776e-03, PNorm = 36.7416, GNorm = 7.7853, lr_0 = 1.0804e-04
Loss = 2.7082e-03, PNorm = 36.7459, GNorm = 4.5556, lr_0 = 1.0804e-04
Loss = 3.0162e-03, PNorm = 36.7506, GNorm = 2.2623, lr_0 = 1.0804e-04
Loss = 2.5103e-03, PNorm = 36.7539, GNorm = 3.5398, lr_0 = 1.0804e-04
Loss = 2.8328e-03, PNorm = 36.7586, GNorm = 6.0817, lr_0 = 1.0804e-04
Validation rmse logD = 0.777912
Validation R2 logD = 0.621948
Epoch 59
Train function
Loss = 2.3844e-03, PNorm = 36.7635, GNorm = 1.6078, lr_0 = 1.0804e-04
Loss = 2.6639e-03, PNorm = 36.7685, GNorm = 1.8296, lr_0 = 1.0804e-04
Loss = 2.9468e-03, PNorm = 36.7728, GNorm = 8.6611, lr_0 = 1.0804e-04
Loss = 2.9582e-03, PNorm = 36.7766, GNorm = 1.9805, lr_0 = 1.0804e-04
Loss = 2.6259e-03, PNorm = 36.7808, GNorm = 3.9673, lr_0 = 1.0804e-04
Validation rmse logD = 0.775570
Validation R2 logD = 0.624222
Epoch 60
Train function
Loss = 2.2922e-03, PNorm = 36.7853, GNorm = 2.9420, lr_0 = 1.0804e-04
Loss = 2.4313e-03, PNorm = 36.7884, GNorm = 1.4352, lr_0 = 1.0804e-04
Loss = 2.4975e-03, PNorm = 36.7924, GNorm = 1.9341, lr_0 = 1.0804e-04
Loss = 2.7466e-03, PNorm = 36.7961, GNorm = 1.6086, lr_0 = 1.0804e-04
Loss = 2.5709e-03, PNorm = 36.8006, GNorm = 3.0158, lr_0 = 1.0804e-04
Loss = 2.6901e-03, PNorm = 36.8056, GNorm = 1.8012, lr_0 = 1.0804e-04
Validation rmse logD = 0.781309
Validation R2 logD = 0.618640
Epoch 61
Train function
Loss = 2.4662e-03, PNorm = 36.8102, GNorm = 4.4074, lr_0 = 1.0804e-04
Loss = 2.5165e-03, PNorm = 36.8139, GNorm = 9.5481, lr_0 = 1.0804e-04
Loss = 2.4621e-03, PNorm = 36.8186, GNorm = 1.5669, lr_0 = 1.0804e-04
Loss = 2.6160e-03, PNorm = 36.8223, GNorm = 4.2027, lr_0 = 1.0804e-04
Loss = 2.3997e-03, PNorm = 36.8265, GNorm = 7.0426, lr_0 = 1.0804e-04
Loss = 3.2240e-03, PNorm = 36.8305, GNorm = 6.2015, lr_0 = 1.0804e-04
Validation rmse logD = 0.793666
Validation R2 logD = 0.606482
Epoch 62
Train function
Loss = 2.9635e-03, PNorm = 36.8354, GNorm = 5.7454, lr_0 = 1.0804e-04
Loss = 2.6668e-03, PNorm = 36.8392, GNorm = 1.0512, lr_0 = 1.0804e-04
Loss = 2.4183e-03, PNorm = 36.8435, GNorm = 3.6218, lr_0 = 1.0804e-04
Loss = 2.6484e-03, PNorm = 36.8473, GNorm = 3.8500, lr_0 = 1.0804e-04
Loss = 2.5921e-03, PNorm = 36.8518, GNorm = 4.6099, lr_0 = 1.0804e-04
Validation rmse logD = 0.777781
Validation R2 logD = 0.622076
Epoch 63
Train function
Loss = 1.5844e-03, PNorm = 36.8553, GNorm = 1.9343, lr_0 = 1.0804e-04
Loss = 2.5930e-03, PNorm = 36.8591, GNorm = 3.5567, lr_0 = 1.0804e-04
Loss = 2.5078e-03, PNorm = 36.8640, GNorm = 1.5244, lr_0 = 1.0804e-04
Loss = 2.6878e-03, PNorm = 36.8677, GNorm = 5.1686, lr_0 = 1.0804e-04
Loss = 2.8230e-03, PNorm = 36.8703, GNorm = 4.0947, lr_0 = 1.0804e-04
Loss = 2.9049e-03, PNorm = 36.8743, GNorm = 6.9674, lr_0 = 1.0804e-04
Validation rmse logD = 0.789789
Validation R2 logD = 0.610316
Epoch 64
Train function
Loss = 2.3520e-03, PNorm = 36.8785, GNorm = 2.2365, lr_0 = 1.0804e-04
Loss = 2.4222e-03, PNorm = 36.8825, GNorm = 6.2304, lr_0 = 1.0804e-04
Loss = 2.4540e-03, PNorm = 36.8865, GNorm = 2.2287, lr_0 = 1.0804e-04
Loss = 2.7188e-03, PNorm = 36.8897, GNorm = 1.2712, lr_0 = 1.0804e-04
Loss = 2.2279e-03, PNorm = 36.8935, GNorm = 1.5292, lr_0 = 1.0804e-04
Loss = 2.5405e-03, PNorm = 36.8991, GNorm = 1.6042, lr_0 = 1.0804e-04
Validation rmse logD = 0.779359
Validation R2 logD = 0.620541
Epoch 65
Train function
Loss = 1.9929e-03, PNorm = 36.9052, GNorm = 2.2055, lr_0 = 1.0804e-04
Loss = 2.2966e-03, PNorm = 36.9100, GNorm = 1.9801, lr_0 = 1.0804e-04
Loss = 2.5248e-03, PNorm = 36.9146, GNorm = 1.9618, lr_0 = 1.0804e-04
Loss = 2.3374e-03, PNorm = 36.9183, GNorm = 7.3723, lr_0 = 1.0804e-04
Loss = 2.3054e-03, PNorm = 36.9230, GNorm = 3.2761, lr_0 = 1.0804e-04
Validation rmse logD = 0.798860
Validation R2 logD = 0.601313
Epoch 66
Train function
Loss = 2.5987e-03, PNorm = 36.9270, GNorm = 6.1013, lr_0 = 1.0804e-04
Loss = 2.6738e-03, PNorm = 36.9314, GNorm = 2.7649, lr_0 = 1.0804e-04
Loss = 2.4570e-03, PNorm = 36.9362, GNorm = 6.9316, lr_0 = 1.0804e-04
Loss = 2.1860e-03, PNorm = 36.9400, GNorm = 2.3645, lr_0 = 1.0804e-04
Loss = 2.4107e-03, PNorm = 36.9436, GNorm = 3.2321, lr_0 = 1.0804e-04
Loss = 2.6333e-03, PNorm = 36.9474, GNorm = 2.3843, lr_0 = 1.0804e-04
Validation rmse logD = 0.784251
Validation R2 logD = 0.615762
Epoch 67
Train function
Loss = 2.0973e-03, PNorm = 36.9514, GNorm = 1.8366, lr_0 = 1.0804e-04
Loss = 2.2191e-03, PNorm = 36.9558, GNorm = 1.8067, lr_0 = 1.0804e-04
Loss = 2.2329e-03, PNorm = 36.9595, GNorm = 5.0053, lr_0 = 1.0804e-04
Loss = 2.5018e-03, PNorm = 36.9630, GNorm = 3.3721, lr_0 = 1.0804e-04
Loss = 2.4450e-03, PNorm = 36.9672, GNorm = 9.7241, lr_0 = 1.0804e-04
Loss = 2.4760e-03, PNorm = 36.9722, GNorm = 3.8076, lr_0 = 1.0804e-04
Validation rmse logD = 0.780627
Validation R2 logD = 0.619305
Epoch 68
Train function
Loss = 2.1111e-03, PNorm = 36.9771, GNorm = 2.9094, lr_0 = 1.0804e-04
Loss = 2.2622e-03, PNorm = 36.9814, GNorm = 4.2897, lr_0 = 1.0804e-04
Loss = 2.1114e-03, PNorm = 36.9867, GNorm = 0.9254, lr_0 = 1.0804e-04
Loss = 2.3506e-03, PNorm = 36.9914, GNorm = 1.6156, lr_0 = 1.0804e-04
Loss = 2.4949e-03, PNorm = 36.9955, GNorm = 5.9934, lr_0 = 1.0804e-04
Validation rmse logD = 0.779931
Validation R2 logD = 0.619984
Epoch 69
Train function
Loss = 2.1394e-03, PNorm = 36.9979, GNorm = 1.6764, lr_0 = 1.0804e-04
Loss = 2.3269e-03, PNorm = 37.0015, GNorm = 3.6690, lr_0 = 1.0804e-04
Loss = 2.4069e-03, PNorm = 37.0055, GNorm = 3.1145, lr_0 = 1.0804e-04
Loss = 2.5057e-03, PNorm = 37.0101, GNorm = 5.2775, lr_0 = 1.0804e-04
Loss = 2.1206e-03, PNorm = 37.0144, GNorm = 1.7882, lr_0 = 1.0804e-04
Loss = 2.1066e-03, PNorm = 37.0178, GNorm = 5.1297, lr_0 = 1.0804e-04
Validation rmse logD = 0.790619
Validation R2 logD = 0.609497
Epoch 70
Train function
Loss = 1.7486e-03, PNorm = 37.0226, GNorm = 1.6917, lr_0 = 1.0804e-04
Loss = 2.2615e-03, PNorm = 37.0270, GNorm = 4.8385, lr_0 = 1.0804e-04
Loss = 2.2398e-03, PNorm = 37.0317, GNorm = 2.6308, lr_0 = 1.0804e-04
Loss = 2.4860e-03, PNorm = 37.0359, GNorm = 1.6768, lr_0 = 1.0804e-04
Loss = 2.3263e-03, PNorm = 37.0397, GNorm = 5.3121, lr_0 = 1.0804e-04
Loss = 2.2042e-03, PNorm = 37.0443, GNorm = 1.6923, lr_0 = 1.0804e-04
Validation rmse logD = 0.821636
Validation R2 logD = 0.578256
Epoch 71
Train function
Loss = 2.6072e-03, PNorm = 37.0483, GNorm = 2.9437, lr_0 = 1.0804e-04
Loss = 2.5458e-03, PNorm = 37.0519, GNorm = 5.6599, lr_0 = 1.0804e-04
Loss = 2.4464e-03, PNorm = 37.0555, GNorm = 2.8820, lr_0 = 1.0804e-04
Loss = 2.4163e-03, PNorm = 37.0592, GNorm = 1.7394, lr_0 = 1.0804e-04
Loss = 2.0390e-03, PNorm = 37.0639, GNorm = 2.9285, lr_0 = 1.0804e-04
Validation rmse logD = 0.793548
Validation R2 logD = 0.606598
Epoch 72
Train function
Loss = 2.1327e-03, PNorm = 37.0679, GNorm = 1.4095, lr_0 = 1.0804e-04
Loss = 2.0465e-03, PNorm = 37.0727, GNorm = 2.4910, lr_0 = 1.0804e-04
Loss = 2.0256e-03, PNorm = 37.0773, GNorm = 2.1125, lr_0 = 1.0804e-04
Loss = 2.2933e-03, PNorm = 37.0801, GNorm = 2.9527, lr_0 = 1.0804e-04
Loss = 2.6306e-03, PNorm = 37.0840, GNorm = 7.0984, lr_0 = 1.0804e-04
Loss = 2.2158e-03, PNorm = 37.0880, GNorm = 1.8233, lr_0 = 1.0804e-04
Validation rmse logD = 0.795077
Validation R2 logD = 0.605080
Epoch 73
Train function
Loss = 1.9730e-03, PNorm = 37.0917, GNorm = 1.9370, lr_0 = 1.0804e-04
Loss = 2.1092e-03, PNorm = 37.0950, GNorm = 2.1908, lr_0 = 1.0804e-04
Loss = 2.3897e-03, PNorm = 37.0980, GNorm = 2.7223, lr_0 = 1.0804e-04
Loss = 2.0398e-03, PNorm = 37.1015, GNorm = 6.2754, lr_0 = 1.0804e-04
Loss = 2.2816e-03, PNorm = 37.1060, GNorm = 6.0761, lr_0 = 1.0804e-04
Loss = 2.3661e-03, PNorm = 37.1111, GNorm = 3.9381, lr_0 = 1.0804e-04
Validation rmse logD = 0.785301
Validation R2 logD = 0.614733
Epoch 74
Train function
Loss = 2.0551e-03, PNorm = 37.1159, GNorm = 4.6201, lr_0 = 1.0804e-04
Loss = 1.9689e-03, PNorm = 37.1187, GNorm = 3.0697, lr_0 = 1.0804e-04
Loss = 2.2941e-03, PNorm = 37.1217, GNorm = 2.2313, lr_0 = 1.0804e-04
Loss = 2.4306e-03, PNorm = 37.1262, GNorm = 4.1253, lr_0 = 1.0804e-04
Loss = 2.2623e-03, PNorm = 37.1307, GNorm = 1.7802, lr_0 = 1.0804e-04
Validation rmse logD = 0.796222
Validation R2 logD = 0.603942
Epoch 75
Train function
Loss = 1.9684e-03, PNorm = 37.1353, GNorm = 2.6461, lr_0 = 1.0804e-04
Loss = 1.9895e-03, PNorm = 37.1393, GNorm = 4.2645, lr_0 = 1.0804e-04
Loss = 1.8962e-03, PNorm = 37.1445, GNorm = 3.0456, lr_0 = 1.0804e-04
Loss = 2.4081e-03, PNorm = 37.1486, GNorm = 3.5834, lr_0 = 1.0804e-04
Loss = 2.0654e-03, PNorm = 37.1522, GNorm = 3.9307, lr_0 = 1.0804e-04
Loss = 2.0942e-03, PNorm = 37.1556, GNorm = 6.4149, lr_0 = 1.0804e-04
Validation rmse logD = 0.795021
Validation R2 logD = 0.605136
Epoch 76
Train function
Loss = 2.0654e-03, PNorm = 37.1596, GNorm = 4.4191, lr_0 = 1.0804e-04
Loss = 2.0501e-03, PNorm = 37.1644, GNorm = 1.6290, lr_0 = 1.0804e-04
Loss = 2.0518e-03, PNorm = 37.1685, GNorm = 10.5604, lr_0 = 1.0804e-04
Loss = 2.2443e-03, PNorm = 37.1712, GNorm = 2.1843, lr_0 = 1.0804e-04
Loss = 1.9821e-03, PNorm = 37.1757, GNorm = 4.9050, lr_0 = 1.0804e-04
Loss = 2.0395e-03, PNorm = 37.1799, GNorm = 7.0089, lr_0 = 1.0804e-04
Validation rmse logD = 0.802253
Validation R2 logD = 0.597920
Epoch 77
Train function
Loss = 1.9351e-03, PNorm = 37.1843, GNorm = 1.7468, lr_0 = 1.0804e-04
Loss = 2.1796e-03, PNorm = 37.1890, GNorm = 7.7785, lr_0 = 1.0804e-04
Loss = 2.6485e-03, PNorm = 37.1926, GNorm = 2.1190, lr_0 = 1.0804e-04
Loss = 1.8121e-03, PNorm = 37.1972, GNorm = 2.2453, lr_0 = 1.0804e-04
Loss = 1.9669e-03, PNorm = 37.2009, GNorm = 2.4406, lr_0 = 1.0804e-04
Validation rmse logD = 0.812993
Validation R2 logD = 0.587082
Epoch 78
Train function
Loss = 2.1849e-03, PNorm = 37.2048, GNorm = 8.6793, lr_0 = 1.0804e-04
Loss = 2.1611e-03, PNorm = 37.2088, GNorm = 4.8450, lr_0 = 1.0804e-04
Loss = 1.7186e-03, PNorm = 37.2126, GNorm = 1.7974, lr_0 = 1.0804e-04
Loss = 2.0252e-03, PNorm = 37.2174, GNorm = 4.4848, lr_0 = 1.0804e-04
Loss = 2.0882e-03, PNorm = 37.2203, GNorm = 2.3048, lr_0 = 1.0804e-04
Loss = 2.2316e-03, PNorm = 37.2238, GNorm = 2.9283, lr_0 = 1.0804e-04
Validation rmse logD = 0.793948
Validation R2 logD = 0.606202
Epoch 79
Train function
Loss = 1.8828e-03, PNorm = 37.2278, GNorm = 2.1260, lr_0 = 1.0804e-04
Loss = 1.8085e-03, PNorm = 37.2321, GNorm = 2.7019, lr_0 = 1.0804e-04
Loss = 1.8798e-03, PNorm = 37.2364, GNorm = 1.4430, lr_0 = 1.0804e-04
Loss = 2.3572e-03, PNorm = 37.2404, GNorm = 4.9243, lr_0 = 1.0804e-04
Loss = 2.3498e-03, PNorm = 37.2423, GNorm = 8.2081, lr_0 = 1.0804e-04
Loss = 1.9981e-03, PNorm = 37.2459, GNorm = 2.9592, lr_0 = 1.0804e-04
Validation rmse logD = 0.790626
Validation R2 logD = 0.609490
Epoch 80
Train function
Loss = 1.8191e-03, PNorm = 37.2514, GNorm = 2.3755, lr_0 = 1.0804e-04
Loss = 1.7907e-03, PNorm = 37.2552, GNorm = 1.9268, lr_0 = 1.0804e-04
Loss = 1.7949e-03, PNorm = 37.2590, GNorm = 2.8138, lr_0 = 1.0804e-04
Loss = 2.1295e-03, PNorm = 37.2630, GNorm = 1.5661, lr_0 = 1.0804e-04
Loss = 1.8480e-03, PNorm = 37.2665, GNorm = 1.5532, lr_0 = 1.0804e-04
Validation rmse logD = 0.804172
Validation R2 logD = 0.595994
Epoch 81
Train function
Loss = 2.1880e-03, PNorm = 37.2700, GNorm = 5.9185, lr_0 = 1.0804e-04
Loss = 1.8778e-03, PNorm = 37.2733, GNorm = 5.4915, lr_0 = 1.0804e-04
Loss = 1.8243e-03, PNorm = 37.2779, GNorm = 2.6792, lr_0 = 1.0804e-04
Loss = 1.9414e-03, PNorm = 37.2817, GNorm = 2.7741, lr_0 = 1.0804e-04
Loss = 2.0552e-03, PNorm = 37.2857, GNorm = 2.2793, lr_0 = 1.0804e-04
Loss = 2.0833e-03, PNorm = 37.2886, GNorm = 2.7697, lr_0 = 1.0804e-04
Validation rmse logD = 0.792420
Validation R2 logD = 0.607715
Epoch 82
Train function
Loss = 1.1521e-03, PNorm = 37.2929, GNorm = 2.2840, lr_0 = 1.0804e-04
Loss = 1.8075e-03, PNorm = 37.2971, GNorm = 6.9781, lr_0 = 1.0804e-04
Loss = 2.1089e-03, PNorm = 37.3014, GNorm = 1.7219, lr_0 = 1.0804e-04
Loss = 1.8486e-03, PNorm = 37.3058, GNorm = 3.5638, lr_0 = 1.0804e-04
Loss = 2.0520e-03, PNorm = 37.3098, GNorm = 1.8224, lr_0 = 1.0804e-04
Loss = 1.7116e-03, PNorm = 37.3129, GNorm = 6.0703, lr_0 = 1.0804e-04
Validation rmse logD = 0.798082
Validation R2 logD = 0.602090
Epoch 83
Train function
Loss = 1.7269e-03, PNorm = 37.3174, GNorm = 1.9208, lr_0 = 1.0804e-04
Loss = 1.7385e-03, PNorm = 37.3214, GNorm = 2.0086, lr_0 = 1.0804e-04
Loss = 1.8479e-03, PNorm = 37.3253, GNorm = 1.9695, lr_0 = 1.0804e-04
Loss = 2.0951e-03, PNorm = 37.3290, GNorm = 2.2096, lr_0 = 1.0804e-04
Loss = 2.5592e-03, PNorm = 37.3331, GNorm = 2.3601, lr_0 = 1.0804e-04
Validation rmse logD = 0.852198
Validation R2 logD = 0.546297
Epoch 84
Train function
Loss = 2.5484e-03, PNorm = 37.3364, GNorm = 6.7082, lr_0 = 1.0804e-04
Loss = 1.8261e-03, PNorm = 37.3404, GNorm = 2.2396, lr_0 = 1.0804e-04
Loss = 1.9331e-03, PNorm = 37.3447, GNorm = 7.9645, lr_0 = 1.0804e-04
Loss = 1.5638e-03, PNorm = 37.3483, GNorm = 1.3076, lr_0 = 1.0804e-04
Loss = 1.8117e-03, PNorm = 37.3522, GNorm = 1.5429, lr_0 = 1.0804e-04
Loss = 2.0735e-03, PNorm = 37.3565, GNorm = 3.2347, lr_0 = 1.0804e-04
Validation rmse logD = 0.804559
Validation R2 logD = 0.595605
Epoch 85
Train function
Loss = 1.8839e-03, PNorm = 37.3607, GNorm = 7.4297, lr_0 = 1.0804e-04
Loss = 1.9337e-03, PNorm = 37.3638, GNorm = 4.2976, lr_0 = 1.0804e-04
Loss = 1.7750e-03, PNorm = 37.3669, GNorm = 2.3020, lr_0 = 1.0804e-04
Loss = 1.8907e-03, PNorm = 37.3709, GNorm = 2.7168, lr_0 = 1.0804e-04
Loss = 2.2342e-03, PNorm = 37.3738, GNorm = 3.6315, lr_0 = 1.0804e-04
Loss = 1.7834e-03, PNorm = 37.3779, GNorm = 3.0161, lr_0 = 1.0804e-04
Validation rmse logD = 0.792226
Validation R2 logD = 0.607908
Epoch 86
Train function
Loss = 1.7571e-03, PNorm = 37.3826, GNorm = 1.6193, lr_0 = 1.0804e-04
Loss = 1.7405e-03, PNorm = 37.3859, GNorm = 2.9286, lr_0 = 1.0804e-04
Loss = 2.0521e-03, PNorm = 37.3890, GNorm = 8.3955, lr_0 = 1.0804e-04
Loss = 1.8742e-03, PNorm = 37.3935, GNorm = 10.6393, lr_0 = 1.0804e-04
Loss = 1.7608e-03, PNorm = 37.3972, GNorm = 3.9918, lr_0 = 1.0804e-04
Validation rmse logD = 0.795715
Validation R2 logD = 0.604447
Epoch 87
Train function
Loss = 1.5405e-03, PNorm = 37.4013, GNorm = 2.6837, lr_0 = 1.0804e-04
Loss = 2.0328e-03, PNorm = 37.4051, GNorm = 1.6264, lr_0 = 1.0804e-04
Loss = 1.5976e-03, PNorm = 37.4095, GNorm = 5.9859, lr_0 = 1.0804e-04
Loss = 1.6696e-03, PNorm = 37.4140, GNorm = 1.6398, lr_0 = 1.0804e-04
Loss = 1.7815e-03, PNorm = 37.4149, GNorm = 1.3037, lr_0 = 1.0804e-04
Loss = 1.9079e-03, PNorm = 37.4183, GNorm = 7.2657, lr_0 = 1.0804e-04
Validation rmse logD = 0.810527
Validation R2 logD = 0.589583
Epoch 88
Train function
Loss = 1.5417e-03, PNorm = 37.4232, GNorm = 3.1074, lr_0 = 1.0804e-04
Loss = 1.7421e-03, PNorm = 37.4277, GNorm = 4.2442, lr_0 = 1.0804e-04
Loss = 1.8449e-03, PNorm = 37.4308, GNorm = 8.0508, lr_0 = 1.0804e-04
Loss = 2.1001e-03, PNorm = 37.4343, GNorm = 4.8618, lr_0 = 1.0804e-04
Loss = 1.4575e-03, PNorm = 37.4380, GNorm = 1.7519, lr_0 = 1.0804e-04
Loss = 1.7350e-03, PNorm = 37.4409, GNorm = 2.1717, lr_0 = 1.0804e-04
Validation rmse logD = 0.808542
Validation R2 logD = 0.591591
Epoch 89
Train function
Loss = 1.6610e-03, PNorm = 37.4443, GNorm = 4.3748, lr_0 = 1.0804e-04
Loss = 1.7832e-03, PNorm = 37.4488, GNorm = 2.1645, lr_0 = 1.0804e-04
Loss = 1.7179e-03, PNorm = 37.4531, GNorm = 1.6401, lr_0 = 1.0804e-04
Loss = 1.5714e-03, PNorm = 37.4578, GNorm = 3.6094, lr_0 = 1.0804e-04
Loss = 1.8035e-03, PNorm = 37.4614, GNorm = 2.9070, lr_0 = 1.0804e-04
Validation rmse logD = 0.815315
Validation R2 logD = 0.584720
Epoch 90
Train function
Loss = 1.0479e-03, PNorm = 37.4638, GNorm = 4.3028, lr_0 = 1.0804e-04
Loss = 1.5081e-03, PNorm = 37.4669, GNorm = 1.1695, lr_0 = 1.0804e-04
Loss = 1.6781e-03, PNorm = 37.4705, GNorm = 6.2696, lr_0 = 1.0804e-04
Loss = 1.6327e-03, PNorm = 37.4743, GNorm = 3.5523, lr_0 = 1.0804e-04
Loss = 1.7247e-03, PNorm = 37.4779, GNorm = 2.8385, lr_0 = 1.0804e-04
Loss = 1.9515e-03, PNorm = 37.4813, GNorm = 3.6501, lr_0 = 1.0804e-04
Validation rmse logD = 0.799900
Validation R2 logD = 0.600275
Epoch 91
Train function
Loss = 1.4198e-03, PNorm = 37.4853, GNorm = 4.8596, lr_0 = 1.0804e-04
Loss = 1.5178e-03, PNorm = 37.4889, GNorm = 2.7635, lr_0 = 1.0804e-04
Loss = 1.8349e-03, PNorm = 37.4922, GNorm = 1.3281, lr_0 = 1.0804e-04
Loss = 1.6938e-03, PNorm = 37.4953, GNorm = 5.8420, lr_0 = 1.0804e-04
Loss = 1.9621e-03, PNorm = 37.4991, GNorm = 7.1730, lr_0 = 1.0804e-04
Loss = 1.9601e-03, PNorm = 37.5035, GNorm = 3.3268, lr_0 = 1.0804e-04
Validation rmse logD = 0.808227
Validation R2 logD = 0.591909
Epoch 92
Train function
Loss = 1.5423e-03, PNorm = 37.5079, GNorm = 2.2866, lr_0 = 1.0804e-04
Loss = 1.5258e-03, PNorm = 37.5119, GNorm = 1.8078, lr_0 = 1.0804e-04
Loss = 1.3562e-03, PNorm = 37.5154, GNorm = 1.3365, lr_0 = 1.0804e-04
Loss = 1.7280e-03, PNorm = 37.5195, GNorm = 1.3987, lr_0 = 1.0804e-04
Loss = 1.7559e-03, PNorm = 37.5233, GNorm = 6.3690, lr_0 = 1.0804e-04
Validation rmse logD = 0.810282
Validation R2 logD = 0.589831
Epoch 93
Train function
Loss = 1.5098e-03, PNorm = 37.5263, GNorm = 3.4036, lr_0 = 1.0804e-04
Loss = 2.1949e-03, PNorm = 37.5290, GNorm = 3.6295, lr_0 = 1.0804e-04
Loss = 2.2586e-03, PNorm = 37.5328, GNorm = 2.5771, lr_0 = 1.0804e-04
Loss = 2.1786e-03, PNorm = 37.5350, GNorm = 6.7694, lr_0 = 1.0804e-04
Loss = 2.1040e-03, PNorm = 37.5388, GNorm = 1.4344, lr_0 = 1.0804e-04
Loss = 1.5620e-03, PNorm = 37.5421, GNorm = 2.4704, lr_0 = 1.0804e-04
Validation rmse logD = 0.800448
Validation R2 logD = 0.599727
Epoch 94
Train function
Loss = 1.6531e-03, PNorm = 37.5465, GNorm = 2.1341, lr_0 = 1.0804e-04
Loss = 1.6640e-03, PNorm = 37.5506, GNorm = 1.6607, lr_0 = 1.0804e-04
Loss = 1.4867e-03, PNorm = 37.5541, GNorm = 4.9224, lr_0 = 1.0804e-04
Loss = 1.7891e-03, PNorm = 37.5571, GNorm = 11.8269, lr_0 = 1.0804e-04
Loss = 1.4073e-03, PNorm = 37.5602, GNorm = 2.3464, lr_0 = 1.0804e-04
Loss = 1.7537e-03, PNorm = 37.5635, GNorm = 2.7613, lr_0 = 1.0804e-04
Validation rmse logD = 0.818510
Validation R2 logD = 0.581459
Epoch 95
Train function
Loss = 1.7030e-03, PNorm = 37.5687, GNorm = 7.1193, lr_0 = 1.0804e-04
Loss = 1.4301e-03, PNorm = 37.5722, GNorm = 2.0558, lr_0 = 1.0804e-04
Loss = 1.6014e-03, PNorm = 37.5760, GNorm = 4.5349, lr_0 = 1.0804e-04
Loss = 1.7201e-03, PNorm = 37.5791, GNorm = 8.4300, lr_0 = 1.0804e-04
Loss = 1.8223e-03, PNorm = 37.5823, GNorm = 2.6580, lr_0 = 1.0804e-04
Validation rmse logD = 0.809822
Validation R2 logD = 0.590297
Epoch 96
Train function
Loss = 1.6730e-03, PNorm = 37.5861, GNorm = 4.1170, lr_0 = 1.0804e-04
Loss = 1.4534e-03, PNorm = 37.5899, GNorm = 7.4745, lr_0 = 1.0804e-04
Loss = 1.5122e-03, PNorm = 37.5938, GNorm = 6.7643, lr_0 = 1.0804e-04
Loss = 1.7180e-03, PNorm = 37.5979, GNorm = 4.0317, lr_0 = 1.0804e-04
Loss = 1.7458e-03, PNorm = 37.6011, GNorm = 9.0519, lr_0 = 1.0804e-04
Loss = 1.8827e-03, PNorm = 37.6036, GNorm = 3.3595, lr_0 = 1.0804e-04
Validation rmse logD = 0.822645
Validation R2 logD = 0.577220
Epoch 97
Train function
Loss = 2.3849e-03, PNorm = 37.6067, GNorm = 4.8576, lr_0 = 1.0804e-04
Loss = 1.5853e-03, PNorm = 37.6087, GNorm = 2.1774, lr_0 = 1.0804e-04
Loss = 1.5857e-03, PNorm = 37.6126, GNorm = 1.2626, lr_0 = 1.0804e-04
Loss = 1.6028e-03, PNorm = 37.6173, GNorm = 2.6073, lr_0 = 1.0804e-04
Loss = 1.5759e-03, PNorm = 37.6205, GNorm = 3.2223, lr_0 = 1.0804e-04
Loss = 1.4054e-03, PNorm = 37.6240, GNorm = 3.0782, lr_0 = 1.0804e-04
Validation rmse logD = 0.802435
Validation R2 logD = 0.597737
Epoch 98
Train function
Loss = 1.3315e-03, PNorm = 37.6294, GNorm = 5.7688, lr_0 = 1.0804e-04
Loss = 1.5120e-03, PNorm = 37.6336, GNorm = 2.0508, lr_0 = 1.0804e-04
Loss = 1.3395e-03, PNorm = 37.6377, GNorm = 1.3888, lr_0 = 1.0804e-04
Loss = 1.4983e-03, PNorm = 37.6403, GNorm = 1.8453, lr_0 = 1.0804e-04
Loss = 1.7981e-03, PNorm = 37.6432, GNorm = 4.9574, lr_0 = 1.0804e-04
Validation rmse logD = 0.806907
Validation R2 logD = 0.593241
Epoch 99
Train function
Loss = 1.1757e-03, PNorm = 37.6460, GNorm = 3.8657, lr_0 = 1.0804e-04
Loss = 1.4162e-03, PNorm = 37.6491, GNorm = 2.0108, lr_0 = 1.0804e-04
Loss = 1.3349e-03, PNorm = 37.6525, GNorm = 2.0818, lr_0 = 1.0804e-04
Loss = 1.2904e-03, PNorm = 37.6564, GNorm = 3.6505, lr_0 = 1.0804e-04
Loss = 1.6162e-03, PNorm = 37.6590, GNorm = 1.3985, lr_0 = 1.0804e-04
Loss = 1.6057e-03, PNorm = 37.6617, GNorm = 1.3030, lr_0 = 1.0804e-04
Validation rmse logD = 0.811753
Validation R2 logD = 0.588340
Model 0 best validation rmse = 0.747438 on epoch 32
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.659052
Model 0 test R2 logD = 0.696339
Ensemble test rmse  logD= 0.659052
Ensemble test R2  logD= 0.696339
5-fold cross validation
	Seed 0 ==> test rmse = 0.615328
	Seed 0 ==> test R2 = 0.765592
	Seed 1 ==> test rmse = 0.567807
	Seed 1 ==> test R2 = 0.747130
	Seed 2 ==> test rmse = 0.585928
	Seed 2 ==> test R2 = 0.766258
	Seed 3 ==> test rmse = 0.572041
	Seed 3 ==> test R2 = 0.766427
	Seed 4 ==> test rmse = 0.659052
	Seed 4 ==> test R2 = 0.696339
Overall val rmse logD= 0.624526 +/- 0.063681
Overall val R2 logD = 0.744055 +/- 0.048921
Overall test rmse logD = 0.600031 +/- 0.033877
Overall test R2 logD = 0.748349 +/- 0.027023
Elapsed time = 6:31:40
