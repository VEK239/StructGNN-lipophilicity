Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['smiles', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type random --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'random',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 9,368 | val size = 2,342 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'random',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 9,368 | val size = 2,342 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Test loaded
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Test loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7f0e65dca0d0>
Train loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7f0e660c7dc0>
Val loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7f0e6c115c40>
Test loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7f0e65dca0d0>
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Test loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7ff1de3440d0>
Train loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7ff1de642dc0>
Val loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7ff1de98c610>
Test loaded
<chemprop.data.data.MoleculeDataset object at 0x7ff1de467bb0>
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Test loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7fb210bfc0d0>
Train loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7fb210efadc0>
Val loaded
<chemprop.data.data.MoleculeDatapoint object at 0x7fb21124c310>
Test loaded
<chemprop.data.data.MoleculeDataset object at 0x7fb21124c580>
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Test loader
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Test loader
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Test loader
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Test loader
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type random --num_folds 4
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'random',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 9,368 | val size = 2,342 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4 --num_workers 1
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 1,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Loss = 4.6207e-02, PNorm = 34.0113, GNorm = 9.4283, lr_0 = 1.2829e-04
Loss = 3.8535e-02, PNorm = 34.0129, GNorm = 3.5275, lr_0 = 1.5400e-04
Loss = 3.8940e-02, PNorm = 34.0163, GNorm = 2.9754, lr_0 = 1.7971e-04
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 5.6290e-02, PNorm = 35.0071, GNorm = 15.8876, lr_0 = 1.2829e-04
Loss = 4.1329e-02, PNorm = 35.0062, GNorm = 3.6577, lr_0 = 1.5400e-04
Loss = 3.8880e-02, PNorm = 35.0076, GNorm = 4.4986, lr_0 = 1.7971e-04
Loss = 4.2089e-02, PNorm = 35.0117, GNorm = 14.3109, lr_0 = 2.0543e-04
Loss = 4.1876e-02, PNorm = 35.0174, GNorm = 9.8099, lr_0 = 2.3114e-04
Loss = 2.7737e-02, PNorm = 35.0252, GNorm = 4.6164, lr_0 = 2.5686e-04
Loss = 3.3594e-02, PNorm = 35.0333, GNorm = 4.2468, lr_0 = 2.8257e-04
Loss = 3.7228e-02, PNorm = 35.0422, GNorm = 12.3929, lr_0 = 3.0829e-04
Loss = 2.7655e-02, PNorm = 35.0500, GNorm = 5.2439, lr_0 = 3.3400e-04
Loss = 3.2002e-02, PNorm = 35.0562, GNorm = 9.4360, lr_0 = 3.5971e-04
Loss = 2.9482e-02, PNorm = 35.0657, GNorm = 6.6276, lr_0 = 3.8543e-04
Loss = 2.6144e-02, PNorm = 35.0766, GNorm = 2.9398, lr_0 = 4.1114e-04
Loss = 2.3923e-02, PNorm = 35.0883, GNorm = 4.1305, lr_0 = 4.3686e-04
Loss = 2.6467e-02, PNorm = 35.1014, GNorm = 5.8620, lr_0 = 4.6257e-04
Loss = 2.8310e-02, PNorm = 35.1183, GNorm = 3.8095, lr_0 = 4.8829e-04
Loss = 2.8226e-02, PNorm = 35.1340, GNorm = 17.6219, lr_0 = 5.1400e-04
Loss = 2.8772e-02, PNorm = 35.1446, GNorm = 12.1537, lr_0 = 5.3971e-04
Loss = 2.7828e-02, PNorm = 35.1615, GNorm = 4.7347, lr_0 = 5.6543e-04
Loss = 3.1555e-02, PNorm = 35.1820, GNorm = 7.8100, lr_0 = 5.9114e-04
Loss = 3.0224e-02, PNorm = 35.2028, GNorm = 8.5773, lr_0 = 6.1686e-04
Loss = 2.9031e-02, PNorm = 35.2167, GNorm = 11.9989, lr_0 = 6.4257e-04
Loss = 2.4000e-02, PNorm = 35.2374, GNorm = 1.9951, lr_0 = 6.6829e-04
Loss = 2.9805e-02, PNorm = 35.2605, GNorm = 2.4681, lr_0 = 6.9400e-04
Validation rmse = 1.302457
Validation R2 = 0.502132
Epoch 1
Train function
Loss = 2.8826e-02, PNorm = 35.2855, GNorm = 5.7675, lr_0 = 7.2229e-04
Loss = 2.4075e-02, PNorm = 35.3005, GNorm = 10.2225, lr_0 = 7.4800e-04
Loss = 2.6477e-02, PNorm = 35.3264, GNorm = 6.5361, lr_0 = 7.7371e-04
Loss = 2.5279e-02, PNorm = 35.3518, GNorm = 5.3766, lr_0 = 7.9943e-04
Loss = 2.5769e-02, PNorm = 35.3761, GNorm = 2.2096, lr_0 = 8.2514e-04
Loss = 2.3722e-02, PNorm = 35.4042, GNorm = 9.7364, lr_0 = 8.5086e-04
Loss = 2.8394e-02, PNorm = 35.4225, GNorm = 3.2650, lr_0 = 8.7657e-04
Loss = 2.3566e-02, PNorm = 35.4491, GNorm = 3.1865, lr_0 = 9.0229e-04
Loss = 2.9741e-02, PNorm = 35.4755, GNorm = 2.9755, lr_0 = 9.2800e-04
Loss = 2.8668e-02, PNorm = 35.4987, GNorm = 3.3491, lr_0 = 9.5371e-04
Loss = 2.6141e-02, PNorm = 35.5286, GNorm = 6.4988, lr_0 = 9.7943e-04
Loss = 2.5440e-02, PNorm = 35.5688, GNorm = 1.9632, lr_0 = 9.9973e-04
Loss = 2.4576e-02, PNorm = 35.5952, GNorm = 4.1217, lr_0 = 9.9839e-04
Loss = 2.6480e-02, PNorm = 35.6281, GNorm = 2.0856, lr_0 = 9.9705e-04
Loss = 2.7986e-02, PNorm = 35.6604, GNorm = 1.6886, lr_0 = 9.9571e-04
Loss = 2.3602e-02, PNorm = 35.6954, GNorm = 3.9258, lr_0 = 9.9438e-04
Loss = 2.4073e-02, PNorm = 35.7365, GNorm = 2.3305, lr_0 = 9.9304e-04
Loss = 2.7417e-02, PNorm = 35.7693, GNorm = 2.9489, lr_0 = 9.9171e-04
Loss = 2.6713e-02, PNorm = 35.8000, GNorm = 6.5723, lr_0 = 9.9038e-04
Loss = 2.0941e-02, PNorm = 35.8092, GNorm = 1.7461, lr_0 = 9.8905e-04
Loss = 2.6166e-02, PNorm = 35.8334, GNorm = 3.3305, lr_0 = 9.8772e-04
Loss = 2.4468e-02, PNorm = 35.8597, GNorm = 1.7348, lr_0 = 9.8640e-04
Loss = 2.4389e-02, PNorm = 35.8917, GNorm = 3.2051, lr_0 = 9.8508e-04
Validation rmse = 1.102705
Validation R2 = 0.643133
Epoch 2
Train function
Loss = 1.7546e-02, PNorm = 35.9256, GNorm = 2.2414, lr_0 = 9.8362e-04
Loss = 2.6842e-02, PNorm = 35.9593, GNorm = 5.9792, lr_0 = 9.8230e-04
Loss = 2.5369e-02, PNorm = 35.9922, GNorm = 2.3933, lr_0 = 9.8098e-04
Loss = 2.3241e-02, PNorm = 36.0196, GNorm = 2.8854, lr_0 = 9.7967e-04
Loss = 2.5145e-02, PNorm = 36.0499, GNorm = 2.9880, lr_0 = 9.7835e-04
Loss = 2.4577e-02, PNorm = 36.0666, GNorm = 2.9208, lr_0 = 9.7704e-04
Loss = 2.1487e-02, PNorm = 36.0876, GNorm = 4.9823, lr_0 = 9.7573e-04
Loss = 2.3358e-02, PNorm = 36.1195, GNorm = 2.9638, lr_0 = 9.7442e-04
Loss = 2.3201e-02, PNorm = 36.1366, GNorm = 6.7649, lr_0 = 9.7311e-04
Loss = 2.7157e-02, PNorm = 36.1448, GNorm = 6.3955, lr_0 = 9.7181e-04
Loss = 2.4431e-02, PNorm = 36.1772, GNorm = 2.5842, lr_0 = 9.7050e-04
Loss = 2.0967e-02, PNorm = 36.2072, GNorm = 3.6289, lr_0 = 9.6920e-04
Loss = 2.4241e-02, PNorm = 36.2407, GNorm = 3.0492, lr_0 = 9.6790e-04
Loss = 2.2204e-02, PNorm = 36.2591, GNorm = 1.8447, lr_0 = 9.6660e-04
Loss = 2.2413e-02, PNorm = 36.2828, GNorm = 2.3006, lr_0 = 9.6531e-04
Loss = 2.7601e-02, PNorm = 36.3197, GNorm = 3.3609, lr_0 = 9.6401e-04
Loss = 2.4215e-02, PNorm = 36.3498, GNorm = 2.4421, lr_0 = 9.6272e-04
Loss = 2.2739e-02, PNorm = 36.3781, GNorm = 2.1335, lr_0 = 9.6143e-04
Loss = 2.5037e-02, PNorm = 36.4016, GNorm = 1.2553, lr_0 = 9.6014e-04
Loss = 2.6930e-02, PNorm = 36.4377, GNorm = 2.1221, lr_0 = 9.5885e-04
Loss = 2.2977e-02, PNorm = 36.4763, GNorm = 2.8454, lr_0 = 9.5756e-04
Loss = 2.6097e-02, PNorm = 36.5109, GNorm = 5.8722, lr_0 = 9.5628e-04
Loss = 2.1273e-02, PNorm = 36.5369, GNorm = 2.1729, lr_0 = 9.5499e-04
Loss = 2.4722e-02, PNorm = 36.5646, GNorm = 1.8619, lr_0 = 9.5371e-04
Validation rmse = 1.333504
Validation R2 = 0.478114
Epoch 3
Train function
Loss = 2.1310e-02, PNorm = 36.5875, GNorm = 3.9098, lr_0 = 9.5230e-04
Loss = 2.3988e-02, PNorm = 36.5977, GNorm = 5.1151, lr_0 = 9.5103e-04
Loss = 2.0951e-02, PNorm = 36.6249, GNorm = 1.5673, lr_0 = 9.4975e-04
Loss = 2.2192e-02, PNorm = 36.6428, GNorm = 2.2011, lr_0 = 9.4848e-04
Loss = 2.2654e-02, PNorm = 36.6582, GNorm = 2.1005, lr_0 = 9.4720e-04
Loss = 2.1903e-02, PNorm = 36.6898, GNorm = 7.0296, lr_0 = 9.4593e-04
Loss = 2.6422e-02, PNorm = 36.7090, GNorm = 2.5832, lr_0 = 9.4466e-04
Loss = 2.2306e-02, PNorm = 36.7587, GNorm = 4.0233, lr_0 = 9.4340e-04
Loss = 2.2642e-02, PNorm = 36.7867, GNorm = 2.3218, lr_0 = 9.4213e-04
Loss = 2.1927e-02, PNorm = 36.8166, GNorm = 2.8121, lr_0 = 9.4087e-04
Loss = 2.4510e-02, PNorm = 36.8438, GNorm = 5.2658, lr_0 = 9.3960e-04
Loss = 2.4726e-02, PNorm = 36.8777, GNorm = 2.1252, lr_0 = 9.3834e-04
Loss = 2.4270e-02, PNorm = 36.8859, GNorm = 1.9293, lr_0 = 9.3708e-04
Loss = 2.3978e-02, PNorm = 36.9012, GNorm = 1.6454, lr_0 = 9.3583e-04
Loss = 2.3252e-02, PNorm = 36.9326, GNorm = 4.1991, lr_0 = 9.3457e-04
Loss = 2.2076e-02, PNorm = 36.9531, GNorm = 1.6406, lr_0 = 9.3332e-04
Loss = 2.4599e-02, PNorm = 36.9825, GNorm = 2.2478, lr_0 = 9.3206e-04
Loss = 2.1979e-02, PNorm = 37.0108, GNorm = 1.7495, lr_0 = 9.3081e-04
Loss = 2.7289e-02, PNorm = 37.0296, GNorm = 1.6179, lr_0 = 9.2957e-04
Loss = 2.1157e-02, PNorm = 37.0520, GNorm = 4.7498, lr_0 = 9.2832e-04
Loss = 2.2696e-02, PNorm = 37.0712, GNorm = 4.4626, lr_0 = 9.2707e-04
Loss = 2.4711e-02, PNorm = 37.0946, GNorm = 2.1917, lr_0 = 9.2583e-04
Loss = 2.5319e-02, PNorm = 37.1187, GNorm = 1.6962, lr_0 = 9.2459e-04
Validation rmse = 1.133140
Validation R2 = 0.623162
Epoch 4
Train function
Loss = 2.3752e-02, PNorm = 37.1565, GNorm = 2.6687, lr_0 = 9.2322e-04
Loss = 2.0220e-02, PNorm = 37.1823, GNorm = 1.4929, lr_0 = 9.2198e-04
Loss = 2.2204e-02, PNorm = 37.2072, GNorm = 4.8897, lr_0 = 9.2075e-04
Loss = 2.2208e-02, PNorm = 37.2486, GNorm = 2.8011, lr_0 = 9.1951e-04
Loss = 2.3917e-02, PNorm = 37.2749, GNorm = 2.4038, lr_0 = 9.1828e-04
Loss = 2.3118e-02, PNorm = 37.2936, GNorm = 5.4199, lr_0 = 9.1705e-04
Loss = 2.3425e-02, PNorm = 37.3198, GNorm = 1.6599, lr_0 = 9.1581e-04
Loss = 2.3472e-02, PNorm = 37.3579, GNorm = 3.8529, lr_0 = 9.1459e-04
Loss = 2.2818e-02, PNorm = 37.3778, GNorm = 1.6184, lr_0 = 9.1336e-04
Loss = 2.4070e-02, PNorm = 37.3894, GNorm = 2.1641, lr_0 = 9.1213e-04
Loss = 2.3298e-02, PNorm = 37.4157, GNorm = 2.2017, lr_0 = 9.1091e-04
Loss = 2.3850e-02, PNorm = 37.4381, GNorm = 3.0031, lr_0 = 9.0969e-04
Loss = 2.0108e-02, PNorm = 37.4559, GNorm = 3.0867, lr_0 = 9.0847e-04
Loss = 2.2430e-02, PNorm = 37.4633, GNorm = 1.7558, lr_0 = 9.0725e-04
Loss = 2.3080e-02, PNorm = 37.4933, GNorm = 2.8824, lr_0 = 9.0603e-04
Loss = 2.2671e-02, PNorm = 37.5134, GNorm = 2.8969, lr_0 = 9.0481e-04
Loss = 2.5231e-02, PNorm = 37.5536, GNorm = 1.6392, lr_0 = 9.0360e-04
Loss = 2.4158e-02, PNorm = 37.5784, GNorm = 3.0672, lr_0 = 9.0239e-04
Loss = 2.1257e-02, PNorm = 37.5874, GNorm = 2.7743, lr_0 = 9.0118e-04
Loss = 2.1595e-02, PNorm = 37.6137, GNorm = 2.3084, lr_0 = 8.9997e-04
Loss = 2.1118e-02, PNorm = 37.6376, GNorm = 2.0865, lr_0 = 8.9876e-04
Loss = 2.2741e-02, PNorm = 37.6625, GNorm = 2.2423, lr_0 = 8.9756e-04
Loss = 2.1787e-02, PNorm = 37.6767, GNorm = 1.6623, lr_0 = 8.9635e-04
Loss = 2.2584e-02, PNorm = 37.6941, GNorm = 2.2154, lr_0 = 8.9515e-04
Validation rmse = 1.548204
Validation R2 = 0.296533
Epoch 5
Train function
Loss = 2.0761e-02, PNorm = 37.7291, GNorm = 1.9214, lr_0 = 8.9395e-04
Loss = 2.1975e-02, PNorm = 37.7519, GNorm = 4.5133, lr_0 = 8.9275e-04
Loss = 2.2390e-02, PNorm = 37.7762, GNorm = 2.5616, lr_0 = 8.9155e-04
Loss = 1.8803e-02, PNorm = 37.8107, GNorm = 1.2756, lr_0 = 8.9035e-04
Loss = 2.2857e-02, PNorm = 37.8453, GNorm = 2.3806, lr_0 = 8.8916e-04
Loss = 2.3188e-02, PNorm = 37.8613, GNorm = 2.3381, lr_0 = 8.8797e-04
Loss = 2.1384e-02, PNorm = 37.8811, GNorm = 2.6139, lr_0 = 8.8677e-04
Loss = 2.3982e-02, PNorm = 37.9089, GNorm = 1.3843, lr_0 = 8.8559e-04
Loss = 2.2469e-02, PNorm = 37.9368, GNorm = 1.6028, lr_0 = 8.8440e-04
Loss = 2.1715e-02, PNorm = 37.9606, GNorm = 3.6481, lr_0 = 8.8321e-04
Loss = 1.8398e-02, PNorm = 37.9876, GNorm = 2.6658, lr_0 = 8.8203e-04
Loss = 2.3137e-02, PNorm = 38.0154, GNorm = 2.5273, lr_0 = 8.8084e-04
Loss = 2.5910e-02, PNorm = 38.0497, GNorm = 2.3612, lr_0 = 8.7966e-04
Loss = 2.3625e-02, PNorm = 38.0783, GNorm = 2.2642, lr_0 = 8.7848e-04
Loss = 2.4253e-02, PNorm = 38.1179, GNorm = 6.8399, lr_0 = 8.7730e-04
Loss = 2.0266e-02, PNorm = 38.1384, GNorm = 3.5323, lr_0 = 8.7612e-04
Loss = 2.1072e-02, PNorm = 38.1522, GNorm = 1.3688, lr_0 = 8.7495e-04
Loss = 2.0781e-02, PNorm = 38.1883, GNorm = 1.7885, lr_0 = 8.7377e-04
Loss = 2.2197e-02, PNorm = 38.2117, GNorm = 2.7742, lr_0 = 8.7260e-04
Loss = 2.2317e-02, PNorm = 38.2221, GNorm = 2.0580, lr_0 = 8.7143e-04
Loss = 2.0420e-02, PNorm = 38.2379, GNorm = 1.8662, lr_0 = 8.7026e-04
Loss = 2.2371e-02, PNorm = 38.2548, GNorm = 2.3764, lr_0 = 8.6909e-04
Loss = 2.4429e-02, PNorm = 38.2794, GNorm = 2.1200, lr_0 = 8.6793e-04
Validation rmse = 1.512894
Validation R2 = 0.328255
Epoch 6
Train function
Loss = 1.6707e-02, PNorm = 38.2959, GNorm = 1.6584, lr_0 = 8.6665e-04
Loss = 2.4347e-02, PNorm = 38.3178, GNorm = 1.5377, lr_0 = 8.6548e-04
Loss = 2.2379e-02, PNorm = 38.3507, GNorm = 2.1897, lr_0 = 8.6432e-04
Loss = 1.9442e-02, PNorm = 38.3846, GNorm = 1.5827, lr_0 = 8.6316e-04
Loss = 2.2706e-02, PNorm = 38.4138, GNorm = 1.7271, lr_0 = 8.6201e-04
Loss = 2.2451e-02, PNorm = 38.4291, GNorm = 5.0239, lr_0 = 8.6085e-04
Loss = 2.3577e-02, PNorm = 38.4505, GNorm = 4.4471, lr_0 = 8.5969e-04
Loss = 2.0854e-02, PNorm = 38.4781, GNorm = 1.3787, lr_0 = 8.5854e-04
Loss = 2.1122e-02, PNorm = 38.5108, GNorm = 1.6453, lr_0 = 8.5739e-04
Loss = 2.2316e-02, PNorm = 38.5346, GNorm = 2.7433, lr_0 = 8.5624e-04
Loss = 2.0773e-02, PNorm = 38.5722, GNorm = 3.0005, lr_0 = 8.5509e-04
Loss = 2.0308e-02, PNorm = 38.6036, GNorm = 1.6927, lr_0 = 8.5394e-04
Loss = 2.1962e-02, PNorm = 38.6376, GNorm = 2.7390, lr_0 = 8.5280e-04
Loss = 2.2934e-02, PNorm = 38.6888, GNorm = 3.4750, lr_0 = 8.5165e-04
Loss = 2.0625e-02, PNorm = 38.7157, GNorm = 2.7881, lr_0 = 8.5051e-04
Loss = 2.3293e-02, PNorm = 38.7403, GNorm = 3.5726, lr_0 = 8.4937e-04
Loss = 1.8461e-02, PNorm = 38.7668, GNorm = 1.4913, lr_0 = 8.4823e-04
Loss = 2.3916e-02, PNorm = 38.7842, GNorm = 2.8001, lr_0 = 8.4709e-04
Loss = 2.1094e-02, PNorm = 38.8002, GNorm = 1.9208, lr_0 = 8.4595e-04
Loss = 2.1797e-02, PNorm = 38.8230, GNorm = 2.8963, lr_0 = 8.4482e-04
Loss = 2.3187e-02, PNorm = 38.8566, GNorm = 1.8909, lr_0 = 8.4369e-04
Loss = 2.3221e-02, PNorm = 38.8782, GNorm = 5.4100, lr_0 = 8.4255e-04
Loss = 2.0702e-02, PNorm = 38.9064, GNorm = 1.7840, lr_0 = 8.4142e-04
Validation rmse = 1.272338
Validation R2 = 0.524892
Epoch 7
Train function
Loss = 1.6988e-02, PNorm = 38.9350, GNorm = 1.4116, lr_0 = 8.4018e-04
Loss = 1.7830e-02, PNorm = 38.9537, GNorm = 2.2862, lr_0 = 8.3905e-04
Loss = 1.9610e-02, PNorm = 38.9690, GNorm = 1.1406, lr_0 = 8.3793e-04
Loss = 2.3123e-02, PNorm = 38.9848, GNorm = 1.7512, lr_0 = 8.3680e-04
Loss = 2.0533e-02, PNorm = 39.0189, GNorm = 2.7278, lr_0 = 8.3568e-04
Loss = 2.0872e-02, PNorm = 39.0405, GNorm = 1.7909, lr_0 = 8.3456e-04
Loss = 2.0122e-02, PNorm = 39.0792, GNorm = 1.4186, lr_0 = 8.3344e-04
Loss = 2.1281e-02, PNorm = 39.1162, GNorm = 1.9747, lr_0 = 8.3232e-04
Loss = 1.8083e-02, PNorm = 39.1425, GNorm = 2.3972, lr_0 = 8.3121e-04
Loss = 2.0418e-02, PNorm = 39.1698, GNorm = 2.6254, lr_0 = 8.3009e-04
Loss = 2.1965e-02, PNorm = 39.1971, GNorm = 2.3637, lr_0 = 8.2898e-04
Loss = 1.9978e-02, PNorm = 39.2100, GNorm = 1.7449, lr_0 = 8.2786e-04
Loss = 2.1141e-02, PNorm = 39.2388, GNorm = 2.0661, lr_0 = 8.2675e-04
Loss = 1.8928e-02, PNorm = 39.2638, GNorm = 1.4069, lr_0 = 8.2564e-04
Loss = 1.9678e-02, PNorm = 39.2860, GNorm = 3.2794, lr_0 = 8.2454e-04
Loss = 2.3008e-02, PNorm = 39.3114, GNorm = 1.8436, lr_0 = 8.2343e-04
Loss = 2.2394e-02, PNorm = 39.3268, GNorm = 2.4183, lr_0 = 8.2233e-04
Loss = 2.4660e-02, PNorm = 39.3649, GNorm = 5.6025, lr_0 = 8.2122e-04
Loss = 2.1036e-02, PNorm = 39.4079, GNorm = 1.4827, lr_0 = 8.2012e-04
Loss = 2.2640e-02, PNorm = 39.4423, GNorm = 2.1490, lr_0 = 8.1902e-04
Loss = 2.0691e-02, PNorm = 39.4580, GNorm = 1.6337, lr_0 = 8.1792e-04
Loss = 2.2015e-02, PNorm = 39.4694, GNorm = 2.3365, lr_0 = 8.1682e-04
Loss = 2.1686e-02, PNorm = 39.4945, GNorm = 1.9276, lr_0 = 8.1573e-04
Loss = 2.2811e-02, PNorm = 39.5195, GNorm = 1.8539, lr_0 = 8.1463e-04
Validation rmse = 1.451106
Validation R2 = 0.382004
Epoch 8
Train function
Loss = 2.2547e-02, PNorm = 39.5506, GNorm = 4.0186, lr_0 = 8.1343e-04
Loss = 1.8206e-02, PNorm = 39.5651, GNorm = 1.7110, lr_0 = 8.1234e-04
Loss = 2.1803e-02, PNorm = 39.5963, GNorm = 1.9477, lr_0 = 8.1125e-04
Loss = 2.2901e-02, PNorm = 39.6281, GNorm = 1.6523, lr_0 = 8.1016e-04
Loss = 1.8668e-02, PNorm = 39.6507, GNorm = 3.0937, lr_0 = 8.0907e-04
Loss = 2.0207e-02, PNorm = 39.6781, GNorm = 3.2280, lr_0 = 8.0799e-04
Loss = 1.9973e-02, PNorm = 39.7085, GNorm = 1.9322, lr_0 = 8.0690e-04
Loss = 2.1494e-02, PNorm = 39.7384, GNorm = 1.1887, lr_0 = 8.0582e-04
Loss = 2.1479e-02, PNorm = 39.7763, GNorm = 1.7752, lr_0 = 8.0474e-04
Loss = 2.1431e-02, PNorm = 39.8149, GNorm = 2.5089, lr_0 = 8.0366e-04
Loss = 2.1103e-02, PNorm = 39.8288, GNorm = 1.8436, lr_0 = 8.0258e-04
Loss = 2.1257e-02, PNorm = 39.8513, GNorm = 2.2386, lr_0 = 8.0151e-04
Loss = 1.8996e-02, PNorm = 39.8821, GNorm = 1.2147, lr_0 = 8.0043e-04
Loss = 1.9076e-02, PNorm = 39.8880, GNorm = 1.8696, lr_0 = 7.9936e-04
Loss = 1.8730e-02, PNorm = 39.9109, GNorm = 4.7196, lr_0 = 7.9828e-04
Loss = 2.0289e-02, PNorm = 39.9490, GNorm = 1.3508, lr_0 = 7.9721e-04
Loss = 2.0767e-02, PNorm = 39.9791, GNorm = 1.6681, lr_0 = 7.9614e-04
Loss = 2.0142e-02, PNorm = 40.0116, GNorm = 1.6412, lr_0 = 7.9508e-04
Loss = 2.2361e-02, PNorm = 40.0400, GNorm = 1.3845, lr_0 = 7.9401e-04
Loss = 1.8790e-02, PNorm = 40.0695, GNorm = 1.9809, lr_0 = 7.9294e-04
Loss = 2.1631e-02, PNorm = 40.1075, GNorm = 3.8051, lr_0 = 7.9188e-04
Loss = 2.3450e-02, PNorm = 40.1324, GNorm = 2.7867, lr_0 = 7.9082e-04
Loss = 1.8619e-02, PNorm = 40.1487, GNorm = 1.7824, lr_0 = 7.8976e-04
Validation rmse = 1.364690
Validation R2 = 0.453418
Epoch 9
Train function
Loss = 2.1059e-02, PNorm = 40.1834, GNorm = 1.7554, lr_0 = 7.8859e-04
Loss = 1.7842e-02, PNorm = 40.2080, GNorm = 3.2154, lr_0 = 7.8753e-04
Loss = 2.0088e-02, PNorm = 40.2330, GNorm = 2.7943, lr_0 = 7.8648e-04
Loss = 1.9240e-02, PNorm = 40.2632, GNorm = 1.6880, lr_0 = 7.8542e-04
Loss = 2.1990e-02, PNorm = 40.2944, GNorm = 4.6611, lr_0 = 7.8437e-04
Loss = 1.9704e-02, PNorm = 40.3217, GNorm = 1.6495, lr_0 = 7.8331e-04
Loss = 2.3159e-02, PNorm = 40.3554, GNorm = 2.5813, lr_0 = 7.8226e-04
Loss = 1.8206e-02, PNorm = 40.3936, GNorm = 1.8828, lr_0 = 7.8121e-04
Loss = 1.8043e-02, PNorm = 40.4192, GNorm = 3.2562, lr_0 = 7.8017e-04
Loss = 2.0523e-02, PNorm = 40.4544, GNorm = 3.3244, lr_0 = 7.7912e-04
Loss = 2.1718e-02, PNorm = 40.4924, GNorm = 2.3778, lr_0 = 7.7807e-04
Loss = 2.1291e-02, PNorm = 40.5258, GNorm = 1.7462, lr_0 = 7.7703e-04
Loss = 2.0238e-02, PNorm = 40.5512, GNorm = 2.5313, lr_0 = 7.7599e-04
Loss = 2.2203e-02, PNorm = 40.5834, GNorm = 1.6881, lr_0 = 7.7495e-04
Loss = 1.7062e-02, PNorm = 40.6006, GNorm = 2.8064, lr_0 = 7.7391e-04
Loss = 1.9385e-02, PNorm = 40.6305, GNorm = 3.8202, lr_0 = 7.7287e-04
Loss = 2.0349e-02, PNorm = 40.6489, GNorm = 2.5180, lr_0 = 7.7183e-04
Loss = 1.9026e-02, PNorm = 40.6771, GNorm = 2.5819, lr_0 = 7.7079e-04
Loss = 1.9972e-02, PNorm = 40.7020, GNorm = 2.4683, lr_0 = 7.6976e-04
Loss = 2.2566e-02, PNorm = 40.7270, GNorm = 3.5382, lr_0 = 7.6873e-04
Loss = 1.9662e-02, PNorm = 40.7523, GNorm = 2.0112, lr_0 = 7.6770e-04
Loss = 2.0418e-02, PNorm = 40.7707, GNorm = 3.0337, lr_0 = 7.6667e-04
Loss = 1.9668e-02, PNorm = 40.7958, GNorm = 2.0189, lr_0 = 7.6564e-04
Loss = 2.4876e-02, PNorm = 40.8150, GNorm = 2.4037, lr_0 = 7.6461e-04
Validation rmse = 1.549004
Validation R2 = 0.295806
Epoch 10
Train function
Loss = 2.0724e-02, PNorm = 40.8545, GNorm = 1.7923, lr_0 = 7.6358e-04
Loss = 1.7872e-02, PNorm = 40.8802, GNorm = 1.6626, lr_0 = 7.6256e-04
Loss = 1.9725e-02, PNorm = 40.8973, GNorm = 2.5560, lr_0 = 7.6154e-04
Loss = 1.9850e-02, PNorm = 40.9292, GNorm = 2.0597, lr_0 = 7.6052e-04
Loss = 2.0875e-02, PNorm = 40.9504, GNorm = 1.7265, lr_0 = 7.5949e-04
Loss = 1.9598e-02, PNorm = 40.9729, GNorm = 1.5872, lr_0 = 7.5848e-04
Loss = 2.2396e-02, PNorm = 41.0009, GNorm = 1.5763, lr_0 = 7.5746e-04
Loss = 2.0614e-02, PNorm = 41.0334, GNorm = 2.1080, lr_0 = 7.5644e-04
Loss = 1.8356e-02, PNorm = 41.0661, GNorm = 1.5108, lr_0 = 7.5543e-04
Loss = 1.8095e-02, PNorm = 41.0922, GNorm = 2.6018, lr_0 = 7.5441e-04
Loss = 2.0692e-02, PNorm = 41.1195, GNorm = 2.7244, lr_0 = 7.5340e-04
Loss = 2.0943e-02, PNorm = 41.1405, GNorm = 3.8715, lr_0 = 7.5239e-04
Loss = 1.9399e-02, PNorm = 41.1644, GNorm = 3.1986, lr_0 = 7.5138e-04
Loss = 1.7205e-02, PNorm = 41.1888, GNorm = 1.7158, lr_0 = 7.5037e-04
Loss = 2.0958e-02, PNorm = 41.2176, GNorm = 2.3721, lr_0 = 7.4937e-04
Loss = 2.1621e-02, PNorm = 41.2602, GNorm = 1.9728, lr_0 = 7.4836e-04
Loss = 1.8235e-02, PNorm = 41.2863, GNorm = 1.3102, lr_0 = 7.4736e-04
Loss = 2.0504e-02, PNorm = 41.3076, GNorm = 3.3150, lr_0 = 7.4635e-04
Loss = 2.0257e-02, PNorm = 41.3427, GNorm = 1.8840, lr_0 = 7.4535e-04
Loss = 2.0898e-02, PNorm = 41.3695, GNorm = 1.8559, lr_0 = 7.4435e-04
Loss = 1.8106e-02, PNorm = 41.4035, GNorm = 1.9294, lr_0 = 7.4335e-04
Loss = 1.8916e-02, PNorm = 41.4307, GNorm = 1.7212, lr_0 = 7.4236e-04
Loss = 1.9727e-02, PNorm = 41.4612, GNorm = 2.0140, lr_0 = 7.4136e-04
Validation rmse = 1.782110
Validation R2 = 0.067913
Epoch 11
Train function
Loss = 1.7864e-02, PNorm = 41.4858, GNorm = 2.2356, lr_0 = 7.4027e-04
Loss = 1.9372e-02, PNorm = 41.5151, GNorm = 2.7306, lr_0 = 7.3927e-04
Loss = 1.9321e-02, PNorm = 41.5397, GNorm = 1.8418, lr_0 = 7.3828e-04
Loss = 2.0966e-02, PNorm = 41.5673, GNorm = 2.9326, lr_0 = 7.3729e-04
Loss = 1.9845e-02, PNorm = 41.6125, GNorm = 1.6741, lr_0 = 7.3630e-04
Loss = 1.9502e-02, PNorm = 41.6589, GNorm = 1.8642, lr_0 = 7.3531e-04
Loss = 1.7161e-02, PNorm = 41.6839, GNorm = 1.6731, lr_0 = 7.3433e-04
Loss = 1.8118e-02, PNorm = 41.7143, GNorm = 2.2174, lr_0 = 7.3334e-04
Loss = 2.1608e-02, PNorm = 41.7405, GNorm = 3.7891, lr_0 = 7.3236e-04
Loss = 2.0073e-02, PNorm = 41.7781, GNorm = 2.3625, lr_0 = 7.3137e-04
Loss = 2.0870e-02, PNorm = 41.8065, GNorm = 2.6693, lr_0 = 7.3039e-04
Loss = 2.0861e-02, PNorm = 41.8431, GNorm = 1.6634, lr_0 = 7.2941e-04
Loss = 2.0970e-02, PNorm = 41.8619, GNorm = 1.9433, lr_0 = 7.2843e-04
Loss = 2.0269e-02, PNorm = 41.8897, GNorm = 3.6151, lr_0 = 7.2746e-04
Loss = 1.8939e-02, PNorm = 41.9187, GNorm = 1.9642, lr_0 = 7.2648e-04
Loss = 1.6955e-02, PNorm = 41.9356, GNorm = 2.1667, lr_0 = 7.2551e-04
Loss = 1.6903e-02, PNorm = 41.9541, GNorm = 2.2101, lr_0 = 7.2453e-04
Loss = 2.0659e-02, PNorm = 41.9772, GNorm = 3.3459, lr_0 = 7.2356e-04
Loss = 1.7893e-02, PNorm = 42.0155, GNorm = 1.6539, lr_0 = 7.2259e-04
Loss = 2.0046e-02, PNorm = 42.0470, GNorm = 3.0099, lr_0 = 7.2162e-04
Loss = 1.6987e-02, PNorm = 42.0601, GNorm = 1.9278, lr_0 = 7.2065e-04
Loss = 1.9254e-02, PNorm = 42.0784, GNorm = 1.8939, lr_0 = 7.1969e-04
Loss = 1.8905e-02, PNorm = 42.0904, GNorm = 2.6790, lr_0 = 7.1872e-04
Loss = 1.9497e-02, PNorm = 42.1127, GNorm = 1.8807, lr_0 = 7.1776e-04
Loss = 7.0767e-02, PNorm = 42.1157, GNorm = 5.2022, lr_0 = 7.1766e-04
Validation rmse = 1.425855
Validation R2 = 0.403324
Epoch 12
Train function
Loss = 1.8394e-02, PNorm = 42.1509, GNorm = 3.7699, lr_0 = 7.1670e-04
Loss = 1.8678e-02, PNorm = 42.1929, GNorm = 1.9159, lr_0 = 7.1573e-04
Loss = 1.9223e-02, PNorm = 42.2270, GNorm = 3.1689, lr_0 = 7.1477e-04
Loss = 1.9845e-02, PNorm = 42.2552, GNorm = 2.8553, lr_0 = 7.1382e-04
Loss = 1.8491e-02, PNorm = 42.2786, GNorm = 1.8890, lr_0 = 7.1286e-04
Loss = 1.8482e-02, PNorm = 42.3068, GNorm = 1.9097, lr_0 = 7.1190e-04
Loss = 1.8711e-02, PNorm = 42.3326, GNorm = 2.1665, lr_0 = 7.1095e-04
Loss = 1.7850e-02, PNorm = 42.3606, GNorm = 1.8994, lr_0 = 7.0999e-04
Loss = 1.9262e-02, PNorm = 42.3861, GNorm = 3.2488, lr_0 = 7.0904e-04
Loss = 2.1154e-02, PNorm = 42.4096, GNorm = 5.2021, lr_0 = 7.0809e-04
Loss = 1.7200e-02, PNorm = 42.4427, GNorm = 3.4047, lr_0 = 7.0714e-04
Loss = 2.2610e-02, PNorm = 42.4728, GNorm = 2.5530, lr_0 = 7.0619e-04
Loss = 1.9418e-02, PNorm = 42.5051, GNorm = 1.8436, lr_0 = 7.0524e-04
Loss = 2.0834e-02, PNorm = 42.5483, GNorm = 3.6527, lr_0 = 7.0430e-04
Loss = 1.7900e-02, PNorm = 42.5854, GNorm = 2.2636, lr_0 = 7.0335e-04
Loss = 1.4284e-02, PNorm = 42.6127, GNorm = 2.6390, lr_0 = 7.0241e-04
Loss = 1.7970e-02, PNorm = 42.6251, GNorm = 1.8709, lr_0 = 7.0146e-04
Loss = 2.1106e-02, PNorm = 42.6477, GNorm = 2.7974, lr_0 = 7.0052e-04
Loss = 1.8034e-02, PNorm = 42.6723, GNorm = 2.0700, lr_0 = 6.9958e-04
Loss = 2.1712e-02, PNorm = 42.7096, GNorm = 2.0091, lr_0 = 6.9865e-04
Loss = 1.6256e-02, PNorm = 42.7461, GNorm = 1.7332, lr_0 = 6.9771e-04
Loss = 1.7440e-02, PNorm = 42.7700, GNorm = 1.5407, lr_0 = 6.9677e-04
Loss = 1.9680e-02, PNorm = 42.8019, GNorm = 1.9092, lr_0 = 6.9584e-04
Validation rmse = 1.816535
Validation R2 = 0.031555
Epoch 13
Train function
Loss = 1.8618e-02, PNorm = 42.8355, GNorm = 2.3985, lr_0 = 6.9481e-04
Loss = 1.8653e-02, PNorm = 42.8695, GNorm = 2.5069, lr_0 = 6.9388e-04
Loss = 1.8420e-02, PNorm = 42.9040, GNorm = 1.4010, lr_0 = 6.9295e-04
Loss = 1.8199e-02, PNorm = 42.9384, GNorm = 2.0150, lr_0 = 6.9202e-04
Loss = 1.8096e-02, PNorm = 42.9658, GNorm = 2.6154, lr_0 = 6.9109e-04
Loss = 1.9719e-02, PNorm = 42.9998, GNorm = 3.1296, lr_0 = 6.9016e-04
Loss = 1.9134e-02, PNorm = 43.0374, GNorm = 2.4302, lr_0 = 6.8924e-04
Loss = 1.6652e-02, PNorm = 43.0623, GNorm = 1.8287, lr_0 = 6.8831e-04
Loss = 2.3278e-02, PNorm = 43.0987, GNorm = 2.1299, lr_0 = 6.8739e-04
Loss = 1.8261e-02, PNorm = 43.1436, GNorm = 2.0973, lr_0 = 6.8646e-04
Loss = 1.9682e-02, PNorm = 43.1786, GNorm = 2.5737, lr_0 = 6.8554e-04
Loss = 1.8035e-02, PNorm = 43.2080, GNorm = 1.7526, lr_0 = 6.8462e-04
Loss = 2.0817e-02, PNorm = 43.2432, GNorm = 2.8064, lr_0 = 6.8371e-04
Loss = 2.1630e-02, PNorm = 43.2801, GNorm = 1.7613, lr_0 = 6.8279e-04
Loss = 1.5559e-02, PNorm = 43.3091, GNorm = 1.8049, lr_0 = 6.8187e-04
Loss = 1.7190e-02, PNorm = 43.3339, GNorm = 2.2011, lr_0 = 6.8096e-04
Loss = 1.8530e-02, PNorm = 43.3570, GNorm = 2.8971, lr_0 = 6.8004e-04
Loss = 1.9287e-02, PNorm = 43.3797, GNorm = 2.3612, lr_0 = 6.7913e-04
Loss = 1.8018e-02, PNorm = 43.4029, GNorm = 2.9853, lr_0 = 6.7822e-04
Loss = 1.8459e-02, PNorm = 43.4369, GNorm = 2.5940, lr_0 = 6.7731e-04
Loss = 1.8094e-02, PNorm = 43.4552, GNorm = 1.7182, lr_0 = 6.7640e-04
Loss = 1.4836e-02, PNorm = 43.4775, GNorm = 1.8098, lr_0 = 6.7549e-04
Loss = 1.7354e-02, PNorm = 43.4943, GNorm = 2.3650, lr_0 = 6.7459e-04
Validation rmse = 1.650088
Validation R2 = 0.200899
Epoch 14
Train function
Loss = 1.8241e-02, PNorm = 43.5201, GNorm = 3.0162, lr_0 = 6.7359e-04
Loss = 1.5291e-02, PNorm = 43.5511, GNorm = 1.9845, lr_0 = 6.7269e-04
Loss = 1.7265e-02, PNorm = 43.5835, GNorm = 2.2133, lr_0 = 6.7179e-04
Loss = 1.6905e-02, PNorm = 43.6206, GNorm = 1.6146, lr_0 = 6.7088e-04
Loss = 1.7662e-02, PNorm = 43.6622, GNorm = 2.3176, lr_0 = 6.6998e-04
Loss = 1.6738e-02, PNorm = 43.6929, GNorm = 1.8760, lr_0 = 6.6908e-04
Loss = 1.6726e-02, PNorm = 43.7170, GNorm = 2.4639, lr_0 = 6.6819e-04
Loss = 1.9998e-02, PNorm = 43.7564, GNorm = 1.7725, lr_0 = 6.6729e-04
Loss = 1.7729e-02, PNorm = 43.7890, GNorm = 3.1019, lr_0 = 6.6640e-04
Loss = 1.8263e-02, PNorm = 43.8173, GNorm = 2.0295, lr_0 = 6.6550e-04
Loss = 1.8515e-02, PNorm = 43.8420, GNorm = 2.3091, lr_0 = 6.6461e-04
Loss = 1.7705e-02, PNorm = 43.8786, GNorm = 2.3319, lr_0 = 6.6372e-04
Loss = 2.0671e-02, PNorm = 43.9079, GNorm = 1.5316, lr_0 = 6.6283e-04
Loss = 1.8132e-02, PNorm = 43.9365, GNorm = 2.1250, lr_0 = 6.6194e-04
Loss = 1.8463e-02, PNorm = 43.9697, GNorm = 2.0477, lr_0 = 6.6105e-04
Loss = 1.8776e-02, PNorm = 43.9959, GNorm = 2.8323, lr_0 = 6.6016e-04
Loss = 1.9285e-02, PNorm = 44.0293, GNorm = 1.6604, lr_0 = 6.5928e-04
Loss = 1.7258e-02, PNorm = 44.0599, GNorm = 3.6219, lr_0 = 6.5839e-04
Loss = 1.6395e-02, PNorm = 44.0873, GNorm = 1.8015, lr_0 = 6.5751e-04
Loss = 1.5882e-02, PNorm = 44.1143, GNorm = 2.1341, lr_0 = 6.5663e-04
Loss = 1.9350e-02, PNorm = 44.1463, GNorm = 2.7748, lr_0 = 6.5574e-04
Loss = 1.9200e-02, PNorm = 44.1725, GNorm = 1.8676, lr_0 = 6.5486e-04
Loss = 2.1408e-02, PNorm = 44.2063, GNorm = 2.1416, lr_0 = 6.5399e-04
Loss = 1.8897e-02, PNorm = 44.2310, GNorm = 1.7949, lr_0 = 6.5311e-04
Validation rmse = 1.919066
Validation R2 = -0.080855
Epoch 15
Train function
Loss = 1.8319e-02, PNorm = 44.2628, GNorm = 4.6770, lr_0 = 6.5223e-04
Loss = 1.7543e-02, PNorm = 44.2948, GNorm = 2.2772, lr_0 = 6.5136e-04
Loss = 1.5161e-02, PNorm = 44.3252, GNorm = 2.6430, lr_0 = 6.5048e-04
Loss = 1.6312e-02, PNorm = 44.3590, GNorm = 2.2092, lr_0 = 6.4961e-04
Loss = 1.8686e-02, PNorm = 44.3788, GNorm = 2.4436, lr_0 = 6.4874e-04
Loss = 1.8337e-02, PNorm = 44.4191, GNorm = 2.1433, lr_0 = 6.4787e-04
Loss = 1.5694e-02, PNorm = 44.4484, GNorm = 2.5456, lr_0 = 6.4700e-04
Loss = 1.7888e-02, PNorm = 44.4883, GNorm = 1.6016, lr_0 = 6.4613e-04
Loss = 1.7907e-02, PNorm = 44.5088, GNorm = 1.8453, lr_0 = 6.4526e-04
Loss = 1.6580e-02, PNorm = 44.5428, GNorm = 1.7324, lr_0 = 6.4440e-04
Loss = 1.7948e-02, PNorm = 44.5737, GNorm = 3.6036, lr_0 = 6.4353e-04
Loss = 1.9141e-02, PNorm = 44.6025, GNorm = 2.1215, lr_0 = 6.4267e-04
Loss = 1.9311e-02, PNorm = 44.6365, GNorm = 2.3683, lr_0 = 6.4181e-04
Loss = 1.4562e-02, PNorm = 44.6728, GNorm = 2.1446, lr_0 = 6.4095e-04
Loss = 1.7886e-02, PNorm = 44.6948, GNorm = 1.7824, lr_0 = 6.4009e-04
Loss = 1.8963e-02, PNorm = 44.7156, GNorm = 1.9528, lr_0 = 6.3923e-04
Loss = 1.7062e-02, PNorm = 44.7395, GNorm = 2.2769, lr_0 = 6.3837e-04
Loss = 1.9217e-02, PNorm = 44.7666, GNorm = 2.0097, lr_0 = 6.3751e-04
Loss = 1.7267e-02, PNorm = 44.7984, GNorm = 2.7097, lr_0 = 6.3666e-04
Loss = 1.7952e-02, PNorm = 44.8268, GNorm = 1.9213, lr_0 = 6.3580e-04
Loss = 1.7424e-02, PNorm = 44.8514, GNorm = 2.2973, lr_0 = 6.3495e-04
Loss = 1.7120e-02, PNorm = 44.8715, GNorm = 4.3393, lr_0 = 6.3410e-04
Loss = 1.7959e-02, PNorm = 44.8928, GNorm = 4.2832, lr_0 = 6.3325e-04
Validation rmse = 1.994235
Validation R2 = -0.167187
Epoch 16
Train function
Loss = 1.4763e-02, PNorm = 44.9292, GNorm = 2.4046, lr_0 = 6.3231e-04
Loss = 1.6943e-02, PNorm = 44.9686, GNorm = 1.9928, lr_0 = 6.3147e-04
Loss = 1.6668e-02, PNorm = 44.9968, GNorm = 2.4362, lr_0 = 6.3062e-04
Loss = 1.5639e-02, PNorm = 45.0297, GNorm = 2.2397, lr_0 = 6.2977e-04
Loss = 1.6936e-02, PNorm = 45.0603, GNorm = 1.9572, lr_0 = 6.2893e-04
Loss = 1.8886e-02, PNorm = 45.0904, GNorm = 2.7496, lr_0 = 6.2808e-04
Loss = 1.5427e-02, PNorm = 45.1245, GNorm = 1.8277, lr_0 = 6.2724e-04
Loss = 1.6570e-02, PNorm = 45.1567, GNorm = 3.4898, lr_0 = 6.2640e-04
Loss = 1.7672e-02, PNorm = 45.1891, GNorm = 2.0506, lr_0 = 6.2556e-04
Loss = 1.5381e-02, PNorm = 45.2191, GNorm = 2.0324, lr_0 = 6.2472e-04
Loss = 1.8989e-02, PNorm = 45.2573, GNorm = 2.1976, lr_0 = 6.2388e-04
Loss = 1.7676e-02, PNorm = 45.2963, GNorm = 1.8237, lr_0 = 6.2304e-04
Loss = 1.8252e-02, PNorm = 45.3206, GNorm = 3.3276, lr_0 = 6.2221e-04
Loss = 1.5723e-02, PNorm = 45.3399, GNorm = 2.3341, lr_0 = 6.2137e-04
Loss = 1.8216e-02, PNorm = 45.3630, GNorm = 2.0886, lr_0 = 6.2054e-04
Loss = 1.7728e-02, PNorm = 45.3906, GNorm = 2.7559, lr_0 = 6.1971e-04
Loss = 1.5262e-02, PNorm = 45.4166, GNorm = 3.7020, lr_0 = 6.1888e-04
Loss = 1.6446e-02, PNorm = 45.4384, GNorm = 2.3361, lr_0 = 6.1805e-04
Loss = 1.5608e-02, PNorm = 45.4704, GNorm = 1.5380, lr_0 = 6.1722e-04
Loss = 2.0350e-02, PNorm = 45.4935, GNorm = 4.1017, lr_0 = 6.1639e-04
Loss = 1.6064e-02, PNorm = 45.5187, GNorm = 2.8927, lr_0 = 6.1556e-04
Loss = 1.9433e-02, PNorm = 45.5442, GNorm = 4.1805, lr_0 = 6.1474e-04
Loss = 1.8426e-02, PNorm = 45.5755, GNorm = 1.8816, lr_0 = 6.1391e-04
Loss = 1.5148e-02, PNorm = 45.6018, GNorm = 1.8703, lr_0 = 6.1309e-04
Validation rmse = 1.925506
Validation R2 = -0.088121
Epoch 17
Train function
Loss = 1.6688e-02, PNorm = 45.6403, GNorm = 1.6713, lr_0 = 6.1218e-04
Loss = 1.6282e-02, PNorm = 45.6665, GNorm = 2.0847, lr_0 = 6.1136e-04
Loss = 1.6508e-02, PNorm = 45.7019, GNorm = 2.8873, lr_0 = 6.1054e-04
Loss = 1.6076e-02, PNorm = 45.7358, GNorm = 4.4328, lr_0 = 6.0972e-04
Loss = 1.7881e-02, PNorm = 45.7693, GNorm = 2.6764, lr_0 = 6.0890e-04
Loss = 1.4913e-02, PNorm = 45.8004, GNorm = 3.8521, lr_0 = 6.0809e-04
Loss = 1.8085e-02, PNorm = 45.8323, GNorm = 2.0091, lr_0 = 6.0727e-04
Loss = 1.8820e-02, PNorm = 45.8731, GNorm = 3.5589, lr_0 = 6.0646e-04
Loss = 1.6940e-02, PNorm = 45.9053, GNorm = 3.1221, lr_0 = 6.0564e-04
Loss = 1.5918e-02, PNorm = 45.9373, GNorm = 1.6958, lr_0 = 6.0483e-04
Loss = 1.7386e-02, PNorm = 45.9645, GNorm = 2.0065, lr_0 = 6.0402e-04
Loss = 1.4513e-02, PNorm = 45.9918, GNorm = 2.5363, lr_0 = 6.0321e-04
Loss = 1.5339e-02, PNorm = 46.0182, GNorm = 1.8627, lr_0 = 6.0240e-04
Loss = 1.7748e-02, PNorm = 46.0476, GNorm = 2.7602, lr_0 = 6.0159e-04
Loss = 1.4380e-02, PNorm = 46.0817, GNorm = 3.1110, lr_0 = 6.0078e-04
Loss = 1.7773e-02, PNorm = 46.1000, GNorm = 2.3626, lr_0 = 5.9998e-04
Loss = 1.6841e-02, PNorm = 46.1211, GNorm = 2.0363, lr_0 = 5.9917e-04
Loss = 1.6685e-02, PNorm = 46.1549, GNorm = 1.9430, lr_0 = 5.9837e-04
Loss = 1.8307e-02, PNorm = 46.1824, GNorm = 2.8459, lr_0 = 5.9756e-04
Loss = 1.5279e-02, PNorm = 46.2056, GNorm = 3.5051, lr_0 = 5.9676e-04
Loss = 1.6337e-02, PNorm = 46.2272, GNorm = 2.4251, lr_0 = 5.9596e-04
Loss = 1.5947e-02, PNorm = 46.2484, GNorm = 2.7677, lr_0 = 5.9516e-04
Loss = 1.5278e-02, PNorm = 46.2812, GNorm = 2.0726, lr_0 = 5.9436e-04
Validation rmse = 2.008274
Validation R2 = -0.183678
Epoch 18
Train function
Loss = 1.1645e-02, PNorm = 46.3191, GNorm = 2.5303, lr_0 = 5.9349e-04
Loss = 1.4758e-02, PNorm = 46.3549, GNorm = 3.3801, lr_0 = 5.9269e-04
Loss = 1.6142e-02, PNorm = 46.3840, GNorm = 2.7326, lr_0 = 5.9190e-04
Loss = 1.5497e-02, PNorm = 46.4221, GNorm = 2.2519, lr_0 = 5.9110e-04
Loss = 1.7397e-02, PNorm = 46.4523, GNorm = 3.6341, lr_0 = 5.9031e-04
Loss = 1.4623e-02, PNorm = 46.4761, GNorm = 3.8106, lr_0 = 5.8952e-04
Loss = 1.4769e-02, PNorm = 46.4992, GNorm = 2.1360, lr_0 = 5.8873e-04
Loss = 1.4872e-02, PNorm = 46.5192, GNorm = 1.8730, lr_0 = 5.8794e-04
Loss = 1.6151e-02, PNorm = 46.5442, GNorm = 2.4519, lr_0 = 5.8715e-04
Loss = 1.5771e-02, PNorm = 46.5699, GNorm = 2.6918, lr_0 = 5.8636e-04
Loss = 1.8028e-02, PNorm = 46.5923, GNorm = 2.0103, lr_0 = 5.8557e-04
Loss = 1.7805e-02, PNorm = 46.6215, GNorm = 4.5529, lr_0 = 5.8479e-04
Loss = 1.6962e-02, PNorm = 46.6561, GNorm = 3.2064, lr_0 = 5.8400e-04
Loss = 1.7093e-02, PNorm = 46.6910, GNorm = 2.7437, lr_0 = 5.8322e-04
Loss = 1.9444e-02, PNorm = 46.7309, GNorm = 2.4212, lr_0 = 5.8244e-04
Loss = 1.3917e-02, PNorm = 46.7648, GNorm = 2.0184, lr_0 = 5.8165e-04
Loss = 1.5510e-02, PNorm = 46.7900, GNorm = 3.1971, lr_0 = 5.8087e-04
Loss = 1.3631e-02, PNorm = 46.8142, GNorm = 2.1140, lr_0 = 5.8009e-04
Loss = 1.6678e-02, PNorm = 46.8423, GNorm = 3.1599, lr_0 = 5.7932e-04
Loss = 1.5846e-02, PNorm = 46.8772, GNorm = 1.7489, lr_0 = 5.7854e-04
Loss = 1.5687e-02, PNorm = 46.9070, GNorm = 2.4353, lr_0 = 5.7776e-04
Loss = 1.5052e-02, PNorm = 46.9308, GNorm = 2.9382, lr_0 = 5.7699e-04
Loss = 1.5169e-02, PNorm = 46.9559, GNorm = 2.2894, lr_0 = 5.7621e-04
Validation rmse = 1.830605
Validation R2 = 0.016494
Epoch 19
Train function
Loss = 2.6487e-02, PNorm = 46.9765, GNorm = 3.5295, lr_0 = 5.7536e-04
Loss = 1.5312e-02, PNorm = 47.0091, GNorm = 2.8656, lr_0 = 5.7459e-04
Loss = 1.5546e-02, PNorm = 47.0389, GNorm = 1.9328, lr_0 = 5.7382e-04
Loss = 1.4894e-02, PNorm = 47.0646, GNorm = 3.3688, lr_0 = 5.7305e-04
Loss = 1.7149e-02, PNorm = 47.0980, GNorm = 2.8169, lr_0 = 5.7228e-04
Loss = 1.5340e-02, PNorm = 47.1256, GNorm = 2.3550, lr_0 = 5.7151e-04
Loss = 1.4693e-02, PNorm = 47.1525, GNorm = 2.2700, lr_0 = 5.7075e-04
Loss = 1.5749e-02, PNorm = 47.1772, GNorm = 4.1057, lr_0 = 5.6998e-04
Loss = 1.7513e-02, PNorm = 47.2139, GNorm = 4.9834, lr_0 = 5.6922e-04
Loss = 1.5303e-02, PNorm = 47.2453, GNorm = 2.4038, lr_0 = 5.6845e-04
Loss = 1.4749e-02, PNorm = 47.2718, GNorm = 3.7816, lr_0 = 5.6769e-04
Loss = 1.5521e-02, PNorm = 47.3047, GNorm = 3.2925, lr_0 = 5.6693e-04
Loss = 1.5804e-02, PNorm = 47.3371, GNorm = 1.9615, lr_0 = 5.6617e-04
Loss = 1.7100e-02, PNorm = 47.3730, GNorm = 2.3687, lr_0 = 5.6541e-04
Loss = 1.4634e-02, PNorm = 47.4001, GNorm = 2.8403, lr_0 = 5.6465e-04
Loss = 1.5105e-02, PNorm = 47.4196, GNorm = 2.7664, lr_0 = 5.6389e-04
Loss = 1.5913e-02, PNorm = 47.4401, GNorm = 2.6479, lr_0 = 5.6313e-04
Loss = 1.3884e-02, PNorm = 47.4683, GNorm = 1.8727, lr_0 = 5.6238e-04
Loss = 1.4288e-02, PNorm = 47.4939, GNorm = 2.4514, lr_0 = 5.6162e-04
Loss = 1.2624e-02, PNorm = 47.5164, GNorm = 2.1383, lr_0 = 5.6087e-04
Loss = 1.5526e-02, PNorm = 47.5372, GNorm = 3.2160, lr_0 = 5.6012e-04
Loss = 1.2859e-02, PNorm = 47.5687, GNorm = 2.4297, lr_0 = 5.5937e-04
Loss = 1.6340e-02, PNorm = 47.6055, GNorm = 3.9937, lr_0 = 5.5862e-04
Loss = 1.7082e-02, PNorm = 47.6409, GNorm = 2.8604, lr_0 = 5.5787e-04
Validation rmse = 1.976949
Validation R2 = -0.147040
Epoch 20
Train function
Loss = 1.3674e-02, PNorm = 47.6619, GNorm = 3.2096, lr_0 = 5.5712e-04
Loss = 1.3261e-02, PNorm = 47.6859, GNorm = 2.0698, lr_0 = 5.5637e-04
Loss = 1.3540e-02, PNorm = 47.7227, GNorm = 1.2622, lr_0 = 5.5562e-04
Loss = 1.3589e-02, PNorm = 47.7501, GNorm = 2.7652, lr_0 = 5.5488e-04
Loss = 1.5180e-02, PNorm = 47.7828, GNorm = 2.6091, lr_0 = 5.5413e-04
Loss = 1.5729e-02, PNorm = 47.8154, GNorm = 3.0345, lr_0 = 5.5339e-04
Loss = 1.4389e-02, PNorm = 47.8416, GNorm = 2.2056, lr_0 = 5.5265e-04
Loss = 1.3011e-02, PNorm = 47.8689, GNorm = 1.6672, lr_0 = 5.5191e-04
Loss = 1.6740e-02, PNorm = 47.9023, GNorm = 3.2421, lr_0 = 5.5117e-04
Loss = 1.2927e-02, PNorm = 47.9257, GNorm = 2.0239, lr_0 = 5.5043e-04
Loss = 1.6350e-02, PNorm = 47.9534, GNorm = 2.7542, lr_0 = 5.4969e-04
Loss = 1.4465e-02, PNorm = 47.9830, GNorm = 2.6488, lr_0 = 5.4895e-04
Loss = 1.5478e-02, PNorm = 48.0118, GNorm = 2.9718, lr_0 = 5.4821e-04
Loss = 1.5873e-02, PNorm = 48.0348, GNorm = 4.6296, lr_0 = 5.4748e-04
Loss = 1.7288e-02, PNorm = 48.0615, GNorm = 3.1025, lr_0 = 5.4674e-04
Loss = 1.5239e-02, PNorm = 48.0848, GNorm = 2.7404, lr_0 = 5.4601e-04
Loss = 1.4570e-02, PNorm = 48.1078, GNorm = 1.9309, lr_0 = 5.4528e-04
Loss = 1.7057e-02, PNorm = 48.1377, GNorm = 4.0595, lr_0 = 5.4455e-04
Loss = 1.4180e-02, PNorm = 48.1688, GNorm = 2.1956, lr_0 = 5.4382e-04
Loss = 1.7454e-02, PNorm = 48.2064, GNorm = 3.6120, lr_0 = 5.4309e-04
Loss = 1.4431e-02, PNorm = 48.2327, GNorm = 3.6429, lr_0 = 5.4236e-04
Loss = 1.3799e-02, PNorm = 48.2602, GNorm = 2.0978, lr_0 = 5.4163e-04
Loss = 1.4527e-02, PNorm = 48.2804, GNorm = 2.9220, lr_0 = 5.4090e-04
Validation rmse = 1.953636
Validation R2 = -0.120147
Epoch 21
Train function
Loss = 1.2088e-02, PNorm = 48.3040, GNorm = 2.4223, lr_0 = 5.4010e-04
Loss = 1.4068e-02, PNorm = 48.3310, GNorm = 3.0823, lr_0 = 5.3938e-04
Loss = 1.5467e-02, PNorm = 48.3674, GNorm = 2.5814, lr_0 = 5.3866e-04
Loss = 1.2720e-02, PNorm = 48.3948, GNorm = 2.3179, lr_0 = 5.3793e-04
Loss = 1.2944e-02, PNorm = 48.4271, GNorm = 2.3343, lr_0 = 5.3721e-04
Loss = 1.2741e-02, PNorm = 48.4484, GNorm = 2.8023, lr_0 = 5.3649e-04
Loss = 1.2493e-02, PNorm = 48.4689, GNorm = 4.6028, lr_0 = 5.3577e-04
Loss = 1.3945e-02, PNorm = 48.4871, GNorm = 2.3450, lr_0 = 5.3505e-04
Loss = 1.4694e-02, PNorm = 48.5188, GNorm = 2.7180, lr_0 = 5.3433e-04
Loss = 1.0926e-02, PNorm = 48.5548, GNorm = 2.1883, lr_0 = 5.3362e-04
Loss = 1.6283e-02, PNorm = 48.5829, GNorm = 4.0976, lr_0 = 5.3290e-04
Loss = 1.2996e-02, PNorm = 48.6108, GNorm = 3.1886, lr_0 = 5.3219e-04
Loss = 1.3699e-02, PNorm = 48.6392, GNorm = 2.6646, lr_0 = 5.3147e-04
Loss = 1.4717e-02, PNorm = 48.6663, GNorm = 2.7518, lr_0 = 5.3076e-04
Loss = 1.3886e-02, PNorm = 48.6859, GNorm = 2.3845, lr_0 = 5.3005e-04
Loss = 1.4872e-02, PNorm = 48.7158, GNorm = 2.1787, lr_0 = 5.2934e-04
Loss = 1.7023e-02, PNorm = 48.7437, GNorm = 2.5892, lr_0 = 5.2863e-04
Loss = 1.4282e-02, PNorm = 48.7718, GNorm = 2.2742, lr_0 = 5.2792e-04
Loss = 1.3663e-02, PNorm = 48.7989, GNorm = 2.6342, lr_0 = 5.2721e-04
Loss = 1.2992e-02, PNorm = 48.8241, GNorm = 2.4237, lr_0 = 5.2650e-04
Loss = 1.6264e-02, PNorm = 48.8398, GNorm = 6.0678, lr_0 = 5.2579e-04
Loss = 1.4104e-02, PNorm = 48.8600, GNorm = 2.8185, lr_0 = 5.2509e-04
Loss = 1.4169e-02, PNorm = 48.8778, GNorm = 2.3132, lr_0 = 5.2438e-04
Loss = 1.4401e-02, PNorm = 48.9002, GNorm = 3.5770, lr_0 = 5.2368e-04
Validation rmse = 2.162106
Validation R2 = -0.371960
Epoch 22
Train function
Loss = 1.2150e-02, PNorm = 48.9287, GNorm = 1.9178, lr_0 = 5.2291e-04
Loss = 1.1607e-02, PNorm = 48.9626, GNorm = 1.5661, lr_0 = 5.2221e-04
Loss = 1.2823e-02, PNorm = 48.9817, GNorm = 1.9901, lr_0 = 5.2151e-04
Loss = 1.3144e-02, PNorm = 49.0076, GNorm = 2.4578, lr_0 = 5.2081e-04
Loss = 1.2429e-02, PNorm = 49.0436, GNorm = 3.5512, lr_0 = 5.2011e-04
Loss = 1.1307e-02, PNorm = 49.0734, GNorm = 2.1702, lr_0 = 5.1941e-04
Loss = 1.3494e-02, PNorm = 49.0993, GNorm = 3.7796, lr_0 = 5.1871e-04
Loss = 1.1414e-02, PNorm = 49.1238, GNorm = 3.0341, lr_0 = 5.1802e-04
Loss = 1.2473e-02, PNorm = 49.1484, GNorm = 2.1360, lr_0 = 5.1732e-04
Loss = 1.4241e-02, PNorm = 49.1724, GNorm = 3.3925, lr_0 = 5.1663e-04
Loss = 1.3262e-02, PNorm = 49.2003, GNorm = 4.2316, lr_0 = 5.1593e-04
Loss = 1.2957e-02, PNorm = 49.2299, GNorm = 2.6648, lr_0 = 5.1524e-04
Loss = 1.5598e-02, PNorm = 49.2536, GNorm = 2.8061, lr_0 = 5.1455e-04
Loss = 1.3796e-02, PNorm = 49.2809, GNorm = 3.8756, lr_0 = 5.1386e-04
Loss = 1.5001e-02, PNorm = 49.3105, GNorm = 2.5541, lr_0 = 5.1317e-04
Loss = 1.3751e-02, PNorm = 49.3368, GNorm = 2.6856, lr_0 = 5.1248e-04
Loss = 1.2982e-02, PNorm = 49.3688, GNorm = 2.3494, lr_0 = 5.1180e-04
Loss = 1.3886e-02, PNorm = 49.3923, GNorm = 2.6214, lr_0 = 5.1111e-04
Loss = 1.5134e-02, PNorm = 49.4203, GNorm = 2.5326, lr_0 = 5.1042e-04
Loss = 1.5661e-02, PNorm = 49.4451, GNorm = 3.2865, lr_0 = 5.0974e-04
Loss = 1.3184e-02, PNorm = 49.4686, GNorm = 3.0543, lr_0 = 5.0905e-04
Loss = 1.2283e-02, PNorm = 49.4861, GNorm = 2.3185, lr_0 = 5.0837e-04
Loss = 1.3546e-02, PNorm = 49.5027, GNorm = 2.5489, lr_0 = 5.0769e-04
Validation rmse = 2.371444
Validation R2 = -0.650492
Epoch 23
Train function
Loss = 1.4189e-02, PNorm = 49.5221, GNorm = 2.5469, lr_0 = 5.0694e-04
Loss = 1.0019e-02, PNorm = 49.5467, GNorm = 1.8466, lr_0 = 5.0626e-04
Loss = 1.2305e-02, PNorm = 49.5788, GNorm = 2.4997, lr_0 = 5.0558e-04
Loss = 1.1532e-02, PNorm = 49.6050, GNorm = 2.8803, lr_0 = 5.0490e-04
Loss = 1.2114e-02, PNorm = 49.6347, GNorm = 3.3243, lr_0 = 5.0422e-04
Loss = 1.2627e-02, PNorm = 49.6624, GNorm = 2.9687, lr_0 = 5.0355e-04
Loss = 1.2548e-02, PNorm = 49.6855, GNorm = 4.7783, lr_0 = 5.0287e-04
Loss = 1.3062e-02, PNorm = 49.7071, GNorm = 3.4720, lr_0 = 5.0220e-04
Loss = 1.4421e-02, PNorm = 49.7310, GNorm = 2.1960, lr_0 = 5.0152e-04
Loss = 1.2821e-02, PNorm = 49.7601, GNorm = 3.0576, lr_0 = 5.0085e-04
Loss = 1.3296e-02, PNorm = 49.7834, GNorm = 2.5344, lr_0 = 5.0018e-04
Loss = 1.1640e-02, PNorm = 49.8063, GNorm = 2.2918, lr_0 = 4.9951e-04
Loss = 1.2048e-02, PNorm = 49.8271, GNorm = 2.3481, lr_0 = 4.9884e-04
Loss = 1.2554e-02, PNorm = 49.8536, GNorm = 3.9775, lr_0 = 4.9817e-04
Loss = 1.1552e-02, PNorm = 49.8799, GNorm = 2.9847, lr_0 = 4.9750e-04
Loss = 1.3242e-02, PNorm = 49.9064, GNorm = 5.0563, lr_0 = 4.9683e-04
Loss = 1.6039e-02, PNorm = 49.9355, GNorm = 3.3094, lr_0 = 4.9617e-04
Loss = 1.2594e-02, PNorm = 49.9714, GNorm = 2.4228, lr_0 = 4.9550e-04
Loss = 1.4279e-02, PNorm = 49.9878, GNorm = 4.1042, lr_0 = 4.9484e-04
Loss = 1.3669e-02, PNorm = 50.0119, GNorm = 2.6906, lr_0 = 4.9417e-04
Loss = 1.3161e-02, PNorm = 50.0349, GNorm = 2.7519, lr_0 = 4.9351e-04
Loss = 1.2882e-02, PNorm = 50.0543, GNorm = 2.9622, lr_0 = 4.9285e-04
Loss = 1.4730e-02, PNorm = 50.0732, GNorm = 3.0281, lr_0 = 4.9218e-04
Loss = 1.3167e-02, PNorm = 50.0988, GNorm = 2.6676, lr_0 = 4.9152e-04
Loss = 4.2985e-02, PNorm = 50.1014, GNorm = 3.5083, lr_0 = 4.9146e-04
Validation rmse = 2.491236
Validation R2 = -0.821449
Epoch 24
Train function
Loss = 1.1567e-02, PNorm = 50.1307, GNorm = 2.3926, lr_0 = 4.9080e-04
Loss = 1.1396e-02, PNorm = 50.1591, GNorm = 2.4456, lr_0 = 4.9014e-04
Loss = 1.3035e-02, PNorm = 50.1832, GNorm = 2.4227, lr_0 = 4.8948e-04
Loss = 1.3074e-02, PNorm = 50.2069, GNorm = 6.1633, lr_0 = 4.8883e-04
Loss = 1.0825e-02, PNorm = 50.2326, GNorm = 2.7725, lr_0 = 4.8817e-04
Loss = 1.0851e-02, PNorm = 50.2551, GNorm = 2.6218, lr_0 = 4.8752e-04
Loss = 1.0792e-02, PNorm = 50.2816, GNorm = 2.5151, lr_0 = 4.8686e-04
Loss = 1.5601e-02, PNorm = 50.3123, GNorm = 4.3234, lr_0 = 4.8621e-04
Loss = 1.1413e-02, PNorm = 50.3426, GNorm = 2.7269, lr_0 = 4.8556e-04
Loss = 1.1742e-02, PNorm = 50.3664, GNorm = 2.5185, lr_0 = 4.8490e-04
Loss = 1.0825e-02, PNorm = 50.3920, GNorm = 2.5745, lr_0 = 4.8425e-04
Loss = 1.2287e-02, PNorm = 50.4178, GNorm = 2.4647, lr_0 = 4.8360e-04
Loss = 1.3982e-02, PNorm = 50.4394, GNorm = 4.1732, lr_0 = 4.8296e-04
Loss = 1.1241e-02, PNorm = 50.4605, GNorm = 2.7303, lr_0 = 4.8231e-04
Loss = 1.2262e-02, PNorm = 50.4808, GNorm = 2.1185, lr_0 = 4.8166e-04
Loss = 1.1721e-02, PNorm = 50.5004, GNorm = 2.8569, lr_0 = 4.8101e-04
Loss = 1.2644e-02, PNorm = 50.5135, GNorm = 3.1453, lr_0 = 4.8037e-04
Loss = 1.3269e-02, PNorm = 50.5315, GNorm = 2.9028, lr_0 = 4.7972e-04
Loss = 1.2155e-02, PNorm = 50.5490, GNorm = 2.5972, lr_0 = 4.7908e-04
Loss = 1.1395e-02, PNorm = 50.5686, GNorm = 2.0388, lr_0 = 4.7844e-04
Loss = 1.1153e-02, PNorm = 50.5870, GNorm = 2.2822, lr_0 = 4.7780e-04
Loss = 1.4399e-02, PNorm = 50.6131, GNorm = 4.0284, lr_0 = 4.7715e-04
Loss = 1.2492e-02, PNorm = 50.6419, GNorm = 4.8827, lr_0 = 4.7651e-04
Validation rmse = 2.500443
Validation R2 = -0.834939
Epoch 25
Train function
Loss = 1.0858e-02, PNorm = 50.6687, GNorm = 2.1082, lr_0 = 4.7587e-04
Loss = 1.0375e-02, PNorm = 50.6985, GNorm = 4.1768, lr_0 = 4.7524e-04
Loss = 1.0268e-02, PNorm = 50.7264, GNorm = 3.7314, lr_0 = 4.7460e-04
Loss = 1.1419e-02, PNorm = 50.7450, GNorm = 2.9395, lr_0 = 4.7396e-04
Loss = 1.0107e-02, PNorm = 50.7649, GNorm = 2.7300, lr_0 = 4.7333e-04
Loss = 9.9330e-03, PNorm = 50.7854, GNorm = 2.6467, lr_0 = 4.7269e-04
Loss = 1.1385e-02, PNorm = 50.8106, GNorm = 4.4096, lr_0 = 4.7206e-04
Loss = 1.2495e-02, PNorm = 50.8341, GNorm = 2.8618, lr_0 = 4.7142e-04
Loss = 1.0651e-02, PNorm = 50.8579, GNorm = 2.5317, lr_0 = 4.7079e-04
Loss = 1.0167e-02, PNorm = 50.8794, GNorm = 2.6007, lr_0 = 4.7016e-04
Loss = 1.0286e-02, PNorm = 50.9087, GNorm = 2.2325, lr_0 = 4.6953e-04
Loss = 1.0817e-02, PNorm = 50.9287, GNorm = 3.0638, lr_0 = 4.6890e-04
Loss = 1.2831e-02, PNorm = 50.9511, GNorm = 5.3710, lr_0 = 4.6827e-04
Loss = 1.1932e-02, PNorm = 50.9715, GNorm = 3.5789, lr_0 = 4.6764e-04
Loss = 1.1739e-02, PNorm = 50.9919, GNorm = 6.2744, lr_0 = 4.6701e-04
Loss = 1.0908e-02, PNorm = 51.0177, GNorm = 3.9006, lr_0 = 4.6639e-04
Loss = 1.3987e-02, PNorm = 51.0410, GNorm = 5.3207, lr_0 = 4.6576e-04
Loss = 1.1316e-02, PNorm = 51.0621, GNorm = 2.3069, lr_0 = 4.6514e-04
Loss = 1.1703e-02, PNorm = 51.0804, GNorm = 3.2843, lr_0 = 4.6451e-04
Loss = 1.2280e-02, PNorm = 51.0988, GNorm = 3.1988, lr_0 = 4.6389e-04
Loss = 1.1771e-02, PNorm = 51.1200, GNorm = 2.6472, lr_0 = 4.6327e-04
Loss = 1.2421e-02, PNorm = 51.1435, GNorm = 2.9892, lr_0 = 4.6264e-04
Loss = 1.2704e-02, PNorm = 51.1642, GNorm = 2.0712, lr_0 = 4.6202e-04
Validation rmse = 2.694972
Validation R2 = -1.131552
Epoch 26
Train function
Loss = 6.0127e-03, PNorm = 51.1903, GNorm = 1.6160, lr_0 = 4.6134e-04
Loss = 9.8934e-03, PNorm = 51.2173, GNorm = 2.8693, lr_0 = 4.6072e-04
Loss = 1.0186e-02, PNorm = 51.2466, GNorm = 4.6116, lr_0 = 4.6011e-04
Loss = 1.0537e-02, PNorm = 51.2763, GNorm = 2.3087, lr_0 = 4.5949e-04
Loss = 1.0715e-02, PNorm = 51.3051, GNorm = 2.5588, lr_0 = 4.5887e-04
Loss = 1.0493e-02, PNorm = 51.3265, GNorm = 2.5531, lr_0 = 4.5826e-04
Loss = 1.2147e-02, PNorm = 51.3507, GNorm = 2.9361, lr_0 = 4.5764e-04
Loss = 1.1632e-02, PNorm = 51.3703, GNorm = 2.8671, lr_0 = 4.5703e-04
Loss = 1.0703e-02, PNorm = 51.3916, GNorm = 2.7661, lr_0 = 4.5641e-04
Loss = 1.0587e-02, PNorm = 51.4152, GNorm = 2.2681, lr_0 = 4.5580e-04
Loss = 1.0161e-02, PNorm = 51.4340, GNorm = 2.3056, lr_0 = 4.5519e-04
Loss = 9.6626e-03, PNorm = 51.4547, GNorm = 2.0803, lr_0 = 4.5458e-04
Loss = 9.4057e-03, PNorm = 51.4704, GNorm = 2.7236, lr_0 = 4.5397e-04
Loss = 9.8810e-03, PNorm = 51.4802, GNorm = 2.6110, lr_0 = 4.5336e-04
Loss = 1.1331e-02, PNorm = 51.4973, GNorm = 3.0928, lr_0 = 4.5275e-04
Loss = 1.1972e-02, PNorm = 51.5208, GNorm = 3.8835, lr_0 = 4.5214e-04
Loss = 1.1852e-02, PNorm = 51.5417, GNorm = 2.7917, lr_0 = 4.5154e-04
Loss = 1.0465e-02, PNorm = 51.5624, GNorm = 4.5521, lr_0 = 4.5093e-04
Loss = 1.0820e-02, PNorm = 51.5820, GNorm = 4.5874, lr_0 = 4.5033e-04
Loss = 1.2714e-02, PNorm = 51.6012, GNorm = 3.6779, lr_0 = 4.4972e-04
Loss = 1.1530e-02, PNorm = 51.6204, GNorm = 2.5064, lr_0 = 4.4912e-04
Loss = 1.2514e-02, PNorm = 51.6472, GNorm = 4.0434, lr_0 = 4.4852e-04
Loss = 1.0396e-02, PNorm = 51.6749, GNorm = 3.1008, lr_0 = 4.4791e-04
Loss = 1.2545e-02, PNorm = 51.6962, GNorm = 2.1797, lr_0 = 4.4731e-04
Validation rmse = 2.402577
Validation R2 = -0.694111
Epoch 27
Train function
Loss = 1.0857e-02, PNorm = 51.7174, GNorm = 3.0857, lr_0 = 4.4665e-04
Loss = 1.1070e-02, PNorm = 51.7400, GNorm = 3.7573, lr_0 = 4.4605e-04
Loss = 1.0438e-02, PNorm = 51.7621, GNorm = 3.9673, lr_0 = 4.4546e-04
Loss = 9.4501e-03, PNorm = 51.7817, GNorm = 1.8962, lr_0 = 4.4486e-04
Loss = 1.0215e-02, PNorm = 51.8052, GNorm = 3.6226, lr_0 = 4.4426e-04
Loss = 1.0145e-02, PNorm = 51.8250, GNorm = 2.7855, lr_0 = 4.4367e-04
Loss = 9.9867e-03, PNorm = 51.8490, GNorm = 3.0294, lr_0 = 4.4307e-04
Loss = 8.9180e-03, PNorm = 51.8681, GNorm = 2.5381, lr_0 = 4.4248e-04
Loss = 1.1259e-02, PNorm = 51.8891, GNorm = 2.7008, lr_0 = 4.4188e-04
Loss = 8.9463e-03, PNorm = 51.9099, GNorm = 3.7285, lr_0 = 4.4129e-04
Loss = 1.0358e-02, PNorm = 51.9333, GNorm = 3.0768, lr_0 = 4.4070e-04
Loss = 1.2085e-02, PNorm = 51.9540, GNorm = 3.7035, lr_0 = 4.4011e-04
Loss = 9.8780e-03, PNorm = 51.9738, GNorm = 2.4927, lr_0 = 4.3952e-04
Loss = 1.2785e-02, PNorm = 51.9933, GNorm = 2.0313, lr_0 = 4.3893e-04
Loss = 1.1763e-02, PNorm = 52.0145, GNorm = 3.1418, lr_0 = 4.3834e-04
Loss = 1.0465e-02, PNorm = 52.0357, GNorm = 3.3054, lr_0 = 4.3775e-04
Loss = 1.1047e-02, PNorm = 52.0619, GNorm = 3.6527, lr_0 = 4.3716e-04
Loss = 9.1156e-03, PNorm = 52.0795, GNorm = 2.0859, lr_0 = 4.3657e-04
Loss = 9.7842e-03, PNorm = 52.1001, GNorm = 1.9989, lr_0 = 4.3599e-04
Loss = 8.7263e-03, PNorm = 52.1243, GNorm = 2.2222, lr_0 = 4.3540e-04
Loss = 1.0691e-02, PNorm = 52.1421, GNorm = 3.1291, lr_0 = 4.3482e-04
Loss = 1.0780e-02, PNorm = 52.1682, GNorm = 3.6956, lr_0 = 4.3424e-04
Loss = 1.1744e-02, PNorm = 52.1855, GNorm = 3.6408, lr_0 = 4.3365e-04
Validation rmse = 2.475685
Validation R2 = -0.798781
Epoch 28
Train function
Loss = 7.3155e-03, PNorm = 52.2071, GNorm = 2.1818, lr_0 = 4.3301e-04
Loss = 8.9155e-03, PNorm = 52.2278, GNorm = 2.1315, lr_0 = 4.3243e-04
Loss = 1.1228e-02, PNorm = 52.2494, GNorm = 2.7893, lr_0 = 4.3185e-04
Loss = 8.3822e-03, PNorm = 52.2679, GNorm = 2.4681, lr_0 = 4.3127e-04
Loss = 8.9063e-03, PNorm = 52.2839, GNorm = 3.2371, lr_0 = 4.3069e-04
Loss = 9.5985e-03, PNorm = 52.3031, GNorm = 3.0641, lr_0 = 4.3012e-04
Loss = 1.0083e-02, PNorm = 52.3234, GNorm = 3.4051, lr_0 = 4.2954e-04
Loss = 7.8120e-03, PNorm = 52.3391, GNorm = 2.3544, lr_0 = 4.2896e-04
Loss = 8.2029e-03, PNorm = 52.3536, GNorm = 2.1548, lr_0 = 4.2839e-04
Loss = 9.7915e-03, PNorm = 52.3714, GNorm = 3.6427, lr_0 = 4.2781e-04
Loss = 9.4124e-03, PNorm = 52.3922, GNorm = 2.9369, lr_0 = 4.2724e-04
Loss = 1.0822e-02, PNorm = 52.4094, GNorm = 2.7044, lr_0 = 4.2667e-04
Loss = 1.0251e-02, PNorm = 52.4239, GNorm = 3.2528, lr_0 = 4.2609e-04
Loss = 9.8208e-03, PNorm = 52.4426, GNorm = 2.9461, lr_0 = 4.2552e-04
Loss = 9.5575e-03, PNorm = 52.4693, GNorm = 2.7743, lr_0 = 4.2495e-04
Loss = 1.0394e-02, PNorm = 52.4839, GNorm = 2.6863, lr_0 = 4.2438e-04
Loss = 8.8780e-03, PNorm = 52.5022, GNorm = 2.1236, lr_0 = 4.2381e-04
Loss = 1.0153e-02, PNorm = 52.5228, GNorm = 2.9640, lr_0 = 4.2324e-04
Loss = 9.8468e-03, PNorm = 52.5463, GNorm = 4.9557, lr_0 = 4.2267e-04
Loss = 9.4890e-03, PNorm = 52.5662, GNorm = 2.6298, lr_0 = 4.2211e-04
Loss = 1.0470e-02, PNorm = 52.5829, GNorm = 3.4746, lr_0 = 4.2154e-04
Loss = 8.9352e-03, PNorm = 52.6055, GNorm = 2.9844, lr_0 = 4.2098e-04
Loss = 1.1182e-02, PNorm = 52.6234, GNorm = 2.6088, lr_0 = 4.2041e-04
Loss = 1.0452e-02, PNorm = 52.6400, GNorm = 2.9676, lr_0 = 4.1985e-04
Validation rmse = 2.828889
Validation R2 = -1.348656
Epoch 29
Train function
Loss = 7.9321e-03, PNorm = 52.6622, GNorm = 2.2464, lr_0 = 4.1923e-04
Loss = 9.5782e-03, PNorm = 52.6805, GNorm = 3.6529, lr_0 = 4.1866e-04
Loss = 7.7456e-03, PNorm = 52.6976, GNorm = 2.1935, lr_0 = 4.1810e-04
Loss = 8.7724e-03, PNorm = 52.7224, GNorm = 2.0610, lr_0 = 4.1754e-04
Loss = 9.7487e-03, PNorm = 52.7414, GNorm = 2.4745, lr_0 = 4.1698e-04
Loss = 9.4905e-03, PNorm = 52.7643, GNorm = 2.8194, lr_0 = 4.1642e-04
Loss = 8.4438e-03, PNorm = 52.7875, GNorm = 4.6053, lr_0 = 4.1586e-04
Loss = 9.1380e-03, PNorm = 52.8109, GNorm = 3.7883, lr_0 = 4.1531e-04
Loss = 9.6205e-03, PNorm = 52.8336, GNorm = 2.9796, lr_0 = 4.1475e-04
Loss = 7.9061e-03, PNorm = 52.8498, GNorm = 3.2264, lr_0 = 4.1419e-04
Loss = 9.2398e-03, PNorm = 52.8634, GNorm = 4.9524, lr_0 = 4.1364e-04
Loss = 1.0014e-02, PNorm = 52.8792, GNorm = 2.4315, lr_0 = 4.1308e-04
Loss = 9.4507e-03, PNorm = 52.8946, GNorm = 4.7964, lr_0 = 4.1253e-04
Loss = 8.7590e-03, PNorm = 52.9091, GNorm = 4.7703, lr_0 = 4.1197e-04
Loss = 1.0660e-02, PNorm = 52.9239, GNorm = 2.7584, lr_0 = 4.1142e-04
Loss = 8.8922e-03, PNorm = 52.9393, GNorm = 2.4725, lr_0 = 4.1087e-04
Loss = 1.0319e-02, PNorm = 52.9640, GNorm = 2.4885, lr_0 = 4.1032e-04
Loss = 9.5905e-03, PNorm = 52.9831, GNorm = 2.9218, lr_0 = 4.0977e-04
Loss = 1.0767e-02, PNorm = 52.9977, GNorm = 3.0355, lr_0 = 4.0922e-04
Loss = 9.3393e-03, PNorm = 53.0142, GNorm = 3.7902, lr_0 = 4.0867e-04
Loss = 1.0530e-02, PNorm = 53.0276, GNorm = 2.9213, lr_0 = 4.0812e-04
Loss = 9.7423e-03, PNorm = 53.0434, GNorm = 2.0573, lr_0 = 4.0757e-04
Loss = 9.6786e-03, PNorm = 53.0543, GNorm = 3.7435, lr_0 = 4.0702e-04
Validation rmse = 2.925287
Validation R2 = -1.511450
Epoch 30
Train function
Loss = 6.8184e-03, PNorm = 53.0692, GNorm = 3.2504, lr_0 = 4.0648e-04
Loss = 7.5504e-03, PNorm = 53.0883, GNorm = 2.9827, lr_0 = 4.0593e-04
Loss = 7.3009e-03, PNorm = 53.1103, GNorm = 3.6306, lr_0 = 4.0539e-04
Loss = 7.8483e-03, PNorm = 53.1288, GNorm = 2.5653, lr_0 = 4.0484e-04
Loss = 7.9426e-03, PNorm = 53.1493, GNorm = 2.9715, lr_0 = 4.0430e-04
Loss = 1.0026e-02, PNorm = 53.1697, GNorm = 4.0570, lr_0 = 4.0376e-04
Loss = 8.6605e-03, PNorm = 53.1909, GNorm = 2.4540, lr_0 = 4.0322e-04
Loss = 6.8033e-03, PNorm = 53.2036, GNorm = 2.1577, lr_0 = 4.0268e-04
Loss = 8.3323e-03, PNorm = 53.2205, GNorm = 2.6685, lr_0 = 4.0214e-04
Loss = 9.4916e-03, PNorm = 53.2380, GNorm = 2.7983, lr_0 = 4.0160e-04
Loss = 7.6053e-03, PNorm = 53.2567, GNorm = 2.9027, lr_0 = 4.0106e-04
Loss = 8.7600e-03, PNorm = 53.2694, GNorm = 3.2526, lr_0 = 4.0052e-04
Loss = 7.7575e-03, PNorm = 53.2819, GNorm = 2.6705, lr_0 = 3.9998e-04
Loss = 9.8713e-03, PNorm = 53.2978, GNorm = 5.8080, lr_0 = 3.9945e-04
Loss = 8.9036e-03, PNorm = 53.3123, GNorm = 3.8949, lr_0 = 3.9891e-04
Loss = 9.6428e-03, PNorm = 53.3330, GNorm = 2.1479, lr_0 = 3.9837e-04
Loss = 8.6442e-03, PNorm = 53.3531, GNorm = 3.8329, lr_0 = 3.9784e-04
Loss = 7.9578e-03, PNorm = 53.3670, GNorm = 3.9074, lr_0 = 3.9731e-04
Loss = 1.0160e-02, PNorm = 53.3844, GNorm = 2.4406, lr_0 = 3.9677e-04
Loss = 9.8453e-03, PNorm = 53.4015, GNorm = 3.0731, lr_0 = 3.9624e-04
Loss = 8.7944e-03, PNorm = 53.4195, GNorm = 3.8930, lr_0 = 3.9571e-04
Loss = 8.2600e-03, PNorm = 53.4364, GNorm = 3.0106, lr_0 = 3.9518e-04
Loss = 9.2236e-03, PNorm = 53.4506, GNorm = 3.0785, lr_0 = 3.9465e-04
Loss = 9.2406e-03, PNorm = 53.4606, GNorm = 2.7016, lr_0 = 3.9412e-04
Loss = 5.2320e-02, PNorm = 53.4623, GNorm = 5.9417, lr_0 = 3.9407e-04
Validation rmse = 3.135672
Validation R2 = -1.885684
Epoch 31
Train function
Loss = 7.5059e-03, PNorm = 53.4780, GNorm = 2.1823, lr_0 = 3.9354e-04
Loss = 7.8098e-03, PNorm = 53.4957, GNorm = 3.4394, lr_0 = 3.9301e-04
Loss = 8.1597e-03, PNorm = 53.5104, GNorm = 3.2503, lr_0 = 3.9248e-04
Loss = 7.3574e-03, PNorm = 53.5275, GNorm = 2.2903, lr_0 = 3.9195e-04
Loss = 6.9657e-03, PNorm = 53.5448, GNorm = 2.8764, lr_0 = 3.9143e-04
Loss = 7.5592e-03, PNorm = 53.5610, GNorm = 2.2048, lr_0 = 3.9090e-04
Loss = 7.1333e-03, PNorm = 53.5752, GNorm = 5.0520, lr_0 = 3.9038e-04
Loss = 8.1457e-03, PNorm = 53.5901, GNorm = 3.4532, lr_0 = 3.8986e-04
Loss = 8.4171e-03, PNorm = 53.6065, GNorm = 2.2443, lr_0 = 3.8933e-04
Loss = 8.7066e-03, PNorm = 53.6248, GNorm = 5.1384, lr_0 = 3.8881e-04
Loss = 7.4630e-03, PNorm = 53.6434, GNorm = 2.9701, lr_0 = 3.8829e-04
Loss = 7.8708e-03, PNorm = 53.6620, GNorm = 2.2939, lr_0 = 3.8777e-04
Loss = 7.2708e-03, PNorm = 53.6815, GNorm = 4.0760, lr_0 = 3.8725e-04
Loss = 7.8594e-03, PNorm = 53.6946, GNorm = 2.7443, lr_0 = 3.8673e-04
Loss = 1.0277e-02, PNorm = 53.7069, GNorm = 2.8607, lr_0 = 3.8621e-04
Loss = 8.8108e-03, PNorm = 53.7239, GNorm = 2.7603, lr_0 = 3.8569e-04
Loss = 8.3715e-03, PNorm = 53.7450, GNorm = 3.1185, lr_0 = 3.8517e-04
Loss = 6.9143e-03, PNorm = 53.7610, GNorm = 2.4967, lr_0 = 3.8466e-04
Loss = 8.7426e-03, PNorm = 53.7698, GNorm = 3.2308, lr_0 = 3.8414e-04
Loss = 8.5012e-03, PNorm = 53.7798, GNorm = 2.3395, lr_0 = 3.8362e-04
Loss = 9.2567e-03, PNorm = 53.7934, GNorm = 2.8370, lr_0 = 3.8311e-04
Loss = 7.4781e-03, PNorm = 53.8066, GNorm = 2.8507, lr_0 = 3.8260e-04
Loss = 8.4459e-03, PNorm = 53.8220, GNorm = 3.0461, lr_0 = 3.8208e-04
Validation rmse = 2.858253
Validation R2 = -1.397666
Epoch 32
Train function
Loss = 6.1097e-03, PNorm = 53.8390, GNorm = 2.1365, lr_0 = 3.8152e-04
Loss = 7.5516e-03, PNorm = 53.8581, GNorm = 1.8939, lr_0 = 3.8101e-04
Loss = 6.8881e-03, PNorm = 53.8753, GNorm = 3.3862, lr_0 = 3.8050e-04
Loss = 7.6480e-03, PNorm = 53.8924, GNorm = 3.3485, lr_0 = 3.7999e-04
Loss = 7.4793e-03, PNorm = 53.9121, GNorm = 2.4575, lr_0 = 3.7948e-04
Loss = 7.7988e-03, PNorm = 53.9340, GNorm = 3.4667, lr_0 = 3.7897e-04
Loss = 7.3161e-03, PNorm = 53.9515, GNorm = 3.1495, lr_0 = 3.7846e-04
Loss = 6.6393e-03, PNorm = 53.9685, GNorm = 1.9877, lr_0 = 3.7795e-04
Loss = 6.1117e-03, PNorm = 53.9822, GNorm = 2.5093, lr_0 = 3.7744e-04
Loss = 6.6950e-03, PNorm = 53.9947, GNorm = 2.8746, lr_0 = 3.7694e-04
Loss = 7.3577e-03, PNorm = 54.0094, GNorm = 3.3152, lr_0 = 3.7643e-04
Loss = 7.0707e-03, PNorm = 54.0234, GNorm = 4.0372, lr_0 = 3.7593e-04
Loss = 8.2392e-03, PNorm = 54.0359, GNorm = 4.4160, lr_0 = 3.7542e-04
Loss = 7.4941e-03, PNorm = 54.0503, GNorm = 2.5600, lr_0 = 3.7492e-04
Loss = 7.4972e-03, PNorm = 54.0666, GNorm = 2.9004, lr_0 = 3.7441e-04
Loss = 7.4696e-03, PNorm = 54.0803, GNorm = 2.3204, lr_0 = 3.7391e-04
Loss = 7.2789e-03, PNorm = 54.0936, GNorm = 2.6268, lr_0 = 3.7341e-04
Loss = 9.0052e-03, PNorm = 54.1068, GNorm = 3.7630, lr_0 = 3.7291e-04
Loss = 7.4934e-03, PNorm = 54.1177, GNorm = 2.5066, lr_0 = 3.7241e-04
Loss = 8.5705e-03, PNorm = 54.1310, GNorm = 2.9933, lr_0 = 3.7191e-04
Loss = 7.5105e-03, PNorm = 54.1457, GNorm = 3.7524, lr_0 = 3.7141e-04
Loss = 8.8144e-03, PNorm = 54.1613, GNorm = 2.4211, lr_0 = 3.7091e-04
Loss = 8.2316e-03, PNorm = 54.1749, GNorm = 3.6341, lr_0 = 3.7041e-04
Validation rmse = 3.117179
Validation R2 = -1.851748
Epoch 33
Train function
Loss = 7.5130e-03, PNorm = 54.1906, GNorm = 1.9479, lr_0 = 3.6987e-04
Loss = 6.4104e-03, PNorm = 54.2085, GNorm = 2.0839, lr_0 = 3.6937e-04
Loss = 6.5110e-03, PNorm = 54.2257, GNorm = 2.1637, lr_0 = 3.6888e-04
Loss = 7.4279e-03, PNorm = 54.2437, GNorm = 3.6222, lr_0 = 3.6838e-04
Loss = 7.0514e-03, PNorm = 54.2578, GNorm = 4.3000, lr_0 = 3.6789e-04
Loss = 6.4421e-03, PNorm = 54.2748, GNorm = 2.0945, lr_0 = 3.6739e-04
Loss = 5.9207e-03, PNorm = 54.2898, GNorm = 2.6862, lr_0 = 3.6690e-04
Loss = 6.9098e-03, PNorm = 54.3044, GNorm = 3.2514, lr_0 = 3.6641e-04
Loss = 8.0765e-03, PNorm = 54.3216, GNorm = 2.8501, lr_0 = 3.6592e-04
Loss = 7.2303e-03, PNorm = 54.3344, GNorm = 4.4706, lr_0 = 3.6543e-04
Loss = 7.7802e-03, PNorm = 54.3521, GNorm = 4.2879, lr_0 = 3.6494e-04
Loss = 6.8130e-03, PNorm = 54.3667, GNorm = 4.5062, lr_0 = 3.6445e-04
Loss = 7.1665e-03, PNorm = 54.3817, GNorm = 2.7305, lr_0 = 3.6396e-04
Loss = 6.5607e-03, PNorm = 54.3952, GNorm = 3.7850, lr_0 = 3.6347e-04
Loss = 8.4100e-03, PNorm = 54.4081, GNorm = 4.8021, lr_0 = 3.6298e-04
Loss = 6.6411e-03, PNorm = 54.4211, GNorm = 4.4206, lr_0 = 3.6249e-04
Loss = 7.3889e-03, PNorm = 54.4375, GNorm = 2.8247, lr_0 = 3.6201e-04
Loss = 7.2311e-03, PNorm = 54.4502, GNorm = 2.3661, lr_0 = 3.6152e-04
Loss = 7.8795e-03, PNorm = 54.4642, GNorm = 3.2449, lr_0 = 3.6104e-04
Loss = 7.3014e-03, PNorm = 54.4793, GNorm = 3.9437, lr_0 = 3.6055e-04
Loss = 7.8834e-03, PNorm = 54.4931, GNorm = 2.8503, lr_0 = 3.6007e-04
Loss = 7.3892e-03, PNorm = 54.5013, GNorm = 3.4134, lr_0 = 3.5959e-04
Loss = 6.8869e-03, PNorm = 54.5137, GNorm = 3.2048, lr_0 = 3.5910e-04
Loss = 7.3262e-03, PNorm = 54.5264, GNorm = 3.3363, lr_0 = 3.5862e-04
Validation rmse = 3.479482
Validation R2 = -2.553176
Epoch 34
Train function
Loss = 6.3497e-03, PNorm = 54.5431, GNorm = 3.4074, lr_0 = 3.5809e-04
Loss = 6.3799e-03, PNorm = 54.5548, GNorm = 3.2170, lr_0 = 3.5761e-04
Loss = 6.6330e-03, PNorm = 54.5699, GNorm = 2.1974, lr_0 = 3.5713e-04
Loss = 6.5580e-03, PNorm = 54.5836, GNorm = 2.1801, lr_0 = 3.5665e-04
Loss = 6.8087e-03, PNorm = 54.5977, GNorm = 2.6646, lr_0 = 3.5617e-04
Loss = 7.0009e-03, PNorm = 54.6136, GNorm = 2.8345, lr_0 = 3.5570e-04
Loss = 6.7974e-03, PNorm = 54.6299, GNorm = 3.0117, lr_0 = 3.5522e-04
Loss = 5.8893e-03, PNorm = 54.6427, GNorm = 2.7344, lr_0 = 3.5474e-04
Loss = 6.2735e-03, PNorm = 54.6542, GNorm = 1.8509, lr_0 = 3.5427e-04
Loss = 6.8778e-03, PNorm = 54.6650, GNorm = 3.6468, lr_0 = 3.5379e-04
Loss = 7.7743e-03, PNorm = 54.6739, GNorm = 3.6626, lr_0 = 3.5332e-04
Loss = 6.1690e-03, PNorm = 54.6885, GNorm = 3.4286, lr_0 = 3.5284e-04
Loss = 5.7903e-03, PNorm = 54.7004, GNorm = 3.0415, lr_0 = 3.5237e-04
Loss = 6.4453e-03, PNorm = 54.7119, GNorm = 2.7699, lr_0 = 3.5190e-04
Loss = 5.8373e-03, PNorm = 54.7248, GNorm = 2.9975, lr_0 = 3.5142e-04
Loss = 5.9754e-03, PNorm = 54.7336, GNorm = 3.5291, lr_0 = 3.5095e-04
Loss = 7.2368e-03, PNorm = 54.7496, GNorm = 2.2802, lr_0 = 3.5048e-04
Loss = 5.0694e-03, PNorm = 54.7617, GNorm = 3.5076, lr_0 = 3.5001e-04
Loss = 7.2275e-03, PNorm = 54.7768, GNorm = 3.4721, lr_0 = 3.4954e-04
Loss = 7.2547e-03, PNorm = 54.7911, GNorm = 4.3767, lr_0 = 3.4907e-04
Loss = 8.4450e-03, PNorm = 54.8079, GNorm = 4.5140, lr_0 = 3.4860e-04
Loss = 6.7029e-03, PNorm = 54.8241, GNorm = 3.5483, lr_0 = 3.4814e-04
Loss = 7.8256e-03, PNorm = 54.8355, GNorm = 2.2587, lr_0 = 3.4767e-04
Validation rmse = 3.300589
Validation R2 = -2.197204
Epoch 35
Train function
Loss = 4.8841e-03, PNorm = 54.8486, GNorm = 2.0959, lr_0 = 3.4720e-04
Loss = 5.9008e-03, PNorm = 54.8599, GNorm = 2.5182, lr_0 = 3.4674e-04
Loss = 5.9486e-03, PNorm = 54.8698, GNorm = 3.3447, lr_0 = 3.4627e-04
Loss = 5.7282e-03, PNorm = 54.8821, GNorm = 3.4487, lr_0 = 3.4581e-04
Loss = 5.5972e-03, PNorm = 54.8968, GNorm = 4.8110, lr_0 = 3.4534e-04
Loss = 6.1830e-03, PNorm = 54.9081, GNorm = 4.4283, lr_0 = 3.4488e-04
Loss = 6.7068e-03, PNorm = 54.9216, GNorm = 2.6850, lr_0 = 3.4442e-04
Loss = 6.6691e-03, PNorm = 54.9345, GNorm = 3.3927, lr_0 = 3.4395e-04
Loss = 5.8314e-03, PNorm = 54.9482, GNorm = 3.1463, lr_0 = 3.4349e-04
Loss = 6.3114e-03, PNorm = 54.9605, GNorm = 4.0942, lr_0 = 3.4303e-04
Loss = 6.3140e-03, PNorm = 54.9720, GNorm = 3.5980, lr_0 = 3.4257e-04
Loss = 8.0240e-03, PNorm = 54.9864, GNorm = 2.6790, lr_0 = 3.4211e-04
Loss = 6.8617e-03, PNorm = 55.0034, GNorm = 3.3157, lr_0 = 3.4165e-04
Loss = 6.1186e-03, PNorm = 55.0142, GNorm = 3.7085, lr_0 = 3.4120e-04
Loss = 5.5488e-03, PNorm = 55.0289, GNorm = 2.2999, lr_0 = 3.4074e-04
Loss = 6.4139e-03, PNorm = 55.0426, GNorm = 3.9812, lr_0 = 3.4028e-04
Loss = 6.6520e-03, PNorm = 55.0566, GNorm = 3.0215, lr_0 = 3.3982e-04
Loss = 6.6704e-03, PNorm = 55.0688, GNorm = 2.5349, lr_0 = 3.3937e-04
Loss = 5.5917e-03, PNorm = 55.0792, GNorm = 3.1201, lr_0 = 3.3891e-04
Loss = 7.0901e-03, PNorm = 55.0918, GNorm = 5.3765, lr_0 = 3.3846e-04
Loss = 7.7630e-03, PNorm = 55.1050, GNorm = 2.9045, lr_0 = 3.3800e-04
Loss = 8.6066e-03, PNorm = 55.1232, GNorm = 2.6737, lr_0 = 3.3755e-04
Loss = 7.7502e-03, PNorm = 55.1345, GNorm = 5.2725, lr_0 = 3.3710e-04
Loss = 7.6978e-03, PNorm = 55.1509, GNorm = 4.1146, lr_0 = 3.3664e-04
Validation rmse = 3.352647
Validation R2 = -2.298855
Epoch 36
Train function
Loss = 6.8761e-03, PNorm = 55.1652, GNorm = 3.4906, lr_0 = 3.3615e-04
Loss = 5.4776e-03, PNorm = 55.1765, GNorm = 2.5449, lr_0 = 3.3570e-04
Loss = 5.1252e-03, PNorm = 55.1914, GNorm = 1.4712, lr_0 = 3.3525e-04
Loss = 6.2690e-03, PNorm = 55.2035, GNorm = 3.1529, lr_0 = 3.3480e-04
Loss = 6.4429e-03, PNorm = 55.2169, GNorm = 2.9146, lr_0 = 3.3435e-04
Loss = 5.6126e-03, PNorm = 55.2296, GNorm = 4.4875, lr_0 = 3.3390e-04
Loss = 5.9187e-03, PNorm = 55.2411, GNorm = 2.9051, lr_0 = 3.3345e-04
Loss = 5.9674e-03, PNorm = 55.2560, GNorm = 2.9251, lr_0 = 3.3300e-04
Loss = 4.6229e-03, PNorm = 55.2679, GNorm = 2.5039, lr_0 = 3.3256e-04
Loss = 5.4096e-03, PNorm = 55.2775, GNorm = 4.7669, lr_0 = 3.3211e-04
Loss = 6.9258e-03, PNorm = 55.2921, GNorm = 4.1545, lr_0 = 3.3167e-04
Loss = 5.4363e-03, PNorm = 55.3062, GNorm = 2.0849, lr_0 = 3.3122e-04
Loss = 5.5469e-03, PNorm = 55.3148, GNorm = 3.1189, lr_0 = 3.3078e-04
Loss = 5.6931e-03, PNorm = 55.3219, GNorm = 3.5932, lr_0 = 3.3033e-04
Loss = 6.2825e-03, PNorm = 55.3334, GNorm = 2.7075, lr_0 = 3.2989e-04
Loss = 6.4496e-03, PNorm = 55.3457, GNorm = 4.8606, lr_0 = 3.2945e-04
Loss = 5.5416e-03, PNorm = 55.3540, GNorm = 3.9200, lr_0 = 3.2900e-04
Loss = 6.8276e-03, PNorm = 55.3629, GNorm = 7.4117, lr_0 = 3.2856e-04
Loss = 5.8033e-03, PNorm = 55.3733, GNorm = 2.5194, lr_0 = 3.2812e-04
Loss = 6.1408e-03, PNorm = 55.3855, GNorm = 3.8878, lr_0 = 3.2768e-04
Loss = 5.8572e-03, PNorm = 55.3978, GNorm = 2.6301, lr_0 = 3.2724e-04
Loss = 5.9814e-03, PNorm = 55.4076, GNorm = 2.7165, lr_0 = 3.2680e-04
Loss = 7.1300e-03, PNorm = 55.4171, GNorm = 3.7295, lr_0 = 3.2636e-04
Validation rmse = 3.407015
Validation R2 = -2.406713
Epoch 37
Train function
Loss = 4.8379e-03, PNorm = 55.4279, GNorm = 2.1523, lr_0 = 3.2588e-04
Loss = 5.2567e-03, PNorm = 55.4415, GNorm = 2.6175, lr_0 = 3.2545e-04
Loss = 4.8169e-03, PNorm = 55.4527, GNorm = 2.1127, lr_0 = 3.2501e-04
Loss = 5.0533e-03, PNorm = 55.4624, GNorm = 3.8024, lr_0 = 3.2457e-04
Loss = 4.9763e-03, PNorm = 55.4717, GNorm = 3.4861, lr_0 = 3.2414e-04
Loss = 5.9641e-03, PNorm = 55.4855, GNorm = 2.7114, lr_0 = 3.2370e-04
Loss = 4.6829e-03, PNorm = 55.4961, GNorm = 2.9113, lr_0 = 3.2327e-04
Loss = 4.8830e-03, PNorm = 55.5071, GNorm = 2.3404, lr_0 = 3.2283e-04
Loss = 5.5567e-03, PNorm = 55.5179, GNorm = 2.4182, lr_0 = 3.2240e-04
Loss = 4.9914e-03, PNorm = 55.5305, GNorm = 2.8110, lr_0 = 3.2197e-04
Loss = 5.3623e-03, PNorm = 55.5440, GNorm = 2.2199, lr_0 = 3.2154e-04
Loss = 5.2517e-03, PNorm = 55.5571, GNorm = 2.9818, lr_0 = 3.2111e-04
Loss = 5.0899e-03, PNorm = 55.5641, GNorm = 2.4169, lr_0 = 3.2067e-04
Loss = 6.6835e-03, PNorm = 55.5742, GNorm = 3.4715, lr_0 = 3.2024e-04
Loss = 4.8993e-03, PNorm = 55.5857, GNorm = 1.7891, lr_0 = 3.1981e-04
Loss = 5.4419e-03, PNorm = 55.5975, GNorm = 2.2265, lr_0 = 3.1939e-04
Loss = 5.4128e-03, PNorm = 55.6075, GNorm = 3.1968, lr_0 = 3.1896e-04
Loss = 7.5464e-03, PNorm = 55.6230, GNorm = 2.8212, lr_0 = 3.1853e-04
Loss = 5.5297e-03, PNorm = 55.6386, GNorm = 4.3801, lr_0 = 3.1810e-04
Loss = 5.1659e-03, PNorm = 55.6499, GNorm = 1.9374, lr_0 = 3.1767e-04
Loss = 5.8828e-03, PNorm = 55.6609, GNorm = 2.6640, lr_0 = 3.1725e-04
Loss = 6.5783e-03, PNorm = 55.6709, GNorm = 3.2480, lr_0 = 3.1682e-04
Loss = 5.8362e-03, PNorm = 55.6834, GNorm = 2.9302, lr_0 = 3.1640e-04
Validation rmse = 3.697162
Validation R2 = -3.011663
Epoch 38
Train function
Loss = 2.6833e-03, PNorm = 55.6970, GNorm = 1.6029, lr_0 = 3.1593e-04
Loss = 4.3579e-03, PNorm = 55.7078, GNorm = 2.4656, lr_0 = 3.1551e-04
Loss = 4.7496e-03, PNorm = 55.7195, GNorm = 2.2643, lr_0 = 3.1508e-04
Loss = 5.3808e-03, PNorm = 55.7299, GNorm = 3.1897, lr_0 = 3.1466e-04
Loss = 5.8207e-03, PNorm = 55.7428, GNorm = 3.5750, lr_0 = 3.1424e-04
Loss = 5.3499e-03, PNorm = 55.7570, GNorm = 2.8633, lr_0 = 3.1382e-04
Loss = 5.4257e-03, PNorm = 55.7702, GNorm = 2.4955, lr_0 = 3.1340e-04
Loss = 4.9851e-03, PNorm = 55.7798, GNorm = 4.0209, lr_0 = 3.1298e-04
Loss = 4.7667e-03, PNorm = 55.7904, GNorm = 2.1363, lr_0 = 3.1256e-04
Loss = 4.5279e-03, PNorm = 55.7978, GNorm = 2.8686, lr_0 = 3.1214e-04
Loss = 4.5072e-03, PNorm = 55.8082, GNorm = 2.8738, lr_0 = 3.1172e-04
Loss = 5.2671e-03, PNorm = 55.8184, GNorm = 3.0887, lr_0 = 3.1130e-04
Loss = 5.3116e-03, PNorm = 55.8251, GNorm = 2.6034, lr_0 = 3.1088e-04
Loss = 4.2154e-03, PNorm = 55.8342, GNorm = 1.9582, lr_0 = 3.1046e-04
Loss = 4.5556e-03, PNorm = 55.8411, GNorm = 1.8796, lr_0 = 3.1005e-04
Loss = 6.7391e-03, PNorm = 55.8499, GNorm = 4.6868, lr_0 = 3.0963e-04
Loss = 5.2206e-03, PNorm = 55.8582, GNorm = 2.6456, lr_0 = 3.0922e-04
Loss = 5.2693e-03, PNorm = 55.8672, GNorm = 3.2624, lr_0 = 3.0880e-04
Loss = 6.1621e-03, PNorm = 55.8771, GNorm = 1.9251, lr_0 = 3.0839e-04
Loss = 5.3369e-03, PNorm = 55.8872, GNorm = 2.4768, lr_0 = 3.0797e-04
Loss = 5.7559e-03, PNorm = 55.8980, GNorm = 3.8277, lr_0 = 3.0756e-04
Loss = 5.5012e-03, PNorm = 55.9094, GNorm = 2.7890, lr_0 = 3.0715e-04
Loss = 6.3608e-03, PNorm = 55.9196, GNorm = 2.9939, lr_0 = 3.0674e-04
Loss = 6.0315e-03, PNorm = 55.9310, GNorm = 2.6165, lr_0 = 3.0632e-04
Validation rmse = 3.385917
Validation R2 = -2.364652
Epoch 39
Train function
Loss = 5.0307e-03, PNorm = 55.9415, GNorm = 2.7358, lr_0 = 3.0587e-04
Loss = 5.1577e-03, PNorm = 55.9512, GNorm = 2.2798, lr_0 = 3.0546e-04
Loss = 5.1676e-03, PNorm = 55.9596, GNorm = 1.7151, lr_0 = 3.0505e-04
Loss = 4.9096e-03, PNorm = 55.9709, GNorm = 2.8372, lr_0 = 3.0464e-04
Loss = 4.6104e-03, PNorm = 55.9809, GNorm = 2.7041, lr_0 = 3.0423e-04
Loss = 4.4571e-03, PNorm = 55.9906, GNorm = 2.0828, lr_0 = 3.0383e-04
Loss = 4.0184e-03, PNorm = 56.0013, GNorm = 2.0410, lr_0 = 3.0342e-04
Loss = 5.4851e-03, PNorm = 56.0128, GNorm = 2.0228, lr_0 = 3.0301e-04
Loss = 4.8411e-03, PNorm = 56.0242, GNorm = 3.2631, lr_0 = 3.0260e-04
Loss = 5.2018e-03, PNorm = 56.0349, GNorm = 2.3197, lr_0 = 3.0220e-04
Loss = 4.9895e-03, PNorm = 56.0443, GNorm = 2.9719, lr_0 = 3.0179e-04
Loss = 5.1480e-03, PNorm = 56.0532, GNorm = 2.1791, lr_0 = 3.0139e-04
Loss = 5.5270e-03, PNorm = 56.0588, GNorm = 2.5763, lr_0 = 3.0098e-04
Loss = 3.8563e-03, PNorm = 56.0666, GNorm = 2.1843, lr_0 = 3.0058e-04
Loss = 5.0595e-03, PNorm = 56.0747, GNorm = 3.4614, lr_0 = 3.0018e-04
Loss = 5.0187e-03, PNorm = 56.0806, GNorm = 3.2208, lr_0 = 2.9977e-04
Loss = 7.6534e-03, PNorm = 56.0897, GNorm = 3.7390, lr_0 = 2.9937e-04
Loss = 5.0782e-03, PNorm = 56.1017, GNorm = 3.0987, lr_0 = 2.9897e-04
Loss = 4.1040e-03, PNorm = 56.1112, GNorm = 2.3289, lr_0 = 2.9857e-04
Loss = 4.2700e-03, PNorm = 56.1192, GNorm = 2.4813, lr_0 = 2.9817e-04
Loss = 4.0352e-03, PNorm = 56.1292, GNorm = 2.1096, lr_0 = 2.9777e-04
Loss = 4.8129e-03, PNorm = 56.1368, GNorm = 2.2900, lr_0 = 2.9737e-04
Loss = 4.8051e-03, PNorm = 56.1455, GNorm = 3.1188, lr_0 = 2.9697e-04
Validation rmse = 3.618610
Validation R2 = -2.843007
Epoch 40
Train function
Loss = 2.6928e-03, PNorm = 56.1558, GNorm = 1.6994, lr_0 = 2.9657e-04
Loss = 3.8790e-03, PNorm = 56.1652, GNorm = 1.8756, lr_0 = 2.9617e-04
Loss = 5.2503e-03, PNorm = 56.1739, GNorm = 2.3850, lr_0 = 2.9578e-04
Loss = 5.0825e-03, PNorm = 56.1814, GNorm = 2.9811, lr_0 = 2.9538e-04
Loss = 4.3106e-03, PNorm = 56.1936, GNorm = 2.9661, lr_0 = 2.9498e-04
Loss = 4.6406e-03, PNorm = 56.2057, GNorm = 1.8890, lr_0 = 2.9459e-04
Loss = 4.3003e-03, PNorm = 56.2156, GNorm = 2.7122, lr_0 = 2.9419e-04
Loss = 3.9965e-03, PNorm = 56.2258, GNorm = 3.5069, lr_0 = 2.9380e-04
Loss = 3.9699e-03, PNorm = 56.2354, GNorm = 2.5383, lr_0 = 2.9340e-04
Loss = 4.5955e-03, PNorm = 56.2422, GNorm = 3.8551, lr_0 = 2.9301e-04
Loss = 4.1788e-03, PNorm = 56.2494, GNorm = 1.3341, lr_0 = 2.9262e-04
Loss = 4.9523e-03, PNorm = 56.2585, GNorm = 2.0014, lr_0 = 2.9222e-04
Loss = 3.4653e-03, PNorm = 56.2702, GNorm = 2.0003, lr_0 = 2.9183e-04
Loss = 4.4082e-03, PNorm = 56.2786, GNorm = 2.4616, lr_0 = 2.9144e-04
Loss = 3.7441e-03, PNorm = 56.2826, GNorm = 3.2876, lr_0 = 2.9105e-04
Loss = 4.9701e-03, PNorm = 56.2926, GNorm = 3.5896, lr_0 = 2.9066e-04
Loss = 4.7724e-03, PNorm = 56.3041, GNorm = 3.0024, lr_0 = 2.9027e-04
Loss = 4.3771e-03, PNorm = 56.3160, GNorm = 4.4716, lr_0 = 2.8988e-04
Loss = 4.3015e-03, PNorm = 56.3265, GNorm = 2.0414, lr_0 = 2.8949e-04
Loss = 4.7025e-03, PNorm = 56.3347, GNorm = 4.5197, lr_0 = 2.8910e-04
Loss = 4.8729e-03, PNorm = 56.3419, GNorm = 3.2525, lr_0 = 2.8871e-04
Loss = 4.8972e-03, PNorm = 56.3513, GNorm = 3.6934, lr_0 = 2.8833e-04
Loss = 5.0325e-03, PNorm = 56.3596, GNorm = 2.9783, lr_0 = 2.8794e-04
Loss = 6.3479e-03, PNorm = 56.3679, GNorm = 3.8635, lr_0 = 2.8755e-04
Validation rmse = 3.522365
Validation R2 = -2.641298
Epoch 41
Train function
Loss = 4.0055e-03, PNorm = 56.3844, GNorm = 1.7333, lr_0 = 2.8713e-04
Loss = 4.4212e-03, PNorm = 56.3987, GNorm = 2.4117, lr_0 = 2.8674e-04
Loss = 4.2139e-03, PNorm = 56.4087, GNorm = 3.3996, lr_0 = 2.8636e-04
Loss = 3.6266e-03, PNorm = 56.4191, GNorm = 2.5568, lr_0 = 2.8597e-04
Loss = 3.6519e-03, PNorm = 56.4275, GNorm = 2.5851, lr_0 = 2.8559e-04
Loss = 3.8955e-03, PNorm = 56.4337, GNorm = 4.6694, lr_0 = 2.8521e-04
Loss = 4.6982e-03, PNorm = 56.4425, GNorm = 2.2721, lr_0 = 2.8482e-04
Loss = 3.8979e-03, PNorm = 56.4509, GNorm = 3.9477, lr_0 = 2.8444e-04
Loss = 4.5828e-03, PNorm = 56.4611, GNorm = 3.3939, lr_0 = 2.8406e-04
Loss = 4.2135e-03, PNorm = 56.4703, GNorm = 1.8746, lr_0 = 2.8368e-04
Loss = 3.9397e-03, PNorm = 56.4788, GNorm = 2.2380, lr_0 = 2.8330e-04
Loss = 5.4204e-03, PNorm = 56.4897, GNorm = 3.5163, lr_0 = 2.8292e-04
Loss = 5.0274e-03, PNorm = 56.4978, GNorm = 2.6819, lr_0 = 2.8254e-04
Loss = 5.3650e-03, PNorm = 56.5069, GNorm = 2.5909, lr_0 = 2.8216e-04
Loss = 5.6664e-03, PNorm = 56.5184, GNorm = 3.3189, lr_0 = 2.8178e-04
Loss = 4.4174e-03, PNorm = 56.5311, GNorm = 2.3912, lr_0 = 2.8140e-04
Loss = 4.6458e-03, PNorm = 56.5410, GNorm = 2.5180, lr_0 = 2.8103e-04
Loss = 4.6824e-03, PNorm = 56.5497, GNorm = 2.5858, lr_0 = 2.8065e-04
Loss = 4.5817e-03, PNorm = 56.5573, GNorm = 2.2214, lr_0 = 2.8027e-04
Loss = 3.9658e-03, PNorm = 56.5638, GNorm = 3.9449, lr_0 = 2.7990e-04
Loss = 4.8929e-03, PNorm = 56.5706, GNorm = 2.5720, lr_0 = 2.7952e-04
Loss = 4.9872e-03, PNorm = 56.5780, GNorm = 2.6830, lr_0 = 2.7915e-04
Loss = 4.4390e-03, PNorm = 56.5865, GNorm = 2.3489, lr_0 = 2.7877e-04
Validation rmse = 3.430155
Validation R2 = -2.453147
Epoch 42
Train function
Loss = 4.6421e-03, PNorm = 56.5965, GNorm = 3.4462, lr_0 = 2.7836e-04
Loss = 3.8152e-03, PNorm = 56.6034, GNorm = 2.6068, lr_0 = 2.7799e-04
Loss = 3.8941e-03, PNorm = 56.6108, GNorm = 2.6723, lr_0 = 2.7761e-04
Loss = 4.7630e-03, PNorm = 56.6218, GNorm = 3.7839, lr_0 = 2.7724e-04
Loss = 5.2653e-03, PNorm = 56.6342, GNorm = 2.6526, lr_0 = 2.7687e-04
Loss = 4.1938e-03, PNorm = 56.6456, GNorm = 3.3560, lr_0 = 2.7650e-04
Loss = 3.9813e-03, PNorm = 56.6519, GNorm = 1.9698, lr_0 = 2.7613e-04
Loss = 3.6349e-03, PNorm = 56.6574, GNorm = 3.0938, lr_0 = 2.7576e-04
Loss = 3.7104e-03, PNorm = 56.6655, GNorm = 2.3134, lr_0 = 2.7539e-04
Loss = 3.8975e-03, PNorm = 56.6761, GNorm = 3.1404, lr_0 = 2.7502e-04
Loss = 4.0453e-03, PNorm = 56.6860, GNorm = 2.5819, lr_0 = 2.7465e-04
Loss = 4.4095e-03, PNorm = 56.6921, GNorm = 2.4512, lr_0 = 2.7428e-04
Loss = 4.5944e-03, PNorm = 56.6995, GNorm = 3.2409, lr_0 = 2.7391e-04
Loss = 4.4326e-03, PNorm = 56.7065, GNorm = 2.5839, lr_0 = 2.7354e-04
Loss = 4.1179e-03, PNorm = 56.7135, GNorm = 3.1143, lr_0 = 2.7318e-04
Loss = 3.8760e-03, PNorm = 56.7208, GNorm = 3.7967, lr_0 = 2.7281e-04
Loss = 3.8010e-03, PNorm = 56.7282, GNorm = 2.6480, lr_0 = 2.7244e-04
Loss = 4.0131e-03, PNorm = 56.7356, GNorm = 3.2768, lr_0 = 2.7208e-04
Loss = 3.4750e-03, PNorm = 56.7432, GNorm = 2.4904, lr_0 = 2.7171e-04
Loss = 3.9480e-03, PNorm = 56.7526, GNorm = 1.9494, lr_0 = 2.7135e-04
Loss = 4.7462e-03, PNorm = 56.7607, GNorm = 4.1178, lr_0 = 2.7098e-04
Loss = 4.7386e-03, PNorm = 56.7689, GNorm = 2.7675, lr_0 = 2.7062e-04
Loss = 4.4305e-03, PNorm = 56.7760, GNorm = 3.1242, lr_0 = 2.7026e-04
Loss = 4.3148e-03, PNorm = 56.7822, GNorm = 3.9890, lr_0 = 2.6990e-04
Loss = 1.2418e-02, PNorm = 56.7829, GNorm = 5.4641, lr_0 = 2.6986e-04
Validation rmse = 3.816335
Validation R2 = -3.274453
Epoch 43
Train function
Loss = 3.4290e-03, PNorm = 56.7885, GNorm = 3.2641, lr_0 = 2.6950e-04
Loss = 2.8082e-03, PNorm = 56.7949, GNorm = 2.0317, lr_0 = 2.6914e-04
Loss = 2.9736e-03, PNorm = 56.8011, GNorm = 2.8902, lr_0 = 2.6877e-04
Loss = 3.4479e-03, PNorm = 56.8071, GNorm = 2.7422, lr_0 = 2.6841e-04
Loss = 5.1179e-03, PNorm = 56.8156, GNorm = 1.6756, lr_0 = 2.6805e-04
Loss = 3.5474e-03, PNorm = 56.8242, GNorm = 2.7367, lr_0 = 2.6769e-04
Loss = 3.5270e-03, PNorm = 56.8322, GNorm = 3.5141, lr_0 = 2.6733e-04
Loss = 3.6947e-03, PNorm = 56.8396, GNorm = 1.5218, lr_0 = 2.6698e-04
Loss = 4.2413e-03, PNorm = 56.8476, GNorm = 2.1082, lr_0 = 2.6662e-04
Loss = 3.9498e-03, PNorm = 56.8561, GNorm = 3.7968, lr_0 = 2.6626e-04
Loss = 3.8675e-03, PNorm = 56.8644, GNorm = 1.8714, lr_0 = 2.6590e-04
Loss = 3.6413e-03, PNorm = 56.8715, GNorm = 2.9545, lr_0 = 2.6555e-04
Loss = 4.1426e-03, PNorm = 56.8784, GNorm = 2.2826, lr_0 = 2.6519e-04
Loss = 4.1715e-03, PNorm = 56.8845, GNorm = 2.3825, lr_0 = 2.6483e-04
Loss = 4.1486e-03, PNorm = 56.8918, GNorm = 3.0275, lr_0 = 2.6448e-04
Loss = 4.8032e-03, PNorm = 56.8996, GNorm = 3.5951, lr_0 = 2.6412e-04
Loss = 4.3998e-03, PNorm = 56.9088, GNorm = 3.1124, lr_0 = 2.6377e-04
Loss = 3.5711e-03, PNorm = 56.9175, GNorm = 2.5979, lr_0 = 2.6342e-04
Loss = 4.2479e-03, PNorm = 56.9272, GNorm = 2.4948, lr_0 = 2.6306e-04
Loss = 5.0992e-03, PNorm = 56.9362, GNorm = 2.6886, lr_0 = 2.6271e-04
Loss = 3.8496e-03, PNorm = 56.9441, GNorm = 4.1397, lr_0 = 2.6236e-04
Loss = 4.7141e-03, PNorm = 56.9518, GNorm = 2.7883, lr_0 = 2.6200e-04
Loss = 4.1719e-03, PNorm = 56.9611, GNorm = 2.8015, lr_0 = 2.6165e-04
Validation rmse = 3.601815
Validation R2 = -2.807417
Epoch 44
Train function
Loss = 4.3191e-03, PNorm = 56.9717, GNorm = 3.2182, lr_0 = 2.6127e-04
Loss = 3.7859e-03, PNorm = 56.9808, GNorm = 2.2232, lr_0 = 2.6092e-04
Loss = 4.1886e-03, PNorm = 56.9865, GNorm = 2.8802, lr_0 = 2.6057e-04
Loss = 3.6614e-03, PNorm = 56.9932, GNorm = 2.9511, lr_0 = 2.6022e-04
Loss = 3.7835e-03, PNorm = 57.0022, GNorm = 2.2260, lr_0 = 2.5987e-04
Loss = 3.2968e-03, PNorm = 57.0105, GNorm = 4.4703, lr_0 = 2.5952e-04
Loss = 3.7338e-03, PNorm = 57.0196, GNorm = 1.7441, lr_0 = 2.5917e-04
Loss = 3.8575e-03, PNorm = 57.0286, GNorm = 2.3555, lr_0 = 2.5882e-04
Loss = 2.9190e-03, PNorm = 57.0367, GNorm = 2.9575, lr_0 = 2.5848e-04
Loss = 3.2872e-03, PNorm = 57.0428, GNorm = 1.9004, lr_0 = 2.5813e-04
Loss = 3.4967e-03, PNorm = 57.0503, GNorm = 3.7820, lr_0 = 2.5778e-04
Loss = 4.0982e-03, PNorm = 57.0574, GNorm = 3.3595, lr_0 = 2.5744e-04
Loss = 3.5025e-03, PNorm = 57.0640, GNorm = 1.7763, lr_0 = 2.5709e-04
Loss = 3.7131e-03, PNorm = 57.0717, GNorm = 2.6359, lr_0 = 2.5675e-04
Loss = 4.1968e-03, PNorm = 57.0786, GNorm = 3.0068, lr_0 = 2.5640e-04
Loss = 2.8697e-03, PNorm = 57.0853, GNorm = 1.5943, lr_0 = 2.5606e-04
Loss = 3.5676e-03, PNorm = 57.0915, GNorm = 3.5647, lr_0 = 2.5571e-04
Loss = 3.8729e-03, PNorm = 57.0979, GNorm = 2.5496, lr_0 = 2.5537e-04
Loss = 3.7408e-03, PNorm = 57.1052, GNorm = 1.8823, lr_0 = 2.5503e-04
Loss = 3.1892e-03, PNorm = 57.1127, GNorm = 1.9473, lr_0 = 2.5469e-04
Loss = 4.6319e-03, PNorm = 57.1185, GNorm = 4.3399, lr_0 = 2.5434e-04
Loss = 4.3213e-03, PNorm = 57.1260, GNorm = 4.1754, lr_0 = 2.5400e-04
Loss = 4.2404e-03, PNorm = 57.1339, GNorm = 1.9943, lr_0 = 2.5366e-04
Validation rmse = 3.895611
Validation R2 = -3.453882
Epoch 45
Train function
Loss = 2.2038e-03, PNorm = 57.1402, GNorm = 2.0037, lr_0 = 2.5332e-04
Loss = 2.8960e-03, PNorm = 57.1470, GNorm = 2.5060, lr_0 = 2.5298e-04
Loss = 3.5817e-03, PNorm = 57.1551, GNorm = 2.6936, lr_0 = 2.5264e-04
Loss = 3.3844e-03, PNorm = 57.1629, GNorm = 3.3513, lr_0 = 2.5230e-04
Loss = 3.4857e-03, PNorm = 57.1692, GNorm = 2.9154, lr_0 = 2.5197e-04
Loss = 3.1255e-03, PNorm = 57.1749, GNorm = 1.6169, lr_0 = 2.5163e-04
Loss = 3.3415e-03, PNorm = 57.1822, GNorm = 3.1732, lr_0 = 2.5129e-04
Loss = 3.7245e-03, PNorm = 57.1890, GNorm = 1.6123, lr_0 = 2.5095e-04
Loss = 3.8023e-03, PNorm = 57.1943, GNorm = 2.3826, lr_0 = 2.5062e-04
Loss = 3.7328e-03, PNorm = 57.1989, GNorm = 2.5996, lr_0 = 2.5028e-04
Loss = 3.5391e-03, PNorm = 57.2043, GNorm = 3.4501, lr_0 = 2.4994e-04
Loss = 3.8065e-03, PNorm = 57.2100, GNorm = 2.3597, lr_0 = 2.4961e-04
Loss = 3.5040e-03, PNorm = 57.2176, GNorm = 2.1686, lr_0 = 2.4927e-04
Loss = 2.6340e-03, PNorm = 57.2240, GNorm = 1.9022, lr_0 = 2.4894e-04
Loss = 2.6882e-03, PNorm = 57.2297, GNorm = 1.6972, lr_0 = 2.4861e-04
Loss = 3.0583e-03, PNorm = 57.2375, GNorm = 1.9326, lr_0 = 2.4827e-04
Loss = 3.6360e-03, PNorm = 57.2433, GNorm = 2.1030, lr_0 = 2.4794e-04
Loss = 4.0373e-03, PNorm = 57.2504, GNorm = 1.9163, lr_0 = 2.4761e-04
Loss = 3.8992e-03, PNorm = 57.2577, GNorm = 3.3388, lr_0 = 2.4727e-04
Loss = 3.3412e-03, PNorm = 57.2663, GNorm = 2.1706, lr_0 = 2.4694e-04
Loss = 2.9753e-03, PNorm = 57.2741, GNorm = 2.4013, lr_0 = 2.4661e-04
Loss = 3.0392e-03, PNorm = 57.2796, GNorm = 3.8557, lr_0 = 2.4628e-04
Loss = 4.3863e-03, PNorm = 57.2876, GNorm = 4.7720, lr_0 = 2.4595e-04
Loss = 3.0257e-03, PNorm = 57.2952, GNorm = 2.1883, lr_0 = 2.4562e-04
Validation rmse = 3.695856
Validation R2 = -3.008830
Epoch 46
Train function
Loss = 2.1736e-03, PNorm = 57.3020, GNorm = 1.8940, lr_0 = 2.4526e-04
Loss = 3.3522e-03, PNorm = 57.3077, GNorm = 1.6577, lr_0 = 2.4493e-04
Loss = 2.8002e-03, PNorm = 57.3151, GNorm = 1.4189, lr_0 = 2.4460e-04
Loss = 3.7546e-03, PNorm = 57.3228, GNorm = 3.4009, lr_0 = 2.4427e-04
Loss = 2.9555e-03, PNorm = 57.3315, GNorm = 3.0680, lr_0 = 2.4394e-04
Loss = 3.2603e-03, PNorm = 57.3393, GNorm = 3.2221, lr_0 = 2.4362e-04
Loss = 2.7261e-03, PNorm = 57.3457, GNorm = 2.5244, lr_0 = 2.4329e-04
Loss = 2.5392e-03, PNorm = 57.3508, GNorm = 2.9769, lr_0 = 2.4296e-04
Loss = 2.8603e-03, PNorm = 57.3562, GNorm = 3.3294, lr_0 = 2.4264e-04
Loss = 3.2164e-03, PNorm = 57.3626, GNorm = 2.6879, lr_0 = 2.4231e-04
Loss = 3.5367e-03, PNorm = 57.3699, GNorm = 3.8849, lr_0 = 2.4199e-04
Loss = 2.9236e-03, PNorm = 57.3782, GNorm = 1.8019, lr_0 = 2.4166e-04
Loss = 3.0609e-03, PNorm = 57.3842, GNorm = 1.6653, lr_0 = 2.4134e-04
Loss = 3.4881e-03, PNorm = 57.3910, GNorm = 2.1192, lr_0 = 2.4101e-04
Loss = 3.0944e-03, PNorm = 57.3980, GNorm = 2.8814, lr_0 = 2.4069e-04
Loss = 3.7313e-03, PNorm = 57.4044, GNorm = 2.2550, lr_0 = 2.4037e-04
Loss = 3.7693e-03, PNorm = 57.4109, GNorm = 3.1040, lr_0 = 2.4004e-04
Loss = 2.9382e-03, PNorm = 57.4169, GNorm = 2.0758, lr_0 = 2.3972e-04
Loss = 3.0529e-03, PNorm = 57.4236, GNorm = 3.8453, lr_0 = 2.3940e-04
Loss = 2.9741e-03, PNorm = 57.4302, GNorm = 1.8239, lr_0 = 2.3908e-04
Loss = 3.4779e-03, PNorm = 57.4359, GNorm = 2.4762, lr_0 = 2.3876e-04
Loss = 4.2689e-03, PNorm = 57.4422, GNorm = 5.5369, lr_0 = 2.3844e-04
Loss = 4.2821e-03, PNorm = 57.4513, GNorm = 3.3833, lr_0 = 2.3812e-04
Validation rmse = 4.124837
Validation R2 = -3.993455
Epoch 47
Train function
Loss = 3.4257e-03, PNorm = 57.4598, GNorm = 2.4144, lr_0 = 2.3777e-04
Loss = 3.2108e-03, PNorm = 57.4652, GNorm = 2.3518, lr_0 = 2.3745e-04
Loss = 2.7577e-03, PNorm = 57.4706, GNorm = 1.7805, lr_0 = 2.3713e-04
Loss = 2.6690e-03, PNorm = 57.4771, GNorm = 2.2349, lr_0 = 2.3681e-04
Loss = 2.8750e-03, PNorm = 57.4827, GNorm = 2.7456, lr_0 = 2.3649e-04
Loss = 2.8414e-03, PNorm = 57.4882, GNorm = 1.5226, lr_0 = 2.3618e-04
Loss = 2.6669e-03, PNorm = 57.4944, GNorm = 2.9182, lr_0 = 2.3586e-04
Loss = 3.8676e-03, PNorm = 57.5024, GNorm = 2.9979, lr_0 = 2.3554e-04
Loss = 2.9172e-03, PNorm = 57.5093, GNorm = 2.2850, lr_0 = 2.3523e-04
Loss = 2.6284e-03, PNorm = 57.5134, GNorm = 2.6413, lr_0 = 2.3491e-04
Loss = 3.5417e-03, PNorm = 57.5193, GNorm = 1.4955, lr_0 = 2.3460e-04
Loss = 2.8156e-03, PNorm = 57.5253, GNorm = 2.9156, lr_0 = 2.3428e-04
Loss = 3.0087e-03, PNorm = 57.5324, GNorm = 2.6362, lr_0 = 2.3397e-04
Loss = 3.7865e-03, PNorm = 57.5381, GNorm = 5.1631, lr_0 = 2.3365e-04
Loss = 2.9300e-03, PNorm = 57.5448, GNorm = 3.3504, lr_0 = 2.3334e-04
Loss = 3.5497e-03, PNorm = 57.5528, GNorm = 3.1732, lr_0 = 2.3303e-04
Loss = 3.0764e-03, PNorm = 57.5599, GNorm = 3.1717, lr_0 = 2.3271e-04
Loss = 2.8543e-03, PNorm = 57.5672, GNorm = 1.8159, lr_0 = 2.3240e-04
Loss = 3.3287e-03, PNorm = 57.5729, GNorm = 2.3169, lr_0 = 2.3209e-04
Loss = 3.4469e-03, PNorm = 57.5762, GNorm = 1.9589, lr_0 = 2.3178e-04
Loss = 3.0267e-03, PNorm = 57.5808, GNorm = 2.7483, lr_0 = 2.3147e-04
Loss = 3.0544e-03, PNorm = 57.5853, GNorm = 3.1470, lr_0 = 2.3116e-04
Loss = 3.1369e-03, PNorm = 57.5894, GNorm = 2.2206, lr_0 = 2.3085e-04
Loss = 3.1144e-03, PNorm = 57.5942, GNorm = 3.6359, lr_0 = 2.3054e-04
Validation rmse = 3.836606
Validation R2 = -3.319981
Epoch 48
Train function
Loss = 3.1746e-03, PNorm = 57.5989, GNorm = 4.3898, lr_0 = 2.3020e-04
Loss = 2.4294e-03, PNorm = 57.6032, GNorm = 4.0117, lr_0 = 2.2989e-04
Loss = 1.9168e-03, PNorm = 57.6078, GNorm = 1.7809, lr_0 = 2.2958e-04
Loss = 2.7721e-03, PNorm = 57.6136, GNorm = 1.6442, lr_0 = 2.2927e-04
Loss = 2.1977e-03, PNorm = 57.6199, GNorm = 1.5108, lr_0 = 2.2896e-04
Loss = 3.2141e-03, PNorm = 57.6256, GNorm = 3.0252, lr_0 = 2.2866e-04
Loss = 3.6795e-03, PNorm = 57.6319, GNorm = 3.1797, lr_0 = 2.2835e-04
Loss = 3.1527e-03, PNorm = 57.6415, GNorm = 3.1274, lr_0 = 2.2804e-04
Loss = 2.3541e-03, PNorm = 57.6483, GNorm = 1.8554, lr_0 = 2.2774e-04
Loss = 3.3776e-03, PNorm = 57.6559, GNorm = 3.8681, lr_0 = 2.2743e-04
Loss = 2.0676e-03, PNorm = 57.6620, GNorm = 3.2443, lr_0 = 2.2713e-04
Loss = 2.8402e-03, PNorm = 57.6680, GNorm = 2.2828, lr_0 = 2.2682e-04
Loss = 3.3829e-03, PNorm = 57.6737, GNorm = 2.0248, lr_0 = 2.2652e-04
Loss = 2.8169e-03, PNorm = 57.6795, GNorm = 1.8527, lr_0 = 2.2621e-04
Loss = 2.4165e-03, PNorm = 57.6839, GNorm = 2.3089, lr_0 = 2.2591e-04
Loss = 3.2255e-03, PNorm = 57.6891, GNorm = 3.2378, lr_0 = 2.2561e-04
Loss = 2.9231e-03, PNorm = 57.6942, GNorm = 2.5948, lr_0 = 2.2530e-04
Loss = 3.0261e-03, PNorm = 57.6993, GNorm = 3.4006, lr_0 = 2.2500e-04
Loss = 2.5248e-03, PNorm = 57.7053, GNorm = 2.3894, lr_0 = 2.2470e-04
Loss = 3.8197e-03, PNorm = 57.7103, GNorm = 4.2578, lr_0 = 2.2440e-04
Loss = 3.7020e-03, PNorm = 57.7167, GNorm = 2.2563, lr_0 = 2.2410e-04
Loss = 2.8554e-03, PNorm = 57.7237, GNorm = 1.5740, lr_0 = 2.2380e-04
Loss = 3.1007e-03, PNorm = 57.7297, GNorm = 2.2615, lr_0 = 2.2350e-04
Validation rmse = 3.643751
Validation R2 = -2.896591
Epoch 49
Train function
Loss = 2.9304e-03, PNorm = 57.7373, GNorm = 2.7625, lr_0 = 2.2317e-04
Loss = 2.4863e-03, PNorm = 57.7427, GNorm = 3.1541, lr_0 = 2.2287e-04
Loss = 2.4457e-03, PNorm = 57.7474, GNorm = 2.1097, lr_0 = 2.2257e-04
Loss = 2.7891e-03, PNorm = 57.7526, GNorm = 3.2604, lr_0 = 2.2227e-04
Loss = 2.7877e-03, PNorm = 57.7586, GNorm = 1.9372, lr_0 = 2.2197e-04
Loss = 2.5285e-03, PNorm = 57.7628, GNorm = 1.9019, lr_0 = 2.2167e-04
Loss = 2.7265e-03, PNorm = 57.7670, GNorm = 1.6082, lr_0 = 2.2138e-04
Loss = 2.6037e-03, PNorm = 57.7720, GNorm = 1.5861, lr_0 = 2.2108e-04
Loss = 3.1206e-03, PNorm = 57.7782, GNorm = 2.0954, lr_0 = 2.2078e-04
Loss = 2.8227e-03, PNorm = 57.7835, GNorm = 2.1292, lr_0 = 2.2049e-04
Loss = 2.9545e-03, PNorm = 57.7904, GNorm = 1.4123, lr_0 = 2.2019e-04
Loss = 2.9379e-03, PNorm = 57.7945, GNorm = 2.1887, lr_0 = 2.1990e-04
Loss = 2.2764e-03, PNorm = 57.7991, GNorm = 2.3068, lr_0 = 2.1960e-04
Loss = 1.8560e-03, PNorm = 57.8038, GNorm = 1.3767, lr_0 = 2.1931e-04
Loss = 2.9784e-03, PNorm = 57.8091, GNorm = 3.0475, lr_0 = 2.1901e-04
Loss = 2.0869e-03, PNorm = 57.8131, GNorm = 2.6027, lr_0 = 2.1872e-04
Loss = 2.7694e-03, PNorm = 57.8180, GNorm = 1.5732, lr_0 = 2.1842e-04
Loss = 2.6187e-03, PNorm = 57.8234, GNorm = 2.2596, lr_0 = 2.1813e-04
Loss = 3.0258e-03, PNorm = 57.8306, GNorm = 1.7300, lr_0 = 2.1784e-04
Loss = 3.1499e-03, PNorm = 57.8365, GNorm = 2.9790, lr_0 = 2.1755e-04
Loss = 3.3002e-03, PNorm = 57.8433, GNorm = 2.4511, lr_0 = 2.1725e-04
Loss = 2.6225e-03, PNorm = 57.8489, GNorm = 2.1744, lr_0 = 2.1696e-04
Loss = 3.2271e-03, PNorm = 57.8527, GNorm = 2.0625, lr_0 = 2.1667e-04
Loss = 4.0825e-03, PNorm = 57.8578, GNorm = 5.7471, lr_0 = 2.1638e-04
Validation rmse = 3.814809
Validation R2 = -3.271034
Epoch 50
Train function
Loss = 2.4103e-03, PNorm = 57.8646, GNorm = 1.8431, lr_0 = 2.1609e-04
Loss = 2.5753e-03, PNorm = 57.8710, GNorm = 1.7329, lr_0 = 2.1580e-04
Loss = 2.2076e-03, PNorm = 57.8761, GNorm = 2.7233, lr_0 = 2.1551e-04
Loss = 2.1784e-03, PNorm = 57.8815, GNorm = 2.1320, lr_0 = 2.1522e-04
Loss = 2.2903e-03, PNorm = 57.8867, GNorm = 3.1269, lr_0 = 2.1493e-04
Loss = 2.3784e-03, PNorm = 57.8917, GNorm = 1.3548, lr_0 = 2.1464e-04
Loss = 2.3784e-03, PNorm = 57.8981, GNorm = 1.9892, lr_0 = 2.1436e-04
Loss = 2.5002e-03, PNorm = 57.9034, GNorm = 1.5461, lr_0 = 2.1407e-04
Loss = 2.4283e-03, PNorm = 57.9081, GNorm = 2.1261, lr_0 = 2.1378e-04
Loss = 1.9224e-03, PNorm = 57.9121, GNorm = 1.7304, lr_0 = 2.1350e-04
Loss = 3.3838e-03, PNorm = 57.9167, GNorm = 2.9988, lr_0 = 2.1321e-04
Loss = 2.3921e-03, PNorm = 57.9223, GNorm = 2.3080, lr_0 = 2.1292e-04
Loss = 2.9117e-03, PNorm = 57.9272, GNorm = 3.8426, lr_0 = 2.1264e-04
Loss = 2.6727e-03, PNorm = 57.9326, GNorm = 1.5388, lr_0 = 2.1235e-04
Loss = 2.7177e-03, PNorm = 57.9389, GNorm = 2.3076, lr_0 = 2.1207e-04
Loss = 3.2504e-03, PNorm = 57.9433, GNorm = 1.8021, lr_0 = 2.1178e-04
Loss = 2.4653e-03, PNorm = 57.9472, GNorm = 1.6662, lr_0 = 2.1150e-04
Loss = 2.8838e-03, PNorm = 57.9513, GNorm = 1.7711, lr_0 = 2.1121e-04
Loss = 3.4385e-03, PNorm = 57.9555, GNorm = 3.8632, lr_0 = 2.1093e-04
Loss = 2.3284e-03, PNorm = 57.9609, GNorm = 2.8615, lr_0 = 2.1065e-04
Loss = 3.2981e-03, PNorm = 57.9679, GNorm = 2.5466, lr_0 = 2.1037e-04
Loss = 2.2911e-03, PNorm = 57.9726, GNorm = 2.3066, lr_0 = 2.1008e-04
Loss = 3.5701e-03, PNorm = 57.9779, GNorm = 2.5143, lr_0 = 2.0980e-04
Validation rmse = 3.843922
Validation R2 = -3.336473
Epoch 51
Train function
Loss = 2.0861e-03, PNorm = 57.9857, GNorm = 2.1625, lr_0 = 2.0949e-04
Loss = 3.1447e-03, PNorm = 57.9909, GNorm = 3.6510, lr_0 = 2.0921e-04
Loss = 1.9033e-03, PNorm = 57.9954, GNorm = 1.7534, lr_0 = 2.0893e-04
Loss = 2.1038e-03, PNorm = 58.0003, GNorm = 2.1049, lr_0 = 2.0865e-04
Loss = 2.6312e-03, PNorm = 58.0046, GNorm = 2.2678, lr_0 = 2.0837e-04
Loss = 2.3088e-03, PNorm = 58.0110, GNorm = 2.3232, lr_0 = 2.0809e-04
Loss = 2.6330e-03, PNorm = 58.0162, GNorm = 1.5072, lr_0 = 2.0781e-04
Loss = 2.3381e-03, PNorm = 58.0228, GNorm = 2.8003, lr_0 = 2.0753e-04
Loss = 2.3115e-03, PNorm = 58.0286, GNorm = 2.7694, lr_0 = 2.0725e-04
Loss = 2.9031e-03, PNorm = 58.0341, GNorm = 1.7712, lr_0 = 2.0698e-04
Loss = 2.2055e-03, PNorm = 58.0397, GNorm = 2.5912, lr_0 = 2.0670e-04
Loss = 1.9679e-03, PNorm = 58.0429, GNorm = 2.8286, lr_0 = 2.0642e-04
Loss = 2.2054e-03, PNorm = 58.0470, GNorm = 1.4978, lr_0 = 2.0614e-04
Loss = 1.9898e-03, PNorm = 58.0511, GNorm = 2.5532, lr_0 = 2.0587e-04
Loss = 2.2488e-03, PNorm = 58.0552, GNorm = 1.7168, lr_0 = 2.0559e-04
Loss = 1.9562e-03, PNorm = 58.0592, GNorm = 1.7033, lr_0 = 2.0531e-04
Loss = 2.7891e-03, PNorm = 58.0640, GNorm = 3.0868, lr_0 = 2.0504e-04
Loss = 2.8314e-03, PNorm = 58.0688, GNorm = 2.3104, lr_0 = 2.0476e-04
Loss = 2.7070e-03, PNorm = 58.0734, GNorm = 2.7197, lr_0 = 2.0449e-04
Loss = 2.7225e-03, PNorm = 58.0784, GNorm = 3.2737, lr_0 = 2.0421e-04
Loss = 3.0734e-03, PNorm = 58.0830, GNorm = 1.7387, lr_0 = 2.0394e-04
Loss = 3.5408e-03, PNorm = 58.0869, GNorm = 2.5263, lr_0 = 2.0367e-04
Loss = 3.1320e-03, PNorm = 58.0922, GNorm = 2.4453, lr_0 = 2.0339e-04
Validation rmse = 3.746572
Validation R2 = -3.119605
Epoch 52
Train function
Loss = 2.9483e-03, PNorm = 58.0995, GNorm = 3.4193, lr_0 = 2.0309e-04
Loss = 2.5205e-03, PNorm = 58.1057, GNorm = 2.6751, lr_0 = 2.0282e-04
Loss = 2.1161e-03, PNorm = 58.1100, GNorm = 1.5044, lr_0 = 2.0255e-04
Loss = 2.9712e-03, PNorm = 58.1136, GNorm = 2.5949, lr_0 = 2.0228e-04
Loss = 1.8284e-03, PNorm = 58.1178, GNorm = 2.5656, lr_0 = 2.0201e-04
Loss = 1.9346e-03, PNorm = 58.1228, GNorm = 1.6220, lr_0 = 2.0174e-04
Loss = 2.2396e-03, PNorm = 58.1284, GNorm = 2.3387, lr_0 = 2.0146e-04
Loss = 2.1704e-03, PNorm = 58.1336, GNorm = 1.4517, lr_0 = 2.0119e-04
Loss = 1.8804e-03, PNorm = 58.1376, GNorm = 2.2089, lr_0 = 2.0092e-04
Loss = 2.2520e-03, PNorm = 58.1422, GNorm = 2.3145, lr_0 = 2.0065e-04
Loss = 2.6084e-03, PNorm = 58.1476, GNorm = 2.4278, lr_0 = 2.0039e-04
Loss = 2.1530e-03, PNorm = 58.1518, GNorm = 3.1091, lr_0 = 2.0012e-04
Loss = 2.3417e-03, PNorm = 58.1556, GNorm = 1.3938, lr_0 = 1.9985e-04
Loss = 2.1920e-03, PNorm = 58.1597, GNorm = 2.0846, lr_0 = 1.9958e-04
Loss = 2.7598e-03, PNorm = 58.1652, GNorm = 2.9352, lr_0 = 1.9931e-04
Loss = 2.5591e-03, PNorm = 58.1697, GNorm = 2.0818, lr_0 = 1.9904e-04
Loss = 2.5892e-03, PNorm = 58.1734, GNorm = 2.5100, lr_0 = 1.9878e-04
Loss = 2.0179e-03, PNorm = 58.1769, GNorm = 2.9376, lr_0 = 1.9851e-04
Loss = 3.2417e-03, PNorm = 58.1809, GNorm = 1.8881, lr_0 = 1.9824e-04
Loss = 2.9373e-03, PNorm = 58.1859, GNorm = 2.4038, lr_0 = 1.9798e-04
Loss = 2.2941e-03, PNorm = 58.1913, GNorm = 1.3265, lr_0 = 1.9771e-04
Loss = 2.3553e-03, PNorm = 58.1980, GNorm = 1.7937, lr_0 = 1.9745e-04
Loss = 2.5089e-03, PNorm = 58.2028, GNorm = 2.1305, lr_0 = 1.9718e-04
Loss = 3.0589e-03, PNorm = 58.2073, GNorm = 2.8326, lr_0 = 1.9692e-04
Validation rmse = 4.087926
Validation R2 = -3.904487
Epoch 53
Train function
Loss = 2.2709e-03, PNorm = 58.2122, GNorm = 2.4947, lr_0 = 1.9663e-04
Loss = 2.3566e-03, PNorm = 58.2161, GNorm = 2.5924, lr_0 = 1.9636e-04
Loss = 2.4618e-03, PNorm = 58.2216, GNorm = 2.8265, lr_0 = 1.9610e-04
Loss = 2.0507e-03, PNorm = 58.2283, GNorm = 2.7399, lr_0 = 1.9584e-04
Loss = 2.3615e-03, PNorm = 58.2333, GNorm = 2.5103, lr_0 = 1.9557e-04
Loss = 1.9820e-03, PNorm = 58.2386, GNorm = 1.4567, lr_0 = 1.9531e-04
Loss = 2.0122e-03, PNorm = 58.2429, GNorm = 2.0687, lr_0 = 1.9505e-04
Loss = 1.9459e-03, PNorm = 58.2465, GNorm = 1.9190, lr_0 = 1.9479e-04
Loss = 1.7854e-03, PNorm = 58.2490, GNorm = 1.0715, lr_0 = 1.9453e-04
Loss = 2.1274e-03, PNorm = 58.2537, GNorm = 1.8838, lr_0 = 1.9427e-04
Loss = 2.7473e-03, PNorm = 58.2591, GNorm = 3.1644, lr_0 = 1.9401e-04
Loss = 2.1806e-03, PNorm = 58.2633, GNorm = 1.4014, lr_0 = 1.9374e-04
Loss = 2.8437e-03, PNorm = 58.2679, GNorm = 2.1150, lr_0 = 1.9348e-04
Loss = 1.7940e-03, PNorm = 58.2711, GNorm = 1.9351, lr_0 = 1.9323e-04
Loss = 2.3780e-03, PNorm = 58.2760, GNorm = 2.0573, lr_0 = 1.9297e-04
Loss = 2.2470e-03, PNorm = 58.2799, GNorm = 1.5594, lr_0 = 1.9271e-04
Loss = 1.8251e-03, PNorm = 58.2839, GNorm = 1.6215, lr_0 = 1.9245e-04
Loss = 1.6179e-03, PNorm = 58.2871, GNorm = 2.8349, lr_0 = 1.9219e-04
Loss = 1.6539e-03, PNorm = 58.2901, GNorm = 1.3373, lr_0 = 1.9193e-04
Loss = 2.5371e-03, PNorm = 58.2939, GNorm = 3.0760, lr_0 = 1.9168e-04
Loss = 2.2888e-03, PNorm = 58.2989, GNorm = 1.9752, lr_0 = 1.9142e-04
Loss = 2.5859e-03, PNorm = 58.3037, GNorm = 1.6555, lr_0 = 1.9116e-04
Loss = 2.3640e-03, PNorm = 58.3080, GNorm = 1.3191, lr_0 = 1.9090e-04
Validation rmse = 3.930548
Validation R2 = -3.534127
Epoch 54
Train function
Loss = 1.4738e-03, PNorm = 58.3135, GNorm = 2.6193, lr_0 = 1.9062e-04
Loss = 2.6762e-03, PNorm = 58.3182, GNorm = 1.7036, lr_0 = 1.9037e-04
Loss = 1.4377e-03, PNorm = 58.3223, GNorm = 2.6782, lr_0 = 1.9011e-04
Loss = 2.3812e-03, PNorm = 58.3265, GNorm = 1.7771, lr_0 = 1.8986e-04
Loss = 2.1397e-03, PNorm = 58.3306, GNorm = 1.8447, lr_0 = 1.8960e-04
Loss = 2.1554e-03, PNorm = 58.3349, GNorm = 1.6654, lr_0 = 1.8935e-04
Loss = 1.8302e-03, PNorm = 58.3398, GNorm = 2.0466, lr_0 = 1.8909e-04
Loss = 1.9598e-03, PNorm = 58.3438, GNorm = 3.0335, lr_0 = 1.8884e-04
Loss = 2.2648e-03, PNorm = 58.3480, GNorm = 2.6064, lr_0 = 1.8859e-04
Loss = 2.1894e-03, PNorm = 58.3522, GNorm = 1.9377, lr_0 = 1.8833e-04
Loss = 1.5574e-03, PNorm = 58.3564, GNorm = 1.3267, lr_0 = 1.8808e-04
Loss = 2.3728e-03, PNorm = 58.3606, GNorm = 2.1542, lr_0 = 1.8783e-04
Loss = 2.5264e-03, PNorm = 58.3658, GNorm = 2.9927, lr_0 = 1.8758e-04
Loss = 2.5188e-03, PNorm = 58.3698, GNorm = 2.1463, lr_0 = 1.8732e-04
Loss = 2.0385e-03, PNorm = 58.3737, GNorm = 1.3101, lr_0 = 1.8707e-04
Loss = 2.2358e-03, PNorm = 58.3773, GNorm = 2.9074, lr_0 = 1.8682e-04
Loss = 1.9865e-03, PNorm = 58.3811, GNorm = 2.1873, lr_0 = 1.8657e-04
Loss = 2.3424e-03, PNorm = 58.3868, GNorm = 2.5817, lr_0 = 1.8632e-04
Loss = 2.2517e-03, PNorm = 58.3914, GNorm = 1.3944, lr_0 = 1.8607e-04
Loss = 3.2911e-03, PNorm = 58.3961, GNorm = 2.2159, lr_0 = 1.8582e-04
Loss = 1.7842e-03, PNorm = 58.4008, GNorm = 2.1404, lr_0 = 1.8557e-04
Loss = 2.0307e-03, PNorm = 58.4051, GNorm = 1.9427, lr_0 = 1.8532e-04
Loss = 2.1800e-03, PNorm = 58.4088, GNorm = 1.8806, lr_0 = 1.8507e-04
Loss = 2.1504e-03, PNorm = 58.4124, GNorm = 1.6680, lr_0 = 1.8483e-04
Validation rmse = 4.073318
Validation R2 = -3.869496
Epoch 55
Train function
Loss = 2.5571e-03, PNorm = 58.4176, GNorm = 2.1325, lr_0 = 1.8458e-04
Loss = 2.6356e-03, PNorm = 58.4228, GNorm = 2.0268, lr_0 = 1.8433e-04
Loss = 1.6488e-03, PNorm = 58.4275, GNorm = 1.9574, lr_0 = 1.8408e-04
Loss = 2.1137e-03, PNorm = 58.4322, GNorm = 1.8357, lr_0 = 1.8384e-04
Loss = 3.0429e-03, PNorm = 58.4360, GNorm = 1.9246, lr_0 = 1.8359e-04
Loss = 1.6590e-03, PNorm = 58.4394, GNorm = 2.9972, lr_0 = 1.8334e-04
Loss = 1.7094e-03, PNorm = 58.4423, GNorm = 2.7041, lr_0 = 1.8310e-04
Loss = 1.5466e-03, PNorm = 58.4446, GNorm = 1.4102, lr_0 = 1.8285e-04
Loss = 2.0398e-03, PNorm = 58.4471, GNorm = 2.9582, lr_0 = 1.8261e-04
Loss = 2.3236e-03, PNorm = 58.4523, GNorm = 3.8591, lr_0 = 1.8236e-04
Loss = 2.0365e-03, PNorm = 58.4572, GNorm = 2.0651, lr_0 = 1.8212e-04
Loss = 2.2765e-03, PNorm = 58.4616, GNorm = 2.8264, lr_0 = 1.8187e-04
Loss = 2.4951e-03, PNorm = 58.4680, GNorm = 1.5786, lr_0 = 1.8163e-04
Loss = 1.8859e-03, PNorm = 58.4736, GNorm = 3.0665, lr_0 = 1.8138e-04
Loss = 1.6493e-03, PNorm = 58.4779, GNorm = 1.7581, lr_0 = 1.8114e-04
Loss = 1.6945e-03, PNorm = 58.4817, GNorm = 1.3123, lr_0 = 1.8090e-04
Loss = 1.8786e-03, PNorm = 58.4856, GNorm = 1.5614, lr_0 = 1.8066e-04
Loss = 1.6830e-03, PNorm = 58.4890, GNorm = 1.7378, lr_0 = 1.8041e-04
Loss = 1.6285e-03, PNorm = 58.4913, GNorm = 1.2611, lr_0 = 1.8017e-04
Loss = 2.5202e-03, PNorm = 58.4940, GNorm = 2.8974, lr_0 = 1.7993e-04
Loss = 2.0200e-03, PNorm = 58.4985, GNorm = 1.7114, lr_0 = 1.7969e-04
Loss = 2.1338e-03, PNorm = 58.5029, GNorm = 2.2867, lr_0 = 1.7945e-04
Loss = 2.2417e-03, PNorm = 58.5077, GNorm = 2.3021, lr_0 = 1.7921e-04
Validation rmse = 4.057968
Validation R2 = -3.832867
Epoch 56
Train function
Loss = 1.6066e-03, PNorm = 58.5107, GNorm = 2.6217, lr_0 = 1.7894e-04
Loss = 1.5365e-03, PNorm = 58.5130, GNorm = 1.6927, lr_0 = 1.7870e-04
Loss = 2.2723e-03, PNorm = 58.5150, GNorm = 2.3533, lr_0 = 1.7846e-04
Loss = 1.8564e-03, PNorm = 58.5190, GNorm = 2.8752, lr_0 = 1.7822e-04
Loss = 1.8593e-03, PNorm = 58.5242, GNorm = 1.8975, lr_0 = 1.7798e-04
Loss = 2.0018e-03, PNorm = 58.5281, GNorm = 1.7263, lr_0 = 1.7774e-04
Loss = 1.8504e-03, PNorm = 58.5333, GNorm = 2.5017, lr_0 = 1.7751e-04
Loss = 2.3585e-03, PNorm = 58.5378, GNorm = 2.5148, lr_0 = 1.7727e-04
Loss = 2.0592e-03, PNorm = 58.5428, GNorm = 2.2265, lr_0 = 1.7703e-04
Loss = 1.9036e-03, PNorm = 58.5471, GNorm = 1.3346, lr_0 = 1.7679e-04
Loss = 1.7034e-03, PNorm = 58.5510, GNorm = 1.3205, lr_0 = 1.7656e-04
Loss = 1.6405e-03, PNorm = 58.5540, GNorm = 1.8219, lr_0 = 1.7632e-04
Loss = 1.6923e-03, PNorm = 58.5575, GNorm = 2.4865, lr_0 = 1.7608e-04
Loss = 1.7954e-03, PNorm = 58.5602, GNorm = 2.0290, lr_0 = 1.7585e-04
Loss = 2.0190e-03, PNorm = 58.5632, GNorm = 2.0342, lr_0 = 1.7561e-04
Loss = 2.2437e-03, PNorm = 58.5660, GNorm = 3.1548, lr_0 = 1.7537e-04
Loss = 1.6273e-03, PNorm = 58.5686, GNorm = 1.4671, lr_0 = 1.7514e-04
Loss = 2.0578e-03, PNorm = 58.5718, GNorm = 2.3602, lr_0 = 1.7490e-04
Loss = 2.6197e-03, PNorm = 58.5750, GNorm = 2.7679, lr_0 = 1.7467e-04
Loss = 1.6056e-03, PNorm = 58.5783, GNorm = 1.7721, lr_0 = 1.7443e-04
Loss = 2.0875e-03, PNorm = 58.5812, GNorm = 1.7764, lr_0 = 1.7420e-04
Loss = 1.7866e-03, PNorm = 58.5849, GNorm = 2.2521, lr_0 = 1.7397e-04
Loss = 1.5917e-03, PNorm = 58.5880, GNorm = 2.3680, lr_0 = 1.7373e-04
Validation rmse = 4.198091
Validation R2 = -4.172390
Epoch 57
Train function
Loss = 9.4292e-04, PNorm = 58.5923, GNorm = 2.1359, lr_0 = 1.7348e-04
Loss = 1.7478e-03, PNorm = 58.5961, GNorm = 3.1557, lr_0 = 1.7324e-04
Loss = 2.3141e-03, PNorm = 58.6023, GNorm = 5.1475, lr_0 = 1.7301e-04
Loss = 1.9045e-03, PNorm = 58.6080, GNorm = 2.1654, lr_0 = 1.7278e-04
Loss = 1.9528e-03, PNorm = 58.6137, GNorm = 2.6822, lr_0 = 1.7255e-04
Loss = 2.3318e-03, PNorm = 58.6180, GNorm = 3.6688, lr_0 = 1.7232e-04
Loss = 1.3999e-03, PNorm = 58.6211, GNorm = 2.0744, lr_0 = 1.7209e-04
Loss = 1.7999e-03, PNorm = 58.6250, GNorm = 2.3057, lr_0 = 1.7185e-04
Loss = 1.4070e-03, PNorm = 58.6287, GNorm = 1.8233, lr_0 = 1.7162e-04
Loss = 1.9849e-03, PNorm = 58.6318, GNorm = 2.1018, lr_0 = 1.7139e-04
Loss = 2.0156e-03, PNorm = 58.6356, GNorm = 3.1647, lr_0 = 1.7116e-04
Loss = 2.3075e-03, PNorm = 58.6386, GNorm = 1.8549, lr_0 = 1.7093e-04
Loss = 1.8941e-03, PNorm = 58.6420, GNorm = 1.6600, lr_0 = 1.7070e-04
Loss = 1.9001e-03, PNorm = 58.6448, GNorm = 1.1867, lr_0 = 1.7048e-04
Loss = 1.9542e-03, PNorm = 58.6488, GNorm = 2.5809, lr_0 = 1.7025e-04
Loss = 2.2745e-03, PNorm = 58.6523, GNorm = 2.1177, lr_0 = 1.7002e-04
Loss = 2.2793e-03, PNorm = 58.6580, GNorm = 2.1653, lr_0 = 1.6979e-04
Loss = 1.5097e-03, PNorm = 58.6614, GNorm = 2.0837, lr_0 = 1.6956e-04
Loss = 1.5219e-03, PNorm = 58.6642, GNorm = 1.6512, lr_0 = 1.6933e-04
Loss = 1.9202e-03, PNorm = 58.6682, GNorm = 2.8277, lr_0 = 1.6911e-04
Loss = 2.2403e-03, PNorm = 58.6726, GNorm = 1.2125, lr_0 = 1.6888e-04
Loss = 1.4174e-03, PNorm = 58.6761, GNorm = 1.9159, lr_0 = 1.6865e-04
Loss = 2.0078e-03, PNorm = 58.6787, GNorm = 2.5381, lr_0 = 1.6843e-04
Loss = 2.4069e-03, PNorm = 58.6822, GNorm = 3.2958, lr_0 = 1.6820e-04
Validation rmse = 4.232740
Validation R2 = -4.258121
Epoch 58
Train function
Loss = 1.3684e-03, PNorm = 58.6870, GNorm = 3.0061, lr_0 = 1.6795e-04
Loss = 1.7739e-03, PNorm = 58.6915, GNorm = 2.0639, lr_0 = 1.6773e-04
Loss = 1.8257e-03, PNorm = 58.6950, GNorm = 2.6229, lr_0 = 1.6750e-04
Loss = 1.9680e-03, PNorm = 58.6983, GNorm = 2.3036, lr_0 = 1.6728e-04
Loss = 1.1589e-03, PNorm = 58.7012, GNorm = 1.3611, lr_0 = 1.6705e-04
Loss = 1.7282e-03, PNorm = 58.7046, GNorm = 1.7213, lr_0 = 1.6683e-04
Loss = 1.3230e-03, PNorm = 58.7070, GNorm = 1.8718, lr_0 = 1.6661e-04
Loss = 1.9661e-03, PNorm = 58.7102, GNorm = 1.4368, lr_0 = 1.6638e-04
Loss = 1.7436e-03, PNorm = 58.7136, GNorm = 2.1971, lr_0 = 1.6616e-04
Loss = 1.8462e-03, PNorm = 58.7162, GNorm = 1.2995, lr_0 = 1.6594e-04
Loss = 2.4239e-03, PNorm = 58.7199, GNorm = 3.6750, lr_0 = 1.6571e-04
Loss = 2.0050e-03, PNorm = 58.7230, GNorm = 1.7986, lr_0 = 1.6549e-04
Loss = 1.9792e-03, PNorm = 58.7265, GNorm = 2.4623, lr_0 = 1.6527e-04
Loss = 1.5386e-03, PNorm = 58.7295, GNorm = 2.6934, lr_0 = 1.6505e-04
Loss = 1.9059e-03, PNorm = 58.7327, GNorm = 1.1896, lr_0 = 1.6483e-04
Loss = 2.0652e-03, PNorm = 58.7358, GNorm = 1.4806, lr_0 = 1.6461e-04
Loss = 1.3420e-03, PNorm = 58.7388, GNorm = 3.1757, lr_0 = 1.6438e-04
Loss = 1.2768e-03, PNorm = 58.7412, GNorm = 1.2475, lr_0 = 1.6416e-04
Loss = 1.9891e-03, PNorm = 58.7443, GNorm = 2.9528, lr_0 = 1.6394e-04
Loss = 1.5339e-03, PNorm = 58.7475, GNorm = 1.4441, lr_0 = 1.6372e-04
Loss = 1.5007e-03, PNorm = 58.7507, GNorm = 2.0491, lr_0 = 1.6350e-04
Loss = 1.9349e-03, PNorm = 58.7541, GNorm = 1.7050, lr_0 = 1.6328e-04
Loss = 1.6520e-03, PNorm = 58.7573, GNorm = 1.3479, lr_0 = 1.6307e-04
Validation rmse = 3.930973
Validation R2 = -3.535108
Epoch 59
Train function
Loss = 1.6409e-03, PNorm = 58.7621, GNorm = 1.7314, lr_0 = 1.6282e-04
Loss = 1.3852e-03, PNorm = 58.7667, GNorm = 3.2750, lr_0 = 1.6261e-04
Loss = 1.4402e-03, PNorm = 58.7697, GNorm = 2.0963, lr_0 = 1.6239e-04
Loss = 1.4398e-03, PNorm = 58.7721, GNorm = 2.3485, lr_0 = 1.6217e-04
Loss = 1.4862e-03, PNorm = 58.7749, GNorm = 1.7937, lr_0 = 1.6195e-04
Loss = 1.3764e-03, PNorm = 58.7786, GNorm = 2.0486, lr_0 = 1.6174e-04
Loss = 1.3562e-03, PNorm = 58.7815, GNorm = 2.6572, lr_0 = 1.6152e-04
Loss = 1.7819e-03, PNorm = 58.7851, GNorm = 4.2470, lr_0 = 1.6130e-04
Loss = 1.9633e-03, PNorm = 58.7889, GNorm = 1.9323, lr_0 = 1.6109e-04
Loss = 1.5965e-03, PNorm = 58.7915, GNorm = 2.4710, lr_0 = 1.6087e-04
Loss = 1.6109e-03, PNorm = 58.7943, GNorm = 3.0264, lr_0 = 1.6065e-04
Loss = 1.9491e-03, PNorm = 58.7979, GNorm = 2.2991, lr_0 = 1.6044e-04
Loss = 1.5653e-03, PNorm = 58.7999, GNorm = 1.5077, lr_0 = 1.6022e-04
Loss = 1.5083e-03, PNorm = 58.8030, GNorm = 1.7527, lr_0 = 1.6001e-04
Loss = 1.7944e-03, PNorm = 58.8063, GNorm = 3.5705, lr_0 = 1.5979e-04
Loss = 2.3690e-03, PNorm = 58.8099, GNorm = 3.0856, lr_0 = 1.5958e-04
Loss = 1.7037e-03, PNorm = 58.8138, GNorm = 1.5195, lr_0 = 1.5936e-04
Loss = 1.4991e-03, PNorm = 58.8169, GNorm = 1.6584, lr_0 = 1.5915e-04
Loss = 1.7752e-03, PNorm = 58.8193, GNorm = 1.6026, lr_0 = 1.5894e-04
Loss = 2.0570e-03, PNorm = 58.8225, GNorm = 2.0782, lr_0 = 1.5872e-04
Loss = 1.3501e-03, PNorm = 58.8261, GNorm = 2.0873, lr_0 = 1.5851e-04
Loss = 1.8847e-03, PNorm = 58.8296, GNorm = 3.4012, lr_0 = 1.5830e-04
Loss = 1.2189e-03, PNorm = 58.8316, GNorm = 1.7262, lr_0 = 1.5809e-04
Loss = 1.8243e-03, PNorm = 58.8340, GNorm = 2.2376, lr_0 = 1.5787e-04
Validation rmse = 4.060648
Validation R2 = -3.839251
Epoch 60
Train function
Loss = 1.7562e-03, PNorm = 58.8384, GNorm = 2.3031, lr_0 = 1.5766e-04
Loss = 1.5948e-03, PNorm = 58.8421, GNorm = 1.1401, lr_0 = 1.5745e-04
Loss = 1.5428e-03, PNorm = 58.8450, GNorm = 1.7301, lr_0 = 1.5724e-04
Loss = 1.9042e-03, PNorm = 58.8471, GNorm = 2.3074, lr_0 = 1.5703e-04
Loss = 1.1579e-03, PNorm = 58.8496, GNorm = 1.1333, lr_0 = 1.5682e-04
Loss = 1.8008e-03, PNorm = 58.8519, GNorm = 1.3731, lr_0 = 1.5661e-04
Loss = 1.2734e-03, PNorm = 58.8556, GNorm = 0.8111, lr_0 = 1.5640e-04
Loss = 1.9499e-03, PNorm = 58.8594, GNorm = 2.0376, lr_0 = 1.5619e-04
Loss = 1.1496e-03, PNorm = 58.8631, GNorm = 1.3324, lr_0 = 1.5598e-04
Loss = 1.5014e-03, PNorm = 58.8660, GNorm = 3.2608, lr_0 = 1.5577e-04
Loss = 1.2364e-03, PNorm = 58.8683, GNorm = 2.0043, lr_0 = 1.5556e-04
Loss = 1.2616e-03, PNorm = 58.8714, GNorm = 2.0759, lr_0 = 1.5535e-04
Loss = 2.2724e-03, PNorm = 58.8752, GNorm = 3.2454, lr_0 = 1.5514e-04
Loss = 1.6531e-03, PNorm = 58.8798, GNorm = 1.6569, lr_0 = 1.5493e-04
Loss = 1.4368e-03, PNorm = 58.8837, GNorm = 1.3643, lr_0 = 1.5473e-04
Loss = 1.5196e-03, PNorm = 58.8883, GNorm = 1.4485, lr_0 = 1.5452e-04
Loss = 1.2193e-03, PNorm = 58.8919, GNorm = 3.1797, lr_0 = 1.5431e-04
Loss = 1.7219e-03, PNorm = 58.8949, GNorm = 1.7954, lr_0 = 1.5410e-04
Loss = 1.4273e-03, PNorm = 58.8978, GNorm = 1.9226, lr_0 = 1.5390e-04
Loss = 1.8615e-03, PNorm = 58.9019, GNorm = 1.7640, lr_0 = 1.5369e-04
Loss = 1.5446e-03, PNorm = 58.9045, GNorm = 1.6702, lr_0 = 1.5348e-04
Loss = 1.5308e-03, PNorm = 58.9085, GNorm = 1.6719, lr_0 = 1.5328e-04
Loss = 2.2046e-03, PNorm = 58.9125, GNorm = 2.0708, lr_0 = 1.5307e-04
Validation rmse = 4.095232
Validation R2 = -3.922034
Epoch 61
Train function
Loss = 1.5344e-03, PNorm = 58.9161, GNorm = 2.1217, lr_0 = 1.5285e-04
Loss = 2.0474e-03, PNorm = 58.9195, GNorm = 2.0082, lr_0 = 1.5264e-04
Loss = 1.5125e-03, PNorm = 58.9222, GNorm = 1.8408, lr_0 = 1.5244e-04
Loss = 1.2718e-03, PNorm = 58.9249, GNorm = 2.7698, lr_0 = 1.5223e-04
Loss = 1.8718e-03, PNorm = 58.9278, GNorm = 2.2569, lr_0 = 1.5203e-04
Loss = 1.3901e-03, PNorm = 58.9308, GNorm = 1.8166, lr_0 = 1.5182e-04
Loss = 1.4347e-03, PNorm = 58.9339, GNorm = 2.3973, lr_0 = 1.5162e-04
Loss = 1.8196e-03, PNorm = 58.9384, GNorm = 1.9479, lr_0 = 1.5142e-04
Loss = 1.4057e-03, PNorm = 58.9417, GNorm = 1.3363, lr_0 = 1.5121e-04
Loss = 9.0573e-04, PNorm = 58.9432, GNorm = 1.5416, lr_0 = 1.5101e-04
Loss = 1.7813e-03, PNorm = 58.9450, GNorm = 1.5960, lr_0 = 1.5081e-04
Loss = 1.1421e-03, PNorm = 58.9477, GNorm = 1.7961, lr_0 = 1.5061e-04
Loss = 1.6342e-03, PNorm = 58.9504, GNorm = 1.8317, lr_0 = 1.5040e-04
Loss = 1.2774e-03, PNorm = 58.9534, GNorm = 1.6555, lr_0 = 1.5020e-04
Loss = 1.6848e-03, PNorm = 58.9577, GNorm = 1.7764, lr_0 = 1.5000e-04
Loss = 1.4940e-03, PNorm = 58.9609, GNorm = 2.6016, lr_0 = 1.4980e-04
Loss = 1.6519e-03, PNorm = 58.9655, GNorm = 2.0140, lr_0 = 1.4960e-04
Loss = 1.7375e-03, PNorm = 58.9684, GNorm = 2.3406, lr_0 = 1.4940e-04
Loss = 1.7385e-03, PNorm = 58.9710, GNorm = 2.3504, lr_0 = 1.4920e-04
Loss = 1.5606e-03, PNorm = 58.9727, GNorm = 2.1683, lr_0 = 1.4900e-04
Loss = 1.8517e-03, PNorm = 58.9746, GNorm = 2.1613, lr_0 = 1.4880e-04
Loss = 1.3474e-03, PNorm = 58.9774, GNorm = 1.3656, lr_0 = 1.4860e-04
Loss = 9.8924e-04, PNorm = 58.9803, GNorm = 1.5214, lr_0 = 1.4840e-04
Loss = 1.2482e-03, PNorm = 58.9827, GNorm = 2.3574, lr_0 = 1.4820e-04
Loss = 3.3079e-03, PNorm = 58.9830, GNorm = 1.8712, lr_0 = 1.4818e-04
Validation rmse = 4.040115
Validation R2 = -3.790435
Epoch 62
Train function
Loss = 8.4981e-04, PNorm = 58.9855, GNorm = 1.0333, lr_0 = 1.4798e-04
Loss = 1.7908e-03, PNorm = 58.9884, GNorm = 1.5658, lr_0 = 1.4778e-04
Loss = 1.4925e-03, PNorm = 58.9919, GNorm = 1.9611, lr_0 = 1.4758e-04
Loss = 9.7523e-04, PNorm = 58.9955, GNorm = 1.9860, lr_0 = 1.4739e-04
Loss = 1.4955e-03, PNorm = 58.9998, GNorm = 2.8538, lr_0 = 1.4719e-04
Loss = 1.7503e-03, PNorm = 59.0047, GNorm = 1.1959, lr_0 = 1.4699e-04
Loss = 1.2063e-03, PNorm = 59.0077, GNorm = 2.0288, lr_0 = 1.4679e-04
Loss = 9.1066e-04, PNorm = 59.0104, GNorm = 1.4269, lr_0 = 1.4660e-04
Loss = 1.7836e-03, PNorm = 59.0131, GNorm = 2.9333, lr_0 = 1.4640e-04
Loss = 1.3996e-03, PNorm = 59.0167, GNorm = 1.5736, lr_0 = 1.4620e-04
Loss = 1.2547e-03, PNorm = 59.0195, GNorm = 1.8162, lr_0 = 1.4601e-04
Loss = 1.4507e-03, PNorm = 59.0218, GNorm = 1.3487, lr_0 = 1.4581e-04
Loss = 1.3485e-03, PNorm = 59.0248, GNorm = 3.4171, lr_0 = 1.4562e-04
Loss = 1.3072e-03, PNorm = 59.0271, GNorm = 1.5384, lr_0 = 1.4542e-04
Loss = 1.5180e-03, PNorm = 59.0289, GNorm = 2.8516, lr_0 = 1.4522e-04
Loss = 1.3096e-03, PNorm = 59.0306, GNorm = 1.7429, lr_0 = 1.4503e-04
Loss = 1.5128e-03, PNorm = 59.0335, GNorm = 1.5544, lr_0 = 1.4484e-04
Loss = 1.7587e-03, PNorm = 59.0370, GNorm = 1.7603, lr_0 = 1.4464e-04
Loss = 1.4065e-03, PNorm = 59.0397, GNorm = 3.3089, lr_0 = 1.4445e-04
Loss = 1.5536e-03, PNorm = 59.0429, GNorm = 2.7536, lr_0 = 1.4425e-04
Loss = 1.3701e-03, PNorm = 59.0458, GNorm = 3.7054, lr_0 = 1.4406e-04
Loss = 1.5819e-03, PNorm = 59.0483, GNorm = 1.9672, lr_0 = 1.4387e-04
Loss = 1.6499e-03, PNorm = 59.0508, GNorm = 2.6240, lr_0 = 1.4367e-04
Validation rmse = 4.193627
Validation R2 = -4.161396
Epoch 63
Train function
Loss = 1.7347e-03, PNorm = 59.0546, GNorm = 1.6672, lr_0 = 1.4346e-04
Loss = 1.3604e-03, PNorm = 59.0572, GNorm = 1.6451, lr_0 = 1.4327e-04
Loss = 9.0727e-04, PNorm = 59.0598, GNorm = 2.1792, lr_0 = 1.4308e-04
Loss = 1.1298e-03, PNorm = 59.0620, GNorm = 2.3720, lr_0 = 1.4288e-04
Loss = 1.2171e-03, PNorm = 59.0641, GNorm = 1.9769, lr_0 = 1.4269e-04
Loss = 1.1636e-03, PNorm = 59.0662, GNorm = 2.0108, lr_0 = 1.4250e-04
Loss = 1.0967e-03, PNorm = 59.0691, GNorm = 0.7834, lr_0 = 1.4231e-04
Loss = 1.6355e-03, PNorm = 59.0718, GNorm = 1.7094, lr_0 = 1.4212e-04
Loss = 1.5610e-03, PNorm = 59.0752, GNorm = 2.9867, lr_0 = 1.4193e-04
Loss = 1.6829e-03, PNorm = 59.0794, GNorm = 1.3642, lr_0 = 1.4174e-04
Loss = 1.2706e-03, PNorm = 59.0824, GNorm = 3.0680, lr_0 = 1.4155e-04
Loss = 1.2081e-03, PNorm = 59.0839, GNorm = 1.6949, lr_0 = 1.4136e-04
Loss = 1.7216e-03, PNorm = 59.0862, GNorm = 1.4631, lr_0 = 1.4117e-04
Loss = 1.4881e-03, PNorm = 59.0891, GNorm = 1.2110, lr_0 = 1.4098e-04
Loss = 1.3506e-03, PNorm = 59.0926, GNorm = 2.0833, lr_0 = 1.4079e-04
Loss = 1.1482e-03, PNorm = 59.0962, GNorm = 1.6029, lr_0 = 1.4060e-04
Loss = 1.5654e-03, PNorm = 59.1003, GNorm = 1.0219, lr_0 = 1.4041e-04
Loss = 1.5920e-03, PNorm = 59.1023, GNorm = 2.0537, lr_0 = 1.4022e-04
Loss = 1.8916e-03, PNorm = 59.1048, GNorm = 1.6781, lr_0 = 1.4004e-04
Loss = 1.7047e-03, PNorm = 59.1081, GNorm = 2.7881, lr_0 = 1.3985e-04
Loss = 1.4048e-03, PNorm = 59.1110, GNorm = 2.0558, lr_0 = 1.3966e-04
Loss = 1.1733e-03, PNorm = 59.1141, GNorm = 1.1285, lr_0 = 1.3947e-04
Loss = 1.6686e-03, PNorm = 59.1174, GNorm = 2.1891, lr_0 = 1.3929e-04
Validation rmse = 3.911217
Validation R2 = -3.489638
Epoch 64
Train function
Loss = 6.3947e-04, PNorm = 59.1200, GNorm = 1.5529, lr_0 = 1.3908e-04
Loss = 1.7646e-03, PNorm = 59.1211, GNorm = 1.4398, lr_0 = 1.3889e-04
Loss = 1.4653e-03, PNorm = 59.1222, GNorm = 2.2174, lr_0 = 1.3871e-04
Loss = 1.2362e-03, PNorm = 59.1253, GNorm = 2.0827, lr_0 = 1.3852e-04
Loss = 1.3025e-03, PNorm = 59.1291, GNorm = 1.8688, lr_0 = 1.3834e-04
Loss = 1.0520e-03, PNorm = 59.1323, GNorm = 2.2987, lr_0 = 1.3815e-04
Loss = 1.1858e-03, PNorm = 59.1345, GNorm = 2.9159, lr_0 = 1.3796e-04
Loss = 1.2252e-03, PNorm = 59.1374, GNorm = 1.6831, lr_0 = 1.3778e-04
Loss = 2.0040e-03, PNorm = 59.1401, GNorm = 1.6587, lr_0 = 1.3759e-04
Loss = 1.5420e-03, PNorm = 59.1427, GNorm = 2.7877, lr_0 = 1.3741e-04
Loss = 9.7812e-04, PNorm = 59.1454, GNorm = 1.8496, lr_0 = 1.3723e-04
Loss = 1.7462e-03, PNorm = 59.1487, GNorm = 1.5028, lr_0 = 1.3704e-04
Loss = 1.6493e-03, PNorm = 59.1524, GNorm = 2.6477, lr_0 = 1.3686e-04
Loss = 1.1563e-03, PNorm = 59.1558, GNorm = 2.4002, lr_0 = 1.3667e-04
Loss = 1.4304e-03, PNorm = 59.1591, GNorm = 1.6045, lr_0 = 1.3649e-04
Loss = 1.3213e-03, PNorm = 59.1624, GNorm = 1.9896, lr_0 = 1.3631e-04
Loss = 1.7156e-03, PNorm = 59.1664, GNorm = 1.1540, lr_0 = 1.3612e-04
Loss = 1.0422e-03, PNorm = 59.1690, GNorm = 2.5518, lr_0 = 1.3594e-04
Loss = 1.1812e-03, PNorm = 59.1711, GNorm = 1.9647, lr_0 = 1.3576e-04
Loss = 1.5491e-03, PNorm = 59.1729, GNorm = 1.6347, lr_0 = 1.3558e-04
Loss = 1.0984e-03, PNorm = 59.1757, GNorm = 1.7951, lr_0 = 1.3540e-04
Loss = 1.5556e-03, PNorm = 59.1787, GNorm = 1.8164, lr_0 = 1.3521e-04
Loss = 1.1353e-03, PNorm = 59.1816, GNorm = 1.4672, lr_0 = 1.3503e-04
Loss = 1.1889e-03, PNorm = 59.1842, GNorm = 1.8035, lr_0 = 1.3485e-04
Validation rmse = 4.176916
Validation R2 = -4.120342
Epoch 65
Train function
Loss = 9.6513e-04, PNorm = 59.1865, GNorm = 1.6699, lr_0 = 1.3467e-04
Loss = 7.8596e-04, PNorm = 59.1880, GNorm = 1.8741, lr_0 = 1.3449e-04
Loss = 8.6265e-04, PNorm = 59.1890, GNorm = 1.2758, lr_0 = 1.3431e-04
Loss = 1.0128e-03, PNorm = 59.1909, GNorm = 1.3629, lr_0 = 1.3413e-04
Loss = 1.4828e-03, PNorm = 59.1935, GNorm = 3.3414, lr_0 = 1.3395e-04
Loss = 1.0377e-03, PNorm = 59.1958, GNorm = 2.3785, lr_0 = 1.3377e-04
Loss = 1.4297e-03, PNorm = 59.1990, GNorm = 1.8186, lr_0 = 1.3359e-04
Loss = 9.8095e-04, PNorm = 59.2017, GNorm = 1.9057, lr_0 = 1.3341e-04
Loss = 1.3827e-03, PNorm = 59.2036, GNorm = 1.8406, lr_0 = 1.3323e-04
Loss = 1.4910e-03, PNorm = 59.2063, GNorm = 1.9665, lr_0 = 1.3305e-04
Loss = 1.2143e-03, PNorm = 59.2076, GNorm = 3.0784, lr_0 = 1.3287e-04
Loss = 1.7250e-03, PNorm = 59.2081, GNorm = 2.3691, lr_0 = 1.3270e-04
Loss = 1.2882e-03, PNorm = 59.2099, GNorm = 2.0786, lr_0 = 1.3252e-04
Loss = 1.4328e-03, PNorm = 59.2128, GNorm = 1.2674, lr_0 = 1.3234e-04
Loss = 1.2922e-03, PNorm = 59.2172, GNorm = 1.6547, lr_0 = 1.3216e-04
Loss = 1.2080e-03, PNorm = 59.2210, GNorm = 1.3919, lr_0 = 1.3199e-04
Loss = 1.3505e-03, PNorm = 59.2242, GNorm = 1.6024, lr_0 = 1.3181e-04
Loss = 1.6017e-03, PNorm = 59.2266, GNorm = 1.1337, lr_0 = 1.3163e-04
Loss = 1.2660e-03, PNorm = 59.2284, GNorm = 2.7481, lr_0 = 1.3145e-04
Loss = 1.2780e-03, PNorm = 59.2299, GNorm = 1.4223, lr_0 = 1.3128e-04
Loss = 1.4057e-03, PNorm = 59.2321, GNorm = 1.6168, lr_0 = 1.3110e-04
Loss = 1.5819e-03, PNorm = 59.2337, GNorm = 2.1506, lr_0 = 1.3093e-04
Loss = 1.0749e-03, PNorm = 59.2370, GNorm = 1.9198, lr_0 = 1.3075e-04
Validation rmse = 4.211709
Validation R2 = -4.206000
Epoch 66
Train function
Loss = 1.3207e-03, PNorm = 59.2401, GNorm = 1.6004, lr_0 = 1.3056e-04
Loss = 1.1852e-03, PNorm = 59.2422, GNorm = 2.8804, lr_0 = 1.3038e-04
Loss = 1.2582e-03, PNorm = 59.2447, GNorm = 2.0630, lr_0 = 1.3021e-04
Loss = 1.1021e-03, PNorm = 59.2463, GNorm = 1.3731, lr_0 = 1.3003e-04
Loss = 9.8025e-04, PNorm = 59.2487, GNorm = 1.3385, lr_0 = 1.2986e-04
Loss = 8.6700e-04, PNorm = 59.2508, GNorm = 1.5148, lr_0 = 1.2968e-04
Loss = 1.1370e-03, PNorm = 59.2532, GNorm = 1.1568, lr_0 = 1.2951e-04
Loss = 8.6117e-04, PNorm = 59.2546, GNorm = 2.6201, lr_0 = 1.2934e-04
Loss = 1.5584e-03, PNorm = 59.2568, GNorm = 2.9057, lr_0 = 1.2916e-04
Loss = 8.7176e-04, PNorm = 59.2589, GNorm = 1.2277, lr_0 = 1.2899e-04
Loss = 1.0752e-03, PNorm = 59.2615, GNorm = 2.4777, lr_0 = 1.2882e-04
Loss = 1.1903e-03, PNorm = 59.2632, GNorm = 1.8025, lr_0 = 1.2864e-04
Loss = 1.3392e-03, PNorm = 59.2655, GNorm = 2.3184, lr_0 = 1.2847e-04
Loss = 1.7249e-03, PNorm = 59.2679, GNorm = 3.1318, lr_0 = 1.2830e-04
Loss = 1.2554e-03, PNorm = 59.2706, GNorm = 1.9896, lr_0 = 1.2813e-04
Loss = 1.3977e-03, PNorm = 59.2733, GNorm = 1.6437, lr_0 = 1.2795e-04
Loss = 9.9259e-04, PNorm = 59.2765, GNorm = 1.1948, lr_0 = 1.2778e-04
Loss = 1.3771e-03, PNorm = 59.2790, GNorm = 3.0322, lr_0 = 1.2761e-04
Loss = 1.3176e-03, PNorm = 59.2818, GNorm = 2.2681, lr_0 = 1.2744e-04
Loss = 1.2728e-03, PNorm = 59.2833, GNorm = 3.0363, lr_0 = 1.2727e-04
Loss = 1.5622e-03, PNorm = 59.2859, GNorm = 3.4140, lr_0 = 1.2710e-04
Loss = 1.5294e-03, PNorm = 59.2898, GNorm = 1.8564, lr_0 = 1.2693e-04
Loss = 1.2232e-03, PNorm = 59.2921, GNorm = 1.9754, lr_0 = 1.2676e-04
Loss = 1.0872e-03, PNorm = 59.2949, GNorm = 2.4721, lr_0 = 1.2659e-04
Validation rmse = 3.978447
Validation R2 = -3.645310
Epoch 67
Train function
Loss = 9.1176e-04, PNorm = 59.2979, GNorm = 2.1227, lr_0 = 1.2640e-04
Loss = 1.5708e-03, PNorm = 59.2993, GNorm = 2.3071, lr_0 = 1.2623e-04
Loss = 1.1405e-03, PNorm = 59.3007, GNorm = 2.4167, lr_0 = 1.2606e-04
Loss = 7.6275e-04, PNorm = 59.3022, GNorm = 1.7632, lr_0 = 1.2589e-04
Loss = 1.3875e-03, PNorm = 59.3046, GNorm = 1.4157, lr_0 = 1.2572e-04
Loss = 1.1365e-03, PNorm = 59.3069, GNorm = 2.0733, lr_0 = 1.2555e-04
Loss = 7.7444e-04, PNorm = 59.3094, GNorm = 1.2825, lr_0 = 1.2539e-04
Loss = 1.0604e-03, PNorm = 59.3113, GNorm = 1.4277, lr_0 = 1.2522e-04
Loss = 1.1911e-03, PNorm = 59.3142, GNorm = 1.2898, lr_0 = 1.2505e-04
Loss = 1.0533e-03, PNorm = 59.3166, GNorm = 1.9958, lr_0 = 1.2488e-04
Loss = 8.9191e-04, PNorm = 59.3184, GNorm = 2.0564, lr_0 = 1.2471e-04
Loss = 9.0959e-04, PNorm = 59.3208, GNorm = 2.1081, lr_0 = 1.2455e-04
Loss = 9.6620e-04, PNorm = 59.3235, GNorm = 1.8233, lr_0 = 1.2438e-04
Loss = 1.3270e-03, PNorm = 59.3262, GNorm = 1.7745, lr_0 = 1.2421e-04
Loss = 1.2015e-03, PNorm = 59.3292, GNorm = 2.1143, lr_0 = 1.2405e-04
Loss = 1.0276e-03, PNorm = 59.3312, GNorm = 1.7382, lr_0 = 1.2388e-04
Loss = 1.3375e-03, PNorm = 59.3336, GNorm = 2.1122, lr_0 = 1.2371e-04
Loss = 1.1357e-03, PNorm = 59.3366, GNorm = 2.2880, lr_0 = 1.2355e-04
Loss = 1.0936e-03, PNorm = 59.3399, GNorm = 2.5688, lr_0 = 1.2338e-04
Loss = 1.2811e-03, PNorm = 59.3413, GNorm = 1.4386, lr_0 = 1.2322e-04
Loss = 1.0169e-03, PNorm = 59.3437, GNorm = 1.3752, lr_0 = 1.2305e-04
Loss = 1.9474e-03, PNorm = 59.3471, GNorm = 2.6157, lr_0 = 1.2289e-04
Loss = 1.2265e-03, PNorm = 59.3501, GNorm = 1.1222, lr_0 = 1.2272e-04
Validation rmse = 4.312397
Validation R2 = -4.457893
Epoch 68
Train function
Loss = 1.2361e-03, PNorm = 59.3547, GNorm = 1.5129, lr_0 = 1.2254e-04
Loss = 1.0659e-03, PNorm = 59.3585, GNorm = 1.3289, lr_0 = 1.2238e-04
Loss = 1.4126e-03, PNorm = 59.3608, GNorm = 1.1365, lr_0 = 1.2221e-04
Loss = 1.4290e-03, PNorm = 59.3634, GNorm = 2.6810, lr_0 = 1.2205e-04
Loss = 1.1057e-03, PNorm = 59.3660, GNorm = 1.2554, lr_0 = 1.2188e-04
Loss = 1.0097e-03, PNorm = 59.3685, GNorm = 1.3886, lr_0 = 1.2172e-04
Loss = 1.2546e-03, PNorm = 59.3717, GNorm = 1.4382, lr_0 = 1.2156e-04
Loss = 6.8772e-04, PNorm = 59.3745, GNorm = 1.3890, lr_0 = 1.2139e-04
Loss = 1.1440e-03, PNorm = 59.3765, GNorm = 1.3919, lr_0 = 1.2123e-04
Loss = 8.2118e-04, PNorm = 59.3777, GNorm = 1.4127, lr_0 = 1.2107e-04
Loss = 1.0759e-03, PNorm = 59.3788, GNorm = 1.0802, lr_0 = 1.2091e-04
Loss = 9.4432e-04, PNorm = 59.3811, GNorm = 1.0563, lr_0 = 1.2074e-04
Loss = 1.1220e-03, PNorm = 59.3834, GNorm = 0.9562, lr_0 = 1.2058e-04
Loss = 1.1029e-03, PNorm = 59.3854, GNorm = 2.4356, lr_0 = 1.2042e-04
Loss = 1.2331e-03, PNorm = 59.3871, GNorm = 1.8784, lr_0 = 1.2026e-04
Loss = 1.2941e-03, PNorm = 59.3898, GNorm = 1.2613, lr_0 = 1.2010e-04
Loss = 1.1270e-03, PNorm = 59.3925, GNorm = 1.3031, lr_0 = 1.1994e-04
Loss = 1.4917e-03, PNorm = 59.3947, GNorm = 1.7408, lr_0 = 1.1978e-04
Loss = 1.1556e-03, PNorm = 59.3961, GNorm = 1.3475, lr_0 = 1.1961e-04
Loss = 1.1378e-03, PNorm = 59.3986, GNorm = 1.8083, lr_0 = 1.1945e-04
Loss = 1.4460e-03, PNorm = 59.4014, GNorm = 1.1679, lr_0 = 1.1929e-04
Loss = 8.6661e-04, PNorm = 59.4028, GNorm = 1.7228, lr_0 = 1.1913e-04
Loss = 1.0342e-03, PNorm = 59.4036, GNorm = 1.8850, lr_0 = 1.1897e-04
Validation rmse = 4.144965
Validation R2 = -4.042306
Epoch 69
Train function
Loss = 4.3542e-04, PNorm = 59.4049, GNorm = 0.9440, lr_0 = 1.1880e-04
Loss = 1.0214e-03, PNorm = 59.4065, GNorm = 1.2259, lr_0 = 1.1864e-04
Loss = 1.2058e-03, PNorm = 59.4089, GNorm = 2.2812, lr_0 = 1.1848e-04
Loss = 9.0187e-04, PNorm = 59.4119, GNorm = 1.0816, lr_0 = 1.1832e-04
Loss = 1.7249e-03, PNorm = 59.4153, GNorm = 2.9757, lr_0 = 1.1816e-04
Loss = 9.9636e-04, PNorm = 59.4189, GNorm = 1.6810, lr_0 = 1.1800e-04
Loss = 1.2074e-03, PNorm = 59.4213, GNorm = 2.8299, lr_0 = 1.1785e-04
Loss = 1.0937e-03, PNorm = 59.4236, GNorm = 2.4272, lr_0 = 1.1769e-04
Loss = 9.2541e-04, PNorm = 59.4264, GNorm = 1.3129, lr_0 = 1.1753e-04
Loss = 9.0433e-04, PNorm = 59.4292, GNorm = 0.8342, lr_0 = 1.1737e-04
Loss = 1.2063e-03, PNorm = 59.4309, GNorm = 2.9342, lr_0 = 1.1721e-04
Loss = 1.0551e-03, PNorm = 59.4321, GNorm = 2.2081, lr_0 = 1.1706e-04
Loss = 8.5488e-04, PNorm = 59.4327, GNorm = 0.8783, lr_0 = 1.1690e-04
Loss = 9.4799e-04, PNorm = 59.4338, GNorm = 1.2641, lr_0 = 1.1674e-04
Loss = 2.0614e-03, PNorm = 59.4361, GNorm = 1.7623, lr_0 = 1.1659e-04
Loss = 1.1033e-03, PNorm = 59.4389, GNorm = 1.8247, lr_0 = 1.1643e-04
Loss = 1.0171e-03, PNorm = 59.4410, GNorm = 2.1892, lr_0 = 1.1627e-04
Loss = 9.3321e-04, PNorm = 59.4424, GNorm = 1.7409, lr_0 = 1.1612e-04
Loss = 6.6937e-04, PNorm = 59.4439, GNorm = 1.4810, lr_0 = 1.1596e-04
Loss = 9.7358e-04, PNorm = 59.4457, GNorm = 1.6813, lr_0 = 1.1581e-04
Loss = 7.5552e-04, PNorm = 59.4477, GNorm = 1.5639, lr_0 = 1.1565e-04
Loss = 8.3227e-04, PNorm = 59.4494, GNorm = 1.0002, lr_0 = 1.1550e-04
Loss = 1.1486e-03, PNorm = 59.4517, GNorm = 1.8856, lr_0 = 1.1534e-04
Loss = 8.6212e-04, PNorm = 59.4539, GNorm = 1.8161, lr_0 = 1.1519e-04
Validation rmse = 4.153673
Validation R2 = -4.063516
Epoch 70
Train function
Loss = 1.2090e-03, PNorm = 59.4563, GNorm = 3.0631, lr_0 = 1.1503e-04
Loss = 9.2892e-04, PNorm = 59.4585, GNorm = 1.2822, lr_0 = 1.1488e-04
Loss = 1.1268e-03, PNorm = 59.4608, GNorm = 1.0121, lr_0 = 1.1472e-04
Loss = 8.1355e-04, PNorm = 59.4630, GNorm = 1.3379, lr_0 = 1.1457e-04
Loss = 1.2076e-03, PNorm = 59.4654, GNorm = 1.2723, lr_0 = 1.1442e-04
Loss = 9.5077e-04, PNorm = 59.4677, GNorm = 2.0936, lr_0 = 1.1426e-04
Loss = 1.0138e-03, PNorm = 59.4701, GNorm = 1.3656, lr_0 = 1.1411e-04
Loss = 7.5308e-04, PNorm = 59.4727, GNorm = 1.7007, lr_0 = 1.1396e-04
Loss = 6.2509e-04, PNorm = 59.4753, GNorm = 1.2882, lr_0 = 1.1380e-04
Loss = 9.8233e-04, PNorm = 59.4773, GNorm = 1.3320, lr_0 = 1.1365e-04
Loss = 9.6219e-04, PNorm = 59.4793, GNorm = 2.4059, lr_0 = 1.1350e-04
Loss = 1.1130e-03, PNorm = 59.4811, GNorm = 1.2256, lr_0 = 1.1334e-04
Loss = 8.5751e-04, PNorm = 59.4814, GNorm = 1.3229, lr_0 = 1.1319e-04
Loss = 1.0161e-03, PNorm = 59.4818, GNorm = 1.3963, lr_0 = 1.1304e-04
Loss = 1.1095e-03, PNorm = 59.4836, GNorm = 1.8723, lr_0 = 1.1289e-04
Loss = 1.1856e-03, PNorm = 59.4863, GNorm = 1.4817, lr_0 = 1.1274e-04
Loss = 8.1954e-04, PNorm = 59.4880, GNorm = 1.0055, lr_0 = 1.1259e-04
Loss = 9.3051e-04, PNorm = 59.4899, GNorm = 0.7700, lr_0 = 1.1244e-04
Loss = 1.6434e-03, PNorm = 59.4923, GNorm = 1.8098, lr_0 = 1.1228e-04
Loss = 8.3900e-04, PNorm = 59.4941, GNorm = 1.3753, lr_0 = 1.1213e-04
Loss = 8.2963e-04, PNorm = 59.4961, GNorm = 1.4594, lr_0 = 1.1198e-04
Loss = 1.0974e-03, PNorm = 59.4981, GNorm = 1.4340, lr_0 = 1.1183e-04
Loss = 1.0785e-03, PNorm = 59.5004, GNorm = 1.2365, lr_0 = 1.1168e-04
Validation rmse = 4.009471
Validation R2 = -3.718041
Epoch 71
Train function
Loss = 7.4126e-04, PNorm = 59.5020, GNorm = 1.7828, lr_0 = 1.1152e-04
Loss = 1.2341e-03, PNorm = 59.5043, GNorm = 2.4781, lr_0 = 1.1137e-04
Loss = 6.9647e-04, PNorm = 59.5064, GNorm = 1.6060, lr_0 = 1.1122e-04
Loss = 1.0452e-03, PNorm = 59.5080, GNorm = 1.8066, lr_0 = 1.1107e-04
Loss = 9.5549e-04, PNorm = 59.5095, GNorm = 1.2629, lr_0 = 1.1092e-04
Loss = 7.8621e-04, PNorm = 59.5103, GNorm = 1.4674, lr_0 = 1.1077e-04
Loss = 7.0662e-04, PNorm = 59.5119, GNorm = 1.9187, lr_0 = 1.1062e-04
Loss = 7.7036e-04, PNorm = 59.5137, GNorm = 0.9138, lr_0 = 1.1048e-04
Loss = 9.4130e-04, PNorm = 59.5158, GNorm = 1.1549, lr_0 = 1.1033e-04
Loss = 8.4625e-04, PNorm = 59.5176, GNorm = 0.7613, lr_0 = 1.1018e-04
Loss = 9.6090e-04, PNorm = 59.5193, GNorm = 2.5004, lr_0 = 1.1003e-04
Loss = 1.0385e-03, PNorm = 59.5220, GNorm = 2.3483, lr_0 = 1.0988e-04
Loss = 1.1226e-03, PNorm = 59.5237, GNorm = 1.6936, lr_0 = 1.0974e-04
Loss = 8.1691e-04, PNorm = 59.5254, GNorm = 1.3740, lr_0 = 1.0959e-04
Loss = 1.1006e-03, PNorm = 59.5278, GNorm = 3.3937, lr_0 = 1.0944e-04
Loss = 1.1109e-03, PNorm = 59.5299, GNorm = 1.9487, lr_0 = 1.0930e-04
Loss = 1.0567e-03, PNorm = 59.5318, GNorm = 1.3735, lr_0 = 1.0915e-04
Loss = 7.7859e-04, PNorm = 59.5335, GNorm = 1.6567, lr_0 = 1.0900e-04
Loss = 1.0248e-03, PNorm = 59.5350, GNorm = 1.3743, lr_0 = 1.0886e-04
Loss = 1.2673e-03, PNorm = 59.5368, GNorm = 3.0638, lr_0 = 1.0871e-04
Loss = 1.4013e-03, PNorm = 59.5398, GNorm = 1.6566, lr_0 = 1.0856e-04
Loss = 8.9123e-04, PNorm = 59.5417, GNorm = 1.6786, lr_0 = 1.0842e-04
Loss = 8.1074e-04, PNorm = 59.5430, GNorm = 1.0874, lr_0 = 1.0827e-04
Loss = 1.1477e-03, PNorm = 59.5449, GNorm = 1.1662, lr_0 = 1.0813e-04
Validation rmse = 4.269107
Validation R2 = -4.348864
Epoch 72
Train function
Loss = 8.7305e-04, PNorm = 59.5474, GNorm = 1.7763, lr_0 = 1.0797e-04
Loss = 9.6413e-04, PNorm = 59.5495, GNorm = 1.2322, lr_0 = 1.0782e-04
Loss = 1.2645e-03, PNorm = 59.5515, GNorm = 1.0216, lr_0 = 1.0768e-04
Loss = 6.8078e-04, PNorm = 59.5539, GNorm = 1.0335, lr_0 = 1.0753e-04
Loss = 8.8049e-04, PNorm = 59.5557, GNorm = 1.9030, lr_0 = 1.0739e-04
Loss = 7.4936e-04, PNorm = 59.5576, GNorm = 2.3666, lr_0 = 1.0725e-04
Loss = 8.2919e-04, PNorm = 59.5597, GNorm = 1.6565, lr_0 = 1.0710e-04
Loss = 7.5990e-04, PNorm = 59.5603, GNorm = 0.8418, lr_0 = 1.0696e-04
Loss = 7.9463e-04, PNorm = 59.5623, GNorm = 1.1929, lr_0 = 1.0681e-04
Loss = 8.6489e-04, PNorm = 59.5644, GNorm = 2.0379, lr_0 = 1.0667e-04
Loss = 9.1383e-04, PNorm = 59.5657, GNorm = 2.4324, lr_0 = 1.0653e-04
Loss = 9.9170e-04, PNorm = 59.5676, GNorm = 1.6975, lr_0 = 1.0639e-04
Loss = 7.7093e-04, PNorm = 59.5694, GNorm = 1.3887, lr_0 = 1.0624e-04
Loss = 7.0236e-04, PNorm = 59.5708, GNorm = 2.4367, lr_0 = 1.0610e-04
Loss = 1.4722e-03, PNorm = 59.5730, GNorm = 1.5333, lr_0 = 1.0596e-04
Loss = 1.1411e-03, PNorm = 59.5743, GNorm = 1.3241, lr_0 = 1.0582e-04
Loss = 1.0157e-03, PNorm = 59.5754, GNorm = 1.7053, lr_0 = 1.0567e-04
Loss = 9.2351e-04, PNorm = 59.5774, GNorm = 1.6708, lr_0 = 1.0553e-04
Loss = 7.6983e-04, PNorm = 59.5794, GNorm = 1.2342, lr_0 = 1.0539e-04
Loss = 9.8844e-04, PNorm = 59.5818, GNorm = 2.6577, lr_0 = 1.0525e-04
Loss = 1.0631e-03, PNorm = 59.5838, GNorm = 1.1528, lr_0 = 1.0511e-04
Loss = 1.4608e-03, PNorm = 59.5860, GNorm = 2.5029, lr_0 = 1.0497e-04
Loss = 7.7071e-04, PNorm = 59.5874, GNorm = 1.4443, lr_0 = 1.0483e-04
Validation rmse = 4.121468
Validation R2 = -3.985300
Epoch 73
Train function
Loss = 1.0971e-03, PNorm = 59.5889, GNorm = 2.0142, lr_0 = 1.0467e-04
Loss = 9.8973e-04, PNorm = 59.5909, GNorm = 2.1977, lr_0 = 1.0453e-04
Loss = 7.6544e-04, PNorm = 59.5922, GNorm = 1.3476, lr_0 = 1.0439e-04
Loss = 6.5245e-04, PNorm = 59.5928, GNorm = 1.1575, lr_0 = 1.0425e-04
Loss = 7.7541e-04, PNorm = 59.5936, GNorm = 2.2229, lr_0 = 1.0411e-04
Loss = 7.9412e-04, PNorm = 59.5946, GNorm = 1.0043, lr_0 = 1.0397e-04
Loss = 1.3371e-03, PNorm = 59.5958, GNorm = 3.6109, lr_0 = 1.0383e-04
Loss = 7.0436e-04, PNorm = 59.5978, GNorm = 1.3765, lr_0 = 1.0369e-04
Loss = 7.3536e-04, PNorm = 59.5996, GNorm = 2.2299, lr_0 = 1.0355e-04
Loss = 6.1729e-04, PNorm = 59.6010, GNorm = 1.5017, lr_0 = 1.0341e-04
Loss = 9.0465e-04, PNorm = 59.6022, GNorm = 1.9425, lr_0 = 1.0327e-04
Loss = 1.0856e-03, PNorm = 59.6040, GNorm = 1.5713, lr_0 = 1.0314e-04
Loss = 1.1401e-03, PNorm = 59.6066, GNorm = 1.9659, lr_0 = 1.0300e-04
Loss = 8.4760e-04, PNorm = 59.6092, GNorm = 1.4129, lr_0 = 1.0286e-04
Loss = 9.3716e-04, PNorm = 59.6118, GNorm = 1.0212, lr_0 = 1.0272e-04
Loss = 1.1104e-03, PNorm = 59.6144, GNorm = 1.0095, lr_0 = 1.0258e-04
Loss = 7.0394e-04, PNorm = 59.6161, GNorm = 2.6537, lr_0 = 1.0245e-04
Loss = 6.9958e-04, PNorm = 59.6181, GNorm = 0.7716, lr_0 = 1.0231e-04
Loss = 1.0894e-03, PNorm = 59.6204, GNorm = 1.7753, lr_0 = 1.0217e-04
Loss = 7.9914e-04, PNorm = 59.6220, GNorm = 0.6640, lr_0 = 1.0203e-04
Loss = 8.3659e-04, PNorm = 59.6239, GNorm = 1.8652, lr_0 = 1.0190e-04
Loss = 9.2476e-04, PNorm = 59.6258, GNorm = 1.5340, lr_0 = 1.0176e-04
Loss = 9.0508e-04, PNorm = 59.6285, GNorm = 1.0893, lr_0 = 1.0162e-04
Loss = 1.2080e-03, PNorm = 59.6310, GNorm = 2.4512, lr_0 = 1.0149e-04
Loss = 1.4184e-03, PNorm = 59.6314, GNorm = 1.8370, lr_0 = 1.0147e-04
Validation rmse = 4.275739
Validation R2 = -4.365497
Epoch 74
Train function
Loss = 6.7900e-04, PNorm = 59.6337, GNorm = 1.7266, lr_0 = 1.0134e-04
Loss = 7.0119e-04, PNorm = 59.6355, GNorm = 1.7673, lr_0 = 1.0120e-04
Loss = 7.7644e-04, PNorm = 59.6367, GNorm = 1.5996, lr_0 = 1.0107e-04
Loss = 8.1341e-04, PNorm = 59.6379, GNorm = 1.4619, lr_0 = 1.0093e-04
Loss = 6.5573e-04, PNorm = 59.6394, GNorm = 1.1935, lr_0 = 1.0080e-04
Loss = 5.4613e-04, PNorm = 59.6410, GNorm = 1.5574, lr_0 = 1.0066e-04
Loss = 8.6921e-04, PNorm = 59.6429, GNorm = 1.0097, lr_0 = 1.0052e-04
Loss = 7.0573e-04, PNorm = 59.6446, GNorm = 1.1113, lr_0 = 1.0039e-04
Loss = 7.6533e-04, PNorm = 59.6467, GNorm = 1.5422, lr_0 = 1.0026e-04
Loss = 8.3366e-04, PNorm = 59.6480, GNorm = 2.7146, lr_0 = 1.0012e-04
Loss = 7.4679e-04, PNorm = 59.6492, GNorm = 1.6667, lr_0 = 1.0000e-04
Loss = 6.8602e-04, PNorm = 59.6508, GNorm = 1.9083, lr_0 = 1.0000e-04
Loss = 8.0952e-04, PNorm = 59.6526, GNorm = 1.3837, lr_0 = 1.0000e-04
Loss = 8.2106e-04, PNorm = 59.6547, GNorm = 1.2348, lr_0 = 1.0000e-04
Loss = 1.1991e-03, PNorm = 59.6564, GNorm = 2.1139, lr_0 = 1.0000e-04
Loss = 1.2952e-03, PNorm = 59.6575, GNorm = 1.6021, lr_0 = 1.0000e-04
Loss = 1.1198e-03, PNorm = 59.6585, GNorm = 1.2913, lr_0 = 1.0000e-04
Loss = 8.8625e-04, PNorm = 59.6600, GNorm = 1.9510, lr_0 = 1.0000e-04
Loss = 9.6325e-04, PNorm = 59.6622, GNorm = 1.5724, lr_0 = 1.0000e-04
Loss = 1.1772e-03, PNorm = 59.6649, GNorm = 1.8752, lr_0 = 1.0000e-04
Loss = 7.8260e-04, PNorm = 59.6673, GNorm = 1.7323, lr_0 = 1.0000e-04
Loss = 1.5847e-03, PNorm = 59.6687, GNorm = 1.2121, lr_0 = 1.0000e-04
Loss = 8.6353e-04, PNorm = 59.6701, GNorm = 2.8639, lr_0 = 1.0000e-04
Validation rmse = 4.156512
Validation R2 = -4.070439
Epoch 75
Train function
Loss = 1.0380e-03, PNorm = 59.6717, GNorm = 2.4553, lr_0 = 1.0000e-04
Loss = 6.0692e-04, PNorm = 59.6740, GNorm = 1.4866, lr_0 = 1.0000e-04
Loss = 6.9884e-04, PNorm = 59.6761, GNorm = 1.6057, lr_0 = 1.0000e-04
Loss = 1.0890e-03, PNorm = 59.6777, GNorm = 1.2975, lr_0 = 1.0000e-04
Loss = 6.7898e-04, PNorm = 59.6801, GNorm = 0.9830, lr_0 = 1.0000e-04
Loss = 7.8091e-04, PNorm = 59.6823, GNorm = 1.0169, lr_0 = 1.0000e-04
Loss = 8.5632e-04, PNorm = 59.6838, GNorm = 1.9786, lr_0 = 1.0000e-04
Loss = 7.2342e-04, PNorm = 59.6848, GNorm = 0.9600, lr_0 = 1.0000e-04
Loss = 9.5720e-04, PNorm = 59.6855, GNorm = 2.0274, lr_0 = 1.0000e-04
Loss = 7.6350e-04, PNorm = 59.6866, GNorm = 1.1793, lr_0 = 1.0000e-04
Loss = 7.8566e-04, PNorm = 59.6886, GNorm = 1.8023, lr_0 = 1.0000e-04
Loss = 6.3455e-04, PNorm = 59.6904, GNorm = 1.6089, lr_0 = 1.0000e-04
Loss = 9.3313e-04, PNorm = 59.6917, GNorm = 1.2937, lr_0 = 1.0000e-04
Loss = 6.9513e-04, PNorm = 59.6931, GNorm = 0.9493, lr_0 = 1.0000e-04
Loss = 6.9035e-04, PNorm = 59.6946, GNorm = 1.3014, lr_0 = 1.0000e-04
Loss = 5.3200e-04, PNorm = 59.6963, GNorm = 1.0750, lr_0 = 1.0000e-04
Loss = 1.1432e-03, PNorm = 59.6987, GNorm = 1.4565, lr_0 = 1.0000e-04
Loss = 7.9765e-04, PNorm = 59.7004, GNorm = 1.7122, lr_0 = 1.0000e-04
Loss = 8.5771e-04, PNorm = 59.7025, GNorm = 1.2493, lr_0 = 1.0000e-04
Loss = 6.6203e-04, PNorm = 59.7049, GNorm = 1.2456, lr_0 = 1.0000e-04
Loss = 1.1905e-03, PNorm = 59.7063, GNorm = 1.3751, lr_0 = 1.0000e-04
Loss = 8.3429e-04, PNorm = 59.7084, GNorm = 2.6298, lr_0 = 1.0000e-04
Loss = 7.2239e-04, PNorm = 59.7105, GNorm = 1.8847, lr_0 = 1.0000e-04
Validation rmse = 4.067318
Validation R2 = -3.855163
Epoch 76
Train function
Loss = 1.4176e-03, PNorm = 59.7123, GNorm = 2.0029, lr_0 = 1.0000e-04
Loss = 1.5063e-03, PNorm = 59.7150, GNorm = 1.5471, lr_0 = 1.0000e-04
Loss = 8.4762e-04, PNorm = 59.7174, GNorm = 1.4617, lr_0 = 1.0000e-04
Loss = 7.3385e-04, PNorm = 59.7194, GNorm = 0.8519, lr_0 = 1.0000e-04
Loss = 7.0371e-04, PNorm = 59.7215, GNorm = 0.9642, lr_0 = 1.0000e-04
Loss = 1.0434e-03, PNorm = 59.7240, GNorm = 1.0503, lr_0 = 1.0000e-04
Loss = 6.0738e-04, PNorm = 59.7258, GNorm = 0.9408, lr_0 = 1.0000e-04
Loss = 9.2818e-04, PNorm = 59.7278, GNorm = 1.4175, lr_0 = 1.0000e-04
Loss = 6.7802e-04, PNorm = 59.7291, GNorm = 1.6220, lr_0 = 1.0000e-04
Loss = 8.3685e-04, PNorm = 59.7304, GNorm = 0.6414, lr_0 = 1.0000e-04
Loss = 9.7556e-04, PNorm = 59.7321, GNorm = 1.9015, lr_0 = 1.0000e-04
Loss = 6.5143e-04, PNorm = 59.7332, GNorm = 1.1362, lr_0 = 1.0000e-04
Loss = 7.4946e-04, PNorm = 59.7347, GNorm = 2.1408, lr_0 = 1.0000e-04
Loss = 5.3370e-04, PNorm = 59.7369, GNorm = 1.5366, lr_0 = 1.0000e-04
Loss = 9.2640e-04, PNorm = 59.7393, GNorm = 1.3441, lr_0 = 1.0000e-04
Loss = 6.5593e-04, PNorm = 59.7413, GNorm = 1.0341, lr_0 = 1.0000e-04
Loss = 9.5008e-04, PNorm = 59.7431, GNorm = 1.4620, lr_0 = 1.0000e-04
Loss = 8.6944e-04, PNorm = 59.7450, GNorm = 2.3685, lr_0 = 1.0000e-04
Loss = 5.9789e-04, PNorm = 59.7460, GNorm = 1.1823, lr_0 = 1.0000e-04
Loss = 4.7063e-04, PNorm = 59.7468, GNorm = 0.9572, lr_0 = 1.0000e-04
Loss = 7.9471e-04, PNorm = 59.7472, GNorm = 0.8081, lr_0 = 1.0000e-04
Loss = 7.1967e-04, PNorm = 59.7492, GNorm = 1.1712, lr_0 = 1.0000e-04
Loss = 1.1849e-03, PNorm = 59.7509, GNorm = 1.6832, lr_0 = 1.0000e-04
Loss = 7.7210e-04, PNorm = 59.7520, GNorm = 1.7683, lr_0 = 1.0000e-04
Validation rmse = 4.104891
Validation R2 = -3.945278
Epoch 77
Train function
Loss = 6.5851e-04, PNorm = 59.7534, GNorm = 1.0741, lr_0 = 1.0000e-04
Loss = 8.9722e-04, PNorm = 59.7551, GNorm = 2.0449, lr_0 = 1.0000e-04
Loss = 5.7962e-04, PNorm = 59.7567, GNorm = 1.0430, lr_0 = 1.0000e-04
Loss = 5.5773e-04, PNorm = 59.7585, GNorm = 0.9086, lr_0 = 1.0000e-04
Loss = 7.2134e-04, PNorm = 59.7607, GNorm = 1.7492, lr_0 = 1.0000e-04
Loss = 5.5934e-04, PNorm = 59.7628, GNorm = 1.2215, lr_0 = 1.0000e-04
Loss = 6.4458e-04, PNorm = 59.7649, GNorm = 1.5829, lr_0 = 1.0000e-04
Loss = 8.1332e-04, PNorm = 59.7665, GNorm = 1.7521, lr_0 = 1.0000e-04
Loss = 4.7511e-04, PNorm = 59.7677, GNorm = 1.5729, lr_0 = 1.0000e-04
Loss = 6.6810e-04, PNorm = 59.7688, GNorm = 1.4451, lr_0 = 1.0000e-04
Loss = 1.1049e-03, PNorm = 59.7704, GNorm = 1.7068, lr_0 = 1.0000e-04
Loss = 8.4342e-04, PNorm = 59.7724, GNorm = 1.6596, lr_0 = 1.0000e-04
Loss = 1.0301e-03, PNorm = 59.7746, GNorm = 1.5614, lr_0 = 1.0000e-04
Loss = 6.6827e-04, PNorm = 59.7765, GNorm = 1.4407, lr_0 = 1.0000e-04
Loss = 6.4357e-04, PNorm = 59.7775, GNorm = 1.0171, lr_0 = 1.0000e-04
Loss = 8.4179e-04, PNorm = 59.7779, GNorm = 2.3338, lr_0 = 1.0000e-04
Loss = 1.0607e-03, PNorm = 59.7781, GNorm = 3.3503, lr_0 = 1.0000e-04
Loss = 7.8653e-04, PNorm = 59.7803, GNorm = 1.5885, lr_0 = 1.0000e-04
Loss = 7.7542e-04, PNorm = 59.7828, GNorm = 2.0483, lr_0 = 1.0000e-04
Loss = 9.6116e-04, PNorm = 59.7854, GNorm = 0.9199, lr_0 = 1.0000e-04
Loss = 8.1548e-04, PNorm = 59.7875, GNorm = 1.2590, lr_0 = 1.0000e-04
Loss = 8.8821e-04, PNorm = 59.7900, GNorm = 1.2428, lr_0 = 1.0000e-04
Loss = 1.2930e-03, PNorm = 59.7918, GNorm = 1.6016, lr_0 = 1.0000e-04
Validation rmse = 4.192494
Validation R2 = -4.158608
Epoch 78
Train function
Loss = 7.5384e-04, PNorm = 59.7932, GNorm = 1.3905, lr_0 = 1.0000e-04
Loss = 6.4299e-04, PNorm = 59.7951, GNorm = 1.5754, lr_0 = 1.0000e-04
Loss = 8.0076e-04, PNorm = 59.7972, GNorm = 0.8879, lr_0 = 1.0000e-04
Loss = 8.1999e-04, PNorm = 59.7990, GNorm = 1.4889, lr_0 = 1.0000e-04
Loss = 6.8067e-04, PNorm = 59.8008, GNorm = 0.7614, lr_0 = 1.0000e-04
Loss = 9.9342e-04, PNorm = 59.8022, GNorm = 1.4042, lr_0 = 1.0000e-04
Loss = 8.4936e-04, PNorm = 59.8035, GNorm = 1.1983, lr_0 = 1.0000e-04
Loss = 6.2745e-04, PNorm = 59.8049, GNorm = 1.4227, lr_0 = 1.0000e-04
Loss = 7.8155e-04, PNorm = 59.8059, GNorm = 1.2493, lr_0 = 1.0000e-04
Loss = 7.4957e-04, PNorm = 59.8075, GNorm = 0.9411, lr_0 = 1.0000e-04
Loss = 1.0164e-03, PNorm = 59.8088, GNorm = 1.6717, lr_0 = 1.0000e-04
Loss = 6.2582e-04, PNorm = 59.8109, GNorm = 1.8557, lr_0 = 1.0000e-04
Loss = 1.0211e-03, PNorm = 59.8127, GNorm = 1.0706, lr_0 = 1.0000e-04
Loss = 8.3997e-04, PNorm = 59.8156, GNorm = 1.2418, lr_0 = 1.0000e-04
Loss = 8.9980e-04, PNorm = 59.8181, GNorm = 1.5295, lr_0 = 1.0000e-04
Loss = 9.8196e-04, PNorm = 59.8197, GNorm = 1.6577, lr_0 = 1.0000e-04
Loss = 5.4859e-04, PNorm = 59.8209, GNorm = 0.7932, lr_0 = 1.0000e-04
Loss = 6.5816e-04, PNorm = 59.8215, GNorm = 0.8823, lr_0 = 1.0000e-04
Loss = 8.4204e-04, PNorm = 59.8232, GNorm = 0.8496, lr_0 = 1.0000e-04
Loss = 7.2541e-04, PNorm = 59.8261, GNorm = 1.6395, lr_0 = 1.0000e-04
Loss = 7.1355e-04, PNorm = 59.8277, GNorm = 0.5610, lr_0 = 1.0000e-04
Loss = 6.3081e-04, PNorm = 59.8293, GNorm = 0.9772, lr_0 = 1.0000e-04
Loss = 9.4668e-04, PNorm = 59.8313, GNorm = 2.0135, lr_0 = 1.0000e-04
Loss = 5.5820e-04, PNorm = 59.8328, GNorm = 1.6199, lr_0 = 1.0000e-04
Validation rmse = 4.167236
Validation R2 = -4.096636
Epoch 79
Train function
Loss = 6.5282e-04, PNorm = 59.8340, GNorm = 1.1054, lr_0 = 1.0000e-04
Loss = 8.8107e-04, PNorm = 59.8356, GNorm = 2.4263, lr_0 = 1.0000e-04
Loss = 5.9392e-04, PNorm = 59.8372, GNorm = 1.4247, lr_0 = 1.0000e-04
Loss = 6.9057e-04, PNorm = 59.8387, GNorm = 1.1443, lr_0 = 1.0000e-04
Loss = 6.8711e-04, PNorm = 59.8404, GNorm = 1.4945, lr_0 = 1.0000e-04
Loss = 7.7407e-04, PNorm = 59.8420, GNorm = 1.2962, lr_0 = 1.0000e-04
Loss = 5.8096e-04, PNorm = 59.8433, GNorm = 1.2438, lr_0 = 1.0000e-04
Loss = 9.3379e-04, PNorm = 59.8454, GNorm = 1.1959, lr_0 = 1.0000e-04
Loss = 7.2781e-04, PNorm = 59.8474, GNorm = 0.9429, lr_0 = 1.0000e-04
Loss = 1.0831e-03, PNorm = 59.8497, GNorm = 1.5539, lr_0 = 1.0000e-04
Loss = 8.7344e-04, PNorm = 59.8515, GNorm = 1.9346, lr_0 = 1.0000e-04
Loss = 8.8001e-04, PNorm = 59.8533, GNorm = 1.2944, lr_0 = 1.0000e-04
Loss = 9.9951e-04, PNorm = 59.8540, GNorm = 1.9294, lr_0 = 1.0000e-04
Loss = 6.2503e-04, PNorm = 59.8553, GNorm = 0.9493, lr_0 = 1.0000e-04
Loss = 9.5444e-04, PNorm = 59.8571, GNorm = 1.3148, lr_0 = 1.0000e-04
Loss = 7.5436e-04, PNorm = 59.8593, GNorm = 1.2586, lr_0 = 1.0000e-04
Loss = 8.0647e-04, PNorm = 59.8603, GNorm = 1.9839, lr_0 = 1.0000e-04
Loss = 5.3808e-04, PNorm = 59.8617, GNorm = 1.4336, lr_0 = 1.0000e-04
Loss = 7.8318e-04, PNorm = 59.8640, GNorm = 2.6959, lr_0 = 1.0000e-04
Loss = 9.4880e-04, PNorm = 59.8652, GNorm = 1.0039, lr_0 = 1.0000e-04
Loss = 6.7137e-04, PNorm = 59.8659, GNorm = 1.9571, lr_0 = 1.0000e-04
Loss = 7.0860e-04, PNorm = 59.8672, GNorm = 1.4891, lr_0 = 1.0000e-04
Loss = 7.1967e-04, PNorm = 59.8689, GNorm = 1.2933, lr_0 = 1.0000e-04
Validation rmse = 4.229151
Validation R2 = -4.249209
Epoch 80
Train function
Loss = 4.2912e-04, PNorm = 59.8700, GNorm = 1.0934, lr_0 = 1.0000e-04
Loss = 8.2496e-04, PNorm = 59.8709, GNorm = 0.7512, lr_0 = 1.0000e-04
Loss = 5.1768e-04, PNorm = 59.8720, GNorm = 0.6992, lr_0 = 1.0000e-04
Loss = 7.0088e-04, PNorm = 59.8735, GNorm = 2.2525, lr_0 = 1.0000e-04
Loss = 9.1082e-04, PNorm = 59.8754, GNorm = 0.7739, lr_0 = 1.0000e-04
Loss = 8.6820e-04, PNorm = 59.8770, GNorm = 3.0447, lr_0 = 1.0000e-04
Loss = 7.0486e-04, PNorm = 59.8787, GNorm = 1.2644, lr_0 = 1.0000e-04
Loss = 6.1253e-04, PNorm = 59.8805, GNorm = 1.4149, lr_0 = 1.0000e-04
Loss = 8.7149e-04, PNorm = 59.8822, GNorm = 1.6820, lr_0 = 1.0000e-04
Loss = 7.5068e-04, PNorm = 59.8833, GNorm = 1.0436, lr_0 = 1.0000e-04
Loss = 6.8680e-04, PNorm = 59.8837, GNorm = 0.9282, lr_0 = 1.0000e-04
Loss = 9.5103e-04, PNorm = 59.8848, GNorm = 1.0975, lr_0 = 1.0000e-04
Loss = 8.5796e-04, PNorm = 59.8860, GNorm = 3.1611, lr_0 = 1.0000e-04
Loss = 5.3959e-04, PNorm = 59.8884, GNorm = 0.8637, lr_0 = 1.0000e-04
Loss = 8.1864e-04, PNorm = 59.8902, GNorm = 2.3224, lr_0 = 1.0000e-04
Loss = 7.9990e-04, PNorm = 59.8926, GNorm = 1.6577, lr_0 = 1.0000e-04
Loss = 1.5468e-03, PNorm = 59.8952, GNorm = 2.0475, lr_0 = 1.0000e-04
Loss = 6.1439e-04, PNorm = 59.8970, GNorm = 1.1139, lr_0 = 1.0000e-04
Loss = 1.1243e-03, PNorm = 59.8992, GNorm = 1.6957, lr_0 = 1.0000e-04
Loss = 8.7091e-04, PNorm = 59.9018, GNorm = 1.0982, lr_0 = 1.0000e-04
Loss = 7.8135e-04, PNorm = 59.9042, GNorm = 1.7467, lr_0 = 1.0000e-04
Loss = 5.3379e-04, PNorm = 59.9059, GNorm = 1.1172, lr_0 = 1.0000e-04
Loss = 7.7854e-04, PNorm = 59.9078, GNorm = 1.6577, lr_0 = 1.0000e-04
Loss = 6.9180e-04, PNorm = 59.9093, GNorm = 1.4922, lr_0 = 1.0000e-04
Loss = 1.6167e-03, PNorm = 59.9093, GNorm = 2.1923, lr_0 = 1.0000e-04
Validation rmse = 4.268553
Validation R2 = -4.347476
Epoch 81
Train function
Loss = 6.2442e-04, PNorm = 59.9106, GNorm = 0.8314, lr_0 = 1.0000e-04
Loss = 8.7579e-04, PNorm = 59.9123, GNorm = 3.2507, lr_0 = 1.0000e-04
Loss = 5.1540e-04, PNorm = 59.9138, GNorm = 1.5460, lr_0 = 1.0000e-04
Loss = 1.0869e-03, PNorm = 59.9141, GNorm = 0.8372, lr_0 = 1.0000e-04
Loss = 6.3482e-04, PNorm = 59.9148, GNorm = 0.6125, lr_0 = 1.0000e-04
Loss = 9.6209e-04, PNorm = 59.9164, GNorm = 1.6406, lr_0 = 1.0000e-04
Loss = 9.2538e-04, PNorm = 59.9185, GNorm = 2.8803, lr_0 = 1.0000e-04
Loss = 5.6785e-04, PNorm = 59.9205, GNorm = 1.1845, lr_0 = 1.0000e-04
Loss = 9.0705e-04, PNorm = 59.9226, GNorm = 2.1817, lr_0 = 1.0000e-04
Loss = 8.5220e-04, PNorm = 59.9246, GNorm = 1.8180, lr_0 = 1.0000e-04
Loss = 8.3031e-04, PNorm = 59.9256, GNorm = 1.7126, lr_0 = 1.0000e-04
Loss = 4.3447e-04, PNorm = 59.9271, GNorm = 1.1873, lr_0 = 1.0000e-04
Loss = 6.0538e-04, PNorm = 59.9290, GNorm = 1.1216, lr_0 = 1.0000e-04
Loss = 7.4220e-04, PNorm = 59.9309, GNorm = 1.8295, lr_0 = 1.0000e-04
Loss = 6.0272e-04, PNorm = 59.9323, GNorm = 0.9701, lr_0 = 1.0000e-04
Loss = 7.4729e-04, PNorm = 59.9339, GNorm = 1.7171, lr_0 = 1.0000e-04
Loss = 5.3721e-04, PNorm = 59.9350, GNorm = 1.1945, lr_0 = 1.0000e-04
Loss = 5.6883e-04, PNorm = 59.9358, GNorm = 1.4106, lr_0 = 1.0000e-04
Loss = 6.0781e-04, PNorm = 59.9371, GNorm = 1.2088, lr_0 = 1.0000e-04
Loss = 7.7097e-04, PNorm = 59.9389, GNorm = 1.7508, lr_0 = 1.0000e-04
Loss = 6.9948e-04, PNorm = 59.9410, GNorm = 2.4682, lr_0 = 1.0000e-04
Loss = 7.1273e-04, PNorm = 59.9430, GNorm = 1.0214, lr_0 = 1.0000e-04
Loss = 8.2900e-04, PNorm = 59.9446, GNorm = 2.0589, lr_0 = 1.0000e-04
Validation rmse = 4.262392
Validation R2 = -4.332050
Epoch 82
Train function
Loss = 4.7011e-04, PNorm = 59.9460, GNorm = 1.4080, lr_0 = 1.0000e-04
Loss = 5.3724e-04, PNorm = 59.9480, GNorm = 0.9980, lr_0 = 1.0000e-04
Loss = 7.7484e-04, PNorm = 59.9500, GNorm = 2.4245, lr_0 = 1.0000e-04
Loss = 5.2089e-04, PNorm = 59.9520, GNorm = 1.1092, lr_0 = 1.0000e-04
Loss = 7.7974e-04, PNorm = 59.9541, GNorm = 2.3171, lr_0 = 1.0000e-04
Loss = 6.1789e-04, PNorm = 59.9557, GNorm = 1.9689, lr_0 = 1.0000e-04
Loss = 5.6004e-04, PNorm = 59.9570, GNorm = 1.3297, lr_0 = 1.0000e-04
Loss = 6.8629e-04, PNorm = 59.9577, GNorm = 2.6440, lr_0 = 1.0000e-04
Loss = 7.7787e-04, PNorm = 59.9592, GNorm = 1.3673, lr_0 = 1.0000e-04
Loss = 6.2426e-04, PNorm = 59.9601, GNorm = 1.2016, lr_0 = 1.0000e-04
Loss = 7.2330e-04, PNorm = 59.9614, GNorm = 0.7271, lr_0 = 1.0000e-04
Loss = 7.8509e-04, PNorm = 59.9634, GNorm = 1.1498, lr_0 = 1.0000e-04
Loss = 6.1910e-04, PNorm = 59.9656, GNorm = 1.9626, lr_0 = 1.0000e-04
Loss = 6.8794e-04, PNorm = 59.9669, GNorm = 1.3519, lr_0 = 1.0000e-04
Loss = 6.5216e-04, PNorm = 59.9686, GNorm = 2.3823, lr_0 = 1.0000e-04
Loss = 9.4421e-04, PNorm = 59.9703, GNorm = 1.4747, lr_0 = 1.0000e-04
Loss = 6.1359e-04, PNorm = 59.9710, GNorm = 1.2540, lr_0 = 1.0000e-04
Loss = 9.2163e-04, PNorm = 59.9728, GNorm = 1.3448, lr_0 = 1.0000e-04
Loss = 7.9608e-04, PNorm = 59.9735, GNorm = 1.3088, lr_0 = 1.0000e-04
Loss = 8.9635e-04, PNorm = 59.9745, GNorm = 2.1949, lr_0 = 1.0000e-04
Loss = 7.7374e-04, PNorm = 59.9759, GNorm = 1.5445, lr_0 = 1.0000e-04
Loss = 4.7449e-04, PNorm = 59.9771, GNorm = 1.4391, lr_0 = 1.0000e-04
Loss = 1.2496e-03, PNorm = 59.9790, GNorm = 2.1978, lr_0 = 1.0000e-04
Validation rmse = 4.144713
Validation R2 = -4.041693
Epoch 83
Train function
Loss = 4.7728e-04, PNorm = 59.9816, GNorm = 0.7149, lr_0 = 1.0000e-04
Loss = 7.4463e-04, PNorm = 59.9834, GNorm = 1.5197, lr_0 = 1.0000e-04
Loss = 5.4589e-04, PNorm = 59.9850, GNorm = 1.4123, lr_0 = 1.0000e-04
Loss = 5.0977e-04, PNorm = 59.9868, GNorm = 1.3219, lr_0 = 1.0000e-04
Loss = 5.4460e-04, PNorm = 59.9883, GNorm = 4.1829, lr_0 = 1.0000e-04
Loss = 8.9811e-04, PNorm = 59.9897, GNorm = 1.0043, lr_0 = 1.0000e-04
Loss = 6.3536e-04, PNorm = 59.9908, GNorm = 1.2348, lr_0 = 1.0000e-04
Loss = 8.5789e-04, PNorm = 59.9920, GNorm = 2.8288, lr_0 = 1.0000e-04
Loss = 8.0799e-04, PNorm = 59.9937, GNorm = 3.6448, lr_0 = 1.0000e-04
Loss = 7.4336e-04, PNorm = 59.9958, GNorm = 1.7360, lr_0 = 1.0000e-04
Loss = 3.9025e-04, PNorm = 59.9973, GNorm = 1.0414, lr_0 = 1.0000e-04
Loss = 6.1251e-04, PNorm = 59.9983, GNorm = 1.6889, lr_0 = 1.0000e-04
Loss = 5.9446e-04, PNorm = 59.9995, GNorm = 1.8161, lr_0 = 1.0000e-04
Loss = 7.3541e-04, PNorm = 60.0012, GNorm = 1.4611, lr_0 = 1.0000e-04
Loss = 8.5018e-04, PNorm = 60.0037, GNorm = 1.0937, lr_0 = 1.0000e-04
Loss = 6.4593e-04, PNorm = 60.0060, GNorm = 2.7165, lr_0 = 1.0000e-04
Loss = 6.4501e-04, PNorm = 60.0071, GNorm = 1.5366, lr_0 = 1.0000e-04
Loss = 7.3944e-04, PNorm = 60.0086, GNorm = 1.5376, lr_0 = 1.0000e-04
Loss = 5.4542e-04, PNorm = 60.0104, GNorm = 1.1383, lr_0 = 1.0000e-04
Loss = 9.3048e-04, PNorm = 60.0119, GNorm = 1.7761, lr_0 = 1.0000e-04
Loss = 6.9010e-04, PNorm = 60.0140, GNorm = 1.0117, lr_0 = 1.0000e-04
Loss = 8.5140e-04, PNorm = 60.0160, GNorm = 3.2385, lr_0 = 1.0000e-04
Loss = 5.9097e-04, PNorm = 60.0172, GNorm = 1.6657, lr_0 = 1.0000e-04
Loss = 1.1498e-03, PNorm = 60.0187, GNorm = 3.0627, lr_0 = 1.0000e-04
Validation rmse = 4.311275
Validation R2 = -4.455054
Epoch 84
Train function
Loss = 6.2867e-04, PNorm = 60.0211, GNorm = 0.9189, lr_0 = 1.0000e-04
Loss = 6.9825e-04, PNorm = 60.0231, GNorm = 3.0611, lr_0 = 1.0000e-04
Loss = 6.9252e-04, PNorm = 60.0252, GNorm = 0.9908, lr_0 = 1.0000e-04
Loss = 5.8372e-04, PNorm = 60.0266, GNorm = 1.0366, lr_0 = 1.0000e-04
Loss = 5.8043e-04, PNorm = 60.0276, GNorm = 0.9611, lr_0 = 1.0000e-04
Loss = 4.6387e-04, PNorm = 60.0291, GNorm = 0.9251, lr_0 = 1.0000e-04
Loss = 7.1499e-04, PNorm = 60.0305, GNorm = 2.2163, lr_0 = 1.0000e-04
Loss = 6.8017e-04, PNorm = 60.0318, GNorm = 1.3604, lr_0 = 1.0000e-04
Loss = 7.1333e-04, PNorm = 60.0333, GNorm = 1.0732, lr_0 = 1.0000e-04
Loss = 8.4228e-04, PNorm = 60.0346, GNorm = 1.6827, lr_0 = 1.0000e-04
Loss = 7.4316e-04, PNorm = 60.0359, GNorm = 0.9768, lr_0 = 1.0000e-04
Loss = 5.5988e-04, PNorm = 60.0369, GNorm = 1.6971, lr_0 = 1.0000e-04
Loss = 4.2034e-04, PNorm = 60.0383, GNorm = 1.3794, lr_0 = 1.0000e-04
Loss = 4.8633e-04, PNorm = 60.0395, GNorm = 1.0052, lr_0 = 1.0000e-04
Loss = 8.4141e-04, PNorm = 60.0405, GNorm = 2.2434, lr_0 = 1.0000e-04
Loss = 5.0648e-04, PNorm = 60.0422, GNorm = 1.8983, lr_0 = 1.0000e-04
Loss = 5.3776e-04, PNorm = 60.0437, GNorm = 1.3531, lr_0 = 1.0000e-04
Loss = 1.0300e-03, PNorm = 60.0453, GNorm = 1.2001, lr_0 = 1.0000e-04
Loss = 9.2218e-04, PNorm = 60.0476, GNorm = 1.1270, lr_0 = 1.0000e-04
Loss = 6.9717e-04, PNorm = 60.0490, GNorm = 1.8778, lr_0 = 1.0000e-04
Loss = 1.1091e-03, PNorm = 60.0503, GNorm = 3.7949, lr_0 = 1.0000e-04
Loss = 6.2114e-04, PNorm = 60.0518, GNorm = 1.6163, lr_0 = 1.0000e-04
Loss = 7.9598e-04, PNorm = 60.0533, GNorm = 2.0927, lr_0 = 1.0000e-04
Validation rmse = 4.313473
Validation R2 = -4.460616
Epoch 85
Train function
Loss = 2.1554e-03, PNorm = 60.0548, GNorm = 0.8930, lr_0 = 1.0000e-04
Loss = 6.9389e-04, PNorm = 60.0559, GNorm = 1.6794, lr_0 = 1.0000e-04
Loss = 5.1573e-04, PNorm = 60.0573, GNorm = 1.0134, lr_0 = 1.0000e-04
Loss = 5.2187e-04, PNorm = 60.0590, GNorm = 0.8311, lr_0 = 1.0000e-04
Loss = 6.7410e-04, PNorm = 60.0607, GNorm = 0.5128, lr_0 = 1.0000e-04
Loss = 5.0378e-04, PNorm = 60.0625, GNorm = 1.7134, lr_0 = 1.0000e-04
Loss = 6.2843e-04, PNorm = 60.0646, GNorm = 1.0956, lr_0 = 1.0000e-04
Loss = 8.2382e-04, PNorm = 60.0664, GNorm = 1.3382, lr_0 = 1.0000e-04
Loss = 7.6715e-04, PNorm = 60.0688, GNorm = 1.3363, lr_0 = 1.0000e-04
Loss = 6.1707e-04, PNorm = 60.0706, GNorm = 1.6959, lr_0 = 1.0000e-04
Loss = 7.3491e-04, PNorm = 60.0713, GNorm = 2.0433, lr_0 = 1.0000e-04
Loss = 5.5544e-04, PNorm = 60.0718, GNorm = 1.4364, lr_0 = 1.0000e-04
Loss = 4.2324e-04, PNorm = 60.0727, GNorm = 1.1679, lr_0 = 1.0000e-04
Loss = 5.5322e-04, PNorm = 60.0740, GNorm = 1.3273, lr_0 = 1.0000e-04
Loss = 6.7324e-04, PNorm = 60.0757, GNorm = 2.8106, lr_0 = 1.0000e-04
Loss = 5.8623e-04, PNorm = 60.0773, GNorm = 1.1383, lr_0 = 1.0000e-04
Loss = 5.6726e-04, PNorm = 60.0787, GNorm = 1.0911, lr_0 = 1.0000e-04
Loss = 5.6072e-04, PNorm = 60.0800, GNorm = 1.3355, lr_0 = 1.0000e-04
Loss = 6.6141e-04, PNorm = 60.0810, GNorm = 2.0286, lr_0 = 1.0000e-04
Loss = 4.8998e-04, PNorm = 60.0823, GNorm = 1.8594, lr_0 = 1.0000e-04
Loss = 5.3491e-04, PNorm = 60.0842, GNorm = 1.0592, lr_0 = 1.0000e-04
Loss = 1.1326e-03, PNorm = 60.0863, GNorm = 1.3238, lr_0 = 1.0000e-04
Loss = 8.7618e-04, PNorm = 60.0886, GNorm = 3.0174, lr_0 = 1.0000e-04
Loss = 8.9055e-04, PNorm = 60.0913, GNorm = 1.2028, lr_0 = 1.0000e-04
Validation rmse = 4.275586
Validation R2 = -4.365112
Epoch 86
Train function
Loss = 5.9907e-04, PNorm = 60.0932, GNorm = 2.0212, lr_0 = 1.0000e-04
Loss = 4.4879e-04, PNorm = 60.0943, GNorm = 0.8395, lr_0 = 1.0000e-04
Loss = 6.0267e-04, PNorm = 60.0953, GNorm = 1.7281, lr_0 = 1.0000e-04
Loss = 6.6109e-04, PNorm = 60.0961, GNorm = 0.9029, lr_0 = 1.0000e-04
Loss = 5.6700e-04, PNorm = 60.0966, GNorm = 1.2749, lr_0 = 1.0000e-04
Loss = 8.3596e-04, PNorm = 60.0983, GNorm = 2.2399, lr_0 = 1.0000e-04
Loss = 7.4798e-04, PNorm = 60.1004, GNorm = 1.5413, lr_0 = 1.0000e-04
Loss = 5.3799e-04, PNorm = 60.1017, GNorm = 1.1801, lr_0 = 1.0000e-04
Loss = 7.0234e-04, PNorm = 60.1025, GNorm = 1.5585, lr_0 = 1.0000e-04
Loss = 4.8173e-04, PNorm = 60.1034, GNorm = 0.9906, lr_0 = 1.0000e-04
Loss = 4.3062e-04, PNorm = 60.1046, GNorm = 1.4851, lr_0 = 1.0000e-04
Loss = 3.5470e-04, PNorm = 60.1056, GNorm = 1.3327, lr_0 = 1.0000e-04
Loss = 5.6711e-04, PNorm = 60.1067, GNorm = 2.2098, lr_0 = 1.0000e-04
Loss = 8.9972e-04, PNorm = 60.1078, GNorm = 0.9541, lr_0 = 1.0000e-04
Loss = 1.0624e-03, PNorm = 60.1093, GNorm = 2.1896, lr_0 = 1.0000e-04
Loss = 7.1384e-04, PNorm = 60.1114, GNorm = 0.6671, lr_0 = 1.0000e-04
Loss = 8.1342e-04, PNorm = 60.1139, GNorm = 2.0212, lr_0 = 1.0000e-04
Loss = 5.4580e-04, PNorm = 60.1162, GNorm = 1.6729, lr_0 = 1.0000e-04
Loss = 6.1035e-04, PNorm = 60.1176, GNorm = 1.1758, lr_0 = 1.0000e-04
Loss = 5.9715e-04, PNorm = 60.1190, GNorm = 1.2029, lr_0 = 1.0000e-04
Loss = 6.2057e-04, PNorm = 60.1201, GNorm = 1.2272, lr_0 = 1.0000e-04
Loss = 9.9790e-04, PNorm = 60.1214, GNorm = 1.3753, lr_0 = 1.0000e-04
Loss = 8.8959e-04, PNorm = 60.1225, GNorm = 1.4289, lr_0 = 1.0000e-04
Validation rmse = 4.084335
Validation R2 = -3.895874
Epoch 87
Train function
Loss = 5.3853e-04, PNorm = 60.1239, GNorm = 1.8176, lr_0 = 1.0000e-04
Loss = 6.3542e-04, PNorm = 60.1260, GNorm = 1.3307, lr_0 = 1.0000e-04
Loss = 5.1580e-04, PNorm = 60.1285, GNorm = 1.3808, lr_0 = 1.0000e-04
Loss = 7.1106e-04, PNorm = 60.1307, GNorm = 2.0244, lr_0 = 1.0000e-04
Loss = 6.1359e-04, PNorm = 60.1331, GNorm = 1.4024, lr_0 = 1.0000e-04
Loss = 6.0380e-04, PNorm = 60.1349, GNorm = 1.4703, lr_0 = 1.0000e-04
Loss = 6.0066e-04, PNorm = 60.1364, GNorm = 1.0598, lr_0 = 1.0000e-04
Loss = 6.1876e-04, PNorm = 60.1375, GNorm = 1.0483, lr_0 = 1.0000e-04
Loss = 5.1468e-04, PNorm = 60.1387, GNorm = 0.9201, lr_0 = 1.0000e-04
Loss = 6.2357e-04, PNorm = 60.1398, GNorm = 1.6612, lr_0 = 1.0000e-04
Loss = 6.7999e-04, PNorm = 60.1408, GNorm = 1.3959, lr_0 = 1.0000e-04
Loss = 6.0927e-04, PNorm = 60.1423, GNorm = 1.4268, lr_0 = 1.0000e-04
Loss = 7.7491e-04, PNorm = 60.1435, GNorm = 1.9731, lr_0 = 1.0000e-04
Loss = 4.4194e-04, PNorm = 60.1447, GNorm = 1.1143, lr_0 = 1.0000e-04
Loss = 6.4665e-04, PNorm = 60.1455, GNorm = 1.3801, lr_0 = 1.0000e-04
Loss = 6.5461e-04, PNorm = 60.1469, GNorm = 1.5910, lr_0 = 1.0000e-04
Loss = 1.1452e-03, PNorm = 60.1475, GNorm = 1.6184, lr_0 = 1.0000e-04
Loss = 6.2558e-04, PNorm = 60.1481, GNorm = 1.3810, lr_0 = 1.0000e-04
Loss = 6.6221e-04, PNorm = 60.1503, GNorm = 2.1820, lr_0 = 1.0000e-04
Loss = 4.0090e-04, PNorm = 60.1528, GNorm = 1.2841, lr_0 = 1.0000e-04
Loss = 5.7097e-04, PNorm = 60.1542, GNorm = 2.1450, lr_0 = 1.0000e-04
Loss = 6.3031e-04, PNorm = 60.1564, GNorm = 1.0659, lr_0 = 1.0000e-04
Loss = 7.2555e-04, PNorm = 60.1582, GNorm = 2.0621, lr_0 = 1.0000e-04
Validation rmse = 4.183107
Validation R2 = -4.135532
Epoch 88
Train function
Loss = 2.4894e-04, PNorm = 60.1600, GNorm = 0.9390, lr_0 = 1.0000e-04
Loss = 6.3097e-04, PNorm = 60.1608, GNorm = 1.4679, lr_0 = 1.0000e-04
Loss = 5.4760e-04, PNorm = 60.1619, GNorm = 1.2363, lr_0 = 1.0000e-04
Loss = 7.1537e-04, PNorm = 60.1632, GNorm = 1.2431, lr_0 = 1.0000e-04
Loss = 5.2737e-04, PNorm = 60.1637, GNorm = 2.5715, lr_0 = 1.0000e-04
Loss = 3.9829e-04, PNorm = 60.1646, GNorm = 1.0943, lr_0 = 1.0000e-04
Loss = 6.1749e-04, PNorm = 60.1650, GNorm = 2.8212, lr_0 = 1.0000e-04
Loss = 5.6793e-04, PNorm = 60.1654, GNorm = 1.4111, lr_0 = 1.0000e-04
Loss = 8.7135e-04, PNorm = 60.1669, GNorm = 0.7411, lr_0 = 1.0000e-04
Loss = 4.5317e-04, PNorm = 60.1684, GNorm = 1.6564, lr_0 = 1.0000e-04
Loss = 5.4493e-04, PNorm = 60.1698, GNorm = 1.0520, lr_0 = 1.0000e-04
Loss = 6.2715e-04, PNorm = 60.1711, GNorm = 1.1539, lr_0 = 1.0000e-04
Loss = 3.7314e-04, PNorm = 60.1726, GNorm = 0.9309, lr_0 = 1.0000e-04
Loss = 6.3631e-04, PNorm = 60.1740, GNorm = 1.5224, lr_0 = 1.0000e-04
Loss = 6.8763e-04, PNorm = 60.1760, GNorm = 1.2627, lr_0 = 1.0000e-04
Loss = 9.8102e-04, PNorm = 60.1787, GNorm = 2.2648, lr_0 = 1.0000e-04
Loss = 7.5896e-04, PNorm = 60.1802, GNorm = 1.0749, lr_0 = 1.0000e-04
Loss = 4.3651e-04, PNorm = 60.1819, GNorm = 0.9681, lr_0 = 1.0000e-04
Loss = 5.9383e-04, PNorm = 60.1828, GNorm = 0.8384, lr_0 = 1.0000e-04
Loss = 4.6340e-04, PNorm = 60.1839, GNorm = 1.1554, lr_0 = 1.0000e-04
Loss = 5.3427e-04, PNorm = 60.1854, GNorm = 2.0574, lr_0 = 1.0000e-04
Loss = 6.6810e-04, PNorm = 60.1870, GNorm = 1.3947, lr_0 = 1.0000e-04
Loss = 7.8425e-04, PNorm = 60.1887, GNorm = 1.2248, lr_0 = 1.0000e-04
Loss = 9.1667e-04, PNorm = 60.1898, GNorm = 1.1009, lr_0 = 1.0000e-04
Validation rmse = 3.982742
Validation R2 = -3.655344
Epoch 89
Train function
Loss = 1.1844e-03, PNorm = 60.1909, GNorm = 2.0422, lr_0 = 1.0000e-04
Loss = 7.7012e-04, PNorm = 60.1921, GNorm = 1.0667, lr_0 = 1.0000e-04
Loss = 7.7269e-04, PNorm = 60.1938, GNorm = 1.0655, lr_0 = 1.0000e-04
Loss = 7.0575e-04, PNorm = 60.1950, GNorm = 1.3396, lr_0 = 1.0000e-04
Loss = 4.3393e-04, PNorm = 60.1961, GNorm = 1.2811, lr_0 = 1.0000e-04
Loss = 4.8692e-04, PNorm = 60.1970, GNorm = 1.8081, lr_0 = 1.0000e-04
Loss = 5.5601e-04, PNorm = 60.1986, GNorm = 1.1417, lr_0 = 1.0000e-04
Loss = 5.3093e-04, PNorm = 60.1999, GNorm = 2.5166, lr_0 = 1.0000e-04
Loss = 7.1817e-04, PNorm = 60.2017, GNorm = 1.3059, lr_0 = 1.0000e-04
Loss = 1.0284e-03, PNorm = 60.2028, GNorm = 1.9591, lr_0 = 1.0000e-04
Loss = 7.0823e-04, PNorm = 60.2037, GNorm = 1.9382, lr_0 = 1.0000e-04
Loss = 5.8939e-04, PNorm = 60.2049, GNorm = 1.4871, lr_0 = 1.0000e-04
Loss = 6.2258e-04, PNorm = 60.2068, GNorm = 1.6171, lr_0 = 1.0000e-04
Loss = 8.3144e-04, PNorm = 60.2089, GNorm = 0.9830, lr_0 = 1.0000e-04
Loss = 4.0154e-04, PNorm = 60.2099, GNorm = 1.2729, lr_0 = 1.0000e-04
Loss = 4.2572e-04, PNorm = 60.2110, GNorm = 1.2591, lr_0 = 1.0000e-04
Loss = 6.0871e-04, PNorm = 60.2125, GNorm = 1.2577, lr_0 = 1.0000e-04
Loss = 4.1571e-04, PNorm = 60.2139, GNorm = 1.5066, lr_0 = 1.0000e-04
Loss = 7.3388e-04, PNorm = 60.2157, GNorm = 1.8718, lr_0 = 1.0000e-04
Loss = 9.1207e-04, PNorm = 60.2177, GNorm = 2.1621, lr_0 = 1.0000e-04
Loss = 5.7426e-04, PNorm = 60.2200, GNorm = 1.1597, lr_0 = 1.0000e-04
Loss = 4.3033e-04, PNorm = 60.2214, GNorm = 1.7030, lr_0 = 1.0000e-04
Loss = 4.5871e-04, PNorm = 60.2231, GNorm = 1.1896, lr_0 = 1.0000e-04
Validation rmse = 4.128125
Validation R2 = -4.001418
Epoch 90
Train function
Loss = 5.8062e-04, PNorm = 60.2254, GNorm = 1.4025, lr_0 = 1.0000e-04
Loss = 3.5660e-04, PNorm = 60.2270, GNorm = 1.2008, lr_0 = 1.0000e-04
Loss = 4.3866e-04, PNorm = 60.2275, GNorm = 1.0083, lr_0 = 1.0000e-04
Loss = 5.0062e-04, PNorm = 60.2282, GNorm = 0.9589, lr_0 = 1.0000e-04
Loss = 6.2868e-04, PNorm = 60.2300, GNorm = 1.1696, lr_0 = 1.0000e-04
Loss = 5.5883e-04, PNorm = 60.2319, GNorm = 1.8541, lr_0 = 1.0000e-04
Loss = 6.1490e-04, PNorm = 60.2328, GNorm = 1.3493, lr_0 = 1.0000e-04
Loss = 5.5751e-04, PNorm = 60.2347, GNorm = 1.4063, lr_0 = 1.0000e-04
Loss = 3.9342e-04, PNorm = 60.2365, GNorm = 0.8404, lr_0 = 1.0000e-04
Loss = 3.4479e-04, PNorm = 60.2383, GNorm = 1.2705, lr_0 = 1.0000e-04
Loss = 6.5300e-04, PNorm = 60.2400, GNorm = 0.8091, lr_0 = 1.0000e-04
Loss = 5.6898e-04, PNorm = 60.2411, GNorm = 0.9268, lr_0 = 1.0000e-04
Loss = 8.3805e-04, PNorm = 60.2425, GNorm = 1.4126, lr_0 = 1.0000e-04
Loss = 7.9193e-04, PNorm = 60.2434, GNorm = 1.4132, lr_0 = 1.0000e-04
Loss = 9.7870e-04, PNorm = 60.2435, GNorm = 2.4757, lr_0 = 1.0000e-04
Loss = 5.3863e-04, PNorm = 60.2450, GNorm = 0.9753, lr_0 = 1.0000e-04
Loss = 9.4603e-04, PNorm = 60.2458, GNorm = 1.6449, lr_0 = 1.0000e-04
Loss = 6.7611e-04, PNorm = 60.2469, GNorm = 1.7888, lr_0 = 1.0000e-04
Loss = 5.1050e-04, PNorm = 60.2486, GNorm = 1.4247, lr_0 = 1.0000e-04
Loss = 4.7487e-04, PNorm = 60.2498, GNorm = 0.9622, lr_0 = 1.0000e-04
Loss = 5.7232e-04, PNorm = 60.2518, GNorm = 1.2353, lr_0 = 1.0000e-04
Loss = 6.0191e-04, PNorm = 60.2537, GNorm = 1.3919, lr_0 = 1.0000e-04
Loss = 7.7979e-04, PNorm = 60.2545, GNorm = 1.2999, lr_0 = 1.0000e-04
Loss = 7.7180e-04, PNorm = 60.2564, GNorm = 2.8605, lr_0 = 1.0000e-04
Validation rmse = 4.108672
Validation R2 = -3.954393
Epoch 91
Train function
Loss = 5.2448e-04, PNorm = 60.2581, GNorm = 1.5156, lr_0 = 1.0000e-04
Loss = 6.8764e-04, PNorm = 60.2596, GNorm = 1.4773, lr_0 = 1.0000e-04
Loss = 4.3083e-04, PNorm = 60.2609, GNorm = 1.0400, lr_0 = 1.0000e-04
Loss = 4.6067e-04, PNorm = 60.2625, GNorm = 0.6902, lr_0 = 1.0000e-04
Loss = 6.5267e-04, PNorm = 60.2642, GNorm = 0.9790, lr_0 = 1.0000e-04
Loss = 9.6859e-04, PNorm = 60.2664, GNorm = 1.7014, lr_0 = 1.0000e-04
Loss = 5.0475e-04, PNorm = 60.2686, GNorm = 0.9139, lr_0 = 1.0000e-04
Loss = 4.6548e-04, PNorm = 60.2697, GNorm = 1.0431, lr_0 = 1.0000e-04
Loss = 5.3223e-04, PNorm = 60.2706, GNorm = 1.3973, lr_0 = 1.0000e-04
Loss = 4.0875e-04, PNorm = 60.2712, GNorm = 1.2951, lr_0 = 1.0000e-04
Loss = 8.6927e-04, PNorm = 60.2724, GNorm = 1.2053, lr_0 = 1.0000e-04
Loss = 5.5146e-04, PNorm = 60.2732, GNorm = 1.9192, lr_0 = 1.0000e-04
Loss = 6.7694e-04, PNorm = 60.2755, GNorm = 2.0075, lr_0 = 1.0000e-04
Loss = 6.3829e-04, PNorm = 60.2774, GNorm = 1.8768, lr_0 = 1.0000e-04
Loss = 7.3235e-04, PNorm = 60.2785, GNorm = 1.0335, lr_0 = 1.0000e-04
Loss = 7.3232e-04, PNorm = 60.2802, GNorm = 1.1929, lr_0 = 1.0000e-04
Loss = 4.8063e-04, PNorm = 60.2812, GNorm = 1.8795, lr_0 = 1.0000e-04
Loss = 6.7871e-04, PNorm = 60.2830, GNorm = 1.5539, lr_0 = 1.0000e-04
Loss = 5.3550e-04, PNorm = 60.2846, GNorm = 1.6677, lr_0 = 1.0000e-04
Loss = 4.6037e-04, PNorm = 60.2853, GNorm = 2.1393, lr_0 = 1.0000e-04
Loss = 6.1320e-04, PNorm = 60.2865, GNorm = 1.1859, lr_0 = 1.0000e-04
Loss = 4.9163e-04, PNorm = 60.2879, GNorm = 1.1601, lr_0 = 1.0000e-04
Loss = 8.5918e-04, PNorm = 60.2891, GNorm = 0.9757, lr_0 = 1.0000e-04
Validation rmse = 4.330426
Validation R2 = -4.503623
Epoch 92
Train function
Loss = 5.9974e-04, PNorm = 60.2909, GNorm = 0.8054, lr_0 = 1.0000e-04
Loss = 5.5793e-04, PNorm = 60.2930, GNorm = 1.5602, lr_0 = 1.0000e-04
Loss = 5.5571e-04, PNorm = 60.2939, GNorm = 1.1911, lr_0 = 1.0000e-04
Loss = 3.6806e-04, PNorm = 60.2942, GNorm = 0.7704, lr_0 = 1.0000e-04
Loss = 4.6419e-04, PNorm = 60.2947, GNorm = 1.3289, lr_0 = 1.0000e-04
Loss = 3.7079e-04, PNorm = 60.2955, GNorm = 0.8588, lr_0 = 1.0000e-04
Loss = 5.0915e-04, PNorm = 60.2964, GNorm = 1.2856, lr_0 = 1.0000e-04
Loss = 4.6415e-04, PNorm = 60.2978, GNorm = 1.5107, lr_0 = 1.0000e-04
Loss = 4.1721e-04, PNorm = 60.2995, GNorm = 0.9704, lr_0 = 1.0000e-04
Loss = 5.0653e-04, PNorm = 60.3004, GNorm = 1.2673, lr_0 = 1.0000e-04
Loss = 5.5072e-04, PNorm = 60.3017, GNorm = 2.0199, lr_0 = 1.0000e-04
Loss = 1.0050e-03, PNorm = 60.3034, GNorm = 1.2438, lr_0 = 1.0000e-04
Loss = 4.8581e-04, PNorm = 60.3043, GNorm = 1.0425, lr_0 = 1.0000e-04
Loss = 6.5821e-04, PNorm = 60.3050, GNorm = 2.1133, lr_0 = 1.0000e-04
Loss = 7.9121e-04, PNorm = 60.3057, GNorm = 1.1129, lr_0 = 1.0000e-04
Loss = 5.3334e-04, PNorm = 60.3063, GNorm = 2.0660, lr_0 = 1.0000e-04
Loss = 7.9873e-04, PNorm = 60.3079, GNorm = 3.0651, lr_0 = 1.0000e-04
Loss = 5.0617e-04, PNorm = 60.3095, GNorm = 1.1484, lr_0 = 1.0000e-04
Loss = 6.3458e-04, PNorm = 60.3111, GNorm = 1.1221, lr_0 = 1.0000e-04
Loss = 4.6835e-04, PNorm = 60.3121, GNorm = 1.2454, lr_0 = 1.0000e-04
Loss = 6.6241e-04, PNorm = 60.3134, GNorm = 2.2497, lr_0 = 1.0000e-04
Loss = 6.0549e-04, PNorm = 60.3158, GNorm = 1.1191, lr_0 = 1.0000e-04
Loss = 7.8467e-04, PNorm = 60.3176, GNorm = 2.6546, lr_0 = 1.0000e-04
Loss = 5.6125e-04, PNorm = 60.3197, GNorm = 0.8508, lr_0 = 1.0000e-04
Loss = 9.4218e-04, PNorm = 60.3199, GNorm = 2.2268, lr_0 = 1.0000e-04
Validation rmse = 4.044498
Validation R2 = -3.800835
Epoch 93
Train function
Loss = 9.0096e-04, PNorm = 60.3212, GNorm = 1.2201, lr_0 = 1.0000e-04
Loss = 4.4314e-04, PNorm = 60.3225, GNorm = 1.1840, lr_0 = 1.0000e-04
Loss = 5.1350e-04, PNorm = 60.3239, GNorm = 1.3255, lr_0 = 1.0000e-04
Loss = 3.2472e-04, PNorm = 60.3250, GNorm = 1.1684, lr_0 = 1.0000e-04
Loss = 7.0948e-04, PNorm = 60.3263, GNorm = 0.6901, lr_0 = 1.0000e-04
Loss = 3.7147e-04, PNorm = 60.3275, GNorm = 1.1321, lr_0 = 1.0000e-04
Loss = 9.1319e-04, PNorm = 60.3284, GNorm = 1.0858, lr_0 = 1.0000e-04
Loss = 8.0262e-04, PNorm = 60.3297, GNorm = 1.2417, lr_0 = 1.0000e-04
Loss = 6.7754e-04, PNorm = 60.3313, GNorm = 1.5229, lr_0 = 1.0000e-04
Loss = 5.4515e-04, PNorm = 60.3327, GNorm = 2.7736, lr_0 = 1.0000e-04
Loss = 4.4674e-04, PNorm = 60.3342, GNorm = 1.2006, lr_0 = 1.0000e-04
Loss = 3.6374e-04, PNorm = 60.3352, GNorm = 1.1391, lr_0 = 1.0000e-04
Loss = 5.8483e-04, PNorm = 60.3364, GNorm = 1.6417, lr_0 = 1.0000e-04
Loss = 4.9255e-04, PNorm = 60.3379, GNorm = 1.3549, lr_0 = 1.0000e-04
Loss = 3.4816e-04, PNorm = 60.3387, GNorm = 0.8240, lr_0 = 1.0000e-04
Loss = 5.6074e-04, PNorm = 60.3401, GNorm = 1.8268, lr_0 = 1.0000e-04
Loss = 4.7522e-04, PNorm = 60.3409, GNorm = 1.4101, lr_0 = 1.0000e-04
Loss = 7.3309e-04, PNorm = 60.3421, GNorm = 1.2376, lr_0 = 1.0000e-04
Loss = 6.3819e-04, PNorm = 60.3429, GNorm = 1.3050, lr_0 = 1.0000e-04
Loss = 4.6126e-04, PNorm = 60.3442, GNorm = 1.2807, lr_0 = 1.0000e-04
Loss = 6.4589e-04, PNorm = 60.3459, GNorm = 1.7877, lr_0 = 1.0000e-04
Loss = 5.3146e-04, PNorm = 60.3470, GNorm = 1.2314, lr_0 = 1.0000e-04
Loss = 6.7393e-04, PNorm = 60.3484, GNorm = 2.8867, lr_0 = 1.0000e-04
Validation rmse = 4.164414
Validation R2 = -4.089736
Epoch 94
Train function
Loss = 7.7148e-04, PNorm = 60.3507, GNorm = 1.7954, lr_0 = 1.0000e-04
Loss = 4.1894e-04, PNorm = 60.3512, GNorm = 1.0675, lr_0 = 1.0000e-04
Loss = 3.0219e-04, PNorm = 60.3528, GNorm = 1.3206, lr_0 = 1.0000e-04
Loss = 5.9044e-04, PNorm = 60.3535, GNorm = 0.7303, lr_0 = 1.0000e-04
Loss = 4.0245e-04, PNorm = 60.3543, GNorm = 1.2375, lr_0 = 1.0000e-04
Loss = 4.4554e-04, PNorm = 60.3556, GNorm = 1.7151, lr_0 = 1.0000e-04
Loss = 4.0747e-04, PNorm = 60.3570, GNorm = 0.9775, lr_0 = 1.0000e-04
Loss = 4.6997e-04, PNorm = 60.3586, GNorm = 1.2841, lr_0 = 1.0000e-04
Loss = 6.1223e-04, PNorm = 60.3598, GNorm = 1.2086, lr_0 = 1.0000e-04
Loss = 5.7091e-04, PNorm = 60.3607, GNorm = 1.1212, lr_0 = 1.0000e-04
Loss = 5.8071e-04, PNorm = 60.3622, GNorm = 1.7051, lr_0 = 1.0000e-04
Loss = 5.8726e-04, PNorm = 60.3637, GNorm = 2.5364, lr_0 = 1.0000e-04
Loss = 4.1432e-04, PNorm = 60.3655, GNorm = 1.3378, lr_0 = 1.0000e-04
Loss = 9.2668e-04, PNorm = 60.3665, GNorm = 1.8470, lr_0 = 1.0000e-04
Loss = 8.9633e-04, PNorm = 60.3677, GNorm = 2.8451, lr_0 = 1.0000e-04
Loss = 6.9035e-04, PNorm = 60.3687, GNorm = 1.4745, lr_0 = 1.0000e-04
Loss = 4.0181e-04, PNorm = 60.3702, GNorm = 0.6813, lr_0 = 1.0000e-04
Loss = 6.3535e-04, PNorm = 60.3714, GNorm = 1.2271, lr_0 = 1.0000e-04
Loss = 5.4135e-04, PNorm = 60.3725, GNorm = 1.7051, lr_0 = 1.0000e-04
Loss = 4.5397e-04, PNorm = 60.3742, GNorm = 0.6394, lr_0 = 1.0000e-04
Loss = 6.1881e-04, PNorm = 60.3758, GNorm = 1.2503, lr_0 = 1.0000e-04
Loss = 4.1155e-04, PNorm = 60.3774, GNorm = 1.0879, lr_0 = 1.0000e-04
Loss = 4.8608e-04, PNorm = 60.3793, GNorm = 1.1261, lr_0 = 1.0000e-04
Validation rmse = 4.356683
Validation R2 = -4.570566
Epoch 95
Train function
Loss = 4.0743e-04, PNorm = 60.3802, GNorm = 1.7480, lr_0 = 1.0000e-04
Loss = 4.6464e-04, PNorm = 60.3816, GNorm = 0.9687, lr_0 = 1.0000e-04
Loss = 6.8816e-04, PNorm = 60.3835, GNorm = 1.6700, lr_0 = 1.0000e-04
Loss = 5.1770e-04, PNorm = 60.3848, GNorm = 1.7362, lr_0 = 1.0000e-04
Loss = 4.5361e-04, PNorm = 60.3858, GNorm = 1.7439, lr_0 = 1.0000e-04
Loss = 6.4885e-04, PNorm = 60.3869, GNorm = 1.1099, lr_0 = 1.0000e-04
Loss = 3.3500e-04, PNorm = 60.3880, GNorm = 1.7342, lr_0 = 1.0000e-04
Loss = 5.1463e-04, PNorm = 60.3885, GNorm = 2.0368, lr_0 = 1.0000e-04
Loss = 3.9469e-04, PNorm = 60.3894, GNorm = 1.4718, lr_0 = 1.0000e-04
Loss = 4.4083e-04, PNorm = 60.3904, GNorm = 2.0878, lr_0 = 1.0000e-04
Loss = 1.3995e-03, PNorm = 60.3895, GNorm = 2.5060, lr_0 = 1.0000e-04
Loss = 6.1708e-04, PNorm = 60.3896, GNorm = 1.4102, lr_0 = 1.0000e-04
Loss = 5.1965e-04, PNorm = 60.3910, GNorm = 1.4084, lr_0 = 1.0000e-04
Loss = 7.9617e-04, PNorm = 60.3934, GNorm = 2.9370, lr_0 = 1.0000e-04
Loss = 7.6489e-04, PNorm = 60.3958, GNorm = 1.7328, lr_0 = 1.0000e-04
Loss = 1.0522e-03, PNorm = 60.3972, GNorm = 3.2179, lr_0 = 1.0000e-04
Loss = 9.6800e-04, PNorm = 60.3988, GNorm = 1.4605, lr_0 = 1.0000e-04
Loss = 6.7393e-04, PNorm = 60.4000, GNorm = 1.0408, lr_0 = 1.0000e-04
Loss = 5.4835e-04, PNorm = 60.4012, GNorm = 2.0364, lr_0 = 1.0000e-04
Loss = 4.5613e-04, PNorm = 60.4028, GNorm = 0.8150, lr_0 = 1.0000e-04
Loss = 7.2227e-04, PNorm = 60.4037, GNorm = 0.9255, lr_0 = 1.0000e-04
Loss = 5.6247e-04, PNorm = 60.4052, GNorm = 1.2793, lr_0 = 1.0000e-04
Loss = 6.5680e-04, PNorm = 60.4070, GNorm = 2.6299, lr_0 = 1.0000e-04
Loss = 4.4466e-04, PNorm = 60.4083, GNorm = 1.6035, lr_0 = 1.0000e-04
Validation rmse = 4.151684
Validation R2 = -4.058666
Epoch 96
Train function
Loss = 2.5051e-04, PNorm = 60.4093, GNorm = 0.7907, lr_0 = 1.0000e-04
Loss = 3.3135e-04, PNorm = 60.4097, GNorm = 0.8961, lr_0 = 1.0000e-04
Loss = 5.1230e-04, PNorm = 60.4099, GNorm = 0.8167, lr_0 = 1.0000e-04
Loss = 4.8994e-04, PNorm = 60.4104, GNorm = 0.8203, lr_0 = 1.0000e-04
Loss = 4.2231e-04, PNorm = 60.4112, GNorm = 0.8341, lr_0 = 1.0000e-04
Loss = 5.4997e-04, PNorm = 60.4121, GNorm = 1.4055, lr_0 = 1.0000e-04
Loss = 5.5099e-04, PNorm = 60.4130, GNorm = 1.4376, lr_0 = 1.0000e-04
Loss = 4.4118e-04, PNorm = 60.4136, GNorm = 1.4325, lr_0 = 1.0000e-04
Loss = 7.3421e-04, PNorm = 60.4148, GNorm = 1.6667, lr_0 = 1.0000e-04
Loss = 4.1939e-04, PNorm = 60.4163, GNorm = 0.8997, lr_0 = 1.0000e-04
Loss = 5.2281e-04, PNorm = 60.4177, GNorm = 1.4664, lr_0 = 1.0000e-04
Loss = 4.8239e-04, PNorm = 60.4196, GNorm = 0.8041, lr_0 = 1.0000e-04
Loss = 5.4633e-04, PNorm = 60.4208, GNorm = 1.0694, lr_0 = 1.0000e-04
Loss = 7.2034e-04, PNorm = 60.4217, GNorm = 2.2896, lr_0 = 1.0000e-04
Loss = 4.1199e-04, PNorm = 60.4224, GNorm = 0.7906, lr_0 = 1.0000e-04
Loss = 6.2654e-04, PNorm = 60.4235, GNorm = 0.8960, lr_0 = 1.0000e-04
Loss = 4.3918e-04, PNorm = 60.4251, GNorm = 1.1435, lr_0 = 1.0000e-04
Loss = 5.6858e-04, PNorm = 60.4267, GNorm = 1.2180, lr_0 = 1.0000e-04
Loss = 5.3584e-04, PNorm = 60.4286, GNorm = 1.4657, lr_0 = 1.0000e-04
Loss = 4.7233e-04, PNorm = 60.4302, GNorm = 0.8132, lr_0 = 1.0000e-04
Loss = 9.7200e-04, PNorm = 60.4320, GNorm = 3.7257, lr_0 = 1.0000e-04
Loss = 4.7218e-04, PNorm = 60.4331, GNorm = 1.4198, lr_0 = 1.0000e-04
Loss = 6.5187e-04, PNorm = 60.4344, GNorm = 1.0173, lr_0 = 1.0000e-04
Validation rmse = 4.287692
Validation R2 = -4.395538
Epoch 97
Train function
Loss = 3.2241e-04, PNorm = 60.4367, GNorm = 1.2962, lr_0 = 1.0000e-04
Loss = 3.0403e-04, PNorm = 60.4378, GNorm = 0.9724, lr_0 = 1.0000e-04
Loss = 5.3328e-04, PNorm = 60.4395, GNorm = 1.7398, lr_0 = 1.0000e-04
Loss = 6.6260e-04, PNorm = 60.4412, GNorm = 1.8722, lr_0 = 1.0000e-04
Loss = 4.1156e-04, PNorm = 60.4426, GNorm = 0.7422, lr_0 = 1.0000e-04
Loss = 4.4028e-04, PNorm = 60.4440, GNorm = 1.0393, lr_0 = 1.0000e-04
Loss = 5.5841e-04, PNorm = 60.4448, GNorm = 1.4995, lr_0 = 1.0000e-04
Loss = 3.6228e-04, PNorm = 60.4458, GNorm = 0.6725, lr_0 = 1.0000e-04
Loss = 3.8207e-04, PNorm = 60.4474, GNorm = 1.1009, lr_0 = 1.0000e-04
Loss = 5.5407e-04, PNorm = 60.4491, GNorm = 1.5165, lr_0 = 1.0000e-04
Loss = 4.6310e-04, PNorm = 60.4510, GNorm = 1.4633, lr_0 = 1.0000e-04
Loss = 5.1885e-04, PNorm = 60.4518, GNorm = 0.5420, lr_0 = 1.0000e-04
Loss = 2.8283e-04, PNorm = 60.4522, GNorm = 1.1211, lr_0 = 1.0000e-04
Loss = 6.0874e-04, PNorm = 60.4532, GNorm = 0.8613, lr_0 = 1.0000e-04
Loss = 6.9086e-04, PNorm = 60.4537, GNorm = 0.7657, lr_0 = 1.0000e-04
Loss = 5.4440e-04, PNorm = 60.4548, GNorm = 0.6297, lr_0 = 1.0000e-04
Loss = 4.0933e-04, PNorm = 60.4556, GNorm = 0.9359, lr_0 = 1.0000e-04
Loss = 5.0025e-04, PNorm = 60.4567, GNorm = 1.6549, lr_0 = 1.0000e-04
Loss = 8.2356e-04, PNorm = 60.4577, GNorm = 2.5778, lr_0 = 1.0000e-04
Loss = 2.6893e-04, PNorm = 60.4592, GNorm = 1.1277, lr_0 = 1.0000e-04
Loss = 5.9005e-04, PNorm = 60.4601, GNorm = 1.2775, lr_0 = 1.0000e-04
Loss = 4.7433e-04, PNorm = 60.4618, GNorm = 1.5150, lr_0 = 1.0000e-04
Loss = 5.9833e-04, PNorm = 60.4631, GNorm = 1.2904, lr_0 = 1.0000e-04
Loss = 5.4709e-04, PNorm = 60.4639, GNorm = 0.9415, lr_0 = 1.0000e-04
Validation rmse = 4.055700
Validation R2 = -3.827464
Epoch 98
Train function
Loss = 3.8518e-04, PNorm = 60.4649, GNorm = 0.9490, lr_0 = 1.0000e-04
Loss = 5.3716e-04, PNorm = 60.4660, GNorm = 1.2861, lr_0 = 1.0000e-04
Loss = 3.9440e-04, PNorm = 60.4673, GNorm = 1.3209, lr_0 = 1.0000e-04
Loss = 3.8229e-04, PNorm = 60.4682, GNorm = 0.9467, lr_0 = 1.0000e-04
Loss = 4.5720e-04, PNorm = 60.4693, GNorm = 1.9252, lr_0 = 1.0000e-04
Loss = 5.3745e-04, PNorm = 60.4705, GNorm = 1.2278, lr_0 = 1.0000e-04
Loss = 6.7573e-04, PNorm = 60.4724, GNorm = 0.9673, lr_0 = 1.0000e-04
Loss = 6.2226e-04, PNorm = 60.4736, GNorm = 1.3668, lr_0 = 1.0000e-04
Loss = 7.5648e-04, PNorm = 60.4751, GNorm = 2.5136, lr_0 = 1.0000e-04
Loss = 5.7127e-04, PNorm = 60.4759, GNorm = 1.1739, lr_0 = 1.0000e-04
Loss = 6.0396e-04, PNorm = 60.4771, GNorm = 0.9454, lr_0 = 1.0000e-04
Loss = 4.6359e-04, PNorm = 60.4786, GNorm = 0.9277, lr_0 = 1.0000e-04
Loss = 6.9742e-04, PNorm = 60.4792, GNorm = 1.4545, lr_0 = 1.0000e-04
Loss = 3.0259e-04, PNorm = 60.4800, GNorm = 0.7535, lr_0 = 1.0000e-04
Loss = 3.2504e-04, PNorm = 60.4810, GNorm = 1.3230, lr_0 = 1.0000e-04
Loss = 3.0196e-04, PNorm = 60.4822, GNorm = 0.9060, lr_0 = 1.0000e-04
Loss = 4.6131e-04, PNorm = 60.4829, GNorm = 1.4721, lr_0 = 1.0000e-04
Loss = 3.5729e-04, PNorm = 60.4841, GNorm = 1.0980, lr_0 = 1.0000e-04
Loss = 3.7590e-04, PNorm = 60.4851, GNorm = 1.7327, lr_0 = 1.0000e-04
Loss = 5.0277e-04, PNorm = 60.4856, GNorm = 0.7842, lr_0 = 1.0000e-04
Loss = 4.1872e-04, PNorm = 60.4869, GNorm = 1.2757, lr_0 = 1.0000e-04
Loss = 3.6583e-04, PNorm = 60.4884, GNorm = 1.3842, lr_0 = 1.0000e-04
Loss = 5.1553e-04, PNorm = 60.4891, GNorm = 1.5262, lr_0 = 1.0000e-04
Validation rmse = 4.221345
Validation R2 = -4.229850
Epoch 99
Train function
Loss = 9.9023e-04, PNorm = 60.4904, GNorm = 1.4253, lr_0 = 1.0000e-04
Loss = 4.3455e-04, PNorm = 60.4920, GNorm = 1.3520, lr_0 = 1.0000e-04
Loss = 3.8345e-04, PNorm = 60.4931, GNorm = 1.4555, lr_0 = 1.0000e-04
Loss = 3.6691e-04, PNorm = 60.4941, GNorm = 1.0316, lr_0 = 1.0000e-04
Loss = 7.0919e-04, PNorm = 60.4949, GNorm = 2.4735, lr_0 = 1.0000e-04
Loss = 4.3021e-04, PNorm = 60.4955, GNorm = 0.9986, lr_0 = 1.0000e-04
Loss = 3.1044e-04, PNorm = 60.4962, GNorm = 0.6672, lr_0 = 1.0000e-04
Loss = 3.3443e-04, PNorm = 60.4970, GNorm = 0.9799, lr_0 = 1.0000e-04
Loss = 3.9430e-04, PNorm = 60.4986, GNorm = 1.1166, lr_0 = 1.0000e-04
Loss = 5.2227e-04, PNorm = 60.4998, GNorm = 2.2259, lr_0 = 1.0000e-04
Loss = 4.5864e-04, PNorm = 60.5009, GNorm = 0.8317, lr_0 = 1.0000e-04
Loss = 5.6235e-04, PNorm = 60.5021, GNorm = 1.6239, lr_0 = 1.0000e-04
Loss = 3.6805e-04, PNorm = 60.5036, GNorm = 2.2603, lr_0 = 1.0000e-04
Loss = 4.3694e-04, PNorm = 60.5047, GNorm = 1.0001, lr_0 = 1.0000e-04
Loss = 4.8953e-04, PNorm = 60.5063, GNorm = 2.5229, lr_0 = 1.0000e-04
Loss = 4.0804e-04, PNorm = 60.5080, GNorm = 0.7757, lr_0 = 1.0000e-04
Loss = 4.4085e-04, PNorm = 60.5092, GNorm = 0.9591, lr_0 = 1.0000e-04
Loss = 4.5365e-04, PNorm = 60.5100, GNorm = 0.6905, lr_0 = 1.0000e-04
Loss = 3.1527e-04, PNorm = 60.5115, GNorm = 0.7944, lr_0 = 1.0000e-04
Loss = 7.2652e-04, PNorm = 60.5126, GNorm = 0.7629, lr_0 = 1.0000e-04
Loss = 4.3444e-04, PNorm = 60.5142, GNorm = 1.5660, lr_0 = 1.0000e-04
Loss = 7.1009e-04, PNorm = 60.5158, GNorm = 0.6365, lr_0 = 1.0000e-04
Loss = 4.2733e-04, PNorm = 60.5161, GNorm = 1.8891, lr_0 = 1.0000e-04
Loss = 5.9197e-04, PNorm = 60.5170, GNorm = 3.6113, lr_0 = 1.0000e-04
Validation rmse = 4.214593
Validation R2 = -4.213132
Model 0 best validation rmse = 1.102705 on epoch 1
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.082751
Model 0 test R2 = 0.651871
Ensemble test rmse = 1.082751
Ensemble test R2 = 0.651871
Fold 1
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8782,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 6.3482e-02, PNorm = 35.0070, GNorm = 22.1495, lr_0 = 1.2829e-04
Loss = 4.5406e-02, PNorm = 35.0068, GNorm = 4.8781, lr_0 = 1.5400e-04
Loss = 3.7506e-02, PNorm = 35.0092, GNorm = 4.0696, lr_0 = 1.7971e-04
Loss = 3.5299e-02, PNorm = 35.0130, GNorm = 3.0168, lr_0 = 2.0543e-04
Loss = 3.5122e-02, PNorm = 35.0187, GNorm = 4.6298, lr_0 = 2.3114e-04
Loss = 3.2656e-02, PNorm = 35.0256, GNorm = 6.3766, lr_0 = 2.5686e-04
Loss = 3.2251e-02, PNorm = 35.0332, GNorm = 4.2105, lr_0 = 2.8257e-04
Loss = 3.0675e-02, PNorm = 35.0413, GNorm = 9.1285, lr_0 = 3.0829e-04
Loss = 3.0257e-02, PNorm = 35.0486, GNorm = 5.2696, lr_0 = 3.3400e-04
Loss = 3.3531e-02, PNorm = 35.0586, GNorm = 4.3036, lr_0 = 3.5971e-04
Loss = 3.4854e-02, PNorm = 35.0684, GNorm = 4.4075, lr_0 = 3.8543e-04
Loss = 2.9851e-02, PNorm = 35.0808, GNorm = 2.6199, lr_0 = 4.1114e-04
Loss = 2.8787e-02, PNorm = 35.0918, GNorm = 9.8480, lr_0 = 4.3686e-04
Loss = 2.9863e-02, PNorm = 35.1056, GNorm = 5.9111, lr_0 = 4.6257e-04
Loss = 2.7924e-02, PNorm = 35.1187, GNorm = 2.5277, lr_0 = 4.8829e-04
Loss = 3.1355e-02, PNorm = 35.1387, GNorm = 5.0835, lr_0 = 5.1400e-04
Loss = 2.4620e-02, PNorm = 35.1521, GNorm = 4.1168, lr_0 = 5.3971e-04
Loss = 2.8735e-02, PNorm = 35.1584, GNorm = 6.3628, lr_0 = 5.6543e-04
Loss = 2.5364e-02, PNorm = 35.1731, GNorm = 9.2492, lr_0 = 5.9114e-04
Loss = 3.1453e-02, PNorm = 35.1925, GNorm = 3.9166, lr_0 = 6.1686e-04
Loss = 3.0633e-02, PNorm = 35.2056, GNorm = 7.8812, lr_0 = 6.4257e-04
Loss = 2.5048e-02, PNorm = 35.2191, GNorm = 2.5315, lr_0 = 6.6829e-04
Loss = 2.7203e-02, PNorm = 35.2327, GNorm = 2.9475, lr_0 = 6.9400e-04
Validation rmse = 1.016787
Validation R2 = 0.713117
Epoch 1
Train function
Loss = 2.4682e-02, PNorm = 35.2470, GNorm = 2.2016, lr_0 = 7.2229e-04
Loss = 3.1334e-02, PNorm = 35.2640, GNorm = 13.8153, lr_0 = 7.4800e-04
Loss = 2.8126e-02, PNorm = 35.2801, GNorm = 3.4231, lr_0 = 7.7371e-04
Loss = 2.9421e-02, PNorm = 35.2996, GNorm = 3.3924, lr_0 = 7.9943e-04
Loss = 2.5603e-02, PNorm = 35.3198, GNorm = 4.7340, lr_0 = 8.2514e-04
Loss = 2.6259e-02, PNorm = 35.3366, GNorm = 5.4672, lr_0 = 8.5086e-04
Loss = 2.6923e-02, PNorm = 35.3528, GNorm = 2.5008, lr_0 = 8.7657e-04
Loss = 3.0730e-02, PNorm = 35.3898, GNorm = 4.5956, lr_0 = 9.0229e-04
Loss = 2.4323e-02, PNorm = 35.4250, GNorm = 5.8610, lr_0 = 9.2800e-04
Loss = 2.6392e-02, PNorm = 35.4546, GNorm = 2.9574, lr_0 = 9.5371e-04
Loss = 2.4041e-02, PNorm = 35.4919, GNorm = 4.1288, lr_0 = 9.7943e-04
Loss = 2.3826e-02, PNorm = 35.5177, GNorm = 2.0912, lr_0 = 9.9973e-04
Loss = 2.6757e-02, PNorm = 35.5399, GNorm = 4.1481, lr_0 = 9.9839e-04
Loss = 2.8582e-02, PNorm = 35.5709, GNorm = 2.4185, lr_0 = 9.9705e-04
Loss = 2.7069e-02, PNorm = 35.5992, GNorm = 2.3813, lr_0 = 9.9571e-04
Loss = 2.6733e-02, PNorm = 35.6377, GNorm = 6.0821, lr_0 = 9.9438e-04
Loss = 2.1555e-02, PNorm = 35.6647, GNorm = 4.5302, lr_0 = 9.9304e-04
Loss = 2.6780e-02, PNorm = 35.6884, GNorm = 4.1465, lr_0 = 9.9171e-04
Loss = 2.6029e-02, PNorm = 35.7235, GNorm = 1.4710, lr_0 = 9.9038e-04
Loss = 2.5923e-02, PNorm = 35.7543, GNorm = 2.2419, lr_0 = 9.8905e-04
Loss = 2.5558e-02, PNorm = 35.7937, GNorm = 3.6093, lr_0 = 9.8772e-04
Loss = 2.5308e-02, PNorm = 35.8409, GNorm = 2.7880, lr_0 = 9.8640e-04
Loss = 2.2328e-02, PNorm = 35.8730, GNorm = 4.1026, lr_0 = 9.8508e-04
Validation rmse = 1.295781
Validation R2 = 0.534084
Epoch 2
Train function
Loss = 2.1469e-02, PNorm = 35.9183, GNorm = 2.1885, lr_0 = 9.8362e-04
Loss = 2.2510e-02, PNorm = 35.9546, GNorm = 2.6842, lr_0 = 9.8230e-04
Loss = 2.5024e-02, PNorm = 35.9857, GNorm = 3.6093, lr_0 = 9.8098e-04
Loss = 2.0429e-02, PNorm = 36.0263, GNorm = 3.8040, lr_0 = 9.7967e-04
Loss = 2.3770e-02, PNorm = 36.0516, GNorm = 3.9069, lr_0 = 9.7835e-04
Loss = 2.3926e-02, PNorm = 36.0929, GNorm = 4.4626, lr_0 = 9.7704e-04
Loss = 2.4618e-02, PNorm = 36.1224, GNorm = 5.9338, lr_0 = 9.7573e-04
Loss = 2.3329e-02, PNorm = 36.1469, GNorm = 1.6723, lr_0 = 9.7442e-04
Loss = 2.2548e-02, PNorm = 36.1740, GNorm = 2.8312, lr_0 = 9.7311e-04
Loss = 2.6881e-02, PNorm = 36.2040, GNorm = 2.2026, lr_0 = 9.7181e-04
Loss = 2.4352e-02, PNorm = 36.2442, GNorm = 2.0939, lr_0 = 9.7050e-04
Loss = 2.6995e-02, PNorm = 36.2598, GNorm = 1.4630, lr_0 = 9.6920e-04
Loss = 2.4701e-02, PNorm = 36.2792, GNorm = 4.5303, lr_0 = 9.6790e-04
Loss = 2.8753e-02, PNorm = 36.2999, GNorm = 8.3054, lr_0 = 9.6660e-04
Loss = 2.3271e-02, PNorm = 36.3254, GNorm = 2.6090, lr_0 = 9.6531e-04
Loss = 2.2240e-02, PNorm = 36.3513, GNorm = 1.7495, lr_0 = 9.6401e-04
Loss = 2.6010e-02, PNorm = 36.3841, GNorm = 3.7452, lr_0 = 9.6272e-04
Loss = 2.3144e-02, PNorm = 36.4131, GNorm = 4.4175, lr_0 = 9.6143e-04
Loss = 2.3427e-02, PNorm = 36.4239, GNorm = 2.1403, lr_0 = 9.6014e-04
Loss = 2.2106e-02, PNorm = 36.4375, GNorm = 2.1717, lr_0 = 9.5885e-04
Loss = 2.4489e-02, PNorm = 36.4677, GNorm = 2.5184, lr_0 = 9.5756e-04
Loss = 3.0667e-02, PNorm = 36.5091, GNorm = 5.9220, lr_0 = 9.5628e-04
Loss = 2.5800e-02, PNorm = 36.5477, GNorm = 4.4104, lr_0 = 9.5499e-04
Loss = 2.3162e-02, PNorm = 36.5756, GNorm = 2.1311, lr_0 = 9.5371e-04
Validation rmse = 1.132656
Validation R2 = 0.644007
Epoch 3
Train function
Loss = 2.2200e-02, PNorm = 36.6191, GNorm = 2.3917, lr_0 = 9.5230e-04
Loss = 2.0010e-02, PNorm = 36.6637, GNorm = 2.2704, lr_0 = 9.5103e-04
Loss = 2.6635e-02, PNorm = 36.6879, GNorm = 1.5221, lr_0 = 9.4975e-04
Loss = 2.2847e-02, PNorm = 36.7132, GNorm = 3.7779, lr_0 = 9.4848e-04
Loss = 2.3311e-02, PNorm = 36.7475, GNorm = 2.3015, lr_0 = 9.4720e-04
Loss = 2.5792e-02, PNorm = 36.7758, GNorm = 1.3939, lr_0 = 9.4593e-04
Loss = 2.4388e-02, PNorm = 36.8030, GNorm = 2.6970, lr_0 = 9.4466e-04
Loss = 2.4471e-02, PNorm = 36.8345, GNorm = 3.1453, lr_0 = 9.4340e-04
Loss = 2.4505e-02, PNorm = 36.8628, GNorm = 1.6153, lr_0 = 9.4213e-04
Loss = 2.5446e-02, PNorm = 36.8982, GNorm = 3.4648, lr_0 = 9.4087e-04
Loss = 2.3100e-02, PNorm = 36.9247, GNorm = 2.9390, lr_0 = 9.3960e-04
Loss = 2.2058e-02, PNorm = 36.9456, GNorm = 3.4153, lr_0 = 9.3834e-04
Loss = 2.4745e-02, PNorm = 36.9520, GNorm = 1.5191, lr_0 = 9.3708e-04
Loss = 2.3135e-02, PNorm = 36.9774, GNorm = 3.8420, lr_0 = 9.3583e-04
Loss = 2.7489e-02, PNorm = 37.0184, GNorm = 1.9025, lr_0 = 9.3457e-04
Loss = 2.0867e-02, PNorm = 37.0443, GNorm = 2.8276, lr_0 = 9.3332e-04
Loss = 2.2898e-02, PNorm = 37.0728, GNorm = 4.2021, lr_0 = 9.3206e-04
Loss = 2.0038e-02, PNorm = 37.0912, GNorm = 1.8317, lr_0 = 9.3081e-04
Loss = 2.3121e-02, PNorm = 37.1140, GNorm = 1.9852, lr_0 = 9.2957e-04
Loss = 2.2161e-02, PNorm = 37.1323, GNorm = 1.9996, lr_0 = 9.2832e-04
Loss = 2.3278e-02, PNorm = 37.1596, GNorm = 5.9110, lr_0 = 9.2707e-04
Loss = 2.6174e-02, PNorm = 37.2029, GNorm = 1.5783, lr_0 = 9.2583e-04
Loss = 2.4671e-02, PNorm = 37.2021, GNorm = 5.2194, lr_0 = 9.2459e-04
Validation rmse = 1.077092
Validation R2 = 0.678078
Epoch 4
Train function
Loss = 2.2616e-02, PNorm = 37.2139, GNorm = 2.7132, lr_0 = 9.2322e-04
Loss = 2.0804e-02, PNorm = 37.2440, GNorm = 1.9670, lr_0 = 9.2198e-04
Loss = 2.3757e-02, PNorm = 37.2861, GNorm = 3.4090, lr_0 = 9.2075e-04
Loss = 2.3860e-02, PNorm = 37.3156, GNorm = 3.7896, lr_0 = 9.1951e-04
Loss = 2.3246e-02, PNorm = 37.3298, GNorm = 3.6978, lr_0 = 9.1828e-04
Loss = 2.3595e-02, PNorm = 37.3632, GNorm = 2.3888, lr_0 = 9.1705e-04
Loss = 2.0545e-02, PNorm = 37.3917, GNorm = 1.9879, lr_0 = 9.1581e-04
Loss = 2.3914e-02, PNorm = 37.4167, GNorm = 3.2550, lr_0 = 9.1459e-04
Loss = 2.0605e-02, PNorm = 37.4501, GNorm = 3.7968, lr_0 = 9.1336e-04
Loss = 2.2979e-02, PNorm = 37.4586, GNorm = 2.1669, lr_0 = 9.1213e-04
Loss = 2.2034e-02, PNorm = 37.4667, GNorm = 2.9101, lr_0 = 9.1091e-04
Loss = 2.3014e-02, PNorm = 37.4922, GNorm = 1.9388, lr_0 = 9.0969e-04
Loss = 2.3204e-02, PNorm = 37.5346, GNorm = 4.5092, lr_0 = 9.0847e-04
Loss = 2.3423e-02, PNorm = 37.5755, GNorm = 3.8754, lr_0 = 9.0725e-04
Loss = 2.2969e-02, PNorm = 37.6083, GNorm = 2.5833, lr_0 = 9.0603e-04
Loss = 2.0546e-02, PNorm = 37.6409, GNorm = 2.4179, lr_0 = 9.0481e-04
Loss = 2.4348e-02, PNorm = 37.6634, GNorm = 1.7376, lr_0 = 9.0360e-04
Loss = 2.2000e-02, PNorm = 37.6884, GNorm = 2.0313, lr_0 = 9.0239e-04
Loss = 2.4355e-02, PNorm = 37.7098, GNorm = 2.2500, lr_0 = 9.0118e-04
Loss = 1.7482e-02, PNorm = 37.7309, GNorm = 1.7795, lr_0 = 8.9997e-04
Loss = 2.4060e-02, PNorm = 37.7571, GNorm = 2.4601, lr_0 = 8.9876e-04
Loss = 2.2288e-02, PNorm = 37.7877, GNorm = 2.7700, lr_0 = 8.9756e-04
Loss = 2.3738e-02, PNorm = 37.8172, GNorm = 1.9117, lr_0 = 8.9635e-04
Loss = 2.1913e-02, PNorm = 37.8278, GNorm = 4.5812, lr_0 = 8.9515e-04
Validation rmse = 1.583978
Validation R2 = 0.303786
Epoch 5
Train function
Loss = 2.0392e-02, PNorm = 37.8519, GNorm = 3.7405, lr_0 = 8.9395e-04
Loss = 2.1428e-02, PNorm = 37.8816, GNorm = 1.8116, lr_0 = 8.9275e-04
Loss = 2.2012e-02, PNorm = 37.9186, GNorm = 2.9165, lr_0 = 8.9155e-04
Loss = 2.1540e-02, PNorm = 37.9425, GNorm = 1.4863, lr_0 = 8.9035e-04
Loss = 2.0338e-02, PNorm = 37.9744, GNorm = 1.9893, lr_0 = 8.8916e-04
Loss = 2.3251e-02, PNorm = 38.0008, GNorm = 2.5866, lr_0 = 8.8797e-04
Loss = 2.3092e-02, PNorm = 38.0277, GNorm = 3.8900, lr_0 = 8.8677e-04
Loss = 2.5495e-02, PNorm = 38.0509, GNorm = 5.3866, lr_0 = 8.8559e-04
Loss = 1.9492e-02, PNorm = 38.0816, GNorm = 1.5438, lr_0 = 8.8440e-04
Loss = 2.1407e-02, PNorm = 38.1137, GNorm = 1.8555, lr_0 = 8.8321e-04
Loss = 2.5308e-02, PNorm = 38.1496, GNorm = 3.2745, lr_0 = 8.8203e-04
Loss = 2.3099e-02, PNorm = 38.1751, GNorm = 1.5972, lr_0 = 8.8084e-04
Loss = 1.9743e-02, PNorm = 38.2062, GNorm = 1.5427, lr_0 = 8.7966e-04
Loss = 2.1799e-02, PNorm = 38.2259, GNorm = 2.3824, lr_0 = 8.7848e-04
Loss = 2.3741e-02, PNorm = 38.2612, GNorm = 1.6921, lr_0 = 8.7730e-04
Loss = 2.2923e-02, PNorm = 38.2872, GNorm = 1.9261, lr_0 = 8.7612e-04
Loss = 2.2242e-02, PNorm = 38.3181, GNorm = 1.5466, lr_0 = 8.7495e-04
Loss = 2.1558e-02, PNorm = 38.3324, GNorm = 1.6344, lr_0 = 8.7377e-04
Loss = 2.1720e-02, PNorm = 38.3472, GNorm = 1.4528, lr_0 = 8.7260e-04
Loss = 2.1101e-02, PNorm = 38.3757, GNorm = 3.9969, lr_0 = 8.7143e-04
Loss = 2.3172e-02, PNorm = 38.4150, GNorm = 1.9017, lr_0 = 8.7026e-04
Loss = 2.4492e-02, PNorm = 38.4416, GNorm = 1.8306, lr_0 = 8.6909e-04
Loss = 2.2166e-02, PNorm = 38.4586, GNorm = 2.0572, lr_0 = 8.6793e-04
Validation rmse = 1.791798
Validation R2 = 0.109113
Epoch 6
Train function
Loss = 2.1675e-02, PNorm = 38.4864, GNorm = 2.6193, lr_0 = 8.6665e-04
Loss = 2.1928e-02, PNorm = 38.5205, GNorm = 1.6769, lr_0 = 8.6548e-04
Loss = 2.2204e-02, PNorm = 38.5510, GNorm = 1.6305, lr_0 = 8.6432e-04
Loss = 2.1671e-02, PNorm = 38.5595, GNorm = 4.2906, lr_0 = 8.6316e-04
Loss = 1.9650e-02, PNorm = 38.5881, GNorm = 2.2427, lr_0 = 8.6201e-04
Loss = 2.2009e-02, PNorm = 38.6287, GNorm = 1.5466, lr_0 = 8.6085e-04
Loss = 2.0304e-02, PNorm = 38.6631, GNorm = 3.3775, lr_0 = 8.5969e-04
Loss = 2.1474e-02, PNorm = 38.6970, GNorm = 1.8401, lr_0 = 8.5854e-04
Loss = 2.3610e-02, PNorm = 38.7453, GNorm = 1.6209, lr_0 = 8.5739e-04
Loss = 1.9755e-02, PNorm = 38.7740, GNorm = 2.1190, lr_0 = 8.5624e-04
Loss = 2.2842e-02, PNorm = 38.8170, GNorm = 3.3628, lr_0 = 8.5509e-04
Loss = 2.3863e-02, PNorm = 38.8581, GNorm = 2.2980, lr_0 = 8.5394e-04
Loss = 2.1054e-02, PNorm = 38.8883, GNorm = 3.3470, lr_0 = 8.5280e-04
Loss = 1.8475e-02, PNorm = 38.9103, GNorm = 3.0527, lr_0 = 8.5165e-04
Loss = 2.4652e-02, PNorm = 38.9429, GNorm = 2.1551, lr_0 = 8.5051e-04
Loss = 2.1298e-02, PNorm = 38.9580, GNorm = 4.9332, lr_0 = 8.4937e-04
Loss = 2.0380e-02, PNorm = 38.9942, GNorm = 2.3776, lr_0 = 8.4823e-04
Loss = 2.0649e-02, PNorm = 39.0180, GNorm = 1.5314, lr_0 = 8.4709e-04
Loss = 2.2243e-02, PNorm = 39.0378, GNorm = 5.8939, lr_0 = 8.4595e-04
Loss = 2.4072e-02, PNorm = 39.0643, GNorm = 1.9994, lr_0 = 8.4482e-04
Loss = 2.3572e-02, PNorm = 39.1074, GNorm = 2.2665, lr_0 = 8.4369e-04
Loss = 2.3119e-02, PNorm = 39.1339, GNorm = 3.2288, lr_0 = 8.4255e-04
Loss = 1.9391e-02, PNorm = 39.1599, GNorm = 3.5588, lr_0 = 8.4142e-04
Validation rmse = 1.831373
Validation R2 = 0.069325
Epoch 7
Train function
Loss = 2.1967e-02, PNorm = 39.1689, GNorm = 2.4084, lr_0 = 8.4018e-04
Loss = 1.9279e-02, PNorm = 39.1965, GNorm = 1.2328, lr_0 = 8.3905e-04
Loss = 2.1014e-02, PNorm = 39.2293, GNorm = 1.8578, lr_0 = 8.3793e-04
Loss = 2.2922e-02, PNorm = 39.2689, GNorm = 1.9540, lr_0 = 8.3680e-04
Loss = 2.4049e-02, PNorm = 39.2968, GNorm = 3.0997, lr_0 = 8.3568e-04
Loss = 2.0877e-02, PNorm = 39.3340, GNorm = 1.6852, lr_0 = 8.3456e-04
Loss = 1.8622e-02, PNorm = 39.3685, GNorm = 5.7568, lr_0 = 8.3344e-04
Loss = 2.4551e-02, PNorm = 39.3987, GNorm = 3.8086, lr_0 = 8.3232e-04
Loss = 2.2965e-02, PNorm = 39.4514, GNorm = 2.0058, lr_0 = 8.3121e-04
Loss = 2.2706e-02, PNorm = 39.4983, GNorm = 1.5260, lr_0 = 8.3009e-04
Loss = 2.0212e-02, PNorm = 39.5193, GNorm = 3.2002, lr_0 = 8.2898e-04
Loss = 2.0432e-02, PNorm = 39.5466, GNorm = 2.3505, lr_0 = 8.2786e-04
Loss = 2.2684e-02, PNorm = 39.5820, GNorm = 2.2977, lr_0 = 8.2675e-04
Loss = 2.2018e-02, PNorm = 39.6116, GNorm = 4.6470, lr_0 = 8.2564e-04
Loss = 2.0399e-02, PNorm = 39.6430, GNorm = 2.0246, lr_0 = 8.2454e-04
Loss = 1.8362e-02, PNorm = 39.6729, GNorm = 1.3078, lr_0 = 8.2343e-04
Loss = 2.0418e-02, PNorm = 39.6850, GNorm = 1.6939, lr_0 = 8.2233e-04
Loss = 2.1228e-02, PNorm = 39.7095, GNorm = 1.8297, lr_0 = 8.2122e-04
Loss = 2.0970e-02, PNorm = 39.7397, GNorm = 2.0579, lr_0 = 8.2012e-04
Loss = 2.1013e-02, PNorm = 39.7675, GNorm = 1.9072, lr_0 = 8.1902e-04
Loss = 2.1483e-02, PNorm = 39.7946, GNorm = 2.0576, lr_0 = 8.1792e-04
Loss = 2.1370e-02, PNorm = 39.8129, GNorm = 3.8776, lr_0 = 8.1682e-04
Loss = 2.2135e-02, PNorm = 39.8437, GNorm = 2.0911, lr_0 = 8.1573e-04
Loss = 2.1642e-02, PNorm = 39.8667, GNorm = 2.1925, lr_0 = 8.1463e-04
Validation rmse = 1.574922
Validation R2 = 0.311724
Epoch 8
Train function
Loss = 2.1220e-02, PNorm = 39.8864, GNorm = 2.7840, lr_0 = 8.1343e-04
Loss = 2.3047e-02, PNorm = 39.9255, GNorm = 2.9218, lr_0 = 8.1234e-04
Loss = 2.1833e-02, PNorm = 39.9661, GNorm = 1.7103, lr_0 = 8.1125e-04
Loss = 1.8056e-02, PNorm = 39.9827, GNorm = 2.3255, lr_0 = 8.1016e-04
Loss = 1.8336e-02, PNorm = 40.0054, GNorm = 1.8759, lr_0 = 8.0907e-04
Loss = 1.9666e-02, PNorm = 40.0398, GNorm = 1.8994, lr_0 = 8.0799e-04
Loss = 2.0110e-02, PNorm = 40.0719, GNorm = 2.8809, lr_0 = 8.0690e-04
Loss = 2.1489e-02, PNorm = 40.1033, GNorm = 1.7812, lr_0 = 8.0582e-04
Loss = 2.0212e-02, PNorm = 40.1302, GNorm = 1.4259, lr_0 = 8.0474e-04
Loss = 2.2300e-02, PNorm = 40.1531, GNorm = 2.5781, lr_0 = 8.0366e-04
Loss = 2.1424e-02, PNorm = 40.1867, GNorm = 4.0378, lr_0 = 8.0258e-04
Loss = 2.3090e-02, PNorm = 40.2162, GNorm = 2.1737, lr_0 = 8.0151e-04
Loss = 2.0212e-02, PNorm = 40.2480, GNorm = 2.7222, lr_0 = 8.0043e-04
Loss = 1.9758e-02, PNorm = 40.2831, GNorm = 1.4748, lr_0 = 7.9936e-04
Loss = 2.3046e-02, PNorm = 40.3073, GNorm = 1.9108, lr_0 = 7.9828e-04
Loss = 2.1610e-02, PNorm = 40.3277, GNorm = 2.2902, lr_0 = 7.9721e-04
Loss = 1.9659e-02, PNorm = 40.3644, GNorm = 1.8950, lr_0 = 7.9614e-04
Loss = 1.7036e-02, PNorm = 40.3894, GNorm = 1.9504, lr_0 = 7.9508e-04
Loss = 2.2174e-02, PNorm = 40.4168, GNorm = 1.4369, lr_0 = 7.9401e-04
Loss = 1.9071e-02, PNorm = 40.4503, GNorm = 3.5488, lr_0 = 7.9294e-04
Loss = 2.1307e-02, PNorm = 40.4606, GNorm = 2.4492, lr_0 = 7.9188e-04
Loss = 2.0252e-02, PNorm = 40.4795, GNorm = 1.9297, lr_0 = 7.9082e-04
Loss = 1.9339e-02, PNorm = 40.4953, GNorm = 3.0628, lr_0 = 7.8976e-04
Validation rmse = 1.622590
Validation R2 = 0.269430
Epoch 9
Train function
Loss = 2.0687e-02, PNorm = 40.5208, GNorm = 4.1198, lr_0 = 7.8859e-04
Loss = 1.8478e-02, PNorm = 40.5571, GNorm = 1.7503, lr_0 = 7.8753e-04
Loss = 2.1489e-02, PNorm = 40.5930, GNorm = 2.1628, lr_0 = 7.8648e-04
Loss = 1.9032e-02, PNorm = 40.6302, GNorm = 1.9281, lr_0 = 7.8542e-04
Loss = 2.0432e-02, PNorm = 40.6633, GNorm = 2.8188, lr_0 = 7.8437e-04
Loss = 1.9079e-02, PNorm = 40.6890, GNorm = 2.2023, lr_0 = 7.8331e-04
Loss = 1.8537e-02, PNorm = 40.7250, GNorm = 3.2858, lr_0 = 7.8226e-04
Loss = 2.1700e-02, PNorm = 40.7603, GNorm = 1.8041, lr_0 = 7.8121e-04
Loss = 2.1216e-02, PNorm = 40.7918, GNorm = 3.3519, lr_0 = 7.8017e-04
Loss = 2.0801e-02, PNorm = 40.8232, GNorm = 1.9705, lr_0 = 7.7912e-04
Loss = 1.8881e-02, PNorm = 40.8530, GNorm = 1.3798, lr_0 = 7.7807e-04
Loss = 1.8671e-02, PNorm = 40.8709, GNorm = 1.6549, lr_0 = 7.7703e-04
Loss = 2.2235e-02, PNorm = 40.9021, GNorm = 2.5039, lr_0 = 7.7599e-04
Loss = 2.1816e-02, PNorm = 40.9276, GNorm = 2.1234, lr_0 = 7.7495e-04
Loss = 1.8348e-02, PNorm = 40.9639, GNorm = 1.7100, lr_0 = 7.7391e-04
Loss = 2.2229e-02, PNorm = 40.9943, GNorm = 5.1235, lr_0 = 7.7287e-04
Loss = 1.9567e-02, PNorm = 41.0375, GNorm = 3.6122, lr_0 = 7.7183e-04
Loss = 2.3935e-02, PNorm = 41.0792, GNorm = 2.1008, lr_0 = 7.7079e-04
Loss = 2.1560e-02, PNorm = 41.0990, GNorm = 2.7365, lr_0 = 7.6976e-04
Loss = 2.0101e-02, PNorm = 41.1294, GNorm = 3.1587, lr_0 = 7.6873e-04
Loss = 1.9735e-02, PNorm = 41.1600, GNorm = 2.5779, lr_0 = 7.6770e-04
Loss = 2.2318e-02, PNorm = 41.1989, GNorm = 1.9827, lr_0 = 7.6667e-04
Loss = 1.9969e-02, PNorm = 41.2197, GNorm = 2.4196, lr_0 = 7.6564e-04
Loss = 1.9687e-02, PNorm = 41.2299, GNorm = 3.8714, lr_0 = 7.6461e-04
Validation rmse = 1.133093
Validation R2 = 0.643733
Epoch 10
Train function
Loss = 1.9468e-02, PNorm = 41.2564, GNorm = 2.1084, lr_0 = 7.6358e-04
Loss = 1.9433e-02, PNorm = 41.3001, GNorm = 2.6790, lr_0 = 7.6256e-04
Loss = 1.7682e-02, PNorm = 41.3367, GNorm = 1.9873, lr_0 = 7.6154e-04
Loss = 2.1061e-02, PNorm = 41.3758, GNorm = 4.6538, lr_0 = 7.6052e-04
Loss = 1.7511e-02, PNorm = 41.4079, GNorm = 3.0489, lr_0 = 7.5949e-04
Loss = 2.0482e-02, PNorm = 41.4328, GNorm = 1.6722, lr_0 = 7.5848e-04
Loss = 1.8770e-02, PNorm = 41.4581, GNorm = 1.3575, lr_0 = 7.5746e-04
Loss = 1.9617e-02, PNorm = 41.4741, GNorm = 2.2433, lr_0 = 7.5644e-04
Loss = 1.8966e-02, PNorm = 41.5173, GNorm = 2.1935, lr_0 = 7.5543e-04
Loss = 1.8156e-02, PNorm = 41.5329, GNorm = 2.3914, lr_0 = 7.5441e-04
Loss = 2.0079e-02, PNorm = 41.5660, GNorm = 1.6989, lr_0 = 7.5340e-04
Loss = 1.8362e-02, PNorm = 41.6052, GNorm = 1.7074, lr_0 = 7.5239e-04
Loss = 2.0217e-02, PNorm = 41.6330, GNorm = 2.7570, lr_0 = 7.5138e-04
Loss = 2.0857e-02, PNorm = 41.6550, GNorm = 1.7112, lr_0 = 7.5037e-04
Loss = 2.0071e-02, PNorm = 41.6815, GNorm = 1.6568, lr_0 = 7.4937e-04
Loss = 1.8464e-02, PNorm = 41.7128, GNorm = 2.3044, lr_0 = 7.4836e-04
Loss = 2.0259e-02, PNorm = 41.7428, GNorm = 2.5928, lr_0 = 7.4736e-04
Loss = 2.1571e-02, PNorm = 41.7693, GNorm = 2.0548, lr_0 = 7.4635e-04
Loss = 2.3084e-02, PNorm = 41.8103, GNorm = 2.5834, lr_0 = 7.4535e-04
Loss = 2.0548e-02, PNorm = 41.8369, GNorm = 2.8056, lr_0 = 7.4435e-04
Loss = 2.1285e-02, PNorm = 41.8710, GNorm = 2.7713, lr_0 = 7.4335e-04
Loss = 2.1823e-02, PNorm = 41.9049, GNorm = 2.0779, lr_0 = 7.4236e-04
Loss = 1.8672e-02, PNorm = 41.9416, GNorm = 3.0074, lr_0 = 7.4136e-04
Validation rmse = 1.646649
Validation R2 = 0.247604
Epoch 11
Train function
Loss = 1.8591e-02, PNorm = 41.9556, GNorm = 1.7888, lr_0 = 7.4027e-04
Loss = 1.8881e-02, PNorm = 41.9917, GNorm = 1.5900, lr_0 = 7.3927e-04
Loss = 1.7958e-02, PNorm = 42.0293, GNorm = 1.5963, lr_0 = 7.3828e-04
Loss = 1.7413e-02, PNorm = 42.0531, GNorm = 1.6387, lr_0 = 7.3729e-04
Loss = 2.0606e-02, PNorm = 42.0827, GNorm = 2.3960, lr_0 = 7.3630e-04
Loss = 1.7552e-02, PNorm = 42.1316, GNorm = 1.7137, lr_0 = 7.3531e-04
Loss = 1.9904e-02, PNorm = 42.1544, GNorm = 2.6522, lr_0 = 7.3433e-04
Loss = 1.7887e-02, PNorm = 42.1847, GNorm = 4.9862, lr_0 = 7.3334e-04
Loss = 1.9858e-02, PNorm = 42.2132, GNorm = 1.6273, lr_0 = 7.3236e-04
Loss = 1.9495e-02, PNorm = 42.2411, GNorm = 2.3501, lr_0 = 7.3137e-04
Loss = 1.9134e-02, PNorm = 42.2723, GNorm = 1.9317, lr_0 = 7.3039e-04
Loss = 1.7529e-02, PNorm = 42.3104, GNorm = 2.1879, lr_0 = 7.2941e-04
Loss = 1.8466e-02, PNorm = 42.3525, GNorm = 1.5132, lr_0 = 7.2843e-04
Loss = 1.7981e-02, PNorm = 42.3838, GNorm = 1.8045, lr_0 = 7.2746e-04
Loss = 2.1198e-02, PNorm = 42.4100, GNorm = 4.1057, lr_0 = 7.2648e-04
Loss = 1.9572e-02, PNorm = 42.4388, GNorm = 2.0588, lr_0 = 7.2551e-04
Loss = 1.5589e-02, PNorm = 42.4668, GNorm = 2.3776, lr_0 = 7.2453e-04
Loss = 1.9697e-02, PNorm = 42.4900, GNorm = 2.6276, lr_0 = 7.2356e-04
Loss = 1.8212e-02, PNorm = 42.5196, GNorm = 1.4987, lr_0 = 7.2259e-04
Loss = 2.1962e-02, PNorm = 42.5481, GNorm = 3.3448, lr_0 = 7.2162e-04
Loss = 1.8820e-02, PNorm = 42.5684, GNorm = 2.3201, lr_0 = 7.2065e-04
Loss = 2.1294e-02, PNorm = 42.6019, GNorm = 2.4340, lr_0 = 7.1969e-04
Loss = 2.1229e-02, PNorm = 42.6355, GNorm = 2.2915, lr_0 = 7.1872e-04
Loss = 2.2344e-02, PNorm = 42.6569, GNorm = 2.2243, lr_0 = 7.1776e-04
Loss = 7.6435e-02, PNorm = 42.6597, GNorm = 4.3562, lr_0 = 7.1766e-04
Validation rmse = 1.596303
Validation R2 = 0.292909
Epoch 12
Train function
Loss = 1.8091e-02, PNorm = 42.6924, GNorm = 2.1833, lr_0 = 7.1670e-04
Loss = 1.7537e-02, PNorm = 42.7307, GNorm = 2.8604, lr_0 = 7.1573e-04
Loss = 2.1034e-02, PNorm = 42.7664, GNorm = 3.1019, lr_0 = 7.1477e-04
Loss = 1.7794e-02, PNorm = 42.7983, GNorm = 2.7625, lr_0 = 7.1382e-04
Loss = 1.8554e-02, PNorm = 42.8318, GNorm = 2.5243, lr_0 = 7.1286e-04
Loss = 1.9900e-02, PNorm = 42.8696, GNorm = 5.7474, lr_0 = 7.1190e-04
Loss = 2.0567e-02, PNorm = 42.9057, GNorm = 3.0715, lr_0 = 7.1095e-04
Loss = 1.7930e-02, PNorm = 42.9320, GNorm = 1.4367, lr_0 = 7.0999e-04
Loss = 2.1582e-02, PNorm = 42.9611, GNorm = 2.0813, lr_0 = 7.0904e-04
Loss = 1.9322e-02, PNorm = 42.9938, GNorm = 2.0324, lr_0 = 7.0809e-04
Loss = 1.6286e-02, PNorm = 43.0286, GNorm = 2.2019, lr_0 = 7.0714e-04
Loss = 1.7881e-02, PNorm = 43.0551, GNorm = 2.2724, lr_0 = 7.0619e-04
Loss = 1.8966e-02, PNorm = 43.0828, GNorm = 2.1473, lr_0 = 7.0524e-04
Loss = 1.8230e-02, PNorm = 43.1154, GNorm = 2.4352, lr_0 = 7.0430e-04
Loss = 1.8116e-02, PNorm = 43.1367, GNorm = 1.5794, lr_0 = 7.0335e-04
Loss = 1.9917e-02, PNorm = 43.1563, GNorm = 1.9470, lr_0 = 7.0241e-04
Loss = 2.0180e-02, PNorm = 43.1822, GNorm = 2.0360, lr_0 = 7.0146e-04
Loss = 1.8910e-02, PNorm = 43.2151, GNorm = 3.4845, lr_0 = 7.0052e-04
Loss = 2.0797e-02, PNorm = 43.2411, GNorm = 1.8624, lr_0 = 6.9958e-04
Loss = 1.8473e-02, PNorm = 43.2731, GNorm = 2.2300, lr_0 = 6.9865e-04
Loss = 1.8326e-02, PNorm = 43.3004, GNorm = 1.7373, lr_0 = 6.9771e-04
Loss = 1.9184e-02, PNorm = 43.3189, GNorm = 3.2050, lr_0 = 6.9677e-04
Loss = 1.8450e-02, PNorm = 43.3486, GNorm = 2.6078, lr_0 = 6.9584e-04
Validation rmse = 2.071468
Validation R2 = -0.190697
Epoch 13
Train function
Loss = 1.8260e-02, PNorm = 43.3920, GNorm = 4.9494, lr_0 = 6.9481e-04
Loss = 1.7079e-02, PNorm = 43.4304, GNorm = 2.2660, lr_0 = 6.9388e-04
Loss = 1.7511e-02, PNorm = 43.4752, GNorm = 2.0002, lr_0 = 6.9295e-04
Loss = 1.9424e-02, PNorm = 43.5100, GNorm = 4.0093, lr_0 = 6.9202e-04
Loss = 1.8174e-02, PNorm = 43.5440, GNorm = 1.6997, lr_0 = 6.9109e-04
Loss = 1.7048e-02, PNorm = 43.5842, GNorm = 1.4457, lr_0 = 6.9016e-04
Loss = 2.1074e-02, PNorm = 43.6221, GNorm = 2.4816, lr_0 = 6.8924e-04
Loss = 1.6012e-02, PNorm = 43.6606, GNorm = 2.1416, lr_0 = 6.8831e-04
Loss = 1.7732e-02, PNorm = 43.6946, GNorm = 1.6217, lr_0 = 6.8739e-04
Loss = 1.9822e-02, PNorm = 43.7201, GNorm = 2.0412, lr_0 = 6.8646e-04
Loss = 1.9058e-02, PNorm = 43.7479, GNorm = 2.7357, lr_0 = 6.8554e-04
Loss = 1.9320e-02, PNorm = 43.7689, GNorm = 2.2397, lr_0 = 6.8462e-04
Loss = 1.8256e-02, PNorm = 43.8119, GNorm = 4.0434, lr_0 = 6.8371e-04
Loss = 1.6517e-02, PNorm = 43.8360, GNorm = 2.4111, lr_0 = 6.8279e-04
Loss = 1.9591e-02, PNorm = 43.8636, GNorm = 2.4294, lr_0 = 6.8187e-04
Loss = 1.8102e-02, PNorm = 43.8862, GNorm = 4.0059, lr_0 = 6.8096e-04
Loss = 1.6561e-02, PNorm = 43.9188, GNorm = 2.2276, lr_0 = 6.8004e-04
Loss = 2.0218e-02, PNorm = 43.9483, GNorm = 2.8365, lr_0 = 6.7913e-04
Loss = 1.7906e-02, PNorm = 43.9750, GNorm = 3.6626, lr_0 = 6.7822e-04
Loss = 1.9161e-02, PNorm = 44.0003, GNorm = 5.9391, lr_0 = 6.7731e-04
Loss = 1.7045e-02, PNorm = 44.0223, GNorm = 2.4276, lr_0 = 6.7640e-04
Loss = 1.9690e-02, PNorm = 44.0426, GNorm = 1.5086, lr_0 = 6.7549e-04
Loss = 1.8790e-02, PNorm = 44.0694, GNorm = 3.3117, lr_0 = 6.7459e-04
Validation rmse = 2.291052
Validation R2 = -0.456513
Epoch 14
Train function
Loss = 1.5131e-02, PNorm = 44.1065, GNorm = 4.3305, lr_0 = 6.7359e-04
Loss = 1.5814e-02, PNorm = 44.1622, GNorm = 2.4451, lr_0 = 6.7269e-04
Loss = 1.7006e-02, PNorm = 44.1930, GNorm = 3.2129, lr_0 = 6.7179e-04
Loss = 1.6606e-02, PNorm = 44.2216, GNorm = 2.4948, lr_0 = 6.7088e-04
Loss = 1.9506e-02, PNorm = 44.2646, GNorm = 3.0647, lr_0 = 6.6998e-04
Loss = 1.6929e-02, PNorm = 44.3155, GNorm = 2.3626, lr_0 = 6.6908e-04
Loss = 1.8258e-02, PNorm = 44.3417, GNorm = 2.0082, lr_0 = 6.6819e-04
Loss = 1.6630e-02, PNorm = 44.3748, GNorm = 2.3178, lr_0 = 6.6729e-04
Loss = 1.8337e-02, PNorm = 44.4006, GNorm = 2.0904, lr_0 = 6.6640e-04
Loss = 1.9801e-02, PNorm = 44.4168, GNorm = 2.4348, lr_0 = 6.6550e-04
Loss = 1.9101e-02, PNorm = 44.4439, GNorm = 2.4374, lr_0 = 6.6461e-04
Loss = 1.8816e-02, PNorm = 44.4741, GNorm = 3.1359, lr_0 = 6.6372e-04
Loss = 1.8500e-02, PNorm = 44.5101, GNorm = 2.4888, lr_0 = 6.6283e-04
Loss = 2.0383e-02, PNorm = 44.5473, GNorm = 2.1924, lr_0 = 6.6194e-04
Loss = 1.8360e-02, PNorm = 44.5855, GNorm = 2.4929, lr_0 = 6.6105e-04
Loss = 1.6709e-02, PNorm = 44.6179, GNorm = 3.2802, lr_0 = 6.6016e-04
Loss = 1.8672e-02, PNorm = 44.6478, GNorm = 2.7899, lr_0 = 6.5928e-04
Loss = 1.8618e-02, PNorm = 44.6686, GNorm = 2.7387, lr_0 = 6.5839e-04
Loss = 1.7689e-02, PNorm = 44.7098, GNorm = 1.9587, lr_0 = 6.5751e-04
Loss = 1.9592e-02, PNorm = 44.7461, GNorm = 3.1811, lr_0 = 6.5663e-04
Loss = 1.7720e-02, PNorm = 44.7750, GNorm = 2.3647, lr_0 = 6.5574e-04
Loss = 1.9039e-02, PNorm = 44.8033, GNorm = 1.9701, lr_0 = 6.5486e-04
Loss = 2.0425e-02, PNorm = 44.8279, GNorm = 2.0288, lr_0 = 6.5399e-04
Loss = 1.6945e-02, PNorm = 44.8534, GNorm = 2.2716, lr_0 = 6.5311e-04
Validation rmse = 2.074566
Validation R2 = -0.194261
Epoch 15
Train function
Loss = 1.8332e-02, PNorm = 44.8888, GNorm = 2.8722, lr_0 = 6.5223e-04
Loss = 1.6943e-02, PNorm = 44.9210, GNorm = 2.0259, lr_0 = 6.5136e-04
Loss = 1.6085e-02, PNorm = 44.9523, GNorm = 1.8085, lr_0 = 6.5048e-04
Loss = 1.7682e-02, PNorm = 44.9697, GNorm = 1.8432, lr_0 = 6.4961e-04
Loss = 1.7640e-02, PNorm = 45.0050, GNorm = 3.9550, lr_0 = 6.4874e-04
Loss = 1.5521e-02, PNorm = 45.0387, GNorm = 1.9870, lr_0 = 6.4787e-04
Loss = 1.5635e-02, PNorm = 45.0678, GNorm = 2.2567, lr_0 = 6.4700e-04
Loss = 1.7763e-02, PNorm = 45.0891, GNorm = 3.5250, lr_0 = 6.4613e-04
Loss = 1.7544e-02, PNorm = 45.1268, GNorm = 2.5929, lr_0 = 6.4526e-04
Loss = 1.6981e-02, PNorm = 45.1540, GNorm = 2.2080, lr_0 = 6.4440e-04
Loss = 1.6976e-02, PNorm = 45.1894, GNorm = 2.0750, lr_0 = 6.4353e-04
Loss = 1.7434e-02, PNorm = 45.2188, GNorm = 5.3492, lr_0 = 6.4267e-04
Loss = 1.7349e-02, PNorm = 45.2522, GNorm = 2.1056, lr_0 = 6.4181e-04
Loss = 1.7953e-02, PNorm = 45.2940, GNorm = 2.7199, lr_0 = 6.4095e-04
Loss = 1.8609e-02, PNorm = 45.3239, GNorm = 3.4897, lr_0 = 6.4009e-04
Loss = 1.5638e-02, PNorm = 45.3592, GNorm = 4.7188, lr_0 = 6.3923e-04
Loss = 1.6526e-02, PNorm = 45.3893, GNorm = 2.6290, lr_0 = 6.3837e-04
Loss = 1.7550e-02, PNorm = 45.4136, GNorm = 3.4640, lr_0 = 6.3751e-04
Loss = 1.9023e-02, PNorm = 45.4444, GNorm = 4.2546, lr_0 = 6.3666e-04
Loss = 1.7684e-02, PNorm = 45.4814, GNorm = 2.6009, lr_0 = 6.3580e-04
Loss = 1.7721e-02, PNorm = 45.5175, GNorm = 2.3196, lr_0 = 6.3495e-04
Loss = 1.5963e-02, PNorm = 45.5523, GNorm = 1.5135, lr_0 = 6.3410e-04
Loss = 1.7745e-02, PNorm = 45.5744, GNorm = 2.4925, lr_0 = 6.3325e-04
Validation rmse = 1.927961
Validation R2 = -0.031433
Epoch 16
Train function
Loss = 1.4797e-02, PNorm = 45.5944, GNorm = 2.2520, lr_0 = 6.3231e-04
Loss = 1.6887e-02, PNorm = 45.6309, GNorm = 2.1810, lr_0 = 6.3147e-04
Loss = 1.4027e-02, PNorm = 45.6613, GNorm = 3.3467, lr_0 = 6.3062e-04
Loss = 1.7587e-02, PNorm = 45.6937, GNorm = 2.6499, lr_0 = 6.2977e-04
Loss = 1.6457e-02, PNorm = 45.7325, GNorm = 2.5691, lr_0 = 6.2893e-04
Loss = 1.4967e-02, PNorm = 45.7607, GNorm = 1.7255, lr_0 = 6.2808e-04
Loss = 1.7089e-02, PNorm = 45.7877, GNorm = 3.9571, lr_0 = 6.2724e-04
Loss = 1.7123e-02, PNorm = 45.8212, GNorm = 2.3018, lr_0 = 6.2640e-04
Loss = 1.9119e-02, PNorm = 45.8509, GNorm = 2.1722, lr_0 = 6.2556e-04
Loss = 1.8027e-02, PNorm = 45.8819, GNorm = 2.3013, lr_0 = 6.2472e-04
Loss = 1.6833e-02, PNorm = 45.9135, GNorm = 3.2782, lr_0 = 6.2388e-04
Loss = 1.6288e-02, PNorm = 45.9438, GNorm = 2.4285, lr_0 = 6.2304e-04
Loss = 1.6931e-02, PNorm = 45.9639, GNorm = 2.8678, lr_0 = 6.2221e-04
Loss = 1.6170e-02, PNorm = 45.9914, GNorm = 2.0244, lr_0 = 6.2137e-04
Loss = 1.5471e-02, PNorm = 46.0161, GNorm = 3.9559, lr_0 = 6.2054e-04
Loss = 1.6202e-02, PNorm = 46.0539, GNorm = 3.5797, lr_0 = 6.1971e-04
Loss = 1.7285e-02, PNorm = 46.0800, GNorm = 2.4484, lr_0 = 6.1888e-04
Loss = 1.6146e-02, PNorm = 46.1050, GNorm = 2.3290, lr_0 = 6.1805e-04
Loss = 1.7759e-02, PNorm = 46.1296, GNorm = 2.3866, lr_0 = 6.1722e-04
Loss = 1.5991e-02, PNorm = 46.1574, GNorm = 2.5261, lr_0 = 6.1639e-04
Loss = 1.6804e-02, PNorm = 46.1885, GNorm = 2.3446, lr_0 = 6.1556e-04
Loss = 1.8367e-02, PNorm = 46.2160, GNorm = 2.3834, lr_0 = 6.1474e-04
Loss = 1.8216e-02, PNorm = 46.2505, GNorm = 2.2058, lr_0 = 6.1391e-04
Loss = 1.4473e-02, PNorm = 46.2727, GNorm = 3.1905, lr_0 = 6.1309e-04
Validation rmse = 1.689686
Validation R2 = 0.207761
Epoch 17
Train function
Loss = 1.7148e-02, PNorm = 46.3057, GNorm = 2.5028, lr_0 = 6.1218e-04
Loss = 1.4893e-02, PNorm = 46.3376, GNorm = 6.2010, lr_0 = 6.1136e-04
Loss = 1.6047e-02, PNorm = 46.3797, GNorm = 4.3795, lr_0 = 6.1054e-04
Loss = 1.4391e-02, PNorm = 46.4076, GNorm = 3.3881, lr_0 = 6.0972e-04
Loss = 1.7025e-02, PNorm = 46.4357, GNorm = 2.6071, lr_0 = 6.0890e-04
Loss = 1.6696e-02, PNorm = 46.4676, GNorm = 3.1562, lr_0 = 6.0809e-04
Loss = 1.4824e-02, PNorm = 46.4955, GNorm = 2.2869, lr_0 = 6.0727e-04
Loss = 1.5868e-02, PNorm = 46.5228, GNorm = 1.9880, lr_0 = 6.0646e-04
Loss = 1.5872e-02, PNorm = 46.5544, GNorm = 4.1677, lr_0 = 6.0564e-04
Loss = 1.6837e-02, PNorm = 46.5811, GNorm = 2.6680, lr_0 = 6.0483e-04
Loss = 1.5333e-02, PNorm = 46.6072, GNorm = 2.0770, lr_0 = 6.0402e-04
Loss = 1.5142e-02, PNorm = 46.6327, GNorm = 2.4617, lr_0 = 6.0321e-04
Loss = 1.5419e-02, PNorm = 46.6693, GNorm = 2.8940, lr_0 = 6.0240e-04
Loss = 1.6694e-02, PNorm = 46.7064, GNorm = 2.9491, lr_0 = 6.0159e-04
Loss = 1.5265e-02, PNorm = 46.7468, GNorm = 2.4255, lr_0 = 6.0078e-04
Loss = 1.6202e-02, PNorm = 46.7823, GNorm = 4.5454, lr_0 = 5.9998e-04
Loss = 1.5957e-02, PNorm = 46.8138, GNorm = 2.1035, lr_0 = 5.9917e-04
Loss = 1.7522e-02, PNorm = 46.8370, GNorm = 3.0450, lr_0 = 5.9837e-04
Loss = 1.5657e-02, PNorm = 46.8631, GNorm = 2.3563, lr_0 = 5.9756e-04
Loss = 1.6347e-02, PNorm = 46.9021, GNorm = 2.5305, lr_0 = 5.9676e-04
Loss = 1.7764e-02, PNorm = 46.9287, GNorm = 3.1202, lr_0 = 5.9596e-04
Loss = 1.7995e-02, PNorm = 46.9536, GNorm = 4.7894, lr_0 = 5.9516e-04
Loss = 1.5745e-02, PNorm = 46.9820, GNorm = 3.3702, lr_0 = 5.9436e-04
Validation rmse = 2.056896
Validation R2 = -0.174003
Epoch 18
Train function
Loss = 1.2647e-02, PNorm = 47.0143, GNorm = 2.2682, lr_0 = 5.9349e-04
Loss = 1.3440e-02, PNorm = 47.0484, GNorm = 2.6086, lr_0 = 5.9269e-04
Loss = 1.4929e-02, PNorm = 47.0854, GNorm = 3.2209, lr_0 = 5.9190e-04
Loss = 1.5612e-02, PNorm = 47.1124, GNorm = 2.5769, lr_0 = 5.9110e-04
Loss = 1.5421e-02, PNorm = 47.1517, GNorm = 2.8131, lr_0 = 5.9031e-04
Loss = 1.4164e-02, PNorm = 47.1810, GNorm = 2.0056, lr_0 = 5.8952e-04
Loss = 1.5842e-02, PNorm = 47.2069, GNorm = 3.0572, lr_0 = 5.8873e-04
Loss = 1.4985e-02, PNorm = 47.2435, GNorm = 2.3678, lr_0 = 5.8794e-04
Loss = 1.5032e-02, PNorm = 47.2758, GNorm = 2.1826, lr_0 = 5.8715e-04
Loss = 1.5513e-02, PNorm = 47.2999, GNorm = 3.2930, lr_0 = 5.8636e-04
Loss = 1.7406e-02, PNorm = 47.3287, GNorm = 2.8356, lr_0 = 5.8557e-04
Loss = 1.6225e-02, PNorm = 47.3651, GNorm = 2.4296, lr_0 = 5.8479e-04
Loss = 1.4192e-02, PNorm = 47.3961, GNorm = 3.0832, lr_0 = 5.8400e-04
Loss = 1.3864e-02, PNorm = 47.4166, GNorm = 2.6214, lr_0 = 5.8322e-04
Loss = 1.7705e-02, PNorm = 47.4448, GNorm = 2.3016, lr_0 = 5.8244e-04
Loss = 1.6094e-02, PNorm = 47.4820, GNorm = 4.8246, lr_0 = 5.8165e-04
Loss = 1.7778e-02, PNorm = 47.5119, GNorm = 2.4390, lr_0 = 5.8087e-04
Loss = 1.5923e-02, PNorm = 47.5421, GNorm = 1.9440, lr_0 = 5.8009e-04
Loss = 1.4761e-02, PNorm = 47.5545, GNorm = 2.6110, lr_0 = 5.7932e-04
Loss = 1.4661e-02, PNorm = 47.5833, GNorm = 4.6930, lr_0 = 5.7854e-04
Loss = 1.7083e-02, PNorm = 47.6066, GNorm = 1.6583, lr_0 = 5.7776e-04
Loss = 1.6648e-02, PNorm = 47.6350, GNorm = 2.4714, lr_0 = 5.7699e-04
Loss = 1.6290e-02, PNorm = 47.6633, GNorm = 2.2938, lr_0 = 5.7621e-04
Validation rmse = 2.302744
Validation R2 = -0.471417
Epoch 19
Train function
Loss = 1.3442e-02, PNorm = 47.6909, GNorm = 2.1005, lr_0 = 5.7536e-04
Loss = 1.5720e-02, PNorm = 47.7151, GNorm = 3.3780, lr_0 = 5.7459e-04
Loss = 1.3563e-02, PNorm = 47.7531, GNorm = 3.9569, lr_0 = 5.7382e-04
Loss = 1.5795e-02, PNorm = 47.7835, GNorm = 3.3885, lr_0 = 5.7305e-04
Loss = 1.4697e-02, PNorm = 47.8169, GNorm = 1.9468, lr_0 = 5.7228e-04
Loss = 1.3177e-02, PNorm = 47.8438, GNorm = 2.6386, lr_0 = 5.7151e-04
Loss = 1.5520e-02, PNorm = 47.8687, GNorm = 2.7815, lr_0 = 5.7075e-04
Loss = 1.5191e-02, PNorm = 47.8990, GNorm = 3.0915, lr_0 = 5.6998e-04
Loss = 1.5258e-02, PNorm = 47.9302, GNorm = 2.0925, lr_0 = 5.6922e-04
Loss = 1.4098e-02, PNorm = 47.9602, GNorm = 1.6771, lr_0 = 5.6845e-04
Loss = 1.2329e-02, PNorm = 47.9839, GNorm = 3.3319, lr_0 = 5.6769e-04
Loss = 1.3998e-02, PNorm = 48.0131, GNorm = 2.6915, lr_0 = 5.6693e-04
Loss = 1.4778e-02, PNorm = 48.0299, GNorm = 2.7439, lr_0 = 5.6617e-04
Loss = 1.5831e-02, PNorm = 48.0550, GNorm = 2.8032, lr_0 = 5.6541e-04
Loss = 1.6551e-02, PNorm = 48.0781, GNorm = 2.4920, lr_0 = 5.6465e-04
Loss = 1.6309e-02, PNorm = 48.1064, GNorm = 6.2320, lr_0 = 5.6389e-04
Loss = 1.4565e-02, PNorm = 48.1509, GNorm = 3.9600, lr_0 = 5.6313e-04
Loss = 1.9305e-02, PNorm = 48.1771, GNorm = 3.7766, lr_0 = 5.6238e-04
Loss = 1.4330e-02, PNorm = 48.2181, GNorm = 2.1985, lr_0 = 5.6162e-04
Loss = 1.3590e-02, PNorm = 48.2424, GNorm = 2.7355, lr_0 = 5.6087e-04
Loss = 1.5957e-02, PNorm = 48.2711, GNorm = 2.2600, lr_0 = 5.6012e-04
Loss = 1.8858e-02, PNorm = 48.3074, GNorm = 3.0054, lr_0 = 5.5937e-04
Loss = 1.5352e-02, PNorm = 48.3348, GNorm = 2.8679, lr_0 = 5.5862e-04
Loss = 1.5002e-02, PNorm = 48.3703, GNorm = 2.3016, lr_0 = 5.5787e-04
Validation rmse = 2.333204
Validation R2 = -0.510602
Epoch 20
Train function
Loss = 1.3950e-02, PNorm = 48.3931, GNorm = 3.9915, lr_0 = 5.5712e-04
Loss = 1.3775e-02, PNorm = 48.4227, GNorm = 2.5617, lr_0 = 5.5637e-04
Loss = 1.4599e-02, PNorm = 48.4557, GNorm = 2.1833, lr_0 = 5.5562e-04
Loss = 1.2702e-02, PNorm = 48.4831, GNorm = 2.2522, lr_0 = 5.5488e-04
Loss = 1.2355e-02, PNorm = 48.5121, GNorm = 3.4796, lr_0 = 5.5413e-04
Loss = 1.4158e-02, PNorm = 48.5465, GNorm = 2.6732, lr_0 = 5.5339e-04
Loss = 1.5128e-02, PNorm = 48.5878, GNorm = 2.6745, lr_0 = 5.5265e-04
Loss = 1.2306e-02, PNorm = 48.6107, GNorm = 2.3987, lr_0 = 5.5191e-04
Loss = 1.4139e-02, PNorm = 48.6366, GNorm = 4.4449, lr_0 = 5.5117e-04
Loss = 1.5047e-02, PNorm = 48.6592, GNorm = 2.4339, lr_0 = 5.5043e-04
Loss = 1.2751e-02, PNorm = 48.6775, GNorm = 3.4410, lr_0 = 5.4969e-04
Loss = 1.4939e-02, PNorm = 48.7021, GNorm = 2.8522, lr_0 = 5.4895e-04
Loss = 1.4573e-02, PNorm = 48.7330, GNorm = 2.9216, lr_0 = 5.4821e-04
Loss = 1.3572e-02, PNorm = 48.7606, GNorm = 2.9368, lr_0 = 5.4748e-04
Loss = 1.4706e-02, PNorm = 48.7851, GNorm = 2.6240, lr_0 = 5.4674e-04
Loss = 1.5167e-02, PNorm = 48.8072, GNorm = 2.9320, lr_0 = 5.4601e-04
Loss = 1.3277e-02, PNorm = 48.8377, GNorm = 2.4854, lr_0 = 5.4528e-04
Loss = 1.3858e-02, PNorm = 48.8631, GNorm = 3.0974, lr_0 = 5.4455e-04
Loss = 1.5203e-02, PNorm = 48.8829, GNorm = 2.3835, lr_0 = 5.4382e-04
Loss = 1.3991e-02, PNorm = 48.9128, GNorm = 2.4005, lr_0 = 5.4309e-04
Loss = 1.5612e-02, PNorm = 48.9343, GNorm = 2.9846, lr_0 = 5.4236e-04
Loss = 1.5127e-02, PNorm = 48.9639, GNorm = 5.7383, lr_0 = 5.4163e-04
Loss = 1.5489e-02, PNorm = 48.9927, GNorm = 2.7839, lr_0 = 5.4090e-04
Validation rmse = 2.062589
Validation R2 = -0.180511
Epoch 21
Train function
Loss = 1.9281e-02, PNorm = 49.0223, GNorm = 4.1426, lr_0 = 5.4010e-04
Loss = 1.3340e-02, PNorm = 49.0477, GNorm = 4.4353, lr_0 = 5.3938e-04
Loss = 1.2439e-02, PNorm = 49.0829, GNorm = 2.1393, lr_0 = 5.3866e-04
Loss = 1.3924e-02, PNorm = 49.1195, GNorm = 1.9130, lr_0 = 5.3793e-04
Loss = 1.2898e-02, PNorm = 49.1468, GNorm = 2.8059, lr_0 = 5.3721e-04
Loss = 1.2112e-02, PNorm = 49.1755, GNorm = 3.6893, lr_0 = 5.3649e-04
Loss = 1.2452e-02, PNorm = 49.2031, GNorm = 2.8170, lr_0 = 5.3577e-04
Loss = 1.2524e-02, PNorm = 49.2323, GNorm = 2.3787, lr_0 = 5.3505e-04
Loss = 1.5274e-02, PNorm = 49.2615, GNorm = 2.4235, lr_0 = 5.3433e-04
Loss = 1.3456e-02, PNorm = 49.2837, GNorm = 4.8433, lr_0 = 5.3362e-04
Loss = 1.4556e-02, PNorm = 49.3129, GNorm = 4.4590, lr_0 = 5.3290e-04
Loss = 1.7064e-02, PNorm = 49.3387, GNorm = 3.4557, lr_0 = 5.3219e-04
Loss = 1.3372e-02, PNorm = 49.3714, GNorm = 2.3180, lr_0 = 5.3147e-04
Loss = 1.4146e-02, PNorm = 49.4017, GNorm = 2.8959, lr_0 = 5.3076e-04
Loss = 1.2180e-02, PNorm = 49.4281, GNorm = 2.8616, lr_0 = 5.3005e-04
Loss = 1.4695e-02, PNorm = 49.4492, GNorm = 3.3743, lr_0 = 5.2934e-04
Loss = 1.3415e-02, PNorm = 49.4712, GNorm = 3.9267, lr_0 = 5.2863e-04
Loss = 1.5101e-02, PNorm = 49.5036, GNorm = 4.0054, lr_0 = 5.2792e-04
Loss = 1.2957e-02, PNorm = 49.5259, GNorm = 2.4342, lr_0 = 5.2721e-04
Loss = 1.3659e-02, PNorm = 49.5499, GNorm = 2.8390, lr_0 = 5.2650e-04
Loss = 1.2707e-02, PNorm = 49.5796, GNorm = 1.9559, lr_0 = 5.2579e-04
Loss = 1.4275e-02, PNorm = 49.6028, GNorm = 3.2612, lr_0 = 5.2509e-04
Loss = 1.4120e-02, PNorm = 49.6249, GNorm = 2.5258, lr_0 = 5.2438e-04
Loss = 1.4583e-02, PNorm = 49.6544, GNorm = 7.4295, lr_0 = 5.2368e-04
Validation rmse = 2.649732
Validation R2 = -0.948267
Epoch 22
Train function
Loss = 1.4050e-02, PNorm = 49.6822, GNorm = 2.4134, lr_0 = 5.2291e-04
Loss = 1.0682e-02, PNorm = 49.7184, GNorm = 2.5448, lr_0 = 5.2221e-04
Loss = 1.3006e-02, PNorm = 49.7455, GNorm = 4.2757, lr_0 = 5.2151e-04
Loss = 1.1974e-02, PNorm = 49.7758, GNorm = 3.8271, lr_0 = 5.2081e-04
Loss = 1.0707e-02, PNorm = 49.8049, GNorm = 3.8828, lr_0 = 5.2011e-04
Loss = 1.4001e-02, PNorm = 49.8212, GNorm = 5.8744, lr_0 = 5.1941e-04
Loss = 1.2082e-02, PNorm = 49.8524, GNorm = 2.1112, lr_0 = 5.1871e-04
Loss = 1.0973e-02, PNorm = 49.8757, GNorm = 2.2671, lr_0 = 5.1802e-04
Loss = 1.1875e-02, PNorm = 49.8996, GNorm = 1.9082, lr_0 = 5.1732e-04
Loss = 1.2232e-02, PNorm = 49.9281, GNorm = 3.3902, lr_0 = 5.1663e-04
Loss = 1.0628e-02, PNorm = 49.9541, GNorm = 2.9030, lr_0 = 5.1593e-04
Loss = 1.2151e-02, PNorm = 49.9774, GNorm = 3.2217, lr_0 = 5.1524e-04
Loss = 1.2449e-02, PNorm = 49.9935, GNorm = 3.0396, lr_0 = 5.1455e-04
Loss = 1.4678e-02, PNorm = 50.0151, GNorm = 4.3976, lr_0 = 5.1386e-04
Loss = 1.4877e-02, PNorm = 50.0396, GNorm = 2.6552, lr_0 = 5.1317e-04
Loss = 1.4390e-02, PNorm = 50.0615, GNorm = 2.4172, lr_0 = 5.1248e-04
Loss = 1.5227e-02, PNorm = 50.0910, GNorm = 3.7410, lr_0 = 5.1180e-04
Loss = 1.4541e-02, PNorm = 50.1238, GNorm = 2.8563, lr_0 = 5.1111e-04
Loss = 1.4438e-02, PNorm = 50.1456, GNorm = 5.2358, lr_0 = 5.1042e-04
Loss = 1.2971e-02, PNorm = 50.1729, GNorm = 2.5188, lr_0 = 5.0974e-04
Loss = 1.4681e-02, PNorm = 50.1922, GNorm = 3.7587, lr_0 = 5.0905e-04
Loss = 1.1751e-02, PNorm = 50.2147, GNorm = 2.9147, lr_0 = 5.0837e-04
Loss = 1.4233e-02, PNorm = 50.2355, GNorm = 2.2500, lr_0 = 5.0769e-04
Validation rmse = 2.459815
Validation R2 = -0.678996
Epoch 23
Train function
Loss = 1.0977e-02, PNorm = 50.2599, GNorm = 3.7405, lr_0 = 5.0694e-04
Loss = 1.0098e-02, PNorm = 50.2868, GNorm = 2.4629, lr_0 = 5.0626e-04
Loss = 1.2847e-02, PNorm = 50.3134, GNorm = 2.5669, lr_0 = 5.0558e-04
Loss = 1.0478e-02, PNorm = 50.3428, GNorm = 2.4084, lr_0 = 5.0490e-04
Loss = 1.1512e-02, PNorm = 50.3665, GNorm = 2.8811, lr_0 = 5.0422e-04
Loss = 1.2934e-02, PNorm = 50.3967, GNorm = 3.2276, lr_0 = 5.0355e-04
Loss = 1.0729e-02, PNorm = 50.4246, GNorm = 2.2508, lr_0 = 5.0287e-04
Loss = 1.1832e-02, PNorm = 50.4492, GNorm = 3.3091, lr_0 = 5.0220e-04
Loss = 1.0812e-02, PNorm = 50.4755, GNorm = 1.9664, lr_0 = 5.0152e-04
Loss = 1.1247e-02, PNorm = 50.4981, GNorm = 2.8414, lr_0 = 5.0085e-04
Loss = 1.3082e-02, PNorm = 50.5200, GNorm = 2.2504, lr_0 = 5.0018e-04
Loss = 1.1113e-02, PNorm = 50.5436, GNorm = 2.6944, lr_0 = 4.9951e-04
Loss = 1.2866e-02, PNorm = 50.5694, GNorm = 3.8778, lr_0 = 4.9884e-04
Loss = 1.2982e-02, PNorm = 50.5914, GNorm = 4.7802, lr_0 = 4.9817e-04
Loss = 1.2204e-02, PNorm = 50.6149, GNorm = 4.0211, lr_0 = 4.9750e-04
Loss = 1.3044e-02, PNorm = 50.6365, GNorm = 3.1020, lr_0 = 4.9683e-04
Loss = 1.1225e-02, PNorm = 50.6561, GNorm = 2.8346, lr_0 = 4.9617e-04
Loss = 1.1404e-02, PNorm = 50.6782, GNorm = 3.4542, lr_0 = 4.9550e-04
Loss = 1.3776e-02, PNorm = 50.7041, GNorm = 3.5215, lr_0 = 4.9484e-04
Loss = 1.4188e-02, PNorm = 50.7305, GNorm = 3.3453, lr_0 = 4.9417e-04
Loss = 1.3333e-02, PNorm = 50.7547, GNorm = 3.3118, lr_0 = 4.9351e-04
Loss = 1.3564e-02, PNorm = 50.7879, GNorm = 5.9286, lr_0 = 4.9285e-04
Loss = 1.3575e-02, PNorm = 50.8142, GNorm = 2.5026, lr_0 = 4.9218e-04
Loss = 1.3993e-02, PNorm = 50.8357, GNorm = 2.3095, lr_0 = 4.9152e-04
Loss = 9.8621e-02, PNorm = 50.8375, GNorm = 7.7616, lr_0 = 4.9146e-04
Validation rmse = 2.796659
Validation R2 = -1.170319
Epoch 24
Train function
Loss = 1.1412e-02, PNorm = 50.8644, GNorm = 3.6527, lr_0 = 4.9080e-04
Loss = 1.1865e-02, PNorm = 50.8883, GNorm = 2.8764, lr_0 = 4.9014e-04
Loss = 1.2509e-02, PNorm = 50.9191, GNorm = 4.0432, lr_0 = 4.8948e-04
Loss = 1.0856e-02, PNorm = 50.9465, GNorm = 4.6805, lr_0 = 4.8883e-04
Loss = 1.0727e-02, PNorm = 50.9735, GNorm = 2.9357, lr_0 = 4.8817e-04
Loss = 9.9844e-03, PNorm = 50.9951, GNorm = 2.0562, lr_0 = 4.8752e-04
Loss = 1.0640e-02, PNorm = 51.0200, GNorm = 4.5385, lr_0 = 4.8686e-04
Loss = 1.0559e-02, PNorm = 51.0431, GNorm = 1.8358, lr_0 = 4.8621e-04
Loss = 1.1163e-02, PNorm = 51.0673, GNorm = 3.0210, lr_0 = 4.8556e-04
Loss = 1.1378e-02, PNorm = 51.0838, GNorm = 2.9331, lr_0 = 4.8490e-04
Loss = 1.2156e-02, PNorm = 51.1100, GNorm = 2.9906, lr_0 = 4.8425e-04
Loss = 1.2488e-02, PNorm = 51.1359, GNorm = 4.5093, lr_0 = 4.8360e-04
Loss = 1.0817e-02, PNorm = 51.1554, GNorm = 3.2942, lr_0 = 4.8296e-04
Loss = 1.1846e-02, PNorm = 51.1809, GNorm = 4.7479, lr_0 = 4.8231e-04
Loss = 1.1713e-02, PNorm = 51.2082, GNorm = 2.5201, lr_0 = 4.8166e-04
Loss = 1.1478e-02, PNorm = 51.2303, GNorm = 2.9562, lr_0 = 4.8101e-04
Loss = 1.0185e-02, PNorm = 51.2536, GNorm = 2.2973, lr_0 = 4.8037e-04
Loss = 1.4024e-02, PNorm = 51.2686, GNorm = 2.5788, lr_0 = 4.7972e-04
Loss = 1.2222e-02, PNorm = 51.2865, GNorm = 2.7327, lr_0 = 4.7908e-04
Loss = 1.1389e-02, PNorm = 51.3112, GNorm = 1.9013, lr_0 = 4.7844e-04
Loss = 1.3280e-02, PNorm = 51.3385, GNorm = 2.8427, lr_0 = 4.7780e-04
Loss = 1.0726e-02, PNorm = 51.3609, GNorm = 2.3973, lr_0 = 4.7715e-04
Loss = 1.3056e-02, PNorm = 51.3817, GNorm = 5.5135, lr_0 = 4.7651e-04
Validation rmse = 2.952002
Validation R2 = -1.418120
Epoch 25
Train function
Loss = 1.0657e-02, PNorm = 51.4037, GNorm = 2.6413, lr_0 = 4.7587e-04
Loss = 9.5081e-03, PNorm = 51.4294, GNorm = 2.3529, lr_0 = 4.7524e-04
Loss = 1.0183e-02, PNorm = 51.4527, GNorm = 4.7009, lr_0 = 4.7460e-04
Loss = 1.0933e-02, PNorm = 51.4726, GNorm = 3.5102, lr_0 = 4.7396e-04
Loss = 1.3089e-02, PNorm = 51.5058, GNorm = 3.5549, lr_0 = 4.7333e-04
Loss = 9.4074e-03, PNorm = 51.5317, GNorm = 2.7683, lr_0 = 4.7269e-04
Loss = 1.0951e-02, PNorm = 51.5507, GNorm = 4.2571, lr_0 = 4.7206e-04
Loss = 1.2469e-02, PNorm = 51.5734, GNorm = 2.4702, lr_0 = 4.7142e-04
Loss = 9.8966e-03, PNorm = 51.6000, GNorm = 2.4851, lr_0 = 4.7079e-04
Loss = 1.0616e-02, PNorm = 51.6259, GNorm = 4.0773, lr_0 = 4.7016e-04
Loss = 1.1907e-02, PNorm = 51.6508, GNorm = 3.8451, lr_0 = 4.6953e-04
Loss = 1.0114e-02, PNorm = 51.6713, GNorm = 2.3526, lr_0 = 4.6890e-04
Loss = 1.2443e-02, PNorm = 51.6921, GNorm = 3.3356, lr_0 = 4.6827e-04
Loss = 1.0699e-02, PNorm = 51.7101, GNorm = 2.9159, lr_0 = 4.6764e-04
Loss = 1.2226e-02, PNorm = 51.7297, GNorm = 2.4817, lr_0 = 4.6701e-04
Loss = 1.0712e-02, PNorm = 51.7505, GNorm = 3.5229, lr_0 = 4.6639e-04
Loss = 1.1057e-02, PNorm = 51.7686, GNorm = 6.1229, lr_0 = 4.6576e-04
Loss = 1.1845e-02, PNorm = 51.7901, GNorm = 2.4715, lr_0 = 4.6514e-04
Loss = 1.2039e-02, PNorm = 51.8131, GNorm = 3.3590, lr_0 = 4.6451e-04
Loss = 1.1879e-02, PNorm = 51.8363, GNorm = 2.6410, lr_0 = 4.6389e-04
Loss = 9.9898e-03, PNorm = 51.8573, GNorm = 2.2893, lr_0 = 4.6327e-04
Loss = 9.7728e-03, PNorm = 51.8784, GNorm = 3.4102, lr_0 = 4.6264e-04
Loss = 1.1329e-02, PNorm = 51.9038, GNorm = 3.2445, lr_0 = 4.6202e-04
Validation rmse = 2.734474
Validation R2 = -1.074875
Epoch 26
Train function
Loss = 8.2892e-03, PNorm = 51.9276, GNorm = 2.2056, lr_0 = 4.6134e-04
Loss = 9.8624e-03, PNorm = 51.9497, GNorm = 3.2746, lr_0 = 4.6072e-04
Loss = 1.0085e-02, PNorm = 51.9725, GNorm = 1.9801, lr_0 = 4.6011e-04
Loss = 1.0957e-02, PNorm = 51.9944, GNorm = 4.8247, lr_0 = 4.5949e-04
Loss = 9.9310e-03, PNorm = 52.0182, GNorm = 2.6549, lr_0 = 4.5887e-04
Loss = 1.1023e-02, PNorm = 52.0353, GNorm = 2.3535, lr_0 = 4.5826e-04
Loss = 1.0156e-02, PNorm = 52.0595, GNorm = 1.8964, lr_0 = 4.5764e-04
Loss = 1.0374e-02, PNorm = 52.0780, GNorm = 3.6771, lr_0 = 4.5703e-04
Loss = 1.1444e-02, PNorm = 52.0962, GNorm = 2.5807, lr_0 = 4.5641e-04
Loss = 8.4375e-03, PNorm = 52.1163, GNorm = 2.7882, lr_0 = 4.5580e-04
Loss = 1.0434e-02, PNorm = 52.1395, GNorm = 3.6666, lr_0 = 4.5519e-04
Loss = 1.0986e-02, PNorm = 52.1608, GNorm = 3.0042, lr_0 = 4.5458e-04
Loss = 1.0226e-02, PNorm = 52.1807, GNorm = 3.6663, lr_0 = 4.5397e-04
Loss = 9.2017e-03, PNorm = 52.2020, GNorm = 3.6526, lr_0 = 4.5336e-04
Loss = 1.0223e-02, PNorm = 52.2238, GNorm = 2.8371, lr_0 = 4.5275e-04
Loss = 8.2429e-03, PNorm = 52.2403, GNorm = 3.0967, lr_0 = 4.5214e-04
Loss = 1.0643e-02, PNorm = 52.2590, GNorm = 2.1504, lr_0 = 4.5154e-04
Loss = 1.0576e-02, PNorm = 52.2824, GNorm = 2.8559, lr_0 = 4.5093e-04
Loss = 1.0398e-02, PNorm = 52.3022, GNorm = 3.3964, lr_0 = 4.5033e-04
Loss = 1.0846e-02, PNorm = 52.3242, GNorm = 3.0776, lr_0 = 4.4972e-04
Loss = 1.0379e-02, PNorm = 52.3456, GNorm = 4.7916, lr_0 = 4.4912e-04
Loss = 1.0725e-02, PNorm = 52.3691, GNorm = 3.3972, lr_0 = 4.4852e-04
Loss = 1.2072e-02, PNorm = 52.3912, GNorm = 3.1056, lr_0 = 4.4791e-04
Loss = 1.2519e-02, PNorm = 52.4078, GNorm = 2.3582, lr_0 = 4.4731e-04
Validation rmse = 2.867488
Validation R2 = -1.281644
Epoch 27
Train function
Loss = 7.0698e-03, PNorm = 52.4356, GNorm = 2.2182, lr_0 = 4.4665e-04
Loss = 9.2599e-03, PNorm = 52.4636, GNorm = 2.8697, lr_0 = 4.4605e-04
Loss = 8.6545e-03, PNorm = 52.4926, GNorm = 2.6682, lr_0 = 4.4546e-04
Loss = 9.4262e-03, PNorm = 52.5160, GNorm = 3.5678, lr_0 = 4.4486e-04
Loss = 8.8053e-03, PNorm = 52.5330, GNorm = 3.4315, lr_0 = 4.4426e-04
Loss = 9.2361e-03, PNorm = 52.5525, GNorm = 2.3675, lr_0 = 4.4367e-04
Loss = 1.0381e-02, PNorm = 52.5738, GNorm = 2.8938, lr_0 = 4.4307e-04
Loss = 1.0112e-02, PNorm = 52.5929, GNorm = 2.5862, lr_0 = 4.4248e-04
Loss = 8.8678e-03, PNorm = 52.6136, GNorm = 2.0619, lr_0 = 4.4188e-04
Loss = 1.0063e-02, PNorm = 52.6314, GNorm = 2.1113, lr_0 = 4.4129e-04
Loss = 1.0216e-02, PNorm = 52.6498, GNorm = 2.8175, lr_0 = 4.4070e-04
Loss = 1.0938e-02, PNorm = 52.6699, GNorm = 6.7557, lr_0 = 4.4011e-04
Loss = 9.8166e-03, PNorm = 52.6943, GNorm = 3.7031, lr_0 = 4.3952e-04
Loss = 1.0011e-02, PNorm = 52.7186, GNorm = 3.2852, lr_0 = 4.3893e-04
Loss = 1.0077e-02, PNorm = 52.7395, GNorm = 2.5304, lr_0 = 4.3834e-04
Loss = 1.1492e-02, PNorm = 52.7564, GNorm = 5.3329, lr_0 = 4.3775e-04
Loss = 1.0754e-02, PNorm = 52.7730, GNorm = 2.6394, lr_0 = 4.3716e-04
Loss = 9.1408e-03, PNorm = 52.7928, GNorm = 2.8878, lr_0 = 4.3657e-04
Loss = 9.6477e-03, PNorm = 52.8092, GNorm = 3.1729, lr_0 = 4.3599e-04
Loss = 1.0566e-02, PNorm = 52.8310, GNorm = 4.2852, lr_0 = 4.3540e-04
Loss = 9.1668e-03, PNorm = 52.8537, GNorm = 4.2947, lr_0 = 4.3482e-04
Loss = 9.1202e-03, PNorm = 52.8715, GNorm = 2.7635, lr_0 = 4.3424e-04
Loss = 1.0504e-02, PNorm = 52.8827, GNorm = 3.7114, lr_0 = 4.3365e-04
Validation rmse = 2.923558
Validation R2 = -1.371744
Epoch 28
Train function
Loss = 1.0471e-02, PNorm = 52.9034, GNorm = 3.2380, lr_0 = 4.3301e-04
Loss = 8.3498e-03, PNorm = 52.9243, GNorm = 2.0425, lr_0 = 4.3243e-04
Loss = 8.8156e-03, PNorm = 52.9436, GNorm = 2.1515, lr_0 = 4.3185e-04
Loss = 8.1303e-03, PNorm = 52.9630, GNorm = 2.7084, lr_0 = 4.3127e-04
Loss = 8.6712e-03, PNorm = 52.9875, GNorm = 2.7321, lr_0 = 4.3069e-04
Loss = 1.0885e-02, PNorm = 53.0053, GNorm = 3.0987, lr_0 = 4.3012e-04
Loss = 9.6563e-03, PNorm = 53.0250, GNorm = 2.9042, lr_0 = 4.2954e-04
Loss = 8.7937e-03, PNorm = 53.0458, GNorm = 2.7582, lr_0 = 4.2896e-04
Loss = 9.5360e-03, PNorm = 53.0723, GNorm = 2.9324, lr_0 = 4.2839e-04
Loss = 8.0577e-03, PNorm = 53.0930, GNorm = 4.1626, lr_0 = 4.2781e-04
Loss = 8.8603e-03, PNorm = 53.1108, GNorm = 2.6221, lr_0 = 4.2724e-04
Loss = 8.4843e-03, PNorm = 53.1269, GNorm = 3.2743, lr_0 = 4.2667e-04
Loss = 9.8504e-03, PNorm = 53.1431, GNorm = 2.7574, lr_0 = 4.2609e-04
Loss = 9.0727e-03, PNorm = 53.1662, GNorm = 2.2582, lr_0 = 4.2552e-04
Loss = 9.4430e-03, PNorm = 53.1870, GNorm = 2.7751, lr_0 = 4.2495e-04
Loss = 9.5846e-03, PNorm = 53.2053, GNorm = 3.2971, lr_0 = 4.2438e-04
Loss = 9.8662e-03, PNorm = 53.2292, GNorm = 3.3474, lr_0 = 4.2381e-04
Loss = 9.5789e-03, PNorm = 53.2484, GNorm = 4.8285, lr_0 = 4.2324e-04
Loss = 8.7827e-03, PNorm = 53.2619, GNorm = 2.9156, lr_0 = 4.2267e-04
Loss = 8.6299e-03, PNorm = 53.2776, GNorm = 1.9606, lr_0 = 4.2211e-04
Loss = 8.8384e-03, PNorm = 53.2969, GNorm = 4.4268, lr_0 = 4.2154e-04
Loss = 9.3849e-03, PNorm = 53.3110, GNorm = 4.0216, lr_0 = 4.2098e-04
Loss = 8.6503e-03, PNorm = 53.3324, GNorm = 1.7774, lr_0 = 4.2041e-04
Loss = 9.4918e-03, PNorm = 53.3452, GNorm = 3.1941, lr_0 = 4.1985e-04
Validation rmse = 3.658208
Validation R2 = -2.713481
Epoch 29
Train function
Loss = 9.5440e-03, PNorm = 53.3668, GNorm = 2.6712, lr_0 = 4.1923e-04
Loss = 7.4224e-03, PNorm = 53.3835, GNorm = 2.6642, lr_0 = 4.1866e-04
Loss = 8.7182e-03, PNorm = 53.4015, GNorm = 3.3514, lr_0 = 4.1810e-04
Loss = 7.7847e-03, PNorm = 53.4216, GNorm = 2.4223, lr_0 = 4.1754e-04
Loss = 9.0289e-03, PNorm = 53.4466, GNorm = 3.2252, lr_0 = 4.1698e-04
Loss = 6.0235e-03, PNorm = 53.4651, GNorm = 2.4620, lr_0 = 4.1642e-04
Loss = 9.1167e-03, PNorm = 53.4823, GNorm = 3.2902, lr_0 = 4.1586e-04
Loss = 8.8310e-03, PNorm = 53.5008, GNorm = 3.8510, lr_0 = 4.1531e-04
Loss = 8.1890e-03, PNorm = 53.5219, GNorm = 4.2194, lr_0 = 4.1475e-04
Loss = 8.2308e-03, PNorm = 53.5430, GNorm = 2.2323, lr_0 = 4.1419e-04
Loss = 8.8868e-03, PNorm = 53.5562, GNorm = 2.6753, lr_0 = 4.1364e-04
Loss = 8.9988e-03, PNorm = 53.5763, GNorm = 3.3762, lr_0 = 4.1308e-04
Loss = 9.2476e-03, PNorm = 53.5967, GNorm = 4.5307, lr_0 = 4.1253e-04
Loss = 8.0839e-03, PNorm = 53.6083, GNorm = 2.8245, lr_0 = 4.1197e-04
Loss = 9.9631e-03, PNorm = 53.6297, GNorm = 4.0082, lr_0 = 4.1142e-04
Loss = 9.6004e-03, PNorm = 53.6525, GNorm = 4.3893, lr_0 = 4.1087e-04
Loss = 9.7137e-03, PNorm = 53.6744, GNorm = 3.4259, lr_0 = 4.1032e-04
Loss = 8.1966e-03, PNorm = 53.6899, GNorm = 2.8809, lr_0 = 4.0977e-04
Loss = 8.8795e-03, PNorm = 53.7061, GNorm = 2.6382, lr_0 = 4.0922e-04
Loss = 8.1335e-03, PNorm = 53.7181, GNorm = 4.6091, lr_0 = 4.0867e-04
Loss = 8.2700e-03, PNorm = 53.7299, GNorm = 2.8514, lr_0 = 4.0812e-04
Loss = 1.0112e-02, PNorm = 53.7485, GNorm = 3.6044, lr_0 = 4.0757e-04
Loss = 9.9433e-03, PNorm = 53.7602, GNorm = 5.0051, lr_0 = 4.0702e-04
Validation rmse = 2.756827
Validation R2 = -1.108938
Epoch 30
Train function
Loss = 8.7688e-03, PNorm = 53.7790, GNorm = 2.2590, lr_0 = 4.0648e-04
Loss = 8.4855e-03, PNorm = 53.7963, GNorm = 3.5469, lr_0 = 4.0593e-04
Loss = 8.4108e-03, PNorm = 53.8142, GNorm = 3.1149, lr_0 = 4.0539e-04
Loss = 8.6085e-03, PNorm = 53.8309, GNorm = 1.9785, lr_0 = 4.0484e-04
Loss = 8.8126e-03, PNorm = 53.8550, GNorm = 3.2424, lr_0 = 4.0430e-04
Loss = 8.8879e-03, PNorm = 53.8733, GNorm = 2.8271, lr_0 = 4.0376e-04
Loss = 7.7919e-03, PNorm = 53.8933, GNorm = 2.6793, lr_0 = 4.0322e-04
Loss = 7.4342e-03, PNorm = 53.9104, GNorm = 4.2402, lr_0 = 4.0268e-04
Loss = 7.9076e-03, PNorm = 53.9241, GNorm = 2.3898, lr_0 = 4.0214e-04
Loss = 6.4286e-03, PNorm = 53.9417, GNorm = 2.4606, lr_0 = 4.0160e-04
Loss = 8.6848e-03, PNorm = 53.9553, GNorm = 2.5407, lr_0 = 4.0106e-04
Loss = 7.8260e-03, PNorm = 53.9696, GNorm = 4.5311, lr_0 = 4.0052e-04
Loss = 7.6582e-03, PNorm = 53.9837, GNorm = 1.9422, lr_0 = 3.9998e-04
Loss = 8.3271e-03, PNorm = 54.0001, GNorm = 2.6748, lr_0 = 3.9945e-04
Loss = 7.0106e-03, PNorm = 54.0154, GNorm = 2.3856, lr_0 = 3.9891e-04
Loss = 8.3166e-03, PNorm = 54.0274, GNorm = 2.8221, lr_0 = 3.9837e-04
Loss = 8.3834e-03, PNorm = 54.0456, GNorm = 3.2165, lr_0 = 3.9784e-04
Loss = 7.6782e-03, PNorm = 54.0629, GNorm = 2.4024, lr_0 = 3.9731e-04
Loss = 7.7689e-03, PNorm = 54.0783, GNorm = 2.7731, lr_0 = 3.9677e-04
Loss = 8.5212e-03, PNorm = 54.0950, GNorm = 4.0549, lr_0 = 3.9624e-04
Loss = 8.0622e-03, PNorm = 54.1131, GNorm = 3.3570, lr_0 = 3.9571e-04
Loss = 7.0056e-03, PNorm = 54.1252, GNorm = 1.5338, lr_0 = 3.9518e-04
Loss = 8.9962e-03, PNorm = 54.1409, GNorm = 3.3109, lr_0 = 3.9465e-04
Loss = 7.4548e-03, PNorm = 54.1581, GNorm = 2.7109, lr_0 = 3.9412e-04
Loss = 2.3765e-02, PNorm = 54.1599, GNorm = 5.1221, lr_0 = 3.9407e-04
Validation rmse = 3.622146
Validation R2 = -2.640628
Epoch 31
Train function
Loss = 7.3339e-03, PNorm = 54.1790, GNorm = 3.0389, lr_0 = 3.9354e-04
Loss = 6.1869e-03, PNorm = 54.1941, GNorm = 1.8327, lr_0 = 3.9301e-04
Loss = 6.6184e-03, PNorm = 54.2085, GNorm = 3.4842, lr_0 = 3.9248e-04
Loss = 5.9197e-03, PNorm = 54.2256, GNorm = 4.1993, lr_0 = 3.9195e-04
Loss = 6.7747e-03, PNorm = 54.2411, GNorm = 2.7329, lr_0 = 3.9143e-04
Loss = 6.2865e-03, PNorm = 54.2549, GNorm = 1.9446, lr_0 = 3.9090e-04
Loss = 7.6305e-03, PNorm = 54.2705, GNorm = 2.8508, lr_0 = 3.9038e-04
Loss = 9.0007e-03, PNorm = 54.2868, GNorm = 3.8387, lr_0 = 3.8986e-04
Loss = 6.6781e-03, PNorm = 54.3041, GNorm = 2.7399, lr_0 = 3.8933e-04
Loss = 9.0721e-03, PNorm = 54.3182, GNorm = 2.2355, lr_0 = 3.8881e-04
Loss = 9.3815e-03, PNorm = 54.3358, GNorm = 3.7625, lr_0 = 3.8829e-04
Loss = 9.1333e-03, PNorm = 54.3549, GNorm = 2.6449, lr_0 = 3.8777e-04
Loss = 7.2232e-03, PNorm = 54.3733, GNorm = 3.7459, lr_0 = 3.8725e-04
Loss = 8.1834e-03, PNorm = 54.3921, GNorm = 3.2964, lr_0 = 3.8673e-04
Loss = 7.8711e-03, PNorm = 54.4081, GNorm = 3.5321, lr_0 = 3.8621e-04
Loss = 8.0646e-03, PNorm = 54.4259, GNorm = 5.1146, lr_0 = 3.8569e-04
Loss = 7.1530e-03, PNorm = 54.4421, GNorm = 4.0233, lr_0 = 3.8517e-04
Loss = 7.2550e-03, PNorm = 54.4568, GNorm = 2.6399, lr_0 = 3.8466e-04
Loss = 7.0024e-03, PNorm = 54.4731, GNorm = 2.7985, lr_0 = 3.8414e-04
Loss = 7.9873e-03, PNorm = 54.4862, GNorm = 4.2885, lr_0 = 3.8362e-04
Loss = 7.1852e-03, PNorm = 54.4971, GNorm = 2.2947, lr_0 = 3.8311e-04
Loss = 7.9103e-03, PNorm = 54.5098, GNorm = 2.4863, lr_0 = 3.8260e-04
Loss = 8.7754e-03, PNorm = 54.5246, GNorm = 4.6445, lr_0 = 3.8208e-04
Validation rmse = 3.795453
Validation R2 = -2.997346
Epoch 32
Train function
Loss = 5.7495e-03, PNorm = 54.5458, GNorm = 4.5237, lr_0 = 3.8152e-04
Loss = 5.9932e-03, PNorm = 54.5595, GNorm = 2.0649, lr_0 = 3.8101e-04
Loss = 6.7371e-03, PNorm = 54.5760, GNorm = 2.0886, lr_0 = 3.8050e-04
Loss = 6.9357e-03, PNorm = 54.5938, GNorm = 3.7736, lr_0 = 3.7999e-04
Loss = 7.1489e-03, PNorm = 54.6101, GNorm = 3.8448, lr_0 = 3.7948e-04
Loss = 6.8465e-03, PNorm = 54.6311, GNorm = 1.7100, lr_0 = 3.7897e-04
Loss = 8.9556e-03, PNorm = 54.6518, GNorm = 7.0223, lr_0 = 3.7846e-04
Loss = 6.3245e-03, PNorm = 54.6636, GNorm = 2.6119, lr_0 = 3.7795e-04
Loss = 8.2938e-03, PNorm = 54.6758, GNorm = 4.1558, lr_0 = 3.7744e-04
Loss = 7.1703e-03, PNorm = 54.6919, GNorm = 3.0720, lr_0 = 3.7694e-04
Loss = 7.2171e-03, PNorm = 54.7119, GNorm = 3.6898, lr_0 = 3.7643e-04
Loss = 7.1463e-03, PNorm = 54.7290, GNorm = 2.6037, lr_0 = 3.7593e-04
Loss = 6.2591e-03, PNorm = 54.7415, GNorm = 2.7208, lr_0 = 3.7542e-04
Loss = 6.0145e-03, PNorm = 54.7555, GNorm = 2.2195, lr_0 = 3.7492e-04
Loss = 6.5221e-03, PNorm = 54.7698, GNorm = 4.9334, lr_0 = 3.7441e-04
Loss = 5.8123e-03, PNorm = 54.7891, GNorm = 2.2685, lr_0 = 3.7391e-04
Loss = 8.7393e-03, PNorm = 54.8020, GNorm = 3.7495, lr_0 = 3.7341e-04
Loss = 6.5284e-03, PNorm = 54.8142, GNorm = 2.5921, lr_0 = 3.7291e-04
Loss = 7.6374e-03, PNorm = 54.8305, GNorm = 4.7330, lr_0 = 3.7241e-04
Loss = 8.3973e-03, PNorm = 54.8473, GNorm = 2.9896, lr_0 = 3.7191e-04
Loss = 7.6365e-03, PNorm = 54.8630, GNorm = 3.0555, lr_0 = 3.7141e-04
Loss = 8.1857e-03, PNorm = 54.8773, GNorm = 3.5212, lr_0 = 3.7091e-04
Loss = 6.5968e-03, PNorm = 54.8887, GNorm = 2.8179, lr_0 = 3.7041e-04
Validation rmse = 3.768465
Validation R2 = -2.940702
Epoch 33
Train function
Loss = 6.0107e-03, PNorm = 54.9030, GNorm = 4.2994, lr_0 = 3.6987e-04
Loss = 5.6992e-03, PNorm = 54.9205, GNorm = 2.4085, lr_0 = 3.6937e-04
Loss = 5.7233e-03, PNorm = 54.9356, GNorm = 2.8192, lr_0 = 3.6888e-04
Loss = 6.8232e-03, PNorm = 54.9472, GNorm = 3.3271, lr_0 = 3.6838e-04
Loss = 6.0974e-03, PNorm = 54.9596, GNorm = 3.0308, lr_0 = 3.6789e-04
Loss = 5.9139e-03, PNorm = 54.9769, GNorm = 3.0076, lr_0 = 3.6739e-04
Loss = 6.0696e-03, PNorm = 54.9915, GNorm = 3.6731, lr_0 = 3.6690e-04
Loss = 6.6785e-03, PNorm = 55.0057, GNorm = 2.2606, lr_0 = 3.6641e-04
Loss = 6.6040e-03, PNorm = 55.0191, GNorm = 2.8714, lr_0 = 3.6592e-04
Loss = 6.3223e-03, PNorm = 55.0322, GNorm = 2.1610, lr_0 = 3.6543e-04
Loss = 6.5266e-03, PNorm = 55.0461, GNorm = 4.4499, lr_0 = 3.6494e-04
Loss = 6.3657e-03, PNorm = 55.0600, GNorm = 4.9717, lr_0 = 3.6445e-04
Loss = 6.1276e-03, PNorm = 55.0737, GNorm = 4.4249, lr_0 = 3.6396e-04
Loss = 6.3083e-03, PNorm = 55.0846, GNorm = 2.5525, lr_0 = 3.6347e-04
Loss = 7.3486e-03, PNorm = 55.1000, GNorm = 3.0284, lr_0 = 3.6298e-04
Loss = 7.5586e-03, PNorm = 55.1123, GNorm = 3.0072, lr_0 = 3.6249e-04
Loss = 6.2391e-03, PNorm = 55.1281, GNorm = 1.4129, lr_0 = 3.6201e-04
Loss = 6.1705e-03, PNorm = 55.1414, GNorm = 4.1769, lr_0 = 3.6152e-04
Loss = 8.0207e-03, PNorm = 55.1558, GNorm = 2.5014, lr_0 = 3.6104e-04
Loss = 6.0174e-03, PNorm = 55.1705, GNorm = 2.5749, lr_0 = 3.6055e-04
Loss = 7.1441e-03, PNorm = 55.1858, GNorm = 3.6113, lr_0 = 3.6007e-04
Loss = 7.1645e-03, PNorm = 55.1976, GNorm = 4.6538, lr_0 = 3.5959e-04
Loss = 6.7774e-03, PNorm = 55.2129, GNorm = 2.4068, lr_0 = 3.5910e-04
Loss = 7.6522e-03, PNorm = 55.2244, GNorm = 3.7797, lr_0 = 3.5862e-04
Validation rmse = 2.904389
Validation R2 = -1.340746
Epoch 34
Train function
Loss = 6.1077e-03, PNorm = 55.2389, GNorm = 2.5338, lr_0 = 3.5809e-04
Loss = 6.0557e-03, PNorm = 55.2559, GNorm = 3.7328, lr_0 = 3.5761e-04
Loss = 8.1231e-03, PNorm = 55.2729, GNorm = 4.1320, lr_0 = 3.5713e-04
Loss = 6.4857e-03, PNorm = 55.2920, GNorm = 2.0153, lr_0 = 3.5665e-04
Loss = 5.7268e-03, PNorm = 55.3046, GNorm = 2.4401, lr_0 = 3.5617e-04
Loss = 5.3013e-03, PNorm = 55.3211, GNorm = 2.6783, lr_0 = 3.5570e-04
Loss = 5.6394e-03, PNorm = 55.3355, GNorm = 3.0238, lr_0 = 3.5522e-04
Loss = 5.9419e-03, PNorm = 55.3488, GNorm = 3.1128, lr_0 = 3.5474e-04
Loss = 7.0012e-03, PNorm = 55.3593, GNorm = 2.6026, lr_0 = 3.5427e-04
Loss = 5.5705e-03, PNorm = 55.3698, GNorm = 2.5234, lr_0 = 3.5379e-04
Loss = 6.0380e-03, PNorm = 55.3844, GNorm = 3.8758, lr_0 = 3.5332e-04
Loss = 5.5328e-03, PNorm = 55.3940, GNorm = 2.4563, lr_0 = 3.5284e-04
Loss = 6.4248e-03, PNorm = 55.4082, GNorm = 1.7543, lr_0 = 3.5237e-04
Loss = 5.7549e-03, PNorm = 55.4231, GNorm = 2.9490, lr_0 = 3.5190e-04
Loss = 6.6947e-03, PNorm = 55.4379, GNorm = 4.1293, lr_0 = 3.5142e-04
Loss = 5.1006e-03, PNorm = 55.4518, GNorm = 2.7041, lr_0 = 3.5095e-04
Loss = 6.7175e-03, PNorm = 55.4648, GNorm = 3.1625, lr_0 = 3.5048e-04
Loss = 7.6035e-03, PNorm = 55.4786, GNorm = 4.9223, lr_0 = 3.5001e-04
Loss = 6.6192e-03, PNorm = 55.4915, GNorm = 4.6346, lr_0 = 3.4954e-04
Loss = 5.5257e-03, PNorm = 55.5038, GNorm = 2.4241, lr_0 = 3.4907e-04
Loss = 6.8272e-03, PNorm = 55.5171, GNorm = 4.5024, lr_0 = 3.4860e-04
Loss = 7.2932e-03, PNorm = 55.5311, GNorm = 3.5500, lr_0 = 3.4814e-04
Loss = 5.0930e-03, PNorm = 55.5412, GNorm = 2.6132, lr_0 = 3.4767e-04
Validation rmse = 3.560569
Validation R2 = -2.517899
Epoch 35
Train function
Loss = 5.0909e-03, PNorm = 55.5506, GNorm = 3.3749, lr_0 = 3.4720e-04
Loss = 4.5377e-03, PNorm = 55.5604, GNorm = 2.3201, lr_0 = 3.4674e-04
Loss = 4.6696e-03, PNorm = 55.5708, GNorm = 2.9552, lr_0 = 3.4627e-04
Loss = 5.2208e-03, PNorm = 55.5840, GNorm = 2.8773, lr_0 = 3.4581e-04
Loss = 5.6747e-03, PNorm = 55.5999, GNorm = 7.2562, lr_0 = 3.4534e-04
Loss = 6.4736e-03, PNorm = 55.6138, GNorm = 2.2865, lr_0 = 3.4488e-04
Loss = 5.5892e-03, PNorm = 55.6256, GNorm = 4.0192, lr_0 = 3.4442e-04
Loss = 5.0195e-03, PNorm = 55.6363, GNorm = 2.8624, lr_0 = 3.4395e-04
Loss = 6.1328e-03, PNorm = 55.6452, GNorm = 4.5838, lr_0 = 3.4349e-04
Loss = 5.4069e-03, PNorm = 55.6543, GNorm = 2.1015, lr_0 = 3.4303e-04
Loss = 6.4084e-03, PNorm = 55.6632, GNorm = 2.2067, lr_0 = 3.4257e-04
Loss = 6.4868e-03, PNorm = 55.6720, GNorm = 4.0559, lr_0 = 3.4211e-04
Loss = 5.6727e-03, PNorm = 55.6854, GNorm = 3.4214, lr_0 = 3.4165e-04
Loss = 6.3852e-03, PNorm = 55.7008, GNorm = 2.8349, lr_0 = 3.4120e-04
Loss = 5.7777e-03, PNorm = 55.7152, GNorm = 4.2046, lr_0 = 3.4074e-04
Loss = 6.6488e-03, PNorm = 55.7263, GNorm = 2.5749, lr_0 = 3.4028e-04
Loss = 5.6382e-03, PNorm = 55.7413, GNorm = 2.8033, lr_0 = 3.3982e-04
Loss = 6.4607e-03, PNorm = 55.7551, GNorm = 2.4469, lr_0 = 3.3937e-04
Loss = 5.2856e-03, PNorm = 55.7651, GNorm = 2.6050, lr_0 = 3.3891e-04
Loss = 5.8051e-03, PNorm = 55.7764, GNorm = 3.0128, lr_0 = 3.3846e-04
Loss = 4.9039e-03, PNorm = 55.7887, GNorm = 2.3142, lr_0 = 3.3800e-04
Loss = 5.3160e-03, PNorm = 55.8028, GNorm = 3.3002, lr_0 = 3.3755e-04
Loss = 5.5576e-03, PNorm = 55.8137, GNorm = 5.7785, lr_0 = 3.3710e-04
Loss = 5.4893e-03, PNorm = 55.8256, GNorm = 3.4988, lr_0 = 3.3664e-04
Validation rmse = 3.841822
Validation R2 = -3.095615
Epoch 36
Train function
Loss = 4.1974e-03, PNorm = 55.8386, GNorm = 3.6819, lr_0 = 3.3615e-04
Loss = 6.4656e-03, PNorm = 55.8507, GNorm = 3.0389, lr_0 = 3.3570e-04
Loss = 5.7850e-03, PNorm = 55.8627, GNorm = 4.2175, lr_0 = 3.3525e-04
Loss = 4.4178e-03, PNorm = 55.8758, GNorm = 3.0012, lr_0 = 3.3480e-04
Loss = 5.5704e-03, PNorm = 55.8888, GNorm = 3.1498, lr_0 = 3.3435e-04
Loss = 5.6728e-03, PNorm = 55.8997, GNorm = 3.4931, lr_0 = 3.3390e-04
Loss = 4.9031e-03, PNorm = 55.9131, GNorm = 4.3257, lr_0 = 3.3345e-04
Loss = 4.9274e-03, PNorm = 55.9294, GNorm = 3.3575, lr_0 = 3.3300e-04
Loss = 5.2691e-03, PNorm = 55.9417, GNorm = 2.2417, lr_0 = 3.3256e-04
Loss = 5.1893e-03, PNorm = 55.9541, GNorm = 2.9895, lr_0 = 3.3211e-04
Loss = 5.1583e-03, PNorm = 55.9651, GNorm = 3.2312, lr_0 = 3.3167e-04
Loss = 5.2842e-03, PNorm = 55.9726, GNorm = 2.5739, lr_0 = 3.3122e-04
Loss = 6.4061e-03, PNorm = 55.9842, GNorm = 3.2202, lr_0 = 3.3078e-04
Loss = 4.6712e-03, PNorm = 55.9972, GNorm = 3.0759, lr_0 = 3.3033e-04
Loss = 5.4232e-03, PNorm = 56.0098, GNorm = 3.0990, lr_0 = 3.2989e-04
Loss = 5.4635e-03, PNorm = 56.0216, GNorm = 3.2481, lr_0 = 3.2945e-04
Loss = 5.8354e-03, PNorm = 56.0326, GNorm = 3.5202, lr_0 = 3.2900e-04
Loss = 5.9270e-03, PNorm = 56.0455, GNorm = 1.9530, lr_0 = 3.2856e-04
Loss = 4.9678e-03, PNorm = 56.0594, GNorm = 4.3679, lr_0 = 3.2812e-04
Loss = 4.6214e-03, PNorm = 56.0726, GNorm = 2.3443, lr_0 = 3.2768e-04
Loss = 6.0941e-03, PNorm = 56.0835, GNorm = 4.1954, lr_0 = 3.2724e-04
Loss = 5.2100e-03, PNorm = 56.0948, GNorm = 2.3042, lr_0 = 3.2680e-04
Loss = 6.4945e-03, PNorm = 56.1071, GNorm = 5.0155, lr_0 = 3.2636e-04
Validation rmse = 3.748864
Validation R2 = -2.899814
Epoch 37
Train function
Loss = 4.4626e-03, PNorm = 56.1171, GNorm = 2.4563, lr_0 = 3.2588e-04
Loss = 4.4589e-03, PNorm = 56.1307, GNorm = 3.7798, lr_0 = 3.2545e-04
Loss = 4.8103e-03, PNorm = 56.1413, GNorm = 2.4059, lr_0 = 3.2501e-04
Loss = 5.4516e-03, PNorm = 56.1553, GNorm = 3.9988, lr_0 = 3.2457e-04
Loss = 4.0592e-03, PNorm = 56.1663, GNorm = 3.0489, lr_0 = 3.2414e-04
Loss = 4.5309e-03, PNorm = 56.1786, GNorm = 2.5964, lr_0 = 3.2370e-04
Loss = 4.5473e-03, PNorm = 56.1878, GNorm = 2.2475, lr_0 = 3.2327e-04
Loss = 4.3328e-03, PNorm = 56.1992, GNorm = 3.9144, lr_0 = 3.2283e-04
Loss = 5.0253e-03, PNorm = 56.2096, GNorm = 2.2742, lr_0 = 3.2240e-04
Loss = 5.2620e-03, PNorm = 56.2192, GNorm = 2.3570, lr_0 = 3.2197e-04
Loss = 4.0563e-03, PNorm = 56.2290, GNorm = 1.7345, lr_0 = 3.2154e-04
Loss = 5.1423e-03, PNorm = 56.2387, GNorm = 4.1334, lr_0 = 3.2111e-04
Loss = 5.1695e-03, PNorm = 56.2485, GNorm = 3.1203, lr_0 = 3.2067e-04
Loss = 4.7381e-03, PNorm = 56.2595, GNorm = 2.0480, lr_0 = 3.2024e-04
Loss = 5.1631e-03, PNorm = 56.2691, GNorm = 2.2573, lr_0 = 3.1981e-04
Loss = 4.5654e-03, PNorm = 56.2801, GNorm = 7.0835, lr_0 = 3.1939e-04
Loss = 4.6664e-03, PNorm = 56.2880, GNorm = 2.5475, lr_0 = 3.1896e-04
Loss = 5.1870e-03, PNorm = 56.2969, GNorm = 2.8549, lr_0 = 3.1853e-04
Loss = 6.2921e-03, PNorm = 56.3077, GNorm = 3.6060, lr_0 = 3.1810e-04
Loss = 4.5504e-03, PNorm = 56.3207, GNorm = 3.0879, lr_0 = 3.1767e-04
Loss = 5.8941e-03, PNorm = 56.3299, GNorm = 2.9176, lr_0 = 3.1725e-04
Loss = 5.2549e-03, PNorm = 56.3423, GNorm = 3.5464, lr_0 = 3.1682e-04
Loss = 5.1312e-03, PNorm = 56.3566, GNorm = 2.9881, lr_0 = 3.1640e-04
Validation rmse = 3.939439
Validation R2 = -3.306389
Epoch 38
Train function
Loss = 3.8833e-03, PNorm = 56.3687, GNorm = 2.2367, lr_0 = 3.1593e-04
Loss = 4.4036e-03, PNorm = 56.3807, GNorm = 2.2517, lr_0 = 3.1551e-04
Loss = 5.2590e-03, PNorm = 56.3943, GNorm = 3.6269, lr_0 = 3.1508e-04
Loss = 4.3240e-03, PNorm = 56.4035, GNorm = 2.7548, lr_0 = 3.1466e-04
Loss = 5.2105e-03, PNorm = 56.4117, GNorm = 2.9296, lr_0 = 3.1424e-04
Loss = 3.9302e-03, PNorm = 56.4189, GNorm = 3.2838, lr_0 = 3.1382e-04
Loss = 4.0144e-03, PNorm = 56.4291, GNorm = 3.6106, lr_0 = 3.1340e-04
Loss = 4.5253e-03, PNorm = 56.4433, GNorm = 2.4913, lr_0 = 3.1298e-04
Loss = 4.1767e-03, PNorm = 56.4559, GNorm = 3.1884, lr_0 = 3.1256e-04
Loss = 4.1801e-03, PNorm = 56.4663, GNorm = 1.7602, lr_0 = 3.1214e-04
Loss = 4.9298e-03, PNorm = 56.4771, GNorm = 3.1885, lr_0 = 3.1172e-04
Loss = 4.2845e-03, PNorm = 56.4870, GNorm = 3.3971, lr_0 = 3.1130e-04
Loss = 4.2999e-03, PNorm = 56.4977, GNorm = 2.6145, lr_0 = 3.1088e-04
Loss = 4.2972e-03, PNorm = 56.5121, GNorm = 2.2400, lr_0 = 3.1046e-04
Loss = 5.4846e-03, PNorm = 56.5239, GNorm = 3.9192, lr_0 = 3.1005e-04
Loss = 3.7206e-03, PNorm = 56.5330, GNorm = 2.7905, lr_0 = 3.0963e-04
Loss = 4.8154e-03, PNorm = 56.5421, GNorm = 3.5733, lr_0 = 3.0922e-04
Loss = 6.1325e-03, PNorm = 56.5514, GNorm = 3.9673, lr_0 = 3.0880e-04
Loss = 5.1480e-03, PNorm = 56.5616, GNorm = 3.4236, lr_0 = 3.0839e-04
Loss = 4.7746e-03, PNorm = 56.5735, GNorm = 2.5808, lr_0 = 3.0797e-04
Loss = 5.2480e-03, PNorm = 56.5825, GNorm = 2.1464, lr_0 = 3.0756e-04
Loss = 4.8207e-03, PNorm = 56.5922, GNorm = 2.7097, lr_0 = 3.0715e-04
Loss = 4.6003e-03, PNorm = 56.5990, GNorm = 2.6420, lr_0 = 3.0674e-04
Loss = 4.4667e-03, PNorm = 56.6084, GNorm = 2.4707, lr_0 = 3.0632e-04
Validation rmse = 3.954053
Validation R2 = -3.338399
Epoch 39
Train function
Loss = 3.9482e-03, PNorm = 56.6204, GNorm = 3.8611, lr_0 = 3.0587e-04
Loss = 4.0088e-03, PNorm = 56.6289, GNorm = 2.6418, lr_0 = 3.0546e-04
Loss = 3.6060e-03, PNorm = 56.6380, GNorm = 2.6069, lr_0 = 3.0505e-04
Loss = 4.1371e-03, PNorm = 56.6468, GNorm = 2.9417, lr_0 = 3.0464e-04
Loss = 4.2141e-03, PNorm = 56.6569, GNorm = 2.5895, lr_0 = 3.0423e-04
Loss = 4.0141e-03, PNorm = 56.6693, GNorm = 4.8151, lr_0 = 3.0383e-04
Loss = 4.6938e-03, PNorm = 56.6825, GNorm = 2.3230, lr_0 = 3.0342e-04
Loss = 3.9702e-03, PNorm = 56.6953, GNorm = 2.6436, lr_0 = 3.0301e-04
Loss = 4.3697e-03, PNorm = 56.7095, GNorm = 2.1543, lr_0 = 3.0260e-04
Loss = 3.8104e-03, PNorm = 56.7188, GNorm = 2.2790, lr_0 = 3.0220e-04
Loss = 4.2703e-03, PNorm = 56.7283, GNorm = 3.4129, lr_0 = 3.0179e-04
Loss = 4.7785e-03, PNorm = 56.7393, GNorm = 3.1460, lr_0 = 3.0139e-04
Loss = 3.2984e-03, PNorm = 56.7475, GNorm = 2.1193, lr_0 = 3.0098e-04
Loss = 4.2836e-03, PNorm = 56.7562, GNorm = 2.3145, lr_0 = 3.0058e-04
Loss = 4.4005e-03, PNorm = 56.7658, GNorm = 4.8830, lr_0 = 3.0018e-04
Loss = 4.3711e-03, PNorm = 56.7731, GNorm = 3.5275, lr_0 = 2.9977e-04
Loss = 4.0638e-03, PNorm = 56.7819, GNorm = 2.4209, lr_0 = 2.9937e-04
Loss = 4.2956e-03, PNorm = 56.7919, GNorm = 3.5006, lr_0 = 2.9897e-04
Loss = 4.4303e-03, PNorm = 56.8016, GNorm = 2.9993, lr_0 = 2.9857e-04
Loss = 4.4885e-03, PNorm = 56.8133, GNorm = 3.8608, lr_0 = 2.9817e-04
Loss = 4.8859e-03, PNorm = 56.8200, GNorm = 2.9637, lr_0 = 2.9777e-04
Loss = 4.6320e-03, PNorm = 56.8272, GNorm = 3.3896, lr_0 = 2.9737e-04
Loss = 5.6348e-03, PNorm = 56.8346, GNorm = 2.8000, lr_0 = 2.9697e-04
Validation rmse = 3.617547
Validation R2 = -2.631391
Epoch 40
Train function
Loss = 2.3453e-03, PNorm = 56.8442, GNorm = 2.8368, lr_0 = 2.9657e-04
Loss = 3.8769e-03, PNorm = 56.8551, GNorm = 3.1556, lr_0 = 2.9617e-04
Loss = 3.7837e-03, PNorm = 56.8631, GNorm = 1.6816, lr_0 = 2.9578e-04
Loss = 4.4159e-03, PNorm = 56.8711, GNorm = 2.9901, lr_0 = 2.9538e-04
Loss = 3.7803e-03, PNorm = 56.8810, GNorm = 2.2785, lr_0 = 2.9498e-04
Loss = 3.8699e-03, PNorm = 56.8892, GNorm = 3.5931, lr_0 = 2.9459e-04
Loss = 3.4711e-03, PNorm = 56.8996, GNorm = 3.0104, lr_0 = 2.9419e-04
Loss = 3.7179e-03, PNorm = 56.9062, GNorm = 3.6708, lr_0 = 2.9380e-04
Loss = 4.4784e-03, PNorm = 56.9166, GNorm = 1.8594, lr_0 = 2.9340e-04
Loss = 4.1171e-03, PNorm = 56.9266, GNorm = 2.2260, lr_0 = 2.9301e-04
Loss = 4.6986e-03, PNorm = 56.9360, GNorm = 4.8355, lr_0 = 2.9262e-04
Loss = 5.1070e-03, PNorm = 56.9469, GNorm = 4.2983, lr_0 = 2.9222e-04
Loss = 4.3492e-03, PNorm = 56.9576, GNorm = 4.6643, lr_0 = 2.9183e-04
Loss = 4.1195e-03, PNorm = 56.9691, GNorm = 2.4151, lr_0 = 2.9144e-04
Loss = 3.8218e-03, PNorm = 56.9786, GNorm = 1.5325, lr_0 = 2.9105e-04
Loss = 4.2219e-03, PNorm = 56.9855, GNorm = 2.3894, lr_0 = 2.9066e-04
Loss = 3.7406e-03, PNorm = 56.9931, GNorm = 3.5921, lr_0 = 2.9027e-04
Loss = 4.2288e-03, PNorm = 57.0020, GNorm = 3.7153, lr_0 = 2.8988e-04
Loss = 4.0125e-03, PNorm = 57.0102, GNorm = 3.1471, lr_0 = 2.8949e-04
Loss = 3.7078e-03, PNorm = 57.0184, GNorm = 2.9626, lr_0 = 2.8910e-04
Loss = 4.0791e-03, PNorm = 57.0256, GNorm = 2.4494, lr_0 = 2.8871e-04
Loss = 3.5448e-03, PNorm = 57.0345, GNorm = 2.2280, lr_0 = 2.8833e-04
Loss = 3.6697e-03, PNorm = 57.0437, GNorm = 2.4985, lr_0 = 2.8794e-04
Loss = 4.4497e-03, PNorm = 57.0509, GNorm = 3.8601, lr_0 = 2.8755e-04
Validation rmse = 3.519346
Validation R2 = -2.436913
Epoch 41
Train function
Loss = 3.8770e-03, PNorm = 57.0612, GNorm = 3.7369, lr_0 = 2.8713e-04
Loss = 3.7542e-03, PNorm = 57.0727, GNorm = 2.0740, lr_0 = 2.8674e-04
Loss = 3.0753e-03, PNorm = 57.0804, GNorm = 3.0938, lr_0 = 2.8636e-04
Loss = 2.6572e-03, PNorm = 57.0907, GNorm = 1.3660, lr_0 = 2.8597e-04
Loss = 2.6671e-03, PNorm = 57.0997, GNorm = 1.2890, lr_0 = 2.8559e-04
Loss = 4.3666e-03, PNorm = 57.1055, GNorm = 2.0664, lr_0 = 2.8521e-04
Loss = 3.5940e-03, PNorm = 57.1110, GNorm = 2.5324, lr_0 = 2.8482e-04
Loss = 3.7663e-03, PNorm = 57.1201, GNorm = 2.3581, lr_0 = 2.8444e-04
Loss = 3.2895e-03, PNorm = 57.1280, GNorm = 1.7088, lr_0 = 2.8406e-04
Loss = 3.3838e-03, PNorm = 57.1357, GNorm = 2.9698, lr_0 = 2.8368e-04
Loss = 3.8979e-03, PNorm = 57.1446, GNorm = 3.0621, lr_0 = 2.8330e-04
Loss = 3.2895e-03, PNorm = 57.1527, GNorm = 3.5184, lr_0 = 2.8292e-04
Loss = 4.0881e-03, PNorm = 57.1615, GNorm = 3.1732, lr_0 = 2.8254e-04
Loss = 3.6128e-03, PNorm = 57.1691, GNorm = 4.0130, lr_0 = 2.8216e-04
Loss = 3.6757e-03, PNorm = 57.1759, GNorm = 2.5649, lr_0 = 2.8178e-04
Loss = 3.2288e-03, PNorm = 57.1834, GNorm = 2.1051, lr_0 = 2.8140e-04
Loss = 4.4642e-03, PNorm = 57.1914, GNorm = 2.8197, lr_0 = 2.8103e-04
Loss = 4.1956e-03, PNorm = 57.1988, GNorm = 3.5824, lr_0 = 2.8065e-04
Loss = 3.5725e-03, PNorm = 57.2087, GNorm = 3.5509, lr_0 = 2.8027e-04
Loss = 4.9006e-03, PNorm = 57.2168, GNorm = 2.3753, lr_0 = 2.7990e-04
Loss = 4.3319e-03, PNorm = 57.2234, GNorm = 3.8912, lr_0 = 2.7952e-04
Loss = 3.8296e-03, PNorm = 57.2313, GNorm = 3.5362, lr_0 = 2.7915e-04
Loss = 3.6912e-03, PNorm = 57.2404, GNorm = 2.8546, lr_0 = 2.7877e-04
Validation rmse = 3.945871
Validation R2 = -3.320464
Epoch 42
Train function
Loss = 4.0617e-03, PNorm = 57.2479, GNorm = 3.1507, lr_0 = 2.7836e-04
Loss = 3.5035e-03, PNorm = 57.2584, GNorm = 2.9303, lr_0 = 2.7799e-04
Loss = 3.6803e-03, PNorm = 57.2670, GNorm = 2.0762, lr_0 = 2.7761e-04
Loss = 3.1452e-03, PNorm = 57.2760, GNorm = 3.8841, lr_0 = 2.7724e-04
Loss = 3.1153e-03, PNorm = 57.2820, GNorm = 1.6789, lr_0 = 2.7687e-04
Loss = 2.7022e-03, PNorm = 57.2897, GNorm = 2.4477, lr_0 = 2.7650e-04
Loss = 3.4318e-03, PNorm = 57.2973, GNorm = 3.5136, lr_0 = 2.7613e-04
Loss = 3.2571e-03, PNorm = 57.3046, GNorm = 2.8248, lr_0 = 2.7576e-04
Loss = 3.6542e-03, PNorm = 57.3115, GNorm = 4.0799, lr_0 = 2.7539e-04
Loss = 3.5303e-03, PNorm = 57.3175, GNorm = 2.4301, lr_0 = 2.7502e-04
Loss = 3.9008e-03, PNorm = 57.3253, GNorm = 3.3743, lr_0 = 2.7465e-04
Loss = 3.5684e-03, PNorm = 57.3360, GNorm = 2.6904, lr_0 = 2.7428e-04
Loss = 3.4710e-03, PNorm = 57.3492, GNorm = 3.0136, lr_0 = 2.7391e-04
Loss = 3.5828e-03, PNorm = 57.3583, GNorm = 2.2095, lr_0 = 2.7354e-04
Loss = 3.4324e-03, PNorm = 57.3657, GNorm = 3.3740, lr_0 = 2.7318e-04
Loss = 3.5964e-03, PNorm = 57.3738, GNorm = 2.3643, lr_0 = 2.7281e-04
Loss = 2.9736e-03, PNorm = 57.3814, GNorm = 3.0510, lr_0 = 2.7244e-04
Loss = 3.4838e-03, PNorm = 57.3883, GNorm = 3.0384, lr_0 = 2.7208e-04
Loss = 3.6533e-03, PNorm = 57.3953, GNorm = 2.3584, lr_0 = 2.7171e-04
Loss = 3.7923e-03, PNorm = 57.4039, GNorm = 3.0123, lr_0 = 2.7135e-04
Loss = 2.6152e-03, PNorm = 57.4115, GNorm = 2.0338, lr_0 = 2.7098e-04
Loss = 3.4219e-03, PNorm = 57.4184, GNorm = 1.7172, lr_0 = 2.7062e-04
Loss = 4.4679e-03, PNorm = 57.4244, GNorm = 4.0534, lr_0 = 2.7026e-04
Loss = 3.3313e-03, PNorm = 57.4321, GNorm = 3.1881, lr_0 = 2.6990e-04
Loss = 1.1587e-02, PNorm = 57.4327, GNorm = 3.7062, lr_0 = 2.6986e-04
Validation rmse = 3.826570
Validation R2 = -3.063160
Epoch 43
Train function
Loss = 2.8816e-03, PNorm = 57.4398, GNorm = 4.1903, lr_0 = 2.6950e-04
Loss = 2.8044e-03, PNorm = 57.4478, GNorm = 3.8029, lr_0 = 2.6914e-04
Loss = 3.2741e-03, PNorm = 57.4546, GNorm = 2.9995, lr_0 = 2.6877e-04
Loss = 3.5219e-03, PNorm = 57.4609, GNorm = 2.4602, lr_0 = 2.6841e-04
Loss = 2.6105e-03, PNorm = 57.4689, GNorm = 1.9906, lr_0 = 2.6805e-04
Loss = 2.6184e-03, PNorm = 57.4770, GNorm = 2.3942, lr_0 = 2.6769e-04
Loss = 2.5797e-03, PNorm = 57.4832, GNorm = 3.2435, lr_0 = 2.6733e-04
Loss = 3.6864e-03, PNorm = 57.4896, GNorm = 2.4456, lr_0 = 2.6698e-04
Loss = 3.8712e-03, PNorm = 57.4985, GNorm = 2.3619, lr_0 = 2.6662e-04
Loss = 3.6489e-03, PNorm = 57.5071, GNorm = 3.3841, lr_0 = 2.6626e-04
Loss = 3.1960e-03, PNorm = 57.5165, GNorm = 2.2412, lr_0 = 2.6590e-04
Loss = 3.3564e-03, PNorm = 57.5255, GNorm = 2.5016, lr_0 = 2.6555e-04
Loss = 3.1568e-03, PNorm = 57.5316, GNorm = 3.8579, lr_0 = 2.6519e-04
Loss = 4.1763e-03, PNorm = 57.5388, GNorm = 4.1417, lr_0 = 2.6483e-04
Loss = 3.2967e-03, PNorm = 57.5464, GNorm = 1.9817, lr_0 = 2.6448e-04
Loss = 4.1587e-03, PNorm = 57.5528, GNorm = 3.1754, lr_0 = 2.6412e-04
Loss = 3.8672e-03, PNorm = 57.5613, GNorm = 2.7063, lr_0 = 2.6377e-04
Loss = 2.4612e-03, PNorm = 57.5698, GNorm = 1.5960, lr_0 = 2.6342e-04
Loss = 3.9459e-03, PNorm = 57.5792, GNorm = 3.2334, lr_0 = 2.6306e-04
Loss = 2.8333e-03, PNorm = 57.5864, GNorm = 3.3583, lr_0 = 2.6271e-04
Loss = 3.3014e-03, PNorm = 57.5933, GNorm = 3.2786, lr_0 = 2.6236e-04
Loss = 2.8031e-03, PNorm = 57.6014, GNorm = 1.7861, lr_0 = 2.6200e-04
Loss = 4.6286e-03, PNorm = 57.6079, GNorm = 6.4455, lr_0 = 2.6165e-04
Validation rmse = 3.630679
Validation R2 = -2.657803
Epoch 44
Train function
Loss = 2.4457e-03, PNorm = 57.6152, GNorm = 1.9654, lr_0 = 2.6127e-04
Loss = 2.8775e-03, PNorm = 57.6230, GNorm = 3.5836, lr_0 = 2.6092e-04
Loss = 3.3949e-03, PNorm = 57.6296, GNorm = 2.7267, lr_0 = 2.6057e-04
Loss = 2.5565e-03, PNorm = 57.6380, GNorm = 2.9748, lr_0 = 2.6022e-04
Loss = 2.4821e-03, PNorm = 57.6439, GNorm = 3.2359, lr_0 = 2.5987e-04
Loss = 3.1081e-03, PNorm = 57.6502, GNorm = 2.4392, lr_0 = 2.5952e-04
Loss = 2.6837e-03, PNorm = 57.6558, GNorm = 1.6151, lr_0 = 2.5917e-04
Loss = 3.1517e-03, PNorm = 57.6623, GNorm = 1.4574, lr_0 = 2.5882e-04
Loss = 2.9800e-03, PNorm = 57.6694, GNorm = 2.7519, lr_0 = 2.5848e-04
Loss = 3.3142e-03, PNorm = 57.6751, GNorm = 2.4554, lr_0 = 2.5813e-04
Loss = 2.4626e-03, PNorm = 57.6819, GNorm = 1.3953, lr_0 = 2.5778e-04
Loss = 3.0681e-03, PNorm = 57.6894, GNorm = 2.3935, lr_0 = 2.5744e-04
Loss = 2.8227e-03, PNorm = 57.6965, GNorm = 2.2694, lr_0 = 2.5709e-04
Loss = 3.0615e-03, PNorm = 57.7058, GNorm = 2.4983, lr_0 = 2.5675e-04
Loss = 2.3513e-03, PNorm = 57.7140, GNorm = 1.1527, lr_0 = 2.5640e-04
Loss = 3.4103e-03, PNorm = 57.7201, GNorm = 1.6299, lr_0 = 2.5606e-04
Loss = 2.8887e-03, PNorm = 57.7277, GNorm = 2.4179, lr_0 = 2.5571e-04
Loss = 3.4347e-03, PNorm = 57.7352, GNorm = 1.5764, lr_0 = 2.5537e-04
Loss = 2.6575e-03, PNorm = 57.7411, GNorm = 3.6522, lr_0 = 2.5503e-04
Loss = 3.2127e-03, PNorm = 57.7464, GNorm = 2.7586, lr_0 = 2.5469e-04
Loss = 2.9531e-03, PNorm = 57.7536, GNorm = 3.6375, lr_0 = 2.5434e-04
Loss = 3.7249e-03, PNorm = 57.7598, GNorm = 3.7172, lr_0 = 2.5400e-04
Loss = 3.7453e-03, PNorm = 57.7658, GNorm = 2.0586, lr_0 = 2.5366e-04
Validation rmse = 3.618100
Validation R2 = -2.632501
Epoch 45
Train function
Loss = 1.9601e-03, PNorm = 57.7732, GNorm = 1.5756, lr_0 = 2.5332e-04
Loss = 2.5564e-03, PNorm = 57.7821, GNorm = 2.5479, lr_0 = 2.5298e-04
Loss = 2.7055e-03, PNorm = 57.7908, GNorm = 1.8248, lr_0 = 2.5264e-04
Loss = 2.7806e-03, PNorm = 57.7976, GNorm = 2.6433, lr_0 = 2.5230e-04
Loss = 3.5621e-03, PNorm = 57.8055, GNorm = 1.9691, lr_0 = 2.5197e-04
Loss = 2.6377e-03, PNorm = 57.8128, GNorm = 1.5745, lr_0 = 2.5163e-04
Loss = 2.7672e-03, PNorm = 57.8219, GNorm = 2.9874, lr_0 = 2.5129e-04
Loss = 2.6961e-03, PNorm = 57.8304, GNorm = 1.9321, lr_0 = 2.5095e-04
Loss = 2.4856e-03, PNorm = 57.8367, GNorm = 1.6230, lr_0 = 2.5062e-04
Loss = 2.8859e-03, PNorm = 57.8429, GNorm = 2.2891, lr_0 = 2.5028e-04
Loss = 2.9741e-03, PNorm = 57.8498, GNorm = 3.8758, lr_0 = 2.4994e-04
Loss = 3.0538e-03, PNorm = 57.8562, GNorm = 3.6108, lr_0 = 2.4961e-04
Loss = 3.3201e-03, PNorm = 57.8625, GNorm = 2.3016, lr_0 = 2.4927e-04
Loss = 2.8494e-03, PNorm = 57.8681, GNorm = 2.5229, lr_0 = 2.4894e-04
Loss = 2.9984e-03, PNorm = 57.8741, GNorm = 2.2184, lr_0 = 2.4861e-04
Loss = 2.7105e-03, PNorm = 57.8812, GNorm = 2.3504, lr_0 = 2.4827e-04
Loss = 2.3415e-03, PNorm = 57.8884, GNorm = 2.1845, lr_0 = 2.4794e-04
Loss = 3.8150e-03, PNorm = 57.8970, GNorm = 3.3194, lr_0 = 2.4761e-04
Loss = 2.3781e-03, PNorm = 57.9033, GNorm = 1.6143, lr_0 = 2.4727e-04
Loss = 2.5609e-03, PNorm = 57.9086, GNorm = 1.6971, lr_0 = 2.4694e-04
Loss = 2.6391e-03, PNorm = 57.9148, GNorm = 2.0904, lr_0 = 2.4661e-04
Loss = 2.6857e-03, PNorm = 57.9207, GNorm = 1.5691, lr_0 = 2.4628e-04
Loss = 2.4999e-03, PNorm = 57.9242, GNorm = 2.2091, lr_0 = 2.4595e-04
Loss = 3.9030e-03, PNorm = 57.9276, GNorm = 2.4756, lr_0 = 2.4562e-04
Validation rmse = 4.108295
Validation R2 = -3.683470
Epoch 46
Train function
Loss = 2.9642e-03, PNorm = 57.9351, GNorm = 4.4156, lr_0 = 2.4526e-04
Loss = 2.0912e-03, PNorm = 57.9430, GNorm = 3.7056, lr_0 = 2.4493e-04
Loss = 2.4820e-03, PNorm = 57.9498, GNorm = 2.1317, lr_0 = 2.4460e-04
Loss = 2.2243e-03, PNorm = 57.9555, GNorm = 2.6437, lr_0 = 2.4427e-04
Loss = 2.2957e-03, PNorm = 57.9616, GNorm = 2.5101, lr_0 = 2.4394e-04
Loss = 2.5687e-03, PNorm = 57.9685, GNorm = 3.8442, lr_0 = 2.4362e-04
Loss = 2.9041e-03, PNorm = 57.9761, GNorm = 1.6000, lr_0 = 2.4329e-04
Loss = 2.3988e-03, PNorm = 57.9836, GNorm = 1.9081, lr_0 = 2.4296e-04
Loss = 3.0556e-03, PNorm = 57.9882, GNorm = 3.7056, lr_0 = 2.4264e-04
Loss = 2.1980e-03, PNorm = 57.9939, GNorm = 1.6507, lr_0 = 2.4231e-04
Loss = 2.6339e-03, PNorm = 57.9989, GNorm = 1.9049, lr_0 = 2.4199e-04
Loss = 2.3247e-03, PNorm = 58.0043, GNorm = 2.1017, lr_0 = 2.4166e-04
Loss = 2.6386e-03, PNorm = 58.0101, GNorm = 2.3251, lr_0 = 2.4134e-04
Loss = 2.7172e-03, PNorm = 58.0158, GNorm = 3.2312, lr_0 = 2.4101e-04
Loss = 2.4392e-03, PNorm = 58.0234, GNorm = 3.3776, lr_0 = 2.4069e-04
Loss = 3.7165e-03, PNorm = 58.0284, GNorm = 2.5952, lr_0 = 2.4037e-04
Loss = 3.0646e-03, PNorm = 58.0322, GNorm = 3.4306, lr_0 = 2.4004e-04
Loss = 3.0540e-03, PNorm = 58.0394, GNorm = 3.5651, lr_0 = 2.3972e-04
Loss = 2.8941e-03, PNorm = 58.0457, GNorm = 3.5188, lr_0 = 2.3940e-04
Loss = 2.4192e-03, PNorm = 58.0527, GNorm = 1.9897, lr_0 = 2.3908e-04
Loss = 2.9916e-03, PNorm = 58.0581, GNorm = 1.9903, lr_0 = 2.3876e-04
Loss = 2.2976e-03, PNorm = 58.0626, GNorm = 2.1811, lr_0 = 2.3844e-04
Loss = 3.0048e-03, PNorm = 58.0683, GNorm = 3.9293, lr_0 = 2.3812e-04
Validation rmse = 3.722806
Validation R2 = -2.845789
Epoch 47
Train function
Loss = 2.0493e-03, PNorm = 58.0756, GNorm = 2.0471, lr_0 = 2.3777e-04
Loss = 2.5626e-03, PNorm = 58.0810, GNorm = 1.6199, lr_0 = 2.3745e-04
Loss = 2.6872e-03, PNorm = 58.0862, GNorm = 2.3109, lr_0 = 2.3713e-04
Loss = 2.3047e-03, PNorm = 58.0932, GNorm = 2.2580, lr_0 = 2.3681e-04
Loss = 2.5898e-03, PNorm = 58.0997, GNorm = 2.4379, lr_0 = 2.3649e-04
Loss = 2.0459e-03, PNorm = 58.1084, GNorm = 1.7848, lr_0 = 2.3618e-04
Loss = 2.7220e-03, PNorm = 58.1153, GNorm = 1.4436, lr_0 = 2.3586e-04
Loss = 2.2153e-03, PNorm = 58.1207, GNorm = 1.7729, lr_0 = 2.3554e-04
Loss = 2.8081e-03, PNorm = 58.1258, GNorm = 3.1948, lr_0 = 2.3523e-04
Loss = 2.2117e-03, PNorm = 58.1312, GNorm = 2.5930, lr_0 = 2.3491e-04
Loss = 2.8852e-03, PNorm = 58.1361, GNorm = 4.8620, lr_0 = 2.3460e-04
Loss = 1.9793e-03, PNorm = 58.1414, GNorm = 1.5900, lr_0 = 2.3428e-04
Loss = 1.9479e-03, PNorm = 58.1464, GNorm = 1.8641, lr_0 = 2.3397e-04
Loss = 2.4496e-03, PNorm = 58.1522, GNorm = 2.4598, lr_0 = 2.3365e-04
Loss = 2.4251e-03, PNorm = 58.1571, GNorm = 2.4222, lr_0 = 2.3334e-04
Loss = 2.8011e-03, PNorm = 58.1628, GNorm = 4.5345, lr_0 = 2.3303e-04
Loss = 2.2614e-03, PNorm = 58.1681, GNorm = 3.1087, lr_0 = 2.3271e-04
Loss = 2.6124e-03, PNorm = 58.1742, GNorm = 1.8726, lr_0 = 2.3240e-04
Loss = 2.3019e-03, PNorm = 58.1789, GNorm = 2.1247, lr_0 = 2.3209e-04
Loss = 2.2572e-03, PNorm = 58.1837, GNorm = 2.0766, lr_0 = 2.3178e-04
Loss = 2.8314e-03, PNorm = 58.1891, GNorm = 1.8502, lr_0 = 2.3147e-04
Loss = 2.5839e-03, PNorm = 58.1958, GNorm = 2.1922, lr_0 = 2.3116e-04
Loss = 2.8274e-03, PNorm = 58.2005, GNorm = 5.5847, lr_0 = 2.3085e-04
Loss = 3.4610e-03, PNorm = 58.2047, GNorm = 2.1782, lr_0 = 2.3054e-04
Validation rmse = 3.928768
Validation R2 = -3.283090
Epoch 48
Train function
Loss = 2.3303e-03, PNorm = 58.2106, GNorm = 3.1984, lr_0 = 2.3020e-04
Loss = 2.0379e-03, PNorm = 58.2179, GNorm = 2.4359, lr_0 = 2.2989e-04
Loss = 1.9114e-03, PNorm = 58.2236, GNorm = 2.1307, lr_0 = 2.2958e-04
Loss = 2.8900e-03, PNorm = 58.2297, GNorm = 2.6022, lr_0 = 2.2927e-04
Loss = 2.6304e-03, PNorm = 58.2346, GNorm = 2.2628, lr_0 = 2.2896e-04
Loss = 2.4567e-03, PNorm = 58.2404, GNorm = 2.3513, lr_0 = 2.2866e-04
Loss = 2.4333e-03, PNorm = 58.2468, GNorm = 3.6252, lr_0 = 2.2835e-04
Loss = 2.4645e-03, PNorm = 58.2518, GNorm = 3.2938, lr_0 = 2.2804e-04
Loss = 2.4269e-03, PNorm = 58.2569, GNorm = 2.3331, lr_0 = 2.2774e-04
Loss = 1.8113e-03, PNorm = 58.2627, GNorm = 2.4194, lr_0 = 2.2743e-04
Loss = 2.2893e-03, PNorm = 58.2687, GNorm = 4.1247, lr_0 = 2.2713e-04
Loss = 2.4788e-03, PNorm = 58.2741, GNorm = 1.9929, lr_0 = 2.2682e-04
Loss = 2.9847e-03, PNorm = 58.2786, GNorm = 3.4820, lr_0 = 2.2652e-04
Loss = 2.3756e-03, PNorm = 58.2828, GNorm = 2.5329, lr_0 = 2.2621e-04
Loss = 2.4069e-03, PNorm = 58.2882, GNorm = 1.9213, lr_0 = 2.2591e-04
Loss = 2.4143e-03, PNorm = 58.2931, GNorm = 2.3969, lr_0 = 2.2561e-04
Loss = 2.4186e-03, PNorm = 58.2965, GNorm = 2.4330, lr_0 = 2.2530e-04
Loss = 2.2245e-03, PNorm = 58.3029, GNorm = 2.5517, lr_0 = 2.2500e-04
Loss = 2.6121e-03, PNorm = 58.3097, GNorm = 2.4554, lr_0 = 2.2470e-04
Loss = 2.2363e-03, PNorm = 58.3163, GNorm = 2.7343, lr_0 = 2.2440e-04
Loss = 1.8695e-03, PNorm = 58.3220, GNorm = 2.4147, lr_0 = 2.2410e-04
Loss = 2.2295e-03, PNorm = 58.3276, GNorm = 1.6654, lr_0 = 2.2380e-04
Loss = 2.6092e-03, PNorm = 58.3320, GNorm = 2.6083, lr_0 = 2.2350e-04
Validation rmse = 3.951892
Validation R2 = -3.333659
Epoch 49
Train function
Loss = 2.5385e-03, PNorm = 58.3375, GNorm = 2.9001, lr_0 = 2.2317e-04
Loss = 2.3568e-03, PNorm = 58.3432, GNorm = 2.3403, lr_0 = 2.2287e-04
Loss = 2.1777e-03, PNorm = 58.3474, GNorm = 2.7281, lr_0 = 2.2257e-04
Loss = 2.7909e-03, PNorm = 58.3533, GNorm = 1.5850, lr_0 = 2.2227e-04
Loss = 2.1242e-03, PNorm = 58.3594, GNorm = 2.8777, lr_0 = 2.2197e-04
Loss = 1.6229e-03, PNorm = 58.3656, GNorm = 2.2902, lr_0 = 2.2167e-04
Loss = 1.8720e-03, PNorm = 58.3704, GNorm = 2.4271, lr_0 = 2.2138e-04
Loss = 1.8354e-03, PNorm = 58.3761, GNorm = 2.2434, lr_0 = 2.2108e-04
Loss = 2.2760e-03, PNorm = 58.3828, GNorm = 3.1288, lr_0 = 2.2078e-04
Loss = 2.6342e-03, PNorm = 58.3881, GNorm = 1.9355, lr_0 = 2.2049e-04
Loss = 2.4387e-03, PNorm = 58.3915, GNorm = 2.7801, lr_0 = 2.2019e-04
Loss = 2.5001e-03, PNorm = 58.3953, GNorm = 2.6387, lr_0 = 2.1990e-04
Loss = 2.1532e-03, PNorm = 58.3982, GNorm = 1.6113, lr_0 = 2.1960e-04
Loss = 2.2450e-03, PNorm = 58.4043, GNorm = 2.6432, lr_0 = 2.1931e-04
Loss = 2.2443e-03, PNorm = 58.4108, GNorm = 2.5526, lr_0 = 2.1901e-04
Loss = 2.7746e-03, PNorm = 58.4170, GNorm = 2.0864, lr_0 = 2.1872e-04
Loss = 1.8709e-03, PNorm = 58.4222, GNorm = 2.2085, lr_0 = 2.1842e-04
Loss = 1.9726e-03, PNorm = 58.4277, GNorm = 2.5528, lr_0 = 2.1813e-04
Loss = 2.7570e-03, PNorm = 58.4330, GNorm = 2.3143, lr_0 = 2.1784e-04
Loss = 2.6659e-03, PNorm = 58.4390, GNorm = 2.3588, lr_0 = 2.1755e-04
Loss = 3.5891e-03, PNorm = 58.4456, GNorm = 2.8798, lr_0 = 2.1725e-04
Loss = 1.9971e-03, PNorm = 58.4513, GNorm = 2.4093, lr_0 = 2.1696e-04
Loss = 2.6650e-03, PNorm = 58.4567, GNorm = 1.9568, lr_0 = 2.1667e-04
Loss = 2.6233e-03, PNorm = 58.4614, GNorm = 4.3537, lr_0 = 2.1638e-04
Validation rmse = 3.939070
Validation R2 = -3.305584
Epoch 50
Train function
Loss = 2.1116e-03, PNorm = 58.4656, GNorm = 1.2517, lr_0 = 2.1609e-04
Loss = 2.1806e-03, PNorm = 58.4697, GNorm = 1.5317, lr_0 = 2.1580e-04
Loss = 2.0669e-03, PNorm = 58.4736, GNorm = 1.7722, lr_0 = 2.1551e-04
Loss = 2.1749e-03, PNorm = 58.4786, GNorm = 2.1963, lr_0 = 2.1522e-04
Loss = 1.8493e-03, PNorm = 58.4842, GNorm = 2.2313, lr_0 = 2.1493e-04
Loss = 2.2242e-03, PNorm = 58.4913, GNorm = 2.6322, lr_0 = 2.1464e-04
Loss = 2.0225e-03, PNorm = 58.4967, GNorm = 2.4003, lr_0 = 2.1436e-04
Loss = 2.0215e-03, PNorm = 58.5007, GNorm = 1.5965, lr_0 = 2.1407e-04
Loss = 1.6506e-03, PNorm = 58.5058, GNorm = 1.7053, lr_0 = 2.1378e-04
Loss = 2.6397e-03, PNorm = 58.5118, GNorm = 2.3856, lr_0 = 2.1350e-04
Loss = 2.2327e-03, PNorm = 58.5164, GNorm = 2.1303, lr_0 = 2.1321e-04
Loss = 1.8685e-03, PNorm = 58.5216, GNorm = 1.9888, lr_0 = 2.1292e-04
Loss = 1.6101e-03, PNorm = 58.5265, GNorm = 1.4827, lr_0 = 2.1264e-04
Loss = 1.9074e-03, PNorm = 58.5313, GNorm = 2.5517, lr_0 = 2.1235e-04
Loss = 2.1331e-03, PNorm = 58.5358, GNorm = 2.4608, lr_0 = 2.1207e-04
Loss = 2.2124e-03, PNorm = 58.5418, GNorm = 1.9421, lr_0 = 2.1178e-04
Loss = 2.0919e-03, PNorm = 58.5479, GNorm = 1.9723, lr_0 = 2.1150e-04
Loss = 2.0638e-03, PNorm = 58.5510, GNorm = 2.0309, lr_0 = 2.1121e-04
Loss = 2.9273e-03, PNorm = 58.5561, GNorm = 3.2613, lr_0 = 2.1093e-04
Loss = 2.2842e-03, PNorm = 58.5609, GNorm = 1.7229, lr_0 = 2.1065e-04
Loss = 2.4545e-03, PNorm = 58.5666, GNorm = 2.4292, lr_0 = 2.1037e-04
Loss = 1.8799e-03, PNorm = 58.5710, GNorm = 1.8240, lr_0 = 2.1008e-04
Loss = 2.2000e-03, PNorm = 58.5748, GNorm = 2.2911, lr_0 = 2.0980e-04
Validation rmse = 4.148920
Validation R2 = -3.776554
Epoch 51
Train function
Loss = 1.4528e-03, PNorm = 58.5791, GNorm = 1.8101, lr_0 = 2.0949e-04
Loss = 2.2399e-03, PNorm = 58.5835, GNorm = 2.8878, lr_0 = 2.0921e-04
Loss = 2.1653e-03, PNorm = 58.5885, GNorm = 1.5334, lr_0 = 2.0893e-04
Loss = 1.6212e-03, PNorm = 58.5941, GNorm = 1.9739, lr_0 = 2.0865e-04
Loss = 1.8437e-03, PNorm = 58.5979, GNorm = 2.5078, lr_0 = 2.0837e-04
Loss = 1.9925e-03, PNorm = 58.6005, GNorm = 3.8672, lr_0 = 2.0809e-04
Loss = 1.5141e-03, PNorm = 58.6058, GNorm = 1.5521, lr_0 = 2.0781e-04
Loss = 1.7339e-03, PNorm = 58.6101, GNorm = 2.0718, lr_0 = 2.0753e-04
Loss = 1.4916e-03, PNorm = 58.6145, GNorm = 1.8163, lr_0 = 2.0725e-04
Loss = 1.8917e-03, PNorm = 58.6205, GNorm = 1.7177, lr_0 = 2.0698e-04
Loss = 1.7484e-03, PNorm = 58.6257, GNorm = 2.0924, lr_0 = 2.0670e-04
Loss = 1.7388e-03, PNorm = 58.6305, GNorm = 1.4830, lr_0 = 2.0642e-04
Loss = 2.1617e-03, PNorm = 58.6346, GNorm = 2.8439, lr_0 = 2.0614e-04
Loss = 2.4715e-03, PNorm = 58.6379, GNorm = 2.3641, lr_0 = 2.0587e-04
Loss = 2.5201e-03, PNorm = 58.6412, GNorm = 2.4876, lr_0 = 2.0559e-04
Loss = 2.1335e-03, PNorm = 58.6454, GNorm = 1.3463, lr_0 = 2.0531e-04
Loss = 2.2082e-03, PNorm = 58.6511, GNorm = 1.1524, lr_0 = 2.0504e-04
Loss = 2.1636e-03, PNorm = 58.6564, GNorm = 2.1679, lr_0 = 2.0476e-04
Loss = 1.7628e-03, PNorm = 58.6614, GNorm = 1.6247, lr_0 = 2.0449e-04
Loss = 1.8812e-03, PNorm = 58.6661, GNorm = 2.4628, lr_0 = 2.0421e-04
Loss = 1.7961e-03, PNorm = 58.6707, GNorm = 2.0031, lr_0 = 2.0394e-04
Loss = 2.0825e-03, PNorm = 58.6738, GNorm = 1.4848, lr_0 = 2.0367e-04
Loss = 2.5896e-03, PNorm = 58.6781, GNorm = 2.4984, lr_0 = 2.0339e-04
Validation rmse = 3.909008
Validation R2 = -3.240116
Epoch 52
Train function
Loss = 1.8404e-03, PNorm = 58.6843, GNorm = 2.1482, lr_0 = 2.0309e-04
Loss = 2.5003e-03, PNorm = 58.6902, GNorm = 2.0471, lr_0 = 2.0282e-04
Loss = 1.6592e-03, PNorm = 58.6937, GNorm = 1.9007, lr_0 = 2.0255e-04
Loss = 1.6332e-03, PNorm = 58.6976, GNorm = 3.1299, lr_0 = 2.0228e-04
Loss = 2.0494e-03, PNorm = 58.7006, GNorm = 2.5787, lr_0 = 2.0201e-04
Loss = 1.8136e-03, PNorm = 58.7038, GNorm = 2.0645, lr_0 = 2.0174e-04
Loss = 1.4558e-03, PNorm = 58.7072, GNorm = 1.4516, lr_0 = 2.0146e-04
Loss = 1.7738e-03, PNorm = 58.7104, GNorm = 2.1051, lr_0 = 2.0119e-04
Loss = 1.8060e-03, PNorm = 58.7160, GNorm = 1.2300, lr_0 = 2.0092e-04
Loss = 2.1456e-03, PNorm = 58.7202, GNorm = 2.6103, lr_0 = 2.0065e-04
Loss = 1.9398e-03, PNorm = 58.7252, GNorm = 2.7152, lr_0 = 2.0039e-04
Loss = 1.8869e-03, PNorm = 58.7299, GNorm = 1.5057, lr_0 = 2.0012e-04
Loss = 2.1929e-03, PNorm = 58.7335, GNorm = 2.5863, lr_0 = 1.9985e-04
Loss = 1.6938e-03, PNorm = 58.7383, GNorm = 1.0843, lr_0 = 1.9958e-04
Loss = 1.7851e-03, PNorm = 58.7424, GNorm = 2.1873, lr_0 = 1.9931e-04
Loss = 2.1769e-03, PNorm = 58.7470, GNorm = 1.8602, lr_0 = 1.9904e-04
Loss = 1.7524e-03, PNorm = 58.7507, GNorm = 1.9487, lr_0 = 1.9878e-04
Loss = 1.5120e-03, PNorm = 58.7545, GNorm = 2.3045, lr_0 = 1.9851e-04
Loss = 1.5998e-03, PNorm = 58.7594, GNorm = 3.8356, lr_0 = 1.9824e-04
Loss = 1.9567e-03, PNorm = 58.7626, GNorm = 2.1329, lr_0 = 1.9798e-04
Loss = 2.5141e-03, PNorm = 58.7661, GNorm = 3.1094, lr_0 = 1.9771e-04
Loss = 2.1181e-03, PNorm = 58.7710, GNorm = 2.1033, lr_0 = 1.9745e-04
Loss = 1.8331e-03, PNorm = 58.7777, GNorm = 2.1210, lr_0 = 1.9718e-04
Loss = 1.7109e-03, PNorm = 58.7839, GNorm = 2.0013, lr_0 = 1.9692e-04
Validation rmse = 4.166163
Validation R2 = -3.816340
Epoch 53
Train function
Loss = 1.8607e-03, PNorm = 58.7887, GNorm = 1.9779, lr_0 = 1.9663e-04
Loss = 2.2060e-03, PNorm = 58.7936, GNorm = 2.6124, lr_0 = 1.9636e-04
Loss = 1.6854e-03, PNorm = 58.7989, GNorm = 1.4443, lr_0 = 1.9610e-04
Loss = 1.9747e-03, PNorm = 58.8023, GNorm = 1.5134, lr_0 = 1.9584e-04
Loss = 1.7624e-03, PNorm = 58.8055, GNorm = 1.1261, lr_0 = 1.9557e-04
Loss = 1.6675e-03, PNorm = 58.8102, GNorm = 2.6286, lr_0 = 1.9531e-04
Loss = 1.7623e-03, PNorm = 58.8151, GNorm = 2.5570, lr_0 = 1.9505e-04
Loss = 1.4413e-03, PNorm = 58.8183, GNorm = 1.8298, lr_0 = 1.9479e-04
Loss = 1.7708e-03, PNorm = 58.8219, GNorm = 1.3881, lr_0 = 1.9453e-04
Loss = 1.5524e-03, PNorm = 58.8259, GNorm = 1.4913, lr_0 = 1.9427e-04
Loss = 1.8139e-03, PNorm = 58.8304, GNorm = 1.3337, lr_0 = 1.9401e-04
Loss = 1.6623e-03, PNorm = 58.8351, GNorm = 2.9807, lr_0 = 1.9374e-04
Loss = 2.4023e-03, PNorm = 58.8401, GNorm = 2.4868, lr_0 = 1.9348e-04
Loss = 2.0393e-03, PNorm = 58.8439, GNorm = 1.5714, lr_0 = 1.9323e-04
Loss = 1.6509e-03, PNorm = 58.8461, GNorm = 2.3947, lr_0 = 1.9297e-04
Loss = 1.6019e-03, PNorm = 58.8504, GNorm = 1.7435, lr_0 = 1.9271e-04
Loss = 2.3432e-03, PNorm = 58.8545, GNorm = 2.4513, lr_0 = 1.9245e-04
Loss = 1.5763e-03, PNorm = 58.8565, GNorm = 2.5980, lr_0 = 1.9219e-04
Loss = 1.3956e-03, PNorm = 58.8595, GNorm = 1.5973, lr_0 = 1.9193e-04
Loss = 1.1967e-03, PNorm = 58.8626, GNorm = 2.0250, lr_0 = 1.9168e-04
Loss = 1.7774e-03, PNorm = 58.8661, GNorm = 1.5772, lr_0 = 1.9142e-04
Loss = 1.6997e-03, PNorm = 58.8697, GNorm = 1.8183, lr_0 = 1.9116e-04
Loss = 1.5155e-03, PNorm = 58.8747, GNorm = 1.2662, lr_0 = 1.9090e-04
Validation rmse = 3.994298
Validation R2 = -3.427162
Epoch 54
Train function
Loss = 1.2282e-03, PNorm = 58.8794, GNorm = 1.5278, lr_0 = 1.9062e-04
Loss = 1.0496e-03, PNorm = 58.8834, GNorm = 1.7559, lr_0 = 1.9037e-04
Loss = 2.0974e-03, PNorm = 58.8874, GNorm = 1.7654, lr_0 = 1.9011e-04
Loss = 1.6771e-03, PNorm = 58.8918, GNorm = 2.6602, lr_0 = 1.8986e-04
Loss = 1.3616e-03, PNorm = 58.8970, GNorm = 1.4519, lr_0 = 1.8960e-04
Loss = 1.1247e-03, PNorm = 58.9003, GNorm = 1.6345, lr_0 = 1.8935e-04
Loss = 1.7745e-03, PNorm = 58.9051, GNorm = 1.2263, lr_0 = 1.8909e-04
Loss = 2.0882e-03, PNorm = 58.9093, GNorm = 2.3381, lr_0 = 1.8884e-04
Loss = 1.6775e-03, PNorm = 58.9137, GNorm = 1.5438, lr_0 = 1.8859e-04
Loss = 1.5073e-03, PNorm = 58.9179, GNorm = 2.2652, lr_0 = 1.8833e-04
Loss = 1.7536e-03, PNorm = 58.9220, GNorm = 1.4793, lr_0 = 1.8808e-04
Loss = 1.5376e-03, PNorm = 58.9255, GNorm = 2.0627, lr_0 = 1.8783e-04
Loss = 1.8288e-03, PNorm = 58.9287, GNorm = 1.8127, lr_0 = 1.8758e-04
Loss = 1.7776e-03, PNorm = 58.9326, GNorm = 1.5017, lr_0 = 1.8732e-04
Loss = 2.3199e-03, PNorm = 58.9370, GNorm = 3.4612, lr_0 = 1.8707e-04
Loss = 1.3066e-03, PNorm = 58.9427, GNorm = 2.0127, lr_0 = 1.8682e-04
Loss = 1.9205e-03, PNorm = 58.9462, GNorm = 2.6946, lr_0 = 1.8657e-04
Loss = 1.4856e-03, PNorm = 58.9483, GNorm = 2.1840, lr_0 = 1.8632e-04
Loss = 1.8307e-03, PNorm = 58.9515, GNorm = 2.2072, lr_0 = 1.8607e-04
Loss = 1.6873e-03, PNorm = 58.9545, GNorm = 1.3132, lr_0 = 1.8582e-04
Loss = 1.2693e-03, PNorm = 58.9566, GNorm = 1.4925, lr_0 = 1.8557e-04
Loss = 1.3900e-03, PNorm = 58.9581, GNorm = 1.8944, lr_0 = 1.8532e-04
Loss = 1.5809e-03, PNorm = 58.9614, GNorm = 2.0085, lr_0 = 1.8507e-04
Loss = 1.7565e-03, PNorm = 58.9647, GNorm = 2.4856, lr_0 = 1.8483e-04
Validation rmse = 4.080463
Validation R2 = -3.620227
Epoch 55
Train function
Loss = 1.0253e-03, PNorm = 58.9678, GNorm = 1.2305, lr_0 = 1.8458e-04
Loss = 1.3951e-03, PNorm = 58.9722, GNorm = 1.4851, lr_0 = 1.8433e-04
Loss = 1.3391e-03, PNorm = 58.9756, GNorm = 1.2906, lr_0 = 1.8408e-04
Loss = 1.4295e-03, PNorm = 58.9802, GNorm = 1.6320, lr_0 = 1.8384e-04
Loss = 1.5532e-03, PNorm = 58.9852, GNorm = 1.8472, lr_0 = 1.8359e-04
Loss = 1.0587e-03, PNorm = 58.9888, GNorm = 1.3180, lr_0 = 1.8334e-04
Loss = 1.7170e-03, PNorm = 58.9924, GNorm = 0.9762, lr_0 = 1.8310e-04
Loss = 1.6568e-03, PNorm = 58.9958, GNorm = 1.6292, lr_0 = 1.8285e-04
Loss = 1.3113e-03, PNorm = 58.9983, GNorm = 1.6500, lr_0 = 1.8261e-04
Loss = 1.2134e-03, PNorm = 58.9997, GNorm = 1.9291, lr_0 = 1.8236e-04
Loss = 1.4480e-03, PNorm = 59.0020, GNorm = 1.9717, lr_0 = 1.8212e-04
Loss = 1.4517e-03, PNorm = 59.0057, GNorm = 1.5502, lr_0 = 1.8187e-04
Loss = 1.5709e-03, PNorm = 59.0095, GNorm = 1.3923, lr_0 = 1.8163e-04
Loss = 1.4857e-03, PNorm = 59.0116, GNorm = 1.4114, lr_0 = 1.8138e-04
Loss = 1.5996e-03, PNorm = 59.0150, GNorm = 2.0619, lr_0 = 1.8114e-04
Loss = 1.8968e-03, PNorm = 59.0183, GNorm = 1.9324, lr_0 = 1.8090e-04
Loss = 1.6191e-03, PNorm = 59.0217, GNorm = 1.7108, lr_0 = 1.8066e-04
Loss = 1.8822e-03, PNorm = 59.0250, GNorm = 1.4111, lr_0 = 1.8041e-04
Loss = 1.0886e-03, PNorm = 59.0285, GNorm = 0.8666, lr_0 = 1.8017e-04
Loss = 1.3539e-03, PNorm = 59.0315, GNorm = 1.4220, lr_0 = 1.7993e-04
Loss = 1.4568e-03, PNorm = 59.0341, GNorm = 1.7583, lr_0 = 1.7969e-04
Loss = 1.8521e-03, PNorm = 59.0389, GNorm = 2.0603, lr_0 = 1.7945e-04
Loss = 1.8442e-03, PNorm = 59.0433, GNorm = 3.5225, lr_0 = 1.7921e-04
Validation rmse = 4.022518
Validation R2 = -3.489940
Epoch 56
Train function
Loss = 1.5186e-03, PNorm = 59.0485, GNorm = 1.7724, lr_0 = 1.7894e-04
Loss = 1.2283e-03, PNorm = 59.0534, GNorm = 2.6872, lr_0 = 1.7870e-04
Loss = 1.3455e-03, PNorm = 59.0581, GNorm = 1.4102, lr_0 = 1.7846e-04
Loss = 1.3304e-03, PNorm = 59.0617, GNorm = 1.5475, lr_0 = 1.7822e-04
Loss = 1.1710e-03, PNorm = 59.0657, GNorm = 1.1499, lr_0 = 1.7798e-04
Loss = 1.5026e-03, PNorm = 59.0685, GNorm = 1.3856, lr_0 = 1.7774e-04
Loss = 1.2828e-03, PNorm = 59.0711, GNorm = 2.0674, lr_0 = 1.7751e-04
Loss = 1.7929e-03, PNorm = 59.0742, GNorm = 1.5534, lr_0 = 1.7727e-04
Loss = 1.1503e-03, PNorm = 59.0761, GNorm = 1.8242, lr_0 = 1.7703e-04
Loss = 1.4928e-03, PNorm = 59.0789, GNorm = 1.3020, lr_0 = 1.7679e-04
Loss = 1.2603e-03, PNorm = 59.0828, GNorm = 1.8952, lr_0 = 1.7656e-04
Loss = 1.1951e-03, PNorm = 59.0858, GNorm = 2.1000, lr_0 = 1.7632e-04
Loss = 1.4632e-03, PNorm = 59.0896, GNorm = 2.3357, lr_0 = 1.7608e-04
Loss = 1.1242e-03, PNorm = 59.0940, GNorm = 2.1788, lr_0 = 1.7585e-04
Loss = 1.2738e-03, PNorm = 59.0971, GNorm = 1.8484, lr_0 = 1.7561e-04
Loss = 1.9442e-03, PNorm = 59.1013, GNorm = 2.3409, lr_0 = 1.7537e-04
Loss = 1.2786e-03, PNorm = 59.1055, GNorm = 1.7473, lr_0 = 1.7514e-04
Loss = 1.2627e-03, PNorm = 59.1086, GNorm = 1.7578, lr_0 = 1.7490e-04
Loss = 1.1043e-03, PNorm = 59.1109, GNorm = 2.0011, lr_0 = 1.7467e-04
Loss = 1.3934e-03, PNorm = 59.1131, GNorm = 1.1145, lr_0 = 1.7443e-04
Loss = 1.7815e-03, PNorm = 59.1156, GNorm = 1.9221, lr_0 = 1.7420e-04
Loss = 1.2544e-03, PNorm = 59.1185, GNorm = 1.7480, lr_0 = 1.7397e-04
Loss = 1.7743e-03, PNorm = 59.1235, GNorm = 1.4772, lr_0 = 1.7373e-04
Validation rmse = 4.135052
Validation R2 = -3.744676
Epoch 57
Train function
Loss = 1.6548e-03, PNorm = 59.1280, GNorm = 2.0999, lr_0 = 1.7348e-04
Loss = 1.1727e-03, PNorm = 59.1327, GNorm = 2.2467, lr_0 = 1.7324e-04
Loss = 1.3156e-03, PNorm = 59.1377, GNorm = 1.5545, lr_0 = 1.7301e-04
Loss = 1.2837e-03, PNorm = 59.1417, GNorm = 1.8816, lr_0 = 1.7278e-04
Loss = 1.1153e-03, PNorm = 59.1445, GNorm = 2.0131, lr_0 = 1.7255e-04
Loss = 1.0312e-03, PNorm = 59.1480, GNorm = 1.4738, lr_0 = 1.7232e-04
Loss = 1.1678e-03, PNorm = 59.1506, GNorm = 1.8729, lr_0 = 1.7209e-04
Loss = 1.1187e-03, PNorm = 59.1538, GNorm = 1.0663, lr_0 = 1.7185e-04
Loss = 1.5875e-03, PNorm = 59.1556, GNorm = 1.5716, lr_0 = 1.7162e-04
Loss = 1.5457e-03, PNorm = 59.1590, GNorm = 3.1369, lr_0 = 1.7139e-04
Loss = 1.0326e-03, PNorm = 59.1623, GNorm = 1.4141, lr_0 = 1.7116e-04
Loss = 9.4441e-04, PNorm = 59.1657, GNorm = 1.6426, lr_0 = 1.7093e-04
Loss = 1.4629e-03, PNorm = 59.1689, GNorm = 1.5143, lr_0 = 1.7070e-04
Loss = 1.1782e-03, PNorm = 59.1733, GNorm = 1.5170, lr_0 = 1.7048e-04
Loss = 1.3879e-03, PNorm = 59.1764, GNorm = 2.0428, lr_0 = 1.7025e-04
Loss = 1.7506e-03, PNorm = 59.1789, GNorm = 1.1475, lr_0 = 1.7002e-04
Loss = 2.0227e-03, PNorm = 59.1827, GNorm = 1.3023, lr_0 = 1.6979e-04
Loss = 1.3562e-03, PNorm = 59.1868, GNorm = 1.6098, lr_0 = 1.6956e-04
Loss = 1.6949e-03, PNorm = 59.1890, GNorm = 2.7316, lr_0 = 1.6933e-04
Loss = 1.8364e-03, PNorm = 59.1926, GNorm = 1.2979, lr_0 = 1.6911e-04
Loss = 1.5024e-03, PNorm = 59.1967, GNorm = 1.5604, lr_0 = 1.6888e-04
Loss = 1.4152e-03, PNorm = 59.2002, GNorm = 1.2506, lr_0 = 1.6865e-04
Loss = 1.3059e-03, PNorm = 59.2034, GNorm = 1.7360, lr_0 = 1.6843e-04
Loss = 1.0366e-03, PNorm = 59.2070, GNorm = 1.4832, lr_0 = 1.6820e-04
Validation rmse = 4.020341
Validation R2 = -3.485081
Epoch 58
Train function
Loss = 1.1620e-03, PNorm = 59.2120, GNorm = 1.8633, lr_0 = 1.6795e-04
Loss = 1.6432e-03, PNorm = 59.2162, GNorm = 1.5236, lr_0 = 1.6773e-04
Loss = 1.1329e-03, PNorm = 59.2194, GNorm = 2.4122, lr_0 = 1.6750e-04
Loss = 1.2522e-03, PNorm = 59.2226, GNorm = 3.1744, lr_0 = 1.6728e-04
Loss = 9.6418e-04, PNorm = 59.2256, GNorm = 1.5130, lr_0 = 1.6705e-04
Loss = 1.5298e-03, PNorm = 59.2291, GNorm = 2.8864, lr_0 = 1.6683e-04
Loss = 1.3965e-03, PNorm = 59.2330, GNorm = 2.1884, lr_0 = 1.6661e-04
Loss = 1.1743e-03, PNorm = 59.2366, GNorm = 1.1888, lr_0 = 1.6638e-04
Loss = 1.4838e-03, PNorm = 59.2392, GNorm = 1.4022, lr_0 = 1.6616e-04
Loss = 1.6284e-03, PNorm = 59.2424, GNorm = 2.1409, lr_0 = 1.6594e-04
Loss = 1.3691e-03, PNorm = 59.2448, GNorm = 2.3010, lr_0 = 1.6571e-04
Loss = 1.3093e-03, PNorm = 59.2463, GNorm = 1.8128, lr_0 = 1.6549e-04
Loss = 9.7384e-04, PNorm = 59.2487, GNorm = 1.3925, lr_0 = 1.6527e-04
Loss = 1.1091e-03, PNorm = 59.2510, GNorm = 2.2589, lr_0 = 1.6505e-04
Loss = 1.6285e-03, PNorm = 59.2534, GNorm = 5.1977, lr_0 = 1.6483e-04
Loss = 1.1510e-03, PNorm = 59.2553, GNorm = 1.4101, lr_0 = 1.6461e-04
Loss = 1.2165e-03, PNorm = 59.2572, GNorm = 1.4930, lr_0 = 1.6438e-04
Loss = 1.0678e-03, PNorm = 59.2592, GNorm = 1.9468, lr_0 = 1.6416e-04
Loss = 1.5463e-03, PNorm = 59.2619, GNorm = 1.9046, lr_0 = 1.6394e-04
Loss = 1.2038e-03, PNorm = 59.2647, GNorm = 1.4878, lr_0 = 1.6372e-04
Loss = 1.3451e-03, PNorm = 59.2671, GNorm = 1.4437, lr_0 = 1.6350e-04
Loss = 1.2004e-03, PNorm = 59.2699, GNorm = 2.5065, lr_0 = 1.6328e-04
Loss = 1.4547e-03, PNorm = 59.2737, GNorm = 2.4677, lr_0 = 1.6307e-04
Validation rmse = 4.078339
Validation R2 = -3.615419
Epoch 59
Train function
Loss = 1.1628e-03, PNorm = 59.2787, GNorm = 2.9557, lr_0 = 1.6282e-04
Loss = 2.0423e-03, PNorm = 59.2840, GNorm = 1.7753, lr_0 = 1.6261e-04
Loss = 1.5229e-03, PNorm = 59.2873, GNorm = 2.4021, lr_0 = 1.6239e-04
Loss = 1.6031e-03, PNorm = 59.2905, GNorm = 1.5296, lr_0 = 1.6217e-04
Loss = 1.1342e-03, PNorm = 59.2939, GNorm = 2.0809, lr_0 = 1.6195e-04
Loss = 1.3488e-03, PNorm = 59.2984, GNorm = 2.6992, lr_0 = 1.6174e-04
Loss = 1.6710e-03, PNorm = 59.3016, GNorm = 2.4612, lr_0 = 1.6152e-04
Loss = 1.4763e-03, PNorm = 59.3058, GNorm = 1.4650, lr_0 = 1.6130e-04
Loss = 1.1781e-03, PNorm = 59.3092, GNorm = 1.7114, lr_0 = 1.6109e-04
Loss = 1.6859e-03, PNorm = 59.3126, GNorm = 1.9451, lr_0 = 1.6087e-04
Loss = 1.5590e-03, PNorm = 59.3164, GNorm = 2.8702, lr_0 = 1.6065e-04
Loss = 1.3546e-03, PNorm = 59.3208, GNorm = 2.0302, lr_0 = 1.6044e-04
Loss = 1.7162e-03, PNorm = 59.3247, GNorm = 1.9864, lr_0 = 1.6022e-04
Loss = 1.3365e-03, PNorm = 59.3283, GNorm = 1.4040, lr_0 = 1.6001e-04
Loss = 1.1469e-03, PNorm = 59.3314, GNorm = 1.2425, lr_0 = 1.5979e-04
Loss = 1.2125e-03, PNorm = 59.3350, GNorm = 1.6141, lr_0 = 1.5958e-04
Loss = 1.1206e-03, PNorm = 59.3377, GNorm = 1.4875, lr_0 = 1.5936e-04
Loss = 1.4722e-03, PNorm = 59.3393, GNorm = 1.4628, lr_0 = 1.5915e-04
Loss = 1.3434e-03, PNorm = 59.3428, GNorm = 1.7837, lr_0 = 1.5894e-04
Loss = 1.1436e-03, PNorm = 59.3450, GNorm = 1.9612, lr_0 = 1.5872e-04
Loss = 1.1264e-03, PNorm = 59.3475, GNorm = 1.8742, lr_0 = 1.5851e-04
Loss = 1.0913e-03, PNorm = 59.3509, GNorm = 1.3850, lr_0 = 1.5830e-04
Loss = 1.0812e-03, PNorm = 59.3541, GNorm = 2.0215, lr_0 = 1.5809e-04
Loss = 1.3131e-03, PNorm = 59.3575, GNorm = 1.8066, lr_0 = 1.5787e-04
Validation rmse = 4.158807
Validation R2 = -3.799347
Epoch 60
Train function
Loss = 1.0032e-03, PNorm = 59.3613, GNorm = 2.4005, lr_0 = 1.5766e-04
Loss = 1.0257e-03, PNorm = 59.3644, GNorm = 1.3242, lr_0 = 1.5745e-04
Loss = 1.1466e-03, PNorm = 59.3668, GNorm = 1.7722, lr_0 = 1.5724e-04
Loss = 1.1034e-03, PNorm = 59.3703, GNorm = 1.1898, lr_0 = 1.5703e-04
Loss = 8.6445e-04, PNorm = 59.3727, GNorm = 2.1491, lr_0 = 1.5682e-04
Loss = 1.3213e-03, PNorm = 59.3759, GNorm = 1.5365, lr_0 = 1.5661e-04
Loss = 1.1668e-03, PNorm = 59.3769, GNorm = 1.3893, lr_0 = 1.5640e-04
Loss = 1.2893e-03, PNorm = 59.3788, GNorm = 1.0133, lr_0 = 1.5619e-04
Loss = 1.1615e-03, PNorm = 59.3813, GNorm = 1.4876, lr_0 = 1.5598e-04
Loss = 9.8557e-04, PNorm = 59.3843, GNorm = 1.4529, lr_0 = 1.5577e-04
Loss = 1.0413e-03, PNorm = 59.3860, GNorm = 1.4908, lr_0 = 1.5556e-04
Loss = 1.0456e-03, PNorm = 59.3882, GNorm = 1.3793, lr_0 = 1.5535e-04
Loss = 1.1603e-03, PNorm = 59.3908, GNorm = 3.9298, lr_0 = 1.5514e-04
Loss = 1.5200e-03, PNorm = 59.3936, GNorm = 1.1049, lr_0 = 1.5493e-04
Loss = 1.1955e-03, PNorm = 59.3962, GNorm = 1.4691, lr_0 = 1.5473e-04
Loss = 1.2298e-03, PNorm = 59.3989, GNorm = 0.9729, lr_0 = 1.5452e-04
Loss = 1.5069e-03, PNorm = 59.4016, GNorm = 2.1962, lr_0 = 1.5431e-04
Loss = 9.9517e-04, PNorm = 59.4037, GNorm = 2.0883, lr_0 = 1.5410e-04
Loss = 9.6476e-04, PNorm = 59.4060, GNorm = 1.5136, lr_0 = 1.5390e-04
Loss = 1.2143e-03, PNorm = 59.4082, GNorm = 1.8053, lr_0 = 1.5369e-04
Loss = 1.3612e-03, PNorm = 59.4107, GNorm = 2.5067, lr_0 = 1.5348e-04
Loss = 1.2225e-03, PNorm = 59.4142, GNorm = 3.9488, lr_0 = 1.5328e-04
Loss = 1.3278e-03, PNorm = 59.4169, GNorm = 2.3460, lr_0 = 1.5307e-04
Validation rmse = 4.120131
Validation R2 = -3.710496
Epoch 61
Train function
Loss = 7.3277e-04, PNorm = 59.4198, GNorm = 1.4272, lr_0 = 1.5285e-04
Loss = 1.0989e-03, PNorm = 59.4224, GNorm = 1.7887, lr_0 = 1.5264e-04
Loss = 9.5158e-04, PNorm = 59.4250, GNorm = 2.0700, lr_0 = 1.5244e-04
Loss = 7.6767e-04, PNorm = 59.4287, GNorm = 1.2871, lr_0 = 1.5223e-04
Loss = 9.5642e-04, PNorm = 59.4317, GNorm = 2.9082, lr_0 = 1.5203e-04
Loss = 8.7227e-04, PNorm = 59.4344, GNorm = 1.1786, lr_0 = 1.5182e-04
Loss = 8.5371e-04, PNorm = 59.4366, GNorm = 1.4012, lr_0 = 1.5162e-04
Loss = 1.0652e-03, PNorm = 59.4385, GNorm = 2.5110, lr_0 = 1.5142e-04
Loss = 1.0744e-03, PNorm = 59.4409, GNorm = 1.0662, lr_0 = 1.5121e-04
Loss = 1.2311e-03, PNorm = 59.4440, GNorm = 1.5169, lr_0 = 1.5101e-04
Loss = 9.7780e-04, PNorm = 59.4466, GNorm = 2.0181, lr_0 = 1.5081e-04
Loss = 1.0558e-03, PNorm = 59.4499, GNorm = 1.9379, lr_0 = 1.5061e-04
Loss = 1.2448e-03, PNorm = 59.4531, GNorm = 1.0159, lr_0 = 1.5040e-04
Loss = 1.1497e-03, PNorm = 59.4553, GNorm = 2.3428, lr_0 = 1.5020e-04
Loss = 8.0670e-04, PNorm = 59.4565, GNorm = 1.4597, lr_0 = 1.5000e-04
Loss = 1.2202e-03, PNorm = 59.4585, GNorm = 1.2047, lr_0 = 1.4980e-04
Loss = 1.2543e-03, PNorm = 59.4618, GNorm = 0.9277, lr_0 = 1.4960e-04
Loss = 1.1563e-03, PNorm = 59.4643, GNorm = 1.5380, lr_0 = 1.4940e-04
Loss = 1.4130e-03, PNorm = 59.4664, GNorm = 1.0323, lr_0 = 1.4920e-04
Loss = 1.0599e-03, PNorm = 59.4674, GNorm = 1.6848, lr_0 = 1.4900e-04
Loss = 1.2208e-03, PNorm = 59.4697, GNorm = 1.2183, lr_0 = 1.4880e-04
Loss = 8.6855e-04, PNorm = 59.4726, GNorm = 0.7938, lr_0 = 1.4860e-04
Loss = 1.4239e-03, PNorm = 59.4751, GNorm = 1.9328, lr_0 = 1.4840e-04
Loss = 1.1069e-03, PNorm = 59.4779, GNorm = 1.0433, lr_0 = 1.4820e-04
Loss = 8.0997e-03, PNorm = 59.4783, GNorm = 4.2150, lr_0 = 1.4818e-04
Validation rmse = 4.008960
Validation R2 = -3.459724
Epoch 62
Train function
Loss = 1.0642e-03, PNorm = 59.4805, GNorm = 1.5247, lr_0 = 1.4798e-04
Loss = 8.6286e-04, PNorm = 59.4824, GNorm = 2.2969, lr_0 = 1.4778e-04
Loss = 6.8310e-04, PNorm = 59.4848, GNorm = 1.9820, lr_0 = 1.4758e-04
Loss = 8.9779e-04, PNorm = 59.4871, GNorm = 1.9643, lr_0 = 1.4739e-04
Loss = 1.1663e-03, PNorm = 59.4902, GNorm = 1.3224, lr_0 = 1.4719e-04
Loss = 1.0133e-03, PNorm = 59.4924, GNorm = 1.6762, lr_0 = 1.4699e-04
Loss = 1.0305e-03, PNorm = 59.4951, GNorm = 1.7182, lr_0 = 1.4679e-04
Loss = 1.1857e-03, PNorm = 59.4967, GNorm = 3.3840, lr_0 = 1.4660e-04
Loss = 1.2735e-03, PNorm = 59.4997, GNorm = 2.1709, lr_0 = 1.4640e-04
Loss = 1.0476e-03, PNorm = 59.5028, GNorm = 1.2398, lr_0 = 1.4620e-04
Loss = 8.4474e-04, PNorm = 59.5052, GNorm = 1.3573, lr_0 = 1.4601e-04
Loss = 1.2241e-03, PNorm = 59.5077, GNorm = 1.2047, lr_0 = 1.4581e-04
Loss = 1.3025e-03, PNorm = 59.5093, GNorm = 1.0308, lr_0 = 1.4562e-04
Loss = 1.2419e-03, PNorm = 59.5132, GNorm = 1.6483, lr_0 = 1.4542e-04
Loss = 9.8479e-04, PNorm = 59.5163, GNorm = 1.6317, lr_0 = 1.4522e-04
Loss = 7.3800e-04, PNorm = 59.5189, GNorm = 1.2755, lr_0 = 1.4503e-04
Loss = 7.6563e-04, PNorm = 59.5205, GNorm = 1.6310, lr_0 = 1.4484e-04
Loss = 1.0888e-03, PNorm = 59.5231, GNorm = 1.3291, lr_0 = 1.4464e-04
Loss = 1.3516e-03, PNorm = 59.5264, GNorm = 2.5729, lr_0 = 1.4445e-04
Loss = 9.7202e-04, PNorm = 59.5284, GNorm = 1.2125, lr_0 = 1.4425e-04
Loss = 1.1718e-03, PNorm = 59.5316, GNorm = 2.6166, lr_0 = 1.4406e-04
Loss = 1.3367e-03, PNorm = 59.5352, GNorm = 1.6441, lr_0 = 1.4387e-04
Loss = 9.6890e-04, PNorm = 59.5383, GNorm = 1.2154, lr_0 = 1.4367e-04
Validation rmse = 4.092026
Validation R2 = -3.646451
Epoch 63
Train function
Loss = 6.6283e-04, PNorm = 59.5415, GNorm = 1.2618, lr_0 = 1.4346e-04
Loss = 8.3645e-04, PNorm = 59.5438, GNorm = 1.3421, lr_0 = 1.4327e-04
Loss = 8.6156e-04, PNorm = 59.5460, GNorm = 1.9706, lr_0 = 1.4308e-04
Loss = 8.4204e-04, PNorm = 59.5474, GNorm = 1.7151, lr_0 = 1.4288e-04
Loss = 1.1751e-03, PNorm = 59.5496, GNorm = 1.7714, lr_0 = 1.4269e-04
Loss = 8.0666e-04, PNorm = 59.5532, GNorm = 1.1390, lr_0 = 1.4250e-04
Loss = 8.7906e-04, PNorm = 59.5555, GNorm = 1.8283, lr_0 = 1.4231e-04
Loss = 1.0996e-03, PNorm = 59.5569, GNorm = 2.4843, lr_0 = 1.4212e-04
Loss = 8.3848e-04, PNorm = 59.5580, GNorm = 0.9858, lr_0 = 1.4193e-04
Loss = 1.5966e-03, PNorm = 59.5599, GNorm = 2.3065, lr_0 = 1.4174e-04
Loss = 1.2478e-03, PNorm = 59.5621, GNorm = 2.2549, lr_0 = 1.4155e-04
Loss = 1.1429e-03, PNorm = 59.5646, GNorm = 2.3826, lr_0 = 1.4136e-04
Loss = 8.4613e-04, PNorm = 59.5670, GNorm = 1.5798, lr_0 = 1.4117e-04
Loss = 7.2998e-04, PNorm = 59.5690, GNorm = 2.0904, lr_0 = 1.4098e-04
Loss = 8.9698e-04, PNorm = 59.5711, GNorm = 1.7282, lr_0 = 1.4079e-04
Loss = 9.3389e-04, PNorm = 59.5728, GNorm = 1.1892, lr_0 = 1.4060e-04
Loss = 1.3799e-03, PNorm = 59.5758, GNorm = 1.0702, lr_0 = 1.4041e-04
Loss = 8.1402e-04, PNorm = 59.5792, GNorm = 1.0131, lr_0 = 1.4022e-04
Loss = 7.8115e-04, PNorm = 59.5818, GNorm = 1.7849, lr_0 = 1.4004e-04
Loss = 9.8346e-04, PNorm = 59.5838, GNorm = 1.7097, lr_0 = 1.3985e-04
Loss = 1.2790e-03, PNorm = 59.5870, GNorm = 1.1061, lr_0 = 1.3966e-04
Loss = 9.1736e-04, PNorm = 59.5898, GNorm = 1.1950, lr_0 = 1.3947e-04
Loss = 8.3801e-04, PNorm = 59.5909, GNorm = 2.1031, lr_0 = 1.3929e-04
Validation rmse = 4.096913
Validation R2 = -3.657555
Epoch 64
Train function
Loss = 5.2715e-04, PNorm = 59.5938, GNorm = 0.8616, lr_0 = 1.3908e-04
Loss = 9.8039e-04, PNorm = 59.5961, GNorm = 1.1073, lr_0 = 1.3889e-04
Loss = 6.3292e-04, PNorm = 59.5981, GNorm = 1.4363, lr_0 = 1.3871e-04
Loss = 7.6706e-04, PNorm = 59.6000, GNorm = 1.0074, lr_0 = 1.3852e-04
Loss = 9.2242e-04, PNorm = 59.6026, GNorm = 1.4635, lr_0 = 1.3834e-04
Loss = 7.7951e-04, PNorm = 59.6053, GNorm = 1.9895, lr_0 = 1.3815e-04
Loss = 9.1257e-04, PNorm = 59.6076, GNorm = 1.8332, lr_0 = 1.3796e-04
Loss = 8.3025e-04, PNorm = 59.6101, GNorm = 1.3723, lr_0 = 1.3778e-04
Loss = 5.8934e-04, PNorm = 59.6118, GNorm = 1.1479, lr_0 = 1.3759e-04
Loss = 7.7210e-04, PNorm = 59.6131, GNorm = 1.1464, lr_0 = 1.3741e-04
Loss = 1.1376e-03, PNorm = 59.6158, GNorm = 1.9489, lr_0 = 1.3723e-04
Loss = 1.1979e-03, PNorm = 59.6180, GNorm = 1.9969, lr_0 = 1.3704e-04
Loss = 1.1630e-03, PNorm = 59.6212, GNorm = 2.0406, lr_0 = 1.3686e-04
Loss = 8.3260e-04, PNorm = 59.6239, GNorm = 1.1790, lr_0 = 1.3667e-04
Loss = 9.7411e-04, PNorm = 59.6264, GNorm = 2.3155, lr_0 = 1.3649e-04
Loss = 1.2556e-03, PNorm = 59.6287, GNorm = 2.7317, lr_0 = 1.3631e-04
Loss = 1.0849e-03, PNorm = 59.6324, GNorm = 1.5319, lr_0 = 1.3612e-04
Loss = 9.0014e-04, PNorm = 59.6341, GNorm = 1.8462, lr_0 = 1.3594e-04
Loss = 8.7467e-04, PNorm = 59.6362, GNorm = 1.0419, lr_0 = 1.3576e-04
Loss = 9.4086e-04, PNorm = 59.6392, GNorm = 0.8310, lr_0 = 1.3558e-04
Loss = 8.2706e-04, PNorm = 59.6415, GNorm = 2.1307, lr_0 = 1.3540e-04
Loss = 9.4112e-04, PNorm = 59.6442, GNorm = 2.4346, lr_0 = 1.3521e-04
Loss = 9.4773e-04, PNorm = 59.6459, GNorm = 1.7587, lr_0 = 1.3503e-04
Loss = 1.4367e-03, PNorm = 59.6481, GNorm = 2.3948, lr_0 = 1.3485e-04
Validation rmse = 4.020639
Validation R2 = -3.485746
Epoch 65
Train function
Loss = 8.7708e-04, PNorm = 59.6500, GNorm = 2.0404, lr_0 = 1.3467e-04
Loss = 9.7357e-04, PNorm = 59.6507, GNorm = 2.1155, lr_0 = 1.3449e-04
Loss = 1.0661e-03, PNorm = 59.6533, GNorm = 3.4522, lr_0 = 1.3431e-04
Loss = 6.9500e-04, PNorm = 59.6558, GNorm = 1.8551, lr_0 = 1.3413e-04
Loss = 7.5399e-04, PNorm = 59.6573, GNorm = 2.1282, lr_0 = 1.3395e-04
Loss = 9.7032e-04, PNorm = 59.6588, GNorm = 2.0247, lr_0 = 1.3377e-04
Loss = 1.1759e-03, PNorm = 59.6611, GNorm = 1.4443, lr_0 = 1.3359e-04
Loss = 7.2528e-04, PNorm = 59.6633, GNorm = 1.5900, lr_0 = 1.3341e-04
Loss = 8.4472e-04, PNorm = 59.6656, GNorm = 1.2339, lr_0 = 1.3323e-04
Loss = 9.4961e-04, PNorm = 59.6685, GNorm = 0.9529, lr_0 = 1.3305e-04
Loss = 8.2002e-04, PNorm = 59.6707, GNorm = 1.4573, lr_0 = 1.3287e-04
Loss = 8.4528e-04, PNorm = 59.6728, GNorm = 2.2277, lr_0 = 1.3270e-04
Loss = 7.5866e-04, PNorm = 59.6742, GNorm = 1.5921, lr_0 = 1.3252e-04
Loss = 6.9405e-04, PNorm = 59.6760, GNorm = 1.1984, lr_0 = 1.3234e-04
Loss = 1.2448e-03, PNorm = 59.6788, GNorm = 1.2236, lr_0 = 1.3216e-04
Loss = 1.0535e-03, PNorm = 59.6813, GNorm = 1.4117, lr_0 = 1.3199e-04
Loss = 1.1061e-03, PNorm = 59.6838, GNorm = 1.3135, lr_0 = 1.3181e-04
Loss = 9.3231e-04, PNorm = 59.6867, GNorm = 1.8475, lr_0 = 1.3163e-04
Loss = 9.7235e-04, PNorm = 59.6885, GNorm = 1.9290, lr_0 = 1.3145e-04
Loss = 7.2877e-04, PNorm = 59.6916, GNorm = 1.5044, lr_0 = 1.3128e-04
Loss = 8.5003e-04, PNorm = 59.6934, GNorm = 1.3197, lr_0 = 1.3110e-04
Loss = 9.6270e-04, PNorm = 59.6956, GNorm = 0.9251, lr_0 = 1.3093e-04
Loss = 7.6847e-04, PNorm = 59.6972, GNorm = 1.0472, lr_0 = 1.3075e-04
Validation rmse = 4.206494
Validation R2 = -3.910042
Epoch 66
Train function
Loss = 6.4174e-04, PNorm = 59.6984, GNorm = 1.3612, lr_0 = 1.3056e-04
Loss = 6.7502e-04, PNorm = 59.6995, GNorm = 1.1657, lr_0 = 1.3038e-04
Loss = 5.5795e-04, PNorm = 59.7007, GNorm = 1.0161, lr_0 = 1.3021e-04
Loss = 7.2202e-04, PNorm = 59.7023, GNorm = 1.1264, lr_0 = 1.3003e-04
Loss = 7.6676e-04, PNorm = 59.7043, GNorm = 1.7388, lr_0 = 1.2986e-04
Loss = 7.1230e-04, PNorm = 59.7070, GNorm = 1.4596, lr_0 = 1.2968e-04
Loss = 6.1488e-04, PNorm = 59.7097, GNorm = 1.1539, lr_0 = 1.2951e-04
Loss = 5.7044e-04, PNorm = 59.7115, GNorm = 0.8794, lr_0 = 1.2934e-04
Loss = 8.9759e-04, PNorm = 59.7130, GNorm = 1.6370, lr_0 = 1.2916e-04
Loss = 8.6298e-04, PNorm = 59.7159, GNorm = 1.2492, lr_0 = 1.2899e-04
Loss = 1.0461e-03, PNorm = 59.7185, GNorm = 1.3886, lr_0 = 1.2882e-04
Loss = 7.9053e-04, PNorm = 59.7209, GNorm = 1.4229, lr_0 = 1.2864e-04
Loss = 9.3463e-04, PNorm = 59.7232, GNorm = 1.1419, lr_0 = 1.2847e-04
Loss = 1.0455e-03, PNorm = 59.7255, GNorm = 1.4375, lr_0 = 1.2830e-04
Loss = 9.7388e-04, PNorm = 59.7271, GNorm = 1.8206, lr_0 = 1.2813e-04
Loss = 9.9332e-04, PNorm = 59.7287, GNorm = 1.1107, lr_0 = 1.2795e-04
Loss = 6.7742e-04, PNorm = 59.7301, GNorm = 1.8559, lr_0 = 1.2778e-04
Loss = 9.0840e-04, PNorm = 59.7322, GNorm = 1.1695, lr_0 = 1.2761e-04
Loss = 6.4845e-04, PNorm = 59.7349, GNorm = 1.1664, lr_0 = 1.2744e-04
Loss = 7.3416e-04, PNorm = 59.7370, GNorm = 1.2407, lr_0 = 1.2727e-04
Loss = 6.6959e-04, PNorm = 59.7385, GNorm = 0.8990, lr_0 = 1.2710e-04
Loss = 1.2369e-03, PNorm = 59.7395, GNorm = 1.6654, lr_0 = 1.2693e-04
Loss = 1.0609e-03, PNorm = 59.7409, GNorm = 1.7377, lr_0 = 1.2676e-04
Loss = 8.4968e-04, PNorm = 59.7427, GNorm = 1.6579, lr_0 = 1.2659e-04
Validation rmse = 4.345514
Validation R2 = -4.239948
Epoch 67
Train function
Loss = 6.0468e-04, PNorm = 59.7454, GNorm = 1.4465, lr_0 = 1.2640e-04
Loss = 6.5777e-04, PNorm = 59.7477, GNorm = 2.3313, lr_0 = 1.2623e-04
Loss = 6.6895e-04, PNorm = 59.7490, GNorm = 1.6620, lr_0 = 1.2606e-04
Loss = 7.9840e-04, PNorm = 59.7511, GNorm = 0.9417, lr_0 = 1.2589e-04
Loss = 9.2762e-04, PNorm = 59.7538, GNorm = 2.0097, lr_0 = 1.2572e-04
Loss = 7.7224e-04, PNorm = 59.7561, GNorm = 1.3851, lr_0 = 1.2555e-04
Loss = 7.7297e-04, PNorm = 59.7579, GNorm = 1.2453, lr_0 = 1.2539e-04
Loss = 6.8819e-04, PNorm = 59.7609, GNorm = 1.2559, lr_0 = 1.2522e-04
Loss = 7.7899e-04, PNorm = 59.7633, GNorm = 1.3510, lr_0 = 1.2505e-04
Loss = 9.3434e-04, PNorm = 59.7661, GNorm = 1.4121, lr_0 = 1.2488e-04
Loss = 7.3405e-04, PNorm = 59.7682, GNorm = 1.6365, lr_0 = 1.2471e-04
Loss = 6.6902e-04, PNorm = 59.7699, GNorm = 1.1748, lr_0 = 1.2455e-04
Loss = 5.5968e-04, PNorm = 59.7715, GNorm = 1.0301, lr_0 = 1.2438e-04
Loss = 7.2316e-04, PNorm = 59.7727, GNorm = 1.3829, lr_0 = 1.2421e-04
Loss = 7.0366e-04, PNorm = 59.7742, GNorm = 1.0604, lr_0 = 1.2405e-04
Loss = 1.3250e-03, PNorm = 59.7751, GNorm = 0.9120, lr_0 = 1.2388e-04
Loss = 7.7669e-04, PNorm = 59.7771, GNorm = 0.8785, lr_0 = 1.2371e-04
Loss = 9.8173e-04, PNorm = 59.7793, GNorm = 1.5657, lr_0 = 1.2355e-04
Loss = 1.1165e-03, PNorm = 59.7818, GNorm = 1.3120, lr_0 = 1.2338e-04
Loss = 8.4090e-04, PNorm = 59.7843, GNorm = 1.5750, lr_0 = 1.2322e-04
Loss = 9.9724e-04, PNorm = 59.7868, GNorm = 1.1288, lr_0 = 1.2305e-04
Loss = 8.1689e-04, PNorm = 59.7889, GNorm = 2.1989, lr_0 = 1.2289e-04
Loss = 7.8461e-04, PNorm = 59.7913, GNorm = 1.7582, lr_0 = 1.2272e-04
Validation rmse = 4.040306
Validation R2 = -3.529739
Epoch 68
Train function
Loss = 5.4809e-04, PNorm = 59.7931, GNorm = 1.4368, lr_0 = 1.2254e-04
Loss = 6.9236e-04, PNorm = 59.7942, GNorm = 1.4347, lr_0 = 1.2238e-04
Loss = 7.4313e-04, PNorm = 59.7961, GNorm = 1.4699, lr_0 = 1.2221e-04
Loss = 7.4025e-04, PNorm = 59.7980, GNorm = 1.5375, lr_0 = 1.2205e-04
Loss = 1.0766e-03, PNorm = 59.7997, GNorm = 1.8482, lr_0 = 1.2188e-04
Loss = 6.7949e-04, PNorm = 59.8019, GNorm = 1.2996, lr_0 = 1.2172e-04
Loss = 9.3309e-04, PNorm = 59.8045, GNorm = 1.7557, lr_0 = 1.2156e-04
Loss = 7.8546e-04, PNorm = 59.8065, GNorm = 1.4804, lr_0 = 1.2139e-04
Loss = 9.6912e-04, PNorm = 59.8086, GNorm = 1.8459, lr_0 = 1.2123e-04
Loss = 8.7596e-04, PNorm = 59.8117, GNorm = 1.6069, lr_0 = 1.2107e-04
Loss = 7.6022e-04, PNorm = 59.8143, GNorm = 1.1603, lr_0 = 1.2091e-04
Loss = 1.0543e-03, PNorm = 59.8157, GNorm = 1.0935, lr_0 = 1.2074e-04
Loss = 5.6184e-04, PNorm = 59.8168, GNorm = 1.2168, lr_0 = 1.2058e-04
Loss = 9.9276e-04, PNorm = 59.8180, GNorm = 1.6558, lr_0 = 1.2042e-04
Loss = 8.7890e-04, PNorm = 59.8197, GNorm = 2.0361, lr_0 = 1.2026e-04
Loss = 8.4578e-04, PNorm = 59.8216, GNorm = 1.7568, lr_0 = 1.2010e-04
Loss = 5.9427e-04, PNorm = 59.8227, GNorm = 1.1085, lr_0 = 1.1994e-04
Loss = 5.6592e-04, PNorm = 59.8241, GNorm = 1.9317, lr_0 = 1.1978e-04
Loss = 5.4938e-04, PNorm = 59.8253, GNorm = 1.2731, lr_0 = 1.1961e-04
Loss = 7.4275e-04, PNorm = 59.8264, GNorm = 1.2919, lr_0 = 1.1945e-04
Loss = 6.3632e-04, PNorm = 59.8277, GNorm = 1.8449, lr_0 = 1.1929e-04
Loss = 7.8158e-04, PNorm = 59.8297, GNorm = 1.8519, lr_0 = 1.1913e-04
Loss = 8.1604e-04, PNorm = 59.8324, GNorm = 0.9396, lr_0 = 1.1897e-04
Validation rmse = 4.165056
Validation R2 = -3.813781
Epoch 69
Train function
Loss = 1.0111e-03, PNorm = 59.8348, GNorm = 1.4910, lr_0 = 1.1880e-04
Loss = 5.6453e-04, PNorm = 59.8372, GNorm = 0.8833, lr_0 = 1.1864e-04
Loss = 5.7153e-04, PNorm = 59.8388, GNorm = 1.1849, lr_0 = 1.1848e-04
Loss = 6.2839e-04, PNorm = 59.8401, GNorm = 0.7405, lr_0 = 1.1832e-04
Loss = 9.8282e-04, PNorm = 59.8418, GNorm = 2.5335, lr_0 = 1.1816e-04
Loss = 1.0028e-03, PNorm = 59.8443, GNorm = 2.7298, lr_0 = 1.1800e-04
Loss = 6.0270e-04, PNorm = 59.8474, GNorm = 0.7650, lr_0 = 1.1785e-04
Loss = 5.7211e-04, PNorm = 59.8488, GNorm = 1.3499, lr_0 = 1.1769e-04
Loss = 8.5033e-04, PNorm = 59.8499, GNorm = 2.3949, lr_0 = 1.1753e-04
Loss = 6.7792e-04, PNorm = 59.8519, GNorm = 2.3791, lr_0 = 1.1737e-04
Loss = 6.0797e-04, PNorm = 59.8538, GNorm = 1.1576, lr_0 = 1.1721e-04
Loss = 7.1750e-04, PNorm = 59.8558, GNorm = 1.0405, lr_0 = 1.1706e-04
Loss = 5.3198e-04, PNorm = 59.8568, GNorm = 1.1196, lr_0 = 1.1690e-04
Loss = 7.4528e-04, PNorm = 59.8585, GNorm = 1.3682, lr_0 = 1.1674e-04
Loss = 4.9510e-04, PNorm = 59.8604, GNorm = 0.8442, lr_0 = 1.1659e-04
Loss = 5.0005e-04, PNorm = 59.8617, GNorm = 1.6951, lr_0 = 1.1643e-04
Loss = 7.2035e-04, PNorm = 59.8630, GNorm = 1.1571, lr_0 = 1.1627e-04
Loss = 8.2845e-04, PNorm = 59.8636, GNorm = 1.0600, lr_0 = 1.1612e-04
Loss = 9.3579e-04, PNorm = 59.8654, GNorm = 1.8972, lr_0 = 1.1596e-04
Loss = 9.5361e-04, PNorm = 59.8675, GNorm = 1.2607, lr_0 = 1.1581e-04
Loss = 8.8581e-04, PNorm = 59.8696, GNorm = 0.8588, lr_0 = 1.1565e-04
Loss = 8.0726e-04, PNorm = 59.8722, GNorm = 1.2349, lr_0 = 1.1550e-04
Loss = 8.0869e-04, PNorm = 59.8742, GNorm = 1.3079, lr_0 = 1.1534e-04
Loss = 8.9753e-04, PNorm = 59.8757, GNorm = 2.3359, lr_0 = 1.1519e-04
Validation rmse = 4.215965
Validation R2 = -3.932177
Epoch 70
Train function
Loss = 5.3827e-04, PNorm = 59.8773, GNorm = 1.0249, lr_0 = 1.1503e-04
Loss = 4.5909e-04, PNorm = 59.8783, GNorm = 1.5682, lr_0 = 1.1488e-04
Loss = 6.9843e-04, PNorm = 59.8791, GNorm = 1.7645, lr_0 = 1.1472e-04
Loss = 6.2660e-04, PNorm = 59.8803, GNorm = 1.8929, lr_0 = 1.1457e-04
Loss = 7.1915e-04, PNorm = 59.8815, GNorm = 1.6371, lr_0 = 1.1442e-04
Loss = 7.4778e-04, PNorm = 59.8822, GNorm = 2.6065, lr_0 = 1.1426e-04
Loss = 8.2661e-04, PNorm = 59.8832, GNorm = 2.1396, lr_0 = 1.1411e-04
Loss = 8.4718e-04, PNorm = 59.8846, GNorm = 1.2541, lr_0 = 1.1396e-04
Loss = 5.1801e-04, PNorm = 59.8865, GNorm = 0.9313, lr_0 = 1.1380e-04
Loss = 9.4806e-04, PNorm = 59.8882, GNorm = 2.9239, lr_0 = 1.1365e-04
Loss = 5.3012e-04, PNorm = 59.8905, GNorm = 1.3338, lr_0 = 1.1350e-04
Loss = 7.2145e-04, PNorm = 59.8929, GNorm = 1.8918, lr_0 = 1.1334e-04
Loss = 8.4649e-04, PNorm = 59.8948, GNorm = 1.1298, lr_0 = 1.1319e-04
Loss = 6.5027e-04, PNorm = 59.8961, GNorm = 1.4721, lr_0 = 1.1304e-04
Loss = 7.5777e-04, PNorm = 59.8978, GNorm = 1.6566, lr_0 = 1.1289e-04
Loss = 7.1358e-04, PNorm = 59.9006, GNorm = 2.0416, lr_0 = 1.1274e-04
Loss = 5.9006e-04, PNorm = 59.9021, GNorm = 1.2279, lr_0 = 1.1259e-04
Loss = 5.6148e-04, PNorm = 59.9035, GNorm = 1.5185, lr_0 = 1.1244e-04
Loss = 7.8287e-04, PNorm = 59.9048, GNorm = 0.7542, lr_0 = 1.1228e-04
Loss = 6.6248e-04, PNorm = 59.9063, GNorm = 0.7943, lr_0 = 1.1213e-04
Loss = 7.0416e-04, PNorm = 59.9078, GNorm = 0.8083, lr_0 = 1.1198e-04
Loss = 1.0629e-03, PNorm = 59.9092, GNorm = 2.5002, lr_0 = 1.1183e-04
Loss = 7.8299e-04, PNorm = 59.9111, GNorm = 1.5288, lr_0 = 1.1168e-04
Validation rmse = 3.984667
Validation R2 = -3.405839
Epoch 71
Train function
Loss = 1.6537e-03, PNorm = 59.9126, GNorm = 3.0736, lr_0 = 1.1152e-04
Loss = 6.9735e-04, PNorm = 59.9142, GNorm = 1.2696, lr_0 = 1.1137e-04
Loss = 7.6264e-04, PNorm = 59.9165, GNorm = 2.1101, lr_0 = 1.1122e-04
Loss = 7.7530e-04, PNorm = 59.9188, GNorm = 1.7590, lr_0 = 1.1107e-04
Loss = 6.3747e-04, PNorm = 59.9208, GNorm = 1.2195, lr_0 = 1.1092e-04
Loss = 7.7258e-04, PNorm = 59.9229, GNorm = 0.9624, lr_0 = 1.1077e-04
Loss = 7.4371e-04, PNorm = 59.9252, GNorm = 1.8924, lr_0 = 1.1062e-04
Loss = 6.3777e-04, PNorm = 59.9270, GNorm = 2.5975, lr_0 = 1.1048e-04
Loss = 5.1814e-04, PNorm = 59.9292, GNorm = 1.3749, lr_0 = 1.1033e-04
Loss = 5.5044e-04, PNorm = 59.9304, GNorm = 1.7382, lr_0 = 1.1018e-04
Loss = 5.1783e-04, PNorm = 59.9314, GNorm = 0.7905, lr_0 = 1.1003e-04
Loss = 5.9275e-04, PNorm = 59.9324, GNorm = 1.0362, lr_0 = 1.0988e-04
Loss = 4.6270e-04, PNorm = 59.9331, GNorm = 2.3225, lr_0 = 1.0974e-04
Loss = 5.4096e-04, PNorm = 59.9347, GNorm = 0.9309, lr_0 = 1.0959e-04
Loss = 4.9961e-04, PNorm = 59.9360, GNorm = 1.7982, lr_0 = 1.0944e-04
Loss = 5.4557e-04, PNorm = 59.9366, GNorm = 0.8564, lr_0 = 1.0930e-04
Loss = 6.9785e-04, PNorm = 59.9375, GNorm = 1.5085, lr_0 = 1.0915e-04
Loss = 6.6237e-04, PNorm = 59.9384, GNorm = 1.6671, lr_0 = 1.0900e-04
Loss = 5.2954e-04, PNorm = 59.9399, GNorm = 0.9478, lr_0 = 1.0886e-04
Loss = 1.2073e-03, PNorm = 59.9414, GNorm = 1.2971, lr_0 = 1.0871e-04
Loss = 6.7893e-04, PNorm = 59.9436, GNorm = 1.2270, lr_0 = 1.0856e-04
Loss = 7.7656e-04, PNorm = 59.9460, GNorm = 1.7731, lr_0 = 1.0842e-04
Loss = 8.1566e-04, PNorm = 59.9479, GNorm = 2.0896, lr_0 = 1.0827e-04
Loss = 1.0201e-03, PNorm = 59.9488, GNorm = 1.7294, lr_0 = 1.0813e-04
Validation rmse = 4.229690
Validation R2 = -3.964340
Epoch 72
Train function
Loss = 1.0785e-03, PNorm = 59.9511, GNorm = 1.0799, lr_0 = 1.0797e-04
Loss = 8.0386e-04, PNorm = 59.9531, GNorm = 1.0063, lr_0 = 1.0782e-04
Loss = 4.9342e-04, PNorm = 59.9548, GNorm = 1.2219, lr_0 = 1.0768e-04
Loss = 4.3244e-04, PNorm = 59.9563, GNorm = 1.0700, lr_0 = 1.0753e-04
Loss = 4.7886e-04, PNorm = 59.9579, GNorm = 0.8599, lr_0 = 1.0739e-04
Loss = 5.7908e-04, PNorm = 59.9587, GNorm = 1.7078, lr_0 = 1.0725e-04
Loss = 6.0623e-04, PNorm = 59.9606, GNorm = 1.0116, lr_0 = 1.0710e-04
Loss = 5.0141e-04, PNorm = 59.9619, GNorm = 1.1008, lr_0 = 1.0696e-04
Loss = 6.8051e-04, PNorm = 59.9631, GNorm = 2.0331, lr_0 = 1.0681e-04
Loss = 7.4866e-04, PNorm = 59.9656, GNorm = 1.0924, lr_0 = 1.0667e-04
Loss = 4.5637e-04, PNorm = 59.9667, GNorm = 0.8580, lr_0 = 1.0653e-04
Loss = 6.6800e-04, PNorm = 59.9682, GNorm = 0.8914, lr_0 = 1.0639e-04
Loss = 6.5210e-04, PNorm = 59.9703, GNorm = 1.7946, lr_0 = 1.0624e-04
Loss = 6.2464e-04, PNorm = 59.9718, GNorm = 1.4300, lr_0 = 1.0610e-04
Loss = 1.0814e-03, PNorm = 59.9726, GNorm = 1.4110, lr_0 = 1.0596e-04
Loss = 8.0180e-04, PNorm = 59.9728, GNorm = 1.5445, lr_0 = 1.0582e-04
Loss = 7.9077e-04, PNorm = 59.9754, GNorm = 1.4162, lr_0 = 1.0567e-04
Loss = 8.1165e-04, PNorm = 59.9778, GNorm = 1.4507, lr_0 = 1.0553e-04
Loss = 7.3133e-04, PNorm = 59.9803, GNorm = 1.1849, lr_0 = 1.0539e-04
Loss = 6.3536e-04, PNorm = 59.9821, GNorm = 1.0747, lr_0 = 1.0525e-04
Loss = 5.5884e-04, PNorm = 59.9835, GNorm = 0.7449, lr_0 = 1.0511e-04
Loss = 6.6322e-04, PNorm = 59.9849, GNorm = 1.0292, lr_0 = 1.0497e-04
Loss = 7.7595e-04, PNorm = 59.9863, GNorm = 1.0946, lr_0 = 1.0483e-04
Validation rmse = 4.151435
Validation R2 = -3.782347
Epoch 73
Train function
Loss = 4.0907e-04, PNorm = 59.9874, GNorm = 0.9966, lr_0 = 1.0467e-04
Loss = 4.5129e-04, PNorm = 59.9890, GNorm = 1.2904, lr_0 = 1.0453e-04
Loss = 4.9602e-04, PNorm = 59.9897, GNorm = 1.1684, lr_0 = 1.0439e-04
Loss = 7.4366e-04, PNorm = 59.9909, GNorm = 2.9593, lr_0 = 1.0425e-04
Loss = 6.6314e-04, PNorm = 59.9929, GNorm = 1.5456, lr_0 = 1.0411e-04
Loss = 5.1776e-04, PNorm = 59.9951, GNorm = 1.1288, lr_0 = 1.0397e-04
Loss = 6.9497e-04, PNorm = 59.9972, GNorm = 1.1746, lr_0 = 1.0383e-04
Loss = 4.8613e-04, PNorm = 59.9984, GNorm = 1.1893, lr_0 = 1.0369e-04
Loss = 6.3551e-04, PNorm = 59.9993, GNorm = 1.1678, lr_0 = 1.0355e-04
Loss = 4.1294e-04, PNorm = 59.9993, GNorm = 0.9318, lr_0 = 1.0341e-04
Loss = 6.2169e-04, PNorm = 60.0000, GNorm = 0.7929, lr_0 = 1.0327e-04
Loss = 5.6659e-04, PNorm = 60.0015, GNorm = 1.0012, lr_0 = 1.0314e-04
Loss = 8.7873e-04, PNorm = 60.0035, GNorm = 2.5640, lr_0 = 1.0300e-04
Loss = 6.7953e-04, PNorm = 60.0045, GNorm = 2.4392, lr_0 = 1.0286e-04
Loss = 5.2508e-04, PNorm = 60.0059, GNorm = 1.9195, lr_0 = 1.0272e-04
Loss = 5.9944e-04, PNorm = 60.0069, GNorm = 0.9599, lr_0 = 1.0258e-04
Loss = 7.3699e-04, PNorm = 60.0077, GNorm = 0.9119, lr_0 = 1.0245e-04
Loss = 5.7556e-04, PNorm = 60.0096, GNorm = 1.4326, lr_0 = 1.0231e-04
Loss = 5.2286e-04, PNorm = 60.0111, GNorm = 1.0327, lr_0 = 1.0217e-04
Loss = 5.5649e-04, PNorm = 60.0126, GNorm = 0.9187, lr_0 = 1.0203e-04
Loss = 1.0481e-03, PNorm = 60.0142, GNorm = 1.6653, lr_0 = 1.0190e-04
Loss = 6.5807e-04, PNorm = 60.0155, GNorm = 1.0896, lr_0 = 1.0176e-04
Loss = 6.9344e-04, PNorm = 60.0168, GNorm = 0.9849, lr_0 = 1.0162e-04
Loss = 5.8098e-04, PNorm = 60.0192, GNorm = 1.3389, lr_0 = 1.0149e-04
Loss = 4.4108e-04, PNorm = 60.0194, GNorm = 1.2454, lr_0 = 1.0147e-04
Validation rmse = 4.204091
Validation R2 = -3.904433
Epoch 74
Train function
Loss = 5.5273e-04, PNorm = 60.0211, GNorm = 1.9439, lr_0 = 1.0134e-04
Loss = 4.4211e-04, PNorm = 60.0223, GNorm = 1.2553, lr_0 = 1.0120e-04
Loss = 6.3847e-04, PNorm = 60.0240, GNorm = 1.2900, lr_0 = 1.0107e-04
Loss = 5.6587e-04, PNorm = 60.0247, GNorm = 1.4866, lr_0 = 1.0093e-04
Loss = 4.9320e-04, PNorm = 60.0259, GNorm = 1.5534, lr_0 = 1.0080e-04
Loss = 5.2516e-04, PNorm = 60.0276, GNorm = 0.9052, lr_0 = 1.0066e-04
Loss = 5.6575e-04, PNorm = 60.0297, GNorm = 1.6142, lr_0 = 1.0052e-04
Loss = 5.0977e-04, PNorm = 60.0311, GNorm = 0.9375, lr_0 = 1.0039e-04
Loss = 5.0497e-04, PNorm = 60.0330, GNorm = 0.9780, lr_0 = 1.0026e-04
Loss = 3.8388e-04, PNorm = 60.0337, GNorm = 0.9399, lr_0 = 1.0012e-04
Loss = 4.9553e-04, PNorm = 60.0344, GNorm = 1.6897, lr_0 = 1.0000e-04
Loss = 8.2710e-04, PNorm = 60.0353, GNorm = 2.1411, lr_0 = 1.0000e-04
Loss = 7.7871e-04, PNorm = 60.0364, GNorm = 3.8647, lr_0 = 1.0000e-04
Loss = 4.6788e-04, PNorm = 60.0373, GNorm = 1.5830, lr_0 = 1.0000e-04
Loss = 8.4271e-04, PNorm = 60.0392, GNorm = 1.5703, lr_0 = 1.0000e-04
Loss = 8.9359e-04, PNorm = 60.0416, GNorm = 1.7404, lr_0 = 1.0000e-04
Loss = 7.4419e-04, PNorm = 60.0438, GNorm = 2.4554, lr_0 = 1.0000e-04
Loss = 5.9503e-04, PNorm = 60.0449, GNorm = 1.7684, lr_0 = 1.0000e-04
Loss = 6.0443e-04, PNorm = 60.0458, GNorm = 0.8843, lr_0 = 1.0000e-04
Loss = 1.0513e-03, PNorm = 60.0480, GNorm = 1.5680, lr_0 = 1.0000e-04
Loss = 6.1265e-04, PNorm = 60.0502, GNorm = 3.3268, lr_0 = 1.0000e-04
Loss = 5.0856e-04, PNorm = 60.0512, GNorm = 0.8989, lr_0 = 1.0000e-04
Loss = 3.7533e-04, PNorm = 60.0521, GNorm = 1.2888, lr_0 = 1.0000e-04
Validation rmse = 4.180367
Validation R2 = -3.849238
Epoch 75
Train function
Loss = 3.7623e-04, PNorm = 60.0534, GNorm = 0.9703, lr_0 = 1.0000e-04
Loss = 5.6047e-04, PNorm = 60.0546, GNorm = 1.4684, lr_0 = 1.0000e-04
Loss = 5.9194e-04, PNorm = 60.0558, GNorm = 1.4249, lr_0 = 1.0000e-04
Loss = 3.9101e-04, PNorm = 60.0575, GNorm = 1.3236, lr_0 = 1.0000e-04
Loss = 4.7828e-04, PNorm = 60.0584, GNorm = 1.0622, lr_0 = 1.0000e-04
Loss = 4.1783e-04, PNorm = 60.0594, GNorm = 1.5490, lr_0 = 1.0000e-04
Loss = 4.2599e-04, PNorm = 60.0602, GNorm = 2.3301, lr_0 = 1.0000e-04
Loss = 4.7926e-04, PNorm = 60.0612, GNorm = 0.7917, lr_0 = 1.0000e-04
Loss = 4.4590e-04, PNorm = 60.0624, GNorm = 1.2218, lr_0 = 1.0000e-04
Loss = 5.4873e-04, PNorm = 60.0636, GNorm = 0.9922, lr_0 = 1.0000e-04
Loss = 5.5499e-04, PNorm = 60.0642, GNorm = 0.9196, lr_0 = 1.0000e-04
Loss = 4.8809e-04, PNorm = 60.0652, GNorm = 0.8204, lr_0 = 1.0000e-04
Loss = 5.0235e-04, PNorm = 60.0667, GNorm = 1.2151, lr_0 = 1.0000e-04
Loss = 5.1224e-04, PNorm = 60.0679, GNorm = 1.4251, lr_0 = 1.0000e-04
Loss = 4.8455e-04, PNorm = 60.0686, GNorm = 0.7876, lr_0 = 1.0000e-04
Loss = 7.4118e-04, PNorm = 60.0688, GNorm = 1.8348, lr_0 = 1.0000e-04
Loss = 8.3052e-04, PNorm = 60.0701, GNorm = 1.7097, lr_0 = 1.0000e-04
Loss = 9.8836e-04, PNorm = 60.0718, GNorm = 1.0932, lr_0 = 1.0000e-04
Loss = 7.0781e-04, PNorm = 60.0739, GNorm = 2.0961, lr_0 = 1.0000e-04
Loss = 4.8303e-04, PNorm = 60.0758, GNorm = 1.1984, lr_0 = 1.0000e-04
Loss = 6.6174e-04, PNorm = 60.0770, GNorm = 2.3250, lr_0 = 1.0000e-04
Loss = 7.3786e-04, PNorm = 60.0788, GNorm = 1.4998, lr_0 = 1.0000e-04
Loss = 7.9733e-04, PNorm = 60.0804, GNorm = 1.9166, lr_0 = 1.0000e-04
Validation rmse = 4.124488
Validation R2 = -3.720465
Epoch 76
Train function
Loss = 4.5976e-04, PNorm = 60.0825, GNorm = 1.3728, lr_0 = 1.0000e-04
Loss = 4.4411e-04, PNorm = 60.0842, GNorm = 1.2451, lr_0 = 1.0000e-04
Loss = 4.8903e-04, PNorm = 60.0853, GNorm = 1.0170, lr_0 = 1.0000e-04
Loss = 5.6994e-04, PNorm = 60.0867, GNorm = 1.1376, lr_0 = 1.0000e-04
Loss = 4.4497e-04, PNorm = 60.0881, GNorm = 1.2162, lr_0 = 1.0000e-04
Loss = 4.8913e-04, PNorm = 60.0892, GNorm = 1.0806, lr_0 = 1.0000e-04
Loss = 3.3280e-04, PNorm = 60.0892, GNorm = 1.2157, lr_0 = 1.0000e-04
Loss = 3.9709e-04, PNorm = 60.0908, GNorm = 1.4931, lr_0 = 1.0000e-04
Loss = 6.7857e-04, PNorm = 60.0920, GNorm = 1.0537, lr_0 = 1.0000e-04
Loss = 5.5220e-04, PNorm = 60.0934, GNorm = 1.5346, lr_0 = 1.0000e-04
Loss = 8.2659e-04, PNorm = 60.0954, GNorm = 1.7053, lr_0 = 1.0000e-04
Loss = 8.2056e-04, PNorm = 60.0971, GNorm = 1.2598, lr_0 = 1.0000e-04
Loss = 5.9020e-04, PNorm = 60.0987, GNorm = 1.4238, lr_0 = 1.0000e-04
Loss = 4.9796e-04, PNorm = 60.1007, GNorm = 0.7911, lr_0 = 1.0000e-04
Loss = 5.3321e-04, PNorm = 60.1026, GNorm = 1.1517, lr_0 = 1.0000e-04
Loss = 8.5706e-04, PNorm = 60.1041, GNorm = 2.2079, lr_0 = 1.0000e-04
Loss = 4.9992e-04, PNorm = 60.1056, GNorm = 1.0494, lr_0 = 1.0000e-04
Loss = 5.3047e-04, PNorm = 60.1070, GNorm = 1.0064, lr_0 = 1.0000e-04
Loss = 5.5822e-04, PNorm = 60.1087, GNorm = 0.7668, lr_0 = 1.0000e-04
Loss = 4.7657e-04, PNorm = 60.1104, GNorm = 1.8120, lr_0 = 1.0000e-04
Loss = 5.3998e-04, PNorm = 60.1114, GNorm = 0.9847, lr_0 = 1.0000e-04
Loss = 4.9076e-04, PNorm = 60.1130, GNorm = 1.2291, lr_0 = 1.0000e-04
Loss = 4.6588e-04, PNorm = 60.1139, GNorm = 0.8995, lr_0 = 1.0000e-04
Loss = 6.6714e-04, PNorm = 60.1152, GNorm = 1.2349, lr_0 = 1.0000e-04
Validation rmse = 4.206527
Validation R2 = -3.910117
Epoch 77
Train function
Loss = 4.2860e-04, PNorm = 60.1156, GNorm = 0.9360, lr_0 = 1.0000e-04
Loss = 4.0351e-04, PNorm = 60.1165, GNorm = 1.4537, lr_0 = 1.0000e-04
Loss = 4.4918e-04, PNorm = 60.1175, GNorm = 0.8749, lr_0 = 1.0000e-04
Loss = 4.5937e-04, PNorm = 60.1185, GNorm = 0.9920, lr_0 = 1.0000e-04
Loss = 4.1830e-04, PNorm = 60.1199, GNorm = 0.6560, lr_0 = 1.0000e-04
Loss = 3.9714e-04, PNorm = 60.1208, GNorm = 0.7485, lr_0 = 1.0000e-04
Loss = 4.7791e-04, PNorm = 60.1214, GNorm = 0.7049, lr_0 = 1.0000e-04
Loss = 5.6050e-04, PNorm = 60.1225, GNorm = 0.8024, lr_0 = 1.0000e-04
Loss = 4.3700e-04, PNorm = 60.1236, GNorm = 1.2087, lr_0 = 1.0000e-04
Loss = 3.9622e-04, PNorm = 60.1245, GNorm = 1.0248, lr_0 = 1.0000e-04
Loss = 6.1069e-04, PNorm = 60.1266, GNorm = 1.3406, lr_0 = 1.0000e-04
Loss = 7.1005e-04, PNorm = 60.1290, GNorm = 2.0320, lr_0 = 1.0000e-04
Loss = 5.3309e-04, PNorm = 60.1313, GNorm = 1.5541, lr_0 = 1.0000e-04
Loss = 5.5293e-04, PNorm = 60.1334, GNorm = 1.3346, lr_0 = 1.0000e-04
Loss = 5.0532e-04, PNorm = 60.1345, GNorm = 1.3224, lr_0 = 1.0000e-04
Loss = 4.8688e-04, PNorm = 60.1360, GNorm = 1.1429, lr_0 = 1.0000e-04
Loss = 5.1627e-04, PNorm = 60.1373, GNorm = 1.3510, lr_0 = 1.0000e-04
Loss = 7.5007e-04, PNorm = 60.1382, GNorm = 2.5220, lr_0 = 1.0000e-04
Loss = 6.1923e-04, PNorm = 60.1396, GNorm = 1.5646, lr_0 = 1.0000e-04
Loss = 5.3450e-04, PNorm = 60.1409, GNorm = 1.2537, lr_0 = 1.0000e-04
Loss = 4.5837e-04, PNorm = 60.1420, GNorm = 1.0772, lr_0 = 1.0000e-04
Loss = 8.9616e-04, PNorm = 60.1444, GNorm = 0.9133, lr_0 = 1.0000e-04
Loss = 9.2351e-04, PNorm = 60.1446, GNorm = 3.9199, lr_0 = 1.0000e-04
Validation rmse = 4.225015
Validation R2 = -3.953374
Epoch 78
Train function
Loss = 1.2545e-03, PNorm = 60.1466, GNorm = 2.7836, lr_0 = 1.0000e-04
Loss = 4.6720e-04, PNorm = 60.1482, GNorm = 0.9451, lr_0 = 1.0000e-04
Loss = 3.8065e-04, PNorm = 60.1493, GNorm = 0.7817, lr_0 = 1.0000e-04
Loss = 3.9373e-04, PNorm = 60.1498, GNorm = 0.5938, lr_0 = 1.0000e-04
Loss = 3.1487e-04, PNorm = 60.1510, GNorm = 1.6501, lr_0 = 1.0000e-04
Loss = 5.0712e-04, PNorm = 60.1527, GNorm = 1.3189, lr_0 = 1.0000e-04
Loss = 6.6846e-04, PNorm = 60.1538, GNorm = 1.6256, lr_0 = 1.0000e-04
Loss = 4.4525e-04, PNorm = 60.1550, GNorm = 1.2302, lr_0 = 1.0000e-04
Loss = 4.2102e-04, PNorm = 60.1567, GNorm = 0.9534, lr_0 = 1.0000e-04
Loss = 4.5072e-04, PNorm = 60.1583, GNorm = 0.9962, lr_0 = 1.0000e-04
Loss = 5.4343e-04, PNorm = 60.1600, GNorm = 1.3379, lr_0 = 1.0000e-04
Loss = 9.7449e-04, PNorm = 60.1607, GNorm = 0.8999, lr_0 = 1.0000e-04
Loss = 7.1279e-04, PNorm = 60.1619, GNorm = 1.9106, lr_0 = 1.0000e-04
Loss = 7.4440e-04, PNorm = 60.1633, GNorm = 3.2236, lr_0 = 1.0000e-04
Loss = 4.8465e-04, PNorm = 60.1642, GNorm = 1.7598, lr_0 = 1.0000e-04
Loss = 6.1491e-04, PNorm = 60.1661, GNorm = 2.4950, lr_0 = 1.0000e-04
Loss = 4.9292e-04, PNorm = 60.1679, GNorm = 0.8455, lr_0 = 1.0000e-04
Loss = 3.9776e-04, PNorm = 60.1687, GNorm = 1.3069, lr_0 = 1.0000e-04
Loss = 4.6452e-04, PNorm = 60.1695, GNorm = 0.6305, lr_0 = 1.0000e-04
Loss = 4.4794e-04, PNorm = 60.1709, GNorm = 0.6933, lr_0 = 1.0000e-04
Loss = 6.2555e-04, PNorm = 60.1719, GNorm = 1.1160, lr_0 = 1.0000e-04
Loss = 6.6445e-04, PNorm = 60.1739, GNorm = 1.4990, lr_0 = 1.0000e-04
Loss = 5.2396e-04, PNorm = 60.1757, GNorm = 1.1825, lr_0 = 1.0000e-04
Loss = 5.1241e-04, PNorm = 60.1773, GNorm = 1.2903, lr_0 = 1.0000e-04
Validation rmse = 4.249606
Validation R2 = -4.011201
Epoch 79
Train function
Loss = 4.1134e-04, PNorm = 60.1789, GNorm = 1.0887, lr_0 = 1.0000e-04
Loss = 4.2357e-04, PNorm = 60.1803, GNorm = 1.4639, lr_0 = 1.0000e-04
Loss = 4.6718e-04, PNorm = 60.1813, GNorm = 1.3351, lr_0 = 1.0000e-04
Loss = 5.3938e-04, PNorm = 60.1822, GNorm = 0.7221, lr_0 = 1.0000e-04
Loss = 6.2940e-04, PNorm = 60.1835, GNorm = 1.0754, lr_0 = 1.0000e-04
Loss = 4.1087e-04, PNorm = 60.1852, GNorm = 0.8524, lr_0 = 1.0000e-04
Loss = 5.2319e-04, PNorm = 60.1864, GNorm = 1.8836, lr_0 = 1.0000e-04
Loss = 5.2369e-04, PNorm = 60.1883, GNorm = 0.8501, lr_0 = 1.0000e-04
Loss = 6.3794e-04, PNorm = 60.1892, GNorm = 1.3365, lr_0 = 1.0000e-04
Loss = 4.3163e-04, PNorm = 60.1904, GNorm = 1.6816, lr_0 = 1.0000e-04
Loss = 6.2237e-04, PNorm = 60.1923, GNorm = 0.9906, lr_0 = 1.0000e-04
Loss = 7.0326e-04, PNorm = 60.1937, GNorm = 1.1622, lr_0 = 1.0000e-04
Loss = 5.7091e-04, PNorm = 60.1944, GNorm = 0.8548, lr_0 = 1.0000e-04
Loss = 4.6124e-04, PNorm = 60.1962, GNorm = 1.2625, lr_0 = 1.0000e-04
Loss = 4.9205e-04, PNorm = 60.1971, GNorm = 1.8083, lr_0 = 1.0000e-04
Loss = 5.2998e-04, PNorm = 60.1980, GNorm = 1.3914, lr_0 = 1.0000e-04
Loss = 6.5316e-04, PNorm = 60.1994, GNorm = 1.1875, lr_0 = 1.0000e-04
Loss = 4.3986e-04, PNorm = 60.2007, GNorm = 2.1495, lr_0 = 1.0000e-04
Loss = 3.1273e-04, PNorm = 60.2013, GNorm = 1.3482, lr_0 = 1.0000e-04
Loss = 4.7531e-04, PNorm = 60.2020, GNorm = 1.0376, lr_0 = 1.0000e-04
Loss = 3.5700e-04, PNorm = 60.2030, GNorm = 1.0908, lr_0 = 1.0000e-04
Loss = 4.6696e-04, PNorm = 60.2049, GNorm = 1.0749, lr_0 = 1.0000e-04
Loss = 4.8952e-04, PNorm = 60.2067, GNorm = 0.8738, lr_0 = 1.0000e-04
Validation rmse = 4.278782
Validation R2 = -4.080247
Epoch 80
Train function
Loss = 3.7383e-04, PNorm = 60.2084, GNorm = 0.8877, lr_0 = 1.0000e-04
Loss = 3.5064e-04, PNorm = 60.2100, GNorm = 0.8753, lr_0 = 1.0000e-04
Loss = 3.6418e-04, PNorm = 60.2113, GNorm = 1.0030, lr_0 = 1.0000e-04
Loss = 3.9867e-04, PNorm = 60.2117, GNorm = 1.1023, lr_0 = 1.0000e-04
Loss = 3.9398e-04, PNorm = 60.2129, GNorm = 1.0166, lr_0 = 1.0000e-04
Loss = 4.3208e-04, PNorm = 60.2136, GNorm = 0.8354, lr_0 = 1.0000e-04
Loss = 3.4818e-04, PNorm = 60.2138, GNorm = 1.0028, lr_0 = 1.0000e-04
Loss = 5.6359e-04, PNorm = 60.2155, GNorm = 1.1623, lr_0 = 1.0000e-04
Loss = 5.0184e-04, PNorm = 60.2176, GNorm = 1.8687, lr_0 = 1.0000e-04
Loss = 8.9084e-04, PNorm = 60.2194, GNorm = 1.4733, lr_0 = 1.0000e-04
Loss = 6.1305e-04, PNorm = 60.2204, GNorm = 0.7270, lr_0 = 1.0000e-04
Loss = 5.1957e-04, PNorm = 60.2223, GNorm = 2.2542, lr_0 = 1.0000e-04
Loss = 6.8934e-04, PNorm = 60.2236, GNorm = 2.7159, lr_0 = 1.0000e-04
Loss = 3.6509e-04, PNorm = 60.2237, GNorm = 0.9821, lr_0 = 1.0000e-04
Loss = 5.7072e-04, PNorm = 60.2245, GNorm = 1.1306, lr_0 = 1.0000e-04
Loss = 4.1064e-04, PNorm = 60.2250, GNorm = 1.0226, lr_0 = 1.0000e-04
Loss = 3.9113e-04, PNorm = 60.2252, GNorm = 2.0879, lr_0 = 1.0000e-04
Loss = 6.2468e-04, PNorm = 60.2262, GNorm = 1.2374, lr_0 = 1.0000e-04
Loss = 6.3782e-04, PNorm = 60.2274, GNorm = 1.7921, lr_0 = 1.0000e-04
Loss = 5.8298e-04, PNorm = 60.2292, GNorm = 1.5024, lr_0 = 1.0000e-04
Loss = 6.2442e-04, PNorm = 60.2310, GNorm = 0.9731, lr_0 = 1.0000e-04
Loss = 5.6863e-04, PNorm = 60.2325, GNorm = 1.5281, lr_0 = 1.0000e-04
Loss = 4.8303e-04, PNorm = 60.2340, GNorm = 0.5876, lr_0 = 1.0000e-04
Loss = 4.0132e-04, PNorm = 60.2352, GNorm = 0.8663, lr_0 = 1.0000e-04
Loss = 2.6595e-03, PNorm = 60.2353, GNorm = 1.9029, lr_0 = 1.0000e-04
Validation rmse = 4.280288
Validation R2 = -4.083824
Epoch 81
Train function
Loss = 4.8425e-04, PNorm = 60.2365, GNorm = 0.7469, lr_0 = 1.0000e-04
Loss = 5.8676e-04, PNorm = 60.2374, GNorm = 1.2238, lr_0 = 1.0000e-04
Loss = 5.3700e-04, PNorm = 60.2388, GNorm = 1.3828, lr_0 = 1.0000e-04
Loss = 3.3803e-04, PNorm = 60.2399, GNorm = 0.8892, lr_0 = 1.0000e-04
Loss = 2.9822e-04, PNorm = 60.2409, GNorm = 1.0511, lr_0 = 1.0000e-04
Loss = 3.4798e-04, PNorm = 60.2421, GNorm = 0.9437, lr_0 = 1.0000e-04
Loss = 5.2117e-04, PNorm = 60.2436, GNorm = 2.3298, lr_0 = 1.0000e-04
Loss = 7.7413e-04, PNorm = 60.2446, GNorm = 0.8667, lr_0 = 1.0000e-04
Loss = 4.0810e-04, PNorm = 60.2453, GNorm = 1.1573, lr_0 = 1.0000e-04
Loss = 4.8592e-04, PNorm = 60.2471, GNorm = 1.0298, lr_0 = 1.0000e-04
Loss = 4.6885e-04, PNorm = 60.2484, GNorm = 0.8340, lr_0 = 1.0000e-04
Loss = 5.0481e-04, PNorm = 60.2498, GNorm = 1.0140, lr_0 = 1.0000e-04
Loss = 4.9291e-04, PNorm = 60.2517, GNorm = 1.2679, lr_0 = 1.0000e-04
Loss = 5.3448e-04, PNorm = 60.2541, GNorm = 1.7684, lr_0 = 1.0000e-04
Loss = 3.4429e-04, PNorm = 60.2562, GNorm = 1.0910, lr_0 = 1.0000e-04
Loss = 4.6033e-04, PNorm = 60.2574, GNorm = 1.3948, lr_0 = 1.0000e-04
Loss = 3.9201e-04, PNorm = 60.2589, GNorm = 1.0691, lr_0 = 1.0000e-04
Loss = 4.8978e-04, PNorm = 60.2600, GNorm = 2.0804, lr_0 = 1.0000e-04
Loss = 5.4458e-04, PNorm = 60.2615, GNorm = 1.2313, lr_0 = 1.0000e-04
Loss = 4.4902e-04, PNorm = 60.2624, GNorm = 1.6013, lr_0 = 1.0000e-04
Loss = 4.7306e-04, PNorm = 60.2633, GNorm = 0.9884, lr_0 = 1.0000e-04
Loss = 5.0872e-04, PNorm = 60.2642, GNorm = 3.2656, lr_0 = 1.0000e-04
Loss = 8.4181e-04, PNorm = 60.2665, GNorm = 0.6531, lr_0 = 1.0000e-04
Validation rmse = 4.247192
Validation R2 = -4.005511
Epoch 82
Train function
Loss = 3.4834e-04, PNorm = 60.2681, GNorm = 0.8309, lr_0 = 1.0000e-04
Loss = 4.7406e-04, PNorm = 60.2695, GNorm = 2.0665, lr_0 = 1.0000e-04
Loss = 7.8840e-04, PNorm = 60.2708, GNorm = 1.5270, lr_0 = 1.0000e-04
Loss = 3.2472e-04, PNorm = 60.2722, GNorm = 1.1395, lr_0 = 1.0000e-04
Loss = 5.5076e-04, PNorm = 60.2722, GNorm = 1.2130, lr_0 = 1.0000e-04
Loss = 4.8814e-04, PNorm = 60.2735, GNorm = 0.9471, lr_0 = 1.0000e-04
Loss = 4.1998e-04, PNorm = 60.2750, GNorm = 1.0212, lr_0 = 1.0000e-04
Loss = 4.9219e-04, PNorm = 60.2776, GNorm = 1.3511, lr_0 = 1.0000e-04
Loss = 4.0768e-04, PNorm = 60.2789, GNorm = 1.9671, lr_0 = 1.0000e-04
Loss = 5.1419e-04, PNorm = 60.2799, GNorm = 1.5467, lr_0 = 1.0000e-04
Loss = 6.0123e-04, PNorm = 60.2803, GNorm = 0.9935, lr_0 = 1.0000e-04
Loss = 4.5587e-04, PNorm = 60.2810, GNorm = 1.5233, lr_0 = 1.0000e-04
Loss = 5.4059e-04, PNorm = 60.2827, GNorm = 1.2540, lr_0 = 1.0000e-04
Loss = 5.3220e-04, PNorm = 60.2843, GNorm = 0.6461, lr_0 = 1.0000e-04
Loss = 4.3477e-04, PNorm = 60.2859, GNorm = 0.8404, lr_0 = 1.0000e-04
Loss = 4.1353e-04, PNorm = 60.2874, GNorm = 1.2768, lr_0 = 1.0000e-04
Loss = 5.4297e-04, PNorm = 60.2883, GNorm = 0.7641, lr_0 = 1.0000e-04
Loss = 7.0544e-04, PNorm = 60.2908, GNorm = 2.0384, lr_0 = 1.0000e-04
Loss = 5.4375e-04, PNorm = 60.2929, GNorm = 1.1666, lr_0 = 1.0000e-04
Loss = 5.8414e-04, PNorm = 60.2940, GNorm = 0.9190, lr_0 = 1.0000e-04
Loss = 3.9980e-04, PNorm = 60.2952, GNorm = 1.5323, lr_0 = 1.0000e-04
Loss = 4.5630e-04, PNorm = 60.2966, GNorm = 0.8621, lr_0 = 1.0000e-04
Loss = 5.0736e-04, PNorm = 60.2979, GNorm = 1.0373, lr_0 = 1.0000e-04
Validation rmse = 4.149082
Validation R2 = -3.776927
Epoch 83
Train function
Loss = 5.2003e-04, PNorm = 60.2991, GNorm = 1.0479, lr_0 = 1.0000e-04
Loss = 4.2163e-04, PNorm = 60.3004, GNorm = 1.7209, lr_0 = 1.0000e-04
Loss = 3.7913e-04, PNorm = 60.3016, GNorm = 0.8325, lr_0 = 1.0000e-04
Loss = 5.0920e-04, PNorm = 60.3030, GNorm = 0.8017, lr_0 = 1.0000e-04
Loss = 5.8148e-04, PNorm = 60.3042, GNorm = 1.0541, lr_0 = 1.0000e-04
Loss = 5.8779e-04, PNorm = 60.3050, GNorm = 2.4744, lr_0 = 1.0000e-04
Loss = 4.6412e-04, PNorm = 60.3059, GNorm = 0.9418, lr_0 = 1.0000e-04
Loss = 4.0018e-04, PNorm = 60.3062, GNorm = 0.8726, lr_0 = 1.0000e-04
Loss = 5.2307e-04, PNorm = 60.3074, GNorm = 1.4310, lr_0 = 1.0000e-04
Loss = 8.1503e-04, PNorm = 60.3094, GNorm = 0.7087, lr_0 = 1.0000e-04
Loss = 3.8049e-04, PNorm = 60.3101, GNorm = 1.1717, lr_0 = 1.0000e-04
Loss = 4.3816e-04, PNorm = 60.3114, GNorm = 1.5398, lr_0 = 1.0000e-04
Loss = 5.0739e-04, PNorm = 60.3130, GNorm = 1.2337, lr_0 = 1.0000e-04
Loss = 7.0596e-04, PNorm = 60.3146, GNorm = 1.7762, lr_0 = 1.0000e-04
Loss = 6.1746e-04, PNorm = 60.3158, GNorm = 0.6510, lr_0 = 1.0000e-04
Loss = 4.3664e-04, PNorm = 60.3177, GNorm = 0.9120, lr_0 = 1.0000e-04
Loss = 6.1684e-04, PNorm = 60.3197, GNorm = 1.0785, lr_0 = 1.0000e-04
Loss = 4.6605e-04, PNorm = 60.3217, GNorm = 1.8631, lr_0 = 1.0000e-04
Loss = 4.1711e-04, PNorm = 60.3228, GNorm = 1.6233, lr_0 = 1.0000e-04
Loss = 3.6559e-04, PNorm = 60.3237, GNorm = 1.5264, lr_0 = 1.0000e-04
Loss = 6.0551e-04, PNorm = 60.3253, GNorm = 1.6332, lr_0 = 1.0000e-04
Loss = 3.6042e-04, PNorm = 60.3264, GNorm = 0.6268, lr_0 = 1.0000e-04
Loss = 2.9263e-04, PNorm = 60.3278, GNorm = 0.6800, lr_0 = 1.0000e-04
Loss = 5.3526e-04, PNorm = 60.3290, GNorm = 1.1069, lr_0 = 1.0000e-04
Validation rmse = 3.984941
Validation R2 = -3.406445
Epoch 84
Train function
Loss = 6.6406e-04, PNorm = 60.3302, GNorm = 2.2834, lr_0 = 1.0000e-04
Loss = 3.9316e-04, PNorm = 60.3309, GNorm = 0.8656, lr_0 = 1.0000e-04
Loss = 4.2205e-04, PNorm = 60.3314, GNorm = 0.8544, lr_0 = 1.0000e-04
Loss = 3.8910e-04, PNorm = 60.3327, GNorm = 1.0722, lr_0 = 1.0000e-04
Loss = 3.6333e-04, PNorm = 60.3342, GNorm = 1.3624, lr_0 = 1.0000e-04
Loss = 5.5713e-04, PNorm = 60.3351, GNorm = 0.9143, lr_0 = 1.0000e-04
Loss = 3.4249e-04, PNorm = 60.3358, GNorm = 1.0694, lr_0 = 1.0000e-04
Loss = 4.2376e-04, PNorm = 60.3370, GNorm = 1.6613, lr_0 = 1.0000e-04
Loss = 3.7061e-04, PNorm = 60.3383, GNorm = 0.7817, lr_0 = 1.0000e-04
Loss = 3.1930e-04, PNorm = 60.3393, GNorm = 0.7926, lr_0 = 1.0000e-04
Loss = 4.2223e-04, PNorm = 60.3402, GNorm = 1.3351, lr_0 = 1.0000e-04
Loss = 6.0557e-04, PNorm = 60.3407, GNorm = 1.2112, lr_0 = 1.0000e-04
Loss = 3.7376e-04, PNorm = 60.3415, GNorm = 1.3890, lr_0 = 1.0000e-04
Loss = 4.7287e-04, PNorm = 60.3423, GNorm = 1.3306, lr_0 = 1.0000e-04
Loss = 5.7289e-04, PNorm = 60.3437, GNorm = 1.3805, lr_0 = 1.0000e-04
Loss = 8.1424e-04, PNorm = 60.3448, GNorm = 2.2336, lr_0 = 1.0000e-04
Loss = 4.5368e-04, PNorm = 60.3469, GNorm = 1.2636, lr_0 = 1.0000e-04
Loss = 5.1238e-04, PNorm = 60.3484, GNorm = 2.0656, lr_0 = 1.0000e-04
Loss = 7.2437e-04, PNorm = 60.3510, GNorm = 1.1154, lr_0 = 1.0000e-04
Loss = 1.2564e-03, PNorm = 60.3518, GNorm = 1.2897, lr_0 = 1.0000e-04
Loss = 6.0972e-04, PNorm = 60.3528, GNorm = 0.7912, lr_0 = 1.0000e-04
Loss = 4.1571e-04, PNorm = 60.3546, GNorm = 0.9791, lr_0 = 1.0000e-04
Loss = 4.8337e-04, PNorm = 60.3559, GNorm = 1.2517, lr_0 = 1.0000e-04
Validation rmse = 4.148066
Validation R2 = -3.774587
Epoch 85
Train function
Loss = 5.0742e-04, PNorm = 60.3575, GNorm = 1.3376, lr_0 = 1.0000e-04
Loss = 4.0858e-04, PNorm = 60.3590, GNorm = 1.8950, lr_0 = 1.0000e-04
Loss = 4.3396e-04, PNorm = 60.3598, GNorm = 1.3544, lr_0 = 1.0000e-04
Loss = 5.1405e-04, PNorm = 60.3612, GNorm = 1.4600, lr_0 = 1.0000e-04
Loss = 7.0358e-04, PNorm = 60.3627, GNorm = 2.2714, lr_0 = 1.0000e-04
Loss = 4.5092e-04, PNorm = 60.3643, GNorm = 1.5245, lr_0 = 1.0000e-04
Loss = 5.5014e-04, PNorm = 60.3653, GNorm = 1.8435, lr_0 = 1.0000e-04
Loss = 5.0579e-04, PNorm = 60.3661, GNorm = 0.6590, lr_0 = 1.0000e-04
Loss = 3.8389e-04, PNorm = 60.3673, GNorm = 2.5540, lr_0 = 1.0000e-04
Loss = 3.8568e-04, PNorm = 60.3683, GNorm = 1.4370, lr_0 = 1.0000e-04
Loss = 6.2170e-04, PNorm = 60.3693, GNorm = 4.2592, lr_0 = 1.0000e-04
Loss = 5.2210e-04, PNorm = 60.3706, GNorm = 1.9573, lr_0 = 1.0000e-04
Loss = 5.4338e-04, PNorm = 60.3718, GNorm = 2.8675, lr_0 = 1.0000e-04
Loss = 4.3638e-04, PNorm = 60.3731, GNorm = 1.1232, lr_0 = 1.0000e-04
Loss = 5.4433e-04, PNorm = 60.3745, GNorm = 1.0661, lr_0 = 1.0000e-04
Loss = 4.6889e-04, PNorm = 60.3755, GNorm = 1.3361, lr_0 = 1.0000e-04
Loss = 4.0363e-04, PNorm = 60.3770, GNorm = 1.2838, lr_0 = 1.0000e-04
Loss = 3.5480e-04, PNorm = 60.3777, GNorm = 1.4305, lr_0 = 1.0000e-04
Loss = 5.2803e-04, PNorm = 60.3790, GNorm = 1.2979, lr_0 = 1.0000e-04
Loss = 4.2742e-04, PNorm = 60.3810, GNorm = 1.0708, lr_0 = 1.0000e-04
Loss = 2.7076e-04, PNorm = 60.3816, GNorm = 1.0989, lr_0 = 1.0000e-04
Loss = 4.6949e-04, PNorm = 60.3826, GNorm = 1.0219, lr_0 = 1.0000e-04
Loss = 5.3561e-04, PNorm = 60.3838, GNorm = 1.7454, lr_0 = 1.0000e-04
Loss = 4.5788e-04, PNorm = 60.3844, GNorm = 1.1476, lr_0 = 1.0000e-04
Validation rmse = 4.225127
Validation R2 = -3.953636
Epoch 86
Train function
Loss = 3.5206e-04, PNorm = 60.3853, GNorm = 2.0138, lr_0 = 1.0000e-04
Loss = 3.4992e-04, PNorm = 60.3859, GNorm = 1.3131, lr_0 = 1.0000e-04
Loss = 5.4902e-04, PNorm = 60.3877, GNorm = 3.7739, lr_0 = 1.0000e-04
Loss = 6.7692e-04, PNorm = 60.3895, GNorm = 1.7187, lr_0 = 1.0000e-04
Loss = 4.6333e-04, PNorm = 60.3909, GNorm = 1.1009, lr_0 = 1.0000e-04
Loss = 3.8525e-04, PNorm = 60.3922, GNorm = 1.1030, lr_0 = 1.0000e-04
Loss = 7.0639e-04, PNorm = 60.3922, GNorm = 1.4128, lr_0 = 1.0000e-04
Loss = 3.4912e-04, PNorm = 60.3929, GNorm = 0.9234, lr_0 = 1.0000e-04
Loss = 3.6260e-04, PNorm = 60.3938, GNorm = 0.8903, lr_0 = 1.0000e-04
Loss = 5.5626e-04, PNorm = 60.3953, GNorm = 1.5448, lr_0 = 1.0000e-04
Loss = 4.0014e-04, PNorm = 60.3963, GNorm = 1.6999, lr_0 = 1.0000e-04
Loss = 4.7495e-04, PNorm = 60.3980, GNorm = 0.8268, lr_0 = 1.0000e-04
Loss = 3.9498e-04, PNorm = 60.3987, GNorm = 1.5738, lr_0 = 1.0000e-04
Loss = 4.3534e-04, PNorm = 60.3995, GNorm = 1.4214, lr_0 = 1.0000e-04
Loss = 5.0760e-04, PNorm = 60.4010, GNorm = 1.4123, lr_0 = 1.0000e-04
Loss = 4.5926e-04, PNorm = 60.4025, GNorm = 1.6868, lr_0 = 1.0000e-04
Loss = 4.3484e-04, PNorm = 60.4042, GNorm = 0.7972, lr_0 = 1.0000e-04
Loss = 8.8911e-04, PNorm = 60.4058, GNorm = 1.3465, lr_0 = 1.0000e-04
Loss = 4.6669e-04, PNorm = 60.4070, GNorm = 1.1707, lr_0 = 1.0000e-04
Loss = 4.2551e-04, PNorm = 60.4078, GNorm = 0.8507, lr_0 = 1.0000e-04
Loss = 3.8173e-04, PNorm = 60.4089, GNorm = 1.2435, lr_0 = 1.0000e-04
Loss = 3.2976e-04, PNorm = 60.4100, GNorm = 1.3555, lr_0 = 1.0000e-04
Loss = 3.7324e-04, PNorm = 60.4110, GNorm = 1.0524, lr_0 = 1.0000e-04
Validation rmse = 4.303049
Validation R2 = -4.138036
Epoch 87
Train function
Loss = 2.2877e-04, PNorm = 60.4107, GNorm = 0.9098, lr_0 = 1.0000e-04
Loss = 3.4106e-04, PNorm = 60.4108, GNorm = 1.3465, lr_0 = 1.0000e-04
Loss = 6.1056e-04, PNorm = 60.4115, GNorm = 1.1789, lr_0 = 1.0000e-04
Loss = 2.9393e-04, PNorm = 60.4124, GNorm = 0.7617, lr_0 = 1.0000e-04
Loss = 3.8609e-04, PNorm = 60.4132, GNorm = 1.0479, lr_0 = 1.0000e-04
Loss = 4.5117e-04, PNorm = 60.4149, GNorm = 1.1031, lr_0 = 1.0000e-04
Loss = 3.6770e-04, PNorm = 60.4159, GNorm = 1.1421, lr_0 = 1.0000e-04
Loss = 3.3807e-04, PNorm = 60.4167, GNorm = 0.7973, lr_0 = 1.0000e-04
Loss = 4.4858e-04, PNorm = 60.4181, GNorm = 1.0893, lr_0 = 1.0000e-04
Loss = 3.8025e-04, PNorm = 60.4195, GNorm = 1.0975, lr_0 = 1.0000e-04
Loss = 3.7561e-04, PNorm = 60.4205, GNorm = 1.8126, lr_0 = 1.0000e-04
Loss = 4.4857e-04, PNorm = 60.4210, GNorm = 0.6710, lr_0 = 1.0000e-04
Loss = 4.9471e-04, PNorm = 60.4218, GNorm = 1.0480, lr_0 = 1.0000e-04
Loss = 3.7558e-04, PNorm = 60.4227, GNorm = 1.0358, lr_0 = 1.0000e-04
Loss = 3.9641e-04, PNorm = 60.4242, GNorm = 2.1625, lr_0 = 1.0000e-04
Loss = 2.6385e-04, PNorm = 60.4252, GNorm = 0.8090, lr_0 = 1.0000e-04
Loss = 3.5745e-04, PNorm = 60.4257, GNorm = 2.3523, lr_0 = 1.0000e-04
Loss = 6.1451e-04, PNorm = 60.4269, GNorm = 1.8688, lr_0 = 1.0000e-04
Loss = 7.4028e-04, PNorm = 60.4286, GNorm = 1.8217, lr_0 = 1.0000e-04
Loss = 4.0197e-04, PNorm = 60.4302, GNorm = 1.3431, lr_0 = 1.0000e-04
Loss = 4.6791e-04, PNorm = 60.4310, GNorm = 1.2284, lr_0 = 1.0000e-04
Loss = 5.6821e-04, PNorm = 60.4320, GNorm = 1.7171, lr_0 = 1.0000e-04
Loss = 4.6897e-04, PNorm = 60.4336, GNorm = 1.3374, lr_0 = 1.0000e-04
Validation rmse = 4.287801
Validation R2 = -4.101688
Epoch 88
Train function
Loss = 9.9355e-04, PNorm = 60.4350, GNorm = 2.1940, lr_0 = 1.0000e-04
Loss = 3.6099e-04, PNorm = 60.4365, GNorm = 1.1762, lr_0 = 1.0000e-04
Loss = 2.7779e-04, PNorm = 60.4373, GNorm = 0.7262, lr_0 = 1.0000e-04
Loss = 5.3750e-04, PNorm = 60.4374, GNorm = 1.0481, lr_0 = 1.0000e-04
Loss = 3.4101e-04, PNorm = 60.4379, GNorm = 1.0181, lr_0 = 1.0000e-04
Loss = 6.6313e-04, PNorm = 60.4389, GNorm = 2.3217, lr_0 = 1.0000e-04
Loss = 5.5278e-04, PNorm = 60.4400, GNorm = 2.1719, lr_0 = 1.0000e-04
Loss = 3.5211e-04, PNorm = 60.4412, GNorm = 1.4533, lr_0 = 1.0000e-04
Loss = 5.5981e-04, PNorm = 60.4426, GNorm = 1.0345, lr_0 = 1.0000e-04
Loss = 4.0012e-04, PNorm = 60.4434, GNorm = 0.8156, lr_0 = 1.0000e-04
Loss = 3.6808e-04, PNorm = 60.4448, GNorm = 0.8651, lr_0 = 1.0000e-04
Loss = 5.0837e-04, PNorm = 60.4462, GNorm = 1.7329, lr_0 = 1.0000e-04
Loss = 4.1851e-04, PNorm = 60.4470, GNorm = 1.3303, lr_0 = 1.0000e-04
Loss = 3.5187e-04, PNorm = 60.4481, GNorm = 1.0839, lr_0 = 1.0000e-04
Loss = 6.1991e-04, PNorm = 60.4493, GNorm = 0.8886, lr_0 = 1.0000e-04
Loss = 5.1753e-04, PNorm = 60.4501, GNorm = 1.0722, lr_0 = 1.0000e-04
Loss = 3.9024e-04, PNorm = 60.4514, GNorm = 1.0359, lr_0 = 1.0000e-04
Loss = 4.9606e-04, PNorm = 60.4525, GNorm = 1.1753, lr_0 = 1.0000e-04
Loss = 3.3216e-04, PNorm = 60.4535, GNorm = 1.0895, lr_0 = 1.0000e-04
Loss = 3.7889e-04, PNorm = 60.4545, GNorm = 3.1150, lr_0 = 1.0000e-04
Loss = 6.3510e-04, PNorm = 60.4552, GNorm = 1.3843, lr_0 = 1.0000e-04
Loss = 4.3916e-04, PNorm = 60.4563, GNorm = 1.2028, lr_0 = 1.0000e-04
Loss = 4.2387e-04, PNorm = 60.4565, GNorm = 1.4164, lr_0 = 1.0000e-04
Loss = 4.0037e-04, PNorm = 60.4584, GNorm = 1.0077, lr_0 = 1.0000e-04
Validation rmse = 4.316225
Validation R2 = -4.169550
Epoch 89
Train function
Loss = 2.7627e-04, PNorm = 60.4592, GNorm = 0.9106, lr_0 = 1.0000e-04
Loss = 4.2199e-04, PNorm = 60.4598, GNorm = 0.6598, lr_0 = 1.0000e-04
Loss = 5.1284e-04, PNorm = 60.4614, GNorm = 0.6040, lr_0 = 1.0000e-04
Loss = 3.3254e-04, PNorm = 60.4627, GNorm = 1.2305, lr_0 = 1.0000e-04
Loss = 3.3486e-04, PNorm = 60.4628, GNorm = 0.7573, lr_0 = 1.0000e-04
Loss = 3.0807e-04, PNorm = 60.4631, GNorm = 1.0052, lr_0 = 1.0000e-04
Loss = 4.1289e-04, PNorm = 60.4638, GNorm = 0.9011, lr_0 = 1.0000e-04
Loss = 4.9046e-04, PNorm = 60.4641, GNorm = 0.7671, lr_0 = 1.0000e-04
Loss = 4.4963e-04, PNorm = 60.4660, GNorm = 1.1990, lr_0 = 1.0000e-04
Loss = 4.4563e-04, PNorm = 60.4670, GNorm = 1.6162, lr_0 = 1.0000e-04
Loss = 3.9791e-04, PNorm = 60.4681, GNorm = 0.8319, lr_0 = 1.0000e-04
Loss = 3.9788e-04, PNorm = 60.4693, GNorm = 0.8740, lr_0 = 1.0000e-04
Loss = 4.2722e-04, PNorm = 60.4706, GNorm = 1.4865, lr_0 = 1.0000e-04
Loss = 3.6340e-04, PNorm = 60.4711, GNorm = 1.1107, lr_0 = 1.0000e-04
Loss = 3.4782e-04, PNorm = 60.4716, GNorm = 0.9804, lr_0 = 1.0000e-04
Loss = 3.8671e-04, PNorm = 60.4724, GNorm = 1.7845, lr_0 = 1.0000e-04
Loss = 7.6468e-04, PNorm = 60.4730, GNorm = 0.7359, lr_0 = 1.0000e-04
Loss = 5.3959e-04, PNorm = 60.4742, GNorm = 0.8624, lr_0 = 1.0000e-04
Loss = 3.8549e-04, PNorm = 60.4757, GNorm = 1.1651, lr_0 = 1.0000e-04
Loss = 3.3535e-04, PNorm = 60.4767, GNorm = 1.0271, lr_0 = 1.0000e-04
Loss = 4.1158e-04, PNorm = 60.4781, GNorm = 0.6893, lr_0 = 1.0000e-04
Loss = 4.4234e-04, PNorm = 60.4792, GNorm = 1.0429, lr_0 = 1.0000e-04
Loss = 5.1945e-04, PNorm = 60.4808, GNorm = 0.9622, lr_0 = 1.0000e-04
Validation rmse = 4.218124
Validation R2 = -3.937228
Epoch 90
Train function
Loss = 1.6669e-04, PNorm = 60.4818, GNorm = 0.7156, lr_0 = 1.0000e-04
Loss = 3.8824e-04, PNorm = 60.4827, GNorm = 0.7154, lr_0 = 1.0000e-04
Loss = 3.2183e-04, PNorm = 60.4835, GNorm = 1.3446, lr_0 = 1.0000e-04
Loss = 3.9736e-04, PNorm = 60.4846, GNorm = 0.8984, lr_0 = 1.0000e-04
Loss = 4.1066e-04, PNorm = 60.4854, GNorm = 3.7283, lr_0 = 1.0000e-04
Loss = 3.5019e-04, PNorm = 60.4857, GNorm = 1.4596, lr_0 = 1.0000e-04
Loss = 4.3040e-04, PNorm = 60.4871, GNorm = 1.2978, lr_0 = 1.0000e-04
Loss = 4.0813e-04, PNorm = 60.4885, GNorm = 0.7854, lr_0 = 1.0000e-04
Loss = 4.2898e-04, PNorm = 60.4906, GNorm = 1.5232, lr_0 = 1.0000e-04
Loss = 3.8058e-04, PNorm = 60.4920, GNorm = 1.0359, lr_0 = 1.0000e-04
Loss = 6.0619e-04, PNorm = 60.4932, GNorm = 1.1045, lr_0 = 1.0000e-04
Loss = 4.6785e-04, PNorm = 60.4947, GNorm = 2.0244, lr_0 = 1.0000e-04
Loss = 3.5297e-04, PNorm = 60.4960, GNorm = 0.8502, lr_0 = 1.0000e-04
Loss = 4.6652e-04, PNorm = 60.4970, GNorm = 1.2315, lr_0 = 1.0000e-04
Loss = 4.3371e-04, PNorm = 60.4982, GNorm = 0.7899, lr_0 = 1.0000e-04
Loss = 5.4325e-04, PNorm = 60.4996, GNorm = 1.0217, lr_0 = 1.0000e-04
Loss = 4.0122e-04, PNorm = 60.5019, GNorm = 0.6383, lr_0 = 1.0000e-04
Loss = 5.0307e-04, PNorm = 60.5036, GNorm = 1.2793, lr_0 = 1.0000e-04
Loss = 2.5539e-04, PNorm = 60.5046, GNorm = 0.9701, lr_0 = 1.0000e-04
Loss = 3.5690e-04, PNorm = 60.5054, GNorm = 1.2185, lr_0 = 1.0000e-04
Loss = 4.4285e-04, PNorm = 60.5065, GNorm = 1.1912, lr_0 = 1.0000e-04
Loss = 4.0122e-04, PNorm = 60.5071, GNorm = 0.7523, lr_0 = 1.0000e-04
Loss = 4.1086e-04, PNorm = 60.5077, GNorm = 1.6334, lr_0 = 1.0000e-04
Loss = 5.9985e-04, PNorm = 60.5090, GNorm = 1.3549, lr_0 = 1.0000e-04
Validation rmse = 4.281761
Validation R2 = -4.087325
Epoch 91
Train function
Loss = 2.8985e-04, PNorm = 60.5100, GNorm = 0.7233, lr_0 = 1.0000e-04
Loss = 3.7004e-04, PNorm = 60.5103, GNorm = 0.9104, lr_0 = 1.0000e-04
Loss = 3.3739e-04, PNorm = 60.5112, GNorm = 1.6066, lr_0 = 1.0000e-04
Loss = 2.9172e-04, PNorm = 60.5123, GNorm = 1.1475, lr_0 = 1.0000e-04
Loss = 4.2050e-04, PNorm = 60.5131, GNorm = 1.0285, lr_0 = 1.0000e-04
Loss = 3.5899e-04, PNorm = 60.5144, GNorm = 1.2070, lr_0 = 1.0000e-04
Loss = 3.8877e-04, PNorm = 60.5152, GNorm = 0.8452, lr_0 = 1.0000e-04
Loss = 5.3677e-04, PNorm = 60.5165, GNorm = 1.6947, lr_0 = 1.0000e-04
Loss = 4.5836e-04, PNorm = 60.5171, GNorm = 0.9355, lr_0 = 1.0000e-04
Loss = 4.9289e-04, PNorm = 60.5191, GNorm = 1.5787, lr_0 = 1.0000e-04
Loss = 6.0893e-04, PNorm = 60.5197, GNorm = 1.1533, lr_0 = 1.0000e-04
Loss = 3.6468e-04, PNorm = 60.5203, GNorm = 1.0565, lr_0 = 1.0000e-04
Loss = 2.9390e-04, PNorm = 60.5214, GNorm = 0.8334, lr_0 = 1.0000e-04
Loss = 5.3647e-04, PNorm = 60.5228, GNorm = 1.1291, lr_0 = 1.0000e-04
Loss = 3.1506e-04, PNorm = 60.5241, GNorm = 1.0050, lr_0 = 1.0000e-04
Loss = 2.9840e-04, PNorm = 60.5244, GNorm = 0.6962, lr_0 = 1.0000e-04
Loss = 6.0902e-04, PNorm = 60.5245, GNorm = 1.0502, lr_0 = 1.0000e-04
Loss = 6.2304e-04, PNorm = 60.5240, GNorm = 1.5586, lr_0 = 1.0000e-04
Loss = 4.4687e-04, PNorm = 60.5251, GNorm = 1.3513, lr_0 = 1.0000e-04
Loss = 4.4574e-04, PNorm = 60.5262, GNorm = 1.4703, lr_0 = 1.0000e-04
Loss = 4.9378e-04, PNorm = 60.5279, GNorm = 1.8119, lr_0 = 1.0000e-04
Loss = 4.6454e-04, PNorm = 60.5300, GNorm = 1.4385, lr_0 = 1.0000e-04
Loss = 3.7776e-04, PNorm = 60.5311, GNorm = 0.6312, lr_0 = 1.0000e-04
Validation rmse = 4.194335
Validation R2 = -3.881697
Epoch 92
Train function
Loss = 3.5315e-04, PNorm = 60.5319, GNorm = 1.2742, lr_0 = 1.0000e-04
Loss = 2.4654e-04, PNorm = 60.5320, GNorm = 0.6117, lr_0 = 1.0000e-04
Loss = 3.4779e-04, PNorm = 60.5323, GNorm = 0.8588, lr_0 = 1.0000e-04
Loss = 4.5972e-04, PNorm = 60.5328, GNorm = 1.3368, lr_0 = 1.0000e-04
Loss = 3.3088e-04, PNorm = 60.5340, GNorm = 1.0231, lr_0 = 1.0000e-04
Loss = 4.8500e-04, PNorm = 60.5355, GNorm = 1.1537, lr_0 = 1.0000e-04
Loss = 3.3960e-04, PNorm = 60.5362, GNorm = 1.3680, lr_0 = 1.0000e-04
Loss = 3.5083e-04, PNorm = 60.5369, GNorm = 0.9301, lr_0 = 1.0000e-04
Loss = 3.0746e-04, PNorm = 60.5380, GNorm = 1.0333, lr_0 = 1.0000e-04
Loss = 4.2928e-04, PNorm = 60.5388, GNorm = 1.5786, lr_0 = 1.0000e-04
Loss = 4.1538e-04, PNorm = 60.5400, GNorm = 1.8347, lr_0 = 1.0000e-04
Loss = 3.5686e-04, PNorm = 60.5414, GNorm = 1.0463, lr_0 = 1.0000e-04
Loss = 4.2937e-04, PNorm = 60.5423, GNorm = 0.9688, lr_0 = 1.0000e-04
Loss = 4.0697e-04, PNorm = 60.5431, GNorm = 0.7540, lr_0 = 1.0000e-04
Loss = 3.3879e-04, PNorm = 60.5443, GNorm = 1.4469, lr_0 = 1.0000e-04
Loss = 2.9132e-04, PNorm = 60.5449, GNorm = 1.1587, lr_0 = 1.0000e-04
Loss = 6.8695e-04, PNorm = 60.5462, GNorm = 0.8240, lr_0 = 1.0000e-04
Loss = 4.8743e-04, PNorm = 60.5466, GNorm = 1.0106, lr_0 = 1.0000e-04
Loss = 4.7152e-04, PNorm = 60.5472, GNorm = 0.9340, lr_0 = 1.0000e-04
Loss = 2.9696e-04, PNorm = 60.5476, GNorm = 1.4184, lr_0 = 1.0000e-04
Loss = 3.8959e-04, PNorm = 60.5485, GNorm = 1.0170, lr_0 = 1.0000e-04
Loss = 3.3157e-04, PNorm = 60.5500, GNorm = 0.8221, lr_0 = 1.0000e-04
Loss = 3.2852e-04, PNorm = 60.5507, GNorm = 1.2688, lr_0 = 1.0000e-04
Loss = 5.8170e-04, PNorm = 60.5513, GNorm = 1.8407, lr_0 = 1.0000e-04
Loss = 6.8947e-03, PNorm = 60.5517, GNorm = 5.1203, lr_0 = 1.0000e-04
Validation rmse = 4.180145
Validation R2 = -3.848721
Epoch 93
Train function
Loss = 3.6771e-04, PNorm = 60.5538, GNorm = 1.4611, lr_0 = 1.0000e-04
Loss = 3.8231e-04, PNorm = 60.5553, GNorm = 1.1237, lr_0 = 1.0000e-04
Loss = 3.9696e-04, PNorm = 60.5568, GNorm = 1.2309, lr_0 = 1.0000e-04
Loss = 3.8372e-04, PNorm = 60.5580, GNorm = 1.0518, lr_0 = 1.0000e-04
Loss = 3.2402e-04, PNorm = 60.5591, GNorm = 0.7887, lr_0 = 1.0000e-04
Loss = 3.3324e-04, PNorm = 60.5593, GNorm = 0.7171, lr_0 = 1.0000e-04
Loss = 3.7161e-04, PNorm = 60.5600, GNorm = 0.8821, lr_0 = 1.0000e-04
Loss = 3.6691e-04, PNorm = 60.5612, GNorm = 1.1907, lr_0 = 1.0000e-04
Loss = 2.9025e-04, PNorm = 60.5622, GNorm = 0.9365, lr_0 = 1.0000e-04
Loss = 4.7064e-04, PNorm = 60.5630, GNorm = 1.4397, lr_0 = 1.0000e-04
Loss = 4.3338e-04, PNorm = 60.5651, GNorm = 1.2001, lr_0 = 1.0000e-04
Loss = 3.0271e-04, PNorm = 60.5665, GNorm = 0.9580, lr_0 = 1.0000e-04
Loss = 7.1157e-04, PNorm = 60.5676, GNorm = 0.9556, lr_0 = 1.0000e-04
Loss = 3.8565e-04, PNorm = 60.5692, GNorm = 0.8924, lr_0 = 1.0000e-04
Loss = 3.6154e-04, PNorm = 60.5702, GNorm = 1.6032, lr_0 = 1.0000e-04
Loss = 3.9823e-04, PNorm = 60.5710, GNorm = 0.7662, lr_0 = 1.0000e-04
Loss = 3.7926e-04, PNorm = 60.5721, GNorm = 1.9033, lr_0 = 1.0000e-04
Loss = 2.9445e-04, PNorm = 60.5734, GNorm = 1.1823, lr_0 = 1.0000e-04
Loss = 3.9397e-04, PNorm = 60.5751, GNorm = 1.6971, lr_0 = 1.0000e-04
Loss = 5.1500e-04, PNorm = 60.5769, GNorm = 1.4516, lr_0 = 1.0000e-04
Loss = 3.6923e-04, PNorm = 60.5780, GNorm = 1.3094, lr_0 = 1.0000e-04
Loss = 4.0589e-04, PNorm = 60.5792, GNorm = 0.8402, lr_0 = 1.0000e-04
Loss = 3.4909e-04, PNorm = 60.5805, GNorm = 1.8321, lr_0 = 1.0000e-04
Validation rmse = 4.173231
Validation R2 = -3.832696
Epoch 94
Train function
Loss = 3.3423e-04, PNorm = 60.5815, GNorm = 1.0883, lr_0 = 1.0000e-04
Loss = 2.6896e-04, PNorm = 60.5825, GNorm = 1.0397, lr_0 = 1.0000e-04
Loss = 3.3057e-04, PNorm = 60.5836, GNorm = 1.1527, lr_0 = 1.0000e-04
Loss = 3.1622e-04, PNorm = 60.5838, GNorm = 0.8574, lr_0 = 1.0000e-04
Loss = 2.6438e-04, PNorm = 60.5843, GNorm = 1.1951, lr_0 = 1.0000e-04
Loss = 3.0742e-04, PNorm = 60.5855, GNorm = 1.3943, lr_0 = 1.0000e-04
Loss = 2.8998e-04, PNorm = 60.5862, GNorm = 1.9451, lr_0 = 1.0000e-04
Loss = 3.5332e-04, PNorm = 60.5867, GNorm = 1.3598, lr_0 = 1.0000e-04
Loss = 6.6360e-04, PNorm = 60.5868, GNorm = 2.1260, lr_0 = 1.0000e-04
Loss = 4.1575e-04, PNorm = 60.5879, GNorm = 1.5550, lr_0 = 1.0000e-04
Loss = 3.6554e-04, PNorm = 60.5889, GNorm = 0.5916, lr_0 = 1.0000e-04
Loss = 2.9013e-04, PNorm = 60.5896, GNorm = 1.3074, lr_0 = 1.0000e-04
Loss = 4.8863e-04, PNorm = 60.5910, GNorm = 2.2908, lr_0 = 1.0000e-04
Loss = 4.8075e-04, PNorm = 60.5918, GNorm = 1.0818, lr_0 = 1.0000e-04
Loss = 3.4011e-04, PNorm = 60.5928, GNorm = 0.9060, lr_0 = 1.0000e-04
Loss = 3.1063e-04, PNorm = 60.5931, GNorm = 1.3054, lr_0 = 1.0000e-04
Loss = 3.5793e-04, PNorm = 60.5933, GNorm = 0.9592, lr_0 = 1.0000e-04
Loss = 3.2256e-04, PNorm = 60.5938, GNorm = 1.0845, lr_0 = 1.0000e-04
Loss = 2.7983e-04, PNorm = 60.5946, GNorm = 0.7277, lr_0 = 1.0000e-04
Loss = 3.9528e-04, PNorm = 60.5956, GNorm = 0.8270, lr_0 = 1.0000e-04
Loss = 3.8134e-04, PNorm = 60.5963, GNorm = 0.8768, lr_0 = 1.0000e-04
Loss = 6.9597e-04, PNorm = 60.5973, GNorm = 1.8011, lr_0 = 1.0000e-04
Loss = 3.8467e-04, PNorm = 60.5987, GNorm = 1.1433, lr_0 = 1.0000e-04
Validation rmse = 4.199442
Validation R2 = -3.893592
Epoch 95
Train function
Loss = 3.4642e-04, PNorm = 60.6008, GNorm = 0.8430, lr_0 = 1.0000e-04
Loss = 3.5583e-04, PNorm = 60.6025, GNorm = 0.6639, lr_0 = 1.0000e-04
Loss = 3.4777e-04, PNorm = 60.6040, GNorm = 0.6902, lr_0 = 1.0000e-04
Loss = 3.6268e-04, PNorm = 60.6052, GNorm = 0.8977, lr_0 = 1.0000e-04
Loss = 2.5981e-04, PNorm = 60.6068, GNorm = 1.6020, lr_0 = 1.0000e-04
Loss = 2.3666e-04, PNorm = 60.6077, GNorm = 1.0705, lr_0 = 1.0000e-04
Loss = 4.6061e-04, PNorm = 60.6082, GNorm = 0.5907, lr_0 = 1.0000e-04
Loss = 3.3053e-04, PNorm = 60.6084, GNorm = 1.2181, lr_0 = 1.0000e-04
Loss = 2.3524e-04, PNorm = 60.6090, GNorm = 0.8568, lr_0 = 1.0000e-04
Loss = 2.6252e-04, PNorm = 60.6103, GNorm = 0.6630, lr_0 = 1.0000e-04
Loss = 4.7594e-04, PNorm = 60.6117, GNorm = 2.6949, lr_0 = 1.0000e-04
Loss = 6.0249e-04, PNorm = 60.6130, GNorm = 1.3595, lr_0 = 1.0000e-04
Loss = 3.6568e-04, PNorm = 60.6143, GNorm = 0.7686, lr_0 = 1.0000e-04
Loss = 3.7982e-04, PNorm = 60.6152, GNorm = 1.3817, lr_0 = 1.0000e-04
Loss = 3.2810e-04, PNorm = 60.6157, GNorm = 1.4242, lr_0 = 1.0000e-04
Loss = 5.5429e-04, PNorm = 60.6177, GNorm = 1.0233, lr_0 = 1.0000e-04
Loss = 4.3653e-04, PNorm = 60.6196, GNorm = 1.7460, lr_0 = 1.0000e-04
Loss = 3.9275e-04, PNorm = 60.6210, GNorm = 1.8230, lr_0 = 1.0000e-04
Loss = 3.1371e-04, PNorm = 60.6227, GNorm = 1.1057, lr_0 = 1.0000e-04
Loss = 3.8034e-04, PNorm = 60.6234, GNorm = 1.1349, lr_0 = 1.0000e-04
Loss = 3.3551e-04, PNorm = 60.6235, GNorm = 1.2922, lr_0 = 1.0000e-04
Loss = 3.9034e-04, PNorm = 60.6247, GNorm = 1.6022, lr_0 = 1.0000e-04
Loss = 5.6217e-04, PNorm = 60.6268, GNorm = 1.6135, lr_0 = 1.0000e-04
Loss = 4.5881e-04, PNorm = 60.6282, GNorm = 1.3684, lr_0 = 1.0000e-04
Validation rmse = 4.407403
Validation R2 = -4.390265
Epoch 96
Train function
Loss = 7.0787e-04, PNorm = 60.6301, GNorm = 1.6737, lr_0 = 1.0000e-04
Loss = 2.8926e-04, PNorm = 60.6314, GNorm = 1.2411, lr_0 = 1.0000e-04
Loss = 4.9047e-04, PNorm = 60.6318, GNorm = 0.7855, lr_0 = 1.0000e-04
Loss = 2.1280e-04, PNorm = 60.6321, GNorm = 0.7246, lr_0 = 1.0000e-04
Loss = 2.5107e-04, PNorm = 60.6322, GNorm = 0.8335, lr_0 = 1.0000e-04
Loss = 3.9190e-04, PNorm = 60.6332, GNorm = 1.4553, lr_0 = 1.0000e-04
Loss = 3.2247e-04, PNorm = 60.6339, GNorm = 0.6438, lr_0 = 1.0000e-04
Loss = 2.8608e-04, PNorm = 60.6343, GNorm = 0.9964, lr_0 = 1.0000e-04
Loss = 3.9465e-04, PNorm = 60.6349, GNorm = 0.7869, lr_0 = 1.0000e-04
Loss = 2.5737e-04, PNorm = 60.6353, GNorm = 0.9495, lr_0 = 1.0000e-04
Loss = 4.0255e-04, PNorm = 60.6366, GNorm = 1.7417, lr_0 = 1.0000e-04
Loss = 5.4809e-04, PNorm = 60.6383, GNorm = 1.0676, lr_0 = 1.0000e-04
Loss = 4.4068e-04, PNorm = 60.6400, GNorm = 1.2797, lr_0 = 1.0000e-04
Loss = 5.2034e-04, PNorm = 60.6410, GNorm = 1.2832, lr_0 = 1.0000e-04
Loss = 3.4458e-04, PNorm = 60.6414, GNorm = 1.1778, lr_0 = 1.0000e-04
Loss = 2.9757e-04, PNorm = 60.6414, GNorm = 0.6118, lr_0 = 1.0000e-04
Loss = 3.3944e-04, PNorm = 60.6418, GNorm = 0.8118, lr_0 = 1.0000e-04
Loss = 3.5380e-04, PNorm = 60.6429, GNorm = 1.0846, lr_0 = 1.0000e-04
Loss = 2.8988e-04, PNorm = 60.6437, GNorm = 0.7312, lr_0 = 1.0000e-04
Loss = 4.2421e-04, PNorm = 60.6441, GNorm = 0.9706, lr_0 = 1.0000e-04
Loss = 3.2331e-04, PNorm = 60.6445, GNorm = 0.7956, lr_0 = 1.0000e-04
Loss = 3.8319e-04, PNorm = 60.6456, GNorm = 0.9321, lr_0 = 1.0000e-04
Loss = 3.0151e-04, PNorm = 60.6476, GNorm = 1.1485, lr_0 = 1.0000e-04
Validation rmse = 4.337956
Validation R2 = -4.221735
Epoch 97
Train function
Loss = 3.6328e-04, PNorm = 60.6487, GNorm = 1.3401, lr_0 = 1.0000e-04
Loss = 2.9880e-04, PNorm = 60.6490, GNorm = 1.0782, lr_0 = 1.0000e-04
Loss = 4.2229e-04, PNorm = 60.6501, GNorm = 1.0369, lr_0 = 1.0000e-04
Loss = 3.9857e-04, PNorm = 60.6514, GNorm = 1.2425, lr_0 = 1.0000e-04
Loss = 3.8118e-04, PNorm = 60.6529, GNorm = 1.4081, lr_0 = 1.0000e-04
Loss = 2.5119e-04, PNorm = 60.6540, GNorm = 0.5082, lr_0 = 1.0000e-04
Loss = 4.7964e-04, PNorm = 60.6551, GNorm = 1.4713, lr_0 = 1.0000e-04
Loss = 3.5753e-04, PNorm = 60.6560, GNorm = 0.8754, lr_0 = 1.0000e-04
Loss = 2.4945e-04, PNorm = 60.6573, GNorm = 0.9804, lr_0 = 1.0000e-04
Loss = 2.8253e-04, PNorm = 60.6587, GNorm = 0.6386, lr_0 = 1.0000e-04
Loss = 4.0549e-04, PNorm = 60.6600, GNorm = 1.2230, lr_0 = 1.0000e-04
Loss = 4.0850e-04, PNorm = 60.6604, GNorm = 1.2671, lr_0 = 1.0000e-04
Loss = 3.1212e-04, PNorm = 60.6607, GNorm = 1.2095, lr_0 = 1.0000e-04
Loss = 3.4918e-04, PNorm = 60.6614, GNorm = 1.1865, lr_0 = 1.0000e-04
Loss = 3.8103e-04, PNorm = 60.6624, GNorm = 1.3432, lr_0 = 1.0000e-04
Loss = 3.2059e-04, PNorm = 60.6634, GNorm = 1.7897, lr_0 = 1.0000e-04
Loss = 3.7001e-04, PNorm = 60.6642, GNorm = 1.1013, lr_0 = 1.0000e-04
Loss = 4.1156e-04, PNorm = 60.6652, GNorm = 1.5037, lr_0 = 1.0000e-04
Loss = 3.5947e-04, PNorm = 60.6655, GNorm = 1.0805, lr_0 = 1.0000e-04
Loss = 2.6967e-04, PNorm = 60.6662, GNorm = 1.1341, lr_0 = 1.0000e-04
Loss = 6.2773e-04, PNorm = 60.6673, GNorm = 1.3002, lr_0 = 1.0000e-04
Loss = 4.0915e-04, PNorm = 60.6694, GNorm = 1.4660, lr_0 = 1.0000e-04
Loss = 3.5034e-04, PNorm = 60.6708, GNorm = 0.6581, lr_0 = 1.0000e-04
Loss = 5.3674e-04, PNorm = 60.6726, GNorm = 0.8379, lr_0 = 1.0000e-04
Validation rmse = 4.124963
Validation R2 = -3.721550
Epoch 98
Train function
Loss = 3.3749e-04, PNorm = 60.6739, GNorm = 0.9970, lr_0 = 1.0000e-04
Loss = 3.1661e-04, PNorm = 60.6752, GNorm = 0.8065, lr_0 = 1.0000e-04
Loss = 5.7927e-04, PNorm = 60.6755, GNorm = 1.7897, lr_0 = 1.0000e-04
Loss = 4.0822e-04, PNorm = 60.6763, GNorm = 0.8746, lr_0 = 1.0000e-04
Loss = 4.5687e-04, PNorm = 60.6780, GNorm = 0.6377, lr_0 = 1.0000e-04
Loss = 5.5190e-04, PNorm = 60.6798, GNorm = 0.8261, lr_0 = 1.0000e-04
Loss = 3.0625e-04, PNorm = 60.6814, GNorm = 1.2648, lr_0 = 1.0000e-04
Loss = 3.1668e-04, PNorm = 60.6823, GNorm = 0.8301, lr_0 = 1.0000e-04
Loss = 2.2447e-04, PNorm = 60.6826, GNorm = 0.6770, lr_0 = 1.0000e-04
Loss = 3.1773e-04, PNorm = 60.6825, GNorm = 1.5765, lr_0 = 1.0000e-04
Loss = 3.2304e-04, PNorm = 60.6824, GNorm = 0.9186, lr_0 = 1.0000e-04
Loss = 4.1374e-04, PNorm = 60.6827, GNorm = 0.7614, lr_0 = 1.0000e-04
Loss = 3.1419e-04, PNorm = 60.6840, GNorm = 0.9512, lr_0 = 1.0000e-04
Loss = 4.0652e-04, PNorm = 60.6852, GNorm = 1.2606, lr_0 = 1.0000e-04
Loss = 3.0754e-04, PNorm = 60.6858, GNorm = 1.2853, lr_0 = 1.0000e-04
Loss = 3.5768e-04, PNorm = 60.6859, GNorm = 0.6967, lr_0 = 1.0000e-04
Loss = 3.8892e-04, PNorm = 60.6868, GNorm = 0.8319, lr_0 = 1.0000e-04
Loss = 2.9610e-04, PNorm = 60.6883, GNorm = 1.5004, lr_0 = 1.0000e-04
Loss = 3.0205e-04, PNorm = 60.6892, GNorm = 1.2793, lr_0 = 1.0000e-04
Loss = 2.9978e-04, PNorm = 60.6901, GNorm = 0.9582, lr_0 = 1.0000e-04
Loss = 5.0590e-04, PNorm = 60.6916, GNorm = 0.7738, lr_0 = 1.0000e-04
Loss = 3.0947e-04, PNorm = 60.6927, GNorm = 1.3455, lr_0 = 1.0000e-04
Loss = 3.8137e-04, PNorm = 60.6938, GNorm = 1.8541, lr_0 = 1.0000e-04
Validation rmse = 4.130888
Validation R2 = -3.735125
Epoch 99
Train function
Loss = 4.6507e-04, PNorm = 60.6954, GNorm = 1.1662, lr_0 = 1.0000e-04
Loss = 3.2070e-04, PNorm = 60.6968, GNorm = 0.9489, lr_0 = 1.0000e-04
Loss = 3.4694e-04, PNorm = 60.6975, GNorm = 1.1394, lr_0 = 1.0000e-04
Loss = 2.8315e-04, PNorm = 60.6984, GNorm = 0.8453, lr_0 = 1.0000e-04
Loss = 3.8830e-04, PNorm = 60.6995, GNorm = 0.8716, lr_0 = 1.0000e-04
Loss = 3.2751e-04, PNorm = 60.7005, GNorm = 0.8867, lr_0 = 1.0000e-04
Loss = 2.8599e-04, PNorm = 60.7018, GNorm = 1.2729, lr_0 = 1.0000e-04
Loss = 2.8345e-04, PNorm = 60.7032, GNorm = 0.7766, lr_0 = 1.0000e-04
Loss = 5.3042e-04, PNorm = 60.7033, GNorm = 1.1952, lr_0 = 1.0000e-04
Loss = 2.8297e-04, PNorm = 60.7038, GNorm = 0.8897, lr_0 = 1.0000e-04
Loss = 2.9875e-04, PNorm = 60.7048, GNorm = 1.0091, lr_0 = 1.0000e-04
Loss = 3.4824e-04, PNorm = 60.7061, GNorm = 0.7622, lr_0 = 1.0000e-04
Loss = 3.2686e-04, PNorm = 60.7069, GNorm = 1.2393, lr_0 = 1.0000e-04
Loss = 4.3096e-04, PNorm = 60.7086, GNorm = 1.4504, lr_0 = 1.0000e-04
Loss = 3.9347e-04, PNorm = 60.7098, GNorm = 1.3708, lr_0 = 1.0000e-04
Loss = 6.2002e-04, PNorm = 60.7096, GNorm = 1.5516, lr_0 = 1.0000e-04
Loss = 3.8052e-04, PNorm = 60.7109, GNorm = 1.2661, lr_0 = 1.0000e-04
Loss = 3.2071e-04, PNorm = 60.7118, GNorm = 1.1847, lr_0 = 1.0000e-04
Loss = 4.5285e-04, PNorm = 60.7129, GNorm = 1.6951, lr_0 = 1.0000e-04
Loss = 3.0174e-04, PNorm = 60.7142, GNorm = 0.6190, lr_0 = 1.0000e-04
Loss = 3.2894e-04, PNorm = 60.7152, GNorm = 0.9457, lr_0 = 1.0000e-04
Loss = 5.0873e-04, PNorm = 60.7162, GNorm = 2.1654, lr_0 = 1.0000e-04
Loss = 2.5022e-04, PNorm = 60.7176, GNorm = 0.7728, lr_0 = 1.0000e-04
Loss = 5.3006e-04, PNorm = 60.7190, GNorm = 1.4490, lr_0 = 1.0000e-04
Validation rmse = 4.257588
Validation R2 = -4.030044
Model 0 best validation rmse = 1.016787 on epoch 0
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 1.040931
Model 0 test R2 = 0.678244
Ensemble test rmse = 1.040931
Ensemble test R2 = 0.678244
Fold 2
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8782,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 11,710 | train size = 8,783 | val size = 2,927 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 5.6269e-02, PNorm = 35.0073, GNorm = 7.7352, lr_0 = 1.2829e-04
Loss = 4.9389e-02, PNorm = 35.0076, GNorm = 4.7197, lr_0 = 1.5400e-04
Loss = 3.9896e-02, PNorm = 35.0103, GNorm = 7.8434, lr_0 = 1.7971e-04
Loss = 3.5999e-02, PNorm = 35.0151, GNorm = 7.9555, lr_0 = 2.0543e-04
Loss = 4.8887e-02, PNorm = 35.0226, GNorm = 14.4372, lr_0 = 2.3114e-04
Loss = 3.2446e-02, PNorm = 35.0305, GNorm = 3.2667, lr_0 = 2.5686e-04
Loss = 3.5634e-02, PNorm = 35.0375, GNorm = 4.7762, lr_0 = 2.8257e-04
Loss = 2.4141e-02, PNorm = 35.0459, GNorm = 7.7958, lr_0 = 3.0829e-04
Loss = 3.1513e-02, PNorm = 35.0533, GNorm = 6.9622, lr_0 = 3.3400e-04
Loss = 3.6864e-02, PNorm = 35.0596, GNorm = 8.0131, lr_0 = 3.5971e-04
Loss = 3.0835e-02, PNorm = 35.0694, GNorm = 8.4772, lr_0 = 3.8543e-04
Loss = 3.1720e-02, PNorm = 35.0808, GNorm = 4.0102, lr_0 = 4.1114e-04
Loss = 3.3014e-02, PNorm = 35.0924, GNorm = 8.4047, lr_0 = 4.3686e-04
Loss = 2.5524e-02, PNorm = 35.1036, GNorm = 2.5986, lr_0 = 4.6257e-04
Loss = 2.7070e-02, PNorm = 35.1188, GNorm = 2.3973, lr_0 = 4.8829e-04
Loss = 3.2701e-02, PNorm = 35.1340, GNorm = 15.5615, lr_0 = 5.1400e-04
Loss = 2.8294e-02, PNorm = 35.1450, GNorm = 5.1512, lr_0 = 5.3971e-04
Loss = 2.3995e-02, PNorm = 35.1597, GNorm = 6.3693, lr_0 = 5.6543e-04
Loss = 2.7930e-02, PNorm = 35.1767, GNorm = 7.3474, lr_0 = 5.9114e-04
Loss = 2.1725e-02, PNorm = 35.1918, GNorm = 4.5247, lr_0 = 6.1686e-04
Loss = 2.6113e-02, PNorm = 35.2051, GNorm = 4.9175, lr_0 = 6.4257e-04
Loss = 3.2629e-02, PNorm = 35.2270, GNorm = 1.8687, lr_0 = 6.6829e-04
Loss = 3.2493e-02, PNorm = 35.2530, GNorm = 5.3884, lr_0 = 6.9400e-04
Validation rmse = 1.733760
Validation R2 = 0.140829
Epoch 1
Train function
Loss = 2.9848e-02, PNorm = 35.2742, GNorm = 3.2908, lr_0 = 7.2229e-04
Loss = 2.7560e-02, PNorm = 35.2984, GNorm = 2.8697, lr_0 = 7.4800e-04
Loss = 2.6932e-02, PNorm = 35.3216, GNorm = 2.6543, lr_0 = 7.7371e-04
Loss = 3.1793e-02, PNorm = 35.3481, GNorm = 8.0013, lr_0 = 7.9943e-04
Loss = 2.5485e-02, PNorm = 35.3756, GNorm = 1.6530, lr_0 = 8.2514e-04
Loss = 2.1410e-02, PNorm = 35.3941, GNorm = 3.0132, lr_0 = 8.5086e-04
Loss = 3.1852e-02, PNorm = 35.4289, GNorm = 2.5582, lr_0 = 8.7657e-04
Loss = 3.1112e-02, PNorm = 35.4559, GNorm = 8.1877, lr_0 = 9.0229e-04
Loss = 3.0550e-02, PNorm = 35.4931, GNorm = 5.1194, lr_0 = 9.2800e-04
Loss = 2.4508e-02, PNorm = 35.5251, GNorm = 4.8455, lr_0 = 9.5371e-04
Loss = 2.6800e-02, PNorm = 35.5601, GNorm = 3.6818, lr_0 = 9.7943e-04
Loss = 2.8386e-02, PNorm = 35.5800, GNorm = 7.6433, lr_0 = 9.9973e-04
Loss = 2.3053e-02, PNorm = 35.6144, GNorm = 2.4866, lr_0 = 9.9839e-04
Loss = 2.6024e-02, PNorm = 35.6493, GNorm = 4.7949, lr_0 = 9.9705e-04
Loss = 2.5638e-02, PNorm = 35.6788, GNorm = 7.1453, lr_0 = 9.9571e-04
Loss = 2.4951e-02, PNorm = 35.6974, GNorm = 1.8491, lr_0 = 9.9438e-04
Loss = 2.1569e-02, PNorm = 35.7233, GNorm = 2.6814, lr_0 = 9.9304e-04
Loss = 2.4049e-02, PNorm = 35.7423, GNorm = 1.7592, lr_0 = 9.9171e-04
Loss = 2.7382e-02, PNorm = 35.7758, GNorm = 3.8651, lr_0 = 9.9038e-04
Loss = 2.6508e-02, PNorm = 35.8050, GNorm = 3.2889, lr_0 = 9.8905e-04
Loss = 2.2489e-02, PNorm = 35.8387, GNorm = 7.3840, lr_0 = 9.8772e-04
Loss = 2.7390e-02, PNorm = 35.8703, GNorm = 5.2447, lr_0 = 9.8640e-04
Loss = 2.4695e-02, PNorm = 35.9072, GNorm = 1.5950, lr_0 = 9.8508e-04
Validation rmse = 1.565305
Validation R2 = 0.299676
Epoch 2
Train function
Loss = 3.1384e-02, PNorm = 35.9403, GNorm = 2.3450, lr_0 = 9.8362e-04
Loss = 2.5670e-02, PNorm = 35.9914, GNorm = 1.5849, lr_0 = 9.8230e-04
Loss = 2.5028e-02, PNorm = 36.0151, GNorm = 1.5465, lr_0 = 9.8098e-04
Loss = 2.6201e-02, PNorm = 36.0553, GNorm = 4.6487, lr_0 = 9.7967e-04
Loss = 2.5544e-02, PNorm = 36.0924, GNorm = 2.2411, lr_0 = 9.7835e-04
Loss = 2.6918e-02, PNorm = 36.1342, GNorm = 5.8544, lr_0 = 9.7704e-04
Loss = 2.5283e-02, PNorm = 36.1837, GNorm = 2.1485, lr_0 = 9.7573e-04
Loss = 2.5781e-02, PNorm = 36.2292, GNorm = 2.2739, lr_0 = 9.7442e-04
Loss = 2.2801e-02, PNorm = 36.2670, GNorm = 1.7636, lr_0 = 9.7311e-04
Loss = 2.4309e-02, PNorm = 36.3054, GNorm = 3.1268, lr_0 = 9.7181e-04
Loss = 2.3679e-02, PNorm = 36.3355, GNorm = 2.4675, lr_0 = 9.7050e-04
Loss = 2.3845e-02, PNorm = 36.3653, GNorm = 4.0884, lr_0 = 9.6920e-04
Loss = 2.2550e-02, PNorm = 36.4052, GNorm = 2.8292, lr_0 = 9.6790e-04
Loss = 2.1724e-02, PNorm = 36.4331, GNorm = 2.5023, lr_0 = 9.6660e-04
Loss = 2.2255e-02, PNorm = 36.4572, GNorm = 2.5626, lr_0 = 9.6531e-04
Loss = 2.3826e-02, PNorm = 36.4906, GNorm = 3.4986, lr_0 = 9.6401e-04
Loss = 2.4136e-02, PNorm = 36.5165, GNorm = 1.8534, lr_0 = 9.6272e-04
Loss = 2.2717e-02, PNorm = 36.5554, GNorm = 2.9489, lr_0 = 9.6143e-04
Loss = 2.9394e-02, PNorm = 36.5712, GNorm = 2.3418, lr_0 = 9.6014e-04
Loss = 2.4954e-02, PNorm = 36.6125, GNorm = 2.5110, lr_0 = 9.5885e-04
Loss = 2.6718e-02, PNorm = 36.6626, GNorm = 2.7681, lr_0 = 9.5756e-04
Loss = 2.2925e-02, PNorm = 36.6757, GNorm = 1.5384, lr_0 = 9.5628e-04
Loss = 2.4854e-02, PNorm = 36.6994, GNorm = 2.8985, lr_0 = 9.5499e-04
Loss = 2.5488e-02, PNorm = 36.7304, GNorm = 4.4609, lr_0 = 9.5371e-04
Validation rmse = 1.501168
Validation R2 = 0.355890
Epoch 3
Train function
Loss = 2.6166e-02, PNorm = 36.7582, GNorm = 3.0987, lr_0 = 9.5230e-04
Loss = 2.7050e-02, PNorm = 36.7858, GNorm = 3.1565, lr_0 = 9.5103e-04
Loss = 1.9974e-02, PNorm = 36.8087, GNorm = 3.1488, lr_0 = 9.4975e-04
Loss = 2.5894e-02, PNorm = 36.8410, GNorm = 1.8697, lr_0 = 9.4848e-04
Loss = 2.5455e-02, PNorm = 36.8771, GNorm = 2.8521, lr_0 = 9.4720e-04
Loss = 2.2595e-02, PNorm = 36.9094, GNorm = 2.2930, lr_0 = 9.4593e-04
Loss = 2.3862e-02, PNorm = 36.9523, GNorm = 5.2940, lr_0 = 9.4466e-04
Loss = 2.5550e-02, PNorm = 36.9717, GNorm = 2.6237, lr_0 = 9.4340e-04
Loss = 2.2513e-02, PNorm = 36.9975, GNorm = 1.7733, lr_0 = 9.4213e-04
Loss = 2.5472e-02, PNorm = 37.0273, GNorm = 2.0586, lr_0 = 9.4087e-04
Loss = 2.3425e-02, PNorm = 37.0589, GNorm = 5.4446, lr_0 = 9.3960e-04
Loss = 2.2147e-02, PNorm = 37.1055, GNorm = 2.2835, lr_0 = 9.3834e-04
Loss = 2.5833e-02, PNorm = 37.1338, GNorm = 2.1756, lr_0 = 9.3708e-04
Loss = 2.3258e-02, PNorm = 37.1777, GNorm = 1.6029, lr_0 = 9.3583e-04
Loss = 2.0314e-02, PNorm = 37.2120, GNorm = 2.2835, lr_0 = 9.3457e-04
Loss = 2.3508e-02, PNorm = 37.2350, GNorm = 2.3598, lr_0 = 9.3332e-04
Loss = 2.6988e-02, PNorm = 37.2341, GNorm = 2.2493, lr_0 = 9.3206e-04
Loss = 2.2245e-02, PNorm = 37.2572, GNorm = 2.2133, lr_0 = 9.3081e-04
Loss = 2.3145e-02, PNorm = 37.2846, GNorm = 2.1409, lr_0 = 9.2957e-04
Loss = 2.1408e-02, PNorm = 37.3129, GNorm = 3.0478, lr_0 = 9.2832e-04
Loss = 2.0943e-02, PNorm = 37.3349, GNorm = 1.9641, lr_0 = 9.2707e-04
Loss = 2.0356e-02, PNorm = 37.3484, GNorm = 1.6881, lr_0 = 9.2583e-04
Loss = 2.1229e-02, PNorm = 37.3734, GNorm = 1.4692, lr_0 = 9.2459e-04
Validation rmse = 1.331915
Validation R2 = 0.492946
Epoch 4
Train function
Loss = 2.3973e-02, PNorm = 37.4023, GNorm = 1.9201, lr_0 = 9.2322e-04
Loss = 2.0746e-02, PNorm = 37.4231, GNorm = 2.9071, lr_0 = 9.2198e-04
Loss = 2.3244e-02, PNorm = 37.4383, GNorm = 6.3654, lr_0 = 9.2075e-04
Loss = 2.3053e-02, PNorm = 37.4595, GNorm = 2.4479, lr_0 = 9.1951e-04
Loss = 2.1957e-02, PNorm = 37.4921, GNorm = 2.0444, lr_0 = 9.1828e-04
Loss = 2.0949e-02, PNorm = 37.5255, GNorm = 1.6391, lr_0 = 9.1705e-04
Loss = 1.9433e-02, PNorm = 37.5387, GNorm = 2.2938, lr_0 = 9.1581e-04
Loss = 2.2815e-02, PNorm = 37.5580, GNorm = 2.3110, lr_0 = 9.1459e-04
Loss = 2.2258e-02, PNorm = 37.5903, GNorm = 1.9688, lr_0 = 9.1336e-04
Loss = 2.2900e-02, PNorm = 37.6209, GNorm = 2.0933, lr_0 = 9.1213e-04
Loss = 2.0803e-02, PNorm = 37.6396, GNorm = 1.5871, lr_0 = 9.1091e-04
Loss = 2.4762e-02, PNorm = 37.6677, GNorm = 5.3772, lr_0 = 9.0969e-04
Loss = 2.1039e-02, PNorm = 37.7027, GNorm = 3.5196, lr_0 = 9.0847e-04
Loss = 2.2025e-02, PNorm = 37.7169, GNorm = 2.0268, lr_0 = 9.0725e-04
Loss = 2.6068e-02, PNorm = 37.7486, GNorm = 2.6365, lr_0 = 9.0603e-04
Loss = 2.2375e-02, PNorm = 37.7822, GNorm = 4.8580, lr_0 = 9.0481e-04
Loss = 2.4767e-02, PNorm = 37.8192, GNorm = 2.1203, lr_0 = 9.0360e-04
Loss = 2.2527e-02, PNorm = 37.8526, GNorm = 2.8108, lr_0 = 9.0239e-04
Loss = 2.5021e-02, PNorm = 37.8723, GNorm = 6.0911, lr_0 = 9.0118e-04
Loss = 2.1191e-02, PNorm = 37.8872, GNorm = 3.7718, lr_0 = 8.9997e-04
Loss = 2.4059e-02, PNorm = 37.9163, GNorm = 2.2745, lr_0 = 8.9876e-04
Loss = 2.3733e-02, PNorm = 37.9528, GNorm = 5.6837, lr_0 = 8.9756e-04
Loss = 2.2467e-02, PNorm = 37.9913, GNorm = 4.9599, lr_0 = 8.9635e-04
Loss = 2.2371e-02, PNorm = 38.0152, GNorm = 1.5508, lr_0 = 8.9515e-04
Validation rmse = 1.015447
Validation R2 = 0.705276
Epoch 5
Train function
Loss = 2.1587e-02, PNorm = 38.0295, GNorm = 2.0823, lr_0 = 8.9395e-04
Loss = 2.0094e-02, PNorm = 38.0603, GNorm = 2.6898, lr_0 = 8.9275e-04
Loss = 1.9562e-02, PNorm = 38.1020, GNorm = 1.6537, lr_0 = 8.9155e-04
Loss = 2.4856e-02, PNorm = 38.1310, GNorm = 3.4898, lr_0 = 8.9035e-04
Loss = 2.5529e-02, PNorm = 38.1581, GNorm = 2.2998, lr_0 = 8.8916e-04
Loss = 2.2913e-02, PNorm = 38.1952, GNorm = 3.9195, lr_0 = 8.8797e-04
Loss = 2.3355e-02, PNorm = 38.2305, GNorm = 6.1307, lr_0 = 8.8677e-04
Loss = 2.2073e-02, PNorm = 38.2688, GNorm = 3.2402, lr_0 = 8.8559e-04
Loss = 2.3572e-02, PNorm = 38.2908, GNorm = 2.0696, lr_0 = 8.8440e-04
Loss = 2.3050e-02, PNorm = 38.3081, GNorm = 3.6874, lr_0 = 8.8321e-04
Loss = 2.1464e-02, PNorm = 38.3302, GNorm = 1.8788, lr_0 = 8.8203e-04
Loss = 1.9655e-02, PNorm = 38.3672, GNorm = 1.7486, lr_0 = 8.8084e-04
Loss = 2.2653e-02, PNorm = 38.3929, GNorm = 2.4875, lr_0 = 8.7966e-04
Loss = 2.1528e-02, PNorm = 38.4193, GNorm = 1.5650, lr_0 = 8.7848e-04
Loss = 2.0304e-02, PNorm = 38.4405, GNorm = 2.8419, lr_0 = 8.7730e-04
Loss = 2.4728e-02, PNorm = 38.4639, GNorm = 2.5587, lr_0 = 8.7612e-04
Loss = 2.3709e-02, PNorm = 38.4919, GNorm = 1.9979, lr_0 = 8.7495e-04
Loss = 2.1353e-02, PNorm = 38.5129, GNorm = 4.1451, lr_0 = 8.7377e-04
Loss = 2.1446e-02, PNorm = 38.5504, GNorm = 1.8271, lr_0 = 8.7260e-04
Loss = 1.8285e-02, PNorm = 38.5852, GNorm = 1.3308, lr_0 = 8.7143e-04
Loss = 2.1110e-02, PNorm = 38.6203, GNorm = 2.3496, lr_0 = 8.7026e-04
Loss = 2.1837e-02, PNorm = 38.6421, GNorm = 2.8355, lr_0 = 8.6909e-04
Loss = 2.3034e-02, PNorm = 38.6564, GNorm = 3.7479, lr_0 = 8.6793e-04
Validation rmse = 1.211090
Validation R2 = 0.580768
Epoch 6
Train function
Loss = 2.6991e-02, PNorm = 38.6816, GNorm = 2.2396, lr_0 = 8.6665e-04
Loss = 2.0153e-02, PNorm = 38.7136, GNorm = 1.7513, lr_0 = 8.6548e-04
Loss = 2.2536e-02, PNorm = 38.7428, GNorm = 2.3081, lr_0 = 8.6432e-04
Loss = 2.1653e-02, PNorm = 38.7716, GNorm = 2.1044, lr_0 = 8.6316e-04
Loss = 2.4653e-02, PNorm = 38.8085, GNorm = 5.8741, lr_0 = 8.6201e-04
Loss = 2.6428e-02, PNorm = 38.8498, GNorm = 3.1129, lr_0 = 8.6085e-04
Loss = 2.2163e-02, PNorm = 38.8762, GNorm = 2.0679, lr_0 = 8.5969e-04
Loss = 2.3103e-02, PNorm = 38.9043, GNorm = 5.2651, lr_0 = 8.5854e-04
Loss = 2.1309e-02, PNorm = 38.9281, GNorm = 4.4527, lr_0 = 8.5739e-04
Loss = 2.1862e-02, PNorm = 38.9544, GNorm = 1.6022, lr_0 = 8.5624e-04
Loss = 2.1191e-02, PNorm = 38.9975, GNorm = 3.7269, lr_0 = 8.5509e-04
Loss = 2.3215e-02, PNorm = 39.0219, GNorm = 2.0353, lr_0 = 8.5394e-04
Loss = 2.1157e-02, PNorm = 39.0541, GNorm = 1.9730, lr_0 = 8.5280e-04
Loss = 1.8689e-02, PNorm = 39.0784, GNorm = 2.4729, lr_0 = 8.5165e-04
Loss = 1.9471e-02, PNorm = 39.1000, GNorm = 2.8005, lr_0 = 8.5051e-04
Loss = 2.0735e-02, PNorm = 39.1341, GNorm = 1.9532, lr_0 = 8.4937e-04
Loss = 2.0538e-02, PNorm = 39.1561, GNorm = 2.1137, lr_0 = 8.4823e-04
Loss = 2.0010e-02, PNorm = 39.1818, GNorm = 1.9955, lr_0 = 8.4709e-04
Loss = 2.4106e-02, PNorm = 39.2037, GNorm = 2.4811, lr_0 = 8.4595e-04
Loss = 2.0687e-02, PNorm = 39.2344, GNorm = 1.6200, lr_0 = 8.4482e-04
Loss = 2.2256e-02, PNorm = 39.2545, GNorm = 4.1030, lr_0 = 8.4369e-04
Loss = 2.0192e-02, PNorm = 39.2763, GNorm = 1.8085, lr_0 = 8.4255e-04
Loss = 1.8114e-02, PNorm = 39.2945, GNorm = 1.2900, lr_0 = 8.4142e-04
Validation rmse = 1.882140
Validation R2 = -0.012524
Epoch 7
Train function
Loss = 2.1770e-02, PNorm = 39.3113, GNorm = 2.0863, lr_0 = 8.4018e-04
Loss = 2.3901e-02, PNorm = 39.3587, GNorm = 1.8727, lr_0 = 8.3905e-04
Loss = 2.3629e-02, PNorm = 39.4043, GNorm = 2.1538, lr_0 = 8.3793e-04
Loss = 2.0452e-02, PNorm = 39.4342, GNorm = 1.7445, lr_0 = 8.3680e-04
Loss = 2.2692e-02, PNorm = 39.4585, GNorm = 3.5026, lr_0 = 8.3568e-04
Loss = 2.0759e-02, PNorm = 39.4835, GNorm = 2.1915, lr_0 = 8.3456e-04
Loss = 2.1860e-02, PNorm = 39.5176, GNorm = 1.8232, lr_0 = 8.3344e-04
Loss = 2.0235e-02, PNorm = 39.5395, GNorm = 1.4854, lr_0 = 8.3232e-04
Loss = 1.9029e-02, PNorm = 39.5613, GNorm = 1.8884, lr_0 = 8.3121e-04
Loss = 1.8706e-02, PNorm = 39.5832, GNorm = 1.9110, lr_0 = 8.3009e-04
Loss = 1.7896e-02, PNorm = 39.6198, GNorm = 2.3642, lr_0 = 8.2898e-04
Loss = 2.4532e-02, PNorm = 39.6539, GNorm = 4.6045, lr_0 = 8.2786e-04
Loss = 2.3431e-02, PNorm = 39.6893, GNorm = 2.7841, lr_0 = 8.2675e-04
Loss = 1.9710e-02, PNorm = 39.7217, GNorm = 1.5823, lr_0 = 8.2564e-04
Loss = 1.9560e-02, PNorm = 39.7478, GNorm = 4.1314, lr_0 = 8.2454e-04
Loss = 2.1729e-02, PNorm = 39.7741, GNorm = 1.8250, lr_0 = 8.2343e-04
Loss = 1.8314e-02, PNorm = 39.7972, GNorm = 1.9406, lr_0 = 8.2233e-04
Loss = 2.2631e-02, PNorm = 39.8232, GNorm = 1.8702, lr_0 = 8.2122e-04
Loss = 1.9889e-02, PNorm = 39.8574, GNorm = 2.4384, lr_0 = 8.2012e-04
Loss = 1.7654e-02, PNorm = 39.8884, GNorm = 1.5269, lr_0 = 8.1902e-04
Loss = 2.2631e-02, PNorm = 39.9106, GNorm = 1.7771, lr_0 = 8.1792e-04
Loss = 1.9500e-02, PNorm = 39.9440, GNorm = 3.2545, lr_0 = 8.1682e-04
Loss = 2.0304e-02, PNorm = 39.9698, GNorm = 2.3183, lr_0 = 8.1573e-04
Loss = 1.9362e-02, PNorm = 39.9910, GNorm = 3.6499, lr_0 = 8.1463e-04
Validation rmse = 1.804663
Validation R2 = 0.069120
Epoch 8
Train function
Loss = 1.6522e-02, PNorm = 40.0265, GNorm = 2.8532, lr_0 = 8.1343e-04
Loss = 1.9989e-02, PNorm = 40.0579, GNorm = 1.5336, lr_0 = 8.1234e-04
Loss = 2.1801e-02, PNorm = 40.0985, GNorm = 3.7710, lr_0 = 8.1125e-04
Loss = 2.2068e-02, PNorm = 40.1430, GNorm = 2.2277, lr_0 = 8.1016e-04
Loss = 2.1340e-02, PNorm = 40.1854, GNorm = 1.3839, lr_0 = 8.0907e-04
Loss = 2.0642e-02, PNorm = 40.2093, GNorm = 4.6135, lr_0 = 8.0799e-04
Loss = 1.9306e-02, PNorm = 40.2479, GNorm = 2.1985, lr_0 = 8.0690e-04
Loss = 2.0502e-02, PNorm = 40.2859, GNorm = 3.3379, lr_0 = 8.0582e-04
Loss = 2.1562e-02, PNorm = 40.3081, GNorm = 2.4412, lr_0 = 8.0474e-04
Loss = 2.2678e-02, PNorm = 40.3237, GNorm = 2.3993, lr_0 = 8.0366e-04
Loss = 2.0667e-02, PNorm = 40.3557, GNorm = 2.5543, lr_0 = 8.0258e-04
Loss = 1.9684e-02, PNorm = 40.3866, GNorm = 2.1881, lr_0 = 8.0151e-04
Loss = 1.6828e-02, PNorm = 40.4174, GNorm = 1.5834, lr_0 = 8.0043e-04
Loss = 2.1256e-02, PNorm = 40.4427, GNorm = 2.8001, lr_0 = 7.9936e-04
Loss = 2.1709e-02, PNorm = 40.4688, GNorm = 2.4886, lr_0 = 7.9828e-04
Loss = 2.2743e-02, PNorm = 40.4984, GNorm = 2.0120, lr_0 = 7.9721e-04
Loss = 1.9570e-02, PNorm = 40.5243, GNorm = 1.7340, lr_0 = 7.9614e-04
Loss = 2.2829e-02, PNorm = 40.5463, GNorm = 2.3780, lr_0 = 7.9508e-04
Loss = 2.0175e-02, PNorm = 40.5798, GNorm = 1.5771, lr_0 = 7.9401e-04
Loss = 2.1209e-02, PNorm = 40.6159, GNorm = 3.1928, lr_0 = 7.9294e-04
Loss = 1.6346e-02, PNorm = 40.6334, GNorm = 2.4809, lr_0 = 7.9188e-04
Loss = 2.1298e-02, PNorm = 40.6544, GNorm = 3.4234, lr_0 = 7.9082e-04
Loss = 2.3850e-02, PNorm = 40.6807, GNorm = 3.4457, lr_0 = 7.8976e-04
Validation rmse = 1.396067
Validation R2 = 0.442925
Epoch 9
Train function
Loss = 2.4522e-02, PNorm = 40.7197, GNorm = 2.0646, lr_0 = 7.8859e-04
Loss = 1.7346e-02, PNorm = 40.7506, GNorm = 1.6388, lr_0 = 7.8753e-04
Loss = 1.7890e-02, PNorm = 40.7858, GNorm = 1.4913, lr_0 = 7.8648e-04
Loss = 2.0647e-02, PNorm = 40.8096, GNorm = 2.1796, lr_0 = 7.8542e-04
Loss = 1.9462e-02, PNorm = 40.8468, GNorm = 3.8256, lr_0 = 7.8437e-04
Loss = 1.8357e-02, PNorm = 40.8834, GNorm = 1.7030, lr_0 = 7.8331e-04
Loss = 1.8380e-02, PNorm = 40.9119, GNorm = 1.8677, lr_0 = 7.8226e-04
Loss = 1.9536e-02, PNorm = 40.9525, GNorm = 2.9730, lr_0 = 7.8121e-04
Loss = 2.1127e-02, PNorm = 40.9763, GNorm = 3.3960, lr_0 = 7.8017e-04
Loss = 2.2469e-02, PNorm = 41.0070, GNorm = 2.2934, lr_0 = 7.7912e-04
Loss = 1.8149e-02, PNorm = 41.0452, GNorm = 1.4651, lr_0 = 7.7807e-04
Loss = 1.9830e-02, PNorm = 41.0868, GNorm = 1.5761, lr_0 = 7.7703e-04
Loss = 1.9834e-02, PNorm = 41.1174, GNorm = 1.6833, lr_0 = 7.7599e-04
Loss = 2.1777e-02, PNorm = 41.1402, GNorm = 1.6686, lr_0 = 7.7495e-04
Loss = 2.1500e-02, PNorm = 41.1716, GNorm = 1.6244, lr_0 = 7.7391e-04
Loss = 1.9376e-02, PNorm = 41.1955, GNorm = 2.3695, lr_0 = 7.7287e-04
Loss = 2.1217e-02, PNorm = 41.2321, GNorm = 2.8639, lr_0 = 7.7183e-04
Loss = 2.1249e-02, PNorm = 41.2620, GNorm = 4.1103, lr_0 = 7.7079e-04
Loss = 2.0386e-02, PNorm = 41.2801, GNorm = 3.4859, lr_0 = 7.6976e-04
Loss = 2.1945e-02, PNorm = 41.3037, GNorm = 3.2576, lr_0 = 7.6873e-04
Loss = 2.0844e-02, PNorm = 41.3303, GNorm = 1.7394, lr_0 = 7.6770e-04
Loss = 1.8298e-02, PNorm = 41.3591, GNorm = 1.9061, lr_0 = 7.6667e-04
Loss = 2.2055e-02, PNorm = 41.3903, GNorm = 2.6937, lr_0 = 7.6564e-04
Loss = 1.7432e-02, PNorm = 41.4131, GNorm = 2.4833, lr_0 = 7.6461e-04
Validation rmse = 1.477216
Validation R2 = 0.376281
Epoch 10
Train function
Loss = 1.9114e-02, PNorm = 41.4328, GNorm = 1.8944, lr_0 = 7.6358e-04
Loss = 1.8773e-02, PNorm = 41.4619, GNorm = 1.8418, lr_0 = 7.6256e-04
Loss = 1.9741e-02, PNorm = 41.5113, GNorm = 6.0400, lr_0 = 7.6154e-04
Loss = 1.9566e-02, PNorm = 41.5677, GNorm = 3.2612, lr_0 = 7.6052e-04
Loss = 1.9812e-02, PNorm = 41.6055, GNorm = 1.6884, lr_0 = 7.5949e-04
Loss = 1.9776e-02, PNorm = 41.6365, GNorm = 1.9002, lr_0 = 7.5848e-04
Loss = 1.8769e-02, PNorm = 41.6739, GNorm = 3.2140, lr_0 = 7.5746e-04
Loss = 1.8712e-02, PNorm = 41.7122, GNorm = 1.7052, lr_0 = 7.5644e-04
Loss = 2.0580e-02, PNorm = 41.7437, GNorm = 4.5381, lr_0 = 7.5543e-04
Loss = 2.2651e-02, PNorm = 41.7899, GNorm = 5.2917, lr_0 = 7.5441e-04
Loss = 2.1586e-02, PNorm = 41.8308, GNorm = 2.3062, lr_0 = 7.5340e-04
Loss = 2.0365e-02, PNorm = 41.8600, GNorm = 2.1223, lr_0 = 7.5239e-04
Loss = 2.0782e-02, PNorm = 41.8762, GNorm = 3.9691, lr_0 = 7.5138e-04
Loss = 1.7133e-02, PNorm = 41.8964, GNorm = 2.0686, lr_0 = 7.5037e-04
Loss = 1.7352e-02, PNorm = 41.9195, GNorm = 1.8693, lr_0 = 7.4937e-04
Loss = 1.9349e-02, PNorm = 41.9469, GNorm = 1.9925, lr_0 = 7.4836e-04
Loss = 1.8982e-02, PNorm = 41.9741, GNorm = 3.6992, lr_0 = 7.4736e-04
Loss = 1.8834e-02, PNorm = 41.9947, GNorm = 2.1660, lr_0 = 7.4635e-04
Loss = 1.8377e-02, PNorm = 42.0180, GNorm = 3.5095, lr_0 = 7.4535e-04
Loss = 1.9620e-02, PNorm = 42.0461, GNorm = 3.9509, lr_0 = 7.4435e-04
Loss = 2.0419e-02, PNorm = 42.0724, GNorm = 2.2274, lr_0 = 7.4335e-04
Loss = 1.9827e-02, PNorm = 42.1066, GNorm = 2.6773, lr_0 = 7.4236e-04
Loss = 1.8931e-02, PNorm = 42.1250, GNorm = 2.1290, lr_0 = 7.4136e-04
Validation rmse = 1.341482
Validation R2 = 0.485635
Epoch 11
Train function
Loss = 1.8590e-02, PNorm = 42.1492, GNorm = 5.1894, lr_0 = 7.4027e-04
Loss = 1.9306e-02, PNorm = 42.1783, GNorm = 1.9405, lr_0 = 7.3927e-04
Loss = 1.7122e-02, PNorm = 42.2055, GNorm = 2.1500, lr_0 = 7.3828e-04
Loss = 1.8551e-02, PNorm = 42.2317, GNorm = 2.1688, lr_0 = 7.3729e-04
Loss = 1.9570e-02, PNorm = 42.2529, GNorm = 3.6291, lr_0 = 7.3630e-04
Loss = 2.0041e-02, PNorm = 42.2918, GNorm = 1.7507, lr_0 = 7.3531e-04
Loss = 1.9389e-02, PNorm = 42.3457, GNorm = 1.8585, lr_0 = 7.3433e-04
Loss = 1.7776e-02, PNorm = 42.3820, GNorm = 2.3563, lr_0 = 7.3334e-04
Loss = 2.0247e-02, PNorm = 42.4108, GNorm = 2.1566, lr_0 = 7.3236e-04
Loss = 1.6652e-02, PNorm = 42.4362, GNorm = 2.4199, lr_0 = 7.3137e-04
Loss = 2.1254e-02, PNorm = 42.4703, GNorm = 3.1229, lr_0 = 7.3039e-04
Loss = 2.0940e-02, PNorm = 42.4943, GNorm = 4.4333, lr_0 = 7.2941e-04
Loss = 2.0937e-02, PNorm = 42.5274, GNorm = 2.7079, lr_0 = 7.2843e-04
Loss = 1.9290e-02, PNorm = 42.5537, GNorm = 1.8205, lr_0 = 7.2746e-04
Loss = 1.7877e-02, PNorm = 42.5888, GNorm = 2.5301, lr_0 = 7.2648e-04
Loss = 1.8989e-02, PNorm = 42.6244, GNorm = 2.3294, lr_0 = 7.2551e-04
Loss = 1.5912e-02, PNorm = 42.6451, GNorm = 1.8948, lr_0 = 7.2453e-04
Loss = 2.0961e-02, PNorm = 42.6681, GNorm = 3.0393, lr_0 = 7.2356e-04
Loss = 1.8314e-02, PNorm = 42.6870, GNorm = 1.8193, lr_0 = 7.2259e-04
Loss = 1.7615e-02, PNorm = 42.7106, GNorm = 3.5554, lr_0 = 7.2162e-04
Loss = 2.1475e-02, PNorm = 42.7324, GNorm = 1.5966, lr_0 = 7.2065e-04
Loss = 2.1022e-02, PNorm = 42.7718, GNorm = 2.8940, lr_0 = 7.1969e-04
Loss = 1.8710e-02, PNorm = 42.8063, GNorm = 2.3780, lr_0 = 7.1872e-04
Loss = 1.8265e-02, PNorm = 42.8422, GNorm = 3.4070, lr_0 = 7.1776e-04
Loss = 3.0337e-02, PNorm = 42.8466, GNorm = 3.6870, lr_0 = 7.1766e-04
Validation rmse = 1.739007
Validation R2 = 0.135621
Epoch 12
Train function
Loss = 1.7581e-02, PNorm = 42.8760, GNorm = 1.8201, lr_0 = 7.1670e-04
Loss = 1.7811e-02, PNorm = 42.9078, GNorm = 1.6954, lr_0 = 7.1573e-04
Loss = 2.0406e-02, PNorm = 42.9494, GNorm = 2.0064, lr_0 = 7.1477e-04
Loss = 1.9194e-02, PNorm = 42.9894, GNorm = 2.9621, lr_0 = 7.1382e-04
Loss = 1.7405e-02, PNorm = 43.0302, GNorm = 1.5390, lr_0 = 7.1286e-04
Loss = 1.8376e-02, PNorm = 43.0628, GNorm = 2.3654, lr_0 = 7.1190e-04
Loss = 1.7405e-02, PNorm = 43.0857, GNorm = 1.7560, lr_0 = 7.1095e-04
Loss = 1.8517e-02, PNorm = 43.1082, GNorm = 1.7182, lr_0 = 7.0999e-04
Loss = 2.1111e-02, PNorm = 43.1368, GNorm = 3.9995, lr_0 = 7.0904e-04
Loss = 2.0566e-02, PNorm = 43.1734, GNorm = 3.6388, lr_0 = 7.0809e-04
Loss = 1.8270e-02, PNorm = 43.2142, GNorm = 2.4715, lr_0 = 7.0714e-04
Loss = 2.1712e-02, PNorm = 43.2529, GNorm = 2.7096, lr_0 = 7.0619e-04
Loss = 1.9125e-02, PNorm = 43.2999, GNorm = 4.6702, lr_0 = 7.0524e-04
Loss = 1.9794e-02, PNorm = 43.3324, GNorm = 2.6686, lr_0 = 7.0430e-04
Loss = 1.7467e-02, PNorm = 43.3520, GNorm = 1.6553, lr_0 = 7.0335e-04
Loss = 1.7445e-02, PNorm = 43.3642, GNorm = 2.7176, lr_0 = 7.0241e-04
Loss = 1.8725e-02, PNorm = 43.3808, GNorm = 1.9742, lr_0 = 7.0146e-04
Loss = 1.8501e-02, PNorm = 43.4049, GNorm = 2.7287, lr_0 = 7.0052e-04
Loss = 1.9118e-02, PNorm = 43.4433, GNorm = 2.7773, lr_0 = 6.9958e-04
Loss = 1.9019e-02, PNorm = 43.4770, GNorm = 2.2167, lr_0 = 6.9865e-04
Loss = 1.8721e-02, PNorm = 43.5046, GNorm = 1.7718, lr_0 = 6.9771e-04
Loss = 1.7442e-02, PNorm = 43.5333, GNorm = 1.5953, lr_0 = 6.9677e-04
Loss = 1.9702e-02, PNorm = 43.5596, GNorm = 2.2215, lr_0 = 6.9584e-04
Validation rmse = 1.331097
Validation R2 = 0.493568
Epoch 13
Train function
Loss = 1.7603e-02, PNorm = 43.5902, GNorm = 2.0144, lr_0 = 6.9481e-04
Loss = 1.6744e-02, PNorm = 43.6209, GNorm = 1.6073, lr_0 = 6.9388e-04
Loss = 1.7565e-02, PNorm = 43.6526, GNorm = 2.2707, lr_0 = 6.9295e-04
Loss = 1.8052e-02, PNorm = 43.6834, GNorm = 2.5315, lr_0 = 6.9202e-04
Loss = 1.6699e-02, PNorm = 43.7170, GNorm = 4.5670, lr_0 = 6.9109e-04
Loss = 1.9008e-02, PNorm = 43.7585, GNorm = 2.4746, lr_0 = 6.9016e-04
Loss = 2.1232e-02, PNorm = 43.7958, GNorm = 3.2821, lr_0 = 6.8924e-04
Loss = 1.6185e-02, PNorm = 43.8345, GNorm = 3.2587, lr_0 = 6.8831e-04
Loss = 1.7709e-02, PNorm = 43.8580, GNorm = 4.7756, lr_0 = 6.8739e-04
Loss = 1.8896e-02, PNorm = 43.8975, GNorm = 3.4917, lr_0 = 6.8646e-04
Loss = 1.6930e-02, PNorm = 43.9306, GNorm = 3.1327, lr_0 = 6.8554e-04
Loss = 1.9739e-02, PNorm = 43.9664, GNorm = 2.2488, lr_0 = 6.8462e-04
Loss = 1.9538e-02, PNorm = 43.9857, GNorm = 2.3683, lr_0 = 6.8371e-04
Loss = 1.6186e-02, PNorm = 44.0223, GNorm = 1.8167, lr_0 = 6.8279e-04
Loss = 2.1206e-02, PNorm = 44.0536, GNorm = 2.6847, lr_0 = 6.8187e-04
Loss = 2.0369e-02, PNorm = 44.0891, GNorm = 2.5768, lr_0 = 6.8096e-04
Loss = 1.9254e-02, PNorm = 44.1291, GNorm = 5.1708, lr_0 = 6.8004e-04
Loss = 1.6600e-02, PNorm = 44.1598, GNorm = 1.5294, lr_0 = 6.7913e-04
Loss = 1.5695e-02, PNorm = 44.1838, GNorm = 1.6354, lr_0 = 6.7822e-04
Loss = 1.8975e-02, PNorm = 44.2130, GNorm = 3.1764, lr_0 = 6.7731e-04
Loss = 1.8947e-02, PNorm = 44.2341, GNorm = 3.8562, lr_0 = 6.7640e-04
Loss = 1.9952e-02, PNorm = 44.2523, GNorm = 2.5232, lr_0 = 6.7549e-04
Loss = 1.6730e-02, PNorm = 44.2844, GNorm = 1.7898, lr_0 = 6.7459e-04
Validation rmse = 2.273227
Validation R2 = -0.477022
Epoch 14
Train function
Loss = 1.5404e-02, PNorm = 44.3156, GNorm = 2.1146, lr_0 = 6.7359e-04
Loss = 1.6208e-02, PNorm = 44.3596, GNorm = 2.3085, lr_0 = 6.7269e-04
Loss = 1.6555e-02, PNorm = 44.3959, GNorm = 2.7870, lr_0 = 6.7179e-04
Loss = 1.8547e-02, PNorm = 44.4274, GNorm = 2.7293, lr_0 = 6.7088e-04
Loss = 1.9562e-02, PNorm = 44.4581, GNorm = 2.0853, lr_0 = 6.6998e-04
Loss = 1.8471e-02, PNorm = 44.4952, GNorm = 2.1913, lr_0 = 6.6908e-04
Loss = 1.7670e-02, PNorm = 44.5244, GNorm = 1.7502, lr_0 = 6.6819e-04
Loss = 1.8307e-02, PNorm = 44.5465, GNorm = 2.1725, lr_0 = 6.6729e-04
Loss = 1.6399e-02, PNorm = 44.5877, GNorm = 2.1170, lr_0 = 6.6640e-04
Loss = 1.7767e-02, PNorm = 44.6235, GNorm = 1.5866, lr_0 = 6.6550e-04
Loss = 1.7282e-02, PNorm = 44.6525, GNorm = 2.6920, lr_0 = 6.6461e-04
Loss = 1.7574e-02, PNorm = 44.6766, GNorm = 3.0035, lr_0 = 6.6372e-04
Loss = 1.5624e-02, PNorm = 44.7012, GNorm = 3.3764, lr_0 = 6.6283e-04
Loss = 1.5858e-02, PNorm = 44.7317, GNorm = 2.2203, lr_0 = 6.6194e-04
Loss = 2.0124e-02, PNorm = 44.7693, GNorm = 1.7834, lr_0 = 6.6105e-04
Loss = 1.7667e-02, PNorm = 44.8019, GNorm = 2.3199, lr_0 = 6.6016e-04
Loss = 1.8795e-02, PNorm = 44.8263, GNorm = 3.5592, lr_0 = 6.5928e-04
Loss = 1.8708e-02, PNorm = 44.8465, GNorm = 2.4524, lr_0 = 6.5839e-04
Loss = 1.7237e-02, PNorm = 44.8788, GNorm = 3.2284, lr_0 = 6.5751e-04
Loss = 1.7197e-02, PNorm = 44.9144, GNorm = 1.6060, lr_0 = 6.5663e-04
Loss = 1.7855e-02, PNorm = 44.9413, GNorm = 2.2744, lr_0 = 6.5574e-04
Loss = 2.0236e-02, PNorm = 44.9771, GNorm = 2.6423, lr_0 = 6.5486e-04
Loss = 1.7658e-02, PNorm = 45.0058, GNorm = 2.1775, lr_0 = 6.5399e-04
Loss = 1.5705e-02, PNorm = 45.0383, GNorm = 2.9892, lr_0 = 6.5311e-04
Validation rmse = 1.798847
Validation R2 = 0.075110
Epoch 15
Train function
Loss = 1.5788e-02, PNorm = 45.0655, GNorm = 2.5308, lr_0 = 6.5223e-04
Loss = 1.5885e-02, PNorm = 45.0967, GNorm = 1.8991, lr_0 = 6.5136e-04
Loss = 1.6484e-02, PNorm = 45.1417, GNorm = 3.0822, lr_0 = 6.5048e-04
Loss = 1.5538e-02, PNorm = 45.1692, GNorm = 3.4043, lr_0 = 6.4961e-04
Loss = 1.6092e-02, PNorm = 45.2029, GNorm = 2.0235, lr_0 = 6.4874e-04
Loss = 1.8263e-02, PNorm = 45.2354, GNorm = 1.8926, lr_0 = 6.4787e-04
Loss = 1.8699e-02, PNorm = 45.2676, GNorm = 2.3003, lr_0 = 6.4700e-04
Loss = 1.9075e-02, PNorm = 45.2948, GNorm = 1.3918, lr_0 = 6.4613e-04
Loss = 1.5843e-02, PNorm = 45.3241, GNorm = 1.6158, lr_0 = 6.4526e-04
Loss = 1.8055e-02, PNorm = 45.3593, GNorm = 2.4763, lr_0 = 6.4440e-04
Loss = 1.7070e-02, PNorm = 45.3782, GNorm = 4.7234, lr_0 = 6.4353e-04
Loss = 1.7887e-02, PNorm = 45.4088, GNorm = 2.2754, lr_0 = 6.4267e-04
Loss = 1.8618e-02, PNorm = 45.4380, GNorm = 2.7040, lr_0 = 6.4181e-04
Loss = 1.6550e-02, PNorm = 45.4645, GNorm = 2.8729, lr_0 = 6.4095e-04
Loss = 1.8423e-02, PNorm = 45.4986, GNorm = 2.1736, lr_0 = 6.4009e-04
Loss = 1.8012e-02, PNorm = 45.5273, GNorm = 1.7511, lr_0 = 6.3923e-04
Loss = 1.6397e-02, PNorm = 45.5592, GNorm = 3.2465, lr_0 = 6.3837e-04
Loss = 1.4712e-02, PNorm = 45.5771, GNorm = 2.9480, lr_0 = 6.3751e-04
Loss = 1.7822e-02, PNorm = 45.6158, GNorm = 1.9902, lr_0 = 6.3666e-04
Loss = 1.5113e-02, PNorm = 45.6370, GNorm = 2.4464, lr_0 = 6.3580e-04
Loss = 1.8093e-02, PNorm = 45.6546, GNorm = 4.1585, lr_0 = 6.3495e-04
Loss = 1.7103e-02, PNorm = 45.6758, GNorm = 2.1029, lr_0 = 6.3410e-04
Loss = 1.8268e-02, PNorm = 45.6951, GNorm = 3.2785, lr_0 = 6.3325e-04
Validation rmse = 1.666143
Validation R2 = 0.206538
Epoch 16
Train function
Loss = 1.4813e-02, PNorm = 45.7245, GNorm = 4.0697, lr_0 = 6.3231e-04
Loss = 1.7445e-02, PNorm = 45.7495, GNorm = 3.8831, lr_0 = 6.3147e-04
Loss = 1.5898e-02, PNorm = 45.7890, GNorm = 2.0087, lr_0 = 6.3062e-04
Loss = 1.6605e-02, PNorm = 45.8150, GNorm = 2.0358, lr_0 = 6.2977e-04
Loss = 1.5160e-02, PNorm = 45.8355, GNorm = 2.4611, lr_0 = 6.2893e-04
Loss = 1.6047e-02, PNorm = 45.8593, GNorm = 2.5591, lr_0 = 6.2808e-04
Loss = 1.4840e-02, PNorm = 45.8974, GNorm = 1.7785, lr_0 = 6.2724e-04
Loss = 1.7899e-02, PNorm = 45.9272, GNorm = 2.6375, lr_0 = 6.2640e-04
Loss = 1.7111e-02, PNorm = 45.9603, GNorm = 5.2880, lr_0 = 6.2556e-04
Loss = 1.5300e-02, PNorm = 46.0028, GNorm = 2.5276, lr_0 = 6.2472e-04
Loss = 1.4966e-02, PNorm = 46.0320, GNorm = 2.1996, lr_0 = 6.2388e-04
Loss = 1.5588e-02, PNorm = 46.0573, GNorm = 2.9426, lr_0 = 6.2304e-04
Loss = 1.5558e-02, PNorm = 46.0922, GNorm = 2.1978, lr_0 = 6.2221e-04
Loss = 1.6042e-02, PNorm = 46.1259, GNorm = 2.4271, lr_0 = 6.2137e-04
Loss = 1.8497e-02, PNorm = 46.1505, GNorm = 4.9149, lr_0 = 6.2054e-04
Loss = 1.6298e-02, PNorm = 46.1846, GNorm = 1.7377, lr_0 = 6.1971e-04
Loss = 1.5965e-02, PNorm = 46.2145, GNorm = 1.6292, lr_0 = 6.1888e-04
Loss = 1.5315e-02, PNorm = 46.2477, GNorm = 3.9032, lr_0 = 6.1805e-04
Loss = 1.8388e-02, PNorm = 46.2821, GNorm = 3.6545, lr_0 = 6.1722e-04
Loss = 1.7128e-02, PNorm = 46.3138, GNorm = 2.6800, lr_0 = 6.1639e-04
Loss = 1.5759e-02, PNorm = 46.3377, GNorm = 2.4447, lr_0 = 6.1556e-04
Loss = 1.6494e-02, PNorm = 46.3632, GNorm = 2.3265, lr_0 = 6.1474e-04
Loss = 1.8100e-02, PNorm = 46.3935, GNorm = 3.2931, lr_0 = 6.1391e-04
Loss = 1.7022e-02, PNorm = 46.4202, GNorm = 2.5138, lr_0 = 6.1309e-04
Validation rmse = 2.364125
Validation R2 = -0.597505
Epoch 17
Train function
Loss = 1.6358e-02, PNorm = 46.4535, GNorm = 4.3969, lr_0 = 6.1218e-04
Loss = 1.7114e-02, PNorm = 46.4933, GNorm = 3.2611, lr_0 = 6.1136e-04
Loss = 1.5207e-02, PNorm = 46.5370, GNorm = 2.2586, lr_0 = 6.1054e-04
Loss = 1.6949e-02, PNorm = 46.5678, GNorm = 3.0021, lr_0 = 6.0972e-04
Loss = 1.5466e-02, PNorm = 46.5956, GNorm = 2.7523, lr_0 = 6.0890e-04
Loss = 1.4359e-02, PNorm = 46.6196, GNorm = 4.2630, lr_0 = 6.0809e-04
Loss = 1.7022e-02, PNorm = 46.6428, GNorm = 2.8382, lr_0 = 6.0727e-04
Loss = 1.5432e-02, PNorm = 46.6673, GNorm = 3.4228, lr_0 = 6.0646e-04
Loss = 1.7388e-02, PNorm = 46.6953, GNorm = 2.0242, lr_0 = 6.0564e-04
Loss = 1.3654e-02, PNorm = 46.7177, GNorm = 2.7967, lr_0 = 6.0483e-04
Loss = 1.4810e-02, PNorm = 46.7487, GNorm = 1.8841, lr_0 = 6.0402e-04
Loss = 1.6221e-02, PNorm = 46.7802, GNorm = 3.8692, lr_0 = 6.0321e-04
Loss = 1.7064e-02, PNorm = 46.8168, GNorm = 4.1378, lr_0 = 6.0240e-04
Loss = 1.5502e-02, PNorm = 46.8497, GNorm = 3.5292, lr_0 = 6.0159e-04
Loss = 1.6744e-02, PNorm = 46.8785, GNorm = 2.8778, lr_0 = 6.0078e-04
Loss = 1.5785e-02, PNorm = 46.9094, GNorm = 3.5117, lr_0 = 5.9998e-04
Loss = 1.7242e-02, PNorm = 46.9253, GNorm = 3.5262, lr_0 = 5.9917e-04
Loss = 1.6050e-02, PNorm = 46.9509, GNorm = 2.6430, lr_0 = 5.9837e-04
Loss = 1.6842e-02, PNorm = 46.9752, GNorm = 2.7318, lr_0 = 5.9756e-04
Loss = 1.7032e-02, PNorm = 47.0047, GNorm = 3.1747, lr_0 = 5.9676e-04
Loss = 1.5227e-02, PNorm = 47.0375, GNorm = 2.8539, lr_0 = 5.9596e-04
Loss = 1.4208e-02, PNorm = 47.0611, GNorm = 1.8243, lr_0 = 5.9516e-04
Loss = 1.6452e-02, PNorm = 47.0858, GNorm = 2.2509, lr_0 = 5.9436e-04
Validation rmse = 2.071338
Validation R2 = -0.226318
Epoch 18
Train function
Loss = 1.3541e-02, PNorm = 47.1141, GNorm = 2.3301, lr_0 = 5.9349e-04
Loss = 1.5235e-02, PNorm = 47.1476, GNorm = 1.7608, lr_0 = 5.9269e-04
Loss = 1.4934e-02, PNorm = 47.1828, GNorm = 2.8796, lr_0 = 5.9190e-04
Loss = 1.4775e-02, PNorm = 47.2175, GNorm = 2.6904, lr_0 = 5.9110e-04
Loss = 1.3279e-02, PNorm = 47.2600, GNorm = 2.7828, lr_0 = 5.9031e-04
Loss = 1.6440e-02, PNorm = 47.2934, GNorm = 5.6480, lr_0 = 5.8952e-04
Loss = 1.5893e-02, PNorm = 47.3196, GNorm = 3.7611, lr_0 = 5.8873e-04
Loss = 1.6335e-02, PNorm = 47.3525, GNorm = 3.6365, lr_0 = 5.8794e-04
Loss = 1.6038e-02, PNorm = 47.3939, GNorm = 3.6296, lr_0 = 5.8715e-04
Loss = 1.5695e-02, PNorm = 47.4236, GNorm = 3.6274, lr_0 = 5.8636e-04
Loss = 1.3336e-02, PNorm = 47.4515, GNorm = 2.2345, lr_0 = 5.8557e-04
Loss = 1.5683e-02, PNorm = 47.4815, GNorm = 2.7840, lr_0 = 5.8479e-04
Loss = 1.3871e-02, PNorm = 47.5088, GNorm = 3.2156, lr_0 = 5.8400e-04
Loss = 1.5823e-02, PNorm = 47.5339, GNorm = 2.9833, lr_0 = 5.8322e-04
Loss = 1.6794e-02, PNorm = 47.5562, GNorm = 2.3634, lr_0 = 5.8244e-04
Loss = 1.6666e-02, PNorm = 47.5823, GNorm = 2.8695, lr_0 = 5.8165e-04
Loss = 1.4810e-02, PNorm = 47.6045, GNorm = 2.0826, lr_0 = 5.8087e-04
Loss = 1.3897e-02, PNorm = 47.6322, GNorm = 3.9560, lr_0 = 5.8009e-04
Loss = 1.6350e-02, PNorm = 47.6594, GNorm = 3.8090, lr_0 = 5.7932e-04
Loss = 1.7400e-02, PNorm = 47.6932, GNorm = 2.2774, lr_0 = 5.7854e-04
Loss = 1.5053e-02, PNorm = 47.7240, GNorm = 2.4586, lr_0 = 5.7776e-04
Loss = 1.4545e-02, PNorm = 47.7498, GNorm = 4.0396, lr_0 = 5.7699e-04
Loss = 1.6437e-02, PNorm = 47.7734, GNorm = 2.6545, lr_0 = 5.7621e-04
Validation rmse = 1.979243
Validation R2 = -0.119694
Epoch 19
Train function
Loss = 1.1062e-02, PNorm = 47.7989, GNorm = 2.2315, lr_0 = 5.7536e-04
Loss = 1.4416e-02, PNorm = 47.8209, GNorm = 3.5448, lr_0 = 5.7459e-04
Loss = 1.3006e-02, PNorm = 47.8595, GNorm = 2.6227, lr_0 = 5.7382e-04
Loss = 1.4794e-02, PNorm = 47.8925, GNorm = 2.6374, lr_0 = 5.7305e-04
Loss = 1.4751e-02, PNorm = 47.9199, GNorm = 3.4428, lr_0 = 5.7228e-04
Loss = 1.5508e-02, PNorm = 47.9467, GNorm = 2.2641, lr_0 = 5.7151e-04
Loss = 1.3230e-02, PNorm = 47.9821, GNorm = 3.3848, lr_0 = 5.7075e-04
Loss = 1.4685e-02, PNorm = 48.0129, GNorm = 2.1225, lr_0 = 5.6998e-04
Loss = 1.4639e-02, PNorm = 48.0477, GNorm = 2.3982, lr_0 = 5.6922e-04
Loss = 1.4213e-02, PNorm = 48.0773, GNorm = 2.4538, lr_0 = 5.6845e-04
Loss = 1.3530e-02, PNorm = 48.1057, GNorm = 2.6364, lr_0 = 5.6769e-04
Loss = 1.4054e-02, PNorm = 48.1358, GNorm = 2.9478, lr_0 = 5.6693e-04
Loss = 1.3577e-02, PNorm = 48.1555, GNorm = 2.1646, lr_0 = 5.6617e-04
Loss = 1.5639e-02, PNorm = 48.1895, GNorm = 3.2412, lr_0 = 5.6541e-04
Loss = 1.5242e-02, PNorm = 48.2143, GNorm = 3.1670, lr_0 = 5.6465e-04
Loss = 1.4896e-02, PNorm = 48.2361, GNorm = 2.5864, lr_0 = 5.6389e-04
Loss = 1.7159e-02, PNorm = 48.2589, GNorm = 2.7555, lr_0 = 5.6313e-04
Loss = 1.2252e-02, PNorm = 48.2844, GNorm = 2.1574, lr_0 = 5.6238e-04
Loss = 1.3737e-02, PNorm = 48.3095, GNorm = 2.8937, lr_0 = 5.6162e-04
Loss = 1.4862e-02, PNorm = 48.3368, GNorm = 2.0966, lr_0 = 5.6087e-04
Loss = 1.3069e-02, PNorm = 48.3618, GNorm = 2.3709, lr_0 = 5.6012e-04
Loss = 1.5049e-02, PNorm = 48.3870, GNorm = 2.0571, lr_0 = 5.5937e-04
Loss = 1.7555e-02, PNorm = 48.4057, GNorm = 3.8611, lr_0 = 5.5862e-04
Loss = 1.6827e-02, PNorm = 48.4438, GNorm = 2.7810, lr_0 = 5.5787e-04
Validation rmse = 2.827068
Validation R2 = -1.284409
Epoch 20
Train function
Loss = 1.4761e-02, PNorm = 48.4742, GNorm = 1.9173, lr_0 = 5.5712e-04
Loss = 1.2950e-02, PNorm = 48.5029, GNorm = 2.6489, lr_0 = 5.5637e-04
Loss = 1.5847e-02, PNorm = 48.5348, GNorm = 4.5595, lr_0 = 5.5562e-04
Loss = 1.3526e-02, PNorm = 48.5594, GNorm = 2.3621, lr_0 = 5.5488e-04
Loss = 1.4034e-02, PNorm = 48.5837, GNorm = 3.0921, lr_0 = 5.5413e-04
Loss = 1.2574e-02, PNorm = 48.6129, GNorm = 2.3157, lr_0 = 5.5339e-04
Loss = 1.2768e-02, PNorm = 48.6424, GNorm = 2.9372, lr_0 = 5.5265e-04
Loss = 1.3111e-02, PNorm = 48.6764, GNorm = 2.7067, lr_0 = 5.5191e-04
Loss = 1.3113e-02, PNorm = 48.7069, GNorm = 2.0810, lr_0 = 5.5117e-04
Loss = 1.4521e-02, PNorm = 48.7294, GNorm = 3.8589, lr_0 = 5.5043e-04
Loss = 1.4402e-02, PNorm = 48.7559, GNorm = 2.6906, lr_0 = 5.4969e-04
Loss = 1.4946e-02, PNorm = 48.7872, GNorm = 2.6220, lr_0 = 5.4895e-04
Loss = 1.5335e-02, PNorm = 48.8132, GNorm = 3.8766, lr_0 = 5.4821e-04
Loss = 1.4117e-02, PNorm = 48.8422, GNorm = 3.0886, lr_0 = 5.4748e-04
Loss = 1.2905e-02, PNorm = 48.8746, GNorm = 2.5692, lr_0 = 5.4674e-04
Loss = 1.4546e-02, PNorm = 48.8958, GNorm = 3.7190, lr_0 = 5.4601e-04
Loss = 1.4141e-02, PNorm = 48.9190, GNorm = 5.9942, lr_0 = 5.4528e-04
Loss = 1.4922e-02, PNorm = 48.9447, GNorm = 2.4818, lr_0 = 5.4455e-04
Loss = 1.5695e-02, PNorm = 48.9673, GNorm = 2.5909, lr_0 = 5.4382e-04
Loss = 1.3656e-02, PNorm = 48.9958, GNorm = 2.7503, lr_0 = 5.4309e-04
Loss = 1.4778e-02, PNorm = 49.0130, GNorm = 3.3600, lr_0 = 5.4236e-04
Loss = 1.3105e-02, PNorm = 49.0368, GNorm = 2.4650, lr_0 = 5.4163e-04
Loss = 1.3016e-02, PNorm = 49.0589, GNorm = 2.5686, lr_0 = 5.4090e-04
Validation rmse = 2.263099
Validation R2 = -0.463890
Epoch 21
Train function
Loss = 1.3584e-02, PNorm = 49.0879, GNorm = 2.6302, lr_0 = 5.4010e-04
Loss = 1.2229e-02, PNorm = 49.1195, GNorm = 4.0625, lr_0 = 5.3938e-04
Loss = 1.1848e-02, PNorm = 49.1438, GNorm = 2.3557, lr_0 = 5.3866e-04
Loss = 1.4118e-02, PNorm = 49.1728, GNorm = 3.2113, lr_0 = 5.3793e-04
Loss = 1.2999e-02, PNorm = 49.1998, GNorm = 3.2477, lr_0 = 5.3721e-04
Loss = 1.3382e-02, PNorm = 49.2249, GNorm = 2.4875, lr_0 = 5.3649e-04
Loss = 1.3100e-02, PNorm = 49.2471, GNorm = 2.6284, lr_0 = 5.3577e-04
Loss = 1.4739e-02, PNorm = 49.2772, GNorm = 2.0329, lr_0 = 5.3505e-04
Loss = 1.3614e-02, PNorm = 49.3067, GNorm = 2.7004, lr_0 = 5.3433e-04
Loss = 1.3113e-02, PNorm = 49.3223, GNorm = 3.2616, lr_0 = 5.3362e-04
Loss = 1.3543e-02, PNorm = 49.3477, GNorm = 3.4175, lr_0 = 5.3290e-04
Loss = 1.2863e-02, PNorm = 49.3665, GNorm = 3.3721, lr_0 = 5.3219e-04
Loss = 1.3818e-02, PNorm = 49.4033, GNorm = 2.9887, lr_0 = 5.3147e-04
Loss = 1.2786e-02, PNorm = 49.4298, GNorm = 2.7729, lr_0 = 5.3076e-04
Loss = 1.2858e-02, PNorm = 49.4512, GNorm = 3.7828, lr_0 = 5.3005e-04
Loss = 1.2893e-02, PNorm = 49.4691, GNorm = 2.2490, lr_0 = 5.2934e-04
Loss = 1.2961e-02, PNorm = 49.4933, GNorm = 3.3149, lr_0 = 5.2863e-04
Loss = 1.3596e-02, PNorm = 49.5234, GNorm = 2.3462, lr_0 = 5.2792e-04
Loss = 1.2434e-02, PNorm = 49.5570, GNorm = 3.8001, lr_0 = 5.2721e-04
Loss = 1.4004e-02, PNorm = 49.5833, GNorm = 2.7172, lr_0 = 5.2650e-04
Loss = 1.2103e-02, PNorm = 49.6153, GNorm = 2.4563, lr_0 = 5.2579e-04
Loss = 1.6790e-02, PNorm = 49.6373, GNorm = 6.0604, lr_0 = 5.2509e-04
Loss = 1.3095e-02, PNorm = 49.6688, GNorm = 3.0981, lr_0 = 5.2438e-04
Loss = 1.3383e-02, PNorm = 49.6907, GNorm = 2.0648, lr_0 = 5.2368e-04
Validation rmse = 2.842982
Validation R2 = -1.310200
Epoch 22
Train function
Loss = 1.2231e-02, PNorm = 49.7278, GNorm = 3.0151, lr_0 = 5.2291e-04
Loss = 1.1739e-02, PNorm = 49.7510, GNorm = 3.4258, lr_0 = 5.2221e-04
Loss = 1.2969e-02, PNorm = 49.7803, GNorm = 2.4836, lr_0 = 5.2151e-04
Loss = 1.1773e-02, PNorm = 49.8062, GNorm = 3.1523, lr_0 = 5.2081e-04
Loss = 1.2484e-02, PNorm = 49.8355, GNorm = 2.6435, lr_0 = 5.2011e-04
Loss = 1.2478e-02, PNorm = 49.8626, GNorm = 3.8404, lr_0 = 5.1941e-04
Loss = 1.2031e-02, PNorm = 49.8952, GNorm = 2.7284, lr_0 = 5.1871e-04
Loss = 1.2363e-02, PNorm = 49.9203, GNorm = 4.0060, lr_0 = 5.1802e-04
Loss = 1.2832e-02, PNorm = 49.9443, GNorm = 3.3211, lr_0 = 5.1732e-04
Loss = 1.4260e-02, PNorm = 49.9728, GNorm = 3.6549, lr_0 = 5.1663e-04
Loss = 1.2280e-02, PNorm = 49.9998, GNorm = 3.6562, lr_0 = 5.1593e-04
Loss = 1.2521e-02, PNorm = 50.0235, GNorm = 2.5571, lr_0 = 5.1524e-04
Loss = 1.3491e-02, PNorm = 50.0508, GNorm = 2.8258, lr_0 = 5.1455e-04
Loss = 1.2002e-02, PNorm = 50.0786, GNorm = 2.5306, lr_0 = 5.1386e-04
Loss = 1.1977e-02, PNorm = 50.1007, GNorm = 2.4254, lr_0 = 5.1317e-04
Loss = 1.1054e-02, PNorm = 50.1159, GNorm = 3.1883, lr_0 = 5.1248e-04
Loss = 1.2552e-02, PNorm = 50.1326, GNorm = 3.5826, lr_0 = 5.1180e-04
Loss = 1.2727e-02, PNorm = 50.1564, GNorm = 4.4615, lr_0 = 5.1111e-04
Loss = 1.3330e-02, PNorm = 50.1839, GNorm = 4.4713, lr_0 = 5.1042e-04
Loss = 1.2757e-02, PNorm = 50.2133, GNorm = 3.3659, lr_0 = 5.0974e-04
Loss = 1.3891e-02, PNorm = 50.2324, GNorm = 5.1607, lr_0 = 5.0905e-04
Loss = 1.2648e-02, PNorm = 50.2577, GNorm = 3.4871, lr_0 = 5.0837e-04
Loss = 1.3321e-02, PNorm = 50.2725, GNorm = 2.2964, lr_0 = 5.0769e-04
Validation rmse = 2.507562
Validation R2 = -0.797235
Epoch 23
Train function
Loss = 9.3402e-03, PNorm = 50.2918, GNorm = 2.5968, lr_0 = 5.0694e-04
Loss = 1.1243e-02, PNorm = 50.3183, GNorm = 2.6997, lr_0 = 5.0626e-04
Loss = 1.0874e-02, PNorm = 50.3436, GNorm = 4.4161, lr_0 = 5.0558e-04
Loss = 1.0913e-02, PNorm = 50.3704, GNorm = 3.0671, lr_0 = 5.0490e-04
Loss = 1.3803e-02, PNorm = 50.3936, GNorm = 3.7696, lr_0 = 5.0422e-04
Loss = 1.1559e-02, PNorm = 50.4219, GNorm = 2.4416, lr_0 = 5.0355e-04
Loss = 1.1415e-02, PNorm = 50.4505, GNorm = 2.8886, lr_0 = 5.0287e-04
Loss = 1.1115e-02, PNorm = 50.4752, GNorm = 3.4023, lr_0 = 5.0220e-04
Loss = 1.1817e-02, PNorm = 50.5020, GNorm = 3.6556, lr_0 = 5.0152e-04
Loss = 1.1644e-02, PNorm = 50.5279, GNorm = 2.4723, lr_0 = 5.0085e-04
Loss = 1.2773e-02, PNorm = 50.5541, GNorm = 4.8829, lr_0 = 5.0018e-04
Loss = 1.2151e-02, PNorm = 50.5761, GNorm = 2.3851, lr_0 = 4.9951e-04
Loss = 1.2217e-02, PNorm = 50.6018, GNorm = 2.6191, lr_0 = 4.9884e-04
Loss = 1.2931e-02, PNorm = 50.6314, GNorm = 2.1434, lr_0 = 4.9817e-04
Loss = 1.2473e-02, PNorm = 50.6577, GNorm = 2.9569, lr_0 = 4.9750e-04
Loss = 1.3840e-02, PNorm = 50.6785, GNorm = 3.4250, lr_0 = 4.9683e-04
Loss = 1.1268e-02, PNorm = 50.6996, GNorm = 2.9601, lr_0 = 4.9617e-04
Loss = 1.4743e-02, PNorm = 50.7118, GNorm = 4.1993, lr_0 = 4.9550e-04
Loss = 1.0303e-02, PNorm = 50.7335, GNorm = 2.4810, lr_0 = 4.9484e-04
Loss = 1.1874e-02, PNorm = 50.7525, GNorm = 4.1755, lr_0 = 4.9417e-04
Loss = 1.2017e-02, PNorm = 50.7772, GNorm = 2.0626, lr_0 = 4.9351e-04
Loss = 1.1056e-02, PNorm = 50.7992, GNorm = 2.5013, lr_0 = 4.9285e-04
Loss = 1.3909e-02, PNorm = 50.8225, GNorm = 2.9843, lr_0 = 4.9218e-04
Loss = 1.3917e-02, PNorm = 50.8529, GNorm = 3.0295, lr_0 = 4.9152e-04
Loss = 4.8843e-02, PNorm = 50.8563, GNorm = 4.8362, lr_0 = 4.9146e-04
Validation rmse = 2.521857
Validation R2 = -0.817785
Epoch 24
Train function
Loss = 1.1575e-02, PNorm = 50.8823, GNorm = 3.6441, lr_0 = 4.9080e-04
Loss = 1.2065e-02, PNorm = 50.9126, GNorm = 3.1255, lr_0 = 4.9014e-04
Loss = 1.1320e-02, PNorm = 50.9415, GNorm = 3.3756, lr_0 = 4.8948e-04
Loss = 9.9718e-03, PNorm = 50.9686, GNorm = 2.5106, lr_0 = 4.8883e-04
Loss = 1.0265e-02, PNorm = 50.9955, GNorm = 3.3577, lr_0 = 4.8817e-04
Loss = 1.1816e-02, PNorm = 51.0137, GNorm = 4.1623, lr_0 = 4.8752e-04
Loss = 1.1129e-02, PNorm = 51.0403, GNorm = 2.5151, lr_0 = 4.8686e-04
Loss = 1.1819e-02, PNorm = 51.0688, GNorm = 3.7536, lr_0 = 4.8621e-04
Loss = 9.7484e-03, PNorm = 51.0935, GNorm = 1.9368, lr_0 = 4.8556e-04
Loss = 1.2068e-02, PNorm = 51.1155, GNorm = 3.6651, lr_0 = 4.8490e-04
Loss = 1.0282e-02, PNorm = 51.1417, GNorm = 2.1848, lr_0 = 4.8425e-04
Loss = 1.0385e-02, PNorm = 51.1580, GNorm = 2.5024, lr_0 = 4.8360e-04
Loss = 1.0636e-02, PNorm = 51.1773, GNorm = 2.6020, lr_0 = 4.8296e-04
Loss = 1.2173e-02, PNorm = 51.1945, GNorm = 3.5525, lr_0 = 4.8231e-04
Loss = 1.1338e-02, PNorm = 51.2186, GNorm = 3.9673, lr_0 = 4.8166e-04
Loss = 1.0790e-02, PNorm = 51.2377, GNorm = 4.6056, lr_0 = 4.8101e-04
Loss = 1.0970e-02, PNorm = 51.2561, GNorm = 2.1317, lr_0 = 4.8037e-04
Loss = 1.1117e-02, PNorm = 51.2755, GNorm = 2.7056, lr_0 = 4.7972e-04
Loss = 1.2559e-02, PNorm = 51.3040, GNorm = 3.1056, lr_0 = 4.7908e-04
Loss = 1.4555e-02, PNorm = 51.3215, GNorm = 5.4176, lr_0 = 4.7844e-04
Loss = 1.3505e-02, PNorm = 51.3467, GNorm = 3.1637, lr_0 = 4.7780e-04
Loss = 1.2159e-02, PNorm = 51.3689, GNorm = 3.7319, lr_0 = 4.7715e-04
Loss = 1.1778e-02, PNorm = 51.3971, GNorm = 3.2720, lr_0 = 4.7651e-04
Validation rmse = 2.701409
Validation R2 = -1.085846
Epoch 25
Train function
Loss = 8.6880e-03, PNorm = 51.4229, GNorm = 1.8536, lr_0 = 4.7587e-04
Loss = 1.0746e-02, PNorm = 51.4425, GNorm = 2.4614, lr_0 = 4.7524e-04
Loss = 9.5194e-03, PNorm = 51.4651, GNorm = 2.2453, lr_0 = 4.7460e-04
Loss = 1.1165e-02, PNorm = 51.4943, GNorm = 2.9604, lr_0 = 4.7396e-04
Loss = 9.7881e-03, PNorm = 51.5207, GNorm = 3.7626, lr_0 = 4.7333e-04
Loss = 9.4262e-03, PNorm = 51.5468, GNorm = 4.6952, lr_0 = 4.7269e-04
Loss = 1.0285e-02, PNorm = 51.5687, GNorm = 2.9673, lr_0 = 4.7206e-04
Loss = 1.1073e-02, PNorm = 51.5903, GNorm = 2.1555, lr_0 = 4.7142e-04
Loss = 8.7600e-03, PNorm = 51.6139, GNorm = 2.1785, lr_0 = 4.7079e-04
Loss = 1.0377e-02, PNorm = 51.6307, GNorm = 3.7746, lr_0 = 4.7016e-04
Loss = 1.1275e-02, PNorm = 51.6544, GNorm = 2.6844, lr_0 = 4.6953e-04
Loss = 1.1253e-02, PNorm = 51.6758, GNorm = 2.6334, lr_0 = 4.6890e-04
Loss = 1.0787e-02, PNorm = 51.6966, GNorm = 3.7320, lr_0 = 4.6827e-04
Loss = 9.8806e-03, PNorm = 51.7170, GNorm = 2.2851, lr_0 = 4.6764e-04
Loss = 1.1060e-02, PNorm = 51.7348, GNorm = 2.7871, lr_0 = 4.6701e-04
Loss = 1.1311e-02, PNorm = 51.7550, GNorm = 3.7022, lr_0 = 4.6639e-04
Loss = 8.7879e-03, PNorm = 51.7779, GNorm = 2.5001, lr_0 = 4.6576e-04
Loss = 1.1724e-02, PNorm = 51.7989, GNorm = 3.5450, lr_0 = 4.6514e-04
Loss = 1.2381e-02, PNorm = 51.8215, GNorm = 3.3078, lr_0 = 4.6451e-04
Loss = 1.2916e-02, PNorm = 51.8453, GNorm = 3.5901, lr_0 = 4.6389e-04
Loss = 1.1963e-02, PNorm = 51.8718, GNorm = 2.9467, lr_0 = 4.6327e-04
Loss = 1.0812e-02, PNorm = 51.8959, GNorm = 3.0703, lr_0 = 4.6264e-04
Loss = 1.2758e-02, PNorm = 51.9134, GNorm = 4.1994, lr_0 = 4.6202e-04
Validation rmse = 3.101020
Validation R2 = -1.748593
Epoch 26
Train function
Loss = 1.1759e-02, PNorm = 51.9311, GNorm = 3.2191, lr_0 = 4.6134e-04
Loss = 1.1829e-02, PNorm = 51.9557, GNorm = 4.1501, lr_0 = 4.6072e-04
Loss = 1.1504e-02, PNorm = 51.9857, GNorm = 3.3330, lr_0 = 4.6011e-04
Loss = 1.0097e-02, PNorm = 52.0090, GNorm = 3.6996, lr_0 = 4.5949e-04
Loss = 1.1447e-02, PNorm = 52.0365, GNorm = 3.7949, lr_0 = 4.5887e-04
Loss = 8.9031e-03, PNorm = 52.0592, GNorm = 2.4874, lr_0 = 4.5826e-04
Loss = 9.2189e-03, PNorm = 52.0792, GNorm = 2.8218, lr_0 = 4.5764e-04
Loss = 1.0345e-02, PNorm = 52.1003, GNorm = 3.0053, lr_0 = 4.5703e-04
Loss = 9.3523e-03, PNorm = 52.1192, GNorm = 1.8685, lr_0 = 4.5641e-04
Loss = 1.0848e-02, PNorm = 52.1384, GNorm = 2.3171, lr_0 = 4.5580e-04
Loss = 1.0608e-02, PNorm = 52.1572, GNorm = 2.9422, lr_0 = 4.5519e-04
Loss = 1.0950e-02, PNorm = 52.1740, GNorm = 4.0882, lr_0 = 4.5458e-04
Loss = 9.2698e-03, PNorm = 52.1957, GNorm = 1.4688, lr_0 = 4.5397e-04
Loss = 1.0320e-02, PNorm = 52.2194, GNorm = 3.3195, lr_0 = 4.5336e-04
Loss = 9.3259e-03, PNorm = 52.2402, GNorm = 1.7910, lr_0 = 4.5275e-04
Loss = 1.1251e-02, PNorm = 52.2566, GNorm = 5.1255, lr_0 = 4.5214e-04
Loss = 9.5238e-03, PNorm = 52.2767, GNorm = 4.0102, lr_0 = 4.5154e-04
Loss = 9.4960e-03, PNorm = 52.2979, GNorm = 2.2018, lr_0 = 4.5093e-04
Loss = 1.3487e-02, PNorm = 52.3236, GNorm = 3.5840, lr_0 = 4.5033e-04
Loss = 9.7284e-03, PNorm = 52.3421, GNorm = 2.9471, lr_0 = 4.4972e-04
Loss = 1.0921e-02, PNorm = 52.3590, GNorm = 3.4900, lr_0 = 4.4912e-04
Loss = 9.5241e-03, PNorm = 52.3750, GNorm = 2.6721, lr_0 = 4.4852e-04
Loss = 1.0943e-02, PNorm = 52.3940, GNorm = 6.0017, lr_0 = 4.4791e-04
Loss = 8.7741e-03, PNorm = 52.4146, GNorm = 2.5269, lr_0 = 4.4731e-04
Validation rmse = 2.944441
Validation R2 = -1.478033
Epoch 27
Train function
Loss = 9.1968e-03, PNorm = 52.4316, GNorm = 3.4631, lr_0 = 4.4665e-04
Loss = 8.9483e-03, PNorm = 52.4515, GNorm = 2.3520, lr_0 = 4.4605e-04
Loss = 8.7726e-03, PNorm = 52.4748, GNorm = 2.8915, lr_0 = 4.4546e-04
Loss = 8.8417e-03, PNorm = 52.4986, GNorm = 1.9897, lr_0 = 4.4486e-04
Loss = 9.0485e-03, PNorm = 52.5191, GNorm = 3.5550, lr_0 = 4.4426e-04
Loss = 8.9852e-03, PNorm = 52.5369, GNorm = 2.0815, lr_0 = 4.4367e-04
Loss = 9.6309e-03, PNorm = 52.5610, GNorm = 2.2503, lr_0 = 4.4307e-04
Loss = 1.0671e-02, PNorm = 52.5784, GNorm = 6.0222, lr_0 = 4.4248e-04
Loss = 8.5433e-03, PNorm = 52.6033, GNorm = 2.5701, lr_0 = 4.4188e-04
Loss = 9.6663e-03, PNorm = 52.6306, GNorm = 4.9090, lr_0 = 4.4129e-04
Loss = 8.9386e-03, PNorm = 52.6533, GNorm = 5.7127, lr_0 = 4.4070e-04
Loss = 1.1171e-02, PNorm = 52.6758, GNorm = 3.1966, lr_0 = 4.4011e-04
Loss = 1.3026e-02, PNorm = 52.6973, GNorm = 4.6476, lr_0 = 4.3952e-04
Loss = 1.0262e-02, PNorm = 52.7202, GNorm = 4.8733, lr_0 = 4.3893e-04
Loss = 1.0528e-02, PNorm = 52.7360, GNorm = 4.5752, lr_0 = 4.3834e-04
Loss = 1.0427e-02, PNorm = 52.7536, GNorm = 3.6837, lr_0 = 4.3775e-04
Loss = 1.0513e-02, PNorm = 52.7680, GNorm = 4.2417, lr_0 = 4.3716e-04
Loss = 1.1541e-02, PNorm = 52.7820, GNorm = 2.9846, lr_0 = 4.3657e-04
Loss = 8.7286e-03, PNorm = 52.8029, GNorm = 2.2191, lr_0 = 4.3599e-04
Loss = 8.6858e-03, PNorm = 52.8220, GNorm = 2.5325, lr_0 = 4.3540e-04
Loss = 1.0736e-02, PNorm = 52.8418, GNorm = 2.2522, lr_0 = 4.3482e-04
Loss = 1.0496e-02, PNorm = 52.8600, GNorm = 2.2296, lr_0 = 4.3424e-04
Loss = 9.3132e-03, PNorm = 52.8734, GNorm = 2.9487, lr_0 = 4.3365e-04
Validation rmse = 2.832619
Validation R2 = -1.293389
Epoch 28
Train function
Loss = 7.6945e-03, PNorm = 52.8929, GNorm = 2.2441, lr_0 = 4.3301e-04
Loss = 7.4288e-03, PNorm = 52.9147, GNorm = 2.9980, lr_0 = 4.3243e-04
Loss = 8.9534e-03, PNorm = 52.9368, GNorm = 3.2884, lr_0 = 4.3185e-04
Loss = 9.3009e-03, PNorm = 52.9641, GNorm = 3.4085, lr_0 = 4.3127e-04
Loss = 9.4049e-03, PNorm = 52.9878, GNorm = 2.9812, lr_0 = 4.3069e-04
Loss = 7.7783e-03, PNorm = 53.0051, GNorm = 2.4545, lr_0 = 4.3012e-04
Loss = 7.7340e-03, PNorm = 53.0221, GNorm = 2.9549, lr_0 = 4.2954e-04
Loss = 9.6067e-03, PNorm = 53.0387, GNorm = 2.8785, lr_0 = 4.2896e-04
Loss = 9.6301e-03, PNorm = 53.0600, GNorm = 3.8610, lr_0 = 4.2839e-04
Loss = 9.8026e-03, PNorm = 53.0792, GNorm = 2.3843, lr_0 = 4.2781e-04
Loss = 8.2251e-03, PNorm = 53.1000, GNorm = 2.3027, lr_0 = 4.2724e-04
Loss = 8.4471e-03, PNorm = 53.1185, GNorm = 2.5130, lr_0 = 4.2667e-04
Loss = 9.8655e-03, PNorm = 53.1375, GNorm = 2.8527, lr_0 = 4.2609e-04
Loss = 8.2528e-03, PNorm = 53.1573, GNorm = 2.5067, lr_0 = 4.2552e-04
Loss = 9.9790e-03, PNorm = 53.1723, GNorm = 2.0064, lr_0 = 4.2495e-04
Loss = 1.1472e-02, PNorm = 53.1883, GNorm = 2.5183, lr_0 = 4.2438e-04
Loss = 8.3392e-03, PNorm = 53.2064, GNorm = 3.2299, lr_0 = 4.2381e-04
Loss = 9.6942e-03, PNorm = 53.2209, GNorm = 2.4688, lr_0 = 4.2324e-04
Loss = 1.1032e-02, PNorm = 53.2357, GNorm = 2.6444, lr_0 = 4.2267e-04
Loss = 1.0357e-02, PNorm = 53.2526, GNorm = 2.7566, lr_0 = 4.2211e-04
Loss = 8.9534e-03, PNorm = 53.2691, GNorm = 2.4821, lr_0 = 4.2154e-04
Loss = 8.6398e-03, PNorm = 53.2855, GNorm = 2.8339, lr_0 = 4.2098e-04
Loss = 9.6263e-03, PNorm = 53.3032, GNorm = 3.0121, lr_0 = 4.2041e-04
Loss = 7.9791e-03, PNorm = 53.3175, GNorm = 3.4465, lr_0 = 4.1985e-04
Validation rmse = 2.826295
Validation R2 = -1.283160
Epoch 29
Train function
Loss = 8.1082e-03, PNorm = 53.3352, GNorm = 2.9852, lr_0 = 4.1923e-04
Loss = 8.2626e-03, PNorm = 53.3525, GNorm = 3.4968, lr_0 = 4.1866e-04
Loss = 8.1479e-03, PNorm = 53.3710, GNorm = 2.9106, lr_0 = 4.1810e-04
Loss = 8.3445e-03, PNorm = 53.3890, GNorm = 2.1103, lr_0 = 4.1754e-04
Loss = 7.9283e-03, PNorm = 53.4078, GNorm = 2.9699, lr_0 = 4.1698e-04
Loss = 9.2882e-03, PNorm = 53.4254, GNorm = 2.8613, lr_0 = 4.1642e-04
Loss = 8.8102e-03, PNorm = 53.4413, GNorm = 2.8248, lr_0 = 4.1586e-04
Loss = 8.0686e-03, PNorm = 53.4589, GNorm = 2.4625, lr_0 = 4.1531e-04
Loss = 8.4964e-03, PNorm = 53.4738, GNorm = 3.1319, lr_0 = 4.1475e-04
Loss = 7.9504e-03, PNorm = 53.4914, GNorm = 3.2547, lr_0 = 4.1419e-04
Loss = 9.3676e-03, PNorm = 53.5097, GNorm = 3.4668, lr_0 = 4.1364e-04
Loss = 7.7075e-03, PNorm = 53.5285, GNorm = 4.6531, lr_0 = 4.1308e-04
Loss = 8.7975e-03, PNorm = 53.5487, GNorm = 2.6661, lr_0 = 4.1253e-04
Loss = 9.4347e-03, PNorm = 53.5685, GNorm = 3.3768, lr_0 = 4.1197e-04
Loss = 8.9333e-03, PNorm = 53.5885, GNorm = 2.5328, lr_0 = 4.1142e-04
Loss = 8.6990e-03, PNorm = 53.6024, GNorm = 4.3689, lr_0 = 4.1087e-04
Loss = 9.2454e-03, PNorm = 53.6178, GNorm = 2.5178, lr_0 = 4.1032e-04
Loss = 9.0423e-03, PNorm = 53.6416, GNorm = 5.5110, lr_0 = 4.0977e-04
Loss = 8.7448e-03, PNorm = 53.6611, GNorm = 5.6427, lr_0 = 4.0922e-04
Loss = 7.8766e-03, PNorm = 53.6765, GNorm = 2.4354, lr_0 = 4.0867e-04
Loss = 1.0071e-02, PNorm = 53.6901, GNorm = 2.9056, lr_0 = 4.0812e-04
Loss = 8.8681e-03, PNorm = 53.7078, GNorm = 2.8298, lr_0 = 4.0757e-04
Loss = 9.9269e-03, PNorm = 53.7190, GNorm = 4.2328, lr_0 = 4.0702e-04
Validation rmse = 3.193785
Validation R2 = -1.915498
Epoch 30
Train function
Loss = 7.6163e-03, PNorm = 53.7354, GNorm = 4.0647, lr_0 = 4.0648e-04
Loss = 8.8466e-03, PNorm = 53.7531, GNorm = 3.4484, lr_0 = 4.0593e-04
Loss = 7.7463e-03, PNorm = 53.7751, GNorm = 3.0806, lr_0 = 4.0539e-04
Loss = 7.9438e-03, PNorm = 53.7959, GNorm = 2.4983, lr_0 = 4.0484e-04
Loss = 8.4626e-03, PNorm = 53.8165, GNorm = 4.1216, lr_0 = 4.0430e-04
Loss = 7.4055e-03, PNorm = 53.8373, GNorm = 2.1283, lr_0 = 4.0376e-04
Loss = 8.2146e-03, PNorm = 53.8549, GNorm = 3.2100, lr_0 = 4.0322e-04
Loss = 7.0341e-03, PNorm = 53.8737, GNorm = 3.7843, lr_0 = 4.0268e-04
Loss = 7.5947e-03, PNorm = 53.8908, GNorm = 2.0308, lr_0 = 4.0214e-04
Loss = 7.7051e-03, PNorm = 53.9033, GNorm = 2.7926, lr_0 = 4.0160e-04
Loss = 7.8079e-03, PNorm = 53.9174, GNorm = 2.6575, lr_0 = 4.0106e-04
Loss = 7.9627e-03, PNorm = 53.9314, GNorm = 4.5846, lr_0 = 4.0052e-04
Loss = 8.4246e-03, PNorm = 53.9468, GNorm = 3.6206, lr_0 = 3.9998e-04
Loss = 8.6358e-03, PNorm = 53.9602, GNorm = 2.6936, lr_0 = 3.9945e-04
Loss = 9.3072e-03, PNorm = 53.9759, GNorm = 3.5654, lr_0 = 3.9891e-04
Loss = 8.9456e-03, PNorm = 53.9941, GNorm = 5.5797, lr_0 = 3.9837e-04
Loss = 8.5563e-03, PNorm = 54.0113, GNorm = 2.6065, lr_0 = 3.9784e-04
Loss = 8.2857e-03, PNorm = 54.0251, GNorm = 2.2987, lr_0 = 3.9731e-04
Loss = 1.0002e-02, PNorm = 54.0385, GNorm = 4.4656, lr_0 = 3.9677e-04
Loss = 7.1871e-03, PNorm = 54.0520, GNorm = 2.8423, lr_0 = 3.9624e-04
Loss = 8.2393e-03, PNorm = 54.0679, GNorm = 3.0697, lr_0 = 3.9571e-04
Loss = 7.5486e-03, PNorm = 54.0809, GNorm = 3.7411, lr_0 = 3.9518e-04
Loss = 9.3898e-03, PNorm = 54.0929, GNorm = 2.6542, lr_0 = 3.9465e-04
Loss = 8.1559e-03, PNorm = 54.1080, GNorm = 3.7280, lr_0 = 3.9412e-04
Loss = 2.3554e-02, PNorm = 54.1097, GNorm = 5.2526, lr_0 = 3.9407e-04
Validation rmse = 3.290674
Validation R2 = -2.095074
Epoch 31
Train function
Loss = 7.0669e-03, PNorm = 54.1237, GNorm = 2.6802, lr_0 = 3.9354e-04
Loss = 6.3640e-03, PNorm = 54.1398, GNorm = 3.3743, lr_0 = 3.9301e-04
Loss = 6.6060e-03, PNorm = 54.1577, GNorm = 2.5607, lr_0 = 3.9248e-04
Loss = 7.4318e-03, PNorm = 54.1748, GNorm = 3.1697, lr_0 = 3.9195e-04
Loss = 7.6198e-03, PNorm = 54.1916, GNorm = 1.5958, lr_0 = 3.9143e-04
Loss = 7.1065e-03, PNorm = 54.2086, GNorm = 2.9407, lr_0 = 3.9090e-04
Loss = 6.1122e-03, PNorm = 54.2254, GNorm = 2.2854, lr_0 = 3.9038e-04
Loss = 6.6011e-03, PNorm = 54.2397, GNorm = 2.7619, lr_0 = 3.8986e-04
Loss = 8.2420e-03, PNorm = 54.2543, GNorm = 3.0771, lr_0 = 3.8933e-04
Loss = 9.5329e-03, PNorm = 54.2706, GNorm = 3.0770, lr_0 = 3.8881e-04
Loss = 6.4720e-03, PNorm = 54.2865, GNorm = 3.5528, lr_0 = 3.8829e-04
Loss = 8.3506e-03, PNorm = 54.3021, GNorm = 4.5226, lr_0 = 3.8777e-04
Loss = 8.1135e-03, PNorm = 54.3172, GNorm = 2.7268, lr_0 = 3.8725e-04
Loss = 8.0730e-03, PNorm = 54.3317, GNorm = 3.8113, lr_0 = 3.8673e-04
Loss = 7.5214e-03, PNorm = 54.3458, GNorm = 2.5685, lr_0 = 3.8621e-04
Loss = 7.8599e-03, PNorm = 54.3640, GNorm = 2.8291, lr_0 = 3.8569e-04
Loss = 6.6157e-03, PNorm = 54.3797, GNorm = 2.9002, lr_0 = 3.8517e-04
Loss = 9.2702e-03, PNorm = 54.3972, GNorm = 3.0194, lr_0 = 3.8466e-04
Loss = 8.1184e-03, PNorm = 54.4117, GNorm = 1.7535, lr_0 = 3.8414e-04
Loss = 9.2569e-03, PNorm = 54.4256, GNorm = 3.1357, lr_0 = 3.8362e-04
Loss = 8.1193e-03, PNorm = 54.4423, GNorm = 3.9555, lr_0 = 3.8311e-04
Loss = 7.9607e-03, PNorm = 54.4602, GNorm = 2.6339, lr_0 = 3.8260e-04
Loss = 8.6537e-03, PNorm = 54.4755, GNorm = 4.6111, lr_0 = 3.8208e-04
Validation rmse = 3.213977
Validation R2 = -1.952479
Epoch 32
Train function
Loss = 8.2324e-03, PNorm = 54.4916, GNorm = 2.9171, lr_0 = 3.8152e-04
Loss = 8.3911e-03, PNorm = 54.5113, GNorm = 6.0960, lr_0 = 3.8101e-04
Loss = 8.2318e-03, PNorm = 54.5276, GNorm = 2.5127, lr_0 = 3.8050e-04
Loss = 6.8138e-03, PNorm = 54.5433, GNorm = 3.3008, lr_0 = 3.7999e-04
Loss = 6.2843e-03, PNorm = 54.5571, GNorm = 2.8278, lr_0 = 3.7948e-04
Loss = 7.8989e-03, PNorm = 54.5738, GNorm = 3.7727, lr_0 = 3.7897e-04
Loss = 6.2979e-03, PNorm = 54.5887, GNorm = 2.2761, lr_0 = 3.7846e-04
Loss = 7.4770e-03, PNorm = 54.6044, GNorm = 3.0814, lr_0 = 3.7795e-04
Loss = 6.2364e-03, PNorm = 54.6220, GNorm = 3.4096, lr_0 = 3.7744e-04
Loss = 6.6835e-03, PNorm = 54.6388, GNorm = 2.7649, lr_0 = 3.7694e-04
Loss = 5.9057e-03, PNorm = 54.6545, GNorm = 2.6573, lr_0 = 3.7643e-04
Loss = 6.6306e-03, PNorm = 54.6704, GNorm = 2.9775, lr_0 = 3.7593e-04
Loss = 8.2900e-03, PNorm = 54.6838, GNorm = 3.4300, lr_0 = 3.7542e-04
Loss = 5.9973e-03, PNorm = 54.6982, GNorm = 3.1978, lr_0 = 3.7492e-04
Loss = 5.9653e-03, PNorm = 54.7110, GNorm = 3.1961, lr_0 = 3.7441e-04
Loss = 6.3597e-03, PNorm = 54.7266, GNorm = 2.8370, lr_0 = 3.7391e-04
Loss = 6.8346e-03, PNorm = 54.7408, GNorm = 3.2849, lr_0 = 3.7341e-04
Loss = 7.6075e-03, PNorm = 54.7527, GNorm = 4.9410, lr_0 = 3.7291e-04
Loss = 7.3048e-03, PNorm = 54.7688, GNorm = 3.0199, lr_0 = 3.7241e-04
Loss = 6.5737e-03, PNorm = 54.7807, GNorm = 2.1802, lr_0 = 3.7191e-04
Loss = 7.8464e-03, PNorm = 54.7940, GNorm = 2.7414, lr_0 = 3.7141e-04
Loss = 7.4157e-03, PNorm = 54.8038, GNorm = 3.1533, lr_0 = 3.7091e-04
Loss = 9.4019e-03, PNorm = 54.8179, GNorm = 6.3588, lr_0 = 3.7041e-04
Validation rmse = 3.527090
Validation R2 = -2.555777
Epoch 33
Train function
Loss = 6.5126e-03, PNorm = 54.8335, GNorm = 2.6525, lr_0 = 3.6987e-04
Loss = 7.1565e-03, PNorm = 54.8500, GNorm = 3.2656, lr_0 = 3.6937e-04
Loss = 5.9295e-03, PNorm = 54.8643, GNorm = 3.3947, lr_0 = 3.6888e-04
Loss = 5.6758e-03, PNorm = 54.8793, GNorm = 1.7966, lr_0 = 3.6838e-04
Loss = 7.3261e-03, PNorm = 54.8932, GNorm = 3.0656, lr_0 = 3.6789e-04
Loss = 6.3420e-03, PNorm = 54.9068, GNorm = 4.2774, lr_0 = 3.6739e-04
Loss = 6.9455e-03, PNorm = 54.9200, GNorm = 3.9467, lr_0 = 3.6690e-04
Loss = 6.1585e-03, PNorm = 54.9364, GNorm = 2.2560, lr_0 = 3.6641e-04
Loss = 7.2985e-03, PNorm = 54.9539, GNorm = 4.0315, lr_0 = 3.6592e-04
Loss = 6.6896e-03, PNorm = 54.9691, GNorm = 2.7783, lr_0 = 3.6543e-04
Loss = 6.8642e-03, PNorm = 54.9865, GNorm = 4.6447, lr_0 = 3.6494e-04
Loss = 7.7886e-03, PNorm = 55.0046, GNorm = 3.3426, lr_0 = 3.6445e-04
Loss = 7.3476e-03, PNorm = 55.0182, GNorm = 4.0481, lr_0 = 3.6396e-04
Loss = 8.0019e-03, PNorm = 55.0338, GNorm = 2.6805, lr_0 = 3.6347e-04
Loss = 7.3460e-03, PNorm = 55.0496, GNorm = 3.7832, lr_0 = 3.6298e-04
Loss = 6.2359e-03, PNorm = 55.0638, GNorm = 2.5821, lr_0 = 3.6249e-04
Loss = 6.8699e-03, PNorm = 55.0755, GNorm = 3.4826, lr_0 = 3.6201e-04
Loss = 7.3772e-03, PNorm = 55.0862, GNorm = 2.5745, lr_0 = 3.6152e-04
Loss = 7.1137e-03, PNorm = 55.1013, GNorm = 2.8636, lr_0 = 3.6104e-04
Loss = 8.2980e-03, PNorm = 55.1140, GNorm = 4.4394, lr_0 = 3.6055e-04
Loss = 6.6905e-03, PNorm = 55.1282, GNorm = 2.8125, lr_0 = 3.6007e-04
Loss = 7.2574e-03, PNorm = 55.1442, GNorm = 3.1555, lr_0 = 3.5959e-04
Loss = 7.6215e-03, PNorm = 55.1595, GNorm = 4.4502, lr_0 = 3.5910e-04
Loss = 7.6358e-03, PNorm = 55.1737, GNorm = 2.2241, lr_0 = 3.5862e-04
Validation rmse = 3.044121
Validation R2 = -1.648653
Epoch 34
Train function
Loss = 6.9875e-03, PNorm = 55.1873, GNorm = 2.9245, lr_0 = 3.5809e-04
Loss = 7.7423e-03, PNorm = 55.2020, GNorm = 3.8274, lr_0 = 3.5761e-04
Loss = 6.6442e-03, PNorm = 55.2162, GNorm = 2.6117, lr_0 = 3.5713e-04
Loss = 5.9210e-03, PNorm = 55.2285, GNorm = 2.1374, lr_0 = 3.5665e-04
Loss = 6.7927e-03, PNorm = 55.2428, GNorm = 2.8411, lr_0 = 3.5617e-04
Loss = 6.9835e-03, PNorm = 55.2567, GNorm = 4.1327, lr_0 = 3.5570e-04
Loss = 6.1317e-03, PNorm = 55.2711, GNorm = 2.3544, lr_0 = 3.5522e-04
Loss = 5.3397e-03, PNorm = 55.2822, GNorm = 2.0616, lr_0 = 3.5474e-04
Loss = 6.5394e-03, PNorm = 55.2958, GNorm = 2.9433, lr_0 = 3.5427e-04
Loss = 6.0523e-03, PNorm = 55.3088, GNorm = 2.1013, lr_0 = 3.5379e-04
Loss = 6.5330e-03, PNorm = 55.3231, GNorm = 3.7904, lr_0 = 3.5332e-04
Loss = 5.6346e-03, PNorm = 55.3358, GNorm = 2.0166, lr_0 = 3.5284e-04
Loss = 6.4157e-03, PNorm = 55.3460, GNorm = 4.6004, lr_0 = 3.5237e-04
Loss = 6.8413e-03, PNorm = 55.3575, GNorm = 3.1238, lr_0 = 3.5190e-04
Loss = 6.0404e-03, PNorm = 55.3702, GNorm = 2.9100, lr_0 = 3.5142e-04
Loss = 6.0925e-03, PNorm = 55.3834, GNorm = 3.3204, lr_0 = 3.5095e-04
Loss = 6.1233e-03, PNorm = 55.3953, GNorm = 2.2888, lr_0 = 3.5048e-04
Loss = 6.1791e-03, PNorm = 55.4079, GNorm = 1.9221, lr_0 = 3.5001e-04
Loss = 5.9118e-03, PNorm = 55.4201, GNorm = 2.8388, lr_0 = 3.4954e-04
Loss = 6.8800e-03, PNorm = 55.4307, GNorm = 4.0472, lr_0 = 3.4907e-04
Loss = 7.3018e-03, PNorm = 55.4435, GNorm = 3.4431, lr_0 = 3.4860e-04
Loss = 7.2215e-03, PNorm = 55.4586, GNorm = 4.2570, lr_0 = 3.4814e-04
Loss = 8.4627e-03, PNorm = 55.4732, GNorm = 4.8330, lr_0 = 3.4767e-04
Validation rmse = 3.474760
Validation R2 = -2.451048
Epoch 35
Train function
Loss = 4.7062e-03, PNorm = 55.4867, GNorm = 1.8987, lr_0 = 3.4720e-04
Loss = 5.5379e-03, PNorm = 55.4982, GNorm = 2.3590, lr_0 = 3.4674e-04
Loss = 5.6610e-03, PNorm = 55.5097, GNorm = 2.8388, lr_0 = 3.4627e-04
Loss = 5.1706e-03, PNorm = 55.5208, GNorm = 1.9333, lr_0 = 3.4581e-04
Loss = 6.2694e-03, PNorm = 55.5320, GNorm = 2.8071, lr_0 = 3.4534e-04
Loss = 4.1300e-03, PNorm = 55.5436, GNorm = 2.4936, lr_0 = 3.4488e-04
Loss = 5.5143e-03, PNorm = 55.5569, GNorm = 3.0676, lr_0 = 3.4442e-04
Loss = 6.0607e-03, PNorm = 55.5700, GNorm = 3.3418, lr_0 = 3.4395e-04
Loss = 5.6733e-03, PNorm = 55.5839, GNorm = 1.9059, lr_0 = 3.4349e-04
Loss = 6.8046e-03, PNorm = 55.5943, GNorm = 3.2635, lr_0 = 3.4303e-04
Loss = 5.8857e-03, PNorm = 55.6065, GNorm = 2.3448, lr_0 = 3.4257e-04
Loss = 5.3081e-03, PNorm = 55.6217, GNorm = 2.7851, lr_0 = 3.4211e-04
Loss = 5.1685e-03, PNorm = 55.6361, GNorm = 4.7370, lr_0 = 3.4165e-04
Loss = 4.9862e-03, PNorm = 55.6503, GNorm = 2.2814, lr_0 = 3.4120e-04
Loss = 6.1190e-03, PNorm = 55.6608, GNorm = 4.5382, lr_0 = 3.4074e-04
Loss = 6.9219e-03, PNorm = 55.6713, GNorm = 3.3465, lr_0 = 3.4028e-04
Loss = 6.6426e-03, PNorm = 55.6842, GNorm = 2.4129, lr_0 = 3.3982e-04
Loss = 6.3510e-03, PNorm = 55.6978, GNorm = 2.4688, lr_0 = 3.3937e-04
Loss = 6.7494e-03, PNorm = 55.7136, GNorm = 4.6533, lr_0 = 3.3891e-04
Loss = 6.5731e-03, PNorm = 55.7226, GNorm = 2.2785, lr_0 = 3.3846e-04
Loss = 6.5780e-03, PNorm = 55.7321, GNorm = 2.6693, lr_0 = 3.3800e-04
Loss = 6.8382e-03, PNorm = 55.7448, GNorm = 2.9636, lr_0 = 3.3755e-04
Loss = 6.2517e-03, PNorm = 55.7576, GNorm = 3.6542, lr_0 = 3.3710e-04
Loss = 6.7983e-03, PNorm = 55.7740, GNorm = 3.1446, lr_0 = 3.3664e-04
Validation rmse = 3.645688
Validation R2 = -2.798922
Epoch 36
Train function
Loss = 5.6293e-03, PNorm = 55.7913, GNorm = 2.2490, lr_0 = 3.3615e-04
Loss = 4.7355e-03, PNorm = 55.8033, GNorm = 3.1302, lr_0 = 3.3570e-04
Loss = 4.8378e-03, PNorm = 55.8141, GNorm = 2.5607, lr_0 = 3.3525e-04
Loss = 4.9224e-03, PNorm = 55.8281, GNorm = 3.6319, lr_0 = 3.3480e-04
Loss = 6.8748e-03, PNorm = 55.8420, GNorm = 3.9723, lr_0 = 3.3435e-04
Loss = 5.1296e-03, PNorm = 55.8511, GNorm = 3.1601, lr_0 = 3.3390e-04
Loss = 5.0044e-03, PNorm = 55.8614, GNorm = 2.1988, lr_0 = 3.3345e-04
Loss = 6.2524e-03, PNorm = 55.8712, GNorm = 2.5769, lr_0 = 3.3300e-04
Loss = 5.7228e-03, PNorm = 55.8827, GNorm = 3.2305, lr_0 = 3.3256e-04
Loss = 4.3407e-03, PNorm = 55.8955, GNorm = 1.6362, lr_0 = 3.3211e-04
Loss = 6.5326e-03, PNorm = 55.9088, GNorm = 3.5720, lr_0 = 3.3167e-04
Loss = 5.4944e-03, PNorm = 55.9204, GNorm = 1.9818, lr_0 = 3.3122e-04
Loss = 4.9644e-03, PNorm = 55.9315, GNorm = 2.1621, lr_0 = 3.3078e-04
Loss = 5.9451e-03, PNorm = 55.9441, GNorm = 2.9237, lr_0 = 3.3033e-04
Loss = 6.3855e-03, PNorm = 55.9555, GNorm = 2.7738, lr_0 = 3.2989e-04
Loss = 6.1216e-03, PNorm = 55.9647, GNorm = 2.8120, lr_0 = 3.2945e-04
Loss = 6.8941e-03, PNorm = 55.9761, GNorm = 4.4347, lr_0 = 3.2900e-04
Loss = 5.6135e-03, PNorm = 55.9898, GNorm = 3.3180, lr_0 = 3.2856e-04
Loss = 6.0576e-03, PNorm = 56.0013, GNorm = 1.8662, lr_0 = 3.2812e-04
Loss = 5.0507e-03, PNorm = 56.0110, GNorm = 4.4720, lr_0 = 3.2768e-04
Loss = 5.0820e-03, PNorm = 56.0199, GNorm = 2.3129, lr_0 = 3.2724e-04
Loss = 5.0121e-03, PNorm = 56.0297, GNorm = 2.3945, lr_0 = 3.2680e-04
Loss = 5.6740e-03, PNorm = 56.0381, GNorm = 3.3680, lr_0 = 3.2636e-04
Validation rmse = 3.410207
Validation R2 = -2.324013
Epoch 37
Train function
Loss = 4.2375e-03, PNorm = 56.0484, GNorm = 2.3567, lr_0 = 3.2588e-04
Loss = 4.5176e-03, PNorm = 56.0603, GNorm = 2.2256, lr_0 = 3.2545e-04
Loss = 5.4917e-03, PNorm = 56.0733, GNorm = 1.8664, lr_0 = 3.2501e-04
Loss = 4.5822e-03, PNorm = 56.0837, GNorm = 3.2060, lr_0 = 3.2457e-04
Loss = 4.7044e-03, PNorm = 56.0951, GNorm = 1.8239, lr_0 = 3.2414e-04
Loss = 4.1312e-03, PNorm = 56.1072, GNorm = 2.0475, lr_0 = 3.2370e-04
Loss = 4.8493e-03, PNorm = 56.1154, GNorm = 4.2505, lr_0 = 3.2327e-04
Loss = 5.0929e-03, PNorm = 56.1239, GNorm = 2.4307, lr_0 = 3.2283e-04
Loss = 5.7184e-03, PNorm = 56.1351, GNorm = 2.0015, lr_0 = 3.2240e-04
Loss = 5.0548e-03, PNorm = 56.1458, GNorm = 2.3560, lr_0 = 3.2197e-04
Loss = 5.6184e-03, PNorm = 56.1559, GNorm = 2.5516, lr_0 = 3.2154e-04
Loss = 4.8323e-03, PNorm = 56.1669, GNorm = 1.8637, lr_0 = 3.2111e-04
Loss = 4.9082e-03, PNorm = 56.1801, GNorm = 2.5700, lr_0 = 3.2067e-04
Loss = 6.8579e-03, PNorm = 56.1918, GNorm = 2.7386, lr_0 = 3.2024e-04
Loss = 5.4564e-03, PNorm = 56.2050, GNorm = 2.5527, lr_0 = 3.1981e-04
Loss = 5.7366e-03, PNorm = 56.2173, GNorm = 3.5053, lr_0 = 3.1939e-04
Loss = 4.9313e-03, PNorm = 56.2273, GNorm = 2.2305, lr_0 = 3.1896e-04
Loss = 5.7949e-03, PNorm = 56.2365, GNorm = 3.0871, lr_0 = 3.1853e-04
Loss = 4.9062e-03, PNorm = 56.2471, GNorm = 2.1269, lr_0 = 3.1810e-04
Loss = 5.2122e-03, PNorm = 56.2571, GNorm = 3.3080, lr_0 = 3.1767e-04
Loss = 6.1137e-03, PNorm = 56.2679, GNorm = 4.7593, lr_0 = 3.1725e-04
Loss = 5.1036e-03, PNorm = 56.2818, GNorm = 4.7344, lr_0 = 3.1682e-04
Loss = 6.1099e-03, PNorm = 56.2943, GNorm = 4.4412, lr_0 = 3.1640e-04
Validation rmse = 3.699624
Validation R2 = -2.912159
Epoch 38
Train function
Loss = 2.7013e-03, PNorm = 56.3051, GNorm = 1.7832, lr_0 = 3.1593e-04
Loss = 4.6224e-03, PNorm = 56.3172, GNorm = 1.8492, lr_0 = 3.1551e-04
Loss = 4.3517e-03, PNorm = 56.3299, GNorm = 1.8951, lr_0 = 3.1508e-04
Loss = 4.4146e-03, PNorm = 56.3412, GNorm = 2.4902, lr_0 = 3.1466e-04
Loss = 5.0131e-03, PNorm = 56.3520, GNorm = 2.9574, lr_0 = 3.1424e-04
Loss = 4.6704e-03, PNorm = 56.3621, GNorm = 4.5144, lr_0 = 3.1382e-04
Loss = 3.8786e-03, PNorm = 56.3712, GNorm = 2.3685, lr_0 = 3.1340e-04
Loss = 4.2324e-03, PNorm = 56.3813, GNorm = 3.3644, lr_0 = 3.1298e-04
Loss = 3.9025e-03, PNorm = 56.3933, GNorm = 1.8270, lr_0 = 3.1256e-04
Loss = 3.7962e-03, PNorm = 56.4034, GNorm = 2.6016, lr_0 = 3.1214e-04
Loss = 4.6853e-03, PNorm = 56.4125, GNorm = 2.5775, lr_0 = 3.1172e-04
Loss = 5.2134e-03, PNorm = 56.4211, GNorm = 2.8513, lr_0 = 3.1130e-04
Loss = 4.3768e-03, PNorm = 56.4321, GNorm = 2.0327, lr_0 = 3.1088e-04
Loss = 4.6117e-03, PNorm = 56.4429, GNorm = 2.3301, lr_0 = 3.1046e-04
Loss = 5.3487e-03, PNorm = 56.4524, GNorm = 4.0327, lr_0 = 3.1005e-04
Loss = 4.6817e-03, PNorm = 56.4618, GNorm = 3.6109, lr_0 = 3.0963e-04
Loss = 7.0660e-03, PNorm = 56.4732, GNorm = 5.9111, lr_0 = 3.0922e-04
Loss = 6.1709e-03, PNorm = 56.4855, GNorm = 4.1302, lr_0 = 3.0880e-04
Loss = 6.1222e-03, PNorm = 56.4977, GNorm = 3.5262, lr_0 = 3.0839e-04
Loss = 4.7098e-03, PNorm = 56.5090, GNorm = 1.8046, lr_0 = 3.0797e-04
Loss = 4.5144e-03, PNorm = 56.5210, GNorm = 2.7771, lr_0 = 3.0756e-04
Loss = 6.0076e-03, PNorm = 56.5322, GNorm = 3.0456, lr_0 = 3.0715e-04
Loss = 6.7679e-03, PNorm = 56.5415, GNorm = 3.5442, lr_0 = 3.0674e-04
Loss = 5.3102e-03, PNorm = 56.5518, GNorm = 2.0404, lr_0 = 3.0632e-04
Validation rmse = 3.535503
Validation R2 = -2.572759
Epoch 39
Train function
Loss = 3.9724e-03, PNorm = 56.5658, GNorm = 1.4506, lr_0 = 3.0587e-04
Loss = 4.6644e-03, PNorm = 56.5780, GNorm = 3.5822, lr_0 = 3.0546e-04
Loss = 3.8565e-03, PNorm = 56.5886, GNorm = 2.8882, lr_0 = 3.0505e-04
Loss = 4.7280e-03, PNorm = 56.5995, GNorm = 5.4610, lr_0 = 3.0464e-04
Loss = 4.2835e-03, PNorm = 56.6125, GNorm = 2.1858, lr_0 = 3.0423e-04
Loss = 4.3004e-03, PNorm = 56.6243, GNorm = 2.7786, lr_0 = 3.0383e-04
Loss = 4.3512e-03, PNorm = 56.6342, GNorm = 4.5882, lr_0 = 3.0342e-04
Loss = 4.3378e-03, PNorm = 56.6423, GNorm = 2.2279, lr_0 = 3.0301e-04
Loss = 4.0855e-03, PNorm = 56.6510, GNorm = 1.9576, lr_0 = 3.0260e-04
Loss = 5.4891e-03, PNorm = 56.6594, GNorm = 3.3281, lr_0 = 3.0220e-04
Loss = 4.3250e-03, PNorm = 56.6706, GNorm = 4.3777, lr_0 = 3.0179e-04
Loss = 4.4906e-03, PNorm = 56.6810, GNorm = 4.6425, lr_0 = 3.0139e-04
Loss = 6.2588e-03, PNorm = 56.6903, GNorm = 2.4865, lr_0 = 3.0098e-04
Loss = 4.6627e-03, PNorm = 56.7007, GNorm = 2.8130, lr_0 = 3.0058e-04
Loss = 4.5003e-03, PNorm = 56.7090, GNorm = 2.0089, lr_0 = 3.0018e-04
Loss = 4.1303e-03, PNorm = 56.7179, GNorm = 2.9962, lr_0 = 2.9977e-04
Loss = 4.5605e-03, PNorm = 56.7262, GNorm = 2.0908, lr_0 = 2.9937e-04
Loss = 5.4110e-03, PNorm = 56.7350, GNorm = 3.6989, lr_0 = 2.9897e-04
Loss = 4.5059e-03, PNorm = 56.7431, GNorm = 3.2700, lr_0 = 2.9857e-04
Loss = 5.3442e-03, PNorm = 56.7520, GNorm = 1.8824, lr_0 = 2.9817e-04
Loss = 5.5283e-03, PNorm = 56.7630, GNorm = 2.9666, lr_0 = 2.9777e-04
Loss = 5.2912e-03, PNorm = 56.7736, GNorm = 3.4743, lr_0 = 2.9737e-04
Loss = 5.6488e-03, PNorm = 56.7829, GNorm = 2.5046, lr_0 = 2.9697e-04
Validation rmse = 3.821452
Validation R2 = -3.174056
Epoch 40
Train function
Loss = 3.0671e-03, PNorm = 56.7918, GNorm = 1.8850, lr_0 = 2.9657e-04
Loss = 4.0090e-03, PNorm = 56.8004, GNorm = 2.0672, lr_0 = 2.9617e-04
Loss = 3.8167e-03, PNorm = 56.8099, GNorm = 3.2025, lr_0 = 2.9578e-04
Loss = 4.9909e-03, PNorm = 56.8197, GNorm = 1.9886, lr_0 = 2.9538e-04
Loss = 4.0740e-03, PNorm = 56.8304, GNorm = 3.0662, lr_0 = 2.9498e-04
Loss = 2.9399e-03, PNorm = 56.8398, GNorm = 3.0958, lr_0 = 2.9459e-04
Loss = 4.1088e-03, PNorm = 56.8489, GNorm = 3.5073, lr_0 = 2.9419e-04
Loss = 3.4557e-03, PNorm = 56.8587, GNorm = 2.0907, lr_0 = 2.9380e-04
Loss = 4.7196e-03, PNorm = 56.8685, GNorm = 3.0795, lr_0 = 2.9340e-04
Loss = 4.4620e-03, PNorm = 56.8786, GNorm = 1.7749, lr_0 = 2.9301e-04
Loss = 4.4284e-03, PNorm = 56.8861, GNorm = 2.1304, lr_0 = 2.9262e-04
Loss = 3.7931e-03, PNorm = 56.8918, GNorm = 1.9801, lr_0 = 2.9222e-04
Loss = 5.8013e-03, PNorm = 56.8996, GNorm = 3.7735, lr_0 = 2.9183e-04
Loss = 3.8224e-03, PNorm = 56.9111, GNorm = 4.3375, lr_0 = 2.9144e-04
Loss = 4.6193e-03, PNorm = 56.9186, GNorm = 3.3955, lr_0 = 2.9105e-04
Loss = 4.7543e-03, PNorm = 56.9278, GNorm = 2.2526, lr_0 = 2.9066e-04
Loss = 4.8423e-03, PNorm = 56.9384, GNorm = 1.9829, lr_0 = 2.9027e-04
Loss = 3.7619e-03, PNorm = 56.9499, GNorm = 2.3777, lr_0 = 2.8988e-04
Loss = 4.0014e-03, PNorm = 56.9594, GNorm = 2.3714, lr_0 = 2.8949e-04
Loss = 5.0114e-03, PNorm = 56.9664, GNorm = 3.2808, lr_0 = 2.8910e-04
Loss = 4.4773e-03, PNorm = 56.9749, GNorm = 2.3933, lr_0 = 2.8871e-04
Loss = 5.7359e-03, PNorm = 56.9838, GNorm = 4.1379, lr_0 = 2.8833e-04
Loss = 4.3529e-03, PNorm = 56.9948, GNorm = 1.9520, lr_0 = 2.8794e-04
Loss = 5.4796e-03, PNorm = 57.0073, GNorm = 3.4679, lr_0 = 2.8755e-04
Validation rmse = 4.167574
Validation R2 = -3.964414
Epoch 41
Train function
Loss = 5.3268e-03, PNorm = 57.0197, GNorm = 5.4010, lr_0 = 2.8713e-04
Loss = 4.6940e-03, PNorm = 57.0287, GNorm = 2.7609, lr_0 = 2.8674e-04
Loss = 3.3433e-03, PNorm = 57.0373, GNorm = 2.1434, lr_0 = 2.8636e-04
Loss = 3.3647e-03, PNorm = 57.0472, GNorm = 1.3654, lr_0 = 2.8597e-04
Loss = 3.6885e-03, PNorm = 57.0566, GNorm = 1.4732, lr_0 = 2.8559e-04
Loss = 3.8099e-03, PNorm = 57.0649, GNorm = 3.7987, lr_0 = 2.8521e-04
Loss = 3.8539e-03, PNorm = 57.0725, GNorm = 1.4508, lr_0 = 2.8482e-04
Loss = 3.7521e-03, PNorm = 57.0787, GNorm = 2.3966, lr_0 = 2.8444e-04
Loss = 3.8232e-03, PNorm = 57.0880, GNorm = 1.7699, lr_0 = 2.8406e-04
Loss = 3.8791e-03, PNorm = 57.0970, GNorm = 2.0235, lr_0 = 2.8368e-04
Loss = 3.5203e-03, PNorm = 57.1047, GNorm = 2.4913, lr_0 = 2.8330e-04
Loss = 4.7843e-03, PNorm = 57.1132, GNorm = 2.4803, lr_0 = 2.8292e-04
Loss = 3.8238e-03, PNorm = 57.1237, GNorm = 3.1258, lr_0 = 2.8254e-04
Loss = 4.3165e-03, PNorm = 57.1330, GNorm = 2.1796, lr_0 = 2.8216e-04
Loss = 4.1078e-03, PNorm = 57.1399, GNorm = 3.8620, lr_0 = 2.8178e-04
Loss = 3.6935e-03, PNorm = 57.1446, GNorm = 3.6063, lr_0 = 2.8140e-04
Loss = 5.1986e-03, PNorm = 57.1515, GNorm = 4.3874, lr_0 = 2.8103e-04
Loss = 4.6385e-03, PNorm = 57.1626, GNorm = 2.4218, lr_0 = 2.8065e-04
Loss = 4.6182e-03, PNorm = 57.1742, GNorm = 3.4245, lr_0 = 2.8027e-04
Loss = 3.5225e-03, PNorm = 57.1845, GNorm = 2.9680, lr_0 = 2.7990e-04
Loss = 4.2540e-03, PNorm = 57.1922, GNorm = 2.8581, lr_0 = 2.7952e-04
Loss = 4.1166e-03, PNorm = 57.2013, GNorm = 2.5006, lr_0 = 2.7915e-04
Loss = 4.8772e-03, PNorm = 57.2096, GNorm = 4.3409, lr_0 = 2.7877e-04
Validation rmse = 3.874269
Validation R2 = -3.290234
Epoch 42
Train function
Loss = 4.5266e-03, PNorm = 57.2173, GNorm = 2.7393, lr_0 = 2.7836e-04
Loss = 4.4251e-03, PNorm = 57.2277, GNorm = 3.0250, lr_0 = 2.7799e-04
Loss = 4.4944e-03, PNorm = 57.2386, GNorm = 3.0520, lr_0 = 2.7761e-04
Loss = 2.9890e-03, PNorm = 57.2489, GNorm = 2.4377, lr_0 = 2.7724e-04
Loss = 4.4848e-03, PNorm = 57.2570, GNorm = 4.2540, lr_0 = 2.7687e-04
Loss = 4.0724e-03, PNorm = 57.2656, GNorm = 2.3360, lr_0 = 2.7650e-04
Loss = 3.6518e-03, PNorm = 57.2733, GNorm = 3.3435, lr_0 = 2.7613e-04
Loss = 3.7407e-03, PNorm = 57.2804, GNorm = 3.2055, lr_0 = 2.7576e-04
Loss = 4.0020e-03, PNorm = 57.2876, GNorm = 1.7637, lr_0 = 2.7539e-04
Loss = 4.5660e-03, PNorm = 57.2939, GNorm = 2.1667, lr_0 = 2.7502e-04
Loss = 3.7395e-03, PNorm = 57.3015, GNorm = 2.6688, lr_0 = 2.7465e-04
Loss = 4.9213e-03, PNorm = 57.3101, GNorm = 3.2505, lr_0 = 2.7428e-04
Loss = 4.9874e-03, PNorm = 57.3184, GNorm = 2.0671, lr_0 = 2.7391e-04
Loss = 3.4699e-03, PNorm = 57.3275, GNorm = 2.7424, lr_0 = 2.7354e-04
Loss = 3.6010e-03, PNorm = 57.3366, GNorm = 1.9260, lr_0 = 2.7318e-04
Loss = 3.6983e-03, PNorm = 57.3440, GNorm = 2.9422, lr_0 = 2.7281e-04
Loss = 3.3306e-03, PNorm = 57.3520, GNorm = 3.3924, lr_0 = 2.7244e-04
Loss = 2.9201e-03, PNorm = 57.3601, GNorm = 1.6454, lr_0 = 2.7208e-04
Loss = 4.1097e-03, PNorm = 57.3700, GNorm = 2.8217, lr_0 = 2.7171e-04
Loss = 3.7835e-03, PNorm = 57.3803, GNorm = 5.0624, lr_0 = 2.7135e-04
Loss = 3.4732e-03, PNorm = 57.3895, GNorm = 2.6114, lr_0 = 2.7098e-04
Loss = 3.7413e-03, PNorm = 57.3981, GNorm = 3.0214, lr_0 = 2.7062e-04
Loss = 4.3535e-03, PNorm = 57.4046, GNorm = 1.9842, lr_0 = 2.7026e-04
Loss = 3.7296e-03, PNorm = 57.4110, GNorm = 1.9991, lr_0 = 2.6990e-04
Loss = 5.5974e-02, PNorm = 57.4113, GNorm = 9.7533, lr_0 = 2.6986e-04
Validation rmse = 3.930240
Validation R2 = -3.415089
Epoch 43
Train function
Loss = 3.9777e-03, PNorm = 57.4207, GNorm = 3.7989, lr_0 = 2.6950e-04
Loss = 3.4277e-03, PNorm = 57.4289, GNorm = 2.4614, lr_0 = 2.6914e-04
Loss = 3.0297e-03, PNorm = 57.4369, GNorm = 4.1573, lr_0 = 2.6877e-04
Loss = 4.1124e-03, PNorm = 57.4450, GNorm = 2.7663, lr_0 = 2.6841e-04
Loss = 3.4749e-03, PNorm = 57.4522, GNorm = 2.7883, lr_0 = 2.6805e-04
Loss = 3.2725e-03, PNorm = 57.4602, GNorm = 3.0126, lr_0 = 2.6769e-04
Loss = 3.3845e-03, PNorm = 57.4686, GNorm = 2.2336, lr_0 = 2.6733e-04
Loss = 3.7592e-03, PNorm = 57.4765, GNorm = 2.3563, lr_0 = 2.6698e-04
Loss = 4.1071e-03, PNorm = 57.4855, GNorm = 1.7405, lr_0 = 2.6662e-04
Loss = 2.8977e-03, PNorm = 57.4944, GNorm = 2.4936, lr_0 = 2.6626e-04
Loss = 4.7540e-03, PNorm = 57.5018, GNorm = 1.9941, lr_0 = 2.6590e-04
Loss = 3.1657e-03, PNorm = 57.5079, GNorm = 1.3965, lr_0 = 2.6555e-04
Loss = 3.4988e-03, PNorm = 57.5148, GNorm = 2.6711, lr_0 = 2.6519e-04
Loss = 3.6634e-03, PNorm = 57.5219, GNorm = 1.9759, lr_0 = 2.6483e-04
Loss = 2.7446e-03, PNorm = 57.5278, GNorm = 2.8572, lr_0 = 2.6448e-04
Loss = 2.7132e-03, PNorm = 57.5351, GNorm = 2.1828, lr_0 = 2.6412e-04
Loss = 3.2243e-03, PNorm = 57.5437, GNorm = 2.9246, lr_0 = 2.6377e-04
Loss = 4.1201e-03, PNorm = 57.5512, GNorm = 5.6544, lr_0 = 2.6342e-04
Loss = 4.3790e-03, PNorm = 57.5587, GNorm = 4.3713, lr_0 = 2.6306e-04
Loss = 3.7934e-03, PNorm = 57.5669, GNorm = 2.1101, lr_0 = 2.6271e-04
Loss = 3.6748e-03, PNorm = 57.5735, GNorm = 1.7138, lr_0 = 2.6236e-04
Loss = 5.0413e-03, PNorm = 57.5804, GNorm = 4.2544, lr_0 = 2.6200e-04
Loss = 3.8394e-03, PNorm = 57.5867, GNorm = 2.4195, lr_0 = 2.6165e-04
Validation rmse = 4.019496
Validation R2 = -3.617901
Epoch 44
Train function
Loss = 3.5359e-03, PNorm = 57.5957, GNorm = 2.0918, lr_0 = 2.6127e-04
Loss = 3.2977e-03, PNorm = 57.6063, GNorm = 2.8379, lr_0 = 2.6092e-04
Loss = 2.7640e-03, PNorm = 57.6155, GNorm = 1.6009, lr_0 = 2.6057e-04
Loss = 4.0893e-03, PNorm = 57.6229, GNorm = 5.3178, lr_0 = 2.6022e-04
Loss = 3.6546e-03, PNorm = 57.6294, GNorm = 3.4559, lr_0 = 2.5987e-04
Loss = 3.5849e-03, PNorm = 57.6371, GNorm = 3.5043, lr_0 = 2.5952e-04
Loss = 4.0313e-03, PNorm = 57.6443, GNorm = 2.0957, lr_0 = 2.5917e-04
Loss = 3.0748e-03, PNorm = 57.6518, GNorm = 3.8833, lr_0 = 2.5882e-04
Loss = 2.7836e-03, PNorm = 57.6588, GNorm = 2.1636, lr_0 = 2.5848e-04
Loss = 3.5376e-03, PNorm = 57.6658, GNorm = 3.5831, lr_0 = 2.5813e-04
Loss = 3.4898e-03, PNorm = 57.6731, GNorm = 2.8069, lr_0 = 2.5778e-04
Loss = 3.4025e-03, PNorm = 57.6809, GNorm = 1.8583, lr_0 = 2.5744e-04
Loss = 3.0416e-03, PNorm = 57.6890, GNorm = 1.8155, lr_0 = 2.5709e-04
Loss = 2.6623e-03, PNorm = 57.6947, GNorm = 1.8506, lr_0 = 2.5675e-04
Loss = 2.9312e-03, PNorm = 57.7005, GNorm = 1.7085, lr_0 = 2.5640e-04
Loss = 3.0939e-03, PNorm = 57.7083, GNorm = 1.9321, lr_0 = 2.5606e-04
Loss = 2.9564e-03, PNorm = 57.7159, GNorm = 1.8496, lr_0 = 2.5571e-04
Loss = 2.9552e-03, PNorm = 57.7241, GNorm = 1.7467, lr_0 = 2.5537e-04
Loss = 3.9894e-03, PNorm = 57.7289, GNorm = 4.3371, lr_0 = 2.5503e-04
Loss = 4.0613e-03, PNorm = 57.7363, GNorm = 2.5209, lr_0 = 2.5469e-04
Loss = 3.9884e-03, PNorm = 57.7425, GNorm = 2.8367, lr_0 = 2.5434e-04
Loss = 3.7882e-03, PNorm = 57.7487, GNorm = 4.0998, lr_0 = 2.5400e-04
Loss = 3.4706e-03, PNorm = 57.7550, GNorm = 1.8477, lr_0 = 2.5366e-04
Validation rmse = 3.945932
Validation R2 = -3.450416
Epoch 45
Train function
Loss = 2.8024e-03, PNorm = 57.7644, GNorm = 2.2584, lr_0 = 2.5332e-04
Loss = 3.8286e-03, PNorm = 57.7748, GNorm = 1.6695, lr_0 = 2.5298e-04
Loss = 3.0113e-03, PNorm = 57.7834, GNorm = 2.2680, lr_0 = 2.5264e-04
Loss = 3.0420e-03, PNorm = 57.7926, GNorm = 2.5862, lr_0 = 2.5230e-04
Loss = 4.0941e-03, PNorm = 57.7998, GNorm = 4.0037, lr_0 = 2.5197e-04
Loss = 2.7389e-03, PNorm = 57.8063, GNorm = 2.1269, lr_0 = 2.5163e-04
Loss = 2.1905e-03, PNorm = 57.8128, GNorm = 2.0681, lr_0 = 2.5129e-04
Loss = 2.9275e-03, PNorm = 57.8204, GNorm = 2.3681, lr_0 = 2.5095e-04
Loss = 2.7174e-03, PNorm = 57.8272, GNorm = 1.9439, lr_0 = 2.5062e-04
Loss = 2.6377e-03, PNorm = 57.8315, GNorm = 2.2419, lr_0 = 2.5028e-04
Loss = 2.5293e-03, PNorm = 57.8382, GNorm = 2.3416, lr_0 = 2.4994e-04
Loss = 2.6631e-03, PNorm = 57.8462, GNorm = 2.1108, lr_0 = 2.4961e-04
Loss = 2.5695e-03, PNorm = 57.8526, GNorm = 2.3847, lr_0 = 2.4927e-04
Loss = 3.4165e-03, PNorm = 57.8589, GNorm = 2.8940, lr_0 = 2.4894e-04
Loss = 4.6730e-03, PNorm = 57.8664, GNorm = 2.9710, lr_0 = 2.4861e-04
Loss = 2.7825e-03, PNorm = 57.8734, GNorm = 3.1204, lr_0 = 2.4827e-04
Loss = 2.8711e-03, PNorm = 57.8779, GNorm = 1.9021, lr_0 = 2.4794e-04
Loss = 3.1282e-03, PNorm = 57.8825, GNorm = 4.4240, lr_0 = 2.4761e-04
Loss = 3.5345e-03, PNorm = 57.8868, GNorm = 2.7846, lr_0 = 2.4727e-04
Loss = 3.8774e-03, PNorm = 57.8951, GNorm = 2.2032, lr_0 = 2.4694e-04
Loss = 3.9619e-03, PNorm = 57.9037, GNorm = 2.2156, lr_0 = 2.4661e-04
Loss = 3.2951e-03, PNorm = 57.9118, GNorm = 3.0595, lr_0 = 2.4628e-04
Loss = 3.3910e-03, PNorm = 57.9197, GNorm = 2.6781, lr_0 = 2.4595e-04
Loss = 4.1653e-03, PNorm = 57.9258, GNorm = 2.9458, lr_0 = 2.4562e-04
Validation rmse = 4.006309
Validation R2 = -3.587650
Epoch 46
Train function
Loss = 2.6154e-03, PNorm = 57.9333, GNorm = 1.8340, lr_0 = 2.4526e-04
Loss = 3.0995e-03, PNorm = 57.9405, GNorm = 1.4162, lr_0 = 2.4493e-04
Loss = 2.2832e-03, PNorm = 57.9454, GNorm = 2.0235, lr_0 = 2.4460e-04
Loss = 2.9442e-03, PNorm = 57.9511, GNorm = 2.4131, lr_0 = 2.4427e-04
Loss = 3.3013e-03, PNorm = 57.9585, GNorm = 3.1417, lr_0 = 2.4394e-04
Loss = 2.7289e-03, PNorm = 57.9662, GNorm = 1.7312, lr_0 = 2.4362e-04
Loss = 3.0770e-03, PNorm = 57.9730, GNorm = 2.1478, lr_0 = 2.4329e-04
Loss = 2.9699e-03, PNorm = 57.9794, GNorm = 1.7744, lr_0 = 2.4296e-04
Loss = 3.0591e-03, PNorm = 57.9861, GNorm = 2.8219, lr_0 = 2.4264e-04
Loss = 2.7987e-03, PNorm = 57.9920, GNorm = 1.6915, lr_0 = 2.4231e-04
Loss = 2.8001e-03, PNorm = 57.9961, GNorm = 2.3201, lr_0 = 2.4199e-04
Loss = 3.7528e-03, PNorm = 58.0038, GNorm = 3.1361, lr_0 = 2.4166e-04
Loss = 3.9502e-03, PNorm = 58.0124, GNorm = 3.9235, lr_0 = 2.4134e-04
Loss = 2.3357e-03, PNorm = 58.0204, GNorm = 2.2483, lr_0 = 2.4101e-04
Loss = 3.4389e-03, PNorm = 58.0268, GNorm = 2.0061, lr_0 = 2.4069e-04
Loss = 2.8185e-03, PNorm = 58.0326, GNorm = 1.9127, lr_0 = 2.4037e-04
Loss = 2.4936e-03, PNorm = 58.0377, GNorm = 1.5084, lr_0 = 2.4004e-04
Loss = 2.3990e-03, PNorm = 58.0431, GNorm = 2.1453, lr_0 = 2.3972e-04
Loss = 3.1719e-03, PNorm = 58.0475, GNorm = 1.9026, lr_0 = 2.3940e-04
Loss = 3.1567e-03, PNorm = 58.0528, GNorm = 2.5510, lr_0 = 2.3908e-04
Loss = 4.2637e-03, PNorm = 58.0596, GNorm = 2.0285, lr_0 = 2.3876e-04
Loss = 3.6485e-03, PNorm = 58.0662, GNorm = 2.1533, lr_0 = 2.3844e-04
Loss = 3.4432e-03, PNorm = 58.0726, GNorm = 2.2714, lr_0 = 2.3812e-04
Validation rmse = 3.936746
Validation R2 = -3.429719
Epoch 47
Train function
Loss = 3.4768e-03, PNorm = 58.0814, GNorm = 2.1851, lr_0 = 2.3777e-04
Loss = 2.5616e-03, PNorm = 58.0893, GNorm = 3.0687, lr_0 = 2.3745e-04
Loss = 2.5328e-03, PNorm = 58.0973, GNorm = 2.1646, lr_0 = 2.3713e-04
Loss = 3.4887e-03, PNorm = 58.1049, GNorm = 2.1720, lr_0 = 2.3681e-04
Loss = 2.8742e-03, PNorm = 58.1125, GNorm = 1.7482, lr_0 = 2.3649e-04
Loss = 2.7657e-03, PNorm = 58.1198, GNorm = 1.7187, lr_0 = 2.3618e-04
Loss = 2.3925e-03, PNorm = 58.1266, GNorm = 1.9640, lr_0 = 2.3586e-04
Loss = 2.7201e-03, PNorm = 58.1320, GNorm = 1.9001, lr_0 = 2.3554e-04
Loss = 2.9915e-03, PNorm = 58.1389, GNorm = 2.5518, lr_0 = 2.3523e-04
Loss = 2.4335e-03, PNorm = 58.1461, GNorm = 3.0855, lr_0 = 2.3491e-04
Loss = 2.7949e-03, PNorm = 58.1519, GNorm = 1.7994, lr_0 = 2.3460e-04
Loss = 3.1219e-03, PNorm = 58.1590, GNorm = 2.8671, lr_0 = 2.3428e-04
Loss = 2.1232e-03, PNorm = 58.1634, GNorm = 2.0685, lr_0 = 2.3397e-04
Loss = 3.5441e-03, PNorm = 58.1679, GNorm = 2.9131, lr_0 = 2.3365e-04
Loss = 2.5134e-03, PNorm = 58.1729, GNorm = 2.0802, lr_0 = 2.3334e-04
Loss = 3.3161e-03, PNorm = 58.1777, GNorm = 3.0529, lr_0 = 2.3303e-04
Loss = 2.2993e-03, PNorm = 58.1836, GNorm = 3.3697, lr_0 = 2.3271e-04
Loss = 2.8042e-03, PNorm = 58.1899, GNorm = 3.8300, lr_0 = 2.3240e-04
Loss = 2.7395e-03, PNorm = 58.1956, GNorm = 1.9923, lr_0 = 2.3209e-04
Loss = 3.0502e-03, PNorm = 58.2034, GNorm = 3.0477, lr_0 = 2.3178e-04
Loss = 3.0983e-03, PNorm = 58.2101, GNorm = 2.3785, lr_0 = 2.3147e-04
Loss = 3.3715e-03, PNorm = 58.2163, GNorm = 2.8557, lr_0 = 2.3116e-04
Loss = 3.3146e-03, PNorm = 58.2245, GNorm = 1.1904, lr_0 = 2.3085e-04
Loss = 3.3732e-03, PNorm = 58.2322, GNorm = 3.1661, lr_0 = 2.3054e-04
Validation rmse = 3.784523
Validation R2 = -3.093773
Epoch 48
Train function
Loss = 2.1652e-03, PNorm = 58.2378, GNorm = 1.3521, lr_0 = 2.3020e-04
Loss = 2.5420e-03, PNorm = 58.2440, GNorm = 2.4422, lr_0 = 2.2989e-04
Loss = 2.4224e-03, PNorm = 58.2514, GNorm = 2.9017, lr_0 = 2.2958e-04
Loss = 2.3711e-03, PNorm = 58.2566, GNorm = 4.2364, lr_0 = 2.2927e-04
Loss = 2.3104e-03, PNorm = 58.2623, GNorm = 1.9400, lr_0 = 2.2896e-04
Loss = 2.0305e-03, PNorm = 58.2681, GNorm = 1.3353, lr_0 = 2.2866e-04
Loss = 2.4944e-03, PNorm = 58.2735, GNorm = 2.4213, lr_0 = 2.2835e-04
Loss = 2.5104e-03, PNorm = 58.2781, GNorm = 2.2161, lr_0 = 2.2804e-04
Loss = 2.5559e-03, PNorm = 58.2835, GNorm = 1.9988, lr_0 = 2.2774e-04
Loss = 3.2710e-03, PNorm = 58.2887, GNorm = 3.2467, lr_0 = 2.2743e-04
Loss = 2.6758e-03, PNorm = 58.2942, GNorm = 2.9403, lr_0 = 2.2713e-04
Loss = 2.9936e-03, PNorm = 58.2971, GNorm = 3.5534, lr_0 = 2.2682e-04
Loss = 3.1252e-03, PNorm = 58.3018, GNorm = 1.8293, lr_0 = 2.2652e-04
Loss = 2.5696e-03, PNorm = 58.3073, GNorm = 2.2703, lr_0 = 2.2621e-04
Loss = 2.3272e-03, PNorm = 58.3117, GNorm = 1.7790, lr_0 = 2.2591e-04
Loss = 2.6149e-03, PNorm = 58.3154, GNorm = 2.0506, lr_0 = 2.2561e-04
Loss = 2.4595e-03, PNorm = 58.3194, GNorm = 1.9686, lr_0 = 2.2530e-04
Loss = 3.5871e-03, PNorm = 58.3264, GNorm = 3.3295, lr_0 = 2.2500e-04
Loss = 3.0398e-03, PNorm = 58.3339, GNorm = 4.8666, lr_0 = 2.2470e-04
Loss = 3.6507e-03, PNorm = 58.3407, GNorm = 2.1145, lr_0 = 2.2440e-04
Loss = 2.4209e-03, PNorm = 58.3464, GNorm = 2.8715, lr_0 = 2.2410e-04
Loss = 3.4677e-03, PNorm = 58.3530, GNorm = 4.1080, lr_0 = 2.2380e-04
Loss = 2.9125e-03, PNorm = 58.3602, GNorm = 2.6652, lr_0 = 2.2350e-04
Validation rmse = 4.100492
Validation R2 = -3.805884
Epoch 49
Train function
Loss = 1.6655e-03, PNorm = 58.3669, GNorm = 1.5361, lr_0 = 2.2317e-04
Loss = 2.1579e-03, PNorm = 58.3726, GNorm = 1.6453, lr_0 = 2.2287e-04
Loss = 2.7188e-03, PNorm = 58.3775, GNorm = 2.3267, lr_0 = 2.2257e-04
Loss = 2.8687e-03, PNorm = 58.3840, GNorm = 3.6354, lr_0 = 2.2227e-04
Loss = 2.0574e-03, PNorm = 58.3889, GNorm = 3.0984, lr_0 = 2.2197e-04
Loss = 2.2437e-03, PNorm = 58.3948, GNorm = 1.2610, lr_0 = 2.2167e-04
Loss = 2.5371e-03, PNorm = 58.4004, GNorm = 3.7709, lr_0 = 2.2138e-04
Loss = 2.2005e-03, PNorm = 58.4068, GNorm = 2.5859, lr_0 = 2.2108e-04
Loss = 2.7628e-03, PNorm = 58.4132, GNorm = 1.4860, lr_0 = 2.2078e-04
Loss = 2.1006e-03, PNorm = 58.4183, GNorm = 2.4682, lr_0 = 2.2049e-04
Loss = 2.6583e-03, PNorm = 58.4236, GNorm = 1.9921, lr_0 = 2.2019e-04
Loss = 2.6127e-03, PNorm = 58.4291, GNorm = 2.0179, lr_0 = 2.1990e-04
Loss = 3.7606e-03, PNorm = 58.4354, GNorm = 3.5507, lr_0 = 2.1960e-04
Loss = 2.8591e-03, PNorm = 58.4425, GNorm = 2.7964, lr_0 = 2.1931e-04
Loss = 2.9611e-03, PNorm = 58.4498, GNorm = 2.5431, lr_0 = 2.1901e-04
Loss = 2.4274e-03, PNorm = 58.4555, GNorm = 1.9616, lr_0 = 2.1872e-04
Loss = 2.4319e-03, PNorm = 58.4620, GNorm = 2.8491, lr_0 = 2.1842e-04
Loss = 2.3849e-03, PNorm = 58.4687, GNorm = 2.7743, lr_0 = 2.1813e-04
Loss = 2.2682e-03, PNorm = 58.4757, GNorm = 2.0304, lr_0 = 2.1784e-04
Loss = 3.7623e-03, PNorm = 58.4837, GNorm = 2.0170, lr_0 = 2.1755e-04
Loss = 2.7859e-03, PNorm = 58.4894, GNorm = 3.2884, lr_0 = 2.1725e-04
Loss = 3.1548e-03, PNorm = 58.4950, GNorm = 3.1644, lr_0 = 2.1696e-04
Loss = 3.0305e-03, PNorm = 58.5023, GNorm = 3.2624, lr_0 = 2.1667e-04
Loss = 2.9721e-03, PNorm = 58.5077, GNorm = 4.1560, lr_0 = 2.1638e-04
Validation rmse = 4.002814
Validation R2 = -3.579649
Epoch 50
Train function
Loss = 2.2554e-03, PNorm = 58.5111, GNorm = 2.0451, lr_0 = 2.1609e-04
Loss = 2.2185e-03, PNorm = 58.5160, GNorm = 1.5996, lr_0 = 2.1580e-04
Loss = 2.3580e-03, PNorm = 58.5210, GNorm = 2.2348, lr_0 = 2.1551e-04
Loss = 1.9905e-03, PNorm = 58.5263, GNorm = 2.5087, lr_0 = 2.1522e-04
Loss = 2.3437e-03, PNorm = 58.5322, GNorm = 1.8221, lr_0 = 2.1493e-04
Loss = 2.4869e-03, PNorm = 58.5389, GNorm = 2.0907, lr_0 = 2.1464e-04
Loss = 1.8354e-03, PNorm = 58.5450, GNorm = 3.1715, lr_0 = 2.1436e-04
Loss = 2.5919e-03, PNorm = 58.5491, GNorm = 1.8938, lr_0 = 2.1407e-04
Loss = 1.9959e-03, PNorm = 58.5535, GNorm = 3.0749, lr_0 = 2.1378e-04
Loss = 1.9855e-03, PNorm = 58.5581, GNorm = 1.3635, lr_0 = 2.1350e-04
Loss = 3.5139e-03, PNorm = 58.5611, GNorm = 2.8579, lr_0 = 2.1321e-04
Loss = 3.3856e-03, PNorm = 58.5663, GNorm = 3.5790, lr_0 = 2.1292e-04
Loss = 2.8584e-03, PNorm = 58.5725, GNorm = 2.7831, lr_0 = 2.1264e-04
Loss = 2.2384e-03, PNorm = 58.5786, GNorm = 2.4730, lr_0 = 2.1235e-04
Loss = 2.0472e-03, PNorm = 58.5827, GNorm = 1.2922, lr_0 = 2.1207e-04
Loss = 1.8744e-03, PNorm = 58.5867, GNorm = 1.5276, lr_0 = 2.1178e-04
Loss = 2.1386e-03, PNorm = 58.5911, GNorm = 3.3098, lr_0 = 2.1150e-04
Loss = 2.4413e-03, PNorm = 58.5961, GNorm = 1.5818, lr_0 = 2.1121e-04
Loss = 2.2231e-03, PNorm = 58.6003, GNorm = 1.9382, lr_0 = 2.1093e-04
Loss = 2.5129e-03, PNorm = 58.6060, GNorm = 1.8563, lr_0 = 2.1065e-04
Loss = 2.0447e-03, PNorm = 58.6104, GNorm = 2.0523, lr_0 = 2.1037e-04
Loss = 2.9716e-03, PNorm = 58.6154, GNorm = 4.7385, lr_0 = 2.1008e-04
Loss = 2.3785e-03, PNorm = 58.6218, GNorm = 2.0395, lr_0 = 2.0980e-04
Validation rmse = 4.120508
Validation R2 = -3.852916
Epoch 51
Train function
Loss = 1.7814e-03, PNorm = 58.6290, GNorm = 1.2523, lr_0 = 2.0949e-04
Loss = 1.8830e-03, PNorm = 58.6339, GNorm = 2.9832, lr_0 = 2.0921e-04
Loss = 1.6472e-03, PNorm = 58.6376, GNorm = 1.8433, lr_0 = 2.0893e-04
Loss = 1.5444e-03, PNorm = 58.6406, GNorm = 1.8856, lr_0 = 2.0865e-04
Loss = 2.2886e-03, PNorm = 58.6446, GNorm = 2.3199, lr_0 = 2.0837e-04
Loss = 2.0000e-03, PNorm = 58.6487, GNorm = 1.6954, lr_0 = 2.0809e-04
Loss = 2.3456e-03, PNorm = 58.6537, GNorm = 1.8240, lr_0 = 2.0781e-04
Loss = 3.3311e-03, PNorm = 58.6579, GNorm = 2.4564, lr_0 = 2.0753e-04
Loss = 1.8360e-03, PNorm = 58.6619, GNorm = 2.2425, lr_0 = 2.0725e-04
Loss = 2.0183e-03, PNorm = 58.6669, GNorm = 2.6183, lr_0 = 2.0698e-04
Loss = 2.1191e-03, PNorm = 58.6708, GNorm = 1.6597, lr_0 = 2.0670e-04
Loss = 2.2369e-03, PNorm = 58.6739, GNorm = 2.0240, lr_0 = 2.0642e-04
Loss = 2.2847e-03, PNorm = 58.6802, GNorm = 1.8241, lr_0 = 2.0614e-04
Loss = 1.9596e-03, PNorm = 58.6856, GNorm = 2.2475, lr_0 = 2.0587e-04
Loss = 2.7504e-03, PNorm = 58.6907, GNorm = 1.3076, lr_0 = 2.0559e-04
Loss = 2.5934e-03, PNorm = 58.6961, GNorm = 2.3683, lr_0 = 2.0531e-04
Loss = 2.2166e-03, PNorm = 58.7006, GNorm = 1.9969, lr_0 = 2.0504e-04
Loss = 2.4843e-03, PNorm = 58.7066, GNorm = 3.8757, lr_0 = 2.0476e-04
Loss = 2.6283e-03, PNorm = 58.7142, GNorm = 1.7747, lr_0 = 2.0449e-04
Loss = 2.1642e-03, PNorm = 58.7201, GNorm = 1.4406, lr_0 = 2.0421e-04
Loss = 2.8337e-03, PNorm = 58.7265, GNorm = 3.4811, lr_0 = 2.0394e-04
Loss = 2.4370e-03, PNorm = 58.7337, GNorm = 1.6378, lr_0 = 2.0367e-04
Loss = 2.6065e-03, PNorm = 58.7397, GNorm = 1.6366, lr_0 = 2.0339e-04
Validation rmse = 4.027001
Validation R2 = -3.635161
Epoch 52
Train function
Loss = 1.4598e-03, PNorm = 58.7443, GNorm = 1.3345, lr_0 = 2.0309e-04
Loss = 1.6570e-03, PNorm = 58.7482, GNorm = 2.3293, lr_0 = 2.0282e-04
Loss = 2.1773e-03, PNorm = 58.7536, GNorm = 2.6516, lr_0 = 2.0255e-04
Loss = 1.5865e-03, PNorm = 58.7568, GNorm = 1.7130, lr_0 = 2.0228e-04
Loss = 1.8993e-03, PNorm = 58.7602, GNorm = 1.4916, lr_0 = 2.0201e-04
Loss = 2.1458e-03, PNorm = 58.7640, GNorm = 2.7693, lr_0 = 2.0174e-04
Loss = 2.6962e-03, PNorm = 58.7688, GNorm = 1.5299, lr_0 = 2.0146e-04
Loss = 1.6767e-03, PNorm = 58.7736, GNorm = 1.4566, lr_0 = 2.0119e-04
Loss = 2.3750e-03, PNorm = 58.7787, GNorm = 1.8689, lr_0 = 2.0092e-04
Loss = 2.4991e-03, PNorm = 58.7837, GNorm = 1.4332, lr_0 = 2.0065e-04
Loss = 2.1200e-03, PNorm = 58.7885, GNorm = 3.9721, lr_0 = 2.0039e-04
Loss = 2.6307e-03, PNorm = 58.7939, GNorm = 2.5945, lr_0 = 2.0012e-04
Loss = 2.3324e-03, PNorm = 58.7994, GNorm = 1.6276, lr_0 = 1.9985e-04
Loss = 2.0898e-03, PNorm = 58.8044, GNorm = 1.8746, lr_0 = 1.9958e-04
Loss = 2.2192e-03, PNorm = 58.8101, GNorm = 1.7969, lr_0 = 1.9931e-04
Loss = 2.4090e-03, PNorm = 58.8143, GNorm = 4.0843, lr_0 = 1.9904e-04
Loss = 1.9313e-03, PNorm = 58.8182, GNorm = 1.4104, lr_0 = 1.9878e-04
Loss = 3.4845e-03, PNorm = 58.8241, GNorm = 6.3997, lr_0 = 1.9851e-04
Loss = 1.9631e-03, PNorm = 58.8309, GNorm = 1.8163, lr_0 = 1.9824e-04
Loss = 2.0051e-03, PNorm = 58.8359, GNorm = 2.6396, lr_0 = 1.9798e-04
Loss = 2.7651e-03, PNorm = 58.8408, GNorm = 1.4983, lr_0 = 1.9771e-04
Loss = 2.6153e-03, PNorm = 58.8456, GNorm = 1.9761, lr_0 = 1.9745e-04
Loss = 2.3185e-03, PNorm = 58.8512, GNorm = 2.6263, lr_0 = 1.9718e-04
Loss = 2.0929e-03, PNorm = 58.8571, GNorm = 1.4928, lr_0 = 1.9692e-04
Validation rmse = 4.101823
Validation R2 = -3.809004
Epoch 53
Train function
Loss = 1.7379e-03, PNorm = 58.8640, GNorm = 2.2643, lr_0 = 1.9663e-04
Loss = 1.8781e-03, PNorm = 58.8700, GNorm = 1.4657, lr_0 = 1.9636e-04
Loss = 1.6371e-03, PNorm = 58.8727, GNorm = 1.6111, lr_0 = 1.9610e-04
Loss = 2.6140e-03, PNorm = 58.8748, GNorm = 2.0456, lr_0 = 1.9584e-04
Loss = 1.7681e-03, PNorm = 58.8776, GNorm = 2.1911, lr_0 = 1.9557e-04
Loss = 1.7809e-03, PNorm = 58.8818, GNorm = 3.4720, lr_0 = 1.9531e-04
Loss = 1.6670e-03, PNorm = 58.8862, GNorm = 1.3959, lr_0 = 1.9505e-04
Loss = 1.5904e-03, PNorm = 58.8900, GNorm = 1.2333, lr_0 = 1.9479e-04
Loss = 1.9822e-03, PNorm = 58.8936, GNorm = 2.2792, lr_0 = 1.9453e-04
Loss = 1.8496e-03, PNorm = 58.8988, GNorm = 2.7001, lr_0 = 1.9427e-04
Loss = 2.4046e-03, PNorm = 58.9054, GNorm = 2.0616, lr_0 = 1.9401e-04
Loss = 1.5048e-03, PNorm = 58.9109, GNorm = 1.7503, lr_0 = 1.9374e-04
Loss = 2.2690e-03, PNorm = 58.9148, GNorm = 2.7387, lr_0 = 1.9348e-04
Loss = 2.0309e-03, PNorm = 58.9185, GNorm = 1.6700, lr_0 = 1.9323e-04
Loss = 2.7830e-03, PNorm = 58.9227, GNorm = 2.2883, lr_0 = 1.9297e-04
Loss = 2.7247e-03, PNorm = 58.9278, GNorm = 1.5801, lr_0 = 1.9271e-04
Loss = 2.7049e-03, PNorm = 58.9337, GNorm = 2.9224, lr_0 = 1.9245e-04
Loss = 1.9384e-03, PNorm = 58.9379, GNorm = 2.3231, lr_0 = 1.9219e-04
Loss = 2.2549e-03, PNorm = 58.9419, GNorm = 3.2575, lr_0 = 1.9193e-04
Loss = 2.1660e-03, PNorm = 58.9448, GNorm = 2.1370, lr_0 = 1.9168e-04
Loss = 2.2304e-03, PNorm = 58.9473, GNorm = 2.8875, lr_0 = 1.9142e-04
Loss = 2.6755e-03, PNorm = 58.9519, GNorm = 2.9048, lr_0 = 1.9116e-04
Loss = 2.0111e-03, PNorm = 58.9581, GNorm = 2.5213, lr_0 = 1.9090e-04
Validation rmse = 4.411026
Validation R2 = -4.561354
Epoch 54
Train function
Loss = 1.5544e-03, PNorm = 58.9639, GNorm = 1.7176, lr_0 = 1.9062e-04
Loss = 2.2193e-03, PNorm = 58.9694, GNorm = 2.0534, lr_0 = 1.9037e-04
Loss = 1.3426e-03, PNorm = 58.9738, GNorm = 1.9656, lr_0 = 1.9011e-04
Loss = 1.5214e-03, PNorm = 58.9784, GNorm = 1.3847, lr_0 = 1.8986e-04
Loss = 1.8138e-03, PNorm = 58.9827, GNorm = 2.3406, lr_0 = 1.8960e-04
Loss = 1.3951e-03, PNorm = 58.9855, GNorm = 1.8377, lr_0 = 1.8935e-04
Loss = 1.3453e-03, PNorm = 58.9872, GNorm = 2.1906, lr_0 = 1.8909e-04
Loss = 1.6680e-03, PNorm = 58.9893, GNorm = 3.1949, lr_0 = 1.8884e-04
Loss = 2.1195e-03, PNorm = 58.9931, GNorm = 3.3163, lr_0 = 1.8859e-04
Loss = 2.4020e-03, PNorm = 58.9977, GNorm = 1.7841, lr_0 = 1.8833e-04
Loss = 2.0204e-03, PNorm = 59.0006, GNorm = 1.6255, lr_0 = 1.8808e-04
Loss = 1.5222e-03, PNorm = 59.0034, GNorm = 1.7866, lr_0 = 1.8783e-04
Loss = 2.0406e-03, PNorm = 59.0087, GNorm = 1.9524, lr_0 = 1.8758e-04
Loss = 2.0094e-03, PNorm = 59.0133, GNorm = 1.5060, lr_0 = 1.8732e-04
Loss = 2.1316e-03, PNorm = 59.0175, GNorm = 2.7502, lr_0 = 1.8707e-04
Loss = 2.1870e-03, PNorm = 59.0227, GNorm = 1.5313, lr_0 = 1.8682e-04
Loss = 1.9790e-03, PNorm = 59.0269, GNorm = 2.5397, lr_0 = 1.8657e-04
Loss = 2.0690e-03, PNorm = 59.0301, GNorm = 1.5407, lr_0 = 1.8632e-04
Loss = 2.1351e-03, PNorm = 59.0337, GNorm = 5.9387, lr_0 = 1.8607e-04
Loss = 2.2756e-03, PNorm = 59.0378, GNorm = 1.9097, lr_0 = 1.8582e-04
Loss = 2.2789e-03, PNorm = 59.0417, GNorm = 3.2681, lr_0 = 1.8557e-04
Loss = 2.0103e-03, PNorm = 59.0462, GNorm = 1.6206, lr_0 = 1.8532e-04
Loss = 2.4453e-03, PNorm = 59.0506, GNorm = 1.2483, lr_0 = 1.8507e-04
Loss = 2.1302e-03, PNorm = 59.0560, GNorm = 2.6235, lr_0 = 1.8483e-04
Validation rmse = 3.821388
Validation R2 = -3.173915
Epoch 55
Train function
Loss = 2.0107e-03, PNorm = 59.0622, GNorm = 1.3762, lr_0 = 1.8458e-04
Loss = 1.9540e-03, PNorm = 59.0683, GNorm = 3.1375, lr_0 = 1.8433e-04
Loss = 2.0807e-03, PNorm = 59.0731, GNorm = 1.6875, lr_0 = 1.8408e-04
Loss = 1.5953e-03, PNorm = 59.0777, GNorm = 2.9661, lr_0 = 1.8384e-04
Loss = 2.2280e-03, PNorm = 59.0799, GNorm = 1.6375, lr_0 = 1.8359e-04
Loss = 1.4013e-03, PNorm = 59.0831, GNorm = 1.8601, lr_0 = 1.8334e-04
Loss = 1.3177e-03, PNorm = 59.0868, GNorm = 1.4865, lr_0 = 1.8310e-04
Loss = 2.2636e-03, PNorm = 59.0910, GNorm = 1.2042, lr_0 = 1.8285e-04
Loss = 1.5205e-03, PNorm = 59.0943, GNorm = 1.8611, lr_0 = 1.8261e-04
Loss = 1.5372e-03, PNorm = 59.0966, GNorm = 1.5171, lr_0 = 1.8236e-04
Loss = 2.1956e-03, PNorm = 59.1012, GNorm = 3.1747, lr_0 = 1.8212e-04
Loss = 1.3970e-03, PNorm = 59.1066, GNorm = 1.7231, lr_0 = 1.8187e-04
Loss = 1.8443e-03, PNorm = 59.1102, GNorm = 1.7384, lr_0 = 1.8163e-04
Loss = 1.6905e-03, PNorm = 59.1143, GNorm = 1.7509, lr_0 = 1.8138e-04
Loss = 2.1960e-03, PNorm = 59.1191, GNorm = 1.6733, lr_0 = 1.8114e-04
Loss = 2.1878e-03, PNorm = 59.1232, GNorm = 3.5780, lr_0 = 1.8090e-04
Loss = 1.2406e-03, PNorm = 59.1274, GNorm = 1.5192, lr_0 = 1.8066e-04
Loss = 2.0438e-03, PNorm = 59.1311, GNorm = 2.8245, lr_0 = 1.8041e-04
Loss = 2.5994e-03, PNorm = 59.1340, GNorm = 2.1513, lr_0 = 1.8017e-04
Loss = 2.6320e-03, PNorm = 59.1384, GNorm = 1.7138, lr_0 = 1.7993e-04
Loss = 1.7862e-03, PNorm = 59.1420, GNorm = 1.8950, lr_0 = 1.7969e-04
Loss = 1.7630e-03, PNorm = 59.1448, GNorm = 1.6385, lr_0 = 1.7945e-04
Loss = 1.6404e-03, PNorm = 59.1491, GNorm = 1.2839, lr_0 = 1.7921e-04
Validation rmse = 3.907930
Validation R2 = -3.365108
Epoch 56
Train function
Loss = 1.4352e-03, PNorm = 59.1548, GNorm = 1.7586, lr_0 = 1.7894e-04
Loss = 2.1738e-03, PNorm = 59.1586, GNorm = 4.0056, lr_0 = 1.7870e-04
Loss = 1.5657e-03, PNorm = 59.1624, GNorm = 2.9355, lr_0 = 1.7846e-04
Loss = 1.9448e-03, PNorm = 59.1656, GNorm = 2.0769, lr_0 = 1.7822e-04
Loss = 1.8167e-03, PNorm = 59.1685, GNorm = 1.3996, lr_0 = 1.7798e-04
Loss = 2.6249e-03, PNorm = 59.1723, GNorm = 2.2515, lr_0 = 1.7774e-04
Loss = 1.8543e-03, PNorm = 59.1767, GNorm = 1.4457, lr_0 = 1.7751e-04
Loss = 1.7106e-03, PNorm = 59.1819, GNorm = 1.5444, lr_0 = 1.7727e-04
Loss = 1.4439e-03, PNorm = 59.1860, GNorm = 1.1926, lr_0 = 1.7703e-04
Loss = 1.7506e-03, PNorm = 59.1893, GNorm = 2.1614, lr_0 = 1.7679e-04
Loss = 1.6238e-03, PNorm = 59.1927, GNorm = 2.4967, lr_0 = 1.7656e-04
Loss = 1.6346e-03, PNorm = 59.1962, GNorm = 1.8665, lr_0 = 1.7632e-04
Loss = 1.5220e-03, PNorm = 59.1998, GNorm = 1.7451, lr_0 = 1.7608e-04
Loss = 2.1765e-03, PNorm = 59.2030, GNorm = 2.5133, lr_0 = 1.7585e-04
Loss = 1.7256e-03, PNorm = 59.2069, GNorm = 1.4329, lr_0 = 1.7561e-04
Loss = 1.6419e-03, PNorm = 59.2103, GNorm = 1.6741, lr_0 = 1.7537e-04
Loss = 1.9221e-03, PNorm = 59.2141, GNorm = 2.2233, lr_0 = 1.7514e-04
Loss = 1.5504e-03, PNorm = 59.2184, GNorm = 1.9561, lr_0 = 1.7490e-04
Loss = 1.9679e-03, PNorm = 59.2234, GNorm = 2.0537, lr_0 = 1.7467e-04
Loss = 1.5254e-03, PNorm = 59.2284, GNorm = 2.9374, lr_0 = 1.7443e-04
Loss = 2.1656e-03, PNorm = 59.2325, GNorm = 2.2517, lr_0 = 1.7420e-04
Loss = 1.9773e-03, PNorm = 59.2357, GNorm = 1.6375, lr_0 = 1.7397e-04
Loss = 1.5471e-03, PNorm = 59.2395, GNorm = 2.2700, lr_0 = 1.7373e-04
Validation rmse = 4.155998
Validation R2 = -3.936875
Epoch 57
Train function
Loss = 1.2178e-03, PNorm = 59.2434, GNorm = 1.5039, lr_0 = 1.7348e-04
Loss = 1.5580e-03, PNorm = 59.2476, GNorm = 2.0884, lr_0 = 1.7324e-04
Loss = 1.2999e-03, PNorm = 59.2525, GNorm = 2.0000, lr_0 = 1.7301e-04
Loss = 1.2162e-03, PNorm = 59.2563, GNorm = 1.3635, lr_0 = 1.7278e-04
Loss = 1.5183e-03, PNorm = 59.2594, GNorm = 2.4372, lr_0 = 1.7255e-04
Loss = 1.8545e-03, PNorm = 59.2632, GNorm = 1.4785, lr_0 = 1.7232e-04
Loss = 2.3429e-03, PNorm = 59.2677, GNorm = 1.8455, lr_0 = 1.7209e-04
Loss = 1.7872e-03, PNorm = 59.2721, GNorm = 1.5289, lr_0 = 1.7185e-04
Loss = 1.4087e-03, PNorm = 59.2766, GNorm = 2.0675, lr_0 = 1.7162e-04
Loss = 1.5518e-03, PNorm = 59.2811, GNorm = 2.6495, lr_0 = 1.7139e-04
Loss = 1.8957e-03, PNorm = 59.2851, GNorm = 3.1644, lr_0 = 1.7116e-04
Loss = 1.6253e-03, PNorm = 59.2882, GNorm = 2.3209, lr_0 = 1.7093e-04
Loss = 2.2386e-03, PNorm = 59.2910, GNorm = 2.1336, lr_0 = 1.7070e-04
Loss = 1.2769e-03, PNorm = 59.2945, GNorm = 2.2851, lr_0 = 1.7048e-04
Loss = 1.1991e-03, PNorm = 59.2973, GNorm = 1.8215, lr_0 = 1.7025e-04
Loss = 1.8248e-03, PNorm = 59.3001, GNorm = 3.4323, lr_0 = 1.7002e-04
Loss = 1.7497e-03, PNorm = 59.3041, GNorm = 2.6422, lr_0 = 1.6979e-04
Loss = 1.4526e-03, PNorm = 59.3079, GNorm = 3.0269, lr_0 = 1.6956e-04
Loss = 1.6173e-03, PNorm = 59.3102, GNorm = 2.2328, lr_0 = 1.6933e-04
Loss = 1.5923e-03, PNorm = 59.3119, GNorm = 1.8449, lr_0 = 1.6911e-04
Loss = 2.0910e-03, PNorm = 59.3162, GNorm = 2.9949, lr_0 = 1.6888e-04
Loss = 1.9972e-03, PNorm = 59.3203, GNorm = 1.8669, lr_0 = 1.6865e-04
Loss = 1.8412e-03, PNorm = 59.3230, GNorm = 1.4668, lr_0 = 1.6843e-04
Loss = 2.0590e-03, PNorm = 59.3261, GNorm = 2.5894, lr_0 = 1.6820e-04
Validation rmse = 4.028123
Validation R2 = -3.637744
Epoch 58
Train function
Loss = 1.5158e-03, PNorm = 59.3310, GNorm = 1.8015, lr_0 = 1.6795e-04
Loss = 1.7573e-03, PNorm = 59.3347, GNorm = 1.5514, lr_0 = 1.6773e-04
Loss = 1.3298e-03, PNorm = 59.3386, GNorm = 1.1841, lr_0 = 1.6750e-04
Loss = 1.6765e-03, PNorm = 59.3425, GNorm = 3.0602, lr_0 = 1.6728e-04
Loss = 1.1412e-03, PNorm = 59.3472, GNorm = 2.1796, lr_0 = 1.6705e-04
Loss = 1.4077e-03, PNorm = 59.3503, GNorm = 1.9888, lr_0 = 1.6683e-04
Loss = 1.5561e-03, PNorm = 59.3528, GNorm = 2.4896, lr_0 = 1.6661e-04
Loss = 1.5540e-03, PNorm = 59.3565, GNorm = 2.0401, lr_0 = 1.6638e-04
Loss = 1.7528e-03, PNorm = 59.3600, GNorm = 1.4847, lr_0 = 1.6616e-04
Loss = 2.1291e-03, PNorm = 59.3649, GNorm = 1.0461, lr_0 = 1.6594e-04
Loss = 9.4844e-04, PNorm = 59.3693, GNorm = 0.8589, lr_0 = 1.6571e-04
Loss = 1.3857e-03, PNorm = 59.3722, GNorm = 1.7851, lr_0 = 1.6549e-04
Loss = 1.4717e-03, PNorm = 59.3745, GNorm = 1.3732, lr_0 = 1.6527e-04
Loss = 1.7888e-03, PNorm = 59.3767, GNorm = 2.6326, lr_0 = 1.6505e-04
Loss = 1.6109e-03, PNorm = 59.3796, GNorm = 1.7002, lr_0 = 1.6483e-04
Loss = 1.8966e-03, PNorm = 59.3826, GNorm = 1.6132, lr_0 = 1.6461e-04
Loss = 2.1159e-03, PNorm = 59.3866, GNorm = 2.4429, lr_0 = 1.6438e-04
Loss = 2.0605e-03, PNorm = 59.3909, GNorm = 3.0942, lr_0 = 1.6416e-04
Loss = 1.5645e-03, PNorm = 59.3945, GNorm = 2.1779, lr_0 = 1.6394e-04
Loss = 1.6252e-03, PNorm = 59.3985, GNorm = 2.1710, lr_0 = 1.6372e-04
Loss = 1.2786e-03, PNorm = 59.4016, GNorm = 1.4354, lr_0 = 1.6350e-04
Loss = 1.8090e-03, PNorm = 59.4047, GNorm = 1.5742, lr_0 = 1.6328e-04
Loss = 2.1627e-03, PNorm = 59.4093, GNorm = 1.2636, lr_0 = 1.6307e-04
Validation rmse = 3.978532
Validation R2 = -3.524255
Epoch 59
Train function
Loss = 9.8106e-04, PNorm = 59.4130, GNorm = 2.0723, lr_0 = 1.6282e-04
Loss = 1.6972e-03, PNorm = 59.4159, GNorm = 3.8078, lr_0 = 1.6261e-04
Loss = 1.7965e-03, PNorm = 59.4197, GNorm = 3.1488, lr_0 = 1.6239e-04
Loss = 1.2616e-03, PNorm = 59.4231, GNorm = 2.2700, lr_0 = 1.6217e-04
Loss = 1.1290e-03, PNorm = 59.4260, GNorm = 1.4876, lr_0 = 1.6195e-04
Loss = 1.1678e-03, PNorm = 59.4293, GNorm = 2.2885, lr_0 = 1.6174e-04
Loss = 1.6667e-03, PNorm = 59.4319, GNorm = 2.2250, lr_0 = 1.6152e-04
Loss = 1.3627e-03, PNorm = 59.4350, GNorm = 1.5510, lr_0 = 1.6130e-04
Loss = 1.6412e-03, PNorm = 59.4381, GNorm = 3.6424, lr_0 = 1.6109e-04
Loss = 1.4262e-03, PNorm = 59.4422, GNorm = 2.2812, lr_0 = 1.6087e-04
Loss = 1.6734e-03, PNorm = 59.4468, GNorm = 2.4799, lr_0 = 1.6065e-04
Loss = 1.1955e-03, PNorm = 59.4522, GNorm = 1.6313, lr_0 = 1.6044e-04
Loss = 1.2425e-03, PNorm = 59.4554, GNorm = 1.0103, lr_0 = 1.6022e-04
Loss = 1.3456e-03, PNorm = 59.4590, GNorm = 1.7727, lr_0 = 1.6001e-04
Loss = 1.3758e-03, PNorm = 59.4615, GNorm = 1.2558, lr_0 = 1.5979e-04
Loss = 2.2514e-03, PNorm = 59.4650, GNorm = 2.3204, lr_0 = 1.5958e-04
Loss = 1.4554e-03, PNorm = 59.4686, GNorm = 1.9129, lr_0 = 1.5936e-04
Loss = 1.3152e-03, PNorm = 59.4726, GNorm = 2.7350, lr_0 = 1.5915e-04
Loss = 1.9140e-03, PNorm = 59.4757, GNorm = 1.4892, lr_0 = 1.5894e-04
Loss = 1.5226e-03, PNorm = 59.4790, GNorm = 2.0469, lr_0 = 1.5872e-04
Loss = 2.0664e-03, PNorm = 59.4821, GNorm = 2.3333, lr_0 = 1.5851e-04
Loss = 1.4763e-03, PNorm = 59.4845, GNorm = 1.3936, lr_0 = 1.5830e-04
Loss = 2.0824e-03, PNorm = 59.4879, GNorm = 2.1298, lr_0 = 1.5809e-04
Loss = 1.4561e-03, PNorm = 59.4921, GNorm = 1.4458, lr_0 = 1.5787e-04
Validation rmse = 4.191791
Validation R2 = -4.022276
Epoch 60
Train function
Loss = 1.2840e-03, PNorm = 59.4950, GNorm = 2.1407, lr_0 = 1.5766e-04
Loss = 1.1070e-03, PNorm = 59.4972, GNorm = 1.7920, lr_0 = 1.5745e-04
Loss = 1.0655e-03, PNorm = 59.4998, GNorm = 1.2083, lr_0 = 1.5724e-04
Loss = 1.3734e-03, PNorm = 59.5032, GNorm = 1.4308, lr_0 = 1.5703e-04
Loss = 1.3573e-03, PNorm = 59.5058, GNorm = 2.5305, lr_0 = 1.5682e-04
Loss = 1.7974e-03, PNorm = 59.5093, GNorm = 1.2102, lr_0 = 1.5661e-04
Loss = 2.0164e-03, PNorm = 59.5129, GNorm = 1.6595, lr_0 = 1.5640e-04
Loss = 1.2755e-03, PNorm = 59.5157, GNorm = 2.7031, lr_0 = 1.5619e-04
Loss = 1.4255e-03, PNorm = 59.5190, GNorm = 1.2747, lr_0 = 1.5598e-04
Loss = 1.7924e-03, PNorm = 59.5223, GNorm = 3.0748, lr_0 = 1.5577e-04
Loss = 1.3432e-03, PNorm = 59.5265, GNorm = 1.3917, lr_0 = 1.5556e-04
Loss = 1.2766e-03, PNorm = 59.5303, GNorm = 2.0636, lr_0 = 1.5535e-04
Loss = 1.2646e-03, PNorm = 59.5340, GNorm = 1.6634, lr_0 = 1.5514e-04
Loss = 1.9195e-03, PNorm = 59.5370, GNorm = 2.4597, lr_0 = 1.5493e-04
Loss = 1.5262e-03, PNorm = 59.5401, GNorm = 1.8213, lr_0 = 1.5473e-04
Loss = 1.5342e-03, PNorm = 59.5420, GNorm = 1.8527, lr_0 = 1.5452e-04
Loss = 1.4138e-03, PNorm = 59.5454, GNorm = 3.9601, lr_0 = 1.5431e-04
Loss = 1.3596e-03, PNorm = 59.5494, GNorm = 2.1323, lr_0 = 1.5410e-04
Loss = 1.5559e-03, PNorm = 59.5521, GNorm = 3.2919, lr_0 = 1.5390e-04
Loss = 2.1398e-03, PNorm = 59.5542, GNorm = 1.4598, lr_0 = 1.5369e-04
Loss = 1.8200e-03, PNorm = 59.5573, GNorm = 2.1495, lr_0 = 1.5348e-04
Loss = 1.4570e-03, PNorm = 59.5608, GNorm = 1.1886, lr_0 = 1.5328e-04
Loss = 1.6740e-03, PNorm = 59.5644, GNorm = 2.6270, lr_0 = 1.5307e-04
Validation rmse = 4.047400
Validation R2 = -3.682239
Epoch 61
Train function
Loss = 1.3267e-03, PNorm = 59.5691, GNorm = 2.0211, lr_0 = 1.5285e-04
Loss = 1.4307e-03, PNorm = 59.5728, GNorm = 1.3834, lr_0 = 1.5264e-04
Loss = 1.3907e-03, PNorm = 59.5753, GNorm = 1.9303, lr_0 = 1.5244e-04
Loss = 1.2473e-03, PNorm = 59.5796, GNorm = 1.0667, lr_0 = 1.5223e-04
Loss = 1.9837e-03, PNorm = 59.5829, GNorm = 3.8190, lr_0 = 1.5203e-04
Loss = 1.1330e-03, PNorm = 59.5868, GNorm = 1.5317, lr_0 = 1.5182e-04
Loss = 9.1110e-04, PNorm = 59.5905, GNorm = 1.4850, lr_0 = 1.5162e-04
Loss = 1.0452e-03, PNorm = 59.5936, GNorm = 2.0192, lr_0 = 1.5142e-04
Loss = 1.2399e-03, PNorm = 59.5964, GNorm = 1.7010, lr_0 = 1.5121e-04
Loss = 1.4187e-03, PNorm = 59.5988, GNorm = 1.7359, lr_0 = 1.5101e-04
Loss = 1.7180e-03, PNorm = 59.6014, GNorm = 1.6447, lr_0 = 1.5081e-04
Loss = 1.0532e-03, PNorm = 59.6037, GNorm = 2.1251, lr_0 = 1.5061e-04
Loss = 1.3049e-03, PNorm = 59.6073, GNorm = 1.3705, lr_0 = 1.5040e-04
Loss = 1.3643e-03, PNorm = 59.6114, GNorm = 2.2011, lr_0 = 1.5020e-04
Loss = 1.3882e-03, PNorm = 59.6153, GNorm = 2.1064, lr_0 = 1.5000e-04
Loss = 1.0993e-03, PNorm = 59.6182, GNorm = 1.4995, lr_0 = 1.4980e-04
Loss = 1.2639e-03, PNorm = 59.6208, GNorm = 1.1863, lr_0 = 1.4960e-04
Loss = 1.5523e-03, PNorm = 59.6244, GNorm = 1.6447, lr_0 = 1.4940e-04
Loss = 1.5673e-03, PNorm = 59.6280, GNorm = 2.0431, lr_0 = 1.4920e-04
Loss = 1.5005e-03, PNorm = 59.6305, GNorm = 1.9914, lr_0 = 1.4900e-04
Loss = 2.4866e-03, PNorm = 59.6337, GNorm = 4.1239, lr_0 = 1.4880e-04
Loss = 1.2913e-03, PNorm = 59.6372, GNorm = 1.4470, lr_0 = 1.4860e-04
Loss = 1.2887e-03, PNorm = 59.6400, GNorm = 1.2438, lr_0 = 1.4840e-04
Loss = 1.6534e-03, PNorm = 59.6428, GNorm = 2.4239, lr_0 = 1.4820e-04
Loss = 1.9096e-02, PNorm = 59.6432, GNorm = 7.7825, lr_0 = 1.4818e-04
Validation rmse = 4.128241
Validation R2 = -3.871148
Epoch 62
Train function
Loss = 1.2025e-03, PNorm = 59.6464, GNorm = 2.1357, lr_0 = 1.4798e-04
Loss = 1.2158e-03, PNorm = 59.6497, GNorm = 2.1455, lr_0 = 1.4778e-04
Loss = 1.1092e-03, PNorm = 59.6521, GNorm = 1.3231, lr_0 = 1.4758e-04
Loss = 1.0094e-03, PNorm = 59.6552, GNorm = 1.5409, lr_0 = 1.4739e-04
Loss = 1.1857e-03, PNorm = 59.6577, GNorm = 0.9675, lr_0 = 1.4719e-04
Loss = 9.4802e-04, PNorm = 59.6600, GNorm = 1.3311, lr_0 = 1.4699e-04
Loss = 1.1022e-03, PNorm = 59.6624, GNorm = 1.0207, lr_0 = 1.4679e-04
Loss = 1.3642e-03, PNorm = 59.6655, GNorm = 1.9997, lr_0 = 1.4660e-04
Loss = 1.0538e-03, PNorm = 59.6676, GNorm = 1.5933, lr_0 = 1.4640e-04
Loss = 1.0004e-03, PNorm = 59.6695, GNorm = 1.2964, lr_0 = 1.4620e-04
Loss = 2.3643e-03, PNorm = 59.6712, GNorm = 1.2983, lr_0 = 1.4601e-04
Loss = 1.2493e-03, PNorm = 59.6737, GNorm = 1.3889, lr_0 = 1.4581e-04
Loss = 1.7381e-03, PNorm = 59.6753, GNorm = 1.8194, lr_0 = 1.4562e-04
Loss = 1.5468e-03, PNorm = 59.6780, GNorm = 2.6758, lr_0 = 1.4542e-04
Loss = 1.0094e-03, PNorm = 59.6816, GNorm = 3.1469, lr_0 = 1.4522e-04
Loss = 1.4507e-03, PNorm = 59.6848, GNorm = 1.5078, lr_0 = 1.4503e-04
Loss = 2.1189e-03, PNorm = 59.6889, GNorm = 1.5589, lr_0 = 1.4484e-04
Loss = 1.3954e-03, PNorm = 59.6921, GNorm = 1.4159, lr_0 = 1.4464e-04
Loss = 1.4124e-03, PNorm = 59.6952, GNorm = 2.2297, lr_0 = 1.4445e-04
Loss = 1.1356e-03, PNorm = 59.6982, GNorm = 1.7212, lr_0 = 1.4425e-04
Loss = 1.3876e-03, PNorm = 59.7007, GNorm = 1.5475, lr_0 = 1.4406e-04
Loss = 1.5090e-03, PNorm = 59.7038, GNorm = 2.3783, lr_0 = 1.4387e-04
Loss = 1.0712e-03, PNorm = 59.7066, GNorm = 1.2429, lr_0 = 1.4367e-04
Validation rmse = 4.169603
Validation R2 = -3.969249
Epoch 63
Train function
Loss = 9.4549e-04, PNorm = 59.7113, GNorm = 2.0914, lr_0 = 1.4346e-04
Loss = 1.0273e-03, PNorm = 59.7139, GNorm = 1.4634, lr_0 = 1.4327e-04
Loss = 9.9739e-04, PNorm = 59.7163, GNorm = 1.5392, lr_0 = 1.4308e-04
Loss = 1.7635e-03, PNorm = 59.7189, GNorm = 2.5103, lr_0 = 1.4288e-04
Loss = 1.1188e-03, PNorm = 59.7218, GNorm = 1.4929, lr_0 = 1.4269e-04
Loss = 1.2345e-03, PNorm = 59.7248, GNorm = 1.3199, lr_0 = 1.4250e-04
Loss = 1.0276e-03, PNorm = 59.7271, GNorm = 1.3108, lr_0 = 1.4231e-04
Loss = 1.2479e-03, PNorm = 59.7300, GNorm = 1.1160, lr_0 = 1.4212e-04
Loss = 1.2962e-03, PNorm = 59.7323, GNorm = 1.9370, lr_0 = 1.4193e-04
Loss = 1.1232e-03, PNorm = 59.7349, GNorm = 2.0116, lr_0 = 1.4174e-04
Loss = 9.3384e-04, PNorm = 59.7374, GNorm = 1.1158, lr_0 = 1.4155e-04
Loss = 9.5390e-04, PNorm = 59.7403, GNorm = 1.6245, lr_0 = 1.4136e-04
Loss = 1.8064e-03, PNorm = 59.7422, GNorm = 2.2185, lr_0 = 1.4117e-04
Loss = 1.0244e-03, PNorm = 59.7438, GNorm = 1.7533, lr_0 = 1.4098e-04
Loss = 1.1454e-03, PNorm = 59.7463, GNorm = 1.1020, lr_0 = 1.4079e-04
Loss = 1.9313e-03, PNorm = 59.7502, GNorm = 2.3029, lr_0 = 1.4060e-04
Loss = 1.1492e-03, PNorm = 59.7537, GNorm = 1.2943, lr_0 = 1.4041e-04
Loss = 1.1487e-03, PNorm = 59.7575, GNorm = 1.7491, lr_0 = 1.4022e-04
Loss = 1.0817e-03, PNorm = 59.7604, GNorm = 2.3100, lr_0 = 1.4004e-04
Loss = 1.7520e-03, PNorm = 59.7637, GNorm = 2.0781, lr_0 = 1.3985e-04
Loss = 1.1052e-03, PNorm = 59.7668, GNorm = 1.5294, lr_0 = 1.3966e-04
Loss = 1.5093e-03, PNorm = 59.7695, GNorm = 1.6279, lr_0 = 1.3947e-04
Loss = 1.5175e-03, PNorm = 59.7731, GNorm = 1.3600, lr_0 = 1.3929e-04
Validation rmse = 4.157887
Validation R2 = -3.941362
Epoch 64
Train function
Loss = 6.7051e-04, PNorm = 59.7756, GNorm = 1.0872, lr_0 = 1.3908e-04
Loss = 9.8937e-04, PNorm = 59.7774, GNorm = 1.5287, lr_0 = 1.3889e-04
Loss = 1.2782e-03, PNorm = 59.7799, GNorm = 2.0780, lr_0 = 1.3871e-04
Loss = 1.3254e-03, PNorm = 59.7838, GNorm = 1.4066, lr_0 = 1.3852e-04
Loss = 9.1702e-04, PNorm = 59.7868, GNorm = 1.0496, lr_0 = 1.3834e-04
Loss = 1.0825e-03, PNorm = 59.7888, GNorm = 1.5138, lr_0 = 1.3815e-04
Loss = 1.1670e-03, PNorm = 59.7905, GNorm = 1.6086, lr_0 = 1.3796e-04
Loss = 1.3133e-03, PNorm = 59.7924, GNorm = 1.0515, lr_0 = 1.3778e-04
Loss = 1.2061e-03, PNorm = 59.7937, GNorm = 1.8062, lr_0 = 1.3759e-04
Loss = 9.7391e-04, PNorm = 59.7960, GNorm = 1.5522, lr_0 = 1.3741e-04
Loss = 1.7636e-03, PNorm = 59.7979, GNorm = 1.9563, lr_0 = 1.3723e-04
Loss = 1.0370e-03, PNorm = 59.8007, GNorm = 2.0809, lr_0 = 1.3704e-04
Loss = 1.0098e-03, PNorm = 59.8035, GNorm = 1.6765, lr_0 = 1.3686e-04
Loss = 9.4044e-04, PNorm = 59.8065, GNorm = 0.9624, lr_0 = 1.3667e-04
Loss = 1.3698e-03, PNorm = 59.8090, GNorm = 1.8616, lr_0 = 1.3649e-04
Loss = 1.0895e-03, PNorm = 59.8113, GNorm = 2.6659, lr_0 = 1.3631e-04
Loss = 1.1725e-03, PNorm = 59.8131, GNorm = 2.4166, lr_0 = 1.3612e-04
Loss = 1.7433e-03, PNorm = 59.8165, GNorm = 2.6658, lr_0 = 1.3594e-04
Loss = 1.5354e-03, PNorm = 59.8197, GNorm = 1.9808, lr_0 = 1.3576e-04
Loss = 1.3545e-03, PNorm = 59.8232, GNorm = 2.7882, lr_0 = 1.3558e-04
Loss = 1.2296e-03, PNorm = 59.8266, GNorm = 2.3731, lr_0 = 1.3540e-04
Loss = 1.1777e-03, PNorm = 59.8297, GNorm = 1.8720, lr_0 = 1.3521e-04
Loss = 1.2075e-03, PNorm = 59.8332, GNorm = 1.2824, lr_0 = 1.3503e-04
Loss = 9.1283e-04, PNorm = 59.8365, GNorm = 1.4313, lr_0 = 1.3485e-04
Validation rmse = 4.225134
Validation R2 = -4.102492
Epoch 65
Train function
Loss = 1.1030e-03, PNorm = 59.8402, GNorm = 1.6627, lr_0 = 1.3467e-04
Loss = 8.9388e-04, PNorm = 59.8434, GNorm = 0.9826, lr_0 = 1.3449e-04
Loss = 8.9355e-04, PNorm = 59.8456, GNorm = 1.8682, lr_0 = 1.3431e-04
Loss = 1.3666e-03, PNorm = 59.8476, GNorm = 2.6979, lr_0 = 1.3413e-04
Loss = 1.2748e-03, PNorm = 59.8508, GNorm = 1.9423, lr_0 = 1.3395e-04
Loss = 1.0721e-03, PNorm = 59.8552, GNorm = 1.2776, lr_0 = 1.3377e-04
Loss = 1.5670e-03, PNorm = 59.8575, GNorm = 3.3759, lr_0 = 1.3359e-04
Loss = 9.8948e-04, PNorm = 59.8597, GNorm = 1.1648, lr_0 = 1.3341e-04
Loss = 1.2472e-03, PNorm = 59.8618, GNorm = 2.4720, lr_0 = 1.3323e-04
Loss = 8.5153e-04, PNorm = 59.8632, GNorm = 2.0782, lr_0 = 1.3305e-04
Loss = 8.6225e-04, PNorm = 59.8649, GNorm = 1.6134, lr_0 = 1.3287e-04
Loss = 1.0739e-03, PNorm = 59.8666, GNorm = 1.6563, lr_0 = 1.3270e-04
Loss = 1.6467e-03, PNorm = 59.8691, GNorm = 1.4848, lr_0 = 1.3252e-04
Loss = 9.6720e-04, PNorm = 59.8714, GNorm = 1.2996, lr_0 = 1.3234e-04
Loss = 1.0550e-03, PNorm = 59.8732, GNorm = 1.1634, lr_0 = 1.3216e-04
Loss = 1.1209e-03, PNorm = 59.8752, GNorm = 1.7446, lr_0 = 1.3199e-04
Loss = 1.3474e-03, PNorm = 59.8776, GNorm = 2.6339, lr_0 = 1.3181e-04
Loss = 9.9256e-04, PNorm = 59.8805, GNorm = 1.7269, lr_0 = 1.3163e-04
Loss = 1.2159e-03, PNorm = 59.8827, GNorm = 1.2858, lr_0 = 1.3145e-04
Loss = 1.3777e-03, PNorm = 59.8856, GNorm = 2.1091, lr_0 = 1.3128e-04
Loss = 1.1549e-03, PNorm = 59.8883, GNorm = 1.5514, lr_0 = 1.3110e-04
Loss = 1.3372e-03, PNorm = 59.8901, GNorm = 0.9884, lr_0 = 1.3093e-04
Loss = 1.2254e-03, PNorm = 59.8921, GNorm = 1.6267, lr_0 = 1.3075e-04
Validation rmse = 4.137227
Validation R2 = -3.892379
Epoch 66
Train function
Loss = 1.1498e-03, PNorm = 59.8938, GNorm = 2.3231, lr_0 = 1.3056e-04
Loss = 1.4061e-03, PNorm = 59.8967, GNorm = 1.8948, lr_0 = 1.3038e-04
Loss = 7.8045e-04, PNorm = 59.8988, GNorm = 1.2291, lr_0 = 1.3021e-04
Loss = 1.2081e-03, PNorm = 59.9007, GNorm = 1.7176, lr_0 = 1.3003e-04
Loss = 1.4262e-03, PNorm = 59.9032, GNorm = 3.2980, lr_0 = 1.2986e-04
Loss = 1.0578e-03, PNorm = 59.9061, GNorm = 3.0101, lr_0 = 1.2968e-04
Loss = 1.0459e-03, PNorm = 59.9091, GNorm = 1.5431, lr_0 = 1.2951e-04
Loss = 1.0551e-03, PNorm = 59.9112, GNorm = 1.3295, lr_0 = 1.2934e-04
Loss = 1.0734e-03, PNorm = 59.9135, GNorm = 1.2427, lr_0 = 1.2916e-04
Loss = 8.6548e-04, PNorm = 59.9154, GNorm = 0.8962, lr_0 = 1.2899e-04
Loss = 1.0591e-03, PNorm = 59.9172, GNorm = 0.9707, lr_0 = 1.2882e-04
Loss = 1.1221e-03, PNorm = 59.9195, GNorm = 1.4358, lr_0 = 1.2864e-04
Loss = 9.2414e-04, PNorm = 59.9224, GNorm = 1.3560, lr_0 = 1.2847e-04
Loss = 7.7391e-04, PNorm = 59.9249, GNorm = 2.9303, lr_0 = 1.2830e-04
Loss = 1.2013e-03, PNorm = 59.9271, GNorm = 1.5559, lr_0 = 1.2813e-04
Loss = 1.0446e-03, PNorm = 59.9301, GNorm = 1.4515, lr_0 = 1.2795e-04
Loss = 8.2159e-04, PNorm = 59.9332, GNorm = 1.5181, lr_0 = 1.2778e-04
Loss = 1.2011e-03, PNorm = 59.9358, GNorm = 2.9384, lr_0 = 1.2761e-04
Loss = 1.0775e-03, PNorm = 59.9378, GNorm = 2.4287, lr_0 = 1.2744e-04
Loss = 9.3499e-04, PNorm = 59.9402, GNorm = 1.4624, lr_0 = 1.2727e-04
Loss = 1.1667e-03, PNorm = 59.9426, GNorm = 1.1038, lr_0 = 1.2710e-04
Loss = 1.8019e-03, PNorm = 59.9455, GNorm = 4.3263, lr_0 = 1.2693e-04
Loss = 1.4337e-03, PNorm = 59.9479, GNorm = 2.0569, lr_0 = 1.2676e-04
Loss = 9.9813e-04, PNorm = 59.9502, GNorm = 1.8088, lr_0 = 1.2659e-04
Validation rmse = 4.207077
Validation R2 = -4.058971
Epoch 67
Train function
Loss = 1.0802e-03, PNorm = 59.9531, GNorm = 1.3782, lr_0 = 1.2640e-04
Loss = 8.8287e-04, PNorm = 59.9552, GNorm = 1.8502, lr_0 = 1.2623e-04
Loss = 7.5918e-04, PNorm = 59.9575, GNorm = 1.6559, lr_0 = 1.2606e-04
Loss = 9.6689e-04, PNorm = 59.9592, GNorm = 1.2096, lr_0 = 1.2589e-04
Loss = 1.1758e-03, PNorm = 59.9608, GNorm = 1.6190, lr_0 = 1.2572e-04
Loss = 9.2396e-04, PNorm = 59.9623, GNorm = 1.1286, lr_0 = 1.2555e-04
Loss = 1.0148e-03, PNorm = 59.9653, GNorm = 1.8415, lr_0 = 1.2539e-04
Loss = 1.6947e-03, PNorm = 59.9688, GNorm = 1.1847, lr_0 = 1.2522e-04
Loss = 1.2363e-03, PNorm = 59.9718, GNorm = 0.9403, lr_0 = 1.2505e-04
Loss = 6.0269e-04, PNorm = 59.9737, GNorm = 1.3943, lr_0 = 1.2488e-04
Loss = 1.0334e-03, PNorm = 59.9754, GNorm = 1.5036, lr_0 = 1.2471e-04
Loss = 1.1392e-03, PNorm = 59.9768, GNorm = 2.7632, lr_0 = 1.2455e-04
Loss = 7.6866e-04, PNorm = 59.9796, GNorm = 1.4859, lr_0 = 1.2438e-04
Loss = 1.2114e-03, PNorm = 59.9825, GNorm = 1.8777, lr_0 = 1.2421e-04
Loss = 1.0991e-03, PNorm = 59.9856, GNorm = 1.0402, lr_0 = 1.2405e-04
Loss = 1.4593e-03, PNorm = 59.9880, GNorm = 2.3102, lr_0 = 1.2388e-04
Loss = 8.8779e-04, PNorm = 59.9893, GNorm = 1.8101, lr_0 = 1.2371e-04
Loss = 1.0760e-03, PNorm = 59.9913, GNorm = 1.0827, lr_0 = 1.2355e-04
Loss = 8.6184e-04, PNorm = 59.9940, GNorm = 1.3966, lr_0 = 1.2338e-04
Loss = 1.0622e-03, PNorm = 59.9969, GNorm = 1.3843, lr_0 = 1.2322e-04
Loss = 8.2763e-04, PNorm = 59.9987, GNorm = 1.4224, lr_0 = 1.2305e-04
Loss = 1.1231e-03, PNorm = 60.0008, GNorm = 1.9126, lr_0 = 1.2289e-04
Loss = 9.4565e-04, PNorm = 60.0024, GNorm = 1.6393, lr_0 = 1.2272e-04
Validation rmse = 4.249164
Validation R2 = -4.160696
Epoch 68
Train function
Loss = 6.7614e-04, PNorm = 60.0032, GNorm = 1.7491, lr_0 = 1.2254e-04
Loss = 7.1105e-04, PNorm = 60.0048, GNorm = 1.2102, lr_0 = 1.2238e-04
Loss = 8.9065e-04, PNorm = 60.0064, GNorm = 1.3711, lr_0 = 1.2221e-04
Loss = 7.9705e-04, PNorm = 60.0088, GNorm = 1.0640, lr_0 = 1.2205e-04
Loss = 9.9717e-04, PNorm = 60.0115, GNorm = 1.4550, lr_0 = 1.2188e-04
Loss = 1.1784e-03, PNorm = 60.0140, GNorm = 1.4132, lr_0 = 1.2172e-04
Loss = 6.1722e-04, PNorm = 60.0160, GNorm = 1.0564, lr_0 = 1.2156e-04
Loss = 1.2356e-03, PNorm = 60.0189, GNorm = 1.8107, lr_0 = 1.2139e-04
Loss = 1.0572e-03, PNorm = 60.0217, GNorm = 2.0100, lr_0 = 1.2123e-04
Loss = 1.5863e-03, PNorm = 60.0247, GNorm = 1.6152, lr_0 = 1.2107e-04
Loss = 9.8372e-04, PNorm = 60.0277, GNorm = 1.0668, lr_0 = 1.2091e-04
Loss = 8.7108e-04, PNorm = 60.0298, GNorm = 1.7855, lr_0 = 1.2074e-04
Loss = 1.6026e-03, PNorm = 60.0323, GNorm = 1.9961, lr_0 = 1.2058e-04
Loss = 7.4395e-04, PNorm = 60.0347, GNorm = 1.3999, lr_0 = 1.2042e-04
Loss = 1.0360e-03, PNorm = 60.0369, GNorm = 2.8858, lr_0 = 1.2026e-04
Loss = 1.0974e-03, PNorm = 60.0392, GNorm = 1.5356, lr_0 = 1.2010e-04
Loss = 1.2630e-03, PNorm = 60.0406, GNorm = 1.8311, lr_0 = 1.1994e-04
Loss = 6.8359e-04, PNorm = 60.0419, GNorm = 1.3980, lr_0 = 1.1978e-04
Loss = 1.0729e-03, PNorm = 60.0444, GNorm = 1.4180, lr_0 = 1.1961e-04
Loss = 1.0062e-03, PNorm = 60.0471, GNorm = 1.0280, lr_0 = 1.1945e-04
Loss = 1.2557e-03, PNorm = 60.0495, GNorm = 2.0097, lr_0 = 1.1929e-04
Loss = 9.7427e-04, PNorm = 60.0521, GNorm = 1.6203, lr_0 = 1.1913e-04
Loss = 7.8857e-04, PNorm = 60.0543, GNorm = 1.2753, lr_0 = 1.1897e-04
Validation rmse = 4.172098
Validation R2 = -3.975198
Epoch 69
Train function
Loss = 3.2689e-04, PNorm = 60.0562, GNorm = 0.7779, lr_0 = 1.1880e-04
Loss = 1.1045e-03, PNorm = 60.0579, GNorm = 1.7188, lr_0 = 1.1864e-04
Loss = 1.0668e-03, PNorm = 60.0596, GNorm = 1.4370, lr_0 = 1.1848e-04
Loss = 1.1203e-03, PNorm = 60.0607, GNorm = 1.7486, lr_0 = 1.1832e-04
Loss = 7.1463e-04, PNorm = 60.0629, GNorm = 1.6694, lr_0 = 1.1816e-04
Loss = 5.4256e-04, PNorm = 60.0646, GNorm = 0.7953, lr_0 = 1.1800e-04
Loss = 6.6775e-04, PNorm = 60.0661, GNorm = 1.9694, lr_0 = 1.1785e-04
Loss = 1.0170e-03, PNorm = 60.0682, GNorm = 1.2994, lr_0 = 1.1769e-04
Loss = 1.2905e-03, PNorm = 60.0698, GNorm = 1.1265, lr_0 = 1.1753e-04
Loss = 9.5209e-04, PNorm = 60.0719, GNorm = 1.4644, lr_0 = 1.1737e-04
Loss = 7.8647e-04, PNorm = 60.0743, GNorm = 1.5388, lr_0 = 1.1721e-04
Loss = 1.4989e-03, PNorm = 60.0762, GNorm = 1.8852, lr_0 = 1.1706e-04
Loss = 9.4214e-04, PNorm = 60.0785, GNorm = 1.6787, lr_0 = 1.1690e-04
Loss = 1.1454e-03, PNorm = 60.0801, GNorm = 1.5861, lr_0 = 1.1674e-04
Loss = 9.8476e-04, PNorm = 60.0822, GNorm = 2.1285, lr_0 = 1.1659e-04
Loss = 9.3989e-04, PNorm = 60.0843, GNorm = 1.2039, lr_0 = 1.1643e-04
Loss = 9.7404e-04, PNorm = 60.0864, GNorm = 1.3802, lr_0 = 1.1627e-04
Loss = 7.1766e-04, PNorm = 60.0876, GNorm = 1.0931, lr_0 = 1.1612e-04
Loss = 7.0608e-04, PNorm = 60.0893, GNorm = 1.7706, lr_0 = 1.1596e-04
Loss = 1.2674e-03, PNorm = 60.0911, GNorm = 2.2224, lr_0 = 1.1581e-04
Loss = 8.8912e-04, PNorm = 60.0940, GNorm = 1.3764, lr_0 = 1.1565e-04
Loss = 1.0046e-03, PNorm = 60.0973, GNorm = 1.6687, lr_0 = 1.1550e-04
Loss = 8.0928e-04, PNorm = 60.1007, GNorm = 1.5350, lr_0 = 1.1534e-04
Loss = 6.7862e-04, PNorm = 60.1029, GNorm = 1.7449, lr_0 = 1.1519e-04
Validation rmse = 4.234312
Validation R2 = -4.124684
Epoch 70
Train function
Loss = 5.4065e-04, PNorm = 60.1050, GNorm = 1.1848, lr_0 = 1.1503e-04
Loss = 7.8807e-04, PNorm = 60.1068, GNorm = 1.7890, lr_0 = 1.1488e-04
Loss = 5.1580e-04, PNorm = 60.1082, GNorm = 1.1666, lr_0 = 1.1472e-04
Loss = 1.0703e-03, PNorm = 60.1107, GNorm = 1.0926, lr_0 = 1.1457e-04
Loss = 8.1629e-04, PNorm = 60.1135, GNorm = 1.0275, lr_0 = 1.1442e-04
Loss = 6.9355e-04, PNorm = 60.1152, GNorm = 1.6941, lr_0 = 1.1426e-04
Loss = 7.8044e-04, PNorm = 60.1169, GNorm = 2.4679, lr_0 = 1.1411e-04
Loss = 1.2874e-03, PNorm = 60.1193, GNorm = 1.1751, lr_0 = 1.1396e-04
Loss = 9.4968e-04, PNorm = 60.1210, GNorm = 1.7989, lr_0 = 1.1380e-04
Loss = 8.1865e-04, PNorm = 60.1226, GNorm = 1.5639, lr_0 = 1.1365e-04
Loss = 9.4469e-04, PNorm = 60.1249, GNorm = 1.8355, lr_0 = 1.1350e-04
Loss = 9.4110e-04, PNorm = 60.1268, GNorm = 2.1744, lr_0 = 1.1334e-04
Loss = 5.8950e-04, PNorm = 60.1289, GNorm = 1.6134, lr_0 = 1.1319e-04
Loss = 6.9973e-04, PNorm = 60.1304, GNorm = 1.2321, lr_0 = 1.1304e-04
Loss = 9.5481e-04, PNorm = 60.1315, GNorm = 1.0572, lr_0 = 1.1289e-04
Loss = 1.3328e-03, PNorm = 60.1337, GNorm = 1.2987, lr_0 = 1.1274e-04
Loss = 1.4596e-03, PNorm = 60.1365, GNorm = 1.2850, lr_0 = 1.1259e-04
Loss = 7.2593e-04, PNorm = 60.1393, GNorm = 1.0972, lr_0 = 1.1244e-04
Loss = 6.6057e-04, PNorm = 60.1415, GNorm = 1.2670, lr_0 = 1.1228e-04
Loss = 1.4660e-03, PNorm = 60.1447, GNorm = 1.5479, lr_0 = 1.1213e-04
Loss = 1.4236e-03, PNorm = 60.1477, GNorm = 1.9732, lr_0 = 1.1198e-04
Loss = 9.6618e-04, PNorm = 60.1499, GNorm = 1.7730, lr_0 = 1.1183e-04
Loss = 6.7628e-04, PNorm = 60.1514, GNorm = 1.2251, lr_0 = 1.1168e-04
Validation rmse = 4.259186
Validation R2 = -4.185069
Epoch 71
Train function
Loss = 4.6154e-04, PNorm = 60.1539, GNorm = 1.1733, lr_0 = 1.1152e-04
Loss = 6.1803e-04, PNorm = 60.1560, GNorm = 1.0013, lr_0 = 1.1137e-04
Loss = 5.7575e-04, PNorm = 60.1577, GNorm = 0.9413, lr_0 = 1.1122e-04
Loss = 6.9337e-04, PNorm = 60.1592, GNorm = 1.3093, lr_0 = 1.1107e-04
Loss = 8.7702e-04, PNorm = 60.1615, GNorm = 1.3001, lr_0 = 1.1092e-04
Loss = 5.8544e-04, PNorm = 60.1638, GNorm = 1.7114, lr_0 = 1.1077e-04
Loss = 7.9012e-04, PNorm = 60.1655, GNorm = 1.1630, lr_0 = 1.1062e-04
Loss = 6.7781e-04, PNorm = 60.1674, GNorm = 1.5072, lr_0 = 1.1048e-04
Loss = 1.1927e-03, PNorm = 60.1694, GNorm = 0.7480, lr_0 = 1.1033e-04
Loss = 6.8789e-04, PNorm = 60.1704, GNorm = 1.5417, lr_0 = 1.1018e-04
Loss = 1.0657e-03, PNorm = 60.1721, GNorm = 1.9656, lr_0 = 1.1003e-04
Loss = 7.9818e-04, PNorm = 60.1741, GNorm = 1.2537, lr_0 = 1.0988e-04
Loss = 7.2740e-04, PNorm = 60.1757, GNorm = 1.7330, lr_0 = 1.0974e-04
Loss = 1.2890e-03, PNorm = 60.1778, GNorm = 1.0295, lr_0 = 1.0959e-04
Loss = 1.0334e-03, PNorm = 60.1796, GNorm = 1.5877, lr_0 = 1.0944e-04
Loss = 1.4934e-03, PNorm = 60.1806, GNorm = 0.9246, lr_0 = 1.0930e-04
Loss = 9.6669e-04, PNorm = 60.1824, GNorm = 3.1997, lr_0 = 1.0915e-04
Loss = 8.3781e-04, PNorm = 60.1840, GNorm = 1.6208, lr_0 = 1.0900e-04
Loss = 7.5535e-04, PNorm = 60.1853, GNorm = 1.5333, lr_0 = 1.0886e-04
Loss = 1.0692e-03, PNorm = 60.1875, GNorm = 2.4364, lr_0 = 1.0871e-04
Loss = 8.2363e-04, PNorm = 60.1905, GNorm = 1.8919, lr_0 = 1.0856e-04
Loss = 8.4953e-04, PNorm = 60.1930, GNorm = 1.1218, lr_0 = 1.0842e-04
Loss = 8.6792e-04, PNorm = 60.1949, GNorm = 1.1279, lr_0 = 1.0827e-04
Loss = 1.0618e-03, PNorm = 60.1975, GNorm = 0.8017, lr_0 = 1.0813e-04
Validation rmse = 4.246779
Validation R2 = -4.154905
Epoch 72
Train function
Loss = 1.2532e-03, PNorm = 60.2000, GNorm = 1.4143, lr_0 = 1.0797e-04
Loss = 7.9321e-04, PNorm = 60.2023, GNorm = 0.9681, lr_0 = 1.0782e-04
Loss = 8.7549e-04, PNorm = 60.2038, GNorm = 1.5292, lr_0 = 1.0768e-04
Loss = 1.1626e-03, PNorm = 60.2055, GNorm = 1.6764, lr_0 = 1.0753e-04
Loss = 8.7563e-04, PNorm = 60.2076, GNorm = 1.5127, lr_0 = 1.0739e-04
Loss = 1.1666e-03, PNorm = 60.2100, GNorm = 1.4214, lr_0 = 1.0725e-04
Loss = 7.7703e-04, PNorm = 60.2119, GNorm = 1.1379, lr_0 = 1.0710e-04
Loss = 1.1644e-03, PNorm = 60.2135, GNorm = 2.2352, lr_0 = 1.0696e-04
Loss = 7.7514e-04, PNorm = 60.2156, GNorm = 1.9155, lr_0 = 1.0681e-04
Loss = 5.9952e-04, PNorm = 60.2168, GNorm = 2.6095, lr_0 = 1.0667e-04
Loss = 1.2743e-03, PNorm = 60.2183, GNorm = 1.1044, lr_0 = 1.0653e-04
Loss = 5.9358e-04, PNorm = 60.2205, GNorm = 1.9829, lr_0 = 1.0639e-04
Loss = 9.9038e-04, PNorm = 60.2220, GNorm = 1.0776, lr_0 = 1.0624e-04
Loss = 9.0894e-04, PNorm = 60.2237, GNorm = 1.3320, lr_0 = 1.0610e-04
Loss = 9.9530e-04, PNorm = 60.2267, GNorm = 1.1155, lr_0 = 1.0596e-04
Loss = 7.4989e-04, PNorm = 60.2285, GNorm = 1.8310, lr_0 = 1.0582e-04
Loss = 8.8483e-04, PNorm = 60.2315, GNorm = 1.0564, lr_0 = 1.0567e-04
Loss = 6.3329e-04, PNorm = 60.2337, GNorm = 1.0697, lr_0 = 1.0553e-04
Loss = 1.0322e-03, PNorm = 60.2356, GNorm = 1.0738, lr_0 = 1.0539e-04
Loss = 6.5969e-04, PNorm = 60.2366, GNorm = 2.0508, lr_0 = 1.0525e-04
Loss = 7.9228e-04, PNorm = 60.2380, GNorm = 2.1350, lr_0 = 1.0511e-04
Loss = 7.6340e-04, PNorm = 60.2397, GNorm = 0.8845, lr_0 = 1.0497e-04
Loss = 9.8182e-04, PNorm = 60.2415, GNorm = 1.2650, lr_0 = 1.0483e-04
Validation rmse = 4.052946
Validation R2 = -3.695081
Epoch 73
Train function
Loss = 8.7028e-04, PNorm = 60.2444, GNorm = 1.3977, lr_0 = 1.0467e-04
Loss = 8.1912e-04, PNorm = 60.2461, GNorm = 1.8798, lr_0 = 1.0453e-04
Loss = 6.0006e-04, PNorm = 60.2479, GNorm = 1.0188, lr_0 = 1.0439e-04
Loss = 7.8493e-04, PNorm = 60.2499, GNorm = 1.0935, lr_0 = 1.0425e-04
Loss = 5.6820e-04, PNorm = 60.2523, GNorm = 1.0419, lr_0 = 1.0411e-04
Loss = 4.9281e-04, PNorm = 60.2545, GNorm = 1.2060, lr_0 = 1.0397e-04
Loss = 1.0183e-03, PNorm = 60.2563, GNorm = 3.6988, lr_0 = 1.0383e-04
Loss = 6.8678e-04, PNorm = 60.2568, GNorm = 0.9443, lr_0 = 1.0369e-04
Loss = 1.0515e-03, PNorm = 60.2581, GNorm = 0.9710, lr_0 = 1.0355e-04
Loss = 7.9199e-04, PNorm = 60.2600, GNorm = 1.2938, lr_0 = 1.0341e-04
Loss = 8.9077e-04, PNorm = 60.2621, GNorm = 1.0165, lr_0 = 1.0327e-04
Loss = 7.4779e-04, PNorm = 60.2639, GNorm = 1.2479, lr_0 = 1.0314e-04
Loss = 1.2735e-03, PNorm = 60.2661, GNorm = 0.7217, lr_0 = 1.0300e-04
Loss = 8.3605e-04, PNorm = 60.2673, GNorm = 1.7561, lr_0 = 1.0286e-04
Loss = 8.8253e-04, PNorm = 60.2697, GNorm = 1.2552, lr_0 = 1.0272e-04
Loss = 9.4441e-04, PNorm = 60.2717, GNorm = 1.5622, lr_0 = 1.0258e-04
Loss = 7.1316e-04, PNorm = 60.2734, GNorm = 2.1349, lr_0 = 1.0245e-04
Loss = 7.7343e-04, PNorm = 60.2754, GNorm = 3.0746, lr_0 = 1.0231e-04
Loss = 7.6179e-04, PNorm = 60.2775, GNorm = 2.0047, lr_0 = 1.0217e-04
Loss = 1.2571e-03, PNorm = 60.2792, GNorm = 0.8299, lr_0 = 1.0203e-04
Loss = 6.2972e-04, PNorm = 60.2813, GNorm = 0.9666, lr_0 = 1.0190e-04
Loss = 9.4114e-04, PNorm = 60.2832, GNorm = 1.8321, lr_0 = 1.0176e-04
Loss = 6.3096e-04, PNorm = 60.2852, GNorm = 1.5758, lr_0 = 1.0162e-04
Loss = 7.3775e-04, PNorm = 60.2869, GNorm = 1.4400, lr_0 = 1.0149e-04
Loss = 1.9655e-03, PNorm = 60.2870, GNorm = 2.3988, lr_0 = 1.0147e-04
Validation rmse = 4.163625
Validation R2 = -3.955010
Epoch 74
Train function
Loss = 5.1165e-04, PNorm = 60.2888, GNorm = 1.4864, lr_0 = 1.0134e-04
Loss = 1.0106e-03, PNorm = 60.2908, GNorm = 1.2696, lr_0 = 1.0120e-04
Loss = 9.0455e-04, PNorm = 60.2932, GNorm = 1.8779, lr_0 = 1.0107e-04
Loss = 1.1094e-03, PNorm = 60.2949, GNorm = 0.8394, lr_0 = 1.0093e-04
Loss = 6.3377e-04, PNorm = 60.2959, GNorm = 1.2807, lr_0 = 1.0080e-04
Loss = 6.3447e-04, PNorm = 60.2973, GNorm = 1.2326, lr_0 = 1.0066e-04
Loss = 4.9880e-04, PNorm = 60.2998, GNorm = 1.1333, lr_0 = 1.0052e-04
Loss = 8.8880e-04, PNorm = 60.3015, GNorm = 3.6155, lr_0 = 1.0039e-04
Loss = 1.0858e-03, PNorm = 60.3042, GNorm = 1.7054, lr_0 = 1.0026e-04
Loss = 9.3332e-04, PNorm = 60.3068, GNorm = 1.8649, lr_0 = 1.0012e-04
Loss = 7.2270e-04, PNorm = 60.3088, GNorm = 1.8250, lr_0 = 1.0000e-04
Loss = 1.0094e-03, PNorm = 60.3105, GNorm = 1.4886, lr_0 = 1.0000e-04
Loss = 6.2240e-04, PNorm = 60.3110, GNorm = 1.5681, lr_0 = 1.0000e-04
Loss = 8.0294e-04, PNorm = 60.3120, GNorm = 1.2324, lr_0 = 1.0000e-04
Loss = 7.6276e-04, PNorm = 60.3126, GNorm = 1.0017, lr_0 = 1.0000e-04
Loss = 1.1103e-03, PNorm = 60.3138, GNorm = 1.6180, lr_0 = 1.0000e-04
Loss = 6.5749e-04, PNorm = 60.3156, GNorm = 1.0924, lr_0 = 1.0000e-04
Loss = 7.7296e-04, PNorm = 60.3176, GNorm = 0.9226, lr_0 = 1.0000e-04
Loss = 9.6563e-04, PNorm = 60.3200, GNorm = 1.9443, lr_0 = 1.0000e-04
Loss = 8.4782e-04, PNorm = 60.3219, GNorm = 2.0908, lr_0 = 1.0000e-04
Loss = 7.5153e-04, PNorm = 60.3241, GNorm = 0.8164, lr_0 = 1.0000e-04
Loss = 6.1256e-04, PNorm = 60.3256, GNorm = 1.1731, lr_0 = 1.0000e-04
Loss = 6.9614e-04, PNorm = 60.3270, GNorm = 1.1778, lr_0 = 1.0000e-04
Validation rmse = 4.243630
Validation R2 = -4.147262
Epoch 75
Train function
Loss = 7.4553e-04, PNorm = 60.3293, GNorm = 0.7928, lr_0 = 1.0000e-04
Loss = 6.2569e-04, PNorm = 60.3311, GNorm = 1.1333, lr_0 = 1.0000e-04
Loss = 7.1680e-04, PNorm = 60.3326, GNorm = 1.4542, lr_0 = 1.0000e-04
Loss = 6.2486e-04, PNorm = 60.3342, GNorm = 1.5993, lr_0 = 1.0000e-04
Loss = 5.6442e-04, PNorm = 60.3350, GNorm = 2.0738, lr_0 = 1.0000e-04
Loss = 4.0972e-04, PNorm = 60.3358, GNorm = 0.9520, lr_0 = 1.0000e-04
Loss = 6.9058e-04, PNorm = 60.3369, GNorm = 1.9643, lr_0 = 1.0000e-04
Loss = 9.2543e-04, PNorm = 60.3381, GNorm = 2.2107, lr_0 = 1.0000e-04
Loss = 9.9243e-04, PNorm = 60.3393, GNorm = 2.1731, lr_0 = 1.0000e-04
Loss = 6.5864e-04, PNorm = 60.3402, GNorm = 1.4234, lr_0 = 1.0000e-04
Loss = 5.9022e-04, PNorm = 60.3417, GNorm = 1.0873, lr_0 = 1.0000e-04
Loss = 4.3487e-04, PNorm = 60.3429, GNorm = 0.7485, lr_0 = 1.0000e-04
Loss = 6.4608e-04, PNorm = 60.3446, GNorm = 0.7822, lr_0 = 1.0000e-04
Loss = 7.3648e-04, PNorm = 60.3469, GNorm = 2.4146, lr_0 = 1.0000e-04
Loss = 1.3679e-03, PNorm = 60.3492, GNorm = 0.9994, lr_0 = 1.0000e-04
Loss = 5.9972e-04, PNorm = 60.3512, GNorm = 1.2318, lr_0 = 1.0000e-04
Loss = 9.3497e-04, PNorm = 60.3525, GNorm = 2.1634, lr_0 = 1.0000e-04
Loss = 1.2992e-03, PNorm = 60.3538, GNorm = 1.2923, lr_0 = 1.0000e-04
Loss = 6.9574e-04, PNorm = 60.3558, GNorm = 1.4670, lr_0 = 1.0000e-04
Loss = 7.7628e-04, PNorm = 60.3576, GNorm = 0.6884, lr_0 = 1.0000e-04
Loss = 6.7811e-04, PNorm = 60.3595, GNorm = 0.8383, lr_0 = 1.0000e-04
Loss = 8.8067e-04, PNorm = 60.3625, GNorm = 1.6080, lr_0 = 1.0000e-04
Loss = 5.3120e-04, PNorm = 60.3652, GNorm = 1.4451, lr_0 = 1.0000e-04
Validation rmse = 4.130965
Validation R2 = -3.877580
Epoch 76
Train function
Loss = 2.6306e-04, PNorm = 60.3672, GNorm = 0.8771, lr_0 = 1.0000e-04
Loss = 4.6927e-04, PNorm = 60.3691, GNorm = 1.0273, lr_0 = 1.0000e-04
Loss = 8.3953e-04, PNorm = 60.3704, GNorm = 1.5277, lr_0 = 1.0000e-04
Loss = 8.9472e-04, PNorm = 60.3717, GNorm = 1.8918, lr_0 = 1.0000e-04
Loss = 5.4418e-04, PNorm = 60.3735, GNorm = 1.8677, lr_0 = 1.0000e-04
Loss = 5.3506e-04, PNorm = 60.3750, GNorm = 1.3041, lr_0 = 1.0000e-04
Loss = 6.6476e-04, PNorm = 60.3759, GNorm = 1.4742, lr_0 = 1.0000e-04
Loss = 5.1691e-04, PNorm = 60.3770, GNorm = 1.1367, lr_0 = 1.0000e-04
Loss = 7.0687e-04, PNorm = 60.3778, GNorm = 2.6911, lr_0 = 1.0000e-04
Loss = 5.7637e-04, PNorm = 60.3788, GNorm = 1.2953, lr_0 = 1.0000e-04
Loss = 5.8551e-04, PNorm = 60.3806, GNorm = 2.8597, lr_0 = 1.0000e-04
Loss = 9.9910e-04, PNorm = 60.3825, GNorm = 2.4637, lr_0 = 1.0000e-04
Loss = 7.1257e-04, PNorm = 60.3845, GNorm = 1.8258, lr_0 = 1.0000e-04
Loss = 5.8826e-04, PNorm = 60.3866, GNorm = 0.7018, lr_0 = 1.0000e-04
Loss = 1.4638e-03, PNorm = 60.3880, GNorm = 0.7037, lr_0 = 1.0000e-04
Loss = 7.2549e-04, PNorm = 60.3895, GNorm = 1.3843, lr_0 = 1.0000e-04
Loss = 1.1085e-03, PNorm = 60.3908, GNorm = 1.8392, lr_0 = 1.0000e-04
Loss = 1.0313e-03, PNorm = 60.3934, GNorm = 1.6982, lr_0 = 1.0000e-04
Loss = 5.6789e-04, PNorm = 60.3955, GNorm = 0.9292, lr_0 = 1.0000e-04
Loss = 7.4368e-04, PNorm = 60.3969, GNorm = 1.9142, lr_0 = 1.0000e-04
Loss = 6.6582e-04, PNorm = 60.3981, GNorm = 2.1473, lr_0 = 1.0000e-04
Loss = 7.5212e-04, PNorm = 60.3994, GNorm = 1.5939, lr_0 = 1.0000e-04
Loss = 7.8586e-04, PNorm = 60.4012, GNorm = 1.1886, lr_0 = 1.0000e-04
Loss = 8.0605e-04, PNorm = 60.4033, GNorm = 1.1451, lr_0 = 1.0000e-04
Validation rmse = 4.215734
Validation R2 = -4.079813
Epoch 77
Train function
Loss = 3.9383e-04, PNorm = 60.4050, GNorm = 1.4569, lr_0 = 1.0000e-04
Loss = 5.4145e-04, PNorm = 60.4064, GNorm = 1.2259, lr_0 = 1.0000e-04
Loss = 6.4388e-04, PNorm = 60.4083, GNorm = 1.8885, lr_0 = 1.0000e-04
Loss = 5.0673e-04, PNorm = 60.4098, GNorm = 1.8343, lr_0 = 1.0000e-04
Loss = 1.2915e-03, PNorm = 60.4118, GNorm = 4.0738, lr_0 = 1.0000e-04
Loss = 7.3546e-04, PNorm = 60.4145, GNorm = 1.3758, lr_0 = 1.0000e-04
Loss = 6.4998e-04, PNorm = 60.4167, GNorm = 1.7611, lr_0 = 1.0000e-04
Loss = 4.5869e-04, PNorm = 60.4184, GNorm = 1.0285, lr_0 = 1.0000e-04
Loss = 6.3517e-04, PNorm = 60.4200, GNorm = 1.3011, lr_0 = 1.0000e-04
Loss = 7.2102e-04, PNorm = 60.4215, GNorm = 1.0619, lr_0 = 1.0000e-04
Loss = 5.4057e-04, PNorm = 60.4234, GNorm = 0.9726, lr_0 = 1.0000e-04
Loss = 7.8716e-04, PNorm = 60.4251, GNorm = 0.7126, lr_0 = 1.0000e-04
Loss = 8.0667e-04, PNorm = 60.4264, GNorm = 1.4968, lr_0 = 1.0000e-04
Loss = 6.9756e-04, PNorm = 60.4276, GNorm = 1.1847, lr_0 = 1.0000e-04
Loss = 7.7544e-04, PNorm = 60.4302, GNorm = 1.7821, lr_0 = 1.0000e-04
Loss = 1.2521e-03, PNorm = 60.4322, GNorm = 1.6380, lr_0 = 1.0000e-04
Loss = 8.3043e-04, PNorm = 60.4337, GNorm = 2.0752, lr_0 = 1.0000e-04
Loss = 5.8324e-04, PNorm = 60.4353, GNorm = 1.8930, lr_0 = 1.0000e-04
Loss = 7.7274e-04, PNorm = 60.4368, GNorm = 1.4540, lr_0 = 1.0000e-04
Loss = 4.2614e-04, PNorm = 60.4385, GNorm = 0.8483, lr_0 = 1.0000e-04
Loss = 7.4382e-04, PNorm = 60.4405, GNorm = 1.1622, lr_0 = 1.0000e-04
Loss = 1.0984e-03, PNorm = 60.4424, GNorm = 1.3481, lr_0 = 1.0000e-04
Loss = 7.0772e-04, PNorm = 60.4443, GNorm = 1.1514, lr_0 = 1.0000e-04
Validation rmse = 4.126270
Validation R2 = -3.866500
Epoch 78
Train function
Loss = 7.6164e-04, PNorm = 60.4463, GNorm = 2.4358, lr_0 = 1.0000e-04
Loss = 6.0227e-04, PNorm = 60.4479, GNorm = 1.6230, lr_0 = 1.0000e-04
Loss = 5.2342e-04, PNorm = 60.4491, GNorm = 1.1151, lr_0 = 1.0000e-04
Loss = 6.7705e-04, PNorm = 60.4503, GNorm = 0.8390, lr_0 = 1.0000e-04
Loss = 8.3624e-04, PNorm = 60.4523, GNorm = 0.8573, lr_0 = 1.0000e-04
Loss = 8.5515e-04, PNorm = 60.4544, GNorm = 1.2474, lr_0 = 1.0000e-04
Loss = 7.7585e-04, PNorm = 60.4563, GNorm = 2.7742, lr_0 = 1.0000e-04
Loss = 4.2929e-04, PNorm = 60.4584, GNorm = 1.2199, lr_0 = 1.0000e-04
Loss = 3.5088e-04, PNorm = 60.4599, GNorm = 0.9224, lr_0 = 1.0000e-04
Loss = 6.6772e-04, PNorm = 60.4616, GNorm = 2.2209, lr_0 = 1.0000e-04
Loss = 9.4169e-04, PNorm = 60.4632, GNorm = 0.7962, lr_0 = 1.0000e-04
Loss = 1.0628e-03, PNorm = 60.4643, GNorm = 1.1765, lr_0 = 1.0000e-04
Loss = 1.1994e-03, PNorm = 60.4661, GNorm = 0.8579, lr_0 = 1.0000e-04
Loss = 1.3670e-03, PNorm = 60.4681, GNorm = 3.0159, lr_0 = 1.0000e-04
Loss = 8.8101e-04, PNorm = 60.4706, GNorm = 1.5314, lr_0 = 1.0000e-04
Loss = 6.9441e-04, PNorm = 60.4727, GNorm = 1.0121, lr_0 = 1.0000e-04
Loss = 6.7196e-04, PNorm = 60.4749, GNorm = 1.8511, lr_0 = 1.0000e-04
Loss = 7.4812e-04, PNorm = 60.4774, GNorm = 1.4345, lr_0 = 1.0000e-04
Loss = 5.7898e-04, PNorm = 60.4793, GNorm = 0.9558, lr_0 = 1.0000e-04
Loss = 8.7470e-04, PNorm = 60.4809, GNorm = 1.0944, lr_0 = 1.0000e-04
Loss = 5.4075e-04, PNorm = 60.4823, GNorm = 1.5409, lr_0 = 1.0000e-04
Loss = 8.2766e-04, PNorm = 60.4833, GNorm = 0.8749, lr_0 = 1.0000e-04
Loss = 5.0597e-04, PNorm = 60.4843, GNorm = 1.6249, lr_0 = 1.0000e-04
Loss = 8.0189e-04, PNorm = 60.4860, GNorm = 1.3323, lr_0 = 1.0000e-04
Validation rmse = 4.193350
Validation R2 = -4.026013
Epoch 79
Train function
Loss = 5.9006e-04, PNorm = 60.4884, GNorm = 1.2061, lr_0 = 1.0000e-04
Loss = 5.5083e-04, PNorm = 60.4902, GNorm = 2.4765, lr_0 = 1.0000e-04
Loss = 5.3590e-04, PNorm = 60.4924, GNorm = 0.9453, lr_0 = 1.0000e-04
Loss = 6.4492e-04, PNorm = 60.4943, GNorm = 0.7765, lr_0 = 1.0000e-04
Loss = 7.1122e-04, PNorm = 60.4956, GNorm = 1.2616, lr_0 = 1.0000e-04
Loss = 6.3806e-04, PNorm = 60.4972, GNorm = 2.2121, lr_0 = 1.0000e-04
Loss = 6.2568e-04, PNorm = 60.4986, GNorm = 2.1879, lr_0 = 1.0000e-04
Loss = 4.5972e-04, PNorm = 60.4996, GNorm = 1.2566, lr_0 = 1.0000e-04
Loss = 8.2981e-04, PNorm = 60.5009, GNorm = 3.2185, lr_0 = 1.0000e-04
Loss = 4.4799e-04, PNorm = 60.5021, GNorm = 1.6911, lr_0 = 1.0000e-04
Loss = 6.1922e-04, PNorm = 60.5041, GNorm = 0.6410, lr_0 = 1.0000e-04
Loss = 6.9712e-04, PNorm = 60.5055, GNorm = 1.3898, lr_0 = 1.0000e-04
Loss = 6.7793e-04, PNorm = 60.5072, GNorm = 0.9130, lr_0 = 1.0000e-04
Loss = 1.1032e-03, PNorm = 60.5085, GNorm = 1.3883, lr_0 = 1.0000e-04
Loss = 7.7355e-04, PNorm = 60.5105, GNorm = 1.1537, lr_0 = 1.0000e-04
Loss = 8.0882e-04, PNorm = 60.5119, GNorm = 1.3756, lr_0 = 1.0000e-04
Loss = 9.1782e-04, PNorm = 60.5134, GNorm = 1.0603, lr_0 = 1.0000e-04
Loss = 4.8690e-04, PNorm = 60.5153, GNorm = 1.1904, lr_0 = 1.0000e-04
Loss = 1.2625e-03, PNorm = 60.5172, GNorm = 1.6383, lr_0 = 1.0000e-04
Loss = 6.0645e-04, PNorm = 60.5189, GNorm = 1.7276, lr_0 = 1.0000e-04
Loss = 8.4528e-04, PNorm = 60.5199, GNorm = 2.4882, lr_0 = 1.0000e-04
Loss = 5.0246e-04, PNorm = 60.5213, GNorm = 1.4457, lr_0 = 1.0000e-04
Loss = 8.2304e-04, PNorm = 60.5229, GNorm = 0.6485, lr_0 = 1.0000e-04
Validation rmse = 4.308436
Validation R2 = -4.305676
Epoch 80
Train function
Loss = 9.5937e-04, PNorm = 60.5239, GNorm = 1.7211, lr_0 = 1.0000e-04
Loss = 4.1432e-04, PNorm = 60.5257, GNorm = 0.9976, lr_0 = 1.0000e-04
Loss = 7.1235e-04, PNorm = 60.5276, GNorm = 0.9619, lr_0 = 1.0000e-04
Loss = 5.3181e-04, PNorm = 60.5290, GNorm = 1.7427, lr_0 = 1.0000e-04
Loss = 4.6218e-04, PNorm = 60.5299, GNorm = 0.8507, lr_0 = 1.0000e-04
Loss = 3.7756e-04, PNorm = 60.5314, GNorm = 1.0112, lr_0 = 1.0000e-04
Loss = 1.1563e-03, PNorm = 60.5333, GNorm = 1.0993, lr_0 = 1.0000e-04
Loss = 7.6912e-04, PNorm = 60.5354, GNorm = 2.7049, lr_0 = 1.0000e-04
Loss = 5.2474e-04, PNorm = 60.5367, GNorm = 0.7935, lr_0 = 1.0000e-04
Loss = 1.1855e-03, PNorm = 60.5382, GNorm = 0.8532, lr_0 = 1.0000e-04
Loss = 7.5303e-04, PNorm = 60.5398, GNorm = 1.0250, lr_0 = 1.0000e-04
Loss = 7.3075e-04, PNorm = 60.5411, GNorm = 1.0367, lr_0 = 1.0000e-04
Loss = 6.9246e-04, PNorm = 60.5436, GNorm = 1.8353, lr_0 = 1.0000e-04
Loss = 4.1007e-04, PNorm = 60.5456, GNorm = 0.9303, lr_0 = 1.0000e-04
Loss = 9.5615e-04, PNorm = 60.5466, GNorm = 1.4210, lr_0 = 1.0000e-04
Loss = 4.9574e-04, PNorm = 60.5478, GNorm = 1.4527, lr_0 = 1.0000e-04
Loss = 5.4185e-04, PNorm = 60.5488, GNorm = 1.7967, lr_0 = 1.0000e-04
Loss = 6.0201e-04, PNorm = 60.5497, GNorm = 1.2745, lr_0 = 1.0000e-04
Loss = 5.5070e-04, PNorm = 60.5515, GNorm = 1.5273, lr_0 = 1.0000e-04
Loss = 7.2615e-04, PNorm = 60.5536, GNorm = 2.5230, lr_0 = 1.0000e-04
Loss = 8.4306e-04, PNorm = 60.5554, GNorm = 1.3347, lr_0 = 1.0000e-04
Loss = 7.6510e-04, PNorm = 60.5575, GNorm = 1.8784, lr_0 = 1.0000e-04
Loss = 5.5980e-04, PNorm = 60.5598, GNorm = 1.6150, lr_0 = 1.0000e-04
Loss = 4.2483e-04, PNorm = 60.5609, GNorm = 0.9554, lr_0 = 1.0000e-04
Loss = 1.4605e-03, PNorm = 60.5611, GNorm = 1.8075, lr_0 = 1.0000e-04
Validation rmse = 4.291982
Validation R2 = -4.265226
Epoch 81
Train function
Loss = 7.5638e-04, PNorm = 60.5636, GNorm = 1.2869, lr_0 = 1.0000e-04
Loss = 3.8901e-04, PNorm = 60.5655, GNorm = 1.4179, lr_0 = 1.0000e-04
Loss = 5.9985e-04, PNorm = 60.5674, GNorm = 0.7631, lr_0 = 1.0000e-04
Loss = 6.8387e-04, PNorm = 60.5687, GNorm = 1.6640, lr_0 = 1.0000e-04
Loss = 6.2080e-04, PNorm = 60.5696, GNorm = 1.5322, lr_0 = 1.0000e-04
Loss = 6.6214e-04, PNorm = 60.5711, GNorm = 2.0994, lr_0 = 1.0000e-04
Loss = 6.3229e-04, PNorm = 60.5721, GNorm = 0.5926, lr_0 = 1.0000e-04
Loss = 8.1726e-04, PNorm = 60.5738, GNorm = 1.3549, lr_0 = 1.0000e-04
Loss = 5.9329e-04, PNorm = 60.5754, GNorm = 2.8960, lr_0 = 1.0000e-04
Loss = 5.5186e-04, PNorm = 60.5766, GNorm = 1.7161, lr_0 = 1.0000e-04
Loss = 5.5991e-04, PNorm = 60.5781, GNorm = 0.9426, lr_0 = 1.0000e-04
Loss = 3.1210e-04, PNorm = 60.5793, GNorm = 1.1159, lr_0 = 1.0000e-04
Loss = 9.1498e-04, PNorm = 60.5804, GNorm = 1.1527, lr_0 = 1.0000e-04
Loss = 6.2012e-04, PNorm = 60.5818, GNorm = 0.7410, lr_0 = 1.0000e-04
Loss = 5.6868e-04, PNorm = 60.5833, GNorm = 0.9626, lr_0 = 1.0000e-04
Loss = 6.7256e-04, PNorm = 60.5847, GNorm = 1.4097, lr_0 = 1.0000e-04
Loss = 7.7044e-04, PNorm = 60.5869, GNorm = 0.9260, lr_0 = 1.0000e-04
Loss = 6.3706e-04, PNorm = 60.5889, GNorm = 2.5947, lr_0 = 1.0000e-04
Loss = 6.0080e-04, PNorm = 60.5908, GNorm = 1.3074, lr_0 = 1.0000e-04
Loss = 6.2005e-04, PNorm = 60.5918, GNorm = 1.5119, lr_0 = 1.0000e-04
Loss = 5.0122e-04, PNorm = 60.5941, GNorm = 1.1646, lr_0 = 1.0000e-04
Loss = 3.9945e-04, PNorm = 60.5963, GNorm = 1.0208, lr_0 = 1.0000e-04
Loss = 5.0945e-04, PNorm = 60.5979, GNorm = 1.2954, lr_0 = 1.0000e-04
Validation rmse = 4.300140
Validation R2 = -4.285262
Epoch 82
Train function
Loss = 5.0996e-04, PNorm = 60.5996, GNorm = 1.2436, lr_0 = 1.0000e-04
Loss = 4.8308e-04, PNorm = 60.6013, GNorm = 1.2111, lr_0 = 1.0000e-04
Loss = 4.5775e-04, PNorm = 60.6017, GNorm = 0.9463, lr_0 = 1.0000e-04
Loss = 4.5810e-04, PNorm = 60.6027, GNorm = 0.6539, lr_0 = 1.0000e-04
Loss = 7.2947e-04, PNorm = 60.6040, GNorm = 0.9250, lr_0 = 1.0000e-04
Loss = 7.1162e-04, PNorm = 60.6054, GNorm = 1.6093, lr_0 = 1.0000e-04
Loss = 1.0111e-03, PNorm = 60.6067, GNorm = 2.0515, lr_0 = 1.0000e-04
Loss = 4.5010e-04, PNorm = 60.6081, GNorm = 0.5546, lr_0 = 1.0000e-04
Loss = 1.0602e-03, PNorm = 60.6096, GNorm = 1.4662, lr_0 = 1.0000e-04
Loss = 5.5849e-04, PNorm = 60.6119, GNorm = 1.0714, lr_0 = 1.0000e-04
Loss = 4.6957e-04, PNorm = 60.6132, GNorm = 0.9768, lr_0 = 1.0000e-04
Loss = 7.1736e-04, PNorm = 60.6143, GNorm = 1.8972, lr_0 = 1.0000e-04
Loss = 4.6826e-04, PNorm = 60.6151, GNorm = 1.2945, lr_0 = 1.0000e-04
Loss = 5.0236e-04, PNorm = 60.6166, GNorm = 0.8734, lr_0 = 1.0000e-04
Loss = 1.1996e-03, PNorm = 60.6179, GNorm = 3.0448, lr_0 = 1.0000e-04
Loss = 5.9636e-04, PNorm = 60.6189, GNorm = 1.9596, lr_0 = 1.0000e-04
Loss = 7.5500e-04, PNorm = 60.6213, GNorm = 0.7030, lr_0 = 1.0000e-04
Loss = 5.4643e-04, PNorm = 60.6238, GNorm = 1.3686, lr_0 = 1.0000e-04
Loss = 5.1921e-04, PNorm = 60.6261, GNorm = 1.0271, lr_0 = 1.0000e-04
Loss = 5.6574e-04, PNorm = 60.6282, GNorm = 1.0541, lr_0 = 1.0000e-04
Loss = 5.9638e-04, PNorm = 60.6302, GNorm = 1.8713, lr_0 = 1.0000e-04
Loss = 4.7384e-04, PNorm = 60.6326, GNorm = 2.0869, lr_0 = 1.0000e-04
Loss = 9.4187e-04, PNorm = 60.6342, GNorm = 0.9162, lr_0 = 1.0000e-04
Validation rmse = 4.226722
Validation R2 = -4.106329
Epoch 83
Train function
Loss = 2.8919e-04, PNorm = 60.6358, GNorm = 0.7933, lr_0 = 1.0000e-04
Loss = 1.1082e-03, PNorm = 60.6364, GNorm = 0.5965, lr_0 = 1.0000e-04
Loss = 3.6402e-04, PNorm = 60.6378, GNorm = 1.2481, lr_0 = 1.0000e-04
Loss = 3.8288e-04, PNorm = 60.6390, GNorm = 1.4326, lr_0 = 1.0000e-04
Loss = 7.8595e-04, PNorm = 60.6399, GNorm = 1.7710, lr_0 = 1.0000e-04
Loss = 4.6325e-04, PNorm = 60.6406, GNorm = 1.4614, lr_0 = 1.0000e-04
Loss = 5.9215e-04, PNorm = 60.6423, GNorm = 1.1784, lr_0 = 1.0000e-04
Loss = 5.7478e-04, PNorm = 60.6443, GNorm = 1.2456, lr_0 = 1.0000e-04
Loss = 4.1656e-04, PNorm = 60.6467, GNorm = 0.9830, lr_0 = 1.0000e-04
Loss = 4.4688e-04, PNorm = 60.6483, GNorm = 1.0216, lr_0 = 1.0000e-04
Loss = 4.2495e-04, PNorm = 60.6493, GNorm = 1.1037, lr_0 = 1.0000e-04
Loss = 4.6537e-04, PNorm = 60.6508, GNorm = 0.8312, lr_0 = 1.0000e-04
Loss = 5.1766e-04, PNorm = 60.6523, GNorm = 1.7031, lr_0 = 1.0000e-04
Loss = 8.2585e-04, PNorm = 60.6544, GNorm = 1.4202, lr_0 = 1.0000e-04
Loss = 1.0563e-03, PNorm = 60.6569, GNorm = 1.3102, lr_0 = 1.0000e-04
Loss = 7.2435e-04, PNorm = 60.6587, GNorm = 1.2342, lr_0 = 1.0000e-04
Loss = 6.0304e-04, PNorm = 60.6596, GNorm = 2.6321, lr_0 = 1.0000e-04
Loss = 6.8087e-04, PNorm = 60.6606, GNorm = 0.8513, lr_0 = 1.0000e-04
Loss = 6.0239e-04, PNorm = 60.6614, GNorm = 1.4627, lr_0 = 1.0000e-04
Loss = 9.2924e-04, PNorm = 60.6631, GNorm = 1.1440, lr_0 = 1.0000e-04
Loss = 4.3399e-04, PNorm = 60.6648, GNorm = 1.5403, lr_0 = 1.0000e-04
Loss = 7.3764e-04, PNorm = 60.6662, GNorm = 0.9897, lr_0 = 1.0000e-04
Loss = 7.0912e-04, PNorm = 60.6679, GNorm = 2.2413, lr_0 = 1.0000e-04
Loss = 6.6251e-04, PNorm = 60.6694, GNorm = 1.4037, lr_0 = 1.0000e-04
Validation rmse = 4.159202
Validation R2 = -3.944488
Epoch 84
Train function
Loss = 5.7088e-04, PNorm = 60.6714, GNorm = 0.6328, lr_0 = 1.0000e-04
Loss = 6.6671e-04, PNorm = 60.6735, GNorm = 0.7008, lr_0 = 1.0000e-04
Loss = 4.7307e-04, PNorm = 60.6755, GNorm = 1.9997, lr_0 = 1.0000e-04
Loss = 4.5086e-04, PNorm = 60.6775, GNorm = 0.8524, lr_0 = 1.0000e-04
Loss = 4.5531e-04, PNorm = 60.6783, GNorm = 0.7995, lr_0 = 1.0000e-04
Loss = 6.1780e-04, PNorm = 60.6801, GNorm = 1.4843, lr_0 = 1.0000e-04
Loss = 5.0199e-04, PNorm = 60.6810, GNorm = 0.7802, lr_0 = 1.0000e-04
Loss = 3.8293e-04, PNorm = 60.6825, GNorm = 0.7817, lr_0 = 1.0000e-04
Loss = 7.0892e-04, PNorm = 60.6841, GNorm = 0.6261, lr_0 = 1.0000e-04
Loss = 3.6244e-04, PNorm = 60.6855, GNorm = 1.0294, lr_0 = 1.0000e-04
Loss = 7.9828e-04, PNorm = 60.6874, GNorm = 1.6686, lr_0 = 1.0000e-04
Loss = 4.4202e-04, PNorm = 60.6892, GNorm = 0.7356, lr_0 = 1.0000e-04
Loss = 1.1222e-03, PNorm = 60.6909, GNorm = 1.5609, lr_0 = 1.0000e-04
Loss = 4.4044e-04, PNorm = 60.6927, GNorm = 1.9042, lr_0 = 1.0000e-04
Loss = 8.9622e-04, PNorm = 60.6946, GNorm = 1.5502, lr_0 = 1.0000e-04
Loss = 8.4587e-04, PNorm = 60.6957, GNorm = 0.6052, lr_0 = 1.0000e-04
Loss = 4.7624e-04, PNorm = 60.6965, GNorm = 1.0834, lr_0 = 1.0000e-04
Loss = 8.0478e-04, PNorm = 60.6981, GNorm = 3.2505, lr_0 = 1.0000e-04
Loss = 6.3635e-04, PNorm = 60.6998, GNorm = 1.5642, lr_0 = 1.0000e-04
Loss = 5.3047e-04, PNorm = 60.7019, GNorm = 1.1115, lr_0 = 1.0000e-04
Loss = 4.7853e-04, PNorm = 60.7030, GNorm = 1.3555, lr_0 = 1.0000e-04
Loss = 5.7025e-04, PNorm = 60.7038, GNorm = 0.7810, lr_0 = 1.0000e-04
Loss = 5.8138e-04, PNorm = 60.7049, GNorm = 1.7518, lr_0 = 1.0000e-04
Validation rmse = 4.079263
Validation R2 = -3.756250
Epoch 85
Train function
Loss = 4.2354e-04, PNorm = 60.7071, GNorm = 1.4155, lr_0 = 1.0000e-04
Loss = 5.3426e-04, PNorm = 60.7083, GNorm = 1.9462, lr_0 = 1.0000e-04
Loss = 6.5023e-04, PNorm = 60.7098, GNorm = 2.2654, lr_0 = 1.0000e-04
Loss = 2.7486e-04, PNorm = 60.7108, GNorm = 0.9551, lr_0 = 1.0000e-04
Loss = 5.4854e-04, PNorm = 60.7118, GNorm = 1.6727, lr_0 = 1.0000e-04
Loss = 8.0844e-04, PNorm = 60.7128, GNorm = 2.0420, lr_0 = 1.0000e-04
Loss = 5.5831e-04, PNorm = 60.7142, GNorm = 1.2089, lr_0 = 1.0000e-04
Loss = 5.9598e-04, PNorm = 60.7154, GNorm = 2.1053, lr_0 = 1.0000e-04
Loss = 5.2328e-04, PNorm = 60.7173, GNorm = 0.9317, lr_0 = 1.0000e-04
Loss = 6.8141e-04, PNorm = 60.7198, GNorm = 1.1341, lr_0 = 1.0000e-04
Loss = 7.4151e-04, PNorm = 60.7213, GNorm = 1.6631, lr_0 = 1.0000e-04
Loss = 7.3593e-04, PNorm = 60.7234, GNorm = 1.8027, lr_0 = 1.0000e-04
Loss = 4.5147e-04, PNorm = 60.7247, GNorm = 1.0115, lr_0 = 1.0000e-04
Loss = 6.5576e-04, PNorm = 60.7256, GNorm = 0.9396, lr_0 = 1.0000e-04
Loss = 1.1844e-03, PNorm = 60.7264, GNorm = 0.6589, lr_0 = 1.0000e-04
Loss = 4.6371e-04, PNorm = 60.7275, GNorm = 1.3025, lr_0 = 1.0000e-04
Loss = 4.2196e-04, PNorm = 60.7294, GNorm = 0.6236, lr_0 = 1.0000e-04
Loss = 7.3009e-04, PNorm = 60.7309, GNorm = 1.2352, lr_0 = 1.0000e-04
Loss = 4.3091e-04, PNorm = 60.7325, GNorm = 1.2274, lr_0 = 1.0000e-04
Loss = 7.3629e-04, PNorm = 60.7347, GNorm = 1.0906, lr_0 = 1.0000e-04
Loss = 5.9133e-04, PNorm = 60.7378, GNorm = 1.3430, lr_0 = 1.0000e-04
Loss = 7.8708e-04, PNorm = 60.7393, GNorm = 1.0452, lr_0 = 1.0000e-04
Loss = 4.1275e-04, PNorm = 60.7404, GNorm = 0.8323, lr_0 = 1.0000e-04
Loss = 6.1213e-04, PNorm = 60.7416, GNorm = 1.3338, lr_0 = 1.0000e-04
Validation rmse = 4.286716
Validation R2 = -4.252316
Epoch 86
Train function
Loss = 4.0289e-04, PNorm = 60.7435, GNorm = 1.1491, lr_0 = 1.0000e-04
Loss = 3.4406e-04, PNorm = 60.7449, GNorm = 0.9718, lr_0 = 1.0000e-04
Loss = 3.8110e-04, PNorm = 60.7461, GNorm = 1.0248, lr_0 = 1.0000e-04
Loss = 3.3750e-04, PNorm = 60.7470, GNorm = 0.8794, lr_0 = 1.0000e-04
Loss = 4.7337e-04, PNorm = 60.7479, GNorm = 1.1393, lr_0 = 1.0000e-04
Loss = 5.4451e-04, PNorm = 60.7498, GNorm = 1.3748, lr_0 = 1.0000e-04
Loss = 6.4760e-04, PNorm = 60.7510, GNorm = 1.4089, lr_0 = 1.0000e-04
Loss = 3.9728e-04, PNorm = 60.7521, GNorm = 1.0878, lr_0 = 1.0000e-04
Loss = 3.7130e-04, PNorm = 60.7529, GNorm = 1.9182, lr_0 = 1.0000e-04
Loss = 1.0086e-03, PNorm = 60.7543, GNorm = 1.3906, lr_0 = 1.0000e-04
Loss = 5.1318e-04, PNorm = 60.7563, GNorm = 1.8820, lr_0 = 1.0000e-04
Loss = 5.2292e-04, PNorm = 60.7577, GNorm = 1.8406, lr_0 = 1.0000e-04
Loss = 5.3273e-04, PNorm = 60.7591, GNorm = 1.7301, lr_0 = 1.0000e-04
Loss = 5.9897e-04, PNorm = 60.7610, GNorm = 1.4770, lr_0 = 1.0000e-04
Loss = 7.9116e-04, PNorm = 60.7625, GNorm = 1.3318, lr_0 = 1.0000e-04
Loss = 7.4501e-04, PNorm = 60.7644, GNorm = 1.2218, lr_0 = 1.0000e-04
Loss = 5.2531e-04, PNorm = 60.7663, GNorm = 1.5734, lr_0 = 1.0000e-04
Loss = 8.7943e-04, PNorm = 60.7684, GNorm = 3.0057, lr_0 = 1.0000e-04
Loss = 3.1921e-04, PNorm = 60.7701, GNorm = 0.8577, lr_0 = 1.0000e-04
Loss = 6.6082e-04, PNorm = 60.7716, GNorm = 0.9309, lr_0 = 1.0000e-04
Loss = 4.2341e-04, PNorm = 60.7729, GNorm = 1.3693, lr_0 = 1.0000e-04
Loss = 6.4484e-04, PNorm = 60.7744, GNorm = 1.4265, lr_0 = 1.0000e-04
Loss = 1.1849e-03, PNorm = 60.7768, GNorm = 1.3245, lr_0 = 1.0000e-04
Validation rmse = 4.435752
Validation R2 = -4.623878
Epoch 87
Train function
Loss = 4.0405e-04, PNorm = 60.7797, GNorm = 0.8030, lr_0 = 1.0000e-04
Loss = 6.2619e-04, PNorm = 60.7813, GNorm = 1.0341, lr_0 = 1.0000e-04
Loss = 3.5295e-04, PNorm = 60.7820, GNorm = 1.1137, lr_0 = 1.0000e-04
Loss = 4.2775e-04, PNorm = 60.7832, GNorm = 0.6210, lr_0 = 1.0000e-04
Loss = 9.4856e-04, PNorm = 60.7836, GNorm = 2.3917, lr_0 = 1.0000e-04
Loss = 6.2241e-04, PNorm = 60.7846, GNorm = 2.7228, lr_0 = 1.0000e-04
Loss = 6.3560e-04, PNorm = 60.7861, GNorm = 1.8608, lr_0 = 1.0000e-04
Loss = 5.7086e-04, PNorm = 60.7879, GNorm = 2.2190, lr_0 = 1.0000e-04
Loss = 6.3823e-04, PNorm = 60.7896, GNorm = 0.9254, lr_0 = 1.0000e-04
Loss = 5.2003e-04, PNorm = 60.7916, GNorm = 0.8672, lr_0 = 1.0000e-04
Loss = 6.1101e-04, PNorm = 60.7931, GNorm = 1.5953, lr_0 = 1.0000e-04
Loss = 4.9134e-04, PNorm = 60.7946, GNorm = 1.4206, lr_0 = 1.0000e-04
Loss = 3.5473e-04, PNorm = 60.7961, GNorm = 1.5961, lr_0 = 1.0000e-04
Loss = 4.0191e-04, PNorm = 60.7968, GNorm = 1.3540, lr_0 = 1.0000e-04
Loss = 5.3182e-04, PNorm = 60.7983, GNorm = 1.2160, lr_0 = 1.0000e-04
Loss = 5.2011e-04, PNorm = 60.7998, GNorm = 1.5622, lr_0 = 1.0000e-04
Loss = 8.2562e-04, PNorm = 60.8010, GNorm = 0.7084, lr_0 = 1.0000e-04
Loss = 5.9829e-04, PNorm = 60.8031, GNorm = 1.3253, lr_0 = 1.0000e-04
Loss = 6.3835e-04, PNorm = 60.8047, GNorm = 0.9457, lr_0 = 1.0000e-04
Loss = 6.1707e-04, PNorm = 60.8058, GNorm = 2.9172, lr_0 = 1.0000e-04
Loss = 5.7662e-04, PNorm = 60.8074, GNorm = 1.1315, lr_0 = 1.0000e-04
Loss = 4.0324e-04, PNorm = 60.8084, GNorm = 0.9816, lr_0 = 1.0000e-04
Loss = 1.3143e-03, PNorm = 60.8096, GNorm = 0.8174, lr_0 = 1.0000e-04
Validation rmse = 4.200808
Validation R2 = -4.043906
Epoch 88
Train function
Loss = 2.0905e-04, PNorm = 60.8110, GNorm = 0.9475, lr_0 = 1.0000e-04
Loss = 5.4367e-04, PNorm = 60.8127, GNorm = 1.3149, lr_0 = 1.0000e-04
Loss = 1.1498e-03, PNorm = 60.8142, GNorm = 1.2807, lr_0 = 1.0000e-04
Loss = 6.4038e-04, PNorm = 60.8152, GNorm = 1.7401, lr_0 = 1.0000e-04
Loss = 6.1916e-04, PNorm = 60.8166, GNorm = 1.7620, lr_0 = 1.0000e-04
Loss = 5.9148e-04, PNorm = 60.8179, GNorm = 1.3869, lr_0 = 1.0000e-04
Loss = 6.1788e-04, PNorm = 60.8193, GNorm = 0.9905, lr_0 = 1.0000e-04
Loss = 6.2983e-04, PNorm = 60.8207, GNorm = 0.9519, lr_0 = 1.0000e-04
Loss = 4.0377e-04, PNorm = 60.8215, GNorm = 0.7078, lr_0 = 1.0000e-04
Loss = 3.3317e-04, PNorm = 60.8224, GNorm = 1.0269, lr_0 = 1.0000e-04
Loss = 4.4285e-04, PNorm = 60.8233, GNorm = 0.7829, lr_0 = 1.0000e-04
Loss = 7.6433e-04, PNorm = 60.8240, GNorm = 0.8587, lr_0 = 1.0000e-04
Loss = 4.6985e-04, PNorm = 60.8250, GNorm = 0.9925, lr_0 = 1.0000e-04
Loss = 7.3229e-04, PNorm = 60.8264, GNorm = 0.6090, lr_0 = 1.0000e-04
Loss = 5.8084e-04, PNorm = 60.8277, GNorm = 1.3816, lr_0 = 1.0000e-04
Loss = 8.2609e-04, PNorm = 60.8293, GNorm = 2.7297, lr_0 = 1.0000e-04
Loss = 4.0108e-04, PNorm = 60.8304, GNorm = 1.0085, lr_0 = 1.0000e-04
Loss = 4.6118e-04, PNorm = 60.8319, GNorm = 1.5958, lr_0 = 1.0000e-04
Loss = 4.5096e-04, PNorm = 60.8339, GNorm = 1.0380, lr_0 = 1.0000e-04
Loss = 9.6388e-04, PNorm = 60.8354, GNorm = 1.0360, lr_0 = 1.0000e-04
Loss = 5.2778e-04, PNorm = 60.8367, GNorm = 1.2248, lr_0 = 1.0000e-04
Loss = 4.1933e-04, PNorm = 60.8379, GNorm = 1.6428, lr_0 = 1.0000e-04
Loss = 4.2750e-04, PNorm = 60.8393, GNorm = 1.3528, lr_0 = 1.0000e-04
Loss = 6.3799e-04, PNorm = 60.8410, GNorm = 1.0478, lr_0 = 1.0000e-04
Validation rmse = 4.167738
Validation R2 = -3.964804
Epoch 89
Train function
Loss = 4.6125e-04, PNorm = 60.8424, GNorm = 0.8267, lr_0 = 1.0000e-04
Loss = 3.7042e-04, PNorm = 60.8432, GNorm = 0.9473, lr_0 = 1.0000e-04
Loss = 6.0290e-04, PNorm = 60.8442, GNorm = 3.3023, lr_0 = 1.0000e-04
Loss = 4.9642e-04, PNorm = 60.8458, GNorm = 1.0864, lr_0 = 1.0000e-04
Loss = 4.5583e-04, PNorm = 60.8482, GNorm = 0.7373, lr_0 = 1.0000e-04
Loss = 5.0750e-04, PNorm = 60.8501, GNorm = 1.4706, lr_0 = 1.0000e-04
Loss = 6.1070e-04, PNorm = 60.8517, GNorm = 2.3282, lr_0 = 1.0000e-04
Loss = 5.0704e-04, PNorm = 60.8530, GNorm = 1.1576, lr_0 = 1.0000e-04
Loss = 4.9029e-04, PNorm = 60.8539, GNorm = 1.4665, lr_0 = 1.0000e-04
Loss = 5.8790e-04, PNorm = 60.8557, GNorm = 0.7772, lr_0 = 1.0000e-04
Loss = 6.5260e-04, PNorm = 60.8571, GNorm = 1.2980, lr_0 = 1.0000e-04
Loss = 8.9235e-04, PNorm = 60.8580, GNorm = 1.1874, lr_0 = 1.0000e-04
Loss = 4.5202e-04, PNorm = 60.8591, GNorm = 1.3890, lr_0 = 1.0000e-04
Loss = 6.1663e-04, PNorm = 60.8603, GNorm = 1.5142, lr_0 = 1.0000e-04
Loss = 2.7677e-04, PNorm = 60.8610, GNorm = 0.8300, lr_0 = 1.0000e-04
Loss = 5.2311e-04, PNorm = 60.8619, GNorm = 1.5813, lr_0 = 1.0000e-04
Loss = 4.7000e-04, PNorm = 60.8632, GNorm = 1.1223, lr_0 = 1.0000e-04
Loss = 4.3183e-04, PNorm = 60.8642, GNorm = 0.7492, lr_0 = 1.0000e-04
Loss = 3.2361e-04, PNorm = 60.8651, GNorm = 0.9790, lr_0 = 1.0000e-04
Loss = 4.8360e-04, PNorm = 60.8660, GNorm = 1.4273, lr_0 = 1.0000e-04
Loss = 6.6699e-04, PNorm = 60.8670, GNorm = 1.0690, lr_0 = 1.0000e-04
Loss = 4.4508e-04, PNorm = 60.8685, GNorm = 1.6925, lr_0 = 1.0000e-04
Loss = 6.8331e-04, PNorm = 60.8700, GNorm = 1.8662, lr_0 = 1.0000e-04
Validation rmse = 4.235434
Validation R2 = -4.127399
Epoch 90
Train function
Loss = 4.1847e-04, PNorm = 60.8713, GNorm = 1.3299, lr_0 = 1.0000e-04
Loss = 4.1803e-04, PNorm = 60.8730, GNorm = 0.6974, lr_0 = 1.0000e-04
Loss = 4.2334e-04, PNorm = 60.8743, GNorm = 1.6220, lr_0 = 1.0000e-04
Loss = 5.9911e-04, PNorm = 60.8763, GNorm = 1.2049, lr_0 = 1.0000e-04
Loss = 5.0479e-04, PNorm = 60.8770, GNorm = 1.7859, lr_0 = 1.0000e-04
Loss = 4.8905e-04, PNorm = 60.8785, GNorm = 1.4848, lr_0 = 1.0000e-04
Loss = 6.1736e-04, PNorm = 60.8802, GNorm = 1.6815, lr_0 = 1.0000e-04
Loss = 4.3636e-04, PNorm = 60.8816, GNorm = 0.7428, lr_0 = 1.0000e-04
Loss = 1.1103e-03, PNorm = 60.8828, GNorm = 3.0007, lr_0 = 1.0000e-04
Loss = 5.1377e-04, PNorm = 60.8840, GNorm = 1.0423, lr_0 = 1.0000e-04
Loss = 5.0858e-04, PNorm = 60.8851, GNorm = 1.1667, lr_0 = 1.0000e-04
Loss = 3.9457e-04, PNorm = 60.8868, GNorm = 1.3999, lr_0 = 1.0000e-04
Loss = 6.8514e-04, PNorm = 60.8890, GNorm = 0.8021, lr_0 = 1.0000e-04
Loss = 5.0755e-04, PNorm = 60.8914, GNorm = 1.1217, lr_0 = 1.0000e-04
Loss = 4.5264e-04, PNorm = 60.8934, GNorm = 0.9914, lr_0 = 1.0000e-04
Loss = 8.1119e-04, PNorm = 60.8949, GNorm = 1.4143, lr_0 = 1.0000e-04
Loss = 4.6279e-04, PNorm = 60.8964, GNorm = 0.7938, lr_0 = 1.0000e-04
Loss = 5.8859e-04, PNorm = 60.8970, GNorm = 1.1660, lr_0 = 1.0000e-04
Loss = 9.5651e-04, PNorm = 60.8986, GNorm = 0.8531, lr_0 = 1.0000e-04
Loss = 3.1675e-04, PNorm = 60.8997, GNorm = 1.0593, lr_0 = 1.0000e-04
Loss = 7.1017e-04, PNorm = 60.9007, GNorm = 0.9956, lr_0 = 1.0000e-04
Loss = 5.5444e-04, PNorm = 60.9023, GNorm = 1.5370, lr_0 = 1.0000e-04
Loss = 5.0954e-04, PNorm = 60.9037, GNorm = 0.9555, lr_0 = 1.0000e-04
Loss = 5.8165e-04, PNorm = 60.9050, GNorm = 2.1529, lr_0 = 1.0000e-04
Validation rmse = 4.245417
Validation R2 = -4.151600
Epoch 91
Train function
Loss = 3.7213e-04, PNorm = 60.9060, GNorm = 0.7258, lr_0 = 1.0000e-04
Loss = 2.6646e-04, PNorm = 60.9069, GNorm = 0.5880, lr_0 = 1.0000e-04
Loss = 3.7058e-04, PNorm = 60.9076, GNorm = 0.9585, lr_0 = 1.0000e-04
Loss = 4.4273e-04, PNorm = 60.9088, GNorm = 1.9064, lr_0 = 1.0000e-04
Loss = 6.6868e-04, PNorm = 60.9109, GNorm = 1.3692, lr_0 = 1.0000e-04
Loss = 3.3056e-04, PNorm = 60.9124, GNorm = 1.0375, lr_0 = 1.0000e-04
Loss = 3.4419e-04, PNorm = 60.9136, GNorm = 1.1685, lr_0 = 1.0000e-04
Loss = 4.2959e-04, PNorm = 60.9145, GNorm = 1.6823, lr_0 = 1.0000e-04
Loss = 6.4919e-04, PNorm = 60.9157, GNorm = 2.3891, lr_0 = 1.0000e-04
Loss = 4.2106e-04, PNorm = 60.9170, GNorm = 1.3532, lr_0 = 1.0000e-04
Loss = 6.5547e-04, PNorm = 60.9183, GNorm = 1.5361, lr_0 = 1.0000e-04
Loss = 3.8551e-04, PNorm = 60.9195, GNorm = 0.7962, lr_0 = 1.0000e-04
Loss = 5.8818e-04, PNorm = 60.9209, GNorm = 1.3774, lr_0 = 1.0000e-04
Loss = 8.3041e-04, PNorm = 60.9217, GNorm = 1.8391, lr_0 = 1.0000e-04
Loss = 4.6710e-04, PNorm = 60.9225, GNorm = 1.4762, lr_0 = 1.0000e-04
Loss = 5.7341e-04, PNorm = 60.9245, GNorm = 1.4093, lr_0 = 1.0000e-04
Loss = 3.3628e-04, PNorm = 60.9250, GNorm = 1.7521, lr_0 = 1.0000e-04
Loss = 3.4673e-04, PNorm = 60.9261, GNorm = 0.9498, lr_0 = 1.0000e-04
Loss = 8.8112e-04, PNorm = 60.9276, GNorm = 1.3429, lr_0 = 1.0000e-04
Loss = 7.6314e-04, PNorm = 60.9288, GNorm = 2.5303, lr_0 = 1.0000e-04
Loss = 9.2050e-04, PNorm = 60.9305, GNorm = 1.5280, lr_0 = 1.0000e-04
Loss = 6.0629e-04, PNorm = 60.9317, GNorm = 0.8371, lr_0 = 1.0000e-04
Loss = 4.4871e-04, PNorm = 60.9338, GNorm = 1.2280, lr_0 = 1.0000e-04
Validation rmse = 4.244843
Validation R2 = -4.150205
Epoch 92
Train function
Loss = 3.7413e-04, PNorm = 60.9354, GNorm = 1.3532, lr_0 = 1.0000e-04
Loss = 4.8287e-04, PNorm = 60.9363, GNorm = 0.8015, lr_0 = 1.0000e-04
Loss = 6.2648e-04, PNorm = 60.9381, GNorm = 2.3222, lr_0 = 1.0000e-04
Loss = 3.5881e-04, PNorm = 60.9400, GNorm = 0.9137, lr_0 = 1.0000e-04
Loss = 3.8571e-04, PNorm = 60.9418, GNorm = 1.2065, lr_0 = 1.0000e-04
Loss = 5.0884e-04, PNorm = 60.9436, GNorm = 2.3604, lr_0 = 1.0000e-04
Loss = 3.7913e-04, PNorm = 60.9448, GNorm = 0.7987, lr_0 = 1.0000e-04
Loss = 7.2933e-04, PNorm = 60.9455, GNorm = 2.6796, lr_0 = 1.0000e-04
Loss = 3.7666e-04, PNorm = 60.9454, GNorm = 0.7990, lr_0 = 1.0000e-04
Loss = 5.3017e-04, PNorm = 60.9464, GNorm = 2.4218, lr_0 = 1.0000e-04
Loss = 3.5776e-04, PNorm = 60.9477, GNorm = 1.2979, lr_0 = 1.0000e-04
Loss = 5.6226e-04, PNorm = 60.9480, GNorm = 0.8690, lr_0 = 1.0000e-04
Loss = 5.1152e-04, PNorm = 60.9489, GNorm = 0.9728, lr_0 = 1.0000e-04
Loss = 4.0659e-04, PNorm = 60.9498, GNorm = 1.2283, lr_0 = 1.0000e-04
Loss = 6.4018e-04, PNorm = 60.9516, GNorm = 1.5106, lr_0 = 1.0000e-04
Loss = 5.7487e-04, PNorm = 60.9530, GNorm = 1.5441, lr_0 = 1.0000e-04
Loss = 5.0863e-04, PNorm = 60.9549, GNorm = 0.9229, lr_0 = 1.0000e-04
Loss = 4.0099e-04, PNorm = 60.9565, GNorm = 1.0906, lr_0 = 1.0000e-04
Loss = 6.2545e-04, PNorm = 60.9582, GNorm = 1.1732, lr_0 = 1.0000e-04
Loss = 6.8399e-04, PNorm = 60.9598, GNorm = 1.2054, lr_0 = 1.0000e-04
Loss = 5.3414e-04, PNorm = 60.9609, GNorm = 1.3221, lr_0 = 1.0000e-04
Loss = 7.5460e-04, PNorm = 60.9623, GNorm = 1.3303, lr_0 = 1.0000e-04
Loss = 4.3891e-04, PNorm = 60.9638, GNorm = 1.3888, lr_0 = 1.0000e-04
Loss = 1.0506e-03, PNorm = 60.9654, GNorm = 0.5920, lr_0 = 1.0000e-04
Loss = 1.4219e-03, PNorm = 60.9655, GNorm = 1.3842, lr_0 = 1.0000e-04
Validation rmse = 4.266453
Validation R2 = -4.202777
Epoch 93
Train function
Loss = 5.9623e-04, PNorm = 60.9673, GNorm = 0.8911, lr_0 = 1.0000e-04
Loss = 2.8889e-04, PNorm = 60.9687, GNorm = 0.9564, lr_0 = 1.0000e-04
Loss = 3.4143e-04, PNorm = 60.9697, GNorm = 1.1982, lr_0 = 1.0000e-04
Loss = 6.1737e-04, PNorm = 60.9703, GNorm = 1.2047, lr_0 = 1.0000e-04
Loss = 3.5948e-04, PNorm = 60.9711, GNorm = 1.0920, lr_0 = 1.0000e-04
Loss = 7.7378e-04, PNorm = 60.9719, GNorm = 1.7135, lr_0 = 1.0000e-04
Loss = 3.5123e-04, PNorm = 60.9736, GNorm = 0.9831, lr_0 = 1.0000e-04
Loss = 4.6829e-04, PNorm = 60.9748, GNorm = 1.8562, lr_0 = 1.0000e-04
Loss = 4.8173e-04, PNorm = 60.9755, GNorm = 1.8030, lr_0 = 1.0000e-04
Loss = 4.1741e-04, PNorm = 60.9770, GNorm = 1.3519, lr_0 = 1.0000e-04
Loss = 5.5749e-04, PNorm = 60.9786, GNorm = 1.1320, lr_0 = 1.0000e-04
Loss = 5.0140e-04, PNorm = 60.9794, GNorm = 1.3645, lr_0 = 1.0000e-04
Loss = 5.6397e-04, PNorm = 60.9802, GNorm = 1.7086, lr_0 = 1.0000e-04
Loss = 3.6549e-04, PNorm = 60.9811, GNorm = 1.2523, lr_0 = 1.0000e-04
Loss = 5.6863e-04, PNorm = 60.9824, GNorm = 0.6652, lr_0 = 1.0000e-04
Loss = 4.7307e-04, PNorm = 60.9834, GNorm = 1.3153, lr_0 = 1.0000e-04
Loss = 5.3911e-04, PNorm = 60.9847, GNorm = 0.6149, lr_0 = 1.0000e-04
Loss = 4.9054e-04, PNorm = 60.9863, GNorm = 1.0539, lr_0 = 1.0000e-04
Loss = 5.8122e-04, PNorm = 60.9879, GNorm = 1.0123, lr_0 = 1.0000e-04
Loss = 3.5222e-04, PNorm = 60.9889, GNorm = 0.7378, lr_0 = 1.0000e-04
Loss = 1.1791e-03, PNorm = 60.9908, GNorm = 1.5228, lr_0 = 1.0000e-04
Loss = 4.8237e-04, PNorm = 60.9924, GNorm = 1.2561, lr_0 = 1.0000e-04
Loss = 3.2252e-04, PNorm = 60.9935, GNorm = 0.9900, lr_0 = 1.0000e-04
Validation rmse = 4.248564
Validation R2 = -4.159240
Epoch 94
Train function
Loss = 3.9875e-04, PNorm = 60.9948, GNorm = 1.4791, lr_0 = 1.0000e-04
Loss = 4.7348e-04, PNorm = 60.9958, GNorm = 0.5370, lr_0 = 1.0000e-04
Loss = 4.4097e-04, PNorm = 60.9964, GNorm = 0.6389, lr_0 = 1.0000e-04
Loss = 3.8006e-04, PNorm = 60.9971, GNorm = 0.8454, lr_0 = 1.0000e-04
Loss = 5.9762e-04, PNorm = 60.9979, GNorm = 1.0842, lr_0 = 1.0000e-04
Loss = 3.3904e-04, PNorm = 60.9989, GNorm = 1.0673, lr_0 = 1.0000e-04
Loss = 3.8433e-04, PNorm = 61.0000, GNorm = 0.7301, lr_0 = 1.0000e-04
Loss = 3.7612e-04, PNorm = 61.0017, GNorm = 0.6086, lr_0 = 1.0000e-04
Loss = 4.9681e-04, PNorm = 61.0031, GNorm = 1.3761, lr_0 = 1.0000e-04
Loss = 4.4314e-04, PNorm = 61.0041, GNorm = 1.3730, lr_0 = 1.0000e-04
Loss = 3.3866e-04, PNorm = 61.0049, GNorm = 0.7277, lr_0 = 1.0000e-04
Loss = 3.8688e-04, PNorm = 61.0061, GNorm = 0.9354, lr_0 = 1.0000e-04
Loss = 2.5131e-04, PNorm = 61.0073, GNorm = 0.8764, lr_0 = 1.0000e-04
Loss = 8.5772e-04, PNorm = 61.0085, GNorm = 1.2595, lr_0 = 1.0000e-04
Loss = 3.3957e-04, PNorm = 61.0093, GNorm = 1.2490, lr_0 = 1.0000e-04
Loss = 3.9822e-04, PNorm = 61.0109, GNorm = 0.7203, lr_0 = 1.0000e-04
Loss = 4.5776e-04, PNorm = 61.0122, GNorm = 1.0703, lr_0 = 1.0000e-04
Loss = 1.0056e-03, PNorm = 61.0136, GNorm = 4.4426, lr_0 = 1.0000e-04
Loss = 6.0631e-04, PNorm = 61.0154, GNorm = 0.7548, lr_0 = 1.0000e-04
Loss = 6.4348e-04, PNorm = 61.0166, GNorm = 2.0233, lr_0 = 1.0000e-04
Loss = 3.9197e-04, PNorm = 61.0173, GNorm = 0.7502, lr_0 = 1.0000e-04
Loss = 6.8757e-04, PNorm = 61.0190, GNorm = 0.8529, lr_0 = 1.0000e-04
Loss = 4.7400e-04, PNorm = 61.0214, GNorm = 1.8400, lr_0 = 1.0000e-04
Validation rmse = 4.355433
Validation R2 = -4.422056
Epoch 95
Train function
Loss = 3.9696e-04, PNorm = 61.0233, GNorm = 1.9015, lr_0 = 1.0000e-04
Loss = 4.3484e-04, PNorm = 61.0246, GNorm = 0.9784, lr_0 = 1.0000e-04
Loss = 2.9028e-04, PNorm = 61.0257, GNorm = 1.0854, lr_0 = 1.0000e-04
Loss = 3.9658e-04, PNorm = 61.0271, GNorm = 0.9839, lr_0 = 1.0000e-04
Loss = 3.8227e-04, PNorm = 61.0282, GNorm = 0.8662, lr_0 = 1.0000e-04
Loss = 4.8656e-04, PNorm = 61.0296, GNorm = 0.8229, lr_0 = 1.0000e-04
Loss = 4.4997e-04, PNorm = 61.0316, GNorm = 2.0183, lr_0 = 1.0000e-04
Loss = 3.9929e-04, PNorm = 61.0329, GNorm = 1.8396, lr_0 = 1.0000e-04
Loss = 4.4521e-04, PNorm = 61.0340, GNorm = 1.4254, lr_0 = 1.0000e-04
Loss = 4.2000e-04, PNorm = 61.0348, GNorm = 1.1168, lr_0 = 1.0000e-04
Loss = 7.5025e-04, PNorm = 61.0360, GNorm = 2.6786, lr_0 = 1.0000e-04
Loss = 4.0717e-04, PNorm = 61.0379, GNorm = 0.6540, lr_0 = 1.0000e-04
Loss = 4.0588e-04, PNorm = 61.0391, GNorm = 1.1779, lr_0 = 1.0000e-04
Loss = 6.8863e-04, PNorm = 61.0402, GNorm = 1.1355, lr_0 = 1.0000e-04
Loss = 3.5961e-04, PNorm = 61.0414, GNorm = 0.7951, lr_0 = 1.0000e-04
Loss = 9.2183e-04, PNorm = 61.0435, GNorm = 0.9602, lr_0 = 1.0000e-04
Loss = 2.7562e-04, PNorm = 61.0448, GNorm = 1.1093, lr_0 = 1.0000e-04
Loss = 5.9793e-04, PNorm = 61.0457, GNorm = 1.1651, lr_0 = 1.0000e-04
Loss = 5.8392e-04, PNorm = 61.0478, GNorm = 2.3339, lr_0 = 1.0000e-04
Loss = 5.2080e-04, PNorm = 61.0499, GNorm = 1.0527, lr_0 = 1.0000e-04
Loss = 9.0109e-04, PNorm = 61.0521, GNorm = 1.4821, lr_0 = 1.0000e-04
Loss = 5.2353e-04, PNorm = 61.0532, GNorm = 0.8812, lr_0 = 1.0000e-04
Loss = 4.9743e-04, PNorm = 61.0549, GNorm = 2.5414, lr_0 = 1.0000e-04
Loss = 3.3827e-04, PNorm = 61.0558, GNorm = 1.0582, lr_0 = 1.0000e-04
Validation rmse = 4.300566
Validation R2 = -4.286308
Epoch 96
Train function
Loss = 5.0236e-04, PNorm = 61.0564, GNorm = 1.1018, lr_0 = 1.0000e-04
Loss = 2.9120e-04, PNorm = 61.0578, GNorm = 0.9504, lr_0 = 1.0000e-04
Loss = 2.8944e-04, PNorm = 61.0583, GNorm = 0.8023, lr_0 = 1.0000e-04
Loss = 3.2808e-04, PNorm = 61.0597, GNorm = 1.2570, lr_0 = 1.0000e-04
Loss = 2.6229e-04, PNorm = 61.0611, GNorm = 0.7736, lr_0 = 1.0000e-04
Loss = 3.8670e-04, PNorm = 61.0616, GNorm = 1.4315, lr_0 = 1.0000e-04
Loss = 3.1419e-04, PNorm = 61.0628, GNorm = 1.1457, lr_0 = 1.0000e-04
Loss = 3.8804e-04, PNorm = 61.0635, GNorm = 0.9000, lr_0 = 1.0000e-04
Loss = 2.3001e-04, PNorm = 61.0638, GNorm = 0.8192, lr_0 = 1.0000e-04
Loss = 3.5150e-04, PNorm = 61.0653, GNorm = 1.0588, lr_0 = 1.0000e-04
Loss = 5.1663e-04, PNorm = 61.0671, GNorm = 1.0019, lr_0 = 1.0000e-04
Loss = 6.7516e-04, PNorm = 61.0686, GNorm = 0.6384, lr_0 = 1.0000e-04
Loss = 3.1750e-04, PNorm = 61.0697, GNorm = 0.7309, lr_0 = 1.0000e-04
Loss = 3.8842e-04, PNorm = 61.0709, GNorm = 0.9763, lr_0 = 1.0000e-04
Loss = 5.8692e-04, PNorm = 61.0717, GNorm = 1.1290, lr_0 = 1.0000e-04
Loss = 4.2925e-04, PNorm = 61.0732, GNorm = 1.0989, lr_0 = 1.0000e-04
Loss = 1.0291e-03, PNorm = 61.0746, GNorm = 1.0481, lr_0 = 1.0000e-04
Loss = 5.4475e-04, PNorm = 61.0761, GNorm = 0.8207, lr_0 = 1.0000e-04
Loss = 4.9657e-04, PNorm = 61.0773, GNorm = 1.0837, lr_0 = 1.0000e-04
Loss = 6.7293e-04, PNorm = 61.0790, GNorm = 1.1842, lr_0 = 1.0000e-04
Loss = 9.6965e-04, PNorm = 61.0796, GNorm = 1.1783, lr_0 = 1.0000e-04
Loss = 5.0939e-04, PNorm = 61.0798, GNorm = 1.1586, lr_0 = 1.0000e-04
Loss = 5.8421e-04, PNorm = 61.0806, GNorm = 1.3268, lr_0 = 1.0000e-04
Validation rmse = 4.237201
Validation R2 = -4.131679
Epoch 97
Train function
Loss = 1.5301e-03, PNorm = 61.0816, GNorm = 0.7641, lr_0 = 1.0000e-04
Loss = 7.9042e-04, PNorm = 61.0830, GNorm = 0.5079, lr_0 = 1.0000e-04
Loss = 6.3261e-04, PNorm = 61.0837, GNorm = 1.3583, lr_0 = 1.0000e-04
Loss = 3.5212e-04, PNorm = 61.0847, GNorm = 1.2180, lr_0 = 1.0000e-04
Loss = 3.9594e-04, PNorm = 61.0854, GNorm = 1.8998, lr_0 = 1.0000e-04
Loss = 7.9631e-04, PNorm = 61.0861, GNorm = 3.7735, lr_0 = 1.0000e-04
Loss = 2.9472e-04, PNorm = 61.0869, GNorm = 0.6010, lr_0 = 1.0000e-04
Loss = 4.2634e-04, PNorm = 61.0881, GNorm = 0.9144, lr_0 = 1.0000e-04
Loss = 4.3201e-04, PNorm = 61.0892, GNorm = 0.6770, lr_0 = 1.0000e-04
Loss = 4.8901e-04, PNorm = 61.0911, GNorm = 0.9252, lr_0 = 1.0000e-04
Loss = 4.9734e-04, PNorm = 61.0917, GNorm = 1.0853, lr_0 = 1.0000e-04
Loss = 4.9218e-04, PNorm = 61.0921, GNorm = 0.6652, lr_0 = 1.0000e-04
Loss = 7.5024e-04, PNorm = 61.0936, GNorm = 0.7484, lr_0 = 1.0000e-04
Loss = 2.7157e-04, PNorm = 61.0949, GNorm = 0.8078, lr_0 = 1.0000e-04
Loss = 3.0056e-04, PNorm = 61.0956, GNorm = 0.9454, lr_0 = 1.0000e-04
Loss = 2.7038e-04, PNorm = 61.0969, GNorm = 1.1645, lr_0 = 1.0000e-04
Loss = 3.0456e-04, PNorm = 61.0981, GNorm = 1.0662, lr_0 = 1.0000e-04
Loss = 7.2308e-04, PNorm = 61.0996, GNorm = 1.6128, lr_0 = 1.0000e-04
Loss = 6.2241e-04, PNorm = 61.1018, GNorm = 1.2350, lr_0 = 1.0000e-04
Loss = 4.2146e-04, PNorm = 61.1033, GNorm = 1.1105, lr_0 = 1.0000e-04
Loss = 2.8913e-04, PNorm = 61.1042, GNorm = 0.7659, lr_0 = 1.0000e-04
Loss = 4.7620e-04, PNorm = 61.1065, GNorm = 0.9755, lr_0 = 1.0000e-04
Loss = 4.4311e-04, PNorm = 61.1077, GNorm = 1.1053, lr_0 = 1.0000e-04
Loss = 4.0743e-04, PNorm = 61.1096, GNorm = 0.6232, lr_0 = 1.0000e-04
Validation rmse = 4.290006
Validation R2 = -4.260382
Epoch 98
Train function
Loss = 3.1688e-04, PNorm = 61.1115, GNorm = 1.1189, lr_0 = 1.0000e-04
Loss = 3.2813e-04, PNorm = 61.1124, GNorm = 0.6441, lr_0 = 1.0000e-04
Loss = 3.4595e-04, PNorm = 61.1140, GNorm = 1.1571, lr_0 = 1.0000e-04
Loss = 2.1288e-04, PNorm = 61.1144, GNorm = 1.0169, lr_0 = 1.0000e-04
Loss = 3.7227e-04, PNorm = 61.1151, GNorm = 1.2500, lr_0 = 1.0000e-04
Loss = 3.2768e-04, PNorm = 61.1153, GNorm = 1.6662, lr_0 = 1.0000e-04
Loss = 1.1239e-03, PNorm = 61.1166, GNorm = 3.1723, lr_0 = 1.0000e-04
Loss = 5.7862e-04, PNorm = 61.1186, GNorm = 0.6362, lr_0 = 1.0000e-04
Loss = 3.6462e-04, PNorm = 61.1198, GNorm = 0.8573, lr_0 = 1.0000e-04
Loss = 4.1464e-04, PNorm = 61.1213, GNorm = 0.5847, lr_0 = 1.0000e-04
Loss = 4.7901e-04, PNorm = 61.1222, GNorm = 0.8571, lr_0 = 1.0000e-04
Loss = 3.8690e-04, PNorm = 61.1230, GNorm = 0.9645, lr_0 = 1.0000e-04
Loss = 4.5069e-04, PNorm = 61.1243, GNorm = 0.9037, lr_0 = 1.0000e-04
Loss = 4.1591e-04, PNorm = 61.1251, GNorm = 0.8142, lr_0 = 1.0000e-04
Loss = 3.1794e-04, PNorm = 61.1261, GNorm = 0.8085, lr_0 = 1.0000e-04
Loss = 3.5990e-04, PNorm = 61.1273, GNorm = 0.6997, lr_0 = 1.0000e-04
Loss = 3.4452e-04, PNorm = 61.1292, GNorm = 0.7001, lr_0 = 1.0000e-04
Loss = 3.6698e-04, PNorm = 61.1303, GNorm = 1.8958, lr_0 = 1.0000e-04
Loss = 2.5778e-04, PNorm = 61.1316, GNorm = 0.9966, lr_0 = 1.0000e-04
Loss = 9.9747e-04, PNorm = 61.1320, GNorm = 1.1415, lr_0 = 1.0000e-04
Loss = 7.9277e-04, PNorm = 61.1334, GNorm = 1.1835, lr_0 = 1.0000e-04
Loss = 3.2667e-04, PNorm = 61.1342, GNorm = 0.6544, lr_0 = 1.0000e-04
Loss = 2.8543e-04, PNorm = 61.1351, GNorm = 0.9003, lr_0 = 1.0000e-04
Validation rmse = 4.264627
Validation R2 = -4.198326
Epoch 99
Train function
Loss = 4.0747e-04, PNorm = 61.1363, GNorm = 1.0371, lr_0 = 1.0000e-04
Loss = 3.0282e-04, PNorm = 61.1375, GNorm = 0.9256, lr_0 = 1.0000e-04
Loss = 8.6287e-04, PNorm = 61.1381, GNorm = 1.2688, lr_0 = 1.0000e-04
Loss = 2.7300e-04, PNorm = 61.1386, GNorm = 1.3615, lr_0 = 1.0000e-04
Loss = 4.7247e-04, PNorm = 61.1396, GNorm = 1.6572, lr_0 = 1.0000e-04
Loss = 2.6969e-04, PNorm = 61.1408, GNorm = 0.8729, lr_0 = 1.0000e-04
Loss = 3.2490e-04, PNorm = 61.1421, GNorm = 0.7483, lr_0 = 1.0000e-04
Loss = 4.3121e-04, PNorm = 61.1431, GNorm = 1.5700, lr_0 = 1.0000e-04
Loss = 5.1648e-04, PNorm = 61.1452, GNorm = 1.5860, lr_0 = 1.0000e-04
Loss = 7.4735e-04, PNorm = 61.1475, GNorm = 0.9779, lr_0 = 1.0000e-04
Loss = 3.1972e-04, PNorm = 61.1492, GNorm = 1.0369, lr_0 = 1.0000e-04
Loss = 4.0939e-04, PNorm = 61.1502, GNorm = 0.8648, lr_0 = 1.0000e-04
Loss = 9.9174e-04, PNorm = 61.1513, GNorm = 1.8882, lr_0 = 1.0000e-04
Loss = 3.1577e-04, PNorm = 61.1523, GNorm = 1.4996, lr_0 = 1.0000e-04
Loss = 3.2111e-04, PNorm = 61.1526, GNorm = 1.3526, lr_0 = 1.0000e-04
Loss = 2.9227e-04, PNorm = 61.1533, GNorm = 1.6173, lr_0 = 1.0000e-04
Loss = 3.5101e-04, PNorm = 61.1545, GNorm = 0.9042, lr_0 = 1.0000e-04
Loss = 7.4190e-04, PNorm = 61.1560, GNorm = 2.0792, lr_0 = 1.0000e-04
Loss = 5.8790e-04, PNorm = 61.1573, GNorm = 1.3962, lr_0 = 1.0000e-04
Loss = 6.3657e-04, PNorm = 61.1581, GNorm = 1.2551, lr_0 = 1.0000e-04
Loss = 3.2549e-04, PNorm = 61.1591, GNorm = 1.0135, lr_0 = 1.0000e-04
Loss = 4.1875e-04, PNorm = 61.1598, GNorm = 1.2180, lr_0 = 1.0000e-04
Loss = 5.7764e-04, PNorm = 61.1608, GNorm = 1.9228, lr_0 = 1.0000e-04
Loss = 4.0358e-04, PNorm = 61.1617, GNorm = 0.8220, lr_0 = 1.0000e-04
Validation rmse = 4.249289
Validation R2 = -4.161000
Model 0 best validation rmse = 1.015447 on epoch 4
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.972844
Model 0 test R2 = 0.718960
Ensemble test rmse = 0.972844
Ensemble test R2 = 0.718960
Fold 3
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized_best --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8783,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 11,710 | train size = 8,783 | val size = 2,927 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 5.7283e-02, PNorm = 35.0074, GNorm = 10.1871, lr_0 = 1.2829e-04
Loss = 4.6669e-02, PNorm = 35.0071, GNorm = 4.1935, lr_0 = 1.5400e-04
Loss = 4.1956e-02, PNorm = 35.0103, GNorm = 4.7057, lr_0 = 1.7971e-04
Loss = 3.7930e-02, PNorm = 35.0146, GNorm = 5.8953, lr_0 = 2.0543e-04
Loss = 3.9972e-02, PNorm = 35.0191, GNorm = 2.9608, lr_0 = 2.3114e-04
Loss = 3.3426e-02, PNorm = 35.0253, GNorm = 3.0471, lr_0 = 2.5686e-04
Loss = 3.0631e-02, PNorm = 35.0331, GNorm = 4.2702, lr_0 = 2.8257e-04
Loss = 3.3611e-02, PNorm = 35.0434, GNorm = 3.3398, lr_0 = 3.0829e-04
Loss = 3.1364e-02, PNorm = 35.0544, GNorm = 5.4706, lr_0 = 3.3400e-04
Loss = 2.5546e-02, PNorm = 35.0649, GNorm = 2.2505, lr_0 = 3.5971e-04
Loss = 2.6865e-02, PNorm = 35.0787, GNorm = 4.1569, lr_0 = 3.8543e-04
Loss = 3.4624e-02, PNorm = 35.0856, GNorm = 7.7455, lr_0 = 4.1114e-04
Loss = 2.8201e-02, PNorm = 35.0974, GNorm = 8.1269, lr_0 = 4.3686e-04
Loss = 3.0374e-02, PNorm = 35.1147, GNorm = 7.3930, lr_0 = 4.6257e-04
Loss = 2.5294e-02, PNorm = 35.1219, GNorm = 7.5233, lr_0 = 4.8829e-04
Loss = 3.0002e-02, PNorm = 35.1318, GNorm = 2.2134, lr_0 = 5.1400e-04
Loss = 3.1388e-02, PNorm = 35.1460, GNorm = 10.6514, lr_0 = 5.3971e-04
Loss = 2.9660e-02, PNorm = 35.1605, GNorm = 5.7279, lr_0 = 5.6543e-04
Loss = 2.8643e-02, PNorm = 35.1830, GNorm = 10.0378, lr_0 = 5.9114e-04
Loss = 2.3378e-02, PNorm = 35.1940, GNorm = 2.3892, lr_0 = 6.1686e-04
Loss = 2.7444e-02, PNorm = 35.2116, GNorm = 3.4136, lr_0 = 6.4257e-04
Loss = 2.3773e-02, PNorm = 35.2201, GNorm = 10.8511, lr_0 = 6.6829e-04
Loss = 2.6777e-02, PNorm = 35.2349, GNorm = 11.7170, lr_0 = 6.9400e-04
Validation rmse = 2.065420
Validation R2 = -0.218111
Epoch 1
Train function
Loss = 2.7594e-02, PNorm = 35.2515, GNorm = 7.9161, lr_0 = 7.2229e-04
Loss = 2.5100e-02, PNorm = 35.2724, GNorm = 3.7905, lr_0 = 7.4800e-04
Loss = 2.2407e-02, PNorm = 35.2872, GNorm = 4.6355, lr_0 = 7.7371e-04
Loss = 2.4353e-02, PNorm = 35.2995, GNorm = 4.7951, lr_0 = 7.9943e-04
Loss = 2.4342e-02, PNorm = 35.3216, GNorm = 3.2358, lr_0 = 8.2514e-04
Loss = 2.5827e-02, PNorm = 35.3476, GNorm = 8.5627, lr_0 = 8.5086e-04
Loss = 2.4692e-02, PNorm = 35.3695, GNorm = 7.0302, lr_0 = 8.7657e-04
Loss = 3.1052e-02, PNorm = 35.3940, GNorm = 3.8309, lr_0 = 9.0229e-04
Loss = 2.7325e-02, PNorm = 35.4229, GNorm = 10.9146, lr_0 = 9.2800e-04
Loss = 2.8386e-02, PNorm = 35.4490, GNorm = 4.7222, lr_0 = 9.5371e-04
Loss = 2.9069e-02, PNorm = 35.4847, GNorm = 7.8471, lr_0 = 9.7943e-04
Loss = 2.8548e-02, PNorm = 35.5201, GNorm = 4.8632, lr_0 = 9.9973e-04
Loss = 2.7052e-02, PNorm = 35.5538, GNorm = 5.9671, lr_0 = 9.9839e-04
Loss = 2.3801e-02, PNorm = 35.5907, GNorm = 2.3092, lr_0 = 9.9705e-04
Loss = 2.7800e-02, PNorm = 35.6137, GNorm = 5.0159, lr_0 = 9.9571e-04
Loss = 2.8185e-02, PNorm = 35.6349, GNorm = 8.4381, lr_0 = 9.9438e-04
Loss = 2.6125e-02, PNorm = 35.6610, GNorm = 2.0153, lr_0 = 9.9304e-04
Loss = 2.4812e-02, PNorm = 35.6890, GNorm = 2.5375, lr_0 = 9.9171e-04
Loss = 2.9545e-02, PNorm = 35.7085, GNorm = 4.0768, lr_0 = 9.9038e-04
Loss = 2.4119e-02, PNorm = 35.7427, GNorm = 2.6579, lr_0 = 9.8905e-04
Loss = 2.4220e-02, PNorm = 35.7711, GNorm = 3.3447, lr_0 = 9.8772e-04
Loss = 2.1451e-02, PNorm = 35.8080, GNorm = 1.4606, lr_0 = 9.8640e-04
Loss = 2.0402e-02, PNorm = 35.8333, GNorm = 2.2735, lr_0 = 9.8508e-04
Validation rmse = 1.868997
Validation R2 = 0.002558
Epoch 2
Train function
Loss = 2.1314e-02, PNorm = 35.8690, GNorm = 5.3293, lr_0 = 9.8362e-04
Loss = 2.2635e-02, PNorm = 35.8884, GNorm = 2.9008, lr_0 = 9.8230e-04
Loss = 2.5367e-02, PNorm = 35.9095, GNorm = 3.1768, lr_0 = 9.8098e-04
Loss = 2.3086e-02, PNorm = 35.9529, GNorm = 5.0877, lr_0 = 9.7967e-04
Loss = 2.1302e-02, PNorm = 35.9987, GNorm = 4.0040, lr_0 = 9.7835e-04
Loss = 2.4584e-02, PNorm = 36.0269, GNorm = 1.4182, lr_0 = 9.7704e-04
Loss = 2.8339e-02, PNorm = 36.0762, GNorm = 2.5219, lr_0 = 9.7573e-04
Loss = 2.1481e-02, PNorm = 36.1150, GNorm = 1.8974, lr_0 = 9.7442e-04
Loss = 2.5887e-02, PNorm = 36.1503, GNorm = 2.4762, lr_0 = 9.7311e-04
Loss = 2.2667e-02, PNorm = 36.1634, GNorm = 1.1927, lr_0 = 9.7181e-04
Loss = 2.5357e-02, PNorm = 36.1987, GNorm = 2.9459, lr_0 = 9.7050e-04
Loss = 2.5980e-02, PNorm = 36.2147, GNorm = 2.8796, lr_0 = 9.6920e-04
Loss = 2.6156e-02, PNorm = 36.2440, GNorm = 2.3046, lr_0 = 9.6790e-04
Loss = 2.7609e-02, PNorm = 36.2667, GNorm = 1.9175, lr_0 = 9.6660e-04
Loss = 2.2873e-02, PNorm = 36.2927, GNorm = 3.9026, lr_0 = 9.6531e-04
Loss = 2.5783e-02, PNorm = 36.3172, GNorm = 1.6609, lr_0 = 9.6401e-04
Loss = 2.3273e-02, PNorm = 36.3418, GNorm = 2.1837, lr_0 = 9.6272e-04
Loss = 2.3401e-02, PNorm = 36.3537, GNorm = 4.7226, lr_0 = 9.6143e-04
Loss = 2.3518e-02, PNorm = 36.3659, GNorm = 2.0070, lr_0 = 9.6014e-04
Loss = 2.4599e-02, PNorm = 36.3841, GNorm = 6.9996, lr_0 = 9.5885e-04
Loss = 2.1836e-02, PNorm = 36.4110, GNorm = 1.9780, lr_0 = 9.5756e-04
Loss = 2.0709e-02, PNorm = 36.4225, GNorm = 2.6262, lr_0 = 9.5628e-04
Loss = 2.3768e-02, PNorm = 36.4430, GNorm = 1.9338, lr_0 = 9.5499e-04
Loss = 2.7419e-02, PNorm = 36.4727, GNorm = 2.7690, lr_0 = 9.5371e-04
Validation rmse = 0.977841
Validation R2 = 0.726972
Epoch 3
Train function
Loss = 2.6252e-02, PNorm = 36.5014, GNorm = 1.9412, lr_0 = 9.5230e-04
Loss = 2.5138e-02, PNorm = 36.5337, GNorm = 2.2328, lr_0 = 9.5103e-04
Loss = 2.3920e-02, PNorm = 36.5558, GNorm = 2.3808, lr_0 = 9.4975e-04
Loss = 2.0296e-02, PNorm = 36.5882, GNorm = 2.0202, lr_0 = 9.4848e-04
Loss = 2.3356e-02, PNorm = 36.6175, GNorm = 7.2636, lr_0 = 9.4720e-04
Loss = 2.4131e-02, PNorm = 36.6424, GNorm = 3.5325, lr_0 = 9.4593e-04
Loss = 2.4970e-02, PNorm = 36.6701, GNorm = 3.4013, lr_0 = 9.4466e-04
Loss = 2.1653e-02, PNorm = 36.6960, GNorm = 2.3509, lr_0 = 9.4340e-04
Loss = 2.4444e-02, PNorm = 36.7262, GNorm = 4.4179, lr_0 = 9.4213e-04
Loss = 2.4806e-02, PNorm = 36.7547, GNorm = 2.3905, lr_0 = 9.4087e-04
Loss = 2.5216e-02, PNorm = 36.7941, GNorm = 1.7881, lr_0 = 9.3960e-04
Loss = 2.0859e-02, PNorm = 36.8014, GNorm = 4.7985, lr_0 = 9.3834e-04
Loss = 2.3049e-02, PNorm = 36.8132, GNorm = 1.9658, lr_0 = 9.3708e-04
Loss = 2.1652e-02, PNorm = 36.8405, GNorm = 5.0106, lr_0 = 9.3583e-04
Loss = 2.5225e-02, PNorm = 36.8651, GNorm = 3.3275, lr_0 = 9.3457e-04
Loss = 2.2527e-02, PNorm = 36.8768, GNorm = 3.6952, lr_0 = 9.3332e-04
Loss = 2.5430e-02, PNorm = 36.9141, GNorm = 2.5605, lr_0 = 9.3206e-04
Loss = 2.5085e-02, PNorm = 36.9431, GNorm = 3.0538, lr_0 = 9.3081e-04
Loss = 2.1489e-02, PNorm = 36.9822, GNorm = 1.0822, lr_0 = 9.2957e-04
Loss = 2.0246e-02, PNorm = 37.0049, GNorm = 1.4449, lr_0 = 9.2832e-04
Loss = 2.4848e-02, PNorm = 37.0289, GNorm = 2.4385, lr_0 = 9.2707e-04
Loss = 1.9286e-02, PNorm = 37.0550, GNorm = 1.6713, lr_0 = 9.2583e-04
Loss = 2.1958e-02, PNorm = 37.0729, GNorm = 2.7813, lr_0 = 9.2459e-04
Validation rmse = 1.291545
Validation R2 = 0.523690
Epoch 4
Train function
Loss = 1.9835e-02, PNorm = 37.0959, GNorm = 2.9781, lr_0 = 9.2322e-04
Loss = 2.0219e-02, PNorm = 37.1168, GNorm = 3.4585, lr_0 = 9.2198e-04
Loss = 2.0571e-02, PNorm = 37.1143, GNorm = 2.0653, lr_0 = 9.2075e-04
Loss = 2.8146e-02, PNorm = 37.1490, GNorm = 1.9660, lr_0 = 9.1951e-04
Loss = 2.2030e-02, PNorm = 37.1854, GNorm = 2.9097, lr_0 = 9.1828e-04
Loss = 2.1069e-02, PNorm = 37.2160, GNorm = 1.4991, lr_0 = 9.1705e-04
Loss = 2.8016e-02, PNorm = 37.2555, GNorm = 1.5159, lr_0 = 9.1581e-04
Loss = 2.4968e-02, PNorm = 37.2976, GNorm = 3.9532, lr_0 = 9.1459e-04
Loss = 2.4913e-02, PNorm = 37.3101, GNorm = 7.5723, lr_0 = 9.1336e-04
Loss = 2.0956e-02, PNorm = 37.3395, GNorm = 2.2635, lr_0 = 9.1213e-04
Loss = 2.2774e-02, PNorm = 37.3739, GNorm = 4.1533, lr_0 = 9.1091e-04
Loss = 2.3007e-02, PNorm = 37.3952, GNorm = 2.2860, lr_0 = 9.0969e-04
Loss = 2.1581e-02, PNorm = 37.4154, GNorm = 1.5350, lr_0 = 9.0847e-04
Loss = 2.3504e-02, PNorm = 37.4435, GNorm = 2.2835, lr_0 = 9.0725e-04
Loss = 2.2587e-02, PNorm = 37.4818, GNorm = 2.4701, lr_0 = 9.0603e-04
Loss = 2.1851e-02, PNorm = 37.5141, GNorm = 3.3805, lr_0 = 9.0481e-04
Loss = 2.0886e-02, PNorm = 37.5382, GNorm = 1.6605, lr_0 = 9.0360e-04
Loss = 2.4049e-02, PNorm = 37.5543, GNorm = 2.2253, lr_0 = 9.0239e-04
Loss = 2.4958e-02, PNorm = 37.5818, GNorm = 2.1872, lr_0 = 9.0118e-04
Loss = 2.1958e-02, PNorm = 37.5934, GNorm = 2.6901, lr_0 = 8.9997e-04
Loss = 2.2557e-02, PNorm = 37.6056, GNorm = 1.7038, lr_0 = 8.9876e-04
Loss = 2.0188e-02, PNorm = 37.6094, GNorm = 2.7795, lr_0 = 8.9756e-04
Loss = 2.2707e-02, PNorm = 37.6268, GNorm = 3.0837, lr_0 = 8.9635e-04
Loss = 2.3056e-02, PNorm = 37.6525, GNorm = 2.0347, lr_0 = 8.9515e-04
Validation rmse = 1.299384
Validation R2 = 0.517891
Epoch 5
Train function
Loss = 2.3546e-02, PNorm = 37.6858, GNorm = 1.6487, lr_0 = 8.9395e-04
Loss = 2.3908e-02, PNorm = 37.6905, GNorm = 2.7573, lr_0 = 8.9275e-04
Loss = 2.2054e-02, PNorm = 37.7129, GNorm = 1.3324, lr_0 = 8.9155e-04
Loss = 2.1332e-02, PNorm = 37.7398, GNorm = 3.6594, lr_0 = 8.9035e-04
Loss = 1.9344e-02, PNorm = 37.7643, GNorm = 1.8155, lr_0 = 8.8916e-04
Loss = 2.1325e-02, PNorm = 37.8004, GNorm = 2.4802, lr_0 = 8.8797e-04
Loss = 2.4100e-02, PNorm = 37.8484, GNorm = 2.1114, lr_0 = 8.8677e-04
Loss = 2.4942e-02, PNorm = 37.8678, GNorm = 2.9281, lr_0 = 8.8559e-04
Loss = 2.0341e-02, PNorm = 37.8977, GNorm = 2.2167, lr_0 = 8.8440e-04
Loss = 2.3787e-02, PNorm = 37.9271, GNorm = 1.6164, lr_0 = 8.8321e-04
Loss = 1.7245e-02, PNorm = 37.9488, GNorm = 2.9648, lr_0 = 8.8203e-04
Loss = 2.5568e-02, PNorm = 37.9659, GNorm = 1.8360, lr_0 = 8.8084e-04
Loss = 2.3099e-02, PNorm = 37.9875, GNorm = 1.6510, lr_0 = 8.7966e-04
Loss = 2.2196e-02, PNorm = 38.0192, GNorm = 3.4947, lr_0 = 8.7848e-04
Loss = 2.1976e-02, PNorm = 38.0428, GNorm = 1.7969, lr_0 = 8.7730e-04
Loss = 1.8822e-02, PNorm = 38.0703, GNorm = 3.0943, lr_0 = 8.7612e-04
Loss = 2.6063e-02, PNorm = 38.0923, GNorm = 2.9644, lr_0 = 8.7495e-04
Loss = 2.5143e-02, PNorm = 38.1375, GNorm = 2.3101, lr_0 = 8.7377e-04
Loss = 2.2214e-02, PNorm = 38.1602, GNorm = 2.5448, lr_0 = 8.7260e-04
Loss = 1.7521e-02, PNorm = 38.1686, GNorm = 2.0356, lr_0 = 8.7143e-04
Loss = 2.3392e-02, PNorm = 38.1856, GNorm = 2.5110, lr_0 = 8.7026e-04
Loss = 2.0995e-02, PNorm = 38.2278, GNorm = 2.3267, lr_0 = 8.6909e-04
Loss = 2.3780e-02, PNorm = 38.2394, GNorm = 3.9663, lr_0 = 8.6793e-04
Validation rmse = 1.015607
Validation R2 = 0.705475
Epoch 6
Train function
Loss = 1.9434e-02, PNorm = 38.2490, GNorm = 2.9078, lr_0 = 8.6665e-04
Loss = 2.2159e-02, PNorm = 38.2899, GNorm = 2.6535, lr_0 = 8.6548e-04
Loss = 2.1166e-02, PNorm = 38.3149, GNorm = 2.8090, lr_0 = 8.6432e-04
Loss = 2.2498e-02, PNorm = 38.3481, GNorm = 3.4617, lr_0 = 8.6316e-04
Loss = 2.1425e-02, PNorm = 38.3736, GNorm = 1.2455, lr_0 = 8.6201e-04
Loss = 1.8191e-02, PNorm = 38.3911, GNorm = 2.5087, lr_0 = 8.6085e-04
Loss = 1.9064e-02, PNorm = 38.4038, GNorm = 3.1157, lr_0 = 8.5969e-04
Loss = 2.0998e-02, PNorm = 38.4234, GNorm = 1.9028, lr_0 = 8.5854e-04
Loss = 2.1579e-02, PNorm = 38.4535, GNorm = 2.0195, lr_0 = 8.5739e-04
Loss = 2.0385e-02, PNorm = 38.4763, GNorm = 3.3386, lr_0 = 8.5624e-04
Loss = 2.1430e-02, PNorm = 38.5002, GNorm = 1.5952, lr_0 = 8.5509e-04
Loss = 2.5244e-02, PNorm = 38.5372, GNorm = 2.0007, lr_0 = 8.5394e-04
Loss = 2.0832e-02, PNorm = 38.5606, GNorm = 2.6244, lr_0 = 8.5280e-04
Loss = 1.9360e-02, PNorm = 38.5758, GNorm = 4.4346, lr_0 = 8.5165e-04
Loss = 2.2855e-02, PNorm = 38.6131, GNorm = 1.8916, lr_0 = 8.5051e-04
Loss = 2.2883e-02, PNorm = 38.6506, GNorm = 3.1129, lr_0 = 8.4937e-04
Loss = 2.2101e-02, PNorm = 38.6697, GNorm = 1.7866, lr_0 = 8.4823e-04
Loss = 2.3141e-02, PNorm = 38.6703, GNorm = 4.6657, lr_0 = 8.4709e-04
Loss = 1.9847e-02, PNorm = 38.6962, GNorm = 4.4631, lr_0 = 8.4595e-04
Loss = 1.9891e-02, PNorm = 38.7363, GNorm = 1.5554, lr_0 = 8.4482e-04
Loss = 2.4255e-02, PNorm = 38.7729, GNorm = 2.0485, lr_0 = 8.4369e-04
Loss = 2.4849e-02, PNorm = 38.7975, GNorm = 1.8436, lr_0 = 8.4255e-04
Loss = 2.2643e-02, PNorm = 38.8256, GNorm = 1.7598, lr_0 = 8.4142e-04
Validation rmse = 1.556827
Validation R2 = 0.307929
Epoch 7
Train function
Loss = 1.5281e-02, PNorm = 38.8614, GNorm = 1.6663, lr_0 = 8.4018e-04
Loss = 1.9928e-02, PNorm = 38.8818, GNorm = 2.1098, lr_0 = 8.3905e-04
Loss = 2.2130e-02, PNorm = 38.9251, GNorm = 1.7829, lr_0 = 8.3793e-04
Loss = 2.0512e-02, PNorm = 38.9459, GNorm = 3.1090, lr_0 = 8.3680e-04
Loss = 2.0896e-02, PNorm = 38.9677, GNorm = 2.2646, lr_0 = 8.3568e-04
Loss = 2.4326e-02, PNorm = 39.0078, GNorm = 4.0157, lr_0 = 8.3456e-04
Loss = 1.9466e-02, PNorm = 39.0304, GNorm = 1.9981, lr_0 = 8.3344e-04
Loss = 2.0661e-02, PNorm = 39.0804, GNorm = 2.0041, lr_0 = 8.3232e-04
Loss = 2.1953e-02, PNorm = 39.1095, GNorm = 2.6127, lr_0 = 8.3121e-04
Loss = 2.2561e-02, PNorm = 39.1323, GNorm = 1.8113, lr_0 = 8.3009e-04
Loss = 2.5641e-02, PNorm = 39.1692, GNorm = 4.6249, lr_0 = 8.2898e-04
Loss = 2.1149e-02, PNorm = 39.1972, GNorm = 2.3997, lr_0 = 8.2786e-04
Loss = 2.1508e-02, PNorm = 39.2196, GNorm = 2.1039, lr_0 = 8.2675e-04
Loss = 2.3491e-02, PNorm = 39.2645, GNorm = 2.1025, lr_0 = 8.2564e-04
Loss = 2.2727e-02, PNorm = 39.3088, GNorm = 2.5434, lr_0 = 8.2454e-04
Loss = 2.0571e-02, PNorm = 39.3202, GNorm = 2.6311, lr_0 = 8.2343e-04
Loss = 1.9890e-02, PNorm = 39.3363, GNorm = 5.4187, lr_0 = 8.2233e-04
Loss = 2.0416e-02, PNorm = 39.3604, GNorm = 3.8399, lr_0 = 8.2122e-04
Loss = 1.7490e-02, PNorm = 39.3910, GNorm = 1.7899, lr_0 = 8.2012e-04
Loss = 1.9526e-02, PNorm = 39.4009, GNorm = 4.5933, lr_0 = 8.1902e-04
Loss = 2.2158e-02, PNorm = 39.4170, GNorm = 1.9180, lr_0 = 8.1792e-04
Loss = 2.1617e-02, PNorm = 39.4483, GNorm = 2.6235, lr_0 = 8.1682e-04
Loss = 2.0892e-02, PNorm = 39.4609, GNorm = 2.6973, lr_0 = 8.1573e-04
Loss = 2.0095e-02, PNorm = 39.4790, GNorm = 2.1737, lr_0 = 8.1463e-04
Validation rmse = 1.308931
Validation R2 = 0.510781
Epoch 8
Train function
Loss = 1.9727e-02, PNorm = 39.4939, GNorm = 3.6738, lr_0 = 8.1343e-04
Loss = 2.1214e-02, PNorm = 39.5400, GNorm = 3.5863, lr_0 = 8.1234e-04
Loss = 1.9409e-02, PNorm = 39.5639, GNorm = 1.4786, lr_0 = 8.1125e-04
Loss = 2.0729e-02, PNorm = 39.5896, GNorm = 2.2117, lr_0 = 8.1016e-04
Loss = 2.1350e-02, PNorm = 39.6280, GNorm = 3.4926, lr_0 = 8.0907e-04
Loss = 1.9787e-02, PNorm = 39.6545, GNorm = 1.5964, lr_0 = 8.0799e-04
Loss = 2.2233e-02, PNorm = 39.6759, GNorm = 2.1265, lr_0 = 8.0690e-04
Loss = 2.2065e-02, PNorm = 39.7158, GNorm = 2.4353, lr_0 = 8.0582e-04
Loss = 2.2683e-02, PNorm = 39.7487, GNorm = 2.0150, lr_0 = 8.0474e-04
Loss = 1.8890e-02, PNorm = 39.7742, GNorm = 1.9659, lr_0 = 8.0366e-04
Loss = 1.8465e-02, PNorm = 39.7958, GNorm = 1.8170, lr_0 = 8.0258e-04
Loss = 2.0502e-02, PNorm = 39.8121, GNorm = 2.3786, lr_0 = 8.0151e-04
Loss = 2.1609e-02, PNorm = 39.8367, GNorm = 2.4584, lr_0 = 8.0043e-04
Loss = 2.0634e-02, PNorm = 39.8676, GNorm = 2.1030, lr_0 = 7.9936e-04
Loss = 1.8627e-02, PNorm = 39.8972, GNorm = 1.6366, lr_0 = 7.9828e-04
Loss = 2.2507e-02, PNorm = 39.9382, GNorm = 2.7509, lr_0 = 7.9721e-04
Loss = 2.2310e-02, PNorm = 39.9728, GNorm = 3.8665, lr_0 = 7.9614e-04
Loss = 2.1931e-02, PNorm = 40.0127, GNorm = 3.2277, lr_0 = 7.9508e-04
Loss = 2.1882e-02, PNorm = 40.0360, GNorm = 2.5261, lr_0 = 7.9401e-04
Loss = 2.2156e-02, PNorm = 40.0562, GNorm = 3.5839, lr_0 = 7.9294e-04
Loss = 2.0202e-02, PNorm = 40.0777, GNorm = 2.2660, lr_0 = 7.9188e-04
Loss = 1.8515e-02, PNorm = 40.1033, GNorm = 2.2547, lr_0 = 7.9082e-04
Loss = 1.9986e-02, PNorm = 40.1312, GNorm = 2.9874, lr_0 = 7.8976e-04
Validation rmse = 1.711820
Validation R2 = 0.163268
Epoch 9
Train function
Loss = 1.9404e-02, PNorm = 40.1617, GNorm = 2.4983, lr_0 = 7.8859e-04
Loss = 1.9118e-02, PNorm = 40.1888, GNorm = 2.4896, lr_0 = 7.8753e-04
Loss = 1.7846e-02, PNorm = 40.2129, GNorm = 2.6980, lr_0 = 7.8648e-04
Loss = 1.7729e-02, PNorm = 40.2415, GNorm = 1.3054, lr_0 = 7.8542e-04
Loss = 2.0038e-02, PNorm = 40.2794, GNorm = 1.7405, lr_0 = 7.8437e-04
Loss = 2.0633e-02, PNorm = 40.3208, GNorm = 4.2627, lr_0 = 7.8331e-04
Loss = 1.9390e-02, PNorm = 40.3393, GNorm = 2.5232, lr_0 = 7.8226e-04
Loss = 2.0795e-02, PNorm = 40.3923, GNorm = 2.5452, lr_0 = 7.8121e-04
Loss = 2.0620e-02, PNorm = 40.4396, GNorm = 1.7312, lr_0 = 7.8017e-04
Loss = 2.5928e-02, PNorm = 40.4656, GNorm = 4.2496, lr_0 = 7.7912e-04
Loss = 1.9459e-02, PNorm = 40.4846, GNorm = 2.6694, lr_0 = 7.7807e-04
Loss = 2.1968e-02, PNorm = 40.5237, GNorm = 3.4898, lr_0 = 7.7703e-04
Loss = 2.1346e-02, PNorm = 40.5613, GNorm = 1.4487, lr_0 = 7.7599e-04
Loss = 2.0266e-02, PNorm = 40.5843, GNorm = 3.0250, lr_0 = 7.7495e-04
Loss = 2.2102e-02, PNorm = 40.6108, GNorm = 1.6338, lr_0 = 7.7391e-04
Loss = 2.0490e-02, PNorm = 40.6370, GNorm = 1.7307, lr_0 = 7.7287e-04
Loss = 1.9933e-02, PNorm = 40.6611, GNorm = 1.2824, lr_0 = 7.7183e-04
Loss = 1.9602e-02, PNorm = 40.6812, GNorm = 1.9697, lr_0 = 7.7079e-04
Loss = 1.9227e-02, PNorm = 40.7138, GNorm = 1.9489, lr_0 = 7.6976e-04
Loss = 2.0538e-02, PNorm = 40.7284, GNorm = 1.6676, lr_0 = 7.6873e-04
Loss = 2.3735e-02, PNorm = 40.7701, GNorm = 2.3388, lr_0 = 7.6770e-04
Loss = 1.8627e-02, PNorm = 40.7983, GNorm = 1.5828, lr_0 = 7.6667e-04
Loss = 2.0228e-02, PNorm = 40.8127, GNorm = 2.1722, lr_0 = 7.6564e-04
Loss = 2.1874e-02, PNorm = 40.8282, GNorm = 1.7906, lr_0 = 7.6461e-04
Validation rmse = 1.700101
Validation R2 = 0.174685
Epoch 10
Train function
Loss = 1.8825e-02, PNorm = 40.8554, GNorm = 2.5017, lr_0 = 7.6358e-04
Loss = 2.0205e-02, PNorm = 40.8812, GNorm = 1.5661, lr_0 = 7.6256e-04
Loss = 1.8263e-02, PNorm = 40.9039, GNorm = 1.6340, lr_0 = 7.6154e-04
Loss = 1.8825e-02, PNorm = 40.9402, GNorm = 2.6986, lr_0 = 7.6052e-04
Loss = 1.8613e-02, PNorm = 40.9748, GNorm = 2.0239, lr_0 = 7.5949e-04
Loss = 2.0836e-02, PNorm = 41.0104, GNorm = 6.7058, lr_0 = 7.5848e-04
Loss = 2.1298e-02, PNorm = 41.0481, GNorm = 2.0503, lr_0 = 7.5746e-04
Loss = 1.9330e-02, PNorm = 41.0938, GNorm = 2.4832, lr_0 = 7.5644e-04
Loss = 2.2083e-02, PNorm = 41.1458, GNorm = 1.9663, lr_0 = 7.5543e-04
Loss = 1.9561e-02, PNorm = 41.1908, GNorm = 2.0042, lr_0 = 7.5441e-04
Loss = 2.1334e-02, PNorm = 41.2311, GNorm = 2.7274, lr_0 = 7.5340e-04
Loss = 1.7422e-02, PNorm = 41.2636, GNorm = 2.2927, lr_0 = 7.5239e-04
Loss = 2.0074e-02, PNorm = 41.2908, GNorm = 2.9326, lr_0 = 7.5138e-04
Loss = 2.1254e-02, PNorm = 41.3163, GNorm = 2.5927, lr_0 = 7.5037e-04
Loss = 1.6986e-02, PNorm = 41.3454, GNorm = 2.2783, lr_0 = 7.4937e-04
Loss = 2.2001e-02, PNorm = 41.3848, GNorm = 2.7770, lr_0 = 7.4836e-04
Loss = 1.8221e-02, PNorm = 41.4045, GNorm = 3.0151, lr_0 = 7.4736e-04
Loss = 2.0876e-02, PNorm = 41.4258, GNorm = 2.8996, lr_0 = 7.4635e-04
Loss = 2.0549e-02, PNorm = 41.4665, GNorm = 2.5960, lr_0 = 7.4535e-04
Loss = 2.2818e-02, PNorm = 41.4945, GNorm = 4.9866, lr_0 = 7.4435e-04
Loss = 1.8866e-02, PNorm = 41.5293, GNorm = 2.3638, lr_0 = 7.4335e-04
Loss = 2.1196e-02, PNorm = 41.5533, GNorm = 2.2622, lr_0 = 7.4236e-04
Loss = 2.0041e-02, PNorm = 41.5766, GNorm = 1.6341, lr_0 = 7.4136e-04
Validation rmse = 1.673577
Validation R2 = 0.200237
Epoch 11
Train function
Loss = 1.9043e-02, PNorm = 41.6020, GNorm = 2.8772, lr_0 = 7.4027e-04
Loss = 1.7368e-02, PNorm = 41.6215, GNorm = 1.6129, lr_0 = 7.3927e-04
Loss = 2.0552e-02, PNorm = 41.6526, GNorm = 1.9895, lr_0 = 7.3828e-04
Loss = 1.8790e-02, PNorm = 41.6922, GNorm = 2.1452, lr_0 = 7.3729e-04
Loss = 1.8816e-02, PNorm = 41.7130, GNorm = 3.3984, lr_0 = 7.3630e-04
Loss = 1.9167e-02, PNorm = 41.7423, GNorm = 1.9022, lr_0 = 7.3531e-04
Loss = 2.1817e-02, PNorm = 41.7736, GNorm = 3.0985, lr_0 = 7.3433e-04
Loss = 2.1517e-02, PNorm = 41.8078, GNorm = 6.1418, lr_0 = 7.3334e-04
Loss = 1.8767e-02, PNorm = 41.8358, GNorm = 4.4530, lr_0 = 7.3236e-04
Loss = 2.1349e-02, PNorm = 41.8774, GNorm = 3.2951, lr_0 = 7.3137e-04
Loss = 2.0237e-02, PNorm = 41.9199, GNorm = 3.2120, lr_0 = 7.3039e-04
Loss = 1.7884e-02, PNorm = 41.9532, GNorm = 1.8818, lr_0 = 7.2941e-04
Loss = 2.1410e-02, PNorm = 41.9862, GNorm = 2.4627, lr_0 = 7.2843e-04
Loss = 1.9725e-02, PNorm = 42.0248, GNorm = 2.2430, lr_0 = 7.2746e-04
Loss = 1.9312e-02, PNorm = 42.0439, GNorm = 2.3071, lr_0 = 7.2648e-04
Loss = 1.8182e-02, PNorm = 42.0667, GNorm = 1.7979, lr_0 = 7.2551e-04
Loss = 2.1034e-02, PNorm = 42.0772, GNorm = 2.5020, lr_0 = 7.2453e-04
Loss = 2.1356e-02, PNorm = 42.1132, GNorm = 3.4445, lr_0 = 7.2356e-04
Loss = 1.7206e-02, PNorm = 42.1409, GNorm = 3.7109, lr_0 = 7.2259e-04
Loss = 1.8744e-02, PNorm = 42.1674, GNorm = 3.2390, lr_0 = 7.2162e-04
Loss = 1.9975e-02, PNorm = 42.1934, GNorm = 2.3259, lr_0 = 7.2065e-04
Loss = 1.8859e-02, PNorm = 42.2088, GNorm = 2.4321, lr_0 = 7.1969e-04
Loss = 2.0974e-02, PNorm = 42.2411, GNorm = 1.5475, lr_0 = 7.1872e-04
Loss = 2.1389e-02, PNorm = 42.2598, GNorm = 3.5729, lr_0 = 7.1776e-04
Loss = 2.2787e-01, PNorm = 42.2628, GNorm = 9.9120, lr_0 = 7.1766e-04
Validation rmse = 1.864321
Validation R2 = 0.007543
Epoch 12
Train function
Loss = 2.0955e-02, PNorm = 42.3085, GNorm = 1.7249, lr_0 = 7.1670e-04
Loss = 1.9199e-02, PNorm = 42.3484, GNorm = 2.9398, lr_0 = 7.1573e-04
Loss = 1.7438e-02, PNorm = 42.3840, GNorm = 2.8593, lr_0 = 7.1477e-04
Loss = 1.8349e-02, PNorm = 42.4159, GNorm = 2.0835, lr_0 = 7.1382e-04
Loss = 1.7704e-02, PNorm = 42.4293, GNorm = 2.2889, lr_0 = 7.1286e-04
Loss = 1.8928e-02, PNorm = 42.4625, GNorm = 1.7207, lr_0 = 7.1190e-04
Loss = 2.0289e-02, PNorm = 42.5004, GNorm = 2.4570, lr_0 = 7.1095e-04
Loss = 1.8810e-02, PNorm = 42.5283, GNorm = 3.5253, lr_0 = 7.0999e-04
Loss = 2.2815e-02, PNorm = 42.5548, GNorm = 2.9278, lr_0 = 7.0904e-04
Loss = 1.9412e-02, PNorm = 42.5802, GNorm = 2.9300, lr_0 = 7.0809e-04
Loss = 2.0209e-02, PNorm = 42.6086, GNorm = 1.3476, lr_0 = 7.0714e-04
Loss = 2.1498e-02, PNorm = 42.6355, GNorm = 1.4913, lr_0 = 7.0619e-04
Loss = 1.8184e-02, PNorm = 42.6800, GNorm = 3.0578, lr_0 = 7.0524e-04
Loss = 1.7301e-02, PNorm = 42.6975, GNorm = 2.1354, lr_0 = 7.0430e-04
Loss = 1.9156e-02, PNorm = 42.7352, GNorm = 1.7197, lr_0 = 7.0335e-04
Loss = 1.8242e-02, PNorm = 42.7586, GNorm = 2.5448, lr_0 = 7.0241e-04
Loss = 1.9422e-02, PNorm = 42.7939, GNorm = 1.9639, lr_0 = 7.0146e-04
Loss = 1.8065e-02, PNorm = 42.8262, GNorm = 1.9595, lr_0 = 7.0052e-04
Loss = 1.9831e-02, PNorm = 42.8624, GNorm = 2.5233, lr_0 = 6.9958e-04
Loss = 2.1238e-02, PNorm = 42.8854, GNorm = 2.4926, lr_0 = 6.9865e-04
Loss = 1.6537e-02, PNorm = 42.9137, GNorm = 2.0839, lr_0 = 6.9771e-04
Loss = 1.6364e-02, PNorm = 42.9364, GNorm = 1.4468, lr_0 = 6.9677e-04
Loss = 1.8208e-02, PNorm = 42.9557, GNorm = 1.9674, lr_0 = 6.9584e-04
Validation rmse = 2.247132
Validation R2 = -0.441874
Epoch 13
Train function
Loss = 1.9706e-02, PNorm = 42.9874, GNorm = 2.2439, lr_0 = 6.9481e-04
Loss = 2.0101e-02, PNorm = 43.0368, GNorm = 3.9834, lr_0 = 6.9388e-04
Loss = 1.8256e-02, PNorm = 43.0690, GNorm = 2.5609, lr_0 = 6.9295e-04
Loss = 1.7366e-02, PNorm = 43.0983, GNorm = 2.0410, lr_0 = 6.9202e-04
Loss = 1.7673e-02, PNorm = 43.1194, GNorm = 2.1293, lr_0 = 6.9109e-04
Loss = 1.9061e-02, PNorm = 43.1549, GNorm = 2.7266, lr_0 = 6.9016e-04
Loss = 1.6288e-02, PNorm = 43.1671, GNorm = 1.9134, lr_0 = 6.8924e-04
Loss = 1.9446e-02, PNorm = 43.1957, GNorm = 3.1992, lr_0 = 6.8831e-04
Loss = 1.8218e-02, PNorm = 43.2334, GNorm = 2.4143, lr_0 = 6.8739e-04
Loss = 1.8894e-02, PNorm = 43.2644, GNorm = 1.6960, lr_0 = 6.8646e-04
Loss = 1.8446e-02, PNorm = 43.2948, GNorm = 2.0729, lr_0 = 6.8554e-04
Loss = 1.9208e-02, PNorm = 43.3357, GNorm = 1.8231, lr_0 = 6.8462e-04
Loss = 1.7775e-02, PNorm = 43.3638, GNorm = 3.0277, lr_0 = 6.8371e-04
Loss = 2.1359e-02, PNorm = 43.4003, GNorm = 3.3670, lr_0 = 6.8279e-04
Loss = 1.8890e-02, PNorm = 43.4376, GNorm = 2.0137, lr_0 = 6.8187e-04
Loss = 1.8757e-02, PNorm = 43.4596, GNorm = 1.7632, lr_0 = 6.8096e-04
Loss = 1.6389e-02, PNorm = 43.4833, GNorm = 3.6358, lr_0 = 6.8004e-04
Loss = 1.6558e-02, PNorm = 43.5117, GNorm = 2.5012, lr_0 = 6.7913e-04
Loss = 1.7958e-02, PNorm = 43.5389, GNorm = 2.1161, lr_0 = 6.7822e-04
Loss = 1.7477e-02, PNorm = 43.5622, GNorm = 1.7037, lr_0 = 6.7731e-04
Loss = 2.1553e-02, PNorm = 43.5965, GNorm = 4.8472, lr_0 = 6.7640e-04
Loss = 2.0805e-02, PNorm = 43.6229, GNorm = 2.4782, lr_0 = 6.7549e-04
Loss = 2.0246e-02, PNorm = 43.6484, GNorm = 2.8009, lr_0 = 6.7459e-04
Validation rmse = 1.521162
Validation R2 = 0.339274
Epoch 14
Train function
Loss = 1.5891e-02, PNorm = 43.6912, GNorm = 1.7423, lr_0 = 6.7359e-04
Loss = 1.7679e-02, PNorm = 43.7184, GNorm = 3.6756, lr_0 = 6.7269e-04
Loss = 1.6830e-02, PNorm = 43.7483, GNorm = 1.6780, lr_0 = 6.7179e-04
Loss = 2.1404e-02, PNorm = 43.7876, GNorm = 2.8674, lr_0 = 6.7088e-04
Loss = 1.5282e-02, PNorm = 43.8275, GNorm = 2.5325, lr_0 = 6.6998e-04
Loss = 1.7647e-02, PNorm = 43.8464, GNorm = 2.0118, lr_0 = 6.6908e-04
Loss = 1.6576e-02, PNorm = 43.8666, GNorm = 1.6971, lr_0 = 6.6819e-04
Loss = 2.2196e-02, PNorm = 43.8861, GNorm = 3.6208, lr_0 = 6.6729e-04
Loss = 1.9116e-02, PNorm = 43.9047, GNorm = 1.8417, lr_0 = 6.6640e-04
Loss = 1.8106e-02, PNorm = 43.9439, GNorm = 2.7280, lr_0 = 6.6550e-04
Loss = 1.8903e-02, PNorm = 43.9777, GNorm = 3.1359, lr_0 = 6.6461e-04
Loss = 1.9545e-02, PNorm = 44.0244, GNorm = 5.2063, lr_0 = 6.6372e-04
Loss = 1.8859e-02, PNorm = 44.0500, GNorm = 2.5475, lr_0 = 6.6283e-04
Loss = 1.8609e-02, PNorm = 44.0854, GNorm = 2.3375, lr_0 = 6.6194e-04
Loss = 1.8610e-02, PNorm = 44.1145, GNorm = 1.9389, lr_0 = 6.6105e-04
Loss = 1.5707e-02, PNorm = 44.1510, GNorm = 2.4612, lr_0 = 6.6016e-04
Loss = 1.7663e-02, PNorm = 44.1746, GNorm = 1.5346, lr_0 = 6.5928e-04
Loss = 1.8480e-02, PNorm = 44.2065, GNorm = 1.5810, lr_0 = 6.5839e-04
Loss = 1.6888e-02, PNorm = 44.2363, GNorm = 3.5616, lr_0 = 6.5751e-04
Loss = 1.8878e-02, PNorm = 44.2621, GNorm = 1.6632, lr_0 = 6.5663e-04
Loss = 1.7735e-02, PNorm = 44.2887, GNorm = 2.8899, lr_0 = 6.5574e-04
Loss = 1.9585e-02, PNorm = 44.3128, GNorm = 2.4675, lr_0 = 6.5486e-04
Loss = 1.8593e-02, PNorm = 44.3356, GNorm = 2.7135, lr_0 = 6.5399e-04
Loss = 1.6058e-02, PNorm = 44.3568, GNorm = 3.9997, lr_0 = 6.5311e-04
Validation rmse = 1.786111
Validation R2 = 0.089066
Epoch 15
Train function
Loss = 1.7890e-02, PNorm = 44.3796, GNorm = 1.6843, lr_0 = 6.5223e-04
Loss = 1.8436e-02, PNorm = 44.4135, GNorm = 3.1699, lr_0 = 6.5136e-04
Loss = 1.7367e-02, PNorm = 44.4563, GNorm = 3.8464, lr_0 = 6.5048e-04
Loss = 1.8804e-02, PNorm = 44.4833, GNorm = 3.0124, lr_0 = 6.4961e-04
Loss = 1.8060e-02, PNorm = 44.5189, GNorm = 2.3084, lr_0 = 6.4874e-04
Loss = 2.0185e-02, PNorm = 44.5487, GNorm = 2.5307, lr_0 = 6.4787e-04
Loss = 1.7848e-02, PNorm = 44.5828, GNorm = 3.0629, lr_0 = 6.4700e-04
Loss = 1.5528e-02, PNorm = 44.6068, GNorm = 2.1922, lr_0 = 6.4613e-04
Loss = 1.5924e-02, PNorm = 44.6308, GNorm = 2.8306, lr_0 = 6.4526e-04
Loss = 1.6396e-02, PNorm = 44.6524, GNorm = 2.1143, lr_0 = 6.4440e-04
Loss = 1.6090e-02, PNorm = 44.6814, GNorm = 3.6566, lr_0 = 6.4353e-04
Loss = 1.6015e-02, PNorm = 44.6996, GNorm = 5.4584, lr_0 = 6.4267e-04
Loss = 1.6983e-02, PNorm = 44.7321, GNorm = 3.5821, lr_0 = 6.4181e-04
Loss = 1.8163e-02, PNorm = 44.7487, GNorm = 3.3865, lr_0 = 6.4095e-04
Loss = 1.7603e-02, PNorm = 44.7835, GNorm = 2.1770, lr_0 = 6.4009e-04
Loss = 1.7960e-02, PNorm = 44.8138, GNorm = 2.8420, lr_0 = 6.3923e-04
Loss = 2.0076e-02, PNorm = 44.8382, GNorm = 1.7593, lr_0 = 6.3837e-04
Loss = 2.1687e-02, PNorm = 44.8825, GNorm = 2.1858, lr_0 = 6.3751e-04
Loss = 1.8339e-02, PNorm = 44.9084, GNorm = 1.9417, lr_0 = 6.3666e-04
Loss = 1.7142e-02, PNorm = 44.9417, GNorm = 2.1822, lr_0 = 6.3580e-04
Loss = 1.7105e-02, PNorm = 44.9669, GNorm = 2.6644, lr_0 = 6.3495e-04
Loss = 1.5499e-02, PNorm = 44.9953, GNorm = 2.5150, lr_0 = 6.3410e-04
Loss = 1.7019e-02, PNorm = 45.0173, GNorm = 1.9934, lr_0 = 6.3325e-04
Validation rmse = 1.852295
Validation R2 = 0.020306
Epoch 16
Train function
Loss = 1.8389e-02, PNorm = 45.0357, GNorm = 3.4582, lr_0 = 6.3231e-04
Loss = 1.4495e-02, PNorm = 45.0676, GNorm = 1.8936, lr_0 = 6.3147e-04
Loss = 1.3144e-02, PNorm = 45.0962, GNorm = 2.1450, lr_0 = 6.3062e-04
Loss = 1.7027e-02, PNorm = 45.1250, GNorm = 2.3400, lr_0 = 6.2977e-04
Loss = 1.6849e-02, PNorm = 45.1575, GNorm = 2.0096, lr_0 = 6.2893e-04
Loss = 1.7345e-02, PNorm = 45.1854, GNorm = 2.7146, lr_0 = 6.2808e-04
Loss = 1.5647e-02, PNorm = 45.2160, GNorm = 2.3063, lr_0 = 6.2724e-04
Loss = 1.6976e-02, PNorm = 45.2520, GNorm = 2.2527, lr_0 = 6.2640e-04
Loss = 1.8988e-02, PNorm = 45.2898, GNorm = 4.2033, lr_0 = 6.2556e-04
Loss = 1.9949e-02, PNorm = 45.3405, GNorm = 2.5892, lr_0 = 6.2472e-04
Loss = 1.8440e-02, PNorm = 45.3781, GNorm = 2.4309, lr_0 = 6.2388e-04
Loss = 1.7703e-02, PNorm = 45.4019, GNorm = 2.0578, lr_0 = 6.2304e-04
Loss = 1.8313e-02, PNorm = 45.4380, GNorm = 2.0349, lr_0 = 6.2221e-04
Loss = 1.5480e-02, PNorm = 45.4572, GNorm = 1.9697, lr_0 = 6.2137e-04
Loss = 1.8192e-02, PNorm = 45.4848, GNorm = 1.8023, lr_0 = 6.2054e-04
Loss = 1.6606e-02, PNorm = 45.5102, GNorm = 2.2123, lr_0 = 6.1971e-04
Loss = 1.7593e-02, PNorm = 45.5377, GNorm = 2.9532, lr_0 = 6.1888e-04
Loss = 1.5582e-02, PNorm = 45.5591, GNorm = 2.0828, lr_0 = 6.1805e-04
Loss = 1.7653e-02, PNorm = 45.5775, GNorm = 2.1596, lr_0 = 6.1722e-04
Loss = 1.5400e-02, PNorm = 45.6140, GNorm = 1.9539, lr_0 = 6.1639e-04
Loss = 1.5710e-02, PNorm = 45.6459, GNorm = 2.7711, lr_0 = 6.1556e-04
Loss = 1.7569e-02, PNorm = 45.6661, GNorm = 3.2387, lr_0 = 6.1474e-04
Loss = 1.7826e-02, PNorm = 45.6954, GNorm = 2.0743, lr_0 = 6.1391e-04
Loss = 1.8475e-02, PNorm = 45.7175, GNorm = 2.2342, lr_0 = 6.1309e-04
Validation rmse = 1.979609
Validation R2 = -0.118998
Epoch 17
Train function
Loss = 1.6444e-02, PNorm = 45.7601, GNorm = 3.1474, lr_0 = 6.1218e-04
Loss = 1.5388e-02, PNorm = 45.7978, GNorm = 3.9562, lr_0 = 6.1136e-04
Loss = 1.7702e-02, PNorm = 45.8316, GNorm = 2.9950, lr_0 = 6.1054e-04
Loss = 1.4157e-02, PNorm = 45.8631, GNorm = 1.7197, lr_0 = 6.0972e-04
Loss = 1.6916e-02, PNorm = 45.8900, GNorm = 2.4269, lr_0 = 6.0890e-04
Loss = 1.6447e-02, PNorm = 45.9306, GNorm = 2.9873, lr_0 = 6.0809e-04
Loss = 1.5983e-02, PNorm = 45.9632, GNorm = 1.9478, lr_0 = 6.0727e-04
Loss = 1.6076e-02, PNorm = 46.0036, GNorm = 3.3536, lr_0 = 6.0646e-04
Loss = 1.7226e-02, PNorm = 46.0356, GNorm = 2.2778, lr_0 = 6.0564e-04
Loss = 1.4463e-02, PNorm = 46.0661, GNorm = 2.0577, lr_0 = 6.0483e-04
Loss = 1.8404e-02, PNorm = 46.1018, GNorm = 2.9979, lr_0 = 6.0402e-04
Loss = 1.6619e-02, PNorm = 46.1266, GNorm = 2.5866, lr_0 = 6.0321e-04
Loss = 1.8073e-02, PNorm = 46.1578, GNorm = 2.4850, lr_0 = 6.0240e-04
Loss = 1.4160e-02, PNorm = 46.1805, GNorm = 2.7288, lr_0 = 6.0159e-04
Loss = 1.5058e-02, PNorm = 46.1990, GNorm = 2.4886, lr_0 = 6.0078e-04
Loss = 1.6857e-02, PNorm = 46.2256, GNorm = 3.5423, lr_0 = 5.9998e-04
Loss = 1.8371e-02, PNorm = 46.2533, GNorm = 4.7918, lr_0 = 5.9917e-04
Loss = 1.5071e-02, PNorm = 46.2826, GNorm = 2.4606, lr_0 = 5.9837e-04
Loss = 1.5667e-02, PNorm = 46.3036, GNorm = 3.7931, lr_0 = 5.9756e-04
Loss = 1.6195e-02, PNorm = 46.3266, GNorm = 2.9815, lr_0 = 5.9676e-04
Loss = 1.5395e-02, PNorm = 46.3512, GNorm = 1.9955, lr_0 = 5.9596e-04
Loss = 2.0657e-02, PNorm = 46.3721, GNorm = 2.9166, lr_0 = 5.9516e-04
Loss = 1.6822e-02, PNorm = 46.3996, GNorm = 1.7638, lr_0 = 5.9436e-04
Validation rmse = 1.912380
Validation R2 = -0.044284
Epoch 18
Train function
Loss = 1.4236e-02, PNorm = 46.4392, GNorm = 5.5931, lr_0 = 5.9349e-04
Loss = 1.4829e-02, PNorm = 46.4698, GNorm = 2.3321, lr_0 = 5.9269e-04
Loss = 1.3628e-02, PNorm = 46.4991, GNorm = 1.8711, lr_0 = 5.9190e-04
Loss = 1.3780e-02, PNorm = 46.5191, GNorm = 1.9502, lr_0 = 5.9110e-04
Loss = 1.7844e-02, PNorm = 46.5454, GNorm = 2.5487, lr_0 = 5.9031e-04
Loss = 1.5664e-02, PNorm = 46.5828, GNorm = 1.8397, lr_0 = 5.8952e-04
Loss = 1.8887e-02, PNorm = 46.6095, GNorm = 3.6653, lr_0 = 5.8873e-04
Loss = 1.5366e-02, PNorm = 46.6500, GNorm = 3.0437, lr_0 = 5.8794e-04
Loss = 1.3703e-02, PNorm = 46.6824, GNorm = 3.5917, lr_0 = 5.8715e-04
Loss = 1.4763e-02, PNorm = 46.7128, GNorm = 3.3960, lr_0 = 5.8636e-04
Loss = 1.4904e-02, PNorm = 46.7316, GNorm = 4.6077, lr_0 = 5.8557e-04
Loss = 1.4832e-02, PNorm = 46.7529, GNorm = 1.9050, lr_0 = 5.8479e-04
Loss = 1.6954e-02, PNorm = 46.7806, GNorm = 2.4106, lr_0 = 5.8400e-04
Loss = 1.4691e-02, PNorm = 46.8023, GNorm = 2.7691, lr_0 = 5.8322e-04
Loss = 1.8455e-02, PNorm = 46.8417, GNorm = 3.5723, lr_0 = 5.8244e-04
Loss = 1.7394e-02, PNorm = 46.8780, GNorm = 2.7264, lr_0 = 5.8165e-04
Loss = 1.7002e-02, PNorm = 46.9013, GNorm = 4.1940, lr_0 = 5.8087e-04
Loss = 1.5817e-02, PNorm = 46.9237, GNorm = 2.9495, lr_0 = 5.8009e-04
Loss = 1.7272e-02, PNorm = 46.9402, GNorm = 2.8583, lr_0 = 5.7932e-04
Loss = 1.5411e-02, PNorm = 46.9622, GNorm = 2.5771, lr_0 = 5.7854e-04
Loss = 1.5323e-02, PNorm = 46.9904, GNorm = 2.3249, lr_0 = 5.7776e-04
Loss = 1.7050e-02, PNorm = 47.0182, GNorm = 4.9642, lr_0 = 5.7699e-04
Loss = 1.7051e-02, PNorm = 47.0522, GNorm = 2.5279, lr_0 = 5.7621e-04
Validation rmse = 2.315266
Validation R2 = -0.530636
Epoch 19
Train function
Loss = 2.0951e-02, PNorm = 47.0798, GNorm = 3.3116, lr_0 = 5.7536e-04
Loss = 1.3999e-02, PNorm = 47.1195, GNorm = 2.5370, lr_0 = 5.7459e-04
Loss = 1.3828e-02, PNorm = 47.1501, GNorm = 2.6703, lr_0 = 5.7382e-04
Loss = 1.3977e-02, PNorm = 47.1720, GNorm = 1.9144, lr_0 = 5.7305e-04
Loss = 1.5590e-02, PNorm = 47.1980, GNorm = 2.2427, lr_0 = 5.7228e-04
Loss = 1.5680e-02, PNorm = 47.2295, GNorm = 3.2789, lr_0 = 5.7151e-04
Loss = 1.4262e-02, PNorm = 47.2599, GNorm = 2.8432, lr_0 = 5.7075e-04
Loss = 1.3875e-02, PNorm = 47.2876, GNorm = 3.3793, lr_0 = 5.6998e-04
Loss = 1.6619e-02, PNorm = 47.3138, GNorm = 3.4585, lr_0 = 5.6922e-04
Loss = 1.6374e-02, PNorm = 47.3305, GNorm = 2.1472, lr_0 = 5.6845e-04
Loss = 1.8249e-02, PNorm = 47.3583, GNorm = 3.2326, lr_0 = 5.6769e-04
Loss = 1.6075e-02, PNorm = 47.4056, GNorm = 5.4814, lr_0 = 5.6693e-04
Loss = 1.4707e-02, PNorm = 47.4272, GNorm = 2.5460, lr_0 = 5.6617e-04
Loss = 1.5720e-02, PNorm = 47.4530, GNorm = 2.4301, lr_0 = 5.6541e-04
Loss = 1.5859e-02, PNorm = 47.4855, GNorm = 2.3330, lr_0 = 5.6465e-04
Loss = 1.4239e-02, PNorm = 47.5085, GNorm = 2.7588, lr_0 = 5.6389e-04
Loss = 1.5479e-02, PNorm = 47.5282, GNorm = 2.1457, lr_0 = 5.6313e-04
Loss = 1.5038e-02, PNorm = 47.5555, GNorm = 1.9723, lr_0 = 5.6238e-04
Loss = 1.5995e-02, PNorm = 47.5808, GNorm = 2.0412, lr_0 = 5.6162e-04
Loss = 1.3843e-02, PNorm = 47.5994, GNorm = 3.6387, lr_0 = 5.6087e-04
Loss = 1.3833e-02, PNorm = 47.6300, GNorm = 4.9463, lr_0 = 5.6012e-04
Loss = 1.5505e-02, PNorm = 47.6547, GNorm = 2.4386, lr_0 = 5.5937e-04
Loss = 1.4387e-02, PNorm = 47.6738, GNorm = 2.7205, lr_0 = 5.5862e-04
Loss = 1.4948e-02, PNorm = 47.6991, GNorm = 2.4172, lr_0 = 5.5787e-04
Validation rmse = 2.049761
Validation R2 = -0.199711
Epoch 20
Train function
Loss = 1.3570e-02, PNorm = 47.7272, GNorm = 3.5526, lr_0 = 5.5712e-04
Loss = 1.4717e-02, PNorm = 47.7557, GNorm = 2.8556, lr_0 = 5.5637e-04
Loss = 1.2621e-02, PNorm = 47.7827, GNorm = 2.0735, lr_0 = 5.5562e-04
Loss = 1.1816e-02, PNorm = 47.8076, GNorm = 3.6119, lr_0 = 5.5488e-04
Loss = 1.5463e-02, PNorm = 47.8340, GNorm = 2.8046, lr_0 = 5.5413e-04
Loss = 1.4040e-02, PNorm = 47.8664, GNorm = 2.4499, lr_0 = 5.5339e-04
Loss = 1.3562e-02, PNorm = 47.8989, GNorm = 3.8291, lr_0 = 5.5265e-04
Loss = 1.6246e-02, PNorm = 47.9259, GNorm = 2.8076, lr_0 = 5.5191e-04
Loss = 1.8010e-02, PNorm = 47.9591, GNorm = 3.5591, lr_0 = 5.5117e-04
Loss = 1.3614e-02, PNorm = 47.9926, GNorm = 4.4745, lr_0 = 5.5043e-04
Loss = 1.4099e-02, PNorm = 48.0213, GNorm = 2.4461, lr_0 = 5.4969e-04
Loss = 1.4843e-02, PNorm = 48.0582, GNorm = 5.4870, lr_0 = 5.4895e-04
Loss = 1.5938e-02, PNorm = 48.0888, GNorm = 2.9043, lr_0 = 5.4821e-04
Loss = 1.4179e-02, PNorm = 48.1154, GNorm = 2.7562, lr_0 = 5.4748e-04
Loss = 1.6478e-02, PNorm = 48.1482, GNorm = 2.6571, lr_0 = 5.4674e-04
Loss = 1.7049e-02, PNorm = 48.1843, GNorm = 2.5156, lr_0 = 5.4601e-04
Loss = 1.4855e-02, PNorm = 48.2095, GNorm = 2.7127, lr_0 = 5.4528e-04
Loss = 1.3904e-02, PNorm = 48.2398, GNorm = 1.7956, lr_0 = 5.4455e-04
Loss = 1.4890e-02, PNorm = 48.2606, GNorm = 2.3929, lr_0 = 5.4382e-04
Loss = 1.4152e-02, PNorm = 48.2794, GNorm = 1.7441, lr_0 = 5.4309e-04
Loss = 1.4849e-02, PNorm = 48.2989, GNorm = 2.5847, lr_0 = 5.4236e-04
Loss = 1.5727e-02, PNorm = 48.3204, GNorm = 4.3803, lr_0 = 5.4163e-04
Loss = 1.4818e-02, PNorm = 48.3381, GNorm = 2.1766, lr_0 = 5.4090e-04
Validation rmse = 2.311517
Validation R2 = -0.525684
Epoch 21
Train function
Loss = 1.0488e-02, PNorm = 48.3630, GNorm = 1.8019, lr_0 = 5.4010e-04
Loss = 1.3591e-02, PNorm = 48.3946, GNorm = 1.8522, lr_0 = 5.3938e-04
Loss = 1.3302e-02, PNorm = 48.4213, GNorm = 2.8983, lr_0 = 5.3866e-04
Loss = 1.2875e-02, PNorm = 48.4387, GNorm = 2.2697, lr_0 = 5.3793e-04
Loss = 1.4225e-02, PNorm = 48.4637, GNorm = 2.7564, lr_0 = 5.3721e-04
Loss = 1.3417e-02, PNorm = 48.4945, GNorm = 2.9033, lr_0 = 5.3649e-04
Loss = 1.7119e-02, PNorm = 48.5280, GNorm = 4.4195, lr_0 = 5.3577e-04
Loss = 1.3057e-02, PNorm = 48.5638, GNorm = 1.9612, lr_0 = 5.3505e-04
Loss = 1.4732e-02, PNorm = 48.5917, GNorm = 2.6113, lr_0 = 5.3433e-04
Loss = 1.4617e-02, PNorm = 48.6187, GNorm = 2.6682, lr_0 = 5.3362e-04
Loss = 1.4618e-02, PNorm = 48.6370, GNorm = 6.2794, lr_0 = 5.3290e-04
Loss = 1.5210e-02, PNorm = 48.6635, GNorm = 2.3972, lr_0 = 5.3219e-04
Loss = 1.5375e-02, PNorm = 48.6812, GNorm = 3.3031, lr_0 = 5.3147e-04
Loss = 1.5466e-02, PNorm = 48.7051, GNorm = 3.4069, lr_0 = 5.3076e-04
Loss = 1.2539e-02, PNorm = 48.7308, GNorm = 4.8252, lr_0 = 5.3005e-04
Loss = 1.2741e-02, PNorm = 48.7522, GNorm = 2.4556, lr_0 = 5.2934e-04
Loss = 1.3736e-02, PNorm = 48.7714, GNorm = 2.0763, lr_0 = 5.2863e-04
Loss = 1.2426e-02, PNorm = 48.7935, GNorm = 3.2003, lr_0 = 5.2792e-04
Loss = 1.5318e-02, PNorm = 48.8166, GNorm = 3.3549, lr_0 = 5.2721e-04
Loss = 1.4010e-02, PNorm = 48.8366, GNorm = 2.7057, lr_0 = 5.2650e-04
Loss = 1.3386e-02, PNorm = 48.8579, GNorm = 3.2666, lr_0 = 5.2579e-04
Loss = 1.3570e-02, PNorm = 48.8799, GNorm = 2.3583, lr_0 = 5.2509e-04
Loss = 1.4674e-02, PNorm = 48.9053, GNorm = 2.5512, lr_0 = 5.2438e-04
Loss = 1.4629e-02, PNorm = 48.9369, GNorm = 3.0364, lr_0 = 5.2368e-04
Validation rmse = 2.239661
Validation R2 = -0.432303
Epoch 22
Train function
Loss = 1.2702e-02, PNorm = 48.9602, GNorm = 2.7422, lr_0 = 5.2291e-04
Loss = 1.2651e-02, PNorm = 48.9939, GNorm = 1.9843, lr_0 = 5.2221e-04
Loss = 1.3444e-02, PNorm = 49.0230, GNorm = 3.0340, lr_0 = 5.2151e-04
Loss = 1.2625e-02, PNorm = 49.0442, GNorm = 2.4601, lr_0 = 5.2081e-04
Loss = 1.3478e-02, PNorm = 49.0835, GNorm = 3.9969, lr_0 = 5.2011e-04
Loss = 1.3151e-02, PNorm = 49.1106, GNorm = 3.5678, lr_0 = 5.1941e-04
Loss = 1.4023e-02, PNorm = 49.1343, GNorm = 4.7861, lr_0 = 5.1871e-04
Loss = 1.4154e-02, PNorm = 49.1651, GNorm = 3.3005, lr_0 = 5.1802e-04
Loss = 1.2006e-02, PNorm = 49.1892, GNorm = 2.5740, lr_0 = 5.1732e-04
Loss = 1.4539e-02, PNorm = 49.2178, GNorm = 2.9146, lr_0 = 5.1663e-04
Loss = 1.3022e-02, PNorm = 49.2481, GNorm = 2.2362, lr_0 = 5.1593e-04
Loss = 1.3230e-02, PNorm = 49.2688, GNorm = 3.3372, lr_0 = 5.1524e-04
Loss = 1.3627e-02, PNorm = 49.2928, GNorm = 3.1136, lr_0 = 5.1455e-04
Loss = 1.2245e-02, PNorm = 49.3136, GNorm = 3.1804, lr_0 = 5.1386e-04
Loss = 1.4976e-02, PNorm = 49.3363, GNorm = 3.7220, lr_0 = 5.1317e-04
Loss = 1.4428e-02, PNorm = 49.3553, GNorm = 2.9744, lr_0 = 5.1248e-04
Loss = 1.1805e-02, PNorm = 49.3767, GNorm = 3.2447, lr_0 = 5.1180e-04
Loss = 1.3282e-02, PNorm = 49.3925, GNorm = 2.9817, lr_0 = 5.1111e-04
Loss = 1.3641e-02, PNorm = 49.4245, GNorm = 2.8900, lr_0 = 5.1042e-04
Loss = 1.3722e-02, PNorm = 49.4462, GNorm = 2.7745, lr_0 = 5.0974e-04
Loss = 1.4439e-02, PNorm = 49.4687, GNorm = 3.0178, lr_0 = 5.0905e-04
Loss = 1.6002e-02, PNorm = 49.4940, GNorm = 2.5309, lr_0 = 5.0837e-04
Loss = 1.3910e-02, PNorm = 49.5153, GNorm = 2.7348, lr_0 = 5.0769e-04
Validation rmse = 2.029801
Validation R2 = -0.176459
Epoch 23
Train function
Loss = 1.2643e-02, PNorm = 49.5479, GNorm = 2.8247, lr_0 = 5.0694e-04
Loss = 1.2175e-02, PNorm = 49.5786, GNorm = 2.4862, lr_0 = 5.0626e-04
Loss = 1.2022e-02, PNorm = 49.6114, GNorm = 2.8666, lr_0 = 5.0558e-04
Loss = 1.1578e-02, PNorm = 49.6346, GNorm = 4.4972, lr_0 = 5.0490e-04
Loss = 1.2448e-02, PNorm = 49.6547, GNorm = 2.4891, lr_0 = 5.0422e-04
Loss = 1.3560e-02, PNorm = 49.6878, GNorm = 3.3905, lr_0 = 5.0355e-04
Loss = 1.1735e-02, PNorm = 49.7240, GNorm = 2.8049, lr_0 = 5.0287e-04
Loss = 1.2919e-02, PNorm = 49.7508, GNorm = 2.3424, lr_0 = 5.0220e-04
Loss = 1.2315e-02, PNorm = 49.7774, GNorm = 3.1557, lr_0 = 5.0152e-04
Loss = 1.2058e-02, PNorm = 49.7953, GNorm = 3.0352, lr_0 = 5.0085e-04
Loss = 1.2401e-02, PNorm = 49.8067, GNorm = 2.6850, lr_0 = 5.0018e-04
Loss = 1.1728e-02, PNorm = 49.8324, GNorm = 3.7908, lr_0 = 4.9951e-04
Loss = 1.2799e-02, PNorm = 49.8540, GNorm = 3.0417, lr_0 = 4.9884e-04
Loss = 1.4028e-02, PNorm = 49.8752, GNorm = 2.4578, lr_0 = 4.9817e-04
Loss = 1.4960e-02, PNorm = 49.8961, GNorm = 2.2554, lr_0 = 4.9750e-04
Loss = 1.4903e-02, PNorm = 49.9194, GNorm = 2.6748, lr_0 = 4.9683e-04
Loss = 1.1824e-02, PNorm = 49.9454, GNorm = 2.6208, lr_0 = 4.9617e-04
Loss = 1.3634e-02, PNorm = 49.9743, GNorm = 2.3490, lr_0 = 4.9550e-04
Loss = 1.2801e-02, PNorm = 49.9949, GNorm = 3.2559, lr_0 = 4.9484e-04
Loss = 1.3357e-02, PNorm = 50.0208, GNorm = 3.1586, lr_0 = 4.9417e-04
Loss = 1.2559e-02, PNorm = 50.0445, GNorm = 2.1214, lr_0 = 4.9351e-04
Loss = 1.3610e-02, PNorm = 50.0671, GNorm = 3.5583, lr_0 = 4.9285e-04
Loss = 1.1306e-02, PNorm = 50.0927, GNorm = 2.7851, lr_0 = 4.9218e-04
Loss = 1.1522e-02, PNorm = 50.1092, GNorm = 2.7402, lr_0 = 4.9152e-04
Loss = 3.9477e-02, PNorm = 50.1106, GNorm = 4.7835, lr_0 = 4.9146e-04
Validation rmse = 2.594249
Validation R2 = -0.921735
Epoch 24
Train function
Loss = 1.1132e-02, PNorm = 50.1317, GNorm = 5.1702, lr_0 = 4.9080e-04
Loss = 1.1536e-02, PNorm = 50.1572, GNorm = 3.4082, lr_0 = 4.9014e-04
Loss = 1.2234e-02, PNorm = 50.1847, GNorm = 2.3756, lr_0 = 4.8948e-04
Loss = 1.1650e-02, PNorm = 50.2082, GNorm = 4.4905, lr_0 = 4.8883e-04
Loss = 1.3639e-02, PNorm = 50.2314, GNorm = 2.1455, lr_0 = 4.8817e-04
Loss = 1.1780e-02, PNorm = 50.2520, GNorm = 2.3864, lr_0 = 4.8752e-04
Loss = 1.2078e-02, PNorm = 50.2811, GNorm = 2.9271, lr_0 = 4.8686e-04
Loss = 1.0983e-02, PNorm = 50.3066, GNorm = 2.4233, lr_0 = 4.8621e-04
Loss = 1.3274e-02, PNorm = 50.3315, GNorm = 4.0569, lr_0 = 4.8556e-04
Loss = 1.2573e-02, PNorm = 50.3539, GNorm = 2.1310, lr_0 = 4.8490e-04
Loss = 1.1068e-02, PNorm = 50.3816, GNorm = 2.1840, lr_0 = 4.8425e-04
Loss = 1.1231e-02, PNorm = 50.4066, GNorm = 2.8670, lr_0 = 4.8360e-04
Loss = 1.2333e-02, PNorm = 50.4263, GNorm = 3.0484, lr_0 = 4.8296e-04
Loss = 1.3065e-02, PNorm = 50.4480, GNorm = 3.2677, lr_0 = 4.8231e-04
Loss = 1.2895e-02, PNorm = 50.4680, GNorm = 4.2183, lr_0 = 4.8166e-04
Loss = 1.4541e-02, PNorm = 50.4928, GNorm = 2.9290, lr_0 = 4.8101e-04
Loss = 1.1455e-02, PNorm = 50.5177, GNorm = 3.0950, lr_0 = 4.8037e-04
Loss = 1.3361e-02, PNorm = 50.5431, GNorm = 2.9331, lr_0 = 4.7972e-04
Loss = 1.2280e-02, PNorm = 50.5649, GNorm = 3.4567, lr_0 = 4.7908e-04
Loss = 1.2657e-02, PNorm = 50.5850, GNorm = 1.9756, lr_0 = 4.7844e-04
Loss = 1.3812e-02, PNorm = 50.6116, GNorm = 2.7787, lr_0 = 4.7780e-04
Loss = 1.2923e-02, PNorm = 50.6330, GNorm = 2.7016, lr_0 = 4.7715e-04
Loss = 1.1865e-02, PNorm = 50.6573, GNorm = 2.5003, lr_0 = 4.7651e-04
Validation rmse = 2.290585
Validation R2 = -0.498176
Epoch 25
Train function
Loss = 1.0671e-02, PNorm = 50.6797, GNorm = 2.9894, lr_0 = 4.7587e-04
Loss = 1.2023e-02, PNorm = 50.7059, GNorm = 2.9640, lr_0 = 4.7524e-04
Loss = 9.3211e-03, PNorm = 50.7307, GNorm = 1.9295, lr_0 = 4.7460e-04
Loss = 1.0668e-02, PNorm = 50.7533, GNorm = 2.3575, lr_0 = 4.7396e-04
Loss = 1.0860e-02, PNorm = 50.7705, GNorm = 2.2726, lr_0 = 4.7333e-04
Loss = 1.1473e-02, PNorm = 50.7914, GNorm = 5.1105, lr_0 = 4.7269e-04
Loss = 1.1685e-02, PNorm = 50.8132, GNorm = 2.4232, lr_0 = 4.7206e-04
Loss = 1.3416e-02, PNorm = 50.8353, GNorm = 4.1611, lr_0 = 4.7142e-04
Loss = 1.1488e-02, PNorm = 50.8581, GNorm = 4.3654, lr_0 = 4.7079e-04
Loss = 1.1986e-02, PNorm = 50.8794, GNorm = 2.5011, lr_0 = 4.7016e-04
Loss = 1.1120e-02, PNorm = 50.9036, GNorm = 3.1870, lr_0 = 4.6953e-04
Loss = 1.3320e-02, PNorm = 50.9271, GNorm = 3.0573, lr_0 = 4.6890e-04
Loss = 1.0739e-02, PNorm = 50.9509, GNorm = 3.0275, lr_0 = 4.6827e-04
Loss = 1.1749e-02, PNorm = 50.9750, GNorm = 2.8485, lr_0 = 4.6764e-04
Loss = 1.1261e-02, PNorm = 50.9935, GNorm = 2.3469, lr_0 = 4.6701e-04
Loss = 1.3165e-02, PNorm = 51.0257, GNorm = 3.9900, lr_0 = 4.6639e-04
Loss = 1.3017e-02, PNorm = 51.0446, GNorm = 4.8380, lr_0 = 4.6576e-04
Loss = 1.1390e-02, PNorm = 51.0673, GNorm = 3.4496, lr_0 = 4.6514e-04
Loss = 1.2835e-02, PNorm = 51.0941, GNorm = 3.9983, lr_0 = 4.6451e-04
Loss = 1.1591e-02, PNorm = 51.1142, GNorm = 4.0923, lr_0 = 4.6389e-04
Loss = 1.0108e-02, PNorm = 51.1300, GNorm = 3.4071, lr_0 = 4.6327e-04
Loss = 1.1462e-02, PNorm = 51.1467, GNorm = 2.0427, lr_0 = 4.6264e-04
Loss = 1.3344e-02, PNorm = 51.1591, GNorm = 3.4959, lr_0 = 4.6202e-04
Validation rmse = 2.703315
Validation R2 = -1.086717
Epoch 26
Train function
Loss = 1.8741e-02, PNorm = 51.1852, GNorm = 4.4024, lr_0 = 4.6134e-04
Loss = 1.1533e-02, PNorm = 51.2125, GNorm = 2.2298, lr_0 = 4.6072e-04
Loss = 1.0587e-02, PNorm = 51.2399, GNorm = 3.0274, lr_0 = 4.6011e-04
Loss = 9.2757e-03, PNorm = 51.2605, GNorm = 3.1621, lr_0 = 4.5949e-04
Loss = 1.1421e-02, PNorm = 51.2829, GNorm = 6.7991, lr_0 = 4.5887e-04
Loss = 1.1897e-02, PNorm = 51.3063, GNorm = 4.0538, lr_0 = 4.5826e-04
Loss = 1.1920e-02, PNorm = 51.3225, GNorm = 3.8962, lr_0 = 4.5764e-04
Loss = 1.1396e-02, PNorm = 51.3463, GNorm = 3.0811, lr_0 = 4.5703e-04
Loss = 1.1555e-02, PNorm = 51.3689, GNorm = 4.5131, lr_0 = 4.5641e-04
Loss = 9.8518e-03, PNorm = 51.3869, GNorm = 2.5034, lr_0 = 4.5580e-04
Loss = 1.0063e-02, PNorm = 51.4052, GNorm = 2.3028, lr_0 = 4.5519e-04
Loss = 1.0063e-02, PNorm = 51.4194, GNorm = 3.0188, lr_0 = 4.5458e-04
Loss = 1.2427e-02, PNorm = 51.4355, GNorm = 5.3756, lr_0 = 4.5397e-04
Loss = 1.2323e-02, PNorm = 51.4541, GNorm = 1.9821, lr_0 = 4.5336e-04
Loss = 1.0479e-02, PNorm = 51.4705, GNorm = 2.0793, lr_0 = 4.5275e-04
Loss = 1.1408e-02, PNorm = 51.4928, GNorm = 2.3439, lr_0 = 4.5214e-04
Loss = 1.2059e-02, PNorm = 51.5182, GNorm = 2.9709, lr_0 = 4.5154e-04
Loss = 1.1439e-02, PNorm = 51.5415, GNorm = 3.8162, lr_0 = 4.5093e-04
Loss = 9.3509e-03, PNorm = 51.5692, GNorm = 3.5200, lr_0 = 4.5033e-04
Loss = 1.0630e-02, PNorm = 51.5828, GNorm = 2.9975, lr_0 = 4.4972e-04
Loss = 1.1859e-02, PNorm = 51.5992, GNorm = 3.0654, lr_0 = 4.4912e-04
Loss = 1.2255e-02, PNorm = 51.6262, GNorm = 2.8457, lr_0 = 4.4852e-04
Loss = 1.1973e-02, PNorm = 51.6526, GNorm = 3.3642, lr_0 = 4.4791e-04
Loss = 1.2641e-02, PNorm = 51.6719, GNorm = 2.7778, lr_0 = 4.4731e-04
Validation rmse = 2.481298
Validation R2 = -0.758037
Epoch 27
Train function
Loss = 1.0270e-02, PNorm = 51.6927, GNorm = 3.8296, lr_0 = 4.4665e-04
Loss = 9.9074e-03, PNorm = 51.7115, GNorm = 2.3603, lr_0 = 4.4605e-04
Loss = 1.0363e-02, PNorm = 51.7320, GNorm = 3.8855, lr_0 = 4.4546e-04
Loss = 1.0012e-02, PNorm = 51.7544, GNorm = 2.3782, lr_0 = 4.4486e-04
Loss = 9.6913e-03, PNorm = 51.7780, GNorm = 3.3969, lr_0 = 4.4426e-04
Loss = 1.0364e-02, PNorm = 51.7972, GNorm = 2.1702, lr_0 = 4.4367e-04
Loss = 9.4017e-03, PNorm = 51.8203, GNorm = 2.5917, lr_0 = 4.4307e-04
Loss = 1.0739e-02, PNorm = 51.8433, GNorm = 5.1369, lr_0 = 4.4248e-04
Loss = 1.0342e-02, PNorm = 51.8627, GNorm = 2.9156, lr_0 = 4.4188e-04
Loss = 1.0334e-02, PNorm = 51.8826, GNorm = 3.1363, lr_0 = 4.4129e-04
Loss = 1.0782e-02, PNorm = 51.8986, GNorm = 3.5219, lr_0 = 4.4070e-04
Loss = 9.2673e-03, PNorm = 51.9183, GNorm = 2.4647, lr_0 = 4.4011e-04
Loss = 1.1734e-02, PNorm = 51.9396, GNorm = 2.0931, lr_0 = 4.3952e-04
Loss = 1.1570e-02, PNorm = 51.9650, GNorm = 3.4333, lr_0 = 4.3893e-04
Loss = 9.3766e-03, PNorm = 51.9901, GNorm = 2.5310, lr_0 = 4.3834e-04
Loss = 9.7917e-03, PNorm = 52.0131, GNorm = 2.8458, lr_0 = 4.3775e-04
Loss = 1.1114e-02, PNorm = 52.0359, GNorm = 2.6103, lr_0 = 4.3716e-04
Loss = 1.0550e-02, PNorm = 52.0547, GNorm = 3.2599, lr_0 = 4.3657e-04
Loss = 1.0547e-02, PNorm = 52.0696, GNorm = 2.4088, lr_0 = 4.3599e-04
Loss = 1.1550e-02, PNorm = 52.0954, GNorm = 3.6381, lr_0 = 4.3540e-04
Loss = 1.1928e-02, PNorm = 52.1144, GNorm = 3.5891, lr_0 = 4.3482e-04
Loss = 9.3378e-03, PNorm = 52.1319, GNorm = 2.2203, lr_0 = 4.3424e-04
Loss = 1.2070e-02, PNorm = 52.1479, GNorm = 3.3778, lr_0 = 4.3365e-04
Validation rmse = 3.149382
Validation R2 = -1.832180
Epoch 28
Train function
Loss = 1.1451e-02, PNorm = 52.1669, GNorm = 2.7148, lr_0 = 4.3301e-04
Loss = 9.5662e-03, PNorm = 52.1876, GNorm = 3.1054, lr_0 = 4.3243e-04
Loss = 9.4368e-03, PNorm = 52.2082, GNorm = 2.2945, lr_0 = 4.3185e-04
Loss = 9.1872e-03, PNorm = 52.2237, GNorm = 2.3299, lr_0 = 4.3127e-04
Loss = 1.0173e-02, PNorm = 52.2435, GNorm = 2.5241, lr_0 = 4.3069e-04
Loss = 1.0538e-02, PNorm = 52.2653, GNorm = 3.0023, lr_0 = 4.3012e-04
Loss = 8.7546e-03, PNorm = 52.2821, GNorm = 2.9215, lr_0 = 4.2954e-04
Loss = 8.0077e-03, PNorm = 52.3006, GNorm = 2.5474, lr_0 = 4.2896e-04
Loss = 1.0905e-02, PNorm = 52.3186, GNorm = 8.3585, lr_0 = 4.2839e-04
Loss = 9.9990e-03, PNorm = 52.3408, GNorm = 2.3028, lr_0 = 4.2781e-04
Loss = 8.6487e-03, PNorm = 52.3584, GNorm = 3.0098, lr_0 = 4.2724e-04
Loss = 1.1108e-02, PNorm = 52.3809, GNorm = 3.9048, lr_0 = 4.2667e-04
Loss = 9.9647e-03, PNorm = 52.4001, GNorm = 2.9736, lr_0 = 4.2609e-04
Loss = 9.8039e-03, PNorm = 52.4193, GNorm = 2.4019, lr_0 = 4.2552e-04
Loss = 9.8559e-03, PNorm = 52.4363, GNorm = 2.4883, lr_0 = 4.2495e-04
Loss = 1.0712e-02, PNorm = 52.4621, GNorm = 2.6348, lr_0 = 4.2438e-04
Loss = 1.0655e-02, PNorm = 52.4837, GNorm = 2.7019, lr_0 = 4.2381e-04
Loss = 9.1164e-03, PNorm = 52.5023, GNorm = 3.3346, lr_0 = 4.2324e-04
Loss = 1.0810e-02, PNorm = 52.5233, GNorm = 6.3601, lr_0 = 4.2267e-04
Loss = 1.1475e-02, PNorm = 52.5379, GNorm = 2.8970, lr_0 = 4.2211e-04
Loss = 1.0160e-02, PNorm = 52.5483, GNorm = 2.9498, lr_0 = 4.2154e-04
Loss = 9.8000e-03, PNorm = 52.5648, GNorm = 2.6258, lr_0 = 4.2098e-04
Loss = 9.8277e-03, PNorm = 52.5787, GNorm = 3.5936, lr_0 = 4.2041e-04
Loss = 1.0844e-02, PNorm = 52.5988, GNorm = 3.0128, lr_0 = 4.1985e-04
Validation rmse = 3.148607
Validation R2 = -1.830786
Epoch 29
Train function
Loss = 8.7200e-03, PNorm = 52.6207, GNorm = 3.7425, lr_0 = 4.1923e-04
Loss = 9.6623e-03, PNorm = 52.6410, GNorm = 4.3289, lr_0 = 4.1866e-04
Loss = 9.6364e-03, PNorm = 52.6619, GNorm = 4.4763, lr_0 = 4.1810e-04
Loss = 1.0777e-02, PNorm = 52.6822, GNorm = 2.7623, lr_0 = 4.1754e-04
Loss = 7.5487e-03, PNorm = 52.7012, GNorm = 3.7056, lr_0 = 4.1698e-04
Loss = 9.2718e-03, PNorm = 52.7219, GNorm = 4.7311, lr_0 = 4.1642e-04
Loss = 1.0162e-02, PNorm = 52.7391, GNorm = 3.7218, lr_0 = 4.1586e-04
Loss = 9.8409e-03, PNorm = 52.7556, GNorm = 3.1805, lr_0 = 4.1531e-04
Loss = 7.4011e-03, PNorm = 52.7720, GNorm = 2.5172, lr_0 = 4.1475e-04
Loss = 1.0869e-02, PNorm = 52.7875, GNorm = 6.4180, lr_0 = 4.1419e-04
Loss = 8.8361e-03, PNorm = 52.8019, GNorm = 3.0886, lr_0 = 4.1364e-04
Loss = 1.0997e-02, PNorm = 52.8176, GNorm = 5.9207, lr_0 = 4.1308e-04
Loss = 8.6674e-03, PNorm = 52.8406, GNorm = 3.8311, lr_0 = 4.1253e-04
Loss = 8.8599e-03, PNorm = 52.8616, GNorm = 1.9332, lr_0 = 4.1197e-04
Loss = 1.1096e-02, PNorm = 52.8835, GNorm = 2.9186, lr_0 = 4.1142e-04
Loss = 8.4107e-03, PNorm = 52.9050, GNorm = 2.6506, lr_0 = 4.1087e-04
Loss = 1.2369e-02, PNorm = 52.9187, GNorm = 5.6637, lr_0 = 4.1032e-04
Loss = 8.7474e-03, PNorm = 52.9349, GNorm = 3.9568, lr_0 = 4.0977e-04
Loss = 1.0277e-02, PNorm = 52.9540, GNorm = 4.9641, lr_0 = 4.0922e-04
Loss = 8.2355e-03, PNorm = 52.9716, GNorm = 2.1595, lr_0 = 4.0867e-04
Loss = 7.8924e-03, PNorm = 52.9862, GNorm = 2.7577, lr_0 = 4.0812e-04
Loss = 1.0490e-02, PNorm = 53.0028, GNorm = 2.7468, lr_0 = 4.0757e-04
Loss = 7.8030e-03, PNorm = 53.0186, GNorm = 2.3124, lr_0 = 4.0702e-04
Validation rmse = 3.005770
Validation R2 = -1.579774
Epoch 30
Train function
Loss = 6.1946e-03, PNorm = 53.0380, GNorm = 2.0495, lr_0 = 4.0648e-04
Loss = 8.2655e-03, PNorm = 53.0574, GNorm = 3.9344, lr_0 = 4.0593e-04
Loss = 9.4802e-03, PNorm = 53.0797, GNorm = 2.3027, lr_0 = 4.0539e-04
Loss = 8.9085e-03, PNorm = 53.0992, GNorm = 3.2738, lr_0 = 4.0484e-04
Loss = 8.8288e-03, PNorm = 53.1181, GNorm = 3.8655, lr_0 = 4.0430e-04
Loss = 7.7918e-03, PNorm = 53.1366, GNorm = 1.9131, lr_0 = 4.0376e-04
Loss = 9.1063e-03, PNorm = 53.1532, GNorm = 3.1852, lr_0 = 4.0322e-04
Loss = 9.7807e-03, PNorm = 53.1698, GNorm = 2.1513, lr_0 = 4.0268e-04
Loss = 8.4598e-03, PNorm = 53.1844, GNorm = 3.1657, lr_0 = 4.0214e-04
Loss = 8.3788e-03, PNorm = 53.1987, GNorm = 2.3689, lr_0 = 4.0160e-04
Loss = 8.4756e-03, PNorm = 53.2121, GNorm = 2.1980, lr_0 = 4.0106e-04
Loss = 7.5125e-03, PNorm = 53.2279, GNorm = 1.9318, lr_0 = 4.0052e-04
Loss = 1.0563e-02, PNorm = 53.2436, GNorm = 3.3337, lr_0 = 3.9998e-04
Loss = 9.2187e-03, PNorm = 53.2626, GNorm = 3.0399, lr_0 = 3.9945e-04
Loss = 7.2288e-03, PNorm = 53.2798, GNorm = 2.0256, lr_0 = 3.9891e-04
Loss = 8.2653e-03, PNorm = 53.3004, GNorm = 2.2558, lr_0 = 3.9837e-04
Loss = 9.9817e-03, PNorm = 53.3159, GNorm = 3.2379, lr_0 = 3.9784e-04
Loss = 9.7712e-03, PNorm = 53.3306, GNorm = 6.0809, lr_0 = 3.9731e-04
Loss = 8.4242e-03, PNorm = 53.3433, GNorm = 2.2001, lr_0 = 3.9677e-04
Loss = 8.1106e-03, PNorm = 53.3594, GNorm = 3.4560, lr_0 = 3.9624e-04
Loss = 9.9356e-03, PNorm = 53.3789, GNorm = 4.0177, lr_0 = 3.9571e-04
Loss = 9.9295e-03, PNorm = 53.3929, GNorm = 2.8150, lr_0 = 3.9518e-04
Loss = 8.5578e-03, PNorm = 53.4083, GNorm = 2.5463, lr_0 = 3.9465e-04
Loss = 1.0263e-02, PNorm = 53.4260, GNorm = 2.3625, lr_0 = 3.9412e-04
Loss = 2.4750e-02, PNorm = 53.4282, GNorm = 3.6723, lr_0 = 3.9407e-04
Validation rmse = 2.981923
Validation R2 = -1.539002
Epoch 31
Train function
Loss = 7.3833e-03, PNorm = 53.4462, GNorm = 3.1332, lr_0 = 3.9354e-04
Loss = 9.4185e-03, PNorm = 53.4697, GNorm = 3.4437, lr_0 = 3.9301e-04
Loss = 8.1328e-03, PNorm = 53.4874, GNorm = 3.1589, lr_0 = 3.9248e-04
Loss = 7.8272e-03, PNorm = 53.5042, GNorm = 2.7099, lr_0 = 3.9195e-04
Loss = 8.6158e-03, PNorm = 53.5178, GNorm = 2.7751, lr_0 = 3.9143e-04
Loss = 8.5930e-03, PNorm = 53.5375, GNorm = 2.8653, lr_0 = 3.9090e-04
Loss = 8.3443e-03, PNorm = 53.5565, GNorm = 3.6448, lr_0 = 3.9038e-04
Loss = 7.5851e-03, PNorm = 53.5712, GNorm = 2.8350, lr_0 = 3.8986e-04
Loss = 8.3790e-03, PNorm = 53.5858, GNorm = 2.8717, lr_0 = 3.8933e-04
Loss = 7.7358e-03, PNorm = 53.5981, GNorm = 1.9840, lr_0 = 3.8881e-04
Loss = 8.0013e-03, PNorm = 53.6147, GNorm = 2.7495, lr_0 = 3.8829e-04
Loss = 8.2381e-03, PNorm = 53.6281, GNorm = 3.2603, lr_0 = 3.8777e-04
Loss = 8.5641e-03, PNorm = 53.6430, GNorm = 3.3070, lr_0 = 3.8725e-04
Loss = 8.5215e-03, PNorm = 53.6609, GNorm = 4.0804, lr_0 = 3.8673e-04
Loss = 8.9793e-03, PNorm = 53.6778, GNorm = 2.9076, lr_0 = 3.8621e-04
Loss = 8.8267e-03, PNorm = 53.6930, GNorm = 2.5694, lr_0 = 3.8569e-04
Loss = 9.4865e-03, PNorm = 53.7098, GNorm = 2.3169, lr_0 = 3.8517e-04
Loss = 7.7362e-03, PNorm = 53.7274, GNorm = 2.0769, lr_0 = 3.8466e-04
Loss = 9.0445e-03, PNorm = 53.7426, GNorm = 3.0393, lr_0 = 3.8414e-04
Loss = 1.0015e-02, PNorm = 53.7553, GNorm = 2.8684, lr_0 = 3.8362e-04
Loss = 6.9806e-03, PNorm = 53.7660, GNorm = 2.6643, lr_0 = 3.8311e-04
Loss = 7.8915e-03, PNorm = 53.7816, GNorm = 2.8065, lr_0 = 3.8260e-04
Loss = 7.3955e-03, PNorm = 53.8000, GNorm = 2.3632, lr_0 = 3.8208e-04
Validation rmse = 2.821075
Validation R2 = -1.272477
Epoch 32
Train function
Loss = 7.3228e-03, PNorm = 53.8180, GNorm = 3.1018, lr_0 = 3.8152e-04
Loss = 8.2718e-03, PNorm = 53.8380, GNorm = 2.4593, lr_0 = 3.8101e-04
Loss = 9.4541e-03, PNorm = 53.8570, GNorm = 2.5958, lr_0 = 3.8050e-04
Loss = 9.4456e-03, PNorm = 53.8728, GNorm = 2.5829, lr_0 = 3.7999e-04
Loss = 6.9749e-03, PNorm = 53.8872, GNorm = 2.3928, lr_0 = 3.7948e-04
Loss = 7.8124e-03, PNorm = 53.9048, GNorm = 2.5248, lr_0 = 3.7897e-04
Loss = 7.0734e-03, PNorm = 53.9224, GNorm = 3.3746, lr_0 = 3.7846e-04
Loss = 7.5121e-03, PNorm = 53.9399, GNorm = 3.1596, lr_0 = 3.7795e-04
Loss = 7.9458e-03, PNorm = 53.9550, GNorm = 2.6517, lr_0 = 3.7744e-04
Loss = 8.1074e-03, PNorm = 53.9706, GNorm = 2.8996, lr_0 = 3.7694e-04
Loss = 9.4788e-03, PNorm = 53.9844, GNorm = 3.8215, lr_0 = 3.7643e-04
Loss = 7.4518e-03, PNorm = 53.9996, GNorm = 2.3176, lr_0 = 3.7593e-04
Loss = 7.9153e-03, PNorm = 54.0160, GNorm = 3.3143, lr_0 = 3.7542e-04
Loss = 7.9605e-03, PNorm = 54.0314, GNorm = 4.2963, lr_0 = 3.7492e-04
Loss = 7.4596e-03, PNorm = 54.0444, GNorm = 3.2549, lr_0 = 3.7441e-04
Loss = 8.1186e-03, PNorm = 54.0585, GNorm = 2.7574, lr_0 = 3.7391e-04
Loss = 8.5560e-03, PNorm = 54.0692, GNorm = 2.8438, lr_0 = 3.7341e-04
Loss = 8.0323e-03, PNorm = 54.0832, GNorm = 2.7767, lr_0 = 3.7291e-04
Loss = 7.8620e-03, PNorm = 54.0951, GNorm = 2.4871, lr_0 = 3.7241e-04
Loss = 8.1106e-03, PNorm = 54.1061, GNorm = 2.4239, lr_0 = 3.7191e-04
Loss = 6.6555e-03, PNorm = 54.1196, GNorm = 3.2987, lr_0 = 3.7141e-04
Loss = 7.1571e-03, PNorm = 54.1327, GNorm = 2.9850, lr_0 = 3.7091e-04
Loss = 8.9558e-03, PNorm = 54.1484, GNorm = 2.7002, lr_0 = 3.7041e-04
Validation rmse = 3.254623
Validation R2 = -2.024625
Epoch 33
Train function
Loss = 9.3935e-03, PNorm = 54.1659, GNorm = 3.0296, lr_0 = 3.6987e-04
Loss = 7.4735e-03, PNorm = 54.1830, GNorm = 1.9735, lr_0 = 3.6937e-04
Loss = 6.9317e-03, PNorm = 54.2000, GNorm = 2.6020, lr_0 = 3.6888e-04
Loss = 6.6309e-03, PNorm = 54.2183, GNorm = 2.0132, lr_0 = 3.6838e-04
Loss = 7.1174e-03, PNorm = 54.2376, GNorm = 1.8023, lr_0 = 3.6789e-04
Loss = 7.2583e-03, PNorm = 54.2532, GNorm = 3.5262, lr_0 = 3.6739e-04
Loss = 7.4218e-03, PNorm = 54.2681, GNorm = 3.9158, lr_0 = 3.6690e-04
Loss = 7.8125e-03, PNorm = 54.2858, GNorm = 3.6771, lr_0 = 3.6641e-04
Loss = 8.2495e-03, PNorm = 54.2991, GNorm = 3.0185, lr_0 = 3.6592e-04
Loss = 7.6484e-03, PNorm = 54.3148, GNorm = 2.6091, lr_0 = 3.6543e-04
Loss = 7.6103e-03, PNorm = 54.3313, GNorm = 3.6337, lr_0 = 3.6494e-04
Loss = 8.0081e-03, PNorm = 54.3437, GNorm = 4.5596, lr_0 = 3.6445e-04
Loss = 7.0788e-03, PNorm = 54.3560, GNorm = 2.9230, lr_0 = 3.6396e-04
Loss = 8.8410e-03, PNorm = 54.3685, GNorm = 3.0060, lr_0 = 3.6347e-04
Loss = 8.6618e-03, PNorm = 54.3813, GNorm = 3.5608, lr_0 = 3.6298e-04
Loss = 8.0542e-03, PNorm = 54.3921, GNorm = 3.5122, lr_0 = 3.6249e-04
Loss = 7.7659e-03, PNorm = 54.4070, GNorm = 2.2898, lr_0 = 3.6201e-04
Loss = 5.8954e-03, PNorm = 54.4202, GNorm = 2.3302, lr_0 = 3.6152e-04
Loss = 7.5833e-03, PNorm = 54.4362, GNorm = 3.1558, lr_0 = 3.6104e-04
Loss = 6.4229e-03, PNorm = 54.4509, GNorm = 2.9000, lr_0 = 3.6055e-04
Loss = 7.5508e-03, PNorm = 54.4656, GNorm = 2.6978, lr_0 = 3.6007e-04
Loss = 7.3988e-03, PNorm = 54.4764, GNorm = 2.7385, lr_0 = 3.5959e-04
Loss = 6.9251e-03, PNorm = 54.4883, GNorm = 2.3138, lr_0 = 3.5910e-04
Loss = 8.1793e-03, PNorm = 54.5026, GNorm = 2.6247, lr_0 = 3.5862e-04
Validation rmse = 3.222420
Validation R2 = -1.965067
Epoch 34
Train function
Loss = 6.0783e-03, PNorm = 54.5198, GNorm = 2.9613, lr_0 = 3.5809e-04
Loss = 6.2707e-03, PNorm = 54.5337, GNorm = 4.5423, lr_0 = 3.5761e-04
Loss = 5.7482e-03, PNorm = 54.5482, GNorm = 2.3700, lr_0 = 3.5713e-04
Loss = 5.0583e-03, PNorm = 54.5657, GNorm = 2.5291, lr_0 = 3.5665e-04
Loss = 7.8908e-03, PNorm = 54.5816, GNorm = 3.2504, lr_0 = 3.5617e-04
Loss = 6.6655e-03, PNorm = 54.5986, GNorm = 3.2575, lr_0 = 3.5570e-04
Loss = 6.2886e-03, PNorm = 54.6145, GNorm = 2.9659, lr_0 = 3.5522e-04
Loss = 6.5549e-03, PNorm = 54.6295, GNorm = 1.7408, lr_0 = 3.5474e-04
Loss = 7.1389e-03, PNorm = 54.6445, GNorm = 4.1387, lr_0 = 3.5427e-04
Loss = 7.1789e-03, PNorm = 54.6606, GNorm = 3.0188, lr_0 = 3.5379e-04
Loss = 7.1052e-03, PNorm = 54.6749, GNorm = 2.1449, lr_0 = 3.5332e-04
Loss = 6.9927e-03, PNorm = 54.6897, GNorm = 4.1324, lr_0 = 3.5284e-04
Loss = 7.5222e-03, PNorm = 54.7039, GNorm = 3.7335, lr_0 = 3.5237e-04
Loss = 8.4063e-03, PNorm = 54.7120, GNorm = 3.1218, lr_0 = 3.5190e-04
Loss = 7.1278e-03, PNorm = 54.7217, GNorm = 2.3948, lr_0 = 3.5142e-04
Loss = 9.0054e-03, PNorm = 54.7338, GNorm = 2.8767, lr_0 = 3.5095e-04
Loss = 7.1714e-03, PNorm = 54.7427, GNorm = 3.4717, lr_0 = 3.5048e-04
Loss = 7.6763e-03, PNorm = 54.7547, GNorm = 3.6231, lr_0 = 3.5001e-04
Loss = 7.5662e-03, PNorm = 54.7650, GNorm = 4.0162, lr_0 = 3.4954e-04
Loss = 7.0042e-03, PNorm = 54.7771, GNorm = 2.4925, lr_0 = 3.4907e-04
Loss = 7.5854e-03, PNorm = 54.7924, GNorm = 3.0789, lr_0 = 3.4860e-04
Loss = 6.0263e-03, PNorm = 54.8090, GNorm = 2.5003, lr_0 = 3.4814e-04
Loss = 6.2965e-03, PNorm = 54.8247, GNorm = 1.7989, lr_0 = 3.4767e-04
Validation rmse = 3.355027
Validation R2 = -2.214120
Epoch 35
Train function
Loss = 6.5923e-03, PNorm = 54.8370, GNorm = 2.3524, lr_0 = 3.4720e-04
Loss = 5.6709e-03, PNorm = 54.8514, GNorm = 3.2189, lr_0 = 3.4674e-04
Loss = 6.6139e-03, PNorm = 54.8677, GNorm = 4.3976, lr_0 = 3.4627e-04
Loss = 5.1071e-03, PNorm = 54.8808, GNorm = 3.1578, lr_0 = 3.4581e-04
Loss = 7.4160e-03, PNorm = 54.8965, GNorm = 2.5743, lr_0 = 3.4534e-04
Loss = 6.4742e-03, PNorm = 54.9096, GNorm = 5.1791, lr_0 = 3.4488e-04
Loss = 5.7679e-03, PNorm = 54.9223, GNorm = 2.7610, lr_0 = 3.4442e-04
Loss = 6.4000e-03, PNorm = 54.9326, GNorm = 2.3808, lr_0 = 3.4395e-04
Loss = 6.6370e-03, PNorm = 54.9465, GNorm = 2.6555, lr_0 = 3.4349e-04
Loss = 6.4418e-03, PNorm = 54.9592, GNorm = 3.4140, lr_0 = 3.4303e-04
Loss = 6.2032e-03, PNorm = 54.9706, GNorm = 3.1097, lr_0 = 3.4257e-04
Loss = 6.3021e-03, PNorm = 54.9846, GNorm = 1.8748, lr_0 = 3.4211e-04
Loss = 5.8038e-03, PNorm = 54.9949, GNorm = 2.0638, lr_0 = 3.4165e-04
Loss = 5.5902e-03, PNorm = 55.0070, GNorm = 1.8105, lr_0 = 3.4120e-04
Loss = 5.6290e-03, PNorm = 55.0205, GNorm = 3.3736, lr_0 = 3.4074e-04
Loss = 6.7782e-03, PNorm = 55.0333, GNorm = 2.1386, lr_0 = 3.4028e-04
Loss = 8.4870e-03, PNorm = 55.0514, GNorm = 3.0506, lr_0 = 3.3982e-04
Loss = 8.4801e-03, PNorm = 55.0660, GNorm = 3.0759, lr_0 = 3.3937e-04
Loss = 7.7872e-03, PNorm = 55.0804, GNorm = 3.4320, lr_0 = 3.3891e-04
Loss = 6.8957e-03, PNorm = 55.0947, GNorm = 2.6215, lr_0 = 3.3846e-04
Loss = 7.3652e-03, PNorm = 55.1077, GNorm = 4.5322, lr_0 = 3.3800e-04
Loss = 7.5580e-03, PNorm = 55.1226, GNorm = 4.4915, lr_0 = 3.3755e-04
Loss = 6.8409e-03, PNorm = 55.1360, GNorm = 2.6019, lr_0 = 3.3710e-04
Loss = 7.2998e-03, PNorm = 55.1466, GNorm = 4.2294, lr_0 = 3.3664e-04
Validation rmse = 3.461704
Validation R2 = -2.421763
Epoch 36
Train function
Loss = 6.2577e-03, PNorm = 55.1601, GNorm = 4.6041, lr_0 = 3.3615e-04
Loss = 4.6960e-03, PNorm = 55.1750, GNorm = 3.4060, lr_0 = 3.3570e-04
Loss = 5.9467e-03, PNorm = 55.1896, GNorm = 3.1563, lr_0 = 3.3525e-04
Loss = 5.1973e-03, PNorm = 55.2018, GNorm = 4.6080, lr_0 = 3.3480e-04
Loss = 6.4166e-03, PNorm = 55.2136, GNorm = 3.0150, lr_0 = 3.3435e-04
Loss = 5.7930e-03, PNorm = 55.2251, GNorm = 3.4159, lr_0 = 3.3390e-04
Loss = 5.8560e-03, PNorm = 55.2371, GNorm = 2.6208, lr_0 = 3.3345e-04
Loss = 4.9156e-03, PNorm = 55.2464, GNorm = 2.7437, lr_0 = 3.3300e-04
Loss = 6.0789e-03, PNorm = 55.2584, GNorm = 1.9624, lr_0 = 3.3256e-04
Loss = 6.3459e-03, PNorm = 55.2711, GNorm = 2.6229, lr_0 = 3.3211e-04
Loss = 7.3199e-03, PNorm = 55.2849, GNorm = 5.0536, lr_0 = 3.3167e-04
Loss = 6.9377e-03, PNorm = 55.3020, GNorm = 3.5696, lr_0 = 3.3122e-04
Loss = 4.7125e-03, PNorm = 55.3118, GNorm = 2.9079, lr_0 = 3.3078e-04
Loss = 6.7662e-03, PNorm = 55.3214, GNorm = 3.0745, lr_0 = 3.3033e-04
Loss = 5.2951e-03, PNorm = 55.3304, GNorm = 2.4853, lr_0 = 3.2989e-04
Loss = 6.4280e-03, PNorm = 55.3417, GNorm = 2.3737, lr_0 = 3.2945e-04
Loss = 5.2432e-03, PNorm = 55.3533, GNorm = 2.1594, lr_0 = 3.2900e-04
Loss = 6.9779e-03, PNorm = 55.3677, GNorm = 3.4224, lr_0 = 3.2856e-04
Loss = 5.3808e-03, PNorm = 55.3801, GNorm = 2.5894, lr_0 = 3.2812e-04
Loss = 6.1096e-03, PNorm = 55.3923, GNorm = 2.4389, lr_0 = 3.2768e-04
Loss = 8.4679e-03, PNorm = 55.4034, GNorm = 5.1190, lr_0 = 3.2724e-04
Loss = 7.2210e-03, PNorm = 55.4178, GNorm = 1.8709, lr_0 = 3.2680e-04
Loss = 7.8632e-03, PNorm = 55.4335, GNorm = 2.5660, lr_0 = 3.2636e-04
Validation rmse = 3.473349
Validation R2 = -2.444824
Epoch 37
Train function
Loss = 4.5963e-03, PNorm = 55.4478, GNorm = 2.7915, lr_0 = 3.2588e-04
Loss = 5.7552e-03, PNorm = 55.4576, GNorm = 3.1357, lr_0 = 3.2545e-04
Loss = 4.5571e-03, PNorm = 55.4685, GNorm = 2.4143, lr_0 = 3.2501e-04
Loss = 5.6649e-03, PNorm = 55.4791, GNorm = 2.1896, lr_0 = 3.2457e-04
Loss = 4.9770e-03, PNorm = 55.4893, GNorm = 3.4421, lr_0 = 3.2414e-04
Loss = 6.0480e-03, PNorm = 55.5019, GNorm = 2.8018, lr_0 = 3.2370e-04
Loss = 5.7554e-03, PNorm = 55.5151, GNorm = 3.3935, lr_0 = 3.2327e-04
Loss = 6.9511e-03, PNorm = 55.5281, GNorm = 2.2637, lr_0 = 3.2283e-04
Loss = 5.8148e-03, PNorm = 55.5414, GNorm = 3.6751, lr_0 = 3.2240e-04
Loss = 5.5953e-03, PNorm = 55.5511, GNorm = 2.3436, lr_0 = 3.2197e-04
Loss = 6.2196e-03, PNorm = 55.5595, GNorm = 4.2663, lr_0 = 3.2154e-04
Loss = 6.1288e-03, PNorm = 55.5713, GNorm = 3.0303, lr_0 = 3.2111e-04
Loss = 5.0119e-03, PNorm = 55.5841, GNorm = 2.8560, lr_0 = 3.2067e-04
Loss = 5.1182e-03, PNorm = 55.5924, GNorm = 2.8008, lr_0 = 3.2024e-04
Loss = 5.8058e-03, PNorm = 55.6019, GNorm = 2.9632, lr_0 = 3.1981e-04
Loss = 5.7265e-03, PNorm = 55.6157, GNorm = 2.5144, lr_0 = 3.1939e-04
Loss = 5.9349e-03, PNorm = 55.6296, GNorm = 1.8164, lr_0 = 3.1896e-04
Loss = 5.3105e-03, PNorm = 55.6430, GNorm = 2.2507, lr_0 = 3.1853e-04
Loss = 5.5637e-03, PNorm = 55.6554, GNorm = 3.3903, lr_0 = 3.1810e-04
Loss = 5.6681e-03, PNorm = 55.6659, GNorm = 2.2789, lr_0 = 3.1767e-04
Loss = 6.9522e-03, PNorm = 55.6772, GNorm = 3.7101, lr_0 = 3.1725e-04
Loss = 7.7546e-03, PNorm = 55.6904, GNorm = 2.8716, lr_0 = 3.1682e-04
Loss = 6.7759e-03, PNorm = 55.7023, GNorm = 2.7630, lr_0 = 3.1640e-04
Validation rmse = 3.561431
Validation R2 = -2.621756
Epoch 38
Train function
Loss = 3.5656e-03, PNorm = 55.7110, GNorm = 2.3822, lr_0 = 3.1593e-04
Loss = 5.1596e-03, PNorm = 55.7192, GNorm = 3.8475, lr_0 = 3.1551e-04
Loss = 5.6261e-03, PNorm = 55.7309, GNorm = 2.1721, lr_0 = 3.1508e-04
Loss = 5.4743e-03, PNorm = 55.7461, GNorm = 3.1206, lr_0 = 3.1466e-04
Loss = 4.9318e-03, PNorm = 55.7591, GNorm = 1.9433, lr_0 = 3.1424e-04
Loss = 6.1841e-03, PNorm = 55.7734, GNorm = 3.2307, lr_0 = 3.1382e-04
Loss = 4.3443e-03, PNorm = 55.7866, GNorm = 2.9003, lr_0 = 3.1340e-04
Loss = 4.1701e-03, PNorm = 55.8010, GNorm = 1.8104, lr_0 = 3.1298e-04
Loss = 4.5872e-03, PNorm = 55.8087, GNorm = 2.6961, lr_0 = 3.1256e-04
Loss = 5.0437e-03, PNorm = 55.8186, GNorm = 2.0528, lr_0 = 3.1214e-04
Loss = 4.3955e-03, PNorm = 55.8296, GNorm = 3.3053, lr_0 = 3.1172e-04
Loss = 5.7709e-03, PNorm = 55.8401, GNorm = 2.3039, lr_0 = 3.1130e-04
Loss = 5.9553e-03, PNorm = 55.8501, GNorm = 3.5049, lr_0 = 3.1088e-04
Loss = 5.8256e-03, PNorm = 55.8574, GNorm = 2.1470, lr_0 = 3.1046e-04
Loss = 5.5605e-03, PNorm = 55.8652, GNorm = 2.4680, lr_0 = 3.1005e-04
Loss = 5.6372e-03, PNorm = 55.8740, GNorm = 2.1838, lr_0 = 3.0963e-04
Loss = 5.2667e-03, PNorm = 55.8841, GNorm = 3.6584, lr_0 = 3.0922e-04
Loss = 5.0466e-03, PNorm = 55.8936, GNorm = 2.4536, lr_0 = 3.0880e-04
Loss = 5.4668e-03, PNorm = 55.9004, GNorm = 3.1375, lr_0 = 3.0839e-04
Loss = 6.0609e-03, PNorm = 55.9117, GNorm = 2.9964, lr_0 = 3.0797e-04
Loss = 5.4535e-03, PNorm = 55.9217, GNorm = 3.5418, lr_0 = 3.0756e-04
Loss = 6.5599e-03, PNorm = 55.9312, GNorm = 2.7793, lr_0 = 3.0715e-04
Loss = 5.7481e-03, PNorm = 55.9427, GNorm = 4.9086, lr_0 = 3.0674e-04
Loss = 6.3581e-03, PNorm = 55.9537, GNorm = 3.6457, lr_0 = 3.0632e-04
Validation rmse = 3.353203
Validation R2 = -2.210627
Epoch 39
Train function
Loss = 4.0327e-03, PNorm = 55.9640, GNorm = 1.7032, lr_0 = 3.0587e-04
Loss = 5.0185e-03, PNorm = 55.9738, GNorm = 1.5701, lr_0 = 3.0546e-04
Loss = 6.1181e-03, PNorm = 55.9838, GNorm = 3.0587, lr_0 = 3.0505e-04
Loss = 5.2101e-03, PNorm = 55.9962, GNorm = 3.0505, lr_0 = 3.0464e-04
Loss = 4.8478e-03, PNorm = 56.0075, GNorm = 2.1203, lr_0 = 3.0423e-04
Loss = 4.6182e-03, PNorm = 56.0197, GNorm = 3.6316, lr_0 = 3.0383e-04
Loss = 4.7764e-03, PNorm = 56.0300, GNorm = 3.4631, lr_0 = 3.0342e-04
Loss = 5.7696e-03, PNorm = 56.0399, GNorm = 2.5438, lr_0 = 3.0301e-04
Loss = 4.3096e-03, PNorm = 56.0525, GNorm = 1.8296, lr_0 = 3.0260e-04
Loss = 4.5436e-03, PNorm = 56.0616, GNorm = 2.9765, lr_0 = 3.0220e-04
Loss = 5.6503e-03, PNorm = 56.0743, GNorm = 2.2070, lr_0 = 3.0179e-04
Loss = 6.0627e-03, PNorm = 56.0866, GNorm = 2.4640, lr_0 = 3.0139e-04
Loss = 5.0221e-03, PNorm = 56.0985, GNorm = 2.9691, lr_0 = 3.0098e-04
Loss = 5.1784e-03, PNorm = 56.1106, GNorm = 3.0351, lr_0 = 3.0058e-04
Loss = 5.0699e-03, PNorm = 56.1204, GNorm = 2.5214, lr_0 = 3.0018e-04
Loss = 5.1592e-03, PNorm = 56.1317, GNorm = 3.6483, lr_0 = 2.9977e-04
Loss = 6.1461e-03, PNorm = 56.1379, GNorm = 2.8794, lr_0 = 2.9937e-04
Loss = 4.9612e-03, PNorm = 56.1431, GNorm = 2.5313, lr_0 = 2.9897e-04
Loss = 5.3803e-03, PNorm = 56.1511, GNorm = 3.1537, lr_0 = 2.9857e-04
Loss = 5.8893e-03, PNorm = 56.1581, GNorm = 2.3310, lr_0 = 2.9817e-04
Loss = 5.3105e-03, PNorm = 56.1675, GNorm = 3.3613, lr_0 = 2.9777e-04
Loss = 5.2343e-03, PNorm = 56.1798, GNorm = 4.5378, lr_0 = 2.9737e-04
Loss = 5.8247e-03, PNorm = 56.1905, GNorm = 2.7969, lr_0 = 2.9697e-04
Validation rmse = 3.964384
Validation R2 = -3.487677
Epoch 40
Train function
Loss = 7.0589e-03, PNorm = 56.2003, GNorm = 3.4784, lr_0 = 2.9657e-04
Loss = 4.8952e-03, PNorm = 56.2088, GNorm = 2.3338, lr_0 = 2.9617e-04
Loss = 6.5877e-03, PNorm = 56.2223, GNorm = 4.7528, lr_0 = 2.9578e-04
Loss = 4.3642e-03, PNorm = 56.2342, GNorm = 2.6033, lr_0 = 2.9538e-04
Loss = 4.4399e-03, PNorm = 56.2449, GNorm = 2.1135, lr_0 = 2.9498e-04
Loss = 6.3919e-03, PNorm = 56.2577, GNorm = 2.4668, lr_0 = 2.9459e-04
Loss = 3.8865e-03, PNorm = 56.2687, GNorm = 2.7077, lr_0 = 2.9419e-04
Loss = 5.4219e-03, PNorm = 56.2785, GNorm = 2.1032, lr_0 = 2.9380e-04
Loss = 4.5295e-03, PNorm = 56.2874, GNorm = 1.7566, lr_0 = 2.9340e-04
Loss = 4.5997e-03, PNorm = 56.2972, GNorm = 2.8418, lr_0 = 2.9301e-04
Loss = 4.2122e-03, PNorm = 56.3053, GNorm = 2.9030, lr_0 = 2.9262e-04
Loss = 4.9362e-03, PNorm = 56.3150, GNorm = 3.4536, lr_0 = 2.9222e-04
Loss = 4.8380e-03, PNorm = 56.3261, GNorm = 2.0355, lr_0 = 2.9183e-04
Loss = 5.7684e-03, PNorm = 56.3365, GNorm = 3.5114, lr_0 = 2.9144e-04
Loss = 4.5853e-03, PNorm = 56.3446, GNorm = 5.0279, lr_0 = 2.9105e-04
Loss = 5.4443e-03, PNorm = 56.3547, GNorm = 4.1058, lr_0 = 2.9066e-04
Loss = 5.0528e-03, PNorm = 56.3649, GNorm = 2.8065, lr_0 = 2.9027e-04
Loss = 4.7875e-03, PNorm = 56.3720, GNorm = 3.2230, lr_0 = 2.8988e-04
Loss = 4.2610e-03, PNorm = 56.3800, GNorm = 2.8016, lr_0 = 2.8949e-04
Loss = 5.0574e-03, PNorm = 56.3911, GNorm = 4.1589, lr_0 = 2.8910e-04
Loss = 5.0391e-03, PNorm = 56.4028, GNorm = 2.4639, lr_0 = 2.8871e-04
Loss = 4.4068e-03, PNorm = 56.4125, GNorm = 1.8772, lr_0 = 2.8833e-04
Loss = 4.4366e-03, PNorm = 56.4212, GNorm = 1.3199, lr_0 = 2.8794e-04
Loss = 5.3057e-03, PNorm = 56.4294, GNorm = 3.6323, lr_0 = 2.8755e-04
Validation rmse = 3.427888
Validation R2 = -2.355239
Epoch 41
Train function
Loss = 5.3955e-03, PNorm = 56.4423, GNorm = 3.8497, lr_0 = 2.8713e-04
Loss = 3.3492e-03, PNorm = 56.4541, GNorm = 2.8254, lr_0 = 2.8674e-04
Loss = 4.2246e-03, PNorm = 56.4635, GNorm = 1.6587, lr_0 = 2.8636e-04
Loss = 4.2309e-03, PNorm = 56.4704, GNorm = 2.9436, lr_0 = 2.8597e-04
Loss = 4.2117e-03, PNorm = 56.4803, GNorm = 2.6764, lr_0 = 2.8559e-04
Loss = 3.2396e-03, PNorm = 56.4906, GNorm = 2.8053, lr_0 = 2.8521e-04
Loss = 4.3193e-03, PNorm = 56.5000, GNorm = 3.2470, lr_0 = 2.8482e-04
Loss = 4.1632e-03, PNorm = 56.5089, GNorm = 3.0385, lr_0 = 2.8444e-04
Loss = 3.9235e-03, PNorm = 56.5174, GNorm = 3.5305, lr_0 = 2.8406e-04
Loss = 4.5682e-03, PNorm = 56.5270, GNorm = 2.8869, lr_0 = 2.8368e-04
Loss = 4.9016e-03, PNorm = 56.5358, GNorm = 2.6197, lr_0 = 2.8330e-04
Loss = 4.2189e-03, PNorm = 56.5455, GNorm = 2.1247, lr_0 = 2.8292e-04
Loss = 4.9312e-03, PNorm = 56.5538, GNorm = 3.9060, lr_0 = 2.8254e-04
Loss = 4.4553e-03, PNorm = 56.5633, GNorm = 3.0166, lr_0 = 2.8216e-04
Loss = 3.6672e-03, PNorm = 56.5728, GNorm = 2.7309, lr_0 = 2.8178e-04
Loss = 4.8746e-03, PNorm = 56.5833, GNorm = 2.1655, lr_0 = 2.8140e-04
Loss = 4.8637e-03, PNorm = 56.5922, GNorm = 3.2663, lr_0 = 2.8103e-04
Loss = 4.9161e-03, PNorm = 56.6010, GNorm = 2.2359, lr_0 = 2.8065e-04
Loss = 5.3366e-03, PNorm = 56.6097, GNorm = 3.0097, lr_0 = 2.8027e-04
Loss = 4.7347e-03, PNorm = 56.6188, GNorm = 1.4455, lr_0 = 2.7990e-04
Loss = 5.1276e-03, PNorm = 56.6287, GNorm = 2.8815, lr_0 = 2.7952e-04
Loss = 5.4683e-03, PNorm = 56.6371, GNorm = 4.3074, lr_0 = 2.7915e-04
Loss = 5.4229e-03, PNorm = 56.6457, GNorm = 2.0414, lr_0 = 2.7877e-04
Validation rmse = 3.588814
Validation R2 = -2.677663
Epoch 42
Train function
Loss = 3.5600e-03, PNorm = 56.6551, GNorm = 2.5666, lr_0 = 2.7836e-04
Loss = 4.0777e-03, PNorm = 56.6638, GNorm = 2.4868, lr_0 = 2.7799e-04
Loss = 3.8296e-03, PNorm = 56.6716, GNorm = 2.7804, lr_0 = 2.7761e-04
Loss = 4.0385e-03, PNorm = 56.6822, GNorm = 2.5132, lr_0 = 2.7724e-04
Loss = 4.5537e-03, PNorm = 56.6909, GNorm = 2.5665, lr_0 = 2.7687e-04
Loss = 4.1231e-03, PNorm = 56.6988, GNorm = 2.6074, lr_0 = 2.7650e-04
Loss = 4.3095e-03, PNorm = 56.7077, GNorm = 3.8146, lr_0 = 2.7613e-04
Loss = 4.4131e-03, PNorm = 56.7184, GNorm = 3.3467, lr_0 = 2.7576e-04
Loss = 4.1823e-03, PNorm = 56.7291, GNorm = 3.4988, lr_0 = 2.7539e-04
Loss = 4.5669e-03, PNorm = 56.7383, GNorm = 4.4992, lr_0 = 2.7502e-04
Loss = 3.6740e-03, PNorm = 56.7490, GNorm = 2.0571, lr_0 = 2.7465e-04
Loss = 4.5549e-03, PNorm = 56.7588, GNorm = 2.9772, lr_0 = 2.7428e-04
Loss = 3.8713e-03, PNorm = 56.7677, GNorm = 2.3966, lr_0 = 2.7391e-04
Loss = 4.6600e-03, PNorm = 56.7772, GNorm = 2.1904, lr_0 = 2.7354e-04
Loss = 4.5909e-03, PNorm = 56.7855, GNorm = 3.0659, lr_0 = 2.7318e-04
Loss = 4.0382e-03, PNorm = 56.7946, GNorm = 4.3033, lr_0 = 2.7281e-04
Loss = 4.2554e-03, PNorm = 56.8041, GNorm = 2.4329, lr_0 = 2.7244e-04
Loss = 4.5226e-03, PNorm = 56.8135, GNorm = 2.8515, lr_0 = 2.7208e-04
Loss = 3.7171e-03, PNorm = 56.8208, GNorm = 3.0420, lr_0 = 2.7171e-04
Loss = 6.2200e-03, PNorm = 56.8278, GNorm = 3.0668, lr_0 = 2.7135e-04
Loss = 4.4880e-03, PNorm = 56.8360, GNorm = 2.4679, lr_0 = 2.7098e-04
Loss = 5.2225e-03, PNorm = 56.8455, GNorm = 2.1482, lr_0 = 2.7062e-04
Loss = 4.8832e-03, PNorm = 56.8534, GNorm = 1.9725, lr_0 = 2.7026e-04
Loss = 4.4608e-03, PNorm = 56.8616, GNorm = 2.8826, lr_0 = 2.6990e-04
Loss = 5.3648e-02, PNorm = 56.8625, GNorm = 9.5047, lr_0 = 2.6986e-04
Validation rmse = 4.021634
Validation R2 = -3.618225
Epoch 43
Train function
Loss = 4.5776e-03, PNorm = 56.8741, GNorm = 3.0382, lr_0 = 2.6950e-04
Loss = 3.7621e-03, PNorm = 56.8846, GNorm = 2.2486, lr_0 = 2.6914e-04
Loss = 3.2840e-03, PNorm = 56.8935, GNorm = 3.3695, lr_0 = 2.6877e-04
Loss = 4.5360e-03, PNorm = 56.9021, GNorm = 2.3966, lr_0 = 2.6841e-04
Loss = 3.1483e-03, PNorm = 56.9111, GNorm = 2.7958, lr_0 = 2.6805e-04
Loss = 4.8560e-03, PNorm = 56.9199, GNorm = 4.0525, lr_0 = 2.6769e-04
Loss = 3.9384e-03, PNorm = 56.9277, GNorm = 2.1334, lr_0 = 2.6733e-04
Loss = 4.4051e-03, PNorm = 56.9352, GNorm = 3.1831, lr_0 = 2.6698e-04
Loss = 4.0184e-03, PNorm = 56.9425, GNorm = 2.1509, lr_0 = 2.6662e-04
Loss = 4.1386e-03, PNorm = 56.9509, GNorm = 3.8875, lr_0 = 2.6626e-04
Loss = 3.6643e-03, PNorm = 56.9558, GNorm = 2.1526, lr_0 = 2.6590e-04
Loss = 4.3986e-03, PNorm = 56.9621, GNorm = 2.1510, lr_0 = 2.6555e-04
Loss = 4.1317e-03, PNorm = 56.9699, GNorm = 2.9502, lr_0 = 2.6519e-04
Loss = 4.3745e-03, PNorm = 56.9782, GNorm = 2.2576, lr_0 = 2.6483e-04
Loss = 4.7502e-03, PNorm = 56.9851, GNorm = 3.3277, lr_0 = 2.6448e-04
Loss = 3.9455e-03, PNorm = 56.9910, GNorm = 2.5813, lr_0 = 2.6412e-04
Loss = 4.8310e-03, PNorm = 57.0011, GNorm = 4.1388, lr_0 = 2.6377e-04
Loss = 3.6292e-03, PNorm = 57.0106, GNorm = 3.0953, lr_0 = 2.6342e-04
Loss = 3.9707e-03, PNorm = 57.0206, GNorm = 3.5891, lr_0 = 2.6306e-04
Loss = 4.8664e-03, PNorm = 57.0302, GNorm = 3.8392, lr_0 = 2.6271e-04
Loss = 4.7361e-03, PNorm = 57.0395, GNorm = 4.0596, lr_0 = 2.6236e-04
Loss = 3.7197e-03, PNorm = 57.0498, GNorm = 2.1543, lr_0 = 2.6200e-04
Loss = 3.4739e-03, PNorm = 57.0566, GNorm = 2.3836, lr_0 = 2.6165e-04
Validation rmse = 3.859005
Validation R2 = -3.252271
Epoch 44
Train function
Loss = 3.3016e-03, PNorm = 57.0630, GNorm = 2.4667, lr_0 = 2.6127e-04
Loss = 3.3096e-03, PNorm = 57.0681, GNorm = 3.9667, lr_0 = 2.6092e-04
Loss = 3.2661e-03, PNorm = 57.0755, GNorm = 2.6282, lr_0 = 2.6057e-04
Loss = 3.0088e-03, PNorm = 57.0845, GNorm = 3.0581, lr_0 = 2.6022e-04
Loss = 3.9145e-03, PNorm = 57.0926, GNorm = 2.3768, lr_0 = 2.5987e-04
Loss = 3.0249e-03, PNorm = 57.0999, GNorm = 2.8170, lr_0 = 2.5952e-04
Loss = 3.7699e-03, PNorm = 57.1055, GNorm = 3.0471, lr_0 = 2.5917e-04
Loss = 3.2998e-03, PNorm = 57.1129, GNorm = 2.6282, lr_0 = 2.5882e-04
Loss = 3.6835e-03, PNorm = 57.1217, GNorm = 2.8231, lr_0 = 2.5848e-04
Loss = 3.2316e-03, PNorm = 57.1292, GNorm = 2.5566, lr_0 = 2.5813e-04
Loss = 4.0197e-03, PNorm = 57.1337, GNorm = 2.7121, lr_0 = 2.5778e-04
Loss = 3.9230e-03, PNorm = 57.1404, GNorm = 2.2092, lr_0 = 2.5744e-04
Loss = 3.4131e-03, PNorm = 57.1481, GNorm = 1.6773, lr_0 = 2.5709e-04
Loss = 3.4767e-03, PNorm = 57.1548, GNorm = 1.9999, lr_0 = 2.5675e-04
Loss = 4.0914e-03, PNorm = 57.1595, GNorm = 2.7458, lr_0 = 2.5640e-04
Loss = 3.2111e-03, PNorm = 57.1668, GNorm = 4.0295, lr_0 = 2.5606e-04
Loss = 3.9524e-03, PNorm = 57.1770, GNorm = 4.0239, lr_0 = 2.5571e-04
Loss = 4.9016e-03, PNorm = 57.1862, GNorm = 1.7361, lr_0 = 2.5537e-04
Loss = 3.7352e-03, PNorm = 57.1926, GNorm = 2.3460, lr_0 = 2.5503e-04
Loss = 4.8604e-03, PNorm = 57.1997, GNorm = 4.5018, lr_0 = 2.5469e-04
Loss = 4.2471e-03, PNorm = 57.2071, GNorm = 2.9046, lr_0 = 2.5434e-04
Loss = 3.9673e-03, PNorm = 57.2141, GNorm = 3.9919, lr_0 = 2.5400e-04
Loss = 4.5686e-03, PNorm = 57.2202, GNorm = 1.3348, lr_0 = 2.5366e-04
Validation rmse = 3.828030
Validation R2 = -3.184280
Epoch 45
Train function
Loss = 2.6169e-03, PNorm = 57.2264, GNorm = 1.8503, lr_0 = 2.5332e-04
Loss = 3.7347e-03, PNorm = 57.2331, GNorm = 2.9574, lr_0 = 2.5298e-04
Loss = 3.2474e-03, PNorm = 57.2415, GNorm = 3.5000, lr_0 = 2.5264e-04
Loss = 3.4786e-03, PNorm = 57.2493, GNorm = 3.3364, lr_0 = 2.5230e-04
Loss = 2.8803e-03, PNorm = 57.2565, GNorm = 3.0395, lr_0 = 2.5197e-04
Loss = 3.0400e-03, PNorm = 57.2635, GNorm = 2.8648, lr_0 = 2.5163e-04
Loss = 2.5736e-03, PNorm = 57.2696, GNorm = 1.6179, lr_0 = 2.5129e-04
Loss = 2.8072e-03, PNorm = 57.2775, GNorm = 2.4639, lr_0 = 2.5095e-04
Loss = 3.4470e-03, PNorm = 57.2839, GNorm = 2.4362, lr_0 = 2.5062e-04
Loss = 3.8928e-03, PNorm = 57.2919, GNorm = 2.2377, lr_0 = 2.5028e-04
Loss = 3.1206e-03, PNorm = 57.3016, GNorm = 2.9928, lr_0 = 2.4994e-04
Loss = 3.0351e-03, PNorm = 57.3103, GNorm = 2.5822, lr_0 = 2.4961e-04
Loss = 3.5529e-03, PNorm = 57.3173, GNorm = 1.8486, lr_0 = 2.4927e-04
Loss = 3.1233e-03, PNorm = 57.3231, GNorm = 1.7162, lr_0 = 2.4894e-04
Loss = 3.1434e-03, PNorm = 57.3302, GNorm = 2.0334, lr_0 = 2.4861e-04
Loss = 3.6479e-03, PNorm = 57.3376, GNorm = 2.6768, lr_0 = 2.4827e-04
Loss = 3.3208e-03, PNorm = 57.3470, GNorm = 2.6179, lr_0 = 2.4794e-04
Loss = 3.9898e-03, PNorm = 57.3546, GNorm = 2.1510, lr_0 = 2.4761e-04
Loss = 5.2290e-03, PNorm = 57.3626, GNorm = 2.8407, lr_0 = 2.4727e-04
Loss = 3.0386e-03, PNorm = 57.3712, GNorm = 3.2968, lr_0 = 2.4694e-04
Loss = 3.3680e-03, PNorm = 57.3799, GNorm = 2.0948, lr_0 = 2.4661e-04
Loss = 5.1258e-03, PNorm = 57.3859, GNorm = 4.0580, lr_0 = 2.4628e-04
Loss = 4.0917e-03, PNorm = 57.3919, GNorm = 2.3479, lr_0 = 2.4595e-04
Loss = 3.9092e-03, PNorm = 57.3980, GNorm = 1.7771, lr_0 = 2.4562e-04
Validation rmse = 3.714385
Validation R2 = -2.939526
Epoch 46
Train function
Loss = 3.2125e-03, PNorm = 57.4079, GNorm = 2.8797, lr_0 = 2.4526e-04
Loss = 2.9783e-03, PNorm = 57.4179, GNorm = 2.2528, lr_0 = 2.4493e-04
Loss = 3.3164e-03, PNorm = 57.4271, GNorm = 1.5085, lr_0 = 2.4460e-04
Loss = 3.0924e-03, PNorm = 57.4333, GNorm = 1.7430, lr_0 = 2.4427e-04
Loss = 2.8940e-03, PNorm = 57.4406, GNorm = 1.9744, lr_0 = 2.4394e-04
Loss = 4.1812e-03, PNorm = 57.4486, GNorm = 3.1712, lr_0 = 2.4362e-04
Loss = 3.9725e-03, PNorm = 57.4536, GNorm = 1.8765, lr_0 = 2.4329e-04
Loss = 3.8622e-03, PNorm = 57.4602, GNorm = 1.9393, lr_0 = 2.4296e-04
Loss = 4.6562e-03, PNorm = 57.4695, GNorm = 2.5961, lr_0 = 2.4264e-04
Loss = 3.1685e-03, PNorm = 57.4771, GNorm = 2.9846, lr_0 = 2.4231e-04
Loss = 3.2965e-03, PNorm = 57.4828, GNorm = 3.5562, lr_0 = 2.4199e-04
Loss = 3.2916e-03, PNorm = 57.4895, GNorm = 3.7244, lr_0 = 2.4166e-04
Loss = 3.7610e-03, PNorm = 57.4960, GNorm = 2.6723, lr_0 = 2.4134e-04
Loss = 2.5622e-03, PNorm = 57.5032, GNorm = 1.8717, lr_0 = 2.4101e-04
Loss = 3.7183e-03, PNorm = 57.5096, GNorm = 1.9732, lr_0 = 2.4069e-04
Loss = 2.9150e-03, PNorm = 57.5166, GNorm = 2.6691, lr_0 = 2.4037e-04
Loss = 2.9294e-03, PNorm = 57.5216, GNorm = 1.8311, lr_0 = 2.4004e-04
Loss = 3.4003e-03, PNorm = 57.5290, GNorm = 3.0990, lr_0 = 2.3972e-04
Loss = 3.1019e-03, PNorm = 57.5379, GNorm = 3.4115, lr_0 = 2.3940e-04
Loss = 3.1429e-03, PNorm = 57.5449, GNorm = 2.9476, lr_0 = 2.3908e-04
Loss = 3.3663e-03, PNorm = 57.5541, GNorm = 2.7491, lr_0 = 2.3876e-04
Loss = 2.9104e-03, PNorm = 57.5595, GNorm = 3.7129, lr_0 = 2.3844e-04
Loss = 3.4809e-03, PNorm = 57.5659, GNorm = 2.6149, lr_0 = 2.3812e-04
Validation rmse = 3.677200
Validation R2 = -2.861042
Epoch 47
Train function
Loss = 1.9482e-03, PNorm = 57.5749, GNorm = 1.6324, lr_0 = 2.3777e-04
Loss = 2.9956e-03, PNorm = 57.5824, GNorm = 2.0045, lr_0 = 2.3745e-04
Loss = 2.4016e-03, PNorm = 57.5895, GNorm = 2.0426, lr_0 = 2.3713e-04
Loss = 3.0763e-03, PNorm = 57.5949, GNorm = 1.7425, lr_0 = 2.3681e-04
Loss = 2.8066e-03, PNorm = 57.5995, GNorm = 2.6923, lr_0 = 2.3649e-04
Loss = 4.2122e-03, PNorm = 57.6059, GNorm = 4.5251, lr_0 = 2.3618e-04
Loss = 2.8848e-03, PNorm = 57.6116, GNorm = 2.1224, lr_0 = 2.3586e-04
Loss = 3.1359e-03, PNorm = 57.6174, GNorm = 2.7090, lr_0 = 2.3554e-04
Loss = 2.4863e-03, PNorm = 57.6249, GNorm = 1.6596, lr_0 = 2.3523e-04
Loss = 3.9832e-03, PNorm = 57.6311, GNorm = 3.2537, lr_0 = 2.3491e-04
Loss = 3.0463e-03, PNorm = 57.6383, GNorm = 1.3261, lr_0 = 2.3460e-04
Loss = 3.3798e-03, PNorm = 57.6463, GNorm = 2.8671, lr_0 = 2.3428e-04
Loss = 3.2901e-03, PNorm = 57.6542, GNorm = 2.6979, lr_0 = 2.3397e-04
Loss = 3.2159e-03, PNorm = 57.6611, GNorm = 1.8300, lr_0 = 2.3365e-04
Loss = 2.6324e-03, PNorm = 57.6687, GNorm = 1.3705, lr_0 = 2.3334e-04
Loss = 2.7290e-03, PNorm = 57.6760, GNorm = 2.1333, lr_0 = 2.3303e-04
Loss = 2.8230e-03, PNorm = 57.6829, GNorm = 2.6617, lr_0 = 2.3271e-04
Loss = 3.2957e-03, PNorm = 57.6883, GNorm = 3.7910, lr_0 = 2.3240e-04
Loss = 2.6904e-03, PNorm = 57.6938, GNorm = 3.0782, lr_0 = 2.3209e-04
Loss = 3.0054e-03, PNorm = 57.6992, GNorm = 2.2079, lr_0 = 2.3178e-04
Loss = 4.0879e-03, PNorm = 57.7055, GNorm = 2.1077, lr_0 = 2.3147e-04
Loss = 3.1434e-03, PNorm = 57.7124, GNorm = 3.1092, lr_0 = 2.3116e-04
Loss = 3.6491e-03, PNorm = 57.7179, GNorm = 3.3220, lr_0 = 2.3085e-04
Loss = 4.0001e-03, PNorm = 57.7225, GNorm = 4.4159, lr_0 = 2.3054e-04
Validation rmse = 3.714854
Validation R2 = -2.940522
Epoch 48
Train function
Loss = 2.3814e-03, PNorm = 57.7289, GNorm = 2.2320, lr_0 = 2.3020e-04
Loss = 2.3828e-03, PNorm = 57.7344, GNorm = 1.7827, lr_0 = 2.2989e-04
Loss = 2.8946e-03, PNorm = 57.7404, GNorm = 2.2633, lr_0 = 2.2958e-04
Loss = 2.6153e-03, PNorm = 57.7468, GNorm = 2.1878, lr_0 = 2.2927e-04
Loss = 2.1219e-03, PNorm = 57.7517, GNorm = 1.5814, lr_0 = 2.2896e-04
Loss = 2.5825e-03, PNorm = 57.7581, GNorm = 3.1455, lr_0 = 2.2866e-04
Loss = 2.8089e-03, PNorm = 57.7652, GNorm = 2.4318, lr_0 = 2.2835e-04
Loss = 2.1781e-03, PNorm = 57.7714, GNorm = 2.7133, lr_0 = 2.2804e-04
Loss = 3.2125e-03, PNorm = 57.7769, GNorm = 3.7993, lr_0 = 2.2774e-04
Loss = 3.0849e-03, PNorm = 57.7818, GNorm = 3.5622, lr_0 = 2.2743e-04
Loss = 3.2538e-03, PNorm = 57.7895, GNorm = 3.8578, lr_0 = 2.2713e-04
Loss = 3.7370e-03, PNorm = 57.7984, GNorm = 4.1136, lr_0 = 2.2682e-04
Loss = 3.8832e-03, PNorm = 57.8074, GNorm = 2.5178, lr_0 = 2.2652e-04
Loss = 3.2719e-03, PNorm = 57.8155, GNorm = 2.6598, lr_0 = 2.2621e-04
Loss = 2.6854e-03, PNorm = 57.8213, GNorm = 2.4454, lr_0 = 2.2591e-04
Loss = 2.9028e-03, PNorm = 57.8279, GNorm = 2.5949, lr_0 = 2.2561e-04
Loss = 2.9412e-03, PNorm = 57.8341, GNorm = 2.1837, lr_0 = 2.2530e-04
Loss = 3.4744e-03, PNorm = 57.8406, GNorm = 2.1921, lr_0 = 2.2500e-04
Loss = 3.6939e-03, PNorm = 57.8469, GNorm = 2.8720, lr_0 = 2.2470e-04
Loss = 3.2629e-03, PNorm = 57.8517, GNorm = 4.4301, lr_0 = 2.2440e-04
Loss = 2.7598e-03, PNorm = 57.8590, GNorm = 2.6060, lr_0 = 2.2410e-04
Loss = 3.3707e-03, PNorm = 57.8653, GNorm = 3.3119, lr_0 = 2.2380e-04
Loss = 2.4581e-03, PNorm = 57.8687, GNorm = 3.2502, lr_0 = 2.2350e-04
Validation rmse = 3.890851
Validation R2 = -3.322742
Epoch 49
Train function
Loss = 2.2718e-03, PNorm = 57.8744, GNorm = 1.9032, lr_0 = 2.2317e-04
Loss = 3.4167e-03, PNorm = 57.8823, GNorm = 2.8100, lr_0 = 2.2287e-04
Loss = 2.4642e-03, PNorm = 57.8906, GNorm = 3.3764, lr_0 = 2.2257e-04
Loss = 3.2228e-03, PNorm = 57.8976, GNorm = 2.7930, lr_0 = 2.2227e-04
Loss = 2.3333e-03, PNorm = 57.9040, GNorm = 2.9045, lr_0 = 2.2197e-04
Loss = 2.7140e-03, PNorm = 57.9091, GNorm = 3.0643, lr_0 = 2.2167e-04
Loss = 3.0353e-03, PNorm = 57.9154, GNorm = 1.8430, lr_0 = 2.2138e-04
Loss = 2.9905e-03, PNorm = 57.9204, GNorm = 3.6577, lr_0 = 2.2108e-04
Loss = 2.4180e-03, PNorm = 57.9253, GNorm = 2.0075, lr_0 = 2.2078e-04
Loss = 2.6995e-03, PNorm = 57.9297, GNorm = 3.8184, lr_0 = 2.2049e-04
Loss = 2.7553e-03, PNorm = 57.9331, GNorm = 1.9973, lr_0 = 2.2019e-04
Loss = 2.5522e-03, PNorm = 57.9366, GNorm = 3.2099, lr_0 = 2.1990e-04
Loss = 2.7296e-03, PNorm = 57.9421, GNorm = 2.8252, lr_0 = 2.1960e-04
Loss = 2.3448e-03, PNorm = 57.9477, GNorm = 1.7964, lr_0 = 2.1931e-04
Loss = 2.3897e-03, PNorm = 57.9542, GNorm = 2.2272, lr_0 = 2.1901e-04
Loss = 3.2276e-03, PNorm = 57.9599, GNorm = 3.5484, lr_0 = 2.1872e-04
Loss = 4.2993e-03, PNorm = 57.9645, GNorm = 4.2507, lr_0 = 2.1842e-04
Loss = 2.7063e-03, PNorm = 57.9695, GNorm = 2.3678, lr_0 = 2.1813e-04
Loss = 3.2789e-03, PNorm = 57.9761, GNorm = 2.5078, lr_0 = 2.1784e-04
Loss = 3.0757e-03, PNorm = 57.9819, GNorm = 3.0362, lr_0 = 2.1755e-04
Loss = 2.9356e-03, PNorm = 57.9888, GNorm = 2.5675, lr_0 = 2.1725e-04
Loss = 2.5574e-03, PNorm = 57.9955, GNorm = 1.5727, lr_0 = 2.1696e-04
Loss = 2.7845e-03, PNorm = 58.0013, GNorm = 3.2189, lr_0 = 2.1667e-04
Loss = 2.6728e-03, PNorm = 58.0079, GNorm = 3.5146, lr_0 = 2.1638e-04
Validation rmse = 3.823167
Validation R2 = -3.173657
Epoch 50
Train function
Loss = 2.1642e-03, PNorm = 58.0130, GNorm = 1.9361, lr_0 = 2.1609e-04
Loss = 2.7406e-03, PNorm = 58.0161, GNorm = 2.8047, lr_0 = 2.1580e-04
Loss = 1.8495e-03, PNorm = 58.0207, GNorm = 1.8638, lr_0 = 2.1551e-04
Loss = 2.3245e-03, PNorm = 58.0275, GNorm = 1.4129, lr_0 = 2.1522e-04
Loss = 2.3998e-03, PNorm = 58.0326, GNorm = 2.2494, lr_0 = 2.1493e-04
Loss = 2.8732e-03, PNorm = 58.0403, GNorm = 2.4266, lr_0 = 2.1464e-04
Loss = 2.7929e-03, PNorm = 58.0467, GNorm = 3.2644, lr_0 = 2.1436e-04
Loss = 2.9087e-03, PNorm = 58.0506, GNorm = 1.6610, lr_0 = 2.1407e-04
Loss = 2.4621e-03, PNorm = 58.0550, GNorm = 2.5097, lr_0 = 2.1378e-04
Loss = 2.3069e-03, PNorm = 58.0608, GNorm = 1.7126, lr_0 = 2.1350e-04
Loss = 2.6925e-03, PNorm = 58.0660, GNorm = 3.7125, lr_0 = 2.1321e-04
Loss = 2.7828e-03, PNorm = 58.0704, GNorm = 2.3878, lr_0 = 2.1292e-04
Loss = 2.2494e-03, PNorm = 58.0758, GNorm = 2.2093, lr_0 = 2.1264e-04
Loss = 2.5486e-03, PNorm = 58.0827, GNorm = 2.6243, lr_0 = 2.1235e-04
Loss = 2.2195e-03, PNorm = 58.0893, GNorm = 2.0106, lr_0 = 2.1207e-04
Loss = 2.5294e-03, PNorm = 58.0958, GNorm = 2.5040, lr_0 = 2.1178e-04
Loss = 2.3189e-03, PNorm = 58.1013, GNorm = 2.6339, lr_0 = 2.1150e-04
Loss = 3.4458e-03, PNorm = 58.1088, GNorm = 3.7372, lr_0 = 2.1121e-04
Loss = 2.8317e-03, PNorm = 58.1158, GNorm = 2.1464, lr_0 = 2.1093e-04
Loss = 2.2570e-03, PNorm = 58.1224, GNorm = 1.8612, lr_0 = 2.1065e-04
Loss = 2.7681e-03, PNorm = 58.1280, GNorm = 2.4586, lr_0 = 2.1037e-04
Loss = 3.3745e-03, PNorm = 58.1347, GNorm = 3.3913, lr_0 = 2.1008e-04
Loss = 2.6995e-03, PNorm = 58.1420, GNorm = 2.0788, lr_0 = 2.0980e-04
Validation rmse = 4.016894
Validation R2 = -3.607346
Epoch 51
Train function
Loss = 2.5560e-03, PNorm = 58.1484, GNorm = 3.0171, lr_0 = 2.0949e-04
Loss = 2.7909e-03, PNorm = 58.1539, GNorm = 2.2792, lr_0 = 2.0921e-04
Loss = 2.7338e-03, PNorm = 58.1581, GNorm = 3.0231, lr_0 = 2.0893e-04
Loss = 2.4713e-03, PNorm = 58.1632, GNorm = 3.3167, lr_0 = 2.0865e-04
Loss = 2.8835e-03, PNorm = 58.1683, GNorm = 2.6938, lr_0 = 2.0837e-04
Loss = 2.6026e-03, PNorm = 58.1746, GNorm = 2.2104, lr_0 = 2.0809e-04
Loss = 3.1571e-03, PNorm = 58.1803, GNorm = 2.3525, lr_0 = 2.0781e-04
Loss = 3.0703e-03, PNorm = 58.1884, GNorm = 2.4445, lr_0 = 2.0753e-04
Loss = 1.8176e-03, PNorm = 58.1949, GNorm = 2.6190, lr_0 = 2.0725e-04
Loss = 1.9021e-03, PNorm = 58.1993, GNorm = 1.8497, lr_0 = 2.0698e-04
Loss = 3.1569e-03, PNorm = 58.2044, GNorm = 3.3935, lr_0 = 2.0670e-04
Loss = 2.5691e-03, PNorm = 58.2094, GNorm = 2.4892, lr_0 = 2.0642e-04
Loss = 2.7840e-03, PNorm = 58.2145, GNorm = 1.5266, lr_0 = 2.0614e-04
Loss = 1.8466e-03, PNorm = 58.2189, GNorm = 3.4759, lr_0 = 2.0587e-04
Loss = 2.0939e-03, PNorm = 58.2241, GNorm = 3.2331, lr_0 = 2.0559e-04
Loss = 2.1947e-03, PNorm = 58.2292, GNorm = 2.9482, lr_0 = 2.0531e-04
Loss = 2.3411e-03, PNorm = 58.2347, GNorm = 2.4782, lr_0 = 2.0504e-04
Loss = 2.3278e-03, PNorm = 58.2406, GNorm = 1.9997, lr_0 = 2.0476e-04
Loss = 2.9550e-03, PNorm = 58.2466, GNorm = 3.8172, lr_0 = 2.0449e-04
Loss = 2.3953e-03, PNorm = 58.2516, GNorm = 2.0974, lr_0 = 2.0421e-04
Loss = 2.2652e-03, PNorm = 58.2577, GNorm = 2.1537, lr_0 = 2.0394e-04
Loss = 2.5315e-03, PNorm = 58.2617, GNorm = 2.5311, lr_0 = 2.0367e-04
Loss = 2.2797e-03, PNorm = 58.2646, GNorm = 3.3032, lr_0 = 2.0339e-04
Validation rmse = 3.821916
Validation R2 = -3.170926
Epoch 52
Train function
Loss = 3.8686e-03, PNorm = 58.2688, GNorm = 1.6696, lr_0 = 2.0309e-04
Loss = 2.0753e-03, PNorm = 58.2723, GNorm = 2.5472, lr_0 = 2.0282e-04
Loss = 2.2962e-03, PNorm = 58.2770, GNorm = 2.8866, lr_0 = 2.0255e-04
Loss = 2.4871e-03, PNorm = 58.2821, GNorm = 2.0564, lr_0 = 2.0228e-04
Loss = 2.8584e-03, PNorm = 58.2864, GNorm = 2.0455, lr_0 = 2.0201e-04
Loss = 1.7844e-03, PNorm = 58.2912, GNorm = 1.9388, lr_0 = 2.0174e-04
Loss = 2.3999e-03, PNorm = 58.2970, GNorm = 1.8759, lr_0 = 2.0146e-04
Loss = 1.8316e-03, PNorm = 58.3033, GNorm = 1.9213, lr_0 = 2.0119e-04
Loss = 2.9641e-03, PNorm = 58.3092, GNorm = 3.9680, lr_0 = 2.0092e-04
Loss = 2.3103e-03, PNorm = 58.3137, GNorm = 3.0104, lr_0 = 2.0065e-04
Loss = 2.2093e-03, PNorm = 58.3185, GNorm = 2.3020, lr_0 = 2.0039e-04
Loss = 2.1510e-03, PNorm = 58.3223, GNorm = 1.9907, lr_0 = 2.0012e-04
Loss = 1.4961e-03, PNorm = 58.3252, GNorm = 2.0715, lr_0 = 1.9985e-04
Loss = 2.4576e-03, PNorm = 58.3302, GNorm = 2.9449, lr_0 = 1.9958e-04
Loss = 2.2825e-03, PNorm = 58.3345, GNorm = 1.9738, lr_0 = 1.9931e-04
Loss = 2.9303e-03, PNorm = 58.3399, GNorm = 2.8260, lr_0 = 1.9904e-04
Loss = 2.0903e-03, PNorm = 58.3449, GNorm = 2.0237, lr_0 = 1.9878e-04
Loss = 2.6914e-03, PNorm = 58.3511, GNorm = 3.5439, lr_0 = 1.9851e-04
Loss = 2.1104e-03, PNorm = 58.3569, GNorm = 1.5810, lr_0 = 1.9824e-04
Loss = 1.8798e-03, PNorm = 58.3622, GNorm = 1.7668, lr_0 = 1.9798e-04
Loss = 2.0014e-03, PNorm = 58.3662, GNorm = 2.2201, lr_0 = 1.9771e-04
Loss = 2.8957e-03, PNorm = 58.3703, GNorm = 3.8207, lr_0 = 1.9745e-04
Loss = 2.5485e-03, PNorm = 58.3738, GNorm = 2.6439, lr_0 = 1.9718e-04
Loss = 2.5936e-03, PNorm = 58.3775, GNorm = 4.9535, lr_0 = 1.9692e-04
Validation rmse = 3.994331
Validation R2 = -3.555733
Epoch 53
Train function
Loss = 1.6574e-03, PNorm = 58.3828, GNorm = 1.8457, lr_0 = 1.9663e-04
Loss = 2.1036e-03, PNorm = 58.3878, GNorm = 1.9160, lr_0 = 1.9636e-04
Loss = 2.6707e-03, PNorm = 58.3935, GNorm = 3.4524, lr_0 = 1.9610e-04
Loss = 2.6691e-03, PNorm = 58.3995, GNorm = 1.5067, lr_0 = 1.9584e-04
Loss = 1.9996e-03, PNorm = 58.4044, GNorm = 2.2607, lr_0 = 1.9557e-04
Loss = 2.4736e-03, PNorm = 58.4098, GNorm = 3.3336, lr_0 = 1.9531e-04
Loss = 1.8753e-03, PNorm = 58.4141, GNorm = 2.1111, lr_0 = 1.9505e-04
Loss = 2.1395e-03, PNorm = 58.4204, GNorm = 2.1350, lr_0 = 1.9479e-04
Loss = 1.6997e-03, PNorm = 58.4245, GNorm = 1.0678, lr_0 = 1.9453e-04
Loss = 2.3912e-03, PNorm = 58.4290, GNorm = 2.3684, lr_0 = 1.9427e-04
Loss = 2.4021e-03, PNorm = 58.4326, GNorm = 2.1445, lr_0 = 1.9401e-04
Loss = 1.6874e-03, PNorm = 58.4363, GNorm = 1.3483, lr_0 = 1.9374e-04
Loss = 2.3423e-03, PNorm = 58.4409, GNorm = 1.9777, lr_0 = 1.9348e-04
Loss = 1.9147e-03, PNorm = 58.4461, GNorm = 2.2673, lr_0 = 1.9323e-04
Loss = 2.4929e-03, PNorm = 58.4521, GNorm = 3.1754, lr_0 = 1.9297e-04
Loss = 2.1515e-03, PNorm = 58.4568, GNorm = 2.0265, lr_0 = 1.9271e-04
Loss = 1.7801e-03, PNorm = 58.4600, GNorm = 2.9638, lr_0 = 1.9245e-04
Loss = 2.0222e-03, PNorm = 58.4620, GNorm = 1.9105, lr_0 = 1.9219e-04
Loss = 1.8278e-03, PNorm = 58.4658, GNorm = 1.4128, lr_0 = 1.9193e-04
Loss = 1.9905e-03, PNorm = 58.4710, GNorm = 2.1808, lr_0 = 1.9168e-04
Loss = 2.9285e-03, PNorm = 58.4754, GNorm = 2.4798, lr_0 = 1.9142e-04
Loss = 2.0305e-03, PNorm = 58.4781, GNorm = 1.6108, lr_0 = 1.9116e-04
Loss = 2.8897e-03, PNorm = 58.4820, GNorm = 3.0186, lr_0 = 1.9090e-04
Validation rmse = 3.996396
Validation R2 = -3.560445
Epoch 54
Train function
Loss = 2.2146e-03, PNorm = 58.4872, GNorm = 2.1640, lr_0 = 1.9062e-04
Loss = 1.9035e-03, PNorm = 58.4934, GNorm = 1.9578, lr_0 = 1.9037e-04
Loss = 1.6616e-03, PNorm = 58.4985, GNorm = 2.4535, lr_0 = 1.9011e-04
Loss = 1.8596e-03, PNorm = 58.5038, GNorm = 1.5241, lr_0 = 1.8986e-04
Loss = 1.7851e-03, PNorm = 58.5085, GNorm = 1.8339, lr_0 = 1.8960e-04
Loss = 2.2868e-03, PNorm = 58.5120, GNorm = 3.6913, lr_0 = 1.8935e-04
Loss = 1.5346e-03, PNorm = 58.5150, GNorm = 1.3723, lr_0 = 1.8909e-04
Loss = 3.0652e-03, PNorm = 58.5175, GNorm = 2.9160, lr_0 = 1.8884e-04
Loss = 1.7803e-03, PNorm = 58.5228, GNorm = 2.3198, lr_0 = 1.8859e-04
Loss = 2.3110e-03, PNorm = 58.5276, GNorm = 2.1074, lr_0 = 1.8833e-04
Loss = 2.4220e-03, PNorm = 58.5325, GNorm = 2.6909, lr_0 = 1.8808e-04
Loss = 1.9070e-03, PNorm = 58.5371, GNorm = 2.2257, lr_0 = 1.8783e-04
Loss = 1.6362e-03, PNorm = 58.5411, GNorm = 1.5552, lr_0 = 1.8758e-04
Loss = 1.7854e-03, PNorm = 58.5453, GNorm = 1.8835, lr_0 = 1.8732e-04
Loss = 1.9415e-03, PNorm = 58.5490, GNorm = 2.1375, lr_0 = 1.8707e-04
Loss = 2.0201e-03, PNorm = 58.5525, GNorm = 1.6229, lr_0 = 1.8682e-04
Loss = 2.8485e-03, PNorm = 58.5564, GNorm = 2.0437, lr_0 = 1.8657e-04
Loss = 1.8478e-03, PNorm = 58.5602, GNorm = 2.0191, lr_0 = 1.8632e-04
Loss = 2.0939e-03, PNorm = 58.5640, GNorm = 1.4655, lr_0 = 1.8607e-04
Loss = 2.4537e-03, PNorm = 58.5698, GNorm = 2.4441, lr_0 = 1.8582e-04
Loss = 2.3375e-03, PNorm = 58.5739, GNorm = 2.4925, lr_0 = 1.8557e-04
Loss = 2.6692e-03, PNorm = 58.5786, GNorm = 2.5524, lr_0 = 1.8532e-04
Loss = 2.2242e-03, PNorm = 58.5836, GNorm = 5.5218, lr_0 = 1.8507e-04
Loss = 2.6173e-03, PNorm = 58.5884, GNorm = 3.0650, lr_0 = 1.8483e-04
Validation rmse = 3.929937
Validation R2 = -3.410028
Epoch 55
Train function
Loss = 2.2156e-03, PNorm = 58.5946, GNorm = 2.0243, lr_0 = 1.8458e-04
Loss = 1.6394e-03, PNorm = 58.6009, GNorm = 2.2977, lr_0 = 1.8433e-04
Loss = 2.3285e-03, PNorm = 58.6047, GNorm = 1.6476, lr_0 = 1.8408e-04
Loss = 1.6893e-03, PNorm = 58.6080, GNorm = 3.2852, lr_0 = 1.8384e-04
Loss = 2.4950e-03, PNorm = 58.6118, GNorm = 4.4988, lr_0 = 1.8359e-04
Loss = 2.4340e-03, PNorm = 58.6177, GNorm = 2.2997, lr_0 = 1.8334e-04
Loss = 1.8645e-03, PNorm = 58.6236, GNorm = 2.0475, lr_0 = 1.8310e-04
Loss = 1.8372e-03, PNorm = 58.6286, GNorm = 1.9981, lr_0 = 1.8285e-04
Loss = 2.0813e-03, PNorm = 58.6328, GNorm = 1.2542, lr_0 = 1.8261e-04
Loss = 2.0130e-03, PNorm = 58.6378, GNorm = 2.5677, lr_0 = 1.8236e-04
Loss = 1.8024e-03, PNorm = 58.6411, GNorm = 2.1646, lr_0 = 1.8212e-04
Loss = 1.9857e-03, PNorm = 58.6451, GNorm = 2.6716, lr_0 = 1.8187e-04
Loss = 2.3392e-03, PNorm = 58.6501, GNorm = 1.9125, lr_0 = 1.8163e-04
Loss = 2.2887e-03, PNorm = 58.6519, GNorm = 2.5363, lr_0 = 1.8138e-04
Loss = 1.8903e-03, PNorm = 58.6547, GNorm = 1.9345, lr_0 = 1.8114e-04
Loss = 1.8212e-03, PNorm = 58.6579, GNorm = 1.6644, lr_0 = 1.8090e-04
Loss = 2.5420e-03, PNorm = 58.6622, GNorm = 2.0622, lr_0 = 1.8066e-04
Loss = 2.5254e-03, PNorm = 58.6687, GNorm = 2.9715, lr_0 = 1.8041e-04
Loss = 1.9573e-03, PNorm = 58.6735, GNorm = 2.0694, lr_0 = 1.8017e-04
Loss = 1.6913e-03, PNorm = 58.6778, GNorm = 1.5434, lr_0 = 1.7993e-04
Loss = 2.1788e-03, PNorm = 58.6805, GNorm = 2.4700, lr_0 = 1.7969e-04
Loss = 1.9941e-03, PNorm = 58.6847, GNorm = 3.1387, lr_0 = 1.7945e-04
Loss = 1.8356e-03, PNorm = 58.6894, GNorm = 2.5001, lr_0 = 1.7921e-04
Validation rmse = 4.098139
Validation R2 = -3.795606
Epoch 56
Train function
Loss = 1.3796e-03, PNorm = 58.6920, GNorm = 3.5910, lr_0 = 1.7894e-04
Loss = 1.4983e-03, PNorm = 58.6960, GNorm = 2.4316, lr_0 = 1.7870e-04
Loss = 1.7145e-03, PNorm = 58.7001, GNorm = 1.9099, lr_0 = 1.7846e-04
Loss = 2.0924e-03, PNorm = 58.7026, GNorm = 1.6397, lr_0 = 1.7822e-04
Loss = 2.1870e-03, PNorm = 58.7067, GNorm = 1.7889, lr_0 = 1.7798e-04
Loss = 1.7245e-03, PNorm = 58.7103, GNorm = 2.8396, lr_0 = 1.7774e-04
Loss = 1.8268e-03, PNorm = 58.7137, GNorm = 2.5344, lr_0 = 1.7751e-04
Loss = 1.7872e-03, PNorm = 58.7180, GNorm = 2.0036, lr_0 = 1.7727e-04
Loss = 1.4633e-03, PNorm = 58.7223, GNorm = 1.6827, lr_0 = 1.7703e-04
Loss = 2.1902e-03, PNorm = 58.7263, GNorm = 2.0734, lr_0 = 1.7679e-04
Loss = 1.4907e-03, PNorm = 58.7309, GNorm = 2.0914, lr_0 = 1.7656e-04
Loss = 1.7362e-03, PNorm = 58.7351, GNorm = 1.6041, lr_0 = 1.7632e-04
Loss = 1.5664e-03, PNorm = 58.7397, GNorm = 1.7985, lr_0 = 1.7608e-04
Loss = 2.2050e-03, PNorm = 58.7438, GNorm = 1.3402, lr_0 = 1.7585e-04
Loss = 2.3865e-03, PNorm = 58.7473, GNorm = 1.7467, lr_0 = 1.7561e-04
Loss = 1.8575e-03, PNorm = 58.7513, GNorm = 1.4711, lr_0 = 1.7537e-04
Loss = 1.5923e-03, PNorm = 58.7548, GNorm = 2.6367, lr_0 = 1.7514e-04
Loss = 2.1255e-03, PNorm = 58.7594, GNorm = 1.7986, lr_0 = 1.7490e-04
Loss = 1.6879e-03, PNorm = 58.7638, GNorm = 2.2836, lr_0 = 1.7467e-04
Loss = 1.8773e-03, PNorm = 58.7679, GNorm = 2.3542, lr_0 = 1.7443e-04
Loss = 1.7995e-03, PNorm = 58.7730, GNorm = 3.3586, lr_0 = 1.7420e-04
Loss = 2.2497e-03, PNorm = 58.7767, GNorm = 2.2996, lr_0 = 1.7397e-04
Loss = 1.8419e-03, PNorm = 58.7805, GNorm = 1.4923, lr_0 = 1.7373e-04
Validation rmse = 4.205157
Validation R2 = -4.049340
Epoch 57
Train function
Loss = 8.2897e-04, PNorm = 58.7861, GNorm = 1.7337, lr_0 = 1.7348e-04
Loss = 2.4675e-03, PNorm = 58.7900, GNorm = 1.6153, lr_0 = 1.7324e-04
Loss = 1.8368e-03, PNorm = 58.7950, GNorm = 1.7716, lr_0 = 1.7301e-04
Loss = 1.6823e-03, PNorm = 58.7980, GNorm = 1.8467, lr_0 = 1.7278e-04
Loss = 2.0370e-03, PNorm = 58.8010, GNorm = 2.5355, lr_0 = 1.7255e-04
Loss = 1.2920e-03, PNorm = 58.8057, GNorm = 1.7223, lr_0 = 1.7232e-04
Loss = 1.3164e-03, PNorm = 58.8094, GNorm = 2.1197, lr_0 = 1.7209e-04
Loss = 1.1954e-03, PNorm = 58.8127, GNorm = 1.3389, lr_0 = 1.7185e-04
Loss = 1.5126e-03, PNorm = 58.8162, GNorm = 1.9062, lr_0 = 1.7162e-04
Loss = 1.4896e-03, PNorm = 58.8198, GNorm = 1.2249, lr_0 = 1.7139e-04
Loss = 1.5144e-03, PNorm = 58.8223, GNorm = 2.4080, lr_0 = 1.7116e-04
Loss = 2.0191e-03, PNorm = 58.8250, GNorm = 1.9493, lr_0 = 1.7093e-04
Loss = 1.5679e-03, PNorm = 58.8288, GNorm = 2.2455, lr_0 = 1.7070e-04
Loss = 2.0287e-03, PNorm = 58.8315, GNorm = 2.8684, lr_0 = 1.7048e-04
Loss = 2.1051e-03, PNorm = 58.8361, GNorm = 1.8747, lr_0 = 1.7025e-04
Loss = 1.5876e-03, PNorm = 58.8399, GNorm = 1.7414, lr_0 = 1.7002e-04
Loss = 1.6025e-03, PNorm = 58.8435, GNorm = 1.5983, lr_0 = 1.6979e-04
Loss = 1.3376e-03, PNorm = 58.8458, GNorm = 1.5896, lr_0 = 1.6956e-04
Loss = 1.7024e-03, PNorm = 58.8503, GNorm = 2.0674, lr_0 = 1.6933e-04
Loss = 2.6704e-03, PNorm = 58.8556, GNorm = 2.1543, lr_0 = 1.6911e-04
Loss = 1.5113e-03, PNorm = 58.8601, GNorm = 2.4630, lr_0 = 1.6888e-04
Loss = 2.0805e-03, PNorm = 58.8637, GNorm = 2.7890, lr_0 = 1.6865e-04
Loss = 2.0254e-03, PNorm = 58.8666, GNorm = 1.8695, lr_0 = 1.6843e-04
Loss = 2.6931e-03, PNorm = 58.8695, GNorm = 3.1113, lr_0 = 1.6820e-04
Validation rmse = 4.038804
Validation R2 = -3.657745
Epoch 58
Train function
Loss = 1.2361e-03, PNorm = 58.8748, GNorm = 1.3874, lr_0 = 1.6795e-04
Loss = 1.4245e-03, PNorm = 58.8790, GNorm = 1.5787, lr_0 = 1.6773e-04
Loss = 1.9918e-03, PNorm = 58.8828, GNorm = 1.1671, lr_0 = 1.6750e-04
Loss = 1.4511e-03, PNorm = 58.8860, GNorm = 1.4383, lr_0 = 1.6728e-04
Loss = 1.4698e-03, PNorm = 58.8900, GNorm = 1.9344, lr_0 = 1.6705e-04
Loss = 1.5404e-03, PNorm = 58.8943, GNorm = 1.7727, lr_0 = 1.6683e-04
Loss = 1.7244e-03, PNorm = 58.8980, GNorm = 2.2033, lr_0 = 1.6661e-04
Loss = 1.2607e-03, PNorm = 58.9020, GNorm = 1.4293, lr_0 = 1.6638e-04
Loss = 1.4442e-03, PNorm = 58.9053, GNorm = 1.5351, lr_0 = 1.6616e-04
Loss = 1.4029e-03, PNorm = 58.9088, GNorm = 1.7644, lr_0 = 1.6594e-04
Loss = 1.7380e-03, PNorm = 58.9123, GNorm = 1.9607, lr_0 = 1.6571e-04
Loss = 1.7030e-03, PNorm = 58.9166, GNorm = 1.6717, lr_0 = 1.6549e-04
Loss = 1.9068e-03, PNorm = 58.9209, GNorm = 1.2440, lr_0 = 1.6527e-04
Loss = 2.1191e-03, PNorm = 58.9242, GNorm = 2.4077, lr_0 = 1.6505e-04
Loss = 2.3888e-03, PNorm = 58.9267, GNorm = 2.4403, lr_0 = 1.6483e-04
Loss = 1.8274e-03, PNorm = 58.9295, GNorm = 2.2422, lr_0 = 1.6461e-04
Loss = 2.1551e-03, PNorm = 58.9334, GNorm = 3.2327, lr_0 = 1.6438e-04
Loss = 1.9248e-03, PNorm = 58.9374, GNorm = 3.2455, lr_0 = 1.6416e-04
Loss = 1.5733e-03, PNorm = 58.9417, GNorm = 1.3686, lr_0 = 1.6394e-04
Loss = 1.5176e-03, PNorm = 58.9466, GNorm = 2.7949, lr_0 = 1.6372e-04
Loss = 1.7400e-03, PNorm = 58.9513, GNorm = 1.3563, lr_0 = 1.6350e-04
Loss = 1.6592e-03, PNorm = 58.9545, GNorm = 1.1590, lr_0 = 1.6328e-04
Loss = 2.1089e-03, PNorm = 58.9581, GNorm = 2.9069, lr_0 = 1.6307e-04
Validation rmse = 3.949485
Validation R2 = -3.454010
Epoch 59
Train function
Loss = 1.6981e-03, PNorm = 58.9613, GNorm = 2.9609, lr_0 = 1.6282e-04
Loss = 1.3811e-03, PNorm = 58.9634, GNorm = 1.8679, lr_0 = 1.6261e-04
Loss = 1.5465e-03, PNorm = 58.9663, GNorm = 1.3258, lr_0 = 1.6239e-04
Loss = 1.3393e-03, PNorm = 58.9685, GNorm = 3.2102, lr_0 = 1.6217e-04
Loss = 1.4841e-03, PNorm = 58.9710, GNorm = 1.3536, lr_0 = 1.6195e-04
Loss = 1.3008e-03, PNorm = 58.9751, GNorm = 1.7079, lr_0 = 1.6174e-04
Loss = 1.5753e-03, PNorm = 58.9788, GNorm = 1.8711, lr_0 = 1.6152e-04
Loss = 1.3370e-03, PNorm = 58.9830, GNorm = 1.4982, lr_0 = 1.6130e-04
Loss = 1.4887e-03, PNorm = 58.9855, GNorm = 1.1711, lr_0 = 1.6109e-04
Loss = 1.9230e-03, PNorm = 58.9892, GNorm = 1.6621, lr_0 = 1.6087e-04
Loss = 1.6394e-03, PNorm = 58.9939, GNorm = 3.0157, lr_0 = 1.6065e-04
Loss = 2.1605e-03, PNorm = 58.9991, GNorm = 1.7993, lr_0 = 1.6044e-04
Loss = 2.7333e-03, PNorm = 59.0022, GNorm = 3.8931, lr_0 = 1.6022e-04
Loss = 1.4894e-03, PNorm = 59.0066, GNorm = 1.6086, lr_0 = 1.6001e-04
Loss = 1.6409e-03, PNorm = 59.0125, GNorm = 2.0308, lr_0 = 1.5979e-04
Loss = 1.5425e-03, PNorm = 59.0176, GNorm = 1.5828, lr_0 = 1.5958e-04
Loss = 1.6457e-03, PNorm = 59.0210, GNorm = 1.2015, lr_0 = 1.5936e-04
Loss = 1.6194e-03, PNorm = 59.0245, GNorm = 2.3054, lr_0 = 1.5915e-04
Loss = 1.2075e-03, PNorm = 59.0289, GNorm = 1.1708, lr_0 = 1.5894e-04
Loss = 1.5377e-03, PNorm = 59.0328, GNorm = 1.0820, lr_0 = 1.5872e-04
Loss = 1.6772e-03, PNorm = 59.0363, GNorm = 3.0474, lr_0 = 1.5851e-04
Loss = 1.4480e-03, PNorm = 59.0386, GNorm = 1.6145, lr_0 = 1.5830e-04
Loss = 1.7872e-03, PNorm = 59.0425, GNorm = 4.8206, lr_0 = 1.5809e-04
Loss = 1.8318e-03, PNorm = 59.0457, GNorm = 1.3189, lr_0 = 1.5787e-04
Validation rmse = 4.325532
Validation R2 = -4.342557
Epoch 60
Train function
Loss = 1.0900e-03, PNorm = 59.0497, GNorm = 1.7150, lr_0 = 1.5766e-04
Loss = 1.4557e-03, PNorm = 59.0534, GNorm = 3.0215, lr_0 = 1.5745e-04
Loss = 1.1266e-03, PNorm = 59.0560, GNorm = 2.0397, lr_0 = 1.5724e-04
Loss = 1.3187e-03, PNorm = 59.0586, GNorm = 1.7129, lr_0 = 1.5703e-04
Loss = 1.4180e-03, PNorm = 59.0619, GNorm = 1.9278, lr_0 = 1.5682e-04
Loss = 1.4526e-03, PNorm = 59.0634, GNorm = 1.8322, lr_0 = 1.5661e-04
Loss = 1.5708e-03, PNorm = 59.0651, GNorm = 1.6183, lr_0 = 1.5640e-04
Loss = 1.2498e-03, PNorm = 59.0683, GNorm = 2.7985, lr_0 = 1.5619e-04
Loss = 1.4778e-03, PNorm = 59.0720, GNorm = 2.4313, lr_0 = 1.5598e-04
Loss = 1.1645e-03, PNorm = 59.0747, GNorm = 1.3595, lr_0 = 1.5577e-04
Loss = 1.2713e-03, PNorm = 59.0769, GNorm = 1.6307, lr_0 = 1.5556e-04
Loss = 1.7560e-03, PNorm = 59.0791, GNorm = 1.5351, lr_0 = 1.5535e-04
Loss = 1.3384e-03, PNorm = 59.0812, GNorm = 1.6110, lr_0 = 1.5514e-04
Loss = 1.9130e-03, PNorm = 59.0846, GNorm = 1.7996, lr_0 = 1.5493e-04
Loss = 1.5539e-03, PNorm = 59.0888, GNorm = 1.8599, lr_0 = 1.5473e-04
Loss = 1.6254e-03, PNorm = 59.0925, GNorm = 2.2733, lr_0 = 1.5452e-04
Loss = 1.6301e-03, PNorm = 59.0968, GNorm = 2.0684, lr_0 = 1.5431e-04
Loss = 1.5764e-03, PNorm = 59.1019, GNorm = 1.4795, lr_0 = 1.5410e-04
Loss = 1.3572e-03, PNorm = 59.1066, GNorm = 2.4463, lr_0 = 1.5390e-04
Loss = 1.7828e-03, PNorm = 59.1110, GNorm = 3.4283, lr_0 = 1.5369e-04
Loss = 1.7716e-03, PNorm = 59.1139, GNorm = 1.7470, lr_0 = 1.5348e-04
Loss = 1.8232e-03, PNorm = 59.1179, GNorm = 1.7107, lr_0 = 1.5328e-04
Loss = 1.7999e-03, PNorm = 59.1228, GNorm = 3.8929, lr_0 = 1.5307e-04
Validation rmse = 3.996128
Validation R2 = -3.559832
Epoch 61
Train function
Loss = 2.1815e-03, PNorm = 59.1262, GNorm = 1.8610, lr_0 = 1.5285e-04
Loss = 1.5168e-03, PNorm = 59.1281, GNorm = 1.9922, lr_0 = 1.5264e-04
Loss = 1.7331e-03, PNorm = 59.1315, GNorm = 4.0925, lr_0 = 1.5244e-04
Loss = 1.4602e-03, PNorm = 59.1355, GNorm = 1.6757, lr_0 = 1.5223e-04
Loss = 1.2338e-03, PNorm = 59.1397, GNorm = 1.1355, lr_0 = 1.5203e-04
Loss = 1.1683e-03, PNorm = 59.1431, GNorm = 1.5707, lr_0 = 1.5182e-04
Loss = 1.9087e-03, PNorm = 59.1451, GNorm = 1.5454, lr_0 = 1.5162e-04
Loss = 1.1574e-03, PNorm = 59.1472, GNorm = 1.2993, lr_0 = 1.5142e-04
Loss = 1.9906e-03, PNorm = 59.1497, GNorm = 1.7963, lr_0 = 1.5121e-04
Loss = 1.5502e-03, PNorm = 59.1532, GNorm = 2.2769, lr_0 = 1.5101e-04
Loss = 1.5154e-03, PNorm = 59.1560, GNorm = 2.8361, lr_0 = 1.5081e-04
Loss = 1.3531e-03, PNorm = 59.1585, GNorm = 2.0358, lr_0 = 1.5061e-04
Loss = 1.4272e-03, PNorm = 59.1614, GNorm = 2.0939, lr_0 = 1.5040e-04
Loss = 1.3666e-03, PNorm = 59.1633, GNorm = 1.5475, lr_0 = 1.5020e-04
Loss = 1.7023e-03, PNorm = 59.1651, GNorm = 1.9152, lr_0 = 1.5000e-04
Loss = 1.8618e-03, PNorm = 59.1691, GNorm = 1.4373, lr_0 = 1.4980e-04
Loss = 1.0987e-03, PNorm = 59.1722, GNorm = 1.7500, lr_0 = 1.4960e-04
Loss = 9.4432e-04, PNorm = 59.1741, GNorm = 0.8993, lr_0 = 1.4940e-04
Loss = 1.3156e-03, PNorm = 59.1773, GNorm = 1.8330, lr_0 = 1.4920e-04
Loss = 1.7266e-03, PNorm = 59.1802, GNorm = 1.1488, lr_0 = 1.4900e-04
Loss = 1.4377e-03, PNorm = 59.1831, GNorm = 2.0138, lr_0 = 1.4880e-04
Loss = 1.3103e-03, PNorm = 59.1870, GNorm = 1.7105, lr_0 = 1.4860e-04
Loss = 1.3861e-03, PNorm = 59.1903, GNorm = 2.7328, lr_0 = 1.4840e-04
Loss = 1.7712e-03, PNorm = 59.1931, GNorm = 2.4286, lr_0 = 1.4820e-04
Loss = 4.3243e-03, PNorm = 59.1935, GNorm = 2.6475, lr_0 = 1.4818e-04
Validation rmse = 3.958697
Validation R2 = -3.474811
Epoch 62
Train function
Loss = 8.9048e-04, PNorm = 59.1967, GNorm = 1.7894, lr_0 = 1.4798e-04
Loss = 1.0503e-03, PNorm = 59.1988, GNorm = 1.1121, lr_0 = 1.4778e-04
Loss = 1.0173e-03, PNorm = 59.2010, GNorm = 2.6224, lr_0 = 1.4758e-04
Loss = 1.3778e-03, PNorm = 59.2055, GNorm = 2.0174, lr_0 = 1.4739e-04
Loss = 1.0079e-03, PNorm = 59.2091, GNorm = 0.8167, lr_0 = 1.4719e-04
Loss = 1.5505e-03, PNorm = 59.2110, GNorm = 2.2940, lr_0 = 1.4699e-04
Loss = 1.1780e-03, PNorm = 59.2133, GNorm = 1.4855, lr_0 = 1.4679e-04
Loss = 1.1556e-03, PNorm = 59.2161, GNorm = 1.6549, lr_0 = 1.4660e-04
Loss = 1.2987e-03, PNorm = 59.2199, GNorm = 1.5031, lr_0 = 1.4640e-04
Loss = 1.7447e-03, PNorm = 59.2240, GNorm = 1.3940, lr_0 = 1.4620e-04
Loss = 1.2936e-03, PNorm = 59.2270, GNorm = 2.3954, lr_0 = 1.4601e-04
Loss = 1.2816e-03, PNorm = 59.2304, GNorm = 1.3063, lr_0 = 1.4581e-04
Loss = 1.9753e-03, PNorm = 59.2334, GNorm = 2.8639, lr_0 = 1.4562e-04
Loss = 1.5100e-03, PNorm = 59.2363, GNorm = 2.0056, lr_0 = 1.4542e-04
Loss = 1.3775e-03, PNorm = 59.2390, GNorm = 2.6227, lr_0 = 1.4522e-04
Loss = 1.8858e-03, PNorm = 59.2415, GNorm = 2.2259, lr_0 = 1.4503e-04
Loss = 1.7890e-03, PNorm = 59.2445, GNorm = 2.3601, lr_0 = 1.4484e-04
Loss = 1.8318e-03, PNorm = 59.2471, GNorm = 2.5403, lr_0 = 1.4464e-04
Loss = 1.3227e-03, PNorm = 59.2505, GNorm = 2.9519, lr_0 = 1.4445e-04
Loss = 1.2304e-03, PNorm = 59.2537, GNorm = 1.7531, lr_0 = 1.4425e-04
Loss = 1.2555e-03, PNorm = 59.2567, GNorm = 1.5849, lr_0 = 1.4406e-04
Loss = 1.2788e-03, PNorm = 59.2594, GNorm = 1.8917, lr_0 = 1.4387e-04
Loss = 1.5640e-03, PNorm = 59.2619, GNorm = 1.4177, lr_0 = 1.4367e-04
Validation rmse = 4.110850
Validation R2 = -3.825402
Epoch 63
Train function
Loss = 8.2759e-04, PNorm = 59.2652, GNorm = 1.7691, lr_0 = 1.4346e-04
Loss = 1.2830e-03, PNorm = 59.2676, GNorm = 1.9228, lr_0 = 1.4327e-04
Loss = 1.1422e-03, PNorm = 59.2702, GNorm = 1.7494, lr_0 = 1.4308e-04
Loss = 9.7957e-04, PNorm = 59.2740, GNorm = 1.9744, lr_0 = 1.4288e-04
Loss = 1.3741e-03, PNorm = 59.2765, GNorm = 2.2439, lr_0 = 1.4269e-04
Loss = 1.2926e-03, PNorm = 59.2793, GNorm = 2.9619, lr_0 = 1.4250e-04
Loss = 1.7648e-03, PNorm = 59.2823, GNorm = 1.9403, lr_0 = 1.4231e-04
Loss = 1.0790e-03, PNorm = 59.2861, GNorm = 1.5030, lr_0 = 1.4212e-04
Loss = 1.0132e-03, PNorm = 59.2888, GNorm = 1.0158, lr_0 = 1.4193e-04
Loss = 1.5015e-03, PNorm = 59.2917, GNorm = 2.0254, lr_0 = 1.4174e-04
Loss = 1.3508e-03, PNorm = 59.2944, GNorm = 1.7370, lr_0 = 1.4155e-04
Loss = 1.7130e-03, PNorm = 59.2968, GNorm = 4.1888, lr_0 = 1.4136e-04
Loss = 1.3711e-03, PNorm = 59.2992, GNorm = 1.4830, lr_0 = 1.4117e-04
Loss = 2.1247e-03, PNorm = 59.3023, GNorm = 3.4037, lr_0 = 1.4098e-04
Loss = 1.3058e-03, PNorm = 59.3056, GNorm = 1.8281, lr_0 = 1.4079e-04
Loss = 1.2336e-03, PNorm = 59.3090, GNorm = 1.6412, lr_0 = 1.4060e-04
Loss = 1.2665e-03, PNorm = 59.3121, GNorm = 1.5447, lr_0 = 1.4041e-04
Loss = 1.3153e-03, PNorm = 59.3150, GNorm = 1.5842, lr_0 = 1.4022e-04
Loss = 8.4325e-04, PNorm = 59.3172, GNorm = 1.8552, lr_0 = 1.4004e-04
Loss = 1.2374e-03, PNorm = 59.3197, GNorm = 1.7263, lr_0 = 1.3985e-04
Loss = 1.0759e-03, PNorm = 59.3221, GNorm = 1.1983, lr_0 = 1.3966e-04
Loss = 1.2045e-03, PNorm = 59.3247, GNorm = 1.8655, lr_0 = 1.3947e-04
Loss = 1.2130e-03, PNorm = 59.3275, GNorm = 1.3344, lr_0 = 1.3929e-04
Validation rmse = 4.098532
Validation R2 = -3.796526
Epoch 64
Train function
Loss = 8.6866e-04, PNorm = 59.3311, GNorm = 2.1141, lr_0 = 1.3908e-04
Loss = 1.2605e-03, PNorm = 59.3344, GNorm = 2.3282, lr_0 = 1.3889e-04
Loss = 1.4957e-03, PNorm = 59.3370, GNorm = 2.5562, lr_0 = 1.3871e-04
Loss = 1.3762e-03, PNorm = 59.3404, GNorm = 1.5942, lr_0 = 1.3852e-04
Loss = 1.4785e-03, PNorm = 59.3434, GNorm = 1.9514, lr_0 = 1.3834e-04
Loss = 1.7864e-03, PNorm = 59.3461, GNorm = 1.1158, lr_0 = 1.3815e-04
Loss = 1.4046e-03, PNorm = 59.3492, GNorm = 3.6222, lr_0 = 1.3796e-04
Loss = 1.2008e-03, PNorm = 59.3524, GNorm = 2.0877, lr_0 = 1.3778e-04
Loss = 1.1881e-03, PNorm = 59.3566, GNorm = 1.6483, lr_0 = 1.3759e-04
Loss = 1.4376e-03, PNorm = 59.3595, GNorm = 1.1745, lr_0 = 1.3741e-04
Loss = 1.3993e-03, PNorm = 59.3628, GNorm = 1.9309, lr_0 = 1.3723e-04
Loss = 8.6335e-04, PNorm = 59.3661, GNorm = 0.9158, lr_0 = 1.3704e-04
Loss = 1.0716e-03, PNorm = 59.3696, GNorm = 1.3465, lr_0 = 1.3686e-04
Loss = 1.0051e-03, PNorm = 59.3726, GNorm = 1.6152, lr_0 = 1.3667e-04
Loss = 1.0565e-03, PNorm = 59.3750, GNorm = 1.6643, lr_0 = 1.3649e-04
Loss = 1.1708e-03, PNorm = 59.3766, GNorm = 1.6336, lr_0 = 1.3631e-04
Loss = 1.1893e-03, PNorm = 59.3790, GNorm = 1.3446, lr_0 = 1.3612e-04
Loss = 1.1422e-03, PNorm = 59.3824, GNorm = 1.2322, lr_0 = 1.3594e-04
Loss = 1.1278e-03, PNorm = 59.3853, GNorm = 2.9287, lr_0 = 1.3576e-04
Loss = 1.0458e-03, PNorm = 59.3874, GNorm = 2.4414, lr_0 = 1.3558e-04
Loss = 1.3845e-03, PNorm = 59.3893, GNorm = 2.8178, lr_0 = 1.3540e-04
Loss = 1.7486e-03, PNorm = 59.3917, GNorm = 1.0140, lr_0 = 1.3521e-04
Loss = 1.2351e-03, PNorm = 59.3932, GNorm = 1.3596, lr_0 = 1.3503e-04
Loss = 1.6730e-03, PNorm = 59.3959, GNorm = 3.6828, lr_0 = 1.3485e-04
Validation rmse = 4.020059
Validation R2 = -3.614609
Epoch 65
Train function
Loss = 1.6721e-03, PNorm = 59.3984, GNorm = 3.7598, lr_0 = 1.3467e-04
Loss = 1.0380e-03, PNorm = 59.3998, GNorm = 3.6162, lr_0 = 1.3449e-04
Loss = 9.8701e-04, PNorm = 59.4023, GNorm = 0.9502, lr_0 = 1.3431e-04
Loss = 1.2082e-03, PNorm = 59.4041, GNorm = 1.1713, lr_0 = 1.3413e-04
Loss = 9.4350e-04, PNorm = 59.4066, GNorm = 1.3265, lr_0 = 1.3395e-04
Loss = 1.0784e-03, PNorm = 59.4096, GNorm = 1.6041, lr_0 = 1.3377e-04
Loss = 1.2149e-03, PNorm = 59.4120, GNorm = 1.9084, lr_0 = 1.3359e-04
Loss = 1.4652e-03, PNorm = 59.4145, GNorm = 1.8079, lr_0 = 1.3341e-04
Loss = 1.8677e-03, PNorm = 59.4174, GNorm = 1.2765, lr_0 = 1.3323e-04
Loss = 1.1946e-03, PNorm = 59.4201, GNorm = 1.3424, lr_0 = 1.3305e-04
Loss = 1.1595e-03, PNorm = 59.4234, GNorm = 1.2095, lr_0 = 1.3287e-04
Loss = 8.9543e-04, PNorm = 59.4270, GNorm = 1.7810, lr_0 = 1.3270e-04
Loss = 8.7749e-04, PNorm = 59.4304, GNorm = 1.0585, lr_0 = 1.3252e-04
Loss = 8.9265e-04, PNorm = 59.4342, GNorm = 0.8608, lr_0 = 1.3234e-04
Loss = 8.9860e-04, PNorm = 59.4373, GNorm = 1.1357, lr_0 = 1.3216e-04
Loss = 1.0502e-03, PNorm = 59.4392, GNorm = 2.1817, lr_0 = 1.3199e-04
Loss = 9.9101e-04, PNorm = 59.4426, GNorm = 1.1968, lr_0 = 1.3181e-04
Loss = 1.3456e-03, PNorm = 59.4452, GNorm = 1.3663, lr_0 = 1.3163e-04
Loss = 9.2568e-04, PNorm = 59.4465, GNorm = 1.2367, lr_0 = 1.3145e-04
Loss = 9.7372e-04, PNorm = 59.4480, GNorm = 1.4734, lr_0 = 1.3128e-04
Loss = 2.1653e-03, PNorm = 59.4500, GNorm = 2.3729, lr_0 = 1.3110e-04
Loss = 1.1875e-03, PNorm = 59.4519, GNorm = 1.5898, lr_0 = 1.3093e-04
Loss = 1.3920e-03, PNorm = 59.4530, GNorm = 1.7764, lr_0 = 1.3075e-04
Validation rmse = 4.170676
Validation R2 = -3.966874
Epoch 66
Train function
Loss = 8.3173e-04, PNorm = 59.4555, GNorm = 2.9137, lr_0 = 1.3056e-04
Loss = 7.3967e-04, PNorm = 59.4576, GNorm = 1.1170, lr_0 = 1.3038e-04
Loss = 9.8551e-04, PNorm = 59.4605, GNorm = 1.5521, lr_0 = 1.3021e-04
Loss = 1.1028e-03, PNorm = 59.4639, GNorm = 1.7535, lr_0 = 1.3003e-04
Loss = 1.0004e-03, PNorm = 59.4663, GNorm = 1.6879, lr_0 = 1.2986e-04
Loss = 1.6796e-03, PNorm = 59.4687, GNorm = 1.9915, lr_0 = 1.2968e-04
Loss = 1.6426e-03, PNorm = 59.4716, GNorm = 1.9539, lr_0 = 1.2951e-04
Loss = 1.0805e-03, PNorm = 59.4746, GNorm = 1.3517, lr_0 = 1.2934e-04
Loss = 9.6636e-04, PNorm = 59.4774, GNorm = 1.0735, lr_0 = 1.2916e-04
Loss = 1.1628e-03, PNorm = 59.4808, GNorm = 1.0447, lr_0 = 1.2899e-04
Loss = 9.1155e-04, PNorm = 59.4831, GNorm = 1.2182, lr_0 = 1.2882e-04
Loss = 1.0915e-03, PNorm = 59.4860, GNorm = 1.5082, lr_0 = 1.2864e-04
Loss = 1.0470e-03, PNorm = 59.4887, GNorm = 1.6275, lr_0 = 1.2847e-04
Loss = 7.5231e-04, PNorm = 59.4905, GNorm = 1.6172, lr_0 = 1.2830e-04
Loss = 1.1440e-03, PNorm = 59.4924, GNorm = 1.9360, lr_0 = 1.2813e-04
Loss = 1.5382e-03, PNorm = 59.4934, GNorm = 2.5282, lr_0 = 1.2795e-04
Loss = 1.1018e-03, PNorm = 59.4952, GNorm = 1.6626, lr_0 = 1.2778e-04
Loss = 1.4478e-03, PNorm = 59.4979, GNorm = 2.0381, lr_0 = 1.2761e-04
Loss = 1.2396e-03, PNorm = 59.5009, GNorm = 1.0065, lr_0 = 1.2744e-04
Loss = 1.2737e-03, PNorm = 59.5043, GNorm = 1.5787, lr_0 = 1.2727e-04
Loss = 8.6879e-04, PNorm = 59.5070, GNorm = 2.0163, lr_0 = 1.2710e-04
Loss = 1.1983e-03, PNorm = 59.5087, GNorm = 2.8260, lr_0 = 1.2693e-04
Loss = 1.7629e-03, PNorm = 59.5110, GNorm = 2.0475, lr_0 = 1.2676e-04
Loss = 1.3224e-03, PNorm = 59.5137, GNorm = 1.6003, lr_0 = 1.2659e-04
Validation rmse = 3.952774
Validation R2 = -3.461429
Epoch 67
Train function
Loss = 9.6130e-04, PNorm = 59.5161, GNorm = 1.7561, lr_0 = 1.2640e-04
Loss = 7.9931e-04, PNorm = 59.5185, GNorm = 0.9464, lr_0 = 1.2623e-04
Loss = 1.0031e-03, PNorm = 59.5199, GNorm = 1.8791, lr_0 = 1.2606e-04
Loss = 1.3748e-03, PNorm = 59.5218, GNorm = 2.3753, lr_0 = 1.2589e-04
Loss = 1.0215e-03, PNorm = 59.5240, GNorm = 1.4155, lr_0 = 1.2572e-04
Loss = 8.7948e-04, PNorm = 59.5264, GNorm = 1.2303, lr_0 = 1.2555e-04
Loss = 1.7178e-03, PNorm = 59.5290, GNorm = 1.4064, lr_0 = 1.2539e-04
Loss = 1.2534e-03, PNorm = 59.5321, GNorm = 2.9318, lr_0 = 1.2522e-04
Loss = 6.0400e-04, PNorm = 59.5343, GNorm = 1.3989, lr_0 = 1.2505e-04
Loss = 1.4576e-03, PNorm = 59.5365, GNorm = 1.1618, lr_0 = 1.2488e-04
Loss = 1.1654e-03, PNorm = 59.5385, GNorm = 1.0576, lr_0 = 1.2471e-04
Loss = 7.4178e-04, PNorm = 59.5405, GNorm = 1.2479, lr_0 = 1.2455e-04
Loss = 1.3323e-03, PNorm = 59.5425, GNorm = 1.7780, lr_0 = 1.2438e-04
Loss = 7.7193e-04, PNorm = 59.5445, GNorm = 1.6475, lr_0 = 1.2421e-04
Loss = 9.3512e-04, PNorm = 59.5465, GNorm = 1.2825, lr_0 = 1.2405e-04
Loss = 1.0007e-03, PNorm = 59.5492, GNorm = 1.8006, lr_0 = 1.2388e-04
Loss = 9.7775e-04, PNorm = 59.5520, GNorm = 1.3994, lr_0 = 1.2371e-04
Loss = 1.8635e-03, PNorm = 59.5542, GNorm = 1.8468, lr_0 = 1.2355e-04
Loss = 1.2624e-03, PNorm = 59.5572, GNorm = 1.8934, lr_0 = 1.2338e-04
Loss = 1.1383e-03, PNorm = 59.5600, GNorm = 1.2282, lr_0 = 1.2322e-04
Loss = 1.0637e-03, PNorm = 59.5616, GNorm = 1.3379, lr_0 = 1.2305e-04
Loss = 9.0590e-04, PNorm = 59.5641, GNorm = 1.4620, lr_0 = 1.2289e-04
Loss = 1.0385e-03, PNorm = 59.5657, GNorm = 1.3709, lr_0 = 1.2272e-04
Validation rmse = 4.242067
Validation R2 = -4.138367
Epoch 68
Train function
Loss = 1.1190e-03, PNorm = 59.5668, GNorm = 1.5583, lr_0 = 1.2254e-04
Loss = 8.8275e-04, PNorm = 59.5690, GNorm = 1.7779, lr_0 = 1.2238e-04
Loss = 8.2252e-04, PNorm = 59.5712, GNorm = 1.3267, lr_0 = 1.2221e-04
Loss = 8.8741e-04, PNorm = 59.5730, GNorm = 1.4094, lr_0 = 1.2205e-04
Loss = 8.3182e-04, PNorm = 59.5747, GNorm = 1.1588, lr_0 = 1.2188e-04
Loss = 9.3452e-04, PNorm = 59.5769, GNorm = 1.4944, lr_0 = 1.2172e-04
Loss = 1.0025e-03, PNorm = 59.5786, GNorm = 2.3051, lr_0 = 1.2156e-04
Loss = 7.1982e-04, PNorm = 59.5804, GNorm = 1.3183, lr_0 = 1.2139e-04
Loss = 7.9609e-04, PNorm = 59.5830, GNorm = 1.3674, lr_0 = 1.2123e-04
Loss = 1.3389e-03, PNorm = 59.5856, GNorm = 1.5503, lr_0 = 1.2107e-04
Loss = 6.4089e-04, PNorm = 59.5872, GNorm = 1.7169, lr_0 = 1.2091e-04
Loss = 1.5202e-03, PNorm = 59.5888, GNorm = 0.9192, lr_0 = 1.2074e-04
Loss = 1.2293e-03, PNorm = 59.5922, GNorm = 3.1273, lr_0 = 1.2058e-04
Loss = 1.4099e-03, PNorm = 59.5949, GNorm = 4.5694, lr_0 = 1.2042e-04
Loss = 9.9873e-04, PNorm = 59.5962, GNorm = 2.7265, lr_0 = 1.2026e-04
Loss = 1.2906e-03, PNorm = 59.5983, GNorm = 3.2835, lr_0 = 1.2010e-04
Loss = 1.3720e-03, PNorm = 59.6005, GNorm = 2.2989, lr_0 = 1.1994e-04
Loss = 1.0739e-03, PNorm = 59.6024, GNorm = 2.3533, lr_0 = 1.1978e-04
Loss = 1.0112e-03, PNorm = 59.6050, GNorm = 1.7373, lr_0 = 1.1961e-04
Loss = 9.4501e-04, PNorm = 59.6080, GNorm = 1.0026, lr_0 = 1.1945e-04
Loss = 8.7180e-04, PNorm = 59.6112, GNorm = 2.3785, lr_0 = 1.1929e-04
Loss = 1.1323e-03, PNorm = 59.6137, GNorm = 1.8388, lr_0 = 1.1913e-04
Loss = 9.2973e-04, PNorm = 59.6158, GNorm = 2.8330, lr_0 = 1.1897e-04
Validation rmse = 3.934511
Validation R2 = -3.420299
Epoch 69
Train function
Loss = 7.6439e-04, PNorm = 59.6188, GNorm = 2.0337, lr_0 = 1.1880e-04
Loss = 1.4189e-03, PNorm = 59.6212, GNorm = 0.8196, lr_0 = 1.1864e-04
Loss = 8.5147e-04, PNorm = 59.6228, GNorm = 1.3100, lr_0 = 1.1848e-04
Loss = 1.4446e-03, PNorm = 59.6252, GNorm = 1.2713, lr_0 = 1.1832e-04
Loss = 1.1377e-03, PNorm = 59.6282, GNorm = 2.2742, lr_0 = 1.1816e-04
Loss = 1.1750e-03, PNorm = 59.6302, GNorm = 1.7347, lr_0 = 1.1800e-04
Loss = 1.4322e-03, PNorm = 59.6317, GNorm = 1.7438, lr_0 = 1.1785e-04
Loss = 7.7644e-04, PNorm = 59.6323, GNorm = 2.2856, lr_0 = 1.1769e-04
Loss = 7.8532e-04, PNorm = 59.6340, GNorm = 1.7634, lr_0 = 1.1753e-04
Loss = 1.0083e-03, PNorm = 59.6366, GNorm = 2.4995, lr_0 = 1.1737e-04
Loss = 9.9049e-04, PNorm = 59.6388, GNorm = 1.4376, lr_0 = 1.1721e-04
Loss = 9.3784e-04, PNorm = 59.6404, GNorm = 1.3451, lr_0 = 1.1706e-04
Loss = 1.3157e-03, PNorm = 59.6426, GNorm = 1.0511, lr_0 = 1.1690e-04
Loss = 9.7062e-04, PNorm = 59.6457, GNorm = 1.2291, lr_0 = 1.1674e-04
Loss = 8.6264e-04, PNorm = 59.6487, GNorm = 2.2171, lr_0 = 1.1659e-04
Loss = 9.2754e-04, PNorm = 59.6507, GNorm = 1.2060, lr_0 = 1.1643e-04
Loss = 1.2278e-03, PNorm = 59.6527, GNorm = 1.9182, lr_0 = 1.1627e-04
Loss = 9.5939e-04, PNorm = 59.6542, GNorm = 2.5071, lr_0 = 1.1612e-04
Loss = 9.5817e-04, PNorm = 59.6557, GNorm = 1.4280, lr_0 = 1.1596e-04
Loss = 1.1924e-03, PNorm = 59.6577, GNorm = 1.3572, lr_0 = 1.1581e-04
Loss = 1.0529e-03, PNorm = 59.6608, GNorm = 2.1024, lr_0 = 1.1565e-04
Loss = 9.8502e-04, PNorm = 59.6639, GNorm = 1.8809, lr_0 = 1.1550e-04
Loss = 1.2305e-03, PNorm = 59.6664, GNorm = 2.7609, lr_0 = 1.1534e-04
Loss = 9.3823e-04, PNorm = 59.6683, GNorm = 2.6599, lr_0 = 1.1519e-04
Validation rmse = 3.991635
Validation R2 = -3.549585
Epoch 70
Train function
Loss = 9.2226e-04, PNorm = 59.6699, GNorm = 1.2936, lr_0 = 1.1503e-04
Loss = 1.3528e-03, PNorm = 59.6718, GNorm = 1.9557, lr_0 = 1.1488e-04
Loss = 6.7643e-04, PNorm = 59.6743, GNorm = 1.2816, lr_0 = 1.1472e-04
Loss = 8.8522e-04, PNorm = 59.6769, GNorm = 0.8426, lr_0 = 1.1457e-04
Loss = 1.2372e-03, PNorm = 59.6796, GNorm = 1.2896, lr_0 = 1.1442e-04
Loss = 6.9798e-04, PNorm = 59.6823, GNorm = 1.2095, lr_0 = 1.1426e-04
Loss = 7.9543e-04, PNorm = 59.6842, GNorm = 1.3078, lr_0 = 1.1411e-04
Loss = 1.1354e-03, PNorm = 59.6867, GNorm = 2.2078, lr_0 = 1.1396e-04
Loss = 1.2472e-03, PNorm = 59.6884, GNorm = 2.6307, lr_0 = 1.1380e-04
Loss = 1.1491e-03, PNorm = 59.6895, GNorm = 1.3907, lr_0 = 1.1365e-04
Loss = 1.8380e-03, PNorm = 59.6911, GNorm = 3.1707, lr_0 = 1.1350e-04
Loss = 1.0690e-03, PNorm = 59.6927, GNorm = 2.4674, lr_0 = 1.1334e-04
Loss = 7.8075e-04, PNorm = 59.6945, GNorm = 1.5988, lr_0 = 1.1319e-04
Loss = 9.8533e-04, PNorm = 59.6962, GNorm = 1.4306, lr_0 = 1.1304e-04
Loss = 8.0310e-04, PNorm = 59.6994, GNorm = 2.1238, lr_0 = 1.1289e-04
Loss = 7.0680e-04, PNorm = 59.7015, GNorm = 1.0349, lr_0 = 1.1274e-04
Loss = 1.0038e-03, PNorm = 59.7030, GNorm = 1.4779, lr_0 = 1.1259e-04
Loss = 1.0402e-03, PNorm = 59.7046, GNorm = 1.5569, lr_0 = 1.1244e-04
Loss = 9.1618e-04, PNorm = 59.7077, GNorm = 0.9755, lr_0 = 1.1228e-04
Loss = 8.7078e-04, PNorm = 59.7096, GNorm = 2.2072, lr_0 = 1.1213e-04
Loss = 1.0328e-03, PNorm = 59.7116, GNorm = 1.2246, lr_0 = 1.1198e-04
Loss = 9.4530e-04, PNorm = 59.7148, GNorm = 1.3608, lr_0 = 1.1183e-04
Loss = 9.9464e-04, PNorm = 59.7163, GNorm = 0.7118, lr_0 = 1.1168e-04
Validation rmse = 4.211154
Validation R2 = -4.063751
Epoch 71
Train function
Loss = 6.1398e-04, PNorm = 59.7172, GNorm = 1.3079, lr_0 = 1.1152e-04
Loss = 7.8748e-04, PNorm = 59.7193, GNorm = 1.0339, lr_0 = 1.1137e-04
Loss = 6.7915e-04, PNorm = 59.7216, GNorm = 1.8287, lr_0 = 1.1122e-04
Loss = 5.5184e-04, PNorm = 59.7242, GNorm = 1.1211, lr_0 = 1.1107e-04
Loss = 8.8666e-04, PNorm = 59.7266, GNorm = 1.2899, lr_0 = 1.1092e-04
Loss = 6.8137e-04, PNorm = 59.7288, GNorm = 2.0182, lr_0 = 1.1077e-04
Loss = 1.1536e-03, PNorm = 59.7304, GNorm = 1.4446, lr_0 = 1.1062e-04
Loss = 8.6148e-04, PNorm = 59.7324, GNorm = 0.8788, lr_0 = 1.1048e-04
Loss = 1.1230e-03, PNorm = 59.7345, GNorm = 1.6562, lr_0 = 1.1033e-04
Loss = 1.0197e-03, PNorm = 59.7367, GNorm = 1.5891, lr_0 = 1.1018e-04
Loss = 8.9548e-04, PNorm = 59.7385, GNorm = 1.0388, lr_0 = 1.1003e-04
Loss = 1.1752e-03, PNorm = 59.7394, GNorm = 2.0288, lr_0 = 1.0988e-04
Loss = 7.0359e-04, PNorm = 59.7409, GNorm = 1.0453, lr_0 = 1.0974e-04
Loss = 7.6254e-04, PNorm = 59.7425, GNorm = 1.5165, lr_0 = 1.0959e-04
Loss = 1.6777e-03, PNorm = 59.7435, GNorm = 1.2027, lr_0 = 1.0944e-04
Loss = 9.6016e-04, PNorm = 59.7454, GNorm = 1.8928, lr_0 = 1.0930e-04
Loss = 8.2360e-04, PNorm = 59.7475, GNorm = 1.0248, lr_0 = 1.0915e-04
Loss = 1.2251e-03, PNorm = 59.7495, GNorm = 0.8023, lr_0 = 1.0900e-04
Loss = 1.0178e-03, PNorm = 59.7522, GNorm = 1.4571, lr_0 = 1.0886e-04
Loss = 7.3693e-04, PNorm = 59.7538, GNorm = 1.3303, lr_0 = 1.0871e-04
Loss = 7.5586e-04, PNorm = 59.7552, GNorm = 1.5206, lr_0 = 1.0856e-04
Loss = 6.1693e-04, PNorm = 59.7570, GNorm = 1.1642, lr_0 = 1.0842e-04
Loss = 1.4742e-03, PNorm = 59.7585, GNorm = 4.5557, lr_0 = 1.0827e-04
Loss = 1.0180e-03, PNorm = 59.7601, GNorm = 2.2171, lr_0 = 1.0813e-04
Validation rmse = 4.137265
Validation R2 = -3.887614
Epoch 72
Train function
Loss = 5.7871e-04, PNorm = 59.7623, GNorm = 1.5085, lr_0 = 1.0797e-04
Loss = 1.0863e-03, PNorm = 59.7646, GNorm = 1.4503, lr_0 = 1.0782e-04
Loss = 8.2573e-04, PNorm = 59.7661, GNorm = 0.9544, lr_0 = 1.0768e-04
Loss = 6.6241e-04, PNorm = 59.7681, GNorm = 2.1661, lr_0 = 1.0753e-04
Loss = 8.3812e-04, PNorm = 59.7702, GNorm = 1.4572, lr_0 = 1.0739e-04
Loss = 5.3183e-04, PNorm = 59.7716, GNorm = 1.5237, lr_0 = 1.0725e-04
Loss = 1.1456e-03, PNorm = 59.7743, GNorm = 1.5427, lr_0 = 1.0710e-04
Loss = 7.0613e-04, PNorm = 59.7762, GNorm = 0.9201, lr_0 = 1.0696e-04
Loss = 9.2277e-04, PNorm = 59.7776, GNorm = 1.4918, lr_0 = 1.0681e-04
Loss = 5.8012e-04, PNorm = 59.7790, GNorm = 1.5783, lr_0 = 1.0667e-04
Loss = 1.2662e-03, PNorm = 59.7810, GNorm = 1.3133, lr_0 = 1.0653e-04
Loss = 9.3905e-04, PNorm = 59.7832, GNorm = 0.7989, lr_0 = 1.0639e-04
Loss = 6.3662e-04, PNorm = 59.7847, GNorm = 1.7330, lr_0 = 1.0624e-04
Loss = 5.7548e-04, PNorm = 59.7861, GNorm = 1.3163, lr_0 = 1.0610e-04
Loss = 9.2849e-04, PNorm = 59.7882, GNorm = 2.6174, lr_0 = 1.0596e-04
Loss = 9.0272e-04, PNorm = 59.7902, GNorm = 1.1474, lr_0 = 1.0582e-04
Loss = 8.1042e-04, PNorm = 59.7921, GNorm = 1.0258, lr_0 = 1.0567e-04
Loss = 6.7482e-04, PNorm = 59.7941, GNorm = 1.5083, lr_0 = 1.0553e-04
Loss = 1.5140e-03, PNorm = 59.7953, GNorm = 3.0219, lr_0 = 1.0539e-04
Loss = 5.9661e-04, PNorm = 59.7971, GNorm = 1.6379, lr_0 = 1.0525e-04
Loss = 9.8551e-04, PNorm = 59.7992, GNorm = 2.1181, lr_0 = 1.0511e-04
Loss = 6.6932e-04, PNorm = 59.8014, GNorm = 1.1301, lr_0 = 1.0497e-04
Loss = 1.4415e-03, PNorm = 59.8029, GNorm = 1.3735, lr_0 = 1.0483e-04
Validation rmse = 4.197926
Validation R2 = -4.031990
Epoch 73
Train function
Loss = 1.6339e-03, PNorm = 59.8049, GNorm = 2.6324, lr_0 = 1.0467e-04
Loss = 1.2202e-03, PNorm = 59.8081, GNorm = 0.8936, lr_0 = 1.0453e-04
Loss = 6.1775e-04, PNorm = 59.8112, GNorm = 0.8482, lr_0 = 1.0439e-04
Loss = 7.1440e-04, PNorm = 59.8133, GNorm = 1.5273, lr_0 = 1.0425e-04
Loss = 6.5967e-04, PNorm = 59.8157, GNorm = 1.0042, lr_0 = 1.0411e-04
Loss = 9.3173e-04, PNorm = 59.8174, GNorm = 1.3923, lr_0 = 1.0397e-04
Loss = 6.3101e-04, PNorm = 59.8189, GNorm = 1.4077, lr_0 = 1.0383e-04
Loss = 7.4092e-04, PNorm = 59.8205, GNorm = 2.1646, lr_0 = 1.0369e-04
Loss = 8.2605e-04, PNorm = 59.8224, GNorm = 1.3875, lr_0 = 1.0355e-04
Loss = 9.3166e-04, PNorm = 59.8239, GNorm = 1.6417, lr_0 = 1.0341e-04
Loss = 8.9498e-04, PNorm = 59.8252, GNorm = 2.0709, lr_0 = 1.0327e-04
Loss = 1.1699e-03, PNorm = 59.8263, GNorm = 1.6218, lr_0 = 1.0314e-04
Loss = 1.0358e-03, PNorm = 59.8279, GNorm = 1.5484, lr_0 = 1.0300e-04
Loss = 9.9261e-04, PNorm = 59.8296, GNorm = 1.2352, lr_0 = 1.0286e-04
Loss = 6.0424e-04, PNorm = 59.8309, GNorm = 1.8167, lr_0 = 1.0272e-04
Loss = 8.9908e-04, PNorm = 59.8324, GNorm = 0.8668, lr_0 = 1.0258e-04
Loss = 5.8742e-04, PNorm = 59.8344, GNorm = 1.4991, lr_0 = 1.0245e-04
Loss = 1.2729e-03, PNorm = 59.8358, GNorm = 1.0656, lr_0 = 1.0231e-04
Loss = 7.4310e-04, PNorm = 59.8372, GNorm = 1.1331, lr_0 = 1.0217e-04
Loss = 8.7447e-04, PNorm = 59.8390, GNorm = 0.8693, lr_0 = 1.0203e-04
Loss = 1.3645e-03, PNorm = 59.8407, GNorm = 2.2576, lr_0 = 1.0190e-04
Loss = 6.7802e-04, PNorm = 59.8433, GNorm = 1.8984, lr_0 = 1.0176e-04
Loss = 7.0013e-04, PNorm = 59.8456, GNorm = 0.9837, lr_0 = 1.0162e-04
Loss = 6.5225e-04, PNorm = 59.8473, GNorm = 1.3007, lr_0 = 1.0149e-04
Loss = 3.0613e-03, PNorm = 59.8475, GNorm = 4.1279, lr_0 = 1.0147e-04
Validation rmse = 4.138621
Validation R2 = -3.890819
Epoch 74
Train function
Loss = 6.1809e-04, PNorm = 59.8491, GNorm = 1.1214, lr_0 = 1.0134e-04
Loss = 4.2084e-04, PNorm = 59.8515, GNorm = 1.4624, lr_0 = 1.0120e-04
Loss = 7.3134e-04, PNorm = 59.8532, GNorm = 1.8361, lr_0 = 1.0107e-04
Loss = 9.9093e-04, PNorm = 59.8547, GNorm = 2.8655, lr_0 = 1.0093e-04
Loss = 6.3641e-04, PNorm = 59.8562, GNorm = 1.6341, lr_0 = 1.0080e-04
Loss = 1.0181e-03, PNorm = 59.8577, GNorm = 1.9118, lr_0 = 1.0066e-04
Loss = 8.6028e-04, PNorm = 59.8594, GNorm = 1.6218, lr_0 = 1.0052e-04
Loss = 7.1263e-04, PNorm = 59.8621, GNorm = 1.5914, lr_0 = 1.0039e-04
Loss = 6.4656e-04, PNorm = 59.8640, GNorm = 1.2270, lr_0 = 1.0026e-04
Loss = 5.0864e-04, PNorm = 59.8653, GNorm = 1.4789, lr_0 = 1.0012e-04
Loss = 8.4913e-04, PNorm = 59.8663, GNorm = 1.2931, lr_0 = 1.0000e-04
Loss = 7.0617e-04, PNorm = 59.8676, GNorm = 1.1639, lr_0 = 1.0000e-04
Loss = 7.7059e-04, PNorm = 59.8692, GNorm = 0.9693, lr_0 = 1.0000e-04
Loss = 5.3338e-04, PNorm = 59.8711, GNorm = 0.9634, lr_0 = 1.0000e-04
Loss = 1.2518e-03, PNorm = 59.8729, GNorm = 1.9500, lr_0 = 1.0000e-04
Loss = 8.8725e-04, PNorm = 59.8746, GNorm = 1.2585, lr_0 = 1.0000e-04
Loss = 1.0962e-03, PNorm = 59.8769, GNorm = 2.2059, lr_0 = 1.0000e-04
Loss = 8.2610e-04, PNorm = 59.8790, GNorm = 1.8321, lr_0 = 1.0000e-04
Loss = 1.2795e-03, PNorm = 59.8811, GNorm = 3.3866, lr_0 = 1.0000e-04
Loss = 8.8791e-04, PNorm = 59.8828, GNorm = 1.8704, lr_0 = 1.0000e-04
Loss = 1.0938e-03, PNorm = 59.8834, GNorm = 1.6847, lr_0 = 1.0000e-04
Loss = 7.5326e-04, PNorm = 59.8848, GNorm = 2.0318, lr_0 = 1.0000e-04
Loss = 9.6942e-04, PNorm = 59.8867, GNorm = 0.9622, lr_0 = 1.0000e-04
Validation rmse = 4.119315
Validation R2 = -3.845294
Epoch 75
Train function
Loss = 5.3317e-04, PNorm = 59.8885, GNorm = 0.7921, lr_0 = 1.0000e-04
Loss = 7.9634e-04, PNorm = 59.8897, GNorm = 1.1167, lr_0 = 1.0000e-04
Loss = 6.5250e-04, PNorm = 59.8915, GNorm = 1.1459, lr_0 = 1.0000e-04
Loss = 7.7845e-04, PNorm = 59.8934, GNorm = 1.4594, lr_0 = 1.0000e-04
Loss = 4.5502e-04, PNorm = 59.8953, GNorm = 1.0947, lr_0 = 1.0000e-04
Loss = 4.1670e-04, PNorm = 59.8967, GNorm = 1.3631, lr_0 = 1.0000e-04
Loss = 6.0368e-04, PNorm = 59.8981, GNorm = 2.2504, lr_0 = 1.0000e-04
Loss = 6.3289e-04, PNorm = 59.9001, GNorm = 1.1242, lr_0 = 1.0000e-04
Loss = 1.2660e-03, PNorm = 59.9017, GNorm = 0.8866, lr_0 = 1.0000e-04
Loss = 6.8422e-04, PNorm = 59.9028, GNorm = 2.6794, lr_0 = 1.0000e-04
Loss = 8.0343e-04, PNorm = 59.9050, GNorm = 1.1079, lr_0 = 1.0000e-04
Loss = 8.2784e-04, PNorm = 59.9065, GNorm = 0.6334, lr_0 = 1.0000e-04
Loss = 8.8294e-04, PNorm = 59.9080, GNorm = 1.0016, lr_0 = 1.0000e-04
Loss = 1.0356e-03, PNorm = 59.9100, GNorm = 1.2167, lr_0 = 1.0000e-04
Loss = 7.9985e-04, PNorm = 59.9122, GNorm = 1.4322, lr_0 = 1.0000e-04
Loss = 7.2373e-04, PNorm = 59.9147, GNorm = 2.2768, lr_0 = 1.0000e-04
Loss = 7.2135e-04, PNorm = 59.9168, GNorm = 2.6546, lr_0 = 1.0000e-04
Loss = 9.8164e-04, PNorm = 59.9177, GNorm = 0.7884, lr_0 = 1.0000e-04
Loss = 8.0045e-04, PNorm = 59.9196, GNorm = 1.0155, lr_0 = 1.0000e-04
Loss = 7.4477e-04, PNorm = 59.9212, GNorm = 2.4505, lr_0 = 1.0000e-04
Loss = 9.1277e-04, PNorm = 59.9219, GNorm = 1.2167, lr_0 = 1.0000e-04
Loss = 1.0957e-03, PNorm = 59.9238, GNorm = 1.1092, lr_0 = 1.0000e-04
Loss = 1.2821e-03, PNorm = 59.9254, GNorm = 1.0281, lr_0 = 1.0000e-04
Validation rmse = 4.170877
Validation R2 = -3.967352
Epoch 76
Train function
Loss = 5.0598e-04, PNorm = 59.9268, GNorm = 1.1570, lr_0 = 1.0000e-04
Loss = 6.7232e-04, PNorm = 59.9286, GNorm = 1.3280, lr_0 = 1.0000e-04
Loss = 8.0120e-04, PNorm = 59.9304, GNorm = 1.3015, lr_0 = 1.0000e-04
Loss = 1.0720e-03, PNorm = 59.9314, GNorm = 2.2276, lr_0 = 1.0000e-04
Loss = 8.1239e-04, PNorm = 59.9333, GNorm = 0.9549, lr_0 = 1.0000e-04
Loss = 9.1988e-04, PNorm = 59.9349, GNorm = 3.3647, lr_0 = 1.0000e-04
Loss = 6.3076e-04, PNorm = 59.9361, GNorm = 1.1258, lr_0 = 1.0000e-04
Loss = 8.2847e-04, PNorm = 59.9378, GNorm = 1.0438, lr_0 = 1.0000e-04
Loss = 5.9151e-04, PNorm = 59.9395, GNorm = 1.9726, lr_0 = 1.0000e-04
Loss = 4.7995e-04, PNorm = 59.9415, GNorm = 1.5886, lr_0 = 1.0000e-04
Loss = 7.0517e-04, PNorm = 59.9427, GNorm = 1.0776, lr_0 = 1.0000e-04
Loss = 1.2122e-03, PNorm = 59.9438, GNorm = 1.2812, lr_0 = 1.0000e-04
Loss = 8.7604e-04, PNorm = 59.9454, GNorm = 3.1420, lr_0 = 1.0000e-04
Loss = 8.6090e-04, PNorm = 59.9478, GNorm = 1.9103, lr_0 = 1.0000e-04
Loss = 7.0596e-04, PNorm = 59.9494, GNorm = 1.9712, lr_0 = 1.0000e-04
Loss = 1.2861e-03, PNorm = 59.9519, GNorm = 2.6594, lr_0 = 1.0000e-04
Loss = 5.8821e-04, PNorm = 59.9539, GNorm = 1.6235, lr_0 = 1.0000e-04
Loss = 7.1316e-04, PNorm = 59.9562, GNorm = 1.6100, lr_0 = 1.0000e-04
Loss = 6.2256e-04, PNorm = 59.9583, GNorm = 1.2744, lr_0 = 1.0000e-04
Loss = 6.7578e-04, PNorm = 59.9606, GNorm = 1.2204, lr_0 = 1.0000e-04
Loss = 7.6896e-04, PNorm = 59.9629, GNorm = 0.8408, lr_0 = 1.0000e-04
Loss = 9.5959e-04, PNorm = 59.9637, GNorm = 1.1140, lr_0 = 1.0000e-04
Loss = 8.3267e-04, PNorm = 59.9648, GNorm = 1.0145, lr_0 = 1.0000e-04
Loss = 5.6500e-04, PNorm = 59.9664, GNorm = 1.2343, lr_0 = 1.0000e-04
Validation rmse = 4.046703
Validation R2 = -3.675981
Epoch 77
Train function
Loss = 5.3095e-04, PNorm = 59.9692, GNorm = 1.3365, lr_0 = 1.0000e-04
Loss = 9.9566e-04, PNorm = 59.9711, GNorm = 3.2324, lr_0 = 1.0000e-04
Loss = 9.1488e-04, PNorm = 59.9725, GNorm = 2.2900, lr_0 = 1.0000e-04
Loss = 5.9230e-04, PNorm = 59.9742, GNorm = 2.1179, lr_0 = 1.0000e-04
Loss = 8.4053e-04, PNorm = 59.9756, GNorm = 1.6042, lr_0 = 1.0000e-04
Loss = 6.8258e-04, PNorm = 59.9771, GNorm = 1.2985, lr_0 = 1.0000e-04
Loss = 7.2640e-04, PNorm = 59.9783, GNorm = 1.1726, lr_0 = 1.0000e-04
Loss = 6.5021e-04, PNorm = 59.9795, GNorm = 1.4513, lr_0 = 1.0000e-04
Loss = 8.3011e-04, PNorm = 59.9814, GNorm = 3.0276, lr_0 = 1.0000e-04
Loss = 7.5427e-04, PNorm = 59.9826, GNorm = 1.5488, lr_0 = 1.0000e-04
Loss = 8.0057e-04, PNorm = 59.9847, GNorm = 3.6387, lr_0 = 1.0000e-04
Loss = 6.3130e-04, PNorm = 59.9870, GNorm = 1.6718, lr_0 = 1.0000e-04
Loss = 5.1880e-04, PNorm = 59.9884, GNorm = 1.3702, lr_0 = 1.0000e-04
Loss = 1.2360e-03, PNorm = 59.9904, GNorm = 1.7347, lr_0 = 1.0000e-04
Loss = 8.5644e-04, PNorm = 59.9931, GNorm = 2.6767, lr_0 = 1.0000e-04
Loss = 9.6693e-04, PNorm = 59.9944, GNorm = 1.7751, lr_0 = 1.0000e-04
Loss = 1.3110e-03, PNorm = 59.9964, GNorm = 1.2710, lr_0 = 1.0000e-04
Loss = 9.7104e-04, PNorm = 59.9980, GNorm = 1.4823, lr_0 = 1.0000e-04
Loss = 6.8624e-04, PNorm = 59.9997, GNorm = 1.2787, lr_0 = 1.0000e-04
Loss = 6.8444e-04, PNorm = 60.0025, GNorm = 1.1210, lr_0 = 1.0000e-04
Loss = 6.3900e-04, PNorm = 60.0050, GNorm = 1.3256, lr_0 = 1.0000e-04
Loss = 8.3674e-04, PNorm = 60.0070, GNorm = 1.3370, lr_0 = 1.0000e-04
Loss = 6.4281e-04, PNorm = 60.0086, GNorm = 2.0299, lr_0 = 1.0000e-04
Validation rmse = 4.149999
Validation R2 = -3.917747
Epoch 78
Train function
Loss = 5.1517e-04, PNorm = 60.0102, GNorm = 0.8642, lr_0 = 1.0000e-04
Loss = 7.2512e-04, PNorm = 60.0117, GNorm = 0.8902, lr_0 = 1.0000e-04
Loss = 5.3040e-04, PNorm = 60.0132, GNorm = 0.7400, lr_0 = 1.0000e-04
Loss = 9.4548e-04, PNorm = 60.0147, GNorm = 1.8570, lr_0 = 1.0000e-04
Loss = 5.3037e-04, PNorm = 60.0158, GNorm = 1.1881, lr_0 = 1.0000e-04
Loss = 9.7997e-04, PNorm = 60.0171, GNorm = 1.5359, lr_0 = 1.0000e-04
Loss = 7.5038e-04, PNorm = 60.0192, GNorm = 1.1907, lr_0 = 1.0000e-04
Loss = 6.3929e-04, PNorm = 60.0214, GNorm = 1.4489, lr_0 = 1.0000e-04
Loss = 6.4536e-04, PNorm = 60.0229, GNorm = 1.6436, lr_0 = 1.0000e-04
Loss = 5.7690e-04, PNorm = 60.0247, GNorm = 1.2260, lr_0 = 1.0000e-04
Loss = 7.0690e-04, PNorm = 60.0265, GNorm = 1.1315, lr_0 = 1.0000e-04
Loss = 5.7111e-04, PNorm = 60.0278, GNorm = 1.6325, lr_0 = 1.0000e-04
Loss = 5.9052e-04, PNorm = 60.0302, GNorm = 1.6518, lr_0 = 1.0000e-04
Loss = 4.0616e-04, PNorm = 60.0317, GNorm = 0.6052, lr_0 = 1.0000e-04
Loss = 6.6902e-04, PNorm = 60.0325, GNorm = 0.9665, lr_0 = 1.0000e-04
Loss = 6.4488e-04, PNorm = 60.0336, GNorm = 1.1384, lr_0 = 1.0000e-04
Loss = 6.7162e-04, PNorm = 60.0355, GNorm = 0.8298, lr_0 = 1.0000e-04
Loss = 6.2689e-04, PNorm = 60.0369, GNorm = 2.1501, lr_0 = 1.0000e-04
Loss = 1.3838e-03, PNorm = 60.0382, GNorm = 1.2064, lr_0 = 1.0000e-04
Loss = 6.1599e-04, PNorm = 60.0398, GNorm = 1.1530, lr_0 = 1.0000e-04
Loss = 7.2887e-04, PNorm = 60.0403, GNorm = 2.1202, lr_0 = 1.0000e-04
Loss = 1.3485e-03, PNorm = 60.0414, GNorm = 4.0296, lr_0 = 1.0000e-04
Loss = 1.0159e-03, PNorm = 60.0424, GNorm = 1.9646, lr_0 = 1.0000e-04
Loss = 8.0332e-04, PNorm = 60.0436, GNorm = 2.3366, lr_0 = 1.0000e-04
Validation rmse = 4.249936
Validation R2 = -4.157449
Epoch 79
Train function
Loss = 7.8842e-04, PNorm = 60.0456, GNorm = 1.1434, lr_0 = 1.0000e-04
Loss = 7.0477e-04, PNorm = 60.0474, GNorm = 3.3798, lr_0 = 1.0000e-04
Loss = 1.0259e-03, PNorm = 60.0489, GNorm = 2.6489, lr_0 = 1.0000e-04
Loss = 1.1501e-03, PNorm = 60.0507, GNorm = 1.5308, lr_0 = 1.0000e-04
Loss = 9.0977e-04, PNorm = 60.0531, GNorm = 1.1926, lr_0 = 1.0000e-04
Loss = 7.4261e-04, PNorm = 60.0549, GNorm = 1.9486, lr_0 = 1.0000e-04
Loss = 1.0602e-03, PNorm = 60.0565, GNorm = 2.1920, lr_0 = 1.0000e-04
Loss = 6.4383e-04, PNorm = 60.0585, GNorm = 1.6678, lr_0 = 1.0000e-04
Loss = 5.6266e-04, PNorm = 60.0602, GNorm = 1.9019, lr_0 = 1.0000e-04
Loss = 7.0686e-04, PNorm = 60.0621, GNorm = 1.4386, lr_0 = 1.0000e-04
Loss = 6.3702e-04, PNorm = 60.0632, GNorm = 1.2077, lr_0 = 1.0000e-04
Loss = 5.8696e-04, PNorm = 60.0646, GNorm = 1.1551, lr_0 = 1.0000e-04
Loss = 5.5098e-04, PNorm = 60.0669, GNorm = 1.3332, lr_0 = 1.0000e-04
Loss = 7.0772e-04, PNorm = 60.0695, GNorm = 1.3435, lr_0 = 1.0000e-04
Loss = 4.4029e-04, PNorm = 60.0712, GNorm = 1.2660, lr_0 = 1.0000e-04
Loss = 6.9790e-04, PNorm = 60.0724, GNorm = 2.8940, lr_0 = 1.0000e-04
Loss = 6.3130e-04, PNorm = 60.0738, GNorm = 1.7388, lr_0 = 1.0000e-04
Loss = 4.9209e-04, PNorm = 60.0748, GNorm = 1.0265, lr_0 = 1.0000e-04
Loss = 6.3328e-04, PNorm = 60.0764, GNorm = 2.2179, lr_0 = 1.0000e-04
Loss = 5.0832e-04, PNorm = 60.0779, GNorm = 1.1938, lr_0 = 1.0000e-04
Loss = 5.8221e-04, PNorm = 60.0792, GNorm = 1.1214, lr_0 = 1.0000e-04
Loss = 8.5973e-04, PNorm = 60.0807, GNorm = 2.6180, lr_0 = 1.0000e-04
Loss = 8.5098e-04, PNorm = 60.0823, GNorm = 1.2424, lr_0 = 1.0000e-04
Validation rmse = 4.060732
Validation R2 = -3.708459
Epoch 80
Train function
Loss = 4.5495e-04, PNorm = 60.0835, GNorm = 0.9868, lr_0 = 1.0000e-04
Loss = 7.3613e-04, PNorm = 60.0852, GNorm = 1.9125, lr_0 = 1.0000e-04
Loss = 7.4014e-04, PNorm = 60.0880, GNorm = 0.8828, lr_0 = 1.0000e-04
Loss = 3.5895e-04, PNorm = 60.0895, GNorm = 0.7827, lr_0 = 1.0000e-04
Loss = 9.4732e-04, PNorm = 60.0910, GNorm = 0.9574, lr_0 = 1.0000e-04
Loss = 6.1776e-04, PNorm = 60.0931, GNorm = 0.9873, lr_0 = 1.0000e-04
Loss = 4.4024e-04, PNorm = 60.0951, GNorm = 1.6043, lr_0 = 1.0000e-04
Loss = 4.2193e-04, PNorm = 60.0962, GNorm = 1.0578, lr_0 = 1.0000e-04
Loss = 8.0976e-04, PNorm = 60.0969, GNorm = 0.8556, lr_0 = 1.0000e-04
Loss = 5.9222e-04, PNorm = 60.0985, GNorm = 1.5688, lr_0 = 1.0000e-04
Loss = 8.1925e-04, PNorm = 60.1004, GNorm = 1.3175, lr_0 = 1.0000e-04
Loss = 4.8662e-04, PNorm = 60.1015, GNorm = 0.9368, lr_0 = 1.0000e-04
Loss = 5.2625e-04, PNorm = 60.1027, GNorm = 1.6254, lr_0 = 1.0000e-04
Loss = 7.7151e-04, PNorm = 60.1043, GNorm = 1.6500, lr_0 = 1.0000e-04
Loss = 1.0773e-03, PNorm = 60.1060, GNorm = 1.0612, lr_0 = 1.0000e-04
Loss = 9.7265e-04, PNorm = 60.1075, GNorm = 1.2503, lr_0 = 1.0000e-04
Loss = 9.8229e-04, PNorm = 60.1081, GNorm = 1.9921, lr_0 = 1.0000e-04
Loss = 9.0558e-04, PNorm = 60.1096, GNorm = 1.1538, lr_0 = 1.0000e-04
Loss = 1.0177e-03, PNorm = 60.1111, GNorm = 1.5529, lr_0 = 1.0000e-04
Loss = 6.4325e-04, PNorm = 60.1130, GNorm = 1.8575, lr_0 = 1.0000e-04
Loss = 9.4245e-04, PNorm = 60.1146, GNorm = 1.8906, lr_0 = 1.0000e-04
Loss = 6.0388e-04, PNorm = 60.1164, GNorm = 1.6816, lr_0 = 1.0000e-04
Loss = 1.0614e-03, PNorm = 60.1181, GNorm = 1.2366, lr_0 = 1.0000e-04
Loss = 7.2419e-04, PNorm = 60.1196, GNorm = 1.5646, lr_0 = 1.0000e-04
Loss = 2.0084e-03, PNorm = 60.1197, GNorm = 2.7996, lr_0 = 1.0000e-04
Validation rmse = 4.066089
Validation R2 = -3.720891
Epoch 81
Train function
Loss = 6.7160e-04, PNorm = 60.1214, GNorm = 1.1658, lr_0 = 1.0000e-04
Loss = 6.9440e-04, PNorm = 60.1235, GNorm = 1.6361, lr_0 = 1.0000e-04
Loss = 7.4730e-04, PNorm = 60.1252, GNorm = 1.5923, lr_0 = 1.0000e-04
Loss = 4.2582e-04, PNorm = 60.1268, GNorm = 1.3317, lr_0 = 1.0000e-04
Loss = 9.3542e-04, PNorm = 60.1276, GNorm = 1.6165, lr_0 = 1.0000e-04
Loss = 5.2558e-04, PNorm = 60.1283, GNorm = 1.1457, lr_0 = 1.0000e-04
Loss = 5.4393e-04, PNorm = 60.1296, GNorm = 1.3158, lr_0 = 1.0000e-04
Loss = 8.8784e-04, PNorm = 60.1312, GNorm = 1.2714, lr_0 = 1.0000e-04
Loss = 5.3795e-04, PNorm = 60.1328, GNorm = 1.0936, lr_0 = 1.0000e-04
Loss = 4.8792e-04, PNorm = 60.1342, GNorm = 1.7877, lr_0 = 1.0000e-04
Loss = 8.4800e-04, PNorm = 60.1357, GNorm = 1.2442, lr_0 = 1.0000e-04
Loss = 7.2918e-04, PNorm = 60.1373, GNorm = 1.2116, lr_0 = 1.0000e-04
Loss = 6.9468e-04, PNorm = 60.1397, GNorm = 1.3083, lr_0 = 1.0000e-04
Loss = 7.0109e-04, PNorm = 60.1416, GNorm = 1.7568, lr_0 = 1.0000e-04
Loss = 8.6831e-04, PNorm = 60.1430, GNorm = 3.1982, lr_0 = 1.0000e-04
Loss = 6.3913e-04, PNorm = 60.1443, GNorm = 1.5834, lr_0 = 1.0000e-04
Loss = 8.5529e-04, PNorm = 60.1456, GNorm = 2.4686, lr_0 = 1.0000e-04
Loss = 9.8007e-04, PNorm = 60.1474, GNorm = 1.0923, lr_0 = 1.0000e-04
Loss = 5.3898e-04, PNorm = 60.1495, GNorm = 1.6588, lr_0 = 1.0000e-04
Loss = 7.0957e-04, PNorm = 60.1498, GNorm = 1.4636, lr_0 = 1.0000e-04
Loss = 4.0256e-04, PNorm = 60.1502, GNorm = 1.2853, lr_0 = 1.0000e-04
Loss = 7.9176e-04, PNorm = 60.1511, GNorm = 1.2175, lr_0 = 1.0000e-04
Loss = 9.2374e-04, PNorm = 60.1527, GNorm = 1.9319, lr_0 = 1.0000e-04
Validation rmse = 4.018126
Validation R2 = -3.610173
Epoch 82
Train function
Loss = 6.8456e-04, PNorm = 60.1537, GNorm = 1.1195, lr_0 = 1.0000e-04
Loss = 5.0755e-04, PNorm = 60.1552, GNorm = 1.5963, lr_0 = 1.0000e-04
Loss = 5.6404e-04, PNorm = 60.1569, GNorm = 1.6602, lr_0 = 1.0000e-04
Loss = 6.5755e-04, PNorm = 60.1586, GNorm = 1.1894, lr_0 = 1.0000e-04
Loss = 1.2906e-03, PNorm = 60.1603, GNorm = 1.1269, lr_0 = 1.0000e-04
Loss = 4.4280e-04, PNorm = 60.1620, GNorm = 1.3786, lr_0 = 1.0000e-04
Loss = 6.0393e-04, PNorm = 60.1634, GNorm = 1.4678, lr_0 = 1.0000e-04
Loss = 5.7295e-04, PNorm = 60.1654, GNorm = 1.0402, lr_0 = 1.0000e-04
Loss = 7.1020e-04, PNorm = 60.1675, GNorm = 0.7965, lr_0 = 1.0000e-04
Loss = 6.7188e-04, PNorm = 60.1685, GNorm = 0.8432, lr_0 = 1.0000e-04
Loss = 6.2420e-04, PNorm = 60.1698, GNorm = 1.7425, lr_0 = 1.0000e-04
Loss = 1.0458e-03, PNorm = 60.1718, GNorm = 1.3883, lr_0 = 1.0000e-04
Loss = 6.6576e-04, PNorm = 60.1736, GNorm = 0.9273, lr_0 = 1.0000e-04
Loss = 6.9721e-04, PNorm = 60.1751, GNorm = 1.6537, lr_0 = 1.0000e-04
Loss = 1.1484e-03, PNorm = 60.1759, GNorm = 1.0204, lr_0 = 1.0000e-04
Loss = 5.4968e-04, PNorm = 60.1767, GNorm = 1.3423, lr_0 = 1.0000e-04
Loss = 5.3289e-04, PNorm = 60.1784, GNorm = 0.8118, lr_0 = 1.0000e-04
Loss = 4.6064e-04, PNorm = 60.1795, GNorm = 0.8659, lr_0 = 1.0000e-04
Loss = 5.5070e-04, PNorm = 60.1815, GNorm = 0.7493, lr_0 = 1.0000e-04
Loss = 1.1995e-03, PNorm = 60.1829, GNorm = 1.3647, lr_0 = 1.0000e-04
Loss = 4.6023e-04, PNorm = 60.1840, GNorm = 1.2075, lr_0 = 1.0000e-04
Loss = 9.0828e-04, PNorm = 60.1853, GNorm = 2.3031, lr_0 = 1.0000e-04
Loss = 5.3743e-04, PNorm = 60.1871, GNorm = 1.2922, lr_0 = 1.0000e-04
Validation rmse = 4.135347
Validation R2 = -3.883082
Epoch 83
Train function
Loss = 4.3786e-04, PNorm = 60.1889, GNorm = 1.2111, lr_0 = 1.0000e-04
Loss = 6.9473e-04, PNorm = 60.1912, GNorm = 0.7829, lr_0 = 1.0000e-04
Loss = 3.1304e-04, PNorm = 60.1930, GNorm = 0.8653, lr_0 = 1.0000e-04
Loss = 4.5730e-04, PNorm = 60.1940, GNorm = 1.3082, lr_0 = 1.0000e-04
Loss = 5.5230e-04, PNorm = 60.1954, GNorm = 1.4475, lr_0 = 1.0000e-04
Loss = 1.1864e-03, PNorm = 60.1964, GNorm = 1.9503, lr_0 = 1.0000e-04
Loss = 1.2837e-03, PNorm = 60.1984, GNorm = 1.4300, lr_0 = 1.0000e-04
Loss = 5.0267e-04, PNorm = 60.2004, GNorm = 1.6331, lr_0 = 1.0000e-04
Loss = 5.6060e-04, PNorm = 60.2012, GNorm = 1.6171, lr_0 = 1.0000e-04
Loss = 6.0838e-04, PNorm = 60.2024, GNorm = 2.1756, lr_0 = 1.0000e-04
Loss = 6.4453e-04, PNorm = 60.2042, GNorm = 1.9580, lr_0 = 1.0000e-04
Loss = 5.5669e-04, PNorm = 60.2058, GNorm = 1.5674, lr_0 = 1.0000e-04
Loss = 5.8104e-04, PNorm = 60.2074, GNorm = 0.9595, lr_0 = 1.0000e-04
Loss = 1.0364e-03, PNorm = 60.2084, GNorm = 1.4654, lr_0 = 1.0000e-04
Loss = 9.7208e-04, PNorm = 60.2093, GNorm = 1.4641, lr_0 = 1.0000e-04
Loss = 7.1567e-04, PNorm = 60.2103, GNorm = 1.9904, lr_0 = 1.0000e-04
Loss = 1.0271e-03, PNorm = 60.2117, GNorm = 2.5760, lr_0 = 1.0000e-04
Loss = 4.1812e-04, PNorm = 60.2133, GNorm = 1.1988, lr_0 = 1.0000e-04
Loss = 5.5697e-04, PNorm = 60.2156, GNorm = 1.2605, lr_0 = 1.0000e-04
Loss = 4.9231e-04, PNorm = 60.2165, GNorm = 1.6922, lr_0 = 1.0000e-04
Loss = 9.1296e-04, PNorm = 60.2179, GNorm = 0.9563, lr_0 = 1.0000e-04
Loss = 9.5393e-04, PNorm = 60.2201, GNorm = 1.8065, lr_0 = 1.0000e-04
Loss = 6.8631e-04, PNorm = 60.2214, GNorm = 3.0446, lr_0 = 1.0000e-04
Loss = 5.6397e-04, PNorm = 60.2217, GNorm = 1.8854, lr_0 = 1.0000e-04
Validation rmse = 4.242537
Validation R2 = -4.139506
Epoch 84
Train function
Loss = 3.8238e-04, PNorm = 60.2226, GNorm = 0.7985, lr_0 = 1.0000e-04
Loss = 4.4257e-04, PNorm = 60.2240, GNorm = 0.9165, lr_0 = 1.0000e-04
Loss = 3.2791e-04, PNorm = 60.2248, GNorm = 0.9306, lr_0 = 1.0000e-04
Loss = 8.5613e-04, PNorm = 60.2261, GNorm = 1.1385, lr_0 = 1.0000e-04
Loss = 7.8347e-04, PNorm = 60.2289, GNorm = 1.3177, lr_0 = 1.0000e-04
Loss = 6.4764e-04, PNorm = 60.2306, GNorm = 1.4542, lr_0 = 1.0000e-04
Loss = 8.0845e-04, PNorm = 60.2319, GNorm = 1.1710, lr_0 = 1.0000e-04
Loss = 5.0419e-04, PNorm = 60.2333, GNorm = 0.9968, lr_0 = 1.0000e-04
Loss = 1.3454e-03, PNorm = 60.2351, GNorm = 3.1270, lr_0 = 1.0000e-04
Loss = 5.0039e-04, PNorm = 60.2365, GNorm = 0.9612, lr_0 = 1.0000e-04
Loss = 8.1305e-04, PNorm = 60.2380, GNorm = 1.0093, lr_0 = 1.0000e-04
Loss = 6.3146e-04, PNorm = 60.2395, GNorm = 1.1292, lr_0 = 1.0000e-04
Loss = 8.2155e-04, PNorm = 60.2424, GNorm = 1.7817, lr_0 = 1.0000e-04
Loss = 5.5005e-04, PNorm = 60.2441, GNorm = 0.9713, lr_0 = 1.0000e-04
Loss = 1.0434e-03, PNorm = 60.2446, GNorm = 1.2459, lr_0 = 1.0000e-04
Loss = 6.2251e-04, PNorm = 60.2455, GNorm = 0.7815, lr_0 = 1.0000e-04
Loss = 4.8245e-04, PNorm = 60.2467, GNorm = 0.9592, lr_0 = 1.0000e-04
Loss = 4.3660e-04, PNorm = 60.2477, GNorm = 1.0475, lr_0 = 1.0000e-04
Loss = 7.0171e-04, PNorm = 60.2490, GNorm = 1.0827, lr_0 = 1.0000e-04
Loss = 6.2336e-04, PNorm = 60.2508, GNorm = 1.1430, lr_0 = 1.0000e-04
Loss = 1.0948e-03, PNorm = 60.2523, GNorm = 2.4117, lr_0 = 1.0000e-04
Loss = 4.5320e-04, PNorm = 60.2535, GNorm = 2.1644, lr_0 = 1.0000e-04
Loss = 4.8662e-04, PNorm = 60.2556, GNorm = 0.8172, lr_0 = 1.0000e-04
Validation rmse = 4.065710
Validation R2 = -3.720009
Epoch 85
Train function
Loss = 5.0292e-04, PNorm = 60.2566, GNorm = 1.2734, lr_0 = 1.0000e-04
Loss = 4.9643e-04, PNorm = 60.2574, GNorm = 1.0496, lr_0 = 1.0000e-04
Loss = 6.1617e-04, PNorm = 60.2587, GNorm = 1.6549, lr_0 = 1.0000e-04
Loss = 6.6480e-04, PNorm = 60.2590, GNorm = 2.9220, lr_0 = 1.0000e-04
Loss = 8.1791e-04, PNorm = 60.2599, GNorm = 1.9886, lr_0 = 1.0000e-04
Loss = 5.8477e-04, PNorm = 60.2621, GNorm = 1.4021, lr_0 = 1.0000e-04
Loss = 1.0782e-03, PNorm = 60.2639, GNorm = 1.5141, lr_0 = 1.0000e-04
Loss = 6.0261e-04, PNorm = 60.2653, GNorm = 1.8798, lr_0 = 1.0000e-04
Loss = 5.9037e-04, PNorm = 60.2677, GNorm = 1.5895, lr_0 = 1.0000e-04
Loss = 4.9418e-04, PNorm = 60.2694, GNorm = 1.2852, lr_0 = 1.0000e-04
Loss = 4.8668e-04, PNorm = 60.2713, GNorm = 0.9743, lr_0 = 1.0000e-04
Loss = 4.4686e-04, PNorm = 60.2733, GNorm = 1.1671, lr_0 = 1.0000e-04
Loss = 1.0546e-03, PNorm = 60.2741, GNorm = 1.4194, lr_0 = 1.0000e-04
Loss = 5.4906e-04, PNorm = 60.2752, GNorm = 2.6934, lr_0 = 1.0000e-04
Loss = 6.5329e-04, PNorm = 60.2772, GNorm = 2.0247, lr_0 = 1.0000e-04
Loss = 4.1400e-04, PNorm = 60.2785, GNorm = 0.9453, lr_0 = 1.0000e-04
Loss = 5.0142e-04, PNorm = 60.2802, GNorm = 1.3011, lr_0 = 1.0000e-04
Loss = 5.9584e-04, PNorm = 60.2817, GNorm = 0.9292, lr_0 = 1.0000e-04
Loss = 9.0342e-04, PNorm = 60.2833, GNorm = 1.4716, lr_0 = 1.0000e-04
Loss = 9.3930e-04, PNorm = 60.2859, GNorm = 1.4073, lr_0 = 1.0000e-04
Loss = 7.4938e-04, PNorm = 60.2876, GNorm = 1.6252, lr_0 = 1.0000e-04
Loss = 5.6363e-04, PNorm = 60.2888, GNorm = 2.2144, lr_0 = 1.0000e-04
Loss = 3.7177e-04, PNorm = 60.2901, GNorm = 1.3039, lr_0 = 1.0000e-04
Loss = 7.7978e-04, PNorm = 60.2915, GNorm = 0.7802, lr_0 = 1.0000e-04
Validation rmse = 4.290639
Validation R2 = -4.256710
Epoch 86
Train function
Loss = 6.2993e-04, PNorm = 60.2933, GNorm = 1.0343, lr_0 = 1.0000e-04
Loss = 5.0239e-04, PNorm = 60.2951, GNorm = 0.7405, lr_0 = 1.0000e-04
Loss = 4.8732e-04, PNorm = 60.2959, GNorm = 0.9059, lr_0 = 1.0000e-04
Loss = 6.9883e-04, PNorm = 60.2978, GNorm = 1.5443, lr_0 = 1.0000e-04
Loss = 4.0849e-04, PNorm = 60.2990, GNorm = 0.7118, lr_0 = 1.0000e-04
Loss = 5.3859e-04, PNorm = 60.3000, GNorm = 1.8006, lr_0 = 1.0000e-04
Loss = 4.7332e-04, PNorm = 60.3013, GNorm = 1.5291, lr_0 = 1.0000e-04
Loss = 4.3243e-04, PNorm = 60.3031, GNorm = 1.0270, lr_0 = 1.0000e-04
Loss = 5.0453e-04, PNorm = 60.3056, GNorm = 0.9921, lr_0 = 1.0000e-04
Loss = 1.0954e-03, PNorm = 60.3062, GNorm = 3.3290, lr_0 = 1.0000e-04
Loss = 6.9986e-04, PNorm = 60.3069, GNorm = 1.0592, lr_0 = 1.0000e-04
Loss = 5.1158e-04, PNorm = 60.3091, GNorm = 1.3801, lr_0 = 1.0000e-04
Loss = 6.3227e-04, PNorm = 60.3118, GNorm = 1.5426, lr_0 = 1.0000e-04
Loss = 6.9134e-04, PNorm = 60.3143, GNorm = 1.4718, lr_0 = 1.0000e-04
Loss = 6.1101e-04, PNorm = 60.3165, GNorm = 1.5322, lr_0 = 1.0000e-04
Loss = 8.6389e-04, PNorm = 60.3177, GNorm = 2.5049, lr_0 = 1.0000e-04
Loss = 5.7086e-04, PNorm = 60.3185, GNorm = 0.7045, lr_0 = 1.0000e-04
Loss = 6.1286e-04, PNorm = 60.3205, GNorm = 1.6420, lr_0 = 1.0000e-04
Loss = 4.1758e-04, PNorm = 60.3224, GNorm = 1.2460, lr_0 = 1.0000e-04
Loss = 1.1371e-03, PNorm = 60.3237, GNorm = 0.5502, lr_0 = 1.0000e-04
Loss = 6.1143e-04, PNorm = 60.3247, GNorm = 1.5520, lr_0 = 1.0000e-04
Loss = 5.6220e-04, PNorm = 60.3268, GNorm = 2.9501, lr_0 = 1.0000e-04
Loss = 9.6446e-04, PNorm = 60.3287, GNorm = 1.6467, lr_0 = 1.0000e-04
Validation rmse = 4.181089
Validation R2 = -3.991706
Epoch 87
Train function
Loss = 6.7523e-04, PNorm = 60.3299, GNorm = 1.3936, lr_0 = 1.0000e-04
Loss = 4.4307e-04, PNorm = 60.3312, GNorm = 1.5961, lr_0 = 1.0000e-04
Loss = 4.0157e-04, PNorm = 60.3331, GNorm = 1.0308, lr_0 = 1.0000e-04
Loss = 8.9030e-04, PNorm = 60.3346, GNorm = 0.8406, lr_0 = 1.0000e-04
Loss = 6.2538e-04, PNorm = 60.3360, GNorm = 0.6639, lr_0 = 1.0000e-04
Loss = 7.8540e-04, PNorm = 60.3370, GNorm = 1.7156, lr_0 = 1.0000e-04
Loss = 5.1182e-04, PNorm = 60.3380, GNorm = 0.6675, lr_0 = 1.0000e-04
Loss = 6.7134e-04, PNorm = 60.3398, GNorm = 1.4399, lr_0 = 1.0000e-04
Loss = 4.1185e-04, PNorm = 60.3410, GNorm = 0.6034, lr_0 = 1.0000e-04
Loss = 4.0768e-04, PNorm = 60.3423, GNorm = 0.7377, lr_0 = 1.0000e-04
Loss = 4.9628e-04, PNorm = 60.3430, GNorm = 1.1232, lr_0 = 1.0000e-04
Loss = 8.9108e-04, PNorm = 60.3444, GNorm = 3.0383, lr_0 = 1.0000e-04
Loss = 4.8497e-04, PNorm = 60.3462, GNorm = 1.4090, lr_0 = 1.0000e-04
Loss = 4.6656e-04, PNorm = 60.3485, GNorm = 1.4742, lr_0 = 1.0000e-04
Loss = 5.1241e-04, PNorm = 60.3502, GNorm = 0.9212, lr_0 = 1.0000e-04
Loss = 5.3003e-04, PNorm = 60.3518, GNorm = 1.3543, lr_0 = 1.0000e-04
Loss = 4.5448e-04, PNorm = 60.3529, GNorm = 1.5477, lr_0 = 1.0000e-04
Loss = 1.2391e-03, PNorm = 60.3545, GNorm = 3.8945, lr_0 = 1.0000e-04
Loss = 4.3246e-04, PNorm = 60.3562, GNorm = 0.9460, lr_0 = 1.0000e-04
Loss = 5.9689e-04, PNorm = 60.3573, GNorm = 1.2703, lr_0 = 1.0000e-04
Loss = 8.9212e-04, PNorm = 60.3589, GNorm = 1.0658, lr_0 = 1.0000e-04
Loss = 9.7469e-04, PNorm = 60.3608, GNorm = 1.5620, lr_0 = 1.0000e-04
Loss = 4.8323e-04, PNorm = 60.3612, GNorm = 1.0248, lr_0 = 1.0000e-04
Validation rmse = 4.261893
Validation R2 = -4.186511
Epoch 88
Train function
Loss = 2.6001e-03, PNorm = 60.3615, GNorm = 2.8310, lr_0 = 1.0000e-04
Loss = 4.0704e-04, PNorm = 60.3627, GNorm = 1.0089, lr_0 = 1.0000e-04
Loss = 5.0123e-04, PNorm = 60.3638, GNorm = 1.0242, lr_0 = 1.0000e-04
Loss = 5.4216e-04, PNorm = 60.3646, GNorm = 1.3204, lr_0 = 1.0000e-04
Loss = 7.5331e-04, PNorm = 60.3653, GNorm = 0.5418, lr_0 = 1.0000e-04
Loss = 3.5756e-04, PNorm = 60.3657, GNorm = 1.0359, lr_0 = 1.0000e-04
Loss = 3.6358e-04, PNorm = 60.3666, GNorm = 1.1124, lr_0 = 1.0000e-04
Loss = 6.3950e-04, PNorm = 60.3686, GNorm = 2.3446, lr_0 = 1.0000e-04
Loss = 5.5392e-04, PNorm = 60.3704, GNorm = 0.9847, lr_0 = 1.0000e-04
Loss = 6.8630e-04, PNorm = 60.3715, GNorm = 2.0197, lr_0 = 1.0000e-04
Loss = 5.5530e-04, PNorm = 60.3731, GNorm = 1.1099, lr_0 = 1.0000e-04
Loss = 5.9932e-04, PNorm = 60.3741, GNorm = 1.1985, lr_0 = 1.0000e-04
Loss = 4.5030e-04, PNorm = 60.3752, GNorm = 1.6357, lr_0 = 1.0000e-04
Loss = 4.5401e-04, PNorm = 60.3772, GNorm = 1.1364, lr_0 = 1.0000e-04
Loss = 8.4146e-04, PNorm = 60.3786, GNorm = 1.1308, lr_0 = 1.0000e-04
Loss = 3.3261e-04, PNorm = 60.3800, GNorm = 1.2300, lr_0 = 1.0000e-04
Loss = 5.7973e-04, PNorm = 60.3803, GNorm = 1.2082, lr_0 = 1.0000e-04
Loss = 6.3269e-04, PNorm = 60.3807, GNorm = 1.2924, lr_0 = 1.0000e-04
Loss = 5.2465e-04, PNorm = 60.3815, GNorm = 1.4366, lr_0 = 1.0000e-04
Loss = 6.0870e-04, PNorm = 60.3841, GNorm = 1.0317, lr_0 = 1.0000e-04
Loss = 4.2036e-04, PNorm = 60.3853, GNorm = 0.7994, lr_0 = 1.0000e-04
Loss = 1.3737e-03, PNorm = 60.3867, GNorm = 1.6995, lr_0 = 1.0000e-04
Loss = 5.0842e-04, PNorm = 60.3885, GNorm = 0.9921, lr_0 = 1.0000e-04
Loss = 8.1527e-04, PNorm = 60.3903, GNorm = 4.0808, lr_0 = 1.0000e-04
Validation rmse = 4.176926
Validation R2 = -3.981770
Epoch 89
Train function
Loss = 5.1731e-04, PNorm = 60.3918, GNorm = 1.8884, lr_0 = 1.0000e-04
Loss = 4.8899e-04, PNorm = 60.3934, GNorm = 1.5091, lr_0 = 1.0000e-04
Loss = 5.7160e-04, PNorm = 60.3943, GNorm = 1.6767, lr_0 = 1.0000e-04
Loss = 9.0028e-04, PNorm = 60.3953, GNorm = 3.6269, lr_0 = 1.0000e-04
Loss = 4.8983e-04, PNorm = 60.3962, GNorm = 0.7394, lr_0 = 1.0000e-04
Loss = 4.2133e-04, PNorm = 60.3977, GNorm = 1.0129, lr_0 = 1.0000e-04
Loss = 5.8811e-04, PNorm = 60.3991, GNorm = 0.8724, lr_0 = 1.0000e-04
Loss = 8.7988e-04, PNorm = 60.4009, GNorm = 0.7213, lr_0 = 1.0000e-04
Loss = 6.6458e-04, PNorm = 60.4029, GNorm = 0.7578, lr_0 = 1.0000e-04
Loss = 6.1851e-04, PNorm = 60.4037, GNorm = 2.6865, lr_0 = 1.0000e-04
Loss = 9.2219e-04, PNorm = 60.4057, GNorm = 1.1076, lr_0 = 1.0000e-04
Loss = 4.2844e-04, PNorm = 60.4073, GNorm = 0.8277, lr_0 = 1.0000e-04
Loss = 4.8585e-04, PNorm = 60.4079, GNorm = 1.2606, lr_0 = 1.0000e-04
Loss = 1.0795e-03, PNorm = 60.4079, GNorm = 1.2088, lr_0 = 1.0000e-04
Loss = 7.7899e-04, PNorm = 60.4086, GNorm = 2.8000, lr_0 = 1.0000e-04
Loss = 6.7281e-04, PNorm = 60.4105, GNorm = 1.0778, lr_0 = 1.0000e-04
Loss = 5.3717e-04, PNorm = 60.4115, GNorm = 0.9565, lr_0 = 1.0000e-04
Loss = 6.4353e-04, PNorm = 60.4121, GNorm = 0.8252, lr_0 = 1.0000e-04
Loss = 4.6452e-04, PNorm = 60.4137, GNorm = 1.1379, lr_0 = 1.0000e-04
Loss = 7.2801e-04, PNorm = 60.4150, GNorm = 1.1996, lr_0 = 1.0000e-04
Loss = 1.0494e-03, PNorm = 60.4166, GNorm = 1.1071, lr_0 = 1.0000e-04
Loss = 4.7650e-04, PNorm = 60.4186, GNorm = 0.8817, lr_0 = 1.0000e-04
Loss = 4.9560e-04, PNorm = 60.4200, GNorm = 1.2502, lr_0 = 1.0000e-04
Validation rmse = 4.169262
Validation R2 = -3.963506
Epoch 90
Train function
Loss = 3.5999e-04, PNorm = 60.4205, GNorm = 1.3495, lr_0 = 1.0000e-04
Loss = 3.4350e-04, PNorm = 60.4219, GNorm = 1.2203, lr_0 = 1.0000e-04
Loss = 3.3439e-04, PNorm = 60.4230, GNorm = 0.7697, lr_0 = 1.0000e-04
Loss = 4.7807e-04, PNorm = 60.4238, GNorm = 1.7899, lr_0 = 1.0000e-04
Loss = 4.9653e-04, PNorm = 60.4252, GNorm = 1.6068, lr_0 = 1.0000e-04
Loss = 3.8291e-04, PNorm = 60.4272, GNorm = 0.9278, lr_0 = 1.0000e-04
Loss = 5.8446e-04, PNorm = 60.4292, GNorm = 1.2396, lr_0 = 1.0000e-04
Loss = 8.9702e-04, PNorm = 60.4309, GNorm = 3.4737, lr_0 = 1.0000e-04
Loss = 4.9042e-04, PNorm = 60.4325, GNorm = 0.9240, lr_0 = 1.0000e-04
Loss = 3.8365e-04, PNorm = 60.4337, GNorm = 0.4489, lr_0 = 1.0000e-04
Loss = 1.1432e-03, PNorm = 60.4338, GNorm = 1.1468, lr_0 = 1.0000e-04
Loss = 4.6513e-04, PNorm = 60.4348, GNorm = 1.3492, lr_0 = 1.0000e-04
Loss = 4.8124e-04, PNorm = 60.4367, GNorm = 1.0553, lr_0 = 1.0000e-04
Loss = 6.2502e-04, PNorm = 60.4386, GNorm = 0.9038, lr_0 = 1.0000e-04
Loss = 7.2240e-04, PNorm = 60.4396, GNorm = 0.7208, lr_0 = 1.0000e-04
Loss = 5.8807e-04, PNorm = 60.4404, GNorm = 0.9690, lr_0 = 1.0000e-04
Loss = 5.3539e-04, PNorm = 60.4416, GNorm = 2.2229, lr_0 = 1.0000e-04
Loss = 3.5950e-04, PNorm = 60.4430, GNorm = 0.6311, lr_0 = 1.0000e-04
Loss = 6.3049e-04, PNorm = 60.4446, GNorm = 3.4579, lr_0 = 1.0000e-04
Loss = 1.0824e-03, PNorm = 60.4451, GNorm = 1.1931, lr_0 = 1.0000e-04
Loss = 6.2699e-04, PNorm = 60.4462, GNorm = 0.9546, lr_0 = 1.0000e-04
Loss = 7.5459e-04, PNorm = 60.4473, GNorm = 1.0303, lr_0 = 1.0000e-04
Loss = 7.0784e-04, PNorm = 60.4491, GNorm = 1.2140, lr_0 = 1.0000e-04
Loss = 4.4521e-04, PNorm = 60.4510, GNorm = 1.2155, lr_0 = 1.0000e-04
Validation rmse = 4.355506
Validation R2 = -4.416857
Epoch 91
Train function
Loss = 4.5206e-04, PNorm = 60.4523, GNorm = 1.2887, lr_0 = 1.0000e-04
Loss = 1.0254e-03, PNorm = 60.4525, GNorm = 1.3962, lr_0 = 1.0000e-04
Loss = 4.3092e-04, PNorm = 60.4537, GNorm = 1.1645, lr_0 = 1.0000e-04
Loss = 5.8518e-04, PNorm = 60.4555, GNorm = 1.1764, lr_0 = 1.0000e-04
Loss = 3.3132e-04, PNorm = 60.4567, GNorm = 1.1453, lr_0 = 1.0000e-04
Loss = 6.1190e-04, PNorm = 60.4579, GNorm = 1.4742, lr_0 = 1.0000e-04
Loss = 1.0363e-03, PNorm = 60.4596, GNorm = 2.9647, lr_0 = 1.0000e-04
Loss = 5.3653e-04, PNorm = 60.4620, GNorm = 1.0340, lr_0 = 1.0000e-04
Loss = 5.6468e-04, PNorm = 60.4626, GNorm = 2.0698, lr_0 = 1.0000e-04
Loss = 2.2821e-04, PNorm = 60.4629, GNorm = 1.0164, lr_0 = 1.0000e-04
Loss = 6.0227e-04, PNorm = 60.4642, GNorm = 1.4255, lr_0 = 1.0000e-04
Loss = 4.9126e-04, PNorm = 60.4663, GNorm = 2.6386, lr_0 = 1.0000e-04
Loss = 5.2222e-04, PNorm = 60.4676, GNorm = 3.1264, lr_0 = 1.0000e-04
Loss = 6.2592e-04, PNorm = 60.4692, GNorm = 1.1903, lr_0 = 1.0000e-04
Loss = 7.7456e-04, PNorm = 60.4705, GNorm = 3.2898, lr_0 = 1.0000e-04
Loss = 6.5993e-04, PNorm = 60.4717, GNorm = 2.2312, lr_0 = 1.0000e-04
Loss = 3.1576e-04, PNorm = 60.4731, GNorm = 1.3095, lr_0 = 1.0000e-04
Loss = 5.7856e-04, PNorm = 60.4736, GNorm = 0.8712, lr_0 = 1.0000e-04
Loss = 4.1780e-04, PNorm = 60.4745, GNorm = 1.2207, lr_0 = 1.0000e-04
Loss = 7.2579e-04, PNorm = 60.4758, GNorm = 1.3256, lr_0 = 1.0000e-04
Loss = 3.7303e-04, PNorm = 60.4776, GNorm = 0.7363, lr_0 = 1.0000e-04
Loss = 5.8578e-04, PNorm = 60.4791, GNorm = 1.5105, lr_0 = 1.0000e-04
Loss = 7.5480e-04, PNorm = 60.4800, GNorm = 1.0915, lr_0 = 1.0000e-04
Validation rmse = 4.230092
Validation R2 = -4.109398
Epoch 92
Train function
Loss = 3.1362e-04, PNorm = 60.4816, GNorm = 1.0077, lr_0 = 1.0000e-04
Loss = 3.1159e-04, PNorm = 60.4823, GNorm = 1.1610, lr_0 = 1.0000e-04
Loss = 3.3208e-04, PNorm = 60.4839, GNorm = 0.5510, lr_0 = 1.0000e-04
Loss = 3.8229e-04, PNorm = 60.4854, GNorm = 2.0158, lr_0 = 1.0000e-04
Loss = 3.5479e-04, PNorm = 60.4869, GNorm = 0.8518, lr_0 = 1.0000e-04
Loss = 4.7194e-04, PNorm = 60.4880, GNorm = 1.3964, lr_0 = 1.0000e-04
Loss = 7.7592e-04, PNorm = 60.4896, GNorm = 2.3504, lr_0 = 1.0000e-04
Loss = 6.8805e-04, PNorm = 60.4913, GNorm = 2.3735, lr_0 = 1.0000e-04
Loss = 4.1303e-04, PNorm = 60.4926, GNorm = 1.4273, lr_0 = 1.0000e-04
Loss = 4.1558e-04, PNorm = 60.4939, GNorm = 0.8010, lr_0 = 1.0000e-04
Loss = 5.0626e-04, PNorm = 60.4946, GNorm = 1.9724, lr_0 = 1.0000e-04
Loss = 4.2788e-04, PNorm = 60.4954, GNorm = 1.3272, lr_0 = 1.0000e-04
Loss = 6.3337e-04, PNorm = 60.4971, GNorm = 1.2320, lr_0 = 1.0000e-04
Loss = 4.7944e-04, PNorm = 60.4976, GNorm = 1.2049, lr_0 = 1.0000e-04
Loss = 6.7963e-04, PNorm = 60.4985, GNorm = 0.9714, lr_0 = 1.0000e-04
Loss = 5.0929e-04, PNorm = 60.5004, GNorm = 1.4207, lr_0 = 1.0000e-04
Loss = 9.9151e-04, PNorm = 60.5016, GNorm = 0.9062, lr_0 = 1.0000e-04
Loss = 5.6521e-04, PNorm = 60.5021, GNorm = 1.0453, lr_0 = 1.0000e-04
Loss = 7.2839e-04, PNorm = 60.5042, GNorm = 1.9475, lr_0 = 1.0000e-04
Loss = 5.9905e-04, PNorm = 60.5064, GNorm = 1.3631, lr_0 = 1.0000e-04
Loss = 5.2788e-04, PNorm = 60.5081, GNorm = 0.8714, lr_0 = 1.0000e-04
Loss = 8.6785e-04, PNorm = 60.5095, GNorm = 1.4527, lr_0 = 1.0000e-04
Loss = 1.0211e-03, PNorm = 60.5105, GNorm = 4.9015, lr_0 = 1.0000e-04
Loss = 4.1883e-04, PNorm = 60.5116, GNorm = 2.0734, lr_0 = 1.0000e-04
Loss = 3.7047e-04, PNorm = 60.5118, GNorm = 1.1984, lr_0 = 1.0000e-04
Validation rmse = 4.227539
Validation R2 = -4.103234
Epoch 93
Train function
Loss = 3.8268e-04, PNorm = 60.5139, GNorm = 0.7934, lr_0 = 1.0000e-04
Loss = 3.8586e-04, PNorm = 60.5152, GNorm = 0.9551, lr_0 = 1.0000e-04
Loss = 5.4820e-04, PNorm = 60.5170, GNorm = 0.9528, lr_0 = 1.0000e-04
Loss = 3.4295e-04, PNorm = 60.5185, GNorm = 0.9717, lr_0 = 1.0000e-04
Loss = 8.4251e-04, PNorm = 60.5193, GNorm = 1.1770, lr_0 = 1.0000e-04
Loss = 9.0163e-04, PNorm = 60.5207, GNorm = 2.6890, lr_0 = 1.0000e-04
Loss = 7.8170e-04, PNorm = 60.5229, GNorm = 1.3363, lr_0 = 1.0000e-04
Loss = 3.6113e-04, PNorm = 60.5248, GNorm = 1.4695, lr_0 = 1.0000e-04
Loss = 4.0399e-04, PNorm = 60.5258, GNorm = 1.0725, lr_0 = 1.0000e-04
Loss = 5.5023e-04, PNorm = 60.5262, GNorm = 1.6942, lr_0 = 1.0000e-04
Loss = 3.6169e-04, PNorm = 60.5282, GNorm = 0.9145, lr_0 = 1.0000e-04
Loss = 5.0579e-04, PNorm = 60.5294, GNorm = 1.4632, lr_0 = 1.0000e-04
Loss = 6.1642e-04, PNorm = 60.5302, GNorm = 1.3880, lr_0 = 1.0000e-04
Loss = 4.5426e-04, PNorm = 60.5314, GNorm = 1.3992, lr_0 = 1.0000e-04
Loss = 1.2825e-03, PNorm = 60.5324, GNorm = 1.0305, lr_0 = 1.0000e-04
Loss = 5.2066e-04, PNorm = 60.5332, GNorm = 1.3181, lr_0 = 1.0000e-04
Loss = 8.3013e-04, PNorm = 60.5345, GNorm = 4.0497, lr_0 = 1.0000e-04
Loss = 4.5758e-04, PNorm = 60.5356, GNorm = 1.5645, lr_0 = 1.0000e-04
Loss = 5.0094e-04, PNorm = 60.5370, GNorm = 1.1081, lr_0 = 1.0000e-04
Loss = 3.6355e-04, PNorm = 60.5373, GNorm = 1.0691, lr_0 = 1.0000e-04
Loss = 4.3905e-04, PNorm = 60.5385, GNorm = 0.8808, lr_0 = 1.0000e-04
Loss = 4.7661e-04, PNorm = 60.5404, GNorm = 1.4823, lr_0 = 1.0000e-04
Loss = 3.2467e-04, PNorm = 60.5411, GNorm = 0.7749, lr_0 = 1.0000e-04
Validation rmse = 4.248651
Validation R2 = -4.154330
Epoch 94
Train function
Loss = 3.2241e-04, PNorm = 60.5423, GNorm = 0.8450, lr_0 = 1.0000e-04
Loss = 5.0379e-04, PNorm = 60.5433, GNorm = 1.0466, lr_0 = 1.0000e-04
Loss = 7.0273e-04, PNorm = 60.5446, GNorm = 1.7793, lr_0 = 1.0000e-04
Loss = 7.4960e-04, PNorm = 60.5460, GNorm = 1.0477, lr_0 = 1.0000e-04
Loss = 4.4204e-04, PNorm = 60.5471, GNorm = 1.6181, lr_0 = 1.0000e-04
Loss = 6.0394e-04, PNorm = 60.5481, GNorm = 1.1906, lr_0 = 1.0000e-04
Loss = 4.7256e-04, PNorm = 60.5500, GNorm = 2.6816, lr_0 = 1.0000e-04
Loss = 5.2281e-04, PNorm = 60.5520, GNorm = 2.6576, lr_0 = 1.0000e-04
Loss = 5.4083e-04, PNorm = 60.5540, GNorm = 1.4748, lr_0 = 1.0000e-04
Loss = 3.3676e-04, PNorm = 60.5548, GNorm = 1.0570, lr_0 = 1.0000e-04
Loss = 4.1276e-04, PNorm = 60.5560, GNorm = 1.5807, lr_0 = 1.0000e-04
Loss = 4.8082e-04, PNorm = 60.5574, GNorm = 1.1777, lr_0 = 1.0000e-04
Loss = 3.9548e-04, PNorm = 60.5581, GNorm = 1.5957, lr_0 = 1.0000e-04
Loss = 5.1820e-04, PNorm = 60.5588, GNorm = 1.7819, lr_0 = 1.0000e-04
Loss = 7.1993e-04, PNorm = 60.5594, GNorm = 2.9980, lr_0 = 1.0000e-04
Loss = 4.4930e-04, PNorm = 60.5592, GNorm = 0.9071, lr_0 = 1.0000e-04
Loss = 3.1708e-04, PNorm = 60.5595, GNorm = 1.6022, lr_0 = 1.0000e-04
Loss = 8.3968e-04, PNorm = 60.5605, GNorm = 0.7124, lr_0 = 1.0000e-04
Loss = 5.8741e-04, PNorm = 60.5617, GNorm = 1.0998, lr_0 = 1.0000e-04
Loss = 3.9077e-04, PNorm = 60.5629, GNorm = 1.0977, lr_0 = 1.0000e-04
Loss = 5.2862e-04, PNorm = 60.5645, GNorm = 1.0289, lr_0 = 1.0000e-04
Loss = 7.2027e-04, PNorm = 60.5667, GNorm = 1.0316, lr_0 = 1.0000e-04
Loss = 4.2600e-04, PNorm = 60.5678, GNorm = 0.9729, lr_0 = 1.0000e-04
Validation rmse = 4.125024
Validation R2 = -3.858733
Epoch 95
Train function
Loss = 2.3103e-04, PNorm = 60.5686, GNorm = 0.8672, lr_0 = 1.0000e-04
Loss = 5.5694e-04, PNorm = 60.5695, GNorm = 0.8234, lr_0 = 1.0000e-04
Loss = 4.8913e-04, PNorm = 60.5711, GNorm = 1.9353, lr_0 = 1.0000e-04
Loss = 4.2613e-04, PNorm = 60.5722, GNorm = 0.7956, lr_0 = 1.0000e-04
Loss = 5.8124e-04, PNorm = 60.5736, GNorm = 1.2298, lr_0 = 1.0000e-04
Loss = 3.6883e-04, PNorm = 60.5744, GNorm = 1.0445, lr_0 = 1.0000e-04
Loss = 6.9574e-04, PNorm = 60.5758, GNorm = 1.3466, lr_0 = 1.0000e-04
Loss = 6.4084e-04, PNorm = 60.5775, GNorm = 2.1631, lr_0 = 1.0000e-04
Loss = 1.3451e-03, PNorm = 60.5789, GNorm = 2.3096, lr_0 = 1.0000e-04
Loss = 6.8558e-04, PNorm = 60.5801, GNorm = 2.1540, lr_0 = 1.0000e-04
Loss = 4.8568e-04, PNorm = 60.5815, GNorm = 1.7411, lr_0 = 1.0000e-04
Loss = 5.9363e-04, PNorm = 60.5825, GNorm = 1.7819, lr_0 = 1.0000e-04
Loss = 3.7525e-04, PNorm = 60.5832, GNorm = 0.8229, lr_0 = 1.0000e-04
Loss = 4.5656e-04, PNorm = 60.5845, GNorm = 0.8505, lr_0 = 1.0000e-04
Loss = 8.3455e-04, PNorm = 60.5856, GNorm = 0.7887, lr_0 = 1.0000e-04
Loss = 3.8287e-04, PNorm = 60.5872, GNorm = 0.8520, lr_0 = 1.0000e-04
Loss = 3.4749e-04, PNorm = 60.5883, GNorm = 1.1925, lr_0 = 1.0000e-04
Loss = 7.0888e-04, PNorm = 60.5896, GNorm = 1.2584, lr_0 = 1.0000e-04
Loss = 8.8837e-04, PNorm = 60.5900, GNorm = 1.4252, lr_0 = 1.0000e-04
Loss = 3.7374e-04, PNorm = 60.5910, GNorm = 1.0768, lr_0 = 1.0000e-04
Loss = 4.1820e-04, PNorm = 60.5927, GNorm = 1.1093, lr_0 = 1.0000e-04
Loss = 3.8263e-04, PNorm = 60.5944, GNorm = 0.9056, lr_0 = 1.0000e-04
Loss = 4.0583e-04, PNorm = 60.5958, GNorm = 1.1364, lr_0 = 1.0000e-04
Loss = 4.4965e-04, PNorm = 60.5973, GNorm = 1.3423, lr_0 = 1.0000e-04
Validation rmse = 4.141642
Validation R2 = -3.897961
Epoch 96
Train function
Loss = 2.4853e-04, PNorm = 60.5990, GNorm = 0.8123, lr_0 = 1.0000e-04
Loss = 3.9031e-04, PNorm = 60.6000, GNorm = 0.8533, lr_0 = 1.0000e-04
Loss = 4.3790e-04, PNorm = 60.6013, GNorm = 1.9334, lr_0 = 1.0000e-04
Loss = 3.3273e-04, PNorm = 60.6019, GNorm = 0.6949, lr_0 = 1.0000e-04
Loss = 6.2746e-04, PNorm = 60.6031, GNorm = 1.3267, lr_0 = 1.0000e-04
Loss = 8.6260e-04, PNorm = 60.6049, GNorm = 0.7321, lr_0 = 1.0000e-04
Loss = 4.1406e-04, PNorm = 60.6064, GNorm = 1.1470, lr_0 = 1.0000e-04
Loss = 4.5407e-04, PNorm = 60.6074, GNorm = 1.5745, lr_0 = 1.0000e-04
Loss = 6.3596e-04, PNorm = 60.6085, GNorm = 2.0993, lr_0 = 1.0000e-04
Loss = 3.1940e-04, PNorm = 60.6095, GNorm = 1.4811, lr_0 = 1.0000e-04
Loss = 6.0175e-04, PNorm = 60.6104, GNorm = 0.8749, lr_0 = 1.0000e-04
Loss = 3.7429e-04, PNorm = 60.6114, GNorm = 1.0990, lr_0 = 1.0000e-04
Loss = 8.1235e-04, PNorm = 60.6137, GNorm = 0.7208, lr_0 = 1.0000e-04
Loss = 3.8296e-04, PNorm = 60.6151, GNorm = 1.2087, lr_0 = 1.0000e-04
Loss = 3.6279e-04, PNorm = 60.6157, GNorm = 1.2578, lr_0 = 1.0000e-04
Loss = 6.6085e-04, PNorm = 60.6173, GNorm = 0.9706, lr_0 = 1.0000e-04
Loss = 6.1098e-04, PNorm = 60.6195, GNorm = 0.9769, lr_0 = 1.0000e-04
Loss = 3.5872e-04, PNorm = 60.6209, GNorm = 1.3449, lr_0 = 1.0000e-04
Loss = 3.9905e-04, PNorm = 60.6221, GNorm = 1.1907, lr_0 = 1.0000e-04
Loss = 1.0519e-03, PNorm = 60.6225, GNorm = 1.1632, lr_0 = 1.0000e-04
Loss = 5.3479e-04, PNorm = 60.6229, GNorm = 1.5222, lr_0 = 1.0000e-04
Loss = 6.7749e-04, PNorm = 60.6236, GNorm = 1.5096, lr_0 = 1.0000e-04
Loss = 3.4628e-04, PNorm = 60.6242, GNorm = 0.9251, lr_0 = 1.0000e-04
Validation rmse = 4.163415
Validation R2 = -3.949595
Epoch 97
Train function
Loss = 7.1842e-04, PNorm = 60.6259, GNorm = 0.5576, lr_0 = 1.0000e-04
Loss = 4.7276e-04, PNorm = 60.6277, GNorm = 0.7411, lr_0 = 1.0000e-04
Loss = 3.5977e-04, PNorm = 60.6284, GNorm = 1.1545, lr_0 = 1.0000e-04
Loss = 4.3578e-04, PNorm = 60.6295, GNorm = 1.3910, lr_0 = 1.0000e-04
Loss = 8.4020e-04, PNorm = 60.6305, GNorm = 0.6886, lr_0 = 1.0000e-04
Loss = 3.8918e-04, PNorm = 60.6309, GNorm = 1.6735, lr_0 = 1.0000e-04
Loss = 5.6134e-04, PNorm = 60.6315, GNorm = 1.2858, lr_0 = 1.0000e-04
Loss = 5.1720e-04, PNorm = 60.6332, GNorm = 0.9572, lr_0 = 1.0000e-04
Loss = 5.4366e-04, PNorm = 60.6349, GNorm = 1.3692, lr_0 = 1.0000e-04
Loss = 3.5144e-04, PNorm = 60.6357, GNorm = 1.3337, lr_0 = 1.0000e-04
Loss = 5.8011e-04, PNorm = 60.6369, GNorm = 1.8075, lr_0 = 1.0000e-04
Loss = 9.9012e-04, PNorm = 60.6378, GNorm = 1.8773, lr_0 = 1.0000e-04
Loss = 4.1208e-04, PNorm = 60.6390, GNorm = 1.9550, lr_0 = 1.0000e-04
Loss = 5.5383e-04, PNorm = 60.6405, GNorm = 1.9897, lr_0 = 1.0000e-04
Loss = 1.1431e-03, PNorm = 60.6413, GNorm = 1.6903, lr_0 = 1.0000e-04
Loss = 4.6730e-04, PNorm = 60.6427, GNorm = 1.2900, lr_0 = 1.0000e-04
Loss = 4.3626e-04, PNorm = 60.6440, GNorm = 0.9159, lr_0 = 1.0000e-04
Loss = 4.5421e-04, PNorm = 60.6446, GNorm = 1.4456, lr_0 = 1.0000e-04
Loss = 3.4337e-04, PNorm = 60.6460, GNorm = 1.2852, lr_0 = 1.0000e-04
Loss = 5.0656e-04, PNorm = 60.6477, GNorm = 1.4194, lr_0 = 1.0000e-04
Loss = 3.8414e-04, PNorm = 60.6493, GNorm = 1.2646, lr_0 = 1.0000e-04
Loss = 4.1405e-04, PNorm = 60.6509, GNorm = 1.2425, lr_0 = 1.0000e-04
Loss = 5.8952e-04, PNorm = 60.6529, GNorm = 1.5361, lr_0 = 1.0000e-04
Loss = 6.6355e-04, PNorm = 60.6542, GNorm = 0.9893, lr_0 = 1.0000e-04
Validation rmse = 4.216572
Validation R2 = -4.076789
Epoch 98
Train function
Loss = 5.2478e-04, PNorm = 60.6554, GNorm = 1.8181, lr_0 = 1.0000e-04
Loss = 8.2273e-04, PNorm = 60.6561, GNorm = 1.2367, lr_0 = 1.0000e-04
Loss = 7.5922e-04, PNorm = 60.6568, GNorm = 1.2818, lr_0 = 1.0000e-04
Loss = 7.6242e-04, PNorm = 60.6580, GNorm = 2.3495, lr_0 = 1.0000e-04
Loss = 6.3391e-04, PNorm = 60.6596, GNorm = 1.2533, lr_0 = 1.0000e-04
Loss = 3.6071e-04, PNorm = 60.6606, GNorm = 1.0800, lr_0 = 1.0000e-04
Loss = 5.1186e-04, PNorm = 60.6616, GNorm = 1.0453, lr_0 = 1.0000e-04
Loss = 3.8435e-04, PNorm = 60.6622, GNorm = 0.6849, lr_0 = 1.0000e-04
Loss = 7.8306e-04, PNorm = 60.6626, GNorm = 2.9955, lr_0 = 1.0000e-04
Loss = 5.5730e-04, PNorm = 60.6636, GNorm = 1.8943, lr_0 = 1.0000e-04
Loss = 5.2764e-04, PNorm = 60.6650, GNorm = 0.8887, lr_0 = 1.0000e-04
Loss = 4.7625e-04, PNorm = 60.6663, GNorm = 1.1919, lr_0 = 1.0000e-04
Loss = 4.7305e-04, PNorm = 60.6684, GNorm = 1.7627, lr_0 = 1.0000e-04
Loss = 9.4123e-04, PNorm = 60.6690, GNorm = 1.2079, lr_0 = 1.0000e-04
Loss = 7.6258e-04, PNorm = 60.6703, GNorm = 1.2204, lr_0 = 1.0000e-04
Loss = 2.7083e-04, PNorm = 60.6712, GNorm = 0.6601, lr_0 = 1.0000e-04
Loss = 3.6771e-04, PNorm = 60.6719, GNorm = 0.6192, lr_0 = 1.0000e-04
Loss = 3.5696e-04, PNorm = 60.6735, GNorm = 1.2596, lr_0 = 1.0000e-04
Loss = 5.6339e-04, PNorm = 60.6746, GNorm = 0.8312, lr_0 = 1.0000e-04
Loss = 4.5749e-04, PNorm = 60.6755, GNorm = 0.8128, lr_0 = 1.0000e-04
Loss = 4.6622e-04, PNorm = 60.6761, GNorm = 0.9403, lr_0 = 1.0000e-04
Loss = 5.5328e-04, PNorm = 60.6786, GNorm = 3.0716, lr_0 = 1.0000e-04
Loss = 6.8408e-04, PNorm = 60.6802, GNorm = 1.2487, lr_0 = 1.0000e-04
Validation rmse = 4.265957
Validation R2 = -4.196407
Epoch 99
Train function
Loss = 6.4345e-04, PNorm = 60.6815, GNorm = 1.0117, lr_0 = 1.0000e-04
Loss = 5.2337e-04, PNorm = 60.6822, GNorm = 1.3539, lr_0 = 1.0000e-04
Loss = 3.1791e-04, PNorm = 60.6836, GNorm = 0.6447, lr_0 = 1.0000e-04
Loss = 3.1302e-04, PNorm = 60.6853, GNorm = 0.6525, lr_0 = 1.0000e-04
Loss = 3.4885e-04, PNorm = 60.6858, GNorm = 1.0370, lr_0 = 1.0000e-04
Loss = 3.6728e-04, PNorm = 60.6867, GNorm = 0.9002, lr_0 = 1.0000e-04
Loss = 4.8006e-04, PNorm = 60.6874, GNorm = 2.0333, lr_0 = 1.0000e-04
Loss = 3.7725e-04, PNorm = 60.6880, GNorm = 0.9124, lr_0 = 1.0000e-04
Loss = 3.8926e-04, PNorm = 60.6896, GNorm = 1.5025, lr_0 = 1.0000e-04
Loss = 8.5270e-04, PNorm = 60.6906, GNorm = 1.1124, lr_0 = 1.0000e-04
Loss = 6.0526e-04, PNorm = 60.6928, GNorm = 0.7077, lr_0 = 1.0000e-04
Loss = 8.5365e-04, PNorm = 60.6934, GNorm = 1.4839, lr_0 = 1.0000e-04
Loss = 3.9300e-04, PNorm = 60.6949, GNorm = 1.7323, lr_0 = 1.0000e-04
Loss = 8.5533e-04, PNorm = 60.6967, GNorm = 1.6567, lr_0 = 1.0000e-04
Loss = 7.4132e-04, PNorm = 60.6978, GNorm = 1.8582, lr_0 = 1.0000e-04
Loss = 3.7811e-04, PNorm = 60.6992, GNorm = 1.0654, lr_0 = 1.0000e-04
Loss = 3.6991e-04, PNorm = 60.7006, GNorm = 1.1833, lr_0 = 1.0000e-04
Loss = 7.3589e-04, PNorm = 60.7018, GNorm = 0.7535, lr_0 = 1.0000e-04
Loss = 4.0579e-04, PNorm = 60.7030, GNorm = 1.8751, lr_0 = 1.0000e-04
Loss = 5.0685e-04, PNorm = 60.7046, GNorm = 1.2643, lr_0 = 1.0000e-04
Loss = 4.2985e-04, PNorm = 60.7053, GNorm = 1.7770, lr_0 = 1.0000e-04
Loss = 5.5727e-04, PNorm = 60.7060, GNorm = 0.9177, lr_0 = 1.0000e-04
Loss = 5.3046e-04, PNorm = 60.7074, GNorm = 0.8795, lr_0 = 1.0000e-04
Loss = 7.6724e-04, PNorm = 60.7078, GNorm = 1.9783, lr_0 = 1.0000e-04
Validation rmse = 4.130709
Validation R2 = -3.872136
Model 0 best validation rmse = 0.977841 on epoch 2
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.959208
Model 0 test R2 = 0.726783
Ensemble test rmse = 0.959208
Ensemble test R2 = 0.726783
4-fold cross validation
	Seed 0 ==> test rmse = 1.082751
	Seed 0 ==> test R2 = 0.651871
	Seed 1 ==> test rmse = 1.040931
	Seed 1 ==> test R2 = 0.678244
	Seed 2 ==> test rmse = 0.972844
	Seed 2 ==> test R2 = 0.718960
	Seed 3 ==> test rmse = 0.959208
	Seed 3 ==> test R2 = 0.726783
Overall test rmse = 1.013933 +/- 0.050369
Overall test R2 = 0.693964 +/- 0.030499
Elapsed time = 8:39:24
Fold 0
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
[[4.32], [4.46], [4.3], [3.78], [2.31], [3.12], [1.34], [2.85], [4.91], [3.32], [2.46], [0.95], [6.75], [4.6], [4.52], [1.76], [1.91], [3.89], [0.96], [2.4], [0.35], [2.08], [0.93], [0.77], [2.59], [6.37], [-1.85], [-2.84], [2.71], [1.95], [2.54], [3.17], [5.2], [-1.5], [6.98], [1.29], [0.74], [-1.17], [7.66], [0.66], [-0.04], [6.63], [-0.7], [5.24], [1.84], [-0.85], [3.29], [-0.25], [2.21], [2.75], [0.91], [3.6], [4.75], [0.78], [1.24], [4.31], [1.8], [1.13], [0.83], [0.71], [4.44], [-1.16], [1.43], [1.34], [0.41], [-0.42], [-0.04], [2.45], [2.89], [3.31], [0.51], [3.62], [2.73], [0.82], [1.33], [1.43], [0.65], [-0.8], [1.29], [2.45], [0.89], [1.9], [2.1], [6.53], [3.34], [0.66], [3.8], [2.68], [-1.0], [2.9], [1.6], [1.68], [6.31], [1.04], [1.8], [4.19], [0.28], [4.1], [-0.72], [0.6], [4.02], [3.65], [0.18], [0.73], [-0.71], [3.26], [0.1], [0.9], [0.79], [3.78], [1.12], [2.24], [0.52], [-1.34], [0.85], [0.33], [-1.11], [0.93], [0.76], [4.61], [2.59], [2.31], [0.65], [3.0], [5.2], [1.61], [3.35], [1.04], [3.75], [2.6], [6.28], [0.75], [1.84], [0.93], [2.73], [-1.33], [1.98], [7.05], [-0.4], [6.22], [-0.44], [2.01], [0.17], [-0.7], [3.55], [-0.24], [0.17], [1.56], [1.39], [3.93], [-0.11], [3.4], [3.37], [1.83], [4.14], [1.17], [2.01], [0.9], [6.8], [-0.87], [3.58], [1.05], [1.73], [4.45], [0.9], [2.79], [0.02], [2.16], [0.31], [1.03], [1.24], [1.23], [3.12], [5.2], [3.51], [1.5], [1.85], [1.34], [5.52], [2.35], [0.61], [3.6], [1.77], [3.39], [-0.66], [3.9], [1.64], [3.14], [0.33], [2.54], [7.53], [5.15], [2.9], [3.72], [2.48], [0.7], [2.09], [3.08], [0.46], [0.83], [1.6], [3.16], [1.55], [3.67], [0.95], [1.54], [5.78], [-0.15], [3.2], [1.24], [1.28], [-0.52], [2.84], [1.57], [4.16], [1.96], [2.04], [2.22], [3.41], [2.4], [2.7], [0.72], [4.42], [4.37], [2.82], [1.18], [2.79], [3.17], [-0.63], [1.15], [0.0], [1.64], [4.28], [1.2], [2.19], [2.52], [2.23], [2.11], [4.0], [4.64], [4.62], [4.94], [2.03], [0.57], [5.92], [3.45], [1.93], [0.53], [2.46], [-0.6], [3.53], [3.02], [1.58], [5.7], [1.69], [2.28], [2.24], [2.18], [3.15], [0.54], [2.22], [-2.05], [3.83], [3.93], [-0.68], [4.47], [1.09], [3.9], [-0.34], [1.69], [5.23], [1.3], [1.82], [-1.03], [2.78], [3.32], [3.65], [4.76], [-2.98], [4.02], [1.78], [1.85], [2.17], [4.8], [2.85], [-0.88], [6.15], [1.51], [2.65], [2.49], [-0.11], [2.64], [2.64], [1.59], [7.55], [4.58], [2.59], [2.59], [-0.41], [0.49], [2.91], [2.18], [2.08], [0.89], [2.52], [2.16], [4.48], [4.85], [1.94], [3.21], [2.8], [-2.46], [2.06], [-0.37], [2.14], [0.08], [1.13], [-0.74], [6.17], [3.31], [2.11], [7.64], [2.43], [0.51], [4.5], [0.83], [3.15], [5.7], [0.56], [0.31], [4.05], [-0.54], [4.06], [1.73], [0.97], [2.44], [3.8], [2.74], [1.22], [2.21], [0.95], [3.41], [0.51], [2.45], [0.42], [-0.88], [3.61], [2.15], [0.56], [2.88], [5.35], [1.6], [0.58], [4.33], [3.06], [1.64], [1.15], [2.2], [1.85], [0.92], [3.03], [-1.98], [-0.22], [1.89], [0.83], [-0.17], [3.22], [1.49], [0.54], [1.74], [-2.67], [-0.07], [2.68], [2.19], [2.16], [4.82], [1.76], [4.16], [1.63], [7.2], [-0.58], [2.72], [4.44], [1.58], [1.94], [2.18], [2.72], [1.59], [4.6], [2.52], [1.91], [3.72], [3.29], [6.38], [1.55], [2.11], [4.25], [2.1], [2.6], [-3.24], [1.34], [1.58], [1.88], [4.8], [-0.13], [1.53], [0.29], [1.4], [3.8], [-0.68], [2.86], [1.33], [0.06], [-1.02], [1.93], [4.3], [4.34], [0.14], [0.62], [-0.2], [3.64], [1.19], [2.69], [4.02], [5.25], [3.87], [3.28], [3.95], [3.16], [1.82], [2.11], [1.98], [3.48], [2.75], [2.42], [0.66], [3.38], [0.41], [0.57], [3.72], [-2.33], [0.2], [5.0], [2.42], [4.68], [1.97], [3.5], [1.53], [2.26], [3.69], [1.9], [8.5], [1.65], [2.08], [1.7], [-0.31], [2.12], [2.44], [1.5], [1.18], [1.97], [4.47], [2.15], [3.29], [-0.6], [3.49], [0.39], [4.8], [1.0], [2.27], [1.4], [1.48], [1.31], [4.76], [0.2], [3.48], [3.63], [-1.0], [1.85], [3.35], [2.23], [1.92], [3.43], [0.23], [1.16], [0.86], [3.8], [-1.0], [1.47], [3.14], [0.78], [4.08], [-0.31], [2.47], [2.9], [3.48], [-3.07], [1.71], [4.3], [2.91], [2.67], [2.16], [3.92], [4.64], [-0.07], [-0.26], [2.81], [-0.06], [-0.63], [3.08], [2.11], [0.65], [-0.28], [4.31], [3.61], [1.46], [2.41], [3.54], [3.01], [0.5], [1.1], [0.21], [2.05], [5.85], [2.02], [3.9], [2.53], [0.5], [4.34], [1.0], [-0.24], [0.49], [2.09], [1.09], [4.8], [2.74], [3.7], [1.89], [2.19], [1.77], [1.09], [0.82], [-0.05], [-0.28], [-0.66], [2.35], [3.85], [2.1], [2.13], [-0.76], [2.75], [0.98], [3.89], [5.59], [1.16], [1.45], [6.58], [0.0], [1.74], [0.34], [2.29], [6.25], [5.95], [1.3], [1.02], [3.5], [3.52], [1.24], [2.4], [0.47], [1.89], [-1.43], [1.3], [0.91], [1.66], [-0.38], [3.15], [2.92], [5.16], [2.26], [4.1], [4.8], [2.82], [1.81], [3.55], [-1.55], [2.62], [4.25], [3.06], [1.24], [5.01], [-0.03], [2.01], [8.46], [3.82], [2.47], [1.14], [-0.13], [2.68], [4.59], [1.99], [2.49], [3.88], [-3.21], [3.07], [-0.05], [3.69], [0.51], [1.88], [1.78], [0.39], [2.02], [2.7], [3.96], [1.97], [0.75], [1.89], [2.98], [2.05], [2.46], [2.62], [2.16], [0.84], [2.81], [0.6], [1.26], [5.5], [3.0], [3.6], [2.67], [3.43], [-0.12], [-0.49], [1.8], [0.2], [1.8], [1.2], [5.08], [2.78], [4.85], [1.39], [1.39], [1.19], [-0.6], [3.97], [1.32], [3.52], [-0.09], [3.91], [1.31], [0.99], [1.42], [2.92], [1.05], [1.87], [0.33], [0.99], [2.84], [1.69], [4.25], [4.27], [0.17], [4.44], [1.22], [-0.31], [1.87], [5.21], [1.6], [1.47], [3.4], [2.2], [2.53], [2.13], [1.99], [3.5], [1.62], [2.01], [-0.25], [-0.36], [2.68], [4.51], [2.2], [5.46], [1.36], [-2.05], [3.34], [3.35], [5.07], [1.01], [5.72], [2.59], [1.86], [-0.66], [1.84], [0.6], [0.38], [1.81], [1.59], [0.67], [5.47], [1.14], [3.93], [0.73], [1.06], [-1.88], [2.53], [4.7], [1.63], [4.6], [1.8], [1.43], [0.77], [2.86], [2.78], [2.63], [5.78], [3.89], [1.06], [3.26], [4.17], [4.51], [0.28], [4.32], [2.21], [1.82], [3.09], [1.09], [0.38], [1.58], [2.3], [0.56], [3.6], [3.63], [4.79], [1.18], [2.18], [0.6], [3.62], [2.7], [3.26], [1.51], [1.42], [2.37], [3.17], [1.28], [1.08], [3.05], [3.45], [1.1], [7.81], [1.52], [2.82], [2.84], [3.06], [3.37], [5.04], [2.25], [4.4], [4.86], [1.55], [3.75], [1.23], [4.0], [4.47], [7.54], [1.11], [1.6], [0.9], [-1.33], [0.82], [3.74], [6.2], [2.15], [7.07], [3.98], [1.0], [2.63], [1.18], [3.56], [1.26], [1.79], [2.03], [2.87], [1.57], [1.76], [0.58], [5.86], [6.84], [2.28], [2.14], [0.3], [1.78], [3.42], [4.83], [2.24], [3.13], [0.48], [4.3], [-0.47], [4.65], [1.02], [3.04], [0.77], [-0.14], [5.48], [1.73], [1.44], [3.6], [-0.22], [-0.9], [-2.94], [1.25], [-0.84], [1.25], [3.79], [2.41], [1.81], [3.08], [2.99], [3.04], [0.65], [0.41], [2.64], [7.31], [0.49], [1.24], [-1.22], [2.1], [-0.57], [-0.68], [3.95], [0.55], [4.53], [1.15], [1.78], [1.26], [1.47], [0.08], [2.07], [1.5], [3.45], [4.43], [0.15], [2.01], [1.47], [0.66], [1.41], [2.33], [0.47], [3.58], [1.03], [-0.52], [1.26], [1.99], [0.68], [0.17], [1.54], [2.45], [-2.29], [1.27], [1.88], [2.29], [0.95], [-2.32], [-1.01], [1.5], [6.35], [0.65], [1.64], [3.71], [7.77], [1.94], [4.87], [0.13], [0.85], [0.93], [1.0], [0.22], [6.79], [-0.35], [2.75], [0.27], [-1.53], [2.82], [-0.43], [0.29], [3.19], [3.18], [1.89], [1.54], [0.25], [4.73], [3.53], [4.4], [0.81], [4.8], [1.9], [4.29], [-0.83], [0.76], [2.92], [2.09], [3.2], [5.08], [1.01], [5.58], [0.8], [1.08], [1.47], [1.45], [2.04], [0.6], [3.15], [5.11], [2.6], [1.83], [2.67], [4.3], [0.32], [-1.52], [4.83], [4.77], [2.52], [2.7], [0.89], [2.8], [2.7], [1.28], [2.1], [1.39], [2.93], [-0.25], [-0.46], [4.42], [0.72], [-0.77], [2.97], [2.52], [-1.64], [0.43], [3.0], [2.22], [1.91], [1.23], [1.57], [2.18], [1.82], [1.46], [3.03], [3.72], [2.85], [1.73], [-0.5], [2.44], [3.37], [4.28], [1.57], [2.08], [0.61], [3.0], [1.2], [-1.31], [-1.13], [2.27], [4.01], [0.0], [-0.49], [2.44], [2.69], [1.1], [1.35], [0.7], [4.08], [1.47], [4.17], [4.77], [2.47], [3.66], [2.66], [0.98], [1.82], [5.37], [1.39], [2.15], [0.89], [0.5], [3.67], [2.18], [1.12], [4.97], [1.79], [2.39], [4.81], [4.64], [1.29], [0.75], [0.16], [-3.53], [4.21], [-0.09], [2.19], [2.34], [3.3], [0.08], [0.43], [-0.25], [0.2], [2.68], [0.1], [1.52], [3.66], [4.53], [1.7], [3.69], [-0.97], [4.66], [0.17], [1.13], [2.09], [4.92], [3.35], [2.7], [0.57], [0.78], [3.39], [1.73], [0.41], [0.49], [1.08], [-0.32], [1.88], [2.34], [2.45], [6.82], [1.85], [1.04], [3.36], [1.17], [-0.9], [4.46], [0.01], [0.54], [-1.2], [3.29], [1.92], [1.15], [4.1], [0.29], [4.87], [0.23], [2.17], [0.72], [-1.83], [4.06], [0.47], [0.94], [2.5], [4.31], [2.7], [1.71], [1.69], [1.48], [1.38], [2.54], [3.5], [0.77], [2.34], [2.21], [0.66], [1.43], [1.02], [0.99], [3.25], [1.86], [0.13], [1.8], [3.3], [0.15], [4.2], [0.04], [1.26], [0.74], [-0.22], [0.84], [0.63], [1.96], [1.51], [2.58], [7.2], [1.75], [3.01], [1.19], [1.63], [3.38], [1.82], [4.89], [4.1], [0.56], [0.59], [0.53], [2.48], [0.14], [-1.17], [0.5], [0.78], [2.62], [4.9], [3.54], [5.99], [4.08], [0.03], [3.72], [0.95], [3.2], [1.31], [1.34], [4.66], [0.47], [1.04], [-1.85], [5.67], [7.0], [0.69], [1.49], [3.44], [2.3], [-0.6], [1.29], [1.8], [1.35], [2.42], [3.52], [1.28], [0.15], [1.58], [-1.89], [0.82], [2.3], [1.91], [4.55], [1.59], [2.55], [-1.15], [-2.82], [4.73], [4.17], [-0.79], [-0.96], [0.51], [-2.05], [-0.45], [3.83], [1.3], [0.03], [1.49], [3.89], [0.77], [0.12], [4.17], [3.8], [1.21], [1.28], [1.01], [2.03], [0.8], [6.54], [2.95], [1.76], [0.74], [5.0], [1.24], [3.95], [-0.38], [2.6], [7.26], [1.9], [1.32], [4.85], [5.81], [2.43], [2.31], [2.24], [2.08], [2.08], [2.07], [0.71], [-0.45], [4.2], [3.5], [1.4], [5.07], [4.8], [4.45], [-1.05], [1.08], [5.07], [2.32], [1.76], [1.51], [1.02], [2.16], [2.04], [1.28], [0.86], [8.2], [2.71], [2.71], [4.0], [-0.82], [0.64], [1.73], [1.6], [5.67], [2.33], [4.63], [3.39], [4.01], [-0.06], [2.18], [0.99], [4.48], [2.94], [5.34], [5.45], [0.09], [2.87], [4.55], [-1.86], [0.06], [-1.47], [2.82], [4.26], [2.4], [1.35], [0.48], [-0.07], [1.31], [1.83], [0.42], [2.8], [5.96], [4.04], [2.02], [0.97], [2.49], [1.42], [0.78], [1.7], [3.08], [2.51], [3.28], [3.2], [2.7], [7.59], [1.98], [2.59], [-0.9], [7.15], [-0.57], [1.44], [2.23], [4.88], [2.83], [4.31], [0.84], [2.84], [1.83], [-3.05], [4.78], [5.01], [2.1], [1.8], [-0.63], [1.65], [2.88], [3.15], [6.8], [-0.04], [-0.5], [1.85], [4.27], [1.18], [2.36], [3.8], [0.46], [1.17], [5.33], [2.02], [0.48], [2.67], [0.08], [0.36], [2.15], [-0.2], [3.28], [4.34], [5.23], [3.0], [-0.6], [2.98], [1.4], [8.16], [3.75], [0.1], [4.14], [1.5], [0.9], [3.02], [-0.03], [2.44], [3.43], [2.47], [-0.49], [6.02], [1.94], [2.24], [4.11], [4.44], [1.1], [1.47], [3.84], [3.27], [4.42], [0.56], [1.69], [-3.41], [5.34], [-0.67], [5.9], [2.02], [4.7], [4.97], [0.39], [1.01], [4.17], [6.26], [2.39], [1.11], [2.24], [1.96], [4.42], [0.87], [9.29], [2.11], [2.46], [2.7], [0.91], [3.28], [-0.77], [2.86], [5.19], [3.92], [1.6], [5.58], [-0.78], [0.15], [-0.14], [0.68], [3.64], [4.27], [1.24], [4.15], [2.12], [2.4], [4.02], [0.35], [1.01], [3.21], [3.78], [1.83], [2.5], [2.8], [6.8], [1.15], [2.33], [3.42], [4.57], [1.33], [3.2], [4.69], [9.07], [2.3], [0.48], [3.34], [4.4], [0.76], [3.19], [0.44], [2.7], [2.09], [3.34], [3.29], [-1.08], [2.24], [1.39], [-0.55], [-0.63], [1.78], [-1.61], [4.22], [1.36], [2.64], [5.66], [2.85], [3.06], [3.04], [1.7], [0.51], [2.11], [5.51], [0.24], [1.78], [1.38], [0.28], [4.48], [0.54], [1.56], [1.99], [0.66], [-2.6], [7.32], [0.35], [4.36], [3.6], [1.24], [7.62], [2.89], [2.83], [5.31], [4.55], [4.66], [-0.46], [1.93], [1.44], [1.19], [1.65], [2.65], [6.66], [1.59], [3.36], [1.11], [3.18], [2.41], [-0.35], [3.56], [1.11], [-0.31], [-0.77], [3.99], [3.07], [1.44], [1.18], [1.98], [-1.56], [0.84], [4.85], [1.55], [3.09], [1.07], [3.47], [3.2], [4.55], [1.94], [1.65], [5.7], [4.47], [2.61], [4.94], [9.29], [4.99], [0.42], [3.22], [-1.25], [0.73], [-0.14], [2.16], [2.19], [-1.8], [3.0], [1.72], [0.37], [1.0], [1.13], [4.4], [4.16], [3.32], [3.02], [0.31], [2.94], [5.65], [4.46], [-0.9], [3.74], [1.54], [0.57], [1.87], [2.01], [3.11], [-0.31], [4.81], [2.78], [2.32], [0.17], [-0.21], [2.8], [3.18], [2.29], [3.72], [0.83], [2.35], [1.89], [0.7], [4.3], [1.86], [5.01], [2.55], [1.18], [2.59], [3.0], [-1.4], [2.86], [1.34], [2.09], [-1.32], [6.83], [5.0], [4.31], [1.14], [2.4], [-0.16], [2.99], [4.37], [3.27], [4.3], [2.27], [1.04], [-2.14], [1.95], [3.92], [4.03], [2.48], [3.4], [1.98], [-0.49], [3.67], [1.25], [-0.35], [3.26], [3.55], [0.36], [-0.2], [2.46], [0.24], [2.03], [1.24], [2.7], [3.23], [2.72], [5.1], [0.66], [0.98], [1.59], [0.22], [1.6], [2.16], [0.45], [-0.92], [2.3], [3.32], [2.91], [0.93], [1.88], [1.81], [0.69], [-0.83], [-0.57], [0.14], [2.36], [1.58], [0.87], [3.78], [0.43], [4.7], [3.51], [1.0], [3.77], [4.9], [1.03], [1.1], [3.14], [0.33], [1.28], [2.63], [3.2], [2.34], [3.66], [0.54], [-0.49], [2.12], [0.18], [3.67], [2.88], [2.83], [1.84], [0.28], [3.17], [7.63], [0.97], [2.48], [3.49], [1.92], [1.59], [1.37], [0.55], [0.39], [2.1], [3.42], [2.32], [1.74], [1.16], [2.53], [0.4], [6.22], [4.6], [3.83], [0.94], [0.35], [2.53], [1.63], [2.09], [1.37], [4.51], [-0.37], [4.69], [2.14], [0.01], [0.93], [-0.28], [1.41], [3.09], [0.38], [3.4], [-0.22], [1.74], [0.69], [1.98], [-2.72], [1.09], [4.82], [2.95], [1.27], [2.82], [5.49], [-0.85], [3.48], [1.55], [1.67], [5.0], [4.4], [3.13], [-1.17], [1.51], [3.27], [1.23], [1.81], [1.36], [2.38], [2.62], [2.33], [1.66], [-1.58], [2.76], [3.34], [2.0], [2.24], [3.2], [1.36], [6.1], [2.15], [2.67], [0.02], [1.27], [4.97], [3.83], [3.66], [2.03], [1.83], [-0.02], [-1.87], [0.58], [0.82], [2.56], [-0.13], [2.37], [0.0], [3.11], [1.0], [-0.89], [2.37], [1.52], [1.54], [0.37], [2.51], [4.34], [3.56], [1.07], [2.41], [1.68], [2.55], [1.06], [0.79], [2.9], [4.56], [4.5], [0.35], [-0.16], [2.97], [0.15], [1.9], [3.11], [2.2], [0.0], [4.38], [7.05], [3.31], [-1.4], [3.26], [1.37], [5.65], [-3.64], [1.28], [4.5], [0.11], [1.36], [3.17], [3.53], [2.54], [5.02], [-0.41], [2.87], [2.25], [3.2], [4.19], [1.5], [1.77], [3.05], [0.68], [-0.2], [0.38], [1.45], [0.76], [2.98], [1.29], [3.07], [-0.95], [0.57], [0.12], [0.72], [0.42], [1.73], [3.68], [1.39], [1.42], [-1.3], [3.36], [0.38], [-0.49], [4.15], [2.5], [2.88], [0.53], [1.16], [-1.08], [1.3], [1.83], [3.02], [2.4], [0.4], [1.79], [1.29], [-0.67], [5.82], [0.85], [2.25], [0.37], [1.42], [2.59], [1.46], [3.55], [3.75], [2.59], [0.71], [3.14], [2.53], [3.92], [1.81], [2.68], [0.33], [5.5], [1.67], [2.69], [-0.63], [-1.59], [0.79], [-0.71], [4.53], [1.83], [2.3], [2.56], [1.73], [3.83], [1.12], [5.75], [4.3], [5.18], [1.76], [0.82], [0.39], [4.09], [2.0], [-0.57], [3.15], [3.07], [0.57], [1.5], [1.63], [3.51], [1.42], [4.6], [2.68], [3.91], [2.85], [-0.05], [0.41], [0.86], [-0.04], [2.94], [1.99], [1.49], [2.38], [1.95], [0.55], [0.4], [0.81], [1.4], [3.6], [3.32], [0.58], [-0.04], [2.28], [1.17], [2.14], [5.08], [4.0], [0.74], [0.44], [0.82], [3.55], [4.67], [4.1], [1.27], [1.02], [2.05], [-0.4], [5.86], [3.85], [0.66], [2.72], [2.43], [4.33], [0.67], [3.24], [7.18], [3.26], [1.87], [0.98], [2.88], [1.33], [0.35], [3.73], [-0.84], [-4.0], [0.14], [2.59], [0.16], [4.54], [3.94], [0.24], [5.21], [3.24], [1.96], [-0.21], [1.82], [6.5], [-0.25], [2.2], [0.58], [1.33], [-0.67], [1.79], [2.31], [3.32], [1.58], [1.26], [1.68], [2.44], [7.25], [1.03], [0.58], [3.12], [1.02], [-0.08], [1.6], [0.34], [1.92], [2.4], [2.53], [1.76], [0.58], [3.67], [1.14], [2.1], [2.27], [-0.04], [2.83], [1.4], [6.72], [1.65], [4.2], [2.69], [1.52], [0.81], [5.94], [2.02], [0.73], [2.69], [5.12], [-0.02], [-0.61], [-0.02], [4.73], [2.9], [4.05], [7.21], [4.78], [3.9], [5.35], [2.13], [3.99], [6.67], [0.23], [2.95], [2.9], [4.24], [1.44], [2.47], [4.73], [4.93], [3.5], [0.15], [-0.74], [1.34], [-0.04], [3.42], [3.52], [2.82], [1.92], [2.52], [3.82], [2.51], [6.5], [6.09], [3.74], [-0.39], [6.06], [1.12], [0.45], [2.75], [-0.85], [1.61], [5.22], [-1.9], [1.9], [5.4], [3.12], [1.54], [1.33], [3.23], [0.84], [0.08], [1.41], [4.34], [6.85], [1.39], [1.32], [5.09], [1.86], [-0.05], [2.36], [2.08], [1.5], [0.12], [-1.15], [0.81], [1.99], [3.86], [3.2], [-1.3], [-1.2], [1.34], [3.24], [2.88], [1.27], [1.31], [4.68], [0.52], [2.53], [-0.61], [0.25], [2.61], [1.9], [-1.29], [3.08], [1.72], [4.64], [-0.08], [3.84], [2.29], [0.91], [4.82], [3.08], [1.84], [4.91], [2.32], [-0.34], [1.26], [3.03], [0.45], [3.91], [2.59], [4.58], [1.78], [-1.23], [1.88], [3.85], [1.64], [0.14], [3.58], [2.39], [3.42], [0.49], [0.0], [2.19], [-0.73], [3.21], [2.61], [2.04], [4.14], [2.56], [0.3], [1.3], [4.0], [4.24], [-1.69], [0.65], [0.87], [0.44], [2.64], [1.45], [0.21], [4.37], [4.62], [-0.33], [4.17], [2.92], [3.9], [1.87], [0.91], [4.81], [3.1], [1.58], [1.57], [3.09], [3.16], [1.76], [3.67], [2.43], [0.75], [2.86], [2.94], [-4.43], [1.65], [4.0], [0.3], [-0.3], [3.8], [7.47], [-0.59], [0.57], [3.04], [2.22], [5.16], [1.38], [2.09], [0.19], [-0.17], [4.02], [2.01], [3.24], [1.45], [3.46], [2.67], [1.71], [1.38], [4.0], [0.44], [2.53], [3.51], [2.25], [4.73], [2.58], [0.92], [0.9], [5.2], [1.73], [-0.8], [1.71], [4.76], [3.27], [3.45], [1.04], [1.89], [2.02], [2.76], [5.68], [8.16], [2.5], [3.75], [-1.09], [3.92], [0.73], [4.58], [1.49], [2.21], [0.99], [2.11], [5.83], [0.72], [1.41], [2.14], [-2.55], [2.68], [2.15], [5.34], [3.77], [4.92], [6.52], [-0.38], [2.55], [2.95], [2.55], [1.71], [2.43], [2.44], [1.22], [2.45], [2.17], [2.6], [0.38], [3.12], [1.53], [0.8], [3.8], [2.79], [0.0], [1.74], [4.07], [9.96], [2.79], [5.77], [3.43], [5.89], [3.91], [-0.27], [2.02], [2.25], [2.94], [0.12], [3.63], [5.36], [1.44], [0.39], [-0.22], [3.7], [0.88], [3.74], [1.26], [0.56], [5.1], [1.89], [3.05], [0.5], [-0.7], [0.09], [1.8], [1.96], [1.24], [4.8], [-0.11], [-1.18], [0.93], [2.7], [0.65], [0.68], [-2.42], [-1.43], [-0.43], [6.47], [1.65], [3.05], [3.42], [2.5], [-2.68], [2.85], [1.0], [2.99], [0.54], [-1.4], [0.14], [1.69], [0.75], [-0.1], [-1.3], [3.12], [3.73], [-1.2], [1.29], [2.09], [3.44], [0.74], [2.44], [3.97], [2.15], [4.22], [3.84], [3.03], [2.06], [3.27], [2.46], [5.79], [-0.74], [2.73], [2.89], [-2.2], [1.31], [1.96], [1.65], [2.6], [1.58], [1.12], [0.4], [3.07], [2.67], [2.06], [1.82], [1.59], [6.99], [3.09], [3.27], [3.8], [2.38], [1.73], [-1.87], [3.42], [1.51], [1.21], [0.48], [3.65], [3.96], [3.83], [0.2], [2.92], [0.21], [4.0], [3.4], [1.85], [0.96], [-0.45], [7.46], [2.54], [1.81], [0.69], [4.09], [1.16], [1.86], [1.12], [2.1], [2.13], [0.3], [1.07], [1.79], [1.52], [1.05], [-0.69], [1.7], [3.37], [0.0], [1.47], [3.24], [1.05], [3.36], [2.51], [3.57], [4.24], [-1.08], [3.08], [1.98], [2.8], [-0.27], [1.05], [2.54], [2.92], [2.19], [-1.3], [4.34], [0.25], [2.45], [0.46], [-0.28], [4.09], [3.53], [3.2], [-0.89], [0.41], [3.34], [2.51], [2.77], [1.69], [2.95], [0.53], [3.42], [5.8], [2.64], [4.25], [4.41], [1.11], [0.91], [1.98], [3.6], [0.08], [4.63], [2.0], [0.23], [0.12], [5.62], [3.85], [2.22], [8.06], [-0.4], [0.54], [2.34], [2.73], [4.48], [3.05], [-0.08], [1.85], [8.27], [5.43], [-0.11], [2.74], [-0.72], [1.33], [2.58], [5.26], [2.4], [3.52], [-0.64], [1.28], [1.61], [1.81], [1.08], [3.1], [-0.32], [-2.31], [1.15], [5.72], [0.83], [3.69], [1.91], [2.9], [2.88], [1.54], [3.26], [-1.76], [4.1], [1.37], [4.54], [5.94], [4.97], [0.47], [5.66], [0.87], [1.01], [0.85], [2.2], [1.86], [2.26], [-0.8], [0.54], [1.18], [2.16], [-1.3], [-0.5], [1.09], [2.8], [1.75], [4.8], [1.72], [1.89], [1.56], [4.92], [0.85], [3.33], [1.32], [3.2], [4.39], [1.45], [1.34], [1.85], [1.0], [3.44], [0.8], [0.96], [1.11], [0.67], [1.76], [3.4], [2.25], [3.85], [1.48], [1.06], [-3.09], [1.45], [3.14], [1.2], [1.22], [0.7], [-0.96], [3.21], [0.96], [0.14], [0.85], [-0.7], [5.21], [2.57], [-0.52], [3.77], [3.03], [2.26], [7.11], [5.61], [3.57], [2.9], [3.22], [-0.96], [3.82], [1.6], [3.46], [2.18], [2.4], [2.28], [0.01], [4.75], [2.32], [0.91], [0.71], [0.75], [0.55], [4.94], [0.83], [3.46], [1.63], [5.25], [0.32], [3.0], [0.73], [-0.52], [0.59], [2.74], [2.8], [1.3], [2.64], [1.29], [1.19], [4.67], [1.9], [4.24], [3.06], [-0.67], [2.84], [1.45], [-0.05], [0.42], [4.2], [2.6], [4.77], [4.83], [1.79], [-0.06], [1.37], [-0.9], [1.36], [1.31], [1.44], [2.39], [-1.38], [0.89], [3.8], [4.17], [1.17], [1.93], [3.3], [3.9], [2.93], [-0.11], [0.22], [3.25], [1.72], [2.51], [2.3], [-1.89], [3.01], [1.33], [1.6], [-0.38], [4.37], [1.94], [-2.11], [3.75], [6.64], [4.99], [2.72], [-0.65], [0.06], [2.8], [3.7], [7.11], [0.22], [4.45], [4.15], [-0.21], [3.2], [-0.32], [1.8], [0.81], [1.81], [-1.11], [5.77], [5.69], [0.73], [-0.15], [4.38], [0.24], [0.97], [2.41], [3.57], [0.52], [-0.34], [0.06], [3.39], [4.25], [1.4], [2.52], [1.24], [1.41], [2.99], [2.57], [4.52], [1.21], [1.46], [0.86], [1.42], [-1.89], [1.33], [4.16], [0.26], [3.85], [1.4], [-0.01], [1.38], [1.65], [3.28], [0.56], [3.03], [0.63], [5.91], [1.62], [1.51], [0.11], [-0.52], [1.21], [0.7], [3.17], [1.84], [0.76], [9.3], [2.56], [1.7], [3.05], [0.58], [2.45], [0.87], [0.64], [1.92], [0.3], [2.53], [2.13], [0.85], [2.24], [0.96], [1.33], [2.7], [0.43], [1.88], [0.36], [1.77], [1.14], [-0.35], [1.82], [2.83], [-0.07], [3.58], [-0.17], [1.56], [1.96], [3.2], [1.65], [1.22], [4.48], [0.04], [1.04], [1.33], [3.55], [2.62], [0.64], [1.65], [7.63], [3.75], [-1.22], [1.33], [2.0], [3.3], [1.75], [0.86], [6.2], [1.87], [3.64], [2.69], [1.32], [2.15], [-0.55], [0.9], [1.61], [4.38], [0.0], [1.57], [2.45], [2.86], [2.56], [-1.54], [0.2], [-1.25], [2.17], [1.97], [3.66], [1.62], [0.53], [3.14], [3.68], [1.48], [1.12], [2.9], [3.91], [2.45], [-1.14], [5.78], [2.57], [1.25], [0.72], [-0.27], [3.73], [0.2], [3.63], [4.28], [0.36], [2.93], [-0.02], [1.39], [6.67], [1.05], [0.99], [5.51], [2.71], [1.02], [1.2], [1.65], [-0.74], [-0.92], [3.96], [2.82], [3.72], [0.4], [1.53], [3.86], [3.99], [1.63], [3.9], [4.47], [3.05], [3.28], [5.53], [1.31], [3.32], [2.65], [3.3], [0.87], [1.49], [2.03], [1.52], [3.88], [0.47], [-0.67], [0.84], [2.59], [2.06], [1.9], [1.89], [1.18], [5.18], [0.61], [2.95], [2.81], [2.42], [2.52], [3.89], [1.99], [2.76], [6.51], [4.8], [0.97], [3.92], [5.05], [1.96], [1.45], [1.79], [2.66], [3.09], [2.3], [0.66], [1.36], [1.7], [1.89], [-0.14], [2.6], [2.85], [2.21], [2.84], [1.91], [3.42], [1.87], [2.29], [6.2], [2.06], [3.3], [0.92], [-1.39], [0.37], [3.92], [3.61], [2.61], [1.26], [1.55], [4.88], [0.91], [1.62], [4.66], [0.74], [2.31], [1.18], [2.19], [0.11], [0.74], [2.45], [3.58], [3.45], [4.01], [2.61], [4.43], [-0.94], [1.16], [2.16], [1.46], [2.36], [0.75], [2.67], [5.75], [2.29], [0.97], [3.08], [0.99], [2.7], [3.68], [0.06], [2.17], [2.39], [-0.28], [1.96], [1.8], [6.13], [3.39], [7.83], [-0.55], [3.95], [2.45], [2.47], [1.7], [0.4], [3.08], [3.04], [1.76], [1.8], [2.48], [2.29], [-3.02], [1.76], [2.38], [5.38], [3.73], [-0.62], [5.2], [2.03], [0.62], [2.15], [2.13], [3.25], [1.85], [-0.02], [0.62], [-0.1], [3.87], [3.63], [0.69], [-0.39], [6.42], [3.28], [1.24], [3.2], [1.37], [1.4], [3.11], [2.46], [1.08], [2.91], [0.99], [1.89], [0.06], [2.8], [5.32], [2.51], [2.76], [-0.94], [1.9], [1.61], [1.6], [4.42], [3.2], [2.06], [2.37], [1.12], [1.95], [8.65], [2.0], [3.86], [1.7], [-0.74], [5.07], [-0.61], [-2.4], [-0.27], [0.27], [1.58], [4.48], [3.47], [1.14], [4.51], [-0.2], [-1.3], [1.44], [1.14], [2.91], [1.1], [3.23], [1.82], [0.98], [1.07], [1.7], [3.44], [1.01], [1.01], [0.31], [3.7], [2.59], [0.49], [3.4], [4.25], [2.78], [-0.19], [0.81], [1.84], [3.27], [3.2], [1.59], [2.78], [0.96], [4.73], [0.98], [3.36], [2.98], [1.29], [0.4], [-0.31], [1.8], [1.07], [1.81], [-0.17], [2.17], [5.56], [3.56], [0.44], [2.69], [2.56], [0.51], [-4.65], [6.75], [2.45], [-0.27], [0.04], [2.26], [-0.34], [1.87], [-1.49], [2.2], [0.16], [-0.95], [1.98], [1.33], [1.1], [2.03], [2.88], [-0.16], [1.5], [2.52], [1.9], [1.45], [1.5], [2.56], [4.19], [4.45], [2.81], [3.24], [4.71], [-0.45], [3.58], [5.15], [3.39], [1.56], [2.34], [3.32], [0.66], [4.0], [0.96], [2.09], [5.96], [1.9], [3.12], [4.16], [3.14], [0.2], [2.4], [2.17], [-1.11], [4.26], [4.4], [1.95], [1.23], [0.06], [3.57], [0.8], [1.88], [2.4], [0.85], [1.89], [-0.36], [0.75], [1.06], [3.5], [1.63], [2.6], [1.53], [2.63], [3.15], [1.28], [4.0], [2.96], [1.85], [5.2], [2.23], [4.06], [3.48], [2.59], [2.21], [0.38], [1.47], [3.3], [4.88], [3.67], [5.57], [2.86], [2.53], [4.86], [3.65], [2.19], [1.94], [0.96], [-1.31], [1.98], [4.74], [3.68], [1.8], [4.84], [2.36], [0.71], [2.53], [1.41], [2.6], [0.86], [0.2], [0.24], [1.53], [1.36], [0.6], [0.5], [1.8], [3.52], [2.52], [3.06], [1.78], [1.53], [1.64], [0.04], [2.11], [1.85], [1.05], [1.3], [-0.46], [2.86], [0.8], [3.51], [5.9], [2.02], [0.63], [4.74], [0.65], [3.16], [2.59], [3.0], [3.6], [1.12], [0.61], [0.61], [2.29], [2.09], [2.96], [2.58], [2.3], [-0.93], [6.96], [0.77], [3.24], [3.43], [2.3], [2.55], [3.04], [4.64], [0.62], [0.04], [2.73], [0.93], [1.42], [1.83], [4.35], [2.05], [0.99], [2.0], [1.85], [2.53], [1.54], [3.34], [2.59], [1.64], [-0.8], [2.32], [6.11], [1.75], [5.76], [0.43], [6.1], [3.74], [0.58], [2.84], [0.83], [-0.1], [2.74], [0.95], [-2.47], [1.52], [2.03], [4.28], [2.77], [0.97], [-0.23], [2.62], [1.75], [3.7], [7.2], [0.96], [1.06], [2.63], [0.95], [1.51], [3.84], [-2.26], [3.15], [2.83], [2.78], [2.56], [2.1], [2.77], [1.39], [2.02], [2.9], [3.49], [4.37], [1.75], [3.7], [-1.26], [3.71], [3.14], [4.4], [4.35], [5.7], [0.85], [4.0], [4.21], [1.18], [-0.58], [3.2], [1.29], [0.17], [0.58], [1.15], [2.23], [5.44], [2.56], [4.97], [2.08], [2.68], [2.88], [2.75], [4.73], [3.59], [1.94], [2.16], [4.45], [5.63], [6.65], [0.82], [0.93], [2.78], [3.67], [3.42], [6.18], [3.81], [4.83], [3.7], [2.03], [-0.22], [1.53], [4.51], [2.0], [-2.11], [2.18], [1.84], [1.72], [4.82], [1.01], [4.09], [2.38], [2.4], [0.61], [3.37], [3.39], [2.91], [-0.37], [0.82], [0.57], [1.43], [2.9], [3.9], [0.96], [2.72], [0.45], [4.97], [1.9], [5.09], [2.23], [0.67], [0.22], [6.44], [1.74], [-1.0], [2.72], [0.2], [2.88], [3.78], [4.21], [2.1], [2.07], [1.18], [-1.02], [1.92], [1.03], [-0.06], [-0.67], [-0.41], [1.99], [2.46], [-0.24], [-1.85], [1.18], [1.04], [1.57], [0.91], [1.0], [-0.04], [2.58], [1.34], [2.19], [3.32], [2.03], [6.84], [4.61], [1.95], [1.3], [4.64], [1.9], [3.64], [1.36], [4.97], [2.27], [6.51], [5.21], [0.74], [4.16], [3.7], [2.07], [1.85], [1.85], [0.94], [2.27], [0.48], [6.15], [0.6], [3.31], [0.77], [2.18], [1.36], [1.83], [5.16], [1.07], [3.7], [5.09], [0.74], [5.12], [3.45], [1.1], [3.42], [4.51], [0.7], [1.32], [0.7], [0.83], [2.38], [1.38], [0.6], [-2.9], [2.54], [-0.2], [4.63], [2.9], [1.25], [3.42], [-0.01], [3.18], [2.05], [2.13], [2.84], [1.25], [1.27], [2.75], [7.05], [1.84], [-0.87], [4.4], [5.44], [0.72], [2.71], [4.43], [2.12], [1.06], [1.77], [4.28], [0.72], [3.44], [-0.65], [0.98], [4.07], [1.32], [2.44], [1.5], [3.55], [0.26], [-0.83], [1.49], [5.0], [3.38], [2.12], [1.8], [-0.2], [3.65], [3.08], [4.46], [4.18], [2.36], [0.62], [3.82], [0.6], [0.83], [1.22], [-0.49], [1.23], [0.52], [1.5], [1.49], [1.13], [4.8], [6.47], [4.42], [3.02], [3.68], [2.85], [5.08], [-2.43], [0.65], [1.85], [3.55], [0.83], [2.63], [4.26], [0.62], [1.41], [5.23], [1.87], [3.46], [1.11], [1.5], [1.88], [7.1], [1.56], [2.82], [0.73], [0.55], [2.42], [0.11], [3.62], [2.81], [3.1], [2.88], [1.76], [1.9], [1.46], [0.99], [0.63], [6.4], [1.9], [0.84], [-0.69], [3.52], [2.37], [1.86], [-0.07], [-0.62], [3.25], [2.27], [3.38], [3.43], [2.98], [2.39], [0.88], [1.9], [-0.35], [1.29], [3.94], [0.38], [0.9], [-1.4], [3.05], [2.56], [2.58], [1.96], [1.47], [1.92], [2.89], [1.25], [-0.38], [0.27], [2.52], [1.82], [2.98], [2.06], [8.42], [1.4], [3.02], [2.78], [2.88], [1.78], [5.15], [4.7], [3.37], [3.7], [2.59], [4.52], [4.14], [-0.81], [2.76], [-0.52], [3.31], [4.78], [1.99], [3.67], [1.66], [0.25], [3.4], [5.53], [1.52], [0.04], [-0.64], [3.63], [0.23], [3.64], [2.09], [5.31], [6.63], [2.93], [0.59], [2.39], [1.77], [0.66], [0.76], [-0.5], [3.7], [3.18], [2.56], [-1.0], [1.26], [4.0], [0.95], [2.92], [2.12], [3.7], [1.2], [1.88], [-0.81], [1.63], [3.3], [2.3], [3.2], [4.3], [0.45], [0.49], [2.27], [6.74], [6.8], [3.21], [-0.47], [1.43], [3.4], [5.51], [1.01], [1.98], [3.87], [4.03], [1.4], [0.35], [2.71], [-0.03], [4.72], [0.52], [4.38], [2.42], [0.23], [2.17], [0.37], [2.34], [3.2], [2.32], [2.16], [2.81], [3.71], [0.73], [3.55], [1.87], [1.37], [-1.64], [2.24], [1.42], [4.75], [0.45], [1.99], [1.02], [-0.39], [3.72], [6.06], [5.12], [5.01], [2.27], [2.74], [3.61], [0.23], [2.7], [1.52], [2.48], [0.95], [2.25], [0.4], [2.63], [-0.03], [0.0], [1.64], [1.74], [-0.19], [4.22], [2.45], [-1.56], [5.25], [1.55], [-0.96], [-0.33], [1.78], [0.82], [1.69], [-0.71], [1.03], [3.54], [3.25], [3.29], [4.69], [5.18], [4.2], [0.97], [-0.09], [1.78], [5.29], [0.85], [0.96], [3.83], [4.38], [-0.36], [0.41], [1.48], [3.03], [1.7], [2.16], [1.82], [-0.04], [3.95], [1.39], [0.59], [2.69], [2.33], [-0.08], [0.04], [1.95], [3.14], [1.34], [0.61], [2.8], [1.72], [3.77], [3.88], [5.68], [1.3], [2.78], [1.44], [1.72], [6.67], [0.24], [-0.77], [1.54], [4.44], [6.3], [-1.7], [3.35], [1.26], [1.97], [2.72], [5.33], [4.54], [1.68], [2.9], [-0.79], [2.71], [2.44], [3.35], [4.88], [1.69], [3.06], [1.73], [5.6], [2.82], [3.17], [2.67], [3.85], [3.64], [2.02], [1.95], [0.29], [1.56], [1.6], [3.96], [-1.22], [0.89], [3.17], [0.81], [1.31], [1.58], [3.77], [2.68], [2.94], [0.8], [2.56], [-1.34], [1.98], [2.1], [2.19], [4.5], [1.29], [0.3], [0.13], [6.11], [3.18], [-0.31], [1.76], [1.09], [0.64], [1.13], [0.23], [0.74], [1.6], [-2.37], [4.01], [0.48], [4.53], [4.81], [-0.64], [0.11], [2.79], [4.67], [1.51], [7.11], [4.37], [0.07], [1.48], [4.89], [0.32], [2.86], [3.7], [0.34], [6.47], [3.83], [0.91], [2.1], [0.35], [3.4], [0.83], [2.44], [3.81], [-0.31], [0.68], [-0.51], [2.87], [0.38], [-1.09], [1.18], [4.5], [-0.32], [1.92], [4.91], [2.93], [1.32], [3.74], [-2.47], [4.47], [0.56], [1.98], [0.31], [1.74], [5.63], [2.04], [3.16], [1.67], [-2.16], [1.57], [1.64], [2.71], [2.44], [-0.62], [1.24], [0.77], [3.31], [-1.3], [0.18], [1.7], [2.83], [7.92], [2.01], [0.08], [3.38], [0.27], [-2.27], [-1.77], [1.4], [6.06], [-0.59], [0.27], [0.99], [5.66], [1.73], [2.5], [3.63], [1.28], [3.23], [4.31], [1.52], [3.07], [2.31], [3.9], [1.64], [5.03], [3.84], [0.03], [2.59], [3.77], [3.58], [2.36], [1.86], [3.7], [1.35], [0.72], [2.81], [1.67], [1.35], [4.94], [3.77], [3.62], [0.74], [6.25], [2.32], [0.8], [0.67], [0.23], [3.3], [4.22], [0.26], [4.05], [-2.45], [4.11], [1.54], [4.51], [0.92], [0.65], [3.4], [2.48], [1.34], [3.11], [0.23], [1.5], [-1.87], [0.84], [3.25], [0.4], [2.4], [3.24], [-0.45], [0.9], [4.92], [4.58], [-0.53], [5.09], [2.54], [2.9], [1.92], [0.32], [3.01], [4.34], [3.58], [-0.91], [1.28], [0.26], [0.67], [3.71], [6.93], [0.46], [4.26], [3.08], [1.49], [2.6], [2.54], [0.48], [3.24], [1.03], [0.55], [-2.83], [4.93], [1.57], [1.71], [-0.32], [2.17], [1.86], [1.1], [2.05], [0.57], [4.0], [4.82], [3.93], [-1.27], [2.74], [1.43], [-2.79], [2.09], [1.85], [1.3], [3.44], [2.47], [1.56], [3.92], [3.42], [1.5], [2.37], [3.46], [1.37], [1.73], [1.44], [6.51], [2.85], [0.21], [1.72], [0.22], [1.68], [4.55], [-0.81], [4.09], [1.98], [4.04], [0.54], [6.86], [2.41], [-1.65], [1.63], [-1.07], [2.33], [1.0], [4.56], [3.0], [6.07], [3.64], [2.53], [-1.51], [0.56], [2.33], [-0.47], [0.31], [2.73], [1.56], [3.94], [0.34], [2.6], [4.68], [1.15], [0.84], [0.63], [-0.89], [2.07], [2.07], [0.28], [-1.05], [2.96], [3.4], [4.1], [0.77], [3.18], [1.2], [2.39], [4.85], [5.04], [-0.17], [5.43], [1.01], [2.93], [1.97], [1.53], [1.51], [4.43], [0.84], [5.42], [0.71], [-0.47], [1.83], [2.78], [1.42], [2.38], [1.2], [4.37], [2.87], [1.95], [3.18], [1.56], [1.91], [5.72], [0.3], [2.92], [2.05], [3.61], [1.33], [2.3], [2.55], [3.01], [0.24], [5.55], [8.2], [1.23], [0.24], [2.21], [1.23], [-1.87], [2.62], [2.34], [-1.71], [0.9], [2.45], [4.27], [2.21], [1.99], [2.27], [0.66], [2.82], [1.31], [0.52], [0.01], [3.01], [1.21], [1.25], [0.71], [2.28], [0.5], [1.82], [2.4], [3.6], [1.94], [1.51], [1.94], [0.26], [0.64], [2.79], [0.78], [-0.38], [5.7], [7.19], [0.35], [4.07], [1.95], [0.1], [1.6], [4.51], [3.83], [2.44], [-1.2], [-0.32], [4.55], [2.54], [3.05], [0.35], [3.21], [3.61], [5.11], [3.35], [-0.44], [0.16], [1.23], [0.99], [3.03], [4.1], [2.62], [5.0], [4.2], [2.34], [1.62], [1.67], [0.58], [6.31], [3.67], [1.88], [0.18], [3.27], [1.29], [-0.64], [0.73], [0.5], [1.96], [3.87], [1.42], [1.6], [3.2], [2.22], [-0.21], [1.38], [2.28], [6.2], [0.3], [4.62], [5.77], [2.74], [3.2], [1.85], [1.3], [1.91], [3.39], [2.64], [1.05], [1.7], [-0.09], [3.12], [1.15], [-0.47], [1.8], [0.64], [2.45], [2.95], [2.08], [2.02], [5.81], [4.36], [2.44], [-0.11], [0.46], [1.02], [0.35], [0.55], [0.95], [4.98], [3.15], [1.16], [1.33], [1.76], [1.01], [3.31], [1.56], [2.03], [5.18], [3.48], [0.5], [0.07], [-0.38], [1.04], [1.93], [0.52], [0.36], [0.77], [0.02], [2.87], [1.68], [-0.4], [6.6], [3.57], [6.13], [1.99], [1.2], [5.11], [4.06], [3.95], [0.24], [-0.36], [-0.03], [1.2], [0.46], [4.4], [4.41], [3.4], [0.46], [1.66], [-0.59], [1.71], [3.91], [1.57], [1.65], [8.07], [1.36], [1.83], [5.18], [1.01], [2.29], [3.74], [2.82], [2.1], [0.25], [2.85], [-0.78], [3.96], [2.81], [1.62], [1.87], [0.67], [1.79], [0.39], [3.28], [4.52], [1.39], [1.87], [2.26], [0.57], [1.08], [4.59], [6.16], [2.88], [1.6], [3.26], [0.85], [1.38], [3.85], [5.15], [3.19], [3.7], [0.56], [3.3], [1.64], [1.7], [3.75], [1.12], [5.46], [2.93], [1.03], [2.23], [1.65], [1.36], [1.66], [3.78], [4.98], [1.76], [2.4], [7.31], [3.35], [0.36], [5.4], [-1.7], [2.77], [5.53], [-1.26], [0.57], [-0.62], [2.13], [0.8], [2.86], [3.65], [1.13], [2.2], [-0.35], [2.67], [-0.25], [1.95], [0.44], [-0.11], [2.84], [3.26], [0.95], [4.15], [0.4], [-0.39], [2.2], [-0.17], [0.32], [2.46], [3.47], [2.52], [2.08], [4.48], [2.57], [-0.18], [4.02], [5.05], [1.78], [-0.16], [2.3], [1.04], [3.66], [2.27], [1.98], [4.5], [2.78], [3.03], [1.94], [0.91], [3.13], [0.18], [3.41], [2.91], [4.56], [5.5], [1.56], [3.95], [-0.02], [1.61], [0.7], [-0.07], [1.45], [-1.66], [-0.68], [2.27], [3.15], [-0.49], [0.68], [2.32], [0.64], [1.07], [2.69], [3.38], [1.92], [1.89], [2.3], [2.05], [1.06], [2.74], [1.7], [2.03], [0.96], [1.9], [-0.85], [1.86], [4.56], [-1.13], [2.82], [3.42], [3.56], [2.66], [5.62], [2.78], [2.38], [3.35], [2.13], [3.08], [2.5], [6.11], [1.48], [2.39], [1.81], [0.87], [0.2], [1.38], [2.69], [1.27], [2.71], [0.3], [1.58], [3.1], [1.82], [-0.96], [0.05], [2.14], [4.66], [2.95], [0.13], [0.56], [1.08], [2.05], [0.11], [3.06], [4.13], [2.08], [1.56], [4.51], [1.38], [5.86], [2.4], [-0.3], [1.22], [1.6], [0.14], [0.36], [0.56], [2.68], [1.8], [3.28], [2.5], [0.82], [1.01], [1.62], [2.75], [5.43], [3.82], [2.44], [-0.05], [1.42], [4.29], [-1.98], [9.05], [2.74], [2.08], [2.52], [0.93], [1.2], [1.65], [0.93], [2.18], [2.77], [2.77], [2.37], [2.8], [3.6], [8.01], [2.59], [2.2], [0.54], [1.16], [0.46], [1.44], [0.71], [5.53], [3.6], [0.64], [4.32], [-1.58], [1.1], [-0.36], [1.94], [3.66], [3.34], [5.76], [3.1], [0.66], [-0.32], [7.2], [2.76], [2.31], [3.53], [5.49], [3.69], [0.23], [2.61], [0.37], [5.72], [0.13], [0.16], [0.69], [0.59], [3.87], [2.71], [0.61], [8.29], [0.95], [1.11], [1.52], [1.93], [2.67], [4.83], [4.42], [-0.56], [1.9], [3.35], [3.47], [-0.77], [1.58], [3.08], [4.88], [1.53], [8.68], [3.32], [2.33], [2.82], [3.75], [5.6], [3.27], [1.68], [2.79], [2.19], [2.6], [2.86], [2.8], [1.83], [4.0], [1.67], [2.3], [3.66], [0.91], [2.69], [1.88], [4.04], [-0.05], [-0.28], [2.53], [1.31], [1.63], [2.58], [3.19], [3.32], [4.17], [-2.91], [1.18], [3.25], [0.23], [0.05], [3.91], [4.32], [2.02], [2.98], [2.73], [1.62], [2.0], [2.21], [0.44], [2.32], [3.64], [3.85], [-0.96], [3.39], [0.29], [-2.03], [3.75], [3.08], [2.66], [3.53], [2.14], [0.91], [3.01], [0.1], [2.84], [2.62], [0.46], [1.38], [4.72], [2.13], [7.57], [1.61], [2.1], [1.77], [1.99], [5.66], [1.33], [-1.13], [3.63], [4.9], [-1.2], [1.19], [0.67], [3.01], [0.96], [1.18], [5.18], [0.09], [1.25], [0.32], [-1.91], [4.9], [3.7], [3.94], [2.14], [-0.54], [3.11], [2.02], [1.69], [-0.2], [3.0], [1.38], [2.49], [5.09], [1.23], [2.03], [3.13], [6.01], [1.57], [-1.34], [7.6], [2.4], [0.85], [2.18], [0.68], [0.36], [0.76], [2.93], [1.15], [1.94], [3.35], [2.28], [1.18], [1.96], [1.0], [1.82], [3.25], [5.19], [2.22], [1.1], [1.13], [2.82], [-1.58], [3.42], [1.4], [-1.88], [0.45], [0.81], [1.37], [4.7], [0.82], [0.39], [1.73], [-0.05], [2.59], [-1.57], [1.38], [0.3], [4.12], [0.12], [-0.7], [0.98], [-0.55], [2.54], [2.96], [1.46], [0.86], [4.85], [0.16], [1.74], [2.27], [3.27], [3.99], [2.36], [2.68], [2.07], [3.01], [0.47], [2.51], [2.93], [0.3], [2.29], [0.49], [2.6], [0.86], [1.21], [-0.05], [4.67], [2.1], [1.1], [4.49], [-0.5], [4.51], [4.55], [1.72], [2.09], [2.37], [-0.66], [2.5], [3.56], [0.43], [2.99], [0.28], [2.14], [3.16], [4.04], [1.98], [3.11], [0.3], [3.08], [1.88], [5.81], [1.35], [1.59], [0.51], [2.65], [3.9], [1.9], [6.2], [2.5], [3.89], [3.25], [1.31], [0.08], [2.11], [0.1], [1.0], [4.19], [1.68], [5.86], [2.66], [0.1], [2.72], [2.38], [4.99], [2.11], [4.37], [6.72], [2.68], [0.33], [-0.23], [2.62], [0.74], [2.66], [8.35], [3.2], [0.31], [3.69], [3.12], [2.23], [0.75], [0.85], [3.04], [3.65], [0.9], [3.55], [5.01], [-0.99], [3.13], [3.39], [0.7], [3.15], [1.88], [-1.3], [3.89], [7.43], [1.78], [3.7], [0.15], [2.83], [3.21], [3.65], [1.79], [4.51], [1.28], [2.73], [0.26], [0.98], [1.94], [-0.35], [1.14], [2.11], [1.98], [2.94], [1.64], [-0.78], [3.34], [3.13], [0.24], [1.5], [4.3], [1.77], [5.1], [1.42], [1.19], [1.94], [3.91], [2.33], [3.1], [1.83], [3.9], [1.52], [1.36], [1.46], [-1.23], [2.7], [0.82], [2.54], [4.04], [3.13], [0.0], [3.26], [2.74], [-0.48], [1.7], [0.16], [1.16], [0.38], [2.08], [3.13], [0.81], [2.52], [3.13], [3.49], [2.35], [1.23], [1.86], [1.88], [0.2], [1.44], [-3.05], [3.74], [-0.47], [2.04], [3.56], [4.43], [1.9], [2.09], [2.0], [-0.06], [1.7], [6.21], [3.68], [0.85], [-0.06], [-0.88], [0.13], [0.98], [2.3], [3.76], [4.04], [0.26], [2.62], [3.3], [4.34], [2.24], [5.9], [0.67], [1.99], [2.55], [1.05], [0.76], [8.56], [3.33], [2.02], [0.59], [2.9], [2.95], [-3.17], [1.89], [0.67], [0.56], [2.62], [1.85], [2.4], [3.94], [4.63], [2.82], [3.05], [1.27], [0.53], [5.76], [1.53], [1.49], [3.98], [7.29], [4.75], [1.19], [4.21], [6.01], [4.2], [1.85], [-1.11], [2.6], [2.42], [2.12], [4.9], [1.44], [3.82], [3.38], [1.46], [1.01], [0.93], [3.15], [4.17], [3.64], [1.63], [2.1], [2.93], [2.0], [-0.62], [3.16], [3.18], [0.72], [1.48], [-0.24], [1.12], [2.33], [0.52], [1.96], [-0.27], [1.45], [4.14], [4.17], [3.08], [3.5], [-0.26], [-0.32], [4.5], [3.94], [0.92], [-1.74], [7.11], [4.03], [4.95], [1.24], [5.31], [3.83], [3.42], [9.29], [-0.41], [2.41], [1.56], [3.28], [3.79], [-0.3], [2.06], [3.37], [6.59], [3.2], [2.05], [1.13], [3.58], [3.34], [6.59], [3.65], [-1.33], [3.13], [-0.47], [2.94], [2.51], [1.47], [-0.81], [0.72], [0.55], [2.41], [0.81], [4.56], [0.16], [1.81], [3.91], [3.19], [-1.64], [0.6], [2.16], [2.73], [5.45], [1.11], [2.11], [2.46], [2.28], [7.12], [1.05], [-0.06], [2.28], [0.61], [-0.29], [2.27], [1.69], [1.43], [0.58], [6.54], [2.51], [3.26], [2.4], [-0.62], [2.16], [3.52], [-0.48], [3.55], [2.33], [4.62], [2.21], [4.43], [2.8], [4.12], [0.8], [2.8], [3.58], [2.86], [4.49], [1.13], [2.54], [4.62], [0.94], [-0.3], [2.74], [4.31], [3.39], [5.19], [2.16], [2.48], [1.55], [1.72], [-0.35], [1.9], [3.01], [-1.1], [0.6], [1.34], [7.48], [3.2], [3.73], [1.7], [1.76], [3.96], [1.02], [1.45], [3.14], [5.41], [5.0], [3.14], [0.95], [-0.21], [3.35], [3.88], [1.27], [4.29], [-1.3], [-1.32], [0.13], [1.81], [-1.05], [0.97], [0.37], [3.86], [1.05], [4.33], [-0.23], [6.84], [3.3], [5.43], [1.49], [-2.85], [2.89], [5.44], [2.8], [3.23], [4.09], [-0.85], [1.3], [3.55], [1.28], [0.6], [0.36], [5.35], [3.47], [1.44], [2.84], [1.76], [1.78], [1.08], [4.99], [0.61], [3.78], [-0.7], [3.17], [4.66], [0.62], [1.13], [1.0], [2.92], [3.59], [-1.49], [1.05], [2.68], [3.73], [2.74], [2.71], [-0.22], [1.9], [2.32], [-0.58], [2.39], [0.28], [1.35], [-1.23], [-0.42], [3.78], [2.74], [-1.85], [2.75], [5.02], [0.65], [2.03], [4.43], [1.27], [-0.17], [2.07], [1.26], [2.74], [-1.13], [0.89], [3.71], [5.77], [4.79], [4.92], [1.18], [3.59], [5.4], [4.29], [1.37], [0.73], [9.32], [-0.66], [2.38], [3.63], [1.99], [0.41], [1.79], [2.57], [0.83], [3.62], [0.8], [0.46], [5.16], [1.98], [2.81], [4.57], [0.91], [2.17], [1.61], [2.14], [3.58], [1.77], [0.82], [0.9], [4.12], [0.9], [2.07], [0.59], [2.26], [1.75], [4.28], [4.13], [0.66], [1.06], [6.6], [0.75], [4.69], [-1.05], [1.4], [2.64], [1.98], [1.16], [2.34], [3.52], [1.09], [2.96], [2.01], [1.25], [-2.39], [0.98], [4.64], [4.37], [3.3], [2.6], [8.5], [1.79], [2.37], [8.05], [1.49], [2.3], [2.66], [4.38], [2.81], [-0.52], [4.01], [3.58], [1.81], [0.04], [2.07], [0.51], [0.85], [2.76], [0.74], [2.28], [2.05], [2.28], [2.26], [0.43], [2.46], [2.55], [-2.61], [1.97], [8.18], [0.65], [5.25], [2.75], [1.52], [1.19], [-1.41], [3.1], [4.5], [0.04], [1.91], [-0.28], [0.76], [4.37], [4.12], [4.66], [-0.85], [0.13], [1.01], [0.62], [4.37], [5.75], [2.75], [0.88], [3.43], [6.14], [2.92], [0.4], [1.05], [2.3], [1.4], [-3.03], [1.0], [2.01], [4.08], [1.82], [2.84], [2.47], [3.2], [1.7], [5.25], [2.3], [4.59], [2.85], [1.76], [4.75], [0.36], [0.54], [2.18], [0.55], [2.1], [0.47], [1.44], [0.6], [-0.43], [-0.76], [1.29], [1.24], [1.7], [2.0], [0.81], [2.67], [0.66], [1.61], [-1.8], [1.43], [-1.82], [1.9], [2.05], [3.34], [2.58], [2.25], [1.2], [2.09], [5.12], [2.23], [2.68], [3.77], [1.82], [1.68], [4.06], [0.88], [2.6], [3.26], [3.35], [-0.66], [3.85], [5.8], [0.83], [2.82], [-0.96], [2.72], [4.26], [1.81], [-1.49], [2.1], [2.5], [2.06], [2.73], [3.32], [2.05], [2.75], [-2.54], [1.63], [0.33], [-0.56], [2.51], [1.58], [1.41], [4.98], [0.44], [0.56], [6.49], [2.37], [0.6], [2.35], [0.48], [1.43], [-1.03], [2.23], [1.04], [2.39], [2.27], [1.17], [1.25], [1.26], [5.84], [1.19], [3.23], [4.6], [3.03], [1.17], [3.38], [0.99], [4.3], [0.96], [2.27], [4.96], [2.67], [4.23], [2.81], [3.79], [-2.03], [0.72], [-1.25], [1.7], [2.34], [3.94], [2.62], [5.99], [1.57], [3.96], [1.48], [4.26], [0.71], [-0.56], [0.8], [5.68], [0.92], [2.2], [4.4], [5.28], [2.71], [0.11], [0.43], [0.97], [-0.33], [1.6], [5.44], [0.94], [2.24], [5.7], [3.8], [1.09], [2.37], [6.22], [4.28], [3.55], [2.2], [2.72], [2.68], [1.01], [1.14], [0.34], [3.14], [-0.47], [2.23], [-0.64], [3.49], [-1.8], [5.26], [3.14], [3.1], [0.95], [7.15], [3.5], [1.77], [3.39], [1.92], [1.75], [3.29], [2.54], [1.95], [-2.49], [6.47], [-2.2], [4.31], [2.56], [1.02], [2.46], [1.72], [-1.38], [-1.46], [-0.11], [3.94], [1.93], [1.26], [2.66], [0.32], [2.43], [1.63], [0.32], [1.47], [-0.3], [1.2], [0.12], [0.29], [0.86], [1.96], [0.95], [0.32], [-1.86], [5.57], [1.99], [2.8], [2.17], [0.91], [3.95], [3.99], [2.05], [2.85], [0.65], [2.38], [3.37], [1.76], [-0.95], [2.51], [0.93], [2.63], [5.47], [3.43], [-0.21], [1.24], [2.52], [0.03], [-0.15], [1.19], [-0.51], [-0.04], [3.42], [2.51], [4.49], [-0.23], [8.06], [1.36], [2.68], [1.36], [0.64], [0.87], [2.13], [1.9], [1.28], [4.25], [-0.06], [2.39], [-0.51], [-1.87], [4.83], [1.81], [4.73], [2.52], [2.59], [3.6], [1.98], [3.17], [8.23], [4.88], [-2.57], [2.3], [3.04], [1.57], [2.18], [0.69], [3.18], [2.08], [2.63], [1.18], [3.2], [2.81], [1.24], [4.25], [2.22], [4.93], [0.48], [2.41], [4.5], [1.3], [1.41], [1.34], [2.29], [0.44], [7.12], [-1.05], [2.3], [2.86], [2.98], [0.56], [1.27], [2.06], [3.81], [7.7], [3.6], [1.7], [6.97], [0.89], [-0.41], [2.74], [3.35], [1.02], [6.41], [-0.4], [1.21], [1.31], [3.41], [2.9], [3.24], [7.01], [3.29], [6.45], [-0.61], [0.97], [5.11], [1.48], [0.89], [1.81], [0.3], [3.05], [1.45], [5.3], [0.58], [3.33], [0.75], [0.7], [0.21], [2.99], [0.26], [2.73], [1.4], [2.62], [0.34], [4.2], [4.45], [2.47], [6.26], [0.74], [3.32], [1.03], [2.24], [2.75], [1.8], [0.76], [1.23], [0.28], [1.09], [2.6], [1.75], [2.41], [2.56], [0.98], [3.07], [-0.95], [6.0], [6.91], [0.94], [1.03], [2.19], [4.73], [6.26], [1.57], [1.94], [4.36], [1.05], [3.63], [3.23], [6.9], [1.0], [2.82], [3.6], [4.86], [-0.05], [5.95], [3.08], [1.66], [1.29], [3.01], [3.95], [0.4], [1.75], [4.98], [4.15], [1.78], [1.89], [2.06], [1.73], [3.66], [1.59], [4.6], [1.8], [6.39], [1.34], [1.2], [2.59], [0.38], [1.7], [3.3], [2.62], [2.41], [1.98], [-0.28], [2.61], [0.87], [-1.34], [0.23], [-0.03], [2.09], [1.93], [3.49], [1.61], [1.94], [3.68], [3.99], [2.82], [1.8], [5.87], [3.03], [3.0], [0.56], [1.0], [3.97], [-0.4], [4.05], [-0.9], [1.01], [2.72], [0.06], [3.23], [3.87], [-0.84], [0.92], [1.6], [0.56], [1.4], [3.37], [2.05], [0.69], [0.62], [0.15], [1.38], [2.39], [1.81], [1.86], [0.56], [4.09], [5.02], [0.15], [4.62], [1.12], [1.94], [2.6], [1.37], [3.55], [3.54], [1.09], [0.05], [3.92], [0.13], [3.44], [4.64], [2.98], [-0.2], [3.1], [0.09], [-0.45], [4.54], [3.77], [1.79], [2.14], [3.75], [1.87], [-1.22], [3.27], [4.85], [1.79], [3.81], [-0.05], [0.52], [-0.15], [2.28], [6.44], [5.74], [0.48], [0.67], [-0.71], [0.85], [3.4], [4.39], [2.52], [0.0], [2.43], [3.61], [6.11], [2.5], [-3.1], [3.37], [-0.17], [2.36], [-0.41], [0.0], [6.51], [2.03], [0.17], [5.81], [0.67], [4.49], [0.02], [0.08], [5.15], [1.69], [3.71], [1.73], [1.0], [0.26], [4.74], [3.63], [4.77], [2.9], [0.6], [3.54], [1.37], [3.92], [4.03], [6.68], [3.43], [-0.66], [1.09], [4.38], [0.07], [-1.06], [3.13], [1.22], [-0.03], [4.31], [1.52], [1.63], [0.57], [2.59], [4.66], [5.11], [1.17], [1.26], [0.39], [1.46], [2.3], [1.05], [1.7], [2.6], [4.86], [1.69], [0.88], [3.75], [1.16], [4.63], [0.58], [3.25], [0.58], [2.35], [1.03], [1.43], [0.26], [0.56], [0.9], [4.14], [0.07], [2.5], [0.96], [0.15], [2.85], [3.38], [2.77], [1.32], [3.54], [1.86], [2.03], [4.0], [1.34], [1.5], [1.54], [2.78], [-1.43], [1.64], [1.88], [0.12], [2.8], [2.67], [2.73], [2.4], [2.85], [1.69], [1.91], [4.95], [0.87], [3.17], [3.65], [2.42], [3.37], [1.99], [2.2], [2.91], [0.21], [5.32], [1.37], [1.42], [3.6], [0.54], [1.67], [4.47], [2.8], [1.73], [2.32], [5.62], [1.34], [0.5], [-2.54], [2.86], [5.17], [1.71], [3.37], [5.45], [-0.44], [5.42], [2.08], [-0.64], [-0.3], [2.79], [3.62], [3.06], [2.73], [2.96], [2.9], [5.36], [-0.92], [2.4], [2.7], [-0.04], [1.61], [5.8], [0.88], [2.24], [4.28], [3.72], [1.62], [6.25], [2.0], [1.79], [-0.81], [0.43], [1.59], [-0.18], [-0.35], [1.65], [1.22], [2.72], [3.94], [0.9], [1.62], [1.07], [3.59], [3.87], [1.67], [1.68], [0.15], [0.99], [-1.82], [5.5], [1.94], [-0.07], [2.78], [0.19], [2.4], [2.93], [-0.42], [0.83], [2.93], [4.58], [1.38], [0.68], [1.53], [2.12], [-1.47], [0.76], [0.48], [0.72], [4.14], [5.35], [0.57], [1.59], [1.98], [4.04], [2.86], [1.87], [2.76], [2.7], [4.27], [2.11], [-0.27], [2.11], [3.03], [1.66], [-0.73], [1.58], [1.11], [2.25], [3.48], [2.03], [-0.59], [1.22], [0.68], [5.9], [3.44], [2.14], [3.74], [0.49], [3.2], [5.15], [3.31], [-1.43], [3.0], [3.75], [1.57], [2.03], [3.13], [0.03], [3.85], [1.63], [4.81], [2.33], [0.27], [2.34], [0.63], [2.82], [4.54], [0.83], [3.83], [5.85], [2.21], [2.88], [5.17], [1.63], [2.07], [-2.27], [1.31], [1.2], [-1.14], [0.4], [5.5], [-0.92], [0.87], [8.19], [6.11], [1.83], [-2.0], [-1.59], [4.26], [0.16], [-0.83], [1.24], [3.78], [3.15], [0.74], [0.96], [1.82], [3.56], [3.47], [1.59], [3.65], [2.29], [2.63], [2.04], [2.52], [4.68], [2.42], [4.73], [2.22], [3.82], [0.3], [1.14], [8.77], [3.35], [0.7], [2.2], [3.13], [3.72], [2.96], [3.62], [1.57], [8.38], [5.39], [1.0], [0.15], [4.28], [2.06], [1.75], [1.03], [0.23], [1.64], [3.87], [0.38], [2.42], [-0.32], [1.59], [5.31], [1.51], [2.47], [1.73], [0.84], [4.49], [-1.54], [1.98], [0.62], [0.3], [2.97], [1.19], [-1.85], [1.55], [2.22], [3.91], [-2.07], [0.0], [4.48], [5.52], [-0.89], [0.97], [2.47], [0.5], [0.38], [-0.28], [3.76], [1.9], [-1.05], [2.3], [6.72], [-0.86], [-1.07], [4.17], [0.41], [-1.18], [2.5], [2.22], [0.78], [1.15], [3.49], [4.21], [0.83], [4.41], [1.61], [5.1], [-0.36], [2.23], [0.03], [-0.11], [2.04], [6.4], [0.53], [2.55], [-1.38], [4.28], [1.64], [2.21], [3.39], [2.48], [3.04], [2.86], [0.13], [3.24], [3.82], [1.81], [4.9], [0.97], [3.02], [1.41], [4.69], [7.97], [1.96], [3.83], [1.5], [2.25], [0.26], [-2.14], [0.93], [2.18], [2.53], [3.25], [1.75], [3.79], [3.21], [2.0], [0.78], [3.56], [3.21], [-0.42], [4.41], [3.82], [0.23], [3.25], [4.97], [1.24], [6.98], [0.84], [3.34], [3.12], [5.04], [0.98], [2.33], [-0.23], [4.58], [1.78], [5.19], [2.46], [2.21], [1.99], [2.17], [2.59], [-0.09], [2.92], [2.81], [1.81], [3.61], [0.58], [0.66], [1.88], [3.7], [3.69], [-1.35], [0.34], [-1.38], [0.32], [1.14], [6.39], [0.15], [-0.04], [3.15], [3.76], [0.83], [1.6], [1.54], [2.86], [4.27], [1.08], [3.88], [4.45], [2.05], [3.35], [4.2], [1.71], [2.29], [4.19], [0.46], [5.56], [0.48], [0.64], [1.44], [-0.69], [-4.64], [0.33], [0.04], [0.63], [3.2], [0.85], [3.27], [1.55], [3.43], [0.33], [5.06], [0.44], [3.05], [0.67], [2.1], [1.24], [0.76], [1.38], [3.31], [2.53], [5.76], [4.57], [-1.43], [2.09], [0.39], [2.45], [-2.28], [1.5], [3.91], [1.47], [1.38], [1.85], [0.89], [2.61], [4.09], [-2.84], [0.73], [-1.79], [-2.0], [3.4], [2.0], [2.18], [1.33], [4.21], [1.86], [0.34], [2.78], [1.4], [3.23], [2.71], [1.96], [1.75], [1.03], [0.08], [0.24], [2.98], [1.51], [2.14], [3.67], [0.255], [2.23], [-0.33], [1.41], [2.04], [3.08], [4.2], [0.09], [5.49], [3.03], [2.73], [1.29], [2.22], [1.81], [-0.19], [3.78], [2.94], [0.3], [0.59], [3.55], [1.16], [2.44], [1.28], [-0.55], [4.33], [3.41], [5.76], [3.72], [-1.21], [7.17], [-0.06], [-1.6], [4.06], [1.77], [1.6], [4.3], [0.01], [4.55], [1.72], [3.9], [4.33], [1.44], [3.71], [1.89], [2.26], [2.14], [2.88], [0.49], [2.0], [2.4], [4.4], [1.07], [1.39], [2.83], [3.3], [0.04], [2.49], [3.03], [3.8], [1.44], [5.67], [2.07], [0.87], [3.08], [3.13], [2.79], [0.18], [1.58], [1.14], [1.18], [-1.12], [3.35], [0.16], [0.53], [3.0], [1.4], [1.65], [0.52], [6.9], [2.94], [4.34], [4.04], [3.87], [2.61], [-0.36], [2.76], [1.74], [0.95], [-1.22], [1.85], [4.67], [0.33], [1.66], [2.41], [0.97], [-3.31], [1.28], [5.74], [4.45], [3.77], [7.91], [0.44], [1.87], [1.81], [3.44], [-1.88], [1.06], [3.44], [3.74], [-0.08], [0.56], [6.19], [3.41], [1.5], [2.32], [1.34], [-1.14], [0.97], [4.6], [1.41], [2.88], [4.54], [5.5], [2.15], [4.52], [1.17], [2.7], [1.75], [1.88], [4.27], [4.42], [5.51], [4.14], [1.84], [2.64], [5.83], [0.83], [2.18], [1.15], [2.69], [0.16], [0.45], [4.63], [1.96], [0.18], [1.81], [2.36], [1.73], [0.66], [1.76], [2.28], [0.16], [-0.8], [3.71], [2.41], [3.41], [-0.76], [0.9], [0.89], [2.4], [7.07], [-0.36], [2.68], [1.75], [0.101], [3.82], [5.31], [4.18], [0.87], [1.42], [3.69], [4.09], [1.51], [2.2], [2.84], [0.12], [3.16], [2.63], [0.95], [4.48], [2.2], [2.46], [3.05], [2.0], [3.26], [1.52], [1.13], [-0.3], [0.19], [-0.47], [2.27], [0.69], [2.68], [1.26], [-2.13], [5.27], [4.0], [1.12], [7.5], [2.66], [2.3], [0.62], [1.81], [3.73], [5.55], [1.71], [-0.86], [3.39], [0.61], [4.11], [2.92], [1.96], [0.46], [2.19], [-1.45], [2.11], [1.8], [1.66], [7.64], [1.61], [4.06], [2.36], [5.16], [0.42], [1.66], [4.69], [1.43], [1.13], [1.79], [2.73], [1.69], [1.62], [2.36], [3.0], [3.57], [3.51], [1.3], [1.64], [5.13], [-0.69], [5.77], [4.8], [5.14], [5.41], [3.1], [1.0], [2.97], [1.4], [3.1], [1.78], [4.03], [1.73], [3.42], [3.94], [0.89], [1.41], [6.08], [4.93], [2.05], [5.9], [3.4], [0.69], [2.65], [1.16], [0.99], [1.61], [6.58], [2.29], [1.73], [4.8], [0.23], [2.2], [3.12], [4.96], [2.15], [5.24], [0.23], [2.33], [1.21], [-0.06], [4.41], [2.24], [-0.54], [0.5], [2.81], [0.33], [3.45], [3.82], [2.8], [2.75], [5.7], [3.66], [2.68], [0.71], [1.35], [0.59], [8.14], [4.06], [-0.34], [1.76], [0.6], [4.47], [1.53], [4.48], [1.69], [-0.81], [2.37], [4.09], [3.21], [4.07], [-0.48], [2.45], [1.42], [0.4], [2.85], [2.81], [1.09], [1.43], [2.11], [0.17], [3.31], [1.63], [4.53], [-0.47], [1.2], [1.82], [4.44], [0.01], [3.15], [-1.27], [3.05], [0.9], [4.19], [-0.16], [1.4], [6.95], [3.24], [1.82], [2.34], [3.38], [1.8], [4.64], [4.96], [6.12], [2.87], [3.1], [1.49], [2.36], [0.37], [3.15], [0.28], [0.96], [3.27], [3.46], [2.13], [0.74], [-1.15], [1.68], [2.42], [3.61], [1.38], [4.33], [1.7], [-0.59], [5.58], [3.6], [3.81], [2.03], [1.03], [3.43], [2.28], [2.38], [2.5], [1.7], [0.2], [-0.16], [1.54], [4.11], [0.93], [1.86], [2.18], [2.34], [2.41], [6.23], [3.45], [3.51], [0.22], [0.25], [2.26], [3.3], [3.35], [3.86], [1.44], [-2.64], [0.72], [3.15], [2.0], [1.08], [0.42], [1.01], [-0.52], [4.15], [0.46], [3.93], [0.93], [1.82], [-1.51], [3.0], [0.86], [-0.9], [0.36], [7.41], [2.52], [2.03], [-0.66], [-0.24], [3.76], [1.16], [1.34], [2.15], [-0.16], [2.01], [4.53], [0.47], [-0.46], [1.16], [0.41], [0.2], [2.61], [1.1], [5.13], [2.61], [-0.12], [1.86], [-0.15], [0.02], [3.5], [2.35], [3.06], [3.28], [1.22], [4.47], [3.39], [3.28], [2.34], [1.2], [2.91], [1.61], [6.3], [1.85], [2.42], [3.35], [2.8], [1.32], [4.1], [6.5], [6.8], [2.78], [4.3], [4.79], [2.16], [4.22], [2.39], [2.45], [2.22], [-0.6], [1.04], [1.69], [6.78], [4.18], [1.87], [1.8], [2.4], [1.34], [3.1], [-1.52], [2.64], [0.8], [1.96], [6.3], [3.0], [5.5], [1.61], [0.36], [5.85], [6.44], [3.4], [3.89], [3.03], [3.97], [2.67], [0.76], [-1.38], [2.31], [-0.03], [2.72], [1.03], [3.26], [3.67], [1.63], [0.9], [-2.16], [3.06], [4.25], [2.07], [2.76], [1.75], [3.42], [2.52], [0.11], [2.33], [1.52], [1.94], [0.28], [1.01], [7.37], [5.55], [-1.08], [3.14], [4.64], [1.86], [2.4], [1.21], [1.13], [4.9], [2.88], [2.49], [0.35], [0.85], [-0.41], [0.79], [2.88], [0.33], [1.43], [2.18], [1.88], [2.61], [2.23], [6.0], [1.79], [2.96], [1.12], [1.2], [3.63], [4.63], [2.67], [0.2], [3.12], [3.53], [7.01], [4.24], [3.11], [-0.04], [2.79], [5.2], [-1.71], [2.82], [-2.52], [3.8], [2.6], [2.01], [-0.92], [4.66], [2.55], [1.02], [0.31], [0.12], [1.12], [0.91], [3.99], [2.5], [2.85], [2.75], [1.34], [2.95], [-0.9], [2.25], [2.05], [1.26], [0.89], [3.54], [4.45], [3.46], [1.33], [1.55], [0.86], [0.37], [1.7], [0.39], [1.29], [1.34], [1.87], [4.1], [2.82], [3.13], [0.83], [4.16], [-0.2], [2.95], [4.52], [0.68], [0.08], [3.96], [2.64], [0.91], [4.24], [-1.11], [2.24], [0.24], [1.47], [0.76], [4.73], [0.12], [1.85], [7.4], [4.35], [5.03], [-1.3], [2.6], [0.54], [2.2], [1.95], [-0.31], [3.02], [-0.87], [1.22], [3.53], [7.84], [-1.2], [1.15], [-1.87], [-0.27], [1.74], [0.89], [2.71], [0.4], [0.51], [2.98], [2.14], [1.81], [2.3], [6.11], [2.06], [1.5], [2.42], [7.04], [3.6], [-0.1], [1.27], [3.41], [2.56], [2.3], [2.9], [1.26], [5.02], [-0.65], [3.72], [-0.3], [2.74], [1.87], [1.59], [1.1], [4.27], [-0.9], [1.6], [1.29], [3.18], [2.85], [1.14], [2.2], [4.4], [2.62], [4.51], [3.32], [0.29], [3.04], [3.27], [1.13], [1.74], [0.9], [0.3], [3.38], [3.5], [-0.42], [-0.99], [1.04], [3.01], [0.58], [1.77], [1.25], [2.68], [5.74], [1.97], [2.73], [1.73], [1.8], [3.37], [2.46], [3.43], [0.6], [2.68], [2.0], [0.86], [3.4], [-0.53], [3.6], [-1.0], [1.74], [4.51], [1.53], [1.79], [1.27], [1.55], [0.65], [-1.7], [0.4], [4.22], [2.71], [1.17], [5.51], [2.32], [3.7], [0.37], [6.65], [-0.38], [2.87], [1.73], [1.19], [2.02], [0.91], [-0.6], [7.28], [2.14], [0.12], [-0.02], [1.62], [3.74], [2.88], [2.06], [7.17], [3.04], [5.49], [5.47], [-0.22], [2.18], [1.34], [-1.1], [3.82], [2.45], [3.89], [-0.35], [1.97], [2.35], [1.87], [3.71], [4.55], [2.85], [0.99], [2.38], [1.55], [3.12], [0.63], [1.4], [3.33], [-0.1], [2.98], [1.41], [1.02], [2.03], [0.52], [2.98], [2.26], [6.61], [-0.43], [1.19], [3.71], [2.53], [0.44], [0.75], [0.31], [0.91], [2.82], [1.1], [3.88], [-0.34], [6.85], [3.58], [0.85], [2.99], [0.69], [-0.64], [-1.56], [2.11], [1.57], [0.84], [1.5], [1.88], [1.05], [1.4], [4.09], [2.57], [4.02], [2.24], [0.27], [2.68], [3.92], [-0.13], [-1.14], [1.57], [2.53], [1.65], [-1.32], [-0.07], [2.18], [-1.03], [2.15], [1.17], [4.56], [1.62], [3.8], [3.18], [0.86], [-1.78], [3.69], [1.77], [5.49], [1.63], [0.94], [0.47], [1.31], [4.6], [2.45], [1.16], [3.98], [5.76], [2.2], [-0.21], [8.06], [1.69], [1.67], [1.1], [2.42], [0.83], [3.05], [2.49], [6.63], [3.79], [1.71], [2.3], [0.05], [2.83], [4.81], [0.95], [2.65], [4.89], [2.6], [3.56], [0.91], [4.5], [1.15], [0.82], [-1.5], [2.1], [1.78], [0.34], [0.94], [4.78], [4.62], [2.51], [-1.07], [3.23], [3.27], [1.28], [0.25], [-0.92], [1.48], [-0.96], [3.7], [2.03], [0.86], [3.14], [0.63], [4.94], [9.07], [3.23], [2.11], [0.63], [1.23], [0.21], [4.2], [3.3], [2.97], [2.71], [-0.74], [1.81], [3.78], [0.75], [3.48], [3.68], [1.78], [3.78], [2.1], [3.79], [3.6], [-0.07], [-1.44], [2.1], [2.96], [0.76], [2.06], [6.3], [3.18], [2.25], [-0.37], [5.73], [1.07], [0.4], [0.46], [2.56], [4.1], [3.95], [3.19], [4.75], [2.41], [-0.49], [1.11], [1.72], [0.35], [1.7], [3.0], [2.17], [0.14], [-0.45], [5.34], [3.81], [1.02], [2.58], [0.41], [0.95], [4.1], [3.27], [5.08], [0.47], [4.34], [0.12], [4.68], [1.77], [2.5], [2.09], [0.2], [1.97], [0.84], [2.42], [2.1], [-0.29], [1.42], [1.87], [2.37], [2.76], [1.4], [3.09], [2.05], [1.98], [4.05], [1.64], [4.99], [4.32], [-3.49], [0.65], [4.05], [-2.8], [4.48], [2.76], [2.31], [1.58], [1.92], [0.32], [-0.4], [5.2], [7.35], [-0.99], [0.98], [3.77], [5.44], [-0.49], [1.13], [4.04], [-0.45], [1.42], [2.04], [0.54], [1.89], [-1.41], [1.0], [2.25], [0.04], [5.28], [5.69], [1.39], [1.31], [3.99], [2.38], [2.62], [1.89], [3.56], [1.03], [1.36], [1.88], [-0.52], [3.19], [2.59], [2.59], [3.31], [0.12], [2.51], [1.13], [1.26], [6.17], [0.0], [3.27], [2.09], [2.61], [0.92], [3.18], [2.03], [1.17], [2.1], [2.37], [3.03], [1.14], [1.48], [2.91], [3.55], [1.96], [5.45], [1.48], [1.92], [0.45], [4.64], [2.4], [1.3], [1.19], [1.91], [2.72], [-0.2], [1.33], [2.29], [-0.37], [3.79], [3.84], [1.36], [0.36], [0.72], [2.48], [-2.28], [1.37], [7.55], [3.0], [2.14], [0.81], [2.26], [0.03], [3.53], [2.03], [0.27], [5.72], [3.0], [0.66], [4.33], [-0.6], [2.48], [4.68], [3.14], [-1.11], [1.39], [4.24], [3.1], [2.84], [2.59], [2.35], [-0.31], [0.72], [-1.59], [2.37], [2.8], [1.27], [2.24], [2.2], [4.11], [1.99], [0.07], [0.96], [0.14], [0.28], [2.47], [1.14], [2.82], [1.18], [1.19], [2.88], [1.64], [2.41], [0.23], [-0.09], [2.9], [-0.07], [4.28], [3.63], [1.58], [2.26], [0.16], [1.86], [0.08], [4.57], [0.33], [0.84], [-0.67], [5.0], [-0.29], [3.33], [1.58], [3.35], [-1.4], [3.18], [4.45], [3.17], [3.09], [3.59], [1.51], [0.53], [-0.4], [1.29], [1.63], [2.64], [0.91], [1.71], [-0.93], [1.18], [2.7], [0.21], [0.32], [0.6], [0.79], [1.2], [2.21], [8.39], [2.25], [2.03], [3.31], [0.77], [1.13], [2.37], [1.25], [3.3], [0.6], [0.51], [2.01], [1.75], [1.04], [4.3], [2.71], [2.64], [2.08], [1.26], [4.35], [2.84], [1.68], [1.16], [1.02], [-0.67], [-0.08], [-3.54], [2.74], [-0.1], [2.8], [0.34], [0.65], [0.93], [0.6], [-0.23], [4.11], [1.46], [1.98], [0.81], [4.7], [2.47], [1.0], [3.17], [0.14], [1.58], [-0.89], [-0.48], [1.59], [-0.53], [2.53], [3.53], [-1.05], [4.3], [3.6], [1.79], [2.02], [-0.13], [-0.26], [3.37], [2.13], [4.1], [0.16], [1.25], [0.79], [1.88], [2.24], [3.52], [2.84], [0.71], [1.28], [0.21], [0.51], [-0.1], [3.54], [1.39], [2.73], [0.42], [0.62], [2.29], [2.59], [-0.43], [3.44], [7.6], [1.15], [2.6], [-0.47], [-0.22], [1.67], [2.39], [-0.8], [2.86], [3.1], [1.05], [2.55], [0.56], [0.87], [2.26], [7.04], [1.91], [2.81], [5.13], [-2.23], [1.92], [4.56], [1.06], [7.1], [2.12], [3.88], [3.09], [3.8], [1.35], [1.88], [0.7], [1.9], [2.07], [2.78], [1.72], [3.12], [1.66], [0.8], [0.76], [-2.03], [5.38], [3.56], [1.4], [2.41], [0.32], [0.99], [3.67], [4.06], [6.51], [2.05], [4.55], [4.99], [-0.47], [2.78], [1.7], [6.0], [1.67], [3.72], [4.55], [3.57], [3.8], [2.1], [1.8], [-0.26], [-1.89], [-0.31], [0.37], [3.42], [2.75], [2.48], [2.43], [4.54], [1.26], [0.4], [-0.22], [0.28], [5.05], [3.49], [2.08], [1.12], [2.26], [-0.61], [1.91], [2.62], [3.11], [2.8], [0.5], [-1.73], [2.62], [0.23], [1.92], [3.32], [2.63], [1.77], [2.07], [2.5], [1.43], [-0.55], [8.62], [1.17], [4.28], [0.6], [0.54], [-2.12], [2.87], [4.64], [3.21], [5.88], [3.99], [0.85], [2.53], [3.47], [4.8], [3.35], [4.55], [2.1], [4.38], [2.83], [4.44], [0.97], [2.03], [-0.41], [0.62], [4.3], [1.82], [0.24], [2.22], [1.0], [-1.19], [1.93], [-1.41], [2.6], [-0.9], [3.08], [4.89], [0.63], [1.41], [-0.8], [2.42], [-0.75], [1.67], [2.08], [1.88], [0.96], [1.67], [0.41], [-0.71], [0.94], [2.74], [1.23], [0.77], [0.59], [2.42], [5.02], [1.2], [3.58], [1.88], [1.83], [0.61], [2.19], [-0.48], [-0.76], [1.51], [1.54], [2.51], [-0.62], [3.84], [0.47], [2.15], [1.92], [1.52], [0.9], [4.53], [3.09], [3.16], [1.86], [0.87], [1.06], [4.74], [2.19], [3.4], [1.46], [2.43], [2.62], [0.38], [3.75], [4.73], [3.4], [-2.75], [1.35], [2.06], [0.61], [5.5], [1.96], [2.21], [1.8], [1.23], [2.31], [1.97], [2.72], [-1.23], [1.81], [1.15], [6.14], [0.99], [2.9], [1.63], [3.77], [0.6], [1.6], [4.48], [1.54], [2.23], [2.07], [4.19], [3.37], [1.61], [1.86], [1.24], [2.72], [0.83], [3.88], [1.82], [2.84], [0.57], [1.0], [2.69], [1.04], [2.29], [0.01], [2.09], [4.15], [1.71], [3.11], [0.35], [2.5], [1.63], [2.14], [1.85], [-1.18], [1.53], [0.21], [0.16], [3.5], [1.6], [1.46], [-0.3], [0.04], [2.53], [1.79], [5.07], [0.58], [1.13], [-1.54], [-0.37], [0.65], [-0.87], [2.45], [2.59], [0.48], [2.36], [0.8], [0.2], [2.84], [2.2], [1.96], [2.26], [4.47], [2.19], [3.97], [-0.54], [2.32], [0.28], [-1.52], [4.49], [1.13], [4.85], [3.63], [2.51], [1.63], [3.62], [2.47], [2.57], [3.63], [4.31], [0.8], [3.93], [3.45], [0.3], [2.3], [4.15], [2.07], [1.31], [2.5], [2.77], [3.72], [4.36], [2.96], [0.84], [2.6], [-0.64], [0.06], [2.59], [-0.79], [1.85], [2.4], [3.81], [1.37], [0.82], [2.3], [3.29], [1.47], [5.49], [2.76], [1.65], [1.64], [4.1], [1.88], [1.04], [3.58], [4.45], [0.86], [3.19], [1.54], [3.5], [1.81], [1.66], [-1.57], [1.7], [3.95], [9.14], [1.94], [2.51], [0.07], [1.47], [0.6], [4.11], [0.22], [2.31], [3.01], [-0.67], [1.8], [4.08], [-0.92], [3.78], [-3.1], [1.15], [2.57], [2.67], [0.29], [-1.24], [1.94], [-0.17], [2.2], [2.39], [2.0], [6.67], [3.3], [1.0], [3.23], [2.16], [4.3], [0.49], [0.1], [2.9], [5.89], [-0.21], [1.38], [1.23], [0.09], [2.29], [-0.05], [0.05], [5.81], [1.07], [7.71], [3.03], [1.28], [2.66], [-0.29], [1.17], [1.59], [3.21], [0.59], [2.28], [0.38], [-1.37], [2.47], [4.36], [-0.35], [0.42], [2.62], [1.93], [2.32], [6.64], [4.42], [0.22], [-0.5], [2.79], [6.37], [2.03], [1.09], [2.98], [-0.26], [1.03], [3.18], [4.4], [3.11], [0.13], [3.5], [3.4], [1.36], [2.34], [-0.62], [4.35], [2.89], [3.62], [0.71], [1.73], [1.47], [5.69], [0.0], [3.06], [-0.33], [1.68], [1.04], [2.16], [3.48], [2.33], [3.38], [-0.29], [2.23], [1.58], [0.43], [1.51], [-0.19], [0.12], [3.42], [1.52], [2.58], [1.8], [2.65], [-0.53], [2.46], [4.12], [0.7], [2.05], [1.55], [3.28], [1.77], [4.22], [-0.68], [2.12], [0.76], [1.71], [2.83], [4.7], [4.49], [3.18], [1.17], [2.21], [-0.84], [4.47], [-0.67], [2.62], [0.48], [3.66], [1.59], [2.48], [2.4], [1.12], [5.27], [2.74], [2.22], [1.59], [3.9], [-1.85], [1.41], [3.65], [-0.74], [2.95], [1.56], [1.25], [0.53], [-0.16], [1.31], [3.41], [2.52], [2.8], [1.47], [1.31], [5.53], [0.7], [2.31], [7.02], [1.8], [2.71], [-0.66], [0.97], [4.25], [1.64], [3.75], [-1.38], [0.73], [1.52], [2.85], [0.62], [1.31], [-0.83], [1.87], [-1.1], [2.45], [1.95], [1.98], [2.21], [-0.89], [0.25], [6.73], [-0.46], [3.82], [1.12], [2.14], [2.73], [0.2], [4.48], [2.56], [8.84], [5.6], [2.92], [1.02], [3.51], [3.65], [3.29], [4.05], [1.51], [4.49], [1.32], [2.5], [1.28], [8.1], [2.45], [4.5], [3.61], [0.15], [-0.74], [2.31], [1.6], [3.92], [2.91], [2.67], [-4.2], [1.12], [0.02], [2.69], [4.25], [1.12], [3.09], [0.3], [1.96], [3.03], [2.18], [1.75], [-1.97], [2.03], [1.57], [3.08], [5.08], [1.17], [1.06], [3.3], [2.0], [1.47], [1.2], [2.54], [1.2], [3.45], [0.22], [0.98], [1.1], [0.64], [2.24], [3.63], [-0.53], [3.17], [0.65], [1.41], [2.1], [2.66], [-0.87], [4.44], [3.8], [2.78], [7.0], [5.47], [1.82], [2.24], [5.5], [1.01], [6.92], [2.36], [1.34], [3.77], [0.76], [4.62], [0.48], [4.93], [2.95], [-0.5], [2.48], [0.54], [1.02], [0.65], [1.34], [1.4], [3.0], [3.62], [0.19], [3.71], [0.55], [1.56], [0.45], [3.53], [3.05], [1.2], [0.43], [5.16], [2.02], [-3.69], [1.94], [0.45], [1.76], [1.4], [2.92], [5.69], [0.59], [-1.66], [2.01], [4.3], [2.45], [1.33], [0.25], [1.81], [1.91], [2.82], [1.0], [1.26], [4.7], [1.23], [3.54], [0.98], [4.94], [5.07], [1.75], [0.3], [3.63], [1.03], [2.71], [1.95], [1.7], [-2.11], [1.34], [3.1], [1.58], [0.01], [4.15], [2.78], [2.04], [2.69], [0.99], [5.96], [0.52], [0.69], [4.69], [1.42], [0.97], [7.8], [4.06], [0.69], [7.39], [2.61], [-0.16], [3.33], [4.8], [1.95], [3.12], [5.63], [-2.95], [3.31], [0.77], [3.27], [2.55], [4.73], [-0.03], [1.06], [0.58], [1.91], [4.87], [0.63], [3.02], [2.01], [0.37], [5.51], [2.14], [2.55], [2.41], [2.04], [2.84], [2.66], [3.43], [-3.19], [1.39], [5.14], [-0.48], [0.51], [-1.53], [2.35], [0.69], [4.04], [4.54], [1.38], [3.2], [-2.3], [1.61], [1.6], [2.62], [1.89], [1.7], [7.78], [0.51], [5.13], [3.7], [3.9], [4.47], [5.6], [1.24], [2.9], [2.37], [4.3], [2.75], [0.74], [1.34], [1.69], [4.0], [0.76], [0.19], [0.7], [-2.92], [2.09], [0.33], [0.93], [0.03], [2.91], [4.41], [-1.41], [1.35], [2.32], [4.0], [0.09], [3.3], [2.21], [1.4], [1.18], [1.11], [3.57], [0.06], [3.5], [3.57], [3.92], [4.11], [6.29], [3.8], [2.57], [-3.05], [1.95], [2.1], [-0.66], [1.6], [-1.33], [1.12], [2.25], [0.49], [2.3], [3.78], [1.56], [1.52], [2.11], [0.7], [0.28], [2.15], [0.78], [4.22], [1.29], [0.44], [1.62], [0.56], [0.41], [0.85], [7.1], [-0.43], [3.41], [-1.45], [4.38], [2.49], [6.89], [0.76], [1.22], [4.48], [5.15], [1.98], [1.76], [2.3], [2.53], [3.21], [2.19], [1.53], [0.49], [6.14], [4.01], [2.44], [0.79], [0.22], [1.15], [-0.27], [2.1], [1.36], [0.13], [1.48], [3.22], [1.22], [3.3], [-0.4], [3.55], [0.86], [-1.16], [4.75], [4.45], [2.75], [3.51], [2.35], [4.25], [1.75], [0.77], [0.62], [0.83], [1.84], [6.55], [1.14], [2.49], [0.19], [1.4], [3.63], [3.21], [1.05], [2.12], [1.28], [1.7], [4.71], [0.76], [1.11], [2.03], [4.13], [2.17], [4.2], [2.8], [3.14], [5.35], [2.79], [2.76], [2.38], [4.18], [4.76], [2.24], [1.55], [2.56], [3.11], [4.87], [-0.93], [-0.65], [3.14], [1.19], [4.95], [0.67], [-0.4], [2.31], [2.04], [1.17], [2.32], [1.6], [0.33], [3.4], [0.24], [4.22], [1.5], [4.34], [3.81], [0.88], [3.6], [0.64], [3.03], [2.41], [0.73], [2.62], [1.63], [2.72], [2.32], [7.75], [0.7], [2.54], [0.98], [1.15], [2.14], [-1.47], [2.41], [2.15], [3.18], [0.3], [2.64], [-2.32], [2.41], [3.66], [2.18], [3.28], [6.41], [0.53], [1.14], [2.27], [1.12], [4.1], [2.71], [3.27], [1.0], [3.69], [2.29], [1.46], [2.72], [2.1], [0.86], [1.53], [1.11], [3.28], [-0.73], [7.1], [3.4], [1.05], [2.4], [0.34], [-2.51], [0.76], [0.67], [0.36], [0.28], [0.4], [0.35], [3.11], [-0.26], [1.94], [-1.85], [-0.4], [-0.36], [0.07], [0.99], [0.47], [2.61], [5.12], [4.27], [3.42], [3.1], [1.14], [3.76], [1.99], [1.77], [2.1], [1.04], [7.0], [-0.72], [1.51], [-0.48], [2.4], [3.48], [1.66], [2.27], [0.25], [0.9], [5.13], [1.4], [1.62], [3.61], [3.04], [2.62], [-0.4], [6.31], [4.67], [6.13], [0.96], [3.36], [1.6], [1.12], [-0.44], [3.05], [0.22], [0.14], [2.81], [1.28], [2.67], [3.04], [3.17], [3.06], [3.0], [0.34], [1.75], [1.86], [3.51], [2.01], [4.41], [4.5], [3.01], [-1.7], [2.46], [1.79], [3.18], [2.96], [3.3], [2.44], [2.19], [2.8], [0.71], [0.09], [3.49], [0.89], [1.68], [4.59], [2.57], [-1.31], [0.69], [0.86], [-0.99], [1.98], [1.9], [-0.47], [0.97], [0.95], [-0.35], [5.9], [-1.1], [2.8], [-1.33], [2.55], [-1.77], [2.42], [1.73], [0.44], [4.3], [2.79], [2.74], [2.75], [3.61], [0.76], [0.65], [1.28], [1.61], [1.1], [1.49], [-0.85], [0.18], [1.65], [3.74], [5.66], [1.95], [2.02], [3.63], [2.67], [2.96], [3.03], [3.01], [0.36], [3.22], [2.4], [2.17], [-1.24], [6.03], [5.76], [2.92], [2.05], [3.3], [2.37], [1.83], [0.74], [3.67], [1.0], [1.63], [3.56], [-1.11], [0.18], [1.74], [-1.05], [0.84], [1.55], [3.04], [1.68], [2.3], [1.15], [-0.67], [0.9], [2.76], [2.92], [0.99], [-1.37], [3.15], [2.13], [0.17], [2.7], [1.26], [0.77], [0.55], [3.39], [1.69], [2.3], [2.04], [2.63], [1.78], [1.42], [3.58], [5.4], [0.53], [2.11], [3.69], [3.29], [1.74], [1.93], [0.84], [0.99], [1.96], [0.88], [0.43], [2.9], [3.19], [2.52], [3.08], [0.86], [1.68], [1.26], [-1.59], [5.18], [-0.22], [-1.22], [2.05], [2.37], [3.03], [-1.97], [0.76], [2.93], [0.55], [0.4], [-2.44], [1.29], [3.25], [2.56], [0.17], [0.26], [1.88], [4.22], [3.42], [3.67], [0.69], [5.06], [1.37], [5.54], [0.65], [2.14], [0.58], [2.93], [1.41], [2.19], [3.0], [1.72], [2.22], [1.37], [3.42], [-2.35], [2.38], [2.72], [0.47], [0.79], [2.85], [2.22], [1.69], [3.23], [2.13], [1.88], [2.1], [2.24], [-1.4], [2.22], [2.15], [2.06], [2.33], [2.5], [0.79], [2.68], [3.3], [3.0], [1.14], [7.43], [3.8], [7.06], [-0.71], [2.06], [-0.44], [4.46], [4.27], [4.35], [1.73], [0.95], [1.82], [2.0], [-1.93], [0.96], [0.52], [1.71], [3.53], [1.05], [4.2], [1.96], [1.52], [1.51], [1.04], [3.92], [2.09], [3.12], [0.78], [3.22], [1.38], [3.3], [6.3], [4.11], [0.94], [1.21], [3.72], [1.6], [1.74], [-0.49], [2.05], [2.9], [-1.78], [1.27], [-1.21], [3.44], [5.87], [-1.1], [-0.24], [1.33], [1.1], [4.01], [2.24], [3.46], [2.47], [4.36], [3.2], [2.52], [-0.66], [0.24], [2.72], [0.39], [1.86], [1.6], [1.28], [2.0], [2.3], [-0.13], [2.74], [3.24], [0.4], [2.71], [2.22], [0.25], [2.08], [1.51], [1.28], [2.97], [3.87], [1.06], [-1.35], [1.63], [0.66], [2.3], [1.14], [0.29], [0.98], [-1.07], [4.26], [1.64], [-0.02], [2.8], [1.15], [3.05], [2.18], [1.98], [0.45], [0.22], [0.85], [0.78], [0.93], [0.8], [2.0], [1.38], [1.4], [1.95], [1.83], [1.0], [0.95], [3.22], [2.2], [1.68], [-1.73], [1.91], [2.83], [-0.96], [2.65], [0.83], [2.07], [3.04], [0.57], [2.06], [3.64], [3.53], [-0.36], [3.84], [2.94], [0.31], [1.45], [2.52], [2.94], [1.16], [2.25], [5.99], [1.37], [3.36], [2.03], [-0.7], [5.14], [6.95], [5.71], [2.37], [0.29], [1.77], [0.99], [7.38], [1.23], [3.65], [3.04], [2.06], [1.68], [7.45], [-0.33], [1.47], [2.4], [3.9], [4.48], [2.15], [1.83], [3.0], [-0.29], [1.93], [3.16], [4.49], [3.55], [5.37], [-0.75], [3.21], [4.05], [0.5], [5.04], [2.56], [0.96], [0.36], [1.91], [1.17], [3.72], [1.99], [3.6], [0.73], [2.6], [1.58], [0.45], [4.25], [2.31], [2.32], [3.08], [6.14], [4.05], [0.25], [3.36], [7.75], [0.93], [2.26], [0.98], [2.6], [1.69], [2.24], [3.41], [4.44], [-0.6], [1.1], [0.94], [2.56], [3.0], [2.0], [-2.41], [1.73], [0.65]]
[[1.1615215054148702], [1.2359708466724162], [1.1508858852352206], [0.8743597605643351], [0.09264167736010129], [0.5233842946359037], [-0.42318590135289663], [0.37980342221063623], [1.4752723007145288], [0.6297404964323979], [0.17240882870747204], [-0.6305804948560608], [2.4537493572422773], [1.3104201879299622], [1.2678777072113643], [-0.19983787758025837], [-0.12007072623288761], [0.9328556715524072], [-0.625262684766236], [0.1405019681685237], [-0.9496491002455439], [-0.029667954705867278], [-0.6412161150357101], [-0.7263010764729058], [0.24154035987519337], [2.251672573828938], [-2.1195673200069827], [-2.64603051889963], [0.3053540809530901], [-0.09879948587358871], [0.21495130942606985], [0.5499733450850272], [1.6294887933194457], [-1.9334439668631174], [2.576058989308246], [-0.4497749518020202], [-0.7422545067423799], [-1.7579562338989014], [2.9376700754163267], [-0.7847969874609776], [-1.157043693748708], [2.3899356361643807], [-1.5080191596771397], [1.6507600336787445], [-0.15729539686166058], [-1.5877863110245105], [0.6137870661629239], [-1.2687177056350272], [0.039463576461854034], [0.32662532131238897], [-0.6518517352153596], [0.7786391789474902], [1.3901873392773332], [-0.720983266383081], [-0.47636400225114384], [1.1562036953250452], [-0.17856663722095947], [-0.5348599132392159], [-0.6943942159339573], [-0.7582079370118541], [1.225335226492767], [-1.7526384238090769], [-0.3753256105444742], [-0.42318590135289663], [-0.9177422397065957], [-1.3591204771620475], [-1.157043693748708], [0.16709101861764744], [0.4010746625699351], [0.6244226863425734], [-0.8645641388083485], [0.7892747991271397], [0.3159897011327395], [-0.6997120260237822], [-0.4285037114427213], [-0.3753256105444742], [-0.7901147975508024], [-1.5611972605753868], [-0.4497749518020202], [0.16709101861764744], [-0.662487355395009], [-0.12538853632271232], [-0.019032334526217828], [2.3367575352661336], [0.6403761166120474], [-0.7847969874609776], [0.8849953807439845], [0.28940065068361603], [-1.6675534623718813], [0.40639247265975975], [-0.28492283901745385], [-0.24238035829885618], [2.2197657132899895], [-0.5827202040476382], [-0.17856663722095947], [1.092389974247149], [-0.986873770874317], [1.044529683438726], [-1.5186547798567889], [-0.8167038479999259], [1.0019872027201282], [0.8052282293966138], [-1.0400518717725642], [-0.7475723168322046], [-1.5133369697669643], [0.5978336358934496], [-1.0825943524911619], [-0.6571695453051845], [-0.7156654562932563], [0.8743597605643351], [-0.5401777233290405], [0.05541700673132833], [-0.8592463287185237], [-1.8483590054259218], [-0.6837585957543079], [-0.9602847204251934], [-1.7260493733599533], [-0.6412161150357101], [-0.7316188865627304], [1.3157379980197872], [0.24154035987519337], [0.09264167736010129], [-0.7901147975508024], [0.459570573558007], [1.6294887933194457], [-0.2796050289276291], [0.6456939267018723], [-0.5827202040476382], [0.858406330294861], [0.24685816996501822], [2.2038122830205156], [-0.7369366966525551], [-0.15729539686166058], [-0.6412161150357101], [0.3159897011327395], [-1.843041195336097], [-0.08284605560411454], [2.613283659937019], [-1.348484856982398], [2.171905422481567], [-1.369756097341697], [-0.06689262533464048], [-1.045369681862389], [-1.5080191596771397], [0.7520501284983665], [-1.2633998955452026], [-1.045369681862389], [-0.30619407937675275], [-0.3965968509037731], [0.9541269119117061], [-1.1942683643774812], [0.6722829771509957], [0.6563295468815217], [-0.1626132069514853], [1.065800923798025], [-0.5135886728799169], [-0.06689262533464048], [-0.6571695453051845], [2.480338407691401], [-1.5984219312041599], [0.7680035587678409], [-0.5774023939578136], [-0.21579130784973255], [1.2306530365825916], [-0.6571695453051845], [0.34789656167168787], [-1.1251368332097598], [0.012874526012730526], [-0.9709203406048429], [-0.5880380141374629], [-0.47636400225114384], [-0.4816818123409686], [0.5233842946359037], [1.6294887933194457], [0.7307788881390677], [-0.3381009399157011], [-0.15197758677183584], [-0.42318590135289663], [1.7996587161938364], [0.1139129177194002], [-0.8113860379101013], [0.7786391789474902], [-0.19452006749043366], [0.6669651670611711], [-1.4867479193178408], [0.9381734816422318], [-0.2636515986581551], [0.5340199148155531], [-0.9602847204251934], [0.21495130942606985], [2.8685385442486058], [1.6028997428703222], [0.40639247265975975], [0.842452900025387], [0.1830444488871215], [-0.7635257471016788], [-0.02435014461604267], [0.5021130542766048], [-0.8911531892574721], [-0.6943942159339573], [-0.28492283901745385], [0.5446555349952026], [-0.3115118894665775], [0.8158638495762632], [-0.6305804948560608], [-0.3168296995564022], [1.9379217785292795], [-1.21553960473678], [0.5659267753545015], [-0.47636400225114384], [-0.45509276189184494], [-1.4122985780602948], [0.3744856121208114], [-0.300876269286928], [1.0764365439776746], [-0.09348167578376398], [-0.05093919506516618], [0.044781386551678876], [0.6776007872408206], [0.1405019681685237], [0.30003627086326545], [-0.7528901269220294], [1.2146996063131172], [1.1881105558639937], [0.3638499919411619], [-0.5082708627900923], [0.34789656167168787], [0.5499733450850272], [-1.4707944890483666], [-0.5242242930595664], [-1.1357724533894091], [-0.2636515986581551], [1.1402502650555715], [-0.4976352426104428], [0.028827956282204584], [0.2043156892464204], [0.05009919664150349], [-0.013714524436393219], [0.9913515825404791], [1.331691428289261], [1.3210558081096118], [1.491225730984003], [-0.056257005154991026], [-0.8326572782694003], [2.0123711197868253], [0.6988720276001195], [-0.10943510605323815], [-0.853928518628699], [0.17240882870747204], [-1.4548410587788925], [0.7414145083187171], [0.47020619373765643], [-0.29555845919710333], [1.8953792978106816], [-0.23706254820903144], [0.076688247090627], [0.05541700673132833], [0.023510146192379976], [0.5393377249053778], [-0.8486107085388743], [0.044781386551678876], [-2.2259235218034767], [0.9009488110134588], [0.9541269119117061], [-1.4973835394974904], [1.2412886567622408], [-0.5561311535985146], [0.9381734816422318], [-1.3165779964434496], [-0.23706254820903144], [1.64544222358892], [-0.4444571417121955], [-0.16793101704131003], [-1.6835068926413557], [0.342578751581863], [0.6297404964323979], [0.8052282293966138], [1.3955051493671577], [-2.720479860157176], [1.0019872027201282], [-0.18920225740060892], [-0.15197758677183584], [0.018192336102555134], [1.4167763897264567], [0.37980342221063623], [-1.6037397412939847], [2.134680751852794], [-0.3327831298258764], [0.2734472204141417], [0.18836225897694633], [-1.1942683643774812], [0.2681294103243171], [0.2681294103243171], [-0.2902406491072786], [2.879174164428255], [1.2997845677503128], [0.24154035987519337], [0.24154035987519337], [-1.3538026670722227], [-0.875199758987998], [0.4117102827495846], [0.023510146192379976], [-0.029667954705867278], [-0.662487355395009], [0.2043156892464204], [0.012874526012730526], [1.2466064668520658], [1.4433654401755802], [-0.10411729596341343], [0.5712445854443261], [0.3532143717615125], [-2.4439537354862906], [-0.04030357488551673], [-1.332531426712924], [0.002238905833081075], [-1.0932299726708115], [-0.5348599132392159], [-1.5292904000364387], [2.1453163720324433], [0.6244226863425734], [-0.013714524436393219], [2.927034455236677], [0.156455398437998], [-0.8645641388083485], [1.2572420870317151], [-0.6943942159339573], [0.5393377249053778], [1.8953792978106816], [-0.8379750883592249], [-0.9709203406048429], [1.0179406329896026], [-1.4229341982399442], [1.0232584430794271], [-0.21579130784973255], [-0.6199448746764114], [0.1617732085278226], [0.8849953807439845], [0.32130751122256435], [-0.4869996224307933], [0.039463576461854034], [-0.6305804948560608], [0.6776007872408206], [-0.8645641388083485], [0.16709101861764744], [-0.912424429616771], [-1.6037397412939847], [0.7839569890373149], [0.007556715922905682], [-0.8379750883592249], [0.3957568524801103], [1.709255944666816], [-0.28492283901745385], [-0.8273394681795754], [1.1668393155046948], [0.4914774340969553], [-0.2636515986581551], [-0.5242242930595664], [0.03414576637202943], [-0.15197758677183584], [-0.646533925125535], [0.47552400382748106], [-2.1886988511747036], [-1.2527642753655532], [-0.13070634641253706], [-0.6943942159339573], [-1.2261752249164295], [0.5765623955341509], [-0.34341875000552585], [-0.8486107085388743], [-0.2104734977599078], [-2.5556277473726094], [-1.1729971240181822], [0.28940065068361603], [0.028827956282204584], [0.012874526012730526], [1.4274120099061063], [-0.19983787758025837], [1.0764365439776746], [-0.2689694087479798], [2.69305081128439], [-1.444205438599243], [0.3106718910429149], [1.225335226492767], [-0.29555845919710333], [-0.10411729596341343], [0.023510146192379976], [0.3106718910429149], [-0.2902406491072786], [1.3104201879299622], [0.2043156892464204], [-0.12007072623288761], [0.842452900025387], [0.6137870661629239], [2.2569903839187626], [-0.3115118894665775], [-0.013714524436393219], [1.124296834786097], [-0.019032334526217828], [0.24685816996501822], [-2.8587429224926186], [-0.42318590135289663], [-0.29555845919710333], [-0.1360241565023618], [1.4167763897264567], [-1.2049039845571305], [-0.32214750964622696], [-0.9815559607844923], [-0.3912790408139484], [0.8849953807439845], [-1.4973835394974904], [0.38512123230046086], [-0.4285037114427213], [-1.1038655928504608], [-1.6781890825515307], [-0.10943510605323815], [1.1508858852352206], [1.1721571255945196], [-1.0613231121318631], [-0.8060682278202764], [-1.2421286551859037], [0.7999104193067892], [-0.5029530527002675], [0.2947184607734406], [1.0019872027201282], [1.6560778437685693], [0.9222200513727578], [0.6084692560730991], [0.9647625320913555], [0.5446555349952026], [-0.16793101704131003], [-0.013714524436393219], [-0.08284605560411454], [0.7148254578695936], [0.32662532131238897], [0.15113758834817315], [-0.7847969874609776], [0.6616473569713464], [-0.9177422397065957], [-0.8326572782694003], [0.842452900025387], [-2.374822204318569], [-1.0294162515929148], [1.5231325915229512], [0.15113758834817315], [1.3529626686485599], [-0.08816386569393926], [0.725461078049243], [-0.32214750964622696], [0.06605262691097755], [0.8264994697559127], [-0.12538853632271232], [3.3843661229616036], [-0.25833378856833034], [-0.029667954705867278], [-0.23174473811920673], [-1.3006245661739755], [-0.008396714346568376], [0.1617732085278226], [-0.3381009399157011], [-0.5082708627900923], [-0.08816386569393926], [1.2412886567622408], [0.007556715922905682], [0.6137870661629239], [-1.4548410587788925], [0.7201432679594184], [-0.928377859886245], [1.4167763897264567], [-0.6039914444069372], [0.07137043700080238], [-0.3912790408139484], [-0.3487365600953506], [-0.4391393316223708], [1.3955051493671577], [-1.0294162515929148], [0.7148254578695936], [0.7945926092169643], [-1.6675534623718813], [-0.15197758677183584], [0.6456939267018723], [0.05009919664150349], [-0.11475291614306289], [0.6882364074204701], [-1.0134628213234407], [-0.5189064829697416], [-0.6784407856644833], [0.8849953807439845], [-1.6675534623718813], [-0.35405437018517527], [0.5340199148155531], [-0.720983266383081], [1.033894063259077], [-1.3006245661739755], [0.1777266387972969], [0.40639247265975975], [0.7148254578695936], [-2.768340150965598], [-0.226426928029382], [1.1508858852352206], [0.4117102827495846], [0.2840828405937912], [0.012874526012730526], [0.9488091018218813], [1.331691428289261], [-1.1729971240181822], [-1.2740355157248517], [0.35853218185133734], [-1.1676793139283577], [-1.4707944890483666], [0.5021130542766048], [-0.013714524436393219], [-0.7901147975508024], [-1.2846711359045015], [1.1562036953250452], [0.7839569890373149], [-0.359372180275], [0.14581977825834855], [0.7467323184085419], [0.4648883836478316], [-0.8698819488981732], [-0.5508133435086899], [-1.02409844150309], [-0.04562138497534157], [1.9751464491580522], [-0.06157481524481563], [0.9381734816422318], [0.209633499336245], [-0.8698819488981732], [1.1721571255945196], [-0.6039914444069372], [-1.2633998955452026], [-0.875199758987998], [-0.02435014461604267], [-0.5561311535985146], [1.4167763897264567], [0.32130751122256435], [0.8318172798457375], [-0.13070634641253706], [0.028827956282204584], [-0.19452006749043366], [-0.5561311535985146], [-0.6997120260237822], [-1.1623615038385327], [-1.2846711359045015], [-1.4867479193178408], [0.1139129177194002], [0.9115844311931083], [-0.019032334526217828], [-0.0030789042567437685], [-1.5399260202160878], [0.32662532131238897], [-0.6146270645865866], [0.9328556715524072], [1.8368833868226095], [-0.5189064829697416], [-0.36468999036482475], [2.363346585715257], [-1.1357724533894091], [-0.2104734977599078], [-0.9549669103353686], [0.08200605718045184], [2.187858852751041], [2.0283245500562996], [-0.4444571417121955], [-0.5933558242272877], [0.725461078049243], [0.7360966982288925], [-0.47636400225114384], [0.1405019681685237], [-0.8858353791676473], [-0.13070634641253706], [-1.896219296234344], [-0.4444571417121955], [-0.6518517352153596], [-0.25301597847850565], [-1.3378492368027486], [0.5393377249053778], [0.41702809283940917], [1.6082175529601468], [0.06605262691097755], [1.044529683438726], [1.4167763897264567], [0.3638499919411619], [-0.17324882713113474], [0.7520501284983665], [-1.9600330173122409], [0.25749379014466767], [1.124296834786097], [0.4914774340969553], [-0.47636400225114384], [1.5284504016127758], [-1.1517258836588833], [-0.06689262533464048], [3.363094882602305], [0.895631000923634], [0.1777266387972969], [-0.5295421031493911], [-1.2049039845571305], [0.28940065068361603], [1.3051023778401376], [-0.0775282455142898], [0.18836225897694633], [0.9275378614625823], [-2.8427894922231447], [0.49679524418677995], [-1.1623615038385327], [0.8264994697559127], [-0.8645641388083485], [-0.1360241565023618], [-0.18920225740060892], [-0.928377859886245], [-0.06157481524481563], [0.30003627086326545], [0.9700803421811801], [-0.08816386569393926], [-0.7369366966525551], [-0.13070634641253706], [0.44893495337835754], [-0.04562138497534157], [0.17240882870747204], [0.25749379014466767], [0.012874526012730526], [-0.6890764058441328], [0.35853218185133734], [-0.8167038479999259], [-0.4657283820714944], [1.789023096014187], [0.459570573558007], [0.7786391789474902], [0.2840828405937912], [0.6882364074204701], [-1.199586174467306], [-1.3963451477908206], [-0.17856663722095947], [-1.0294162515929148], [-0.17856663722095947], [-0.4976352426104428], [1.565675072241549], [0.342578751581863], [1.4433654401755802], [-0.3965968509037731], [-0.3965968509037731], [-0.5029530527002675], [-1.4548410587788925], [0.975398152271005], [-0.43382152153254605], [0.7360966982288925], [-1.1836327441978316], [0.9434912917320567], [-0.4391393316223708], [-0.6093092544967619], [-0.3806434206342989], [0.41702809283940917], [-0.5774023939578136], [-0.1413419665921864], [-0.9602847204251934], [-0.6093092544967619], [0.3744856121208114], [-0.23706254820903144], [1.124296834786097], [1.1349324549657462], [-1.045369681862389], [1.225335226492767], [-0.4869996224307933], [-1.3006245661739755], [-0.1413419665921864], [1.6348066034092703], [-0.28492283901745385], [-0.35405437018517527], [0.6722829771509957], [0.03414576637202943], [0.209633499336245], [-0.0030789042567437685], [-0.0775282455142898], [0.725461078049243], [-0.27428721883780444], [-0.06689262533464048], [-1.2687177056350272], [-1.327213616623099], [0.28940065068361603], [1.2625598971215397], [0.03414576637202943], [1.7677518556548883], [-0.41255028117324716], [-2.2259235218034767], [0.6403761166120474], [0.6456939267018723], [1.5603572621517243], [-0.5986736343171124], [1.906014917990331], [0.24154035987519337], [-0.1466597766820111], [-1.4867479193178408], [-0.15729539686166058], [-0.8167038479999259], [-0.9336956699760699], [-0.17324882713113474], [-0.2902406491072786], [-0.779479177371153], [1.773069665744713], [-0.5295421031493911], [0.9541269119117061], [-0.7475723168322046], [-0.5720845838679888], [-2.1355207502764566], [0.209633499336245], [1.3635982888282097], [-0.2689694087479798], [1.3104201879299622], [-0.17856663722095947], [-0.3753256105444742], [-0.7263010764729058], [0.38512123230046086], [0.342578751581863], [0.2628116002344923], [1.9379217785292795], [0.9328556715524072], [-0.5720845838679888], [0.5978336358934496], [1.0817543540674992], [1.2625598971215397], [-0.986873770874317], [1.1615215054148702], [0.039463576461854034], [-0.16793101704131003], [0.5074308643664294], [-0.5561311535985146], [-0.9336956699760699], [-0.29555845919710333], [0.08732386727027644], [-0.8379750883592249], [0.7786391789474902], [0.7945926092169643], [1.411458579636632], [-0.5082708627900923], [0.023510146192379976], [-0.8167038479999259], [0.7892747991271397], [0.30003627086326545], [0.5978336358934496], [-0.3327831298258764], [-0.3806434206342989], [0.12454853789904964], [0.5499733450850272], [-0.45509276189184494], [-0.5614489636883393], [0.4861596240071305], [0.6988720276001195], [-0.5508133435086899], [3.0174372267636973], [-0.32746531973605164], [0.3638499919411619], [0.3744856121208114], [0.4914774340969553], [0.6563295468815217], [1.54440383188225], [0.060734816821152934], [1.204063986133468], [1.4486832502654052], [-0.3115118894665775], [0.858406330294861], [-0.4816818123409686], [0.9913515825404791], [1.2412886567622408], [2.87385635433843], [-0.5454955334188651], [-0.28492283901745385], [-0.6571695453051845], [-1.843041195336097], [-0.6997120260237822], [0.8530885202050364], [2.1612698023019177], [0.007556715922905682], [2.6239192801166684], [0.9807159623608296], [-0.6039914444069372], [0.2628116002344923], [-0.5082708627900923], [0.7573679385881914], [-0.4657283820714944], [-0.1838844473107842], [-0.056257005154991026], [0.39043904239028565], [-0.300876269286928], [-0.19983787758025837], [-0.8273394681795754], [1.9804642592478774], [2.5016096480506995], [0.076688247090627], [0.002238905833081075], [-0.9762381506946676], [-0.18920225740060892], [0.6829185973306452], [1.4327298199959309], [0.05541700673132833], [0.5287021047257283], [-0.8805175690778226], [1.1508858852352206], [-1.385709527611171], [1.3370092383790861], [-0.5933558242272877], [0.4808418139173059], [-0.7263010764729058], [-1.2102217946469553], [1.778387475834538], [-0.21579130784973255], [-0.3700078004546495], [0.7786391789474902], [-1.2527642753655532], [-1.614375361473634], [-2.6992086197978775], [-0.47104619216131915], [-1.5824685009346857], [-0.47104619216131915], [0.87967757065416], [0.14581977825834855], [-0.17324882713113474], [0.5021130542766048], [0.4542527634681824], [0.4808418139173059], [-0.7901147975508024], [-0.9177422397065957], [0.2681294103243171], [2.751546722272461], [-0.875199758987998], [-0.47636400225114384], [-1.784545284348025], [-0.019032334526217828], [-1.4388876285094183], [-1.4973835394974904], [0.9647625320913555], [-0.8432928984490495], [1.2731955173011893], [-0.5242242930595664], [-0.18920225740060892], [-0.4657283820714944], [-0.35405437018517527], [-1.0932299726708115], [-0.03498576479569212], [-0.3381009399157011], [0.6988720276001195], [1.2200174164029418], [-1.0560053020420384], [-0.06689262533464048], [-0.35405437018517527], [-0.7847969874609776], [-0.38596123072412364], [0.10327729753975073], [-0.8858353791676473], [0.7680035587678409], [-0.5880380141374629], [-1.4122985780602948], [-0.4657283820714944], [-0.0775282455142898], [-0.7741613672813281], [-1.045369681862389], [-0.3168296995564022], [0.16709101861764744], [-2.3535509639592704], [-0.4604105719816697], [-0.1360241565023618], [0.08200605718045184], [-0.6305804948560608], [-2.369504394228744], [-1.6728712724617059], [-0.3381009399157011], [2.2410369536492882], [-0.7901147975508024], [-0.2636515986581551], [0.8371350899355622], [2.9961659864043986], [-0.10411729596341343], [1.4540010603552298], [-1.066640922221688], [-0.6837585957543079], [-0.6412161150357101], [-0.6039914444069372], [-1.0187806314132655], [2.475020597601576], [-1.3218958065332744], [0.32662532131238897], [-0.9921915809641417], [-1.9493973971325915], [0.3638499919411619], [-1.3644382872518723], [-0.9815559607844923], [0.5606089652646766], [0.5552911551748521], [-0.13070634641253706], [-0.3168296995564022], [-1.0028272011437913], [1.3795517190976838], [0.7414145083187171], [1.204063986133468], [-0.7050298361136068], [1.4167763897264567], [-0.12538853632271232], [1.145568075145396], [-1.5771506908448611], [-0.7316188865627304], [0.41702809283940917], [-0.02435014461604267], [0.5659267753545015], [1.565675072241549], [-0.5986736343171124], [1.831565576732785], [-0.7103476462034315], [-0.5614489636883393], [-0.35405437018517527], [-0.36468999036482475], [-0.05093919506516618], [-0.8167038479999259], [0.5393377249053778], [1.5816285025110233], [0.24685816996501822], [-0.1626132069514853], [0.2840828405937912], [1.1508858852352206], [-0.9656025305150181], [-1.9440795870427667], [1.4327298199959309], [1.4008229594569823], [0.2043156892464204], [0.30003627086326545], [-0.662487355395009], [0.3532143717615125], [0.30003627086326545], [-0.45509276189184494], [-0.019032334526217828], [-0.3965968509037731], [0.422345902929234], [-1.2687177056350272], [-1.3803917175213463], [1.2146996063131172], [-0.7528901269220294], [-1.5452438303059128], [0.4436171432885329], [0.2043156892464204], [-2.0078933081206634], [-0.9071066195269463], [0.459570573558007], [0.044781386551678876], [-0.12007072623288761], [-0.4816818123409686], [-0.300876269286928], [0.023510146192379976], [-0.16793101704131003], [-0.359372180275], [0.47552400382748106], [0.842452900025387], [0.37980342221063623], [-0.21579130784973255], [-1.4016629578806452], [0.1617732085278226], [0.6563295468815217], [1.1402502650555715], [-0.300876269286928], [-0.029667954705867278], [-0.8113860379101013], [0.459570573558007], [-0.4976352426104428], [-1.8324055751564476], [-1.7366849935396027], [0.07137043700080238], [0.9966693926303036], [-1.1357724533894091], [-1.3963451477908206], [0.1617732085278226], [0.2947184607734406], [-0.5508133435086899], [-0.4178680912630719], [-0.7635257471016788], [1.033894063259077], [-0.35405437018517527], [1.0817543540674992], [1.4008229594569823], [0.1777266387972969], [0.8105460394864387], [0.27876503050396656], [-0.6146270645865866], [-0.16793101704131003], [1.7198915648464659], [-0.3965968509037731], [0.007556715922905682], [-0.662487355395009], [-0.8698819488981732], [0.8158638495762632], [0.023510146192379976], [-0.5401777233290405], [1.5071791612534768], [-0.1838844473107842], [0.1351841580786991], [1.4220941998162813], [1.331691428289261], [-0.4497749518020202], [-0.7369366966525551], [-1.0506874919522138], [-3.012959415097536], [1.1030255944267982], [-1.1836327441978316], [0.028827956282204584], [0.10859510762957535], [0.6191048762527486], [-1.0932299726708115], [-0.9071066195269463], [-1.2687177056350272], [-1.0294162515929148], [0.28940065068361603], [-1.0825943524911619], [-0.32746531973605164], [0.8105460394864387], [1.2731955173011893], [-0.23174473811920673], [0.8264994697559127], [-1.651600032102407], [1.3423270484689107], [-1.045369681862389], [-0.5348599132392159], [-0.02435014461604267], [1.4805901108043533], [0.6456939267018723], [0.30003627086326545], [-0.8326572782694003], [-0.720983266383081], [0.6669651670611711], [-0.21579130784973255], [-0.9177422397065957], [-0.875199758987998], [-0.5614489636883393], [-1.3059423762638003], [-0.1360241565023618], [0.10859510762957535], [0.16709101861764744], [2.4909740278710504], [-0.15197758677183584], [-0.5827202040476382], [0.6510117367916969], [-0.5135886728799169], [-1.614375361473634], [1.2359708466724162], [-1.1304546432995846], [-0.8486107085388743], [-1.7739096641683758], [0.6137870661629239], [-0.11475291614306289], [-0.5242242930595664], [1.044529683438726], [-0.9815559607844923], [1.4540010603552298], [-1.0134628213234407], [0.018192336102555134], [-0.7528901269220294], [-2.108931699827333], [1.0232584430794271], [-0.8858353791676473], [-0.6358983049458855], [0.19368006906677096], [1.1562036953250452], [0.30003627086326545], [-0.226426928029382], [-0.23706254820903144], [-0.3487365600953506], [-0.4019146609935978], [0.21495130942606985], [0.725461078049243], [-0.7263010764729058], [0.10859510762957535], [0.039463576461854034], [-0.7847969874609776], [-0.3753256105444742], [-0.5933558242272877], [-0.6093092544967619], [0.592515825803625], [-0.1466597766820111], [-1.066640922221688], [-0.17856663722095947], [0.6191048762527486], [-1.0560053020420384], [1.0977077843369736], [-1.1145012130301104], [-0.4657283820714944], [-0.7422545067423799], [-1.2527642753655532], [-0.6890764058441328], [-0.8007504177304519], [-0.09348167578376398], [-0.3327831298258764], [0.23622254978536875], [2.69305081128439], [-0.2051556876700831], [0.4648883836478316], [-0.5029530527002675], [-0.2689694087479798], [0.6616473569713464], [-0.16793101704131003], [1.464636680534879], [1.044529683438726], [-0.8379750883592249], [-0.8220216580897508], [-0.853928518628699], [0.1830444488871215], [-1.0613231121318631], [-1.7579562338989014], [-0.8698819488981732], [-0.720983266383081], [0.25749379014466767], [1.4699544906247042], [0.7467323184085419], [2.049595790415599], [1.033894063259077], [-1.1198190231199352], [0.842452900025387], [-0.6305804948560608], [0.5659267753545015], [-0.4391393316223708], [-0.42318590135289663], [1.3423270484689107], [-0.8858353791676473], [-0.5827202040476382], [-2.1195673200069827], [1.8794258675412074], [2.5866946094878953], [-0.7688435571915035], [-0.34341875000552585], [0.6935542175102947], [0.08732386727027644], [-1.4548410587788925], [-0.4497749518020202], [-0.17856663722095947], [-0.4178680912630719], [0.15113758834817315], [0.7360966982288925], [-0.45509276189184494], [-1.0560053020420384], [-0.29555845919710333], [-2.1408385603662814], [-0.6997120260237822], [0.08732386727027644], [-0.12007072623288761], [1.2838311374808387], [-0.2902406491072786], [0.22026911951589445], [-1.747320613719252], [-2.63539489871998], [1.3795517190976838], [1.0817543540674992], [-1.5558794504855622], [-1.6462822220125823], [-0.8645641388083485], [-2.2259235218034767], [-1.3750739074315217], [0.9009488110134588], [-0.4444571417121955], [-1.1198190231199352], [-0.34341875000552585], [0.9328556715524072], [-0.7263010764729058], [-1.0719587323115125], [1.0817543540674992], [0.8849953807439845], [-0.49231743252061805], [-0.45509276189184494], [-0.5986736343171124], [-0.056257005154991026], [-0.7103476462034315], [2.342075345355958], [0.4329815231088835], [-0.19983787758025837], [-0.7422545067423799], [1.5231325915229512], [-0.47636400225114384], [0.9647625320913555], [-1.3378492368027486], [0.24685816996501822], [2.7249576718233377], [-0.12538853632271232], [-0.43382152153254605], [1.4433654401755802], [1.9538752087987532], [0.156455398437998], [0.09264167736010129], [0.05541700673132833], [-0.029667954705867278], [-0.029667954705867278], [-0.03498576479569212], [-0.7582079370118541], [-1.3750739074315217], [1.0977077843369736], [0.725461078049243], [-0.3912790408139484], [1.5603572621517243], [1.4167763897264567], [1.2306530365825916], [-1.6941425128210048], [-0.5614489636883393], [1.5603572621517243], [0.0979594874499259], [-0.19983787758025837], [-0.3327831298258764], [-0.5933558242272877], [0.012874526012730526], [-0.05093919506516618], [-0.45509276189184494], [-0.6784407856644833], [3.2248318202668615], [0.3053540809530901], [0.3053540809530901], [0.9913515825404791], [-1.5718328807550361], [-0.7954326076406271], [-0.21579130784973255], [-0.28492283901745385], [1.8794258675412074], [0.10327729753975073], [1.3263736181994363], [0.6669651670611711], [0.9966693926303036], [-1.1676793139283577], [0.023510146192379976], [-0.6093092544967619], [1.2466064668520658], [0.42766371301905864], [1.7039381345769915], [1.7624340455650636], [-1.0879121625809869], [0.39043904239028565], [1.2838311374808387], [-2.1248851300968075], [-1.1038655928504608], [-1.917490536593643], [0.3638499919411619], [1.1296146448759217], [0.1405019681685237], [-0.4178680912630719], [-0.8805175690778226], [-1.1729971240181822], [-0.4391393316223708], [-0.1626132069514853], [-0.912424429616771], [0.3532143717615125], [2.0336423601461244], [1.012622822899778], [-0.06157481524481563], [-0.6199448746764114], [0.18836225897694633], [-0.3806434206342989], [-0.720983266383081], [-0.23174473811920673], [0.5021130542766048], [0.19899787915659556], [0.6084692560730991], [0.5659267753545015], [0.30003627086326545], [2.9004454047875536], [-0.08284605560411454], [0.24154035987519337], [-1.614375361473634], [2.6664617608352663], [-1.4388876285094183], [-0.3700078004546495], [0.05009919664150349], [1.4593188704450544], [0.36916780203098676], [1.1562036953250452], [-0.6890764058441328], [0.3744856121208114], [-0.1626132069514853], [-2.757704530785949], [1.4061407695468073], [1.5284504016127758], [-0.019032334526217828], [-0.17856663722095947], [-1.4707944890483666], [-0.25833378856833034], [0.3957568524801103], [0.5393377249053778], [2.480338407691401], [-1.157043693748708], [-1.4016629578806452], [-0.15197758677183584], [1.1349324549657462], [-0.5082708627900923], [0.11923072780922479], [0.8849953807439845], [-0.8911531892574721], [-0.5135886728799169], [1.698620324487167], [-0.06157481524481563], [-0.8805175690778226], [0.2840828405937912], [-1.0932299726708115], [-0.9443312901557194], [0.007556715922905682], [-1.2421286551859037], [0.6084692560730991], [1.1721571255945196], [1.64544222358892], [0.459570573558007], [-1.4548410587788925], [0.44893495337835754], [-0.3912790408139484], [3.203560579907563], [0.858406330294861], [-1.0825943524911619], [1.065800923798025], [-0.3381009399157011], [-0.6571695453051845], [0.47020619373765643], [-1.1517258836588833], [0.1617732085278226], [0.6882364074204701], [0.1777266387972969], [-1.3963451477908206], [2.0655492206850723], [-0.10411729596341343], [0.05541700673132833], [1.0498474935285511], [1.225335226492767], [-0.5508133435086899], [-0.35405437018517527], [0.9062666211032835], [0.6031514459832744], [1.2146996063131172], [-0.8379750883592249], [-0.23706254820903144], [-2.949145694019639], [1.7039381345769915], [-1.4920657294076656], [2.001735499607176], [-0.06157481524481563], [1.3635982888282097], [1.5071791612534768], [-0.928377859886245], [-0.5986736343171124], [1.0817543540674992], [2.193176662840866], [0.1351841580786991], [-0.5454955334188651], [0.05541700673132833], [-0.09348167578376398], [1.2146996063131172], [-0.6731229755746585], [3.804473120057756], [-0.013714524436393219], [0.17240882870747204], [0.30003627086326545], [-0.6518517352153596], [0.6084692560730991], [-1.5452438303059128], [0.38512123230046086], [1.624170983229621], [0.9488091018218813], [-0.28492283901745385], [1.831565576732785], [-1.5505616403957376], [-1.0560053020420384], [-1.2102217946469553], [-0.7741613672813281], [0.7999104193067892], [1.1349324549657462], [-0.47636400225114384], [1.07111873388785], [-0.008396714346568376], [0.1405019681685237], [1.0019872027201282], [-0.9496491002455439], [-0.5986736343171124], [0.5712445854443261], [0.8743597605643351], [-0.1626132069514853], [0.19368006906677096], [0.3532143717615125], [2.480338407691401], [-0.5242242930595664], [0.10327729753975073], [0.6829185973306452], [1.2944667576604882], [-0.4285037114427213], [0.5659267753545015], [1.358280478738385], [3.6874812980816127], [0.08732386727027644], [-0.8805175690778226], [0.6403761166120474], [1.204063986133468], [-0.7316188865627304], [0.5606089652646766], [-0.9017888094371216], [0.30003627086326545], [-0.02435014461604267], [0.6403761166120474], [0.6137870661629239], [-1.7100959430904792], [0.05541700673132833], [-0.3965968509037731], [-1.4282520083297687], [-1.4707944890483666], [-0.18920225740060892], [-1.9919398778511894], [1.1083434045166227], [-0.41255028117324716], [0.2681294103243171], [1.8741080574513829], [0.37980342221063623], [0.4914774340969553], [0.4808418139173059], [-0.23174473811920673], [-0.8645641388083485], [-0.013714524436393219], [1.7943409061040119], [-1.0081450112336159], [-0.18920225740060892], [-0.4019146609935978], [-0.986873770874317], [1.2466064668520658], [-0.8486107085388743], [-0.30619407937675275], [-0.0775282455142898], [-0.7847969874609776], [-2.518403076743837], [2.7568645323622865], [-0.9496491002455439], [1.1827927457741692], [0.7786391789474902], [-0.47636400225114384], [2.916398835057028], [0.4010746625699351], [0.36916780203098676], [1.6879847043075173], [1.2838311374808387], [1.3423270484689107], [-1.3803917175213463], [-0.10943510605323815], [-0.3700078004546495], [-0.5029530527002675], [-0.25833378856833034], [0.2734472204141417], [2.405889066433855], [-0.2902406491072786], [0.6510117367916969], [-0.5454955334188651], [0.5552911551748521], [0.14581977825834855], [-1.3218958065332744], [0.7573679385881914], [-0.5454955334188651], [-1.3006245661739755], [-1.5452438303059128], [0.9860337724506545], [0.49679524418677995], [-0.3700078004546495], [-0.5082708627900923], [-0.08284605560411454], [-1.9653508274020657], [-0.6890764058441328], [1.4433654401755802], [-0.3115118894665775], [0.5074308643664294], [-0.5667667737781641], [0.7095076477797689], [0.5659267753545015], [1.2838311374808387], [-0.10411729596341343], [-0.25833378856833034], [1.8953792978106816], [1.2412886567622408], [0.2521759800548428], [1.491225730984003], [3.804473120057756], [1.5178147814331264], [-0.912424429616771], [0.5765623955341509], [-1.8004987146174993], [-0.7475723168322046], [-1.2102217946469553], [0.012874526012730526], [0.028827956282204584], [-2.0929782695578587], [0.459570573558007], [-0.2211091179395573], [-0.9390134800658945], [-0.6039914444069372], [-0.5348599132392159], [1.204063986133468], [1.0764365439776746], [0.6297404964323979], [0.47020619373765643], [-0.9709203406048429], [0.42766371301905864], [1.868790247361558], [1.2359708466724162], [-1.614375361473634], [0.8530885202050364], [-0.3168296995564022], [-0.8326572782694003], [-0.1413419665921864], [-0.06689262533464048], [0.5180664845460788], [-1.3006245661739755], [1.4220941998162813], [0.342578751581863], [0.0979594874499259], [-1.045369681862389], [-1.2474464652757284], [0.3532143717615125], [0.5552911551748521], [0.08200605718045184], [0.842452900025387], [-0.6943942159339573], [0.1139129177194002], [-0.13070634641253706], [-0.7635257471016788], [1.1508858852352206], [-0.1466597766820111], [1.5284504016127758], [0.22026911951589445], [-0.5082708627900923], [0.24154035987519337], [0.459570573558007], [-1.88026586596487], [0.38512123230046086], [-0.42318590135289663], [-0.02435014461604267], [-1.8377233852462724], [2.496291837960875], [1.5231325915229512], [1.1562036953250452], [-0.5295421031493911], [0.1405019681685237], [-1.220857414826605], [0.4542527634681824], [1.1881105558639937], [0.6031514459832744], [1.1508858852352206], [0.07137043700080238], [-0.5827202040476382], [-2.2737838126118994], [-0.09879948587358871], [0.9488091018218813], [1.0073050128099534], [0.1830444488871215], [0.6722829771509957], [-0.08284605560411454], [-1.3963451477908206], [0.8158638495762632], [-0.47104619216131915], [-1.3218958065332744], [0.5978336358934496], [0.7520501284983665], [-0.9443312901557194], [-1.2421286551859037], [0.17240882870747204], [-1.0081450112336159], [-0.056257005154991026], [-0.47636400225114384], [0.30003627086326545], [0.5818802056239756], [0.3106718910429149], [1.5763106924211983], [-0.7847969874609776], [-0.6146270645865866], [-0.2902406491072786], [-1.0187806314132655], [-0.28492283901745385], [0.012874526012730526], [-0.8964709993472968], [-1.6250109816532834], [0.08732386727027644], [0.6297404964323979], [0.4117102827495846], [-0.6412161150357101], [-0.1360241565023618], [-0.17324882713113474], [-0.7688435571915035], [-1.5771506908448611], [-1.4388876285094183], [-1.0613231121318631], [0.11923072780922479], [-0.29555845919710333], [-0.6731229755746585], [0.8743597605643351], [-0.9071066195269463], [1.3635982888282097], [0.7307788881390677], [-0.6039914444069372], [0.8690419504745105], [1.4699544906247042], [-0.5880380141374629], [-0.5508133435086899], [0.5340199148155531], [-0.9602847204251934], [-0.45509276189184494], [0.2628116002344923], [0.5659267753545015], [0.10859510762957535], [0.8105460394864387], [-0.8486107085388743], [-1.3963451477908206], [-0.008396714346568376], [-1.0400518717725642], [0.8158638495762632], [0.3957568524801103], [0.36916780203098676], [-0.15729539686166058], [-0.986873770874317], [0.5499733450850272], [2.921716645146853], [-0.6199448746764114], [0.1830444488871215], [0.7201432679594184], [-0.11475291614306289], [-0.2902406491072786], [-0.4072324710834224], [-0.8432928984490495], [-0.928377859886245], [-0.019032334526217828], [0.6829185973306452], [0.0979594874499259], [-0.2104734977599078], [-0.5189064829697416], [0.209633499336245], [-0.9230600497964204], [2.171905422481567], [1.3104201879299622], [0.9009488110134588], [-0.6358983049458855], [-0.9496491002455439], [0.209633499336245], [-0.2689694087479798], [-0.02435014461604267], [-0.4072324710834224], [1.2625598971215397], [-1.332531426712924], [1.358280478738385], [0.002238905833081075], [-1.1304546432995846], [-0.6412161150357101], [-1.2846711359045015], [-0.38596123072412364], [0.5074308643664294], [-0.9336956699760699], [0.6722829771509957], [-1.2527642753655532], [-0.2104734977599078], [-0.7688435571915035], [-0.08284605560411454], [-2.582216797821733], [-0.5561311535985146], [1.4274120099061063], [0.4329815231088835], [-0.4604105719816697], [0.3638499919411619], [1.7837052859243625], [-1.5877863110245105], [0.7148254578695936], [-0.3115118894665775], [-0.2476981683886809], [1.5231325915229512], [1.204063986133468], [0.5287021047257283], [-1.7579562338989014], [-0.3327831298258764], [0.6031514459832744], [-0.4816818123409686], [-0.17324882713113474], [-0.41255028117324716], [0.12986634798887425], [0.25749379014466767], [0.10327729753975073], [-0.25301597847850565], [-1.975986447581715], [0.3319431314022136], [0.6403761166120474], [-0.07221043542446508], [0.05541700673132833], [0.5659267753545015], [-0.41255028117324716], [2.10809170140367], [0.007556715922905682], [0.2840828405937912], [-1.1251368332097598], [-0.4604105719816697], [1.5071791612534768], [0.9009488110134588], [0.8105460394864387], [-0.056257005154991026], [-0.1626132069514853], [-1.1464080735690587], [-2.1302029401866323], [-0.8273394681795754], [-0.6997120260237822], [0.2255869296057193], [-1.2049039845571305], [0.12454853789904964], [-1.1357724533894091], [0.5180664845460788], [-0.6039914444069372], [-1.6090575513838095], [0.12454853789904964], [-0.32746531973605164], [-0.3168296995564022], [-0.9390134800658945], [0.19899787915659556], [1.1721571255945196], [0.7573679385881914], [-0.5667667737781641], [0.14581977825834855], [-0.24238035829885618], [0.22026911951589445], [-0.5720845838679888], [-0.7156654562932563], [0.40639247265975975], [1.2891489475706632], [1.2572420870317151], [-0.9496491002455439], [-1.220857414826605], [0.4436171432885329], [-1.0560053020420384], [-0.12538853632271232], [0.5180664845460788], [0.03414576637202943], [-1.1357724533894091], [1.1934283659538183], [2.613283659937019], [0.6244226863425734], [-1.88026586596487], [0.5978336358934496], [-0.4072324710834224], [1.868790247361558], [-3.0714553260856072], [-0.45509276189184494], [1.2572420870317151], [-1.0772765424013373], [-0.41255028117324716], [0.5499733450850272], [0.7414145083187171], [0.21495130942606985], [1.5337682117026004], [-1.3538026670722227], [0.39043904239028565], [0.060734816821152934], [0.5659267753545015], [1.092389974247149], [-0.3381009399157011], [-0.19452006749043366], [0.4861596240071305], [-0.7741613672813281], [-1.2421286551859037], [-0.9336956699760699], [-0.36468999036482475], [-0.7316188865627304], [0.44893495337835754], [-0.4497749518020202], [0.49679524418677995], [-1.6409644119227578], [-0.8326572782694003], [-1.0719587323115125], [-0.7528901269220294], [-0.912424429616771], [-0.21579130784973255], [0.8211816596660881], [-0.3965968509037731], [-0.3806434206342989], [-1.8270877650666228], [0.6510117367916969], [-0.9336956699760699], [-1.3963451477908206], [1.07111873388785], [0.19368006906677096], [0.3957568524801103], [-0.853928518628699], [-0.5189064829697416], [-1.7100959430904792], [-0.4444571417121955], [-0.1626132069514853], [0.47020619373765643], [0.1405019681685237], [-0.9230600497964204], [-0.1838844473107842], [-0.4497749518020202], [-1.4920657294076656], [1.9591930188885784], [-0.6837585957543079], [0.060734816821152934], [-0.9390134800658945], [-0.3806434206342989], [0.24154035987519337], [-0.359372180275], [0.7520501284983665], [0.858406330294861], [0.24154035987519337], [-0.7582079370118541], [0.5340199148155531], [0.209633499336245], [0.9488091018218813], [-0.17324882713113474], [0.28940065068361603], [-0.9602847204251934], [1.789023096014187], [-0.2476981683886809], [0.2947184607734406], [-1.4707944890483666], [-1.9813042576715398], [-0.7156654562932563], [-1.5133369697669643], [1.2731955173011893], [-0.1626132069514853], [0.08732386727027644], [0.2255869296057193], [-0.21579130784973255], [0.9009488110134588], [-0.5401777233290405], [1.9219683482598051], [1.1508858852352206], [1.618853173139796], [-0.19983787758025837], [-0.6997120260237822], [-0.928377859886245], [1.0392118733489015], [-0.07221043542446508], [-1.4388876285094183], [0.5393377249053778], [0.49679524418677995], [-0.8326572782694003], [-0.3381009399157011], [-0.2689694087479798], [0.7307788881390677], [-0.3806434206342989], [1.3104201879299622], [0.28940065068361603], [0.9434912917320567], [0.37980342221063623], [-1.1623615038385327], [-0.9177422397065957], [-0.6784407856644833], [-1.157043693748708], [0.42766371301905864], [-0.0775282455142898], [-0.34341875000552585], [0.12986634798887425], [-0.09879948587358871], [-0.8432928984490495], [-0.9230600497964204], [-0.7050298361136068], [-0.3912790408139484], [0.7786391789474902], [0.6297404964323979], [-0.8273394681795754], [-1.157043693748708], [0.076688247090627], [-0.5135886728799169], [0.002238905833081075], [1.565675072241549], [0.9913515825404791], [-0.7422545067423799], [-0.9017888094371216], [-0.6997120260237822], [0.7520501284983665], [1.3476448585587353], [1.044529683438726], [-0.4604105719816697], [-0.5933558242272877], [-0.04562138497534157], [-1.348484856982398], [1.9804642592478774], [0.9115844311931083], [-0.7847969874609776], [0.3106718910429149], [0.156455398437998], [1.1668393155046948], [-0.779479177371153], [0.5871980157138004], [2.6824151911047402], [0.5978336358934496], [-0.1413419665921864], [-0.6146270645865866], [0.3957568524801103], [-0.4285037114427213], [-0.9496491002455439], [0.8477707101152115], [-1.5824685009346857], [-3.2628964893192975], [-1.0613231121318631], [0.24154035987519337], [-1.0506874919522138], [1.278513327391014], [0.9594447220015307], [-1.0081450112336159], [1.6348066034092703], [0.5871980157138004], [-0.09348167578376398], [-1.2474464652757284], [-0.16793101704131003], [2.3208041049966592], [-1.2687177056350272], [0.03414576637202943], [-0.8273394681795754], [-0.4285037114427213], [-1.4920657294076656], [-0.1838844473107842], [0.09264167736010129], [0.6297404964323979], [-0.29555845919710333], [-0.4657283820714944], [-0.24238035829885618], [0.1617732085278226], [2.7196398617335134], [-0.5880380141374629], [-0.8273394681795754], [0.5233842946359037], [-0.5933558242272877], [-1.178314934108007], [-0.28492283901745385], [-0.9549669103353686], [-0.11475291614306289], [0.1405019681685237], [0.209633499336245], [-0.19983787758025837], [-0.8273394681795754], [0.8158638495762632], [-0.5295421031493911], [-0.019032334526217828], [0.07137043700080238], [-1.157043693748708], [0.36916780203098676], [-0.3912790408139484], [2.437795926972803], [-0.25833378856833034], [1.0977077843369736], [0.2947184607734406], [-0.32746531973605164], [-0.7050298361136068], [2.0230067399664753], [-0.06157481524481563], [-0.7475723168322046], [0.2947184607734406], [1.5869463126008478], [-1.1464080735690587], [-1.460158868868717], [-1.1464080735690587], [1.3795517190976838], [0.40639247265975975], [1.0179406329896026], [2.698368621374214], [1.4061407695468073], [0.9381734816422318], [1.709255944666816], [-0.0030789042567437685], [0.9860337724506545], [2.4112068765236794], [-1.0134628213234407], [0.4329815231088835], [0.40639247265975975], [1.1189790246962725], [-0.3700078004546495], [0.1777266387972969], [1.3795517190976838], [1.485907920894178], [0.725461078049243], [-1.0560053020420384], [-1.5292904000364387], [-0.42318590135289663], [-1.157043693748708], [0.6829185973306452], [0.7360966982288925], [0.3638499919411619], [-0.11475291614306289], [0.2043156892464204], [0.895631000923634], [0.19899787915659556], [2.3208041049966592], [2.1027738913138454], [0.8530885202050364], [-1.3431670468925734], [2.0868204610443715], [-0.5401777233290405], [-0.8964709993472968], [0.32662532131238897], [-1.5877863110245105], [-0.2796050289276291], [1.6401244134990949], [-2.1461563704561057], [-0.12538853632271232], [1.73584499511594], [0.5233842946359037], [-0.3168296995564022], [-0.4285037114427213], [0.5818802056239756], [-0.6890764058441328], [-1.0932299726708115], [-0.38596123072412364], [1.1721571255945196], [2.5069274581405243], [-0.3965968509037731], [-0.43382152153254605], [1.5709928823313735], [-0.1466597766820111], [-1.1623615038385327], [0.11923072780922479], [-0.029667954705867278], [-0.3381009399157011], [-1.0719587323115125], [-1.747320613719252], [-0.7050298361136068], [-0.0775282455142898], [0.9169022412829329], [0.5659267753545015], [-1.8270877650666228], [-1.7739096641683758], [-0.42318590135289663], [0.5871980157138004], [0.3957568524801103], [-0.4604105719816697], [-0.4391393316223708], [1.3529626686485599], [-0.8592463287185237], [0.209633499336245], [-1.460158868868717], [-1.0028272011437913], [0.2521759800548428], [-0.12538853632271232], [-1.8217699549767983], [0.5021130542766048], [-0.2211091179395573], [1.331691428289261], [-1.178314934108007], [0.9062666211032835], [0.08200605718045184], [-0.6518517352153596], [1.4274120099061063], [0.5021130542766048], [-0.15729539686166058], [1.4752723007145288], [0.0979594874499259], [-1.3165779964434496], [-0.4657283820714944], [0.47552400382748106], [-0.8964709993472968], [0.9434912917320567], [0.24154035987519337], [1.2997845677503128], [-0.18920225740060892], [-1.78986309443785], [-0.1360241565023618], [0.9115844311931083], [-0.2636515986581551], [-1.0613231121318631], [0.7680035587678409], [0.1351841580786991], [0.6829185973306452], [-0.875199758987998], [-1.1357724533894091], [0.028827956282204584], [-1.5239725899466139], [0.5712445854443261], [0.2521759800548428], [-0.05093919506516618], [1.065800923798025], [0.2255869296057193], [-0.9762381506946676], [-0.4444571417121955], [0.9913515825404791], [1.1189790246962725], [-2.034482358569787], [-0.7901147975508024], [-0.6731229755746585], [-0.9017888094371216], [0.2681294103243171], [-0.36468999036482475], [-1.02409844150309], [1.1881105558639937], [1.3210558081096118], [-1.311260186353625], [1.0817543540674992], [0.41702809283940917], [0.9381734816422318], [-0.1413419665921864], [-0.6518517352153596], [1.4220941998162813], [0.5127486744562543], [-0.29555845919710333], [-0.300876269286928], [0.5074308643664294], [0.5446555349952026], [-0.19983787758025837], [0.8158638495762632], [0.156455398437998], [-0.7369366966525551], [0.38512123230046086], [0.42766371301905864], [-3.4915623231817605], [-0.25833378856833034], [0.9913515825404791], [-0.9762381506946676], [-1.2953067560841507], [0.8849953807439845], [2.836631683709657], [-1.4495232486890677], [-0.8326572782694003], [0.4808418139173059], [0.044781386551678876], [1.6082175529601468], [-0.4019146609935978], [-0.02435014461604267], [-1.0347340616827396], [-1.2261752249164295], [1.0019872027201282], [-0.06689262533464048], [0.5871980157138004], [-0.36468999036482475], [0.7041898376899441], [0.2840828405937912], [-0.226426928029382], [-0.4019146609935978], [0.9913515825404791], [-0.9017888094371216], [0.209633499336245], [0.7307788881390677], [0.060734816821152934], [1.3795517190976838], [0.23622254978536875], [-0.646533925125535], [-0.6571695453051845], [1.6294887933194457], [-0.21579130784973255], [-1.5611972605753868], [-0.226426928029382], [1.3955051493671577], [0.6031514459832744], [0.6988720276001195], [-0.5827202040476382], [-0.13070634641253706], [-0.06157481524481563], [0.3319431314022136], [1.884743677631032], [3.203560579907563], [0.19368006906677096], [0.858406330294861], [-1.7154137531803038], [0.9488091018218813], [-0.7475723168322046], [1.2997845677503128], [-0.34341875000552585], [0.039463576461854034], [-0.6093092544967619], [-0.013714524436393219], [1.964510828978403], [-0.7528901269220294], [-0.38596123072412364], [0.002238905833081075], [-2.491814026294713], [0.28940065068361603], [0.007556715922905682], [1.7039381345769915], [0.8690419504745105], [1.4805901108043533], [2.3314397251763084], [-1.3378492368027486], [0.22026911951589445], [0.4329815231088835], [0.22026911951589445], [-0.226426928029382], [0.156455398437998], [0.1617732085278226], [-0.4869996224307933], [0.16709101861764744], [0.018192336102555134], [0.24685816996501822], [-0.9336956699760699], [0.5233842946359037], [-0.32214750964622696], [-0.7103476462034315], [0.8849953807439845], [0.34789656167168787], [-1.1357724533894091], [-0.2104734977599078], [1.0285762531692522], [4.160766396076013], [0.34789656167168787], [1.9326039684394545], [0.6882364074204701], [1.996417689517351], [0.9434912917320567], [-1.2793533258146768], [-0.06157481524481563], [0.060734816821152934], [0.42766371301905864], [-1.0719587323115125], [0.7945926092169643], [1.7145737547566413], [-0.3700078004546495], [-0.928377859886245], [-1.2527642753655532], [0.8318172798457375], [-0.6678051654848338], [0.8530885202050364], [-0.4657283820714944], [-0.8379750883592249], [1.5763106924211983], [-0.13070634641253706], [0.4861596240071305], [-0.8698819488981732], [-1.5080191596771397], [-1.0879121625809869], [-0.17856663722095947], [-0.09348167578376398], [-0.47636400225114384], [1.4167763897264567], [-1.1942683643774812], [-1.763274043988726], [-0.6412161150357101], [0.30003627086326545], [-0.7901147975508024], [-0.7741613672813281], [-2.4226824951269914], [-1.896219296234344], [-1.3644382872518723], [2.304850674727185], [-0.25833378856833034], [0.4861596240071305], [0.6829185973306452], [0.19368006906677096], [-2.5609455574624347], [0.37980342221063623], [-0.6039914444069372], [0.4542527634681824], [-0.8486107085388743], [-1.88026586596487], [-1.0613231121318631], [-0.23706254820903144], [-0.7369366966525551], [-1.1889505542876564], [-1.8270877650666228], [0.5233842946359037], [0.8477707101152115], [-1.7739096641683758], [-0.4497749518020202], [-0.02435014461604267], [0.6935542175102947], [-0.7422545067423799], [0.1617732085278226], [0.975398152271005], [0.007556715922905682], [1.1083434045166227], [0.9062666211032835], [0.47552400382748106], [-0.04030357488551673], [0.6031514459832744], [0.17240882870747204], [1.943239588619104], [-1.5292904000364387], [0.3159897011327395], [0.4010746625699351], [-2.3056906731508477], [-0.4391393316223708], [-0.09348167578376398], [-0.25833378856833034], [0.24685816996501822], [-0.29555845919710333], [-0.5401777233290405], [-0.9230600497964204], [0.49679524418677995], [0.2840828405937912], [-0.04030357488551673], [-0.16793101704131003], [-0.2902406491072786], [2.5813767993980705], [0.5074308643664294], [0.6031514459832744], [0.8849953807439845], [0.12986634798887425], [-0.21579130784973255], [-2.1302029401866323], [0.6829185973306452], [-0.3327831298258764], [-0.49231743252061805], [-0.8805175690778226], [0.8052282293966138], [0.9700803421811801], [0.9009488110134588], [-1.0294162515929148], [0.41702809283940917], [-1.02409844150309], [0.9913515825404791], [0.6722829771509957], [-0.15197758677183584], [-0.625262684766236], [-1.3750739074315217], [2.8313138736198322], [0.21495130942606985], [-0.17324882713113474], [-0.7688435571915035], [1.0392118733489015], [-0.5189064829697416], [-0.1466597766820111], [-0.5401777233290405], [-0.019032334526217828], [-0.0030789042567437685], [-0.9762381506946676], [-0.5667667737781641], [-0.1838844473107842], [-0.32746531973605164], [-0.5774023939578136], [-1.502701349587315], [-0.23174473811920673], [0.6563295468815217], [-1.1357724533894091], [-0.35405437018517527], [0.5871980157138004], [-0.5774023939578136], [0.6510117367916969], [0.19899787915659556], [0.762685748678016], [1.1189790246962725], [-1.7100959430904792], [0.5021130542766048], [-0.08284605560411454], [0.3532143717615125], [-1.2793533258146768], [-0.5774023939578136], [0.21495130942606985], [0.41702809283940917], [0.028827956282204584], [-1.8270877650666228], [1.1721571255945196], [-1.0028272011437913], [0.16709101861764744], [-0.8911531892574721], [-1.2846711359045015], [1.0392118733489015], [0.7414145083187171], [0.5659267753545015], [-1.6090575513838095], [-0.9177422397065957], [0.6403761166120474], [0.19899787915659556], [0.33726094149203845], [-0.23706254820903144], [0.4329815231088835], [-0.853928518628699], [0.6829185973306452], [1.9485573987089286], [0.2681294103243171], [1.124296834786097], [1.2093817962232927], [-0.5454955334188651], [-0.6518517352153596], [-0.08284605560411454], [0.7786391789474902], [-1.0932299726708115], [1.3263736181994363], [-0.07221043542446508], [-1.0134628213234407], [-1.0719587323115125], [1.852836817092084], [0.9115844311931083], [0.044781386551678876], [3.150382479009316], [-1.348484856982398], [-0.8486107085388743], [0.10859510762957535], [0.3159897011327395], [1.2466064668520658], [0.4861596240071305], [-1.178314934108007], [-0.15197758677183584], [3.2620564908956347], [1.751798425385414], [-1.1942683643774812], [0.32130751122256435], [-1.5186547798567889], [-0.4285037114427213], [0.23622254978536875], [1.6613956538583938], [0.1405019681685237], [0.7360966982288925], [-1.4761122991381914], [-0.45509276189184494], [-0.2796050289276291], [-0.17324882713113474], [-0.5614489636883393], [0.5127486744562543], [-1.3059423762638003], [-2.3641865841389196], [-0.5242242930595664], [1.906014917990331], [-0.6943942159339573], [0.8264994697559127], [-0.12007072623288761], [0.40639247265975975], [0.3957568524801103], [-0.3168296995564022], [0.5978336358934496], [-2.07170702919856], [1.044529683438726], [-0.4072324710834224], [1.278513327391014], [2.0230067399664753], [1.5071791612534768], [-0.8858353791676473], [1.8741080574513829], [-0.6731229755746585], [-0.5986736343171124], [-0.6837585957543079], [0.03414576637202943], [-0.1466597766820111], [0.06605262691097755], [-1.5611972605753868], [-0.8486107085388743], [-0.5082708627900923], [0.012874526012730526], [-1.8270877650666228], [-1.4016629578806452], [-0.5561311535985146], [0.3532143717615125], [-0.2051556876700831], [1.4167763897264567], [-0.2211091179395573], [-0.13070634641253706], [-0.30619407937675275], [1.4805901108043533], [-0.6837585957543079], [0.6350583065222228], [-0.43382152153254605], [0.5659267753545015], [1.198746176043643], [-0.36468999036482475], [-0.42318590135289663], [-0.15197758677183584], [-0.6039914444069372], [0.6935542175102947], [-0.7103476462034315], [-0.625262684766236], [-0.5454955334188651], [-0.779479177371153], [-0.19983787758025837], [0.6722829771509957], [0.060734816821152934], [0.9115844311931083], [-0.3487365600953506], [-0.5720845838679888], [-2.7789757711452476], [-0.36468999036482475], [0.5340199148155531], [-0.4976352426104428], [-0.4869996224307933], [-0.7635257471016788], [-1.6462822220125823], [0.5712445854443261], [-0.625262684766236], [-1.0613231121318631], [-0.6837585957543079], [-1.5080191596771397], [1.6348066034092703], [0.23090473969554393], [-1.4122985780602948], [0.8690419504745105], [0.47552400382748106], [0.06605262691097755], [2.6451905204759676], [1.8475190070022594], [0.762685748678016], [0.40639247265975975], [0.5765623955341509], [-1.6462822220125823], [0.895631000923634], [-0.28492283901745385], [0.7041898376899441], [0.023510146192379976], [0.1405019681685237], [0.076688247090627], [-1.1304546432995846], [1.3901873392773332], [0.0979594874499259], [-0.6518517352153596], [-0.7582079370118541], [-0.7369366966525551], [-0.8432928984490495], [1.491225730984003], [-0.6943942159339573], [0.7041898376899441], [-0.2689694087479798], [1.6560778437685693], [-0.9656025305150181], [0.459570573558007], [-0.7475723168322046], [-1.4122985780602948], [-0.8220216580897508], [0.32130751122256435], [0.3532143717615125], [-0.4444571417121955], [0.2681294103243171], [-0.4497749518020202], [-0.5029530527002675], [1.3476448585587353], [-0.12538853632271232], [1.1189790246962725], [0.4914774340969553], [-1.4920657294076656], [0.3744856121208114], [-0.36468999036482475], [-1.1623615038385327], [-0.912424429616771], [1.0977077843369736], [0.24685816996501822], [1.4008229594569823], [1.4327298199959309], [-0.1838844473107842], [-1.1676793139283577], [-0.4072324710834224], [-1.614375361473634], [-0.41255028117324716], [-0.4391393316223708], [-0.3700078004546495], [0.1351841580786991], [-1.8696302457852205], [-0.662487355395009], [0.8849953807439845], [1.0817543540674992], [-0.5135886728799169], [-0.10943510605323815], [0.6191048762527486], [0.9381734816422318], [0.422345902929234], [-1.1942683643774812], [-1.0187806314132655], [0.592515825803625], [-0.2211091179395573], [0.19899787915659556], [0.08732386727027644], [-2.1408385603662814], [0.4648883836478316], [-0.4285037114427213], [-0.28492283901745385], [-1.3378492368027486], [1.1881105558639937], [-0.10411729596341343], [-2.2578303823424255], [0.858406330294861], [2.395253446254205], [1.5178147814331264], [0.3106718910429149], [-1.481430109228016], [-1.1038655928504608], [0.3532143717615125], [0.8318172798457375], [2.6451905204759676], [-1.0187806314132655], [1.2306530365825916], [1.07111873388785], [-1.2474464652757284], [0.5659267753545015], [-1.3059423762638003], [-0.17856663722095947], [-0.7050298361136068], [-0.17324882713113474], [-1.7260493733599533], [1.9326039684394545], [1.890061487720857], [-0.7475723168322046], [-1.21553960473678], [1.1934283659538183], [-1.0081450112336159], [-0.6199448746764114], [0.14581977825834855], [0.762685748678016], [-0.8592463287185237], [-1.3165779964434496], [-1.1038655928504608], [0.6669651670611711], [1.124296834786097], [-0.3912790408139484], [0.2043156892464204], [-0.47636400225114384], [-0.38596123072412364], [0.4542527634681824], [0.23090473969554393], [1.2678777072113643], [-0.49231743252061805], [-0.359372180275], [-0.6784407856644833], [-0.3806434206342989], [-2.1408385603662814], [-0.4285037114427213], [1.0764365439776746], [-0.9975093910539665], [0.9115844311931083], [-0.3912790408139484], [-1.141090263479234], [-0.4019146609935978], [-0.25833378856833034], [0.6084692560730991], [-0.8379750883592249], [0.47552400382748106], [-0.8007504177304519], [2.007053309697001], [-0.27428721883780444], [-0.3327831298258764], [-1.0772765424013373], [-1.4122985780602948], [-0.49231743252061805], [-0.7635257471016788], [0.5499733450850272], [-0.15729539686166058], [-0.7316188865627304], [3.809790930147581], [0.2255869296057193], [-0.23174473811920673], [0.4861596240071305], [-0.8273394681795754], [0.16709101861764744], [-0.6731229755746585], [-0.7954326076406271], [-0.11475291614306289], [-0.9762381506946676], [0.209633499336245], [-0.0030789042567437685], [-0.6837585957543079], [0.05541700673132833], [-0.625262684766236], [-0.4285037114427213], [0.30003627086326545], [-0.9071066195269463], [-0.1360241565023618], [-0.9443312901557194], [-0.19452006749043366], [-0.5295421031493911], [-1.3218958065332744], [-0.16793101704131003], [0.36916780203098676], [-1.1729971240181822], [0.7680035587678409], [-1.2261752249164295], [-0.30619407937675275], [-0.09348167578376398], [0.5659267753545015], [-0.25833378856833034], [-0.4869996224307933], [1.2466064668520658], [-1.1145012130301104], [-0.5827202040476382], [-0.4285037114427213], [0.7520501284983665], [0.25749379014466767], [-0.7954326076406271], [-0.25833378856833034], [2.921716645146853], [0.858406330294861], [-1.784545284348025], [-0.4285037114427213], [-0.07221043542446508], [0.6191048762527486], [-0.2051556876700831], [-0.6784407856644833], [2.1612698023019177], [-0.1413419665921864], [0.7999104193067892], [0.2947184607734406], [-0.43382152153254605], [0.007556715922905682], [-1.4282520083297687], [-0.6571695453051845], [-0.2796050289276291], [1.1934283659538183], [-1.1357724533894091], [-0.300876269286928], [0.16709101861764744], [0.38512123230046086], [0.2255869296057193], [-1.9547152072224163], [-1.0294162515929148], [-1.8004987146174993], [0.018192336102555134], [-0.08816386569393926], [0.8105460394864387], [-0.27428721883780444], [-0.853928518628699], [0.5340199148155531], [0.8211816596660881], [-0.3487365600953506], [-0.5401777233290405], [0.40639247265975975], [0.9434912917320567], [0.16709101861764744], [-1.7420028036294273], [1.9379217785292795], [0.23090473969554393], [-0.47104619216131915], [-0.7528901269220294], [-1.2793533258146768], [0.8477707101152115], [-1.0294162515929148], [0.7945926092169643], [1.1402502650555715], [-0.9443312901557194], [0.422345902929234], [-1.1464080735690587], [-0.3965968509037731], [2.4112068765236794], [-0.5774023939578136], [-0.6093092544967619], [1.7943409061040119], [0.3053540809530901], [-0.5933558242272877], [-0.4976352426104428], [-0.25833378856833034], [-1.5292904000364387], [-1.6250109816532834], [0.9700803421811801], [0.3638499919411619], [0.842452900025387], [-0.9230600497964204], [-0.32214750964622696], [0.9169022412829329], [0.9860337724506545], [-0.2689694087479798], [0.9381734816422318], [1.2412886567622408], [0.4861596240071305], [0.6084692560730991], [1.8049765262836615], [-0.4391393316223708], [0.6297404964323979], [0.2734472204141417], [0.6191048762527486], [-0.6731229755746585], [-0.34341875000552585], [-0.056257005154991026], [-0.32746531973605164], [0.9275378614625823], [-0.8858353791676473], [-1.4920657294076656], [-0.6890764058441328], [0.24154035987519337], [-0.04030357488551673], [-0.12538853632271232], [-0.13070634641253706], [-0.5082708627900923], [1.618853173139796], [-0.8113860379101013], [0.4329815231088835], [0.35853218185133734], [0.15113758834817315], [0.2043156892464204], [0.9328556715524072], [-0.0775282455142898], [0.3319431314022136], [2.326121915086484], [1.4167763897264567], [-0.6199448746764114], [0.9488091018218813], [1.5497216419720747], [-0.09348167578376398], [-0.36468999036482475], [-0.1838844473107842], [0.27876503050396656], [0.5074308643664294], [0.08732386727027644], [-0.7847969874609776], [-0.41255028117324716], [-0.23174473811920673], [-0.13070634641253706], [-1.2102217946469553], [0.24685816996501822], [0.37980342221063623], [0.039463576461854034], [0.3744856121208114], [-0.12007072623288761], [0.6829185973306452], [-0.1413419665921864], [0.08200605718045184], [2.1612698023019177], [-0.04030357488551673], [0.6191048762527486], [-0.646533925125535], [-1.8749480558750453], [-0.9390134800658945], [0.9488091018218813], [0.7839569890373149], [0.2521759800548428], [-0.4657283820714944], [-0.3115118894665775], [1.4593188704450544], [-0.6518517352153596], [-0.27428721883780444], [1.3423270484689107], [-0.7422545067423799], [0.09264167736010129], [-0.5082708627900923], [0.028827956282204584], [-1.0772765424013373], [-0.7422545067423799], [0.16709101861764744], [0.7680035587678409], [0.6988720276001195], [0.9966693926303036], [0.2521759800548428], [1.2200174164029418], [-1.635646601832933], [-0.5189064829697416], [0.012874526012730526], [-0.359372180275], [0.11923072780922479], [-0.7369366966525551], [0.2840828405937912], [1.9219683482598051], [0.08200605718045184], [-0.6199448746764114], [0.5021130542766048], [-0.6093092544967619], [0.30003627086326545], [0.8211816596660881], [-1.1038655928504608], [0.018192336102555134], [0.1351841580786991], [-1.2846711359045015], [-0.09348167578376398], [-0.17856663722095947], [2.1240451316731446], [0.6669651670611711], [3.0280728469433473], [-1.4282520083297687], [0.9647625320913555], [0.16709101861764744], [0.1777266387972969], [-0.23174473811920673], [-0.9230600497964204], [0.5021130542766048], [0.4808418139173059], [-0.19983787758025837], [-0.17856663722095947], [0.1830444488871215], [0.08200605718045184], [-2.741751100516475], [-0.19983787758025837], [0.12986634798887425], [1.7252093749362905], [0.8477707101152115], [-1.465476678958542], [1.6294887933194457], [-0.056257005154991026], [-0.8060682278202764], [0.007556715922905682], [-0.0030789042567437685], [0.592515825803625], [-0.15197758677183584], [-1.1464080735690587], [-0.8060682278202764], [-1.1889505542876564], [0.9222200513727578], [0.7945926092169643], [-0.7688435571915035], [-1.3431670468925734], [2.2782616242780613], [0.6084692560730991], [-0.47636400225114384], [0.5659267753545015], [-0.4072324710834224], [-0.3912790408139484], [0.5180664845460788], [0.17240882870747204], [-0.5614489636883393], [0.4117102827495846], [-0.6093092544967619], [-0.13070634641253706], [-1.1038655928504608], [0.3532143717615125], [1.6933025143973424], [0.19899787915659556], [0.3319431314022136], [-1.635646601832933], [-0.12538853632271232], [-0.2796050289276291], [-0.28492283901745385], [1.2146996063131172], [0.5659267753545015], [-0.04030357488551673], [0.12454853789904964], [-0.5401777233290405], [-0.09879948587358871], [3.4641332743089746], [-0.07221043542446508], [0.9169022412829329], [-0.23174473811920673], [-1.5292904000364387], [1.5603572621517243], [-1.460158868868717], [-2.412046874947342], [-1.2793533258146768], [-0.9921915809641417], [-0.29555845919710333], [1.2466064668520658], [0.7095076477797689], [-0.5295421031493911], [1.2625598971215397], [-1.2421286551859037], [-1.8270877650666228], [-0.3700078004546495], [-0.5295421031493911], [0.4117102827495846], [-0.5508133435086899], [0.5818802056239756], [-0.16793101704131003], [-0.6146270645865866], [-0.5667667737781641], [-0.23174473811920673], [0.6935542175102947], [-0.5986736343171124], [-0.5986736343171124], [-0.9709203406048429], [0.8318172798457375], [0.24154035987519337], [-0.875199758987998], [0.6722829771509957], [1.124296834786097], [0.342578751581863], [-1.2368108450960789], [-0.7050298361136068], [-0.15729539686166058], [0.6031514459832744], [0.5659267753545015], [-0.2902406491072786], [0.342578751581863], [-0.625262684766236], [1.3795517190976838], [-0.6146270645865866], [0.6510117367916969], [0.44893495337835754], [-0.4497749518020202], [-0.9230600497964204], [-1.3006245661739755], [-0.17856663722095947], [-0.5667667737781641], [-0.17324882713113474], [-1.2261752249164295], [0.018192336102555134], [1.8209299565531354], [0.7573679385881914], [-0.9017888094371216], [0.2947184607734406], [0.2255869296057193], [-0.8645641388083485], [-3.6085541451579046], [2.4537493572422773], [0.16709101861764744], [-1.2793533258146768], [-1.1145012130301104], [0.06605262691097755], [-1.3165779964434496], [-0.1413419665921864], [-1.9281261567732928], [0.03414576637202943], [-1.0506874919522138], [-1.6409644119227578], [-0.08284605560411454], [-0.4285037114427213], [-0.5508133435086899], [-0.056257005154991026], [0.3957568524801103], [-1.220857414826605], [-0.3381009399157011], [0.2043156892464204], [-0.12538853632271232], [-0.36468999036482475], [-0.3381009399157011], [0.2255869296057193], [1.092389974247149], [1.2306530365825916], [0.35853218185133734], [0.5871980157138004], [1.3689160989180342], [-1.3750739074315217], [0.7680035587678409], [1.6028997428703222], [0.6669651670611711], [-0.30619407937675275], [0.10859510762957535], [0.6297404964323979], [-0.7847969874609776], [0.9913515825404791], [-0.625262684766236], [-0.02435014461604267], [2.0336423601461244], [-0.12538853632271232], [0.5233842946359037], [1.0764365439776746], [0.5340199148155531], [-1.0294162515929148], [0.1405019681685237], [0.018192336102555134], [-1.7260493733599533], [1.1296146448759217], [1.204063986133468], [-0.09879948587358871], [-0.4816818123409686], [-1.1038655928504608], [0.762685748678016], [-0.7103476462034315], [-0.1360241565023618], [0.1405019681685237], [-0.6837585957543079], [-0.13070634641253706], [-1.327213616623099], [-0.7369366966525551], [-0.5720845838679888], [0.725461078049243], [-0.2689694087479798], [0.24685816996501822], [-0.32214750964622696], [0.2628116002344923], [0.5393377249053778], [-0.45509276189184494], [0.9913515825404791], [0.43829933319870806], [-0.15197758677183584], [1.6294887933194457], [0.05009919664150349], [1.0232584430794271], [0.7148254578695936], [0.24154035987519337], [0.039463576461854034], [-0.9336956699760699], [-0.35405437018517527], [0.6191048762527486], [1.4593188704450544], [0.8158638495762632], [1.8262477666429604], [0.38512123230046086], [0.209633499336245], [1.4486832502654052], [0.8052282293966138], [0.028827956282204584], [-0.10411729596341343], [-0.625262684766236], [-1.8324055751564476], [-0.08284605560411454], [1.3848695291875086], [0.8211816596660881], [-0.17856663722095947], [1.4380476300857554], [0.11923072780922479], [-0.7582079370118541], [0.209633499336245], [-0.38596123072412364], [0.24685816996501822], [-0.6784407856644833], [-1.0294162515929148], [-1.0081450112336159], [-0.32214750964622696], [-0.41255028117324716], [-0.8167038479999259], [-0.8698819488981732], [-0.17856663722095947], [0.7360966982288925], [0.2043156892464204], [0.4914774340969553], [-0.18920225740060892], [-0.32214750964622696], [-0.2636515986581551], [-1.1145012130301104], [-0.013714524436393219], [-0.15197758677183584], [-0.5774023939578136], [-0.4444571417121955], [-1.3803917175213463], [0.38512123230046086], [-0.7103476462034315], [0.7307788881390677], [2.001735499607176], [-0.06157481524481563], [-0.8007504177304519], [1.3848695291875086], [-0.7901147975508024], [0.5446555349952026], [0.24154035987519337], [0.459570573558007], [0.7786391789474902], [-0.5401777233290405], [-0.8113860379101013], [-0.8113860379101013], [0.08200605718045184], [-0.02435014461604267], [0.43829933319870806], [0.23622254978536875], [0.08732386727027644], [-1.6303287917431084], [2.5654233691285966], [-0.7263010764729058], [0.5871980157138004], [0.6882364074204701], [0.08732386727027644], [0.22026911951589445], [0.4808418139173059], [1.331691428289261], [-0.8060682278202764], [-1.1145012130301104], [0.3159897011327395], [-0.6412161150357101], [-0.3806434206342989], [-0.1626132069514853], [1.1774749356843441], [-0.04562138497534157], [-0.6093092544967619], [-0.07221043542446508], [-0.15197758677183584], [0.209633499336245], [-0.3168296995564022], [0.6403761166120474], [0.24154035987519337], [-0.2636515986581551], [-1.5611972605753868], [0.0979594874499259], [2.1134095114934954], [-0.2051556876700831], [1.9272861583496297], [-0.9071066195269463], [2.10809170140367], [0.8530885202050364], [-0.8273394681795754], [0.3744856121208114], [-0.6943942159339573], [-1.1889505542876564], [0.32130751122256435], [-0.6305804948560608], [-2.449271545576115], [-0.32746531973605164], [-0.056257005154991026], [1.1402502650555715], [0.33726094149203845], [-0.6199448746764114], [-1.2580820854553778], [0.25749379014466767], [-0.2051556876700831], [0.8318172798457375], [2.69305081128439], [-0.625262684766236], [-0.5720845838679888], [0.2628116002344923], [-0.6305804948560608], [-0.3327831298258764], [0.9062666211032835], [-2.337597533689796], [0.5393377249053778], [0.36916780203098676], [0.342578751581863], [0.2255869296057193], [-0.019032334526217828], [0.33726094149203845], [-0.3965968509037731], [-0.06157481524481563], [0.40639247265975975], [0.7201432679594184], [1.1881105558639937], [-0.2051556876700831], [0.8318172798457375], [-1.805816524707324], [0.8371350899355622], [0.5340199148155531], [1.204063986133468], [1.1774749356843441], [1.8953792978106816], [-0.6837585957543079], [0.9913515825404791], [1.1030255944267982], [-0.5082708627900923], [-1.444205438599243], [0.5659267753545015], [-0.4497749518020202], [-1.045369681862389], [-0.8273394681795754], [-0.5242242930595664], [0.05009919664150349], [1.757116235475239], [0.2255869296057193], [1.5071791612534768], [-0.029667954705867278], [0.28940065068361603], [0.3957568524801103], [0.32662532131238897], [1.3795517190976838], [0.7733213688576654], [-0.10411729596341343], [0.012874526012730526], [1.2306530365825916], [1.8581546271819085], [2.4005712563440302], [-0.6997120260237822], [-0.6412161150357101], [0.342578751581863], [0.8158638495762632], [0.6829185973306452], [2.150634182122268], [0.8903131908338094], [1.4327298199959309], [0.8318172798457375], [-0.056257005154991026], [-1.2527642753655532], [-0.32214750964622696], [1.2625598971215397], [-0.07221043542446508], [-2.2578303823424255], [0.023510146192379976], [-0.15729539686166058], [-0.2211091179395573], [1.4274120099061063], [-0.5986736343171124], [1.0392118733489015], [0.12986634798887425], [0.1405019681685237], [-0.8113860379101013], [0.6563295468815217], [0.6669651670611711], [0.4117102827495846], [-1.332531426712924], [-0.6997120260237822], [-0.8326572782694003], [-0.3753256105444742], [0.40639247265975975], [0.9381734816422318], [-0.625262684766236], [0.3106718910429149], [-0.8964709993472968], [1.5071791612534768], [-0.12538853632271232], [1.5709928823313735], [0.05009919664150349], [-0.779479177371153], [-1.0187806314132655], [2.288897244457711], [-0.2104734977599078], [-1.6675534623718813], [0.3106718910429149], [-1.0294162515929148], [0.3957568524801103], [0.8743597605643351], [1.1030255944267982], [-0.019032334526217828], [-0.03498576479569212], [-0.5082708627900923], [-1.6781890825515307], [-0.11475291614306289], [-0.5880380141374629], [-1.1676793139283577], [-1.4920657294076656], [-1.3538026670722227], [-0.0775282455142898], [0.17240882870747204], [-1.2633998955452026], [-2.1195673200069827], [-0.5082708627900923], [-0.5827202040476382], [-0.300876269286928], [-0.6518517352153596], [-0.6039914444069372], [-1.157043693748708], [0.23622254978536875], [-0.42318590135289663], [0.028827956282204584], [0.6297404964323979], [-0.056257005154991026], [2.5016096480506995], [1.3157379980197872], [-0.09879948587358871], [-0.4444571417121955], [1.331691428289261], [-0.12538853632271232], [0.7999104193067892], [-0.41255028117324716], [1.5071791612534768], [0.07137043700080238], [2.326121915086484], [1.6348066034092703], [-0.7422545067423799], [1.0764365439776746], [0.8318172798457375], [-0.03498576479569212], [-0.15197758677183584], [-0.15197758677183584], [-0.6358983049458855], [0.07137043700080238], [-0.8805175690778226], [2.134680751852794], [-0.8167038479999259], [0.6244226863425734], [-0.7263010764729058], [0.023510146192379976], [-0.41255028117324716], [-0.1626132069514853], [1.6082175529601468], [-0.5667667737781641], [0.8318172798457375], [1.5709928823313735], [-0.7422545067423799], [1.5869463126008478], [0.6988720276001195], [-0.5508133435086899], [0.6829185973306452], [1.2625598971215397], [-0.7635257471016788], [-0.43382152153254605], [-0.7635257471016788], [-0.6943942159339573], [0.12986634798887425], [-0.4019146609935978], [-0.8167038479999259], [-2.677937379438578], [0.21495130942606985], [-1.2421286551859037], [1.3263736181994363], [0.40639247265975975], [-0.47104619216131915], [0.6829185973306452], [-1.141090263479234], [0.5552911551748521], [-0.04562138497534157], [-0.0030789042567437685], [0.3744856121208114], [-0.47104619216131915], [-0.4604105719816697], [0.32662532131238897], [2.613283659937019], [-0.15729539686166058], [-1.5984219312041599], [1.204063986133468], [1.757116235475239], [-0.7528901269220294], [0.3053540809530901], [1.2200174164029418], [-0.008396714346568376], [-0.5720845838679888], [-0.19452006749043366], [1.1402502650555715], [-0.7528901269220294], [0.6935542175102947], [-1.481430109228016], [-0.6146270645865866], [1.0285762531692522], [-0.43382152153254605], [0.1617732085278226], [-0.3381009399157011], [0.7520501284983665], [-0.9975093910539665], [-1.5771506908448611], [-0.34341875000552585], [1.5231325915229512], [0.6616473569713464], [-0.008396714346568376], [-0.17856663722095947], [-1.2421286551859037], [0.8052282293966138], [0.5021130542766048], [1.2359708466724162], [1.0870721641573238], [0.11923072780922479], [-0.8060682278202764], [0.895631000923634], [-0.8167038479999259], [-0.6943942159339573], [-0.4869996224307933], [-1.3963451477908206], [-0.4816818123409686], [-0.8592463287185237], [-0.3381009399157011], [-0.34341875000552585], [-0.5348599132392159], [1.4167763897264567], [2.304850674727185], [1.2146996063131172], [0.47020619373765643], [0.8211816596660881], [0.37980342221063623], [1.565675072241549], [-2.4280003052168166], [-0.7901147975508024], [-0.15197758677183584], [0.7520501284983665], [-0.6943942159339573], [0.2628116002344923], [1.1296146448759217], [-0.8060682278202764], [-0.38596123072412364], [1.64544222358892], [-0.1413419665921864], [0.7041898376899441], [-0.5454955334188651], [-0.3381009399157011], [-0.1360241565023618], [2.6398727103861424], [-0.30619407937675275], [0.3638499919411619], [-0.7475723168322046], [-0.8432928984490495], [0.15113758834817315], [-1.0772765424013373], [0.7892747991271397], [0.35853218185133734], [0.5127486744562543], [0.3957568524801103], [-0.19983787758025837], [-0.12538853632271232], [-0.359372180275], [-0.6093092544967619], [-0.8007504177304519], [2.267626004098412], [-0.12538853632271232], [-0.6890764058441328], [-1.502701349587315], [0.7360966982288925], [0.12454853789904964], [-0.1466597766820111], [-1.1729971240181822], [-1.465476678958542], [0.592515825803625], [0.07137043700080238], [0.6616473569713464], [0.6882364074204701], [0.44893495337835754], [0.1351841580786991], [-0.6678051654848338], [-0.12538853632271232], [-1.3218958065332744], [-0.4497749518020202], [0.9594447220015307], [-0.9336956699760699], [-0.6571695453051845], [-1.88026586596487], [0.4861596240071305], [0.2255869296057193], [0.23622254978536875], [-0.09348167578376398], [-0.35405437018517527], [-0.11475291614306289], [0.4010746625699351], [-0.47104619216131915], [-1.3378492368027486], [-0.9921915809641417], [0.2043156892464204], [-0.16793101704131003], [0.44893495337835754], [-0.04030357488551673], [3.3418236422430057], [-0.3912790408139484], [0.47020619373765643], [0.342578751581863], [0.3957568524801103], [-0.18920225740060892], [1.6028997428703222], [1.3635982888282097], [0.6563295468815217], [0.8318172798457375], [0.24154035987519337], [1.2678777072113643], [1.065800923798025], [-1.5665150706652116], [0.3319431314022136], [-1.4122985780602948], [0.6244226863425734], [1.4061407695468073], [-0.0775282455142898], [0.8158638495762632], [-0.25301597847850565], [-1.0028272011437913], [0.6722829771509957], [1.8049765262836615], [-0.32746531973605164], [-1.1145012130301104], [-1.4761122991381914], [0.7945926092169643], [-1.0134628213234407], [0.7999104193067892], [-0.02435014461604267], [1.6879847043075173], [2.3899356361643807], [0.422345902929234], [-0.8220216580897508], [0.1351841580786991], [-0.19452006749043366], [-0.7847969874609776], [-0.7316188865627304], [-1.4016629578806452], [0.8318172798457375], [0.5552911551748521], [0.2255869296057193], [-1.6675534623718813], [-0.4657283820714944], [0.9913515825404791], [-0.6305804948560608], [0.41702809283940917], [-0.008396714346568376], [0.8318172798457375], [-0.4976352426104428], [-0.1360241565023618], [-1.5665150706652116], [-0.2689694087479798], [0.6191048762527486], [0.08732386727027644], [0.5659267753545015], [1.1508858852352206], [-0.8964709993472968], [-0.875199758987998], [0.07137043700080238], [2.4484315471524525], [2.480338407691401], [0.5712445854443261], [-1.385709527611171], [-0.3753256105444742], [0.6722829771509957], [1.7943409061040119], [-0.5986736343171124], [-0.08284605560411454], [0.9222200513727578], [1.0073050128099534], [-0.3912790408139484], [-0.9496491002455439], [0.3053540809530901], [-1.1517258836588833], [1.3742339090078588], [-0.8592463287185237], [1.1934283659538183], [0.15113758834817315], [-1.0134628213234407], [0.018192336102555134], [-0.9390134800658945], [0.10859510762957535], [0.5659267753545015], [0.0979594874499259], [0.012874526012730526], [0.35853218185133734], [0.8371350899355622], [-0.7475723168322046], [0.7520501284983665], [-0.1413419665921864], [-0.4072324710834224], [-2.0078933081206634], [0.05541700673132833], [-0.3806434206342989], [1.3901873392773332], [-0.8964709993472968], [-0.0775282455142898], [-0.5933558242272877], [-1.3431670468925734], [0.842452900025387], [2.0868204610443715], [1.5869463126008478], [1.5284504016127758], [0.07137043700080238], [0.32130751122256435], [0.7839569890373149], [-1.0134628213234407], [0.30003627086326545], [-0.32746531973605164], [0.1830444488871215], [-0.6305804948560608], [0.060734816821152934], [-0.9230600497964204], [0.2628116002344923], [-1.1517258836588833], [-1.1357724533894091], [-0.2636515986581551], [-0.2104734977599078], [-1.2368108450960789], [1.1083434045166227], [0.16709101861764744], [-1.9653508274020657], [1.6560778437685693], [-0.3115118894665775], [-1.6462822220125823], [-1.311260186353625], [-0.18920225740060892], [-0.6997120260237822], [-0.23706254820903144], [-1.5133369697669643], [-0.5880380141374629], [0.7467323184085419], [0.592515825803625], [0.6137870661629239], [1.358280478738385], [1.618853173139796], [1.0977077843369736], [-0.6199448746764114], [-1.1836327441978316], [-0.18920225740060892], [1.677349084127868], [-0.6837585957543079], [-0.625262684766236], [0.9009488110134588], [1.1934283659538183], [-1.327213616623099], [-0.9177422397065957], [-0.3487365600953506], [0.47552400382748106], [-0.23174473811920673], [0.012874526012730526], [-0.16793101704131003], [-1.157043693748708], [0.9647625320913555], [-0.3965968509037731], [-0.8220216580897508], [0.2947184607734406], [0.10327729753975073], [-1.178314934108007], [-1.1145012130301104], [-0.09879948587358871], [0.5340199148155531], [-0.42318590135289663], [-0.8113860379101013], [0.3532143717615125], [-0.2211091179395573], [0.8690419504745105], [0.9275378614625823], [1.884743677631032], [-0.4444571417121955], [0.342578751581863], [-0.3700078004546495], [-0.2211091179395573], [2.4112068765236794], [-1.0081450112336159], [-1.5452438303059128], [-0.3168296995564022], [1.225335226492767], [2.2144479032001647], [-2.0398001686596117], [0.6456939267018723], [-0.4657283820714944], [-0.08816386569393926], [0.3106718910429149], [1.698620324487167], [1.278513327391014], [-0.24238035829885618], [0.40639247265975975], [-1.5558794504855622], [0.3053540809530901], [0.1617732085278226], [0.6456939267018723], [1.4593188704450544], [-0.23706254820903144], [0.4914774340969553], [-0.21579130784973255], [1.8422011969124341], [0.3638499919411619], [0.5499733450850272], [0.2840828405937912], [0.9115844311931083], [0.7999104193067892], [-0.06157481524481563], [-0.09879948587358871], [-0.9815559607844923], [-0.30619407937675275], [-0.28492283901745385], [0.9700803421811801], [-1.784545284348025], [-0.662487355395009], [0.5499733450850272], [-0.7050298361136068], [-0.4391393316223708], [-0.29555845919710333], [0.8690419504745105], [0.28940065068361603], [0.42766371301905864], [-0.7103476462034315], [0.2255869296057193], [-1.8483590054259218], [-0.08284605560411454], [-0.019032334526217828], [0.028827956282204584], [1.2572420870317151], [-0.4497749518020202], [-0.9762381506946676], [-1.066640922221688], [2.1134095114934954], [0.5552911551748521], [-1.3006245661739755], [-0.19983787758025837], [-0.5561311535985146], [-0.7954326076406271], [-0.5348599132392159], [-1.0134628213234407], [-0.7422545067423799], [-0.28492283901745385], [-2.396093444677868], [0.9966693926303036], [-0.8805175690778226], [1.2731955173011893], [1.4220941998162813], [-1.4761122991381914], [-1.0772765424013373], [0.34789656167168787], [1.3476448585587353], [-0.3327831298258764], [2.6451905204759676], [1.1881105558639937], [-1.0985477827606362], [-0.3487365600953506], [1.464636680534879], [-0.9656025305150181], [0.38512123230046086], [0.8318172798457375], [-0.9549669103353686], [2.304850674727185], [0.9009488110134588], [-0.6518517352153596], [-0.019032334526217828], [-0.9496491002455439], [0.6722829771509957], [-0.6943942159339573], [0.1617732085278226], [0.8903131908338094], [-1.3006245661739755], [-0.7741613672813281], [-1.4069807679704698], [0.39043904239028565], [-0.9336956699760699], [-1.7154137531803038], [-0.5082708627900923], [1.2572420870317151], [-1.3059423762638003], [-0.11475291614306289], [1.4752723007145288], [0.422345902929234], [-0.43382152153254605], [0.8530885202050364], [-2.449271545576115], [1.2412886567622408], [-0.8379750883592249], [-0.08284605560411454], [-0.9709203406048429], [-0.2104734977599078], [1.8581546271819085], [-0.05093919506516618], [0.5446555349952026], [-0.2476981683886809], [-2.284419432791549], [-0.300876269286928], [-0.2636515986581551], [0.3053540809530901], [0.1617732085278226], [-1.465476678958542], [-0.47636400225114384], [-0.7263010764729058], [0.6244226863425734], [-1.8270877650666228], [-1.0400518717725642], [-0.23174473811920673], [0.36916780203098676], [3.0759331377517696], [-0.06689262533464048], [-1.0932299726708115], [0.6616473569713464], [-0.9921915809641417], [-2.342915343779621], [-2.0770248392883848], [-0.3912790408139484], [2.0868204610443715], [-1.4495232486890677], [-0.9921915809641417], [-0.6093092544967619], [1.8741080574513829], [-0.21579130784973255], [0.19368006906677096], [0.7945926092169643], [-0.45509276189184494], [0.5818802056239756], [1.1562036953250452], [-0.32746531973605164], [0.49679524418677995], [0.09264167736010129], [0.9381734816422318], [-0.2636515986581551], [1.5390860217924254], [0.9062666211032835], [-1.1198190231199352], [0.24154035987519337], [0.8690419504745105], [0.7680035587678409], [0.11923072780922479], [-0.1466597766820111], [0.8318172798457375], [-0.4178680912630719], [-0.7528901269220294], [0.35853218185133734], [-0.2476981683886809], [-0.4178680912630719], [1.491225730984003], [0.8690419504745105], [0.7892747991271397], [-0.7422545067423799], [2.187858852751041], [0.0979594874499259], [-0.7103476462034315], [-0.779479177371153], [-1.0134628213234407], [0.6191048762527486], [1.1083434045166227], [-0.9975093910539665], [1.0179406329896026], [-2.438635925396466], [1.0498474935285511], [-0.3168296995564022], [1.2625598971215397], [-0.646533925125535], [-0.7901147975508024], [0.6722829771509957], [0.1830444488871215], [-0.42318590135289663], [0.5180664845460788], [-1.0134628213234407], [-0.3381009399157011], [-2.1302029401866323], [-0.6890764058441328], [0.592515825803625], [-0.9230600497964204], [0.1405019681685237], [0.5871980157138004], [-1.3750739074315217], [-0.6571695453051845], [1.4805901108043533], [1.2997845677503128], [-1.4176163881501196], [1.5709928823313735], [0.21495130942606985], [0.40639247265975975], [-0.11475291614306289], [-0.9656025305150181], [0.4648883836478316], [1.1721571255945196], [0.7680035587678409], [-1.6196931715634588], [-0.45509276189184494], [-0.9975093910539665], [-0.779479177371153], [0.8371350899355622], [2.549469938859122], [-0.8911531892574721], [1.1296146448759217], [0.5021130542766048], [-0.34341875000552585], [0.24685816996501822], [0.21495130942606985], [-0.8805175690778226], [0.5871980157138004], [-0.5880380141374629], [-0.8432928984490495], [-2.6407127088098052], [1.485907920894178], [-0.300876269286928], [-0.226426928029382], [-1.3059423762638003], [0.018192336102555134], [-0.1466597766820111], [-0.5508133435086899], [-0.04562138497534157], [-0.8326572782694003], [0.9913515825404791], [1.4274120099061063], [0.9541269119117061], [-1.8111343347971487], [0.32130751122256435], [-0.3753256105444742], [-2.6194414684505065], [-0.02435014461604267], [-0.15197758677183584], [-0.4444571417121955], [0.6935542175102947], [0.1777266387972969], [-0.30619407937675275], [0.9488091018218813], [0.6829185973306452], [-0.3381009399157011], [0.12454853789904964], [0.7041898376899441], [-0.4072324710834224], [-0.21579130784973255], [-0.3700078004546495], [2.326121915086484], [0.37980342221063623], [-1.02409844150309], [-0.2211091179395573], [-1.0187806314132655], [-0.24238035829885618], [1.2838311374808387], [-1.5665150706652116], [1.0392118733489015], [-0.08284605560411454], [1.012622822899778], [-0.8486107085388743], [2.5122452682303495], [0.14581977825834855], [-2.013211118210488], [-0.2689694087479798], [-1.7047781330006544], [0.10327729753975073], [-0.6039914444069372], [1.2891489475706632], [0.459570573558007], [2.0921382711341963], [0.7999104193067892], [0.209633499336245], [-1.938761776952942], [-0.8379750883592249], [0.10327729753975073], [-1.385709527611171], [-0.9709203406048429], [0.3159897011327395], [-0.30619407937675275], [0.9594447220015307], [-0.9549669103353686], [0.24685816996501822], [1.3529626686485599], [-0.5242242930595664], [-0.6890764058441328], [-0.8007504177304519], [-1.6090575513838095], [-0.03498576479569212], [-0.03498576479569212], [-0.986873770874317], [-1.6941425128210048], [0.43829933319870806], [0.6722829771509957], [1.044529683438726], [-0.7263010764729058], [0.5552911551748521], [-0.4976352426104428], [0.1351841580786991], [1.4433654401755802], [1.54440383188225], [-1.2261752249164295], [1.751798425385414], [-0.5986736343171124], [0.422345902929234], [-0.08816386569393926], [-0.32214750964622696], [-0.3327831298258764], [1.2200174164029418], [-0.6890764058441328], [1.7464806152955894], [-0.7582079370118541], [-1.385709527611171], [-0.1626132069514853], [0.342578751581863], [-0.3806434206342989], [0.12986634798887425], [-0.4976352426104428], [1.1881105558639937], [0.39043904239028565], [-0.09879948587358871], [0.5552911551748521], [-0.30619407937675275], [-0.12007072623288761], [1.906014917990331], [-0.9762381506946676], [0.41702809283940917], [-0.04562138497534157], [0.7839569890373149], [-0.4285037114427213], [0.08732386727027644], [0.22026911951589445], [0.4648883836478316], [-1.0081450112336159], [1.8156121464633106], [3.2248318202668615], [-0.4816818123409686], [-1.0081450112336159], [0.039463576461854034], [-0.4816818123409686], [-2.1302029401866323], [0.25749379014466767], [0.10859510762957535], [-2.0451179787494365], [-0.6571695453051845], [0.16709101861764744], [1.1349324549657462], [0.039463576461854034], [-0.0775282455142898], [0.07137043700080238], [-0.7847969874609776], [0.3638499919411619], [-0.4391393316223708], [-0.8592463287185237], [-1.1304546432995846], [0.4648883836478316], [-0.49231743252061805], [-0.47104619216131915], [-0.7582079370118541], [0.076688247090627], [-0.8698819488981732], [-0.16793101704131003], [0.1405019681685237], [0.7786391789474902], [-0.10411729596341343], [-0.3327831298258764], [-0.10411729596341343], [-0.9975093910539665], [-0.7954326076406271], [0.34789656167168787], [-0.720983266383081], [-1.3378492368027486], [1.8953792978106816], [2.687733001194565], [-0.9496491002455439], [1.0285762531692522], [-0.09879948587358871], [-1.0825943524911619], [-0.28492283901745385], [1.2625598971215397], [0.9009488110134588], [0.1617732085278226], [-1.7739096641683758], [-1.3059423762638003], [1.2838311374808387], [0.21495130942606985], [0.4861596240071305], [-0.9496491002455439], [0.5712445854443261], [0.7839569890373149], [1.5816285025110233], [0.6456939267018723], [-1.369756097341697], [-1.0506874919522138], [-0.4816818123409686], [-0.6093092544967619], [0.47552400382748106], [1.044529683438726], [0.25749379014466767], [1.5231325915229512], [1.0977077843369736], [0.10859510762957535], [-0.27428721883780444], [-0.2476981683886809], [-0.8273394681795754], [2.2197657132899895], [0.8158638495762632], [-0.1360241565023618], [-1.0400518717725642], [0.6031514459832744], [-0.4497749518020202], [-1.4761122991381914], [-0.7475723168322046], [-0.8698819488981732], [-0.09348167578376398], [0.9222200513727578], [-0.3806434206342989], [-0.28492283901745385], [0.5659267753545015], [0.044781386551678876], [-1.2474464652757284], [-0.4019146609935978], [0.076688247090627], [2.1612698023019177], [-0.9762381506946676], [1.3210558081096118], [1.9326039684394545], [0.32130751122256435], [0.5659267753545015], [-0.15197758677183584], [-0.4444571417121955], [-0.12007072623288761], [0.6669651670611711], [0.2681294103243171], [-0.5774023939578136], [-0.23174473811920673], [-1.1836327441978316], [0.5233842946359037], [-0.5242242930595664], [-1.385709527611171], [-0.17856663722095947], [-0.7954326076406271], [0.16709101861764744], [0.4329815231088835], [-0.029667954705867278], [-0.06157481524481563], [1.9538752087987532], [1.1827927457741692], [0.1617732085278226], [-1.1942683643774812], [-0.8911531892574721], [-0.5933558242272877], [-0.9496491002455439], [-0.8432928984490495], [-0.6305804948560608], [1.5124969713433019], [0.5393377249053778], [-0.5189064829697416], [-0.4285037114427213], [-0.19983787758025837], [-0.5986736343171124], [0.6244226863425734], [-0.30619407937675275], [-0.056257005154991026], [1.618853173139796], [0.7148254578695936], [-0.8698819488981732], [-1.0985477827606362], [-1.3378492368027486], [-0.5827202040476382], [-0.10943510605323815], [-0.8592463287185237], [-0.9443312901557194], [-0.7263010764729058], [-1.1251368332097598], [0.39043904239028565], [-0.24238035829885618], [-1.348484856982398], [2.3739822058949063], [0.762685748678016], [2.1240451316731446], [-0.0775282455142898], [-0.4976352426104428], [1.5816285025110233], [1.0232584430794271], [0.9647625320913555], [-1.0081450112336159], [-1.327213616623099], [-1.1517258836588833], [-0.4976352426104428], [-0.8911531892574721], [1.204063986133468], [1.2093817962232927], [0.6722829771509957], [-0.8911531892574721], [-0.25301597847850565], [-1.4495232486890677], [-0.226426928029382], [0.9434912917320567], [-0.300876269286928], [-0.25833378856833034], [3.1557002890991406], [-0.41255028117324716], [-0.1626132069514853], [1.618853173139796], [-0.5986736343171124], [0.08200605718045184], [0.8530885202050364], [0.3638499919411619], [-0.019032334526217828], [-1.0028272011437913], [0.37980342221063623], [-1.5505616403957376], [0.9700803421811801], [0.35853218185133734], [-0.27428721883780444], [-0.1413419665921864], [-0.779479177371153], [-0.1838844473107842], [-0.928377859886245], [0.6084692560730991], [1.2678777072113643], [-0.3965968509037731], [-0.1413419665921864], [0.06605262691097755], [-0.8326572782694003], [-0.5614489636883393], [1.3051023778401376], [2.139998561942619], [0.3957568524801103], [-0.28492283901745385], [0.5978336358934496], [-0.6837585957543079], [-0.4019146609935978], [0.9115844311931083], [1.6028997428703222], [0.5606089652646766], [0.8318172798457375], [-0.8379750883592249], [0.6191048762527486], [-0.2636515986581551], [-0.23174473811920673], [0.858406330294861], [-0.5401777233290405], [1.7677518556548883], [0.422345902929234], [-0.5880380141374629], [0.05009919664150349], [-0.25833378856833034], [-0.41255028117324716], [-0.25301597847850565], [0.8743597605643351], [1.5124969713433019], [-0.19983787758025837], [0.1405019681685237], [2.751546722272461], [0.6456939267018723], [-0.9443312901557194], [1.73584499511594], [-2.0398001686596117], [0.33726094149203845], [1.8049765262836615], [-1.805816524707324], [-0.8326572782694003], [-1.465476678958542], [-0.0030789042567437685], [-0.7103476462034315], [0.38512123230046086], [0.8052282293966138], [-0.5348599132392159], [0.03414576637202943], [-1.3218958065332744], [0.2840828405937912], [-1.2687177056350272], [-0.09879948587358871], [-0.9017888094371216], [-1.1942683643774812], [0.3744856121208114], [0.5978336358934496], [-0.6305804948560608], [1.07111873388785], [-0.9230600497964204], [-1.3431670468925734], [0.03414576637202943], [-1.2261752249164295], [-0.9656025305150181], [0.17240882870747204], [0.7095076477797689], [0.2043156892464204], [-0.029667954705867278], [1.2466064668520658], [0.23090473969554393], [-1.2314930350062543], [1.0019872027201282], [1.5497216419720747], [-0.18920225740060892], [-1.220857414826605], [0.08732386727027644], [-0.5827202040476382], [0.8105460394864387], [0.07137043700080238], [-0.08284605560411454], [1.2572420870317151], [0.342578751581863], [0.47552400382748106], [-0.10411729596341343], [-0.6518517352153596], [0.5287021047257283], [-1.0400518717725642], [0.6776007872408206], [0.4117102827495846], [1.2891489475706632], [1.789023096014187], [-0.30619407937675275], [0.9647625320913555], [-1.1464080735690587], [-0.2796050289276291], [-0.7635257471016788], [-1.1729971240181822], [-0.36468999036482475], [-2.018528928300313], [-1.4973835394974904], [0.07137043700080238], [0.5393377249053778], [-1.3963451477908206], [-0.7741613672813281], [0.0979594874499259], [-0.7954326076406271], [-0.5667667737781641], [0.2947184607734406], [0.6616473569713464], [-0.11475291614306289], [-0.13070634641253706], [0.08732386727027644], [-0.04562138497534157], [-0.5720845838679888], [0.32130751122256435], [-0.23174473811920673], [-0.056257005154991026], [-0.625262684766236], [-0.12538853632271232], [-1.5877863110245105], [-0.1466597766820111], [1.2891489475706632], [-1.7366849935396027], [0.3638499919411619], [0.6829185973306452], [0.7573679385881914], [0.27876503050396656], [1.852836817092084], [0.342578751581863], [0.12986634798887425], [0.6456939267018723], [-0.0030789042567437685], [0.5021130542766048], [0.19368006906677096], [2.1134095114934954], [-0.3487365600953506], [0.1351841580786991], [-0.17324882713113474], [-0.6731229755746585], [-1.0294162515929148], [-0.4019146609935978], [0.2947184607734406], [-0.4604105719816697], [0.3053540809530901], [-0.9762381506946676], [-0.29555845919710333], [0.5127486744562543], [-0.16793101704131003], [-1.6462822220125823], [-1.1091834029402856], [0.002238905833081075], [1.3423270484689107], [0.4329815231088835], [-1.066640922221688], [-0.8379750883592249], [-0.5614489636883393], [-0.04562138497534157], [-1.0772765424013373], [0.4914774340969553], [1.0604831137082005], [-0.029667954705867278], [-0.30619407937675275], [1.2625598971215397], [-0.4019146609935978], [1.9804642592478774], [0.1405019681685237], [-1.2953067560841507], [-0.4869996224307933], [-0.28492283901745385], [-1.0613231121318631], [-0.9443312901557194], [-0.8379750883592249], [0.28940065068361603], [-0.17856663722095947], [0.6084692560730991], [0.19368006906677096], [-0.6997120260237822], [-0.5986736343171124], [-0.27428721883780444], [0.32662532131238897], [1.751798425385414], [0.895631000923634], [0.1617732085278226], [-1.1623615038385327], [-0.3806434206342989], [1.145568075145396], [-2.1886988511747036], [3.6768456779019636], [0.32130751122256435], [-0.029667954705867278], [0.2043156892464204], [-0.6412161150357101], [-0.4976352426104428], [-0.25833378856833034], [-0.6412161150357101], [0.023510146192379976], [0.33726094149203845], [0.33726094149203845], [0.12454853789904964], [0.3532143717615125], [0.7786391789474902], [3.123793428560192], [0.24154035987519337], [0.03414576637202943], [-0.8486107085388743], [-0.5189064829697416], [-0.8911531892574721], [-0.3700078004546495], [-0.7582079370118541], [1.8049765262836615], [0.7786391789474902], [-0.7954326076406271], [1.1615215054148702], [-1.975986447581715], [-0.5508133435086899], [-1.327213616623099], [-0.10411729596341343], [0.8105460394864387], [0.6403761166120474], [1.9272861583496297], [0.5127486744562543], [-0.7847969874609776], [-1.3059423762638003], [2.69305081128439], [0.3319431314022136], [0.09264167736010129], [0.7414145083187171], [1.7837052859243625], [0.8264994697559127], [-1.0134628213234407], [0.2521759800548428], [-0.9390134800658945], [1.906014917990331], [-1.066640922221688], [-1.0506874919522138], [-0.7688435571915035], [-0.8220216580897508], [0.9222200513727578], [0.3053540809530901], [-0.8113860379101013], [3.272692111075284], [-0.6305804948560608], [-0.5454955334188651], [-0.32746531973605164], [-0.10943510605323815], [0.2840828405937912], [1.4327298199959309], [1.2146996063131172], [-1.4335698184195935], [-0.12538853632271232], [0.6456939267018723], [0.7095076477797689], [-1.5452438303059128], [-0.29555845919710333], [0.5021130542766048], [1.4593188704450544], [-0.32214750964622696], [3.480086704578448], [0.6297404964323979], [0.10327729753975073], [0.3638499919411619], [0.858406330294861], [1.8422011969124341], [0.6031514459832744], [-0.24238035829885618], [0.34789656167168787], [0.028827956282204584], [0.24685816996501822], [0.38512123230046086], [0.3532143717615125], [-0.1626132069514853], [0.9913515825404791], [-0.2476981683886809], [0.08732386727027644], [0.8105460394864387], [-0.6518517352153596], [0.2947184607734406], [-0.1360241565023618], [1.012622822899778], [-1.1623615038385327], [-1.2846711359045015], [0.209633499336245], [-0.4391393316223708], [-0.2689694087479798], [0.23622254978536875], [0.5606089652646766], [0.6297404964323979], [1.0817543540674992], [-2.683255189528403], [-0.5082708627900923], [0.592515825803625], [-1.0134628213234407], [-1.1091834029402856], [0.9434912917320567], [1.1615215054148702], [-0.06157481524481563], [0.44893495337835754], [0.3159897011327395], [-0.27428721883780444], [-0.07221043542446508], [0.039463576461854034], [-0.9017888094371216], [0.0979594874499259], [0.7999104193067892], [0.9115844311931083], [-1.6462822220125823], [0.6669651670611711], [-0.9815559607844923], [-2.2152879016238276], [0.858406330294861], [0.5021130542766048], [0.27876503050396656], [0.7414145083187171], [0.002238905833081075], [-0.6518517352153596], [0.4648883836478316], [-1.0825943524911619], [0.3744856121208114], [0.25749379014466767], [-0.8911531892574721], [-0.4019146609935978], [1.3742339090078588], [-0.0030789042567437685], [2.8898097846079045], [-0.2796050289276291], [-0.019032334526217828], [-0.19452006749043366], [-0.0775282455142898], [1.8741080574513829], [-0.4285037114427213], [-1.7366849935396027], [0.7945926092169643], [1.4699544906247042], [-1.7739096641683758], [-0.5029530527002675], [-0.779479177371153], [0.4648883836478316], [-0.625262684766236], [-0.5082708627900923], [1.618853173139796], [-1.0879121625809869], [-0.47104619216131915], [-0.9656025305150181], [-2.151474180545931], [1.4699544906247042], [0.8318172798457375], [0.9594447220015307], [0.002238905833081075], [-1.4229341982399442], [0.5180664845460788], [-0.06157481524481563], [-0.23706254820903144], [-1.2421286551859037], [0.459570573558007], [-0.4019146609935978], [0.18836225897694633], [1.5709928823313735], [-0.4816818123409686], [-0.056257005154991026], [0.5287021047257283], [2.060231410595248], [-0.300876269286928], [-1.8483590054259218], [2.9057632148773784], [0.1405019681685237], [-0.6837585957543079], [0.023510146192379976], [-0.7741613672813281], [-0.9443312901557194], [-0.7316188865627304], [0.422345902929234], [-0.5242242930595664], [-0.10411729596341343], [0.6456939267018723], [0.076688247090627], [-0.5082708627900923], [-0.09348167578376398], [-0.6039914444069372], [-0.16793101704131003], [0.592515825803625], [1.624170983229621], [0.044781386551678876], [-0.5508133435086899], [-0.5348599132392159], [0.3638499919411619], [-1.975986447581715], [0.6829185973306452], [-0.3912790408139484], [-2.1355207502764566], [-0.8964709993472968], [-0.7050298361136068], [-0.4072324710834224], [1.3635982888282097], [-0.6997120260237822], [-0.928377859886245], [-0.21579130784973255], [-1.1623615038385327], [0.24154035987519337], [-1.9706686374918905], [-0.4019146609935978], [-0.9762381506946676], [1.0551653036183757], [-1.0719587323115125], [-1.5080191596771397], [-0.6146270645865866], [-1.4282520083297687], [0.21495130942606985], [0.43829933319870806], [-0.359372180275], [-0.6784407856644833], [1.4433654401755802], [-1.0506874919522138], [-0.2104734977599078], [0.07137043700080238], [0.6031514459832744], [0.9860337724506545], [0.11923072780922479], [0.28940065068361603], [-0.03498576479569212], [0.4648883836478316], [-0.8858353791676473], [0.19899787915659556], [0.422345902929234], [-0.9762381506946676], [0.08200605718045184], [-0.875199758987998], [0.24685816996501822], [-0.6784407856644833], [-0.49231743252061805], [-1.1623615038385327], [1.3476448585587353], [-0.019032334526217828], [-0.5508133435086899], [1.2519242769418906], [-1.4016629578806452], [1.2625598971215397], [1.2838311374808387], [-0.2211091179395573], [-0.02435014461604267], [0.12454853789904964], [-1.4867479193178408], [0.19368006906677096], [0.7573679385881914], [-0.9071066195269463], [0.4542527634681824], [-0.986873770874317], [0.002238905833081075], [0.5446555349952026], [1.012622822899778], [-0.08284605560411454], [0.5180664845460788], [-0.9762381506946676], [0.5021130542766048], [-0.1360241565023618], [1.9538752087987532], [-0.4178680912630719], [-0.2902406491072786], [-0.8645641388083485], [0.2734472204141417], [0.9381734816422318], [-0.12538853632271232], [2.1612698023019177], [0.19368006906677096], [0.9328556715524072], [0.592515825803625], [-0.4391393316223708], [-1.0932299726708115], [-0.013714524436393219], [-1.0825943524911619], [-0.6039914444069372], [1.092389974247149], [-0.24238035829885618], [1.9804642592478774], [0.27876503050396656], [-1.0825943524911619], [0.3106718910429149], [0.12986634798887425], [1.5178147814331264], [-0.013714524436393219], [1.1881105558639937], [2.437795926972803], [0.28940065068361603], [-0.9602847204251934], [-1.2580820854553778], [0.25749379014466767], [-0.7422545067423799], [0.27876503050396656], [3.3045989716142325], [0.5659267753545015], [-0.9709203406048429], [0.8264994697559127], [0.5233842946359037], [0.05009919664150349], [-0.7369366966525551], [-0.6837585957543079], [0.4808418139173059], [0.8052282293966138], [-0.6571695453051845], [0.7520501284983665], [1.5284504016127758], [-1.6622356522820567], [0.5287021047257283], [0.6669651670611711], [-0.7635257471016788], [0.5393377249053778], [-0.1360241565023618], [-1.8270877650666228], [0.9328556715524072], [2.8153604433503583], [-0.18920225740060892], [0.8318172798457375], [-1.0560053020420384], [0.36916780203098676], [0.5712445854443261], [0.8052282293966138], [-0.1838844473107842], [1.2625598971215397], [-0.45509276189184494], [0.3159897011327395], [-0.9975093910539665], [-0.6146270645865866], [-0.10411729596341343], [-1.3218958065332744], [-0.5295421031493911], [-0.013714524436393219], [-0.08284605560411454], [0.42766371301905864], [-0.2636515986581551], [-1.5505616403957376], [0.6403761166120474], [0.5287021047257283], [-1.0081450112336159], [-0.3381009399157011], [1.1508858852352206], [-0.19452006749043366], [1.5763106924211983], [-0.3806434206342989], [-0.5029530527002675], [-0.10411729596341343], [0.9434912917320567], [0.10327729753975073], [0.5127486744562543], [-0.1626132069514853], [0.9381734816422318], [-0.32746531973605164], [-0.41255028117324716], [-0.359372180275], [-1.78986309443785], [0.30003627086326545], [-0.6997120260237822], [0.21495130942606985], [1.012622822899778], [0.5287021047257283], [-1.1357724533894091], [0.5978336358934496], [0.32130751122256435], [-1.3910273377009958], [-0.23174473811920673], [-1.0506874919522138], [-0.5189064829697416], [-0.9336956699760699], [-0.029667954705867278], [0.5287021047257283], [-0.7050298361136068], [0.2043156892464204], [0.5287021047257283], [0.7201432679594184], [0.1139129177194002], [-0.4816818123409686], [-0.1466597766820111], [-0.1360241565023618], [-1.0294162515929148], [-0.3700078004546495], [-2.757704530785949], [0.8530885202050364], [-1.385709527611171], [-0.05093919506516618], [0.7573679385881914], [1.2200174164029418], [-0.12538853632271232], [-0.02435014461604267], [-0.07221043542446508], [-1.1676793139283577], [-0.23174473811920673], [2.1665876123917425], [0.8211816596660881], [-0.6837585957543079], [-1.1676793139283577], [-1.6037397412939847], [-1.066640922221688], [-0.6146270645865866], [0.08732386727027644], [0.8637241403846857], [1.012622822899778], [-0.9975093910539665], [0.25749379014466767], [0.6191048762527486], [1.1721571255945196], [0.05541700673132833], [2.001735499607176], [-0.779479177371153], [-0.0775282455142898], [0.22026911951589445], [-0.5774023939578136], [-0.7316188865627304], [3.416272983500552], [0.6350583065222228], [-0.06157481524481563], [-0.8220216580897508], [0.40639247265975975], [0.4329815231088835], [-2.8215182518638455], [-0.13070634641253706], [-0.779479177371153], [-0.8379750883592249], [0.25749379014466767], [-0.15197758677183584], [0.1405019681685237], [0.9594447220015307], [1.3263736181994363], [0.3638499919411619], [0.4861596240071305], [-0.4604105719816697], [-0.853928518628699], [1.9272861583496297], [-0.32214750964622696], [-0.34341875000552585], [0.9807159623608296], [2.740911102092812], [1.3901873392773332], [-0.5029530527002675], [1.1030255944267982], [2.060231410595248], [1.0977077843369736], [-0.15197758677183584], [-1.7260493733599533], [0.24685816996501822], [0.15113758834817315], [-0.008396714346568376], [1.4699544906247042], [-0.3700078004546495], [0.895631000923634], [0.6616473569713464], [-0.359372180275], [-0.5986736343171124], [-0.6412161150357101], [0.5393377249053778], [1.0817543540674992], [0.7999104193067892], [-0.2689694087479798], [-0.019032334526217828], [0.422345902929234], [-0.07221043542446508], [-1.465476678958542], [0.5446555349952026], [0.5552911551748521], [-0.7528901269220294], [-0.3487365600953506], [-1.2633998955452026], [-0.5401777233290405], [0.10327729753975073], [-0.8592463287185237], [-0.09348167578376398], [-1.2793533258146768], [-0.36468999036482475], [1.065800923798025], [1.0817543540674992], [0.5021130542766048], [0.725461078049243], [-1.2740355157248517], [-1.3059423762638003], [1.2572420870317151], [0.9594447220015307], [-0.646533925125535], [-2.061071409018911], [2.6451905204759676], [1.0073050128099534], [1.4965435410738277], [-0.47636400225114384], [1.6879847043075173], [0.9009488110134588], [0.6829185973306452], [3.804473120057756], [-1.3538026670722227], [0.14581977825834855], [-0.30619407937675275], [0.6084692560730991], [0.87967757065416], [-1.2953067560841507], [-0.04030357488551673], [0.6563295468815217], [2.3686643958050815], [0.5659267753545015], [-0.04562138497534157], [-0.5348599132392159], [0.7680035587678409], [0.6403761166120474], [2.3686643958050815], [0.8052282293966138], [-1.843041195336097], [0.5287021047257283], [-1.385709527611171], [0.42766371301905864], [0.19899787915659556], [-0.35405437018517527], [-1.5665150706652116], [-0.7528901269220294], [-0.8432928984490495], [0.14581977825834855], [-0.7050298361136068], [1.2891489475706632], [-1.0506874919522138], [-0.17324882713113474], [0.9434912917320567], [0.5606089652646766], [-2.0078933081206634], [-0.8167038479999259], [0.012874526012730526], [0.3159897011327395], [1.7624340455650636], [-0.5454955334188651], [-0.013714524436393219], [0.17240882870747204], [0.076688247090627], [2.650508330565792], [-0.5774023939578136], [-1.1676793139283577], [0.076688247090627], [-0.8113860379101013], [-1.2899889459943261], [0.07137043700080238], [-0.23706254820903144], [-0.3753256105444742], [-0.8273394681795754], [2.342075345355958], [0.19899787915659556], [0.5978336358934496], [0.1405019681685237], [-1.465476678958542], [0.012874526012730526], [0.7360966982288925], [-1.3910273377009958], [0.7520501284983665], [0.10327729753975073], [1.3210558081096118], [0.039463576461854034], [1.2200174164029418], [0.3532143717615125], [1.0551653036183757], [-0.7103476462034315], [0.3532143717615125], [0.7680035587678409], [0.38512123230046086], [1.2519242769418906], [-0.5348599132392159], [0.21495130942606985], [1.3210558081096118], [-0.6358983049458855], [-1.2953067560841507], [0.32130751122256435], [1.1562036953250452], [0.6669651670611711], [1.624170983229621], [0.012874526012730526], [0.1830444488871215], [-0.3115118894665775], [-0.2211091179395573], [-1.3218958065332744], [-0.12538853632271232], [0.4648883836478316], [-1.7207315632701286], [-0.8167038479999259], [-0.42318590135289663], [2.8419494937994823], [0.5659267753545015], [0.8477707101152115], [-0.23174473811920673], [-0.19983787758025837], [0.9700803421811801], [-0.5933558242272877], [-0.36468999036482475], [0.5340199148155531], [1.7411628052057648], [1.5231325915229512], [0.5340199148155531], [-0.6305804948560608], [-1.2474464652757284], [0.6456939267018723], [0.9275378614625823], [-0.4604105719816697], [1.145568075145396], [-1.8270877650666228], [-1.8377233852462724], [-1.066640922221688], [-0.17324882713113474], [-1.6941425128210048], [-0.6199448746764114], [-0.9390134800658945], [0.9169022412829329], [-0.5774023939578136], [1.1668393155046948], [-1.2580820854553778], [2.5016096480506995], [0.6191048762527486], [1.751798425385414], [-0.34341875000552585], [-2.651348328989455], [0.4010746625699351], [1.757116235475239], [0.3532143717615125], [0.5818802056239756], [1.0392118733489015], [-1.5877863110245105], [-0.4444571417121955], [0.7520501284983665], [-0.45509276189184494], [-0.8167038479999259], [-0.9443312901557194], [1.709255944666816], [0.7095076477797689], [-0.3700078004546495], [0.3744856121208114], [-0.19983787758025837], [-0.18920225740060892], [-0.5614489636883393], [1.5178147814331264], [-0.8113860379101013], [0.8743597605643351], [-1.5080191596771397], [0.5499733450850272], [1.3423270484689107], [-0.8060682278202764], [-0.5348599132392159], [-0.6039914444069372], [0.41702809283940917], [0.7733213688576654], [-1.9281261567732928], [-0.5774023939578136], [0.28940065068361603], [0.8477707101152115], [0.32130751122256435], [0.3053540809530901], [-1.2527642753655532], [-0.12538853632271232], [0.0979594874499259], [-1.444205438599243], [0.1351841580786991], [-0.986873770874317], [-0.4178680912630719], [-1.78986309443785], [-1.3591204771620475], [0.8743597605643351], [0.32130751122256435], [-2.1195673200069827], [0.32662532131238897], [1.5337682117026004], [-0.7901147975508024], [-0.056257005154991026], [1.2200174164029418], [-0.4604105719816697], [-1.2261752249164295], [-0.03498576479569212], [-0.4657283820714944], [0.32130751122256435], [-1.7366849935396027], [-0.662487355395009], [0.8371350899355622], [1.9326039684394545], [1.411458579636632], [1.4805901108043533], [-0.5082708627900923], [0.7733213688576654], [1.73584499511594], [1.145568075145396], [-0.4072324710834224], [-0.7475723168322046], [3.8204265503272308], [-1.4867479193178408], [0.12986634798887425], [0.7945926092169643], [-0.0775282455142898], [-0.9177422397065957], [-0.1838844473107842], [0.23090473969554393], [-0.6943942159339573], [0.7892747991271397], [-0.7103476462034315], [-0.8911531892574721], [1.6082175529601468], [-0.08284605560411454], [0.35853218185133734], [1.2944667576604882], [-0.6518517352153596], [0.018192336102555134], [-0.2796050289276291], [0.002238905833081075], [0.7680035587678409], [-0.19452006749043366], [-0.6997120260237822], [-0.6571695453051845], [1.0551653036183757], [-0.6571695453051845], [-0.03498576479569212], [-0.8220216580897508], [0.06605262691097755], [-0.2051556876700831], [1.1402502650555715], [1.0604831137082005], [-0.7847969874609776], [-0.5720845838679888], [2.3739822058949063], [-0.7369366966525551], [1.358280478738385], [-1.6941425128210048], [-0.3912790408139484], [0.2681294103243171], [-0.08284605560411454], [-0.5189064829697416], [0.10859510762957535], [0.7360966982288925], [-0.5561311535985146], [0.43829933319870806], [-0.06689262533464048], [-0.47104619216131915], [-2.4067290648575175], [-0.6146270645865866], [1.331691428289261], [1.1881105558639937], [0.6191048762527486], [0.24685816996501822], [3.3843661229616036], [-0.1838844473107842], [0.12454853789904964], [3.1450646689194914], [-0.34341875000552585], [0.08732386727027644], [0.27876503050396656], [1.1934283659538183], [0.35853218185133734], [-1.4122985780602948], [0.9966693926303036], [0.7680035587678409], [-0.17324882713113474], [-1.1145012130301104], [-0.03498576479569212], [-0.8645641388083485], [-0.6837585957543079], [0.3319431314022136], [-0.7422545067423799], [0.076688247090627], [-0.04562138497534157], [0.076688247090627], [0.06605262691097755], [-0.9071066195269463], [0.17240882870747204], [0.22026911951589445], [-2.5237208868336616], [-0.08816386569393926], [3.214196200087212], [-0.7901147975508024], [1.6560778437685693], [0.32662532131238897], [-0.32746531973605164], [-0.5029530527002675], [-1.885583676054695], [0.5127486744562543], [1.2572420870317151], [-1.1145012130301104], [-0.12007072623288761], [-1.2846711359045015], [-0.7316188865627304], [1.1881105558639937], [1.0551653036183757], [1.3423270484689107], [-1.5877863110245105], [-1.066640922221688], [-0.5986736343171124], [-0.8060682278202764], [1.1881105558639937], [1.9219683482598051], [0.32662532131238897], [-0.6678051654848338], [0.6882364074204701], [2.129362941762969], [0.41702809283940917], [-0.9230600497964204], [-0.5774023939578136], [0.08732386727027644], [-0.3912790408139484], [-2.7470689106062998], [-0.6039914444069372], [-0.06689262533464048], [1.033894063259077], [-0.16793101704131003], [0.3744856121208114], [0.1777266387972969], [0.5659267753545015], [-0.23174473811920673], [1.6560778437685693], [0.08732386727027644], [1.3051023778401376], [0.37980342221063623], [-0.19983787758025837], [1.3901873392773332], [-0.9443312901557194], [-0.8486107085388743], [0.023510146192379976], [-0.8432928984490495], [-0.019032334526217828], [-0.8858353791676473], [-0.3700078004546495], [-0.8167038479999259], [-1.3644382872518723], [-1.5399260202160878], [-0.4497749518020202], [-0.47636400225114384], [-0.23174473811920673], [-0.07221043542446508], [-0.7050298361136068], [0.2840828405937912], [-0.7847969874609776], [-0.2796050289276291], [-2.0929782695578587], [-0.3753256105444742], [-2.1036138897375087], [-0.12538853632271232], [-0.04562138497534157], [0.6403761166120474], [0.23622254978536875], [0.060734816821152934], [-0.4976352426104428], [-0.02435014461604267], [1.5869463126008478], [0.05009919664150349], [0.28940065068361603], [0.8690419504745105], [-0.16793101704131003], [-0.24238035829885618], [1.0232584430794271], [-0.6678051654848338], [0.24685816996501822], [0.5978336358934496], [0.6456939267018723], [-1.4867479193178408], [0.9115844311931083], [1.9485573987089286], [-0.6943942159339573], [0.3638499919411619], [-1.6462822220125823], [0.3106718910429149], [1.1296146448759217], [-0.17324882713113474], [-1.9281261567732928], [-0.019032334526217828], [0.19368006906677096], [-0.04030357488551673], [0.3159897011327395], [0.6297404964323979], [-0.04562138497534157], [0.32662532131238897], [-2.4864962162048885], [-0.2689694087479798], [-0.9602847204251934], [-1.4335698184195935], [0.19899787915659556], [-0.29555845919710333], [-0.38596123072412364], [1.5124969713433019], [-0.9017888094371216], [-0.8379750883592249], [2.3154862949068344], [0.12454853789904964], [-0.8167038479999259], [0.1139129177194002], [-0.8805175690778226], [-0.3753256105444742], [-1.6835068926413557], [0.05009919664150349], [-0.5827202040476382], [0.1351841580786991], [0.07137043700080238], [-0.5135886728799169], [-0.47104619216131915], [-0.4657283820714944], [1.9698286390682276], [-0.5029530527002675], [0.5818802056239756], [1.3104201879299622], [0.47552400382748106], [-0.5135886728799169], [0.6616473569713464], [-0.6093092544967619], [1.1508858852352206], [-0.625262684766236], [0.07137043700080238], [1.5018613511636523], [0.2840828405937912], [1.113661214606448], [0.35853218185133734], [0.87967757065416], [-2.2152879016238276], [-0.7528901269220294], [-1.8004987146174993], [-0.23174473811920673], [0.10859510762957535], [0.9594447220015307], [0.25749379014466767], [2.049595790415599], [-0.300876269286928], [0.9700803421811801], [-0.3487365600953506], [1.1296146448759217], [-0.7582079370118541], [-1.4335698184195935], [-0.7103476462034315], [1.884743677631032], [-0.646533925125535], [0.03414576637202943], [1.204063986133468], [1.6720312740380434], [0.3053540809530901], [-1.0772765424013373], [-0.9071066195269463], [-0.6199448746764114], [-1.311260186353625], [-0.28492283901745385], [1.757116235475239], [-0.6358983049458855], [0.05541700673132833], [1.8953792978106816], [0.8849953807439845], [-0.5561311535985146], [0.12454853789904964], [2.171905422481567], [1.1402502650555715], [0.7520501284983665], [0.03414576637202943], [0.3106718910429149], [0.28940065068361603], [-0.5986736343171124], [-0.5295421031493911], [-0.9549669103353686], [0.5340199148155531], [-1.385709527611171], [0.05009919664150349], [-1.4761122991381914], [0.7201432679594184], [-2.0929782695578587], [1.6613956538583938], [0.5340199148155531], [0.5127486744562543], [-0.6305804948560608], [2.6664617608352663], [0.725461078049243], [-0.19452006749043366], [0.6669651670611711], [-0.11475291614306289], [-0.2051556876700831], [0.6137870661629239], [0.21495130942606985], [-0.09879948587358871], [-2.459907165755765], [2.304850674727185], [-2.3056906731508477], [1.1562036953250452], [0.2255869296057193], [-0.5933558242272877], [0.17240882870747204], [-0.2211091179395573], [-1.8696302457852205], [-1.9121727265038184], [-1.1942683643774812], [0.9594447220015307], [-0.10943510605323815], [-0.4657283820714944], [0.27876503050396656], [-0.9656025305150181], [0.156455398437998], [-0.2689694087479798], [-0.9656025305150181], [-0.35405437018517527], [-1.2953067560841507], [-0.4976352426104428], [-1.0719587323115125], [-0.9815559607844923], [-0.6784407856644833], [-0.09348167578376398], [-0.6305804948560608], [-0.9656025305150181], [-2.1248851300968075], [1.8262477666429604], [-0.0775282455142898], [0.3532143717615125], [0.018192336102555134], [-0.6518517352153596], [0.9647625320913555], [0.9860337724506545], [-0.04562138497534157], [0.37980342221063623], [-0.7901147975508024], [0.12986634798887425], [0.6563295468815217], [-0.19983787758025837], [-1.6409644119227578], [0.19899787915659556], [-0.6412161150357101], [0.2628116002344923], [1.773069665744713], [0.6882364074204701], [-1.2474464652757284], [-0.47636400225114384], [0.2043156892464204], [-1.1198190231199352], [-1.21553960473678], [-0.5029530527002675], [-1.4069807679704698], [-1.157043693748708], [0.6829185973306452], [0.19899787915659556], [1.2519242769418906], [-1.2580820854553778], [3.150382479009316], [-0.41255028117324716], [0.28940065068361603], [-0.41255028117324716], [-0.7954326076406271], [-0.6731229755746585], [-0.0030789042567437685], [-0.12538853632271232], [-0.45509276189184494], [1.124296834786097], [-1.1676793139283577], [0.1351841580786991], [-1.4069807679704698], [-2.1302029401866323], [1.4327298199959309], [-0.17324882713113474], [1.3795517190976838], [0.2043156892464204], [0.24154035987519337], [0.7786391789474902], [-0.08284605560411454], [0.5499733450850272], [3.240785250536336], [1.4593188704450544], [-2.502449646474362], [0.08732386727027644], [0.4808418139173059], [-0.300876269286928], [0.023510146192379976], [-0.7688435571915035], [0.5552911551748521], [-0.029667954705867278], [0.2628116002344923], [-0.5082708627900923], [0.5659267753545015], [0.35853218185133734], [-0.47636400225114384], [1.124296834786097], [0.044781386551678876], [1.485907920894178], [-0.8805175690778226], [0.14581977825834855], [1.2572420870317151], [-0.4444571417121955], [-0.38596123072412364], [-0.42318590135289663], [0.08200605718045184], [-0.9017888094371216], [2.650508330565792], [-1.6941425128210048], [0.08732386727027644], [0.38512123230046086], [0.44893495337835754], [-0.8379750883592249], [-0.4604105719816697], [-0.04030357488551673], [0.8903131908338094], [2.958941315775626], [0.7786391789474902], [-0.23174473811920673], [2.570741179218421], [-0.662487355395009], [-1.3538026670722227], [0.32130751122256435], [0.6456939267018723], [-0.5933558242272877], [2.272943814188237], [-1.348484856982398], [-0.49231743252061805], [-0.4391393316223708], [0.6776007872408206], [0.40639247265975975], [0.5871980157138004], [2.5920124195777197], [0.6137870661629239], [2.2942150545475357], [-1.460158868868717], [-0.6199448746764114], [1.5816285025110233], [-0.3487365600953506], [-0.662487355395009], [-0.17324882713113474], [-0.9762381506946676], [0.4861596240071305], [-0.36468999036482475], [1.6826668942176926], [-0.8273394681795754], [0.6350583065222228], [-0.7369366966525551], [-0.7635257471016788], [-1.02409844150309], [0.4542527634681824], [-0.9975093910539665], [0.3159897011327395], [-0.3912790408139484], [0.25749379014466767], [-0.9549669103353686], [1.0977077843369736], [1.2306530365825916], [0.1777266387972969], [2.193176662840866], [-0.7422545067423799], [0.6297404964323979], [-0.5880380141374629], [0.05541700673132833], [0.32662532131238897], [-0.17856663722095947], [-0.7316188865627304], [-0.4816818123409686], [-0.986873770874317], [-0.5561311535985146], [0.24685816996501822], [-0.2051556876700831], [0.14581977825834855], [0.2255869296057193], [-0.6146270645865866], [0.49679524418677995], [-1.6409644119227578], [2.054913600505423], [2.538834318679473], [-0.6358983049458855], [-0.5880380141374629], [0.028827956282204584], [1.3795517190976838], [2.193176662840866], [-0.300876269286928], [-0.10411729596341343], [1.1827927457741692], [-0.5774023939578136], [0.7945926092169643], [0.5818802056239756], [2.5335165085896483], [-0.6039914444069372], [0.3638499919411619], [0.7786391789474902], [1.4486832502654052], [-1.1623615038385327], [2.0283245500562996], [0.5021130542766048], [-0.25301597847850565], [-0.4497749518020202], [0.4648883836478316], [0.9647625320913555], [-0.9230600497964204], [-0.2051556876700831], [1.5124969713433019], [1.07111873388785], [-0.18920225740060892], [-0.13070634641253706], [-0.04030357488551673], [-0.21579130784973255], [0.8105460394864387], [-0.2902406491072786], [1.3104201879299622], [-0.17856663722095947], [2.262308194008587], [-0.42318590135289663], [-0.4976352426104428], [0.24154035987519337], [-0.9336956699760699], [-0.23174473811920673], [0.6191048762527486], [0.25749379014466767], [0.14581977825834855], [-0.08284605560411454], [-1.2846711359045015], [0.2521759800548428], [-0.6731229755746585], [-1.8483590054259218], [-1.0134628213234407], [-1.1517258836588833], [-0.02435014461604267], [-0.10943510605323815], [0.7201432679594184], [-0.2796050289276291], [-0.10411729596341343], [0.8211816596660881], [0.9860337724506545], [0.3638499919411619], [-0.17856663722095947], [1.985782069337702], [0.47552400382748106], [0.459570573558007], [-0.8379750883592249], [-0.6039914444069372], [0.975398152271005], [-1.348484856982398], [1.0179406329896026], [-1.614375361473634], [-0.5986736343171124], [0.3106718910429149], [-1.1038655928504608], [0.5818802056239756], [0.9222200513727578], [-1.5824685009346857], [-0.646533925125535], [-0.28492283901745385], [-0.8379750883592249], [-0.3912790408139484], [0.6563295468815217], [-0.04562138497534157], [-0.7688435571915035], [-0.8060682278202764], [-1.0560053020420384], [-0.4019146609935978], [0.1351841580786991], [-0.17324882713113474], [-0.1466597766820111], [-0.8379750883592249], [1.0392118733489015], [1.5337682117026004], [-1.0560053020420384], [1.3210558081096118], [-0.5401777233290405], [-0.10411729596341343], [0.24685816996501822], [-0.4072324710834224], [0.7520501284983665], [0.7467323184085419], [-0.5561311535985146], [-1.1091834029402856], [0.9488091018218813], [-1.066640922221688], [0.6935542175102947], [1.331691428289261], [0.44893495337835754], [-1.2421286551859037], [0.5127486744562543], [-1.0879121625809869], [-1.3750739074315217], [1.278513327391014], [0.8690419504745105], [-0.1838844473107842], [0.002238905833081075], [0.858406330294861], [-0.1413419665921864], [-1.784545284348025], [0.6031514459832744], [1.4433654401755802], [-0.1838844473107842], [0.8903131908338094], [-1.1623615038385327], [-0.8592463287185237], [-1.21553960473678], [0.076688247090627], [2.288897244457711], [1.9166505381699805], [-0.8805175690778226], [-0.779479177371153], [-1.5133369697669643], [-0.6837585957543079], [0.6722829771509957], [1.198746176043643], [0.2043156892464204], [-1.1357724533894091], [0.156455398437998], [0.7839569890373149], [2.1134095114934954], [0.19368006906677096], [-2.784293581235073], [0.6563295468815217], [-1.2261752249164295], [0.11923072780922479], [-1.3538026670722227], [-1.1357724533894091], [2.326121915086484], [-0.056257005154991026], [-1.045369681862389], [1.9538752087987532], [-0.779479177371153], [1.2519242769418906], [-1.1251368332097598], [-1.0932299726708115], [1.6028997428703222], [-0.23706254820903144], [0.8371350899355622], [-0.21579130784973255], [-0.6039914444069372], [-0.9975093910539665], [1.3848695291875086], [0.7945926092169643], [1.4008229594569823], [0.40639247265975975], [-0.8167038479999259], [0.7467323184085419], [-0.4072324710834224], [0.9488091018218813], [1.0073050128099534], [2.416524686613504], [0.6882364074204701], [-1.4867479193178408], [-0.5561311535985146], [1.1934283659538183], [-1.0985477827606362], [-1.6994603229108296], [0.5287021047257283], [-0.4869996224307933], [-1.1517258836588833], [1.1562036953250452], [-0.32746531973605164], [-0.2689694087479798], [-0.8326572782694003], [0.24154035987519337], [1.3423270484689107], [1.5816285025110233], [-0.5135886728799169], [-0.4657283820714944], [-0.928377859886245], [-0.359372180275], [0.08732386727027644], [-0.5774023939578136], [-0.23174473811920673], [0.24685816996501822], [1.4486832502654052], [-0.23706254820903144], [-0.6678051654848338], [0.858406330294861], [-0.5189064829697416], [1.3263736181994363], [-0.8273394681795754], [0.592515825803625], [-0.8273394681795754], [0.1139129177194002], [-0.5880380141374629], [-0.3753256105444742], [-0.9975093910539665], [-0.8379750883592249], [-0.6571695453051845], [1.065800923798025], [-1.0985477827606362], [0.19368006906677096], [-0.625262684766236], [-1.0560053020420384], [0.37980342221063623], [0.6616473569713464], [0.33726094149203845], [-0.43382152153254605], [0.7467323184085419], [-0.1466597766820111], [-0.056257005154991026], [0.9913515825404791], [-0.42318590135289663], [-0.3381009399157011], [-0.3168296995564022], [0.342578751581863], [-1.896219296234344], [-0.2636515986581551], [-0.1360241565023618], [-1.0719587323115125], [0.3532143717615125], [0.2840828405937912], [0.3159897011327395], [0.1405019681685237], [0.37980342221063623], [-0.23706254820903144], [-0.12007072623288761], [1.4965435410738277], [-0.6731229755746585], [0.5499733450850272], [0.8052282293966138], [0.15113758834817315], [0.6563295468815217], [-0.0775282455142898], [0.03414576637202943], [0.4117102827495846], [-1.02409844150309], [1.6933025143973424], [-0.4072324710834224], [-0.3806434206342989], [0.7786391789474902], [-0.8486107085388743], [-0.2476981683886809], [1.2412886567622408], [0.3532143717615125], [-0.21579130784973255], [0.0979594874499259], [1.852836817092084], [-0.42318590135289663], [-0.8698819488981732], [-2.4864962162048885], [0.38512123230046086], [1.6135353630499714], [-0.226426928029382], [0.6563295468815217], [1.7624340455650636], [-1.369756097341697], [1.7464806152955894], [-0.029667954705867278], [-1.4761122991381914], [-1.2953067560841507], [0.34789656167168787], [0.7892747991271397], [0.4914774340969553], [0.3159897011327395], [0.43829933319870806], [0.40639247265975975], [1.7145737547566413], [-1.6250109816532834], [0.1405019681685237], [0.30003627086326545], [-1.157043693748708], [-0.2796050289276291], [1.9485573987089286], [-0.6678051654848338], [0.05541700673132833], [1.1402502650555715], [0.842452900025387], [-0.27428721883780444], [2.187858852751041], [-0.07221043542446508], [-0.1838844473107842], [-1.5665150706652116], [-0.9071066195269463], [-0.2902406491072786], [-1.2314930350062543], [-1.3218958065332744], [-0.25833378856833034], [-0.4869996224307933], [0.3106718910429149], [0.9594447220015307], [-0.6571695453051845], [-0.27428721883780444], [-0.5667667737781641], [0.7733213688576654], [0.9222200513727578], [-0.2476981683886809], [-0.24238035829885618], [-1.0560053020420384], [-0.6093092544967619], [-2.1036138897375087], [1.789023096014187], [-0.10411729596341343], [-1.1729971240181822], [0.342578751581863], [-1.0347340616827396], [0.1405019681685237], [0.422345902929234], [-1.3591204771620475], [-0.6943942159339573], [0.422345902929234], [1.2997845677503128], [-0.4019146609935978], [-0.7741613672813281], [-0.32214750964622696], [-0.008396714346568376], [-1.917490536593643], [-0.7316188865627304], [-0.8805175690778226], [-0.7528901269220294], [1.065800923798025], [1.709255944666816], [-0.8326572782694003], [-0.2902406491072786], [-0.08284605560411454], [1.012622822899778], [0.38512123230046086], [-0.1413419665921864], [0.3319431314022136], [0.30003627086326545], [1.1349324549657462], [-0.013714524436393219], [-1.2793533258146768], [-0.013714524436393219], [0.47552400382748106], [-0.25301597847850565], [-1.5239725899466139], [-0.29555845919710333], [-0.5454955334188651], [0.060734816821152934], [0.7148254578695936], [-0.056257005154991026], [-1.4495232486890677], [-0.4869996224307933], [-0.7741613672813281], [2.001735499607176], [0.6935542175102947], [0.002238905833081075], [0.8530885202050364], [-0.875199758987998], [0.5659267753545015], [1.6028997428703222], [0.6244226863425734], [-1.896219296234344], [0.459570573558007], [0.858406330294861], [-0.300876269286928], [-0.056257005154991026], [0.5287021047257283], [-1.1198190231199352], [0.9115844311931083], [-0.2689694087479798], [1.4220941998162813], [0.10327729753975073], [-0.9921915809641417], [0.10859510762957535], [-0.8007504177304519], [0.3638499919411619], [1.278513327391014], [-0.6943942159339573], [0.9009488110134588], [1.9751464491580522], [0.039463576461854034], [0.3957568524801103], [1.6135353630499714], [-0.2689694087479798], [-0.03498576479569212], [-2.342915343779621], [-0.4391393316223708], [-0.4976352426104428], [-1.7420028036294273], [-0.9230600497964204], [1.789023096014187], [-1.6250109816532834], [-0.6731229755746585], [3.2195140101770368], [2.1134095114934954], [-0.1626132069514853], [-2.1993344713543532], [-1.9813042576715398], [1.1296146448759217], [-1.0506874919522138], [-1.5771506908448611], [-0.47636400225114384], [0.8743597605643351], [0.5393377249053778], [-0.7422545067423799], [-0.625262684766236], [-0.16793101704131003], [0.7573679385881914], [0.7095076477797689], [-0.2902406491072786], [0.8052282293966138], [0.08200605718045184], [0.2628116002344923], [-0.05093919506516618], [0.2043156892464204], [1.3529626686485599], [0.15113758834817315], [1.3795517190976838], [0.044781386551678876], [0.895631000923634], [-0.9762381506946676], [-0.5295421031493911], [3.5279469953868707], [0.6456939267018723], [-0.7635257471016788], [0.03414576637202943], [0.5287021047257283], [0.842452900025387], [0.43829933319870806], [0.7892747991271397], [-0.300876269286928], [3.320552401883707], [1.730527185026115], [-0.6039914444069372], [-1.0560053020420384], [1.1402502650555715], [-0.04030357488551673], [-0.2051556876700831], [-0.5880380141374629], [-1.0134628213234407], [-0.2636515986581551], [0.9222200513727578], [-0.9336956699760699], [0.15113758834817315], [-1.3059423762638003], [-0.2902406491072786], [1.6879847043075173], [-0.3327831298258764], [0.1777266387972969], [-0.21579130784973255], [-0.6890764058441328], [1.2519242769418906], [-1.9547152072224163], [-0.08284605560411454], [-0.8060682278202764], [-0.9762381506946676], [0.4436171432885329], [-0.5029530527002675], [-2.1195673200069827], [-0.3115118894665775], [0.044781386551678876], [0.9434912917320567], [-2.236559141983126], [-1.1357724533894091], [1.2466064668520658], [1.7996587161938364], [-1.6090575513838095], [-0.6199448746764114], [0.1777266387972969], [-0.8698819488981732], [-0.9336956699760699], [-1.2846711359045015], [0.8637241403846857], [-0.12538853632271232], [-1.6941425128210048], [0.08732386727027644], [2.437795926972803], [-1.593104121114335], [-1.7047781330006544], [1.0817543540674992], [-0.9177422397065957], [-1.763274043988726], [0.19368006906677096], [0.044781386551678876], [-0.720983266383081], [-0.5242242930595664], [0.7201432679594184], [1.1030255944267982], [-0.6943942159339573], [1.2093817962232927], [-0.2796050289276291], [1.5763106924211983], [-1.327213616623099], [0.05009919664150349], [-1.1198190231199352], [-1.1942683643774812], [-0.05093919506516618], [2.267626004098412], [-0.853928518628699], [0.22026911951589445], [-1.8696302457852205], [1.1402502650555715], [-0.2636515986581551], [0.039463576461854034], [0.6669651670611711], [0.1830444488871215], [0.4808418139173059], [0.38512123230046086], [-1.066640922221688], [0.5871980157138004], [0.895631000923634], [-0.17324882713113474], [1.4699544906247042], [-0.6199448746764114], [0.47020619373765643], [-0.38596123072412364], [1.358280478738385], [3.102522188200893], [-0.09348167578376398], [0.9009488110134588], [-0.3381009399157011], [0.060734816821152934], [-0.9975093910539665], [-2.2737838126118994], [-0.6412161150357101], [0.023510146192379976], [0.209633499336245], [0.592515825803625], [-0.2051556876700831], [0.87967757065416], [0.5712445854443261], [-0.07221043542446508], [-0.720983266383081], [0.7573679385881914], [0.5712445854443261], [-1.3591204771620475], [1.2093817962232927], [0.895631000923634], [-1.0134628213234407], [0.592515825803625], [1.5071791612534768], [-0.47636400225114384], [2.576058989308246], [-0.6890764058441328], [0.6403761166120474], [0.5233842946359037], [1.54440383188225], [-0.6146270645865866], [0.10327729753975073], [-1.2580820854553778], [1.2997845677503128], [-0.18920225740060892], [1.624170983229621], [0.17240882870747204], [0.039463576461854034], [-0.0775282455142898], [0.018192336102555134], [0.24154035987519337], [-1.1836327441978316], [0.41702809283940917], [0.35853218185133734], [-0.17324882713113474], [0.7839569890373149], [-0.8273394681795754], [-0.7847969874609776], [-0.1360241565023618], [0.8318172798457375], [0.8264994697559127], [-1.8536768155157466], [-0.9549669103353686], [-1.8696302457852205], [-0.9656025305150181], [-0.5295421031493911], [2.262308194008587], [-1.0560053020420384], [-1.157043693748708], [0.5393377249053778], [0.8637241403846857], [-0.6943942159339573], [-0.28492283901745385], [-0.3168296995564022], [0.38512123230046086], [1.1349324549657462], [-0.5614489636883393], [0.9275378614625823], [1.2306530365825916], [-0.04562138497534157], [0.6456939267018723], [1.0977077843369736], [-0.226426928029382], [0.08200605718045184], [1.092389974247149], [-0.8911531892574721], [1.8209299565531354], [-0.8805175690778226], [-0.7954326076406271], [-0.3700078004546495], [-1.502701349587315], [-3.6032363350680794], [-0.9602847204251934], [-1.1145012130301104], [-0.8007504177304519], [0.5659267753545015], [-0.6837585957543079], [0.6031514459832744], [-0.3115118894665775], [0.6882364074204701], [-0.9602847204251934], [1.5550394520618993], [-0.9017888094371216], [0.4861596240071305], [-0.779479177371153], [-0.019032334526217828], [-0.47636400225114384], [-0.7316188865627304], [-0.4019146609935978], [0.6244226863425734], [0.209633499336245], [1.9272861583496297], [1.2944667576604882], [-1.896219296234344], [-0.02435014461604267], [-0.928377859886245], [0.16709101861764744], [-2.3482331538694456], [-0.3381009399157011], [0.9434912917320567], [-0.35405437018517527], [-0.4019146609935978], [-0.15197758677183584], [-0.662487355395009], [0.2521759800548428], [1.0392118733489015], [-2.64603051889963], [-0.7475723168322046], [-2.0876604594680344], [-2.1993344713543532], [0.6722829771509957], [-0.07221043542446508], [0.023510146192379976], [-0.4285037114427213], [1.1030255944267982], [-0.1466597766820111], [-0.9549669103353686], [0.342578751581863], [-0.3912790408139484], [0.5818802056239756], [0.3053540809530901], [-0.09348167578376398], [-0.2051556876700831], [-0.5880380141374629], [-1.0932299726708115], [-1.0081450112336159], [0.44893495337835754], [-0.3327831298258764], [0.002238905833081075], [0.8158638495762632], [-1.000168296098879], [0.05009919664150349], [-1.311260186353625], [-0.38596123072412364], [-0.05093919506516618], [0.5021130542766048], [1.0977077843369736], [-1.0879121625809869], [1.7837052859243625], [0.47552400382748106], [0.3159897011327395], [-0.4497749518020202], [0.044781386551678876], [-0.17324882713113474], [-1.2368108450960789], [0.8743597605643351], [0.42766371301905864], [-0.9762381506946676], [-0.8220216580897508], [0.7520501284983665], [-0.5189064829697416], [0.1617732085278226], [-0.45509276189184494], [-1.4282520083297687], [1.1668393155046948], [0.6776007872408206], [1.9272861583496297], [0.842452900025387], [-1.7792274742582004], [2.6770973810149155], [-1.1676793139283577], [-1.9866220677613646], [1.0232584430794271], [-0.19452006749043366], [-0.28492283901745385], [1.1508858852352206], [-1.1304546432995846], [1.2838311374808387], [-0.2211091179395573], [0.9381734816422318], [1.1668393155046948], [-0.3700078004546495], [0.8371350899355622], [-0.13070634641253706], [0.06605262691097755], [0.002238905833081075], [0.3957568524801103], [-0.875199758987998], [-0.07221043542446508], [0.1405019681685237], [1.204063986133468], [-0.5667667737781641], [-0.3965968509037731], [0.36916780203098676], [0.6191048762527486], [-1.1145012130301104], [0.18836225897694633], [0.47552400382748106], [0.8849953807439845], [-0.3700078004546495], [1.8794258675412074], [-0.03498576479569212], [-0.6731229755746585], [0.5021130542766048], [0.5287021047257283], [0.34789656167168787], [-1.0400518717725642], [-0.29555845919710333], [-0.5295421031493911], [-0.5082708627900923], [-1.731367183449778], [0.6456939267018723], [-1.0506874919522138], [-0.853928518628699], [0.459570573558007], [-0.3912790408139484], [-0.25833378856833034], [-0.8592463287185237], [2.5335165085896483], [0.42766371301905864], [1.1721571255945196], [1.012622822899778], [0.9222200513727578], [0.2521759800548428], [-1.327213616623099], [0.3319431314022136], [-0.2104734977599078], [-0.6305804948560608], [-1.784545284348025], [-0.15197758677183584], [1.3476448585587353], [-0.9602847204251934], [-0.25301597847850565], [0.14581977825834855], [-0.6199448746764114], [-2.8959675931213917], [-0.45509276189184494], [1.9166505381699805], [1.2306530365825916], [0.8690419504745105], [3.070615327661945], [-0.9017888094371216], [-0.1413419665921864], [-0.17324882713113474], [0.6935542175102947], [-2.1355207502764566], [-0.5720845838679888], [0.6935542175102947], [0.8530885202050364], [-1.178314934108007], [-0.8379750883592249], [2.155951992212093], [0.6776007872408206], [-0.3381009399157011], [0.0979594874499259], [-0.42318590135289663], [-1.7420028036294273], [-0.6199448746764114], [1.3104201879299622], [-0.38596123072412364], [0.3957568524801103], [1.278513327391014], [1.789023096014187], [0.007556715922905682], [1.2678777072113643], [-0.5135886728799169], [0.30003627086326545], [-0.2051556876700831], [-0.1360241565023618], [1.1349324549657462], [1.2146996063131172], [1.7943409061040119], [1.065800923798025], [-0.15729539686166058], [0.2681294103243171], [1.964510828978403], [-0.6943942159339573], [0.023510146192379976], [-0.5242242930595664], [0.2947184607734406], [-1.0506874919522138], [-0.8964709993472968], [1.3263736181994363], [-0.09348167578376398], [-1.0400518717725642], [-0.17324882713113474], [0.11923072780922479], [-0.21579130784973255], [-0.7847969874609776], [-0.19983787758025837], [0.076688247090627], [-1.0506874919522138], [-1.5611972605753868], [0.8371350899355622], [0.14581977825834855], [0.6776007872408206], [-1.5399260202160878], [-0.6571695453051845], [-0.662487355395009], [0.1405019681685237], [2.6239192801166684], [-1.327213616623099], [0.28940065068361603], [-0.2051556876700831], [-1.0820625714821797], [0.895631000923634], [1.6879847043075173], [1.0870721641573238], [-0.6731229755746585], [-0.3806434206342989], [0.8264994697559127], [1.0392118733489015], [-0.3327831298258764], [0.03414576637202943], [0.3744856121208114], [-1.0719587323115125], [0.5446555349952026], [0.2628116002344923], [-0.6305804948560608], [1.2466064668520658], [0.03414576637202943], [0.17240882870747204], [0.4861596240071305], [-0.07221043542446508], [0.5978336358934496], [-0.32746531973605164], [-0.5348599132392159], [-1.2953067560841507], [-1.0347340616827396], [-1.385709527611171], [0.07137043700080238], [-0.7688435571915035], [0.28940065068361603], [-0.4657283820714944], [-2.2684660025220746], [1.6667134639482184], [0.9913515825404791], [-0.5401777233290405], [2.8525851139791314], [0.27876503050396656], [0.08732386727027644], [-0.8060682278202764], [-0.17324882713113474], [0.8477707101152115], [1.8156121464633106], [-0.226426928029382], [-1.593104121114335], [0.6669651670611711], [-0.8113860379101013], [1.0498474935285511], [0.41702809283940917], [-0.09348167578376398], [-0.8911531892574721], [0.028827956282204584], [-1.9068549164139939], [-0.013714524436393219], [-0.17856663722095947], [-0.25301597847850565], [2.927034455236677], [-0.2796050289276291], [1.0232584430794271], [0.11923072780922479], [1.6082175529601468], [-0.912424429616771], [-0.25301597847850565], [1.358280478738385], [-0.3753256105444742], [-0.5348599132392159], [-0.1838844473107842], [0.3159897011327395], [-0.23706254820903144], [-0.27428721883780444], [0.11923072780922479], [0.459570573558007], [0.762685748678016], [0.7307788881390677], [-0.4444571417121955], [-0.2636515986581551], [1.5922641226906724], [-1.502701349587315], [1.9326039684394545], [1.4167763897264567], [1.597581932780497], [1.7411628052057648], [0.5127486744562543], [-0.6039914444069372], [0.4436171432885329], [-0.3912790408139484], [0.5127486744562543], [-0.18920225740060892], [1.0073050128099534], [-0.21579130784973255], [0.6829185973306452], [0.9594447220015307], [-0.662487355395009], [-0.38596123072412364], [2.097456081224021], [1.485907920894178], [-0.04562138497534157], [2.001735499607176], [0.6722829771509957], [-0.7688435571915035], [0.2734472204141417], [-0.5189064829697416], [-0.6093092544967619], [-0.2796050289276291], [2.363346585715257], [0.08200605718045184], [-0.21579130784973255], [1.4167763897264567], [-1.0134628213234407], [0.03414576637202943], [0.5233842946359037], [1.5018613511636523], [0.007556715922905682], [1.6507600336787445], [-1.0134628213234407], [0.10327729753975073], [-0.49231743252061805], [-1.1676793139283577], [1.2093817962232927], [0.05541700673132833], [-1.4229341982399442], [-0.8698819488981732], [0.35853218185133734], [-0.9602847204251934], [0.6988720276001195], [0.895631000923634], [0.3532143717615125], [0.32662532131238897], [1.8953792978106816], [0.8105460394864387], [0.28940065068361603], [-0.7582079370118541], [-0.4178680912630719], [-0.8220216580897508], [3.1929249597279137], [1.0232584430794271], [-1.3165779964434496], [-0.19983787758025837], [-0.8167038479999259], [1.2412886567622408], [-0.32214750964622696], [1.2466064668520658], [-0.23706254820903144], [-1.5665150706652116], [0.12454853789904964], [1.0392118733489015], [0.5712445854443261], [1.0285762531692522], [-1.3910273377009958], [0.16709101861764744], [-0.3806434206342989], [-0.9230600497964204], [0.37980342221063623], [0.35853218185133734], [-0.5561311535985146], [-0.3753256105444742], [-0.013714524436393219], [-1.045369681862389], [0.6244226863425734], [-0.2689694087479798], [1.2731955173011893], [-1.385709527611171], [-0.4976352426104428], [-0.16793101704131003], [1.225335226492767], [-1.1304546432995846], [0.5393377249053778], [-1.8111343347971487], [0.4861596240071305], [-0.6571695453051845], [1.092389974247149], [-1.220857414826605], [-0.3912790408139484], [2.560105559038772], [0.5871980157138004], [-0.16793101704131003], [0.10859510762957535], [0.6616473569713464], [-0.17856663722095947], [1.331691428289261], [1.5018613511636523], [2.11872732158332], [0.39043904239028565], [0.5127486744562543], [-0.34341875000552585], [0.11923072780922479], [-0.9390134800658945], [0.5393377249053778], [-0.986873770874317], [-0.625262684766236], [0.6031514459832744], [0.7041898376899441], [-0.0030789042567437685], [-0.7422545067423799], [-1.747320613719252], [-0.24238035829885618], [0.15113758834817315], [0.7839569890373149], [-0.4019146609935978], [1.1668393155046948], [-0.23174473811920673], [-1.4495232486890677], [1.831565576732785], [0.7786391789474902], [0.8903131908338094], [-0.056257005154991026], [-0.5880380141374629], [0.6882364074204701], [0.076688247090627], [0.12986634798887425], [0.19368006906677096], [-0.23174473811920673], [-1.0294162515929148], [-1.220857414826605], [-0.3168296995564022], [1.0498474935285511], [-0.6412161150357101], [-0.1466597766820111], [0.023510146192379976], [0.10859510762957535], [0.14581977825834855], [2.177223232571392], [0.6988720276001195], [0.7307788881390677], [-1.0187806314132655], [-1.0028272011437913], [0.06605262691097755], [0.6191048762527486], [0.6456939267018723], [0.9169022412829329], [-0.3700078004546495], [-2.5396743171031355], [-0.7528901269220294], [0.5393377249053778], [-0.07221043542446508], [-0.5614489636883393], [-0.912424429616771], [-0.5986736343171124], [-1.4122985780602948], [1.07111873388785], [-0.8911531892574721], [0.9541269119117061], [-0.6412161150357101], [-0.16793101704131003], [-1.938761776952942], [0.459570573558007], [-0.6784407856644833], [-1.614375361473634], [-0.9443312901557194], [2.8047248231707087], [0.2043156892464204], [-0.056257005154991026], [-1.4867479193178408], [-1.2633998955452026], [0.8637241403846857], [-0.5189064829697416], [-0.42318590135289663], [0.007556715922905682], [-1.220857414826605], [-0.06689262533464048], [1.2731955173011893], [-0.8858353791676473], [-1.3803917175213463], [-0.5189064829697416], [-0.9177422397065957], [-1.0294162515929148], [0.2521759800548428], [-0.5508133435086899], [1.5922641226906724], [0.2521759800548428], [-1.199586174467306], [-0.1466597766820111], [-1.21553960473678], [-1.1251368332097598], [0.725461078049243], [0.1139129177194002], [0.4914774340969553], [0.6084692560730991], [-0.4869996224307933], [1.2412886567622408], [0.6669651670611711], [0.6084692560730991], [0.10859510762957535], [-0.4976352426104428], [0.4117102827495846], [-0.2796050289276291], [2.2144479032001647], [-0.15197758677183584], [0.15113758834817315], [0.6456939267018723], [0.3532143717615125], [-0.43382152153254605], [1.044529683438726], [2.3208041049966592], [2.480338407691401], [0.342578751581863], [1.1508858852352206], [1.411458579636632], [0.012874526012730526], [1.1083434045166227], [0.1351841580786991], [0.16709101861764744], [0.044781386551678876], [-1.4548410587788925], [-0.5827202040476382], [-0.23706254820903144], [2.4697027875117517], [1.0870721641573238], [-0.1413419665921864], [-0.17856663722095947], [0.1405019681685237], [-0.42318590135289663], [0.5127486744562543], [-1.9440795870427667], [0.2681294103243171], [-0.7103476462034315], [-0.09348167578376398], [2.2144479032001647], [0.459570573558007], [1.789023096014187], [-0.2796050289276291], [-0.9443312901557194], [1.9751464491580522], [2.288897244457711], [0.6722829771509957], [0.9328556715524072], [0.47552400382748106], [0.975398152271005], [0.2840828405937912], [-0.7316188865627304], [-1.8696302457852205], [0.09264167736010129], [-1.1517258836588833], [0.3106718910429149], [-0.5880380141374629], [0.5978336358934496], [0.8158638495762632], [-0.2689694087479798], [-0.6571695453051845], [-2.284419432791549], [0.4914774340969553], [1.124296834786097], [-0.03498576479569212], [0.3319431314022136], [-0.2051556876700831], [0.6829185973306452], [0.2043156892464204], [-1.0772765424013373], [0.10327729753975073], [-0.32746531973605164], [-0.10411729596341343], [-0.986873770874317], [-0.5986736343171124], [2.78345358281141], [1.8156121464633106], [-1.7100959430904792], [0.5340199148155531], [1.331691428289261], [-0.1466597766820111], [0.1405019681685237], [-0.49231743252061805], [-0.5348599132392159], [1.4699544906247042], [0.3957568524801103], [0.18836225897694633], [-0.9496491002455439], [-0.6837585957543079], [-1.3538026670722227], [-0.7156654562932563], [0.3957568524801103], [-0.9602847204251934], [-0.3753256105444742], [0.023510146192379976], [-0.1360241565023618], [0.2521759800548428], [0.05009919664150349], [2.054913600505423], [-0.1838844473107842], [0.43829933319870806], [-0.5401777233290405], [-0.4976352426104428], [0.7945926092169643], [1.3263736181994363], [0.2840828405937912], [-1.0294162515929148], [0.5233842946359037], [0.7414145083187171], [2.5920124195777197], [1.1189790246962725], [0.5180664845460788], [-1.157043693748708], [0.34789656167168787], [1.6294887933194457], [-2.0451179787494365], [0.3638499919411619], [-2.475860596025239], [0.8849953807439845], [0.24685816996501822], [-0.06689262533464048], [-1.6250109816532834], [1.3423270484689107], [0.22026911951589445], [-0.5933558242272877], [-0.9709203406048429], [-1.0719587323115125], [-0.5401777233290405], [-0.6518517352153596], [0.9860337724506545], [0.19368006906677096], [0.37980342221063623], [0.32662532131238897], [-0.42318590135289663], [0.4329815231088835], [-1.614375361473634], [0.060734816821152934], [-0.04562138497534157], [-0.4657283820714944], [-0.662487355395009], [0.7467323184085419], [1.2306530365825916], [0.7041898376899441], [-0.4285037114427213], [-0.3115118894665775], [-0.6784407856644833], [-0.9390134800658945], [-0.23174473811920673], [-0.928377859886245], [-0.4497749518020202], [-0.42318590135289663], [-0.1413419665921864], [1.044529683438726], [0.3638499919411619], [0.5287021047257283], [-0.6943942159339573], [1.0764365439776746], [-1.2421286551859037], [0.4329815231088835], [1.2678777072113643], [-0.7741613672813281], [-1.0932299726708115], [0.9700803421811801], [0.2681294103243171], [-0.6518517352153596], [1.1189790246962725], [-1.7260493733599533], [0.05541700673132833], [-1.0081450112336159], [-0.35405437018517527], [-0.7316188865627304], [1.3795517190976838], [-1.0719587323115125], [-0.15197758677183584], [2.7994070130808844], [1.1774749356843441], [1.5390860217924254], [-1.8270877650666228], [0.24685816996501822], [-0.8486107085388743], [0.03414576637202943], [-0.09879948587358871], [-1.3006245661739755], [0.47020619373765643], [-1.5984219312041599], [-0.4869996224307933], [0.7414145083187171], [3.0333906570331717], [-1.7739096641683758], [-0.5242242930595664], [-2.1302029401866323], [-1.2793533258146768], [-0.2104734977599078], [-0.662487355395009], [0.3053540809530901], [-0.9230600497964204], [-0.8645641388083485], [0.44893495337835754], [0.002238905833081075], [-0.17324882713113474], [0.08732386727027644], [2.1134095114934954], [-0.04030357488551673], [-0.3381009399157011], [0.15113758834817315], [2.607965849847194], [0.7786391789474902], [-1.1889505542876564], [-0.4604105719816697], [0.6776007872408206], [0.2255869296057193], [0.08732386727027644], [0.40639247265975975], [-0.4657283820714944], [1.5337682117026004], [-1.481430109228016], [0.842452900025387], [-1.2953067560841507], [0.32130751122256435], [-0.1413419665921864], [-0.2902406491072786], [-0.5508133435086899], [1.1349324549657462], [-1.614375361473634], [-0.28492283901745385], [-0.4497749518020202], [0.5552911551748521], [0.37980342221063623], [-0.5295421031493911], [0.03414576637202943], [1.204063986133468], [0.25749379014466767], [1.2625598971215397], [0.6297404964323979], [-0.9815559607844923], [0.4808418139173059], [0.6031514459832744], [-0.5348599132392159], [-0.2104734977599078], [-0.6571695453051845], [-0.9762381506946676], [0.6616473569713464], [0.725461078049243], [-1.3591204771620475], [-1.6622356522820567], [-0.5827202040476382], [0.4648883836478316], [-0.8273394681795754], [-0.19452006749043366], [-0.47104619216131915], [0.28940065068361603], [1.9166505381699805], [-0.08816386569393926], [0.3159897011327395], [-0.21579130784973255], [-0.17856663722095947], [0.6563295468815217], [0.17240882870747204], [0.6882364074204701], [-0.8167038479999259], [0.28940065068361603], [-0.07221043542446508], [-0.6784407856644833], [0.6722829771509957], [-1.4176163881501196], [0.7786391789474902], [-1.6675534623718813], [-0.2104734977599078], [1.2625598971215397], [-0.32214750964622696], [-0.1838844473107842], [-0.4604105719816697], [-0.3115118894665775], [-0.7901147975508024], [-2.0398001686596117], [-0.9230600497964204], [1.1083434045166227], [0.3053540809530901], [-0.5135886728799169], [1.7943409061040119], [0.0979594874499259], [0.8318172798457375], [-0.9390134800658945], [2.4005712563440302], [-1.3378492368027486], [0.39043904239028565], [-0.21579130784973255], [-0.5029530527002675], [-0.06157481524481563], [-0.6518517352153596], [-1.4548410587788925], [2.7355932920029877], [0.002238905833081075], [-1.0719587323115125], [-1.1464080735690587], [-0.27428721883780444], [0.8530885202050364], [0.3957568524801103], [-0.04030357488551673], [2.6770973810149155], [0.4808418139173059], [1.7837052859243625], [1.773069665744713], [-1.2527642753655532], [0.023510146192379976], [-0.42318590135289663], [-1.7207315632701286], [0.895631000923634], [0.16709101861764744], [0.9328556715524072], [-1.3218958065332744], [-0.08816386569393926], [0.1139129177194002], [-0.1413419665921864], [0.8371350899355622], [1.2838311374808387], [0.37980342221063623], [-0.6093092544967619], [0.12986634798887425], [-0.3115118894665775], [0.5233842946359037], [-0.8007504177304519], [-0.3912790408139484], [0.6350583065222228], [-1.1889505542876564], [0.44893495337835754], [-0.38596123072412364], [-0.5933558242272877], [-0.056257005154991026], [-0.8592463287185237], [0.44893495337835754], [0.06605262691097755], [2.3793000159847315], [-1.3644382872518723], [-0.5029530527002675], [0.8371350899355622], [0.209633499336245], [-0.9017888094371216], [-0.7369366966525551], [-0.9709203406048429], [-0.6518517352153596], [0.3638499919411619], [-0.5508133435086899], [0.9275378614625823], [-1.3165779964434496], [2.5069274581405243], [0.7680035587678409], [-0.6837585957543079], [0.4542527634681824], [-0.7688435571915035], [-1.4761122991381914], [-1.9653508274020657], [-0.013714524436393219], [-0.300876269286928], [-0.6890764058441328], [-0.3381009399157011], [-0.1360241565023618], [-0.5774023939578136], [-0.3912790408139484], [1.0392118733489015], [0.23090473969554393], [1.0019872027201282], [0.05541700673132833], [-0.9921915809641417], [0.28940065068361603], [0.9488091018218813], [-1.2049039845571305], [-1.7420028036294273], [-0.300876269286928], [0.209633499336245], [-0.25833378856833034], [-1.8377233852462724], [-1.1729971240181822], [0.023510146192379976], [-1.6835068926413557], [0.007556715922905682], [-0.5135886728799169], [1.2891489475706632], [-0.27428721883780444], [0.8849953807439845], [0.5552911551748521], [-0.6784407856644833], [-2.0823426493782096], [0.8264994697559127], [-0.19452006749043366], [1.7837052859243625], [-0.2689694087479798], [-0.6358983049458855], [-0.8858353791676473], [-0.4391393316223708], [1.3104201879299622], [0.16709101861764744], [-0.5189064829697416], [0.9807159623608296], [1.9272861583496297], [0.03414576637202943], [-1.2474464652757284], [3.150382479009316], [-0.23706254820903144], [-0.2476981683886809], [-0.5508133435086899], [0.15113758834817315], [-0.6943942159339573], [0.4861596240071305], [0.18836225897694633], [2.3899356361643807], [0.87967757065416], [-0.226426928029382], [0.08732386727027644], [-1.1091834029402856], [0.36916780203098676], [1.4220941998162813], [-0.6305804948560608], [0.2734472204141417], [1.464636680534879], [0.24685816996501822], [0.7573679385881914], [-0.6518517352153596], [1.2572420870317151], [-0.5242242930595664], [-0.6997120260237822], [-1.9334439668631174], [-0.019032334526217828], [-0.18920225740060892], [-0.9549669103353686], [-0.6358983049458855], [1.4061407695468073], [1.3210558081096118], [0.19899787915659556], [-1.7047781330006544], [0.5818802056239756], [0.6031514459832744], [-0.45509276189184494], [-1.0028272011437913], [-1.6250109816532834], [-0.3487365600953506], [-1.6462822220125823], [0.8318172798457375], [-0.056257005154991026], [-0.6784407856644833], [0.5340199148155531], [-0.8007504177304519], [1.491225730984003], [3.6874812980816127], [0.5818802056239756], [-0.013714524436393219], [-0.8007504177304519], [-0.4816818123409686], [-1.02409844150309], [1.0977077843369736], [0.6191048762527486], [0.4436171432885329], [0.3053540809530901], [-1.5292904000364387], [-0.17324882713113474], [0.8743597605643351], [-0.7369366966525551], [0.7148254578695936], [0.8211816596660881], [-0.18920225740060892], [0.8743597605643351], [-0.019032334526217828], [0.87967757065416], [0.7786391789474902], [-1.1729971240181822], [-1.901537106324169], [-0.019032334526217828], [0.43829933319870806], [-0.7316188865627304], [-0.04030357488551673], [2.2144479032001647], [0.5552911551748521], [0.060734816821152934], [-1.332531426712924], [1.911332728080156], [-0.5667667737781641], [-0.9230600497964204], [-0.8911531892574721], [0.2255869296057193], [1.044529683438726], [0.9647625320913555], [0.5606089652646766], [1.3901873392773332], [0.14581977825834855], [-1.3963451477908206], [-0.5454955334188651], [-0.2211091179395573], [-0.9496491002455439], [-0.23174473811920673], [0.459570573558007], [0.018192336102555134], [-1.0613231121318631], [-1.3750739074315217], [1.7039381345769915], [0.8903131908338094], [-0.5933558242272877], [0.23622254978536875], [-0.9177422397065957], [-0.6305804948560608], [1.044529683438726], [0.6031514459832744], [1.565675072241549], [-0.8858353791676473], [1.1721571255945196], [-1.0719587323115125], [1.3529626686485599], [-0.19452006749043366], [0.19368006906677096], [-0.02435014461604267], [-1.0294162515929148], [-0.08816386569393926], [-0.6890764058441328], [0.15113758834817315], [-0.019032334526217828], [-1.2899889459943261], [-0.3806434206342989], [-0.1413419665921864], [0.12454853789904964], [0.3319431314022136], [-0.3912790408139484], [0.5074308643664294], [-0.04562138497534157], [-0.08284605560411454], [1.0179406329896026], [-0.2636515986581551], [1.5178147814331264], [1.1615215054148702], [-2.9916881747382367], [-0.7901147975508024], [1.0179406329896026], [-2.624759278540331], [1.2466064668520658], [0.3319431314022136], [0.09264167736010129], [-0.29555845919710333], [-0.11475291614306289], [-0.9656025305150181], [-1.348484856982398], [1.6294887933194457], [2.7728179626317604], [-1.6622356522820567], [-0.6146270645865866], [0.8690419504745105], [1.757116235475239], [-1.3963451477908206], [-0.5348599132392159], [1.012622822899778], [-1.3750739074315217], [-0.3806434206342989], [-0.05093919506516618], [-0.8486107085388743], [-0.13070634641253706], [-1.885583676054695], [-0.6039914444069372], [0.060734816821152934], [-1.1145012130301104], [1.6720312740380434], [1.890061487720857], [-0.3965968509037731], [-0.4391393316223708], [0.9860337724506545], [0.12986634798887425], [0.25749379014466767], [-0.13070634641253706], [0.7573679385881914], [-0.5880380141374629], [-0.41255028117324716], [-0.1360241565023618], [-1.4122985780602948], [0.5606089652646766], [0.24154035987519337], [0.24154035987519337], [0.6244226863425734], [-1.0719587323115125], [0.19899787915659556], [-0.5348599132392159], [-0.4657283820714944], [2.1453163720324433], [-1.1357724533894091], [0.6031514459832744], [-0.02435014461604267], [0.2521759800548428], [-0.646533925125535], [0.5552911551748521], [-0.056257005154991026], [-0.5135886728799169], [-0.019032334526217828], [0.12454853789904964], [0.47552400382748106], [-0.5295421031493911], [-0.3487365600953506], [0.4117102827495846], [0.7520501284983665], [-0.09348167578376398], [1.7624340455650636], [-0.3487365600953506], [-0.11475291614306289], [-0.8964709993472968], [1.331691428289261], [0.1405019681685237], [-0.4444571417121955], [-0.5029530527002675], [-0.12007072623288761], [0.3106718910429149], [-1.2421286551859037], [-0.4285037114427213], [0.08200605718045184], [-1.332531426712924], [0.87967757065416], [0.9062666211032835], [-0.41255028117324716], [-0.9443312901557194], [-0.7528901269220294], [0.1830444488871215], [-2.3482331538694456], [-0.4072324710834224], [2.879174164428255], [0.459570573558007], [0.002238905833081075], [-0.7050298361136068], [0.06605262691097755], [-1.1198190231199352], [0.7414145083187171], [-0.056257005154991026], [-0.9921915809641417], [1.906014917990331], [0.459570573558007], [-0.7847969874609776], [1.1668393155046948], [-1.4548410587788925], [0.1830444488871215], [1.3529626686485599], [0.5340199148155531], [-1.7260493733599533], [-0.3965968509037731], [1.1189790246962725], [0.5127486744562543], [0.3744856121208114], [0.24154035987519337], [0.1139129177194002], [-1.3006245661739755], [-0.7528901269220294], [-1.9813042576715398], [0.12454853789904964], [0.3532143717615125], [-0.4604105719816697], [0.05541700673132833], [0.03414576637202943], [1.0498474935285511], [-0.0775282455142898], [-1.0985477827606362], [-0.625262684766236], [-1.0613231121318631], [-0.986873770874317], [0.1777266387972969], [-0.5295421031493911], [0.3638499919411619], [-0.5082708627900923], [-0.5029530527002675], [0.3957568524801103], [-0.2636515986581551], [0.14581977825834855], [-1.0134628213234407], [-1.1836327441978316], [0.40639247265975975], [-1.1729971240181822], [1.1402502650555715], [0.7945926092169643], [-0.29555845919710333], [0.06605262691097755], [-1.0506874919522138], [-0.1466597766820111], [-1.0932299726708115], [1.2944667576604882], [-0.9602847204251934], [-0.6890764058441328], [-1.4920657294076656], [1.5231325915229512], [-1.2899889459943261], [0.6350583065222228], [-0.29555845919710333], [0.6456939267018723], [-1.88026586596487], [0.5552911551748521], [1.2306530365825916], [0.5499733450850272], [0.5074308643664294], [0.7733213688576654], [-0.3327831298258764], [-0.853928518628699], [-1.348484856982398], [-0.4497749518020202], [-0.2689694087479798], [0.2681294103243171], [-0.6518517352153596], [-0.226426928029382], [-1.6303287917431084], [-0.5082708627900923], [0.30003627086326545], [-1.02409844150309], [-0.9656025305150181], [-0.8167038479999259], [-0.7156654562932563], [-0.4976352426104428], [0.039463576461854034], [3.3258702119735317], [0.060734816821152934], [-0.056257005154991026], [0.6244226863425734], [-0.7263010764729058], [-0.5348599132392159], [0.12454853789904964], [-0.47104619216131915], [0.6191048762527486], [-0.8167038479999259], [-0.8645641388083485], [-0.06689262533464048], [-0.2051556876700831], [-0.5827202040476382], [1.1508858852352206], [0.3053540809530901], [0.2681294103243171], [-0.029667954705867278], [-0.4657283820714944], [1.1774749356843441], [0.3744856121208114], [-0.24238035829885618], [-0.5189064829697416], [-0.5933558242272877], [-1.4920657294076656], [-1.178314934108007], [-3.01827722518736], [0.32130751122256435], [-1.1889505542876564], [0.3532143717615125], [-0.9549669103353686], [-0.7901147975508024], [-0.6412161150357101], [-0.8167038479999259], [-1.2580820854553778], [1.0498474935285511], [-0.359372180275], [-0.08284605560411454], [-0.7050298361136068], [1.3635982888282097], [0.1777266387972969], [-0.6039914444069372], [0.5499733450850272], [-1.0613231121318631], [-0.29555845919710333], [-1.6090575513838095], [-1.3910273377009958], [-0.2902406491072786], [-1.4176163881501196], [0.209633499336245], [0.7414145083187171], [-1.6941425128210048], [1.1508858852352206], [0.7786391789474902], [-0.1838844473107842], [-0.06157481524481563], [-1.2049039845571305], [-1.2740355157248517], [0.6563295468815217], [-0.0030789042567437685], [1.044529683438726], [-1.0506874919522138], [-0.47104619216131915], [-0.7156654562932563], [-0.1360241565023618], [0.05541700673132833], [0.7360966982288925], [0.3744856121208114], [-0.7582079370118541], [-0.45509276189184494], [-1.02409844150309], [-0.8645641388083485], [-1.1889505542876564], [0.7467323184085419], [-0.3965968509037731], [0.3159897011327395], [-0.912424429616771], [-0.8060682278202764], [0.08200605718045184], [0.24154035987519337], [-1.3644382872518723], [0.6935542175102947], [2.9057632148773784], [-0.5242242930595664], [0.24685816996501822], [-1.385709527611171], [-1.2527642753655532], [-0.2476981683886809], [0.1351841580786991], [-1.5611972605753868], [0.38512123230046086], [0.5127486744562543], [-0.5774023939578136], [0.22026911951589445], [-0.8379750883592249], [-0.6731229755746585], [0.06605262691097755], [2.607965849847194], [-0.12007072623288761], [0.35853218185133734], [1.5922641226906724], [-2.3216441034203217], [-0.11475291614306289], [1.2891489475706632], [-0.5720845838679888], [2.6398727103861424], [-0.008396714346568376], [0.9275378614625823], [0.5074308643664294], [0.8849953807439845], [-0.4178680912630719], [-0.1360241565023618], [-0.7635257471016788], [-0.12538853632271232], [-0.03498576479569212], [0.342578751581863], [-0.2211091179395573], [0.5233842946359037], [-0.25301597847850565], [-0.7103476462034315], [-0.7316188865627304], [-2.2152879016238276], [1.7252093749362905], [0.7573679385881914], [-0.3912790408139484], [0.14581977825834855], [-0.9656025305150181], [-0.6093092544967619], [0.8158638495762632], [1.0232584430794271], [2.326121915086484], [-0.04562138497534157], [1.2838311374808387], [1.5178147814331264], [-1.385709527611171], [0.342578751581863], [-0.23174473811920673], [2.054913600505423], [-0.2476981683886809], [0.842452900025387], [1.2838311374808387], [0.762685748678016], [0.8849953807439845], [-0.019032334526217828], [-0.17856663722095947], [-1.2740355157248517], [-2.1408385603662814], [-1.3006245661739755], [-0.9390134800658945], [0.6829185973306452], [0.32662532131238897], [0.1830444488871215], [0.156455398437998], [1.278513327391014], [-0.4657283820714944], [-0.9230600497964204], [-1.2527642753655532], [-0.986873770874317], [1.5497216419720747], [0.7201432679594184], [-0.029667954705867278], [-0.5401777233290405], [0.06605262691097755], [-1.460158868868717], [-0.12007072623288761], [0.25749379014466767], [0.5180664845460788], [0.3532143717615125], [-0.8698819488981732], [-2.055753598929086], [0.25749379014466767], [-1.0134628213234407], [-0.11475291614306289], [0.6297404964323979], [0.2628116002344923], [-0.19452006749043366], [-0.03498576479569212], [0.19368006906677096], [-0.3753256105444742], [-1.4282520083297687], [3.4481798440394997], [-0.5135886728799169], [1.1402502650555715], [-0.8167038479999259], [-0.8486107085388743], [-2.26314819243225], [0.39043904239028565], [1.331691428289261], [0.5712445854443261], [1.9910998794275265], [0.9860337724506545], [-0.6837585957543079], [0.209633499336245], [0.7095076477797689], [1.4167763897264567], [0.6456939267018723], [1.2838311374808387], [-0.019032334526217828], [1.1934283659538183], [0.36916780203098676], [1.225335226492767], [-0.6199448746764114], [-0.056257005154991026], [-1.3538026670722227], [-0.8060682278202764], [1.1508858852352206], [-0.16793101704131003], [-1.0081450112336159], [0.044781386551678876], [-0.6039914444069372], [-1.768591854078551], [-0.10943510605323815], [-1.885583676054695], [0.24685816996501822], [-1.614375361473634], [0.5021130542766048], [1.464636680534879], [-0.8007504177304519], [-0.38596123072412364], [-1.5611972605753868], [0.15113758834817315], [-1.5346082101262633], [-0.2476981683886809], [-0.029667954705867278], [-0.1360241565023618], [-0.625262684766236], [-0.2476981683886809], [-0.9177422397065957], [-1.5133369697669643], [-0.6358983049458855], [0.32130751122256435], [-0.4816818123409686], [-0.7263010764729058], [-0.8220216580897508], [0.15113758834817315], [1.5337682117026004], [-0.4976352426104428], [0.7680035587678409], [-0.1360241565023618], [-0.1626132069514853], [-0.8113860379101013], [0.028827956282204584], [-1.3910273377009958], [-1.5399260202160878], [-0.3327831298258764], [-0.3168296995564022], [0.19899787915659556], [-1.465476678958542], [0.9062666211032835], [-0.8858353791676473], [0.007556715922905682], [-0.11475291614306289], [-0.32746531973605164], [-0.6571695453051845], [1.2731955173011893], [0.5074308643664294], [0.5446555349952026], [-0.1466597766820111], [-0.6731229755746585], [-0.5720845838679888], [1.3848695291875086], [0.028827956282204584], [0.6722829771509957], [-0.359372180275], [0.156455398437998], [0.25749379014466767], [-0.9336956699760699], [0.858406330294861], [1.3795517190976838], [0.6722829771509957], [-2.5981702280912073], [-0.4178680912630719], [-0.04030357488551673], [-0.8113860379101013], [1.789023096014187], [-0.09348167578376398], [0.039463576461854034], [-0.17856663722095947], [-0.4816818123409686], [0.09264167736010129], [-0.08816386569393926], [0.3106718910429149], [-1.78986309443785], [-0.17324882713113474], [-0.5242242930595664], [2.129362941762969], [-0.6093092544967619], [0.40639247265975975], [-0.2689694087479798], [0.8690419504745105], [-0.8167038479999259], [-0.28492283901745385], [1.2466064668520658], [-0.3168296995564022], [0.05009919664150349], [-0.03498576479569212], [1.092389974247149], [0.6563295468815217], [-0.2796050289276291], [-0.1466597766820111], [-0.47636400225114384], [0.3106718910429149], [-0.6943942159339573], [0.9275378614625823], [-0.16793101704131003], [0.3744856121208114], [-0.8326572782694003], [-0.6039914444069372], [0.2947184607734406], [-0.5827202040476382], [0.08200605718045184], [-1.1304546432995846], [-0.02435014461604267], [1.07111873388785], [-0.226426928029382], [0.5180664845460788], [-0.9496491002455439], [0.19368006906677096], [-0.2689694087479798], [0.002238905833081075], [-0.15197758677183584], [-1.763274043988726], [-0.32214750964622696], [-1.02409844150309], [-1.0506874919522138], [0.725461078049243], [-0.28492283901745385], [-0.359372180275], [-1.2953067560841507], [-1.1145012130301104], [0.209633499336245], [-0.1838844473107842], [1.5603572621517243], [-0.8273394681795754], [-0.5348599132392159], [-1.9547152072224163], [-1.332531426712924], [-0.7901147975508024], [-1.5984219312041599], [0.16709101861764744], [0.24154035987519337], [-0.8805175690778226], [0.11923072780922479], [-0.7103476462034315], [-1.0294162515929148], [0.3744856121208114], [0.03414576637202943], [-0.09348167578376398], [0.06605262691097755], [1.2412886567622408], [0.028827956282204584], [0.975398152271005], [-1.4229341982399442], [0.0979594874499259], [-0.986873770874317], [-1.9440795870427667], [1.2519242769418906], [-0.5348599132392159], [1.4433654401755802], [0.7945926092169643], [0.19899787915659556], [-0.2689694087479798], [0.7892747991271397], [0.1777266387972969], [0.23090473969554393], [0.7945926092169643], [1.1562036953250452], [-0.7103476462034315], [0.9541269119117061], [0.6988720276001195], [-0.9762381506946676], [0.08732386727027644], [1.07111873388785], [-0.03498576479569212], [-0.4391393316223708], [0.19368006906677096], [0.33726094149203845], [0.842452900025387], [1.1827927457741692], [0.43829933319870806], [-0.6890764058441328], [0.24685816996501822], [-1.4761122991381914], [-1.1038655928504608], [0.24154035987519337], [-1.5558794504855622], [-0.15197758677183584], [0.1405019681685237], [0.8903131908338094], [-0.4072324710834224], [-0.6997120260237822], [0.08732386727027644], [0.6137870661629239], [-0.35405437018517527], [1.7837052859243625], [0.3319431314022136], [-0.25833378856833034], [-0.2636515986581551], [1.044529683438726], [-0.1360241565023618], [-0.5827202040476382], [0.7680035587678409], [1.2306530365825916], [-0.6784407856644833], [0.5606089652646766], [-0.3168296995564022], [0.725461078049243], [-0.17324882713113474], [-0.25301597847850565], [-1.9706686374918905], [-0.23174473811920673], [0.9647625320913555], [3.724705968710386], [-0.10411729596341343], [0.19899787915659556], [-1.0985477827606362], [-0.35405437018517527], [-0.8167038479999259], [1.0498474935285511], [-1.0187806314132655], [0.09264167736010129], [0.4648883836478316], [-1.4920657294076656], [-0.17856663722095947], [1.033894063259077], [-1.6250109816532834], [0.8743597605643351], [-2.784293581235073], [-0.5242242930595664], [0.23090473969554393], [0.2840828405937912], [-0.9815559607844923], [-1.7951809045276748], [-0.10411729596341343], [-1.2261752249164295], [0.03414576637202943], [0.1351841580786991], [-0.07221043542446508], [2.4112068765236794], [0.6191048762527486], [-0.6039914444069372], [0.5818802056239756], [0.012874526012730526], [1.1508858852352206], [-0.875199758987998], [-1.0825943524911619], [0.40639247265975975], [1.996417689517351], [-1.2474464652757284], [-0.4019146609935978], [-0.4816818123409686], [-1.0879121625809869], [0.08200605718045184], [-1.1623615038385327], [-1.1091834029402856], [1.9538752087987532], [-0.5667667737781641], [2.9642591258654503], [0.47552400382748106], [-0.45509276189184494], [0.27876503050396656], [-1.2899889459943261], [-0.5135886728799169], [-0.2902406491072786], [0.5712445854443261], [-0.8220216580897508], [0.076688247090627], [-0.9336956699760699], [-1.864312435695396], [0.1777266387972969], [1.1827927457741692], [-1.3218958065332744], [-0.912424429616771], [0.25749379014466767], [-0.10943510605323815], [0.0979594874499259], [2.395253446254205], [1.2146996063131172], [-1.0187806314132655], [-1.4016629578806452], [0.34789656167168787], [2.251672573828938], [-0.056257005154991026], [-0.5561311535985146], [0.44893495337835754], [-1.2740355157248517], [-0.5880380141374629], [0.5552911551748521], [1.204063986133468], [0.5180664845460788], [-1.066640922221688], [0.725461078049243], [0.6722829771509957], [-0.41255028117324716], [0.10859510762957535], [-1.465476678958542], [1.1774749356843441], [0.4010746625699351], [0.7892747991271397], [-0.7582079370118541], [-0.21579130784973255], [-0.35405437018517527], [1.890061487720857], [-1.1357724533894091], [0.4914774340969553], [-1.311260186353625], [-0.24238035829885618], [-0.5827202040476382], [0.012874526012730526], [0.7148254578695936], [0.10327729753975073], [0.6616473569713464], [-1.2899889459943261], [0.05009919664150349], [-0.29555845919710333], [-0.9071066195269463], [-0.3327831298258764], [-1.2368108450960789], [-1.0719587323115125], [0.6829185973306452], [-0.32746531973605164], [0.23622254978536875], [-0.17856663722095947], [0.2734472204141417], [-1.4176163881501196], [0.17240882870747204], [1.0551653036183757], [-0.7635257471016788], [-0.04562138497534157], [-0.3115118894665775], [0.6084692560730991], [-0.19452006749043366], [1.1083434045166227], [-1.4973835394974904], [-0.008396714346568376], [-0.7316188865627304], [-0.226426928029382], [0.36916780203098676], [1.3635982888282097], [1.2519242769418906], [0.5552911551748521], [-0.5135886728799169], [0.039463576461854034], [-1.5824685009346857], [1.2412886567622408], [-1.4920657294076656], [0.25749379014466767], [-0.8805175690778226], [0.8105460394864387], [-0.2902406491072786], [0.1830444488871215], [0.1405019681685237], [-0.5401777233290405], [1.6667134639482184], [0.32130751122256435], [0.044781386551678876], [-0.2902406491072786], [0.9381734816422318], [-2.1195673200069827], [-0.38596123072412364], [0.8052282293966138], [-1.5292904000364387], [0.4329815231088835], [-0.30619407937675275], [-0.47104619216131915], [-0.853928518628699], [-1.220857414826605], [-0.4391393316223708], [0.6776007872408206], [0.2043156892464204], [0.3532143717615125], [-0.35405437018517527], [-0.4391393316223708], [1.8049765262836615], [-0.7635257471016788], [0.09264167736010129], [2.5973302296675445], [-0.17856663722095947], [0.3053540809530901], [-1.4867479193178408], [-0.6199448746764114], [1.124296834786097], [-0.2636515986581551], [0.858406330294861], [-1.8696302457852205], [-0.7475723168322046], [-0.32746531973605164], [0.37980342221063623], [-0.8060682278202764], [-0.4391393316223708], [-1.5771506908448611], [-0.1413419665921864], [-1.7207315632701286], [0.16709101861764744], [-0.09879948587358871], [-0.08284605560411454], [0.039463576461854034], [-1.6090575513838095], [-1.0028272011437913], [2.443113737062628], [-1.3803917175213463], [0.895631000923634], [-0.5401777233290405], [0.002238905833081075], [0.3159897011327395], [-1.0294162515929148], [1.2466064668520658], [0.2255869296057193], [3.565171666015644], [1.8422011969124341], [0.41702809283940917], [-0.5933558242272877], [0.7307788881390677], [0.8052282293966138], [0.6137870661629239], [1.0179406329896026], [-0.3327831298258764], [1.2519242769418906], [-0.43382152153254605], [0.19368006906677096], [-0.45509276189184494], [3.1716537193686145], [0.16709101861764744], [1.2572420870317151], [0.7839569890373149], [-1.0560053020420384], [-1.5292904000364387], [0.09264167736010129], [-0.28492283901745385], [0.9488091018218813], [0.4117102827495846], [0.2840828405937912], [-3.369252691115792], [-0.5401777233290405], [-1.1251368332097598], [0.2947184607734406], [1.124296834786097], [-0.5401777233290405], [0.5074308643664294], [-0.9762381506946676], [-0.09348167578376398], [0.47552400382748106], [0.023510146192379976], [-0.2051556876700831], [-2.183381041084879], [-0.056257005154991026], [-0.300876269286928], [0.5021130542766048], [1.565675072241549], [-0.5135886728799169], [-0.5720845838679888], [0.6191048762527486], [-0.07221043542446508], [-0.35405437018517527], [-0.4976352426104428], [0.21495130942606985], [-0.4976352426104428], [0.6988720276001195], [-1.0187806314132655], [-0.6146270645865866], [-0.5508133435086899], [-0.7954326076406271], [0.05541700673132833], [0.7945926092169643], [-1.4176163881501196], [0.5499733450850272], [-0.7901147975508024], [-0.38596123072412364], [-0.019032334526217828], [0.27876503050396656], [-1.5984219312041599], [1.225335226492767], [0.8849953807439845], [0.342578751581863], [2.5866946094878953], [1.773069665744713], [-0.16793101704131003], [0.05541700673132833], [1.789023096014187], [-0.5986736343171124], [2.5441521287692974], [0.11923072780922479], [-0.42318590135289663], [0.8690419504745105], [-0.7316188865627304], [1.3210558081096118], [-0.8805175690778226], [1.485907920894178], [0.4329815231088835], [-1.4016629578806452], [0.1830444488871215], [-0.8486107085388743], [-0.5933558242272877], [-0.7901147975508024], [-0.42318590135289663], [-0.3912790408139484], [0.459570573558007], [0.7892747991271397], [-1.0347340616827396], [0.8371350899355622], [-0.8432928984490495], [-0.30619407937675275], [-0.8964709993472968], [0.7414145083187171], [0.4861596240071305], [-0.4976352426104428], [-0.9071066195269463], [1.6082175529601468], [-0.06157481524481563], [-3.098044376534731], [-0.10411729596341343], [-0.8964709993472968], [-0.19983787758025837], [-0.3912790408139484], [0.41702809283940917], [1.890061487720857], [-0.8220216580897508], [-2.018528928300313], [-0.06689262533464048], [1.1508858852352206], [0.16709101861764744], [-0.4285037114427213], [-1.0028272011437913], [-0.17324882713113474], [-0.12007072623288761], [0.3638499919411619], [-0.6039914444069372], [-0.4657283820714944], [1.3635982888282097], [-0.4816818123409686], [0.7467323184085419], [-0.6146270645865866], [1.491225730984003], [1.5603572621517243], [-0.2051556876700831], [-0.9762381506946676], [0.7945926092169643], [-0.5880380141374629], [0.3053540809530901], [-0.09879948587358871], [-0.23174473811920673], [-2.2578303823424255], [-0.42318590135289663], [0.5127486744562543], [-0.29555845919710333], [-1.1304546432995846], [1.07111873388785], [0.342578751581863], [-0.05093919506516618], [0.2947184607734406], [-0.6093092544967619], [2.0336423601461244], [-0.8592463287185237], [-0.7688435571915035], [1.358280478738385], [-0.3806434206342989], [-0.6199448746764114], [3.012119416673873], [1.0232584430794271], [-0.7688435571915035], [2.794089202991059], [0.2521759800548428], [-1.220857414826605], [0.6350583065222228], [1.4167763897264567], [-0.09879948587358871], [0.5233842946359037], [1.8581546271819085], [-2.704526429887702], [0.6244226863425734], [-0.7263010764729058], [0.6031514459832744], [0.22026911951589445], [1.3795517190976838], [-1.1517258836588833], [-0.5720845838679888], [-0.8273394681795754], [-0.12007072623288761], [1.4540010603552298], [-0.8007504177304519], [0.47020619373765643], [-0.06689262533464048], [-0.9390134800658945], [1.7943409061040119], [0.002238905833081075], [0.22026911951589445], [0.14581977825834855], [-0.05093919506516618], [0.3744856121208114], [0.27876503050396656], [0.6882364074204701], [-2.832153872043495], [-0.3965968509037731], [1.597581932780497], [-1.3910273377009958], [-0.8645641388083485], [-1.9493973971325915], [0.1139129177194002], [-0.7688435571915035], [1.012622822899778], [1.278513327391014], [-0.4019146609935978], [0.5659267753545015], [-2.358868774049095], [-0.2796050289276291], [-0.28492283901745385], [0.25749379014466767], [-0.13070634641253706], [-0.23174473811920673], [3.001483796494224], [-0.8645641388083485], [1.5922641226906724], [0.8318172798457375], [0.9381734816422318], [1.2412886567622408], [1.8422011969124341], [-0.47636400225114384], [0.40639247265975975], [0.12454853789904964], [1.1508858852352206], [0.32662532131238897], [-0.7422545067423799], [-0.42318590135289663], [-0.23706254820903144], [0.9913515825404791], [-0.7316188865627304], [-1.0347340616827396], [-0.7635257471016788], [-2.6885729996182275], [-0.02435014461604267], [-0.9602847204251934], [-0.6412161150357101], [-1.1198190231199352], [0.4117102827495846], [1.2093817962232927], [-1.885583676054695], [-0.4178680912630719], [0.0979594874499259], [0.9913515825404791], [-1.0879121625809869], [0.6191048762527486], [0.039463576461854034], [-0.3912790408139484], [-0.5082708627900923], [-0.5454955334188651], [0.762685748678016], [-1.1038655928504608], [0.725461078049243], [0.762685748678016], [0.9488091018218813], [1.0498474935285511], [2.20913009311034], [0.8849953807439845], [0.23090473969554393], [-2.757704530785949], [-0.09879948587358871], [-0.019032334526217828], [-1.4867479193178408], [-0.28492283901745385], [-1.843041195336097], [-0.5401777233290405], [0.060734816821152934], [-0.875199758987998], [0.08732386727027644], [0.8743597605643351], [-0.30619407937675275], [-0.32746531973605164], [-0.013714524436393219], [-0.7635257471016788], [-0.986873770874317], [0.007556715922905682], [-0.720983266383081], [1.1083434045166227], [-0.4497749518020202], [-0.9017888094371216], [-0.27428721883780444], [-0.8379750883592249], [-0.9177422397065957], [-0.6837585957543079], [2.6398727103861424], [-1.3644382872518723], [0.6776007872408206], [-1.9068549164139939], [1.1934283659538183], [0.18836225897694633], [2.528198698499823], [-0.7316188865627304], [-0.4869996224307933], [1.2466064668520658], [1.6028997428703222], [-0.08284605560411454], [-0.19983787758025837], [0.08732386727027644], [0.209633499336245], [0.5712445854443261], [0.028827956282204584], [-0.32214750964622696], [-0.875199758987998], [2.129362941762969], [0.9966693926303036], [0.1617732085278226], [-0.7156654562932563], [-1.0187806314132655], [-0.5242242930595664], [-1.2793533258146768], [-0.019032334526217828], [-0.41255028117324716], [-1.066640922221688], [-0.3487365600953506], [0.5765623955341509], [-0.4869996224307933], [0.6191048762527486], [-1.348484856982398], [0.7520501284983665], [-0.6784407856644833], [-1.7526384238090769], [1.3901873392773332], [1.2306530365825916], [0.32662532131238897], [0.7307788881390677], [0.1139129177194002], [1.124296834786097], [-0.2051556876700831], [-0.7263010764729058], [-0.8060682278202764], [-0.6943942159339573], [-0.15729539686166058], [2.3473931554457828], [-0.5295421031493911], [0.18836225897694633], [-1.0347340616827396], [-0.3912790408139484], [0.7945926092169643], [0.5712445854443261], [-0.5774023939578136], [-0.008396714346568376], [-0.45509276189184494], [-0.23174473811920673], [1.3689160989180342], [-0.7316188865627304], [-0.5454955334188651], [-0.056257005154991026], [1.0604831137082005], [0.018192336102555134], [1.0977077843369736], [0.3532143717615125], [0.5340199148155531], [1.709255944666816], [0.34789656167168787], [0.3319431314022136], [0.12986634798887425], [1.0870721641573238], [1.3955051493671577], [0.05541700673132833], [-0.3115118894665775], [0.2255869296057193], [0.5180664845460788], [1.4540010603552298], [-1.6303287917431084], [-1.481430109228016], [0.5340199148155531], [-0.5029530527002675], [1.4965435410738277], [-0.779479177371153], [-1.348484856982398], [0.09264167736010129], [-0.05093919506516618], [-0.5135886728799169], [0.0979594874499259], [-0.28492283901745385], [-0.9602847204251934], [0.6722829771509957], [-1.0081450112336159], [1.1083434045166227], [-0.3381009399157011], [1.1721571255945196], [0.8903131908338094], [-0.6678051654848338], [0.7786391789474902], [-0.7954326076406271], [0.47552400382748106], [0.14581977825834855], [-0.7475723168322046], [0.25749379014466767], [-0.2689694087479798], [0.3106718910429149], [0.0979594874499259], [2.9855303662247494], [-0.7635257471016788], [0.21495130942606985], [-0.6146270645865866], [-0.5242242930595664], [0.002238905833081075], [-1.917490536593643], [0.14581977825834855], [0.007556715922905682], [0.5552911551748521], [-0.9762381506946676], [0.2681294103243171], [-2.369504394228744], [0.14581977825834855], [0.8105460394864387], [0.023510146192379976], [0.6084692560730991], [2.272943814188237], [-0.853928518628699], [-0.5295421031493911], [0.07137043700080238], [-0.5401777233290405], [1.044529683438726], [0.3053540809530901], [0.6031514459832744], [-0.6039914444069372], [0.8264994697559127], [0.08200605718045184], [-0.359372180275], [0.3106718910429149], [-0.019032334526217828], [-0.6784407856644833], [-0.32214750964622696], [-0.5454955334188651], [0.6084692560730991], [-1.5239725899466139], [2.6398727103861424], [0.6722829771509957], [-0.5774023939578136], [0.1405019681685237], [-0.9549669103353686], [-2.470542785935414], [-0.7316188865627304], [-0.779479177371153], [-0.9443312901557194], [-0.986873770874317], [-0.9230600497964204], [-0.9496491002455439], [0.5180664845460788], [-1.2740355157248517], [-0.10411729596341343], [-2.1195673200069827], [-1.348484856982398], [-1.327213616623099], [-1.0985477827606362], [-0.6093092544967619], [-0.8858353791676473], [0.2521759800548428], [1.5869463126008478], [1.1349324549657462], [0.6829185973306452], [0.5127486744562543], [-0.5295421031493911], [0.8637241403846857], [-0.0775282455142898], [-0.19452006749043366], [-0.019032334526217828], [-0.5827202040476382], [2.5866946094878953], [-1.5186547798567889], [-0.3327831298258764], [-1.3910273377009958], [0.1405019681685237], [0.7148254578695936], [-0.25301597847850565], [0.07137043700080238], [-1.0028272011437913], [-0.6571695453051845], [1.5922641226906724], [-0.3912790408139484], [-0.27428721883780444], [0.7839569890373149], [0.4808418139173059], [0.25749379014466767], [-1.348484856982398], [2.2197657132899895], [1.3476448585587353], [2.1240451316731446], [-0.625262684766236], [0.6510117367916969], [-0.28492283901745385], [-0.5401777233290405], [-1.369756097341697], [0.4861596240071305], [-1.0187806314132655], [-1.0613231121318631], [0.35853218185133734], [-0.45509276189184494], [0.2840828405937912], [0.4808418139173059], [0.5499733450850272], [0.4914774340969553], [0.459570573558007], [-0.9549669103353686], [-0.2051556876700831], [-0.1466597766820111], [0.7307788881390677], [-0.06689262533464048], [1.2093817962232927], [1.2572420870317151], [0.4648883836478316], [-2.0398001686596117], [0.17240882870747204], [-0.1838844473107842], [0.5552911551748521], [0.43829933319870806], [0.6191048762527486], [0.1617732085278226], [0.028827956282204584], [0.3532143717615125], [-0.7582079370118541], [-1.0879121625809869], [0.7201432679594184], [-0.662487355395009], [-0.24238035829885618], [1.3051023778401376], [0.23090473969554393], [-1.8324055751564476], [-0.7688435571915035], [-0.6784407856644833], [-1.6622356522820567], [-0.08284605560411454], [-0.12538853632271232], [-1.385709527611171], [-0.6199448746764114], [-0.6305804948560608], [-1.3218958065332744], [2.001735499607176], [-1.7207315632701286], [0.3532143717615125], [-1.843041195336097], [0.22026911951589445], [-2.0770248392883848], [0.15113758834817315], [-0.21579130784973255], [-0.9017888094371216], [1.1508858852352206], [0.34789656167168787], [0.32130751122256435], [0.32662532131238897], [0.7839569890373149], [-0.7316188865627304], [-0.7901147975508024], [-0.45509276189184494], [-0.2796050289276291], [-0.5508133435086899], [-0.34341875000552585], [-1.5877863110245105], [-1.0400518717725642], [-0.25833378856833034], [0.8530885202050364], [1.8741080574513829], [-0.09879948587358871], [-0.06157481524481563], [0.7945926092169643], [0.2840828405937912], [0.43829933319870806], [0.47552400382748106], [0.4648883836478316], [-0.9443312901557194], [0.5765623955341509], [0.1405019681685237], [0.018192336102555134], [-1.7951809045276748], [2.0708670307748975], [1.9272861583496297], [0.41702809283940917], [-0.04562138497534157], [0.6191048762527486], [0.12454853789904964], [-0.1626132069514853], [-0.7422545067423799], [0.8158638495762632], [-0.6039914444069372], [-0.2689694087479798], [0.7573679385881914], [-1.7260493733599533], [-1.0400518717725642], [-0.2104734977599078], [-1.6941425128210048], [-0.6890764058441328], [-0.3115118894665775], [0.4808418139173059], [-0.24238035829885618], [0.08732386727027644], [-0.5242242930595664], [-1.4920657294076656], [-0.6571695453051845], [0.3319431314022136], [0.41702809283940917], [-0.6093092544967619], [-1.864312435695396], [0.5393377249053778], [-0.0030789042567437685], [-1.045369681862389], [0.30003627086326545], [-0.4657283820714944], [-0.7263010764729058], [-0.8432928984490495], [0.6669651670611711], [-0.23706254820903144], [0.08732386727027644], [-0.05093919506516618], [0.2628116002344923], [-0.18920225740060892], [-0.3806434206342989], [0.7680035587678409], [1.73584499511594], [-0.853928518628699], [-0.013714524436393219], [0.8264994697559127], [0.6137870661629239], [-0.2104734977599078], [-0.10943510605323815], [-0.6890764058441328], [-0.6093092544967619], [-0.09348167578376398], [-0.6678051654848338], [-0.9071066195269463], [0.40639247265975975], [0.5606089652646766], [0.2043156892464204], [0.5021130542766048], [-0.6784407856644833], [-0.24238035829885618], [-0.4657283820714944], [-1.9813042576715398], [1.618853173139796], [-1.2527642753655532], [-1.784545284348025], [-0.04562138497534157], [0.12454853789904964], [0.47552400382748106], [-2.183381041084879], [-0.7316188865627304], [0.422345902929234], [-0.8432928984490495], [-0.9230600497964204], [-2.4333181153066414], [-0.4497749518020202], [0.592515825803625], [0.2255869296057193], [-1.045369681862389], [-0.9975093910539665], [-0.1360241565023618], [1.1083434045166227], [0.6829185973306452], [0.8158638495762632], [-0.7688435571915035], [1.5550394520618993], [-0.4072324710834224], [1.810294336373486], [-0.7901147975508024], [0.002238905833081075], [-0.8273394681795754], [0.422345902929234], [-0.38596123072412364], [0.028827956282204584], [0.459570573558007], [-0.2211091179395573], [0.044781386551678876], [-0.4072324710834224], [0.6829185973306452], [-2.3854578244982187], [0.12986634798887425], [0.3106718910429149], [-0.8858353791676473], [-0.7156654562932563], [0.37980342221063623], [0.044781386551678876], [-0.23706254820903144], [0.5818802056239756], [-0.0030789042567437685], [-0.1360241565023618], [-0.019032334526217828], [0.05541700673132833], [-1.88026586596487], [0.044781386551678876], [0.007556715922905682], [-0.04030357488551673], [0.10327729753975073], [0.19368006906677096], [-0.7156654562932563], [0.28940065068361603], [0.6191048762527486], [0.459570573558007], [-0.5295421031493911], [2.8153604433503583], [0.8849953807439845], [2.618601470026843], [-1.5133369697669643], [-0.04030357488551673], [-1.369756097341697], [1.2359708466724162], [1.1349324549657462], [1.1774749356843441], [-0.21579130784973255], [-0.6305804948560608], [-0.16793101704131003], [-0.07221043542446508], [-2.16210980072558], [-0.625262684766236], [-0.8592463287185237], [-0.226426928029382], [0.7414145083187171], [-0.5774023939578136], [1.0977077843369736], [-0.09348167578376398], [-0.32746531973605164], [-0.3327831298258764], [-0.5827202040476382], [0.9488091018218813], [-0.02435014461604267], [0.5233842946359037], [-0.720983266383081], [0.5765623955341509], [-0.4019146609935978], [0.6191048762527486], [2.2144479032001647], [1.0498474935285511], [-0.6358983049458855], [-0.49231743252061805], [0.842452900025387], [-0.28492283901745385], [-0.2104734977599078], [-1.3963451477908206], [-0.04562138497534157], [0.40639247265975975], [-2.0823426493782096], [-0.4604105719816697], [-1.7792274742582004], [0.6935542175102947], [1.985782069337702], [-1.7207315632701286], [-1.2633998955452026], [-0.4285037114427213], [-0.5508133435086899], [0.9966693926303036], [0.05541700673132833], [0.7041898376899441], [0.1777266387972969], [1.1827927457741692], [0.5659267753545015], [0.2043156892464204], [-1.4867479193178408], [-1.0081450112336159], [0.3106718910429149], [-0.928377859886245], [-0.1466597766820111], [-0.28492283901745385], [-0.45509276189184494], [-0.07221043542446508], [0.08732386727027644], [-1.2049039845571305], [0.32130751122256435], [0.5871980157138004], [-0.9230600497964204], [0.3053540809530901], [0.044781386551678876], [-1.0028272011437913], [-0.029667954705867278], [-0.3327831298258764], [-0.45509276189184494], [0.4436171432885329], [0.9222200513727578], [-0.5720845838679888], [-1.8536768155157466], [-0.2689694087479798], [-0.7847969874609776], [0.08732386727027644], [-0.5295421031493911], [-0.9815559607844923], [-0.6146270645865866], [-1.7047781330006544], [1.1296146448759217], [-0.2636515986581551], [-1.1464080735690587], [0.3532143717615125], [-0.5242242930595664], [0.4861596240071305], [0.023510146192379976], [-0.08284605560411454], [-0.8964709993472968], [-1.0187806314132655], [-0.6837585957543079], [-0.720983266383081], [-0.6412161150357101], [-0.7103476462034315], [-0.07221043542446508], [-0.4019146609935978], [-0.3912790408139484], [-0.09879948587358871], [-0.1626132069514853], [-0.6039914444069372], [-0.6305804948560608], [0.5765623955341509], [0.03414576637202943], [-0.24238035829885618], [-2.055753598929086], [-0.12007072623288761], [0.36916780203098676], [-1.6462822220125823], [0.2734472204141417], [-0.6943942159339573], [-0.03498576479569212], [0.4808418139173059], [-0.8326572782694003], [-0.04030357488551673], [0.7999104193067892], [0.7414145083187171], [-1.327213616623099], [0.9062666211032835], [0.42766371301905864], [-0.9709203406048429], [-0.36468999036482475], [0.2043156892464204], [0.42766371301905864], [-0.5189064829697416], [0.060734816821152934], [2.049595790415599], [-0.4072324710834224], [0.6510117367916969], [-0.056257005154991026], [-1.5080191596771397], [1.597581932780497], [2.560105559038772], [1.9006971079005064], [0.12454853789904964], [-0.9815559607844923], [-0.19452006749043366], [-0.6093092544967619], [2.7887713929012348], [-0.4816818123409686], [0.8052282293966138], [0.4808418139173059], [-0.04030357488551673], [-0.24238035829885618], [2.825996063530008], [-1.311260186353625], [-0.35405437018517527], [0.1405019681685237], [0.9381734816422318], [1.2466064668520658], [0.007556715922905682], [-0.1626132069514853], [0.459570573558007], [-1.2899889459943261], [-0.10943510605323815], [0.5446555349952026], [1.2519242769418906], [0.7520501284983665], [1.7198915648464659], [-1.5346082101262633], [0.5712445854443261], [1.0179406329896026], [-0.8698819488981732], [1.54440383188225], [0.2255869296057193], [-0.625262684766236], [-0.9443312901557194], [-0.12007072623288761], [-0.5135886728799169], [0.842452900025387], [-0.0775282455142898], [0.7786391789474902], [-0.7475723168322046], [0.24685816996501822], [-0.29555845919710333], [-0.8964709993472968], [1.124296834786097], [0.09264167736010129], [0.0979594874499259], [0.5021130542766048], [2.129362941762969], [1.0179406329896026], [-1.0028272011437913], [0.6510117367916969], [2.9855303662247494], [-0.6412161150357101], [0.06605262691097755], [-0.6146270645865866], [0.24685816996501822], [-0.23706254820903144], [0.05541700673132833], [0.6776007872408206], [1.225335226492767], [-1.4548410587788925], [-0.5508133435086899], [-0.6358983049458855], [0.2255869296057193], [0.459570573558007], [-0.07221043542446508], [-2.417364685037167], [-0.21579130784973255], [-0.7901147975508024]]
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,901
Moving model to cuda
Epoch 0
Train function
Loss = 1.7395e-02, PNorm = 35.0668, GNorm = 2.7341, lr_0 = 1.2829e-04
Loss = 1.7322e-02, PNorm = 35.0697, GNorm = 1.8803, lr_0 = 1.5400e-04
Loss = 1.1920e-02, PNorm = 35.0743, GNorm = 4.3421, lr_0 = 1.7971e-04
Loss = 8.8196e-03, PNorm = 35.0800, GNorm = 14.0593, lr_0 = 2.0543e-04
Loss = 8.1877e-03, PNorm = 35.0861, GNorm = 6.2230, lr_0 = 2.3114e-04
Loss = 8.2731e-03, PNorm = 35.0934, GNorm = 2.4716, lr_0 = 2.5686e-04
Loss = 6.8798e-03, PNorm = 35.1020, GNorm = 8.6145, lr_0 = 2.8257e-04
Loss = 6.5067e-03, PNorm = 35.1096, GNorm = 1.4723, lr_0 = 3.0829e-04
Loss = 6.7393e-03, PNorm = 35.1182, GNorm = 4.2987, lr_0 = 3.3400e-04
Loss = 5.0334e-03, PNorm = 35.1284, GNorm = 3.4461, lr_0 = 3.5971e-04
Loss = 4.7970e-03, PNorm = 35.1373, GNorm = 2.4831, lr_0 = 3.8543e-04
Loss = 4.3143e-03, PNorm = 35.1492, GNorm = 1.8517, lr_0 = 4.1114e-04
Loss = 3.8728e-03, PNorm = 35.1601, GNorm = 3.2017, lr_0 = 4.3686e-04
Loss = 4.8710e-03, PNorm = 35.1746, GNorm = 5.0076, lr_0 = 4.6257e-04
Loss = 5.6224e-03, PNorm = 35.1906, GNorm = 0.9118, lr_0 = 4.8829e-04
Loss = 4.2623e-03, PNorm = 35.2111, GNorm = 2.1698, lr_0 = 5.1400e-04
Loss = 4.2435e-03, PNorm = 35.2343, GNorm = 3.7633, lr_0 = 5.3971e-04
Validation rmse = 0.995215
Validation R2 = 0.709316
Epoch 1
Train function
Loss = 3.8876e-03, PNorm = 35.2536, GNorm = 2.2584, lr_0 = 5.6800e-04
Loss = 3.5921e-03, PNorm = 35.2706, GNorm = 2.6479, lr_0 = 5.9371e-04
Loss = 3.9314e-03, PNorm = 35.2914, GNorm = 1.1906, lr_0 = 6.1943e-04
Loss = 3.7480e-03, PNorm = 35.3212, GNorm = 1.2441, lr_0 = 6.4514e-04
Loss = 3.5532e-03, PNorm = 35.3464, GNorm = 2.4098, lr_0 = 6.7086e-04
Loss = 3.2962e-03, PNorm = 35.3722, GNorm = 2.6040, lr_0 = 6.9657e-04
Loss = 3.3625e-03, PNorm = 35.3972, GNorm = 2.2935, lr_0 = 7.2229e-04
Loss = 3.0700e-03, PNorm = 35.4312, GNorm = 1.1091, lr_0 = 7.4800e-04
Loss = 2.3535e-03, PNorm = 35.4544, GNorm = 1.2674, lr_0 = 7.7371e-04
Loss = 2.9403e-03, PNorm = 35.4732, GNorm = 1.8968, lr_0 = 7.9943e-04
Loss = 2.6876e-03, PNorm = 35.5002, GNorm = 0.7946, lr_0 = 8.2514e-04
Loss = 3.6169e-03, PNorm = 35.5316, GNorm = 2.3463, lr_0 = 8.5086e-04
Loss = 2.5012e-03, PNorm = 35.5673, GNorm = 5.6140, lr_0 = 8.7657e-04
Loss = 3.1758e-03, PNorm = 35.5902, GNorm = 3.8615, lr_0 = 9.0229e-04
Loss = 3.5125e-03, PNorm = 35.6119, GNorm = 3.9687, lr_0 = 9.2800e-04
Loss = 3.3924e-03, PNorm = 35.6414, GNorm = 5.6920, lr_0 = 9.5371e-04
Loss = 3.1736e-03, PNorm = 35.6682, GNorm = 1.2700, lr_0 = 9.7943e-04
Loss = 2.7601e-03, PNorm = 35.7033, GNorm = 2.0176, lr_0 = 9.9973e-04
Validation rmse = 0.723571
Validation R2 = 0.846344
Epoch 2
Train function
Loss = 2.5622e-03, PNorm = 35.7334, GNorm = 1.4069, lr_0 = 9.9839e-04
Loss = 2.6180e-03, PNorm = 35.7685, GNorm = 1.8410, lr_0 = 9.9705e-04
Loss = 2.3592e-03, PNorm = 35.7997, GNorm = 1.0189, lr_0 = 9.9571e-04
Loss = 2.4091e-03, PNorm = 35.8324, GNorm = 0.8850, lr_0 = 9.9438e-04
Loss = 2.4590e-03, PNorm = 35.8589, GNorm = 1.8692, lr_0 = 9.9304e-04
Loss = 2.3195e-03, PNorm = 35.8857, GNorm = 1.5893, lr_0 = 9.9171e-04
Loss = 2.2650e-03, PNorm = 35.8999, GNorm = 0.6178, lr_0 = 9.9038e-04
Loss = 2.5635e-03, PNorm = 35.9232, GNorm = 0.6235, lr_0 = 9.8905e-04
Loss = 2.3266e-03, PNorm = 35.9493, GNorm = 0.7958, lr_0 = 9.8772e-04
Loss = 2.7112e-03, PNorm = 35.9744, GNorm = 2.4283, lr_0 = 9.8640e-04
Loss = 2.5795e-03, PNorm = 35.9892, GNorm = 1.0621, lr_0 = 9.8508e-04
Loss = 2.3728e-03, PNorm = 36.0229, GNorm = 0.8457, lr_0 = 9.8375e-04
Loss = 2.6220e-03, PNorm = 36.0584, GNorm = 0.9844, lr_0 = 9.8243e-04
Loss = 2.0586e-03, PNorm = 36.0918, GNorm = 0.6321, lr_0 = 9.8112e-04
Loss = 2.4470e-03, PNorm = 36.1167, GNorm = 1.3315, lr_0 = 9.7980e-04
Loss = 2.2778e-03, PNorm = 36.1423, GNorm = 1.4441, lr_0 = 9.7848e-04
Loss = 2.1931e-03, PNorm = 36.1664, GNorm = 2.9623, lr_0 = 9.7717e-04
Validation rmse = 0.654736
Validation R2 = 0.874189
Epoch 3
Train function
Loss = 2.7901e-03, PNorm = 36.1962, GNorm = 2.3369, lr_0 = 9.7573e-04
Loss = 2.2365e-03, PNorm = 36.2213, GNorm = 1.9238, lr_0 = 9.7442e-04
Loss = 1.8684e-03, PNorm = 36.2490, GNorm = 1.3596, lr_0 = 9.7311e-04
Loss = 1.8516e-03, PNorm = 36.2782, GNorm = 0.7401, lr_0 = 9.7181e-04
Loss = 2.0249e-03, PNorm = 36.2961, GNorm = 0.7514, lr_0 = 9.7050e-04
Loss = 2.2848e-03, PNorm = 36.3105, GNorm = 1.5971, lr_0 = 9.6920e-04
Loss = 3.1089e-03, PNorm = 36.3387, GNorm = 2.6978, lr_0 = 9.6790e-04
Loss = 2.5788e-03, PNorm = 36.3688, GNorm = 1.6164, lr_0 = 9.6660e-04
Loss = 2.4753e-03, PNorm = 36.3924, GNorm = 0.7351, lr_0 = 9.6531e-04
Loss = 2.3519e-03, PNorm = 36.4253, GNorm = 1.9318, lr_0 = 9.6401e-04
Loss = 1.7825e-03, PNorm = 36.4560, GNorm = 1.6668, lr_0 = 9.6272e-04
Loss = 2.1124e-03, PNorm = 36.4813, GNorm = 1.2828, lr_0 = 9.6143e-04
Loss = 1.9811e-03, PNorm = 36.5053, GNorm = 0.5501, lr_0 = 9.6014e-04
Loss = 1.5310e-03, PNorm = 36.5325, GNorm = 0.7523, lr_0 = 9.5885e-04
Loss = 1.7001e-03, PNorm = 36.5492, GNorm = 0.8769, lr_0 = 9.5756e-04
Loss = 1.7259e-03, PNorm = 36.5721, GNorm = 1.2521, lr_0 = 9.5628e-04
Loss = 2.1213e-03, PNorm = 36.5922, GNorm = 0.5739, lr_0 = 9.5499e-04
Loss = 1.9535e-03, PNorm = 36.6162, GNorm = 1.2644, lr_0 = 9.5371e-04
Validation rmse = 0.684671
Validation R2 = 0.862421
Epoch 4
Train function
Loss = 1.6359e-03, PNorm = 36.6387, GNorm = 0.8241, lr_0 = 9.5243e-04
Loss = 1.6015e-03, PNorm = 36.6589, GNorm = 0.6252, lr_0 = 9.5115e-04
Loss = 1.5478e-03, PNorm = 36.6874, GNorm = 0.7215, lr_0 = 9.4988e-04
Loss = 1.8852e-03, PNorm = 36.7080, GNorm = 0.6802, lr_0 = 9.4860e-04
Loss = 1.6516e-03, PNorm = 36.7260, GNorm = 0.5054, lr_0 = 9.4733e-04
Loss = 1.4649e-03, PNorm = 36.7397, GNorm = 1.0701, lr_0 = 9.4606e-04
Loss = 1.3880e-03, PNorm = 36.7669, GNorm = 1.3040, lr_0 = 9.4479e-04
Loss = 1.8449e-03, PNorm = 36.7890, GNorm = 0.4276, lr_0 = 9.4352e-04
Loss = 1.5963e-03, PNorm = 36.8134, GNorm = 1.0600, lr_0 = 9.4226e-04
Loss = 1.5120e-03, PNorm = 36.8389, GNorm = 0.6879, lr_0 = 9.4099e-04
Loss = 1.4828e-03, PNorm = 36.8603, GNorm = 0.5095, lr_0 = 9.3973e-04
Loss = 1.1996e-03, PNorm = 36.8811, GNorm = 0.8399, lr_0 = 9.3847e-04
Loss = 1.5445e-03, PNorm = 36.8970, GNorm = 0.9635, lr_0 = 9.3721e-04
Loss = 1.9166e-03, PNorm = 36.9180, GNorm = 0.4236, lr_0 = 9.3595e-04
Loss = 1.5742e-03, PNorm = 36.9416, GNorm = 0.9264, lr_0 = 9.3470e-04
Loss = 1.5664e-03, PNorm = 36.9597, GNorm = 0.8811, lr_0 = 9.3344e-04
Loss = 1.4375e-03, PNorm = 36.9862, GNorm = 0.6779, lr_0 = 9.3219e-04
Validation rmse = 0.570544
Validation R2 = 0.904464
Epoch 5
Train function
Loss = 1.9340e-03, PNorm = 37.0065, GNorm = 1.3739, lr_0 = 9.3094e-04
Loss = 1.2640e-03, PNorm = 37.0274, GNorm = 1.7060, lr_0 = 9.2969e-04
Loss = 1.2612e-03, PNorm = 37.0522, GNorm = 0.9336, lr_0 = 9.2844e-04
Loss = 1.2924e-03, PNorm = 37.0738, GNorm = 0.9427, lr_0 = 9.2720e-04
Loss = 1.6221e-03, PNorm = 37.0964, GNorm = 0.5957, lr_0 = 9.2595e-04
Loss = 1.2143e-03, PNorm = 37.1274, GNorm = 1.0757, lr_0 = 9.2471e-04
Loss = 1.5619e-03, PNorm = 37.1539, GNorm = 0.9830, lr_0 = 9.2347e-04
Loss = 1.0816e-03, PNorm = 37.1601, GNorm = 0.9710, lr_0 = 9.2223e-04
Loss = 1.3317e-03, PNorm = 37.1777, GNorm = 0.6404, lr_0 = 9.2099e-04
Loss = 1.4032e-03, PNorm = 37.1982, GNorm = 0.5901, lr_0 = 9.1976e-04
Loss = 1.6320e-03, PNorm = 37.2253, GNorm = 3.0718, lr_0 = 9.1852e-04
Loss = 1.8459e-03, PNorm = 37.2466, GNorm = 0.9158, lr_0 = 9.1729e-04
Loss = 1.6529e-03, PNorm = 37.2645, GNorm = 1.7810, lr_0 = 9.1606e-04
Loss = 1.7582e-03, PNorm = 37.2887, GNorm = 1.9407, lr_0 = 9.1483e-04
Loss = 1.6337e-03, PNorm = 37.3149, GNorm = 0.6059, lr_0 = 9.1360e-04
Loss = 1.6786e-03, PNorm = 37.3410, GNorm = 0.6810, lr_0 = 9.1238e-04
Loss = 1.5518e-03, PNorm = 37.3626, GNorm = 0.8943, lr_0 = 9.1115e-04
Loss = 1.6128e-03, PNorm = 37.3889, GNorm = 0.3320, lr_0 = 9.0993e-04
Validation rmse = 0.550717
Validation R2 = 0.910989
Epoch 6
Train function
Loss = 1.1601e-03, PNorm = 37.4181, GNorm = 0.3503, lr_0 = 9.0859e-04
Loss = 1.2074e-03, PNorm = 37.4383, GNorm = 0.6089, lr_0 = 9.0737e-04
Loss = 9.9274e-04, PNorm = 37.4528, GNorm = 0.5022, lr_0 = 9.0615e-04
Loss = 1.4914e-03, PNorm = 37.4752, GNorm = 1.3709, lr_0 = 9.0494e-04
Loss = 1.1988e-03, PNorm = 37.5033, GNorm = 1.2267, lr_0 = 9.0372e-04
Loss = 1.3089e-03, PNorm = 37.5330, GNorm = 0.6873, lr_0 = 9.0251e-04
Loss = 1.5387e-03, PNorm = 37.5565, GNorm = 1.9124, lr_0 = 9.0130e-04
Loss = 1.2340e-03, PNorm = 37.5740, GNorm = 0.3922, lr_0 = 9.0009e-04
Loss = 1.1725e-03, PNorm = 37.5958, GNorm = 1.0597, lr_0 = 8.9888e-04
Loss = 1.2613e-03, PNorm = 37.6156, GNorm = 0.9916, lr_0 = 8.9768e-04
Loss = 1.2512e-03, PNorm = 37.6398, GNorm = 0.8151, lr_0 = 8.9647e-04
Loss = 1.3178e-03, PNorm = 37.6599, GNorm = 0.8638, lr_0 = 8.9527e-04
Loss = 1.1165e-03, PNorm = 37.6852, GNorm = 1.4288, lr_0 = 8.9407e-04
Loss = 1.4044e-03, PNorm = 37.7058, GNorm = 0.7364, lr_0 = 8.9287e-04
Loss = 1.0634e-03, PNorm = 37.7329, GNorm = 0.5946, lr_0 = 8.9167e-04
Loss = 1.4740e-03, PNorm = 37.7501, GNorm = 0.5819, lr_0 = 8.9047e-04
Loss = 1.3264e-03, PNorm = 37.7712, GNorm = 0.6449, lr_0 = 8.8928e-04
Validation rmse = 0.552967
Validation R2 = 0.910260
Epoch 7
Train function
Loss = 1.1776e-03, PNorm = 37.7858, GNorm = 0.7302, lr_0 = 8.8809e-04
Loss = 9.2756e-04, PNorm = 37.8013, GNorm = 0.5909, lr_0 = 8.8689e-04
Loss = 1.1942e-03, PNorm = 37.8240, GNorm = 0.5709, lr_0 = 8.8570e-04
Loss = 1.1540e-03, PNorm = 37.8558, GNorm = 0.5053, lr_0 = 8.8452e-04
Loss = 1.2247e-03, PNorm = 37.8811, GNorm = 0.8812, lr_0 = 8.8333e-04
Loss = 1.3370e-03, PNorm = 37.9044, GNorm = 0.8322, lr_0 = 8.8214e-04
Loss = 1.2816e-03, PNorm = 37.9259, GNorm = 0.3286, lr_0 = 8.8096e-04
Loss = 9.5771e-04, PNorm = 37.9512, GNorm = 1.6374, lr_0 = 8.7978e-04
Loss = 1.2130e-03, PNorm = 37.9760, GNorm = 0.9299, lr_0 = 8.7860e-04
Loss = 9.4688e-04, PNorm = 37.9926, GNorm = 0.6256, lr_0 = 8.7742e-04
Loss = 1.3725e-03, PNorm = 38.0107, GNorm = 0.5672, lr_0 = 8.7624e-04
Loss = 1.2246e-03, PNorm = 38.0254, GNorm = 0.5259, lr_0 = 8.7507e-04
Loss = 1.4377e-03, PNorm = 38.0456, GNorm = 1.3806, lr_0 = 8.7389e-04
Loss = 1.2404e-03, PNorm = 38.0753, GNorm = 0.6791, lr_0 = 8.7272e-04
Loss = 1.1106e-03, PNorm = 38.0971, GNorm = 0.7614, lr_0 = 8.7155e-04
Loss = 1.0318e-03, PNorm = 38.1177, GNorm = 0.5475, lr_0 = 8.7038e-04
Loss = 1.2433e-03, PNorm = 38.1375, GNorm = 1.4389, lr_0 = 8.6921e-04
Loss = 1.1020e-03, PNorm = 38.1624, GNorm = 0.3346, lr_0 = 8.6805e-04
Validation rmse = 0.526533
Validation R2 = 0.918635
Epoch 8
Train function
Loss = 1.1453e-03, PNorm = 38.1829, GNorm = 0.9391, lr_0 = 8.6688e-04
Loss = 1.1463e-03, PNorm = 38.2009, GNorm = 0.9118, lr_0 = 8.6572e-04
Loss = 9.8709e-04, PNorm = 38.2286, GNorm = 1.2153, lr_0 = 8.6456e-04
Loss = 1.2984e-03, PNorm = 38.2594, GNorm = 0.4961, lr_0 = 8.6340e-04
Loss = 1.2053e-03, PNorm = 38.2861, GNorm = 1.7065, lr_0 = 8.6224e-04
Loss = 1.1059e-03, PNorm = 38.2998, GNorm = 0.7600, lr_0 = 8.6108e-04
Loss = 1.3661e-03, PNorm = 38.3200, GNorm = 2.4711, lr_0 = 8.5993e-04
Loss = 1.2526e-03, PNorm = 38.3521, GNorm = 0.8026, lr_0 = 8.5877e-04
Loss = 1.0742e-03, PNorm = 38.3709, GNorm = 0.9034, lr_0 = 8.5762e-04
Loss = 1.0052e-03, PNorm = 38.3931, GNorm = 0.6943, lr_0 = 8.5647e-04
Loss = 8.8814e-04, PNorm = 38.4089, GNorm = 0.4728, lr_0 = 8.5532e-04
Loss = 1.0782e-03, PNorm = 38.4245, GNorm = 0.4065, lr_0 = 8.5417e-04
Loss = 8.7892e-04, PNorm = 38.4399, GNorm = 0.6560, lr_0 = 8.5303e-04
Loss = 7.4972e-04, PNorm = 38.4530, GNorm = 0.3917, lr_0 = 8.5188e-04
Loss = 9.1852e-04, PNorm = 38.4712, GNorm = 0.7393, lr_0 = 8.5074e-04
Loss = 1.0093e-03, PNorm = 38.4940, GNorm = 0.6981, lr_0 = 8.4960e-04
Loss = 9.9824e-04, PNorm = 38.5108, GNorm = 0.7179, lr_0 = 8.4846e-04
Loss = 1.0295e-03, PNorm = 38.5315, GNorm = 0.9722, lr_0 = 8.4732e-04
Loss = 1.8238e-03, PNorm = 38.5329, GNorm = 0.9363, lr_0 = 8.4720e-04
Validation rmse = 0.540418
Validation R2 = 0.914287
Epoch 9
Train function
Loss = 8.1274e-04, PNorm = 38.5451, GNorm = 0.4113, lr_0 = 8.4607e-04
Loss = 8.6318e-04, PNorm = 38.5653, GNorm = 1.3559, lr_0 = 8.4493e-04
Loss = 8.7772e-04, PNorm = 38.5866, GNorm = 0.6443, lr_0 = 8.4380e-04
Loss = 8.9822e-04, PNorm = 38.6096, GNorm = 0.8143, lr_0 = 8.4267e-04
Loss = 8.3111e-04, PNorm = 38.6363, GNorm = 1.0137, lr_0 = 8.4154e-04
Loss = 8.4511e-04, PNorm = 38.6556, GNorm = 0.5095, lr_0 = 8.4041e-04
Loss = 9.1575e-04, PNorm = 38.6824, GNorm = 0.3451, lr_0 = 8.3928e-04
Loss = 1.0202e-03, PNorm = 38.7042, GNorm = 0.8687, lr_0 = 8.3815e-04
Loss = 9.7748e-04, PNorm = 38.7221, GNorm = 0.9746, lr_0 = 8.3703e-04
Loss = 7.6346e-04, PNorm = 38.7419, GNorm = 0.7732, lr_0 = 8.3591e-04
Loss = 1.1037e-03, PNorm = 38.7544, GNorm = 0.4130, lr_0 = 8.3478e-04
Loss = 9.2130e-04, PNorm = 38.7774, GNorm = 0.9084, lr_0 = 8.3366e-04
Loss = 1.0038e-03, PNorm = 38.8053, GNorm = 0.4734, lr_0 = 8.3255e-04
Loss = 9.3822e-04, PNorm = 38.8222, GNorm = 1.2687, lr_0 = 8.3143e-04
Loss = 1.0798e-03, PNorm = 38.8549, GNorm = 0.5226, lr_0 = 8.3031e-04
Loss = 1.0042e-03, PNorm = 38.8727, GNorm = 0.9283, lr_0 = 8.2920e-04
Loss = 1.2967e-03, PNorm = 38.8900, GNorm = 1.8189, lr_0 = 8.2809e-04
Validation rmse = 0.512518
Validation R2 = 0.922909
Epoch 10
Train function
Loss = 1.0269e-03, PNorm = 38.9042, GNorm = 1.1015, lr_0 = 8.2698e-04
Loss = 9.2908e-04, PNorm = 38.9210, GNorm = 0.6919, lr_0 = 8.2587e-04
Loss = 8.0963e-04, PNorm = 38.9423, GNorm = 0.8802, lr_0 = 8.2476e-04
Loss = 8.4411e-04, PNorm = 38.9709, GNorm = 1.5990, lr_0 = 8.2365e-04
Loss = 8.7425e-04, PNorm = 38.9940, GNorm = 1.0957, lr_0 = 8.2255e-04
Loss = 1.0848e-03, PNorm = 39.0206, GNorm = 1.3010, lr_0 = 8.2144e-04
Loss = 1.2327e-03, PNorm = 39.0481, GNorm = 1.1334, lr_0 = 8.2034e-04
Loss = 8.9340e-04, PNorm = 39.0774, GNorm = 1.3919, lr_0 = 8.1924e-04
Loss = 9.2977e-04, PNorm = 39.0994, GNorm = 1.0330, lr_0 = 8.1814e-04
Loss = 8.7650e-04, PNorm = 39.1181, GNorm = 0.3836, lr_0 = 8.1704e-04
Loss = 9.9913e-04, PNorm = 39.1321, GNorm = 1.5036, lr_0 = 8.1595e-04
Loss = 6.6991e-04, PNorm = 39.1473, GNorm = 0.7332, lr_0 = 8.1485e-04
Loss = 9.5647e-04, PNorm = 39.1701, GNorm = 0.4096, lr_0 = 8.1376e-04
Loss = 9.5034e-04, PNorm = 39.1820, GNorm = 1.1724, lr_0 = 8.1267e-04
Loss = 8.7977e-04, PNorm = 39.1998, GNorm = 0.5402, lr_0 = 8.1158e-04
Loss = 9.1125e-04, PNorm = 39.2242, GNorm = 0.8482, lr_0 = 8.1049e-04
Loss = 7.7600e-04, PNorm = 39.2458, GNorm = 0.3390, lr_0 = 8.0940e-04
Loss = 8.2512e-04, PNorm = 39.2665, GNorm = 0.4265, lr_0 = 8.0831e-04
Validation rmse = 0.510471
Validation R2 = 0.923523
Epoch 11
Train function
Loss = 9.0482e-04, PNorm = 39.2895, GNorm = 1.3643, lr_0 = 8.0723e-04
Loss = 8.3444e-04, PNorm = 39.3020, GNorm = 1.0315, lr_0 = 8.0615e-04
Loss = 8.4803e-04, PNorm = 39.3238, GNorm = 0.7648, lr_0 = 8.0506e-04
Loss = 7.5796e-04, PNorm = 39.3397, GNorm = 0.8084, lr_0 = 8.0398e-04
Loss = 7.6705e-04, PNorm = 39.3528, GNorm = 0.6221, lr_0 = 8.0291e-04
Loss = 8.4451e-04, PNorm = 39.3817, GNorm = 0.3918, lr_0 = 8.0183e-04
Loss = 9.3669e-04, PNorm = 39.4110, GNorm = 0.3790, lr_0 = 8.0075e-04
Loss = 5.5270e-04, PNorm = 39.4268, GNorm = 0.3404, lr_0 = 7.9968e-04
Loss = 6.1304e-04, PNorm = 39.4315, GNorm = 0.4479, lr_0 = 7.9861e-04
Loss = 9.4609e-04, PNorm = 39.4542, GNorm = 0.6045, lr_0 = 7.9753e-04
Loss = 9.1921e-04, PNorm = 39.4805, GNorm = 0.7171, lr_0 = 7.9646e-04
Loss = 7.9386e-04, PNorm = 39.5011, GNorm = 0.8392, lr_0 = 7.9540e-04
Loss = 7.0244e-04, PNorm = 39.5113, GNorm = 0.5452, lr_0 = 7.9433e-04
Loss = 8.0123e-04, PNorm = 39.5319, GNorm = 1.3591, lr_0 = 7.9326e-04
Loss = 8.5179e-04, PNorm = 39.5520, GNorm = 0.7474, lr_0 = 7.9220e-04
Loss = 7.3601e-04, PNorm = 39.5759, GNorm = 0.3332, lr_0 = 7.9114e-04
Loss = 8.2477e-04, PNorm = 39.5829, GNorm = 0.5198, lr_0 = 7.9007e-04
Validation rmse = 0.523361
Validation R2 = 0.919612
Epoch 12
Train function
Loss = 8.0136e-04, PNorm = 39.5944, GNorm = 1.0507, lr_0 = 7.8891e-04
Loss = 8.2783e-04, PNorm = 39.6237, GNorm = 0.5892, lr_0 = 7.8785e-04
Loss = 6.7890e-04, PNorm = 39.6497, GNorm = 0.5851, lr_0 = 7.8679e-04
Loss = 8.8843e-04, PNorm = 39.6702, GNorm = 0.6258, lr_0 = 7.8574e-04
Loss = 8.6629e-04, PNorm = 39.6869, GNorm = 0.3916, lr_0 = 7.8468e-04
Loss = 6.2749e-04, PNorm = 39.7078, GNorm = 0.3667, lr_0 = 7.8363e-04
Loss = 6.1707e-04, PNorm = 39.7268, GNorm = 0.4038, lr_0 = 7.8258e-04
Loss = 7.7180e-04, PNorm = 39.7400, GNorm = 0.7972, lr_0 = 7.8153e-04
Loss = 9.4560e-04, PNorm = 39.7605, GNorm = 0.6691, lr_0 = 7.8048e-04
Loss = 7.2809e-04, PNorm = 39.7799, GNorm = 1.1783, lr_0 = 7.7943e-04
Loss = 7.8058e-04, PNorm = 39.8037, GNorm = 0.3965, lr_0 = 7.7839e-04
Loss = 6.7009e-04, PNorm = 39.8213, GNorm = 0.5176, lr_0 = 7.7734e-04
Loss = 7.6616e-04, PNorm = 39.8371, GNorm = 0.5326, lr_0 = 7.7630e-04
Loss = 7.2780e-04, PNorm = 39.8602, GNorm = 0.6118, lr_0 = 7.7526e-04
Loss = 7.3666e-04, PNorm = 39.8781, GNorm = 0.3983, lr_0 = 7.7422e-04
Loss = 6.6500e-04, PNorm = 39.8968, GNorm = 1.3105, lr_0 = 7.7318e-04
Loss = 7.0216e-04, PNorm = 39.9164, GNorm = 0.6466, lr_0 = 7.7214e-04
Loss = 6.5146e-04, PNorm = 39.9319, GNorm = 0.4132, lr_0 = 7.7111e-04
Validation rmse = 0.494288
Validation R2 = 0.928295
Epoch 13
Train function
Loss = 7.6148e-04, PNorm = 39.9453, GNorm = 0.7913, lr_0 = 7.7007e-04
Loss = 6.4009e-04, PNorm = 39.9684, GNorm = 0.8638, lr_0 = 7.6904e-04
Loss = 6.0621e-04, PNorm = 39.9862, GNorm = 0.6418, lr_0 = 7.6801e-04
Loss = 5.5230e-04, PNorm = 40.0011, GNorm = 0.3963, lr_0 = 7.6698e-04
Loss = 6.3971e-04, PNorm = 40.0134, GNorm = 0.7100, lr_0 = 7.6595e-04
Loss = 6.4926e-04, PNorm = 40.0317, GNorm = 0.6215, lr_0 = 7.6492e-04
Loss = 7.7133e-04, PNorm = 40.0500, GNorm = 0.5579, lr_0 = 7.6389e-04
Loss = 6.7821e-04, PNorm = 40.0681, GNorm = 1.0820, lr_0 = 7.6287e-04
Loss = 5.5949e-04, PNorm = 40.0845, GNorm = 0.6090, lr_0 = 7.6184e-04
Loss = 6.3837e-04, PNorm = 40.1004, GNorm = 0.5758, lr_0 = 7.6082e-04
Loss = 5.5698e-04, PNorm = 40.1181, GNorm = 0.4322, lr_0 = 7.5980e-04
Loss = 6.1983e-04, PNorm = 40.1342, GNorm = 0.8660, lr_0 = 7.5878e-04
Loss = 6.8746e-04, PNorm = 40.1493, GNorm = 0.3652, lr_0 = 7.5776e-04
Loss = 5.8017e-04, PNorm = 40.1613, GNorm = 0.7979, lr_0 = 7.5675e-04
Loss = 5.9809e-04, PNorm = 40.1809, GNorm = 0.7537, lr_0 = 7.5573e-04
Loss = 7.0794e-04, PNorm = 40.1989, GNorm = 1.1023, lr_0 = 7.5472e-04
Loss = 7.6651e-04, PNorm = 40.2179, GNorm = 0.5042, lr_0 = 7.5370e-04
Validation rmse = 0.487284
Validation R2 = 0.930313
Epoch 14
Train function
Loss = 4.4844e-04, PNorm = 40.2360, GNorm = 0.3687, lr_0 = 7.5259e-04
Loss = 6.6501e-04, PNorm = 40.2600, GNorm = 0.6148, lr_0 = 7.5158e-04
Loss = 7.1710e-04, PNorm = 40.2753, GNorm = 0.8791, lr_0 = 7.5057e-04
Loss = 6.7051e-04, PNorm = 40.2935, GNorm = 0.5344, lr_0 = 7.4957e-04
Loss = 6.2862e-04, PNorm = 40.3154, GNorm = 0.9172, lr_0 = 7.4856e-04
Loss = 6.8874e-04, PNorm = 40.3417, GNorm = 0.3379, lr_0 = 7.4756e-04
Loss = 7.2947e-04, PNorm = 40.3664, GNorm = 1.1789, lr_0 = 7.4655e-04
Loss = 6.8775e-04, PNorm = 40.3797, GNorm = 0.4343, lr_0 = 7.4555e-04
Loss = 6.5782e-04, PNorm = 40.3953, GNorm = 0.4437, lr_0 = 7.4455e-04
Loss = 5.8522e-04, PNorm = 40.4138, GNorm = 0.2523, lr_0 = 7.4355e-04
Loss = 6.6653e-04, PNorm = 40.4277, GNorm = 0.6216, lr_0 = 7.4256e-04
Loss = 5.2775e-04, PNorm = 40.4370, GNorm = 0.8714, lr_0 = 7.4156e-04
Loss = 5.2309e-04, PNorm = 40.4580, GNorm = 0.6393, lr_0 = 7.4056e-04
Loss = 5.1690e-04, PNorm = 40.4721, GNorm = 0.8197, lr_0 = 7.3957e-04
Loss = 5.5710e-04, PNorm = 40.4890, GNorm = 0.9580, lr_0 = 7.3858e-04
Loss = 6.3245e-04, PNorm = 40.5067, GNorm = 0.9976, lr_0 = 7.3759e-04
Loss = 6.5837e-04, PNorm = 40.5311, GNorm = 0.5765, lr_0 = 7.3660e-04
Loss = 9.0782e-04, PNorm = 40.5402, GNorm = 1.4965, lr_0 = 7.3561e-04
Validation rmse = 0.497273
Validation R2 = 0.927427
Epoch 15
Train function
Loss = 6.0429e-04, PNorm = 40.5626, GNorm = 0.3856, lr_0 = 7.3462e-04
Loss = 5.0110e-04, PNorm = 40.5844, GNorm = 0.8263, lr_0 = 7.3364e-04
Loss = 5.4856e-04, PNorm = 40.6062, GNorm = 0.3681, lr_0 = 7.3265e-04
Loss = 5.1980e-04, PNorm = 40.6311, GNorm = 0.3500, lr_0 = 7.3167e-04
Loss = 4.4572e-04, PNorm = 40.6484, GNorm = 0.8201, lr_0 = 7.3069e-04
Loss = 6.2451e-04, PNorm = 40.6574, GNorm = 0.3936, lr_0 = 7.2971e-04
Loss = 5.6430e-04, PNorm = 40.6755, GNorm = 0.9937, lr_0 = 7.2873e-04
Loss = 6.0451e-04, PNorm = 40.6923, GNorm = 0.3802, lr_0 = 7.2775e-04
Loss = 5.5221e-04, PNorm = 40.6977, GNorm = 0.7202, lr_0 = 7.2677e-04
Loss = 5.0475e-04, PNorm = 40.7058, GNorm = 0.5248, lr_0 = 7.2580e-04
Loss = 5.9603e-04, PNorm = 40.7243, GNorm = 0.5811, lr_0 = 7.2483e-04
Loss = 5.6594e-04, PNorm = 40.7422, GNorm = 0.4715, lr_0 = 7.2385e-04
Loss = 5.8548e-04, PNorm = 40.7565, GNorm = 0.5580, lr_0 = 7.2288e-04
Loss = 8.1447e-04, PNorm = 40.7656, GNorm = 0.4168, lr_0 = 7.2191e-04
Loss = 7.5150e-04, PNorm = 40.7786, GNorm = 0.5979, lr_0 = 7.2094e-04
Loss = 6.7586e-04, PNorm = 40.8030, GNorm = 0.6215, lr_0 = 7.1998e-04
Loss = 6.2194e-04, PNorm = 40.8240, GNorm = 0.9441, lr_0 = 7.1901e-04
Loss = 5.4901e-04, PNorm = 40.8422, GNorm = 0.4915, lr_0 = 7.1804e-04
Validation rmse = 0.501378
Validation R2 = 0.926224
Epoch 16
Train function
Loss = 5.9862e-04, PNorm = 40.8639, GNorm = 0.7016, lr_0 = 7.1708e-04
Loss = 4.8366e-04, PNorm = 40.8820, GNorm = 0.3340, lr_0 = 7.1612e-04
Loss = 4.2733e-04, PNorm = 40.9029, GNorm = 0.3267, lr_0 = 7.1516e-04
Loss = 4.8786e-04, PNorm = 40.9204, GNorm = 0.5437, lr_0 = 7.1420e-04
Loss = 4.9096e-04, PNorm = 40.9340, GNorm = 0.5579, lr_0 = 7.1324e-04
Loss = 4.3570e-04, PNorm = 40.9442, GNorm = 0.6921, lr_0 = 7.1228e-04
Loss = 5.5874e-04, PNorm = 40.9606, GNorm = 0.3467, lr_0 = 7.1133e-04
Loss = 6.2286e-04, PNorm = 40.9789, GNorm = 0.8662, lr_0 = 7.1037e-04
Loss = 5.7304e-04, PNorm = 40.9929, GNorm = 0.3676, lr_0 = 7.0942e-04
Loss = 6.5921e-04, PNorm = 41.0115, GNorm = 1.1190, lr_0 = 7.0847e-04
Loss = 5.9909e-04, PNorm = 41.0259, GNorm = 0.7092, lr_0 = 7.0752e-04
Loss = 5.8669e-04, PNorm = 41.0439, GNorm = 0.3456, lr_0 = 7.0657e-04
Loss = 5.9351e-04, PNorm = 41.0623, GNorm = 0.7736, lr_0 = 7.0562e-04
Loss = 6.3424e-04, PNorm = 41.0809, GNorm = 1.2874, lr_0 = 7.0467e-04
Loss = 6.4313e-04, PNorm = 41.0986, GNorm = 1.0298, lr_0 = 7.0373e-04
Loss = 4.6083e-04, PNorm = 41.1106, GNorm = 0.3898, lr_0 = 7.0278e-04
Loss = 6.7457e-04, PNorm = 41.1242, GNorm = 0.8177, lr_0 = 7.0184e-04
Validation rmse = 0.479841
Validation R2 = 0.932426
Epoch 17
Train function
Loss = 4.1728e-04, PNorm = 41.1420, GNorm = 0.4131, lr_0 = 7.0081e-04
Loss = 5.2956e-04, PNorm = 41.1586, GNorm = 0.4807, lr_0 = 6.9987e-04
Loss = 5.2026e-04, PNorm = 41.1740, GNorm = 0.4237, lr_0 = 6.9893e-04
Loss = 5.2971e-04, PNorm = 41.1961, GNorm = 0.8843, lr_0 = 6.9799e-04
Loss = 5.2554e-04, PNorm = 41.2151, GNorm = 0.5743, lr_0 = 6.9705e-04
Loss = 6.7476e-04, PNorm = 41.2277, GNorm = 0.6286, lr_0 = 6.9612e-04
Loss = 5.9119e-04, PNorm = 41.2474, GNorm = 0.7241, lr_0 = 6.9518e-04
Loss = 4.8752e-04, PNorm = 41.2653, GNorm = 0.3627, lr_0 = 6.9425e-04
Loss = 5.2492e-04, PNorm = 41.2828, GNorm = 0.3786, lr_0 = 6.9332e-04
Loss = 5.5979e-04, PNorm = 41.2935, GNorm = 0.9508, lr_0 = 6.9239e-04
Loss = 4.0994e-04, PNorm = 41.3122, GNorm = 0.4015, lr_0 = 6.9146e-04
Loss = 4.0302e-04, PNorm = 41.3234, GNorm = 0.5162, lr_0 = 6.9053e-04
Loss = 4.0974e-04, PNorm = 41.3411, GNorm = 0.3170, lr_0 = 6.8961e-04
Loss = 5.5159e-04, PNorm = 41.3567, GNorm = 0.6506, lr_0 = 6.8868e-04
Loss = 4.4872e-04, PNorm = 41.3702, GNorm = 0.8467, lr_0 = 6.8776e-04
Loss = 4.6572e-04, PNorm = 41.3817, GNorm = 0.3549, lr_0 = 6.8683e-04
Loss = 5.4681e-04, PNorm = 41.3950, GNorm = 1.4265, lr_0 = 6.8591e-04
Loss = 6.7254e-04, PNorm = 41.4119, GNorm = 1.0755, lr_0 = 6.8499e-04
Validation rmse = 0.491055
Validation R2 = 0.929230
Epoch 18
Train function
Loss = 4.7424e-04, PNorm = 41.4272, GNorm = 0.3072, lr_0 = 6.8407e-04
Loss = 4.6993e-04, PNorm = 41.4446, GNorm = 0.7363, lr_0 = 6.8315e-04
Loss = 5.3987e-04, PNorm = 41.4546, GNorm = 0.3051, lr_0 = 6.8224e-04
Loss = 4.0182e-04, PNorm = 41.4785, GNorm = 0.3802, lr_0 = 6.8132e-04
Loss = 3.9665e-04, PNorm = 41.4947, GNorm = 0.4614, lr_0 = 6.8041e-04
Loss = 3.7033e-04, PNorm = 41.5084, GNorm = 0.5882, lr_0 = 6.7950e-04
Loss = 4.0297e-04, PNorm = 41.5174, GNorm = 0.3088, lr_0 = 6.7858e-04
Loss = 4.0335e-04, PNorm = 41.5258, GNorm = 0.3452, lr_0 = 6.7767e-04
Loss = 3.7583e-04, PNorm = 41.5420, GNorm = 0.3890, lr_0 = 6.7676e-04
Loss = 5.6013e-04, PNorm = 41.5549, GNorm = 1.3951, lr_0 = 6.7586e-04
Loss = 4.8485e-04, PNorm = 41.5717, GNorm = 1.1504, lr_0 = 6.7495e-04
Loss = 6.4779e-04, PNorm = 41.5865, GNorm = 0.9110, lr_0 = 6.7404e-04
Loss = 6.1255e-04, PNorm = 41.6096, GNorm = 0.4135, lr_0 = 6.7314e-04
Loss = 7.8579e-04, PNorm = 41.6304, GNorm = 0.2644, lr_0 = 6.7224e-04
Loss = 7.1230e-04, PNorm = 41.6574, GNorm = 0.8936, lr_0 = 6.7133e-04
Loss = 4.8945e-04, PNorm = 41.6768, GNorm = 0.6471, lr_0 = 6.7043e-04
Loss = 4.4992e-04, PNorm = 41.6941, GNorm = 0.7218, lr_0 = 6.6953e-04
Validation rmse = 0.488289
Validation R2 = 0.930025
Epoch 19
Train function
Loss = 4.2014e-04, PNorm = 41.7023, GNorm = 0.3733, lr_0 = 6.6864e-04
Loss = 4.3517e-04, PNorm = 41.7221, GNorm = 0.3788, lr_0 = 6.6774e-04
Loss = 4.2978e-04, PNorm = 41.7321, GNorm = 0.8907, lr_0 = 6.6684e-04
Loss = 5.4946e-04, PNorm = 41.7552, GNorm = 0.4004, lr_0 = 6.6595e-04
Loss = 5.4018e-04, PNorm = 41.7697, GNorm = 0.7045, lr_0 = 6.6505e-04
Loss = 5.5537e-04, PNorm = 41.7853, GNorm = 1.0545, lr_0 = 6.6416e-04
Loss = 4.3046e-04, PNorm = 41.8065, GNorm = 0.9365, lr_0 = 6.6327e-04
Loss = 3.3812e-04, PNorm = 41.8142, GNorm = 0.5841, lr_0 = 6.6238e-04
Loss = 4.1704e-04, PNorm = 41.8304, GNorm = 0.5679, lr_0 = 6.6149e-04
Loss = 4.8312e-04, PNorm = 41.8468, GNorm = 0.5016, lr_0 = 6.6060e-04
Loss = 3.8756e-04, PNorm = 41.8645, GNorm = 0.3807, lr_0 = 6.5972e-04
Loss = 3.9230e-04, PNorm = 41.8774, GNorm = 0.3746, lr_0 = 6.5883e-04
Loss = 3.3596e-04, PNorm = 41.8881, GNorm = 0.2133, lr_0 = 6.5795e-04
Loss = 3.4717e-04, PNorm = 41.8986, GNorm = 0.6172, lr_0 = 6.5707e-04
Loss = 4.3853e-04, PNorm = 41.9115, GNorm = 0.5487, lr_0 = 6.5618e-04
Loss = 3.6155e-04, PNorm = 41.9256, GNorm = 0.3629, lr_0 = 6.5530e-04
Loss = 4.8771e-04, PNorm = 41.9339, GNorm = 0.4622, lr_0 = 6.5443e-04
Loss = 4.4181e-04, PNorm = 41.9440, GNorm = 0.7307, lr_0 = 6.5355e-04
Validation rmse = 0.478161
Validation R2 = 0.932898
Epoch 20
Train function
Loss = 3.9631e-04, PNorm = 41.9649, GNorm = 0.3902, lr_0 = 6.5258e-04
Loss = 2.9959e-04, PNorm = 41.9803, GNorm = 0.4144, lr_0 = 6.5171e-04
Loss = 3.3849e-04, PNorm = 41.9911, GNorm = 0.3451, lr_0 = 6.5083e-04
Loss = 2.7284e-04, PNorm = 41.9956, GNorm = 0.2091, lr_0 = 6.4996e-04
Loss = 4.2730e-04, PNorm = 42.0080, GNorm = 0.2828, lr_0 = 6.4909e-04
Loss = 3.7790e-04, PNorm = 42.0190, GNorm = 0.8847, lr_0 = 6.4822e-04
Loss = 3.1292e-04, PNorm = 42.0341, GNorm = 0.2642, lr_0 = 6.4735e-04
Loss = 3.8960e-04, PNorm = 42.0473, GNorm = 0.4591, lr_0 = 6.4648e-04
Loss = 3.2723e-04, PNorm = 42.0554, GNorm = 0.5220, lr_0 = 6.4561e-04
Loss = 3.6306e-04, PNorm = 42.0706, GNorm = 0.5358, lr_0 = 6.4474e-04
Loss = 3.6652e-04, PNorm = 42.0892, GNorm = 0.3300, lr_0 = 6.4388e-04
Loss = 3.6987e-04, PNorm = 42.0943, GNorm = 0.3480, lr_0 = 6.4302e-04
Loss = 4.3101e-04, PNorm = 42.1025, GNorm = 0.5379, lr_0 = 6.4215e-04
Loss = 4.2285e-04, PNorm = 42.1152, GNorm = 0.5285, lr_0 = 6.4129e-04
Loss = 4.3833e-04, PNorm = 42.1250, GNorm = 0.6309, lr_0 = 6.4043e-04
Loss = 4.2579e-04, PNorm = 42.1409, GNorm = 0.7598, lr_0 = 6.3957e-04
Loss = 5.2128e-04, PNorm = 42.1572, GNorm = 1.6065, lr_0 = 6.3871e-04
Validation rmse = 0.489220
Validation R2 = 0.929758
Epoch 21
Train function
Loss = 3.3439e-04, PNorm = 42.1773, GNorm = 0.3950, lr_0 = 6.3786e-04
Loss = 2.9760e-04, PNorm = 42.1828, GNorm = 0.5835, lr_0 = 6.3700e-04
Loss = 3.8531e-04, PNorm = 42.1935, GNorm = 0.4630, lr_0 = 6.3615e-04
Loss = 2.9054e-04, PNorm = 42.2055, GNorm = 0.3136, lr_0 = 6.3529e-04
Loss = 3.0996e-04, PNorm = 42.2212, GNorm = 0.2316, lr_0 = 6.3444e-04
Loss = 3.2748e-04, PNorm = 42.2321, GNorm = 0.4399, lr_0 = 6.3359e-04
Loss = 4.0634e-04, PNorm = 42.2442, GNorm = 0.3771, lr_0 = 6.3274e-04
Loss = 3.8811e-04, PNorm = 42.2628, GNorm = 0.3474, lr_0 = 6.3189e-04
Loss = 4.2812e-04, PNorm = 42.2782, GNorm = 0.3655, lr_0 = 6.3104e-04
Loss = 4.5300e-04, PNorm = 42.2966, GNorm = 0.3430, lr_0 = 6.3020e-04
Loss = 5.1002e-04, PNorm = 42.3153, GNorm = 0.4837, lr_0 = 6.2935e-04
Loss = 4.1316e-04, PNorm = 42.3333, GNorm = 0.9845, lr_0 = 6.2851e-04
Loss = 4.0314e-04, PNorm = 42.3470, GNorm = 0.3462, lr_0 = 6.2766e-04
Loss = 3.7540e-04, PNorm = 42.3603, GNorm = 0.3799, lr_0 = 6.2682e-04
Loss = 4.7973e-04, PNorm = 42.3668, GNorm = 0.5030, lr_0 = 6.2598e-04
Loss = 4.4209e-04, PNorm = 42.3821, GNorm = 0.5279, lr_0 = 6.2514e-04
Loss = 3.3330e-04, PNorm = 42.3969, GNorm = 0.3503, lr_0 = 6.2430e-04
Loss = 3.3231e-04, PNorm = 42.4095, GNorm = 0.4871, lr_0 = 6.2346e-04
Validation rmse = 0.484548
Validation R2 = 0.931093
Epoch 22
Train function
Loss = 2.3315e-04, PNorm = 42.4192, GNorm = 0.2424, lr_0 = 6.2263e-04
Loss = 3.5488e-04, PNorm = 42.4246, GNorm = 0.3934, lr_0 = 6.2179e-04
Loss = 2.8428e-04, PNorm = 42.4349, GNorm = 0.1716, lr_0 = 6.2096e-04
Loss = 3.4102e-04, PNorm = 42.4482, GNorm = 0.4158, lr_0 = 6.2012e-04
Loss = 3.5081e-04, PNorm = 42.4584, GNorm = 0.3412, lr_0 = 6.1929e-04
Loss = 2.5322e-04, PNorm = 42.4697, GNorm = 0.2246, lr_0 = 6.1846e-04
Loss = 2.9602e-04, PNorm = 42.4849, GNorm = 0.4205, lr_0 = 6.1763e-04
Loss = 3.2168e-04, PNorm = 42.4985, GNorm = 0.2890, lr_0 = 6.1680e-04
Loss = 3.0821e-04, PNorm = 42.5050, GNorm = 0.4725, lr_0 = 6.1597e-04
Loss = 3.5995e-04, PNorm = 42.5164, GNorm = 0.7815, lr_0 = 6.1515e-04
Loss = 3.8586e-04, PNorm = 42.5266, GNorm = 0.2768, lr_0 = 6.1432e-04
Loss = 3.0045e-04, PNorm = 42.5358, GNorm = 0.2103, lr_0 = 6.1350e-04
Loss = 2.9768e-04, PNorm = 42.5439, GNorm = 0.6997, lr_0 = 6.1268e-04
Loss = 2.8253e-04, PNorm = 42.5507, GNorm = 0.7297, lr_0 = 6.1185e-04
Loss = 3.0971e-04, PNorm = 42.5635, GNorm = 0.2325, lr_0 = 6.1103e-04
Loss = 3.8436e-04, PNorm = 42.5784, GNorm = 0.4139, lr_0 = 6.1021e-04
Loss = 3.0960e-04, PNorm = 42.5892, GNorm = 0.3684, lr_0 = 6.0939e-04
Validation rmse = 0.467532
Validation R2 = 0.935848
Epoch 23
Train function
Loss = 2.8573e-04, PNorm = 42.5996, GNorm = 0.3430, lr_0 = 6.0849e-04
Loss = 2.9871e-04, PNorm = 42.6155, GNorm = 0.4010, lr_0 = 6.0768e-04
Loss = 2.6867e-04, PNorm = 42.6266, GNorm = 1.1001, lr_0 = 6.0686e-04
Loss = 2.5401e-04, PNorm = 42.6354, GNorm = 0.3607, lr_0 = 6.0605e-04
Loss = 2.3081e-04, PNorm = 42.6454, GNorm = 0.2837, lr_0 = 6.0524e-04
Loss = 2.3942e-04, PNorm = 42.6585, GNorm = 0.2461, lr_0 = 6.0442e-04
Loss = 2.9705e-04, PNorm = 42.6673, GNorm = 0.2097, lr_0 = 6.0361e-04
Loss = 3.3418e-04, PNorm = 42.6781, GNorm = 0.8327, lr_0 = 6.0280e-04
Loss = 2.9010e-04, PNorm = 42.6866, GNorm = 0.2182, lr_0 = 6.0199e-04
Loss = 2.9030e-04, PNorm = 42.6956, GNorm = 0.3169, lr_0 = 6.0119e-04
Loss = 2.9176e-04, PNorm = 42.7073, GNorm = 0.5556, lr_0 = 6.0038e-04
Loss = 3.0608e-04, PNorm = 42.7220, GNorm = 0.5218, lr_0 = 5.9957e-04
Loss = 2.7651e-04, PNorm = 42.7338, GNorm = 0.4586, lr_0 = 5.9877e-04
Loss = 2.9537e-04, PNorm = 42.7445, GNorm = 0.1860, lr_0 = 5.9797e-04
Loss = 2.8455e-04, PNorm = 42.7557, GNorm = 0.2979, lr_0 = 5.9716e-04
Loss = 4.3411e-04, PNorm = 42.7680, GNorm = 0.5845, lr_0 = 5.9636e-04
Loss = 3.0262e-04, PNorm = 42.7836, GNorm = 0.3106, lr_0 = 5.9556e-04
Loss = 3.7184e-04, PNorm = 42.7980, GNorm = 0.3451, lr_0 = 5.9476e-04
Validation rmse = 0.477258
Validation R2 = 0.933151
Epoch 24
Train function
Loss = 2.4485e-04, PNorm = 42.8064, GNorm = 0.3449, lr_0 = 5.9397e-04
Loss = 2.7254e-04, PNorm = 42.8180, GNorm = 0.4584, lr_0 = 5.9317e-04
Loss = 2.3010e-04, PNorm = 42.8293, GNorm = 0.2940, lr_0 = 5.9237e-04
Loss = 3.3547e-04, PNorm = 42.8430, GNorm = 0.3678, lr_0 = 5.9158e-04
Loss = 2.7571e-04, PNorm = 42.8514, GNorm = 0.2486, lr_0 = 5.9078e-04
Loss = 3.2215e-04, PNorm = 42.8631, GNorm = 0.3438, lr_0 = 5.8999e-04
Loss = 2.4655e-04, PNorm = 42.8769, GNorm = 0.4601, lr_0 = 5.8920e-04
Loss = 2.5812e-04, PNorm = 42.8857, GNorm = 0.4169, lr_0 = 5.8841e-04
Loss = 3.7385e-04, PNorm = 42.9031, GNorm = 0.2445, lr_0 = 5.8762e-04
Loss = 3.9781e-04, PNorm = 42.9165, GNorm = 0.6671, lr_0 = 5.8683e-04
Loss = 2.9068e-04, PNorm = 42.9276, GNorm = 0.3386, lr_0 = 5.8604e-04
Loss = 3.7214e-04, PNorm = 42.9419, GNorm = 0.5226, lr_0 = 5.8526e-04
Loss = 3.5441e-04, PNorm = 42.9515, GNorm = 0.3898, lr_0 = 5.8447e-04
Loss = 3.2953e-04, PNorm = 42.9638, GNorm = 0.3669, lr_0 = 5.8369e-04
Loss = 3.2375e-04, PNorm = 42.9775, GNorm = 0.3981, lr_0 = 5.8290e-04
Loss = 3.8078e-04, PNorm = 42.9851, GNorm = 0.4911, lr_0 = 5.8212e-04
Loss = 2.7193e-04, PNorm = 42.9979, GNorm = 0.3300, lr_0 = 5.8134e-04
Loss = 3.1952e-04, PNorm = 43.0077, GNorm = 0.2534, lr_0 = 5.8056e-04
Validation rmse = 0.499440
Validation R2 = 0.926793
Epoch 25
Train function
Loss = 2.7458e-04, PNorm = 43.0235, GNorm = 0.4931, lr_0 = 5.7978e-04
Loss = 2.7966e-04, PNorm = 43.0360, GNorm = 0.2094, lr_0 = 5.7900e-04
Loss = 2.7551e-04, PNorm = 43.0515, GNorm = 0.2359, lr_0 = 5.7823e-04
Loss = 2.6889e-04, PNorm = 43.0609, GNorm = 0.7672, lr_0 = 5.7745e-04
Loss = 2.8878e-04, PNorm = 43.0727, GNorm = 0.3678, lr_0 = 5.7668e-04
Loss = 3.0125e-04, PNorm = 43.0896, GNorm = 0.5712, lr_0 = 5.7590e-04
Loss = 2.7968e-04, PNorm = 43.0978, GNorm = 0.2063, lr_0 = 5.7513e-04
Loss = 2.6276e-04, PNorm = 43.1156, GNorm = 0.3376, lr_0 = 5.7436e-04
Loss = 3.2541e-04, PNorm = 43.1301, GNorm = 0.5104, lr_0 = 5.7359e-04
Loss = 2.6966e-04, PNorm = 43.1416, GNorm = 0.2229, lr_0 = 5.7282e-04
Loss = 2.6205e-04, PNorm = 43.1537, GNorm = 0.4761, lr_0 = 5.7205e-04
Loss = 2.3142e-04, PNorm = 43.1592, GNorm = 0.2820, lr_0 = 5.7128e-04
Loss = 3.4127e-04, PNorm = 43.1704, GNorm = 0.5224, lr_0 = 5.7052e-04
Loss = 2.7671e-04, PNorm = 43.1784, GNorm = 0.2718, lr_0 = 5.6975e-04
Loss = 3.2431e-04, PNorm = 43.1929, GNorm = 0.5524, lr_0 = 5.6899e-04
Loss = 3.1046e-04, PNorm = 43.2088, GNorm = 0.7113, lr_0 = 5.6822e-04
Loss = 3.5016e-04, PNorm = 43.2214, GNorm = 0.7178, lr_0 = 5.6746e-04
Validation rmse = 0.475402
Validation R2 = 0.933670
Epoch 26
Train function
Loss = 2.5109e-04, PNorm = 43.2352, GNorm = 0.2364, lr_0 = 5.6662e-04
Loss = 2.4862e-04, PNorm = 43.2467, GNorm = 0.2898, lr_0 = 5.6586e-04
Loss = 2.5565e-04, PNorm = 43.2581, GNorm = 0.4484, lr_0 = 5.6510e-04
Loss = 2.7810e-04, PNorm = 43.2689, GNorm = 0.3157, lr_0 = 5.6435e-04
Loss = 2.4638e-04, PNorm = 43.2781, GNorm = 0.1899, lr_0 = 5.6359e-04
Loss = 2.4172e-04, PNorm = 43.2866, GNorm = 0.2551, lr_0 = 5.6283e-04
Loss = 2.0846e-04, PNorm = 43.2959, GNorm = 0.3829, lr_0 = 5.6208e-04
Loss = 3.2829e-04, PNorm = 43.3023, GNorm = 0.4610, lr_0 = 5.6132e-04
Loss = 2.6566e-04, PNorm = 43.3175, GNorm = 0.4376, lr_0 = 5.6057e-04
Loss = 2.9529e-04, PNorm = 43.3306, GNorm = 0.8141, lr_0 = 5.5982e-04
Loss = 2.5968e-04, PNorm = 43.3441, GNorm = 0.3274, lr_0 = 5.5907e-04
Loss = 2.7772e-04, PNorm = 43.3544, GNorm = 0.6686, lr_0 = 5.5832e-04
Loss = 2.9520e-04, PNorm = 43.3689, GNorm = 0.3781, lr_0 = 5.5757e-04
Loss = 3.3493e-04, PNorm = 43.3796, GNorm = 0.6754, lr_0 = 5.5682e-04
Loss = 2.6922e-04, PNorm = 43.3854, GNorm = 0.4701, lr_0 = 5.5607e-04
Loss = 2.5089e-04, PNorm = 43.3966, GNorm = 0.3893, lr_0 = 5.5533e-04
Loss = 2.9040e-04, PNorm = 43.4125, GNorm = 0.2331, lr_0 = 5.5458e-04
Loss = 2.9872e-04, PNorm = 43.4255, GNorm = 0.3520, lr_0 = 5.5384e-04
Validation rmse = 0.493651
Validation R2 = 0.928480
Epoch 27
Train function
Loss = 2.5092e-04, PNorm = 43.4378, GNorm = 0.4028, lr_0 = 5.5309e-04
Loss = 2.3831e-04, PNorm = 43.4442, GNorm = 0.4406, lr_0 = 5.5235e-04
Loss = 2.2468e-04, PNorm = 43.4562, GNorm = 0.2413, lr_0 = 5.5161e-04
Loss = 1.9517e-04, PNorm = 43.4671, GNorm = 0.6050, lr_0 = 5.5087e-04
Loss = 2.1238e-04, PNorm = 43.4718, GNorm = 0.1964, lr_0 = 5.5013e-04
Loss = 2.3331e-04, PNorm = 43.4801, GNorm = 0.1993, lr_0 = 5.4939e-04
Loss = 2.2191e-04, PNorm = 43.4921, GNorm = 0.4006, lr_0 = 5.4866e-04
Loss = 2.8348e-04, PNorm = 43.5012, GNorm = 0.4298, lr_0 = 5.4792e-04
Loss = 2.8503e-04, PNorm = 43.5111, GNorm = 0.8212, lr_0 = 5.4718e-04
Loss = 3.1668e-04, PNorm = 43.5237, GNorm = 0.2248, lr_0 = 5.4645e-04
Loss = 2.6737e-04, PNorm = 43.5355, GNorm = 0.2988, lr_0 = 5.4572e-04
Loss = 2.5569e-04, PNorm = 43.5461, GNorm = 0.2727, lr_0 = 5.4499e-04
Loss = 2.2057e-04, PNorm = 43.5548, GNorm = 0.2740, lr_0 = 5.4425e-04
Loss = 2.6905e-04, PNorm = 43.5623, GNorm = 0.7770, lr_0 = 5.4352e-04
Loss = 2.4003e-04, PNorm = 43.5757, GNorm = 0.4395, lr_0 = 5.4279e-04
Loss = 2.2027e-04, PNorm = 43.5871, GNorm = 0.3827, lr_0 = 5.4207e-04
Loss = 3.0562e-04, PNorm = 43.5980, GNorm = 0.2903, lr_0 = 5.4134e-04
Validation rmse = 0.479786
Validation R2 = 0.932441
Epoch 28
Train function
Loss = 2.1963e-04, PNorm = 43.6123, GNorm = 0.3386, lr_0 = 5.4054e-04
Loss = 2.2037e-04, PNorm = 43.6227, GNorm = 0.4135, lr_0 = 5.3981e-04
Loss = 2.3308e-04, PNorm = 43.6328, GNorm = 0.4333, lr_0 = 5.3909e-04
Loss = 2.7116e-04, PNorm = 43.6437, GNorm = 0.2323, lr_0 = 5.3837e-04
Loss = 2.4362e-04, PNorm = 43.6560, GNorm = 0.2637, lr_0 = 5.3765e-04
Loss = 2.4120e-04, PNorm = 43.6712, GNorm = 0.3715, lr_0 = 5.3692e-04
Loss = 1.9699e-04, PNorm = 43.6789, GNorm = 0.2355, lr_0 = 5.3620e-04
Loss = 2.0092e-04, PNorm = 43.6838, GNorm = 0.1703, lr_0 = 5.3548e-04
Loss = 2.7863e-04, PNorm = 43.6904, GNorm = 0.4950, lr_0 = 5.3477e-04
Loss = 2.3410e-04, PNorm = 43.6953, GNorm = 0.5610, lr_0 = 5.3405e-04
Loss = 2.5002e-04, PNorm = 43.7086, GNorm = 0.4820, lr_0 = 5.3333e-04
Loss = 2.8969e-04, PNorm = 43.7201, GNorm = 0.7137, lr_0 = 5.3262e-04
Loss = 2.1478e-04, PNorm = 43.7331, GNorm = 0.3916, lr_0 = 5.3190e-04
Loss = 2.3444e-04, PNorm = 43.7411, GNorm = 0.2491, lr_0 = 5.3119e-04
Loss = 2.7290e-04, PNorm = 43.7528, GNorm = 0.8334, lr_0 = 5.3047e-04
Loss = 2.6687e-04, PNorm = 43.7592, GNorm = 0.3542, lr_0 = 5.2976e-04
Loss = 2.1144e-04, PNorm = 43.7703, GNorm = 0.3529, lr_0 = 5.2905e-04
Loss = 2.8569e-04, PNorm = 43.7815, GNorm = 0.5155, lr_0 = 5.2834e-04
Validation rmse = 0.474477
Validation R2 = 0.933928
Epoch 29
Train function
Loss = 2.8668e-04, PNorm = 43.7886, GNorm = 0.9951, lr_0 = 5.2763e-04
Loss = 2.6914e-04, PNorm = 43.8012, GNorm = 0.3014, lr_0 = 5.2693e-04
Loss = 1.9836e-04, PNorm = 43.8122, GNorm = 0.3800, lr_0 = 5.2622e-04
Loss = 2.6848e-04, PNorm = 43.8191, GNorm = 0.6021, lr_0 = 5.2551e-04
Loss = 2.7873e-04, PNorm = 43.8315, GNorm = 0.8439, lr_0 = 5.2481e-04
Loss = 2.9393e-04, PNorm = 43.8448, GNorm = 0.8260, lr_0 = 5.2410e-04
Loss = 2.6195e-04, PNorm = 43.8571, GNorm = 0.2929, lr_0 = 5.2340e-04
Loss = 2.6842e-04, PNorm = 43.8663, GNorm = 0.6097, lr_0 = 5.2270e-04
Loss = 2.5262e-04, PNorm = 43.8746, GNorm = 0.4065, lr_0 = 5.2200e-04
Loss = 2.6366e-04, PNorm = 43.8851, GNorm = 0.3177, lr_0 = 5.2130e-04
Loss = 2.6767e-04, PNorm = 43.8927, GNorm = 0.1782, lr_0 = 5.2060e-04
Loss = 2.1252e-04, PNorm = 43.9002, GNorm = 0.2082, lr_0 = 5.1990e-04
Loss = 1.8085e-04, PNorm = 43.9136, GNorm = 0.3141, lr_0 = 5.1920e-04
Loss = 2.0397e-04, PNorm = 43.9241, GNorm = 0.4761, lr_0 = 5.1850e-04
Loss = 1.9472e-04, PNorm = 43.9308, GNorm = 0.2946, lr_0 = 5.1781e-04
Loss = 2.5617e-04, PNorm = 43.9401, GNorm = 0.4882, lr_0 = 5.1711e-04
Loss = 2.0278e-04, PNorm = 43.9507, GNorm = 0.3040, lr_0 = 5.1642e-04
Validation rmse = 0.473163
Validation R2 = 0.934293
Epoch 30
Train function
Loss = 1.6987e-04, PNorm = 43.9586, GNorm = 0.1858, lr_0 = 5.1573e-04
Loss = 2.6553e-04, PNorm = 43.9679, GNorm = 0.3273, lr_0 = 5.1503e-04
Loss = 2.8069e-04, PNorm = 43.9790, GNorm = 0.9266, lr_0 = 5.1434e-04
Loss = 2.5382e-04, PNorm = 43.9930, GNorm = 0.7311, lr_0 = 5.1365e-04
Loss = 1.7279e-04, PNorm = 44.0048, GNorm = 0.3305, lr_0 = 5.1296e-04
Loss = 1.6857e-04, PNorm = 44.0139, GNorm = 0.2473, lr_0 = 5.1228e-04
Loss = 1.8333e-04, PNorm = 44.0228, GNorm = 0.1749, lr_0 = 5.1159e-04
Loss = 1.6503e-04, PNorm = 44.0255, GNorm = 0.3147, lr_0 = 5.1090e-04
Loss = 1.9058e-04, PNorm = 44.0307, GNorm = 0.2084, lr_0 = 5.1022e-04
Loss = 2.1914e-04, PNorm = 44.0429, GNorm = 0.4324, lr_0 = 5.0953e-04
Loss = 2.6834e-04, PNorm = 44.0573, GNorm = 0.4582, lr_0 = 5.0885e-04
Loss = 2.0386e-04, PNorm = 44.0660, GNorm = 0.4893, lr_0 = 5.0817e-04
Loss = 2.2868e-04, PNorm = 44.0745, GNorm = 0.3158, lr_0 = 5.0748e-04
Loss = 2.0749e-04, PNorm = 44.0862, GNorm = 0.4680, lr_0 = 5.0680e-04
Loss = 2.1962e-04, PNorm = 44.0938, GNorm = 0.2687, lr_0 = 5.0612e-04
Loss = 2.2817e-04, PNorm = 44.0992, GNorm = 0.3084, lr_0 = 5.0544e-04
Loss = 2.8730e-04, PNorm = 44.1096, GNorm = 0.3556, lr_0 = 5.0477e-04
Loss = 2.5432e-04, PNorm = 44.1180, GNorm = 0.3865, lr_0 = 5.0409e-04
Validation rmse = 0.478792
Validation R2 = 0.932721
Epoch 31
Train function
Loss = 2.0783e-04, PNorm = 44.1287, GNorm = 0.2795, lr_0 = 5.0335e-04
Loss = 1.6775e-04, PNorm = 44.1319, GNorm = 0.4217, lr_0 = 5.0267e-04
Loss = 1.7175e-04, PNorm = 44.1429, GNorm = 0.2164, lr_0 = 5.0200e-04
Loss = 2.0866e-04, PNorm = 44.1533, GNorm = 0.4223, lr_0 = 5.0132e-04
Loss = 1.6864e-04, PNorm = 44.1582, GNorm = 0.5745, lr_0 = 5.0065e-04
Loss = 1.7867e-04, PNorm = 44.1671, GNorm = 0.1484, lr_0 = 4.9998e-04
Loss = 1.6704e-04, PNorm = 44.1769, GNorm = 0.3281, lr_0 = 4.9931e-04
Loss = 1.5954e-04, PNorm = 44.1836, GNorm = 0.3093, lr_0 = 4.9864e-04
Loss = 1.6308e-04, PNorm = 44.1897, GNorm = 0.5080, lr_0 = 4.9797e-04
Loss = 1.6406e-04, PNorm = 44.1966, GNorm = 0.2211, lr_0 = 4.9730e-04
Loss = 1.6614e-04, PNorm = 44.2078, GNorm = 0.6195, lr_0 = 4.9663e-04
Loss = 2.1443e-04, PNorm = 44.2173, GNorm = 0.3940, lr_0 = 4.9597e-04
Loss = 2.7047e-04, PNorm = 44.2253, GNorm = 0.9489, lr_0 = 4.9530e-04
Loss = 2.5416e-04, PNorm = 44.2380, GNorm = 0.4236, lr_0 = 4.9464e-04
Loss = 2.1367e-04, PNorm = 44.2480, GNorm = 0.2957, lr_0 = 4.9397e-04
Loss = 1.9642e-04, PNorm = 44.2574, GNorm = 0.4483, lr_0 = 4.9331e-04
Loss = 1.9618e-04, PNorm = 44.2667, GNorm = 0.1768, lr_0 = 4.9265e-04
Loss = 2.3328e-04, PNorm = 44.2738, GNorm = 0.3398, lr_0 = 4.9199e-04
Validation rmse = 0.466649
Validation R2 = 0.936090
Epoch 32
Train function
Loss = 1.6330e-04, PNorm = 44.2810, GNorm = 0.3520, lr_0 = 4.9133e-04
Loss = 1.7850e-04, PNorm = 44.2845, GNorm = 0.2161, lr_0 = 4.9067e-04
Loss = 1.8138e-04, PNorm = 44.2964, GNorm = 0.1862, lr_0 = 4.9001e-04
Loss = 1.8771e-04, PNorm = 44.3018, GNorm = 0.1969, lr_0 = 4.8935e-04
Loss = 1.5061e-04, PNorm = 44.3146, GNorm = 0.2835, lr_0 = 4.8870e-04
Loss = 1.7621e-04, PNorm = 44.3223, GNorm = 0.6511, lr_0 = 4.8804e-04
Loss = 1.8226e-04, PNorm = 44.3329, GNorm = 0.5969, lr_0 = 4.8738e-04
Loss = 1.5581e-04, PNorm = 44.3387, GNorm = 0.2097, lr_0 = 4.8673e-04
Loss = 2.0800e-04, PNorm = 44.3467, GNorm = 0.3209, lr_0 = 4.8608e-04
Loss = 2.1798e-04, PNorm = 44.3552, GNorm = 0.2976, lr_0 = 4.8543e-04
Loss = 2.2533e-04, PNorm = 44.3632, GNorm = 0.4062, lr_0 = 4.8477e-04
Loss = 1.7146e-04, PNorm = 44.3729, GNorm = 0.2287, lr_0 = 4.8412e-04
Loss = 1.8808e-04, PNorm = 44.3782, GNorm = 0.4556, lr_0 = 4.8347e-04
Loss = 1.9996e-04, PNorm = 44.3857, GNorm = 0.5245, lr_0 = 4.8283e-04
Loss = 1.6604e-04, PNorm = 44.3912, GNorm = 0.1838, lr_0 = 4.8218e-04
Loss = 1.9694e-04, PNorm = 44.4018, GNorm = 0.2799, lr_0 = 4.8153e-04
Loss = 2.5447e-04, PNorm = 44.4107, GNorm = 0.5446, lr_0 = 4.8088e-04
Validation rmse = 0.479366
Validation R2 = 0.932559
Epoch 33
Train function
Loss = 1.5619e-04, PNorm = 44.4218, GNorm = 0.5887, lr_0 = 4.8024e-04
Loss = 1.8180e-04, PNorm = 44.4307, GNorm = 0.1746, lr_0 = 4.7959e-04
Loss = 1.7573e-04, PNorm = 44.4380, GNorm = 0.2329, lr_0 = 4.7895e-04
Loss = 1.5780e-04, PNorm = 44.4469, GNorm = 0.1621, lr_0 = 4.7831e-04
Loss = 1.9422e-04, PNorm = 44.4595, GNorm = 0.2823, lr_0 = 4.7767e-04
Loss = 1.7325e-04, PNorm = 44.4656, GNorm = 0.1488, lr_0 = 4.7703e-04
Loss = 1.5651e-04, PNorm = 44.4716, GNorm = 0.3716, lr_0 = 4.7639e-04
Loss = 1.3358e-04, PNorm = 44.4794, GNorm = 0.2155, lr_0 = 4.7575e-04
Loss = 1.6937e-04, PNorm = 44.4853, GNorm = 0.2945, lr_0 = 4.7511e-04
Loss = 1.5253e-04, PNorm = 44.4926, GNorm = 0.3371, lr_0 = 4.7447e-04
Loss = 1.7529e-04, PNorm = 44.5020, GNorm = 0.2493, lr_0 = 4.7383e-04
Loss = 1.4942e-04, PNorm = 44.5092, GNorm = 0.2173, lr_0 = 4.7320e-04
Loss = 1.5000e-04, PNorm = 44.5173, GNorm = 0.4258, lr_0 = 4.7256e-04
Loss = 1.6393e-04, PNorm = 44.5265, GNorm = 0.3476, lr_0 = 4.7193e-04
Loss = 1.4947e-04, PNorm = 44.5308, GNorm = 0.3269, lr_0 = 4.7130e-04
Loss = 1.7141e-04, PNorm = 44.5404, GNorm = 0.3026, lr_0 = 4.7066e-04
Loss = 1.6412e-04, PNorm = 44.5491, GNorm = 0.1844, lr_0 = 4.7003e-04
Loss = 1.9128e-04, PNorm = 44.5562, GNorm = 0.6303, lr_0 = 4.6940e-04
Validation rmse = 0.494150
Validation R2 = 0.928335
Epoch 34
Train function
Loss = 2.0351e-04, PNorm = 44.5676, GNorm = 0.6616, lr_0 = 4.6871e-04
Loss = 1.4008e-04, PNorm = 44.5749, GNorm = 0.2527, lr_0 = 4.6808e-04
Loss = 1.6308e-04, PNorm = 44.5844, GNorm = 0.3566, lr_0 = 4.6745e-04
Loss = 1.5275e-04, PNorm = 44.5912, GNorm = 0.5582, lr_0 = 4.6683e-04
Loss = 1.3001e-04, PNorm = 44.5996, GNorm = 0.2097, lr_0 = 4.6620e-04
Loss = 1.6620e-04, PNorm = 44.6055, GNorm = 0.3370, lr_0 = 4.6557e-04
Loss = 1.4158e-04, PNorm = 44.6145, GNorm = 0.2425, lr_0 = 4.6495e-04
Loss = 1.8659e-04, PNorm = 44.6211, GNorm = 0.6263, lr_0 = 4.6433e-04
Loss = 1.3495e-04, PNorm = 44.6285, GNorm = 0.1867, lr_0 = 4.6370e-04
Loss = 1.2983e-04, PNorm = 44.6327, GNorm = 0.4339, lr_0 = 4.6308e-04
Loss = 1.5496e-04, PNorm = 44.6388, GNorm = 0.4674, lr_0 = 4.6246e-04
Loss = 1.5917e-04, PNorm = 44.6453, GNorm = 0.3029, lr_0 = 4.6184e-04
Loss = 1.8438e-04, PNorm = 44.6528, GNorm = 0.1880, lr_0 = 4.6122e-04
Loss = 1.6370e-04, PNorm = 44.6601, GNorm = 0.2225, lr_0 = 4.6060e-04
Loss = 2.0060e-04, PNorm = 44.6639, GNorm = 0.5270, lr_0 = 4.5998e-04
Loss = 1.9948e-04, PNorm = 44.6729, GNorm = 0.3299, lr_0 = 4.5936e-04
Loss = 2.0135e-04, PNorm = 44.6816, GNorm = 0.5963, lr_0 = 4.5875e-04
Validation rmse = 0.469636
Validation R2 = 0.935269
Epoch 35
Train function
Loss = 1.8690e-04, PNorm = 44.6908, GNorm = 0.9126, lr_0 = 4.5813e-04
Loss = 1.4655e-04, PNorm = 44.6966, GNorm = 0.1832, lr_0 = 4.5752e-04
Loss = 1.4279e-04, PNorm = 44.7079, GNorm = 0.2312, lr_0 = 4.5690e-04
Loss = 1.4190e-04, PNorm = 44.7137, GNorm = 0.1971, lr_0 = 4.5629e-04
Loss = 1.3507e-04, PNorm = 44.7215, GNorm = 0.3907, lr_0 = 4.5568e-04
Loss = 1.6409e-04, PNorm = 44.7285, GNorm = 0.2066, lr_0 = 4.5507e-04
Loss = 1.5680e-04, PNorm = 44.7398, GNorm = 0.3797, lr_0 = 4.5446e-04
Loss = 1.4665e-04, PNorm = 44.7462, GNorm = 0.1770, lr_0 = 4.5385e-04
Loss = 1.2388e-04, PNorm = 44.7524, GNorm = 0.2020, lr_0 = 4.5324e-04
Loss = 1.1783e-04, PNorm = 44.7581, GNorm = 0.1694, lr_0 = 4.5263e-04
Loss = 1.2402e-04, PNorm = 44.7659, GNorm = 0.2131, lr_0 = 4.5202e-04
Loss = 1.5298e-04, PNorm = 44.7742, GNorm = 0.2990, lr_0 = 4.5142e-04
Loss = 1.5390e-04, PNorm = 44.7775, GNorm = 0.4595, lr_0 = 4.5081e-04
Loss = 1.8305e-04, PNorm = 44.7825, GNorm = 0.5870, lr_0 = 4.5021e-04
Loss = 1.6169e-04, PNorm = 44.7925, GNorm = 0.6085, lr_0 = 4.4960e-04
Loss = 1.5806e-04, PNorm = 44.7984, GNorm = 0.2993, lr_0 = 4.4900e-04
Loss = 1.7846e-04, PNorm = 44.8081, GNorm = 0.1865, lr_0 = 4.4840e-04
Loss = 1.4619e-04, PNorm = 44.8173, GNorm = 0.3040, lr_0 = 4.4779e-04
Validation rmse = 0.472748
Validation R2 = 0.934409
Epoch 36
Train function
Loss = 1.3654e-04, PNorm = 44.8246, GNorm = 0.3820, lr_0 = 4.4719e-04
Loss = 1.2044e-04, PNorm = 44.8306, GNorm = 0.1949, lr_0 = 4.4659e-04
Loss = 1.1205e-04, PNorm = 44.8370, GNorm = 0.2684, lr_0 = 4.4599e-04
Loss = 1.0883e-04, PNorm = 44.8413, GNorm = 0.2470, lr_0 = 4.4540e-04
Loss = 1.4943e-04, PNorm = 44.8467, GNorm = 0.1713, lr_0 = 4.4480e-04
Loss = 1.2196e-04, PNorm = 44.8563, GNorm = 0.3316, lr_0 = 4.4420e-04
Loss = 1.0290e-04, PNorm = 44.8617, GNorm = 0.1294, lr_0 = 4.4361e-04
Loss = 1.1494e-04, PNorm = 44.8657, GNorm = 0.3753, lr_0 = 4.4301e-04
Loss = 1.1135e-04, PNorm = 44.8709, GNorm = 0.3407, lr_0 = 4.4242e-04
Loss = 1.5216e-04, PNorm = 44.8752, GNorm = 0.7101, lr_0 = 4.4182e-04
Loss = 1.3175e-04, PNorm = 44.8869, GNorm = 0.2199, lr_0 = 4.4123e-04
Loss = 1.5745e-04, PNorm = 44.8972, GNorm = 0.3049, lr_0 = 4.4064e-04
Loss = 1.5651e-04, PNorm = 44.9053, GNorm = 0.1753, lr_0 = 4.4005e-04
Loss = 1.3783e-04, PNorm = 44.9104, GNorm = 0.1838, lr_0 = 4.3946e-04
Loss = 1.1713e-04, PNorm = 44.9179, GNorm = 0.3612, lr_0 = 4.3887e-04
Loss = 1.3237e-04, PNorm = 44.9200, GNorm = 0.2075, lr_0 = 4.3828e-04
Loss = 1.5064e-04, PNorm = 44.9256, GNorm = 0.5224, lr_0 = 4.3769e-04
Validation rmse = 0.468634
Validation R2 = 0.935545
Epoch 37
Train function
Loss = 1.1564e-04, PNorm = 44.9318, GNorm = 0.2966, lr_0 = 4.3704e-04
Loss = 1.1830e-04, PNorm = 44.9375, GNorm = 0.1635, lr_0 = 4.3646e-04
Loss = 1.5519e-04, PNorm = 44.9436, GNorm = 0.3595, lr_0 = 4.3587e-04
Loss = 1.2168e-04, PNorm = 44.9485, GNorm = 0.2387, lr_0 = 4.3529e-04
Loss = 1.4378e-04, PNorm = 44.9559, GNorm = 0.1921, lr_0 = 4.3470e-04
Loss = 1.1602e-04, PNorm = 44.9630, GNorm = 0.2238, lr_0 = 4.3412e-04
Loss = 1.3928e-04, PNorm = 44.9726, GNorm = 0.1416, lr_0 = 4.3354e-04
Loss = 1.4136e-04, PNorm = 44.9830, GNorm = 0.3399, lr_0 = 4.3296e-04
Loss = 1.8561e-04, PNorm = 44.9912, GNorm = 0.4155, lr_0 = 4.3237e-04
Loss = 1.5568e-04, PNorm = 44.9990, GNorm = 0.1908, lr_0 = 4.3179e-04
Loss = 1.2563e-04, PNorm = 45.0064, GNorm = 0.1938, lr_0 = 4.3122e-04
Loss = 1.2410e-04, PNorm = 45.0138, GNorm = 0.2323, lr_0 = 4.3064e-04
Loss = 1.5981e-04, PNorm = 45.0199, GNorm = 0.2625, lr_0 = 4.3006e-04
Loss = 1.4410e-04, PNorm = 45.0277, GNorm = 0.2257, lr_0 = 4.2948e-04
Loss = 1.1953e-04, PNorm = 45.0339, GNorm = 0.1468, lr_0 = 4.2891e-04
Loss = 1.3576e-04, PNorm = 45.0436, GNorm = 0.2743, lr_0 = 4.2833e-04
Loss = 1.4685e-04, PNorm = 45.0494, GNorm = 0.2247, lr_0 = 4.2776e-04
Loss = 1.2068e-04, PNorm = 45.0564, GNorm = 0.1490, lr_0 = 4.2718e-04
Validation rmse = 0.468946
Validation R2 = 0.935459
Epoch 38
Train function
Loss = 1.1280e-04, PNorm = 45.0651, GNorm = 0.3182, lr_0 = 4.2661e-04
Loss = 1.2135e-04, PNorm = 45.0742, GNorm = 0.3467, lr_0 = 4.2604e-04
Loss = 1.0057e-04, PNorm = 45.0816, GNorm = 0.1351, lr_0 = 4.2546e-04
Loss = 9.7623e-05, PNorm = 45.0856, GNorm = 0.2313, lr_0 = 4.2489e-04
Loss = 1.0218e-04, PNorm = 45.0903, GNorm = 0.1550, lr_0 = 4.2432e-04
Loss = 1.2987e-04, PNorm = 45.0970, GNorm = 0.1495, lr_0 = 4.2375e-04
Loss = 1.1028e-04, PNorm = 45.1031, GNorm = 0.2472, lr_0 = 4.2319e-04
Loss = 1.2848e-04, PNorm = 45.1071, GNorm = 0.2838, lr_0 = 4.2262e-04
Loss = 1.1828e-04, PNorm = 45.1138, GNorm = 0.4139, lr_0 = 4.2205e-04
Loss = 1.4136e-04, PNorm = 45.1210, GNorm = 0.3785, lr_0 = 4.2148e-04
Loss = 1.3931e-04, PNorm = 45.1249, GNorm = 0.1242, lr_0 = 4.2092e-04
Loss = 1.6044e-04, PNorm = 45.1341, GNorm = 0.1368, lr_0 = 4.2035e-04
Loss = 1.7150e-04, PNorm = 45.1446, GNorm = 0.3775, lr_0 = 4.1979e-04
Loss = 1.3466e-04, PNorm = 45.1517, GNorm = 0.3820, lr_0 = 4.1923e-04
Loss = 1.3865e-04, PNorm = 45.1613, GNorm = 0.4283, lr_0 = 4.1866e-04
Loss = 1.2130e-04, PNorm = 45.1723, GNorm = 0.3834, lr_0 = 4.1810e-04
Loss = 1.2851e-04, PNorm = 45.1777, GNorm = 0.2147, lr_0 = 4.1754e-04
Validation rmse = 0.482723
Validation R2 = 0.931611
Epoch 39
Train function
Loss = 1.5536e-04, PNorm = 45.1850, GNorm = 0.5658, lr_0 = 4.1693e-04
Loss = 1.1698e-04, PNorm = 45.1901, GNorm = 0.1932, lr_0 = 4.1637e-04
Loss = 1.0894e-04, PNorm = 45.1948, GNorm = 0.2137, lr_0 = 4.1581e-04
Loss = 1.0009e-04, PNorm = 45.1959, GNorm = 0.2197, lr_0 = 4.1525e-04
Loss = 1.0542e-04, PNorm = 45.2002, GNorm = 0.3168, lr_0 = 4.1469e-04
Loss = 1.0310e-04, PNorm = 45.2062, GNorm = 0.1512, lr_0 = 4.1414e-04
Loss = 1.0572e-04, PNorm = 45.2116, GNorm = 0.4583, lr_0 = 4.1358e-04
Loss = 1.1608e-04, PNorm = 45.2165, GNorm = 0.2203, lr_0 = 4.1303e-04
Loss = 1.5601e-04, PNorm = 45.2219, GNorm = 0.6469, lr_0 = 4.1247e-04
Loss = 1.5238e-04, PNorm = 45.2285, GNorm = 0.3027, lr_0 = 4.1192e-04
Loss = 1.4666e-04, PNorm = 45.2373, GNorm = 0.2404, lr_0 = 4.1137e-04
Loss = 1.3519e-04, PNorm = 45.2431, GNorm = 0.2977, lr_0 = 4.1081e-04
Loss = 1.2405e-04, PNorm = 45.2460, GNorm = 0.1999, lr_0 = 4.1026e-04
Loss = 1.3766e-04, PNorm = 45.2567, GNorm = 0.3633, lr_0 = 4.0971e-04
Loss = 1.2360e-04, PNorm = 45.2675, GNorm = 0.1821, lr_0 = 4.0916e-04
Loss = 1.3090e-04, PNorm = 45.2708, GNorm = 0.1984, lr_0 = 4.0861e-04
Loss = 1.0794e-04, PNorm = 45.2743, GNorm = 0.2963, lr_0 = 4.0806e-04
Loss = 1.4902e-04, PNorm = 45.2817, GNorm = 0.5482, lr_0 = 4.0752e-04
Validation rmse = 0.475307
Validation R2 = 0.933697
Epoch 40
Train function
Loss = 1.2281e-04, PNorm = 45.2894, GNorm = 0.3400, lr_0 = 4.0697e-04
Loss = 1.1709e-04, PNorm = 45.2969, GNorm = 0.1300, lr_0 = 4.0642e-04
Loss = 1.2365e-04, PNorm = 45.3015, GNorm = 0.3409, lr_0 = 4.0588e-04
Loss = 1.3170e-04, PNorm = 45.3093, GNorm = 0.3753, lr_0 = 4.0533e-04
Loss = 1.0016e-04, PNorm = 45.3161, GNorm = 0.1293, lr_0 = 4.0479e-04
Loss = 1.1144e-04, PNorm = 45.3221, GNorm = 0.3606, lr_0 = 4.0425e-04
Loss = 1.1560e-04, PNorm = 45.3266, GNorm = 0.3750, lr_0 = 4.0371e-04
Loss = 1.1869e-04, PNorm = 45.3322, GNorm = 0.1520, lr_0 = 4.0316e-04
Loss = 1.3823e-04, PNorm = 45.3381, GNorm = 0.3807, lr_0 = 4.0262e-04
Loss = 1.1494e-04, PNorm = 45.3466, GNorm = 0.4421, lr_0 = 4.0208e-04
Loss = 1.2671e-04, PNorm = 45.3527, GNorm = 0.3025, lr_0 = 4.0154e-04
Loss = 1.3113e-04, PNorm = 45.3564, GNorm = 0.5076, lr_0 = 4.0100e-04
Loss = 1.2307e-04, PNorm = 45.3650, GNorm = 0.3171, lr_0 = 4.0047e-04
Loss = 1.3932e-04, PNorm = 45.3667, GNorm = 0.3912, lr_0 = 3.9993e-04
Loss = 1.2911e-04, PNorm = 45.3757, GNorm = 0.1950, lr_0 = 3.9939e-04
Loss = 1.1094e-04, PNorm = 45.3794, GNorm = 0.1964, lr_0 = 3.9886e-04
Loss = 1.1528e-04, PNorm = 45.3868, GNorm = 0.2446, lr_0 = 3.9832e-04
Loss = 1.1593e-04, PNorm = 45.3920, GNorm = 0.1260, lr_0 = 3.9779e-04
Validation rmse = 0.469183
Validation R2 = 0.935394
Epoch 41
Train function
Loss = 1.1433e-04, PNorm = 45.3975, GNorm = 0.4924, lr_0 = 3.9725e-04
Loss = 1.0170e-04, PNorm = 45.4035, GNorm = 0.3306, lr_0 = 3.9672e-04
Loss = 1.2923e-04, PNorm = 45.4060, GNorm = 0.3467, lr_0 = 3.9619e-04
Loss = 1.2416e-04, PNorm = 45.4094, GNorm = 0.1472, lr_0 = 3.9566e-04
Loss = 1.3467e-04, PNorm = 45.4163, GNorm = 0.1471, lr_0 = 3.9513e-04
Loss = 1.3096e-04, PNorm = 45.4238, GNorm = 0.1548, lr_0 = 3.9460e-04
Loss = 9.6021e-05, PNorm = 45.4334, GNorm = 0.2218, lr_0 = 3.9407e-04
Loss = 1.0251e-04, PNorm = 45.4394, GNorm = 0.3627, lr_0 = 3.9354e-04
Loss = 9.6305e-05, PNorm = 45.4470, GNorm = 0.2782, lr_0 = 3.9301e-04
Loss = 1.1080e-04, PNorm = 45.4541, GNorm = 0.1537, lr_0 = 3.9248e-04
Loss = 1.1181e-04, PNorm = 45.4611, GNorm = 0.1320, lr_0 = 3.9195e-04
Loss = 1.2460e-04, PNorm = 45.4675, GNorm = 0.1628, lr_0 = 3.9143e-04
Loss = 1.2433e-04, PNorm = 45.4734, GNorm = 0.2152, lr_0 = 3.9090e-04
Loss = 1.2849e-04, PNorm = 45.4807, GNorm = 0.2442, lr_0 = 3.9038e-04
Loss = 1.2031e-04, PNorm = 45.4850, GNorm = 0.1986, lr_0 = 3.8986e-04
Loss = 1.0134e-04, PNorm = 45.4880, GNorm = 0.5188, lr_0 = 3.8933e-04
Loss = 1.4448e-04, PNorm = 45.4936, GNorm = 0.6476, lr_0 = 3.8881e-04
Validation rmse = 0.464357
Validation R2 = 0.936716
Epoch 42
Train function
Loss = 1.1339e-04, PNorm = 45.5009, GNorm = 0.1699, lr_0 = 3.8824e-04
Loss = 8.3305e-05, PNorm = 45.5071, GNorm = 0.1671, lr_0 = 3.8772e-04
Loss = 1.1559e-04, PNorm = 45.5123, GNorm = 0.1867, lr_0 = 3.8720e-04
Loss = 1.0226e-04, PNorm = 45.5207, GNorm = 0.2922, lr_0 = 3.8668e-04
Loss = 1.0624e-04, PNorm = 45.5274, GNorm = 0.4307, lr_0 = 3.8616e-04
Loss = 9.6450e-05, PNorm = 45.5324, GNorm = 0.1384, lr_0 = 3.8564e-04
Loss = 9.5933e-05, PNorm = 45.5404, GNorm = 0.1576, lr_0 = 3.8512e-04
Loss = 1.2403e-04, PNorm = 45.5469, GNorm = 0.2793, lr_0 = 3.8460e-04
Loss = 9.9415e-05, PNorm = 45.5565, GNorm = 0.1410, lr_0 = 3.8409e-04
Loss = 1.1715e-04, PNorm = 45.5627, GNorm = 0.4056, lr_0 = 3.8357e-04
Loss = 1.5291e-04, PNorm = 45.5637, GNorm = 0.8038, lr_0 = 3.8306e-04
Loss = 1.7900e-04, PNorm = 45.5704, GNorm = 0.5088, lr_0 = 3.8254e-04
Loss = 2.4649e-04, PNorm = 45.5813, GNorm = 0.8479, lr_0 = 3.8203e-04
Loss = 2.0233e-04, PNorm = 45.5938, GNorm = 0.6172, lr_0 = 3.8152e-04
Loss = 1.7111e-04, PNorm = 45.6015, GNorm = 0.2509, lr_0 = 3.8101e-04
Loss = 1.5096e-04, PNorm = 45.6082, GNorm = 0.1583, lr_0 = 3.8050e-04
Loss = 1.5285e-04, PNorm = 45.6174, GNorm = 0.1949, lr_0 = 3.7999e-04
Loss = 1.4238e-04, PNorm = 45.6206, GNorm = 0.3189, lr_0 = 3.7948e-04
Validation rmse = 0.478266
Validation R2 = 0.932869
Epoch 43
Train function
Loss = 1.1018e-04, PNorm = 45.6259, GNorm = 0.2116, lr_0 = 3.7897e-04
Loss = 9.1387e-05, PNorm = 45.6301, GNorm = 0.1361, lr_0 = 3.7846e-04
Loss = 7.9217e-05, PNorm = 45.6362, GNorm = 0.1281, lr_0 = 3.7795e-04
Loss = 9.8515e-05, PNorm = 45.6409, GNorm = 0.2312, lr_0 = 3.7744e-04
Loss = 1.0095e-04, PNorm = 45.6452, GNorm = 0.2195, lr_0 = 3.7694e-04
Loss = 9.7533e-05, PNorm = 45.6463, GNorm = 0.3091, lr_0 = 3.7643e-04
Loss = 1.2718e-04, PNorm = 45.6530, GNorm = 0.2601, lr_0 = 3.7593e-04
Loss = 8.5812e-05, PNorm = 45.6604, GNorm = 0.1403, lr_0 = 3.7542e-04
Loss = 9.7943e-05, PNorm = 45.6678, GNorm = 0.1305, lr_0 = 3.7492e-04
Loss = 9.6752e-05, PNorm = 45.6703, GNorm = 0.2920, lr_0 = 3.7441e-04
Loss = 1.3192e-04, PNorm = 45.6755, GNorm = 0.5286, lr_0 = 3.7391e-04
Loss = 1.4207e-04, PNorm = 45.6842, GNorm = 0.5210, lr_0 = 3.7341e-04
Loss = 1.3419e-04, PNorm = 45.6919, GNorm = 0.6577, lr_0 = 3.7291e-04
Loss = 1.1584e-04, PNorm = 45.6993, GNorm = 0.1337, lr_0 = 3.7241e-04
Loss = 1.1765e-04, PNorm = 45.7031, GNorm = 0.3195, lr_0 = 3.7191e-04
Loss = 1.2241e-04, PNorm = 45.7055, GNorm = 0.1548, lr_0 = 3.7141e-04
Loss = 1.2900e-04, PNorm = 45.7121, GNorm = 0.3699, lr_0 = 3.7091e-04
Validation rmse = 0.468508
Validation R2 = 0.935580
Epoch 44
Train function
Loss = 1.0987e-04, PNorm = 45.7178, GNorm = 0.4424, lr_0 = 3.7041e-04
Loss = 9.3219e-05, PNorm = 45.7261, GNorm = 0.1205, lr_0 = 3.6992e-04
Loss = 1.1445e-04, PNorm = 45.7319, GNorm = 0.5599, lr_0 = 3.6942e-04
Loss = 9.8404e-05, PNorm = 45.7359, GNorm = 0.4276, lr_0 = 3.6893e-04
Loss = 1.0317e-04, PNorm = 45.7400, GNorm = 0.3989, lr_0 = 3.6843e-04
Loss = 1.3010e-04, PNorm = 45.7447, GNorm = 0.3514, lr_0 = 3.6794e-04
Loss = 1.1409e-04, PNorm = 45.7527, GNorm = 0.2171, lr_0 = 3.6744e-04
Loss = 8.1249e-05, PNorm = 45.7578, GNorm = 0.1090, lr_0 = 3.6695e-04
Loss = 8.4000e-05, PNorm = 45.7643, GNorm = 0.2707, lr_0 = 3.6646e-04
Loss = 1.0167e-04, PNorm = 45.7718, GNorm = 0.2845, lr_0 = 3.6597e-04
Loss = 9.6348e-05, PNorm = 45.7792, GNorm = 0.1359, lr_0 = 3.6547e-04
Loss = 1.0873e-04, PNorm = 45.7842, GNorm = 0.2026, lr_0 = 3.6498e-04
Loss = 1.0945e-04, PNorm = 45.7884, GNorm = 0.5054, lr_0 = 3.6449e-04
Loss = 1.4021e-04, PNorm = 45.7935, GNorm = 0.3822, lr_0 = 3.6401e-04
Loss = 1.2569e-04, PNorm = 45.8023, GNorm = 0.1753, lr_0 = 3.6352e-04
Loss = 1.2877e-04, PNorm = 45.8075, GNorm = 0.2558, lr_0 = 3.6303e-04
Loss = 8.1955e-05, PNorm = 45.8117, GNorm = 0.2130, lr_0 = 3.6254e-04
Loss = 1.1875e-04, PNorm = 45.8138, GNorm = 0.2702, lr_0 = 3.6206e-04
Validation rmse = 0.463813
Validation R2 = 0.936865
Epoch 45
Train function
Loss = 9.8505e-05, PNorm = 45.8182, GNorm = 0.2415, lr_0 = 3.6152e-04
Loss = 8.9730e-05, PNorm = 45.8212, GNorm = 0.1457, lr_0 = 3.6104e-04
Loss = 9.3240e-05, PNorm = 45.8244, GNorm = 0.3593, lr_0 = 3.6055e-04
Loss = 8.2207e-05, PNorm = 45.8303, GNorm = 0.1857, lr_0 = 3.6007e-04
Loss = 6.8796e-05, PNorm = 45.8347, GNorm = 0.2150, lr_0 = 3.5959e-04
Loss = 9.0972e-05, PNorm = 45.8416, GNorm = 0.1092, lr_0 = 3.5910e-04
Loss = 7.6519e-05, PNorm = 45.8458, GNorm = 0.1708, lr_0 = 3.5862e-04
Loss = 6.7652e-05, PNorm = 45.8487, GNorm = 0.1992, lr_0 = 3.5814e-04
Loss = 7.0701e-05, PNorm = 45.8507, GNorm = 0.2192, lr_0 = 3.5766e-04
Loss = 7.6978e-05, PNorm = 45.8534, GNorm = 0.2016, lr_0 = 3.5718e-04
Loss = 7.4803e-05, PNorm = 45.8564, GNorm = 0.2053, lr_0 = 3.5670e-04
Loss = 9.5172e-05, PNorm = 45.8602, GNorm = 0.2210, lr_0 = 3.5622e-04
Loss = 7.2133e-05, PNorm = 45.8646, GNorm = 0.1940, lr_0 = 3.5574e-04
Loss = 9.0071e-05, PNorm = 45.8708, GNorm = 0.3846, lr_0 = 3.5527e-04
Loss = 8.6203e-05, PNorm = 45.8751, GNorm = 0.1641, lr_0 = 3.5479e-04
Loss = 9.6013e-05, PNorm = 45.8791, GNorm = 0.3899, lr_0 = 3.5431e-04
Loss = 1.0766e-04, PNorm = 45.8857, GNorm = 0.3789, lr_0 = 3.5384e-04
Validation rmse = 0.466348
Validation R2 = 0.936173
Epoch 46
Train function
Loss = 1.3086e-04, PNorm = 45.8942, GNorm = 0.4558, lr_0 = 3.5336e-04
Loss = 6.6200e-05, PNorm = 45.9020, GNorm = 0.1280, lr_0 = 3.5289e-04
Loss = 9.3273e-05, PNorm = 45.9071, GNorm = 0.3654, lr_0 = 3.5242e-04
Loss = 7.3524e-05, PNorm = 45.9122, GNorm = 0.2381, lr_0 = 3.5194e-04
Loss = 6.9458e-05, PNorm = 45.9141, GNorm = 0.4195, lr_0 = 3.5147e-04
Loss = 9.0087e-05, PNorm = 45.9196, GNorm = 0.3174, lr_0 = 3.5100e-04
Loss = 6.9420e-05, PNorm = 45.9251, GNorm = 0.2607, lr_0 = 3.5053e-04
Loss = 6.8344e-05, PNorm = 45.9303, GNorm = 0.1867, lr_0 = 3.5006e-04
Loss = 7.3620e-05, PNorm = 45.9334, GNorm = 0.1532, lr_0 = 3.4959e-04
Loss = 6.7171e-05, PNorm = 45.9386, GNorm = 0.2104, lr_0 = 3.4912e-04
Loss = 8.1036e-05, PNorm = 45.9407, GNorm = 0.1746, lr_0 = 3.4865e-04
Loss = 7.6013e-05, PNorm = 45.9431, GNorm = 0.1689, lr_0 = 3.4818e-04
Loss = 8.7502e-05, PNorm = 45.9474, GNorm = 0.2758, lr_0 = 3.4772e-04
Loss = 9.0281e-05, PNorm = 45.9511, GNorm = 0.2112, lr_0 = 3.4725e-04
Loss = 7.8120e-05, PNorm = 45.9558, GNorm = 0.1539, lr_0 = 3.4678e-04
Loss = 6.8586e-05, PNorm = 45.9599, GNorm = 0.1215, lr_0 = 3.4632e-04
Loss = 7.3707e-05, PNorm = 45.9630, GNorm = 0.2978, lr_0 = 3.4585e-04
Loss = 1.1394e-04, PNorm = 45.9691, GNorm = 0.4288, lr_0 = 3.4539e-04
Validation rmse = 0.471355
Validation R2 = 0.934795
Epoch 47
Train function
Loss = 1.1843e-04, PNorm = 45.9727, GNorm = 0.4051, lr_0 = 3.4493e-04
Loss = 8.0011e-05, PNorm = 45.9798, GNorm = 0.1238, lr_0 = 3.4446e-04
Loss = 7.2805e-05, PNorm = 45.9885, GNorm = 0.1409, lr_0 = 3.4400e-04
Loss = 7.2597e-05, PNorm = 45.9916, GNorm = 0.2295, lr_0 = 3.4354e-04
Loss = 8.2744e-05, PNorm = 45.9945, GNorm = 0.0991, lr_0 = 3.4308e-04
Loss = 7.1785e-05, PNorm = 45.9995, GNorm = 0.1734, lr_0 = 3.4262e-04
Loss = 8.0907e-05, PNorm = 46.0015, GNorm = 0.1519, lr_0 = 3.4216e-04
Loss = 8.8250e-05, PNorm = 46.0066, GNorm = 0.1731, lr_0 = 3.4170e-04
Loss = 6.7437e-05, PNorm = 46.0082, GNorm = 0.1889, lr_0 = 3.4124e-04
Loss = 7.9999e-05, PNorm = 46.0103, GNorm = 0.1451, lr_0 = 3.4078e-04
Loss = 9.0300e-05, PNorm = 46.0132, GNorm = 0.1306, lr_0 = 3.4033e-04
Loss = 9.5400e-05, PNorm = 46.0178, GNorm = 0.2654, lr_0 = 3.3987e-04
Loss = 9.0161e-05, PNorm = 46.0187, GNorm = 0.1400, lr_0 = 3.3941e-04
Loss = 8.8157e-05, PNorm = 46.0239, GNorm = 0.1267, lr_0 = 3.3896e-04
Loss = 7.1806e-05, PNorm = 46.0289, GNorm = 0.1398, lr_0 = 3.3850e-04
Loss = 7.8901e-05, PNorm = 46.0357, GNorm = 0.2430, lr_0 = 3.3805e-04
Loss = 8.4846e-05, PNorm = 46.0372, GNorm = 0.1867, lr_0 = 3.3760e-04
Loss = 7.6740e-05, PNorm = 46.0393, GNorm = 0.3166, lr_0 = 3.3714e-04
Loss = 6.5915e-05, PNorm = 46.0397, GNorm = 0.1194, lr_0 = 3.3710e-04
Validation rmse = 0.467358
Validation R2 = 0.935896
Epoch 48
Train function
Loss = 6.2615e-05, PNorm = 46.0429, GNorm = 0.1075, lr_0 = 3.3664e-04
Loss = 6.3990e-05, PNorm = 46.0464, GNorm = 0.1802, lr_0 = 3.3619e-04
Loss = 6.2806e-05, PNorm = 46.0486, GNorm = 0.1459, lr_0 = 3.3574e-04
Loss = 5.5142e-05, PNorm = 46.0515, GNorm = 0.0906, lr_0 = 3.3529e-04
Loss = 6.3386e-05, PNorm = 46.0561, GNorm = 0.1643, lr_0 = 3.3484e-04
Loss = 5.7391e-05, PNorm = 46.0600, GNorm = 0.1894, lr_0 = 3.3439e-04
Loss = 5.7369e-05, PNorm = 46.0637, GNorm = 0.1606, lr_0 = 3.3394e-04
Loss = 6.7704e-05, PNorm = 46.0644, GNorm = 0.1565, lr_0 = 3.3350e-04
Loss = 7.1864e-05, PNorm = 46.0696, GNorm = 0.1485, lr_0 = 3.3305e-04
Loss = 6.9133e-05, PNorm = 46.0727, GNorm = 0.1010, lr_0 = 3.3260e-04
Loss = 7.9966e-05, PNorm = 46.0758, GNorm = 0.2717, lr_0 = 3.3216e-04
Loss = 7.0453e-05, PNorm = 46.0791, GNorm = 0.1147, lr_0 = 3.3171e-04
Loss = 7.0793e-05, PNorm = 46.0845, GNorm = 0.2627, lr_0 = 3.3126e-04
Loss = 6.7964e-05, PNorm = 46.0894, GNorm = 0.1603, lr_0 = 3.3082e-04
Loss = 8.0025e-05, PNorm = 46.0937, GNorm = 0.3435, lr_0 = 3.3038e-04
Loss = 6.8464e-05, PNorm = 46.0979, GNorm = 0.1597, lr_0 = 3.2993e-04
Loss = 6.7058e-05, PNorm = 46.0996, GNorm = 0.2045, lr_0 = 3.2949e-04
Validation rmse = 0.468543
Validation R2 = 0.935570
Epoch 49
Train function
Loss = 6.7180e-05, PNorm = 46.1030, GNorm = 0.1349, lr_0 = 3.2905e-04
Loss = 7.6274e-05, PNorm = 46.1089, GNorm = 0.4524, lr_0 = 3.2861e-04
Loss = 7.8490e-05, PNorm = 46.1104, GNorm = 0.3349, lr_0 = 3.2817e-04
Loss = 8.2075e-05, PNorm = 46.1151, GNorm = 0.5866, lr_0 = 3.2773e-04
Loss = 7.3588e-05, PNorm = 46.1189, GNorm = 0.2498, lr_0 = 3.2729e-04
Loss = 7.4679e-05, PNorm = 46.1244, GNorm = 0.2115, lr_0 = 3.2685e-04
Loss = 7.4569e-05, PNorm = 46.1318, GNorm = 0.2122, lr_0 = 3.2641e-04
Loss = 7.3985e-05, PNorm = 46.1352, GNorm = 0.1141, lr_0 = 3.2597e-04
Loss = 7.4384e-05, PNorm = 46.1414, GNorm = 0.2495, lr_0 = 3.2553e-04
Loss = 7.3315e-05, PNorm = 46.1474, GNorm = 0.4431, lr_0 = 3.2510e-04
Loss = 6.6847e-05, PNorm = 46.1517, GNorm = 0.1954, lr_0 = 3.2466e-04
Loss = 7.4956e-05, PNorm = 46.1545, GNorm = 0.4063, lr_0 = 3.2422e-04
Loss = 7.4441e-05, PNorm = 46.1623, GNorm = 0.2156, lr_0 = 3.2379e-04
Loss = 5.7350e-05, PNorm = 46.1679, GNorm = 0.2458, lr_0 = 3.2335e-04
Loss = 7.5356e-05, PNorm = 46.1693, GNorm = 0.2827, lr_0 = 3.2292e-04
Loss = 7.1667e-05, PNorm = 46.1700, GNorm = 0.3298, lr_0 = 3.2249e-04
Loss = 7.3219e-05, PNorm = 46.1750, GNorm = 0.3898, lr_0 = 3.2205e-04
Loss = 5.8612e-05, PNorm = 46.1789, GNorm = 0.1483, lr_0 = 3.2162e-04
Validation rmse = 0.468613
Validation R2 = 0.935551
Epoch 50
Train function
Loss = 7.9057e-05, PNorm = 46.1798, GNorm = 0.2690, lr_0 = 3.2119e-04
Loss = 6.1579e-05, PNorm = 46.1824, GNorm = 0.1752, lr_0 = 3.2076e-04
Loss = 6.5151e-05, PNorm = 46.1874, GNorm = 0.2049, lr_0 = 3.2033e-04
Loss = 5.4039e-05, PNorm = 46.1926, GNorm = 0.1771, lr_0 = 3.1990e-04
Loss = 6.4775e-05, PNorm = 46.1950, GNorm = 0.1489, lr_0 = 3.1947e-04
Loss = 6.1808e-05, PNorm = 46.1984, GNorm = 0.1759, lr_0 = 3.1904e-04
Loss = 7.5187e-05, PNorm = 46.2063, GNorm = 0.1730, lr_0 = 3.1861e-04
Loss = 5.8843e-05, PNorm = 46.2092, GNorm = 0.1317, lr_0 = 3.1819e-04
Loss = 7.4837e-05, PNorm = 46.2133, GNorm = 0.2311, lr_0 = 3.1776e-04
Loss = 7.5657e-05, PNorm = 46.2170, GNorm = 0.1036, lr_0 = 3.1733e-04
Loss = 7.2244e-05, PNorm = 46.2229, GNorm = 0.1052, lr_0 = 3.1691e-04
Loss = 6.0200e-05, PNorm = 46.2261, GNorm = 0.1150, lr_0 = 3.1648e-04
Loss = 8.0506e-05, PNorm = 46.2287, GNorm = 0.1246, lr_0 = 3.1606e-04
Loss = 8.7477e-05, PNorm = 46.2309, GNorm = 0.3485, lr_0 = 3.1563e-04
Loss = 7.4745e-05, PNorm = 46.2380, GNorm = 0.2279, lr_0 = 3.1521e-04
Loss = 7.2975e-05, PNorm = 46.2418, GNorm = 0.3132, lr_0 = 3.1479e-04
Loss = 9.5195e-05, PNorm = 46.2462, GNorm = 0.4396, lr_0 = 3.1437e-04
Validation rmse = 0.469098
Validation R2 = 0.935417
Epoch 51
Train function
Loss = 8.4601e-05, PNorm = 46.2540, GNorm = 0.1839, lr_0 = 3.1390e-04
Loss = 7.5846e-05, PNorm = 46.2564, GNorm = 0.1295, lr_0 = 3.1348e-04
Loss = 7.7315e-05, PNorm = 46.2623, GNorm = 0.2175, lr_0 = 3.1306e-04
Loss = 9.1638e-05, PNorm = 46.2648, GNorm = 0.2634, lr_0 = 3.1264e-04
Loss = 6.4218e-05, PNorm = 46.2669, GNorm = 0.1372, lr_0 = 3.1222e-04
Loss = 6.7351e-05, PNorm = 46.2692, GNorm = 0.1181, lr_0 = 3.1180e-04
Loss = 8.6139e-05, PNorm = 46.2728, GNorm = 0.4212, lr_0 = 3.1138e-04
Loss = 7.6932e-05, PNorm = 46.2795, GNorm = 0.3276, lr_0 = 3.1096e-04
Loss = 6.2061e-05, PNorm = 46.2861, GNorm = 0.1853, lr_0 = 3.1055e-04
Loss = 6.1226e-05, PNorm = 46.2910, GNorm = 0.1978, lr_0 = 3.1013e-04
Loss = 8.1612e-05, PNorm = 46.2941, GNorm = 0.3382, lr_0 = 3.0971e-04
Loss = 8.4431e-05, PNorm = 46.2981, GNorm = 0.2029, lr_0 = 3.0930e-04
Loss = 1.0125e-04, PNorm = 46.3002, GNorm = 0.1332, lr_0 = 3.0888e-04
Loss = 7.2317e-05, PNorm = 46.3090, GNorm = 0.1310, lr_0 = 3.0847e-04
Loss = 7.7611e-05, PNorm = 46.3124, GNorm = 0.3068, lr_0 = 3.0806e-04
Loss = 8.3526e-05, PNorm = 46.3161, GNorm = 0.1471, lr_0 = 3.0764e-04
Loss = 8.5199e-05, PNorm = 46.3205, GNorm = 0.2313, lr_0 = 3.0723e-04
Loss = 6.4372e-05, PNorm = 46.3248, GNorm = 0.1866, lr_0 = 3.0682e-04
Validation rmse = 0.467334
Validation R2 = 0.935902
Epoch 52
Train function
Loss = 6.7511e-05, PNorm = 46.3298, GNorm = 0.3175, lr_0 = 3.0641e-04
Loss = 5.9046e-05, PNorm = 46.3322, GNorm = 0.2976, lr_0 = 3.0599e-04
Loss = 6.5284e-05, PNorm = 46.3368, GNorm = 0.1539, lr_0 = 3.0558e-04
Loss = 5.6101e-05, PNorm = 46.3399, GNorm = 0.1000, lr_0 = 3.0517e-04
Loss = 5.1997e-05, PNorm = 46.3440, GNorm = 0.0938, lr_0 = 3.0476e-04
Loss = 6.1303e-05, PNorm = 46.3484, GNorm = 0.0910, lr_0 = 3.0436e-04
Loss = 6.9777e-05, PNorm = 46.3501, GNorm = 0.2680, lr_0 = 3.0395e-04
Loss = 6.3620e-05, PNorm = 46.3542, GNorm = 0.1347, lr_0 = 3.0354e-04
Loss = 5.6783e-05, PNorm = 46.3589, GNorm = 0.3229, lr_0 = 3.0313e-04
Loss = 5.9926e-05, PNorm = 46.3634, GNorm = 0.2697, lr_0 = 3.0273e-04
Loss = 6.8678e-05, PNorm = 46.3669, GNorm = 0.4500, lr_0 = 3.0232e-04
Loss = 6.7358e-05, PNorm = 46.3707, GNorm = 0.4188, lr_0 = 3.0191e-04
Loss = 8.0289e-05, PNorm = 46.3750, GNorm = 0.2358, lr_0 = 3.0151e-04
Loss = 6.2749e-05, PNorm = 46.3794, GNorm = 0.3999, lr_0 = 3.0110e-04
Loss = 7.4507e-05, PNorm = 46.3850, GNorm = 0.2216, lr_0 = 3.0070e-04
Loss = 5.4912e-05, PNorm = 46.3870, GNorm = 0.0723, lr_0 = 3.0030e-04
Loss = 5.7678e-05, PNorm = 46.3899, GNorm = 0.1901, lr_0 = 2.9989e-04
Validation rmse = 0.466872
Validation R2 = 0.936029
Epoch 53
Train function
Loss = 3.4438e-05, PNorm = 46.3944, GNorm = 0.1860, lr_0 = 2.9945e-04
Loss = 4.9784e-05, PNorm = 46.3956, GNorm = 0.2229, lr_0 = 2.9905e-04
Loss = 6.6389e-05, PNorm = 46.3973, GNorm = 0.3702, lr_0 = 2.9865e-04
Loss = 7.1813e-05, PNorm = 46.4013, GNorm = 0.1706, lr_0 = 2.9825e-04
Loss = 4.7612e-05, PNorm = 46.4068, GNorm = 0.0906, lr_0 = 2.9785e-04
Loss = 5.4498e-05, PNorm = 46.4086, GNorm = 0.1743, lr_0 = 2.9745e-04
Loss = 5.4219e-05, PNorm = 46.4121, GNorm = 0.1755, lr_0 = 2.9705e-04
Loss = 5.9053e-05, PNorm = 46.4120, GNorm = 0.2635, lr_0 = 2.9665e-04
Loss = 5.3689e-05, PNorm = 46.4152, GNorm = 0.1532, lr_0 = 2.9625e-04
Loss = 4.8456e-05, PNorm = 46.4169, GNorm = 0.1101, lr_0 = 2.9585e-04
Loss = 4.4699e-05, PNorm = 46.4199, GNorm = 0.0862, lr_0 = 2.9546e-04
Loss = 6.0151e-05, PNorm = 46.4223, GNorm = 0.2501, lr_0 = 2.9506e-04
Loss = 5.8988e-05, PNorm = 46.4258, GNorm = 0.1205, lr_0 = 2.9467e-04
Loss = 5.7288e-05, PNorm = 46.4275, GNorm = 0.1385, lr_0 = 2.9427e-04
Loss = 5.2591e-05, PNorm = 46.4299, GNorm = 0.1572, lr_0 = 2.9388e-04
Loss = 6.8210e-05, PNorm = 46.4331, GNorm = 0.1543, lr_0 = 2.9348e-04
Loss = 6.9752e-05, PNorm = 46.4367, GNorm = 0.1320, lr_0 = 2.9309e-04
Loss = 7.3392e-05, PNorm = 46.4404, GNorm = 0.1421, lr_0 = 2.9269e-04
Validation rmse = 0.473785
Validation R2 = 0.934121
Epoch 54
Train function
Loss = 7.3464e-05, PNorm = 46.4463, GNorm = 0.2282, lr_0 = 2.9230e-04
Loss = 5.4522e-05, PNorm = 46.4509, GNorm = 0.1514, lr_0 = 2.9191e-04
Loss = 5.4177e-05, PNorm = 46.4573, GNorm = 0.1512, lr_0 = 2.9152e-04
Loss = 5.3150e-05, PNorm = 46.4602, GNorm = 0.1634, lr_0 = 2.9113e-04
Loss = 5.6025e-05, PNorm = 46.4610, GNorm = 0.1797, lr_0 = 2.9074e-04
Loss = 6.0581e-05, PNorm = 46.4630, GNorm = 0.1157, lr_0 = 2.9035e-04
Loss = 6.3482e-05, PNorm = 46.4659, GNorm = 0.1372, lr_0 = 2.8996e-04
Loss = 5.0483e-05, PNorm = 46.4696, GNorm = 0.2517, lr_0 = 2.8957e-04
Loss = 6.2125e-05, PNorm = 46.4689, GNorm = 0.2484, lr_0 = 2.8918e-04
Loss = 4.9966e-05, PNorm = 46.4741, GNorm = 0.0936, lr_0 = 2.8879e-04
Loss = 4.2824e-05, PNorm = 46.4774, GNorm = 0.1634, lr_0 = 2.8840e-04
Loss = 5.8768e-05, PNorm = 46.4793, GNorm = 0.1577, lr_0 = 2.8802e-04
Loss = 4.7024e-05, PNorm = 46.4828, GNorm = 0.0698, lr_0 = 2.8763e-04
Loss = 4.6505e-05, PNorm = 46.4860, GNorm = 0.1570, lr_0 = 2.8724e-04
Loss = 4.4618e-05, PNorm = 46.4902, GNorm = 0.1812, lr_0 = 2.8686e-04
Loss = 4.8290e-05, PNorm = 46.4942, GNorm = 0.1320, lr_0 = 2.8647e-04
Loss = 5.8033e-05, PNorm = 46.4981, GNorm = 0.1985, lr_0 = 2.8609e-04
Loss = 4.9154e-05, PNorm = 46.5015, GNorm = 0.1359, lr_0 = 2.8571e-04
Validation rmse = 0.465331
Validation R2 = 0.936450
Epoch 55
Train function
Loss = 5.4540e-05, PNorm = 46.5038, GNorm = 0.1090, lr_0 = 2.8532e-04
Loss = 5.6482e-05, PNorm = 46.5062, GNorm = 0.2481, lr_0 = 2.8494e-04
Loss = 4.4052e-05, PNorm = 46.5083, GNorm = 0.1089, lr_0 = 2.8456e-04
Loss = 4.2051e-05, PNorm = 46.5090, GNorm = 0.1567, lr_0 = 2.8418e-04
Loss = 4.4783e-05, PNorm = 46.5125, GNorm = 0.1442, lr_0 = 2.8379e-04
Loss = 4.2807e-05, PNorm = 46.5146, GNorm = 0.0872, lr_0 = 2.8341e-04
Loss = 5.0150e-05, PNorm = 46.5174, GNorm = 0.2160, lr_0 = 2.8303e-04
Loss = 5.6212e-05, PNorm = 46.5215, GNorm = 0.1435, lr_0 = 2.8265e-04
Loss = 5.1936e-05, PNorm = 46.5220, GNorm = 0.1206, lr_0 = 2.8227e-04
Loss = 5.4637e-05, PNorm = 46.5249, GNorm = 0.1064, lr_0 = 2.8190e-04
Loss = 5.2521e-05, PNorm = 46.5280, GNorm = 0.1530, lr_0 = 2.8152e-04
Loss = 4.3534e-05, PNorm = 46.5323, GNorm = 0.0968, lr_0 = 2.8114e-04
Loss = 4.3748e-05, PNorm = 46.5359, GNorm = 0.1400, lr_0 = 2.8076e-04
Loss = 4.1947e-05, PNorm = 46.5391, GNorm = 0.1646, lr_0 = 2.8039e-04
Loss = 4.5046e-05, PNorm = 46.5416, GNorm = 0.1230, lr_0 = 2.8001e-04
Loss = 4.8016e-05, PNorm = 46.5436, GNorm = 0.1239, lr_0 = 2.7963e-04
Loss = 4.9393e-05, PNorm = 46.5456, GNorm = 0.1459, lr_0 = 2.7926e-04
Validation rmse = 0.466569
Validation R2 = 0.936112
Epoch 56
Train function
Loss = 3.2709e-05, PNorm = 46.5479, GNorm = 0.0815, lr_0 = 2.7885e-04
Loss = 5.0745e-05, PNorm = 46.5517, GNorm = 0.1436, lr_0 = 2.7847e-04
Loss = 4.0768e-05, PNorm = 46.5540, GNorm = 0.1062, lr_0 = 2.7810e-04
Loss = 3.3770e-05, PNorm = 46.5558, GNorm = 0.0869, lr_0 = 2.7773e-04
Loss = 4.3059e-05, PNorm = 46.5575, GNorm = 0.0885, lr_0 = 2.7735e-04
Loss = 4.8940e-05, PNorm = 46.5599, GNorm = 0.1043, lr_0 = 2.7698e-04
Loss = 3.7460e-05, PNorm = 46.5622, GNorm = 0.2073, lr_0 = 2.7661e-04
Loss = 3.9426e-05, PNorm = 46.5638, GNorm = 0.2111, lr_0 = 2.7624e-04
Loss = 4.0151e-05, PNorm = 46.5659, GNorm = 0.0898, lr_0 = 2.7587e-04
Loss = 4.7871e-05, PNorm = 46.5683, GNorm = 0.1280, lr_0 = 2.7550e-04
Loss = 4.3683e-05, PNorm = 46.5706, GNorm = 0.1020, lr_0 = 2.7513e-04
Loss = 5.7256e-05, PNorm = 46.5736, GNorm = 0.1338, lr_0 = 2.7476e-04
Loss = 5.6982e-05, PNorm = 46.5789, GNorm = 0.2012, lr_0 = 2.7439e-04
Loss = 4.5973e-05, PNorm = 46.5815, GNorm = 0.1667, lr_0 = 2.7402e-04
Loss = 6.0203e-05, PNorm = 46.5854, GNorm = 0.1493, lr_0 = 2.7365e-04
Loss = 6.9293e-05, PNorm = 46.5916, GNorm = 0.1325, lr_0 = 2.7329e-04
Loss = 5.4666e-05, PNorm = 46.5966, GNorm = 0.1572, lr_0 = 2.7292e-04
Loss = 5.5055e-05, PNorm = 46.6021, GNorm = 0.3545, lr_0 = 2.7255e-04
Validation rmse = 0.468294
Validation R2 = 0.935639
Epoch 57
Train function
Loss = 3.8565e-05, PNorm = 46.6057, GNorm = 0.1321, lr_0 = 2.7219e-04
Loss = 3.5218e-05, PNorm = 46.6079, GNorm = 0.0810, lr_0 = 2.7182e-04
Loss = 3.6618e-05, PNorm = 46.6092, GNorm = 0.1796, lr_0 = 2.7146e-04
Loss = 3.6067e-05, PNorm = 46.6114, GNorm = 0.0843, lr_0 = 2.7109e-04
Loss = 3.8564e-05, PNorm = 46.6138, GNorm = 0.1941, lr_0 = 2.7073e-04
Loss = 4.0634e-05, PNorm = 46.6162, GNorm = 0.3811, lr_0 = 2.7037e-04
Loss = 4.7552e-05, PNorm = 46.6203, GNorm = 0.1668, lr_0 = 2.7000e-04
Loss = 4.6915e-05, PNorm = 46.6212, GNorm = 0.1298, lr_0 = 2.6964e-04
Loss = 4.1953e-05, PNorm = 46.6233, GNorm = 0.1558, lr_0 = 2.6928e-04
Loss = 4.6611e-05, PNorm = 46.6247, GNorm = 0.1305, lr_0 = 2.6892e-04
Loss = 5.9442e-05, PNorm = 46.6256, GNorm = 0.3045, lr_0 = 2.6856e-04
Loss = 4.8843e-05, PNorm = 46.6293, GNorm = 0.1597, lr_0 = 2.6820e-04
Loss = 5.2818e-05, PNorm = 46.6350, GNorm = 0.2112, lr_0 = 2.6784e-04
Loss = 4.6246e-05, PNorm = 46.6373, GNorm = 0.1831, lr_0 = 2.6748e-04
Loss = 4.7378e-05, PNorm = 46.6392, GNorm = 0.1169, lr_0 = 2.6712e-04
Loss = 4.2397e-05, PNorm = 46.6406, GNorm = 0.1322, lr_0 = 2.6676e-04
Loss = 4.5027e-05, PNorm = 46.6443, GNorm = 0.2412, lr_0 = 2.6640e-04
Validation rmse = 0.468111
Validation R2 = 0.935689
Epoch 58
Train function
Loss = 3.8086e-05, PNorm = 46.6460, GNorm = 0.1624, lr_0 = 2.6605e-04
Loss = 3.6618e-05, PNorm = 46.6487, GNorm = 0.2121, lr_0 = 2.6569e-04
Loss = 6.0011e-05, PNorm = 46.6538, GNorm = 0.1194, lr_0 = 2.6533e-04
Loss = 5.7843e-05, PNorm = 46.6580, GNorm = 0.1941, lr_0 = 2.6498e-04
Loss = 5.6631e-05, PNorm = 46.6628, GNorm = 0.1901, lr_0 = 2.6462e-04
Loss = 7.9587e-05, PNorm = 46.6631, GNorm = 0.4456, lr_0 = 2.6427e-04
Loss = 5.0584e-05, PNorm = 46.6642, GNorm = 0.1395, lr_0 = 2.6391e-04
Loss = 6.1922e-05, PNorm = 46.6667, GNorm = 0.2066, lr_0 = 2.6356e-04
Loss = 6.6450e-05, PNorm = 46.6727, GNorm = 0.1782, lr_0 = 2.6320e-04
Loss = 5.8094e-05, PNorm = 46.6795, GNorm = 0.1146, lr_0 = 2.6285e-04
Loss = 3.5622e-05, PNorm = 46.6812, GNorm = 0.1189, lr_0 = 2.6250e-04
Loss = 3.5296e-05, PNorm = 46.6826, GNorm = 0.0805, lr_0 = 2.6215e-04
Loss = 4.4018e-05, PNorm = 46.6843, GNorm = 0.1001, lr_0 = 2.6179e-04
Loss = 4.1298e-05, PNorm = 46.6886, GNorm = 0.2474, lr_0 = 2.6144e-04
Loss = 3.9003e-05, PNorm = 46.6903, GNorm = 0.1089, lr_0 = 2.6109e-04
Loss = 4.3676e-05, PNorm = 46.6940, GNorm = 0.1423, lr_0 = 2.6074e-04
Loss = 4.4661e-05, PNorm = 46.6966, GNorm = 0.1075, lr_0 = 2.6039e-04
Loss = 4.2021e-05, PNorm = 46.6999, GNorm = 0.1983, lr_0 = 2.6004e-04
Validation rmse = 0.469237
Validation R2 = 0.935379
Epoch 59
Train function
Loss = 4.0476e-05, PNorm = 46.7017, GNorm = 0.1458, lr_0 = 2.5966e-04
Loss = 3.5887e-05, PNorm = 46.7025, GNorm = 0.1499, lr_0 = 2.5931e-04
Loss = 4.1834e-05, PNorm = 46.7035, GNorm = 0.1624, lr_0 = 2.5896e-04
Loss = 4.0676e-05, PNorm = 46.7035, GNorm = 0.1639, lr_0 = 2.5861e-04
Loss = 3.9833e-05, PNorm = 46.7049, GNorm = 0.1559, lr_0 = 2.5827e-04
Loss = 3.4081e-05, PNorm = 46.7094, GNorm = 0.1947, lr_0 = 2.5792e-04
Loss = 5.0303e-05, PNorm = 46.7128, GNorm = 0.1164, lr_0 = 2.5758e-04
Loss = 4.1018e-05, PNorm = 46.7166, GNorm = 0.0910, lr_0 = 2.5723e-04
Loss = 4.3274e-05, PNorm = 46.7204, GNorm = 0.1201, lr_0 = 2.5688e-04
Loss = 4.0559e-05, PNorm = 46.7230, GNorm = 0.1261, lr_0 = 2.5654e-04
Loss = 3.6410e-05, PNorm = 46.7278, GNorm = 0.0817, lr_0 = 2.5620e-04
Loss = 4.0616e-05, PNorm = 46.7308, GNorm = 0.3600, lr_0 = 2.5585e-04
Loss = 4.6677e-05, PNorm = 46.7306, GNorm = 0.1999, lr_0 = 2.5551e-04
Loss = 4.0193e-05, PNorm = 46.7345, GNorm = 0.1029, lr_0 = 2.5517e-04
Loss = 4.2582e-05, PNorm = 46.7362, GNorm = 0.1131, lr_0 = 2.5482e-04
Loss = 4.1945e-05, PNorm = 46.7373, GNorm = 0.1684, lr_0 = 2.5448e-04
Loss = 3.6815e-05, PNorm = 46.7409, GNorm = 0.1035, lr_0 = 2.5414e-04
Validation rmse = 0.469990
Validation R2 = 0.935172
Epoch 60
Train function
Loss = 4.5352e-05, PNorm = 46.7436, GNorm = 0.2736, lr_0 = 2.5380e-04
Loss = 3.8313e-05, PNorm = 46.7439, GNorm = 0.1567, lr_0 = 2.5346e-04
Loss = 4.1341e-05, PNorm = 46.7450, GNorm = 0.1580, lr_0 = 2.5312e-04
Loss = 3.5081e-05, PNorm = 46.7507, GNorm = 0.1160, lr_0 = 2.5278e-04
Loss = 3.3894e-05, PNorm = 46.7530, GNorm = 0.1200, lr_0 = 2.5244e-04
Loss = 3.5528e-05, PNorm = 46.7567, GNorm = 0.0855, lr_0 = 2.5210e-04
Loss = 3.1908e-05, PNorm = 46.7577, GNorm = 0.0856, lr_0 = 2.5176e-04
Loss = 3.0992e-05, PNorm = 46.7603, GNorm = 0.0920, lr_0 = 2.5142e-04
Loss = 3.6390e-05, PNorm = 46.7629, GNorm = 0.0690, lr_0 = 2.5109e-04
Loss = 4.0927e-05, PNorm = 46.7655, GNorm = 0.1125, lr_0 = 2.5075e-04
Loss = 2.9537e-05, PNorm = 46.7691, GNorm = 0.0979, lr_0 = 2.5041e-04
Loss = 4.5064e-05, PNorm = 46.7686, GNorm = 0.1604, lr_0 = 2.5008e-04
Loss = 4.1808e-05, PNorm = 46.7706, GNorm = 0.1656, lr_0 = 2.4974e-04
Loss = 3.6277e-05, PNorm = 46.7752, GNorm = 0.1826, lr_0 = 2.4941e-04
Loss = 4.0189e-05, PNorm = 46.7784, GNorm = 0.1100, lr_0 = 2.4907e-04
Loss = 4.6552e-05, PNorm = 46.7785, GNorm = 0.2013, lr_0 = 2.4874e-04
Loss = 4.5822e-05, PNorm = 46.7796, GNorm = 0.1838, lr_0 = 2.4841e-04
Loss = 4.2054e-05, PNorm = 46.7829, GNorm = 0.1117, lr_0 = 2.4807e-04
Validation rmse = 0.468888
Validation R2 = 0.935475
Epoch 61
Train function
Loss = 4.8088e-05, PNorm = 46.7858, GNorm = 0.1302, lr_0 = 2.4774e-04
Loss = 4.5849e-05, PNorm = 46.7889, GNorm = 0.1075, lr_0 = 2.4741e-04
Loss = 3.4775e-05, PNorm = 46.7915, GNorm = 0.1721, lr_0 = 2.4707e-04
Loss = 3.8201e-05, PNorm = 46.7926, GNorm = 0.0690, lr_0 = 2.4674e-04
Loss = 3.8842e-05, PNorm = 46.7958, GNorm = 0.0863, lr_0 = 2.4641e-04
Loss = 3.6941e-05, PNorm = 46.7970, GNorm = 0.0891, lr_0 = 2.4608e-04
Loss = 4.4843e-05, PNorm = 46.8002, GNorm = 0.2382, lr_0 = 2.4575e-04
Loss = 4.2177e-05, PNorm = 46.8029, GNorm = 0.2139, lr_0 = 2.4542e-04
Loss = 4.3559e-05, PNorm = 46.8053, GNorm = 0.2457, lr_0 = 2.4509e-04
Loss = 3.9351e-05, PNorm = 46.8067, GNorm = 0.2322, lr_0 = 2.4476e-04
Loss = 3.6558e-05, PNorm = 46.8098, GNorm = 0.1035, lr_0 = 2.4443e-04
Loss = 4.6970e-05, PNorm = 46.8128, GNorm = 0.0994, lr_0 = 2.4411e-04
Loss = 3.6936e-05, PNorm = 46.8152, GNorm = 0.1001, lr_0 = 2.4378e-04
Loss = 3.5147e-05, PNorm = 46.8161, GNorm = 0.1062, lr_0 = 2.4345e-04
Loss = 3.2299e-05, PNorm = 46.8186, GNorm = 0.0999, lr_0 = 2.4313e-04
Loss = 3.5361e-05, PNorm = 46.8207, GNorm = 0.1964, lr_0 = 2.4280e-04
Loss = 3.5219e-05, PNorm = 46.8200, GNorm = 0.1210, lr_0 = 2.4247e-04
Validation rmse = 0.471166
Validation R2 = 0.934847
Epoch 62
Train function
Loss = 3.3215e-05, PNorm = 46.8232, GNorm = 0.0920, lr_0 = 2.4212e-04
Loss = 3.3929e-05, PNorm = 46.8232, GNorm = 0.1735, lr_0 = 2.4179e-04
Loss = 3.2816e-05, PNorm = 46.8263, GNorm = 0.0928, lr_0 = 2.4147e-04
Loss = 3.2971e-05, PNorm = 46.8286, GNorm = 0.0896, lr_0 = 2.4114e-04
Loss = 3.4079e-05, PNorm = 46.8306, GNorm = 0.1484, lr_0 = 2.4082e-04
Loss = 3.3096e-05, PNorm = 46.8335, GNorm = 0.1464, lr_0 = 2.4050e-04
Loss = 3.2489e-05, PNorm = 46.8353, GNorm = 0.1000, lr_0 = 2.4017e-04
Loss = 3.1915e-05, PNorm = 46.8368, GNorm = 0.0851, lr_0 = 2.3985e-04
Loss = 3.8725e-05, PNorm = 46.8390, GNorm = 0.0702, lr_0 = 2.3953e-04
Loss = 3.9714e-05, PNorm = 46.8416, GNorm = 0.0836, lr_0 = 2.3921e-04
Loss = 4.8065e-05, PNorm = 46.8439, GNorm = 0.2810, lr_0 = 2.3889e-04
Loss = 3.6524e-05, PNorm = 46.8479, GNorm = 0.2755, lr_0 = 2.3857e-04
Loss = 4.4280e-05, PNorm = 46.8463, GNorm = 0.1078, lr_0 = 2.3825e-04
Loss = 3.5226e-05, PNorm = 46.8478, GNorm = 0.2121, lr_0 = 2.3793e-04
Loss = 3.7710e-05, PNorm = 46.8504, GNorm = 0.1713, lr_0 = 2.3761e-04
Loss = 4.5988e-05, PNorm = 46.8542, GNorm = 0.2464, lr_0 = 2.3729e-04
Loss = 4.1382e-05, PNorm = 46.8571, GNorm = 0.1667, lr_0 = 2.3697e-04
Loss = 4.5931e-05, PNorm = 46.8591, GNorm = 0.1732, lr_0 = 2.3665e-04
Validation rmse = 0.470075
Validation R2 = 0.935148
Epoch 63
Train function
Loss = 3.2993e-05, PNorm = 46.8641, GNorm = 0.1503, lr_0 = 2.3633e-04
Loss = 3.3781e-05, PNorm = 46.8672, GNorm = 0.0956, lr_0 = 2.3602e-04
Loss = 2.7783e-05, PNorm = 46.8681, GNorm = 0.1119, lr_0 = 2.3570e-04
Loss = 2.9149e-05, PNorm = 46.8691, GNorm = 0.1210, lr_0 = 2.3538e-04
Loss = 2.6779e-05, PNorm = 46.8706, GNorm = 0.1370, lr_0 = 2.3507e-04
Loss = 3.6603e-05, PNorm = 46.8733, GNorm = 0.1841, lr_0 = 2.3475e-04
Loss = 3.9068e-05, PNorm = 46.8759, GNorm = 0.3612, lr_0 = 2.3444e-04
Loss = 4.7335e-05, PNorm = 46.8799, GNorm = 0.3102, lr_0 = 2.3412e-04
Loss = 3.6144e-05, PNorm = 46.8824, GNorm = 0.1234, lr_0 = 2.3381e-04
Loss = 3.9964e-05, PNorm = 46.8842, GNorm = 0.2861, lr_0 = 2.3350e-04
Loss = 3.4535e-05, PNorm = 46.8863, GNorm = 0.1253, lr_0 = 2.3318e-04
Loss = 2.9966e-05, PNorm = 46.8908, GNorm = 0.1074, lr_0 = 2.3287e-04
Loss = 3.5872e-05, PNorm = 46.8929, GNorm = 0.1166, lr_0 = 2.3256e-04
Loss = 3.1889e-05, PNorm = 46.8946, GNorm = 0.1604, lr_0 = 2.3225e-04
Loss = 3.4539e-05, PNorm = 46.8950, GNorm = 0.1220, lr_0 = 2.3193e-04
Loss = 4.3189e-05, PNorm = 46.8957, GNorm = 0.1511, lr_0 = 2.3162e-04
Loss = 3.4828e-05, PNorm = 46.8995, GNorm = 0.1329, lr_0 = 2.3131e-04
Loss = 3.3572e-05, PNorm = 46.9041, GNorm = 0.0883, lr_0 = 2.3100e-04
Loss = 3.0745e-05, PNorm = 46.9043, GNorm = 0.1744, lr_0 = 2.3097e-04
Validation rmse = 0.469778
Validation R2 = 0.935230
Epoch 64
Train function
Loss = 3.1905e-05, PNorm = 46.9056, GNorm = 0.1428, lr_0 = 2.3066e-04
Loss = 3.5389e-05, PNorm = 46.9077, GNorm = 0.2701, lr_0 = 2.3035e-04
Loss = 5.2568e-05, PNorm = 46.9100, GNorm = 0.3167, lr_0 = 2.3004e-04
Loss = 5.1663e-05, PNorm = 46.9131, GNorm = 0.2093, lr_0 = 2.2973e-04
Loss = 3.7370e-05, PNorm = 46.9154, GNorm = 0.1441, lr_0 = 2.2943e-04
Loss = 3.0272e-05, PNorm = 46.9180, GNorm = 0.0778, lr_0 = 2.2912e-04
Loss = 2.9160e-05, PNorm = 46.9200, GNorm = 0.1046, lr_0 = 2.2881e-04
Loss = 3.7518e-05, PNorm = 46.9224, GNorm = 0.0852, lr_0 = 2.2850e-04
Loss = 3.3651e-05, PNorm = 46.9267, GNorm = 0.0920, lr_0 = 2.2820e-04
Loss = 3.2596e-05, PNorm = 46.9278, GNorm = 0.1291, lr_0 = 2.2789e-04
Loss = 3.1310e-05, PNorm = 46.9296, GNorm = 0.0998, lr_0 = 2.2758e-04
Loss = 3.5464e-05, PNorm = 46.9314, GNorm = 0.2596, lr_0 = 2.2728e-04
Loss = 3.6220e-05, PNorm = 46.9322, GNorm = 0.3861, lr_0 = 2.2697e-04
Loss = 3.2729e-05, PNorm = 46.9349, GNorm = 0.1071, lr_0 = 2.2667e-04
Loss = 3.4692e-05, PNorm = 46.9379, GNorm = 0.0921, lr_0 = 2.2637e-04
Loss = 2.6046e-05, PNorm = 46.9405, GNorm = 0.0761, lr_0 = 2.2606e-04
Loss = 3.2430e-05, PNorm = 46.9411, GNorm = 0.1010, lr_0 = 2.2576e-04
Validation rmse = 0.467023
Validation R2 = 0.935988
Epoch 65
Train function
Loss = 3.6675e-05, PNorm = 46.9430, GNorm = 0.1247, lr_0 = 2.2546e-04
Loss = 2.8334e-05, PNorm = 46.9461, GNorm = 0.1051, lr_0 = 2.2515e-04
Loss = 2.9815e-05, PNorm = 46.9480, GNorm = 0.1920, lr_0 = 2.2485e-04
Loss = 2.7347e-05, PNorm = 46.9500, GNorm = 0.1438, lr_0 = 2.2455e-04
Loss = 2.8728e-05, PNorm = 46.9529, GNorm = 0.1015, lr_0 = 2.2425e-04
Loss = 2.4325e-05, PNorm = 46.9541, GNorm = 0.1264, lr_0 = 2.2395e-04
Loss = 4.1527e-05, PNorm = 46.9564, GNorm = 0.2485, lr_0 = 2.2365e-04
Loss = 3.4104e-05, PNorm = 46.9586, GNorm = 0.0992, lr_0 = 2.2335e-04
Loss = 2.8962e-05, PNorm = 46.9603, GNorm = 0.2558, lr_0 = 2.2305e-04
Loss = 3.0452e-05, PNorm = 46.9629, GNorm = 0.2495, lr_0 = 2.2275e-04
Loss = 3.4358e-05, PNorm = 46.9667, GNorm = 0.1287, lr_0 = 2.2245e-04
Loss = 3.3571e-05, PNorm = 46.9696, GNorm = 0.2429, lr_0 = 2.2215e-04
Loss = 3.7007e-05, PNorm = 46.9731, GNorm = 0.1862, lr_0 = 2.2185e-04
Loss = 2.7015e-05, PNorm = 46.9753, GNorm = 0.0687, lr_0 = 2.2155e-04
Loss = 3.1621e-05, PNorm = 46.9763, GNorm = 0.0912, lr_0 = 2.2126e-04
Loss = 3.6551e-05, PNorm = 46.9777, GNorm = 0.1491, lr_0 = 2.2096e-04
Loss = 4.0041e-05, PNorm = 46.9818, GNorm = 0.1461, lr_0 = 2.2066e-04
Loss = 4.2130e-05, PNorm = 46.9839, GNorm = 0.3668, lr_0 = 2.2037e-04
Validation rmse = 0.467214
Validation R2 = 0.935935
Epoch 66
Train function
Loss = 5.3971e-05, PNorm = 46.9862, GNorm = 0.3792, lr_0 = 2.2007e-04
Loss = 5.1163e-05, PNorm = 46.9872, GNorm = 0.1603, lr_0 = 2.1978e-04
Loss = 3.7436e-05, PNorm = 46.9893, GNorm = 0.1504, lr_0 = 2.1948e-04
Loss = 3.6189e-05, PNorm = 46.9905, GNorm = 0.1065, lr_0 = 2.1919e-04
Loss = 3.7248e-05, PNorm = 46.9938, GNorm = 0.0985, lr_0 = 2.1889e-04
Loss = 3.1990e-05, PNorm = 46.9957, GNorm = 0.1174, lr_0 = 2.1860e-04
Loss = 2.8741e-05, PNorm = 46.9992, GNorm = 0.0716, lr_0 = 2.1831e-04
Loss = 2.8942e-05, PNorm = 47.0008, GNorm = 0.0764, lr_0 = 2.1801e-04
Loss = 3.4042e-05, PNorm = 47.0047, GNorm = 0.0986, lr_0 = 2.1772e-04
Loss = 3.7185e-05, PNorm = 47.0067, GNorm = 0.2296, lr_0 = 2.1743e-04
Loss = 4.5889e-05, PNorm = 47.0086, GNorm = 0.2714, lr_0 = 2.1714e-04
Loss = 3.3981e-05, PNorm = 47.0115, GNorm = 0.1203, lr_0 = 2.1685e-04
Loss = 3.8034e-05, PNorm = 47.0132, GNorm = 0.1648, lr_0 = 2.1656e-04
Loss = 3.3708e-05, PNorm = 47.0147, GNorm = 0.0943, lr_0 = 2.1626e-04
Loss = 3.4779e-05, PNorm = 47.0152, GNorm = 0.1969, lr_0 = 2.1597e-04
Loss = 4.0182e-05, PNorm = 47.0160, GNorm = 0.1208, lr_0 = 2.1568e-04
Loss = 3.4356e-05, PNorm = 47.0182, GNorm = 0.1827, lr_0 = 2.1540e-04
Validation rmse = 0.467420
Validation R2 = 0.935879
Epoch 67
Train function
Loss = 2.6549e-05, PNorm = 47.0211, GNorm = 0.0689, lr_0 = 2.1508e-04
Loss = 2.9890e-05, PNorm = 47.0244, GNorm = 0.2505, lr_0 = 2.1479e-04
Loss = 3.4793e-05, PNorm = 47.0261, GNorm = 0.2247, lr_0 = 2.1450e-04
Loss = 3.6021e-05, PNorm = 47.0260, GNorm = 0.2666, lr_0 = 2.1421e-04
Loss = 4.7441e-05, PNorm = 47.0294, GNorm = 0.2404, lr_0 = 2.1393e-04
Loss = 4.3217e-05, PNorm = 47.0335, GNorm = 0.2392, lr_0 = 2.1364e-04
Loss = 4.5309e-05, PNorm = 47.0372, GNorm = 0.2116, lr_0 = 2.1335e-04
Loss = 3.4370e-05, PNorm = 47.0396, GNorm = 0.1245, lr_0 = 2.1307e-04
Loss = 3.0101e-05, PNorm = 47.0394, GNorm = 0.0598, lr_0 = 2.1278e-04
Loss = 3.1792e-05, PNorm = 47.0407, GNorm = 0.1006, lr_0 = 2.1249e-04
Loss = 3.9976e-05, PNorm = 47.0432, GNorm = 0.1430, lr_0 = 2.1221e-04
Loss = 3.2748e-05, PNorm = 47.0458, GNorm = 0.1977, lr_0 = 2.1192e-04
Loss = 2.5503e-05, PNorm = 47.0478, GNorm = 0.0894, lr_0 = 2.1164e-04
Loss = 2.9963e-05, PNorm = 47.0492, GNorm = 0.1923, lr_0 = 2.1136e-04
Loss = 3.2959e-05, PNorm = 47.0511, GNorm = 0.1481, lr_0 = 2.1107e-04
Loss = 3.2645e-05, PNorm = 47.0528, GNorm = 0.0741, lr_0 = 2.1079e-04
Loss = 3.1171e-05, PNorm = 47.0542, GNorm = 0.2429, lr_0 = 2.1051e-04
Loss = 3.6450e-05, PNorm = 47.0565, GNorm = 0.1624, lr_0 = 2.1022e-04
Validation rmse = 0.466180
Validation R2 = 0.936219
Epoch 68
Train function
Loss = 2.0786e-05, PNorm = 47.0597, GNorm = 0.0818, lr_0 = 2.0994e-04
Loss = 2.7510e-05, PNorm = 47.0606, GNorm = 0.1417, lr_0 = 2.0966e-04
Loss = 2.6760e-05, PNorm = 47.0622, GNorm = 0.2126, lr_0 = 2.0938e-04
Loss = 3.2731e-05, PNorm = 47.0653, GNorm = 0.1657, lr_0 = 2.0910e-04
Loss = 3.6147e-05, PNorm = 47.0668, GNorm = 0.0878, lr_0 = 2.0882e-04
Loss = 3.1929e-05, PNorm = 47.0694, GNorm = 0.1977, lr_0 = 2.0854e-04
Loss = 2.7844e-05, PNorm = 47.0718, GNorm = 0.1044, lr_0 = 2.0826e-04
Loss = 3.0116e-05, PNorm = 47.0731, GNorm = 0.1389, lr_0 = 2.0798e-04
Loss = 2.9257e-05, PNorm = 47.0742, GNorm = 0.0868, lr_0 = 2.0770e-04
Loss = 2.5536e-05, PNorm = 47.0751, GNorm = 0.0789, lr_0 = 2.0742e-04
Loss = 3.7952e-05, PNorm = 47.0750, GNorm = 0.1360, lr_0 = 2.0714e-04
Loss = 3.3971e-05, PNorm = 47.0777, GNorm = 0.1008, lr_0 = 2.0686e-04
Loss = 2.5880e-05, PNorm = 47.0786, GNorm = 0.0974, lr_0 = 2.0659e-04
Loss = 2.7581e-05, PNorm = 47.0791, GNorm = 0.0882, lr_0 = 2.0631e-04
Loss = 3.1285e-05, PNorm = 47.0823, GNorm = 0.1557, lr_0 = 2.0603e-04
Loss = 3.3309e-05, PNorm = 47.0853, GNorm = 0.1667, lr_0 = 2.0576e-04
Loss = 3.4104e-05, PNorm = 47.0870, GNorm = 0.1057, lr_0 = 2.0548e-04
Validation rmse = 0.466703
Validation R2 = 0.936075
Epoch 69
Train function
Loss = 2.9698e-05, PNorm = 47.0897, GNorm = 0.1384, lr_0 = 2.0520e-04
Loss = 2.7387e-05, PNorm = 47.0917, GNorm = 0.1714, lr_0 = 2.0493e-04
Loss = 2.6060e-05, PNorm = 47.0942, GNorm = 0.0982, lr_0 = 2.0465e-04
Loss = 2.7241e-05, PNorm = 47.0967, GNorm = 0.0611, lr_0 = 2.0438e-04
Loss = 2.5716e-05, PNorm = 47.0978, GNorm = 0.1281, lr_0 = 2.0411e-04
Loss = 2.5171e-05, PNorm = 47.0994, GNorm = 0.1294, lr_0 = 2.0383e-04
Loss = 2.0144e-05, PNorm = 47.1002, GNorm = 0.1386, lr_0 = 2.0356e-04
Loss = 2.2542e-05, PNorm = 47.1008, GNorm = 0.1224, lr_0 = 2.0328e-04
Loss = 2.5387e-05, PNorm = 47.1031, GNorm = 0.2264, lr_0 = 2.0301e-04
Loss = 2.4836e-05, PNorm = 47.1043, GNorm = 0.1158, lr_0 = 2.0274e-04
Loss = 3.0398e-05, PNorm = 47.1051, GNorm = 0.0554, lr_0 = 2.0247e-04
Loss = 3.5586e-05, PNorm = 47.1063, GNorm = 0.4247, lr_0 = 2.0220e-04
Loss = 3.6155e-05, PNorm = 47.1089, GNorm = 0.2910, lr_0 = 2.0192e-04
Loss = 3.0388e-05, PNorm = 47.1105, GNorm = 0.1013, lr_0 = 2.0165e-04
Loss = 2.9835e-05, PNorm = 47.1113, GNorm = 0.2957, lr_0 = 2.0138e-04
Loss = 2.9335e-05, PNorm = 47.1120, GNorm = 0.0925, lr_0 = 2.0111e-04
Loss = 2.4124e-05, PNorm = 47.1140, GNorm = 0.0833, lr_0 = 2.0084e-04
Loss = 2.5553e-05, PNorm = 47.1156, GNorm = 0.1040, lr_0 = 2.0057e-04
Validation rmse = 0.466035
Validation R2 = 0.936258
Epoch 70
Train function
Loss = 2.4271e-05, PNorm = 47.1171, GNorm = 0.1630, lr_0 = 2.0028e-04
Loss = 2.6873e-05, PNorm = 47.1212, GNorm = 0.2259, lr_0 = 2.0001e-04
Loss = 2.2198e-05, PNorm = 47.1225, GNorm = 0.0754, lr_0 = 1.9974e-04
Loss = 2.3055e-05, PNorm = 47.1223, GNorm = 0.0761, lr_0 = 1.9947e-04
Loss = 3.0080e-05, PNorm = 47.1236, GNorm = 0.0737, lr_0 = 1.9921e-04
Loss = 2.9908e-05, PNorm = 47.1249, GNorm = 0.1084, lr_0 = 1.9894e-04
Loss = 2.5789e-05, PNorm = 47.1271, GNorm = 0.0648, lr_0 = 1.9867e-04
Loss = 2.3253e-05, PNorm = 47.1283, GNorm = 0.0935, lr_0 = 1.9840e-04
Loss = 2.4915e-05, PNorm = 47.1306, GNorm = 0.1755, lr_0 = 1.9814e-04
Loss = 2.3533e-05, PNorm = 47.1334, GNorm = 0.1248, lr_0 = 1.9787e-04
Loss = 2.3987e-05, PNorm = 47.1348, GNorm = 0.1625, lr_0 = 1.9761e-04
Loss = 2.8200e-05, PNorm = 47.1363, GNorm = 0.2125, lr_0 = 1.9734e-04
Loss = 2.8446e-05, PNorm = 47.1359, GNorm = 0.1256, lr_0 = 1.9708e-04
Loss = 3.1097e-05, PNorm = 47.1377, GNorm = 0.1994, lr_0 = 1.9681e-04
Loss = 2.6831e-05, PNorm = 47.1412, GNorm = 0.1074, lr_0 = 1.9655e-04
Loss = 2.3220e-05, PNorm = 47.1439, GNorm = 0.0572, lr_0 = 1.9628e-04
Loss = 2.4669e-05, PNorm = 47.1475, GNorm = 0.0916, lr_0 = 1.9602e-04
Loss = 2.5978e-05, PNorm = 47.1478, GNorm = 0.1883, lr_0 = 1.9576e-04
Validation rmse = 0.467885
Validation R2 = 0.935751
Epoch 71
Train function
Loss = 2.3610e-05, PNorm = 47.1476, GNorm = 0.0939, lr_0 = 1.9550e-04
Loss = 1.9418e-05, PNorm = 47.1480, GNorm = 0.1688, lr_0 = 1.9523e-04
Loss = 1.6047e-05, PNorm = 47.1494, GNorm = 0.0549, lr_0 = 1.9497e-04
Loss = 2.1308e-05, PNorm = 47.1520, GNorm = 0.2608, lr_0 = 1.9471e-04
Loss = 2.1866e-05, PNorm = 47.1535, GNorm = 0.1336, lr_0 = 1.9445e-04
Loss = 2.4535e-05, PNorm = 47.1571, GNorm = 0.1229, lr_0 = 1.9419e-04
Loss = 3.0655e-05, PNorm = 47.1578, GNorm = 0.0698, lr_0 = 1.9393e-04
Loss = 2.1969e-05, PNorm = 47.1585, GNorm = 0.0766, lr_0 = 1.9367e-04
Loss = 2.2786e-05, PNorm = 47.1592, GNorm = 0.0817, lr_0 = 1.9341e-04
Loss = 2.3089e-05, PNorm = 47.1596, GNorm = 0.2232, lr_0 = 1.9315e-04
Loss = 2.4440e-05, PNorm = 47.1615, GNorm = 0.0649, lr_0 = 1.9289e-04
Loss = 2.2035e-05, PNorm = 47.1624, GNorm = 0.1378, lr_0 = 1.9263e-04
Loss = 3.1581e-05, PNorm = 47.1645, GNorm = 0.2486, lr_0 = 1.9237e-04
Loss = 3.8249e-05, PNorm = 47.1673, GNorm = 0.3013, lr_0 = 1.9211e-04
Loss = 2.7005e-05, PNorm = 47.1704, GNorm = 0.1660, lr_0 = 1.9186e-04
Loss = 2.4690e-05, PNorm = 47.1734, GNorm = 0.1030, lr_0 = 1.9160e-04
Loss = 2.6482e-05, PNorm = 47.1749, GNorm = 0.0801, lr_0 = 1.9134e-04
Validation rmse = 0.465405
Validation R2 = 0.936430
Epoch 72
Train function
Loss = 2.7212e-05, PNorm = 47.1764, GNorm = 0.1408, lr_0 = 1.9108e-04
Loss = 2.2604e-05, PNorm = 47.1780, GNorm = 0.0949, lr_0 = 1.9083e-04
Loss = 2.2156e-05, PNorm = 47.1786, GNorm = 0.2875, lr_0 = 1.9057e-04
Loss = 2.4337e-05, PNorm = 47.1798, GNorm = 0.0880, lr_0 = 1.9032e-04
Loss = 2.4505e-05, PNorm = 47.1825, GNorm = 0.0802, lr_0 = 1.9006e-04
Loss = 2.2541e-05, PNorm = 47.1828, GNorm = 0.0651, lr_0 = 1.8981e-04
Loss = 1.8738e-05, PNorm = 47.1824, GNorm = 0.1266, lr_0 = 1.8955e-04
Loss = 2.8326e-05, PNorm = 47.1845, GNorm = 0.3157, lr_0 = 1.8930e-04
Loss = 2.4211e-05, PNorm = 47.1853, GNorm = 0.2310, lr_0 = 1.8904e-04
Loss = 3.7381e-05, PNorm = 47.1878, GNorm = 0.2150, lr_0 = 1.8879e-04
Loss = 3.5531e-05, PNorm = 47.1883, GNorm = 0.1910, lr_0 = 1.8854e-04
Loss = 3.9205e-05, PNorm = 47.1891, GNorm = 0.3273, lr_0 = 1.8828e-04
Loss = 3.2397e-05, PNorm = 47.1910, GNorm = 0.1919, lr_0 = 1.8803e-04
Loss = 2.8679e-05, PNorm = 47.1944, GNorm = 0.1103, lr_0 = 1.8778e-04
Loss = 2.6147e-05, PNorm = 47.1985, GNorm = 0.1055, lr_0 = 1.8753e-04
Loss = 2.2739e-05, PNorm = 47.2001, GNorm = 0.0951, lr_0 = 1.8727e-04
Loss = 2.3272e-05, PNorm = 47.2017, GNorm = 0.1140, lr_0 = 1.8702e-04
Loss = 2.4566e-05, PNorm = 47.2015, GNorm = 0.1477, lr_0 = 1.8677e-04
Validation rmse = 0.464786
Validation R2 = 0.936599
Epoch 73
Train function
Loss = 2.9823e-05, PNorm = 47.2030, GNorm = 0.0895, lr_0 = 1.8650e-04
Loss = 2.4059e-05, PNorm = 47.2041, GNorm = 0.1760, lr_0 = 1.8625e-04
Loss = 2.5118e-05, PNorm = 47.2056, GNorm = 0.1435, lr_0 = 1.8600e-04
Loss = 2.2040e-05, PNorm = 47.2084, GNorm = 0.1585, lr_0 = 1.8575e-04
Loss = 2.4560e-05, PNorm = 47.2076, GNorm = 0.1117, lr_0 = 1.8550e-04
Loss = 2.1321e-05, PNorm = 47.2094, GNorm = 0.1169, lr_0 = 1.8525e-04
Loss = 2.6462e-05, PNorm = 47.2115, GNorm = 0.0652, lr_0 = 1.8500e-04
Loss = 2.8080e-05, PNorm = 47.2125, GNorm = 0.1203, lr_0 = 1.8475e-04
Loss = 2.7711e-05, PNorm = 47.2163, GNorm = 0.0689, lr_0 = 1.8450e-04
Loss = 2.5288e-05, PNorm = 47.2188, GNorm = 0.1432, lr_0 = 1.8426e-04
Loss = 2.5466e-05, PNorm = 47.2202, GNorm = 0.1307, lr_0 = 1.8401e-04
Loss = 1.9191e-05, PNorm = 47.2214, GNorm = 0.1061, lr_0 = 1.8376e-04
Loss = 2.7038e-05, PNorm = 47.2238, GNorm = 0.0929, lr_0 = 1.8352e-04
Loss = 2.1005e-05, PNorm = 47.2234, GNorm = 0.0835, lr_0 = 1.8327e-04
Loss = 1.7969e-05, PNorm = 47.2222, GNorm = 0.1156, lr_0 = 1.8302e-04
Loss = 1.9515e-05, PNorm = 47.2245, GNorm = 0.1669, lr_0 = 1.8278e-04
Loss = 2.0615e-05, PNorm = 47.2267, GNorm = 0.0587, lr_0 = 1.8253e-04
Validation rmse = 0.464929
Validation R2 = 0.936560
Epoch 74
Train function
Loss = 1.7689e-05, PNorm = 47.2277, GNorm = 0.1393, lr_0 = 1.8229e-04
Loss = 1.8679e-05, PNorm = 47.2292, GNorm = 0.0773, lr_0 = 1.8204e-04
Loss = 1.6513e-05, PNorm = 47.2310, GNorm = 0.0874, lr_0 = 1.8180e-04
Loss = 1.6381e-05, PNorm = 47.2321, GNorm = 0.1020, lr_0 = 1.8156e-04
Loss = 1.9735e-05, PNorm = 47.2330, GNorm = 0.0875, lr_0 = 1.8131e-04
Loss = 1.9029e-05, PNorm = 47.2340, GNorm = 0.0663, lr_0 = 1.8107e-04
Loss = 1.6680e-05, PNorm = 47.2338, GNorm = 0.1363, lr_0 = 1.8083e-04
Loss = 1.8444e-05, PNorm = 47.2352, GNorm = 0.1190, lr_0 = 1.8058e-04
Loss = 2.1984e-05, PNorm = 47.2349, GNorm = 0.0633, lr_0 = 1.8034e-04
Loss = 2.3723e-05, PNorm = 47.2361, GNorm = 0.2252, lr_0 = 1.8010e-04
Loss = 2.2437e-05, PNorm = 47.2381, GNorm = 0.1349, lr_0 = 1.7986e-04
Loss = 2.5403e-05, PNorm = 47.2400, GNorm = 0.1420, lr_0 = 1.7962e-04
Loss = 2.3600e-05, PNorm = 47.2410, GNorm = 0.1155, lr_0 = 1.7937e-04
Loss = 2.4413e-05, PNorm = 47.2440, GNorm = 0.0685, lr_0 = 1.7913e-04
Loss = 2.4204e-05, PNorm = 47.2454, GNorm = 0.1338, lr_0 = 1.7889e-04
Loss = 2.3146e-05, PNorm = 47.2469, GNorm = 0.0962, lr_0 = 1.7865e-04
Loss = 2.1793e-05, PNorm = 47.2493, GNorm = 0.0860, lr_0 = 1.7841e-04
Loss = 2.4565e-05, PNorm = 47.2495, GNorm = 0.0808, lr_0 = 1.7817e-04
Validation rmse = 0.469075
Validation R2 = 0.935424
Epoch 75
Train function
Loss = 2.1255e-05, PNorm = 47.2506, GNorm = 0.1773, lr_0 = 1.7794e-04
Loss = 1.6840e-05, PNorm = 47.2523, GNorm = 0.0810, lr_0 = 1.7770e-04
Loss = 1.8100e-05, PNorm = 47.2545, GNorm = 0.1546, lr_0 = 1.7746e-04
Loss = 2.0942e-05, PNorm = 47.2546, GNorm = 0.2781, lr_0 = 1.7722e-04
Loss = 2.3050e-05, PNorm = 47.2566, GNorm = 0.2678, lr_0 = 1.7698e-04
Loss = 1.8368e-05, PNorm = 47.2592, GNorm = 0.1275, lr_0 = 1.7674e-04
Loss = 2.3951e-05, PNorm = 47.2593, GNorm = 0.2527, lr_0 = 1.7651e-04
Loss = 1.9648e-05, PNorm = 47.2599, GNorm = 0.1387, lr_0 = 1.7627e-04
Loss = 1.6716e-05, PNorm = 47.2622, GNorm = 0.0570, lr_0 = 1.7603e-04
Loss = 1.6659e-05, PNorm = 47.2631, GNorm = 0.0675, lr_0 = 1.7580e-04
Loss = 2.2090e-05, PNorm = 47.2631, GNorm = 0.1060, lr_0 = 1.7556e-04
Loss = 2.1690e-05, PNorm = 47.2643, GNorm = 0.2080, lr_0 = 1.7533e-04
Loss = 2.0008e-05, PNorm = 47.2649, GNorm = 0.1098, lr_0 = 1.7509e-04
Loss = 2.0186e-05, PNorm = 47.2654, GNorm = 0.0890, lr_0 = 1.7486e-04
Loss = 2.0509e-05, PNorm = 47.2683, GNorm = 0.1356, lr_0 = 1.7462e-04
Loss = 2.0300e-05, PNorm = 47.2701, GNorm = 0.0631, lr_0 = 1.7439e-04
Loss = 2.5309e-05, PNorm = 47.2732, GNorm = 0.1599, lr_0 = 1.7415e-04
Validation rmse = 0.469607
Validation R2 = 0.935277
Epoch 76
Train function
Loss = 1.8128e-05, PNorm = 47.2735, GNorm = 0.1398, lr_0 = 1.7390e-04
Loss = 2.5654e-05, PNorm = 47.2736, GNorm = 0.1176, lr_0 = 1.7366e-04
Loss = 1.8676e-05, PNorm = 47.2752, GNorm = 0.0749, lr_0 = 1.7343e-04
Loss = 1.8632e-05, PNorm = 47.2756, GNorm = 0.0814, lr_0 = 1.7320e-04
Loss = 1.5534e-05, PNorm = 47.2780, GNorm = 0.1256, lr_0 = 1.7297e-04
Loss = 1.7382e-05, PNorm = 47.2785, GNorm = 0.1349, lr_0 = 1.7273e-04
Loss = 1.8097e-05, PNorm = 47.2797, GNorm = 0.1171, lr_0 = 1.7250e-04
Loss = 1.6454e-05, PNorm = 47.2799, GNorm = 0.0709, lr_0 = 1.7227e-04
Loss = 1.8391e-05, PNorm = 47.2821, GNorm = 0.0965, lr_0 = 1.7204e-04
Loss = 1.8372e-05, PNorm = 47.2839, GNorm = 0.1642, lr_0 = 1.7181e-04
Loss = 2.0139e-05, PNorm = 47.2863, GNorm = 0.1402, lr_0 = 1.7158e-04
Loss = 1.5999e-05, PNorm = 47.2871, GNorm = 0.0733, lr_0 = 1.7135e-04
Loss = 1.6125e-05, PNorm = 47.2890, GNorm = 0.0801, lr_0 = 1.7112e-04
Loss = 2.0078e-05, PNorm = 47.2915, GNorm = 0.1094, lr_0 = 1.7089e-04
Loss = 2.6499e-05, PNorm = 47.2924, GNorm = 0.2626, lr_0 = 1.7066e-04
Loss = 2.5563e-05, PNorm = 47.2951, GNorm = 0.1401, lr_0 = 1.7043e-04
Loss = 2.5640e-05, PNorm = 47.2975, GNorm = 0.1010, lr_0 = 1.7020e-04
Loss = 2.6199e-05, PNorm = 47.2986, GNorm = 0.1461, lr_0 = 1.6997e-04
Validation rmse = 0.466002
Validation R2 = 0.936267
Epoch 77
Train function
Loss = 2.4360e-05, PNorm = 47.2998, GNorm = 0.1822, lr_0 = 1.6974e-04
Loss = 1.8682e-05, PNorm = 47.3022, GNorm = 0.0657, lr_0 = 1.6952e-04
Loss = 3.5779e-05, PNorm = 47.3045, GNorm = 0.2393, lr_0 = 1.6929e-04
Loss = 2.2280e-05, PNorm = 47.3063, GNorm = 0.1458, lr_0 = 1.6906e-04
Loss = 1.8208e-05, PNorm = 47.3075, GNorm = 0.0541, lr_0 = 1.6884e-04
Loss = 1.6131e-05, PNorm = 47.3088, GNorm = 0.0882, lr_0 = 1.6861e-04
Loss = 1.7990e-05, PNorm = 47.3107, GNorm = 0.0848, lr_0 = 1.6838e-04
Loss = 1.6845e-05, PNorm = 47.3134, GNorm = 0.0774, lr_0 = 1.6816e-04
Loss = 1.5963e-05, PNorm = 47.3137, GNorm = 0.0842, lr_0 = 1.6793e-04
Loss = 1.3332e-05, PNorm = 47.3146, GNorm = 0.0642, lr_0 = 1.6771e-04
Loss = 1.4695e-05, PNorm = 47.3143, GNorm = 0.0711, lr_0 = 1.6748e-04
Loss = 1.9715e-05, PNorm = 47.3145, GNorm = 0.0661, lr_0 = 1.6726e-04
Loss = 1.4343e-05, PNorm = 47.3157, GNorm = 0.0674, lr_0 = 1.6703e-04
Loss = 1.8521e-05, PNorm = 47.3159, GNorm = 0.0914, lr_0 = 1.6681e-04
Loss = 1.7239e-05, PNorm = 47.3160, GNorm = 0.1284, lr_0 = 1.6658e-04
Loss = 1.7151e-05, PNorm = 47.3168, GNorm = 0.0636, lr_0 = 1.6636e-04
Loss = 1.2320e-05, PNorm = 47.3190, GNorm = 0.0840, lr_0 = 1.6614e-04
Validation rmse = 0.468946
Validation R2 = 0.935459
Epoch 78
Train function
Loss = 2.0753e-05, PNorm = 47.3199, GNorm = 0.1722, lr_0 = 1.6589e-04
Loss = 2.2480e-05, PNorm = 47.3213, GNorm = 0.1288, lr_0 = 1.6567e-04
Loss = 1.7836e-05, PNorm = 47.3222, GNorm = 0.0678, lr_0 = 1.6545e-04
Loss = 1.6816e-05, PNorm = 47.3232, GNorm = 0.0826, lr_0 = 1.6523e-04
Loss = 1.4230e-05, PNorm = 47.3247, GNorm = 0.1486, lr_0 = 1.6500e-04
Loss = 1.2037e-05, PNorm = 47.3254, GNorm = 0.1195, lr_0 = 1.6478e-04
Loss = 1.2715e-05, PNorm = 47.3259, GNorm = 0.1235, lr_0 = 1.6456e-04
Loss = 1.4432e-05, PNorm = 47.3270, GNorm = 0.0510, lr_0 = 1.6434e-04
Loss = 1.9460e-05, PNorm = 47.3284, GNorm = 0.0702, lr_0 = 1.6412e-04
Loss = 1.9839e-05, PNorm = 47.3312, GNorm = 0.0772, lr_0 = 1.6390e-04
Loss = 2.2316e-05, PNorm = 47.3320, GNorm = 0.1108, lr_0 = 1.6368e-04
Loss = 2.3821e-05, PNorm = 47.3338, GNorm = 0.1912, lr_0 = 1.6346e-04
Loss = 2.3144e-05, PNorm = 47.3354, GNorm = 0.0777, lr_0 = 1.6324e-04
Loss = 1.6573e-05, PNorm = 47.3365, GNorm = 0.0654, lr_0 = 1.6302e-04
Loss = 2.0363e-05, PNorm = 47.3388, GNorm = 0.0644, lr_0 = 1.6280e-04
Loss = 2.2950e-05, PNorm = 47.3403, GNorm = 0.0895, lr_0 = 1.6258e-04
Loss = 2.4476e-05, PNorm = 47.3420, GNorm = 0.0862, lr_0 = 1.6237e-04
Loss = 1.9719e-05, PNorm = 47.3435, GNorm = 0.0543, lr_0 = 1.6215e-04
Validation rmse = 0.465244
Validation R2 = 0.936474
Epoch 79
Train function
Loss = 1.8068e-05, PNorm = 47.3444, GNorm = 0.1073, lr_0 = 1.6193e-04
Loss = 1.8476e-05, PNorm = 47.3448, GNorm = 0.1354, lr_0 = 1.6171e-04
Loss = 2.0207e-05, PNorm = 47.3468, GNorm = 0.1830, lr_0 = 1.6150e-04
Loss = 2.4704e-05, PNorm = 47.3494, GNorm = 0.1922, lr_0 = 1.6128e-04
Loss = 1.5284e-05, PNorm = 47.3511, GNorm = 0.1312, lr_0 = 1.6106e-04
Loss = 1.5839e-05, PNorm = 47.3522, GNorm = 0.0703, lr_0 = 1.6085e-04
Loss = 1.5676e-05, PNorm = 47.3515, GNorm = 0.0837, lr_0 = 1.6063e-04
Loss = 1.4064e-05, PNorm = 47.3517, GNorm = 0.0579, lr_0 = 1.6042e-04
Loss = 1.8742e-05, PNorm = 47.3525, GNorm = 0.0653, lr_0 = 1.6020e-04
Loss = 1.5351e-05, PNorm = 47.3542, GNorm = 0.0860, lr_0 = 1.5999e-04
Loss = 1.5076e-05, PNorm = 47.3549, GNorm = 0.0896, lr_0 = 1.5977e-04
Loss = 1.3442e-05, PNorm = 47.3565, GNorm = 0.1643, lr_0 = 1.5956e-04
Loss = 2.4035e-05, PNorm = 47.3593, GNorm = 0.3038, lr_0 = 1.5934e-04
Loss = 2.4748e-05, PNorm = 47.3607, GNorm = 0.0826, lr_0 = 1.5913e-04
Loss = 2.0362e-05, PNorm = 47.3626, GNorm = 0.0872, lr_0 = 1.5892e-04
Loss = 1.4815e-05, PNorm = 47.3644, GNorm = 0.1006, lr_0 = 1.5870e-04
Loss = 1.7818e-05, PNorm = 47.3654, GNorm = 0.0396, lr_0 = 1.5849e-04
Loss = 2.1305e-05, PNorm = 47.3660, GNorm = 0.0558, lr_0 = 1.5828e-04
Validation rmse = 0.468358
Validation R2 = 0.935621
Epoch 80
Train function
Loss = 1.7965e-05, PNorm = 47.3657, GNorm = 0.0809, lr_0 = 1.5806e-04
Loss = 3.0038e-05, PNorm = 47.3673, GNorm = 0.2835, lr_0 = 1.5785e-04
Loss = 2.8238e-05, PNorm = 47.3674, GNorm = 0.2151, lr_0 = 1.5764e-04
Loss = 2.5103e-05, PNorm = 47.3706, GNorm = 0.1828, lr_0 = 1.5743e-04
Loss = 1.9588e-05, PNorm = 47.3722, GNorm = 0.0840, lr_0 = 1.5722e-04
Loss = 1.7511e-05, PNorm = 47.3737, GNorm = 0.1907, lr_0 = 1.5701e-04
Loss = 1.7224e-05, PNorm = 47.3752, GNorm = 0.0561, lr_0 = 1.5680e-04
Loss = 1.5014e-05, PNorm = 47.3760, GNorm = 0.0545, lr_0 = 1.5659e-04
Loss = 1.6723e-05, PNorm = 47.3774, GNorm = 0.1449, lr_0 = 1.5638e-04
Loss = 1.8670e-05, PNorm = 47.3792, GNorm = 0.1196, lr_0 = 1.5617e-04
Loss = 1.9108e-05, PNorm = 47.3804, GNorm = 0.2321, lr_0 = 1.5596e-04
Loss = 2.0054e-05, PNorm = 47.3810, GNorm = 0.2276, lr_0 = 1.5575e-04
Loss = 2.6093e-05, PNorm = 47.3808, GNorm = 0.2120, lr_0 = 1.5554e-04
Loss = 2.5130e-05, PNorm = 47.3830, GNorm = 0.0980, lr_0 = 1.5533e-04
Loss = 1.9914e-05, PNorm = 47.3838, GNorm = 0.1465, lr_0 = 1.5512e-04
Loss = 1.8068e-05, PNorm = 47.3843, GNorm = 0.0839, lr_0 = 1.5491e-04
Loss = 2.2034e-05, PNorm = 47.3852, GNorm = 0.2176, lr_0 = 1.5471e-04
Validation rmse = 0.466829
Validation R2 = 0.936041
Epoch 81
Train function
Loss = 2.1416e-05, PNorm = 47.3890, GNorm = 0.1239, lr_0 = 1.5448e-04
Loss = 1.9381e-05, PNorm = 47.3901, GNorm = 0.2408, lr_0 = 1.5427e-04
Loss = 2.4175e-05, PNorm = 47.3922, GNorm = 0.1833, lr_0 = 1.5406e-04
Loss = 1.6382e-05, PNorm = 47.3940, GNorm = 0.0769, lr_0 = 1.5386e-04
Loss = 2.3748e-05, PNorm = 47.3959, GNorm = 0.0860, lr_0 = 1.5365e-04
Loss = 2.0318e-05, PNorm = 47.3997, GNorm = 0.0897, lr_0 = 1.5344e-04
Loss = 2.2264e-05, PNorm = 47.4012, GNorm = 0.1710, lr_0 = 1.5324e-04
Loss = 1.6897e-05, PNorm = 47.4013, GNorm = 0.0509, lr_0 = 1.5303e-04
Loss = 1.7796e-05, PNorm = 47.4038, GNorm = 0.0962, lr_0 = 1.5283e-04
Loss = 1.4805e-05, PNorm = 47.4061, GNorm = 0.0964, lr_0 = 1.5262e-04
Loss = 1.6900e-05, PNorm = 47.4076, GNorm = 0.0848, lr_0 = 1.5242e-04
Loss = 1.6162e-05, PNorm = 47.4077, GNorm = 0.1177, lr_0 = 1.5221e-04
Loss = 1.9202e-05, PNorm = 47.4080, GNorm = 0.1235, lr_0 = 1.5201e-04
Loss = 2.0016e-05, PNorm = 47.4095, GNorm = 0.1795, lr_0 = 1.5180e-04
Loss = 2.1105e-05, PNorm = 47.4098, GNorm = 0.1259, lr_0 = 1.5160e-04
Loss = 1.4802e-05, PNorm = 47.4117, GNorm = 0.0798, lr_0 = 1.5140e-04
Loss = 1.3635e-05, PNorm = 47.4132, GNorm = 0.0665, lr_0 = 1.5119e-04
Loss = 1.4143e-05, PNorm = 47.4136, GNorm = 0.1296, lr_0 = 1.5099e-04
Validation rmse = 0.468136
Validation R2 = 0.935682
Epoch 82
Train function
Loss = 2.5870e-05, PNorm = 47.4144, GNorm = 0.1273, lr_0 = 1.5079e-04
Loss = 1.0844e-05, PNorm = 47.4158, GNorm = 0.0476, lr_0 = 1.5059e-04
Loss = 1.1945e-05, PNorm = 47.4174, GNorm = 0.0843, lr_0 = 1.5038e-04
Loss = 1.5973e-05, PNorm = 47.4198, GNorm = 0.0741, lr_0 = 1.5018e-04
Loss = 1.8826e-05, PNorm = 47.4195, GNorm = 0.2130, lr_0 = 1.4998e-04
Loss = 1.3393e-05, PNorm = 47.4197, GNorm = 0.0478, lr_0 = 1.4978e-04
Loss = 1.2336e-05, PNorm = 47.4195, GNorm = 0.0673, lr_0 = 1.4958e-04
Loss = 1.3311e-05, PNorm = 47.4201, GNorm = 0.0770, lr_0 = 1.4938e-04
Loss = 1.3827e-05, PNorm = 47.4203, GNorm = 0.0630, lr_0 = 1.4918e-04
Loss = 1.4047e-05, PNorm = 47.4206, GNorm = 0.0877, lr_0 = 1.4898e-04
Loss = 1.4163e-05, PNorm = 47.4210, GNorm = 0.0733, lr_0 = 1.4878e-04
Loss = 1.4085e-05, PNorm = 47.4230, GNorm = 0.1006, lr_0 = 1.4858e-04
Loss = 1.5774e-05, PNorm = 47.4252, GNorm = 0.0526, lr_0 = 1.4838e-04
Loss = 1.4086e-05, PNorm = 47.4266, GNorm = 0.0818, lr_0 = 1.4818e-04
Loss = 1.3947e-05, PNorm = 47.4260, GNorm = 0.0530, lr_0 = 1.4798e-04
Loss = 1.7172e-05, PNorm = 47.4282, GNorm = 0.1276, lr_0 = 1.4778e-04
Loss = 1.3139e-05, PNorm = 47.4285, GNorm = 0.0744, lr_0 = 1.4758e-04
Validation rmse = 0.467248
Validation R2 = 0.935926
Epoch 83
Train function
Loss = 2.1243e-05, PNorm = 47.4282, GNorm = 0.1130, lr_0 = 1.4739e-04
Loss = 1.4794e-05, PNorm = 47.4297, GNorm = 0.1194, lr_0 = 1.4719e-04
Loss = 1.2875e-05, PNorm = 47.4305, GNorm = 0.1197, lr_0 = 1.4699e-04
Loss = 1.2127e-05, PNorm = 47.4317, GNorm = 0.0733, lr_0 = 1.4679e-04
Loss = 1.4224e-05, PNorm = 47.4331, GNorm = 0.0514, lr_0 = 1.4660e-04
Loss = 1.2006e-05, PNorm = 47.4338, GNorm = 0.1280, lr_0 = 1.4640e-04
Loss = 1.3698e-05, PNorm = 47.4345, GNorm = 0.0778, lr_0 = 1.4620e-04
Loss = 1.3592e-05, PNorm = 47.4349, GNorm = 0.2027, lr_0 = 1.4601e-04
Loss = 1.7098e-05, PNorm = 47.4355, GNorm = 0.1825, lr_0 = 1.4581e-04
Loss = 2.0235e-05, PNorm = 47.4368, GNorm = 0.1965, lr_0 = 1.4562e-04
Loss = 1.6800e-05, PNorm = 47.4383, GNorm = 0.0617, lr_0 = 1.4542e-04
Loss = 1.5602e-05, PNorm = 47.4390, GNorm = 0.0538, lr_0 = 1.4522e-04
Loss = 1.8083e-05, PNorm = 47.4407, GNorm = 0.1121, lr_0 = 1.4503e-04
Loss = 1.9262e-05, PNorm = 47.4409, GNorm = 0.1568, lr_0 = 1.4484e-04
Loss = 1.7264e-05, PNorm = 47.4428, GNorm = 0.1565, lr_0 = 1.4464e-04
Loss = 1.3685e-05, PNorm = 47.4437, GNorm = 0.0802, lr_0 = 1.4445e-04
Loss = 1.6071e-05, PNorm = 47.4448, GNorm = 0.1305, lr_0 = 1.4425e-04
Loss = 1.2822e-05, PNorm = 47.4456, GNorm = 0.0736, lr_0 = 1.4406e-04
Validation rmse = 0.467137
Validation R2 = 0.935956
Epoch 84
Train function
Loss = 1.2384e-05, PNorm = 47.4464, GNorm = 0.0563, lr_0 = 1.4385e-04
Loss = 1.1575e-05, PNorm = 47.4480, GNorm = 0.0513, lr_0 = 1.4365e-04
Loss = 1.1009e-05, PNorm = 47.4483, GNorm = 0.0532, lr_0 = 1.4346e-04
Loss = 1.1243e-05, PNorm = 47.4491, GNorm = 0.0727, lr_0 = 1.4327e-04
Loss = 1.3035e-05, PNorm = 47.4505, GNorm = 0.0548, lr_0 = 1.4308e-04
Loss = 9.8109e-06, PNorm = 47.4509, GNorm = 0.1056, lr_0 = 1.4288e-04
Loss = 1.3245e-05, PNorm = 47.4507, GNorm = 0.1750, lr_0 = 1.4269e-04
Loss = 1.3548e-05, PNorm = 47.4516, GNorm = 0.1472, lr_0 = 1.4250e-04
Loss = 1.0733e-05, PNorm = 47.4532, GNorm = 0.0467, lr_0 = 1.4231e-04
Loss = 1.4281e-05, PNorm = 47.4539, GNorm = 0.0953, lr_0 = 1.4212e-04
Loss = 2.1887e-05, PNorm = 47.4555, GNorm = 0.1641, lr_0 = 1.4193e-04
Loss = 1.4264e-05, PNorm = 47.4574, GNorm = 0.1416, lr_0 = 1.4174e-04
Loss = 1.4120e-05, PNorm = 47.4577, GNorm = 0.1072, lr_0 = 1.4155e-04
Loss = 1.5630e-05, PNorm = 47.4600, GNorm = 0.1433, lr_0 = 1.4136e-04
Loss = 1.9031e-05, PNorm = 47.4610, GNorm = 0.1692, lr_0 = 1.4117e-04
Loss = 1.5262e-05, PNorm = 47.4612, GNorm = 0.0875, lr_0 = 1.4098e-04
Loss = 1.4668e-05, PNorm = 47.4623, GNorm = 0.0825, lr_0 = 1.4079e-04
Validation rmse = 0.466508
Validation R2 = 0.936129
Epoch 85
Train function
Loss = 2.2194e-05, PNorm = 47.4620, GNorm = 0.2131, lr_0 = 1.4060e-04
Loss = 2.1857e-05, PNorm = 47.4638, GNorm = 0.1984, lr_0 = 1.4041e-04
Loss = 1.9627e-05, PNorm = 47.4651, GNorm = 0.1416, lr_0 = 1.4022e-04
Loss = 1.6944e-05, PNorm = 47.4665, GNorm = 0.1770, lr_0 = 1.4004e-04
Loss = 1.4981e-05, PNorm = 47.4670, GNorm = 0.1562, lr_0 = 1.3985e-04
Loss = 1.3295e-05, PNorm = 47.4667, GNorm = 0.0587, lr_0 = 1.3966e-04
Loss = 1.4370e-05, PNorm = 47.4693, GNorm = 0.0792, lr_0 = 1.3947e-04
Loss = 1.4151e-05, PNorm = 47.4713, GNorm = 0.0544, lr_0 = 1.3929e-04
Loss = 1.2039e-05, PNorm = 47.4715, GNorm = 0.0482, lr_0 = 1.3910e-04
Loss = 1.2723e-05, PNorm = 47.4723, GNorm = 0.0707, lr_0 = 1.3891e-04
Loss = 1.5318e-05, PNorm = 47.4736, GNorm = 0.1139, lr_0 = 1.3873e-04
Loss = 1.1915e-05, PNorm = 47.4747, GNorm = 0.0961, lr_0 = 1.3854e-04
Loss = 1.0355e-05, PNorm = 47.4751, GNorm = 0.0709, lr_0 = 1.3835e-04
Loss = 1.9997e-05, PNorm = 47.4757, GNorm = 0.1167, lr_0 = 1.3817e-04
Loss = 1.3896e-05, PNorm = 47.4763, GNorm = 0.0582, lr_0 = 1.3798e-04
Loss = 1.4837e-05, PNorm = 47.4767, GNorm = 0.1026, lr_0 = 1.3780e-04
Loss = 1.6069e-05, PNorm = 47.4772, GNorm = 0.0724, lr_0 = 1.3761e-04
Loss = 1.4332e-05, PNorm = 47.4775, GNorm = 0.1908, lr_0 = 1.3743e-04
Validation rmse = 0.469604
Validation R2 = 0.935278
Epoch 86
Train function
Loss = 1.7366e-05, PNorm = 47.4790, GNorm = 0.1995, lr_0 = 1.3724e-04
Loss = 1.3819e-05, PNorm = 47.4791, GNorm = 0.0751, lr_0 = 1.3706e-04
Loss = 1.4422e-05, PNorm = 47.4789, GNorm = 0.1049, lr_0 = 1.3688e-04
Loss = 1.4302e-05, PNorm = 47.4808, GNorm = 0.1630, lr_0 = 1.3669e-04
Loss = 1.3901e-05, PNorm = 47.4808, GNorm = 0.0899, lr_0 = 1.3651e-04
Loss = 1.1815e-05, PNorm = 47.4825, GNorm = 0.1307, lr_0 = 1.3633e-04
Loss = 1.2702e-05, PNorm = 47.4832, GNorm = 0.1144, lr_0 = 1.3614e-04
Loss = 1.3024e-05, PNorm = 47.4847, GNorm = 0.0650, lr_0 = 1.3596e-04
Loss = 1.0842e-05, PNorm = 47.4852, GNorm = 0.0338, lr_0 = 1.3578e-04
Loss = 1.7160e-05, PNorm = 47.4846, GNorm = 0.0557, lr_0 = 1.3560e-04
Loss = 1.6318e-05, PNorm = 47.4855, GNorm = 0.0712, lr_0 = 1.3541e-04
Loss = 1.4418e-05, PNorm = 47.4864, GNorm = 0.0849, lr_0 = 1.3523e-04
Loss = 1.6657e-05, PNorm = 47.4860, GNorm = 0.1148, lr_0 = 1.3505e-04
Loss = 1.5548e-05, PNorm = 47.4873, GNorm = 0.1849, lr_0 = 1.3487e-04
Loss = 1.4265e-05, PNorm = 47.4885, GNorm = 0.1633, lr_0 = 1.3469e-04
Loss = 1.5283e-05, PNorm = 47.4883, GNorm = 0.1328, lr_0 = 1.3451e-04
Loss = 1.5101e-05, PNorm = 47.4901, GNorm = 0.0486, lr_0 = 1.3433e-04
Loss = 1.3312e-05, PNorm = 47.4918, GNorm = 0.1251, lr_0 = 1.3415e-04
Loss = 2.4890e-05, PNorm = 47.4919, GNorm = 0.1317, lr_0 = 1.3413e-04
Validation rmse = 0.467364
Validation R2 = 0.935894
Epoch 87
Train function
Loss = 1.3430e-05, PNorm = 47.4935, GNorm = 0.1016, lr_0 = 1.3395e-04
Loss = 1.1529e-05, PNorm = 47.4949, GNorm = 0.0458, lr_0 = 1.3377e-04
Loss = 1.4541e-05, PNorm = 47.4953, GNorm = 0.0685, lr_0 = 1.3359e-04
Loss = 1.2311e-05, PNorm = 47.4965, GNorm = 0.1021, lr_0 = 1.3341e-04
Loss = 1.0775e-05, PNorm = 47.4974, GNorm = 0.1591, lr_0 = 1.3323e-04
Loss = 1.1775e-05, PNorm = 47.4989, GNorm = 0.0922, lr_0 = 1.3305e-04
Loss = 1.3209e-05, PNorm = 47.4998, GNorm = 0.1098, lr_0 = 1.3287e-04
Loss = 1.1682e-05, PNorm = 47.5003, GNorm = 0.0706, lr_0 = 1.3270e-04
Loss = 1.2593e-05, PNorm = 47.5016, GNorm = 0.0382, lr_0 = 1.3252e-04
Loss = 9.8575e-06, PNorm = 47.5025, GNorm = 0.0471, lr_0 = 1.3234e-04
Loss = 1.3498e-05, PNorm = 47.5023, GNorm = 0.1218, lr_0 = 1.3216e-04
Loss = 1.1229e-05, PNorm = 47.5019, GNorm = 0.0868, lr_0 = 1.3199e-04
Loss = 1.1826e-05, PNorm = 47.5025, GNorm = 0.0328, lr_0 = 1.3181e-04
Loss = 1.2749e-05, PNorm = 47.5047, GNorm = 0.1360, lr_0 = 1.3163e-04
Loss = 9.7360e-06, PNorm = 47.5064, GNorm = 0.0701, lr_0 = 1.3145e-04
Loss = 1.1718e-05, PNorm = 47.5071, GNorm = 0.1267, lr_0 = 1.3128e-04
Loss = 1.1334e-05, PNorm = 47.5078, GNorm = 0.0445, lr_0 = 1.3110e-04
Validation rmse = 0.465965
Validation R2 = 0.936277
Epoch 88
Train function
Loss = 9.4843e-06, PNorm = 47.5096, GNorm = 0.0859, lr_0 = 1.3093e-04
Loss = 1.1390e-05, PNorm = 47.5099, GNorm = 0.0552, lr_0 = 1.3075e-04
Loss = 1.1730e-05, PNorm = 47.5115, GNorm = 0.0957, lr_0 = 1.3058e-04
Loss = 1.3650e-05, PNorm = 47.5112, GNorm = 0.1159, lr_0 = 1.3040e-04
Loss = 1.9112e-05, PNorm = 47.5117, GNorm = 0.0921, lr_0 = 1.3022e-04
Loss = 1.2718e-05, PNorm = 47.5122, GNorm = 0.0586, lr_0 = 1.3005e-04
Loss = 1.3368e-05, PNorm = 47.5128, GNorm = 0.0809, lr_0 = 1.2988e-04
Loss = 1.2689e-05, PNorm = 47.5150, GNorm = 0.0820, lr_0 = 1.2970e-04
Loss = 1.0715e-05, PNorm = 47.5164, GNorm = 0.0532, lr_0 = 1.2953e-04
Loss = 9.5359e-06, PNorm = 47.5174, GNorm = 0.0445, lr_0 = 1.2935e-04
Loss = 1.0388e-05, PNorm = 47.5187, GNorm = 0.0993, lr_0 = 1.2918e-04
Loss = 8.9277e-06, PNorm = 47.5198, GNorm = 0.0497, lr_0 = 1.2901e-04
Loss = 8.5389e-06, PNorm = 47.5210, GNorm = 0.1273, lr_0 = 1.2883e-04
Loss = 1.0832e-05, PNorm = 47.5217, GNorm = 0.1300, lr_0 = 1.2866e-04
Loss = 1.1352e-05, PNorm = 47.5215, GNorm = 0.0870, lr_0 = 1.2849e-04
Loss = 1.2633e-05, PNorm = 47.5224, GNorm = 0.1177, lr_0 = 1.2832e-04
Loss = 1.3801e-05, PNorm = 47.5223, GNorm = 0.0765, lr_0 = 1.2814e-04
Loss = 9.6671e-06, PNorm = 47.5233, GNorm = 0.0407, lr_0 = 1.2797e-04
Validation rmse = 0.467347
Validation R2 = 0.935899
Epoch 89
Train function
Loss = 8.1592e-06, PNorm = 47.5235, GNorm = 0.0494, lr_0 = 1.2778e-04
Loss = 7.9672e-06, PNorm = 47.5243, GNorm = 0.0939, lr_0 = 1.2761e-04
Loss = 9.4650e-06, PNorm = 47.5247, GNorm = 0.1226, lr_0 = 1.2744e-04
Loss = 9.2139e-06, PNorm = 47.5244, GNorm = 0.1551, lr_0 = 1.2727e-04
Loss = 1.2206e-05, PNorm = 47.5237, GNorm = 0.1201, lr_0 = 1.2710e-04
Loss = 1.3093e-05, PNorm = 47.5242, GNorm = 0.0697, lr_0 = 1.2693e-04
Loss = 1.0069e-05, PNorm = 47.5256, GNorm = 0.0901, lr_0 = 1.2676e-04
Loss = 9.0595e-06, PNorm = 47.5264, GNorm = 0.1510, lr_0 = 1.2659e-04
Loss = 1.1170e-05, PNorm = 47.5268, GNorm = 0.0987, lr_0 = 1.2642e-04
Loss = 1.3830e-05, PNorm = 47.5280, GNorm = 0.0736, lr_0 = 1.2625e-04
Loss = 1.3043e-05, PNorm = 47.5291, GNorm = 0.1608, lr_0 = 1.2608e-04
Loss = 1.3750e-05, PNorm = 47.5297, GNorm = 0.2671, lr_0 = 1.2591e-04
Loss = 1.5809e-05, PNorm = 47.5309, GNorm = 0.2250, lr_0 = 1.2574e-04
Loss = 1.3883e-05, PNorm = 47.5321, GNorm = 0.1417, lr_0 = 1.2557e-04
Loss = 1.3382e-05, PNorm = 47.5338, GNorm = 0.1388, lr_0 = 1.2540e-04
Loss = 1.1770e-05, PNorm = 47.5340, GNorm = 0.0770, lr_0 = 1.2524e-04
Loss = 1.0045e-05, PNorm = 47.5348, GNorm = 0.0401, lr_0 = 1.2507e-04
Validation rmse = 0.468747
Validation R2 = 0.935514
Epoch 90
Train function
Loss = 1.1960e-05, PNorm = 47.5368, GNorm = 0.0659, lr_0 = 1.2490e-04
Loss = 1.2687e-05, PNorm = 47.5376, GNorm = 0.0437, lr_0 = 1.2473e-04
Loss = 9.0076e-06, PNorm = 47.5380, GNorm = 0.0525, lr_0 = 1.2456e-04
Loss = 8.5583e-06, PNorm = 47.5393, GNorm = 0.0761, lr_0 = 1.2440e-04
Loss = 1.2993e-05, PNorm = 47.5398, GNorm = 0.2222, lr_0 = 1.2423e-04
Loss = 1.5333e-05, PNorm = 47.5405, GNorm = 0.2120, lr_0 = 1.2406e-04
Loss = 1.4550e-05, PNorm = 47.5418, GNorm = 0.1448, lr_0 = 1.2390e-04
Loss = 9.1416e-06, PNorm = 47.5433, GNorm = 0.0704, lr_0 = 1.2373e-04
Loss = 1.2446e-05, PNorm = 47.5452, GNorm = 0.0909, lr_0 = 1.2356e-04
Loss = 9.7265e-06, PNorm = 47.5454, GNorm = 0.1169, lr_0 = 1.2340e-04
Loss = 1.0443e-05, PNorm = 47.5458, GNorm = 0.1275, lr_0 = 1.2323e-04
Loss = 1.0237e-05, PNorm = 47.5468, GNorm = 0.0718, lr_0 = 1.2307e-04
Loss = 1.1003e-05, PNorm = 47.5478, GNorm = 0.1262, lr_0 = 1.2290e-04
Loss = 1.2130e-05, PNorm = 47.5483, GNorm = 0.0864, lr_0 = 1.2274e-04
Loss = 9.1088e-06, PNorm = 47.5496, GNorm = 0.0405, lr_0 = 1.2257e-04
Loss = 8.8226e-06, PNorm = 47.5503, GNorm = 0.0820, lr_0 = 1.2241e-04
Loss = 1.1973e-05, PNorm = 47.5502, GNorm = 0.0462, lr_0 = 1.2224e-04
Loss = 1.1165e-05, PNorm = 47.5512, GNorm = 0.0535, lr_0 = 1.2208e-04
Validation rmse = 0.465908
Validation R2 = 0.936293
Epoch 91
Train function
Loss = 8.8562e-06, PNorm = 47.5524, GNorm = 0.0510, lr_0 = 1.2192e-04
Loss = 7.3795e-06, PNorm = 47.5535, GNorm = 0.0578, lr_0 = 1.2175e-04
Loss = 6.5166e-06, PNorm = 47.5537, GNorm = 0.1078, lr_0 = 1.2159e-04
Loss = 7.5169e-06, PNorm = 47.5535, GNorm = 0.0573, lr_0 = 1.2143e-04
Loss = 7.6172e-06, PNorm = 47.5536, GNorm = 0.0335, lr_0 = 1.2126e-04
Loss = 8.3762e-06, PNorm = 47.5544, GNorm = 0.1330, lr_0 = 1.2110e-04
Loss = 9.8787e-06, PNorm = 47.5549, GNorm = 0.1306, lr_0 = 1.2094e-04
Loss = 9.2197e-06, PNorm = 47.5551, GNorm = 0.1810, lr_0 = 1.2078e-04
Loss = 1.4380e-05, PNorm = 47.5574, GNorm = 0.1100, lr_0 = 1.2061e-04
Loss = 9.9168e-06, PNorm = 47.5578, GNorm = 0.0741, lr_0 = 1.2045e-04
Loss = 1.0408e-05, PNorm = 47.5580, GNorm = 0.0764, lr_0 = 1.2029e-04
Loss = 7.1010e-06, PNorm = 47.5587, GNorm = 0.0678, lr_0 = 1.2013e-04
Loss = 9.8996e-06, PNorm = 47.5590, GNorm = 0.0759, lr_0 = 1.1997e-04
Loss = 9.4146e-06, PNorm = 47.5589, GNorm = 0.0595, lr_0 = 1.1981e-04
Loss = 7.8634e-06, PNorm = 47.5594, GNorm = 0.0594, lr_0 = 1.1965e-04
Loss = 9.0999e-06, PNorm = 47.5590, GNorm = 0.0790, lr_0 = 1.1949e-04
Loss = 8.4519e-06, PNorm = 47.5595, GNorm = 0.0391, lr_0 = 1.1933e-04
Validation rmse = 0.466820
Validation R2 = 0.936043
Epoch 92
Train function
Loss = 5.8958e-06, PNorm = 47.5601, GNorm = 0.0314, lr_0 = 1.1915e-04
Loss = 7.3094e-06, PNorm = 47.5607, GNorm = 0.0363, lr_0 = 1.1899e-04
Loss = 7.3566e-06, PNorm = 47.5616, GNorm = 0.0484, lr_0 = 1.1883e-04
Loss = 6.6571e-06, PNorm = 47.5623, GNorm = 0.0577, lr_0 = 1.1867e-04
Loss = 7.2913e-06, PNorm = 47.5628, GNorm = 0.0434, lr_0 = 1.1851e-04
Loss = 1.0497e-05, PNorm = 47.5642, GNorm = 0.1180, lr_0 = 1.1835e-04
Loss = 9.0055e-06, PNorm = 47.5652, GNorm = 0.0467, lr_0 = 1.1819e-04
Loss = 7.1988e-06, PNorm = 47.5671, GNorm = 0.0833, lr_0 = 1.1804e-04
Loss = 1.0266e-05, PNorm = 47.5678, GNorm = 0.0715, lr_0 = 1.1788e-04
Loss = 9.4588e-06, PNorm = 47.5671, GNorm = 0.0464, lr_0 = 1.1772e-04
Loss = 9.7072e-06, PNorm = 47.5675, GNorm = 0.0665, lr_0 = 1.1756e-04
Loss = 8.6613e-06, PNorm = 47.5692, GNorm = 0.1046, lr_0 = 1.1740e-04
Loss = 6.8571e-06, PNorm = 47.5688, GNorm = 0.1143, lr_0 = 1.1725e-04
Loss = 8.9161e-06, PNorm = 47.5693, GNorm = 0.0405, lr_0 = 1.1709e-04
Loss = 1.1518e-05, PNorm = 47.5695, GNorm = 0.0861, lr_0 = 1.1693e-04
Loss = 8.2660e-06, PNorm = 47.5711, GNorm = 0.0967, lr_0 = 1.1677e-04
Loss = 1.0328e-05, PNorm = 47.5720, GNorm = 0.0459, lr_0 = 1.1662e-04
Loss = 1.0965e-05, PNorm = 47.5727, GNorm = 0.0696, lr_0 = 1.1646e-04
Validation rmse = 0.466412
Validation R2 = 0.936155
Epoch 93
Train function
Loss = 1.2140e-05, PNorm = 47.5724, GNorm = 0.0920, lr_0 = 1.1630e-04
Loss = 1.0375e-05, PNorm = 47.5731, GNorm = 0.0868, lr_0 = 1.1615e-04
Loss = 9.4857e-06, PNorm = 47.5742, GNorm = 0.0753, lr_0 = 1.1599e-04
Loss = 6.5754e-06, PNorm = 47.5758, GNorm = 0.0476, lr_0 = 1.1584e-04
Loss = 8.6379e-06, PNorm = 47.5774, GNorm = 0.0376, lr_0 = 1.1568e-04
Loss = 6.4728e-06, PNorm = 47.5776, GNorm = 0.0302, lr_0 = 1.1553e-04
Loss = 6.8858e-06, PNorm = 47.5778, GNorm = 0.0538, lr_0 = 1.1537e-04
Loss = 1.1308e-05, PNorm = 47.5782, GNorm = 0.1469, lr_0 = 1.1522e-04
Loss = 1.2408e-05, PNorm = 47.5788, GNorm = 0.1977, lr_0 = 1.1506e-04
Loss = 1.0323e-05, PNorm = 47.5795, GNorm = 0.0698, lr_0 = 1.1491e-04
Loss = 8.0932e-06, PNorm = 47.5804, GNorm = 0.0350, lr_0 = 1.1475e-04
Loss = 1.0457e-05, PNorm = 47.5808, GNorm = 0.1326, lr_0 = 1.1460e-04
Loss = 1.0815e-05, PNorm = 47.5813, GNorm = 0.0545, lr_0 = 1.1445e-04
Loss = 8.7597e-06, PNorm = 47.5820, GNorm = 0.0885, lr_0 = 1.1429e-04
Loss = 1.0066e-05, PNorm = 47.5832, GNorm = 0.0716, lr_0 = 1.1414e-04
Loss = 7.4673e-06, PNorm = 47.5838, GNorm = 0.0592, lr_0 = 1.1399e-04
Loss = 5.8767e-06, PNorm = 47.5846, GNorm = 0.0521, lr_0 = 1.1383e-04
Loss = 9.8931e-06, PNorm = 47.5859, GNorm = 0.0741, lr_0 = 1.1368e-04
Validation rmse = 0.464962
Validation R2 = 0.936551
Epoch 94
Train function
Loss = 7.2146e-06, PNorm = 47.5860, GNorm = 0.1298, lr_0 = 1.1353e-04
Loss = 6.6326e-06, PNorm = 47.5861, GNorm = 0.0518, lr_0 = 1.1338e-04
Loss = 7.8833e-06, PNorm = 47.5864, GNorm = 0.0503, lr_0 = 1.1322e-04
Loss = 9.0526e-06, PNorm = 47.5872, GNorm = 0.0569, lr_0 = 1.1307e-04
Loss = 6.9343e-06, PNorm = 47.5872, GNorm = 0.0385, lr_0 = 1.1292e-04
Loss = 6.5946e-06, PNorm = 47.5877, GNorm = 0.0401, lr_0 = 1.1277e-04
Loss = 5.7113e-06, PNorm = 47.5882, GNorm = 0.0822, lr_0 = 1.1262e-04
Loss = 6.7915e-06, PNorm = 47.5889, GNorm = 0.0573, lr_0 = 1.1247e-04
Loss = 9.5973e-06, PNorm = 47.5895, GNorm = 0.1660, lr_0 = 1.1231e-04
Loss = 9.6330e-06, PNorm = 47.5898, GNorm = 0.1906, lr_0 = 1.1216e-04
Loss = 1.2622e-05, PNorm = 47.5901, GNorm = 0.1122, lr_0 = 1.1201e-04
Loss = 1.4583e-05, PNorm = 47.5904, GNorm = 0.0949, lr_0 = 1.1186e-04
Loss = 1.1097e-05, PNorm = 47.5912, GNorm = 0.1011, lr_0 = 1.1171e-04
Loss = 9.2372e-06, PNorm = 47.5917, GNorm = 0.0381, lr_0 = 1.1156e-04
Loss = 1.0926e-05, PNorm = 47.5925, GNorm = 0.0958, lr_0 = 1.1141e-04
Loss = 7.3978e-06, PNorm = 47.5932, GNorm = 0.0617, lr_0 = 1.1126e-04
Loss = 7.4670e-06, PNorm = 47.5944, GNorm = 0.0642, lr_0 = 1.1111e-04
Validation rmse = 0.468003
Validation R2 = 0.935719
Epoch 95
Train function
Loss = 2.1407e-05, PNorm = 47.5955, GNorm = 0.0734, lr_0 = 1.1095e-04
Loss = 9.2820e-06, PNorm = 47.5971, GNorm = 0.0433, lr_0 = 1.1080e-04
Loss = 9.6321e-06, PNorm = 47.5981, GNorm = 0.0420, lr_0 = 1.1065e-04
Loss = 8.2481e-06, PNorm = 47.5980, GNorm = 0.1118, lr_0 = 1.1050e-04
Loss = 8.1307e-06, PNorm = 47.5988, GNorm = 0.0449, lr_0 = 1.1036e-04
Loss = 8.3049e-06, PNorm = 47.5984, GNorm = 0.0583, lr_0 = 1.1021e-04
Loss = 8.7665e-06, PNorm = 47.5997, GNorm = 0.1482, lr_0 = 1.1006e-04
Loss = 1.1098e-05, PNorm = 47.6009, GNorm = 0.1420, lr_0 = 1.0991e-04
Loss = 7.7062e-06, PNorm = 47.6014, GNorm = 0.0742, lr_0 = 1.0977e-04
Loss = 8.4036e-06, PNorm = 47.6023, GNorm = 0.0475, lr_0 = 1.0962e-04
Loss = 6.1635e-06, PNorm = 47.6036, GNorm = 0.0638, lr_0 = 1.0947e-04
Loss = 8.4405e-06, PNorm = 47.6038, GNorm = 0.0890, lr_0 = 1.0932e-04
Loss = 6.8056e-06, PNorm = 47.6048, GNorm = 0.0728, lr_0 = 1.0918e-04
Loss = 8.7537e-06, PNorm = 47.6047, GNorm = 0.0928, lr_0 = 1.0903e-04
Loss = 7.5342e-06, PNorm = 47.6047, GNorm = 0.0691, lr_0 = 1.0888e-04
Loss = 8.4322e-06, PNorm = 47.6048, GNorm = 0.0427, lr_0 = 1.0874e-04
Loss = 8.9045e-06, PNorm = 47.6051, GNorm = 0.0465, lr_0 = 1.0859e-04
Loss = 8.2317e-06, PNorm = 47.6072, GNorm = 0.0365, lr_0 = 1.0845e-04
Validation rmse = 0.467613
Validation R2 = 0.935826
Epoch 96
Train function
Loss = 7.6090e-06, PNorm = 47.6080, GNorm = 0.0434, lr_0 = 1.0830e-04
Loss = 6.1285e-06, PNorm = 47.6083, GNorm = 0.0589, lr_0 = 1.0816e-04
Loss = 6.1235e-06, PNorm = 47.6089, GNorm = 0.0509, lr_0 = 1.0801e-04
Loss = 5.4158e-06, PNorm = 47.6100, GNorm = 0.0322, lr_0 = 1.0787e-04
Loss = 7.2122e-06, PNorm = 47.6098, GNorm = 0.1193, lr_0 = 1.0772e-04
Loss = 6.5465e-06, PNorm = 47.6107, GNorm = 0.0858, lr_0 = 1.0758e-04
Loss = 6.9100e-06, PNorm = 47.6106, GNorm = 0.0358, lr_0 = 1.0743e-04
Loss = 5.7664e-06, PNorm = 47.6112, GNorm = 0.0446, lr_0 = 1.0729e-04
Loss = 6.7014e-06, PNorm = 47.6114, GNorm = 0.0901, lr_0 = 1.0714e-04
Loss = 6.8155e-06, PNorm = 47.6127, GNorm = 0.0841, lr_0 = 1.0700e-04
Loss = 5.7825e-06, PNorm = 47.6134, GNorm = 0.0389, lr_0 = 1.0686e-04
Loss = 8.3351e-06, PNorm = 47.6140, GNorm = 0.0400, lr_0 = 1.0671e-04
Loss = 6.8750e-06, PNorm = 47.6137, GNorm = 0.0523, lr_0 = 1.0657e-04
Loss = 1.0601e-05, PNorm = 47.6142, GNorm = 0.1174, lr_0 = 1.0643e-04
Loss = 1.0954e-05, PNorm = 47.6152, GNorm = 0.0765, lr_0 = 1.0629e-04
Loss = 1.0071e-05, PNorm = 47.6170, GNorm = 0.0404, lr_0 = 1.0614e-04
Loss = 1.2180e-05, PNorm = 47.6171, GNorm = 0.1009, lr_0 = 1.0600e-04
Validation rmse = 0.466990
Validation R2 = 0.935997
Epoch 97
Train function
Loss = 6.3201e-06, PNorm = 47.6174, GNorm = 0.0875, lr_0 = 1.0586e-04
Loss = 1.0070e-05, PNorm = 47.6177, GNorm = 0.0933, lr_0 = 1.0572e-04
Loss = 8.6285e-06, PNorm = 47.6175, GNorm = 0.1216, lr_0 = 1.0557e-04
Loss = 1.2319e-05, PNorm = 47.6183, GNorm = 0.1188, lr_0 = 1.0543e-04
Loss = 8.5428e-06, PNorm = 47.6190, GNorm = 0.0509, lr_0 = 1.0529e-04
Loss = 1.0430e-05, PNorm = 47.6197, GNorm = 0.1234, lr_0 = 1.0515e-04
Loss = 9.4793e-06, PNorm = 47.6190, GNorm = 0.0643, lr_0 = 1.0501e-04
Loss = 1.2421e-05, PNorm = 47.6195, GNorm = 0.2318, lr_0 = 1.0487e-04
Loss = 9.9690e-06, PNorm = 47.6204, GNorm = 0.1259, lr_0 = 1.0473e-04
Loss = 1.1270e-05, PNorm = 47.6218, GNorm = 0.1405, lr_0 = 1.0459e-04
Loss = 8.5672e-06, PNorm = 47.6220, GNorm = 0.0616, lr_0 = 1.0445e-04
Loss = 1.3615e-05, PNorm = 47.6227, GNorm = 0.1258, lr_0 = 1.0431e-04
Loss = 1.0047e-05, PNorm = 47.6249, GNorm = 0.0963, lr_0 = 1.0417e-04
Loss = 8.7378e-06, PNorm = 47.6259, GNorm = 0.0563, lr_0 = 1.0403e-04
Loss = 6.8236e-06, PNorm = 47.6268, GNorm = 0.0457, lr_0 = 1.0389e-04
Loss = 5.9621e-06, PNorm = 47.6274, GNorm = 0.0589, lr_0 = 1.0375e-04
Loss = 1.3446e-05, PNorm = 47.6272, GNorm = 0.1667, lr_0 = 1.0361e-04
Loss = 1.0499e-05, PNorm = 47.6275, GNorm = 0.0612, lr_0 = 1.0347e-04
Validation rmse = 0.464795
Validation R2 = 0.936597
Epoch 98
Train function
Loss = 8.9550e-06, PNorm = 47.6287, GNorm = 0.0984, lr_0 = 1.0332e-04
Loss = 7.6711e-06, PNorm = 47.6290, GNorm = 0.1173, lr_0 = 1.0318e-04
Loss = 1.3656e-05, PNorm = 47.6295, GNorm = 0.1582, lr_0 = 1.0304e-04
Loss = 1.2834e-05, PNorm = 47.6307, GNorm = 0.1210, lr_0 = 1.0290e-04
Loss = 9.4964e-06, PNorm = 47.6322, GNorm = 0.0980, lr_0 = 1.0276e-04
Loss = 1.5392e-05, PNorm = 47.6329, GNorm = 0.1731, lr_0 = 1.0263e-04
Loss = 1.2691e-05, PNorm = 47.6335, GNorm = 0.1239, lr_0 = 1.0249e-04
Loss = 1.0727e-05, PNorm = 47.6342, GNorm = 0.0894, lr_0 = 1.0235e-04
Loss = 1.0012e-05, PNorm = 47.6340, GNorm = 0.0345, lr_0 = 1.0221e-04
Loss = 7.9829e-06, PNorm = 47.6348, GNorm = 0.0941, lr_0 = 1.0208e-04
Loss = 7.7230e-06, PNorm = 47.6359, GNorm = 0.0592, lr_0 = 1.0194e-04
Loss = 8.3252e-06, PNorm = 47.6363, GNorm = 0.0563, lr_0 = 1.0180e-04
Loss = 9.6419e-06, PNorm = 47.6363, GNorm = 0.0706, lr_0 = 1.0167e-04
Loss = 7.5055e-06, PNorm = 47.6367, GNorm = 0.0551, lr_0 = 1.0153e-04
Loss = 7.4856e-06, PNorm = 47.6378, GNorm = 0.0562, lr_0 = 1.0139e-04
Loss = 6.4432e-06, PNorm = 47.6392, GNorm = 0.0417, lr_0 = 1.0126e-04
Loss = 8.5120e-06, PNorm = 47.6400, GNorm = 0.0557, lr_0 = 1.0112e-04
Validation rmse = 0.466169
Validation R2 = 0.936221
Epoch 99
Train function
Loss = 7.4841e-06, PNorm = 47.6400, GNorm = 0.0668, lr_0 = 1.0098e-04
Loss = 7.6921e-06, PNorm = 47.6398, GNorm = 0.0453, lr_0 = 1.0085e-04
Loss = 7.0112e-06, PNorm = 47.6406, GNorm = 0.0453, lr_0 = 1.0071e-04
Loss = 4.9263e-06, PNorm = 47.6408, GNorm = 0.0608, lr_0 = 1.0058e-04
Loss = 6.7454e-06, PNorm = 47.6414, GNorm = 0.0357, lr_0 = 1.0044e-04
Loss = 5.9923e-06, PNorm = 47.6419, GNorm = 0.0531, lr_0 = 1.0031e-04
Loss = 7.0830e-06, PNorm = 47.6423, GNorm = 0.0500, lr_0 = 1.0017e-04
Loss = 7.3759e-06, PNorm = 47.6427, GNorm = 0.0332, lr_0 = 1.0004e-04
Loss = 8.2724e-06, PNorm = 47.6429, GNorm = 0.0589, lr_0 = 1.0000e-04
Loss = 8.1062e-06, PNorm = 47.6440, GNorm = 0.0322, lr_0 = 1.0000e-04
Loss = 9.8094e-06, PNorm = 47.6449, GNorm = 0.0665, lr_0 = 1.0000e-04
Loss = 7.7545e-06, PNorm = 47.6452, GNorm = 0.0925, lr_0 = 1.0000e-04
Loss = 7.0175e-06, PNorm = 47.6457, GNorm = 0.0638, lr_0 = 1.0000e-04
Loss = 7.6129e-06, PNorm = 47.6463, GNorm = 0.0306, lr_0 = 1.0000e-04
Loss = 5.9231e-06, PNorm = 47.6471, GNorm = 0.0518, lr_0 = 1.0000e-04
Loss = 9.2535e-06, PNorm = 47.6479, GNorm = 0.0799, lr_0 = 1.0000e-04
Loss = 6.9047e-06, PNorm = 47.6484, GNorm = 0.0803, lr_0 = 1.0000e-04
Loss = 6.2444e-06, PNorm = 47.6492, GNorm = 0.0824, lr_0 = 1.0000e-04
Validation rmse = 0.467478
Validation R2 = 0.935863
Model 0 best validation rmse = 0.463813 on epoch 44
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.458375
Model 0 test R2 = 0.937609
Ensemble test rmse = 0.458375
Ensemble test R2 = 0.937609
Fold 1
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 200,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8782,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 1
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
[[-1.01], [2.13], [4.67], [1.85], [1.35], [3.45], [-0.6], [0.34], [5.23], [4.91], [1.29], [-1.22], [5.8], [4.04], [-0.24], [3.18], [1.89], [0.66], [3.42], [3.0], [0.9], [0.08], [2.61], [2.65], [2.17], [0.31], [0.42], [3.25], [-0.51], [2.55], [-0.21], [3.93], [3.61], [3.05], [3.2], [-0.07], [3.18], [1.85], [5.05], [4.66], [0.29], [0.57], [5.04], [2.22], [1.38], [5.16], [2.88], [1.13], [1.48], [2.75], [3.07], [0.61], [0.68], [4.93], [1.3], [0.73], [1.73], [-1.95], [4.37], [2.8], [3.76], [2.83], [0.63], [2.63], [2.25], [1.54], [3.08], [1.41], [1.45], [1.36], [4.0], [-0.22], [0.06], [0.93], [2.42], [2.47], [0.56], [3.47], [0.48], [1.92], [6.23], [1.46], [-0.1], [0.8], [0.84], [1.91], [3.03], [0.36], [0.72], [4.43], [0.16], [-0.85], [1.67], [2.91], [2.12], [1.03], [-2.41], [3.85], [6.39], [4.75], [2.4], [-0.47], [2.16], [1.89], [-2.96], [3.03], [2.92], [2.49], [2.41], [2.14], [2.72], [1.33], [-0.38], [2.99], [2.28], [2.8], [3.15], [3.78], [4.3], [1.7], [0.63], [1.5], [1.8], [0.79], [1.41], [2.27], [2.78], [2.64], [1.65], [1.51], [2.57], [4.78], [2.02], [6.61], [0.98], [2.4], [4.36], [2.58], [0.23], [1.42], [1.24], [3.05], [1.31], [1.94], [6.66], [1.84], [3.43], [0.29], [2.83], [1.56], [2.16], [0.82], [4.0], [-1.62], [3.18], [3.2], [-0.15], [-0.15], [1.83], [3.8], [3.86], [1.16], [2.32], [3.11], [1.74], [1.8], [5.04], [0.49], [0.61], [0.7], [4.31], [2.7], [2.65], [2.67], [0.54], [1.03], [0.52], [3.26], [-1.56], [0.06], [2.65], [5.31], [2.14], [4.89], [2.91], [1.21], [4.77], [2.33], [3.1], [5.59], [1.02], [0.74], [1.71], [1.96], [1.83], [-0.14], [-1.04], [-0.85], [0.8], [2.71], [2.4], [0.62], [1.09], [3.65], [3.4], [5.15], [1.28], [-0.78], [2.72], [2.33], [1.6], [1.54], [1.92], [1.57], [-0.35], [-0.1], [5.22], [5.74], [1.68], [5.07], [0.5], [0.08], [-0.27], [3.3], [1.02], [-1.22], [-1.37], [-0.74], [4.2], [2.67], [1.84], [-0.4], [-0.18], [2.47], [1.58], [0.65], [7.44], [2.12], [1.9], [1.53], [0.0], [1.56], [2.11], [2.31], [1.32], [4.34], [-0.29], [0.6], [2.32], [1.42], [0.34], [0.08], [2.26], [1.97], [2.31], [2.63], [0.42], [0.98], [3.74], [2.34], [3.12], [5.93], [-1.57], [0.57], [3.94], [4.44], [2.1], [5.0], [2.92], [0.66], [3.39], [-0.96], [4.12], [1.91], [0.29], [2.82], [2.16], [3.96], [1.46], [0.31], [-0.47], [4.66], [0.64], [1.9], [1.43], [2.01], [0.05], [1.92], [-0.34], [2.31], [2.27], [2.4], [2.1], [2.59], [0.56], [4.26], [2.39], [5.9], [-0.44], [3.82], [0.49], [1.2], [4.26], [1.3], [2.65], [3.51], [-1.73], [2.98], [4.18], [3.2], [3.91], [0.21], [0.23], [5.31], [0.01], [4.15], [2.52], [2.31], [0.38], [1.95], [-0.59], [3.42], [2.16], [0.47], [0.2], [1.81], [5.64], [4.22], [0.98], [1.0], [1.71], [3.72], [0.75], [-0.59], [2.55], [1.58], [2.04], [2.54], [2.74], [2.11], [0.37], [2.27], [0.54], [0.81], [1.02], [3.55], [1.85], [3.56], [-0.11], [0.49], [3.34], [2.04], [2.78], [2.04], [1.79], [3.17], [3.14], [4.1], [1.55], [-0.51], [2.11], [1.02], [2.13], [0.59], [4.44], [1.65], [1.59], [1.68], [1.24], [1.52], [0.32], [1.16], [2.82], [2.16], [0.39], [0.86], [0.77], [-1.05], [0.45], [2.85], [4.48], [1.98], [1.32], [2.18], [0.72], [1.62], [2.35], [6.01], [-0.78], [-0.09], [-0.45], [1.41], [5.8], [3.3], [0.52], [1.76], [1.8], [2.17], [1.4], [-0.86], [2.54], [3.19], [0.92], [4.07], [1.38], [2.48], [1.27], [1.78], [1.83], [0.53], [4.06], [-0.19], [2.5], [1.76], [2.66], [4.93], [-0.98], [2.6], [1.23], [2.73], [3.2], [3.82], [2.22], [7.41], [1.31], [3.21], [1.95], [0.87], [0.86], [2.07], [2.42], [1.38], [3.24], [2.79], [1.41], [-0.26], [1.82], [3.18], [0.97], [1.87], [0.54], [3.16], [2.44], [-0.7], [0.9], [4.55], [1.8], [3.1], [4.09], [0.7], [3.66], [1.53], [3.65], [1.1], [2.69], [1.03], [1.92], [3.07], [3.5], [1.65], [3.52], [0.93], [1.24], [2.83], [2.0], [3.2], [-1.97], [1.49], [2.33], [0.03], [2.47], [1.49], [1.49], [-0.7], [2.91], [1.51], [1.49], [1.0], [0.5], [5.26], [2.28], [3.15], [2.04], [3.42], [2.71], [0.56], [2.96], [4.65], [4.67], [2.86], [0.87], [1.59], [1.52], [-1.14], [2.58], [2.84], [2.31], [0.25], [2.04], [2.09], [1.82], [3.53], [2.29], [1.78], [0.25], [1.26], [0.9], [2.99], [3.39], [6.34], [2.71], [4.47], [0.49], [-0.05], [3.57], [1.0], [1.47], [0.56], [2.23], [0.28], [0.46], [1.66], [2.42], [-0.48], [0.66], [4.61], [3.0], [5.51], [1.2], [0.13], [3.38], [0.86], [-0.61], [1.06], [-0.62], [2.18], [-1.45], [3.35], [3.43], [0.71], [3.36], [2.28], [4.92], [2.28], [3.07], [0.46], [0.61], [2.06], [4.41], [0.83], [1.81], [1.86], [-0.58], [3.08], [2.45], [6.82], [-0.6], [2.25], [2.78], [3.32], [5.2], [0.73], [4.38], [1.38], [1.18], [2.5], [3.7], [0.99], [4.34], [4.63], [1.43], [4.65], [0.35], [1.57], [2.96], [3.95], [2.95], [2.28], [2.55], [2.47], [3.46], [2.36], [0.15], [2.75], [2.79], [4.76], [1.63], [2.31], [3.46], [2.05], [0.84], [2.45], [1.9], [2.95], [1.41], [3.33], [2.25], [2.99], [1.11], [3.09], [2.98], [1.35], [2.37], [5.29], [0.88], [2.21], [1.78], [-0.06], [2.01], [0.59], [2.54], [0.49], [2.79], [1.02], [2.22], [4.3], [0.82], [4.98], [0.95], [5.7], [1.82], [1.69], [3.51], [0.7], [1.64], [4.56], [2.71], [1.17], [2.19], [2.73], [0.22], [3.87], [2.22], [2.74], [4.78], [0.78], [3.41], [3.52], [2.17], [3.38], [3.87], [2.29], [-0.25], [-0.77], [1.27], [-0.26], [2.05], [2.03], [2.08], [1.4], [4.28], [3.83], [7.25], [1.34], [1.83], [2.27], [4.58], [4.3], [0.62], [2.01], [1.14], [2.33], [0.04], [6.65], [3.57], [5.56], [1.51], [-2.49], [-1.99], [-0.04], [2.6], [4.52], [-1.49], [2.74], [1.44], [1.03], [-1.12], [0.23], [4.0], [2.06], [-0.77], [1.44], [3.73], [1.1], [0.26], [1.76], [1.79], [1.01], [1.54], [-0.3], [4.6], [2.44], [3.21], [-1.1], [2.78], [1.09], [2.78], [1.0], [2.7], [1.24], [0.58], [1.74], [1.91], [-1.32], [-0.92], [4.11], [3.45], [-0.6], [0.52], [4.88], [2.63], [-0.53], [3.96], [4.16], [4.22], [3.14], [1.4], [0.65], [-1.18], [1.65], [1.98], [0.82], [0.45], [1.97], [2.17], [2.72], [3.36], [1.81], [4.94], [1.38], [-1.6], [2.87], [6.11], [2.67], [0.95], [4.04], [1.0], [2.04], [1.15], [6.05], [-0.6], [2.23], [2.25], [2.57], [1.28], [3.3], [0.95], [0.16], [-0.44], [2.75], [1.58], [0.52], [2.43], [1.29], [-0.21], [3.1], [3.79], [-1.87], [2.64], [2.05], [3.93], [4.06], [4.9], [6.3], [3.1], [2.29], [-1.43], [0.29], [0.35], [0.85], [2.69], [1.21], [1.28], [4.51], [3.3], [4.2], [1.5], [-1.84], [0.43], [2.57], [-0.57], [3.11], [-0.74], [2.2], [6.22], [2.47], [1.68], [0.02], [0.91], [2.15], [7.12], [2.47], [-0.09], [4.8], [0.9], [2.85], [-0.37], [0.12], [-1.7], [2.65], [1.34], [4.01], [7.5], [1.92], [1.29], [3.03], [4.09], [-0.64], [9.16], [0.6], [1.84], [2.46], [-1.3], [2.19], [-2.63], [0.73], [2.71], [3.61], [2.48], [0.06], [-0.77], [1.8], [-0.27], [-0.04], [2.23], [7.45], [2.39], [-0.29], [1.15], [0.3], [1.07], [1.37], [2.73], [2.86], [1.29], [2.26], [4.62], [5.76], [0.28], [2.18], [1.96], [1.89], [-1.64], [2.3], [1.87], [1.37], [3.79], [-1.46], [1.48], [0.09], [1.21], [-0.04], [2.97], [-0.01], [3.28], [1.13], [4.82], [6.53], [5.2], [1.47], [3.91], [1.37], [2.56], [2.42], [1.24], [2.66], [2.72], [0.63], [2.35], [1.41], [2.42], [4.55], [0.79], [-0.25], [-0.66], [3.23], [3.36], [0.35], [3.13], [3.8], [1.52], [2.03], [2.83], [1.0], [2.88], [6.63], [3.62], [5.92], [0.39], [0.76], [4.45], [3.31], [2.19], [1.58], [1.65], [2.09], [1.86], [1.46], [3.37], [2.78], [4.24], [1.16], [4.16], [3.11], [3.23], [3.84], [2.56], [3.1], [3.91], [1.38], [-0.6], [2.48], [0.63], [2.82], [3.61], [2.01], [-0.21], [-0.3], [3.73], [2.1], [2.03], [1.88], [2.99], [1.94], [0.06], [1.09], [3.12], [-2.52], [1.74], [1.85], [4.2], [3.5], [2.47], [-0.58], [3.57], [2.86], [2.03], [-0.59], [2.06], [6.04], [4.51], [2.19], [2.65], [4.43], [0.12], [1.73], [1.86], [3.37], [-0.76], [1.35], [2.94], [1.48], [2.66], [2.21], [4.49], [2.91], [-1.16], [2.3], [2.09], [1.18], [-1.68], [7.18], [1.6], [1.22], [0.7], [5.98], [2.5], [4.66], [-2.1], [2.5], [3.92], [1.41], [3.06], [3.63], [5.13], [6.27], [-2.0], [3.52], [2.42], [3.12], [2.09], [3.75], [0.29], [2.72], [2.19], [1.18], [0.45], [-0.26], [0.38], [9.16], [3.11], [1.12], [-0.97], [1.2], [3.41], [1.82], [2.23], [1.69], [3.44], [3.28], [2.45], [4.21], [4.21], [4.99], [2.32], [2.28], [2.06], [-0.09], [2.34], [-0.11], [-0.05], [1.82], [2.12], [2.58], [-0.89], [6.14], [1.77], [-1.01], [2.24], [3.49], [-2.27], [1.03], [1.83], [2.26], [0.94], [8.61], [4.92], [2.14], [0.88], [2.95], [3.41], [1.67], [0.87], [1.98], [0.72], [2.37], [1.25], [0.64], [0.52], [-2.2], [-1.15], [1.86], [2.77], [2.2], [2.7], [0.08], [3.21], [1.2], [2.65], [-0.49], [2.34], [2.85], [-3.32], [2.83], [4.31], [4.14], [1.76], [2.36], [-1.8], [-1.76], [5.06], [0.55], [-0.98], [1.63], [2.05], [2.0], [2.44], [0.59], [2.7], [-0.24], [0.35], [2.08], [0.07], [2.75], [0.62], [2.62], [2.42], [4.46], [1.78], [4.03], [1.64], [1.63], [1.94], [3.91], [0.77], [0.11], [0.79], [0.86], [-0.16], [1.16], [4.45], [1.53], [3.05], [1.07], [0.97], [5.7], [-2.28], [1.12], [1.53], [-2.55], [0.95], [1.91], [-0.82], [0.19], [5.33], [-0.54], [3.46], [3.62], [2.56], [2.44], [2.63], [2.99], [2.77], [1.09], [-0.18], [2.26], [4.73], [0.3], [-1.39], [5.11], [2.54], [5.7], [3.52], [-1.82], [2.4], [-0.2], [0.16], [1.85], [2.25], [2.71], [0.3], [2.52], [2.64], [-0.22], [2.12], [0.04], [0.39], [3.55], [0.36], [1.5], [3.17], [2.11], [2.83], [2.36], [2.76], [-0.32], [1.73], [1.34], [3.36], [1.39], [1.76], [1.79], [3.87], [2.97], [0.42], [-1.33], [1.48], [1.88], [0.31], [5.14], [-0.67], [2.18], [0.08], [1.21], [2.08], [2.7], [3.7], [3.46], [-0.72], [5.44], [2.21], [3.15], [5.44], [-0.15], [3.33], [2.17], [0.79], [3.64], [2.16], [2.76], [3.71], [1.99], [3.9], [2.25], [4.04], [2.09], [3.28], [1.37], [3.2], [3.24], [3.27], [2.33], [4.44], [1.98], [2.3], [1.23], [2.17], [0.61], [1.55], [-0.01], [3.0], [1.41], [1.79], [3.9], [2.63], [1.7], [1.6], [1.1], [1.72], [5.54], [1.77], [2.07], [2.32], [2.66], [1.6], [1.0], [3.88], [1.55], [5.05], [-1.14], [-0.13], [2.0], [5.73], [1.31], [1.98], [0.64], [-0.99], [2.48], [3.86], [3.52], [3.92], [3.65], [3.8], [-0.26], [3.26], [-1.6], [1.22], [1.61], [4.2], [5.19], [0.25], [3.17], [2.13], [2.35], [1.87], [0.93], [2.07], [4.08], [-1.41], [4.47], [1.22], [4.62], [1.57], [2.42], [0.18], [2.59], [3.16], [0.8], [2.43], [2.59], [1.41], [-0.1], [8.71], [-1.03], [1.56], [1.2], [2.55], [1.59], [2.57], [-0.17], [4.38], [3.16], [3.18], [-0.77], [1.39], [1.58], [-2.2], [-0.25], [4.04], [3.82], [4.07], [0.16], [1.08], [4.11], [0.13], [2.28], [4.63], [0.61], [0.91], [2.79], [1.22], [3.13], [1.82], [5.8], [0.36], [-0.62], [1.34], [-0.74], [1.11], [1.33], [0.21], [2.92], [0.59], [1.68], [2.4], [0.47], [0.74], [1.21], [1.61], [1.63], [0.64], [2.15], [-0.17], [1.39], [4.62], [-0.28], [1.66], [0.53], [1.31], [-0.94], [1.84], [1.48], [2.93], [3.51], [1.0], [1.0], [-2.39], [1.57], [1.73], [-3.1], [4.22], [4.12], [3.23], [1.83], [5.56], [1.83], [0.87], [2.1], [-0.38], [-1.68], [2.3], [1.6], [1.86], [1.3], [5.41], [2.59], [2.8], [3.45], [-1.08], [0.47], [2.82], [3.09], [1.76], [0.91], [2.82], [1.63], [-1.36], [2.41], [1.98], [0.48], [3.99], [1.59], [0.1], [6.07], [2.58], [2.56], [0.55], [-0.57], [7.53], [-0.7], [2.99], [3.43], [1.92], [3.75], [1.2], [-2.51], [3.57], [1.54], [1.13], [0.64], [1.75], [1.39], [-0.31], [0.63], [4.21], [0.14], [3.2], [-0.71], [4.42], [1.72], [2.95], [2.86], [5.77], [3.91], [-1.56], [0.4], [2.0], [0.35], [7.64], [5.17], [4.23], [4.61], [2.13], [3.15], [4.01], [0.49], [0.95], [2.06], [3.51], [4.02], [6.51], [0.7], [5.31], [2.78], [0.75], [-0.37], [2.14], [0.21], [1.78], [0.25], [2.26], [3.21], [6.46], [-1.69], [2.73], [1.0], [2.3], [2.72], [2.72], [2.83], [-0.4], [3.56], [2.07], [-0.26], [0.71], [2.22], [3.2], [0.54], [0.19], [-2.96], [0.83], [0.54], [2.3], [3.1], [1.88], [-0.02], [2.8], [2.44], [3.31], [1.91], [4.62], [-0.7], [2.4], [2.51], [2.53], [0.89], [3.05], [2.61], [1.18], [0.41], [-0.1], [3.85], [2.28], [0.38], [1.65], [7.25], [2.47], [2.63], [6.82], [1.62], [1.36], [2.52], [3.0], [3.66], [0.63], [9.25], [3.1], [2.46], [2.59], [0.04], [1.1], [1.04], [0.01], [-0.38], [3.55], [0.74], [1.78], [4.05], [3.9], [3.78], [2.29], [2.01], [2.14], [2.2], [0.0], [2.62], [2.3], [2.88], [2.95], [2.5], [-0.62], [1.48], [1.53], [3.78], [1.83], [4.1], [3.9], [1.29], [3.15], [4.04], [0.05], [2.23], [3.62], [3.46], [2.74], [-0.21], [0.83], [0.97], [3.33], [3.75], [2.53], [1.23], [-1.34], [2.05], [6.37], [1.25], [1.24], [-0.19], [4.4], [2.12], [0.49], [4.25], [4.23], [1.3], [4.45], [0.06], [1.65], [3.83], [2.62], [1.38], [0.08], [1.25], [1.21], [1.76], [1.92], [0.68], [2.1], [2.01], [2.66], [1.48], [0.77], [3.63], [4.92], [1.77], [3.91], [2.02], [0.24], [2.36], [0.95], [0.12], [3.0], [1.88], [2.19], [3.6], [3.14], [4.49], [-1.28], [0.57], [-0.79], [4.59], [3.08], [1.54], [-2.0], [1.04], [-2.19], [-0.5], [-1.66], [3.73], [3.44], [3.6], [-0.32], [2.38], [3.85], [2.64], [1.66], [2.2], [6.58], [1.95], [2.48], [1.62], [3.38], [1.48], [4.16], [0.14], [2.31], [2.54], [1.52], [1.26], [4.2], [2.06], [2.04], [0.95], [2.93], [2.09], [5.79], [-2.56], [3.21], [-0.1], [3.62], [1.08], [3.53], [5.03], [3.76], [1.65], [1.76], [3.48], [5.3], [-1.06], [3.9], [4.56], [1.62], [-0.1], [1.43], [4.6], [1.12], [1.13], [5.48], [2.8], [0.28], [3.5], [0.04], [2.39], [1.09], [-0.08], [1.34], [3.5], [1.58], [-1.53], [0.75], [7.45], [3.1], [5.02], [1.79], [-0.2], [2.73], [2.58], [-0.59], [3.79], [3.71], [-0.7], [3.83], [-0.86], [0.2], [1.04], [3.36], [1.12], [0.51], [0.33], [2.71], [-2.33], [1.52], [2.62], [1.54], [2.47], [1.33], [0.51], [0.71], [2.73], [2.17], [3.02], [1.83], [2.35], [4.83], [1.25], [1.39], [1.24], [0.82], [0.88], [2.55], [1.76], [1.53], [3.33], [-0.39], [3.3], [4.35], [2.48], [3.24], [4.92], [3.77], [3.46], [2.75], [0.51], [2.61], [5.46], [5.87], [-2.1], [1.44], [1.28], [1.63], [5.29], [2.65], [1.45], [2.19], [2.87], [2.82], [1.06], [2.68], [3.56], [-0.1], [1.2], [0.56], [3.69], [0.42], [1.47], [3.82], [2.54], [2.16], [4.1], [3.5], [0.47], [2.63], [1.87], [0.47], [0.95], [2.27], [3.4], [2.03], [-2.84], [2.7], [1.55], [0.26], [0.12], [0.76], [6.29], [2.38], [2.58], [3.16], [0.26], [1.28], [5.08], [1.1], [1.69], [3.38], [2.83], [1.3], [0.3], [1.07], [2.21], [-0.03], [2.09], [0.78], [0.81], [2.24], [2.61], [2.9], [0.99], [0.89], [1.71], [-0.47], [1.82], [1.67], [2.1], [-1.5], [-0.44], [-0.66], [2.5], [2.9], [1.07], [2.83], [3.28], [1.25], [5.45], [3.73], [2.19], [-0.11], [2.87], [1.29], [3.02], [0.5], [1.5], [2.6], [-0.15], [1.11], [-0.75], [2.08], [1.25], [1.35], [-0.47], [4.38], [0.62], [1.4], [1.4], [5.14], [3.65], [1.11], [1.84], [1.47], [3.16], [2.24], [7.73], [4.29], [-0.12], [1.65], [0.69], [1.66], [0.85], [3.69], [2.33], [1.46], [3.27], [2.18], [1.02], [3.24], [5.2], [2.4], [3.08], [2.95], [1.4], [0.26], [2.14], [1.79], [0.92], [-0.73], [-1.57], [2.84], [3.65], [-0.5], [3.61], [2.99], [0.48], [1.63], [0.51], [1.14], [1.19], [2.9], [4.33], [2.01], [1.8], [0.3], [2.64], [2.61], [2.08], [0.66], [0.41], [3.16], [1.32], [3.3], [0.16], [2.85], [5.33], [0.32], [3.44], [2.96], [0.65], [-0.29], [1.39], [2.86], [0.2], [1.4], [7.1], [3.61], [4.43], [-0.35], [4.97], [0.52], [0.83], [2.32], [1.74], [0.89], [1.88], [0.97], [-1.01], [0.91], [7.17], [1.35], [1.72], [6.58], [0.93], [2.23], [4.42], [3.7], [2.33], [0.87], [3.06], [2.4], [3.2], [2.92], [1.82], [1.3], [1.89], [2.98], [3.85], [3.52], [5.2], [1.51], [2.4], [5.55], [1.98], [0.11], [2.3], [3.41], [1.17], [1.7], [0.83], [3.44], [2.63], [3.55], [-0.94], [1.24], [1.72], [4.27], [0.83], [0.79], [2.22], [1.08], [-0.57], [4.61], [2.8], [2.04], [1.56], [2.25], [1.18], [1.36], [3.09], [0.84], [-1.85], [-1.09], [-0.17], [1.96], [0.24], [1.63], [0.89], [0.04], [-0.57], [0.3], [3.15], [1.1], [1.46], [2.54], [-1.96], [4.09], [1.57], [4.37], [0.62], [0.47], [2.49], [4.58], [3.5], [2.1], [1.8], [2.29], [2.23], [4.02], [2.68], [3.19], [0.63], [1.76], [2.58], [6.51], [3.66], [0.26], [0.96], [2.46], [1.05], [3.78], [1.55], [-1.01], [2.15], [2.74], [-1.29], [-1.55], [1.64], [1.95], [-0.46], [3.6], [-0.32], [1.17], [-0.01], [0.75], [1.02], [-0.63], [1.11], [2.57], [2.01], [0.31], [6.98], [2.6], [3.12], [1.58], [2.89], [2.47], [1.61], [-1.64], [1.4], [1.34], [2.9], [0.76], [2.62], [0.82], [-0.32], [2.92], [0.33], [0.36], [2.67], [4.2], [3.29], [3.38], [0.07], [3.2], [1.87], [-0.8], [6.13], [-2.09], [3.82], [-0.01], [-0.06], [1.92], [2.45], [2.12], [0.07], [5.75], [1.29], [1.46], [1.96], [2.99], [5.06], [2.34], [0.4], [3.96], [4.3], [2.32], [1.89], [0.4], [4.9], [2.61], [0.95], [1.63], [6.06], [0.98], [1.09], [4.58], [3.61], [3.61], [3.61], [1.93], [0.82], [1.18], [2.84], [1.03], [3.08], [0.92], [1.32], [0.72], [6.23], [2.22], [3.91], [0.3], [0.83], [0.84], [-1.94], [-1.48], [1.43], [1.74], [2.65], [1.13], [4.72], [2.7], [0.22], [1.68], [3.74], [3.9], [-0.17], [4.78], [2.07], [1.6], [-0.19], [-1.7], [0.66], [4.62], [3.13], [1.38], [2.3], [3.36], [5.71], [0.01], [1.9], [1.94], [2.39], [-0.02], [4.27], [1.77], [2.15], [-0.54], [3.57], [1.7], [-0.28], [1.22], [1.63], [-1.3], [1.35], [2.41], [1.3], [2.89], [1.04], [2.24], [-2.65], [2.82], [2.0], [2.86], [3.34], [3.6], [-1.95], [0.84], [5.45], [3.1], [-2.07], [3.27], [3.94], [1.27], [2.96], [1.73], [3.48], [2.98], [1.45], [2.34], [2.35], [1.82], [-1.07], [-1.33], [1.29], [0.85], [-1.4], [2.75], [3.3], [2.65], [3.66], [1.46], [1.66], [0.67], [1.6], [2.47], [0.95], [4.04], [4.12], [2.0], [-0.04], [4.4], [2.16], [2.1], [1.56], [1.29], [3.5], [1.78], [1.56], [0.76], [6.34], [5.31], [1.55], [1.84], [5.57], [1.83], [3.13], [1.7], [3.14], [2.16], [-1.5], [-0.94], [2.84], [0.44], [4.61], [2.3], [7.4], [0.76], [2.1], [2.69], [1.16], [3.5], [3.05], [2.91], [0.18], [2.22], [0.59], [4.94], [2.1], [0.47], [-0.4], [0.84], [-1.42], [3.1], [1.52], [3.62], [6.25], [0.36], [0.81], [3.82], [2.64], [2.69], [2.35], [3.56], [1.49], [5.83], [1.71], [3.93], [1.53], [4.5], [1.83], [3.47], [6.35], [5.36], [0.82], [6.36], [0.77], [-2.89], [1.59], [-1.47], [-0.08], [3.16], [5.96], [7.02], [0.57], [2.53], [4.29], [2.12], [-0.15], [1.77], [4.13], [2.88], [1.16], [2.85], [3.11], [6.36], [3.2], [1.1], [2.68], [5.73], [0.98], [1.68], [1.34], [0.28], [2.81], [3.4], [-0.32], [-0.59], [3.42], [1.3], [-1.42], [2.99], [2.38], [1.8], [0.97], [3.27], [3.69], [4.02], [5.55], [2.12], [0.88], [-1.21], [1.59], [2.81], [1.98], [5.97], [-0.8], [2.59], [5.65], [0.65], [2.45], [1.53], [0.61], [2.04], [3.63], [2.54], [1.42], [1.81], [3.56], [2.49], [5.41], [6.24], [5.39], [0.94], [3.31], [-0.29], [3.82], [0.01], [1.63], [4.39], [0.75], [1.75], [0.8], [2.23], [0.83], [2.13], [4.25], [0.63], [2.86], [3.87], [1.56], [1.64], [0.68], [2.63], [1.21], [7.0], [4.51], [0.33], [2.12], [3.78], [-0.04], [0.2], [5.3], [1.99], [6.09], [0.15], [0.56], [6.36], [1.96], [4.41], [3.45], [6.79], [-4.22], [2.43], [6.3], [0.88], [3.06], [3.57], [-2.0], [1.14], [4.5], [1.3], [3.37], [1.71], [3.78], [2.45], [3.25], [0.02], [0.99], [1.3], [1.44], [1.73], [1.7], [1.72], [-1.01], [3.92], [3.09], [-0.33], [0.68], [1.79], [-0.02], [9.36], [-0.06], [1.75], [0.44], [2.31], [0.85], [2.08], [1.94], [4.44], [2.98], [0.69], [-0.04], [3.02], [4.82], [4.3], [3.89], [3.69], [4.05], [0.34], [4.25], [2.0], [-2.04], [3.09], [1.45], [0.48], [-0.04], [1.43], [-1.82], [-0.91], [0.9], [1.83], [4.81], [4.1], [1.31], [-2.04], [1.27], [6.46], [2.88], [-0.03], [1.88], [3.65], [1.33], [2.17], [2.32], [2.48], [-2.1], [1.87], [1.6], [2.06], [0.3], [6.17], [1.64], [5.81], [-0.11], [6.28], [1.74], [2.16], [0.1], [1.24], [7.3], [3.03], [0.23], [1.75], [3.25], [2.53], [4.27], [2.46], [0.65], [1.5], [1.65], [1.89], [2.43], [-0.64], [2.95], [2.74], [1.08], [1.35], [0.34], [3.87], [2.85], [1.73], [0.78], [2.57], [3.34], [3.23], [0.65], [6.22], [2.3], [1.73], [1.29], [2.11], [1.86], [0.93], [3.48], [3.1], [0.78], [2.31], [1.46], [0.2], [1.76], [0.46], [2.04], [3.74], [1.9], [2.8], [-0.56], [0.24], [1.76], [0.27], [5.76], [0.08], [1.21], [0.68], [1.36], [2.94], [1.61], [3.01], [1.78], [0.47], [7.11], [0.6], [1.9], [0.62], [4.0], [1.98], [0.79], [-0.3], [2.9], [1.85], [4.16], [5.26], [4.57], [1.28], [4.96], [1.27], [2.48], [2.86], [0.33], [1.8], [1.76], [4.24], [3.52], [0.3], [-1.4], [3.11], [-0.13], [1.45], [1.21], [0.56], [1.27], [2.46], [7.25], [7.44], [-0.16], [4.4], [1.56], [1.61], [2.57], [2.99], [-2.0], [4.61], [3.1], [3.86], [0.16], [1.73], [2.15], [2.75], [4.2], [2.82], [1.37], [1.53], [2.41], [1.27], [4.1], [3.11], [3.82], [1.95], [1.29], [1.83], [0.98], [3.04], [2.23], [1.04], [0.68], [-3.89], [0.24], [1.26], [0.79], [0.5], [2.54], [-2.05], [1.08], [2.19], [2.68], [-0.59], [7.1], [2.75], [0.24], [-1.04], [3.57], [0.32], [-0.11], [5.76], [2.77], [4.58], [1.61], [5.67], [0.87], [5.21], [1.56], [2.18], [1.59], [2.8], [2.89], [2.04], [0.49], [2.82], [1.88], [3.51], [2.18], [0.92], [2.18], [1.72], [4.7], [3.68], [0.87], [0.53], [5.03], [2.94], [3.76], [2.29], [0.92], [2.38], [3.25], [2.54], [4.26], [3.6], [1.14], [2.97], [-2.34], [0.33], [0.78], [2.88], [3.57], [0.71], [1.1], [-1.0], [2.41], [-0.66], [0.56], [1.73], [1.07], [3.47], [0.27], [4.82], [2.42], [3.64], [-0.29], [2.95], [3.3], [-1.66], [2.38], [-0.28], [1.7], [-0.5], [-0.2], [1.83], [-2.01], [1.18], [5.43], [0.17], [2.4], [0.41], [1.24], [3.45], [4.03], [3.82], [3.3], [3.52], [1.7], [4.23], [-0.87], [4.67], [2.86], [3.97], [-1.05], [4.76], [-1.77], [5.08], [0.68], [4.57], [2.44], [1.48], [3.34], [2.03], [2.59], [6.46], [2.49], [3.23], [-0.96], [0.4], [2.84], [2.64], [2.57], [1.23], [2.37], [2.86], [3.0], [6.08], [1.75], [0.57], [1.71], [2.67], [5.18], [-2.78], [5.41], [1.75], [2.54], [0.05], [-0.3], [0.44], [6.2], [1.82], [0.71], [0.75], [3.0], [2.05], [2.48], [4.43], [2.69], [1.93], [1.06], [1.64], [6.09], [2.73], [1.99], [1.21], [1.5], [1.01], [2.56], [0.95], [1.33], [1.8], [1.31], [-0.7], [3.74], [0.35], [4.75], [5.88], [3.38], [0.8], [1.68], [7.44], [0.38], [1.58], [5.48], [1.7], [2.95], [2.09], [3.2], [2.11], [3.09], [2.21], [-0.22], [4.43], [0.71], [1.15], [0.23], [2.04], [2.06], [4.07], [5.23], [1.66], [4.21], [0.42], [3.12], [1.27], [1.11], [6.68], [3.62], [2.28], [-0.26], [3.04], [3.9], [2.03], [-1.58], [1.78], [2.49], [0.86], [2.46], [3.58], [0.73], [2.67], [8.03], [0.91], [4.24], [2.3], [0.32], [3.9], [0.7], [3.14], [2.11], [1.05], [-0.94], [3.11], [4.26], [0.86], [0.55], [-0.04], [2.35], [2.87], [1.87], [2.11], [-0.39], [1.98], [1.95], [2.27], [0.28], [3.65], [0.88], [-0.78], [1.51], [2.27], [2.41], [0.72], [-0.12], [2.34], [2.48], [2.31], [4.42], [-1.02], [1.68], [1.76], [0.17], [4.11], [1.42], [2.33], [5.9], [1.35], [1.65], [-0.67], [0.82], [0.39], [0.71], [0.67], [-1.26], [0.52], [0.36], [2.98], [2.74], [2.18], [4.97], [3.05], [-0.13], [8.2], [3.51], [4.43], [3.18], [2.08], [2.43], [4.12], [-0.05], [-0.89], [2.49], [3.4], [0.51], [1.49], [1.71], [5.83], [3.95], [5.07], [3.83], [4.22], [-0.49], [3.72], [-0.37], [3.79], [-0.56], [2.12], [1.46], [2.93], [1.1], [3.11], [-1.71], [3.58], [2.46], [3.49], [2.51], [6.3], [7.13], [2.33], [5.23], [2.96], [1.88], [1.23], [-0.38], [0.95], [4.0], [6.51], [2.89], [2.31], [1.87], [3.21], [3.66], [-1.16], [1.55], [1.15], [2.9], [3.3], [1.28], [0.86], [0.65], [0.56], [0.01], [0.98], [2.92], [3.51], [-0.68], [1.79], [1.47], [3.78], [2.2], [5.49], [2.58], [-0.52], [-0.05], [0.23], [-0.17], [3.33], [2.56], [0.36], [1.91], [-0.2], [4.41], [3.32], [0.57], [3.9], [1.78], [2.0], [0.11], [5.15], [4.56], [6.08], [0.7], [1.9], [5.19], [2.85], [-0.7], [4.25], [2.68], [1.49], [4.9], [1.73], [5.07], [-0.61], [3.55], [5.5], [3.08], [2.52], [1.65], [4.3], [2.89], [1.42], [5.09], [-0.38], [0.62], [4.21], [4.1], [0.65], [0.29], [-2.0], [1.9], [4.91], [8.65], [0.45], [3.78], [2.23], [6.8], [0.63], [1.83], [1.76], [5.78], [1.29], [0.4], [-0.31], [1.8], [1.07], [1.81], [-0.17], [2.17], [5.56], [3.56], [0.44], [2.69], [2.56], [0.51], [-4.65], [6.75], [2.45], [-0.27], [0.04], [2.26], [-0.34], [1.87], [-1.49], [2.2], [0.16], [-0.95], [1.98], [1.33], [1.1], [2.03], [2.88], [-0.16], [1.5], [2.52], [1.9], [1.45], [1.5], [2.56], [4.19], [4.45], [2.81], [3.24], [4.71], [-0.45], [3.58], [5.15], [3.39], [1.56], [2.34], [3.32], [0.66], [4.0], [0.96], [2.09], [5.96], [1.9], [3.12], [4.16], [3.14], [0.2], [2.4], [2.17], [-1.11], [4.26], [4.4], [1.95], [1.23], [0.06], [3.57], [0.8], [1.88], [2.4], [0.85], [1.89], [-0.36], [0.75], [1.06], [3.5], [1.63], [2.6], [1.53], [2.63], [3.15], [1.28], [4.0], [2.96], [1.85], [5.2], [2.23], [4.06], [3.48], [2.59], [2.21], [0.38], [1.47], [3.3], [4.88], [3.67], [5.57], [2.86], [2.53], [4.86], [3.65], [2.19], [1.94], [0.96], [-1.31], [1.98], [4.74], [3.68], [1.8], [4.84], [2.36], [0.71], [2.53], [1.41], [2.6], [0.86], [0.2], [0.24], [1.53], [1.36], [0.6], [0.5], [1.8], [3.52], [2.52], [3.06], [1.78], [1.53], [1.64], [0.04], [2.11], [1.85], [1.05], [1.3], [-0.46], [2.86], [0.8], [3.51], [5.9], [2.02], [0.63], [4.74], [0.65], [3.16], [2.59], [3.0], [3.6], [1.12], [0.61], [0.61], [2.29], [2.09], [2.96], [2.58], [2.3], [-0.93], [6.96], [0.77], [3.24], [3.43], [2.3], [2.55], [3.04], [4.64], [0.62], [0.04], [2.73], [0.93], [1.42], [1.83], [4.35], [2.05], [0.99], [2.0], [1.85], [2.53], [1.54], [3.34], [2.59], [1.64], [-0.8], [2.32], [6.11], [1.75], [5.76], [0.43], [6.1], [3.74], [0.58], [2.84], [0.83], [-0.1], [2.74], [0.95], [-2.47], [1.52], [2.03], [4.28], [2.77], [0.97], [-0.23], [2.62], [1.75], [3.7], [7.2], [0.96], [1.06], [2.63], [0.95], [1.51], [3.84], [-2.26], [3.15], [2.83], [2.78], [2.56], [2.1], [2.77], [1.39], [2.02], [2.9], [3.49], [4.37], [1.75], [3.7], [-1.26], [3.71], [3.14], [4.4], [4.35], [5.7], [0.85], [4.0], [4.21], [1.18], [-0.58], [3.2], [1.29], [0.17], [0.58], [1.15], [2.23], [5.44], [2.56], [4.97], [2.08], [2.68], [2.88], [2.75], [4.73], [3.59], [1.94], [2.16], [4.45], [5.63], [6.65], [0.82], [0.93], [2.78], [3.67], [3.42], [6.18], [3.81], [4.83], [3.7], [2.03], [-0.22], [1.53], [4.51], [2.0], [-2.11], [2.18], [1.84], [1.72], [4.82], [1.01], [4.09], [2.38], [2.4], [0.61], [3.37], [3.39], [2.91], [-0.37], [0.82], [0.57], [1.43], [2.9], [3.9], [0.96], [2.72], [0.45], [4.97], [1.9], [5.09], [2.23], [0.67], [0.22], [6.44], [1.74], [-1.0], [2.72], [0.2], [2.88], [3.78], [4.21], [2.1], [2.07], [1.18], [-1.02], [1.92], [1.03], [-0.06], [-0.67], [-0.41], [1.99], [2.46], [-0.24], [-1.85], [1.18], [1.04], [1.57], [0.91], [1.0], [-0.04], [2.58], [1.34], [2.19], [3.32], [2.03], [6.84], [4.61], [1.95], [1.3], [4.64], [1.9], [3.64], [1.36], [4.97], [2.27], [6.51], [5.21], [0.74], [4.16], [3.7], [2.07], [1.85], [1.85], [0.94], [2.27], [0.48], [6.15], [0.6], [3.31], [0.77], [2.18], [1.36], [1.83], [5.16], [1.07], [3.7], [5.09], [0.74], [5.12], [3.45], [1.1], [3.42], [4.51], [0.7], [1.32], [0.7], [0.83], [2.38], [1.38], [0.6], [-2.9], [2.54], [-0.2], [4.63], [2.9], [1.25], [3.42], [-0.01], [3.18], [2.05], [2.13], [2.84], [1.25], [1.27], [2.75], [7.05], [1.84], [-0.87], [4.4], [5.44], [0.72], [2.71], [4.43], [2.12], [1.06], [1.77], [4.28], [0.72], [3.44], [-0.65], [0.98], [4.07], [1.32], [2.44], [1.5], [3.55], [0.26], [-0.83], [1.49], [5.0], [3.38], [2.12], [1.8], [-0.2], [3.65], [3.08], [4.46], [4.18], [2.36], [0.62], [3.82], [0.6], [0.83], [1.22], [-0.49], [1.23], [0.52], [1.5], [1.49], [1.13], [4.8], [6.47], [4.42], [3.02], [3.68], [2.85], [5.08], [-2.43], [0.65], [1.85], [3.55], [0.83], [2.63], [4.26], [0.62], [1.41], [5.23], [1.87], [3.46], [1.11], [1.5], [1.88], [7.1], [1.56], [2.82], [0.73], [0.55], [2.42], [0.11], [3.62], [2.81], [3.1], [2.88], [1.76], [1.9], [1.46], [0.99], [0.63], [6.4], [1.9], [0.84], [-0.69], [3.52], [2.37], [1.86], [-0.07], [-0.62], [3.25], [2.27], [3.38], [3.43], [2.98], [2.39], [0.88], [1.9], [-0.35], [1.29], [3.94], [0.38], [0.9], [-1.4], [3.05], [2.56], [2.58], [1.96], [1.47], [1.92], [2.89], [1.25], [-0.38], [0.27], [2.52], [1.82], [2.98], [2.06], [8.42], [1.4], [3.02], [2.78], [2.88], [1.78], [5.15], [4.7], [3.37], [3.7], [2.59], [4.52], [4.14], [-0.81], [2.76], [-0.52], [3.31], [4.78], [1.99], [3.67], [1.66], [0.25], [3.4], [5.53], [1.52], [0.04], [-0.64], [3.63], [0.23], [3.64], [2.09], [5.31], [6.63], [2.93], [0.59], [2.39], [1.77], [0.66], [0.76], [-0.5], [3.7], [3.18], [2.56], [-1.0], [1.26], [4.0], [0.95], [2.92], [2.12], [3.7], [1.2], [1.88], [-0.81], [1.63], [3.3], [2.3], [3.2], [4.3], [0.45], [0.49], [2.27], [6.74], [6.8], [3.21], [-0.47], [1.43], [3.4], [5.51], [1.01], [1.98], [3.87], [4.03], [1.4], [0.35], [2.71], [-0.03], [4.72], [0.52], [4.38], [2.42], [0.23], [2.17], [0.37], [2.34], [3.2], [2.32], [2.16], [2.81], [3.71], [0.73], [3.55], [1.87], [1.37], [-1.64], [2.24], [1.42], [4.75], [0.45], [1.99], [1.02], [-0.39], [3.72], [6.06], [5.12], [5.01], [2.27], [2.74], [3.61], [0.23], [2.7], [1.52], [2.48], [0.95], [2.25], [0.4], [2.63], [-0.03], [0.0], [1.64], [1.74], [-0.19], [4.22], [2.45], [-1.56], [5.25], [1.55], [-0.96], [-0.33], [1.78], [0.82], [1.69], [-0.71], [1.03], [3.54], [3.25], [3.29], [4.69], [5.18], [4.2], [0.97], [-0.09], [1.78], [5.29], [0.85], [0.96], [3.83], [4.38], [-0.36], [0.41], [1.48], [3.03], [1.7], [2.16], [1.82], [-0.04], [3.95], [1.39], [0.59], [2.69], [2.33], [-0.08], [0.04], [1.95], [3.14], [1.34], [0.61], [2.8], [1.72], [3.77], [3.88], [5.68], [1.3], [2.78], [1.44], [1.72], [6.67], [0.24], [-0.77], [1.54], [4.44], [6.3], [-1.7], [3.35], [1.26], [1.97], [2.72], [5.33], [4.54], [1.68], [2.9], [-0.79], [2.71], [2.44], [3.35], [4.88], [1.69], [3.06], [1.73], [5.6], [2.82], [3.17], [2.67], [3.85], [3.64], [2.02], [1.95], [0.29], [1.56], [1.6], [3.96], [-1.22], [0.89], [3.17], [0.81], [1.31], [1.58], [3.77], [2.68], [2.94], [0.8], [2.56], [-1.34], [1.98], [2.1], [2.19], [4.5], [1.29], [0.3], [0.13], [6.11], [3.18], [-0.31], [1.76], [1.09], [0.64], [1.13], [0.23], [0.74], [1.6], [-2.37], [4.01], [0.48], [4.53], [4.81], [-0.64], [0.11], [2.79], [4.67], [1.51], [7.11], [4.37], [0.07], [1.48], [4.89], [0.32], [2.86], [3.7], [0.34], [6.47], [3.83], [0.91], [2.1], [0.35], [3.4], [0.83], [2.44], [3.81], [-0.31], [0.68], [-0.51], [2.87], [0.38], [-1.09], [1.18], [4.5], [-0.32], [1.92], [4.91], [2.93], [1.32], [3.74], [-2.47], [4.47], [0.56], [1.98], [0.31], [1.74], [5.63], [2.04], [3.16], [1.67], [-2.16], [1.57], [1.64], [2.71], [2.44], [-0.62], [1.24], [0.77], [3.31], [-1.3], [0.18], [1.7], [2.83], [7.92], [2.01], [0.08], [3.38], [0.27], [-2.27], [-1.77], [1.4], [6.06], [-0.59], [0.27], [0.99], [5.66], [1.73], [2.5], [3.63], [1.28], [3.23], [4.31], [1.52], [3.07], [2.31], [3.9], [1.64], [5.03], [3.84], [0.03], [2.59], [3.77], [3.58], [2.36], [1.86], [3.7], [1.35], [0.72], [2.81], [1.67], [1.35], [4.94], [3.77], [3.62], [0.74], [6.25], [2.32], [0.8], [0.67], [0.23], [3.3], [4.22], [0.26], [4.05], [-2.45], [4.11], [1.54], [4.51], [0.92], [0.65], [3.4], [2.48], [1.34], [3.11], [0.23], [1.5], [-1.87], [0.84], [3.25], [0.4], [2.4], [3.24], [-0.45], [0.9], [4.92], [4.58], [-0.53], [5.09], [2.54], [2.9], [1.92], [0.32], [3.01], [4.34], [3.58], [-0.91], [1.28], [0.26], [0.67], [3.71], [6.93], [0.46], [4.26], [3.08], [1.49], [2.6], [2.54], [0.48], [3.24], [1.03], [0.55], [-2.83], [4.93], [1.57], [1.71], [-0.32], [2.17], [1.86], [1.1], [2.05], [0.57], [4.0], [4.82], [3.93], [-1.27], [2.74], [1.43], [-2.79], [2.09], [1.85], [1.3], [3.44], [2.47], [1.56], [3.92], [3.42], [1.5], [2.37], [3.46], [1.37], [1.73], [1.44], [6.51], [2.85], [0.21], [1.72], [0.22], [1.68], [4.55], [-0.81], [4.09], [1.98], [4.04], [0.54], [6.86], [2.41], [-1.65], [1.63], [-1.07], [2.33], [1.0], [4.56], [3.0], [6.07], [3.64], [2.53], [-1.51], [0.56], [2.33], [-0.47], [0.31], [2.73], [1.56], [3.94], [0.34], [2.6], [4.68], [1.15], [0.84], [0.63], [-0.89], [2.07], [2.07], [0.28], [-1.05], [2.96], [3.4], [4.1], [0.77], [3.18], [1.2], [2.39], [4.85], [5.04], [-0.17], [5.43], [1.01], [2.93], [1.97], [1.53], [1.51], [4.43], [0.84], [5.42], [0.71], [-0.47], [1.83], [2.78], [1.42], [2.38], [1.2], [4.37], [2.87], [1.95], [3.18], [1.56], [1.91], [5.72], [0.3], [2.92], [2.05], [3.61], [1.33], [2.3], [2.55], [3.01], [0.24], [5.55], [8.2], [1.23], [0.24], [2.21], [1.23], [-1.87], [2.62], [2.34], [-1.71], [0.9], [2.45], [4.27], [2.21], [1.99], [2.27], [0.66], [2.82], [1.31], [0.52], [0.01], [3.01], [1.21], [1.25], [0.71], [2.28], [0.5], [1.82], [2.4], [3.6], [1.94], [1.51], [1.94], [0.26], [0.64], [2.79], [0.78], [-0.38], [5.7], [7.19], [0.35], [4.07], [1.95], [0.1], [1.6], [4.51], [3.83], [2.44], [-1.2], [-0.32], [4.55], [2.54], [3.05], [0.35], [3.21], [3.61], [5.11], [3.35], [-0.44], [0.16], [1.23], [0.99], [3.03], [4.1], [2.62], [5.0], [4.2], [2.34], [1.62], [1.67], [0.58], [6.31], [3.67], [1.88], [0.18], [3.27], [1.29], [-0.64], [0.73], [0.5], [1.96], [3.87], [1.42], [1.6], [3.2], [2.22], [-0.21], [1.38], [2.28], [6.2], [0.3], [4.62], [5.77], [2.74], [3.2], [1.85], [1.3], [1.91], [3.39], [2.64], [1.05], [1.7], [-0.09], [3.12], [1.15], [-0.47], [1.8], [0.64], [2.45], [2.95], [2.08], [2.02], [5.81], [4.36], [2.44], [-0.11], [0.46], [1.02], [0.35], [0.55], [0.95], [4.98], [3.15], [1.16], [1.33], [1.76], [1.01], [3.31], [1.56], [2.03], [5.18], [3.48], [0.5], [0.07], [-0.38], [1.04], [1.93], [0.52], [0.36], [0.77], [0.02], [2.87], [1.68], [-0.4], [6.6], [3.57], [6.13], [1.99], [1.2], [5.11], [4.06], [3.95], [0.24], [-0.36], [-0.03], [1.2], [0.46], [4.4], [4.41], [3.4], [0.46], [1.66], [-0.59], [1.71], [3.91], [1.57], [1.65], [8.07], [1.36], [1.83], [5.18], [1.01], [2.29], [3.74], [2.82], [2.1], [0.25], [2.85], [-0.78], [3.96], [2.81], [1.62], [1.87], [0.67], [1.79], [0.39], [3.28], [4.52], [1.39], [1.87], [2.26], [0.57], [1.08], [4.59], [6.16], [2.88], [1.6], [3.26], [0.85], [1.38], [3.85], [5.15], [3.19], [3.7], [0.56], [3.3], [1.64], [1.7], [3.75], [1.12], [5.46], [2.93], [1.03], [2.23], [1.65], [1.36], [1.66], [3.78], [4.98], [1.76], [2.4], [7.31], [3.35], [0.36], [5.4], [-1.7], [2.77], [5.53], [-1.26], [0.57], [-0.62], [2.13], [0.8], [2.86], [3.65], [1.13], [2.2], [-0.35], [2.67], [-0.25], [1.95], [0.44], [-0.11], [2.84], [3.26], [0.95], [4.15], [0.4], [-0.39], [2.2], [-0.17], [0.32], [2.46], [3.47], [2.52], [2.08], [4.48], [2.57], [-0.18], [4.02], [5.05], [1.78], [-0.16], [2.3], [1.04], [3.66], [2.27], [1.98], [4.5], [2.78], [3.03], [1.94], [0.91], [3.13], [0.18], [3.41], [2.91], [4.56], [5.5], [1.56], [3.95], [-0.02], [1.61], [0.7], [-0.07], [1.45], [-1.66], [-0.68], [2.27], [3.15], [-0.49], [0.68], [2.32], [0.64], [1.07], [2.69], [3.38], [1.92], [1.89], [2.3], [2.05], [1.06], [2.74], [1.7], [2.03], [0.96], [1.9], [-0.85], [1.86], [4.56], [-1.13], [2.82], [3.42], [3.56], [2.66], [5.62], [2.78], [2.38], [3.35], [2.13], [3.08], [2.5], [6.11], [1.48], [2.39], [1.81], [0.87], [0.2], [1.38], [2.69], [1.27], [2.71], [0.3], [1.58], [3.1], [1.82], [-0.96], [0.05], [2.14], [4.66], [2.95], [0.13], [0.56], [1.08], [2.05], [0.11], [3.06], [4.13], [2.08], [1.56], [4.51], [1.38], [5.86], [2.4], [-0.3], [1.22], [1.6], [0.14], [0.36], [0.56], [2.68], [1.8], [3.28], [2.5], [0.82], [1.01], [1.62], [2.75], [5.43], [3.82], [2.44], [-0.05], [1.42], [4.29], [-1.98], [9.05], [2.74], [2.08], [2.52], [0.93], [1.2], [1.65], [0.93], [2.18], [2.77], [2.77], [2.37], [2.8], [3.6], [8.01], [2.59], [2.2], [0.54], [1.16], [0.46], [1.44], [0.71], [5.53], [3.6], [0.64], [4.32], [-1.58], [1.1], [-0.36], [1.94], [3.66], [3.34], [5.76], [3.1], [0.66], [-0.32], [7.2], [2.76], [2.31], [3.53], [5.49], [3.69], [0.23], [2.61], [0.37], [5.72], [0.13], [0.16], [0.69], [0.59], [3.87], [2.71], [0.61], [8.29], [0.95], [1.11], [1.52], [1.93], [2.67], [4.83], [4.42], [-0.56], [1.9], [3.35], [3.47], [-0.77], [1.58], [3.08], [4.88], [1.53], [8.68], [3.32], [2.33], [2.82], [3.75], [5.6], [3.27], [1.68], [2.79], [2.19], [2.6], [2.86], [2.8], [1.83], [4.0], [1.67], [2.3], [3.66], [0.91], [2.69], [1.88], [4.04], [-0.05], [-0.28], [2.53], [1.31], [1.63], [2.58], [3.19], [3.32], [4.17], [-2.91], [1.18], [3.25], [0.23], [0.05], [3.91], [4.32], [2.02], [2.98], [2.73], [1.62], [2.0], [2.21], [0.44], [2.32], [3.64], [3.85], [-0.96], [3.39], [0.29], [-2.03], [3.75], [3.08], [2.66], [3.53], [2.14], [0.91], [3.01], [0.1], [2.84], [2.62], [0.46], [1.38], [4.72], [2.13], [7.57], [1.61], [2.1], [1.77], [1.99], [5.66], [1.33], [-1.13], [3.63], [4.9], [-1.2], [1.19], [0.67], [3.01], [0.96], [1.18], [5.18], [0.09], [1.25], [0.32], [-1.91], [4.9], [3.7], [3.94], [2.14], [-0.54], [3.11], [2.02], [1.69], [-0.2], [3.0], [1.38], [2.49], [5.09], [1.23], [2.03], [3.13], [6.01], [1.57], [-1.34], [7.6], [2.4], [0.85], [2.18], [0.68], [0.36], [0.76], [2.93], [1.15], [1.94], [3.35], [2.28], [1.18], [1.96], [1.0], [1.82], [3.25], [5.19], [2.22], [1.1], [1.13], [2.82], [-1.58], [3.42], [1.4], [-1.88], [0.45], [0.81], [1.37], [4.7], [0.82], [0.39], [1.73], [-0.05], [2.59], [-1.57], [1.38], [0.3], [4.12], [0.12], [-0.7], [0.98], [-0.55], [2.54], [2.96], [1.46], [0.86], [4.85], [0.16], [1.74], [2.27], [3.27], [3.99], [2.36], [2.68], [2.07], [3.01], [0.47], [2.51], [2.93], [0.3], [2.29], [0.49], [2.6], [0.86], [1.21], [-0.05], [4.67], [2.1], [1.1], [4.49], [-0.5], [4.51], [4.55], [1.72], [2.09], [2.37], [-0.66], [2.5], [3.56], [0.43], [2.99], [0.28], [2.14], [3.16], [4.04], [1.98], [3.11], [0.3], [3.08], [1.88], [5.81], [1.35], [1.59], [0.51], [2.65], [3.9], [1.9], [6.2], [2.5], [3.89], [3.25], [1.31], [0.08], [2.11], [0.1], [1.0], [4.19], [1.68], [5.86], [2.66], [0.1], [2.72], [2.38], [4.99], [2.11], [4.37], [6.72], [2.68], [0.33], [-0.23], [2.62], [0.74], [2.66], [8.35], [3.2], [0.31], [3.69], [3.12], [2.23], [0.75], [0.85], [3.04], [3.65], [0.9], [3.55], [5.01], [-0.99], [3.13], [3.39], [0.7], [3.15], [1.88], [-1.3], [3.89], [7.43], [1.78], [3.7], [0.15], [2.83], [3.21], [3.65], [1.79], [4.51], [1.28], [2.73], [0.26], [0.98], [1.94], [-0.35], [1.14], [2.11], [1.98], [2.94], [1.64], [-0.78], [3.34], [3.13], [0.24], [1.5], [4.3], [1.77], [5.1], [1.42], [1.19], [1.94], [3.91], [2.33], [3.1], [1.83], [3.9], [1.52], [1.36], [1.46], [-1.23], [2.7], [0.82], [2.54], [4.04], [3.13], [0.0], [3.26], [2.74], [-0.48], [1.7], [0.16], [1.16], [0.38], [2.08], [3.13], [0.81], [2.52], [3.13], [3.49], [2.35], [1.23], [1.86], [1.88], [0.2], [1.44], [-3.05], [3.74], [-0.47], [2.04], [3.56], [4.43], [1.9], [2.09], [2.0], [-0.06], [1.7], [6.21], [3.68], [0.85], [-0.06], [-0.88], [0.13], [0.98], [2.3], [3.76], [4.04], [0.26], [2.62], [3.3], [4.34], [2.24], [5.9], [0.67], [1.99], [2.55], [1.05], [0.76], [8.56], [3.33], [2.02], [0.59], [2.9], [2.95], [-3.17], [1.89], [0.67], [0.56], [2.62], [1.85], [2.4], [3.94], [4.63], [2.82], [3.05], [1.27], [0.53], [5.76], [1.53], [1.49], [3.98], [7.29], [4.75], [1.19], [4.21], [6.01], [4.2], [1.85], [-1.11], [2.6], [2.42], [2.12], [4.9], [1.44], [3.82], [3.38], [1.46], [1.01], [0.93], [3.15], [4.17], [3.64], [1.63], [2.1], [2.93], [2.0], [-0.62], [3.16], [3.18], [0.72], [1.48], [-0.24], [1.12], [2.33], [0.52], [1.96], [-0.27], [1.45], [4.14], [4.17], [3.08], [3.5], [-0.26], [-0.32], [4.5], [3.94], [0.92], [-1.74], [7.11], [4.03], [4.95], [1.24], [5.31], [3.83], [3.42], [9.29], [-0.41], [2.41], [1.56], [3.28], [3.79], [-0.3], [2.06], [3.37], [6.59], [3.2], [2.05], [1.13], [3.58], [3.34], [6.59], [3.65], [-1.33], [3.13], [-0.47], [2.94], [2.51], [1.47], [-0.81], [0.72], [0.55], [2.41], [0.81], [4.56], [0.16], [1.81], [3.91], [3.19], [-1.64], [0.6], [2.16], [2.73], [5.45], [1.11], [2.11], [2.46], [2.28], [7.12], [1.05], [-0.06], [2.28], [0.61], [-0.29], [2.27], [1.69], [1.43], [0.58], [6.54], [2.51], [3.26], [2.4], [-0.62], [2.16], [3.52], [-0.48], [3.55], [2.33], [4.62], [2.21], [4.43], [2.8], [4.12], [0.8], [2.8], [3.58], [2.86], [4.49], [1.13], [2.54], [4.62], [0.94], [-0.3], [2.74], [4.31], [3.39], [5.19], [2.16], [2.48], [1.55], [1.72], [-0.35], [1.9], [3.01], [-1.1], [0.6], [1.34], [7.48], [3.2], [3.73], [1.7], [1.76], [3.96], [1.02], [1.45], [3.14], [5.41], [5.0], [3.14], [0.95], [-0.21], [3.35], [3.88], [1.27], [4.29], [-1.3], [-1.32], [0.13], [1.81], [-1.05], [0.97], [0.37], [3.86], [1.05], [4.33], [-0.23], [6.84], [3.3], [5.43], [1.49], [-2.85], [2.89], [5.44], [2.8], [3.23], [4.09], [-0.85], [1.3], [3.55], [1.28], [0.6], [0.36], [5.35], [3.47], [1.44], [2.84], [1.76], [1.78], [1.08], [4.99], [0.61], [3.78], [-0.7], [3.17], [4.66], [0.62], [1.13], [1.0], [2.92], [3.59], [-1.49], [1.05], [2.68], [3.73], [2.74], [2.71], [-0.22], [1.9], [2.32], [-0.58], [2.39], [0.28], [1.35], [-1.23], [-0.42], [3.78], [2.74], [-1.85], [2.75], [5.02], [0.65], [2.03], [4.43], [1.27], [-0.17], [2.07], [1.26], [2.74], [-1.13], [0.89], [3.71], [5.77], [4.79], [4.92], [1.18], [3.59], [5.4], [4.29], [1.37], [0.73], [9.32], [-0.66], [2.38], [3.63], [1.99], [0.41], [1.79], [2.57], [0.83], [3.62], [0.8], [0.46], [5.16], [1.98], [2.81], [4.57], [0.91], [2.17], [1.61], [2.14], [3.58], [1.77], [0.82], [0.9], [4.12], [0.9], [2.07], [0.59], [2.26], [1.75], [4.28], [4.13], [0.66], [1.06], [6.6], [0.75], [4.69], [-1.05], [1.4], [2.64], [1.98], [1.16], [2.34], [3.52], [1.09], [2.96], [2.01], [1.25], [-2.39], [0.98], [4.64], [4.37], [3.3], [2.6], [8.5], [1.79], [2.37], [8.05], [1.49], [2.3], [2.66], [4.38], [2.81], [-0.52], [4.01], [3.58], [1.81], [0.04], [2.07], [0.51], [0.85], [2.76], [0.74], [2.28], [2.05], [2.28], [2.26], [0.43], [2.46], [2.55], [-2.61], [1.97], [8.18], [0.65], [5.25], [2.75], [1.52], [1.19], [-1.41], [3.1], [4.5], [0.04], [1.91], [-0.28], [0.76], [4.37], [4.12], [4.66], [-0.85], [0.13], [1.01], [0.62], [4.37], [5.75], [2.75], [0.88], [3.43], [6.14], [2.92], [0.4], [1.05], [2.3], [1.4], [-3.03], [1.0], [2.01], [4.08], [1.82], [2.84], [2.47], [3.2], [1.7], [5.25], [2.3], [4.59], [2.85], [1.76], [4.75], [0.36], [0.54], [2.18], [0.55], [2.1], [0.47], [1.44], [0.6], [-0.43], [-0.76], [1.29], [1.24], [1.7], [2.0], [0.81], [2.67], [0.66], [1.61], [-1.8], [1.43], [-1.82], [1.9], [2.05], [3.34], [2.58], [2.25], [1.2], [2.09], [5.12], [2.23], [2.68], [3.77], [1.82], [1.68], [4.06], [0.88], [2.6], [3.26], [3.35], [-0.66], [3.85], [5.8], [0.83], [2.82], [-0.96], [2.72], [4.26], [1.81], [-1.49], [2.1], [2.5], [2.06], [2.73], [3.32], [2.05], [2.75], [-2.54], [1.63], [0.33], [-0.56], [2.51], [1.58], [1.41], [4.98], [0.44], [0.56], [6.49], [2.37], [0.6], [2.35], [0.48], [1.43], [-1.03], [2.23], [1.04], [2.39], [2.27], [1.17], [1.25], [1.26], [5.84], [1.19], [3.23], [4.6], [3.03], [1.17], [3.38], [0.99], [4.3], [0.96], [2.27], [4.96], [2.67], [4.23], [2.81], [3.79], [-2.03], [0.72], [-1.25], [1.7], [2.34], [3.94], [2.62], [5.99], [1.57], [3.96], [1.48], [4.26], [0.71], [-0.56], [0.8], [5.68], [0.92], [2.2], [4.4], [5.28], [2.71], [0.11], [0.43], [0.97], [-0.33], [1.6], [5.44], [0.94], [2.24], [5.7], [3.8], [1.09], [2.37], [6.22], [4.28], [3.55], [2.2], [2.72], [2.68], [1.01], [1.14], [0.34], [3.14], [-0.47], [2.23], [-0.64], [3.49], [-1.8], [5.26], [3.14], [3.1], [0.95], [7.15], [3.5], [1.77], [3.39], [1.92], [1.75], [3.29], [2.54], [1.95], [-2.49], [6.47], [-2.2], [4.31], [2.56], [1.02], [2.46], [1.72], [-1.38], [-1.46], [-0.11], [3.94], [1.93], [1.26], [2.66], [0.32], [2.43], [1.63], [0.32], [1.47], [-0.3], [1.2], [0.12], [0.29], [0.86], [1.96], [0.95], [0.32], [-1.86], [5.57], [1.99], [2.8], [2.17], [0.91], [3.95], [3.99], [2.05], [2.85], [0.65], [2.38], [3.37], [1.76], [-0.95], [2.51], [0.93], [2.63], [5.47], [3.43], [-0.21], [1.24], [2.52], [0.03], [-0.15], [1.19], [-0.51], [-0.04], [3.42], [2.51], [4.49], [-0.23], [8.06], [1.36], [2.68], [1.36], [0.64], [0.87], [2.13], [1.9], [1.28], [4.25], [-0.06], [2.39], [-0.51], [-1.87], [4.83], [1.81], [4.73], [2.52], [2.59], [3.6], [1.98], [3.17], [8.23], [4.88], [-2.57], [2.3], [3.04], [1.57], [2.18], [0.69], [3.18], [2.08], [2.63], [1.18], [3.2], [2.81], [1.24], [4.25], [2.22], [4.93], [0.48], [2.41], [4.5], [1.3], [1.41], [1.34], [2.29], [0.44], [7.12], [-1.05], [2.3], [2.86], [2.98], [0.56], [1.27], [2.06], [3.81], [7.7], [3.6], [1.7], [6.97], [0.89], [-0.41], [2.74], [3.35], [1.02], [6.41], [-0.4], [1.21], [1.31], [3.41], [2.9], [3.24], [7.01], [3.29], [6.45], [-0.61], [0.97], [5.11], [1.48], [0.89], [1.81], [0.3], [3.05], [1.45], [5.3], [0.58], [3.33], [0.75], [0.7], [0.21], [2.99], [0.26], [2.73], [1.4], [2.62], [0.34], [4.2], [4.45], [2.47], [6.26], [0.74], [3.32], [1.03], [2.24], [2.75], [1.8], [0.76], [1.23], [0.28], [1.09], [2.6], [1.75], [2.41], [2.56], [0.98], [3.07], [-0.95], [6.0], [6.91], [0.94], [1.03], [2.19], [4.73], [6.26], [1.57], [1.94], [4.36], [1.05], [3.63], [3.23], [6.9], [1.0], [2.82], [3.6], [4.86], [-0.05], [5.95], [3.08], [1.66], [1.29], [3.01], [3.95], [0.4], [1.75], [4.98], [4.15], [1.78], [1.89], [2.06], [1.73], [3.66], [1.59], [4.6], [1.8], [6.39], [1.34], [1.2], [2.59], [0.38], [1.7], [3.3], [2.62], [2.41], [1.98], [-0.28], [2.61], [0.87], [-1.34], [0.23], [-0.03], [2.09], [1.93], [3.49], [1.61], [1.94], [3.68], [3.99], [2.82], [1.8], [5.87], [3.03], [3.0], [0.56], [1.0], [3.97], [-0.4], [4.05], [-0.9], [1.01], [2.72], [0.06], [3.23], [3.87], [-0.84], [0.92], [1.6], [0.56], [1.4], [3.37], [2.05], [0.69], [0.62], [0.15], [1.38], [2.39], [1.81], [1.86], [0.56], [4.09], [5.02], [0.15], [4.62], [1.12], [1.94], [2.6], [1.37], [3.55], [3.54], [1.09], [0.05], [3.92], [0.13], [3.44], [4.64], [2.98], [-0.2], [3.1], [0.09], [-0.45], [4.54], [3.77], [1.79], [2.14], [3.75], [1.87], [-1.22], [3.27], [4.85], [1.79], [3.81], [-0.05], [0.52], [-0.15], [2.28], [6.44], [5.74], [0.48], [0.67], [-0.71], [0.85], [3.4], [4.39], [2.52], [0.0], [2.43], [3.61], [6.11], [2.5], [-3.1], [3.37], [-0.17], [2.36], [-0.41], [0.0], [6.51], [2.03], [0.17], [5.81], [0.67], [4.49], [0.02], [0.08], [5.15], [1.69], [3.71], [1.73], [1.0], [0.26], [4.74], [3.63], [4.77], [2.9], [0.6], [3.54], [1.37], [3.92], [4.03], [6.68], [3.43], [-0.66], [1.09], [4.38], [0.07], [-1.06], [3.13], [1.22], [-0.03], [4.31], [1.52], [1.63], [0.57], [2.59], [4.66], [5.11], [1.17], [1.26], [0.39], [1.46], [2.3], [1.05], [1.7], [2.6], [4.86], [1.69], [0.88], [3.75], [1.16], [4.63], [0.58], [3.25], [0.58], [2.35], [1.03], [1.43], [0.26], [0.56], [0.9], [4.14], [0.07], [2.5], [0.96], [0.15], [2.85], [3.38], [2.77], [1.32], [3.54], [1.86], [2.03], [4.0], [1.34], [1.5], [1.54], [2.78], [-1.43], [1.64], [1.88], [0.12], [2.8], [2.67], [2.73], [2.4], [2.85], [1.69], [1.91], [4.95], [0.87], [3.17], [3.65], [2.42], [3.37], [1.99], [2.2], [2.91], [0.21], [5.32], [1.37], [1.42], [3.6], [0.54], [1.67], [4.47], [2.8], [1.73], [2.32], [5.62], [1.34], [0.5], [-2.54], [2.86], [5.17], [1.71], [3.37], [5.45], [-0.44], [5.42], [2.08], [-0.64], [-0.3], [2.79], [3.62], [3.06], [2.73], [2.96], [2.9], [5.36], [-0.92], [2.4], [2.7], [-0.04], [1.61], [5.8], [0.88], [2.24], [4.28], [3.72], [1.62], [6.25], [2.0], [1.79], [-0.81], [0.43], [1.59], [-0.18], [-0.35], [1.65], [1.22], [2.72], [3.94], [0.9], [1.62], [1.07], [3.59], [3.87], [1.67], [1.68], [0.15], [0.99], [-1.82], [5.5], [1.94], [-0.07], [2.78], [0.19], [2.4], [2.93], [-0.42], [0.83], [2.93], [4.58], [1.38], [0.68], [1.53], [2.12], [-1.47], [0.76], [0.48], [0.72], [4.14], [5.35], [0.57], [1.59], [1.98], [4.04], [2.86], [1.87], [2.76], [2.7], [4.27], [2.11], [-0.27], [2.11], [3.03], [1.66], [-0.73], [1.58], [1.11], [2.25], [3.48], [2.03], [-0.59], [1.22], [0.68], [5.9], [3.44], [2.14], [3.74], [0.49], [3.2], [5.15], [3.31], [-1.43], [3.0], [3.75], [1.57], [2.03], [3.13], [0.03], [3.85], [1.63], [4.81], [2.33], [0.27], [2.34], [0.63], [2.82], [4.54], [0.83], [3.83], [5.85], [2.21], [2.88], [5.17], [1.63], [2.07], [-2.27], [1.31], [1.2], [-1.14], [0.4], [5.5], [-0.92], [0.87], [8.19], [6.11], [1.83], [-2.0], [-1.59], [4.26], [0.16], [-0.83], [1.24], [3.78], [3.15], [0.74], [0.96], [1.82], [3.56], [3.47], [1.59], [3.65], [2.29], [2.63], [2.04], [2.52], [4.68], [2.42], [4.73], [2.22], [3.82], [0.3], [1.14], [8.77], [3.35], [0.7], [2.2], [3.13], [3.72], [2.96], [3.62], [1.57], [8.38], [5.39], [1.0], [0.15], [4.28], [2.06], [1.75], [1.03], [0.23], [1.64], [3.87], [0.38], [2.42], [-0.32], [1.59], [5.31], [1.51], [2.47], [1.73], [0.84], [4.49], [-1.54], [1.98], [0.62], [0.3], [2.97], [1.19], [-1.85], [1.55], [2.22], [3.91], [-2.07], [0.0], [4.48], [5.52], [-0.89], [0.97], [2.47], [0.5], [0.38], [-0.28], [3.76], [1.9], [-1.05], [2.3], [6.72], [-0.86], [-1.07], [4.17], [0.41], [-1.18], [2.5], [2.22], [0.78], [1.15], [3.49], [4.21], [0.83], [4.41], [1.61], [5.1], [-0.36], [2.23], [0.03], [-0.11], [2.04], [6.4], [0.53], [2.55], [-1.38], [4.28], [1.64], [2.21], [3.39], [2.48], [3.04], [2.86], [0.13], [3.24], [3.82], [1.81], [4.9], [0.97], [3.02], [1.41], [4.69], [7.97], [1.96], [3.83], [1.5], [2.25], [0.26], [-2.14], [0.93], [2.18], [2.53], [3.25], [1.75], [3.79], [3.21], [2.0], [0.78], [3.56], [3.21], [-0.42], [4.41], [3.82], [0.23], [3.25], [4.97], [1.24], [6.98], [0.84], [3.34], [3.12], [5.04], [0.98], [2.33], [-0.23], [4.58], [1.78], [5.19], [2.46], [2.21], [1.99], [2.17], [2.59], [-0.09], [2.92], [2.81], [1.81], [3.61], [0.58], [0.66], [1.88], [3.7], [3.69], [-1.35], [0.34], [-1.38], [0.32], [1.14], [6.39], [0.15], [-0.04], [3.15], [3.76], [0.83], [1.6], [1.54], [2.86], [4.27], [1.08], [3.88], [4.45], [2.05], [3.35], [4.2], [1.71], [2.29], [4.19], [0.46], [5.56], [0.48], [0.64], [1.44], [-0.69], [-4.64], [0.33], [0.04], [0.63], [3.2], [0.85], [3.27], [1.55], [3.43], [0.33], [5.06], [0.44], [3.05], [0.67], [2.1], [1.24], [0.76], [1.38], [3.31], [2.53], [5.76], [4.57], [-1.43], [2.09], [0.39], [2.45], [-2.28], [1.5], [3.91], [1.47], [1.38], [1.85], [0.89], [2.61], [4.09], [-2.84], [0.73], [-1.79], [-2.0], [3.4], [2.0], [2.18], [1.33], [4.21], [1.86], [0.34], [2.78], [1.4], [3.23], [2.71], [1.96], [1.75], [1.03], [0.08], [0.24], [2.98], [1.51], [2.14], [3.67], [0.255], [2.23], [-0.33], [1.41], [2.04], [3.08], [4.2], [0.09], [5.49], [3.03], [2.73], [1.29], [2.22], [1.81], [-0.19], [3.78], [2.94], [0.3], [0.59], [3.55], [1.16], [2.44], [1.28], [-0.55], [4.33], [3.41], [5.76], [3.72], [-1.21], [7.17], [-0.06], [-1.6], [4.06], [1.77], [1.6], [4.3], [0.01], [4.55], [1.72], [3.9], [4.33], [1.44], [3.71], [1.89], [2.26], [2.14], [2.88], [0.49], [2.0], [2.4], [4.4], [1.07], [1.39], [2.83], [3.3], [0.04], [2.49], [3.03], [3.8], [1.44], [5.67], [2.07], [0.87], [3.08], [3.13], [2.79], [0.18], [1.58], [1.14], [1.18], [-1.12], [3.35], [0.16], [0.53], [3.0], [1.4], [1.65], [0.52], [6.9], [2.94], [4.34], [4.04], [3.87], [2.61], [-0.36], [2.76], [1.74], [0.95], [-1.22], [1.85], [4.67], [0.33], [1.66], [2.41], [0.97], [-3.31], [1.28], [5.74], [4.45], [3.77], [7.91], [0.44], [1.87], [1.81], [3.44], [-1.88], [1.06], [3.44], [3.74], [-0.08], [0.56], [6.19], [3.41], [1.5], [2.32], [1.34], [-1.14], [0.97], [4.6], [1.41], [2.88], [4.54], [5.5], [2.15], [4.52], [1.17], [2.7], [1.75], [1.88], [4.27], [4.42], [5.51], [4.14], [1.84], [2.64], [5.83], [0.83], [2.18], [1.15], [2.69], [0.16], [0.45], [4.63], [1.96], [0.18], [1.81], [2.36], [1.73], [0.66], [1.76], [2.28], [0.16], [-0.8], [3.71], [2.41], [3.41], [-0.76], [0.9], [0.89], [2.4], [7.07], [-0.36], [2.68], [1.75], [0.101], [3.82], [5.31], [4.18], [0.87], [1.42], [3.69], [4.09], [1.51], [2.2], [2.84], [0.12], [3.16], [2.63], [0.95], [4.48], [2.2], [2.46], [3.05], [2.0], [3.26], [1.52], [1.13], [-0.3], [0.19], [-0.47], [2.27], [0.69], [2.68], [1.26], [-2.13], [5.27], [4.0], [1.12], [7.5], [2.66], [2.3], [0.62], [1.81], [3.73], [5.55], [1.71], [-0.86], [3.39], [0.61], [4.11], [2.92], [1.96], [0.46], [2.19], [-1.45], [2.11], [1.8], [1.66], [7.64], [1.61], [4.06], [2.36], [5.16], [0.42], [1.66], [4.69], [1.43], [1.13], [1.79], [2.73], [1.69], [1.62], [2.36], [3.0], [3.57], [3.51], [1.3], [1.64], [5.13], [-0.69], [5.77], [4.8], [5.14], [5.41], [3.1], [1.0], [2.97], [1.4], [3.1], [1.78], [4.03], [1.73], [3.42], [3.94], [0.89], [1.41], [6.08], [4.93], [2.05], [5.9], [3.4], [0.69], [2.65], [1.16], [0.99], [1.61], [6.58], [2.29], [1.73], [4.8], [0.23], [2.2], [3.12], [4.96], [2.15], [5.24], [0.23], [2.33], [1.21], [-0.06], [4.41], [2.24], [-0.54], [0.5], [2.81], [0.33], [3.45], [3.82], [2.8], [2.75], [5.7], [3.66], [2.68], [0.71], [1.35], [0.59], [8.14], [4.06], [-0.34], [1.76], [0.6], [4.47], [1.53], [4.48], [1.69], [-0.81], [2.37], [4.09], [3.21], [4.07], [-0.48], [2.45], [1.42], [0.4], [2.85], [2.81], [1.09], [1.43], [2.11], [0.17], [3.31], [1.63], [4.53], [-0.47], [1.2], [1.82], [4.44], [0.01], [3.15], [-1.27], [3.05], [0.9], [4.19], [-0.16], [1.4], [6.95], [3.24], [1.82], [2.34], [3.38], [1.8], [4.64], [4.96], [6.12], [2.87], [3.1], [1.49], [2.36], [0.37], [3.15], [0.28], [0.96], [3.27], [3.46], [2.13], [0.74], [-1.15], [1.68], [2.42], [3.61], [1.38], [4.33], [1.7], [-0.59], [5.58], [3.6], [3.81], [2.03], [1.03], [3.43], [2.28], [2.38], [2.5], [1.7], [0.2], [-0.16], [1.54], [4.11], [0.93], [1.86], [2.18], [2.34], [2.41], [6.23], [3.45], [3.51], [0.22], [0.25], [2.26], [3.3], [3.35], [3.86], [1.44], [-2.64], [0.72], [3.15], [2.0], [1.08], [0.42], [1.01], [-0.52], [4.15], [0.46], [3.93], [0.93], [1.82], [-1.51], [3.0], [0.86], [-0.9], [0.36], [7.41], [2.52], [2.03], [-0.66], [-0.24], [3.76], [1.16], [1.34], [2.15], [-0.16], [2.01], [4.53], [0.47], [-0.46], [1.16], [0.41], [0.2], [2.61], [1.1], [5.13], [2.61], [-0.12], [1.86], [-0.15], [0.02], [3.5], [2.35], [3.06], [3.28], [1.22], [4.47], [3.39], [3.28], [2.34], [1.2], [2.91], [1.61], [6.3], [1.85], [2.42], [3.35], [2.8], [1.32], [4.1], [6.5], [6.8], [2.78], [4.3], [4.79], [2.16], [4.22], [2.39], [2.45], [2.22], [-0.6], [1.04], [1.69], [6.78], [4.18], [1.87], [1.8], [2.4], [1.34], [3.1], [-1.52], [2.64], [0.8], [1.96], [6.3], [3.0], [5.5], [1.61], [0.36], [5.85], [6.44], [3.4], [3.89], [3.03], [3.97], [2.67], [0.76], [-1.38], [2.31], [-0.03], [2.72], [1.03], [3.26], [3.67], [1.63], [0.9], [-2.16], [3.06], [4.25], [2.07], [2.76], [1.75], [3.42], [2.52], [0.11], [2.33], [1.52], [1.94], [0.28], [1.01], [7.37], [5.55], [-1.08], [3.14], [4.64], [1.86], [2.4], [1.21], [1.13], [4.9], [2.88], [2.49], [0.35], [0.85], [-0.41], [0.79], [2.88], [0.33], [1.43], [2.18], [1.88], [2.61], [2.23], [6.0], [1.79], [2.96], [1.12], [1.2], [3.63], [4.63], [2.67], [0.2], [3.12], [3.53], [7.01], [4.24], [3.11], [-0.04], [2.79], [5.2], [-1.71], [2.82], [-2.52], [3.8], [2.6], [2.01], [-0.92], [4.66], [2.55], [1.02], [0.31], [0.12], [1.12], [0.91], [3.99], [2.5], [2.85], [2.75], [1.34], [2.95], [-0.9], [2.25], [2.05], [1.26], [0.89], [3.54], [4.45], [3.46], [1.33], [1.55], [0.86], [0.37], [1.7], [0.39], [1.29], [1.34], [1.87], [4.1], [2.82], [3.13], [0.83], [4.16], [-0.2], [2.95], [4.52], [0.68], [0.08], [3.96], [2.64], [0.91], [4.24], [-1.11], [2.24], [0.24], [1.47], [0.76], [4.73], [0.12], [1.85], [7.4], [4.35], [5.03], [-1.3], [2.6], [0.54], [2.2], [1.95], [-0.31], [3.02], [-0.87], [1.22], [3.53], [7.84], [-1.2], [1.15], [-1.87], [-0.27], [1.74], [0.89], [2.71], [0.4], [0.51], [2.98], [2.14], [1.81], [2.3], [6.11], [2.06], [1.5], [2.42], [7.04], [3.6], [-0.1], [1.27], [3.41], [2.56], [2.3], [2.9], [1.26], [5.02], [-0.65], [3.72], [-0.3], [2.74], [1.87], [1.59], [1.1], [4.27], [-0.9], [1.6], [1.29], [3.18], [2.85], [1.14], [2.2], [4.4], [2.62], [4.51], [3.32], [0.29], [3.04], [3.27], [1.13], [1.74], [0.9], [0.3], [3.38], [3.5], [-0.42], [-0.99], [1.04], [3.01], [0.58], [1.77], [1.25], [2.68], [5.74], [1.97], [2.73], [1.73], [1.8], [3.37], [2.46], [3.43], [0.6], [2.68], [2.0], [0.86], [3.4], [-0.53], [3.6], [-1.0], [1.74], [4.51], [1.53], [1.79], [1.27], [1.55], [0.65], [-1.7], [0.4], [4.22], [2.71], [1.17], [5.51], [2.32], [3.7], [0.37], [6.65], [-0.38], [2.87], [1.73], [1.19], [2.02], [0.91], [-0.6], [7.28], [2.14], [0.12], [-0.02], [1.62], [3.74], [2.88], [2.06], [7.17], [3.04], [5.49], [5.47], [-0.22], [2.18], [1.34], [-1.1], [3.82], [2.45], [3.89], [-0.35], [1.97], [2.35], [1.87], [3.71], [4.55], [2.85], [0.99], [2.38], [1.55], [3.12], [0.63], [1.4], [3.33], [-0.1], [2.98], [1.41], [1.02], [2.03], [0.52], [2.98], [2.26], [6.61], [-0.43], [1.19], [3.71], [2.53], [0.44], [0.75], [0.31], [0.91], [2.82], [1.1], [3.88], [-0.34], [6.85], [3.58], [0.85], [2.99], [0.69], [-0.64], [-1.56], [2.11], [1.57], [0.84], [1.5], [1.88], [1.05], [1.4], [4.09], [2.57], [4.02], [2.24], [0.27], [2.68], [3.92], [-0.13], [-1.14], [1.57], [2.53], [1.65], [-1.32], [-0.07], [2.18], [-1.03], [2.15], [1.17], [4.56], [1.62], [3.8], [3.18], [0.86], [-1.78], [3.69], [1.77], [5.49], [1.63], [0.94], [0.47], [1.31], [4.6], [2.45], [1.16], [3.98], [5.76], [2.2], [-0.21], [8.06], [1.69], [1.67], [1.1], [2.42], [0.83], [3.05], [2.49], [6.63], [3.79], [1.71], [2.3], [0.05], [2.83], [4.81], [0.95], [2.65], [4.89], [2.6], [3.56], [0.91], [4.5], [1.15], [0.82], [-1.5], [2.1], [1.78], [0.34], [0.94], [4.78], [4.62], [2.51], [-1.07], [3.23], [3.27], [1.28], [0.25], [-0.92], [1.48], [-0.96], [3.7], [2.03], [0.86], [3.14], [0.63], [4.94], [9.07], [3.23], [2.11], [0.63], [1.23], [0.21], [4.2], [3.3], [2.97], [2.71], [-0.74], [1.81], [3.78], [0.75], [3.48], [3.68], [1.78], [3.78], [2.1], [3.79], [3.6], [-0.07], [-1.44], [2.1], [2.96], [0.76], [2.06], [6.3], [3.18], [2.25], [-0.37], [5.73], [1.07], [0.4], [0.46], [2.56], [4.1], [3.95], [3.19], [4.75], [2.41], [-0.49], [1.11], [1.72], [0.35], [1.7], [3.0], [2.17], [0.14], [-0.45], [5.34], [3.81], [1.02], [2.58], [0.41], [0.95], [4.1], [3.27], [5.08], [0.47], [4.34], [0.12], [4.68], [1.77], [2.5], [2.09], [0.2], [1.97], [0.84], [2.42], [2.1], [-0.29], [1.42], [1.87], [2.37], [2.76], [1.4], [3.09], [2.05], [1.98], [4.05], [1.64], [4.99], [4.32], [-3.49], [0.65], [4.05], [-2.8], [4.48], [2.76], [2.31], [1.58], [1.92], [0.32], [-0.4], [5.2], [7.35], [-0.99], [0.98], [3.77], [5.44], [-0.49], [1.13], [4.04], [-0.45], [1.42], [2.04], [0.54], [1.89], [-1.41], [1.0], [2.25], [0.04], [5.28], [5.69], [1.39], [1.31], [3.99], [2.38], [2.62], [1.89], [3.56], [1.03], [1.36], [1.88], [-0.52], [3.19], [2.59], [2.59], [3.31], [0.12], [2.51], [1.13], [1.26], [6.17], [0.0], [3.27], [2.09], [2.61], [0.92], [3.18], [2.03], [1.17], [2.1], [2.37], [3.03], [1.14], [1.48], [2.91], [3.55], [1.96], [5.45], [1.48], [1.92], [0.45], [4.64], [2.4], [1.3], [1.19], [1.91], [2.72], [-0.2], [1.33], [2.29], [-0.37], [3.79], [3.84], [1.36], [0.36], [0.72], [2.48], [-2.28], [1.37], [7.55], [3.0], [2.14], [0.81], [2.26], [0.03], [3.53], [2.03], [0.27], [5.72], [3.0], [0.66], [4.33], [-0.6], [2.48], [4.68], [3.14], [-1.11], [1.39], [4.24], [3.1], [2.84], [2.59], [2.35], [-0.31], [0.72], [-1.59], [2.37], [2.8], [1.27], [2.24], [2.2], [4.11], [1.99], [0.07], [0.96], [0.14], [0.28], [2.47], [1.14], [2.82], [1.18], [1.19], [2.88], [1.64], [2.41], [0.23], [-0.09], [2.9], [-0.07], [4.28], [3.63], [1.58], [2.26], [0.16], [1.86], [0.08], [4.57], [0.33], [0.84], [-0.67], [5.0], [-0.29], [3.33], [1.58], [3.35], [-1.4], [3.18], [4.45], [3.17], [3.09], [3.59], [1.51], [0.53], [-0.4], [1.29], [1.63], [2.64], [0.91], [1.71], [-0.93], [1.18], [2.7], [0.21], [0.32], [0.6], [0.79], [1.2], [2.21], [8.39], [2.25], [2.03], [3.31], [0.77], [1.13], [2.37], [1.25], [3.3], [0.6], [0.51], [2.01], [1.75], [1.04], [4.3], [2.71], [2.64], [2.08], [1.26], [4.35], [2.84], [1.68], [1.16], [1.02], [-0.67], [-0.08], [-3.54], [2.74], [-0.1], [2.8], [0.34], [0.65], [0.93], [0.6], [-0.23], [4.11], [1.46], [1.98], [0.81], [4.7], [2.47], [1.0], [3.17], [0.14], [1.58], [-0.89], [-0.48], [1.59], [-0.53], [2.53], [3.53], [-1.05], [4.3], [3.6], [1.79], [2.02], [-0.13], [-0.26], [3.37], [2.13], [4.1], [0.16], [1.25], [0.79], [1.88], [2.24], [3.52], [2.84], [0.71], [1.28], [0.21], [0.51], [-0.1], [3.54], [1.39], [2.73], [0.42], [0.62], [2.29], [2.59], [-0.43], [3.44], [7.6], [1.15], [2.6], [-0.47], [-0.22], [1.67], [2.39], [-0.8], [2.86], [3.1], [1.05], [2.55], [0.56], [0.87], [2.26], [7.04], [1.91], [2.81], [5.13], [-2.23], [1.92], [4.56], [1.06], [7.1], [2.12], [3.88], [3.09], [3.8], [1.35], [1.88], [0.7], [1.9], [2.07], [2.78], [1.72], [3.12], [1.66], [0.8], [0.76], [-2.03], [5.38], [3.56], [1.4], [2.41], [0.32], [0.99], [3.67], [4.06], [6.51], [2.05], [4.55], [4.99], [-0.47], [2.78], [1.7], [6.0], [1.67], [3.72], [4.55], [3.57], [3.8], [2.1], [1.8], [-0.26], [-1.89], [-0.31], [0.37], [3.42], [2.75], [2.48], [2.43], [4.54], [1.26], [0.4], [-0.22], [0.28], [5.05], [3.49], [2.08], [1.12], [2.26], [-0.61], [1.91], [2.62], [3.11], [2.8], [0.5], [-1.73], [2.62], [0.23], [1.92], [3.32], [2.63], [1.77], [2.07], [2.5], [1.43], [-0.55], [8.62], [1.17], [4.28], [0.6], [0.54], [-2.12], [2.87], [4.64], [3.21], [5.88], [3.99], [0.85], [2.53], [3.47], [4.8], [3.35], [4.55], [2.1], [4.38], [2.83], [4.44], [0.97], [2.03], [-0.41], [0.62], [4.3], [1.82], [0.24], [2.22], [1.0], [-1.19], [1.93], [-1.41], [2.6], [-0.9], [3.08], [4.89], [0.63], [1.41], [-0.8], [2.42], [-0.75], [1.67], [2.08], [1.88], [0.96], [1.67], [0.41], [-0.71], [0.94], [2.74], [1.23], [0.77], [0.59], [2.42], [5.02], [1.2], [3.58], [1.88], [1.83], [0.61], [2.19], [-0.48], [-0.76], [1.51], [1.54], [2.51], [-0.62], [3.84], [0.47], [2.15], [1.92], [1.52], [0.9], [4.53], [3.09], [3.16], [1.86], [0.87], [1.06], [4.74], [2.19], [3.4], [1.46], [2.43], [2.62], [0.38], [3.75], [4.73], [3.4], [-2.75], [1.35], [2.06], [0.61], [5.5], [1.96], [2.21], [1.8], [1.23], [2.31], [1.97], [2.72], [-1.23], [1.81], [1.15], [6.14], [0.99], [2.9], [1.63], [3.77], [0.6], [1.6], [4.48], [1.54], [2.23], [2.07], [4.19], [3.37], [1.61], [1.86], [1.24], [2.72], [0.83], [3.88], [1.82], [2.84], [0.57], [1.0], [2.69], [1.04], [2.29], [0.01], [2.09], [4.15], [1.71], [3.11], [0.35], [2.5], [1.63], [2.14], [1.85], [-1.18], [1.53], [0.21], [0.16], [3.5], [1.6], [1.46], [-0.3], [0.04], [2.53], [1.79], [5.07], [0.58], [1.13], [-1.54], [-0.37], [0.65], [-0.87], [2.45], [2.59], [0.48], [2.36], [0.8], [0.2], [2.84], [2.2], [1.96], [2.26], [4.47], [2.19], [3.97], [-0.54], [2.32], [0.28], [-1.52], [4.49], [1.13], [4.85], [3.63], [2.51], [1.63], [3.62], [2.47], [2.57], [3.63], [4.31], [0.8], [3.93], [3.45], [0.3], [2.3], [4.15], [2.07], [1.31], [2.5], [2.77], [3.72], [4.36], [2.96], [0.84], [2.6], [-0.64], [0.06], [2.59], [-0.79], [1.85], [2.4], [3.81], [1.37], [0.82], [2.3], [3.29], [1.47], [5.49], [2.76], [1.65], [1.64], [4.1], [1.88], [1.04], [3.58], [4.45], [0.86], [3.19], [1.54], [3.5], [1.81], [1.66], [-1.57], [1.7], [3.95], [9.14], [1.94], [2.51], [0.07], [1.47], [0.6], [4.11], [0.22], [2.31], [3.01], [-0.67], [1.8], [4.08], [-0.92], [3.78], [-3.1], [1.15], [2.57], [2.67], [0.29], [-1.24], [1.94], [-0.17], [2.2], [2.39], [2.0], [6.67], [3.3], [1.0], [3.23], [2.16], [4.3], [0.49], [0.1], [2.9], [5.89], [-0.21], [1.38], [1.23], [0.09], [2.29], [-0.05], [0.05], [5.81], [1.07], [7.71], [3.03], [1.28], [2.66], [-0.29], [1.17], [1.59], [3.21], [0.59], [2.28], [0.38], [-1.37], [2.47], [4.36], [-0.35], [0.42], [2.62], [1.93], [2.32], [6.64], [4.42], [0.22], [-0.5], [2.79], [6.37], [2.03], [1.09], [2.98], [-0.26], [1.03], [3.18], [4.4], [3.11], [0.13], [3.5], [3.4], [1.36], [2.34], [-0.62], [4.35], [2.89], [3.62], [0.71], [1.73], [1.47], [5.69], [0.0], [3.06], [-0.33], [1.68], [1.04], [2.16], [3.48], [2.33], [3.38], [-0.29], [2.23], [1.58], [0.43], [1.51], [-0.19], [0.12], [3.42], [1.52], [2.58], [1.8], [2.65], [-0.53], [2.46], [4.12], [0.7], [2.05], [1.55], [3.28], [1.77], [4.22], [-0.68], [2.12], [0.76], [1.71], [2.83], [4.7], [4.49], [3.18], [1.17], [2.21], [-0.84], [4.47], [-0.67], [2.62], [0.48], [3.66], [1.59], [2.48], [2.4], [1.12], [5.27], [2.74], [2.22], [1.59], [3.9], [-1.85], [1.41], [3.65], [-0.74], [2.95], [1.56], [1.25], [0.53], [-0.16], [1.31], [3.41], [2.52], [2.8], [1.47], [1.31], [5.53], [0.7], [2.31], [7.02], [1.8], [2.71], [-0.66], [0.97], [4.25], [1.64], [3.75], [-1.38], [0.73], [1.52], [2.85], [0.62], [1.31], [-0.83], [1.87], [-1.1], [2.45], [1.95], [1.98], [2.21], [-0.89], [0.25], [6.73], [-0.46], [3.82], [1.12], [2.14], [2.73], [0.2], [4.48], [2.56], [8.84], [5.6], [2.92], [1.02], [3.51], [3.65], [3.29], [4.05], [1.51], [4.49], [1.32], [2.5], [1.28], [8.1], [2.45], [4.5], [3.61], [0.15], [-0.74], [2.31], [1.6], [3.92], [2.91], [2.67], [-4.2], [1.12], [0.02], [2.69], [4.25], [1.12], [3.09], [0.3], [1.96], [3.03], [2.18], [1.75], [-1.97], [2.03], [1.57], [3.08], [5.08], [1.17], [1.06], [3.3], [2.0], [1.47], [1.2], [2.54], [1.2], [3.45], [0.22], [0.98], [1.1], [0.64], [2.24], [3.63], [-0.53], [3.17], [0.65], [1.41], [2.1], [2.66], [-0.87], [4.44], [3.8], [2.78], [7.0], [5.47], [1.82], [2.24], [5.5], [1.01], [6.92], [2.36], [1.34], [3.77], [0.76], [4.62], [0.48], [4.93], [2.95], [-0.5], [2.48], [0.54], [1.02], [0.65], [1.34], [1.4], [3.0], [3.62], [0.19], [3.71], [0.55], [1.56], [0.45], [3.53], [3.05], [1.2], [0.43], [5.16], [2.02], [-3.69], [1.94], [0.45], [1.76], [1.4], [2.92], [5.69], [0.59], [-1.66], [2.01], [4.3], [2.45], [1.33], [0.25], [1.81], [1.91], [2.82], [1.0], [1.26], [4.7], [1.23], [3.54], [0.98], [4.94], [5.07], [1.75], [0.3], [3.63], [1.03], [2.71], [1.95], [1.7], [-2.11], [1.34], [3.1], [1.58], [0.01], [4.15], [2.78], [2.04], [2.69], [0.99], [5.96], [0.52], [0.69], [4.69], [1.42], [0.97], [7.8], [4.06], [0.69], [7.39], [2.61], [-0.16], [3.33], [4.8], [1.95], [3.12], [5.63], [-2.95], [3.31], [0.77], [3.27], [2.55], [4.73], [-0.03], [1.06], [0.58], [1.91], [4.87], [0.63], [3.02], [2.01], [0.37], [5.51], [2.14], [2.55], [2.41], [2.04], [2.84], [2.66], [3.43], [-3.19], [1.39], [5.14], [-0.48], [0.51], [-1.53], [2.35], [0.69], [4.04], [4.54], [1.38], [3.2], [-2.3], [1.61], [1.6], [2.62], [1.89], [1.7], [7.78], [0.51], [5.13], [3.7], [3.9], [4.47], [5.6], [1.24], [2.9], [2.37], [4.3], [2.75], [0.74], [1.34], [1.69], [4.0], [0.76], [0.19], [0.7], [-2.92], [2.09], [0.33], [0.93], [0.03], [2.91], [4.41], [-1.41], [1.35], [2.32], [4.0], [0.09], [3.3], [2.21], [1.4], [1.18], [1.11], [3.57], [0.06], [3.5], [3.57], [3.92], [4.11], [6.29], [3.8], [2.57], [-3.05], [1.95], [2.1], [-0.66], [1.6], [-1.33], [1.12], [2.25], [0.49], [2.3], [3.78], [1.56], [1.52], [2.11], [0.7], [0.28], [2.15], [0.78], [4.22], [1.29], [0.44], [1.62], [0.56], [0.41], [0.85], [7.1], [-0.43], [3.41], [-1.45], [4.38], [2.49], [6.89], [0.76], [1.22], [4.48], [5.15], [1.98], [1.76], [2.3], [2.53], [3.21], [2.19], [1.53], [0.49], [6.14], [4.01], [2.44], [0.79], [0.22], [1.15], [-0.27], [2.1], [1.36], [0.13], [1.48], [3.22], [1.22], [3.3], [-0.4], [3.55], [0.86], [-1.16], [4.75], [4.45], [2.75], [3.51], [2.35], [4.25], [1.75], [0.77], [0.62], [0.83], [1.84], [6.55], [1.14], [2.49], [0.19], [1.4], [3.63], [3.21], [1.05], [2.12], [1.28], [1.7], [4.71], [0.76], [1.11], [2.03], [4.13], [2.17], [4.2], [2.8], [3.14], [5.35], [2.79], [2.76], [2.38], [4.18], [4.76], [2.24], [1.55], [2.56], [3.11], [4.87], [-0.93], [-0.65], [3.14], [1.19], [4.95], [0.67], [-0.4], [2.31], [2.04], [1.17], [2.32], [1.6], [0.33], [3.4], [0.24], [4.22], [1.5], [4.34], [3.81], [0.88], [3.6], [0.64], [3.03], [2.41], [0.73], [2.62], [1.63], [2.72], [2.32], [7.75], [0.7], [2.54], [0.98], [1.15], [2.14], [-1.47], [2.41], [2.15], [3.18], [0.3], [2.64], [-2.32], [2.41], [3.66], [2.18], [3.28], [6.41], [0.53], [1.14], [2.27], [1.12], [4.1], [2.71], [3.27], [1.0], [3.69], [2.29], [1.46], [2.72], [2.1], [0.86], [1.53], [1.11], [3.28], [-0.73], [7.1], [3.4], [1.05], [2.4], [0.34], [-2.51], [0.76], [0.67], [0.36], [0.28], [0.4], [0.35], [3.11], [-0.26], [1.94], [-1.85], [-0.4], [-0.36], [0.07], [0.99], [0.47], [2.61], [5.12], [4.27], [3.42], [3.1], [1.14], [3.76], [1.99], [1.77], [2.1], [1.04], [7.0], [-0.72], [1.51], [-0.48], [2.4], [3.48], [1.66], [2.27], [0.25], [0.9], [5.13], [1.4], [1.62], [3.61], [3.04], [2.62], [-0.4], [6.31], [4.67], [6.13], [0.96], [3.36], [1.6], [1.12], [-0.44], [3.05], [0.22], [0.14], [2.81], [1.28], [2.67], [3.04], [3.17], [3.06], [3.0], [0.34], [1.75], [1.86], [3.51], [2.01], [4.41], [4.5], [3.01], [-1.7], [2.46], [1.79], [3.18], [2.96], [3.3], [2.44], [2.19], [2.8], [0.71], [0.09], [3.49], [0.89], [1.68], [4.59], [2.57], [-1.31], [0.69], [0.86], [-0.99], [1.98], [1.9], [-0.47], [0.97], [0.95], [-0.35], [5.9], [-1.1], [2.8], [-1.33], [2.55], [-1.77], [2.42], [1.73], [0.44], [4.3], [2.79], [2.74], [2.75], [3.61], [0.76], [0.65], [1.28], [1.61], [1.1], [1.49], [-0.85], [0.18], [1.65], [3.74], [5.66], [1.95], [2.02], [3.63], [2.67], [2.96], [3.03], [3.01], [0.36], [3.22], [2.4], [2.17], [-1.24], [6.03], [5.76], [2.92], [2.05], [3.3], [2.37], [1.83], [0.74], [3.67], [1.0], [1.63], [3.56], [-1.11], [0.18], [1.74], [-1.05], [0.84], [1.55], [3.04], [1.68], [2.3], [1.15], [-0.67], [0.9], [2.76], [2.92], [0.99], [-1.37], [3.15], [2.13], [0.17], [2.7], [1.26], [0.77], [0.55], [3.39], [1.69], [2.3], [2.04], [2.63], [1.78], [1.42], [3.58], [5.4], [0.53], [2.11], [3.69], [3.29], [1.74], [1.93], [0.84], [0.99], [1.96], [0.88], [0.43], [2.9], [3.19], [2.52], [3.08], [0.86], [1.68], [1.26], [-1.59], [5.18], [-0.22], [-1.22], [2.05], [2.37], [3.03], [-1.97], [0.76], [2.93], [0.55], [0.4], [-2.44], [1.29], [3.25], [2.56], [0.17], [0.26], [1.88], [4.22], [3.42], [3.67], [0.69], [5.06], [1.37], [5.54], [0.65], [2.14], [0.58], [2.93], [1.41], [2.19], [3.0], [1.72], [2.22], [1.37], [3.42], [-2.35], [2.38], [2.72], [0.47], [0.79], [2.85], [2.22], [1.69], [3.23], [2.13], [1.88], [2.1], [2.24], [-1.4], [2.22], [2.15], [2.06], [2.33], [2.5], [0.79], [2.68], [3.3], [3.0], [1.14], [7.43], [3.8], [7.06], [-0.71], [2.06], [-0.44], [4.46], [4.27], [4.35], [1.73], [0.95], [1.82], [2.0], [-1.93], [0.96], [0.52], [1.71], [3.53], [1.05], [4.2], [1.96], [1.52], [1.51], [1.04], [3.92], [2.09], [3.12], [0.78], [3.22], [1.38], [3.3], [6.3], [4.11], [0.94], [1.21], [3.72], [1.6], [1.74], [-0.49], [2.05], [2.9], [-1.78], [1.27], [-1.21], [3.44], [5.87], [-1.1], [-0.24], [1.33], [1.1], [4.01], [2.24], [3.46], [2.47], [4.36], [3.2], [2.52], [-0.66], [0.24], [2.72], [0.39], [1.86], [1.6], [1.28], [2.0], [2.3], [-0.13], [2.74], [3.24], [0.4], [2.71], [2.22], [0.25], [2.08], [1.51], [1.28], [2.97], [3.87], [1.06], [-1.35], [1.63], [0.66], [2.3], [1.14], [0.29], [0.98], [-1.07], [4.26], [1.64], [-0.02], [2.8], [1.15], [3.05], [2.18], [1.98], [0.45], [0.22], [0.85], [0.78], [0.93], [0.8], [2.0], [1.38], [1.4], [1.95], [1.83], [1.0], [0.95], [3.22], [2.2], [1.68], [-1.73], [1.91], [2.83], [-0.96], [2.65], [0.83], [2.07], [3.04], [0.57], [2.06], [3.64], [3.53], [-0.36], [3.84], [2.94], [0.31], [1.45], [2.52], [2.94], [1.16], [2.25], [5.99], [1.37], [3.36], [2.03], [-0.7], [5.14], [6.95], [5.71], [2.37], [0.29], [1.77], [0.99], [7.38], [1.23], [3.65], [3.04], [2.06], [1.68], [7.45], [-0.33], [1.47], [2.4], [3.9], [4.48], [2.15], [1.83], [3.0], [-0.29], [1.93], [3.16], [4.49], [3.55], [5.37], [-0.75], [3.21], [4.05], [0.5], [5.04], [2.56], [0.96], [0.36], [1.91], [1.17], [3.72], [1.99], [3.6], [0.73], [2.6], [1.58], [0.45], [4.25], [2.31], [2.32], [3.08], [6.14], [4.05], [0.25], [3.36], [7.75], [0.93], [2.26], [0.98], [2.6], [1.69], [2.24], [3.41], [4.44], [-0.6], [1.1], [0.94], [2.56], [3.0], [2.0], [-2.41], [1.73], [0.65]]
[[-1.6755631999839844], [0.009625975241280766], [1.3728044800413362], [-0.14064567095715044], [-0.40898789631149207], [0.7180494501767428], [-1.4555225751934244], [-0.9510391915272621], [1.673347772438199], [1.5016087482114204], [-0.4411889633540131], [-1.788266934632808], [1.9792579093421483], [1.034693276094866], [-1.2623161729382986], [0.5731446484853984], [-0.1191782929288032], [-0.7793001673004835], [0.7019489166554822], [0.47654144735783527], [-0.6504958991303996], [-1.09057714871152], [0.26723451158144873], [0.28870188960979604], [0.031093353269628116], [-0.9671397250485226], [-0.9081044354705675], [0.6107125600350061], [-1.407220974629643], [0.2350334445389277], [-1.246215639417038], [0.9756579865169107], [0.8039189622901319], [0.5033756698932693], [0.583878337499572], [-1.1710798163178222], [0.5731446484853984], [-0.14064567095715044], [1.5767445713106358], [1.3674376355342495], [-0.9778734140626963], [-0.8276017678642651], [1.5713777268035491], [0.05792757580506242], [-0.3928873627902317], [1.6357798608885912], [0.4121393132727932], [-0.5270584754674025], [-0.3392189177193633], [0.3423703346806644], [0.514109358907443], [-0.8061343898359178], [-0.7685664782863098], [1.5123424372255938], [-0.43582211884692623], [-0.7417322557508758], [-0.20504780504219247], [-2.180046583650147], [1.2117991448287313], [0.3692045572160985], [0.8844216298964344], [0.38530509073735913], [-0.7954007008217441], [0.2779682005956224], [0.07402810932632281], [-0.3070178506768423], [0.5194762034145299], [-0.37678682926897117], [-0.3553194512406238], [-0.4036210518044052], [1.0132258980665185], [-1.251582483924125], [-1.1013108377256935], [-0.634395365609139], [0.16526446594679892], [0.19209868848223324], [-0.8329686123713519], [0.7287831391909165], [-0.8759033684280465], [-0.1030777594075427], [2.2100322231468823], [-0.34995260673353695], [-1.187180349839083], [-0.7041643442012678], [-0.6826969661729206], [-0.10844460391462954], [0.49264198087909566], [-0.9403055025130886], [-0.7470991002579626], [1.244000211871252], [-1.0476423926548253], [-1.5896936878705954], [-0.2372488720847135], [0.42823984679405386], [0.004259130734194047], [-0.5807269205382707], [-2.426921430976141], [0.9327232304602161], [2.295901735260271], [1.415739236098031], [0.15453077693262526], [-1.3857535966012955], [0.025726508762541397], [-0.1191782929288032], [-2.7220978788659167], [0.49264198087909566], [0.43360669130114055], [0.2028323774964069], [0.1598976214397122], [0.014992819748367723], [0.326269801159404], [-0.4197215853256657], [-1.337451996037514], [0.4711746028507485], [0.0901286428475832], [0.3692045572160985], [0.5570441149641376], [0.8951553189106081], [1.1742312332791234], [-0.221148338563453], [-0.7954007008217441], [-0.32848522870518965], [-0.16747989349258463], [-0.7095311887083547], [-0.37678682926897117], [0.08476179834049649], [0.3584708682019248], [0.28333504510270935], [-0.2479825610988872], [-0.3231183841981028], [0.24576713355310137], [1.4318397696192915], [-0.04940931433667432], [2.4139723144161818], [-0.6075611430737049], [0.15453077693262526], [1.2064323003216446], [0.25113397806018833], [-1.0100744811052174], [-0.3714199847618843], [-0.46802318588944725], [0.5033756698932693], [-0.43045527433983943], [-0.09234407039336902], [2.440806536951616], [-0.14601251546423727], [0.7073157611625691], [-0.9778734140626963], [0.38530509073735913], [-0.2962841616626686], [0.025726508762541397], [-0.6934306551870943], [1.0132258980665185], [-2.0029407149162815], [0.5731446484853984], [0.583878337499572], [-1.2140145723745168], [-1.2140145723745168], [-0.15137935997132412], [0.9058890079247818], [0.9380900749673028], [-0.510957941946142], [0.11159602087593055], [0.5355767369357903], [-0.19968096053510564], [-0.16747989349258463], [1.5713777268035491], [-0.8705365239209597], [-0.8061343898359178], [-0.7578327892721363], [1.17959807778621], [0.31553611214523036], [0.28870188960979604], [0.29943557862396974], [-0.8437023013855255], [-0.5807269205382707], [-0.8544359903996992], [0.6160794045420928], [-1.9707396478737604], [-1.1013108377256935], [0.28870188960979604], [1.7162825284948933], [0.014992819748367723], [1.4908750591972464], [0.42823984679405386], [-0.4841237194107078], [1.4264729251122044], [0.1169628653830175], [0.5302098924287036], [1.8665541746933247], [-0.5860937650453576], [-0.7363654112437888], [-0.21578149405636615], [-0.08161038137919535], [-0.15137935997132412], [-1.2086477278674301], [-1.6916637335052451], [-1.5896936878705954], [-0.7041643442012678], [0.3209029566523171], [0.15453077693262526], [-0.8007675453288309], [-0.5485258534957497], [0.8253863403184794], [0.6912152276413085], [1.6304130163815045], [-0.44655580786109994], [-1.5521257763209875], [0.326269801159404], [0.1169628653830175], [-0.27481678363432127], [-0.3070178506768423], [-0.1030777594075427], [-0.2909173171555818], [-1.3213514625162537], [-1.187180349839083], [1.667980927931112], [1.9470568422996275], [-0.23188202757762666], [1.5874782603248097], [-0.8651696794138729], [-1.09057714871152], [-1.278416706459559], [0.6375467825704402], [-0.5860937650453576], [-1.788266934632808], [-1.8687696022391107], [-1.5306583982926403], [1.1205627882082552], [0.29943557862396974], [-0.14601251546423727], [-1.3481856850516878], [-1.2301151058957775], [0.19209868848223324], [-0.2855504726484949], [-0.7846670118075705], [2.859420408504389], [0.004259130734194047], [-0.11381144842171637], [-0.3123846951839291], [-1.1335119047682145], [-0.2962841616626686], [-0.0011077137728929085], [0.10622917636884384], [-0.4250884298327526], [1.1956986113074708], [-1.2891503954737327], [-0.8115012343430045], [0.11159602087593055], [-0.3714199847618843], [-0.9510391915272621], [-1.09057714871152], [0.07939495383340953], [-0.07624353687210851], [0.10622917636884384], [0.2779682005956224], [-0.9081044354705675], [-0.6075611430737049], [0.873687940882261], [0.12232970989010424], [0.5409435814428772], [2.049026887934277], [-1.9761064923808473], [-0.8276017678642651], [0.9810248310239975], [1.2493670563783392], [-0.006474558279979626], [1.5499103487752017], [0.43360669130114055], [-0.7793001673004835], [0.6858483831342218], [-1.6487289774485503], [1.0776280321515606], [-0.10844460391462954], [-0.9778734140626963], [0.37993824623027217], [0.025726508762541397], [0.9917585200381711], [-0.34995260673353695], [-0.9671397250485226], [-1.3857535966012955], [1.3674376355342495], [-0.7900338563146572], [-0.11381144842171637], [-0.36605314025479746], [-0.05477615884376128], [-1.1066776822327804], [-0.1030777594075427], [-1.3159846180091668], [0.10622917636884384], [0.08476179834049649], [0.15453077693262526], [-0.006474558279979626], [0.256500822567275], [-0.8329686123713519], [1.152763855250776], [0.14916393242553852], [2.032926354413017], [-1.369653063080035], [0.9166226969389554], [-0.8705365239209597], [-0.4894905639177946], [1.152763855250776], [-0.43582211884692623], [0.28870188960979604], [0.7502505172192636], [-2.0619760044942366], [0.46580775834366156], [1.1098290991940813], [0.583878337499572], [0.9649242975027371], [-1.020808170119391], [-1.0100744811052174], [1.7162825284948933], [-1.1281450602611278], [1.093728565672821], [0.2189329110176673], [0.10622917636884384], [-0.9295718134989149], [-0.08697722588628219], [-1.4501557306863375], [0.7019489166554822], [0.025726508762541397], [-0.8812702129351334], [-1.0261750146264779], [-0.16211304898549778], [1.8933883972287588], [1.1312964772224288], [-0.6075611430737049], [-0.5968274540595312], [-0.21578149405636615], [0.8629542518680873], [-0.730998566736702], [-1.4501557306863375], [0.2350334445389277], [-0.2855504726484949], [-0.03867562532250065], [0.22966660003184097], [0.3370034901735777], [-0.0011077137728929085], [-0.9349386580060016], [0.08476179834049649], [-0.8437023013855255], [-0.698797499694181], [-0.5860937650453576], [0.7717178952476109], [-0.14064567095715044], [0.7770847397546979], [-1.1925471943461696], [-0.8705365239209597], [0.6590141605987875], [-0.03867562532250065], [0.3584708682019248], [-0.03867562532250065], [-0.17284673799967146], [0.5677778039783113], [0.551677270457051], [1.0668943431373867], [-0.30165100616975543], [-1.407220974629643], [-0.0011077137728929085], [-0.5860937650453576], [0.009625975241280766], [-0.8168680788500915], [1.2493670563783392], [-0.2479825610988872], [-0.28018362814140807], [-0.23188202757762666], [-0.46802318588944725], [-0.31775153969101594], [-0.9617728805414358], [-0.510957941946142], [0.37993824623027217], [0.025726508762541397], [-0.9242049689918279], [-0.6719632771587469], [-0.7202648777225283], [-1.6970305780123318], [-0.892003901949307], [0.3960387797515328], [1.2708344344066866], [-0.07087669236502167], [-0.4250884298327526], [0.036460197776715074], [-0.7470991002579626], [-0.26408309462014756], [0.1276965543971912], [2.0919616439909716], [-1.5521257763209875], [-1.1818135053319958], [-1.3750199075871221], [-0.37678682926897117], [1.9792579093421483], [0.6375467825704402], [-0.8544359903996992], [-0.18894727152093196], [-0.16747989349258463], [0.031093353269628116], [-0.38215367377605797], [-1.595060532377682], [0.22966660003184097], [0.578511492992485], [-0.6397622101162259], [1.0507938096161265], [-0.3928873627902317], [0.19746553298931996], [-0.45192265236818674], [-0.1782135825067583], [-0.15137935997132412], [-0.8490691458926124], [1.0454269651090393], [-1.2354819504028642], [0.2081992220034936], [-0.18894727152093196], [0.294068734116883], [1.5123424372255938], [-1.6594626664627241], [0.261867667074362], [-0.4733900303965341], [0.33163664566649076], [0.583878337499572], [0.9166226969389554], [0.05792757580506242], [2.8433198749831283], [-0.43045527433983943], [0.5892451820066588], [-0.08697722588628219], [-0.66659643265166], [-0.6719632771587469], [-0.022575091801240257], [0.16526446594679892], [-0.3928873627902317], [0.6053457155279194], [0.3638377127090118], [-0.37678682926897117], [-1.273049861952472], [-0.15674620447841095], [0.5731446484853984], [-0.6129279875807918], [-0.12991198194297676], [-0.8437023013855255], [0.5624109594712247], [0.1759981549609726], [-1.5091910202642929], [-0.6504958991303996], [1.3084023459562941], [-0.16747989349258463], [0.5302098924287036], [1.0615274986302998], [-0.7578327892721363], [0.8307531848255663], [-0.3123846951839291], [0.8253863403184794], [-0.5431590089886629], [0.3101692676381434], [-0.5807269205382707], [-0.1030777594075427], [0.514109358907443], [0.7448836727121769], [-0.2479825610988872], [0.7556173617263505], [-0.634395365609139], [-0.46802318588944725], [0.38530509073735913], [-0.060143003350848], [0.583878337499572], [-2.19078027266432], [-0.33385207321227645], [0.1169628653830175], [-1.117411371246954], [0.19209868848223324], [-0.33385207321227645], [-0.33385207321227645], [-1.5091910202642929], [0.42823984679405386], [-0.3231183841981028], [-0.33385207321227645], [-0.5968274540595312], [-0.8651696794138729], [1.6894483059594592], [0.0901286428475832], [0.5570441149641376], [-0.03867562532250065], [0.7019489166554822], [0.3209029566523171], [-0.8329686123713519], [0.4550740693294879], [1.3620707910271628], [1.3728044800413362], [0.40140562425861953], [-0.66659643265166], [-0.28018362814140807], [-0.31775153969101594], [-1.7453321785761131], [0.25113397806018833], [0.3906719352444459], [0.10622917636884384], [-0.9993407920910437], [-0.03867562532250065], [-0.011841402787066583], [-0.15674620447841095], [0.7609842062334372], [0.09549548735467016], [-0.1782135825067583], [-0.9993407920910437], [-0.4572894968752736], [-0.6504958991303996], [0.4711746028507485], [0.6858483831342218], [2.2690675127248374], [0.3209029566523171], [1.2654675898995995], [-0.8705365239209597], [-1.1603461273036486], [0.7824515842617846], [-0.5968274540595312], [-0.34458576222645015], [-0.8329686123713519], [0.06329442031214914], [-0.9832402585697831], [-0.8866370574422202], [-0.24261571659180034], [0.16526446594679892], [-1.3911204411083824], [-0.7793001673004835], [1.3406034129988154], [0.47654144735783527], [1.8236194186366301], [-0.4894905639177946], [-1.0637429261760858], [0.6804815386271348], [-0.6719632771587469], [-1.4608894197005111], [-0.5646263870170102], [-1.4662562642075982], [0.036460197776715074], [-1.9117043582958053], [0.6643810051058744], [0.7073157611625691], [-0.7524659447650494], [0.6697478496129612], [0.0901286428475832], [1.5069755927185071], [0.0901286428475832], [0.514109358907443], [-0.8866370574422202], [-0.8061343898359178], [-0.027941936308326976], [1.2332665228570787], [-0.6880638106800073], [-0.16211304898549778], [-0.1352788264500636], [-1.4447888861792508], [0.5194762034145299], [0.18136499946805956], [2.5266760490650055], [-1.4555225751934244], [0.07402810932632281], [0.3584708682019248], [0.6482804715846138], [1.6572472389169386], [-0.7417322557508758], [1.217165989335818], [-0.3928873627902317], [-0.5002242529319683], [0.2081992220034936], [0.8522205628539136], [-0.6021942985666181], [1.1956986113074708], [1.351337102012989], [-0.36605314025479746], [1.3620707910271628], [-0.9456723470201753], [-0.2909173171555818], [0.4550740693294879], [0.9863916755310844], [0.44970722482240116], [0.0901286428475832], [0.2350334445389277], [0.19209868848223324], [0.7234162946838295], [0.1330633989042779], [-1.053009237161912], [0.3423703346806644], [0.3638377127090118], [1.4211060806051177], [-0.2587162501130609], [0.10622917636884384], [0.7234162946838295], [-0.033308780815413934], [-0.6826969661729206], [0.18136499946805956], [-0.11381144842171637], [0.44970722482240116], [-0.37678682926897117], [0.6536473160917008], [0.07402810932632281], [0.4711746028507485], [-0.5377921644815761], [0.5248430479216166], [0.46580775834366156], [-0.40898789631149207], [0.13843024341136487], [1.70554883948072], [-0.6612295881445733], [0.05256073129797546], [-0.1782135825067583], [-1.1657129718107355], [-0.05477615884376128], [-0.8168680788500915], [0.22966660003184097], [-0.8705365239209597], [0.3638377127090118], [-0.5860937650453576], [0.05792757580506242], [1.1742312332791234], [-0.6934306551870943], [1.5391766597610284], [-0.6236616765949654], [1.92558946427128], [-0.15674620447841095], [-0.22651518307053983], [0.7502505172192636], [-0.7578327892721363], [-0.253349405605974], [1.3137691904633808], [0.3209029566523171], [-0.5055910974390552], [0.04182704228380179], [0.33163664566649076], [-1.0154413256123043], [0.9434569194743897], [0.05792757580506242], [0.3370034901735777], [1.4318397696192915], [-0.7148980332154415], [0.6965820721483954], [0.7556173617263505], [0.031093353269628116], [0.6804815386271348], [0.9434569194743897], [0.09549548735467016], [-1.2676830174453853], [-1.5467589318139006], [-0.45192265236818674], [-1.273049861952472], [-0.033308780815413934], [-0.04404246982958761], [-0.017208247294153302], [-0.38215367377605797], [1.16349754426495], [0.9219895414460424], [2.757450362869739], [-0.4143547408185789], [-0.15137935997132412], [0.08476179834049649], [1.3245028794775549], [1.1742312332791234], [-0.8007675453288309], [-0.05477615884376128], [-0.5216916309603157], [0.1169628653830175], [-1.112044526739867], [2.4354396924445294], [0.7824515842617846], [1.8504536411720642], [-0.3231183841981028], [-2.469856187032836], [-2.2015139616784944], [-1.154979282796562], [0.261867667074362], [1.2923018124350336], [-1.9331717363241527], [0.3370034901735777], [-0.36068629574771066], [-0.5807269205382707], [-1.7345984895619397], [-1.0100744811052174], [1.0132258980665185], [-0.027941936308326976], [-1.5467589318139006], [-0.36068629574771066], [0.868321096375174], [-0.5431590089886629], [-0.9939739475839569], [-0.18894727152093196], [-0.17284673799967146], [-0.5914606095524444], [-0.3070178506768423], [-1.2945172399808194], [1.3352365684917282], [0.1759981549609726], [0.5892451820066588], [-1.7238648005477661], [0.3584708682019248], [-0.5485258534957497], [0.3584708682019248], [-0.5968274540595312], [0.31553611214523036], [-0.46802318588944725], [-0.8222349233571782], [-0.19968096053510564], [-0.10844460391462954], [-1.8419353797036766], [-1.627261599420203], [1.0722611876444739], [0.7180494501767428], [-1.4555225751934244], [-0.8544359903996992], [1.4855082146901597], [0.2779682005956224], [-1.4179546636438167], [0.9917585200381711], [1.099095410179908], [1.1312964772224288], [0.551677270457051], [-0.38215367377605797], [-0.7846670118075705], [-1.7667995566044605], [-0.2479825610988872], [-0.07087669236502167], [-0.6934306551870943], [-0.892003901949307], [-0.07624353687210851], [0.031093353269628116], [0.326269801159404], [0.6697478496129612], [-0.16211304898549778], [1.517709281732681], [-0.3928873627902317], [-1.9922070259021076], [0.4067724687657065], [2.1456300890618403], [0.29943557862396974], [-0.6236616765949654], [1.034693276094866], [-0.5968274540595312], [-0.03867562532250065], [-0.5163247864532288], [2.1134290220193193], [-1.4555225751934244], [0.06329442031214914], [0.07402810932632281], [0.24576713355310137], [-0.44655580786109994], [0.6375467825704402], [-0.6236616765949654], [-1.0476423926548253], [-1.369653063080035], [0.3423703346806644], [-0.2855504726484949], [-0.8544359903996992], [0.17063131045388588], [-0.4411889633540131], [-1.246215639417038], [0.5302098924287036], [0.900522163417695], [-2.1371118275934524], [0.28333504510270935], [-0.033308780815413934], [0.9756579865169107], [1.0454269651090393], [1.4962419037043335], [2.24760013469649], [0.5302098924287036], [0.09549548735467016], [-1.9009706692816313], [-0.9778734140626963], [-0.9456723470201753], [-0.6773301216658337], [0.3101692676381434], [-0.4841237194107078], [-0.44655580786109994], [1.286934967927947], [0.6375467825704402], [1.1205627882082552], [-0.32848522870518965], [-2.1210112940721917], [-0.9027375909634807], [0.24576713355310137], [-1.439422041672164], [0.5355767369357903], [-1.5306583982926403], [0.04719388679088875], [2.204665378639795], [0.19209868848223324], [-0.23188202757762666], [-1.122778215754041], [-0.6451290546233127], [0.020359664255454442], [2.68768138427761], [0.19209868848223324], [-1.1818135053319958], [1.442573458633465], [-0.6504958991303996], [0.3960387797515328], [-1.3320851515304273], [-1.0691097706831725], [-2.0458754709729763], [0.28870188960979604], [-0.4143547408185789], [1.0185927425736052], [2.89162147554691], [-0.1030777594075427], [-0.4411889633540131], [0.49264198087909566], [1.0615274986302998], [-1.4769899532217718], [3.782517663723324], [-0.8115012343430045], [-0.14601251546423727], [0.18673184397514628], [-1.8312016906895026], [0.04182704228380179], [-2.5449920101320513], [-0.7417322557508758], [0.3209029566523171], [0.8039189622901319], [0.19746553298931996], [-1.1013108377256935], [-1.5467589318139006], [-0.16747989349258463], [-1.278416706459559], [-1.154979282796562], [0.06329442031214914], [2.864787253011476], [0.14916393242553852], [-1.2891503954737327], [-0.5163247864532288], [-0.9725065695556095], [-0.5592595425099234], [-0.39825420729731836], [0.33163664566649076], [0.40140562425861953], [-0.4411889633540131], [0.07939495383340953], [1.3459702575059023], [1.9577905313138009], [-0.9832402585697831], [0.036460197776715074], [-0.08161038137919535], [-0.1191782929288032], [-2.013674403930455], [0.10086233186175687], [-0.12991198194297676], [-0.39825420729731836], [0.900522163417695], [-1.917071202802892], [-0.3392189177193633], [-1.085210304204433], [-0.4841237194107078], [-1.154979282796562], [0.46044091383657487], [-1.1388787492753012], [0.6268130935562665], [-0.5270584754674025], [1.453307147647639], [2.3710375583594874], [1.6572472389169386], [-0.34458576222645015], [0.9649242975027371], [-0.39825420729731836], [0.24040028904601465], [0.16526446594679892], [-0.46802318588944725], [0.294068734116883], [0.326269801159404], [-0.7954007008217441], [0.1276965543971912], [-0.37678682926897117], [0.16526446594679892], [1.3084023459562941], [-0.7095311887083547], [-1.2676830174453853], [-1.4877236422359454], [0.5999788710208324], [0.6697478496129612], [-0.9456723470201753], [0.546310425949964], [0.9058890079247818], [-0.31775153969101594], [-0.04404246982958761], [0.38530509073735913], [-0.5968274540595312], [0.4121393132727932], [2.4247060034303556], [0.809285806797219], [2.0436600434271903], [-0.9242049689918279], [-0.7256317222296153], [1.2547339008854261], [0.6429136270775271], [0.04182704228380179], [-0.2855504726484949], [-0.2479825610988872], [-0.011841402787066583], [-0.1352788264500636], [-0.34995260673353695], [0.6751146941200481], [0.3584708682019248], [1.1420301662366026], [-0.510957941946142], [1.099095410179908], [0.5355767369357903], [0.5999788710208324], [0.9273563859531291], [0.24040028904601465], [0.5302098924287036], [0.9649242975027371], [-0.3928873627902317], [-1.4555225751934244], [0.19746553298931996], [-0.7954007008217441], [0.37993824623027217], [0.8039189622901319], [-0.05477615884376128], [-1.246215639417038], [-1.2945172399808194], [0.868321096375174], [-0.006474558279979626], [-0.04404246982958761], [-0.12454513743589005], [0.4711746028507485], [-0.09234407039336902], [-1.1013108377256935], [-0.5485258534957497], [0.5409435814428772], [-2.485956720554096], [-0.19968096053510564], [-0.14064567095715044], [1.1205627882082552], [0.7448836727121769], [0.19209868848223324], [-1.4447888861792508], [0.7824515842617846], [0.40140562425861953], [-0.04404246982958761], [-1.4501557306863375], [-0.027941936308326976], [2.1080621775122323], [1.286934967927947], [0.04182704228380179], [0.28870188960979604], [1.244000211871252], [-1.0691097706831725], [-0.20504780504219247], [-0.1352788264500636], [0.6751146941200481], [-1.5413920873068137], [-0.40898789631149207], [0.4443403803153142], [-0.3392189177193633], [0.294068734116883], [0.05256073129797546], [1.2762012789137733], [0.42823984679405386], [-1.7560658675902872], [0.10086233186175687], [-0.011841402787066583], [-0.5002242529319683], [-2.035141781958802], [2.719882451320131], [-0.27481678363432127], [-0.47875687490362095], [-0.7578327892721363], [2.0758611104697113], [0.2081992220034936], [1.3674376355342495], [-2.260549251256449], [0.2081992220034936], [0.9702911420098238], [-0.37678682926897117], [0.5087425144003562], [0.8146526513043056], [1.6196793273673304], [2.231499601175229], [-2.206880806185581], [0.7556173617263505], [0.16526446594679892], [0.5409435814428772], [-0.011841402787066583], [0.8790547853893477], [-0.9778734140626963], [0.326269801159404], [0.04182704228380179], [-0.5002242529319683], [-0.892003901949307], [-1.273049861952472], [-0.9295718134989149], [3.782517663723324], [0.5355767369357903], [-0.5324253199744892], [-1.6540958219556372], [-0.4894905639177946], [0.6965820721483954], [-0.15674620447841095], [0.06329442031214914], [-0.22651518307053983], [0.7126826056696558], [0.6268130935562665], [0.18136499946805956], [1.1259296327153419], [1.1259296327153419], [1.544543504268115], [0.11159602087593055], [0.0901286428475832], [-0.027941936308326976], [-1.1818135053319958], [0.12232970989010424], [-1.1925471943461696], [-1.1603461273036486], [-0.15674620447841095], [0.004259130734194047], [0.25113397806018833], [-1.6111610658989426], [2.1617306225831006], [-0.18358042701384514], [-1.6755631999839844], [0.0686612648192361], [0.7395168282050901], [-2.3517856078769253], [-0.5807269205382707], [-0.15137935997132412], [0.07939495383340953], [-0.6290285211020523], [3.487341215833548], [1.5069755927185071], [0.014992819748367723], [-0.6612295881445733], [0.44970722482240116], [0.6965820721483954], [-0.2372488720847135], [-0.66659643265166], [-0.07087669236502167], [-0.7470991002579626], [0.13843024341136487], [-0.46265634138236045], [-0.7900338563146572], [-0.8544359903996992], [-2.3142176963273178], [-1.7506990230832002], [-0.1352788264500636], [0.3531040236948381], [0.04719388679088875], [0.31553611214523036], [-1.09057714871152], [0.5892451820066588], [-0.4894905639177946], [0.28870188960979604], [-1.3964872856154693], [0.12232970989010424], [0.3960387797515328], [-2.9153042811210432], [0.38530509073735913], [1.17959807778621], [1.088361721165734], [-0.18894727152093196], [0.1330633989042779], [-2.099543916043844], [-2.078076538015497], [1.5821114158177225], [-0.8383354568784387], [-1.6594626664627241], [-0.2587162501130609], [-0.033308780815413934], [-0.060143003350848], [0.1759981549609726], [-0.8168680788500915], [0.31553611214523036], [-1.2623161729382986], [-0.9456723470201753], [-0.017208247294153302], [-1.0959439932186068], [0.3423703346806644], [-0.8007675453288309], [0.2726013560885357], [0.16526446594679892], [1.2601007453925128], [-0.1782135825067583], [1.029326431587779], [-0.253349405605974], [-0.2587162501130609], [-0.09234407039336902], [0.9649242975027371], [-0.7202648777225283], [-1.0744766151902594], [-0.7095311887083547], [-0.6719632771587469], [-1.219381416881604], [-0.510957941946142], [1.2547339008854261], [-0.3123846951839291], [0.5033756698932693], [-0.5592595425099234], [-0.6129279875807918], [1.92558946427128], [-2.357152452384012], [-0.5324253199744892], [-0.3123846951839291], [-2.5020572540753565], [-0.6236616765949654], [-0.10844460391462954], [-1.5735931543493347], [-1.0315418591335648], [1.7270162175090673], [-1.4233215081509034], [0.7234162946838295], [0.809285806797219], [0.24040028904601465], [0.1759981549609726], [0.2779682005956224], [0.4711746028507485], [0.3531040236948381], [-0.5485258534957497], [-1.2301151058957775], [0.07939495383340953], [1.4050055470838574], [-0.9725065695556095], [-1.879503291253284], [1.608945638353157], [0.22966660003184097], [1.92558946427128], [0.7556173617263505], [-2.1102776050580183], [0.15453077693262526], [-1.2408487949099511], [-1.0476423926548253], [-0.14064567095715044], [0.07402810932632281], [0.3209029566523171], [-0.9725065695556095], [0.2189329110176673], [0.28333504510270935], [-1.251582483924125], [0.004259130734194047], [-1.112044526739867], [-0.9242049689918279], [0.7717178952476109], [-0.9403055025130886], [-0.32848522870518965], [0.5677778039783113], [-0.0011077137728929085], [0.38530509073735913], [0.1330633989042779], [0.34773717918775116], [-1.305250928994993], [-0.20504780504219247], [-0.4143547408185789], [0.6697478496129612], [-0.3875205182831448], [-0.18894727152093196], [-0.17284673799967146], [0.9434569194743897], [0.46044091383657487], [-0.9081044354705675], [-1.8473022242107633], [-0.3392189177193633], [-0.12454513743589005], [-0.9671397250485226], [1.6250461718744171], [-1.4930904867430321], [0.036460197776715074], [-1.09057714871152], [-0.4841237194107078], [-0.017208247294153302], [0.31553611214523036], [0.8522205628539136], [0.7234162946838295], [-1.5199247092784662], [1.7860515070870226], [0.05256073129797546], [0.5570441149641376], [1.7860515070870226], [-1.2140145723745168], [0.6536473160917008], [0.031093353269628116], [-0.7095311887083547], [0.8200194958113926], [0.025726508762541397], [0.34773717918775116], [0.8575874073610004], [-0.06550984785793483], [0.9595574529956501], [0.07402810932632281], [1.034693276094866], [-0.011841402787066583], [0.6268130935562665], [-0.39825420729731836], [0.583878337499572], [0.6053457155279194], [0.6214462490491798], [0.1169628653830175], [1.2493670563783392], [-0.07087669236502167], [0.10086233186175687], [-0.4733900303965341], [0.031093353269628116], [-0.8061343898359178], [-0.30165100616975543], [-1.1388787492753012], [0.47654144735783527], [-0.37678682926897117], [-0.17284673799967146], [0.9595574529956501], [0.2779682005956224], [-0.221148338563453], [-0.27481678363432127], [-0.5431590089886629], [-0.21041464954927933], [1.8397199521578906], [-0.18358042701384514], [-0.022575091801240257], [0.11159602087593055], [0.294068734116883], [-0.27481678363432127], [-0.5968274540595312], [0.9488237639814765], [-0.30165100616975543], [1.5767445713106358], [-1.7453321785761131], [-1.2032808833603432], [-0.060143003350848], [1.9416899977925408], [-0.43045527433983943], [-0.07087669236502167], [-0.7900338563146572], [-1.664829510969811], [0.19746553298931996], [0.9380900749673028], [0.7556173617263505], [0.9702911420098238], [0.8253863403184794], [0.9058890079247818], [-1.273049861952472], [0.6160794045420928], [-1.9922070259021076], [-0.47875687490362095], [-0.2694499391272344], [1.1205627882082552], [1.6518803944098517], [-0.9993407920910437], [0.5677778039783113], [0.009625975241280766], [0.1276965543971912], [-0.12991198194297676], [-0.634395365609139], [-0.022575091801240257], [1.0561606541232131], [-1.890236980267458], [1.2654675898995995], [-0.47875687490362095], [1.3459702575059023], [-0.2909173171555818], [0.16526446594679892], [-1.0369087036406515], [0.256500822567275], [0.5624109594712247], [-0.7041643442012678], [0.17063131045388588], [0.256500822567275], [-0.37678682926897117], [-1.187180349839083], [3.541009660904417], [-1.6862968889981584], [-0.2962841616626686], [-0.4894905639177946], [0.2350334445389277], [-0.28018362814140807], [0.24576713355310137], [-1.2247482613886906], [1.217165989335818], [0.5624109594712247], [0.5731446484853984], [-1.5467589318139006], [-0.3875205182831448], [-0.2855504726484949], [-2.3142176963273178], [-1.2676830174453853], [1.034693276094866], [0.9166226969389554], [1.0507938096161265], [-1.0476423926548253], [-0.5538926980028366], [1.0722611876444739], [-1.0637429261760858], [0.0901286428475832], [1.351337102012989], [-0.8061343898359178], [-0.6451290546233127], [0.3638377127090118], [-0.47875687490362095], [0.546310425949964], [-0.15674620447841095], [1.9792579093421483], [-0.9403055025130886], [-1.4662562642075982], [-0.4143547408185789], [-1.5306583982926403], [-0.5377921644815761], [-0.4197215853256657], [-1.020808170119391], [0.43360669130114055], [-0.8168680788500915], [-0.23188202757762666], [0.15453077693262526], [-0.8812702129351334], [-0.7363654112437888], [-0.4841237194107078], [-0.2694499391272344], [-0.2587162501130609], [-0.7900338563146572], [0.020359664255454442], [-1.2247482613886906], [-0.3875205182831448], [1.3459702575059023], [-1.283783550966646], [-0.24261571659180034], [-0.8490691458926124], [-0.43045527433983943], [-1.6379952884343767], [-0.14601251546423727], [-0.3392189177193633], [0.4389735358082275], [0.7502505172192636], [-0.5968274540595312], [-0.5968274540595312], [-2.4161877419619677], [-0.2909173171555818], [-0.20504780504219247], [-2.7972337019651325], [1.1312964772224288], [1.0776280321515606], [0.5999788710208324], [-0.15137935997132412], [1.8504536411720642], [-0.15137935997132412], [-0.66659643265166], [-0.006474558279979626], [-1.337451996037514], [-2.035141781958802], [0.10086233186175687], [-0.27481678363432127], [-0.1352788264500636], [-0.43582211884692623], [1.769950973565762], [0.256500822567275], [0.3692045572160985], [0.7180494501767428], [-1.7131311115335925], [-0.8812702129351334], [0.37993824623027217], [0.5248430479216166], [-0.18894727152093196], [-0.6451290546233127], [0.37993824623027217], [-0.2587162501130609], [-1.8634027577320238], [0.1598976214397122], [-0.07087669236502167], [-0.8759033684280465], [1.0078590535594318], [-0.28018362814140807], [-1.079843459697346], [2.124162711033493], [0.25113397806018833], [0.24040028904601465], [-0.8383354568784387], [-1.439422041672164], [2.9077220090681704], [-1.5091910202642929], [0.4711746028507485], [0.7073157611625691], [-0.1030777594075427], [0.8790547853893477], [-0.4894905639177946], [-2.4805898760470093], [0.7824515842617846], [-0.3070178506768423], [-0.5270584754674025], [-0.7900338563146572], [-0.19431411602801882], [-0.3875205182831448], [-1.2998840844879063], [-0.7954007008217441], [1.1259296327153419], [-1.0583760816689989], [0.583878337499572], [-1.5145578647713795], [1.2386333673641654], [-0.21041464954927933], [0.44970722482240116], [0.40140562425861953], [1.9631573758208876], [0.9649242975027371], [-1.9707396478737604], [-0.9188381244847412], [-0.060143003350848], [-0.9456723470201753], [2.9667572986461255], [1.6411467053956779], [1.136663321729516], [1.3406034129988154], [0.009625975241280766], [0.5570441149641376], [1.0185927425736052], [-0.8705365239209597], [-0.6236616765949654], [-0.027941936308326976], [0.7502505172192636], [1.023959587080692], [2.360303869345313], [-0.7578327892721363], [1.7162825284948933], [0.3584708682019248], [-0.730998566736702], [-1.3320851515304273], [0.014992819748367723], [-1.020808170119391], [-0.1782135825067583], [-0.9993407920910437], [0.07939495383340953], [0.5892451820066588], [2.3334696468098794], [-2.040508626465889], [0.33163664566649076], [-0.5968274540595312], [0.10086233186175687], [0.326269801159404], [0.326269801159404], [0.38530509073735913], [-1.3481856850516878], [0.7770847397546979], [-0.022575091801240257], [-1.273049861952472], [-0.7524659447650494], [0.05792757580506242], [0.583878337499572], [-0.8437023013855255], [-1.0315418591335648], [-2.7220978788659167], [-0.6880638106800073], [-0.8437023013855255], [0.10086233186175687], [0.5302098924287036], [-0.12454513743589005], [-1.144245593782388], [0.3692045572160985], [0.1759981549609726], [0.6429136270775271], [-0.10844460391462954], [1.3459702575059023], [-1.5091910202642929], [0.15453077693262526], [0.21356606651058035], [0.224299755524754], [-0.6558627436374863], [0.5033756698932693], [0.26723451158144873], [-0.5002242529319683], [-0.9134712799776544], [-1.187180349839083], [0.9327232304602161], [0.0901286428475832], [-0.9295718134989149], [-0.2479825610988872], [2.757450362869739], [0.19209868848223324], [0.2779682005956224], [2.5266760490650055], [-0.26408309462014756], [-0.4036210518044052], [0.2189329110176673], [0.47654144735783527], [0.8307531848255663], [-0.7954007008217441], [3.8308192642871055], [0.5302098924287036], [0.18673184397514628], [0.256500822567275], [-1.112044526739867], [-0.5431590089886629], [-0.5753600760311839], [-1.1281450602611278], [-1.337451996037514], [0.7717178952476109], [-0.7363654112437888], [-0.1782135825067583], [1.0400601206019526], [0.9595574529956501], [0.8951553189106081], [0.09549548735467016], [-0.05477615884376128], [0.014992819748367723], [0.04719388679088875], [-1.1335119047682145], [0.2726013560885357], [0.10086233186175687], [0.4121393132727932], [0.44970722482240116], [0.2081992220034936], [-1.4662562642075982], [-0.3392189177193633], [-0.3123846951839291], [0.8951553189106081], [-0.15137935997132412], [1.0668943431373867], [0.9595574529956501], [-0.4411889633540131], [0.5570441149641376], [1.034693276094866], [-1.1066776822327804], [0.06329442031214914], [0.809285806797219], [0.7234162946838295], [0.3370034901735777], [-1.246215639417038], [-0.6880638106800073], [-0.6129279875807918], [0.6536473160917008], [0.8790547853893477], [0.224299755524754], [-0.4733900303965341], [-1.85266906871785], [-0.033308780815413934], [2.2851680462460977], [-0.46265634138236045], [-0.46802318588944725], [-1.2354819504028642], [1.227899678349992], [0.004259130734194047], [-0.8705365239209597], [1.1473970107436893], [1.136663321729516], [-0.43582211884692623], [1.2547339008854261], [-1.1013108377256935], [-0.2479825610988872], [0.9219895414460424], [0.2726013560885357], [-0.3928873627902317], [-1.09057714871152], [-0.46265634138236045], [-0.4841237194107078], [-0.18894727152093196], [-0.1030777594075427], [-0.7685664782863098], [-0.006474558279979626], [-0.05477615884376128], [0.294068734116883], [-0.3392189177193633], [-0.7202648777225283], [0.8146526513043056], [1.5069755927185071], [-0.18358042701384514], [0.9649242975027371], [-0.04940931433667432], [-1.0047076365981304], [0.1330633989042779], [-0.6236616765949654], [-1.0691097706831725], [0.47654144735783527], [-0.12454513743589005], [0.04182704228380179], [0.7985521177830452], [0.551677270457051], [1.2762012789137733], [-1.8204680016753292], [-0.8276017678642651], [-1.5574926208280744], [1.3298697239846415], [0.5194762034145299], [-0.3070178506768423], [-2.206880806185581], [-0.5753600760311839], [-2.3088508518202304], [-1.4018541301225562], [-2.0244080929446286], [0.868321096375174], [0.7126826056696558], [0.7985521177830452], [-1.305250928994993], [0.14379708791845158], [0.9327232304602161], [0.28333504510270935], [-0.24261571659180034], [0.04719388679088875], [2.3978717808949215], [-0.08697722588628219], [0.19746553298931996], [-0.26408309462014756], [0.6804815386271348], [-0.3392189177193633], [1.099095410179908], [-1.0583760816689989], [0.10622917636884384], [0.22966660003184097], [-0.31775153969101594], [-0.4572894968752736], [1.1205627882082552], [-0.027941936308326976], [-0.03867562532250065], [-0.6236616765949654], [0.4389735358082275], [-0.011841402787066583], [1.9738910648350616], [-2.507424098582444], [0.5892451820066588], [-1.187180349839083], [0.809285806797219], [-0.5538926980028366], [0.7609842062334372], [1.5660108822964625], [0.8844216298964344], [-0.2479825610988872], [-0.18894727152093196], [0.7341499836980032], [1.7109156839878066], [-1.7023974225194187], [0.9595574529956501], [1.3137691904633808], [-0.26408309462014756], [-1.187180349839083], [-0.36605314025479746], [1.3352365684917282], [-0.5324253199744892], [-0.5270584754674025], [1.8075188851153698], [0.3692045572160985], [-0.9832402585697831], [0.7448836727121769], [-1.112044526739867], [0.14916393242553852], [-0.5485258534957497], [-1.1764466608249091], [-0.4143547408185789], [0.7448836727121769], [-0.2855504726484949], [-1.9546391143525], [-0.730998566736702], [2.864787253011476], [0.5302098924287036], [1.560644037789375], [-0.17284673799967146], [-1.2408487949099511], [0.33163664566649076], [0.25113397806018833], [-1.4501557306863375], [0.900522163417695], [0.8575874073610004], [-1.5091910202642929], [0.9219895414460424], [-1.595060532377682], [-1.0261750146264779], [-0.5753600760311839], [0.6697478496129612], [-0.5324253199744892], [-0.859802834906786], [-0.9564060360343489], [0.3209029566523171], [-2.3839866749194467], [-0.31775153969101594], [0.2726013560885357], [-0.3070178506768423], [0.19209868848223324], [-0.4197215853256657], [-0.859802834906786], [-0.7524659447650494], [0.33163664566649076], [0.031093353269628116], [0.4872751363720089], [-0.15137935997132412], [0.1276965543971912], [1.4586739921547256], [-0.46265634138236045], [-0.3875205182831448], [-0.46802318588944725], [-0.6934306551870943], [-0.6612295881445733], [0.2350334445389277], [-0.18894727152093196], [-0.3123846951839291], [0.6536473160917008], [-1.342818840544601], [0.6375467825704402], [1.2010654558145575], [0.19746553298931996], [0.6053457155279194], [1.5069755927185071], [0.8897884744035214], [0.7234162946838295], [0.3423703346806644], [-0.859802834906786], [0.26723451158144873], [1.796785196101196], [2.016825820891756], [-2.260549251256449], [-0.36068629574771066], [-0.44655580786109994], [-0.2587162501130609], [1.70554883948072], [0.28870188960979604], [-0.3553194512406238], [0.04182704228380179], [0.4067724687657065], [0.37993824623027217], [-0.5646263870170102], [0.3048024231310567], [0.7770847397546979], [-1.187180349839083], [-0.4894905639177946], [-0.8329686123713519], [0.8468537183468267], [-0.9081044354705675], [-0.34458576222645015], [0.9166226969389554], [0.22966660003184097], [0.025726508762541397], [1.0668943431373867], [0.7448836727121769], [-0.8812702129351334], [0.2779682005956224], [-0.12991198194297676], [-0.8812702129351334], [-0.6236616765949654], [0.08476179834049649], [0.6912152276413085], [-0.04404246982958761], [-2.6576957447808747], [0.31553611214523036], [-0.30165100616975543], [-0.9939739475839569], [-1.0691097706831725], [-0.7256317222296153], [2.2422332901894033], [0.14379708791845158], [0.25113397806018833], [0.5624109594712247], [-0.9939739475839569], [-0.44655580786109994], [1.5928451048318963], [-0.5431590089886629], [-0.22651518307053983], [0.6804815386271348], [0.38530509073735913], [-0.43582211884692623], [-0.9725065695556095], [-0.5592595425099234], [0.05256073129797546], [-1.1496124382894748], [-0.011841402787066583], [-0.7148980332154415], [-0.698797499694181], [0.0686612648192361], [0.26723451158144873], [0.4228730022869669], [-0.6021942985666181], [-0.6558627436374863], [-0.21578149405636615], [-1.3857535966012955], [-0.15674620447841095], [-0.2372488720847135], [-0.006474558279979626], [-1.9385385808312394], [-1.369653063080035], [-1.4877236422359454], [0.2081992220034936], [0.4228730022869669], [-0.5592595425099234], [0.38530509073735913], [0.6268130935562665], [-0.46265634138236045], [1.7914183515941093], [0.868321096375174], [0.04182704228380179], [-1.1925471943461696], [0.4067724687657065], [-0.4411889633540131], [0.4872751363720089], [-0.8651696794138729], [-0.32848522870518965], [0.261867667074362], [-1.2140145723745168], [-0.5377921644815761], [-1.536025242799727], [-0.017208247294153302], [-0.46265634138236045], [-0.40898789631149207], [-1.3857535966012955], [1.217165989335818], [-0.8007675453288309], [-0.38215367377605797], [-0.38215367377605797], [1.6250461718744171], [0.8253863403184794], [-0.5377921644815761], [-0.14601251546423727], [-0.34458576222645015], [0.5624109594712247], [0.0686612648192361], [3.015058899209907], [1.1688643887720367], [-1.1979140388532565], [-0.2479825610988872], [-0.7631996337792231], [-0.24261571659180034], [-0.6773301216658337], [0.8468537183468267], [0.1169628653830175], [-0.34995260673353695], [0.6214462490491798], [0.036460197776715074], [-0.5860937650453576], [0.6053457155279194], [1.6572472389169386], [0.15453077693262526], [0.5194762034145299], [0.44970722482240116], [-0.38215367377605797], [-0.9939739475839569], [0.014992819748367723], [-0.17284673799967146], [-0.6397622101162259], [-1.5252915537855531], [-1.9761064923808473], [0.3906719352444459], [0.8253863403184794], [-1.4018541301225562], [0.8039189622901319], [0.4711746028507485], [-0.8759033684280465], [-0.2587162501130609], [-0.859802834906786], [-0.5216916309603157], [-0.49485740842488146], [0.4228730022869669], [1.190331766800384], [-0.05477615884376128], [-0.16747989349258463], [-0.9725065695556095], [0.28333504510270935], [0.26723451158144873], [-0.017208247294153302], [-0.7793001673004835], [-0.9134712799776544], [0.5624109594712247], [-0.4250884298327526], [0.6375467825704402], [-1.0476423926548253], [0.3960387797515328], [1.7270162175090673], [-0.9617728805414358], [0.7126826056696558], [0.4550740693294879], [-0.7846670118075705], [-1.2891503954737327], [-0.3875205182831448], [0.40140562425861953], [-1.0261750146264779], [-0.38215367377605797], [2.6769476952634363], [0.8039189622901319], [1.244000211871252], [-1.3213514625162537], [1.533809815253941], [-0.8544359903996992], [-0.6880638106800073], [0.11159602087593055], [-0.19968096053510564], [-0.6558627436374863], [-0.12454513743589005], [-0.6129279875807918], [-1.6755631999839844], [-0.6451290546233127], [2.7145156068130443], [-0.40898789631149207], [-0.21041464954927933], [2.3978717808949215], [-0.634395365609139], [0.06329442031214914], [1.2386333673641654], [0.8522205628539136], [0.1169628653830175], [-0.66659643265166], [0.5087425144003562], [0.15453077693262526], [0.583878337499572], [0.43360669130114055], [-0.15674620447841095], [-0.43582211884692623], [-0.1191782929288032], [0.46580775834366156], [0.9327232304602161], [0.7556173617263505], [1.6572472389169386], [-0.3231183841981028], [0.15453077693262526], [1.8450867966649773], [-0.07087669236502167], [-1.0744766151902594], [0.10086233186175687], [0.6965820721483954], [-0.5055910974390552], [-0.221148338563453], [-0.6880638106800073], [0.7126826056696558], [0.2779682005956224], [0.7717178952476109], [-1.6379952884343767], [-0.46802318588944725], [-0.21041464954927933], [1.1581306997578626], [-0.6880638106800073], [-0.7095311887083547], [0.05792757580506242], [-0.5538926980028366], [-1.439422041672164], [1.3406034129988154], [0.3692045572160985], [-0.03867562532250065], [-0.2962841616626686], [0.07402810932632281], [-0.5002242529319683], [-0.4036210518044052], [0.5248430479216166], [-0.6826969661729206], [-2.1263781385792786], [-1.7184979560406792], [-1.2247482613886906], [-0.08161038137919535], [-1.0047076365981304], [-0.2587162501130609], [-0.6558627436374863], [-1.112044526739867], [-1.439422041672164], [-0.9725065695556095], [0.5570441149641376], [-0.5431590089886629], [-0.34995260673353695], [0.22966660003184097], [-2.1854134281572337], [1.0615274986302998], [-0.2909173171555818], [1.2117991448287313], [-0.8007675453288309], [-0.8812702129351334], [0.2028323774964069], [1.3245028794775549], [0.7448836727121769], [-0.006474558279979626], [-0.16747989349258463], [0.09549548735467016], [0.06329442031214914], [1.023959587080692], [0.3048024231310567], [0.578511492992485], [-0.7954007008217441], [-0.18894727152093196], [0.25113397806018833], [2.360303869345313], [0.8307531848255663], [-0.9939739475839569], [-0.6182948320878786], [0.18673184397514628], [-0.5699932315240971], [0.8951553189106081], [-0.30165100616975543], [-1.6755631999839844], [0.020359664255454442], [0.3370034901735777], [-1.8258348461824159], [-1.9653728033666735], [-0.253349405605974], [-0.08697722588628219], [-1.3803867520942088], [0.7985521177830452], [-1.305250928994993], [-0.5055910974390552], [-1.1388787492753012], [-0.730998566736702], [-0.5860937650453576], [-1.471623108714685], [-0.5377921644815761], [0.24576713355310137], [-0.05477615884376128], [-0.9671397250485226], [2.6125455611783948], [0.261867667074362], [0.5409435814428772], [-0.2855504726484949], [0.41750615777988015], [0.19209868848223324], [-0.2694499391272344], [-2.013674403930455], [-0.38215367377605797], [-0.4143547408185789], [0.4228730022869669], [-0.7256317222296153], [0.2726013560885357], [-0.6934306551870943], [-1.305250928994993], [0.43360669130114055], [-0.9564060360343489], [-0.9403055025130886], [0.29943557862396974], [1.1205627882082552], [0.6321799380633534], [0.6804815386271348], [-1.0959439932186068], [0.583878337499572], [-0.12991198194297676], [-1.562859465335161], [2.1563637780760136], [-2.255182406749362], [0.9166226969389554], [-1.1388787492753012], [-1.1657129718107355], [-0.1030777594075427], [0.18136499946805956], [0.004259130734194047], [-1.0959439932186068], [1.9524236868067142], [-0.4411889633540131], [-0.34995260673353695], [-0.08161038137919535], [0.4711746028507485], [1.5821114158177225], [0.12232970989010424], [-0.9188381244847412], [0.9917585200381711], [1.1742312332791234], [0.11159602087593055], [-0.1191782929288032], [-0.9188381244847412], [1.4962419037043335], [0.26723451158144873], [-0.6236616765949654], [-0.2587162501130609], [2.1187958665264057], [-0.6075611430737049], [-0.5485258534957497], [1.3245028794775549], [0.8039189622901319], [0.8039189622901319], [0.8039189622901319], [-0.09771091490045586], [-0.6934306551870943], [-0.5002242529319683], [0.3906719352444459], [-0.5807269205382707], [0.5194762034145299], [-0.6397622101162259], [-0.4250884298327526], [-0.7470991002579626], [2.2100322231468823], [0.05792757580506242], [0.9649242975027371], [-0.9725065695556095], [-0.6880638106800073], [-0.6826969661729206], [-2.17467973914306], [-1.9278048918170656], [-0.36605314025479746], [-0.19968096053510564], [0.28870188960979604], [-0.5270584754674025], [1.3996387025767703], [0.31553611214523036], [-1.0154413256123043], [-0.23188202757762666], [0.873687940882261], [0.9595574529956501], [-1.2247482613886906], [1.4318397696192915], [-0.022575091801240257], [-0.27481678363432127], [-1.2354819504028642], [-2.0458754709729763], [-0.7793001673004835], [1.3459702575059023], [0.546310425949964], [-0.3928873627902317], [0.10086233186175687], [0.6697478496129612], [1.9309563087783668], [-1.1281450602611278], [-0.11381144842171637], [-0.09234407039336902], [0.14916393242553852], [-1.144245593782388], [1.1581306997578626], [-0.18358042701384514], [0.020359664255454442], [-1.4233215081509034], [0.7824515842617846], [-0.221148338563453], [-1.283783550966646], [-0.47875687490362095], [-0.2587162501130609], [-1.8312016906895026], [-0.40898789631149207], [0.1598976214397122], [-0.43582211884692623], [0.41750615777988015], [-0.5753600760311839], [0.0686612648192361], [-2.555725699146225], [0.37993824623027217], [-0.060143003350848], [0.40140562425861953], [0.6590141605987875], [0.7985521177830452], [-2.180046583650147], [-0.6826969661729206], [1.7914183515941093], [0.5302098924287036], [-2.244448717735189], [0.6214462490491798], [0.9810248310239975], [-0.45192265236818674], [0.4550740693294879], [-0.20504780504219247], [0.7341499836980032], [0.46580775834366156], [-0.3553194512406238], [0.12232970989010424], [0.1276965543971912], [-0.15674620447841095], [-1.7077642670265056], [-1.8473022242107633], [-0.4411889633540131], [-0.6773301216658337], [-1.884870135760371], [0.3423703346806644], [0.6375467825704402], [0.28870188960979604], [0.8307531848255663], [-0.34995260673353695], [-0.24261571659180034], [-0.7739333227933968], [-0.27481678363432127], [0.19209868848223324], [-0.6236616765949654], [1.034693276094866], [1.0776280321515606], [-0.060143003350848], [-1.154979282796562], [1.227899678349992], [0.025726508762541397], [-0.006474558279979626], [-0.2962841616626686], [-0.4411889633540131], [0.7448836727121769], [-0.1782135825067583], [-0.2962841616626686], [-0.7256317222296153], [2.2690675127248374], [1.7162825284948933], [-0.30165100616975543], [-0.14601251546423727], [1.8558204856791514], [-0.15137935997132412], [0.546310425949964], [-0.221148338563453], [0.551677270457051], [0.025726508762541397], [-1.9385385808312394], [-1.6379952884343767], [0.3906719352444459], [-0.8973707464563939], [1.3406034129988154], [0.10086233186175687], [2.837953030476042], [-0.7256317222296153], [-0.006474558279979626], [0.3101692676381434], [-0.510957941946142], [0.7448836727121769], [0.5033756698932693], [0.42823984679405386], [-1.0369087036406515], [0.05792757580506242], [-0.8168680788500915], [1.517709281732681], [-0.006474558279979626], [-0.8812702129351334], [-1.3481856850516878], [-0.6826969661729206], [-1.8956038247745446], [0.5302098924287036], [-0.31775153969101594], [0.809285806797219], [2.2207659121610557], [-0.9403055025130886], [-0.698797499694181], [0.9166226969389554], [0.28333504510270935], [0.3101692676381434], [0.1276965543971912], [0.7770847397546979], [-0.33385207321227645], [1.9953584428634088], [-0.21578149405636615], [0.9756579865169107], [-0.3123846951839291], [1.28156812342086], [-0.15137935997132412], [0.7287831391909165], [2.274434357231924], [1.7431167510303278], [-0.6934306551870943], [2.2798012017390112], [-0.7202648777225283], [-2.684529967316309], [-0.28018362814140807], [-1.9224380473099787], [-1.1764466608249091], [0.5624109594712247], [2.0651274214555375], [2.6340129392067415], [-0.8276017678642651], [0.224299755524754], [1.1688643887720367], [0.004259130734194047], [-1.2140145723745168], [-0.18358042701384514], [1.0829948766586472], [0.4121393132727932], [-0.510957941946142], [0.3960387797515328], [0.5355767369357903], [2.2798012017390112], [0.583878337499572], [-0.5431590089886629], [0.3048024231310567], [1.9416899977925408], [-0.6075611430737049], [-0.23188202757762666], [-0.4143547408185789], [-0.9832402585697831], [0.3745714017231855], [0.6912152276413085], [-1.305250928994993], [-1.4501557306863375], [0.7019489166554822], [-0.43582211884692623], [-1.8956038247745446], [0.4711746028507485], [0.14379708791845158], [-0.16747989349258463], [-0.6129279875807918], [0.6214462490491798], [0.8468537183468267], [1.023959587080692], [1.8450867966649773], [0.004259130734194047], [-0.6612295881445733], [-1.7829000901257213], [-0.28018362814140807], [0.3745714017231855], [-0.07087669236502167], [2.0704942659626244], [-1.562859465335161], [0.256500822567275], [1.898755241735846], [-0.7846670118075705], [0.18136499946805956], [-0.3123846951839291], [-0.8061343898359178], [-0.03867562532250065], [0.8146526513043056], [0.22966660003184097], [-0.3714199847618843], [-0.16211304898549778], [0.7770847397546979], [0.2028323774964069], [1.769950973565762], [2.215399067653969], [1.759217284551588], [-0.6290285211020523], [0.6429136270775271], [-1.2891503954737327], [0.9166226969389554], [-1.1281450602611278], [-0.2587162501130609], [1.222532833842905], [-0.730998566736702], [-0.19431411602801882], [-0.7041643442012678], [0.06329442031214914], [-0.6880638106800073], [0.009625975241280766], [1.1473970107436893], [-0.7954007008217441], [0.40140562425861953], [0.9434569194743897], [-0.2962841616626686], [-0.253349405605974], [-0.7685664782863098], [0.2779682005956224], [-0.4841237194107078], [2.623279250192568], [1.286934967927947], [-0.9564060360343489], [0.004259130734194047], [0.8951553189106081], [-1.154979282796562], [-1.0261750146264779], [1.7109156839878066], [-0.06550984785793483], [2.1348964000476665], [-1.053009237161912], [-0.8329686123713519], [2.2798012017390112], [-0.08161038137919535], [1.2332665228570787], [0.7180494501767428], [2.510575515543745], [-3.3983202867588576], [0.17063131045388588], [2.24760013469649], [-0.6612295881445733], [0.5087425144003562], [0.7824515842617846], [-2.206880806185581], [-0.5216916309603157], [1.28156812342086], [-0.43582211884692623], [0.6751146941200481], [-0.21578149405636615], [0.8951553189106081], [0.18136499946805956], [0.6107125600350061], [-1.122778215754041], [-0.6021942985666181], [-0.43582211884692623], [-0.36068629574771066], [-0.20504780504219247], [-0.221148338563453], [-0.21041464954927933], [-1.6755631999839844], [0.9702911420098238], [0.5248430479216166], [-1.31061777350208], [-0.7685664782863098], [-0.17284673799967146], [-1.144245593782388], [3.88985455386506], [-1.1657129718107355], [-0.19431411602801882], [-0.8973707464563939], [0.10622917636884384], [-0.6773301216658337], [-0.017208247294153302], [-0.09234407039336902], [1.2493670563783392], [0.46580775834366156], [-0.7631996337792231], [-1.154979282796562], [0.4872751363720089], [1.453307147647639], [1.1742312332791234], [0.9541906084885634], [0.8468537183468267], [1.0400601206019526], [-0.9510391915272621], [1.1473970107436893], [-0.060143003350848], [-2.2283481842139286], [0.5248430479216166], [-0.3553194512406238], [-0.8759033684280465], [-1.154979282796562], [-0.36605314025479746], [-2.1102776050580183], [-1.6218947549131164], [-0.6504958991303996], [-0.15137935997132412], [1.4479403031405518], [1.0668943431373867], [-0.43045527433983943], [-2.2283481842139286], [-0.45192265236818674], [2.3334696468098794], [0.4121393132727932], [-1.1496124382894748], [-0.12454513743589005], [0.8253863403184794], [-0.4197215853256657], [0.031093353269628116], [0.11159602087593055], [0.19746553298931996], [-2.260549251256449], [-0.12991198194297676], [-0.27481678363432127], [-0.027941936308326976], [-0.9725065695556095], [2.1778311561043613], [-0.253349405605974], [1.984624753849235], [-1.1925471943461696], [2.2368664456823164], [-0.19968096053510564], [0.025726508762541397], [-1.079843459697346], [-0.46802318588944725], [2.784284585405173], [0.49264198087909566], [-1.0100744811052174], [-0.19431411602801882], [0.6107125600350061], [0.224299755524754], [1.1581306997578626], [0.18673184397514628], [-0.7846670118075705], [-0.32848522870518965], [-0.2479825610988872], [-0.1191782929288032], [0.17063131045388588], [-1.4769899532217718], [0.44970722482240116], [0.3370034901735777], [-0.5538926980028366], [-0.40898789631149207], [-0.9510391915272621], [0.9434569194743897], [0.3960387797515328], [-0.20504780504219247], [-0.7148980332154415], [0.24576713355310137], [0.6590141605987875], [0.5999788710208324], [-0.7846670118075705], [2.204665378639795], [0.10086233186175687], [-0.20504780504219247], [-0.4411889633540131], [-0.0011077137728929085], [-0.1352788264500636], [-0.634395365609139], [0.7341499836980032], [0.5302098924287036], [-0.7148980332154415], [0.10622917636884384], [-0.34995260673353695], [-1.0261750146264779], [-0.18894727152093196], [-0.8866370574422202], [-0.03867562532250065], [0.873687940882261], [-0.11381144842171637], [0.3692045572160985], [-1.4340551971650772], [-1.0047076365981304], [-0.18894727152093196], [-0.98860710307687], [1.9577905313138009], [-1.09057714871152], [-0.4841237194107078], [-0.7685664782863098], [-0.4036210518044052], [0.4443403803153142], [-0.2694499391272344], [0.48190829186492196], [-0.1782135825067583], [-0.8812702129351334], [2.6823145397705237], [-0.8115012343430045], [-0.11381144842171637], [-0.8007675453288309], [1.0132258980665185], [-0.07087669236502167], [-0.7095311887083547], [-1.2945172399808194], [0.4228730022869669], [-0.14064567095715044], [1.099095410179908], [1.6894483059594592], [1.3191360349704682], [-0.44655580786109994], [1.5284429707468543], [-0.45192265236818674], [0.19746553298931996], [0.40140562425861953], [-0.9564060360343489], [-0.16747989349258463], [-0.18894727152093196], [1.1420301662366026], [0.7556173617263505], [-0.9725065695556095], [-1.884870135760371], [0.5355767369357903], [-1.2032808833603432], [-0.3553194512406238], [-0.4841237194107078], [-0.8329686123713519], [-0.45192265236818674], [0.18673184397514628], [2.757450362869739], [2.859420408504389], [-1.219381416881604], [1.227899678349992], [-0.2962841616626686], [-0.2694499391272344], [0.24576713355310137], [0.4711746028507485], [-2.206880806185581], [1.3406034129988154], [0.5302098924287036], [0.9380900749673028], [-1.0476423926548253], [-0.20504780504219247], [0.020359664255454442], [0.3423703346806644], [1.1205627882082552], [0.37993824623027217], [-0.39825420729731836], [-0.3123846951839291], [0.1598976214397122], [-0.45192265236818674], [1.0668943431373867], [0.5355767369357903], [0.9166226969389554], [-0.08697722588628219], [-0.4411889633540131], [-0.15137935997132412], [-0.6075611430737049], [0.4980088253861826], [0.06329442031214914], [-0.5753600760311839], [-0.7685664782863098], [-3.2212144180249926], [-1.0047076365981304], [-0.4572894968752736], [-0.7095311887083547], [-0.8651696794138729], [0.22966660003184097], [-2.233715028721015], [-0.5538926980028366], [0.04182704228380179], [0.3048024231310567], [-1.4501557306863375], [2.6769476952634363], [0.3423703346806644], [-1.0047076365981304], [-1.6916637335052451], [0.7824515842617846], [-0.9617728805414358], [-1.1925471943461696], [1.9577905313138009], [0.3531040236948381], [1.3245028794775549], [-0.2694499391272344], [1.9094889307500196], [-0.66659643265166], [1.6626140834240253], [-0.2962841616626686], [0.036460197776715074], [-0.28018362814140807], [0.3692045572160985], [0.41750615777988015], [-0.03867562532250065], [-0.8705365239209597], [0.37993824623027217], [-0.12454513743589005], [0.7502505172192636], [0.036460197776715074], [-0.6397622101162259], [0.036460197776715074], [-0.21041464954927933], [1.3889050135625969], [0.84148687383974], [-0.66659643265166], [-0.8490691458926124], [1.5660108822964625], [0.4443403803153142], [0.8844216298964344], [0.09549548735467016], [-0.6397622101162259], [0.14379708791845158], [0.6107125600350061], [0.22966660003184097], [1.152763855250776], [0.7985521177830452], [-0.5216916309603157], [0.46044091383657487], [-2.389353519426533], [-0.9564060360343489], [-0.7148980332154415], [0.4121393132727932], [0.7824515842617846], [-0.7524659447650494], [-0.5431590089886629], [-1.6701963554768977], [0.1598976214397122], [-1.4877236422359454], [-0.8329686123713519], [-0.20504780504219247], [-0.5592595425099234], [0.7287831391909165], [-0.98860710307687], [1.453307147647639], [0.16526446594679892], [0.8200194958113926], [-1.2891503954737327], [0.44970722482240116], [0.6375467825704402], [-2.0244080929446286], [0.14379708791845158], [-1.283783550966646], [-0.221148338563453], [-1.4018541301225562], [-1.2408487949099511], [-0.15137935997132412], [-2.212247650692668], [-0.5002242529319683], [1.7806846625799353], [-1.0422755481477384], [0.15453077693262526], [-0.9134712799776544], [-0.46802318588944725], [0.7180494501767428], [1.029326431587779], [0.9166226969389554], [0.6375467825704402], [0.7556173617263505], [-0.221148338563453], [1.136663321729516], [-1.600427376884769], [1.3728044800413362], [0.40140562425861953], [0.9971253645452581], [-1.6970305780123318], [1.4211060806051177], [-2.0834433825225838], [1.5928451048318963], [-0.7685664782863098], [1.3191360349704682], [0.1759981549609726], [-0.3392189177193633], [0.6590141605987875], [-0.04404246982958761], [0.256500822567275], [2.3334696468098794], [0.2028323774964069], [0.5999788710208324], [-1.6487289774485503], [-0.9188381244847412], [0.3906719352444459], [0.28333504510270935], [0.24576713355310137], [-0.4733900303965341], [0.13843024341136487], [0.40140562425861953], [0.47654144735783527], [2.1295295555405795], [-0.19431411602801882], [-0.8276017678642651], [-0.21578149405636615], [0.29943557862396974], [1.6465135499027646], [-2.6254946777383537], [1.769950973565762], [-0.19431411602801882], [0.22966660003184097], [-1.1066776822327804], [-1.2945172399808194], [-0.8973707464563939], [2.1939316896256216], [-0.15674620447841095], [-0.7524659447650494], [-0.730998566736702], [0.47654144735783527], [-0.033308780815413934], [0.19746553298931996], [1.244000211871252], [0.3101692676381434], [-0.09771091490045586], [-0.5646263870170102], [-0.253349405605974], [2.1348964000476665], [0.33163664566649076], [-0.06550984785793483], [-0.4841237194107078], [-0.32848522870518965], [-0.5914606095524444], [0.24040028904601465], [-0.6236616765949654], [-0.4197215853256657], [-0.16747989349258463], [-0.43045527433983943], [-1.5091910202642929], [0.873687940882261], [-0.9456723470201753], [1.415739236098031], [2.022192665398843], [0.6804815386271348], [-0.7041643442012678], [-0.23188202757762666], [2.859420408504389], [-0.9295718134989149], [-0.2855504726484949], [1.8075188851153698], [-0.221148338563453], [0.44970722482240116], [-0.011841402787066583], [0.583878337499572], [-0.0011077137728929085], [0.5248430479216166], [0.05256073129797546], [-1.251582483924125], [1.244000211871252], [-0.7524659447650494], [-0.5163247864532288], [-1.0100744811052174], [-0.03867562532250065], [-0.027941936308326976], [1.0507938096161265], [1.673347772438199], [-0.24261571659180034], [1.1259296327153419], [-0.9081044354705675], [0.5409435814428772], [-0.45192265236818674], [-0.5377921644815761], [2.4515402259657892], [0.809285806797219], [0.0901286428475832], [-1.273049861952472], [0.4980088253861826], [0.9595574529956501], [-0.04404246982958761], [-1.981473336887934], [-0.1782135825067583], [0.2028323774964069], [-0.6719632771587469], [0.18673184397514628], [0.7878184287688715], [-0.7417322557508758], [0.29943557862396974], [3.176064234422512], [-0.6451290546233127], [1.1420301662366026], [0.10086233186175687], [-0.9617728805414358], [0.9595574529956501], [-0.7578327892721363], [0.551677270457051], [-0.0011077137728929085], [-0.5699932315240971], [-1.6379952884343767], [0.5355767369357903], [1.152763855250776], [-0.6719632771587469], [-0.8383354568784387], [-1.154979282796562], [0.1276965543971912], [0.4067724687657065], [-0.12991198194297676], [-0.0011077137728929085], [-1.342818840544601], [-0.07087669236502167], [-0.08697722588628219], [0.08476179834049649], [-0.9832402585697831], [0.8253863403184794], [-0.6612295881445733], [-1.5521257763209875], [-0.3231183841981028], [0.08476179834049649], [0.1598976214397122], [-0.7470991002579626], [-1.1979140388532565], [0.12232970989010424], [0.19746553298931996], [0.10622917636884384], [1.2386333673641654], [-1.6809300444910713], [-0.23188202757762666], [-0.18894727152093196], [-1.0422755481477384], [1.0722611876444739], [-0.3714199847618843], [0.1169628653830175], [2.032926354413017], [-0.40898789631149207], [-0.2479825610988872], [-1.4930904867430321], [-0.6934306551870943], [-0.9242049689918279], [-0.7524659447650494], [-0.7739333227933968], [-1.8097343126611554], [-0.8544359903996992], [-0.9403055025130886], [0.46580775834366156], [0.3370034901735777], [0.036460197776715074], [1.533809815253941], [0.5033756698932693], [-1.2032808833603432], [3.2673005910429875], [0.7502505172192636], [1.244000211871252], [0.5731446484853984], [-0.017208247294153302], [0.17063131045388588], [1.0776280321515606], [-1.1603461273036486], [-1.6111610658989426], [0.2028323774964069], [0.6912152276413085], [-0.859802834906786], [-0.33385207321227645], [-0.21578149405636615], [1.9953584428634088], [0.9863916755310844], [1.5874782603248097], [0.9219895414460424], [1.1312964772224288], [-1.3964872856154693], [0.8629542518680873], [-1.3320851515304273], [0.900522163417695], [-1.4340551971650772], [0.004259130734194047], [-0.34995260673353695], [0.4389735358082275], [-0.5431590089886629], [0.5355767369357903], [-2.0512423154800628], [0.7878184287688715], [0.18673184397514628], [0.7395168282050901], [0.21356606651058035], [2.24760013469649], [2.693048228784697], [0.1169628653830175], [1.673347772438199], [0.4550740693294879], [-0.12454513743589005], [-0.4733900303965341], [-1.337451996037514], [-0.6236616765949654], [1.0132258980665185], [2.360303869345313], [0.41750615777988015], [0.10622917636884384], [-0.12991198194297676], [0.5892451820066588], [0.8307531848255663], [-1.7560658675902872], [-0.30165100616975543], [-0.5163247864532288], [0.4228730022869669], [0.6375467825704402], [-0.44655580786109994], [-0.6719632771587469], [-0.7846670118075705], [-0.8329686123713519], [-1.1281450602611278], [-0.6075611430737049], [0.43360669130114055], [0.7502505172192636], [-1.4984573312501193], [-0.17284673799967146], [-0.34458576222645015], [0.8951553189106081], [0.04719388679088875], [1.8128857296224568], [0.25113397806018833], [-1.4125878191367298], [-1.1603461273036486], [-1.0100744811052174], [-1.2247482613886906], [0.6536473160917008], [0.24040028904601465], [-0.9403055025130886], [-0.10844460391462954], [-1.2408487949099511], [1.2332665228570787], [0.6482804715846138], [-0.8276017678642651], [0.9595574529956501], [-0.1782135825067583], [-0.060143003350848], [-1.0744766151902594], [1.6304130163815045], [1.3137691904633808], [2.1295295555405795], [-0.7578327892721363], [-0.11381144842171637], [1.6518803944098517], [0.3960387797515328], [-1.5091910202642929], [1.1473970107436893], [0.3048024231310567], [-0.33385207321227645], [1.4962419037043335], [-0.20504780504219247], [1.5874782603248097], [-1.4608894197005111], [0.7717178952476109], [1.8182525741295434], [0.5194762034145299], [0.2189329110176673], [-0.2479825610988872], [1.1742312332791234], [0.41750615777988015], [-0.3714199847618843], [1.5982119493389833], [-1.337451996037514], [-0.8007675453288309], [1.1259296327153419], [1.0668943431373867], [-0.7846670118075705], [-0.9778734140626963], [-2.206880806185581], [-0.11381144842171637], [1.5016087482114204], [3.508808593861896], [-0.892003901949307], [0.8951553189106081], [0.06329442031214914], [2.5159423600508313], [-0.7954007008217441], [-0.15137935997132412], [-0.18894727152093196], [1.9685242203279747], [-0.4411889633540131], [-0.9188381244847412], [-1.2998840844879063], [-0.16747989349258463], [-0.5592595425099234], [-0.16211304898549778], [-1.2247482613886906], [0.031093353269628116], [1.8504536411720642], [0.7770847397546979], [-0.8973707464563939], [0.3101692676381434], [0.24040028904601465], [-0.859802834906786], [-3.6290946005635916], [2.4891081375153976], [0.18136499946805956], [-1.278416706459559], [-1.112044526739867], [0.07939495383340953], [-1.3159846180091668], [-0.12991198194297676], [-1.9331717363241527], [0.04719388679088875], [-1.0476423926548253], [-1.6433621329414636], [-0.07087669236502167], [-0.4197215853256657], [-0.5431590089886629], [-0.04404246982958761], [0.4121393132727932], [-1.219381416881604], [-0.32848522870518965], [0.2189329110176673], [-0.11381144842171637], [-0.3553194512406238], [-0.32848522870518965], [0.24040028904601465], [1.1151959437011685], [1.2547339008854261], [0.3745714017231855], [0.6053457155279194], [1.3942718580696836], [-1.3750199075871221], [0.7878184287688715], [1.6304130163815045], [0.6858483831342218], [-0.2962841616626686], [0.12232970989010424], [0.6482804715846138], [-0.7793001673004835], [1.0132258980665185], [-0.6182948320878786], [-0.011841402787066583], [2.0651274214555375], [-0.11381144842171637], [0.5409435814428772], [1.099095410179908], [0.551677270457051], [-1.0261750146264779], [0.15453077693262526], [0.031093353269628116], [-1.729231645054853], [1.152763855250776], [1.227899678349992], [-0.08697722588628219], [-0.4733900303965341], [-1.1013108377256935], [0.7824515842617846], [-0.7041643442012678], [-0.12454513743589005], [0.15453077693262526], [-0.6773301216658337], [-0.1191782929288032], [-1.3267183070233404], [-0.730998566736702], [-0.5646263870170102], [0.7448836727121769], [-0.2587162501130609], [0.261867667074362], [-0.3123846951839291], [0.2779682005956224], [0.5570441149641376], [-0.44655580786109994], [1.0132258980665185], [0.4550740693294879], [-0.14064567095715044], [1.6572472389169386], [0.06329442031214914], [1.0454269651090393], [0.7341499836980032], [0.256500822567275], [0.05256073129797546], [-0.9295718134989149], [-0.34458576222645015], [0.6375467825704402], [1.4855082146901597], [0.836120029332653], [1.8558204856791514], [0.40140562425861953], [0.224299755524754], [1.4747745256759863], [0.8253863403184794], [0.04182704228380179], [-0.09234407039336902], [-0.6182948320878786], [-1.8365685351965895], [-0.07087669236502167], [1.4103723915909443], [0.84148687383974], [-0.16747989349258463], [1.4640408366618123], [0.1330633989042779], [-0.7524659447650494], [0.224299755524754], [-0.37678682926897117], [0.261867667074362], [-0.6719632771587469], [-1.0261750146264779], [-1.0047076365981304], [-0.3123846951839291], [-0.4036210518044052], [-0.8115012343430045], [-0.8651696794138729], [-0.16747989349258463], [0.7556173617263505], [0.2189329110176673], [0.5087425144003562], [-0.1782135825067583], [-0.3123846951839291], [-0.253349405605974], [-1.112044526739867], [-0.0011077137728929085], [-0.14064567095715044], [-0.5699932315240971], [-0.43582211884692623], [-1.3803867520942088], [0.40140562425861953], [-0.7041643442012678], [0.7502505172192636], [2.032926354413017], [-0.04940931433667432], [-0.7954007008217441], [1.4103723915909443], [-0.7846670118075705], [0.5624109594712247], [0.256500822567275], [0.47654144735783527], [0.7985521177830452], [-0.5324253199744892], [-0.8061343898359178], [-0.8061343898359178], [0.09549548735467016], [-0.011841402787066583], [0.4550740693294879], [0.25113397806018833], [0.10086233186175687], [-1.63262844392729], [2.601811872164221], [-0.7202648777225283], [0.6053457155279194], [0.7073157611625691], [0.10086233186175687], [0.2350334445389277], [0.4980088253861826], [1.3567039465200756], [-0.8007675453288309], [-1.112044526739867], [0.33163664566649076], [-0.634395365609139], [-0.3714199847618843], [-0.15137935997132412], [1.2010654558145575], [-0.033308780815413934], [-0.6021942985666181], [-0.060143003350848], [-0.14064567095715044], [0.224299755524754], [-0.3070178506768423], [0.6590141605987875], [0.256500822567275], [-0.253349405605974], [-1.562859465335161], [0.11159602087593055], [2.1456300890618403], [-0.19431411602801882], [1.9577905313138009], [-0.9027375909634807], [2.140263244554753], [0.873687940882261], [-0.8222349233571782], [0.3906719352444459], [-0.6880638106800073], [-1.187180349839083], [0.3370034901735777], [-0.6236616765949654], [-2.4591224980186626], [-0.31775153969101594], [-0.04404246982958761], [1.16349754426495], [0.3531040236948381], [-0.6129279875807918], [-1.2569493284312117], [0.2726013560885357], [-0.19431411602801882], [0.8522205628539136], [2.730616140334305], [-0.6182948320878786], [-0.5646263870170102], [0.2779682005956224], [-0.6236616765949654], [-0.3231183841981028], [0.9273563859531291], [-2.3464187633698383], [0.5570441149641376], [0.38530509073735913], [0.3584708682019248], [0.24040028904601465], [-0.006474558279979626], [0.3531040236948381], [-0.3875205182831448], [-0.04940931433667432], [0.4228730022869669], [0.7395168282050901], [1.2117991448287313], [-0.19431411602801882], [0.8522205628539136], [-1.8097343126611554], [0.8575874073610004], [0.551677270457051], [1.227899678349992], [1.2010654558145575], [1.92558946427128], [-0.6773301216658337], [1.0132258980665185], [1.1259296327153419], [-0.5002242529319683], [-1.4447888861792508], [0.583878337499572], [-0.4411889633540131], [-1.0422755481477384], [-0.8222349233571782], [-0.5163247864532288], [0.06329442031214914], [1.7860515070870226], [0.24040028904601465], [1.533809815253941], [-0.017208247294153302], [0.3048024231310567], [0.4121393132727932], [0.3423703346806644], [1.4050055470838574], [0.7931852732759583], [-0.09234407039336902], [0.025726508762541397], [1.2547339008854261], [1.8880215527216722], [2.4354396924445294], [-0.6934306551870943], [-0.634395365609139], [0.3584708682019248], [0.836120029332653], [0.7019489166554822], [2.1831980006114478], [0.9112558524318687], [1.4586739921547256], [0.8522205628539136], [-0.04404246982958761], [-1.251582483924125], [-0.3123846951839291], [1.286934967927947], [-0.060143003350848], [-2.265916095763536], [0.036460197776715074], [-0.14601251546423727], [-0.21041464954927933], [1.453307147647639], [-0.5914606095524444], [1.0615274986302998], [0.14379708791845158], [0.15453077693262526], [-0.8061343898359178], [0.6751146941200481], [0.6858483831342218], [0.42823984679405386], [-1.3320851515304273], [-0.6934306551870943], [-0.8276017678642651], [-0.36605314025479746], [0.4228730022869669], [0.9595574529956501], [-0.6182948320878786], [0.326269801159404], [-0.892003901949307], [1.533809815253941], [-0.11381144842171637], [1.5982119493389833], [0.06329442031214914], [-0.7739333227933968], [-1.0154413256123043], [2.3227359577957056], [-0.19968096053510564], [-1.6701963554768977], [0.326269801159404], [-1.0261750146264779], [0.4121393132727932], [0.8951553189106081], [1.1259296327153419], [-0.006474558279979626], [-0.022575091801240257], [-0.5002242529319683], [-1.6809300444910713], [-0.1030777594075427], [-0.5807269205382707], [-1.1657129718107355], [-1.4930904867430321], [-1.3535525295587747], [-0.06550984785793483], [0.18673184397514628], [-1.2623161729382986], [-2.1263781385792786], [-0.5002242529319683], [-0.5753600760311839], [-0.2909173171555818], [-0.6451290546233127], [-0.5968274540595312], [-1.154979282796562], [0.25113397806018833], [-0.4143547408185789], [0.04182704228380179], [0.6482804715846138], [-0.04404246982958761], [2.537409738079179], [1.3406034129988154], [-0.08697722588628219], [-0.43582211884692623], [1.3567039465200756], [-0.11381144842171637], [0.8200194958113926], [-0.4036210518044052], [1.533809815253941], [0.08476179834049649], [2.360303869345313], [1.6626140834240253], [-0.7363654112437888], [1.099095410179908], [0.8522205628539136], [-0.022575091801240257], [-0.14064567095715044], [-0.14064567095715044], [-0.6290285211020523], [0.08476179834049649], [-0.8759033684280465], [2.1670974670901875], [-0.8115012343430045], [0.6429136270775271], [-0.7202648777225283], [0.036460197776715074], [-0.4036210518044052], [-0.15137935997132412], [1.6357798608885912], [-0.5592595425099234], [0.8522205628539136], [1.5982119493389833], [-0.7363654112437888], [1.6143124828602438], [0.7180494501767428], [-0.5431590089886629], [0.7019489166554822], [1.286934967927947], [-0.7578327892721363], [-0.4250884298327526], [-0.7578327892721363], [-0.6880638106800073], [0.14379708791845158], [-0.3928873627902317], [-0.8115012343430045], [-2.689896811823396], [0.22966660003184097], [-1.2408487949099511], [1.351337102012989], [0.4228730022869669], [-0.46265634138236045], [0.7019489166554822], [-1.1388787492753012], [0.5731446484853984], [-0.033308780815413934], [0.009625975241280766], [0.3906719352444459], [-0.46265634138236045], [-0.45192265236818674], [0.3423703346806644], [2.6501134727280022], [-0.14601251546423727], [-1.600427376884769], [1.227899678349992], [1.7860515070870226], [-0.7470991002579626], [0.3209029566523171], [1.244000211871252], [0.004259130734194047], [-0.5646263870170102], [-0.18358042701384514], [1.16349754426495], [-0.7470991002579626], [0.7126826056696558], [-1.4823567977288585], [-0.6075611430737049], [1.0507938096161265], [-0.4250884298327526], [0.1759981549609726], [-0.32848522870518965], [0.7717178952476109], [-0.9939739475839569], [-1.5789599988564216], [-0.33385207321227645], [1.5499103487752017], [0.6804815386271348], [0.004259130734194047], [-0.16747989349258463], [-1.2408487949099511], [0.8253863403184794], [0.5194762034145299], [1.2601007453925128], [1.1098290991940813], [0.1330633989042779], [-0.8007675453288309], [0.9166226969389554], [-0.8115012343430045], [-0.6880638106800073], [-0.47875687490362095], [-1.3964872856154693], [-0.4733900303965341], [-0.8544359903996992], [-0.32848522870518965], [-0.33385207321227645], [-0.5270584754674025], [1.442573458633465], [2.338836491316966], [1.2386333673641654], [0.4872751363720089], [0.84148687383974], [0.3960387797515328], [1.5928451048318963], [-2.4376551199903145], [-0.7846670118075705], [-0.14064567095715044], [0.7717178952476109], [-0.6880638106800073], [0.2779682005956224], [1.152763855250776], [-0.8007675453288309], [-0.37678682926897117], [1.673347772438199], [-0.12991198194297676], [0.7234162946838295], [-0.5377921644815761], [-0.32848522870518965], [-0.12454513743589005], [2.6769476952634363], [-0.2962841616626686], [0.37993824623027217], [-0.7417322557508758], [-0.8383354568784387], [0.16526446594679892], [-1.0744766151902594], [0.809285806797219], [0.3745714017231855], [0.5302098924287036], [0.4121393132727932], [-0.18894727152093196], [-0.11381144842171637], [-0.34995260673353695], [-0.6021942985666181], [-0.7954007008217441], [2.3012685797673584], [-0.11381144842171637], [-0.6826969661729206], [-1.503824175757206], [0.7556173617263505], [0.13843024341136487], [-0.1352788264500636], [-1.1710798163178222], [-1.4662562642075982], [0.6107125600350061], [0.08476179834049649], [0.6804815386271348], [0.7073157611625691], [0.46580775834366156], [0.14916393242553852], [-0.6612295881445733], [-0.11381144842171637], [-1.3213514625162537], [-0.4411889633540131], [0.9810248310239975], [-0.9295718134989149], [-0.6504958991303996], [-1.884870135760371], [0.5033756698932693], [0.24040028904601465], [0.25113397806018833], [-0.08161038137919535], [-0.34458576222645015], [-0.1030777594075427], [0.41750615777988015], [-0.46265634138236045], [-1.337451996037514], [-0.98860710307687], [0.2189329110176673], [-0.15674620447841095], [0.46580775834366156], [-0.027941936308326976], [3.385371170198898], [-0.38215367377605797], [0.4872751363720089], [0.3584708682019248], [0.4121393132727932], [-0.1782135825067583], [1.6304130163815045], [1.3889050135625969], [0.6751146941200481], [0.8522205628539136], [0.256500822567275], [1.2923018124350336], [1.088361721165734], [-1.568226309842248], [0.34773717918775116], [-1.4125878191367298], [0.6429136270775271], [1.4318397696192915], [-0.06550984785793483], [0.836120029332653], [-0.24261571659180034], [-0.9993407920910437], [0.6912152276413085], [1.834353107650804], [-0.31775153969101594], [-1.112044526739867], [-1.4769899532217718], [0.8146526513043056], [-1.0100744811052174], [0.8200194958113926], [-0.011841402787066583], [1.7162825284948933], [2.4247060034303556], [0.4389735358082275], [-0.8168680788500915], [0.14916393242553852], [-0.18358042701384514], [-0.7793001673004835], [-0.7256317222296153], [-1.4018541301225562], [0.8522205628539136], [0.5731446484853984], [0.24040028904601465], [-1.6701963554768977], [-0.4572894968752736], [1.0132258980665185], [-0.6236616765949654], [0.43360669130114055], [0.004259130734194047], [0.8522205628539136], [-0.4894905639177946], [-0.12454513743589005], [-1.568226309842248], [-0.2587162501130609], [0.6375467825704402], [0.10086233186175687], [0.583878337499572], [1.1742312332791234], [-0.892003901949307], [-0.8705365239209597], [0.08476179834049649], [2.4837412930083107], [2.5159423600508313], [0.5892451820066588], [-1.3857535966012955], [-0.36605314025479746], [0.6912152276413085], [1.8236194186366301], [-0.5914606095524444], [-0.07087669236502167], [0.9434569194743897], [1.029326431587779], [-0.38215367377605797], [-0.9456723470201753], [0.3209029566523171], [-1.1496124382894748], [1.3996387025767703], [-0.8544359903996992], [1.217165989335818], [0.16526446594679892], [-1.0100744811052174], [0.031093353269628116], [-0.9349386580060016], [0.12232970989010424], [0.583878337499572], [0.11159602087593055], [0.025726508762541397], [0.3745714017231855], [0.8575874073610004], [-0.7417322557508758], [0.7717178952476109], [-0.12991198194297676], [-0.39825420729731836], [-2.013674403930455], [0.0686612648192361], [-0.3714199847618843], [1.415739236098031], [-0.892003901949307], [-0.06550984785793483], [-0.5860937650453576], [-1.342818840544601], [0.8629542518680873], [2.1187958665264057], [1.6143124828602438], [1.5552771932822884], [0.08476179834049649], [0.3370034901735777], [0.8039189622901319], [-1.0100744811052174], [0.31553611214523036], [-0.31775153969101594], [0.19746553298931996], [-0.6236616765949654], [0.07402810932632281], [-0.9188381244847412], [0.2779682005956224], [-1.1496124382894748], [-1.1335119047682145], [-0.253349405605974], [-0.19968096053510564], [-1.2354819504028642], [1.1312964772224288], [0.18136499946805956], [-1.9707396478737604], [1.6840814614523725], [-0.30165100616975543], [-1.6487289774485503], [-1.31061777350208], [-0.1782135825067583], [-0.6934306551870943], [-0.22651518307053983], [-1.5145578647713795], [-0.5807269205382707], [0.7663510507405242], [0.6107125600350061], [0.6321799380633534], [1.3835381690555102], [1.6465135499027646], [1.1205627882082552], [-0.6129279875807918], [-1.1818135053319958], [-0.1782135825067583], [1.70554883948072], [-0.6773301216658337], [-0.6182948320878786], [0.9219895414460424], [1.217165989335818], [-1.3267183070233404], [-0.9134712799776544], [-0.3392189177193633], [0.49264198087909566], [-0.221148338563453], [0.025726508762541397], [-0.15674620447841095], [-1.154979282796562], [0.9863916755310844], [-0.3875205182831448], [-0.8168680788500915], [0.3101692676381434], [0.1169628653830175], [-1.1764466608249091], [-1.112044526739867], [-0.08697722588628219], [0.551677270457051], [-0.4143547408185789], [-0.8061343898359178], [0.3692045572160985], [-0.21041464954927933], [0.8897884744035214], [0.9488237639814765], [1.9148557752571063], [-0.43582211884692623], [0.3584708682019248], [-0.36068629574771066], [-0.21041464954927933], [2.446173381458703], [-1.0047076365981304], [-1.5467589318139006], [-0.3070178506768423], [1.2493670563783392], [2.24760013469649], [-2.0458754709729763], [0.6643810051058744], [-0.4572894968752736], [-0.07624353687210851], [0.326269801159404], [1.7270162175090673], [1.3030355014492074], [-0.23188202757762666], [0.4228730022869669], [-1.5574926208280744], [0.3209029566523171], [0.1759981549609726], [0.6643810051058744], [1.4855082146901597], [-0.22651518307053983], [0.5087425144003562], [-0.20504780504219247], [1.8719210192004114], [0.37993824623027217], [0.5677778039783113], [0.29943557862396974], [0.9327232304602161], [0.8200194958113926], [-0.04940931433667432], [-0.08697722588628219], [-0.9778734140626963], [-0.2962841616626686], [-0.27481678363432127], [0.9917585200381711], [-1.788266934632808], [-0.6558627436374863], [0.5677778039783113], [-0.698797499694181], [-0.43045527433983943], [-0.2855504726484949], [0.8897884744035214], [0.3048024231310567], [0.4443403803153142], [-0.7041643442012678], [0.24040028904601465], [-1.85266906871785], [-0.07087669236502167], [-0.006474558279979626], [0.04182704228380179], [1.28156812342086], [-0.4411889633540131], [-0.9725065695556095], [-1.0637429261760858], [2.1456300890618403], [0.5731446484853984], [-1.2998840844879063], [-0.18894727152093196], [-0.5485258534957497], [-0.7900338563146572], [-0.5270584754674025], [-1.0100744811052174], [-0.7363654112437888], [-0.27481678363432127], [-2.405454052947794], [1.0185927425736052], [-0.8759033684280465], [1.2976686569421207], [1.4479403031405518], [-1.4769899532217718], [-1.0744766151902594], [0.3638377127090118], [1.3728044800413362], [-0.3231183841981028], [2.6823145397705237], [1.2117991448287313], [-1.0959439932186068], [-0.3392189177193633], [1.4908750591972464], [-0.9617728805414358], [0.40140562425861953], [0.8522205628539136], [-0.9510391915272621], [2.338836491316966], [0.9219895414460424], [-0.6451290546233127], [-0.006474558279979626], [-0.9456723470201753], [0.6912152276413085], [-0.6880638106800073], [0.1759981549609726], [0.9112558524318687], [-1.2998840844879063], [-0.7685664782863098], [-1.407220974629643], [0.4067724687657065], [-0.9295718134989149], [-1.7184979560406792], [-0.5002242529319683], [1.28156812342086], [-1.305250928994993], [-0.1030777594075427], [1.5016087482114204], [0.4389735358082275], [-0.4250884298327526], [0.873687940882261], [-2.4591224980186626], [1.2654675898995995], [-0.8329686123713519], [-0.07087669236502167], [-0.9671397250485226], [-0.19968096053510564], [1.8880215527216722], [-0.03867562532250065], [0.5624109594712247], [-0.2372488720847135], [-2.2927503182989706], [-0.2909173171555818], [-0.253349405605974], [0.3209029566523171], [0.1759981549609726], [-1.4662562642075982], [-0.46802318588944725], [-0.7202648777225283], [0.6429136270775271], [-1.8312016906895026], [-1.0369087036406515], [-0.221148338563453], [0.38530509073735913], [3.1170289448445567], [-0.05477615884376128], [-1.09057714871152], [0.6804815386271348], [-0.98860710307687], [-2.3517856078769253], [-2.0834433825225838], [-0.38215367377605797], [2.1187958665264057], [-1.4501557306863375], [-0.98860710307687], [-0.6021942985666181], [1.9041220862429327], [-0.20504780504219247], [0.2081992220034936], [0.8146526513043056], [-0.44655580786109994], [0.5999788710208324], [1.17959807778621], [-0.31775153969101594], [0.514109358907443], [0.10622917636884384], [0.9595574529956501], [-0.253349405605974], [1.5660108822964625], [0.9273563859531291], [-1.117411371246954], [0.256500822567275], [0.8897884744035214], [0.7878184287688715], [0.1330633989042779], [-0.1352788264500636], [0.8522205628539136], [-0.40898789631149207], [-0.7470991002579626], [0.3745714017231855], [-0.2372488720847135], [-0.40898789631149207], [1.517709281732681], [0.8897884744035214], [0.809285806797219], [-0.7363654112437888], [2.2207659121610557], [0.11159602087593055], [-0.7041643442012678], [-0.7739333227933968], [-1.0100744811052174], [0.6375467825704402], [1.1312964772224288], [-0.9939739475839569], [1.0400601206019526], [-2.4483888090044887], [1.0722611876444739], [-0.3070178506768423], [1.286934967927947], [-0.6397622101162259], [-0.7846670118075705], [0.6912152276413085], [0.19746553298931996], [-0.4143547408185789], [0.5355767369357903], [-1.0100744811052174], [-0.32848522870518965], [-2.1371118275934524], [-0.6826969661729206], [0.6107125600350061], [-0.9188381244847412], [0.15453077693262526], [0.6053457155279194], [-1.3750199075871221], [-0.6504958991303996], [1.5069755927185071], [1.3245028794775549], [-1.4179546636438167], [1.5982119493389833], [0.22966660003184097], [0.4228730022869669], [-0.1030777594075427], [-0.9617728805414358], [0.48190829186492196], [1.1956986113074708], [0.7878184287688715], [-1.6218947549131164], [-0.44655580786109994], [-0.9939739475839569], [-0.7739333227933968], [0.8575874073610004], [2.58571133864296], [-0.8866370574422202], [1.152763855250776], [0.5194762034145299], [-0.33385207321227645], [0.261867667074362], [0.22966660003184097], [-0.8759033684280465], [0.6053457155279194], [-0.5807269205382707], [-0.8383354568784387], [-2.652328900273788], [1.5123424372255938], [-0.2909173171555818], [-0.21578149405636615], [-1.305250928994993], [0.031093353269628116], [-0.1352788264500636], [-0.5431590089886629], [-0.033308780815413934], [-0.8276017678642651], [1.0132258980665185], [1.453307147647639], [0.9756579865169107], [-1.8151011571682423], [0.3370034901735777], [-0.36605314025479746], [-2.6308615222454406], [-0.011841402787066583], [-0.14064567095715044], [-0.43582211884692623], [0.7126826056696558], [0.19209868848223324], [-0.2962841616626686], [0.9702911420098238], [0.7019489166554822], [-0.32848522870518965], [0.13843024341136487], [0.7234162946838295], [-0.39825420729731836], [-0.20504780504219247], [-0.36068629574771066], [2.360303869345313], [0.3960387797515328], [-1.020808170119391], [-0.21041464954927933], [-1.0154413256123043], [-0.23188202757762666], [1.3084023459562941], [-1.568226309842248], [1.0615274986302998], [-0.07087669236502167], [1.034693276094866], [-0.8437023013855255], [2.5481434270933527], [0.1598976214397122], [-2.0190412484375417], [-0.2587162501130609], [-1.7077642670265056], [0.1169628653830175], [-0.5968274540595312], [1.3137691904633808], [0.47654144735783527], [2.124162711033493], [0.8200194958113926], [0.224299755524754], [-1.943905425338326], [-0.8329686123713519], [0.1169628653830175], [-1.3857535966012955], [-0.9671397250485226], [0.33163664566649076], [-0.2962841616626686], [0.9810248310239975], [-0.9510391915272621], [0.261867667074362], [1.3781713245484228], [-0.5163247864532288], [-0.6826969661729206], [-0.7954007008217441], [-1.6111610658989426], [-0.022575091801240257], [-0.022575091801240257], [-0.9832402585697831], [-1.6970305780123318], [0.4550740693294879], [0.6912152276413085], [1.0668943431373867], [-0.7202648777225283], [0.5731446484853984], [-0.4894905639177946], [0.14916393242553852], [1.469407681168899], [1.5713777268035491], [-1.2247482613886906], [1.7806846625799353], [-0.5914606095524444], [0.4389735358082275], [-0.07624353687210851], [-0.3123846951839291], [-0.3231183841981028], [1.244000211871252], [-0.6826969661729206], [1.7753178180728486], [-0.7524659447650494], [-1.3857535966012955], [-0.15137935997132412], [0.3584708682019248], [-0.3714199847618843], [0.14379708791845158], [-0.4894905639177946], [1.2117991448287313], [0.4067724687657065], [-0.08697722588628219], [0.5731446484853984], [-0.2962841616626686], [-0.10844460391462954], [1.9363231532854535], [-0.9725065695556095], [0.43360669130114055], [-0.033308780815413934], [0.8039189622901319], [-0.4197215853256657], [0.10086233186175687], [0.2350334445389277], [0.48190829186492196], [-1.0047076365981304], [1.8450867966649773], [3.2673005910429875], [-0.4733900303965341], [-1.0047076365981304], [0.05256073129797546], [-0.4733900303965341], [-2.1371118275934524], [0.2726013560885357], [0.12232970989010424], [-2.0512423154800628], [-0.6504958991303996], [0.18136499946805956], [1.1581306997578626], [0.05256073129797546], [-0.06550984785793483], [0.08476179834049649], [-0.7793001673004835], [0.37993824623027217], [-0.43045527433983943], [-0.8544359903996992], [-1.1281450602611278], [0.48190829186492196], [-0.4841237194107078], [-0.46265634138236045], [-0.7524659447650494], [0.0901286428475832], [-0.8651696794138729], [-0.15674620447841095], [0.15453077693262526], [0.7985521177830452], [-0.09234407039336902], [-0.3231183841981028], [-0.09234407039336902], [-0.9939739475839569], [-0.7900338563146572], [0.3638377127090118], [-0.7148980332154415], [-1.337451996037514], [1.92558946427128], [2.725249295827218], [-0.9456723470201753], [1.0507938096161265], [-0.08697722588628219], [-1.079843459697346], [-0.27481678363432127], [1.286934967927947], [0.9219895414460424], [0.1759981549609726], [-1.7775332456186346], [-1.305250928994993], [1.3084023459562941], [0.22966660003184097], [0.5033756698932693], [-0.9456723470201753], [0.5892451820066588], [0.8039189622901319], [1.608945638353157], [0.6643810051058744], [-1.369653063080035], [-1.0476423926548253], [-0.4733900303965341], [-0.6021942985666181], [0.49264198087909566], [1.0668943431373867], [0.2726013560885357], [1.5499103487752017], [1.1205627882082552], [0.12232970989010424], [-0.26408309462014756], [-0.2372488720847135], [-0.8222349233571782], [2.2529669792035767], [0.836120029332653], [-0.12454513743589005], [-1.0369087036406515], [0.6214462490491798], [-0.4411889633540131], [-1.4769899532217718], [-0.7417322557508758], [-0.8651696794138729], [-0.08161038137919535], [0.9434569194743897], [-0.3714199847618843], [-0.27481678363432127], [0.583878337499572], [0.05792757580506242], [-1.246215639417038], [-0.3928873627902317], [0.0901286428475832], [2.1939316896256216], [-0.9725065695556095], [1.3459702575059023], [1.9631573758208876], [0.3370034901735777], [0.583878337499572], [-0.14064567095715044], [-0.43582211884692623], [-0.10844460391462954], [0.6858483831342218], [0.28333504510270935], [-0.5699932315240971], [-0.221148338563453], [-1.1818135053319958], [0.5409435814428772], [-0.5163247864532288], [-1.3857535966012955], [-0.16747989349258463], [-0.7900338563146572], [0.18136499946805956], [0.44970722482240116], [-0.017208247294153302], [-0.04940931433667432], [1.984624753849235], [1.2064323003216446], [0.1759981549609726], [-1.1925471943461696], [-0.8866370574422202], [-0.5860937650453576], [-0.9456723470201753], [-0.8383354568784387], [-0.6236616765949654], [1.5391766597610284], [0.5570441149641376], [-0.510957941946142], [-0.4197215853256657], [-0.18894727152093196], [-0.5914606095524444], [0.6429136270775271], [-0.2962841616626686], [-0.04404246982958761], [1.6465135499027646], [0.7341499836980032], [-0.8651696794138729], [-1.0959439932186068], [-1.337451996037514], [-0.5753600760311839], [-0.09771091490045586], [-0.8544359903996992], [-0.9403055025130886], [-0.7202648777225283], [-1.122778215754041], [0.4067724687657065], [-0.23188202757762666], [-1.3481856850516878], [2.408605469909095], [0.7824515842617846], [2.1563637780760136], [-0.06550984785793483], [-0.4894905639177946], [1.608945638353157], [1.0454269651090393], [0.9863916755310844], [-1.0047076365981304], [-1.3267183070233404], [-1.1496124382894748], [-0.4894905639177946], [-0.8866370574422202], [1.227899678349992], [1.2332665228570787], [0.6912152276413085], [-0.8866370574422202], [-0.24261571659180034], [-1.4501557306863375], [-0.21578149405636615], [0.9649242975027371], [-0.2909173171555818], [-0.2479825610988872], [3.1975316124508595], [-0.4036210518044052], [-0.15137935997132412], [1.6465135499027646], [-0.5914606095524444], [0.09549548735467016], [0.873687940882261], [0.37993824623027217], [-0.006474558279979626], [-0.9993407920910437], [0.3960387797515328], [-1.5521257763209875], [0.9917585200381711], [0.3745714017231855], [-0.26408309462014756], [-0.12991198194297676], [-0.7739333227933968], [-0.17284673799967146], [-0.9242049689918279], [0.6268130935562665], [1.2923018124350336], [-0.3875205182831448], [-0.12991198194297676], [0.07939495383340953], [-0.8276017678642651], [-0.5538926980028366], [1.3298697239846415], [2.1724643115972744], [0.4121393132727932], [-0.27481678363432127], [0.6160794045420928], [-0.6773301216658337], [-0.3928873627902317], [0.9327232304602161], [1.6304130163815045], [0.578511492992485], [0.8522205628539136], [-0.8329686123713519], [0.6375467825704402], [-0.253349405605974], [-0.221148338563453], [0.8790547853893477], [-0.5324253199744892], [1.796785196101196], [0.4389735358082275], [-0.5807269205382707], [0.06329442031214914], [-0.2479825610988872], [-0.4036210518044052], [-0.24261571659180034], [0.8951553189106081], [1.5391766597610284], [-0.18894727152093196], [0.15453077693262526], [2.7896514299122597], [0.6643810051058744], [-0.9403055025130886], [1.7645841290586752], [-2.0458754709729763], [0.3531040236948381], [1.834353107650804], [-1.8097343126611554], [-0.8276017678642651], [-1.4662562642075982], [0.009625975241280766], [-0.7041643442012678], [0.40140562425861953], [0.8253863403184794], [-0.5270584754674025], [0.04719388679088875], [-1.3213514625162537], [0.29943557862396974], [-1.2676830174453853], [-0.08697722588628219], [-0.8973707464563939], [-1.1925471943461696], [0.3906719352444459], [0.6160794045420928], [-0.6236616765949654], [1.093728565672821], [-0.9188381244847412], [-1.342818840544601], [0.04719388679088875], [-1.2247482613886906], [-0.9617728805414358], [0.18673184397514628], [0.7287831391909165], [0.2189329110176673], [-0.017208247294153302], [1.2708344344066866], [0.24576713355310137], [-1.2301151058957775], [1.023959587080692], [1.5767445713106358], [-0.1782135825067583], [-1.219381416881604], [0.10086233186175687], [-0.5753600760311839], [0.8307531848255663], [0.08476179834049649], [-0.07087669236502167], [1.28156812342086], [0.3584708682019248], [0.49264198087909566], [-0.09234407039336902], [-0.6451290546233127], [0.546310425949964], [-1.0369087036406515], [0.6965820721483954], [0.42823984679405386], [1.3137691904633808], [1.8182525741295434], [-0.2962841616626686], [0.9863916755310844], [-1.144245593782388], [-0.2694499391272344], [-0.7578327892721363], [-1.1710798163178222], [-0.3553194512406238], [-2.0244080929446286], [-1.4984573312501193], [0.08476179834049649], [0.5570441149641376], [-1.3964872856154693], [-0.7685664782863098], [0.11159602087593055], [-0.7900338563146572], [-0.5592595425099234], [0.3101692676381434], [0.6804815386271348], [-0.1030777594075427], [-0.1191782929288032], [0.10086233186175687], [-0.033308780815413934], [-0.5646263870170102], [0.3370034901735777], [-0.221148338563453], [-0.04404246982958761], [-0.6182948320878786], [-0.11381144842171637], [-1.5896936878705954], [-0.1352788264500636], [1.3137691904633808], [-1.7399653340690264], [0.37993824623027217], [0.7019489166554822], [0.7770847397546979], [0.294068734116883], [1.8826547082145855], [0.3584708682019248], [0.14379708791845158], [0.6643810051058744], [0.009625975241280766], [0.5194762034145299], [0.2081992220034936], [2.1456300890618403], [-0.3392189177193633], [0.14916393242553852], [-0.16211304898549778], [-0.66659643265166], [-1.0261750146264779], [-0.3928873627902317], [0.3101692676381434], [-0.45192265236818674], [0.3209029566523171], [-0.9725065695556095], [-0.2855504726484949], [0.5302098924287036], [-0.15674620447841095], [-1.6487289774485503], [-1.1066776822327804], [0.014992819748367723], [1.3674376355342495], [0.44970722482240116], [-1.0637429261760858], [-0.8329686123713519], [-0.5538926980028366], [-0.033308780815413934], [-1.0744766151902594], [0.5087425144003562], [1.0829948766586472], [-0.017208247294153302], [-0.2962841616626686], [1.286934967927947], [-0.3928873627902317], [2.0114589763846693], [0.15453077693262526], [-1.2945172399808194], [-0.47875687490362095], [-0.27481678363432127], [-1.0583760816689989], [-0.9403055025130886], [-0.8329686123713519], [0.3048024231310567], [-0.16747989349258463], [0.6268130935562665], [0.2081992220034936], [-0.6934306551870943], [-0.5914606095524444], [-0.26408309462014756], [0.3423703346806644], [1.7806846625799353], [0.9166226969389554], [0.1759981549609726], [-1.1603461273036486], [-0.3714199847618843], [1.1688643887720367], [-2.1961471171714075], [3.723482374145369], [0.3370034901735777], [-0.017208247294153302], [0.2189329110176673], [-0.634395365609139], [-0.4894905639177946], [-0.2479825610988872], [-0.634395365609139], [0.036460197776715074], [0.3531040236948381], [0.3531040236948381], [0.13843024341136487], [0.3692045572160985], [0.7985521177830452], [3.165330545408338], [0.256500822567275], [0.04719388679088875], [-0.8437023013855255], [-0.510957941946142], [-0.8866370574422202], [-0.36068629574771066], [-0.7524659447650494], [1.834353107650804], [0.7985521177830452], [-0.7900338563146572], [1.1849649222932972], [-1.981473336887934], [-0.5431590089886629], [-1.3267183070233404], [-0.09234407039336902], [0.8307531848255663], [0.6590141605987875], [1.9577905313138009], [0.5302098924287036], [-0.7793001673004835], [-1.305250928994993], [2.730616140334305], [0.34773717918775116], [0.10622917636884384], [0.7609842062334372], [1.8128857296224568], [0.8468537183468267], [-1.0100744811052174], [0.26723451158144873], [-0.9349386580060016], [1.9363231532854535], [-1.0637429261760858], [-1.0476423926548253], [-0.7631996337792231], [-0.8168680788500915], [0.9434569194743897], [0.3209029566523171], [-0.8061343898359178], [3.3156021916067693], [-0.6236616765949654], [-0.5377921644815761], [-0.31775153969101594], [-0.09771091490045586], [0.29943557862396974], [1.4586739921547256], [1.2386333673641654], [-1.4340551971650772], [-0.11381144842171637], [0.6643810051058744], [0.7287831391909165], [-1.5467589318139006], [-0.2855504726484949], [0.5194762034145299], [1.4855082146901597], [-0.3123846951839291], [3.524909127383156], [0.6482804715846138], [0.1169628653830175], [0.37993824623027217], [0.8790547853893477], [1.8719210192004114], [0.6214462490491798], [-0.23188202757762666], [0.3638377127090118], [0.04182704228380179], [0.261867667074362], [0.40140562425861953], [0.3692045572160985], [-0.15137935997132412], [1.0132258980665185], [-0.2372488720847135], [0.10086233186175687], [0.8307531848255663], [-0.6451290546233127], [0.3101692676381434], [-0.12454513743589005], [1.034693276094866], [-1.1603461273036486], [-1.283783550966646], [0.224299755524754], [-0.43045527433983943], [-0.2587162501130609], [0.25113397806018833], [0.578511492992485], [0.6482804715846138], [1.1044622546869947], [-2.6952636563304826], [-0.5002242529319683], [0.6107125600350061], [-1.0100744811052174], [-1.1066776822327804], [0.9649242975027371], [1.1849649222932972], [-0.04940931433667432], [0.46580775834366156], [0.33163664566649076], [-0.26408309462014756], [-0.060143003350848], [0.05256073129797546], [-0.8973707464563939], [0.11159602087593055], [0.8200194958113926], [0.9327232304602161], [-1.6487289774485503], [0.6858483831342218], [-0.9778734140626963], [-2.222981339706841], [0.8790547853893477], [0.5194762034145299], [0.294068734116883], [0.7609842062334372], [0.014992819748367723], [-0.6451290546233127], [0.48190829186492196], [-1.079843459697346], [0.3906719352444459], [0.2726013560885357], [-0.8866370574422202], [-0.3928873627902317], [1.3996387025767703], [0.009625975241280766], [2.929189387096518], [-0.2694499391272344], [-0.006474558279979626], [-0.18358042701384514], [-0.06550984785793483], [1.9041220862429327], [-0.4197215853256657], [-1.7399653340690264], [0.8146526513043056], [1.4962419037043335], [-1.7775332456186346], [-0.49485740842488146], [-0.7739333227933968], [0.48190829186492196], [-0.6182948320878786], [-0.5002242529319683], [1.6465135499027646], [-1.085210304204433], [-0.46265634138236045], [-0.9617728805414358], [-2.1585792056217996], [1.4962419037043335], [0.8522205628539136], [0.9810248310239975], [0.014992819748367723], [-1.4233215081509034], [0.5355767369357903], [-0.04940931433667432], [-0.22651518307053983], [-1.2408487949099511], [0.47654144735783527], [-0.3928873627902317], [0.2028323774964069], [1.5982119493389833], [-0.4733900303965341], [-0.04404246982958761], [0.546310425949964], [2.0919616439909716], [-0.2909173171555818], [-1.85266906871785], [2.945289920617778], [0.15453077693262526], [-0.6773301216658337], [0.036460197776715074], [-0.7685664782863098], [-0.9403055025130886], [-0.7256317222296153], [0.4389735358082275], [-0.5163247864532288], [-0.09234407039336902], [0.6643810051058744], [0.0901286428475832], [-0.5002242529319683], [-0.08161038137919535], [-0.5968274540595312], [-0.15674620447841095], [0.6107125600350061], [1.6518803944098517], [0.05792757580506242], [-0.5431590089886629], [-0.5270584754674025], [0.37993824623027217], [-1.981473336887934], [0.7019489166554822], [-0.38215367377605797], [-2.142478672100539], [-0.892003901949307], [-0.698797499694181], [-0.39825420729731836], [1.3889050135625969], [-0.6934306551870943], [-0.9242049689918279], [-0.20504780504219247], [-1.1603461273036486], [0.256500822567275], [-1.9761064923808473], [-0.3928873627902317], [-0.9725065695556095], [1.0776280321515606], [-1.0691097706831725], [-1.5091910202642929], [-0.6075611430737049], [-1.42868835265799], [0.22966660003184097], [0.4550740693294879], [-0.34995260673353695], [-0.6719632771587469], [1.469407681168899], [-1.0476423926548253], [-0.19968096053510564], [0.08476179834049649], [0.6214462490491798], [1.0078590535594318], [0.1330633989042779], [0.3048024231310567], [-0.022575091801240257], [0.48190829186492196], [-0.8812702129351334], [0.21356606651058035], [0.4389735358082275], [-0.9725065695556095], [0.09549548735467016], [-0.8705365239209597], [0.261867667074362], [-0.6719632771587469], [-0.4841237194107078], [-1.1603461273036486], [1.3728044800413362], [-0.006474558279979626], [-0.5431590089886629], [1.2762012789137733], [-1.4018541301225562], [1.286934967927947], [1.3084023459562941], [-0.21041464954927933], [-0.011841402787066583], [0.13843024341136487], [-1.4877236422359454], [0.2081992220034936], [0.7770847397546979], [-0.9027375909634807], [0.4711746028507485], [-0.9832402585697831], [0.014992819748367723], [0.5624109594712247], [1.034693276094866], [-0.07087669236502167], [0.5355767369357903], [-0.9725065695556095], [0.5194762034145299], [-0.12454513743589005], [1.984624753849235], [-0.40898789631149207], [-0.28018362814140807], [-0.859802834906786], [0.28870188960979604], [0.9595574529956501], [-0.11381144842171637], [2.1939316896256216], [0.2081992220034936], [0.9541906084885634], [0.6107125600350061], [-0.43045527433983943], [-1.09057714871152], [-0.0011077137728929085], [-1.079843459697346], [-0.5968274540595312], [1.1151959437011685], [-0.23188202757762666], [2.0114589763846693], [0.294068734116883], [-1.079843459697346], [0.326269801159404], [0.14379708791845158], [1.544543504268115], [-0.0011077137728929085], [1.2117991448287313], [2.473007603994137], [0.3048024231310567], [-0.9564060360343489], [-1.2569493284312117], [0.2726013560885357], [-0.7363654112437888], [0.294068734116883], [3.3478032586492903], [0.583878337499572], [-0.9671397250485226], [0.8468537183468267], [0.5409435814428772], [0.06329442031214914], [-0.730998566736702], [-0.6773301216658337], [0.4980088253861826], [0.8253863403184794], [-0.6504958991303996], [0.7717178952476109], [1.5552771932822884], [-1.664829510969811], [0.546310425949964], [0.6858483831342218], [-0.7578327892721363], [0.5570441149641376], [-0.12454513743589005], [-1.8312016906895026], [0.9541906084885634], [2.8540535639973017], [-0.1782135825067583], [0.8522205628539136], [-1.053009237161912], [0.38530509073735913], [0.5892451820066588], [0.8253863403184794], [-0.17284673799967146], [1.286934967927947], [-0.44655580786109994], [0.33163664566649076], [-0.9939739475839569], [-0.6075611430737049], [-0.09234407039336902], [-1.3213514625162537], [-0.5216916309603157], [-0.0011077137728929085], [-0.07087669236502167], [0.4443403803153142], [-0.253349405605974], [-1.5521257763209875], [0.6590141605987875], [0.546310425949964], [-1.0047076365981304], [-0.32848522870518965], [1.1742312332791234], [-0.18358042701384514], [1.60357879384607], [-0.3714199847618843], [-0.49485740842488146], [-0.09234407039336902], [0.9649242975027371], [0.1169628653830175], [0.5302098924287036], [-0.15137935997132412], [0.9595574529956501], [-0.31775153969101594], [-0.4036210518044052], [-0.34995260673353695], [-1.7936337791398949], [0.31553611214523036], [-0.6934306551870943], [0.22966660003184097], [1.034693276094866], [0.546310425949964], [-1.1335119047682145], [0.6160794045420928], [0.3370034901735777], [-1.3911204411083824], [-0.221148338563453], [-1.0476423926548253], [-0.510957941946142], [-0.9295718134989149], [-0.017208247294153302], [0.546310425949964], [-0.698797499694181], [0.2189329110176673], [0.546310425949964], [0.7395168282050901], [0.1276965543971912], [-0.4733900303965341], [-0.1352788264500636], [-0.12454513743589005], [-1.0261750146264779], [-0.36068629574771066], [-2.7703994794296984], [0.873687940882261], [-1.3857535966012955], [-0.03867562532250065], [0.7770847397546979], [1.244000211871252], [-0.11381144842171637], [-0.011841402787066583], [-0.060143003350848], [-1.1657129718107355], [-0.221148338563453], [2.1992985341327085], [0.84148687383974], [-0.6773301216658337], [-1.1657129718107355], [-1.6057942213918557], [-1.0637429261760858], [-0.6075611430737049], [0.10086233186175687], [0.8844216298964344], [1.034693276094866], [-0.9939739475839569], [0.2726013560885357], [0.6375467825704402], [1.1956986113074708], [0.0686612648192361], [2.032926354413017], [-0.7739333227933968], [-0.06550984785793483], [0.2350334445389277], [-0.5699932315240971], [-0.7256317222296153], [3.4605069932981145], [0.6536473160917008], [-0.04940931433667432], [-0.8168680788500915], [0.4228730022869669], [0.44970722482240116], [-2.8348016135147405], [-0.1191782929288032], [-0.7739333227933968], [-0.8329686123713519], [0.2726013560885357], [-0.14064567095715044], [0.15453077693262526], [0.9810248310239975], [1.351337102012989], [0.37993824623027217], [0.5033756698932693], [-0.45192265236818674], [-0.8490691458926124], [1.9577905313138009], [-0.3123846951839291], [-0.33385207321227645], [1.002492209052345], [2.7789177408980863], [1.415739236098031], [-0.49485740842488146], [1.1259296327153419], [2.0919616439909716], [1.1205627882082552], [-0.14064567095715044], [-1.729231645054853], [0.261867667074362], [0.16526446594679892], [0.004259130734194047], [1.4962419037043335], [-0.36068629574771066], [0.9166226969389554], [0.6804815386271348], [-0.34995260673353695], [-0.5914606095524444], [-0.634395365609139], [0.5570441149641376], [1.1044622546869947], [0.8200194958113926], [-0.2587162501130609], [-0.006474558279979626], [0.4389735358082275], [-0.060143003350848], [-1.4662562642075982], [0.5624109594712247], [0.5731446484853984], [-0.7470991002579626], [-0.3392189177193633], [-1.2623161729382986], [-0.5324253199744892], [0.1169628653830175], [-0.8544359903996992], [-0.08161038137919535], [-1.278416706459559], [-0.3553194512406238], [1.088361721165734], [1.1044622546869947], [0.5194762034145299], [0.7448836727121769], [-1.273049861952472], [-1.305250928994993], [1.28156812342086], [0.9810248310239975], [-0.6397622101162259], [-2.0673428490013235], [2.6823145397705237], [1.029326431587779], [1.5230761262397676], [-0.46802318588944725], [1.7162825284948933], [0.9219895414460424], [0.7019489166554822], [3.8522866423154523], [-1.3535525295587747], [0.1598976214397122], [-0.2962841616626686], [0.6268130935562665], [0.900522163417695], [-1.2945172399808194], [-0.027941936308326976], [0.6751146941200481], [2.403238625402008], [0.583878337499572], [-0.033308780815413934], [-0.5270584754674025], [0.7878184287688715], [0.6590141605987875], [2.403238625402008], [0.8253863403184794], [-1.8473022242107633], [0.546310425949964], [-1.3857535966012955], [0.4443403803153142], [0.21356606651058035], [-0.34458576222645015], [-1.568226309842248], [-0.7470991002579626], [-0.8383354568784387], [0.1598976214397122], [-0.698797499694181], [1.3137691904633808], [-1.0476423926548253], [-0.16211304898549778], [0.9649242975027371], [0.578511492992485], [-2.013674403930455], [-0.8115012343430045], [0.025726508762541397], [0.33163664566649076], [1.7914183515941093], [-0.5377921644815761], [-0.0011077137728929085], [0.18673184397514628], [0.0901286428475832], [2.68768138427761], [-0.5699932315240971], [-1.1657129718107355], [0.0901286428475832], [-0.8061343898359178], [-1.2891503954737327], [0.08476179834049649], [-0.22651518307053983], [-0.36605314025479746], [-0.8222349233571782], [2.376404402866574], [0.21356606651058035], [0.6160794045420928], [0.15453077693262526], [-1.4662562642075982], [0.025726508762541397], [0.7556173617263505], [-1.3911204411083824], [0.7717178952476109], [0.1169628653830175], [1.3459702575059023], [0.05256073129797546], [1.244000211871252], [0.3692045572160985], [1.0776280321515606], [-0.7041643442012678], [0.3692045572160985], [0.7878184287688715], [0.40140562425861953], [1.2762012789137733], [-0.5270584754674025], [0.22966660003184097], [1.3459702575059023], [-0.6290285211020523], [-1.2945172399808194], [0.3370034901735777], [1.17959807778621], [0.6858483831342218], [1.6518803944098517], [0.025726508762541397], [0.19746553298931996], [-0.30165100616975543], [-0.21041464954927933], [-1.3213514625162537], [-0.11381144842171637], [0.48190829186492196], [-1.7238648005477661], [-0.8115012343430045], [-0.4143547408185789], [2.8808877865327362], [0.583878337499572], [0.868321096375174], [-0.221148338563453], [-0.18894727152093196], [0.9917585200381711], [-0.5860937650453576], [-0.3553194512406238], [0.551677270457051], [1.769950973565762], [1.5499103487752017], [0.551677270457051], [-0.6236616765949654], [-1.246215639417038], [0.6643810051058744], [0.9488237639814765], [-0.45192265236818674], [1.1688643887720367], [-1.8312016906895026], [-1.8419353797036766], [-1.0637429261760858], [-0.16211304898549778], [-1.6970305780123318], [-0.6129279875807918], [-0.9349386580060016], [0.9380900749673028], [-0.5699932315240971], [1.190331766800384], [-1.2569493284312117], [2.537409738079179], [0.6375467825704402], [1.7806846625799353], [-0.33385207321227645], [-2.6630625892879616], [0.41750615777988015], [1.7860515070870226], [0.3692045572160985], [0.5999788710208324], [1.0615274986302998], [-1.5896936878705954], [-0.43582211884692623], [0.7717178952476109], [-0.44655580786109994], [-0.8115012343430045], [-0.9403055025130886], [1.7377499065232407], [0.7287831391909165], [-0.36068629574771066], [0.3906719352444459], [-0.18894727152093196], [-0.1782135825067583], [-0.5538926980028366], [1.544543504268115], [-0.8061343898359178], [0.8951553189106081], [-1.5091910202642929], [0.5677778039783113], [1.3674376355342495], [-0.8007675453288309], [-0.5270584754674025], [-0.5968274540595312], [0.43360669130114055], [0.7931852732759583], [-1.9331717363241527], [-0.5699932315240971], [0.3048024231310567], [0.868321096375174], [0.3370034901735777], [0.3209029566523171], [-1.251582483924125], [-0.11381144842171637], [0.11159602087593055], [-1.4447888861792508], [0.14916393242553852], [-0.9832402585697831], [-0.40898789631149207], [-1.7936337791398949], [-1.3589193740658614], [0.8951553189106081], [0.3370034901735777], [-2.1263781385792786], [0.3423703346806644], [1.560644037789375], [-0.7846670118075705], [-0.04404246982958761], [1.244000211871252], [-0.45192265236818674], [-1.2247482613886906], [-0.022575091801240257], [-0.4572894968752736], [0.3370034901735777], [-1.7399653340690264], [-0.6558627436374863], [0.8575874073610004], [1.9631573758208876], [1.4372066141263782], [1.5069755927185071], [-0.5002242529319683], [0.7931852732759583], [1.7645841290586752], [1.1688643887720367], [-0.39825420729731836], [-0.7417322557508758], [3.8683871758367134], [-1.4877236422359454], [0.14379708791845158], [0.8146526513043056], [-0.06550984785793483], [-0.9134712799776544], [-0.17284673799967146], [0.24576713355310137], [-0.6880638106800073], [0.809285806797219], [-0.7041643442012678], [-0.8866370574422202], [1.6357798608885912], [-0.07087669236502167], [0.3745714017231855], [1.3191360349704682], [-0.6451290546233127], [0.031093353269628116], [-0.2694499391272344], [0.014992819748367723], [0.7878184287688715], [-0.18358042701384514], [-0.6934306551870943], [-0.6504958991303996], [1.0776280321515606], [-0.6504958991303996], [-0.022575091801240257], [-0.8168680788500915], [0.07939495383340953], [-0.19431411602801882], [1.16349754426495], [1.0829948766586472], [-0.7793001673004835], [-0.5646263870170102], [2.408605469909095], [-0.730998566736702], [1.3835381690555102], [-1.6970305780123318], [-0.38215367377605797], [0.28333504510270935], [-0.07087669236502167], [-0.510957941946142], [0.12232970989010424], [0.7556173617263505], [-0.5485258534957497], [0.4550740693294879], [-0.05477615884376128], [-0.46265634138236045], [-2.4161877419619677], [-0.6075611430737049], [1.3567039465200756], [1.2117991448287313], [0.6375467825704402], [0.261867667074362], [3.428305926255593], [-0.17284673799967146], [0.13843024341136487], [3.186797923436686], [-0.33385207321227645], [0.10086233186175687], [0.294068734116883], [1.217165989335818], [0.3745714017231855], [-1.4125878191367298], [1.0185927425736052], [0.7878184287688715], [-0.16211304898549778], [-1.112044526739867], [-0.022575091801240257], [-0.859802834906786], [-0.6773301216658337], [0.34773717918775116], [-0.7363654112437888], [0.0901286428475832], [-0.033308780815413934], [0.0901286428475832], [0.07939495383340953], [-0.9027375909634807], [0.18673184397514628], [0.2350334445389277], [-2.5342583211178775], [-0.07624353687210851], [3.256566902028814], [-0.7846670118075705], [1.6840814614523725], [0.3423703346806644], [-0.31775153969101594], [-0.49485740842488146], [-1.890236980267458], [0.5302098924287036], [1.28156812342086], [-1.112044526739867], [-0.10844460391462954], [-1.283783550966646], [-0.7256317222296153], [1.2117991448287313], [1.0776280321515606], [1.3674376355342495], [-1.5896936878705954], [-1.0637429261760858], [-0.5914606095524444], [-0.8007675453288309], [1.2117991448287313], [1.9524236868067142], [0.3423703346806644], [-0.6612295881445733], [0.7073157611625691], [2.1617306225831006], [0.43360669130114055], [-0.9188381244847412], [-0.5699932315240971], [0.10086233186175687], [-0.38215367377605797], [-2.759665790415524], [-0.5968274540595312], [-0.05477615884376128], [1.0561606541232131], [-0.15674620447841095], [0.3906719352444459], [0.19209868848223324], [0.583878337499572], [-0.221148338563453], [1.6840814614523725], [0.10086233186175687], [1.3298697239846415], [0.3960387797515328], [-0.18894727152093196], [1.415739236098031], [-0.9403055025130886], [-0.8437023013855255], [0.036460197776715074], [-0.8383354568784387], [-0.006474558279979626], [-0.8812702129351334], [-0.36068629574771066], [-0.8115012343430045], [-1.3642862185729483], [-1.5413920873068137], [-0.4411889633540131], [-0.46802318588944725], [-0.221148338563453], [-0.060143003350848], [-0.698797499694181], [0.29943557862396974], [-0.7793001673004835], [-0.2694499391272344], [-2.099543916043844], [-0.36605314025479746], [-2.1102776050580183], [-0.11381144842171637], [-0.033308780815413934], [0.6590141605987875], [0.25113397806018833], [0.07402810932632281], [-0.4894905639177946], [-0.011841402787066583], [1.6143124828602438], [0.06329442031214914], [0.3048024231310567], [0.8897884744035214], [-0.15674620447841095], [-0.23188202757762666], [1.0454269651090393], [-0.6612295881445733], [0.261867667074362], [0.6160794045420928], [0.6643810051058744], [-1.4877236422359454], [0.9327232304602161], [1.9792579093421483], [-0.6880638106800073], [0.37993824623027217], [-1.6487289774485503], [0.326269801159404], [1.152763855250776], [-0.16211304898549778], [-1.9331717363241527], [-0.006474558279979626], [0.2081992220034936], [-0.027941936308326976], [0.33163664566649076], [0.6482804715846138], [-0.033308780815413934], [0.3423703346806644], [-2.49669040956827], [-0.2587162501130609], [-0.9564060360343489], [-1.4340551971650772], [0.21356606651058035], [-0.2855504726484949], [-0.37678682926897117], [1.5391766597610284], [-0.8973707464563939], [-0.8329686123713519], [2.3495701803311397], [0.13843024341136487], [-0.8115012343430045], [0.1276965543971912], [-0.8759033684280465], [-0.36605314025479746], [-1.6862968889981584], [0.06329442031214914], [-0.5753600760311839], [0.14916393242553852], [0.08476179834049649], [-0.5055910974390552], [-0.46265634138236045], [-0.4572894968752736], [2.0007252873704955], [-0.49485740842488146], [0.5999788710208324], [1.3352365684917282], [0.49264198087909566], [-0.5055910974390552], [0.6804815386271348], [-0.6021942985666181], [1.1742312332791234], [-0.6182948320878786], [0.08476179834049649], [1.5284429707468543], [0.29943557862396974], [1.136663321729516], [0.3745714017231855], [0.900522163417695], [-2.222981339706841], [-0.7470991002579626], [-1.8043674681540685], [-0.221148338563453], [0.12232970989010424], [0.9810248310239975], [0.2726013560885357], [2.0812279549767982], [-0.2909173171555818], [0.9917585200381711], [-0.3392189177193633], [1.152763855250776], [-0.7524659447650494], [-1.4340551971650772], [-0.7041643442012678], [1.9148557752571063], [-0.6397622101162259], [0.04719388679088875], [1.227899678349992], [1.7001819949736332], [0.3209029566523171], [-1.0744766151902594], [-0.9027375909634807], [-0.6129279875807918], [-1.31061777350208], [-0.27481678363432127], [1.7860515070870226], [-0.6290285211020523], [0.0686612648192361], [1.92558946427128], [0.9058890079247818], [-0.5485258534957497], [0.13843024341136487], [2.204665378639795], [1.16349754426495], [0.7717178952476109], [0.04719388679088875], [0.326269801159404], [0.3048024231310567], [-0.5914606095524444], [-0.5216916309603157], [-0.9510391915272621], [0.551677270457051], [-1.3857535966012955], [0.06329442031214914], [-1.4769899532217718], [0.7395168282050901], [-2.099543916043844], [1.6894483059594592], [0.551677270457051], [0.5302098924287036], [-0.6236616765949654], [2.703781917798871], [0.7448836727121769], [-0.18358042701384514], [0.6858483831342218], [-0.1030777594075427], [-0.19431411602801882], [0.6321799380633534], [0.22966660003184097], [-0.08697722588628219], [-2.469856187032836], [2.338836491316966], [-2.3142176963273178], [1.17959807778621], [0.24040028904601465], [-0.5860937650453576], [0.18673184397514628], [-0.21041464954927933], [-1.8741364467461974], [-1.917071202802892], [-1.1925471943461696], [0.9810248310239975], [-0.09771091490045586], [-0.4572894968752736], [0.294068734116883], [-0.9617728805414358], [0.17063131045388588], [-0.2587162501130609], [-0.9617728805414358], [-0.34458576222645015], [-1.2945172399808194], [-0.4894905639177946], [-1.0691097706831725], [-0.9778734140626963], [-0.6719632771587469], [-0.08161038137919535], [-0.6236616765949654], [-0.9617728805414358], [-2.1317449830863655], [1.8558204856791514], [-0.06550984785793483], [0.3692045572160985], [0.031093353269628116], [-0.6451290546233127], [0.9863916755310844], [1.0078590535594318], [-0.033308780815413934], [0.3960387797515328], [-0.7846670118075705], [0.14379708791845158], [0.6751146941200481], [-0.18894727152093196], [-1.6433621329414636], [0.21356606651058035], [-0.634395365609139], [0.2779682005956224], [1.8021520406082827], [0.7073157611625691], [-1.246215639417038], [-0.46802318588944725], [0.2189329110176673], [-1.117411371246954], [-1.2140145723745168], [-0.49485740842488146], [-1.407220974629643], [-1.154979282796562], [0.7019489166554822], [0.21356606651058035], [1.2762012789137733], [-1.2569493284312117], [3.1921647679437726], [-0.4036210518044052], [0.3048024231310567], [-0.4036210518044052], [-0.7900338563146572], [-0.66659643265166], [0.009625975241280766], [-0.11381144842171637], [-0.44655580786109994], [1.1473970107436893], [-1.1657129718107355], [0.14916393242553852], [-1.407220974629643], [-2.1371118275934524], [1.4586739921547256], [-0.16211304898549778], [1.4050055470838574], [0.2189329110176673], [0.256500822567275], [0.7985521177830452], [-0.07087669236502167], [0.5677778039783113], [3.2834011245642487], [1.4855082146901597], [-2.5127909430895308], [0.10086233186175687], [0.4980088253861826], [-0.2909173171555818], [0.036460197776715074], [-0.7631996337792231], [0.5731446484853984], [-0.017208247294153302], [0.2779682005956224], [-0.5002242529319683], [0.583878337499572], [0.3745714017231855], [-0.46802318588944725], [1.1473970107436893], [0.05792757580506242], [1.5123424372255938], [-0.8759033684280465], [0.1598976214397122], [1.28156812342086], [-0.43582211884692623], [-0.37678682926897117], [-0.4143547408185789], [0.09549548735467016], [-0.8973707464563939], [2.68768138427761], [-1.6970305780123318], [0.10086233186175687], [0.40140562425861953], [0.46580775834366156], [-0.8329686123713519], [-0.45192265236818674], [-0.027941936308326976], [0.9112558524318687], [2.9989583656886465], [0.7985521177830452], [-0.221148338563453], [2.6071787166713074], [-0.6558627436374863], [-1.3535525295587747], [0.3370034901735777], [0.6643810051058744], [-0.5860937650453576], [2.3066354242744453], [-1.3481856850516878], [-0.4841237194107078], [-0.43045527433983943], [0.6965820721483954], [0.4228730022869669], [0.6053457155279194], [2.628646094699655], [0.6321799380633534], [2.3281028023027925], [-1.4608894197005111], [-0.6129279875807918], [1.608945638353157], [-0.3392189177193633], [-0.6558627436374863], [-0.16211304898549778], [-0.9725065695556095], [0.5033756698932693], [-0.3553194512406238], [1.7109156839878066], [-0.8222349233571782], [0.6536473160917008], [-0.730998566736702], [-0.7578327892721363], [-1.020808170119391], [0.4711746028507485], [-0.9939739475839569], [0.33163664566649076], [-0.38215367377605797], [0.2726013560885357], [-0.9510391915272621], [1.1205627882082552], [1.2547339008854261], [0.19209868848223324], [2.2261327566681426], [-0.7363654112437888], [0.6482804715846138], [-0.5807269205382707], [0.0686612648192361], [0.3423703346806644], [-0.16747989349258463], [-0.7256317222296153], [-0.4733900303965341], [-0.9832402585697831], [-0.5485258534957497], [0.261867667074362], [-0.19431411602801882], [0.1598976214397122], [0.24040028904601465], [-0.6075611430737049], [0.514109358907443], [-1.6433621329414636], [2.086594799483885], [2.574977649628787], [-0.6290285211020523], [-0.5807269205382707], [0.04182704228380179], [1.4050055470838574], [2.2261327566681426], [-0.2909173171555818], [-0.09234407039336902], [1.2064323003216446], [-0.5699932315240971], [0.8146526513043056], [0.5999788710208324], [2.5696108051217], [-0.5968274540595312], [0.37993824623027217], [0.7985521177830452], [1.4747745256759863], [-1.1603461273036486], [2.059760576948451], [0.5194762034145299], [-0.24261571659180034], [-0.4411889633540131], [0.48190829186492196], [0.9863916755310844], [-0.9188381244847412], [-0.19431411602801882], [1.5391766597610284], [1.093728565672821], [-0.1782135825067583], [-0.1191782929288032], [-0.027941936308326976], [-0.20504780504219247], [0.8307531848255663], [-0.28018362814140807], [1.3352365684917282], [-0.16747989349258463], [2.295901735260271], [-0.4143547408185789], [-0.4894905639177946], [0.256500822567275], [-0.9295718134989149], [-0.221148338563453], [0.6375467825704402], [0.2726013560885357], [0.1598976214397122], [-0.07087669236502167], [-1.283783550966646], [0.26723451158144873], [-0.66659643265166], [-1.85266906871785], [-1.0100744811052174], [-1.1496124382894748], [-0.011841402787066583], [-0.09771091490045586], [0.7395168282050901], [-0.2694499391272344], [-0.09234407039336902], [0.84148687383974], [1.0078590535594318], [0.37993824623027217], [-0.16747989349258463], [2.016825820891756], [0.49264198087909566], [0.47654144735783527], [-0.8329686123713519], [-0.5968274540595312], [0.9971253645452581], [-1.3481856850516878], [1.0400601206019526], [-1.6165279104060293], [-0.5914606095524444], [0.326269801159404], [-1.1013108377256935], [0.5999788710208324], [0.9434569194743897], [-1.5843268433635083], [-0.6397622101162259], [-0.27481678363432127], [-0.8329686123713519], [-0.38215367377605797], [0.6751146941200481], [-0.033308780815413934], [-0.7631996337792231], [-0.8007675453288309], [-1.053009237161912], [-0.3928873627902317], [0.14916393242553852], [-0.16211304898549778], [-0.1352788264500636], [-0.8329686123713519], [1.0615274986302998], [1.560644037789375], [-1.053009237161912], [1.3459702575059023], [-0.5324253199744892], [-0.09234407039336902], [0.261867667074362], [-0.39825420729731836], [0.7717178952476109], [0.7663510507405242], [-0.5485258534957497], [-1.1066776822327804], [0.9702911420098238], [-1.0637429261760858], [0.7126826056696558], [1.3567039465200756], [0.46580775834366156], [-1.2408487949099511], [0.5302098924287036], [-1.085210304204433], [-1.3750199075871221], [1.3030355014492074], [0.8897884744035214], [-0.17284673799967146], [0.014992819748367723], [0.8790547853893477], [-0.12991198194297676], [-1.788266934632808], [0.6214462490491798], [1.469407681168899], [-0.17284673799967146], [0.9112558524318687], [-1.1603461273036486], [-0.8544359903996992], [-1.2140145723745168], [0.0901286428475832], [2.3227359577957056], [1.9470568422996275], [-0.8759033684280465], [-0.7739333227933968], [-1.5145578647713795], [-0.6773301216658337], [0.6912152276413085], [1.222532833842905], [0.2189329110176673], [-1.1335119047682145], [0.17063131045388588], [0.8039189622901319], [2.1456300890618403], [0.2081992220034936], [-2.7972337019651325], [0.6751146941200481], [-1.2247482613886906], [0.1330633989042779], [-1.3535525295587747], [-1.1335119047682145], [2.360303869345313], [-0.04404246982958761], [-1.0422755481477384], [1.984624753849235], [-0.7739333227933968], [1.2762012789137733], [-1.122778215754041], [-1.09057714871152], [1.6304130163815045], [-0.22651518307053983], [0.8575874073610004], [-0.20504780504219247], [-0.5968274540595312], [-0.9939739475839569], [1.4103723915909443], [0.8146526513043056], [1.4264729251122044], [0.4228730022869669], [-0.8115012343430045], [0.7663510507405242], [-0.39825420729731836], [0.9702911420098238], [1.029326431587779], [2.4515402259657892], [0.7073157611625691], [-1.4877236422359454], [-0.5485258534957497], [1.217165989335818], [-1.0959439932186068], [-1.7023974225194187], [0.546310425949964], [-0.47875687490362095], [-1.1496124382894748], [1.17959807778621], [-0.31775153969101594], [-0.2587162501130609], [-0.8276017678642651], [0.256500822567275], [1.3674376355342495], [1.608945638353157], [-0.5055910974390552], [-0.4572894968752736], [-0.9242049689918279], [-0.34995260673353695], [0.10086233186175687], [-0.5699932315240971], [-0.221148338563453], [0.261867667074362], [1.4747745256759863], [-0.22651518307053983], [-0.6612295881445733], [0.8790547853893477], [-0.510957941946142], [1.351337102012989], [-0.8222349233571782], [0.6107125600350061], [-0.8222349233571782], [0.1276965543971912], [-0.5807269205382707], [-0.36605314025479746], [-0.9939739475839569], [-0.8329686123713519], [-0.6504958991303996], [1.088361721165734], [-1.0959439932186068], [0.2081992220034936], [-0.6182948320878786], [-1.053009237161912], [0.3960387797515328], [0.6804815386271348], [0.3531040236948381], [-0.4250884298327526], [0.7663510507405242], [-0.1352788264500636], [-0.04404246982958761], [1.0132258980665185], [-0.4143547408185789], [-0.32848522870518965], [-0.3070178506768423], [0.3584708682019248], [-1.9009706692816313], [-0.253349405605974], [-0.12454513743589005], [-1.0691097706831725], [0.3692045572160985], [0.29943557862396974], [0.33163664566649076], [0.15453077693262526], [0.3960387797515328], [-0.22651518307053983], [-0.10844460391462954], [1.5230761262397676], [-0.66659643265166], [0.5677778039783113], [0.8253863403184794], [0.16526446594679892], [0.6751146941200481], [-0.06550984785793483], [0.04719388679088875], [0.42823984679405386], [-1.020808170119391], [1.7216493730019806], [-0.39825420729731836], [-0.3714199847618843], [0.7985521177830452], [-0.8437023013855255], [-0.2372488720847135], [1.2654675898995995], [0.3692045572160985], [-0.20504780504219247], [0.11159602087593055], [1.8826547082145855], [-0.4143547408185789], [-0.8651696794138729], [-2.49669040956827], [0.40140562425861953], [1.6411467053956779], [-0.21578149405636615], [0.6751146941200481], [1.7914183515941093], [-1.369653063080035], [1.7753178180728486], [-0.017208247294153302], [-1.4769899532217718], [-1.2945172399808194], [0.3638377127090118], [0.809285806797219], [0.5087425144003562], [0.33163664566649076], [0.4550740693294879], [0.4228730022869669], [1.7431167510303278], [-1.627261599420203], [0.15453077693262526], [0.31553611214523036], [-1.154979282796562], [-0.2694499391272344], [1.9792579093421483], [-0.6612295881445733], [0.0686612648192361], [1.16349754426495], [0.8629542518680873], [-0.26408309462014756], [2.2207659121610557], [-0.060143003350848], [-0.17284673799967146], [-1.568226309842248], [-0.9027375909634807], [-0.28018362814140807], [-1.2301151058957775], [-1.3213514625162537], [-0.2479825610988872], [-0.47875687490362095], [0.326269801159404], [0.9810248310239975], [-0.6504958991303996], [-0.26408309462014756], [-0.5592595425099234], [0.7931852732759583], [0.9434569194743897], [-0.2372488720847135], [-0.23188202757762666], [-1.053009237161912], [-0.6021942985666181], [-2.1102776050580183], [1.8182525741295434], [-0.09234407039336902], [-1.1710798163178222], [0.3584708682019248], [-1.0315418591335648], [0.15453077693262526], [0.4389735358082275], [-1.3589193740658614], [-0.6880638106800073], [0.4389735358082275], [1.3245028794775549], [-0.3928873627902317], [-0.7685664782863098], [-0.3123846951839291], [0.004259130734194047], [-1.9224380473099787], [-0.7256317222296153], [-0.8759033684280465], [-0.7470991002579626], [1.088361721165734], [1.7377499065232407], [-0.8276017678642651], [-0.28018362814140807], [-0.07087669236502167], [1.034693276094866], [0.40140562425861953], [-0.12991198194297676], [0.34773717918775116], [0.31553611214523036], [1.1581306997578626], [-0.0011077137728929085], [-1.278416706459559], [-0.0011077137728929085], [0.49264198087909566], [-0.24261571659180034], [-1.5252915537855531], [-0.2855504726484949], [-0.5377921644815761], [0.07402810932632281], [0.7341499836980032], [-0.04404246982958761], [-1.4501557306863375], [-0.47875687490362095], [-0.7685664782863098], [2.032926354413017], [0.7126826056696558], [0.014992819748367723], [0.873687940882261], [-0.8705365239209597], [0.583878337499572], [1.6304130163815045], [0.6429136270775271], [-1.9009706692816313], [0.47654144735783527], [0.8790547853893477], [-0.2909173171555818], [-0.04404246982958761], [0.546310425949964], [-1.117411371246954], [0.9327232304602161], [-0.2587162501130609], [1.4479403031405518], [0.1169628653830175], [-0.98860710307687], [0.12232970989010424], [-0.7954007008217441], [0.37993824623027217], [1.3030355014492074], [-0.6880638106800073], [0.9219895414460424], [2.0060921318775824], [0.05256073129797546], [0.4121393132727932], [1.6411467053956779], [-0.2587162501130609], [-0.022575091801240257], [-2.3517856078769253], [-0.43045527433983943], [-0.4894905639177946], [-1.7453321785761131], [-0.9188381244847412], [1.8182525741295434], [-1.627261599420203], [-0.66659643265166], [3.261933746535901], [2.1456300890618403], [-0.15137935997132412], [-2.206880806185581], [-1.9868401813950207], [1.152763855250776], [-1.0476423926548253], [-1.5789599988564216], [-0.46802318588944725], [0.8951553189106081], [0.5570441149641376], [-0.7363654112437888], [-0.6182948320878786], [-0.15674620447841095], [0.7770847397546979], [0.7287831391909165], [-0.28018362814140807], [0.8253863403184794], [0.09549548735467016], [0.2779682005956224], [-0.03867562532250065], [0.2189329110176673], [1.3781713245484228], [0.16526446594679892], [1.4050055470838574], [0.05792757580506242], [0.9166226969389554], [-0.9725065695556095], [-0.5216916309603157], [3.5732107279469374], [0.6643810051058744], [-0.7578327892721363], [0.04719388679088875], [0.546310425949964], [0.8629542518680873], [0.4550740693294879], [0.809285806797219], [-0.2909173171555818], [3.3639037921705515], [1.759217284551588], [-0.5968274540595312], [-1.053009237161912], [1.16349754426495], [-0.027941936308326976], [-0.19431411602801882], [-0.5807269205382707], [-1.0100744811052174], [-0.253349405605974], [0.9434569194743897], [-0.9295718134989149], [0.16526446594679892], [-1.305250928994993], [-0.28018362814140807], [1.7162825284948933], [-0.3231183841981028], [0.19209868848223324], [-0.20504780504219247], [-0.6826969661729206], [1.2762012789137733], [-1.9600059588595866], [-0.07087669236502167], [-0.8007675453288309], [-0.9725065695556095], [0.46044091383657487], [-0.49485740842488146], [-2.1263781385792786], [-0.30165100616975543], [0.05792757580506242], [0.9649242975027371], [-2.244448717735189], [-1.1335119047682145], [1.2708344344066866], [1.8289862631437168], [-1.6111610658989426], [-0.6129279875807918], [0.19209868848223324], [-0.8651696794138729], [-0.9295718134989149], [-1.283783550966646], [0.8844216298964344], [-0.11381144842171637], [-1.6970305780123318], [0.10086233186175687], [2.473007603994137], [-1.595060532377682], [-1.7077642670265056], [1.1044622546869947], [-0.9134712799776544], [-1.7667995566044605], [0.2081992220034936], [0.05792757580506242], [-0.7148980332154415], [-0.5163247864532288], [0.7395168282050901], [1.1259296327153419], [-0.6880638106800073], [1.2332665228570787], [-0.2694499391272344], [1.60357879384607], [-1.3267183070233404], [0.06329442031214914], [-1.117411371246954], [-1.1925471943461696], [-0.03867562532250065], [2.3012685797673584], [-0.8490691458926124], [0.2350334445389277], [-1.8741364467461974], [1.16349754426495], [-0.253349405605974], [0.05256073129797546], [0.6858483831342218], [0.19746553298931996], [0.4980088253861826], [0.40140562425861953], [-1.0637429261760858], [0.6053457155279194], [0.9166226969389554], [-0.16211304898549778], [1.4962419037043335], [-0.6129279875807918], [0.4872751363720089], [-0.37678682926897117], [1.3835381690555102], [3.143863167379991], [-0.08161038137919535], [0.9219895414460424], [-0.32848522870518965], [0.07402810932632281], [-0.9939739475839569], [-2.2820166292847968], [-0.634395365609139], [0.036460197776715074], [0.224299755524754], [0.6107125600350061], [-0.19431411602801882], [0.900522163417695], [0.5892451820066588], [-0.060143003350848], [-0.7148980332154415], [0.7770847397546979], [0.5892451820066588], [-1.3589193740658614], [1.2332665228570787], [0.9166226969389554], [-1.0100744811052174], [0.6107125600350061], [1.533809815253941], [-0.46802318588944725], [2.6125455611783948], [-0.6826969661729206], [0.6590141605987875], [0.5409435814428772], [1.5713777268035491], [-0.6075611430737049], [0.1169628653830175], [-1.2569493284312117], [1.3245028794775549], [-0.1782135825067583], [1.6518803944098517], [0.18673184397514628], [0.05256073129797546], [-0.06550984785793483], [0.031093353269628116], [0.256500822567275], [-1.1818135053319958], [0.43360669130114055], [0.3745714017231855], [-0.16211304898549778], [0.8039189622901319], [-0.8222349233571782], [-0.7793001673004835], [-0.12454513743589005], [0.8522205628539136], [0.8468537183468267], [-1.8580359132249369], [-0.9510391915272621], [-1.8741364467461974], [-0.9617728805414358], [-0.5216916309603157], [2.295901735260271], [-1.053009237161912], [-1.154979282796562], [0.5570441149641376], [0.8844216298964344], [-0.6880638106800073], [-0.27481678363432127], [-0.3070178506768423], [0.40140562425861953], [1.1581306997578626], [-0.5538926980028366], [0.9488237639814765], [1.2547339008854261], [-0.033308780815413934], [0.6643810051058744], [1.1205627882082552], [-0.21578149405636615], [0.09549548735467016], [1.1151959437011685], [-0.8866370574422202], [1.8504536411720642], [-0.8759033684280465], [-0.7900338563146572], [-0.36068629574771066], [-1.503824175757206], [-3.6237277560565047], [-0.9564060360343489], [-1.112044526739867], [-0.7954007008217441], [0.583878337499572], [-0.6773301216658337], [0.6214462490491798], [-0.30165100616975543], [0.7073157611625691], [-0.9564060360343489], [1.5821114158177225], [-0.8973707464563939], [0.5033756698932693], [-0.7739333227933968], [-0.006474558279979626], [-0.46802318588944725], [-0.7256317222296153], [-0.3928873627902317], [0.6429136270775271], [0.224299755524754], [1.9577905313138009], [1.3191360349704682], [-1.9009706692816313], [-0.011841402787066583], [-0.9242049689918279], [0.18136499946805956], [-2.357152452384012], [-0.32848522870518965], [0.9649242975027371], [-0.34458576222645015], [-0.3928873627902317], [-0.14064567095715044], [-0.6558627436374863], [0.26723451158144873], [1.0615274986302998], [-2.6576957447808747], [-0.7417322557508758], [-2.0941770715367576], [-2.206880806185581], [0.6912152276413085], [-0.060143003350848], [0.036460197776715074], [-0.4197215853256657], [1.1259296327153419], [-0.1352788264500636], [-0.9510391915272621], [0.3584708682019248], [-0.38215367377605797], [0.5999788710208324], [0.3209029566523171], [-0.08161038137919535], [-0.19431411602801882], [-0.5807269205382707], [-1.09057714871152], [-1.0047076365981304], [0.46580775834366156], [-0.3231183841981028], [0.014992819748367723], [0.836120029332653], [-0.9966573698375003], [0.06329442031214914], [-1.31061777350208], [-0.37678682926897117], [-0.03867562532250065], [0.5194762034145299], [1.1205627882082552], [-1.085210304204433], [1.8128857296224568], [0.49264198087909566], [0.33163664566649076], [-0.4411889633540131], [0.05792757580506242], [-0.16211304898549778], [-1.2354819504028642], [0.8951553189106081], [0.4443403803153142], [-0.9725065695556095], [-0.8168680788500915], [0.7717178952476109], [-0.510957941946142], [0.1759981549609726], [-0.44655580786109994], [-1.42868835265799], [1.190331766800384], [0.6965820721483954], [1.9577905313138009], [0.8629542518680873], [-1.7829000901257213], [2.7145156068130443], [-1.1657129718107355], [-1.9922070259021076], [1.0454269651090393], [-0.18358042701384514], [-0.27481678363432127], [1.1742312332791234], [-1.1281450602611278], [1.3084023459562941], [-0.21041464954927933], [0.9595574529956501], [1.190331766800384], [-0.36068629574771066], [0.8575874073610004], [-0.1191782929288032], [0.07939495383340953], [0.014992819748367723], [0.4121393132727932], [-0.8705365239209597], [-0.060143003350848], [0.15453077693262526], [1.227899678349992], [-0.5592595425099234], [-0.3875205182831448], [0.38530509073735913], [0.6375467825704402], [-1.112044526739867], [0.2028323774964069], [0.49264198087909566], [0.9058890079247818], [-0.36068629574771066], [1.9094889307500196], [-0.022575091801240257], [-0.66659643265166], [0.5194762034145299], [0.546310425949964], [0.3638377127090118], [-1.0369087036406515], [-0.2855504726484949], [-0.5216916309603157], [-0.5002242529319683], [-1.7345984895619397], [0.6643810051058744], [-1.0476423926548253], [-0.8490691458926124], [0.47654144735783527], [-0.38215367377605797], [-0.2479825610988872], [-0.8544359903996992], [2.5696108051217], [0.4443403803153142], [1.1956986113074708], [1.034693276094866], [0.9434569194743897], [0.26723451158144873], [-1.3267183070233404], [0.34773717918775116], [-0.19968096053510564], [-0.6236616765949654], [-1.788266934632808], [-0.14064567095715044], [1.3728044800413362], [-0.9564060360343489], [-0.24261571659180034], [0.1598976214397122], [-0.6129279875807918], [-2.9099374366139563], [-0.44655580786109994], [1.9470568422996275], [1.2547339008854261], [0.8897884744035214], [3.1116621003374703], [-0.8973707464563939], [-0.12991198194297676], [-0.16211304898549778], [0.7126826056696558], [-2.142478672100539], [-0.5646263870170102], [0.7126826056696558], [0.873687940882261], [-1.1764466608249091], [-0.8329686123713519], [2.188564845118535], [0.6965820721483954], [-0.32848522870518965], [0.11159602087593055], [-0.4143547408185789], [-1.7453321785761131], [-0.6129279875807918], [1.3352365684917282], [-0.37678682926897117], [0.4121393132727932], [1.3030355014492074], [1.8182525741295434], [0.020359664255454442], [1.2923018124350336], [-0.5055910974390552], [0.31553611214523036], [-0.19431411602801882], [-0.12454513743589005], [1.1581306997578626], [1.2386333673641654], [1.8236194186366301], [1.088361721165734], [-0.14601251546423727], [0.28333504510270935], [1.9953584428634088], [-0.6880638106800073], [0.036460197776715074], [-0.5163247864532288], [0.3101692676381434], [-1.0476423926548253], [-0.892003901949307], [1.351337102012989], [-0.08161038137919535], [-1.0369087036406515], [-0.16211304898549778], [0.1330633989042779], [-0.20504780504219247], [-0.7793001673004835], [-0.18894727152093196], [0.0901286428475832], [-1.0476423926548253], [-1.562859465335161], [0.8575874073610004], [0.1598976214397122], [0.6965820721483954], [-1.5413920873068137], [-0.6504958991303996], [-0.6558627436374863], [0.15453077693262526], [2.660847161742176], [-1.3267183070233404], [0.3048024231310567], [-0.19431411602801882], [-1.0793067752466374], [0.9166226969389554], [1.7162825284948933], [1.1098290991940813], [-0.66659643265166], [-0.3714199847618843], [0.8468537183468267], [1.0615274986302998], [-0.3231183841981028], [0.04719388679088875], [0.3906719352444459], [-1.0691097706831725], [0.5624109594712247], [0.2779682005956224], [-0.6236616765949654], [1.2708344344066866], [0.04719388679088875], [0.18673184397514628], [0.5033756698932693], [-0.060143003350848], [0.6160794045420928], [-0.31775153969101594], [-0.5270584754674025], [-1.2945172399808194], [-1.0315418591335648], [-1.3857535966012955], [0.08476179834049649], [-0.7631996337792231], [0.3048024231310567], [-0.4572894968752736], [-2.27664978477771], [1.694815150466546], [1.0132258980665185], [-0.5324253199744892], [2.89162147554691], [0.294068734116883], [0.10086233186175687], [-0.8007675453288309], [-0.16211304898549778], [0.868321096375174], [1.8450867966649773], [-0.21578149405636615], [-1.595060532377682], [0.6858483831342218], [-0.8061343898359178], [1.0722611876444739], [0.43360669130114055], [-0.08161038137919535], [-0.8866370574422202], [0.04182704228380179], [-1.9117043582958053], [-0.0011077137728929085], [-0.16747989349258463], [-0.24261571659180034], [2.9667572986461255], [-0.2694499391272344], [1.0454269651090393], [0.1330633989042779], [1.6357798608885912], [-0.9081044354705675], [-0.24261571659180034], [1.3835381690555102], [-0.36605314025479746], [-0.5270584754674025], [-0.17284673799967146], [0.33163664566649076], [-0.22651518307053983], [-0.26408309462014756], [0.1330633989042779], [0.47654144735783527], [0.7824515842617846], [0.7502505172192636], [-0.43582211884692623], [-0.253349405605974], [1.6196793273673304], [-1.503824175757206], [1.9631573758208876], [1.442573458633465], [1.6250461718744171], [1.769950973565762], [0.5302098924287036], [-0.5968274540595312], [0.46044091383657487], [-0.38215367377605797], [0.5302098924287036], [-0.1782135825067583], [1.029326431587779], [-0.20504780504219247], [0.7019489166554822], [0.9810248310239975], [-0.6558627436374863], [-0.37678682926897117], [2.1295295555405795], [1.5123424372255938], [-0.033308780815413934], [2.032926354413017], [0.6912152276413085], [-0.7631996337792231], [0.28870188960979604], [-0.510957941946142], [-0.6021942985666181], [-0.2694499391272344], [2.3978717808949215], [0.09549548735467016], [-0.20504780504219247], [1.442573458633465], [-1.0100744811052174], [0.04719388679088875], [0.5409435814428772], [1.5284429707468543], [0.020359664255454442], [1.6787146169452858], [-1.0100744811052174], [0.1169628653830175], [-0.4841237194107078], [-1.1657129718107355], [1.2332665228570787], [0.0686612648192361], [-1.4233215081509034], [-0.8651696794138729], [0.3745714017231855], [-0.9564060360343489], [0.7180494501767428], [0.9166226969389554], [0.3692045572160985], [0.3423703346806644], [1.92558946427128], [0.8307531848255663], [0.3048024231310567], [-0.7524659447650494], [-0.40898789631149207], [-0.8168680788500915], [3.2350995240004674], [1.0454269651090393], [-1.3159846180091668], [-0.18894727152093196], [-0.8115012343430045], [1.2654675898995995], [-0.3123846951839291], [1.2708344344066866], [-0.22651518307053983], [-1.568226309842248], [0.13843024341136487], [1.0615274986302998], [0.5892451820066588], [1.0507938096161265], [-1.3911204411083824], [0.18136499946805956], [-0.3714199847618843], [-0.9188381244847412], [0.3960387797515328], [0.3745714017231855], [-0.5485258534957497], [-0.36605314025479746], [-0.0011077137728929085], [-1.0422755481477384], [0.6429136270775271], [-0.2587162501130609], [1.2976686569421207], [-1.3857535966012955], [-0.4894905639177946], [-0.15674620447841095], [1.2493670563783392], [-1.1281450602611278], [0.5570441149641376], [-1.8151011571682423], [0.5033756698932693], [-0.6504958991303996], [1.1151959437011685], [-1.219381416881604], [-0.38215367377605797], [2.596445027657134], [0.6053457155279194], [-0.15674620447841095], [0.12232970989010424], [0.6804815386271348], [-0.16747989349258463], [1.3567039465200756], [1.5284429707468543], [2.150996933568927], [0.4067724687657065], [0.5302098924287036], [-0.33385207321227645], [0.1330633989042779], [-0.9349386580060016], [0.5570441149641376], [-0.9832402585697831], [-0.6182948320878786], [0.6214462490491798], [0.7234162946838295], [0.009625975241280766], [-0.7363654112437888], [-1.7506990230832002], [-0.23188202757762666], [0.16526446594679892], [0.8039189622901319], [-0.3928873627902317], [1.190331766800384], [-0.221148338563453], [-1.4501557306863375], [1.861187330186238], [0.7985521177830452], [0.9112558524318687], [-0.04404246982958761], [-0.5807269205382707], [0.7073157611625691], [0.0901286428475832], [0.14379708791845158], [0.2081992220034936], [-0.221148338563453], [-1.0261750146264779], [-1.219381416881604], [-0.3070178506768423], [1.0722611876444739], [-0.634395365609139], [-0.1352788264500636], [0.036460197776715074], [0.12232970989010424], [0.1598976214397122], [2.2100322231468823], [0.7180494501767428], [0.7502505172192636], [-1.0154413256123043], [-0.9993407920910437], [0.07939495383340953], [0.6375467825704402], [0.6643810051058744], [0.9380900749673028], [-0.36068629574771066], [-2.5503588546391387], [-0.7470991002579626], [0.5570441149641376], [-0.060143003350848], [-0.5538926980028366], [-0.9081044354705675], [-0.5914606095524444], [-1.4125878191367298], [1.093728565672821], [-0.8866370574422202], [0.9756579865169107], [-0.634395365609139], [-0.15674620447841095], [-1.943905425338326], [0.47654144735783527], [-0.6719632771587469], [-1.6165279104060293], [-0.9403055025130886], [2.8433198749831283], [0.2189329110176673], [-0.04404246982958761], [-1.4877236422359454], [-1.2623161729382986], [0.8844216298964344], [-0.510957941946142], [-0.4143547408185789], [0.020359664255454442], [-1.219381416881604], [-0.05477615884376128], [1.2976686569421207], [-0.8812702129351334], [-1.3803867520942088], [-0.510957941946142], [-0.9134712799776544], [-1.0261750146264779], [0.26723451158144873], [-0.5431590089886629], [1.6196793273673304], [0.26723451158144873], [-1.1979140388532565], [-0.1352788264500636], [-1.2140145723745168], [-1.122778215754041], [0.7448836727121769], [0.1276965543971912], [0.5087425144003562], [0.6268130935562665], [-0.47875687490362095], [1.2654675898995995], [0.6858483831342218], [0.6268130935562665], [0.12232970989010424], [-0.4894905639177946], [0.42823984679405386], [-0.2694499391272344], [2.24760013469649], [-0.14064567095715044], [0.16526446594679892], [0.6643810051058744], [0.3692045572160985], [-0.4250884298327526], [1.0668943431373867], [2.3549370248382266], [2.5159423600508313], [0.3584708682019248], [1.1742312332791234], [1.4372066141263782], [0.025726508762541397], [1.1312964772224288], [0.14916393242553852], [0.18136499946805956], [0.05792757580506242], [-1.4555225751934244], [-0.5753600760311839], [-0.22651518307053983], [2.505208671036658], [1.1098290991940813], [-0.12991198194297676], [-0.16747989349258463], [0.15453077693262526], [-0.4143547408185789], [0.5302098924287036], [-1.949272269845413], [0.28333504510270935], [-0.7041643442012678], [-0.08161038137919535], [2.24760013469649], [0.47654144735783527], [1.8182525741295434], [-0.2694499391272344], [-0.9403055025130886], [2.0060921318775824], [2.3227359577957056], [0.6912152276413085], [0.9541906084885634], [0.49264198087909566], [0.9971253645452581], [0.29943557862396974], [-0.7256317222296153], [-1.8741364467461974], [0.10622917636884384], [-1.1496124382894748], [0.326269801159404], [-0.5807269205382707], [0.6160794045420928], [0.836120029332653], [-0.2587162501130609], [-0.6504958991303996], [-2.2927503182989706], [0.5087425144003562], [1.1473970107436893], [-0.022575091801240257], [0.34773717918775116], [-0.19431411602801882], [0.7019489166554822], [0.2189329110176673], [-1.0744766151902594], [0.1169628653830175], [-0.31775153969101594], [-0.09234407039336902], [-0.9832402585697831], [-0.5914606095524444], [2.821852496954781], [1.8450867966649773], [-1.7131311115335925], [0.551677270457051], [1.3567039465200756], [-0.1352788264500636], [0.15453077693262526], [-0.4841237194107078], [-0.5270584754674025], [1.4962419037043335], [0.4121393132727932], [0.2028323774964069], [-0.9456723470201753], [-0.6773301216658337], [-1.3535525295587747], [-0.7095311887083547], [0.4121393132727932], [-0.9564060360343489], [-0.36605314025479746], [0.036460197776715074], [-0.12454513743589005], [0.26723451158144873], [0.06329442031214914], [2.086594799483885], [-0.17284673799967146], [0.4550740693294879], [-0.5324253199744892], [-0.4894905639177946], [0.8146526513043056], [1.351337102012989], [0.29943557862396974], [-1.0261750146264779], [0.5409435814428772], [0.7609842062334372], [2.628646094699655], [1.1420301662366026], [0.5355767369357903], [-1.154979282796562], [0.3638377127090118], [1.6572472389169386], [-2.0512423154800628], [0.37993824623027217], [-2.485956720554096], [0.9058890079247818], [0.261867667074362], [-0.05477615884376128], [-1.627261599420203], [1.3674376355342495], [0.2350334445389277], [-0.5860937650453576], [-0.9671397250485226], [-1.0691097706831725], [-0.5324253199744892], [-0.6451290546233127], [1.0078590535594318], [0.2081992220034936], [0.3960387797515328], [0.3423703346806644], [-0.4143547408185789], [0.44970722482240116], [-1.6165279104060293], [0.07402810932632281], [-0.033308780815413934], [-0.4572894968752736], [-0.6558627436374863], [0.7663510507405242], [1.2547339008854261], [0.7234162946838295], [-0.4197215853256657], [-0.30165100616975543], [-0.6719632771587469], [-0.9349386580060016], [-0.221148338563453], [-0.9242049689918279], [-0.4411889633540131], [-0.4143547408185789], [-0.12991198194297676], [1.0668943431373867], [0.37993824623027217], [0.546310425949964], [-0.6880638106800073], [1.099095410179908], [-1.2408487949099511], [0.44970722482240116], [1.2923018124350336], [-0.7685664782863098], [-1.09057714871152], [0.9917585200381711], [0.28333504510270935], [-0.6451290546233127], [1.1420301662366026], [-1.729231645054853], [0.0686612648192361], [-1.0047076365981304], [-0.34458576222645015], [-0.7256317222296153], [1.4050055470838574], [-1.0691097706831725], [-0.14064567095715044], [2.837953030476042], [1.2010654558145575], [1.5660108822964625], [-1.8312016906895026], [0.261867667074362], [-0.8437023013855255], [0.04719388679088875], [-0.08697722588628219], [-1.2998840844879063], [0.4872751363720089], [-1.600427376884769], [-0.47875687490362095], [0.7609842062334372], [3.074094188787862], [-1.7775332456186346], [-0.5163247864532288], [-2.1371118275934524], [-1.278416706459559], [-0.19968096053510564], [-0.6558627436374863], [0.3209029566523171], [-0.9188381244847412], [-0.859802834906786], [0.46580775834366156], [0.014992819748367723], [-0.16211304898549778], [0.10086233186175687], [2.1456300890618403], [-0.027941936308326976], [-0.32848522870518965], [0.16526446594679892], [2.6447466282209158], [0.7985521177830452], [-1.187180349839083], [-0.45192265236818674], [0.6965820721483954], [0.24040028904601465], [0.10086233186175687], [0.4228730022869669], [-0.4572894968752736], [1.560644037789375], [-1.4823567977288585], [0.8629542518680873], [-1.2945172399808194], [0.3370034901735777], [-0.12991198194297676], [-0.28018362814140807], [-0.5431590089886629], [1.1581306997578626], [-1.6165279104060293], [-0.27481678363432127], [-0.4411889633540131], [0.5731446484853984], [0.3960387797515328], [-0.5216916309603157], [0.04719388679088875], [1.227899678349992], [0.2726013560885357], [1.286934967927947], [0.6482804715846138], [-0.9778734140626963], [0.4980088253861826], [0.6214462490491798], [-0.5270584754674025], [-0.19968096053510564], [-0.6504958991303996], [-0.9725065695556095], [0.6804815386271348], [0.7448836727121769], [-1.3589193740658614], [-1.664829510969811], [-0.5753600760311839], [0.48190829186492196], [-0.8222349233571782], [-0.18358042701384514], [-0.46265634138236045], [0.3048024231310567], [1.9470568422996275], [-0.07624353687210851], [0.33163664566649076], [-0.20504780504219247], [-0.16747989349258463], [0.6751146941200481], [0.18673184397514628], [0.7073157611625691], [-0.8115012343430045], [0.3048024231310567], [-0.060143003350848], [-0.6719632771587469], [0.6912152276413085], [-1.4179546636438167], [0.7985521177830452], [-1.6701963554768977], [-0.19968096053510564], [1.286934967927947], [-0.3123846951839291], [-0.17284673799967146], [-0.45192265236818674], [-0.30165100616975543], [-0.7846670118075705], [-2.0458754709729763], [-0.9188381244847412], [1.1312964772224288], [0.3209029566523171], [-0.5055910974390552], [1.8236194186366301], [0.11159602087593055], [0.8522205628539136], [-0.9349386580060016], [2.4354396924445294], [-1.337451996037514], [0.4067724687657065], [-0.20504780504219247], [-0.49485740842488146], [-0.04940931433667432], [-0.6451290546233127], [-1.4555225751934244], [2.773550896391], [0.014992819748367723], [-1.0691097706831725], [-1.144245593782388], [-0.26408309462014756], [0.873687940882261], [0.4121393132727932], [-0.027941936308326976], [2.7145156068130443], [0.4980088253861826], [1.8128857296224568], [1.8021520406082827], [-1.251582483924125], [0.036460197776715074], [-0.4143547408185789], [-1.7238648005477661], [0.9166226969389554], [0.18136499946805956], [0.9541906084885634], [-1.3213514625162537], [-0.07624353687210851], [0.1276965543971912], [-0.12991198194297676], [0.8575874073610004], [1.3084023459562941], [0.3960387797515328], [-0.6021942985666181], [0.14379708791845158], [-0.30165100616975543], [0.5409435814428772], [-0.7954007008217441], [-0.38215367377605797], [0.6536473160917008], [-1.187180349839083], [0.46580775834366156], [-0.37678682926897117], [-0.5860937650453576], [-0.04404246982958761], [-0.8544359903996992], [0.46580775834366156], [0.07939495383340953], [2.4139723144161818], [-1.3642862185729483], [-0.49485740842488146], [0.8575874073610004], [0.224299755524754], [-0.8973707464563939], [-0.730998566736702], [-0.9671397250485226], [-0.6451290546233127], [0.37993824623027217], [-0.5431590089886629], [0.9488237639814765], [-1.3159846180091668], [2.5427765825862654], [0.7878184287688715], [-0.6773301216658337], [0.4711746028507485], [-0.7631996337792231], [-1.4769899532217718], [-1.9707396478737604], [-0.0011077137728929085], [-0.2909173171555818], [-0.6826969661729206], [-0.32848522870518965], [-0.12454513743589005], [-0.5699932315240971], [-0.38215367377605797], [1.0615274986302998], [0.24576713355310137], [1.023959587080692], [0.0686612648192361], [-0.98860710307687], [0.3048024231310567], [0.9702911420098238], [-1.2032808833603432], [-1.7453321785761131], [-0.2909173171555818], [0.224299755524754], [-0.2479825610988872], [-1.8419353797036766], [-1.1710798163178222], [0.036460197776715074], [-1.6862968889981584], [0.020359664255454442], [-0.5055910974390552], [1.3137691904633808], [-0.26408309462014756], [0.9058890079247818], [0.5731446484853984], [-0.6719632771587469], [-2.0888102270296707], [0.8468537183468267], [-0.18358042701384514], [1.8128857296224568], [-0.2587162501130609], [-0.6290285211020523], [-0.8812702129351334], [-0.43045527433983943], [1.3352365684917282], [0.18136499946805956], [-0.510957941946142], [1.002492209052345], [1.9577905313138009], [0.04719388679088875], [-1.246215639417038], [3.1921647679437726], [-0.22651518307053983], [-0.2372488720847135], [-0.5431590089886629], [0.16526446594679892], [-0.6880638106800073], [0.5033756698932693], [0.2028323774964069], [2.4247060034303556], [0.900522163417695], [-0.21578149405636615], [0.10086233186175687], [-1.1066776822327804], [0.38530509073735913], [1.4479403031405518], [-0.6236616765949654], [0.28870188960979604], [1.4908750591972464], [0.261867667074362], [0.7770847397546979], [-0.6451290546233127], [1.28156812342086], [-0.5163247864532288], [-0.6934306551870943], [-1.9385385808312394], [-0.006474558279979626], [-0.1782135825067583], [-0.9510391915272621], [-0.6290285211020523], [1.4318397696192915], [1.3459702575059023], [0.21356606651058035], [-1.7077642670265056], [0.5999788710208324], [0.6214462490491798], [-0.44655580786109994], [-0.9993407920910437], [-1.627261599420203], [-0.3392189177193633], [-1.6487289774485503], [0.8522205628539136], [-0.04404246982958761], [-0.6719632771587469], [0.551677270457051], [-0.7954007008217441], [1.517709281732681], [3.734216063159543], [0.5999788710208324], [-0.0011077137728929085], [-0.7954007008217441], [-0.4733900303965341], [-1.020808170119391], [1.1205627882082552], [0.6375467825704402], [0.46044091383657487], [0.3209029566523171], [-1.5306583982926403], [-0.16211304898549778], [0.8951553189106081], [-0.730998566736702], [0.7341499836980032], [0.84148687383974], [-0.1782135825067583], [0.8951553189106081], [-0.006474558279979626], [0.900522163417695], [0.7985521177830452], [-1.1710798163178222], [-1.9063375137887184], [-0.006474558279979626], [0.4550740693294879], [-0.7256317222296153], [-0.027941936308326976], [2.24760013469649], [0.5731446484853984], [0.07402810932632281], [-1.3320851515304273], [1.9416899977925408], [-0.5592595425099234], [-0.9188381244847412], [-0.8866370574422202], [0.24040028904601465], [1.0668943431373867], [0.9863916755310844], [0.578511492992485], [1.415739236098031], [0.1598976214397122], [-1.3964872856154693], [-0.5377921644815761], [-0.21041464954927933], [-0.9456723470201753], [-0.221148338563453], [0.47654144735783527], [0.031093353269628116], [-1.0583760816689989], [-1.3750199075871221], [1.732383062016154], [0.9112558524318687], [-0.5860937650453576], [0.25113397806018833], [-0.9134712799776544], [-0.6236616765949654], [1.0668943431373867], [0.6214462490491798], [1.5928451048318963], [-0.8812702129351334], [1.1956986113074708], [-1.0691097706831725], [1.3781713245484228], [-0.18358042701384514], [0.2081992220034936], [-0.011841402787066583], [-1.0261750146264779], [-0.07624353687210851], [-0.6826969661729206], [0.16526446594679892], [-0.006474558279979626], [-1.2891503954737327], [-0.3714199847618843], [-0.12991198194297676], [0.13843024341136487], [0.34773717918775116], [-0.38215367377605797], [0.5248430479216166], [-0.033308780815413934], [-0.07087669236502167], [1.0400601206019526], [-0.253349405605974], [1.544543504268115], [1.1849649222932972], [-3.006540637741519], [-0.7846670118075705], [1.0400601206019526], [-2.6362283667525275], [1.2708344344066866], [0.34773717918775116], [0.10622917636884384], [-0.2855504726484949], [-0.1030777594075427], [-0.9617728805414358], [-1.3481856850516878], [1.6572472389169386], [2.8111188079406073], [-1.664829510969811], [-0.6075611430737049], [0.8897884744035214], [1.7860515070870226], [-1.3964872856154693], [-0.5270584754674025], [1.034693276094866], [-1.3750199075871221], [-0.3714199847618843], [-0.03867562532250065], [-0.8437023013855255], [-0.1191782929288032], [-1.890236980267458], [-0.5968274540595312], [0.07402810932632281], [-1.112044526739867], [1.7001819949736332], [1.9202226197641934], [-0.3875205182831448], [-0.43045527433983943], [1.0078590535594318], [0.14379708791845158], [0.2726013560885357], [-0.1191782929288032], [0.7770847397546979], [-0.5807269205382707], [-0.4036210518044052], [-0.12454513743589005], [-1.4125878191367298], [0.578511492992485], [0.256500822567275], [0.256500822567275], [0.6429136270775271], [-1.0691097706831725], [0.21356606651058035], [-0.5270584754674025], [-0.4572894968752736], [2.1778311561043613], [-1.1335119047682145], [0.6214462490491798], [-0.011841402787066583], [0.26723451158144873], [-0.6397622101162259], [0.5731446484853984], [-0.04404246982958761], [-0.5055910974390552], [-0.006474558279979626], [0.13843024341136487], [0.49264198087909566], [-0.5216916309603157], [-0.3392189177193633], [0.42823984679405386], [0.7717178952476109], [-0.08161038137919535], [1.7914183515941093], [-0.3392189177193633], [-0.1030777594075427], [-0.892003901949307], [1.3567039465200756], [0.15453077693262526], [-0.43582211884692623], [-0.49485740842488146], [-0.10844460391462954], [0.326269801159404], [-1.2408487949099511], [-0.4197215853256657], [0.09549548735467016], [-1.3320851515304273], [0.900522163417695], [0.9273563859531291], [-0.4036210518044052], [-0.9403055025130886], [-0.7470991002579626], [0.19746553298931996], [-2.357152452384012], [-0.39825420729731836], [2.9184556980823437], [0.47654144735783527], [0.014992819748367723], [-0.698797499694181], [0.07939495383340953], [-1.117411371246954], [0.7609842062334372], [-0.04404246982958761], [-0.98860710307687], [1.9363231532854535], [0.47654144735783527], [-0.7793001673004835], [1.190331766800384], [-1.4555225751934244], [0.19746553298931996], [1.3781713245484228], [0.551677270457051], [-1.729231645054853], [-0.3875205182831448], [1.1420301662366026], [0.5302098924287036], [0.3906719352444459], [0.256500822567275], [0.1276965543971912], [-1.2998840844879063], [-0.7470991002579626], [-1.9868401813950207], [0.13843024341136487], [0.3692045572160985], [-0.45192265236818674], [0.0686612648192361], [0.04719388679088875], [1.0722611876444739], [-0.06550984785793483], [-1.0959439932186068], [-0.6182948320878786], [-1.0583760816689989], [-0.9832402585697831], [0.19209868848223324], [-0.5216916309603157], [0.37993824623027217], [-0.5002242529319683], [-0.49485740842488146], [0.4121393132727932], [-0.253349405605974], [0.1598976214397122], [-1.0100744811052174], [-1.1818135053319958], [0.4228730022869669], [-1.1710798163178222], [1.16349754426495], [0.8146526513043056], [-0.2855504726484949], [0.07939495383340953], [-1.0476423926548253], [-0.1352788264500636], [-1.09057714871152], [1.3191360349704682], [-0.9564060360343489], [-0.6826969661729206], [-1.4930904867430321], [1.5499103487752017], [-1.2891503954737327], [0.6536473160917008], [-0.2855504726484949], [0.6643810051058744], [-1.884870135760371], [0.5731446484853984], [1.2547339008854261], [0.5677778039783113], [0.5248430479216166], [0.7931852732759583], [-0.3231183841981028], [-0.8490691458926124], [-1.3481856850516878], [-0.4411889633540131], [-0.2587162501130609], [0.28333504510270935], [-0.6451290546233127], [-0.21578149405636615], [-1.63262844392729], [-0.5002242529319683], [0.31553611214523036], [-1.020808170119391], [-0.9617728805414358], [-0.8115012343430045], [-0.7095311887083547], [-0.4894905639177946], [0.05256073129797546], [3.3692706366776384], [0.07402810932632281], [-0.04404246982958761], [0.6429136270775271], [-0.7202648777225283], [-0.5270584754674025], [0.13843024341136487], [-0.46265634138236045], [0.6375467825704402], [-0.8115012343430045], [-0.859802834906786], [-0.05477615884376128], [-0.19431411602801882], [-0.5753600760311839], [1.1742312332791234], [0.3209029566523171], [0.28333504510270935], [-0.017208247294153302], [-0.4572894968752736], [1.2010654558145575], [0.3906719352444459], [-0.23188202757762666], [-0.510957941946142], [-0.5860937650453576], [-1.4930904867430321], [-1.1764466608249091], [-3.033374860276953], [0.3370034901735777], [-1.187180349839083], [0.3692045572160985], [-0.9510391915272621], [-0.7846670118075705], [-0.634395365609139], [-0.8115012343430045], [-1.2569493284312117], [1.0722611876444739], [-0.34995260673353695], [-0.07087669236502167], [-0.698797499694181], [1.3889050135625969], [0.19209868848223324], [-0.5968274540595312], [0.5677778039783113], [-1.0583760816689989], [-0.2855504726484949], [-1.6111610658989426], [-1.3911204411083824], [-0.28018362814140807], [-1.4179546636438167], [0.224299755524754], [0.7609842062334372], [-1.6970305780123318], [1.1742312332791234], [0.7985521177830452], [-0.17284673799967146], [-0.04940931433667432], [-1.2032808833603432], [-1.273049861952472], [0.6751146941200481], [0.009625975241280766], [1.0668943431373867], [-1.0476423926548253], [-0.46265634138236045], [-0.7095311887083547], [-0.12454513743589005], [0.0686612648192361], [0.7556173617263505], [0.3906719352444459], [-0.7524659447650494], [-0.44655580786109994], [-1.020808170119391], [-0.859802834906786], [-1.187180349839083], [0.7663510507405242], [-0.3875205182831448], [0.33163664566649076], [-0.9081044354705675], [-0.8007675453288309], [0.09549548735467016], [0.256500822567275], [-1.3642862185729483], [0.7126826056696558], [2.945289920617778], [-0.5163247864532288], [0.261867667074362], [-1.3857535966012955], [-1.251582483924125], [-0.2372488720847135], [0.14916393242553852], [-1.562859465335161], [0.40140562425861953], [0.5302098924287036], [-0.5699932315240971], [0.2350334445389277], [-0.8329686123713519], [-0.66659643265166], [0.07939495383340953], [2.6447466282209158], [-0.10844460391462954], [0.3745714017231855], [1.6196793273673304], [-2.3303182298485785], [-0.1030777594075427], [1.3137691904633808], [-0.5646263870170102], [2.6769476952634363], [0.004259130734194047], [0.9488237639814765], [0.5248430479216166], [0.9058890079247818], [-0.40898789631149207], [-0.12454513743589005], [-0.7578327892721363], [-0.11381144842171637], [-0.022575091801240257], [0.3584708682019248], [-0.21041464954927933], [0.5409435814428772], [-0.24261571659180034], [-0.7041643442012678], [-0.7256317222296153], [-2.222981339706841], [1.7538504400445014], [0.7770847397546979], [-0.38215367377605797], [0.1598976214397122], [-0.9617728805414358], [-0.6021942985666181], [0.836120029332653], [1.0454269651090393], [2.360303869345313], [-0.033308780815413934], [1.3084023459562941], [1.544543504268115], [-1.3857535966012955], [0.3584708682019248], [-0.221148338563453], [2.086594799483885], [-0.2372488720847135], [0.8629542518680873], [1.3084023459562941], [0.7824515842617846], [0.9058890079247818], [-0.006474558279979626], [-0.16747989349258463], [-1.273049861952472], [-2.147845516607626], [-1.2998840844879063], [-0.9349386580060016], [0.7019489166554822], [0.3423703346806644], [0.19746553298931996], [0.17063131045388588], [1.3030355014492074], [-0.4572894968752736], [-0.9188381244847412], [-1.251582483924125], [-0.9832402585697831], [1.5767445713106358], [0.7395168282050901], [-0.017208247294153302], [-0.5324253199744892], [0.07939495383340953], [-1.4608894197005111], [-0.10844460391462954], [0.2726013560885357], [0.5355767369357903], [0.3692045572160985], [-0.8651696794138729], [-2.0619760044942366], [0.2726013560885357], [-1.0100744811052174], [-0.1030777594075427], [0.6482804715846138], [0.2779682005956224], [-0.18358042701384514], [-0.022575091801240257], [0.2081992220034936], [-0.36605314025479746], [-1.42868835265799], [3.4927080603406346], [-0.5055910974390552], [1.16349754426495], [-0.8115012343430045], [-0.8437023013855255], [-2.271282940270623], [0.4067724687657065], [1.3567039465200756], [0.5892451820066588], [2.022192665398843], [1.0078590535594318], [-0.6773301216658337], [0.224299755524754], [0.7287831391909165], [1.442573458633465], [0.6643810051058744], [1.3084023459562941], [-0.006474558279979626], [1.217165989335818], [0.38530509073735913], [1.2493670563783392], [-0.6129279875807918], [-0.04404246982958761], [-1.3535525295587747], [-0.8007675453288309], [1.1742312332791234], [-0.15674620447841095], [-1.0047076365981304], [0.05792757580506242], [-0.5968274540595312], [-1.7721664011115474], [-0.09771091490045586], [-1.890236980267458], [0.261867667074362], [-1.6165279104060293], [0.5194762034145299], [1.4908750591972464], [-0.7954007008217441], [-0.37678682926897117], [-1.562859465335161], [0.16526446594679892], [-1.536025242799727], [-0.2372488720847135], [-0.017208247294153302], [-0.12454513743589005], [-0.6182948320878786], [-0.2372488720847135], [-0.9134712799776544], [-1.5145578647713795], [-0.6290285211020523], [0.3370034901735777], [-0.4733900303965341], [-0.7202648777225283], [-0.8168680788500915], [0.16526446594679892], [1.560644037789375], [-0.4894905639177946], [0.7878184287688715], [-0.12454513743589005], [-0.15137935997132412], [-0.8061343898359178], [0.04182704228380179], [-1.3911204411083824], [-1.5413920873068137], [-0.3231183841981028], [-0.3070178506768423], [0.21356606651058035], [-1.4662562642075982], [0.9273563859531291], [-0.8812702129351334], [0.020359664255454442], [-0.1030777594075427], [-0.31775153969101594], [-0.6504958991303996], [1.2976686569421207], [0.5248430479216166], [0.5624109594712247], [-0.1352788264500636], [-0.66659643265166], [-0.5646263870170102], [1.4103723915909443], [0.04182704228380179], [0.6912152276413085], [-0.34995260673353695], [0.17063131045388588], [0.2726013560885357], [-0.9295718134989149], [0.8790547853893477], [1.4050055470838574], [0.6912152276413085], [-2.6093941442170934], [-0.40898789631149207], [-0.027941936308326976], [-0.8061343898359178], [1.8182525741295434], [-0.08161038137919535], [0.05256073129797546], [-0.16747989349258463], [-0.4733900303965341], [0.10622917636884384], [-0.07624353687210851], [0.326269801159404], [-1.7936337791398949], [-0.16211304898549778], [-0.5163247864532288], [2.1617306225831006], [-0.6021942985666181], [0.4228730022869669], [-0.2587162501130609], [0.8897884744035214], [-0.8115012343430045], [-0.27481678363432127], [1.2708344344066866], [-0.3070178506768423], [0.06329442031214914], [-0.022575091801240257], [1.1151959437011685], [0.6751146941200481], [-0.2694499391272344], [-0.1352788264500636], [-0.46802318588944725], [0.326269801159404], [-0.6880638106800073], [0.9488237639814765], [-0.15674620447841095], [0.3906719352444459], [-0.8276017678642651], [-0.5968274540595312], [0.3101692676381434], [-0.5753600760311839], [0.09549548735467016], [-1.1281450602611278], [-0.011841402787066583], [1.093728565672821], [-0.21578149405636615], [0.5355767369357903], [-0.9456723470201753], [0.2081992220034936], [-0.2587162501130609], [0.014992819748367723], [-0.14064567095715044], [-1.7667995566044605], [-0.3123846951839291], [-1.020808170119391], [-1.0476423926548253], [0.7448836727121769], [-0.27481678363432127], [-0.34995260673353695], [-1.2945172399808194], [-1.112044526739867], [0.224299755524754], [-0.17284673799967146], [1.5874782603248097], [-0.8222349233571782], [-0.5270584754674025], [-1.9600059588595866], [-1.3320851515304273], [-0.7846670118075705], [-1.600427376884769], [0.18136499946805956], [0.256500822567275], [-0.8759033684280465], [0.1330633989042779], [-0.7041643442012678], [-1.0261750146264779], [0.3906719352444459], [0.04719388679088875], [-0.08161038137919535], [0.07939495383340953], [1.2654675898995995], [0.04182704228380179], [0.9971253645452581], [-1.4233215081509034], [0.11159602087593055], [-0.9832402585697831], [-1.949272269845413], [1.2762012789137733], [-0.5270584754674025], [1.469407681168899], [0.8146526513043056], [0.21356606651058035], [-0.2587162501130609], [0.809285806797219], [0.19209868848223324], [0.24576713355310137], [0.8146526513043056], [1.17959807778621], [-0.7041643442012678], [0.9756579865169107], [0.7180494501767428], [-0.9725065695556095], [0.10086233186175687], [1.093728565672821], [-0.022575091801240257], [-0.43045527433983943], [0.2081992220034936], [0.3531040236948381], [0.8629542518680873], [1.2064323003216446], [0.4550740693294879], [-0.6826969661729206], [0.261867667074362], [-1.4769899532217718], [-1.1013108377256935], [0.256500822567275], [-1.5574926208280744], [-0.14064567095715044], [0.15453077693262526], [0.9112558524318687], [-0.39825420729731836], [-0.6934306551870943], [0.10086233186175687], [0.6321799380633534], [-0.34458576222645015], [1.8128857296224568], [0.34773717918775116], [-0.2479825610988872], [-0.253349405605974], [1.0668943431373867], [-0.12454513743589005], [-0.5753600760311839], [0.7878184287688715], [1.2547339008854261], [-0.6719632771587469], [0.578511492992485], [-0.3070178506768423], [0.7448836727121769], [-0.16211304898549778], [-0.24261571659180034], [-1.9761064923808473], [-0.221148338563453], [0.9863916755310844], [3.771783974709151], [-0.09234407039336902], [0.21356606651058035], [-1.0959439932186068], [-0.34458576222645015], [-0.8115012343430045], [1.0722611876444739], [-1.0154413256123043], [0.10622917636884384], [0.48190829186492196], [-1.4930904867430321], [-0.16747989349258463], [1.0561606541232131], [-1.627261599420203], [0.8951553189106081], [-2.7972337019651325], [-0.5163247864532288], [0.24576713355310137], [0.29943557862396974], [-0.9778734140626963], [-1.7990006236469818], [-0.09234407039336902], [-1.2247482613886906], [0.04719388679088875], [0.14916393242553852], [-0.060143003350848], [2.446173381458703], [0.6375467825704402], [-0.5968274540595312], [0.5999788710208324], [0.025726508762541397], [1.1742312332791234], [-0.8705365239209597], [-1.079843459697346], [0.4228730022869669], [2.0275595099059296], [-1.246215639417038], [-0.3928873627902317], [-0.4733900303965341], [-1.085210304204433], [0.09549548735467016], [-1.1603461273036486], [-1.1066776822327804], [1.984624753849235], [-0.5592595425099234], [3.0043252101957334], [0.49264198087909566], [-0.44655580786109994], [0.294068734116883], [-1.2891503954737327], [-0.5055910974390552], [-0.28018362814140807], [0.5892451820066588], [-0.8168680788500915], [0.0901286428475832], [-0.9295718134989149], [-1.8687696022391107], [0.19209868848223324], [1.2064323003216446], [-1.3213514625162537], [-0.9081044354705675], [0.2726013560885357], [-0.09771091490045586], [0.11159602087593055], [2.430072847937442], [1.2386333673641654], [-1.0154413256123043], [-1.4018541301225562], [0.3638377127090118], [2.2851680462460977], [-0.04404246982958761], [-0.5485258534957497], [0.46580775834366156], [-1.273049861952472], [-0.5807269205382707], [0.5731446484853984], [1.227899678349992], [0.5355767369357903], [-1.0637429261760858], [0.7448836727121769], [0.6912152276413085], [-0.4036210518044052], [0.12232970989010424], [-1.4662562642075982], [1.2010654558145575], [0.41750615777988015], [0.809285806797219], [-0.7524659447650494], [-0.20504780504219247], [-0.34458576222645015], [1.9202226197641934], [-1.1335119047682145], [0.5087425144003562], [-1.31061777350208], [-0.23188202757762666], [-0.5753600760311839], [0.025726508762541397], [0.7341499836980032], [0.1169628653830175], [0.6804815386271348], [-1.2891503954737327], [0.06329442031214914], [-0.2855504726484949], [-0.9027375909634807], [-0.3231183841981028], [-1.2354819504028642], [-1.0691097706831725], [0.7019489166554822], [-0.31775153969101594], [0.25113397806018833], [-0.16747989349258463], [0.28870188960979604], [-1.4179546636438167], [0.18673184397514628], [1.0776280321515606], [-0.7578327892721363], [-0.033308780815413934], [-0.30165100616975543], [0.6268130935562665], [-0.18358042701384514], [1.1312964772224288], [-1.4984573312501193], [0.004259130734194047], [-0.7256317222296153], [-0.21578149405636615], [0.38530509073735913], [1.3889050135625969], [1.2762012789137733], [0.5731446484853984], [-0.5055910974390552], [0.05256073129797546], [-1.5843268433635083], [1.2654675898995995], [-1.4930904867430321], [0.2726013560885357], [-0.8759033684280465], [0.8307531848255663], [-0.28018362814140807], [0.19746553298931996], [0.15453077693262526], [-0.5324253199744892], [1.694815150466546], [0.3370034901735777], [0.05792757580506242], [-0.28018362814140807], [0.9595574529956501], [-2.1263781385792786], [-0.37678682926897117], [0.8253863403184794], [-1.5306583982926403], [0.44970722482240116], [-0.2962841616626686], [-0.46265634138236045], [-0.8490691458926124], [-1.219381416881604], [-0.43045527433983943], [0.6965820721483954], [0.2189329110176673], [0.3692045572160985], [-0.34458576222645015], [-0.43045527433983943], [1.834353107650804], [-0.7578327892721363], [0.10622917636884384], [2.6340129392067415], [-0.16747989349258463], [0.3209029566523171], [-1.4877236422359454], [-0.6129279875807918], [1.1473970107436893], [-0.253349405605974], [0.8790547853893477], [-1.8741364467461974], [-0.7417322557508758], [-0.31775153969101594], [0.3960387797515328], [-0.8007675453288309], [-0.43045527433983943], [-1.5789599988564216], [-0.12991198194297676], [-1.7238648005477661], [0.18136499946805956], [-0.08697722588628219], [-0.07087669236502167], [0.05256073129797546], [-1.6111610658989426], [-0.9993407920910437], [2.478374448501224], [-1.3803867520942088], [0.9166226969389554], [-0.5324253199744892], [0.014992819748367723], [0.33163664566649076], [-1.0261750146264779], [1.2708344344066866], [0.24040028904601465], [3.6107786394965453], [1.8719210192004114], [0.43360669130114055], [-0.5860937650453576], [0.7502505172192636], [0.8253863403184794], [0.6321799380633534], [1.0400601206019526], [-0.3231183841981028], [1.2762012789137733], [-0.4250884298327526], [0.2081992220034936], [-0.44655580786109994], [3.2136321459721198], [0.18136499946805956], [1.28156812342086], [0.8039189622901319], [-1.053009237161912], [-1.5306583982926403], [0.10622917636884384], [-0.27481678363432127], [0.9702911420098238], [0.42823984679405386], [0.29943557862396974], [-3.387586597744684], [-0.5324253199744892], [-1.122778215754041], [0.3101692676381434], [1.1473970107436893], [-0.5324253199744892], [0.5248430479216166], [-0.9725065695556095], [-0.08161038137919535], [0.49264198087909566], [0.036460197776715074], [-0.19431411602801882], [-2.19078027266432], [-0.04404246982958761], [-0.2909173171555818], [0.5194762034145299], [1.5928451048318963], [-0.5055910974390552], [-0.5646263870170102], [0.6375467825704402], [-0.060143003350848], [-0.34458576222645015], [-0.4894905639177946], [0.22966660003184097], [-0.4894905639177946], [0.7180494501767428], [-1.0154413256123043], [-0.6075611430737049], [-0.5431590089886629], [-0.7900338563146572], [0.0686612648192361], [0.8146526513043056], [-1.4179546636438167], [0.5677778039783113], [-0.7846670118075705], [-0.37678682926897117], [-0.006474558279979626], [0.294068734116883], [-1.600427376884769], [1.2493670563783392], [0.9058890079247818], [0.3584708682019248], [2.623279250192568], [1.8021520406082827], [-0.15674620447841095], [0.0686612648192361], [1.8182525741295434], [-0.5914606095524444], [2.5803444941358737], [0.1330633989042779], [-0.4143547408185789], [0.8897884744035214], [-0.7256317222296153], [1.3459702575059023], [-0.8759033684280465], [1.5123424372255938], [0.44970722482240116], [-1.4018541301225562], [0.19746553298931996], [-0.8437023013855255], [-0.5860937650453576], [-0.7846670118075705], [-0.4143547408185789], [-0.38215367377605797], [0.47654144735783527], [0.809285806797219], [-1.0315418591335648], [0.8575874073610004], [-0.8383354568784387], [-0.2962841616626686], [-0.892003901949307], [0.7609842062334372], [0.5033756698932693], [-0.4894905639177946], [-0.9027375909634807], [1.6357798608885912], [-0.04940931433667432], [-3.1138775278832553], [-0.09234407039336902], [-0.892003901949307], [-0.18894727152093196], [-0.38215367377605797], [0.43360669130114055], [1.9202226197641934], [-0.8168680788500915], [-2.0244080929446286], [-0.05477615884376128], [1.1742312332791234], [0.18136499946805956], [-0.4197215853256657], [-0.9993407920910437], [-0.16211304898549778], [-0.10844460391462954], [0.37993824623027217], [-0.5968274540595312], [-0.4572894968752736], [1.3889050135625969], [-0.4733900303965341], [0.7663510507405242], [-0.6075611430737049], [1.517709281732681], [1.5874782603248097], [-0.19431411602801882], [-0.9725065695556095], [0.8146526513043056], [-0.5807269205382707], [0.3209029566523171], [-0.08697722588628219], [-0.221148338563453], [-2.265916095763536], [-0.4143547408185789], [0.5302098924287036], [-0.2855504726484949], [-1.1281450602611278], [1.093728565672821], [0.3584708682019248], [-0.03867562532250065], [0.3101692676381434], [-0.6021942985666181], [2.0651274214555375], [-0.8544359903996992], [-0.7631996337792231], [1.3835381690555102], [-0.3714199847618843], [-0.6129279875807918], [3.0526268107595147], [1.0454269651090393], [-0.7631996337792231], [2.8325861859689545], [0.26723451158144873], [-1.219381416881604], [0.6536473160917008], [1.442573458633465], [-0.08697722588628219], [0.5409435814428772], [1.8880215527216722], [-2.7167310343588302], [0.6429136270775271], [-0.7202648777225283], [0.6214462490491798], [0.2350334445389277], [1.4050055470838574], [-1.1496124382894748], [-0.5646263870170102], [-0.8222349233571782], [-0.10844460391462954], [1.480141370183073], [-0.7954007008217441], [0.4872751363720089], [-0.05477615884376128], [-0.9349386580060016], [1.8236194186366301], [0.014992819748367723], [0.2350334445389277], [0.1598976214397122], [-0.03867562532250065], [0.3906719352444459], [0.294068734116883], [0.7073157611625691], [-2.845535302528914], [-0.3875205182831448], [1.6250461718744171], [-1.3911204411083824], [-0.859802834906786], [-1.9546391143525], [0.1276965543971912], [-0.7631996337792231], [1.034693276094866], [1.3030355014492074], [-0.3928873627902317], [0.583878337499572], [-2.367886141398186], [-0.2694499391272344], [-0.27481678363432127], [0.2726013560885357], [-0.1191782929288032], [-0.221148338563453], [3.0418931217453413], [-0.859802834906786], [1.6196793273673304], [0.8522205628539136], [0.9595574529956501], [1.2654675898995995], [1.8719210192004114], [-0.46802318588944725], [0.4228730022869669], [0.13843024341136487], [1.1742312332791234], [0.3423703346806644], [-0.7363654112437888], [-0.4143547408185789], [-0.22651518307053983], [1.0132258980665185], [-0.7256317222296153], [-1.0315418591335648], [-0.7578327892721363], [-2.7006305008375695], [-0.011841402787066583], [-0.9564060360343489], [-0.634395365609139], [-1.117411371246954], [0.42823984679405386], [1.2332665228570787], [-1.890236980267458], [-0.40898789631149207], [0.11159602087593055], [1.0132258980665185], [-1.085210304204433], [0.6375467825704402], [0.05256073129797546], [-0.38215367377605797], [-0.5002242529319683], [-0.5377921644815761], [0.7824515842617846], [-1.1013108377256935], [0.7448836727121769], [0.7824515842617846], [0.9702911420098238], [1.0722611876444739], [2.2422332901894033], [0.9058890079247818], [0.24576713355310137], [-2.7703994794296984], [-0.08697722588628219], [-0.006474558279979626], [-1.4877236422359454], [-0.27481678363432127], [-1.8473022242107633], [-0.5324253199744892], [0.07402810932632281], [-0.8705365239209597], [0.10086233186175687], [0.8951553189106081], [-0.2962841616626686], [-0.31775153969101594], [-0.0011077137728929085], [-0.7578327892721363], [-0.9832402585697831], [0.020359664255454442], [-0.7148980332154415], [1.1312964772224288], [-0.4411889633540131], [-0.8973707464563939], [-0.26408309462014756], [-0.8329686123713519], [-0.9134712799776544], [-0.6773301216658337], [2.6769476952634363], [-1.3642862185729483], [0.6965820721483954], [-1.9117043582958053], [1.217165989335818], [0.2028323774964069], [2.564243960614613], [-0.7256317222296153], [-0.47875687490362095], [1.2708344344066866], [1.6304130163815045], [-0.07087669236502167], [-0.18894727152093196], [0.10086233186175687], [0.224299755524754], [0.5892451820066588], [0.04182704228380179], [-0.3123846951839291], [-0.8705365239209597], [2.1617306225831006], [1.0185927425736052], [0.1759981549609726], [-0.7095311887083547], [-1.0154413256123043], [-0.5163247864532288], [-1.278416706459559], [-0.006474558279979626], [-0.4036210518044052], [-1.0637429261760858], [-0.3392189177193633], [0.5946120265137457], [-0.47875687490362095], [0.6375467825704402], [-1.3481856850516878], [0.7717178952476109], [-0.6719632771587469], [-1.7560658675902872], [1.415739236098031], [1.2547339008854261], [0.3423703346806644], [0.7502505172192636], [0.1276965543971912], [1.1473970107436893], [-0.19431411602801882], [-0.7202648777225283], [-0.8007675453288309], [-0.6880638106800073], [-0.14601251546423727], [2.3817712473736607], [-0.5216916309603157], [0.2028323774964069], [-1.0315418591335648], [-0.38215367377605797], [0.8146526513043056], [0.5892451820066588], [-0.5699932315240971], [0.004259130734194047], [-0.44655580786109994], [-0.221148338563453], [1.3942718580696836], [-0.7256317222296153], [-0.5377921644815761], [-0.04404246982958761], [1.0829948766586472], [0.031093353269628116], [1.1205627882082552], [0.3692045572160985], [0.551677270457051], [1.7377499065232407], [0.3638377127090118], [0.34773717918775116], [0.14379708791845158], [1.1098290991940813], [1.4211060806051177], [0.0686612648192361], [-0.30165100616975543], [0.24040028904601465], [0.5355767369357903], [1.480141370183073], [-1.63262844392729], [-1.4823567977288585], [0.551677270457051], [-0.49485740842488146], [1.5230761262397676], [-0.7739333227933968], [-1.3481856850516878], [0.10622917636884384], [-0.03867562532250065], [-0.5055910974390552], [0.11159602087593055], [-0.27481678363432127], [-0.9564060360343489], [0.6912152276413085], [-1.0047076365981304], [1.1312964772224288], [-0.32848522870518965], [1.1956986113074708], [0.9112558524318687], [-0.6612295881445733], [0.7985521177830452], [-0.7900338563146572], [0.49264198087909566], [0.1598976214397122], [-0.7417322557508758], [0.2726013560885357], [-0.2587162501130609], [0.326269801159404], [0.11159602087593055], [3.0257925882240806], [-0.7578327892721363], [0.22966660003184097], [-0.6075611430737049], [-0.5163247864532288], [0.014992819748367723], [-1.9224380473099787], [0.1598976214397122], [0.020359664255454442], [0.5731446484853984], [-0.9725065695556095], [0.28333504510270935], [-2.37861983041236], [0.1598976214397122], [0.8307531848255663], [0.036460197776715074], [0.6268130935562665], [2.3066354242744453], [-0.8490691458926124], [-0.5216916309603157], [0.08476179834049649], [-0.5324253199744892], [1.0668943431373867], [0.3209029566523171], [0.6214462490491798], [-0.5968274540595312], [0.8468537183468267], [0.09549548735467016], [-0.34995260673353695], [0.326269801159404], [-0.006474558279979626], [-0.6719632771587469], [-0.3123846951839291], [-0.5377921644815761], [0.6268130935562665], [-1.5252915537855531], [2.6769476952634363], [0.6912152276413085], [-0.5699932315240971], [0.15453077693262526], [-0.9510391915272621], [-2.4805898760470093], [-0.7256317222296153], [-0.7739333227933968], [-0.9403055025130886], [-0.9832402585697831], [-0.9188381244847412], [-0.9456723470201753], [0.5355767369357903], [-1.273049861952472], [-0.09234407039336902], [-2.1263781385792786], [-1.3481856850516878], [-1.3267183070233404], [-1.0959439932186068], [-0.6021942985666181], [-0.8812702129351334], [0.26723451158144873], [1.6143124828602438], [1.1581306997578626], [0.7019489166554822], [0.5302098924287036], [-0.5216916309603157], [0.8844216298964344], [-0.06550984785793483], [-0.18358042701384514], [-0.006474558279979626], [-0.5753600760311839], [2.623279250192568], [-1.5199247092784662], [-0.3231183841981028], [-1.3911204411083824], [0.15453077693262526], [0.7341499836980032], [-0.24261571659180034], [0.08476179834049649], [-0.9993407920910437], [-0.6504958991303996], [1.6196793273673304], [-0.38215367377605797], [-0.26408309462014756], [0.8039189622901319], [0.4980088253861826], [0.2726013560885357], [-1.3481856850516878], [2.2529669792035767], [1.3728044800413362], [2.1563637780760136], [-0.6182948320878786], [0.6697478496129612], [-0.27481678363432127], [-0.5324253199744892], [-1.369653063080035], [0.5033756698932693], [-1.0154413256123043], [-1.0583760816689989], [0.3745714017231855], [-0.44655580786109994], [0.29943557862396974], [0.4980088253861826], [0.5677778039783113], [0.5087425144003562], [0.47654144735783527], [-0.9510391915272621], [-0.19431411602801882], [-0.1352788264500636], [0.7502505172192636], [-0.05477615884376128], [1.2332665228570787], [1.28156812342086], [0.48190829186492196], [-2.0458754709729763], [0.18673184397514628], [-0.17284673799967146], [0.5731446484853984], [0.4550740693294879], [0.6375467825704402], [0.1759981549609726], [0.04182704228380179], [0.3692045572160985], [-0.7524659447650494], [-1.085210304204433], [0.7395168282050901], [-0.6558627436374863], [-0.23188202757762666], [1.3298697239846415], [0.24576713355310137], [-1.8365685351965895], [-0.7631996337792231], [-0.6719632771587469], [-1.664829510969811], [-0.07087669236502167], [-0.11381144842171637], [-1.3857535966012955], [-0.6129279875807918], [-0.6236616765949654], [-1.3213514625162537], [2.032926354413017], [-1.7238648005477661], [0.3692045572160985], [-1.8473022242107633], [0.2350334445389277], [-2.0834433825225838], [0.16526446594679892], [-0.20504780504219247], [-0.8973707464563939], [1.1742312332791234], [0.3638377127090118], [0.3370034901735777], [0.3423703346806644], [0.8039189622901319], [-0.7256317222296153], [-0.7846670118075705], [-0.44655580786109994], [-0.2694499391272344], [-0.5431590089886629], [-0.33385207321227645], [-1.5896936878705954], [-1.0369087036406515], [-0.2479825610988872], [0.873687940882261], [1.9041220862429327], [-0.08697722588628219], [-0.04940931433667432], [0.8146526513043056], [0.29943557862396974], [0.4550740693294879], [0.49264198087909566], [0.48190829186492196], [-0.9403055025130886], [0.5946120265137457], [0.15453077693262526], [0.031093353269628116], [-1.7990006236469818], [2.1026953330051454], [1.9577905313138009], [0.43360669130114055], [-0.033308780815413934], [0.6375467825704402], [0.13843024341136487], [-0.15137935997132412], [-0.7363654112437888], [0.836120029332653], [-0.5968274540595312], [-0.2587162501130609], [0.7770847397546979], [-1.729231645054853], [-1.0369087036406515], [-0.19968096053510564], [-1.6970305780123318], [-0.6826969661729206], [-0.30165100616975543], [0.4980088253861826], [-0.23188202757762666], [0.10086233186175687], [-0.5163247864532288], [-1.4930904867430321], [-0.6504958991303996], [0.34773717918775116], [0.43360669130114055], [-0.6021942985666181], [-1.8687696022391107], [0.5570441149641376], [0.009625975241280766], [-1.0422755481477384], [0.31553611214523036], [-0.4572894968752736], [-0.7202648777225283], [-0.8383354568784387], [0.6858483831342218], [-0.22651518307053983], [0.10086233186175687], [-0.03867562532250065], [0.2779682005956224], [-0.1782135825067583], [-0.3714199847618843], [0.7878184287688715], [1.7645841290586752], [-0.8490691458926124], [-0.0011077137728929085], [0.8468537183468267], [0.6321799380633534], [-0.19968096053510564], [-0.09771091490045586], [-0.6826969661729206], [-0.6021942985666181], [-0.08161038137919535], [-0.6612295881445733], [-0.9027375909634807], [0.4228730022869669], [0.578511492992485], [0.2189329110176673], [0.5194762034145299], [-0.6719632771587469], [-0.23188202757762666], [-0.4572894968752736], [-1.9868401813950207], [1.6465135499027646], [-1.251582483924125], [-1.788266934632808], [-0.033308780815413934], [0.13843024341136487], [0.49264198087909566], [-2.19078027266432], [-0.7256317222296153], [0.4389735358082275], [-0.8383354568784387], [-0.9188381244847412], [-2.4430219644974014], [-0.4411889633540131], [0.6107125600350061], [0.24040028904601465], [-1.0422755481477384], [-0.9939739475839569], [-0.12454513743589005], [1.1312964772224288], [0.7019489166554822], [0.836120029332653], [-0.7631996337792231], [1.5821114158177225], [-0.39825420729731836], [1.8397199521578906], [-0.7846670118075705], [0.014992819748367723], [-0.8222349233571782], [0.4389735358082275], [-0.37678682926897117], [0.04182704228380179], [0.47654144735783527], [-0.21041464954927933], [0.05792757580506242], [-0.39825420729731836], [0.7019489166554822], [-2.39472036393362], [0.14379708791845158], [0.326269801159404], [-0.8812702129351334], [-0.7095311887083547], [0.3960387797515328], [0.05792757580506242], [-0.22651518307053983], [0.5999788710208324], [0.009625975241280766], [-0.12454513743589005], [-0.006474558279979626], [0.0686612648192361], [-1.884870135760371], [0.05792757580506242], [0.020359664255454442], [-0.027941936308326976], [0.1169628653830175], [0.2081992220034936], [-0.7095311887083547], [0.3048024231310567], [0.6375467825704402], [0.47654144735783527], [-0.5216916309603157], [2.8540535639973017], [0.9058890079247818], [2.655480317235089], [-1.5145578647713795], [-0.027941936308326976], [-1.369653063080035], [1.2601007453925128], [1.1581306997578626], [1.2010654558145575], [-0.20504780504219247], [-0.6236616765949654], [-0.15674620447841095], [-0.060143003350848], [-2.169312894635973], [-0.6182948320878786], [-0.8544359903996992], [-0.21578149405636615], [0.7609842062334372], [-0.5699932315240971], [1.1205627882082552], [-0.08161038137919535], [-0.31775153969101594], [-0.3231183841981028], [-0.5753600760311839], [0.9702911420098238], [-0.011841402787066583], [0.5409435814428772], [-0.7148980332154415], [0.5946120265137457], [-0.3928873627902317], [0.6375467825704402], [2.24760013469649], [1.0722611876444739], [-0.6290285211020523], [-0.4841237194107078], [0.8629542518680873], [-0.27481678363432127], [-0.19968096053510564], [-1.3964872856154693], [-0.033308780815413934], [0.4228730022869669], [-2.0888102270296707], [-0.45192265236818674], [-1.7829000901257213], [0.7126826056696558], [2.016825820891756], [-1.7238648005477661], [-1.2623161729382986], [-0.4197215853256657], [-0.5431590089886629], [1.0185927425736052], [0.0686612648192361], [0.7234162946838295], [0.19209868848223324], [1.2064323003216446], [0.583878337499572], [0.2189329110176673], [-1.4877236422359454], [-1.0047076365981304], [0.326269801159404], [-0.9242049689918279], [-0.1352788264500636], [-0.27481678363432127], [-0.44655580786109994], [-0.060143003350848], [0.10086233186175687], [-1.2032808833603432], [0.3370034901735777], [0.6053457155279194], [-0.9188381244847412], [0.3209029566523171], [0.05792757580506242], [-0.9993407920910437], [-0.017208247294153302], [-0.3231183841981028], [-0.44655580786109994], [0.46044091383657487], [0.9434569194743897], [-0.5646263870170102], [-1.8580359132249369], [-0.2587162501130609], [-0.7793001673004835], [0.10086233186175687], [-0.5216916309603157], [-0.9778734140626963], [-0.6075611430737049], [-1.7077642670265056], [1.152763855250776], [-0.253349405605974], [-1.144245593782388], [0.3692045572160985], [-0.5163247864532288], [0.5033756698932693], [0.036460197776715074], [-0.07087669236502167], [-0.892003901949307], [-1.0154413256123043], [-0.6773301216658337], [-0.7148980332154415], [-0.634395365609139], [-0.7041643442012678], [-0.060143003350848], [-0.3928873627902317], [-0.38215367377605797], [-0.08697722588628219], [-0.15137935997132412], [-0.5968274540595312], [-0.6236616765949654], [0.5946120265137457], [0.04719388679088875], [-0.23188202757762666], [-2.0619760044942366], [-0.10844460391462954], [0.38530509073735913], [-1.6487289774485503], [0.28870188960979604], [-0.6880638106800073], [-0.022575091801240257], [0.4980088253861826], [-0.8276017678642651], [-0.027941936308326976], [0.8200194958113926], [0.7609842062334372], [-1.3267183070233404], [0.9273563859531291], [0.4443403803153142], [-0.9671397250485226], [-0.3553194512406238], [0.2189329110176673], [0.4443403803153142], [-0.510957941946142], [0.07402810932632281], [2.0812279549767982], [-0.39825420729731836], [0.6697478496129612], [-0.04404246982958761], [-1.5091910202642929], [1.6250461718744171], [2.596445027657134], [1.9309563087783668], [0.13843024341136487], [-0.9778734140626963], [-0.18358042701384514], [-0.6021942985666181], [2.8272193414618676], [-0.4733900303965341], [0.8253863403184794], [0.4980088253861826], [-0.027941936308326976], [-0.23188202757762666], [2.864787253011476], [-1.31061777350208], [-0.34458576222645015], [0.15453077693262526], [0.9595574529956501], [1.2708344344066866], [0.020359664255454442], [-0.15137935997132412], [0.47654144735783527], [-1.2891503954737327], [-0.09771091490045586], [0.5624109594712247], [1.2762012789137733], [0.7717178952476109], [1.7484835955374145], [-1.536025242799727], [0.5892451820066588], [1.0400601206019526], [-0.8651696794138729], [1.5713777268035491], [0.24040028904601465], [-0.6182948320878786], [-0.9403055025130886], [-0.10844460391462954], [-0.5055910974390552], [0.8629542518680873], [-0.06550984785793483], [0.7985521177830452], [-0.7417322557508758], [0.261867667074362], [-0.2855504726484949], [-0.892003901949307], [1.1473970107436893], [0.10622917636884384], [0.11159602087593055], [0.5194762034145299], [2.1617306225831006], [1.0400601206019526], [-0.9993407920910437], [0.6697478496129612], [3.0257925882240806], [-0.634395365609139], [0.07939495383340953], [-0.6075611430737049], [0.261867667074362], [-0.22651518307053983], [0.0686612648192361], [0.6965820721483954], [1.2493670563783392], [-1.4555225751934244], [-0.5431590089886629], [-0.6290285211020523], [0.24040028904601465], [0.47654144735783527], [-0.060143003350848], [-2.426921430976141], [-0.20504780504219247], [-0.7846670118075705]]
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,901
Moving model to cuda
Epoch 0
Train function
Loss = 2.0714e-02, PNorm = 35.0667, GNorm = 4.7171, lr_0 = 1.2829e-04
Loss = 1.7292e-02, PNorm = 35.0696, GNorm = 7.0817, lr_0 = 1.5400e-04
Loss = 1.0808e-02, PNorm = 35.0742, GNorm = 3.3950, lr_0 = 1.7971e-04
Loss = 1.0189e-02, PNorm = 35.0797, GNorm = 6.8625, lr_0 = 2.0543e-04
Loss = 1.0166e-02, PNorm = 35.0857, GNorm = 13.0125, lr_0 = 2.3114e-04
Loss = 8.4264e-03, PNorm = 35.0917, GNorm = 7.1172, lr_0 = 2.5686e-04
Loss = 7.7868e-03, PNorm = 35.0990, GNorm = 8.4367, lr_0 = 2.8257e-04
Loss = 7.1268e-03, PNorm = 35.1052, GNorm = 7.1166, lr_0 = 3.0829e-04
Loss = 6.0049e-03, PNorm = 35.1120, GNorm = 1.5995, lr_0 = 3.3400e-04
Loss = 5.8448e-03, PNorm = 35.1226, GNorm = 1.8465, lr_0 = 3.5971e-04
Loss = 6.0176e-03, PNorm = 35.1355, GNorm = 6.7717, lr_0 = 3.8543e-04
Loss = 4.2996e-03, PNorm = 35.1475, GNorm = 6.9488, lr_0 = 4.1114e-04
Loss = 5.0011e-03, PNorm = 35.1614, GNorm = 5.8770, lr_0 = 4.3686e-04
Loss = 4.3249e-03, PNorm = 35.1761, GNorm = 4.9064, lr_0 = 4.6257e-04
Loss = 5.4793e-03, PNorm = 35.1936, GNorm = 3.2304, lr_0 = 4.8829e-04
Loss = 4.2587e-03, PNorm = 35.2130, GNorm = 1.9788, lr_0 = 5.1400e-04
Loss = 4.8040e-03, PNorm = 35.2265, GNorm = 8.0182, lr_0 = 5.3971e-04
Validation rmse = 0.945391
Validation R2 = 0.751991
Epoch 1
Train function
Loss = 5.0888e-03, PNorm = 35.2419, GNorm = 4.4947, lr_0 = 5.6800e-04
Loss = 4.1618e-03, PNorm = 35.2595, GNorm = 1.0753, lr_0 = 5.9371e-04
Loss = 3.4494e-03, PNorm = 35.2807, GNorm = 1.5973, lr_0 = 6.1943e-04
Loss = 3.3442e-03, PNorm = 35.3012, GNorm = 1.4038, lr_0 = 6.4514e-04
Loss = 3.0003e-03, PNorm = 35.3245, GNorm = 3.9111, lr_0 = 6.7086e-04
Loss = 4.0036e-03, PNorm = 35.3566, GNorm = 2.3255, lr_0 = 6.9657e-04
Loss = 3.3012e-03, PNorm = 35.3871, GNorm = 3.4952, lr_0 = 7.2229e-04
Loss = 3.8308e-03, PNorm = 35.4137, GNorm = 3.6712, lr_0 = 7.4800e-04
Loss = 3.4168e-03, PNorm = 35.4447, GNorm = 0.9129, lr_0 = 7.7371e-04
Loss = 3.2290e-03, PNorm = 35.4779, GNorm = 1.5189, lr_0 = 7.9943e-04
Loss = 3.9214e-03, PNorm = 35.5103, GNorm = 1.0882, lr_0 = 8.2514e-04
Loss = 3.2833e-03, PNorm = 35.5459, GNorm = 0.8669, lr_0 = 8.5086e-04
Loss = 2.5657e-03, PNorm = 35.5747, GNorm = 1.1915, lr_0 = 8.7657e-04
Loss = 2.6910e-03, PNorm = 35.6062, GNorm = 1.8981, lr_0 = 9.0229e-04
Loss = 3.1974e-03, PNorm = 35.6414, GNorm = 3.2493, lr_0 = 9.2800e-04
Loss = 2.4626e-03, PNorm = 35.6671, GNorm = 1.5822, lr_0 = 9.5371e-04
Loss = 2.7872e-03, PNorm = 35.6886, GNorm = 1.2606, lr_0 = 9.7943e-04
Loss = 2.3683e-03, PNorm = 35.7150, GNorm = 1.5761, lr_0 = 9.9973e-04
Validation rmse = 0.678620
Validation R2 = 0.872210
Epoch 2
Train function
Loss = 2.2549e-03, PNorm = 35.7518, GNorm = 2.0097, lr_0 = 9.9839e-04
Loss = 2.5321e-03, PNorm = 35.7861, GNorm = 2.4847, lr_0 = 9.9705e-04
Loss = 2.6153e-03, PNorm = 35.8254, GNorm = 0.6531, lr_0 = 9.9571e-04
Loss = 2.7123e-03, PNorm = 35.8455, GNorm = 3.8685, lr_0 = 9.9438e-04
Loss = 2.8215e-03, PNorm = 35.8760, GNorm = 2.4712, lr_0 = 9.9304e-04
Loss = 2.7413e-03, PNorm = 35.9061, GNorm = 1.0215, lr_0 = 9.9171e-04
Loss = 3.1968e-03, PNorm = 35.9322, GNorm = 1.0714, lr_0 = 9.9038e-04
Loss = 2.6974e-03, PNorm = 35.9611, GNorm = 0.9102, lr_0 = 9.8905e-04
Loss = 2.1177e-03, PNorm = 35.9833, GNorm = 1.0272, lr_0 = 9.8772e-04
Loss = 2.3807e-03, PNorm = 36.0078, GNorm = 2.2802, lr_0 = 9.8640e-04
Loss = 2.2945e-03, PNorm = 36.0257, GNorm = 0.6471, lr_0 = 9.8508e-04
Loss = 2.0595e-03, PNorm = 36.0531, GNorm = 0.7731, lr_0 = 9.8375e-04
Loss = 2.8007e-03, PNorm = 36.0798, GNorm = 2.7372, lr_0 = 9.8243e-04
Loss = 2.8416e-03, PNorm = 36.1003, GNorm = 1.3320, lr_0 = 9.8112e-04
Loss = 2.3709e-03, PNorm = 36.1342, GNorm = 1.2904, lr_0 = 9.7980e-04
Loss = 2.6184e-03, PNorm = 36.1657, GNorm = 2.7077, lr_0 = 9.7848e-04
Loss = 2.0045e-03, PNorm = 36.1938, GNorm = 0.8423, lr_0 = 9.7717e-04
Validation rmse = 0.630876
Validation R2 = 0.889558
Epoch 3
Train function
Loss = 2.1722e-03, PNorm = 36.2160, GNorm = 1.2052, lr_0 = 9.7573e-04
Loss = 1.7063e-03, PNorm = 36.2395, GNorm = 1.0244, lr_0 = 9.7442e-04
Loss = 2.1713e-03, PNorm = 36.2586, GNorm = 1.5676, lr_0 = 9.7311e-04
Loss = 2.0870e-03, PNorm = 36.2869, GNorm = 2.5874, lr_0 = 9.7181e-04
Loss = 1.7822e-03, PNorm = 36.3040, GNorm = 1.9499, lr_0 = 9.7050e-04
Loss = 2.1393e-03, PNorm = 36.3305, GNorm = 2.7333, lr_0 = 9.6920e-04
Loss = 1.9687e-03, PNorm = 36.3519, GNorm = 1.1072, lr_0 = 9.6790e-04
Loss = 2.1665e-03, PNorm = 36.3742, GNorm = 1.3449, lr_0 = 9.6660e-04
Loss = 2.0739e-03, PNorm = 36.3999, GNorm = 1.2602, lr_0 = 9.6531e-04
Loss = 2.1504e-03, PNorm = 36.4311, GNorm = 1.6365, lr_0 = 9.6401e-04
Loss = 2.0064e-03, PNorm = 36.4553, GNorm = 0.8059, lr_0 = 9.6272e-04
Loss = 1.9359e-03, PNorm = 36.4690, GNorm = 1.1273, lr_0 = 9.6143e-04
Loss = 1.9201e-03, PNorm = 36.4956, GNorm = 0.5581, lr_0 = 9.6014e-04
Loss = 2.1426e-03, PNorm = 36.5209, GNorm = 0.9407, lr_0 = 9.5885e-04
Loss = 1.9845e-03, PNorm = 36.5376, GNorm = 1.3455, lr_0 = 9.5756e-04
Loss = 1.9648e-03, PNorm = 36.5540, GNorm = 1.9392, lr_0 = 9.5628e-04
Loss = 1.9642e-03, PNorm = 36.5745, GNorm = 0.6492, lr_0 = 9.5499e-04
Loss = 1.6309e-03, PNorm = 36.5979, GNorm = 1.3015, lr_0 = 9.5371e-04
Validation rmse = 0.588828
Validation R2 = 0.903790
Epoch 4
Train function
Loss = 1.8432e-03, PNorm = 36.6281, GNorm = 1.6634, lr_0 = 9.5243e-04
Loss = 1.7894e-03, PNorm = 36.6529, GNorm = 0.7975, lr_0 = 9.5115e-04
Loss = 1.6748e-03, PNorm = 36.6810, GNorm = 1.4302, lr_0 = 9.4988e-04
Loss = 1.5788e-03, PNorm = 36.6980, GNorm = 0.6322, lr_0 = 9.4860e-04
Loss = 1.6300e-03, PNorm = 36.7143, GNorm = 1.6152, lr_0 = 9.4733e-04
Loss = 1.4243e-03, PNorm = 36.7427, GNorm = 0.9620, lr_0 = 9.4606e-04
Loss = 1.5554e-03, PNorm = 36.7735, GNorm = 0.8238, lr_0 = 9.4479e-04
Loss = 1.9938e-03, PNorm = 36.7939, GNorm = 0.7918, lr_0 = 9.4352e-04
Loss = 1.8720e-03, PNorm = 36.8247, GNorm = 2.1159, lr_0 = 9.4226e-04
Loss = 1.7720e-03, PNorm = 36.8432, GNorm = 3.0010, lr_0 = 9.4099e-04
Loss = 1.9411e-03, PNorm = 36.8723, GNorm = 2.2569, lr_0 = 9.3973e-04
Loss = 1.5792e-03, PNorm = 36.9041, GNorm = 0.5253, lr_0 = 9.3847e-04
Loss = 1.7395e-03, PNorm = 36.9325, GNorm = 0.7221, lr_0 = 9.3721e-04
Loss = 1.5651e-03, PNorm = 36.9564, GNorm = 0.5993, lr_0 = 9.3595e-04
Loss = 1.7400e-03, PNorm = 36.9841, GNorm = 0.8281, lr_0 = 9.3470e-04
Loss = 1.5161e-03, PNorm = 37.0119, GNorm = 0.6283, lr_0 = 9.3344e-04
Loss = 1.6646e-03, PNorm = 37.0339, GNorm = 0.9545, lr_0 = 9.3219e-04
Validation rmse = 0.543950
Validation R2 = 0.917896
Epoch 5
Train function
Loss = 1.3116e-03, PNorm = 37.0396, GNorm = 0.7273, lr_0 = 9.3094e-04
Loss = 1.4027e-03, PNorm = 37.0605, GNorm = 1.7158, lr_0 = 9.2969e-04
Loss = 1.9709e-03, PNorm = 37.0935, GNorm = 1.4835, lr_0 = 9.2844e-04
Loss = 1.6999e-03, PNorm = 37.1642, GNorm = 0.8659, lr_0 = 9.2720e-04
Loss = 1.6856e-03, PNorm = 37.2105, GNorm = 2.6538, lr_0 = 9.2595e-04
Loss = 1.7645e-03, PNorm = 37.2553, GNorm = 1.5602, lr_0 = 9.2471e-04
Loss = 1.7834e-03, PNorm = 37.2964, GNorm = 1.0150, lr_0 = 9.2347e-04
Loss = 1.7880e-03, PNorm = 37.3362, GNorm = 0.6107, lr_0 = 9.2223e-04
Loss = 1.6211e-03, PNorm = 37.3672, GNorm = 0.4857, lr_0 = 9.2099e-04
Loss = 1.7612e-03, PNorm = 37.3803, GNorm = 0.4414, lr_0 = 9.1976e-04
Loss = 1.8526e-03, PNorm = 37.4088, GNorm = 2.4534, lr_0 = 9.1852e-04
Loss = 1.8504e-03, PNorm = 37.4403, GNorm = 0.6090, lr_0 = 9.1729e-04
Loss = 1.7659e-03, PNorm = 37.4632, GNorm = 1.1322, lr_0 = 9.1606e-04
Loss = 1.5262e-03, PNorm = 37.4798, GNorm = 1.0674, lr_0 = 9.1483e-04
Loss = 1.9359e-03, PNorm = 37.5028, GNorm = 2.5040, lr_0 = 9.1360e-04
Loss = 1.3221e-03, PNorm = 37.5265, GNorm = 1.3805, lr_0 = 9.1238e-04
Loss = 1.4248e-03, PNorm = 37.5534, GNorm = 0.3940, lr_0 = 9.1115e-04
Loss = 1.4636e-03, PNorm = 37.5677, GNorm = 1.6556, lr_0 = 9.0993e-04
Validation rmse = 0.545573
Validation R2 = 0.917406
Epoch 6
Train function
Loss = 1.3357e-03, PNorm = 37.5891, GNorm = 0.7528, lr_0 = 9.0859e-04
Loss = 1.2405e-03, PNorm = 37.6184, GNorm = 0.4666, lr_0 = 9.0737e-04
Loss = 1.3016e-03, PNorm = 37.6359, GNorm = 0.8303, lr_0 = 9.0615e-04
Loss = 9.2140e-04, PNorm = 37.6595, GNorm = 0.4776, lr_0 = 9.0494e-04
Loss = 1.3763e-03, PNorm = 37.6896, GNorm = 1.5351, lr_0 = 9.0372e-04
Loss = 1.2701e-03, PNorm = 37.7081, GNorm = 0.7609, lr_0 = 9.0251e-04
Loss = 1.1844e-03, PNorm = 37.7331, GNorm = 1.1715, lr_0 = 9.0130e-04
Loss = 1.7383e-03, PNorm = 37.7520, GNorm = 2.8568, lr_0 = 9.0009e-04
Loss = 1.6724e-03, PNorm = 37.7781, GNorm = 1.9895, lr_0 = 8.9888e-04
Loss = 1.5342e-03, PNorm = 37.7960, GNorm = 0.3873, lr_0 = 8.9768e-04
Loss = 1.1166e-03, PNorm = 37.8178, GNorm = 0.8024, lr_0 = 8.9647e-04
Loss = 1.1532e-03, PNorm = 37.8403, GNorm = 0.5540, lr_0 = 8.9527e-04
Loss = 1.6031e-03, PNorm = 37.8658, GNorm = 0.8666, lr_0 = 8.9407e-04
Loss = 1.3542e-03, PNorm = 37.8764, GNorm = 0.4153, lr_0 = 8.9287e-04
Loss = 1.2784e-03, PNorm = 37.8912, GNorm = 0.5619, lr_0 = 8.9167e-04
Loss = 1.4189e-03, PNorm = 37.9073, GNorm = 0.5929, lr_0 = 8.9047e-04
Loss = 1.4926e-03, PNorm = 37.9225, GNorm = 0.9371, lr_0 = 8.8928e-04
Validation rmse = 0.524689
Validation R2 = 0.923608
Epoch 7
Train function
Loss = 1.5673e-03, PNorm = 37.9379, GNorm = 0.8697, lr_0 = 8.8809e-04
Loss = 1.5089e-03, PNorm = 37.9613, GNorm = 2.3140, lr_0 = 8.8689e-04
Loss = 1.4577e-03, PNorm = 37.9890, GNorm = 2.2050, lr_0 = 8.8570e-04
Loss = 9.5418e-04, PNorm = 38.0163, GNorm = 0.7667, lr_0 = 8.8452e-04
Loss = 1.1357e-03, PNorm = 38.0427, GNorm = 0.8037, lr_0 = 8.8333e-04
Loss = 1.2016e-03, PNorm = 38.0655, GNorm = 0.4603, lr_0 = 8.8214e-04
Loss = 1.3990e-03, PNorm = 38.0863, GNorm = 0.8151, lr_0 = 8.8096e-04
Loss = 1.2200e-03, PNorm = 38.1137, GNorm = 0.7373, lr_0 = 8.7978e-04
Loss = 1.0108e-03, PNorm = 38.1392, GNorm = 0.6590, lr_0 = 8.7860e-04
Loss = 8.9439e-04, PNorm = 38.1483, GNorm = 0.4368, lr_0 = 8.7742e-04
Loss = 1.2664e-03, PNorm = 38.1710, GNorm = 1.5358, lr_0 = 8.7624e-04
Loss = 1.1705e-03, PNorm = 38.1826, GNorm = 0.5315, lr_0 = 8.7507e-04
Loss = 1.5444e-03, PNorm = 38.2040, GNorm = 2.9460, lr_0 = 8.7389e-04
Loss = 1.4252e-03, PNorm = 38.2194, GNorm = 1.1768, lr_0 = 8.7272e-04
Loss = 1.3425e-03, PNorm = 38.2474, GNorm = 0.6940, lr_0 = 8.7155e-04
Loss = 1.6030e-03, PNorm = 38.2715, GNorm = 2.1412, lr_0 = 8.7038e-04
Loss = 1.2821e-03, PNorm = 38.2878, GNorm = 0.4804, lr_0 = 8.6921e-04
Loss = 1.2854e-03, PNorm = 38.2946, GNorm = 1.9090, lr_0 = 8.6805e-04
Validation rmse = 0.522659
Validation R2 = 0.924198
Epoch 8
Train function
Loss = 8.9360e-04, PNorm = 38.3146, GNorm = 0.5839, lr_0 = 8.6688e-04
Loss = 1.1036e-03, PNorm = 38.3426, GNorm = 0.8119, lr_0 = 8.6572e-04
Loss = 9.9936e-04, PNorm = 38.3573, GNorm = 0.9915, lr_0 = 8.6456e-04
Loss = 1.1362e-03, PNorm = 38.3767, GNorm = 1.2885, lr_0 = 8.6340e-04
Loss = 1.2051e-03, PNorm = 38.3931, GNorm = 0.5914, lr_0 = 8.6224e-04
Loss = 1.0826e-03, PNorm = 38.4168, GNorm = 0.9190, lr_0 = 8.6108e-04
Loss = 1.1105e-03, PNorm = 38.4346, GNorm = 0.7008, lr_0 = 8.5993e-04
Loss = 1.1827e-03, PNorm = 38.4600, GNorm = 1.2942, lr_0 = 8.5877e-04
Loss = 1.0517e-03, PNorm = 38.4846, GNorm = 0.4220, lr_0 = 8.5762e-04
Loss = 9.3515e-04, PNorm = 38.4976, GNorm = 0.5068, lr_0 = 8.5647e-04
Loss = 1.1141e-03, PNorm = 38.5139, GNorm = 0.8924, lr_0 = 8.5532e-04
Loss = 9.1300e-04, PNorm = 38.5310, GNorm = 1.0923, lr_0 = 8.5417e-04
Loss = 1.1799e-03, PNorm = 38.5528, GNorm = 0.8869, lr_0 = 8.5303e-04
Loss = 9.8502e-04, PNorm = 38.5684, GNorm = 0.4243, lr_0 = 8.5188e-04
Loss = 1.3278e-03, PNorm = 38.5968, GNorm = 0.8025, lr_0 = 8.5074e-04
Loss = 1.0194e-03, PNorm = 38.6048, GNorm = 0.5154, lr_0 = 8.4960e-04
Loss = 1.0471e-03, PNorm = 38.6303, GNorm = 1.2383, lr_0 = 8.4846e-04
Loss = 1.4801e-03, PNorm = 38.6552, GNorm = 0.9213, lr_0 = 8.4732e-04
Loss = 1.9477e-03, PNorm = 38.6570, GNorm = 0.9085, lr_0 = 8.4720e-04
Validation rmse = 0.508562
Validation R2 = 0.928232
Epoch 9
Train function
Loss = 1.1180e-03, PNorm = 38.6782, GNorm = 1.2362, lr_0 = 8.4607e-04
Loss = 1.1750e-03, PNorm = 38.6980, GNorm = 1.0867, lr_0 = 8.4493e-04
Loss = 1.1646e-03, PNorm = 38.7237, GNorm = 0.2985, lr_0 = 8.4380e-04
Loss = 1.0160e-03, PNorm = 38.7467, GNorm = 1.5515, lr_0 = 8.4267e-04
Loss = 8.9004e-04, PNorm = 38.7687, GNorm = 0.4086, lr_0 = 8.4154e-04
Loss = 9.7054e-04, PNorm = 38.7900, GNorm = 1.2927, lr_0 = 8.4041e-04
Loss = 8.1535e-04, PNorm = 38.8067, GNorm = 0.4268, lr_0 = 8.3928e-04
Loss = 8.5890e-04, PNorm = 38.8325, GNorm = 0.7474, lr_0 = 8.3815e-04
Loss = 9.4436e-04, PNorm = 38.8543, GNorm = 0.9875, lr_0 = 8.3703e-04
Loss = 7.6113e-04, PNorm = 38.8720, GNorm = 0.3823, lr_0 = 8.3591e-04
Loss = 1.1053e-03, PNorm = 38.8874, GNorm = 0.5209, lr_0 = 8.3478e-04
Loss = 9.7185e-04, PNorm = 38.9001, GNorm = 1.1217, lr_0 = 8.3366e-04
Loss = 1.0087e-03, PNorm = 38.9208, GNorm = 0.7368, lr_0 = 8.3255e-04
Loss = 1.0121e-03, PNorm = 38.9442, GNorm = 0.8435, lr_0 = 8.3143e-04
Loss = 1.0051e-03, PNorm = 38.9618, GNorm = 0.8685, lr_0 = 8.3031e-04
Loss = 9.3589e-04, PNorm = 38.9755, GNorm = 0.4117, lr_0 = 8.2920e-04
Loss = 9.5049e-04, PNorm = 38.9894, GNorm = 2.1030, lr_0 = 8.2809e-04
Validation rmse = 0.536273
Validation R2 = 0.920198
Epoch 10
Train function
Loss = 8.8728e-04, PNorm = 39.0049, GNorm = 1.3086, lr_0 = 8.2698e-04
Loss = 6.6382e-04, PNorm = 39.0133, GNorm = 1.0410, lr_0 = 8.2587e-04
Loss = 8.5413e-04, PNorm = 39.0335, GNorm = 0.3489, lr_0 = 8.2476e-04
Loss = 7.7498e-04, PNorm = 39.0553, GNorm = 1.0782, lr_0 = 8.2365e-04
Loss = 9.4569e-04, PNorm = 39.0730, GNorm = 1.2523, lr_0 = 8.2255e-04
Loss = 8.7216e-04, PNorm = 39.0892, GNorm = 0.5500, lr_0 = 8.2144e-04
Loss = 9.2598e-04, PNorm = 39.1072, GNorm = 0.3820, lr_0 = 8.2034e-04
Loss = 9.1538e-04, PNorm = 39.1331, GNorm = 1.3025, lr_0 = 8.1924e-04
Loss = 9.0358e-04, PNorm = 39.1531, GNorm = 0.6428, lr_0 = 8.1814e-04
Loss = 9.9896e-04, PNorm = 39.1704, GNorm = 1.5440, lr_0 = 8.1704e-04
Loss = 1.3619e-03, PNorm = 39.1894, GNorm = 1.9771, lr_0 = 8.1595e-04
Loss = 1.0774e-03, PNorm = 39.2155, GNorm = 0.4710, lr_0 = 8.1485e-04
Loss = 1.1648e-03, PNorm = 39.2397, GNorm = 1.6749, lr_0 = 8.1376e-04
Loss = 8.7805e-04, PNorm = 39.2599, GNorm = 0.4871, lr_0 = 8.1267e-04
Loss = 1.0576e-03, PNorm = 39.2801, GNorm = 0.8425, lr_0 = 8.1158e-04
Loss = 8.7985e-04, PNorm = 39.3065, GNorm = 0.6852, lr_0 = 8.1049e-04
Loss = 8.6805e-04, PNorm = 39.3230, GNorm = 0.5936, lr_0 = 8.0940e-04
Loss = 1.2624e-03, PNorm = 39.3338, GNorm = 1.6973, lr_0 = 8.0831e-04
Validation rmse = 0.513938
Validation R2 = 0.926706
Epoch 11
Train function
Loss = 1.0418e-03, PNorm = 39.3588, GNorm = 0.4139, lr_0 = 8.0723e-04
Loss = 1.3176e-03, PNorm = 39.3784, GNorm = 2.3523, lr_0 = 8.0615e-04
Loss = 1.1840e-03, PNorm = 39.4136, GNorm = 0.5903, lr_0 = 8.0506e-04
Loss = 1.0895e-03, PNorm = 39.4405, GNorm = 0.6815, lr_0 = 8.0398e-04
Loss = 6.4021e-04, PNorm = 39.4616, GNorm = 0.7163, lr_0 = 8.0291e-04
Loss = 7.6478e-04, PNorm = 39.4825, GNorm = 0.3767, lr_0 = 8.0183e-04
Loss = 8.3987e-04, PNorm = 39.4951, GNorm = 0.9234, lr_0 = 8.0075e-04
Loss = 7.7951e-04, PNorm = 39.5127, GNorm = 0.3082, lr_0 = 7.9968e-04
Loss = 7.0557e-04, PNorm = 39.5267, GNorm = 0.3534, lr_0 = 7.9861e-04
Loss = 7.8011e-04, PNorm = 39.5396, GNorm = 0.4351, lr_0 = 7.9753e-04
Loss = 8.7457e-04, PNorm = 39.5580, GNorm = 0.6455, lr_0 = 7.9646e-04
Loss = 8.3467e-04, PNorm = 39.5751, GNorm = 1.2506, lr_0 = 7.9540e-04
Loss = 8.9544e-04, PNorm = 39.5860, GNorm = 0.7742, lr_0 = 7.9433e-04
Loss = 9.3550e-04, PNorm = 39.6085, GNorm = 0.9765, lr_0 = 7.9326e-04
Loss = 8.0565e-04, PNorm = 39.6271, GNorm = 0.2752, lr_0 = 7.9220e-04
Loss = 8.5419e-04, PNorm = 39.6348, GNorm = 0.8459, lr_0 = 7.9114e-04
Loss = 8.9126e-04, PNorm = 39.6554, GNorm = 1.1237, lr_0 = 7.9007e-04
Validation rmse = 0.500068
Validation R2 = 0.930609
Epoch 12
Train function
Loss = 7.5328e-04, PNorm = 39.6788, GNorm = 1.1234, lr_0 = 7.8891e-04
Loss = 6.5018e-04, PNorm = 39.6879, GNorm = 0.3237, lr_0 = 7.8785e-04
Loss = 7.0708e-04, PNorm = 39.6991, GNorm = 0.7068, lr_0 = 7.8679e-04
Loss = 5.5435e-04, PNorm = 39.7228, GNorm = 0.3265, lr_0 = 7.8574e-04
Loss = 6.2485e-04, PNorm = 39.7354, GNorm = 0.4603, lr_0 = 7.8468e-04
Loss = 6.1864e-04, PNorm = 39.7504, GNorm = 0.2975, lr_0 = 7.8363e-04
Loss = 6.3884e-04, PNorm = 39.7650, GNorm = 1.0307, lr_0 = 7.8258e-04
Loss = 8.4794e-04, PNorm = 39.7801, GNorm = 0.6983, lr_0 = 7.8153e-04
Loss = 9.8467e-04, PNorm = 39.7969, GNorm = 1.0246, lr_0 = 7.8048e-04
Loss = 7.0604e-04, PNorm = 39.8143, GNorm = 0.4605, lr_0 = 7.7943e-04
Loss = 8.2328e-04, PNorm = 39.8316, GNorm = 0.8925, lr_0 = 7.7839e-04
Loss = 7.0998e-04, PNorm = 39.8465, GNorm = 0.5906, lr_0 = 7.7734e-04
Loss = 8.5409e-04, PNorm = 39.8601, GNorm = 0.3392, lr_0 = 7.7630e-04
Loss = 7.7742e-04, PNorm = 39.8798, GNorm = 0.5539, lr_0 = 7.7526e-04
Loss = 7.7284e-04, PNorm = 39.9019, GNorm = 1.1220, lr_0 = 7.7422e-04
Loss = 1.0618e-03, PNorm = 39.9174, GNorm = 1.9169, lr_0 = 7.7318e-04
Loss = 8.8887e-04, PNorm = 39.9465, GNorm = 0.9955, lr_0 = 7.7214e-04
Loss = 7.9891e-04, PNorm = 39.9631, GNorm = 0.3848, lr_0 = 7.7111e-04
Validation rmse = 0.510885
Validation R2 = 0.927575
Epoch 13
Train function
Loss = 7.2339e-04, PNorm = 39.9852, GNorm = 0.4434, lr_0 = 7.7007e-04
Loss = 7.4844e-04, PNorm = 40.0053, GNorm = 0.5986, lr_0 = 7.6904e-04
Loss = 6.9536e-04, PNorm = 40.0261, GNorm = 0.6084, lr_0 = 7.6801e-04
Loss = 5.6900e-04, PNorm = 40.0389, GNorm = 0.3048, lr_0 = 7.6698e-04
Loss = 5.8557e-04, PNorm = 40.0509, GNorm = 0.4181, lr_0 = 7.6595e-04
Loss = 6.9105e-04, PNorm = 40.0651, GNorm = 0.3136, lr_0 = 7.6492e-04
Loss = 6.5579e-04, PNorm = 40.0777, GNorm = 0.4955, lr_0 = 7.6389e-04
Loss = 7.3035e-04, PNorm = 40.0963, GNorm = 1.4382, lr_0 = 7.6287e-04
Loss = 7.1675e-04, PNorm = 40.1065, GNorm = 0.4913, lr_0 = 7.6184e-04
Loss = 8.4589e-04, PNorm = 40.1305, GNorm = 0.6484, lr_0 = 7.6082e-04
Loss = 6.0880e-04, PNorm = 40.1450, GNorm = 0.8630, lr_0 = 7.5980e-04
Loss = 6.7340e-04, PNorm = 40.1669, GNorm = 0.3285, lr_0 = 7.5878e-04
Loss = 5.8719e-04, PNorm = 40.1880, GNorm = 0.3523, lr_0 = 7.5776e-04
Loss = 5.7875e-04, PNorm = 40.2045, GNorm = 0.2579, lr_0 = 7.5675e-04
Loss = 7.3140e-04, PNorm = 40.2245, GNorm = 0.3697, lr_0 = 7.5573e-04
Loss = 7.3163e-04, PNorm = 40.2447, GNorm = 0.3847, lr_0 = 7.5472e-04
Loss = 6.7773e-04, PNorm = 40.2578, GNorm = 0.9753, lr_0 = 7.5370e-04
Validation rmse = 0.481548
Validation R2 = 0.935654
Epoch 14
Train function
Loss = 4.5541e-04, PNorm = 40.2780, GNorm = 0.3945, lr_0 = 7.5259e-04
Loss = 4.8355e-04, PNorm = 40.2905, GNorm = 0.3911, lr_0 = 7.5158e-04
Loss = 5.5205e-04, PNorm = 40.2990, GNorm = 0.8495, lr_0 = 7.5057e-04
Loss = 6.0055e-04, PNorm = 40.3184, GNorm = 0.6867, lr_0 = 7.4957e-04
Loss = 4.9196e-04, PNorm = 40.3351, GNorm = 0.5354, lr_0 = 7.4856e-04
Loss = 5.9234e-04, PNorm = 40.3513, GNorm = 1.1349, lr_0 = 7.4756e-04
Loss = 6.1505e-04, PNorm = 40.3619, GNorm = 0.8184, lr_0 = 7.4655e-04
Loss = 5.4940e-04, PNorm = 40.3790, GNorm = 0.7557, lr_0 = 7.4555e-04
Loss = 6.1421e-04, PNorm = 40.3973, GNorm = 0.4467, lr_0 = 7.4455e-04
Loss = 7.0418e-04, PNorm = 40.4087, GNorm = 0.5622, lr_0 = 7.4355e-04
Loss = 5.1177e-04, PNorm = 40.4268, GNorm = 0.3143, lr_0 = 7.4256e-04
Loss = 6.5290e-04, PNorm = 40.4381, GNorm = 0.3303, lr_0 = 7.4156e-04
Loss = 6.3510e-04, PNorm = 40.4505, GNorm = 0.3125, lr_0 = 7.4056e-04
Loss = 8.6299e-04, PNorm = 40.4619, GNorm = 0.5487, lr_0 = 7.3957e-04
Loss = 6.8693e-04, PNorm = 40.4818, GNorm = 0.3444, lr_0 = 7.3858e-04
Loss = 6.9197e-04, PNorm = 40.4918, GNorm = 1.6208, lr_0 = 7.3759e-04
Loss = 7.2832e-04, PNorm = 40.5188, GNorm = 0.3475, lr_0 = 7.3660e-04
Loss = 7.2892e-04, PNorm = 40.5289, GNorm = 0.5273, lr_0 = 7.3561e-04
Validation rmse = 0.494774
Validation R2 = 0.932070
Epoch 15
Train function
Loss = 7.1829e-04, PNorm = 40.5441, GNorm = 1.1106, lr_0 = 7.3462e-04
Loss = 7.1364e-04, PNorm = 40.5668, GNorm = 0.3435, lr_0 = 7.3364e-04
Loss = 5.6231e-04, PNorm = 40.5854, GNorm = 0.5580, lr_0 = 7.3265e-04
Loss = 5.3463e-04, PNorm = 40.6023, GNorm = 0.5474, lr_0 = 7.3167e-04
Loss = 4.5426e-04, PNorm = 40.6180, GNorm = 0.3418, lr_0 = 7.3069e-04
Loss = 4.3062e-04, PNorm = 40.6309, GNorm = 0.4187, lr_0 = 7.2971e-04
Loss = 6.5663e-04, PNorm = 40.6422, GNorm = 0.4626, lr_0 = 7.2873e-04
Loss = 7.9017e-04, PNorm = 40.6588, GNorm = 1.5544, lr_0 = 7.2775e-04
Loss = 6.3822e-04, PNorm = 40.6823, GNorm = 1.1478, lr_0 = 7.2677e-04
Loss = 6.7928e-04, PNorm = 40.6951, GNorm = 0.5846, lr_0 = 7.2580e-04
Loss = 6.9076e-04, PNorm = 40.7159, GNorm = 0.3364, lr_0 = 7.2483e-04
Loss = 6.1388e-04, PNorm = 40.7264, GNorm = 0.6213, lr_0 = 7.2385e-04
Loss = 5.3925e-04, PNorm = 40.7466, GNorm = 0.7239, lr_0 = 7.2288e-04
Loss = 5.4012e-04, PNorm = 40.7628, GNorm = 0.6722, lr_0 = 7.2191e-04
Loss = 7.9317e-04, PNorm = 40.7782, GNorm = 1.3120, lr_0 = 7.2094e-04
Loss = 6.1554e-04, PNorm = 40.7903, GNorm = 0.6157, lr_0 = 7.1998e-04
Loss = 5.7113e-04, PNorm = 40.8044, GNorm = 0.4955, lr_0 = 7.1901e-04
Loss = 5.7811e-04, PNorm = 40.8173, GNorm = 0.3718, lr_0 = 7.1804e-04
Validation rmse = 0.477550
Validation R2 = 0.936718
Epoch 16
Train function
Loss = 4.7175e-04, PNorm = 40.8332, GNorm = 0.3077, lr_0 = 7.1708e-04
Loss = 6.2456e-04, PNorm = 40.8479, GNorm = 1.4992, lr_0 = 7.1612e-04
Loss = 6.4235e-04, PNorm = 40.8615, GNorm = 0.4623, lr_0 = 7.1516e-04
Loss = 5.4598e-04, PNorm = 40.8804, GNorm = 0.4417, lr_0 = 7.1420e-04
Loss = 5.7448e-04, PNorm = 40.8927, GNorm = 1.2164, lr_0 = 7.1324e-04
Loss = 5.4413e-04, PNorm = 40.9080, GNorm = 0.5596, lr_0 = 7.1228e-04
Loss = 5.3792e-04, PNorm = 40.9228, GNorm = 0.4022, lr_0 = 7.1133e-04
Loss = 4.2408e-04, PNorm = 40.9329, GNorm = 0.6926, lr_0 = 7.1037e-04
Loss = 6.4070e-04, PNorm = 40.9456, GNorm = 0.4134, lr_0 = 7.0942e-04
Loss = 4.8694e-04, PNorm = 40.9570, GNorm = 0.4042, lr_0 = 7.0847e-04
Loss = 6.9499e-04, PNorm = 40.9847, GNorm = 0.5457, lr_0 = 7.0752e-04
Loss = 5.7228e-04, PNorm = 41.0005, GNorm = 0.6787, lr_0 = 7.0657e-04
Loss = 5.2495e-04, PNorm = 41.0128, GNorm = 0.3760, lr_0 = 7.0562e-04
Loss = 5.2023e-04, PNorm = 41.0264, GNorm = 1.2460, lr_0 = 7.0467e-04
Loss = 6.2761e-04, PNorm = 41.0366, GNorm = 0.5994, lr_0 = 7.0373e-04
Loss = 5.8378e-04, PNorm = 41.0555, GNorm = 0.7513, lr_0 = 7.0278e-04
Loss = 5.4536e-04, PNorm = 41.0725, GNorm = 0.3542, lr_0 = 7.0184e-04
Validation rmse = 0.496241
Validation R2 = 0.931667
Epoch 17
Train function
Loss = 5.5095e-04, PNorm = 41.0939, GNorm = 0.7647, lr_0 = 7.0081e-04
Loss = 4.8128e-04, PNorm = 41.1118, GNorm = 0.3141, lr_0 = 6.9987e-04
Loss = 6.0548e-04, PNorm = 41.1265, GNorm = 0.7758, lr_0 = 6.9893e-04
Loss = 5.8247e-04, PNorm = 41.1388, GNorm = 0.3596, lr_0 = 6.9799e-04
Loss = 5.1019e-04, PNorm = 41.1614, GNorm = 0.4101, lr_0 = 6.9705e-04
Loss = 4.7786e-04, PNorm = 41.1787, GNorm = 0.6948, lr_0 = 6.9612e-04
Loss = 4.9531e-04, PNorm = 41.1914, GNorm = 0.3756, lr_0 = 6.9518e-04
Loss = 4.2437e-04, PNorm = 41.2054, GNorm = 0.2244, lr_0 = 6.9425e-04
Loss = 4.0903e-04, PNorm = 41.2178, GNorm = 0.5934, lr_0 = 6.9332e-04
Loss = 6.1542e-04, PNorm = 41.2293, GNorm = 0.4948, lr_0 = 6.9239e-04
Loss = 5.5994e-04, PNorm = 41.2472, GNorm = 0.4192, lr_0 = 6.9146e-04
Loss = 5.9664e-04, PNorm = 41.2582, GNorm = 1.0243, lr_0 = 6.9053e-04
Loss = 6.9706e-04, PNorm = 41.2727, GNorm = 1.7677, lr_0 = 6.8961e-04
Loss = 5.5389e-04, PNorm = 41.2891, GNorm = 0.2970, lr_0 = 6.8868e-04
Loss = 6.5690e-04, PNorm = 41.3149, GNorm = 0.9105, lr_0 = 6.8776e-04
Loss = 4.8646e-04, PNorm = 41.3285, GNorm = 0.4192, lr_0 = 6.8683e-04
Loss = 4.8176e-04, PNorm = 41.3383, GNorm = 0.2564, lr_0 = 6.8591e-04
Loss = 4.7354e-04, PNorm = 41.3550, GNorm = 0.7370, lr_0 = 6.8499e-04
Validation rmse = 0.487253
Validation R2 = 0.934120
Epoch 18
Train function
Loss = 4.0636e-04, PNorm = 41.3669, GNorm = 0.3765, lr_0 = 6.8407e-04
Loss = 3.6463e-04, PNorm = 41.3804, GNorm = 0.2799, lr_0 = 6.8315e-04
Loss = 4.1689e-04, PNorm = 41.3915, GNorm = 0.3830, lr_0 = 6.8224e-04
Loss = 4.4197e-04, PNorm = 41.4054, GNorm = 0.7289, lr_0 = 6.8132e-04
Loss = 3.9873e-04, PNorm = 41.4169, GNorm = 0.3730, lr_0 = 6.8041e-04
Loss = 5.8293e-04, PNorm = 41.4280, GNorm = 0.4981, lr_0 = 6.7950e-04
Loss = 5.4248e-04, PNorm = 41.4461, GNorm = 0.8075, lr_0 = 6.7858e-04
Loss = 5.8310e-04, PNorm = 41.4634, GNorm = 1.1419, lr_0 = 6.7767e-04
Loss = 5.6072e-04, PNorm = 41.4746, GNorm = 0.4960, lr_0 = 6.7676e-04
Loss = 5.5443e-04, PNorm = 41.4977, GNorm = 0.3513, lr_0 = 6.7586e-04
Loss = 4.2246e-04, PNorm = 41.5086, GNorm = 0.7115, lr_0 = 6.7495e-04
Loss = 4.9123e-04, PNorm = 41.5199, GNorm = 0.5470, lr_0 = 6.7404e-04
Loss = 5.2766e-04, PNorm = 41.5384, GNorm = 0.9893, lr_0 = 6.7314e-04
Loss = 5.2108e-04, PNorm = 41.5543, GNorm = 0.3616, lr_0 = 6.7224e-04
Loss = 5.5478e-04, PNorm = 41.5737, GNorm = 0.4076, lr_0 = 6.7133e-04
Loss = 4.9209e-04, PNorm = 41.5817, GNorm = 0.3345, lr_0 = 6.7043e-04
Loss = 4.3452e-04, PNorm = 41.5930, GNorm = 0.7277, lr_0 = 6.6953e-04
Validation rmse = 0.483746
Validation R2 = 0.935065
Epoch 19
Train function
Loss = 4.7371e-04, PNorm = 41.6058, GNorm = 0.6348, lr_0 = 6.6864e-04
Loss = 4.7145e-04, PNorm = 41.6218, GNorm = 0.5513, lr_0 = 6.6774e-04
Loss = 4.2314e-04, PNorm = 41.6330, GNorm = 0.3630, lr_0 = 6.6684e-04
Loss = 3.8956e-04, PNorm = 41.6483, GNorm = 0.3153, lr_0 = 6.6595e-04
Loss = 3.8195e-04, PNorm = 41.6626, GNorm = 0.4607, lr_0 = 6.6505e-04
Loss = 4.4015e-04, PNorm = 41.6709, GNorm = 0.7564, lr_0 = 6.6416e-04
Loss = 4.5336e-04, PNorm = 41.6799, GNorm = 0.2619, lr_0 = 6.6327e-04
Loss = 4.2258e-04, PNorm = 41.6908, GNorm = 0.4151, lr_0 = 6.6238e-04
Loss = 3.7724e-04, PNorm = 41.7072, GNorm = 0.2253, lr_0 = 6.6149e-04
Loss = 4.9845e-04, PNorm = 41.7185, GNorm = 0.7401, lr_0 = 6.6060e-04
Loss = 4.0158e-04, PNorm = 41.7281, GNorm = 0.2717, lr_0 = 6.5972e-04
Loss = 4.0018e-04, PNorm = 41.7404, GNorm = 0.3220, lr_0 = 6.5883e-04
Loss = 4.4438e-04, PNorm = 41.7519, GNorm = 0.3653, lr_0 = 6.5795e-04
Loss = 4.7466e-04, PNorm = 41.7595, GNorm = 0.4953, lr_0 = 6.5707e-04
Loss = 4.8912e-04, PNorm = 41.7745, GNorm = 0.3360, lr_0 = 6.5618e-04
Loss = 4.1050e-04, PNorm = 41.7906, GNorm = 0.8029, lr_0 = 6.5530e-04
Loss = 4.1991e-04, PNorm = 41.8001, GNorm = 0.3709, lr_0 = 6.5443e-04
Loss = 5.5418e-04, PNorm = 41.8142, GNorm = 0.7274, lr_0 = 6.5355e-04
Validation rmse = 0.483796
Validation R2 = 0.935052
Epoch 20
Train function
Loss = 3.3304e-04, PNorm = 41.8345, GNorm = 0.3570, lr_0 = 6.5258e-04
Loss = 3.6697e-04, PNorm = 41.8478, GNorm = 0.3274, lr_0 = 6.5171e-04
Loss = 4.8034e-04, PNorm = 41.8644, GNorm = 0.2961, lr_0 = 6.5083e-04
Loss = 4.3267e-04, PNorm = 41.8793, GNorm = 0.6563, lr_0 = 6.4996e-04
Loss = 3.6186e-04, PNorm = 41.8920, GNorm = 0.5085, lr_0 = 6.4909e-04
Loss = 3.5967e-04, PNorm = 41.9041, GNorm = 0.7304, lr_0 = 6.4822e-04
Loss = 3.9354e-04, PNorm = 41.9181, GNorm = 0.2843, lr_0 = 6.4735e-04
Loss = 4.7917e-04, PNorm = 41.9369, GNorm = 0.7832, lr_0 = 6.4648e-04
Loss = 5.6381e-04, PNorm = 41.9525, GNorm = 1.4580, lr_0 = 6.4561e-04
Loss = 5.6178e-04, PNorm = 41.9706, GNorm = 0.7649, lr_0 = 6.4474e-04
Loss = 5.8464e-04, PNorm = 41.9810, GNorm = 0.6175, lr_0 = 6.4388e-04
Loss = 5.1161e-04, PNorm = 42.0042, GNorm = 0.7684, lr_0 = 6.4302e-04
Loss = 3.9661e-04, PNorm = 42.0136, GNorm = 0.3525, lr_0 = 6.4215e-04
Loss = 5.4211e-04, PNorm = 42.0213, GNorm = 0.4777, lr_0 = 6.4129e-04
Loss = 3.8803e-04, PNorm = 42.0442, GNorm = 0.4143, lr_0 = 6.4043e-04
Loss = 3.6716e-04, PNorm = 42.0482, GNorm = 0.5288, lr_0 = 6.3957e-04
Loss = 5.2831e-04, PNorm = 42.0650, GNorm = 0.9776, lr_0 = 6.3871e-04
Validation rmse = 0.476114
Validation R2 = 0.937098
Epoch 21
Train function
Loss = 2.7695e-04, PNorm = 42.0833, GNorm = 0.2767, lr_0 = 6.3786e-04
Loss = 3.1194e-04, PNorm = 42.1021, GNorm = 0.3785, lr_0 = 6.3700e-04
Loss = 4.0914e-04, PNorm = 42.1179, GNorm = 0.4083, lr_0 = 6.3615e-04
Loss = 3.3816e-04, PNorm = 42.1354, GNorm = 0.2792, lr_0 = 6.3529e-04
Loss = 3.5133e-04, PNorm = 42.1480, GNorm = 0.3380, lr_0 = 6.3444e-04
Loss = 3.9836e-04, PNorm = 42.1518, GNorm = 0.5640, lr_0 = 6.3359e-04
Loss = 4.6722e-04, PNorm = 42.1690, GNorm = 0.4515, lr_0 = 6.3274e-04
Loss = 3.4854e-04, PNorm = 42.1851, GNorm = 0.4417, lr_0 = 6.3189e-04
Loss = 3.9611e-04, PNorm = 42.1929, GNorm = 0.7911, lr_0 = 6.3104e-04
Loss = 3.7425e-04, PNorm = 42.2000, GNorm = 0.4409, lr_0 = 6.3020e-04
Loss = 4.4619e-04, PNorm = 42.2111, GNorm = 0.5444, lr_0 = 6.2935e-04
Loss = 3.5283e-04, PNorm = 42.2231, GNorm = 0.7619, lr_0 = 6.2851e-04
Loss = 4.5466e-04, PNorm = 42.2306, GNorm = 0.8753, lr_0 = 6.2766e-04
Loss = 4.3120e-04, PNorm = 42.2522, GNorm = 0.6269, lr_0 = 6.2682e-04
Loss = 4.4841e-04, PNorm = 42.2679, GNorm = 1.0555, lr_0 = 6.2598e-04
Loss = 3.9961e-04, PNorm = 42.2781, GNorm = 0.4809, lr_0 = 6.2514e-04
Loss = 3.4379e-04, PNorm = 42.2873, GNorm = 0.3216, lr_0 = 6.2430e-04
Loss = 3.7214e-04, PNorm = 42.3018, GNorm = 0.3243, lr_0 = 6.2346e-04
Validation rmse = 0.482146
Validation R2 = 0.935494
Epoch 22
Train function
Loss = 3.1376e-04, PNorm = 42.3135, GNorm = 0.4372, lr_0 = 6.2263e-04
Loss = 3.9658e-04, PNorm = 42.3248, GNorm = 0.2952, lr_0 = 6.2179e-04
Loss = 3.3884e-04, PNorm = 42.3367, GNorm = 0.2920, lr_0 = 6.2096e-04
Loss = 2.9815e-04, PNorm = 42.3463, GNorm = 0.2876, lr_0 = 6.2012e-04
Loss = 3.2521e-04, PNorm = 42.3579, GNorm = 0.3695, lr_0 = 6.1929e-04
Loss = 3.5352e-04, PNorm = 42.3741, GNorm = 0.6116, lr_0 = 6.1846e-04
Loss = 3.3858e-04, PNorm = 42.3835, GNorm = 0.6127, lr_0 = 6.1763e-04
Loss = 3.3830e-04, PNorm = 42.3993, GNorm = 0.3146, lr_0 = 6.1680e-04
Loss = 4.1962e-04, PNorm = 42.4051, GNorm = 0.2447, lr_0 = 6.1597e-04
Loss = 4.0530e-04, PNorm = 42.4181, GNorm = 0.6707, lr_0 = 6.1515e-04
Loss = 3.8435e-04, PNorm = 42.4291, GNorm = 0.5599, lr_0 = 6.1432e-04
Loss = 4.2726e-04, PNorm = 42.4449, GNorm = 0.3555, lr_0 = 6.1350e-04
Loss = 3.5198e-04, PNorm = 42.4541, GNorm = 0.3055, lr_0 = 6.1268e-04
Loss = 3.8016e-04, PNorm = 42.4712, GNorm = 0.6887, lr_0 = 6.1185e-04
Loss = 3.8029e-04, PNorm = 42.4816, GNorm = 0.9767, lr_0 = 6.1103e-04
Loss = 5.1382e-04, PNorm = 42.4973, GNorm = 0.7539, lr_0 = 6.1021e-04
Loss = 5.6970e-04, PNorm = 42.5100, GNorm = 0.3854, lr_0 = 6.0939e-04
Validation rmse = 0.479147
Validation R2 = 0.936294
Epoch 23
Train function
Loss = 2.9516e-04, PNorm = 42.5244, GNorm = 0.2780, lr_0 = 6.0849e-04
Loss = 4.6177e-04, PNorm = 42.5454, GNorm = 0.6626, lr_0 = 6.0768e-04
Loss = 3.7086e-04, PNorm = 42.5635, GNorm = 0.4139, lr_0 = 6.0686e-04
Loss = 2.9408e-04, PNorm = 42.5705, GNorm = 0.2046, lr_0 = 6.0605e-04
Loss = 3.7411e-04, PNorm = 42.5816, GNorm = 1.0335, lr_0 = 6.0524e-04
Loss = 3.5353e-04, PNorm = 42.5953, GNorm = 0.2768, lr_0 = 6.0442e-04
Loss = 4.1890e-04, PNorm = 42.6115, GNorm = 0.9992, lr_0 = 6.0361e-04
Loss = 4.2761e-04, PNorm = 42.6278, GNorm = 0.9511, lr_0 = 6.0280e-04
Loss = 3.9224e-04, PNorm = 42.6389, GNorm = 0.8080, lr_0 = 6.0199e-04
Loss = 3.2326e-04, PNorm = 42.6506, GNorm = 0.5061, lr_0 = 6.0119e-04
Loss = 3.3415e-04, PNorm = 42.6650, GNorm = 0.5720, lr_0 = 6.0038e-04
Loss = 4.3432e-04, PNorm = 42.6813, GNorm = 0.7830, lr_0 = 5.9957e-04
Loss = 4.3214e-04, PNorm = 42.6929, GNorm = 1.3872, lr_0 = 5.9877e-04
Loss = 3.5249e-04, PNorm = 42.7017, GNorm = 0.9393, lr_0 = 5.9797e-04
Loss = 4.1899e-04, PNorm = 42.7151, GNorm = 0.4590, lr_0 = 5.9716e-04
Loss = 3.2898e-04, PNorm = 42.7250, GNorm = 0.3746, lr_0 = 5.9636e-04
Loss = 3.2333e-04, PNorm = 42.7285, GNorm = 0.6476, lr_0 = 5.9556e-04
Loss = 3.5871e-04, PNorm = 42.7414, GNorm = 0.2717, lr_0 = 5.9476e-04
Validation rmse = 0.471187
Validation R2 = 0.938393
Epoch 24
Train function
Loss = 2.7369e-04, PNorm = 42.7498, GNorm = 0.3932, lr_0 = 5.9397e-04
Loss = 3.1988e-04, PNorm = 42.7633, GNorm = 0.2586, lr_0 = 5.9317e-04
Loss = 3.1390e-04, PNorm = 42.7705, GNorm = 0.3431, lr_0 = 5.9237e-04
Loss = 2.3746e-04, PNorm = 42.7792, GNorm = 0.5296, lr_0 = 5.9158e-04
Loss = 2.3846e-04, PNorm = 42.7879, GNorm = 0.1878, lr_0 = 5.9078e-04
Loss = 2.4537e-04, PNorm = 42.7987, GNorm = 0.3473, lr_0 = 5.8999e-04
Loss = 2.3316e-04, PNorm = 42.8068, GNorm = 0.4041, lr_0 = 5.8920e-04
Loss = 2.8230e-04, PNorm = 42.8155, GNorm = 0.2979, lr_0 = 5.8841e-04
Loss = 4.1954e-04, PNorm = 42.8273, GNorm = 0.6443, lr_0 = 5.8762e-04
Loss = 3.5133e-04, PNorm = 42.8406, GNorm = 0.4051, lr_0 = 5.8683e-04
Loss = 2.6417e-04, PNorm = 42.8477, GNorm = 0.2632, lr_0 = 5.8604e-04
Loss = 2.8509e-04, PNorm = 42.8622, GNorm = 0.4146, lr_0 = 5.8526e-04
Loss = 2.7677e-04, PNorm = 42.8705, GNorm = 0.2735, lr_0 = 5.8447e-04
Loss = 3.2339e-04, PNorm = 42.8806, GNorm = 0.2242, lr_0 = 5.8369e-04
Loss = 3.2555e-04, PNorm = 42.8930, GNorm = 0.2360, lr_0 = 5.8290e-04
Loss = 2.9434e-04, PNorm = 42.9010, GNorm = 0.6816, lr_0 = 5.8212e-04
Loss = 3.5798e-04, PNorm = 42.9116, GNorm = 0.3336, lr_0 = 5.8134e-04
Loss = 3.0745e-04, PNorm = 42.9212, GNorm = 0.4276, lr_0 = 5.8056e-04
Validation rmse = 0.473334
Validation R2 = 0.937830
Epoch 25
Train function
Loss = 2.6769e-04, PNorm = 42.9326, GNorm = 1.0427, lr_0 = 5.7978e-04
Loss = 3.0060e-04, PNorm = 42.9413, GNorm = 0.4605, lr_0 = 5.7900e-04
Loss = 2.9180e-04, PNorm = 42.9504, GNorm = 0.6303, lr_0 = 5.7823e-04
Loss = 3.0430e-04, PNorm = 42.9570, GNorm = 0.3912, lr_0 = 5.7745e-04
Loss = 2.2193e-04, PNorm = 42.9681, GNorm = 0.3377, lr_0 = 5.7668e-04
Loss = 3.2372e-04, PNorm = 42.9780, GNorm = 0.5093, lr_0 = 5.7590e-04
Loss = 3.1300e-04, PNorm = 42.9896, GNorm = 0.4584, lr_0 = 5.7513e-04
Loss = 3.5033e-04, PNorm = 42.9976, GNorm = 0.8343, lr_0 = 5.7436e-04
Loss = 3.7015e-04, PNorm = 43.0143, GNorm = 0.5079, lr_0 = 5.7359e-04
Loss = 3.7315e-04, PNorm = 43.0240, GNorm = 0.2534, lr_0 = 5.7282e-04
Loss = 2.8761e-04, PNorm = 43.0342, GNorm = 0.4459, lr_0 = 5.7205e-04
Loss = 2.5588e-04, PNorm = 43.0439, GNorm = 0.2740, lr_0 = 5.7128e-04
Loss = 3.3594e-04, PNorm = 43.0553, GNorm = 0.9411, lr_0 = 5.7052e-04
Loss = 3.1094e-04, PNorm = 43.0649, GNorm = 0.3425, lr_0 = 5.6975e-04
Loss = 4.3500e-04, PNorm = 43.0796, GNorm = 0.2137, lr_0 = 5.6899e-04
Loss = 4.3839e-04, PNorm = 43.0953, GNorm = 0.6520, lr_0 = 5.6822e-04
Loss = 3.8392e-04, PNorm = 43.1055, GNorm = 0.3412, lr_0 = 5.6746e-04
Validation rmse = 0.480890
Validation R2 = 0.935829
Epoch 26
Train function
Loss = 2.5960e-04, PNorm = 43.1220, GNorm = 0.6053, lr_0 = 5.6662e-04
Loss = 2.2808e-04, PNorm = 43.1331, GNorm = 0.2566, lr_0 = 5.6586e-04
Loss = 2.3343e-04, PNorm = 43.1465, GNorm = 0.2776, lr_0 = 5.6510e-04
Loss = 2.5242e-04, PNorm = 43.1540, GNorm = 0.3348, lr_0 = 5.6435e-04
Loss = 2.1323e-04, PNorm = 43.1596, GNorm = 0.2323, lr_0 = 5.6359e-04
Loss = 2.6395e-04, PNorm = 43.1672, GNorm = 0.8454, lr_0 = 5.6283e-04
Loss = 3.1766e-04, PNorm = 43.1833, GNorm = 0.6579, lr_0 = 5.6208e-04
Loss = 3.0191e-04, PNorm = 43.1956, GNorm = 0.8206, lr_0 = 5.6132e-04
Loss = 2.4564e-04, PNorm = 43.2025, GNorm = 0.1702, lr_0 = 5.6057e-04
Loss = 2.7056e-04, PNorm = 43.2128, GNorm = 0.3792, lr_0 = 5.5982e-04
Loss = 2.7532e-04, PNorm = 43.2238, GNorm = 0.5424, lr_0 = 5.5907e-04
Loss = 2.1441e-04, PNorm = 43.2390, GNorm = 0.3652, lr_0 = 5.5832e-04
Loss = 2.4736e-04, PNorm = 43.2466, GNorm = 0.2296, lr_0 = 5.5757e-04
Loss = 2.4696e-04, PNorm = 43.2556, GNorm = 0.5178, lr_0 = 5.5682e-04
Loss = 3.1873e-04, PNorm = 43.2654, GNorm = 0.2559, lr_0 = 5.5607e-04
Loss = 3.0683e-04, PNorm = 43.2742, GNorm = 0.6848, lr_0 = 5.5533e-04
Loss = 4.8816e-04, PNorm = 43.2825, GNorm = 1.2846, lr_0 = 5.5458e-04
Loss = 3.2686e-04, PNorm = 43.2975, GNorm = 0.4751, lr_0 = 5.5384e-04
Validation rmse = 0.482336
Validation R2 = 0.935443
Epoch 27
Train function
Loss = 2.9684e-04, PNorm = 43.3056, GNorm = 0.1400, lr_0 = 5.5309e-04
Loss = 3.2754e-04, PNorm = 43.3127, GNorm = 0.6374, lr_0 = 5.5235e-04
Loss = 3.0575e-04, PNorm = 43.3185, GNorm = 0.5298, lr_0 = 5.5161e-04
Loss = 2.6519e-04, PNorm = 43.3315, GNorm = 0.5096, lr_0 = 5.5087e-04
Loss = 2.2221e-04, PNorm = 43.3414, GNorm = 0.2074, lr_0 = 5.5013e-04
Loss = 2.5723e-04, PNorm = 43.3518, GNorm = 0.2680, lr_0 = 5.4939e-04
Loss = 2.1853e-04, PNorm = 43.3623, GNorm = 0.3272, lr_0 = 5.4866e-04
Loss = 3.0094e-04, PNorm = 43.3735, GNorm = 0.3359, lr_0 = 5.4792e-04
Loss = 3.9050e-04, PNorm = 43.3852, GNorm = 0.8287, lr_0 = 5.4718e-04
Loss = 2.8137e-04, PNorm = 43.3984, GNorm = 0.8400, lr_0 = 5.4645e-04
Loss = 2.7830e-04, PNorm = 43.4095, GNorm = 0.5355, lr_0 = 5.4572e-04
Loss = 2.3492e-04, PNorm = 43.4169, GNorm = 0.5913, lr_0 = 5.4499e-04
Loss = 2.8227e-04, PNorm = 43.4266, GNorm = 0.5199, lr_0 = 5.4425e-04
Loss = 3.5435e-04, PNorm = 43.4324, GNorm = 0.3806, lr_0 = 5.4352e-04
Loss = 3.3900e-04, PNorm = 43.4483, GNorm = 0.3487, lr_0 = 5.4279e-04
Loss = 2.7506e-04, PNorm = 43.4568, GNorm = 0.2081, lr_0 = 5.4207e-04
Loss = 2.7268e-04, PNorm = 43.4675, GNorm = 0.2780, lr_0 = 5.4134e-04
Validation rmse = 0.470931
Validation R2 = 0.938460
Epoch 28
Train function
Loss = 2.0347e-04, PNorm = 43.4794, GNorm = 0.3121, lr_0 = 5.4054e-04
Loss = 3.2780e-04, PNorm = 43.4884, GNorm = 0.2825, lr_0 = 5.3981e-04
Loss = 2.0200e-04, PNorm = 43.5006, GNorm = 0.2784, lr_0 = 5.3909e-04
Loss = 2.4871e-04, PNorm = 43.5112, GNorm = 0.2177, lr_0 = 5.3837e-04
Loss = 2.3404e-04, PNorm = 43.5189, GNorm = 0.2176, lr_0 = 5.3765e-04
Loss = 2.1987e-04, PNorm = 43.5279, GNorm = 0.4721, lr_0 = 5.3692e-04
Loss = 2.2284e-04, PNorm = 43.5367, GNorm = 0.4045, lr_0 = 5.3620e-04
Loss = 2.0745e-04, PNorm = 43.5443, GNorm = 0.2264, lr_0 = 5.3548e-04
Loss = 2.2539e-04, PNorm = 43.5525, GNorm = 0.4054, lr_0 = 5.3477e-04
Loss = 2.0258e-04, PNorm = 43.5603, GNorm = 0.1524, lr_0 = 5.3405e-04
Loss = 2.8763e-04, PNorm = 43.5639, GNorm = 0.4096, lr_0 = 5.3333e-04
Loss = 1.9364e-04, PNorm = 43.5705, GNorm = 0.2658, lr_0 = 5.3262e-04
Loss = 2.5290e-04, PNorm = 43.5762, GNorm = 0.3352, lr_0 = 5.3190e-04
Loss = 2.8130e-04, PNorm = 43.5866, GNorm = 0.2078, lr_0 = 5.3119e-04
Loss = 2.9798e-04, PNorm = 43.5980, GNorm = 0.3534, lr_0 = 5.3047e-04
Loss = 2.6335e-04, PNorm = 43.6104, GNorm = 0.5084, lr_0 = 5.2976e-04
Loss = 2.1654e-04, PNorm = 43.6172, GNorm = 0.2032, lr_0 = 5.2905e-04
Loss = 2.0280e-04, PNorm = 43.6239, GNorm = 0.2988, lr_0 = 5.2834e-04
Validation rmse = 0.468020
Validation R2 = 0.939218
Epoch 29
Train function
Loss = 1.6336e-04, PNorm = 43.6313, GNorm = 0.3724, lr_0 = 5.2763e-04
Loss = 2.4790e-04, PNorm = 43.6375, GNorm = 0.3826, lr_0 = 5.2693e-04
Loss = 2.6833e-04, PNorm = 43.6414, GNorm = 0.3995, lr_0 = 5.2622e-04
Loss = 3.1305e-04, PNorm = 43.6530, GNorm = 0.2170, lr_0 = 5.2551e-04
Loss = 2.9364e-04, PNorm = 43.6628, GNorm = 0.4023, lr_0 = 5.2481e-04
Loss = 2.8609e-04, PNorm = 43.6757, GNorm = 0.6975, lr_0 = 5.2410e-04
Loss = 2.6964e-04, PNorm = 43.6869, GNorm = 0.8645, lr_0 = 5.2340e-04
Loss = 2.9828e-04, PNorm = 43.6996, GNorm = 0.5763, lr_0 = 5.2270e-04
Loss = 1.9639e-04, PNorm = 43.7122, GNorm = 0.2296, lr_0 = 5.2200e-04
Loss = 2.6669e-04, PNorm = 43.7217, GNorm = 0.5755, lr_0 = 5.2130e-04
Loss = 2.1336e-04, PNorm = 43.7301, GNorm = 0.2939, lr_0 = 5.2060e-04
Loss = 2.6578e-04, PNorm = 43.7413, GNorm = 0.2910, lr_0 = 5.1990e-04
Loss = 1.8492e-04, PNorm = 43.7494, GNorm = 0.4742, lr_0 = 5.1920e-04
Loss = 2.5501e-04, PNorm = 43.7536, GNorm = 0.4980, lr_0 = 5.1850e-04
Loss = 2.8119e-04, PNorm = 43.7624, GNorm = 0.3999, lr_0 = 5.1781e-04
Loss = 1.8602e-04, PNorm = 43.7716, GNorm = 0.2098, lr_0 = 5.1711e-04
Loss = 2.4705e-04, PNorm = 43.7778, GNorm = 0.3906, lr_0 = 5.1642e-04
Validation rmse = 0.474603
Validation R2 = 0.937496
Epoch 30
Train function
Loss = 2.5992e-04, PNorm = 43.7848, GNorm = 0.2723, lr_0 = 5.1573e-04
Loss = 2.3440e-04, PNorm = 43.7932, GNorm = 0.6493, lr_0 = 5.1503e-04
Loss = 2.1597e-04, PNorm = 43.8030, GNorm = 0.2324, lr_0 = 5.1434e-04
Loss = 2.1457e-04, PNorm = 43.8110, GNorm = 0.2416, lr_0 = 5.1365e-04
Loss = 2.5268e-04, PNorm = 43.8205, GNorm = 0.3897, lr_0 = 5.1296e-04
Loss = 2.0735e-04, PNorm = 43.8251, GNorm = 0.2956, lr_0 = 5.1228e-04
Loss = 2.6299e-04, PNorm = 43.8294, GNorm = 0.2109, lr_0 = 5.1159e-04
Loss = 2.0897e-04, PNorm = 43.8397, GNorm = 0.6142, lr_0 = 5.1090e-04
Loss = 2.7633e-04, PNorm = 43.8507, GNorm = 0.8197, lr_0 = 5.1022e-04
Loss = 1.7757e-04, PNorm = 43.8610, GNorm = 0.6669, lr_0 = 5.0953e-04
Loss = 2.4814e-04, PNorm = 43.8711, GNorm = 0.6914, lr_0 = 5.0885e-04
Loss = 2.5274e-04, PNorm = 43.8839, GNorm = 0.4169, lr_0 = 5.0817e-04
Loss = 2.2457e-04, PNorm = 43.8933, GNorm = 0.2771, lr_0 = 5.0748e-04
Loss = 1.8812e-04, PNorm = 43.9037, GNorm = 0.2309, lr_0 = 5.0680e-04
Loss = 2.3998e-04, PNorm = 43.9088, GNorm = 0.3046, lr_0 = 5.0612e-04
Loss = 2.1726e-04, PNorm = 43.9170, GNorm = 0.1898, lr_0 = 5.0544e-04
Loss = 2.0100e-04, PNorm = 43.9233, GNorm = 0.3906, lr_0 = 5.0477e-04
Loss = 2.2168e-04, PNorm = 43.9324, GNorm = 0.3608, lr_0 = 5.0409e-04
Validation rmse = 0.477132
Validation R2 = 0.936828
Epoch 31
Train function
Loss = 2.2406e-04, PNorm = 43.9415, GNorm = 0.6172, lr_0 = 5.0335e-04
Loss = 2.8140e-04, PNorm = 43.9490, GNorm = 0.3628, lr_0 = 5.0267e-04
Loss = 1.8726e-04, PNorm = 43.9561, GNorm = 0.2161, lr_0 = 5.0200e-04
Loss = 1.7046e-04, PNorm = 43.9685, GNorm = 0.4057, lr_0 = 5.0132e-04
Loss = 2.0121e-04, PNorm = 43.9765, GNorm = 0.2549, lr_0 = 5.0065e-04
Loss = 2.3646e-04, PNorm = 43.9853, GNorm = 0.5460, lr_0 = 4.9998e-04
Loss = 1.8128e-04, PNorm = 43.9953, GNorm = 0.2742, lr_0 = 4.9931e-04
Loss = 1.8899e-04, PNorm = 43.9999, GNorm = 0.3998, lr_0 = 4.9864e-04
Loss = 2.0400e-04, PNorm = 44.0057, GNorm = 0.2201, lr_0 = 4.9797e-04
Loss = 1.7622e-04, PNorm = 44.0160, GNorm = 0.2441, lr_0 = 4.9730e-04
Loss = 2.0970e-04, PNorm = 44.0220, GNorm = 0.1985, lr_0 = 4.9663e-04
Loss = 1.9955e-04, PNorm = 44.0309, GNorm = 0.5826, lr_0 = 4.9597e-04
Loss = 2.0118e-04, PNorm = 44.0435, GNorm = 0.2277, lr_0 = 4.9530e-04
Loss = 2.3685e-04, PNorm = 44.0520, GNorm = 0.4395, lr_0 = 4.9464e-04
Loss = 2.4176e-04, PNorm = 44.0602, GNorm = 0.5653, lr_0 = 4.9397e-04
Loss = 2.3385e-04, PNorm = 44.0658, GNorm = 0.3983, lr_0 = 4.9331e-04
Loss = 3.2543e-04, PNorm = 44.0747, GNorm = 0.1594, lr_0 = 4.9265e-04
Loss = 2.9665e-04, PNorm = 44.0846, GNorm = 0.2863, lr_0 = 4.9199e-04
Validation rmse = 0.479441
Validation R2 = 0.936216
Epoch 32
Train function
Loss = 2.0453e-04, PNorm = 44.0941, GNorm = 0.5366, lr_0 = 4.9133e-04
Loss = 2.3426e-04, PNorm = 44.1061, GNorm = 0.2469, lr_0 = 4.9067e-04
Loss = 1.7057e-04, PNorm = 44.1144, GNorm = 0.4946, lr_0 = 4.9001e-04
Loss = 1.8908e-04, PNorm = 44.1232, GNorm = 0.5859, lr_0 = 4.8935e-04
Loss = 1.7466e-04, PNorm = 44.1283, GNorm = 0.4586, lr_0 = 4.8870e-04
Loss = 1.8048e-04, PNorm = 44.1336, GNorm = 0.2545, lr_0 = 4.8804e-04
Loss = 2.5001e-04, PNorm = 44.1463, GNorm = 0.4495, lr_0 = 4.8738e-04
Loss = 2.5801e-04, PNorm = 44.1574, GNorm = 0.4097, lr_0 = 4.8673e-04
Loss = 2.3094e-04, PNorm = 44.1699, GNorm = 0.2158, lr_0 = 4.8608e-04
Loss = 2.1353e-04, PNorm = 44.1781, GNorm = 0.3327, lr_0 = 4.8543e-04
Loss = 2.2449e-04, PNorm = 44.1942, GNorm = 0.3953, lr_0 = 4.8477e-04
Loss = 2.0816e-04, PNorm = 44.2017, GNorm = 0.5197, lr_0 = 4.8412e-04
Loss = 2.1733e-04, PNorm = 44.2088, GNorm = 0.6321, lr_0 = 4.8347e-04
Loss = 2.6011e-04, PNorm = 44.2157, GNorm = 0.7523, lr_0 = 4.8283e-04
Loss = 3.2949e-04, PNorm = 44.2238, GNorm = 0.4396, lr_0 = 4.8218e-04
Loss = 2.0374e-04, PNorm = 44.2329, GNorm = 0.3332, lr_0 = 4.8153e-04
Loss = 2.3726e-04, PNorm = 44.2423, GNorm = 0.3341, lr_0 = 4.8088e-04
Validation rmse = 0.475384
Validation R2 = 0.937291
Epoch 33
Train function
Loss = 1.6436e-04, PNorm = 44.2542, GNorm = 0.2025, lr_0 = 4.8024e-04
Loss = 1.6131e-04, PNorm = 44.2632, GNorm = 0.3440, lr_0 = 4.7959e-04
Loss = 1.3296e-04, PNorm = 44.2682, GNorm = 0.3973, lr_0 = 4.7895e-04
Loss = 1.4233e-04, PNorm = 44.2706, GNorm = 0.2083, lr_0 = 4.7831e-04
Loss = 1.7999e-04, PNorm = 44.2727, GNorm = 0.3071, lr_0 = 4.7767e-04
Loss = 1.7737e-04, PNorm = 44.2767, GNorm = 0.1984, lr_0 = 4.7703e-04
Loss = 1.6900e-04, PNorm = 44.2867, GNorm = 0.1547, lr_0 = 4.7639e-04
Loss = 1.8263e-04, PNorm = 44.2895, GNorm = 0.4247, lr_0 = 4.7575e-04
Loss = 1.9443e-04, PNorm = 44.2969, GNorm = 0.2034, lr_0 = 4.7511e-04
Loss = 1.9406e-04, PNorm = 44.3056, GNorm = 0.1793, lr_0 = 4.7447e-04
Loss = 2.2864e-04, PNorm = 44.3149, GNorm = 0.2593, lr_0 = 4.7383e-04
Loss = 1.8446e-04, PNorm = 44.3257, GNorm = 0.3126, lr_0 = 4.7320e-04
Loss = 1.7806e-04, PNorm = 44.3328, GNorm = 0.2059, lr_0 = 4.7256e-04
Loss = 1.6830e-04, PNorm = 44.3394, GNorm = 0.2583, lr_0 = 4.7193e-04
Loss = 2.0914e-04, PNorm = 44.3451, GNorm = 0.3005, lr_0 = 4.7130e-04
Loss = 1.6003e-04, PNorm = 44.3523, GNorm = 0.1960, lr_0 = 4.7066e-04
Loss = 2.0385e-04, PNorm = 44.3574, GNorm = 0.2664, lr_0 = 4.7003e-04
Loss = 2.2108e-04, PNorm = 44.3653, GNorm = 0.5178, lr_0 = 4.6940e-04
Validation rmse = 0.473395
Validation R2 = 0.937814
Epoch 34
Train function
Loss = 1.5842e-04, PNorm = 44.3739, GNorm = 0.4233, lr_0 = 4.6871e-04
Loss = 1.4927e-04, PNorm = 44.3837, GNorm = 0.1868, lr_0 = 4.6808e-04
Loss = 1.3881e-04, PNorm = 44.3861, GNorm = 0.3183, lr_0 = 4.6745e-04
Loss = 1.7253e-04, PNorm = 44.3984, GNorm = 0.3870, lr_0 = 4.6683e-04
Loss = 1.8092e-04, PNorm = 44.4070, GNorm = 0.3190, lr_0 = 4.6620e-04
Loss = 2.2489e-04, PNorm = 44.4165, GNorm = 0.3328, lr_0 = 4.6557e-04
Loss = 1.9865e-04, PNorm = 44.4222, GNorm = 0.4190, lr_0 = 4.6495e-04
Loss = 2.0609e-04, PNorm = 44.4317, GNorm = 0.4176, lr_0 = 4.6433e-04
Loss = 2.2784e-04, PNorm = 44.4410, GNorm = 0.4810, lr_0 = 4.6370e-04
Loss = 2.5015e-04, PNorm = 44.4521, GNorm = 0.2406, lr_0 = 4.6308e-04
Loss = 1.5870e-04, PNorm = 44.4642, GNorm = 0.3522, lr_0 = 4.6246e-04
Loss = 1.7576e-04, PNorm = 44.4698, GNorm = 0.3962, lr_0 = 4.6184e-04
Loss = 1.9378e-04, PNorm = 44.4758, GNorm = 0.7165, lr_0 = 4.6122e-04
Loss = 1.6752e-04, PNorm = 44.4812, GNorm = 0.2615, lr_0 = 4.6060e-04
Loss = 2.2339e-04, PNorm = 44.4862, GNorm = 0.1640, lr_0 = 4.5998e-04
Loss = 1.6504e-04, PNorm = 44.4950, GNorm = 0.2296, lr_0 = 4.5936e-04
Loss = 1.6363e-04, PNorm = 44.5000, GNorm = 0.5283, lr_0 = 4.5875e-04
Validation rmse = 0.473870
Validation R2 = 0.937689
Epoch 35
Train function
Loss = 1.2912e-04, PNorm = 44.5072, GNorm = 0.2822, lr_0 = 4.5813e-04
Loss = 1.3615e-04, PNorm = 44.5169, GNorm = 0.1961, lr_0 = 4.5752e-04
Loss = 1.2577e-04, PNorm = 44.5241, GNorm = 0.3085, lr_0 = 4.5690e-04
Loss = 1.2504e-04, PNorm = 44.5306, GNorm = 0.2671, lr_0 = 4.5629e-04
Loss = 1.2251e-04, PNorm = 44.5382, GNorm = 0.4269, lr_0 = 4.5568e-04
Loss = 2.2701e-04, PNorm = 44.5423, GNorm = 0.2512, lr_0 = 4.5507e-04
Loss = 1.5073e-04, PNorm = 44.5495, GNorm = 0.3486, lr_0 = 4.5446e-04
Loss = 1.6033e-04, PNorm = 44.5587, GNorm = 0.3115, lr_0 = 4.5385e-04
Loss = 1.3537e-04, PNorm = 44.5636, GNorm = 0.2811, lr_0 = 4.5324e-04
Loss = 1.4646e-04, PNorm = 44.5698, GNorm = 0.2154, lr_0 = 4.5263e-04
Loss = 1.5554e-04, PNorm = 44.5755, GNorm = 0.4422, lr_0 = 4.5202e-04
Loss = 1.9266e-04, PNorm = 44.5867, GNorm = 0.2254, lr_0 = 4.5142e-04
Loss = 1.9840e-04, PNorm = 44.5954, GNorm = 0.5167, lr_0 = 4.5081e-04
Loss = 2.1773e-04, PNorm = 44.6047, GNorm = 0.3791, lr_0 = 4.5021e-04
Loss = 1.7292e-04, PNorm = 44.6106, GNorm = 0.2103, lr_0 = 4.4960e-04
Loss = 1.5924e-04, PNorm = 44.6168, GNorm = 0.2124, lr_0 = 4.4900e-04
Loss = 1.7949e-04, PNorm = 44.6248, GNorm = 0.3252, lr_0 = 4.4840e-04
Loss = 2.1963e-04, PNorm = 44.6257, GNorm = 0.4431, lr_0 = 4.4779e-04
Validation rmse = 0.476127
Validation R2 = 0.937094
Epoch 36
Train function
Loss = 1.3504e-04, PNorm = 44.6340, GNorm = 0.2737, lr_0 = 4.4719e-04
Loss = 1.6516e-04, PNorm = 44.6445, GNorm = 0.2116, lr_0 = 4.4659e-04
Loss = 1.1952e-04, PNorm = 44.6520, GNorm = 0.1526, lr_0 = 4.4599e-04
Loss = 1.1480e-04, PNorm = 44.6569, GNorm = 0.3273, lr_0 = 4.4540e-04
Loss = 1.8302e-04, PNorm = 44.6665, GNorm = 0.5312, lr_0 = 4.4480e-04
Loss = 1.6073e-04, PNorm = 44.6741, GNorm = 0.1884, lr_0 = 4.4420e-04
Loss = 1.3712e-04, PNorm = 44.6810, GNorm = 0.3700, lr_0 = 4.4361e-04
Loss = 2.0584e-04, PNorm = 44.6898, GNorm = 0.3157, lr_0 = 4.4301e-04
Loss = 1.5182e-04, PNorm = 44.6974, GNorm = 0.3386, lr_0 = 4.4242e-04
Loss = 1.4446e-04, PNorm = 44.7043, GNorm = 0.2505, lr_0 = 4.4182e-04
Loss = 1.5746e-04, PNorm = 44.7119, GNorm = 0.1666, lr_0 = 4.4123e-04
Loss = 1.5074e-04, PNorm = 44.7192, GNorm = 0.4028, lr_0 = 4.4064e-04
Loss = 1.5938e-04, PNorm = 44.7286, GNorm = 0.3345, lr_0 = 4.4005e-04
Loss = 1.8234e-04, PNorm = 44.7349, GNorm = 0.5111, lr_0 = 4.3946e-04
Loss = 1.3868e-04, PNorm = 44.7425, GNorm = 0.3634, lr_0 = 4.3887e-04
Loss = 1.9030e-04, PNorm = 44.7492, GNorm = 0.1684, lr_0 = 4.3828e-04
Loss = 1.8003e-04, PNorm = 44.7568, GNorm = 0.2662, lr_0 = 4.3769e-04
Validation rmse = 0.482546
Validation R2 = 0.935387
Epoch 37
Train function
Loss = 1.6338e-04, PNorm = 44.7620, GNorm = 0.2724, lr_0 = 4.3704e-04
Loss = 1.7476e-04, PNorm = 44.7703, GNorm = 0.2639, lr_0 = 4.3646e-04
Loss = 1.7387e-04, PNorm = 44.7803, GNorm = 0.2580, lr_0 = 4.3587e-04
Loss = 1.9331e-04, PNorm = 44.7884, GNorm = 0.2383, lr_0 = 4.3529e-04
Loss = 1.6769e-04, PNorm = 44.7976, GNorm = 0.5703, lr_0 = 4.3470e-04
Loss = 1.5123e-04, PNorm = 44.8048, GNorm = 0.3436, lr_0 = 4.3412e-04
Loss = 2.2329e-04, PNorm = 44.8156, GNorm = 0.7218, lr_0 = 4.3354e-04
Loss = 1.8059e-04, PNorm = 44.8232, GNorm = 0.6231, lr_0 = 4.3296e-04
Loss = 1.5427e-04, PNorm = 44.8336, GNorm = 0.2326, lr_0 = 4.3237e-04
Loss = 1.4282e-04, PNorm = 44.8410, GNorm = 0.2033, lr_0 = 4.3179e-04
Loss = 1.9889e-04, PNorm = 44.8457, GNorm = 0.1817, lr_0 = 4.3122e-04
Loss = 1.7600e-04, PNorm = 44.8531, GNorm = 0.5046, lr_0 = 4.3064e-04
Loss = 1.3076e-04, PNorm = 44.8591, GNorm = 0.1800, lr_0 = 4.3006e-04
Loss = 1.2271e-04, PNorm = 44.8653, GNorm = 0.2435, lr_0 = 4.2948e-04
Loss = 1.7082e-04, PNorm = 44.8654, GNorm = 0.5070, lr_0 = 4.2891e-04
Loss = 1.5235e-04, PNorm = 44.8723, GNorm = 0.2865, lr_0 = 4.2833e-04
Loss = 1.4863e-04, PNorm = 44.8827, GNorm = 0.4403, lr_0 = 4.2776e-04
Loss = 1.4861e-04, PNorm = 44.8833, GNorm = 0.2307, lr_0 = 4.2718e-04
Validation rmse = 0.474331
Validation R2 = 0.937568
Epoch 38
Train function
Loss = 1.2775e-04, PNorm = 44.8905, GNorm = 0.3425, lr_0 = 4.2661e-04
Loss = 1.6831e-04, PNorm = 44.8950, GNorm = 0.4519, lr_0 = 4.2604e-04
Loss = 1.6781e-04, PNorm = 44.9009, GNorm = 0.3991, lr_0 = 4.2546e-04
Loss = 1.2577e-04, PNorm = 44.9130, GNorm = 0.2259, lr_0 = 4.2489e-04
Loss = 1.2059e-04, PNorm = 44.9173, GNorm = 0.1538, lr_0 = 4.2432e-04
Loss = 1.0929e-04, PNorm = 44.9215, GNorm = 0.1569, lr_0 = 4.2375e-04
Loss = 1.3535e-04, PNorm = 44.9280, GNorm = 0.1458, lr_0 = 4.2319e-04
Loss = 1.0314e-04, PNorm = 44.9341, GNorm = 0.3187, lr_0 = 4.2262e-04
Loss = 1.7311e-04, PNorm = 44.9396, GNorm = 0.2065, lr_0 = 4.2205e-04
Loss = 1.3974e-04, PNorm = 44.9425, GNorm = 0.2006, lr_0 = 4.2148e-04
Loss = 1.9500e-04, PNorm = 44.9531, GNorm = 0.4399, lr_0 = 4.2092e-04
Loss = 1.4568e-04, PNorm = 44.9615, GNorm = 0.2263, lr_0 = 4.2035e-04
Loss = 1.2295e-04, PNorm = 44.9676, GNorm = 0.1740, lr_0 = 4.1979e-04
Loss = 1.8855e-04, PNorm = 44.9760, GNorm = 0.1930, lr_0 = 4.1923e-04
Loss = 1.6579e-04, PNorm = 44.9846, GNorm = 0.2412, lr_0 = 4.1866e-04
Loss = 1.3673e-04, PNorm = 44.9927, GNorm = 0.4295, lr_0 = 4.1810e-04
Loss = 1.4235e-04, PNorm = 44.9987, GNorm = 0.1731, lr_0 = 4.1754e-04
Validation rmse = 0.470283
Validation R2 = 0.938629
Epoch 39
Train function
Loss = 8.4209e-05, PNorm = 45.0096, GNorm = 0.2030, lr_0 = 4.1693e-04
Loss = 1.4106e-04, PNorm = 45.0169, GNorm = 0.1794, lr_0 = 4.1637e-04
Loss = 1.4085e-04, PNorm = 45.0227, GNorm = 0.4748, lr_0 = 4.1581e-04
Loss = 1.4654e-04, PNorm = 45.0294, GNorm = 0.3608, lr_0 = 4.1525e-04
Loss = 1.4552e-04, PNorm = 45.0313, GNorm = 0.6785, lr_0 = 4.1469e-04
Loss = 1.5915e-04, PNorm = 45.0409, GNorm = 0.5002, lr_0 = 4.1414e-04
Loss = 1.3200e-04, PNorm = 45.0459, GNorm = 0.1819, lr_0 = 4.1358e-04
Loss = 1.3623e-04, PNorm = 45.0496, GNorm = 0.1848, lr_0 = 4.1303e-04
Loss = 1.0488e-04, PNorm = 45.0558, GNorm = 0.3085, lr_0 = 4.1247e-04
Loss = 1.4650e-04, PNorm = 45.0584, GNorm = 0.6976, lr_0 = 4.1192e-04
Loss = 1.5714e-04, PNorm = 45.0692, GNorm = 0.3186, lr_0 = 4.1137e-04
Loss = 1.4417e-04, PNorm = 45.0740, GNorm = 0.3233, lr_0 = 4.1081e-04
Loss = 1.4608e-04, PNorm = 45.0814, GNorm = 0.4033, lr_0 = 4.1026e-04
Loss = 1.3574e-04, PNorm = 45.0890, GNorm = 0.5002, lr_0 = 4.0971e-04
Loss = 1.3509e-04, PNorm = 45.0965, GNorm = 0.2730, lr_0 = 4.0916e-04
Loss = 1.2682e-04, PNorm = 45.1014, GNorm = 0.2815, lr_0 = 4.0861e-04
Loss = 1.4491e-04, PNorm = 45.1079, GNorm = 0.3690, lr_0 = 4.0806e-04
Loss = 1.7021e-04, PNorm = 45.1135, GNorm = 0.2331, lr_0 = 4.0752e-04
Validation rmse = 0.473656
Validation R2 = 0.937746
Epoch 40
Train function
Loss = 1.3571e-04, PNorm = 45.1215, GNorm = 0.2153, lr_0 = 4.0697e-04
Loss = 1.3186e-04, PNorm = 45.1291, GNorm = 0.2712, lr_0 = 4.0642e-04
Loss = 8.0281e-05, PNorm = 45.1347, GNorm = 0.1970, lr_0 = 4.0588e-04
Loss = 8.6232e-05, PNorm = 45.1398, GNorm = 0.2680, lr_0 = 4.0533e-04
Loss = 1.4535e-04, PNorm = 45.1459, GNorm = 0.2647, lr_0 = 4.0479e-04
Loss = 1.1030e-04, PNorm = 45.1518, GNorm = 0.2290, lr_0 = 4.0425e-04
Loss = 1.5787e-04, PNorm = 45.1560, GNorm = 0.2387, lr_0 = 4.0371e-04
Loss = 1.2883e-04, PNorm = 45.1617, GNorm = 0.6316, lr_0 = 4.0316e-04
Loss = 1.9913e-04, PNorm = 45.1703, GNorm = 0.4996, lr_0 = 4.0262e-04
Loss = 1.7247e-04, PNorm = 45.1780, GNorm = 0.3254, lr_0 = 4.0208e-04
Loss = 1.6081e-04, PNorm = 45.1889, GNorm = 0.2360, lr_0 = 4.0154e-04
Loss = 1.1732e-04, PNorm = 45.1956, GNorm = 0.2612, lr_0 = 4.0100e-04
Loss = 1.2317e-04, PNorm = 45.2026, GNorm = 0.1877, lr_0 = 4.0047e-04
Loss = 1.1445e-04, PNorm = 45.2080, GNorm = 0.2682, lr_0 = 3.9993e-04
Loss = 1.0960e-04, PNorm = 45.2119, GNorm = 0.1630, lr_0 = 3.9939e-04
Loss = 1.2955e-04, PNorm = 45.2150, GNorm = 0.4886, lr_0 = 3.9886e-04
Loss = 1.3391e-04, PNorm = 45.2223, GNorm = 0.1529, lr_0 = 3.9832e-04
Loss = 1.6885e-04, PNorm = 45.2274, GNorm = 0.4822, lr_0 = 3.9779e-04
Validation rmse = 0.484871
Validation R2 = 0.934762
Epoch 41
Train function
Loss = 1.7237e-04, PNorm = 45.2355, GNorm = 0.5301, lr_0 = 3.9725e-04
Loss = 1.8064e-04, PNorm = 45.2456, GNorm = 0.4917, lr_0 = 3.9672e-04
Loss = 1.4718e-04, PNorm = 45.2541, GNorm = 0.4691, lr_0 = 3.9619e-04
Loss = 1.1608e-04, PNorm = 45.2577, GNorm = 0.2384, lr_0 = 3.9566e-04
Loss = 1.1256e-04, PNorm = 45.2646, GNorm = 0.1849, lr_0 = 3.9513e-04
Loss = 9.4530e-05, PNorm = 45.2686, GNorm = 0.2676, lr_0 = 3.9460e-04
Loss = 1.0930e-04, PNorm = 45.2732, GNorm = 0.1544, lr_0 = 3.9407e-04
Loss = 9.4043e-05, PNorm = 45.2798, GNorm = 0.3757, lr_0 = 3.9354e-04
Loss = 1.0426e-04, PNorm = 45.2838, GNorm = 0.1466, lr_0 = 3.9301e-04
Loss = 1.1057e-04, PNorm = 45.2883, GNorm = 0.3235, lr_0 = 3.9248e-04
Loss = 1.1668e-04, PNorm = 45.2928, GNorm = 0.2484, lr_0 = 3.9195e-04
Loss = 9.2695e-05, PNorm = 45.2967, GNorm = 0.1107, lr_0 = 3.9143e-04
Loss = 1.6189e-04, PNorm = 45.3041, GNorm = 0.3156, lr_0 = 3.9090e-04
Loss = 9.4495e-05, PNorm = 45.3086, GNorm = 0.1709, lr_0 = 3.9038e-04
Loss = 1.2952e-04, PNorm = 45.3137, GNorm = 0.2095, lr_0 = 3.8986e-04
Loss = 1.1385e-04, PNorm = 45.3186, GNorm = 0.1484, lr_0 = 3.8933e-04
Loss = 1.4355e-04, PNorm = 45.3232, GNorm = 0.2271, lr_0 = 3.8881e-04
Validation rmse = 0.471359
Validation R2 = 0.938348
Epoch 42
Train function
Loss = 7.9905e-05, PNorm = 45.3292, GNorm = 0.1943, lr_0 = 3.8824e-04
Loss = 9.5826e-05, PNorm = 45.3332, GNorm = 0.1870, lr_0 = 3.8772e-04
Loss = 9.7348e-05, PNorm = 45.3382, GNorm = 0.2474, lr_0 = 3.8720e-04
Loss = 9.7103e-05, PNorm = 45.3438, GNorm = 0.2913, lr_0 = 3.8668e-04
Loss = 1.2323e-04, PNorm = 45.3501, GNorm = 0.3229, lr_0 = 3.8616e-04
Loss = 1.2384e-04, PNorm = 45.3566, GNorm = 0.2099, lr_0 = 3.8564e-04
Loss = 1.3358e-04, PNorm = 45.3605, GNorm = 0.2987, lr_0 = 3.8512e-04
Loss = 1.3103e-04, PNorm = 45.3660, GNorm = 0.3849, lr_0 = 3.8460e-04
Loss = 9.7880e-05, PNorm = 45.3713, GNorm = 0.1316, lr_0 = 3.8409e-04
Loss = 1.2971e-04, PNorm = 45.3767, GNorm = 0.2819, lr_0 = 3.8357e-04
Loss = 1.4084e-04, PNorm = 45.3808, GNorm = 0.4924, lr_0 = 3.8306e-04
Loss = 1.4625e-04, PNorm = 45.3878, GNorm = 0.5951, lr_0 = 3.8254e-04
Loss = 1.5283e-04, PNorm = 45.3956, GNorm = 0.6389, lr_0 = 3.8203e-04
Loss = 1.6667e-04, PNorm = 45.4031, GNorm = 0.2947, lr_0 = 3.8152e-04
Loss = 1.5256e-04, PNorm = 45.4130, GNorm = 0.1815, lr_0 = 3.8101e-04
Loss = 1.3990e-04, PNorm = 45.4195, GNorm = 0.2709, lr_0 = 3.8050e-04
Loss = 1.0947e-04, PNorm = 45.4276, GNorm = 0.2312, lr_0 = 3.7999e-04
Loss = 1.5698e-04, PNorm = 45.4356, GNorm = 0.1658, lr_0 = 3.7948e-04
Validation rmse = 0.475723
Validation R2 = 0.937201
Epoch 43
Train function
Loss = 1.5315e-04, PNorm = 45.4423, GNorm = 0.2642, lr_0 = 3.7897e-04
Loss = 8.6044e-05, PNorm = 45.4474, GNorm = 0.2077, lr_0 = 3.7846e-04
Loss = 9.9896e-05, PNorm = 45.4500, GNorm = 0.3084, lr_0 = 3.7795e-04
Loss = 1.0241e-04, PNorm = 45.4552, GNorm = 0.2846, lr_0 = 3.7744e-04
Loss = 1.0015e-04, PNorm = 45.4601, GNorm = 0.2482, lr_0 = 3.7694e-04
Loss = 9.2081e-05, PNorm = 45.4646, GNorm = 0.1399, lr_0 = 3.7643e-04
Loss = 1.3672e-04, PNorm = 45.4691, GNorm = 0.2293, lr_0 = 3.7593e-04
Loss = 9.0734e-05, PNorm = 45.4744, GNorm = 0.2575, lr_0 = 3.7542e-04
Loss = 1.0827e-04, PNorm = 45.4811, GNorm = 0.1330, lr_0 = 3.7492e-04
Loss = 8.3618e-05, PNorm = 45.4856, GNorm = 0.1190, lr_0 = 3.7441e-04
Loss = 1.1630e-04, PNorm = 45.4863, GNorm = 0.2434, lr_0 = 3.7391e-04
Loss = 1.1493e-04, PNorm = 45.4896, GNorm = 0.1783, lr_0 = 3.7341e-04
Loss = 8.2872e-05, PNorm = 45.4982, GNorm = 0.2653, lr_0 = 3.7291e-04
Loss = 1.0831e-04, PNorm = 45.5041, GNorm = 0.4986, lr_0 = 3.7241e-04
Loss = 1.2712e-04, PNorm = 45.5091, GNorm = 0.3913, lr_0 = 3.7191e-04
Loss = 1.0259e-04, PNorm = 45.5163, GNorm = 0.1676, lr_0 = 3.7141e-04
Loss = 8.4534e-05, PNorm = 45.5221, GNorm = 0.1894, lr_0 = 3.7091e-04
Validation rmse = 0.477113
Validation R2 = 0.936834
Epoch 44
Train function
Loss = 8.9296e-05, PNorm = 45.5276, GNorm = 0.3898, lr_0 = 3.7041e-04
Loss = 1.2988e-04, PNorm = 45.5348, GNorm = 0.5112, lr_0 = 3.6992e-04
Loss = 9.9188e-05, PNorm = 45.5412, GNorm = 0.2665, lr_0 = 3.6942e-04
Loss = 8.2250e-05, PNorm = 45.5479, GNorm = 0.1571, lr_0 = 3.6893e-04
Loss = 9.5990e-05, PNorm = 45.5526, GNorm = 0.2281, lr_0 = 3.6843e-04
Loss = 8.2682e-05, PNorm = 45.5617, GNorm = 0.2574, lr_0 = 3.6794e-04
Loss = 9.3173e-05, PNorm = 45.5656, GNorm = 0.2792, lr_0 = 3.6744e-04
Loss = 1.2378e-04, PNorm = 45.5707, GNorm = 0.2227, lr_0 = 3.6695e-04
Loss = 1.0199e-04, PNorm = 45.5729, GNorm = 0.2039, lr_0 = 3.6646e-04
Loss = 1.3772e-04, PNorm = 45.5779, GNorm = 0.3754, lr_0 = 3.6597e-04
Loss = 9.0519e-05, PNorm = 45.5787, GNorm = 0.1660, lr_0 = 3.6547e-04
Loss = 1.1820e-04, PNorm = 45.5855, GNorm = 0.1170, lr_0 = 3.6498e-04
Loss = 1.1267e-04, PNorm = 45.5893, GNorm = 0.1526, lr_0 = 3.6449e-04
Loss = 1.0882e-04, PNorm = 45.5951, GNorm = 0.4288, lr_0 = 3.6401e-04
Loss = 1.1487e-04, PNorm = 45.5999, GNorm = 0.2551, lr_0 = 3.6352e-04
Loss = 1.0010e-04, PNorm = 45.6052, GNorm = 0.2460, lr_0 = 3.6303e-04
Loss = 1.1271e-04, PNorm = 45.6109, GNorm = 0.1356, lr_0 = 3.6254e-04
Loss = 1.0924e-04, PNorm = 45.6147, GNorm = 0.3533, lr_0 = 3.6206e-04
Validation rmse = 0.472236
Validation R2 = 0.938118
Epoch 45
Train function
Loss = 9.9383e-05, PNorm = 45.6200, GNorm = 0.1475, lr_0 = 3.6152e-04
Loss = 9.0058e-05, PNorm = 45.6273, GNorm = 0.3201, lr_0 = 3.6104e-04
Loss = 1.2632e-04, PNorm = 45.6290, GNorm = 0.2256, lr_0 = 3.6055e-04
Loss = 1.1939e-04, PNorm = 45.6381, GNorm = 0.1360, lr_0 = 3.6007e-04
Loss = 8.5904e-05, PNorm = 45.6434, GNorm = 0.1410, lr_0 = 3.5959e-04
Loss = 9.3538e-05, PNorm = 45.6481, GNorm = 0.1347, lr_0 = 3.5910e-04
Loss = 1.2973e-04, PNorm = 45.6551, GNorm = 0.1742, lr_0 = 3.5862e-04
Loss = 1.1906e-04, PNorm = 45.6615, GNorm = 0.1504, lr_0 = 3.5814e-04
Loss = 1.2274e-04, PNorm = 45.6647, GNorm = 0.6886, lr_0 = 3.5766e-04
Loss = 1.3560e-04, PNorm = 45.6664, GNorm = 0.2586, lr_0 = 3.5718e-04
Loss = 1.0927e-04, PNorm = 45.6706, GNorm = 0.1709, lr_0 = 3.5670e-04
Loss = 1.1702e-04, PNorm = 45.6755, GNorm = 0.1817, lr_0 = 3.5622e-04
Loss = 1.1788e-04, PNorm = 45.6820, GNorm = 0.2718, lr_0 = 3.5574e-04
Loss = 9.6317e-05, PNorm = 45.6876, GNorm = 0.2621, lr_0 = 3.5527e-04
Loss = 9.6986e-05, PNorm = 45.6903, GNorm = 0.3078, lr_0 = 3.5479e-04
Loss = 8.4070e-05, PNorm = 45.6949, GNorm = 0.1426, lr_0 = 3.5431e-04
Loss = 1.2407e-04, PNorm = 45.7004, GNorm = 0.1642, lr_0 = 3.5384e-04
Validation rmse = 0.479069
Validation R2 = 0.936315
Epoch 46
Train function
Loss = 1.2361e-04, PNorm = 45.7044, GNorm = 0.5032, lr_0 = 3.5336e-04
Loss = 9.6870e-05, PNorm = 45.7084, GNorm = 0.5737, lr_0 = 3.5289e-04
Loss = 7.7795e-05, PNorm = 45.7142, GNorm = 0.1138, lr_0 = 3.5242e-04
Loss = 8.1696e-05, PNorm = 45.7173, GNorm = 0.2950, lr_0 = 3.5194e-04
Loss = 6.8780e-05, PNorm = 45.7216, GNorm = 0.2858, lr_0 = 3.5147e-04
Loss = 5.9964e-05, PNorm = 45.7265, GNorm = 0.1593, lr_0 = 3.5100e-04
Loss = 7.0188e-05, PNorm = 45.7284, GNorm = 0.1098, lr_0 = 3.5053e-04
Loss = 1.0186e-04, PNorm = 45.7322, GNorm = 0.1722, lr_0 = 3.5006e-04
Loss = 1.1925e-04, PNorm = 45.7401, GNorm = 0.3069, lr_0 = 3.4959e-04
Loss = 1.1463e-04, PNorm = 45.7446, GNorm = 0.1502, lr_0 = 3.4912e-04
Loss = 9.8456e-05, PNorm = 45.7520, GNorm = 0.1941, lr_0 = 3.4865e-04
Loss = 9.9036e-05, PNorm = 45.7597, GNorm = 0.2171, lr_0 = 3.4818e-04
Loss = 7.5349e-05, PNorm = 45.7643, GNorm = 0.1798, lr_0 = 3.4772e-04
Loss = 1.2147e-04, PNorm = 45.7705, GNorm = 0.1642, lr_0 = 3.4725e-04
Loss = 9.4111e-05, PNorm = 45.7772, GNorm = 0.1401, lr_0 = 3.4678e-04
Loss = 9.5093e-05, PNorm = 45.7819, GNorm = 0.2027, lr_0 = 3.4632e-04
Loss = 8.5799e-05, PNorm = 45.7867, GNorm = 0.1040, lr_0 = 3.4585e-04
Loss = 9.8042e-05, PNorm = 45.7905, GNorm = 0.2127, lr_0 = 3.4539e-04
Validation rmse = 0.472856
Validation R2 = 0.937956
Epoch 47
Train function
Loss = 7.3348e-05, PNorm = 45.7979, GNorm = 0.2560, lr_0 = 3.4493e-04
Loss = 6.4730e-05, PNorm = 45.8020, GNorm = 0.1256, lr_0 = 3.4446e-04
Loss = 9.4254e-05, PNorm = 45.8051, GNorm = 0.3505, lr_0 = 3.4400e-04
Loss = 7.5151e-05, PNorm = 45.8083, GNorm = 0.3686, lr_0 = 3.4354e-04
Loss = 8.2666e-05, PNorm = 45.8114, GNorm = 0.4180, lr_0 = 3.4308e-04
Loss = 8.7371e-05, PNorm = 45.8161, GNorm = 0.2789, lr_0 = 3.4262e-04
Loss = 9.2747e-05, PNorm = 45.8217, GNorm = 0.3603, lr_0 = 3.4216e-04
Loss = 8.4232e-05, PNorm = 45.8265, GNorm = 0.1266, lr_0 = 3.4170e-04
Loss = 8.8855e-05, PNorm = 45.8288, GNorm = 0.1304, lr_0 = 3.4124e-04
Loss = 1.0097e-04, PNorm = 45.8323, GNorm = 0.1981, lr_0 = 3.4078e-04
Loss = 7.9958e-05, PNorm = 45.8389, GNorm = 0.1785, lr_0 = 3.4033e-04
Loss = 6.9948e-05, PNorm = 45.8415, GNorm = 0.2814, lr_0 = 3.3987e-04
Loss = 1.1200e-04, PNorm = 45.8459, GNorm = 0.1818, lr_0 = 3.3941e-04
Loss = 1.0611e-04, PNorm = 45.8498, GNorm = 0.2444, lr_0 = 3.3896e-04
Loss = 8.5880e-05, PNorm = 45.8525, GNorm = 0.2857, lr_0 = 3.3850e-04
Loss = 1.0386e-04, PNorm = 45.8547, GNorm = 0.3487, lr_0 = 3.3805e-04
Loss = 1.0755e-04, PNorm = 45.8619, GNorm = 0.2427, lr_0 = 3.3760e-04
Loss = 9.6177e-05, PNorm = 45.8677, GNorm = 0.1591, lr_0 = 3.3714e-04
Loss = 1.2282e-04, PNorm = 45.8683, GNorm = 0.1886, lr_0 = 3.3710e-04
Validation rmse = 0.477564
Validation R2 = 0.936714
Epoch 48
Train function
Loss = 1.1555e-04, PNorm = 45.8778, GNorm = 0.1781, lr_0 = 3.3664e-04
Loss = 7.7965e-05, PNorm = 45.8812, GNorm = 0.1172, lr_0 = 3.3619e-04
Loss = 7.5459e-05, PNorm = 45.8844, GNorm = 0.1872, lr_0 = 3.3574e-04
Loss = 8.2223e-05, PNorm = 45.8867, GNorm = 0.2525, lr_0 = 3.3529e-04
Loss = 8.2847e-05, PNorm = 45.8902, GNorm = 0.2853, lr_0 = 3.3484e-04
Loss = 6.5957e-05, PNorm = 45.8923, GNorm = 0.1371, lr_0 = 3.3439e-04
Loss = 7.4050e-05, PNorm = 45.8956, GNorm = 0.2951, lr_0 = 3.3394e-04
Loss = 1.1106e-04, PNorm = 45.9033, GNorm = 0.2656, lr_0 = 3.3350e-04
Loss = 9.6719e-05, PNorm = 45.9084, GNorm = 0.1315, lr_0 = 3.3305e-04
Loss = 8.7553e-05, PNorm = 45.9133, GNorm = 0.4155, lr_0 = 3.3260e-04
Loss = 9.3431e-05, PNorm = 45.9181, GNorm = 0.2657, lr_0 = 3.3216e-04
Loss = 9.2875e-05, PNorm = 45.9207, GNorm = 0.3574, lr_0 = 3.3171e-04
Loss = 7.5778e-05, PNorm = 45.9256, GNorm = 0.2615, lr_0 = 3.3126e-04
Loss = 1.0031e-04, PNorm = 45.9312, GNorm = 0.1975, lr_0 = 3.3082e-04
Loss = 7.6335e-05, PNorm = 45.9349, GNorm = 0.1970, lr_0 = 3.3038e-04
Loss = 9.2171e-05, PNorm = 45.9395, GNorm = 0.1463, lr_0 = 3.2993e-04
Loss = 6.9994e-05, PNorm = 45.9439, GNorm = 0.4537, lr_0 = 3.2949e-04
Validation rmse = 0.470875
Validation R2 = 0.938474
Epoch 49
Train function
Loss = 6.3248e-05, PNorm = 45.9462, GNorm = 0.2629, lr_0 = 3.2905e-04
Loss = 7.6986e-05, PNorm = 45.9507, GNorm = 0.3279, lr_0 = 3.2861e-04
Loss = 7.5293e-05, PNorm = 45.9548, GNorm = 0.3035, lr_0 = 3.2817e-04
Loss = 7.9342e-05, PNorm = 45.9583, GNorm = 0.1545, lr_0 = 3.2773e-04
Loss = 6.9946e-05, PNorm = 45.9604, GNorm = 0.1907, lr_0 = 3.2729e-04
Loss = 1.1942e-04, PNorm = 45.9643, GNorm = 0.3486, lr_0 = 3.2685e-04
Loss = 1.0248e-04, PNorm = 45.9678, GNorm = 0.2112, lr_0 = 3.2641e-04
Loss = 6.5300e-05, PNorm = 45.9729, GNorm = 0.1284, lr_0 = 3.2597e-04
Loss = 6.9164e-05, PNorm = 45.9776, GNorm = 0.0880, lr_0 = 3.2553e-04
Loss = 7.3708e-05, PNorm = 45.9824, GNorm = 0.1332, lr_0 = 3.2510e-04
Loss = 7.8762e-05, PNorm = 45.9879, GNorm = 0.1107, lr_0 = 3.2466e-04
Loss = 5.6575e-05, PNorm = 45.9931, GNorm = 0.2531, lr_0 = 3.2422e-04
Loss = 8.3256e-05, PNorm = 45.9956, GNorm = 0.2195, lr_0 = 3.2379e-04
Loss = 7.3095e-05, PNorm = 45.9987, GNorm = 0.1922, lr_0 = 3.2335e-04
Loss = 8.2309e-05, PNorm = 46.0059, GNorm = 0.1258, lr_0 = 3.2292e-04
Loss = 9.1737e-05, PNorm = 46.0129, GNorm = 0.3327, lr_0 = 3.2249e-04
Loss = 9.3336e-05, PNorm = 46.0144, GNorm = 0.3895, lr_0 = 3.2205e-04
Loss = 8.2305e-05, PNorm = 46.0178, GNorm = 0.1431, lr_0 = 3.2162e-04
Validation rmse = 0.474513
Validation R2 = 0.937520
Epoch 50
Train function
Loss = 7.5778e-05, PNorm = 46.0239, GNorm = 0.1366, lr_0 = 3.2119e-04
Loss = 6.9642e-05, PNorm = 46.0279, GNorm = 0.1258, lr_0 = 3.2076e-04
Loss = 6.4688e-05, PNorm = 46.0322, GNorm = 0.2092, lr_0 = 3.2033e-04
Loss = 7.3426e-05, PNorm = 46.0376, GNorm = 0.1497, lr_0 = 3.1990e-04
Loss = 8.0193e-05, PNorm = 46.0406, GNorm = 0.1723, lr_0 = 3.1947e-04
Loss = 6.8908e-05, PNorm = 46.0450, GNorm = 0.1262, lr_0 = 3.1904e-04
Loss = 7.4384e-05, PNorm = 46.0479, GNorm = 0.1058, lr_0 = 3.1861e-04
Loss = 6.8231e-05, PNorm = 46.0512, GNorm = 0.1470, lr_0 = 3.1819e-04
Loss = 7.4801e-05, PNorm = 46.0544, GNorm = 0.3002, lr_0 = 3.1776e-04
Loss = 6.3031e-05, PNorm = 46.0591, GNorm = 0.1189, lr_0 = 3.1733e-04
Loss = 7.4553e-05, PNorm = 46.0616, GNorm = 0.1515, lr_0 = 3.1691e-04
Loss = 6.8807e-05, PNorm = 46.0678, GNorm = 0.1953, lr_0 = 3.1648e-04
Loss = 1.1740e-04, PNorm = 46.0732, GNorm = 0.2316, lr_0 = 3.1606e-04
Loss = 8.4010e-05, PNorm = 46.0816, GNorm = 0.3866, lr_0 = 3.1563e-04
Loss = 8.5712e-05, PNorm = 46.0846, GNorm = 0.1721, lr_0 = 3.1521e-04
Loss = 7.2465e-05, PNorm = 46.0886, GNorm = 0.2105, lr_0 = 3.1479e-04
Loss = 1.0785e-04, PNorm = 46.0929, GNorm = 0.1520, lr_0 = 3.1437e-04
Validation rmse = 0.472244
Validation R2 = 0.938116
Epoch 51
Train function
Loss = 6.0601e-05, PNorm = 46.0996, GNorm = 0.1465, lr_0 = 3.1390e-04
Loss = 6.2393e-05, PNorm = 46.1028, GNorm = 0.2139, lr_0 = 3.1348e-04
Loss = 7.8093e-05, PNorm = 46.1063, GNorm = 0.3360, lr_0 = 3.1306e-04
Loss = 6.9560e-05, PNorm = 46.1124, GNorm = 0.2937, lr_0 = 3.1264e-04
Loss = 6.8548e-05, PNorm = 46.1162, GNorm = 0.2689, lr_0 = 3.1222e-04
Loss = 5.2652e-05, PNorm = 46.1191, GNorm = 0.1514, lr_0 = 3.1180e-04
Loss = 6.2721e-05, PNorm = 46.1231, GNorm = 0.1814, lr_0 = 3.1138e-04
Loss = 5.9162e-05, PNorm = 46.1287, GNorm = 0.1718, lr_0 = 3.1096e-04
Loss = 6.6128e-05, PNorm = 46.1317, GNorm = 0.1239, lr_0 = 3.1055e-04
Loss = 6.1986e-05, PNorm = 46.1345, GNorm = 0.1335, lr_0 = 3.1013e-04
Loss = 6.5874e-05, PNorm = 46.1382, GNorm = 0.1405, lr_0 = 3.0971e-04
Loss = 6.9118e-05, PNorm = 46.1432, GNorm = 0.2063, lr_0 = 3.0930e-04
Loss = 6.3537e-05, PNorm = 46.1451, GNorm = 0.2306, lr_0 = 3.0888e-04
Loss = 5.7225e-05, PNorm = 46.1471, GNorm = 0.1455, lr_0 = 3.0847e-04
Loss = 9.7464e-05, PNorm = 46.1510, GNorm = 0.2380, lr_0 = 3.0806e-04
Loss = 9.8884e-05, PNorm = 46.1585, GNorm = 0.2385, lr_0 = 3.0764e-04
Loss = 9.4606e-05, PNorm = 46.1637, GNorm = 0.2276, lr_0 = 3.0723e-04
Loss = 6.4920e-05, PNorm = 46.1680, GNorm = 0.2193, lr_0 = 3.0682e-04
Validation rmse = 0.479185
Validation R2 = 0.936284
Epoch 52
Train function
Loss = 5.1578e-05, PNorm = 46.1721, GNorm = 0.1129, lr_0 = 3.0641e-04
Loss = 8.0801e-05, PNorm = 46.1754, GNorm = 0.1154, lr_0 = 3.0599e-04
Loss = 6.7525e-05, PNorm = 46.1824, GNorm = 0.1737, lr_0 = 3.0558e-04
Loss = 8.4552e-05, PNorm = 46.1874, GNorm = 0.3791, lr_0 = 3.0517e-04
Loss = 7.5931e-05, PNorm = 46.1909, GNorm = 0.3028, lr_0 = 3.0476e-04
Loss = 7.0626e-05, PNorm = 46.1945, GNorm = 0.4205, lr_0 = 3.0436e-04
Loss = 7.0580e-05, PNorm = 46.2012, GNorm = 0.1328, lr_0 = 3.0395e-04
Loss = 5.0620e-05, PNorm = 46.2036, GNorm = 0.0898, lr_0 = 3.0354e-04
Loss = 6.4779e-05, PNorm = 46.2045, GNorm = 0.1546, lr_0 = 3.0313e-04
Loss = 6.1909e-05, PNorm = 46.2082, GNorm = 0.1003, lr_0 = 3.0273e-04
Loss = 6.9976e-05, PNorm = 46.2095, GNorm = 0.1362, lr_0 = 3.0232e-04
Loss = 6.9202e-05, PNorm = 46.2131, GNorm = 0.1548, lr_0 = 3.0191e-04
Loss = 8.0913e-05, PNorm = 46.2165, GNorm = 0.3098, lr_0 = 3.0151e-04
Loss = 9.1830e-05, PNorm = 46.2219, GNorm = 0.2539, lr_0 = 3.0110e-04
Loss = 8.0098e-05, PNorm = 46.2266, GNorm = 0.3429, lr_0 = 3.0070e-04
Loss = 7.3394e-05, PNorm = 46.2307, GNorm = 0.2035, lr_0 = 3.0030e-04
Loss = 6.1128e-05, PNorm = 46.2325, GNorm = 0.1435, lr_0 = 2.9989e-04
Validation rmse = 0.477819
Validation R2 = 0.936647
Epoch 53
Train function
Loss = 7.2371e-05, PNorm = 46.2367, GNorm = 0.3146, lr_0 = 2.9945e-04
Loss = 8.4136e-05, PNorm = 46.2438, GNorm = 0.3515, lr_0 = 2.9905e-04
Loss = 5.1253e-05, PNorm = 46.2458, GNorm = 0.2387, lr_0 = 2.9865e-04
Loss = 6.5606e-05, PNorm = 46.2489, GNorm = 0.1989, lr_0 = 2.9825e-04
Loss = 5.3719e-05, PNorm = 46.2537, GNorm = 0.3634, lr_0 = 2.9785e-04
Loss = 5.7515e-05, PNorm = 46.2601, GNorm = 0.1954, lr_0 = 2.9745e-04
Loss = 5.7415e-05, PNorm = 46.2643, GNorm = 0.0987, lr_0 = 2.9705e-04
Loss = 6.9467e-05, PNorm = 46.2696, GNorm = 0.2949, lr_0 = 2.9665e-04
Loss = 6.1747e-05, PNorm = 46.2707, GNorm = 0.2056, lr_0 = 2.9625e-04
Loss = 7.0997e-05, PNorm = 46.2762, GNorm = 0.1270, lr_0 = 2.9585e-04
Loss = 6.0289e-05, PNorm = 46.2788, GNorm = 0.1295, lr_0 = 2.9546e-04
Loss = 4.2327e-05, PNorm = 46.2786, GNorm = 0.0860, lr_0 = 2.9506e-04
Loss = 5.1741e-05, PNorm = 46.2821, GNorm = 0.1626, lr_0 = 2.9467e-04
Loss = 6.4412e-05, PNorm = 46.2859, GNorm = 0.1095, lr_0 = 2.9427e-04
Loss = 5.9018e-05, PNorm = 46.2929, GNorm = 0.2478, lr_0 = 2.9388e-04
Loss = 4.8336e-05, PNorm = 46.2948, GNorm = 0.2044, lr_0 = 2.9348e-04
Loss = 6.6523e-05, PNorm = 46.2980, GNorm = 0.1507, lr_0 = 2.9309e-04
Loss = 6.3048e-05, PNorm = 46.3016, GNorm = 0.2916, lr_0 = 2.9269e-04
Validation rmse = 0.473131
Validation R2 = 0.937884
Epoch 54
Train function
Loss = 5.1499e-05, PNorm = 46.3027, GNorm = 0.1733, lr_0 = 2.9230e-04
Loss = 6.2925e-05, PNorm = 46.3059, GNorm = 0.2318, lr_0 = 2.9191e-04
Loss = 4.2076e-05, PNorm = 46.3108, GNorm = 0.1012, lr_0 = 2.9152e-04
Loss = 4.9625e-05, PNorm = 46.3160, GNorm = 0.1064, lr_0 = 2.9113e-04
Loss = 4.5956e-05, PNorm = 46.3169, GNorm = 0.1919, lr_0 = 2.9074e-04
Loss = 4.1778e-05, PNorm = 46.3194, GNorm = 0.1636, lr_0 = 2.9035e-04
Loss = 5.5936e-05, PNorm = 46.3229, GNorm = 0.1657, lr_0 = 2.8996e-04
Loss = 5.6098e-05, PNorm = 46.3266, GNorm = 0.2359, lr_0 = 2.8957e-04
Loss = 5.8269e-05, PNorm = 46.3306, GNorm = 0.1427, lr_0 = 2.8918e-04
Loss = 5.3921e-05, PNorm = 46.3342, GNorm = 0.1645, lr_0 = 2.8879e-04
Loss = 8.7878e-05, PNorm = 46.3385, GNorm = 0.2636, lr_0 = 2.8840e-04
Loss = 6.9503e-05, PNorm = 46.3431, GNorm = 0.1836, lr_0 = 2.8802e-04
Loss = 5.9154e-05, PNorm = 46.3454, GNorm = 0.2387, lr_0 = 2.8763e-04
Loss = 6.2585e-05, PNorm = 46.3465, GNorm = 0.1934, lr_0 = 2.8724e-04
Loss = 6.1145e-05, PNorm = 46.3513, GNorm = 0.2427, lr_0 = 2.8686e-04
Loss = 6.0878e-05, PNorm = 46.3572, GNorm = 0.1964, lr_0 = 2.8647e-04
Loss = 6.4577e-05, PNorm = 46.3587, GNorm = 0.0926, lr_0 = 2.8609e-04
Loss = 7.1153e-05, PNorm = 46.3648, GNorm = 0.1713, lr_0 = 2.8571e-04
Validation rmse = 0.473771
Validation R2 = 0.937715
Epoch 55
Train function
Loss = 4.2955e-05, PNorm = 46.3668, GNorm = 0.0908, lr_0 = 2.8532e-04
Loss = 5.5158e-05, PNorm = 46.3699, GNorm = 0.1410, lr_0 = 2.8494e-04
Loss = 4.8643e-05, PNorm = 46.3730, GNorm = 0.1416, lr_0 = 2.8456e-04
Loss = 4.4779e-05, PNorm = 46.3744, GNorm = 0.1189, lr_0 = 2.8418e-04
Loss = 7.3566e-05, PNorm = 46.3782, GNorm = 0.3394, lr_0 = 2.8379e-04
Loss = 7.9422e-05, PNorm = 46.3850, GNorm = 0.2331, lr_0 = 2.8341e-04
Loss = 6.2753e-05, PNorm = 46.3908, GNorm = 0.4415, lr_0 = 2.8303e-04
Loss = 6.2126e-05, PNorm = 46.3926, GNorm = 0.2644, lr_0 = 2.8265e-04
Loss = 5.8182e-05, PNorm = 46.3970, GNorm = 0.3375, lr_0 = 2.8227e-04
Loss = 7.2068e-05, PNorm = 46.3993, GNorm = 0.2193, lr_0 = 2.8190e-04
Loss = 6.2105e-05, PNorm = 46.4014, GNorm = 0.1269, lr_0 = 2.8152e-04
Loss = 5.8210e-05, PNorm = 46.4037, GNorm = 0.1740, lr_0 = 2.8114e-04
Loss = 4.8287e-05, PNorm = 46.4073, GNorm = 0.1442, lr_0 = 2.8076e-04
Loss = 5.7393e-05, PNorm = 46.4086, GNorm = 0.1458, lr_0 = 2.8039e-04
Loss = 7.2152e-05, PNorm = 46.4147, GNorm = 0.1231, lr_0 = 2.8001e-04
Loss = 6.3907e-05, PNorm = 46.4207, GNorm = 0.1303, lr_0 = 2.7963e-04
Loss = 5.7138e-05, PNorm = 46.4250, GNorm = 0.1871, lr_0 = 2.7926e-04
Validation rmse = 0.476850
Validation R2 = 0.936903
Epoch 56
Train function
Loss = 5.4078e-05, PNorm = 46.4282, GNorm = 0.2200, lr_0 = 2.7885e-04
Loss = 5.1280e-05, PNorm = 46.4333, GNorm = 0.1705, lr_0 = 2.7847e-04
Loss = 4.1580e-05, PNorm = 46.4357, GNorm = 0.1136, lr_0 = 2.7810e-04
Loss = 4.8361e-05, PNorm = 46.4372, GNorm = 0.0984, lr_0 = 2.7773e-04
Loss = 4.8805e-05, PNorm = 46.4403, GNorm = 0.1913, lr_0 = 2.7735e-04
Loss = 5.2340e-05, PNorm = 46.4428, GNorm = 0.2082, lr_0 = 2.7698e-04
Loss = 4.1262e-05, PNorm = 46.4457, GNorm = 0.1500, lr_0 = 2.7661e-04
Loss = 5.6345e-05, PNorm = 46.4485, GNorm = 0.1508, lr_0 = 2.7624e-04
Loss = 4.4044e-05, PNorm = 46.4524, GNorm = 0.2156, lr_0 = 2.7587e-04
Loss = 5.6622e-05, PNorm = 46.4573, GNorm = 0.3481, lr_0 = 2.7550e-04
Loss = 4.5476e-05, PNorm = 46.4591, GNorm = 0.1212, lr_0 = 2.7513e-04
Loss = 6.0395e-05, PNorm = 46.4627, GNorm = 0.1315, lr_0 = 2.7476e-04
Loss = 5.4518e-05, PNorm = 46.4668, GNorm = 0.1926, lr_0 = 2.7439e-04
Loss = 5.3552e-05, PNorm = 46.4692, GNorm = 0.1517, lr_0 = 2.7402e-04
Loss = 5.2523e-05, PNorm = 46.4712, GNorm = 0.1054, lr_0 = 2.7365e-04
Loss = 4.4661e-05, PNorm = 46.4751, GNorm = 0.0898, lr_0 = 2.7329e-04
Loss = 6.0719e-05, PNorm = 46.4789, GNorm = 0.2103, lr_0 = 2.7292e-04
Loss = 7.3051e-05, PNorm = 46.4823, GNorm = 0.3174, lr_0 = 2.7255e-04
Validation rmse = 0.476337
Validation R2 = 0.937039
Epoch 57
Train function
Loss = 4.4822e-05, PNorm = 46.4851, GNorm = 0.1272, lr_0 = 2.7219e-04
Loss = 4.7776e-05, PNorm = 46.4882, GNorm = 0.0911, lr_0 = 2.7182e-04
Loss = 5.6130e-05, PNorm = 46.4913, GNorm = 0.1460, lr_0 = 2.7146e-04
Loss = 5.4536e-05, PNorm = 46.4971, GNorm = 0.1660, lr_0 = 2.7109e-04
Loss = 4.5060e-05, PNorm = 46.4996, GNorm = 0.1835, lr_0 = 2.7073e-04
Loss = 4.6532e-05, PNorm = 46.4995, GNorm = 0.2593, lr_0 = 2.7037e-04
Loss = 4.5500e-05, PNorm = 46.5015, GNorm = 0.1335, lr_0 = 2.7000e-04
Loss = 4.0491e-05, PNorm = 46.5031, GNorm = 0.1024, lr_0 = 2.6964e-04
Loss = 4.9770e-05, PNorm = 46.5048, GNorm = 0.3217, lr_0 = 2.6928e-04
Loss = 4.7304e-05, PNorm = 46.5072, GNorm = 0.1777, lr_0 = 2.6892e-04
Loss = 5.2215e-05, PNorm = 46.5100, GNorm = 0.1308, lr_0 = 2.6856e-04
Loss = 4.5978e-05, PNorm = 46.5144, GNorm = 0.1839, lr_0 = 2.6820e-04
Loss = 5.7118e-05, PNorm = 46.5164, GNorm = 0.1191, lr_0 = 2.6784e-04
Loss = 6.6121e-05, PNorm = 46.5171, GNorm = 0.1710, lr_0 = 2.6748e-04
Loss = 6.1454e-05, PNorm = 46.5211, GNorm = 0.1689, lr_0 = 2.6712e-04
Loss = 7.5560e-05, PNorm = 46.5266, GNorm = 0.2812, lr_0 = 2.6676e-04
Loss = 5.2025e-05, PNorm = 46.5300, GNorm = 0.0746, lr_0 = 2.6640e-04
Validation rmse = 0.476337
Validation R2 = 0.937039
Epoch 58
Train function
Loss = 3.3982e-05, PNorm = 46.5339, GNorm = 0.0776, lr_0 = 2.6605e-04
Loss = 4.4537e-05, PNorm = 46.5360, GNorm = 0.1550, lr_0 = 2.6569e-04
Loss = 5.3974e-05, PNorm = 46.5397, GNorm = 0.2618, lr_0 = 2.6533e-04
Loss = 5.8493e-05, PNorm = 46.5413, GNorm = 0.1270, lr_0 = 2.6498e-04
Loss = 7.8384e-05, PNorm = 46.5445, GNorm = 0.1918, lr_0 = 2.6462e-04
Loss = 5.5818e-05, PNorm = 46.5498, GNorm = 0.0905, lr_0 = 2.6427e-04
Loss = 4.9446e-05, PNorm = 46.5552, GNorm = 0.1420, lr_0 = 2.6391e-04
Loss = 5.2354e-05, PNorm = 46.5571, GNorm = 0.0855, lr_0 = 2.6356e-04
Loss = 4.8048e-05, PNorm = 46.5602, GNorm = 0.0711, lr_0 = 2.6320e-04
Loss = 4.7328e-05, PNorm = 46.5642, GNorm = 0.2514, lr_0 = 2.6285e-04
Loss = 4.6615e-05, PNorm = 46.5651, GNorm = 0.1302, lr_0 = 2.6250e-04
Loss = 4.5859e-05, PNorm = 46.5687, GNorm = 0.2309, lr_0 = 2.6215e-04
Loss = 5.6504e-05, PNorm = 46.5729, GNorm = 0.1281, lr_0 = 2.6179e-04
Loss = 3.5845e-05, PNorm = 46.5751, GNorm = 0.1047, lr_0 = 2.6144e-04
Loss = 5.6953e-05, PNorm = 46.5784, GNorm = 0.2519, lr_0 = 2.6109e-04
Loss = 5.6968e-05, PNorm = 46.5838, GNorm = 0.1277, lr_0 = 2.6074e-04
Loss = 5.2729e-05, PNorm = 46.5856, GNorm = 0.0735, lr_0 = 2.6039e-04
Loss = 5.4443e-05, PNorm = 46.5887, GNorm = 0.1927, lr_0 = 2.6004e-04
Validation rmse = 0.475718
Validation R2 = 0.937202
Epoch 59
Train function
Loss = 3.5404e-05, PNorm = 46.5908, GNorm = 0.1061, lr_0 = 2.5966e-04
Loss = 3.9323e-05, PNorm = 46.5928, GNorm = 0.0550, lr_0 = 2.5931e-04
Loss = 4.5618e-05, PNorm = 46.5954, GNorm = 0.0910, lr_0 = 2.5896e-04
Loss = 3.8871e-05, PNorm = 46.5960, GNorm = 0.0816, lr_0 = 2.5861e-04
Loss = 4.7855e-05, PNorm = 46.5990, GNorm = 0.2381, lr_0 = 2.5827e-04
Loss = 4.7394e-05, PNorm = 46.6015, GNorm = 0.2342, lr_0 = 2.5792e-04
Loss = 4.2006e-05, PNorm = 46.6066, GNorm = 0.1167, lr_0 = 2.5758e-04
Loss = 5.5141e-05, PNorm = 46.6096, GNorm = 0.2333, lr_0 = 2.5723e-04
Loss = 4.3445e-05, PNorm = 46.6097, GNorm = 0.1524, lr_0 = 2.5688e-04
Loss = 4.7612e-05, PNorm = 46.6128, GNorm = 0.1104, lr_0 = 2.5654e-04
Loss = 4.1536e-05, PNorm = 46.6150, GNorm = 0.0742, lr_0 = 2.5620e-04
Loss = 5.5619e-05, PNorm = 46.6180, GNorm = 0.1169, lr_0 = 2.5585e-04
Loss = 4.4136e-05, PNorm = 46.6212, GNorm = 0.1074, lr_0 = 2.5551e-04
Loss = 7.1196e-05, PNorm = 46.6224, GNorm = 0.2905, lr_0 = 2.5517e-04
Loss = 7.4471e-05, PNorm = 46.6274, GNorm = 0.1335, lr_0 = 2.5482e-04
Loss = 6.0380e-05, PNorm = 46.6325, GNorm = 0.1318, lr_0 = 2.5448e-04
Loss = 5.1886e-05, PNorm = 46.6348, GNorm = 0.1952, lr_0 = 2.5414e-04
Validation rmse = 0.477762
Validation R2 = 0.936662
Epoch 60
Train function
Loss = 5.6883e-05, PNorm = 46.6399, GNorm = 0.1782, lr_0 = 2.5380e-04
Loss = 4.7419e-05, PNorm = 46.6425, GNorm = 0.2779, lr_0 = 2.5346e-04
Loss = 4.9153e-05, PNorm = 46.6446, GNorm = 0.1141, lr_0 = 2.5312e-04
Loss = 4.6131e-05, PNorm = 46.6481, GNorm = 0.1730, lr_0 = 2.5278e-04
Loss = 3.8792e-05, PNorm = 46.6510, GNorm = 0.1614, lr_0 = 2.5244e-04
Loss = 4.8339e-05, PNorm = 46.6555, GNorm = 0.2073, lr_0 = 2.5210e-04
Loss = 4.3492e-05, PNorm = 46.6577, GNorm = 0.0832, lr_0 = 2.5176e-04
Loss = 4.2145e-05, PNorm = 46.6614, GNorm = 0.1746, lr_0 = 2.5142e-04
Loss = 4.8370e-05, PNorm = 46.6666, GNorm = 0.1687, lr_0 = 2.5109e-04
Loss = 5.5128e-05, PNorm = 46.6670, GNorm = 0.1682, lr_0 = 2.5075e-04
Loss = 5.1967e-05, PNorm = 46.6700, GNorm = 0.1118, lr_0 = 2.5041e-04
Loss = 4.9064e-05, PNorm = 46.6737, GNorm = 0.2086, lr_0 = 2.5008e-04
Loss = 4.0425e-05, PNorm = 46.6769, GNorm = 0.0810, lr_0 = 2.4974e-04
Loss = 3.4065e-05, PNorm = 46.6792, GNorm = 0.1105, lr_0 = 2.4941e-04
Loss = 4.8344e-05, PNorm = 46.6817, GNorm = 0.2587, lr_0 = 2.4907e-04
Loss = 4.1869e-05, PNorm = 46.6851, GNorm = 0.1798, lr_0 = 2.4874e-04
Loss = 4.3574e-05, PNorm = 46.6889, GNorm = 0.1829, lr_0 = 2.4841e-04
Loss = 4.2348e-05, PNorm = 46.6891, GNorm = 0.0741, lr_0 = 2.4807e-04
Validation rmse = 0.472172
Validation R2 = 0.938135
Epoch 61
Train function
Loss = 3.3023e-05, PNorm = 46.6902, GNorm = 0.1310, lr_0 = 2.4774e-04
Loss = 3.6511e-05, PNorm = 46.6926, GNorm = 0.1947, lr_0 = 2.4741e-04
Loss = 2.6118e-05, PNorm = 46.6962, GNorm = 0.0739, lr_0 = 2.4707e-04
Loss = 4.0352e-05, PNorm = 46.7006, GNorm = 0.1982, lr_0 = 2.4674e-04
Loss = 3.1879e-05, PNorm = 46.7017, GNorm = 0.1136, lr_0 = 2.4641e-04
Loss = 3.6789e-05, PNorm = 46.7030, GNorm = 0.0770, lr_0 = 2.4608e-04
Loss = 4.6783e-05, PNorm = 46.7041, GNorm = 0.1268, lr_0 = 2.4575e-04
Loss = 4.5552e-05, PNorm = 46.7077, GNorm = 0.2626, lr_0 = 2.4542e-04
Loss = 4.0198e-05, PNorm = 46.7096, GNorm = 0.1901, lr_0 = 2.4509e-04
Loss = 4.1520e-05, PNorm = 46.7127, GNorm = 0.1057, lr_0 = 2.4476e-04
Loss = 4.1482e-05, PNorm = 46.7138, GNorm = 0.1195, lr_0 = 2.4443e-04
Loss = 3.8079e-05, PNorm = 46.7138, GNorm = 0.1001, lr_0 = 2.4411e-04
Loss = 3.8752e-05, PNorm = 46.7164, GNorm = 0.1451, lr_0 = 2.4378e-04
Loss = 4.5477e-05, PNorm = 46.7184, GNorm = 0.3074, lr_0 = 2.4345e-04
Loss = 3.9359e-05, PNorm = 46.7195, GNorm = 0.0936, lr_0 = 2.4313e-04
Loss = 4.0953e-05, PNorm = 46.7223, GNorm = 0.1246, lr_0 = 2.4280e-04
Loss = 3.3614e-05, PNorm = 46.7253, GNorm = 0.0753, lr_0 = 2.4247e-04
Validation rmse = 0.480640
Validation R2 = 0.935896
Epoch 62
Train function
Loss = 2.9719e-05, PNorm = 46.7291, GNorm = 0.2063, lr_0 = 2.4212e-04
Loss = 3.8093e-05, PNorm = 46.7337, GNorm = 0.1803, lr_0 = 2.4179e-04
Loss = 3.9470e-05, PNorm = 46.7347, GNorm = 0.1400, lr_0 = 2.4147e-04
Loss = 4.6836e-05, PNorm = 46.7366, GNorm = 0.1896, lr_0 = 2.4114e-04
Loss = 3.5424e-05, PNorm = 46.7399, GNorm = 0.0701, lr_0 = 2.4082e-04
Loss = 3.9063e-05, PNorm = 46.7412, GNorm = 0.1651, lr_0 = 2.4050e-04
Loss = 4.1209e-05, PNorm = 46.7442, GNorm = 0.1210, lr_0 = 2.4017e-04
Loss = 4.3322e-05, PNorm = 46.7474, GNorm = 0.1496, lr_0 = 2.3985e-04
Loss = 5.1320e-05, PNorm = 46.7485, GNorm = 0.2909, lr_0 = 2.3953e-04
Loss = 3.8388e-05, PNorm = 46.7512, GNorm = 0.1296, lr_0 = 2.3921e-04
Loss = 4.6427e-05, PNorm = 46.7513, GNorm = 0.1225, lr_0 = 2.3889e-04
Loss = 3.7205e-05, PNorm = 46.7532, GNorm = 0.2395, lr_0 = 2.3857e-04
Loss = 4.1449e-05, PNorm = 46.7588, GNorm = 0.1379, lr_0 = 2.3825e-04
Loss = 4.7316e-05, PNorm = 46.7621, GNorm = 0.2810, lr_0 = 2.3793e-04
Loss = 3.9171e-05, PNorm = 46.7649, GNorm = 0.0752, lr_0 = 2.3761e-04
Loss = 3.5132e-05, PNorm = 46.7657, GNorm = 0.1094, lr_0 = 2.3729e-04
Loss = 4.1685e-05, PNorm = 46.7686, GNorm = 0.1075, lr_0 = 2.3697e-04
Loss = 4.0429e-05, PNorm = 46.7719, GNorm = 0.1351, lr_0 = 2.3665e-04
Validation rmse = 0.479028
Validation R2 = 0.936325
Epoch 63
Train function
Loss = 3.3966e-05, PNorm = 46.7736, GNorm = 0.0887, lr_0 = 2.3633e-04
Loss = 3.6447e-05, PNorm = 46.7733, GNorm = 0.0858, lr_0 = 2.3602e-04
Loss = 2.6407e-05, PNorm = 46.7758, GNorm = 0.0758, lr_0 = 2.3570e-04
Loss = 2.9013e-05, PNorm = 46.7771, GNorm = 0.0816, lr_0 = 2.3538e-04
Loss = 2.5842e-05, PNorm = 46.7789, GNorm = 0.1035, lr_0 = 2.3507e-04
Loss = 3.2128e-05, PNorm = 46.7800, GNorm = 0.0711, lr_0 = 2.3475e-04
Loss = 3.1545e-05, PNorm = 46.7815, GNorm = 0.0800, lr_0 = 2.3444e-04
Loss = 3.5792e-05, PNorm = 46.7849, GNorm = 0.1933, lr_0 = 2.3412e-04
Loss = 4.3302e-05, PNorm = 46.7876, GNorm = 0.2988, lr_0 = 2.3381e-04
Loss = 6.1888e-05, PNorm = 46.7900, GNorm = 0.4278, lr_0 = 2.3350e-04
Loss = 4.0986e-05, PNorm = 46.7912, GNorm = 0.1676, lr_0 = 2.3318e-04
Loss = 3.9754e-05, PNorm = 46.7944, GNorm = 0.1779, lr_0 = 2.3287e-04
Loss = 4.4234e-05, PNorm = 46.7976, GNorm = 0.2102, lr_0 = 2.3256e-04
Loss = 3.7403e-05, PNorm = 46.8003, GNorm = 0.0911, lr_0 = 2.3225e-04
Loss = 3.8356e-05, PNorm = 46.8033, GNorm = 0.1180, lr_0 = 2.3193e-04
Loss = 4.0814e-05, PNorm = 46.8064, GNorm = 0.2419, lr_0 = 2.3162e-04
Loss = 7.0299e-05, PNorm = 46.8114, GNorm = 0.3919, lr_0 = 2.3131e-04
Loss = 6.0866e-05, PNorm = 46.8169, GNorm = 0.1944, lr_0 = 2.3100e-04
Loss = 3.0507e-04, PNorm = 46.8174, GNorm = 0.4336, lr_0 = 2.3097e-04
Validation rmse = 0.484888
Validation R2 = 0.934758
Epoch 64
Train function
Loss = 5.0645e-05, PNorm = 46.8224, GNorm = 0.2918, lr_0 = 2.3066e-04
Loss = 3.9495e-05, PNorm = 46.8242, GNorm = 0.0815, lr_0 = 2.3035e-04
Loss = 3.8428e-05, PNorm = 46.8260, GNorm = 0.1205, lr_0 = 2.3004e-04
Loss = 3.0220e-05, PNorm = 46.8295, GNorm = 0.1435, lr_0 = 2.2973e-04
Loss = 2.7573e-05, PNorm = 46.8331, GNorm = 0.1600, lr_0 = 2.2943e-04
Loss = 3.1240e-05, PNorm = 46.8343, GNorm = 0.0834, lr_0 = 2.2912e-04
Loss = 3.4877e-05, PNorm = 46.8363, GNorm = 0.1066, lr_0 = 2.2881e-04
Loss = 3.3257e-05, PNorm = 46.8386, GNorm = 0.2190, lr_0 = 2.2850e-04
Loss = 4.1844e-05, PNorm = 46.8397, GNorm = 0.1132, lr_0 = 2.2820e-04
Loss = 4.5647e-05, PNorm = 46.8428, GNorm = 0.0913, lr_0 = 2.2789e-04
Loss = 3.7838e-05, PNorm = 46.8455, GNorm = 0.0699, lr_0 = 2.2758e-04
Loss = 4.9574e-05, PNorm = 46.8469, GNorm = 0.2369, lr_0 = 2.2728e-04
Loss = 3.9549e-05, PNorm = 46.8492, GNorm = 0.1726, lr_0 = 2.2697e-04
Loss = 3.8554e-05, PNorm = 46.8488, GNorm = 0.1234, lr_0 = 2.2667e-04
Loss = 5.3734e-05, PNorm = 46.8523, GNorm = 0.2335, lr_0 = 2.2637e-04
Loss = 4.8395e-05, PNorm = 46.8551, GNorm = 0.1041, lr_0 = 2.2606e-04
Loss = 4.6976e-05, PNorm = 46.8559, GNorm = 0.1142, lr_0 = 2.2576e-04
Validation rmse = 0.476378
Validation R2 = 0.937028
Epoch 65
Train function
Loss = 2.8009e-05, PNorm = 46.8582, GNorm = 0.0682, lr_0 = 2.2546e-04
Loss = 3.1808e-05, PNorm = 46.8610, GNorm = 0.1550, lr_0 = 2.2515e-04
Loss = 3.5683e-05, PNorm = 46.8625, GNorm = 0.1490, lr_0 = 2.2485e-04
Loss = 2.9187e-05, PNorm = 46.8636, GNorm = 0.0825, lr_0 = 2.2455e-04
Loss = 3.9460e-05, PNorm = 46.8662, GNorm = 0.2513, lr_0 = 2.2425e-04
Loss = 3.2222e-05, PNorm = 46.8703, GNorm = 0.1009, lr_0 = 2.2395e-04
Loss = 4.1340e-05, PNorm = 46.8745, GNorm = 0.2294, lr_0 = 2.2365e-04
Loss = 4.0479e-05, PNorm = 46.8758, GNorm = 0.1314, lr_0 = 2.2335e-04
Loss = 3.9020e-05, PNorm = 46.8799, GNorm = 0.1301, lr_0 = 2.2305e-04
Loss = 3.6901e-05, PNorm = 46.8816, GNorm = 0.1032, lr_0 = 2.2275e-04
Loss = 3.3026e-05, PNorm = 46.8828, GNorm = 0.1423, lr_0 = 2.2245e-04
Loss = 3.3549e-05, PNorm = 46.8841, GNorm = 0.0909, lr_0 = 2.2215e-04
Loss = 3.3695e-05, PNorm = 46.8857, GNorm = 0.1868, lr_0 = 2.2185e-04
Loss = 3.2232e-05, PNorm = 46.8896, GNorm = 0.1615, lr_0 = 2.2155e-04
Loss = 3.4222e-05, PNorm = 46.8907, GNorm = 0.1099, lr_0 = 2.2126e-04
Loss = 3.3848e-05, PNorm = 46.8917, GNorm = 0.1634, lr_0 = 2.2096e-04
Loss = 3.1792e-05, PNorm = 46.8932, GNorm = 0.0911, lr_0 = 2.2066e-04
Loss = 3.9494e-05, PNorm = 46.8980, GNorm = 0.1324, lr_0 = 2.2037e-04
Validation rmse = 0.473611
Validation R2 = 0.937757
Epoch 66
Train function
Loss = 2.8143e-05, PNorm = 46.8992, GNorm = 0.1062, lr_0 = 2.2007e-04
Loss = 3.1409e-05, PNorm = 46.9000, GNorm = 0.1858, lr_0 = 2.1978e-04
Loss = 2.2947e-05, PNorm = 46.9014, GNorm = 0.0837, lr_0 = 2.1948e-04
Loss = 2.3717e-05, PNorm = 46.9028, GNorm = 0.0848, lr_0 = 2.1919e-04
Loss = 2.7738e-05, PNorm = 46.9041, GNorm = 0.0991, lr_0 = 2.1889e-04
Loss = 2.5591e-05, PNorm = 46.9049, GNorm = 0.0716, lr_0 = 2.1860e-04
Loss = 3.1519e-05, PNorm = 46.9044, GNorm = 0.1517, lr_0 = 2.1831e-04
Loss = 3.8256e-05, PNorm = 46.9071, GNorm = 0.2565, lr_0 = 2.1801e-04
Loss = 3.8997e-05, PNorm = 46.9087, GNorm = 0.0743, lr_0 = 2.1772e-04
Loss = 4.6773e-05, PNorm = 46.9102, GNorm = 0.1242, lr_0 = 2.1743e-04
Loss = 3.5549e-05, PNorm = 46.9143, GNorm = 0.1906, lr_0 = 2.1714e-04
Loss = 4.5401e-05, PNorm = 46.9163, GNorm = 0.2510, lr_0 = 2.1685e-04
Loss = 4.8807e-05, PNorm = 46.9200, GNorm = 0.2919, lr_0 = 2.1656e-04
Loss = 4.3133e-05, PNorm = 46.9234, GNorm = 0.1365, lr_0 = 2.1626e-04
Loss = 4.5620e-05, PNorm = 46.9265, GNorm = 0.1979, lr_0 = 2.1597e-04
Loss = 3.3249e-05, PNorm = 46.9294, GNorm = 0.0852, lr_0 = 2.1568e-04
Loss = 3.9667e-05, PNorm = 46.9310, GNorm = 0.2226, lr_0 = 2.1540e-04
Validation rmse = 0.475183
Validation R2 = 0.937344
Epoch 67
Train function
Loss = 2.3456e-05, PNorm = 46.9339, GNorm = 0.1488, lr_0 = 2.1508e-04
Loss = 3.3900e-05, PNorm = 46.9356, GNorm = 0.1674, lr_0 = 2.1479e-04
Loss = 2.5838e-05, PNorm = 46.9396, GNorm = 0.1099, lr_0 = 2.1450e-04
Loss = 3.0154e-05, PNorm = 46.9421, GNorm = 0.0894, lr_0 = 2.1421e-04
Loss = 4.3446e-05, PNorm = 46.9451, GNorm = 0.2628, lr_0 = 2.1393e-04
Loss = 4.3817e-05, PNorm = 46.9482, GNorm = 0.1519, lr_0 = 2.1364e-04
Loss = 4.5621e-05, PNorm = 46.9503, GNorm = 0.1089, lr_0 = 2.1335e-04
Loss = 3.7633e-05, PNorm = 46.9522, GNorm = 0.1222, lr_0 = 2.1307e-04
Loss = 3.0253e-05, PNorm = 46.9548, GNorm = 0.1505, lr_0 = 2.1278e-04
Loss = 2.7148e-05, PNorm = 46.9561, GNorm = 0.0764, lr_0 = 2.1249e-04
Loss = 3.5352e-05, PNorm = 46.9564, GNorm = 0.1387, lr_0 = 2.1221e-04
Loss = 3.8716e-05, PNorm = 46.9578, GNorm = 0.1968, lr_0 = 2.1192e-04
Loss = 3.9436e-05, PNorm = 46.9590, GNorm = 0.3237, lr_0 = 2.1164e-04
Loss = 3.5246e-05, PNorm = 46.9594, GNorm = 0.1369, lr_0 = 2.1136e-04
Loss = 3.2866e-05, PNorm = 46.9616, GNorm = 0.1765, lr_0 = 2.1107e-04
Loss = 3.0868e-05, PNorm = 46.9644, GNorm = 0.1147, lr_0 = 2.1079e-04
Loss = 3.8579e-05, PNorm = 46.9663, GNorm = 0.1254, lr_0 = 2.1051e-04
Loss = 3.7139e-05, PNorm = 46.9678, GNorm = 0.1562, lr_0 = 2.1022e-04
Validation rmse = 0.475068
Validation R2 = 0.937374
Epoch 68
Train function
Loss = 3.2258e-05, PNorm = 46.9700, GNorm = 0.1460, lr_0 = 2.0994e-04
Loss = 3.1891e-05, PNorm = 46.9718, GNorm = 0.1141, lr_0 = 2.0966e-04
Loss = 3.3164e-05, PNorm = 46.9771, GNorm = 0.1035, lr_0 = 2.0938e-04
Loss = 2.4999e-05, PNorm = 46.9798, GNorm = 0.1996, lr_0 = 2.0910e-04
Loss = 2.7691e-05, PNorm = 46.9805, GNorm = 0.0905, lr_0 = 2.0882e-04
Loss = 2.9941e-05, PNorm = 46.9817, GNorm = 0.1763, lr_0 = 2.0854e-04
Loss = 2.9737e-05, PNorm = 46.9832, GNorm = 0.2867, lr_0 = 2.0826e-04
Loss = 3.0243e-05, PNorm = 46.9848, GNorm = 0.0858, lr_0 = 2.0798e-04
Loss = 2.2101e-05, PNorm = 46.9860, GNorm = 0.0900, lr_0 = 2.0770e-04
Loss = 3.2728e-05, PNorm = 46.9873, GNorm = 0.1527, lr_0 = 2.0742e-04
Loss = 3.6267e-05, PNorm = 46.9890, GNorm = 0.0838, lr_0 = 2.0714e-04
Loss = 3.2437e-05, PNorm = 46.9891, GNorm = 0.1489, lr_0 = 2.0686e-04
Loss = 2.7056e-05, PNorm = 46.9897, GNorm = 0.1348, lr_0 = 2.0659e-04
Loss = 3.7910e-05, PNorm = 46.9933, GNorm = 0.1533, lr_0 = 2.0631e-04
Loss = 3.4268e-05, PNorm = 46.9950, GNorm = 0.1144, lr_0 = 2.0603e-04
Loss = 3.4430e-05, PNorm = 46.9974, GNorm = 0.1268, lr_0 = 2.0576e-04
Loss = 5.0838e-05, PNorm = 47.0016, GNorm = 0.3694, lr_0 = 2.0548e-04
Validation rmse = 0.478717
Validation R2 = 0.936408
Epoch 69
Train function
Loss = 4.0573e-05, PNorm = 47.0059, GNorm = 0.2772, lr_0 = 2.0520e-04
Loss = 3.3545e-05, PNorm = 47.0103, GNorm = 0.0982, lr_0 = 2.0493e-04
Loss = 4.7973e-05, PNorm = 47.0132, GNorm = 0.0858, lr_0 = 2.0465e-04
Loss = 3.9274e-05, PNorm = 47.0164, GNorm = 0.1384, lr_0 = 2.0438e-04
Loss = 3.6536e-05, PNorm = 47.0175, GNorm = 0.1022, lr_0 = 2.0411e-04
Loss = 3.8207e-05, PNorm = 47.0212, GNorm = 0.1357, lr_0 = 2.0383e-04
Loss = 2.9766e-05, PNorm = 47.0218, GNorm = 0.1909, lr_0 = 2.0356e-04
Loss = 2.7738e-05, PNorm = 47.0220, GNorm = 0.1402, lr_0 = 2.0328e-04
Loss = 3.3123e-05, PNorm = 47.0255, GNorm = 0.0873, lr_0 = 2.0301e-04
Loss = 2.6854e-05, PNorm = 47.0278, GNorm = 0.0945, lr_0 = 2.0274e-04
Loss = 3.1894e-05, PNorm = 47.0290, GNorm = 0.2077, lr_0 = 2.0247e-04
Loss = 2.9965e-05, PNorm = 47.0294, GNorm = 0.1357, lr_0 = 2.0220e-04
Loss = 3.8620e-05, PNorm = 47.0332, GNorm = 0.1364, lr_0 = 2.0192e-04
Loss = 2.6629e-05, PNorm = 47.0357, GNorm = 0.0659, lr_0 = 2.0165e-04
Loss = 2.4072e-05, PNorm = 47.0368, GNorm = 0.0895, lr_0 = 2.0138e-04
Loss = 2.6850e-05, PNorm = 47.0392, GNorm = 0.1492, lr_0 = 2.0111e-04
Loss = 3.1064e-05, PNorm = 47.0411, GNorm = 0.1228, lr_0 = 2.0084e-04
Loss = 3.2456e-05, PNorm = 47.0435, GNorm = 0.0831, lr_0 = 2.0057e-04
Validation rmse = 0.475769
Validation R2 = 0.937189
Epoch 70
Train function
Loss = 1.8570e-05, PNorm = 47.0456, GNorm = 0.0861, lr_0 = 2.0028e-04
Loss = 2.8711e-05, PNorm = 47.0452, GNorm = 0.1937, lr_0 = 2.0001e-04
Loss = 1.9320e-05, PNorm = 47.0468, GNorm = 0.0751, lr_0 = 1.9974e-04
Loss = 2.4880e-05, PNorm = 47.0478, GNorm = 0.1723, lr_0 = 1.9947e-04
Loss = 2.4698e-05, PNorm = 47.0495, GNorm = 0.0779, lr_0 = 1.9921e-04
Loss = 1.8883e-05, PNorm = 47.0518, GNorm = 0.0585, lr_0 = 1.9894e-04
Loss = 2.6020e-05, PNorm = 47.0542, GNorm = 0.1203, lr_0 = 1.9867e-04
Loss = 2.7771e-05, PNorm = 47.0553, GNorm = 0.1714, lr_0 = 1.9840e-04
Loss = 2.4796e-05, PNorm = 47.0545, GNorm = 0.1053, lr_0 = 1.9814e-04
Loss = 2.4492e-05, PNorm = 47.0570, GNorm = 0.1031, lr_0 = 1.9787e-04
Loss = 2.9033e-05, PNorm = 47.0580, GNorm = 0.1196, lr_0 = 1.9761e-04
Loss = 2.7707e-05, PNorm = 47.0609, GNorm = 0.1198, lr_0 = 1.9734e-04
Loss = 2.3096e-05, PNorm = 47.0618, GNorm = 0.1503, lr_0 = 1.9708e-04
Loss = 2.6333e-05, PNorm = 47.0645, GNorm = 0.1024, lr_0 = 1.9681e-04
Loss = 3.0420e-05, PNorm = 47.0656, GNorm = 0.1920, lr_0 = 1.9655e-04
Loss = 2.0266e-05, PNorm = 47.0669, GNorm = 0.0849, lr_0 = 1.9628e-04
Loss = 2.3535e-05, PNorm = 47.0697, GNorm = 0.1207, lr_0 = 1.9602e-04
Loss = 3.0430e-05, PNorm = 47.0716, GNorm = 0.1130, lr_0 = 1.9576e-04
Validation rmse = 0.475206
Validation R2 = 0.937337
Epoch 71
Train function
Loss = 2.3450e-05, PNorm = 47.0724, GNorm = 0.0967, lr_0 = 1.9550e-04
Loss = 2.3669e-05, PNorm = 47.0731, GNorm = 0.0658, lr_0 = 1.9523e-04
Loss = 2.0946e-05, PNorm = 47.0752, GNorm = 0.1286, lr_0 = 1.9497e-04
Loss = 2.2170e-05, PNorm = 47.0774, GNorm = 0.1591, lr_0 = 1.9471e-04
Loss = 2.0267e-05, PNorm = 47.0781, GNorm = 0.1097, lr_0 = 1.9445e-04
Loss = 2.4155e-05, PNorm = 47.0794, GNorm = 0.2316, lr_0 = 1.9419e-04
Loss = 1.9463e-05, PNorm = 47.0799, GNorm = 0.1305, lr_0 = 1.9393e-04
Loss = 2.7260e-05, PNorm = 47.0818, GNorm = 0.1246, lr_0 = 1.9367e-04
Loss = 1.7615e-05, PNorm = 47.0832, GNorm = 0.0671, lr_0 = 1.9341e-04
Loss = 1.9417e-05, PNorm = 47.0833, GNorm = 0.0972, lr_0 = 1.9315e-04
Loss = 2.4441e-05, PNorm = 47.0839, GNorm = 0.1315, lr_0 = 1.9289e-04
Loss = 1.9986e-05, PNorm = 47.0860, GNorm = 0.0983, lr_0 = 1.9263e-04
Loss = 1.8038e-05, PNorm = 47.0862, GNorm = 0.0639, lr_0 = 1.9237e-04
Loss = 2.4229e-05, PNorm = 47.0870, GNorm = 0.1953, lr_0 = 1.9211e-04
Loss = 2.3997e-05, PNorm = 47.0878, GNorm = 0.1109, lr_0 = 1.9186e-04
Loss = 2.7075e-05, PNorm = 47.0902, GNorm = 0.0727, lr_0 = 1.9160e-04
Loss = 2.6716e-05, PNorm = 47.0929, GNorm = 0.1268, lr_0 = 1.9134e-04
Validation rmse = 0.474703
Validation R2 = 0.937470
Epoch 72
Train function
Loss = 2.0819e-05, PNorm = 47.0965, GNorm = 0.2161, lr_0 = 1.9108e-04
Loss = 2.2384e-05, PNorm = 47.0988, GNorm = 0.1028, lr_0 = 1.9083e-04
Loss = 2.0767e-05, PNorm = 47.1019, GNorm = 0.2101, lr_0 = 1.9057e-04
Loss = 2.2790e-05, PNorm = 47.1027, GNorm = 0.1601, lr_0 = 1.9032e-04
Loss = 2.3797e-05, PNorm = 47.1047, GNorm = 0.1431, lr_0 = 1.9006e-04
Loss = 1.9340e-05, PNorm = 47.1058, GNorm = 0.1145, lr_0 = 1.8981e-04
Loss = 1.6798e-05, PNorm = 47.1069, GNorm = 0.0612, lr_0 = 1.8955e-04
Loss = 2.0660e-05, PNorm = 47.1088, GNorm = 0.1081, lr_0 = 1.8930e-04
Loss = 2.5238e-05, PNorm = 47.1095, GNorm = 0.1203, lr_0 = 1.8904e-04
Loss = 1.8097e-05, PNorm = 47.1104, GNorm = 0.0977, lr_0 = 1.8879e-04
Loss = 2.1427e-05, PNorm = 47.1109, GNorm = 0.0694, lr_0 = 1.8854e-04
Loss = 2.7207e-05, PNorm = 47.1132, GNorm = 0.0658, lr_0 = 1.8828e-04
Loss = 2.8834e-05, PNorm = 47.1174, GNorm = 0.1917, lr_0 = 1.8803e-04
Loss = 2.3499e-05, PNorm = 47.1194, GNorm = 0.1288, lr_0 = 1.8778e-04
Loss = 2.8709e-05, PNorm = 47.1205, GNorm = 0.1414, lr_0 = 1.8753e-04
Loss = 3.5686e-05, PNorm = 47.1233, GNorm = 0.4181, lr_0 = 1.8727e-04
Loss = 3.5509e-05, PNorm = 47.1261, GNorm = 0.2435, lr_0 = 1.8702e-04
Loss = 2.3895e-05, PNorm = 47.1286, GNorm = 0.1409, lr_0 = 1.8677e-04
Validation rmse = 0.475614
Validation R2 = 0.937230
Epoch 73
Train function
Loss = 2.2051e-05, PNorm = 47.1314, GNorm = 0.1281, lr_0 = 1.8650e-04
Loss = 2.2979e-05, PNorm = 47.1329, GNorm = 0.1232, lr_0 = 1.8625e-04
Loss = 2.0932e-05, PNorm = 47.1348, GNorm = 0.0666, lr_0 = 1.8600e-04
Loss = 2.2593e-05, PNorm = 47.1353, GNorm = 0.1553, lr_0 = 1.8575e-04
Loss = 2.3879e-05, PNorm = 47.1354, GNorm = 0.1845, lr_0 = 1.8550e-04
Loss = 2.5455e-05, PNorm = 47.1354, GNorm = 0.1109, lr_0 = 1.8525e-04
Loss = 2.8385e-05, PNorm = 47.1375, GNorm = 0.0785, lr_0 = 1.8500e-04
Loss = 2.5894e-05, PNorm = 47.1398, GNorm = 0.1108, lr_0 = 1.8475e-04
Loss = 2.0451e-05, PNorm = 47.1409, GNorm = 0.0764, lr_0 = 1.8450e-04
Loss = 1.7419e-05, PNorm = 47.1423, GNorm = 0.1110, lr_0 = 1.8426e-04
Loss = 2.4469e-05, PNorm = 47.1427, GNorm = 0.0542, lr_0 = 1.8401e-04
Loss = 2.4002e-05, PNorm = 47.1447, GNorm = 0.1488, lr_0 = 1.8376e-04
Loss = 1.7722e-05, PNorm = 47.1473, GNorm = 0.1457, lr_0 = 1.8352e-04
Loss = 2.9379e-05, PNorm = 47.1475, GNorm = 0.1065, lr_0 = 1.8327e-04
Loss = 1.8456e-05, PNorm = 47.1484, GNorm = 0.1119, lr_0 = 1.8302e-04
Loss = 2.0476e-05, PNorm = 47.1490, GNorm = 0.1254, lr_0 = 1.8278e-04
Loss = 2.5983e-05, PNorm = 47.1506, GNorm = 0.1556, lr_0 = 1.8253e-04
Validation rmse = 0.475329
Validation R2 = 0.937305
Epoch 74
Train function
Loss = 2.2273e-05, PNorm = 47.1528, GNorm = 0.1719, lr_0 = 1.8229e-04
Loss = 1.8679e-05, PNorm = 47.1533, GNorm = 0.1849, lr_0 = 1.8204e-04
Loss = 2.1890e-05, PNorm = 47.1545, GNorm = 0.1256, lr_0 = 1.8180e-04
Loss = 2.2802e-05, PNorm = 47.1578, GNorm = 0.2061, lr_0 = 1.8156e-04
Loss = 2.6731e-05, PNorm = 47.1582, GNorm = 0.1518, lr_0 = 1.8131e-04
Loss = 2.1917e-05, PNorm = 47.1608, GNorm = 0.0856, lr_0 = 1.8107e-04
Loss = 2.6518e-05, PNorm = 47.1620, GNorm = 0.0807, lr_0 = 1.8083e-04
Loss = 2.1980e-05, PNorm = 47.1628, GNorm = 0.1540, lr_0 = 1.8058e-04
Loss = 1.5862e-05, PNorm = 47.1631, GNorm = 0.0782, lr_0 = 1.8034e-04
Loss = 1.7473e-05, PNorm = 47.1642, GNorm = 0.1100, lr_0 = 1.8010e-04
Loss = 2.0755e-05, PNorm = 47.1662, GNorm = 0.0737, lr_0 = 1.7986e-04
Loss = 2.3564e-05, PNorm = 47.1667, GNorm = 0.1083, lr_0 = 1.7962e-04
Loss = 2.0805e-05, PNorm = 47.1676, GNorm = 0.0659, lr_0 = 1.7937e-04
Loss = 3.2411e-05, PNorm = 47.1705, GNorm = 0.1327, lr_0 = 1.7913e-04
Loss = 3.5884e-05, PNorm = 47.1726, GNorm = 0.1609, lr_0 = 1.7889e-04
Loss = 3.3569e-05, PNorm = 47.1718, GNorm = 0.2777, lr_0 = 1.7865e-04
Loss = 2.6485e-05, PNorm = 47.1738, GNorm = 0.1606, lr_0 = 1.7841e-04
Loss = 2.2896e-05, PNorm = 47.1762, GNorm = 0.1328, lr_0 = 1.7817e-04
Validation rmse = 0.476460
Validation R2 = 0.937006
Epoch 75
Train function
Loss = 2.4751e-05, PNorm = 47.1773, GNorm = 0.1384, lr_0 = 1.7794e-04
Loss = 2.2665e-05, PNorm = 47.1797, GNorm = 0.1852, lr_0 = 1.7770e-04
Loss = 2.2898e-05, PNorm = 47.1810, GNorm = 0.1294, lr_0 = 1.7746e-04
Loss = 2.0268e-05, PNorm = 47.1827, GNorm = 0.0606, lr_0 = 1.7722e-04
Loss = 1.9093e-05, PNorm = 47.1843, GNorm = 0.0713, lr_0 = 1.7698e-04
Loss = 2.3680e-05, PNorm = 47.1853, GNorm = 0.2069, lr_0 = 1.7674e-04
Loss = 2.0059e-05, PNorm = 47.1878, GNorm = 0.1276, lr_0 = 1.7651e-04
Loss = 1.6275e-05, PNorm = 47.1894, GNorm = 0.0773, lr_0 = 1.7627e-04
Loss = 1.5815e-05, PNorm = 47.1900, GNorm = 0.0968, lr_0 = 1.7603e-04
Loss = 2.0147e-05, PNorm = 47.1916, GNorm = 0.0798, lr_0 = 1.7580e-04
Loss = 3.0755e-05, PNorm = 47.1924, GNorm = 0.1735, lr_0 = 1.7556e-04
Loss = 2.2392e-05, PNorm = 47.1937, GNorm = 0.1508, lr_0 = 1.7533e-04
Loss = 2.9164e-05, PNorm = 47.1952, GNorm = 0.2954, lr_0 = 1.7509e-04
Loss = 3.1332e-05, PNorm = 47.1969, GNorm = 0.0852, lr_0 = 1.7486e-04
Loss = 2.6228e-05, PNorm = 47.1994, GNorm = 0.1850, lr_0 = 1.7462e-04
Loss = 2.4431e-05, PNorm = 47.1997, GNorm = 0.1626, lr_0 = 1.7439e-04
Loss = 2.4274e-05, PNorm = 47.2001, GNorm = 0.0716, lr_0 = 1.7415e-04
Validation rmse = 0.478013
Validation R2 = 0.936595
Epoch 76
Train function
Loss = 2.5830e-05, PNorm = 47.2022, GNorm = 0.1093, lr_0 = 1.7390e-04
Loss = 2.2980e-05, PNorm = 47.2041, GNorm = 0.0885, lr_0 = 1.7366e-04
Loss = 2.1572e-05, PNorm = 47.2076, GNorm = 0.1401, lr_0 = 1.7343e-04
Loss = 1.4875e-05, PNorm = 47.2096, GNorm = 0.0533, lr_0 = 1.7320e-04
Loss = 1.7386e-05, PNorm = 47.2103, GNorm = 0.1646, lr_0 = 1.7297e-04
Loss = 2.0567e-05, PNorm = 47.2128, GNorm = 0.0607, lr_0 = 1.7273e-04
Loss = 1.5197e-05, PNorm = 47.2133, GNorm = 0.0658, lr_0 = 1.7250e-04
Loss = 1.6008e-05, PNorm = 47.2141, GNorm = 0.1239, lr_0 = 1.7227e-04
Loss = 2.0903e-05, PNorm = 47.2141, GNorm = 0.1423, lr_0 = 1.7204e-04
Loss = 2.4256e-05, PNorm = 47.2149, GNorm = 0.1839, lr_0 = 1.7181e-04
Loss = 2.0172e-05, PNorm = 47.2172, GNorm = 0.0568, lr_0 = 1.7158e-04
Loss = 2.6600e-05, PNorm = 47.2184, GNorm = 0.0902, lr_0 = 1.7135e-04
Loss = 1.9628e-05, PNorm = 47.2206, GNorm = 0.1124, lr_0 = 1.7112e-04
Loss = 1.8514e-05, PNorm = 47.2208, GNorm = 0.0564, lr_0 = 1.7089e-04
Loss = 1.5727e-05, PNorm = 47.2215, GNorm = 0.0717, lr_0 = 1.7066e-04
Loss = 2.5891e-05, PNorm = 47.2234, GNorm = 0.1422, lr_0 = 1.7043e-04
Loss = 1.7048e-05, PNorm = 47.2254, GNorm = 0.0756, lr_0 = 1.7020e-04
Loss = 2.7875e-05, PNorm = 47.2263, GNorm = 0.3393, lr_0 = 1.6997e-04
Validation rmse = 0.476041
Validation R2 = 0.937117
Epoch 77
Train function
Loss = 2.5286e-05, PNorm = 47.2253, GNorm = 0.2141, lr_0 = 1.6974e-04
Loss = 2.4813e-05, PNorm = 47.2263, GNorm = 0.1665, lr_0 = 1.6952e-04
Loss = 2.0778e-05, PNorm = 47.2281, GNorm = 0.0893, lr_0 = 1.6929e-04
Loss = 1.9500e-05, PNorm = 47.2292, GNorm = 0.0878, lr_0 = 1.6906e-04
Loss = 1.7692e-05, PNorm = 47.2315, GNorm = 0.0700, lr_0 = 1.6884e-04
Loss = 2.6675e-05, PNorm = 47.2346, GNorm = 0.1202, lr_0 = 1.6861e-04
Loss = 2.6916e-05, PNorm = 47.2366, GNorm = 0.1767, lr_0 = 1.6838e-04
Loss = 2.0162e-05, PNorm = 47.2381, GNorm = 0.1180, lr_0 = 1.6816e-04
Loss = 1.9437e-05, PNorm = 47.2398, GNorm = 0.0813, lr_0 = 1.6793e-04
Loss = 1.8005e-05, PNorm = 47.2395, GNorm = 0.1231, lr_0 = 1.6771e-04
Loss = 1.8339e-05, PNorm = 47.2403, GNorm = 0.1792, lr_0 = 1.6748e-04
Loss = 2.6040e-05, PNorm = 47.2416, GNorm = 0.1355, lr_0 = 1.6726e-04
Loss = 1.5087e-05, PNorm = 47.2436, GNorm = 0.0608, lr_0 = 1.6703e-04
Loss = 1.6977e-05, PNorm = 47.2460, GNorm = 0.0651, lr_0 = 1.6681e-04
Loss = 1.5402e-05, PNorm = 47.2471, GNorm = 0.0985, lr_0 = 1.6658e-04
Loss = 1.7906e-05, PNorm = 47.2477, GNorm = 0.0720, lr_0 = 1.6636e-04
Loss = 1.9193e-05, PNorm = 47.2490, GNorm = 0.0644, lr_0 = 1.6614e-04
Validation rmse = 0.475416
Validation R2 = 0.937282
Epoch 78
Train function
Loss = 1.3771e-05, PNorm = 47.2514, GNorm = 0.0769, lr_0 = 1.6589e-04
Loss = 1.7042e-05, PNorm = 47.2524, GNorm = 0.1416, lr_0 = 1.6567e-04
Loss = 1.3208e-05, PNorm = 47.2533, GNorm = 0.0529, lr_0 = 1.6545e-04
Loss = 1.2840e-05, PNorm = 47.2540, GNorm = 0.0766, lr_0 = 1.6523e-04
Loss = 1.3772e-05, PNorm = 47.2553, GNorm = 0.0544, lr_0 = 1.6500e-04
Loss = 1.7232e-05, PNorm = 47.2567, GNorm = 0.0662, lr_0 = 1.6478e-04
Loss = 1.2197e-05, PNorm = 47.2583, GNorm = 0.0694, lr_0 = 1.6456e-04
Loss = 2.1043e-05, PNorm = 47.2578, GNorm = 0.0592, lr_0 = 1.6434e-04
Loss = 1.5867e-05, PNorm = 47.2587, GNorm = 0.0649, lr_0 = 1.6412e-04
Loss = 1.7005e-05, PNorm = 47.2594, GNorm = 0.0468, lr_0 = 1.6390e-04
Loss = 1.6880e-05, PNorm = 47.2612, GNorm = 0.0943, lr_0 = 1.6368e-04
Loss = 1.7283e-05, PNorm = 47.2628, GNorm = 0.1287, lr_0 = 1.6346e-04
Loss = 2.0318e-05, PNorm = 47.2627, GNorm = 0.0678, lr_0 = 1.6324e-04
Loss = 2.0103e-05, PNorm = 47.2638, GNorm = 0.1034, lr_0 = 1.6302e-04
Loss = 1.5640e-05, PNorm = 47.2654, GNorm = 0.0854, lr_0 = 1.6280e-04
Loss = 1.4386e-05, PNorm = 47.2676, GNorm = 0.0759, lr_0 = 1.6258e-04
Loss = 2.1439e-05, PNorm = 47.2688, GNorm = 0.2509, lr_0 = 1.6237e-04
Loss = 2.5629e-05, PNorm = 47.2701, GNorm = 0.2137, lr_0 = 1.6215e-04
Validation rmse = 0.477587
Validation R2 = 0.936708
Epoch 79
Train function
Loss = 3.2674e-05, PNorm = 47.2724, GNorm = 0.1836, lr_0 = 1.6193e-04
Loss = 2.3519e-05, PNorm = 47.2726, GNorm = 0.0956, lr_0 = 1.6171e-04
Loss = 2.1991e-05, PNorm = 47.2740, GNorm = 0.1251, lr_0 = 1.6150e-04
Loss = 1.5778e-05, PNorm = 47.2766, GNorm = 0.0805, lr_0 = 1.6128e-04
Loss = 1.8217e-05, PNorm = 47.2792, GNorm = 0.1107, lr_0 = 1.6106e-04
Loss = 2.1220e-05, PNorm = 47.2804, GNorm = 0.0954, lr_0 = 1.6085e-04
Loss = 1.4845e-05, PNorm = 47.2804, GNorm = 0.0566, lr_0 = 1.6063e-04
Loss = 1.7443e-05, PNorm = 47.2801, GNorm = 0.0580, lr_0 = 1.6042e-04
Loss = 1.5206e-05, PNorm = 47.2819, GNorm = 0.1421, lr_0 = 1.6020e-04
Loss = 1.7942e-05, PNorm = 47.2825, GNorm = 0.0883, lr_0 = 1.5999e-04
Loss = 1.5653e-05, PNorm = 47.2836, GNorm = 0.0671, lr_0 = 1.5977e-04
Loss = 1.9001e-05, PNorm = 47.2848, GNorm = 0.1105, lr_0 = 1.5956e-04
Loss = 1.7819e-05, PNorm = 47.2876, GNorm = 0.1474, lr_0 = 1.5934e-04
Loss = 1.6461e-05, PNorm = 47.2892, GNorm = 0.1290, lr_0 = 1.5913e-04
Loss = 1.6918e-05, PNorm = 47.2908, GNorm = 0.0578, lr_0 = 1.5892e-04
Loss = 2.0416e-05, PNorm = 47.2939, GNorm = 0.1026, lr_0 = 1.5870e-04
Loss = 1.5157e-05, PNorm = 47.2948, GNorm = 0.0936, lr_0 = 1.5849e-04
Loss = 2.2038e-05, PNorm = 47.2968, GNorm = 0.2516, lr_0 = 1.5828e-04
Validation rmse = 0.477709
Validation R2 = 0.936676
Epoch 80
Train function
Loss = 2.2199e-05, PNorm = 47.2977, GNorm = 0.2724, lr_0 = 1.5806e-04
Loss = 2.2386e-05, PNorm = 47.2983, GNorm = 0.2536, lr_0 = 1.5785e-04
Loss = 1.9523e-05, PNorm = 47.2981, GNorm = 0.1223, lr_0 = 1.5764e-04
Loss = 1.6190e-05, PNorm = 47.2990, GNorm = 0.0703, lr_0 = 1.5743e-04
Loss = 1.8391e-05, PNorm = 47.3004, GNorm = 0.0592, lr_0 = 1.5722e-04
Loss = 1.5840e-05, PNorm = 47.3024, GNorm = 0.1056, lr_0 = 1.5701e-04
Loss = 1.5392e-05, PNorm = 47.3039, GNorm = 0.0741, lr_0 = 1.5680e-04
Loss = 1.4783e-05, PNorm = 47.3061, GNorm = 0.1307, lr_0 = 1.5659e-04
Loss = 1.8436e-05, PNorm = 47.3072, GNorm = 0.2126, lr_0 = 1.5638e-04
Loss = 1.6668e-05, PNorm = 47.3088, GNorm = 0.0884, lr_0 = 1.5617e-04
Loss = 1.4102e-05, PNorm = 47.3087, GNorm = 0.0744, lr_0 = 1.5596e-04
Loss = 1.9856e-05, PNorm = 47.3101, GNorm = 0.0741, lr_0 = 1.5575e-04
Loss = 1.5417e-05, PNorm = 47.3112, GNorm = 0.1458, lr_0 = 1.5554e-04
Loss = 2.0949e-05, PNorm = 47.3125, GNorm = 0.1019, lr_0 = 1.5533e-04
Loss = 1.9549e-05, PNorm = 47.3141, GNorm = 0.0579, lr_0 = 1.5512e-04
Loss = 1.5063e-05, PNorm = 47.3153, GNorm = 0.1041, lr_0 = 1.5491e-04
Loss = 1.6573e-05, PNorm = 47.3155, GNorm = 0.0886, lr_0 = 1.5471e-04
Validation rmse = 0.476842
Validation R2 = 0.936905
Epoch 81
Train function
Loss = 2.4116e-05, PNorm = 47.3167, GNorm = 0.1168, lr_0 = 1.5448e-04
Loss = 1.7072e-05, PNorm = 47.3180, GNorm = 0.2426, lr_0 = 1.5427e-04
Loss = 2.2626e-05, PNorm = 47.3201, GNorm = 0.0860, lr_0 = 1.5406e-04
Loss = 1.3321e-05, PNorm = 47.3213, GNorm = 0.1448, lr_0 = 1.5386e-04
Loss = 1.6680e-05, PNorm = 47.3225, GNorm = 0.2365, lr_0 = 1.5365e-04
Loss = 1.6342e-05, PNorm = 47.3247, GNorm = 0.0544, lr_0 = 1.5344e-04
Loss = 1.5969e-05, PNorm = 47.3257, GNorm = 0.0442, lr_0 = 1.5324e-04
Loss = 1.8838e-05, PNorm = 47.3259, GNorm = 0.1303, lr_0 = 1.5303e-04
Loss = 2.2236e-05, PNorm = 47.3278, GNorm = 0.1965, lr_0 = 1.5283e-04
Loss = 1.7707e-05, PNorm = 47.3289, GNorm = 0.0939, lr_0 = 1.5262e-04
Loss = 1.4834e-05, PNorm = 47.3292, GNorm = 0.0465, lr_0 = 1.5242e-04
Loss = 1.8575e-05, PNorm = 47.3304, GNorm = 0.0444, lr_0 = 1.5221e-04
Loss = 1.4990e-05, PNorm = 47.3315, GNorm = 0.1402, lr_0 = 1.5201e-04
Loss = 1.3315e-05, PNorm = 47.3315, GNorm = 0.0555, lr_0 = 1.5180e-04
Loss = 1.4767e-05, PNorm = 47.3325, GNorm = 0.0739, lr_0 = 1.5160e-04
Loss = 1.2165e-05, PNorm = 47.3346, GNorm = 0.0739, lr_0 = 1.5140e-04
Loss = 1.5564e-05, PNorm = 47.3370, GNorm = 0.1349, lr_0 = 1.5119e-04
Loss = 1.5492e-05, PNorm = 47.3387, GNorm = 0.0668, lr_0 = 1.5099e-04
Validation rmse = 0.476343
Validation R2 = 0.937037
Epoch 82
Train function
Loss = 1.9392e-05, PNorm = 47.3398, GNorm = 0.1758, lr_0 = 1.5079e-04
Loss = 2.1316e-05, PNorm = 47.3418, GNorm = 0.1784, lr_0 = 1.5059e-04
Loss = 1.6991e-05, PNorm = 47.3414, GNorm = 0.0876, lr_0 = 1.5038e-04
Loss = 1.8459e-05, PNorm = 47.3430, GNorm = 0.0819, lr_0 = 1.5018e-04
Loss = 1.7739e-05, PNorm = 47.3426, GNorm = 0.1556, lr_0 = 1.4998e-04
Loss = 1.6222e-05, PNorm = 47.3427, GNorm = 0.1041, lr_0 = 1.4978e-04
Loss = 1.4280e-05, PNorm = 47.3450, GNorm = 0.0640, lr_0 = 1.4958e-04
Loss = 1.0012e-05, PNorm = 47.3465, GNorm = 0.0497, lr_0 = 1.4938e-04
Loss = 1.8324e-05, PNorm = 47.3493, GNorm = 0.0604, lr_0 = 1.4918e-04
Loss = 1.3334e-05, PNorm = 47.3495, GNorm = 0.0794, lr_0 = 1.4898e-04
Loss = 1.4897e-05, PNorm = 47.3500, GNorm = 0.0657, lr_0 = 1.4878e-04
Loss = 1.3088e-05, PNorm = 47.3510, GNorm = 0.0674, lr_0 = 1.4858e-04
Loss = 1.0507e-05, PNorm = 47.3514, GNorm = 0.0641, lr_0 = 1.4838e-04
Loss = 1.2217e-05, PNorm = 47.3517, GNorm = 0.0543, lr_0 = 1.4818e-04
Loss = 1.3959e-05, PNorm = 47.3532, GNorm = 0.0834, lr_0 = 1.4798e-04
Loss = 1.5590e-05, PNorm = 47.3540, GNorm = 0.1543, lr_0 = 1.4778e-04
Loss = 1.3038e-05, PNorm = 47.3555, GNorm = 0.0553, lr_0 = 1.4758e-04
Validation rmse = 0.475496
Validation R2 = 0.937261
Epoch 83
Train function
Loss = 1.3717e-05, PNorm = 47.3565, GNorm = 0.0546, lr_0 = 1.4739e-04
Loss = 1.8691e-05, PNorm = 47.3570, GNorm = 0.1134, lr_0 = 1.4719e-04
Loss = 1.7725e-05, PNorm = 47.3578, GNorm = 0.1336, lr_0 = 1.4699e-04
Loss = 1.3832e-05, PNorm = 47.3577, GNorm = 0.0899, lr_0 = 1.4679e-04
Loss = 1.5479e-05, PNorm = 47.3597, GNorm = 0.1016, lr_0 = 1.4660e-04
Loss = 1.1946e-05, PNorm = 47.3617, GNorm = 0.1067, lr_0 = 1.4640e-04
Loss = 1.7978e-05, PNorm = 47.3634, GNorm = 0.1883, lr_0 = 1.4620e-04
Loss = 1.3784e-05, PNorm = 47.3652, GNorm = 0.0646, lr_0 = 1.4601e-04
Loss = 1.5630e-05, PNorm = 47.3662, GNorm = 0.0935, lr_0 = 1.4581e-04
Loss = 1.4194e-05, PNorm = 47.3670, GNorm = 0.1256, lr_0 = 1.4562e-04
Loss = 1.5596e-05, PNorm = 47.3673, GNorm = 0.0945, lr_0 = 1.4542e-04
Loss = 1.5244e-05, PNorm = 47.3693, GNorm = 0.0786, lr_0 = 1.4522e-04
Loss = 1.4529e-05, PNorm = 47.3700, GNorm = 0.0649, lr_0 = 1.4503e-04
Loss = 1.7345e-05, PNorm = 47.3713, GNorm = 0.0607, lr_0 = 1.4484e-04
Loss = 1.5110e-05, PNorm = 47.3728, GNorm = 0.0927, lr_0 = 1.4464e-04
Loss = 1.7537e-05, PNorm = 47.3741, GNorm = 0.0529, lr_0 = 1.4445e-04
Loss = 1.7868e-05, PNorm = 47.3759, GNorm = 0.0520, lr_0 = 1.4425e-04
Loss = 1.8270e-05, PNorm = 47.3783, GNorm = 0.1848, lr_0 = 1.4406e-04
Validation rmse = 0.477175
Validation R2 = 0.936817
Epoch 84
Train function
Loss = 1.7171e-05, PNorm = 47.3800, GNorm = 0.1253, lr_0 = 1.4385e-04
Loss = 1.3884e-05, PNorm = 47.3809, GNorm = 0.0722, lr_0 = 1.4365e-04
Loss = 1.5769e-05, PNorm = 47.3826, GNorm = 0.0927, lr_0 = 1.4346e-04
Loss = 1.2931e-05, PNorm = 47.3843, GNorm = 0.1027, lr_0 = 1.4327e-04
Loss = 1.0755e-05, PNorm = 47.3836, GNorm = 0.0534, lr_0 = 1.4308e-04
Loss = 1.3326e-05, PNorm = 47.3842, GNorm = 0.0590, lr_0 = 1.4288e-04
Loss = 1.2185e-05, PNorm = 47.3857, GNorm = 0.1031, lr_0 = 1.4269e-04
Loss = 1.2206e-05, PNorm = 47.3863, GNorm = 0.0531, lr_0 = 1.4250e-04
Loss = 1.1067e-05, PNorm = 47.3867, GNorm = 0.1288, lr_0 = 1.4231e-04
Loss = 1.2861e-05, PNorm = 47.3880, GNorm = 0.0653, lr_0 = 1.4212e-04
Loss = 1.2060e-05, PNorm = 47.3881, GNorm = 0.0611, lr_0 = 1.4193e-04
Loss = 1.2399e-05, PNorm = 47.3876, GNorm = 0.0948, lr_0 = 1.4174e-04
Loss = 1.5434e-05, PNorm = 47.3893, GNorm = 0.0771, lr_0 = 1.4155e-04
Loss = 1.2964e-05, PNorm = 47.3910, GNorm = 0.0760, lr_0 = 1.4136e-04
Loss = 1.6919e-05, PNorm = 47.3925, GNorm = 0.0756, lr_0 = 1.4117e-04
Loss = 2.0487e-05, PNorm = 47.3942, GNorm = 0.0791, lr_0 = 1.4098e-04
Loss = 1.3859e-05, PNorm = 47.3957, GNorm = 0.0917, lr_0 = 1.4079e-04
Validation rmse = 0.476449
Validation R2 = 0.937009
Epoch 85
Train function
Loss = 3.3627e-05, PNorm = 47.3963, GNorm = 0.2795, lr_0 = 1.4060e-04
Loss = 2.1422e-05, PNorm = 47.3978, GNorm = 0.1324, lr_0 = 1.4041e-04
Loss = 1.7467e-05, PNorm = 47.3985, GNorm = 0.0627, lr_0 = 1.4022e-04
Loss = 1.4747e-05, PNorm = 47.4000, GNorm = 0.0653, lr_0 = 1.4004e-04
Loss = 1.6789e-05, PNorm = 47.4016, GNorm = 0.0740, lr_0 = 1.3985e-04
Loss = 1.1683e-05, PNorm = 47.4024, GNorm = 0.1019, lr_0 = 1.3966e-04
Loss = 1.1737e-05, PNorm = 47.4038, GNorm = 0.0662, lr_0 = 1.3947e-04
Loss = 1.1927e-05, PNorm = 47.4044, GNorm = 0.0443, lr_0 = 1.3929e-04
Loss = 1.1089e-05, PNorm = 47.4041, GNorm = 0.1085, lr_0 = 1.3910e-04
Loss = 1.2494e-05, PNorm = 47.4042, GNorm = 0.1134, lr_0 = 1.3891e-04
Loss = 1.1806e-05, PNorm = 47.4049, GNorm = 0.0622, lr_0 = 1.3873e-04
Loss = 1.0158e-05, PNorm = 47.4059, GNorm = 0.0610, lr_0 = 1.3854e-04
Loss = 1.0619e-05, PNorm = 47.4061, GNorm = 0.0628, lr_0 = 1.3835e-04
Loss = 1.2382e-05, PNorm = 47.4070, GNorm = 0.1081, lr_0 = 1.3817e-04
Loss = 1.3489e-05, PNorm = 47.4080, GNorm = 0.1150, lr_0 = 1.3798e-04
Loss = 1.6435e-05, PNorm = 47.4085, GNorm = 0.1188, lr_0 = 1.3780e-04
Loss = 1.2821e-05, PNorm = 47.4103, GNorm = 0.0818, lr_0 = 1.3761e-04
Loss = 1.1122e-05, PNorm = 47.4117, GNorm = 0.0654, lr_0 = 1.3743e-04
Validation rmse = 0.477722
Validation R2 = 0.936672
Epoch 86
Train function
Loss = 1.1674e-05, PNorm = 47.4124, GNorm = 0.0953, lr_0 = 1.3724e-04
Loss = 1.0794e-05, PNorm = 47.4134, GNorm = 0.0712, lr_0 = 1.3706e-04
Loss = 9.5092e-06, PNorm = 47.4144, GNorm = 0.0334, lr_0 = 1.3688e-04
Loss = 1.0110e-05, PNorm = 47.4143, GNorm = 0.0933, lr_0 = 1.3669e-04
Loss = 1.2958e-05, PNorm = 47.4157, GNorm = 0.0606, lr_0 = 1.3651e-04
Loss = 1.5429e-05, PNorm = 47.4152, GNorm = 0.0509, lr_0 = 1.3633e-04
Loss = 1.0254e-05, PNorm = 47.4162, GNorm = 0.0592, lr_0 = 1.3614e-04
Loss = 1.0252e-05, PNorm = 47.4179, GNorm = 0.0881, lr_0 = 1.3596e-04
Loss = 8.4597e-06, PNorm = 47.4195, GNorm = 0.0590, lr_0 = 1.3578e-04
Loss = 1.0056e-05, PNorm = 47.4207, GNorm = 0.0717, lr_0 = 1.3560e-04
Loss = 1.7141e-05, PNorm = 47.4221, GNorm = 0.0540, lr_0 = 1.3541e-04
Loss = 1.2496e-05, PNorm = 47.4235, GNorm = 0.1557, lr_0 = 1.3523e-04
Loss = 1.3412e-05, PNorm = 47.4231, GNorm = 0.0556, lr_0 = 1.3505e-04
Loss = 1.4770e-05, PNorm = 47.4228, GNorm = 0.1337, lr_0 = 1.3487e-04
Loss = 1.4836e-05, PNorm = 47.4219, GNorm = 0.1066, lr_0 = 1.3469e-04
Loss = 1.2757e-05, PNorm = 47.4221, GNorm = 0.0878, lr_0 = 1.3451e-04
Loss = 1.7965e-05, PNorm = 47.4235, GNorm = 0.2244, lr_0 = 1.3433e-04
Loss = 1.3598e-05, PNorm = 47.4237, GNorm = 0.1425, lr_0 = 1.3415e-04
Loss = 2.1231e-05, PNorm = 47.4239, GNorm = 0.1025, lr_0 = 1.3413e-04
Validation rmse = 0.475796
Validation R2 = 0.937182
Epoch 87
Train function
Loss = 1.1347e-05, PNorm = 47.4250, GNorm = 0.0893, lr_0 = 1.3395e-04
Loss = 1.0369e-05, PNorm = 47.4255, GNorm = 0.0777, lr_0 = 1.3377e-04
Loss = 1.0871e-05, PNorm = 47.4262, GNorm = 0.0618, lr_0 = 1.3359e-04
Loss = 1.2650e-05, PNorm = 47.4265, GNorm = 0.1078, lr_0 = 1.3341e-04
Loss = 1.0682e-05, PNorm = 47.4266, GNorm = 0.0573, lr_0 = 1.3323e-04
Loss = 1.3752e-05, PNorm = 47.4267, GNorm = 0.0877, lr_0 = 1.3305e-04
Loss = 1.2248e-05, PNorm = 47.4279, GNorm = 0.0568, lr_0 = 1.3287e-04
Loss = 9.8562e-06, PNorm = 47.4299, GNorm = 0.1118, lr_0 = 1.3270e-04
Loss = 1.3851e-05, PNorm = 47.4317, GNorm = 0.1038, lr_0 = 1.3252e-04
Loss = 1.2685e-05, PNorm = 47.4331, GNorm = 0.1309, lr_0 = 1.3234e-04
Loss = 1.1510e-05, PNorm = 47.4334, GNorm = 0.1667, lr_0 = 1.3216e-04
Loss = 1.3077e-05, PNorm = 47.4338, GNorm = 0.0693, lr_0 = 1.3199e-04
Loss = 1.3660e-05, PNorm = 47.4343, GNorm = 0.1562, lr_0 = 1.3181e-04
Loss = 1.2334e-05, PNorm = 47.4370, GNorm = 0.0961, lr_0 = 1.3163e-04
Loss = 2.6004e-05, PNorm = 47.4382, GNorm = 0.1726, lr_0 = 1.3145e-04
Loss = 1.3491e-05, PNorm = 47.4401, GNorm = 0.1412, lr_0 = 1.3128e-04
Loss = 1.5564e-05, PNorm = 47.4404, GNorm = 0.0712, lr_0 = 1.3110e-04
Validation rmse = 0.475487
Validation R2 = 0.937263
Epoch 88
Train function
Loss = 1.0924e-05, PNorm = 47.4419, GNorm = 0.0651, lr_0 = 1.3093e-04
Loss = 1.3024e-05, PNorm = 47.4428, GNorm = 0.0748, lr_0 = 1.3075e-04
Loss = 1.2958e-05, PNorm = 47.4424, GNorm = 0.0926, lr_0 = 1.3058e-04
Loss = 1.2619e-05, PNorm = 47.4425, GNorm = 0.1639, lr_0 = 1.3040e-04
Loss = 1.4672e-05, PNorm = 47.4426, GNorm = 0.2808, lr_0 = 1.3022e-04
Loss = 2.1207e-05, PNorm = 47.4438, GNorm = 0.2666, lr_0 = 1.3005e-04
Loss = 1.4030e-05, PNorm = 47.4458, GNorm = 0.0550, lr_0 = 1.2988e-04
Loss = 1.3348e-05, PNorm = 47.4469, GNorm = 0.1193, lr_0 = 1.2970e-04
Loss = 2.0693e-05, PNorm = 47.4465, GNorm = 0.0926, lr_0 = 1.2953e-04
Loss = 2.1761e-05, PNorm = 47.4475, GNorm = 0.0734, lr_0 = 1.2935e-04
Loss = 1.6815e-05, PNorm = 47.4492, GNorm = 0.0652, lr_0 = 1.2918e-04
Loss = 1.0024e-05, PNorm = 47.4500, GNorm = 0.0603, lr_0 = 1.2901e-04
Loss = 1.3572e-05, PNorm = 47.4523, GNorm = 0.1777, lr_0 = 1.2883e-04
Loss = 1.1401e-05, PNorm = 47.4541, GNorm = 0.0871, lr_0 = 1.2866e-04
Loss = 1.1074e-05, PNorm = 47.4561, GNorm = 0.1289, lr_0 = 1.2849e-04
Loss = 1.1626e-05, PNorm = 47.4562, GNorm = 0.0658, lr_0 = 1.2832e-04
Loss = 1.1574e-05, PNorm = 47.4564, GNorm = 0.0791, lr_0 = 1.2814e-04
Loss = 1.5661e-05, PNorm = 47.4580, GNorm = 0.1134, lr_0 = 1.2797e-04
Validation rmse = 0.477482
Validation R2 = 0.936736
Epoch 89
Train function
Loss = 1.2984e-05, PNorm = 47.4595, GNorm = 0.0611, lr_0 = 1.2778e-04
Loss = 1.1079e-05, PNorm = 47.4604, GNorm = 0.0419, lr_0 = 1.2761e-04
Loss = 9.9578e-06, PNorm = 47.4613, GNorm = 0.0503, lr_0 = 1.2744e-04
Loss = 1.0848e-05, PNorm = 47.4626, GNorm = 0.0846, lr_0 = 1.2727e-04
Loss = 1.0225e-05, PNorm = 47.4628, GNorm = 0.0927, lr_0 = 1.2710e-04
Loss = 1.5930e-05, PNorm = 47.4636, GNorm = 0.0690, lr_0 = 1.2693e-04
Loss = 1.2355e-05, PNorm = 47.4649, GNorm = 0.1640, lr_0 = 1.2676e-04
Loss = 1.4231e-05, PNorm = 47.4656, GNorm = 0.1340, lr_0 = 1.2659e-04
Loss = 1.2631e-05, PNorm = 47.4673, GNorm = 0.0650, lr_0 = 1.2642e-04
Loss = 1.2885e-05, PNorm = 47.4671, GNorm = 0.0560, lr_0 = 1.2625e-04
Loss = 1.1388e-05, PNorm = 47.4674, GNorm = 0.1117, lr_0 = 1.2608e-04
Loss = 1.1350e-05, PNorm = 47.4682, GNorm = 0.1748, lr_0 = 1.2591e-04
Loss = 1.2115e-05, PNorm = 47.4693, GNorm = 0.0757, lr_0 = 1.2574e-04
Loss = 1.8201e-05, PNorm = 47.4706, GNorm = 0.0620, lr_0 = 1.2557e-04
Loss = 1.7124e-05, PNorm = 47.4722, GNorm = 0.0602, lr_0 = 1.2540e-04
Loss = 1.3556e-05, PNorm = 47.4725, GNorm = 0.0757, lr_0 = 1.2524e-04
Loss = 1.1916e-05, PNorm = 47.4730, GNorm = 0.0482, lr_0 = 1.2507e-04
Validation rmse = 0.475704
Validation R2 = 0.937206
Epoch 90
Train function
Loss = 1.0317e-05, PNorm = 47.4736, GNorm = 0.1037, lr_0 = 1.2490e-04
Loss = 1.1813e-05, PNorm = 47.4745, GNorm = 0.0683, lr_0 = 1.2473e-04
Loss = 1.1524e-05, PNorm = 47.4743, GNorm = 0.1109, lr_0 = 1.2456e-04
Loss = 1.0608e-05, PNorm = 47.4748, GNorm = 0.0617, lr_0 = 1.2440e-04
Loss = 1.5219e-05, PNorm = 47.4762, GNorm = 0.1296, lr_0 = 1.2423e-04
Loss = 2.0151e-05, PNorm = 47.4767, GNorm = 0.3172, lr_0 = 1.2406e-04
Loss = 1.6986e-05, PNorm = 47.4776, GNorm = 0.1733, lr_0 = 1.2390e-04
Loss = 1.3224e-05, PNorm = 47.4792, GNorm = 0.0449, lr_0 = 1.2373e-04
Loss = 9.7400e-06, PNorm = 47.4806, GNorm = 0.0655, lr_0 = 1.2356e-04
Loss = 1.0945e-05, PNorm = 47.4808, GNorm = 0.1099, lr_0 = 1.2340e-04
Loss = 1.1356e-05, PNorm = 47.4811, GNorm = 0.1650, lr_0 = 1.2323e-04
Loss = 1.1671e-05, PNorm = 47.4815, GNorm = 0.1229, lr_0 = 1.2307e-04
Loss = 1.6309e-05, PNorm = 47.4822, GNorm = 0.1013, lr_0 = 1.2290e-04
Loss = 9.6542e-06, PNorm = 47.4837, GNorm = 0.0462, lr_0 = 1.2274e-04
Loss = 1.1755e-05, PNorm = 47.4848, GNorm = 0.0714, lr_0 = 1.2257e-04
Loss = 9.1648e-06, PNorm = 47.4857, GNorm = 0.0604, lr_0 = 1.2241e-04
Loss = 1.1759e-05, PNorm = 47.4868, GNorm = 0.1135, lr_0 = 1.2224e-04
Loss = 1.0723e-05, PNorm = 47.4875, GNorm = 0.0675, lr_0 = 1.2208e-04
Validation rmse = 0.477648
Validation R2 = 0.936692
Epoch 91
Train function
Loss = 9.9739e-06, PNorm = 47.4886, GNorm = 0.0618, lr_0 = 1.2192e-04
Loss = 8.6660e-06, PNorm = 47.4892, GNorm = 0.0735, lr_0 = 1.2175e-04
Loss = 9.2257e-06, PNorm = 47.4903, GNorm = 0.0443, lr_0 = 1.2159e-04
Loss = 1.1800e-05, PNorm = 47.4911, GNorm = 0.1693, lr_0 = 1.2143e-04
Loss = 1.1635e-05, PNorm = 47.4926, GNorm = 0.0624, lr_0 = 1.2126e-04
Loss = 1.1078e-05, PNorm = 47.4936, GNorm = 0.0797, lr_0 = 1.2110e-04
Loss = 1.0106e-05, PNorm = 47.4946, GNorm = 0.0514, lr_0 = 1.2094e-04
Loss = 1.0619e-05, PNorm = 47.4951, GNorm = 0.0660, lr_0 = 1.2078e-04
Loss = 1.7315e-05, PNorm = 47.4957, GNorm = 0.0480, lr_0 = 1.2061e-04
Loss = 1.2710e-05, PNorm = 47.4976, GNorm = 0.1050, lr_0 = 1.2045e-04
Loss = 1.2470e-05, PNorm = 47.4986, GNorm = 0.0535, lr_0 = 1.2029e-04
Loss = 1.1228e-05, PNorm = 47.4988, GNorm = 0.0909, lr_0 = 1.2013e-04
Loss = 1.3828e-05, PNorm = 47.4999, GNorm = 0.0487, lr_0 = 1.1997e-04
Loss = 1.2868e-05, PNorm = 47.4999, GNorm = 0.1267, lr_0 = 1.1981e-04
Loss = 1.1137e-05, PNorm = 47.5007, GNorm = 0.0887, lr_0 = 1.1965e-04
Loss = 9.4330e-06, PNorm = 47.5012, GNorm = 0.0536, lr_0 = 1.1949e-04
Loss = 7.1993e-06, PNorm = 47.5017, GNorm = 0.0464, lr_0 = 1.1933e-04
Validation rmse = 0.474718
Validation R2 = 0.937466
Epoch 92
Train function
Loss = 8.3803e-06, PNorm = 47.5021, GNorm = 0.0713, lr_0 = 1.1915e-04
Loss = 9.5283e-06, PNorm = 47.5026, GNorm = 0.0902, lr_0 = 1.1899e-04
Loss = 9.7165e-06, PNorm = 47.5044, GNorm = 0.0460, lr_0 = 1.1883e-04
Loss = 8.1353e-06, PNorm = 47.5051, GNorm = 0.0814, lr_0 = 1.1867e-04
Loss = 1.1926e-05, PNorm = 47.5046, GNorm = 0.1001, lr_0 = 1.1851e-04
Loss = 9.1445e-06, PNorm = 47.5049, GNorm = 0.1167, lr_0 = 1.1835e-04
Loss = 8.4968e-06, PNorm = 47.5056, GNorm = 0.0398, lr_0 = 1.1819e-04
Loss = 9.2287e-06, PNorm = 47.5060, GNorm = 0.0627, lr_0 = 1.1804e-04
Loss = 8.8376e-06, PNorm = 47.5071, GNorm = 0.0481, lr_0 = 1.1788e-04
Loss = 8.2749e-06, PNorm = 47.5082, GNorm = 0.0537, lr_0 = 1.1772e-04
Loss = 8.3440e-06, PNorm = 47.5094, GNorm = 0.0403, lr_0 = 1.1756e-04
Loss = 7.6852e-06, PNorm = 47.5095, GNorm = 0.0503, lr_0 = 1.1740e-04
Loss = 9.5105e-06, PNorm = 47.5105, GNorm = 0.0435, lr_0 = 1.1725e-04
Loss = 9.2093e-06, PNorm = 47.5111, GNorm = 0.0343, lr_0 = 1.1709e-04
Loss = 9.9325e-06, PNorm = 47.5113, GNorm = 0.0793, lr_0 = 1.1693e-04
Loss = 1.1752e-05, PNorm = 47.5112, GNorm = 0.1888, lr_0 = 1.1677e-04
Loss = 9.5626e-06, PNorm = 47.5122, GNorm = 0.1386, lr_0 = 1.1662e-04
Loss = 1.4658e-05, PNorm = 47.5133, GNorm = 0.0663, lr_0 = 1.1646e-04
Validation rmse = 0.476009
Validation R2 = 0.937126
Epoch 93
Train function
Loss = 1.2064e-05, PNorm = 47.5150, GNorm = 0.0815, lr_0 = 1.1630e-04
Loss = 1.1662e-05, PNorm = 47.5154, GNorm = 0.0415, lr_0 = 1.1615e-04
Loss = 7.9263e-06, PNorm = 47.5163, GNorm = 0.0510, lr_0 = 1.1599e-04
Loss = 1.0148e-05, PNorm = 47.5176, GNorm = 0.1662, lr_0 = 1.1584e-04
Loss = 1.0758e-05, PNorm = 47.5187, GNorm = 0.0817, lr_0 = 1.1568e-04
Loss = 1.6476e-05, PNorm = 47.5186, GNorm = 0.0451, lr_0 = 1.1553e-04
Loss = 1.2763e-05, PNorm = 47.5189, GNorm = 0.0617, lr_0 = 1.1537e-04
Loss = 1.1631e-05, PNorm = 47.5202, GNorm = 0.0763, lr_0 = 1.1522e-04
Loss = 1.5106e-05, PNorm = 47.5211, GNorm = 0.0799, lr_0 = 1.1506e-04
Loss = 1.1177e-05, PNorm = 47.5227, GNorm = 0.1182, lr_0 = 1.1491e-04
Loss = 1.5020e-05, PNorm = 47.5232, GNorm = 0.1027, lr_0 = 1.1475e-04
Loss = 1.3584e-05, PNorm = 47.5239, GNorm = 0.0915, lr_0 = 1.1460e-04
Loss = 1.1854e-05, PNorm = 47.5256, GNorm = 0.0717, lr_0 = 1.1445e-04
Loss = 1.1563e-05, PNorm = 47.5269, GNorm = 0.1190, lr_0 = 1.1429e-04
Loss = 1.0563e-05, PNorm = 47.5270, GNorm = 0.0615, lr_0 = 1.1414e-04
Loss = 1.0963e-05, PNorm = 47.5279, GNorm = 0.0739, lr_0 = 1.1399e-04
Loss = 1.2468e-05, PNorm = 47.5287, GNorm = 0.0690, lr_0 = 1.1383e-04
Loss = 1.3910e-05, PNorm = 47.5303, GNorm = 0.0957, lr_0 = 1.1368e-04
Validation rmse = 0.476053
Validation R2 = 0.937114
Epoch 94
Train function
Loss = 1.5159e-05, PNorm = 47.5300, GNorm = 0.0917, lr_0 = 1.1353e-04
Loss = 1.4334e-05, PNorm = 47.5300, GNorm = 0.1366, lr_0 = 1.1338e-04
Loss = 9.0676e-06, PNorm = 47.5316, GNorm = 0.0570, lr_0 = 1.1322e-04
Loss = 7.6106e-06, PNorm = 47.5331, GNorm = 0.0496, lr_0 = 1.1307e-04
Loss = 9.7409e-06, PNorm = 47.5331, GNorm = 0.1003, lr_0 = 1.1292e-04
Loss = 6.1905e-06, PNorm = 47.5340, GNorm = 0.0550, lr_0 = 1.1277e-04
Loss = 6.6764e-06, PNorm = 47.5347, GNorm = 0.0423, lr_0 = 1.1262e-04
Loss = 8.1232e-06, PNorm = 47.5352, GNorm = 0.0938, lr_0 = 1.1247e-04
Loss = 5.2693e-06, PNorm = 47.5354, GNorm = 0.0317, lr_0 = 1.1231e-04
Loss = 9.0545e-06, PNorm = 47.5354, GNorm = 0.0475, lr_0 = 1.1216e-04
Loss = 1.0478e-05, PNorm = 47.5357, GNorm = 0.0869, lr_0 = 1.1201e-04
Loss = 9.7863e-06, PNorm = 47.5365, GNorm = 0.0489, lr_0 = 1.1186e-04
Loss = 1.2815e-05, PNorm = 47.5374, GNorm = 0.0940, lr_0 = 1.1171e-04
Loss = 1.1756e-05, PNorm = 47.5383, GNorm = 0.0853, lr_0 = 1.1156e-04
Loss = 1.0753e-05, PNorm = 47.5389, GNorm = 0.0774, lr_0 = 1.1141e-04
Loss = 9.5310e-06, PNorm = 47.5387, GNorm = 0.0564, lr_0 = 1.1126e-04
Loss = 9.4037e-06, PNorm = 47.5401, GNorm = 0.0549, lr_0 = 1.1111e-04
Validation rmse = 0.474931
Validation R2 = 0.937410
Epoch 95
Train function
Loss = 7.5924e-06, PNorm = 47.5417, GNorm = 0.0668, lr_0 = 1.1095e-04
Loss = 7.5380e-06, PNorm = 47.5424, GNorm = 0.0513, lr_0 = 1.1080e-04
Loss = 6.9032e-06, PNorm = 47.5432, GNorm = 0.0785, lr_0 = 1.1065e-04
Loss = 7.4854e-06, PNorm = 47.5445, GNorm = 0.0520, lr_0 = 1.1050e-04
Loss = 8.9362e-06, PNorm = 47.5448, GNorm = 0.0401, lr_0 = 1.1036e-04
Loss = 7.4292e-06, PNorm = 47.5441, GNorm = 0.0846, lr_0 = 1.1021e-04
Loss = 1.1440e-05, PNorm = 47.5442, GNorm = 0.0856, lr_0 = 1.1006e-04
Loss = 8.5041e-06, PNorm = 47.5447, GNorm = 0.0940, lr_0 = 1.0991e-04
Loss = 1.0316e-05, PNorm = 47.5455, GNorm = 0.0805, lr_0 = 1.0977e-04
Loss = 9.3562e-06, PNorm = 47.5458, GNorm = 0.1052, lr_0 = 1.0962e-04
Loss = 8.4843e-06, PNorm = 47.5469, GNorm = 0.1110, lr_0 = 1.0947e-04
Loss = 1.0743e-05, PNorm = 47.5480, GNorm = 0.0597, lr_0 = 1.0932e-04
Loss = 1.0163e-05, PNorm = 47.5484, GNorm = 0.0983, lr_0 = 1.0918e-04
Loss = 1.2242e-05, PNorm = 47.5497, GNorm = 0.0767, lr_0 = 1.0903e-04
Loss = 9.2935e-06, PNorm = 47.5509, GNorm = 0.0594, lr_0 = 1.0888e-04
Loss = 8.9342e-06, PNorm = 47.5509, GNorm = 0.0407, lr_0 = 1.0874e-04
Loss = 9.9633e-06, PNorm = 47.5516, GNorm = 0.1233, lr_0 = 1.0859e-04
Loss = 1.0676e-05, PNorm = 47.5532, GNorm = 0.1195, lr_0 = 1.0845e-04
Validation rmse = 0.475833
Validation R2 = 0.937172
Epoch 96
Train function
Loss = 1.2083e-05, PNorm = 47.5542, GNorm = 0.1152, lr_0 = 1.0830e-04
Loss = 1.1566e-05, PNorm = 47.5544, GNorm = 0.0943, lr_0 = 1.0816e-04
Loss = 1.0415e-05, PNorm = 47.5564, GNorm = 0.0873, lr_0 = 1.0801e-04
Loss = 7.2405e-06, PNorm = 47.5570, GNorm = 0.0909, lr_0 = 1.0787e-04
Loss = 8.7673e-06, PNorm = 47.5575, GNorm = 0.0775, lr_0 = 1.0772e-04
Loss = 6.8629e-06, PNorm = 47.5577, GNorm = 0.0336, lr_0 = 1.0758e-04
Loss = 8.2875e-06, PNorm = 47.5585, GNorm = 0.0307, lr_0 = 1.0743e-04
Loss = 6.1312e-06, PNorm = 47.5598, GNorm = 0.0382, lr_0 = 1.0729e-04
Loss = 1.0302e-05, PNorm = 47.5606, GNorm = 0.0800, lr_0 = 1.0714e-04
Loss = 7.4435e-06, PNorm = 47.5614, GNorm = 0.0455, lr_0 = 1.0700e-04
Loss = 9.6656e-06, PNorm = 47.5616, GNorm = 0.0881, lr_0 = 1.0686e-04
Loss = 1.4511e-05, PNorm = 47.5630, GNorm = 0.1443, lr_0 = 1.0671e-04
Loss = 1.3788e-05, PNorm = 47.5633, GNorm = 0.1707, lr_0 = 1.0657e-04
Loss = 1.2704e-05, PNorm = 47.5630, GNorm = 0.1311, lr_0 = 1.0643e-04
Loss = 1.3575e-05, PNorm = 47.5651, GNorm = 0.1299, lr_0 = 1.0629e-04
Loss = 1.8183e-05, PNorm = 47.5658, GNorm = 0.0437, lr_0 = 1.0614e-04
Loss = 1.6936e-05, PNorm = 47.5675, GNorm = 0.0799, lr_0 = 1.0600e-04
Validation rmse = 0.477623
Validation R2 = 0.936698
Epoch 97
Train function
Loss = 1.6397e-05, PNorm = 47.5695, GNorm = 0.0691, lr_0 = 1.0586e-04
Loss = 1.4411e-05, PNorm = 47.5703, GNorm = 0.1585, lr_0 = 1.0572e-04
Loss = 1.0706e-05, PNorm = 47.5709, GNorm = 0.0573, lr_0 = 1.0557e-04
Loss = 1.1454e-05, PNorm = 47.5718, GNorm = 0.0442, lr_0 = 1.0543e-04
Loss = 1.2088e-05, PNorm = 47.5722, GNorm = 0.1079, lr_0 = 1.0529e-04
Loss = 9.9180e-06, PNorm = 47.5731, GNorm = 0.0708, lr_0 = 1.0515e-04
Loss = 8.3845e-06, PNorm = 47.5735, GNorm = 0.0528, lr_0 = 1.0501e-04
Loss = 7.4373e-06, PNorm = 47.5743, GNorm = 0.0688, lr_0 = 1.0487e-04
Loss = 8.1916e-06, PNorm = 47.5746, GNorm = 0.0511, lr_0 = 1.0473e-04
Loss = 9.4259e-06, PNorm = 47.5749, GNorm = 0.0840, lr_0 = 1.0459e-04
Loss = 7.4268e-06, PNorm = 47.5746, GNorm = 0.1212, lr_0 = 1.0445e-04
Loss = 8.2167e-06, PNorm = 47.5762, GNorm = 0.0809, lr_0 = 1.0431e-04
Loss = 9.2702e-06, PNorm = 47.5774, GNorm = 0.1247, lr_0 = 1.0417e-04
Loss = 9.5625e-06, PNorm = 47.5778, GNorm = 0.0884, lr_0 = 1.0403e-04
Loss = 8.7677e-06, PNorm = 47.5785, GNorm = 0.0382, lr_0 = 1.0389e-04
Loss = 9.6652e-06, PNorm = 47.5794, GNorm = 0.0603, lr_0 = 1.0375e-04
Loss = 1.1006e-05, PNorm = 47.5798, GNorm = 0.0835, lr_0 = 1.0361e-04
Loss = 1.0605e-05, PNorm = 47.5798, GNorm = 0.1146, lr_0 = 1.0347e-04
Validation rmse = 0.476663
Validation R2 = 0.936952
Epoch 98
Train function
Loss = 8.3841e-06, PNorm = 47.5808, GNorm = 0.1054, lr_0 = 1.0332e-04
Loss = 8.8338e-06, PNorm = 47.5817, GNorm = 0.0590, lr_0 = 1.0318e-04
Loss = 7.8978e-06, PNorm = 47.5819, GNorm = 0.0629, lr_0 = 1.0304e-04
Loss = 1.1824e-05, PNorm = 47.5826, GNorm = 0.1285, lr_0 = 1.0290e-04
Loss = 7.4823e-06, PNorm = 47.5838, GNorm = 0.0530, lr_0 = 1.0276e-04
Loss = 7.3739e-06, PNorm = 47.5845, GNorm = 0.0236, lr_0 = 1.0263e-04
Loss = 7.2783e-06, PNorm = 47.5850, GNorm = 0.1267, lr_0 = 1.0249e-04
Loss = 8.0767e-06, PNorm = 47.5857, GNorm = 0.0776, lr_0 = 1.0235e-04
Loss = 9.3419e-06, PNorm = 47.5858, GNorm = 0.0973, lr_0 = 1.0221e-04
Loss = 8.0900e-06, PNorm = 47.5863, GNorm = 0.0661, lr_0 = 1.0208e-04
Loss = 4.8716e-06, PNorm = 47.5868, GNorm = 0.0394, lr_0 = 1.0194e-04
Loss = 1.2185e-05, PNorm = 47.5869, GNorm = 0.1184, lr_0 = 1.0180e-04
Loss = 7.3247e-06, PNorm = 47.5875, GNorm = 0.0680, lr_0 = 1.0167e-04
Loss = 7.8440e-06, PNorm = 47.5885, GNorm = 0.0861, lr_0 = 1.0153e-04
Loss = 6.2529e-06, PNorm = 47.5899, GNorm = 0.0580, lr_0 = 1.0139e-04
Loss = 6.5638e-06, PNorm = 47.5905, GNorm = 0.0769, lr_0 = 1.0126e-04
Loss = 6.7189e-06, PNorm = 47.5906, GNorm = 0.0319, lr_0 = 1.0112e-04
Validation rmse = 0.476104
Validation R2 = 0.937100
Epoch 99
Train function
Loss = 5.4010e-06, PNorm = 47.5906, GNorm = 0.0385, lr_0 = 1.0098e-04
Loss = 6.6304e-06, PNorm = 47.5919, GNorm = 0.0455, lr_0 = 1.0085e-04
Loss = 5.1563e-06, PNorm = 47.5922, GNorm = 0.0572, lr_0 = 1.0071e-04
Loss = 5.0850e-06, PNorm = 47.5926, GNorm = 0.0468, lr_0 = 1.0058e-04
Loss = 6.9817e-06, PNorm = 47.5929, GNorm = 0.0605, lr_0 = 1.0044e-04
Loss = 6.2331e-06, PNorm = 47.5937, GNorm = 0.0761, lr_0 = 1.0031e-04
Loss = 6.1090e-06, PNorm = 47.5941, GNorm = 0.0489, lr_0 = 1.0017e-04
Loss = 6.9928e-06, PNorm = 47.5943, GNorm = 0.0791, lr_0 = 1.0004e-04
Loss = 6.2177e-06, PNorm = 47.5946, GNorm = 0.0509, lr_0 = 1.0000e-04
Loss = 8.5900e-06, PNorm = 47.5949, GNorm = 0.0645, lr_0 = 1.0000e-04
Loss = 9.2610e-06, PNorm = 47.5959, GNorm = 0.0493, lr_0 = 1.0000e-04
Loss = 5.6001e-06, PNorm = 47.5961, GNorm = 0.0855, lr_0 = 1.0000e-04
Loss = 6.9772e-06, PNorm = 47.5964, GNorm = 0.0394, lr_0 = 1.0000e-04
Loss = 9.7899e-06, PNorm = 47.5963, GNorm = 0.0825, lr_0 = 1.0000e-04
Loss = 9.7298e-06, PNorm = 47.5976, GNorm = 0.0685, lr_0 = 1.0000e-04
Loss = 1.2592e-05, PNorm = 47.5965, GNorm = 0.0656, lr_0 = 1.0000e-04
Loss = 8.4638e-06, PNorm = 47.5978, GNorm = 0.1050, lr_0 = 1.0000e-04
Loss = 8.5431e-06, PNorm = 47.5984, GNorm = 0.0823, lr_0 = 1.0000e-04
Validation rmse = 0.475250
Validation R2 = 0.937326
Model 0 best validation rmse = 0.468020 on epoch 28
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.469304
Model 0 test R2 = 0.934598
Ensemble test rmse = 0.469304
Ensemble test R2 = 0.934598
Fold 2
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 200,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8782,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 2
Total size = 11,710 | train size = 8,783 | val size = 2,927 | test size = 2,067
Fitting scaler
[[-1.01], [2.13], [4.67], [1.85], [1.35], [3.45], [-0.6], [0.34], [5.23], [4.91], [1.29], [-1.22], [5.8], [4.04], [-0.24], [3.18], [1.89], [0.66], [3.42], [3.0], [0.9], [0.08], [2.61], [2.65], [2.17], [0.31], [0.42], [3.25], [-0.51], [2.55], [-0.21], [3.93], [3.61], [3.05], [3.2], [-0.07], [3.18], [1.85], [5.05], [4.66], [0.29], [0.57], [5.04], [2.22], [1.38], [5.16], [2.88], [1.13], [1.48], [2.75], [3.07], [0.61], [0.68], [4.93], [1.3], [0.73], [1.73], [-1.95], [4.37], [2.8], [3.76], [2.83], [0.63], [2.63], [2.25], [1.54], [3.08], [1.41], [1.45], [1.36], [4.0], [-0.22], [0.06], [0.93], [2.42], [2.47], [0.56], [3.47], [0.48], [1.92], [6.23], [1.46], [-0.1], [0.8], [0.84], [1.91], [3.03], [0.36], [0.72], [4.43], [0.16], [-0.85], [1.67], [2.91], [2.12], [1.03], [-2.41], [3.85], [6.39], [4.75], [2.4], [-0.47], [2.16], [1.89], [-2.96], [3.03], [2.92], [2.49], [2.41], [2.14], [2.72], [1.33], [-0.38], [2.99], [2.28], [2.8], [3.15], [3.78], [4.3], [1.7], [0.63], [1.5], [1.8], [0.79], [1.41], [2.27], [2.78], [2.64], [1.65], [1.51], [2.57], [4.78], [2.02], [6.61], [0.98], [2.4], [4.36], [2.58], [0.23], [1.42], [1.24], [3.05], [1.31], [1.94], [6.66], [1.84], [3.43], [0.29], [2.83], [1.56], [2.16], [0.82], [4.0], [-1.62], [3.18], [3.2], [-0.15], [-0.15], [1.83], [3.8], [3.86], [1.16], [2.32], [3.11], [1.74], [1.8], [5.04], [0.49], [0.61], [0.7], [4.31], [2.7], [2.65], [2.67], [0.54], [1.03], [0.52], [3.26], [-1.56], [0.06], [2.65], [5.31], [2.14], [4.89], [2.91], [1.21], [4.77], [2.33], [3.1], [5.59], [1.02], [0.74], [1.71], [1.96], [1.83], [-0.14], [-1.04], [-0.85], [0.8], [2.71], [2.4], [0.62], [1.09], [3.65], [3.4], [5.15], [1.28], [-0.78], [2.72], [2.33], [1.6], [1.54], [1.92], [1.57], [-0.35], [-0.1], [5.22], [5.74], [1.68], [5.07], [0.5], [0.08], [-0.27], [3.3], [1.02], [-1.22], [-1.37], [-0.74], [4.2], [2.67], [1.84], [-0.4], [-0.18], [2.47], [1.58], [0.65], [7.44], [2.12], [1.9], [1.53], [0.0], [1.56], [2.11], [2.31], [1.32], [4.34], [-0.29], [0.6], [2.32], [1.42], [0.34], [0.08], [2.26], [1.97], [2.31], [2.63], [0.42], [0.98], [3.74], [2.34], [3.12], [5.93], [-1.57], [0.57], [3.94], [4.44], [2.1], [5.0], [2.92], [0.66], [3.39], [-0.96], [4.12], [1.91], [0.29], [2.82], [2.16], [3.96], [1.46], [0.31], [-0.47], [4.66], [0.64], [1.9], [1.43], [2.01], [0.05], [1.92], [-0.34], [2.31], [2.27], [2.4], [2.1], [2.59], [0.56], [4.26], [2.39], [5.9], [-0.44], [3.82], [0.49], [1.2], [4.26], [1.3], [2.65], [3.51], [-1.73], [2.98], [4.18], [3.2], [3.91], [0.21], [0.23], [5.31], [0.01], [4.15], [2.52], [2.31], [0.38], [1.95], [-0.59], [3.42], [2.16], [0.47], [0.2], [1.81], [5.64], [4.22], [0.98], [1.0], [1.71], [3.72], [0.75], [-0.59], [2.55], [1.58], [2.04], [2.54], [2.74], [2.11], [0.37], [2.27], [0.54], [0.81], [1.02], [3.55], [1.85], [3.56], [-0.11], [0.49], [3.34], [2.04], [2.78], [2.04], [1.79], [3.17], [3.14], [4.1], [1.55], [-0.51], [2.11], [1.02], [2.13], [0.59], [4.44], [1.65], [1.59], [1.68], [1.24], [1.52], [0.32], [1.16], [2.82], [2.16], [0.39], [0.86], [0.77], [-1.05], [0.45], [2.85], [4.48], [1.98], [1.32], [2.18], [0.72], [1.62], [2.35], [6.01], [-0.78], [-0.09], [-0.45], [1.41], [5.8], [3.3], [0.52], [1.76], [1.8], [2.17], [1.4], [-0.86], [2.54], [3.19], [0.92], [4.07], [1.38], [2.48], [1.27], [1.78], [1.83], [0.53], [4.06], [-0.19], [2.5], [1.76], [2.66], [4.93], [-0.98], [2.6], [1.23], [2.73], [3.2], [3.82], [2.22], [7.41], [1.31], [3.21], [1.95], [0.87], [0.86], [2.07], [2.42], [1.38], [3.24], [2.79], [1.41], [-0.26], [1.82], [3.18], [0.97], [1.87], [0.54], [3.16], [2.44], [-0.7], [0.9], [4.55], [1.8], [3.1], [4.09], [0.7], [3.66], [1.53], [3.65], [1.1], [2.69], [1.03], [1.92], [3.07], [3.5], [1.65], [3.52], [0.93], [1.24], [2.83], [2.0], [3.2], [-1.97], [1.49], [2.33], [0.03], [2.47], [1.49], [1.49], [-0.7], [2.91], [1.51], [1.49], [1.0], [0.5], [5.26], [2.28], [3.15], [2.04], [3.42], [2.71], [0.56], [2.96], [4.65], [4.67], [2.86], [0.87], [1.59], [1.52], [-1.14], [2.58], [2.84], [2.31], [0.25], [2.04], [2.09], [1.82], [3.53], [2.29], [1.78], [0.25], [1.26], [0.9], [2.99], [3.39], [6.34], [2.71], [4.47], [0.49], [-0.05], [3.57], [1.0], [1.47], [0.56], [2.23], [0.28], [0.46], [1.66], [2.42], [-0.48], [0.66], [4.61], [3.0], [5.51], [1.2], [0.13], [3.38], [0.86], [-0.61], [1.06], [-0.62], [2.18], [-1.45], [3.35], [3.43], [0.71], [3.36], [2.28], [4.92], [2.28], [3.07], [0.46], [0.61], [2.06], [4.41], [0.83], [1.81], [1.86], [-0.58], [3.08], [2.45], [6.82], [-0.6], [2.25], [2.78], [3.32], [5.2], [0.73], [4.38], [1.38], [1.18], [2.5], [3.7], [0.99], [4.34], [4.63], [1.43], [4.65], [0.35], [1.57], [2.96], [3.95], [2.95], [2.28], [2.55], [2.47], [3.46], [2.36], [0.15], [2.75], [2.79], [4.76], [1.63], [2.31], [3.46], [2.05], [0.84], [2.45], [1.9], [2.95], [1.41], [3.33], [2.25], [2.99], [1.11], [3.09], [2.98], [1.35], [2.37], [5.29], [0.88], [2.21], [1.78], [-0.06], [2.01], [0.59], [2.54], [0.49], [2.79], [1.02], [2.22], [4.3], [0.82], [4.98], [0.95], [5.7], [1.82], [1.69], [3.51], [0.7], [1.64], [4.56], [2.71], [1.17], [2.19], [2.73], [0.22], [3.87], [2.22], [2.74], [4.78], [0.78], [3.41], [3.52], [2.17], [3.38], [3.87], [2.29], [-0.25], [-0.77], [1.27], [-0.26], [2.05], [2.03], [2.08], [1.4], [4.28], [3.83], [7.25], [1.34], [1.83], [2.27], [4.58], [4.3], [0.62], [2.01], [1.14], [2.33], [0.04], [6.65], [3.57], [5.56], [1.51], [-2.49], [-1.99], [-0.04], [2.6], [4.52], [-1.49], [2.74], [1.44], [1.03], [-1.12], [0.23], [4.0], [2.06], [-0.77], [1.44], [3.73], [1.1], [0.26], [1.76], [1.79], [1.01], [1.54], [-0.3], [4.6], [2.44], [3.21], [-1.1], [2.78], [1.09], [2.78], [1.0], [2.7], [1.24], [0.58], [1.74], [1.91], [-1.32], [-0.92], [4.11], [3.45], [-0.6], [0.52], [4.88], [2.63], [-0.53], [3.96], [4.16], [4.22], [3.14], [1.4], [0.65], [-1.18], [1.65], [1.98], [0.82], [0.45], [1.97], [2.17], [2.72], [3.36], [1.81], [4.94], [1.38], [-1.6], [2.87], [6.11], [2.67], [0.95], [4.04], [1.0], [2.04], [1.15], [6.05], [-0.6], [2.23], [2.25], [2.57], [1.28], [3.3], [0.95], [0.16], [-0.44], [2.75], [1.58], [0.52], [2.43], [1.29], [-0.21], [3.1], [3.79], [-1.87], [2.64], [2.05], [3.93], [4.06], [4.9], [6.3], [3.1], [2.29], [-1.43], [0.29], [0.35], [0.85], [2.69], [1.21], [1.28], [4.51], [3.3], [4.2], [1.5], [-1.84], [0.43], [2.57], [-0.57], [3.11], [-0.74], [2.2], [6.22], [2.47], [1.68], [0.02], [0.91], [2.15], [7.12], [2.47], [-0.09], [4.8], [0.9], [2.85], [-0.37], [0.12], [-1.7], [2.65], [1.34], [4.01], [7.5], [1.92], [1.29], [3.03], [4.09], [-0.64], [9.16], [0.6], [1.84], [2.46], [-1.3], [2.19], [-2.63], [0.73], [2.71], [3.61], [2.48], [0.06], [-0.77], [1.8], [-0.27], [-0.04], [2.23], [7.45], [2.39], [-0.29], [1.15], [0.3], [1.07], [1.37], [2.73], [2.86], [1.29], [2.26], [4.62], [5.76], [0.28], [2.18], [1.96], [1.89], [-1.64], [2.3], [1.87], [1.37], [3.79], [-1.46], [1.48], [0.09], [1.21], [-0.04], [2.97], [-0.01], [3.28], [1.13], [4.82], [6.53], [5.2], [1.47], [3.91], [1.37], [2.56], [2.42], [1.24], [2.66], [2.72], [0.63], [2.35], [1.41], [2.42], [4.55], [0.79], [-0.25], [-0.66], [3.23], [3.36], [0.35], [3.13], [3.8], [1.52], [2.03], [2.83], [1.0], [2.88], [6.63], [3.62], [5.92], [0.39], [0.76], [4.45], [3.31], [2.19], [1.58], [1.65], [2.09], [1.86], [1.46], [3.37], [2.78], [4.24], [1.16], [4.16], [3.11], [3.23], [3.84], [2.56], [3.1], [3.91], [1.38], [-0.6], [2.48], [0.63], [2.82], [3.61], [2.01], [-0.21], [-0.3], [3.73], [2.1], [2.03], [1.88], [2.99], [1.94], [0.06], [1.09], [3.12], [-2.52], [1.74], [1.85], [4.2], [3.5], [2.47], [-0.58], [3.57], [2.86], [2.03], [-0.59], [2.06], [6.04], [4.51], [2.19], [2.65], [4.43], [0.12], [1.73], [1.86], [3.37], [-0.76], [1.35], [2.94], [1.48], [2.66], [2.21], [4.49], [2.91], [-1.16], [2.3], [2.09], [1.18], [-1.68], [7.18], [1.6], [1.22], [0.7], [5.98], [2.5], [4.66], [-2.1], [2.5], [3.92], [1.41], [3.06], [3.63], [5.13], [6.27], [-2.0], [3.52], [2.42], [3.12], [2.09], [3.75], [0.29], [2.72], [2.19], [1.18], [0.45], [-0.26], [0.38], [9.16], [3.11], [1.12], [-0.97], [1.2], [3.41], [1.82], [2.23], [1.69], [3.44], [3.28], [2.45], [4.21], [4.21], [4.99], [2.32], [2.28], [2.06], [-0.09], [2.34], [-0.11], [-0.05], [1.82], [2.12], [2.58], [-0.89], [6.14], [1.77], [-1.01], [2.24], [3.49], [-2.27], [1.03], [1.83], [2.26], [0.94], [8.61], [4.92], [2.14], [0.88], [2.95], [3.41], [1.67], [0.87], [1.98], [0.72], [2.37], [1.25], [0.64], [0.52], [-2.2], [-1.15], [1.86], [2.77], [2.2], [2.7], [0.08], [3.21], [1.2], [2.65], [-0.49], [2.34], [2.85], [-3.32], [2.83], [4.31], [4.14], [1.76], [2.36], [-1.8], [-1.76], [5.06], [0.55], [-0.98], [1.63], [2.05], [2.0], [2.44], [0.59], [2.7], [-0.24], [0.35], [2.08], [0.07], [2.75], [0.62], [2.62], [2.42], [4.46], [1.78], [4.03], [1.64], [1.63], [1.94], [3.91], [0.77], [0.11], [0.79], [0.86], [-0.16], [1.16], [4.45], [1.53], [3.05], [1.07], [0.97], [5.7], [-2.28], [1.12], [1.53], [-2.55], [0.95], [1.91], [-0.82], [0.19], [5.33], [-0.54], [3.46], [3.62], [2.56], [2.44], [2.63], [2.99], [2.77], [1.09], [-0.18], [2.26], [4.73], [0.3], [-1.39], [5.11], [2.54], [5.7], [3.52], [-1.82], [2.4], [-0.2], [0.16], [1.85], [2.25], [2.71], [0.3], [2.52], [2.64], [-0.22], [2.12], [0.04], [0.39], [3.55], [0.36], [1.5], [3.17], [2.11], [2.83], [2.36], [2.76], [-0.32], [1.73], [1.34], [3.36], [1.39], [1.76], [1.79], [3.87], [2.97], [0.42], [-1.33], [1.48], [1.88], [0.31], [5.14], [-0.67], [2.18], [0.08], [1.21], [2.08], [2.7], [3.7], [3.46], [-0.72], [5.44], [2.21], [3.15], [5.44], [-0.15], [3.33], [2.17], [0.79], [3.64], [2.16], [2.76], [3.71], [1.99], [3.9], [2.25], [4.04], [2.09], [3.28], [1.37], [3.2], [3.24], [3.27], [2.33], [4.44], [1.98], [2.3], [1.23], [2.17], [0.61], [1.55], [-0.01], [3.0], [1.41], [1.79], [3.9], [2.63], [1.7], [1.6], [1.1], [1.72], [5.54], [1.77], [2.07], [2.32], [2.66], [1.6], [1.0], [3.88], [1.55], [5.05], [-1.14], [-0.13], [2.0], [5.73], [1.31], [1.98], [0.64], [-0.99], [2.48], [3.86], [3.52], [3.92], [3.65], [3.8], [-0.26], [3.26], [-1.6], [1.22], [1.61], [4.2], [5.19], [0.25], [3.17], [2.13], [2.35], [1.87], [0.93], [2.07], [4.08], [-1.41], [4.47], [1.22], [4.62], [1.57], [2.42], [0.18], [2.59], [3.16], [0.8], [2.43], [2.59], [1.41], [-0.1], [8.71], [-1.03], [1.56], [1.2], [2.55], [1.59], [2.57], [-0.17], [4.38], [3.16], [3.18], [-0.77], [1.39], [1.58], [-2.2], [-0.25], [4.04], [3.82], [4.07], [0.16], [1.08], [4.11], [0.13], [2.28], [4.63], [0.61], [0.91], [2.79], [1.22], [3.13], [1.82], [5.8], [0.36], [-0.62], [1.34], [-0.74], [1.11], [1.33], [0.21], [2.92], [0.59], [1.68], [2.4], [0.47], [0.74], [1.21], [1.61], [1.63], [0.64], [2.15], [-0.17], [1.39], [4.62], [-0.28], [1.66], [0.53], [1.31], [-0.94], [1.84], [1.48], [2.93], [3.51], [1.0], [1.0], [-2.39], [1.57], [1.73], [-3.1], [4.22], [4.12], [3.23], [1.83], [5.56], [1.83], [0.87], [2.1], [-0.38], [-1.68], [2.3], [1.6], [1.86], [1.3], [5.41], [2.59], [2.8], [3.45], [-1.08], [0.47], [2.82], [3.09], [1.76], [0.91], [2.82], [1.63], [-1.36], [2.41], [1.98], [0.48], [3.99], [1.59], [0.1], [6.07], [2.58], [2.56], [0.55], [-0.57], [7.53], [-0.7], [2.99], [3.43], [1.92], [3.75], [1.2], [-2.51], [3.57], [1.54], [1.13], [0.64], [1.75], [1.39], [-0.31], [0.63], [4.21], [0.14], [3.2], [-0.71], [4.42], [1.72], [2.95], [2.86], [5.77], [3.91], [-1.56], [0.4], [2.0], [0.35], [7.64], [5.17], [4.23], [4.61], [2.13], [3.15], [4.01], [0.49], [0.95], [2.06], [3.51], [4.02], [6.51], [0.7], [5.31], [2.78], [0.75], [-0.37], [2.14], [0.21], [1.78], [0.25], [2.26], [3.21], [6.46], [-1.69], [2.73], [1.0], [2.3], [2.72], [2.72], [2.83], [-0.4], [3.56], [2.07], [-0.26], [0.71], [2.22], [3.2], [0.54], [0.19], [-2.96], [0.83], [0.54], [2.3], [3.1], [1.88], [-0.02], [2.8], [2.44], [3.31], [1.91], [4.62], [-0.7], [2.4], [2.51], [2.53], [0.89], [3.05], [2.61], [1.18], [0.41], [-0.1], [3.85], [2.28], [0.38], [1.65], [7.25], [2.47], [2.63], [6.82], [1.62], [1.36], [2.52], [3.0], [3.66], [0.63], [9.25], [3.1], [2.46], [2.59], [0.04], [1.1], [1.04], [0.01], [-0.38], [3.55], [0.74], [1.78], [4.05], [3.9], [3.78], [2.29], [2.01], [2.14], [2.2], [0.0], [2.62], [2.3], [2.88], [2.95], [2.5], [-0.62], [1.48], [1.53], [3.78], [1.83], [4.1], [3.9], [1.29], [3.15], [4.04], [0.05], [2.23], [3.62], [3.46], [2.74], [-0.21], [0.83], [0.97], [3.33], [3.75], [2.53], [1.23], [-1.34], [2.05], [6.37], [1.25], [1.24], [-0.19], [4.4], [2.12], [0.49], [4.25], [4.23], [1.3], [4.45], [0.06], [1.65], [3.83], [2.62], [1.38], [0.08], [1.25], [1.21], [1.76], [1.92], [0.68], [2.1], [2.01], [2.66], [1.48], [0.77], [3.63], [4.92], [1.77], [3.91], [2.02], [0.24], [2.36], [0.95], [0.12], [3.0], [1.88], [2.19], [3.6], [3.14], [4.49], [-1.28], [0.57], [-0.79], [4.59], [3.08], [1.54], [-2.0], [1.04], [-2.19], [-0.5], [-1.66], [3.73], [3.44], [3.6], [-0.32], [2.38], [3.85], [2.64], [1.66], [2.2], [6.58], [1.95], [2.48], [1.62], [3.38], [1.48], [4.16], [0.14], [2.31], [2.54], [1.52], [1.26], [4.2], [2.06], [2.04], [0.95], [2.93], [2.09], [5.79], [-2.56], [3.21], [-0.1], [3.62], [1.08], [3.53], [5.03], [3.76], [1.65], [1.76], [3.48], [5.3], [-1.06], [3.9], [4.56], [1.62], [-0.1], [1.43], [4.6], [1.12], [1.13], [5.48], [2.8], [0.28], [3.5], [0.04], [2.39], [1.09], [-0.08], [1.34], [3.5], [1.58], [-1.53], [0.75], [7.45], [3.1], [5.02], [1.79], [-0.2], [2.73], [2.58], [-0.59], [3.79], [3.71], [-0.7], [3.83], [-0.86], [0.2], [1.04], [3.36], [1.12], [0.51], [0.33], [2.71], [-2.33], [1.52], [2.62], [1.54], [2.47], [1.33], [0.51], [0.71], [2.73], [2.17], [3.02], [1.83], [2.35], [4.83], [1.25], [1.39], [1.24], [0.82], [0.88], [2.55], [1.76], [1.53], [3.33], [-0.39], [3.3], [4.35], [2.48], [3.24], [4.92], [3.77], [3.46], [2.75], [0.51], [2.61], [5.46], [5.87], [-2.1], [1.44], [1.28], [1.63], [5.29], [2.65], [1.45], [2.19], [2.87], [2.82], [1.06], [2.68], [3.56], [-0.1], [1.2], [0.56], [3.69], [0.42], [1.47], [3.82], [2.54], [2.16], [4.1], [3.5], [0.47], [2.63], [1.87], [0.47], [0.95], [2.27], [3.4], [2.03], [-2.84], [2.7], [1.55], [0.26], [0.12], [0.76], [6.29], [2.38], [2.58], [3.16], [0.26], [1.28], [5.08], [1.1], [1.69], [3.38], [2.83], [1.3], [0.3], [1.07], [2.21], [-0.03], [2.09], [0.78], [0.81], [2.24], [2.61], [2.9], [0.99], [0.89], [1.71], [-0.47], [1.82], [1.67], [2.1], [-1.5], [-0.44], [-0.66], [2.5], [2.9], [1.07], [2.83], [3.28], [1.25], [5.45], [3.73], [2.19], [-0.11], [2.87], [1.29], [3.02], [0.5], [1.5], [2.6], [-0.15], [1.11], [-0.75], [2.08], [1.25], [1.35], [-0.47], [4.38], [0.62], [1.4], [1.4], [5.14], [3.65], [1.11], [1.84], [1.47], [3.16], [2.24], [7.73], [4.29], [-0.12], [1.65], [0.69], [1.66], [0.85], [3.69], [2.33], [1.46], [3.27], [2.18], [1.02], [3.24], [5.2], [2.4], [3.08], [2.95], [1.4], [0.26], [2.14], [1.79], [0.92], [-0.73], [-1.57], [2.84], [3.65], [-0.5], [3.61], [2.99], [0.48], [1.63], [0.51], [1.14], [1.19], [2.9], [4.33], [2.01], [1.8], [0.3], [2.64], [2.61], [2.08], [0.66], [0.41], [3.16], [1.32], [3.3], [0.16], [2.85], [5.33], [0.32], [3.44], [2.96], [0.65], [-0.29], [1.39], [2.86], [0.2], [1.4], [7.1], [3.61], [4.43], [-0.35], [4.97], [0.52], [0.83], [2.32], [1.74], [0.89], [1.88], [0.97], [-1.01], [0.91], [7.17], [1.35], [1.72], [6.58], [0.93], [2.23], [4.42], [3.7], [2.33], [0.87], [3.06], [2.4], [3.2], [2.92], [1.82], [1.3], [1.89], [2.98], [3.85], [3.52], [5.2], [1.51], [2.4], [5.55], [1.98], [0.11], [2.3], [3.41], [1.17], [1.7], [0.83], [3.44], [2.63], [3.55], [-0.94], [1.24], [1.72], [4.27], [0.83], [0.79], [2.22], [1.08], [-0.57], [4.61], [2.8], [2.04], [1.56], [2.25], [1.18], [1.36], [3.09], [0.84], [-1.85], [-1.09], [-0.17], [1.96], [0.24], [1.63], [0.89], [0.04], [-0.57], [0.3], [3.15], [1.1], [1.46], [2.54], [-1.96], [4.09], [1.57], [4.37], [0.62], [0.47], [2.49], [4.58], [3.5], [2.1], [1.8], [2.29], [2.23], [4.02], [2.68], [3.19], [0.63], [1.76], [2.58], [6.51], [3.66], [0.26], [0.96], [2.46], [1.05], [3.78], [1.55], [-1.01], [2.15], [2.74], [-1.29], [-1.55], [1.64], [1.95], [-0.46], [3.6], [-0.32], [1.17], [-0.01], [0.75], [1.02], [-0.63], [1.11], [2.57], [2.01], [0.31], [6.98], [2.6], [3.12], [1.58], [2.89], [2.47], [1.61], [-1.64], [1.4], [1.34], [2.9], [0.76], [2.62], [0.82], [-0.32], [2.92], [0.33], [0.36], [2.67], [4.2], [3.29], [3.38], [0.07], [3.2], [1.87], [-0.8], [6.13], [-2.09], [3.82], [-0.01], [-0.06], [1.92], [2.45], [2.12], [0.07], [5.75], [1.29], [1.46], [1.96], [2.99], [5.06], [2.34], [0.4], [3.96], [4.3], [2.32], [1.89], [0.4], [4.9], [2.61], [0.95], [1.63], [6.06], [0.98], [1.09], [4.58], [3.61], [3.61], [3.61], [1.93], [0.82], [1.18], [2.84], [1.03], [3.08], [0.92], [1.32], [0.72], [6.23], [2.22], [3.91], [0.3], [0.83], [0.84], [-1.94], [-1.48], [1.43], [1.74], [2.65], [1.13], [4.72], [2.7], [0.22], [1.68], [3.74], [3.9], [-0.17], [4.78], [2.07], [1.6], [-0.19], [-1.7], [0.66], [4.62], [3.13], [1.38], [2.3], [3.36], [5.71], [0.01], [1.9], [1.94], [2.39], [-0.02], [4.27], [1.77], [2.15], [-0.54], [3.57], [1.7], [-0.28], [1.22], [1.63], [-1.3], [1.35], [2.41], [1.3], [2.89], [1.04], [2.24], [-2.65], [2.82], [2.0], [2.86], [3.34], [3.6], [-1.95], [0.84], [5.45], [3.1], [-2.07], [3.27], [3.94], [1.27], [2.96], [1.73], [3.48], [2.98], [1.45], [2.34], [2.35], [1.82], [-1.07], [-1.33], [1.29], [0.85], [-1.4], [2.75], [3.3], [2.65], [3.66], [1.46], [1.66], [0.67], [1.6], [2.47], [0.95], [4.04], [4.12], [2.0], [-0.04], [4.4], [2.16], [2.1], [1.56], [1.29], [3.5], [1.78], [1.56], [0.76], [6.34], [5.31], [1.55], [1.84], [5.57], [1.83], [3.13], [1.7], [3.14], [2.16], [-1.5], [-0.94], [2.84], [0.44], [4.61], [2.3], [7.4], [0.76], [2.1], [2.69], [1.16], [3.5], [3.05], [2.91], [0.18], [2.22], [0.59], [4.94], [2.1], [0.47], [-0.4], [0.84], [-1.42], [3.1], [1.52], [3.62], [6.25], [0.36], [0.81], [3.82], [2.64], [2.69], [2.35], [3.56], [1.49], [5.83], [1.71], [3.93], [1.53], [4.5], [1.83], [3.47], [6.35], [5.36], [0.82], [6.36], [0.77], [-2.89], [1.59], [-1.47], [-0.08], [3.16], [5.96], [7.02], [0.57], [2.53], [4.29], [2.12], [-0.15], [1.77], [4.13], [2.88], [1.16], [2.85], [3.11], [6.36], [3.2], [1.1], [2.68], [5.73], [0.98], [1.68], [1.34], [0.28], [2.81], [3.4], [-0.32], [-0.59], [3.42], [1.3], [-1.42], [2.99], [2.38], [1.8], [0.97], [3.27], [3.69], [4.02], [5.55], [2.12], [0.88], [-1.21], [1.59], [2.81], [1.98], [5.97], [-0.8], [2.59], [5.65], [0.65], [2.45], [1.53], [0.61], [2.04], [3.63], [2.54], [1.42], [1.81], [3.56], [2.49], [5.41], [6.24], [5.39], [0.94], [3.31], [-0.29], [3.82], [0.01], [1.63], [4.39], [0.75], [1.75], [0.8], [2.23], [0.83], [2.13], [4.25], [0.63], [2.86], [3.87], [1.56], [1.64], [0.68], [2.63], [1.21], [7.0], [4.51], [0.33], [2.12], [3.78], [-0.04], [0.2], [5.3], [1.99], [6.09], [0.15], [0.56], [6.36], [1.96], [4.41], [3.45], [6.79], [-4.22], [2.43], [6.3], [0.88], [3.06], [3.57], [-2.0], [1.14], [4.5], [1.3], [3.37], [1.71], [3.78], [2.45], [3.25], [0.02], [0.99], [1.3], [1.44], [1.73], [1.7], [1.72], [-1.01], [3.92], [3.09], [-0.33], [0.68], [1.79], [-0.02], [9.36], [-0.06], [1.75], [0.44], [2.31], [0.85], [2.08], [1.94], [4.44], [2.98], [0.69], [-0.04], [3.02], [4.82], [4.3], [3.89], [3.69], [4.05], [0.34], [4.25], [2.0], [-2.04], [3.09], [1.45], [0.48], [-0.04], [1.43], [-1.82], [-0.91], [0.9], [1.83], [4.81], [4.1], [1.31], [-2.04], [1.27], [6.46], [2.88], [-0.03], [1.88], [3.65], [1.33], [2.17], [2.32], [2.48], [-2.1], [1.87], [1.6], [2.06], [0.3], [6.17], [1.64], [5.81], [-0.11], [6.28], [1.74], [2.16], [0.1], [1.24], [7.3], [3.03], [0.23], [1.75], [3.25], [2.53], [4.27], [2.46], [0.65], [1.5], [1.65], [1.89], [2.43], [-0.64], [2.95], [2.74], [1.08], [1.35], [0.34], [3.87], [2.85], [1.73], [0.78], [2.57], [3.34], [3.23], [0.65], [6.22], [2.3], [1.73], [1.29], [2.11], [1.86], [0.93], [3.48], [3.1], [0.78], [2.31], [1.46], [0.2], [1.76], [0.46], [2.04], [3.74], [1.9], [2.8], [-0.56], [0.24], [1.76], [0.27], [5.76], [0.08], [1.21], [0.68], [1.36], [2.94], [1.61], [3.01], [1.78], [0.47], [7.11], [0.6], [1.9], [0.62], [4.0], [1.98], [0.79], [-0.3], [2.9], [1.85], [4.16], [5.26], [4.57], [1.28], [4.96], [1.27], [2.48], [2.86], [0.33], [1.8], [1.76], [4.24], [3.52], [0.3], [-1.4], [3.11], [-0.13], [1.45], [1.21], [0.56], [1.27], [2.46], [7.25], [7.44], [-0.16], [4.4], [1.56], [1.61], [2.57], [2.99], [-2.0], [4.61], [3.1], [3.86], [0.16], [1.73], [2.15], [2.75], [4.2], [2.82], [1.37], [1.53], [2.41], [1.27], [4.1], [3.11], [3.82], [1.95], [1.29], [1.83], [0.98], [3.04], [2.23], [1.04], [0.68], [-3.89], [0.24], [1.26], [0.79], [0.5], [2.54], [-2.05], [1.08], [2.19], [2.68], [-0.59], [7.1], [2.75], [0.24], [-1.04], [3.57], [0.32], [-0.11], [5.76], [2.77], [4.58], [1.61], [5.67], [0.87], [5.21], [1.56], [2.18], [1.59], [2.8], [2.89], [2.04], [0.49], [2.82], [1.88], [3.51], [2.18], [0.92], [2.18], [1.72], [4.7], [3.68], [0.87], [0.53], [5.03], [2.94], [3.76], [2.29], [0.92], [2.38], [3.25], [2.54], [4.26], [3.6], [1.14], [2.97], [-2.34], [0.33], [0.78], [2.88], [3.57], [0.71], [1.1], [-1.0], [2.41], [-0.66], [0.56], [1.73], [1.07], [3.47], [0.27], [4.82], [2.42], [3.64], [-0.29], [2.95], [3.3], [-1.66], [2.38], [-0.28], [1.7], [-0.5], [-0.2], [1.83], [-2.01], [1.18], [5.43], [0.17], [2.4], [0.41], [1.24], [3.45], [4.03], [3.82], [3.3], [3.52], [1.7], [4.23], [-0.87], [4.67], [2.86], [3.97], [-1.05], [4.76], [-1.77], [5.08], [0.68], [4.57], [2.44], [1.48], [3.34], [2.03], [2.59], [6.46], [2.49], [3.23], [-0.96], [0.4], [2.84], [2.64], [2.57], [1.23], [2.37], [2.86], [3.0], [6.08], [1.75], [0.57], [1.71], [2.67], [5.18], [-2.78], [5.41], [1.75], [2.54], [0.05], [-0.3], [0.44], [6.2], [1.82], [0.71], [0.75], [3.0], [2.05], [2.48], [4.43], [2.69], [1.93], [1.06], [1.64], [6.09], [2.73], [1.99], [1.21], [1.5], [1.01], [2.56], [0.95], [1.33], [1.8], [1.31], [-0.7], [3.74], [0.35], [4.75], [5.88], [3.38], [0.8], [1.68], [7.44], [0.38], [1.58], [5.48], [1.7], [2.95], [2.09], [3.2], [2.11], [3.09], [2.21], [-0.22], [4.43], [0.71], [1.15], [0.23], [2.04], [2.06], [4.07], [5.23], [1.66], [4.21], [0.42], [3.12], [1.27], [1.11], [6.68], [3.62], [2.28], [-0.26], [3.04], [3.9], [2.03], [-1.58], [1.78], [2.49], [0.86], [2.46], [3.58], [0.73], [2.67], [8.03], [0.91], [4.24], [2.3], [0.32], [3.9], [0.7], [3.14], [2.11], [1.05], [-0.94], [3.11], [4.26], [0.86], [0.55], [-0.04], [2.35], [2.87], [1.87], [2.11], [-0.39], [1.98], [1.95], [2.27], [0.28], [3.65], [0.88], [-0.78], [1.51], [2.27], [2.41], [0.72], [-0.12], [2.34], [2.48], [2.31], [4.42], [-1.02], [1.68], [1.76], [0.17], [4.11], [1.42], [2.33], [5.9], [1.35], [1.65], [-0.67], [0.82], [0.39], [0.71], [0.67], [-1.26], [0.52], [0.36], [2.98], [2.74], [2.18], [4.97], [3.05], [-0.13], [8.2], [3.51], [4.43], [3.18], [2.08], [2.43], [4.12], [-0.05], [-0.89], [2.49], [3.4], [0.51], [1.49], [1.71], [5.83], [3.95], [5.07], [3.83], [4.22], [-0.49], [3.72], [-0.37], [3.79], [-0.56], [2.12], [1.46], [2.93], [1.1], [3.11], [-1.71], [3.58], [2.46], [3.49], [2.51], [6.3], [7.13], [2.33], [5.23], [2.96], [1.88], [1.23], [-0.38], [0.95], [4.0], [6.51], [2.89], [2.31], [1.87], [3.21], [3.66], [-1.16], [1.55], [1.15], [2.9], [3.3], [1.28], [0.86], [0.65], [0.56], [0.01], [0.98], [2.92], [3.51], [-0.68], [1.79], [1.47], [3.78], [2.2], [5.49], [2.58], [-0.52], [-0.05], [0.23], [-0.17], [3.33], [2.56], [0.36], [1.91], [-0.2], [4.41], [3.32], [0.57], [3.9], [1.78], [2.0], [0.11], [5.15], [4.56], [6.08], [0.7], [1.9], [5.19], [2.85], [-0.7], [4.25], [2.68], [1.49], [4.9], [1.73], [5.07], [-0.61], [3.55], [5.5], [3.08], [2.52], [1.65], [4.3], [2.89], [1.42], [5.09], [-0.38], [0.62], [4.21], [4.1], [0.65], [0.29], [-2.0], [1.9], [4.91], [8.65], [0.45], [3.78], [2.23], [6.8], [0.63], [1.83], [1.76], [5.78], [4.32], [4.46], [4.3], [3.78], [2.31], [3.12], [1.34], [2.85], [4.91], [3.32], [2.46], [0.95], [6.75], [4.6], [4.52], [1.76], [1.91], [3.89], [0.96], [2.4], [0.35], [2.08], [0.93], [0.77], [2.59], [6.37], [-1.85], [-2.84], [2.71], [1.95], [2.54], [3.17], [5.2], [-1.5], [6.98], [1.29], [0.74], [-1.17], [7.66], [0.66], [-0.04], [6.63], [-0.7], [5.24], [1.84], [-0.85], [3.29], [-0.25], [2.21], [2.75], [0.91], [3.6], [4.75], [0.78], [1.24], [4.31], [1.8], [1.13], [0.83], [0.71], [4.44], [-1.16], [1.43], [1.34], [0.41], [-0.42], [-0.04], [2.45], [2.89], [3.31], [0.51], [3.62], [2.73], [0.82], [1.33], [1.43], [0.65], [-0.8], [1.29], [2.45], [0.89], [1.9], [2.1], [6.53], [3.34], [0.66], [3.8], [2.68], [-1.0], [2.9], [1.6], [1.68], [6.31], [1.04], [1.8], [4.19], [0.28], [4.1], [-0.72], [0.6], [4.02], [3.65], [0.18], [0.73], [-0.71], [3.26], [0.1], [0.9], [0.79], [3.78], [1.12], [2.24], [0.52], [-1.34], [0.85], [0.33], [-1.11], [0.93], [0.76], [4.61], [2.59], [2.31], [0.65], [3.0], [5.2], [1.61], [3.35], [1.04], [3.75], [2.6], [6.28], [0.75], [1.84], [0.93], [2.73], [-1.33], [1.98], [7.05], [-0.4], [6.22], [-0.44], [2.01], [0.17], [-0.7], [3.55], [-0.24], [0.17], [1.56], [1.39], [3.93], [-0.11], [3.4], [3.37], [1.83], [4.14], [1.17], [2.01], [0.9], [6.8], [-0.87], [3.58], [1.05], [1.73], [4.45], [0.9], [2.79], [0.02], [2.16], [0.31], [1.03], [1.24], [1.23], [3.12], [5.2], [3.51], [1.5], [1.85], [1.34], [5.52], [2.35], [0.61], [3.6], [1.77], [3.39], [-0.66], [3.9], [1.64], [3.14], [0.33], [2.54], [7.53], [5.15], [2.9], [3.72], [2.48], [0.7], [2.09], [3.08], [0.46], [0.83], [1.6], [3.16], [1.55], [3.67], [0.95], [1.54], [5.78], [-0.15], [3.2], [1.24], [1.28], [-0.52], [2.84], [1.57], [4.16], [1.96], [2.04], [2.22], [3.41], [2.4], [2.7], [0.72], [4.42], [4.37], [2.82], [1.18], [2.79], [3.17], [-0.63], [1.15], [0.0], [1.64], [4.28], [1.2], [2.19], [2.52], [2.23], [2.11], [4.0], [4.64], [4.62], [4.94], [2.03], [0.57], [5.92], [3.45], [1.93], [0.53], [2.46], [-0.6], [3.53], [3.02], [1.58], [5.7], [1.69], [2.28], [2.24], [2.18], [3.15], [0.54], [2.22], [-2.05], [3.83], [3.93], [-0.68], [4.47], [1.09], [3.9], [-0.34], [1.69], [5.23], [1.3], [1.82], [-1.03], [2.78], [3.32], [3.65], [4.76], [-2.98], [4.02], [1.78], [1.85], [2.17], [4.8], [2.85], [-0.88], [6.15], [1.51], [2.65], [2.49], [-0.11], [2.64], [2.64], [1.59], [7.55], [4.58], [2.59], [2.59], [-0.41], [0.49], [2.91], [2.18], [2.08], [0.89], [2.52], [2.16], [4.48], [4.85], [1.94], [3.21], [2.8], [-2.46], [2.06], [-0.37], [2.14], [0.08], [1.13], [-0.74], [6.17], [3.31], [2.11], [7.64], [2.43], [0.51], [4.5], [0.83], [3.15], [5.7], [0.56], [0.31], [4.05], [-0.54], [4.06], [1.73], [0.97], [2.44], [3.8], [2.74], [1.22], [2.21], [0.95], [3.41], [0.51], [2.45], [0.42], [-0.88], [3.61], [2.15], [0.56], [2.88], [5.35], [1.6], [0.58], [4.33], [3.06], [1.64], [1.15], [2.2], [1.85], [0.92], [3.03], [-1.98], [-0.22], [1.89], [0.83], [-0.17], [3.22], [1.49], [0.54], [1.74], [-2.67], [-0.07], [2.68], [2.19], [2.16], [4.82], [1.76], [4.16], [1.63], [7.2], [-0.58], [2.72], [4.44], [1.58], [1.94], [2.18], [2.72], [1.59], [4.6], [2.52], [1.91], [3.72], [3.29], [6.38], [1.55], [2.11], [4.25], [2.1], [2.6], [-3.24], [1.34], [1.58], [1.88], [4.8], [-0.13], [1.53], [0.29], [1.4], [3.8], [-0.68], [2.86], [1.33], [0.06], [-1.02], [1.93], [4.3], [4.34], [0.14], [0.62], [-0.2], [3.64], [1.19], [2.69], [4.02], [5.25], [3.87], [3.28], [3.95], [3.16], [1.82], [2.11], [1.98], [3.48], [2.75], [2.42], [0.66], [3.38], [0.41], [0.57], [3.72], [-2.33], [0.2], [5.0], [2.42], [4.68], [1.97], [3.5], [1.53], [2.26], [3.69], [1.9], [8.5], [1.65], [2.08], [1.7], [-0.31], [2.12], [2.44], [1.5], [1.18], [1.97], [4.47], [2.15], [3.29], [-0.6], [3.49], [0.39], [4.8], [1.0], [2.27], [1.4], [1.48], [1.31], [4.76], [0.2], [3.48], [3.63], [-1.0], [1.85], [3.35], [2.23], [1.92], [3.43], [0.23], [1.16], [0.86], [3.8], [-1.0], [1.47], [3.14], [0.78], [4.08], [-0.31], [2.47], [2.9], [3.48], [-3.07], [1.71], [4.3], [2.91], [2.67], [2.16], [3.92], [4.64], [-0.07], [-0.26], [2.81], [-0.06], [-0.63], [3.08], [2.11], [0.65], [-0.28], [4.31], [3.61], [1.46], [2.41], [3.54], [3.01], [0.5], [1.1], [0.21], [2.05], [5.85], [2.02], [3.9], [2.53], [0.5], [4.34], [1.0], [-0.24], [0.49], [2.09], [1.09], [4.8], [2.74], [3.7], [1.89], [2.19], [1.77], [1.09], [0.82], [-0.05], [-0.28], [-0.66], [2.35], [3.85], [2.1], [2.13], [-0.76], [2.75], [0.98], [3.89], [5.59], [1.16], [1.45], [6.58], [0.0], [1.74], [0.34], [2.29], [6.25], [5.95], [1.3], [1.02], [3.5], [3.52], [1.24], [2.4], [0.47], [1.89], [-1.43], [1.3], [0.91], [1.66], [-0.38], [3.15], [2.92], [5.16], [2.26], [4.1], [4.8], [2.82], [1.81], [3.55], [-1.55], [2.62], [4.25], [3.06], [1.24], [5.01], [-0.03], [2.01], [8.46], [3.82], [2.47], [1.14], [-0.13], [2.68], [4.59], [1.99], [2.49], [3.88], [-3.21], [3.07], [-0.05], [3.69], [0.51], [1.88], [1.78], [0.39], [2.02], [2.7], [3.96], [1.97], [0.75], [1.89], [2.98], [2.05], [2.46], [2.62], [2.16], [0.84], [2.81], [0.6], [1.26], [5.5], [3.0], [3.6], [2.67], [3.43], [-0.12], [-0.49], [1.8], [0.2], [1.8], [1.2], [5.08], [2.78], [4.85], [1.39], [1.39], [1.19], [-0.6], [3.97], [1.32], [3.52], [-0.09], [3.91], [1.31], [0.99], [1.42], [2.92], [1.05], [1.87], [0.33], [0.99], [2.84], [1.69], [4.25], [4.27], [0.17], [4.44], [1.22], [-0.31], [1.87], [5.21], [1.6], [1.47], [3.4], [2.2], [2.53], [2.13], [1.99], [3.5], [1.62], [2.01], [-0.25], [-0.36], [2.68], [4.51], [2.2], [5.46], [1.36], [-2.05], [3.34], [3.35], [5.07], [1.01], [5.72], [2.59], [1.86], [-0.66], [1.84], [0.6], [0.38], [1.81], [1.59], [0.67], [5.47], [1.14], [3.93], [0.73], [1.06], [-1.88], [2.53], [4.7], [1.63], [4.6], [1.8], [1.43], [0.77], [2.86], [2.78], [2.63], [5.78], [3.89], [1.06], [3.26], [4.17], [4.51], [0.28], [4.32], [2.21], [1.82], [3.09], [1.09], [0.38], [1.58], [2.3], [0.56], [3.6], [3.63], [4.79], [1.18], [2.18], [0.6], [3.62], [2.7], [3.26], [1.51], [1.42], [2.37], [3.17], [1.28], [1.08], [3.05], [3.45], [1.1], [7.81], [1.52], [2.82], [2.84], [3.06], [3.37], [5.04], [2.25], [4.4], [4.86], [1.55], [3.75], [1.23], [4.0], [4.47], [7.54], [1.11], [1.6], [0.9], [-1.33], [0.82], [3.74], [6.2], [2.15], [7.07], [3.98], [1.0], [2.63], [1.18], [3.56], [1.26], [1.79], [2.03], [2.87], [1.57], [1.76], [0.58], [5.86], [6.84], [2.28], [2.14], [0.3], [1.78], [3.42], [4.83], [2.24], [3.13], [0.48], [4.3], [-0.47], [4.65], [1.02], [3.04], [0.77], [-0.14], [5.48], [1.73], [1.44], [3.6], [-0.22], [-0.9], [-2.94], [1.25], [-0.84], [1.25], [3.79], [2.41], [1.81], [3.08], [2.99], [3.04], [0.65], [0.41], [2.64], [7.31], [0.49], [1.24], [-1.22], [2.1], [-0.57], [-0.68], [3.95], [0.55], [4.53], [1.15], [1.78], [1.26], [1.47], [0.08], [2.07], [1.5], [3.45], [4.43], [0.15], [2.01], [1.47], [0.66], [1.41], [2.33], [0.47], [3.58], [1.03], [-0.52], [1.26], [1.99], [0.68], [0.17], [1.54], [2.45], [-2.29], [1.27], [1.88], [2.29], [0.95], [-2.32], [-1.01], [1.5], [6.35], [0.65], [1.64], [3.71], [7.77], [1.94], [4.87], [0.13], [0.85], [0.93], [1.0], [0.22], [6.79], [-0.35], [2.75], [0.27], [-1.53], [2.82], [-0.43], [0.29], [3.19], [3.18], [1.89], [1.54], [0.25], [4.73], [3.53], [4.4], [0.81], [4.8], [1.9], [4.29], [-0.83], [0.76], [2.92], [2.09], [3.2], [5.08], [1.01], [5.58], [0.8], [1.08], [1.47], [1.45], [2.04], [0.6], [3.15], [5.11], [2.6], [1.83], [2.67], [4.3], [0.32], [-1.52], [4.83], [4.77], [2.52], [2.7], [0.89], [2.8], [2.7], [1.28], [2.1], [1.39], [2.93], [-0.25], [-0.46], [4.42], [0.72], [-0.77], [2.97], [2.52], [-1.64], [0.43], [3.0], [2.22], [1.91], [1.23], [1.57], [2.18], [1.82], [1.46], [3.03], [3.72], [2.85], [1.73], [-0.5], [2.44], [3.37], [4.28], [1.57], [2.08], [0.61], [3.0], [1.2], [-1.31], [-1.13], [2.27], [4.01], [0.0], [-0.49], [2.44], [2.69], [1.1], [1.35], [0.7], [4.08], [1.47], [4.17], [4.77], [2.47], [3.66], [2.66], [0.98], [1.82], [5.37], [1.39], [2.15], [0.89], [0.5], [3.67], [2.18], [1.12], [4.97], [1.79], [2.39], [4.81], [4.64], [1.29], [0.75], [0.16], [-3.53], [4.21], [-0.09], [2.19], [2.34], [3.3], [0.08], [0.43], [-0.25], [0.2], [2.68], [0.1], [1.52], [3.66], [4.53], [1.7], [3.69], [-0.97], [4.66], [0.17], [1.13], [2.09], [4.92], [3.35], [2.7], [0.57], [0.78], [3.39], [1.73], [0.41], [0.49], [1.08], [-0.32], [1.88], [2.34], [2.45], [6.82], [1.85], [1.04], [3.36], [1.17], [-0.9], [4.46], [0.01], [0.54], [-1.2], [3.29], [1.92], [1.15], [4.1], [0.29], [4.87], [0.23], [2.17], [0.72], [-1.83], [4.06], [0.47], [0.94], [2.5], [4.31], [2.7], [1.71], [1.69], [1.48], [1.38], [2.54], [3.5], [0.77], [2.34], [2.21], [0.66], [1.43], [1.02], [0.99], [3.25], [1.86], [0.13], [1.8], [3.3], [0.15], [4.2], [0.04], [1.26], [0.74], [-0.22], [0.84], [0.63], [1.96], [1.51], [2.58], [7.2], [1.75], [3.01], [1.19], [1.63], [3.38], [1.82], [4.89], [4.1], [0.56], [0.59], [0.53], [2.48], [0.14], [-1.17], [0.5], [0.78], [2.62], [4.9], [3.54], [5.99], [4.08], [0.03], [3.72], [0.95], [3.2], [1.31], [1.34], [4.66], [0.47], [1.04], [-1.85], [5.67], [7.0], [0.69], [1.49], [3.44], [2.3], [-0.6], [1.29], [1.8], [1.35], [2.42], [3.52], [1.28], [0.15], [1.58], [-1.89], [0.82], [2.3], [1.91], [4.55], [1.59], [2.55], [-1.15], [-2.82], [4.73], [4.17], [-0.79], [-0.96], [0.51], [-2.05], [-0.45], [3.83], [1.3], [0.03], [1.49], [3.89], [0.77], [0.12], [4.17], [3.8], [1.21], [1.28], [1.01], [2.03], [0.8], [6.54], [2.95], [1.76], [0.74], [5.0], [1.24], [3.95], [-0.38], [2.6], [7.26], [1.9], [1.32], [4.85], [5.81], [2.43], [2.31], [2.24], [2.08], [2.08], [2.07], [0.71], [-0.45], [4.2], [3.5], [1.4], [5.07], [4.8], [4.45], [-1.05], [1.08], [5.07], [2.32], [1.76], [1.51], [1.02], [2.16], [2.04], [1.28], [0.86], [8.2], [2.71], [2.71], [4.0], [-0.82], [0.64], [1.73], [1.6], [5.67], [2.33], [4.63], [3.39], [4.01], [-0.06], [2.18], [0.99], [4.48], [2.94], [5.34], [5.45], [0.09], [2.87], [4.55], [-1.86], [0.06], [-1.47], [2.82], [4.26], [2.4], [1.35], [0.48], [-0.07], [1.31], [1.83], [0.42], [2.8], [5.96], [4.04], [2.02], [0.97], [2.49], [1.42], [0.78], [1.7], [3.08], [2.51], [3.28], [3.2], [2.7], [7.59], [1.98], [2.59], [-0.9], [7.15], [-0.57], [1.44], [2.23], [4.88], [2.83], [4.31], [0.84], [2.84], [1.83], [-3.05], [4.78], [5.01], [2.1], [1.8], [-0.63], [1.65], [2.88], [3.15], [6.8], [-0.04], [-0.5], [1.85], [4.27], [1.18], [2.36], [3.8], [0.46], [1.17], [5.33], [2.02], [0.48], [2.67], [0.08], [0.36], [2.15], [-0.2], [3.28], [4.34], [5.23], [3.0], [-0.6], [2.98], [1.4], [8.16], [3.75], [0.1], [4.14], [1.5], [0.9], [3.02], [-0.03], [2.44], [3.43], [2.47], [-0.49], [6.02], [1.94], [2.24], [4.11], [4.44], [1.1], [1.47], [3.84], [3.27], [4.42], [0.56], [1.69], [-3.41], [5.34], [-0.67], [5.9], [2.02], [4.7], [4.97], [0.39], [1.01], [4.17], [6.26], [2.39], [1.11], [2.24], [1.96], [4.42], [0.87], [9.29], [2.11], [2.46], [2.7], [0.91], [3.28], [-0.77], [2.86], [5.19], [3.92], [1.6], [5.58], [-0.78], [0.15], [-0.14], [0.68], [3.64], [4.27], [1.24], [4.15], [2.12], [2.4], [4.02], [0.35], [1.01], [3.21], [3.78], [1.83], [2.5], [2.8], [6.8], [1.15], [2.33], [3.42], [4.57], [1.33], [3.2], [4.69], [9.07], [2.3], [0.48], [3.34], [4.4], [0.76], [3.19], [0.44], [2.7], [2.09], [3.34], [3.29], [-1.08], [2.24], [1.39], [-0.55], [-0.63], [1.78], [-1.61], [4.22], [1.36], [2.64], [5.66], [2.85], [3.06], [3.04], [1.7], [0.51], [2.11], [5.51], [0.24], [1.78], [1.38], [0.28], [4.48], [0.54], [1.56], [1.99], [0.66], [-2.6], [7.32], [0.35], [4.36], [3.6], [1.24], [7.62], [2.89], [2.83], [5.31], [4.55], [4.66], [-0.46], [1.93], [1.44], [1.19], [1.65], [2.65], [6.66], [1.59], [3.36], [1.11], [3.18], [2.41], [-0.35], [3.56], [1.11], [-0.31], [-0.77], [3.99], [3.07], [1.44], [1.18], [1.98], [-1.56], [0.84], [4.85], [1.55], [3.09], [1.07], [3.47], [3.2], [4.55], [1.94], [1.65], [5.7], [4.47], [2.61], [4.94], [9.29], [4.99], [0.42], [3.22], [-1.25], [0.73], [-0.14], [2.16], [2.19], [-1.8], [3.0], [1.72], [0.37], [1.0], [1.13], [4.4], [4.16], [3.32], [3.02], [0.31], [2.94], [5.65], [4.46], [-0.9], [3.74], [1.54], [0.57], [1.87], [2.01], [3.11], [-0.31], [4.81], [2.78], [2.32], [0.17], [-0.21], [2.8], [3.18], [2.29], [3.72], [0.83], [2.35], [1.89], [0.7], [4.3], [1.86], [5.01], [2.55], [1.18], [2.59], [3.0], [-1.4], [2.86], [1.34], [2.09], [-1.32], [6.83], [5.0], [4.31], [1.14], [2.4], [-0.16], [2.99], [4.37], [3.27], [4.3], [2.27], [1.04], [-2.14], [1.95], [3.92], [4.03], [2.48], [3.4], [1.98], [-0.49], [3.67], [1.25], [-0.35], [3.26], [3.55], [0.36], [-0.2], [2.46], [0.24], [2.03], [1.24], [2.7], [3.23], [2.72], [5.1], [0.66], [0.98], [1.59], [0.22], [1.6], [2.16], [0.45], [-0.92], [2.3], [3.32], [2.91], [0.93], [1.88], [1.81], [0.69], [-0.83], [-0.57], [0.14], [2.36], [1.58], [0.87], [3.78], [0.43], [4.7], [3.51], [1.0], [3.77], [4.9], [1.03], [1.1], [3.14], [0.33], [1.28], [2.63], [3.2], [2.34], [3.66], [0.54], [-0.49], [2.12], [0.18], [3.67], [2.88], [2.83], [1.84], [0.28], [3.17], [7.63], [0.97], [2.48], [3.49], [1.92], [1.59], [1.37], [0.55], [0.39], [2.1], [3.42], [2.32], [1.74], [1.16], [2.53], [0.4], [6.22], [4.6], [3.83], [0.94], [0.35], [2.53], [1.63], [2.09], [1.37], [4.51], [-0.37], [4.69], [2.14], [0.01], [0.93], [-0.28], [1.41], [3.09], [0.38], [3.4], [-0.22], [1.74], [0.69], [1.98], [-2.72], [1.09], [4.82], [2.95], [1.27], [2.82], [5.49], [-0.85], [3.48], [1.55], [1.67], [5.0], [4.4], [3.13], [-1.17], [1.51], [3.27], [1.23], [1.81], [1.36], [2.38], [2.62], [2.33], [1.66], [-1.58], [2.76], [3.34], [2.0], [2.24], [3.2], [1.36], [6.1], [2.15], [2.67], [0.02], [1.27], [4.97], [3.83], [3.66], [2.03], [1.83], [-0.02], [-1.87], [0.58], [0.82], [2.56], [-0.13], [2.37], [0.0], [3.11], [1.0], [-0.89], [2.37], [1.52], [1.54], [0.37], [2.51], [4.34], [3.56], [1.07], [2.41], [1.68], [2.55], [1.06], [0.79], [2.9], [4.56], [4.5], [0.35], [-0.16], [2.97], [0.15], [1.9], [3.11], [2.2], [0.0], [4.38], [7.05], [3.31], [-1.4], [3.26], [1.37], [5.65], [-3.64], [1.28], [4.5], [0.11], [1.36], [3.17], [3.53], [2.54], [5.02], [-0.41], [2.87], [2.25], [3.2], [4.19], [1.5], [1.77], [3.05], [0.68], [-0.2], [0.38], [1.45], [0.76], [2.98], [1.29], [3.07], [-0.95], [0.57], [0.12], [0.72], [0.42], [1.73], [3.68], [1.39], [1.42], [-1.3], [3.36], [0.38], [-0.49], [4.15], [2.5], [2.88], [0.53], [1.16], [-1.08], [1.3], [1.83], [3.02], [2.4], [0.4], [1.79], [1.29], [-0.67], [5.82], [0.85], [2.25], [0.37], [1.42], [2.59], [1.46], [3.55], [3.75], [2.59], [0.71], [3.14], [2.53], [3.92], [1.81], [2.68], [0.33], [5.5], [1.67], [2.69], [-0.63], [-1.59], [0.79], [-0.71], [4.53], [1.83], [2.3], [2.56], [1.73], [3.83], [1.12], [5.75], [4.3], [5.18], [1.76], [0.82], [0.39], [4.09], [2.0], [-0.57], [3.15], [3.07], [0.57], [1.5], [1.63], [3.51], [1.42], [4.6], [2.68], [3.91], [2.85], [-0.05], [0.41], [0.86], [-0.04], [2.94], [1.99], [1.49], [2.38], [1.95], [0.55], [0.4], [0.81], [1.4], [3.6], [3.32], [0.58], [-0.04], [2.28], [1.17], [2.14], [5.08], [4.0], [0.74], [0.44], [0.82], [3.55], [4.67], [4.1], [1.27], [1.02], [2.05], [-0.4], [5.86], [3.85], [0.66], [2.72], [2.43], [4.33], [0.67], [3.24], [7.18], [3.26], [1.87], [0.98], [2.88], [1.33], [0.35], [3.73], [-0.84], [-4.0], [0.14], [2.59], [0.16], [4.54], [3.94], [0.24], [5.21], [3.24], [1.96], [-0.21], [1.82], [6.5], [-0.25], [2.2], [0.58], [1.33], [-0.67], [1.79], [2.31], [3.32], [1.58], [1.26], [1.68], [2.44], [7.25], [1.03], [0.58], [3.12], [1.02], [-0.08], [1.6], [0.34], [1.92], [2.4], [2.53], [1.76], [0.58], [3.67], [1.14], [2.1], [2.27], [-0.04], [2.83], [1.4], [6.72], [1.65], [4.2], [2.69], [1.52], [0.81], [5.94], [2.02], [0.73], [2.69], [5.12], [-0.02], [-0.61], [-0.02], [4.73], [2.9], [4.05], [7.21], [4.78], [3.9], [5.35], [2.13], [3.99], [6.67], [0.23], [2.95], [2.9], [4.24], [1.44], [2.47], [4.73], [4.93], [3.5], [0.15], [-0.74], [1.34], [-0.04], [3.42], [3.52], [2.82], [1.92], [2.52], [3.82], [2.51], [6.5], [6.09], [3.74], [-0.39], [6.06], [1.12], [0.45], [2.75], [-0.85], [1.61], [5.22], [-1.9], [1.9], [5.4], [3.12], [1.54], [1.33], [3.23], [0.84], [0.08], [1.41], [4.34], [6.85], [1.39], [1.32], [5.09], [1.86], [-0.05], [2.36], [2.08], [1.5], [0.12], [-1.15], [0.81], [1.99], [3.86], [3.2], [-1.3], [-1.2], [1.34], [3.24], [2.88], [1.27], [1.31], [4.68], [0.52], [2.53], [-0.61], [0.25], [2.61], [1.9], [-1.29], [3.08], [1.72], [4.64], [-0.08], [3.84], [2.29], [0.91], [4.82], [3.08], [1.84], [4.91], [2.32], [-0.34], [1.26], [3.03], [0.45], [3.91], [2.59], [4.58], [1.78], [-1.23], [1.88], [3.85], [1.64], [0.14], [3.58], [2.39], [3.42], [0.49], [0.0], [2.19], [-0.73], [3.21], [2.61], [2.04], [4.14], [2.56], [0.3], [1.3], [4.0], [4.24], [-1.69], [0.65], [0.87], [0.44], [2.64], [1.45], [0.21], [4.37], [4.62], [-0.33], [4.17], [2.92], [3.9], [1.87], [0.91], [4.81], [3.1], [1.58], [1.57], [3.09], [3.16], [1.76], [3.67], [2.43], [0.75], [2.86], [2.94], [-4.43], [1.65], [4.0], [0.3], [-0.3], [3.8], [7.47], [-0.59], [0.57], [3.04], [2.22], [5.16], [1.38], [2.09], [0.19], [-0.17], [4.02], [2.01], [3.24], [1.45], [3.46], [2.67], [1.71], [1.38], [4.0], [0.44], [2.53], [3.51], [2.25], [4.73], [2.58], [0.92], [0.9], [5.2], [1.73], [-0.8], [1.71], [4.76], [3.27], [3.45], [1.04], [1.89], [2.02], [2.76], [5.68], [8.16], [2.5], [3.75], [-1.09], [3.92], [0.73], [4.58], [1.49], [2.21], [0.99], [2.11], [5.83], [0.72], [1.41], [2.14], [-2.55], [2.68], [2.15], [5.34], [3.77], [4.92], [6.52], [-0.38], [2.55], [2.95], [2.55], [1.71], [2.43], [2.44], [1.22], [2.45], [2.17], [2.6], [0.38], [3.12], [1.53], [0.8], [3.8], [2.79], [0.0], [1.74], [4.07], [9.96], [2.79], [5.77], [3.43], [5.89], [3.91], [-0.27], [2.02], [2.25], [2.94], [0.12], [3.63], [5.36], [1.44], [0.39], [-0.22], [3.7], [0.88], [3.74], [1.26], [0.56], [5.1], [1.89], [3.05], [0.5], [-0.7], [0.09], [1.8], [1.96], [1.24], [4.8], [-0.11], [-1.18], [0.93], [2.7], [0.65], [0.68], [-2.42], [-1.43], [-0.43], [6.47], [1.65], [3.05], [3.42], [2.5], [-2.68], [2.85], [1.0], [2.99], [0.54], [-1.4], [0.14], [1.69], [0.75], [-0.1], [-1.3], [3.12], [3.73], [-1.2], [1.29], [2.09], [3.44], [0.74], [2.44], [3.97], [2.15], [4.22], [3.84], [3.03], [2.06], [3.27], [2.46], [5.79], [-0.74], [2.73], [2.89], [-2.2], [1.31], [1.96], [1.65], [2.6], [1.58], [1.12], [0.4], [3.07], [2.67], [2.06], [1.82], [1.59], [6.99], [3.09], [3.27], [3.8], [2.38], [1.73], [-1.87], [3.42], [1.51], [1.21], [0.48], [3.65], [3.96], [3.83], [0.2], [2.92], [0.21], [4.0], [3.4], [1.85], [0.96], [-0.45], [7.46], [2.54], [1.81], [0.69], [4.09], [1.16], [1.86], [1.12], [2.1], [2.13], [0.3], [1.07], [1.79], [1.52], [1.05], [-0.69], [1.7], [3.37], [0.0], [1.47], [3.24], [1.05], [3.36], [2.51], [3.57], [4.24], [-1.08], [3.08], [1.98], [2.8], [-0.27], [1.05], [2.54], [2.92], [2.19], [-1.3], [4.34], [0.25], [2.45], [0.46], [-0.28], [4.09], [3.53], [3.2], [-0.89], [0.41], [3.34], [2.51], [2.77], [1.69], [2.95], [0.53], [3.42], [5.8], [2.64], [4.25], [4.41], [1.11], [0.91], [1.98], [3.6], [0.08], [4.63], [2.0], [0.23], [0.12], [5.62], [3.85], [2.22], [8.06], [-0.4], [0.54], [2.34], [2.73], [4.48], [3.05], [-0.08], [1.85], [8.27], [5.43], [-0.11], [2.74], [-0.72], [1.33], [2.58], [5.26], [2.4], [3.52], [-0.64], [1.28], [1.61], [1.81], [1.08], [3.1], [-0.32], [-2.31], [1.15], [5.72], [0.83], [3.69], [1.91], [2.9], [2.88], [1.54], [3.26], [-1.76], [4.1], [1.37], [4.54], [5.94], [4.97], [0.47], [5.66], [0.87], [1.01], [0.85], [2.2], [1.86], [2.26], [-0.8], [0.54], [1.18], [2.16], [-1.3], [-0.5], [1.09], [2.8], [1.75], [4.8], [1.72], [1.89], [1.56], [4.92], [0.85], [3.33], [1.32], [3.2], [4.39], [1.45], [1.34], [1.85], [1.0], [3.44], [0.8], [0.96], [1.11], [0.67], [1.76], [3.4], [2.25], [3.85], [1.48], [1.06], [-3.09], [1.45], [3.14], [1.2], [1.22], [0.7], [-0.96], [3.21], [0.96], [0.14], [0.85], [-0.7], [5.21], [2.57], [-0.52], [3.77], [3.03], [2.26], [7.11], [5.61], [3.57], [2.9], [3.22], [-0.96], [3.82], [1.6], [3.46], [2.18], [2.4], [2.28], [0.01], [4.75], [2.32], [0.91], [0.71], [0.75], [0.55], [4.94], [0.83], [3.46], [1.63], [5.25], [0.32], [3.0], [0.73], [-0.52], [0.59], [2.74], [2.8], [1.3], [2.64], [1.29], [1.19], [4.67], [1.9], [4.24], [3.06], [-0.67], [2.84], [1.45], [-0.05], [0.42], [4.2], [2.6], [4.77], [4.83], [1.79], [-0.06], [1.37], [-0.9], [1.36], [1.31], [1.44], [2.39], [-1.38], [0.89], [3.8], [4.17], [1.17], [1.93], [3.3], [3.9], [2.93], [-0.11], [0.22], [3.25], [1.72], [2.51], [2.3], [-1.89], [3.01], [1.33], [1.6], [-0.38], [4.37], [1.94], [-2.11], [3.75], [6.64], [4.99], [2.72], [-0.65], [0.06], [2.8], [3.7], [7.11], [0.22], [4.45], [4.15], [-0.21], [3.2], [-0.32], [1.8], [0.81], [1.81], [-1.11], [5.77], [5.69], [0.73], [-0.15], [4.38], [0.24], [0.97], [2.41], [3.57], [0.52], [-0.34], [0.06], [3.39], [4.25], [1.4], [2.52], [1.24], [1.41], [2.99], [2.57], [4.52], [1.21], [1.46], [0.86], [1.42], [-1.89], [1.33], [4.16], [0.26], [3.85], [1.4], [-0.01], [1.38], [1.65], [3.28], [0.56], [3.03], [0.63], [5.91], [1.62], [1.51], [0.11], [-0.52], [1.21], [0.7], [3.17], [1.84], [0.76], [9.3], [2.56], [1.7], [3.05], [0.58], [2.45], [0.87], [0.64], [1.92], [0.3], [2.53], [2.13], [0.85], [2.24], [0.96], [1.33], [2.7], [0.43], [1.88], [0.36], [1.77], [1.14], [-0.35], [1.82], [2.83], [-0.07], [3.58], [-0.17], [1.56], [1.96], [3.2], [1.65], [1.22], [4.48], [0.04], [1.04], [1.33], [3.55], [2.62], [0.64], [1.65], [7.63], [3.75], [-1.22], [1.33], [2.0], [3.3], [1.75], [0.86], [6.2], [1.87], [3.64], [2.69], [1.32], [2.15], [-0.55], [0.9], [1.61], [4.38], [0.0], [1.57], [2.45], [2.86], [2.56], [-1.54], [0.2], [-1.25], [2.17], [1.97], [3.66], [1.62], [0.53], [3.14], [3.68], [1.48], [1.12], [2.9], [3.91], [2.45], [-1.14], [5.78], [2.57], [1.25], [0.72], [-0.27], [3.73], [0.2], [3.63], [4.28], [0.36], [2.93], [-0.02], [1.39], [6.67], [1.05], [0.99], [5.51], [2.71], [1.02], [1.2], [1.65], [-0.74], [-0.92], [3.96], [2.82], [3.72], [0.4], [1.53], [3.86], [3.99], [1.63], [3.9], [4.47], [3.05], [3.28], [5.53], [1.31], [3.32], [2.65], [3.3], [0.87], [1.49], [2.03], [1.52], [3.88], [0.47], [-0.67], [0.84], [2.59], [2.06], [1.9], [1.89], [1.18], [5.18], [0.61], [2.95], [2.81], [2.42], [2.52], [3.89], [1.99], [2.76], [6.51], [4.8], [0.97], [3.92], [5.05], [1.96], [1.45], [1.79], [2.66], [3.09], [2.3], [0.66], [1.36], [1.7], [1.89], [-0.14], [2.6], [2.85], [2.21], [2.84], [1.91], [3.42], [1.87], [2.29], [6.2], [2.06], [3.3], [0.92], [-1.39], [0.37], [3.92], [3.61], [2.61], [1.26], [1.55], [4.88], [0.91], [1.62], [4.66], [0.74], [2.31], [1.18], [2.19], [0.11], [0.74], [2.45], [3.58], [3.45], [4.01], [2.61], [4.43], [-0.94], [1.16], [2.16], [1.46], [2.36], [0.75], [2.67], [5.75], [2.29], [0.97], [3.08], [0.99], [2.7], [3.68], [0.06], [2.17], [2.39], [-0.28], [1.96], [1.8], [6.13], [3.39], [7.83], [-0.55], [3.95], [2.45], [2.47], [1.7], [0.4], [3.08], [3.04], [1.76], [1.8], [2.48], [2.29], [-3.02], [1.76], [2.38], [5.38], [3.73], [-0.62], [5.2], [2.03], [0.62], [2.15], [2.13], [3.25], [1.85], [-0.02], [0.62], [-0.1], [3.87], [3.63], [0.69], [-0.39], [6.42], [3.28], [1.24], [3.2], [1.37], [1.4], [3.11], [2.46], [1.08], [2.91], [0.99], [1.89], [0.06], [2.8], [5.32], [2.51], [2.76], [-0.94], [1.9], [1.61], [1.6], [4.42], [3.2], [2.06], [2.37], [1.12], [1.95], [8.65], [2.0], [3.86], [1.7], [-0.74], [5.07], [-0.61], [-2.4], [-0.27], [0.27], [1.58], [4.48], [3.47], [1.14], [4.51], [-0.2], [-1.3], [1.44], [1.14], [2.91], [1.1], [3.23], [1.82], [0.98], [1.07], [1.7], [3.44], [1.01], [1.01], [0.31], [3.7], [2.59], [0.49], [3.4], [4.25], [2.78], [-0.19], [0.81], [1.84], [3.27], [3.2], [1.59], [2.78], [0.96], [4.73], [0.98], [3.36], [2.98], [0.03], [3.85], [1.63], [4.81], [2.33], [0.27], [2.34], [0.63], [2.82], [4.54], [0.83], [3.83], [5.85], [2.21], [2.88], [5.17], [1.63], [2.07], [-2.27], [1.31], [1.2], [-1.14], [0.4], [5.5], [-0.92], [0.87], [8.19], [6.11], [1.83], [-2.0], [-1.59], [4.26], [0.16], [-0.83], [1.24], [3.78], [3.15], [0.74], [0.96], [1.82], [3.56], [3.47], [1.59], [3.65], [2.29], [2.63], [2.04], [2.52], [4.68], [2.42], [4.73], [2.22], [3.82], [0.3], [1.14], [8.77], [3.35], [0.7], [2.2], [3.13], [3.72], [2.96], [3.62], [1.57], [8.38], [5.39], [1.0], [0.15], [4.28], [2.06], [1.75], [1.03], [0.23], [1.64], [3.87], [0.38], [2.42], [-0.32], [1.59], [5.31], [1.51], [2.47], [1.73], [0.84], [4.49], [-1.54], [1.98], [0.62], [0.3], [2.97], [1.19], [-1.85], [1.55], [2.22], [3.91], [-2.07], [0.0], [4.48], [5.52], [-0.89], [0.97], [2.47], [0.5], [0.38], [-0.28], [3.76], [1.9], [-1.05], [2.3], [6.72], [-0.86], [-1.07], [4.17], [0.41], [-1.18], [2.5], [2.22], [0.78], [1.15], [3.49], [4.21], [0.83], [4.41], [1.61], [5.1], [-0.36], [2.23], [0.03], [-0.11], [2.04], [6.4], [0.53], [2.55], [-1.38], [4.28], [1.64], [2.21], [3.39], [2.48], [3.04], [2.86], [0.13], [3.24], [3.82], [1.81], [4.9], [0.97], [3.02], [1.41], [4.69], [7.97], [1.96], [3.83], [1.5], [2.25], [0.26], [-2.14], [0.93], [2.18], [2.53], [3.25], [1.75], [3.79], [3.21], [2.0], [0.78], [3.56], [3.21], [-0.42], [4.41], [3.82], [0.23], [3.25], [4.97], [1.24], [6.98], [0.84], [3.34], [3.12], [5.04], [0.98], [2.33], [-0.23], [4.58], [1.78], [5.19], [2.46], [2.21], [1.99], [2.17], [2.59], [-0.09], [2.92], [2.81], [1.81], [3.61], [0.58], [0.66], [1.88], [3.7], [3.69], [-1.35], [0.34], [-1.38], [0.32], [1.14], [6.39], [0.15], [-0.04], [3.15], [3.76], [0.83], [1.6], [1.54], [2.86], [4.27], [1.08], [3.88], [4.45], [2.05], [3.35], [4.2], [1.71], [2.29], [4.19], [0.46], [5.56], [0.48], [0.64], [1.44], [-0.69], [-4.64], [0.33], [0.04], [0.63], [3.2], [0.85], [3.27], [1.55], [3.43], [0.33], [5.06], [0.44], [3.05], [0.67], [2.1], [1.24], [0.76], [1.38], [3.31], [2.53], [5.76], [4.57], [-1.43], [2.09], [0.39], [2.45], [-2.28], [1.5], [3.91], [1.47], [1.38], [1.85], [0.89], [2.61], [4.09], [-2.84], [0.73], [-1.79], [-2.0], [3.4], [2.0], [2.18], [1.33], [4.21], [1.86], [0.34], [2.78], [1.4], [3.23], [2.71], [1.96], [1.75], [1.03], [0.08], [0.24], [2.98], [1.51], [2.14], [3.67], [0.255], [2.23], [-0.33], [1.41], [2.04], [3.08], [4.2], [0.09], [5.49], [3.03], [2.73], [1.29], [2.22], [1.81], [-0.19], [3.78], [2.94], [0.3], [0.59], [3.55], [1.16], [2.44], [1.28], [-0.55], [4.33], [3.41], [5.76], [3.72], [-1.21], [7.17], [-0.06], [-1.6], [4.06], [1.77], [1.6], [4.3], [0.01], [4.55], [1.72], [3.9], [4.33], [1.44], [3.71], [1.89], [2.26], [2.14], [2.88], [0.49], [2.0], [2.4], [4.4], [1.07], [1.39], [2.83], [3.3], [0.04], [2.49], [3.03], [3.8], [1.44], [5.67], [2.07], [0.87], [3.08], [3.13], [2.79], [0.18], [1.58], [1.14], [1.18], [-1.12], [3.35], [0.16], [0.53], [3.0], [1.4], [1.65], [0.52], [6.9], [2.94], [4.34], [4.04], [3.87], [2.61], [-0.36], [2.76], [1.74], [0.95], [-1.22], [1.85], [4.67], [0.33], [1.66], [2.41], [0.97], [-3.31], [1.28], [5.74], [4.45], [3.77], [7.91], [0.44], [1.87], [1.81], [3.44], [-1.88], [1.06], [3.44], [3.74], [-0.08], [0.56], [6.19], [3.41], [1.5], [2.32], [1.34], [-1.14], [0.97], [4.6], [1.41], [2.88], [4.54], [5.5], [2.15], [4.52], [1.17], [2.7], [1.75], [1.88], [4.27], [4.42], [5.51], [4.14], [1.84], [2.64], [5.83], [0.83], [2.18], [1.15], [2.69], [0.16], [0.45], [4.63], [1.96], [0.18], [1.81], [2.36], [1.73], [0.66], [1.76], [2.28], [0.16], [-0.8], [3.71], [2.41], [3.41], [-0.76], [0.9], [0.89], [2.4], [7.07], [-0.36], [2.68], [1.75], [0.101], [3.82], [5.31], [4.18], [0.87], [1.42], [3.69], [4.09], [1.51], [2.2], [2.84], [0.12], [3.16], [2.63], [0.95], [4.48], [2.2], [2.46], [3.05], [2.0], [3.26], [1.52], [1.13], [-0.3], [0.19], [-0.47], [2.27], [0.69], [2.68], [1.26], [-2.13], [5.27], [4.0], [1.12], [7.5], [2.66], [2.3], [0.62], [1.81], [3.73], [5.55], [1.71], [-0.86], [3.39], [0.61], [4.11], [2.92], [1.96], [0.46], [2.19], [-1.45], [2.11], [1.8], [1.66], [7.64], [1.61], [4.06], [2.36], [5.16], [0.42], [1.66], [4.69], [1.43], [1.13], [1.79], [2.73], [1.69], [1.62], [2.36], [3.0], [3.57], [3.51], [1.3], [1.64], [5.13], [-0.69], [5.77], [4.8], [5.14], [5.41], [3.1], [1.0], [2.97], [1.4], [3.1], [1.78], [4.03], [1.73], [3.42], [3.94], [0.89], [1.41], [6.08], [4.93], [2.05], [5.9], [3.4], [0.69], [2.65], [1.16], [0.99], [1.61], [6.58], [2.29], [1.73], [4.8], [0.23], [2.2], [3.12], [4.96], [2.15], [5.24], [0.23], [2.33], [1.21], [-0.06], [4.41], [2.24], [-0.54], [0.5], [2.81], [0.33], [3.45], [3.82], [2.8], [2.75], [5.7], [3.66], [2.68], [0.71], [1.35], [0.59], [8.14], [4.06], [-0.34], [1.76], [0.6], [4.47], [1.53], [4.48], [1.69], [-0.81], [2.37], [4.09], [3.21], [4.07], [-0.48], [2.45], [1.42], [0.4], [2.85], [2.81], [1.09], [1.43], [2.11], [0.17], [3.31], [1.63], [4.53], [-0.47], [1.2], [1.82], [4.44], [0.01], [3.15], [-1.27], [3.05], [0.9], [4.19], [-0.16], [1.4], [6.95], [3.24], [1.82], [2.34], [3.38], [1.8], [4.64], [4.96], [6.12], [2.87], [3.1], [1.49], [2.36], [0.37], [3.15], [0.28], [0.96], [3.27], [3.46], [2.13], [0.74], [-1.15], [1.68], [2.42], [3.61], [1.38], [4.33], [1.7], [-0.59], [5.58], [3.6], [3.81], [2.03], [1.03], [3.43], [2.28], [2.38], [2.5], [1.7], [0.2], [-0.16], [1.54], [4.11], [0.93], [1.86], [2.18], [2.34], [2.41], [6.23], [3.45], [3.51], [0.22], [0.25], [2.26], [3.3], [3.35], [3.86], [1.44], [-2.64], [0.72], [3.15], [2.0], [1.08], [0.42], [1.01], [-0.52], [4.15], [0.46], [3.93], [0.93], [1.82], [-1.51], [3.0], [0.86], [-0.9], [0.36], [7.41], [2.52], [2.03], [-0.66], [-0.24], [3.76], [1.16], [1.34], [2.15], [-0.16], [2.01], [4.53], [0.47], [-0.46], [1.16], [0.41], [0.2], [2.61], [1.1], [5.13], [2.61], [-0.12], [1.86], [-0.15], [0.02], [3.5], [2.35], [3.06], [3.28], [1.22], [4.47], [3.39], [3.28], [2.34], [1.2], [2.91], [1.61], [6.3], [1.85], [2.42], [3.35], [2.8], [1.32], [4.1], [6.5], [6.8], [2.78], [4.3], [4.79], [2.16], [4.22], [2.39], [2.45], [2.22], [-0.6], [1.04], [1.69], [6.78], [4.18], [1.87], [1.8], [2.4], [1.34], [3.1], [-1.52], [2.64], [0.8], [1.96], [6.3], [3.0], [5.5], [1.61], [0.36], [5.85], [6.44], [3.4], [3.89], [3.03], [3.97], [2.67], [0.76], [-1.38], [2.31], [-0.03], [2.72], [1.03], [3.26], [3.67], [1.63], [0.9], [-2.16], [3.06], [4.25], [2.07], [2.76], [1.75], [3.42], [2.52], [0.11], [2.33], [1.52], [1.94], [0.28], [1.01], [7.37], [5.55], [-1.08], [3.14], [4.64], [1.86], [2.4], [1.21], [1.13], [4.9], [2.88], [2.49], [0.35], [0.85], [-0.41], [0.79], [2.88], [0.33], [1.43], [2.18], [1.88], [2.61], [2.23], [6.0], [1.79], [2.96], [1.12], [1.2], [3.63], [4.63], [2.67], [0.2], [3.12], [3.53], [7.01], [4.24], [3.11], [-0.04], [2.79], [5.2], [-1.71], [2.82], [-2.52], [3.8], [2.6], [2.01], [-0.92], [4.66], [2.55], [1.02], [0.31], [0.12], [1.12], [0.91], [3.99], [2.5], [2.85], [2.75], [1.34], [2.95], [-0.9], [2.25], [2.05], [1.26], [0.89], [3.54], [4.45], [3.46], [1.33], [1.55], [0.86], [0.37], [1.7], [0.39], [1.29], [1.34], [1.87], [4.1], [2.82], [3.13], [0.83], [4.16], [-0.2], [2.95], [4.52], [0.68], [0.08], [3.96], [2.64], [0.91], [4.24], [-1.11], [2.24], [0.24], [1.47], [0.76], [4.73], [0.12], [1.85], [7.4], [4.35], [5.03], [-1.3], [2.6], [0.54], [2.2], [1.95], [-0.31], [3.02], [-0.87], [1.22], [3.53], [7.84], [-1.2], [1.15], [-1.87], [-0.27], [1.74], [0.89], [2.71], [0.4], [0.51], [2.98], [2.14], [1.81], [2.3], [6.11], [2.06], [1.5], [2.42], [7.04], [3.6], [-0.1], [1.27], [3.41], [2.56], [2.3], [2.9], [1.26], [5.02], [-0.65], [3.72], [-0.3], [2.74], [1.87], [1.59], [1.1], [4.27], [-0.9], [1.6], [1.29], [3.18], [2.85], [1.14], [2.2], [4.4], [2.62], [4.51], [3.32], [0.29], [3.04], [3.27], [1.13], [1.74], [0.9], [0.3], [3.38], [3.5], [-0.42], [-0.99], [1.04], [3.01], [0.58], [1.77], [1.25], [2.68], [5.74], [1.97], [2.73], [1.73], [1.8], [3.37], [2.46], [3.43], [0.6], [2.68], [2.0], [0.86], [3.4], [-0.53], [3.6], [-1.0], [1.74], [4.51], [1.53], [1.79], [1.27], [1.55], [0.65], [-1.7], [0.4], [4.22], [2.71], [1.17], [5.51], [2.32], [3.7], [0.37], [6.65], [-0.38], [2.87], [1.73], [1.19], [2.02], [0.91], [-0.6], [7.28], [2.14], [0.12], [-0.02], [1.62], [3.74], [2.88], [2.06], [7.17], [3.04], [5.49], [5.47], [-0.22], [2.18], [1.34], [-1.1], [3.82], [2.45], [3.89], [-0.35], [1.97], [2.35], [1.87], [3.71], [4.55], [2.85], [0.99], [2.38], [1.55], [3.12], [0.63], [1.4], [3.33], [-0.1], [2.98], [1.41], [1.02], [2.03], [0.52], [2.98], [2.26], [6.61], [-0.43], [1.19], [3.71], [2.53], [0.44], [0.75], [0.31], [0.91], [2.82], [1.1], [3.88], [-0.34], [6.85], [3.58], [0.85], [2.99], [0.69], [-0.64], [-1.56], [2.11], [1.57], [0.84], [1.5], [1.88], [1.05], [1.4], [4.09], [2.57], [4.02], [2.24], [0.27], [2.68], [3.92], [-0.13], [-1.14], [1.57], [2.53], [1.65], [-1.32], [-0.07], [2.18], [-1.03], [2.15], [1.17], [4.56], [1.62], [3.8], [3.18], [0.86], [-1.78], [3.69], [1.77], [5.49], [1.63], [0.94], [0.47], [1.31], [4.6], [2.45], [1.16], [3.98], [5.76], [2.2], [-0.21], [8.06], [1.69], [1.67], [1.1], [2.42], [0.83], [3.05], [2.49], [6.63], [3.79], [1.71], [2.3], [0.05], [2.83], [4.81], [0.95], [2.65], [4.89], [2.6], [3.56], [0.91], [4.5], [1.15], [0.82], [-1.5], [2.1], [1.78], [0.34], [0.94], [4.78], [4.62], [2.51], [-1.07], [3.23], [3.27], [1.28], [0.25], [-0.92], [1.48], [-0.96], [3.7], [2.03], [0.86], [3.14], [0.63], [4.94], [9.07], [3.23], [2.11], [0.63], [1.23], [0.21], [4.2], [3.3], [2.97], [2.71], [-0.74], [1.81], [3.78], [0.75], [3.48], [3.68], [1.78], [3.78], [2.1], [3.79], [3.6], [-0.07], [-1.44], [2.1], [2.96], [0.76], [2.06], [6.3], [3.18], [2.25], [-0.37], [5.73], [1.07], [0.4], [0.46], [2.56], [4.1], [3.95], [3.19], [4.75], [2.41], [-0.49], [1.11], [1.72], [0.35], [1.7], [3.0], [2.17], [0.14], [-0.45], [5.34], [3.81], [1.02], [2.58], [0.41], [0.95], [4.1], [3.27], [5.08], [0.47], [4.34], [0.12], [4.68], [1.77], [2.5], [2.09], [0.2], [1.97], [0.84], [2.42], [2.1], [-0.29], [1.42], [1.87], [2.37], [2.76], [1.4], [3.09], [2.05], [1.98], [4.05], [1.64], [4.99], [4.32], [-3.49], [0.65], [4.05], [-2.8], [4.48], [2.76], [2.31], [1.58], [1.92], [0.32], [-0.4], [5.2], [7.35], [-0.99], [0.98], [3.77], [5.44], [-0.49], [1.13], [4.04], [-0.45], [1.42], [2.04], [0.54], [1.89], [-1.41], [1.0], [2.25], [0.04], [5.28], [5.69], [1.39], [1.31], [3.99], [2.38], [2.62], [1.89], [3.56], [1.03], [1.36], [1.88], [-0.52], [3.19], [2.59], [2.59], [3.31], [0.12], [2.51], [1.13], [1.26], [6.17], [0.0], [3.27], [2.09], [2.61], [0.92], [3.18], [2.03], [1.17], [2.1], [2.37], [3.03], [1.14], [1.48], [2.91], [3.55], [1.96], [5.45], [1.48], [1.92], [0.45], [4.64], [2.4], [1.3], [1.19], [1.91], [2.72], [-0.2], [1.33], [2.29], [-0.37], [3.79], [3.84], [1.36], [0.36], [0.72], [2.48], [-2.28], [1.37], [7.55], [3.0], [2.14], [0.81], [2.26], [0.03], [3.53], [2.03], [0.27], [5.72], [3.0], [0.66], [4.33], [-0.6], [2.48], [4.68], [3.14], [-1.11], [1.39], [4.24], [3.1], [2.84], [2.59], [2.35], [-0.31], [0.72], [-1.59], [2.37], [2.8], [1.27], [2.24], [2.2], [4.11], [1.99], [0.07], [0.96], [0.14], [0.28], [2.47], [1.14], [2.82], [1.18], [1.19], [2.88], [1.64], [2.41], [0.23], [-0.09], [2.9], [-0.07], [4.28], [3.63], [1.58], [2.26], [0.16], [1.86], [0.08], [4.57], [0.33], [0.84], [-0.67], [5.0], [-0.29], [3.33], [1.58], [3.35], [-1.4], [3.18], [4.45], [3.17], [3.09], [3.59], [1.51], [0.53], [-0.4], [1.29], [1.63], [2.64], [0.91], [1.71], [-0.93], [1.18], [2.7], [0.21], [0.32], [0.6], [0.79], [1.2], [2.21], [8.39], [2.25], [2.03], [3.31], [0.77], [1.13], [2.37], [1.25], [3.3], [0.6], [0.51], [2.01], [1.75], [1.04], [4.3], [2.71], [2.64], [2.08], [1.26], [4.35], [2.84], [1.68], [1.16], [1.02], [-0.67], [-0.08], [-3.54], [2.74], [-0.1], [2.8], [0.34], [0.65], [0.93], [0.6], [-0.23], [4.11], [1.46], [1.98], [0.81], [4.7], [2.47], [1.0], [3.17], [0.14], [1.58], [-0.89], [-0.48], [1.59], [-0.53], [2.53], [3.53], [-1.05], [4.3], [3.6], [1.79], [2.02], [-0.13], [-0.26], [3.37], [2.13], [4.1], [0.16], [1.25], [0.79], [1.88], [2.24], [3.52], [2.84], [0.71], [1.28], [0.21], [0.51], [-0.1], [3.54], [1.39], [2.73], [0.42], [0.62], [2.29], [2.59], [-0.43], [3.44], [7.6], [1.15], [2.6], [-0.47], [-0.22], [1.67], [2.39], [-0.8], [2.86], [3.1], [1.05], [2.55], [0.56], [0.87], [2.26], [7.04], [1.91], [2.81], [5.13], [-2.23], [1.92], [4.56], [1.06], [7.1], [2.12], [3.88], [3.09], [3.8], [1.35], [1.88], [0.7], [1.9], [2.07], [2.78], [1.72], [3.12], [1.66], [0.8], [0.76], [-2.03], [5.38], [3.56], [1.4], [2.41], [0.32], [0.99], [3.67], [4.06], [6.51], [2.05], [4.55], [4.99], [-0.47], [2.78], [1.7], [6.0], [1.67], [3.72], [4.55], [3.57], [3.8], [2.1], [1.8], [-0.26], [-1.89], [-0.31], [0.37], [3.42], [2.75], [2.48], [2.43], [4.54], [1.26], [0.4], [-0.22], [0.28], [5.05], [3.49], [2.08], [1.12], [2.26], [-0.61], [1.91], [2.62], [3.11], [2.8], [0.5], [-1.73], [2.62], [0.23], [1.92], [3.32], [2.63], [1.77], [2.07], [2.5], [1.43], [-0.55], [8.62], [1.17], [4.28], [0.6], [0.54], [-2.12], [2.87], [4.64], [3.21], [5.88], [3.99], [0.85], [2.53], [3.47], [4.8], [3.35], [4.55], [2.1], [4.38], [2.83], [4.44], [0.97], [2.03], [-0.41], [0.62], [4.3], [1.82], [0.24], [2.22], [1.0], [-1.19], [1.93], [-1.41], [2.6], [-0.9], [3.08], [4.89], [0.63], [1.41], [-0.8], [2.42], [-0.75], [1.67], [2.08], [1.88], [0.96], [1.67], [0.41], [-0.71], [0.94], [2.74], [1.23], [0.77], [0.59], [2.42], [5.02], [1.2], [3.58], [1.88], [1.83], [0.61], [2.19], [-0.48], [-0.76], [1.51], [1.54], [2.51], [-0.62], [3.84], [0.47], [2.15], [1.92], [1.52], [0.9], [4.53], [3.09], [3.16], [1.86], [0.87], [1.06], [4.74], [2.19], [3.4], [1.46], [2.43], [2.62], [0.38], [3.75], [4.73], [3.4], [-2.75], [1.35], [2.06], [0.61], [5.5], [1.96], [2.21], [1.8], [1.23], [2.31], [1.97], [2.72], [-1.23], [1.81], [1.15], [6.14], [0.99], [2.9], [1.63], [3.77], [0.6], [1.6], [4.48], [1.54], [2.23], [2.07], [4.19], [3.37], [1.61], [1.86], [1.24], [2.72], [0.83], [3.88], [1.82], [2.84], [0.57], [1.0], [2.69], [1.04], [2.29], [0.01], [2.09], [4.15], [1.71], [3.11], [0.35], [2.5], [1.63], [2.14], [1.85], [-1.18], [1.53], [0.21], [0.16], [3.5], [1.6], [1.46], [-0.3], [0.04], [2.53], [1.79], [5.07], [0.58], [1.13], [-1.54], [-0.37], [0.65], [-0.87], [2.45], [2.59], [0.48], [2.36], [0.8], [0.2], [2.84], [2.2], [1.96], [2.26], [4.47], [2.19], [3.97], [-0.54], [2.32], [0.28], [-1.52], [4.49], [1.13], [4.85], [3.63], [2.51], [1.63], [3.62], [2.47], [2.57], [3.63], [4.31], [0.8], [3.93], [3.45], [0.3], [2.3], [4.15], [2.07], [1.31], [2.5], [2.77], [3.72], [4.36], [2.96], [0.84], [2.6], [-0.64], [0.06], [2.59], [-0.79], [1.85], [2.4], [3.81], [1.37], [0.82], [2.3], [3.29], [1.47], [5.49], [2.76], [1.65], [1.64], [4.1], [1.88], [1.04], [3.58], [4.45], [0.86], [3.19], [1.54], [3.5], [1.81], [1.66], [-1.57], [1.7], [3.95], [9.14], [1.94], [2.51], [0.07], [1.47], [0.6], [4.11], [0.22], [2.31], [3.01], [-0.67], [1.8], [4.08], [-0.92], [3.78], [-3.1], [1.15], [2.57], [2.67], [0.29], [-1.24], [1.94], [-0.17], [2.2], [2.39], [2.0], [6.67], [3.3], [1.0], [3.23], [2.16], [4.3], [0.49], [0.1], [2.9], [5.89], [-0.21], [1.38], [1.23], [0.09], [2.29], [-0.05], [0.05], [5.81], [1.07], [7.71], [3.03], [1.28], [2.66], [-0.29], [1.17], [1.59], [3.21], [0.59], [2.28], [0.38], [-1.37], [2.47], [4.36], [-0.35], [0.42], [2.62], [1.93], [2.32], [6.64], [4.42], [0.22], [-0.5], [2.79], [6.37], [2.03], [1.09], [2.98], [-0.26], [1.03], [3.18], [4.4], [3.11], [0.13], [3.5], [3.4], [1.36], [2.34], [-0.62], [4.35], [2.89], [3.62], [0.71], [1.73], [1.47], [5.69], [0.0], [3.06], [-0.33], [1.68], [1.04], [2.16], [3.48], [2.33], [3.38], [-0.29], [2.23], [1.58], [0.43], [1.51], [-0.19], [0.12], [3.42], [1.52], [2.58], [1.8], [2.65], [-0.53], [2.46], [4.12], [0.7], [2.05], [1.55], [3.28], [1.77], [4.22], [-0.68], [2.12], [0.76], [1.71], [2.83], [4.7], [4.49], [3.18], [1.17], [2.21], [-0.84], [4.47], [-0.67], [2.62], [0.48], [3.66], [1.59], [2.48], [2.4], [1.12], [5.27], [2.74], [2.22], [1.59], [3.9], [-1.85], [1.41], [3.65], [-0.74], [2.95], [1.56], [1.25], [0.53], [-0.16], [1.31], [3.41], [2.52], [2.8], [1.47], [1.31], [5.53], [0.7], [2.31], [7.02], [1.8], [2.71], [-0.66], [0.97], [4.25], [1.64], [3.75], [-1.38], [0.73], [1.52], [2.85], [0.62], [1.31], [-0.83], [1.87], [-1.1], [2.45], [1.95], [1.98], [2.21], [-0.89], [0.25], [6.73], [-0.46], [3.82], [1.12], [2.14], [2.73], [0.2], [4.48], [2.56], [8.84], [5.6], [2.92], [1.02], [3.51], [3.65], [3.29], [4.05], [1.51], [4.49], [1.32], [2.5], [1.28], [8.1], [2.45], [4.5], [3.61], [0.15], [-0.74], [2.31], [1.6], [3.92], [2.91], [2.67], [-4.2], [1.12], [0.02], [2.69], [4.25], [1.12], [3.09], [0.3], [1.96], [3.03], [2.18], [1.75], [-1.97], [2.03], [1.57], [3.08], [5.08], [1.17], [1.06], [3.3], [2.0], [1.47], [1.2], [2.54], [1.2], [3.45], [0.22], [0.98], [1.1], [0.64], [2.24], [3.63], [-0.53], [3.17], [0.65], [1.41], [2.1], [2.66], [-0.87], [4.44], [3.8], [2.78], [7.0], [5.47], [1.82], [2.24], [5.5], [1.01], [6.92], [2.36], [1.34], [3.77], [0.76], [4.62], [0.48], [4.93], [2.95], [-0.5], [2.48], [0.54], [1.02], [0.65], [1.34], [1.4], [3.0], [3.62], [0.19], [3.71], [0.55], [1.56], [0.45], [3.53], [3.05], [1.2], [0.43], [5.16], [2.02], [-3.69], [1.94], [0.45], [1.76], [1.4], [2.92], [5.69], [0.59], [-1.66], [2.01], [4.3], [2.45], [1.33], [0.25], [1.81], [1.91], [2.82], [1.0], [1.26], [4.7], [1.23], [3.54], [0.98], [4.94], [5.07], [1.75], [0.3], [3.63], [1.03], [2.71], [1.95], [1.7], [-2.11], [1.34], [3.1], [1.58], [0.01], [4.15], [2.78], [2.04], [2.69], [0.99], [5.96], [0.52], [0.69], [4.69], [1.42], [0.97], [7.8], [4.06], [0.69], [7.39], [2.61], [-0.16], [3.33], [4.8], [1.95], [3.12], [5.63], [-2.95], [3.31], [0.77], [3.27], [2.55], [4.73], [-0.03], [1.06], [0.58], [1.91], [4.87], [0.63], [3.02], [2.01], [0.37], [5.51], [2.14], [2.55], [2.41], [2.04], [2.84], [2.66], [3.43], [-3.19], [1.39], [5.14], [-0.48], [0.51], [-1.53], [2.35], [0.69], [4.04], [4.54], [1.38], [3.2], [-2.3], [1.61], [1.6], [2.62], [1.89], [1.7], [7.78], [0.51], [5.13], [3.7], [3.9], [4.47], [5.6], [1.24], [2.9], [2.37], [4.3], [2.75], [0.74], [1.34], [1.69], [4.0], [0.76], [0.19], [0.7], [-2.92], [2.09], [0.33], [0.93], [0.03], [2.91], [4.41], [-1.41], [1.35], [2.32], [4.0], [0.09], [3.3], [2.21], [1.4], [1.18], [1.11], [3.57], [0.06], [3.5], [3.57], [3.92], [4.11], [6.29], [3.8], [2.57], [-3.05], [1.95], [2.1], [-0.66], [1.6], [-1.33], [1.12], [2.25], [0.49], [2.3], [3.78], [1.56], [1.52], [2.11], [0.7], [0.28], [2.15], [0.78], [4.22], [1.29], [0.44], [1.62], [0.56], [0.41], [0.85], [7.1], [-0.43], [3.41], [-1.45], [4.38], [2.49], [6.89], [0.76], [1.22], [4.48], [5.15], [1.98], [1.76], [2.3], [2.53], [3.21], [2.19], [1.53], [0.49], [6.14], [4.01], [2.44], [0.79], [0.22], [1.15], [-0.27], [2.1], [1.36], [0.13], [1.48], [3.22], [1.22], [3.3], [-0.4], [3.55], [0.86], [-1.16], [4.75], [4.45], [2.75], [3.51], [2.35], [4.25], [1.75], [0.77], [0.62], [0.83], [1.84], [6.55], [1.14], [2.49], [0.19], [1.4], [3.63], [3.21], [1.05], [2.12], [1.28], [1.7], [4.71], [0.76], [1.11], [2.03], [4.13], [2.17], [4.2], [2.8], [3.14], [5.35], [2.79], [2.76], [2.38], [4.18], [4.76], [2.24], [1.55], [2.56], [3.11], [4.87], [-0.93], [-0.65], [3.14], [1.19], [4.95], [0.67], [-0.4], [2.31], [2.04], [1.17], [2.32], [1.6], [0.33], [3.4], [0.24], [4.22], [1.5], [4.34], [3.81], [0.88], [3.6], [0.64], [3.03], [2.41], [0.73], [2.62], [1.63], [2.72], [2.32], [7.75], [0.7], [2.54], [0.98], [1.15], [2.14], [-1.47], [2.41], [2.15], [3.18], [0.3], [2.64], [-2.32], [2.41], [3.66], [2.18], [3.28], [6.41], [0.53], [1.14], [2.27], [1.12], [4.1], [2.71], [3.27], [1.0], [3.69], [2.29], [1.46], [2.72], [2.1], [0.86], [1.53], [1.11], [3.28], [-0.73], [7.1], [3.4], [1.05], [2.4], [0.34], [-2.51], [0.76], [0.67], [0.36], [0.28], [0.4], [0.35], [3.11], [-0.26], [1.94], [-1.85], [-0.4], [-0.36], [0.07], [0.99], [0.47], [2.61], [5.12], [4.27], [3.42], [3.1], [1.14], [3.76], [1.99], [1.77], [2.1], [1.04], [7.0], [-0.72], [1.51], [-0.48], [2.4], [3.48], [1.66], [2.27], [0.25], [0.9], [5.13], [1.4], [1.62], [3.61], [3.04], [2.62], [-0.4], [6.31], [4.67], [6.13], [0.96], [3.36], [1.6], [1.12], [-0.44], [3.05], [0.22], [0.14], [2.81], [1.28], [2.67], [3.04], [3.17], [3.06], [3.0], [0.34], [1.75], [1.86], [3.51], [2.01], [4.41], [4.5], [3.01], [-1.7], [2.46], [1.79], [3.18], [2.96], [3.3], [2.44], [2.19], [2.8], [0.71], [0.09], [3.49], [0.89], [1.68], [4.59], [2.57], [-1.31], [0.69], [0.86], [-0.99], [1.98], [1.9], [-0.47], [0.97], [0.95], [-0.35], [5.9], [-1.1], [2.8], [-1.33], [2.55], [-1.77], [2.42], [1.73], [0.44], [4.3], [2.79], [2.74], [2.75], [3.61], [0.76], [0.65], [1.28], [1.61], [1.1], [1.49], [-0.85], [0.18], [1.65], [3.74], [5.66], [1.95], [2.02], [3.63], [2.67], [2.96], [3.03], [3.01], [0.36], [3.22], [2.4], [2.17], [-1.24], [6.03], [5.76], [2.92], [2.05], [3.3], [2.37], [1.83], [0.74], [3.67], [1.0], [1.63], [3.56], [-1.11], [0.18], [1.74], [-1.05], [0.84], [1.55], [3.04], [1.68], [2.3], [1.15], [-0.67], [0.9], [2.76], [2.92], [0.99], [-1.37], [3.15], [2.13], [0.17], [2.7], [1.26], [0.77], [0.55], [3.39], [1.69], [2.3], [2.04], [2.63], [1.78], [1.42], [3.58], [5.4], [0.53], [2.11], [3.69], [3.29], [1.74], [1.93], [0.84], [0.99], [1.96], [0.88], [0.43], [2.9], [3.19], [2.52], [3.08], [0.86], [1.68], [1.26], [-1.59], [5.18], [-0.22], [-1.22], [2.05], [2.37], [3.03], [-1.97], [0.76], [2.93], [0.55], [0.4], [-2.44], [1.29], [3.25], [2.56], [0.17], [0.26], [1.88], [4.22], [3.42], [3.67], [0.69], [5.06], [1.37], [5.54], [0.65], [2.14], [0.58], [2.93], [1.41], [2.19], [3.0], [1.72], [2.22], [1.37], [3.42], [-2.35], [2.38], [2.72], [0.47], [0.79], [2.85], [2.22], [1.69], [3.23], [2.13], [1.88], [2.1], [2.24], [-1.4], [2.22], [2.15], [2.06], [2.33], [2.5], [0.79], [2.68], [3.3], [3.0], [1.14], [7.43], [3.8], [7.06], [-0.71], [2.06], [-0.44], [4.46], [4.27], [4.35], [1.73], [0.95], [1.82], [2.0], [-1.93], [0.96], [0.52], [1.71], [3.53], [1.05], [4.2], [1.96], [1.52], [1.51], [1.04], [3.92], [2.09], [3.12], [0.78], [3.22], [1.38], [3.3], [6.3], [4.11], [0.94], [1.21], [3.72], [1.6], [1.74], [-0.49], [2.05], [2.9], [-1.78], [1.27], [-1.21], [3.44], [5.87], [-1.1], [-0.24], [1.33], [1.1], [4.01], [2.24], [3.46], [2.47], [4.36], [3.2], [2.52], [-0.66], [0.24], [2.72], [0.39], [1.86], [1.6], [1.28], [2.0], [2.3], [-0.13], [2.74], [3.24], [0.4], [2.71], [2.22], [0.25], [2.08], [1.51], [1.28], [2.97], [3.87], [1.06], [-1.35], [1.63], [0.66], [2.3], [1.14], [0.29], [0.98], [-1.07], [4.26], [1.64], [-0.02], [2.8], [1.15], [3.05], [2.18], [1.98], [0.45], [0.22], [0.85], [0.78], [0.93], [0.8], [2.0], [1.38], [1.4], [1.95], [1.83], [1.0], [0.95], [3.22], [2.2], [1.68], [-1.73], [1.91], [2.83], [-0.96], [2.65], [0.83], [2.07], [3.04], [0.57], [2.06], [3.64], [3.53], [-0.36], [3.84], [2.94], [0.31], [1.45], [2.52], [2.94], [1.16], [2.25], [5.99], [1.37], [3.36], [2.03], [-0.7], [5.14], [6.95], [5.71], [2.37], [0.29], [1.77], [0.99], [7.38], [1.23], [3.65], [3.04], [2.06], [1.68], [7.45], [-0.33], [1.47], [2.4], [3.9], [4.48], [2.15], [1.83], [3.0], [-0.29], [1.93], [3.16], [4.49], [3.55], [5.37], [-0.75], [3.21], [4.05], [0.5], [5.04], [2.56], [0.96], [0.36], [1.91], [1.17], [3.72], [1.99], [3.6], [0.73], [2.6], [1.58], [0.45], [4.25], [2.31], [2.32], [3.08], [6.14], [4.05], [0.25], [3.36], [7.75], [0.93], [2.26], [0.98], [2.6], [1.69], [2.24], [3.41], [4.44], [-0.6], [1.1], [0.94], [2.56], [3.0], [2.0], [-2.41], [1.73], [0.65]]
[[-1.6593223892120565], [0.017820320113350947], [1.3744899002682984], [-0.13173380683286362], [-0.398794747808247], [0.7228612042883632], [-1.440332417612242], [-0.9382578485785213], [1.673598154160728], [1.5026791519364826], [-0.430842060725293], [-1.7714879844217175], [1.9780476268726648], [1.0379931146393155], [-1.248048540109966], [0.5786482961616561], [-0.11036893155483306], [-0.767338846354276], [0.70683754782984], [0.48250635741051806], [-0.6391495946860921], [-1.0771295378857206], [0.27419882344971896], [0.2955636987277496], [0.039185195391381634], [-0.9542815050370443], [-0.8955280980224601], [0.6160368278982097], [-1.3922614482366733], [0.24215151053267292], [-1.2320248836514431], [0.9792397076247311], [0.8083207054004856], [0.5092124515080563], [0.5893307338006715], [-1.1572478201783356], [0.5786482961616561], [-0.13173380683286362], [1.5774562154095897], [1.3691486814487908], [-0.9649639426760597], [-0.8154098157298452], [1.5721149965900822], [0.0658912894889201], [-0.3827710913497241], [1.6362096224241742], [0.41841173157642597], [-0.5163015618374157], [-0.3293589031546474], [0.3489758869228264], [0.5198948891470716], [-0.7940449404518145], [-0.7566564087152606], [1.5133615895754977], [-0.42550084190578535], [-0.7299503146177224], [-0.19582843266695568], [-2.161396958245777], [1.2142533356830685], [0.3756819810203646], [0.8884389876931006], [0.39170563747888776], [-0.7833625028127991], [0.2848812610887343], [0.081914945947443], [-0.29731159023760134], [0.5252361079665794], [-0.3667474348912011], [-0.3453825596131704], [-0.3934535289887393], [1.0166282393612847], [-1.2373661024709508], [-1.087811975524736], [-0.623125938227569], [0.1727156658790733], [0.1994217599766118], [-0.8207510345493527], [0.7335436419273785], [-0.863480785105414], [-0.09434527509631005], [2.207720036111495], [-0.3400413407936627], [-1.1732714766368588], [-0.6925617828811687], [-0.6711969076031381], [-0.09968649391581771], [0.49853001386904094], [-0.9275754109395061], [-0.7352915334372301], [1.2463006486001142], [-1.0343997873296595], [-1.573862888099934], [-0.22787574558400173], [0.43443538803494913], [0.012479101293843393], [-0.5697137500324924], [-2.40709302394313], [0.9365099570686698], [2.2931795372236166], [1.4172196508243597], [0.16203322824005797], [-1.3708965729586426], [0.03384397657187408], [-0.11036893155483306], [-2.7008600590160516], [0.49853001386904094], [0.4397766068544567], [0.21010419761562713], [0.16737444705956575], [0.023161538932858737], [0.33295223046430344], [-0.4094771854472623], [-1.3228256035830734], [0.4771651385910105], [0.0979386024059659], [0.3756819810203646], [0.562624639703133], [0.8991214253321159], [1.1768648039465146], [-0.2118520891254787], [-0.7833625028127991], [-0.318676465515632], [-0.158439900930402], [-0.6979030017006763], [-0.3667474348912011], [0.09259738358645835], [0.36499954338134927], [0.29022247990824207], [-0.23855818322301706], [-0.31333524669612434], [0.25283394817168825], [1.433243307282883], [-0.040933086901233325], [2.4106863512527856], [-0.5964198441300307], [0.16203322824005797], [1.208912116863561], [0.2581751669911961], [-0.9970112555931058], [-0.3614062160716934], [-0.4575481548228314], [0.5092124515080563], [-0.4201596230862777], [-0.0836628374572947], [2.4373924453503246], [-0.1370750256523713], [0.7121787666493478], [-0.9649639426760597], [0.39170563747888776], [-0.286629152598586], [0.03384397657187408], [-0.6818793452421534], [1.0166282393612847], [-1.985136737202024], [0.5786482961616561], [0.5893307338006715], [-1.1999775707343971], [-1.1999775707343971], [-0.14241624447187898], [0.9098038629711314], [0.9418511758881773], [-0.5002779053788927], [0.11930347768399659], [0.5412597644251023], [-0.19048721384744802], [-0.158439900930402], [1.5721149965900822], [-0.8581395662859064], [-0.7940449404518145], [-0.7459739710762454], [1.1822060227660223], [0.3222697928252881], [0.2955636987277496], [0.306246136366765], [-0.831433472188368], [-0.5697137500324924], [-0.8421159098273834], [0.6213780467177172], [-1.9530894242849781], [-1.087811975524736], [0.2955636987277496], [1.716327904716789], [0.023161538932858737], [1.491996714297467], [0.43443538803494913], [-0.4735718112813544], [1.4279020884633749], [0.12464469650350438], [0.5359185456055947], [1.8658820316630038], [-0.575054968852], [-0.7246090957982148], [-0.20651087030597104], [-0.07298039981827936], [-0.14241624447187898], [-1.1946363519148895], [-1.6753460456705795], [-1.573862888099934], [-0.6925617828811687], [0.32761101164479567], [0.16203322824005797], [-0.7887037216323066], [-0.5376664371154464], [0.8296855806785164], [0.6961551101908247], [1.6308684036046666], [-0.4361832795448007], [-1.53647435636338], [0.33295223046430344], [0.12464469650350438], [-0.2652642773205553], [-0.29731159023760134], [-0.09434527509631005], [-0.28128793377907835], [-1.3068019471245504], [-1.1732714766368588], [1.66825693534122], [1.946000313955619], [-0.22253452676449406], [1.5881386530486052], [-0.8527983474663987], [-1.0771295378857206], [-1.2640721965684891], [0.642742921995748], [-0.575054968852], [-1.7714879844217175], [-1.8516062667143325], [-1.5151094810853494], [1.1234526157514382], [0.306246136366765], [-0.1370750256523713], [-1.3335080412220888], [-1.2160012271929201], [0.1994217599766118], [-0.2759467149595706], [-0.7726800651737837], [2.854007513271922], [0.012479101293843393], [-0.1050277127353254], [-0.302652809057109], [-1.1198592884417822], [-0.286629152598586], [0.007137882474335602], [0.11396225886448903], [-0.41481840426677], [1.1982296792245453], [-1.2747546342075045], [-0.7993861592713221], [0.11930347768399659], [-0.3614062160716934], [-0.9382578485785213], [-1.0771295378857206], [0.08725616476695056], [-0.06763918099877168], [0.11396225886448903], [0.2848812610887343], [-0.8955280980224601], [-0.5964198441300307], [0.8777565500540855], [0.12998591532301193], [0.5466009832446102], [2.0474834715262644], [-1.9584306431044858], [-0.8154098157298452], [0.9845809264442387], [1.2516418674196224], [0.0017966636548280492], [1.5507501213120514], [0.4397766068544567], [-0.767338846354276], [0.6908138913713171], [-1.632616295114518], [1.0807228651953769], [-0.09968649391581771], [-0.9649639426760597], [0.3863644186593799], [0.03384397657187408], [0.9952633640832541], [-0.3400413407936627], [-0.9542815050370443], [-1.3708965729586426], [1.3691486814487908], [-0.7780212839932913], [-0.1050277127353254], [-0.3560649972521857], [-0.046274305720741114], [-1.0931531943442439], [-0.09434527509631005], [-1.3014607283050428], [0.11396225886448903], [0.09259738358645835], [0.16203322824005797], [0.0017966636548280492], [0.26351638581070363], [-0.8207510345493527], [1.155499928668484], [0.15669200942055042], [2.0314598150677416], [-1.3548729165001194], [0.9204863006101467], [-0.8581395662859064], [-0.47891303010086206], [1.155499928668484], [-0.42550084190578535], [0.2955636987277496], [0.754908517205409], [-2.0438901442166086], [0.4718239197715027], [1.1127701781124226], [0.5893307338006715], [0.9685572699857158], [-1.007693693232121], [-0.9970112555931058], [1.716327904716789], [-1.1145180696222745], [1.0967465216538999], [0.22612785407415004], [0.11396225886448903], [-0.9168929733004908], [-0.07832161863778703], [-1.4349911987927344], [0.70683754782984], [0.03384397657187408], [-0.8688220039249217], [-1.0130349120516287], [-0.1530986821108943], [1.892588125760542], [1.1341350533904533], [-0.5964198441300307], [-0.5857374064910154], [-0.20651087030597104], [0.8670741124150702], [-0.7192678769787071], [-1.4349911987927344], [0.24215151053267292], [-0.2759467149595706], [-0.03025064926221798], [0.23681029171316537], [0.34363466810331883], [0.007137882474335602], [-0.9222341921199984], [0.09259738358645835], [-0.831433472188368], [-0.687220564061661], [-0.575054968852], [0.7762733924834396], [-0.13173380683286362], [0.7816146113029474], [-1.1786126954563663], [-0.8581395662859064], [0.6641077972737787], [-0.03025064926221798], [0.36499954338134927], [-0.03025064926221798], [-0.16378111974990966], [0.5733070773421484], [0.5572834208836255], [1.0700404275563613], [-0.2919703714180937], [-1.3922614482366733], [0.007137882474335602], [-0.575054968852], [0.017820320113350947], [-0.8047273780908298], [1.2516418674196224], [-0.23855818322301706], [-0.27060549614006296], [-0.22253452676449406], [-0.4575481548228314], [-0.30799402787661667], [-0.9489402862175367], [-0.5002779053788927], [0.3863644186593799], [0.03384397657187408], [-0.911551754480983], [-0.6605144699641228], [-0.7085854393396918], [-1.6806872644900872], [-0.879504441563937], [0.4023880751179031], [1.273006742697653], [-0.06229796217926401], [-0.41481840426677], [0.044526414210889424], [-0.7352915334372301], [-0.25458183968153997], [0.13532713414251973], [2.0902132220823257], [-1.53647435636338], [-1.167930257817351], [-1.360214135319627], [-0.3667474348912011], [1.9780476268726648], [0.642742921995748], [-0.8421159098273834], [-0.1798047762084327], [-0.158439900930402], [0.039185195391381634], [-0.37208865371070876], [-1.5792041069194414], [0.23681029171316537], [0.5839895149811637], [-0.6284671570470768], [1.0540167710978385], [-0.3827710913497241], [0.20476297879611935], [-0.44152449836430835], [-0.16912233856941733], [-0.14241624447187898], [-0.8367746910078757], [1.0486755522783306], [-1.2213424460124278], [0.21544541643513468], [-0.1798047762084327], [0.30090491754725746], [1.5133615895754977], [-1.6432987327535336], [0.2688576046302114], [-0.46288937364233906], [0.338293449283811], [0.5893307338006715], [0.9204863006101467], [0.0658912894889201], [2.8379838568133997], [-0.4201596230862777], [0.594671952620179], [-0.07832161863778703], [-0.655173251144615], [-0.6605144699641228], [-0.014226992803695085], [0.1727156658790733], [-0.3827710913497241], [0.6106956090787021], [0.37034076220085704], [-0.3667474348912011], [-1.2587309777489815], [-0.14775746329138664], [0.5786482961616561], [-0.6017610629495384], [-0.12105136919384829], [-0.831433472188368], [0.5679658585226408], [0.18339810351808866], [-1.4937446058073187], [-0.6391495946860921], [1.3103952744342064], [-0.158439900930402], [0.5359185456055947], [1.0646992087368536], [-0.7459739710762454], [0.8350267994980242], [-0.302652809057109], [0.8296855806785164], [-0.5323252182959387], [0.31692857400578034], [-0.5697137500324924], [-0.09434527509631005], [0.5198948891470716], [0.7495672983859014], [-0.23855818322301706], [0.7602497360249167], [-0.623125938227569], [-0.4575481548228314], [0.39170563747888776], [-0.05161552454024867], [0.5893307338006715], [-2.1720793958847926], [-0.3240176843351397], [0.12464469650350438], [-1.1038356319832592], [0.1994217599766118], [-0.3240176843351397], [-0.3240176843351397], [-1.4937446058073187], [0.43443538803494913], [-0.31333524669612434], [-0.3240176843351397], [-0.5857374064910154], [-0.8527983474663987], [1.6896218106192507], [0.0979386024059659], [0.562624639703133], [-0.03025064926221798], [0.70683754782984], [0.32761101164479567], [-0.8207510345493527], [0.46114148213248735], [1.3638074626292833], [1.3744899002682984], [0.40772929393741064], [-0.655173251144615], [-0.27060549614006296], [-0.30799402787661667], [-1.7287582338656562], [0.2581751669911961], [0.3970468562983953], [0.11396225886448903], [-0.9863288179540904], [-0.03025064926221798], [-0.003544555164679741], [-0.14775746329138664], [0.7655909548444243], [0.10327982122547369], [-0.16912233856941733], [-0.9863288179540904], [-0.446865717183816], [-0.6391495946860921], [0.4771651385910105], [0.6908138913713171], [2.266473443126079], [0.32761101164479567], [1.267665523878145], [-0.8581395662859064], [-1.1465653825393203], [0.786955830122455], [-0.5857374064910154], [-0.33470012197415505], [-0.8207510345493527], [0.07123250830842766], [-0.9703051614955673], [-0.8741632227444294], [-0.2332169644035094], [0.1727156658790733], [-1.37623779177815], [-0.767338846354276], [1.3424425873512527], [0.48250635741051806], [1.8231522811069423], [-0.47891303010086206], [-1.0504234437881825], [0.6854726725518093], [-0.6605144699641228], [-1.4456736364317497], [-0.5536900935739694], [-1.4510148552512574], [0.044526414210889424], [-1.8943360172703936], [0.6694490160932864], [0.7121787666493478], [-0.7406327522567377], [0.674790234912794], [0.0979386024059659], [1.50802037075599], [0.0979386024059659], [0.5198948891470716], [-0.8741632227444294], [-0.7940449404518145], [-0.019568211623202637], [1.2356182109610991], [-0.6765381264226457], [-0.1530986821108943], [-0.12639258801335596], [-1.4296499799732267], [0.5252361079665794], [0.18873932233759644], [2.5228519464624473], [-1.440332417612242], [0.081914945947443], [0.36499954338134927], [0.6534253596347633], [1.6575744977022049], [-0.7299503146177224], [1.2195945545025761], [-0.3827710913497241], [-0.4895954677398774], [0.21544541643513468], [0.8563916747760548], [-0.591078625310523], [1.1982296792245453], [1.3531250249902678], [-0.3560649972521857], [1.3638074626292833], [-0.9329166297590137], [-0.28128793377907835], [0.46114148213248735], [0.9899221452637466], [0.4558002633129798], [0.0979386024059659], [0.24215151053267292], [0.1994217599766118], [0.7282024231078708], [0.1406683529620273], [-1.0397410061491672], [0.3489758869228264], [0.37034076220085704], [1.4225608696438674], [-0.2492406208620324], [0.11396225886448903], [0.7282024231078708], [-0.024909430442710427], [-0.6711969076031381], [0.18873932233759644], [-0.1050277127353254], [0.4558002633129798], [-0.3667474348912011], [0.6587665784542711], [0.081914945947443], [0.4771651385910105], [-0.5269839994764309], [0.5305773267860869], [0.4718239197715027], [-0.398794747808247], [0.14600957178153506], [1.7056454670777739], [-0.6498320323251074], [0.06055007066941232], [-0.16912233856941733], [-1.1519066013588282], [-0.046274305720741114], [-0.8047273780908298], [0.23681029171316537], [-0.8581395662859064], [0.37034076220085704], [-0.575054968852], [0.0658912894889201], [1.1768648039465146], [-0.6818793452421534], [1.5400676836730363], [-0.6124435005885538], [1.9246354386775884], [-0.14775746329138664], [-0.21719330794498637], [0.754908517205409], [-0.7459739710762454], [-0.24389940204252475], [1.315736493253714], [0.32761101164479567], [-0.49493668655938505], [0.04986763303039698], [0.338293449283811], [-1.0023524744126133], [0.9471923947076851], [0.0658912894889201], [0.34363466810331883], [1.433243307282883], [-0.703244220520184], [0.7014963290103324], [0.7602497360249167], [0.039185195391381634], [0.6854726725518093], [0.9471923947076851], [0.10327982122547369], [-1.2533897589294738], [-1.5311331375438724], [-0.44152449836430835], [-1.2587309777489815], [-0.024909430442710427], [-0.03559186808172577], [-0.008885773984187294], [-0.37208865371070876], [1.1661823663074995], [0.9258275194296545], [2.7525243557012766], [-0.40413596662775464], [-0.14241624447187898], [0.09259738358645835], [1.3264189308927294], [1.1768648039465146], [-0.7887037216323066], [-0.046274305720741114], [-0.510960343017908], [0.12464469650350438], [-1.0984944131637513], [2.4320512265308167], [0.786955830122455], [1.8498583752044806], [-0.31333524669612434], [-2.449822774499191], [-2.182761833523808], [-1.1412241637198128], [0.2688576046302114], [1.2943716179756832], [-1.9157008925484245], [0.34363466810331883], [-0.35072377843267805], [-0.5697137500324924], [-1.7180757962266409], [-0.9970112555931058], [1.0166282393612847], [-0.019568211623202637], [-1.5311331375438724], [-0.35072377843267805], [0.8724153312345777], [-0.5323252182959387], [-0.9809875991345828], [-0.1798047762084327], [-0.16378111974990966], [-0.5803961876715077], [-0.29731159023760134], [-1.280095853027012], [1.3371013685317445], [0.18339810351808866], [0.594671952620179], [-1.7073933585876255], [0.36499954338134927], [-0.5376664371154464], [0.36499954338134927], [-0.5857374064910154], [0.3222697928252881], [-0.4575481548228314], [-0.8100685969103374], [-0.19048721384744802], [-0.09968649391581771], [-1.8249001726167942], [-1.6112514198364873], [1.0753816463758692], [0.7228612042883632], [-1.440332417612242], [-0.8421159098273834], [1.4866554954779594], [0.2848812610887343], [-1.4029438858756884], [0.9952633640832541], [1.1020877404734075], [1.1341350533904533], [0.5572834208836255], [-0.37208865371070876], [-0.7726800651737837], [-1.7501231091436869], [-0.23855818322301706], [-0.06229796217926401], [-0.6818793452421534], [-0.879504441563937], [-0.06763918099877168], [0.039185195391381634], [0.33295223046430344], [0.674790234912794], [-0.1530986821108943], [1.5187028083950056], [-0.3827710913497241], [-1.9744542995630088], [0.4130705127569184], [2.1436254102774024], [0.306246136366765], [-0.6124435005885538], [1.0379931146393155], [-0.5857374064910154], [-0.03025064926221798], [-0.5056191241984004], [2.1115780973603564], [-1.440332417612242], [0.07123250830842766], [0.081914945947443], [0.25283394817168825], [-0.4361832795448007], [0.642742921995748], [-0.6124435005885538], [-1.0343997873296595], [-1.3548729165001194], [0.3489758869228264], [-0.2759467149595706], [-0.8421159098273834], [0.1780568846985811], [-0.430842060725293], [-1.2320248836514431], [0.5359185456055947], [0.9044626441516238], [-2.118667207689716], [0.29022247990824207], [-0.024909430442710427], [0.9792397076247311], [1.0486755522783306], [1.497337933116975], [2.245108567848048], [0.5359185456055947], [0.10327982122547369], [-1.8836535796313785], [-0.9649639426760597], [-0.9329166297590137], [-0.6658556887836303], [0.31692857400578034], [-0.4735718112813544], [-0.4361832795448007], [1.2890303991561756], [0.642742921995748], [1.1234526157514382], [-0.318676465515632], [-2.102643551231193], [-0.8901868792029525], [0.25283394817168825], [-1.424308761153719], [0.5412597644251023], [-1.5151094810853494], [0.05520885184990477], [2.2023788172919865], [0.1994217599766118], [-0.22253452676449406], [-1.1091768508027668], [-0.6338083758665843], [0.02850275775236629], [2.6830885110476768], [0.1994217599766118], [-1.167930257817351], [1.443925744921898], [-0.6391495946860921], [0.4023880751179031], [-1.3174843847635658], [-1.05576466260769], [-2.0278664877580854], [0.2955636987277496], [-0.40413596662775464], [1.0219694581807923], [2.8860548261889685], [-0.09434527509631005], [-0.430842060725293], [0.49853001386904094], [1.0646992087368536], [-1.461697292890273], [3.7726971502272413], [-0.7993861592713221], [-0.1370750256523713], [0.194080541157104], [-1.814217734977779], [0.04986763303039698], [-2.524599837972299], [-0.7299503146177224], [0.32761101164479567], [0.8083207054004856], [0.20476297879611935], [-1.087811975524736], [-1.5311331375438724], [-0.158439900930402], [-1.2640721965684891], [-1.1412241637198128], [0.07123250830842766], [2.85934873209143], [0.15669200942055042], [-1.2747546342075045], [-0.5056191241984004], [-0.959622723856552], [-0.5483488747544617], [-0.38811231016923164], [0.338293449283811], [0.40772929393741064], [-0.430842060725293], [0.08725616476695056], [1.34778380617076], [1.9566827515946341], [-0.9703051614955673], [0.044526414210889424], [-0.07298039981827936], [-0.11036893155483306], [-1.9958191748410397], [0.10862104004498124], [-0.12105136919384829], [-0.38811231016923164], [0.9044626441516238], [-1.8996772360899015], [-0.3293589031546474], [-1.0717883190662132], [-0.4735718112813544], [-1.1412241637198128], [0.4664827009519951], [-1.1252005072612896], [0.6320604843567326], [-0.5163015618374157], [1.4546081825609136], [2.3679566006967243], [1.6575744977022049], [-0.33470012197415505], [0.9685572699857158], [-0.38811231016923164], [0.24749272935218072], [0.1727156658790733], [-0.4575481548228314], [0.30090491754725746], [0.33295223046430344], [-0.7833625028127991], [0.13532713414251973], [-0.3667474348912011], [0.1727156658790733], [1.3103952744342064], [-0.6979030017006763], [-1.2533897589294738], [-1.4723797305292883], [0.6053543902591944], [0.674790234912794], [-0.9329166297590137], [0.5519422020641177], [0.9098038629711314], [-0.30799402787661667], [-0.03559186808172577], [0.39170563747888776], [-0.5857374064910154], [0.41841173157642597], [2.421368788891801], [0.8136619242199935], [2.042142252706757], [-0.911551754480983], [-0.7139266581591994], [1.2569830862391298], [0.6480841408152558], [0.04986763303039698], [-0.2759467149595706], [-0.23855818322301706], [-0.003544555164679741], [-0.12639258801335596], [-0.3400413407936627], [0.6801314537323018], [0.36499954338134927], [1.1448174910294688], [-0.5002779053788927], [1.1020877404734075], [0.5412597644251023], [0.6053543902591944], [0.931168738249162], [0.24749272935218072], [0.5359185456055947], [0.9685572699857158], [-0.3827710913497241], [-1.440332417612242], [0.20476297879611935], [-0.7833625028127991], [0.3863644186593799], [0.8083207054004856], [-0.046274305720741114], [-1.2320248836514431], [-1.280095853027012], [0.8724153312345777], [0.0017966636548280492], [-0.03559186808172577], [-0.11571015037434074], [0.4771651385910105], [-0.0836628374572947], [-1.087811975524736], [-0.5376664371154464], [0.5466009832446102], [-2.4658464309577144], [-0.19048721384744802], [-0.13173380683286362], [1.1234526157514382], [0.7495672983859014], [0.1994217599766118], [-1.4296499799732267], [0.786955830122455], [0.40772929393741064], [-0.03559186808172577], [-1.4349911987927344], [-0.019568211623202637], [2.106236878540849], [1.2890303991561756], [0.04986763303039698], [0.2955636987277496], [1.2463006486001142], [-1.05576466260769], [-0.19582843266695568], [-0.12639258801335596], [0.6801314537323018], [-1.525791918724365], [-0.398794747808247], [0.450459044493472], [-0.3293589031546474], [0.30090491754725746], [0.06055007066941232], [1.2783479615171605], [0.43443538803494913], [-1.7394406715046713], [0.10862104004498124], [-0.003544555164679741], [-0.4895954677398774], [-2.01718405011907], [2.7151358239647227], [-0.2652642773205553], [-0.46823059246184673], [-0.7459739710762454], [2.074189565623803], [0.21544541643513468], [1.3691486814487908], [-2.241515240538392], [0.21544541643513468], [0.9738984888052233], [-0.3667474348912011], [0.514553670327564], [0.8190031430395011], [1.620185965965651], [2.229084911389525], [-2.1881030523433154], [0.7602497360249167], [0.1727156658790733], [0.5466009832446102], [-0.003544555164679741], [0.883097768873593], [-0.9649639426760597], [0.33295223046430344], [0.04986763303039698], [-0.4895954677398774], [-0.879504441563937], [-1.2587309777489815], [-0.9168929733004908], [3.7726971502272413], [0.5412597644251023], [-0.5216427806569233], [-1.6379575139340259], [-0.47891303010086206], [0.7014963290103324], [-0.14775746329138664], [0.07123250830842766], [-0.21719330794498637], [0.7175199854688553], [0.6320604843567326], [0.18873932233759644], [1.1287938345709458], [1.1287938345709458], [1.545408902492544], [0.11930347768399659], [0.0979386024059659], [-0.019568211623202637], [-1.167930257817351], [0.12998591532301193], [-1.1786126954563663], [-1.1465653825393203], [-0.14775746329138664], [0.012479101293843393], [0.2581751669911961], [-1.5952277633779646], [2.159649066735925], [-0.174463557388925], [-1.6593223892120565], [0.07657372712793545], [0.7442260795663939], [-2.3323159604700225], [-0.5697137500324924], [-0.14241624447187898], [0.08725616476695056], [-0.6177847194080615], [3.478930115154319], [1.50802037075599], [0.023161538932858737], [-0.6498320323251074], [0.4558002633129798], [0.7014963290103324], [-0.22787574558400173], [-0.655173251144615], [-0.06229796217926401], [-0.7352915334372301], [0.14600957178153506], [-0.4522069360033237], [-0.7780212839932913], [-0.8421159098273834], [-2.294927428733469], [-1.7340994526851639], [-0.12639258801335596], [0.3596583245618417], [0.05520885184990477], [0.3222697928252881], [-1.0771295378857206], [0.594671952620179], [-0.47891303010086206], [0.2955636987277496], [-1.3815790105976578], [0.12998591532301193], [0.4023880751179031], [-2.8931439365183276], [0.39170563747888776], [1.1822060227660223], [1.091405302834392], [-0.1798047762084327], [0.1406683529620273], [-2.0812786759531625], [-2.0599138006751314], [1.5827974342290974], [-0.8260922533688604], [-1.6432987327535336], [-0.2492406208620324], [-0.024909430442710427], [-0.05161552454024867], [0.18339810351808866], [-0.8047273780908298], [0.3222697928252881], [-1.248048540109966], [-0.9329166297590137], [-0.008885773984187294], [-1.0824707567052285], [0.3489758869228264], [-0.7887037216323066], [0.27954004226922674], [0.1727156658790733], [1.2623243050586375], [-0.16912233856941733], [1.0326518958198079], [-0.24389940204252475], [-0.2492406208620324], [-0.0836628374572947], [0.9685572699857158], [-0.7085854393396918], [-1.0611058814271976], [-0.6979030017006763], [-0.6605144699641228], [-1.2053187895539048], [-0.5002779053788927], [1.2569830862391298], [-0.302652809057109], [0.5092124515080563], [-0.5483488747544617], [-0.6017610629495384], [1.9246354386775884], [-2.33765717928953], [-0.5216427806569233], [-0.302652809057109], [-2.481870087416237], [-0.6124435005885538], [-0.09968649391581771], [-1.5578392316414107], [-1.0183761308711365], [1.7270103423558045], [-1.408285104695196], [0.7282024231078708], [0.8136619242199935], [0.24749272935218072], [0.18339810351808866], [0.2848812610887343], [0.4771651385910105], [0.3596583245618417], [-0.5376664371154464], [-1.2160012271929201], [0.08725616476695056], [1.4065372131853446], [-0.959622723856552], [-1.8622887043533478], [1.609503528326636], [0.23681029171316537], [1.9246354386775884], [0.7602497360249167], [-2.0919611135921774], [0.16203322824005797], [-1.2266836648319355], [-1.0343997873296595], [-0.13173380683286362], [0.081914945947443], [0.32761101164479567], [-0.959622723856552], [0.22612785407415004], [0.29022247990824207], [-1.2373661024709508], [0.012479101293843393], [-1.0984944131637513], [-0.911551754480983], [0.7762733924834396], [-0.9275754109395061], [-0.318676465515632], [0.5733070773421484], [0.007137882474335602], [0.39170563747888776], [0.1406683529620273], [0.35431710574233394], [-1.2907782906660275], [-0.19582843266695568], [-0.40413596662775464], [0.674790234912794], [-0.3774298725302164], [-0.1798047762084327], [-0.16378111974990966], [0.9471923947076851], [0.4664827009519951], [-0.8955280980224601], [-1.8302413914363018], [-0.3293589031546474], [-0.11571015037434074], [-0.9542815050370443], [1.6255271847851587], [-1.4777209493487957], [0.044526414210889424], [-1.0771295378857206], [-0.4735718112813544], [-0.008885773984187294], [0.3222697928252881], [0.8563916747760548], [0.7282024231078708], [-1.5044270434463343], [1.785763749370389], [0.06055007066941232], [0.562624639703133], [1.785763749370389], [-1.1999775707343971], [0.6587665784542711], [0.039185195391381634], [-0.6979030017006763], [0.8243443618590088], [0.03384397657187408], [0.35431710574233394], [0.8617328935955624], [-0.05695674335975634], [0.963216051166208], [0.081914945947443], [1.0379931146393155], [-0.003544555164679741], [0.6320604843567326], [-0.38811231016923164], [0.5893307338006715], [0.6106956090787021], [0.626719265537225], [0.12464469650350438], [1.2516418674196224], [-0.06229796217926401], [0.10862104004498124], [-0.46288937364233906], [0.039185195391381634], [-0.7940449404518145], [-0.2919703714180937], [-1.1252005072612896], [0.48250635741051806], [-0.3667474348912011], [-0.16378111974990966], [0.963216051166208], [0.2848812610887343], [-0.2118520891254787], [-0.2652642773205553], [-0.5323252182959387], [-0.20116965148646337], [1.8391759375654655], [-0.174463557388925], [-0.014226992803695085], [0.11930347768399659], [0.30090491754725746], [-0.2652642773205553], [-0.5857374064910154], [0.9525336135271927], [-0.2919703714180937], [1.5774562154095897], [-1.7287582338656562], [-1.1892951330953816], [-0.05161552454024867], [1.9406590951361113], [-0.4201596230862777], [-0.06229796217926401], [-0.7780212839932913], [-1.648639951573041], [0.20476297879611935], [0.9418511758881773], [0.7602497360249167], [0.9738984888052233], [0.8296855806785164], [0.9098038629711314], [-1.2587309777489815], [0.6213780467177172], [-1.9744542995630088], [-0.46823059246184673], [-0.25992305850104763], [1.1234526157514382], [1.6522332788826974], [-0.9863288179540904], [0.5733070773421484], [0.017820320113350947], [0.13532713414251973], [-0.12105136919384829], [-0.623125938227569], [-0.014226992803695085], [1.0593579899173462], [-1.872971141992363], [1.267665523878145], [-0.46823059246184673], [1.34778380617076], [-0.28128793377907835], [0.1727156658790733], [-1.0237173496906442], [0.26351638581070363], [0.5679658585226408], [-0.6925617828811687], [0.1780568846985811], [0.26351638581070363], [-0.3667474348912011], [-1.1732714766368588], [3.5323423033493966], [-1.6700048268510717], [-0.286629152598586], [-0.47891303010086206], [0.24215151053267292], [-0.27060549614006296], [0.25283394817168825], [-1.2106600083734125], [1.2195945545025761], [0.5679658585226408], [0.5786482961616561], [-1.5311331375438724], [-0.3774298725302164], [-0.2759467149595706], [-2.294927428733469], [-1.2533897589294738], [1.0379931146393155], [0.9204863006101467], [1.0540167710978385], [-1.0343997873296595], [-0.543007655934954], [1.0753816463758692], [-1.0504234437881825], [0.0979386024059659], [1.3531250249902678], [-0.7940449404518145], [-0.6338083758665843], [0.37034076220085704], [-0.46823059246184673], [0.5519422020641177], [-0.14775746329138664], [1.9780476268726648], [-0.9275754109395061], [-1.4510148552512574], [-0.40413596662775464], [-1.5151094810853494], [-0.5269839994764309], [-0.4094771854472623], [-1.007693693232121], [0.4397766068544567], [-0.8047273780908298], [-0.22253452676449406], [0.16203322824005797], [-0.8688220039249217], [-0.7246090957982148], [-0.4735718112813544], [-0.25992305850104763], [-0.2492406208620324], [-0.7780212839932913], [0.02850275775236629], [-1.2106600083734125], [-0.3774298725302164], [1.34778380617076], [-1.2694134153879966], [-0.2332169644035094], [-0.8367746910078757], [-0.4201596230862777], [-1.6219338574755027], [-0.1370750256523713], [-0.3293589031546474], [0.44511782567396446], [0.754908517205409], [-0.5857374064910154], [-0.5857374064910154], [-2.3964105863041145], [-0.28128793377907835], [-0.19582843266695568], [-2.775637122489159], [1.1341350533904533], [1.0807228651953769], [0.6053543902591944], [-0.14241624447187898], [1.8498583752044806], [-0.14241624447187898], [-0.655173251144615], [0.0017966636548280492], [-1.3228256035830734], [-2.01718405011907], [0.10862104004498124], [-0.2652642773205553], [-0.12639258801335596], [-0.42550084190578535], [1.7697400929118658], [0.26351638581070363], [0.3756819810203646], [0.7228612042883632], [-1.6967109209486102], [-0.8688220039249217], [0.3863644186593799], [0.5305773267860869], [-0.1798047762084327], [-0.6338083758665843], [0.3863644186593799], [-0.2492406208620324], [-1.8462650478948248], [0.16737444705956575], [-0.06229796217926401], [-0.863480785105414], [1.0112870205417772], [-0.27060549614006296], [-1.0664471002467053], [2.122260534999372], [0.2581751669911961], [0.24749272935218072], [-0.8260922533688604], [-1.424308761153719], [2.9020784826474912], [-1.4937446058073187], [0.4771651385910105], [0.7121787666493478], [-0.09434527509631005], [0.883097768873593], [-0.47891303010086206], [-2.460505212138206], [0.786955830122455], [-0.29731159023760134], [-0.5163015618374157], [-0.7780212839932913], [-0.18514599502794035], [-0.3774298725302164], [-1.2854370718465198], [-0.7833625028127991], [1.1287938345709458], [-1.0450822249686746], [0.5893307338006715], [-1.4990858246268264], [1.2409594297806068], [-0.20116965148646337], [0.4558002633129798], [0.40772929393741064], [1.9620239704141416], [0.9685572699857158], [-1.9530894242849781], [-0.9062105356614755], [-0.05161552454024867], [-0.9329166297590137], [2.9608318896620753], [1.6415508412436817], [1.1394762722099614], [1.3424425873512527], [0.017820320113350947], [0.562624639703133], [1.0219694581807923], [-0.8581395662859064], [-0.6124435005885538], [-0.019568211623202637], [0.754908517205409], [1.0273106770002998], [2.3572741630577094], [-0.7459739710762454], [1.716327904716789], [0.36499954338134927], [-0.7192678769787071], [-1.3174843847635658], [0.023161538932858737], [-1.007693693232121], [-0.16912233856941733], [-0.9863288179540904], [0.08725616476695056], [0.594671952620179], [2.3305680689601704], [-2.022525268938578], [0.338293449283811], [-0.5857374064910154], [0.10862104004498124], [0.33295223046430344], [0.33295223046430344], [0.39170563747888776], [-1.3335080412220888], [0.7816146113029474], [-0.014226992803695085], [-1.2587309777489815], [-0.7406327522567377], [0.0658912894889201], [0.5893307338006715], [-0.831433472188368], [-1.0183761308711365], [-2.7008600590160516], [-0.6765381264226457], [-0.831433472188368], [0.10862104004498124], [0.5359185456055947], [-0.11571015037434074], [-1.1305417260807975], [0.3756819810203646], [0.18339810351808866], [0.6480841408152558], [-0.09968649391581771], [1.34778380617076], [-1.4937446058073187], [0.16203322824005797], [0.22078663525464223], [0.2314690728936576], [-0.6444908135055997], [0.5092124515080563], [0.27419882344971896], [-0.4895954677398774], [-0.9008693168419678], [-1.1732714766368588], [0.9365099570686698], [0.0979386024059659], [-0.9168929733004908], [-0.23855818322301706], [2.7525243557012766], [0.1994217599766118], [0.2848812610887343], [2.5228519464624473], [-0.25458183968153997], [-0.3934535289887393], [0.22612785407415004], [0.48250635741051806], [0.8350267994980242], [-0.7833625028127991], [3.82076811960281], [0.5359185456055947], [0.194080541157104], [0.26351638581070363], [-1.0984944131637513], [-0.5323252182959387], [-0.5643725312129847], [-1.1145180696222745], [-1.3228256035830734], [0.7762733924834396], [-0.7246090957982148], [-0.16912233856941733], [1.043334333458823], [0.963216051166208], [0.8991214253321159], [0.10327982122547369], [-0.046274305720741114], [0.023161538932858737], [0.05520885184990477], [-1.1198592884417822], [0.27954004226922674], [0.10862104004498124], [0.41841173157642597], [0.4558002633129798], [0.21544541643513468], [-1.4510148552512574], [-0.3293589031546474], [-0.302652809057109], [0.8991214253321159], [-0.14241624447187898], [1.0700404275563613], [0.963216051166208], [-0.430842060725293], [0.562624639703133], [1.0379931146393155], [-1.0931531943442439], [0.07123250830842766], [0.8136619242199935], [0.7282024231078708], [0.34363466810331883], [-1.2320248836514431], [-0.6765381264226457], [-0.6017610629495384], [0.6587665784542711], [0.883097768873593], [0.2314690728936576], [-0.46288937364233906], [-1.8355826102558097], [-0.024909430442710427], [2.2824970995846017], [-0.4522069360033237], [-0.4575481548228314], [-1.2213424460124278], [1.2302769921415917], [0.012479101293843393], [-0.8581395662859064], [1.1501587098489765], [1.1394762722099614], [-0.42550084190578535], [1.2569830862391298], [-1.087811975524736], [-0.23855818322301706], [0.9258275194296545], [0.27954004226922674], [-0.3827710913497241], [-1.0771295378857206], [-0.4522069360033237], [-0.4735718112813544], [-0.1798047762084327], [-0.09434527509631005], [-0.7566564087152606], [0.0017966636548280492], [-0.046274305720741114], [0.30090491754725746], [-0.3293589031546474], [-0.7085854393396918], [0.8190031430395011], [1.50802037075599], [-0.174463557388925], [0.9685572699857158], [-0.040933086901233325], [-0.9916700367735981], [0.1406683529620273], [-0.6124435005885538], [-1.05576466260769], [0.48250635741051806], [-0.11571015037434074], [0.04986763303039698], [0.8029794865809781], [0.5572834208836255], [1.2783479615171605], [-1.8035352973387633], [-0.8154098157298452], [-1.5418155751828877], [1.331760149712237], [0.5252361079665794], [-0.29731159023760134], [-2.1881030523433154], [-0.5643725312129847], [-2.2895862099139612], [-1.3869202294171654], [-2.0065016124800548], [0.8724153312345777], [0.7175199854688553], [0.8029794865809781], [-1.2907782906660275], [0.15135079060104262], [0.9365099570686698], [0.29022247990824207], [-0.2332169644035094], [0.05520885184990477], [2.3946626947942633], [-0.07832161863778703], [0.20476297879611935], [-0.25458183968153997], [0.6854726725518093], [-0.3293589031546474], [1.1020877404734075], [-1.0450822249686746], [0.11396225886448903], [0.23681029171316537], [-0.30799402787661667], [-0.446865717183816], [1.1234526157514382], [-0.019568211623202637], [-0.03025064926221798], [-0.6124435005885538], [0.44511782567396446], [-0.003544555164679741], [1.9727064080531571], [-2.487211306235745], [0.594671952620179], [-1.1732714766368588], [0.8136619242199935], [-0.543007655934954], [0.7655909548444243], [1.5667737777705746], [0.8884389876931006], [-0.23855818322301706], [-0.1798047762084327], [0.7388848607468861], [1.7109866858972813], [-1.6860284833095949], [0.963216051166208], [1.315736493253714], [-0.25458183968153997], [-1.1732714766368588], [-0.3560649972521857], [1.3371013685317445], [-0.5216427806569233], [-0.5163015618374157], [1.8071286246484197], [0.3756819810203646], [-0.9703051614955673], [0.7495672983859014], [-1.0984944131637513], [0.15669200942055042], [-0.5376664371154464], [-1.1625890389978435], [-0.40413596662775464], [0.7495672983859014], [-0.2759467149595706], [-1.9370657678264551], [-0.7192678769787071], [2.85934873209143], [0.5359185456055947], [1.5614325589510665], [-0.16378111974990966], [-1.2266836648319355], [0.338293449283811], [0.2581751669911961], [-1.4349911987927344], [0.9044626441516238], [0.8617328935955624], [-1.4937446058073187], [0.9258275194296545], [-1.5792041069194414], [-1.0130349120516287], [-0.5643725312129847], [0.674790234912794], [-0.5216427806569233], [-0.847457128646891], [-0.943599067398029], [0.32761101164479567], [-2.3643632733870685], [-0.30799402787661667], [0.27954004226922674], [-0.29731159023760134], [0.1994217599766118], [-0.4094771854472623], [-0.847457128646891], [-0.7406327522567377], [0.338293449283811], [0.039185195391381634], [0.4931887950495334], [-0.14241624447187898], [0.13532713414251973], [1.459949401380421], [-0.4522069360033237], [-0.3774298725302164], [-0.4575481548228314], [-0.6818793452421534], [-0.6498320323251074], [0.24215151053267292], [-0.1798047762084327], [-0.302652809057109], [0.6587665784542711], [-1.328166822402581], [0.642742921995748], [1.203570898044053], [0.20476297879611935], [0.6106956090787021], [1.50802037075599], [0.8937802065126084], [0.7282024231078708], [0.3489758869228264], [-0.847457128646891], [0.27419882344971896], [1.7964461870094042], [2.0154361586092184], [-2.241515240538392], [-0.35072377843267805], [-0.4361832795448007], [-0.2492406208620324], [1.7056454670777739], [0.2955636987277496], [-0.3453825596131704], [0.04986763303039698], [0.4130705127569184], [0.3863644186593799], [-0.5536900935739694], [0.3115873551862728], [0.7816146113029474], [-1.1732714766368588], [-0.47891303010086206], [-0.8207510345493527], [0.851050455956547], [-0.8955280980224601], [-0.33470012197415505], [0.9204863006101467], [0.23681029171316537], [0.03384397657187408], [1.0700404275563613], [0.7495672983859014], [-0.8688220039249217], [0.2848812610887343], [-0.12105136919384829], [-0.8688220039249217], [-0.6124435005885538], [0.09259738358645835], [0.6961551101908247], [-0.03559186808172577], [-2.636765433181959], [0.3222697928252881], [-0.2919703714180937], [-0.9809875991345828], [-1.05576466260769], [-0.7139266581591994], [2.2397673490285404], [0.15135079060104262], [0.2581751669911961], [0.5679658585226408], [-0.9809875991345828], [-0.4361832795448007], [1.593479871868113], [-0.5323252182959387], [-0.21719330794498637], [0.6854726725518093], [0.39170563747888776], [-0.42550084190578535], [-0.959622723856552], [-0.5483488747544617], [0.06055007066941232], [-1.135882944900305], [-0.003544555164679741], [-0.703244220520184], [-0.687220564061661], [0.07657372712793545], [0.27419882344971896], [0.4290941692154413], [-0.591078625310523], [-0.6444908135055997], [-0.20651087030597104], [-1.3708965729586426], [-0.14775746329138664], [-0.22787574558400173], [0.0017966636548280492], [-1.9210421113679321], [-1.3548729165001194], [-1.4723797305292883], [0.21544541643513468], [0.4290941692154413], [-0.5483488747544617], [0.39170563747888776], [0.6320604843567326], [-0.4522069360033237], [1.7911049681898965], [0.8724153312345777], [0.04986763303039698], [-1.1786126954563663], [0.4130705127569184], [-0.430842060725293], [0.4931887950495334], [-0.8527983474663987], [-0.318676465515632], [0.2688576046302114], [-1.1999775707343971], [-0.5269839994764309], [-1.520450699904857], [-0.008885773984187294], [-0.4522069360033237], [-0.398794747808247], [-1.3708965729586426], [1.2195945545025761], [-0.7887037216323066], [-0.37208865371070876], [-0.37208865371070876], [1.6255271847851587], [0.8296855806785164], [-0.5269839994764309], [-0.1370750256523713], [-0.33470012197415505], [0.5679658585226408], [0.07657372712793545], [3.008902859037645], [1.1715235851270072], [-1.1839539142758742], [-0.23855818322301706], [-0.7513151898957531], [-0.2332169644035094], [-0.6658556887836303], [0.851050455956547], [0.12464469650350438], [-0.3400413407936627], [0.626719265537225], [0.044526414210889424], [-0.575054968852], [0.6106956090787021], [1.6575744977022049], [0.16203322824005797], [0.5252361079665794], [0.4558002633129798], [-0.37208865371070876], [-0.9809875991345828], [0.023161538932858737], [-0.16378111974990966], [-0.6284671570470768], [-1.5097682622658417], [-1.9584306431044858], [0.3970468562983953], [0.8296855806785164], [-1.3869202294171654], [0.8083207054004856], [0.4771651385910105], [-0.863480785105414], [-0.2492406208620324], [-0.847457128646891], [-0.510960343017908], [-0.4842542489203697], [0.4290941692154413], [1.1928884604050378], [-0.046274305720741114], [-0.158439900930402], [-0.959622723856552], [0.29022247990824207], [0.27419882344971896], [-0.008885773984187294], [-0.767338846354276], [-0.9008693168419678], [0.5679658585226408], [-0.41481840426677], [0.642742921995748], [-1.0343997873296595], [0.4023880751179031], [1.7270103423558045], [-0.9489402862175367], [0.7175199854688553], [0.46114148213248735], [-0.7726800651737837], [-1.2747546342075045], [-0.3774298725302164], [0.40772929393741064], [-1.0130349120516287], [-0.37208865371070876], [2.6724060734086614], [0.8083207054004856], [1.2463006486001142], [-1.3068019471245504], [1.5347264648535284], [-0.8421159098273834], [-0.6765381264226457], [0.11930347768399659], [-0.19048721384744802], [-0.6444908135055997], [-0.11571015037434074], [-0.6017610629495384], [-1.6593223892120565], [-0.6338083758665843], [2.7097946051452153], [-0.398794747808247], [-0.20116965148646337], [2.3946626947942633], [-0.623125938227569], [0.07123250830842766], [1.2409594297806068], [0.8563916747760548], [0.12464469650350438], [-0.655173251144615], [0.514553670327564], [0.16203322824005797], [0.5893307338006715], [0.4397766068544567], [-0.14775746329138664], [-0.42550084190578535], [-0.11036893155483306], [0.4718239197715027], [0.9365099570686698], [0.7602497360249167], [1.6575744977022049], [-0.31333524669612434], [0.16203322824005797], [1.8445171563849732], [-0.06229796217926401], [-1.0611058814271976], [0.10862104004498124], [0.7014963290103324], [-0.49493668655938505], [-0.2118520891254787], [-0.6765381264226457], [0.7175199854688553], [0.2848812610887343], [0.7762733924834396], [-1.6219338574755027], [-0.4575481548228314], [-0.20116965148646337], [1.1608411474879916], [-0.6765381264226457], [-0.6979030017006763], [0.0658912894889201], [-0.543007655934954], [-1.424308761153719], [1.3424425873512527], [0.3756819810203646], [-0.03025064926221798], [-0.286629152598586], [0.081914945947443], [-0.4895954677398774], [-0.3934535289887393], [0.5305773267860869], [-0.6711969076031381], [-2.1079847700507006], [-1.7020521397681179], [-1.2106600083734125], [-0.07298039981827936], [-0.9916700367735981], [-0.2492406208620324], [-0.6444908135055997], [-1.0984944131637513], [-1.424308761153719], [-0.959622723856552], [0.562624639703133], [-0.5323252182959387], [-0.3400413407936627], [0.23681029171316537], [-2.166738177065285], [1.0646992087368536], [-0.28128793377907835], [1.2142533356830685], [-0.7887037216323066], [-0.8688220039249217], [0.21010419761562713], [1.3264189308927294], [0.7495672983859014], [0.0017966636548280492], [-0.158439900930402], [0.10327982122547369], [0.07123250830842766], [1.0273106770002998], [0.3115873551862728], [0.5839895149811637], [-0.7833625028127991], [-0.1798047762084327], [0.2581751669911961], [2.3572741630577094], [0.8350267994980242], [-0.9809875991345828], [-0.607102281769046], [0.194080541157104], [-0.559031312393477], [0.8991214253321159], [-0.2919703714180937], [-1.6593223892120565], [0.02850275775236629], [0.34363466810331883], [-1.8088765161582712], [-1.9477482054654707], [-0.24389940204252475], [-0.07832161863778703], [-1.3655553541391348], [0.8029794865809781], [-1.2907782906660275], [-0.49493668655938505], [-1.1252005072612896], [-0.7192678769787071], [-0.575054968852], [-1.456356074070765], [-0.5269839994764309], [0.25283394817168825], [-0.046274305720741114], [-0.9542815050370443], [2.60831144757457], [0.2688576046302114], [0.5466009832446102], [-0.2759467149595706], [0.42375295039593375], [0.1994217599766118], [-0.25992305850104763], [-1.9958191748410397], [-0.37208865371070876], [-0.40413596662775464], [0.4290941692154413], [-0.7139266581591994], [0.27954004226922674], [-0.6818793452421534], [-1.2907782906660275], [0.4397766068544567], [-0.943599067398029], [-0.9275754109395061], [0.306246136366765], [1.1234526157514382], [0.6374017031762405], [0.6854726725518093], [-1.0824707567052285], [0.5893307338006715], [-0.12105136919384829], [-1.5471567940023956], [2.1543078479164177], [-2.236174021718884], [0.9204863006101467], [-1.1252005072612896], [-1.1519066013588282], [-0.09434527509631005], [0.18873932233759644], [0.012479101293843393], [-1.0824707567052285], [1.9513415327751265], [-0.430842060725293], [-0.3400413407936627], [-0.07298039981827936], [0.4771651385910105], [1.5827974342290974], [0.12998591532301193], [-0.9062105356614755], [0.9952633640832541], [1.1768648039465146], [0.11930347768399659], [-0.11036893155483306], [-0.9062105356614755], [1.497337933116975], [0.27419882344971896], [-0.6124435005885538], [-0.2492406208620324], [2.116919316179864], [-0.5964198441300307], [-0.5376664371154464], [1.3264189308927294], [0.8083207054004856], [0.8083207054004856], [0.8083207054004856], [-0.08900405627680237], [-0.6818793452421534], [-0.4895954677398774], [0.3970468562983953], [-0.5697137500324924], [0.5252361079665794], [-0.6284671570470768], [-0.41481840426677], [-0.7352915334372301], [2.207720036111495], [0.0658912894889201], [0.9685572699857158], [-0.959622723856552], [-0.6765381264226457], [-0.6711969076031381], [-2.1560557394262694], [-1.9103596737289168], [-0.3560649972521857], [-0.19048721384744802], [0.2955636987277496], [-0.5163015618374157], [1.4011959943658368], [0.3222697928252881], [-1.0023524744126133], [-0.22253452676449406], [0.8777565500540855], [0.963216051166208], [-1.2106600083734125], [1.433243307282883], [-0.014226992803695085], [-0.2652642773205553], [-1.2213424460124278], [-2.0278664877580854], [-0.767338846354276], [1.34778380617076], [0.5519422020641177], [-0.3827710913497241], [0.10862104004498124], [0.674790234912794], [1.9299766574970958], [-1.1145180696222745], [-0.1050277127353254], [-0.0836628374572947], [0.15669200942055042], [-1.1305417260807975], [1.1608411474879916], [-0.174463557388925], [0.02850275775236629], [-1.408285104695196], [0.786955830122455], [-0.2118520891254787], [-1.2694134153879966], [-0.46823059246184673], [-0.2492406208620324], [-1.814217734977779], [-0.398794747808247], [0.16737444705956575], [-0.42550084190578535], [0.42375295039593375], [-0.5643725312129847], [0.07657372712793545], [-2.535282275611314], [0.3863644186593799], [-0.05161552454024867], [0.40772929393741064], [0.6641077972737787], [0.8029794865809781], [-2.161396958245777], [-0.6711969076031381], [1.7911049681898965], [0.5359185456055947], [-2.2254915840798692], [0.626719265537225], [0.9845809264442387], [-0.44152449836430835], [0.46114148213248735], [-0.19582843266695568], [0.7388848607468861], [0.4718239197715027], [-0.3453825596131704], [0.12998591532301193], [0.13532713414251973], [-0.14775746329138664], [-1.6913697021291023], [-1.8302413914363018], [-0.430842060725293], [-0.6658556887836303], [-1.8676299231728555], [0.3489758869228264], [0.642742921995748], [0.2955636987277496], [0.8350267994980242], [-0.3400413407936627], [-0.2332169644035094], [-0.7619976275347684], [-0.2652642773205553], [0.1994217599766118], [-0.6124435005885538], [1.0379931146393155], [1.0807228651953769], [-0.05161552454024867], [-1.1412241637198128], [1.2302769921415917], [0.03384397657187408], [0.0017966636548280492], [-0.286629152598586], [-0.430842060725293], [0.7495672983859014], [-0.16912233856941733], [-0.286629152598586], [-0.7139266581591994], [2.266473443126079], [1.716327904716789], [-0.2919703714180937], [-0.1370750256523713], [1.8551995940239887], [-0.14241624447187898], [0.5519422020641177], [-0.2118520891254787], [0.5572834208836255], [0.03384397657187408], [-1.9210421113679321], [-1.6219338574755027], [0.3970468562983953], [-0.8848456603834448], [1.3424425873512527], [0.10862104004498124], [2.832642637993892], [-0.7139266581591994], [0.0017966636548280492], [0.31692857400578034], [-0.5002779053788927], [0.7495672983859014], [0.5092124515080563], [0.43443538803494913], [-1.0237173496906442], [0.0658912894889201], [-0.8047273780908298], [1.5187028083950056], [0.0017966636548280492], [-0.8688220039249217], [-1.3335080412220888], [-0.6711969076031381], [-1.8783123608118708], [0.5359185456055947], [-0.30799402787661667], [0.8136619242199935], [2.21840247375051], [-0.9275754109395061], [-0.687220564061661], [0.9204863006101467], [0.29022247990824207], [0.31692857400578034], [0.13532713414251973], [0.7816146113029474], [-0.3240176843351397], [1.9940712833311878], [-0.20651087030597104], [0.9792397076247311], [-0.302652809057109], [1.2836891803366681], [-0.14241624447187898], [0.7335436419273785], [2.2718146619455863], [1.7430339988143277], [-0.6818793452421534], [2.2771558807650942], [-0.7085854393396918], [-2.6634715272794978], [-0.27060549614006296], [-1.9050184549094094], [-1.1625890389978435], [0.5679658585226408], [2.0635071279847876], [2.6296763228526], [-0.8154098157298452], [0.2314690728936576], [1.1715235851270072], [0.012479101293843393], [-1.1999775707343971], [-0.174463557388925], [1.0860640840148843], [0.41841173157642597], [-0.5002779053788927], [0.4023880751179031], [0.5412597644251023], [2.2771558807650942], [0.5893307338006715], [-0.5323252182959387], [0.3115873551862728], [1.9406590951361113], [-0.5964198441300307], [-0.22253452676449406], [-0.40413596662775464], [-0.9703051614955673], [0.3810231998398724], [0.6961551101908247], [-1.2907782906660275], [-1.4349911987927344], [0.70683754782984], [-0.42550084190578535], [-1.8783123608118708], [0.4771651385910105], [0.15135079060104262], [-0.158439900930402], [-0.6017610629495384], [0.626719265537225], [0.851050455956547], [1.0273106770002998], [1.8445171563849732], [0.012479101293843393], [-0.6498320323251074], [-1.7661467656022098], [-0.27060549614006296], [0.3810231998398724], [-0.06229796217926401], [2.068848346804295], [-1.5471567940023956], [0.26351638581070363], [1.89792934458005], [-0.7726800651737837], [0.18873932233759644], [-0.302652809057109], [-0.7940449404518145], [-0.03025064926221798], [0.8190031430395011], [0.23681029171316537], [-0.3614062160716934], [-0.1530986821108943], [0.7816146113029474], [0.21010419761562713], [1.7697400929118658], [2.2130612549310027], [1.7590576552728503], [-0.6177847194080615], [0.6480841408152558], [-1.2747546342075045], [0.9204863006101467], [-1.1145180696222745], [-0.2492406208620324], [1.2249357733220836], [-0.7192678769787071], [-0.18514599502794035], [-0.6925617828811687], [0.07123250830842766], [-0.6765381264226457], [0.017820320113350947], [1.1501587098489765], [-0.7833625028127991], [0.40772929393741064], [0.9471923947076851], [-0.286629152598586], [-0.24389940204252475], [-0.7566564087152606], [0.2848812610887343], [-0.4735718112813544], [2.6189938852135852], [1.2890303991561756], [-0.943599067398029], [0.012479101293843393], [0.8991214253321159], [-1.1412241637198128], [-1.0130349120516287], [1.7109866858972813], [-0.05695674335975634], [2.132942972638387], [-1.0397410061491672], [-0.8207510345493527], [2.2771558807650942], [-0.07298039981827936], [1.2356182109610991], [0.7228612042883632], [2.5068282900039236], [-3.373853630274018], [0.1780568846985811], [2.245108567848048], [-0.6498320323251074], [0.514553670327564], [0.786955830122455], [-2.1881030523433154], [-0.510960343017908], [1.2836891803366681], [-0.42550084190578535], [0.6801314537323018], [-0.20651087030597104], [0.8991214253321159], [0.18873932233759644], [0.6160368278982097], [-1.1091768508027668], [-0.591078625310523], [-0.42550084190578535], [-0.35072377843267805], [-0.19582843266695568], [-0.2118520891254787], [-0.20116965148646337], [-1.6593223892120565], [0.9738984888052233], [0.5305773267860869], [-1.2961195094855351], [-0.7566564087152606], [-0.16378111974990966], [-1.1305417260807975], [3.879521526617394], [-1.1519066013588282], [-0.18514599502794035], [-0.8848456603834448], [0.11396225886448903], [-0.6658556887836303], [-0.008885773984187294], [-0.0836628374572947], [1.2516418674196224], [0.4718239197715027], [-0.7513151898957531], [-1.1412241637198128], [0.4931887950495334], [1.4546081825609136], [1.1768648039465146], [0.9578748323467005], [0.851050455956547], [1.043334333458823], [-0.9382578485785213], [1.1501587098489765], [-0.05161552454024867], [-2.2094679276213465], [0.5305773267860869], [-0.3453825596131704], [-0.863480785105414], [-1.1412241637198128], [-0.3560649972521857], [-2.0919611135921774], [-1.60591020101698], [-0.6391495946860921], [-0.14241624447187898], [1.4492669637414055], [1.0700404275563613], [-0.4201596230862777], [-2.2094679276213465], [-0.44152449836430835], [2.3305680689601704], [0.41841173157642597], [-1.135882944900305], [-0.11571015037434074], [0.8296855806785164], [-0.4094771854472623], [0.039185195391381634], [0.11930347768399659], [0.20476297879611935], [-2.241515240538392], [-0.12105136919384829], [-0.2652642773205553], [-0.019568211623202637], [-0.959622723856552], [2.175672723194449], [-0.24389940204252475], [1.9833888456921722], [-1.1786126954563663], [2.234426130209033], [-0.19048721384744802], [0.03384397657187408], [-1.0664471002467053], [-0.4575481548228314], [2.7792304497988147], [0.49853001386904094], [-0.9970112555931058], [-0.18514599502794035], [0.6160368278982097], [0.2314690728936576], [1.1608411474879916], [0.194080541157104], [-0.7726800651737837], [-0.318676465515632], [-0.23855818322301706], [-0.11036893155483306], [0.1780568846985811], [-1.461697292890273], [0.4558002633129798], [0.34363466810331883], [-0.543007655934954], [-0.398794747808247], [-0.9382578485785213], [0.9471923947076851], [0.4023880751179031], [-0.19582843266695568], [-0.703244220520184], [0.25283394817168825], [0.6641077972737787], [0.6053543902591944], [-0.7726800651737837], [2.2023788172919865], [0.10862104004498124], [-0.19582843266695568], [-0.430842060725293], [0.007137882474335602], [-0.12639258801335596], [-0.623125938227569], [0.7388848607468861], [0.5359185456055947], [-0.703244220520184], [0.11396225886448903], [-0.3400413407936627], [-1.0130349120516287], [-0.1798047762084327], [-0.8741632227444294], [-0.03025064926221798], [0.8777565500540855], [-0.1050277127353254], [0.3756819810203646], [-1.4189675423342114], [-0.9916700367735981], [-0.1798047762084327], [-0.9756463803150751], [1.9566827515946341], [-1.0771295378857206], [-0.4735718112813544], [-0.7566564087152606], [-0.3934535289887393], [0.450459044493472], [-0.25992305850104763], [0.4878475762300256], [-0.16912233856941733], [-0.8688220039249217], [2.6777472922281693], [-0.7993861592713221], [-0.1050277127353254], [-0.7887037216323066], [1.0166282393612847], [-0.06229796217926401], [-0.6979030017006763], [-1.280095853027012], [0.4290941692154413], [-0.13173380683286362], [1.1020877404734075], [1.6896218106192507], [1.321077712073222], [-0.4361832795448007], [1.5293852460340207], [-0.44152449836430835], [0.20476297879611935], [0.40772929393741064], [-0.943599067398029], [-0.158439900930402], [-0.1798047762084327], [1.1448174910294688], [0.7602497360249167], [-0.959622723856552], [-1.8676299231728555], [0.5412597644251023], [-1.1892951330953816], [-0.3453825596131704], [-0.4735718112813544], [-0.8207510345493527], [-0.44152449836430835], [0.194080541157104], [2.7525243557012766], [2.854007513271922], [-1.2053187895539048], [1.2302769921415917], [-0.286629152598586], [-0.25992305850104763], [0.25283394817168825], [0.4771651385910105], [-2.1881030523433154], [1.3424425873512527], [0.5359185456055947], [0.9418511758881773], [-1.0343997873296595], [-0.19582843266695568], [0.02850275775236629], [0.3489758869228264], [1.1234526157514382], [0.3863644186593799], [-0.38811231016923164], [-0.302652809057109], [0.16737444705956575], [-0.44152449836430835], [1.0700404275563613], [0.5412597644251023], [0.9204863006101467], [-0.07832161863778703], [-0.430842060725293], [-0.14241624447187898], [-0.5964198441300307], [0.5038712326885487], [0.07123250830842766], [-0.5643725312129847], [-0.7566564087152606], [-3.1975934092302647], [-0.9916700367735981], [-0.446865717183816], [-0.6979030017006763], [-0.8527983474663987], [0.23681029171316537], [-2.214809146440854], [-0.543007655934954], [0.04986763303039698], [0.3115873551862728], [-1.4349911987927344], [2.6724060734086614], [0.3489758869228264], [-0.9916700367735981], [-1.6753460456705795], [0.786955830122455], [-0.9489402862175367], [-1.1786126954563663], [1.9566827515946341], [0.3596583245618417], [1.3264189308927294], [-0.25992305850104763], [1.9086117822190651], [-0.655173251144615], [1.6629157165217126], [-0.286629152598586], [0.044526414210889424], [-0.27060549614006296], [0.3756819810203646], [0.42375295039593375], [-0.03025064926221798], [-0.8581395662859064], [0.3863644186593799], [-0.11571015037434074], [0.754908517205409], [0.044526414210889424], [-0.6284671570470768], [0.044526414210889424], [-0.20116965148646337], [1.3905135567268216], [0.8457092371370395], [-0.655173251144615], [-0.8367746910078757], [1.5667737777705746], [0.450459044493472], [0.8884389876931006], [0.10327982122547369], [-0.6284671570470768], [0.15135079060104262], [0.6160368278982097], [0.23681029171316537], [1.155499928668484], [0.8029794865809781], [-0.510960343017908], [0.4664827009519951], [-2.369704492206576], [-0.943599067398029], [-0.703244220520184], [0.41841173157642597], [0.786955830122455], [-0.7406327522567377], [-0.5323252182959387], [-1.6539811703925489], [0.16737444705956575], [-1.4723797305292883], [-0.8207510345493527], [-0.19582843266695568], [-0.5483488747544617], [0.7335436419273785], [-0.9756463803150751], [1.4546081825609136], [0.1727156658790733], [0.8243443618590088], [-1.2747546342075045], [0.4558002633129798], [0.642742921995748], [-2.0065016124800548], [0.15135079060104262], [-1.2694134153879966], [-0.2118520891254787], [-1.3869202294171654], [-1.2266836648319355], [-0.14241624447187898], [-2.193444271162823], [-0.4895954677398774], [1.780422530550881], [-1.0290585685101519], [0.16203322824005797], [-0.9008693168419678], [-0.4575481548228314], [0.7228612042883632], [1.0326518958198079], [0.9204863006101467], [0.642742921995748], [0.7602497360249167], [-0.2118520891254787], [1.1394762722099614], [-1.5845453257389492], [1.3744899002682984], [0.40772929393741064], [1.0006045829027619], [-1.6806872644900872], [1.4225608696438674], [-2.0652550194946393], [1.593479871868113], [-0.7566564087152606], [1.321077712073222], [0.18339810351808866], [-0.3293589031546474], [0.6641077972737787], [-0.03559186808172577], [0.26351638581070363], [2.3305680689601704], [0.21010419761562713], [0.6053543902591944], [-1.632616295114518], [-0.9062105356614755], [0.3970468562983953], [0.29022247990824207], [0.25283394817168825], [-0.46288937364233906], [0.14600957178153506], [0.40772929393741064], [0.48250635741051806], [2.1276017538188796], [-0.18514599502794035], [-0.8154098157298452], [-0.20651087030597104], [0.306246136366765], [1.6468920600631893], [-2.6047181202649132], [1.7697400929118658], [-0.18514599502794035], [0.23681029171316537], [-1.0931531943442439], [-1.280095853027012], [-0.8848456603834448], [2.191696379652971], [-0.14775746329138664], [-0.7406327522567377], [-0.7192678769787071], [0.48250635741051806], [-0.024909430442710427], [0.20476297879611935], [1.2463006486001142], [0.31692857400578034], [-0.08900405627680237], [-0.5536900935739694], [-0.24389940204252475], [2.132942972638387], [0.338293449283811], [-0.05695674335975634], [-0.4735718112813544], [-0.318676465515632], [-0.5803961876715077], [0.24749272935218072], [-0.6124435005885538], [-0.4094771854472623], [-0.158439900930402], [-0.4201596230862777], [-1.4937446058073187], [0.8777565500540855], [-0.9329166297590137], [1.4172196508243597], [2.0207773774287263], [0.6854726725518093], [-0.6925617828811687], [-0.22253452676449406], [2.854007513271922], [-0.9168929733004908], [-0.2759467149595706], [1.8071286246484197], [-0.2118520891254787], [0.4558002633129798], [-0.003544555164679741], [0.5893307338006715], [0.007137882474335602], [0.5305773267860869], [0.06055007066941232], [-1.2373661024709508], [1.2463006486001142], [-0.7406327522567377], [-0.5056191241984004], [-0.9970112555931058], [-0.03025064926221798], [-0.019568211623202637], [1.0540167710978385], [1.673598154160728], [-0.2332169644035094], [1.1287938345709458], [-0.8955280980224601], [0.5466009832446102], [-0.44152449836430835], [-0.5269839994764309], [2.4480748829893395], [0.8136619242199935], [0.0979386024059659], [-1.2587309777489815], [0.5038712326885487], [0.963216051166208], [-0.03559186808172577], [-1.9637718619239934], [-0.16912233856941733], [0.21010419761562713], [-0.6605144699641228], [0.194080541157104], [0.7922970489419627], [-0.7299503146177224], [0.306246136366765], [3.1691394236228745], [-0.6338083758665843], [1.1448174910294688], [0.10862104004498124], [-0.9489402862175367], [0.963216051166208], [-0.7459739710762454], [0.5572834208836255], [0.007137882474335602], [-0.559031312393477], [-1.6219338574755027], [0.5412597644251023], [1.155499928668484], [-0.6605144699641228], [-0.8260922533688604], [-1.1412241637198128], [0.13532713414251973], [0.4130705127569184], [-0.12105136919384829], [0.007137882474335602], [-1.328166822402581], [-0.06229796217926401], [-0.07832161863778703], [0.09259738358645835], [-0.9703051614955673], [0.8296855806785164], [-0.6498320323251074], [-1.53647435636338], [-0.31333524669612434], [0.09259738358645835], [0.16737444705956575], [-0.7352915334372301], [-1.1839539142758742], [0.12998591532301193], [0.20476297879611935], [0.11396225886448903], [1.2409594297806068], [-1.6646636080315642], [-0.22253452676449406], [-0.1798047762084327], [-1.0290585685101519], [1.0753816463758692], [-0.3614062160716934], [0.12464469650350438], [2.0314598150677416], [-0.398794747808247], [-0.23855818322301706], [-1.4777209493487957], [-0.6818793452421534], [-0.911551754480983], [-0.7406327522567377], [-0.7619976275347684], [-1.7928528596997482], [-0.8421159098273834], [-0.9275754109395061], [0.4718239197715027], [0.34363466810331883], [0.044526414210889424], [1.5347264648535284], [0.5092124515080563], [-1.1892951330953816], [3.2599401435545046], [0.754908517205409], [1.2463006486001142], [0.5786482961616561], [-0.008885773984187294], [0.1780568846985811], [1.0807228651953769], [-1.1465653825393203], [-1.5952277633779646], [0.21010419761562713], [0.6961551101908247], [-0.847457128646891], [-0.3240176843351397], [-0.20651087030597104], [1.9940712833311878], [0.9899221452637466], [1.5881386530486052], [0.9258275194296545], [1.1341350533904533], [-1.3815790105976578], [0.8670741124150702], [-1.3174843847635658], [0.9044626441516238], [-1.4189675423342114], [0.012479101293843393], [-0.3400413407936627], [0.44511782567396446], [-0.5323252182959387], [0.5412597644251023], [-2.0332077065775933], [0.7922970489419627], [0.194080541157104], [0.7442260795663939], [0.22078663525464223], [2.245108567848048], [2.688429729867184], [0.12464469650350438], [1.673598154160728], [0.46114148213248735], [-0.11571015037434074], [-0.46288937364233906], [-1.3228256035830734], [-0.6124435005885538], [1.0166282393612847], [2.3572741630577094], [0.42375295039593375], [0.11396225886448903], [-0.12105136919384829], [0.594671952620179], [0.8350267994980242], [-1.7394406715046713], [-0.2919703714180937], [-0.5056191241984004], [0.4290941692154413], [0.642742921995748], [-0.4361832795448007], [-0.6605144699641228], [-0.7726800651737837], [-0.8207510345493527], [-1.1145180696222745], [-0.5964198441300307], [0.4397766068544567], [0.754908517205409], [-1.4830621681683036], [-0.16378111974990966], [-0.33470012197415505], [0.8991214253321159], [0.05520885184990477], [1.8124698434679272], [0.2581751669911961], [-1.3976026670561807], [-1.1465653825393203], [-0.9970112555931058], [-1.2106600083734125], [0.6587665784542711], [0.24749272935218072], [-0.9275754109395061], [-0.09968649391581771], [-1.2266836648319355], [1.2356182109610991], [0.6534253596347633], [-0.8154098157298452], [0.963216051166208], [-0.16912233856941733], [-0.05161552454024867], [-1.0611058814271976], [1.6308684036046666], [1.315736493253714], [2.1276017538188796], [-0.7459739710762454], [-0.1050277127353254], [1.6522332788826974], [0.4023880751179031], [-1.4937446058073187], [1.1501587098489765], [0.3115873551862728], [-0.3240176843351397], [1.497337933116975], [-0.19582843266695568], [1.5881386530486052], [-1.4456736364317497], [0.7762733924834396], [1.8178110622874348], [0.5252361079665794], [0.22612785407415004], [-0.23855818322301706], [1.1768648039465146], [0.42375295039593375], [-0.3614062160716934], [1.5988210906876203], [-1.3228256035830734], [-0.7887037216323066], [1.1287938345709458], [1.0700404275563613], [-0.7726800651737837], [-0.9649639426760597], [-2.1881030523433154], [-0.1050277127353254], [1.5026791519364826], [3.50029499043235], [-0.879504441563937], [0.8991214253321159], [0.07123250830842766], [2.512169508823431], [-0.7833625028127991], [-0.14241624447187898], [-0.1798047762084327], [1.9673651892336497], [1.1875472415855302], [1.2623243050586375], [1.1768648039465146], [0.8991214253321159], [0.11396225886448903], [0.5466009832446102], [-0.40413596662775464], [0.4023880751179031], [1.5026791519364826], [0.6534253596347633], [0.194080541157104], [-0.6124435005885538], [2.4854634147258934], [1.3371013685317445], [1.2943716179756832], [-0.1798047762084327], [-0.09968649391581771], [0.9578748323467005], [-0.607102281769046], [0.16203322824005797], [-0.9329166297590137], [-0.008885773984187294], [-0.623125938227569], [-0.7085854393396918], [0.26351638581070363], [2.2824970995846017], [-2.1079847700507006], [-2.636765433181959], [0.32761101164479567], [-0.07832161863778703], [0.23681029171316537], [0.5733070773421484], [1.6575744977022049], [-1.9210421113679321], [2.60831144757457], [-0.430842060725293], [-0.7246090957982148], [-1.7447818903241792], [2.971514327301091], [-0.767338846354276], [-1.1412241637198128], [2.421368788891801], [-1.4937446058073187], [1.6789393729802355], [-0.1370750256523713], [-1.573862888099934], [0.6374017031762405], [-1.2533897589294738], [0.06055007066941232], [0.3489758869228264], [-0.6338083758665843], [0.8029794865809781], [1.4172196508243597], [-0.703244220520184], [-0.4575481548228314], [1.1822060227660223], [-0.158439900930402], [-0.5163015618374157], [-0.6765381264226457], [-0.7406327522567377], [1.2516418674196224], [-1.7394406715046713], [-0.3560649972521857], [-0.40413596662775464], [-0.9008693168419678], [-1.344190478861104], [-1.1412241637198128], [0.18873932233759644], [0.42375295039593375], [0.6480841408152558], [-0.847457128646891], [0.8136619242199935], [0.338293449283811], [-0.6818793452421534], [-0.4094771854472623], [-0.3560649972521857], [-0.7726800651737837], [-1.5471567940023956], [-0.430842060725293], [0.18873932233759644], [-0.6444908135055997], [-0.1050277127353254], [0.0017966636548280492], [2.3679566006967243], [0.6641077972737787], [-0.767338846354276], [0.9098038629711314], [0.3115873551862728], [-1.6539811703925489], [0.4290941692154413], [-0.2652642773205553], [-0.22253452676449406], [2.2504497866675552], [-0.5643725312129847], [-0.158439900930402], [1.1181113969319307], [-0.9703051614955673], [1.0700404275563613], [-1.5044270434463343], [-0.7993861592713221], [1.0273106770002998], [0.8296855806785164], [-1.0237173496906442], [-0.7299503146177224], [-1.4990858246268264], [0.6213780467177172], [-1.0664471002467053], [-0.6391495946860921], [-0.6979030017006763], [0.8991214253321159], [-0.5216427806569233], [0.07657372712793545], [-0.8421159098273834], [-1.8355826102558097], [-0.6658556887836303], [-0.943599067398029], [-1.712734577407133], [-0.623125938227569], [-0.7139266581591994], [1.3424425873512527], [0.26351638581070363], [0.11396225886448903], [-0.7726800651737837], [0.48250635741051806], [1.6575744977022049], [-0.25992305850104763], [0.6694490160932864], [-0.5643725312129847], [0.883097768873593], [0.2688576046302114], [2.234426130209033], [-0.7192678769787071], [-0.1370750256523713], [-0.623125938227569], [0.338293449283811], [-1.8302413914363018], [-0.06229796217926401], [2.645699979311123], [-1.3335080412220888], [2.2023788172919865], [-1.3548729165001194], [-0.046274305720741114], [-1.0290585685101519], [-1.4937446058073187], [0.7762733924834396], [-1.248048540109966], [-1.0290585685101519], [-0.286629152598586], [-0.3774298725302164], [0.9792397076247311], [-1.1786126954563663], [0.6961551101908247], [0.6801314537323018], [-0.14241624447187898], [1.091405302834392], [-0.49493668655938505], [-0.046274305720741114], [-0.6391495946860921], [2.512169508823431], [-1.5845453257389492], [0.7922970489419627], [-0.559031312393477], [-0.19582843266695568], [1.2569830862391298], [-0.6391495946860921], [0.37034076220085704], [-1.1091768508027668], [0.03384397657187408], [-0.9542815050370443], [-0.5697137500324924], [-0.4575481548228314], [-0.46288937364233906], [0.5466009832446102], [1.6575744977022049], [0.754908517205409], [-0.318676465515632], [-0.13173380683286362], [-0.40413596662775464], [1.82849349992645], [0.13532713414251973], [-0.7940449404518145], [0.8029794865809781], [-0.174463557388925], [0.6908138913713171], [-1.4723797305292883], [0.963216051166208], [-0.24389940204252475], [0.5572834208836255], [-0.943599067398029], [0.23681029171316537], [2.9020784826474912], [1.6308684036046666], [0.4290941692154413], [0.8670741124150702], [0.20476297879611935], [-0.7459739710762454], [-0.003544555164679741], [0.5252361079665794], [-0.8741632227444294], [-0.6765381264226457], [-0.2652642773205553], [0.5679658585226408], [-0.2919703714180937], [0.8403680183175317], [-0.6124435005885538], [-0.29731159023760134], [1.9673651892336497], [-1.1999775707343971], [0.5893307338006715], [-0.4575481548228314], [-0.4361832795448007], [-1.3976026670561807], [0.3970468562983953], [-0.28128793377907835], [1.1020877404734075], [-0.07298039981827936], [-0.03025064926221798], [0.0658912894889201], [0.7014963290103324], [0.16203322824005797], [0.3222697928252881], [-0.7352915334372301], [1.2409594297806068], [1.2142533356830685], [0.3863644186593799], [-0.4895954677398774], [0.37034076220085704], [0.5733070773421484], [-1.456356074070765], [-0.5056191241984004], [-1.1198592884417822], [-0.24389940204252475], [1.1661823663074995], [-0.47891303010086206], [0.04986763303039698], [0.22612785407415004], [0.07123250830842766], [0.007137882474335602], [1.0166282393612847], [1.3584662438097752], [1.34778380617076], [1.5187028083950056], [-0.03559186808172577], [-0.8154098157298452], [2.042142252706757], [0.7228612042883632], [-0.08900405627680237], [-0.8367746910078757], [0.194080541157104], [-1.440332417612242], [0.7655909548444243], [0.4931887950495334], [-0.2759467149595706], [1.9246354386775884], [-0.21719330794498637], [0.0979386024059659], [0.07657372712793545], [0.044526414210889424], [0.562624639703133], [-0.831433472188368], [0.0658912894889201], [-2.214809146440854], [0.9258275194296545], [0.9792397076247311], [-1.4830621681683036], [1.267665523878145], [-0.5376664371154464], [0.963216051166208], [-1.3014607283050428], [-0.21719330794498637], [1.673598154160728], [-0.42550084190578535], [-0.14775746329138664], [-1.6700048268510717], [0.36499954338134927], [0.6534253596347633], [0.8296855806785164], [1.4225608696438674], [-2.711542496655067], [1.0273106770002998], [-0.16912233856941733], [-0.13173380683286362], [0.039185195391381634], [1.443925744921898], [0.4023880751179031], [-1.5898865445584567], [2.1649902855554335], [-0.31333524669612434], [0.2955636987277496], [0.21010419761562713], [-1.1786126954563663], [0.29022247990824207], [0.29022247990824207], [-0.27060549614006296], [2.912760920286506], [1.3264189308927294], [0.26351638581070363], [0.26351638581070363], [-1.3388492600415964], [-0.8581395662859064], [0.43443538803494913], [0.044526414210889424], [-0.008885773984187294], [-0.6444908135055997], [0.22612785407415004], [0.03384397657187408], [1.273006742697653], [1.4706318390194362], [-0.0836628374572947], [0.594671952620179], [0.3756819810203646], [-2.4337991180406684], [-0.019568211623202637], [-1.3174843847635658], [0.023161538932858737], [-1.0771295378857206], [-0.5163015618374157], [-1.5151094810853494], [2.175672723194449], [0.6480841408152558], [0.007137882474335602], [2.9608318896620753], [0.1780568846985811], [-0.847457128646891], [1.2836891803366681], [-0.6765381264226457], [0.562624639703133], [1.9246354386775884], [-0.8207510345493527], [-0.9542815050370443], [1.043334333458823], [-1.408285104695196], [1.0486755522783306], [-0.19582843266695568], [-0.6017610629495384], [0.18339810351808866], [0.9098038629711314], [0.34363466810331883], [-0.46823059246184673], [0.06055007066941232], [-0.6124435005885538], [0.7014963290103324], [-0.847457128646891], [0.18873932233759644], [-0.8955280980224601], [-1.5898865445584567], [0.8083207054004856], [0.02850275775236629], [-0.8207510345493527], [0.41841173157642597], [1.7376927799948196], [-0.2652642773205553], [-0.8100685969103374], [1.1928884604050378], [0.514553670327564], [-0.24389940204252475], [-0.5056191241984004], [0.05520885184990477], [-0.13173380683286362], [-0.6284671570470768], [0.49853001386904094], [-2.1774206147043], [-1.2373661024709508], [-0.11036893155483306], [-0.6765381264226457], [-1.2106600083734125], [0.6000131714396868], [-0.3240176843351397], [-0.831433472188368], [-0.19048721384744802], [-2.545964713250329], [-1.1572478201783356], [0.3115873551862728], [0.04986763303039698], [0.03384397657187408], [1.4546081825609136], [-0.1798047762084327], [1.1020877404734075], [-0.2492406208620324], [2.725818261603738], [-1.4296499799732267], [0.33295223046430344], [1.2516418674196224], [-0.2759467149595706], [-0.0836628374572947], [0.044526414210889424], [0.33295223046430344], [-0.27060549614006296], [1.3371013685317445], [0.22612785407415004], [-0.09968649391581771], [0.8670741124150702], [0.6374017031762405], [2.287838318404109], [-0.2919703714180937], [0.007137882474335602], [1.1501587098489765], [0.0017966636548280492], [0.2688576046302114], [-2.8504141859622663], [-0.40413596662775464], [-0.2759467149595706], [-0.11571015037434074], [1.443925744921898], [-1.1892951330953816], [-0.302652809057109], [-0.9649639426760597], [-0.37208865371070876], [0.9098038629711314], [-1.4830621681683036], [0.40772929393741064], [-0.4094771854472623], [-1.087811975524736], [-1.6646636080315642], [-0.08900405627680237], [1.1768648039465146], [1.1982296792245453], [-1.0450822249686746], [-0.7887037216323066], [-1.2266836648319355], [0.8243443618590088], [-0.4842542489203697], [0.31692857400578034], [1.0273106770002998], [1.6842805917997432], [0.9471923947076851], [0.6320604843567326], [0.9899221452637466], [0.5679658585226408], [-0.14775746329138664], [0.007137882474335602], [-0.06229796217926401], [0.7388848607468861], [0.3489758869228264], [0.1727156658790733], [-0.767338846354276], [0.6854726725518093], [-0.9008693168419678], [-0.8154098157298452], [0.8670741124150702], [-2.3643632733870685], [-1.0130349120516287], [1.5507501213120514], [0.1727156658790733], [1.3798311190878059], [-0.06763918099877168], [0.7495672983859014], [-0.302652809057109], [0.08725616476695056], [0.851050455956547], [-0.1050277127353254], [3.420176708139735], [-0.23855818322301706], [-0.008885773984187294], [-0.2118520891254787], [-1.2854370718465198], [0.012479101293843393], [0.18339810351808866], [-0.318676465515632], [-0.4895954677398774], [-0.06763918099877168], [1.267665523878145], [0.02850275775236629], [0.6374017031762405], [-1.440332417612242], [0.7442260795663939], [-0.911551754480983], [1.443925744921898], [-0.5857374064910154], [0.09259738358645835], [-0.37208865371070876], [-0.3293589031546474], [-0.4201596230862777], [1.4225608696438674], [-1.0130349120516287], [0.7388848607468861], [0.8190031430395011], [-1.6539811703925489], [-0.13173380683286362], [0.6694490160932864], [0.07123250830842766], [-0.09434527509631005], [0.7121787666493478], [-0.9970112555931058], [-0.5002779053788927], [-0.6605144699641228], [0.9098038629711314], [-1.6539811703925489], [-0.33470012197415505], [0.5572834208836255], [-0.703244220520184], [1.0593579899173462], [-1.2854370718465198], [0.1994217599766118], [0.4290941692154413], [0.7388848607468861], [-2.7596134660306357], [-0.20651087030597104], [1.1768648039465146], [0.43443538803494913], [0.306246136366765], [0.03384397657187408], [0.9738984888052233], [1.3584662438097752], [-1.1572478201783356], [-1.2587309777489815], [0.3810231998398724], [-1.1519066013588282], [-1.456356074070765], [0.5252361079665794], [0.007137882474335602], [-0.7726800651737837], [-1.2694134153879966], [1.1822060227660223], [0.8083207054004856], [-0.3400413407936627], [0.16737444705956575], [0.7709321736639321], [0.4878475762300256], [-0.8527983474663987], [-0.5323252182959387], [-1.007693693232121], [-0.024909430442710427], [2.004753720970203], [-0.040933086901233325], [0.963216051166208], [0.2314690728936576], [-0.8527983474663987], [1.1982296792245453], [-0.5857374064910154], [-1.248048540109966], [-0.8581395662859064], [-0.003544555164679741], [-0.5376664371154464], [1.443925744921898], [0.34363466810331883], [0.8563916747760548], [-0.11036893155483306], [0.04986763303039698], [-0.174463557388925], [-0.5376664371154464], [-0.6818793452421534], [-1.1465653825393203], [-1.2694134153879966], [-1.4723797305292883], [0.13532713414251973], [0.9365099570686698], [0.0017966636548280492], [0.017820320113350947], [-1.525791918724365], [0.3489758869228264], [-0.5964198441300307], [0.9578748323467005], [1.8658820316630038], [-0.5002779053788927], [-0.3453825596131704], [2.3946626947942633], [-1.1198592884417822], [-0.19048721384744802], [-0.9382578485785213], [0.10327982122547369], [2.21840247375051], [2.0581659091652797], [-0.42550084190578535], [-0.575054968852], [0.7495672983859014], [0.7602497360249167], [-0.4575481548228314], [0.16203322824005797], [-0.8688220039249217], [-0.11036893155483306], [-1.8836535796313785], [-0.42550084190578535], [-0.6338083758665843], [-0.2332169644035094], [-1.3228256035830734], [0.562624639703133], [0.4397766068544567], [1.6362096224241742], [0.08725616476695056], [1.0700404275563613], [1.443925744921898], [0.3863644186593799], [-0.1530986821108943], [0.7762733924834396], [-1.9477482054654707], [0.27954004226922674], [1.1501587098489765], [0.514553670327564], [-0.4575481548228314], [1.556091340131559], [-1.135882944900305], [-0.046274305720741114], [3.3988118328617047], [0.9204863006101467], [0.1994217599766118], [-0.510960343017908], [-1.1892951330953816], [0.3115873551862728], [1.331760149712237], [-0.05695674335975634], [0.21010419761562713], [0.9525336135271927], [-2.8343905295037435], [0.5198948891470716], [-1.1465653825393203], [0.851050455956547], [-0.847457128646891], [-0.11571015037434074], [-0.16912233856941733], [-0.911551754480983], [-0.040933086901233325], [0.3222697928252881], [0.9952633640832541], [-0.06763918099877168], [-0.7192678769787071], [-0.11036893155483306], [0.4718239197715027], [-0.024909430442710427], [0.194080541157104], [0.27954004226922674], [0.03384397657187408], [-0.6711969076031381], [0.3810231998398724], [-0.7993861592713221], [-0.446865717183816], [1.8178110622874348], [0.48250635741051806], [0.8029794865809781], [0.306246136366765], [0.7121787666493478], [-1.1839539142758742], [-1.3815790105976578], [-0.158439900930402], [-1.0130349120516287], [-0.158439900930402], [-0.47891303010086206], [1.593479871868113], [0.36499954338134927], [1.4706318390194362], [-0.3774298725302164], [-0.3774298725302164], [-0.4842542489203697], [-1.440332417612242], [1.0006045829027619], [-0.41481840426677], [0.7602497360249167], [-1.167930257817351], [0.9685572699857158], [-0.4201596230862777], [-0.591078625310523], [-0.3614062160716934], [0.4397766068544567], [-0.559031312393477], [-0.12105136919384829], [-0.943599067398029], [-0.591078625310523], [0.3970468562983953], [-0.21719330794498637], [1.1501587098489765], [1.1608411474879916], [-1.0290585685101519], [1.2516418674196224], [-0.46823059246184673], [-1.2854370718465198], [-0.12105136919384829], [1.6629157165217126], [-0.2652642773205553], [-0.33470012197415505], [0.6961551101908247], [0.05520885184990477], [0.2314690728936576], [0.017820320113350947], [-0.05695674335975634], [0.7495672983859014], [-0.25458183968153997], [-0.046274305720741114], [-1.2533897589294738], [-1.312143165944058], [0.3115873551862728], [1.2890303991561756], [0.05520885184990477], [1.7964461870094042], [-0.3934535289887393], [-2.214809146440854], [0.6641077972737787], [0.6694490160932864], [1.5881386530486052], [-0.5803961876715077], [1.9353178763166035], [0.26351638581070363], [-0.12639258801335596], [-1.4723797305292883], [-0.1370750256523713], [-0.7993861592713221], [-0.9168929733004908], [-0.1530986821108943], [-0.27060549614006296], [-0.7619976275347684], [1.8017874058289116], [-0.510960343017908], [0.9792397076247311], [-0.7299503146177224], [-0.5536900935739694], [-2.1240084265092234], [0.2314690728936576], [1.3905135567268216], [-0.2492406208620324], [1.3371013685317445], [-0.158439900930402], [-0.3560649972521857], [-0.7085854393396918], [0.40772929393741064], [0.36499954338134927], [0.2848812610887343], [1.9673651892336497], [0.9578748323467005], [-0.5536900935739694], [0.6213780467177172], [1.107428959292915], [1.2890303991561756], [-0.9703051614955673], [1.1875472415855302], [0.06055007066941232], [-0.14775746329138664], [0.5305773267860869], [-0.5376664371154464], [-0.9168929733004908], [-0.2759467149595706], [0.10862104004498124], [-0.8207510345493527], [0.8029794865809781], [0.8190031430395011], [1.4385845261023904], [-0.4895954677398774], [0.044526414210889424], [-0.7993861592713221], [0.8136619242199935], [0.3222697928252881], [0.6213780467177172], [-0.31333524669612434], [-0.3614062160716934], [0.14600957178153506], [0.5733070773421484], [-0.4361832795448007], [-0.543007655934954], [0.5092124515080563], [0.7228612042883632], [-0.5323252182959387], [3.0516326095937054], [-0.30799402787661667], [0.3863644186593799], [0.3970468562983953], [0.514553670327564], [0.6801314537323018], [1.5721149965900822], [0.081914945947443], [1.2302769921415917], [1.4759730578389443], [-0.2919703714180937], [0.883097768873593], [-0.46288937364233906], [1.0166282393612847], [1.267665523878145], [2.9074197014669987], [-0.5269839994764309], [-0.2652642773205553], [-0.6391495946860921], [-1.8302413914363018], [-0.6818793452421534], [0.8777565500540855], [2.191696379652971], [0.02850275775236629], [2.656382416950139], [1.0059458017222693], [-0.5857374064910154], [0.2848812610887343], [-0.4895954677398774], [0.7816146113029474], [-0.446865717183816], [-0.16378111974990966], [-0.03559186808172577], [0.4130705127569184], [-0.28128793377907835], [-0.1798047762084327], [-0.8100685969103374], [2.010094939789711], [2.533534384101462], [0.0979386024059659], [0.023161538932858737], [-0.959622723856552], [-0.16912233856941733], [0.70683754782984], [1.459949401380421], [0.07657372712793545], [0.5519422020641177], [-0.863480785105414], [1.1768648039465146], [-1.3708965729586426], [1.3638074626292833], [-0.575054968852], [0.5038712326885487], [-0.7085854393396918], [-1.1946363519148895], [1.8071286246484197], [-0.19582843266695568], [-0.35072377843267805], [0.8029794865809781], [-1.2373661024709508], [-1.600568982197472], [-2.6901776213770363], [-0.4522069360033237], [-1.568521669280426], [-0.4522069360033237], [0.9044626441516238], [0.16737444705956575], [-0.1530986821108943], [0.5252361079665794], [0.4771651385910105], [0.5038712326885487], [-0.7726800651737837], [-0.9008693168419678], [0.29022247990824207], [2.784571668618322], [-0.8581395662859064], [-0.4575481548228314], [-1.7714879844217175], [0.0017966636548280492], [-1.424308761153719], [-1.4830621681683036], [0.9899221452637466], [-0.8260922533688604], [1.2997128367951913], [-0.5056191241984004], [-0.16912233856941733], [-0.446865717183816], [-0.33470012197415505], [-1.0771295378857206], [-0.014226992803695085], [-0.318676465515632], [0.7228612042883632], [1.2463006486001142], [-1.0397410061491672], [-0.046274305720741114], [-0.33470012197415505], [-0.767338846354276], [-0.3667474348912011], [0.12464469650350438], [-0.8688220039249217], [0.7922970489419627], [-0.5697137500324924], [-1.3976026670561807], [-0.446865717183816], [-0.05695674335975634], [-0.7566564087152606], [-1.0290585685101519], [-0.29731159023760134], [0.18873932233759644], [-2.3429983981090383], [-0.44152449836430835], [-0.11571015037434074], [0.10327982122547369], [-0.6124435005885538], [-2.3590220545675606], [-1.6593223892120565], [-0.318676465515632], [2.2718146619455863], [-0.7726800651737837], [-0.24389940204252475], [0.8617328935955624], [3.030267734315675], [-0.0836628374572947], [1.481314276658452], [-1.0504234437881825], [-0.6658556887836303], [-0.623125938227569], [-0.5857374064910154], [-1.0023524744126133], [2.5068282900039236], [-1.3068019471245504], [0.3489758869228264], [-0.9756463803150751], [-1.9370657678264551], [0.3863644186593799], [-1.3495316976806118], [-0.9649639426760597], [0.5839895149811637], [0.5786482961616561], [-0.11036893155483306], [-0.29731159023760134], [-0.9863288179540904], [1.4065372131853446], [0.7655909548444243], [1.2302769921415917], [-0.687220564061661], [1.443925744921898], [-0.1050277127353254], [1.1715235851270072], [-1.5631804504609186], [-0.7139266581591994], [0.4397766068544567], [-0.003544555164679741], [0.5893307338006715], [1.593479871868113], [-0.5803961876715077], [1.8605408128434962], [-0.6925617828811687], [-0.543007655934954], [-0.33470012197415505], [-0.3453825596131704], [-0.03025064926221798], [-0.7993861592713221], [0.562624639703133], [1.609503528326636], [0.2688576046302114], [-0.14241624447187898], [0.306246136366765], [1.1768648039465146], [-0.9489402862175367], [-1.9317245490069475], [1.459949401380421], [1.4279020884633749], [0.22612785407415004], [0.3222697928252881], [-0.6444908135055997], [0.3756819810203646], [0.3222697928252881], [-0.4361832795448007], [0.0017966636548280492], [-0.3774298725302164], [0.44511782567396446], [-1.2533897589294738], [-1.3655553541391348], [1.2409594297806068], [-0.7352915334372301], [-1.5311331375438724], [0.4664827009519951], [0.22612785407415004], [-1.9958191748410397], [-0.8901868792029525], [0.48250635741051806], [0.0658912894889201], [-0.09968649391581771], [-0.46288937364233906], [-0.28128793377907835], [0.044526414210889424], [-0.14775746329138664], [-0.3400413407936627], [0.49853001386904094], [0.8670741124150702], [0.4023880751179031], [-0.19582843266695568], [-1.3869202294171654], [0.18339810351808866], [0.6801314537323018], [1.1661823663074995], [-0.28128793377907835], [-0.008885773984187294], [-0.7940449404518145], [0.48250635741051806], [-0.47891303010086206], [-1.8195589537972865], [-1.7234170150461483], [0.09259738358645835], [1.0219694581807923], [-1.1198592884417822], [-1.3815790105976578], [0.18339810351808866], [0.31692857400578034], [-0.5323252182959387], [-0.398794747808247], [-0.7459739710762454], [1.0593579899173462], [-0.33470012197415505], [1.107428959292915], [1.4279020884633749], [0.1994217599766118], [0.8350267994980242], [0.30090491754725746], [-0.5964198441300307], [-0.14775746329138664], [1.7483752176338352], [-0.3774298725302164], [0.02850275775236629], [-0.6444908135055997], [-0.8527983474663987], [0.8403680183175317], [0.044526414210889424], [-0.5216427806569233], [1.5347264648535284], [-0.16378111974990966], [0.15669200942055042], [1.4492669637414055], [1.3584662438097752], [-0.430842060725293], [-0.7192678769787071], [-1.0343997873296595], [-3.0053095317279883], [1.1287938345709458], [-1.167930257817351], [0.04986763303039698], [0.12998591532301193], [0.642742921995748], [-1.0771295378857206], [-0.8901868792029525], [-1.2533897589294738], [-1.0130349120516287], [0.3115873551862728], [-1.0664471002467053], [-0.30799402787661667], [0.8350267994980242], [1.2997128367951913], [-0.2118520891254787], [0.851050455956547], [-1.6379575139340259], [1.3691486814487908], [-1.0290585685101519], [-0.5163015618374157], [-0.003544555164679741], [1.50802037075599], [0.6694490160932864], [0.3222697928252881], [-0.8154098157298452], [-0.703244220520184], [0.6908138913713171], [-0.19582843266695568], [-0.9008693168419678], [-0.8581395662859064], [-0.543007655934954], [-1.2907782906660275], [-0.11571015037434074], [0.12998591532301193], [0.18873932233759644], [2.5228519464624473], [-0.13173380683286362], [-0.5643725312129847], [0.674790234912794], [-0.49493668655938505], [-1.600568982197472], [1.2623243050586375], [-1.1145180696222745], [-0.831433472188368], [-1.760805546782702], [0.6374017031762405], [-0.09434527509631005], [-0.5056191241984004], [1.0700404275563613], [-0.9649639426760597], [1.481314276658452], [-0.9970112555931058], [0.039185195391381634], [-0.7352915334372301], [-2.0973023324116853], [1.0486755522783306], [-0.8688220039249217], [-0.6177847194080615], [0.21544541643513468], [1.1822060227660223], [0.3222697928252881], [-0.20651087030597104], [-0.21719330794498637], [-0.3293589031546474], [-0.3827710913497241], [0.23681029171316537], [0.7495672983859014], [-0.7085854393396918], [0.12998591532301193], [0.06055007066941232], [-0.767338846354276], [-0.3560649972521857], [-0.575054968852], [-0.591078625310523], [0.6160368278982097], [-0.12639258801335596], [-1.0504234437881825], [-0.158439900930402], [0.642742921995748], [-1.0397410061491672], [1.1234526157514382], [-1.0984944131637513], [-0.446865717183816], [-0.7246090957982148], [-1.2373661024709508], [-0.6711969076031381], [-0.7833625028127991], [-0.07298039981827936], [-0.31333524669612434], [0.2581751669911961], [2.725818261603738], [-0.18514599502794035], [0.4878475762300256], [-0.4842542489203697], [-0.2492406208620324], [0.6854726725518093], [-0.14775746329138664], [1.491996714297467], [1.0700404275563613], [-0.8207510345493527], [-0.8047273780908298], [-0.8367746910078757], [0.20476297879611935], [-1.0450822249686746], [-1.7447818903241792], [-0.8527983474663987], [-0.703244220520184], [0.27954004226922674], [1.497337933116975], [0.7709321736639321], [2.0795307844433104], [1.0593579899173462], [-1.1038356319832592], [0.8670741124150702], [-0.6124435005885538], [0.5893307338006715], [-0.4201596230862777], [-0.40413596662775464], [1.3691486814487908], [-0.8688220039249217], [-0.5643725312129847], [-2.1079847700507006], [1.9086117822190651], [2.6189938852135852], [-0.7513151898957531], [-0.3240176843351397], [0.7175199854688553], [0.10862104004498124], [-1.440332417612242], [-0.430842060725293], [-0.158439900930402], [-0.398794747808247], [0.1727156658790733], [0.7602497360249167], [-0.4361832795448007], [-1.0397410061491672], [-0.2759467149595706], [-2.1293496453287313], [-0.6818793452421534], [0.10862104004498124], [-0.09968649391581771], [1.3103952744342064], [-0.27060549614006296], [0.24215151053267292], [-1.7340994526851639], [-2.6260829955429443], [1.4065372131853446], [1.107428959292915], [-1.5418155751828877], [-1.632616295114518], [-0.847457128646891], [-2.214809146440854], [-1.360214135319627], [0.9258275194296545], [-0.42550084190578535], [-1.1038356319832592], [-0.3240176843351397], [0.9578748323467005], [-0.7085854393396918], [-1.05576466260769], [1.107428959292915], [0.9098038629711314], [-0.4735718112813544], [-0.4361832795448007], [-0.5803961876715077], [-0.03559186808172577], [-0.6925617828811687], [2.3732978195162318], [0.4558002633129798], [-0.1798047762084327], [-0.7246090957982148], [1.5507501213120514], [-0.4575481548228314], [0.9899221452637466], [-1.3228256035830734], [0.2688576046302114], [2.7578655745207845], [-0.1050277127353254], [-0.41481840426677], [1.4706318390194362], [1.9833888456921722], [0.1780568846985811], [0.11396225886448903], [0.07657372712793545], [-0.008885773984187294], [-0.008885773984187294], [-0.014226992803695085], [-0.7406327522567377], [-1.360214135319627], [1.1234526157514382], [0.7495672983859014], [-0.37208865371070876], [1.5881386530486052], [1.443925744921898], [1.2569830862391298], [-1.6806872644900872], [-0.543007655934954], [1.5881386530486052], [0.11930347768399659], [-0.1798047762084327], [-0.31333524669612434], [-0.575054968852], [0.03384397657187408], [-0.03025064926221798], [-0.4361832795448007], [-0.6605144699641228], [3.2599401435545046], [0.32761101164479567], [0.32761101164479567], [1.0166282393612847], [-1.5578392316414107], [-0.7780212839932913], [-0.19582843266695568], [-0.2652642773205553], [1.9086117822190651], [0.12464469650350438], [1.3531250249902678], [0.6908138913713171], [1.0219694581807923], [-1.1519066013588282], [0.044526414210889424], [-0.591078625310523], [1.273006742697653], [0.450459044493472], [1.732351561175312], [1.7911049681898965], [-1.0717883190662132], [0.4130705127569184], [1.3103952744342064], [-2.113325988870208], [-1.087811975524736], [-1.9050184549094094], [0.3863644186593799], [1.155499928668484], [0.16203322824005797], [-0.398794747808247], [-0.863480785105414], [-1.1572478201783356], [-0.4201596230862777], [-0.14241624447187898], [-0.8955280980224601], [0.3756819810203646], [2.0635071279847876], [1.0379931146393155], [-0.040933086901233325], [-0.6017610629495384], [0.21010419761562713], [-0.3614062160716934], [-0.703244220520184], [-0.2118520891254787], [0.5252361079665794], [0.22078663525464223], [0.6320604843567326], [0.5893307338006715], [0.3222697928252881], [2.9341257955645372], [-0.06229796217926401], [0.26351638581070363], [-1.600568982197472], [2.6991121675062004], [-1.424308761153719], [-0.35072377843267805], [0.07123250830842766], [1.4866554954779594], [0.39170563747888776], [1.1822060227660223], [-0.6711969076031381], [0.3970468562983953], [-0.14241624447187898], [-2.748931028391621], [1.433243307282883], [1.556091340131559], [0.0017966636548280492], [-0.158439900930402], [-1.456356074070765], [-0.23855818322301706], [0.41841173157642597], [0.562624639703133], [2.512169508823431], [-1.1412241637198128], [-1.3869202294171654], [-0.13173380683286362], [1.1608411474879916], [-0.4895954677398774], [0.1406683529620273], [0.9098038629711314], [-0.8741632227444294], [-0.49493668655938505], [1.7270103423558045], [-0.040933086901233325], [-0.863480785105414], [0.306246136366765], [-1.0771295378857206], [-0.9275754109395061], [0.02850275775236629], [-1.2266836648319355], [0.6320604843567326], [1.1982296792245453], [1.673598154160728], [0.48250635741051806], [-1.440332417612242], [0.4718239197715027], [-0.37208865371070876], [3.2385752682764744], [0.883097768873593], [-1.0664471002467053], [1.091405302834392], [-0.318676465515632], [-0.6391495946860921], [0.4931887950495334], [-1.135882944900305], [0.18339810351808866], [0.7121787666493478], [0.1994217599766118], [-1.3815790105976578], [2.095554440901833], [-0.0836628374572947], [0.07657372712793545], [1.0753816463758692], [1.2516418674196224], [-0.5323252182959387], [-0.33470012197415505], [0.931168738249162], [0.626719265537225], [1.2409594297806068], [-0.8207510345493527], [-0.21719330794498637], [-2.9412149058938963], [1.732351561175312], [-1.4777209493487957], [2.0314598150677416], [-0.040933086901233325], [1.3905135567268216], [1.5347264648535284], [-0.911551754480983], [-0.5803961876715077], [1.107428959292915], [2.2237436925700176], [0.15669200942055042], [-0.5269839994764309], [0.07657372712793545], [-0.07298039981827936], [1.2409594297806068], [-0.655173251144615], [3.8421329948808403], [0.007137882474335602], [0.194080541157104], [0.3222697928252881], [-0.6338083758665843], [0.6320604843567326], [-1.5311331375438724], [0.40772929393741064], [1.6522332788826974], [0.9738984888052233], [-0.2652642773205553], [1.8605408128434962], [-1.53647435636338], [-1.0397410061491672], [-1.1946363519148895], [-0.7566564087152606], [0.8243443618590088], [1.1608411474879916], [-0.4575481548228314], [1.0967465216538999], [0.012479101293843393], [0.16203322824005797], [1.0273106770002998], [-0.9329166297590137], [-0.5803961876715077], [0.594671952620179], [0.8991214253321159], [-0.14241624447187898], [0.21544541643513468], [0.3756819810203646], [2.512169508823431], [-0.5056191241984004], [0.12464469650350438], [0.70683754782984], [1.321077712073222], [-0.4094771854472623], [0.5893307338006715], [1.385172337907314], [3.7246261808516725], [0.10862104004498124], [-0.863480785105414], [0.6641077972737787], [1.2302769921415917], [-0.7139266581591994], [0.5839895149811637], [-0.8848456603834448], [0.3222697928252881], [-0.003544555164679741], [0.6641077972737787], [0.6374017031762405], [-1.6967109209486102], [0.07657372712793545], [-0.3774298725302164], [-1.413626323514704], [-1.456356074070765], [-0.16912233856941733], [-1.9797955183825164], [1.1341350533904533], [-0.3934535289887393], [0.29022247990824207], [1.9032705633995575], [0.4023880751179031], [0.514553670327564], [0.5038712326885487], [-0.2118520891254787], [-0.847457128646891], [0.007137882474335602], [1.8231522811069423], [-0.9916700367735981], [-0.16912233856941733], [-0.3827710913497241], [-0.9703051614955673], [1.273006742697653], [-0.831433472188368], [-0.286629152598586], [-0.05695674335975634], [-0.767338846354276], [-2.5085761815137757], [2.7899128874378305], [-0.9329166297590137], [1.208912116863561], [0.8029794865809781], [-0.4575481548228314], [2.95014945202306], [0.42375295039593375], [0.39170563747888776], [1.716327904716789], [1.3103952744342064], [1.3691486814487908], [-1.3655553541391348], [-0.08900405627680237], [-0.35072377843267805], [-0.4842542489203697], [-0.23855818322301706], [0.2955636987277496], [2.4373924453503246], [-0.27060549614006296], [0.674790234912794], [-0.5269839994764309], [0.5786482961616561], [0.16737444705956575], [-1.3068019471245504], [0.7816146113029474], [-0.5269839994764309], [-1.2854370718465198], [-1.5311331375438724], [1.0112870205417772], [0.5198948891470716], [-0.35072377843267805], [-0.4895954677398774], [-0.06229796217926401], [-1.9530894242849781], [-0.6711969076031381], [1.4706318390194362], [-0.2919703714180937], [0.5305773267860869], [-0.5483488747544617], [0.7335436419273785], [0.5893307338006715], [1.3103952744342064], [-0.0836628374572947], [-0.23855818322301706], [1.9246354386775884], [1.267665523878145], [0.27419882344971896], [1.5187028083950056], [3.8421329948808403], [1.545408902492544], [-0.8955280980224601], [0.6000131714396868], [-1.7875116408802405], [-0.7299503146177224], [-1.1946363519148895], [0.03384397657187408], [0.04986763303039698], [-2.0812786759531625], [0.48250635741051806], [-0.20116965148646337], [-0.9222341921199984], [-0.5857374064910154], [-0.5163015618374157], [1.2302769921415917], [1.1020877404734075], [0.6534253596347633], [0.4931887950495334], [-0.9542815050370443], [0.450459044493472], [1.89792934458005], [1.2623243050586375], [-1.600568982197472], [0.8777565500540855], [-0.29731159023760134], [-0.8154098157298452], [-0.12105136919384829], [-0.046274305720741114], [0.5412597644251023], [-1.2854370718465198], [1.4492669637414055], [0.36499954338134927], [0.11930347768399659], [-1.0290585685101519], [-1.2320248836514431], [0.3756819810203646], [0.5786482961616561], [0.10327982122547369], [0.8670741124150702], [-0.6765381264226457], [0.13532713414251973], [-0.11036893155483306], [-0.7459739710762454], [1.1768648039465146], [-0.12639258801335596], [1.556091340131559], [0.24215151053267292], [-0.4895954677398774], [0.26351638581070363], [0.48250635741051806], [-1.8676299231728555], [0.40772929393741064], [-0.40413596662775464], [-0.003544555164679741], [-1.8249001726167942], [2.5281931652819547], [1.5507501213120514], [1.1822060227660223], [-0.510960343017908], [0.16203322824005797], [-1.2053187895539048], [0.4771651385910105], [1.2142533356830685], [0.626719265537225], [1.1768648039465146], [0.09259738358645835], [-0.5643725312129847], [-2.262880115816423], [-0.07832161863778703], [0.9738984888052233], [1.0326518958198079], [0.20476297879611935], [0.6961551101908247], [-0.06229796217926401], [-1.3815790105976578], [0.8403680183175317], [-0.4522069360033237], [-1.3068019471245504], [0.6213780467177172], [0.7762733924834396], [-0.9275754109395061], [-1.2266836648319355], [0.194080541157104], [-0.9916700367735981], [-0.03559186808172577], [-0.4575481548228314], [0.3222697928252881], [0.6053543902591944], [0.33295223046430344], [1.604162309507128], [-0.767338846354276], [-0.5964198441300307], [-0.27060549614006296], [-1.0023524744126133], [-0.2652642773205553], [0.03384397657187408], [-0.879504441563937], [-1.6112514198364873], [0.10862104004498124], [0.6534253596347633], [0.43443538803494913], [-0.623125938227569], [-0.11571015037434074], [-0.1530986821108943], [-0.7513151898957531], [-1.5631804504609186], [-1.424308761153719], [-1.0450822249686746], [0.1406683529620273], [-0.2759467149595706], [-0.655173251144615], [0.8991214253321159], [-0.8901868792029525], [1.3905135567268216], [0.754908517205409], [-0.5857374064910154], [0.8937802065126084], [1.497337933116975], [-0.5697137500324924], [-0.5323252182959387], [0.5572834208836255], [-0.943599067398029], [-0.4361832795448007], [0.2848812610887343], [0.5893307338006715], [0.12998591532301193], [0.8350267994980242], [-0.831433472188368], [-1.3815790105976578], [0.012479101293843393], [-1.0237173496906442], [0.8403680183175317], [0.41841173157642597], [0.39170563747888776], [-0.1370750256523713], [-0.9703051614955673], [0.5733070773421484], [2.9554906708425674], [-0.6017610629495384], [0.20476297879611935], [0.7442260795663939], [-0.09434527509631005], [-0.27060549614006296], [-0.38811231016923164], [-0.8260922533688604], [-0.911551754480983], [0.0017966636548280492], [0.70683754782984], [0.11930347768399659], [-0.19048721384744802], [-0.5002779053788927], [0.2314690728936576], [-0.9062105356614755], [2.2023788172919865], [1.3371013685317445], [0.9258275194296545], [-0.6177847194080615], [-0.9329166297590137], [0.2314690728936576], [-0.2492406208620324], [-0.003544555164679741], [-0.38811231016923164], [1.2890303991561756], [-1.3174843847635658], [1.385172337907314], [0.023161538932858737], [-1.1145180696222745], [-0.623125938227569], [-1.2694134153879966], [-0.3667474348912011], [0.5305773267860869], [-0.9168929733004908], [0.6961551101908247], [-1.2373661024709508], [-0.19048721384744802], [-0.7513151898957531], [-0.06229796217926401], [-2.5726708073478677], [-0.5376664371154464], [1.4546081825609136], [0.4558002633129798], [-0.44152449836430835], [0.3863644186593799], [1.8124698434679272], [-1.573862888099934], [0.7388848607468861], [-0.2919703714180937], [-0.22787574558400173], [1.5507501213120514], [1.2302769921415917], [0.5519422020641177], [-1.7447818903241792], [-0.31333524669612434], [0.626719265537225], [-0.46288937364233906], [-0.1530986821108943], [-0.3934535289887393], [0.15135079060104262], [0.27954004226922674], [0.12464469650350438], [-0.2332169644035094], [-1.9637718619239934], [0.35431710574233394], [0.6641077972737787], [-0.05161552454024867], [0.07657372712793545], [0.5893307338006715], [-0.3934535289887393], [2.138284191457895], [0.02850275775236629], [0.306246136366765], [-1.1091768508027668], [-0.44152449836430835], [1.5347264648535284], [0.9258275194296545], [0.8350267994980242], [-0.03559186808172577], [-0.14241624447187898], [-1.1305417260807975], [-2.118667207689716], [-0.8100685969103374], [-0.6818793452421534], [0.24749272935218072], [-1.1892951330953816], [0.14600957178153506], [-1.1198592884417822], [0.5412597644251023], [-0.5857374064910154], [-1.5952277633779646], [0.14600957178153506], [-0.30799402787661667], [-0.29731159023760134], [-0.9222341921199984], [0.22078663525464223], [1.1982296792245453], [0.7816146113029474], [-0.5483488747544617], [0.16737444705956575], [-0.22253452676449406], [0.24215151053267292], [-0.5536900935739694], [-0.6979030017006763], [0.4290941692154413], [1.315736493253714], [1.2836891803366681], [-0.9329166297590137], [-1.2053187895539048], [0.4664827009519951], [-1.0397410061491672], [-0.1050277127353254], [0.5412597644251023], [0.05520885184990477], [-1.1198592884417822], [1.2195945545025761], [2.645699979311123], [0.6480841408152558], [-1.8676299231728555], [0.6213780467177172], [-0.38811231016923164], [1.89792934458005], [-3.064062938742573], [-0.4361832795448007], [1.2836891803366681], [-1.0611058814271976], [-0.3934535289887393], [0.5733070773421484], [0.7655909548444243], [0.23681029171316537], [1.5614325589510665], [-1.3388492600415964], [0.4130705127569184], [0.081914945947443], [0.5893307338006715], [1.1181113969319307], [-0.318676465515632], [-0.174463557388925], [0.5092124515080563], [-0.7566564087152606], [-1.2266836648319355], [-0.9168929733004908], [-0.3453825596131704], [-0.7139266581591994], [0.4718239197715027], [-0.430842060725293], [0.5198948891470716], [-1.6272750762950103], [-0.8154098157298452], [-1.05576466260769], [-0.7352915334372301], [-0.8955280980224601], [-0.19582843266695568], [0.8457092371370395], [-0.3774298725302164], [-0.3614062160716934], [-1.814217734977779], [0.674790234912794], [-0.9168929733004908], [-1.3815790105976578], [1.0967465216538999], [0.21544541643513468], [0.41841173157642597], [-0.8367746910078757], [-0.5002779053788927], [-1.6967109209486102], [-0.42550084190578535], [-0.14241624447187898], [0.4931887950495334], [0.16203322824005797], [-0.9062105356614755], [-0.16378111974990966], [-0.430842060725293], [-1.4777209493487957], [1.9887300645116803], [-0.6658556887836303], [0.081914945947443], [-0.9222341921199984], [-0.3614062160716934], [0.26351638581070363], [-0.3400413407936627], [0.7762733924834396], [0.883097768873593], [0.26351638581070363], [-0.7406327522567377], [0.5572834208836255], [0.2314690728936576], [0.9738984888052233], [-0.1530986821108943], [0.3115873551862728], [-0.943599067398029], [1.8178110622874348], [-0.22787574558400173], [0.31692857400578034], [-1.456356074070765], [-1.9691130807435013], [-0.6979030017006763], [-1.4990858246268264], [1.2997128367951913], [-0.14241624447187898], [0.10862104004498124], [0.24749272935218072], [-0.19582843266695568], [0.9258275194296545], [-0.5216427806569233], [1.9513415327751265], [1.1768648039465146], [1.6468920600631893], [-0.1798047762084327], [-0.6818793452421534], [-0.911551754480983], [1.0646992087368536], [-0.05161552454024867], [-1.424308761153719], [0.562624639703133], [0.5198948891470716], [-0.8154098157298452], [-0.318676465515632], [-0.2492406208620324], [0.754908517205409], [-0.3614062160716934], [1.3371013685317445], [0.3115873551862728], [0.9685572699857158], [0.4023880751179031], [-1.1465653825393203], [-0.9008693168419678], [-0.6605144699641228], [-1.1412241637198128], [0.450459044493472], [-0.05695674335975634], [-0.3240176843351397], [0.15135079060104262], [-0.07832161863778703], [-0.8260922533688604], [-0.9062105356614755], [-0.687220564061661], [-0.37208865371070876], [0.8029794865809781], [0.6534253596347633], [-0.8100685969103374], [-1.1412241637198128], [0.0979386024059659], [-0.49493668655938505], [0.023161538932858737], [1.593479871868113], [1.0166282393612847], [-0.7246090957982148], [-0.8848456603834448], [-0.6818793452421534], [0.7762733924834396], [1.3744899002682984], [1.0700404275563613], [-0.44152449836430835], [-0.575054968852], [-0.024909430442710427], [-1.3335080412220888], [2.010094939789711], [0.9365099570686698], [-0.767338846354276], [0.33295223046430344], [0.1780568846985811], [1.1928884604050378], [-0.7619976275347684], [0.6106956090787021], [2.7151358239647227], [0.6213780467177172], [-0.12105136919384829], [-0.5964198441300307], [0.41841173157642597], [-0.4094771854472623], [-0.9329166297590137], [0.8724153312345777], [-1.568521669280426], [-3.256346816244849], [-1.0450822249686746], [0.26351638581070363], [-1.0343997873296595], [1.3050540556146988], [0.9845809264442387], [-0.9916700367735981], [1.6629157165217126], [0.6106956090787021], [-0.07298039981827936], [-1.2320248836514431], [-0.14775746329138664], [2.3519329442382015], [-1.2533897589294738], [0.05520885184990477], [-0.8100685969103374], [-0.4094771854472623], [-1.4777209493487957], [-0.16378111974990966], [0.11396225886448903], [0.6534253596347633], [-0.2759467149595706], [-0.446865717183816], [-0.22253452676449406], [0.18339810351808866], [2.7525243557012766], [-0.5697137500324924], [-0.8100685969103374], [0.5466009832446102], [-0.575054968852], [-1.1625890389978435], [-0.2652642773205553], [-0.9382578485785213], [-0.09434527509631005], [0.16203322824005797], [0.2314690728936576], [-0.1798047762084327], [-0.8100685969103374], [0.8403680183175317], [-0.510960343017908], [0.0017966636548280492], [0.09259738358645835], [-1.1412241637198128], [0.39170563747888776], [-0.37208865371070876], [2.4694397582673697], [-0.23855818322301706], [1.1234526157514382], [0.31692857400578034], [-0.30799402787661667], [-0.687220564061661], [2.0528246903457723], [-0.040933086901233325], [-0.7299503146177224], [0.31692857400578034], [1.6148447471461436], [-1.1305417260807975], [-1.4456736364317497], [-1.1305417260807975], [1.4065372131853446], [0.4290941692154413], [1.043334333458823], [2.7311594804232455], [1.433243307282883], [0.963216051166208], [1.7376927799948196], [0.017820320113350947], [1.0112870205417772], [2.442733664169832], [-0.9970112555931058], [0.4558002633129798], [0.4290941692154413], [1.1448174910294688], [-0.35072377843267805], [0.1994217599766118], [1.4065372131853446], [1.5133615895754977], [0.7495672983859014], [-1.0397410061491672], [-1.5151094810853494], [-0.40413596662775464], [-1.1412241637198128], [0.70683754782984], [0.7602497360249167], [0.3863644186593799], [-0.09434527509631005], [0.22612785407415004], [0.9204863006101467], [0.22078663525464223], [2.3519329442382015], [2.132942972638387], [0.8777565500540855], [-1.328166822402581], [2.116919316179864], [-0.5216427806569233], [-0.879504441563937], [0.3489758869228264], [-1.573862888099934], [-0.25992305850104763], [1.66825693534122], [-2.1346908641482387], [-0.1050277127353254], [1.7643988740923584], [0.5466009832446102], [-0.29731159023760134], [-0.4094771854472623], [0.6053543902591944], [-0.6711969076031381], [-1.0771295378857206], [-0.3667474348912011], [1.1982296792245453], [2.53887560292097], [-0.3774298725302164], [-0.41481840426677], [1.5988210906876203], [-0.12639258801335596], [-1.1465653825393203], [0.1406683529620273], [-0.008885773984187294], [-0.318676465515632], [-1.05576466260769], [-1.7340994526851639], [-0.687220564061661], [-0.05695674335975634], [0.9418511758881773], [0.5893307338006715], [-1.814217734977779], [-1.760805546782702], [-0.40413596662775464], [0.6106956090787021], [0.41841173157642597], [-0.44152449836430835], [-0.4201596230862777], [1.3798311190878059], [-0.8421159098273834], [0.2314690728936576], [-1.4456736364317497], [-0.9863288179540904], [0.27419882344971896], [-0.1050277127353254], [-1.8088765161582712], [0.5252361079665794], [-0.20116965148646337], [1.3584662438097752], [-1.1625890389978435], [0.931168738249162], [0.10327982122547369], [-0.6338083758665843], [1.4546081825609136], [0.5252361079665794], [-0.1370750256523713], [1.5026791519364826], [0.11930347768399659], [-1.3014607283050428], [-0.446865717183816], [0.49853001386904094], [-0.879504441563937], [0.9685572699857158], [0.26351638581070363], [1.3264189308927294], [-0.16912233856941733], [-1.7768292032412252], [-0.11571015037434074], [0.9365099570686698], [-0.24389940204252475], [-1.0450822249686746], [0.7922970489419627], [0.15669200942055042], [0.70683754782984], [-0.8581395662859064], [-1.1198592884417822], [0.04986763303039698], [-1.5097682622658417], [0.594671952620179], [0.27419882344971896], [-0.03025064926221798], [1.091405302834392], [0.24749272935218072], [-0.959622723856552], [-0.42550084190578535], [1.0166282393612847], [1.1448174910294688], [-2.022525268938578], [-0.7726800651737837], [-0.655173251144615], [-0.8848456603834448], [0.29022247990824207], [-0.3453825596131704], [-1.007693693232121], [1.2142533356830685], [1.34778380617076], [-1.2961195094855351], [1.107428959292915], [0.4397766068544567], [0.963216051166208], [-0.12105136919384829], [-0.6338083758665843], [1.4492669637414055], [0.5359185456055947], [-0.2759467149595706], [-0.28128793377907835], [0.5305773267860869], [0.5679658585226408], [-0.1798047762084327], [0.8403680183175317], [0.1780568846985811], [-0.7192678769787071], [0.40772929393741064], [0.450459044493472], [-3.486019225483678], [-0.23855818322301706], [1.0166282393612847], [-0.959622723856552], [-1.280095853027012], [0.9098038629711314], [2.870031169730445], [-1.4349911987927344], [-0.8154098157298452], [0.5038712326885487], [0.0658912894889201], [1.6362096224241742], [-0.3827710913497241], [-0.003544555164679741], [-1.0183761308711365], [-1.2106600083734125], [1.0273106770002998], [-0.046274305720741114], [0.6106956090787021], [-0.3453825596131704], [0.7282024231078708], [0.306246136366765], [-0.20651087030597104], [-0.3827710913497241], [1.0166282393612847], [-0.8848456603834448], [0.2314690728936576], [0.754908517205409], [0.081914945947443], [1.4065372131853446], [0.2581751669911961], [-0.6284671570470768], [-0.6391495946860921], [1.6575744977022049], [-0.19582843266695568], [-1.5471567940023956], [-0.20651087030597104], [1.4225608696438674], [0.626719265537225], [0.7228612042883632], [-0.5643725312129847], [-0.11036893155483306], [-0.040933086901233325], [0.35431710574233394], [1.9139530010385726], [3.2385752682764744], [0.21544541643513468], [0.883097768873593], [-1.7020521397681179], [0.9738984888052233], [-0.7299503146177224], [1.3264189308927294], [-0.3240176843351397], [0.06055007066941232], [-0.591078625310523], [0.007137882474335602], [1.9940712833311878], [-0.7352915334372301], [-0.3667474348912011], [0.023161538932858737], [-2.481870087416237], [0.3115873551862728], [0.02850275775236629], [1.732351561175312], [0.8937802065126084], [1.50802037075599], [2.362615381877217], [-1.3228256035830734], [0.24215151053267292], [0.4558002633129798], [0.24215151053267292], [-0.20651087030597104], [0.1780568846985811], [0.18339810351808866], [-0.46823059246184673], [0.18873932233759644], [0.039185195391381634], [0.2688576046302114], [-0.9168929733004908], [0.5466009832446102], [-0.302652809057109], [-0.6925617828811687], [0.9098038629711314], [0.37034076220085704], [-1.1198592884417822], [-0.19048721384744802], [1.0540167710978385], [4.199994655787855], [0.37034076220085704], [1.9620239704141416], [0.7121787666493478], [2.0261185962482338], [0.9685572699857158], [-1.2640721965684891], [-0.040933086901233325], [0.081914945947443], [0.450459044493472], [-1.05576466260769], [0.8190031430395011], [1.7430339988143277], [-0.35072377843267805], [-0.911551754480983], [-1.2373661024709508], [0.8563916747760548], [-0.6498320323251074], [0.8777565500540855], [-0.446865717183816], [-0.8207510345493527], [1.604162309507128], [-0.11036893155483306], [0.5092124515080563], [-0.8527983474663987], [-1.4937446058073187], [-1.0717883190662132], [-0.158439900930402], [-0.07298039981827936], [-0.4575481548228314], [1.443925744921898], [-1.1786126954563663], [-1.7501231091436869], [-0.623125938227569], [0.3222697928252881], [-0.7726800651737837], [-0.7566564087152606], [-2.4124342427626373], [-1.8836535796313785], [-1.3495316976806118], [2.3359092877796783], [-0.23855818322301706], [0.5092124515080563], [0.70683754782984], [0.21544541643513468], [-2.551305932069837], [0.4023880751179031], [-0.5857374064910154], [0.4771651385910105], [-0.831433472188368], [-1.8676299231728555], [-1.0450822249686746], [-0.21719330794498637], [-0.7192678769787071], [-1.1732714766368588], [-1.814217734977779], [0.5466009832446102], [0.8724153312345777], [-1.760805546782702], [-0.430842060725293], [-0.003544555164679741], [0.7175199854688553], [-0.7246090957982148], [0.18339810351808866], [1.0006045829027619], [0.02850275775236629], [1.1341350533904533], [0.931168738249162], [0.49853001386904094], [-0.019568211623202637], [0.626719265537225], [0.194080541157104], [1.9727064080531571], [-1.5151094810853494], [0.338293449283811], [0.42375295039593375], [-2.294927428733469], [-0.4201596230862777], [-0.07298039981827936], [-0.23855818322301706], [0.2688576046302114], [-0.2759467149595706], [-0.5216427806569233], [-0.9062105356614755], [0.5198948891470716], [0.306246136366765], [-0.019568211623202637], [-0.14775746329138664], [-0.27060549614006296], [2.6136526663940773], [0.5305773267860869], [0.626719265537225], [0.9098038629711314], [0.15135079060104262], [-0.19582843266695568], [-2.118667207689716], [0.70683754782984], [-0.31333524669612434], [-0.4735718112813544], [-0.863480785105414], [0.8296855806785164], [0.9952633640832541], [0.9258275194296545], [-1.0130349120516287], [0.4397766068544567], [-1.007693693232121], [1.0166282393612847], [0.6961551101908247], [-0.13173380683286362], [-0.607102281769046], [-1.360214135319627], [2.8646899509109374], [0.23681029171316537], [-0.1530986821108943], [-0.7513151898957531], [1.0646992087368536], [-0.5002779053788927], [-0.12639258801335596], [-0.5216427806569233], [0.0017966636548280492], [0.017820320113350947], [-0.959622723856552], [-0.5483488747544617], [-0.16378111974990966], [-0.30799402787661667], [-0.559031312393477], [-1.488403386987811], [-0.2118520891254787], [0.6801314537323018], [-1.1198592884417822], [-0.33470012197415505], [0.6106956090787021], [-0.559031312393477], [0.674790234912794], [0.22078663525464223], [0.786955830122455], [1.1448174910294688], [-1.6967109209486102], [0.5252361079665794], [-0.06229796217926401], [0.3756819810203646], [-1.2640721965684891], [-0.559031312393477], [0.23681029171316537], [0.4397766068544567], [0.04986763303039698], [-1.814217734977779], [1.1982296792245453], [-0.9863288179540904], [0.18873932233759644], [-0.8741632227444294], [-1.2694134153879966], [1.0646992087368536], [0.7655909548444243], [0.5893307338006715], [-1.5952277633779646], [-0.9008693168419678], [0.6641077972737787], [0.22078663525464223], [0.3596583245618417], [-0.21719330794498637], [0.4558002633129798], [-0.8367746910078757], [0.70683754782984], [1.9780476268726648], [0.29022247990824207], [1.1501587098489765], [1.2356182109610991], [-0.5269839994764309], [-0.6338083758665843], [-0.06229796217926401], [0.8029794865809781], [-1.0771295378857206], [1.3531250249902678], [-0.05161552454024867], [-0.9970112555931058], [-1.05576466260769], [1.8819056881215268], [0.9365099570686698], [0.0658912894889201], [3.185163080081398], [-1.3335080412220888], [-0.831433472188368], [0.12998591532301193], [0.338293449283811], [1.273006742697653], [0.5092124515080563], [-1.1625890389978435], [-0.13173380683286362], [3.2973286752910584], [1.780422530550881], [-1.1786126954563663], [0.34363466810331883], [-1.5044270434463343], [-0.4094771854472623], [0.2581751669911961], [1.6896218106192507], [0.16203322824005797], [0.7602497360249167], [-1.461697292890273], [-0.4361832795448007], [-0.25992305850104763], [-0.1530986821108943], [-0.543007655934954], [0.5359185456055947], [-1.2907782906660275], [-2.353680835748053], [-0.5056191241984004], [1.9353178763166035], [-0.6765381264226457], [0.851050455956547], [-0.09968649391581771], [0.4290941692154413], [0.41841173157642597], [-0.29731159023760134], [0.6213780467177172], [-2.0599138006751314], [1.0700404275563613], [-0.38811231016923164], [1.3050540556146988], [2.0528246903457723], [1.5347264648535284], [-0.8688220039249217], [1.9032705633995575], [-0.655173251144615], [-0.5803961876715077], [-0.6658556887836303], [0.05520885184990477], [-0.12639258801335596], [0.08725616476695056], [-1.5471567940023956], [-0.831433472188368], [-0.4895954677398774], [0.03384397657187408], [-1.814217734977779], [-1.3869202294171654], [-0.5376664371154464], [0.3756819810203646], [-0.18514599502794035], [1.443925744921898], [-0.20116965148646337], [-0.11036893155483306], [-0.286629152598586], [1.50802037075599], [-0.6658556887836303], [0.6587665784542711], [-0.41481840426677], [0.5893307338006715], [1.2249357733220836], [-0.3453825596131704], [-0.40413596662775464], [-0.13173380683286362], [-0.5857374064910154], [0.7175199854688553], [-0.6925617828811687], [-0.607102281769046], [-0.5269839994764309], [-0.7619976275347684], [-0.1798047762084327], [0.6961551101908247], [0.081914945947443], [0.9365099570686698], [-0.3293589031546474], [-0.5536900935739694], [-2.770295903669651], [-0.3453825596131704], [0.5572834208836255], [-0.47891303010086206], [-0.46823059246184673], [-0.7459739710762454], [-1.632616295114518], [0.594671952620179], [-0.607102281769046], [-1.0450822249686746], [-0.6658556887836303], [-1.4937446058073187], [1.6629157165217126], [0.25283394817168825], [-1.3976026670561807], [0.8937802065126084], [0.49853001386904094], [0.08725616476695056], [2.6777472922281693], [1.8765644693020194], [0.786955830122455], [0.4290941692154413], [0.6000131714396868], [-1.632616295114518], [0.9204863006101467], [-0.2652642773205553], [0.7282024231078708], [0.044526414210889424], [0.16203322824005797], [0.0979386024059659], [-1.1145180696222745], [1.4172196508243597], [0.11930347768399659], [-0.6338083758665843], [-0.7406327522567377], [-0.7192678769787071], [-0.8260922533688604], [1.5187028083950056], [-0.6765381264226457], [0.7282024231078708], [-0.2492406208620324], [1.6842805917997432], [-0.9489402862175367], [0.48250635741051806], [-0.7299503146177224], [-1.3976026670561807], [-0.8047273780908298], [0.34363466810331883], [0.3756819810203646], [-0.42550084190578535], [0.29022247990824207], [-0.430842060725293], [-0.4842542489203697], [1.3744899002682984], [-0.1050277127353254], [1.1448174910294688], [0.514553670327564], [-1.4777209493487957], [0.3970468562983953], [-0.3453825596131704], [-1.1465653825393203], [-0.8955280980224601], [1.1234526157514382], [0.2688576046302114], [1.4279020884633749], [1.459949401380421], [-0.16378111974990966], [-1.1519066013588282], [-0.38811231016923164], [-1.600568982197472], [-0.3934535289887393], [-0.4201596230862777], [-0.35072377843267805], [0.15669200942055042], [-1.8569474855338401], [-0.6444908135055997], [0.9098038629711314], [1.107428959292915], [-0.49493668655938505], [-0.08900405627680237], [0.642742921995748], [0.963216051166208], [0.44511782567396446], [-1.1786126954563663], [-1.0023524744126133], [0.6160368278982097], [-0.20116965148646337], [0.22078663525464223], [0.10862104004498124], [-2.1293496453287313], [0.4878475762300256], [-0.4094771854472623], [-0.2652642773205553], [-1.3228256035830734], [1.2142533356830685], [-0.0836628374572947], [-2.2468564593579], [0.883097768873593], [2.4267100077113084], [1.545408902492544], [0.33295223046430344], [-1.4670385117097804], [-1.087811975524736], [0.3756819810203646], [0.8563916747760548], [2.6777472922281693], [-1.0023524744126133], [1.2569830862391298], [1.0967465216538999], [-1.2320248836514431], [0.5893307338006715], [-1.2907782906660275], [-0.158439900930402], [-0.687220564061661], [-0.1530986821108943], [-1.712734577407133], [1.9620239704141416], [1.9192942198580807], [-0.7299503146177224], [-1.1999775707343971], [1.2195945545025761], [-0.9916700367735981], [-0.6017610629495384], [0.16737444705956575], [0.786955830122455], [-0.8421159098273834], [-1.3014607283050428], [-1.087811975524736], [0.6908138913713171], [1.1501587098489765], [-0.37208865371070876], [0.22612785407415004], [-0.4575481548228314], [-0.3667474348912011], [0.4771651385910105], [0.25283394817168825], [1.2943716179756832], [-0.4735718112813544], [-0.3400413407936627], [-0.6605144699641228], [-0.3614062160716934], [-2.1293496453287313], [-0.4094771854472623], [1.1020877404734075], [-0.9809875991345828], [0.9365099570686698], [-0.37208865371070876], [-1.1252005072612896], [-0.3827710913497241], [-0.23855818322301706], [0.6320604843567326], [-0.8207510345493527], [0.49853001386904094], [-0.7833625028127991], [2.036801033887249], [-0.25458183968153997], [-0.31333524669612434], [-1.0611058814271976], [-1.3976026670561807], [-0.4735718112813544], [-0.7459739710762454], [0.5733070773421484], [-0.1370750256523713], [-0.7139266581591994], [3.847474213700349], [0.24749272935218072], [-0.2118520891254787], [0.5092124515080563], [-0.8100685969103374], [0.18873932233759644], [-0.655173251144615], [-0.7780212839932913], [-0.09434527509631005], [-0.959622723856552], [0.2314690728936576], [0.017820320113350947], [-0.6658556887836303], [0.07657372712793545], [-0.607102281769046], [-0.4094771854472623], [0.3222697928252881], [-0.8901868792029525], [-0.11571015037434074], [-0.9275754109395061], [-0.174463557388925], [-0.510960343017908], [-1.3068019471245504], [-0.14775746329138664], [0.39170563747888776], [-1.1572478201783356], [0.7922970489419627], [-1.2106600083734125], [-0.286629152598586], [-0.07298039981827936], [0.5893307338006715], [-0.23855818322301706], [-0.46823059246184673], [1.273006742697653], [-1.0984944131637513], [-0.5643725312129847], [-0.4094771854472623], [0.7762733924834396], [0.27954004226922674], [-0.7780212839932913], [-0.23855818322301706], [2.9554906708425674], [0.883097768873593], [-1.7714879844217175], [-0.4094771854472623], [-0.05161552454024867], [0.642742921995748], [-0.18514599502794035], [-0.6605144699641228], [2.191696379652971], [-0.12105136919384829], [0.8243443618590088], [0.31692857400578034], [-0.41481840426677], [0.02850275775236629], [-1.413626323514704], [-0.6391495946860921], [-0.25992305850104763], [1.2195945545025761], [-1.1198592884417822], [-0.28128793377907835], [0.18873932233759644], [0.40772929393741064], [0.24749272935218072], [-1.9424069866459628], [-1.0130349120516287], [-1.7875116408802405], [0.039185195391381634], [-0.06763918099877168], [0.8350267994980242], [-0.25458183968153997], [-0.8367746910078757], [0.5572834208836255], [0.8457092371370395], [-0.3293589031546474], [-0.5216427806569233], [0.4290941692154413], [0.9685572699857158], [0.18873932233759644], [-1.7287582338656562], [1.9673651892336497], [0.25283394817168825], [-0.4522069360033237], [-0.7352915334372301], [-1.2640721965684891], [0.8724153312345777], [-1.0130349120516287], [0.8190031430395011], [1.1661823663074995], [-0.9275754109395061], [0.44511782567396446], [-1.1305417260807975], [-0.3774298725302164], [2.442733664169832], [-0.559031312393477], [-0.591078625310523], [1.8231522811069423], [0.32761101164479567], [-0.575054968852], [-0.47891303010086206], [-0.23855818322301706], [-1.5151094810853494], [-1.6112514198364873], [0.9952633640832541], [0.3863644186593799], [0.8670741124150702], [-0.9062105356614755], [-0.302652809057109], [0.9418511758881773], [1.0112870205417772], [-0.2492406208620324], [0.963216051166208], [1.267665523878145], [0.5092124515080563], [0.6320604843567326], [1.833834718745958], [-0.4201596230862777], [0.6534253596347633], [0.2955636987277496], [0.642742921995748], [-0.655173251144615], [-0.3240176843351397], [-0.03559186808172577], [-0.30799402787661667], [0.9525336135271927], [-0.8688220039249217], [-1.4777209493487957], [-0.6711969076031381], [0.26351638581070363], [-0.019568211623202637], [-0.1050277127353254], [-0.11036893155483306], [-0.4895954677398774], [1.6468920600631893], [-0.7940449404518145], [0.4558002633129798], [0.3810231998398724], [0.1727156658790733], [0.22612785407415004], [0.9578748323467005], [-0.05695674335975634], [0.35431710574233394], [2.3572741630577094], [1.443925744921898], [-0.6017610629495384], [0.9738984888052233], [1.5774562154095897], [-0.07298039981827936], [-0.3453825596131704], [-0.16378111974990966], [0.30090491754725746], [0.5305773267860869], [0.10862104004498124], [-0.767338846354276], [-0.3934535289887393], [-0.2118520891254787], [-0.11036893155483306], [-1.1946363519148895], [0.2688576046302114], [0.4023880751179031], [0.06055007066941232], [0.3970468562983953], [-0.09968649391581771], [0.70683754782984], [-0.12105136919384829], [0.10327982122547369], [2.191696379652971], [-0.019568211623202637], [0.642742921995748], [-0.6284671570470768], [-1.8622887043533478], [-0.9222341921199984], [0.9738984888052233], [0.8083207054004856], [0.27419882344971896], [-0.446865717183816], [-0.2919703714180937], [1.4866554954779594], [-0.6338083758665843], [-0.25458183968153997], [1.3691486814487908], [-0.7246090957982148], [0.11396225886448903], [-0.4895954677398774], [0.04986763303039698], [-1.0611058814271976], [-0.7246090957982148], [0.18873932233759644], [0.7922970489419627], [0.7228612042883632], [1.0219694581807923], [0.27419882344971896], [1.2463006486001142], [-1.6219338574755027], [-0.5002779053788927], [0.03384397657187408], [-0.3400413407936627], [0.1406683529620273], [-0.7192678769787071], [0.306246136366765], [1.9513415327751265], [0.10327982122547369], [-0.6017610629495384], [0.5252361079665794], [-0.591078625310523], [0.3222697928252881], [0.8457092371370395], [-1.087811975524736], [0.039185195391381634], [0.15669200942055042], [-1.2694134153879966], [-0.07298039981827936], [-0.158439900930402], [2.1543078479164177], [0.6908138913713171], [3.0623150472327216], [-1.413626323514704], [0.9899221452637466], [0.18873932233759644], [0.1994217599766118], [-0.2118520891254787], [-0.9062105356614755], [0.5252361079665794], [0.5038712326885487], [-0.1798047762084327], [-0.158439900930402], [0.20476297879611935], [0.10327982122547369], [-2.7329073719330976], [-0.1798047762084327], [0.15135079060104262], [1.7537164364533429], [0.8724153312345777], [-1.4510148552512574], [1.6575744977022049], [-0.03559186808172577], [-0.7887037216323066], [0.02850275775236629], [0.017820320113350947], [0.6160368278982097], [-0.13173380683286362], [-1.1305417260807975], [-0.7887037216323066], [-1.1732714766368588], [0.9471923947076851], [0.8190031430395011], [-0.7513151898957531], [-1.328166822402581], [2.30920319368214], [0.6320604843567326], [-0.4575481548228314], [0.5893307338006715], [-0.38811231016923164], [-0.37208865371070876], [0.5412597644251023], [0.194080541157104], [-0.543007655934954], [0.43443538803494913], [-0.591078625310523], [-0.11036893155483306], [-1.087811975524736], [0.3756819810203646], [1.7216691235362969], [0.22078663525464223], [0.35431710574233394], [-1.6219338574755027], [-0.1050277127353254], [-0.25992305850104763], [-0.2652642773205553], [1.2409594297806068], [0.5893307338006715], [-0.019568211623202637], [0.14600957178153506], [-0.5216427806569233], [-0.07832161863778703], [3.50029499043235], [-0.05161552454024867], [0.9418511758881773], [-0.2118520891254787], [-1.5151094810853494], [1.5881386530486052], [-1.4456736364317497], [-2.401751805123622], [-1.2640721965684891], [-0.9756463803150751], [-0.2759467149595706], [1.273006742697653], [0.7335436419273785], [-0.510960343017908], [1.2890303991561756], [-1.2266836648319355], [-1.814217734977779], [-0.35072377843267805], [-0.510960343017908], [0.43443538803494913], [-0.5323252182959387], [0.6053543902591944], [-0.14775746329138664], [-0.5964198441300307], [-0.5483488747544617], [-0.2118520891254787], [0.7175199854688553], [-0.5803961876715077], [-0.5803961876715077], [-0.9542815050370443], [0.8563916747760548], [0.26351638581070363], [-0.8581395662859064], [0.6961551101908247], [1.1501587098489765], [0.36499954338134927], [-1.2213424460124278], [-0.687220564061661], [-0.1370750256523713], [0.626719265537225], [0.5893307338006715], [-0.27060549614006296], [0.36499954338134927], [-0.607102281769046], [1.4065372131853446], [-0.5964198441300307], [0.674790234912794], [0.4718239197715027], [-1.1038356319832592], [0.9365099570686698], [-0.2492406208620324], [1.4492669637414055], [0.12464469650350438], [-0.9756463803150751], [0.12998591532301193], [-0.7833625028127991], [0.3863644186593799], [1.3050540556146988], [-0.6765381264226457], [0.9258275194296545], [2.004753720970203], [0.06055007066941232], [0.41841173157642597], [1.6415508412436817], [-0.2492406208620324], [-0.014226992803695085], [-2.3323159604700225], [-0.4201596230862777], [-0.47891303010086206], [-1.7287582338656562], [-0.9062105356614755], [1.8178110622874348], [-1.6112514198364873], [-0.655173251144615], [3.254598924734997], [2.1436254102774024], [-0.14241624447187898], [-2.1881030523433154], [-1.9691130807435013], [1.155499928668484], [-1.0343997873296595], [-1.5631804504609186], [-0.4575481548228314], [0.8991214253321159], [0.562624639703133], [-0.7246090957982148], [-0.607102281769046], [-0.14775746329138664], [0.7816146113029474], [0.7335436419273785], [-0.27060549614006296], [0.8296855806785164], [0.10327982122547369], [0.2848812610887343], [-0.03025064926221798], [0.22612785407415004], [1.3798311190878059], [0.1727156658790733], [1.4065372131853446], [0.0658912894889201], [0.9204863006101467], [-0.959622723856552], [-0.510960343017908], [3.564389616266442], [0.6694490160932864], [-0.7459739710762454], [0.05520885184990477], [0.5519422020641177], [0.8670741124150702], [0.46114148213248735], [0.8136619242199935], [-0.28128793377907835], [3.3560820823056434], [1.7590576552728503], [-0.5857374064910154], [-1.0397410061491672], [1.1661823663074995], [-0.019568211623202637], [-0.18514599502794035], [-0.5697137500324924], [-0.9970112555931058], [-0.24389940204252475], [0.9471923947076851], [-0.9168929733004908], [0.1727156658790733], [-1.2907782906660275], [-0.27060549614006296], [1.716327904716789], [-0.31333524669612434], [0.1994217599766118], [-0.19582843266695568], [-0.6711969076031381], [1.2783479615171605], [-1.9424069866459628], [-0.06229796217926401], [-0.7887037216323066], [-0.959622723856552], [0.4664827009519951], [-0.4842542489203697], [-2.1079847700507006], [-0.2919703714180937], [0.0658912894889201], [0.9685572699857158], [-2.2254915840798692], [-1.1198592884417822], [1.273006742697653], [1.82849349992645], [-1.5952277633779646], [-0.6017610629495384], [0.1994217599766118], [-0.8527983474663987], [-0.9168929733004908], [-1.2694134153879966], [0.8884389876931006], [-0.1050277127353254], [-1.6806872644900872], [0.10862104004498124], [2.4694397582673697], [-1.5792041069194414], [-1.6913697021291023], [1.107428959292915], [-0.9008693168419678], [-1.7501231091436869], [0.21544541643513468], [0.0658912894889201], [-0.703244220520184], [-0.5056191241984004], [0.7442260795663939], [1.1287938345709458], [-0.6765381264226457], [1.2356182109610991], [-0.25992305850104763], [1.604162309507128], [-1.312143165944058], [0.07123250830842766], [-1.1038356319832592], [-1.1786126954563663], [-0.03025064926221798], [2.2985207560431253], [-0.8367746910078757], [0.24215151053267292], [-1.8569474855338401], [1.1661823663074995], [-0.24389940204252475], [0.06055007066941232], [0.6908138913713171], [0.20476297879611935], [0.5038712326885487], [0.40772929393741064], [-1.0504234437881825], [0.6106956090787021], [0.9204863006101467], [-0.1530986821108943], [1.497337933116975], [-0.6017610629495384], [0.4931887950495334], [-0.3667474348912011], [1.385172337907314], [3.137092110705828], [-0.07298039981827936], [0.9258275194296545], [-0.318676465515632], [0.081914945947443], [-0.9809875991345828], [-2.262880115816423], [-0.623125938227569], [0.044526414210889424], [0.2314690728936576], [0.6160368278982097], [-0.18514599502794035], [0.9044626441516238], [0.594671952620179], [-0.05161552454024867], [-0.703244220520184], [0.7816146113029474], [0.594671952620179], [-1.344190478861104], [1.2356182109610991], [0.9204863006101467], [-0.9970112555931058], [0.6160368278982097], [1.5347264648535284], [-0.4575481548228314], [2.60831144757457], [-0.6711969076031381], [0.6641077972737787], [0.5466009832446102], [1.5721149965900822], [-0.5964198441300307], [0.12464469650350438], [-1.2427073212904585], [1.3264189308927294], [-0.16912233856941733], [1.6522332788826974], [0.194080541157104], [0.06055007066941232], [-0.05695674335975634], [0.039185195391381634], [0.26351638581070363], [-1.167930257817351], [0.4397766068544567], [0.3810231998398724], [-0.1530986821108943], [0.8083207054004856], [-0.8100685969103374], [-0.767338846354276], [-0.11571015037434074], [0.8563916747760548], [0.851050455956547], [-1.8409238290753172], [-0.9382578485785213], [-1.8569474855338401], [-0.9489402862175367], [-0.510960343017908], [2.2931795372236166], [-1.0397410061491672], [-1.1412241637198128], [0.562624639703133], [0.8884389876931006], [-0.6765381264226457], [-0.2652642773205553], [-0.29731159023760134], [0.40772929393741064], [1.1608411474879916], [-0.543007655934954], [0.9525336135271927], [1.2569830862391298], [-0.024909430442710427], [0.6694490160932864], [1.1234526157514382], [-0.20651087030597104], [0.10327982122547369], [1.1181113969319307], [-0.8741632227444294], [1.8498583752044806], [-0.863480785105414], [-0.7780212839932913], [-0.35072377843267805], [-1.488403386987811], [-3.59818482069334], [-0.943599067398029], [-1.0984944131637513], [-0.7833625028127991], [0.5893307338006715], [-0.6658556887836303], [0.626719265537225], [-0.2919703714180937], [0.7121787666493478], [-0.943599067398029], [1.5827974342290974], [-0.8848456603834448], [0.5092124515080563], [-0.7619976275347684], [0.0017966636548280492], [-0.4575481548228314], [-0.7139266581591994], [-0.3827710913497241], [0.6480841408152558], [0.2314690728936576], [1.9566827515946341], [1.321077712073222], [-1.8836535796313785], [-0.003544555164679741], [-0.911551754480983], [0.18873932233759644], [-2.33765717928953], [-0.318676465515632], [0.9685572699857158], [-0.33470012197415505], [-0.3827710913497241], [-0.13173380683286362], [-0.6444908135055997], [0.27419882344971896], [1.0646992087368536], [-2.636765433181959], [-0.7299503146177224], [-2.0759374571336546], [-2.1881030523433154], [0.6961551101908247], [-0.05161552454024867], [0.044526414210889424], [-0.4094771854472623], [1.1287938345709458], [-0.12639258801335596], [-0.9382578485785213], [0.36499954338134927], [-0.37208865371070876], [0.6053543902591944], [0.32761101164479567], [-0.07298039981827936], [-0.18514599502794035], [-0.5697137500324924], [-1.0771295378857206], [-0.9916700367735981], [0.4718239197715027], [-0.31333524669612434], [0.023161538932858737], [0.8403680183175317], [-0.9836582085443366], [0.07123250830842766], [-1.2961195094855351], [-0.3667474348912011], [-0.03025064926221798], [0.5252361079665794], [1.1234526157514382], [-1.0717883190662132], [1.8124698434679272], [0.49853001386904094], [0.338293449283811], [-0.430842060725293], [0.0658912894889201], [-0.1530986821108943], [-1.2213424460124278], [0.8991214253321159], [0.450459044493472], [-0.959622723856552], [-0.8047273780908298], [0.7762733924834396], [-0.5002779053788927], [0.18339810351808866], [-0.4361832795448007], [-1.413626323514704], [1.1928884604050378], [0.7014963290103324], [1.9566827515946341], [0.8670741124150702], [-1.7661467656022098], [2.7097946051452153], [-1.1519066013588282], [-1.9744542995630088], [1.0486755522783306], [-0.174463557388925], [-0.2652642773205553], [1.1768648039465146], [-1.1145180696222745], [1.3103952744342064], [-0.20116965148646337], [0.963216051166208], [1.1928884604050378], [-0.35072377843267805], [0.8617328935955624], [-0.11036893155483306], [0.08725616476695056], [0.023161538932858737], [0.41841173157642597], [-0.8581395662859064], [-0.05161552454024867], [0.16203322824005797], [1.2302769921415917], [-0.5483488747544617], [-0.3774298725302164], [0.39170563747888776], [0.642742921995748], [-1.0984944131637513], [0.21010419761562713], [0.49853001386904094], [0.9098038629711314], [-0.35072377843267805], [1.9086117822190651], [-0.014226992803695085], [-0.655173251144615], [0.5252361079665794], [0.5519422020641177], [0.37034076220085704], [-1.0237173496906442], [-0.2759467149595706], [-0.510960343017908], [-0.4895954677398774], [-1.7180757962266409], [0.6694490160932864], [-1.0343997873296595], [-0.8367746910078757], [0.48250635741051806], [-0.37208865371070876], [-0.23855818322301706], [-0.8421159098273834], [2.5655816970185086], [0.450459044493472], [1.1982296792245453], [1.0379931146393155], [0.9471923947076851], [0.27419882344971896], [-1.312143165944058], [0.35431710574233394], [-0.19048721384744802], [-0.6124435005885538], [-1.7714879844217175], [-0.13173380683286362], [1.3744899002682984], [-0.943599067398029], [-0.2332169644035094], [0.16737444705956575], [-0.6017610629495384], [-2.88780271769882], [-0.4361832795448007], [1.946000313955619], [1.2569830862391298], [0.8937802065126084], [3.105044797788783], [-0.8848456603834448], [-0.12105136919384829], [-0.1530986821108943], [0.7175199854688553], [-2.1240084265092234], [-0.5536900935739694], [0.7175199854688553], [0.8777565500540855], [-1.1625890389978435], [-0.8207510345493527], [2.1863551608334637], [0.7014963290103324], [-0.318676465515632], [0.11930347768399659], [-0.40413596662775464], [-1.7287582338656562], [-0.6017610629495384], [1.3371013685317445], [-0.3667474348912011], [0.41841173157642597], [1.3050540556146988], [1.8178110622874348], [0.02850275775236629], [1.2943716179756832], [-0.49493668655938505], [0.3222697928252881], [-0.18514599502794035], [-0.11571015037434074], [1.1608411474879916], [1.2409594297806068], [1.8231522811069423], [1.091405302834392], [-0.1370750256523713], [0.29022247990824207], [1.9940712833311878], [-0.6765381264226457], [0.044526414210889424], [-0.5056191241984004], [0.31692857400578034], [-1.0343997873296595], [-0.879504441563937], [1.3531250249902678], [-0.07298039981827936], [-1.0237173496906442], [-0.1530986821108943], [0.1406683529620273], [-0.19582843266695568], [-0.767338846354276], [-0.1798047762084327], [0.0979386024059659], [-1.0343997873296595], [-1.5471567940023956], [0.8617328935955624], [0.16737444705956575], [0.7014963290103324], [-1.525791918724365], [-0.6391495946860921], [-0.6444908135055997], [0.16203322824005797], [2.656382416950139], [-1.312143165944058], [0.3115873551862728], [-0.18514599502794035], [-1.0659129783647547], [0.9204863006101467], [1.716327904716789], [1.1127701781124226], [-0.655173251144615], [-0.3614062160716934], [0.851050455956547], [1.0646992087368536], [-0.31333524669612434], [0.05520885184990477], [0.3970468562983953], [-1.05576466260769], [0.5679658585226408], [0.2848812610887343], [-0.6124435005885538], [1.273006742697653], [0.05520885184990477], [0.194080541157104], [0.5092124515080563], [-0.05161552454024867], [0.6213780467177172], [-0.30799402787661667], [-0.5163015618374157], [-1.280095853027012], [-1.0183761308711365], [-1.3708965729586426], [0.09259738358645835], [-0.7513151898957531], [0.3115873551862728], [-0.446865717183816], [-2.2575388969969152], [1.6949630294387583], [1.0166282393612847], [-0.5216427806569233], [2.8860548261889685], [0.30090491754725746], [0.10862104004498124], [-0.7887037216323066], [-0.1530986821108943], [0.8724153312345777], [1.8445171563849732], [-0.20651087030597104], [-1.5792041069194414], [0.6908138913713171], [-0.7940449404518145], [1.0753816463758692], [0.4397766068544567], [-0.07298039981827936], [-0.8741632227444294], [0.04986763303039698], [-1.8943360172703936], [0.007137882474335602], [-0.158439900930402], [-0.2332169644035094], [2.9608318896620753], [-0.25992305850104763], [1.0486755522783306], [0.1406683529620273], [1.6362096224241742], [-0.8955280980224601], [-0.2332169644035094], [1.385172337907314], [-0.3560649972521857], [-0.5163015618374157], [-0.16378111974990966], [0.338293449283811], [-0.21719330794498637], [-0.25458183968153997], [0.1406683529620273], [0.48250635741051806], [0.786955830122455], [0.754908517205409], [-0.42550084190578535], [-0.24389940204252475], [1.620185965965651], [-1.488403386987811], [1.9620239704141416], [1.443925744921898], [1.6255271847851587], [1.7697400929118658], [0.5359185456055947], [-0.5857374064910154], [0.4664827009519951], [-0.37208865371070876], [0.5359185456055947], [-0.16912233856941733], [1.0326518958198079], [-0.19582843266695568], [0.70683754782984], [0.9845809264442387], [-0.6444908135055997], [-0.3667474348912011], [2.1276017538188796], [1.5133615895754977], [-0.024909430442710427], [2.0314598150677416], [0.6961551101908247], [-0.7513151898957531], [0.2955636987277496], [-0.5002779053788927], [-0.591078625310523], [-0.25992305850104763], [2.3946626947942633], [0.10327982122547369], [-0.19582843266695568], [1.443925744921898], [-0.9970112555931058], [0.05520885184990477], [0.5466009832446102], [1.5293852460340207], [0.02850275775236629], [1.6789393729802355], [-0.9970112555931058], [0.12464469650350438], [-0.4735718112813544], [-1.1519066013588282], [1.2356182109610991], [0.07657372712793545], [-1.408285104695196], [-0.8527983474663987], [0.3810231998398724], [-0.943599067398029], [0.7228612042883632], [0.9204863006101467], [0.3756819810203646], [0.3489758869228264], [1.9246354386775884], [0.8350267994980242], [0.3115873551862728], [-0.7406327522567377], [-0.398794747808247], [-0.8047273780908298], [3.2278928306374595], [1.0486755522783306], [-1.3014607283050428], [-0.1798047762084327], [-0.7993861592713221], [1.267665523878145], [-0.302652809057109], [1.273006742697653], [-0.21719330794498637], [-1.5524980128219033], [0.14600957178153506], [1.0646992087368536], [0.594671952620179], [1.0540167710978385], [-1.37623779177815], [0.18873932233759644], [-0.3614062160716934], [-0.9062105356614755], [0.4023880751179031], [0.3810231998398724], [-0.5376664371154464], [-0.3560649972521857], [0.007137882474335602], [-1.0290585685101519], [0.6480841408152558], [-0.2492406208620324], [1.2997128367951913], [-1.3708965729586426], [-0.47891303010086206], [-0.14775746329138664], [1.2516418674196224], [-1.1145180696222745], [0.562624639703133], [-1.7981940785192558], [0.5092124515080563], [-0.6391495946860921], [1.1181113969319307], [-1.2053187895539048], [-0.37208865371070876], [2.5922877911160462], [0.6106956090787021], [-0.14775746329138664], [0.12998591532301193], [0.6854726725518093], [-0.158439900930402], [1.3584662438097752], [1.5293852460340207], [2.14896662909691], [0.4130705127569184], [0.5359185456055947], [-0.3240176843351397], [0.1406683529620273], [-0.9222341921199984], [0.562624639703133], [-0.9703051614955673], [-0.607102281769046], [0.626719265537225], [0.7282024231078708], [0.017820320113350947], [-0.7246090957982148], [-1.7340994526851639], [-0.22253452676449406], [0.1727156658790733], [0.8083207054004856], [-0.3827710913497241], [1.1928884604050378], [-0.2118520891254787], [-1.4349911987927344], [1.8605408128434962], [0.8029794865809781], [0.9151450817906391], [-0.03559186808172577], [-0.5697137500324924], [0.7121787666493478], [0.0979386024059659], [0.15135079060104262], [0.21544541643513468], [-0.2118520891254787], [-1.0130349120516287], [-1.2053187895539048], [-0.29731159023760134], [1.0753816463758692], [-0.623125938227569], [-0.12639258801335596], [0.044526414210889424], [0.12998591532301193], [0.16737444705956575], [2.207720036111495], [0.7228612042883632], [0.754908517205409], [-1.0023524744126133], [-0.9863288179540904], [0.08725616476695056], [0.642742921995748], [0.6694490160932864], [0.9418511758881773], [-0.35072377843267805], [-2.5299410567918064], [-0.7352915334372301], [0.562624639703133], [-0.05161552454024867], [-0.543007655934954], [-0.8955280980224601], [-0.5803961876715077], [-1.3976026670561807], [1.0967465216538999], [-0.8741632227444294], [0.9792397076247311], [-0.623125938227569], [-0.14775746329138664], [-1.92638333018744], [0.48250635741051806], [-0.6605144699641228], [-1.600568982197472], [-0.9275754109395061], [2.8379838568133997], [0.22612785407415004], [-0.03559186808172577], [-1.4723797305292883], [-1.248048540109966], [0.8884389876931006], [-0.5002779053788927], [-0.40413596662775464], [0.02850275775236629], [-1.2053187895539048], [-0.046274305720741114], [1.2997128367951913], [-0.8688220039249217], [-1.3655553541391348], [-0.5002779053788927], [-0.9008693168419678], [-1.0130349120516287], [0.27419882344971896], [-0.5323252182959387], [1.620185965965651], [0.27419882344971896], [-1.1839539142758742], [-0.12639258801335596], [-1.1999775707343971], [-1.1091768508027668], [0.7495672983859014], [0.13532713414251973], [0.514553670327564], [0.6320604843567326], [-0.46823059246184673], [1.267665523878145], [0.6908138913713171], [0.6320604843567326], [0.12998591532301193], [-0.47891303010086206], [0.43443538803494913], [-0.25992305850104763], [2.245108567848048], [-0.13173380683286362], [0.1727156658790733], [0.6694490160932864], [0.3756819810203646], [-0.41481840426677], [1.0700404275563613], [2.3519329442382015], [2.512169508823431], [0.36499954338134927], [1.1768648039465146], [1.4385845261023904], [0.03384397657187408], [1.1341350533904533], [0.15669200942055042], [0.18873932233759644], [0.0658912894889201], [-1.440332417612242], [-0.5643725312129847], [-0.21719330794498637], [2.501487071184416], [1.1127701781124226], [-0.12105136919384829], [-0.158439900930402], [0.16203322824005797], [-0.40413596662775464], [0.5359185456055947], [-1.9317245490069475], [0.29022247990824207], [-0.6925617828811687], [-0.07298039981827936], [2.245108567848048], [0.48250635741051806], [1.8178110622874348], [-0.25992305850104763], [-0.9275754109395061], [2.004753720970203], [2.3198856313211556], [0.6961551101908247], [0.9578748323467005], [0.49853001386904094], [1.0006045829027619], [0.306246136366765], [-0.7139266581591994], [-1.8569474855338401], [0.11396225886448903], [-1.135882944900305], [0.33295223046430344], [-0.5697137500324924], [0.6213780467177172], [0.8403680183175317], [-0.2492406208620324], [-0.6391495946860921], [-2.273562553455438], [0.514553670327564], [1.1501587098489765], [-0.014226992803695085], [0.35431710574233394], [-0.18514599502794035], [0.70683754782984], [0.22612785407415004], [-1.0611058814271976], [0.12464469650350438], [-0.30799402787661667], [-0.0836628374572947], [-0.9703051614955673], [-0.5803961876715077], [2.816618981535368], [1.8445171563849732], [-1.6967109209486102], [0.5572834208836255], [1.3584662438097752], [-0.12639258801335596], [0.16203322824005797], [-0.4735718112813544], [-0.5163015618374157], [1.497337933116975], [0.41841173157642597], [0.21010419761562713], [-0.9329166297590137], [-0.6658556887836303], [-1.3388492600415964], [-0.6979030017006763], [0.41841173157642597], [-0.943599067398029], [-0.3560649972521857], [0.044526414210889424], [-0.11571015037434074], [0.27419882344971896], [0.07123250830842766], [2.0848720032628183], [-0.16378111974990966], [0.46114148213248735], [-0.5216427806569233], [-0.47891303010086206], [0.8190031430395011], [1.3531250249902678], [0.306246136366765], [-1.0130349120516287], [0.5466009832446102], [0.7655909548444243], [2.6243351040330927], [1.1448174910294688], [0.5412597644251023], [-1.1412241637198128], [0.37034076220085704], [1.6575744977022049], [-2.0332077065775933], [0.3863644186593799], [-2.4658464309577144], [0.9098038629711314], [0.2688576046302114], [-0.046274305720741114], [-1.6112514198364873], [1.3691486814487908], [0.24215151053267292], [-0.575054968852], [-0.9542815050370443], [-1.05576466260769], [-0.5216427806569233], [-0.6338083758665843], [1.0112870205417772], [0.21544541643513468], [0.4023880751179031], [0.3489758869228264], [-0.40413596662775464], [0.4558002633129798], [-1.600568982197472], [0.081914945947443], [-0.024909430442710427], [-0.446865717183816], [-0.6444908135055997], [0.7709321736639321], [1.2569830862391298], [0.7282024231078708], [-0.4094771854472623], [-0.2919703714180937], [-0.6605144699641228], [-0.9222341921199984], [-0.2118520891254787], [-0.911551754480983], [-0.430842060725293], [-0.40413596662775464], [-0.12105136919384829], [1.0700404275563613], [0.3863644186593799], [0.5519422020641177], [-0.6765381264226457], [1.1020877404734075], [-1.2266836648319355], [0.4558002633129798], [1.2943716179756832], [-0.7566564087152606], [-1.0771295378857206], [0.9952633640832541], [0.29022247990824207], [-0.6338083758665843], [1.1448174910294688], [-1.712734577407133], [0.07657372712793545], [-0.9916700367735981], [-0.33470012197415505], [-0.7139266581591994], [1.4065372131853446], [-1.05576466260769], [-0.13173380683286362], [2.832642637993892], [1.203570898044053], [1.5667737777705746], [-1.814217734977779], [0.2688576046302114], [-0.831433472188368], [0.05520885184990477], [-0.07832161863778703], [-1.2854370718465198], [0.4931887950495334], [-1.5845453257389492], [-0.46823059246184673], [0.7655909548444243], [3.067656266052229], [-1.760805546782702], [-0.5056191241984004], [-2.118667207689716], [-1.2640721965684891], [-0.19048721384744802], [-0.6444908135055997], [0.32761101164479567], [-0.9062105356614755], [-0.847457128646891], [0.4718239197715027], [0.023161538932858737], [-0.1530986821108943], [0.10862104004498124], [2.1436254102774024], [-0.019568211623202637], [-0.318676465515632], [0.1727156658790733], [2.6403587604916154], [0.8029794865809781], [-1.1732714766368588], [-0.44152449836430835], [0.7014963290103324], [0.24749272935218072], [0.10862104004498124], [0.4290941692154413], [-0.446865717183816], [1.5614325589510665], [-1.4670385117097804], [0.8670741124150702], [-1.280095853027012], [0.34363466810331883], [-0.12105136919384829], [-0.27060549614006296], [-0.5323252182959387], [1.1608411474879916], [-1.600568982197472], [-0.2652642773205553], [-0.430842060725293], [0.5786482961616561], [0.4023880751179031], [-0.510960343017908], [0.05520885184990477], [1.2302769921415917], [0.27954004226922674], [1.2890303991561756], [0.6534253596347633], [-0.9649639426760597], [0.5038712326885487], [0.626719265537225], [-0.5163015618374157], [-0.19048721384744802], [-0.6391495946860921], [-0.959622723856552], [0.6854726725518093], [0.7495672983859014], [-1.344190478861104], [-1.648639951573041], [-0.5643725312129847], [0.4878475762300256], [-0.8100685969103374], [-0.174463557388925], [-0.4522069360033237], [0.3115873551862728], [1.946000313955619], [-0.06763918099877168], [0.338293449283811], [-0.19582843266695568], [-0.158439900930402], [0.6801314537323018], [0.194080541157104], [0.7121787666493478], [-0.7993861592713221], [0.3115873551862728], [-0.05161552454024867], [-0.6605144699641228], [0.6961551101908247], [-1.4029438858756884], [0.8029794865809781], [-1.6539811703925489], [-0.19048721384744802], [1.2890303991561756], [-0.302652809057109], [-0.16378111974990966], [-0.44152449836430835], [-0.2919703714180937], [-0.7726800651737837], [-2.0278664877580854], [-0.9062105356614755], [1.1341350533904533], [0.32761101164479567], [-0.49493668655938505], [1.8231522811069423], [0.11930347768399659], [0.8563916747760548], [-0.9222341921199984], [2.4320512265308167], [-1.3228256035830734], [0.4130705127569184], [-0.19582843266695568], [-0.4842542489203697], [-0.040933086901233325], [-0.6338083758665843], [-1.440332417612242], [2.7685480121597994], [0.023161538932858737], [-1.05576466260769], [-1.1305417260807975], [-0.25458183968153997], [0.8777565500540855], [0.41841173157642597], [-0.019568211623202637], [2.7097946051452153], [0.5038712326885487], [1.8124698434679272], [1.8017874058289116], [-1.2373661024709508], [0.044526414210889424], [-0.40413596662775464], [-1.7073933585876255], [0.9204863006101467], [0.18873932233759644], [0.9578748323467005], [-1.3068019471245504], [-0.06763918099877168], [0.13532713414251973], [-0.12105136919384829], [0.8617328935955624], [1.3103952744342064], [0.4023880751179031], [-0.591078625310523], [0.15135079060104262], [-0.2919703714180937], [0.5466009832446102], [-0.7833625028127991], [-0.37208865371070876], [0.6587665784542711], [-1.1732714766368588], [0.4718239197715027], [-0.3667474348912011], [-0.575054968852], [-0.03559186808172577], [-0.8421159098273834], [0.4718239197715027], [0.08725616476695056], [2.4106863512527856], [-1.3495316976806118], [-0.4842542489203697], [0.8617328935955624], [0.2314690728936576], [-0.8848456603834448], [-0.7192678769787071], [-0.9542815050370443], [-0.6338083758665843], [0.3863644186593799], [-0.5323252182959387], [0.9525336135271927], [-1.3014607283050428], [2.53887560292097], [0.7922970489419627], [-0.6658556887836303], [0.4771651385910105], [-0.7513151898957531], [-1.461697292890273], [-1.9530894242849781], [0.007137882474335602], [-0.28128793377907835], [-0.6711969076031381], [-0.318676465515632], [-0.11571015037434074], [-0.559031312393477], [-0.37208865371070876], [1.0646992087368536], [0.25283394817168825], [1.0273106770002998], [0.07657372712793545], [-0.9756463803150751], [0.3115873551862728], [0.9738984888052233], [-1.1892951330953816], [-1.7287582338656562], [-0.28128793377907835], [0.2314690728936576], [-0.23855818322301706], [-1.8249001726167942], [-1.1572478201783356], [0.044526414210889424], [-1.6700048268510717], [0.02850275775236629], [-0.49493668655938505], [1.315736493253714], [-0.25458183968153997], [0.9098038629711314], [0.5786482961616561], [-0.6605144699641228], [-2.0705962383141467], [0.851050455956547], [-0.174463557388925], [1.8124698434679272], [-0.2492406208620324], [-0.6177847194080615], [-0.8688220039249217], [-0.4201596230862777], [1.3371013685317445], [0.18873932233759644], [-0.5002779053788927], [1.0059458017222693], [1.9566827515946341], [0.05520885184990477], [-1.2320248836514431], [3.185163080081398], [-0.21719330794498637], [-0.22787574558400173], [-0.5323252182959387], [0.1727156658790733], [-0.6765381264226457], [0.5092124515080563], [0.21010419761562713], [2.421368788891801], [0.9044626441516238], [-0.20651087030597104], [0.10862104004498124], [-1.0931531943442439], [0.39170563747888776], [1.4492669637414055], [-0.6124435005885538], [0.2955636987277496], [1.491996714297467], [0.2688576046302114], [0.7816146113029474], [-0.6338083758665843], [1.2836891803366681], [-0.5056191241984004], [-0.6818793452421534], [-1.9210421113679321], [0.0017966636548280492], [-0.16912233856941733], [-0.9382578485785213], [-0.6177847194080615], [1.433243307282883], [1.34778380617076], [0.22078663525464223], [-1.6913697021291023], [0.6053543902591944], [0.626719265537225], [-0.4361832795448007], [-0.9863288179540904], [-1.6112514198364873], [-0.3293589031546474], [-1.632616295114518], [0.8563916747760548], [-0.03559186808172577], [-0.6605144699641228], [0.5572834208836255], [-0.7833625028127991], [1.5187028083950056], [3.7246261808516725], [0.6053543902591944], [0.007137882474335602], [-0.7833625028127991], [-0.46288937364233906], [-1.007693693232121], [1.1234526157514382], [0.642742921995748], [0.4664827009519951], [0.32761101164479567], [-1.5151094810853494], [-0.1530986821108943], [0.8991214253321159], [-0.7192678769787071], [0.7388848607468861], [0.8457092371370395], [-0.16912233856941733], [0.8991214253321159], [0.0017966636548280492], [0.9044626441516238], [0.8029794865809781], [-1.1572478201783356], [-1.8889947984508861], [0.0017966636548280492], [0.46114148213248735], [-0.7139266581591994], [-0.019568211623202637], [2.245108567848048], [0.5786482961616561], [0.081914945947443], [-1.3174843847635658], [1.9406590951361113], [-0.5483488747544617], [-0.9062105356614755], [-0.8741632227444294], [0.24749272935218072], [1.0700404275563613], [0.9899221452637466], [0.5839895149811637], [1.4172196508243597], [0.16737444705956575], [-1.3815790105976578], [-0.5269839994764309], [-0.20116965148646337], [-0.9329166297590137], [-0.2118520891254787], [0.48250635741051806], [0.039185195391381634], [-1.0450822249686746], [-1.360214135319627], [1.732351561175312], [0.9151450817906391], [-0.575054968852], [0.2581751669911961], [-0.9008693168419678], [-0.6124435005885538], [1.0700404275563613], [0.626719265537225], [1.593479871868113], [-0.8688220039249217], [1.1982296792245453], [-1.05576466260769], [1.3798311190878059], [-0.174463557388925], [0.21544541643513468], [-0.003544555164679741], [-1.0130349120516287], [-0.06763918099877168], [-0.6711969076031381], [0.1727156658790733], [0.0017966636548280492], [-1.2747546342075045], [-0.3614062160716934], [-0.12105136919384829], [0.14600957178153506], [0.35431710574233394], [-0.37208865371070876], [0.5305773267860869], [-0.024909430442710427], [-0.06229796217926401], [1.043334333458823], [-0.24389940204252475], [1.545408902492544], [1.1875472415855302], [-2.9839446564499577], [-0.7726800651737837], [1.043334333458823], [-2.615400557903929], [1.273006742697653], [0.35431710574233394], [0.11396225886448903], [-0.2759467149595706], [-0.09434527509631005], [-0.9489402862175367], [-1.3335080412220888], [1.6575744977022049], [2.8059365438963533], [-1.648639951573041], [-0.5964198441300307], [0.8937802065126084], [1.785763749370389], [-1.3815790105976578], [-0.5163015618374157], [1.0379931146393155], [-1.360214135319627], [-0.3614062160716934], [-0.03025064926221798], [-0.831433472188368], [-0.11036893155483306], [-1.872971141992363], [-0.5857374064910154], [0.081914945947443], [-1.0984944131637513], [1.7003042482582662], [1.9192942198580807], [-0.3774298725302164], [-0.4201596230862777], [1.0112870205417772], [0.15135079060104262], [0.27954004226922674], [-0.11036893155483306], [0.7816146113029474], [-0.5697137500324924], [-0.3934535289887393], [-0.11571015037434074], [-1.3976026670561807], [0.5839895149811637], [0.26351638581070363], [0.26351638581070363], [0.6480841408152558], [-1.05576466260769], [0.22078663525464223], [-0.5163015618374157], [-0.446865717183816], [2.175672723194449], [-1.1198592884417822], [0.626719265537225], [-0.003544555164679741], [0.27419882344971896], [-0.6284671570470768], [0.5786482961616561], [-0.03559186808172577], [-0.49493668655938505], [0.0017966636548280492], [0.14600957178153506], [0.49853001386904094], [-0.510960343017908], [-0.3293589031546474], [0.43443538803494913], [0.7762733924834396], [-0.07298039981827936], [1.7911049681898965], [-0.3293589031546474], [-0.09434527509631005], [-0.879504441563937], [1.3584662438097752], [0.16203322824005797], [-0.42550084190578535], [-0.4842542489203697], [-0.09968649391581771], [0.33295223046430344], [-1.2266836648319355], [-0.4094771854472623], [0.10327982122547369], [-1.3174843847635658], [0.9044626441516238], [0.931168738249162], [-0.3934535289887393], [-0.9275754109395061], [-0.7352915334372301], [0.20476297879611935], [-2.33765717928953], [-0.38811231016923164], [2.912760920286506], [0.48250635741051806], [0.023161538932858737], [-0.687220564061661], [0.08725616476695056], [-1.1038356319832592], [0.7655909548444243], [-0.03559186808172577], [-0.9756463803150751], [1.9353178763166035], [0.48250635741051806], [-0.767338846354276], [1.1928884604050378], [-1.440332417612242], [0.20476297879611935], [1.3798311190878059], [0.5572834208836255], [-1.712734577407133], [-0.3774298725302164], [1.1448174910294688], [0.5359185456055947], [0.3970468562983953], [0.26351638581070363], [0.13532713414251973], [-1.2854370718465198], [-0.7352915334372301], [-1.9691130807435013], [0.14600957178153506], [0.3756819810203646], [-0.44152449836430835], [0.07657372712793545], [0.05520885184990477], [1.0753816463758692], [-0.05695674335975634], [-1.0824707567052285], [-0.607102281769046], [-1.0450822249686746], [-0.9703051614955673], [0.1994217599766118], [-0.510960343017908], [0.3863644186593799], [-0.4895954677398774], [-0.4842542489203697], [0.41841173157642597], [-0.24389940204252475], [0.16737444705956575], [-0.9970112555931058], [-1.167930257817351], [0.4290941692154413], [-1.1572478201783356], [1.1661823663074995], [0.8190031430395011], [-0.2759467149595706], [0.08725616476695056], [-1.0343997873296595], [-0.12639258801335596], [-1.0771295378857206], [1.321077712073222], [-0.943599067398029], [-0.6711969076031381], [-1.4777209493487957], [1.5507501213120514], [-1.2747546342075045], [0.6587665784542711], [-0.2759467149595706], [0.6694490160932864], [-1.8676299231728555], [0.5786482961616561], [1.2569830862391298], [0.5733070773421484], [0.5305773267860869], [0.7976382677614703], [-0.31333524669612434], [-0.8367746910078757], [-1.3335080412220888], [-0.430842060725293], [-0.2492406208620324], [0.29022247990824207], [-0.6338083758665843], [-0.20651087030597104], [-1.6165926386559952], [-0.4895954677398774], [0.3222697928252881], [-1.007693693232121], [-0.9489402862175367], [-0.7993861592713221], [-0.6979030017006763], [-0.47891303010086206], [0.06055007066941232], [3.3614233011251513], [0.081914945947443], [-0.03559186808172577], [0.6480841408152558], [-0.7085854393396918], [-0.5163015618374157], [0.14600957178153506], [-0.4522069360033237], [0.642742921995748], [-0.7993861592713221], [-0.847457128646891], [-0.046274305720741114], [-0.18514599502794035], [-0.5643725312129847], [1.1768648039465146], [0.32761101164479567], [0.29022247990824207], [-0.008885773984187294], [-0.446865717183816], [1.203570898044053], [0.3970468562983953], [-0.22253452676449406], [-0.5002779053788927], [-0.575054968852], [-1.4777209493487957], [-1.1625890389978435], [-3.0106507505474966], [0.34363466810331883], [-1.1732714766368588], [0.3756819810203646], [-0.9382578485785213], [-0.7726800651737837], [-0.623125938227569], [-0.7993861592713221], [-1.2427073212904585], [1.0753816463758692], [-0.3400413407936627], [-0.06229796217926401], [-0.687220564061661], [1.3905135567268216], [0.1994217599766118], [-0.5857374064910154], [0.5733070773421484], [-1.0450822249686746], [-0.2759467149595706], [-1.5952277633779646], [-1.37623779177815], [-0.27060549614006296], [-1.4029438858756884], [0.2314690728936576], [0.7655909548444243], [-1.6806872644900872], [1.1768648039465146], [0.8029794865809781], [-0.16378111974990966], [-0.040933086901233325], [-1.1892951330953816], [-1.2587309777489815], [0.6801314537323018], [0.017820320113350947], [1.0700404275563613], [-1.0343997873296595], [-0.4522069360033237], [-0.6979030017006763], [-0.11571015037434074], [0.07657372712793545], [0.7602497360249167], [0.3970468562983953], [-0.7406327522567377], [-0.4361832795448007], [-1.007693693232121], [-0.847457128646891], [-1.1732714766368588], [0.7709321736639321], [-0.3774298725302164], [0.338293449283811], [-0.8955280980224601], [-0.7887037216323066], [0.10327982122547369], [0.26351638581070363], [-1.3495316976806118], [0.7175199854688553], [2.939467014384045], [-0.5056191241984004], [0.2688576046302114], [-1.3708965729586426], [-1.2373661024709508], [-0.22787574558400173], [0.15669200942055042], [-1.5471567940023956], [0.40772929393741064], [0.5359185456055947], [-0.559031312393477], [0.24215151053267292], [-0.8207510345493527], [-0.655173251144615], [0.08725616476695056], [2.6403587604916154], [-0.09968649391581771], [0.3810231998398724], [1.620185965965651], [-2.310951085191992], [-0.09434527509631005], [1.315736493253714], [-0.5536900935739694], [2.6724060734086614], [0.012479101293843393], [0.9525336135271927], [0.5305773267860869], [0.9098038629711314], [-0.398794747808247], [-0.11571015037434074], [-0.7459739710762454], [-0.1050277127353254], [-0.014226992803695085], [0.36499954338134927], [-0.20116965148646337], [0.5466009832446102], [-0.2332169644035094], [-0.6925617828811687], [-0.7139266581591994], [-2.2041267088018386], [1.7537164364533429], [0.7816146113029474], [-0.37208865371070876], [0.16737444705956575], [-0.9489402862175367], [-0.591078625310523], [0.8403680183175317], [1.0486755522783306], [2.3572741630577094], [-0.024909430442710427], [1.3103952744342064], [1.545408902492544], [-1.3708965729586426], [0.36499954338134927], [-0.2118520891254787], [2.0848720032628183], [-0.22787574558400173], [0.8670741124150702], [1.3103952744342064], [0.786955830122455], [0.9098038629711314], [0.0017966636548280492], [-0.158439900930402], [-1.2587309777489815], [-2.1293496453287313], [-1.2854370718465198], [-0.9222341921199984], [0.70683754782984], [0.3489758869228264], [0.20476297879611935], [0.1780568846985811], [1.3050540556146988], [-0.446865717183816], [-0.9062105356614755], [-1.2373661024709508], [-0.9703051614955673], [1.5774562154095897], [0.7442260795663939], [-0.008885773984187294], [-0.5216427806569233], [0.08725616476695056], [-1.4456736364317497], [-0.09968649391581771], [0.27954004226922674], [0.5412597644251023], [0.3756819810203646], [-0.8527983474663987], [-2.0438901442166086], [0.27954004226922674], [-0.9970112555931058], [-0.09434527509631005], [0.6534253596347633], [0.2848812610887343], [-0.174463557388925], [-0.014226992803695085], [0.21544541643513468], [-0.3560649972521857], [-1.413626323514704], [3.484271333973827], [-0.49493668655938505], [1.1661823663074995], [-0.7993861592713221], [-0.831433472188368], [-2.252197678177408], [0.4130705127569184], [1.3584662438097752], [0.594671952620179], [2.0207773774287263], [1.0112870205417772], [-0.6658556887836303], [0.2314690728936576], [0.7335436419273785], [1.443925744921898], [0.6694490160932864], [1.3103952744342064], [0.0017966636548280492], [1.2195945545025761], [0.39170563747888776], [1.2516418674196224], [-0.6017610629495384], [-0.03559186808172577], [-1.3388492600415964], [-0.7887037216323066], [1.1768648039465146], [-0.14775746329138664], [-0.9916700367735981], [0.0658912894889201], [-0.5857374064910154], [-1.7554643279631945], [-0.08900405627680237], [-1.872971141992363], [0.2688576046302114], [-1.600568982197472], [0.5252361079665794], [1.491996714297467], [-0.7833625028127991], [-0.3667474348912011], [-1.5471567940023956], [0.1727156658790733], [-1.520450699904857], [-0.22787574558400173], [-0.008885773984187294], [-0.11571015037434074], [-0.607102281769046], [-0.22787574558400173], [-0.9008693168419678], [-1.4990858246268264], [-0.6177847194080615], [0.34363466810331883], [-0.46288937364233906], [-0.7085854393396918], [-0.8047273780908298], [0.1727156658790733], [1.5614325589510665], [-0.47891303010086206], [0.7922970489419627], [-0.11571015037434074], [-0.14241624447187898], [-0.7940449404518145], [0.04986763303039698], [-1.37623779177815], [-1.525791918724365], [-0.31333524669612434], [-0.29731159023760134], [0.22078663525464223], [-1.4510148552512574], [0.931168738249162], [-0.8688220039249217], [0.02850275775236629], [-0.09434527509631005], [-0.30799402787661667], [-0.6391495946860921], [1.2997128367951913], [0.5305773267860869], [0.5679658585226408], [-0.12639258801335596], [-0.655173251144615], [-0.5536900935739694], [1.4118784320048523], [0.04986763303039698], [0.6961551101908247], [-0.3400413407936627], [0.1780568846985811], [0.27954004226922674], [-0.9168929733004908], [0.883097768873593], [1.4065372131853446], [0.6961551101908247], [-2.5886944638063905], [-0.398794747808247], [-0.019568211623202637], [-0.7940449404518145], [1.8178110622874348], [-0.07298039981827936], [0.06055007066941232], [-0.158439900930402], [-0.46288937364233906], [0.11396225886448903], [-0.06763918099877168], [0.33295223046430344], [-1.7768292032412252], [-0.1530986821108943], [-0.5056191241984004], [2.159649066735925], [-0.591078625310523], [0.4290941692154413], [-0.2492406208620324], [0.8937802065126084], [-0.7993861592713221], [-0.2652642773205553], [1.273006742697653], [-0.29731159023760134], [0.07123250830842766], [-0.014226992803695085], [1.1181113969319307], [0.6801314537323018], [-0.25992305850104763], [-0.12639258801335596], [-0.4575481548228314], [0.33295223046430344], [-0.6765381264226457], [0.9525336135271927], [-0.14775746329138664], [0.3970468562983953], [-0.8154098157298452], [-0.5857374064910154], [0.31692857400578034], [-0.5643725312129847], [0.10327982122547369], [-1.1145180696222745], [-0.003544555164679741], [1.0967465216538999], [-0.20651087030597104], [0.5412597644251023], [-0.9329166297590137], [0.21544541643513468], [-0.2492406208620324], [0.023161538932858737], [-0.13173380683286362], [-1.7501231091436869], [-0.302652809057109], [-1.007693693232121], [-1.0343997873296595], [0.7495672983859014], [-0.2652642773205553], [-0.3400413407936627], [-1.280095853027012], [-1.0984944131637513], [0.2314690728936576], [-0.16378111974990966], [1.5881386530486052], [-0.8100685969103374], [-0.5163015618374157], [-1.9424069866459628], [-1.3174843847635658], [-0.7726800651737837], [-1.5845453257389492], [0.18873932233759644], [0.26351638581070363], [-0.863480785105414], [0.1406683529620273], [-0.6925617828811687], [-1.0130349120516287], [0.3970468562983953], [0.05520885184990477], [-0.07298039981827936], [0.08725616476695056], [1.267665523878145], [0.04986763303039698], [1.0006045829027619], [-1.408285104695196], [0.11930347768399659], [-0.9703051614955673], [-1.9317245490069475], [1.2783479615171605], [-0.5163015618374157], [1.4706318390194362], [0.8190031430395011], [0.22078663525464223], [-0.2492406208620324], [0.8136619242199935], [0.1994217599766118], [0.25283394817168825], [0.8190031430395011], [1.1822060227660223], [-0.6925617828811687], [0.9792397076247311], [0.7228612042883632], [-0.959622723856552], [0.10862104004498124], [1.0967465216538999], [-0.014226992803695085], [-0.4201596230862777], [0.21544541643513468], [0.3596583245618417], [0.8670741124150702], [1.208912116863561], [0.46114148213248735], [-0.6711969076031381], [0.2688576046302114], [-1.461697292890273], [-1.087811975524736], [0.26351638581070363], [-1.5418155751828877], [-0.13173380683286362], [0.16203322824005797], [0.9151450817906391], [-0.38811231016923164], [-0.6818793452421534], [0.10862104004498124], [0.6374017031762405], [-0.33470012197415505], [1.8124698434679272], [0.35431710574233394], [-0.23855818322301706], [-0.24389940204252475], [1.0700404275563613], [-0.11571015037434074], [-0.5643725312129847], [0.7922970489419627], [1.2569830862391298], [-0.6605144699641228], [0.5839895149811637], [-0.29731159023760134], [0.7495672983859014], [-0.1530986821108943], [-0.2332169644035094], [-1.9584306431044858], [-0.2118520891254787], [0.9899221452637466], [3.762014712588226], [-0.0836628374572947], [0.22078663525464223], [-1.0824707567052285], [-0.33470012197415505], [-0.7993861592713221], [1.0753816463758692], [-1.0023524744126133], [0.11396225886448903], [0.4878475762300256], [-1.4777209493487957], [-0.158439900930402], [1.0593579899173462], [-1.6112514198364873], [0.8991214253321159], [-2.775637122489159], [-0.5056191241984004], [0.25283394817168825], [0.306246136366765], [-0.9649639426760597], [-1.7821704220607326], [-0.0836628374572947], [-1.2106600083734125], [0.05520885184990477], [0.15669200942055042], [-0.05161552454024867], [2.442733664169832], [0.642742921995748], [-0.5857374064910154], [0.6053543902591944], [0.03384397657187408], [1.1768648039465146], [-0.8581395662859064], [-1.0664471002467053], [0.4290941692154413], [2.0261185962482338], [-1.2320248836514431], [-0.3827710913497241], [-0.46288937364233906], [-1.0717883190662132], [0.10327982122547369], [-1.1465653825393203], [-1.0931531943442439], [1.9833888456921722], [-0.5483488747544617], [2.9982204213986288], [0.49853001386904094], [-0.4361832795448007], [0.30090491754725746], [-1.2747546342075045], [-0.49493668655938505], [-0.27060549614006296], [0.594671952620179], [-0.8047273780908298], [0.0979386024059659], [-0.9168929733004908], [-1.8516062667143325], [0.1994217599766118], [1.208912116863561], [-1.3068019471245504], [-0.8955280980224601], [0.27954004226922674], [-0.08900405627680237], [0.11930347768399659], [2.4267100077113084], [1.2409594297806068], [-1.0023524744126133], [-1.3869202294171654], [0.37034076220085704], [2.2824970995846017], [-0.03559186808172577], [-0.5376664371154464], [0.4718239197715027], [-1.2587309777489815], [-0.5697137500324924], [0.5786482961616561], [1.2302769921415917], [0.5412597644251023], [-1.0504234437881825], [0.7495672983859014], [0.6961551101908247], [-0.3934535289887393], [0.12998591532301193], [-1.4510148552512574], [1.203570898044053], [0.42375295039593375], [0.8136619242199935], [-0.7406327522567377], [-0.19582843266695568], [-0.33470012197415505], [1.9192942198580807], [-1.1198592884417822], [0.514553670327564], [-1.2961195094855351], [-0.22253452676449406], [-0.5643725312129847], [0.03384397657187408], [0.7388848607468861], [0.12464469650350438], [0.6854726725518093], [-1.2747546342075045], [0.07123250830842766], [-0.2759467149595706], [-0.8901868792029525], [-0.31333524669612434], [-1.2213424460124278], [-1.05576466260769], [0.70683754782984], [-0.30799402787661667], [0.2581751669911961], [-0.158439900930402], [0.2955636987277496], [-1.4029438858756884], [0.194080541157104], [1.0807228651953769], [-0.7459739710762454], [-0.024909430442710427], [-0.2919703714180937], [0.6320604843567326], [-0.174463557388925], [1.1341350533904533], [-1.4830621681683036], [0.012479101293843393], [-0.7139266581591994], [-0.20651087030597104], [0.39170563747888776], [1.3905135567268216], [1.2783479615171605], [0.5786482961616561], [-0.49493668655938505], [0.06055007066941232], [-1.568521669280426], [1.267665523878145], [-1.4777209493487957], [0.27954004226922674], [-0.863480785105414], [0.8350267994980242], [-0.27060549614006296], [0.20476297879611935], [0.16203322824005797], [-0.5216427806569233], [1.6949630294387583], [0.34363466810331883], [0.0658912894889201], [-0.27060549614006296], [0.963216051166208], [-2.1079847700507006], [-0.3667474348912011], [0.8296855806785164], [-1.5151094810853494], [0.4558002633129798], [-0.286629152598586], [-0.4522069360033237], [-0.8367746910078757], [-1.2053187895539048], [-0.4201596230862777], [0.7014963290103324], [0.22612785407415004], [0.3756819810203646], [-0.33470012197415505], [-0.4201596230862777], [1.833834718745958], [-0.7459739710762454], [0.11396225886448903], [2.6296763228526], [-0.158439900930402], [0.32761101164479567], [-1.4723797305292883], [-0.6017610629495384], [1.1501587098489765], [-0.24389940204252475], [0.883097768873593], [-1.8569474855338401], [-0.7299503146177224], [-0.30799402787661667], [0.4023880751179031], [-0.7887037216323066], [-0.4201596230862777], [-1.5631804504609186], [-0.12105136919384829], [-1.7073933585876255], [0.18873932233759644], [-0.07832161863778703], [-0.06229796217926401], [0.06055007066941232], [-1.5952277633779646], [-0.9863288179540904], [2.4747809770868785], [-1.3655553541391348], [0.9204863006101467], [-0.5216427806569233], [0.023161538932858737], [0.338293449283811], [-1.0130349120516287], [1.273006742697653], [0.24749272935218072], [3.6017781480029956], [1.8712232504825113], [0.4397766068544567], [-0.575054968852], [0.754908517205409], [0.8296855806785164], [0.6374017031762405], [1.043334333458823], [-0.31333524669612434], [1.2783479615171605], [-0.41481840426677], [0.21544541643513468], [-0.4361832795448007], [3.2065279553594284], [0.18873932233759644], [1.2836891803366681], [0.8083207054004856], [-1.0397410061491672], [-1.5151094810853494], [0.11396225886448903], [-0.2652642773205553], [0.9738984888052233], [0.43443538803494913], [0.306246136366765], [-3.3631711926350025], [-0.5216427806569233], [-1.1091768508027668], [0.31692857400578034], [1.1501587098489765], [-0.5216427806569233], [0.5305773267860869], [-0.959622723856552], [-0.07298039981827936], [0.49853001386904094], [0.044526414210889424], [-0.18514599502794035], [-2.1720793958847926], [-0.03559186808172577], [-0.28128793377907835], [0.5252361079665794], [1.593479871868113], [-0.49493668655938505], [-0.5536900935739694], [0.642742921995748], [-0.05161552454024867], [-0.33470012197415505], [-0.47891303010086206], [0.23681029171316537], [-0.47891303010086206], [0.7228612042883632], [-1.0023524744126133], [-0.5964198441300307], [-0.5323252182959387], [-0.7780212839932913], [0.07657372712793545], [0.8190031430395011], [-1.4029438858756884], [0.5733070773421484], [-0.7726800651737837], [-0.3667474348912011], [0.0017966636548280492], [0.30090491754725746], [-1.5845453257389492], [1.2516418674196224], [0.9098038629711314], [0.36499954338134927], [2.6189938852135852], [1.8017874058289116], [-0.14775746329138664], [0.07657372712793545], [1.8178110622874348], [-0.5803961876715077], [2.576264134657524], [0.1406683529620273], [-0.40413596662775464], [0.8937802065126084], [-0.7139266581591994], [1.34778380617076], [-0.863480785105414], [1.5133615895754977], [0.4558002633129798], [-1.3869202294171654], [0.20476297879611935], [-0.831433472188368], [-0.575054968852], [-0.7726800651737837], [-0.40413596662775464], [-0.37208865371070876], [0.48250635741051806], [0.8136619242199935], [-1.0183761308711365], [0.8617328935955624], [-0.8260922533688604], [-0.286629152598586], [-0.879504441563937], [0.7655909548444243], [0.5092124515080563], [-0.47891303010086206], [-0.8901868792029525], [1.6362096224241742], [-0.040933086901233325], [-3.0907690328401114], [-0.0836628374572947], [-0.879504441563937], [-0.1798047762084327], [-0.37208865371070876], [0.4397766068544567], [1.9192942198580807], [-0.8047273780908298], [-2.0065016124800548], [-0.046274305720741114], [1.1768648039465146], [0.18873932233759644], [-0.4094771854472623], [-0.9863288179540904], [-0.1530986821108943], [-0.09968649391581771], [0.3863644186593799], [-0.5857374064910154], [-0.446865717183816], [1.3905135567268216], [-0.46288937364233906], [0.7709321736639321], [-0.5964198441300307], [1.5187028083950056], [1.5881386530486052], [-0.18514599502794035], [-0.959622723856552], [0.8190031430395011], [-0.5697137500324924], [0.32761101164479567], [-0.07832161863778703], [-0.2118520891254787], [-2.2468564593579], [-0.40413596662775464], [0.5359185456055947], [-0.2759467149595706], [-1.1145180696222745], [1.0967465216538999], [0.36499954338134927], [-0.03025064926221798], [0.31692857400578034], [-0.591078625310523], [2.0635071279847876], [-0.8421159098273834], [-0.7513151898957531], [1.385172337907314], [-0.3614062160716934], [-0.6017610629495384], [3.046291390774198], [1.0486755522783306], [-0.7513151898957531], [2.8273014191743835], [0.27419882344971896], [-1.2053187895539048], [0.6587665784542711], [1.443925744921898], [-0.07832161863778703], [0.5466009832446102], [1.8872469069410345], [-2.695518840196544], [0.6480841408152558], [-0.7085854393396918], [0.626719265537225], [0.24215151053267292], [1.4065372131853446], [-1.135882944900305], [-0.5536900935739694], [-0.8100685969103374], [-0.09968649391581771], [1.481314276658452], [-0.7833625028127991], [0.4931887950495334], [-0.046274305720741114], [-0.9222341921199984], [1.8231522811069423], [0.023161538932858737], [0.24215151053267292], [0.16737444705956575], [-0.03025064926221798], [0.3970468562983953], [0.30090491754725746], [0.7121787666493478], [-2.8237080918647277], [-0.3774298725302164], [1.6255271847851587], [-1.37623779177815], [-0.847457128646891], [-1.9370657678264551], [0.13532713414251973], [-0.7513151898957531], [1.0379931146393155], [1.3050540556146988], [-0.3827710913497241], [0.5893307338006715], [-2.3483396169285458], [-0.25992305850104763], [-0.2652642773205553], [0.27954004226922674], [-0.11036893155483306], [-0.2118520891254787], [3.0356089531351826], [-0.847457128646891], [1.620185965965651], [0.8563916747760548], [0.963216051166208], [1.267665523878145], [1.8712232504825113], [-0.4575481548228314], [0.4290941692154413], [0.14600957178153506], [1.1768648039465146], [0.3489758869228264], [-0.7246090957982148], [-0.40413596662775464], [-0.21719330794498637], [1.0166282393612847], [-0.7139266581591994], [-1.0183761308711365], [-0.7459739710762454], [-2.6794951837380205], [-0.003544555164679741], [-0.943599067398029], [-0.623125938227569], [-1.1038356319832592], [0.43443538803494913], [1.2356182109610991], [-1.872971141992363], [-0.398794747808247], [0.11930347768399659], [1.0166282393612847], [-1.0717883190662132], [0.642742921995748], [0.06055007066941232], [-0.37208865371070876], [-0.4895954677398774], [-0.5269839994764309], [0.786955830122455], [-1.087811975524736], [0.7495672983859014], [0.786955830122455], [0.9738984888052233], [1.0753816463758692], [2.2397673490285404], [0.9098038629711314], [0.25283394817168825], [-2.748931028391621], [-0.07832161863778703], [0.0017966636548280492], [-1.4723797305292883], [-0.2652642773205553], [-1.8302413914363018], [-0.5216427806569233], [0.081914945947443], [-0.8581395662859064], [0.10862104004498124], [0.8991214253321159], [-0.286629152598586], [-0.30799402787661667], [0.007137882474335602], [-0.7459739710762454], [-0.9703051614955673], [0.02850275775236629], [-0.703244220520184], [1.1341350533904533], [-0.430842060725293], [-0.8848456603834448], [-0.25458183968153997], [-0.8207510345493527], [-0.9008693168419678], [-0.6658556887836303], [2.6724060734086614], [-1.3495316976806118], [0.7014963290103324], [-1.8943360172703936], [1.2195945545025761], [0.21010419761562713], [2.5602404781990002], [-0.7139266581591994], [-0.46823059246184673], [1.273006742697653], [1.6308684036046666], [-0.06229796217926401], [-0.1798047762084327], [0.10862104004498124], [0.2314690728936576], [0.594671952620179], [0.04986763303039698], [-0.302652809057109], [-0.8581395662859064], [2.159649066735925], [1.0219694581807923], [0.18339810351808866], [-0.6979030017006763], [-1.0023524744126133], [-0.5056191241984004], [-1.2640721965684891], [0.0017966636548280492], [-0.3934535289887393], [-1.0504234437881825], [-0.3293589031546474], [0.6000131714396868], [-0.46823059246184673], [0.642742921995748], [-1.3335080412220888], [0.7762733924834396], [-0.6605144699641228], [-1.7394406715046713], [1.4172196508243597], [1.2569830862391298], [0.3489758869228264], [0.754908517205409], [0.13532713414251973], [1.1501587098489765], [-0.18514599502794035], [-0.7085854393396918], [-0.7887037216323066], [-0.6765381264226457], [-0.1370750256523713], [2.3786390383357396], [-0.510960343017908], [0.21010419761562713], [-1.0183761308711365], [-0.37208865371070876], [0.8190031430395011], [0.594671952620179], [-0.559031312393477], [0.012479101293843393], [-0.4361832795448007], [-0.2118520891254787], [1.395854775546329], [-0.7139266581591994], [-0.5269839994764309], [-0.03559186808172577], [1.0860640840148843], [0.039185195391381634], [1.1234526157514382], [0.3756819810203646], [0.5572834208836255], [1.7376927799948196], [0.37034076220085704], [0.35431710574233394], [0.15135079060104262], [1.1127701781124226], [1.4225608696438674], [0.07657372712793545], [-0.2919703714180937], [0.24749272935218072], [0.5412597644251023], [1.481314276658452], [-1.6165926386559952], [-1.4670385117097804], [0.5572834208836255], [-0.4842542489203697], [1.5240440272145133], [-0.7619976275347684], [-1.3335080412220888], [0.11396225886448903], [-0.03025064926221798], [-0.49493668655938505], [0.11930347768399659], [-0.2652642773205553], [-0.943599067398029], [0.6961551101908247], [-0.9916700367735981], [1.1341350533904533], [-0.318676465515632], [1.1982296792245453], [0.9151450817906391], [-0.6498320323251074], [0.8029794865809781], [-0.7780212839932913], [0.49853001386904094], [0.16737444705956575], [-0.7299503146177224], [0.27954004226922674], [-0.2492406208620324], [0.33295223046430344], [0.11930347768399659], [3.0195852966766603], [-0.7459739710762454], [0.23681029171316537], [-0.5964198441300307], [-0.5056191241984004], [0.023161538932858737], [-1.9050184549094094], [0.16737444705956575], [0.02850275775236629], [0.5786482961616561], [-0.959622723856552], [0.29022247990824207], [-2.3590220545675606], [0.16737444705956575], [0.8350267994980242], [0.044526414210889424], [0.6320604843567326], [2.3038619748626328], [-0.8367746910078757], [-0.510960343017908], [0.09259738358645835], [-0.5216427806569233], [1.0700404275563613], [0.32761101164479567], [0.626719265537225], [-0.5857374064910154], [0.851050455956547], [0.10327982122547369], [-0.3400413407936627], [0.33295223046430344], [0.0017966636548280492], [-0.6605144699641228], [-0.302652809057109], [-0.5269839994764309], [0.6320604843567326], [-1.5097682622658417], [2.6724060734086614], [0.6961551101908247], [-0.559031312393477], [0.16203322824005797], [-0.9382578485785213], [-2.460505212138206], [-0.7139266581591994], [-0.7619976275347684], [-0.9275754109395061], [-0.9703051614955673], [-0.9062105356614755], [-0.9329166297590137], [0.5412597644251023], [-1.2587309777489815], [-0.0836628374572947], [-2.1079847700507006], [-1.3335080412220888], [-1.312143165944058], [-1.0824707567052285], [-0.591078625310523], [-0.8688220039249217], [0.27419882344971896], [1.6148447471461436], [1.1608411474879916], [0.70683754782984], [0.5359185456055947], [-0.510960343017908], [0.8884389876931006], [-0.05695674335975634], [-0.174463557388925], [0.0017966636548280492], [-0.5643725312129847], [2.6189938852135852], [-1.5044270434463343], [-0.31333524669612434], [-1.37623779177815], [0.16203322824005797], [0.7388848607468861], [-0.2332169644035094], [0.09259738358645835], [-0.9863288179540904], [-0.6391495946860921], [1.620185965965651], [-0.37208865371070876], [-0.25458183968153997], [0.8083207054004856], [0.5038712326885487], [0.27954004226922674], [-1.3335080412220888], [2.2504497866675552], [1.3744899002682984], [2.1543078479164177], [-0.607102281769046], [0.674790234912794], [-0.2652642773205553], [-0.5216427806569233], [-1.3548729165001194], [0.5092124515080563], [-1.0023524744126133], [-1.0450822249686746], [0.3810231998398724], [-0.4361832795448007], [0.306246136366765], [0.5038712326885487], [0.5733070773421484], [0.514553670327564], [0.48250635741051806], [-0.9382578485785213], [-0.18514599502794035], [-0.12639258801335596], [0.754908517205409], [-0.046274305720741114], [1.2356182109610991], [1.2836891803366681], [0.4878475762300256], [-2.0278664877580854], [0.194080541157104], [-0.16378111974990966], [0.5786482961616561], [0.46114148213248735], [0.642742921995748], [0.18339810351808866], [0.04986763303039698], [0.3756819810203646], [-0.7406327522567377], [-1.0717883190662132], [0.7442260795663939], [-0.6444908135055997], [-0.22253452676449406], [1.331760149712237], [0.25283394817168825], [-1.8195589537972865], [-0.7513151898957531], [-0.6605144699641228], [-1.648639951573041], [-0.06229796217926401], [-0.1050277127353254], [-1.3708965729586426], [-0.6017610629495384], [-0.6124435005885538], [-1.3068019471245504], [2.0314598150677416], [-1.7073933585876255], [0.3756819810203646], [-1.8302413914363018], [0.24215151053267292], [-2.0652550194946393], [0.1727156658790733], [-0.19582843266695568], [-0.8848456603834448], [1.1768648039465146], [0.37034076220085704], [0.34363466810331883], [0.3489758869228264], [0.8083207054004856], [-0.7139266581591994], [-0.7726800651737837], [-0.4361832795448007], [-0.25992305850104763], [-0.5323252182959387], [-0.3240176843351397], [-1.573862888099934], [-1.0237173496906442], [-0.23855818322301706], [0.8777565500540855], [1.9032705633995575], [-0.07832161863778703], [-0.040933086901233325], [0.8190031430395011], [0.306246136366765], [0.46114148213248735], [0.49853001386904094], [0.4878475762300256], [-0.9275754109395061], [0.6000131714396868], [0.16203322824005797], [0.039185195391381634], [-1.7821704220607326], [2.1008956597213415], [1.9566827515946341], [0.4397766068544567], [-0.024909430442710427], [0.642742921995748], [0.14600957178153506], [-0.14241624447187898], [-0.7246090957982148], [0.8403680183175317], [-0.5857374064910154], [-0.2492406208620324], [0.7816146113029474], [-1.712734577407133], [-1.0237173496906442], [-0.19048721384744802], [-1.6806872644900872], [-0.6711969076031381], [-0.2919703714180937], [0.5038712326885487], [-0.22253452676449406], [0.10862104004498124], [-0.5056191241984004], [-1.4777209493487957], [-0.6391495946860921], [0.35431710574233394], [0.4397766068544567], [-0.591078625310523], [-1.8516062667143325], [0.562624639703133], [0.017820320113350947], [-1.0290585685101519], [0.3222697928252881], [-0.446865717183816], [-0.7085854393396918], [-0.8260922533688604], [0.6908138913713171], [-0.21719330794498637], [0.10862104004498124], [-0.03025064926221798], [0.2848812610887343], [-0.16912233856941733], [-0.3614062160716934], [0.7922970489419627], [1.7643988740923584], [-0.8367746910078757], [0.007137882474335602], [0.851050455956547], [0.6374017031762405], [-0.19048721384744802], [-0.08900405627680237], [-0.6711969076031381], [-0.591078625310523], [-0.07298039981827936], [-0.6498320323251074], [-0.8901868792029525], [0.4290941692154413], [0.5839895149811637], [0.22612785407415004], [0.5252361079665794], [-0.6605144699641228], [-0.22253452676449406], [-0.446865717183816], [-1.9691130807435013], [1.6468920600631893], [-1.2373661024709508], [-1.7714879844217175], [-0.024909430442710427], [0.14600957178153506], [0.49853001386904094], [-2.1720793958847926], [-0.7139266581591994], [0.44511782567396446], [-0.8260922533688604], [-0.9062105356614755], [-2.4231166804016526], [-0.430842060725293], [0.6160368278982097], [0.24749272935218072], [-1.0290585685101519], [-0.9809875991345828], [-0.11571015037434074], [1.1341350533904533], [0.70683754782984], [0.8403680183175317], [-0.7513151898957531], [1.5827974342290974], [-0.38811231016923164], [1.8391759375654655], [-0.7726800651737837], [0.023161538932858737], [-0.8100685969103374], [0.44511782567396446], [-0.3667474348912011], [0.04986763303039698], [0.48250635741051806], [-0.20116965148646337], [0.0658912894889201], [-0.38811231016923164], [0.70683754782984], [-2.375045711026084], [0.15135079060104262], [0.33295223046430344], [-0.8688220039249217], [-0.6979030017006763], [0.4023880751179031], [0.0658912894889201], [-0.21719330794498637], [0.6053543902591944], [0.017820320113350947], [-0.11571015037434074], [0.0017966636548280492], [0.07657372712793545], [-1.8676299231728555], [0.0658912894889201], [0.02850275775236629], [-0.019568211623202637], [0.12464469650350438], [0.21544541643513468], [-0.6979030017006763], [0.3115873551862728], [0.642742921995748], [0.48250635741051806], [-0.510960343017908], [2.8486662944524146], [0.9098038629711314], [2.6510411981306303], [-1.4990858246268264], [-0.019568211623202637], [-1.3548729165001194], [1.2623243050586375], [1.1608411474879916], [1.203570898044053], [-0.19582843266695568], [-0.6124435005885538], [-0.14775746329138664], [-0.05161552454024867], [-2.150714520606762], [-0.607102281769046], [-0.8421159098273834], [-0.20651087030597104], [0.7655909548444243], [-0.559031312393477], [1.1234526157514382], [-0.07298039981827936], [-0.30799402787661667], [-0.31333524669612434], [-0.5643725312129847], [0.9738984888052233], [-0.003544555164679741], [0.5466009832446102], [-0.703244220520184], [0.6000131714396868], [-0.3827710913497241], [0.642742921995748], [2.245108567848048], [1.0753816463758692], [-0.6177847194080615], [-0.4735718112813544], [0.8670741124150702], [-0.2652642773205553], [-0.19048721384744802], [-1.3815790105976578], [-0.024909430442710427], [0.4290941692154413], [-2.0705962383141467], [-0.44152449836430835], [-1.7661467656022098], [0.7175199854688553], [2.0154361586092184], [-1.7073933585876255], [-1.248048540109966], [-0.4094771854472623], [-0.5323252182959387], [1.0219694581807923], [0.07657372712793545], [0.7282024231078708], [0.1994217599766118], [1.208912116863561], [0.5893307338006715], [0.22612785407415004], [-1.4723797305292883], [-0.9916700367735981], [0.33295223046430344], [-0.911551754480983], [-0.12639258801335596], [-0.2652642773205553], [-0.4361832795448007], [-0.05161552454024867], [0.10862104004498124], [-1.1892951330953816], [0.34363466810331883], [0.6106956090787021], [-0.9062105356614755], [0.32761101164479567], [0.0658912894889201], [-0.9863288179540904], [-0.008885773984187294], [-0.31333524669612434], [-0.4361832795448007], [0.4664827009519951], [0.9471923947076851], [-0.5536900935739694], [-1.8409238290753172], [-0.2492406208620324], [-0.767338846354276], [0.10862104004498124], [-0.510960343017908], [-0.9649639426760597], [-0.5964198441300307], [-1.6913697021291023], [1.155499928668484], [-0.24389940204252475], [-1.1305417260807975], [0.3756819810203646], [-0.5056191241984004], [0.5092124515080563], [0.044526414210889424], [-0.06229796217926401], [-0.879504441563937], [-1.0023524744126133], [-0.6658556887836303], [-0.703244220520184], [-0.623125938227569], [-0.6925617828811687], [-0.05161552454024867], [-0.3827710913497241], [-0.37208865371070876], [-0.07832161863778703], [-0.14241624447187898], [-0.5857374064910154], [-0.6124435005885538], [0.6000131714396868], [0.05520885184990477], [-0.22253452676449406], [-2.0438901442166086], [-0.09968649391581771], [0.39170563747888776], [-1.632616295114518], [0.2955636987277496], [-0.6765381264226457], [-0.014226992803695085], [0.5038712326885487], [-0.8154098157298452], [-0.019568211623202637], [0.8243443618590088], [0.7655909548444243], [-1.312143165944058], [0.931168738249162], [0.450459044493472], [-0.9542815050370443], [-0.3453825596131704], [0.22612785407415004], [0.450459044493472], [-0.5002779053788927], [0.081914945947443], [2.0795307844433104], [-0.38811231016923164], [0.674790234912794], [-0.03559186808172577], [-1.4937446058073187], [1.6255271847851587], [2.5922877911160462], [1.9299766574970958], [0.14600957178153506], [-0.9649639426760597], [-0.174463557388925], [-0.591078625310523], [2.821960200354876], [-0.46288937364233906], [0.8296855806785164], [0.5038712326885487], [-0.019568211623202637], [-0.22253452676449406], [2.85934873209143], [-1.2961195094855351], [-0.33470012197415505], [0.16203322824005797], [0.963216051166208], [1.273006742697653], [0.02850275775236629], [-0.14241624447187898], [0.48250635741051806], [-1.2747546342075045], [-0.08900405627680237], [0.5679658585226408], [1.2783479615171605], [0.7762733924834396], [1.7483752176338352], [-1.520450699904857], [0.594671952620179], [1.043334333458823], [-0.8527983474663987], [1.5721149965900822], [0.24749272935218072], [-0.607102281769046], [-0.9275754109395061], [-0.09968649391581771], [-0.49493668655938505], [0.8670741124150702], [-0.05695674335975634], [0.8029794865809781], [-0.7299503146177224], [0.2688576046302114], [-0.2759467149595706], [-0.879504441563937], [1.1501587098489765], [0.11396225886448903], [0.11930347768399659], [0.5252361079665794], [2.159649066735925], [1.043334333458823], [-0.9863288179540904], [0.674790234912794], [3.0195852966766603], [-0.623125938227569], [0.08725616476695056], [-0.5964198441300307], [0.2688576046302114], [-0.21719330794498637], [0.07657372712793545], [0.7014963290103324], [1.2516418674196224], [-1.440332417612242], [-0.5323252182959387], [-0.6177847194080615], [0.24749272935218072], [0.48250635741051806], [-0.05161552454024867], [-2.40709302394313], [-0.19582843266695568], [-0.7726800651737837]]
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,901
Moving model to cuda
Epoch 0
Train function
Loss = 2.1797e-02, PNorm = 35.0659, GNorm = 3.9099, lr_0 = 1.2829e-04
Loss = 1.5172e-02, PNorm = 35.0681, GNorm = 2.2431, lr_0 = 1.5400e-04
Loss = 1.6018e-02, PNorm = 35.0724, GNorm = 1.7654, lr_0 = 1.7971e-04
Loss = 9.1975e-03, PNorm = 35.0784, GNorm = 1.6264, lr_0 = 2.0543e-04
Loss = 8.5438e-03, PNorm = 35.0857, GNorm = 7.8236, lr_0 = 2.3114e-04
Loss = 7.8498e-03, PNorm = 35.0948, GNorm = 4.6487, lr_0 = 2.5686e-04
Loss = 6.5695e-03, PNorm = 35.1025, GNorm = 1.5205, lr_0 = 2.8257e-04
Loss = 5.9563e-03, PNorm = 35.1106, GNorm = 5.0239, lr_0 = 3.0829e-04
Loss = 5.9334e-03, PNorm = 35.1201, GNorm = 2.9150, lr_0 = 3.3400e-04
Loss = 5.0099e-03, PNorm = 35.1324, GNorm = 3.7653, lr_0 = 3.5971e-04
Loss = 5.2563e-03, PNorm = 35.1415, GNorm = 1.9251, lr_0 = 3.8543e-04
Loss = 4.6976e-03, PNorm = 35.1532, GNorm = 5.3481, lr_0 = 4.1114e-04
Loss = 6.3578e-03, PNorm = 35.1638, GNorm = 10.9825, lr_0 = 4.3686e-04
Loss = 5.7079e-03, PNorm = 35.1738, GNorm = 4.1029, lr_0 = 4.6257e-04
Loss = 5.3515e-03, PNorm = 35.1920, GNorm = 1.2541, lr_0 = 4.8829e-04
Loss = 4.9405e-03, PNorm = 35.2080, GNorm = 3.8298, lr_0 = 5.1400e-04
Loss = 4.9290e-03, PNorm = 35.2257, GNorm = 5.4354, lr_0 = 5.3971e-04
Validation rmse = 0.830301
Validation R2 = 0.802952
Epoch 1
Train function
Loss = 4.1478e-03, PNorm = 35.2467, GNorm = 2.3069, lr_0 = 5.6800e-04
Loss = 3.7837e-03, PNorm = 35.2696, GNorm = 3.5022, lr_0 = 5.9371e-04
Loss = 3.0940e-03, PNorm = 35.2868, GNorm = 1.6536, lr_0 = 6.1943e-04
Loss = 3.5566e-03, PNorm = 35.3091, GNorm = 2.2550, lr_0 = 6.4514e-04
Loss = 3.2397e-03, PNorm = 35.3331, GNorm = 1.1744, lr_0 = 6.7086e-04
Loss = 3.9555e-03, PNorm = 35.3539, GNorm = 3.5126, lr_0 = 6.9657e-04
Loss = 3.7622e-03, PNorm = 35.3755, GNorm = 1.5538, lr_0 = 7.2229e-04
Loss = 3.5692e-03, PNorm = 35.4029, GNorm = 2.8805, lr_0 = 7.4800e-04
Loss = 3.3499e-03, PNorm = 35.4296, GNorm = 3.0981, lr_0 = 7.7371e-04
Loss = 2.8673e-03, PNorm = 35.4634, GNorm = 1.5403, lr_0 = 7.9943e-04
Loss = 2.9792e-03, PNorm = 35.4958, GNorm = 2.8931, lr_0 = 8.2514e-04
Loss = 3.1237e-03, PNorm = 35.5257, GNorm = 2.2388, lr_0 = 8.5086e-04
Loss = 2.4077e-03, PNorm = 35.5558, GNorm = 2.3563, lr_0 = 8.7657e-04
Loss = 2.5800e-03, PNorm = 35.5819, GNorm = 2.0468, lr_0 = 9.0229e-04
Loss = 2.4345e-03, PNorm = 35.6077, GNorm = 1.3488, lr_0 = 9.2800e-04
Loss = 2.5875e-03, PNorm = 35.6398, GNorm = 2.4283, lr_0 = 9.5371e-04
Loss = 2.5853e-03, PNorm = 35.6728, GNorm = 1.3418, lr_0 = 9.7943e-04
Loss = 2.8070e-03, PNorm = 35.7119, GNorm = 0.7090, lr_0 = 9.9973e-04
Validation rmse = 0.653385
Validation R2 = 0.877977
Epoch 2
Train function
Loss = 2.5818e-03, PNorm = 35.7484, GNorm = 2.0988, lr_0 = 9.9839e-04
Loss = 2.8179e-03, PNorm = 35.7714, GNorm = 3.6843, lr_0 = 9.9705e-04
Loss = 2.8765e-03, PNorm = 35.7979, GNorm = 3.2447, lr_0 = 9.9571e-04
Loss = 2.9066e-03, PNorm = 35.8243, GNorm = 1.2338, lr_0 = 9.9438e-04
Loss = 2.4777e-03, PNorm = 35.8627, GNorm = 1.3388, lr_0 = 9.9304e-04
Loss = 2.0944e-03, PNorm = 35.8983, GNorm = 1.8648, lr_0 = 9.9171e-04
Loss = 2.7008e-03, PNorm = 35.9203, GNorm = 2.2602, lr_0 = 9.9038e-04
Loss = 1.9753e-03, PNorm = 35.9320, GNorm = 1.4721, lr_0 = 9.8905e-04
Loss = 2.4456e-03, PNorm = 35.9498, GNorm = 0.9693, lr_0 = 9.8772e-04
Loss = 2.7667e-03, PNorm = 35.9735, GNorm = 1.6296, lr_0 = 9.8640e-04
Loss = 3.0052e-03, PNorm = 36.0068, GNorm = 0.8400, lr_0 = 9.8508e-04
Loss = 2.6103e-03, PNorm = 36.0345, GNorm = 0.6816, lr_0 = 9.8375e-04
Loss = 2.2030e-03, PNorm = 36.0628, GNorm = 1.1296, lr_0 = 9.8243e-04
Loss = 2.1635e-03, PNorm = 36.0852, GNorm = 1.5752, lr_0 = 9.8112e-04
Loss = 2.8536e-03, PNorm = 36.1109, GNorm = 0.9877, lr_0 = 9.7980e-04
Loss = 3.0931e-03, PNorm = 36.1487, GNorm = 5.5115, lr_0 = 9.7848e-04
Loss = 3.6925e-03, PNorm = 36.1772, GNorm = 1.6868, lr_0 = 9.7717e-04
Validation rmse = 0.694908
Validation R2 = 0.861975
Epoch 3
Train function
Loss = 2.0989e-03, PNorm = 36.2066, GNorm = 2.2712, lr_0 = 9.7573e-04
Loss = 2.4416e-03, PNorm = 36.2407, GNorm = 0.6204, lr_0 = 9.7442e-04
Loss = 2.0924e-03, PNorm = 36.2669, GNorm = 1.4800, lr_0 = 9.7311e-04
Loss = 2.3280e-03, PNorm = 36.2917, GNorm = 1.2870, lr_0 = 9.7181e-04
Loss = 2.2571e-03, PNorm = 36.3171, GNorm = 1.9939, lr_0 = 9.7050e-04
Loss = 2.5438e-03, PNorm = 36.3367, GNorm = 1.4338, lr_0 = 9.6920e-04
Loss = 2.0901e-03, PNorm = 36.3680, GNorm = 1.7220, lr_0 = 9.6790e-04
Loss = 1.7329e-03, PNorm = 36.3893, GNorm = 1.0277, lr_0 = 9.6660e-04
Loss = 2.5048e-03, PNorm = 36.4084, GNorm = 0.9664, lr_0 = 9.6531e-04
Loss = 1.7906e-03, PNorm = 36.4307, GNorm = 0.6270, lr_0 = 9.6401e-04
Loss = 1.9426e-03, PNorm = 36.4512, GNorm = 2.5395, lr_0 = 9.6272e-04
Loss = 2.2976e-03, PNorm = 36.4716, GNorm = 1.5784, lr_0 = 9.6143e-04
Loss = 1.9988e-03, PNorm = 36.4972, GNorm = 1.8507, lr_0 = 9.6014e-04
Loss = 1.4890e-03, PNorm = 36.5153, GNorm = 0.6218, lr_0 = 9.5885e-04
Loss = 1.6748e-03, PNorm = 36.5473, GNorm = 0.5454, lr_0 = 9.5756e-04
Loss = 1.5818e-03, PNorm = 36.5702, GNorm = 0.7873, lr_0 = 9.5628e-04
Loss = 1.6302e-03, PNorm = 36.5823, GNorm = 1.0508, lr_0 = 9.5499e-04
Loss = 1.8378e-03, PNorm = 36.6100, GNorm = 1.3827, lr_0 = 9.5371e-04
Validation rmse = 0.581576
Validation R2 = 0.903325
Epoch 4
Train function
Loss = 1.4479e-03, PNorm = 36.6372, GNorm = 1.3318, lr_0 = 9.5243e-04
Loss = 1.6248e-03, PNorm = 36.6537, GNorm = 1.7839, lr_0 = 9.5115e-04
Loss = 1.8719e-03, PNorm = 36.6681, GNorm = 2.0399, lr_0 = 9.4988e-04
Loss = 1.8577e-03, PNorm = 36.6929, GNorm = 1.7475, lr_0 = 9.4860e-04
Loss = 1.4348e-03, PNorm = 36.7254, GNorm = 0.7777, lr_0 = 9.4733e-04
Loss = 2.1081e-03, PNorm = 36.7468, GNorm = 0.6267, lr_0 = 9.4606e-04
Loss = 1.8887e-03, PNorm = 36.7767, GNorm = 0.6277, lr_0 = 9.4479e-04
Loss = 1.5878e-03, PNorm = 36.8026, GNorm = 0.7915, lr_0 = 9.4352e-04
Loss = 1.7640e-03, PNorm = 36.8304, GNorm = 0.9455, lr_0 = 9.4226e-04
Loss = 1.5887e-03, PNorm = 36.8538, GNorm = 1.8480, lr_0 = 9.4099e-04
Loss = 2.2160e-03, PNorm = 36.8783, GNorm = 1.4692, lr_0 = 9.3973e-04
Loss = 1.8578e-03, PNorm = 36.8950, GNorm = 0.8196, lr_0 = 9.3847e-04
Loss = 1.5721e-03, PNorm = 36.9232, GNorm = 2.3543, lr_0 = 9.3721e-04
Loss = 2.0235e-03, PNorm = 36.9584, GNorm = 1.5758, lr_0 = 9.3595e-04
Loss = 1.8872e-03, PNorm = 36.9745, GNorm = 1.0639, lr_0 = 9.3470e-04
Loss = 1.4556e-03, PNorm = 37.0086, GNorm = 0.4705, lr_0 = 9.3344e-04
Loss = 1.3437e-03, PNorm = 37.0303, GNorm = 0.6276, lr_0 = 9.3219e-04
Validation rmse = 0.549248
Validation R2 = 0.913774
Epoch 5
Train function
Loss = 1.1390e-03, PNorm = 37.0499, GNorm = 0.6667, lr_0 = 9.3094e-04
Loss = 1.3602e-03, PNorm = 37.0809, GNorm = 0.7479, lr_0 = 9.2969e-04
Loss = 1.2179e-03, PNorm = 37.1148, GNorm = 0.2755, lr_0 = 9.2844e-04
Loss = 1.0380e-03, PNorm = 37.1361, GNorm = 0.4640, lr_0 = 9.2720e-04
Loss = 1.2284e-03, PNorm = 37.1548, GNorm = 0.3975, lr_0 = 9.2595e-04
Loss = 1.5122e-03, PNorm = 37.1739, GNorm = 2.9192, lr_0 = 9.2471e-04
Loss = 1.6106e-03, PNorm = 37.1867, GNorm = 2.3709, lr_0 = 9.2347e-04
Loss = 1.8422e-03, PNorm = 37.2224, GNorm = 0.5627, lr_0 = 9.2223e-04
Loss = 2.0130e-03, PNorm = 37.2499, GNorm = 3.0261, lr_0 = 9.2099e-04
Loss = 1.7719e-03, PNorm = 37.2744, GNorm = 0.7454, lr_0 = 9.1976e-04
Loss = 1.5477e-03, PNorm = 37.3010, GNorm = 0.7224, lr_0 = 9.1852e-04
Loss = 1.2535e-03, PNorm = 37.3206, GNorm = 0.7124, lr_0 = 9.1729e-04
Loss = 1.7471e-03, PNorm = 37.3481, GNorm = 0.6483, lr_0 = 9.1606e-04
Loss = 1.3834e-03, PNorm = 37.3650, GNorm = 0.6294, lr_0 = 9.1483e-04
Loss = 1.6643e-03, PNorm = 37.3879, GNorm = 1.1274, lr_0 = 9.1360e-04
Loss = 1.6092e-03, PNorm = 37.4103, GNorm = 1.1730, lr_0 = 9.1238e-04
Loss = 1.7590e-03, PNorm = 37.4309, GNorm = 1.7817, lr_0 = 9.1115e-04
Loss = 1.8496e-03, PNorm = 37.4496, GNorm = 1.2407, lr_0 = 9.0993e-04
Validation rmse = 0.575054
Validation R2 = 0.905481
Epoch 6
Train function
Loss = 1.3371e-03, PNorm = 37.4764, GNorm = 0.5285, lr_0 = 9.0859e-04
Loss = 1.3131e-03, PNorm = 37.4991, GNorm = 0.7615, lr_0 = 9.0737e-04
Loss = 1.0857e-03, PNorm = 37.5196, GNorm = 0.9727, lr_0 = 9.0615e-04
Loss = 1.1125e-03, PNorm = 37.5393, GNorm = 0.4660, lr_0 = 9.0494e-04
Loss = 1.2950e-03, PNorm = 37.5532, GNorm = 0.6274, lr_0 = 9.0372e-04
Loss = 1.3520e-03, PNorm = 37.5742, GNorm = 2.0490, lr_0 = 9.0251e-04
Loss = 1.4407e-03, PNorm = 37.5958, GNorm = 1.2665, lr_0 = 9.0130e-04
Loss = 1.1809e-03, PNorm = 37.6208, GNorm = 1.2509, lr_0 = 9.0009e-04
Loss = 1.2228e-03, PNorm = 37.6468, GNorm = 1.0993, lr_0 = 8.9888e-04
Loss = 1.4337e-03, PNorm = 37.6742, GNorm = 0.7836, lr_0 = 8.9768e-04
Loss = 1.2238e-03, PNorm = 37.6983, GNorm = 1.8581, lr_0 = 8.9647e-04
Loss = 1.2901e-03, PNorm = 37.7153, GNorm = 0.8799, lr_0 = 8.9527e-04
Loss = 1.3801e-03, PNorm = 37.7334, GNorm = 0.3266, lr_0 = 8.9407e-04
Loss = 1.3810e-03, PNorm = 37.7514, GNorm = 0.8441, lr_0 = 8.9287e-04
Loss = 1.5164e-03, PNorm = 37.7662, GNorm = 0.7514, lr_0 = 8.9167e-04
Loss = 1.3367e-03, PNorm = 37.7914, GNorm = 0.8819, lr_0 = 8.9047e-04
Loss = 1.3769e-03, PNorm = 37.8208, GNorm = 1.5909, lr_0 = 8.8928e-04
Validation rmse = 0.559937
Validation R2 = 0.910385
Epoch 7
Train function
Loss = 7.1891e-04, PNorm = 37.8485, GNorm = 0.3780, lr_0 = 8.8809e-04
Loss = 1.1565e-03, PNorm = 37.8669, GNorm = 0.4411, lr_0 = 8.8689e-04
Loss = 1.1628e-03, PNorm = 37.8941, GNorm = 0.4980, lr_0 = 8.8570e-04
Loss = 9.9519e-04, PNorm = 37.9163, GNorm = 0.6482, lr_0 = 8.8452e-04
Loss = 1.0597e-03, PNorm = 37.9451, GNorm = 0.5598, lr_0 = 8.8333e-04
Loss = 9.6669e-04, PNorm = 37.9700, GNorm = 0.5988, lr_0 = 8.8214e-04
Loss = 1.1266e-03, PNorm = 37.9834, GNorm = 0.7313, lr_0 = 8.8096e-04
Loss = 1.3995e-03, PNorm = 38.0034, GNorm = 1.2357, lr_0 = 8.7978e-04
Loss = 1.2869e-03, PNorm = 38.0238, GNorm = 0.5098, lr_0 = 8.7860e-04
Loss = 1.3908e-03, PNorm = 38.0519, GNorm = 2.4954, lr_0 = 8.7742e-04
Loss = 1.2263e-03, PNorm = 38.0761, GNorm = 1.0621, lr_0 = 8.7624e-04
Loss = 1.1339e-03, PNorm = 38.1032, GNorm = 0.7104, lr_0 = 8.7507e-04
Loss = 1.0417e-03, PNorm = 38.1198, GNorm = 1.8418, lr_0 = 8.7389e-04
Loss = 1.4820e-03, PNorm = 38.1550, GNorm = 0.9719, lr_0 = 8.7272e-04
Loss = 1.3299e-03, PNorm = 38.1726, GNorm = 0.5205, lr_0 = 8.7155e-04
Loss = 1.5544e-03, PNorm = 38.1967, GNorm = 0.9434, lr_0 = 8.7038e-04
Loss = 1.2063e-03, PNorm = 38.2272, GNorm = 1.0035, lr_0 = 8.6921e-04
Loss = 1.2745e-03, PNorm = 38.2438, GNorm = 0.8369, lr_0 = 8.6805e-04
Validation rmse = 0.514450
Validation R2 = 0.924354
Epoch 8
Train function
Loss = 1.0712e-03, PNorm = 38.2728, GNorm = 0.4112, lr_0 = 8.6688e-04
Loss = 9.6539e-04, PNorm = 38.2952, GNorm = 0.6280, lr_0 = 8.6572e-04
Loss = 1.1719e-03, PNorm = 38.3189, GNorm = 1.1446, lr_0 = 8.6456e-04
Loss = 9.4956e-04, PNorm = 38.3435, GNorm = 0.4209, lr_0 = 8.6340e-04
Loss = 1.0438e-03, PNorm = 38.3631, GNorm = 1.8151, lr_0 = 8.6224e-04
Loss = 1.1443e-03, PNorm = 38.3824, GNorm = 0.8719, lr_0 = 8.6108e-04
Loss = 1.2433e-03, PNorm = 38.4115, GNorm = 1.4589, lr_0 = 8.5993e-04
Loss = 1.1168e-03, PNorm = 38.4319, GNorm = 0.8682, lr_0 = 8.5877e-04
Loss = 1.1869e-03, PNorm = 38.4581, GNorm = 1.6595, lr_0 = 8.5762e-04
Loss = 1.2052e-03, PNorm = 38.4831, GNorm = 0.5465, lr_0 = 8.5647e-04
Loss = 1.0487e-03, PNorm = 38.5041, GNorm = 1.1952, lr_0 = 8.5532e-04
Loss = 8.6841e-04, PNorm = 38.5273, GNorm = 0.4855, lr_0 = 8.5417e-04
Loss = 1.0135e-03, PNorm = 38.5454, GNorm = 0.9148, lr_0 = 8.5303e-04
Loss = 1.0623e-03, PNorm = 38.5615, GNorm = 0.7466, lr_0 = 8.5188e-04
Loss = 1.2862e-03, PNorm = 38.5800, GNorm = 1.3544, lr_0 = 8.5074e-04
Loss = 1.0967e-03, PNorm = 38.6045, GNorm = 0.5821, lr_0 = 8.4960e-04
Loss = 1.1914e-03, PNorm = 38.6244, GNorm = 0.4465, lr_0 = 8.4846e-04
Loss = 7.8499e-04, PNorm = 38.6462, GNorm = 0.4192, lr_0 = 8.4732e-04
Loss = 1.0202e-03, PNorm = 38.6480, GNorm = 0.9908, lr_0 = 8.4720e-04
Validation rmse = 0.496028
Validation R2 = 0.929674
Epoch 9
Train function
Loss = 1.1014e-03, PNorm = 38.6656, GNorm = 1.6898, lr_0 = 8.4607e-04
Loss = 1.1978e-03, PNorm = 38.6727, GNorm = 0.6942, lr_0 = 8.4493e-04
Loss = 1.0492e-03, PNorm = 38.6979, GNorm = 0.5997, lr_0 = 8.4380e-04
Loss = 1.0211e-03, PNorm = 38.7231, GNorm = 0.6982, lr_0 = 8.4267e-04
Loss = 1.0672e-03, PNorm = 38.7498, GNorm = 1.0008, lr_0 = 8.4154e-04
Loss = 9.6478e-04, PNorm = 38.7793, GNorm = 0.5369, lr_0 = 8.4041e-04
Loss = 9.8479e-04, PNorm = 38.8054, GNorm = 0.7121, lr_0 = 8.3928e-04
Loss = 8.5775e-04, PNorm = 38.8276, GNorm = 0.4358, lr_0 = 8.3815e-04
Loss = 9.3629e-04, PNorm = 38.8506, GNorm = 0.8748, lr_0 = 8.3703e-04
Loss = 8.9753e-04, PNorm = 38.8690, GNorm = 0.3996, lr_0 = 8.3591e-04
Loss = 8.1396e-04, PNorm = 38.8844, GNorm = 0.4970, lr_0 = 8.3478e-04
Loss = 1.0430e-03, PNorm = 38.9010, GNorm = 1.7297, lr_0 = 8.3366e-04
Loss = 8.8184e-04, PNorm = 38.9236, GNorm = 0.9124, lr_0 = 8.3255e-04
Loss = 9.1606e-04, PNorm = 38.9518, GNorm = 0.9096, lr_0 = 8.3143e-04
Loss = 1.0353e-03, PNorm = 38.9702, GNorm = 0.3184, lr_0 = 8.3031e-04
Loss = 1.1226e-03, PNorm = 38.9900, GNorm = 0.7864, lr_0 = 8.2920e-04
Loss = 1.0720e-03, PNorm = 39.0181, GNorm = 0.8866, lr_0 = 8.2809e-04
Validation rmse = 0.498973
Validation R2 = 0.928837
Epoch 10
Train function
Loss = 6.7545e-04, PNorm = 39.0330, GNorm = 0.3537, lr_0 = 8.2698e-04
Loss = 6.6606e-04, PNorm = 39.0562, GNorm = 0.3888, lr_0 = 8.2587e-04
Loss = 8.3159e-04, PNorm = 39.0784, GNorm = 1.4745, lr_0 = 8.2476e-04
Loss = 7.9289e-04, PNorm = 39.0971, GNorm = 1.1367, lr_0 = 8.2365e-04
Loss = 6.5529e-04, PNorm = 39.1113, GNorm = 0.3991, lr_0 = 8.2255e-04
Loss = 9.1228e-04, PNorm = 39.1259, GNorm = 0.5164, lr_0 = 8.2144e-04
Loss = 8.6507e-04, PNorm = 39.1387, GNorm = 0.5701, lr_0 = 8.2034e-04
Loss = 8.9804e-04, PNorm = 39.1610, GNorm = 0.3702, lr_0 = 8.1924e-04
Loss = 7.9874e-04, PNorm = 39.1792, GNorm = 0.3984, lr_0 = 8.1814e-04
Loss = 7.6134e-04, PNorm = 39.1947, GNorm = 1.3102, lr_0 = 8.1704e-04
Loss = 8.3451e-04, PNorm = 39.2136, GNorm = 0.7457, lr_0 = 8.1595e-04
Loss = 9.8616e-04, PNorm = 39.2391, GNorm = 0.5668, lr_0 = 8.1485e-04
Loss = 8.5628e-04, PNorm = 39.2606, GNorm = 0.7157, lr_0 = 8.1376e-04
Loss = 9.2311e-04, PNorm = 39.2766, GNorm = 0.7427, lr_0 = 8.1267e-04
Loss = 1.0700e-03, PNorm = 39.3049, GNorm = 0.6250, lr_0 = 8.1158e-04
Loss = 1.0239e-03, PNorm = 39.3305, GNorm = 1.0200, lr_0 = 8.1049e-04
Loss = 1.1520e-03, PNorm = 39.3562, GNorm = 0.6408, lr_0 = 8.0940e-04
Loss = 9.5771e-04, PNorm = 39.3698, GNorm = 0.7699, lr_0 = 8.0831e-04
Validation rmse = 0.483312
Validation R2 = 0.933234
Epoch 11
Train function
Loss = 6.9167e-04, PNorm = 39.3885, GNorm = 0.3230, lr_0 = 8.0723e-04
Loss = 8.1148e-04, PNorm = 39.4149, GNorm = 0.4633, lr_0 = 8.0615e-04
Loss = 9.0443e-04, PNorm = 39.4336, GNorm = 0.9334, lr_0 = 8.0506e-04
Loss = 7.8484e-04, PNorm = 39.4581, GNorm = 0.5853, lr_0 = 8.0398e-04
Loss = 6.7931e-04, PNorm = 39.4754, GNorm = 0.2298, lr_0 = 8.0291e-04
Loss = 7.8747e-04, PNorm = 39.4917, GNorm = 0.3269, lr_0 = 8.0183e-04
Loss = 6.2098e-04, PNorm = 39.5096, GNorm = 0.3319, lr_0 = 8.0075e-04
Loss = 6.9650e-04, PNorm = 39.5256, GNorm = 0.5085, lr_0 = 7.9968e-04
Loss = 8.3281e-04, PNorm = 39.5398, GNorm = 0.6679, lr_0 = 7.9861e-04
Loss = 9.0105e-04, PNorm = 39.5538, GNorm = 0.4611, lr_0 = 7.9753e-04
Loss = 1.2327e-03, PNorm = 39.5855, GNorm = 1.8038, lr_0 = 7.9646e-04
Loss = 1.0493e-03, PNorm = 39.6136, GNorm = 0.4893, lr_0 = 7.9540e-04
Loss = 9.2126e-04, PNorm = 39.6373, GNorm = 1.3882, lr_0 = 7.9433e-04
Loss = 9.7404e-04, PNorm = 39.6629, GNorm = 0.8559, lr_0 = 7.9326e-04
Loss = 9.3430e-04, PNorm = 39.6886, GNorm = 1.2376, lr_0 = 7.9220e-04
Loss = 1.2488e-03, PNorm = 39.7068, GNorm = 1.2979, lr_0 = 7.9114e-04
Loss = 8.5807e-04, PNorm = 39.7289, GNorm = 0.6027, lr_0 = 7.9007e-04
Validation rmse = 0.516208
Validation R2 = 0.923836
Epoch 12
Train function
Loss = 7.4844e-04, PNorm = 39.7548, GNorm = 0.4048, lr_0 = 7.8891e-04
Loss = 7.0391e-04, PNorm = 39.7835, GNorm = 0.7834, lr_0 = 7.8785e-04
Loss = 6.7544e-04, PNorm = 39.8033, GNorm = 0.7418, lr_0 = 7.8679e-04
Loss = 6.3868e-04, PNorm = 39.8270, GNorm = 0.3946, lr_0 = 7.8574e-04
Loss = 6.9668e-04, PNorm = 39.8399, GNorm = 0.6866, lr_0 = 7.8468e-04
Loss = 6.2813e-04, PNorm = 39.8586, GNorm = 0.2981, lr_0 = 7.8363e-04
Loss = 5.9423e-04, PNorm = 39.8744, GNorm = 0.3506, lr_0 = 7.8258e-04
Loss = 6.4750e-04, PNorm = 39.8884, GNorm = 0.5107, lr_0 = 7.8153e-04
Loss = 7.3891e-04, PNorm = 39.9078, GNorm = 0.4486, lr_0 = 7.8048e-04
Loss = 8.1929e-04, PNorm = 39.9269, GNorm = 1.3382, lr_0 = 7.7943e-04
Loss = 8.8088e-04, PNorm = 39.9534, GNorm = 1.3361, lr_0 = 7.7839e-04
Loss = 9.3136e-04, PNorm = 39.9745, GNorm = 1.3512, lr_0 = 7.7734e-04
Loss = 9.9467e-04, PNorm = 39.9897, GNorm = 1.0634, lr_0 = 7.7630e-04
Loss = 8.9023e-04, PNorm = 40.0134, GNorm = 0.9229, lr_0 = 7.7526e-04
Loss = 6.8286e-04, PNorm = 40.0385, GNorm = 0.3144, lr_0 = 7.7422e-04
Loss = 7.4633e-04, PNorm = 40.0611, GNorm = 0.4957, lr_0 = 7.7318e-04
Loss = 8.4869e-04, PNorm = 40.0809, GNorm = 0.5720, lr_0 = 7.7214e-04
Loss = 8.2236e-04, PNorm = 40.0929, GNorm = 0.5132, lr_0 = 7.7111e-04
Validation rmse = 0.489691
Validation R2 = 0.931460
Epoch 13
Train function
Loss = 6.5887e-04, PNorm = 40.1087, GNorm = 0.3417, lr_0 = 7.7007e-04
Loss = 6.1199e-04, PNorm = 40.1216, GNorm = 0.8129, lr_0 = 7.6904e-04
Loss = 7.7117e-04, PNorm = 40.1400, GNorm = 1.3484, lr_0 = 7.6801e-04
Loss = 6.3082e-04, PNorm = 40.1621, GNorm = 0.5174, lr_0 = 7.6698e-04
Loss = 7.2692e-04, PNorm = 40.1789, GNorm = 0.2920, lr_0 = 7.6595e-04
Loss = 8.8307e-04, PNorm = 40.2019, GNorm = 0.6988, lr_0 = 7.6492e-04
Loss = 6.4338e-04, PNorm = 40.2206, GNorm = 0.3034, lr_0 = 7.6389e-04
Loss = 7.3898e-04, PNorm = 40.2404, GNorm = 0.5118, lr_0 = 7.6287e-04
Loss = 6.3221e-04, PNorm = 40.2547, GNorm = 0.7424, lr_0 = 7.6184e-04
Loss = 1.0017e-03, PNorm = 40.2711, GNorm = 0.7259, lr_0 = 7.6082e-04
Loss = 6.7812e-04, PNorm = 40.2953, GNorm = 0.5555, lr_0 = 7.5980e-04
Loss = 7.4354e-04, PNorm = 40.3199, GNorm = 0.4310, lr_0 = 7.5878e-04
Loss = 6.4590e-04, PNorm = 40.3434, GNorm = 0.4318, lr_0 = 7.5776e-04
Loss = 7.0278e-04, PNorm = 40.3620, GNorm = 0.7904, lr_0 = 7.5675e-04
Loss = 6.1806e-04, PNorm = 40.3754, GNorm = 0.4917, lr_0 = 7.5573e-04
Loss = 6.3937e-04, PNorm = 40.3889, GNorm = 0.5556, lr_0 = 7.5472e-04
Loss = 5.5232e-04, PNorm = 40.4044, GNorm = 0.2383, lr_0 = 7.5370e-04
Validation rmse = 0.469147
Validation R2 = 0.937090
Epoch 14
Train function
Loss = 4.4078e-04, PNorm = 40.4239, GNorm = 0.5083, lr_0 = 7.5269e-04
Loss = 6.3457e-04, PNorm = 40.4412, GNorm = 0.7011, lr_0 = 7.5168e-04
Loss = 5.7723e-04, PNorm = 40.4594, GNorm = 0.8545, lr_0 = 7.5067e-04
Loss = 5.5209e-04, PNorm = 40.4755, GNorm = 0.2879, lr_0 = 7.4967e-04
Loss = 6.4157e-04, PNorm = 40.4878, GNorm = 1.3589, lr_0 = 7.4866e-04
Loss = 5.7834e-04, PNorm = 40.5091, GNorm = 0.3364, lr_0 = 7.4766e-04
Loss = 7.4761e-04, PNorm = 40.5269, GNorm = 0.5648, lr_0 = 7.4665e-04
Loss = 6.3084e-04, PNorm = 40.5419, GNorm = 0.7621, lr_0 = 7.4565e-04
Loss = 6.3936e-04, PNorm = 40.5581, GNorm = 0.6837, lr_0 = 7.4465e-04
Loss = 6.0347e-04, PNorm = 40.5770, GNorm = 0.5323, lr_0 = 7.4365e-04
Loss = 5.3597e-04, PNorm = 40.5884, GNorm = 0.4136, lr_0 = 7.4266e-04
Loss = 5.2418e-04, PNorm = 40.6059, GNorm = 0.3606, lr_0 = 7.4166e-04
Loss = 8.5752e-04, PNorm = 40.6252, GNorm = 0.8666, lr_0 = 7.4066e-04
Loss = 5.5928e-04, PNorm = 40.6467, GNorm = 1.3598, lr_0 = 7.3967e-04
Loss = 6.7991e-04, PNorm = 40.6674, GNorm = 0.3544, lr_0 = 7.3868e-04
Loss = 6.3024e-04, PNorm = 40.6834, GNorm = 1.0490, lr_0 = 7.3769e-04
Loss = 5.9701e-04, PNorm = 40.6904, GNorm = 0.6468, lr_0 = 7.3670e-04
Loss = 8.0712e-04, PNorm = 40.7052, GNorm = 0.3491, lr_0 = 7.3571e-04
Validation rmse = 0.500217
Validation R2 = 0.928481
Epoch 15
Train function
Loss = 5.3183e-04, PNorm = 40.7304, GNorm = 0.3168, lr_0 = 7.3462e-04
Loss = 5.6807e-04, PNorm = 40.7602, GNorm = 0.4282, lr_0 = 7.3364e-04
Loss = 5.3119e-04, PNorm = 40.7753, GNorm = 0.3774, lr_0 = 7.3265e-04
Loss = 5.1658e-04, PNorm = 40.7886, GNorm = 0.7544, lr_0 = 7.3167e-04
Loss = 5.7986e-04, PNorm = 40.8110, GNorm = 0.5249, lr_0 = 7.3069e-04
Loss = 6.6789e-04, PNorm = 40.8337, GNorm = 0.3112, lr_0 = 7.2971e-04
Loss = 6.3966e-04, PNorm = 40.8556, GNorm = 0.5522, lr_0 = 7.2873e-04
Loss = 4.4949e-04, PNorm = 40.8757, GNorm = 0.7041, lr_0 = 7.2775e-04
Loss = 5.5991e-04, PNorm = 40.8897, GNorm = 0.8972, lr_0 = 7.2677e-04
Loss = 5.7706e-04, PNorm = 40.8978, GNorm = 0.4208, lr_0 = 7.2580e-04
Loss = 1.0034e-03, PNorm = 40.9110, GNorm = 0.8231, lr_0 = 7.2483e-04
Loss = 6.6987e-04, PNorm = 40.9319, GNorm = 0.8574, lr_0 = 7.2385e-04
Loss = 7.1767e-04, PNorm = 40.9497, GNorm = 0.4228, lr_0 = 7.2288e-04
Loss = 6.2126e-04, PNorm = 40.9720, GNorm = 0.3687, lr_0 = 7.2191e-04
Loss = 5.3757e-04, PNorm = 40.9963, GNorm = 0.3475, lr_0 = 7.2094e-04
Loss = 5.5202e-04, PNorm = 41.0138, GNorm = 0.3387, lr_0 = 7.1998e-04
Loss = 5.9828e-04, PNorm = 41.0310, GNorm = 1.5665, lr_0 = 7.1901e-04
Loss = 6.8054e-04, PNorm = 41.0470, GNorm = 0.3026, lr_0 = 7.1804e-04
Validation rmse = 0.483423
Validation R2 = 0.933203
Epoch 16
Train function
Loss = 5.7985e-04, PNorm = 41.0644, GNorm = 1.2438, lr_0 = 7.1708e-04
Loss = 5.0713e-04, PNorm = 41.0821, GNorm = 0.4617, lr_0 = 7.1612e-04
Loss = 5.4441e-04, PNorm = 41.1019, GNorm = 0.8871, lr_0 = 7.1516e-04
Loss = 5.2666e-04, PNorm = 41.1174, GNorm = 1.3205, lr_0 = 7.1420e-04
Loss = 5.1208e-04, PNorm = 41.1253, GNorm = 0.8750, lr_0 = 7.1324e-04
Loss = 4.7709e-04, PNorm = 41.1424, GNorm = 0.3575, lr_0 = 7.1228e-04
Loss = 5.2174e-04, PNorm = 41.1585, GNorm = 0.5785, lr_0 = 7.1133e-04
Loss = 4.1518e-04, PNorm = 41.1688, GNorm = 0.4796, lr_0 = 7.1037e-04
Loss = 5.0070e-04, PNorm = 41.1796, GNorm = 0.5169, lr_0 = 7.0942e-04
Loss = 6.0497e-04, PNorm = 41.1981, GNorm = 1.1435, lr_0 = 7.0847e-04
Loss = 5.9395e-04, PNorm = 41.2191, GNorm = 0.6167, lr_0 = 7.0752e-04
Loss = 5.2448e-04, PNorm = 41.2335, GNorm = 0.3021, lr_0 = 7.0657e-04
Loss = 5.4313e-04, PNorm = 41.2532, GNorm = 0.9781, lr_0 = 7.0562e-04
Loss = 5.9010e-04, PNorm = 41.2736, GNorm = 0.4046, lr_0 = 7.0467e-04
Loss = 6.8297e-04, PNorm = 41.2893, GNorm = 0.5486, lr_0 = 7.0373e-04
Loss = 7.3096e-04, PNorm = 41.3061, GNorm = 0.8311, lr_0 = 7.0278e-04
Loss = 4.8433e-04, PNorm = 41.3209, GNorm = 0.4311, lr_0 = 7.0184e-04
Validation rmse = 0.470801
Validation R2 = 0.936646
Epoch 17
Train function
Loss = 5.3765e-04, PNorm = 41.3361, GNorm = 0.5838, lr_0 = 7.0090e-04
Loss = 5.3516e-04, PNorm = 41.3519, GNorm = 0.6351, lr_0 = 6.9996e-04
Loss = 4.9734e-04, PNorm = 41.3670, GNorm = 0.5881, lr_0 = 6.9902e-04
Loss = 5.3049e-04, PNorm = 41.3813, GNorm = 0.5188, lr_0 = 6.9808e-04
Loss = 4.3078e-04, PNorm = 41.3882, GNorm = 0.4284, lr_0 = 6.9715e-04
Loss = 5.2482e-04, PNorm = 41.4029, GNorm = 0.6055, lr_0 = 6.9621e-04
Loss = 4.8232e-04, PNorm = 41.4154, GNorm = 0.4064, lr_0 = 6.9528e-04
Loss = 4.4601e-04, PNorm = 41.4255, GNorm = 0.4927, lr_0 = 6.9434e-04
Loss = 5.2605e-04, PNorm = 41.4414, GNorm = 0.3927, lr_0 = 6.9341e-04
Loss = 4.8827e-04, PNorm = 41.4594, GNorm = 0.3989, lr_0 = 6.9248e-04
Loss = 4.1214e-04, PNorm = 41.4695, GNorm = 0.5298, lr_0 = 6.9155e-04
Loss = 6.1408e-04, PNorm = 41.4939, GNorm = 1.1655, lr_0 = 6.9062e-04
Loss = 5.1717e-04, PNorm = 41.5113, GNorm = 0.4274, lr_0 = 6.8970e-04
Loss = 4.9720e-04, PNorm = 41.5330, GNorm = 0.5876, lr_0 = 6.8877e-04
Loss = 4.4754e-04, PNorm = 41.5453, GNorm = 0.6253, lr_0 = 6.8785e-04
Loss = 4.0657e-04, PNorm = 41.5558, GNorm = 0.3439, lr_0 = 6.8693e-04
Loss = 5.1452e-04, PNorm = 41.5659, GNorm = 0.3092, lr_0 = 6.8600e-04
Loss = 5.8816e-04, PNorm = 41.5864, GNorm = 1.0204, lr_0 = 6.8508e-04
Validation rmse = 0.488354
Validation R2 = 0.931834
Epoch 18
Train function
Loss = 5.7731e-04, PNorm = 41.5979, GNorm = 1.0548, lr_0 = 6.8407e-04
Loss = 4.1230e-04, PNorm = 41.6152, GNorm = 0.3114, lr_0 = 6.8315e-04
Loss = 4.4428e-04, PNorm = 41.6291, GNorm = 0.3812, lr_0 = 6.8224e-04
Loss = 4.9737e-04, PNorm = 41.6432, GNorm = 1.3247, lr_0 = 6.8132e-04
Loss = 6.5105e-04, PNorm = 41.6692, GNorm = 1.0651, lr_0 = 6.8041e-04
Loss = 4.9461e-04, PNorm = 41.6865, GNorm = 0.3985, lr_0 = 6.7950e-04
Loss = 4.5720e-04, PNorm = 41.7074, GNorm = 0.2778, lr_0 = 6.7858e-04
Loss = 4.1866e-04, PNorm = 41.7292, GNorm = 0.4508, lr_0 = 6.7767e-04
Loss = 4.5052e-04, PNorm = 41.7386, GNorm = 0.2553, lr_0 = 6.7676e-04
Loss = 4.1736e-04, PNorm = 41.7540, GNorm = 0.2785, lr_0 = 6.7586e-04
Loss = 4.4013e-04, PNorm = 41.7688, GNorm = 0.6613, lr_0 = 6.7495e-04
Loss = 4.3485e-04, PNorm = 41.7777, GNorm = 0.3822, lr_0 = 6.7404e-04
Loss = 5.1055e-04, PNorm = 41.7915, GNorm = 0.3529, lr_0 = 6.7314e-04
Loss = 5.4895e-04, PNorm = 41.8039, GNorm = 0.8598, lr_0 = 6.7224e-04
Loss = 4.3442e-04, PNorm = 41.8191, GNorm = 0.5019, lr_0 = 6.7133e-04
Loss = 5.8440e-04, PNorm = 41.8367, GNorm = 0.9274, lr_0 = 6.7043e-04
Loss = 5.9473e-04, PNorm = 41.8457, GNorm = 0.3173, lr_0 = 6.6953e-04
Validation rmse = 0.469977
Validation R2 = 0.936867
Epoch 19
Train function
Loss = 2.9565e-04, PNorm = 41.8643, GNorm = 0.3779, lr_0 = 6.6864e-04
Loss = 3.4676e-04, PNorm = 41.8701, GNorm = 0.2658, lr_0 = 6.6774e-04
Loss = 3.9955e-04, PNorm = 41.8799, GNorm = 0.4010, lr_0 = 6.6684e-04
Loss = 5.4721e-04, PNorm = 41.8974, GNorm = 0.5071, lr_0 = 6.6595e-04
Loss = 4.4794e-04, PNorm = 41.9172, GNorm = 0.2656, lr_0 = 6.6505e-04
Loss = 4.2142e-04, PNorm = 41.9371, GNorm = 0.4499, lr_0 = 6.6416e-04
Loss = 4.9707e-04, PNorm = 41.9518, GNorm = 0.5191, lr_0 = 6.6327e-04
Loss = 3.9502e-04, PNorm = 41.9686, GNorm = 0.4061, lr_0 = 6.6238e-04
Loss = 3.7892e-04, PNorm = 41.9821, GNorm = 0.4303, lr_0 = 6.6149e-04
Loss = 3.9743e-04, PNorm = 41.9908, GNorm = 0.3004, lr_0 = 6.6060e-04
Loss = 3.8344e-04, PNorm = 42.0061, GNorm = 0.3642, lr_0 = 6.5972e-04
Loss = 4.9887e-04, PNorm = 42.0147, GNorm = 1.1480, lr_0 = 6.5883e-04
Loss = 4.7425e-04, PNorm = 42.0231, GNorm = 0.3575, lr_0 = 6.5795e-04
Loss = 4.6210e-04, PNorm = 42.0367, GNorm = 0.4945, lr_0 = 6.5707e-04
Loss = 4.8132e-04, PNorm = 42.0472, GNorm = 0.9560, lr_0 = 6.5618e-04
Loss = 5.8557e-04, PNorm = 42.0651, GNorm = 0.7844, lr_0 = 6.5530e-04
Loss = 5.3490e-04, PNorm = 42.0885, GNorm = 0.3725, lr_0 = 6.5443e-04
Loss = 4.4161e-04, PNorm = 42.1114, GNorm = 0.4126, lr_0 = 6.5355e-04
Validation rmse = 0.464319
Validation R2 = 0.938378
Epoch 20
Train function
Loss = 2.8757e-04, PNorm = 42.1258, GNorm = 0.2415, lr_0 = 6.5267e-04
Loss = 3.6869e-04, PNorm = 42.1368, GNorm = 0.5552, lr_0 = 6.5179e-04
Loss = 3.9086e-04, PNorm = 42.1508, GNorm = 0.2519, lr_0 = 6.5092e-04
Loss = 3.8953e-04, PNorm = 42.1628, GNorm = 0.3156, lr_0 = 6.5005e-04
Loss = 3.9582e-04, PNorm = 42.1758, GNorm = 0.4657, lr_0 = 6.4917e-04
Loss = 3.8644e-04, PNorm = 42.1868, GNorm = 0.6781, lr_0 = 6.4830e-04
Loss = 3.5701e-04, PNorm = 42.1991, GNorm = 0.9372, lr_0 = 6.4743e-04
Loss = 4.4798e-04, PNorm = 42.2066, GNorm = 0.5725, lr_0 = 6.4657e-04
Loss = 4.4677e-04, PNorm = 42.2233, GNorm = 0.5457, lr_0 = 6.4570e-04
Loss = 4.0171e-04, PNorm = 42.2356, GNorm = 0.3658, lr_0 = 6.4483e-04
Loss = 3.7933e-04, PNorm = 42.2507, GNorm = 0.4015, lr_0 = 6.4397e-04
Loss = 3.1448e-04, PNorm = 42.2647, GNorm = 0.2832, lr_0 = 6.4310e-04
Loss = 3.1221e-04, PNorm = 42.2761, GNorm = 0.3157, lr_0 = 6.4224e-04
Loss = 3.5563e-04, PNorm = 42.2810, GNorm = 0.2490, lr_0 = 6.4138e-04
Loss = 4.4451e-04, PNorm = 42.2945, GNorm = 0.2975, lr_0 = 6.4052e-04
Loss = 3.7426e-04, PNorm = 42.3092, GNorm = 0.4012, lr_0 = 6.3966e-04
Loss = 4.5977e-04, PNorm = 42.3184, GNorm = 0.6343, lr_0 = 6.3880e-04
Validation rmse = 0.460072
Validation R2 = 0.939500
Epoch 21
Train function
Loss = 2.4081e-04, PNorm = 42.3247, GNorm = 0.2820, lr_0 = 6.3786e-04
Loss = 3.4357e-04, PNorm = 42.3381, GNorm = 0.3751, lr_0 = 6.3700e-04
Loss = 3.5227e-04, PNorm = 42.3508, GNorm = 0.3157, lr_0 = 6.3615e-04
Loss = 3.7830e-04, PNorm = 42.3631, GNorm = 0.4490, lr_0 = 6.3529e-04
Loss = 3.9434e-04, PNorm = 42.3787, GNorm = 0.6801, lr_0 = 6.3444e-04
Loss = 3.9317e-04, PNorm = 42.3936, GNorm = 0.5326, lr_0 = 6.3359e-04
Loss = 4.3622e-04, PNorm = 42.4105, GNorm = 0.6235, lr_0 = 6.3274e-04
Loss = 4.7604e-04, PNorm = 42.4238, GNorm = 0.7358, lr_0 = 6.3189e-04
Loss = 3.8449e-04, PNorm = 42.4392, GNorm = 0.4419, lr_0 = 6.3104e-04
Loss = 3.7600e-04, PNorm = 42.4519, GNorm = 0.7460, lr_0 = 6.3020e-04
Loss = 4.0028e-04, PNorm = 42.4679, GNorm = 0.8522, lr_0 = 6.2935e-04
Loss = 3.2286e-04, PNorm = 42.4765, GNorm = 0.3289, lr_0 = 6.2851e-04
Loss = 4.0083e-04, PNorm = 42.4842, GNorm = 0.3870, lr_0 = 6.2766e-04
Loss = 3.9772e-04, PNorm = 42.5018, GNorm = 0.5462, lr_0 = 6.2682e-04
Loss = 3.3605e-04, PNorm = 42.5148, GNorm = 0.4338, lr_0 = 6.2598e-04
Loss = 3.3841e-04, PNorm = 42.5282, GNorm = 0.3227, lr_0 = 6.2514e-04
Loss = 4.1297e-04, PNorm = 42.5457, GNorm = 0.4025, lr_0 = 6.2430e-04
Loss = 3.5899e-04, PNorm = 42.5614, GNorm = 0.4352, lr_0 = 6.2346e-04
Validation rmse = 0.464346
Validation R2 = 0.938371
Epoch 22
Train function
Loss = 3.0095e-04, PNorm = 42.5702, GNorm = 0.2366, lr_0 = 6.2263e-04
Loss = 3.1515e-04, PNorm = 42.5846, GNorm = 0.3429, lr_0 = 6.2179e-04
Loss = 3.8039e-04, PNorm = 42.5877, GNorm = 0.3432, lr_0 = 6.2096e-04
Loss = 3.7578e-04, PNorm = 42.5962, GNorm = 0.3448, lr_0 = 6.2012e-04
Loss = 4.1643e-04, PNorm = 42.6137, GNorm = 0.3513, lr_0 = 6.1929e-04
Loss = 3.6109e-04, PNorm = 42.6228, GNorm = 0.6097, lr_0 = 6.1846e-04
Loss = 4.0624e-04, PNorm = 42.6377, GNorm = 0.2288, lr_0 = 6.1763e-04
Loss = 3.2280e-04, PNorm = 42.6548, GNorm = 0.2523, lr_0 = 6.1680e-04
Loss = 3.2396e-04, PNorm = 42.6671, GNorm = 0.4118, lr_0 = 6.1597e-04
Loss = 3.0792e-04, PNorm = 42.6822, GNorm = 0.3054, lr_0 = 6.1515e-04
Loss = 3.8415e-04, PNorm = 42.6996, GNorm = 0.4437, lr_0 = 6.1432e-04
Loss = 3.9633e-04, PNorm = 42.7088, GNorm = 0.8283, lr_0 = 6.1350e-04
Loss = 4.1684e-04, PNorm = 42.7256, GNorm = 0.3307, lr_0 = 6.1268e-04
Loss = 3.4212e-04, PNorm = 42.7377, GNorm = 0.1713, lr_0 = 6.1185e-04
Loss = 3.0622e-04, PNorm = 42.7458, GNorm = 0.2246, lr_0 = 6.1103e-04
Loss = 3.0077e-04, PNorm = 42.7551, GNorm = 0.5587, lr_0 = 6.1021e-04
Loss = 2.9261e-04, PNorm = 42.7661, GNorm = 0.3440, lr_0 = 6.0939e-04
Loss = 3.6169e-04, PNorm = 42.7793, GNorm = 0.5615, lr_0 = 6.0858e-04
Validation rmse = 0.458114
Validation R2 = 0.940014
Epoch 23
Train function
Loss = 3.1073e-04, PNorm = 42.7899, GNorm = 0.5224, lr_0 = 6.0776e-04
Loss = 3.6158e-04, PNorm = 42.8057, GNorm = 0.4217, lr_0 = 6.0694e-04
Loss = 3.6536e-04, PNorm = 42.8156, GNorm = 0.5115, lr_0 = 6.0613e-04
Loss = 3.6522e-04, PNorm = 42.8280, GNorm = 0.4826, lr_0 = 6.0532e-04
Loss = 2.9617e-04, PNorm = 42.8420, GNorm = 0.2300, lr_0 = 6.0450e-04
Loss = 3.3787e-04, PNorm = 42.8583, GNorm = 1.0925, lr_0 = 6.0369e-04
Loss = 3.4483e-04, PNorm = 42.8682, GNorm = 0.3843, lr_0 = 6.0288e-04
Loss = 2.8210e-04, PNorm = 42.8835, GNorm = 0.3591, lr_0 = 6.0207e-04
Loss = 3.0922e-04, PNorm = 42.8961, GNorm = 0.3862, lr_0 = 6.0127e-04
Loss = 3.2676e-04, PNorm = 42.9054, GNorm = 0.2685, lr_0 = 6.0046e-04
Loss = 3.3398e-04, PNorm = 42.9136, GNorm = 0.4820, lr_0 = 5.9965e-04
Loss = 3.1442e-04, PNorm = 42.9241, GNorm = 0.2371, lr_0 = 5.9885e-04
Loss = 2.2199e-04, PNorm = 42.9359, GNorm = 0.2258, lr_0 = 5.9805e-04
Loss = 3.4400e-04, PNorm = 42.9436, GNorm = 0.3857, lr_0 = 5.9724e-04
Loss = 4.2245e-04, PNorm = 42.9528, GNorm = 0.8035, lr_0 = 5.9644e-04
Loss = 4.5507e-04, PNorm = 42.9611, GNorm = 0.6808, lr_0 = 5.9564e-04
Loss = 3.3842e-04, PNorm = 42.9754, GNorm = 0.8582, lr_0 = 5.9484e-04
Validation rmse = 0.467914
Validation R2 = 0.937420
Epoch 24
Train function
Loss = 2.3415e-04, PNorm = 42.9879, GNorm = 0.6194, lr_0 = 5.9397e-04
Loss = 2.8542e-04, PNorm = 42.9998, GNorm = 0.5132, lr_0 = 5.9317e-04
Loss = 2.2903e-04, PNorm = 43.0127, GNorm = 0.2552, lr_0 = 5.9237e-04
Loss = 2.9107e-04, PNorm = 43.0205, GNorm = 0.2419, lr_0 = 5.9158e-04
Loss = 2.6792e-04, PNorm = 43.0302, GNorm = 0.3243, lr_0 = 5.9078e-04
Loss = 2.7580e-04, PNorm = 43.0452, GNorm = 0.8112, lr_0 = 5.8999e-04
Loss = 3.0292e-04, PNorm = 43.0562, GNorm = 1.0411, lr_0 = 5.8920e-04
Loss = 3.9887e-04, PNorm = 43.0682, GNorm = 0.4418, lr_0 = 5.8841e-04
Loss = 4.5055e-04, PNorm = 43.0789, GNorm = 0.7491, lr_0 = 5.8762e-04
Loss = 3.3691e-04, PNorm = 43.0975, GNorm = 0.5169, lr_0 = 5.8683e-04
Loss = 3.2132e-04, PNorm = 43.1100, GNorm = 0.7933, lr_0 = 5.8604e-04
Loss = 3.4190e-04, PNorm = 43.1251, GNorm = 0.3709, lr_0 = 5.8526e-04
Loss = 3.1307e-04, PNorm = 43.1360, GNorm = 0.4272, lr_0 = 5.8447e-04
Loss = 3.1673e-04, PNorm = 43.1488, GNorm = 0.4381, lr_0 = 5.8369e-04
Loss = 3.1424e-04, PNorm = 43.1600, GNorm = 0.4010, lr_0 = 5.8290e-04
Loss = 4.1152e-04, PNorm = 43.1749, GNorm = 0.3651, lr_0 = 5.8212e-04
Loss = 3.8042e-04, PNorm = 43.1916, GNorm = 0.3542, lr_0 = 5.8134e-04
Loss = 2.8123e-04, PNorm = 43.2011, GNorm = 0.7666, lr_0 = 5.8056e-04
Validation rmse = 0.455044
Validation R2 = 0.940815
Epoch 25
Train function
Loss = 3.2642e-04, PNorm = 43.2182, GNorm = 0.3764, lr_0 = 5.7978e-04
Loss = 2.3529e-04, PNorm = 43.2269, GNorm = 0.3540, lr_0 = 5.7900e-04
Loss = 3.1623e-04, PNorm = 43.2437, GNorm = 0.6627, lr_0 = 5.7823e-04
Loss = 3.1941e-04, PNorm = 43.2522, GNorm = 1.0825, lr_0 = 5.7745e-04
Loss = 2.4879e-04, PNorm = 43.2635, GNorm = 0.3860, lr_0 = 5.7668e-04
Loss = 2.6519e-04, PNorm = 43.2722, GNorm = 0.2261, lr_0 = 5.7590e-04
Loss = 2.0684e-04, PNorm = 43.2774, GNorm = 0.1580, lr_0 = 5.7513e-04
Loss = 3.2115e-04, PNorm = 43.2863, GNorm = 0.2954, lr_0 = 5.7436e-04
Loss = 2.5932e-04, PNorm = 43.2943, GNorm = 0.6513, lr_0 = 5.7359e-04
Loss = 2.6425e-04, PNorm = 43.3018, GNorm = 0.6253, lr_0 = 5.7282e-04
Loss = 2.7237e-04, PNorm = 43.3098, GNorm = 0.3261, lr_0 = 5.7205e-04
Loss = 2.3726e-04, PNorm = 43.3204, GNorm = 0.5645, lr_0 = 5.7128e-04
Loss = 2.4210e-04, PNorm = 43.3285, GNorm = 0.2860, lr_0 = 5.7052e-04
Loss = 2.6162e-04, PNorm = 43.3377, GNorm = 0.2467, lr_0 = 5.6975e-04
Loss = 2.9732e-04, PNorm = 43.3442, GNorm = 0.4245, lr_0 = 5.6899e-04
Loss = 3.0066e-04, PNorm = 43.3536, GNorm = 0.6068, lr_0 = 5.6822e-04
Loss = 3.4977e-04, PNorm = 43.3667, GNorm = 0.3353, lr_0 = 5.6746e-04
Validation rmse = 0.462958
Validation R2 = 0.938739
Epoch 26
Train function
Loss = 2.7472e-04, PNorm = 43.3789, GNorm = 0.2296, lr_0 = 5.6670e-04
Loss = 2.2348e-04, PNorm = 43.3881, GNorm = 0.8034, lr_0 = 5.6594e-04
Loss = 2.3603e-04, PNorm = 43.3994, GNorm = 0.3797, lr_0 = 5.6518e-04
Loss = 2.3446e-04, PNorm = 43.4085, GNorm = 0.2117, lr_0 = 5.6442e-04
Loss = 2.0531e-04, PNorm = 43.4159, GNorm = 0.6635, lr_0 = 5.6366e-04
Loss = 2.2270e-04, PNorm = 43.4223, GNorm = 0.5235, lr_0 = 5.6291e-04
Loss = 2.7738e-04, PNorm = 43.4355, GNorm = 0.2805, lr_0 = 5.6215e-04
Loss = 2.4316e-04, PNorm = 43.4446, GNorm = 0.3270, lr_0 = 5.6140e-04
Loss = 2.3346e-04, PNorm = 43.4600, GNorm = 0.1835, lr_0 = 5.6065e-04
Loss = 2.6743e-04, PNorm = 43.4719, GNorm = 0.5154, lr_0 = 5.5989e-04
Loss = 2.6059e-04, PNorm = 43.4836, GNorm = 0.2093, lr_0 = 5.5914e-04
Loss = 2.7896e-04, PNorm = 43.4934, GNorm = 0.5486, lr_0 = 5.5839e-04
Loss = 2.9112e-04, PNorm = 43.5027, GNorm = 0.3948, lr_0 = 5.5764e-04
Loss = 3.2232e-04, PNorm = 43.5163, GNorm = 0.6059, lr_0 = 5.5689e-04
Loss = 2.7408e-04, PNorm = 43.5213, GNorm = 0.2140, lr_0 = 5.5615e-04
Loss = 2.5712e-04, PNorm = 43.5263, GNorm = 0.3879, lr_0 = 5.5540e-04
Loss = 3.1574e-04, PNorm = 43.5361, GNorm = 0.5104, lr_0 = 5.5466e-04
Loss = 3.4964e-04, PNorm = 43.5455, GNorm = 0.8193, lr_0 = 5.5391e-04
Validation rmse = 0.471538
Validation R2 = 0.936447
Epoch 27
Train function
Loss = 3.2115e-04, PNorm = 43.5615, GNorm = 0.2768, lr_0 = 5.5309e-04
Loss = 2.0388e-04, PNorm = 43.5752, GNorm = 0.2587, lr_0 = 5.5235e-04
Loss = 2.3227e-04, PNorm = 43.5860, GNorm = 0.4749, lr_0 = 5.5161e-04
Loss = 2.1312e-04, PNorm = 43.5943, GNorm = 0.3173, lr_0 = 5.5087e-04
Loss = 2.3917e-04, PNorm = 43.6051, GNorm = 0.5691, lr_0 = 5.5013e-04
Loss = 2.8582e-04, PNorm = 43.6204, GNorm = 0.8328, lr_0 = 5.4939e-04
Loss = 2.6722e-04, PNorm = 43.6341, GNorm = 0.4864, lr_0 = 5.4866e-04
Loss = 2.5811e-04, PNorm = 43.6511, GNorm = 0.4219, lr_0 = 5.4792e-04
Loss = 2.3727e-04, PNorm = 43.6625, GNorm = 0.4187, lr_0 = 5.4718e-04
Loss = 2.6636e-04, PNorm = 43.6709, GNorm = 0.3167, lr_0 = 5.4645e-04
Loss = 2.5101e-04, PNorm = 43.6825, GNorm = 0.7159, lr_0 = 5.4572e-04
Loss = 2.6028e-04, PNorm = 43.6897, GNorm = 0.3016, lr_0 = 5.4499e-04
Loss = 1.8461e-04, PNorm = 43.6954, GNorm = 0.2297, lr_0 = 5.4425e-04
Loss = 2.5413e-04, PNorm = 43.7053, GNorm = 0.5322, lr_0 = 5.4352e-04
Loss = 2.8818e-04, PNorm = 43.7201, GNorm = 0.4362, lr_0 = 5.4279e-04
Loss = 2.6190e-04, PNorm = 43.7265, GNorm = 0.4423, lr_0 = 5.4207e-04
Loss = 2.4649e-04, PNorm = 43.7336, GNorm = 0.2717, lr_0 = 5.4134e-04
Validation rmse = 0.457684
Validation R2 = 0.940127
Epoch 28
Train function
Loss = 2.6126e-04, PNorm = 43.7434, GNorm = 0.6891, lr_0 = 5.4061e-04
Loss = 2.5927e-04, PNorm = 43.7543, GNorm = 0.6849, lr_0 = 5.3989e-04
Loss = 2.5164e-04, PNorm = 43.7681, GNorm = 0.6091, lr_0 = 5.3916e-04
Loss = 2.4790e-04, PNorm = 43.7758, GNorm = 0.3018, lr_0 = 5.3844e-04
Loss = 2.2881e-04, PNorm = 43.7870, GNorm = 0.3761, lr_0 = 5.3772e-04
Loss = 2.9327e-04, PNorm = 43.8020, GNorm = 0.4675, lr_0 = 5.3700e-04
Loss = 2.6470e-04, PNorm = 43.8102, GNorm = 0.4956, lr_0 = 5.3628e-04
Loss = 2.5729e-04, PNorm = 43.8215, GNorm = 0.4550, lr_0 = 5.3556e-04
Loss = 2.6756e-04, PNorm = 43.8310, GNorm = 0.3517, lr_0 = 5.3484e-04
Loss = 2.2827e-04, PNorm = 43.8430, GNorm = 0.2690, lr_0 = 5.3412e-04
Loss = 2.4533e-04, PNorm = 43.8565, GNorm = 0.4909, lr_0 = 5.3340e-04
Loss = 2.1174e-04, PNorm = 43.8627, GNorm = 0.1510, lr_0 = 5.3269e-04
Loss = 2.3844e-04, PNorm = 43.8732, GNorm = 0.3671, lr_0 = 5.3197e-04
Loss = 2.2847e-04, PNorm = 43.8803, GNorm = 0.3510, lr_0 = 5.3126e-04
Loss = 2.0759e-04, PNorm = 43.8859, GNorm = 0.2337, lr_0 = 5.3055e-04
Loss = 3.1613e-04, PNorm = 43.9005, GNorm = 0.2430, lr_0 = 5.2983e-04
Loss = 2.8517e-04, PNorm = 43.9099, GNorm = 0.5312, lr_0 = 5.2912e-04
Loss = 2.4510e-04, PNorm = 43.9241, GNorm = 0.5452, lr_0 = 5.2841e-04
Validation rmse = 0.460694
Validation R2 = 0.939337
Epoch 29
Train function
Loss = 2.1595e-04, PNorm = 43.9366, GNorm = 0.5176, lr_0 = 5.2770e-04
Loss = 2.2450e-04, PNorm = 43.9435, GNorm = 0.3469, lr_0 = 5.2700e-04
Loss = 2.0231e-04, PNorm = 43.9473, GNorm = 0.2984, lr_0 = 5.2629e-04
Loss = 2.7345e-04, PNorm = 43.9535, GNorm = 0.2491, lr_0 = 5.2558e-04
Loss = 2.1874e-04, PNorm = 43.9635, GNorm = 0.5654, lr_0 = 5.2488e-04
Loss = 1.9294e-04, PNorm = 43.9712, GNorm = 0.5375, lr_0 = 5.2417e-04
Loss = 2.1764e-04, PNorm = 43.9853, GNorm = 0.3764, lr_0 = 5.2347e-04
Loss = 2.3805e-04, PNorm = 43.9972, GNorm = 0.6152, lr_0 = 5.2277e-04
Loss = 1.9694e-04, PNorm = 44.0093, GNorm = 0.4035, lr_0 = 5.2207e-04
Loss = 2.1517e-04, PNorm = 44.0209, GNorm = 0.1655, lr_0 = 5.2137e-04
Loss = 2.1764e-04, PNorm = 44.0307, GNorm = 0.2398, lr_0 = 5.2067e-04
Loss = 1.7473e-04, PNorm = 44.0403, GNorm = 0.1843, lr_0 = 5.1997e-04
Loss = 2.1419e-04, PNorm = 44.0480, GNorm = 0.2885, lr_0 = 5.1927e-04
Loss = 1.9758e-04, PNorm = 44.0553, GNorm = 0.4829, lr_0 = 5.1857e-04
Loss = 2.1553e-04, PNorm = 44.0612, GNorm = 0.4060, lr_0 = 5.1788e-04
Loss = 2.4878e-04, PNorm = 44.0692, GNorm = 0.2201, lr_0 = 5.1718e-04
Loss = 2.3901e-04, PNorm = 44.0815, GNorm = 0.1496, lr_0 = 5.1649e-04
Validation rmse = 0.453487
Validation R2 = 0.941220
Epoch 30
Train function
Loss = 7.1699e-05, PNorm = 44.0990, GNorm = 0.1318, lr_0 = 5.1573e-04
Loss = 1.9296e-04, PNorm = 44.1079, GNorm = 0.5157, lr_0 = 5.1503e-04
Loss = 2.2043e-04, PNorm = 44.1143, GNorm = 0.3655, lr_0 = 5.1434e-04
Loss = 2.1020e-04, PNorm = 44.1248, GNorm = 0.7734, lr_0 = 5.1365e-04
Loss = 1.9204e-04, PNorm = 44.1304, GNorm = 0.2813, lr_0 = 5.1296e-04
Loss = 1.7775e-04, PNorm = 44.1428, GNorm = 0.3290, lr_0 = 5.1228e-04
Loss = 2.1527e-04, PNorm = 44.1479, GNorm = 0.5661, lr_0 = 5.1159e-04
Loss = 2.4001e-04, PNorm = 44.1628, GNorm = 0.4512, lr_0 = 5.1090e-04
Loss = 2.0791e-04, PNorm = 44.1737, GNorm = 0.2673, lr_0 = 5.1022e-04
Loss = 2.1944e-04, PNorm = 44.1842, GNorm = 0.5748, lr_0 = 5.0953e-04
Loss = 2.2267e-04, PNorm = 44.1946, GNorm = 0.3125, lr_0 = 5.0885e-04
Loss = 2.1532e-04, PNorm = 44.2047, GNorm = 0.3991, lr_0 = 5.0817e-04
Loss = 1.9364e-04, PNorm = 44.2115, GNorm = 0.3377, lr_0 = 5.0748e-04
Loss = 2.0062e-04, PNorm = 44.2188, GNorm = 0.2389, lr_0 = 5.0680e-04
Loss = 1.7980e-04, PNorm = 44.2297, GNorm = 0.2141, lr_0 = 5.0612e-04
Loss = 2.1471e-04, PNorm = 44.2372, GNorm = 0.2586, lr_0 = 5.0544e-04
Loss = 2.3169e-04, PNorm = 44.2448, GNorm = 0.5015, lr_0 = 5.0477e-04
Loss = 2.0535e-04, PNorm = 44.2533, GNorm = 0.4218, lr_0 = 5.0409e-04
Validation rmse = 0.459392
Validation R2 = 0.939679
Epoch 31
Train function
Loss = 1.9420e-04, PNorm = 44.2585, GNorm = 0.2502, lr_0 = 5.0341e-04
Loss = 2.3310e-04, PNorm = 44.2660, GNorm = 0.3454, lr_0 = 5.0274e-04
Loss = 2.1312e-04, PNorm = 44.2728, GNorm = 0.4202, lr_0 = 5.0206e-04
Loss = 1.8782e-04, PNorm = 44.2799, GNorm = 0.3050, lr_0 = 5.0139e-04
Loss = 1.5898e-04, PNorm = 44.2872, GNorm = 0.1797, lr_0 = 5.0072e-04
Loss = 1.7018e-04, PNorm = 44.2952, GNorm = 0.4199, lr_0 = 5.0004e-04
Loss = 1.8991e-04, PNorm = 44.3021, GNorm = 0.2906, lr_0 = 4.9937e-04
Loss = 2.2057e-04, PNorm = 44.3109, GNorm = 0.5115, lr_0 = 4.9870e-04
Loss = 2.1843e-04, PNorm = 44.3187, GNorm = 0.3149, lr_0 = 4.9803e-04
Loss = 2.0840e-04, PNorm = 44.3261, GNorm = 0.6452, lr_0 = 4.9737e-04
Loss = 2.2676e-04, PNorm = 44.3359, GNorm = 0.3172, lr_0 = 4.9670e-04
Loss = 2.1412e-04, PNorm = 44.3462, GNorm = 0.2007, lr_0 = 4.9603e-04
Loss = 3.0505e-04, PNorm = 44.3610, GNorm = 0.5617, lr_0 = 4.9537e-04
Loss = 2.3347e-04, PNorm = 44.3752, GNorm = 0.4321, lr_0 = 4.9470e-04
Loss = 2.2767e-04, PNorm = 44.3864, GNorm = 0.2017, lr_0 = 4.9404e-04
Loss = 1.6793e-04, PNorm = 44.3974, GNorm = 0.1511, lr_0 = 4.9338e-04
Loss = 2.0855e-04, PNorm = 44.4028, GNorm = 0.3313, lr_0 = 4.9271e-04
Loss = 2.0265e-04, PNorm = 44.4115, GNorm = 0.3533, lr_0 = 4.9205e-04
Validation rmse = 0.463290
Validation R2 = 0.938651
Epoch 32
Train function
Loss = 1.7905e-04, PNorm = 44.4253, GNorm = 0.3245, lr_0 = 4.9139e-04
Loss = 1.5610e-04, PNorm = 44.4340, GNorm = 0.4415, lr_0 = 4.9073e-04
Loss = 1.7882e-04, PNorm = 44.4381, GNorm = 0.1953, lr_0 = 4.9007e-04
Loss = 1.6553e-04, PNorm = 44.4459, GNorm = 0.2162, lr_0 = 4.8942e-04
Loss = 1.1445e-04, PNorm = 44.4530, GNorm = 0.1319, lr_0 = 4.8876e-04
Loss = 1.8760e-04, PNorm = 44.4571, GNorm = 0.3082, lr_0 = 4.8810e-04
Loss = 1.8074e-04, PNorm = 44.4601, GNorm = 0.3141, lr_0 = 4.8745e-04
Loss = 1.9798e-04, PNorm = 44.4704, GNorm = 0.3483, lr_0 = 4.8680e-04
Loss = 1.9787e-04, PNorm = 44.4800, GNorm = 0.1950, lr_0 = 4.8614e-04
Loss = 1.6074e-04, PNorm = 44.4892, GNorm = 0.1599, lr_0 = 4.8549e-04
Loss = 1.5795e-04, PNorm = 44.4978, GNorm = 0.2243, lr_0 = 4.8484e-04
Loss = 3.0094e-04, PNorm = 44.5091, GNorm = 0.5951, lr_0 = 4.8419e-04
Loss = 2.1394e-04, PNorm = 44.5152, GNorm = 0.4584, lr_0 = 4.8354e-04
Loss = 2.6478e-04, PNorm = 44.5222, GNorm = 0.5613, lr_0 = 4.8289e-04
Loss = 2.8981e-04, PNorm = 44.5350, GNorm = 0.3516, lr_0 = 4.8224e-04
Loss = 2.2857e-04, PNorm = 44.5482, GNorm = 0.2214, lr_0 = 4.8160e-04
Loss = 2.4666e-04, PNorm = 44.5614, GNorm = 0.8413, lr_0 = 4.8095e-04
Validation rmse = 0.462813
Validation R2 = 0.938777
Epoch 33
Train function
Loss = 1.9463e-04, PNorm = 44.5668, GNorm = 0.5235, lr_0 = 4.8024e-04
Loss = 1.7804e-04, PNorm = 44.5721, GNorm = 0.4433, lr_0 = 4.7959e-04
Loss = 1.7923e-04, PNorm = 44.5807, GNorm = 0.3118, lr_0 = 4.7895e-04
Loss = 1.5620e-04, PNorm = 44.5877, GNorm = 0.3782, lr_0 = 4.7831e-04
Loss = 1.1938e-04, PNorm = 44.5939, GNorm = 0.2222, lr_0 = 4.7767e-04
Loss = 1.5752e-04, PNorm = 44.6017, GNorm = 0.2003, lr_0 = 4.7703e-04
Loss = 1.5341e-04, PNorm = 44.6095, GNorm = 0.3839, lr_0 = 4.7639e-04
Loss = 1.5455e-04, PNorm = 44.6159, GNorm = 0.2747, lr_0 = 4.7575e-04
Loss = 1.9657e-04, PNorm = 44.6208, GNorm = 0.8292, lr_0 = 4.7511e-04
Loss = 2.3325e-04, PNorm = 44.6278, GNorm = 0.8306, lr_0 = 4.7447e-04
Loss = 2.5043e-04, PNorm = 44.6385, GNorm = 0.3885, lr_0 = 4.7383e-04
Loss = 2.2466e-04, PNorm = 44.6546, GNorm = 0.3080, lr_0 = 4.7320e-04
Loss = 2.1055e-04, PNorm = 44.6639, GNorm = 0.6366, lr_0 = 4.7256e-04
Loss = 2.2242e-04, PNorm = 44.6723, GNorm = 0.3950, lr_0 = 4.7193e-04
Loss = 1.8847e-04, PNorm = 44.6764, GNorm = 0.4517, lr_0 = 4.7130e-04
Loss = 2.3007e-04, PNorm = 44.6882, GNorm = 0.1390, lr_0 = 4.7066e-04
Loss = 2.0180e-04, PNorm = 44.7007, GNorm = 0.3522, lr_0 = 4.7003e-04
Loss = 2.3360e-04, PNorm = 44.7117, GNorm = 0.5262, lr_0 = 4.6940e-04
Validation rmse = 0.464836
Validation R2 = 0.938241
Epoch 34
Train function
Loss = 2.2101e-04, PNorm = 44.7208, GNorm = 0.4513, lr_0 = 4.6877e-04
Loss = 2.0997e-04, PNorm = 44.7313, GNorm = 0.2044, lr_0 = 4.6814e-04
Loss = 1.5183e-04, PNorm = 44.7429, GNorm = 0.3813, lr_0 = 4.6752e-04
Loss = 1.7255e-04, PNorm = 44.7499, GNorm = 0.3516, lr_0 = 4.6689e-04
Loss = 2.5508e-04, PNorm = 44.7551, GNorm = 0.7532, lr_0 = 4.6626e-04
Loss = 1.6807e-04, PNorm = 44.7653, GNorm = 0.2067, lr_0 = 4.6564e-04
Loss = 2.3922e-04, PNorm = 44.7710, GNorm = 0.4356, lr_0 = 4.6501e-04
Loss = 2.0319e-04, PNorm = 44.7799, GNorm = 0.2856, lr_0 = 4.6439e-04
Loss = 1.3994e-04, PNorm = 44.7829, GNorm = 0.3713, lr_0 = 4.6376e-04
Loss = 1.3914e-04, PNorm = 44.7901, GNorm = 0.2022, lr_0 = 4.6314e-04
Loss = 1.4468e-04, PNorm = 44.7955, GNorm = 0.4507, lr_0 = 4.6252e-04
Loss = 1.4205e-04, PNorm = 44.8012, GNorm = 0.2253, lr_0 = 4.6190e-04
Loss = 1.4883e-04, PNorm = 44.8086, GNorm = 0.2703, lr_0 = 4.6128e-04
Loss = 2.0633e-04, PNorm = 44.8189, GNorm = 0.3012, lr_0 = 4.6066e-04
Loss = 1.6905e-04, PNorm = 44.8305, GNorm = 0.2652, lr_0 = 4.6004e-04
Loss = 1.7155e-04, PNorm = 44.8374, GNorm = 0.2451, lr_0 = 4.5943e-04
Loss = 1.9581e-04, PNorm = 44.8441, GNorm = 0.2094, lr_0 = 4.5881e-04
Validation rmse = 0.467509
Validation R2 = 0.937528
Epoch 35
Train function
Loss = 1.5701e-04, PNorm = 44.8516, GNorm = 0.4207, lr_0 = 4.5819e-04
Loss = 2.3745e-04, PNorm = 44.8625, GNorm = 0.3321, lr_0 = 4.5758e-04
Loss = 1.7451e-04, PNorm = 44.8752, GNorm = 0.1555, lr_0 = 4.5697e-04
Loss = 1.5496e-04, PNorm = 44.8843, GNorm = 0.1851, lr_0 = 4.5635e-04
Loss = 1.4697e-04, PNorm = 44.8929, GNorm = 0.1354, lr_0 = 4.5574e-04
Loss = 1.3817e-04, PNorm = 44.8990, GNorm = 0.3184, lr_0 = 4.5513e-04
Loss = 1.7038e-04, PNorm = 44.9055, GNorm = 0.4587, lr_0 = 4.5452e-04
Loss = 1.5601e-04, PNorm = 44.9120, GNorm = 0.1515, lr_0 = 4.5391e-04
Loss = 1.9758e-04, PNorm = 44.9185, GNorm = 0.3791, lr_0 = 4.5330e-04
Loss = 1.6917e-04, PNorm = 44.9239, GNorm = 0.3810, lr_0 = 4.5269e-04
Loss = 1.3754e-04, PNorm = 44.9292, GNorm = 0.1935, lr_0 = 4.5208e-04
Loss = 1.2582e-04, PNorm = 44.9360, GNorm = 0.2777, lr_0 = 4.5148e-04
Loss = 1.4010e-04, PNorm = 44.9434, GNorm = 0.3668, lr_0 = 4.5087e-04
Loss = 1.4642e-04, PNorm = 44.9522, GNorm = 0.2015, lr_0 = 4.5027e-04
Loss = 1.4998e-04, PNorm = 44.9590, GNorm = 0.5115, lr_0 = 4.4966e-04
Loss = 1.3804e-04, PNorm = 44.9660, GNorm = 0.1631, lr_0 = 4.4906e-04
Loss = 1.6090e-04, PNorm = 44.9731, GNorm = 0.2429, lr_0 = 4.4846e-04
Loss = 1.5989e-04, PNorm = 44.9829, GNorm = 0.5379, lr_0 = 4.4785e-04
Validation rmse = 0.467180
Validation R2 = 0.937616
Epoch 36
Train function
Loss = 1.8507e-04, PNorm = 44.9871, GNorm = 0.1275, lr_0 = 4.4719e-04
Loss = 1.7994e-04, PNorm = 44.9918, GNorm = 0.3048, lr_0 = 4.4659e-04
Loss = 1.7229e-04, PNorm = 45.0012, GNorm = 0.2054, lr_0 = 4.4599e-04
Loss = 1.5340e-04, PNorm = 45.0072, GNorm = 0.1558, lr_0 = 4.4540e-04
Loss = 1.5325e-04, PNorm = 45.0159, GNorm = 0.2572, lr_0 = 4.4480e-04
Loss = 1.1437e-04, PNorm = 45.0214, GNorm = 0.2810, lr_0 = 4.4420e-04
Loss = 1.3894e-04, PNorm = 45.0243, GNorm = 0.1927, lr_0 = 4.4361e-04
Loss = 1.2309e-04, PNorm = 45.0342, GNorm = 0.1444, lr_0 = 4.4301e-04
Loss = 1.1606e-04, PNorm = 45.0389, GNorm = 0.1863, lr_0 = 4.4242e-04
Loss = 1.5972e-04, PNorm = 45.0463, GNorm = 0.3451, lr_0 = 4.4182e-04
Loss = 1.7173e-04, PNorm = 45.0520, GNorm = 0.5310, lr_0 = 4.4123e-04
Loss = 1.1573e-04, PNorm = 45.0541, GNorm = 0.3017, lr_0 = 4.4064e-04
Loss = 1.3403e-04, PNorm = 45.0582, GNorm = 0.2912, lr_0 = 4.4005e-04
Loss = 1.6045e-04, PNorm = 45.0629, GNorm = 0.2825, lr_0 = 4.3946e-04
Loss = 1.6756e-04, PNorm = 45.0707, GNorm = 0.2886, lr_0 = 4.3887e-04
Loss = 1.9168e-04, PNorm = 45.0769, GNorm = 0.3526, lr_0 = 4.3828e-04
Loss = 1.5402e-04, PNorm = 45.0843, GNorm = 0.2155, lr_0 = 4.3769e-04
Validation rmse = 0.455174
Validation R2 = 0.940782
Epoch 37
Train function
Loss = 1.3663e-04, PNorm = 45.0924, GNorm = 0.2147, lr_0 = 4.3710e-04
Loss = 1.0402e-04, PNorm = 45.0955, GNorm = 0.1283, lr_0 = 4.3652e-04
Loss = 1.1556e-04, PNorm = 45.1003, GNorm = 0.4435, lr_0 = 4.3593e-04
Loss = 1.3186e-04, PNorm = 45.1049, GNorm = 0.1495, lr_0 = 4.3535e-04
Loss = 1.2003e-04, PNorm = 45.1097, GNorm = 0.1668, lr_0 = 4.3476e-04
Loss = 1.2897e-04, PNorm = 45.1188, GNorm = 0.2367, lr_0 = 4.3418e-04
Loss = 1.2286e-04, PNorm = 45.1256, GNorm = 0.3790, lr_0 = 4.3360e-04
Loss = 1.3070e-04, PNorm = 45.1345, GNorm = 0.1980, lr_0 = 4.3301e-04
Loss = 1.0299e-04, PNorm = 45.1394, GNorm = 0.1654, lr_0 = 4.3243e-04
Loss = 1.4906e-04, PNorm = 45.1475, GNorm = 0.3026, lr_0 = 4.3185e-04
Loss = 1.2327e-04, PNorm = 45.1525, GNorm = 0.2856, lr_0 = 4.3127e-04
Loss = 1.4115e-04, PNorm = 45.1584, GNorm = 0.1616, lr_0 = 4.3069e-04
Loss = 1.2981e-04, PNorm = 45.1650, GNorm = 0.4199, lr_0 = 4.3012e-04
Loss = 1.7058e-04, PNorm = 45.1717, GNorm = 0.4506, lr_0 = 4.2954e-04
Loss = 1.3086e-04, PNorm = 45.1819, GNorm = 0.2381, lr_0 = 4.2896e-04
Loss = 1.3156e-04, PNorm = 45.1847, GNorm = 0.1453, lr_0 = 4.2839e-04
Loss = 1.4850e-04, PNorm = 45.1905, GNorm = 0.3112, lr_0 = 4.2781e-04
Loss = 1.7431e-04, PNorm = 45.1965, GNorm = 0.3556, lr_0 = 4.2724e-04
Validation rmse = 0.464409
Validation R2 = 0.938354
Epoch 38
Train function
Loss = 1.4833e-04, PNorm = 45.2051, GNorm = 0.2891, lr_0 = 4.2667e-04
Loss = 1.4577e-04, PNorm = 45.2115, GNorm = 0.3273, lr_0 = 4.2609e-04
Loss = 1.4934e-04, PNorm = 45.2173, GNorm = 0.2883, lr_0 = 4.2552e-04
Loss = 1.8464e-04, PNorm = 45.2234, GNorm = 0.2252, lr_0 = 4.2495e-04
Loss = 1.8099e-04, PNorm = 45.2296, GNorm = 0.4529, lr_0 = 4.2438e-04
Loss = 1.3018e-04, PNorm = 45.2360, GNorm = 0.3878, lr_0 = 4.2381e-04
Loss = 1.1202e-04, PNorm = 45.2425, GNorm = 0.1839, lr_0 = 4.2324e-04
Loss = 1.3649e-04, PNorm = 45.2493, GNorm = 0.4174, lr_0 = 4.2267e-04
Loss = 1.3020e-04, PNorm = 45.2553, GNorm = 0.3002, lr_0 = 4.2211e-04
Loss = 9.4272e-05, PNorm = 45.2607, GNorm = 0.2324, lr_0 = 4.2154e-04
Loss = 1.2196e-04, PNorm = 45.2660, GNorm = 0.2335, lr_0 = 4.2098e-04
Loss = 1.1557e-04, PNorm = 45.2729, GNorm = 0.3279, lr_0 = 4.2041e-04
Loss = 1.2062e-04, PNorm = 45.2746, GNorm = 0.1470, lr_0 = 4.1985e-04
Loss = 1.4445e-04, PNorm = 45.2814, GNorm = 0.1623, lr_0 = 4.1928e-04
Loss = 1.3690e-04, PNorm = 45.2885, GNorm = 0.4187, lr_0 = 4.1872e-04
Loss = 1.3563e-04, PNorm = 45.2952, GNorm = 0.1938, lr_0 = 4.1816e-04
Loss = 1.4325e-04, PNorm = 45.3065, GNorm = 0.2583, lr_0 = 4.1760e-04
Loss = 1.5958e-04, PNorm = 45.3142, GNorm = 0.4162, lr_0 = 4.1704e-04
Loss = 1.3788e-04, PNorm = 45.3150, GNorm = 0.2934, lr_0 = 4.1698e-04
Validation rmse = 0.462035
Validation R2 = 0.938983
Epoch 39
Train function
Loss = 1.3518e-04, PNorm = 45.3226, GNorm = 0.2538, lr_0 = 4.1642e-04
Loss = 1.3189e-04, PNorm = 45.3288, GNorm = 0.3232, lr_0 = 4.1586e-04
Loss = 9.2583e-05, PNorm = 45.3365, GNorm = 0.2270, lr_0 = 4.1531e-04
Loss = 8.8177e-05, PNorm = 45.3416, GNorm = 0.1176, lr_0 = 4.1475e-04
Loss = 9.0846e-05, PNorm = 45.3466, GNorm = 0.1535, lr_0 = 4.1419e-04
Loss = 1.0267e-04, PNorm = 45.3500, GNorm = 0.2040, lr_0 = 4.1364e-04
Loss = 1.2748e-04, PNorm = 45.3560, GNorm = 0.4048, lr_0 = 4.1308e-04
Loss = 1.3506e-04, PNorm = 45.3665, GNorm = 0.4602, lr_0 = 4.1253e-04
Loss = 1.0926e-04, PNorm = 45.3722, GNorm = 0.4109, lr_0 = 4.1197e-04
Loss = 1.1384e-04, PNorm = 45.3798, GNorm = 0.1851, lr_0 = 4.1142e-04
Loss = 1.0741e-04, PNorm = 45.3848, GNorm = 0.1534, lr_0 = 4.1087e-04
Loss = 1.2286e-04, PNorm = 45.3882, GNorm = 0.2281, lr_0 = 4.1032e-04
Loss = 1.6829e-04, PNorm = 45.3922, GNorm = 0.4737, lr_0 = 4.0977e-04
Loss = 1.1619e-04, PNorm = 45.4019, GNorm = 0.2565, lr_0 = 4.0922e-04
Loss = 1.3971e-04, PNorm = 45.4063, GNorm = 0.3690, lr_0 = 4.0867e-04
Loss = 1.2337e-04, PNorm = 45.4164, GNorm = 0.2120, lr_0 = 4.0812e-04
Loss = 1.7491e-04, PNorm = 45.4236, GNorm = 0.3295, lr_0 = 4.0757e-04
Validation rmse = 0.460834
Validation R2 = 0.939300
Epoch 40
Train function
Loss = 9.2469e-05, PNorm = 45.4314, GNorm = 0.1718, lr_0 = 4.0702e-04
Loss = 1.0161e-04, PNorm = 45.4364, GNorm = 0.1451, lr_0 = 4.0648e-04
Loss = 1.0654e-04, PNorm = 45.4376, GNorm = 0.2988, lr_0 = 4.0593e-04
Loss = 1.1490e-04, PNorm = 45.4435, GNorm = 0.3850, lr_0 = 4.0539e-04
Loss = 1.2683e-04, PNorm = 45.4502, GNorm = 0.2532, lr_0 = 4.0484e-04
Loss = 1.0221e-04, PNorm = 45.4530, GNorm = 0.1961, lr_0 = 4.0430e-04
Loss = 1.2665e-04, PNorm = 45.4623, GNorm = 0.4755, lr_0 = 4.0376e-04
Loss = 1.1881e-04, PNorm = 45.4682, GNorm = 0.1662, lr_0 = 4.0322e-04
Loss = 1.0846e-04, PNorm = 45.4719, GNorm = 0.3614, lr_0 = 4.0268e-04
Loss = 1.5105e-04, PNorm = 45.4787, GNorm = 0.3422, lr_0 = 4.0214e-04
Loss = 1.2694e-04, PNorm = 45.4860, GNorm = 0.3883, lr_0 = 4.0160e-04
Loss = 1.5612e-04, PNorm = 45.4944, GNorm = 0.3673, lr_0 = 4.0106e-04
Loss = 1.2872e-04, PNorm = 45.5006, GNorm = 0.4613, lr_0 = 4.0052e-04
Loss = 1.2267e-04, PNorm = 45.5080, GNorm = 0.1898, lr_0 = 3.9998e-04
Loss = 1.0276e-04, PNorm = 45.5135, GNorm = 0.1974, lr_0 = 3.9945e-04
Loss = 1.0534e-04, PNorm = 45.5185, GNorm = 0.1257, lr_0 = 3.9891e-04
Loss = 1.3181e-04, PNorm = 45.5252, GNorm = 0.3275, lr_0 = 3.9837e-04
Loss = 1.2122e-04, PNorm = 45.5313, GNorm = 0.2653, lr_0 = 3.9784e-04
Validation rmse = 0.456828
Validation R2 = 0.940350
Epoch 41
Train function
Loss = 1.1168e-04, PNorm = 45.5376, GNorm = 0.1517, lr_0 = 3.9731e-04
Loss = 1.2673e-04, PNorm = 45.5426, GNorm = 0.1666, lr_0 = 3.9677e-04
Loss = 1.1180e-04, PNorm = 45.5461, GNorm = 0.2471, lr_0 = 3.9624e-04
Loss = 1.0997e-04, PNorm = 45.5497, GNorm = 0.2140, lr_0 = 3.9571e-04
Loss = 1.1269e-04, PNorm = 45.5561, GNorm = 0.2049, lr_0 = 3.9518e-04
Loss = 1.0795e-04, PNorm = 45.5589, GNorm = 0.1471, lr_0 = 3.9465e-04
Loss = 1.0855e-04, PNorm = 45.5653, GNorm = 0.1858, lr_0 = 3.9412e-04
Loss = 1.0609e-04, PNorm = 45.5698, GNorm = 0.1229, lr_0 = 3.9359e-04
Loss = 1.1191e-04, PNorm = 45.5746, GNorm = 0.2391, lr_0 = 3.9306e-04
Loss = 1.2376e-04, PNorm = 45.5830, GNorm = 0.3700, lr_0 = 3.9253e-04
Loss = 1.6179e-04, PNorm = 45.5882, GNorm = 0.3889, lr_0 = 3.9201e-04
Loss = 1.4047e-04, PNorm = 45.5971, GNorm = 0.4464, lr_0 = 3.9148e-04
Loss = 1.3321e-04, PNorm = 45.6033, GNorm = 0.3396, lr_0 = 3.9096e-04
Loss = 1.5355e-04, PNorm = 45.6129, GNorm = 0.3796, lr_0 = 3.9043e-04
Loss = 1.5617e-04, PNorm = 45.6199, GNorm = 0.2026, lr_0 = 3.8991e-04
Loss = 1.4901e-04, PNorm = 45.6287, GNorm = 0.1989, lr_0 = 3.8938e-04
Loss = 1.4105e-04, PNorm = 45.6369, GNorm = 0.2534, lr_0 = 3.8886e-04
Validation rmse = 0.461036
Validation R2 = 0.939247
Epoch 42
Train function
Loss = 1.0074e-04, PNorm = 45.6459, GNorm = 0.3222, lr_0 = 3.8829e-04
Loss = 1.3632e-04, PNorm = 45.6483, GNorm = 0.2675, lr_0 = 3.8777e-04
Loss = 1.1288e-04, PNorm = 45.6548, GNorm = 0.1913, lr_0 = 3.8725e-04
Loss = 9.8498e-05, PNorm = 45.6614, GNorm = 0.2061, lr_0 = 3.8673e-04
Loss = 1.3028e-04, PNorm = 45.6737, GNorm = 0.2266, lr_0 = 3.8621e-04
Loss = 1.1495e-04, PNorm = 45.6804, GNorm = 0.2576, lr_0 = 3.8569e-04
Loss = 1.0042e-04, PNorm = 45.6837, GNorm = 0.3036, lr_0 = 3.8517e-04
Loss = 9.4359e-05, PNorm = 45.6885, GNorm = 0.4438, lr_0 = 3.8466e-04
Loss = 1.0045e-04, PNorm = 45.6915, GNorm = 0.2434, lr_0 = 3.8414e-04
Loss = 1.0613e-04, PNorm = 45.6959, GNorm = 0.2457, lr_0 = 3.8362e-04
Loss = 1.1533e-04, PNorm = 45.7016, GNorm = 0.2457, lr_0 = 3.8311e-04
Loss = 9.6220e-05, PNorm = 45.7056, GNorm = 0.1583, lr_0 = 3.8260e-04
Loss = 1.1753e-04, PNorm = 45.7098, GNorm = 0.2127, lr_0 = 3.8208e-04
Loss = 1.5287e-04, PNorm = 45.7130, GNorm = 0.3144, lr_0 = 3.8157e-04
Loss = 1.2082e-04, PNorm = 45.7212, GNorm = 0.3507, lr_0 = 3.8106e-04
Loss = 8.0972e-05, PNorm = 45.7276, GNorm = 0.2754, lr_0 = 3.8055e-04
Loss = 1.0267e-04, PNorm = 45.7347, GNorm = 0.1272, lr_0 = 3.8004e-04
Loss = 1.1776e-04, PNorm = 45.7404, GNorm = 0.2218, lr_0 = 3.7953e-04
Validation rmse = 0.456434
Validation R2 = 0.940453
Epoch 43
Train function
Loss = 1.1149e-04, PNorm = 45.7428, GNorm = 0.2051, lr_0 = 3.7902e-04
Loss = 8.0057e-05, PNorm = 45.7482, GNorm = 0.2450, lr_0 = 3.7851e-04
Loss = 8.7337e-05, PNorm = 45.7542, GNorm = 0.2678, lr_0 = 3.7800e-04
Loss = 8.4990e-05, PNorm = 45.7603, GNorm = 0.2327, lr_0 = 3.7749e-04
Loss = 8.1250e-05, PNorm = 45.7646, GNorm = 0.1497, lr_0 = 3.7699e-04
Loss = 8.3210e-05, PNorm = 45.7701, GNorm = 0.1429, lr_0 = 3.7648e-04
Loss = 1.3070e-04, PNorm = 45.7715, GNorm = 0.3061, lr_0 = 3.7598e-04
Loss = 1.0835e-04, PNorm = 45.7783, GNorm = 0.2773, lr_0 = 3.7547e-04
Loss = 1.1055e-04, PNorm = 45.7826, GNorm = 0.2905, lr_0 = 3.7497e-04
Loss = 9.2821e-05, PNorm = 45.7857, GNorm = 0.6466, lr_0 = 3.7446e-04
Loss = 1.0307e-04, PNorm = 45.7917, GNorm = 0.4930, lr_0 = 3.7396e-04
Loss = 1.0668e-04, PNorm = 45.7987, GNorm = 0.3433, lr_0 = 3.7346e-04
Loss = 8.6520e-05, PNorm = 45.8037, GNorm = 0.1526, lr_0 = 3.7296e-04
Loss = 9.1787e-05, PNorm = 45.8090, GNorm = 0.3198, lr_0 = 3.7246e-04
Loss = 1.0110e-04, PNorm = 45.8147, GNorm = 0.4229, lr_0 = 3.7196e-04
Loss = 1.6332e-04, PNorm = 45.8188, GNorm = 0.8337, lr_0 = 3.7146e-04
Loss = 1.0912e-04, PNorm = 45.8225, GNorm = 0.1867, lr_0 = 3.7096e-04
Validation rmse = 0.459539
Validation R2 = 0.939640
Epoch 44
Train function
Loss = 9.2267e-05, PNorm = 45.8278, GNorm = 0.3846, lr_0 = 3.7046e-04
Loss = 1.0456e-04, PNorm = 45.8315, GNorm = 0.2032, lr_0 = 3.6997e-04
Loss = 1.0047e-04, PNorm = 45.8371, GNorm = 0.1739, lr_0 = 3.6947e-04
Loss = 7.0099e-05, PNorm = 45.8416, GNorm = 0.1818, lr_0 = 3.6898e-04
Loss = 8.4338e-05, PNorm = 45.8450, GNorm = 0.1545, lr_0 = 3.6848e-04
Loss = 1.0152e-04, PNorm = 45.8465, GNorm = 0.1381, lr_0 = 3.6799e-04
Loss = 1.0367e-04, PNorm = 45.8519, GNorm = 0.2159, lr_0 = 3.6749e-04
Loss = 1.0789e-04, PNorm = 45.8596, GNorm = 0.5825, lr_0 = 3.6700e-04
Loss = 1.0391e-04, PNorm = 45.8660, GNorm = 0.3156, lr_0 = 3.6651e-04
Loss = 1.0468e-04, PNorm = 45.8718, GNorm = 0.3909, lr_0 = 3.6601e-04
Loss = 8.9532e-05, PNorm = 45.8753, GNorm = 0.1835, lr_0 = 3.6552e-04
Loss = 1.0213e-04, PNorm = 45.8802, GNorm = 0.3652, lr_0 = 3.6503e-04
Loss = 1.0207e-04, PNorm = 45.8861, GNorm = 0.1142, lr_0 = 3.6454e-04
Loss = 9.2578e-05, PNorm = 45.8924, GNorm = 0.2571, lr_0 = 3.6405e-04
Loss = 1.0514e-04, PNorm = 45.8969, GNorm = 0.2767, lr_0 = 3.6357e-04
Loss = 8.4873e-05, PNorm = 45.9038, GNorm = 0.4046, lr_0 = 3.6308e-04
Loss = 8.9839e-05, PNorm = 45.9097, GNorm = 0.1564, lr_0 = 3.6259e-04
Loss = 1.1498e-04, PNorm = 45.9136, GNorm = 0.3715, lr_0 = 3.6210e-04
Validation rmse = 0.455517
Validation R2 = 0.940692
Epoch 45
Train function
Loss = 9.0615e-05, PNorm = 45.9170, GNorm = 0.3328, lr_0 = 3.6157e-04
Loss = 7.6756e-05, PNorm = 45.9213, GNorm = 0.1528, lr_0 = 3.6108e-04
Loss = 7.5093e-05, PNorm = 45.9251, GNorm = 0.2753, lr_0 = 3.6060e-04
Loss = 8.0456e-05, PNorm = 45.9301, GNorm = 0.2253, lr_0 = 3.6012e-04
Loss = 8.5980e-05, PNorm = 45.9361, GNorm = 0.1841, lr_0 = 3.5963e-04
Loss = 1.1168e-04, PNorm = 45.9401, GNorm = 0.5632, lr_0 = 3.5915e-04
Loss = 1.0526e-04, PNorm = 45.9442, GNorm = 0.4432, lr_0 = 3.5867e-04
Loss = 1.1870e-04, PNorm = 45.9546, GNorm = 0.5681, lr_0 = 3.5819e-04
Loss = 1.2237e-04, PNorm = 45.9606, GNorm = 0.5152, lr_0 = 3.5771e-04
Loss = 9.2378e-05, PNorm = 45.9649, GNorm = 0.3010, lr_0 = 3.5723e-04
Loss = 8.8115e-05, PNorm = 45.9710, GNorm = 0.2515, lr_0 = 3.5675e-04
Loss = 8.8592e-05, PNorm = 45.9743, GNorm = 0.4608, lr_0 = 3.5627e-04
Loss = 1.0474e-04, PNorm = 45.9773, GNorm = 0.3415, lr_0 = 3.5579e-04
Loss = 1.2639e-04, PNorm = 45.9815, GNorm = 0.1860, lr_0 = 3.5531e-04
Loss = 1.0547e-04, PNorm = 45.9890, GNorm = 0.1289, lr_0 = 3.5484e-04
Loss = 9.0054e-05, PNorm = 45.9942, GNorm = 0.4378, lr_0 = 3.5436e-04
Loss = 1.4256e-04, PNorm = 46.0018, GNorm = 0.5305, lr_0 = 3.5389e-04
Loss = 9.3912e-05, PNorm = 46.0094, GNorm = 0.1273, lr_0 = 3.5341e-04
Validation rmse = 0.458864
Validation R2 = 0.939818
Epoch 46
Train function
Loss = 1.0907e-04, PNorm = 46.0161, GNorm = 0.1676, lr_0 = 3.5294e-04
Loss = 8.8158e-05, PNorm = 46.0227, GNorm = 0.1699, lr_0 = 3.5246e-04
Loss = 7.8589e-05, PNorm = 46.0291, GNorm = 0.3608, lr_0 = 3.5199e-04
Loss = 8.8307e-05, PNorm = 46.0344, GNorm = 0.1155, lr_0 = 3.5152e-04
Loss = 6.1756e-05, PNorm = 46.0393, GNorm = 0.1122, lr_0 = 3.5105e-04
Loss = 6.9483e-05, PNorm = 46.0434, GNorm = 0.1010, lr_0 = 3.5058e-04
Loss = 7.1483e-05, PNorm = 46.0439, GNorm = 0.2322, lr_0 = 3.5010e-04
Loss = 7.2095e-05, PNorm = 46.0456, GNorm = 0.2199, lr_0 = 3.4964e-04
Loss = 8.5131e-05, PNorm = 46.0534, GNorm = 0.1330, lr_0 = 3.4917e-04
Loss = 7.3077e-05, PNorm = 46.0581, GNorm = 0.1693, lr_0 = 3.4870e-04
Loss = 7.9366e-05, PNorm = 46.0622, GNorm = 0.2074, lr_0 = 3.4823e-04
Loss = 7.6860e-05, PNorm = 46.0672, GNorm = 0.1425, lr_0 = 3.4776e-04
Loss = 1.0450e-04, PNorm = 46.0730, GNorm = 0.3556, lr_0 = 3.4730e-04
Loss = 1.3346e-04, PNorm = 46.0770, GNorm = 0.3992, lr_0 = 3.4683e-04
Loss = 1.0844e-04, PNorm = 46.0806, GNorm = 0.2881, lr_0 = 3.4636e-04
Loss = 1.0000e-04, PNorm = 46.0847, GNorm = 0.2481, lr_0 = 3.4590e-04
Loss = 9.5329e-05, PNorm = 46.0885, GNorm = 0.2590, lr_0 = 3.4544e-04
Validation rmse = 0.461489
Validation R2 = 0.939127
Epoch 47
Train function
Loss = 8.4122e-05, PNorm = 46.0928, GNorm = 0.2826, lr_0 = 3.4497e-04
Loss = 8.0233e-05, PNorm = 46.0994, GNorm = 0.2557, lr_0 = 3.4451e-04
Loss = 8.8325e-05, PNorm = 46.1029, GNorm = 0.3787, lr_0 = 3.4405e-04
Loss = 7.7133e-05, PNorm = 46.1085, GNorm = 0.2943, lr_0 = 3.4359e-04
Loss = 7.1518e-05, PNorm = 46.1106, GNorm = 0.3250, lr_0 = 3.4312e-04
Loss = 8.2351e-05, PNorm = 46.1157, GNorm = 0.3304, lr_0 = 3.4266e-04
Loss = 7.6187e-05, PNorm = 46.1205, GNorm = 0.2247, lr_0 = 3.4220e-04
Loss = 7.2029e-05, PNorm = 46.1250, GNorm = 0.1587, lr_0 = 3.4175e-04
Loss = 5.5368e-05, PNorm = 46.1299, GNorm = 0.1400, lr_0 = 3.4129e-04
Loss = 8.2679e-05, PNorm = 46.1352, GNorm = 0.1583, lr_0 = 3.4083e-04
Loss = 6.0225e-05, PNorm = 46.1387, GNorm = 0.2541, lr_0 = 3.4037e-04
Loss = 7.9940e-05, PNorm = 46.1426, GNorm = 0.1935, lr_0 = 3.3991e-04
Loss = 7.4585e-05, PNorm = 46.1494, GNorm = 0.3800, lr_0 = 3.3946e-04
Loss = 6.5328e-05, PNorm = 46.1534, GNorm = 0.1765, lr_0 = 3.3900e-04
Loss = 6.3964e-05, PNorm = 46.1557, GNorm = 0.1458, lr_0 = 3.3855e-04
Loss = 8.3516e-05, PNorm = 46.1586, GNorm = 0.1612, lr_0 = 3.3809e-04
Loss = 8.6319e-05, PNorm = 46.1641, GNorm = 0.3538, lr_0 = 3.3764e-04
Loss = 9.0777e-05, PNorm = 46.1693, GNorm = 0.5208, lr_0 = 3.3719e-04
Validation rmse = 0.465300
Validation R2 = 0.938118
Epoch 48
Train function
Loss = 8.8921e-05, PNorm = 46.1789, GNorm = 0.2778, lr_0 = 3.3669e-04
Loss = 6.9252e-05, PNorm = 46.1852, GNorm = 0.2866, lr_0 = 3.3624e-04
Loss = 7.8749e-05, PNorm = 46.1876, GNorm = 0.2180, lr_0 = 3.3579e-04
Loss = 7.5339e-05, PNorm = 46.1887, GNorm = 0.1789, lr_0 = 3.3534e-04
Loss = 9.7981e-05, PNorm = 46.1922, GNorm = 0.3930, lr_0 = 3.3489e-04
Loss = 8.1759e-05, PNorm = 46.1960, GNorm = 0.2170, lr_0 = 3.3444e-04
Loss = 7.3607e-05, PNorm = 46.1988, GNorm = 0.2155, lr_0 = 3.3399e-04
Loss = 6.2880e-05, PNorm = 46.2009, GNorm = 0.1759, lr_0 = 3.3354e-04
Loss = 6.0652e-05, PNorm = 46.2050, GNorm = 0.1768, lr_0 = 3.3309e-04
Loss = 6.3104e-05, PNorm = 46.2083, GNorm = 0.1364, lr_0 = 3.3265e-04
Loss = 7.5264e-05, PNorm = 46.2097, GNorm = 0.1837, lr_0 = 3.3220e-04
Loss = 8.2408e-05, PNorm = 46.2129, GNorm = 0.1451, lr_0 = 3.3175e-04
Loss = 6.5472e-05, PNorm = 46.2193, GNorm = 0.2763, lr_0 = 3.3131e-04
Loss = 8.4010e-05, PNorm = 46.2242, GNorm = 0.3252, lr_0 = 3.3086e-04
Loss = 6.7708e-05, PNorm = 46.2282, GNorm = 0.2196, lr_0 = 3.3042e-04
Loss = 8.2646e-05, PNorm = 46.2314, GNorm = 0.4497, lr_0 = 3.2998e-04
Loss = 7.1386e-05, PNorm = 46.2345, GNorm = 0.2722, lr_0 = 3.2953e-04
Validation rmse = 0.460479
Validation R2 = 0.939393
Epoch 49
Train function
Loss = 5.5046e-05, PNorm = 46.2374, GNorm = 0.1933, lr_0 = 3.2909e-04
Loss = 5.4894e-05, PNorm = 46.2416, GNorm = 0.1253, lr_0 = 3.2865e-04
Loss = 7.5732e-05, PNorm = 46.2467, GNorm = 0.2352, lr_0 = 3.2821e-04
Loss = 7.1915e-05, PNorm = 46.2490, GNorm = 0.1248, lr_0 = 3.2777e-04
Loss = 7.9148e-05, PNorm = 46.2530, GNorm = 0.3433, lr_0 = 3.2733e-04
Loss = 6.8197e-05, PNorm = 46.2564, GNorm = 0.1237, lr_0 = 3.2689e-04
Loss = 5.5123e-05, PNorm = 46.2602, GNorm = 0.2199, lr_0 = 3.2645e-04
Loss = 5.7405e-05, PNorm = 46.2625, GNorm = 0.1243, lr_0 = 3.2601e-04
Loss = 5.8701e-05, PNorm = 46.2654, GNorm = 0.1595, lr_0 = 3.2558e-04
Loss = 6.5888e-05, PNorm = 46.2708, GNorm = 0.2686, lr_0 = 3.2514e-04
Loss = 7.1199e-05, PNorm = 46.2763, GNorm = 0.3810, lr_0 = 3.2470e-04
Loss = 7.0496e-05, PNorm = 46.2805, GNorm = 0.1347, lr_0 = 3.2427e-04
Loss = 6.0231e-05, PNorm = 46.2843, GNorm = 0.4677, lr_0 = 3.2383e-04
Loss = 8.3890e-05, PNorm = 46.2867, GNorm = 0.2458, lr_0 = 3.2340e-04
Loss = 9.7993e-05, PNorm = 46.2910, GNorm = 0.4198, lr_0 = 3.2296e-04
Loss = 1.2870e-04, PNorm = 46.2970, GNorm = 0.2492, lr_0 = 3.2253e-04
Loss = 1.3797e-04, PNorm = 46.3005, GNorm = 0.8496, lr_0 = 3.2210e-04
Loss = 1.1845e-04, PNorm = 46.3083, GNorm = 0.6420, lr_0 = 3.2167e-04
Validation rmse = 0.469090
Validation R2 = 0.937105
Epoch 50
Train function
Loss = 1.1448e-04, PNorm = 46.3152, GNorm = 0.4550, lr_0 = 3.2123e-04
Loss = 8.9265e-05, PNorm = 46.3229, GNorm = 0.3140, lr_0 = 3.2080e-04
Loss = 7.9713e-05, PNorm = 46.3301, GNorm = 0.1492, lr_0 = 3.2037e-04
Loss = 8.6620e-05, PNorm = 46.3312, GNorm = 0.3309, lr_0 = 3.1994e-04
Loss = 8.6224e-05, PNorm = 46.3356, GNorm = 0.3143, lr_0 = 3.1951e-04
Loss = 7.4896e-05, PNorm = 46.3382, GNorm = 0.1528, lr_0 = 3.1909e-04
Loss = 7.1827e-05, PNorm = 46.3424, GNorm = 0.1900, lr_0 = 3.1866e-04
Loss = 6.4682e-05, PNorm = 46.3448, GNorm = 0.1110, lr_0 = 3.1823e-04
Loss = 6.1703e-05, PNorm = 46.3470, GNorm = 0.1063, lr_0 = 3.1780e-04
Loss = 6.1590e-05, PNorm = 46.3507, GNorm = 0.1450, lr_0 = 3.1738e-04
Loss = 5.6386e-05, PNorm = 46.3551, GNorm = 0.1574, lr_0 = 3.1695e-04
Loss = 6.3049e-05, PNorm = 46.3599, GNorm = 0.1806, lr_0 = 3.1653e-04
Loss = 6.5286e-05, PNorm = 46.3595, GNorm = 0.2353, lr_0 = 3.1610e-04
Loss = 7.3218e-05, PNorm = 46.3617, GNorm = 0.3689, lr_0 = 3.1568e-04
Loss = 1.0184e-04, PNorm = 46.3665, GNorm = 0.1095, lr_0 = 3.1525e-04
Loss = 8.4719e-05, PNorm = 46.3700, GNorm = 0.2110, lr_0 = 3.1483e-04
Loss = 6.6018e-05, PNorm = 46.3742, GNorm = 0.1651, lr_0 = 3.1441e-04
Validation rmse = 0.467969
Validation R2 = 0.937406
Epoch 51
Train function
Loss = 8.6113e-05, PNorm = 46.3837, GNorm = 0.2253, lr_0 = 3.1394e-04
Loss = 6.5471e-05, PNorm = 46.3874, GNorm = 0.1345, lr_0 = 3.1352e-04
Loss = 6.9524e-05, PNorm = 46.3925, GNorm = 0.1092, lr_0 = 3.1310e-04
Loss = 5.7534e-05, PNorm = 46.3960, GNorm = 0.1626, lr_0 = 3.1268e-04
Loss = 5.6746e-05, PNorm = 46.4009, GNorm = 0.1849, lr_0 = 3.1226e-04
Loss = 6.3743e-05, PNorm = 46.4049, GNorm = 0.2703, lr_0 = 3.1184e-04
Loss = 5.3592e-05, PNorm = 46.4079, GNorm = 0.1171, lr_0 = 3.1142e-04
Loss = 5.8247e-05, PNorm = 46.4117, GNorm = 0.1114, lr_0 = 3.1101e-04
Loss = 5.9457e-05, PNorm = 46.4159, GNorm = 0.1697, lr_0 = 3.1059e-04
Loss = 7.2159e-05, PNorm = 46.4180, GNorm = 0.1717, lr_0 = 3.1017e-04
Loss = 5.5727e-05, PNorm = 46.4198, GNorm = 0.1602, lr_0 = 3.0976e-04
Loss = 5.8036e-05, PNorm = 46.4237, GNorm = 0.2102, lr_0 = 3.0934e-04
Loss = 7.1209e-05, PNorm = 46.4279, GNorm = 0.1265, lr_0 = 3.0893e-04
Loss = 6.4270e-05, PNorm = 46.4328, GNorm = 0.1189, lr_0 = 3.0851e-04
Loss = 6.6063e-05, PNorm = 46.4353, GNorm = 0.1352, lr_0 = 3.0810e-04
Loss = 7.7555e-05, PNorm = 46.4390, GNorm = 0.1292, lr_0 = 3.0768e-04
Loss = 5.1028e-05, PNorm = 46.4423, GNorm = 0.3222, lr_0 = 3.0727e-04
Loss = 5.9863e-05, PNorm = 46.4461, GNorm = 0.1315, lr_0 = 3.0686e-04
Validation rmse = 0.456961
Validation R2 = 0.940316
Epoch 52
Train function
Loss = 4.4899e-05, PNorm = 46.4499, GNorm = 0.1734, lr_0 = 3.0645e-04
Loss = 6.5659e-05, PNorm = 46.4548, GNorm = 0.2644, lr_0 = 3.0604e-04
Loss = 5.7813e-05, PNorm = 46.4573, GNorm = 0.2505, lr_0 = 3.0563e-04
Loss = 5.6978e-05, PNorm = 46.4608, GNorm = 0.2861, lr_0 = 3.0522e-04
Loss = 5.1509e-05, PNorm = 46.4638, GNorm = 0.0774, lr_0 = 3.0481e-04
Loss = 4.7076e-05, PNorm = 46.4677, GNorm = 0.1430, lr_0 = 3.0440e-04
Loss = 5.5934e-05, PNorm = 46.4705, GNorm = 0.1727, lr_0 = 3.0399e-04
Loss = 5.7274e-05, PNorm = 46.4714, GNorm = 0.3013, lr_0 = 3.0358e-04
Loss = 7.5980e-05, PNorm = 46.4723, GNorm = 0.4346, lr_0 = 3.0317e-04
Loss = 6.2937e-05, PNorm = 46.4768, GNorm = 0.1910, lr_0 = 3.0277e-04
Loss = 6.1382e-05, PNorm = 46.4821, GNorm = 0.2441, lr_0 = 3.0236e-04
Loss = 5.9928e-05, PNorm = 46.4842, GNorm = 0.1889, lr_0 = 3.0195e-04
Loss = 7.0525e-05, PNorm = 46.4880, GNorm = 0.1019, lr_0 = 3.0155e-04
Loss = 7.0773e-05, PNorm = 46.4940, GNorm = 0.2297, lr_0 = 3.0114e-04
Loss = 5.3561e-05, PNorm = 46.4974, GNorm = 0.1052, lr_0 = 3.0074e-04
Loss = 6.1471e-05, PNorm = 46.4991, GNorm = 0.1223, lr_0 = 3.0034e-04
Loss = 6.2284e-05, PNorm = 46.5042, GNorm = 0.1786, lr_0 = 2.9993e-04
Validation rmse = 0.455925
Validation R2 = 0.940586
Epoch 53
Train function
Loss = 2.3165e-05, PNorm = 46.5054, GNorm = 0.1146, lr_0 = 2.9949e-04
Loss = 5.8525e-05, PNorm = 46.5076, GNorm = 0.1055, lr_0 = 2.9909e-04
Loss = 7.8097e-05, PNorm = 46.5089, GNorm = 0.3501, lr_0 = 2.9869e-04
Loss = 6.0417e-05, PNorm = 46.5116, GNorm = 0.1745, lr_0 = 2.9829e-04
Loss = 4.7919e-05, PNorm = 46.5152, GNorm = 0.1315, lr_0 = 2.9789e-04
Loss = 4.5263e-05, PNorm = 46.5198, GNorm = 0.3848, lr_0 = 2.9749e-04
Loss = 4.8766e-05, PNorm = 46.5231, GNorm = 0.3313, lr_0 = 2.9709e-04
Loss = 4.9205e-05, PNorm = 46.5258, GNorm = 0.1336, lr_0 = 2.9669e-04
Loss = 4.7764e-05, PNorm = 46.5310, GNorm = 0.1119, lr_0 = 2.9629e-04
Loss = 6.5248e-05, PNorm = 46.5367, GNorm = 0.1193, lr_0 = 2.9589e-04
Loss = 4.8213e-05, PNorm = 46.5406, GNorm = 0.1363, lr_0 = 2.9550e-04
Loss = 5.7499e-05, PNorm = 46.5442, GNorm = 0.1987, lr_0 = 2.9510e-04
Loss = 6.9551e-05, PNorm = 46.5479, GNorm = 0.2122, lr_0 = 2.9471e-04
Loss = 6.6724e-05, PNorm = 46.5516, GNorm = 0.4010, lr_0 = 2.9431e-04
Loss = 8.1534e-05, PNorm = 46.5558, GNorm = 0.2239, lr_0 = 2.9391e-04
Loss = 7.0125e-05, PNorm = 46.5602, GNorm = 0.2112, lr_0 = 2.9352e-04
Loss = 8.0620e-05, PNorm = 46.5625, GNorm = 0.4963, lr_0 = 2.9313e-04
Loss = 8.4986e-05, PNorm = 46.5644, GNorm = 0.4115, lr_0 = 2.9273e-04
Validation rmse = 0.459370
Validation R2 = 0.939685
Epoch 54
Train function
Loss = 1.0397e-04, PNorm = 46.5707, GNorm = 0.3623, lr_0 = 2.9234e-04
Loss = 7.2870e-05, PNorm = 46.5754, GNorm = 0.1603, lr_0 = 2.9195e-04
Loss = 7.6218e-05, PNorm = 46.5814, GNorm = 0.3368, lr_0 = 2.9156e-04
Loss = 5.8213e-05, PNorm = 46.5848, GNorm = 0.2611, lr_0 = 2.9117e-04
Loss = 5.4383e-05, PNorm = 46.5886, GNorm = 0.1209, lr_0 = 2.9077e-04
Loss = 5.0246e-05, PNorm = 46.5920, GNorm = 0.2350, lr_0 = 2.9038e-04
Loss = 5.5882e-05, PNorm = 46.5957, GNorm = 0.1530, lr_0 = 2.9000e-04
Loss = 5.3469e-05, PNorm = 46.5992, GNorm = 0.1284, lr_0 = 2.8961e-04
Loss = 5.3079e-05, PNorm = 46.6013, GNorm = 0.1978, lr_0 = 2.8922e-04
Loss = 5.4132e-05, PNorm = 46.6048, GNorm = 0.1322, lr_0 = 2.8883e-04
Loss = 5.7485e-05, PNorm = 46.6077, GNorm = 0.0789, lr_0 = 2.8844e-04
Loss = 5.9548e-05, PNorm = 46.6095, GNorm = 0.1551, lr_0 = 2.8805e-04
Loss = 4.9736e-05, PNorm = 46.6133, GNorm = 0.0816, lr_0 = 2.8767e-04
Loss = 4.7899e-05, PNorm = 46.6146, GNorm = 0.1176, lr_0 = 2.8728e-04
Loss = 5.4826e-05, PNorm = 46.6190, GNorm = 0.0703, lr_0 = 2.8690e-04
Loss = 6.9105e-05, PNorm = 46.6222, GNorm = 0.1300, lr_0 = 2.8651e-04
Loss = 5.7676e-05, PNorm = 46.6278, GNorm = 0.5004, lr_0 = 2.8613e-04
Loss = 6.0186e-05, PNorm = 46.6316, GNorm = 0.1020, lr_0 = 2.8574e-04
Validation rmse = 0.458466
Validation R2 = 0.939922
Epoch 55
Train function
Loss = 4.7223e-05, PNorm = 46.6369, GNorm = 0.1879, lr_0 = 2.8536e-04
Loss = 4.4595e-05, PNorm = 46.6371, GNorm = 0.0983, lr_0 = 2.8498e-04
Loss = 5.6257e-05, PNorm = 46.6409, GNorm = 0.2478, lr_0 = 2.8460e-04
Loss = 5.6920e-05, PNorm = 46.6441, GNorm = 0.1176, lr_0 = 2.8421e-04
Loss = 5.7657e-05, PNorm = 46.6470, GNorm = 0.1221, lr_0 = 2.8383e-04
Loss = 4.6950e-05, PNorm = 46.6508, GNorm = 0.0947, lr_0 = 2.8345e-04
Loss = 4.7212e-05, PNorm = 46.6521, GNorm = 0.1156, lr_0 = 2.8307e-04
Loss = 3.6205e-05, PNorm = 46.6547, GNorm = 0.1379, lr_0 = 2.8269e-04
Loss = 6.4355e-05, PNorm = 46.6578, GNorm = 0.5712, lr_0 = 2.8231e-04
Loss = 6.4748e-05, PNorm = 46.6621, GNorm = 0.3994, lr_0 = 2.8193e-04
Loss = 6.3920e-05, PNorm = 46.6648, GNorm = 0.5124, lr_0 = 2.8155e-04
Loss = 4.7891e-05, PNorm = 46.6695, GNorm = 0.2260, lr_0 = 2.8118e-04
Loss = 5.8326e-05, PNorm = 46.6724, GNorm = 0.1871, lr_0 = 2.8080e-04
Loss = 5.7877e-05, PNorm = 46.6758, GNorm = 0.1362, lr_0 = 2.8042e-04
Loss = 6.4477e-05, PNorm = 46.6802, GNorm = 0.2437, lr_0 = 2.8005e-04
Loss = 5.9172e-05, PNorm = 46.6840, GNorm = 0.1482, lr_0 = 2.7967e-04
Loss = 5.7025e-05, PNorm = 46.6859, GNorm = 0.1138, lr_0 = 2.7930e-04
Validation rmse = 0.458836
Validation R2 = 0.939825
Epoch 56
Train function
Loss = 4.5469e-05, PNorm = 46.6929, GNorm = 0.1103, lr_0 = 2.7888e-04
Loss = 5.6899e-05, PNorm = 46.6967, GNorm = 0.2860, lr_0 = 2.7851e-04
Loss = 4.8953e-05, PNorm = 46.6969, GNorm = 0.2689, lr_0 = 2.7814e-04
Loss = 3.8480e-05, PNorm = 46.6987, GNorm = 0.1101, lr_0 = 2.7776e-04
Loss = 4.3388e-05, PNorm = 46.6997, GNorm = 0.1181, lr_0 = 2.7739e-04
Loss = 4.5006e-05, PNorm = 46.7016, GNorm = 0.1259, lr_0 = 2.7702e-04
Loss = 3.9830e-05, PNorm = 46.7048, GNorm = 0.2300, lr_0 = 2.7665e-04
Loss = 5.5185e-05, PNorm = 46.7034, GNorm = 0.3753, lr_0 = 2.7627e-04
Loss = 5.2890e-05, PNorm = 46.7068, GNorm = 0.1143, lr_0 = 2.7590e-04
Loss = 4.9908e-05, PNorm = 46.7102, GNorm = 0.1357, lr_0 = 2.7553e-04
Loss = 4.2794e-05, PNorm = 46.7125, GNorm = 0.1610, lr_0 = 2.7516e-04
Loss = 5.2612e-05, PNorm = 46.7147, GNorm = 0.0991, lr_0 = 2.7479e-04
Loss = 5.2260e-05, PNorm = 46.7173, GNorm = 0.2180, lr_0 = 2.7443e-04
Loss = 5.5175e-05, PNorm = 46.7211, GNorm = 0.2706, lr_0 = 2.7406e-04
Loss = 6.4475e-05, PNorm = 46.7247, GNorm = 0.1379, lr_0 = 2.7369e-04
Loss = 6.2599e-05, PNorm = 46.7285, GNorm = 0.1485, lr_0 = 2.7332e-04
Loss = 7.3526e-05, PNorm = 46.7317, GNorm = 0.4349, lr_0 = 2.7296e-04
Loss = 6.0176e-05, PNorm = 46.7351, GNorm = 0.1293, lr_0 = 2.7259e-04
Validation rmse = 0.457541
Validation R2 = 0.940164
Epoch 57
Train function
Loss = 5.0891e-05, PNorm = 46.7407, GNorm = 0.1335, lr_0 = 2.7222e-04
Loss = 4.8510e-05, PNorm = 46.7429, GNorm = 0.0841, lr_0 = 2.7186e-04
Loss = 3.3419e-05, PNorm = 46.7456, GNorm = 0.0986, lr_0 = 2.7149e-04
Loss = 4.2096e-05, PNorm = 46.7492, GNorm = 0.0677, lr_0 = 2.7113e-04
Loss = 5.7207e-05, PNorm = 46.7528, GNorm = 0.1815, lr_0 = 2.7077e-04
Loss = 4.1135e-05, PNorm = 46.7580, GNorm = 0.1053, lr_0 = 2.7040e-04
Loss = 4.2447e-05, PNorm = 46.7621, GNorm = 0.1294, lr_0 = 2.7004e-04
Loss = 4.3109e-05, PNorm = 46.7622, GNorm = 0.1830, lr_0 = 2.6968e-04
Loss = 4.2467e-05, PNorm = 46.7637, GNorm = 0.0922, lr_0 = 2.6932e-04
Loss = 3.5839e-05, PNorm = 46.7677, GNorm = 0.1063, lr_0 = 2.6895e-04
Loss = 4.0301e-05, PNorm = 46.7694, GNorm = 0.1198, lr_0 = 2.6859e-04
Loss = 4.8651e-05, PNorm = 46.7728, GNorm = 0.1726, lr_0 = 2.6823e-04
Loss = 3.7818e-05, PNorm = 46.7743, GNorm = 0.1710, lr_0 = 2.6787e-04
Loss = 3.7216e-05, PNorm = 46.7766, GNorm = 0.2068, lr_0 = 2.6751e-04
Loss = 5.3037e-05, PNorm = 46.7771, GNorm = 0.0993, lr_0 = 2.6716e-04
Loss = 4.0101e-05, PNorm = 46.7777, GNorm = 0.1148, lr_0 = 2.6680e-04
Loss = 4.3165e-05, PNorm = 46.7813, GNorm = 0.2033, lr_0 = 2.6644e-04
Validation rmse = 0.459177
Validation R2 = 0.939735
Epoch 58
Train function
Loss = 2.5115e-05, PNorm = 46.7828, GNorm = 0.0867, lr_0 = 2.6608e-04
Loss = 4.2678e-05, PNorm = 46.7862, GNorm = 0.1475, lr_0 = 2.6572e-04
Loss = 4.7411e-05, PNorm = 46.7893, GNorm = 0.1093, lr_0 = 2.6537e-04
Loss = 6.0271e-05, PNorm = 46.7905, GNorm = 0.2819, lr_0 = 2.6501e-04
Loss = 6.2694e-05, PNorm = 46.7956, GNorm = 0.4243, lr_0 = 2.6466e-04
Loss = 4.3745e-05, PNorm = 46.7983, GNorm = 0.2000, lr_0 = 2.6430e-04
Loss = 4.0558e-05, PNorm = 46.7997, GNorm = 0.2161, lr_0 = 2.6395e-04
Loss = 4.6422e-05, PNorm = 46.8020, GNorm = 0.2619, lr_0 = 2.6359e-04
Loss = 4.4114e-05, PNorm = 46.8016, GNorm = 0.2704, lr_0 = 2.6324e-04
Loss = 4.8374e-05, PNorm = 46.8036, GNorm = 0.2384, lr_0 = 2.6289e-04
Loss = 4.9123e-05, PNorm = 46.8048, GNorm = 0.2240, lr_0 = 2.6253e-04
Loss = 4.1072e-05, PNorm = 46.8076, GNorm = 0.1509, lr_0 = 2.6218e-04
Loss = 4.8319e-05, PNorm = 46.8124, GNorm = 0.2303, lr_0 = 2.6183e-04
Loss = 5.3531e-05, PNorm = 46.8190, GNorm = 0.2528, lr_0 = 2.6148e-04
Loss = 4.6984e-05, PNorm = 46.8254, GNorm = 0.1155, lr_0 = 2.6113e-04
Loss = 4.6051e-05, PNorm = 46.8281, GNorm = 0.1079, lr_0 = 2.6078e-04
Loss = 5.2662e-05, PNorm = 46.8317, GNorm = 0.2667, lr_0 = 2.6043e-04
Loss = 4.8373e-05, PNorm = 46.8350, GNorm = 0.1288, lr_0 = 2.6008e-04
Validation rmse = 0.456882
Validation R2 = 0.940336
Epoch 59
Train function
Loss = 4.9489e-05, PNorm = 46.8362, GNorm = 0.1926, lr_0 = 2.5969e-04
Loss = 5.4505e-05, PNorm = 46.8378, GNorm = 0.3017, lr_0 = 2.5934e-04
Loss = 6.1772e-05, PNorm = 46.8407, GNorm = 0.1664, lr_0 = 2.5900e-04
Loss = 5.2661e-05, PNorm = 46.8432, GNorm = 0.3375, lr_0 = 2.5865e-04
Loss = 4.5529e-05, PNorm = 46.8457, GNorm = 0.1092, lr_0 = 2.5830e-04
Loss = 4.9644e-05, PNorm = 46.8486, GNorm = 0.1516, lr_0 = 2.5796e-04
Loss = 5.6112e-05, PNorm = 46.8501, GNorm = 0.1357, lr_0 = 2.5761e-04
Loss = 5.9358e-05, PNorm = 46.8560, GNorm = 0.0860, lr_0 = 2.5726e-04
Loss = 4.1508e-05, PNorm = 46.8573, GNorm = 0.1160, lr_0 = 2.5692e-04
Loss = 4.8566e-05, PNorm = 46.8606, GNorm = 0.2396, lr_0 = 2.5657e-04
Loss = 3.9307e-05, PNorm = 46.8632, GNorm = 0.1229, lr_0 = 2.5623e-04
Loss = 3.3197e-05, PNorm = 46.8657, GNorm = 0.1970, lr_0 = 2.5589e-04
Loss = 4.7007e-05, PNorm = 46.8700, GNorm = 0.0923, lr_0 = 2.5554e-04
Loss = 4.6033e-05, PNorm = 46.8730, GNorm = 0.2127, lr_0 = 2.5520e-04
Loss = 6.9125e-05, PNorm = 46.8774, GNorm = 0.1476, lr_0 = 2.5486e-04
Loss = 5.7545e-05, PNorm = 46.8817, GNorm = 0.1402, lr_0 = 2.5452e-04
Loss = 5.6660e-05, PNorm = 46.8821, GNorm = 0.2231, lr_0 = 2.5417e-04
Validation rmse = 0.463780
Validation R2 = 0.938521
Epoch 60
Train function
Loss = 8.4594e-05, PNorm = 46.8878, GNorm = 0.3989, lr_0 = 2.5383e-04
Loss = 5.3723e-05, PNorm = 46.8899, GNorm = 0.5000, lr_0 = 2.5349e-04
Loss = 3.6998e-05, PNorm = 46.8928, GNorm = 0.1617, lr_0 = 2.5315e-04
Loss = 4.7331e-05, PNorm = 46.8970, GNorm = 0.1517, lr_0 = 2.5281e-04
Loss = 4.1507e-05, PNorm = 46.8980, GNorm = 0.1086, lr_0 = 2.5247e-04
Loss = 4.1752e-05, PNorm = 46.9001, GNorm = 0.1423, lr_0 = 2.5213e-04
Loss = 5.0018e-05, PNorm = 46.9044, GNorm = 0.2771, lr_0 = 2.5180e-04
Loss = 4.2549e-05, PNorm = 46.9079, GNorm = 0.1795, lr_0 = 2.5146e-04
Loss = 4.6836e-05, PNorm = 46.9093, GNorm = 0.1184, lr_0 = 2.5112e-04
Loss = 3.8103e-05, PNorm = 46.9114, GNorm = 0.1346, lr_0 = 2.5078e-04
Loss = 3.5349e-05, PNorm = 46.9138, GNorm = 0.1840, lr_0 = 2.5045e-04
Loss = 3.2267e-05, PNorm = 46.9154, GNorm = 0.0992, lr_0 = 2.5011e-04
Loss = 4.2474e-05, PNorm = 46.9174, GNorm = 0.1754, lr_0 = 2.4978e-04
Loss = 4.1786e-05, PNorm = 46.9190, GNorm = 0.3764, lr_0 = 2.4944e-04
Loss = 4.8919e-05, PNorm = 46.9250, GNorm = 0.2511, lr_0 = 2.4911e-04
Loss = 4.4689e-05, PNorm = 46.9297, GNorm = 0.2102, lr_0 = 2.4877e-04
Loss = 4.9018e-05, PNorm = 46.9334, GNorm = 0.1452, lr_0 = 2.4844e-04
Loss = 5.6181e-05, PNorm = 46.9379, GNorm = 0.2286, lr_0 = 2.4811e-04
Validation rmse = 0.459592
Validation R2 = 0.939626
Epoch 61
Train function
Loss = 4.3542e-05, PNorm = 46.9424, GNorm = 0.2288, lr_0 = 2.4777e-04
Loss = 5.1267e-05, PNorm = 46.9436, GNorm = 0.3133, lr_0 = 2.4744e-04
Loss = 4.1820e-05, PNorm = 46.9459, GNorm = 0.1972, lr_0 = 2.4711e-04
Loss = 4.7177e-05, PNorm = 46.9483, GNorm = 0.1231, lr_0 = 2.4678e-04
Loss = 3.0880e-05, PNorm = 46.9519, GNorm = 0.0885, lr_0 = 2.4645e-04
Loss = 3.3875e-05, PNorm = 46.9544, GNorm = 0.1042, lr_0 = 2.4611e-04
Loss = 3.0246e-05, PNorm = 46.9549, GNorm = 0.0931, lr_0 = 2.4578e-04
Loss = 4.6212e-05, PNorm = 46.9565, GNorm = 0.2989, lr_0 = 2.4545e-04
Loss = 4.9538e-05, PNorm = 46.9594, GNorm = 0.3325, lr_0 = 2.4513e-04
Loss = 4.0485e-05, PNorm = 46.9626, GNorm = 0.0890, lr_0 = 2.4480e-04
Loss = 3.9131e-05, PNorm = 46.9642, GNorm = 0.1972, lr_0 = 2.4447e-04
Loss = 3.8957e-05, PNorm = 46.9658, GNorm = 0.1403, lr_0 = 2.4414e-04
Loss = 3.8034e-05, PNorm = 46.9710, GNorm = 0.3499, lr_0 = 2.4381e-04
Loss = 5.7613e-05, PNorm = 46.9721, GNorm = 0.3594, lr_0 = 2.4349e-04
Loss = 5.0396e-05, PNorm = 46.9735, GNorm = 0.4346, lr_0 = 2.4316e-04
Loss = 5.9138e-05, PNorm = 46.9769, GNorm = 0.2578, lr_0 = 2.4283e-04
Loss = 6.5275e-05, PNorm = 46.9799, GNorm = 0.4369, lr_0 = 2.4251e-04
Loss = 5.0114e-05, PNorm = 46.9833, GNorm = 0.1406, lr_0 = 2.4218e-04
Loss = 3.3059e-05, PNorm = 46.9835, GNorm = 0.1081, lr_0 = 2.4215e-04
Validation rmse = 0.458325
Validation R2 = 0.939959
Epoch 62
Train function
Loss = 4.5009e-05, PNorm = 46.9874, GNorm = 0.2195, lr_0 = 2.4182e-04
Loss = 5.7093e-05, PNorm = 46.9873, GNorm = 0.3689, lr_0 = 2.4150e-04
Loss = 3.5960e-05, PNorm = 46.9905, GNorm = 0.2793, lr_0 = 2.4118e-04
Loss = 3.6452e-05, PNorm = 46.9934, GNorm = 0.1720, lr_0 = 2.4085e-04
Loss = 3.4002e-05, PNorm = 46.9965, GNorm = 0.0854, lr_0 = 2.4053e-04
Loss = 2.8229e-05, PNorm = 46.9989, GNorm = 0.0981, lr_0 = 2.4021e-04
Loss = 3.3145e-05, PNorm = 46.9985, GNorm = 0.0855, lr_0 = 2.3988e-04
Loss = 4.1505e-05, PNorm = 47.0018, GNorm = 0.1371, lr_0 = 2.3956e-04
Loss = 3.2000e-05, PNorm = 47.0042, GNorm = 0.0972, lr_0 = 2.3924e-04
Loss = 3.3863e-05, PNorm = 47.0058, GNorm = 0.1015, lr_0 = 2.3892e-04
Loss = 3.4840e-05, PNorm = 47.0068, GNorm = 0.1454, lr_0 = 2.3860e-04
Loss = 3.3372e-05, PNorm = 47.0087, GNorm = 0.1354, lr_0 = 2.3828e-04
Loss = 3.3048e-05, PNorm = 47.0118, GNorm = 0.1264, lr_0 = 2.3796e-04
Loss = 3.4481e-05, PNorm = 47.0137, GNorm = 0.0820, lr_0 = 2.3764e-04
Loss = 3.4097e-05, PNorm = 47.0160, GNorm = 0.1948, lr_0 = 2.3732e-04
Loss = 3.0349e-05, PNorm = 47.0174, GNorm = 0.1351, lr_0 = 2.3700e-04
Loss = 3.8208e-05, PNorm = 47.0198, GNorm = 0.1432, lr_0 = 2.3668e-04
Validation rmse = 0.456891
Validation R2 = 0.940334
Epoch 63
Train function
Loss = 4.5501e-05, PNorm = 47.0209, GNorm = 0.0833, lr_0 = 2.3637e-04
Loss = 3.4866e-05, PNorm = 47.0236, GNorm = 0.1014, lr_0 = 2.3605e-04
Loss = 3.1926e-05, PNorm = 47.0243, GNorm = 0.0963, lr_0 = 2.3573e-04
Loss = 2.6118e-05, PNorm = 47.0244, GNorm = 0.1496, lr_0 = 2.3542e-04
Loss = 3.1546e-05, PNorm = 47.0271, GNorm = 0.2190, lr_0 = 2.3510e-04
Loss = 3.5098e-05, PNorm = 47.0294, GNorm = 0.1241, lr_0 = 2.3479e-04
Loss = 4.7155e-05, PNorm = 47.0309, GNorm = 0.3594, lr_0 = 2.3447e-04
Loss = 4.9983e-05, PNorm = 47.0378, GNorm = 0.1611, lr_0 = 2.3416e-04
Loss = 4.0665e-05, PNorm = 47.0396, GNorm = 0.1945, lr_0 = 2.3384e-04
Loss = 3.9212e-05, PNorm = 47.0423, GNorm = 0.0630, lr_0 = 2.3353e-04
Loss = 3.8221e-05, PNorm = 47.0473, GNorm = 0.0887, lr_0 = 2.3321e-04
Loss = 3.0089e-05, PNorm = 47.0502, GNorm = 0.1581, lr_0 = 2.3290e-04
Loss = 3.4461e-05, PNorm = 47.0522, GNorm = 0.0775, lr_0 = 2.3259e-04
Loss = 3.2643e-05, PNorm = 47.0535, GNorm = 0.2153, lr_0 = 2.3228e-04
Loss = 3.8569e-05, PNorm = 47.0550, GNorm = 0.1236, lr_0 = 2.3197e-04
Loss = 4.2308e-05, PNorm = 47.0583, GNorm = 0.1130, lr_0 = 2.3165e-04
Loss = 3.5384e-05, PNorm = 47.0578, GNorm = 0.1792, lr_0 = 2.3134e-04
Loss = 3.2607e-05, PNorm = 47.0605, GNorm = 0.1255, lr_0 = 2.3103e-04
Validation rmse = 0.457448
Validation R2 = 0.940189
Epoch 64
Train function
Loss = 3.2175e-05, PNorm = 47.0633, GNorm = 0.1529, lr_0 = 2.3072e-04
Loss = 2.7624e-05, PNorm = 47.0656, GNorm = 0.1045, lr_0 = 2.3041e-04
Loss = 2.6680e-05, PNorm = 47.0678, GNorm = 0.1287, lr_0 = 2.3010e-04
Loss = 2.7114e-05, PNorm = 47.0674, GNorm = 0.0816, lr_0 = 2.2980e-04
Loss = 4.3240e-05, PNorm = 47.0672, GNorm = 0.1423, lr_0 = 2.2949e-04
Loss = 2.9892e-05, PNorm = 47.0692, GNorm = 0.0973, lr_0 = 2.2918e-04
Loss = 3.7841e-05, PNorm = 47.0718, GNorm = 0.1069, lr_0 = 2.2887e-04
Loss = 2.5746e-05, PNorm = 47.0750, GNorm = 0.1439, lr_0 = 2.2856e-04
Loss = 2.6564e-05, PNorm = 47.0767, GNorm = 0.1040, lr_0 = 2.2826e-04
Loss = 2.5114e-05, PNorm = 47.0763, GNorm = 0.1302, lr_0 = 2.2795e-04
Loss = 2.8010e-05, PNorm = 47.0778, GNorm = 0.1275, lr_0 = 2.2765e-04
Loss = 3.4150e-05, PNorm = 47.0783, GNorm = 0.3050, lr_0 = 2.2734e-04
Loss = 3.8615e-05, PNorm = 47.0821, GNorm = 0.1311, lr_0 = 2.2704e-04
Loss = 3.8740e-05, PNorm = 47.0837, GNorm = 0.1249, lr_0 = 2.2673e-04
Loss = 3.8034e-05, PNorm = 47.0860, GNorm = 0.1198, lr_0 = 2.2643e-04
Loss = 3.7808e-05, PNorm = 47.0858, GNorm = 0.1046, lr_0 = 2.2612e-04
Loss = 3.7024e-05, PNorm = 47.0879, GNorm = 0.1601, lr_0 = 2.2582e-04
Validation rmse = 0.458192
Validation R2 = 0.939994
Epoch 65
Train function
Loss = 2.9664e-05, PNorm = 47.0908, GNorm = 0.1296, lr_0 = 2.2549e-04
Loss = 2.6378e-05, PNorm = 47.0912, GNorm = 0.0721, lr_0 = 2.2518e-04
Loss = 2.6228e-05, PNorm = 47.0930, GNorm = 0.1093, lr_0 = 2.2488e-04
Loss = 2.8339e-05, PNorm = 47.0944, GNorm = 0.1117, lr_0 = 2.2458e-04
Loss = 2.8381e-05, PNorm = 47.0970, GNorm = 0.2143, lr_0 = 2.2428e-04
Loss = 3.5743e-05, PNorm = 47.0986, GNorm = 0.1521, lr_0 = 2.2398e-04
Loss = 3.7094e-05, PNorm = 47.1005, GNorm = 0.2110, lr_0 = 2.2368e-04
Loss = 2.8959e-05, PNorm = 47.1025, GNorm = 0.1343, lr_0 = 2.2338e-04
Loss = 3.3321e-05, PNorm = 47.1058, GNorm = 0.1463, lr_0 = 2.2308e-04
Loss = 2.9986e-05, PNorm = 47.1068, GNorm = 0.3306, lr_0 = 2.2278e-04
Loss = 4.0373e-05, PNorm = 47.1083, GNorm = 0.3034, lr_0 = 2.2248e-04
Loss = 4.3708e-05, PNorm = 47.1099, GNorm = 0.2923, lr_0 = 2.2218e-04
Loss = 4.5604e-05, PNorm = 47.1116, GNorm = 0.1589, lr_0 = 2.2188e-04
Loss = 5.2622e-05, PNorm = 47.1154, GNorm = 0.4646, lr_0 = 2.2158e-04
Loss = 4.1524e-05, PNorm = 47.1188, GNorm = 0.2557, lr_0 = 2.2129e-04
Loss = 3.4785e-05, PNorm = 47.1218, GNorm = 0.1800, lr_0 = 2.2099e-04
Loss = 3.8727e-05, PNorm = 47.1250, GNorm = 0.2068, lr_0 = 2.2069e-04
Loss = 3.9789e-05, PNorm = 47.1247, GNorm = 0.1613, lr_0 = 2.2040e-04
Validation rmse = 0.456758
Validation R2 = 0.940369
Epoch 66
Train function
Loss = 4.3068e-05, PNorm = 47.1270, GNorm = 0.2250, lr_0 = 2.2010e-04
Loss = 4.1690e-05, PNorm = 47.1306, GNorm = 0.2208, lr_0 = 2.1981e-04
Loss = 4.3383e-05, PNorm = 47.1335, GNorm = 0.1053, lr_0 = 2.1951e-04
Loss = 2.7590e-05, PNorm = 47.1372, GNorm = 0.1928, lr_0 = 2.1922e-04
Loss = 2.9876e-05, PNorm = 47.1405, GNorm = 0.0870, lr_0 = 2.1892e-04
Loss = 3.1504e-05, PNorm = 47.1433, GNorm = 0.0914, lr_0 = 2.1863e-04
Loss = 2.7971e-05, PNorm = 47.1451, GNorm = 0.0693, lr_0 = 2.1834e-04
Loss = 2.9168e-05, PNorm = 47.1461, GNorm = 0.2421, lr_0 = 2.1804e-04
Loss = 3.1689e-05, PNorm = 47.1491, GNorm = 0.1541, lr_0 = 2.1775e-04
Loss = 2.3291e-05, PNorm = 47.1497, GNorm = 0.0817, lr_0 = 2.1746e-04
Loss = 3.7977e-05, PNorm = 47.1516, GNorm = 0.4154, lr_0 = 2.1717e-04
Loss = 2.8478e-05, PNorm = 47.1540, GNorm = 0.1019, lr_0 = 2.1688e-04
Loss = 2.6623e-05, PNorm = 47.1559, GNorm = 0.0953, lr_0 = 2.1658e-04
Loss = 3.4299e-05, PNorm = 47.1569, GNorm = 0.1739, lr_0 = 2.1629e-04
Loss = 2.9570e-05, PNorm = 47.1577, GNorm = 0.0758, lr_0 = 2.1600e-04
Loss = 2.7623e-05, PNorm = 47.1588, GNorm = 0.1514, lr_0 = 2.1571e-04
Loss = 3.0610e-05, PNorm = 47.1627, GNorm = 0.1175, lr_0 = 2.1542e-04
Validation rmse = 0.458241
Validation R2 = 0.939981
Epoch 67
Train function
Loss = 2.5413e-05, PNorm = 47.1658, GNorm = 0.1105, lr_0 = 2.1514e-04
Loss = 2.5523e-05, PNorm = 47.1667, GNorm = 0.0664, lr_0 = 2.1485e-04
Loss = 2.3893e-05, PNorm = 47.1680, GNorm = 0.1112, lr_0 = 2.1456e-04
Loss = 1.9319e-05, PNorm = 47.1698, GNorm = 0.0603, lr_0 = 2.1427e-04
Loss = 2.5311e-05, PNorm = 47.1706, GNorm = 0.1020, lr_0 = 2.1398e-04
Loss = 2.4531e-05, PNorm = 47.1718, GNorm = 0.1481, lr_0 = 2.1370e-04
Loss = 2.2486e-05, PNorm = 47.1742, GNorm = 0.0885, lr_0 = 2.1341e-04
Loss = 2.5670e-05, PNorm = 47.1761, GNorm = 0.1254, lr_0 = 2.1312e-04
Loss = 2.0844e-05, PNorm = 47.1782, GNorm = 0.0873, lr_0 = 2.1284e-04
Loss = 2.7643e-05, PNorm = 47.1812, GNorm = 0.1657, lr_0 = 2.1255e-04
Loss = 2.7924e-05, PNorm = 47.1841, GNorm = 0.1318, lr_0 = 2.1227e-04
Loss = 2.3447e-05, PNorm = 47.1850, GNorm = 0.1245, lr_0 = 2.1198e-04
Loss = 3.0559e-05, PNorm = 47.1858, GNorm = 0.2099, lr_0 = 2.1170e-04
Loss = 3.2683e-05, PNorm = 47.1878, GNorm = 0.1119, lr_0 = 2.1141e-04
Loss = 2.4837e-05, PNorm = 47.1875, GNorm = 0.1012, lr_0 = 2.1113e-04
Loss = 3.1070e-05, PNorm = 47.1886, GNorm = 0.1210, lr_0 = 2.1085e-04
Loss = 2.3086e-05, PNorm = 47.1897, GNorm = 0.1326, lr_0 = 2.1056e-04
Loss = 2.3577e-05, PNorm = 47.1914, GNorm = 0.0917, lr_0 = 2.1028e-04
Validation rmse = 0.457435
Validation R2 = 0.940192
Epoch 68
Train function
Loss = 2.1756e-05, PNorm = 47.1931, GNorm = 0.1448, lr_0 = 2.0997e-04
Loss = 1.8028e-05, PNorm = 47.1936, GNorm = 0.1675, lr_0 = 2.0969e-04
Loss = 2.6385e-05, PNorm = 47.1935, GNorm = 0.2723, lr_0 = 2.0941e-04
Loss = 2.9099e-05, PNorm = 47.1958, GNorm = 0.1761, lr_0 = 2.0913e-04
Loss = 2.1682e-05, PNorm = 47.1974, GNorm = 0.1236, lr_0 = 2.0885e-04
Loss = 2.7034e-05, PNorm = 47.1973, GNorm = 0.2038, lr_0 = 2.0857e-04
Loss = 3.5819e-05, PNorm = 47.2000, GNorm = 0.4174, lr_0 = 2.0829e-04
Loss = 5.2167e-05, PNorm = 47.2030, GNorm = 0.5021, lr_0 = 2.0801e-04
Loss = 3.9268e-05, PNorm = 47.2062, GNorm = 0.1842, lr_0 = 2.0773e-04
Loss = 2.7824e-05, PNorm = 47.2063, GNorm = 0.1076, lr_0 = 2.0745e-04
Loss = 3.0546e-05, PNorm = 47.2085, GNorm = 0.2272, lr_0 = 2.0717e-04
Loss = 3.0656e-05, PNorm = 47.2108, GNorm = 0.0849, lr_0 = 2.0689e-04
Loss = 2.5542e-05, PNorm = 47.2126, GNorm = 0.1522, lr_0 = 2.0661e-04
Loss = 2.6972e-05, PNorm = 47.2138, GNorm = 0.2098, lr_0 = 2.0634e-04
Loss = 3.2822e-05, PNorm = 47.2156, GNorm = 0.1082, lr_0 = 2.0606e-04
Loss = 2.6818e-05, PNorm = 47.2156, GNorm = 0.1711, lr_0 = 2.0578e-04
Loss = 3.4027e-05, PNorm = 47.2199, GNorm = 0.0947, lr_0 = 2.0551e-04
Loss = 2.9010e-05, PNorm = 47.2232, GNorm = 0.2846, lr_0 = 2.0523e-04
Validation rmse = 0.456769
Validation R2 = 0.940366
Epoch 69
Train function
Loss = 3.1069e-05, PNorm = 47.2255, GNorm = 0.2702, lr_0 = 2.0496e-04
Loss = 2.4584e-05, PNorm = 47.2283, GNorm = 0.2016, lr_0 = 2.0468e-04
Loss = 2.5910e-05, PNorm = 47.2313, GNorm = 0.1182, lr_0 = 2.0441e-04
Loss = 2.5279e-05, PNorm = 47.2335, GNorm = 0.2274, lr_0 = 2.0413e-04
Loss = 2.5490e-05, PNorm = 47.2346, GNorm = 0.1893, lr_0 = 2.0386e-04
Loss = 2.3482e-05, PNorm = 47.2365, GNorm = 0.1356, lr_0 = 2.0359e-04
Loss = 2.9918e-05, PNorm = 47.2393, GNorm = 0.1303, lr_0 = 2.0331e-04
Loss = 2.7559e-05, PNorm = 47.2410, GNorm = 0.0852, lr_0 = 2.0304e-04
Loss = 3.3031e-05, PNorm = 47.2425, GNorm = 0.1245, lr_0 = 2.0277e-04
Loss = 2.9757e-05, PNorm = 47.2448, GNorm = 0.0945, lr_0 = 2.0249e-04
Loss = 2.7446e-05, PNorm = 47.2477, GNorm = 0.1253, lr_0 = 2.0222e-04
Loss = 2.9042e-05, PNorm = 47.2513, GNorm = 0.1945, lr_0 = 2.0195e-04
Loss = 3.1176e-05, PNorm = 47.2536, GNorm = 0.2800, lr_0 = 2.0168e-04
Loss = 3.3924e-05, PNorm = 47.2561, GNorm = 0.4239, lr_0 = 2.0141e-04
Loss = 4.5725e-05, PNorm = 47.2581, GNorm = 0.0988, lr_0 = 2.0114e-04
Loss = 4.1976e-05, PNorm = 47.2609, GNorm = 0.1013, lr_0 = 2.0087e-04
Loss = 3.6590e-05, PNorm = 47.2646, GNorm = 0.1837, lr_0 = 2.0060e-04
Validation rmse = 0.458875
Validation R2 = 0.939815
Epoch 70
Train function
Loss = 3.8028e-05, PNorm = 47.2666, GNorm = 0.1595, lr_0 = 2.0033e-04
Loss = 3.1303e-05, PNorm = 47.2675, GNorm = 0.2000, lr_0 = 2.0006e-04
Loss = 3.3003e-05, PNorm = 47.2712, GNorm = 0.2003, lr_0 = 1.9979e-04
Loss = 3.3575e-05, PNorm = 47.2751, GNorm = 0.3065, lr_0 = 1.9953e-04
Loss = 2.6944e-05, PNorm = 47.2774, GNorm = 0.1604, lr_0 = 1.9926e-04
Loss = 2.5533e-05, PNorm = 47.2800, GNorm = 0.0715, lr_0 = 1.9899e-04
Loss = 2.6992e-05, PNorm = 47.2819, GNorm = 0.1252, lr_0 = 1.9872e-04
Loss = 2.7759e-05, PNorm = 47.2840, GNorm = 0.0692, lr_0 = 1.9846e-04
Loss = 2.2947e-05, PNorm = 47.2843, GNorm = 0.0849, lr_0 = 1.9819e-04
Loss = 2.3583e-05, PNorm = 47.2833, GNorm = 0.0607, lr_0 = 1.9793e-04
Loss = 1.7730e-05, PNorm = 47.2835, GNorm = 0.0710, lr_0 = 1.9766e-04
Loss = 3.1729e-05, PNorm = 47.2847, GNorm = 0.0995, lr_0 = 1.9739e-04
Loss = 3.2435e-05, PNorm = 47.2877, GNorm = 0.1059, lr_0 = 1.9713e-04
Loss = 2.4768e-05, PNorm = 47.2885, GNorm = 0.1016, lr_0 = 1.9687e-04
Loss = 2.5557e-05, PNorm = 47.2898, GNorm = 0.0893, lr_0 = 1.9660e-04
Loss = 2.7219e-05, PNorm = 47.2912, GNorm = 0.1612, lr_0 = 1.9634e-04
Loss = 3.1090e-05, PNorm = 47.2916, GNorm = 0.1523, lr_0 = 1.9607e-04
Loss = 2.7960e-05, PNorm = 47.2943, GNorm = 0.0633, lr_0 = 1.9581e-04
Validation rmse = 0.456917
Validation R2 = 0.940327
Epoch 71
Train function
Loss = 2.6378e-05, PNorm = 47.2985, GNorm = 0.1217, lr_0 = 1.9552e-04
Loss = 2.6174e-05, PNorm = 47.3008, GNorm = 0.0597, lr_0 = 1.9526e-04
Loss = 2.5104e-05, PNorm = 47.3022, GNorm = 0.0826, lr_0 = 1.9500e-04
Loss = 2.6192e-05, PNorm = 47.3025, GNorm = 0.2806, lr_0 = 1.9474e-04
Loss = 2.0812e-05, PNorm = 47.3025, GNorm = 0.0840, lr_0 = 1.9447e-04
Loss = 2.5876e-05, PNorm = 47.3043, GNorm = 0.2167, lr_0 = 1.9421e-04
Loss = 2.2728e-05, PNorm = 47.3058, GNorm = 0.0679, lr_0 = 1.9395e-04
Loss = 1.8244e-05, PNorm = 47.3070, GNorm = 0.1439, lr_0 = 1.9369e-04
Loss = 1.7406e-05, PNorm = 47.3068, GNorm = 0.0661, lr_0 = 1.9343e-04
Loss = 2.1606e-05, PNorm = 47.3065, GNorm = 0.0791, lr_0 = 1.9317e-04
Loss = 2.1284e-05, PNorm = 47.3079, GNorm = 0.0813, lr_0 = 1.9291e-04
Loss = 1.9689e-05, PNorm = 47.3105, GNorm = 0.1005, lr_0 = 1.9266e-04
Loss = 2.4377e-05, PNorm = 47.3115, GNorm = 0.2955, lr_0 = 1.9240e-04
Loss = 2.1492e-05, PNorm = 47.3121, GNorm = 0.0854, lr_0 = 1.9214e-04
Loss = 2.0696e-05, PNorm = 47.3141, GNorm = 0.1149, lr_0 = 1.9188e-04
Loss = 2.3768e-05, PNorm = 47.3165, GNorm = 0.0901, lr_0 = 1.9162e-04
Loss = 2.7200e-05, PNorm = 47.3165, GNorm = 0.1097, lr_0 = 1.9137e-04
Validation rmse = 0.456852
Validation R2 = 0.940344
Epoch 72
Train function
Loss = 1.6032e-05, PNorm = 47.3189, GNorm = 0.0733, lr_0 = 1.9111e-04
Loss = 1.6336e-05, PNorm = 47.3213, GNorm = 0.0633, lr_0 = 1.9085e-04
Loss = 1.8087e-05, PNorm = 47.3231, GNorm = 0.1341, lr_0 = 1.9060e-04
Loss = 2.0116e-05, PNorm = 47.3238, GNorm = 0.1153, lr_0 = 1.9034e-04
Loss = 2.2180e-05, PNorm = 47.3253, GNorm = 0.1187, lr_0 = 1.9009e-04
Loss = 2.0543e-05, PNorm = 47.3261, GNorm = 0.1753, lr_0 = 1.8983e-04
Loss = 2.6083e-05, PNorm = 47.3283, GNorm = 0.2876, lr_0 = 1.8958e-04
Loss = 2.0793e-05, PNorm = 47.3302, GNorm = 0.1012, lr_0 = 1.8932e-04
Loss = 2.0466e-05, PNorm = 47.3315, GNorm = 0.0696, lr_0 = 1.8907e-04
Loss = 2.4457e-05, PNorm = 47.3341, GNorm = 0.1373, lr_0 = 1.8881e-04
Loss = 1.9057e-05, PNorm = 47.3349, GNorm = 0.0502, lr_0 = 1.8856e-04
Loss = 2.3037e-05, PNorm = 47.3369, GNorm = 0.0884, lr_0 = 1.8831e-04
Loss = 2.7940e-05, PNorm = 47.3391, GNorm = 0.0560, lr_0 = 1.8806e-04
Loss = 2.4088e-05, PNorm = 47.3419, GNorm = 0.0927, lr_0 = 1.8780e-04
Loss = 2.2766e-05, PNorm = 47.3439, GNorm = 0.0791, lr_0 = 1.8755e-04
Loss = 2.3080e-05, PNorm = 47.3462, GNorm = 0.1243, lr_0 = 1.8730e-04
Loss = 1.9335e-05, PNorm = 47.3464, GNorm = 0.0852, lr_0 = 1.8705e-04
Loss = 1.7810e-05, PNorm = 47.3482, GNorm = 0.1071, lr_0 = 1.8680e-04
Validation rmse = 0.455489
Validation R2 = 0.940700
Epoch 73
Train function
Loss = 1.7585e-05, PNorm = 47.3480, GNorm = 0.0972, lr_0 = 1.8655e-04
Loss = 1.8448e-05, PNorm = 47.3505, GNorm = 0.1009, lr_0 = 1.8630e-04
Loss = 2.0697e-05, PNorm = 47.3521, GNorm = 0.1251, lr_0 = 1.8605e-04
Loss = 1.7004e-05, PNorm = 47.3534, GNorm = 0.0828, lr_0 = 1.8580e-04
Loss = 1.8117e-05, PNorm = 47.3540, GNorm = 0.0949, lr_0 = 1.8555e-04
Loss = 2.5827e-05, PNorm = 47.3562, GNorm = 0.0792, lr_0 = 1.8530e-04
Loss = 1.9196e-05, PNorm = 47.3571, GNorm = 0.0674, lr_0 = 1.8505e-04
Loss = 2.0793e-05, PNorm = 47.3577, GNorm = 0.0783, lr_0 = 1.8480e-04
Loss = 1.8556e-05, PNorm = 47.3606, GNorm = 0.0855, lr_0 = 1.8455e-04
Loss = 1.8354e-05, PNorm = 47.3612, GNorm = 0.1336, lr_0 = 1.8431e-04
Loss = 2.2992e-05, PNorm = 47.3615, GNorm = 0.2197, lr_0 = 1.8406e-04
Loss = 2.0720e-05, PNorm = 47.3636, GNorm = 0.0711, lr_0 = 1.8381e-04
Loss = 1.9784e-05, PNorm = 47.3643, GNorm = 0.0846, lr_0 = 1.8357e-04
Loss = 1.4198e-05, PNorm = 47.3659, GNorm = 0.0884, lr_0 = 1.8332e-04
Loss = 2.4410e-05, PNorm = 47.3678, GNorm = 0.0831, lr_0 = 1.8307e-04
Loss = 1.9377e-05, PNorm = 47.3690, GNorm = 0.2060, lr_0 = 1.8283e-04
Loss = 2.3086e-05, PNorm = 47.3696, GNorm = 0.1082, lr_0 = 1.8258e-04
Validation rmse = 0.457853
Validation R2 = 0.940083
Epoch 74
Train function
Loss = 1.8819e-05, PNorm = 47.3723, GNorm = 0.1277, lr_0 = 1.8231e-04
Loss = 1.9774e-05, PNorm = 47.3737, GNorm = 0.1180, lr_0 = 1.8207e-04
Loss = 1.8304e-05, PNorm = 47.3741, GNorm = 0.0822, lr_0 = 1.8182e-04
Loss = 2.6398e-05, PNorm = 47.3762, GNorm = 0.1577, lr_0 = 1.8158e-04
Loss = 2.3058e-05, PNorm = 47.3759, GNorm = 0.1804, lr_0 = 1.8134e-04
Loss = 1.6651e-05, PNorm = 47.3786, GNorm = 0.1720, lr_0 = 1.8109e-04
Loss = 1.9908e-05, PNorm = 47.3810, GNorm = 0.1885, lr_0 = 1.8085e-04
Loss = 1.6222e-05, PNorm = 47.3830, GNorm = 0.0641, lr_0 = 1.8061e-04
Loss = 1.8982e-05, PNorm = 47.3862, GNorm = 0.0572, lr_0 = 1.8036e-04
Loss = 1.4511e-05, PNorm = 47.3863, GNorm = 0.0877, lr_0 = 1.8012e-04
Loss = 1.9124e-05, PNorm = 47.3866, GNorm = 0.1820, lr_0 = 1.7988e-04
Loss = 1.7863e-05, PNorm = 47.3870, GNorm = 0.0770, lr_0 = 1.7964e-04
Loss = 1.6014e-05, PNorm = 47.3875, GNorm = 0.0579, lr_0 = 1.7940e-04
Loss = 1.5955e-05, PNorm = 47.3874, GNorm = 0.0586, lr_0 = 1.7916e-04
Loss = 1.8992e-05, PNorm = 47.3892, GNorm = 0.1378, lr_0 = 1.7892e-04
Loss = 2.0704e-05, PNorm = 47.3916, GNorm = 0.0943, lr_0 = 1.7868e-04
Loss = 2.4284e-05, PNorm = 47.3920, GNorm = 0.1197, lr_0 = 1.7844e-04
Loss = 2.5823e-05, PNorm = 47.3961, GNorm = 0.2164, lr_0 = 1.7820e-04
Validation rmse = 0.458134
Validation R2 = 0.940009
Epoch 75
Train function
Loss = 2.2330e-05, PNorm = 47.3977, GNorm = 0.1277, lr_0 = 1.7796e-04
Loss = 2.1466e-05, PNorm = 47.3992, GNorm = 0.1173, lr_0 = 1.7772e-04
Loss = 1.5250e-05, PNorm = 47.4003, GNorm = 0.0670, lr_0 = 1.7748e-04
Loss = 2.2598e-05, PNorm = 47.4003, GNorm = 0.2647, lr_0 = 1.7724e-04
Loss = 2.8952e-05, PNorm = 47.4025, GNorm = 0.1746, lr_0 = 1.7701e-04
Loss = 3.2358e-05, PNorm = 47.4064, GNorm = 0.1100, lr_0 = 1.7677e-04
Loss = 3.3124e-05, PNorm = 47.4111, GNorm = 0.1423, lr_0 = 1.7653e-04
Loss = 2.8505e-05, PNorm = 47.4132, GNorm = 0.2476, lr_0 = 1.7629e-04
Loss = 2.2483e-05, PNorm = 47.4125, GNorm = 0.1729, lr_0 = 1.7606e-04
Loss = 2.4935e-05, PNorm = 47.4137, GNorm = 0.1040, lr_0 = 1.7582e-04
Loss = 2.5614e-05, PNorm = 47.4156, GNorm = 0.2482, lr_0 = 1.7559e-04
Loss = 2.1158e-05, PNorm = 47.4176, GNorm = 0.0956, lr_0 = 1.7535e-04
Loss = 2.8677e-05, PNorm = 47.4204, GNorm = 0.3059, lr_0 = 1.7512e-04
Loss = 2.7981e-05, PNorm = 47.4216, GNorm = 0.1707, lr_0 = 1.7488e-04
Loss = 3.2675e-05, PNorm = 47.4239, GNorm = 0.1021, lr_0 = 1.7465e-04
Loss = 2.5844e-05, PNorm = 47.4233, GNorm = 0.0847, lr_0 = 1.7441e-04
Loss = 2.5254e-05, PNorm = 47.4259, GNorm = 0.0908, lr_0 = 1.7418e-04
Loss = 3.0412e-05, PNorm = 47.4263, GNorm = 0.2146, lr_0 = 1.7394e-04
Validation rmse = 0.459278
Validation R2 = 0.939709
Epoch 76
Train function
Loss = 2.7996e-05, PNorm = 47.4292, GNorm = 0.2113, lr_0 = 1.7371e-04
Loss = 4.2337e-05, PNorm = 47.4329, GNorm = 0.2763, lr_0 = 1.7348e-04
Loss = 3.0727e-05, PNorm = 47.4329, GNorm = 0.1609, lr_0 = 1.7324e-04
Loss = 2.3181e-05, PNorm = 47.4336, GNorm = 0.1307, lr_0 = 1.7301e-04
Loss = 2.3273e-05, PNorm = 47.4338, GNorm = 0.0644, lr_0 = 1.7278e-04
Loss = 1.9141e-05, PNorm = 47.4368, GNorm = 0.0670, lr_0 = 1.7255e-04
Loss = 2.1067e-05, PNorm = 47.4379, GNorm = 0.1249, lr_0 = 1.7232e-04
Loss = 2.3169e-05, PNorm = 47.4392, GNorm = 0.1050, lr_0 = 1.7209e-04
Loss = 2.1489e-05, PNorm = 47.4418, GNorm = 0.0790, lr_0 = 1.7185e-04
Loss = 2.1863e-05, PNorm = 47.4443, GNorm = 0.1201, lr_0 = 1.7162e-04
Loss = 2.1776e-05, PNorm = 47.4450, GNorm = 0.1367, lr_0 = 1.7139e-04
Loss = 2.3261e-05, PNorm = 47.4465, GNorm = 0.0616, lr_0 = 1.7116e-04
Loss = 1.7717e-05, PNorm = 47.4483, GNorm = 0.1134, lr_0 = 1.7093e-04
Loss = 2.3523e-05, PNorm = 47.4483, GNorm = 0.0972, lr_0 = 1.7070e-04
Loss = 1.5564e-05, PNorm = 47.4498, GNorm = 0.0909, lr_0 = 1.7048e-04
Loss = 1.5906e-05, PNorm = 47.4507, GNorm = 0.0986, lr_0 = 1.7025e-04
Loss = 2.2155e-05, PNorm = 47.4520, GNorm = 0.1321, lr_0 = 1.7002e-04
Validation rmse = 0.457655
Validation R2 = 0.940134
Epoch 77
Train function
Loss = 1.2882e-05, PNorm = 47.4552, GNorm = 0.0835, lr_0 = 1.6977e-04
Loss = 1.3246e-05, PNorm = 47.4565, GNorm = 0.0843, lr_0 = 1.6954e-04
Loss = 1.1194e-05, PNorm = 47.4571, GNorm = 0.0910, lr_0 = 1.6931e-04
Loss = 1.5111e-05, PNorm = 47.4574, GNorm = 0.0569, lr_0 = 1.6908e-04
Loss = 1.5322e-05, PNorm = 47.4575, GNorm = 0.1725, lr_0 = 1.6886e-04
Loss = 1.8206e-05, PNorm = 47.4600, GNorm = 0.1307, lr_0 = 1.6863e-04
Loss = 1.4636e-05, PNorm = 47.4622, GNorm = 0.0495, lr_0 = 1.6841e-04
Loss = 1.6989e-05, PNorm = 47.4644, GNorm = 0.0888, lr_0 = 1.6818e-04
Loss = 1.3960e-05, PNorm = 47.4649, GNorm = 0.0495, lr_0 = 1.6795e-04
Loss = 1.7498e-05, PNorm = 47.4659, GNorm = 0.0671, lr_0 = 1.6773e-04
Loss = 2.1890e-05, PNorm = 47.4671, GNorm = 0.0852, lr_0 = 1.6750e-04
Loss = 2.4202e-05, PNorm = 47.4701, GNorm = 0.2404, lr_0 = 1.6728e-04
Loss = 1.6405e-05, PNorm = 47.4713, GNorm = 0.1042, lr_0 = 1.6705e-04
Loss = 2.6424e-05, PNorm = 47.4713, GNorm = 0.1831, lr_0 = 1.6683e-04
Loss = 2.5806e-05, PNorm = 47.4734, GNorm = 0.1863, lr_0 = 1.6661e-04
Loss = 2.1979e-05, PNorm = 47.4747, GNorm = 0.0715, lr_0 = 1.6638e-04
Loss = 1.9976e-05, PNorm = 47.4766, GNorm = 0.0771, lr_0 = 1.6616e-04
Loss = 1.5916e-05, PNorm = 47.4772, GNorm = 0.0973, lr_0 = 1.6594e-04
Validation rmse = 0.456547
Validation R2 = 0.940424
Epoch 78
Train function
Loss = 1.6191e-05, PNorm = 47.4782, GNorm = 0.1141, lr_0 = 1.6571e-04
Loss = 1.5937e-05, PNorm = 47.4805, GNorm = 0.0826, lr_0 = 1.6549e-04
Loss = 1.2667e-05, PNorm = 47.4834, GNorm = 0.0666, lr_0 = 1.6527e-04
Loss = 1.3820e-05, PNorm = 47.4836, GNorm = 0.0786, lr_0 = 1.6505e-04
Loss = 1.4613e-05, PNorm = 47.4843, GNorm = 0.1040, lr_0 = 1.6483e-04
Loss = 1.2601e-05, PNorm = 47.4861, GNorm = 0.0454, lr_0 = 1.6461e-04
Loss = 1.4444e-05, PNorm = 47.4861, GNorm = 0.0751, lr_0 = 1.6438e-04
Loss = 1.2716e-05, PNorm = 47.4863, GNorm = 0.0512, lr_0 = 1.6416e-04
Loss = 1.4345e-05, PNorm = 47.4872, GNorm = 0.0809, lr_0 = 1.6394e-04
Loss = 1.9682e-05, PNorm = 47.4877, GNorm = 0.1793, lr_0 = 1.6372e-04
Loss = 2.4859e-05, PNorm = 47.4888, GNorm = 0.1269, lr_0 = 1.6350e-04
Loss = 1.6693e-05, PNorm = 47.4901, GNorm = 0.1647, lr_0 = 1.6328e-04
Loss = 1.5404e-05, PNorm = 47.4914, GNorm = 0.0994, lr_0 = 1.6307e-04
Loss = 1.5817e-05, PNorm = 47.4914, GNorm = 0.0824, lr_0 = 1.6285e-04
Loss = 1.7654e-05, PNorm = 47.4925, GNorm = 0.0741, lr_0 = 1.6263e-04
Loss = 2.0644e-05, PNorm = 47.4938, GNorm = 0.0835, lr_0 = 1.6241e-04
Loss = 1.9316e-05, PNorm = 47.4950, GNorm = 0.1538, lr_0 = 1.6219e-04
Validation rmse = 0.458140
Validation R2 = 0.940008
Epoch 79
Train function
Loss = 1.5280e-05, PNorm = 47.4969, GNorm = 0.1642, lr_0 = 1.6197e-04
Loss = 1.5995e-05, PNorm = 47.4974, GNorm = 0.0664, lr_0 = 1.6176e-04
Loss = 1.7525e-05, PNorm = 47.4996, GNorm = 0.0503, lr_0 = 1.6154e-04
Loss = 1.8540e-05, PNorm = 47.5014, GNorm = 0.0732, lr_0 = 1.6132e-04
Loss = 1.3759e-05, PNorm = 47.5024, GNorm = 0.0840, lr_0 = 1.6111e-04
Loss = 1.7106e-05, PNorm = 47.5026, GNorm = 0.0843, lr_0 = 1.6089e-04
Loss = 2.0571e-05, PNorm = 47.5050, GNorm = 0.1143, lr_0 = 1.6067e-04
Loss = 2.2357e-05, PNorm = 47.5057, GNorm = 0.0959, lr_0 = 1.6046e-04
Loss = 1.8413e-05, PNorm = 47.5058, GNorm = 0.1727, lr_0 = 1.6024e-04
Loss = 1.7167e-05, PNorm = 47.5066, GNorm = 0.0814, lr_0 = 1.6003e-04
Loss = 1.4950e-05, PNorm = 47.5082, GNorm = 0.0692, lr_0 = 1.5981e-04
Loss = 1.4292e-05, PNorm = 47.5098, GNorm = 0.0564, lr_0 = 1.5960e-04
Loss = 2.0057e-05, PNorm = 47.5113, GNorm = 0.1446, lr_0 = 1.5939e-04
Loss = 1.4497e-05, PNorm = 47.5126, GNorm = 0.0942, lr_0 = 1.5917e-04
Loss = 2.5848e-05, PNorm = 47.5147, GNorm = 0.1625, lr_0 = 1.5896e-04
Loss = 1.5281e-05, PNorm = 47.5150, GNorm = 0.0501, lr_0 = 1.5874e-04
Loss = 1.7601e-05, PNorm = 47.5149, GNorm = 0.1668, lr_0 = 1.5853e-04
Loss = 1.9044e-05, PNorm = 47.5146, GNorm = 0.1238, lr_0 = 1.5832e-04
Validation rmse = 0.457338
Validation R2 = 0.940217
Epoch 80
Train function
Loss = 1.6359e-05, PNorm = 47.5161, GNorm = 0.1138, lr_0 = 1.5809e-04
Loss = 1.9924e-05, PNorm = 47.5163, GNorm = 0.1023, lr_0 = 1.5787e-04
Loss = 2.4872e-05, PNorm = 47.5170, GNorm = 0.1524, lr_0 = 1.5766e-04
Loss = 1.9283e-05, PNorm = 47.5178, GNorm = 0.0891, lr_0 = 1.5745e-04
Loss = 1.8895e-05, PNorm = 47.5203, GNorm = 0.0659, lr_0 = 1.5724e-04
Loss = 1.5029e-05, PNorm = 47.5212, GNorm = 0.1474, lr_0 = 1.5703e-04
Loss = 1.6122e-05, PNorm = 47.5229, GNorm = 0.0839, lr_0 = 1.5682e-04
Loss = 1.4862e-05, PNorm = 47.5245, GNorm = 0.0945, lr_0 = 1.5661e-04
Loss = 1.6966e-05, PNorm = 47.5254, GNorm = 0.0792, lr_0 = 1.5640e-04
Loss = 1.7738e-05, PNorm = 47.5254, GNorm = 0.1325, lr_0 = 1.5619e-04
Loss = 1.9584e-05, PNorm = 47.5275, GNorm = 0.1543, lr_0 = 1.5598e-04
Loss = 1.7095e-05, PNorm = 47.5284, GNorm = 0.2276, lr_0 = 1.5577e-04
Loss = 2.1790e-05, PNorm = 47.5306, GNorm = 0.0431, lr_0 = 1.5556e-04
Loss = 2.1099e-05, PNorm = 47.5317, GNorm = 0.1536, lr_0 = 1.5535e-04
Loss = 2.3407e-05, PNorm = 47.5347, GNorm = 0.1144, lr_0 = 1.5514e-04
Loss = 2.1734e-05, PNorm = 47.5347, GNorm = 0.1605, lr_0 = 1.5493e-04
Loss = 1.8308e-05, PNorm = 47.5355, GNorm = 0.1052, lr_0 = 1.5473e-04
Validation rmse = 0.457569
Validation R2 = 0.940157
Epoch 81
Train function
Loss = 1.5137e-05, PNorm = 47.5368, GNorm = 0.1852, lr_0 = 1.5452e-04
Loss = 1.7377e-05, PNorm = 47.5377, GNorm = 0.0504, lr_0 = 1.5431e-04
Loss = 1.5456e-05, PNorm = 47.5379, GNorm = 0.0763, lr_0 = 1.5410e-04
Loss = 1.8366e-05, PNorm = 47.5400, GNorm = 0.0838, lr_0 = 1.5390e-04
Loss = 1.7582e-05, PNorm = 47.5417, GNorm = 0.0476, lr_0 = 1.5369e-04
Loss = 1.4885e-05, PNorm = 47.5444, GNorm = 0.0905, lr_0 = 1.5348e-04
Loss = 1.2718e-05, PNorm = 47.5456, GNorm = 0.0476, lr_0 = 1.5328e-04
Loss = 1.6869e-05, PNorm = 47.5466, GNorm = 0.0635, lr_0 = 1.5307e-04
Loss = 2.2433e-05, PNorm = 47.5468, GNorm = 0.0621, lr_0 = 1.5287e-04
Loss = 1.3333e-05, PNorm = 47.5490, GNorm = 0.0564, lr_0 = 1.5266e-04
Loss = 1.3955e-05, PNorm = 47.5512, GNorm = 0.0638, lr_0 = 1.5246e-04
Loss = 1.9602e-05, PNorm = 47.5522, GNorm = 0.0879, lr_0 = 1.5225e-04
Loss = 1.6210e-05, PNorm = 47.5542, GNorm = 0.0743, lr_0 = 1.5205e-04
Loss = 1.8933e-05, PNorm = 47.5544, GNorm = 0.2421, lr_0 = 1.5184e-04
Loss = 2.5394e-05, PNorm = 47.5553, GNorm = 0.1339, lr_0 = 1.5164e-04
Loss = 1.9328e-05, PNorm = 47.5563, GNorm = 0.1047, lr_0 = 1.5144e-04
Loss = 1.3950e-05, PNorm = 47.5571, GNorm = 0.0831, lr_0 = 1.5123e-04
Loss = 1.4733e-05, PNorm = 47.5583, GNorm = 0.1271, lr_0 = 1.5103e-04
Validation rmse = 0.457649
Validation R2 = 0.940136
Epoch 82
Train function
Loss = 1.2047e-05, PNorm = 47.5598, GNorm = 0.0884, lr_0 = 1.5083e-04
Loss = 1.0755e-05, PNorm = 47.5600, GNorm = 0.0519, lr_0 = 1.5063e-04
Loss = 1.1837e-05, PNorm = 47.5602, GNorm = 0.0442, lr_0 = 1.5042e-04
Loss = 1.3146e-05, PNorm = 47.5604, GNorm = 0.0529, lr_0 = 1.5022e-04
Loss = 1.4074e-05, PNorm = 47.5604, GNorm = 0.0761, lr_0 = 1.5002e-04
Loss = 1.3004e-05, PNorm = 47.5601, GNorm = 0.0675, lr_0 = 1.4982e-04
Loss = 1.4778e-05, PNorm = 47.5605, GNorm = 0.1247, lr_0 = 1.4962e-04
Loss = 1.1859e-05, PNorm = 47.5612, GNorm = 0.0638, lr_0 = 1.4942e-04
Loss = 1.4370e-05, PNorm = 47.5618, GNorm = 0.0622, lr_0 = 1.4922e-04
Loss = 9.3049e-06, PNorm = 47.5624, GNorm = 0.0647, lr_0 = 1.4902e-04
Loss = 1.3860e-05, PNorm = 47.5621, GNorm = 0.1190, lr_0 = 1.4882e-04
Loss = 1.4309e-05, PNorm = 47.5634, GNorm = 0.0631, lr_0 = 1.4862e-04
Loss = 1.1530e-05, PNorm = 47.5642, GNorm = 0.1009, lr_0 = 1.4842e-04
Loss = 1.2669e-05, PNorm = 47.5650, GNorm = 0.0432, lr_0 = 1.4822e-04
Loss = 1.3136e-05, PNorm = 47.5661, GNorm = 0.1011, lr_0 = 1.4802e-04
Loss = 1.5541e-05, PNorm = 47.5660, GNorm = 0.0498, lr_0 = 1.4782e-04
Loss = 1.8449e-05, PNorm = 47.5671, GNorm = 0.0541, lr_0 = 1.4762e-04
Validation rmse = 0.458564
Validation R2 = 0.939896
Epoch 83
Train function
Loss = 1.0695e-05, PNorm = 47.5684, GNorm = 0.1233, lr_0 = 1.4741e-04
Loss = 1.6359e-05, PNorm = 47.5691, GNorm = 0.0838, lr_0 = 1.4721e-04
Loss = 1.7817e-05, PNorm = 47.5696, GNorm = 0.1914, lr_0 = 1.4701e-04
Loss = 1.6429e-05, PNorm = 47.5695, GNorm = 0.1180, lr_0 = 1.4681e-04
Loss = 1.2035e-05, PNorm = 47.5697, GNorm = 0.1130, lr_0 = 1.4662e-04
Loss = 1.1418e-05, PNorm = 47.5710, GNorm = 0.0799, lr_0 = 1.4642e-04
Loss = 1.4465e-05, PNorm = 47.5730, GNorm = 0.1435, lr_0 = 1.4622e-04
Loss = 1.2507e-05, PNorm = 47.5737, GNorm = 0.0906, lr_0 = 1.4603e-04
Loss = 1.2434e-05, PNorm = 47.5746, GNorm = 0.1027, lr_0 = 1.4583e-04
Loss = 1.5150e-05, PNorm = 47.5764, GNorm = 0.1456, lr_0 = 1.4563e-04
Loss = 1.0712e-05, PNorm = 47.5783, GNorm = 0.0617, lr_0 = 1.4544e-04
Loss = 9.3167e-06, PNorm = 47.5800, GNorm = 0.0601, lr_0 = 1.4524e-04
Loss = 9.0159e-06, PNorm = 47.5803, GNorm = 0.0801, lr_0 = 1.4505e-04
Loss = 1.1828e-05, PNorm = 47.5805, GNorm = 0.1618, lr_0 = 1.4485e-04
Loss = 9.4779e-06, PNorm = 47.5810, GNorm = 0.0490, lr_0 = 1.4466e-04
Loss = 1.1510e-05, PNorm = 47.5812, GNorm = 0.0880, lr_0 = 1.4447e-04
Loss = 2.0422e-05, PNorm = 47.5824, GNorm = 0.0926, lr_0 = 1.4427e-04
Loss = 2.3497e-05, PNorm = 47.5855, GNorm = 0.1165, lr_0 = 1.4408e-04
Validation rmse = 0.458968
Validation R2 = 0.939790
Epoch 84
Train function
Loss = 1.7169e-05, PNorm = 47.5877, GNorm = 0.1144, lr_0 = 1.4389e-04
Loss = 1.6194e-05, PNorm = 47.5899, GNorm = 0.0654, lr_0 = 1.4369e-04
Loss = 1.0466e-05, PNorm = 47.5902, GNorm = 0.1211, lr_0 = 1.4350e-04
Loss = 1.3843e-05, PNorm = 47.5904, GNorm = 0.0517, lr_0 = 1.4331e-04
Loss = 1.4237e-05, PNorm = 47.5921, GNorm = 0.0753, lr_0 = 1.4311e-04
Loss = 1.1232e-05, PNorm = 47.5927, GNorm = 0.0364, lr_0 = 1.4292e-04
Loss = 1.1477e-05, PNorm = 47.5935, GNorm = 0.0761, lr_0 = 1.4273e-04
Loss = 9.8684e-06, PNorm = 47.5946, GNorm = 0.0854, lr_0 = 1.4254e-04
Loss = 9.7972e-06, PNorm = 47.5950, GNorm = 0.0497, lr_0 = 1.4235e-04
Loss = 1.0045e-05, PNorm = 47.5950, GNorm = 0.0622, lr_0 = 1.4216e-04
Loss = 1.1353e-05, PNorm = 47.5953, GNorm = 0.1146, lr_0 = 1.4197e-04
Loss = 1.1443e-05, PNorm = 47.5969, GNorm = 0.0592, lr_0 = 1.4178e-04
Loss = 1.2009e-05, PNorm = 47.5983, GNorm = 0.0429, lr_0 = 1.4159e-04
Loss = 1.1475e-05, PNorm = 47.5985, GNorm = 0.1393, lr_0 = 1.4140e-04
Loss = 1.0109e-05, PNorm = 47.5994, GNorm = 0.0488, lr_0 = 1.4121e-04
Loss = 1.1744e-05, PNorm = 47.6012, GNorm = 0.0572, lr_0 = 1.4102e-04
Loss = 1.3084e-05, PNorm = 47.6019, GNorm = 0.1146, lr_0 = 1.4083e-04
Loss = 1.0113e-05, PNorm = 47.6029, GNorm = 0.0958, lr_0 = 1.4064e-04
Validation rmse = 0.457493
Validation R2 = 0.940177
Epoch 85
Train function
Loss = 1.0705e-05, PNorm = 47.6039, GNorm = 0.1856, lr_0 = 1.4045e-04
Loss = 1.0413e-05, PNorm = 47.6042, GNorm = 0.1454, lr_0 = 1.4026e-04
Loss = 1.3518e-05, PNorm = 47.6049, GNorm = 0.0606, lr_0 = 1.4007e-04
Loss = 1.2753e-05, PNorm = 47.6061, GNorm = 0.0699, lr_0 = 1.3989e-04
Loss = 1.0203e-05, PNorm = 47.6069, GNorm = 0.0950, lr_0 = 1.3970e-04
Loss = 9.0457e-06, PNorm = 47.6078, GNorm = 0.0576, lr_0 = 1.3951e-04
Loss = 8.9756e-06, PNorm = 47.6084, GNorm = 0.0483, lr_0 = 1.3932e-04
Loss = 9.2965e-06, PNorm = 47.6091, GNorm = 0.0399, lr_0 = 1.3914e-04
Loss = 1.4291e-05, PNorm = 47.6103, GNorm = 0.1707, lr_0 = 1.3895e-04
Loss = 1.1720e-05, PNorm = 47.6105, GNorm = 0.0821, lr_0 = 1.3876e-04
Loss = 1.3539e-05, PNorm = 47.6114, GNorm = 0.0693, lr_0 = 1.3858e-04
Loss = 1.6085e-05, PNorm = 47.6103, GNorm = 0.0817, lr_0 = 1.3839e-04
Loss = 1.4388e-05, PNorm = 47.6116, GNorm = 0.1066, lr_0 = 1.3821e-04
Loss = 1.3990e-05, PNorm = 47.6123, GNorm = 0.0748, lr_0 = 1.3802e-04
Loss = 1.3152e-05, PNorm = 47.6142, GNorm = 0.1351, lr_0 = 1.3783e-04
Loss = 1.3197e-05, PNorm = 47.6166, GNorm = 0.1419, lr_0 = 1.3765e-04
Loss = 1.0375e-05, PNorm = 47.6170, GNorm = 0.0553, lr_0 = 1.3747e-04
Validation rmse = 0.456067
Validation R2 = 0.940549
Epoch 86
Train function
Loss = 1.0238e-05, PNorm = 47.6177, GNorm = 0.0495, lr_0 = 1.3726e-04
Loss = 9.1666e-06, PNorm = 47.6204, GNorm = 0.0615, lr_0 = 1.3708e-04
Loss = 1.1794e-05, PNorm = 47.6205, GNorm = 0.1179, lr_0 = 1.3689e-04
Loss = 1.1564e-05, PNorm = 47.6211, GNorm = 0.1146, lr_0 = 1.3671e-04
Loss = 1.2543e-05, PNorm = 47.6224, GNorm = 0.1660, lr_0 = 1.3653e-04
Loss = 1.6516e-05, PNorm = 47.6242, GNorm = 0.0524, lr_0 = 1.3634e-04
Loss = 2.2430e-05, PNorm = 47.6245, GNorm = 0.1209, lr_0 = 1.3616e-04
Loss = 1.6907e-05, PNorm = 47.6258, GNorm = 0.1833, lr_0 = 1.3598e-04
Loss = 1.9637e-05, PNorm = 47.6270, GNorm = 0.1669, lr_0 = 1.3580e-04
Loss = 1.7369e-05, PNorm = 47.6279, GNorm = 0.1039, lr_0 = 1.3561e-04
Loss = 2.0746e-05, PNorm = 47.6288, GNorm = 0.1041, lr_0 = 1.3543e-04
Loss = 2.1290e-05, PNorm = 47.6305, GNorm = 0.0801, lr_0 = 1.3525e-04
Loss = 1.4156e-05, PNorm = 47.6314, GNorm = 0.1071, lr_0 = 1.3507e-04
Loss = 1.6865e-05, PNorm = 47.6340, GNorm = 0.1044, lr_0 = 1.3489e-04
Loss = 1.4213e-05, PNorm = 47.6366, GNorm = 0.0842, lr_0 = 1.3471e-04
Loss = 1.4888e-05, PNorm = 47.6376, GNorm = 0.0550, lr_0 = 1.3453e-04
Loss = 1.6734e-05, PNorm = 47.6391, GNorm = 0.1006, lr_0 = 1.3435e-04
Loss = 1.3336e-05, PNorm = 47.6397, GNorm = 0.1010, lr_0 = 1.3416e-04
Validation rmse = 0.457631
Validation R2 = 0.940141
Epoch 87
Train function
Loss = 1.1369e-05, PNorm = 47.6410, GNorm = 0.0892, lr_0 = 1.3398e-04
Loss = 1.4356e-05, PNorm = 47.6411, GNorm = 0.1009, lr_0 = 1.3380e-04
Loss = 1.4396e-05, PNorm = 47.6409, GNorm = 0.0919, lr_0 = 1.3363e-04
Loss = 1.4004e-05, PNorm = 47.6416, GNorm = 0.0523, lr_0 = 1.3345e-04
Loss = 1.1043e-05, PNorm = 47.6423, GNorm = 0.0638, lr_0 = 1.3327e-04
Loss = 1.0914e-05, PNorm = 47.6433, GNorm = 0.0541, lr_0 = 1.3309e-04
Loss = 1.3960e-05, PNorm = 47.6436, GNorm = 0.1191, lr_0 = 1.3291e-04
Loss = 1.1396e-05, PNorm = 47.6440, GNorm = 0.0956, lr_0 = 1.3273e-04
Loss = 1.3683e-05, PNorm = 47.6458, GNorm = 0.0608, lr_0 = 1.3255e-04
Loss = 8.9965e-06, PNorm = 47.6466, GNorm = 0.0591, lr_0 = 1.3238e-04
Loss = 9.5928e-06, PNorm = 47.6468, GNorm = 0.0603, lr_0 = 1.3220e-04
Loss = 1.0432e-05, PNorm = 47.6475, GNorm = 0.0851, lr_0 = 1.3202e-04
Loss = 1.4249e-05, PNorm = 47.6477, GNorm = 0.0457, lr_0 = 1.3184e-04
Loss = 1.3768e-05, PNorm = 47.6484, GNorm = 0.0438, lr_0 = 1.3167e-04
Loss = 1.4178e-05, PNorm = 47.6488, GNorm = 0.0859, lr_0 = 1.3149e-04
Loss = 1.5143e-05, PNorm = 47.6497, GNorm = 0.0568, lr_0 = 1.3131e-04
Loss = 1.5040e-05, PNorm = 47.6509, GNorm = 0.1005, lr_0 = 1.3114e-04
Validation rmse = 0.458065
Validation R2 = 0.940027
Epoch 88
Train function
Loss = 1.3794e-05, PNorm = 47.6514, GNorm = 0.1033, lr_0 = 1.3096e-04
Loss = 9.4523e-06, PNorm = 47.6510, GNorm = 0.0807, lr_0 = 1.3079e-04
Loss = 9.8520e-06, PNorm = 47.6507, GNorm = 0.0513, lr_0 = 1.3061e-04
Loss = 1.2719e-05, PNorm = 47.6516, GNorm = 0.0950, lr_0 = 1.3043e-04
Loss = 1.1010e-05, PNorm = 47.6522, GNorm = 0.0565, lr_0 = 1.3026e-04
Loss = 9.0083e-06, PNorm = 47.6523, GNorm = 0.0879, lr_0 = 1.3009e-04
Loss = 9.5042e-06, PNorm = 47.6524, GNorm = 0.0433, lr_0 = 1.2991e-04
Loss = 8.9795e-06, PNorm = 47.6528, GNorm = 0.0350, lr_0 = 1.2974e-04
Loss = 1.1928e-05, PNorm = 47.6540, GNorm = 0.0653, lr_0 = 1.2956e-04
Loss = 8.6245e-06, PNorm = 47.6551, GNorm = 0.0355, lr_0 = 1.2939e-04
Loss = 1.1890e-05, PNorm = 47.6569, GNorm = 0.0528, lr_0 = 1.2921e-04
Loss = 1.7111e-05, PNorm = 47.6579, GNorm = 0.1307, lr_0 = 1.2904e-04
Loss = 1.3573e-05, PNorm = 47.6595, GNorm = 0.0863, lr_0 = 1.2887e-04
Loss = 1.4849e-05, PNorm = 47.6601, GNorm = 0.1917, lr_0 = 1.2870e-04
Loss = 1.5125e-05, PNorm = 47.6610, GNorm = 0.1857, lr_0 = 1.2852e-04
Loss = 1.7790e-05, PNorm = 47.6619, GNorm = 0.1531, lr_0 = 1.2835e-04
Loss = 1.3154e-05, PNorm = 47.6637, GNorm = 0.0792, lr_0 = 1.2818e-04
Loss = 1.5666e-05, PNorm = 47.6651, GNorm = 0.0701, lr_0 = 1.2801e-04
Validation rmse = 0.456891
Validation R2 = 0.940334
Epoch 89
Train function
Loss = 1.1864e-05, PNorm = 47.6665, GNorm = 0.1220, lr_0 = 1.2782e-04
Loss = 1.3734e-05, PNorm = 47.6663, GNorm = 0.0804, lr_0 = 1.2765e-04
Loss = 1.1279e-05, PNorm = 47.6680, GNorm = 0.0586, lr_0 = 1.2747e-04
Loss = 1.1543e-05, PNorm = 47.6696, GNorm = 0.1120, lr_0 = 1.2730e-04
Loss = 1.2388e-05, PNorm = 47.6703, GNorm = 0.1171, lr_0 = 1.2713e-04
Loss = 1.0685e-05, PNorm = 47.6715, GNorm = 0.0852, lr_0 = 1.2696e-04
Loss = 1.0234e-05, PNorm = 47.6720, GNorm = 0.1264, lr_0 = 1.2679e-04
Loss = 1.1630e-05, PNorm = 47.6726, GNorm = 0.0794, lr_0 = 1.2662e-04
Loss = 1.0730e-05, PNorm = 47.6726, GNorm = 0.1219, lr_0 = 1.2645e-04
Loss = 1.0642e-05, PNorm = 47.6728, GNorm = 0.0385, lr_0 = 1.2628e-04
Loss = 1.0550e-05, PNorm = 47.6732, GNorm = 0.0291, lr_0 = 1.2611e-04
Loss = 1.1319e-05, PNorm = 47.6739, GNorm = 0.0474, lr_0 = 1.2594e-04
Loss = 9.1690e-06, PNorm = 47.6755, GNorm = 0.1691, lr_0 = 1.2577e-04
Loss = 1.2224e-05, PNorm = 47.6759, GNorm = 0.0570, lr_0 = 1.2561e-04
Loss = 1.2892e-05, PNorm = 47.6772, GNorm = 0.0590, lr_0 = 1.2544e-04
Loss = 1.5343e-05, PNorm = 47.6782, GNorm = 0.1379, lr_0 = 1.2527e-04
Loss = 1.1122e-05, PNorm = 47.6790, GNorm = 0.0373, lr_0 = 1.2510e-04
Validation rmse = 0.458267
Validation R2 = 0.939974
Epoch 90
Train function
Loss = 1.5288e-05, PNorm = 47.6811, GNorm = 0.0901, lr_0 = 1.2493e-04
Loss = 1.4777e-05, PNorm = 47.6824, GNorm = 0.0416, lr_0 = 1.2477e-04
Loss = 1.2838e-05, PNorm = 47.6828, GNorm = 0.0662, lr_0 = 1.2460e-04
Loss = 1.1077e-05, PNorm = 47.6836, GNorm = 0.0754, lr_0 = 1.2443e-04
Loss = 9.2201e-06, PNorm = 47.6842, GNorm = 0.0708, lr_0 = 1.2426e-04
Loss = 8.6797e-06, PNorm = 47.6838, GNorm = 0.0511, lr_0 = 1.2410e-04
Loss = 8.5320e-06, PNorm = 47.6854, GNorm = 0.1545, lr_0 = 1.2393e-04
Loss = 8.4866e-06, PNorm = 47.6865, GNorm = 0.0488, lr_0 = 1.2376e-04
Loss = 1.0419e-05, PNorm = 47.6867, GNorm = 0.0796, lr_0 = 1.2360e-04
Loss = 1.3042e-05, PNorm = 47.6881, GNorm = 0.0994, lr_0 = 1.2343e-04
Loss = 1.4518e-05, PNorm = 47.6896, GNorm = 0.0574, lr_0 = 1.2327e-04
Loss = 1.4630e-05, PNorm = 47.6903, GNorm = 0.0835, lr_0 = 1.2310e-04
Loss = 1.6080e-05, PNorm = 47.6913, GNorm = 0.0627, lr_0 = 1.2294e-04
Loss = 1.2522e-05, PNorm = 47.6915, GNorm = 0.0585, lr_0 = 1.2277e-04
Loss = 1.2942e-05, PNorm = 47.6925, GNorm = 0.0575, lr_0 = 1.2261e-04
Loss = 1.3448e-05, PNorm = 47.6929, GNorm = 0.0671, lr_0 = 1.2244e-04
Loss = 1.3221e-05, PNorm = 47.6935, GNorm = 0.0543, lr_0 = 1.2228e-04
Loss = 1.0882e-05, PNorm = 47.6940, GNorm = 0.0451, lr_0 = 1.2211e-04
Validation rmse = 0.456414
Validation R2 = 0.940459
Epoch 91
Train function
Loss = 8.2911e-06, PNorm = 47.6951, GNorm = 0.0432, lr_0 = 1.2195e-04
Loss = 8.3307e-06, PNorm = 47.6952, GNorm = 0.0427, lr_0 = 1.2179e-04
Loss = 7.9381e-06, PNorm = 47.6957, GNorm = 0.0279, lr_0 = 1.2162e-04
Loss = 7.2408e-06, PNorm = 47.6961, GNorm = 0.0800, lr_0 = 1.2146e-04
Loss = 8.7941e-06, PNorm = 47.6967, GNorm = 0.1459, lr_0 = 1.2130e-04
Loss = 1.7474e-05, PNorm = 47.6973, GNorm = 0.2448, lr_0 = 1.2113e-04
Loss = 1.5657e-05, PNorm = 47.6985, GNorm = 0.1816, lr_0 = 1.2097e-04
Loss = 1.2053e-05, PNorm = 47.6992, GNorm = 0.0819, lr_0 = 1.2081e-04
Loss = 1.7277e-05, PNorm = 47.6998, GNorm = 0.1025, lr_0 = 1.2065e-04
Loss = 1.2252e-05, PNorm = 47.7012, GNorm = 0.0729, lr_0 = 1.2048e-04
Loss = 1.0941e-05, PNorm = 47.7025, GNorm = 0.0693, lr_0 = 1.2032e-04
Loss = 1.3833e-05, PNorm = 47.7028, GNorm = 0.0972, lr_0 = 1.2016e-04
Loss = 1.6242e-05, PNorm = 47.7029, GNorm = 0.1155, lr_0 = 1.2000e-04
Loss = 1.2761e-05, PNorm = 47.7046, GNorm = 0.0990, lr_0 = 1.1984e-04
Loss = 1.1097e-05, PNorm = 47.7066, GNorm = 0.1382, lr_0 = 1.1968e-04
Loss = 1.0288e-05, PNorm = 47.7073, GNorm = 0.0490, lr_0 = 1.1952e-04
Loss = 6.9877e-06, PNorm = 47.7084, GNorm = 0.0486, lr_0 = 1.1936e-04
Loss = 8.8958e-06, PNorm = 47.7103, GNorm = 0.0455, lr_0 = 1.1920e-04
Loss = 8.7548e-06, PNorm = 47.7104, GNorm = 0.0967, lr_0 = 1.1918e-04
Validation rmse = 0.456982
Validation R2 = 0.940310
Epoch 92
Train function
Loss = 7.8566e-06, PNorm = 47.7099, GNorm = 0.0506, lr_0 = 1.1902e-04
Loss = 1.1298e-05, PNorm = 47.7101, GNorm = 0.0584, lr_0 = 1.1886e-04
Loss = 1.3635e-05, PNorm = 47.7103, GNorm = 0.0687, lr_0 = 1.1870e-04
Loss = 1.4500e-05, PNorm = 47.7103, GNorm = 0.0924, lr_0 = 1.1854e-04
Loss = 1.5256e-05, PNorm = 47.7122, GNorm = 0.0951, lr_0 = 1.1838e-04
Loss = 9.5089e-06, PNorm = 47.7140, GNorm = 0.0763, lr_0 = 1.1823e-04
Loss = 1.1318e-05, PNorm = 47.7147, GNorm = 0.0723, lr_0 = 1.1807e-04
Loss = 1.1951e-05, PNorm = 47.7144, GNorm = 0.0731, lr_0 = 1.1791e-04
Loss = 9.0561e-06, PNorm = 47.7152, GNorm = 0.0633, lr_0 = 1.1775e-04
Loss = 1.0409e-05, PNorm = 47.7149, GNorm = 0.0700, lr_0 = 1.1759e-04
Loss = 1.1611e-05, PNorm = 47.7158, GNorm = 0.0914, lr_0 = 1.1743e-04
Loss = 1.0116e-05, PNorm = 47.7175, GNorm = 0.0732, lr_0 = 1.1728e-04
Loss = 1.2541e-05, PNorm = 47.7184, GNorm = 0.0790, lr_0 = 1.1712e-04
Loss = 1.0271e-05, PNorm = 47.7200, GNorm = 0.1033, lr_0 = 1.1696e-04
Loss = 7.3002e-06, PNorm = 47.7206, GNorm = 0.0669, lr_0 = 1.1681e-04
Loss = 8.4431e-06, PNorm = 47.7220, GNorm = 0.0772, lr_0 = 1.1665e-04
Loss = 1.3399e-05, PNorm = 47.7220, GNorm = 0.0820, lr_0 = 1.1649e-04
Validation rmse = 0.457178
Validation R2 = 0.940259
Epoch 93
Train function
Loss = 1.0522e-05, PNorm = 47.7225, GNorm = 0.0725, lr_0 = 1.1634e-04
Loss = 7.3781e-06, PNorm = 47.7230, GNorm = 0.0802, lr_0 = 1.1618e-04
Loss = 8.3216e-06, PNorm = 47.7229, GNorm = 0.0450, lr_0 = 1.1602e-04
Loss = 7.8776e-06, PNorm = 47.7230, GNorm = 0.0891, lr_0 = 1.1587e-04
Loss = 8.2089e-06, PNorm = 47.7242, GNorm = 0.0682, lr_0 = 1.1571e-04
Loss = 1.0015e-05, PNorm = 47.7240, GNorm = 0.0795, lr_0 = 1.1556e-04
Loss = 8.2509e-06, PNorm = 47.7250, GNorm = 0.0404, lr_0 = 1.1540e-04
Loss = 8.6481e-06, PNorm = 47.7258, GNorm = 0.0499, lr_0 = 1.1525e-04
Loss = 9.8041e-06, PNorm = 47.7266, GNorm = 0.0650, lr_0 = 1.1509e-04
Loss = 7.6462e-06, PNorm = 47.7273, GNorm = 0.0522, lr_0 = 1.1494e-04
Loss = 8.8582e-06, PNorm = 47.7283, GNorm = 0.1338, lr_0 = 1.1478e-04
Loss = 6.6818e-06, PNorm = 47.7296, GNorm = 0.0482, lr_0 = 1.1463e-04
Loss = 1.0691e-05, PNorm = 47.7311, GNorm = 0.0674, lr_0 = 1.1448e-04
Loss = 9.5793e-06, PNorm = 47.7324, GNorm = 0.1393, lr_0 = 1.1432e-04
Loss = 8.3060e-06, PNorm = 47.7329, GNorm = 0.0612, lr_0 = 1.1417e-04
Loss = 1.1694e-05, PNorm = 47.7328, GNorm = 0.1315, lr_0 = 1.1402e-04
Loss = 1.2636e-05, PNorm = 47.7330, GNorm = 0.1624, lr_0 = 1.1386e-04
Loss = 1.8290e-05, PNorm = 47.7329, GNorm = 0.1900, lr_0 = 1.1371e-04
Validation rmse = 0.459766
Validation R2 = 0.939581
Epoch 94
Train function
Loss = 1.2290e-05, PNorm = 47.7343, GNorm = 0.0657, lr_0 = 1.1356e-04
Loss = 1.2192e-05, PNorm = 47.7351, GNorm = 0.0473, lr_0 = 1.1341e-04
Loss = 1.0187e-05, PNorm = 47.7356, GNorm = 0.0853, lr_0 = 1.1325e-04
Loss = 9.4864e-06, PNorm = 47.7365, GNorm = 0.0529, lr_0 = 1.1310e-04
Loss = 1.0642e-05, PNorm = 47.7369, GNorm = 0.0459, lr_0 = 1.1295e-04
Loss = 8.8294e-06, PNorm = 47.7374, GNorm = 0.0378, lr_0 = 1.1280e-04
Loss = 8.2077e-06, PNorm = 47.7372, GNorm = 0.0528, lr_0 = 1.1265e-04
Loss = 9.4034e-06, PNorm = 47.7371, GNorm = 0.0479, lr_0 = 1.1250e-04
Loss = 9.2617e-06, PNorm = 47.7373, GNorm = 0.0547, lr_0 = 1.1235e-04
Loss = 9.2611e-06, PNorm = 47.7382, GNorm = 0.0256, lr_0 = 1.1219e-04
Loss = 7.6778e-06, PNorm = 47.7394, GNorm = 0.0391, lr_0 = 1.1204e-04
Loss = 1.1281e-05, PNorm = 47.7400, GNorm = 0.0686, lr_0 = 1.1189e-04
Loss = 1.2474e-05, PNorm = 47.7413, GNorm = 0.0949, lr_0 = 1.1174e-04
Loss = 1.2141e-05, PNorm = 47.7421, GNorm = 0.0356, lr_0 = 1.1159e-04
Loss = 1.0409e-05, PNorm = 47.7436, GNorm = 0.0827, lr_0 = 1.1144e-04
Loss = 8.1868e-06, PNorm = 47.7441, GNorm = 0.0652, lr_0 = 1.1129e-04
Loss = 8.3586e-06, PNorm = 47.7450, GNorm = 0.0610, lr_0 = 1.1114e-04
Validation rmse = 0.455881
Validation R2 = 0.940598
Epoch 95
Train function
Loss = 7.5567e-06, PNorm = 47.7455, GNorm = 0.0479, lr_0 = 1.1098e-04
Loss = 1.0148e-05, PNorm = 47.7459, GNorm = 0.0865, lr_0 = 1.1083e-04
Loss = 6.7695e-06, PNorm = 47.7464, GNorm = 0.1274, lr_0 = 1.1068e-04
Loss = 7.0926e-06, PNorm = 47.7470, GNorm = 0.0995, lr_0 = 1.1053e-04
Loss = 8.9946e-06, PNorm = 47.7477, GNorm = 0.0605, lr_0 = 1.1039e-04
Loss = 7.2638e-06, PNorm = 47.7483, GNorm = 0.0458, lr_0 = 1.1024e-04
Loss = 8.1288e-06, PNorm = 47.7494, GNorm = 0.0770, lr_0 = 1.1009e-04
Loss = 7.4319e-06, PNorm = 47.7506, GNorm = 0.0736, lr_0 = 1.0994e-04
Loss = 8.8121e-06, PNorm = 47.7511, GNorm = 0.0705, lr_0 = 1.0980e-04
Loss = 1.0393e-05, PNorm = 47.7514, GNorm = 0.0405, lr_0 = 1.0965e-04
Loss = 1.3799e-05, PNorm = 47.7530, GNorm = 0.0780, lr_0 = 1.0950e-04
Loss = 1.0598e-05, PNorm = 47.7536, GNorm = 0.1648, lr_0 = 1.0935e-04
Loss = 7.5212e-06, PNorm = 47.7544, GNorm = 0.0569, lr_0 = 1.0921e-04
Loss = 7.6830e-06, PNorm = 47.7555, GNorm = 0.0849, lr_0 = 1.0906e-04
Loss = 9.0667e-06, PNorm = 47.7552, GNorm = 0.0508, lr_0 = 1.0891e-04
Loss = 1.0925e-05, PNorm = 47.7560, GNorm = 0.0866, lr_0 = 1.0877e-04
Loss = 1.0503e-05, PNorm = 47.7573, GNorm = 0.0638, lr_0 = 1.0862e-04
Loss = 7.5032e-06, PNorm = 47.7583, GNorm = 0.0594, lr_0 = 1.0848e-04
Validation rmse = 0.457430
Validation R2 = 0.940193
Epoch 96
Train function
Loss = 6.8030e-06, PNorm = 47.7588, GNorm = 0.0423, lr_0 = 1.0833e-04
Loss = 7.7461e-06, PNorm = 47.7596, GNorm = 0.0610, lr_0 = 1.0819e-04
Loss = 6.4687e-06, PNorm = 47.7600, GNorm = 0.0382, lr_0 = 1.0804e-04
Loss = 6.0828e-06, PNorm = 47.7603, GNorm = 0.0432, lr_0 = 1.0790e-04
Loss = 6.7303e-06, PNorm = 47.7608, GNorm = 0.0402, lr_0 = 1.0775e-04
Loss = 7.8253e-06, PNorm = 47.7610, GNorm = 0.0563, lr_0 = 1.0761e-04
Loss = 7.3102e-06, PNorm = 47.7610, GNorm = 0.0944, lr_0 = 1.0746e-04
Loss = 9.6686e-06, PNorm = 47.7613, GNorm = 0.0856, lr_0 = 1.0732e-04
Loss = 1.1360e-05, PNorm = 47.7624, GNorm = 0.0396, lr_0 = 1.0717e-04
Loss = 7.4453e-06, PNorm = 47.7635, GNorm = 0.0734, lr_0 = 1.0703e-04
Loss = 7.9881e-06, PNorm = 47.7645, GNorm = 0.0559, lr_0 = 1.0689e-04
Loss = 6.9036e-06, PNorm = 47.7655, GNorm = 0.0859, lr_0 = 1.0674e-04
Loss = 1.0573e-05, PNorm = 47.7666, GNorm = 0.1216, lr_0 = 1.0660e-04
Loss = 1.3106e-05, PNorm = 47.7681, GNorm = 0.1286, lr_0 = 1.0646e-04
Loss = 1.1666e-05, PNorm = 47.7673, GNorm = 0.0620, lr_0 = 1.0631e-04
Loss = 1.0063e-05, PNorm = 47.7679, GNorm = 0.1238, lr_0 = 1.0617e-04
Loss = 1.0468e-05, PNorm = 47.7683, GNorm = 0.1088, lr_0 = 1.0603e-04
Validation rmse = 0.456734
Validation R2 = 0.940375
Epoch 97
Train function
Loss = 9.5510e-06, PNorm = 47.7690, GNorm = 0.1110, lr_0 = 1.0589e-04
Loss = 7.0425e-06, PNorm = 47.7692, GNorm = 0.0343, lr_0 = 1.0574e-04
Loss = 6.6525e-06, PNorm = 47.7694, GNorm = 0.0607, lr_0 = 1.0560e-04
Loss = 6.4779e-06, PNorm = 47.7707, GNorm = 0.0359, lr_0 = 1.0546e-04
Loss = 8.5961e-06, PNorm = 47.7712, GNorm = 0.0410, lr_0 = 1.0532e-04
Loss = 7.1174e-06, PNorm = 47.7714, GNorm = 0.0477, lr_0 = 1.0518e-04
Loss = 7.7729e-06, PNorm = 47.7723, GNorm = 0.1034, lr_0 = 1.0504e-04
Loss = 5.6912e-06, PNorm = 47.7729, GNorm = 0.0427, lr_0 = 1.0490e-04
Loss = 5.4818e-06, PNorm = 47.7727, GNorm = 0.0550, lr_0 = 1.0476e-04
Loss = 9.9744e-06, PNorm = 47.7740, GNorm = 0.0530, lr_0 = 1.0461e-04
Loss = 7.1851e-06, PNorm = 47.7747, GNorm = 0.1349, lr_0 = 1.0447e-04
Loss = 1.3211e-05, PNorm = 47.7749, GNorm = 0.1602, lr_0 = 1.0433e-04
Loss = 1.2357e-05, PNorm = 47.7748, GNorm = 0.0409, lr_0 = 1.0419e-04
Loss = 8.0690e-06, PNorm = 47.7753, GNorm = 0.0848, lr_0 = 1.0405e-04
Loss = 8.7737e-06, PNorm = 47.7765, GNorm = 0.0533, lr_0 = 1.0391e-04
Loss = 7.8583e-06, PNorm = 47.7770, GNorm = 0.0384, lr_0 = 1.0378e-04
Loss = 1.1637e-05, PNorm = 47.7777, GNorm = 0.1028, lr_0 = 1.0364e-04
Loss = 1.1956e-05, PNorm = 47.7792, GNorm = 0.1706, lr_0 = 1.0350e-04
Validation rmse = 0.458609
Validation R2 = 0.939884
Epoch 98
Train function
Loss = 9.5699e-06, PNorm = 47.7804, GNorm = 0.0543, lr_0 = 1.0334e-04
Loss = 7.8874e-06, PNorm = 47.7802, GNorm = 0.0550, lr_0 = 1.0321e-04
Loss = 8.2956e-06, PNorm = 47.7809, GNorm = 0.0393, lr_0 = 1.0307e-04
Loss = 7.1364e-06, PNorm = 47.7815, GNorm = 0.0351, lr_0 = 1.0293e-04
Loss = 6.4936e-06, PNorm = 47.7812, GNorm = 0.0384, lr_0 = 1.0279e-04
Loss = 1.0022e-05, PNorm = 47.7826, GNorm = 0.0438, lr_0 = 1.0265e-04
Loss = 5.3953e-06, PNorm = 47.7828, GNorm = 0.0678, lr_0 = 1.0251e-04
Loss = 8.8481e-06, PNorm = 47.7828, GNorm = 0.0432, lr_0 = 1.0238e-04
Loss = 6.8721e-06, PNorm = 47.7834, GNorm = 0.0629, lr_0 = 1.0224e-04
Loss = 9.2434e-06, PNorm = 47.7838, GNorm = 0.0872, lr_0 = 1.0210e-04
Loss = 7.0875e-06, PNorm = 47.7845, GNorm = 0.0374, lr_0 = 1.0197e-04
Loss = 5.7630e-06, PNorm = 47.7849, GNorm = 0.0394, lr_0 = 1.0183e-04
Loss = 1.3061e-05, PNorm = 47.7848, GNorm = 0.0807, lr_0 = 1.0169e-04
Loss = 8.1976e-06, PNorm = 47.7854, GNorm = 0.0737, lr_0 = 1.0156e-04
Loss = 1.0711e-05, PNorm = 47.7863, GNorm = 0.1389, lr_0 = 1.0142e-04
Loss = 6.3753e-06, PNorm = 47.7875, GNorm = 0.0428, lr_0 = 1.0128e-04
Loss = 7.8263e-06, PNorm = 47.7885, GNorm = 0.1226, lr_0 = 1.0115e-04
Loss = 8.0143e-06, PNorm = 47.7891, GNorm = 0.0595, lr_0 = 1.0101e-04
Validation rmse = 0.457117
Validation R2 = 0.940275
Epoch 99
Train function
Loss = 6.9198e-06, PNorm = 47.7896, GNorm = 0.0995, lr_0 = 1.0088e-04
Loss = 5.8401e-06, PNorm = 47.7899, GNorm = 0.0391, lr_0 = 1.0074e-04
Loss = 9.3550e-06, PNorm = 47.7902, GNorm = 0.1106, lr_0 = 1.0061e-04
Loss = 7.8058e-06, PNorm = 47.7903, GNorm = 0.0357, lr_0 = 1.0047e-04
Loss = 6.0655e-06, PNorm = 47.7907, GNorm = 0.0506, lr_0 = 1.0034e-04
Loss = 7.5462e-06, PNorm = 47.7914, GNorm = 0.0552, lr_0 = 1.0020e-04
Loss = 1.2390e-05, PNorm = 47.7922, GNorm = 0.1088, lr_0 = 1.0007e-04
Loss = 1.1064e-05, PNorm = 47.7933, GNorm = 0.0990, lr_0 = 1.0000e-04
Loss = 8.3645e-06, PNorm = 47.7945, GNorm = 0.0462, lr_0 = 1.0000e-04
Loss = 7.7921e-06, PNorm = 47.7947, GNorm = 0.0855, lr_0 = 1.0000e-04
Loss = 6.9280e-06, PNorm = 47.7948, GNorm = 0.0392, lr_0 = 1.0000e-04
Loss = 7.7161e-06, PNorm = 47.7959, GNorm = 0.1247, lr_0 = 1.0000e-04
Loss = 6.5334e-06, PNorm = 47.7960, GNorm = 0.0538, lr_0 = 1.0000e-04
Loss = 6.1700e-06, PNorm = 47.7963, GNorm = 0.0472, lr_0 = 1.0000e-04
Loss = 6.0343e-06, PNorm = 47.7975, GNorm = 0.0321, lr_0 = 1.0000e-04
Loss = 6.4764e-06, PNorm = 47.7982, GNorm = 0.0568, lr_0 = 1.0000e-04
Loss = 7.9382e-06, PNorm = 47.7981, GNorm = 0.0467, lr_0 = 1.0000e-04
Validation rmse = 0.458293
Validation R2 = 0.939967
Model 0 best validation rmse = 0.453487 on epoch 29
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.467688
Model 0 test R2 = 0.935047
Ensemble test rmse = 0.467688
Ensemble test R2 = 0.935047
Fold 3
Command line
python train.py --data_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv --dataset_type regression --save_dir ../../../data/raw/baselines/dmpnn/logs/exp_201 --separate_test_path ../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv --epochs 100 --depth 6 --features_generator rdkit_2d_normalized --no_features_scaling --split_type k-fold --num_folds 4 --num_workers 0
Args
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_train_val.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 200,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': '../../../data/raw/baselines/dmpnn/logs/exp_201/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': '../../../data/raw/baselines/dmpnn/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': None,
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'symmetry_feature': False,
 'target_columns': None,
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 8783,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 3
Total size = 11,710 | train size = 8,783 | val size = 2,927 | test size = 2,067
Fitting scaler
[[-1.01], [2.13], [4.67], [1.85], [1.35], [3.45], [-0.6], [0.34], [5.23], [4.91], [1.29], [-1.22], [5.8], [4.04], [-0.24], [3.18], [1.89], [0.66], [3.42], [3.0], [0.9], [0.08], [2.61], [2.65], [2.17], [0.31], [0.42], [3.25], [-0.51], [2.55], [-0.21], [3.93], [3.61], [3.05], [3.2], [-0.07], [3.18], [1.85], [5.05], [4.66], [0.29], [0.57], [5.04], [2.22], [1.38], [5.16], [2.88], [1.13], [1.48], [2.75], [3.07], [0.61], [0.68], [4.93], [1.3], [0.73], [1.73], [-1.95], [4.37], [2.8], [3.76], [2.83], [0.63], [2.63], [2.25], [1.54], [3.08], [1.41], [1.45], [1.36], [4.0], [-0.22], [0.06], [0.93], [2.42], [2.47], [0.56], [3.47], [0.48], [1.92], [6.23], [1.46], [-0.1], [0.8], [0.84], [1.91], [3.03], [0.36], [0.72], [4.43], [0.16], [-0.85], [1.67], [2.91], [2.12], [1.03], [-2.41], [3.85], [6.39], [4.75], [2.4], [-0.47], [2.16], [1.89], [-2.96], [3.03], [2.92], [2.49], [2.41], [2.14], [2.72], [1.33], [-0.38], [2.99], [2.28], [2.8], [3.15], [3.78], [4.3], [1.7], [0.63], [1.5], [1.8], [0.79], [1.41], [2.27], [2.78], [2.64], [1.65], [1.51], [2.57], [4.78], [2.02], [6.61], [0.98], [2.4], [4.36], [2.58], [0.23], [1.42], [1.24], [3.05], [1.31], [1.94], [6.66], [1.84], [3.43], [0.29], [2.83], [1.56], [2.16], [0.82], [4.0], [-1.62], [3.18], [3.2], [-0.15], [-0.15], [1.83], [3.8], [3.86], [1.16], [2.32], [3.11], [1.74], [1.8], [5.04], [0.49], [0.61], [0.7], [4.31], [2.7], [2.65], [2.67], [0.54], [1.03], [0.52], [3.26], [-1.56], [0.06], [2.65], [5.31], [2.14], [4.89], [2.91], [1.21], [4.77], [2.33], [3.1], [5.59], [1.02], [0.74], [1.71], [1.96], [1.83], [-0.14], [-1.04], [-0.85], [0.8], [2.71], [2.4], [0.62], [1.09], [3.65], [3.4], [5.15], [1.28], [-0.78], [2.72], [2.33], [1.6], [1.54], [1.92], [1.57], [-0.35], [-0.1], [5.22], [5.74], [1.68], [5.07], [0.5], [0.08], [-0.27], [3.3], [1.02], [-1.22], [-1.37], [-0.74], [4.2], [2.67], [1.84], [-0.4], [-0.18], [2.47], [1.58], [0.65], [7.44], [2.12], [1.9], [1.53], [0.0], [1.56], [2.11], [2.31], [1.32], [4.34], [-0.29], [0.6], [2.32], [1.42], [0.34], [0.08], [2.26], [1.97], [2.31], [2.63], [0.42], [0.98], [3.74], [2.34], [3.12], [5.93], [-1.57], [0.57], [3.94], [4.44], [2.1], [5.0], [2.92], [0.66], [3.39], [-0.96], [4.12], [1.91], [0.29], [2.82], [2.16], [3.96], [1.46], [0.31], [-0.47], [4.66], [0.64], [1.9], [1.43], [2.01], [0.05], [1.92], [-0.34], [2.31], [2.27], [2.4], [2.1], [2.59], [0.56], [4.26], [2.39], [5.9], [-0.44], [3.82], [0.49], [1.2], [4.26], [1.3], [2.65], [3.51], [-1.73], [2.98], [4.18], [3.2], [3.91], [0.21], [0.23], [5.31], [0.01], [4.15], [2.52], [2.31], [0.38], [1.95], [-0.59], [3.42], [2.16], [0.47], [0.2], [1.81], [5.64], [4.22], [0.98], [1.0], [1.71], [3.72], [0.75], [-0.59], [2.55], [1.58], [2.04], [2.54], [2.74], [2.11], [0.37], [2.27], [0.54], [0.81], [1.02], [3.55], [1.85], [3.56], [-0.11], [0.49], [3.34], [2.04], [2.78], [2.04], [1.79], [3.17], [3.14], [4.1], [1.55], [-0.51], [2.11], [1.02], [2.13], [0.59], [4.44], [1.65], [1.59], [1.68], [1.24], [1.52], [0.32], [1.16], [2.82], [2.16], [0.39], [0.86], [0.77], [-1.05], [0.45], [2.85], [4.48], [1.98], [1.32], [2.18], [0.72], [1.62], [2.35], [6.01], [-0.78], [-0.09], [-0.45], [1.41], [5.8], [3.3], [0.52], [1.76], [1.8], [2.17], [1.4], [-0.86], [2.54], [3.19], [0.92], [4.07], [1.38], [2.48], [1.27], [1.78], [1.83], [0.53], [4.06], [-0.19], [2.5], [1.76], [2.66], [4.93], [-0.98], [2.6], [1.23], [2.73], [3.2], [3.82], [2.22], [7.41], [1.31], [3.21], [1.95], [0.87], [0.86], [2.07], [2.42], [1.38], [3.24], [2.79], [1.41], [-0.26], [1.82], [3.18], [0.97], [1.87], [0.54], [3.16], [2.44], [-0.7], [0.9], [4.55], [1.8], [3.1], [4.09], [0.7], [3.66], [1.53], [3.65], [1.1], [2.69], [1.03], [1.92], [3.07], [3.5], [1.65], [3.52], [0.93], [1.24], [2.83], [2.0], [3.2], [-1.97], [1.49], [2.33], [0.03], [2.47], [1.49], [1.49], [-0.7], [2.91], [1.51], [1.49], [1.0], [0.5], [5.26], [2.28], [3.15], [2.04], [3.42], [2.71], [0.56], [2.96], [4.65], [4.67], [2.86], [0.87], [1.59], [1.52], [-1.14], [2.58], [2.84], [2.31], [0.25], [2.04], [2.09], [1.82], [3.53], [2.29], [1.78], [0.25], [1.26], [0.9], [2.99], [3.39], [6.34], [2.71], [4.47], [0.49], [-0.05], [3.57], [1.0], [1.47], [0.56], [2.23], [0.28], [0.46], [1.66], [2.42], [-0.48], [0.66], [4.61], [3.0], [5.51], [1.2], [0.13], [3.38], [0.86], [-0.61], [1.06], [-0.62], [2.18], [-1.45], [3.35], [3.43], [0.71], [3.36], [2.28], [4.92], [2.28], [3.07], [0.46], [0.61], [2.06], [4.41], [0.83], [1.81], [1.86], [-0.58], [3.08], [2.45], [6.82], [-0.6], [2.25], [2.78], [3.32], [5.2], [0.73], [4.38], [1.38], [1.18], [2.5], [3.7], [0.99], [4.34], [4.63], [1.43], [4.65], [0.35], [1.57], [2.96], [3.95], [2.95], [2.28], [2.55], [2.47], [3.46], [2.36], [0.15], [2.75], [2.79], [4.76], [1.63], [2.31], [3.46], [2.05], [0.84], [2.45], [1.9], [2.95], [1.41], [3.33], [2.25], [2.99], [1.11], [3.09], [2.98], [1.35], [2.37], [5.29], [0.88], [2.21], [1.78], [-0.06], [2.01], [0.59], [2.54], [0.49], [2.79], [1.02], [2.22], [4.3], [0.82], [4.98], [0.95], [5.7], [1.82], [1.69], [3.51], [0.7], [1.64], [4.56], [2.71], [1.17], [2.19], [2.73], [0.22], [3.87], [2.22], [2.74], [4.78], [0.78], [3.41], [3.52], [2.17], [3.38], [3.87], [2.29], [-0.25], [-0.77], [1.27], [-0.26], [2.05], [2.03], [2.08], [1.4], [4.28], [3.83], [7.25], [1.34], [1.83], [2.27], [4.58], [4.3], [0.62], [2.01], [1.14], [2.33], [0.04], [6.65], [3.57], [5.56], [1.51], [-2.49], [-1.99], [-0.04], [2.6], [4.52], [-1.49], [2.74], [1.44], [1.03], [-1.12], [0.23], [4.0], [2.06], [-0.77], [1.44], [3.73], [1.1], [0.26], [1.76], [1.79], [1.01], [1.54], [-0.3], [4.6], [2.44], [3.21], [-1.1], [2.78], [1.09], [2.78], [1.0], [2.7], [1.24], [0.58], [1.74], [1.91], [-1.32], [-0.92], [4.11], [3.45], [-0.6], [0.52], [4.88], [2.63], [-0.53], [3.96], [4.16], [4.22], [3.14], [1.4], [0.65], [-1.18], [1.65], [1.98], [0.82], [0.45], [1.97], [2.17], [2.72], [3.36], [1.81], [4.94], [1.38], [-1.6], [2.87], [6.11], [2.67], [0.95], [4.04], [1.0], [2.04], [1.15], [6.05], [-0.6], [2.23], [2.25], [2.57], [1.28], [3.3], [0.95], [0.16], [-0.44], [2.75], [1.58], [0.52], [2.43], [1.29], [-0.21], [3.1], [3.79], [-1.87], [2.64], [2.05], [3.93], [4.06], [4.9], [6.3], [3.1], [2.29], [-1.43], [0.29], [0.35], [0.85], [2.69], [1.21], [1.28], [4.51], [3.3], [4.2], [1.5], [-1.84], [0.43], [2.57], [-0.57], [3.11], [-0.74], [2.2], [6.22], [2.47], [1.68], [0.02], [0.91], [2.15], [7.12], [2.47], [-0.09], [4.8], [0.9], [2.85], [-0.37], [0.12], [-1.7], [2.65], [1.34], [4.01], [7.5], [1.92], [1.29], [3.03], [4.09], [-0.64], [9.16], [0.6], [1.84], [2.46], [-1.3], [2.19], [-2.63], [0.73], [2.71], [3.61], [2.48], [0.06], [-0.77], [1.8], [-0.27], [-0.04], [2.23], [7.45], [2.39], [-0.29], [1.15], [0.3], [1.07], [1.37], [2.73], [2.86], [1.29], [2.26], [4.62], [5.76], [0.28], [2.18], [1.96], [1.89], [-1.64], [2.3], [1.87], [1.37], [3.79], [-1.46], [1.48], [0.09], [1.21], [-0.04], [2.97], [-0.01], [3.28], [1.13], [4.82], [6.53], [5.2], [1.47], [3.91], [1.37], [2.56], [2.42], [1.24], [2.66], [2.72], [0.63], [2.35], [1.41], [2.42], [4.55], [0.79], [-0.25], [-0.66], [3.23], [3.36], [0.35], [3.13], [3.8], [1.52], [2.03], [2.83], [1.0], [2.88], [6.63], [3.62], [5.92], [0.39], [0.76], [4.45], [3.31], [2.19], [1.58], [1.65], [2.09], [1.86], [1.46], [3.37], [2.78], [4.24], [1.16], [4.16], [3.11], [3.23], [3.84], [2.56], [3.1], [3.91], [1.38], [-0.6], [2.48], [0.63], [2.82], [3.61], [2.01], [-0.21], [-0.3], [3.73], [2.1], [2.03], [1.88], [2.99], [1.94], [0.06], [1.09], [3.12], [-2.52], [1.74], [1.85], [4.2], [3.5], [2.47], [-0.58], [3.57], [2.86], [2.03], [-0.59], [2.06], [6.04], [4.51], [2.19], [2.65], [4.43], [0.12], [1.73], [1.86], [3.37], [-0.76], [1.35], [2.94], [1.48], [2.66], [2.21], [4.49], [2.91], [-1.16], [2.3], [2.09], [1.18], [-1.68], [7.18], [1.6], [1.22], [0.7], [5.98], [2.5], [4.66], [-2.1], [2.5], [3.92], [1.41], [3.06], [3.63], [5.13], [6.27], [-2.0], [3.52], [2.42], [3.12], [2.09], [3.75], [0.29], [2.72], [2.19], [1.18], [0.45], [-0.26], [0.38], [9.16], [3.11], [1.12], [-0.97], [1.2], [3.41], [1.82], [2.23], [1.69], [3.44], [3.28], [2.45], [4.21], [4.21], [4.99], [2.32], [2.28], [2.06], [-0.09], [2.34], [-0.11], [-0.05], [1.82], [2.12], [2.58], [-0.89], [6.14], [1.77], [-1.01], [2.24], [3.49], [-2.27], [1.03], [1.83], [2.26], [0.94], [8.61], [4.92], [2.14], [0.88], [2.95], [3.41], [1.67], [0.87], [1.98], [0.72], [2.37], [1.25], [0.64], [0.52], [-2.2], [-1.15], [1.86], [2.77], [2.2], [2.7], [0.08], [3.21], [1.2], [2.65], [-0.49], [2.34], [2.85], [-3.32], [2.83], [4.31], [4.14], [1.76], [2.36], [-1.8], [-1.76], [5.06], [0.55], [-0.98], [1.63], [2.05], [2.0], [2.44], [0.59], [2.7], [-0.24], [0.35], [2.08], [0.07], [2.75], [0.62], [2.62], [2.42], [4.46], [1.78], [4.03], [1.64], [1.63], [1.94], [3.91], [0.77], [0.11], [0.79], [0.86], [-0.16], [1.16], [4.45], [1.53], [3.05], [1.07], [0.97], [5.7], [-2.28], [1.12], [1.53], [-2.55], [0.95], [1.91], [-0.82], [0.19], [5.33], [-0.54], [3.46], [3.62], [2.56], [2.44], [2.63], [2.99], [2.77], [1.09], [-0.18], [2.26], [4.73], [0.3], [-1.39], [5.11], [2.54], [5.7], [3.52], [-1.82], [2.4], [-0.2], [0.16], [1.85], [2.25], [2.71], [0.3], [2.52], [2.64], [-0.22], [2.12], [0.04], [0.39], [3.55], [0.36], [1.5], [3.17], [2.11], [2.83], [2.36], [2.76], [-0.32], [1.73], [1.34], [3.36], [1.39], [1.76], [1.79], [3.87], [2.97], [0.42], [-1.33], [1.48], [1.88], [0.31], [5.14], [-0.67], [2.18], [0.08], [1.21], [2.08], [2.7], [3.7], [3.46], [-0.72], [5.44], [2.21], [3.15], [5.44], [-0.15], [3.33], [2.17], [0.79], [3.64], [2.16], [2.76], [3.71], [1.99], [3.9], [2.25], [4.04], [2.09], [3.28], [1.37], [3.2], [3.24], [3.27], [2.33], [4.44], [1.98], [2.3], [1.23], [2.17], [0.61], [1.55], [-0.01], [3.0], [1.41], [1.79], [3.9], [2.63], [1.7], [1.6], [1.1], [1.72], [5.54], [1.77], [2.07], [2.32], [2.66], [1.6], [1.0], [3.88], [1.55], [5.05], [-1.14], [-0.13], [2.0], [5.73], [1.31], [1.98], [0.64], [-0.99], [2.48], [3.86], [3.52], [3.92], [3.65], [3.8], [-0.26], [3.26], [-1.6], [1.22], [1.61], [4.2], [5.19], [0.25], [3.17], [2.13], [2.35], [1.87], [0.93], [2.07], [4.08], [-1.41], [4.47], [1.22], [4.62], [1.57], [2.42], [0.18], [2.59], [3.16], [0.8], [2.43], [2.59], [1.41], [-0.1], [8.71], [-1.03], [1.56], [1.2], [2.55], [1.59], [2.57], [-0.17], [4.38], [3.16], [3.18], [-0.77], [1.39], [1.58], [-2.2], [-0.25], [4.04], [3.82], [4.07], [0.16], [1.08], [4.11], [0.13], [2.28], [4.63], [0.61], [0.91], [2.79], [1.22], [3.13], [1.82], [5.8], [0.36], [-0.62], [1.34], [-0.74], [1.11], [1.33], [0.21], [2.92], [0.59], [1.68], [2.4], [0.47], [0.74], [1.21], [1.61], [1.63], [0.64], [2.15], [-0.17], [1.39], [4.62], [-0.28], [1.66], [0.53], [1.31], [-0.94], [1.84], [1.48], [2.93], [3.51], [1.0], [1.0], [-2.39], [1.57], [1.73], [-3.1], [4.22], [4.12], [3.23], [1.83], [5.56], [1.83], [0.87], [2.1], [-0.38], [-1.68], [2.3], [1.6], [1.86], [1.3], [5.41], [2.59], [2.8], [3.45], [-1.08], [0.47], [2.82], [3.09], [1.76], [0.91], [2.82], [1.63], [-1.36], [2.41], [1.98], [0.48], [3.99], [1.59], [0.1], [6.07], [2.58], [2.56], [0.55], [-0.57], [7.53], [-0.7], [2.99], [3.43], [1.92], [3.75], [1.2], [-2.51], [3.57], [1.54], [1.13], [0.64], [1.75], [1.39], [-0.31], [0.63], [4.21], [0.14], [3.2], [-0.71], [4.42], [1.72], [2.95], [2.86], [5.77], [3.91], [-1.56], [0.4], [2.0], [0.35], [7.64], [5.17], [4.23], [4.61], [2.13], [3.15], [4.01], [0.49], [0.95], [2.06], [3.51], [4.02], [6.51], [0.7], [5.31], [2.78], [0.75], [-0.37], [2.14], [0.21], [1.78], [0.25], [2.26], [3.21], [6.46], [-1.69], [2.73], [1.0], [2.3], [2.72], [2.72], [2.83], [-0.4], [3.56], [2.07], [-0.26], [0.71], [2.22], [3.2], [0.54], [0.19], [-2.96], [0.83], [0.54], [2.3], [3.1], [1.88], [-0.02], [2.8], [2.44], [3.31], [1.91], [4.62], [-0.7], [2.4], [2.51], [2.53], [0.89], [3.05], [2.61], [1.18], [0.41], [-0.1], [3.85], [2.28], [0.38], [1.65], [7.25], [2.47], [2.63], [6.82], [1.62], [1.36], [2.52], [3.0], [3.66], [0.63], [9.25], [3.1], [2.46], [2.59], [0.04], [1.1], [1.04], [0.01], [-0.38], [3.55], [0.74], [1.78], [4.05], [3.9], [3.78], [2.29], [2.01], [2.14], [2.2], [0.0], [2.62], [2.3], [2.88], [2.95], [2.5], [-0.62], [1.48], [1.53], [3.78], [1.83], [4.1], [3.9], [1.29], [3.15], [4.04], [0.05], [2.23], [3.62], [3.46], [2.74], [-0.21], [0.83], [0.97], [3.33], [3.75], [2.53], [1.23], [-1.34], [2.05], [6.37], [1.25], [1.24], [-0.19], [4.4], [2.12], [0.49], [4.25], [4.23], [1.3], [4.45], [0.06], [1.65], [3.83], [2.62], [1.38], [0.08], [1.25], [1.21], [1.76], [1.92], [0.68], [2.1], [2.01], [2.66], [1.48], [0.77], [3.63], [4.92], [1.77], [3.91], [2.02], [0.24], [2.36], [0.95], [0.12], [3.0], [1.88], [2.19], [3.6], [3.14], [4.49], [-1.28], [0.57], [-0.79], [4.59], [3.08], [1.54], [-2.0], [1.04], [-2.19], [-0.5], [-1.66], [3.73], [3.44], [3.6], [-0.32], [2.38], [3.85], [2.64], [1.66], [2.2], [6.58], [1.95], [2.48], [1.62], [3.38], [1.48], [4.16], [0.14], [2.31], [2.54], [1.52], [1.26], [4.2], [2.06], [2.04], [0.95], [2.93], [2.09], [5.79], [-2.56], [3.21], [-0.1], [3.62], [1.08], [3.53], [5.03], [3.76], [1.65], [1.76], [3.48], [5.3], [-1.06], [3.9], [4.56], [1.62], [-0.1], [1.43], [4.6], [1.12], [1.13], [5.48], [2.8], [0.28], [3.5], [0.04], [2.39], [1.09], [-0.08], [1.34], [3.5], [1.58], [-1.53], [0.75], [7.45], [3.1], [5.02], [1.79], [-0.2], [2.73], [2.58], [-0.59], [3.79], [3.71], [-0.7], [3.83], [-0.86], [0.2], [1.04], [3.36], [1.12], [0.51], [0.33], [2.71], [-2.33], [1.52], [2.62], [1.54], [2.47], [1.33], [0.51], [0.71], [2.73], [2.17], [3.02], [1.83], [2.35], [4.83], [1.25], [1.39], [1.24], [0.82], [0.88], [2.55], [1.76], [1.53], [3.33], [-0.39], [3.3], [4.35], [2.48], [3.24], [4.92], [3.77], [3.46], [2.75], [0.51], [2.61], [5.46], [5.87], [-2.1], [1.44], [1.28], [1.63], [5.29], [2.65], [1.45], [2.19], [2.87], [2.82], [1.06], [2.68], [3.56], [-0.1], [1.2], [0.56], [3.69], [0.42], [1.47], [3.82], [2.54], [2.16], [4.1], [3.5], [0.47], [2.63], [1.87], [0.47], [0.95], [2.27], [3.4], [2.03], [-2.84], [2.7], [1.55], [0.26], [0.12], [0.76], [6.29], [2.38], [2.58], [3.16], [0.26], [1.28], [5.08], [1.1], [1.69], [3.38], [2.83], [1.3], [0.3], [1.07], [2.21], [-0.03], [2.09], [0.78], [0.81], [2.24], [2.61], [2.9], [0.99], [0.89], [1.71], [-0.47], [1.82], [1.67], [2.1], [-1.5], [-0.44], [-0.66], [2.5], [2.9], [1.07], [2.83], [3.28], [1.25], [5.45], [3.73], [2.19], [-0.11], [2.87], [1.29], [3.02], [0.5], [1.5], [2.6], [-0.15], [1.11], [-0.75], [2.08], [1.25], [1.35], [-0.47], [4.38], [0.62], [1.4], [1.4], [5.14], [3.65], [1.11], [1.84], [1.47], [3.16], [2.24], [7.73], [4.29], [-0.12], [1.65], [0.69], [1.66], [0.85], [3.69], [2.33], [1.46], [3.27], [2.18], [1.02], [3.24], [5.2], [2.4], [3.08], [2.95], [1.4], [0.26], [2.14], [1.79], [0.92], [-0.73], [-1.57], [2.84], [3.65], [-0.5], [3.61], [2.99], [0.48], [1.63], [0.51], [1.14], [1.19], [2.9], [4.33], [2.01], [1.8], [0.3], [2.64], [2.61], [2.08], [0.66], [0.41], [3.16], [1.32], [3.3], [0.16], [2.85], [5.33], [0.32], [3.44], [2.96], [0.65], [-0.29], [1.39], [2.86], [0.2], [1.4], [7.1], [3.61], [4.43], [-0.35], [4.97], [0.52], [0.83], [2.32], [1.74], [0.89], [1.88], [0.97], [-1.01], [0.91], [7.17], [1.35], [1.72], [6.58], [0.93], [2.23], [4.42], [3.7], [2.33], [0.87], [3.06], [2.4], [3.2], [2.92], [1.82], [1.3], [1.89], [2.98], [3.85], [3.52], [5.2], [1.51], [2.4], [5.55], [1.98], [0.11], [2.3], [3.41], [1.17], [1.7], [0.83], [3.44], [2.63], [3.55], [-0.94], [1.24], [1.72], [4.27], [0.83], [0.79], [2.22], [1.08], [-0.57], [4.61], [2.8], [2.04], [1.56], [2.25], [1.18], [1.36], [3.09], [0.84], [-1.85], [-1.09], [-0.17], [1.96], [0.24], [1.63], [0.89], [0.04], [-0.57], [0.3], [3.15], [1.1], [1.46], [2.54], [-1.96], [4.09], [1.57], [4.37], [0.62], [0.47], [2.49], [4.58], [3.5], [2.1], [1.8], [2.29], [2.23], [4.02], [2.68], [3.19], [0.63], [1.76], [2.58], [6.51], [3.66], [0.26], [0.96], [2.46], [1.05], [3.78], [1.55], [-1.01], [2.15], [2.74], [-1.29], [-1.55], [1.64], [1.95], [-0.46], [3.6], [-0.32], [1.17], [-0.01], [0.75], [1.02], [-0.63], [1.11], [2.57], [2.01], [0.31], [6.98], [2.6], [3.12], [1.58], [2.89], [2.47], [1.61], [-1.64], [1.4], [1.34], [2.9], [0.76], [2.62], [0.82], [-0.32], [2.92], [0.33], [0.36], [2.67], [4.2], [3.29], [3.38], [0.07], [3.2], [1.87], [-0.8], [6.13], [-2.09], [3.82], [-0.01], [-0.06], [1.92], [2.45], [2.12], [0.07], [5.75], [1.29], [1.46], [1.96], [2.99], [5.06], [2.34], [0.4], [3.96], [4.3], [2.32], [1.89], [0.4], [4.9], [2.61], [0.95], [1.63], [6.06], [0.98], [1.09], [4.58], [3.61], [3.61], [3.61], [1.93], [0.82], [1.18], [2.84], [1.03], [3.08], [0.92], [1.32], [0.72], [6.23], [2.22], [3.91], [0.3], [0.83], [0.84], [-1.94], [-1.48], [1.43], [1.74], [2.65], [1.13], [4.72], [2.7], [0.22], [1.68], [3.74], [3.9], [-0.17], [4.78], [2.07], [1.6], [-0.19], [-1.7], [0.66], [4.62], [3.13], [1.38], [2.3], [3.36], [5.71], [0.01], [1.9], [1.94], [2.39], [-0.02], [4.27], [1.77], [2.15], [-0.54], [3.57], [1.7], [-0.28], [1.22], [1.63], [-1.3], [1.35], [2.41], [1.3], [2.89], [1.04], [2.24], [-2.65], [2.82], [2.0], [2.86], [3.34], [3.6], [-1.95], [0.84], [5.45], [3.1], [-2.07], [3.27], [3.94], [1.27], [2.96], [1.73], [3.48], [2.98], [1.45], [2.34], [2.35], [1.82], [-1.07], [-1.33], [1.29], [0.85], [-1.4], [2.75], [3.3], [2.65], [3.66], [1.46], [1.66], [0.67], [1.6], [2.47], [0.95], [4.04], [4.12], [2.0], [-0.04], [4.4], [2.16], [2.1], [1.56], [1.29], [3.5], [1.78], [1.56], [0.76], [6.34], [5.31], [1.55], [1.84], [5.57], [1.83], [3.13], [1.7], [3.14], [2.16], [-1.5], [-0.94], [2.84], [0.44], [4.61], [2.3], [7.4], [0.76], [2.1], [2.69], [1.16], [3.5], [3.05], [2.91], [0.18], [2.22], [0.59], [4.94], [2.1], [0.47], [-0.4], [0.84], [-1.42], [3.1], [1.52], [3.62], [6.25], [0.36], [0.81], [3.82], [2.64], [2.69], [2.35], [3.56], [1.49], [5.83], [1.71], [3.93], [1.53], [4.5], [1.83], [3.47], [6.35], [5.36], [0.82], [6.36], [0.77], [-2.89], [1.59], [-1.47], [-0.08], [3.16], [5.96], [7.02], [0.57], [2.53], [4.29], [2.12], [-0.15], [1.77], [4.13], [2.88], [1.16], [2.85], [3.11], [6.36], [3.2], [1.1], [2.68], [5.73], [0.98], [1.68], [1.34], [0.28], [2.81], [3.4], [-0.32], [-0.59], [3.42], [1.3], [-1.42], [2.99], [2.38], [1.8], [0.97], [3.27], [3.69], [4.02], [5.55], [2.12], [0.88], [-1.21], [1.59], [2.81], [1.98], [5.97], [-0.8], [2.59], [5.65], [0.65], [2.45], [1.53], [0.61], [2.04], [3.63], [2.54], [1.42], [1.81], [3.56], [2.49], [5.41], [6.24], [5.39], [0.94], [3.31], [-0.29], [3.82], [0.01], [1.63], [4.39], [0.75], [1.75], [0.8], [2.23], [0.83], [2.13], [4.25], [0.63], [2.86], [3.87], [1.56], [1.64], [0.68], [2.63], [1.21], [7.0], [4.51], [0.33], [2.12], [3.78], [-0.04], [0.2], [5.3], [1.99], [6.09], [0.15], [0.56], [6.36], [1.96], [4.41], [3.45], [6.79], [-4.22], [2.43], [6.3], [0.88], [3.06], [3.57], [-2.0], [1.14], [4.5], [1.3], [3.37], [1.71], [3.78], [2.45], [3.25], [0.02], [0.99], [1.3], [1.44], [1.73], [1.7], [1.72], [-1.01], [3.92], [3.09], [-0.33], [0.68], [1.79], [-0.02], [9.36], [-0.06], [1.75], [0.44], [2.31], [0.85], [2.08], [1.94], [4.44], [2.98], [0.69], [-0.04], [3.02], [4.82], [4.3], [3.89], [3.69], [4.05], [0.34], [4.25], [2.0], [-2.04], [3.09], [1.45], [0.48], [-0.04], [1.43], [-1.82], [-0.91], [0.9], [1.83], [4.81], [4.1], [1.31], [-2.04], [1.27], [6.46], [2.88], [-0.03], [1.88], [3.65], [1.33], [2.17], [2.32], [2.48], [-2.1], [1.87], [1.6], [2.06], [0.3], [6.17], [1.64], [5.81], [-0.11], [6.28], [1.74], [2.16], [0.1], [1.24], [7.3], [3.03], [0.23], [1.75], [3.25], [2.53], [4.27], [2.46], [0.65], [1.5], [1.65], [1.89], [2.43], [-0.64], [2.95], [2.74], [1.08], [1.35], [0.34], [3.87], [2.85], [1.73], [0.78], [2.57], [3.34], [3.23], [0.65], [6.22], [2.3], [1.73], [1.29], [2.11], [1.86], [0.93], [3.48], [3.1], [0.78], [2.31], [1.46], [0.2], [1.76], [0.46], [2.04], [3.74], [1.9], [2.8], [-0.56], [0.24], [1.76], [0.27], [5.76], [0.08], [1.21], [0.68], [1.36], [2.94], [1.61], [3.01], [1.78], [0.47], [7.11], [0.6], [1.9], [0.62], [4.0], [1.98], [0.79], [-0.3], [2.9], [1.85], [4.16], [5.26], [4.57], [1.28], [4.96], [1.27], [2.48], [2.86], [0.33], [1.8], [1.76], [4.24], [3.52], [0.3], [-1.4], [3.11], [-0.13], [1.45], [1.21], [0.56], [1.27], [2.46], [7.25], [7.44], [-0.16], [4.4], [1.56], [1.61], [2.57], [2.99], [-2.0], [4.61], [3.1], [3.86], [0.16], [1.73], [2.15], [2.75], [4.2], [2.82], [1.37], [1.53], [2.41], [1.27], [4.1], [3.11], [3.82], [1.95], [1.29], [1.83], [0.98], [3.04], [2.23], [1.04], [0.68], [-3.89], [0.24], [1.26], [0.79], [0.5], [2.54], [-2.05], [1.08], [2.19], [2.68], [-0.59], [7.1], [2.75], [0.24], [-1.04], [3.57], [0.32], [-0.11], [5.76], [2.77], [4.58], [1.61], [5.67], [0.87], [5.21], [1.56], [2.18], [1.59], [2.8], [2.89], [2.04], [0.49], [2.82], [1.88], [3.51], [2.18], [0.92], [2.18], [1.72], [4.7], [3.68], [0.87], [0.53], [5.03], [2.94], [3.76], [2.29], [0.92], [2.38], [3.25], [2.54], [4.26], [3.6], [1.14], [2.97], [-2.34], [0.33], [0.78], [2.88], [3.57], [0.71], [1.1], [-1.0], [2.41], [-0.66], [0.56], [1.73], [1.07], [3.47], [0.27], [4.82], [2.42], [3.64], [-0.29], [2.95], [3.3], [-1.66], [2.38], [-0.28], [1.7], [-0.5], [-0.2], [1.83], [-2.01], [1.18], [5.43], [0.17], [2.4], [0.41], [1.24], [3.45], [4.03], [3.82], [3.3], [3.52], [1.7], [4.23], [-0.87], [4.67], [2.86], [3.97], [-1.05], [4.76], [-1.77], [5.08], [0.68], [4.57], [2.44], [1.48], [3.34], [2.03], [2.59], [6.46], [2.49], [3.23], [-0.96], [0.4], [2.84], [2.64], [2.57], [1.23], [2.37], [2.86], [3.0], [6.08], [1.75], [0.57], [1.71], [2.67], [5.18], [-2.78], [5.41], [1.75], [2.54], [0.05], [-0.3], [0.44], [6.2], [1.82], [0.71], [0.75], [3.0], [2.05], [2.48], [4.43], [2.69], [1.93], [1.06], [1.64], [6.09], [2.73], [1.99], [1.21], [1.5], [1.01], [2.56], [0.95], [1.33], [1.8], [1.31], [-0.7], [3.74], [0.35], [4.75], [5.88], [3.38], [0.8], [1.68], [7.44], [0.38], [1.58], [5.48], [1.7], [2.95], [2.09], [3.2], [2.11], [3.09], [2.21], [-0.22], [4.43], [0.71], [1.15], [0.23], [2.04], [2.06], [4.07], [5.23], [1.66], [4.21], [0.42], [3.12], [1.27], [1.11], [6.68], [3.62], [2.28], [-0.26], [3.04], [3.9], [2.03], [-1.58], [1.78], [2.49], [0.86], [2.46], [3.58], [0.73], [2.67], [8.03], [0.91], [4.24], [2.3], [0.32], [3.9], [0.7], [3.14], [2.11], [1.05], [-0.94], [3.11], [4.26], [0.86], [0.55], [-0.04], [2.35], [2.87], [1.87], [2.11], [-0.39], [1.98], [1.95], [2.27], [0.28], [3.65], [0.88], [-0.78], [1.51], [2.27], [2.41], [0.72], [-0.12], [2.34], [2.48], [2.31], [4.42], [-1.02], [1.68], [1.76], [0.17], [4.11], [1.42], [2.33], [5.9], [1.35], [1.65], [-0.67], [0.82], [0.39], [0.71], [0.67], [-1.26], [0.52], [0.36], [2.98], [2.74], [2.18], [4.97], [3.05], [-0.13], [8.2], [3.51], [4.43], [3.18], [2.08], [2.43], [4.12], [-0.05], [-0.89], [2.49], [3.4], [0.51], [1.49], [1.71], [5.83], [3.95], [5.07], [3.83], [4.22], [-0.49], [3.72], [-0.37], [3.79], [-0.56], [2.12], [1.46], [2.93], [1.1], [3.11], [-1.71], [3.58], [2.46], [3.49], [2.51], [6.3], [7.13], [2.33], [5.23], [2.96], [1.88], [1.23], [-0.38], [0.95], [4.0], [6.51], [2.89], [2.31], [1.87], [3.21], [3.66], [-1.16], [1.55], [1.15], [2.9], [3.3], [1.28], [0.86], [0.65], [0.56], [0.01], [0.98], [2.92], [3.51], [-0.68], [1.79], [1.47], [3.78], [2.2], [5.49], [2.58], [-0.52], [-0.05], [0.23], [-0.17], [3.33], [2.56], [0.36], [1.91], [-0.2], [4.41], [3.32], [0.57], [3.9], [1.78], [2.0], [0.11], [5.15], [4.56], [6.08], [0.7], [1.9], [5.19], [2.85], [-0.7], [4.25], [2.68], [1.49], [4.9], [1.73], [5.07], [-0.61], [3.55], [5.5], [3.08], [2.52], [1.65], [4.3], [2.89], [1.42], [5.09], [-0.38], [0.62], [4.21], [4.1], [0.65], [0.29], [-2.0], [1.9], [4.91], [8.65], [0.45], [3.78], [2.23], [6.8], [0.63], [1.83], [1.76], [5.78], [4.32], [4.46], [4.3], [3.78], [2.31], [3.12], [1.34], [2.85], [4.91], [3.32], [2.46], [0.95], [6.75], [4.6], [4.52], [1.76], [1.91], [3.89], [0.96], [2.4], [0.35], [2.08], [0.93], [0.77], [2.59], [6.37], [-1.85], [-2.84], [2.71], [1.95], [2.54], [3.17], [5.2], [-1.5], [6.98], [1.29], [0.74], [-1.17], [7.66], [0.66], [-0.04], [6.63], [-0.7], [5.24], [1.84], [-0.85], [3.29], [-0.25], [2.21], [2.75], [0.91], [3.6], [4.75], [0.78], [1.24], [4.31], [1.8], [1.13], [0.83], [0.71], [4.44], [-1.16], [1.43], [1.34], [0.41], [-0.42], [-0.04], [2.45], [2.89], [3.31], [0.51], [3.62], [2.73], [0.82], [1.33], [1.43], [0.65], [-0.8], [1.29], [2.45], [0.89], [1.9], [2.1], [6.53], [3.34], [0.66], [3.8], [2.68], [-1.0], [2.9], [1.6], [1.68], [6.31], [1.04], [1.8], [4.19], [0.28], [4.1], [-0.72], [0.6], [4.02], [3.65], [0.18], [0.73], [-0.71], [3.26], [0.1], [0.9], [0.79], [3.78], [1.12], [2.24], [0.52], [-1.34], [0.85], [0.33], [-1.11], [0.93], [0.76], [4.61], [2.59], [2.31], [0.65], [3.0], [5.2], [1.61], [3.35], [1.04], [3.75], [2.6], [6.28], [0.75], [1.84], [0.93], [2.73], [-1.33], [1.98], [7.05], [-0.4], [6.22], [-0.44], [2.01], [0.17], [-0.7], [3.55], [-0.24], [0.17], [1.56], [1.39], [3.93], [-0.11], [3.4], [3.37], [1.83], [4.14], [1.17], [2.01], [0.9], [6.8], [-0.87], [3.58], [1.05], [1.73], [4.45], [0.9], [2.79], [0.02], [2.16], [0.31], [1.03], [1.24], [1.23], [3.12], [5.2], [3.51], [1.5], [1.85], [1.34], [5.52], [2.35], [0.61], [3.6], [1.77], [3.39], [-0.66], [3.9], [1.64], [3.14], [0.33], [2.54], [7.53], [5.15], [2.9], [3.72], [2.48], [0.7], [2.09], [3.08], [0.46], [0.83], [1.6], [3.16], [1.55], [3.67], [0.95], [1.54], [5.78], [-0.15], [3.2], [1.24], [1.28], [-0.52], [2.84], [1.57], [4.16], [1.96], [2.04], [2.22], [3.41], [2.4], [2.7], [0.72], [4.42], [4.37], [2.82], [1.18], [2.79], [3.17], [-0.63], [1.15], [0.0], [1.64], [4.28], [1.2], [2.19], [2.52], [2.23], [2.11], [4.0], [4.64], [4.62], [4.94], [2.03], [0.57], [5.92], [3.45], [1.93], [0.53], [2.46], [-0.6], [3.53], [3.02], [1.58], [5.7], [1.69], [2.28], [2.24], [2.18], [3.15], [0.54], [2.22], [-2.05], [3.83], [3.93], [-0.68], [4.47], [1.09], [3.9], [-0.34], [1.69], [5.23], [1.3], [1.82], [-1.03], [2.78], [3.32], [3.65], [4.76], [-2.98], [4.02], [1.78], [1.85], [2.17], [4.8], [2.85], [-0.88], [6.15], [1.51], [2.65], [2.49], [-0.11], [2.64], [2.64], [1.59], [7.55], [4.58], [2.59], [2.59], [-0.41], [0.49], [2.91], [2.18], [2.08], [0.89], [2.52], [2.16], [4.48], [4.85], [1.94], [3.21], [2.8], [-2.46], [2.06], [-0.37], [2.14], [0.08], [1.13], [-0.74], [6.17], [3.31], [2.11], [7.64], [2.43], [0.51], [4.5], [0.83], [3.15], [5.7], [0.56], [0.31], [4.05], [-0.54], [4.06], [1.73], [0.97], [2.44], [3.8], [2.74], [1.22], [2.21], [0.95], [3.41], [0.51], [2.45], [0.42], [-0.88], [3.61], [2.15], [0.56], [2.88], [5.35], [1.6], [0.58], [4.33], [3.06], [1.64], [1.15], [2.2], [1.85], [0.92], [3.03], [-1.98], [-0.22], [1.89], [0.83], [-0.17], [3.22], [1.49], [0.54], [1.74], [-2.67], [-0.07], [2.68], [2.19], [2.16], [4.82], [1.76], [4.16], [1.63], [7.2], [-0.58], [2.72], [4.44], [1.58], [1.94], [2.18], [2.72], [1.59], [4.6], [2.52], [1.91], [3.72], [3.29], [6.38], [1.55], [2.11], [4.25], [2.1], [2.6], [-3.24], [1.34], [1.58], [1.88], [4.8], [-0.13], [1.53], [0.29], [1.4], [3.8], [-0.68], [2.86], [1.33], [0.06], [-1.02], [1.93], [4.3], [4.34], [0.14], [0.62], [-0.2], [3.64], [1.19], [2.69], [4.02], [5.25], [3.87], [3.28], [3.95], [3.16], [1.82], [2.11], [1.98], [3.48], [2.75], [2.42], [0.66], [3.38], [0.41], [0.57], [3.72], [-2.33], [0.2], [5.0], [2.42], [4.68], [1.97], [3.5], [1.53], [2.26], [3.69], [1.9], [8.5], [1.65], [2.08], [1.7], [-0.31], [2.12], [2.44], [1.5], [1.18], [1.97], [4.47], [2.15], [3.29], [-0.6], [3.49], [0.39], [4.8], [1.0], [2.27], [1.4], [1.48], [1.31], [4.76], [0.2], [3.48], [3.63], [-1.0], [1.85], [3.35], [2.23], [1.92], [3.43], [0.23], [1.16], [0.86], [3.8], [-1.0], [1.47], [3.14], [0.78], [4.08], [-0.31], [2.47], [2.9], [3.48], [-3.07], [1.71], [4.3], [2.91], [2.67], [2.16], [3.92], [4.64], [-0.07], [-0.26], [2.81], [-0.06], [-0.63], [3.08], [2.11], [0.65], [-0.28], [4.31], [3.61], [1.46], [2.41], [3.54], [3.01], [0.5], [1.1], [0.21], [2.05], [5.85], [2.02], [3.9], [2.53], [0.5], [4.34], [1.0], [-0.24], [0.49], [2.09], [1.09], [4.8], [2.74], [3.7], [1.89], [2.19], [1.77], [1.09], [0.82], [-0.05], [-0.28], [-0.66], [2.35], [3.85], [2.1], [2.13], [-0.76], [2.75], [0.98], [3.89], [5.59], [1.16], [1.45], [6.58], [0.0], [1.74], [0.34], [2.29], [6.25], [5.95], [1.3], [1.02], [3.5], [3.52], [1.24], [2.4], [0.47], [1.89], [-1.43], [1.3], [0.91], [1.66], [-0.38], [3.15], [2.92], [5.16], [2.26], [4.1], [4.8], [2.82], [1.81], [3.55], [-1.55], [2.62], [4.25], [3.06], [1.24], [5.01], [-0.03], [2.01], [8.46], [3.82], [2.47], [1.14], [-0.13], [2.68], [4.59], [1.99], [2.49], [3.88], [-3.21], [3.07], [-0.05], [3.69], [0.51], [1.88], [1.78], [0.39], [2.02], [2.7], [3.96], [1.97], [0.75], [1.89], [2.98], [2.05], [2.46], [2.62], [2.16], [0.84], [2.81], [0.6], [1.26], [5.5], [3.0], [3.6], [2.67], [3.43], [-0.12], [-0.49], [1.8], [0.2], [1.8], [1.2], [5.08], [2.78], [4.85], [1.39], [1.39], [1.19], [-0.6], [3.97], [1.32], [3.52], [-0.09], [3.91], [1.31], [0.99], [1.42], [2.92], [1.05], [1.87], [0.33], [0.99], [2.84], [1.69], [4.25], [4.27], [0.17], [4.44], [1.22], [-0.31], [1.87], [5.21], [1.6], [1.47], [3.4], [2.2], [2.53], [2.13], [1.99], [3.5], [1.62], [2.01], [-0.25], [-0.36], [2.68], [4.51], [2.2], [5.46], [1.36], [-2.05], [3.34], [3.35], [5.07], [1.01], [5.72], [2.59], [1.86], [-0.66], [1.84], [0.6], [0.38], [1.81], [1.59], [0.67], [5.47], [1.14], [3.93], [0.73], [1.06], [-1.88], [2.53], [4.7], [1.63], [4.6], [1.8], [1.43], [0.77], [2.86], [2.78], [2.63], [5.78], [3.89], [1.06], [3.26], [4.17], [4.51], [0.28], [4.32], [2.21], [1.82], [3.09], [1.09], [0.38], [1.58], [2.3], [0.56], [3.6], [3.63], [4.79], [1.18], [2.18], [0.6], [3.62], [2.7], [3.26], [1.51], [1.42], [2.37], [3.17], [1.28], [1.08], [3.05], [3.45], [1.1], [7.81], [1.52], [2.82], [2.84], [3.06], [3.37], [5.04], [2.25], [4.4], [4.86], [1.55], [3.75], [1.23], [4.0], [4.47], [7.54], [1.11], [1.6], [0.9], [-1.33], [0.82], [3.74], [6.2], [2.15], [7.07], [3.98], [1.0], [2.63], [1.18], [3.56], [1.26], [1.79], [2.03], [2.87], [1.57], [1.76], [0.58], [5.86], [6.84], [2.28], [2.14], [0.3], [1.78], [3.42], [4.83], [2.24], [3.13], [0.48], [4.3], [-0.47], [4.65], [1.02], [3.04], [0.77], [-0.14], [5.48], [1.73], [1.44], [3.6], [-0.22], [-0.9], [-2.94], [1.25], [-0.84], [1.25], [3.79], [2.41], [1.81], [3.08], [2.99], [3.04], [0.65], [0.41], [2.64], [7.31], [0.49], [1.24], [-1.22], [2.1], [-0.57], [-0.68], [3.95], [0.55], [4.53], [1.15], [1.78], [1.26], [1.47], [0.08], [2.07], [1.5], [3.45], [4.43], [0.15], [2.01], [1.47], [0.66], [1.41], [2.33], [0.47], [3.58], [1.03], [-0.52], [1.26], [1.99], [0.68], [0.17], [1.54], [2.45], [-2.29], [1.27], [1.88], [2.29], [0.95], [-2.32], [-1.01], [1.5], [6.35], [0.65], [1.64], [3.71], [7.77], [1.94], [4.87], [0.13], [0.85], [0.93], [1.0], [0.22], [6.79], [-0.35], [2.75], [0.27], [-1.53], [2.82], [-0.43], [0.29], [3.19], [3.18], [1.89], [1.54], [0.25], [4.73], [3.53], [4.4], [0.81], [4.8], [1.9], [4.29], [-0.83], [0.76], [2.92], [2.09], [3.2], [5.08], [1.01], [5.58], [0.8], [1.08], [1.47], [1.45], [2.04], [0.6], [3.15], [5.11], [2.6], [1.83], [2.67], [4.3], [0.32], [-1.52], [4.83], [4.77], [2.52], [2.7], [0.89], [2.8], [2.7], [1.28], [2.1], [1.39], [2.93], [-0.25], [-0.46], [4.42], [0.72], [-0.77], [2.97], [2.52], [-1.64], [0.43], [3.0], [2.22], [1.91], [1.23], [1.57], [2.18], [1.82], [1.46], [3.03], [3.72], [2.85], [1.73], [-0.5], [2.44], [3.37], [4.28], [1.57], [2.08], [0.61], [3.0], [1.2], [-1.31], [-1.13], [2.27], [4.01], [0.0], [-0.49], [2.44], [2.69], [1.1], [1.35], [0.7], [4.08], [1.47], [4.17], [4.77], [2.47], [3.66], [2.66], [0.98], [1.82], [5.37], [1.39], [2.15], [0.89], [0.5], [3.67], [2.18], [1.12], [4.97], [1.79], [2.39], [4.81], [4.64], [1.29], [0.75], [0.16], [-3.53], [4.21], [-0.09], [2.19], [2.34], [3.3], [0.08], [0.43], [-0.25], [0.2], [2.68], [0.1], [1.52], [3.66], [4.53], [1.7], [3.69], [-0.97], [4.66], [0.17], [1.13], [2.09], [4.92], [3.35], [2.7], [0.57], [0.78], [3.39], [1.73], [0.41], [0.49], [1.08], [-0.32], [1.88], [2.34], [2.45], [6.82], [1.85], [1.04], [3.36], [1.17], [-0.9], [4.46], [0.01], [0.54], [-1.2], [3.29], [1.92], [1.15], [4.1], [0.29], [4.87], [0.23], [2.17], [0.72], [-1.83], [4.06], [0.47], [0.94], [2.5], [4.31], [2.7], [1.71], [1.69], [1.48], [1.38], [2.54], [3.5], [0.77], [2.34], [2.21], [0.66], [1.43], [1.02], [0.99], [3.25], [1.86], [0.13], [1.8], [3.3], [0.15], [4.2], [0.04], [1.26], [0.74], [-0.22], [0.84], [0.63], [1.96], [1.51], [2.58], [7.2], [1.75], [3.01], [1.19], [1.63], [3.38], [1.82], [4.89], [4.1], [0.56], [0.59], [0.53], [2.48], [0.14], [-1.17], [0.5], [0.78], [2.62], [4.9], [3.54], [5.99], [4.08], [0.03], [3.72], [0.95], [3.2], [1.31], [1.34], [4.66], [0.47], [1.04], [-1.85], [5.67], [7.0], [0.69], [1.49], [3.44], [2.3], [-0.6], [1.29], [1.8], [1.35], [2.42], [3.52], [1.28], [0.15], [1.58], [-1.89], [0.82], [2.3], [1.91], [4.55], [1.59], [2.55], [-1.15], [-2.82], [4.73], [4.17], [-0.79], [-0.96], [0.51], [-2.05], [-0.45], [3.83], [1.3], [0.03], [1.49], [3.89], [0.77], [0.12], [4.17], [3.8], [1.21], [1.28], [1.01], [2.03], [0.8], [6.54], [2.95], [1.76], [0.74], [5.0], [1.24], [3.95], [-0.38], [2.6], [7.26], [1.9], [1.32], [4.85], [5.81], [2.43], [2.31], [2.24], [2.08], [2.08], [2.07], [0.71], [-0.45], [4.2], [3.5], [1.4], [5.07], [4.8], [4.45], [-1.05], [1.08], [5.07], [2.32], [1.76], [1.51], [1.02], [2.16], [2.04], [1.28], [0.86], [8.2], [2.71], [2.71], [4.0], [-0.82], [0.64], [1.73], [1.6], [5.67], [2.33], [4.63], [3.39], [4.01], [-0.06], [2.18], [0.99], [4.48], [2.94], [5.34], [5.45], [0.09], [2.87], [4.55], [-1.86], [0.06], [-1.47], [2.82], [4.26], [2.4], [1.35], [0.48], [-0.07], [1.31], [1.83], [0.42], [2.8], [5.96], [4.04], [2.02], [0.97], [2.49], [1.42], [0.78], [1.7], [3.08], [2.51], [3.28], [3.2], [2.7], [7.59], [1.98], [2.59], [-0.9], [7.15], [-0.57], [1.44], [2.23], [4.88], [2.83], [4.31], [0.84], [2.84], [1.83], [-3.05], [4.78], [5.01], [2.1], [1.8], [-0.63], [1.65], [2.88], [3.15], [6.8], [-0.04], [-0.5], [1.85], [4.27], [1.18], [2.36], [3.8], [0.46], [1.17], [5.33], [2.02], [0.48], [2.67], [0.08], [0.36], [2.15], [-0.2], [3.28], [4.34], [5.23], [3.0], [-0.6], [2.98], [1.4], [8.16], [3.75], [0.1], [4.14], [1.5], [0.9], [3.02], [-0.03], [2.44], [3.43], [2.47], [-0.49], [6.02], [1.94], [2.24], [4.11], [4.44], [1.1], [1.47], [3.84], [3.27], [4.42], [0.56], [1.69], [-3.41], [5.34], [-0.67], [5.9], [2.02], [4.7], [4.97], [0.39], [1.01], [4.17], [6.26], [2.39], [1.11], [2.24], [1.96], [4.42], [0.87], [9.29], [2.11], [2.46], [2.7], [0.91], [3.28], [-0.77], [2.86], [5.19], [3.92], [1.6], [5.58], [-0.78], [0.15], [-0.14], [0.68], [3.64], [4.27], [1.24], [4.15], [2.12], [2.4], [4.02], [0.35], [1.01], [3.21], [3.78], [1.83], [2.5], [2.8], [6.8], [1.15], [2.33], [3.42], [4.57], [1.33], [3.2], [4.69], [9.07], [2.3], [0.48], [3.34], [4.4], [0.76], [3.19], [0.44], [2.7], [2.09], [3.34], [3.29], [-1.08], [2.24], [1.39], [-0.55], [-0.63], [1.78], [-1.61], [4.22], [1.36], [2.64], [5.66], [2.85], [3.06], [3.04], [1.7], [0.51], [2.11], [5.51], [0.24], [1.78], [1.38], [0.28], [4.48], [0.54], [1.56], [1.99], [0.66], [-2.6], [7.32], [0.35], [4.36], [3.6], [1.24], [7.62], [2.89], [2.83], [5.31], [4.55], [4.66], [-0.46], [1.93], [1.44], [1.19], [1.65], [2.65], [6.66], [1.59], [3.36], [1.11], [3.18], [2.41], [-0.35], [3.56], [1.11], [-0.31], [-0.77], [3.99], [3.07], [1.44], [1.18], [1.98], [-1.56], [0.84], [4.85], [1.55], [3.09], [1.07], [3.47], [3.2], [4.55], [1.94], [1.65], [5.7], [4.47], [2.61], [4.94], [9.29], [4.99], [0.42], [3.22], [-1.25], [0.73], [-0.14], [2.16], [2.19], [-1.8], [3.0], [1.72], [0.37], [1.0], [1.13], [4.4], [4.16], [3.32], [3.02], [0.31], [2.94], [5.65], [4.46], [-0.9], [3.74], [1.54], [0.57], [1.87], [2.01], [3.11], [-0.31], [4.81], [2.78], [2.32], [0.17], [-0.21], [2.8], [3.18], [2.29], [3.72], [0.83], [2.35], [1.89], [0.7], [4.3], [1.86], [5.01], [2.55], [1.18], [2.59], [3.0], [-1.4], [2.86], [1.34], [2.09], [-1.32], [6.83], [5.0], [4.31], [1.14], [2.4], [-0.16], [2.99], [4.37], [3.27], [4.3], [2.27], [1.04], [-2.14], [1.95], [3.92], [4.03], [2.48], [3.4], [1.98], [-0.49], [3.67], [1.25], [-0.35], [3.26], [3.55], [0.36], [-0.2], [2.46], [0.24], [2.03], [1.24], [2.7], [3.23], [2.72], [5.1], [0.66], [0.98], [1.59], [0.22], [1.6], [2.16], [0.45], [-0.92], [2.3], [3.32], [2.91], [0.93], [1.88], [1.81], [0.69], [-0.83], [-0.57], [0.14], [2.36], [1.58], [0.87], [3.78], [0.43], [4.7], [3.51], [1.0], [3.77], [4.9], [1.03], [1.1], [3.14], [0.33], [1.28], [2.63], [3.2], [2.34], [3.66], [0.54], [-0.49], [2.12], [0.18], [3.67], [2.88], [2.83], [1.84], [0.28], [3.17], [7.63], [0.97], [2.48], [3.49], [1.92], [1.59], [1.37], [0.55], [0.39], [2.1], [3.42], [2.32], [1.74], [1.16], [2.53], [0.4], [6.22], [4.6], [3.83], [0.94], [0.35], [2.53], [1.63], [2.09], [1.37], [4.51], [-0.37], [4.69], [2.14], [0.01], [0.93], [-0.28], [1.41], [3.09], [0.38], [3.4], [-0.22], [1.74], [0.69], [1.98], [-2.72], [1.09], [4.82], [2.95], [1.27], [2.82], [5.49], [-0.85], [3.48], [1.55], [1.67], [5.0], [4.4], [3.13], [-1.17], [1.51], [3.27], [1.23], [1.81], [1.36], [2.38], [2.62], [2.33], [1.66], [-1.58], [2.76], [3.34], [2.0], [2.24], [3.2], [1.36], [6.1], [2.15], [2.67], [0.02], [1.27], [4.97], [3.83], [3.66], [2.03], [1.83], [-0.02], [-1.87], [0.58], [0.82], [2.56], [-0.13], [2.37], [0.0], [3.11], [1.0], [-0.89], [2.37], [1.52], [1.54], [0.37], [2.51], [4.34], [3.56], [1.07], [2.41], [1.68], [2.55], [1.06], [0.79], [2.9], [4.56], [4.5], [0.35], [-0.16], [2.97], [0.15], [1.9], [3.11], [2.2], [0.0], [4.38], [7.05], [3.31], [-1.4], [3.26], [1.37], [5.65], [-3.64], [1.28], [4.5], [0.11], [1.36], [3.17], [3.53], [2.54], [5.02], [-0.41], [2.87], [2.25], [3.2], [4.19], [1.5], [1.77], [3.05], [0.68], [-0.2], [0.38], [1.45], [0.76], [2.98], [1.29], [3.07], [-0.95], [0.57], [0.12], [0.72], [0.42], [1.73], [3.68], [1.39], [1.42], [-1.3], [3.36], [0.38], [-0.49], [4.15], [2.5], [2.88], [0.53], [1.16], [-1.08], [1.3], [1.83], [3.02], [2.4], [0.4], [1.79], [1.29], [-0.67], [5.82], [0.85], [2.25], [0.37], [1.42], [2.59], [1.46], [3.55], [3.75], [2.59], [0.71], [3.14], [2.53], [3.92], [1.81], [2.68], [0.33], [5.5], [1.67], [2.69], [-0.63], [-1.59], [0.79], [-0.71], [4.53], [1.83], [2.3], [2.56], [1.73], [3.83], [1.12], [5.75], [4.3], [5.18], [1.76], [0.82], [0.39], [4.09], [2.0], [-0.57], [3.15], [3.07], [0.57], [1.5], [1.63], [3.51], [1.42], [4.6], [2.68], [3.91], [2.85], [-0.05], [0.41], [0.86], [-0.04], [2.94], [1.99], [1.49], [2.38], [1.95], [0.55], [0.4], [0.81], [1.4], [3.6], [3.32], [0.58], [-0.04], [2.28], [1.17], [2.14], [5.08], [4.0], [0.74], [0.44], [0.82], [3.55], [4.67], [4.1], [1.27], [1.02], [2.05], [-0.4], [5.86], [3.85], [0.66], [2.72], [2.43], [4.33], [0.67], [3.24], [7.18], [3.26], [1.87], [0.98], [2.88], [1.33], [0.35], [3.73], [-0.84], [-4.0], [0.14], [2.59], [0.16], [4.54], [3.94], [0.24], [5.21], [3.24], [1.96], [-0.21], [1.82], [6.5], [-0.25], [2.2], [0.58], [1.33], [-0.67], [1.79], [2.31], [3.32], [1.58], [1.26], [1.68], [2.44], [7.25], [1.03], [0.58], [3.12], [1.02], [-0.08], [1.6], [0.34], [1.92], [2.4], [2.53], [1.76], [0.58], [3.67], [1.14], [2.1], [2.27], [-0.04], [2.83], [1.4], [6.72], [1.65], [4.2], [2.69], [1.52], [0.81], [5.94], [2.02], [0.73], [2.69], [5.12], [-0.02], [-0.61], [-0.02], [4.73], [2.9], [4.05], [7.21], [4.78], [3.9], [5.35], [2.13], [3.99], [6.67], [0.23], [2.95], [2.9], [4.24], [1.44], [2.47], [4.73], [4.93], [3.5], [0.15], [-0.74], [1.34], [-0.04], [3.42], [3.52], [2.82], [1.92], [2.52], [3.82], [2.51], [6.5], [6.09], [3.74], [-0.39], [6.06], [1.12], [0.45], [2.75], [-0.85], [1.61], [5.22], [-1.9], [1.9], [5.4], [3.12], [1.54], [1.33], [3.23], [0.84], [0.08], [1.41], [4.34], [6.85], [1.39], [1.32], [5.09], [1.86], [-0.05], [2.36], [2.08], [1.5], [0.12], [-1.15], [0.81], [1.99], [3.86], [3.2], [-1.3], [-1.2], [1.34], [3.24], [2.88], [1.27], [1.31], [4.68], [0.52], [2.53], [-0.61], [0.25], [2.61], [1.9], [-1.29], [3.08], [1.72], [4.64], [-0.08], [3.84], [2.29], [0.91], [4.82], [3.08], [1.84], [4.91], [2.32], [-0.34], [1.26], [3.03], [0.45], [3.91], [2.59], [4.58], [1.78], [-1.23], [1.88], [3.85], [1.64], [0.14], [3.58], [2.39], [3.42], [0.49], [0.0], [2.19], [-0.73], [3.21], [2.61], [2.04], [4.14], [2.56], [0.3], [1.3], [4.0], [4.24], [-1.69], [0.65], [0.87], [0.44], [2.64], [1.45], [0.21], [4.37], [4.62], [-0.33], [4.17], [2.92], [3.9], [1.87], [0.91], [4.81], [3.1], [1.58], [1.57], [3.09], [3.16], [1.76], [3.67], [2.43], [0.75], [2.86], [2.94], [-4.43], [1.65], [4.0], [0.3], [-0.3], [3.8], [7.47], [-0.59], [0.57], [3.04], [2.22], [5.16], [1.38], [2.09], [0.19], [-0.17], [4.02], [2.01], [3.24], [1.45], [3.46], [2.67], [1.71], [1.38], [4.0], [0.44], [2.53], [3.51], [2.25], [4.73], [2.58], [0.92], [0.9], [5.2], [1.73], [-0.8], [1.71], [4.76], [3.27], [3.45], [1.04], [1.89], [2.02], [2.76], [5.68], [8.16], [2.5], [3.75], [-1.09], [3.92], [0.73], [4.58], [1.49], [2.21], [0.99], [2.11], [5.83], [0.72], [1.41], [2.14], [-2.55], [2.68], [2.15], [5.34], [3.77], [4.92], [6.52], [-0.38], [2.55], [2.95], [2.55], [1.71], [2.43], [2.44], [1.22], [2.45], [2.17], [2.6], [0.38], [3.12], [1.53], [0.8], [3.8], [2.79], [0.0], [1.74], [4.07], [9.96], [2.79], [5.77], [3.43], [5.89], [3.91], [-0.27], [2.02], [2.25], [2.94], [0.12], [3.63], [5.36], [1.44], [0.39], [-0.22], [3.7], [0.88], [3.74], [1.26], [0.56], [5.1], [1.89], [3.05], [0.5], [-0.7], [0.09], [1.8], [1.96], [1.24], [4.8], [-0.11], [-1.18], [0.93], [2.7], [0.65], [0.68], [-2.42], [-1.43], [-0.43], [6.47], [1.65], [3.05], [3.42], [2.5], [-2.68], [2.85], [1.0], [2.99], [0.54], [-1.4], [0.14], [1.69], [0.75], [-0.1], [-1.3], [3.12], [3.73], [-1.2], [1.29], [2.09], [3.44], [0.74], [2.44], [3.97], [2.15], [4.22], [3.84], [3.03], [2.06], [3.27], [2.46], [5.79], [-0.74], [2.73], [2.89], [-2.2], [1.31], [1.96], [1.65], [2.6], [1.58], [1.12], [0.4], [3.07], [2.67], [2.06], [1.82], [1.59], [6.99], [3.09], [3.27], [3.8], [2.38], [1.73], [-1.87], [3.42], [1.51], [1.21], [0.48], [3.65], [3.96], [3.83], [0.2], [2.92], [0.21], [4.0], [3.4], [1.85], [0.96], [-0.45], [7.46], [2.54], [1.81], [0.69], [4.09], [1.16], [1.86], [1.12], [2.1], [2.13], [0.3], [1.07], [1.79], [1.52], [1.05], [-0.69], [1.7], [3.37], [0.0], [1.47], [3.24], [1.05], [3.36], [2.51], [3.57], [4.24], [-1.08], [3.08], [1.98], [2.8], [-0.27], [1.05], [2.54], [2.92], [2.19], [-1.3], [4.34], [0.25], [2.45], [0.46], [-0.28], [4.09], [3.53], [3.2], [-0.89], [0.41], [3.34], [2.51], [2.77], [1.69], [2.95], [0.53], [3.42], [5.8], [2.64], [4.25], [4.41], [1.11], [0.91], [1.98], [3.6], [0.08], [4.63], [2.0], [0.23], [0.12], [5.62], [3.85], [2.22], [8.06], [-0.4], [0.54], [2.34], [2.73], [4.48], [3.05], [-0.08], [1.85], [8.27], [5.43], [-0.11], [2.74], [-0.72], [1.33], [2.58], [5.26], [2.4], [3.52], [-0.64], [1.28], [1.61], [1.81], [1.08], [3.1], [-0.32], [-2.31], [1.15], [5.72], [0.83], [3.69], [1.91], [2.9], [2.88], [1.54], [3.26], [-1.76], [4.1], [1.37], [4.54], [5.94], [4.97], [0.47], [5.66], [0.87], [1.01], [0.85], [2.2], [1.86], [2.26], [-0.8], [0.54], [1.18], [2.16], [-1.3], [-0.5], [1.09], [2.8], [1.75], [4.8], [1.72], [1.89], [1.56], [4.92], [0.85], [3.33], [1.32], [3.2], [4.39], [1.45], [1.34], [1.85], [1.0], [3.44], [0.8], [0.96], [1.11], [0.67], [1.76], [3.4], [2.25], [3.85], [1.48], [1.06], [-3.09], [1.45], [3.14], [1.2], [1.22], [0.7], [-0.96], [3.21], [0.96], [0.14], [0.85], [-0.7], [5.21], [2.57], [-0.52], [3.77], [3.03], [2.26], [7.11], [5.61], [3.57], [2.9], [3.22], [-0.96], [3.82], [1.6], [3.46], [2.18], [2.4], [2.28], [0.01], [4.75], [2.32], [0.91], [0.71], [0.75], [0.55], [4.94], [0.83], [3.46], [1.63], [5.25], [0.32], [3.0], [0.73], [-0.52], [0.59], [2.74], [2.8], [1.3], [2.64], [1.29], [1.19], [4.67], [1.9], [4.24], [3.06], [-0.67], [2.84], [1.45], [-0.05], [0.42], [4.2], [2.6], [4.77], [4.83], [1.79], [-0.06], [1.37], [-0.9], [1.36], [1.31], [1.44], [2.39], [-1.38], [0.89], [3.8], [4.17], [1.17], [1.93], [3.3], [3.9], [2.93], [-0.11], [0.22], [3.25], [1.72], [2.51], [2.3], [-1.89], [3.01], [1.33], [1.6], [-0.38], [4.37], [1.94], [-2.11], [3.75], [6.64], [4.99], [2.72], [-0.65], [0.06], [2.8], [3.7], [7.11], [0.22], [4.45], [4.15], [-0.21], [3.2], [-0.32], [1.8], [0.81], [1.81], [-1.11], [5.77], [5.69], [0.73], [-0.15], [4.38], [0.24], [0.97], [2.41], [3.57], [0.52], [-0.34], [0.06], [3.39], [4.25], [1.4], [2.52], [1.24], [1.41], [2.99], [2.57], [4.52], [1.21], [1.46], [0.86], [1.42], [-1.89], [1.33], [4.16], [0.26], [3.85], [1.4], [-0.01], [1.38], [1.65], [3.28], [0.56], [3.03], [0.63], [5.91], [1.62], [1.51], [0.11], [-0.52], [1.21], [0.7], [3.17], [1.84], [0.76], [9.3], [2.56], [1.7], [3.05], [0.58], [2.45], [0.87], [0.64], [1.92], [0.3], [2.53], [2.13], [0.85], [2.24], [0.96], [1.33], [2.7], [0.43], [1.88], [0.36], [1.77], [1.14], [-0.35], [1.82], [2.83], [-0.07], [3.58], [-0.17], [1.56], [1.96], [3.2], [1.65], [1.22], [4.48], [0.04], [1.04], [1.33], [3.55], [2.62], [0.64], [1.65], [7.63], [3.75], [-1.22], [1.33], [2.0], [3.3], [1.75], [0.86], [6.2], [1.87], [3.64], [2.69], [1.32], [2.15], [-0.55], [0.9], [1.61], [4.38], [0.0], [1.57], [2.45], [2.86], [2.56], [-1.54], [0.2], [-1.25], [2.17], [1.97], [3.66], [1.62], [0.53], [3.14], [3.68], [1.48], [1.12], [2.9], [3.91], [2.45], [-1.14], [5.78], [2.57], [1.25], [0.72], [-0.27], [3.73], [0.2], [3.63], [4.28], [0.36], [2.93], [-0.02], [1.39], [6.67], [1.05], [0.99], [5.51], [2.71], [1.02], [1.2], [1.65], [-0.74], [-0.92], [3.96], [2.82], [3.72], [0.4], [1.53], [3.86], [3.99], [1.63], [3.9], [4.47], [3.05], [3.28], [5.53], [1.31], [3.32], [2.65], [3.3], [0.87], [1.49], [2.03], [1.52], [3.88], [0.47], [-0.67], [0.84], [2.59], [2.06], [1.9], [1.89], [1.18], [5.18], [0.61], [2.95], [2.81], [2.42], [2.52], [3.89], [1.99], [2.76], [6.51], [4.8], [0.97], [3.92], [5.05], [1.96], [1.45], [1.79], [2.66], [3.09], [2.3], [0.66], [1.36], [1.7], [1.89], [-0.14], [2.6], [2.85], [2.21], [2.84], [1.91], [3.42], [1.87], [2.29], [6.2], [2.06], [3.3], [0.92], [-1.39], [0.37], [3.92], [3.61], [2.61], [1.26], [1.55], [4.88], [0.91], [1.62], [4.66], [0.74], [2.31], [1.18], [2.19], [0.11], [0.74], [2.45], [3.58], [3.45], [4.01], [2.61], [4.43], [-0.94], [1.16], [2.16], [1.46], [2.36], [0.75], [2.67], [5.75], [2.29], [0.97], [3.08], [0.99], [2.7], [3.68], [0.06], [2.17], [2.39], [-0.28], [1.96], [1.8], [6.13], [3.39], [7.83], [-0.55], [3.95], [2.45], [2.47], [1.7], [0.4], [3.08], [3.04], [1.76], [1.8], [2.48], [2.29], [-3.02], [1.76], [2.38], [5.38], [3.73], [-0.62], [5.2], [2.03], [0.62], [2.15], [2.13], [3.25], [1.85], [-0.02], [0.62], [-0.1], [3.87], [3.63], [0.69], [-0.39], [6.42], [3.28], [1.24], [3.2], [1.37], [1.4], [3.11], [2.46], [1.08], [2.91], [0.99], [1.89], [0.06], [2.8], [5.32], [2.51], [2.76], [-0.94], [1.9], [1.61], [1.6], [4.42], [3.2], [2.06], [2.37], [1.12], [1.95], [8.65], [2.0], [3.86], [1.7], [-0.74], [5.07], [-0.61], [-2.4], [-0.27], [0.27], [1.58], [4.48], [3.47], [1.14], [4.51], [-0.2], [-1.3], [1.44], [1.14], [2.91], [1.1], [3.23], [1.82], [0.98], [1.07], [1.7], [3.44], [1.01], [1.01], [0.31], [3.7], [2.59], [0.49], [3.4], [4.25], [2.78], [-0.19], [0.81], [1.84], [3.27], [3.2], [1.59], [2.78], [0.96], [4.73], [0.98], [3.36], [2.98], [1.29], [0.4], [-0.31], [1.8], [1.07], [1.81], [-0.17], [2.17], [5.56], [3.56], [0.44], [2.69], [2.56], [0.51], [-4.65], [6.75], [2.45], [-0.27], [0.04], [2.26], [-0.34], [1.87], [-1.49], [2.2], [0.16], [-0.95], [1.98], [1.33], [1.1], [2.03], [2.88], [-0.16], [1.5], [2.52], [1.9], [1.45], [1.5], [2.56], [4.19], [4.45], [2.81], [3.24], [4.71], [-0.45], [3.58], [5.15], [3.39], [1.56], [2.34], [3.32], [0.66], [4.0], [0.96], [2.09], [5.96], [1.9], [3.12], [4.16], [3.14], [0.2], [2.4], [2.17], [-1.11], [4.26], [4.4], [1.95], [1.23], [0.06], [3.57], [0.8], [1.88], [2.4], [0.85], [1.89], [-0.36], [0.75], [1.06], [3.5], [1.63], [2.6], [1.53], [2.63], [3.15], [1.28], [4.0], [2.96], [1.85], [5.2], [2.23], [4.06], [3.48], [2.59], [2.21], [0.38], [1.47], [3.3], [4.88], [3.67], [5.57], [2.86], [2.53], [4.86], [3.65], [2.19], [1.94], [0.96], [-1.31], [1.98], [4.74], [3.68], [1.8], [4.84], [2.36], [0.71], [2.53], [1.41], [2.6], [0.86], [0.2], [0.24], [1.53], [1.36], [0.6], [0.5], [1.8], [3.52], [2.52], [3.06], [1.78], [1.53], [1.64], [0.04], [2.11], [1.85], [1.05], [1.3], [-0.46], [2.86], [0.8], [3.51], [5.9], [2.02], [0.63], [4.74], [0.65], [3.16], [2.59], [3.0], [3.6], [1.12], [0.61], [0.61], [2.29], [2.09], [2.96], [2.58], [2.3], [-0.93], [6.96], [0.77], [3.24], [3.43], [2.3], [2.55], [3.04], [4.64], [0.62], [0.04], [2.73], [0.93], [1.42], [1.83], [4.35], [2.05], [0.99], [2.0], [1.85], [2.53], [1.54], [3.34], [2.59], [1.64], [-0.8], [2.32], [6.11], [1.75], [5.76], [0.43], [6.1], [3.74], [0.58], [2.84], [0.83], [-0.1], [2.74], [0.95], [-2.47], [1.52], [2.03], [4.28], [2.77], [0.97], [-0.23], [2.62], [1.75], [3.7], [7.2], [0.96], [1.06], [2.63], [0.95], [1.51], [3.84], [-2.26], [3.15], [2.83], [2.78], [2.56], [2.1], [2.77], [1.39], [2.02], [2.9], [3.49], [4.37], [1.75], [3.7], [-1.26], [3.71], [3.14], [4.4], [4.35], [5.7], [0.85], [4.0], [4.21], [1.18], [-0.58], [3.2], [1.29], [0.17], [0.58], [1.15], [2.23], [5.44], [2.56], [4.97], [2.08], [2.68], [2.88], [2.75], [4.73], [3.59], [1.94], [2.16], [4.45], [5.63], [6.65], [0.82], [0.93], [2.78], [3.67], [3.42], [6.18], [3.81], [4.83], [3.7], [2.03], [-0.22], [1.53], [4.51], [2.0], [-2.11], [2.18], [1.84], [1.72], [4.82], [1.01], [4.09], [2.38], [2.4], [0.61], [3.37], [3.39], [2.91], [-0.37], [0.82], [0.57], [1.43], [2.9], [3.9], [0.96], [2.72], [0.45], [4.97], [1.9], [5.09], [2.23], [0.67], [0.22], [6.44], [1.74], [-1.0], [2.72], [0.2], [2.88], [3.78], [4.21], [2.1], [2.07], [1.18], [-1.02], [1.92], [1.03], [-0.06], [-0.67], [-0.41], [1.99], [2.46], [-0.24], [-1.85], [1.18], [1.04], [1.57], [0.91], [1.0], [-0.04], [2.58], [1.34], [2.19], [3.32], [2.03], [6.84], [4.61], [1.95], [1.3], [4.64], [1.9], [3.64], [1.36], [4.97], [2.27], [6.51], [5.21], [0.74], [4.16], [3.7], [2.07], [1.85], [1.85], [0.94], [2.27], [0.48], [6.15], [0.6], [3.31], [0.77], [2.18], [1.36], [1.83], [5.16], [1.07], [3.7], [5.09], [0.74], [5.12], [3.45], [1.1], [3.42], [4.51], [0.7], [1.32], [0.7], [0.83], [2.38], [1.38], [0.6], [-2.9], [2.54], [-0.2], [4.63], [2.9], [1.25], [3.42], [-0.01], [3.18], [2.05], [2.13], [2.84], [1.25], [1.27], [2.75], [7.05], [1.84], [-0.87], [4.4], [5.44], [0.72], [2.71], [4.43], [2.12], [1.06], [1.77], [4.28], [0.72], [3.44], [-0.65], [0.98], [4.07], [1.32], [2.44], [1.5], [3.55], [0.26], [-0.83], [1.49], [5.0], [3.38], [2.12], [1.8], [-0.2], [3.65], [3.08], [4.46], [4.18], [2.36], [0.62], [3.82], [0.6], [0.83], [1.22], [-0.49], [1.23], [0.52], [1.5], [1.49], [1.13], [4.8], [6.47], [4.42], [3.02], [3.68], [2.85], [5.08], [-2.43], [0.65], [1.85], [3.55], [0.83], [2.63], [4.26], [0.62], [1.41], [5.23], [1.87], [3.46], [1.11], [1.5], [1.88], [7.1], [1.56], [2.82], [0.73], [0.55], [2.42], [0.11], [3.62], [2.81], [3.1], [2.88], [1.76], [1.9], [1.46], [0.99], [0.63], [6.4], [1.9], [0.84], [-0.69], [3.52], [2.37], [1.86], [-0.07], [-0.62], [3.25], [2.27], [3.38], [3.43], [2.98], [2.39], [0.88], [1.9], [-0.35], [1.29], [3.94], [0.38], [0.9], [-1.4], [3.05], [2.56], [2.58], [1.96], [1.47], [1.92], [2.89], [1.25], [-0.38], [0.27], [2.52], [1.82], [2.98], [2.06], [8.42], [1.4], [3.02], [2.78], [2.88], [1.78], [5.15], [4.7], [3.37], [3.7], [2.59], [4.52], [4.14], [-0.81], [2.76], [-0.52], [3.31], [4.78], [1.99], [3.67], [1.66], [0.25], [3.4], [5.53], [1.52], [0.04], [-0.64], [3.63], [0.23], [3.64], [2.09], [5.31], [6.63], [2.93], [0.59], [2.39], [1.77], [0.66], [0.76], [-0.5], [3.7], [3.18], [2.56], [-1.0], [1.26], [4.0], [0.95], [2.92], [2.12], [3.7], [1.2], [1.88], [-0.81], [1.63], [3.3], [2.3], [3.2], [4.3], [0.45], [0.49], [2.27], [6.74], [6.8], [3.21], [-0.47], [1.43], [3.4], [5.51], [1.01], [1.98], [3.87], [4.03], [1.4], [0.35], [2.71], [-0.03], [4.72], [0.52], [4.38], [2.42], [0.23], [2.17], [0.37], [2.34], [3.2], [2.32], [2.16], [2.81], [3.71], [0.73], [3.55], [1.87], [1.37], [-1.64], [2.24], [1.42], [4.75], [0.45], [1.99], [1.02], [-0.39], [3.72], [6.06], [5.12], [5.01], [2.27], [2.74], [3.61], [0.23], [2.7], [1.52], [2.48], [0.95], [2.25], [0.4], [2.63], [-0.03], [0.0], [1.64], [1.74], [-0.19], [4.22], [2.45], [-1.56], [5.25], [1.55], [-0.96], [-0.33], [1.78], [0.82], [1.69], [-0.71], [1.03], [3.54], [3.25], [3.29], [4.69], [5.18], [4.2], [0.97], [-0.09], [1.78], [5.29], [0.85], [0.96], [3.83], [4.38], [-0.36], [0.41], [1.48], [3.03], [1.7], [2.16], [1.82], [-0.04], [3.95], [1.39], [0.59], [2.69], [2.33], [-0.08], [0.04], [1.95], [3.14], [1.34], [0.61], [2.8], [1.72], [3.77], [3.88], [5.68], [1.3], [2.78], [1.44], [1.72], [6.67], [0.24], [-0.77], [1.54], [4.44], [6.3], [-1.7], [3.35], [1.26], [1.97], [2.72], [5.33], [4.54], [1.68], [2.9], [-0.79], [2.71], [2.44], [3.35], [4.88], [1.69], [3.06], [1.73], [5.6], [2.82], [3.17], [2.67], [3.85], [3.64], [2.02], [1.95], [0.29], [1.56], [1.6], [3.96], [-1.22], [0.89], [3.17], [0.81], [1.31], [1.58], [3.77], [2.68], [2.94], [0.8], [2.56], [-1.34], [1.98], [2.1], [2.19], [4.5], [1.29], [0.3], [0.13], [6.11], [3.18], [-0.31], [1.76], [1.09], [0.64], [1.13], [0.23], [0.74], [1.6], [-2.37], [4.01], [0.48], [4.53], [4.81], [-0.64], [0.11], [2.79], [4.67], [1.51], [7.11], [4.37], [0.07], [1.48], [4.89], [0.32], [2.86], [3.7], [0.34], [6.47], [3.83], [0.91], [2.1], [0.35], [3.4], [0.83], [2.44], [3.81], [-0.31], [0.68], [-0.51], [2.87], [0.38], [-1.09], [1.18], [4.5], [-0.32], [1.92], [4.91], [2.93], [1.32], [3.74], [-2.47], [4.47], [0.56], [1.98], [0.31], [1.74], [5.63], [2.04], [3.16], [1.67], [-2.16], [1.57], [1.64], [2.71], [2.44], [-0.62], [1.24], [0.77], [3.31], [-1.3], [0.18], [1.7], [2.83], [7.92], [2.01], [0.08], [3.38], [0.27], [-2.27], [-1.77], [1.4], [6.06], [-0.59], [0.27], [0.99], [5.66], [1.73], [2.5], [3.63], [1.28], [3.23], [4.31], [1.52], [3.07], [2.31], [3.9], [1.64], [5.03], [3.84], [0.03], [2.59], [3.77], [3.58], [2.36], [1.86], [3.7], [1.35], [0.72], [2.81], [1.67], [1.35], [4.94], [3.77], [3.62], [0.74], [6.25], [2.32], [0.8], [0.67], [0.23], [3.3], [4.22], [0.26], [4.05], [-2.45], [4.11], [1.54], [4.51], [0.92], [0.65], [3.4], [2.48], [1.34], [3.11], [0.23], [1.5], [-1.87], [0.84], [3.25], [0.4], [2.4], [3.24], [-0.45], [0.9], [4.92], [4.58], [-0.53], [5.09], [2.54], [2.9], [1.92], [0.32], [3.01], [4.34], [3.58], [-0.91], [1.28], [0.26], [0.67], [3.71], [6.93], [0.46], [4.26], [3.08], [1.49], [2.6], [2.54], [0.48], [3.24], [1.03], [0.55], [-2.83], [4.93], [1.57], [1.71], [-0.32], [2.17], [1.86], [1.1], [2.05], [0.57], [4.0], [4.82], [3.93], [-1.27], [2.74], [1.43], [-2.79], [2.09], [1.85], [1.3], [3.44], [2.47], [1.56], [3.92], [3.42], [1.5], [2.37], [3.46], [1.37], [1.73], [1.44], [6.51], [2.85], [0.21], [1.72], [0.22], [1.68], [4.55], [-0.81], [4.09], [1.98], [4.04], [0.54], [6.86], [2.41], [-1.65], [1.63], [-1.07], [2.33], [1.0], [4.56], [3.0], [6.07], [3.64], [2.53], [-1.51], [0.56], [2.33], [-0.47], [0.31], [2.73], [1.56], [3.94], [0.34], [2.6], [4.68], [1.15], [0.84], [0.63], [-0.89], [2.07], [2.07], [0.28], [-1.05], [2.96], [3.4], [4.1], [0.77], [3.18], [1.2], [2.39], [4.85], [5.04], [-0.17], [5.43], [1.01], [2.93], [1.97], [1.53], [1.51], [4.43], [0.84], [5.42], [0.71], [-0.47], [1.83], [2.78], [1.42], [2.38], [1.2], [4.37], [2.87], [1.95], [3.18], [1.56], [1.91], [5.72], [0.3], [2.92], [2.05], [3.61], [1.33], [2.3], [2.55], [3.01], [0.24], [5.55], [8.2], [1.23], [0.24], [2.21], [1.23], [-1.87], [2.62], [2.34], [-1.71], [0.9], [2.45], [4.27], [2.21], [1.99], [2.27], [0.66], [2.82], [1.31], [0.52], [0.01], [3.01], [1.21], [1.25], [0.71], [2.28], [0.5], [1.82], [2.4], [3.6], [1.94], [1.51], [1.94], [0.26], [0.64], [2.79], [0.78], [-0.38], [5.7], [7.19], [0.35], [4.07], [1.95], [0.1], [1.6], [4.51], [3.83], [2.44], [-1.2], [-0.32], [4.55], [2.54], [3.05], [0.35], [3.21], [3.61], [5.11], [3.35], [-0.44], [0.16], [1.23], [0.99], [3.03], [4.1], [2.62], [5.0], [4.2], [2.34], [1.62], [1.67], [0.58], [6.31], [3.67], [1.88], [0.18], [3.27], [1.29], [-0.64], [0.73], [0.5], [1.96], [3.87], [1.42], [1.6], [3.2], [2.22], [-0.21], [1.38], [2.28], [6.2], [0.3], [4.62], [5.77], [2.74], [3.2], [1.85], [1.3], [1.91], [3.39], [2.64], [1.05], [1.7], [-0.09], [3.12], [1.15], [-0.47], [1.8], [0.64], [2.45], [2.95], [2.08], [2.02], [5.81], [4.36], [2.44], [-0.11], [0.46], [1.02], [0.35], [0.55], [0.95], [4.98], [3.15], [1.16], [1.33], [1.76], [1.01], [3.31], [1.56], [2.03], [5.18], [3.48], [0.5], [0.07], [-0.38], [1.04], [1.93], [0.52], [0.36], [0.77], [0.02], [2.87], [1.68], [-0.4], [6.6], [3.57], [6.13], [1.99], [1.2], [5.11], [4.06], [3.95], [0.24], [-0.36], [-0.03], [1.2], [0.46], [4.4], [4.41], [3.4], [0.46], [1.66], [-0.59], [1.71], [3.91], [1.57], [1.65], [8.07], [1.36], [1.83], [5.18], [1.01], [2.29], [3.74], [2.82], [2.1], [0.25], [2.85], [-0.78], [3.96], [2.81], [1.62], [1.87], [0.67], [1.79], [0.39], [3.28], [4.52], [1.39], [1.87], [2.26], [0.57], [1.08], [4.59], [6.16], [2.88], [1.6], [3.26], [0.85], [1.38], [3.85], [5.15], [3.19], [3.7], [0.56], [3.3], [1.64], [1.7], [3.75], [1.12], [5.46], [2.93], [1.03], [2.23], [1.65], [1.36], [1.66], [3.78], [4.98], [1.76], [2.4], [7.31], [3.35], [0.36], [5.4], [-1.7], [2.77], [5.53], [-1.26], [0.57], [-0.62], [2.13], [0.8], [2.86], [3.65], [1.13], [2.2], [-0.35], [2.67], [-0.25], [1.95], [0.44], [-0.11], [2.84], [3.26], [0.95], [4.15], [0.4], [-0.39], [2.2], [-0.17], [0.32], [2.46], [3.47], [2.52], [2.08], [4.48], [2.57], [-0.18], [4.02], [5.05], [1.78], [-0.16], [2.3], [1.04], [3.66], [2.27], [1.98], [4.5], [2.78], [3.03], [1.94], [0.91], [3.13], [0.18], [3.41], [2.91], [4.56], [5.5], [1.56], [3.95], [-0.02], [1.61], [0.7], [-0.07], [1.45], [-1.66], [-0.68], [2.27], [3.15], [-0.49], [0.68], [2.32], [0.64], [1.07], [2.69], [3.38], [1.92], [1.89], [2.3], [2.05], [1.06], [2.74], [1.7], [2.03], [0.96], [1.9], [-0.85], [1.86], [4.56], [-1.13], [2.82], [3.42], [3.56], [2.66], [5.62], [2.78], [2.38], [3.35], [2.13], [3.08], [2.5], [6.11], [1.48], [2.39], [1.81], [0.87], [0.2], [1.38], [2.69], [1.27], [2.71], [0.3], [1.58], [3.1], [1.82], [-0.96], [0.05], [2.14], [4.66], [2.95], [0.13], [0.56], [1.08], [2.05], [0.11], [3.06], [4.13], [2.08], [1.56], [4.51], [1.38], [5.86], [2.4], [-0.3], [1.22], [1.6], [0.14], [0.36], [0.56], [2.68], [1.8], [3.28], [2.5], [0.82], [1.01], [1.62], [2.75], [5.43], [3.82], [2.44], [-0.05], [1.42], [4.29], [-1.98], [9.05], [2.74], [2.08], [2.52], [0.93], [1.2], [1.65], [0.93], [2.18], [2.77], [2.77], [2.37], [2.8], [3.6], [8.01], [2.59], [2.2], [0.54], [1.16], [0.46], [1.44], [0.71], [5.53], [3.6], [0.64], [4.32], [-1.58], [1.1], [-0.36], [1.94], [3.66], [3.34], [5.76], [3.1], [0.66], [-0.32], [7.2], [2.76], [2.31], [3.53], [5.49], [3.69], [0.23], [2.61], [0.37], [5.72], [0.13], [0.16], [0.69], [0.59], [3.87], [2.71], [0.61], [8.29], [0.95], [1.11], [1.52], [1.93], [2.67], [4.83], [4.42], [-0.56], [1.9], [3.35], [3.47], [-0.77], [1.58], [3.08], [4.88], [1.53], [8.68], [3.32], [2.33], [2.82], [3.75], [5.6], [3.27], [1.68], [2.79], [2.19], [2.6], [2.86], [2.8], [1.83], [4.0], [1.67], [2.3], [3.66], [0.91], [2.69], [1.88], [4.04], [-0.05], [-0.28], [2.53], [1.31], [1.63], [2.58], [3.19], [3.32], [4.17], [-2.91], [1.18], [3.25], [0.23], [0.05], [3.91], [4.32], [2.02], [2.98], [2.73], [1.62], [2.0], [2.21], [0.44], [2.32], [3.64], [3.85], [-0.96], [3.39], [0.29], [-2.03], [3.75], [3.08], [2.66], [3.53], [2.14], [0.91], [3.01], [0.1], [2.84], [2.62], [0.46], [1.38], [4.72], [2.13], [7.57], [1.61], [2.1], [1.77], [1.99], [5.66], [1.33], [-1.13], [3.63], [4.9], [-1.2], [1.19], [0.67], [3.01], [0.96], [1.18], [5.18], [0.09], [1.25], [0.32], [-1.91], [4.9], [3.7], [3.94], [2.14], [-0.54], [3.11], [2.02], [1.69], [-0.2], [3.0], [1.38], [2.49], [5.09], [1.23], [2.03], [3.13], [6.01], [1.57], [-1.34], [7.6], [2.4], [0.85], [2.18], [0.68], [0.36], [0.76], [2.93], [1.15], [1.94], [3.35], [2.28], [1.18], [1.96], [1.0], [1.82], [3.25], [5.19], [2.22], [1.1], [1.13], [2.82], [-1.58], [3.42], [1.4], [-1.88], [0.45], [0.81], [1.37], [4.7], [0.82], [0.39], [1.73], [-0.05], [2.59], [-1.57], [1.38], [0.3], [4.12], [0.12], [-0.7], [0.98], [-0.55], [2.54], [2.96], [1.46], [0.86], [4.85], [0.16], [1.74], [2.27], [3.27], [3.99], [2.36], [2.68], [2.07], [3.01], [0.47], [2.51], [2.93], [0.3], [2.29], [0.49], [2.6], [0.86], [1.21], [-0.05], [4.67], [2.1], [1.1], [4.49], [-0.5], [4.51], [4.55], [1.72], [2.09], [2.37], [-0.66], [2.5], [3.56], [0.43], [2.99], [0.28], [2.14], [3.16], [4.04], [1.98], [3.11], [0.3], [3.08], [1.88], [5.81], [1.35], [1.59], [0.51], [2.65], [3.9], [1.9], [6.2], [2.5], [3.89], [3.25], [1.31], [0.08], [2.11], [0.1], [1.0], [4.19], [1.68], [5.86], [2.66], [0.1], [2.72], [2.38], [4.99], [2.11], [4.37], [6.72], [2.68], [0.33], [-0.23], [2.62], [0.74], [2.66], [8.35], [3.2], [0.31], [3.69], [3.12], [2.23], [0.75], [0.85], [3.04], [3.65], [0.9], [3.55], [5.01], [-0.99], [3.13], [3.39], [0.7], [3.15], [1.88], [-1.3], [3.89], [7.43], [1.78], [3.7], [0.15], [2.83], [3.21], [3.65], [1.79], [4.51], [1.28], [2.73], [0.26], [0.98], [1.94], [-0.35], [1.14], [2.11], [1.98], [2.94], [1.64], [-0.78], [3.34], [3.13], [0.24], [1.5], [4.3], [1.77], [5.1], [1.42], [1.19], [1.94], [3.91], [2.33], [3.1], [1.83], [3.9], [1.52], [1.36], [1.46], [-1.23], [2.7], [0.82], [2.54], [4.04], [3.13], [0.0], [3.26], [2.74], [-0.48], [1.7], [0.16], [1.16], [0.38], [2.08], [3.13], [0.81], [2.52], [3.13], [3.49], [2.35], [1.23], [1.86], [1.88], [0.2], [1.44], [-3.05], [3.74], [-0.47], [2.04], [3.56], [4.43], [1.9], [2.09], [2.0], [-0.06], [1.7], [6.21], [3.68], [0.85], [-0.06], [-0.88], [0.13], [0.98], [2.3], [3.76], [4.04], [0.26], [2.62], [3.3], [4.34], [2.24], [5.9], [0.67], [1.99], [2.55], [1.05], [0.76], [8.56], [3.33], [2.02], [0.59], [2.9], [2.95], [-3.17], [1.89], [0.67], [0.56], [2.62], [1.85], [2.4], [3.94], [4.63], [2.82], [3.05], [1.27], [0.53], [5.76], [1.53], [1.49], [3.98], [7.29], [4.75], [1.19], [4.21], [6.01], [4.2], [1.85], [-1.11], [2.6], [2.42], [2.12], [4.9], [1.44], [3.82], [3.38], [1.46], [1.01], [0.93], [3.15], [4.17], [3.64], [1.63], [2.1], [2.93], [2.0], [-0.62], [3.16], [3.18], [0.72], [1.48], [-0.24], [1.12], [2.33], [0.52], [1.96], [-0.27], [1.45], [4.14], [4.17], [3.08], [3.5], [-0.26], [-0.32], [4.5], [3.94], [0.92], [-1.74], [7.11], [4.03], [4.95], [1.24], [5.31], [3.83], [3.42], [9.29], [-0.41], [2.41], [1.56], [3.28], [3.79], [-0.3], [2.06], [3.37], [6.59], [3.2], [2.05], [1.13], [3.58], [3.34], [6.59], [3.65], [-1.33], [3.13], [-0.47], [2.94], [2.51], [1.47], [-0.81], [0.72], [0.55], [2.41], [0.81], [4.56], [0.16], [1.81], [3.91], [3.19], [-1.64], [0.6], [2.16], [2.73], [5.45], [1.11], [2.11], [2.46], [2.28], [7.12], [1.05], [-0.06], [2.28], [0.61], [-0.29], [2.27], [1.69], [1.43], [0.58], [6.54], [2.51], [3.26], [2.4], [-0.62], [2.16], [3.52], [-0.48], [3.55], [2.33], [4.62], [2.21], [4.43], [2.8], [4.12], [0.8], [2.8], [3.58], [2.86], [4.49], [1.13], [2.54], [4.62], [0.94], [-0.3], [2.74], [4.31], [3.39], [5.19], [2.16], [2.48], [1.55], [1.72], [-0.35], [1.9], [3.01], [-1.1], [0.6], [1.34], [7.48], [3.2], [3.73], [1.7], [1.76], [3.96], [1.02], [1.45], [3.14], [5.41], [5.0], [3.14], [0.95], [-0.21], [3.35], [3.88], [1.27], [4.29], [-1.3], [-1.32], [0.13], [1.81], [-1.05], [0.97], [0.37], [3.86], [1.05], [4.33], [-0.23], [6.84], [3.3], [5.43], [1.49], [-2.85], [2.89], [5.44], [2.8], [3.23], [4.09], [-0.85], [1.3], [3.55], [1.28], [0.6], [0.36], [5.35], [3.47], [1.44], [2.84], [1.76], [1.78], [1.08], [4.99], [0.61], [3.78], [-0.7], [3.17], [4.66], [0.62], [1.13], [1.0], [2.92], [3.59], [-1.49], [1.05], [2.68], [3.73], [2.74], [2.71], [-0.22], [1.9], [2.32], [-0.58], [2.39], [0.28], [1.35], [-1.23], [-0.42], [3.78], [2.74], [-1.85], [2.75], [5.02], [0.65], [2.03], [4.43], [1.27], [-0.17], [2.07], [1.26], [2.74], [-1.13], [0.89], [3.71], [5.77], [4.79], [4.92], [1.18], [3.59], [5.4], [4.29], [1.37], [0.73], [9.32], [-0.66], [2.38], [3.63], [1.99], [0.41], [1.79], [2.57], [0.83], [3.62], [0.8], [0.46], [5.16], [1.98], [2.81], [4.57], [0.91], [2.17], [1.61], [2.14], [3.58], [1.77], [0.82], [0.9], [4.12], [0.9], [2.07], [0.59], [2.26], [1.75], [4.28], [4.13], [0.66], [1.06], [6.6], [0.75], [4.69], [-1.05], [1.4], [2.64], [1.98], [1.16], [2.34], [3.52], [1.09], [2.96], [2.01], [1.25], [-2.39], [0.98], [4.64], [4.37], [3.3], [2.6], [8.5], [1.79], [2.37], [8.05], [1.49], [2.3], [2.66], [4.38], [2.81], [-0.52], [4.01], [3.58], [1.81], [0.04], [2.07], [0.51], [0.85], [2.76], [0.74], [2.28], [2.05], [2.28], [2.26], [0.43], [2.46], [2.55], [-2.61], [1.97], [8.18], [0.65], [5.25], [2.75], [1.52], [1.19], [-1.41], [3.1], [4.5], [0.04], [1.91], [-0.28], [0.76], [4.37], [4.12], [4.66], [-0.85], [0.13], [1.01], [0.62], [4.37], [5.75], [2.75], [0.88], [3.43], [6.14], [2.92], [0.4], [1.05], [2.3], [1.4], [-3.03], [1.0], [2.01], [4.08], [1.82], [2.84], [2.47], [3.2], [1.7], [5.25], [2.3], [4.59], [2.85], [1.76], [4.75], [0.36], [0.54], [2.18], [0.55], [2.1], [0.47], [1.44], [0.6], [-0.43], [-0.76], [1.29], [1.24], [1.7], [2.0], [0.81], [2.67], [0.66], [1.61], [-1.8], [1.43], [-1.82], [1.9], [2.05], [3.34], [2.58], [2.25], [1.2], [2.09], [5.12], [2.23], [2.68], [3.77], [1.82], [1.68], [4.06], [0.88], [2.6], [3.26], [3.35], [-0.66], [3.85], [5.8], [0.83], [2.82], [-0.96], [2.72], [4.26], [1.81], [-1.49], [2.1], [2.5], [2.06], [2.73], [3.32], [2.05], [2.75], [-2.54], [1.63], [0.33], [-0.56], [2.51], [1.58], [1.41], [4.98], [0.44], [0.56], [6.49], [2.37], [0.6], [2.35], [0.48], [1.43], [-1.03], [2.23], [1.04], [2.39], [2.27], [1.17], [1.25], [1.26], [5.84], [1.19], [3.23], [4.6], [3.03], [1.17], [3.38], [0.99], [4.3], [0.96], [2.27], [4.96], [2.67], [4.23], [2.81], [3.79], [-2.03], [0.72], [-1.25], [1.7], [2.34], [3.94], [2.62], [5.99], [1.57], [3.96], [1.48], [4.26], [0.71], [-0.56], [0.8], [5.68], [0.92], [2.2], [4.4], [5.28], [2.71], [0.11], [0.43], [0.97], [-0.33], [1.6], [5.44], [0.94], [2.24], [5.7], [3.8], [1.09], [2.37], [6.22], [4.28], [3.55], [2.2], [2.72], [2.68], [1.01], [1.14], [0.34], [3.14], [-0.47], [2.23], [-0.64], [3.49], [-1.8], [5.26], [3.14], [3.1], [0.95], [7.15], [3.5], [1.77], [3.39], [1.92], [1.75], [3.29], [2.54], [1.95], [-2.49], [6.47], [-2.2], [4.31], [2.56], [1.02], [2.46], [1.72], [-1.38], [-1.46], [-0.11], [3.94], [1.93], [1.26], [2.66], [0.32], [2.43], [1.63], [0.32], [1.47], [-0.3], [1.2], [0.12], [0.29], [0.86], [1.96], [0.95], [0.32], [-1.86], [5.57], [1.99], [2.8], [2.17], [0.91], [3.95], [3.99], [2.05], [2.85], [0.65], [2.38], [3.37], [1.76], [-0.95], [2.51], [0.93], [2.63], [5.47], [3.43], [-0.21], [1.24], [2.52], [0.03], [-0.15], [1.19], [-0.51], [-0.04], [3.42], [2.51], [4.49], [-0.23], [8.06], [1.36], [2.68], [1.36], [0.64], [0.87], [2.13], [1.9], [1.28], [4.25], [-0.06], [2.39], [-0.51], [-1.87], [4.83], [1.81], [4.73], [2.52], [2.59], [3.6], [1.98], [3.17], [8.23], [4.88], [-2.57], [2.3], [3.04], [1.57], [2.18], [0.69], [3.18], [2.08], [2.63], [1.18], [3.2], [2.81], [1.24], [4.25], [2.22], [4.93], [0.48], [2.41], [4.5], [1.3], [1.41], [1.34], [2.29], [0.44], [7.12], [-1.05], [2.3], [2.86], [2.98], [0.56], [1.27], [2.06], [3.81], [7.7], [3.6], [1.7], [6.97], [0.89], [-0.41], [2.74], [3.35], [1.02], [6.41], [-0.4], [1.21], [1.31], [3.41], [2.9], [3.24], [7.01], [3.29], [6.45], [-0.61], [0.97], [5.11], [1.48], [0.89], [1.81], [0.3], [3.05], [1.45], [5.3], [0.58], [3.33], [0.75], [0.7], [0.21], [2.99], [0.26], [2.73], [1.4], [2.62], [0.34], [4.2], [4.45], [2.47], [6.26], [0.74], [3.32], [1.03], [2.24], [2.75], [1.8], [0.76], [1.23], [0.28], [1.09], [2.6], [1.75], [2.41], [2.56], [0.98], [3.07], [-0.95], [6.0], [6.91], [0.94], [1.03], [2.19], [4.73], [6.26], [1.57], [1.94], [4.36], [1.05], [3.63], [3.23], [6.9], [1.0], [2.82], [3.6], [4.86], [-0.05], [5.95], [3.08], [1.66], [1.29], [3.01], [3.95], [0.4], [1.75], [4.98], [4.15], [1.78], [1.89], [2.06], [1.73], [3.66], [1.59], [4.6], [1.8], [6.39], [1.34], [1.2], [2.59], [0.38], [1.7], [3.3], [2.62], [2.41], [1.98], [-0.28], [2.61], [0.87], [-1.34], [0.23], [-0.03], [2.09], [1.93], [3.49], [1.61], [1.94], [3.68], [3.99], [2.82], [1.8], [5.87], [3.03], [3.0], [0.56], [1.0], [3.97], [-0.4], [4.05], [-0.9], [1.01], [2.72], [0.06], [3.23], [3.87], [-0.84], [0.92], [1.6], [0.56], [1.4], [3.37], [2.05], [0.69], [0.62], [0.15], [1.38], [2.39], [1.81], [1.86], [0.56], [4.09], [5.02], [0.15], [4.62], [1.12], [1.94], [2.6], [1.37], [3.55], [3.54], [1.09], [0.05], [3.92], [0.13], [3.44], [4.64], [2.98], [-0.2], [3.1], [0.09], [-0.45], [4.54], [3.77], [1.79], [2.14], [3.75], [1.87], [-1.22], [3.27], [4.85], [1.79], [3.81], [-0.05], [0.52], [-0.15], [2.28], [6.44], [5.74], [0.48], [0.67], [-0.71], [0.85], [3.4], [4.39], [2.52], [0.0], [2.43], [3.61], [6.11], [2.5], [-3.1], [3.37], [-0.17], [2.36], [-0.41], [0.0], [6.51], [2.03], [0.17], [5.81], [0.67], [4.49], [0.02], [0.08], [5.15], [1.69], [3.71], [1.73], [1.0], [0.26], [4.74], [3.63], [4.77], [2.9], [0.6], [3.54], [1.37], [3.92], [4.03], [6.68], [3.43], [-0.66], [1.09], [4.38], [0.07], [-1.06], [3.13], [1.22], [-0.03], [4.31], [1.52], [1.63], [0.57], [2.59], [4.66], [5.11], [1.17], [1.26], [0.39], [1.46], [2.3], [1.05], [1.7], [2.6], [4.86], [1.69], [0.88], [3.75], [1.16], [4.63], [0.58], [3.25], [0.58], [2.35], [1.03], [1.43], [0.26], [0.56], [0.9], [4.14], [0.07], [2.5], [0.96], [0.15], [2.85], [3.38], [2.77], [1.32], [3.54], [1.86], [2.03], [4.0], [1.34], [1.5], [1.54], [2.78], [-1.43], [1.64], [1.88], [0.12], [2.8], [2.67], [2.73], [2.4], [2.85], [1.69], [1.91], [4.95], [0.87], [3.17], [3.65], [2.42], [3.37], [1.99], [2.2], [2.91], [0.21], [5.32], [1.37], [1.42], [3.6], [0.54], [1.67], [4.47], [2.8], [1.73], [2.32], [5.62], [1.34], [0.5], [-2.54], [2.86], [5.17], [1.71], [3.37], [5.45], [-0.44], [5.42], [2.08], [-0.64], [-0.3], [2.79], [3.62], [3.06], [2.73], [2.96], [2.9], [5.36], [-0.92], [2.4], [2.7], [-0.04], [1.61], [5.8], [0.88], [2.24], [4.28], [3.72], [1.62], [6.25], [2.0], [1.79], [-0.81], [0.43], [1.59], [-0.18], [-0.35], [1.65], [1.22], [2.72], [3.94], [0.9], [1.62], [1.07], [3.59], [3.87], [1.67], [1.68], [0.15], [0.99], [-1.82], [5.5], [1.94], [-0.07], [2.78], [0.19], [2.4], [2.93], [-0.42], [0.83], [2.93], [4.58], [1.38], [0.68], [1.53], [2.12], [-1.47], [0.76], [0.48], [0.72], [4.14], [5.35], [0.57], [1.59], [1.98], [4.04], [2.86], [1.87], [2.76], [2.7], [4.27], [2.11], [-0.27], [2.11], [3.03], [1.66], [-0.73], [1.58], [1.11], [2.25], [3.48], [2.03], [-0.59], [1.22], [0.68], [5.9], [3.44], [2.14], [3.74], [0.49], [3.2], [5.15], [3.31], [-1.43], [3.0], [3.75], [1.57], [2.03], [3.13]]
[[-1.675192994707775], [0.0018735680319758635], [1.3584815519042586], [-0.1476737687728426], [-0.4147225844957329], [0.7068824415404064], [-1.4562129658150051], [-0.9541611922559713], [1.657576225513896], [1.486664983451246], [-0.44676844238247976], [-1.787353497311389], [1.9620118754379907], [1.022000044093417], [-1.2639378184945242], [0.5626760810500456], [-0.12630986351501147], [-0.7832499501933214], [0.6908595125970328], [0.46653850738980507], [-0.6550665186463343], [-1.0930265764318743], [0.2582404311259505], [0.2796043363837818], [0.023237473289807107], [-0.9701841211993447], [-0.911433381740309], [0.6000629152512502], [-1.4081441789848848], [0.22619457323920367], [-1.2479148895511507], [0.9632493046343811], [0.7923380625717311], [0.49324338896209396], [0.5733580336789612], [-1.1731412211487413], [0.5626760810500456], [-0.1476737687728426], [1.5614386518536552], [1.353140575589801], [-0.9808660738282604], [-0.831318737023442], [1.5560976755391975], [0.04994235486209628], [-0.3986996555523596], [1.6201893913126912], [0.4024467916163113], [-0.5322240634138047], [-0.34528989240778146], [0.3330140995283599], [0.5039253415910095], [-0.8099548317656107], [-0.7725679975644059], [1.4973469360801615], [-0.44142746606802197], [-0.745863115992117], [-0.21176548454633634], [-2.1772447682668092], [1.1982522624705245], [0.3597189811006488], [0.8724527072885981], [0.37574191004402235], [-0.7992728791366951], [0.26892238375486616], [0.0659652838054696], [-0.3132440345210346], [0.5092663179054675], [-0.38267672660898616], [-0.3613128213511549], [-0.4093816081812751], [1.0006361388355856], [-1.2532558658656086], [-1.10370852906079], [-0.6390435897029607], [0.15676188115125225], [0.18346676272354143], [-0.8366597133378996], [0.717564394169322], [-0.8793875238535621], [-0.11028693457163805], [2.1916738569596768], [-0.3559718450366971], [-1.1891641500921148], [-0.7084762817909123], [-0.6871123765330811], [-0.11562791088609585], [0.4825614363331784], [-0.9434792396270558], [-0.7512040923065747], [1.2302981203572712], [-1.050298765916212], [-1.5897373736764504], [-0.2438113424330832], [0.41846972055968484], [-0.0034674082824818287], [-0.5856338265583827], [-2.422929678731868], [0.9205214941187186], [2.277129477991001], [1.4012093624199211], [0.14607992852233664], [-1.3867802737270536], [0.017896496975349414], [-0.12630986351501147], [-2.7166833760270475], [0.4825614363331784], [0.4238106968741426], [0.19414871535245706], [0.15142090483679457], [0.007214544346433793], [0.3169911705849866], [-0.42540453712464854], [-1.3387114868969334], [0.46119753107534733], [0.08198821274884291], [0.3597189811006488], [0.5466531521066721], [0.8831346599175138], [1.1608654282693198], [-0.22778841348970977], [-0.7992728791366951], [-0.3346079397788659], [-0.17437865034513164], [-0.7138172581053701], [-0.38267672660898616], [0.07664723643438522], [0.3490370284717332], [0.2742633600693241], [-0.2544932950619988], [-0.32926696346440804], [0.2368765258681193], [1.4172322913632946], [-0.05687717142705993], [2.394630956909073], [-0.6123387081306718], [0.14607992852233664], [1.192911286156067], [0.24221750218257723], [-1.0129119317150073], [-0.37733575029452837], [-0.4734733239547688], [0.49324338896209396], [-0.4360864897535641], [-0.09960498194272242], [2.421335838481362], [-0.15301474508730042], [0.6962004889114908], [-0.9808660738282604], [0.37574191004402235], [-0.302562081892119], [0.017896496975349414], [-0.6977943291619968], [1.0006361388355856], [-2.0009925498897014], [0.5626760810500456], [0.5733580336789612], [-1.2158690316644039], [-1.2158690316644039], [-0.15835572140175821], [0.8938166125464294], [0.9258624704331763], [-0.5162011344704313], [0.10335211800667415], [0.5252892468488408], [-0.20642450823187852], [-0.17437865034513164], [1.5560976755391975], [-0.8740465475391043], [-0.8099548317656107], [-0.7618860449354904], [1.1662064045837774], [0.30630921795607097], [0.2796043363837818], [0.29028628901269743], [-0.8473416659668153], [-0.5856338265583827], [-0.8580236185957308], [0.6054038915657078], [-1.9689466920029546], [-1.10370852906079], [0.2796043363837818], [1.700304036029558], [0.007214544346433793], [1.4759830308223303], [0.41846972055968484], [-0.48949625289814225], [1.4118913150488366], [0.10869309432113208], [0.5199482705343832], [1.8498513728343766], [-0.5909748028728405], [-0.7405221396776591], [-0.22244743717525195], [-0.0889230293138068], [-0.15835572140175821], [-1.210528055349946], [-1.6912159236511486], [-1.5897373736764504], [-0.7084762817909123], [0.31165019427052865], [0.14607992852233664], [-0.8046138554511527], [-0.5535879686716358], [0.8137019678295624], [0.6801775599681172], [1.6148484149982336], [-0.45210941869693755], [-1.5523505394752457], [0.3169911705849866], [0.10869309432113208], [-0.28119817663428776], [-0.3132440345210346], [-0.11028693457163805], [-0.2972211055776612], [-1.32268855795356], [-1.1891641500921148], [1.6522352491994379], [1.929966017551244], [-0.23847036611862538], [1.572120604482571], [-0.8687055712246464], [-1.0930265764318743], [-1.2799607474378976], [0.6267677968235391], [-0.5909748028728405], [-1.787353497311389], [-1.8674681420282562], [-1.5309866342174145], [1.1074556651247418], [0.29028628901269743], [-0.15301474508730042], [-1.349393439525849], [-1.2318919606077774], [0.18346676272354143], [-0.2918801292632034], [-0.7885909265077794], [2.837931991009071], [-0.0034674082824818287], [-0.12096888720055367], [-0.3185850108354924], [-1.1357543869475368], [-0.302562081892119], [-0.008808384596939759], [0.09801114169221646], [-0.43074551343910633], [1.182229333527151], [-1.2906427000668133], [-0.8152958080800683], [0.10335211800667415], [-0.37733575029452837], [-0.9541611922559713], [-1.0930265764318743], [0.07130626011992729], [-0.083582052999349], [0.09801114169221646], [0.26892238375486616], [-0.911433381740309], [-0.6123387081306718], [0.8617707546596828], [0.11403407063558978], [0.5306302231632988], [2.0314445675259423], [-1.9742876683174124], [-0.831318737023442], [0.9685902809488388], [1.2356390966717292], [-0.01414936091139745], [1.5347337702813661], [0.4238106968741426], [-0.7832499501933214], [0.6748365836536595], [-1.648488113135486], [1.0647278546090795], [-0.11562791088609585], [-0.9808660738282604], [0.37040093372956445], [0.017896496975349414], [0.9792722335777544], [-0.3559718450366971], [-0.9701841211993447], [-1.3867802737270536], [1.353140575589801], [-0.7939319028222371], [-0.12096888720055367], [-0.3719947739800705], [-0.06221814774151786], [-1.1090495053752478], [-0.11028693457163805], [-1.317347581639102], [0.09801114169221646], [0.07664723643438522], [0.14607992852233664], [-0.01414936091139745], [0.2475584784970349], [-0.8366597133378996], [1.1395015230114884], [0.14073895220787894], [2.015421638582569], [-1.3707573447836803], [0.9044985651753451], [-0.8740465475391043], [-0.49483722921260004], [1.1395015230114884], [-0.44142746606802197], [0.2796043363837818], [0.738928299427153], [-2.059743289348737], [0.45585655476088943], [1.096773712495826], [0.5733580336789612], [0.9525673520054655], [-1.023593884343923], [-1.0129119317150073], [1.700304036029558], [-1.130413410633079], [1.080750783552453], [0.21017164429583035], [0.09801114169221646], [-0.9327972869981402], [-0.0942640056282646], [-1.4508719895005473], [0.6908595125970328], [0.017896496975349414], [-0.8847285001680198], [-1.0289348606583806], [-0.16903767403067385], [1.8765562544066656], [1.1181376177536573], [-0.6123387081306718], [-0.6016567555017561], [-0.22244743717525195], [0.8510888020307672], [-0.7351811633632013], [-1.4508719895005473], [0.22619457323920367], [-0.2918801292632034], [-0.04619521879814432], [0.220853596924746], [0.3276731232139022], [-0.008808384596939759], [-0.9381382633125979], [0.07664723643438522], [-0.8473416659668153], [-0.7031353054764544], [-0.5909748028728405], [0.7602922046849843], [-0.1476737687728426], [0.7656331809994422], [-1.1945051264065725], [-0.8740465475391043], [0.6481317020813704], [-0.04619521879814432], [0.3490370284717332], [-0.04619521879814432], [-0.17971962665958946], [0.5573351047355877], [0.5413121757922144], [1.0540459019801636], [-0.3079030582065768], [-1.4081441789848848], [-0.008808384596939759], [-0.5909748028728405], [0.0018735680319758635], [-0.8206367843945263], [1.2356390966717292], [-0.2544932950619988], [-0.28653915294874555], [-0.23847036611862538], [-0.4734733239547688], [-0.32392598714995025], [-0.964843144884887], [-0.5162011344704313], [0.37040093372956445], [0.017896496975349414], [-0.9274563106836823], [-0.6764304239041655], [-0.7244992107342857], [-1.6965568999656062], [-0.8954104527969355], [0.386423862672938], [1.2570030019295606], [-0.07824107668489118], [-0.43074551343910633], [0.028578449604265036], [-0.7512040923065747], [-0.2705162240053721], [0.1193750469500477], [2.0741723780416046], [-1.5523505394752457], [-1.183823173777657], [-1.3760983210981381], [-0.38267672660898616], [1.9620118754379907], [0.6267677968235391], [-0.8580236185957308], [-0.1957425556029629], [-0.17437865034513164], [0.023237473289807107], [-0.38801770292344395], [-1.595078349990908], [0.220853596924746], [0.5680170573645034], [-0.6443845660174187], [1.0380229730367905], [-0.3986996555523596], [0.18880773903799913], [-0.4574503950113954], [-0.18506060297404728], [-0.15835572140175821], [-0.852682642281273], [1.0326819967223322], [-1.237232936922235], [0.19948969166691474], [-0.1957425556029629], [0.2849453126982397], [1.4973469360801615], [-1.6591700657644017], [0.25289945481149284], [-0.4788143002692266], [0.3223321468994443], [0.5733580336789612], [0.9044985651753451], [0.04994235486209628], [2.8219090620656977], [-0.4360864897535641], [0.578699009993419], [-0.0942640056282646], [-0.6710894475897076], [-0.6764304239041655], [-0.030172289854771002], [0.15676188115125225], [-0.3986996555523596], [0.5947219389367925], [0.35437800478619114], [-0.38267672660898616], [-1.2746197711234395], [-0.16369669771621603], [0.5626760810500456], [-0.6176796844451296], [-0.13699181614392697], [-0.8473416659668153], [0.55199412842113], [0.1674438337801679], [-1.5096227289595834], [-0.6550665186463343], [1.2943898361307649], [-0.17437865034513164], [0.5199482705343832], [1.0487049256657057], [-0.7618860449354904], [0.8190429441440203], [-0.3185850108354924], [0.8137019678295624], [-0.548246992357178], [0.300968241641613], [-0.5856338265583827], [-0.11028693457163805], [0.5039253415910095], [0.7335873231126954], [-0.2544932950619988], [0.744269275741611], [-0.6390435897029607], [-0.4734733239547688], [0.37574191004402235], [-0.06755912405597556], [0.5733580336789612], [-2.1879267208957245], [-0.33994891609332367], [0.10869309432113208], [-1.1197314580041635], [0.18346676272354143], [-0.33994891609332367], [-0.33994891609332367], [-1.5096227289595834], [0.41846972055968484], [-0.32926696346440804], [-0.33994891609332367], [-0.6016567555017561], [-0.8687055712246464], [1.673599154457269], [0.08198821274884291], [0.5466531521066721], [-0.04619521879814432], [0.6908595125970328], [0.31165019427052865], [-0.8366597133378996], [0.4451746021319738], [1.3477995992753433], [1.3584815519042586], [0.39176483898739567], [-0.6710894475897076], [-0.28653915294874555], [-0.32392598714995025], [-1.7446256867957264], [0.24221750218257723], [0.3810828863584801], [0.09801114169221646], [-1.0022299790860916], [-0.04619521879814432], [-0.01949033722585538], [-0.16369669771621603], [0.7496102520560687], [0.08732918906330084], [-0.18506060297404728], [-1.0022299790860916], [-0.4627913713258532], [-0.6550665186463343], [0.46119753107534733], [0.6748365836536595], [2.250424596418712], [0.31165019427052865], [1.2516620256151023], [-0.8740465475391043], [-1.1624592685198256], [0.7709741573139], [-0.6016567555017561], [-0.3506308687222393], [-0.8366597133378996], [0.05528333117655397], [-0.9862070501427181], [-0.8900694764824777], [-0.249152318747541], [0.15676188115125225], [-1.3921212500415114], [-0.7832499501933214], [1.326435694017512], [0.46653850738980507], [1.8071235623187143], [-0.49483722921260004], [-1.0663216948595853], [0.6694956073392017], [-0.6764304239041655], [-1.4615539421294628], [-0.5696108976150093], [-1.4668949184439208], [0.028578449604265036], [-1.9101959525439187], [0.6534726783958283], [0.6962004889114908], [-0.7565450686210325], [0.658813654710286], [0.08198821274884291], [1.4920059597657038], [0.08198821274884291], [0.5039253415910095], [-0.8900694764824777], [-0.8099548317656107], [-0.035513266169228695], [1.2196161677283557], [-0.6924533528475388], [-0.16903767403067385], [-0.1423327924583848], [-1.4455310131860895], [0.5092663179054675], [0.17278481009462582], [2.5067914595126872], [-1.4562129658150051], [0.0659652838054696], [0.3490370284717332], [0.6374497494524547], [1.6415532965705224], [-0.745863115992117], [1.2035932387849821], [-0.3986996555523596], [-0.5055191818415157], [0.19948969166691474], [0.8404068494018515], [-0.606997731816214], [1.182229333527151], [1.3371176466464274], [-0.3719947739800705], [1.3477995992753433], [-0.9488202159415136], [-0.2972211055776612], [0.4451746021319738], [0.9739312572632967], [0.4398336258175161], [0.08198821274884291], [0.22619457323920367], [0.18346676272354143], [0.7122234178548641], [0.1247160232645054], [-1.0556397422306698], [0.3330140995283599], [0.35437800478619114], [1.4065503387343787], [-0.26517524769091444], [0.09801114169221646], [0.7122234178548641], [-0.040854242483686624], [-0.6871123765330811], [0.17278481009462582], [-0.12096888720055367], [0.4398336258175161], [-0.38267672660898616], [0.6427907257669127], [0.0659652838054696], [0.46119753107534733], [-0.5429060160427203], [0.5146072942199252], [0.45585655476088943], [-0.4147225844957329], [0.13005699957896333], [1.6896220834006426], [-0.6657484712752499], [0.04460137854763835], [-0.18506060297404728], [-1.1678002448342837], [-0.06221814774151786], [-0.8206367843945263], [0.220853596924746], [-0.8740465475391043], [0.35437800478619114], [-0.5909748028728405], [0.04994235486209628], [1.1608654282693198], [-0.6977943291619968], [1.524051817652451], [-0.6283616370740452], [1.9086021122934127], [-0.16369669771621603], [-0.23312938980416759], [0.738928299427153], [-0.7618860449354904], [-0.25983427137645665], [1.2997308124452225], [0.31165019427052865], [-0.5108601581559735], [0.033919425918722726], [0.3223321468994443], [-1.018252908029465], [0.9312034467476342], [0.04994235486209628], [0.3276731232139022], [1.4172322913632946], [-0.7191582344198278], [0.6855185362825752], [0.744269275741611], [0.023237473289807107], [0.6694956073392017], [0.9312034467476342], [0.08732918906330084], [-1.2692787948089819], [-1.5470095631607879], [-0.4574503950113954], [-1.2746197711234395], [-0.040854242483686624], [-0.05153619511260225], [-0.024831313540313073], [-0.38801770292344395], [1.1501834756404044], [0.909839541489803], [2.7364534410343726], [-0.4200635608101907], [-0.15835572140175821], [0.07664723643438522], [1.3104127650741384], [1.1608654282693198], [-0.8046138554511527], [-0.06221814774151786], [-0.526883087099347], [0.10869309432113208], [-1.1143904816897054], [2.4159948621669045], [0.7709741573139], [1.833828443891003], [-0.32926696346440804], [-2.4656574892475307], [-2.19860867352464], [-1.157118292205368], [0.25289945481149284], [1.2783669071873913], [-1.9315598578017499], [0.3276731232139022], [-0.36665379766561274], [-0.5856338265583827], [-1.7339437341668111], [-1.0129119317150073], [1.0006361388355856], [-0.035513266169228695], [-1.5470095631607879], [-0.36665379766561274], [0.8564297783452248], [-0.548246992357178], [-0.9968890027716338], [-0.1957425556029629], [-0.17971962665958946], [-0.5963157791872984], [-0.3132440345210346], [-1.2959836763812709], [1.3210947177030539], [0.1674438337801679], [0.578699009993419], [-1.7232617815378954], [0.3490370284717332], [-0.5535879686716358], [0.3490370284717332], [-0.6016567555017561], [0.30630921795607097], [-0.4734733239547688], [-0.825977760708984], [-0.20642450823187852], [-0.11562791088609585], [-1.8407632604559674], [-1.6271242078776549], [1.0593868782946216], [0.7068824415404064], [-1.4562129658150051], [-0.8580236185957308], [1.4706420545078724], [0.26892238375486616], [-1.4188261316138007], [0.9792722335777544], [1.0860917598669106], [1.1181376177536573], [0.5413121757922144], [-0.38801770292344395], [-0.7885909265077794], [-1.7659895920535578], [-0.2544932950619988], [-0.07824107668489118], [-0.6977943291619968], [-0.8954104527969355], [-0.083582052999349], [0.023237473289807107], [0.3169911705849866], [0.658813654710286], [-0.16903767403067385], [1.5026879123946195], [-0.3986996555523596], [-1.9903105972607857], [0.3971058153018536], [2.127582141186183], [0.29028628901269743], [-0.6283616370740452], [1.022000044093417], [-0.6016567555017561], [-0.04619521879814432], [-0.5215421107848891], [2.095536283299436], [-1.4562129658150051], [0.05528333117655397], [0.0659652838054696], [0.2368765258681193], [-0.45210941869693755], [0.6267677968235391], [-0.6283616370740452], [-1.050298765916212], [-1.3707573447836803], [0.3330140995283599], [-0.2918801292632034], [-0.8580236185957308], [0.16210285746571018], [-0.44676844238247976], [-1.2479148895511507], [0.5199482705343832], [0.8884756362319718], [-2.1345169577511465], [0.2742633600693241], [-0.040854242483686624], [0.9632493046343811], [1.0326819967223322], [1.4813240071367884], [2.229060691160881], [0.5199482705343832], [0.08732918906330084], [-1.8995139999150028], [-0.9808660738282604], [-0.9488202159415136], [-0.6817714002186231], [0.300968241641613], [-0.48949625289814225], [-0.45210941869693755], [1.2730259308729337], [0.6267677968235391], [1.1074556651247418], [-0.3346079397788659], [-2.118494028807773], [-0.9060924054258511], [0.2368765258681193], [-1.4401900368716316], [0.5252892468488408], [-1.5309866342174145], [0.039260402233180655], [2.1863328806452182], [0.18346676272354143], [-0.23847036611862538], [-1.1250724343186211], [-0.6497255423318763], [0.012555520660891484], [2.6670207489464213], [0.18346676272354143], [-1.183823173777657], [1.4279142439922101], [-0.6550665186463343], [0.386423862672938], [-1.3333705105824756], [-1.0716626711740431], [-2.0437203604053638], [0.2796043363837818], [-0.4200635608101907], [1.0059771151500434], [2.8699778488958176], [-0.11028693457163805], [-0.44676844238247976], [0.4825614363331784], [1.0487049256657057], [-1.4775768710728363], [3.7565799170958134], [-0.8152958080800683], [-0.15301474508730042], [0.1781257864090835], [-1.8300813078270515], [0.033919425918722726], [-2.5404311576499397], [-0.745863115992117], [0.31165019427052865], [0.7923380625717311], [0.18880773903799913], [-1.10370852906079], [-1.5470095631607879], [-0.17437865034513164], [-1.2799607474378976], [-1.157118292205368], [0.05528333117655397], [2.8432729673235286], [0.14073895220787894], [-1.2906427000668133], [-0.5215421107848891], [-0.9755250975138026], [-0.5642699213005515], [-0.40404063186681727], [0.3223321468994443], [0.39176483898739567], [-0.44676844238247976], [0.07130626011992729], [1.3317766703319698], [1.9406479701801593], [-0.9862070501427181], [0.028578449604265036], [-0.0889230293138068], [-0.12630986351501147], [-2.0116745025186167], [0.09267016537775853], [-0.13699181614392697], [-0.40404063186681727], [0.8884756362319718], [-1.9155369288583763], [-0.34528989240778146], [-1.0876856001174167], [-0.48949625289814225], [-1.157118292205368], [0.45051557844643175], [-1.1410953632619945], [0.6160858441946235], [-0.5322240634138047], [1.4385961966211258], [2.351903146393411], [1.6415532965705224], [-0.3506308687222393], [0.9525673520054655], [-0.40404063186681727], [0.2315355495536616], [0.15676188115125225], [-0.4734733239547688], [0.2849453126982397], [0.3169911705849866], [-0.7992728791366951], [0.1193750469500477], [-0.38267672660898616], [0.15676188115125225], [1.2943898361307649], [-0.7138172581053701], [-1.2692787948089819], [-1.488258823701752], [0.5893809626223345], [0.658813654710286], [-0.9488202159415136], [0.5359711994777565], [0.8938166125464294], [-0.32392598714995025], [-0.05153619511260225], [0.37574191004402235], [-0.6016567555017561], [0.4024467916163113], [2.4053129095379884], [0.7976790388861891], [2.026103591211484], [-0.9274563106836823], [-0.7298401870487435], [1.240980072986187], [0.6321087731379971], [0.033919425918722726], [-0.2918801292632034], [-0.2544932950619988], [-0.01949033722585538], [-0.1423327924583848], [-0.3559718450366971], [0.6641546310247439], [0.3490370284717332], [1.1288195703825732], [-0.5162011344704313], [1.0860917598669106], [0.5252892468488408], [0.5893809626223345], [0.9151805178042607], [0.2315355495536616], [0.5199482705343832], [0.9525673520054655], [-0.3986996555523596], [-1.4562129658150051], [0.18880773903799913], [-0.7992728791366951], [0.37040093372956445], [0.7923380625717311], [-0.06221814774151786], [-1.2479148895511507], [-1.2959836763812709], [0.8564297783452248], [-0.01414936091139745], [-0.05153619511260225], [-0.1316508398294693], [0.46119753107534733], [-0.09960498194272242], [-1.10370852906079], [-0.5535879686716358], [0.5306302231632988], [-2.4816804181909036], [-0.20642450823187852], [-0.1476737687728426], [1.1074556651247418], [0.7335873231126954], [0.18346676272354143], [-1.4455310131860895], [0.7709741573139], [0.39176483898739567], [-0.05153619511260225], [-1.4508719895005473], [-0.035513266169228695], [2.090195306984978], [1.2730259308729337], [0.033919425918722726], [0.2796043363837818], [1.2302981203572712], [-1.0716626711740431], [-0.21176548454633634], [-0.1423327924583848], [0.6641546310247439], [-1.5416685868463298], [-0.4147225844957329], [0.43449264950305816], [-0.34528989240778146], [0.2849453126982397], [0.04460137854763835], [1.2623439782440182], [0.41846972055968484], [-1.7553076394246423], [0.09267016537775853], [-0.01949033722585538], [-0.5055191818415157], [-2.033038407776448], [2.699066606833168], [-0.28119817663428776], [-0.48415527658368446], [-0.7618860449354904], [2.0581494490982313], [0.19948969166691474], [1.353140575589801], [-2.257359412983676], [0.19948969166691474], [0.9579083283199231], [-0.38267672660898616], [0.4985843652765519], [0.8030200152006468], [1.6041664623693177], [2.2130377622175073], [-2.203949649839098], [0.744269275741611], [0.15676188115125225], [0.5306302231632988], [-0.01949033722585538], [0.8671117309741405], [-0.9808660738282604], [0.3169911705849866], [0.033919425918722726], [-0.5055191818415157], [-0.8954104527969355], [-1.2746197711234395], [-0.9327972869981402], [3.7565799170958134], [0.5252892468488408], [-0.5375650397282624], [-1.653829089449944], [-0.49483722921260004], [0.6855185362825752], [-0.16369669771621603], [0.05528333117655397], [-0.23312938980416759], [0.7015414652259485], [0.6160858441946235], [0.17278481009462582], [1.1127966414391997], [1.1127966414391997], [1.5293927939669085], [0.10335211800667415], [0.08198821274884291], [-0.035513266169228695], [-1.183823173777657], [0.11403407063558978], [-1.1945051264065725], [-1.1624592685198256], [-0.16369669771621603], [-0.0034674082824818287], [0.24221750218257723], [-1.6111012789342816], [2.143605070129556], [-0.1904015792885051], [-1.675192994707775], [0.0606243074910119], [0.7282463467982376], [-2.3481560103294585], [-0.5856338265583827], [-0.15835572140175821], [0.07130626011992729], [-0.633702613388503], [3.462826219800634], [1.4920059597657038], [0.007214544346433793], [-0.6657484712752499], [0.4398336258175161], [0.6855185362825752], [-0.2438113424330832], [-0.6710894475897076], [-0.07824107668489118], [-0.7512040923065747], [0.13005699957896333], [-0.46813234764031103], [-0.7939319028222371], [-0.8580236185957308], [-2.3107691761282543], [-1.7499666631101845], [-0.1423327924583848], [0.3436960521572755], [0.039260402233180655], [0.30630921795607097], [-1.0930265764318743], [0.578699009993419], [-0.49483722921260004], [0.2796043363837818], [-1.3974622263559693], [0.11403407063558978], [0.386423862672938], [-2.9089585233475286], [0.37574191004402235], [1.1662064045837774], [1.0754098072379947], [-0.1957425556029629], [0.1247160232645054], [-2.0971301235499418], [-2.0757662182921104], [1.5667796281681128], [-0.8420006896523574], [-1.6591700657644017], [-0.26517524769091444], [-0.040854242483686624], [-0.06755912405597556], [0.1674438337801679], [-0.8206367843945263], [0.30630921795607097], [-1.2639378184945242], [-0.9488202159415136], [-0.024831313540313073], [-1.0983675527463321], [0.3330140995283599], [-0.8046138554511527], [0.2635814074404085], [0.15676188115125225], [1.2463210493006447], [-0.18506060297404728], [1.016659067778959], [-0.25983427137645665], [-0.26517524769091444], [-0.09960498194272242], [0.9525673520054655], [-0.7244992107342857], [-1.077003647488501], [-0.7138172581053701], [-0.6764304239041655], [-1.2212100079788617], [-0.5162011344704313], [1.240980072986187], [-0.3185850108354924], [0.49324338896209396], [-0.5642699213005515], [-0.6176796844451296], [1.9086021122934127], [-2.353496986643916], [-0.5375650397282624], [-0.3185850108354924], [-2.4977033471342773], [-0.6283616370740452], [-0.11562791088609585], [-1.5737144447330769], [-1.0342758369728384], [1.710985988658474], [-1.4241671079282583], [0.7122234178548641], [0.7976790388861891], [0.2315355495536616], [0.1674438337801679], [0.26892238375486616], [0.46119753107534733], [0.3436960521572755], [-0.5535879686716358], [-1.2318919606077774], [0.07130626011992729], [1.3905274097910056], [-0.9755250975138026], [-1.8781500946571716], [1.5934845097404022], [0.220853596924746], [1.9086021122934127], [0.744269275741611], [-2.1078120761788575], [0.14607992852233664], [-1.242573913236693], [-1.050298765916212], [-0.1476737687728426], [0.0659652838054696], [0.31165019427052865], [-0.9755250975138026], [0.21017164429583035], [0.2742633600693241], [-1.2532558658656086], [-0.0034674082824818287], [-1.1143904816897054], [-0.9274563106836823], [0.7602922046849843], [-0.9434792396270558], [-0.3346079397788659], [0.5573351047355877], [-0.008808384596939759], [0.37574191004402235], [0.1247160232645054], [0.3383550758428176], [-1.3066656290101866], [-0.21176548454633634], [-0.4200635608101907], [0.658813654710286], [-0.3933586792379018], [-0.1957425556029629], [-0.17971962665958946], [0.9312034467476342], [0.45051557844643175], [-0.911433381740309], [-1.846104236770425], [-0.34528989240778146], [-0.1316508398294693], [-0.9701841211993447], [1.6095074386837753], [-1.4935998000162096], [0.028578449604265036], [-1.0930265764318743], [-0.48949625289814225], [-0.024831313540313073], [0.30630921795607097], [0.8404068494018515], [0.7122234178548641], [-1.5203046815884986], [1.7697367281175098], [0.04460137854763835], [0.5466531521066721], [1.7697367281175098], [-1.2158690316644039], [0.6427907257669127], [0.023237473289807107], [-0.7138172581053701], [0.8083609915151047], [0.017896496975349414], [0.3383550758428176], [0.8457478257163092], [-0.07290010037043337], [0.9472263756910075], [0.0659652838054696], [1.022000044093417], [-0.01949033722585538], [0.6160858441946235], [-0.40404063186681727], [0.5733580336789612], [0.5947219389367925], [0.6107448678801658], [0.10869309432113208], [1.2356390966717292], [-0.07824107668489118], [0.09267016537775853], [-0.4788143002692266], [0.023237473289807107], [-0.8099548317656107], [-0.3079030582065768], [-1.1410953632619945], [0.46653850738980507], [-0.38267672660898616], [-0.17971962665958946], [0.9472263756910075], [0.26892238375486616], [-0.22778841348970977], [-0.28119817663428776], [-0.548246992357178], [-0.21710646086079413], [1.8231464912620878], [-0.1904015792885051], [-0.030172289854771002], [0.10335211800667415], [0.2849453126982397], [-0.28119817663428776], [-0.6016567555017561], [0.936544423062092], [-0.3079030582065768], [1.5614386518536552], [-1.7446256867957264], [-1.2051870790354882], [-0.06755912405597556], [1.9246250412367862], [-0.4360864897535641], [-0.07824107668489118], [-0.7939319028222371], [-1.6645110420788596], [0.18880773903799913], [0.9258624704331763], [0.744269275741611], [0.9579083283199231], [0.8137019678295624], [0.8938166125464294], [-1.2746197711234395], [0.6054038915657078], [-1.9903105972607857], [-0.48415527658368446], [-0.27585720031982996], [1.1074556651247418], [1.6362123202560648], [-1.0022299790860916], [0.5573351047355877], [0.0018735680319758635], [0.1193750469500477], [-0.13699181614392697], [-0.6390435897029607], [-0.030172289854771002], [1.043363949351248], [-1.8888320472860876], [1.2516620256151023], [-0.48415527658368446], [1.3317766703319698], [-0.2972211055776612], [0.15676188115125225], [-1.0396168132872963], [0.2475584784970349], [0.55199412842113], [-0.7084762817909123], [0.16210285746571018], [0.2475584784970349], [-0.38267672660898616], [-1.1891641500921148], [3.516235982945213], [-1.685874947336691], [-0.302562081892119], [-0.49483722921260004], [0.22619457323920367], [-0.28653915294874555], [0.2368765258681193], [-1.2265509842933193], [1.2035932387849821], [0.55199412842113], [0.5626760810500456], [-1.5470095631607879], [-0.3933586792379018], [-0.2918801292632034], [-2.3107691761282543], [-1.2692787948089819], [1.022000044093417], [0.9044985651753451], [1.0380229730367905], [-1.050298765916212], [-0.5589289449860937], [1.0593868782946216], [-1.0663216948595853], [0.08198821274884291], [1.3371176466464274], [-0.8099548317656107], [-0.6497255423318763], [0.35437800478619114], [-0.48415527658368446], [0.5359711994777565], [-0.16369669771621603], [1.9620118754379907], [-0.9434792396270558], [-1.4668949184439208], [-0.4200635608101907], [-1.5309866342174145], [-0.5429060160427203], [-0.42540453712464854], [-1.023593884343923], [0.4238106968741426], [-0.8206367843945263], [-0.23847036611862538], [0.14607992852233664], [-0.8847285001680198], [-0.7405221396776591], [-0.48949625289814225], [-0.27585720031982996], [-0.26517524769091444], [-0.7939319028222371], [0.012555520660891484], [-1.2265509842933193], [-0.3933586792379018], [1.3317766703319698], [-1.2853017237523554], [-0.249152318747541], [-0.852682642281273], [-0.4360864897535641], [-1.6378061605065706], [-0.15301474508730042], [-0.34528989240778146], [0.4291516731886005], [0.738928299427153], [-0.6016567555017561], [-0.6016567555017561], [-2.4122477261029527], [-0.2972211055776612], [-0.21176548454633634], [-2.7914570444294564], [1.1181376177536573], [1.0647278546090795], [0.5893809626223345], [-0.15835572140175821], [1.833828443891003], [-0.15835572140175821], [-0.6710894475897076], [-0.01414936091139745], [-1.3387114868969334], [-2.033038407776448], [0.09267016537775853], [-0.28119817663428776], [-0.1423327924583848], [-0.44142746606802197], [1.7537137991741363], [0.2475584784970349], [0.3597189811006488], [0.7068824415404064], [-1.7125798289089798], [-0.8847285001680198], [0.37040093372956445], [0.5146072942199252], [-0.1957425556029629], [-0.6497255423318763], [0.37040093372956445], [-0.26517524769091444], [-1.8621271657137985], [0.15142090483679457], [-0.07824107668489118], [-0.8793875238535621], [0.9952951625211279], [-0.28653915294874555], [-1.0823446238029586], [2.1062182359283517], [0.24221750218257723], [0.2315355495536616], [-0.8420006896523574], [-1.4401900368716316], [2.8860007778391914], [-1.5096227289595834], [0.46119753107534733], [0.6962004889114908], [-0.11028693457163805], [0.8671117309741405], [-0.49483722921260004], [-2.476339441876446], [0.7709741573139], [-0.3132440345210346], [-0.5322240634138047], [-0.7939319028222371], [-0.2010835319174207], [-0.3933586792379018], [-1.3013246526957287], [-0.7992728791366951], [1.1127966414391997], [-1.0609807185451274], [0.5733580336789612], [-1.514963705274041], [1.2249571440428135], [-0.21710646086079413], [0.4398336258175161], [0.39176483898739567], [1.9459889464946172], [0.9525673520054655], [-1.9689466920029546], [-0.9221153343692245], [-0.06755912405597556], [-0.9488202159415136], [2.944751517298227], [1.6255303676271489], [1.1234785940681153], [1.326435694017512], [0.0018735680319758635], [0.5466531521066721], [1.0059771151500434], [-0.8740465475391043], [-0.6283616370740452], [-0.035513266169228695], [0.738928299427153], [1.011318091464501], [2.3412211937644947], [-0.7618860449354904], [1.700304036029558], [0.3490370284717332], [-0.7351811633632013], [-1.3333705105824756], [0.007214544346433793], [-1.023593884343923], [-0.18506060297404728], [-1.0022299790860916], [0.07130626011992729], [0.578699009993419], [2.314516312192206], [-2.038379384090906], [0.3223321468994443], [-0.6016567555017561], [0.09267016537775853], [0.3169911705849866], [0.3169911705849866], [0.37574191004402235], [-1.349393439525849], [0.7656331809994422], [-0.030172289854771002], [-1.2746197711234395], [-0.7565450686210325], [0.04994235486209628], [0.5733580336789612], [-0.8473416659668153], [-1.0342758369728384], [-2.7166833760270475], [-0.6924533528475388], [-0.8473416659668153], [0.09267016537775853], [0.5199482705343832], [-0.1316508398294693], [-1.1464363395764523], [0.3597189811006488], [0.1674438337801679], [0.6321087731379971], [-0.11562791088609585], [1.3317766703319698], [-1.5096227289595834], [0.14607992852233664], [0.20483066798137242], [0.21551262061028806], [-0.660407494960792], [0.49324338896209396], [0.2582404311259505], [-0.5055191818415157], [-0.9167743580547667], [-1.1891641500921148], [0.9205214941187186], [0.08198821274884291], [-0.9327972869981402], [-0.2544932950619988], [2.7364534410343726], [0.18346676272354143], [0.26892238375486616], [2.5067914595126872], [-0.2705162240053721], [-0.4093816081812751], [0.21017164429583035], [0.46653850738980507], [0.8190429441440203], [-0.7992728791366951], [3.804648703925934], [0.5199482705343832], [0.1781257864090835], [0.2475584784970349], [-1.1143904816897054], [-0.548246992357178], [-0.580292850243925], [-1.130413410633079], [-1.3387114868969334], [0.7602922046849843], [-0.7405221396776591], [-0.18506060297404728], [1.0273410204078746], [0.9472263756910075], [0.8831346599175138], [0.08732918906330084], [-0.06221814774151786], [0.007214544346433793], [0.039260402233180655], [-1.1357543869475368], [0.2635814074404085], [0.09267016537775853], [0.4024467916163113], [0.4398336258175161], [0.19948969166691474], [-1.4668949184439208], [-0.34528989240778146], [-0.3185850108354924], [0.8831346599175138], [-0.15835572140175821], [1.0540459019801636], [0.9472263756910075], [-0.44676844238247976], [0.5466531521066721], [1.022000044093417], [-1.1090495053752478], [0.05528333117655397], [0.7976790388861891], [0.7122234178548641], [0.3276731232139022], [-1.2479148895511507], [-0.6924533528475388], [-0.6176796844451296], [0.6427907257669127], [0.8671117309741405], [0.21551262061028806], [-0.4788143002692266], [-1.8514452130848826], [-0.040854242483686624], [2.2664475253620857], [-0.46813234764031103], [-0.4734733239547688], [-1.237232936922235], [1.214275191413898], [-0.0034674082824818287], [-0.8740465475391043], [1.1341605466970308], [1.1234785940681153], [-0.44142746606802197], [1.240980072986187], [-1.10370852906079], [-0.2544932950619988], [0.909839541489803], [0.2635814074404085], [-0.3986996555523596], [-1.0930265764318743], [-0.46813234764031103], [-0.48949625289814225], [-0.1957425556029629], [-0.11028693457163805], [-0.7725679975644059], [-0.01414936091139745], [-0.06221814774151786], [0.2849453126982397], [-0.34528989240778146], [-0.7244992107342857], [0.8030200152006468], [1.4920059597657038], [-0.1904015792885051], [0.9525673520054655], [-0.05687717142705993], [-1.0075709554005494], [0.1247160232645054], [-0.6283616370740452], [-1.0716626711740431], [0.46653850738980507], [-0.1316508398294693], [0.033919425918722726], [0.7869970862572735], [0.5413121757922144], [1.2623439782440182], [-1.819399355198136], [-0.831318737023442], [-1.5576915157897036], [1.315753741388596], [0.5092663179054675], [-0.3132440345210346], [-2.203949649839098], [-0.580292850243925], [-2.305428199813796], [-1.4028032026704271], [-2.022356455147533], [0.8564297783452248], [0.7015414652259485], [0.7869970862572735], [-1.3066656290101866], [0.135397975893421], [0.9205214941187186], [0.2742633600693241], [-0.249152318747541], [0.039260402233180655], [2.3786080279657], [-0.0942640056282646], [0.18880773903799913], [-0.2705162240053721], [0.6694956073392017], [-0.34528989240778146], [1.0860917598669106], [-1.0609807185451274], [0.09801114169221646], [0.220853596924746], [-0.32392598714995025], [-0.4627913713258532], [1.1074556651247418], [-0.035513266169228695], [-0.04619521879814432], [-0.6283616370740452], [0.4291516731886005], [-0.01949033722585538], [1.9566708991235329], [-2.5030443234487354], [0.578699009993419], [-1.1891641500921148], [0.7976790388861891], [-0.5589289449860937], [0.7496102520560687], [1.5507566992247397], [0.8724527072885981], [-0.2544932950619988], [-0.1957425556029629], [0.7229053704837797], [1.6949630597151004], [-1.7018978762800643], [0.9472263756910075], [1.2997308124452225], [-0.2705162240053721], [-1.1891641500921148], [-0.3719947739800705], [1.3210947177030539], [-0.5375650397282624], [-0.5322240634138047], [1.7911006333753412], [0.3597189811006488], [-0.9862070501427181], [0.7335873231126954], [-1.1143904816897054], [0.14073895220787894], [-0.5535879686716358], [-1.1784821974631992], [-0.4200635608101907], [0.7335873231126954], [-0.2918801292632034], [-1.9529237630595813], [-0.7351811633632013], [2.8432729673235286], [0.5199482705343832], [1.5454157229102816], [-0.17971962665958946], [-1.242573913236693], [0.3223321468994443], [0.24221750218257723], [-1.4508719895005473], [0.8884756362319718], [0.8457478257163092], [-1.5096227289595834], [0.909839541489803], [-1.595078349990908], [-1.0289348606583806], [-0.580292850243925], [0.658813654710286], [-0.5375650397282624], [-0.8633645949101887], [-0.9595021685704291], [0.31165019427052865], [-2.3802018682162056], [-0.32392598714995025], [0.2635814074404085], [-0.3132440345210346], [0.18346676272354143], [-0.42540453712464854], [-0.8633645949101887], [-0.7565450686210325], [0.3223321468994443], [0.023237473289807107], [0.47722046001872065], [-0.15835572140175821], [0.1193750469500477], [1.4439371729355837], [-0.46813234764031103], [-0.3933586792379018], [-0.4734733239547688], [-0.6977943291619968], [-0.6657484712752499], [0.22619457323920367], [-0.1957425556029629], [-0.3185850108354924], [0.6427907257669127], [-1.3440524632113913], [0.6267677968235391], [1.1875703098416086], [0.18880773903799913], [0.5947219389367925], [1.4920059597657038], [0.8777936836030561], [0.7122234178548641], [0.3330140995283599], [-0.8633645949101887], [0.2582404311259505], [1.7804186807464253], [1.9993987096391954], [-2.257359412983676], [-0.36665379766561274], [-0.45210941869693755], [-0.26517524769091444], [1.6896220834006426], [0.2796043363837818], [-0.3613128213511549], [0.033919425918722726], [0.3971058153018536], [0.37040093372956445], [-0.5696108976150093], [0.29562726532715533], [0.7656331809994422], [-1.1891641500921148], [-0.49483722921260004], [-0.8366597133378996], [0.8350658730873937], [-0.911433381740309], [-0.3506308687222393], [0.9044985651753451], [0.220853596924746], [0.017896496975349414], [1.0540459019801636], [0.7335873231126954], [-0.8847285001680198], [0.26892238375486616], [-0.13699181614392697], [-0.8847285001680198], [-0.6283616370740452], [0.07664723643438522], [0.6801775599681172], [-0.05153619511260225], [-2.6525916602535538], [0.30630921795607097], [-0.3079030582065768], [-0.9968890027716338], [-1.0716626711740431], [-0.7298401870487435], [2.2237197148464234], [0.135397975893421], [0.24221750218257723], [0.55199412842113], [-0.9968890027716338], [-0.45210941869693755], [1.5774615807970287], [-0.548246992357178], [-0.23312938980416759], [0.6694956073392017], [0.37574191004402235], [-0.44142746606802197], [-0.9755250975138026], [-0.5642699213005515], [0.04460137854763835], [-1.1517773158909101], [-0.01949033722585538], [-0.7191582344198278], [-0.7031353054764544], [0.0606243074910119], [0.2582404311259505], [0.41312874424522694], [-0.606997731816214], [-0.660407494960792], [-0.22244743717525195], [-1.3867802737270536], [-0.16369669771621603], [-0.2438113424330832], [-0.01414936091139745], [-1.9369008341162077], [-1.3707573447836803], [-1.488258823701752], [0.19948969166691474], [0.41312874424522694], [-0.5642699213005515], [0.37574191004402235], [0.6160858441946235], [-0.46813234764031103], [1.7750777044319677], [0.8564297783452248], [0.033919425918722726], [-1.1945051264065725], [0.3971058153018536], [-0.44676844238247976], [0.47722046001872065], [-0.8687055712246464], [-0.3346079397788659], [0.25289945481149284], [-1.2158690316644039], [-0.5429060160427203], [-1.5363276105318722], [-0.024831313540313073], [-0.46813234764031103], [-0.4147225844957329], [-1.3867802737270536], [1.2035932387849821], [-0.8046138554511527], [-0.38801770292344395], [-0.38801770292344395], [1.6095074386837753], [0.8137019678295624], [-0.5429060160427203], [-0.15301474508730042], [-0.3506308687222393], [0.55199412842113], [0.0606243074910119], [2.9928203041283474], [1.155524451954862], [-1.1998461027210305], [-0.2544932950619988], [-0.7672270212499481], [-0.249152318747541], [-0.6817714002186231], [0.8350658730873937], [0.10869309432113208], [-0.3559718450366971], [0.6107448678801658], [0.028578449604265036], [-0.5909748028728405], [0.5947219389367925], [1.6415532965705224], [0.14607992852233664], [0.5092663179054675], [0.4398336258175161], [-0.38801770292344395], [-0.9968890027716338], [0.007214544346433793], [-0.17971962665958946], [-0.6443845660174187], [-1.5256456579029567], [-1.9742876683174124], [0.3810828863584801], [0.8137019678295624], [-1.4028032026704271], [0.7923380625717311], [0.46119753107534733], [-0.8793875238535621], [-0.26517524769091444], [-0.8633645949101887], [-0.526883087099347], [-0.5001782055270578], [0.41312874424522694], [1.1768883572126934], [-0.06221814774151786], [-0.17437865034513164], [-0.9755250975138026], [0.2742633600693241], [0.2582404311259505], [-0.024831313540313073], [-0.7832499501933214], [-0.9167743580547667], [0.55199412842113], [-0.43074551343910633], [0.6267677968235391], [-1.050298765916212], [0.386423862672938], [1.710985988658474], [-0.964843144884887], [0.7015414652259485], [0.4451746021319738], [-0.7885909265077794], [-1.2906427000668133], [-0.3933586792379018], [0.39176483898739567], [-1.0289348606583806], [-0.38801770292344395], [2.656338796317505], [0.7923380625717311], [1.2302981203572712], [-1.32268855795356], [1.5187108413379926], [-0.8580236185957308], [-0.6924533528475388], [0.10335211800667415], [-0.20642450823187852], [-0.660407494960792], [-0.1316508398294693], [-0.6176796844451296], [-1.675192994707775], [-0.6497255423318763], [2.6937256305187103], [-0.4147225844957329], [-0.21710646086079413], [2.3786080279657], [-0.6390435897029607], [0.05528333117655397], [1.2249571440428135], [0.8404068494018515], [0.10869309432113208], [-0.6710894475897076], [0.4985843652765519], [0.14607992852233664], [0.5733580336789612], [0.4238106968741426], [-0.16369669771621603], [-0.44142746606802197], [-0.12630986351501147], [0.45585655476088943], [0.9205214941187186], [0.744269275741611], [1.6415532965705224], [-0.32926696346440804], [0.14607992852233664], [1.8284874675765455], [-0.07824107668489118], [-1.077003647488501], [0.09267016537775853], [0.6855185362825752], [-0.5108601581559735], [-0.22778841348970977], [-0.6924533528475388], [0.7015414652259485], [0.26892238375486616], [0.7602922046849843], [-1.6378061605065706], [-0.4734733239547688], [-0.21710646086079413], [1.1448424993259463], [-0.6924533528475388], [-0.7138172581053701], [0.04994235486209628], [-0.5589289449860937], [-1.4401900368716316], [1.326435694017512], [0.3597189811006488], [-0.04619521879814432], [-0.302562081892119], [0.0659652838054696], [-0.5055191818415157], [-0.4093816081812751], [0.5146072942199252], [-0.6871123765330811], [-2.123835005122231], [-1.7179208052234376], [-1.2265509842933193], [-0.0889230293138068], [-1.0075709554005494], [-0.26517524769091444], [-0.660407494960792], [-1.1143904816897054], [-1.4401900368716316], [-0.9755250975138026], [0.5466531521066721], [-0.548246992357178], [-0.3559718450366971], [0.220853596924746], [-2.182585744581267], [1.0487049256657057], [-0.2972211055776612], [1.1982522624705245], [-0.8046138554511527], [-0.8847285001680198], [0.19414871535245706], [1.3104127650741384], [0.7335873231126954], [-0.01414936091139745], [-0.17437865034513164], [0.08732918906330084], [0.05528333117655397], [1.011318091464501], [0.29562726532715533], [0.5680170573645034], [-0.7992728791366951], [-0.1957425556029629], [0.24221750218257723], [2.3412211937644947], [0.8190429441440203], [-0.9968890027716338], [-0.6230206607595874], [0.1781257864090835], [-0.5749518739294671], [0.8831346599175138], [-0.3079030582065768], [-1.675192994707775], [0.012555520660891484], [0.3276731232139022], [-1.8247403315125938], [-1.9636057156884965], [-0.25983427137645665], [-0.0942640056282646], [-1.3814392974125957], [0.7869970862572735], [-1.3066656290101866], [-0.5108601581559735], [-1.1410953632619945], [-0.7351811633632013], [-0.5909748028728405], [-1.4722358947583785], [-0.5429060160427203], [0.2368765258681193], [-0.06221814774151786], [-0.9701841211993447], [2.592247080544012], [0.25289945481149284], [0.5306302231632988], [-0.2918801292632034], [0.40778776793076926], [0.18346676272354143], [-0.27585720031982996], [-2.0116745025186167], [-0.38801770292344395], [-0.4200635608101907], [0.41312874424522694], [-0.7298401870487435], [0.2635814074404085], [-0.6977943291619968], [-1.3066656290101866], [0.4238106968741426], [-0.9595021685704291], [-0.9434792396270558], [0.29028628901269743], [1.1074556651247418], [0.6214268205090815], [0.6694956073392017], [-1.0983675527463321], [0.5733580336789612], [-0.13699181614392697], [-1.5630324921041612], [2.1382640938150983], [-2.252018436669218], [0.9044985651753451], [-1.1410953632619945], [-1.1678002448342837], [-0.11028693457163805], [0.17278481009462582], [-0.0034674082824818287], [-1.0983675527463321], [1.9353069938657017], [-0.44676844238247976], [-0.3559718450366971], [-0.0889230293138068], [0.46119753107534733], [1.5667796281681128], [0.11403407063558978], [-0.9221153343692245], [0.9792722335777544], [1.1608654282693198], [0.10335211800667415], [-0.12630986351501147], [-0.9221153343692245], [1.4813240071367884], [0.2582404311259505], [-0.6283616370740452], [-0.26517524769091444], [2.1008772596138936], [-0.6123387081306718], [-0.5535879686716358], [1.3104127650741384], [0.7923380625717311], [0.7923380625717311], [0.7923380625717311], [-0.10494595825718023], [-0.6977943291619968], [-0.5055191818415157], [0.3810828863584801], [-0.5856338265583827], [0.5092663179054675], [-0.6443845660174187], [-0.43074551343910633], [-0.7512040923065747], [2.1916738569596768], [0.04994235486209628], [0.9525673520054655], [-0.9755250975138026], [-0.6924533528475388], [-0.6871123765330811], [-2.1719037919523507], [-1.926218881487292], [-0.3719947739800705], [-0.20642450823187852], [0.2796043363837818], [-0.5322240634138047], [1.3851864334765476], [0.30630921795607097], [-1.018252908029465], [-0.23847036611862538], [0.8617707546596828], [0.9472263756910075], [-1.2265509842933193], [1.4172322913632946], [-0.030172289854771002], [-0.28119817663428776], [-1.237232936922235], [-2.0437203604053638], [-0.7832499501933214], [1.3317766703319698], [0.5359711994777565], [-0.3986996555523596], [0.09267016537775853], [0.658813654710286], [1.9139430886078705], [-1.130413410633079], [-0.12096888720055367], [-0.09960498194272242], [0.14073895220787894], [-1.1464363395764523], [1.1448424993259463], [-0.1904015792885051], [0.012555520660891484], [-1.4241671079282583], [0.7709741573139], [-0.22778841348970977], [-1.2853017237523554], [-0.48415527658368446], [-0.26517524769091444], [-1.8300813078270515], [-0.4147225844957329], [0.15142090483679457], [-0.44142746606802197], [0.40778776793076926], [-0.580292850243925], [0.0606243074910119], [-2.5511131102788553], [0.37040093372956445], [-0.06755912405597556], [0.39176483898739567], [0.6481317020813704], [0.7869970862572735], [-2.1772447682668092], [-0.6871123765330811], [1.7750777044319677], [0.5199482705343832], [-2.241336484040303], [0.6107448678801658], [0.9685902809488388], [-0.4574503950113954], [0.4451746021319738], [-0.21176548454633634], [0.7229053704837797], [0.45585655476088943], [-0.3613128213511549], [0.11403407063558978], [0.1193750469500477], [-0.16369669771621603], [-1.7072388525945221], [-1.846104236770425], [-0.44676844238247976], [-0.6817714002186231], [-1.8834910709716295], [0.3330140995283599], [0.6267677968235391], [0.2796043363837818], [0.8190429441440203], [-0.3559718450366971], [-0.249152318747541], [-0.7779089738788638], [-0.28119817663428776], [0.18346676272354143], [-0.6283616370740452], [1.022000044093417], [1.0647278546090795], [-0.06755912405597556], [-1.157118292205368], [1.214275191413898], [0.017896496975349414], [-0.01414936091139745], [-0.302562081892119], [-0.44676844238247976], [0.7335873231126954], [-0.18506060297404728], [-0.302562081892119], [-0.7298401870487435], [2.250424596418712], [1.700304036029558], [-0.3079030582065768], [-0.15301474508730042], [1.8391694202054614], [-0.15835572140175821], [0.5359711994777565], [-0.22778841348970977], [0.5413121757922144], [0.017896496975349414], [-1.9369008341162077], [-1.6378061605065706], [0.3810828863584801], [-0.9007514291113933], [1.326435694017512], [0.09267016537775853], [2.81656808575124], [-0.7298401870487435], [-0.01414936091139745], [0.300968241641613], [-0.5162011344704313], [0.7335873231126954], [0.49324338896209396], [0.41846972055968484], [-1.0396168132872963], [0.04994235486209628], [-0.8206367843945263], [1.5026879123946195], [-0.01414936091139745], [-0.8847285001680198], [-1.349393439525849], [-0.6871123765330811], [-1.8941730236005452], [0.5199482705343832], [-0.32392598714995025], [0.7976790388861891], [2.202355809588592], [-0.9434792396270558], [-0.7031353054764544], [0.9044985651753451], [0.2742633600693241], [0.300968241641613], [0.1193750469500477], [0.7656331809994422], [-0.33994891609332367], [1.9780348043813643], [-0.22244743717525195], [0.9632493046343811], [-0.3185850108354924], [1.2676849545584759], [-0.15835572140175821], [0.717564394169322], [2.25576557273317], [1.7270089176018475], [-0.6977943291619968], [2.261106549047628], [-0.7244992107342857], [-2.679296541825843], [-0.28653915294874555], [-1.9208779051728342], [-1.1784821974631992], [0.55199412842113], [2.0474674964693156], [2.613610985801843], [-0.831318737023442], [0.21551262061028806], [1.155524451954862], [-0.0034674082824818287], [-1.2158690316644039], [-0.1904015792885051], [1.070068830923537], [0.4024467916163113], [-0.5162011344704313], [0.386423862672938], [0.5252892468488408], [2.261106549047628], [0.5733580336789612], [-0.548246992357178], [0.29562726532715533], [1.9246250412367862], [-0.6123387081306718], [-0.23847036611862538], [-0.4200635608101907], [-0.9862070501427181], [0.3650599574151068], [0.6801775599681172], [-1.3066656290101866], [-1.4508719895005473], [0.6908595125970328], [-0.44142746606802197], [-1.8941730236005452], [0.46119753107534733], [0.135397975893421], [-0.17437865034513164], [-0.6176796844451296], [0.6107448678801658], [0.8350658730873937], [1.011318091464501], [1.8284874675765455], [-0.0034674082824818287], [-0.6657484712752499], [-1.7820125209969313], [-0.28653915294874555], [0.3650599574151068], [-0.07824107668489118], [2.052808472783773], [-1.5630324921041612], [0.2475584784970349], [1.881897230721124], [-0.7885909265077794], [0.17278481009462582], [-0.3185850108354924], [-0.8099548317656107], [-0.04619521879814432], [0.8030200152006468], [0.220853596924746], [-0.37733575029452837], [-0.16903767403067385], [0.7656331809994422], [0.19414871535245706], [1.7537137991741363], [2.1970148332741344], [1.7430318465452206], [-0.633702613388503], [0.6321087731379971], [-1.2906427000668133], [0.9044985651753451], [-1.130413410633079], [-0.26517524769091444], [1.20893421509944], [-0.7351811633632013], [-0.2010835319174207], [-0.7084762817909123], [0.05528333117655397], [-0.6924533528475388], [0.0018735680319758635], [1.1341605466970308], [-0.7992728791366951], [0.39176483898739567], [0.9312034467476342], [-0.302562081892119], [-0.25983427137645665], [-0.7725679975644059], [0.26892238375486616], [-0.48949625289814225], [2.6029290331729276], [1.2730259308729337], [-0.9595021685704291], [-0.0034674082824818287], [0.8831346599175138], [-1.157118292205368], [-1.0289348606583806], [1.6949630597151004], [-0.07290010037043337], [2.116900188557267], [-1.0556397422306698], [-0.8366597133378996], [2.261106549047628], [-0.0889230293138068], [1.2196161677283557], [0.7068824415404064], [2.4907685305693135], [-3.3896463916487307], [0.16210285746571018], [2.229060691160881], [-0.6657484712752499], [0.4985843652765519], [0.7709741573139], [-2.203949649839098], [-0.526883087099347], [1.2676849545584759], [-0.44142746606802197], [0.6641546310247439], [-0.22244743717525195], [0.8831346599175138], [0.17278481009462582], [0.6000629152512502], [-1.1250724343186211], [-0.606997731816214], [-0.44142746606802197], [-0.36665379766561274], [-0.21176548454633634], [-0.22778841348970977], [-0.21710646086079413], [-1.675192994707775], [0.9579083283199231], [0.5146072942199252], [-1.3120066053246444], [-0.7725679975644059], [-0.17971962665958946], [-1.1464363395764523], [3.8633994433849694], [-1.1678002448342837], [-0.2010835319174207], [-0.9007514291113933], [0.09801114169221646], [-0.6817714002186231], [-0.024831313540313073], [-0.09960498194272242], [1.2356390966717292], [0.45585655476088943], [-0.7672270212499481], [-1.157118292205368], [0.47722046001872065], [1.4385961966211258], [1.1608654282693198], [0.9418853993765498], [0.8350658730873937], [1.0273410204078746], [-0.9541611922559713], [1.1341605466970308], [-0.06755912405597556], [-2.225313555096929], [0.5146072942199252], [-0.3613128213511549], [-0.8793875238535621], [-1.157118292205368], [-0.3719947739800705], [-2.1078120761788575], [-1.6217832315631973], [-0.6550665186463343], [-0.15835572140175821], [1.4332552203066677], [1.0540459019801636], [-0.4360864897535641], [-2.225313555096929], [-0.4574503950113954], [2.314516312192206], [0.4024467916163113], [-1.1517773158909101], [-0.1316508398294693], [0.8137019678295624], [-0.42540453712464854], [0.023237473289807107], [0.10335211800667415], [0.18880773903799913], [-2.257359412983676], [-0.13699181614392697], [-0.28119817663428776], [-0.035513266169228695], [-0.9755250975138026], [2.1596279990729297], [-0.25983427137645665], [1.9673528517524483], [-1.1945051264065725], [2.2183787385319658], [-0.20642450823187852], [0.017896496975349414], [-1.0823446238029586], [-0.4734733239547688], [2.7631583226066616], [0.4825614363331784], [-1.0129119317150073], [-0.2010835319174207], [0.6000629152512502], [0.21551262061028806], [1.1448424993259463], [0.1781257864090835], [-0.7885909265077794], [-0.3346079397788659], [-0.2544932950619988], [-0.12630986351501147], [0.16210285746571018], [-1.4775768710728363], [0.4398336258175161], [0.3276731232139022], [-0.5589289449860937], [-0.4147225844957329], [-0.9541611922559713], [0.9312034467476342], [0.386423862672938], [-0.21176548454633634], [-0.7191582344198278], [0.2368765258681193], [0.6481317020813704], [0.5893809626223345], [-0.7885909265077794], [2.1863328806452182], [0.09267016537775853], [-0.21176548454633634], [-0.44676844238247976], [-0.008808384596939759], [-0.1423327924583848], [-0.6390435897029607], [0.7229053704837797], [0.5199482705343832], [-0.7191582344198278], [0.09801114169221646], [-0.3559718450366971], [-1.0289348606583806], [-0.1957425556029629], [-0.8900694764824777], [-0.04619521879814432], [0.8617707546596828], [-0.12096888720055367], [0.3597189811006488], [-1.434849060557174], [-1.0075709554005494], [-0.1957425556029629], [-0.991548026457176], [1.9406479701801593], [-1.0930265764318743], [-0.48949625289814225], [-0.7725679975644059], [-0.4093816081812751], [0.43449264950305816], [-0.27585720031982996], [0.47187948370426275], [-0.18506060297404728], [-0.8847285001680198], [2.6616797726319636], [-0.8152958080800683], [-0.12096888720055367], [-0.8046138554511527], [1.0006361388355856], [-0.07824107668489118], [-0.7138172581053701], [-1.2959836763812709], [0.41312874424522694], [-0.1476737687728426], [1.0860917598669106], [1.673599154457269], [1.3050717887596808], [-0.45210941869693755], [1.513369865023535], [-0.4574503950113954], [0.18880773903799913], [0.39176483898739567], [-0.9595021685704291], [-0.17437865034513164], [-0.1957425556029629], [1.1288195703825732], [0.744269275741611], [-0.9755250975138026], [-1.8834910709716295], [0.5252892468488408], [-1.2051870790354882], [-0.3613128213511549], [-0.48949625289814225], [-0.8366597133378996], [-0.4574503950113954], [0.1781257864090835], [2.7364534410343726], [2.837931991009071], [-1.2212100079788617], [1.214275191413898], [-0.302562081892119], [-0.27585720031982996], [0.2368765258681193], [0.46119753107534733], [-2.203949649839098], [1.326435694017512], [0.5199482705343832], [0.9258624704331763], [-1.050298765916212], [-0.21176548454633634], [0.012555520660891484], [0.3330140995283599], [1.1074556651247418], [0.37040093372956445], [-0.40404063186681727], [-0.3185850108354924], [0.15142090483679457], [-0.4574503950113954], [1.0540459019801636], [0.5252892468488408], [0.9044985651753451], [-0.0942640056282646], [-0.44676844238247976], [-0.15835572140175821], [-0.6123387081306718], [0.4879024126476363], [0.05528333117655397], [-0.580292850243925], [-0.7725679975644059], [-3.213394173271624], [-1.0075709554005494], [-0.4627913713258532], [-0.7138172581053701], [-0.8687055712246464], [0.220853596924746], [-2.230654531411387], [-0.5589289449860937], [0.033919425918722726], [0.29562726532715533], [-1.4508719895005473], [2.656338796317505], [0.3330140995283599], [-1.0075709554005494], [-1.6912159236511486], [0.7709741573139], [-0.964843144884887], [-1.1945051264065725], [1.9406479701801593], [0.3436960521572755], [1.3104127650741384], [-0.27585720031982996], [1.8925791833500392], [-0.6710894475897076], [1.6468942728849802], [-0.302562081892119], [0.028578449604265036], [-0.28653915294874555], [0.3597189811006488], [0.40778776793076926], [-0.04619521879814432], [-0.8740465475391043], [0.37040093372956445], [-0.1316508398294693], [0.738928299427153], [0.028578449604265036], [-0.6443845660174187], [0.028578449604265036], [-0.21710646086079413], [1.374504480847632], [0.8297248967729359], [-0.6710894475897076], [-0.852682642281273], [1.5507566992247397], [0.43449264950305816], [0.8724527072885981], [0.08732918906330084], [-0.6443845660174187], [0.135397975893421], [0.6000629152512502], [0.220853596924746], [1.1395015230114884], [0.7869970862572735], [-0.526883087099347], [0.45051557844643175], [-2.3855428445306632], [-0.9595021685704291], [-0.7191582344198278], [0.4024467916163113], [0.7709741573139], [-0.7565450686210325], [-0.548246992357178], [-1.6698520183933174], [0.15142090483679457], [-1.488258823701752], [-0.8366597133378996], [-0.21176548454633634], [-0.5642699213005515], [0.717564394169322], [-0.991548026457176], [1.4385961966211258], [0.15676188115125225], [0.8083609915151047], [-1.2906427000668133], [0.4398336258175161], [0.6267677968235391], [-2.022356455147533], [0.135397975893421], [-1.2853017237523554], [-0.22778841348970977], [-1.4028032026704271], [-1.242573913236693], [-0.15835572140175821], [-2.209290626153556], [-0.5055191818415157], [1.7643957518030517], [-1.0449577896017541], [0.14607992852233664], [-0.9167743580547667], [-0.4734733239547688], [0.7068824415404064], [1.016659067778959], [0.9044985651753451], [0.6267677968235391], [0.744269275741611], [-0.22778841348970977], [1.1234785940681153], [-1.6004193263053659], [1.3584815519042586], [0.39176483898739567], [0.9846132098922123], [-1.6965568999656062], [1.4065503387343787], [-2.0811071946065685], [1.5774615807970287], [-0.7725679975644059], [1.3050717887596808], [0.1674438337801679], [-0.34528989240778146], [0.6481317020813704], [-0.05153619511260225], [0.2475584784970349], [2.314516312192206], [0.19414871535245706], [0.5893809626223345], [-1.648488113135486], [-0.9221153343692245], [0.3810828863584801], [0.2742633600693241], [0.2368765258681193], [-0.4788143002692266], [0.13005699957896333], [0.39176483898739567], [0.46653850738980507], [2.1115592122428093], [-0.2010835319174207], [-0.831318737023442], [-0.22244743717525195], [0.29028628901269743], [1.6308713439416067], [-2.6205458023668067], [1.7537137991741363], [-0.2010835319174207], [0.220853596924746], [-1.1090495053752478], [-1.2959836763812709], [-0.9007514291113933], [2.175650928016303], [-0.16369669771621603], [-0.7565450686210325], [-0.7351811633632013], [0.46653850738980507], [-0.040854242483686624], [0.18880773903799913], [1.2302981203572712], [0.300968241641613], [-0.10494595825718023], [-0.5696108976150093], [-0.25983427137645665], [2.116900188557267], [0.3223321468994443], [-0.07290010037043337], [-0.48949625289814225], [-0.3346079397788659], [-0.5963157791872984], [0.2315355495536616], [-0.6283616370740452], [-0.42540453712464854], [-0.17437865034513164], [-0.4360864897535641], [-1.5096227289595834], [0.8617707546596828], [-0.9488202159415136], [1.4012093624199211], [2.0047396859536533], [0.6694956073392017], [-0.7084762817909123], [-0.23847036611862538], [2.837931991009071], [-0.9327972869981402], [-0.2918801292632034], [1.7911006333753412], [-0.22778841348970977], [0.4398336258175161], [-0.01949033722585538], [0.5733580336789612], [-0.008808384596939759], [0.5146072942199252], [0.04460137854763835], [-1.2532558658656086], [1.2302981203572712], [-0.7565450686210325], [-0.5215421107848891], [-1.0129119317150073], [-0.04619521879814432], [-0.035513266169228695], [1.0380229730367905], [1.657576225513896], [-0.249152318747541], [1.1127966414391997], [-0.911433381740309], [0.5306302231632988], [-0.4574503950113954], [-0.5429060160427203], [2.4320177911102774], [0.7976790388861891], [0.08198821274884291], [-1.2746197711234395], [0.4879024126476363], [0.9472263756910075], [-0.05153619511260225], [-1.97962864463187], [-0.18506060297404728], [0.19414871535245706], [-0.6764304239041655], [0.1781257864090835], [0.7763151336283578], [-0.745863115992117], [0.29028628901269743], [3.153049593562081], [-0.6497255423318763], [1.1288195703825732], [0.09267016537775853], [-0.964843144884887], [0.9472263756910075], [-0.7618860449354904], [0.5413121757922144], [-0.008808384596939759], [-0.5749518739294671], [-1.6378061605065706], [0.5252892468488408], [1.1395015230114884], [-0.6764304239041655], [-0.8420006896523574], [-1.157118292205368], [0.1193750469500477], [0.3971058153018536], [-0.13699181614392697], [-0.008808384596939759], [-1.3440524632113913], [-0.07824107668489118], [-0.0942640056282646], [0.07664723643438522], [-0.9862070501427181], [0.8137019678295624], [-0.6657484712752499], [-1.5523505394752457], [-0.32926696346440804], [0.07664723643438522], [0.15142090483679457], [-0.7512040923065747], [-1.1998461027210305], [0.11403407063558978], [0.18880773903799913], [0.09801114169221646], [1.2249571440428135], [-1.680533971022233], [-0.23847036611862538], [-0.1957425556029629], [-1.0449577896017541], [1.0593868782946216], [-0.37733575029452837], [0.10869309432113208], [2.015421638582569], [-0.4147225844957329], [-0.2544932950619988], [-1.4935998000162096], [-0.6977943291619968], [-0.9274563106836823], [-0.7565450686210325], [-0.7779089738788638], [-1.8087174025692203], [-0.8580236185957308], [-0.9434792396270558], [0.45585655476088943], [0.3276731232139022], [0.028578449604265036], [1.5187108413379926], [0.49324338896209396], [-1.2051870790354882], [3.2438461909078637], [0.738928299427153], [1.2302981203572712], [0.5626760810500456], [-0.024831313540313073], [0.16210285746571018], [1.0647278546090795], [-1.1624592685198256], [-1.6111012789342816], [0.19414871535245706], [0.6801775599681172], [-0.8633645949101887], [-0.33994891609332367], [-0.22244743717525195], [1.9780348043813643], [0.9739312572632967], [1.572120604482571], [0.909839541489803], [1.1181376177536573], [-1.3974622263559693], [0.8510888020307672], [-1.3333705105824756], [0.8884756362319718], [-1.434849060557174], [-0.0034674082824818287], [-0.3559718450366971], [0.4291516731886005], [-0.548246992357178], [0.5252892468488408], [-2.0490613367198214], [0.7763151336283578], [0.1781257864090835], [0.7282463467982376], [0.20483066798137242], [2.229060691160881], [2.672361725260879], [0.10869309432113208], [1.657576225513896], [0.4451746021319738], [-0.1316508398294693], [-0.4788143002692266], [-1.3387114868969334], [-0.6283616370740452], [1.0006361388355856], [2.3412211937644947], [0.40778776793076926], [0.09801114169221646], [-0.13699181614392697], [0.578699009993419], [0.8190429441440203], [-1.7553076394246423], [-0.3079030582065768], [-0.5215421107848891], [0.41312874424522694], [0.6267677968235391], [-0.45210941869693755], [-0.6764304239041655], [-0.7885909265077794], [-0.8366597133378996], [-1.130413410633079], [-0.6123387081306718], [0.4238106968741426], [0.738928299427153], [-1.4989407763306677], [-0.17971962665958946], [-0.3506308687222393], [0.8831346599175138], [0.039260402233180655], [1.7964416096897988], [0.24221750218257723], [-1.4134851552993426], [-1.1624592685198256], [-1.0129119317150073], [-1.2265509842933193], [0.6427907257669127], [0.2315355495536616], [-0.9434792396270558], [-0.11562791088609585], [-1.242573913236693], [1.2196161677283557], [0.6374497494524547], [-0.831318737023442], [0.9472263756910075], [-0.18506060297404728], [-0.06755912405597556], [-1.077003647488501], [1.6148484149982336], [1.2997308124452225], [2.1115592122428093], [-0.7618860449354904], [-0.12096888720055367], [1.6362123202560648], [0.386423862672938], [-1.5096227289595834], [1.1341605466970308], [0.29562726532715533], [-0.33994891609332367], [1.4813240071367884], [-0.21176548454633634], [1.572120604482571], [-1.4615539421294628], [0.7602922046849843], [1.8017825860042564], [0.5092663179054675], [0.21017164429583035], [-0.2544932950619988], [1.1608654282693198], [0.40778776793076926], [-0.37733575029452837], [1.5828025571114863], [-1.3387114868969334], [-0.8046138554511527], [1.1127966414391997], [1.0540459019801636], [-0.7885909265077794], [-0.9808660738282604], [-2.203949649839098], [-0.12096888720055367], [1.486664983451246], [3.4841901250584657], [-0.8954104527969355], [0.8831346599175138], [0.05528333117655397], [2.496109506883771], [-0.7992728791366951], [-0.15835572140175821], [-0.1957425556029629], [1.9513299228090752], [1.1715473808982355], [1.2463210493006447], [1.1608654282693198], [0.8831346599175138], [0.09801114169221646], [0.5306302231632988], [-0.4200635608101907], [0.386423862672938], [1.486664983451246], [0.6374497494524547], [0.1781257864090835], [-0.6283616370740452], [2.469404625311482], [1.3210947177030539], [1.2783669071873913], [-0.1957425556029629], [-0.11562791088609585], [0.9418853993765498], [-0.6230206607595874], [0.14607992852233664], [-0.9488202159415136], [-0.024831313540313073], [-0.6390435897029607], [-0.7244992107342857], [0.2475584784970349], [2.2664475253620857], [-2.123835005122231], [-2.6525916602535538], [0.31165019427052865], [-0.0942640056282646], [0.220853596924746], [0.5573351047355877], [1.6415532965705224], [-1.9369008341162077], [2.592247080544012], [-0.44676844238247976], [-0.7405221396776591], [-1.7606486157391], [2.9554334699271427], [-0.7832499501933214], [-1.157118292205368], [2.4053129095379884], [-1.5096227289595834], [1.6629172018283538], [-0.15301474508730042], [-1.5897373736764504], [0.6214268205090815], [-1.2692787948089819], [0.04460137854763835], [0.3330140995283599], [-0.6497255423318763], [0.7869970862572735], [1.4012093624199211], [-0.7191582344198278], [-0.4734733239547688], [1.1662064045837774], [-0.17437865034513164], [-0.5322240634138047], [-0.6924533528475388], [-0.7565450686210325], [1.2356390966717292], [-1.7553076394246423], [-0.3719947739800705], [-0.4200635608101907], [-0.9167743580547667], [-1.3600753921547646], [-1.157118292205368], [0.17278481009462582], [0.40778776793076926], [0.6321087731379971], [-0.8633645949101887], [0.7976790388861891], [0.3223321468994443], [-0.6977943291619968], [-0.42540453712464854], [-0.3719947739800705], [-0.7885909265077794], [-1.5630324921041612], [-0.44676844238247976], [0.17278481009462582], [-0.660407494960792], [-0.12096888720055367], [-0.01414936091139745], [2.351903146393411], [0.6481317020813704], [-0.7832499501933214], [0.8938166125464294], [0.29562726532715533], [-1.6698520183933174], [0.41312874424522694], [-0.28119817663428776], [-0.23847036611862538], [2.2344016674753386], [-0.580292850243925], [-0.17437865034513164], [1.1021146888102842], [-0.9862070501427181], [1.0540459019801636], [-1.5203046815884986], [-0.8152958080800683], [1.011318091464501], [0.8137019678295624], [-1.0396168132872963], [-0.745863115992117], [-1.514963705274041], [0.6054038915657078], [-1.0823446238029586], [-0.6550665186463343], [-0.7138172581053701], [0.8831346599175138], [-0.5375650397282624], [0.0606243074910119], [-0.8580236185957308], [-1.8514452130848826], [-0.6817714002186231], [-0.9595021685704291], [-1.7286027578523533], [-0.6390435897029607], [-0.7298401870487435], [1.326435694017512], [0.2475584784970349], [0.09801114169221646], [-0.7885909265077794], [0.46653850738980507], [1.6415532965705224], [-0.27585720031982996], [0.6534726783958283], [-0.580292850243925], [0.8671117309741405], [0.25289945481149284], [2.2183787385319658], [-0.7351811633632013], [-0.15301474508730042], [-0.6390435897029607], [0.3223321468994443], [-1.846104236770425], [-0.07824107668489118], [2.6296339147452166], [-1.349393439525849], [2.1863328806452182], [-1.3707573447836803], [-0.06221814774151786], [-1.0449577896017541], [-1.5096227289595834], [0.7602922046849843], [-1.2639378184945242], [-1.0449577896017541], [-0.302562081892119], [-0.3933586792379018], [0.9632493046343811], [-1.1945051264065725], [0.6801775599681172], [0.6641546310247439], [-0.15835572140175821], [1.0754098072379947], [-0.5108601581559735], [-0.06221814774151786], [-0.6550665186463343], [2.496109506883771], [-1.6004193263053659], [0.7763151336283578], [-0.5749518739294671], [-0.21176548454633634], [1.240980072986187], [-0.6550665186463343], [0.35437800478619114], [-1.1250724343186211], [0.017896496975349414], [-0.9701841211993447], [-0.5856338265583827], [-0.4734733239547688], [-0.4788143002692266], [0.5306302231632988], [1.6415532965705224], [0.738928299427153], [-0.3346079397788659], [-0.1476737687728426], [-0.4200635608101907], [1.812464538633172], [0.1193750469500477], [-0.8099548317656107], [0.7869970862572735], [-0.1904015792885051], [0.6748365836536595], [-1.488258823701752], [0.9472263756910075], [-0.25983427137645665], [0.5413121757922144], [-0.9595021685704291], [0.220853596924746], [2.8860007778391914], [1.6148484149982336], [0.41312874424522694], [0.8510888020307672], [0.18880773903799913], [-0.7618860449354904], [-0.01949033722585538], [0.5092663179054675], [-0.8900694764824777], [-0.6924533528475388], [-0.28119817663428776], [0.55199412842113], [-0.3079030582065768], [0.824383920458478], [-0.6283616370740452], [-0.3132440345210346], [1.9513299228090752], [-1.2158690316644039], [0.5733580336789612], [-0.4734733239547688], [-0.45210941869693755], [-1.4134851552993426], [0.3810828863584801], [-0.2972211055776612], [1.0860917598669106], [-0.0889230293138068], [-0.04619521879814432], [0.04994235486209628], [0.6855185362825752], [0.14607992852233664], [0.30630921795607097], [-0.7512040923065747], [1.2249571440428135], [1.1982522624705245], [0.37040093372956445], [-0.5055191818415157], [0.35437800478619114], [0.5573351047355877], [-1.4722358947583785], [-0.5215421107848891], [-1.1357543869475368], [-0.25983427137645665], [1.1501834756404044], [-0.49483722921260004], [0.033919425918722726], [0.21017164429583035], [0.05528333117655397], [-0.008808384596939759], [1.0006361388355856], [1.342458622960885], [1.3317766703319698], [1.5026879123946195], [-0.05153619511260225], [-0.831318737023442], [2.026103591211484], [0.7068824415404064], [-0.10494595825718023], [-0.852682642281273], [0.1781257864090835], [-1.4562129658150051], [0.7496102520560687], [0.47722046001872065], [-0.2918801292632034], [1.9086021122934127], [-0.23312938980416759], [0.08198821274884291], [0.0606243074910119], [0.028578449604265036], [0.5466531521066721], [-0.8473416659668153], [0.04994235486209628], [-2.230654531411387], [0.909839541489803], [0.9632493046343811], [-1.4989407763306677], [1.2516620256151023], [-0.5535879686716358], [0.9472263756910075], [-1.317347581639102], [-0.23312938980416759], [1.657576225513896], [-0.44142746606802197], [-0.16369669771621603], [-1.685874947336691], [0.3490370284717332], [0.6374497494524547], [0.8137019678295624], [1.4065503387343787], [-2.727365328655963], [1.011318091464501], [-0.18506060297404728], [-0.1476737687728426], [0.023237473289807107], [1.4279142439922101], [0.386423862672938], [-1.6057603026198237], [2.148946046444014], [-0.32926696346440804], [0.2796043363837818], [0.19414871535245706], [-1.1945051264065725], [0.2742633600693241], [0.2742633600693241], [-0.28653915294874555], [2.8966827304681066], [1.3104127650741384], [0.2475584784970349], [0.2475584784970349], [-1.354734415840307], [-0.8740465475391043], [0.41846972055968484], [0.028578449604265036], [-0.024831313540313073], [-0.660407494960792], [0.21017164429583035], [0.017896496975349414], [1.2570030019295606], [1.454619125564499], [-0.09960498194272242], [0.578699009993419], [0.3597189811006488], [-2.449634560304157], [-0.035513266169228695], [-1.3333705105824756], [0.007214544346433793], [-1.0930265764318743], [-0.5322240634138047], [-1.5309866342174145], [2.1596279990729297], [0.6321087731379971], [-0.008808384596939759], [2.944751517298227], [0.16210285746571018], [-0.8633645949101887], [1.2676849545584759], [-0.6924533528475388], [0.5466531521066721], [1.9086021122934127], [-0.8366597133378996], [-0.9701841211993447], [1.0273410204078746], [-1.4241671079282583], [1.0326819967223322], [-0.21176548454633634], [-0.6176796844451296], [0.1674438337801679], [0.8938166125464294], [0.3276731232139022], [-0.48415527658368446], [0.04460137854763835], [-0.6283616370740452], [0.6855185362825752], [-0.8633645949101887], [0.17278481009462582], [-0.911433381740309], [-1.6057603026198237], [0.7923380625717311], [0.012555520660891484], [-0.8366597133378996], [0.4024467916163113], [1.7216679412873892], [-0.28119817663428776], [-0.825977760708984], [1.1768883572126934], [0.4985843652765519], [-0.25983427137645665], [-0.5215421107848891], [0.039260402233180655], [-0.1476737687728426], [-0.6443845660174187], [0.4825614363331784], [-2.1932676972101826], [-1.2532558658656086], [-0.12630986351501147], [-0.6924533528475388], [-1.2265509842933193], [0.5840399863078769], [-0.33994891609332367], [-0.8473416659668153], [-0.20642450823187852], [-2.561795062907771], [-1.1731412211487413], [0.29562726532715533], [0.033919425918722726], [0.017896496975349414], [1.4385961966211258], [-0.1957425556029629], [1.0860917598669106], [-0.26517524769091444], [2.7097485594620836], [-1.4455310131860895], [0.3169911705849866], [1.2356390966717292], [-0.2918801292632034], [-0.09960498194272242], [0.028578449604265036], [0.3169911705849866], [-0.28653915294874555], [1.3210947177030539], [0.21017164429583035], [-0.11562791088609585], [0.8510888020307672], [0.6214268205090815], [2.2717885016765433], [-0.3079030582065768], [-0.008808384596939759], [1.1341605466970308], [-0.01414936091139745], [0.25289945481149284], [-2.866230712831866], [-0.4200635608101907], [-0.2918801292632034], [-0.1316508398294693], [1.4279142439922101], [-1.2051870790354882], [-0.3185850108354924], [-0.9808660738282604], [-0.38801770292344395], [0.8938166125464294], [-1.4989407763306677], [0.39176483898739567], [-0.42540453712464854], [-1.10370852906079], [-1.680533971022233], [-0.10494595825718023], [1.1608654282693198], [1.182229333527151], [-1.0609807185451274], [-0.8046138554511527], [-1.242573913236693], [0.8083609915151047], [-0.5001782055270578], [0.300968241641613], [1.011318091464501], [1.6682581781428114], [0.9312034467476342], [0.6160858441946235], [0.9739312572632967], [0.55199412842113], [-0.16369669771621603], [-0.008808384596939759], [-0.07824107668489118], [0.7229053704837797], [0.3330140995283599], [0.15676188115125225], [-0.7832499501933214], [0.6694956073392017], [-0.9167743580547667], [-0.831318737023442], [0.8510888020307672], [-2.3802018682162056], [-1.0289348606583806], [1.5347337702813661], [0.15676188115125225], [1.3638225282187162], [-0.083582052999349], [0.7335873231126954], [-0.3185850108354924], [0.07130626011992729], [0.8350658730873937], [-0.12096888720055367], [3.4040754803415982], [-0.2544932950619988], [-0.024831313540313073], [-0.22778841348970977], [-1.3013246526957287], [-0.0034674082824818287], [0.1674438337801679], [-0.3346079397788659], [-0.5055191818415157], [-0.083582052999349], [1.2516620256151023], [0.012555520660891484], [0.6214268205090815], [-1.4562129658150051], [0.7282463467982376], [-0.9274563106836823], [1.4279142439922101], [-0.6016567555017561], [0.07664723643438522], [-0.38801770292344395], [-0.34528989240778146], [-0.4360864897535641], [1.4065503387343787], [-1.0289348606583806], [0.7229053704837797], [0.8030200152006468], [-1.6698520183933174], [-0.1476737687728426], [0.6534726783958283], [0.05528333117655397], [-0.11028693457163805], [0.6962004889114908], [-1.0129119317150073], [-0.5162011344704313], [-0.6764304239041655], [0.8938166125464294], [-1.6698520183933174], [-0.3506308687222393], [0.5413121757922144], [-0.7191582344198278], [1.043363949351248], [-1.3013246526957287], [0.18346676272354143], [0.41312874424522694], [0.7229053704837797], [-2.7754341154860835], [-0.22244743717525195], [1.1608654282693198], [0.41846972055968484], [0.29028628901269743], [0.017896496975349414], [0.9579083283199231], [1.342458622960885], [-1.1731412211487413], [-1.2746197711234395], [0.3650599574151068], [-1.1678002448342837], [-1.4722358947583785], [0.5092663179054675], [-0.008808384596939759], [-0.7885909265077794], [-1.2853017237523554], [1.1662064045837774], [0.7923380625717311], [-0.3559718450366971], [0.15142090483679457], [0.7549512283705266], [0.47187948370426275], [-0.8687055712246464], [-0.548246992357178], [-1.023593884343923], [-0.040854242483686624], [1.9887167570102795], [-0.05687717142705993], [0.9472263756910075], [0.21551262061028806], [-0.8687055712246464], [1.182229333527151], [-0.6016567555017561], [-1.2639378184945242], [-0.8740465475391043], [-0.01949033722585538], [-0.5535879686716358], [1.4279142439922101], [0.3276731232139022], [0.8404068494018515], [-0.12630986351501147], [0.033919425918722726], [-0.1904015792885051], [-0.5535879686716358], [-0.6977943291619968], [-1.1624592685198256], [-1.2853017237523554], [-1.488258823701752], [0.1193750469500477], [0.9205214941187186], [-0.01414936091139745], [0.0018735680319758635], [-1.5416685868463298], [0.3330140995283599], [-0.6123387081306718], [0.9418853993765498], [1.8498513728343766], [-0.5162011344704313], [-0.3613128213511549], [2.3786080279657], [-1.1357543869475368], [-0.20642450823187852], [-0.9541611922559713], [0.08732918906330084], [2.202355809588592], [2.042126520154858], [-0.44142746606802197], [-0.5909748028728405], [0.7335873231126954], [0.744269275741611], [-0.4734733239547688], [0.14607992852233664], [-0.8847285001680198], [-0.12630986351501147], [-1.8995139999150028], [-0.44142746606802197], [-0.6497255423318763], [-0.249152318747541], [-1.3387114868969334], [0.5466531521066721], [0.4238106968741426], [1.6201893913126912], [0.07130626011992729], [1.0540459019801636], [1.4279142439922101], [0.37040093372956445], [-0.16903767403067385], [0.7602922046849843], [-1.9636057156884965], [0.2635814074404085], [1.1341605466970308], [0.4985843652765519], [-0.4734733239547688], [1.540074746595824], [-1.1517773158909101], [-0.06221814774151786], [3.3827115750837677], [0.9044985651753451], [0.18346676272354143], [-0.526883087099347], [-1.2051870790354882], [0.29562726532715533], [1.315753741388596], [-0.07290010037043337], [0.19414871535245706], [0.936544423062092], [-2.8502077838884925], [0.5039253415910095], [-1.1624592685198256], [0.8350658730873937], [-0.8633645949101887], [-0.1316508398294693], [-0.18506060297404728], [-0.9274563106836823], [-0.05687717142705993], [0.30630921795607097], [0.9792722335777544], [-0.083582052999349], [-0.7351811633632013], [-0.12630986351501147], [0.45585655476088943], [-0.040854242483686624], [0.1781257864090835], [0.2635814074404085], [0.017896496975349414], [-0.6871123765330811], [0.3650599574151068], [-0.8152958080800683], [-0.4627913713258532], [1.8017825860042564], [0.46653850738980507], [0.7869970862572735], [0.29028628901269743], [0.6962004889114908], [-1.1998461027210305], [-1.3974622263559693], [-0.17437865034513164], [-1.0289348606583806], [-0.17437865034513164], [-0.49483722921260004], [1.5774615807970287], [0.3490370284717332], [1.454619125564499], [-0.3933586792379018], [-0.3933586792379018], [-0.5001782055270578], [-1.4562129658150051], [0.9846132098922123], [-0.43074551343910633], [0.744269275741611], [-1.183823173777657], [0.9525673520054655], [-0.4360864897535641], [-0.606997731816214], [-0.37733575029452837], [0.4238106968741426], [-0.5749518739294671], [-0.13699181614392697], [-0.9595021685704291], [-0.606997731816214], [0.3810828863584801], [-0.23312938980416759], [1.1341605466970308], [1.1448424993259463], [-1.0449577896017541], [1.2356390966717292], [-0.48415527658368446], [-1.3013246526957287], [-0.13699181614392697], [1.6468942728849802], [-0.28119817663428776], [-0.3506308687222393], [0.6801775599681172], [0.039260402233180655], [0.21551262061028806], [0.0018735680319758635], [-0.07290010037043337], [0.7335873231126954], [-0.2705162240053721], [-0.06221814774151786], [-1.2692787948089819], [-1.3280295342680177], [0.29562726532715533], [1.2730259308729337], [0.039260402233180655], [1.7804186807464253], [-0.4093816081812751], [-2.230654531411387], [0.6481317020813704], [0.6534726783958283], [1.572120604482571], [-0.5963157791872984], [1.9192840649223282], [0.2475584784970349], [-0.1423327924583848], [-1.488258823701752], [-0.15301474508730042], [-0.8152958080800683], [-0.9327972869981402], [-0.16903767403067385], [-0.28653915294874555], [-0.7779089738788638], [1.785759657060883], [-0.526883087099347], [0.9632493046343811], [-0.745863115992117], [-0.5696108976150093], [-2.139857934065604], [0.21551262061028806], [1.374504480847632], [-0.26517524769091444], [1.3210947177030539], [-0.17437865034513164], [-0.3719947739800705], [-0.7244992107342857], [0.39176483898739567], [0.3490370284717332], [0.26892238375486616], [1.9513299228090752], [0.9418853993765498], [-0.5696108976150093], [0.6054038915657078], [1.0914327361813683], [1.2730259308729337], [-0.9862070501427181], [1.1715473808982355], [0.04460137854763835], [-0.16369669771621603], [0.5146072942199252], [-0.5535879686716358], [-0.9327972869981402], [-0.2918801292632034], [0.09267016537775853], [-0.8366597133378996], [0.7869970862572735], [0.8030200152006468], [1.4225732676777523], [-0.5055191818415157], [0.028578449604265036], [-0.8152958080800683], [0.7976790388861891], [0.30630921795607097], [0.6054038915657078], [-0.32926696346440804], [-0.37733575029452837], [0.13005699957896333], [0.5573351047355877], [-0.45210941869693755], [-0.5589289449860937], [0.49324338896209396], [0.7068824415404064], [-0.548246992357178], [3.0355481146440093], [-0.32392598714995025], [0.37040093372956445], [0.3810828863584801], [0.4985843652765519], [0.6641546310247439], [1.5560976755391975], [0.0659652838054696], [1.214275191413898], [1.4599601018789572], [-0.3079030582065768], [0.8671117309741405], [-0.4788143002692266], [1.0006361388355856], [1.2516620256151023], [2.891341754153649], [-0.5429060160427203], [-0.28119817663428776], [-0.6550665186463343], [-1.846104236770425], [-0.6977943291619968], [0.8617707546596828], [2.175650928016303], [0.012555520660891484], [2.6403158673741323], [0.98995418620667], [-0.6016567555017561], [0.26892238375486616], [-0.5055191818415157], [0.7656331809994422], [-0.4627913713258532], [-0.17971962665958946], [-0.05153619511260225], [0.3971058153018536], [-0.2972211055776612], [-0.1957425556029629], [-0.825977760708984], [1.9940577333247378], [2.5174734121416025], [0.08198821274884291], [0.007214544346433793], [-0.9755250975138026], [-0.18506060297404728], [0.6908595125970328], [1.4439371729355837], [0.0606243074910119], [0.5359711994777565], [-0.8793875238535621], [1.1608654282693198], [-1.3867802737270536], [1.3477995992753433], [-0.5909748028728405], [0.4879024126476363], [-0.7244992107342857], [-1.210528055349946], [1.7911006333753412], [-0.21176548454633634], [-0.36665379766561274], [0.7869970862572735], [-1.2532558658656086], [-1.6164422552487392], [-2.7060014233981313], [-0.46813234764031103], [-1.5843963973619923], [-0.46813234764031103], [0.8884756362319718], [0.15142090483679457], [-0.16903767403067385], [0.5092663179054675], [0.46119753107534733], [0.4879024126476363], [-0.7885909265077794], [-0.9167743580547667], [0.2742633600693241], [2.7684992989211192], [-0.8740465475391043], [-0.4734733239547688], [-1.787353497311389], [-0.01414936091139745], [-1.4401900368716316], [-1.4989407763306677], [0.9739312572632967], [-0.8420006896523574], [1.2837078835018494], [-0.5215421107848891], [-0.18506060297404728], [-0.4627913713258532], [-0.3506308687222393], [-1.0930265764318743], [-0.030172289854771002], [-0.3346079397788659], [0.7068824415404064], [1.2302981203572712], [-1.0556397422306698], [-0.06221814774151786], [-0.3506308687222393], [-0.7832499501933214], [-0.38267672660898616], [0.10869309432113208], [-0.8847285001680198], [0.7763151336283578], [-0.5856338265583827], [-1.4134851552993426], [-0.4627913713258532], [-0.07290010037043337], [-0.7725679975644059], [-1.0449577896017541], [-0.3132440345210346], [0.17278481009462582], [-2.3588379629583742], [-0.4574503950113954], [-0.1316508398294693], [0.08732918906330084], [-0.6283616370740452], [-2.374860891901748], [-1.675192994707775], [-0.3346079397788659], [2.25576557273317], [-0.7885909265077794], [-0.25983427137645665], [0.8457478257163092], [3.0141842093861784], [-0.09960498194272242], [1.4653010781934148], [-1.0663216948595853], [-0.6817714002186231], [-0.6390435897029607], [-0.6016567555017561], [-1.018252908029465], [2.4907685305693135], [-1.32268855795356], [0.3330140995283599], [-0.991548026457176], [-1.9529237630595813], [0.37040093372956445], [-1.3654163684692224], [-0.9808660738282604], [0.5680170573645034], [0.5626760810500456], [-0.12630986351501147], [-0.3132440345210346], [-1.0022299790860916], [1.3905274097910056], [0.7496102520560687], [1.214275191413898], [-0.7031353054764544], [1.4279142439922101], [-0.12096888720055367], [1.155524451954862], [-1.5790554210475347], [-0.7298401870487435], [0.4238106968741426], [-0.01949033722585538], [0.5733580336789612], [1.5774615807970287], [-0.5963157791872984], [1.844510396519919], [-0.7084762817909123], [-0.5589289449860937], [-0.3506308687222393], [-0.3613128213511549], [-0.04619521879814432], [-0.8152958080800683], [0.5466531521066721], [1.5934845097404022], [0.25289945481149284], [-0.15835572140175821], [0.29028628901269743], [1.1608654282693198], [-0.964843144884887], [-1.9475827867451232], [1.4439371729355837], [1.4118913150488366], [0.21017164429583035], [0.30630921795607097], [-0.660407494960792], [0.3597189811006488], [0.30630921795607097], [-0.45210941869693755], [-0.01414936091139745], [-0.3933586792379018], [0.4291516731886005], [-1.2692787948089819], [-1.3814392974125957], [1.2249571440428135], [-0.7512040923065747], [-1.5470095631607879], [0.45051557844643175], [0.21017164429583035], [-2.0116745025186167], [-0.9060924054258511], [0.46653850738980507], [0.04994235486209628], [-0.11562791088609585], [-0.4788143002692266], [-0.2972211055776612], [0.028578449604265036], [-0.16369669771621603], [-0.3559718450366971], [0.4825614363331784], [0.8510888020307672], [0.386423862672938], [-0.21176548454633634], [-1.4028032026704271], [0.1674438337801679], [0.6641546310247439], [1.1501834756404044], [-0.2972211055776612], [-0.024831313540313073], [-0.8099548317656107], [0.46653850738980507], [-0.49483722921260004], [-1.8354222841415093], [-1.7392847104812688], [0.07664723643438522], [1.0059771151500434], [-1.1357543869475368], [-1.3974622263559693], [0.1674438337801679], [0.300968241641613], [-0.548246992357178], [-0.4147225844957329], [-0.7618860449354904], [1.043363949351248], [-0.3506308687222393], [1.0914327361813683], [1.4118913150488366], [0.18346676272354143], [0.8190429441440203], [0.2849453126982397], [-0.6123387081306718], [-0.16369669771621603], [1.7323498939163051], [-0.3933586792379018], [0.012555520660891484], [-0.660407494960792], [-0.8687055712246464], [0.824383920458478], [0.028578449604265036], [-0.5375650397282624], [1.5187108413379926], [-0.17971962665958946], [0.14073895220787894], [1.4332552203066677], [1.342458622960885], [-0.44676844238247976], [-0.7351811633632013], [-1.050298765916212], [-3.021119025951142], [1.1127966414391997], [-1.183823173777657], [0.033919425918722726], [0.11403407063558978], [0.6267677968235391], [-1.0930265764318743], [-0.9060924054258511], [-1.2692787948089819], [-1.0289348606583806], [0.29562726532715533], [-1.0823446238029586], [-0.32392598714995025], [0.8190429441440203], [1.2837078835018494], [-0.22778841348970977], [0.8350658730873937], [-1.653829089449944], [1.353140575589801], [-1.0449577896017541], [-0.5322240634138047], [-0.01949033722585538], [1.4920059597657038], [0.6534726783958283], [0.30630921795607097], [-0.831318737023442], [-0.7191582344198278], [0.6748365836536595], [-0.21176548454633634], [-0.9167743580547667], [-0.8740465475391043], [-0.5589289449860937], [-1.3066656290101866], [-0.1316508398294693], [0.11403407063558978], [0.17278481009462582], [2.5067914595126872], [-0.1476737687728426], [-0.580292850243925], [0.658813654710286], [-0.5108601581559735], [-1.6164422552487392], [1.2463210493006447], [-1.130413410633079], [-0.8473416659668153], [-1.7766715446824737], [0.6214268205090815], [-0.11028693457163805], [-0.5215421107848891], [1.0540459019801636], [-0.9808660738282604], [1.4653010781934148], [-1.0129119317150073], [0.023237473289807107], [-0.7512040923065747], [-2.113153052493315], [1.0326819967223322], [-0.8847285001680198], [-0.633702613388503], [0.19948969166691474], [1.1662064045837774], [0.30630921795607097], [-0.22244743717525195], [-0.23312938980416759], [-0.34528989240778146], [-0.3986996555523596], [0.220853596924746], [0.7335873231126954], [-0.7244992107342857], [0.11403407063558978], [0.04460137854763835], [-0.7832499501933214], [-0.3719947739800705], [-0.5909748028728405], [-0.606997731816214], [0.6000629152512502], [-0.1423327924583848], [-1.0663216948595853], [-0.17437865034513164], [0.6267677968235391], [-1.0556397422306698], [1.1074556651247418], [-1.1143904816897054], [-0.4627913713258532], [-0.7405221396776591], [-1.2532558658656086], [-0.6871123765330811], [-0.7992728791366951], [-0.0889230293138068], [-0.32926696346440804], [0.24221750218257723], [2.7097485594620836], [-0.2010835319174207], [0.47187948370426275], [-0.5001782055270578], [-0.26517524769091444], [0.6694956073392017], [-0.16369669771621603], [1.4759830308223303], [1.0540459019801636], [-0.8366597133378996], [-0.8206367843945263], [-0.852682642281273], [0.18880773903799913], [-1.0609807185451274], [-1.7606486157391], [-0.8687055712246464], [-0.7191582344198278], [0.2635814074404085], [1.4813240071367884], [0.7549512283705266], [2.0634904254126893], [1.043363949351248], [-1.1197314580041635], [0.8510888020307672], [-0.6283616370740452], [0.5733580336789612], [-0.4360864897535641], [-0.4200635608101907], [1.353140575589801], [-0.8847285001680198], [-0.580292850243925], [-2.123835005122231], [1.8925791833500392], [2.6029290331729276], [-0.7672270212499481], [-0.33994891609332367], [0.7015414652259485], [0.09267016537775853], [-1.4562129658150051], [-0.44676844238247976], [-0.17437865034513164], [-0.4147225844957329], [0.15676188115125225], [0.744269275741611], [-0.45210941869693755], [-1.0556397422306698], [-0.2918801292632034], [-2.1451989103800617], [-0.6977943291619968], [0.09267016537775853], [-0.11562791088609585], [1.2943898361307649], [-0.28653915294874555], [0.22619457323920367], [-1.7499666631101845], [-2.641909707624638], [1.3905274097910056], [1.0914327361813683], [-1.5576915157897036], [-1.648488113135486], [-0.8633645949101887], [-2.230654531411387], [-1.3760983210981381], [0.909839541489803], [-0.44142746606802197], [-1.1197314580041635], [-0.33994891609332367], [0.9418853993765498], [-0.7244992107342857], [-1.0716626711740431], [1.0914327361813683], [0.8938166125464294], [-0.48949625289814225], [-0.45210941869693755], [-0.5963157791872984], [-0.05153619511260225], [-0.7084762817909123], [2.3572441227078684], [0.4398336258175161], [-0.1957425556029629], [-0.7405221396776591], [1.5347337702813661], [-0.4734733239547688], [0.9739312572632967], [-1.3387114868969334], [0.25289945481149284], [2.7417944173488302], [-0.12096888720055367], [-0.43074551343910633], [1.454619125564499], [1.9673528517524483], [0.16210285746571018], [0.09801114169221646], [0.0606243074910119], [-0.024831313540313073], [-0.024831313540313073], [-0.030172289854771002], [-0.7565450686210325], [-1.3760983210981381], [1.1074556651247418], [0.7335873231126954], [-0.38801770292344395], [1.572120604482571], [1.4279142439922101], [1.240980072986187], [-1.6965568999656062], [-0.5589289449860937], [1.572120604482571], [0.10335211800667415], [-0.1957425556029629], [-0.32926696346440804], [-0.5909748028728405], [0.017896496975349414], [-0.04619521879814432], [-0.45210941869693755], [-0.6764304239041655], [3.2438461909078637], [0.31165019427052865], [0.31165019427052865], [1.0006361388355856], [-1.5737144447330769], [-0.7939319028222371], [-0.21176548454633634], [-0.28119817663428776], [1.8925791833500392], [0.10869309432113208], [1.3371176466464274], [0.6748365836536595], [1.0059771151500434], [-1.1678002448342837], [0.028578449604265036], [-0.606997731816214], [1.2570030019295606], [0.43449264950305816], [1.7163269649729316], [1.7750777044319677], [-1.0876856001174167], [0.3971058153018536], [1.2943898361307649], [-2.129175981436689], [-1.10370852906079], [-1.9208779051728342], [0.37040093372956445], [1.1395015230114884], [0.14607992852233664], [-0.4147225844957329], [-0.8793875238535621], [-1.1731412211487413], [-0.4360864897535641], [-0.15835572140175821], [-0.911433381740309], [0.3597189811006488], [2.0474674964693156], [1.022000044093417], [-0.05687717142705993], [-0.6176796844451296], [0.19414871535245706], [-0.37733575029452837], [-0.7191582344198278], [-0.22778841348970977], [0.5092663179054675], [0.20483066798137242], [0.6160858441946235], [0.5733580336789612], [0.30630921795607097], [2.918046635725938], [-0.07824107668489118], [0.2475584784970349], [-1.6164422552487392], [2.6830436778897946], [-1.4401900368716316], [-0.36665379766561274], [0.05528333117655397], [1.4706420545078724], [0.37574191004402235], [1.1662064045837774], [-0.6871123765330811], [0.3810828863584801], [-0.15835572140175821], [-2.7647521628571674], [1.4172322913632946], [1.540074746595824], [-0.01414936091139745], [-0.17437865034513164], [-1.4722358947583785], [-0.2544932950619988], [0.4024467916163113], [0.5466531521066721], [2.496109506883771], [-1.157118292205368], [-1.4028032026704271], [-0.1476737687728426], [1.1448424993259463], [-0.5055191818415157], [0.1247160232645054], [0.8938166125464294], [-0.8900694764824777], [-0.5108601581559735], [1.710985988658474], [-0.05687717142705993], [-0.8793875238535621], [0.29028628901269743], [-1.0930265764318743], [-0.9434792396270558], [0.012555520660891484], [-1.242573913236693], [0.6160858441946235], [1.182229333527151], [1.657576225513896], [0.46653850738980507], [-1.4562129658150051], [0.45585655476088943], [-0.38801770292344395], [3.222482285650033], [0.8671117309741405], [-1.0823446238029586], [1.0754098072379947], [-0.3346079397788659], [-0.6550665186463343], [0.47722046001872065], [-1.1517773158909101], [0.1674438337801679], [0.6962004889114908], [0.18346676272354143], [-1.3974622263559693], [2.079513354356062], [-0.09960498194272242], [0.0606243074910119], [1.0593868782946216], [1.2356390966717292], [-0.548246992357178], [-0.3506308687222393], [0.9151805178042607], [0.6107448678801658], [1.2249571440428135], [-0.8366597133378996], [-0.23312938980416759], [-2.9570273101776485], [1.7163269649729316], [-1.4935998000162096], [2.015421638582569], [-0.05687717142705993], [1.374504480847632], [1.5187108413379926], [-0.9274563106836823], [-0.5963157791872984], [1.0914327361813683], [2.2076967859030496], [0.14073895220787894], [-0.5429060160427203], [0.0606243074910119], [-0.0889230293138068], [1.2249571440428135], [-0.6710894475897076], [3.8260126091837647], [-0.008808384596939759], [0.1781257864090835], [0.30630921795607097], [-0.6497255423318763], [0.6160858441946235], [-1.5470095631607879], [0.39176483898739567], [1.6362123202560648], [0.9579083283199231], [-0.28119817663428776], [1.844510396519919], [-1.5523505394752457], [-1.0556397422306698], [-1.210528055349946], [-0.7725679975644059], [0.8083609915151047], [1.1448424993259463], [-0.4734733239547688], [1.080750783552453], [-0.0034674082824818287], [0.14607992852233664], [1.011318091464501], [-0.9488202159415136], [-0.5963157791872984], [0.578699009993419], [0.8831346599175138], [-0.15835572140175821], [0.19948969166691474], [0.3597189811006488], [2.496109506883771], [-0.5215421107848891], [0.10869309432113208], [0.6908595125970328], [1.3050717887596808], [-0.42540453712464854], [0.5733580336789612], [1.3691635045331745], [3.7085111302656935], [0.09267016537775853], [-0.8793875238535621], [0.6481317020813704], [1.214275191413898], [-0.7298401870487435], [0.5680170573645034], [-0.9007514291113933], [0.30630921795607097], [-0.01949033722585538], [0.6481317020813704], [0.6214268205090815], [-1.7125798289089798], [0.0606243074910119], [-0.3933586792379018], [-1.429508084242716], [-1.4722358947583785], [-0.18506060297404728], [-1.9956515735752436], [1.1181376177536573], [-0.4093816081812751], [0.2742633600693241], [1.8872382070355815], [0.386423862672938], [0.4985843652765519], [0.4879024126476363], [-0.22778841348970977], [-0.8633645949101887], [-0.008808384596939759], [1.8071235623187143], [-1.0075709554005494], [-0.18506060297404728], [-0.3986996555523596], [-0.9862070501427181], [1.2570030019295606], [-0.8473416659668153], [-0.302562081892119], [-0.07290010037043337], [-0.7832499501933214], [-2.5244082287065663], [2.7738402752355773], [-0.9488202159415136], [1.192911286156067], [0.7869970862572735], [-0.4734733239547688], [2.9340695646693113], [0.40778776793076926], [0.37574191004402235], [1.700304036029558], [1.2943898361307649], [1.353140575589801], [-1.3814392974125957], [-0.10494595825718023], [-0.36665379766561274], [-0.5001782055270578], [-0.2544932950619988], [0.2796043363837818], [2.421335838481362], [-0.28653915294874555], [0.658813654710286], [-0.5429060160427203], [0.5626760810500456], [0.15142090483679457], [-1.32268855795356], [0.7656331809994422], [-0.5429060160427203], [-1.3013246526957287], [-1.5470095631607879], [0.9952951625211279], [0.5039253415910095], [-0.36665379766561274], [-0.5055191818415157], [-0.07824107668489118], [-1.9689466920029546], [-0.6871123765330811], [1.454619125564499], [-0.3079030582065768], [0.5146072942199252], [-0.5642699213005515], [0.717564394169322], [0.5733580336789612], [1.2943898361307649], [-0.09960498194272242], [-0.2544932950619988], [1.9086021122934127], [1.2516620256151023], [0.2582404311259505], [1.5026879123946195], [3.8260126091837647], [1.5293927939669085], [-0.911433381740309], [0.5840399863078769], [-1.8033764262547625], [-0.745863115992117], [-1.210528055349946], [0.017896496975349414], [0.033919425918722726], [-2.0971301235499418], [0.46653850738980507], [-0.21710646086079413], [-0.9381382633125979], [-0.6016567555017561], [-0.5322240634138047], [1.214275191413898], [1.0860917598669106], [0.6374497494524547], [0.47722046001872065], [-0.9701841211993447], [0.43449264950305816], [1.881897230721124], [1.2463210493006447], [-1.6164422552487392], [0.8617707546596828], [-0.3132440345210346], [-0.831318737023442], [-0.13699181614392697], [-0.06221814774151786], [0.5252892468488408], [-1.3013246526957287], [1.4332552203066677], [0.3490370284717332], [0.10335211800667415], [-1.0449577896017541], [-1.2479148895511507], [0.3597189811006488], [0.5626760810500456], [0.08732918906330084], [0.8510888020307672], [-0.6924533528475388], [0.1193750469500477], [-0.12630986351501147], [-0.7618860449354904], [1.1608654282693198], [-0.1423327924583848], [1.540074746595824], [0.22619457323920367], [-0.5055191818415157], [0.2475584784970349], [0.46653850738980507], [-1.8834910709716295], [0.39176483898739567], [-0.4200635608101907], [-0.01949033722585538], [-1.8407632604559674], [2.512132435827145], [1.5347337702813661], [1.1662064045837774], [-0.526883087099347], [0.14607992852233664], [-1.2212100079788617], [0.46119753107534733], [1.1982522624705245], [0.6107448678801658], [1.1608654282693198], [0.07664723643438522], [-0.580292850243925], [-2.2787233182415076], [-0.0942640056282646], [0.9579083283199231], [1.016659067778959], [0.18880773903799913], [0.6801775599681172], [-0.07824107668489118], [-1.3974622263559693], [0.824383920458478], [-0.46813234764031103], [-1.32268855795356], [0.6054038915657078], [0.7602922046849843], [-0.9434792396270558], [-1.242573913236693], [0.1781257864090835], [-1.0075709554005494], [-0.05153619511260225], [-0.4734733239547688], [0.30630921795607097], [0.5893809626223345], [0.3169911705849866], [1.5881435334259442], [-0.7832499501933214], [-0.6123387081306718], [-0.28653915294874555], [-1.018252908029465], [-0.28119817663428776], [0.017896496975349414], [-0.8954104527969355], [-1.6271242078776549], [0.09267016537775853], [0.6374497494524547], [0.41846972055968484], [-0.6390435897029607], [-0.1316508398294693], [-0.16903767403067385], [-0.7672270212499481], [-1.5790554210475347], [-1.4401900368716316], [-1.0609807185451274], [0.1247160232645054], [-0.2918801292632034], [-0.6710894475897076], [0.8831346599175138], [-0.9060924054258511], [1.374504480847632], [0.738928299427153], [-0.6016567555017561], [0.8777936836030561], [1.4813240071367884], [-0.5856338265583827], [-0.548246992357178], [0.5413121757922144], [-0.9595021685704291], [-0.45210941869693755], [0.26892238375486616], [0.5733580336789612], [0.11403407063558978], [0.8190429441440203], [-0.8473416659668153], [-1.3974622263559693], [-0.0034674082824818287], [-1.0396168132872963], [0.824383920458478], [0.4024467916163113], [0.37574191004402235], [-0.15301474508730042], [-0.9862070501427181], [0.5573351047355877], [2.939410540983769], [-0.6176796844451296], [0.18880773903799913], [0.7282463467982376], [-0.11028693457163805], [-0.28653915294874555], [-0.40404063186681727], [-0.8420006896523574], [-0.9274563106836823], [-0.01414936091139745], [0.6908595125970328], [0.10335211800667415], [-0.20642450823187852], [-0.5162011344704313], [0.21551262061028806], [-0.9221153343692245], [2.1863328806452182], [1.3210947177030539], [0.909839541489803], [-0.633702613388503], [-0.9488202159415136], [0.21551262061028806], [-0.26517524769091444], [-0.01949033722585538], [-0.40404063186681727], [1.2730259308729337], [-1.3333705105824756], [1.3691635045331745], [0.007214544346433793], [-1.130413410633079], [-0.6390435897029607], [-1.2853017237523554], [-0.38267672660898616], [0.5146072942199252], [-0.9327972869981402], [0.6801775599681172], [-1.2532558658656086], [-0.20642450823187852], [-0.7672270212499481], [-0.07824107668489118], [-2.5884999444800605], [-0.5535879686716358], [1.4385961966211258], [0.4398336258175161], [-0.4574503950113954], [0.37040093372956445], [1.7964416096897988], [-1.5897373736764504], [0.7229053704837797], [-0.3079030582065768], [-0.2438113424330832], [1.5347337702813661], [1.214275191413898], [0.5359711994777565], [-1.7606486157391], [-0.32926696346440804], [0.6107448678801658], [-0.4788143002692266], [-0.16903767403067385], [-0.4093816081812751], [0.135397975893421], [0.2635814074404085], [0.10869309432113208], [-0.249152318747541], [-1.97962864463187], [0.3383550758428176], [0.6481317020813704], [-0.06755912405597556], [0.0606243074910119], [0.5733580336789612], [-0.4093816081812751], [2.1222411648717245], [0.012555520660891484], [0.29028628901269743], [-1.1250724343186211], [-0.4574503950113954], [1.5187108413379926], [0.909839541489803], [0.8190429441440203], [-0.05153619511260225], [-0.15835572140175821], [-1.1464363395764523], [-2.1345169577511465], [-0.825977760708984], [-0.6977943291619968], [0.2315355495536616], [-1.2051870790354882], [0.13005699957896333], [-1.1357543869475368], [0.5252892468488408], [-0.6016567555017561], [-1.6111012789342816], [0.13005699957896333], [-0.32392598714995025], [-0.3132440345210346], [-0.9381382633125979], [0.20483066798137242], [1.182229333527151], [0.7656331809994422], [-0.5642699213005515], [0.15142090483679457], [-0.23847036611862538], [0.22619457323920367], [-0.5696108976150093], [-0.7138172581053701], [0.41312874424522694], [1.2997308124452225], [1.2676849545584759], [-0.9488202159415136], [-1.2212100079788617], [0.45051557844643175], [-1.0556397422306698], [-0.12096888720055367], [0.5252892468488408], [0.039260402233180655], [-1.1357543869475368], [1.2035932387849821], [2.6296339147452166], [0.6321087731379971], [-1.8834910709716295], [0.6054038915657078], [-0.40404063186681727], [1.881897230721124], [-3.0798697654101783], [-0.45210941869693755], [1.2676849545584759], [-1.077003647488501], [-0.4093816081812751], [0.5573351047355877], [0.7496102520560687], [0.220853596924746], [1.5454157229102816], [-1.354734415840307], [0.3971058153018536], [0.0659652838054696], [0.5733580336789612], [1.1021146888102842], [-0.3346079397788659], [-0.1904015792885051], [0.49324338896209396], [-0.7725679975644059], [-1.242573913236693], [-0.9327972869981402], [-0.3613128213511549], [-0.7298401870487435], [0.45585655476088943], [-0.44676844238247976], [0.5039253415910095], [-1.6431471368210284], [-0.831318737023442], [-1.0716626711740431], [-0.7512040923065747], [-0.911433381740309], [-0.21176548454633634], [0.8297248967729359], [-0.3933586792379018], [-0.37733575029452837], [-1.8300813078270515], [0.658813654710286], [-0.9327972869981402], [-1.3974622263559693], [1.080750783552453], [0.19948969166691474], [0.4024467916163113], [-0.852682642281273], [-0.5162011344704313], [-1.7125798289089798], [-0.44142746606802197], [-0.15835572140175821], [0.47722046001872065], [0.14607992852233664], [-0.9221153343692245], [-0.17971962665958946], [-0.44676844238247976], [-1.4935998000162096], [1.9726938280669064], [-0.6817714002186231], [0.0659652838054696], [-0.9381382633125979], [-0.37733575029452837], [0.2475584784970349], [-0.3559718450366971], [0.7602922046849843], [0.8671117309741405], [0.2475584784970349], [-0.7565450686210325], [0.5413121757922144], [0.21551262061028806], [0.9579083283199231], [-0.16903767403067385], [0.29562726532715533], [-0.9595021685704291], [1.8017825860042564], [-0.2438113424330832], [0.300968241641613], [-1.4722358947583785], [-1.984969620946328], [-0.7138172581053701], [-1.514963705274041], [1.2837078835018494], [-0.15835572140175821], [0.09267016537775853], [0.2315355495536616], [-0.21176548454633634], [0.909839541489803], [-0.5375650397282624], [1.9353069938657017], [1.1608654282693198], [1.6308713439416067], [-0.1957425556029629], [-0.6977943291619968], [-0.9274563106836823], [1.0487049256657057], [-0.06755912405597556], [-1.4401900368716316], [0.5466531521066721], [0.5039253415910095], [-0.831318737023442], [-0.3346079397788659], [-0.26517524769091444], [0.738928299427153], [-0.37733575029452837], [1.3210947177030539], [0.29562726532715533], [0.9525673520054655], [0.386423862672938], [-1.1624592685198256], [-0.9167743580547667], [-0.6764304239041655], [-1.157118292205368], [0.43449264950305816], [-0.07290010037043337], [-0.33994891609332367], [0.135397975893421], [-0.0942640056282646], [-0.8420006896523574], [-0.9221153343692245], [-0.7031353054764544], [-0.38801770292344395], [0.7869970862572735], [0.6374497494524547], [-0.825977760708984], [-1.157118292205368], [0.08198821274884291], [-0.5108601581559735], [0.007214544346433793], [1.5774615807970287], [1.0006361388355856], [-0.7405221396776591], [-0.9007514291113933], [-0.6977943291619968], [0.7602922046849843], [1.3584815519042586], [1.0540459019801636], [-0.4574503950113954], [-0.5909748028728405], [-0.040854242483686624], [-1.349393439525849], [1.9940577333247378], [0.9205214941187186], [-0.7832499501933214], [0.3169911705849866], [0.16210285746571018], [1.1768883572126934], [-0.7779089738788638], [0.5947219389367925], [2.699066606833168], [0.6054038915657078], [-0.13699181614392697], [-0.6123387081306718], [0.4024467916163113], [-0.42540453712464854], [-0.9488202159415136], [0.8564297783452248], [-1.5843963973619923], [-3.272144912730659], [-1.0609807185451274], [0.2475584784970349], [-1.050298765916212], [1.2890488598163072], [0.9685902809488388], [-1.0075709554005494], [1.6468942728849802], [0.5947219389367925], [-0.0889230293138068], [-1.2479148895511507], [-0.16369669771621603], [2.335880217450037], [-1.2692787948089819], [0.039260402233180655], [-0.825977760708984], [-0.42540453712464854], [-1.4935998000162096], [-0.17971962665958946], [0.09801114169221646], [0.6374497494524547], [-0.2918801292632034], [-0.4627913713258532], [-0.23847036611862538], [0.1674438337801679], [2.7364534410343726], [-0.5856338265583827], [-0.825977760708984], [0.5306302231632988], [-0.5909748028728405], [-1.1784821974631992], [-0.28119817663428776], [-0.9541611922559713], [-0.11028693457163805], [0.14607992852233664], [0.21551262061028806], [-0.1957425556029629], [-0.825977760708984], [0.824383920458478], [-0.526883087099347], [-0.01414936091139745], [0.07664723643438522], [-1.157118292205368], [0.37574191004402235], [-0.38801770292344395], [2.4533816963681088], [-0.2544932950619988], [1.1074556651247418], [0.300968241641613], [-0.32392598714995025], [-0.7031353054764544], [2.0367855438404003], [-0.05687717142705993], [-0.745863115992117], [0.300968241641613], [1.59882548605486], [-1.1464363395764523], [-1.4615539421294628], [-1.1464363395764523], [1.3905274097910056], [0.41312874424522694], [1.0273410204078746], [2.715089535776541], [1.4172322913632946], [0.9472263756910075], [1.7216679412873892], [0.0018735680319758635], [0.9952951625211279], [2.4266768147958198], [-1.0129119317150073], [0.4398336258175161], [0.41312874424522694], [1.1288195703825732], [-0.36665379766561274], [0.18346676272354143], [1.3905274097910056], [1.4973469360801615], [0.7335873231126954], [-1.0556397422306698], [-1.5309866342174145], [-0.4200635608101907], [-1.157118292205368], [0.6908595125970328], [0.744269275741611], [0.37040093372956445], [-0.11028693457163805], [0.21017164429583035], [0.9044985651753451], [0.20483066798137242], [2.335880217450037], [2.116900188557267], [0.8617707546596828], [-1.3440524632113913], [2.1008772596138936], [-0.5375650397282624], [-0.8954104527969355], [0.3330140995283599], [-1.5897373736764504], [-0.27585720031982996], [1.6522352491994379], [-2.1505398866945202], [-0.12096888720055367], [1.7483728228596787], [0.5306302231632988], [-0.3132440345210346], [-0.42540453712464854], [0.5893809626223345], [-0.6871123765330811], [-1.0930265764318743], [-0.38267672660898616], [1.182229333527151], [2.52281438845606], [-0.3933586792379018], [-0.43074551343910633], [1.5828025571114863], [-0.1423327924583848], [-1.1624592685198256], [0.1247160232645054], [-0.024831313540313073], [-0.3346079397788659], [-1.0716626711740431], [-1.7499666631101845], [-0.7031353054764544], [-0.07290010037043337], [0.9258624704331763], [0.5733580336789612], [-1.8300813078270515], [-1.7766715446824737], [-0.4200635608101907], [0.5947219389367925], [0.4024467916163113], [-0.4574503950113954], [-0.4360864897535641], [1.3638225282187162], [-0.8580236185957308], [0.21551262061028806], [-1.4615539421294628], [-1.0022299790860916], [0.2582404311259505], [-0.12096888720055367], [-1.8247403315125938], [0.5092663179054675], [-0.21710646086079413], [1.342458622960885], [-1.1784821974631992], [0.9151805178042607], [0.08732918906330084], [-0.6497255423318763], [1.4385961966211258], [0.5092663179054675], [-0.15301474508730042], [1.486664983451246], [0.10335211800667415], [-1.317347581639102], [-0.4627913713258532], [0.4825614363331784], [-0.8954104527969355], [0.9525673520054655], [0.2475584784970349], [1.3104127650741384], [-0.18506060297404728], [-1.792694473625847], [-0.1316508398294693], [0.9205214941187186], [-0.25983427137645665], [-1.0609807185451274], [0.7763151336283578], [0.14073895220787894], [0.6908595125970328], [-0.8740465475391043], [-1.1357543869475368], [0.033919425918722726], [-1.5256456579029567], [0.578699009993419], [0.2582404311259505], [-0.04619521879814432], [1.0754098072379947], [0.2315355495536616], [-0.9755250975138026], [-0.44142746606802197], [1.0006361388355856], [1.1288195703825732], [-2.038379384090906], [-0.7885909265077794], [-0.6710894475897076], [-0.9007514291113933], [0.2742633600693241], [-0.3613128213511549], [-1.023593884343923], [1.1982522624705245], [1.3317766703319698], [-1.3120066053246444], [1.0914327361813683], [0.4238106968741426], [0.9472263756910075], [-0.13699181614392697], [-0.6497255423318763], [1.4332552203066677], [0.5199482705343832], [-0.2918801292632034], [-0.2972211055776612], [0.5146072942199252], [0.55199412842113], [-0.1957425556029629], [0.824383920458478], [0.16210285746571018], [-0.7351811633632013], [0.39176483898739567], [0.43449264950305816], [-3.501806894252345], [-0.2544932950619988], [1.0006361388355856], [-0.9755250975138026], [-1.2959836763812709], [0.8938166125464294], [2.8539549199524443], [-1.4508719895005473], [-0.831318737023442], [0.4879024126476363], [0.04994235486209628], [1.6201893913126912], [-0.3986996555523596], [-0.01949033722585538], [-1.0342758369728384], [-1.2265509842933193], [1.011318091464501], [-0.06221814774151786], [0.5947219389367925], [-0.3613128213511549], [0.7122234178548641], [0.29028628901269743], [-0.22244743717525195], [-0.3986996555523596], [1.0006361388355856], [-0.9007514291113933], [0.21551262061028806], [0.738928299427153], [0.0659652838054696], [1.3905274097910056], [0.24221750218257723], [-0.6443845660174187], [-0.6550665186463343], [1.6415532965705224], [-0.21176548454633634], [-1.5630324921041612], [-0.22244743717525195], [1.4065503387343787], [0.6107448678801658], [0.7068824415404064], [-0.580292850243925], [-0.12630986351501147], [-0.05687717142705993], [0.3383550758428176], [1.897920159664497], [3.222482285650033], [0.19948969166691474], [0.8671117309741405], [-1.7179208052234376], [0.9579083283199231], [-0.745863115992117], [1.3104127650741384], [-0.33994891609332367], [0.04460137854763835], [-0.606997731816214], [-0.008808384596939759], [1.9780348043813643], [-0.7512040923065747], [-0.38267672660898616], [0.007214544346433793], [-2.4977033471342773], [0.29562726532715533], [0.012555520660891484], [1.7163269649729316], [0.8777936836030561], [1.4920059597657038], [2.3465621700789527], [-1.3387114868969334], [0.22619457323920367], [0.4398336258175161], [0.22619457323920367], [-0.22244743717525195], [0.16210285746571018], [0.1674438337801679], [-0.48415527658368446], [0.17278481009462582], [0.023237473289807107], [0.25289945481149284], [-0.9327972869981402], [0.5306302231632988], [-0.3185850108354924], [-0.7084762817909123], [0.8938166125464294], [0.35437800478619114], [-1.1357543869475368], [-0.20642450823187852], [1.0380229730367905], [4.183858022252439], [0.35437800478619114], [1.9459889464946172], [0.6962004889114908], [2.010080662268111], [0.9525673520054655], [-1.2799607474378976], [-0.05687717142705993], [0.0659652838054696], [0.43449264950305816], [-1.0716626711740431], [0.8030200152006468], [1.7270089176018475], [-0.36665379766561274], [-0.9274563106836823], [-1.2532558658656086], [0.8404068494018515], [-0.6657484712752499], [0.8617707546596828], [-0.4627913713258532], [-0.8366597133378996], [1.5881435334259442], [-0.12630986351501147], [0.49324338896209396], [-0.8687055712246464], [-1.5096227289595834], [-1.0876856001174167], [-0.17437865034513164], [-0.0889230293138068], [-0.4734733239547688], [1.4279142439922101], [-1.1945051264065725], [-1.7659895920535578], [-0.6390435897029607], [0.30630921795607097], [-0.7885909265077794], [-0.7725679975644059], [-2.4282706550463256], [-1.8995139999150028], [-1.3654163684692224], [2.3198572885066637], [-0.2544932950619988], [0.49324338896209396], [0.6908595125970328], [0.19948969166691474], [-2.5671360392222287], [0.386423862672938], [-0.6016567555017561], [0.46119753107534733], [-0.8473416659668153], [-1.8834910709716295], [-1.0609807185451274], [-0.23312938980416759], [-0.7351811633632013], [-1.1891641500921148], [-1.8300813078270515], [0.5306302231632988], [0.8564297783452248], [-1.7766715446824737], [-0.44676844238247976], [-0.01949033722585538], [0.7015414652259485], [-0.7405221396776591], [0.1674438337801679], [0.9846132098922123], [0.012555520660891484], [1.1181376177536573], [0.9151805178042607], [0.4825614363331784], [-0.035513266169228695], [0.6107448678801658], [0.1781257864090835], [1.9566708991235329], [-1.5309866342174145], [0.3223321468994443], [0.40778776793076926], [-2.3107691761282543], [-0.4360864897535641], [-0.0889230293138068], [-0.2544932950619988], [0.25289945481149284], [-0.2918801292632034], [-0.5375650397282624], [-0.9221153343692245], [0.5039253415910095], [0.29028628901269743], [-0.035513266169228695], [-0.16369669771621603], [-0.28653915294874555], [2.59758805685847], [0.5146072942199252], [0.6107448678801658], [0.8938166125464294], [0.135397975893421], [-0.21176548454633634], [-2.1345169577511465], [0.6908595125970328], [-0.32926696346440804], [-0.48949625289814225], [-0.8793875238535621], [0.8137019678295624], [0.9792722335777544], [0.909839541489803], [-1.0289348606583806], [0.4238106968741426], [-1.023593884343923], [1.0006361388355856], [0.6801775599681172], [-0.1476737687728426], [-0.6230206607595874], [-1.3760983210981381], [2.8486139436379867], [0.220853596924746], [-0.16903767403067385], [-0.7672270212499481], [1.0487049256657057], [-0.5162011344704313], [-0.1423327924583848], [-0.5375650397282624], [-0.01414936091139745], [0.0018735680319758635], [-0.9755250975138026], [-0.5642699213005515], [-0.17971962665958946], [-0.32392598714995025], [-0.5749518739294671], [-1.5042817526451253], [-0.22778841348970977], [0.6641546310247439], [-1.1357543869475368], [-0.3506308687222393], [0.5947219389367925], [-0.5749518739294671], [0.658813654710286], [0.20483066798137242], [0.7709741573139], [1.1288195703825732], [-1.7125798289089798], [0.5092663179054675], [-0.07824107668489118], [0.3597189811006488], [-1.2799607474378976], [-0.5749518739294671], [0.220853596924746], [0.4238106968741426], [0.033919425918722726], [-1.8300813078270515], [1.182229333527151], [-1.0022299790860916], [0.17278481009462582], [-0.8900694764824777], [-1.2853017237523554], [1.0487049256657057], [0.7496102520560687], [0.5733580336789612], [-1.6111012789342816], [-0.9167743580547667], [0.6481317020813704], [0.20483066798137242], [0.3436960521572755], [-0.23312938980416759], [0.4398336258175161], [-0.852682642281273], [0.6908595125970328], [1.9620118754379907], [0.2742633600693241], [1.1341605466970308], [1.2196161677283557], [-0.5429060160427203], [-0.6497255423318763], [-0.07824107668489118], [0.7869970862572735], [-1.0930265764318743], [1.3371176466464274], [-0.06755912405597556], [-1.0129119317150073], [-1.0716626711740431], [1.8658743017777504], [0.9205214941187186], [0.04994235486209628], [3.1690725225054552], [-1.349393439525849], [-0.8473416659668153], [0.11403407063558978], [0.3223321468994443], [1.2570030019295606], [0.49324338896209396], [-1.1784821974631992], [-0.1476737687728426], [3.2812330251090684], [1.7643957518030517], [-1.1945051264065725], [0.3276731232139022], [-1.5203046815884986], [-0.42540453712464854], [0.24221750218257723], [1.673599154457269], [0.14607992852233664], [0.744269275741611], [-1.4775768710728363], [-0.45210941869693755], [-0.27585720031982996], [-0.16903767403067385], [-0.5589289449860937], [0.5199482705343832], [-1.3066656290101866], [-2.3695199155872904], [-0.5215421107848891], [1.9192840649223282], [-0.6924533528475388], [0.8350658730873937], [-0.11562791088609585], [0.41312874424522694], [0.4024467916163113], [-0.3132440345210346], [0.6054038915657078], [-2.0757662182921104], [1.0540459019801636], [-0.40404063186681727], [1.2890488598163072], [2.0367855438404003], [1.5187108413379926], [-0.8847285001680198], [1.8872382070355815], [-0.6710894475897076], [-0.5963157791872984], [-0.6817714002186231], [0.039260402233180655], [-0.1423327924583848], [0.07130626011992729], [-1.5630324921041612], [-0.8473416659668153], [-0.5055191818415157], [0.017896496975349414], [-1.8300813078270515], [-1.4028032026704271], [-0.5535879686716358], [0.3597189811006488], [-0.2010835319174207], [1.4279142439922101], [-0.21710646086079413], [-0.12630986351501147], [-0.302562081892119], [1.4920059597657038], [-0.6817714002186231], [0.6427907257669127], [-0.43074551343910633], [0.5733580336789612], [1.20893421509944], [-0.3613128213511549], [-0.4200635608101907], [-0.1476737687728426], [-0.6016567555017561], [0.7015414652259485], [-0.7084762817909123], [-0.6230206607595874], [-0.5429060160427203], [-0.7779089738788638], [-0.1957425556029629], [0.6801775599681172], [0.0659652838054696], [0.9205214941187186], [-0.34528989240778146], [-0.5696108976150093], [-2.786116068114999], [-0.3613128213511549], [0.5413121757922144], [-0.49483722921260004], [-0.48415527658368446], [-0.7618860449354904], [-1.648488113135486], [0.578699009993419], [-0.6230206607595874], [-1.0609807185451274], [-0.6817714002186231], [-1.5096227289595834], [1.6468942728849802], [0.2368765258681193], [-1.4134851552993426], [0.8777936836030561], [0.4825614363331784], [0.07130626011992729], [2.6616797726319636], [1.8605333254632925], [0.7709741573139], [0.41312874424522694], [0.5840399863078769], [-1.648488113135486], [0.9044985651753451], [-0.28119817663428776], [0.7122234178548641], [0.028578449604265036], [0.14607992852233664], [0.08198821274884291], [-1.130413410633079], [1.4012093624199211], [0.10335211800667415], [-0.6497255423318763], [-0.7565450686210325], [-0.7351811633632013], [-0.8420006896523574], [1.5026879123946195], [-0.6924533528475388], [0.7122234178548641], [-0.26517524769091444], [1.6682581781428114], [-0.964843144884887], [0.46653850738980507], [-0.745863115992117], [-1.4134851552993426], [-0.8206367843945263], [0.3276731232139022], [0.3597189811006488], [-0.44142746606802197], [0.2742633600693241], [-0.44676844238247976], [-0.5001782055270578], [1.3584815519042586], [-0.12096888720055367], [1.1288195703825732], [0.4985843652765519], [-1.4935998000162096], [0.3810828863584801], [-0.3613128213511549], [-1.1624592685198256], [-0.911433381740309], [1.1074556651247418], [0.25289945481149284], [1.4118913150488366], [1.4439371729355837], [-0.17971962665958946], [-1.1678002448342837], [-0.40404063186681727], [-1.6164422552487392], [-0.4093816081812751], [-0.4360864897535641], [-0.36665379766561274], [0.14073895220787894], [-1.872809118342714], [-0.660407494960792], [0.8938166125464294], [1.0914327361813683], [-0.5108601581559735], [-0.10494595825718023], [0.6267677968235391], [0.9472263756910075], [0.4291516731886005], [-1.1945051264065725], [-1.018252908029465], [0.6000629152512502], [-0.21710646086079413], [0.20483066798137242], [0.09267016537775853], [-2.1451989103800617], [0.47187948370426275], [-0.42540453712464854], [-0.28119817663428776], [-1.3387114868969334], [1.1982522624705245], [-0.09960498194272242], [-2.2627003892981334], [0.8671117309741405], [2.4106538858524464], [1.5293927939669085], [0.3169911705849866], [-1.4829178473872942], [-1.10370852906079], [0.3597189811006488], [0.8404068494018515], [2.6616797726319636], [-1.018252908029465], [1.240980072986187], [1.080750783552453], [-1.2479148895511507], [0.5733580336789612], [-1.3066656290101866], [-0.17437865034513164], [-0.7031353054764544], [-0.16903767403067385], [-1.7286027578523533], [1.9459889464946172], [1.903261135978955], [-0.745863115992117], [-1.2158690316644039], [1.2035932387849821], [-1.0075709554005494], [-0.6176796844451296], [0.15142090483679457], [0.7709741573139], [-0.8580236185957308], [-1.317347581639102], [-1.10370852906079], [0.6748365836536595], [1.1341605466970308], [-0.38801770292344395], [0.21017164429583035], [-0.4734733239547688], [-0.38267672660898616], [0.46119753107534733], [0.2368765258681193], [1.2783669071873913], [-0.48949625289814225], [-0.3559718450366971], [-0.6764304239041655], [-0.37733575029452837], [-2.1451989103800617], [-0.42540453712464854], [1.0860917598669106], [-0.9968890027716338], [0.9205214941187186], [-0.38801770292344395], [-1.1410953632619945], [-0.3986996555523596], [-0.2544932950619988], [0.6160858441946235], [-0.8366597133378996], [0.4825614363331784], [-0.7992728791366951], [2.0207626148970266], [-0.2705162240053721], [-0.32926696346440804], [-1.077003647488501], [-1.4134851552993426], [-0.48949625289814225], [-0.7618860449354904], [0.5573351047355877], [-0.15301474508730042], [-0.7298401870487435], [3.8313535854982232], [0.2315355495536616], [-0.22778841348970977], [0.49324338896209396], [-0.825977760708984], [0.17278481009462582], [-0.6710894475897076], [-0.7939319028222371], [-0.11028693457163805], [-0.9755250975138026], [0.21551262061028806], [0.0018735680319758635], [-0.6817714002186231], [0.0606243074910119], [-0.6230206607595874], [-0.42540453712464854], [0.30630921795607097], [-0.9060924054258511], [-0.1316508398294693], [-0.9434792396270558], [-0.1904015792885051], [-0.526883087099347], [-1.32268855795356], [-0.16369669771621603], [0.37574191004402235], [-1.1731412211487413], [0.7763151336283578], [-1.2265509842933193], [-0.302562081892119], [-0.0889230293138068], [0.5733580336789612], [-0.2544932950619988], [-0.48415527658368446], [1.2570030019295606], [-1.1143904816897054], [-0.580292850243925], [-0.42540453712464854], [0.7602922046849843], [0.2635814074404085], [-0.7939319028222371], [-0.2544932950619988], [2.939410540983769], [0.8671117309741405], [-1.787353497311389], [-0.42540453712464854], [-0.06755912405597556], [0.6267677968235391], [-0.2010835319174207], [-0.6764304239041655], [2.175650928016303], [-0.13699181614392697], [0.8083609915151047], [0.300968241641613], [-0.43074551343910633], [0.012555520660891484], [-1.429508084242716], [-0.6550665186463343], [-0.27585720031982996], [1.2035932387849821], [-1.1357543869475368], [-0.2972211055776612], [0.17278481009462582], [0.39176483898739567], [0.2315355495536616], [-1.9582647393740389], [-1.0289348606583806], [-1.8033764262547625], [0.023237473289807107], [-0.083582052999349], [0.8190429441440203], [-0.2705162240053721], [-0.852682642281273], [0.5413121757922144], [0.8297248967729359], [-0.34528989240778146], [-0.5375650397282624], [0.41312874424522694], [0.9525673520054655], [0.17278481009462582], [-1.7446256867957264], [1.9513299228090752], [0.2368765258681193], [-0.46813234764031103], [-0.7512040923065747], [-1.2799607474378976], [0.8564297783452248], [-1.0289348606583806], [0.8030200152006468], [1.1501834756404044], [-0.9434792396270558], [0.4291516731886005], [-1.1464363395764523], [-0.3933586792379018], [2.4266768147958198], [-0.5749518739294671], [-0.606997731816214], [1.8071235623187143], [0.31165019427052865], [-0.5909748028728405], [-0.49483722921260004], [-0.2544932950619988], [-1.5309866342174145], [-1.6271242078776549], [0.9792722335777544], [0.37040093372956445], [0.8510888020307672], [-0.9221153343692245], [-0.3185850108354924], [0.9258624704331763], [0.9952951625211279], [-0.26517524769091444], [0.9472263756910075], [1.2516620256151023], [0.49324338896209396], [0.6160858441946235], [1.81780551494763], [-0.4360864897535641], [0.6374497494524547], [0.2796043363837818], [0.6267677968235391], [-0.6710894475897076], [-0.33994891609332367], [-0.05153619511260225], [-0.32392598714995025], [0.936544423062092], [-0.8847285001680198], [-1.4935998000162096], [-0.6871123765330811], [0.2475584784970349], [-0.035513266169228695], [-0.12096888720055367], [-0.12630986351501147], [-0.5055191818415157], [1.6308713439416067], [-0.8099548317656107], [0.4398336258175161], [0.3650599574151068], [0.15676188115125225], [0.21017164429583035], [0.9418853993765498], [-0.07290010037043337], [0.3383550758428176], [2.3412211937644947], [1.4279142439922101], [-0.6176796844451296], [0.9579083283199231], [1.5614386518536552], [-0.0889230293138068], [-0.3613128213511549], [-0.17971962665958946], [0.2849453126982397], [0.5146072942199252], [0.09267016537775853], [-0.7832499501933214], [-0.4093816081812751], [-0.22778841348970977], [-0.12630986351501147], [-1.210528055349946], [0.25289945481149284], [0.386423862672938], [0.04460137854763835], [0.3810828863584801], [-0.11562791088609585], [0.6908595125970328], [-0.13699181614392697], [0.08732918906330084], [2.175650928016303], [-0.035513266169228695], [0.6267677968235391], [-0.6443845660174187], [-1.8781500946571716], [-0.9381382633125979], [0.9579083283199231], [0.7923380625717311], [0.2582404311259505], [-0.4627913713258532], [-0.3079030582065768], [1.4706420545078724], [-0.6497255423318763], [-0.2705162240053721], [1.353140575589801], [-0.7405221396776591], [0.09801114169221646], [-0.5055191818415157], [0.033919425918722726], [-1.077003647488501], [-0.7405221396776591], [0.17278481009462582], [0.7763151336283578], [0.7068824415404064], [1.0059771151500434], [0.2582404311259505], [1.2302981203572712], [-1.6378061605065706], [-0.5162011344704313], [0.017896496975349414], [-0.3559718450366971], [0.1247160232645054], [-0.7351811633632013], [0.29028628901269743], [1.9353069938657017], [0.08732918906330084], [-0.6176796844451296], [0.5092663179054675], [-0.606997731816214], [0.30630921795607097], [0.8297248967729359], [-1.10370852906079], [0.023237473289807107], [0.14073895220787894], [-1.2853017237523554], [-0.0889230293138068], [-0.17437865034513164], [2.1382640938150983], [0.6748365836536595], [3.0462300672729254], [-1.429508084242716], [0.9739312572632967], [0.17278481009462582], [0.18346676272354143], [-0.22778841348970977], [-0.9221153343692245], [0.5092663179054675], [0.4879024126476363], [-0.1957425556029629], [-0.17437865034513164], [0.18880773903799913], [0.08732918906330084], [-2.748729233913794], [-0.1957425556029629], [0.135397975893421], [1.7376908702307627], [0.8564297783452248], [-1.4668949184439208], [1.6415532965705224], [-0.05153619511260225], [-0.8046138554511527], [0.012555520660891484], [0.0018735680319758635], [0.6000629152512502], [-0.1476737687728426], [-1.1464363395764523], [-0.8046138554511527], [-1.1891641500921148], [0.9312034467476342], [0.8030200152006468], [-0.7672270212499481], [-1.3440524632113913], [2.2931524069343747], [0.6160858441946235], [-0.4734733239547688], [0.5733580336789612], [-0.40404063186681727], [-0.38801770292344395], [0.5252892468488408], [0.1781257864090835], [-0.5589289449860937], [0.41846972055968484], [-0.606997731816214], [-0.12630986351501147], [-1.10370852906079], [0.3597189811006488], [1.705645012344016], [0.20483066798137242], [0.3383550758428176], [-1.6378061605065706], [-0.12096888720055367], [-0.27585720031982996], [-0.28119817663428776], [1.2249571440428135], [0.5733580336789612], [-0.035513266169228695], [0.13005699957896333], [-0.5375650397282624], [-0.0942640056282646], [3.4841901250584657], [-0.06755912405597556], [0.9258624704331763], [-0.22778841348970977], [-1.5309866342174145], [1.572120604482571], [-1.4615539421294628], [-2.4175887024174103], [-1.2799607474378976], [-0.991548026457176], [-0.2918801292632034], [1.2570030019295606], [0.717564394169322], [-0.526883087099347], [1.2730259308729337], [-1.242573913236693], [-1.8300813078270515], [-0.36665379766561274], [-0.526883087099347], [0.41846972055968484], [-0.548246992357178], [0.5893809626223345], [-0.16369669771621603], [-0.6123387081306718], [-0.5642699213005515], [-0.22778841348970977], [0.7015414652259485], [-0.5963157791872984], [-0.5963157791872984], [-0.9701841211993447], [0.8404068494018515], [0.2475584784970349], [-0.8740465475391043], [0.6801775599681172], [1.1341605466970308], [0.3490370284717332], [-1.237232936922235], [-0.7031353054764544], [-0.15301474508730042], [0.6107448678801658], [0.5733580336789612], [-0.28653915294874555], [0.3490370284717332], [-0.6230206607595874], [1.3905274097910056], [-0.6123387081306718], [0.658813654710286], [0.45585655476088943], [-0.44676844238247976], [-0.9221153343692245], [-1.3013246526957287], [-0.17437865034513164], [-0.5642699213005515], [-0.16903767403067385], [-1.2265509842933193], [0.023237473289807107], [1.833828443891003], [0.7656331809994422], [-0.9007514291113933], [0.300968241641613], [0.2315355495536616], [-0.8633645949101887], [-3.6193083731704165], [2.469404625311482], [0.17278481009462582], [-1.2799607474378976], [-1.1143904816897054], [0.07130626011992729], [-1.317347581639102], [-0.13699181614392697], [-1.9315598578017499], [0.039260402233180655], [-1.050298765916212], [-1.6431471368210284], [-0.07824107668489118], [-0.42540453712464854], [-0.548246992357178], [-0.05153619511260225], [0.4024467916163113], [-1.2212100079788617], [-0.3346079397788659], [0.21017164429583035], [-0.12096888720055367], [-0.3613128213511549], [-0.3346079397788659], [0.2315355495536616], [1.1021146888102842], [1.240980072986187], [0.3650599574151068], [0.5947219389367925], [1.37984545716209], [-1.3760983210981381], [0.7763151336283578], [1.6148484149982336], [0.6748365836536595], [-0.302562081892119], [0.11403407063558978], [0.6374497494524547], [-0.7832499501933214], [1.0006361388355856], [-0.6230206607595874], [-0.01949033722585538], [2.0474674964693156], [-0.12096888720055367], [0.5306302231632988], [1.0860917598669106], [0.5413121757922144], [-1.0289348606583806], [0.14607992852233664], [0.023237473289807107], [-1.7286027578523533], [1.1395015230114884], [1.214275191413898], [-0.0942640056282646], [-0.4788143002692266], [-1.10370852906079], [0.7709741573139], [-0.7084762817909123], [-0.1316508398294693], [0.14607992852233664], [-0.6817714002186231], [-0.12630986351501147], [-1.3280295342680177], [-0.7351811633632013], [-0.5696108976150093], [0.7335873231126954], [-0.26517524769091444], [0.25289945481149284], [-0.3185850108354924], [0.26892238375486616], [0.5466531521066721], [-0.45210941869693755], [1.0006361388355856], [0.4451746021319738], [-0.1476737687728426], [1.6415532965705224], [0.05528333117655397], [1.0326819967223322], [0.7229053704837797], [0.2475584784970349], [0.04460137854763835], [-0.9327972869981402], [-0.3506308687222393], [0.6267677968235391], [1.4706420545078724], [0.824383920458478], [1.8391694202054614], [0.39176483898739567], [0.21551262061028806], [1.4599601018789572], [0.8137019678295624], [0.033919425918722726], [-0.09960498194272242], [-0.6230206607595874], [-1.8354222841415093], [-0.07824107668489118], [1.3958683861054635], [0.8297248967729359], [-0.17437865034513164], [1.4492781492500413], [0.1247160232645054], [-0.7565450686210325], [0.21551262061028806], [-0.38267672660898616], [0.25289945481149284], [-0.6764304239041655], [-1.0289348606583806], [-1.0075709554005494], [-0.3185850108354924], [-0.4093816081812751], [-0.8152958080800683], [-0.8687055712246464], [-0.17437865034513164], [0.744269275741611], [0.21017164429583035], [0.4985843652765519], [-0.18506060297404728], [-0.3185850108354924], [-0.25983427137645665], [-1.1143904816897054], [-0.008808384596939759], [-0.1476737687728426], [-0.5749518739294671], [-0.44142746606802197], [-1.3814392974125957], [0.39176483898739567], [-0.7084762817909123], [0.738928299427153], [2.015421638582569], [-0.05687717142705993], [-0.7992728791366951], [1.3958683861054635], [-0.7885909265077794], [0.55199412842113], [0.2475584784970349], [0.46653850738980507], [0.7869970862572735], [-0.5375650397282624], [-0.8099548317656107], [-0.8099548317656107], [0.08732918906330084], [-0.01949033722585538], [0.4451746021319738], [0.24221750218257723], [0.09267016537775853], [-1.6324651841921127], [2.581565127915096], [-0.7244992107342857], [0.5947219389367925], [0.6962004889114908], [0.09267016537775853], [0.22619457323920367], [0.4879024126476363], [1.342458622960885], [-0.8046138554511527], [-1.1143904816897054], [0.3223321468994443], [-0.6390435897029607], [-0.37733575029452837], [-0.15835572140175821], [1.1875703098416086], [-0.040854242483686624], [-0.606997731816214], [-0.06755912405597556], [-0.1476737687728426], [0.21551262061028806], [-0.3132440345210346], [0.6481317020813704], [0.2475584784970349], [-0.25983427137645665], [-1.5630324921041612], [0.10335211800667415], [2.127582141186183], [-0.2010835319174207], [1.9406479701801593], [-0.9060924054258511], [2.1222411648717245], [0.8617707546596828], [-0.825977760708984], [0.3810828863584801], [-0.6924533528475388], [-1.1891641500921148], [0.3276731232139022], [-0.6283616370740452], [-2.454975536618615], [-0.32392598714995025], [-0.05153619511260225], [1.1501834756404044], [0.3436960521572755], [-0.6176796844451296], [-1.2585968421800662], [0.2635814074404085], [-0.2010835319174207], [0.8404068494018515], [2.7097485594620836], [-0.6230206607595874], [-0.5696108976150093], [0.26892238375486616], [-0.6283616370740452], [-0.32926696346440804], [0.9151805178042607], [-2.342815034015001], [0.5466531521066721], [0.37574191004402235], [0.3490370284717332], [0.2315355495536616], [-0.01414936091139745], [0.3436960521572755], [-0.3933586792379018], [-0.05687717142705993], [0.41312874424522694], [0.7282463467982376], [1.1982522624705245], [-0.2010835319174207], [0.8404068494018515], [-1.8087174025692203], [0.8457478257163092], [0.5413121757922144], [1.214275191413898], [1.1875703098416086], [1.9086021122934127], [-0.6817714002186231], [1.0006361388355856], [1.1127966414391997], [-0.5055191818415157], [-1.4455310131860895], [0.5733580336789612], [-0.44676844238247976], [-1.0449577896017541], [-0.825977760708984], [-0.5215421107848891], [0.05528333117655397], [1.7697367281175098], [0.2315355495536616], [1.5187108413379926], [-0.024831313540313073], [0.29562726532715533], [0.4024467916163113], [0.3330140995283599], [1.3905274097910056], [0.7816561099428155], [-0.09960498194272242], [0.017896496975349414], [1.240980072986187], [1.871215278092208], [2.4159948621669045], [-0.6977943291619968], [-0.6390435897029607], [0.3490370284717332], [0.824383920458478], [0.6908595125970328], [2.1649689753873873], [0.8991575888608874], [1.4439371729355837], [0.8404068494018515], [-0.05153619511260225], [-1.2532558658656086], [-0.3185850108354924], [1.2730259308729337], [-0.06755912405597556], [-2.2627003892981334], [0.028578449604265036], [-0.15301474508730042], [-0.21710646086079413], [1.4385961966211258], [-0.5963157791872984], [1.0487049256657057], [0.135397975893421], [0.14607992852233664], [-0.8099548317656107], [0.6641546310247439], [0.6748365836536595], [0.41846972055968484], [-1.3333705105824756], [-0.6977943291619968], [-0.831318737023442], [-0.3719947739800705], [0.41312874424522694], [0.9472263756910075], [-0.6230206607595874], [0.3169911705849866], [-0.8954104527969355], [1.5187108413379926], [-0.12096888720055367], [1.5828025571114863], [0.05528333117655397], [-0.7779089738788638], [-1.018252908029465], [2.3038343595632904], [-0.20642450823187852], [-1.6698520183933174], [0.3169911705849866], [-1.0289348606583806], [0.4024467916163113], [0.8831346599175138], [1.1127966414391997], [-0.01414936091139745], [-0.030172289854771002], [-0.5055191818415157], [-1.680533971022233], [-0.11028693457163805], [-0.5856338265583827], [-1.1678002448342837], [-1.4935998000162096], [-1.354734415840307], [-0.07290010037043337], [0.1781257864090835], [-1.2639378184945242], [-2.123835005122231], [-0.5055191818415157], [-0.580292850243925], [-0.2972211055776612], [-0.6497255423318763], [-0.6016567555017561], [-1.157118292205368], [0.24221750218257723], [-0.4200635608101907], [0.033919425918722726], [0.6374497494524547], [-0.05153619511260225], [2.5174734121416025], [1.326435694017512], [-0.0942640056282646], [-0.44142746606802197], [1.342458622960885], [-0.12096888720055367], [0.8083609915151047], [-0.4093816081812751], [1.5187108413379926], [0.07664723643438522], [2.3412211937644947], [1.6468942728849802], [-0.7405221396776591], [1.0860917598669106], [0.8404068494018515], [-0.030172289854771002], [-0.1476737687728426], [-0.1476737687728426], [-0.633702613388503], [0.07664723643438522], [-0.8793875238535621], [2.148946046444014], [-0.8152958080800683], [0.6321087731379971], [-0.7244992107342857], [0.028578449604265036], [-0.4093816081812751], [-0.15835572140175821], [1.6201893913126912], [-0.5642699213005515], [0.8404068494018515], [1.5828025571114863], [-0.7405221396776591], [1.59882548605486], [0.7068824415404064], [-0.548246992357178], [0.6908595125970328], [1.2730259308729337], [-0.7618860449354904], [-0.43074551343910633], [-0.7618860449354904], [-0.6924533528475388], [0.135397975893421], [-0.3986996555523596], [-0.8152958080800683], [-2.684637518140301], [0.220853596924746], [-1.242573913236693], [1.3371176466464274], [0.41312874424522694], [-0.46813234764031103], [0.6908595125970328], [-1.1410953632619945], [0.5626760810500456], [-0.040854242483686624], [0.0018735680319758635], [0.3810828863584801], [-0.46813234764031103], [-0.4574503950113954], [0.3330140995283599], [2.6296339147452166], [-0.15301474508730042], [-1.6004193263053659], [1.214275191413898], [1.7697367281175098], [-0.7512040923065747], [0.31165019427052865], [1.2302981203572712], [-0.0034674082824818287], [-0.5696108976150093], [-0.1904015792885051], [1.1501834756404044], [-0.7512040923065747], [0.7015414652259485], [-1.4829178473872942], [-0.6123387081306718], [1.0380229730367905], [-0.43074551343910633], [0.1674438337801679], [-0.3346079397788659], [0.7602922046849843], [-0.9968890027716338], [-1.5790554210475347], [-0.33994891609332367], [1.5347337702813661], [0.6694956073392017], [-0.0034674082824818287], [-0.17437865034513164], [-1.242573913236693], [0.8137019678295624], [0.5092663179054675], [1.2463210493006447], [1.096773712495826], [0.1247160232645054], [-0.8046138554511527], [0.9044985651753451], [-0.8152958080800683], [-0.6924533528475388], [-0.48415527658368446], [-1.3974622263559693], [-0.4788143002692266], [-0.8580236185957308], [-0.3346079397788659], [-0.33994891609332367], [-0.5322240634138047], [1.4279142439922101], [2.3198572885066637], [1.2249571440428135], [0.47722046001872065], [0.8297248967729359], [0.386423862672938], [1.5774615807970287], [-2.4336116313607836], [-0.7885909265077794], [-0.1476737687728426], [0.7602922046849843], [-0.6924533528475388], [0.26892238375486616], [1.1395015230114884], [-0.8046138554511527], [-0.38267672660898616], [1.657576225513896], [-0.13699181614392697], [0.7122234178548641], [-0.5429060160427203], [-0.3346079397788659], [-0.1316508398294693], [2.656338796317505], [-0.302562081892119], [0.37040093372956445], [-0.745863115992117], [-0.8420006896523574], [0.15676188115125225], [-1.077003647488501], [0.7976790388861891], [0.3650599574151068], [0.5199482705343832], [0.4024467916163113], [-0.1957425556029629], [-0.12096888720055367], [-0.3559718450366971], [-0.606997731816214], [-0.7992728791366951], [2.2824704543054595], [-0.12096888720055367], [-0.6871123765330811], [-1.5042817526451253], [0.744269275741611], [0.13005699957896333], [-0.1423327924583848], [-1.1731412211487413], [-1.4668949184439208], [0.6000629152512502], [0.07664723643438522], [0.6694956073392017], [0.6962004889114908], [0.45585655476088943], [0.14073895220787894], [-0.6657484712752499], [-0.12096888720055367], [-1.32268855795356], [-0.44676844238247976], [0.9685902809488388], [-0.9327972869981402], [-0.6550665186463343], [-1.8834910709716295], [0.49324338896209396], [0.2315355495536616], [0.24221750218257723], [-0.0889230293138068], [-0.3506308687222393], [-0.11028693457163805], [0.40778776793076926], [-0.46813234764031103], [-1.3387114868969334], [-0.991548026457176], [0.21017164429583035], [-0.16369669771621603], [0.45585655476088943], [-0.035513266169228695], [3.361347669825936], [-0.38801770292344395], [0.47722046001872065], [0.3490370284717332], [0.4024467916163113], [-0.18506060297404728], [1.6148484149982336], [1.374504480847632], [0.6641546310247439], [0.8404068494018515], [0.2475584784970349], [1.2783669071873913], [1.0754098072379947], [-1.568373468418619], [0.3383550758428176], [-1.4134851552993426], [0.6321087731379971], [1.4172322913632946], [-0.07290010037043337], [0.824383920458478], [-0.249152318747541], [-1.0022299790860916], [0.6801775599681172], [1.81780551494763], [-0.32392598714995025], [-1.1143904816897054], [-1.4775768710728363], [0.8030200152006468], [-1.0129119317150073], [0.8083609915151047], [-0.01949033722585538], [1.700304036029558], [2.4053129095379884], [0.4291516731886005], [-0.8206367843945263], [0.14073895220787894], [-0.1904015792885051], [-0.7832499501933214], [-0.7298401870487435], [-1.4028032026704271], [0.8404068494018515], [0.5626760810500456], [0.2315355495536616], [-1.6698520183933174], [-0.4627913713258532], [1.0006361388355856], [-0.6283616370740452], [0.4238106968741426], [-0.0034674082824818287], [0.8404068494018515], [-0.49483722921260004], [-0.1316508398294693], [-1.568373468418619], [-0.26517524769091444], [0.6267677968235391], [0.09267016537775853], [0.5733580336789612], [1.1608654282693198], [-0.8954104527969355], [-0.8740465475391043], [0.07664723643438522], [2.4640636489970245], [2.496109506883771], [0.578699009993419], [-1.3867802737270536], [-0.3719947739800705], [0.6801775599681172], [1.8071235623187143], [-0.5963157791872984], [-0.07824107668489118], [0.9312034467476342], [1.016659067778959], [-0.38801770292344395], [-0.9488202159415136], [0.31165019427052865], [-1.1517773158909101], [1.3851864334765476], [-0.8580236185957308], [1.2035932387849821], [0.15676188115125225], [-1.0129119317150073], [0.023237473289807107], [-0.9381382633125979], [0.11403407063558978], [0.5733580336789612], [0.10335211800667415], [0.017896496975349414], [0.3650599574151068], [0.8457478257163092], [-0.745863115992117], [0.7602922046849843], [-0.13699181614392697], [-0.40404063186681727], [-2.0116745025186167], [0.0606243074910119], [-0.37733575029452837], [1.4012093624199211], [-0.8954104527969355], [-0.07290010037043337], [-0.5909748028728405], [-1.3440524632113913], [0.8510888020307672], [2.1008772596138936], [1.59882548605486], [1.540074746595824], [0.07664723643438522], [0.3276731232139022], [0.7923380625717311], [-1.0129119317150073], [0.30630921795607097], [-0.32392598714995025], [0.18880773903799913], [-0.6283616370740452], [0.0659652838054696], [-0.9221153343692245], [0.26892238375486616], [-1.1517773158909101], [-1.1357543869475368], [-0.25983427137645665], [-0.20642450823187852], [-1.237232936922235], [1.1181376177536573], [0.17278481009462582], [-1.9689466920029546], [1.6682581781428114], [-0.3079030582065768], [-1.648488113135486], [-1.3120066053246444], [-0.18506060297404728], [-0.6977943291619968], [-0.23312938980416759], [-1.514963705274041], [-0.5856338265583827], [0.7549512283705266], [0.6000629152512502], [0.6214268205090815], [1.3691635045331745], [1.6308713439416067], [1.1074556651247418], [-0.6176796844451296], [-1.183823173777657], [-0.18506060297404728], [1.6896220834006426], [-0.6817714002186231], [-0.6230206607595874], [0.909839541489803], [1.2035932387849821], [-1.3280295342680177], [-0.9167743580547667], [-0.34528989240778146], [0.4825614363331784], [-0.22778841348970977], [0.017896496975349414], [-0.16369669771621603], [-1.157118292205368], [0.9739312572632967], [-0.3933586792379018], [-0.8206367843945263], [0.300968241641613], [0.10869309432113208], [-1.1784821974631992], [-1.1143904816897054], [-0.0942640056282646], [0.5413121757922144], [-0.4200635608101907], [-0.8099548317656107], [0.3597189811006488], [-0.21710646086079413], [0.8777936836030561], [0.936544423062092], [1.897920159664497], [-0.44142746606802197], [0.3490370284717332], [-0.36665379766561274], [-0.21710646086079413], [2.4266768147958198], [-1.0075709554005494], [-1.5470095631607879], [-0.3132440345210346], [1.2356390966717292], [2.229060691160881], [-2.0437203604053638], [0.6534726783958283], [-0.4627913713258532], [-0.083582052999349], [0.3169911705849866], [1.710985988658474], [1.2890488598163072], [-0.23847036611862538], [0.41312874424522694], [-1.5576915157897036], [0.31165019427052865], [0.1674438337801679], [0.6534726783958283], [1.4706420545078724], [-0.23312938980416759], [0.4985843652765519], [-0.21176548454633634], [1.8551923491488345], [0.37040093372956445], [0.5573351047355877], [0.29028628901269743], [0.9205214941187186], [0.8083609915151047], [-0.05687717142705993], [-0.0942640056282646], [-0.9808660738282604], [-0.302562081892119], [-0.28119817663428776], [0.9792722335777544], [-1.787353497311389], [-0.660407494960792], [0.5573351047355877], [-0.7031353054764544], [-0.4360864897535641], [-0.2918801292632034], [0.8777936836030561], [0.29562726532715533], [0.43449264950305816], [-0.7084762817909123], [0.2315355495536616], [-1.8514452130848826], [-0.07824107668489118], [-0.01414936091139745], [0.033919425918722726], [1.2676849545584759], [-0.44676844238247976], [-0.9755250975138026], [-1.0663216948595853], [2.127582141186183], [0.5626760810500456], [-1.3013246526957287], [-0.1957425556029629], [-0.5535879686716358], [-0.7939319028222371], [-0.5322240634138047], [-1.0129119317150073], [-0.7405221396776591], [-0.28119817663428776], [-2.401565773474037], [1.0059771151500434], [-0.8793875238535621], [1.2837078835018494], [1.4332552203066677], [-1.4775768710728363], [-1.077003647488501], [0.35437800478619114], [1.3584815519042586], [-0.32926696346440804], [2.6616797726319636], [1.1982522624705245], [-1.0983675527463321], [-0.34528989240778146], [1.4759830308223303], [-0.964843144884887], [0.39176483898739567], [0.8404068494018515], [-0.9541611922559713], [2.3198572885066637], [0.909839541489803], [-0.6497255423318763], [-0.01414936091139745], [-0.9488202159415136], [0.6801775599681172], [-0.6924533528475388], [0.1674438337801679], [0.8991575888608874], [-1.3013246526957287], [-0.7725679975644059], [-1.4081441789848848], [0.3971058153018536], [-0.9327972869981402], [-1.7179208052234376], [-0.5055191818415157], [1.2676849545584759], [-1.3066656290101866], [-0.11028693457163805], [1.486664983451246], [0.4291516731886005], [-0.43074551343910633], [0.8617707546596828], [-2.454975536618615], [1.2516620256151023], [-0.8366597133378996], [-0.07824107668489118], [-0.9701841211993447], [-0.20642450823187852], [1.871215278092208], [-0.04619521879814432], [0.55199412842113], [-0.2438113424330832], [-2.289405270870423], [-0.2972211055776612], [-0.25983427137645665], [0.31165019427052865], [0.1674438337801679], [-1.4668949184439208], [-0.4734733239547688], [-0.7244992107342857], [0.6321087731379971], [-1.8300813078270515], [-1.0396168132872963], [-0.22778841348970977], [0.37574191004402235], [3.0942988541030454], [-0.06221814774151786], [-1.0930265764318743], [0.6694956073392017], [-0.991548026457176], [-2.3481560103294585], [-2.0811071946065685], [-0.38801770292344395], [2.1008772596138936], [-1.4508719895005473], [-0.991548026457176], [-0.606997731816214], [1.8872382070355815], [-0.21176548454633634], [0.19948969166691474], [0.8030200152006468], [-0.45210941869693755], [0.5893809626223345], [1.1662064045837774], [-0.32392598714995025], [0.5039253415910095], [0.09801114169221646], [0.9472263756910075], [-0.25983427137645665], [1.5507566992247397], [0.9151805178042607], [-1.1197314580041635], [0.2475584784970349], [0.8777936836030561], [0.7763151336283578], [0.1247160232645054], [-0.1423327924583848], [0.8404068494018515], [-0.4147225844957329], [-0.7512040923065747], [0.3650599574151068], [-0.2438113424330832], [-0.4147225844957329], [1.5026879123946195], [0.8777936836030561], [0.7976790388861891], [-0.7405221396776591], [2.202355809588592], [0.10335211800667415], [-0.7084762817909123], [-0.7779089738788638], [-1.0129119317150073], [0.6267677968235391], [1.1181376177536573], [-0.9968890027716338], [1.0273410204078746], [-2.4442935839896993], [1.0593868782946216], [-0.3132440345210346], [1.2730259308729337], [-0.6443845660174187], [-0.7885909265077794], [0.6801775599681172], [0.18880773903799913], [-0.4200635608101907], [0.5252892468488408], [-1.0129119317150073], [-0.3346079397788659], [-2.1345169577511465], [-0.6871123765330811], [0.6000629152512502], [-0.9221153343692245], [0.14607992852233664], [0.5947219389367925], [-1.3760983210981381], [-0.6550665186463343], [1.4920059597657038], [1.3104127650741384], [-1.4188261316138007], [1.5828025571114863], [0.220853596924746], [0.41312874424522694], [-0.11028693457163805], [-0.964843144884887], [0.47187948370426275], [1.182229333527151], [0.7763151336283578], [-1.6217832315631973], [-0.45210941869693755], [-0.9968890027716338], [-0.7779089738788638], [0.8457478257163092], [2.565542198971723], [-0.8900694764824777], [1.1395015230114884], [0.5092663179054675], [-0.33994891609332367], [0.25289945481149284], [0.220853596924746], [-0.8793875238535621], [0.5947219389367925], [-0.5856338265583827], [-0.8420006896523574], [-2.6472506839390957], [1.4973469360801615], [-0.2972211055776612], [-0.22244743717525195], [-1.3066656290101866], [0.023237473289807107], [-0.1423327924583848], [-0.548246992357178], [-0.040854242483686624], [-0.831318737023442], [1.0006361388355856], [1.4385961966211258], [0.9632493046343811], [-1.8140583788836782], [0.3276731232139022], [-0.3719947739800705], [-2.6258867786812647], [-0.01949033722585538], [-0.1476737687728426], [-0.44142746606802197], [0.7015414652259485], [0.18346676272354143], [-0.302562081892119], [0.9579083283199231], [0.6908595125970328], [-0.3346079397788659], [0.13005699957896333], [0.7122234178548641], [-0.40404063186681727], [-0.21176548454633634], [-0.36665379766561274], [2.3412211937644947], [0.386423862672938], [-1.023593884343923], [-0.21710646086079413], [-1.018252908029465], [-0.23847036611862538], [1.2943898361307649], [-1.568373468418619], [1.0487049256657057], [-0.07824107668489118], [1.022000044093417], [-0.8473416659668153], [2.528155364770518], [0.15142090483679457], [-2.0170154788330747], [-0.26517524769091444], [-1.7072388525945221], [0.10869309432113208], [-0.6016567555017561], [1.2997308124452225], [0.46653850738980507], [2.1062182359283517], [0.8083609915151047], [0.21551262061028806], [-1.9422418104306653], [-0.8366597133378996], [0.10869309432113208], [-1.3867802737270536], [-0.9701841211993447], [0.3223321468994443], [-0.302562081892119], [0.9685902809488388], [-0.9541611922559713], [0.25289945481149284], [1.3638225282187162], [-0.5215421107848891], [-0.6871123765330811], [-0.7992728791366951], [-1.6111012789342816], [-0.030172289854771002], [-0.030172289854771002], [-0.9862070501427181], [-1.6965568999656062], [0.4451746021319738], [0.6801775599681172], [1.0540459019801636], [-0.7244992107342857], [0.5626760810500456], [-0.49483722921260004], [0.14073895220787894], [1.454619125564499], [1.5560976755391975], [-1.2265509842933193], [1.7643957518030517], [-0.5963157791872984], [0.4291516731886005], [-0.083582052999349], [-0.3185850108354924], [-0.32926696346440804], [1.2302981203572712], [-0.6871123765330811], [1.7590547754885941], [-0.7565450686210325], [-1.3867802737270536], [-0.15835572140175821], [0.3490370284717332], [-0.37733575029452837], [0.135397975893421], [-0.49483722921260004], [1.1982522624705245], [0.3971058153018536], [-0.0942640056282646], [0.5626760810500456], [-0.302562081892119], [-0.11562791088609585], [1.9192840649223282], [-0.9755250975138026], [0.4238106968741426], [-0.040854242483686624], [0.7923380625717311], [-0.42540453712464854], [0.09267016537775853], [0.22619457323920367], [0.47187948370426275], [-1.0075709554005494], [1.8284874675765455], [3.2438461909078637], [-0.4788143002692266], [-1.0075709554005494], [0.04460137854763835], [-0.4788143002692266], [-2.1345169577511465], [0.2635814074404085], [0.11403407063558978], [-2.0490613367198214], [-0.6550665186463343], [0.17278481009462582], [1.1448424993259463], [0.04460137854763835], [-0.07290010037043337], [0.07664723643438522], [-0.7832499501933214], [0.37040093372956445], [-0.4360864897535641], [-0.8580236185957308], [-1.130413410633079], [0.47187948370426275], [-0.48949625289814225], [-0.46813234764031103], [-0.7565450686210325], [0.08198821274884291], [-0.8687055712246464], [-0.16369669771621603], [0.14607992852233664], [0.7869970862572735], [-0.09960498194272242], [-0.32926696346440804], [-0.09960498194272242], [-0.9968890027716338], [-0.7939319028222371], [0.35437800478619114], [-0.7191582344198278], [-1.3387114868969334], [1.9086021122934127], [2.704407583147626], [-0.9488202159415136], [1.0380229730367905], [-0.0942640056282646], [-1.0823446238029586], [-0.28119817663428776], [1.2730259308729337], [0.909839541489803], [0.1674438337801679], [-1.7766715446824737], [-1.3066656290101866], [1.2943898361307649], [0.220853596924746], [0.49324338896209396], [-0.9488202159415136], [0.578699009993419], [0.7923380625717311], [1.5934845097404022], [0.6534726783958283], [-1.3707573447836803], [-1.050298765916212], [-0.4788143002692266], [-0.606997731816214], [0.4825614363331784], [1.0540459019801636], [0.2635814074404085], [1.5347337702813661], [1.1074556651247418], [0.11403407063558978], [-0.2705162240053721], [-0.2438113424330832], [-0.825977760708984], [2.2344016674753386], [0.824383920458478], [-0.1316508398294693], [-1.0396168132872963], [0.6107448678801658], [-0.44676844238247976], [-1.4775768710728363], [-0.745863115992117], [-0.8687055712246464], [-0.0889230293138068], [0.9312034467476342], [-0.37733575029452837], [-0.28119817663428776], [0.5733580336789612], [0.04994235486209628], [-1.2479148895511507], [-0.3986996555523596], [0.08198821274884291], [2.175650928016303], [-0.9755250975138026], [1.3317766703319698], [1.9459889464946172], [0.3276731232139022], [0.5733580336789612], [-0.1476737687728426], [-0.44142746606802197], [-0.11562791088609585], [0.6748365836536595], [0.2742633600693241], [-0.5749518739294671], [-0.22778841348970977], [-1.183823173777657], [0.5306302231632988], [-0.5215421107848891], [-1.3867802737270536], [-0.17437865034513164], [-0.7939319028222371], [0.17278481009462582], [0.4398336258175161], [-0.024831313540313073], [-0.05687717142705993], [1.9673528517524483], [1.192911286156067], [0.1674438337801679], [-1.1945051264065725], [-0.8900694764824777], [-0.5909748028728405], [-0.9488202159415136], [-0.8420006896523574], [-0.6283616370740452], [1.524051817652451], [0.5466531521066721], [-0.5162011344704313], [-0.42540453712464854], [-0.1957425556029629], [-0.5963157791872984], [0.6321087731379971], [-0.302562081892119], [-0.05153619511260225], [1.6308713439416067], [0.7229053704837797], [-0.8687055712246464], [-1.0983675527463321], [-1.3387114868969334], [-0.580292850243925], [-0.10494595825718023], [-0.8580236185957308], [-0.9434792396270558], [-0.7244992107342857], [-1.1250724343186211], [0.3971058153018536], [-0.23847036611862538], [-1.349393439525849], [2.389289980594615], [0.7709741573139], [2.1382640938150983], [-0.07290010037043337], [-0.49483722921260004], [1.5934845097404022], [1.0326819967223322], [0.9739312572632967], [-1.0075709554005494], [-1.3280295342680177], [-1.1517773158909101], [-0.49483722921260004], [-0.8900694764824777], [1.214275191413898], [1.2196161677283557], [0.6801775599681172], [-0.8900694764824777], [-0.249152318747541], [-1.4508719895005473], [-0.22244743717525195], [0.9525673520054655], [-0.2972211055776612], [-0.2544932950619988], [3.174413498819913], [-0.4093816081812751], [-0.15835572140175821], [1.6308713439416067], [-0.5963157791872984], [0.08732918906330084], [0.8617707546596828], [0.37040093372956445], [-0.01414936091139745], [-1.0022299790860916], [0.386423862672938], [-1.5523505394752457], [0.9792722335777544], [0.3650599574151068], [-0.2705162240053721], [-0.13699181614392697], [-0.7779089738788638], [-0.17971962665958946], [-0.9274563106836823], [0.6160858441946235], [1.2783669071873913], [-0.3933586792379018], [-0.13699181614392697], [0.07130626011992729], [-0.831318737023442], [-0.5589289449860937], [1.315753741388596], [2.1542870227584716], [0.4024467916163113], [-0.28119817663428776], [0.6054038915657078], [-0.6817714002186231], [-0.3986996555523596], [0.9205214941187186], [1.6148484149982336], [0.5680170573645034], [0.8404068494018515], [-0.8366597133378996], [0.6267677968235391], [-0.25983427137645665], [-0.22778841348970977], [0.8671117309741405], [-0.5375650397282624], [1.7804186807464253], [0.4291516731886005], [-0.5856338265583827], [0.05528333117655397], [-0.2544932950619988], [-0.4093816081812751], [-0.249152318747541], [0.8831346599175138], [1.524051817652451], [-0.1957425556029629], [0.14607992852233664], [2.7684992989211192], [0.6534726783958283], [-0.9434792396270558], [1.7483728228596787], [-2.0437203604053638], [0.3436960521572755], [1.81780551494763], [-1.8087174025692203], [-0.831318737023442], [-1.4668949184439208], [0.0018735680319758635], [-0.7084762817909123], [0.39176483898739567], [0.8137019678295624], [-0.5322240634138047], [0.039260402233180655], [-1.32268855795356], [0.29028628901269743], [-1.2692787948089819], [-0.0942640056282646], [-0.9007514291113933], [-1.1945051264065725], [0.3810828863584801], [0.6054038915657078], [-0.6283616370740452], [1.080750783552453], [-0.9221153343692245], [-1.3440524632113913], [0.039260402233180655], [-1.2265509842933193], [-0.964843144884887], [0.1781257864090835], [0.717564394169322], [0.21017164429583035], [-0.024831313540313073], [1.2570030019295606], [0.2368765258681193], [-1.2318919606077774], [1.011318091464501], [1.5614386518536552], [-0.18506060297404728], [-1.2212100079788617], [0.09267016537775853], [-0.580292850243925], [0.8190429441440203], [0.07664723643438522], [-0.07824107668489118], [1.2676849545584759], [0.3490370284717332], [0.4825614363331784], [-0.09960498194272242], [-0.6497255423318763], [0.5359711994777565], [-1.0396168132872963], [0.6855185362825752], [0.41846972055968484], [1.2997308124452225], [1.8017825860042564], [-0.302562081892119], [0.9739312572632967], [-1.1464363395764523], [-0.27585720031982996], [-0.7618860449354904], [-1.1731412211487413], [-0.3613128213511549], [-2.022356455147533], [-1.4989407763306677], [0.07664723643438522], [0.5466531521066721], [-1.3974622263559693], [-0.7725679975644059], [0.10335211800667415], [-0.7939319028222371], [-0.5642699213005515], [0.300968241641613], [0.6694956073392017], [-0.11028693457163805], [-0.12630986351501147], [0.09267016537775853], [-0.040854242483686624], [-0.5696108976150093], [0.3276731232139022], [-0.22778841348970977], [-0.05153619511260225], [-0.6230206607595874], [-0.12096888720055367], [-1.5897373736764504], [-0.1423327924583848], [1.2997308124452225], [-1.7392847104812688], [0.37040093372956445], [0.6908595125970328], [0.7656331809994422], [0.2849453126982397], [1.8658743017777504], [0.3490370284717332], [0.135397975893421], [0.6534726783958283], [0.0018735680319758635], [0.5092663179054675], [0.19948969166691474], [2.127582141186183], [-0.34528989240778146], [0.14073895220787894], [-0.16903767403067385], [-0.6710894475897076], [-1.0289348606583806], [-0.3986996555523596], [0.300968241641613], [-0.4574503950113954], [0.31165019427052865], [-0.9755250975138026], [-0.2918801292632034], [0.5199482705343832], [-0.16369669771621603], [-1.648488113135486], [-1.1090495053752478], [0.007214544346433793], [1.353140575589801], [0.4398336258175161], [-1.0663216948595853], [-0.8366597133378996], [-0.5589289449860937], [-0.040854242483686624], [-1.077003647488501], [0.4985843652765519], [1.070068830923537], [-0.024831313540313073], [-0.302562081892119], [1.2730259308729337], [-0.3986996555523596], [1.9940577333247378], [0.14607992852233664], [-1.2959836763812709], [-0.48415527658368446], [-0.28119817663428776], [-1.0609807185451274], [-0.9434792396270558], [-0.8366597133378996], [0.29562726532715533], [-0.17437865034513164], [0.6160858441946235], [0.19948969166691474], [-0.6977943291619968], [-0.5963157791872984], [-0.2705162240053721], [0.3330140995283599], [1.7643957518030517], [0.9044985651753451], [0.1674438337801679], [-1.1624592685198256], [-0.37733575029452837], [1.155524451954862], [-2.1932676972101826], [3.697829177636778], [0.3276731232139022], [-0.024831313540313073], [0.21017164429583035], [-0.6390435897029607], [-0.49483722921260004], [-0.2544932950619988], [-0.6390435897029607], [0.028578449604265036], [0.3436960521572755], [0.3436960521572755], [0.13005699957896333], [0.3597189811006488], [0.7869970862572735], [3.142367640933166], [0.2475584784970349], [0.039260402233180655], [-0.8473416659668153], [-0.5162011344704313], [-0.8900694764824777], [-0.36665379766561274], [-0.7565450686210325], [1.81780551494763], [0.7869970862572735], [-0.7939319028222371], [1.1715473808982355], [-1.97962864463187], [-0.548246992357178], [-1.3280295342680177], [-0.09960498194272242], [0.8190429441440203], [0.6481317020813704], [1.9406479701801593], [0.5199482705343832], [-0.7832499501933214], [-1.3066656290101866], [2.7097485594620836], [0.3383550758428176], [0.09801114169221646], [0.7496102520560687], [1.7964416096897988], [0.8350658730873937], [-1.0129119317150073], [0.2582404311259505], [-0.9381382633125979], [1.9192840649223282], [-1.0663216948595853], [-1.050298765916212], [-0.7672270212499481], [-0.8206367843945263], [0.9312034467476342], [0.31165019427052865], [-0.8099548317656107], [3.291914977737984], [-0.6283616370740452], [-0.5429060160427203], [-0.32392598714995025], [-0.10494595825718023], [0.29028628901269743], [1.4439371729355837], [1.2249571440428135], [-1.434849060557174], [-0.12096888720055367], [0.6534726783958283], [0.717564394169322], [-1.5470095631607879], [-0.2918801292632034], [0.5092663179054675], [1.4706420545078724], [-0.3185850108354924], [3.5002130540018386], [0.6374497494524547], [0.10869309432113208], [0.37040093372956445], [0.8671117309741405], [1.8551923491488345], [0.6107448678801658], [-0.23847036611862538], [0.35437800478619114], [0.033919425918722726], [0.25289945481149284], [0.39176483898739567], [0.3597189811006488], [-0.15835572140175821], [1.0006361388355856], [-0.2438113424330832], [0.09267016537775853], [0.8190429441440203], [-0.6497255423318763], [0.300968241641613], [-0.1316508398294693], [1.022000044093417], [-1.1624592685198256], [-1.2853017237523554], [0.21551262061028806], [-0.4360864897535641], [-0.26517524769091444], [0.24221750218257723], [0.5680170573645034], [0.6374497494524547], [1.0914327361813683], [-2.6899784944547585], [-0.5055191818415157], [0.6000629152512502], [-1.0129119317150073], [-1.1090495053752478], [0.9525673520054655], [1.1715473808982355], [-0.05687717142705993], [0.45585655476088943], [0.3223321468994443], [-0.2705162240053721], [-0.06755912405597556], [0.04460137854763835], [-0.9007514291113933], [0.10335211800667415], [0.8083609915151047], [0.9205214941187186], [-1.648488113135486], [0.6748365836536595], [-0.9808660738282604], [-2.219972578782471], [0.8671117309741405], [0.5092663179054675], [0.2849453126982397], [0.7496102520560687], [0.007214544346433793], [-0.6497255423318763], [0.47187948370426275], [-1.0823446238029586], [0.3810828863584801], [0.2635814074404085], [-0.8900694764824777], [-0.3986996555523596], [1.3851864334765476], [0.0018735680319758635], [2.9073646830970223], [-0.27585720031982996], [-0.01414936091139745], [-0.1904015792885051], [-0.07290010037043337], [1.8872382070355815], [-0.42540453712464854], [-1.7392847104812688], [0.8030200152006468], [1.4813240071367884], [-1.7766715446824737], [-0.5001782055270578], [-0.7779089738788638], [0.47187948370426275], [-0.6230206607595874], [-0.5055191818415157], [1.6308713439416067], [-1.0876856001174167], [-0.46813234764031103], [-0.964843144884887], [-2.155880863008978], [1.4813240071367884], [0.8404068494018515], [0.9685902809488388], [0.007214544346433793], [-1.4241671079282583], [0.5252892468488408], [-0.05687717142705993], [-0.23312938980416759], [-1.242573913236693], [0.46653850738980507], [-0.3986996555523596], [0.19414871535245706], [1.5828025571114863], [-0.4788143002692266], [-0.05153619511260225], [0.5359711994777565], [2.0741723780416046], [-0.2972211055776612], [-1.8514452130848826], [2.9233876120403957], [0.14607992852233664], [-0.6817714002186231], [0.028578449604265036], [-0.7725679975644059], [-0.9434792396270558], [-0.7298401870487435], [0.4291516731886005], [-0.5215421107848891], [-0.09960498194272242], [0.6534726783958283], [0.08198821274884291], [-0.5055191818415157], [-0.0889230293138068], [-0.6016567555017561], [-0.16369669771621603], [0.6000629152512502], [1.6362123202560648], [0.04994235486209628], [-0.548246992357178], [-0.5322240634138047], [0.37040093372956445], [-1.97962864463187], [0.6908595125970328], [-0.38801770292344395], [-2.139857934065604], [-0.8954104527969355], [-0.7031353054764544], [-0.40404063186681727], [1.374504480847632], [-0.6977943291619968], [-0.9274563106836823], [-0.21176548454633634], [-1.1624592685198256], [0.2475584784970349], [-1.9742876683174124], [-0.3986996555523596], [-0.9755250975138026], [1.0647278546090795], [-1.0716626711740431], [-1.5096227289595834], [-0.6123387081306718], [-1.429508084242716], [0.220853596924746], [0.4451746021319738], [-0.3559718450366971], [-0.6764304239041655], [1.454619125564499], [-1.050298765916212], [-0.20642450823187852], [0.07664723643438522], [0.6107448678801658], [0.9952951625211279], [0.1247160232645054], [0.29562726532715533], [-0.030172289854771002], [0.47187948370426275], [-0.8847285001680198], [0.20483066798137242], [0.4291516731886005], [-0.9755250975138026], [0.08732918906330084], [-0.8740465475391043], [0.25289945481149284], [-0.6764304239041655], [-0.48949625289814225], [-1.1624592685198256], [1.3584815519042586], [-0.01414936091139745], [-0.548246992357178], [1.2623439782440182], [-1.4028032026704271], [1.2730259308729337], [1.2943898361307649], [-0.21710646086079413], [-0.01949033722585538], [0.13005699957896333], [-1.488258823701752], [0.19948969166691474], [0.7656331809994422], [-0.9060924054258511], [0.46119753107534733], [-0.9862070501427181], [0.007214544346433793], [0.55199412842113], [1.022000044093417], [-0.07824107668489118], [0.5252892468488408], [-0.9755250975138026], [0.5092663179054675], [-0.1316508398294693], [1.9673528517524483], [-0.4147225844957329], [-0.28653915294874555], [-0.8633645949101887], [0.2796043363837818], [0.9472263756910075], [-0.12096888720055367], [2.175650928016303], [0.19948969166691474], [0.9418853993765498], [0.6000629152512502], [-0.4360864897535641], [-1.0930265764318743], [-0.008808384596939759], [-1.0823446238029586], [-0.6016567555017561], [1.1021146888102842], [-0.23847036611862538], [1.9940577333247378], [0.2849453126982397], [-1.0823446238029586], [0.3169911705849866], [0.135397975893421], [1.5293927939669085], [-0.008808384596939759], [1.1982522624705245], [2.4533816963681088], [0.29562726532715533], [-0.9595021685704291], [-1.2585968421800662], [0.2635814074404085], [-0.7405221396776591], [0.2849453126982397], [3.323960835624731], [0.5733580336789612], [-0.9701841211993447], [0.8350658730873937], [0.5306302231632988], [0.05528333117655397], [-0.7351811633632013], [-0.6817714002186231], [0.4879024126476363], [0.8137019678295624], [-0.6550665186463343], [0.7602922046849843], [1.540074746595824], [-1.6645110420788596], [0.5359711994777565], [0.6748365836536595], [-0.7618860449354904], [0.5466531521066721], [-0.1316508398294693], [-1.8300813078270515], [0.9418853993765498], [2.832591014694613], [-0.18506060297404728], [0.8404068494018515], [-1.0556397422306698], [0.37574191004402235], [0.578699009993419], [0.8137019678295624], [-0.17971962665958946], [1.2730259308729337], [-0.45210941869693755], [0.3223321468994443], [-0.9968890027716338], [-0.6123387081306718], [-0.09960498194272242], [-1.32268855795356], [-0.526883087099347], [-0.008808384596939759], [-0.07824107668489118], [0.43449264950305816], [-0.25983427137645665], [-1.5523505394752457], [0.6481317020813704], [0.5359711994777565], [-1.0075709554005494], [-0.3346079397788659], [1.1608654282693198], [-0.1904015792885051], [1.5881435334259442], [-0.37733575029452837], [-0.5001782055270578], [-0.09960498194272242], [0.9525673520054655], [0.10869309432113208], [0.5199482705343832], [-0.15835572140175821], [0.9472263756910075], [-0.32392598714995025], [-0.4093816081812751], [-0.3559718450366971], [-1.792694473625847], [0.30630921795607097], [-0.6977943291619968], [0.220853596924746], [1.022000044093417], [0.5359711994777565], [-1.1357543869475368], [0.6054038915657078], [0.3276731232139022], [-1.3921212500415114], [-0.22778841348970977], [-1.050298765916212], [-0.5162011344704313], [-0.9327972869981402], [-0.024831313540313073], [0.5359711994777565], [-0.7031353054764544], [0.21017164429583035], [0.5359711994777565], [0.7282463467982376], [0.1193750469500477], [-0.4788143002692266], [-0.1423327924583848], [-0.1316508398294693], [-1.0289348606583806], [-0.36665379766561274], [-2.7647521628571674], [0.8617707546596828], [-1.3867802737270536], [-0.04619521879814432], [0.7656331809994422], [1.2302981203572712], [-0.12096888720055367], [-0.01949033722585538], [-0.06755912405597556], [-1.1678002448342837], [-0.22778841348970977], [2.1809919043307606], [0.8297248967729359], [-0.6817714002186231], [-1.1678002448342837], [-1.6057603026198237], [-1.0663216948595853], [-0.6123387081306718], [0.09267016537775853], [0.8724527072885981], [1.022000044093417], [-0.9968890027716338], [0.2635814074404085], [0.6267677968235391], [1.182229333527151], [0.0606243074910119], [2.015421638582569], [-0.7779089738788638], [-0.07290010037043337], [0.22619457323920367], [-0.5749518739294671], [-0.7298401870487435], [3.4361213382283453], [0.6427907257669127], [-0.05687717142705993], [-0.8206367843945263], [0.41312874424522694], [0.4398336258175161], [-2.828843878630661], [-0.12630986351501147], [-0.7779089738788638], [-0.8366597133378996], [0.2635814074404085], [-0.1476737687728426], [0.14607992852233664], [0.9685902809488388], [1.3371176466464274], [0.37040093372956445], [0.49324338896209396], [-0.4574503950113954], [-0.852682642281273], [1.9406479701801593], [-0.3185850108354924], [-0.33994891609332367], [0.98995418620667], [2.757817346292204], [1.4012093624199211], [-0.5001782055270578], [1.1127966414391997], [2.0741723780416046], [1.1074556651247418], [-0.1476737687728426], [-1.7286027578523533], [0.25289945481149284], [0.15676188115125225], [-0.0034674082824818287], [1.4813240071367884], [-0.36665379766561274], [0.9044985651753451], [0.6694956073392017], [-0.3559718450366971], [-0.5963157791872984], [-0.6390435897029607], [0.5466531521066721], [1.0914327361813683], [0.8083609915151047], [-0.26517524769091444], [-0.01414936091139745], [0.4291516731886005], [-0.06755912405597556], [-1.4668949184439208], [0.55199412842113], [0.5626760810500456], [-0.7512040923065747], [-0.34528989240778146], [-1.2639378184945242], [-0.5375650397282624], [0.10869309432113208], [-0.8580236185957308], [-0.0889230293138068], [-1.2799607474378976], [-0.3613128213511549], [1.0754098072379947], [1.0914327361813683], [0.5092663179054675], [0.7335873231126954], [-1.2746197711234395], [-1.3066656290101866], [1.2676849545584759], [0.9685902809488388], [-0.6443845660174187], [-2.065084265663195], [2.6616797726319636], [1.016659067778959], [1.5080288887090774], [-0.4734733239547688], [1.700304036029558], [0.909839541489803], [0.6908595125970328], [3.8260126091837647], [-1.354734415840307], [0.15142090483679457], [-0.302562081892119], [0.6160858441946235], [0.8884756362319718], [-1.2959836763812709], [-0.035513266169228695], [0.6641546310247439], [2.3839490042801574], [0.5733580336789612], [-0.040854242483686624], [-0.5322240634138047], [0.7763151336283578], [0.6481317020813704], [2.3839490042801574], [0.8137019678295624], [-1.846104236770425], [0.5359711994777565], [-1.3867802737270536], [0.43449264950305816], [0.20483066798137242], [-0.3506308687222393], [-1.568373468418619], [-0.7512040923065747], [-0.8420006896523574], [0.15142090483679457], [-0.7031353054764544], [1.2997308124452225], [-1.050298765916212], [-0.16903767403067385], [0.9525673520054655], [0.5680170573645034], [-2.0116745025186167], [-0.8152958080800683], [0.017896496975349414], [0.3223321468994443], [1.7750777044319677], [-0.5429060160427203], [-0.008808384596939759], [0.1781257864090835], [0.08198821274884291], [2.6670207489464213], [-0.5749518739294671], [-1.1678002448342837], [0.08198821274884291], [-0.8099548317656107], [-1.2906427000668133], [0.07664723643438522], [-0.23312938980416759], [-0.3719947739800705], [-0.825977760708984], [2.3572441227078684], [0.20483066798137242], [0.6054038915657078], [0.14607992852233664], [-1.4668949184439208], [0.017896496975349414], [0.744269275741611], [-1.3921212500415114], [0.7602922046849843], [0.10869309432113208], [1.3317766703319698], [0.04460137854763835], [1.2302981203572712], [0.3597189811006488], [1.0647278546090795], [-0.7084762817909123], [0.3597189811006488], [0.7763151336283578], [0.39176483898739567], [1.2623439782440182], [-0.5322240634138047], [0.220853596924746], [1.3317766703319698], [-0.633702613388503], [-1.2959836763812709], [0.3276731232139022], [1.1662064045837774], [0.6748365836536595], [1.6362123202560648], [0.017896496975349414], [0.18880773903799913], [-0.3079030582065768], [-0.21710646086079413], [-1.32268855795356], [-0.12096888720055367], [0.47187948370426275], [-1.7232617815378954], [-0.8152958080800683], [-0.4200635608101907], [2.8592958962669024], [0.5733580336789612], [0.8564297783452248], [-0.22778841348970977], [-0.1957425556029629], [0.9792722335777544], [-0.5909748028728405], [-0.3613128213511549], [0.5413121757922144], [1.7537137991741363], [1.5347337702813661], [0.5413121757922144], [-0.6283616370740452], [-1.2479148895511507], [0.6534726783958283], [0.936544423062092], [-0.4574503950113954], [1.155524451954862], [-1.8300813078270515], [-1.8407632604559674], [-1.0663216948595853], [-0.16903767403067385], [-1.6965568999656062], [-0.6176796844451296], [-0.9381382633125979], [0.9258624704331763], [-0.5749518739294671], [1.1768883572126934], [-1.2585968421800662], [2.5174734121416025], [0.6267677968235391], [1.7643957518030517], [-0.33994891609332367], [-2.6579326365680114], [0.40778776793076926], [1.7697367281175098], [0.3597189811006488], [0.5893809626223345], [1.0487049256657057], [-1.5897373736764504], [-0.44142746606802197], [0.7602922046849843], [-0.45210941869693755], [-0.8152958080800683], [-0.9434792396270558], [1.7216679412873892], [0.717564394169322], [-0.36665379766561274], [0.3810828863584801], [-0.1957425556029629], [-0.18506060297404728], [-0.5589289449860937], [1.5293927939669085], [-0.8099548317656107], [0.8831346599175138], [-1.5096227289595834], [0.5573351047355877], [1.353140575589801], [-0.8046138554511527], [-0.5322240634138047], [-0.6016567555017561], [0.4238106968741426], [0.7816561099428155], [-1.9315598578017499], [-0.5749518739294671], [0.29562726532715533], [0.8564297783452248], [0.3276731232139022], [0.31165019427052865], [-1.2532558658656086], [-0.12096888720055367], [0.10335211800667415], [-1.4455310131860895], [0.14073895220787894], [-0.9862070501427181], [-0.4147225844957329], [-1.792694473625847], [-1.3600753921547646], [0.8831346599175138], [0.3276731232139022], [-2.123835005122231], [0.3330140995283599], [1.5454157229102816], [-0.7885909265077794], [-0.05153619511260225], [1.2302981203572712], [-0.4574503950113954], [-1.2265509842933193], [-0.030172289854771002], [-0.4627913713258532], [0.3276731232139022], [-1.7392847104812688], [-0.660407494960792], [0.8457478257163092], [1.9459889464946172], [1.4225732676777523], [1.4920059597657038], [-0.5055191818415157], [0.7816561099428155], [1.7483728228596787], [1.155524451954862], [-0.40404063186681727], [-0.745863115992117], [3.8420355381271385], [-1.488258823701752], [0.135397975893421], [0.8030200152006468], [-0.07290010037043337], [-0.9167743580547667], [-0.17971962665958946], [0.2368765258681193], [-0.6924533528475388], [0.7976790388861891], [-0.7084762817909123], [-0.8900694764824777], [1.6201893913126912], [-0.07824107668489118], [0.3650599574151068], [1.3050717887596808], [-0.6497255423318763], [0.023237473289807107], [-0.27585720031982996], [0.007214544346433793], [0.7763151336283578], [-0.1904015792885051], [-0.6977943291619968], [-0.6550665186463343], [1.0647278546090795], [-0.6550665186463343], [-0.030172289854771002], [-0.8206367843945263], [0.07130626011992729], [-0.2010835319174207], [1.1501834756404044], [1.070068830923537], [-0.7832499501933214], [-0.5696108976150093], [2.389289980594615], [-0.7351811633632013], [1.3691635045331745], [-1.6965568999656062], [-0.38801770292344395], [0.2742633600693241], [-0.07824107668489118], [-0.5162011344704313], [0.11403407063558978], [0.744269275741611], [-0.5535879686716358], [0.4451746021319738], [-0.06221814774151786], [-0.46813234764031103], [-2.4122477261029527], [-0.6123387081306718], [1.342458622960885], [1.1982522624705245], [0.6267677968235391], [0.25289945481149284], [3.4040754803415982], [-0.17971962665958946], [0.13005699957896333], [3.1637315461909976], [-0.33994891609332367], [0.09267016537775853], [0.2849453126982397], [1.2035932387849821], [0.3650599574151068], [-1.4134851552993426], [1.0059771151500434], [0.7763151336283578], [-0.16903767403067385], [-1.1143904816897054], [-0.030172289854771002], [-0.8633645949101887], [-0.6817714002186231], [0.3383550758428176], [-0.7405221396776591], [0.08198821274884291], [-0.040854242483686624], [0.08198821274884291], [0.07130626011992729], [-0.9060924054258511], [0.1781257864090835], [0.22619457323920367], [-2.529749205021024], [-0.083582052999349], [3.2331642382789485], [-0.7885909265077794], [1.6682581781428114], [0.3330140995283599], [-0.32392598714995025], [-0.5001782055270578], [-1.8888320472860876], [0.5199482705343832], [1.2676849545584759], [-1.1143904816897054], [-0.11562791088609585], [-1.2853017237523554], [-0.7298401870487435], [1.1982522624705245], [1.0647278546090795], [1.353140575589801], [-1.5897373736764504], [-1.0663216948595853], [-0.5963157791872984], [-0.8046138554511527], [1.1982522624705245], [1.9353069938657017], [0.3330140995283599], [-0.6657484712752499], [0.6962004889114908], [2.143605070129556], [0.4238106968741426], [-0.9221153343692245], [-0.5749518739294671], [0.09267016537775853], [-0.38801770292344395], [-2.7540702102282517], [-0.6016567555017561], [-0.06221814774151786], [1.043363949351248], [-0.16369669771621603], [0.3810828863584801], [0.18346676272354143], [0.5733580336789612], [-0.22778841348970977], [1.6682581781428114], [0.09267016537775853], [1.315753741388596], [0.386423862672938], [-0.1957425556029629], [1.4012093624199211], [-0.9434792396270558], [-0.8473416659668153], [0.028578449604265036], [-0.8420006896523574], [-0.01414936091139745], [-0.8847285001680198], [-0.36665379766561274], [-0.8152958080800683], [-1.3654163684692224], [-1.5416685868463298], [-0.44676844238247976], [-0.4734733239547688], [-0.22778841348970977], [-0.06755912405597556], [-0.7031353054764544], [0.29028628901269743], [-0.7832499501933214], [-0.27585720031982996], [-2.0971301235499418], [-0.3719947739800705], [-2.1078120761788575], [-0.12096888720055367], [-0.040854242483686624], [0.6481317020813704], [0.24221750218257723], [0.0659652838054696], [-0.49483722921260004], [-0.01949033722585538], [1.59882548605486], [0.05528333117655397], [0.29562726532715533], [0.8777936836030561], [-0.16369669771621603], [-0.23847036611862538], [1.0326819967223322], [-0.6657484712752499], [0.25289945481149284], [0.6054038915657078], [0.6534726783958283], [-1.488258823701752], [0.9205214941187186], [1.9620118754379907], [-0.6924533528475388], [0.37040093372956445], [-1.648488113135486], [0.3169911705849866], [1.1395015230114884], [-0.16903767403067385], [-1.9315598578017499], [-0.01414936091139745], [0.19948969166691474], [-0.035513266169228695], [0.3223321468994443], [0.6374497494524547], [-0.040854242483686624], [0.3330140995283599], [-2.4923623708198197], [-0.26517524769091444], [-0.9595021685704291], [-1.434849060557174], [0.20483066798137242], [-0.2918801292632034], [-0.38267672660898616], [1.524051817652451], [-0.9007514291113933], [-0.8366597133378996], [2.3305392411355794], [0.13005699957896333], [-0.8152958080800683], [0.1193750469500477], [-0.8793875238535621], [-0.3719947739800705], [-1.685874947336691], [0.05528333117655397], [-0.580292850243925], [0.14073895220787894], [0.07664723643438522], [-0.5108601581559735], [-0.46813234764031103], [-0.4627913713258532], [1.9833757806958219], [-0.5001782055270578], [0.5893809626223345], [1.3210947177030539], [0.4825614363331784], [-0.5108601581559735], [0.6694956073392017], [-0.606997731816214], [1.1608654282693198], [-0.6230206607595874], [0.07664723643438522], [1.513369865023535], [0.29028628901269743], [1.1234785940681153], [0.3650599574151068], [0.8884756362319718], [-2.219972578782471], [-0.7512040923065747], [-1.8033764262547625], [-0.22778841348970977], [0.11403407063558978], [0.9685902809488388], [0.2635814074404085], [2.0634904254126893], [-0.2972211055776612], [0.9792722335777544], [-0.34528989240778146], [1.1395015230114884], [-0.7565450686210325], [-1.434849060557174], [-0.7084762817909123], [1.897920159664497], [-0.6443845660174187], [0.039260402233180655], [1.214275191413898], [1.684281107086185], [0.31165019427052865], [-1.077003647488501], [-0.9060924054258511], [-0.6176796844451296], [-1.3120066053246444], [-0.28119817663428776], [1.7697367281175098], [-0.633702613388503], [0.0606243074910119], [1.9086021122934127], [0.8938166125464294], [-0.5535879686716358], [0.13005699957896333], [2.1863328806452182], [1.1501834756404044], [0.7602922046849843], [0.039260402233180655], [0.3169911705849866], [0.29562726532715533], [-0.5963157791872984], [-0.526883087099347], [-0.9541611922559713], [0.5413121757922144], [-1.3867802737270536], [0.05528333117655397], [-1.4775768710728363], [0.7282463467982376], [-2.0971301235499418], [1.673599154457269], [0.5413121757922144], [0.5199482705343832], [-0.6283616370740452], [2.6830436778897946], [0.7335873231126954], [-0.1904015792885051], [0.6748365836536595], [-0.11028693457163805], [-0.2010835319174207], [0.6214268205090815], [0.220853596924746], [-0.0942640056282646], [-2.4656574892475307], [2.3198572885066637], [-2.3107691761282543], [1.1662064045837774], [0.2315355495536616], [-0.5909748028728405], [0.1781257864090835], [-0.21710646086079413], [-1.872809118342714], [-1.9155369288583763], [-1.1945051264065725], [0.9685902809488388], [-0.10494595825718023], [-0.4627913713258532], [0.2849453126982397], [-0.964843144884887], [0.16210285746571018], [-0.26517524769091444], [-0.964843144884887], [-0.3506308687222393], [-1.2959836763812709], [-0.49483722921260004], [-1.0716626711740431], [-0.9808660738282604], [-0.6764304239041655], [-0.0889230293138068], [-0.6283616370740452], [-0.964843144884887], [-2.129175981436689], [1.8391694202054614], [-0.07290010037043337], [0.3597189811006488], [0.023237473289807107], [-0.6497255423318763], [0.9739312572632967], [0.9952951625211279], [-0.040854242483686624], [0.386423862672938], [-0.7885909265077794], [0.135397975893421], [0.6641546310247439], [-0.1957425556029629], [-1.6431471368210284], [0.20483066798137242], [-0.6390435897029607], [0.26892238375486616], [1.785759657060883], [0.6962004889114908], [-1.2479148895511507], [-0.4734733239547688], [0.21017164429583035], [-1.1197314580041635], [-1.2158690316644039], [-0.5001782055270578], [-1.4081441789848848], [-1.157118292205368], [0.6908595125970328], [0.20483066798137242], [1.2623439782440182], [-1.2585968421800662], [3.1690725225054552], [-0.4093816081812751], [0.29562726532715533], [-0.4093816081812751], [-0.7939319028222371], [-0.6710894475897076], [0.0018735680319758635], [-0.12096888720055367], [-0.45210941869693755], [1.1341605466970308], [-1.1678002448342837], [0.14073895220787894], [-1.4081441789848848], [-2.1345169577511465], [1.4439371729355837], [-0.16903767403067385], [1.3905274097910056], [0.21017164429583035], [0.2475584784970349], [0.7869970862572735], [-0.07824107668489118], [0.5573351047355877], [3.259869119851238], [1.4706420545078724], [-2.508385299763193], [0.09267016537775853], [0.4879024126476363], [-0.2972211055776612], [0.028578449604265036], [-0.7672270212499481], [0.5626760810500456], [-0.024831313540313073], [0.26892238375486616], [-0.5055191818415157], [0.5733580336789612], [0.3650599574151068], [-0.4734733239547688], [1.1341605466970308], [0.04994235486209628], [1.4973469360801615], [-0.8793875238535621], [0.15142090483679457], [1.2676849545584759], [-0.44142746606802197], [-0.38267672660898616], [-0.4200635608101907], [0.08732918906330084], [-0.9007514291113933], [2.6670207489464213], [-1.6965568999656062], [0.09267016537775853], [0.39176483898739567], [0.45585655476088943], [-0.8366597133378996], [-0.4574503950113954], [-0.035513266169228695], [0.8991575888608874], [2.976797375184974], [0.7869970862572735], [-0.22778841348970977], [2.586906104229554], [-0.660407494960792], [-1.354734415840307], [0.3276731232139022], [0.6534726783958283], [-0.5909748028728405], [2.287811430619917], [-1.349393439525849], [-0.48949625289814225], [-0.4360864897535641], [0.6855185362825752], [0.41312874424522694], [0.5947219389367925], [2.608270009487385], [0.6214268205090815], [2.309175335877748], [-1.4615539421294628], [-0.6176796844451296], [1.5934845097404022], [-0.34528989240778146], [-0.660407494960792], [-0.16903767403067385], [-0.9755250975138026], [0.49324338896209396], [-0.3613128213511549], [1.6949630597151004], [-0.825977760708984], [0.6427907257669127], [-0.7351811633632013], [-0.7618860449354904], [-1.023593884343923], [0.46119753107534733], [-0.9968890027716338], [0.3223321468994443], [-0.38801770292344395], [0.2635814074404085], [-0.9541611922559713], [1.1074556651247418], [1.240980072986187], [0.18346676272354143], [2.2076967859030496], [-0.7405221396776591], [0.6374497494524547], [-0.5856338265583827], [0.0606243074910119], [0.3330140995283599], [-0.17437865034513164], [-0.7298401870487435], [-0.4788143002692266], [-0.9862070501427181], [-0.5535879686716358], [0.25289945481149284], [-0.2010835319174207], [0.15142090483679457], [0.2315355495536616], [-0.6123387081306718], [0.5039253415910095], [-1.6431471368210284], [2.068831401727147], [2.554860246342807], [-0.633702613388503], [-0.5856338265583827], [0.033919425918722726], [1.3905274097910056], [2.2076967859030496], [-0.2972211055776612], [-0.09960498194272242], [1.192911286156067], [-0.5749518739294671], [0.8030200152006468], [0.5893809626223345], [2.5495192700283495], [-0.6016567555017561], [0.37040093372956445], [0.7869970862572735], [1.4599601018789572], [-1.1624592685198256], [2.042126520154858], [0.5092663179054675], [-0.249152318747541], [-0.44676844238247976], [0.47187948370426275], [0.9739312572632967], [-0.9221153343692245], [-0.2010835319174207], [1.524051817652451], [1.080750783552453], [-0.18506060297404728], [-0.12630986351501147], [-0.035513266169228695], [-0.21176548454633634], [0.8190429441440203], [-0.28653915294874555], [1.3210947177030539], [-0.17437865034513164], [2.277129477991001], [-0.4200635608101907], [-0.49483722921260004], [0.2475584784970349], [-0.9327972869981402], [-0.22778841348970977], [0.6267677968235391], [0.2635814074404085], [0.15142090483679457], [-0.07824107668489118], [-1.2853017237523554], [0.2582404311259505], [-0.6710894475897076], [-1.8514452130848826], [-1.0129119317150073], [-1.1517773158909101], [-0.01949033722585538], [-0.10494595825718023], [0.7282463467982376], [-0.27585720031982996], [-0.09960498194272242], [0.8297248967729359], [0.9952951625211279], [0.37040093372956445], [-0.17437865034513164], [1.9993987096391954], [0.4825614363331784], [0.46653850738980507], [-0.8366597133378996], [-0.6016567555017561], [0.9846132098922123], [-1.349393439525849], [1.0273410204078746], [-1.6164422552487392], [-0.5963157791872984], [0.3169911705849866], [-1.10370852906079], [0.5893809626223345], [0.9312034467476342], [-1.5843963973619923], [-0.6443845660174187], [-0.28119817663428776], [-0.8366597133378996], [-0.38801770292344395], [0.6641546310247439], [-0.040854242483686624], [-0.7672270212499481], [-0.8046138554511527], [-1.0556397422306698], [-0.3986996555523596], [0.14073895220787894], [-0.16903767403067385], [-0.1423327924583848], [-0.8366597133378996], [1.0487049256657057], [1.5454157229102816], [-1.0556397422306698], [1.3317766703319698], [-0.5375650397282624], [-0.09960498194272242], [0.25289945481149284], [-0.40404063186681727], [0.7602922046849843], [0.7549512283705266], [-0.5535879686716358], [-1.1090495053752478], [0.9579083283199231], [-1.0663216948595853], [0.7015414652259485], [1.342458622960885], [0.45585655476088943], [-1.242573913236693], [0.5199482705343832], [-1.0876856001174167], [-1.3760983210981381], [1.2890488598163072], [0.8777936836030561], [-0.17971962665958946], [0.007214544346433793], [0.8671117309741405], [-0.13699181614392697], [-1.787353497311389], [0.6107448678801658], [1.454619125564499], [-0.17971962665958946], [0.8991575888608874], [-1.1624592685198256], [-0.8580236185957308], [-1.2158690316644039], [0.08198821274884291], [2.3038343595632904], [1.929966017551244], [-0.8793875238535621], [-0.7779089738788638], [-1.514963705274041], [-0.6817714002186231], [0.6801775599681172], [1.20893421509944], [0.21017164429583035], [-1.1357543869475368], [0.16210285746571018], [0.7923380625717311], [2.127582141186183], [0.19948969166691474], [-2.7914570444294564], [0.6641546310247439], [-1.2265509842933193], [0.1247160232645054], [-1.354734415840307], [-1.1357543869475368], [2.3412211937644947], [-0.05153619511260225], [-1.0449577896017541], [1.9673528517524483], [-0.7779089738788638], [1.2623439782440182], [-1.1250724343186211], [-1.0930265764318743], [1.6148484149982336], [-0.23312938980416759], [0.8457478257163092], [-0.21176548454633634], [-0.6016567555017561], [-0.9968890027716338], [1.3958683861054635], [0.8030200152006468], [1.4118913150488366], [0.41312874424522694], [-0.8152958080800683], [0.7549512283705266], [-0.40404063186681727], [0.9579083283199231], [1.016659067778959], [2.4320177911102774], [0.6962004889114908], [-1.488258823701752], [-0.5535879686716358], [1.2035932387849821], [-1.0983675527463321], [-1.7018978762800643], [0.5359711994777565], [-0.48415527658368446], [-1.1517773158909101], [1.1662064045837774], [-0.32392598714995025], [-0.26517524769091444], [-0.831318737023442], [0.2475584784970349], [1.353140575589801], [1.5934845097404022], [-0.5108601581559735], [-0.4627913713258532], [-0.9274563106836823], [-0.3559718450366971], [0.09267016537775853], [-0.5749518739294671], [-0.22778841348970977], [0.25289945481149284], [1.4599601018789572], [-0.23312938980416759], [-0.6657484712752499], [0.8671117309741405], [-0.5162011344704313], [1.3371176466464274], [-0.825977760708984], [0.6000629152512502], [-0.825977760708984], [0.1193750469500477], [-0.5856338265583827], [-0.3719947739800705], [-0.9968890027716338], [-0.8366597133378996], [-0.6550665186463343], [1.0754098072379947], [-1.0983675527463321], [0.19948969166691474], [-0.6230206607595874], [-1.0556397422306698], [0.386423862672938], [0.6694956073392017], [0.3436960521572755], [-0.43074551343910633], [0.7549512283705266], [-0.1423327924583848], [-0.05153619511260225], [1.0006361388355856], [-0.4200635608101907], [-0.3346079397788659], [-0.3132440345210346], [0.3490370284717332], [-1.8995139999150028], [-0.25983427137645665], [-0.1316508398294693], [-1.0716626711740431], [0.3597189811006488], [0.29028628901269743], [0.3223321468994443], [0.14607992852233664], [0.386423862672938], [-0.23312938980416759], [-0.11562791088609585], [1.5080288887090774], [-0.6710894475897076], [0.5573351047355877], [0.8137019678295624], [0.15676188115125225], [0.6641546310247439], [-0.07290010037043337], [0.039260402233180655], [0.41846972055968484], [-1.023593884343923], [1.705645012344016], [-0.40404063186681727], [-0.37733575029452837], [0.7869970862572735], [-0.8473416659668153], [-0.2438113424330832], [1.2516620256151023], [0.3597189811006488], [-0.21176548454633634], [0.10335211800667415], [1.8658743017777504], [-0.4200635608101907], [-0.8687055712246464], [-2.4923623708198197], [0.39176483898739567], [1.6255303676271489], [-0.22244743717525195], [0.6641546310247439], [1.7750777044319677], [-1.3707573447836803], [1.7590547754885941], [-0.024831313540313073], [-1.4775768710728363], [-1.2959836763812709], [0.35437800478619114], [0.7976790388861891], [0.4985843652765519], [0.3223321468994443], [0.4451746021319738], [0.41312874424522694], [1.7270089176018475], [-1.6271242078776549], [0.14607992852233664], [0.30630921795607097], [-1.157118292205368], [-0.27585720031982996], [1.9620118754379907], [-0.6657484712752499], [0.0606243074910119], [1.1501834756404044], [0.8510888020307672], [-0.2705162240053721], [2.202355809588592], [-0.06755912405597556], [-0.17971962665958946], [-1.568373468418619], [-0.9060924054258511], [-0.28653915294874555], [-1.2318919606077774], [-1.32268855795356], [-0.2544932950619988], [-0.48415527658368446], [0.3169911705849866], [0.9685902809488388], [-0.6550665186463343], [-0.2705162240053721], [-0.5642699213005515], [0.7816561099428155], [0.9312034467476342], [-0.2438113424330832], [-0.23847036611862538], [-1.0556397422306698], [-0.606997731816214], [-2.1078120761788575], [1.8017825860042564], [-0.09960498194272242], [-1.1731412211487413], [0.3490370284717332], [-1.0342758369728384], [0.14607992852233664], [0.4291516731886005], [-1.3600753921547646], [-0.6924533528475388], [0.4291516731886005], [1.3104127650741384], [-0.3986996555523596], [-0.7725679975644059], [-0.3185850108354924], [-0.0034674082824818287], [-1.9208779051728342], [-0.7298401870487435], [-0.8793875238535621], [-0.7512040923065747], [1.0754098072379947], [1.7216679412873892], [-0.831318737023442], [-0.28653915294874555], [-0.07824107668489118], [1.022000044093417], [0.39176483898739567], [-0.13699181614392697], [0.3383550758428176], [0.30630921795607097], [1.1448424993259463], [-0.008808384596939759], [-1.2799607474378976], [-0.008808384596939759], [0.4825614363331784], [-0.249152318747541], [-1.5256456579029567], [-0.2918801292632034], [-0.5429060160427203], [0.0659652838054696], [0.7229053704837797], [-0.05153619511260225], [-1.4508719895005473], [-0.48415527658368446], [-0.7725679975644059], [2.015421638582569], [0.7015414652259485], [0.007214544346433793], [0.8617707546596828], [-0.8740465475391043], [0.5733580336789612], [1.6148484149982336], [0.6321087731379971], [-1.8995139999150028], [0.46653850738980507], [0.8671117309741405], [-0.2972211055776612], [-0.05153619511260225], [0.5359711994777565]]
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,901
Moving model to cuda
Epoch 0
Train function
Loss = 1.9873e-02, PNorm = 35.0664, GNorm = 2.9082, lr_0 = 1.2829e-04
Loss = 1.5646e-02, PNorm = 35.0695, GNorm = 2.2256, lr_0 = 1.5400e-04
Loss = 1.2995e-02, PNorm = 35.0738, GNorm = 6.0069, lr_0 = 1.7971e-04
Loss = 9.9025e-03, PNorm = 35.0795, GNorm = 7.4768, lr_0 = 2.0543e-04
Loss = 9.7240e-03, PNorm = 35.0846, GNorm = 8.7705, lr_0 = 2.3114e-04
Loss = 9.3758e-03, PNorm = 35.0917, GNorm = 1.3294, lr_0 = 2.5686e-04
Loss = 6.1737e-03, PNorm = 35.1001, GNorm = 4.8986, lr_0 = 2.8257e-04
Loss = 6.4486e-03, PNorm = 35.1105, GNorm = 1.5188, lr_0 = 3.0829e-04
Loss = 5.7218e-03, PNorm = 35.1222, GNorm = 3.5365, lr_0 = 3.3400e-04
Loss = 6.3468e-03, PNorm = 35.1323, GNorm = 2.2051, lr_0 = 3.5971e-04
Loss = 5.2192e-03, PNorm = 35.1414, GNorm = 2.8851, lr_0 = 3.8543e-04
Loss = 5.1623e-03, PNorm = 35.1534, GNorm = 1.7006, lr_0 = 4.1114e-04
Loss = 3.7810e-03, PNorm = 35.1651, GNorm = 2.5140, lr_0 = 4.3686e-04
Loss = 3.7641e-03, PNorm = 35.1788, GNorm = 1.0678, lr_0 = 4.6257e-04
Loss = 3.9567e-03, PNorm = 35.1976, GNorm = 8.3788, lr_0 = 4.8829e-04
Loss = 4.2416e-03, PNorm = 35.2121, GNorm = 2.5101, lr_0 = 5.1400e-04
Loss = 4.0038e-03, PNorm = 35.2255, GNorm = 1.2716, lr_0 = 5.3971e-04
Validation rmse = 0.811050
Validation R2 = 0.812170
Epoch 1
Train function
Loss = 3.6311e-03, PNorm = 35.2461, GNorm = 1.4059, lr_0 = 5.6800e-04
Loss = 3.5562e-03, PNorm = 35.2632, GNorm = 3.4911, lr_0 = 5.9371e-04
Loss = 3.8377e-03, PNorm = 35.2809, GNorm = 1.3809, lr_0 = 6.1943e-04
Loss = 3.3633e-03, PNorm = 35.2975, GNorm = 1.7831, lr_0 = 6.4514e-04
Loss = 3.3621e-03, PNorm = 35.3239, GNorm = 3.8087, lr_0 = 6.7086e-04
Loss = 3.3838e-03, PNorm = 35.3503, GNorm = 7.2336, lr_0 = 6.9657e-04
Loss = 3.1268e-03, PNorm = 35.3791, GNorm = 0.6048, lr_0 = 7.2229e-04
Loss = 3.1937e-03, PNorm = 35.4001, GNorm = 2.0351, lr_0 = 7.4800e-04
Loss = 3.9399e-03, PNorm = 35.4283, GNorm = 4.9512, lr_0 = 7.7371e-04
Loss = 2.8954e-03, PNorm = 35.4628, GNorm = 0.7992, lr_0 = 7.9943e-04
Loss = 2.5225e-03, PNorm = 35.4945, GNorm = 1.7323, lr_0 = 8.2514e-04
Loss = 2.3789e-03, PNorm = 35.5171, GNorm = 3.4461, lr_0 = 8.5086e-04
Loss = 3.2679e-03, PNorm = 35.5411, GNorm = 4.3179, lr_0 = 8.7657e-04
Loss = 3.4322e-03, PNorm = 35.5732, GNorm = 1.4026, lr_0 = 9.0229e-04
Loss = 3.7279e-03, PNorm = 35.6105, GNorm = 1.2025, lr_0 = 9.2800e-04
Loss = 3.4302e-03, PNorm = 35.6333, GNorm = 2.1882, lr_0 = 9.5371e-04
Loss = 3.1795e-03, PNorm = 35.6670, GNorm = 1.8848, lr_0 = 9.7943e-04
Loss = 3.1680e-03, PNorm = 35.6904, GNorm = 2.3371, lr_0 = 9.9973e-04
Validation rmse = 0.670169
Validation R2 = 0.871756
Epoch 2
Train function
Loss = 2.1225e-03, PNorm = 35.7235, GNorm = 0.6553, lr_0 = 9.9839e-04
Loss = 2.6673e-03, PNorm = 35.7582, GNorm = 0.8546, lr_0 = 9.9705e-04
Loss = 2.8198e-03, PNorm = 35.7867, GNorm = 2.5583, lr_0 = 9.9571e-04
Loss = 2.6880e-03, PNorm = 35.8066, GNorm = 1.8126, lr_0 = 9.9438e-04
Loss = 2.6062e-03, PNorm = 35.8356, GNorm = 1.0404, lr_0 = 9.9304e-04
Loss = 2.1979e-03, PNorm = 35.8624, GNorm = 0.9708, lr_0 = 9.9171e-04
Loss = 2.3205e-03, PNorm = 35.8890, GNorm = 0.7009, lr_0 = 9.9038e-04
Loss = 2.5455e-03, PNorm = 35.9053, GNorm = 2.2041, lr_0 = 9.8905e-04
Loss = 2.5761e-03, PNorm = 35.9322, GNorm = 1.0317, lr_0 = 9.8772e-04
Loss = 2.5637e-03, PNorm = 35.9796, GNorm = 0.7040, lr_0 = 9.8640e-04
Loss = 2.2716e-03, PNorm = 36.0006, GNorm = 0.7163, lr_0 = 9.8508e-04
Loss = 2.1762e-03, PNorm = 36.0232, GNorm = 0.9747, lr_0 = 9.8375e-04
Loss = 2.4508e-03, PNorm = 36.0385, GNorm = 2.2135, lr_0 = 9.8243e-04
Loss = 2.1509e-03, PNorm = 36.0613, GNorm = 0.5675, lr_0 = 9.8112e-04
Loss = 2.3175e-03, PNorm = 36.0864, GNorm = 1.7275, lr_0 = 9.7980e-04
Loss = 2.3710e-03, PNorm = 36.1157, GNorm = 2.3524, lr_0 = 9.7848e-04
Loss = 2.3131e-03, PNorm = 36.1486, GNorm = 1.8334, lr_0 = 9.7717e-04
Validation rmse = 0.705470
Validation R2 = 0.857889
Epoch 3
Train function
Loss = 2.4996e-03, PNorm = 36.1706, GNorm = 3.9308, lr_0 = 9.7573e-04
Loss = 2.4466e-03, PNorm = 36.1919, GNorm = 2.2468, lr_0 = 9.7442e-04
Loss = 2.6495e-03, PNorm = 36.2210, GNorm = 3.0780, lr_0 = 9.7311e-04
Loss = 1.7912e-03, PNorm = 36.2493, GNorm = 0.6818, lr_0 = 9.7181e-04
Loss = 2.0765e-03, PNorm = 36.2824, GNorm = 1.1626, lr_0 = 9.7050e-04
Loss = 2.1968e-03, PNorm = 36.3048, GNorm = 1.6142, lr_0 = 9.6920e-04
Loss = 1.7851e-03, PNorm = 36.3251, GNorm = 0.7658, lr_0 = 9.6790e-04
Loss = 1.8624e-03, PNorm = 36.3318, GNorm = 0.8935, lr_0 = 9.6660e-04
Loss = 1.9117e-03, PNorm = 36.3521, GNorm = 1.6181, lr_0 = 9.6531e-04
Loss = 2.1523e-03, PNorm = 36.3817, GNorm = 1.5026, lr_0 = 9.6401e-04
Loss = 1.6021e-03, PNorm = 36.4119, GNorm = 0.8169, lr_0 = 9.6272e-04
Loss = 2.1582e-03, PNorm = 36.4254, GNorm = 1.7827, lr_0 = 9.6143e-04
Loss = 1.7272e-03, PNorm = 36.4541, GNorm = 0.9881, lr_0 = 9.6014e-04
Loss = 2.1286e-03, PNorm = 36.4800, GNorm = 1.0490, lr_0 = 9.5885e-04
Loss = 1.8630e-03, PNorm = 36.5094, GNorm = 0.7378, lr_0 = 9.5756e-04
Loss = 1.7736e-03, PNorm = 36.5316, GNorm = 1.4073, lr_0 = 9.5628e-04
Loss = 1.7683e-03, PNorm = 36.5498, GNorm = 0.6626, lr_0 = 9.5499e-04
Loss = 1.6859e-03, PNorm = 36.5685, GNorm = 1.0200, lr_0 = 9.5371e-04
Validation rmse = 0.563244
Validation R2 = 0.909414
Epoch 4
Train function
Loss = 1.8155e-03, PNorm = 36.5898, GNorm = 2.6387, lr_0 = 9.5243e-04
Loss = 2.2110e-03, PNorm = 36.6153, GNorm = 1.3393, lr_0 = 9.5115e-04
Loss = 1.8742e-03, PNorm = 36.6516, GNorm = 0.8387, lr_0 = 9.4988e-04
Loss = 1.7544e-03, PNorm = 36.6742, GNorm = 1.8106, lr_0 = 9.4860e-04
Loss = 1.6286e-03, PNorm = 36.6982, GNorm = 1.3348, lr_0 = 9.4733e-04
Loss = 1.8022e-03, PNorm = 36.7373, GNorm = 1.0533, lr_0 = 9.4606e-04
Loss = 1.7009e-03, PNorm = 36.7619, GNorm = 0.4281, lr_0 = 9.4479e-04
Loss = 1.9150e-03, PNorm = 36.7800, GNorm = 2.2136, lr_0 = 9.4352e-04
Loss = 2.2046e-03, PNorm = 36.8095, GNorm = 0.9467, lr_0 = 9.4226e-04
Loss = 1.5528e-03, PNorm = 36.8442, GNorm = 1.1326, lr_0 = 9.4099e-04
Loss = 1.2732e-03, PNorm = 36.8753, GNorm = 0.5500, lr_0 = 9.3973e-04
Loss = 1.5150e-03, PNorm = 36.9006, GNorm = 0.8199, lr_0 = 9.3847e-04
Loss = 1.6096e-03, PNorm = 36.9248, GNorm = 0.7964, lr_0 = 9.3721e-04
Loss = 1.7405e-03, PNorm = 36.9502, GNorm = 0.4911, lr_0 = 9.3595e-04
Loss = 1.7270e-03, PNorm = 36.9809, GNorm = 1.2527, lr_0 = 9.3470e-04
Loss = 1.5809e-03, PNorm = 37.0037, GNorm = 0.5898, lr_0 = 9.3344e-04
Loss = 1.7636e-03, PNorm = 37.0254, GNorm = 1.2375, lr_0 = 9.3219e-04
Validation rmse = 0.558316
Validation R2 = 0.910992
Epoch 5
Train function
Loss = 8.9721e-04, PNorm = 37.0483, GNorm = 0.7369, lr_0 = 9.3094e-04
Loss = 1.5102e-03, PNorm = 37.0686, GNorm = 0.6566, lr_0 = 9.2969e-04
Loss = 1.8458e-03, PNorm = 37.0914, GNorm = 1.2840, lr_0 = 9.2844e-04
Loss = 1.3021e-03, PNorm = 37.1183, GNorm = 0.8579, lr_0 = 9.2720e-04
Loss = 1.5056e-03, PNorm = 37.1466, GNorm = 0.5358, lr_0 = 9.2595e-04
Loss = 1.3651e-03, PNorm = 37.1704, GNorm = 1.0140, lr_0 = 9.2471e-04
Loss = 1.4769e-03, PNorm = 37.1926, GNorm = 2.4241, lr_0 = 9.2347e-04
Loss = 1.6316e-03, PNorm = 37.2160, GNorm = 1.9423, lr_0 = 9.2223e-04
Loss = 1.4784e-03, PNorm = 37.2356, GNorm = 0.6870, lr_0 = 9.2099e-04
Loss = 1.2294e-03, PNorm = 37.2525, GNorm = 0.6958, lr_0 = 9.1976e-04
Loss = 1.2481e-03, PNorm = 37.2746, GNorm = 0.5434, lr_0 = 9.1852e-04
Loss = 1.3858e-03, PNorm = 37.3033, GNorm = 0.6631, lr_0 = 9.1729e-04
Loss = 1.5546e-03, PNorm = 37.3224, GNorm = 1.3848, lr_0 = 9.1606e-04
Loss = 1.6030e-03, PNorm = 37.3426, GNorm = 0.5000, lr_0 = 9.1483e-04
Loss = 1.2698e-03, PNorm = 37.3635, GNorm = 0.3567, lr_0 = 9.1360e-04
Loss = 1.5927e-03, PNorm = 37.3990, GNorm = 2.6247, lr_0 = 9.1238e-04
Loss = 1.9427e-03, PNorm = 37.4216, GNorm = 2.6411, lr_0 = 9.1115e-04
Loss = 1.6600e-03, PNorm = 37.4496, GNorm = 1.7368, lr_0 = 9.0993e-04
Validation rmse = 0.593161
Validation R2 = 0.899535
Epoch 6
Train function
Loss = 1.8427e-03, PNorm = 37.4769, GNorm = 1.2775, lr_0 = 9.0859e-04
Loss = 1.5946e-03, PNorm = 37.5048, GNorm = 0.9616, lr_0 = 9.0737e-04
Loss = 1.3246e-03, PNorm = 37.5412, GNorm = 1.0112, lr_0 = 9.0615e-04
Loss = 1.2373e-03, PNorm = 37.5675, GNorm = 1.2341, lr_0 = 9.0494e-04
Loss = 1.7060e-03, PNorm = 37.5902, GNorm = 1.9257, lr_0 = 9.0372e-04
Loss = 1.4515e-03, PNorm = 37.6242, GNorm = 1.9854, lr_0 = 9.0251e-04
Loss = 1.3949e-03, PNorm = 37.6427, GNorm = 0.9685, lr_0 = 9.0130e-04
Loss = 1.2317e-03, PNorm = 37.6690, GNorm = 0.6250, lr_0 = 9.0009e-04
Loss = 1.1024e-03, PNorm = 37.6959, GNorm = 0.5638, lr_0 = 8.9888e-04
Loss = 1.6005e-03, PNorm = 37.7146, GNorm = 0.8464, lr_0 = 8.9768e-04
Loss = 1.3572e-03, PNorm = 37.7493, GNorm = 1.3101, lr_0 = 8.9647e-04
Loss = 1.1426e-03, PNorm = 37.7674, GNorm = 0.4840, lr_0 = 8.9527e-04
Loss = 1.3240e-03, PNorm = 37.7850, GNorm = 1.0441, lr_0 = 8.9407e-04
Loss = 1.6479e-03, PNorm = 37.8106, GNorm = 1.6841, lr_0 = 8.9287e-04
Loss = 1.6236e-03, PNorm = 37.8307, GNorm = 1.5166, lr_0 = 8.9167e-04
Loss = 1.4762e-03, PNorm = 37.8616, GNorm = 0.5217, lr_0 = 8.9047e-04
Loss = 1.1563e-03, PNorm = 37.8902, GNorm = 0.4342, lr_0 = 8.8928e-04
Validation rmse = 0.524195
Validation R2 = 0.921539
Epoch 7
Train function
Loss = 8.2835e-04, PNorm = 37.9140, GNorm = 0.6076, lr_0 = 8.8809e-04
Loss = 1.0397e-03, PNorm = 37.9329, GNorm = 0.7342, lr_0 = 8.8689e-04
Loss = 9.5521e-04, PNorm = 37.9506, GNorm = 0.5245, lr_0 = 8.8570e-04
Loss = 1.2512e-03, PNorm = 37.9695, GNorm = 1.8379, lr_0 = 8.8452e-04
Loss = 1.2276e-03, PNorm = 37.9871, GNorm = 1.9965, lr_0 = 8.8333e-04
Loss = 1.1787e-03, PNorm = 38.0089, GNorm = 0.5922, lr_0 = 8.8214e-04
Loss = 1.0184e-03, PNorm = 38.0330, GNorm = 0.4864, lr_0 = 8.8096e-04
Loss = 1.2792e-03, PNorm = 38.0572, GNorm = 1.1366, lr_0 = 8.7978e-04
Loss = 1.2038e-03, PNorm = 38.0801, GNorm = 0.4455, lr_0 = 8.7860e-04
Loss = 1.2064e-03, PNorm = 38.1015, GNorm = 0.5544, lr_0 = 8.7742e-04
Loss = 1.5335e-03, PNorm = 38.1195, GNorm = 1.1696, lr_0 = 8.7624e-04
Loss = 9.6671e-04, PNorm = 38.1365, GNorm = 0.4924, lr_0 = 8.7507e-04
Loss = 1.3181e-03, PNorm = 38.1630, GNorm = 1.1875, lr_0 = 8.7389e-04
Loss = 1.0606e-03, PNorm = 38.1875, GNorm = 0.4750, lr_0 = 8.7272e-04
Loss = 1.2019e-03, PNorm = 38.2067, GNorm = 0.6693, lr_0 = 8.7155e-04
Loss = 1.1333e-03, PNorm = 38.2278, GNorm = 0.7861, lr_0 = 8.7038e-04
Loss = 1.1889e-03, PNorm = 38.2463, GNorm = 0.5492, lr_0 = 8.6921e-04
Loss = 1.2871e-03, PNorm = 38.2682, GNorm = 0.2601, lr_0 = 8.6805e-04
Validation rmse = 0.502666
Validation R2 = 0.927851
Epoch 8
Train function
Loss = 1.6474e-03, PNorm = 38.2898, GNorm = 0.6180, lr_0 = 8.6688e-04
Loss = 1.0933e-03, PNorm = 38.3123, GNorm = 0.7699, lr_0 = 8.6572e-04
Loss = 1.3815e-03, PNorm = 38.3403, GNorm = 1.1047, lr_0 = 8.6456e-04
Loss = 1.5313e-03, PNorm = 38.3717, GNorm = 1.4025, lr_0 = 8.6340e-04
Loss = 1.1049e-03, PNorm = 38.3942, GNorm = 1.4643, lr_0 = 8.6224e-04
Loss = 9.3993e-04, PNorm = 38.4193, GNorm = 0.7741, lr_0 = 8.6108e-04
Loss = 9.5247e-04, PNorm = 38.4452, GNorm = 0.9369, lr_0 = 8.5993e-04
Loss = 1.1224e-03, PNorm = 38.4694, GNorm = 0.4653, lr_0 = 8.5877e-04
Loss = 1.1539e-03, PNorm = 38.4914, GNorm = 0.5229, lr_0 = 8.5762e-04
Loss = 9.0155e-04, PNorm = 38.5053, GNorm = 0.9125, lr_0 = 8.5647e-04
Loss = 7.8863e-04, PNorm = 38.5272, GNorm = 0.4884, lr_0 = 8.5532e-04
Loss = 1.2704e-03, PNorm = 38.5424, GNorm = 1.0034, lr_0 = 8.5417e-04
Loss = 9.9985e-04, PNorm = 38.5629, GNorm = 1.2291, lr_0 = 8.5303e-04
Loss = 9.6979e-04, PNorm = 38.5826, GNorm = 0.9052, lr_0 = 8.5188e-04
Loss = 1.2124e-03, PNorm = 38.6032, GNorm = 1.2445, lr_0 = 8.5074e-04
Loss = 1.1568e-03, PNorm = 38.6324, GNorm = 0.7423, lr_0 = 8.4960e-04
Loss = 8.6198e-04, PNorm = 38.6570, GNorm = 0.6196, lr_0 = 8.4846e-04
Loss = 1.0508e-03, PNorm = 38.6684, GNorm = 0.8913, lr_0 = 8.4732e-04
Loss = 1.8019e-03, PNorm = 38.6718, GNorm = 0.7760, lr_0 = 8.4720e-04
Validation rmse = 0.535645
Validation R2 = 0.918074
Epoch 9
Train function
Loss = 9.7910e-04, PNorm = 38.7032, GNorm = 1.4529, lr_0 = 8.4607e-04
Loss = 8.5168e-04, PNorm = 38.7255, GNorm = 1.3259, lr_0 = 8.4493e-04
Loss = 1.0897e-03, PNorm = 38.7590, GNorm = 0.7561, lr_0 = 8.4380e-04
Loss = 8.2886e-04, PNorm = 38.7771, GNorm = 0.4725, lr_0 = 8.4267e-04
Loss = 8.4725e-04, PNorm = 38.7948, GNorm = 0.5006, lr_0 = 8.4154e-04
Loss = 8.6442e-04, PNorm = 38.8049, GNorm = 0.4967, lr_0 = 8.4041e-04
Loss = 1.0539e-03, PNorm = 38.8261, GNorm = 1.5569, lr_0 = 8.3928e-04
Loss = 8.9397e-04, PNorm = 38.8383, GNorm = 0.5266, lr_0 = 8.3815e-04
Loss = 1.1104e-03, PNorm = 38.8592, GNorm = 1.0407, lr_0 = 8.3703e-04
Loss = 1.0843e-03, PNorm = 38.8843, GNorm = 0.7841, lr_0 = 8.3591e-04
Loss = 9.6949e-04, PNorm = 38.9024, GNorm = 0.9659, lr_0 = 8.3478e-04
Loss = 8.3672e-04, PNorm = 38.9244, GNorm = 0.5651, lr_0 = 8.3366e-04
Loss = 9.6272e-04, PNorm = 38.9450, GNorm = 1.2434, lr_0 = 8.3255e-04
Loss = 1.0701e-03, PNorm = 38.9729, GNorm = 1.9674, lr_0 = 8.3143e-04
Loss = 1.3787e-03, PNorm = 39.0014, GNorm = 0.6738, lr_0 = 8.3031e-04
Loss = 1.4054e-03, PNorm = 39.0294, GNorm = 1.9062, lr_0 = 8.2920e-04
Loss = 1.0950e-03, PNorm = 39.0560, GNorm = 0.8581, lr_0 = 8.2809e-04
Validation rmse = 0.528154
Validation R2 = 0.920349
Epoch 10
Train function
Loss = 7.6056e-04, PNorm = 39.0736, GNorm = 1.0496, lr_0 = 8.2698e-04
Loss = 8.9087e-04, PNorm = 39.0945, GNorm = 0.7611, lr_0 = 8.2587e-04
Loss = 9.4120e-04, PNorm = 39.1206, GNorm = 0.4361, lr_0 = 8.2476e-04
Loss = 9.7856e-04, PNorm = 39.1459, GNorm = 0.6992, lr_0 = 8.2365e-04
Loss = 8.2060e-04, PNorm = 39.1652, GNorm = 1.1284, lr_0 = 8.2255e-04
Loss = 6.9738e-04, PNorm = 39.1836, GNorm = 0.8925, lr_0 = 8.2144e-04
Loss = 9.3253e-04, PNorm = 39.2037, GNorm = 0.4935, lr_0 = 8.2034e-04
Loss = 9.2631e-04, PNorm = 39.2253, GNorm = 0.9474, lr_0 = 8.1924e-04
Loss = 1.2586e-03, PNorm = 39.2478, GNorm = 0.6115, lr_0 = 8.1814e-04
Loss = 7.8048e-04, PNorm = 39.2726, GNorm = 0.3919, lr_0 = 8.1704e-04
Loss = 7.6601e-04, PNorm = 39.2918, GNorm = 0.2855, lr_0 = 8.1595e-04
Loss = 1.2827e-03, PNorm = 39.3189, GNorm = 0.3379, lr_0 = 8.1485e-04
Loss = 1.0444e-03, PNorm = 39.3457, GNorm = 1.5089, lr_0 = 8.1376e-04
Loss = 9.2794e-04, PNorm = 39.3707, GNorm = 0.8623, lr_0 = 8.1267e-04
Loss = 7.7660e-04, PNorm = 39.3902, GNorm = 0.3822, lr_0 = 8.1158e-04
Loss = 8.8657e-04, PNorm = 39.4101, GNorm = 0.6431, lr_0 = 8.1049e-04
Loss = 7.1337e-04, PNorm = 39.4233, GNorm = 0.9072, lr_0 = 8.0940e-04
Loss = 8.3944e-04, PNorm = 39.4380, GNorm = 1.0167, lr_0 = 8.0831e-04
Validation rmse = 0.480212
Validation R2 = 0.934153
Epoch 11
Train function
Loss = 9.6719e-04, PNorm = 39.4573, GNorm = 0.4797, lr_0 = 8.0723e-04
Loss = 7.3358e-04, PNorm = 39.4801, GNorm = 0.4140, lr_0 = 8.0615e-04
Loss = 1.0524e-03, PNorm = 39.4924, GNorm = 1.1509, lr_0 = 8.0506e-04
Loss = 9.7322e-04, PNorm = 39.5103, GNorm = 1.5800, lr_0 = 8.0398e-04
Loss = 8.2995e-04, PNorm = 39.5310, GNorm = 0.7872, lr_0 = 8.0291e-04
Loss = 9.4556e-04, PNorm = 39.5551, GNorm = 0.4482, lr_0 = 8.0183e-04
Loss = 7.6993e-04, PNorm = 39.5773, GNorm = 0.5687, lr_0 = 8.0075e-04
Loss = 7.1440e-04, PNorm = 39.5930, GNorm = 0.8578, lr_0 = 7.9968e-04
Loss = 8.3686e-04, PNorm = 39.6145, GNorm = 1.2611, lr_0 = 7.9861e-04
Loss = 8.3316e-04, PNorm = 39.6296, GNorm = 0.3930, lr_0 = 7.9753e-04
Loss = 8.5899e-04, PNorm = 39.6537, GNorm = 1.1096, lr_0 = 7.9646e-04
Loss = 8.8300e-04, PNorm = 39.6757, GNorm = 1.1862, lr_0 = 7.9540e-04
Loss = 8.0047e-04, PNorm = 39.6970, GNorm = 0.6124, lr_0 = 7.9433e-04
Loss = 7.2348e-04, PNorm = 39.7180, GNorm = 0.6797, lr_0 = 7.9326e-04
Loss = 1.0991e-03, PNorm = 39.7422, GNorm = 1.9511, lr_0 = 7.9220e-04
Loss = 9.2968e-04, PNorm = 39.7677, GNorm = 0.8312, lr_0 = 7.9114e-04
Loss = 1.0396e-03, PNorm = 39.7915, GNorm = 2.1085, lr_0 = 7.9007e-04
Validation rmse = 0.474874
Validation R2 = 0.935609
Epoch 12
Train function
Loss = 8.7607e-04, PNorm = 39.8153, GNorm = 0.6948, lr_0 = 7.8891e-04
Loss = 7.1674e-04, PNorm = 39.8434, GNorm = 0.8699, lr_0 = 7.8785e-04
Loss = 6.2725e-04, PNorm = 39.8624, GNorm = 0.3830, lr_0 = 7.8679e-04
Loss = 6.0420e-04, PNorm = 39.8808, GNorm = 0.7165, lr_0 = 7.8574e-04
Loss = 7.5722e-04, PNorm = 39.9000, GNorm = 0.7270, lr_0 = 7.8468e-04
Loss = 7.1291e-04, PNorm = 39.9195, GNorm = 0.9008, lr_0 = 7.8363e-04
Loss = 7.2266e-04, PNorm = 39.9323, GNorm = 0.4088, lr_0 = 7.8258e-04
Loss = 8.4100e-04, PNorm = 39.9489, GNorm = 0.9217, lr_0 = 7.8153e-04
Loss = 8.1125e-04, PNorm = 39.9598, GNorm = 0.4463, lr_0 = 7.8048e-04
Loss = 8.9672e-04, PNorm = 39.9751, GNorm = 1.2960, lr_0 = 7.7943e-04
Loss = 9.0293e-04, PNorm = 40.0011, GNorm = 0.7477, lr_0 = 7.7839e-04
Loss = 6.1878e-04, PNorm = 40.0216, GNorm = 0.3255, lr_0 = 7.7734e-04
Loss = 9.1679e-04, PNorm = 40.0436, GNorm = 0.5418, lr_0 = 7.7630e-04
Loss = 8.7530e-04, PNorm = 40.0631, GNorm = 1.1250, lr_0 = 7.7526e-04
Loss = 7.6685e-04, PNorm = 40.0760, GNorm = 0.6458, lr_0 = 7.7422e-04
Loss = 9.2735e-04, PNorm = 40.1072, GNorm = 0.3915, lr_0 = 7.7318e-04
Loss = 7.5617e-04, PNorm = 40.1308, GNorm = 0.4748, lr_0 = 7.7214e-04
Loss = 7.2526e-04, PNorm = 40.1436, GNorm = 0.5227, lr_0 = 7.7111e-04
Validation rmse = 0.470257
Validation R2 = 0.936855
Epoch 13
Train function
Loss = 5.9914e-04, PNorm = 40.1642, GNorm = 0.5031, lr_0 = 7.7007e-04
Loss = 7.7720e-04, PNorm = 40.1811, GNorm = 0.5792, lr_0 = 7.6904e-04
Loss = 7.4820e-04, PNorm = 40.2050, GNorm = 0.3061, lr_0 = 7.6801e-04
Loss = 5.9454e-04, PNorm = 40.2262, GNorm = 1.1561, lr_0 = 7.6698e-04
Loss = 8.3094e-04, PNorm = 40.2509, GNorm = 1.1773, lr_0 = 7.6595e-04
Loss = 1.0374e-03, PNorm = 40.2708, GNorm = 0.6625, lr_0 = 7.6492e-04
Loss = 7.9720e-04, PNorm = 40.2973, GNorm = 1.3743, lr_0 = 7.6389e-04
Loss = 7.3026e-04, PNorm = 40.3273, GNorm = 0.7251, lr_0 = 7.6287e-04
Loss = 8.5211e-04, PNorm = 40.3440, GNorm = 0.3994, lr_0 = 7.6184e-04
Loss = 7.6948e-04, PNorm = 40.3628, GNorm = 0.6981, lr_0 = 7.6082e-04
Loss = 7.6896e-04, PNorm = 40.3863, GNorm = 0.5969, lr_0 = 7.5980e-04
Loss = 6.7177e-04, PNorm = 40.4002, GNorm = 0.3803, lr_0 = 7.5878e-04
Loss = 6.9218e-04, PNorm = 40.4186, GNorm = 0.9405, lr_0 = 7.5776e-04
Loss = 6.1643e-04, PNorm = 40.4393, GNorm = 1.3031, lr_0 = 7.5675e-04
Loss = 7.0561e-04, PNorm = 40.4535, GNorm = 0.8237, lr_0 = 7.5573e-04
Loss = 7.0967e-04, PNorm = 40.4724, GNorm = 0.8075, lr_0 = 7.5472e-04
Loss = 5.9090e-04, PNorm = 40.4900, GNorm = 0.3114, lr_0 = 7.5370e-04
Validation rmse = 0.468081
Validation R2 = 0.937438
Epoch 14
Train function
Loss = 9.3207e-04, PNorm = 40.5092, GNorm = 1.1156, lr_0 = 7.5269e-04
Loss = 5.7948e-04, PNorm = 40.5364, GNorm = 0.3158, lr_0 = 7.5168e-04
Loss = 4.9113e-04, PNorm = 40.5509, GNorm = 0.5375, lr_0 = 7.5067e-04
Loss = 5.0701e-04, PNorm = 40.5627, GNorm = 0.5824, lr_0 = 7.4967e-04
Loss = 6.7263e-04, PNorm = 40.5786, GNorm = 0.5606, lr_0 = 7.4866e-04
Loss = 5.5348e-04, PNorm = 40.5970, GNorm = 0.4874, lr_0 = 7.4766e-04
Loss = 6.3027e-04, PNorm = 40.6125, GNorm = 0.6922, lr_0 = 7.4665e-04
Loss = 8.4009e-04, PNorm = 40.6297, GNorm = 0.6305, lr_0 = 7.4565e-04
Loss = 6.4115e-04, PNorm = 40.6588, GNorm = 0.3419, lr_0 = 7.4465e-04
Loss = 5.6298e-04, PNorm = 40.6742, GNorm = 0.5085, lr_0 = 7.4365e-04
Loss = 7.4249e-04, PNorm = 40.6944, GNorm = 0.4708, lr_0 = 7.4266e-04
Loss = 6.5816e-04, PNorm = 40.7151, GNorm = 0.8854, lr_0 = 7.4166e-04
Loss = 5.5603e-04, PNorm = 40.7280, GNorm = 0.8782, lr_0 = 7.4066e-04
Loss = 6.1641e-04, PNorm = 40.7446, GNorm = 0.2861, lr_0 = 7.3967e-04
Loss = 6.6850e-04, PNorm = 40.7573, GNorm = 0.6077, lr_0 = 7.3868e-04
Loss = 6.7571e-04, PNorm = 40.7759, GNorm = 1.3341, lr_0 = 7.3769e-04
Loss = 8.4477e-04, PNorm = 40.7950, GNorm = 0.4270, lr_0 = 7.3670e-04
Loss = 6.7116e-04, PNorm = 40.8168, GNorm = 0.3018, lr_0 = 7.3571e-04
Validation rmse = 0.466524
Validation R2 = 0.937853
Epoch 15
Train function
Loss = 4.4540e-04, PNorm = 40.8363, GNorm = 0.6668, lr_0 = 7.3462e-04
Loss = 4.9091e-04, PNorm = 40.8500, GNorm = 0.3965, lr_0 = 7.3364e-04
Loss = 5.9799e-04, PNorm = 40.8654, GNorm = 0.5082, lr_0 = 7.3265e-04
Loss = 7.6639e-04, PNorm = 40.8759, GNorm = 1.1998, lr_0 = 7.3167e-04
Loss = 6.1811e-04, PNorm = 40.8969, GNorm = 1.0545, lr_0 = 7.3069e-04
Loss = 5.9479e-04, PNorm = 40.9173, GNorm = 0.8017, lr_0 = 7.2971e-04
Loss = 5.4187e-04, PNorm = 40.9383, GNorm = 0.9899, lr_0 = 7.2873e-04
Loss = 5.6215e-04, PNorm = 40.9567, GNorm = 0.2965, lr_0 = 7.2775e-04
Loss = 5.7090e-04, PNorm = 40.9759, GNorm = 0.5066, lr_0 = 7.2677e-04
Loss = 6.3150e-04, PNorm = 40.9892, GNorm = 0.7427, lr_0 = 7.2580e-04
Loss = 6.2794e-04, PNorm = 41.0042, GNorm = 1.1677, lr_0 = 7.2483e-04
Loss = 6.6755e-04, PNorm = 41.0208, GNorm = 0.3337, lr_0 = 7.2385e-04
Loss = 6.5552e-04, PNorm = 41.0361, GNorm = 0.5102, lr_0 = 7.2288e-04
Loss = 5.0118e-04, PNorm = 41.0582, GNorm = 0.4381, lr_0 = 7.2191e-04
Loss = 5.1112e-04, PNorm = 41.0724, GNorm = 0.7869, lr_0 = 7.2094e-04
Loss = 4.8232e-04, PNorm = 41.0888, GNorm = 0.3751, lr_0 = 7.1998e-04
Loss = 6.8924e-04, PNorm = 41.1090, GNorm = 1.9204, lr_0 = 7.1901e-04
Loss = 6.3113e-04, PNorm = 41.1266, GNorm = 0.7571, lr_0 = 7.1804e-04
Validation rmse = 0.487235
Validation R2 = 0.932213
Epoch 16
Train function
Loss = 6.9175e-04, PNorm = 41.1459, GNorm = 0.7566, lr_0 = 7.1708e-04
Loss = 4.9248e-04, PNorm = 41.1649, GNorm = 0.4897, lr_0 = 7.1612e-04
Loss = 6.4719e-04, PNorm = 41.1759, GNorm = 0.9974, lr_0 = 7.1516e-04
Loss = 6.8140e-04, PNorm = 41.1954, GNorm = 1.0932, lr_0 = 7.1420e-04
Loss = 5.0206e-04, PNorm = 41.2156, GNorm = 0.8590, lr_0 = 7.1324e-04
Loss = 4.4557e-04, PNorm = 41.2301, GNorm = 0.3025, lr_0 = 7.1228e-04
Loss = 5.0290e-04, PNorm = 41.2509, GNorm = 0.6360, lr_0 = 7.1133e-04
Loss = 5.2492e-04, PNorm = 41.2651, GNorm = 0.4355, lr_0 = 7.1037e-04
Loss = 6.4597e-04, PNorm = 41.2785, GNorm = 0.9008, lr_0 = 7.0942e-04
Loss = 5.4802e-04, PNorm = 41.2934, GNorm = 0.6183, lr_0 = 7.0847e-04
Loss = 6.2171e-04, PNorm = 41.3125, GNorm = 0.3511, lr_0 = 7.0752e-04
Loss = 6.3578e-04, PNorm = 41.3255, GNorm = 1.6712, lr_0 = 7.0657e-04
Loss = 6.5214e-04, PNorm = 41.3406, GNorm = 0.4377, lr_0 = 7.0562e-04
Loss = 5.9716e-04, PNorm = 41.3666, GNorm = 1.1072, lr_0 = 7.0467e-04
Loss = 6.6829e-04, PNorm = 41.3819, GNorm = 0.7922, lr_0 = 7.0373e-04
Loss = 6.3715e-04, PNorm = 41.4065, GNorm = 0.4770, lr_0 = 7.0278e-04
Loss = 6.2588e-04, PNorm = 41.4324, GNorm = 0.3055, lr_0 = 7.0184e-04
Validation rmse = 0.463560
Validation R2 = 0.938640
Epoch 17
Train function
Loss = 5.1576e-04, PNorm = 41.4590, GNorm = 0.8234, lr_0 = 7.0090e-04
Loss = 5.1338e-04, PNorm = 41.4761, GNorm = 1.1073, lr_0 = 6.9996e-04
Loss = 6.1285e-04, PNorm = 41.4932, GNorm = 0.6925, lr_0 = 6.9902e-04
Loss = 5.7759e-04, PNorm = 41.5105, GNorm = 0.8318, lr_0 = 6.9808e-04
Loss = 4.8260e-04, PNorm = 41.5233, GNorm = 0.3776, lr_0 = 6.9715e-04
Loss = 5.7423e-04, PNorm = 41.5369, GNorm = 1.0227, lr_0 = 6.9621e-04
Loss = 5.3630e-04, PNorm = 41.5510, GNorm = 0.4497, lr_0 = 6.9528e-04
Loss = 4.4204e-04, PNorm = 41.5672, GNorm = 0.5536, lr_0 = 6.9434e-04
Loss = 4.4955e-04, PNorm = 41.5801, GNorm = 0.6741, lr_0 = 6.9341e-04
Loss = 4.0157e-04, PNorm = 41.5962, GNorm = 0.6471, lr_0 = 6.9248e-04
Loss = 5.0786e-04, PNorm = 41.6082, GNorm = 0.8604, lr_0 = 6.9155e-04
Loss = 6.0757e-04, PNorm = 41.6309, GNorm = 0.9376, lr_0 = 6.9062e-04
Loss = 4.2327e-04, PNorm = 41.6485, GNorm = 0.3459, lr_0 = 6.8970e-04
Loss = 4.7840e-04, PNorm = 41.6665, GNorm = 0.6006, lr_0 = 6.8877e-04
Loss = 3.8466e-04, PNorm = 41.6788, GNorm = 0.4322, lr_0 = 6.8785e-04
Loss = 6.1987e-04, PNorm = 41.6919, GNorm = 0.3341, lr_0 = 6.8693e-04
Loss = 5.0039e-04, PNorm = 41.7061, GNorm = 0.3025, lr_0 = 6.8600e-04
Loss = 5.7353e-04, PNorm = 41.7218, GNorm = 1.1700, lr_0 = 6.8508e-04
Validation rmse = 0.465967
Validation R2 = 0.938002
Epoch 18
Train function
Loss = 4.4746e-04, PNorm = 41.7356, GNorm = 0.4562, lr_0 = 6.8407e-04
Loss = 3.3047e-04, PNorm = 41.7567, GNorm = 0.2558, lr_0 = 6.8315e-04
Loss = 4.4856e-04, PNorm = 41.7696, GNorm = 0.5829, lr_0 = 6.8224e-04
Loss = 5.3879e-04, PNorm = 41.7845, GNorm = 0.3118, lr_0 = 6.8132e-04
Loss = 3.9674e-04, PNorm = 41.7992, GNorm = 0.3616, lr_0 = 6.8041e-04
Loss = 4.8619e-04, PNorm = 41.8117, GNorm = 0.3414, lr_0 = 6.7950e-04
Loss = 5.0558e-04, PNorm = 41.8278, GNorm = 0.6891, lr_0 = 6.7858e-04
Loss = 3.5034e-04, PNorm = 41.8354, GNorm = 0.3178, lr_0 = 6.7767e-04
Loss = 4.4946e-04, PNorm = 41.8510, GNorm = 0.4791, lr_0 = 6.7676e-04
Loss = 4.6764e-04, PNorm = 41.8616, GNorm = 0.2569, lr_0 = 6.7586e-04
Loss = 6.2652e-04, PNorm = 41.8770, GNorm = 0.5258, lr_0 = 6.7495e-04
Loss = 4.8202e-04, PNorm = 41.8935, GNorm = 0.4996, lr_0 = 6.7404e-04
Loss = 5.9012e-04, PNorm = 41.9032, GNorm = 0.4943, lr_0 = 6.7314e-04
Loss = 5.0357e-04, PNorm = 41.9196, GNorm = 1.4085, lr_0 = 6.7224e-04
Loss = 4.9706e-04, PNorm = 41.9407, GNorm = 0.3784, lr_0 = 6.7133e-04
Loss = 3.8243e-04, PNorm = 41.9508, GNorm = 0.3776, lr_0 = 6.7043e-04
Loss = 5.1449e-04, PNorm = 41.9602, GNorm = 0.4674, lr_0 = 6.6953e-04
Validation rmse = 0.453405
Validation R2 = 0.941299
Epoch 19
Train function
Loss = 3.3463e-04, PNorm = 41.9777, GNorm = 0.3259, lr_0 = 6.6864e-04
Loss = 5.7072e-04, PNorm = 41.9960, GNorm = 0.4312, lr_0 = 6.6774e-04
Loss = 4.6074e-04, PNorm = 42.0085, GNorm = 1.4999, lr_0 = 6.6684e-04
Loss = 4.2763e-04, PNorm = 42.0189, GNorm = 0.5721, lr_0 = 6.6595e-04
Loss = 5.1719e-04, PNorm = 42.0385, GNorm = 0.4092, lr_0 = 6.6505e-04
Loss = 3.9417e-04, PNorm = 42.0534, GNorm = 0.4839, lr_0 = 6.6416e-04
Loss = 4.9244e-04, PNorm = 42.0648, GNorm = 0.7175, lr_0 = 6.6327e-04
Loss = 6.1846e-04, PNorm = 42.0834, GNorm = 1.1085, lr_0 = 6.6238e-04
Loss = 5.8331e-04, PNorm = 42.1061, GNorm = 0.7118, lr_0 = 6.6149e-04
Loss = 4.2904e-04, PNorm = 42.1251, GNorm = 0.5320, lr_0 = 6.6060e-04
Loss = 4.1154e-04, PNorm = 42.1407, GNorm = 0.5444, lr_0 = 6.5972e-04
Loss = 4.8114e-04, PNorm = 42.1510, GNorm = 0.6154, lr_0 = 6.5883e-04
Loss = 4.1128e-04, PNorm = 42.1649, GNorm = 1.0234, lr_0 = 6.5795e-04
Loss = 6.2052e-04, PNorm = 42.1810, GNorm = 0.8565, lr_0 = 6.5707e-04
Loss = 4.5766e-04, PNorm = 42.1949, GNorm = 0.3367, lr_0 = 6.5618e-04
Loss = 5.1299e-04, PNorm = 42.2094, GNorm = 0.6475, lr_0 = 6.5530e-04
Loss = 5.5961e-04, PNorm = 42.2273, GNorm = 0.8402, lr_0 = 6.5443e-04
Loss = 5.4186e-04, PNorm = 42.2501, GNorm = 0.7927, lr_0 = 6.5355e-04
Validation rmse = 0.462351
Validation R2 = 0.938960
Epoch 20
Train function
Loss = 3.0083e-04, PNorm = 42.2660, GNorm = 0.2645, lr_0 = 6.5267e-04
Loss = 3.6358e-04, PNorm = 42.2809, GNorm = 0.3712, lr_0 = 6.5179e-04
Loss = 3.1637e-04, PNorm = 42.2919, GNorm = 0.2427, lr_0 = 6.5092e-04
Loss = 3.5629e-04, PNorm = 42.2995, GNorm = 0.3822, lr_0 = 6.5005e-04
Loss = 3.5255e-04, PNorm = 42.3126, GNorm = 0.3485, lr_0 = 6.4917e-04
Loss = 3.4739e-04, PNorm = 42.3264, GNorm = 0.2907, lr_0 = 6.4830e-04
Loss = 3.5110e-04, PNorm = 42.3396, GNorm = 0.5307, lr_0 = 6.4743e-04
Loss = 3.3449e-04, PNorm = 42.3523, GNorm = 0.5743, lr_0 = 6.4657e-04
Loss = 3.7401e-04, PNorm = 42.3622, GNorm = 0.3540, lr_0 = 6.4570e-04
Loss = 5.1303e-04, PNorm = 42.3733, GNorm = 1.1625, lr_0 = 6.4483e-04
Loss = 4.6966e-04, PNorm = 42.3861, GNorm = 0.3973, lr_0 = 6.4397e-04
Loss = 3.9350e-04, PNorm = 42.3914, GNorm = 0.3572, lr_0 = 6.4310e-04
Loss = 3.9472e-04, PNorm = 42.4087, GNorm = 0.4450, lr_0 = 6.4224e-04
Loss = 3.9754e-04, PNorm = 42.4201, GNorm = 0.3775, lr_0 = 6.4138e-04
Loss = 4.4321e-04, PNorm = 42.4361, GNorm = 0.6037, lr_0 = 6.4052e-04
Loss = 4.4010e-04, PNorm = 42.4512, GNorm = 0.6639, lr_0 = 6.3966e-04
Loss = 3.8181e-04, PNorm = 42.4642, GNorm = 0.3663, lr_0 = 6.3880e-04
Validation rmse = 0.452614
Validation R2 = 0.941504
Epoch 21
Train function
Loss = 4.8510e-04, PNorm = 42.4786, GNorm = 0.9016, lr_0 = 6.3786e-04
Loss = 3.5256e-04, PNorm = 42.4958, GNorm = 0.5659, lr_0 = 6.3700e-04
Loss = 2.9021e-04, PNorm = 42.5071, GNorm = 0.3168, lr_0 = 6.3615e-04
Loss = 3.6237e-04, PNorm = 42.5168, GNorm = 0.3945, lr_0 = 6.3529e-04
Loss = 3.9805e-04, PNorm = 42.5277, GNorm = 0.3096, lr_0 = 6.3444e-04
Loss = 4.1037e-04, PNorm = 42.5425, GNorm = 0.4536, lr_0 = 6.3359e-04
Loss = 3.4981e-04, PNorm = 42.5560, GNorm = 0.2399, lr_0 = 6.3274e-04
Loss = 3.4008e-04, PNorm = 42.5660, GNorm = 0.2523, lr_0 = 6.3189e-04
Loss = 3.7498e-04, PNorm = 42.5733, GNorm = 0.3818, lr_0 = 6.3104e-04
Loss = 3.6113e-04, PNorm = 42.5886, GNorm = 0.3526, lr_0 = 6.3020e-04
Loss = 3.5095e-04, PNorm = 42.6001, GNorm = 0.5815, lr_0 = 6.2935e-04
Loss = 3.3286e-04, PNorm = 42.6082, GNorm = 0.3090, lr_0 = 6.2851e-04
Loss = 3.8721e-04, PNorm = 42.6205, GNorm = 0.7630, lr_0 = 6.2766e-04
Loss = 3.1952e-04, PNorm = 42.6345, GNorm = 0.3165, lr_0 = 6.2682e-04
Loss = 2.8561e-04, PNorm = 42.6466, GNorm = 0.2647, lr_0 = 6.2598e-04
Loss = 4.1048e-04, PNorm = 42.6590, GNorm = 0.5440, lr_0 = 6.2514e-04
Loss = 5.1520e-04, PNorm = 42.6775, GNorm = 0.6343, lr_0 = 6.2430e-04
Loss = 4.0279e-04, PNorm = 42.6899, GNorm = 0.4785, lr_0 = 6.2346e-04
Validation rmse = 0.456964
Validation R2 = 0.940374
Epoch 22
Train function
Loss = 3.3142e-04, PNorm = 42.6982, GNorm = 0.3758, lr_0 = 6.2263e-04
Loss = 2.7231e-04, PNorm = 42.7121, GNorm = 0.2295, lr_0 = 6.2179e-04
Loss = 2.9269e-04, PNorm = 42.7227, GNorm = 0.2963, lr_0 = 6.2096e-04
Loss = 3.2490e-04, PNorm = 42.7376, GNorm = 0.2995, lr_0 = 6.2012e-04
Loss = 2.6887e-04, PNorm = 42.7473, GNorm = 0.4853, lr_0 = 6.1929e-04
Loss = 4.3999e-04, PNorm = 42.7597, GNorm = 1.0107, lr_0 = 6.1846e-04
Loss = 3.4761e-04, PNorm = 42.7709, GNorm = 0.2868, lr_0 = 6.1763e-04
Loss = 3.7755e-04, PNorm = 42.7852, GNorm = 0.3755, lr_0 = 6.1680e-04
Loss = 3.5456e-04, PNorm = 42.7993, GNorm = 0.3679, lr_0 = 6.1597e-04
Loss = 3.7185e-04, PNorm = 42.8126, GNorm = 0.3743, lr_0 = 6.1515e-04
Loss = 2.9683e-04, PNorm = 42.8246, GNorm = 0.4134, lr_0 = 6.1432e-04
Loss = 3.1004e-04, PNorm = 42.8368, GNorm = 0.4313, lr_0 = 6.1350e-04
Loss = 3.6159e-04, PNorm = 42.8451, GNorm = 0.3644, lr_0 = 6.1268e-04
Loss = 3.6682e-04, PNorm = 42.8534, GNorm = 0.3448, lr_0 = 6.1185e-04
Loss = 3.4314e-04, PNorm = 42.8642, GNorm = 0.2640, lr_0 = 6.1103e-04
Loss = 3.4079e-04, PNorm = 42.8738, GNorm = 0.3776, lr_0 = 6.1021e-04
Loss = 3.4843e-04, PNorm = 42.8818, GNorm = 0.2856, lr_0 = 6.0939e-04
Loss = 3.8012e-04, PNorm = 42.8960, GNorm = 0.3960, lr_0 = 6.0858e-04
Validation rmse = 0.457963
Validation R2 = 0.940113
Epoch 23
Train function
Loss = 2.7693e-04, PNorm = 42.9112, GNorm = 0.3524, lr_0 = 6.0776e-04
Loss = 2.9050e-04, PNorm = 42.9197, GNorm = 0.3709, lr_0 = 6.0694e-04
Loss = 2.3388e-04, PNorm = 42.9339, GNorm = 0.4900, lr_0 = 6.0613e-04
Loss = 3.2976e-04, PNorm = 42.9488, GNorm = 0.3246, lr_0 = 6.0532e-04
Loss = 3.2368e-04, PNorm = 42.9623, GNorm = 0.4617, lr_0 = 6.0450e-04
Loss = 2.5266e-04, PNorm = 42.9739, GNorm = 0.2686, lr_0 = 6.0369e-04
Loss = 3.1878e-04, PNorm = 42.9849, GNorm = 0.6321, lr_0 = 6.0288e-04
Loss = 4.0971e-04, PNorm = 42.9947, GNorm = 0.9228, lr_0 = 6.0207e-04
Loss = 3.1967e-04, PNorm = 43.0128, GNorm = 0.3449, lr_0 = 6.0127e-04
Loss = 2.8605e-04, PNorm = 43.0267, GNorm = 0.3254, lr_0 = 6.0046e-04
Loss = 3.3742e-04, PNorm = 43.0462, GNorm = 0.2888, lr_0 = 5.9965e-04
Loss = 3.4375e-04, PNorm = 43.0602, GNorm = 0.2850, lr_0 = 5.9885e-04
Loss = 4.0398e-04, PNorm = 43.0677, GNorm = 0.2157, lr_0 = 5.9805e-04
Loss = 3.2580e-04, PNorm = 43.0819, GNorm = 0.6851, lr_0 = 5.9724e-04
Loss = 4.4098e-04, PNorm = 43.0936, GNorm = 0.5383, lr_0 = 5.9644e-04
Loss = 3.7291e-04, PNorm = 43.1090, GNorm = 0.6663, lr_0 = 5.9564e-04
Loss = 3.3137e-04, PNorm = 43.1251, GNorm = 0.4224, lr_0 = 5.9484e-04
Validation rmse = 0.454814
Validation R2 = 0.940934
Epoch 24
Train function
Loss = 3.3593e-04, PNorm = 43.1435, GNorm = 0.2958, lr_0 = 5.9397e-04
Loss = 2.6858e-04, PNorm = 43.1583, GNorm = 0.3688, lr_0 = 5.9317e-04
Loss = 2.8752e-04, PNorm = 43.1698, GNorm = 0.6076, lr_0 = 5.9237e-04
Loss = 2.3379e-04, PNorm = 43.1782, GNorm = 0.2447, lr_0 = 5.9158e-04
Loss = 3.1157e-04, PNorm = 43.1881, GNorm = 0.2349, lr_0 = 5.9078e-04
Loss = 2.5605e-04, PNorm = 43.1968, GNorm = 0.4144, lr_0 = 5.8999e-04
Loss = 2.5199e-04, PNorm = 43.2079, GNorm = 0.3321, lr_0 = 5.8920e-04
Loss = 3.2062e-04, PNorm = 43.2137, GNorm = 0.4407, lr_0 = 5.8841e-04
Loss = 4.0177e-04, PNorm = 43.2248, GNorm = 0.6075, lr_0 = 5.8762e-04
Loss = 3.0076e-04, PNorm = 43.2364, GNorm = 0.2510, lr_0 = 5.8683e-04
Loss = 3.4565e-04, PNorm = 43.2507, GNorm = 0.2272, lr_0 = 5.8604e-04
Loss = 3.2143e-04, PNorm = 43.2666, GNorm = 0.3041, lr_0 = 5.8526e-04
Loss = 3.6086e-04, PNorm = 43.2763, GNorm = 0.3796, lr_0 = 5.8447e-04
Loss = 3.6878e-04, PNorm = 43.2890, GNorm = 0.4112, lr_0 = 5.8369e-04
Loss = 2.9015e-04, PNorm = 43.3028, GNorm = 0.2040, lr_0 = 5.8290e-04
Loss = 3.3530e-04, PNorm = 43.3090, GNorm = 0.8517, lr_0 = 5.8212e-04
Loss = 3.1736e-04, PNorm = 43.3198, GNorm = 0.4433, lr_0 = 5.8134e-04
Loss = 2.9465e-04, PNorm = 43.3326, GNorm = 0.3076, lr_0 = 5.8056e-04
Validation rmse = 0.458214
Validation R2 = 0.940048
Epoch 25
Train function
Loss = 3.4547e-04, PNorm = 43.3486, GNorm = 0.3815, lr_0 = 5.7978e-04
Loss = 2.8998e-04, PNorm = 43.3610, GNorm = 0.3584, lr_0 = 5.7900e-04
Loss = 3.1906e-04, PNorm = 43.3700, GNorm = 0.4620, lr_0 = 5.7823e-04
Loss = 3.3265e-04, PNorm = 43.3820, GNorm = 0.1998, lr_0 = 5.7745e-04
Loss = 3.2996e-04, PNorm = 43.3954, GNorm = 0.3395, lr_0 = 5.7668e-04
Loss = 3.1229e-04, PNorm = 43.4046, GNorm = 0.3289, lr_0 = 5.7590e-04
Loss = 2.2414e-04, PNorm = 43.4117, GNorm = 0.3348, lr_0 = 5.7513e-04
Loss = 3.2449e-04, PNorm = 43.4248, GNorm = 0.5073, lr_0 = 5.7436e-04
Loss = 2.6894e-04, PNorm = 43.4341, GNorm = 0.7871, lr_0 = 5.7359e-04
Loss = 2.7843e-04, PNorm = 43.4457, GNorm = 0.2775, lr_0 = 5.7282e-04
Loss = 2.5605e-04, PNorm = 43.4585, GNorm = 0.1728, lr_0 = 5.7205e-04
Loss = 2.7048e-04, PNorm = 43.4721, GNorm = 0.3336, lr_0 = 5.7128e-04
Loss = 2.9158e-04, PNorm = 43.4801, GNorm = 0.5841, lr_0 = 5.7052e-04
Loss = 2.3647e-04, PNorm = 43.4934, GNorm = 0.4120, lr_0 = 5.6975e-04
Loss = 2.7214e-04, PNorm = 43.5060, GNorm = 0.4932, lr_0 = 5.6899e-04
Loss = 3.3616e-04, PNorm = 43.5151, GNorm = 0.2812, lr_0 = 5.6822e-04
Loss = 2.9707e-04, PNorm = 43.5253, GNorm = 0.3440, lr_0 = 5.6746e-04
Validation rmse = 0.459281
Validation R2 = 0.939768
Epoch 26
Train function
Loss = 2.4959e-04, PNorm = 43.5380, GNorm = 0.4929, lr_0 = 5.6670e-04
Loss = 3.0719e-04, PNorm = 43.5507, GNorm = 0.7104, lr_0 = 5.6594e-04
Loss = 2.8599e-04, PNorm = 43.5624, GNorm = 0.2334, lr_0 = 5.6518e-04
Loss = 2.3586e-04, PNorm = 43.5748, GNorm = 0.5353, lr_0 = 5.6442e-04
Loss = 2.1189e-04, PNorm = 43.5875, GNorm = 0.2565, lr_0 = 5.6366e-04
Loss = 2.3719e-04, PNorm = 43.5961, GNorm = 0.5908, lr_0 = 5.6291e-04
Loss = 2.9335e-04, PNorm = 43.6064, GNorm = 0.3489, lr_0 = 5.6215e-04
Loss = 2.7165e-04, PNorm = 43.6196, GNorm = 0.2124, lr_0 = 5.6140e-04
Loss = 2.1976e-04, PNorm = 43.6309, GNorm = 0.6214, lr_0 = 5.6065e-04
Loss = 2.5027e-04, PNorm = 43.6340, GNorm = 0.3349, lr_0 = 5.5989e-04
Loss = 2.8903e-04, PNorm = 43.6416, GNorm = 0.5994, lr_0 = 5.5914e-04
Loss = 2.7125e-04, PNorm = 43.6571, GNorm = 0.3327, lr_0 = 5.5839e-04
Loss = 3.6760e-04, PNorm = 43.6687, GNorm = 0.3244, lr_0 = 5.5764e-04
Loss = 3.7191e-04, PNorm = 43.6825, GNorm = 1.0513, lr_0 = 5.5689e-04
Loss = 3.3228e-04, PNorm = 43.6975, GNorm = 0.6760, lr_0 = 5.5615e-04
Loss = 2.8751e-04, PNorm = 43.7098, GNorm = 0.4839, lr_0 = 5.5540e-04
Loss = 3.0089e-04, PNorm = 43.7274, GNorm = 0.4847, lr_0 = 5.5466e-04
Loss = 2.9609e-04, PNorm = 43.7388, GNorm = 0.3830, lr_0 = 5.5391e-04
Validation rmse = 0.455051
Validation R2 = 0.940872
Epoch 27
Train function
Loss = 2.0403e-04, PNorm = 43.7482, GNorm = 0.2464, lr_0 = 5.5309e-04
Loss = 1.6838e-04, PNorm = 43.7513, GNorm = 0.2663, lr_0 = 5.5235e-04
Loss = 2.4777e-04, PNorm = 43.7588, GNorm = 0.4267, lr_0 = 5.5161e-04
Loss = 2.4003e-04, PNorm = 43.7662, GNorm = 0.1866, lr_0 = 5.5087e-04
Loss = 2.4114e-04, PNorm = 43.7810, GNorm = 0.2263, lr_0 = 5.5013e-04
Loss = 2.5007e-04, PNorm = 43.7908, GNorm = 0.3699, lr_0 = 5.4939e-04
Loss = 2.3694e-04, PNorm = 43.7999, GNorm = 0.4921, lr_0 = 5.4866e-04
Loss = 2.5027e-04, PNorm = 43.8075, GNorm = 0.3029, lr_0 = 5.4792e-04
Loss = 2.8643e-04, PNorm = 43.8145, GNorm = 0.3347, lr_0 = 5.4718e-04
Loss = 2.9135e-04, PNorm = 43.8233, GNorm = 0.2065, lr_0 = 5.4645e-04
Loss = 2.1285e-04, PNorm = 43.8325, GNorm = 0.1661, lr_0 = 5.4572e-04
Loss = 3.2087e-04, PNorm = 43.8372, GNorm = 0.4201, lr_0 = 5.4499e-04
Loss = 2.9005e-04, PNorm = 43.8461, GNorm = 0.7013, lr_0 = 5.4425e-04
Loss = 2.4972e-04, PNorm = 43.8567, GNorm = 0.2928, lr_0 = 5.4352e-04
Loss = 2.8736e-04, PNorm = 43.8722, GNorm = 0.4295, lr_0 = 5.4279e-04
Loss = 2.6357e-04, PNorm = 43.8836, GNorm = 0.5589, lr_0 = 5.4207e-04
Loss = 3.1779e-04, PNorm = 43.8961, GNorm = 0.2391, lr_0 = 5.4134e-04
Validation rmse = 0.455092
Validation R2 = 0.940862
Epoch 28
Train function
Loss = 1.8095e-04, PNorm = 43.9058, GNorm = 0.2502, lr_0 = 5.4061e-04
Loss = 2.0696e-04, PNorm = 43.9179, GNorm = 0.4564, lr_0 = 5.3989e-04
Loss = 3.2789e-04, PNorm = 43.9295, GNorm = 0.4227, lr_0 = 5.3916e-04
Loss = 2.8619e-04, PNorm = 43.9378, GNorm = 0.3020, lr_0 = 5.3844e-04
Loss = 2.4607e-04, PNorm = 43.9526, GNorm = 0.3721, lr_0 = 5.3772e-04
Loss = 2.4690e-04, PNorm = 43.9591, GNorm = 0.4840, lr_0 = 5.3700e-04
Loss = 2.5063e-04, PNorm = 43.9678, GNorm = 0.5070, lr_0 = 5.3628e-04
Loss = 2.6133e-04, PNorm = 43.9782, GNorm = 0.7030, lr_0 = 5.3556e-04
Loss = 2.6255e-04, PNorm = 43.9901, GNorm = 0.6583, lr_0 = 5.3484e-04
Loss = 2.3771e-04, PNorm = 44.0042, GNorm = 0.8340, lr_0 = 5.3412e-04
Loss = 1.8532e-04, PNorm = 44.0136, GNorm = 0.2385, lr_0 = 5.3340e-04
Loss = 2.4783e-04, PNorm = 44.0195, GNorm = 0.5029, lr_0 = 5.3269e-04
Loss = 3.0000e-04, PNorm = 44.0339, GNorm = 0.4419, lr_0 = 5.3197e-04
Loss = 1.9971e-04, PNorm = 44.0452, GNorm = 0.3533, lr_0 = 5.3126e-04
Loss = 2.3106e-04, PNorm = 44.0519, GNorm = 0.5482, lr_0 = 5.3055e-04
Loss = 2.1978e-04, PNorm = 44.0632, GNorm = 0.4543, lr_0 = 5.2983e-04
Loss = 2.3349e-04, PNorm = 44.0740, GNorm = 0.2494, lr_0 = 5.2912e-04
Loss = 2.2589e-04, PNorm = 44.0835, GNorm = 0.4094, lr_0 = 5.2841e-04
Validation rmse = 0.452943
Validation R2 = 0.941419
Epoch 29
Train function
Loss = 1.7618e-04, PNorm = 44.0895, GNorm = 0.3261, lr_0 = 5.2770e-04
Loss = 1.8309e-04, PNorm = 44.0957, GNorm = 0.6287, lr_0 = 5.2700e-04
Loss = 2.4492e-04, PNorm = 44.1063, GNorm = 0.5823, lr_0 = 5.2629e-04
Loss = 2.0738e-04, PNorm = 44.1170, GNorm = 0.2360, lr_0 = 5.2558e-04
Loss = 3.0774e-04, PNorm = 44.1267, GNorm = 0.4141, lr_0 = 5.2488e-04
Loss = 2.1245e-04, PNorm = 44.1399, GNorm = 0.2519, lr_0 = 5.2417e-04
Loss = 1.9058e-04, PNorm = 44.1513, GNorm = 0.1858, lr_0 = 5.2347e-04
Loss = 1.9189e-04, PNorm = 44.1572, GNorm = 0.4573, lr_0 = 5.2277e-04
Loss = 2.7159e-04, PNorm = 44.1690, GNorm = 0.4089, lr_0 = 5.2207e-04
Loss = 2.4537e-04, PNorm = 44.1749, GNorm = 0.4643, lr_0 = 5.2137e-04
Loss = 3.2526e-04, PNorm = 44.1853, GNorm = 0.2690, lr_0 = 5.2067e-04
Loss = 2.5912e-04, PNorm = 44.1925, GNorm = 0.5148, lr_0 = 5.1997e-04
Loss = 2.3326e-04, PNorm = 44.2061, GNorm = 0.3622, lr_0 = 5.1927e-04
Loss = 2.4781e-04, PNorm = 44.2163, GNorm = 0.3166, lr_0 = 5.1857e-04
Loss = 2.2115e-04, PNorm = 44.2227, GNorm = 0.2288, lr_0 = 5.1788e-04
Loss = 2.1909e-04, PNorm = 44.2295, GNorm = 0.2745, lr_0 = 5.1718e-04
Loss = 1.7241e-04, PNorm = 44.2336, GNorm = 0.2392, lr_0 = 5.1649e-04
Validation rmse = 0.447116
Validation R2 = 0.942916
Epoch 30
Train function
Loss = 1.3916e-04, PNorm = 44.2395, GNorm = 0.2304, lr_0 = 5.1573e-04
Loss = 1.7705e-04, PNorm = 44.2471, GNorm = 0.1435, lr_0 = 5.1503e-04
Loss = 1.7262e-04, PNorm = 44.2553, GNorm = 0.2519, lr_0 = 5.1434e-04
Loss = 1.7518e-04, PNorm = 44.2622, GNorm = 0.2090, lr_0 = 5.1365e-04
Loss = 1.9938e-04, PNorm = 44.2699, GNorm = 0.7200, lr_0 = 5.1296e-04
Loss = 2.4610e-04, PNorm = 44.2802, GNorm = 0.1835, lr_0 = 5.1228e-04
Loss = 2.0976e-04, PNorm = 44.2871, GNorm = 0.3565, lr_0 = 5.1159e-04
Loss = 2.2667e-04, PNorm = 44.2966, GNorm = 0.3674, lr_0 = 5.1090e-04
Loss = 2.0868e-04, PNorm = 44.3080, GNorm = 0.1735, lr_0 = 5.1022e-04
Loss = 2.0787e-04, PNorm = 44.3146, GNorm = 0.1817, lr_0 = 5.0953e-04
Loss = 2.0991e-04, PNorm = 44.3228, GNorm = 0.7952, lr_0 = 5.0885e-04
Loss = 2.4756e-04, PNorm = 44.3368, GNorm = 0.2960, lr_0 = 5.0817e-04
Loss = 2.1033e-04, PNorm = 44.3507, GNorm = 0.5413, lr_0 = 5.0748e-04
Loss = 1.8361e-04, PNorm = 44.3603, GNorm = 0.1914, lr_0 = 5.0680e-04
Loss = 2.1841e-04, PNorm = 44.3706, GNorm = 0.6295, lr_0 = 5.0612e-04
Loss = 2.3609e-04, PNorm = 44.3758, GNorm = 0.6268, lr_0 = 5.0544e-04
Loss = 2.0714e-04, PNorm = 44.3852, GNorm = 0.2524, lr_0 = 5.0477e-04
Loss = 1.9720e-04, PNorm = 44.3988, GNorm = 0.2794, lr_0 = 5.0409e-04
Validation rmse = 0.445324
Validation R2 = 0.943373
Epoch 31
Train function
Loss = 1.5072e-04, PNorm = 44.4033, GNorm = 0.1603, lr_0 = 5.0341e-04
Loss = 2.0942e-04, PNorm = 44.4093, GNorm = 0.4812, lr_0 = 5.0274e-04
Loss = 2.2232e-04, PNorm = 44.4201, GNorm = 0.2831, lr_0 = 5.0206e-04
Loss = 1.8574e-04, PNorm = 44.4253, GNorm = 0.3495, lr_0 = 5.0139e-04
Loss = 2.3737e-04, PNorm = 44.4348, GNorm = 0.4701, lr_0 = 5.0072e-04
Loss = 2.3927e-04, PNorm = 44.4425, GNorm = 0.5902, lr_0 = 5.0004e-04
Loss = 2.0749e-04, PNorm = 44.4535, GNorm = 0.5056, lr_0 = 4.9937e-04
Loss = 1.7792e-04, PNorm = 44.4605, GNorm = 0.4449, lr_0 = 4.9870e-04
Loss = 2.3513e-04, PNorm = 44.4663, GNorm = 0.1597, lr_0 = 4.9803e-04
Loss = 2.2420e-04, PNorm = 44.4769, GNorm = 0.4925, lr_0 = 4.9737e-04
Loss = 2.6954e-04, PNorm = 44.4944, GNorm = 0.5085, lr_0 = 4.9670e-04
Loss = 2.2254e-04, PNorm = 44.5071, GNorm = 0.2249, lr_0 = 4.9603e-04
Loss = 2.1082e-04, PNorm = 44.5190, GNorm = 0.3750, lr_0 = 4.9537e-04
Loss = 2.2037e-04, PNorm = 44.5275, GNorm = 0.2496, lr_0 = 4.9470e-04
Loss = 1.9429e-04, PNorm = 44.5337, GNorm = 0.2131, lr_0 = 4.9404e-04
Loss = 1.9887e-04, PNorm = 44.5436, GNorm = 0.3245, lr_0 = 4.9338e-04
Loss = 1.8192e-04, PNorm = 44.5543, GNorm = 0.4068, lr_0 = 4.9271e-04
Loss = 2.2455e-04, PNorm = 44.5597, GNorm = 0.2142, lr_0 = 4.9205e-04
Validation rmse = 0.450619
Validation R2 = 0.942019
Epoch 32
Train function
Loss = 1.9972e-04, PNorm = 44.5661, GNorm = 0.2746, lr_0 = 4.9139e-04
Loss = 1.8497e-04, PNorm = 44.5704, GNorm = 0.3043, lr_0 = 4.9073e-04
Loss = 2.1364e-04, PNorm = 44.5756, GNorm = 0.3679, lr_0 = 4.9007e-04
Loss = 1.9308e-04, PNorm = 44.5858, GNorm = 0.6828, lr_0 = 4.8942e-04
Loss = 2.3358e-04, PNorm = 44.5991, GNorm = 0.4766, lr_0 = 4.8876e-04
Loss = 1.6337e-04, PNorm = 44.6122, GNorm = 0.2253, lr_0 = 4.8810e-04
Loss = 1.8189e-04, PNorm = 44.6196, GNorm = 0.2318, lr_0 = 4.8745e-04
Loss = 1.7061e-04, PNorm = 44.6292, GNorm = 0.1973, lr_0 = 4.8680e-04
Loss = 1.6374e-04, PNorm = 44.6371, GNorm = 0.1563, lr_0 = 4.8614e-04
Loss = 2.2901e-04, PNorm = 44.6432, GNorm = 0.2765, lr_0 = 4.8549e-04
Loss = 2.1448e-04, PNorm = 44.6533, GNorm = 0.6086, lr_0 = 4.8484e-04
Loss = 2.1079e-04, PNorm = 44.6641, GNorm = 0.4873, lr_0 = 4.8419e-04
Loss = 2.2825e-04, PNorm = 44.6759, GNorm = 0.3337, lr_0 = 4.8354e-04
Loss = 2.6800e-04, PNorm = 44.6835, GNorm = 0.5065, lr_0 = 4.8289e-04
Loss = 2.3946e-04, PNorm = 44.6899, GNorm = 0.4369, lr_0 = 4.8224e-04
Loss = 2.5405e-04, PNorm = 44.7013, GNorm = 0.8208, lr_0 = 4.8160e-04
Loss = 2.2544e-04, PNorm = 44.7123, GNorm = 0.2238, lr_0 = 4.8095e-04
Validation rmse = 0.472259
Validation R2 = 0.936316
Epoch 33
Train function
Loss = 1.9781e-04, PNorm = 44.7212, GNorm = 0.5102, lr_0 = 4.8024e-04
Loss = 2.1587e-04, PNorm = 44.7274, GNorm = 0.3664, lr_0 = 4.7959e-04
Loss = 2.2428e-04, PNorm = 44.7387, GNorm = 0.1523, lr_0 = 4.7895e-04
Loss = 3.2064e-04, PNorm = 44.7495, GNorm = 0.4258, lr_0 = 4.7831e-04
Loss = 2.6097e-04, PNorm = 44.7601, GNorm = 0.4471, lr_0 = 4.7767e-04
Loss = 2.5602e-04, PNorm = 44.7654, GNorm = 0.9182, lr_0 = 4.7703e-04
Loss = 2.7936e-04, PNorm = 44.7783, GNorm = 0.3474, lr_0 = 4.7639e-04
Loss = 2.3423e-04, PNorm = 44.7925, GNorm = 0.4035, lr_0 = 4.7575e-04
Loss = 1.5116e-04, PNorm = 44.7998, GNorm = 0.2737, lr_0 = 4.7511e-04
Loss = 1.5138e-04, PNorm = 44.8101, GNorm = 0.2422, lr_0 = 4.7447e-04
Loss = 1.6366e-04, PNorm = 44.8168, GNorm = 0.2456, lr_0 = 4.7383e-04
Loss = 1.3901e-04, PNorm = 44.8217, GNorm = 0.2156, lr_0 = 4.7320e-04
Loss = 1.7122e-04, PNorm = 44.8266, GNorm = 0.3788, lr_0 = 4.7256e-04
Loss = 1.4902e-04, PNorm = 44.8335, GNorm = 0.1831, lr_0 = 4.7193e-04
Loss = 1.8691e-04, PNorm = 44.8404, GNorm = 0.3660, lr_0 = 4.7130e-04
Loss = 1.8228e-04, PNorm = 44.8474, GNorm = 0.1973, lr_0 = 4.7066e-04
Loss = 2.3062e-04, PNorm = 44.8519, GNorm = 0.4401, lr_0 = 4.7003e-04
Loss = 2.0046e-04, PNorm = 44.8612, GNorm = 0.2440, lr_0 = 4.6940e-04
Validation rmse = 0.452463
Validation R2 = 0.941543
Epoch 34
Train function
Loss = 2.4495e-04, PNorm = 44.8709, GNorm = 0.2988, lr_0 = 4.6877e-04
Loss = 1.8428e-04, PNorm = 44.8812, GNorm = 0.4267, lr_0 = 4.6814e-04
Loss = 1.3695e-04, PNorm = 44.8873, GNorm = 0.2094, lr_0 = 4.6752e-04
Loss = 1.3043e-04, PNorm = 44.8966, GNorm = 0.1802, lr_0 = 4.6689e-04
Loss = 2.0546e-04, PNorm = 44.9022, GNorm = 0.5056, lr_0 = 4.6626e-04
Loss = 1.8016e-04, PNorm = 44.9090, GNorm = 0.2072, lr_0 = 4.6564e-04
Loss = 2.0229e-04, PNorm = 44.9149, GNorm = 0.2826, lr_0 = 4.6501e-04
Loss = 1.9345e-04, PNorm = 44.9231, GNorm = 0.4434, lr_0 = 4.6439e-04
Loss = 1.7136e-04, PNorm = 44.9312, GNorm = 0.6220, lr_0 = 4.6376e-04
Loss = 2.2539e-04, PNorm = 44.9376, GNorm = 0.8982, lr_0 = 4.6314e-04
Loss = 1.8482e-04, PNorm = 44.9440, GNorm = 0.5383, lr_0 = 4.6252e-04
Loss = 1.8041e-04, PNorm = 44.9538, GNorm = 0.4655, lr_0 = 4.6190e-04
Loss = 1.5146e-04, PNorm = 44.9657, GNorm = 0.1781, lr_0 = 4.6128e-04
Loss = 1.6070e-04, PNorm = 44.9731, GNorm = 0.3434, lr_0 = 4.6066e-04
Loss = 1.7739e-04, PNorm = 44.9781, GNorm = 0.3851, lr_0 = 4.6004e-04
Loss = 2.4123e-04, PNorm = 44.9846, GNorm = 0.6479, lr_0 = 4.5943e-04
Loss = 3.0714e-04, PNorm = 44.9981, GNorm = 0.2453, lr_0 = 4.5881e-04
Validation rmse = 0.478377
Validation R2 = 0.934655
Epoch 35
Train function
Loss = 2.0479e-04, PNorm = 45.0117, GNorm = 0.2473, lr_0 = 4.5819e-04
Loss = 2.1380e-04, PNorm = 45.0216, GNorm = 0.4810, lr_0 = 4.5758e-04
Loss = 1.4760e-04, PNorm = 45.0324, GNorm = 0.1091, lr_0 = 4.5697e-04
Loss = 1.5738e-04, PNorm = 45.0388, GNorm = 0.3230, lr_0 = 4.5635e-04
Loss = 1.7334e-04, PNorm = 45.0430, GNorm = 0.6591, lr_0 = 4.5574e-04
Loss = 1.5290e-04, PNorm = 45.0557, GNorm = 0.4716, lr_0 = 4.5513e-04
Loss = 1.9933e-04, PNorm = 45.0594, GNorm = 0.3532, lr_0 = 4.5452e-04
Loss = 1.7142e-04, PNorm = 45.0637, GNorm = 0.2003, lr_0 = 4.5391e-04
Loss = 1.5855e-04, PNorm = 45.0714, GNorm = 0.3052, lr_0 = 4.5330e-04
Loss = 1.8064e-04, PNorm = 45.0818, GNorm = 0.1189, lr_0 = 4.5269e-04
Loss = 2.3221e-04, PNorm = 45.0911, GNorm = 0.6954, lr_0 = 4.5208e-04
Loss = 2.0148e-04, PNorm = 45.0965, GNorm = 0.3565, lr_0 = 4.5148e-04
Loss = 2.7029e-04, PNorm = 45.1041, GNorm = 0.7266, lr_0 = 4.5087e-04
Loss = 1.8212e-04, PNorm = 45.1180, GNorm = 0.2115, lr_0 = 4.5027e-04
Loss = 1.6546e-04, PNorm = 45.1238, GNorm = 0.2598, lr_0 = 4.4966e-04
Loss = 1.5738e-04, PNorm = 45.1308, GNorm = 0.2307, lr_0 = 4.4906e-04
Loss = 1.7012e-04, PNorm = 45.1393, GNorm = 0.6620, lr_0 = 4.4846e-04
Loss = 1.6589e-04, PNorm = 45.1434, GNorm = 0.3583, lr_0 = 4.4785e-04
Validation rmse = 0.447566
Validation R2 = 0.942802
Epoch 36
Train function
Loss = 1.4099e-04, PNorm = 45.1498, GNorm = 0.2671, lr_0 = 4.4719e-04
Loss = 1.2561e-04, PNorm = 45.1589, GNorm = 0.2076, lr_0 = 4.4659e-04
Loss = 1.3560e-04, PNorm = 45.1642, GNorm = 0.3915, lr_0 = 4.4599e-04
Loss = 1.3211e-04, PNorm = 45.1673, GNorm = 0.2782, lr_0 = 4.4540e-04
Loss = 1.4373e-04, PNorm = 45.1746, GNorm = 0.8212, lr_0 = 4.4480e-04
Loss = 1.6559e-04, PNorm = 45.1820, GNorm = 0.1786, lr_0 = 4.4420e-04
Loss = 1.4251e-04, PNorm = 45.1879, GNorm = 0.1633, lr_0 = 4.4361e-04
Loss = 1.2248e-04, PNorm = 45.1946, GNorm = 0.2357, lr_0 = 4.4301e-04
Loss = 1.2980e-04, PNorm = 45.1977, GNorm = 0.2322, lr_0 = 4.4242e-04
Loss = 1.5568e-04, PNorm = 45.2022, GNorm = 0.2215, lr_0 = 4.4182e-04
Loss = 1.5963e-04, PNorm = 45.2071, GNorm = 0.1709, lr_0 = 4.4123e-04
Loss = 1.9552e-04, PNorm = 45.2171, GNorm = 0.6177, lr_0 = 4.4064e-04
Loss = 2.2888e-04, PNorm = 45.2274, GNorm = 0.7005, lr_0 = 4.4005e-04
Loss = 1.7845e-04, PNorm = 45.2389, GNorm = 0.4831, lr_0 = 4.3946e-04
Loss = 1.5475e-04, PNorm = 45.2430, GNorm = 0.3058, lr_0 = 4.3887e-04
Loss = 1.5259e-04, PNorm = 45.2471, GNorm = 0.2514, lr_0 = 4.3828e-04
Loss = 1.4113e-04, PNorm = 45.2530, GNorm = 0.2479, lr_0 = 4.3769e-04
Validation rmse = 0.455484
Validation R2 = 0.940760
Epoch 37
Train function
Loss = 1.3213e-04, PNorm = 45.2624, GNorm = 0.4735, lr_0 = 4.3710e-04
Loss = 1.2907e-04, PNorm = 45.2708, GNorm = 0.1940, lr_0 = 4.3652e-04
Loss = 1.5625e-04, PNorm = 45.2786, GNorm = 0.4162, lr_0 = 4.3593e-04
Loss = 1.5530e-04, PNorm = 45.2853, GNorm = 0.1973, lr_0 = 4.3535e-04
Loss = 1.4920e-04, PNorm = 45.2899, GNorm = 0.3814, lr_0 = 4.3476e-04
Loss = 1.4947e-04, PNorm = 45.2985, GNorm = 0.1637, lr_0 = 4.3418e-04
Loss = 1.2986e-04, PNorm = 45.3066, GNorm = 0.3649, lr_0 = 4.3360e-04
Loss = 1.2379e-04, PNorm = 45.3104, GNorm = 0.2502, lr_0 = 4.3301e-04
Loss = 1.3293e-04, PNorm = 45.3180, GNorm = 0.1477, lr_0 = 4.3243e-04
Loss = 1.2852e-04, PNorm = 45.3241, GNorm = 0.1894, lr_0 = 4.3185e-04
Loss = 1.2183e-04, PNorm = 45.3297, GNorm = 0.3113, lr_0 = 4.3127e-04
Loss = 1.3745e-04, PNorm = 45.3343, GNorm = 0.4447, lr_0 = 4.3069e-04
Loss = 1.5331e-04, PNorm = 45.3426, GNorm = 0.2578, lr_0 = 4.3012e-04
Loss = 1.3437e-04, PNorm = 45.3486, GNorm = 0.2304, lr_0 = 4.2954e-04
Loss = 1.2911e-04, PNorm = 45.3485, GNorm = 0.2238, lr_0 = 4.2896e-04
Loss = 1.5933e-04, PNorm = 45.3551, GNorm = 0.1274, lr_0 = 4.2839e-04
Loss = 1.7482e-04, PNorm = 45.3610, GNorm = 0.1626, lr_0 = 4.2781e-04
Loss = 1.7030e-04, PNorm = 45.3692, GNorm = 0.2469, lr_0 = 4.2724e-04
Validation rmse = 0.449896
Validation R2 = 0.942204
Epoch 38
Train function
Loss = 1.9157e-04, PNorm = 45.3785, GNorm = 0.3617, lr_0 = 4.2667e-04
Loss = 1.6794e-04, PNorm = 45.3828, GNorm = 0.4647, lr_0 = 4.2609e-04
Loss = 1.4636e-04, PNorm = 45.3901, GNorm = 0.2725, lr_0 = 4.2552e-04
Loss = 1.0884e-04, PNorm = 45.3931, GNorm = 0.1897, lr_0 = 4.2495e-04
Loss = 9.7262e-05, PNorm = 45.4007, GNorm = 0.2002, lr_0 = 4.2438e-04
Loss = 1.1586e-04, PNorm = 45.4041, GNorm = 0.1337, lr_0 = 4.2381e-04
Loss = 1.0637e-04, PNorm = 45.4101, GNorm = 0.2495, lr_0 = 4.2324e-04
Loss = 1.5151e-04, PNorm = 45.4182, GNorm = 0.1656, lr_0 = 4.2267e-04
Loss = 1.4962e-04, PNorm = 45.4262, GNorm = 0.3071, lr_0 = 4.2211e-04
Loss = 1.2966e-04, PNorm = 45.4327, GNorm = 0.1827, lr_0 = 4.2154e-04
Loss = 1.5711e-04, PNorm = 45.4417, GNorm = 0.4807, lr_0 = 4.2098e-04
Loss = 1.1540e-04, PNorm = 45.4483, GNorm = 0.2899, lr_0 = 4.2041e-04
Loss = 1.1030e-04, PNorm = 45.4532, GNorm = 0.5141, lr_0 = 4.1985e-04
Loss = 1.1369e-04, PNorm = 45.4608, GNorm = 0.2810, lr_0 = 4.1928e-04
Loss = 1.3472e-04, PNorm = 45.4683, GNorm = 0.5676, lr_0 = 4.1872e-04
Loss = 1.4655e-04, PNorm = 45.4736, GNorm = 0.2854, lr_0 = 4.1816e-04
Loss = 1.1592e-04, PNorm = 45.4835, GNorm = 0.2182, lr_0 = 4.1760e-04
Loss = 1.2710e-04, PNorm = 45.4858, GNorm = 0.3252, lr_0 = 4.1704e-04
Loss = 2.0943e-04, PNorm = 45.4863, GNorm = 0.6040, lr_0 = 4.1698e-04
Validation rmse = 0.451125
Validation R2 = 0.941888
Epoch 39
Train function
Loss = 1.1716e-04, PNorm = 45.4911, GNorm = 0.3102, lr_0 = 4.1642e-04
Loss = 7.8616e-05, PNorm = 45.4997, GNorm = 0.1647, lr_0 = 4.1586e-04
Loss = 9.9157e-05, PNorm = 45.5057, GNorm = 0.2368, lr_0 = 4.1531e-04
Loss = 1.3130e-04, PNorm = 45.5089, GNorm = 0.6040, lr_0 = 4.1475e-04
Loss = 1.6703e-04, PNorm = 45.5163, GNorm = 0.6715, lr_0 = 4.1419e-04
Loss = 1.4320e-04, PNorm = 45.5258, GNorm = 0.2537, lr_0 = 4.1364e-04
Loss = 1.0890e-04, PNorm = 45.5340, GNorm = 0.1882, lr_0 = 4.1308e-04
Loss = 1.1430e-04, PNorm = 45.5397, GNorm = 0.2484, lr_0 = 4.1253e-04
Loss = 1.2046e-04, PNorm = 45.5471, GNorm = 0.3010, lr_0 = 4.1197e-04
Loss = 1.2768e-04, PNorm = 45.5491, GNorm = 0.3687, lr_0 = 4.1142e-04
Loss = 2.0082e-04, PNorm = 45.5545, GNorm = 0.1356, lr_0 = 4.1087e-04
Loss = 1.2160e-04, PNorm = 45.5635, GNorm = 0.2053, lr_0 = 4.1032e-04
Loss = 9.8170e-05, PNorm = 45.5673, GNorm = 0.1526, lr_0 = 4.0977e-04
Loss = 9.3403e-05, PNorm = 45.5725, GNorm = 0.2038, lr_0 = 4.0922e-04
Loss = 1.0363e-04, PNorm = 45.5797, GNorm = 0.1650, lr_0 = 4.0867e-04
Loss = 1.5494e-04, PNorm = 45.5837, GNorm = 0.2866, lr_0 = 4.0812e-04
Loss = 1.1765e-04, PNorm = 45.5874, GNorm = 0.2883, lr_0 = 4.0757e-04
Validation rmse = 0.451472
Validation R2 = 0.941799
Epoch 40
Train function
Loss = 1.3534e-04, PNorm = 45.5951, GNorm = 0.2720, lr_0 = 4.0702e-04
Loss = 9.1326e-05, PNorm = 45.6033, GNorm = 0.1544, lr_0 = 4.0648e-04
Loss = 1.1312e-04, PNorm = 45.6077, GNorm = 0.5748, lr_0 = 4.0593e-04
Loss = 9.7834e-05, PNorm = 45.6110, GNorm = 0.1521, lr_0 = 4.0539e-04
Loss = 1.1433e-04, PNorm = 45.6162, GNorm = 0.2110, lr_0 = 4.0484e-04
Loss = 1.0806e-04, PNorm = 45.6235, GNorm = 0.2407, lr_0 = 4.0430e-04
Loss = 1.2063e-04, PNorm = 45.6302, GNorm = 0.2999, lr_0 = 4.0376e-04
Loss = 1.1711e-04, PNorm = 45.6396, GNorm = 0.2572, lr_0 = 4.0322e-04
Loss = 1.3218e-04, PNorm = 45.6438, GNorm = 0.3552, lr_0 = 4.0268e-04
Loss = 1.1034e-04, PNorm = 45.6495, GNorm = 0.2754, lr_0 = 4.0214e-04
Loss = 1.1379e-04, PNorm = 45.6537, GNorm = 0.1431, lr_0 = 4.0160e-04
Loss = 1.2146e-04, PNorm = 45.6608, GNorm = 0.3514, lr_0 = 4.0106e-04
Loss = 1.0870e-04, PNorm = 45.6662, GNorm = 0.2213, lr_0 = 4.0052e-04
Loss = 1.1152e-04, PNorm = 45.6723, GNorm = 0.2103, lr_0 = 3.9998e-04
Loss = 1.0036e-04, PNorm = 45.6759, GNorm = 0.1396, lr_0 = 3.9945e-04
Loss = 1.3969e-04, PNorm = 45.6817, GNorm = 0.3997, lr_0 = 3.9891e-04
Loss = 1.2160e-04, PNorm = 45.6855, GNorm = 0.2500, lr_0 = 3.9837e-04
Loss = 1.5725e-04, PNorm = 45.6927, GNorm = 0.2263, lr_0 = 3.9784e-04
Validation rmse = 0.450881
Validation R2 = 0.941951
Epoch 41
Train function
Loss = 1.0518e-04, PNorm = 45.6982, GNorm = 0.3689, lr_0 = 3.9731e-04
Loss = 8.5139e-05, PNorm = 45.7035, GNorm = 0.3175, lr_0 = 3.9677e-04
Loss = 8.8352e-05, PNorm = 45.7102, GNorm = 0.1420, lr_0 = 3.9624e-04
Loss = 8.7249e-05, PNorm = 45.7183, GNorm = 0.1828, lr_0 = 3.9571e-04
Loss = 9.1545e-05, PNorm = 45.7212, GNorm = 0.1606, lr_0 = 3.9518e-04
Loss = 1.3940e-04, PNorm = 45.7257, GNorm = 0.3642, lr_0 = 3.9465e-04
Loss = 1.1016e-04, PNorm = 45.7338, GNorm = 0.2443, lr_0 = 3.9412e-04
Loss = 1.3870e-04, PNorm = 45.7393, GNorm = 0.2411, lr_0 = 3.9359e-04
Loss = 1.4030e-04, PNorm = 45.7430, GNorm = 0.4997, lr_0 = 3.9306e-04
Loss = 1.4486e-04, PNorm = 45.7564, GNorm = 0.4994, lr_0 = 3.9253e-04
Loss = 1.7011e-04, PNorm = 45.7641, GNorm = 0.1998, lr_0 = 3.9201e-04
Loss = 1.3061e-04, PNorm = 45.7734, GNorm = 0.2887, lr_0 = 3.9148e-04
Loss = 1.2820e-04, PNorm = 45.7769, GNorm = 0.2230, lr_0 = 3.9096e-04
Loss = 1.2606e-04, PNorm = 45.7863, GNorm = 0.2761, lr_0 = 3.9043e-04
Loss = 1.2267e-04, PNorm = 45.7946, GNorm = 0.1742, lr_0 = 3.8991e-04
Loss = 1.2739e-04, PNorm = 45.7989, GNorm = 0.2428, lr_0 = 3.8938e-04
Loss = 1.2459e-04, PNorm = 45.8047, GNorm = 0.2153, lr_0 = 3.8886e-04
Validation rmse = 0.450905
Validation R2 = 0.941945
Epoch 42
Train function
Loss = 8.9376e-05, PNorm = 45.8115, GNorm = 0.2753, lr_0 = 3.8829e-04
Loss = 1.1390e-04, PNorm = 45.8161, GNorm = 0.4511, lr_0 = 3.8777e-04
Loss = 1.1574e-04, PNorm = 45.8227, GNorm = 0.2340, lr_0 = 3.8725e-04
Loss = 1.2053e-04, PNorm = 45.8325, GNorm = 0.3482, lr_0 = 3.8673e-04
Loss = 1.4964e-04, PNorm = 45.8333, GNorm = 0.2407, lr_0 = 3.8621e-04
Loss = 1.1818e-04, PNorm = 45.8401, GNorm = 0.1834, lr_0 = 3.8569e-04
Loss = 1.6650e-04, PNorm = 45.8455, GNorm = 0.4637, lr_0 = 3.8517e-04
Loss = 1.6263e-04, PNorm = 45.8550, GNorm = 0.2427, lr_0 = 3.8466e-04
Loss = 1.6841e-04, PNorm = 45.8642, GNorm = 0.2439, lr_0 = 3.8414e-04
Loss = 1.2371e-04, PNorm = 45.8732, GNorm = 0.3344, lr_0 = 3.8362e-04
Loss = 1.0465e-04, PNorm = 45.8795, GNorm = 0.1981, lr_0 = 3.8311e-04
Loss = 1.5379e-04, PNorm = 45.8853, GNorm = 0.4337, lr_0 = 3.8260e-04
Loss = 1.1863e-04, PNorm = 45.8908, GNorm = 0.3729, lr_0 = 3.8208e-04
Loss = 1.3804e-04, PNorm = 45.8985, GNorm = 0.4201, lr_0 = 3.8157e-04
Loss = 1.0362e-04, PNorm = 45.9052, GNorm = 0.1508, lr_0 = 3.8106e-04
Loss = 1.1969e-04, PNorm = 45.9083, GNorm = 0.2725, lr_0 = 3.8055e-04
Loss = 1.3635e-04, PNorm = 45.9124, GNorm = 0.1974, lr_0 = 3.8004e-04
Loss = 1.0072e-04, PNorm = 45.9175, GNorm = 0.2174, lr_0 = 3.7953e-04
Validation rmse = 0.450024
Validation R2 = 0.942171
Epoch 43
Train function
Loss = 1.0105e-04, PNorm = 45.9222, GNorm = 0.1414, lr_0 = 3.7902e-04
Loss = 8.3878e-05, PNorm = 45.9248, GNorm = 0.1131, lr_0 = 3.7851e-04
Loss = 8.5677e-05, PNorm = 45.9288, GNorm = 0.4116, lr_0 = 3.7800e-04
Loss = 9.9507e-05, PNorm = 45.9349, GNorm = 0.5266, lr_0 = 3.7749e-04
Loss = 1.4830e-04, PNorm = 45.9404, GNorm = 0.6216, lr_0 = 3.7699e-04
Loss = 9.1537e-05, PNorm = 45.9468, GNorm = 0.1205, lr_0 = 3.7648e-04
Loss = 9.3322e-05, PNorm = 45.9481, GNorm = 0.1718, lr_0 = 3.7598e-04
Loss = 9.7167e-05, PNorm = 45.9494, GNorm = 0.1464, lr_0 = 3.7547e-04
Loss = 8.5750e-05, PNorm = 45.9559, GNorm = 0.2720, lr_0 = 3.7497e-04
Loss = 9.7430e-05, PNorm = 45.9624, GNorm = 0.2012, lr_0 = 3.7446e-04
Loss = 8.5804e-05, PNorm = 45.9657, GNorm = 0.1928, lr_0 = 3.7396e-04
Loss = 1.2931e-04, PNorm = 45.9696, GNorm = 0.3219, lr_0 = 3.7346e-04
Loss = 1.1526e-04, PNorm = 45.9764, GNorm = 0.6307, lr_0 = 3.7296e-04
Loss = 1.2327e-04, PNorm = 45.9810, GNorm = 0.1892, lr_0 = 3.7246e-04
Loss = 1.0817e-04, PNorm = 45.9872, GNorm = 0.2325, lr_0 = 3.7196e-04
Loss = 1.3274e-04, PNorm = 45.9925, GNorm = 0.1990, lr_0 = 3.7146e-04
Loss = 1.5510e-04, PNorm = 46.0008, GNorm = 0.2849, lr_0 = 3.7096e-04
Validation rmse = 0.453597
Validation R2 = 0.941250
Epoch 44
Train function
Loss = 8.6040e-05, PNorm = 46.0086, GNorm = 0.2132, lr_0 = 3.7046e-04
Loss = 9.5486e-05, PNorm = 46.0151, GNorm = 0.1383, lr_0 = 3.6997e-04
Loss = 1.0808e-04, PNorm = 46.0170, GNorm = 0.1519, lr_0 = 3.6947e-04
Loss = 8.2820e-05, PNorm = 46.0223, GNorm = 0.1727, lr_0 = 3.6898e-04
Loss = 8.1673e-05, PNorm = 46.0293, GNorm = 0.2291, lr_0 = 3.6848e-04
Loss = 9.0428e-05, PNorm = 46.0359, GNorm = 0.1700, lr_0 = 3.6799e-04
Loss = 7.2653e-05, PNorm = 46.0383, GNorm = 0.3372, lr_0 = 3.6749e-04
Loss = 7.1430e-05, PNorm = 46.0394, GNorm = 0.2035, lr_0 = 3.6700e-04
Loss = 9.5006e-05, PNorm = 46.0447, GNorm = 0.2449, lr_0 = 3.6651e-04
Loss = 7.1456e-05, PNorm = 46.0478, GNorm = 0.1110, lr_0 = 3.6601e-04
Loss = 7.0248e-05, PNorm = 46.0513, GNorm = 0.2930, lr_0 = 3.6552e-04
Loss = 7.9545e-05, PNorm = 46.0541, GNorm = 0.1372, lr_0 = 3.6503e-04
Loss = 1.0226e-04, PNorm = 46.0564, GNorm = 0.2922, lr_0 = 3.6454e-04
Loss = 8.7588e-05, PNorm = 46.0665, GNorm = 0.2806, lr_0 = 3.6405e-04
Loss = 1.0136e-04, PNorm = 46.0759, GNorm = 0.1864, lr_0 = 3.6357e-04
Loss = 9.8395e-05, PNorm = 46.0829, GNorm = 0.1771, lr_0 = 3.6308e-04
Loss = 1.0777e-04, PNorm = 46.0903, GNorm = 0.2958, lr_0 = 3.6259e-04
Loss = 9.9740e-05, PNorm = 46.0978, GNorm = 0.1882, lr_0 = 3.6210e-04
Validation rmse = 0.449718
Validation R2 = 0.942250
Epoch 45
Train function
Loss = 1.0792e-04, PNorm = 46.1033, GNorm = 0.2221, lr_0 = 3.6157e-04
Loss = 9.2157e-05, PNorm = 46.1088, GNorm = 0.2158, lr_0 = 3.6108e-04
Loss = 8.4055e-05, PNorm = 46.1137, GNorm = 0.3052, lr_0 = 3.6060e-04
Loss = 8.2847e-05, PNorm = 46.1145, GNorm = 0.1503, lr_0 = 3.6012e-04
Loss = 7.6381e-05, PNorm = 46.1170, GNorm = 0.1834, lr_0 = 3.5963e-04
Loss = 6.7945e-05, PNorm = 46.1205, GNorm = 0.1473, lr_0 = 3.5915e-04
Loss = 9.5325e-05, PNorm = 46.1202, GNorm = 0.3889, lr_0 = 3.5867e-04
Loss = 9.4457e-05, PNorm = 46.1237, GNorm = 0.4617, lr_0 = 3.5819e-04
Loss = 8.5859e-05, PNorm = 46.1259, GNorm = 0.2031, lr_0 = 3.5771e-04
Loss = 7.7951e-05, PNorm = 46.1272, GNorm = 0.2439, lr_0 = 3.5723e-04
Loss = 9.9569e-05, PNorm = 46.1300, GNorm = 0.1444, lr_0 = 3.5675e-04
Loss = 9.7897e-05, PNorm = 46.1383, GNorm = 0.1306, lr_0 = 3.5627e-04
Loss = 8.0690e-05, PNorm = 46.1439, GNorm = 0.1274, lr_0 = 3.5579e-04
Loss = 9.0941e-05, PNorm = 46.1509, GNorm = 0.1906, lr_0 = 3.5531e-04
Loss = 9.0376e-05, PNorm = 46.1556, GNorm = 0.3565, lr_0 = 3.5484e-04
Loss = 7.4968e-05, PNorm = 46.1594, GNorm = 0.2213, lr_0 = 3.5436e-04
Loss = 6.9161e-05, PNorm = 46.1627, GNorm = 0.1294, lr_0 = 3.5389e-04
Loss = 8.0370e-05, PNorm = 46.1642, GNorm = 0.2337, lr_0 = 3.5341e-04
Validation rmse = 0.449781
Validation R2 = 0.942234
Epoch 46
Train function
Loss = 8.1442e-05, PNorm = 46.1687, GNorm = 0.1553, lr_0 = 3.5294e-04
Loss = 8.0212e-05, PNorm = 46.1714, GNorm = 0.2796, lr_0 = 3.5246e-04
Loss = 9.1355e-05, PNorm = 46.1751, GNorm = 0.2464, lr_0 = 3.5199e-04
Loss = 9.3572e-05, PNorm = 46.1823, GNorm = 0.3566, lr_0 = 3.5152e-04
Loss = 1.2078e-04, PNorm = 46.1873, GNorm = 0.8558, lr_0 = 3.5105e-04
Loss = 1.0532e-04, PNorm = 46.1927, GNorm = 0.3216, lr_0 = 3.5058e-04
Loss = 8.7992e-05, PNorm = 46.2003, GNorm = 0.4057, lr_0 = 3.5010e-04
Loss = 1.2367e-04, PNorm = 46.2028, GNorm = 0.5516, lr_0 = 3.4964e-04
Loss = 1.7907e-04, PNorm = 46.2097, GNorm = 0.5209, lr_0 = 3.4917e-04
Loss = 1.4625e-04, PNorm = 46.2175, GNorm = 0.5567, lr_0 = 3.4870e-04
Loss = 8.8761e-05, PNorm = 46.2223, GNorm = 0.2866, lr_0 = 3.4823e-04
Loss = 9.4272e-05, PNorm = 46.2296, GNorm = 0.2411, lr_0 = 3.4776e-04
Loss = 1.0404e-04, PNorm = 46.2341, GNorm = 0.2263, lr_0 = 3.4730e-04
Loss = 9.1703e-05, PNorm = 46.2363, GNorm = 0.1473, lr_0 = 3.4683e-04
Loss = 1.0781e-04, PNorm = 46.2414, GNorm = 0.3607, lr_0 = 3.4636e-04
Loss = 8.4959e-05, PNorm = 46.2474, GNorm = 0.1667, lr_0 = 3.4590e-04
Loss = 9.5622e-05, PNorm = 46.2523, GNorm = 0.1641, lr_0 = 3.4544e-04
Validation rmse = 0.450888
Validation R2 = 0.941949
Epoch 47
Train function
Loss = 8.3241e-05, PNorm = 46.2584, GNorm = 0.1872, lr_0 = 3.4497e-04
Loss = 1.0003e-04, PNorm = 46.2629, GNorm = 0.3071, lr_0 = 3.4451e-04
Loss = 6.2727e-05, PNorm = 46.2675, GNorm = 0.2368, lr_0 = 3.4405e-04
Loss = 7.7956e-05, PNorm = 46.2730, GNorm = 0.1597, lr_0 = 3.4359e-04
Loss = 6.7654e-05, PNorm = 46.2798, GNorm = 0.1308, lr_0 = 3.4312e-04
Loss = 7.3180e-05, PNorm = 46.2841, GNorm = 0.2233, lr_0 = 3.4266e-04
Loss = 7.4380e-05, PNorm = 46.2876, GNorm = 0.1821, lr_0 = 3.4220e-04
Loss = 7.1887e-05, PNorm = 46.2925, GNorm = 0.2550, lr_0 = 3.4175e-04
Loss = 9.2670e-05, PNorm = 46.2969, GNorm = 0.4717, lr_0 = 3.4129e-04
Loss = 1.0382e-04, PNorm = 46.3046, GNorm = 0.1500, lr_0 = 3.4083e-04
Loss = 7.0833e-05, PNorm = 46.3094, GNorm = 0.1544, lr_0 = 3.4037e-04
Loss = 8.7528e-05, PNorm = 46.3113, GNorm = 0.2416, lr_0 = 3.3991e-04
Loss = 1.0235e-04, PNorm = 46.3160, GNorm = 0.1639, lr_0 = 3.3946e-04
Loss = 9.3438e-05, PNorm = 46.3200, GNorm = 0.2306, lr_0 = 3.3900e-04
Loss = 8.6461e-05, PNorm = 46.3227, GNorm = 0.2217, lr_0 = 3.3855e-04
Loss = 8.2045e-05, PNorm = 46.3263, GNorm = 0.1911, lr_0 = 3.3809e-04
Loss = 8.0516e-05, PNorm = 46.3314, GNorm = 0.3032, lr_0 = 3.3764e-04
Loss = 8.3687e-05, PNorm = 46.3365, GNorm = 0.1827, lr_0 = 3.3719e-04
Validation rmse = 0.454241
Validation R2 = 0.941083
Epoch 48
Train function
Loss = 9.7270e-05, PNorm = 46.3411, GNorm = 0.1310, lr_0 = 3.3669e-04
Loss = 9.5154e-05, PNorm = 46.3469, GNorm = 0.2731, lr_0 = 3.3624e-04
Loss = 8.7873e-05, PNorm = 46.3507, GNorm = 0.1526, lr_0 = 3.3579e-04
Loss = 8.6637e-05, PNorm = 46.3537, GNorm = 0.1566, lr_0 = 3.3534e-04
Loss = 7.4249e-05, PNorm = 46.3553, GNorm = 0.2145, lr_0 = 3.3489e-04
Loss = 8.5127e-05, PNorm = 46.3602, GNorm = 0.2739, lr_0 = 3.3444e-04
Loss = 9.5576e-05, PNorm = 46.3626, GNorm = 0.3424, lr_0 = 3.3399e-04
Loss = 9.8709e-05, PNorm = 46.3675, GNorm = 0.2847, lr_0 = 3.3354e-04
Loss = 7.2816e-05, PNorm = 46.3738, GNorm = 0.1394, lr_0 = 3.3309e-04
Loss = 8.1975e-05, PNorm = 46.3778, GNorm = 0.2566, lr_0 = 3.3265e-04
Loss = 8.5655e-05, PNorm = 46.3825, GNorm = 0.2594, lr_0 = 3.3220e-04
Loss = 7.0201e-05, PNorm = 46.3854, GNorm = 0.1595, lr_0 = 3.3175e-04
Loss = 5.3855e-05, PNorm = 46.3885, GNorm = 0.2463, lr_0 = 3.3131e-04
Loss = 6.4687e-05, PNorm = 46.3917, GNorm = 0.2644, lr_0 = 3.3086e-04
Loss = 9.1175e-05, PNorm = 46.3963, GNorm = 0.3177, lr_0 = 3.3042e-04
Loss = 8.5606e-05, PNorm = 46.4017, GNorm = 0.2266, lr_0 = 3.2998e-04
Loss = 8.8489e-05, PNorm = 46.4069, GNorm = 0.1616, lr_0 = 3.2953e-04
Validation rmse = 0.456136
Validation R2 = 0.940590
Epoch 49
Train function
Loss = 6.5167e-05, PNorm = 46.4117, GNorm = 0.2093, lr_0 = 3.2909e-04
Loss = 6.6743e-05, PNorm = 46.4189, GNorm = 0.1566, lr_0 = 3.2865e-04
Loss = 6.3057e-05, PNorm = 46.4234, GNorm = 0.2291, lr_0 = 3.2821e-04
Loss = 1.0127e-04, PNorm = 46.4280, GNorm = 0.1656, lr_0 = 3.2777e-04
Loss = 1.0273e-04, PNorm = 46.4314, GNorm = 0.1497, lr_0 = 3.2733e-04
Loss = 7.8620e-05, PNorm = 46.4364, GNorm = 0.2341, lr_0 = 3.2689e-04
Loss = 8.7706e-05, PNorm = 46.4393, GNorm = 0.3978, lr_0 = 3.2645e-04
Loss = 9.3702e-05, PNorm = 46.4436, GNorm = 0.2385, lr_0 = 3.2601e-04
Loss = 8.1501e-05, PNorm = 46.4473, GNorm = 0.1808, lr_0 = 3.2558e-04
Loss = 8.0481e-05, PNorm = 46.4519, GNorm = 0.4234, lr_0 = 3.2514e-04
Loss = 8.3093e-05, PNorm = 46.4558, GNorm = 0.3550, lr_0 = 3.2470e-04
Loss = 6.3643e-05, PNorm = 46.4585, GNorm = 0.1257, lr_0 = 3.2427e-04
Loss = 7.4243e-05, PNorm = 46.4647, GNorm = 0.3624, lr_0 = 3.2383e-04
Loss = 9.8770e-05, PNorm = 46.4700, GNorm = 0.2345, lr_0 = 3.2340e-04
Loss = 8.9943e-05, PNorm = 46.4760, GNorm = 0.1474, lr_0 = 3.2296e-04
Loss = 9.6753e-05, PNorm = 46.4803, GNorm = 0.4354, lr_0 = 3.2253e-04
Loss = 8.3422e-05, PNorm = 46.4885, GNorm = 0.1050, lr_0 = 3.2210e-04
Loss = 6.5465e-05, PNorm = 46.4917, GNorm = 0.2380, lr_0 = 3.2167e-04
Validation rmse = 0.448878
Validation R2 = 0.942466
Epoch 50
Train function
Loss = 6.3564e-05, PNorm = 46.4947, GNorm = 0.2292, lr_0 = 3.2123e-04
Loss = 7.1200e-05, PNorm = 46.4988, GNorm = 0.3863, lr_0 = 3.2080e-04
Loss = 7.0882e-05, PNorm = 46.5032, GNorm = 0.1689, lr_0 = 3.2037e-04
Loss = 6.5827e-05, PNorm = 46.5045, GNorm = 0.2136, lr_0 = 3.1994e-04
Loss = 7.0215e-05, PNorm = 46.5067, GNorm = 0.1404, lr_0 = 3.1951e-04
Loss = 6.0878e-05, PNorm = 46.5114, GNorm = 0.1560, lr_0 = 3.1909e-04
Loss = 9.4600e-05, PNorm = 46.5157, GNorm = 0.3160, lr_0 = 3.1866e-04
Loss = 1.0154e-04, PNorm = 46.5222, GNorm = 0.2302, lr_0 = 3.1823e-04
Loss = 8.7743e-05, PNorm = 46.5254, GNorm = 0.1925, lr_0 = 3.1780e-04
Loss = 9.1442e-05, PNorm = 46.5298, GNorm = 0.2046, lr_0 = 3.1738e-04
Loss = 8.4012e-05, PNorm = 46.5332, GNorm = 0.2216, lr_0 = 3.1695e-04
Loss = 5.5089e-05, PNorm = 46.5348, GNorm = 0.0932, lr_0 = 3.1653e-04
Loss = 7.4110e-05, PNorm = 46.5390, GNorm = 0.2321, lr_0 = 3.1610e-04
Loss = 6.9055e-05, PNorm = 46.5446, GNorm = 0.1057, lr_0 = 3.1568e-04
Loss = 9.1872e-05, PNorm = 46.5502, GNorm = 0.5989, lr_0 = 3.1525e-04
Loss = 1.0554e-04, PNorm = 46.5575, GNorm = 0.4255, lr_0 = 3.1483e-04
Loss = 9.6014e-05, PNorm = 46.5623, GNorm = 0.2770, lr_0 = 3.1441e-04
Validation rmse = 0.462446
Validation R2 = 0.938935
Epoch 51
Train function
Loss = 1.3595e-04, PNorm = 46.5658, GNorm = 0.6372, lr_0 = 3.1394e-04
Loss = 8.5332e-05, PNorm = 46.5697, GNorm = 0.1664, lr_0 = 3.1352e-04
Loss = 6.3874e-05, PNorm = 46.5739, GNorm = 0.3380, lr_0 = 3.1310e-04
Loss = 6.2667e-05, PNorm = 46.5819, GNorm = 0.2027, lr_0 = 3.1268e-04
Loss = 6.5165e-05, PNorm = 46.5870, GNorm = 0.2982, lr_0 = 3.1226e-04
Loss = 6.8119e-05, PNorm = 46.5901, GNorm = 0.1870, lr_0 = 3.1184e-04
Loss = 6.0926e-05, PNorm = 46.5940, GNorm = 0.1187, lr_0 = 3.1142e-04
Loss = 5.8374e-05, PNorm = 46.5970, GNorm = 0.2668, lr_0 = 3.1101e-04
Loss = 6.1395e-05, PNorm = 46.5973, GNorm = 0.3117, lr_0 = 3.1059e-04
Loss = 1.1049e-04, PNorm = 46.6010, GNorm = 0.2864, lr_0 = 3.1017e-04
Loss = 7.8175e-05, PNorm = 46.6032, GNorm = 0.1628, lr_0 = 3.0976e-04
Loss = 8.2067e-05, PNorm = 46.6095, GNorm = 0.1685, lr_0 = 3.0934e-04
Loss = 5.9891e-05, PNorm = 46.6129, GNorm = 0.1777, lr_0 = 3.0893e-04
Loss = 7.6894e-05, PNorm = 46.6152, GNorm = 0.4055, lr_0 = 3.0851e-04
Loss = 6.7726e-05, PNorm = 46.6176, GNorm = 0.0871, lr_0 = 3.0810e-04
Loss = 5.4010e-05, PNorm = 46.6200, GNorm = 0.1098, lr_0 = 3.0768e-04
Loss = 8.6160e-05, PNorm = 46.6254, GNorm = 0.1427, lr_0 = 3.0727e-04
Loss = 9.2905e-05, PNorm = 46.6286, GNorm = 0.1350, lr_0 = 3.0686e-04
Validation rmse = 0.455558
Validation R2 = 0.940741
Epoch 52
Train function
Loss = 1.1523e-04, PNorm = 46.6344, GNorm = 0.2885, lr_0 = 3.0645e-04
Loss = 9.1170e-05, PNorm = 46.6400, GNorm = 0.2029, lr_0 = 3.0604e-04
Loss = 7.3607e-05, PNorm = 46.6457, GNorm = 0.4153, lr_0 = 3.0563e-04
Loss = 6.8065e-05, PNorm = 46.6481, GNorm = 0.1489, lr_0 = 3.0522e-04
Loss = 7.3107e-05, PNorm = 46.6495, GNorm = 0.1841, lr_0 = 3.0481e-04
Loss = 7.0407e-05, PNorm = 46.6530, GNorm = 0.1161, lr_0 = 3.0440e-04
Loss = 6.8910e-05, PNorm = 46.6555, GNorm = 0.2021, lr_0 = 3.0399e-04
Loss = 7.7609e-05, PNorm = 46.6586, GNorm = 0.4867, lr_0 = 3.0358e-04
Loss = 7.8696e-05, PNorm = 46.6618, GNorm = 0.5359, lr_0 = 3.0317e-04
Loss = 6.9027e-05, PNorm = 46.6663, GNorm = 0.2933, lr_0 = 3.0277e-04
Loss = 5.8569e-05, PNorm = 46.6700, GNorm = 0.2870, lr_0 = 3.0236e-04
Loss = 5.7205e-05, PNorm = 46.6732, GNorm = 0.1662, lr_0 = 3.0195e-04
Loss = 6.9345e-05, PNorm = 46.6783, GNorm = 0.1104, lr_0 = 3.0155e-04
Loss = 6.5580e-05, PNorm = 46.6794, GNorm = 0.1291, lr_0 = 3.0114e-04
Loss = 5.9823e-05, PNorm = 46.6811, GNorm = 0.1623, lr_0 = 3.0074e-04
Loss = 7.0059e-05, PNorm = 46.6848, GNorm = 0.2913, lr_0 = 3.0034e-04
Loss = 6.3112e-05, PNorm = 46.6886, GNorm = 0.3356, lr_0 = 2.9993e-04
Validation rmse = 0.452917
Validation R2 = 0.941426
Epoch 53
Train function
Loss = 4.3419e-05, PNorm = 46.6932, GNorm = 0.1759, lr_0 = 2.9949e-04
Loss = 6.3796e-05, PNorm = 46.6956, GNorm = 0.1584, lr_0 = 2.9909e-04
Loss = 5.3305e-05, PNorm = 46.6976, GNorm = 0.1774, lr_0 = 2.9869e-04
Loss = 6.4931e-05, PNorm = 46.7002, GNorm = 0.1739, lr_0 = 2.9829e-04
Loss = 5.7098e-05, PNorm = 46.7035, GNorm = 0.5034, lr_0 = 2.9789e-04
Loss = 6.3650e-05, PNorm = 46.7062, GNorm = 0.1493, lr_0 = 2.9749e-04
Loss = 5.3612e-05, PNorm = 46.7116, GNorm = 0.0978, lr_0 = 2.9709e-04
Loss = 5.6640e-05, PNorm = 46.7160, GNorm = 0.1587, lr_0 = 2.9669e-04
Loss = 4.9345e-05, PNorm = 46.7192, GNorm = 0.1311, lr_0 = 2.9629e-04
Loss = 5.3049e-05, PNorm = 46.7201, GNorm = 0.1974, lr_0 = 2.9589e-04
Loss = 5.9603e-05, PNorm = 46.7236, GNorm = 0.4576, lr_0 = 2.9550e-04
Loss = 5.9775e-05, PNorm = 46.7276, GNorm = 0.4059, lr_0 = 2.9510e-04
Loss = 6.4714e-05, PNorm = 46.7312, GNorm = 0.4712, lr_0 = 2.9471e-04
Loss = 8.1532e-05, PNorm = 46.7388, GNorm = 0.4309, lr_0 = 2.9431e-04
Loss = 9.4790e-05, PNorm = 46.7405, GNorm = 0.3132, lr_0 = 2.9391e-04
Loss = 6.8442e-05, PNorm = 46.7421, GNorm = 0.1299, lr_0 = 2.9352e-04
Loss = 6.4868e-05, PNorm = 46.7459, GNorm = 0.2225, lr_0 = 2.9313e-04
Loss = 8.2060e-05, PNorm = 46.7501, GNorm = 0.2829, lr_0 = 2.9273e-04
Validation rmse = 0.447486
Validation R2 = 0.942822
Epoch 54
Train function
Loss = 5.7264e-05, PNorm = 46.7526, GNorm = 0.1664, lr_0 = 2.9234e-04
Loss = 5.1220e-05, PNorm = 46.7554, GNorm = 0.1380, lr_0 = 2.9195e-04
Loss = 4.8479e-05, PNorm = 46.7585, GNorm = 0.1250, lr_0 = 2.9156e-04
Loss = 4.6183e-05, PNorm = 46.7641, GNorm = 0.0938, lr_0 = 2.9117e-04
Loss = 5.4076e-05, PNorm = 46.7669, GNorm = 0.0759, lr_0 = 2.9077e-04
Loss = 6.4605e-05, PNorm = 46.7706, GNorm = 0.2460, lr_0 = 2.9038e-04
Loss = 5.0519e-05, PNorm = 46.7742, GNorm = 0.3517, lr_0 = 2.9000e-04
Loss = 5.1235e-05, PNorm = 46.7758, GNorm = 0.2182, lr_0 = 2.8961e-04
Loss = 5.1305e-05, PNorm = 46.7797, GNorm = 0.1728, lr_0 = 2.8922e-04
Loss = 8.0912e-05, PNorm = 46.7841, GNorm = 0.1624, lr_0 = 2.8883e-04
Loss = 7.1647e-05, PNorm = 46.7884, GNorm = 0.1045, lr_0 = 2.8844e-04
Loss = 7.2547e-05, PNorm = 46.7876, GNorm = 0.2775, lr_0 = 2.8805e-04
Loss = 5.1125e-05, PNorm = 46.7901, GNorm = 0.1163, lr_0 = 2.8767e-04
Loss = 5.8106e-05, PNorm = 46.7946, GNorm = 0.1602, lr_0 = 2.8728e-04
Loss = 5.9236e-05, PNorm = 46.7987, GNorm = 0.2043, lr_0 = 2.8690e-04
Loss = 4.6048e-05, PNorm = 46.8015, GNorm = 0.2556, lr_0 = 2.8651e-04
Loss = 5.3586e-05, PNorm = 46.8055, GNorm = 0.1254, lr_0 = 2.8613e-04
Loss = 4.8871e-05, PNorm = 46.8060, GNorm = 0.1959, lr_0 = 2.8574e-04
Validation rmse = 0.448397
Validation R2 = 0.942589
Epoch 55
Train function
Loss = 5.1168e-05, PNorm = 46.8066, GNorm = 0.1138, lr_0 = 2.8536e-04
Loss = 5.1175e-05, PNorm = 46.8064, GNorm = 0.1125, lr_0 = 2.8498e-04
Loss = 5.0058e-05, PNorm = 46.8081, GNorm = 0.2640, lr_0 = 2.8460e-04
Loss = 4.8345e-05, PNorm = 46.8110, GNorm = 0.1638, lr_0 = 2.8421e-04
Loss = 5.8992e-05, PNorm = 46.8132, GNorm = 0.1965, lr_0 = 2.8383e-04
Loss = 7.2427e-05, PNorm = 46.8178, GNorm = 0.1245, lr_0 = 2.8345e-04
Loss = 4.2679e-05, PNorm = 46.8216, GNorm = 0.1375, lr_0 = 2.8307e-04
Loss = 5.6399e-05, PNorm = 46.8245, GNorm = 0.1412, lr_0 = 2.8269e-04
Loss = 5.5372e-05, PNorm = 46.8286, GNorm = 0.1224, lr_0 = 2.8231e-04
Loss = 6.0581e-05, PNorm = 46.8358, GNorm = 0.2059, lr_0 = 2.8193e-04
Loss = 4.7787e-05, PNorm = 46.8404, GNorm = 0.1983, lr_0 = 2.8155e-04
Loss = 5.6442e-05, PNorm = 46.8452, GNorm = 0.1835, lr_0 = 2.8118e-04
Loss = 5.1638e-05, PNorm = 46.8490, GNorm = 0.1625, lr_0 = 2.8080e-04
Loss = 6.3489e-05, PNorm = 46.8532, GNorm = 0.1353, lr_0 = 2.8042e-04
Loss = 5.3354e-05, PNorm = 46.8581, GNorm = 0.1119, lr_0 = 2.8005e-04
Loss = 5.1927e-05, PNorm = 46.8598, GNorm = 0.0852, lr_0 = 2.7967e-04
Loss = 4.6344e-05, PNorm = 46.8619, GNorm = 0.1758, lr_0 = 2.7930e-04
Validation rmse = 0.449222
Validation R2 = 0.942378
Epoch 56
Train function
Loss = 3.7293e-05, PNorm = 46.8642, GNorm = 0.1653, lr_0 = 2.7888e-04
Loss = 4.7720e-05, PNorm = 46.8659, GNorm = 0.1975, lr_0 = 2.7851e-04
Loss = 5.5182e-05, PNorm = 46.8691, GNorm = 0.1439, lr_0 = 2.7814e-04
Loss = 5.8509e-05, PNorm = 46.8718, GNorm = 0.2879, lr_0 = 2.7776e-04
Loss = 5.7800e-05, PNorm = 46.8752, GNorm = 0.1152, lr_0 = 2.7739e-04
Loss = 5.9467e-05, PNorm = 46.8806, GNorm = 0.2859, lr_0 = 2.7702e-04
Loss = 3.9334e-05, PNorm = 46.8826, GNorm = 0.0947, lr_0 = 2.7665e-04
Loss = 5.2535e-05, PNorm = 46.8858, GNorm = 0.3176, lr_0 = 2.7627e-04
Loss = 5.9543e-05, PNorm = 46.8890, GNorm = 0.4017, lr_0 = 2.7590e-04
Loss = 6.2561e-05, PNorm = 46.8901, GNorm = 0.3975, lr_0 = 2.7553e-04
Loss = 5.1037e-05, PNorm = 46.8928, GNorm = 0.1940, lr_0 = 2.7516e-04
Loss = 5.1754e-05, PNorm = 46.8974, GNorm = 0.2078, lr_0 = 2.7479e-04
Loss = 4.8556e-05, PNorm = 46.8999, GNorm = 0.2578, lr_0 = 2.7443e-04
Loss = 3.8050e-05, PNorm = 46.9009, GNorm = 0.1932, lr_0 = 2.7406e-04
Loss = 4.6735e-05, PNorm = 46.9017, GNorm = 0.2168, lr_0 = 2.7369e-04
Loss = 6.3796e-05, PNorm = 46.9041, GNorm = 0.1647, lr_0 = 2.7332e-04
Loss = 6.6513e-05, PNorm = 46.9052, GNorm = 0.2208, lr_0 = 2.7296e-04
Loss = 4.4505e-05, PNorm = 46.9072, GNorm = 0.1707, lr_0 = 2.7259e-04
Validation rmse = 0.452467
Validation R2 = 0.941542
Epoch 57
Train function
Loss = 4.0280e-05, PNorm = 46.9095, GNorm = 0.2311, lr_0 = 2.7222e-04
Loss = 4.1957e-05, PNorm = 46.9126, GNorm = 0.1017, lr_0 = 2.7186e-04
Loss = 4.8129e-05, PNorm = 46.9163, GNorm = 0.2311, lr_0 = 2.7149e-04
Loss = 3.7644e-05, PNorm = 46.9171, GNorm = 0.1083, lr_0 = 2.7113e-04
Loss = 4.4069e-05, PNorm = 46.9183, GNorm = 0.3247, lr_0 = 2.7077e-04
Loss = 4.2145e-05, PNorm = 46.9195, GNorm = 0.1298, lr_0 = 2.7040e-04
Loss = 4.3435e-05, PNorm = 46.9227, GNorm = 0.1466, lr_0 = 2.7004e-04
Loss = 3.7590e-05, PNorm = 46.9269, GNorm = 0.0942, lr_0 = 2.6968e-04
Loss = 5.0378e-05, PNorm = 46.9273, GNorm = 0.1217, lr_0 = 2.6932e-04
Loss = 5.1455e-05, PNorm = 46.9331, GNorm = 0.1151, lr_0 = 2.6895e-04
Loss = 4.9884e-05, PNorm = 46.9349, GNorm = 0.1420, lr_0 = 2.6859e-04
Loss = 3.6334e-05, PNorm = 46.9375, GNorm = 0.1647, lr_0 = 2.6823e-04
Loss = 7.4926e-05, PNorm = 46.9405, GNorm = 0.2129, lr_0 = 2.6787e-04
Loss = 9.6223e-05, PNorm = 46.9452, GNorm = 0.4064, lr_0 = 2.6751e-04
Loss = 7.0733e-05, PNorm = 46.9491, GNorm = 0.2673, lr_0 = 2.6716e-04
Loss = 6.6089e-05, PNorm = 46.9519, GNorm = 0.1823, lr_0 = 2.6680e-04
Loss = 9.8798e-05, PNorm = 46.9581, GNorm = 0.2975, lr_0 = 2.6644e-04
Validation rmse = 0.454740
Validation R2 = 0.940953
Epoch 58
Train function
Loss = 6.7468e-05, PNorm = 46.9656, GNorm = 0.2347, lr_0 = 2.6608e-04
Loss = 1.0706e-04, PNorm = 46.9706, GNorm = 0.2747, lr_0 = 2.6572e-04
Loss = 1.0443e-04, PNorm = 46.9736, GNorm = 0.4992, lr_0 = 2.6537e-04
Loss = 9.9336e-05, PNorm = 46.9776, GNorm = 0.4960, lr_0 = 2.6501e-04
Loss = 6.8047e-05, PNorm = 46.9862, GNorm = 0.1358, lr_0 = 2.6466e-04
Loss = 6.6920e-05, PNorm = 46.9933, GNorm = 0.1354, lr_0 = 2.6430e-04
Loss = 4.3183e-05, PNorm = 46.9961, GNorm = 0.1172, lr_0 = 2.6395e-04
Loss = 4.6951e-05, PNorm = 46.9984, GNorm = 0.1069, lr_0 = 2.6359e-04
Loss = 4.2735e-05, PNorm = 47.0015, GNorm = 0.1761, lr_0 = 2.6324e-04
Loss = 4.3074e-05, PNorm = 47.0034, GNorm = 0.2659, lr_0 = 2.6289e-04
Loss = 4.7535e-05, PNorm = 47.0056, GNorm = 0.1516, lr_0 = 2.6253e-04
Loss = 3.8893e-05, PNorm = 47.0081, GNorm = 0.2249, lr_0 = 2.6218e-04
Loss = 4.6931e-05, PNorm = 47.0084, GNorm = 0.1951, lr_0 = 2.6183e-04
Loss = 5.3399e-05, PNorm = 47.0125, GNorm = 0.1071, lr_0 = 2.6148e-04
Loss = 5.8440e-05, PNorm = 47.0182, GNorm = 0.3602, lr_0 = 2.6113e-04
Loss = 5.4858e-05, PNorm = 47.0213, GNorm = 0.2309, lr_0 = 2.6078e-04
Loss = 5.4275e-05, PNorm = 47.0244, GNorm = 0.1724, lr_0 = 2.6043e-04
Loss = 5.5190e-05, PNorm = 47.0298, GNorm = 0.1160, lr_0 = 2.6008e-04
Validation rmse = 0.449190
Validation R2 = 0.942386
Epoch 59
Train function
Loss = 4.2918e-05, PNorm = 47.0360, GNorm = 0.1316, lr_0 = 2.5969e-04
Loss = 4.0651e-05, PNorm = 47.0386, GNorm = 0.1269, lr_0 = 2.5934e-04
Loss = 3.7587e-05, PNorm = 47.0420, GNorm = 0.2722, lr_0 = 2.5900e-04
Loss = 4.1307e-05, PNorm = 47.0437, GNorm = 0.1618, lr_0 = 2.5865e-04
Loss = 3.6589e-05, PNorm = 47.0444, GNorm = 0.0896, lr_0 = 2.5830e-04
Loss = 4.2973e-05, PNorm = 47.0436, GNorm = 0.0949, lr_0 = 2.5796e-04
Loss = 5.0862e-05, PNorm = 47.0432, GNorm = 0.1971, lr_0 = 2.5761e-04
Loss = 4.1819e-05, PNorm = 47.0470, GNorm = 0.1173, lr_0 = 2.5726e-04
Loss = 4.5362e-05, PNorm = 47.0466, GNorm = 0.0943, lr_0 = 2.5692e-04
Loss = 4.8224e-05, PNorm = 47.0479, GNorm = 0.1118, lr_0 = 2.5657e-04
Loss = 4.5026e-05, PNorm = 47.0497, GNorm = 0.0951, lr_0 = 2.5623e-04
Loss = 5.1828e-05, PNorm = 47.0530, GNorm = 0.3055, lr_0 = 2.5589e-04
Loss = 4.6241e-05, PNorm = 47.0573, GNorm = 0.1782, lr_0 = 2.5554e-04
Loss = 5.0012e-05, PNorm = 47.0591, GNorm = 0.0841, lr_0 = 2.5520e-04
Loss = 4.5888e-05, PNorm = 47.0607, GNorm = 0.1110, lr_0 = 2.5486e-04
Loss = 5.1563e-05, PNorm = 47.0638, GNorm = 0.2149, lr_0 = 2.5452e-04
Loss = 4.5970e-05, PNorm = 47.0651, GNorm = 0.1164, lr_0 = 2.5417e-04
Validation rmse = 0.448945
Validation R2 = 0.942448
Epoch 60
Train function
Loss = 4.2865e-05, PNorm = 47.0678, GNorm = 0.1276, lr_0 = 2.5383e-04
Loss = 3.4215e-05, PNorm = 47.0735, GNorm = 0.2732, lr_0 = 2.5349e-04
Loss = 3.7340e-05, PNorm = 47.0755, GNorm = 0.1698, lr_0 = 2.5315e-04
Loss = 3.2198e-05, PNorm = 47.0773, GNorm = 0.1082, lr_0 = 2.5281e-04
Loss = 4.7983e-05, PNorm = 47.0790, GNorm = 0.1336, lr_0 = 2.5247e-04
Loss = 5.3162e-05, PNorm = 47.0804, GNorm = 0.1447, lr_0 = 2.5213e-04
Loss = 5.6579e-05, PNorm = 47.0845, GNorm = 0.1508, lr_0 = 2.5180e-04
Loss = 5.3595e-05, PNorm = 47.0849, GNorm = 0.2718, lr_0 = 2.5146e-04
Loss = 3.5540e-05, PNorm = 47.0863, GNorm = 0.1164, lr_0 = 2.5112e-04
Loss = 5.3847e-05, PNorm = 47.0882, GNorm = 0.1644, lr_0 = 2.5078e-04
Loss = 3.9895e-05, PNorm = 47.0895, GNorm = 0.1055, lr_0 = 2.5045e-04
Loss = 4.3194e-05, PNorm = 47.0918, GNorm = 0.1716, lr_0 = 2.5011e-04
Loss = 3.6107e-05, PNorm = 47.0926, GNorm = 0.2441, lr_0 = 2.4978e-04
Loss = 3.3718e-05, PNorm = 47.0957, GNorm = 0.1031, lr_0 = 2.4944e-04
Loss = 4.3600e-05, PNorm = 47.1000, GNorm = 0.1120, lr_0 = 2.4911e-04
Loss = 5.0088e-05, PNorm = 47.1036, GNorm = 0.1167, lr_0 = 2.4877e-04
Loss = 4.4502e-05, PNorm = 47.1079, GNorm = 0.2000, lr_0 = 2.4844e-04
Loss = 4.0486e-05, PNorm = 47.1102, GNorm = 0.2512, lr_0 = 2.4811e-04
Validation rmse = 0.451075
Validation R2 = 0.941901
Epoch 61
Train function
Loss = 4.9636e-05, PNorm = 47.1126, GNorm = 0.3224, lr_0 = 2.4777e-04
Loss = 3.5698e-05, PNorm = 47.1146, GNorm = 0.0936, lr_0 = 2.4744e-04
Loss = 4.0795e-05, PNorm = 47.1182, GNorm = 0.0951, lr_0 = 2.4711e-04
Loss = 4.1028e-05, PNorm = 47.1204, GNorm = 0.0966, lr_0 = 2.4678e-04
Loss = 3.1744e-05, PNorm = 47.1223, GNorm = 0.1186, lr_0 = 2.4645e-04
Loss = 3.2332e-05, PNorm = 47.1223, GNorm = 0.0838, lr_0 = 2.4611e-04
Loss = 3.4725e-05, PNorm = 47.1230, GNorm = 0.1955, lr_0 = 2.4578e-04
Loss = 2.6511e-05, PNorm = 47.1257, GNorm = 0.0918, lr_0 = 2.4545e-04
Loss = 2.6649e-05, PNorm = 47.1262, GNorm = 0.0879, lr_0 = 2.4513e-04
Loss = 3.0325e-05, PNorm = 47.1293, GNorm = 0.0994, lr_0 = 2.4480e-04
Loss = 3.5361e-05, PNorm = 47.1319, GNorm = 0.1679, lr_0 = 2.4447e-04
Loss = 4.0428e-05, PNorm = 47.1325, GNorm = 0.2502, lr_0 = 2.4414e-04
Loss = 3.3090e-05, PNorm = 47.1331, GNorm = 0.1659, lr_0 = 2.4381e-04
Loss = 3.3399e-05, PNorm = 47.1363, GNorm = 0.0956, lr_0 = 2.4349e-04
Loss = 4.6540e-05, PNorm = 47.1375, GNorm = 0.1102, lr_0 = 2.4316e-04
Loss = 4.5817e-05, PNorm = 47.1420, GNorm = 0.1605, lr_0 = 2.4283e-04
Loss = 4.7495e-05, PNorm = 47.1469, GNorm = 0.1481, lr_0 = 2.4251e-04
Loss = 4.7310e-05, PNorm = 47.1510, GNorm = 0.1357, lr_0 = 2.4218e-04
Loss = 4.8769e-05, PNorm = 47.1513, GNorm = 0.1439, lr_0 = 2.4215e-04
Validation rmse = 0.451809
Validation R2 = 0.941712
Epoch 62
Train function
Loss = 4.5190e-05, PNorm = 47.1550, GNorm = 0.0967, lr_0 = 2.4182e-04
Loss = 4.2091e-05, PNorm = 47.1576, GNorm = 0.1240, lr_0 = 2.4150e-04
Loss = 2.9551e-05, PNorm = 47.1604, GNorm = 0.1708, lr_0 = 2.4118e-04
Loss = 3.0974e-05, PNorm = 47.1624, GNorm = 0.0973, lr_0 = 2.4085e-04
Loss = 2.9482e-05, PNorm = 47.1635, GNorm = 0.0655, lr_0 = 2.4053e-04
Loss = 3.0924e-05, PNorm = 47.1663, GNorm = 0.0593, lr_0 = 2.4021e-04
Loss = 3.5338e-05, PNorm = 47.1681, GNorm = 0.2020, lr_0 = 2.3988e-04
Loss = 3.8079e-05, PNorm = 47.1691, GNorm = 0.2269, lr_0 = 2.3956e-04
Loss = 3.8956e-05, PNorm = 47.1703, GNorm = 0.1194, lr_0 = 2.3924e-04
Loss = 4.5111e-05, PNorm = 47.1724, GNorm = 0.1788, lr_0 = 2.3892e-04
Loss = 4.3544e-05, PNorm = 47.1745, GNorm = 0.2117, lr_0 = 2.3860e-04
Loss = 6.5388e-05, PNorm = 47.1783, GNorm = 0.2701, lr_0 = 2.3828e-04
Loss = 3.6010e-05, PNorm = 47.1783, GNorm = 0.0944, lr_0 = 2.3796e-04
Loss = 4.1887e-05, PNorm = 47.1802, GNorm = 0.1193, lr_0 = 2.3764e-04
Loss = 3.4343e-05, PNorm = 47.1811, GNorm = 0.1382, lr_0 = 2.3732e-04
Loss = 4.1190e-05, PNorm = 47.1837, GNorm = 0.0920, lr_0 = 2.3700e-04
Loss = 3.8849e-05, PNorm = 47.1853, GNorm = 0.1375, lr_0 = 2.3668e-04
Validation rmse = 0.449055
Validation R2 = 0.942420
Epoch 63
Train function
Loss = 2.9463e-05, PNorm = 47.1868, GNorm = 0.1010, lr_0 = 2.3637e-04
Loss = 3.5510e-05, PNorm = 47.1880, GNorm = 0.1675, lr_0 = 2.3605e-04
Loss = 3.4650e-05, PNorm = 47.1903, GNorm = 0.1190, lr_0 = 2.3573e-04
Loss = 2.3731e-05, PNorm = 47.1928, GNorm = 0.0507, lr_0 = 2.3542e-04
Loss = 3.6636e-05, PNorm = 47.1956, GNorm = 0.0905, lr_0 = 2.3510e-04
Loss = 3.5574e-05, PNorm = 47.1979, GNorm = 0.1887, lr_0 = 2.3479e-04
Loss = 4.2981e-05, PNorm = 47.1992, GNorm = 0.0993, lr_0 = 2.3447e-04
Loss = 3.5605e-05, PNorm = 47.1983, GNorm = 0.1714, lr_0 = 2.3416e-04
Loss = 3.8946e-05, PNorm = 47.2030, GNorm = 0.1190, lr_0 = 2.3384e-04
Loss = 3.7554e-05, PNorm = 47.2087, GNorm = 0.1146, lr_0 = 2.3353e-04
Loss = 3.8142e-05, PNorm = 47.2103, GNorm = 0.1164, lr_0 = 2.3321e-04
Loss = 4.3306e-05, PNorm = 47.2116, GNorm = 0.0986, lr_0 = 2.3290e-04
Loss = 3.3698e-05, PNorm = 47.2125, GNorm = 0.0999, lr_0 = 2.3259e-04
Loss = 3.3051e-05, PNorm = 47.2141, GNorm = 0.0926, lr_0 = 2.3228e-04
Loss = 2.9473e-05, PNorm = 47.2165, GNorm = 0.1693, lr_0 = 2.3197e-04
Loss = 4.7727e-05, PNorm = 47.2199, GNorm = 0.2626, lr_0 = 2.3165e-04
Loss = 4.4675e-05, PNorm = 47.2207, GNorm = 0.2197, lr_0 = 2.3134e-04
Loss = 3.9963e-05, PNorm = 47.2227, GNorm = 0.1840, lr_0 = 2.3103e-04
Validation rmse = 0.447167
Validation R2 = 0.942903
Epoch 64
Train function
Loss = 3.1217e-05, PNorm = 47.2252, GNorm = 0.1421, lr_0 = 2.3072e-04
Loss = 3.3768e-05, PNorm = 47.2279, GNorm = 0.1227, lr_0 = 2.3041e-04
Loss = 2.6136e-05, PNorm = 47.2299, GNorm = 0.0916, lr_0 = 2.3010e-04
Loss = 4.7807e-05, PNorm = 47.2315, GNorm = 0.2590, lr_0 = 2.2980e-04
Loss = 5.0097e-05, PNorm = 47.2324, GNorm = 0.1268, lr_0 = 2.2949e-04
Loss = 3.2048e-05, PNorm = 47.2349, GNorm = 0.1446, lr_0 = 2.2918e-04
Loss = 3.1540e-05, PNorm = 47.2381, GNorm = 0.1491, lr_0 = 2.2887e-04
Loss = 2.4297e-05, PNorm = 47.2410, GNorm = 0.1018, lr_0 = 2.2856e-04
Loss = 3.5897e-05, PNorm = 47.2426, GNorm = 0.1462, lr_0 = 2.2826e-04
Loss = 3.9015e-05, PNorm = 47.2431, GNorm = 0.1296, lr_0 = 2.2795e-04
Loss = 3.0952e-05, PNorm = 47.2431, GNorm = 0.0854, lr_0 = 2.2765e-04
Loss = 4.0070e-05, PNorm = 47.2467, GNorm = 0.2084, lr_0 = 2.2734e-04
Loss = 2.6658e-05, PNorm = 47.2475, GNorm = 0.1026, lr_0 = 2.2704e-04
Loss = 3.4228e-05, PNorm = 47.2495, GNorm = 0.3584, lr_0 = 2.2673e-04
Loss = 4.7603e-05, PNorm = 47.2541, GNorm = 0.5020, lr_0 = 2.2643e-04
Loss = 4.3091e-05, PNorm = 47.2581, GNorm = 0.3481, lr_0 = 2.2612e-04
Loss = 4.5805e-05, PNorm = 47.2604, GNorm = 0.2032, lr_0 = 2.2582e-04
Validation rmse = 0.449197
Validation R2 = 0.942384
Epoch 65
Train function
Loss = 5.0434e-05, PNorm = 47.2620, GNorm = 0.4011, lr_0 = 2.2549e-04
Loss = 5.0160e-05, PNorm = 47.2656, GNorm = 0.1099, lr_0 = 2.2518e-04
Loss = 3.7527e-05, PNorm = 47.2694, GNorm = 0.1929, lr_0 = 2.2488e-04
Loss = 4.8934e-05, PNorm = 47.2716, GNorm = 0.1485, lr_0 = 2.2458e-04
Loss = 3.2202e-05, PNorm = 47.2728, GNorm = 0.1185, lr_0 = 2.2428e-04
Loss = 4.5027e-05, PNorm = 47.2754, GNorm = 0.0850, lr_0 = 2.2398e-04
Loss = 2.9873e-05, PNorm = 47.2772, GNorm = 0.1115, lr_0 = 2.2368e-04
Loss = 2.9458e-05, PNorm = 47.2778, GNorm = 0.1191, lr_0 = 2.2338e-04
Loss = 2.5682e-05, PNorm = 47.2804, GNorm = 0.0865, lr_0 = 2.2308e-04
Loss = 1.9149e-05, PNorm = 47.2827, GNorm = 0.1119, lr_0 = 2.2278e-04
Loss = 2.9100e-05, PNorm = 47.2859, GNorm = 0.0866, lr_0 = 2.2248e-04
Loss = 2.5007e-05, PNorm = 47.2894, GNorm = 0.0695, lr_0 = 2.2218e-04
Loss = 2.6985e-05, PNorm = 47.2910, GNorm = 0.0820, lr_0 = 2.2188e-04
Loss = 3.1273e-05, PNorm = 47.2917, GNorm = 0.1038, lr_0 = 2.2158e-04
Loss = 3.8652e-05, PNorm = 47.2934, GNorm = 0.2385, lr_0 = 2.2129e-04
Loss = 3.4565e-05, PNorm = 47.2983, GNorm = 0.0931, lr_0 = 2.2099e-04
Loss = 3.8446e-05, PNorm = 47.2994, GNorm = 0.1826, lr_0 = 2.2069e-04
Loss = 3.1215e-05, PNorm = 47.3026, GNorm = 0.0653, lr_0 = 2.2040e-04
Validation rmse = 0.450438
Validation R2 = 0.942065
Epoch 66
Train function
Loss = 3.4026e-05, PNorm = 47.3052, GNorm = 0.1102, lr_0 = 2.2010e-04
Loss = 2.7664e-05, PNorm = 47.3065, GNorm = 0.0714, lr_0 = 2.1981e-04
Loss = 2.3989e-05, PNorm = 47.3081, GNorm = 0.1743, lr_0 = 2.1951e-04
Loss = 2.8727e-05, PNorm = 47.3089, GNorm = 0.2264, lr_0 = 2.1922e-04
Loss = 3.5501e-05, PNorm = 47.3118, GNorm = 0.2395, lr_0 = 2.1892e-04
Loss = 3.3911e-05, PNorm = 47.3131, GNorm = 0.2672, lr_0 = 2.1863e-04
Loss = 3.1991e-05, PNorm = 47.3139, GNorm = 0.1678, lr_0 = 2.1834e-04
Loss = 3.4687e-05, PNorm = 47.3149, GNorm = 0.2063, lr_0 = 2.1804e-04
Loss = 3.4454e-05, PNorm = 47.3157, GNorm = 0.1583, lr_0 = 2.1775e-04
Loss = 3.1374e-05, PNorm = 47.3184, GNorm = 0.0580, lr_0 = 2.1746e-04
Loss = 3.5786e-05, PNorm = 47.3197, GNorm = 0.1380, lr_0 = 2.1717e-04
Loss = 3.6124e-05, PNorm = 47.3205, GNorm = 0.1350, lr_0 = 2.1688e-04
Loss = 3.1155e-05, PNorm = 47.3215, GNorm = 0.1428, lr_0 = 2.1658e-04
Loss = 2.7264e-05, PNorm = 47.3232, GNorm = 0.1437, lr_0 = 2.1629e-04
Loss = 3.0200e-05, PNorm = 47.3234, GNorm = 0.1759, lr_0 = 2.1600e-04
Loss = 2.9603e-05, PNorm = 47.3257, GNorm = 0.0957, lr_0 = 2.1571e-04
Loss = 3.1988e-05, PNorm = 47.3257, GNorm = 0.1642, lr_0 = 2.1542e-04
Validation rmse = 0.448713
Validation R2 = 0.942508
Epoch 67
Train function
Loss = 2.8869e-05, PNorm = 47.3256, GNorm = 0.1765, lr_0 = 2.1514e-04
Loss = 3.2704e-05, PNorm = 47.3266, GNorm = 0.0658, lr_0 = 2.1485e-04
Loss = 3.4385e-05, PNorm = 47.3306, GNorm = 0.0766, lr_0 = 2.1456e-04
Loss = 2.7592e-05, PNorm = 47.3340, GNorm = 0.0886, lr_0 = 2.1427e-04
Loss = 2.0586e-05, PNorm = 47.3352, GNorm = 0.1240, lr_0 = 2.1398e-04
Loss = 3.3294e-05, PNorm = 47.3366, GNorm = 0.0902, lr_0 = 2.1370e-04
Loss = 2.6238e-05, PNorm = 47.3405, GNorm = 0.1331, lr_0 = 2.1341e-04
Loss = 2.8166e-05, PNorm = 47.3419, GNorm = 0.0741, lr_0 = 2.1312e-04
Loss = 2.7851e-05, PNorm = 47.3438, GNorm = 0.1292, lr_0 = 2.1284e-04
Loss = 2.6793e-05, PNorm = 47.3457, GNorm = 0.1270, lr_0 = 2.1255e-04
Loss = 2.3502e-05, PNorm = 47.3465, GNorm = 0.0708, lr_0 = 2.1227e-04
Loss = 2.4863e-05, PNorm = 47.3468, GNorm = 0.0809, lr_0 = 2.1198e-04
Loss = 2.5246e-05, PNorm = 47.3487, GNorm = 0.1180, lr_0 = 2.1170e-04
Loss = 3.2066e-05, PNorm = 47.3515, GNorm = 0.0596, lr_0 = 2.1141e-04
Loss = 2.7462e-05, PNorm = 47.3523, GNorm = 0.1992, lr_0 = 2.1113e-04
Loss = 2.0753e-05, PNorm = 47.3520, GNorm = 0.0657, lr_0 = 2.1085e-04
Loss = 2.5856e-05, PNorm = 47.3547, GNorm = 0.1034, lr_0 = 2.1056e-04
Loss = 2.7604e-05, PNorm = 47.3579, GNorm = 0.0811, lr_0 = 2.1028e-04
Validation rmse = 0.447727
Validation R2 = 0.942760
Epoch 68
Train function
Loss = 3.7734e-05, PNorm = 47.3608, GNorm = 0.1159, lr_0 = 2.0997e-04
Loss = 2.5342e-05, PNorm = 47.3625, GNorm = 0.1061, lr_0 = 2.0969e-04
Loss = 2.3861e-05, PNorm = 47.3642, GNorm = 0.1039, lr_0 = 2.0941e-04
Loss = 2.5734e-05, PNorm = 47.3640, GNorm = 0.1719, lr_0 = 2.0913e-04
Loss = 2.6400e-05, PNorm = 47.3658, GNorm = 0.0964, lr_0 = 2.0885e-04
Loss = 2.5776e-05, PNorm = 47.3661, GNorm = 0.0976, lr_0 = 2.0857e-04
Loss = 2.8879e-05, PNorm = 47.3672, GNorm = 0.3027, lr_0 = 2.0829e-04
Loss = 3.3365e-05, PNorm = 47.3690, GNorm = 0.2143, lr_0 = 2.0801e-04
Loss = 2.0710e-05, PNorm = 47.3709, GNorm = 0.0978, lr_0 = 2.0773e-04
Loss = 2.2280e-05, PNorm = 47.3731, GNorm = 0.0898, lr_0 = 2.0745e-04
Loss = 3.2199e-05, PNorm = 47.3748, GNorm = 0.1967, lr_0 = 2.0717e-04
Loss = 3.4187e-05, PNorm = 47.3772, GNorm = 0.0998, lr_0 = 2.0689e-04
Loss = 2.2929e-05, PNorm = 47.3791, GNorm = 0.1476, lr_0 = 2.0661e-04
Loss = 2.6125e-05, PNorm = 47.3811, GNorm = 0.0862, lr_0 = 2.0634e-04
Loss = 2.8849e-05, PNorm = 47.3834, GNorm = 0.1096, lr_0 = 2.0606e-04
Loss = 3.0986e-05, PNorm = 47.3868, GNorm = 0.0875, lr_0 = 2.0578e-04
Loss = 3.0063e-05, PNorm = 47.3898, GNorm = 0.0515, lr_0 = 2.0551e-04
Loss = 1.9940e-05, PNorm = 47.3930, GNorm = 0.0839, lr_0 = 2.0523e-04
Validation rmse = 0.448701
Validation R2 = 0.942511
Epoch 69
Train function
Loss = 2.1529e-05, PNorm = 47.3955, GNorm = 0.1508, lr_0 = 2.0496e-04
Loss = 2.4099e-05, PNorm = 47.3960, GNorm = 0.2148, lr_0 = 2.0468e-04
Loss = 2.3542e-05, PNorm = 47.3969, GNorm = 0.0935, lr_0 = 2.0441e-04
Loss = 2.9734e-05, PNorm = 47.3972, GNorm = 0.0985, lr_0 = 2.0413e-04
Loss = 2.5658e-05, PNorm = 47.3967, GNorm = 0.0896, lr_0 = 2.0386e-04
Loss = 3.0243e-05, PNorm = 47.3985, GNorm = 0.1259, lr_0 = 2.0359e-04
Loss = 3.9550e-05, PNorm = 47.4020, GNorm = 0.1265, lr_0 = 2.0331e-04
Loss = 3.6778e-05, PNorm = 47.4037, GNorm = 0.1019, lr_0 = 2.0304e-04
Loss = 2.8124e-05, PNorm = 47.4051, GNorm = 0.1239, lr_0 = 2.0277e-04
Loss = 2.5289e-05, PNorm = 47.4076, GNorm = 0.1812, lr_0 = 2.0249e-04
Loss = 3.2147e-05, PNorm = 47.4096, GNorm = 0.0997, lr_0 = 2.0222e-04
Loss = 3.1054e-05, PNorm = 47.4114, GNorm = 0.0995, lr_0 = 2.0195e-04
Loss = 3.7820e-05, PNorm = 47.4131, GNorm = 0.1129, lr_0 = 2.0168e-04
Loss = 3.9865e-05, PNorm = 47.4139, GNorm = 0.2430, lr_0 = 2.0141e-04
Loss = 4.1414e-05, PNorm = 47.4143, GNorm = 0.2812, lr_0 = 2.0114e-04
Loss = 3.7679e-05, PNorm = 47.4158, GNorm = 0.1627, lr_0 = 2.0087e-04
Loss = 4.1745e-05, PNorm = 47.4173, GNorm = 0.1603, lr_0 = 2.0060e-04
Validation rmse = 0.455741
Validation R2 = 0.940693
Epoch 70
Train function
Loss = 5.3384e-05, PNorm = 47.4198, GNorm = 0.1815, lr_0 = 2.0033e-04
Loss = 4.1580e-05, PNorm = 47.4218, GNorm = 0.1305, lr_0 = 2.0006e-04
Loss = 3.0115e-05, PNorm = 47.4237, GNorm = 0.0947, lr_0 = 1.9979e-04
Loss = 3.3653e-05, PNorm = 47.4230, GNorm = 0.2031, lr_0 = 1.9953e-04
Loss = 3.1992e-05, PNorm = 47.4269, GNorm = 0.1249, lr_0 = 1.9926e-04
Loss = 3.6896e-05, PNorm = 47.4288, GNorm = 0.1092, lr_0 = 1.9899e-04
Loss = 3.2290e-05, PNorm = 47.4313, GNorm = 0.0791, lr_0 = 1.9872e-04
Loss = 2.9487e-05, PNorm = 47.4341, GNorm = 0.1180, lr_0 = 1.9846e-04
Loss = 3.4268e-05, PNorm = 47.4363, GNorm = 0.1234, lr_0 = 1.9819e-04
Loss = 3.2634e-05, PNorm = 47.4386, GNorm = 0.2647, lr_0 = 1.9793e-04
Loss = 3.1895e-05, PNorm = 47.4418, GNorm = 0.2090, lr_0 = 1.9766e-04
Loss = 3.3715e-05, PNorm = 47.4460, GNorm = 0.1157, lr_0 = 1.9739e-04
Loss = 3.5135e-05, PNorm = 47.4489, GNorm = 0.3570, lr_0 = 1.9713e-04
Loss = 3.2466e-05, PNorm = 47.4519, GNorm = 0.0863, lr_0 = 1.9687e-04
Loss = 2.7613e-05, PNorm = 47.4545, GNorm = 0.0652, lr_0 = 1.9660e-04
Loss = 3.3188e-05, PNorm = 47.4577, GNorm = 0.2838, lr_0 = 1.9634e-04
Loss = 4.0747e-05, PNorm = 47.4606, GNorm = 0.2402, lr_0 = 1.9607e-04
Loss = 4.0614e-05, PNorm = 47.4623, GNorm = 0.2142, lr_0 = 1.9581e-04
Validation rmse = 0.451014
Validation R2 = 0.941917
Epoch 71
Train function
Loss = 3.5210e-05, PNorm = 47.4672, GNorm = 0.1243, lr_0 = 1.9552e-04
Loss = 2.9912e-05, PNorm = 47.4685, GNorm = 0.0951, lr_0 = 1.9526e-04
Loss = 2.6130e-05, PNorm = 47.4691, GNorm = 0.0894, lr_0 = 1.9500e-04
Loss = 2.5938e-05, PNorm = 47.4705, GNorm = 0.1695, lr_0 = 1.9474e-04
Loss = 3.5052e-05, PNorm = 47.4729, GNorm = 0.3034, lr_0 = 1.9447e-04
Loss = 3.8449e-05, PNorm = 47.4753, GNorm = 0.0980, lr_0 = 1.9421e-04
Loss = 2.6300e-05, PNorm = 47.4762, GNorm = 0.0948, lr_0 = 1.9395e-04
Loss = 2.7728e-05, PNorm = 47.4761, GNorm = 0.1147, lr_0 = 1.9369e-04
Loss = 2.9944e-05, PNorm = 47.4783, GNorm = 0.2241, lr_0 = 1.9343e-04
Loss = 2.2423e-05, PNorm = 47.4794, GNorm = 0.0653, lr_0 = 1.9317e-04
Loss = 3.1964e-05, PNorm = 47.4798, GNorm = 0.3081, lr_0 = 1.9291e-04
Loss = 2.4513e-05, PNorm = 47.4827, GNorm = 0.1055, lr_0 = 1.9266e-04
Loss = 2.5224e-05, PNorm = 47.4852, GNorm = 0.0605, lr_0 = 1.9240e-04
Loss = 2.2386e-05, PNorm = 47.4863, GNorm = 0.1034, lr_0 = 1.9214e-04
Loss = 2.1033e-05, PNorm = 47.4883, GNorm = 0.0963, lr_0 = 1.9188e-04
Loss = 2.4374e-05, PNorm = 47.4914, GNorm = 0.1139, lr_0 = 1.9162e-04
Loss = 3.1073e-05, PNorm = 47.4944, GNorm = 0.1278, lr_0 = 1.9137e-04
Validation rmse = 0.446992
Validation R2 = 0.942948
Epoch 72
Train function
Loss = 2.3106e-05, PNorm = 47.4971, GNorm = 0.0959, lr_0 = 1.9111e-04
Loss = 1.9979e-05, PNorm = 47.4960, GNorm = 0.0720, lr_0 = 1.9085e-04
Loss = 1.9729e-05, PNorm = 47.4966, GNorm = 0.1522, lr_0 = 1.9060e-04
Loss = 2.1537e-05, PNorm = 47.4979, GNorm = 0.0879, lr_0 = 1.9034e-04
Loss = 2.2050e-05, PNorm = 47.4989, GNorm = 0.1241, lr_0 = 1.9009e-04
Loss = 2.1796e-05, PNorm = 47.4998, GNorm = 0.0649, lr_0 = 1.8983e-04
Loss = 3.1787e-05, PNorm = 47.5006, GNorm = 0.1422, lr_0 = 1.8958e-04
Loss = 3.3176e-05, PNorm = 47.5011, GNorm = 0.2616, lr_0 = 1.8932e-04
Loss = 3.4045e-05, PNorm = 47.5029, GNorm = 0.1021, lr_0 = 1.8907e-04
Loss = 2.0717e-05, PNorm = 47.5042, GNorm = 0.0739, lr_0 = 1.8881e-04
Loss = 2.1173e-05, PNorm = 47.5065, GNorm = 0.0936, lr_0 = 1.8856e-04
Loss = 2.2451e-05, PNorm = 47.5093, GNorm = 0.0716, lr_0 = 1.8831e-04
Loss = 2.0405e-05, PNorm = 47.5109, GNorm = 0.1432, lr_0 = 1.8806e-04
Loss = 2.5069e-05, PNorm = 47.5124, GNorm = 0.0984, lr_0 = 1.8780e-04
Loss = 3.0818e-05, PNorm = 47.5134, GNorm = 0.1453, lr_0 = 1.8755e-04
Loss = 2.4168e-05, PNorm = 47.5163, GNorm = 0.1037, lr_0 = 1.8730e-04
Loss = 2.5094e-05, PNorm = 47.5184, GNorm = 0.0862, lr_0 = 1.8705e-04
Loss = 1.9846e-05, PNorm = 47.5205, GNorm = 0.0767, lr_0 = 1.8680e-04
Validation rmse = 0.447533
Validation R2 = 0.942810
Epoch 73
Train function
Loss = 2.1603e-05, PNorm = 47.5215, GNorm = 0.1611, lr_0 = 1.8655e-04
Loss = 1.8562e-05, PNorm = 47.5212, GNorm = 0.0861, lr_0 = 1.8630e-04
Loss = 1.9985e-05, PNorm = 47.5228, GNorm = 0.0803, lr_0 = 1.8605e-04
Loss = 1.8827e-05, PNorm = 47.5235, GNorm = 0.2114, lr_0 = 1.8580e-04
Loss = 2.7737e-05, PNorm = 47.5244, GNorm = 0.0900, lr_0 = 1.8555e-04
Loss = 3.4586e-05, PNorm = 47.5274, GNorm = 0.1246, lr_0 = 1.8530e-04
Loss = 3.1090e-05, PNorm = 47.5308, GNorm = 0.1197, lr_0 = 1.8505e-04
Loss = 2.8385e-05, PNorm = 47.5317, GNorm = 0.2079, lr_0 = 1.8480e-04
Loss = 2.7789e-05, PNorm = 47.5318, GNorm = 0.1032, lr_0 = 1.8455e-04
Loss = 2.7790e-05, PNorm = 47.5351, GNorm = 0.1288, lr_0 = 1.8431e-04
Loss = 3.4583e-05, PNorm = 47.5362, GNorm = 0.0690, lr_0 = 1.8406e-04
Loss = 2.0845e-05, PNorm = 47.5369, GNorm = 0.0981, lr_0 = 1.8381e-04
Loss = 2.1846e-05, PNorm = 47.5387, GNorm = 0.0646, lr_0 = 1.8357e-04
Loss = 2.3886e-05, PNorm = 47.5412, GNorm = 0.2040, lr_0 = 1.8332e-04
Loss = 2.4311e-05, PNorm = 47.5437, GNorm = 0.0982, lr_0 = 1.8307e-04
Loss = 2.4469e-05, PNorm = 47.5459, GNorm = 0.0600, lr_0 = 1.8283e-04
Loss = 1.9765e-05, PNorm = 47.5482, GNorm = 0.0802, lr_0 = 1.8258e-04
Validation rmse = 0.449710
Validation R2 = 0.942252
Epoch 74
Train function
Loss = 1.5487e-05, PNorm = 47.5481, GNorm = 0.1265, lr_0 = 1.8231e-04
Loss = 1.8071e-05, PNorm = 47.5493, GNorm = 0.0596, lr_0 = 1.8207e-04
Loss = 1.7794e-05, PNorm = 47.5500, GNorm = 0.0857, lr_0 = 1.8182e-04
Loss = 1.8560e-05, PNorm = 47.5506, GNorm = 0.1104, lr_0 = 1.8158e-04
Loss = 1.5999e-05, PNorm = 47.5504, GNorm = 0.0607, lr_0 = 1.8134e-04
Loss = 1.5638e-05, PNorm = 47.5508, GNorm = 0.0759, lr_0 = 1.8109e-04
Loss = 1.9482e-05, PNorm = 47.5523, GNorm = 0.2868, lr_0 = 1.8085e-04
Loss = 2.9256e-05, PNorm = 47.5522, GNorm = 0.2662, lr_0 = 1.8061e-04
Loss = 2.5713e-05, PNorm = 47.5537, GNorm = 0.1225, lr_0 = 1.8036e-04
Loss = 2.5760e-05, PNorm = 47.5549, GNorm = 0.0673, lr_0 = 1.8012e-04
Loss = 2.3623e-05, PNorm = 47.5566, GNorm = 0.1645, lr_0 = 1.7988e-04
Loss = 2.3205e-05, PNorm = 47.5582, GNorm = 0.1343, lr_0 = 1.7964e-04
Loss = 2.2124e-05, PNorm = 47.5608, GNorm = 0.0856, lr_0 = 1.7940e-04
Loss = 2.1352e-05, PNorm = 47.5608, GNorm = 0.0929, lr_0 = 1.7916e-04
Loss = 2.9458e-05, PNorm = 47.5624, GNorm = 0.1908, lr_0 = 1.7892e-04
Loss = 1.9623e-05, PNorm = 47.5661, GNorm = 0.1915, lr_0 = 1.7868e-04
Loss = 2.4964e-05, PNorm = 47.5679, GNorm = 0.1625, lr_0 = 1.7844e-04
Loss = 2.5425e-05, PNorm = 47.5712, GNorm = 0.0879, lr_0 = 1.7820e-04
Validation rmse = 0.450119
Validation R2 = 0.942147
Epoch 75
Train function
Loss = 2.2269e-05, PNorm = 47.5728, GNorm = 0.1000, lr_0 = 1.7796e-04
Loss = 1.8892e-05, PNorm = 47.5725, GNorm = 0.0738, lr_0 = 1.7772e-04
Loss = 2.3426e-05, PNorm = 47.5726, GNorm = 0.1741, lr_0 = 1.7748e-04
Loss = 1.8142e-05, PNorm = 47.5735, GNorm = 0.1438, lr_0 = 1.7724e-04
Loss = 2.2166e-05, PNorm = 47.5729, GNorm = 0.0818, lr_0 = 1.7701e-04
Loss = 1.4595e-05, PNorm = 47.5742, GNorm = 0.0622, lr_0 = 1.7677e-04
Loss = 1.8659e-05, PNorm = 47.5747, GNorm = 0.1175, lr_0 = 1.7653e-04
Loss = 1.5871e-05, PNorm = 47.5761, GNorm = 0.0887, lr_0 = 1.7629e-04
Loss = 1.8098e-05, PNorm = 47.5776, GNorm = 0.1207, lr_0 = 1.7606e-04
Loss = 2.6281e-05, PNorm = 47.5790, GNorm = 0.1045, lr_0 = 1.7582e-04
Loss = 2.0173e-05, PNorm = 47.5792, GNorm = 0.0819, lr_0 = 1.7559e-04
Loss = 3.0914e-05, PNorm = 47.5810, GNorm = 0.1045, lr_0 = 1.7535e-04
Loss = 2.4544e-05, PNorm = 47.5835, GNorm = 0.0772, lr_0 = 1.7512e-04
Loss = 2.5264e-05, PNorm = 47.5863, GNorm = 0.1081, lr_0 = 1.7488e-04
Loss = 2.7078e-05, PNorm = 47.5891, GNorm = 0.1105, lr_0 = 1.7465e-04
Loss = 2.3718e-05, PNorm = 47.5902, GNorm = 0.0897, lr_0 = 1.7441e-04
Loss = 1.9389e-05, PNorm = 47.5912, GNorm = 0.0895, lr_0 = 1.7418e-04
Loss = 2.0014e-05, PNorm = 47.5931, GNorm = 0.1240, lr_0 = 1.7394e-04
Validation rmse = 0.449327
Validation R2 = 0.942351
Epoch 76
Train function
Loss = 2.3477e-05, PNorm = 47.5939, GNorm = 0.2172, lr_0 = 1.7371e-04
Loss = 2.2336e-05, PNorm = 47.5950, GNorm = 0.1560, lr_0 = 1.7348e-04
Loss = 2.7801e-05, PNorm = 47.5971, GNorm = 0.3135, lr_0 = 1.7324e-04
Loss = 1.8351e-05, PNorm = 47.5975, GNorm = 0.0573, lr_0 = 1.7301e-04
Loss = 1.4905e-05, PNorm = 47.5986, GNorm = 0.0597, lr_0 = 1.7278e-04
Loss = 2.0423e-05, PNorm = 47.6020, GNorm = 0.1011, lr_0 = 1.7255e-04
Loss = 2.4693e-05, PNorm = 47.6042, GNorm = 0.1636, lr_0 = 1.7232e-04
Loss = 1.7041e-05, PNorm = 47.6044, GNorm = 0.1331, lr_0 = 1.7209e-04
Loss = 1.4586e-05, PNorm = 47.6047, GNorm = 0.1126, lr_0 = 1.7185e-04
Loss = 1.5833e-05, PNorm = 47.6057, GNorm = 0.1307, lr_0 = 1.7162e-04
Loss = 2.2436e-05, PNorm = 47.6067, GNorm = 0.1544, lr_0 = 1.7139e-04
Loss = 1.6964e-05, PNorm = 47.6085, GNorm = 0.0687, lr_0 = 1.7116e-04
Loss = 1.6643e-05, PNorm = 47.6098, GNorm = 0.1223, lr_0 = 1.7093e-04
Loss = 2.1043e-05, PNorm = 47.6101, GNorm = 0.1045, lr_0 = 1.7070e-04
Loss = 1.8836e-05, PNorm = 47.6129, GNorm = 0.1457, lr_0 = 1.7048e-04
Loss = 1.9347e-05, PNorm = 47.6143, GNorm = 0.1155, lr_0 = 1.7025e-04
Loss = 1.8469e-05, PNorm = 47.6148, GNorm = 0.0688, lr_0 = 1.7002e-04
Validation rmse = 0.450101
Validation R2 = 0.942152
Epoch 77
Train function
Loss = 1.5756e-05, PNorm = 47.6143, GNorm = 0.0713, lr_0 = 1.6977e-04
Loss = 2.0154e-05, PNorm = 47.6150, GNorm = 0.1077, lr_0 = 1.6954e-04
Loss = 2.2271e-05, PNorm = 47.6160, GNorm = 0.1105, lr_0 = 1.6931e-04
Loss = 2.1047e-05, PNorm = 47.6183, GNorm = 0.1379, lr_0 = 1.6908e-04
Loss = 2.6105e-05, PNorm = 47.6191, GNorm = 0.0648, lr_0 = 1.6886e-04
Loss = 2.8495e-05, PNorm = 47.6194, GNorm = 0.1095, lr_0 = 1.6863e-04
Loss = 2.4225e-05, PNorm = 47.6228, GNorm = 0.1281, lr_0 = 1.6841e-04
Loss = 1.8535e-05, PNorm = 47.6266, GNorm = 0.0751, lr_0 = 1.6818e-04
Loss = 2.6914e-05, PNorm = 47.6274, GNorm = 0.2755, lr_0 = 1.6795e-04
Loss = 3.4163e-05, PNorm = 47.6292, GNorm = 0.0933, lr_0 = 1.6773e-04
Loss = 3.1524e-05, PNorm = 47.6296, GNorm = 0.1068, lr_0 = 1.6750e-04
Loss = 2.4157e-05, PNorm = 47.6310, GNorm = 0.1023, lr_0 = 1.6728e-04
Loss = 1.7946e-05, PNorm = 47.6321, GNorm = 0.0750, lr_0 = 1.6705e-04
Loss = 1.7379e-05, PNorm = 47.6337, GNorm = 0.0655, lr_0 = 1.6683e-04
Loss = 1.7426e-05, PNorm = 47.6349, GNorm = 0.1226, lr_0 = 1.6661e-04
Loss = 1.5440e-05, PNorm = 47.6373, GNorm = 0.1125, lr_0 = 1.6638e-04
Loss = 3.2829e-05, PNorm = 47.6389, GNorm = 0.1387, lr_0 = 1.6616e-04
Loss = 3.3645e-05, PNorm = 47.6406, GNorm = 0.2273, lr_0 = 1.6594e-04
Validation rmse = 0.456333
Validation R2 = 0.940539
Epoch 78
Train function
Loss = 3.3593e-05, PNorm = 47.6401, GNorm = 0.2999, lr_0 = 1.6571e-04
Loss = 2.9258e-05, PNorm = 47.6415, GNorm = 0.0731, lr_0 = 1.6549e-04
Loss = 1.9901e-05, PNorm = 47.6446, GNorm = 0.1647, lr_0 = 1.6527e-04
Loss = 2.4054e-05, PNorm = 47.6473, GNorm = 0.2560, lr_0 = 1.6505e-04
Loss = 1.7877e-05, PNorm = 47.6485, GNorm = 0.0737, lr_0 = 1.6483e-04
Loss = 1.7244e-05, PNorm = 47.6497, GNorm = 0.0669, lr_0 = 1.6461e-04
Loss = 2.0026e-05, PNorm = 47.6492, GNorm = 0.0745, lr_0 = 1.6438e-04
Loss = 2.6304e-05, PNorm = 47.6498, GNorm = 0.1915, lr_0 = 1.6416e-04
Loss = 2.5529e-05, PNorm = 47.6522, GNorm = 0.1097, lr_0 = 1.6394e-04
Loss = 2.6651e-05, PNorm = 47.6539, GNorm = 0.1606, lr_0 = 1.6372e-04
Loss = 2.2388e-05, PNorm = 47.6568, GNorm = 0.0910, lr_0 = 1.6350e-04
Loss = 3.0069e-05, PNorm = 47.6575, GNorm = 0.0743, lr_0 = 1.6328e-04
Loss = 2.7661e-05, PNorm = 47.6601, GNorm = 0.1540, lr_0 = 1.6307e-04
Loss = 2.9405e-05, PNorm = 47.6624, GNorm = 0.2074, lr_0 = 1.6285e-04
Loss = 2.6750e-05, PNorm = 47.6632, GNorm = 0.1788, lr_0 = 1.6263e-04
Loss = 2.4253e-05, PNorm = 47.6653, GNorm = 0.1036, lr_0 = 1.6241e-04
Loss = 2.7153e-05, PNorm = 47.6663, GNorm = 0.1257, lr_0 = 1.6219e-04
Validation rmse = 0.450162
Validation R2 = 0.942136
Epoch 79
Train function
Loss = 2.6567e-05, PNorm = 47.6669, GNorm = 0.1661, lr_0 = 1.6197e-04
Loss = 2.3074e-05, PNorm = 47.6681, GNorm = 0.1079, lr_0 = 1.6176e-04
Loss = 1.9786e-05, PNorm = 47.6680, GNorm = 0.0738, lr_0 = 1.6154e-04
Loss = 1.9236e-05, PNorm = 47.6682, GNorm = 0.0644, lr_0 = 1.6132e-04
Loss = 1.4422e-05, PNorm = 47.6692, GNorm = 0.0844, lr_0 = 1.6111e-04
Loss = 1.3357e-05, PNorm = 47.6689, GNorm = 0.1021, lr_0 = 1.6089e-04
Loss = 1.6636e-05, PNorm = 47.6698, GNorm = 0.0833, lr_0 = 1.6067e-04
Loss = 2.6250e-05, PNorm = 47.6730, GNorm = 0.0819, lr_0 = 1.6046e-04
Loss = 1.6711e-05, PNorm = 47.6744, GNorm = 0.0647, lr_0 = 1.6024e-04
Loss = 2.1411e-05, PNorm = 47.6755, GNorm = 0.2273, lr_0 = 1.6003e-04
Loss = 2.1722e-05, PNorm = 47.6770, GNorm = 0.0604, lr_0 = 1.5981e-04
Loss = 2.5589e-05, PNorm = 47.6773, GNorm = 0.2191, lr_0 = 1.5960e-04
Loss = 2.0181e-05, PNorm = 47.6788, GNorm = 0.0988, lr_0 = 1.5939e-04
Loss = 1.9480e-05, PNorm = 47.6797, GNorm = 0.0840, lr_0 = 1.5917e-04
Loss = 2.0009e-05, PNorm = 47.6813, GNorm = 0.1019, lr_0 = 1.5896e-04
Loss = 2.2761e-05, PNorm = 47.6817, GNorm = 0.0696, lr_0 = 1.5874e-04
Loss = 2.5145e-05, PNorm = 47.6827, GNorm = 0.0753, lr_0 = 1.5853e-04
Loss = 2.1334e-05, PNorm = 47.6840, GNorm = 0.0838, lr_0 = 1.5832e-04
Validation rmse = 0.449943
Validation R2 = 0.942192
Epoch 80
Train function
Loss = 1.9201e-05, PNorm = 47.6857, GNorm = 0.0754, lr_0 = 1.5809e-04
Loss = 1.4952e-05, PNorm = 47.6873, GNorm = 0.0711, lr_0 = 1.5787e-04
Loss = 1.4344e-05, PNorm = 47.6881, GNorm = 0.0588, lr_0 = 1.5766e-04
Loss = 1.5248e-05, PNorm = 47.6890, GNorm = 0.0482, lr_0 = 1.5745e-04
Loss = 1.4137e-05, PNorm = 47.6893, GNorm = 0.0870, lr_0 = 1.5724e-04
Loss = 1.3354e-05, PNorm = 47.6916, GNorm = 0.0733, lr_0 = 1.5703e-04
Loss = 1.9156e-05, PNorm = 47.6928, GNorm = 0.0542, lr_0 = 1.5682e-04
Loss = 1.5204e-05, PNorm = 47.6927, GNorm = 0.1172, lr_0 = 1.5661e-04
Loss = 1.6352e-05, PNorm = 47.6937, GNorm = 0.0965, lr_0 = 1.5640e-04
Loss = 1.6533e-05, PNorm = 47.6938, GNorm = 0.1443, lr_0 = 1.5619e-04
Loss = 1.6075e-05, PNorm = 47.6947, GNorm = 0.0741, lr_0 = 1.5598e-04
Loss = 1.5603e-05, PNorm = 47.6951, GNorm = 0.0913, lr_0 = 1.5577e-04
Loss = 1.4553e-05, PNorm = 47.6963, GNorm = 0.0637, lr_0 = 1.5556e-04
Loss = 1.9202e-05, PNorm = 47.6967, GNorm = 0.0774, lr_0 = 1.5535e-04
Loss = 1.7105e-05, PNorm = 47.6981, GNorm = 0.0757, lr_0 = 1.5514e-04
Loss = 1.4088e-05, PNorm = 47.7002, GNorm = 0.1318, lr_0 = 1.5493e-04
Loss = 1.4305e-05, PNorm = 47.7010, GNorm = 0.0781, lr_0 = 1.5473e-04
Validation rmse = 0.449744
Validation R2 = 0.942244
Epoch 81
Train function
Loss = 1.1824e-05, PNorm = 47.7017, GNorm = 0.0678, lr_0 = 1.5452e-04
Loss = 1.9219e-05, PNorm = 47.7033, GNorm = 0.0620, lr_0 = 1.5431e-04
Loss = 1.3283e-05, PNorm = 47.7048, GNorm = 0.0502, lr_0 = 1.5410e-04
Loss = 1.4459e-05, PNorm = 47.7057, GNorm = 0.0829, lr_0 = 1.5390e-04
Loss = 1.2075e-05, PNorm = 47.7071, GNorm = 0.0786, lr_0 = 1.5369e-04
Loss = 1.1202e-05, PNorm = 47.7090, GNorm = 0.1318, lr_0 = 1.5348e-04
Loss = 1.2308e-05, PNorm = 47.7100, GNorm = 0.0740, lr_0 = 1.5328e-04
Loss = 1.4662e-05, PNorm = 47.7101, GNorm = 0.0717, lr_0 = 1.5307e-04
Loss = 1.3428e-05, PNorm = 47.7110, GNorm = 0.0817, lr_0 = 1.5287e-04
Loss = 1.5446e-05, PNorm = 47.7108, GNorm = 0.1322, lr_0 = 1.5266e-04
Loss = 1.2318e-05, PNorm = 47.7118, GNorm = 0.0534, lr_0 = 1.5246e-04
Loss = 1.2456e-05, PNorm = 47.7129, GNorm = 0.1050, lr_0 = 1.5225e-04
Loss = 1.0962e-05, PNorm = 47.7142, GNorm = 0.0618, lr_0 = 1.5205e-04
Loss = 1.2051e-05, PNorm = 47.7153, GNorm = 0.0945, lr_0 = 1.5184e-04
Loss = 1.3695e-05, PNorm = 47.7143, GNorm = 0.0656, lr_0 = 1.5164e-04
Loss = 9.5296e-06, PNorm = 47.7151, GNorm = 0.0679, lr_0 = 1.5144e-04
Loss = 1.2015e-05, PNorm = 47.7167, GNorm = 0.0930, lr_0 = 1.5123e-04
Loss = 1.8330e-05, PNorm = 47.7190, GNorm = 0.0630, lr_0 = 1.5103e-04
Validation rmse = 0.449739
Validation R2 = 0.942245
Epoch 82
Train function
Loss = 1.0965e-05, PNorm = 47.7189, GNorm = 0.0471, lr_0 = 1.5083e-04
Loss = 1.3232e-05, PNorm = 47.7208, GNorm = 0.0706, lr_0 = 1.5063e-04
Loss = 1.8175e-05, PNorm = 47.7221, GNorm = 0.1266, lr_0 = 1.5042e-04
Loss = 1.3113e-05, PNorm = 47.7231, GNorm = 0.1666, lr_0 = 1.5022e-04
Loss = 1.2043e-05, PNorm = 47.7250, GNorm = 0.0839, lr_0 = 1.5002e-04
Loss = 9.6163e-06, PNorm = 47.7255, GNorm = 0.0564, lr_0 = 1.4982e-04
Loss = 1.1682e-05, PNorm = 47.7266, GNorm = 0.0574, lr_0 = 1.4962e-04
Loss = 1.5701e-05, PNorm = 47.7280, GNorm = 0.1082, lr_0 = 1.4942e-04
Loss = 1.1728e-05, PNorm = 47.7300, GNorm = 0.1205, lr_0 = 1.4922e-04
Loss = 2.1837e-05, PNorm = 47.7308, GNorm = 0.2858, lr_0 = 1.4902e-04
Loss = 2.1200e-05, PNorm = 47.7314, GNorm = 0.1705, lr_0 = 1.4882e-04
Loss = 1.6520e-05, PNorm = 47.7322, GNorm = 0.1496, lr_0 = 1.4862e-04
Loss = 2.0758e-05, PNorm = 47.7317, GNorm = 0.0878, lr_0 = 1.4842e-04
Loss = 2.5285e-05, PNorm = 47.7331, GNorm = 0.0843, lr_0 = 1.4822e-04
Loss = 1.8220e-05, PNorm = 47.7333, GNorm = 0.1093, lr_0 = 1.4802e-04
Loss = 1.7920e-05, PNorm = 47.7340, GNorm = 0.0776, lr_0 = 1.4782e-04
Loss = 1.3760e-05, PNorm = 47.7355, GNorm = 0.0425, lr_0 = 1.4762e-04
Validation rmse = 0.448815
Validation R2 = 0.942482
Epoch 83
Train function
Loss = 8.3884e-06, PNorm = 47.7377, GNorm = 0.0671, lr_0 = 1.4741e-04
Loss = 1.3231e-05, PNorm = 47.7383, GNorm = 0.0554, lr_0 = 1.4721e-04
Loss = 1.3115e-05, PNorm = 47.7396, GNorm = 0.0832, lr_0 = 1.4701e-04
Loss = 1.3128e-05, PNorm = 47.7410, GNorm = 0.1696, lr_0 = 1.4681e-04
Loss = 1.3495e-05, PNorm = 47.7410, GNorm = 0.0565, lr_0 = 1.4662e-04
Loss = 9.6130e-06, PNorm = 47.7415, GNorm = 0.0399, lr_0 = 1.4642e-04
Loss = 9.6851e-06, PNorm = 47.7431, GNorm = 0.0477, lr_0 = 1.4622e-04
Loss = 1.5541e-05, PNorm = 47.7439, GNorm = 0.1038, lr_0 = 1.4603e-04
Loss = 1.4854e-05, PNorm = 47.7458, GNorm = 0.1339, lr_0 = 1.4583e-04
Loss = 1.4641e-05, PNorm = 47.7469, GNorm = 0.1175, lr_0 = 1.4563e-04
Loss = 1.2156e-05, PNorm = 47.7478, GNorm = 0.0849, lr_0 = 1.4544e-04
Loss = 1.8491e-05, PNorm = 47.7482, GNorm = 0.0746, lr_0 = 1.4524e-04
Loss = 1.4819e-05, PNorm = 47.7482, GNorm = 0.0955, lr_0 = 1.4505e-04
Loss = 1.7092e-05, PNorm = 47.7494, GNorm = 0.0565, lr_0 = 1.4485e-04
Loss = 1.3550e-05, PNorm = 47.7498, GNorm = 0.0836, lr_0 = 1.4466e-04
Loss = 1.5487e-05, PNorm = 47.7506, GNorm = 0.0826, lr_0 = 1.4447e-04
Loss = 1.8173e-05, PNorm = 47.7513, GNorm = 0.2063, lr_0 = 1.4427e-04
Loss = 3.0131e-05, PNorm = 47.7525, GNorm = 0.1281, lr_0 = 1.4408e-04
Validation rmse = 0.450621
Validation R2 = 0.942018
Epoch 84
Train function
Loss = 1.9977e-05, PNorm = 47.7543, GNorm = 0.1596, lr_0 = 1.4389e-04
Loss = 1.6795e-05, PNorm = 47.7559, GNorm = 0.1507, lr_0 = 1.4369e-04
Loss = 1.7521e-05, PNorm = 47.7571, GNorm = 0.0597, lr_0 = 1.4350e-04
Loss = 1.2449e-05, PNorm = 47.7581, GNorm = 0.0925, lr_0 = 1.4331e-04
Loss = 1.8654e-05, PNorm = 47.7582, GNorm = 0.0928, lr_0 = 1.4311e-04
Loss = 1.1527e-05, PNorm = 47.7599, GNorm = 0.1443, lr_0 = 1.4292e-04
Loss = 1.1039e-05, PNorm = 47.7608, GNorm = 0.0731, lr_0 = 1.4273e-04
Loss = 1.1220e-05, PNorm = 47.7614, GNorm = 0.0845, lr_0 = 1.4254e-04
Loss = 9.4933e-06, PNorm = 47.7627, GNorm = 0.0871, lr_0 = 1.4235e-04
Loss = 2.0229e-05, PNorm = 47.7632, GNorm = 0.0787, lr_0 = 1.4216e-04
Loss = 1.3775e-05, PNorm = 47.7652, GNorm = 0.1144, lr_0 = 1.4197e-04
Loss = 1.4169e-05, PNorm = 47.7669, GNorm = 0.1330, lr_0 = 1.4178e-04
Loss = 1.9283e-05, PNorm = 47.7684, GNorm = 0.0631, lr_0 = 1.4159e-04
Loss = 1.3079e-05, PNorm = 47.7707, GNorm = 0.0618, lr_0 = 1.4140e-04
Loss = 1.3999e-05, PNorm = 47.7718, GNorm = 0.1332, lr_0 = 1.4121e-04
Loss = 1.7147e-05, PNorm = 47.7720, GNorm = 0.0625, lr_0 = 1.4102e-04
Loss = 1.1706e-05, PNorm = 47.7727, GNorm = 0.0625, lr_0 = 1.4083e-04
Loss = 1.1584e-05, PNorm = 47.7731, GNorm = 0.0596, lr_0 = 1.4064e-04
Validation rmse = 0.449137
Validation R2 = 0.942399
Epoch 85
Train function
Loss = 8.8226e-06, PNorm = 47.7734, GNorm = 0.0563, lr_0 = 1.4045e-04
Loss = 1.4651e-05, PNorm = 47.7745, GNorm = 0.2091, lr_0 = 1.4026e-04
Loss = 1.6656e-05, PNorm = 47.7754, GNorm = 0.1681, lr_0 = 1.4007e-04
Loss = 1.7423e-05, PNorm = 47.7750, GNorm = 0.1683, lr_0 = 1.3989e-04
Loss = 2.0403e-05, PNorm = 47.7753, GNorm = 0.0781, lr_0 = 1.3970e-04
Loss = 1.4723e-05, PNorm = 47.7755, GNorm = 0.0565, lr_0 = 1.3951e-04
Loss = 1.5038e-05, PNorm = 47.7773, GNorm = 0.1282, lr_0 = 1.3932e-04
Loss = 1.1927e-05, PNorm = 47.7774, GNorm = 0.0582, lr_0 = 1.3914e-04
Loss = 1.3654e-05, PNorm = 47.7778, GNorm = 0.1923, lr_0 = 1.3895e-04
Loss = 1.5471e-05, PNorm = 47.7789, GNorm = 0.0760, lr_0 = 1.3876e-04
Loss = 1.5289e-05, PNorm = 47.7787, GNorm = 0.0807, lr_0 = 1.3858e-04
Loss = 1.6910e-05, PNorm = 47.7809, GNorm = 0.0571, lr_0 = 1.3839e-04
Loss = 1.3236e-05, PNorm = 47.7818, GNorm = 0.0619, lr_0 = 1.3821e-04
Loss = 1.5879e-05, PNorm = 47.7829, GNorm = 0.3186, lr_0 = 1.3802e-04
Loss = 1.8579e-05, PNorm = 47.7828, GNorm = 0.1720, lr_0 = 1.3783e-04
Loss = 1.6354e-05, PNorm = 47.7829, GNorm = 0.1204, lr_0 = 1.3765e-04
Loss = 1.8654e-05, PNorm = 47.7842, GNorm = 0.0955, lr_0 = 1.3747e-04
Validation rmse = 0.449751
Validation R2 = 0.942242
Epoch 86
Train function
Loss = 1.1356e-05, PNorm = 47.7842, GNorm = 0.0564, lr_0 = 1.3726e-04
Loss = 9.8024e-06, PNorm = 47.7851, GNorm = 0.0784, lr_0 = 1.3708e-04
Loss = 1.5741e-05, PNorm = 47.7853, GNorm = 0.0588, lr_0 = 1.3689e-04
Loss = 1.4207e-05, PNorm = 47.7875, GNorm = 0.0584, lr_0 = 1.3671e-04
Loss = 1.3321e-05, PNorm = 47.7890, GNorm = 0.0724, lr_0 = 1.3653e-04
Loss = 1.3188e-05, PNorm = 47.7890, GNorm = 0.0580, lr_0 = 1.3634e-04
Loss = 1.8748e-05, PNorm = 47.7908, GNorm = 0.1400, lr_0 = 1.3616e-04
Loss = 1.3368e-05, PNorm = 47.7926, GNorm = 0.0682, lr_0 = 1.3598e-04
Loss = 1.4738e-05, PNorm = 47.7939, GNorm = 0.0655, lr_0 = 1.3580e-04
Loss = 1.1052e-05, PNorm = 47.7944, GNorm = 0.0695, lr_0 = 1.3561e-04
Loss = 2.2181e-05, PNorm = 47.7950, GNorm = 0.1799, lr_0 = 1.3543e-04
Loss = 1.1690e-05, PNorm = 47.7959, GNorm = 0.0954, lr_0 = 1.3525e-04
Loss = 1.2927e-05, PNorm = 47.7964, GNorm = 0.0934, lr_0 = 1.3507e-04
Loss = 1.9086e-05, PNorm = 47.7989, GNorm = 0.1128, lr_0 = 1.3489e-04
Loss = 1.5533e-05, PNorm = 47.8009, GNorm = 0.1553, lr_0 = 1.3471e-04
Loss = 1.3165e-05, PNorm = 47.8013, GNorm = 0.0967, lr_0 = 1.3453e-04
Loss = 1.4934e-05, PNorm = 47.8026, GNorm = 0.0717, lr_0 = 1.3435e-04
Loss = 1.7860e-05, PNorm = 47.8055, GNorm = 0.1378, lr_0 = 1.3416e-04
Validation rmse = 0.450789
Validation R2 = 0.941975
Epoch 87
Train function
Loss = 1.3699e-05, PNorm = 47.8071, GNorm = 0.0637, lr_0 = 1.3398e-04
Loss = 1.7254e-05, PNorm = 47.8071, GNorm = 0.0939, lr_0 = 1.3380e-04
Loss = 1.2185e-05, PNorm = 47.8083, GNorm = 0.1215, lr_0 = 1.3363e-04
Loss = 1.7216e-05, PNorm = 47.8086, GNorm = 0.1490, lr_0 = 1.3345e-04
Loss = 1.4079e-05, PNorm = 47.8107, GNorm = 0.1709, lr_0 = 1.3327e-04
Loss = 1.0349e-05, PNorm = 47.8118, GNorm = 0.0632, lr_0 = 1.3309e-04
Loss = 1.4964e-05, PNorm = 47.8126, GNorm = 0.0702, lr_0 = 1.3291e-04
Loss = 2.0241e-05, PNorm = 47.8136, GNorm = 0.1937, lr_0 = 1.3273e-04
Loss = 1.4792e-05, PNorm = 47.8146, GNorm = 0.1105, lr_0 = 1.3255e-04
Loss = 1.5629e-05, PNorm = 47.8160, GNorm = 0.1158, lr_0 = 1.3238e-04
Loss = 2.2073e-05, PNorm = 47.8170, GNorm = 0.0684, lr_0 = 1.3220e-04
Loss = 2.0074e-05, PNorm = 47.8169, GNorm = 0.0840, lr_0 = 1.3202e-04
Loss = 1.5669e-05, PNorm = 47.8173, GNorm = 0.0838, lr_0 = 1.3184e-04
Loss = 1.4547e-05, PNorm = 47.8189, GNorm = 0.0507, lr_0 = 1.3167e-04
Loss = 1.4095e-05, PNorm = 47.8201, GNorm = 0.1066, lr_0 = 1.3149e-04
Loss = 1.3306e-05, PNorm = 47.8202, GNorm = 0.0642, lr_0 = 1.3131e-04
Loss = 1.2380e-05, PNorm = 47.8216, GNorm = 0.0646, lr_0 = 1.3114e-04
Validation rmse = 0.451170
Validation R2 = 0.941877
Epoch 88
Train function
Loss = 1.0606e-05, PNorm = 47.8226, GNorm = 0.0668, lr_0 = 1.3096e-04
Loss = 1.2290e-05, PNorm = 47.8236, GNorm = 0.0611, lr_0 = 1.3079e-04
Loss = 1.3260e-05, PNorm = 47.8248, GNorm = 0.0605, lr_0 = 1.3061e-04
Loss = 1.6593e-05, PNorm = 47.8252, GNorm = 0.0719, lr_0 = 1.3043e-04
Loss = 1.0799e-05, PNorm = 47.8257, GNorm = 0.0636, lr_0 = 1.3026e-04
Loss = 1.0956e-05, PNorm = 47.8264, GNorm = 0.1138, lr_0 = 1.3009e-04
Loss = 1.3101e-05, PNorm = 47.8267, GNorm = 0.0963, lr_0 = 1.2991e-04
Loss = 1.6909e-05, PNorm = 47.8276, GNorm = 0.1065, lr_0 = 1.2974e-04
Loss = 1.4954e-05, PNorm = 47.8291, GNorm = 0.0713, lr_0 = 1.2956e-04
Loss = 1.4853e-05, PNorm = 47.8308, GNorm = 0.0979, lr_0 = 1.2939e-04
Loss = 1.7166e-05, PNorm = 47.8331, GNorm = 0.0828, lr_0 = 1.2921e-04
Loss = 1.3127e-05, PNorm = 47.8343, GNorm = 0.0567, lr_0 = 1.2904e-04
Loss = 1.0296e-05, PNorm = 47.8354, GNorm = 0.0683, lr_0 = 1.2887e-04
Loss = 9.9336e-06, PNorm = 47.8358, GNorm = 0.0655, lr_0 = 1.2870e-04
Loss = 8.4111e-06, PNorm = 47.8358, GNorm = 0.0718, lr_0 = 1.2852e-04
Loss = 1.2471e-05, PNorm = 47.8361, GNorm = 0.0755, lr_0 = 1.2835e-04
Loss = 1.2034e-05, PNorm = 47.8358, GNorm = 0.1321, lr_0 = 1.2818e-04
Loss = 1.1201e-05, PNorm = 47.8373, GNorm = 0.0600, lr_0 = 1.2801e-04
Validation rmse = 0.451145
Validation R2 = 0.941883
Epoch 89
Train function
Loss = 8.0558e-06, PNorm = 47.8376, GNorm = 0.0520, lr_0 = 1.2782e-04
Loss = 9.3661e-06, PNorm = 47.8387, GNorm = 0.0405, lr_0 = 1.2765e-04
Loss = 8.0931e-06, PNorm = 47.8390, GNorm = 0.1258, lr_0 = 1.2747e-04
Loss = 1.1910e-05, PNorm = 47.8395, GNorm = 0.0634, lr_0 = 1.2730e-04
Loss = 8.8411e-06, PNorm = 47.8408, GNorm = 0.0840, lr_0 = 1.2713e-04
Loss = 8.6100e-06, PNorm = 47.8420, GNorm = 0.0581, lr_0 = 1.2696e-04
Loss = 2.0968e-05, PNorm = 47.8444, GNorm = 0.1050, lr_0 = 1.2679e-04
Loss = 1.5618e-05, PNorm = 47.8448, GNorm = 0.1220, lr_0 = 1.2662e-04
Loss = 1.2470e-05, PNorm = 47.8456, GNorm = 0.1267, lr_0 = 1.2645e-04
Loss = 1.0800e-05, PNorm = 47.8456, GNorm = 0.1185, lr_0 = 1.2628e-04
Loss = 1.4378e-05, PNorm = 47.8462, GNorm = 0.1445, lr_0 = 1.2611e-04
Loss = 1.2591e-05, PNorm = 47.8474, GNorm = 0.0515, lr_0 = 1.2594e-04
Loss = 1.4406e-05, PNorm = 47.8476, GNorm = 0.0807, lr_0 = 1.2577e-04
Loss = 1.1072e-05, PNorm = 47.8490, GNorm = 0.0510, lr_0 = 1.2561e-04
Loss = 1.1659e-05, PNorm = 47.8505, GNorm = 0.0398, lr_0 = 1.2544e-04
Loss = 8.7800e-06, PNorm = 47.8509, GNorm = 0.0976, lr_0 = 1.2527e-04
Loss = 7.8487e-06, PNorm = 47.8510, GNorm = 0.0948, lr_0 = 1.2510e-04
Validation rmse = 0.450063
Validation R2 = 0.942162
Epoch 90
Train function
Loss = 1.1465e-05, PNorm = 47.8516, GNorm = 0.0803, lr_0 = 1.2493e-04
Loss = 1.0543e-05, PNorm = 47.8530, GNorm = 0.0706, lr_0 = 1.2477e-04
Loss = 9.7167e-06, PNorm = 47.8543, GNorm = 0.1137, lr_0 = 1.2460e-04
Loss = 1.3150e-05, PNorm = 47.8544, GNorm = 0.0450, lr_0 = 1.2443e-04
Loss = 1.0932e-05, PNorm = 47.8560, GNorm = 0.1074, lr_0 = 1.2426e-04
Loss = 1.4214e-05, PNorm = 47.8577, GNorm = 0.0616, lr_0 = 1.2410e-04
Loss = 1.5754e-05, PNorm = 47.8591, GNorm = 0.0485, lr_0 = 1.2393e-04
Loss = 1.0829e-05, PNorm = 47.8604, GNorm = 0.0467, lr_0 = 1.2376e-04
Loss = 1.7657e-05, PNorm = 47.8609, GNorm = 0.1109, lr_0 = 1.2360e-04
Loss = 1.3917e-05, PNorm = 47.8625, GNorm = 0.2028, lr_0 = 1.2343e-04
Loss = 1.0514e-05, PNorm = 47.8631, GNorm = 0.0783, lr_0 = 1.2327e-04
Loss = 9.0929e-06, PNorm = 47.8638, GNorm = 0.0490, lr_0 = 1.2310e-04
Loss = 9.7885e-06, PNorm = 47.8652, GNorm = 0.0439, lr_0 = 1.2294e-04
Loss = 9.2232e-06, PNorm = 47.8651, GNorm = 0.0633, lr_0 = 1.2277e-04
Loss = 8.2835e-06, PNorm = 47.8659, GNorm = 0.0417, lr_0 = 1.2261e-04
Loss = 1.6632e-05, PNorm = 47.8664, GNorm = 0.1952, lr_0 = 1.2244e-04
Loss = 1.2565e-05, PNorm = 47.8661, GNorm = 0.0977, lr_0 = 1.2228e-04
Loss = 1.0058e-05, PNorm = 47.8674, GNorm = 0.0720, lr_0 = 1.2211e-04
Validation rmse = 0.450555
Validation R2 = 0.942035
Epoch 91
Train function
Loss = 1.2532e-05, PNorm = 47.8684, GNorm = 0.1536, lr_0 = 1.2195e-04
Loss = 1.2501e-05, PNorm = 47.8694, GNorm = 0.1971, lr_0 = 1.2179e-04
Loss = 1.6069e-05, PNorm = 47.8692, GNorm = 0.1775, lr_0 = 1.2162e-04
Loss = 1.3706e-05, PNorm = 47.8699, GNorm = 0.0622, lr_0 = 1.2146e-04
Loss = 1.4255e-05, PNorm = 47.8709, GNorm = 0.2200, lr_0 = 1.2130e-04
Loss = 1.1780e-05, PNorm = 47.8709, GNorm = 0.0719, lr_0 = 1.2113e-04
Loss = 1.9294e-05, PNorm = 47.8716, GNorm = 0.1865, lr_0 = 1.2097e-04
Loss = 1.3736e-05, PNorm = 47.8731, GNorm = 0.0552, lr_0 = 1.2081e-04
Loss = 9.8928e-06, PNorm = 47.8740, GNorm = 0.0425, lr_0 = 1.2065e-04
Loss = 9.7080e-06, PNorm = 47.8750, GNorm = 0.0640, lr_0 = 1.2048e-04
Loss = 1.0064e-05, PNorm = 47.8758, GNorm = 0.0831, lr_0 = 1.2032e-04
Loss = 7.9178e-06, PNorm = 47.8764, GNorm = 0.1159, lr_0 = 1.2016e-04
Loss = 9.5812e-06, PNorm = 47.8771, GNorm = 0.0537, lr_0 = 1.2000e-04
Loss = 9.4239e-06, PNorm = 47.8776, GNorm = 0.1041, lr_0 = 1.1984e-04
Loss = 1.2978e-05, PNorm = 47.8783, GNorm = 0.0498, lr_0 = 1.1968e-04
Loss = 1.0039e-05, PNorm = 47.8780, GNorm = 0.1048, lr_0 = 1.1952e-04
Loss = 1.0639e-05, PNorm = 47.8783, GNorm = 0.1057, lr_0 = 1.1936e-04
Loss = 7.4875e-06, PNorm = 47.8787, GNorm = 0.0768, lr_0 = 1.1920e-04
Loss = 1.4776e-05, PNorm = 47.8788, GNorm = 0.0671, lr_0 = 1.1918e-04
Validation rmse = 0.450192
Validation R2 = 0.942128
Epoch 92
Train function
Loss = 1.0233e-05, PNorm = 47.8800, GNorm = 0.0802, lr_0 = 1.1902e-04
Loss = 9.0482e-06, PNorm = 47.8812, GNorm = 0.1267, lr_0 = 1.1886e-04
Loss = 8.6559e-06, PNorm = 47.8823, GNorm = 0.0649, lr_0 = 1.1870e-04
Loss = 7.1242e-06, PNorm = 47.8836, GNorm = 0.0756, lr_0 = 1.1854e-04
Loss = 7.2727e-06, PNorm = 47.8842, GNorm = 0.0494, lr_0 = 1.1838e-04
Loss = 7.4865e-06, PNorm = 47.8844, GNorm = 0.0430, lr_0 = 1.1823e-04
Loss = 1.2785e-05, PNorm = 47.8851, GNorm = 0.1264, lr_0 = 1.1807e-04
Loss = 8.7107e-06, PNorm = 47.8851, GNorm = 0.1533, lr_0 = 1.1791e-04
Loss = 1.1262e-05, PNorm = 47.8854, GNorm = 0.0547, lr_0 = 1.1775e-04
Loss = 8.0969e-06, PNorm = 47.8869, GNorm = 0.0490, lr_0 = 1.1759e-04
Loss = 8.4425e-06, PNorm = 47.8880, GNorm = 0.0676, lr_0 = 1.1743e-04
Loss = 9.1216e-06, PNorm = 47.8879, GNorm = 0.1529, lr_0 = 1.1728e-04
Loss = 9.5780e-06, PNorm = 47.8884, GNorm = 0.1322, lr_0 = 1.1712e-04
Loss = 8.6145e-06, PNorm = 47.8890, GNorm = 0.0799, lr_0 = 1.1696e-04
Loss = 1.1862e-05, PNorm = 47.8893, GNorm = 0.0537, lr_0 = 1.1681e-04
Loss = 1.4129e-05, PNorm = 47.8905, GNorm = 0.0608, lr_0 = 1.1665e-04
Loss = 1.0439e-05, PNorm = 47.8907, GNorm = 0.0759, lr_0 = 1.1649e-04
Validation rmse = 0.450628
Validation R2 = 0.942016
Epoch 93
Train function
Loss = 9.3617e-06, PNorm = 47.8909, GNorm = 0.0490, lr_0 = 1.1634e-04
Loss = 7.4925e-06, PNorm = 47.8914, GNorm = 0.0388, lr_0 = 1.1618e-04
Loss = 8.3329e-06, PNorm = 47.8918, GNorm = 0.0632, lr_0 = 1.1602e-04
Loss = 9.0997e-06, PNorm = 47.8916, GNorm = 0.0466, lr_0 = 1.1587e-04
Loss = 1.1886e-05, PNorm = 47.8917, GNorm = 0.1498, lr_0 = 1.1571e-04
Loss = 1.1775e-05, PNorm = 47.8926, GNorm = 0.1246, lr_0 = 1.1556e-04
Loss = 8.7893e-06, PNorm = 47.8935, GNorm = 0.0554, lr_0 = 1.1540e-04
Loss = 7.1898e-06, PNorm = 47.8941, GNorm = 0.0357, lr_0 = 1.1525e-04
Loss = 8.2300e-06, PNorm = 47.8943, GNorm = 0.1193, lr_0 = 1.1509e-04
Loss = 1.6370e-05, PNorm = 47.8967, GNorm = 0.0524, lr_0 = 1.1494e-04
Loss = 1.7298e-05, PNorm = 47.8978, GNorm = 0.0514, lr_0 = 1.1478e-04
Loss = 1.0298e-05, PNorm = 47.8983, GNorm = 0.0635, lr_0 = 1.1463e-04
Loss = 9.5139e-06, PNorm = 47.8987, GNorm = 0.0758, lr_0 = 1.1448e-04
Loss = 1.6220e-05, PNorm = 47.8996, GNorm = 0.1409, lr_0 = 1.1432e-04
Loss = 1.4338e-05, PNorm = 47.9008, GNorm = 0.0988, lr_0 = 1.1417e-04
Loss = 1.3484e-05, PNorm = 47.9025, GNorm = 0.0656, lr_0 = 1.1402e-04
Loss = 9.9007e-06, PNorm = 47.9035, GNorm = 0.1022, lr_0 = 1.1386e-04
Loss = 1.4133e-05, PNorm = 47.9034, GNorm = 0.0440, lr_0 = 1.1371e-04
Validation rmse = 0.450430
Validation R2 = 0.942067
Epoch 94
Train function
Loss = 1.0706e-05, PNorm = 47.9044, GNorm = 0.0550, lr_0 = 1.1356e-04
Loss = 9.0699e-06, PNorm = 47.9051, GNorm = 0.0915, lr_0 = 1.1341e-04
Loss = 1.1917e-05, PNorm = 47.9055, GNorm = 0.1117, lr_0 = 1.1325e-04
Loss = 1.2398e-05, PNorm = 47.9059, GNorm = 0.0437, lr_0 = 1.1310e-04
Loss = 1.2049e-05, PNorm = 47.9076, GNorm = 0.0903, lr_0 = 1.1295e-04
Loss = 1.0220e-05, PNorm = 47.9083, GNorm = 0.0500, lr_0 = 1.1280e-04
Loss = 1.0696e-05, PNorm = 47.9089, GNorm = 0.0763, lr_0 = 1.1265e-04
Loss = 9.1896e-06, PNorm = 47.9098, GNorm = 0.0752, lr_0 = 1.1250e-04
Loss = 9.3398e-06, PNorm = 47.9098, GNorm = 0.0466, lr_0 = 1.1235e-04
Loss = 9.3497e-06, PNorm = 47.9095, GNorm = 0.0698, lr_0 = 1.1219e-04
Loss = 1.2442e-05, PNorm = 47.9104, GNorm = 0.0676, lr_0 = 1.1204e-04
Loss = 1.1259e-05, PNorm = 47.9117, GNorm = 0.0829, lr_0 = 1.1189e-04
Loss = 9.9816e-06, PNorm = 47.9128, GNorm = 0.0397, lr_0 = 1.1174e-04
Loss = 9.3957e-06, PNorm = 47.9134, GNorm = 0.0690, lr_0 = 1.1159e-04
Loss = 1.1609e-05, PNorm = 47.9135, GNorm = 0.0729, lr_0 = 1.1144e-04
Loss = 1.6745e-05, PNorm = 47.9153, GNorm = 0.0580, lr_0 = 1.1129e-04
Loss = 8.0855e-06, PNorm = 47.9168, GNorm = 0.0453, lr_0 = 1.1114e-04
Validation rmse = 0.450609
Validation R2 = 0.942021
Epoch 95
Train function
Loss = 1.1365e-05, PNorm = 47.9180, GNorm = 0.0516, lr_0 = 1.1098e-04
Loss = 7.2149e-06, PNorm = 47.9173, GNorm = 0.0471, lr_0 = 1.1083e-04
Loss = 1.0868e-05, PNorm = 47.9165, GNorm = 0.0490, lr_0 = 1.1068e-04
Loss = 6.2191e-06, PNorm = 47.9164, GNorm = 0.0337, lr_0 = 1.1053e-04
Loss = 8.8577e-06, PNorm = 47.9170, GNorm = 0.0813, lr_0 = 1.1039e-04
Loss = 9.1878e-06, PNorm = 47.9176, GNorm = 0.0908, lr_0 = 1.1024e-04
Loss = 1.0161e-05, PNorm = 47.9183, GNorm = 0.1167, lr_0 = 1.1009e-04
Loss = 9.6880e-06, PNorm = 47.9185, GNorm = 0.0552, lr_0 = 1.0994e-04
Loss = 7.7685e-06, PNorm = 47.9190, GNorm = 0.1650, lr_0 = 1.0980e-04
Loss = 9.2534e-06, PNorm = 47.9190, GNorm = 0.1433, lr_0 = 1.0965e-04
Loss = 1.1605e-05, PNorm = 47.9194, GNorm = 0.1487, lr_0 = 1.0950e-04
Loss = 1.2801e-05, PNorm = 47.9202, GNorm = 0.1300, lr_0 = 1.0935e-04
Loss = 1.3286e-05, PNorm = 47.9204, GNorm = 0.0628, lr_0 = 1.0921e-04
Loss = 1.0918e-05, PNorm = 47.9219, GNorm = 0.1286, lr_0 = 1.0906e-04
Loss = 1.0939e-05, PNorm = 47.9227, GNorm = 0.0434, lr_0 = 1.0891e-04
Loss = 9.6564e-06, PNorm = 47.9229, GNorm = 0.0630, lr_0 = 1.0877e-04
Loss = 1.5146e-05, PNorm = 47.9233, GNorm = 0.1047, lr_0 = 1.0862e-04
Loss = 1.4646e-05, PNorm = 47.9240, GNorm = 0.1004, lr_0 = 1.0848e-04
Validation rmse = 0.449312
Validation R2 = 0.942355
Epoch 96
Train function
Loss = 1.0258e-05, PNorm = 47.9264, GNorm = 0.0685, lr_0 = 1.0833e-04
Loss = 7.1219e-06, PNorm = 47.9282, GNorm = 0.0687, lr_0 = 1.0819e-04
Loss = 6.7160e-06, PNorm = 47.9276, GNorm = 0.0723, lr_0 = 1.0804e-04
Loss = 7.2244e-06, PNorm = 47.9280, GNorm = 0.0785, lr_0 = 1.0790e-04
Loss = 5.4624e-06, PNorm = 47.9282, GNorm = 0.0434, lr_0 = 1.0775e-04
Loss = 5.3319e-06, PNorm = 47.9281, GNorm = 0.0664, lr_0 = 1.0761e-04
Loss = 6.1138e-06, PNorm = 47.9288, GNorm = 0.0788, lr_0 = 1.0746e-04
Loss = 1.0024e-05, PNorm = 47.9290, GNorm = 0.0942, lr_0 = 1.0732e-04
Loss = 1.1252e-05, PNorm = 47.9297, GNorm = 0.1439, lr_0 = 1.0717e-04
Loss = 1.2740e-05, PNorm = 47.9311, GNorm = 0.0879, lr_0 = 1.0703e-04
Loss = 8.0428e-06, PNorm = 47.9318, GNorm = 0.1008, lr_0 = 1.0689e-04
Loss = 1.1081e-05, PNorm = 47.9332, GNorm = 0.1014, lr_0 = 1.0674e-04
Loss = 1.1980e-05, PNorm = 47.9334, GNorm = 0.0763, lr_0 = 1.0660e-04
Loss = 1.3769e-05, PNorm = 47.9341, GNorm = 0.2070, lr_0 = 1.0646e-04
Loss = 1.0320e-05, PNorm = 47.9353, GNorm = 0.1036, lr_0 = 1.0631e-04
Loss = 9.1316e-06, PNorm = 47.9354, GNorm = 0.0791, lr_0 = 1.0617e-04
Loss = 1.0377e-05, PNorm = 47.9353, GNorm = 0.0635, lr_0 = 1.0603e-04
Validation rmse = 0.452252
Validation R2 = 0.941597
Epoch 97
Train function
Loss = 9.4887e-06, PNorm = 47.9364, GNorm = 0.0717, lr_0 = 1.0589e-04
Loss = 1.1756e-05, PNorm = 47.9368, GNorm = 0.0619, lr_0 = 1.0574e-04
Loss = 1.3644e-05, PNorm = 47.9381, GNorm = 0.0522, lr_0 = 1.0560e-04
Loss = 7.8546e-06, PNorm = 47.9388, GNorm = 0.0405, lr_0 = 1.0546e-04
Loss = 9.1045e-06, PNorm = 47.9402, GNorm = 0.0557, lr_0 = 1.0532e-04
Loss = 8.9800e-06, PNorm = 47.9409, GNorm = 0.0675, lr_0 = 1.0518e-04
Loss = 8.5152e-06, PNorm = 47.9423, GNorm = 0.0763, lr_0 = 1.0504e-04
Loss = 1.4667e-05, PNorm = 47.9428, GNorm = 0.1721, lr_0 = 1.0490e-04
Loss = 1.7644e-05, PNorm = 47.9436, GNorm = 0.0815, lr_0 = 1.0476e-04
Loss = 1.5394e-05, PNorm = 47.9438, GNorm = 0.0780, lr_0 = 1.0461e-04
Loss = 1.4424e-05, PNorm = 47.9454, GNorm = 0.1598, lr_0 = 1.0447e-04
Loss = 1.2508e-05, PNorm = 47.9462, GNorm = 0.2243, lr_0 = 1.0433e-04
Loss = 1.5214e-05, PNorm = 47.9476, GNorm = 0.0884, lr_0 = 1.0419e-04
Loss = 7.6835e-06, PNorm = 47.9495, GNorm = 0.0419, lr_0 = 1.0405e-04
Loss = 9.3334e-06, PNorm = 47.9500, GNorm = 0.1797, lr_0 = 1.0391e-04
Loss = 9.8869e-06, PNorm = 47.9510, GNorm = 0.0711, lr_0 = 1.0378e-04
Loss = 7.0052e-06, PNorm = 47.9517, GNorm = 0.0373, lr_0 = 1.0364e-04
Loss = 6.5058e-06, PNorm = 47.9524, GNorm = 0.0357, lr_0 = 1.0350e-04
Validation rmse = 0.451609
Validation R2 = 0.941763
Epoch 98
Train function
Loss = 7.0137e-06, PNorm = 47.9529, GNorm = 0.0912, lr_0 = 1.0334e-04
Loss = 1.0509e-05, PNorm = 47.9539, GNorm = 0.0461, lr_0 = 1.0321e-04
Loss = 6.9294e-06, PNorm = 47.9544, GNorm = 0.0513, lr_0 = 1.0307e-04
Loss = 7.4945e-06, PNorm = 47.9542, GNorm = 0.0400, lr_0 = 1.0293e-04
Loss = 8.6485e-06, PNorm = 47.9550, GNorm = 0.0839, lr_0 = 1.0279e-04
Loss = 8.7512e-06, PNorm = 47.9562, GNorm = 0.0578, lr_0 = 1.0265e-04
Loss = 6.5212e-06, PNorm = 47.9564, GNorm = 0.0697, lr_0 = 1.0251e-04
Loss = 5.3465e-06, PNorm = 47.9563, GNorm = 0.0774, lr_0 = 1.0238e-04
Loss = 1.7905e-05, PNorm = 47.9571, GNorm = 0.1588, lr_0 = 1.0224e-04
Loss = 8.7495e-06, PNorm = 47.9571, GNorm = 0.1241, lr_0 = 1.0210e-04
Loss = 8.7146e-06, PNorm = 47.9581, GNorm = 0.0562, lr_0 = 1.0197e-04
Loss = 8.8813e-06, PNorm = 47.9583, GNorm = 0.0700, lr_0 = 1.0183e-04
Loss = 7.5976e-06, PNorm = 47.9584, GNorm = 0.0511, lr_0 = 1.0169e-04
Loss = 7.6886e-06, PNorm = 47.9585, GNorm = 0.0626, lr_0 = 1.0156e-04
Loss = 8.5180e-06, PNorm = 47.9589, GNorm = 0.0839, lr_0 = 1.0142e-04
Loss = 7.8932e-06, PNorm = 47.9591, GNorm = 0.0946, lr_0 = 1.0128e-04
Loss = 8.5062e-06, PNorm = 47.9590, GNorm = 0.0876, lr_0 = 1.0115e-04
Loss = 1.0497e-05, PNorm = 47.9597, GNorm = 0.1041, lr_0 = 1.0101e-04
Validation rmse = 0.451268
Validation R2 = 0.941851
Epoch 99
Train function
Loss = 9.7109e-06, PNorm = 47.9601, GNorm = 0.1203, lr_0 = 1.0088e-04
Loss = 1.0155e-05, PNorm = 47.9607, GNorm = 0.0560, lr_0 = 1.0074e-04
Loss = 9.1219e-06, PNorm = 47.9622, GNorm = 0.0704, lr_0 = 1.0061e-04
Loss = 1.2344e-05, PNorm = 47.9630, GNorm = 0.2224, lr_0 = 1.0047e-04
Loss = 1.0079e-05, PNorm = 47.9630, GNorm = 0.0395, lr_0 = 1.0034e-04
Loss = 1.5348e-05, PNorm = 47.9628, GNorm = 0.1410, lr_0 = 1.0020e-04
Loss = 9.3319e-06, PNorm = 47.9640, GNorm = 0.0445, lr_0 = 1.0007e-04
Loss = 1.3517e-05, PNorm = 47.9647, GNorm = 0.0760, lr_0 = 1.0000e-04
Loss = 7.4402e-06, PNorm = 47.9655, GNorm = 0.0498, lr_0 = 1.0000e-04
Loss = 7.6852e-06, PNorm = 47.9656, GNorm = 0.0580, lr_0 = 1.0000e-04
Loss = 6.1342e-06, PNorm = 47.9671, GNorm = 0.0371, lr_0 = 1.0000e-04
Loss = 7.3488e-06, PNorm = 47.9667, GNorm = 0.0439, lr_0 = 1.0000e-04
Loss = 5.7237e-06, PNorm = 47.9671, GNorm = 0.0664, lr_0 = 1.0000e-04
Loss = 6.3721e-06, PNorm = 47.9674, GNorm = 0.0719, lr_0 = 1.0000e-04
Loss = 7.0605e-06, PNorm = 47.9676, GNorm = 0.0343, lr_0 = 1.0000e-04
Loss = 5.9698e-06, PNorm = 47.9686, GNorm = 0.1073, lr_0 = 1.0000e-04
Loss = 6.6622e-06, PNorm = 47.9692, GNorm = 0.0362, lr_0 = 1.0000e-04
Validation rmse = 0.450932
Validation R2 = 0.941938
Model 0 best validation rmse = 0.445324 on epoch 30
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse = 0.450212
Model 0 test R2 = 0.939811
Ensemble test rmse = 0.450212
Ensemble test R2 = 0.939811
4-fold cross validation
	Seed 0 ==> test rmse = 0.458375
	Seed 0 ==> test R2 = 0.937609
	Seed 1 ==> test rmse = 0.469304
	Seed 1 ==> test R2 = 0.934598
	Seed 2 ==> test rmse = 0.467688
	Seed 2 ==> test R2 = 0.935047
	Seed 3 ==> test rmse = 0.450212
	Seed 3 ==> test R2 = 0.939811
Overall test rmse = 0.461395 +/- 0.007687
Overall test R2 = 0.936766 +/- 0.002100
Elapsed time = 7:07:21
