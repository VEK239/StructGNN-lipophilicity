Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 1.9976e-02, PNorm = 35.0897, GNorm = 4.1144, lr_0 = 1.2200e-04
Loss = 1.9948e-02, PNorm = 35.0916, GNorm = 3.7086, lr_0 = 1.4200e-04
Loss = 1.5198e-02, PNorm = 35.0950, GNorm = 5.5799, lr_0 = 1.6200e-04
Loss = 1.3925e-02, PNorm = 35.0991, GNorm = 3.5163, lr_0 = 1.8200e-04
Loss = 1.3778e-02, PNorm = 35.1040, GNorm = 6.1062, lr_0 = 2.0200e-04
Loss = 1.1762e-02, PNorm = 35.1086, GNorm = 2.7936, lr_0 = 2.2200e-04
Loss = 9.6353e-03, PNorm = 35.1158, GNorm = 2.2301, lr_0 = 2.4200e-04
Loss = 1.0510e-02, PNorm = 35.1228, GNorm = 2.6535, lr_0 = 2.6200e-04
Loss = 8.7578e-03, PNorm = 35.1312, GNorm = 3.0003, lr_0 = 2.8200e-04
Loss = 7.6346e-03, PNorm = 35.1405, GNorm = 5.2295, lr_0 = 3.0200e-04
Loss = 8.0946e-03, PNorm = 35.1488, GNorm = 1.9133, lr_0 = 3.2200e-04
Loss = 9.0692e-03, PNorm = 35.1590, GNorm = 7.3742, lr_0 = 3.4200e-04
Loss = 9.2227e-03, PNorm = 35.1702, GNorm = 4.7346, lr_0 = 3.6200e-04
Loss = 7.4747e-03, PNorm = 35.1816, GNorm = 3.0333, lr_0 = 3.8200e-04
Loss = 7.2203e-03, PNorm = 35.1940, GNorm = 2.5792, lr_0 = 4.0200e-04
Loss = 6.7861e-03, PNorm = 35.2114, GNorm = 2.8959, lr_0 = 4.2200e-04
Loss = 7.2321e-03, PNorm = 35.2264, GNorm = 1.9655, lr_0 = 4.4200e-04
Loss = 7.6254e-03, PNorm = 35.2454, GNorm = 3.1361, lr_0 = 4.6200e-04
Loss = 5.8946e-03, PNorm = 35.2567, GNorm = 2.3058, lr_0 = 4.8200e-04
Loss = 6.3124e-03, PNorm = 35.2699, GNorm = 4.0191, lr_0 = 5.0200e-04
Loss = 5.9955e-03, PNorm = 35.2884, GNorm = 0.9291, lr_0 = 5.2200e-04
Loss = 5.8557e-03, PNorm = 35.3074, GNorm = 2.2882, lr_0 = 5.4200e-04
Validation rmse logD = 0.911702
Validation R2 logD = 0.418676
Validation rmse logP = 0.875806
Validation R2 logP = 0.788851
Epoch 1
Train function
Loss = 5.7604e-03, PNorm = 35.3267, GNorm = 2.9603, lr_0 = 5.6400e-04
Loss = 6.1488e-03, PNorm = 35.3431, GNorm = 5.8294, lr_0 = 5.8400e-04
Loss = 5.5698e-03, PNorm = 35.3613, GNorm = 1.2178, lr_0 = 6.0400e-04
Loss = 5.7392e-03, PNorm = 35.3844, GNorm = 7.3213, lr_0 = 6.2400e-04
Loss = 6.7854e-03, PNorm = 35.4044, GNorm = 3.4981, lr_0 = 6.4400e-04
Loss = 5.5204e-03, PNorm = 35.4295, GNorm = 2.9583, lr_0 = 6.6400e-04
Loss = 4.9738e-03, PNorm = 35.4482, GNorm = 2.4650, lr_0 = 6.8400e-04
Loss = 5.0726e-03, PNorm = 35.4678, GNorm = 2.0897, lr_0 = 7.0400e-04
Loss = 5.3033e-03, PNorm = 35.4934, GNorm = 2.2148, lr_0 = 7.2400e-04
Loss = 6.2883e-03, PNorm = 35.5197, GNorm = 4.4177, lr_0 = 7.4400e-04
Loss = 5.1991e-03, PNorm = 35.5509, GNorm = 3.2274, lr_0 = 7.6400e-04
Loss = 4.8484e-03, PNorm = 35.5792, GNorm = 2.0745, lr_0 = 7.8400e-04
Loss = 5.4484e-03, PNorm = 35.6043, GNorm = 2.4488, lr_0 = 8.0400e-04
Loss = 5.0224e-03, PNorm = 35.6331, GNorm = 1.9733, lr_0 = 8.2400e-04
Loss = 5.0902e-03, PNorm = 35.6613, GNorm = 1.4672, lr_0 = 8.4400e-04
Loss = 5.0732e-03, PNorm = 35.6886, GNorm = 2.5791, lr_0 = 8.6400e-04
Loss = 4.2656e-03, PNorm = 35.7193, GNorm = 2.4681, lr_0 = 8.8400e-04
Loss = 4.8722e-03, PNorm = 35.7548, GNorm = 1.5593, lr_0 = 9.0400e-04
Loss = 4.5416e-03, PNorm = 35.7902, GNorm = 1.7941, lr_0 = 9.2400e-04
Loss = 5.3429e-03, PNorm = 35.8248, GNorm = 2.5273, lr_0 = 9.4400e-04
Loss = 4.4257e-03, PNorm = 35.8594, GNorm = 3.2945, lr_0 = 9.6400e-04
Loss = 4.9025e-03, PNorm = 35.8981, GNorm = 1.2320, lr_0 = 9.8400e-04
Loss = 5.3621e-03, PNorm = 35.9286, GNorm = 5.0058, lr_0 = 9.9979e-04
Loss = 5.9538e-03, PNorm = 35.9332, GNorm = 1.5970, lr_0 = 9.9969e-04
Validation rmse logD = 0.826052
Validation R2 logD = 0.522771
Validation rmse logP = 0.690806
Validation R2 logP = 0.868633
Epoch 2
Train function
Loss = 4.3315e-03, PNorm = 35.9558, GNorm = 1.4483, lr_0 = 9.9864e-04
Loss = 5.2577e-03, PNorm = 35.9943, GNorm = 1.4090, lr_0 = 9.9760e-04
Loss = 3.8897e-03, PNorm = 36.0343, GNorm = 2.7217, lr_0 = 9.9656e-04
Loss = 3.8411e-03, PNorm = 36.0691, GNorm = 1.5081, lr_0 = 9.9552e-04
Loss = 4.3725e-03, PNorm = 36.0968, GNorm = 2.4745, lr_0 = 9.9448e-04
Loss = 4.3164e-03, PNorm = 36.1340, GNorm = 3.8727, lr_0 = 9.9344e-04
Loss = 5.5445e-03, PNorm = 36.1572, GNorm = 3.0272, lr_0 = 9.9241e-04
Loss = 3.5235e-03, PNorm = 36.1965, GNorm = 1.6457, lr_0 = 9.9137e-04
Loss = 4.1966e-03, PNorm = 36.2343, GNorm = 1.7425, lr_0 = 9.9034e-04
Loss = 4.3382e-03, PNorm = 36.2704, GNorm = 2.3061, lr_0 = 9.8930e-04
Loss = 4.3971e-03, PNorm = 36.3115, GNorm = 3.8305, lr_0 = 9.8827e-04
Loss = 3.8491e-03, PNorm = 36.3527, GNorm = 2.4135, lr_0 = 9.8724e-04
Loss = 4.0185e-03, PNorm = 36.3875, GNorm = 1.3550, lr_0 = 9.8621e-04
Loss = 3.7084e-03, PNorm = 36.4144, GNorm = 3.5740, lr_0 = 9.8518e-04
Loss = 4.7324e-03, PNorm = 36.4539, GNorm = 2.7882, lr_0 = 9.8415e-04
Loss = 4.9644e-03, PNorm = 36.4923, GNorm = 3.2834, lr_0 = 9.8312e-04
Loss = 4.6318e-03, PNorm = 36.5426, GNorm = 0.7184, lr_0 = 9.8210e-04
Loss = 3.3577e-03, PNorm = 36.5760, GNorm = 1.8317, lr_0 = 9.8107e-04
Loss = 3.4895e-03, PNorm = 36.6050, GNorm = 1.1729, lr_0 = 9.8005e-04
Loss = 3.3745e-03, PNorm = 36.6291, GNorm = 2.5263, lr_0 = 9.7902e-04
Loss = 3.4826e-03, PNorm = 36.6555, GNorm = 1.1155, lr_0 = 9.7800e-04
Loss = 3.3216e-03, PNorm = 36.6830, GNorm = 1.0919, lr_0 = 9.7698e-04
Validation rmse logD = 0.810774
Validation R2 logD = 0.540260
Validation rmse logP = 0.632847
Validation R2 logP = 0.889752
Epoch 3
Train function
Loss = 2.7631e-03, PNorm = 36.7030, GNorm = 1.3556, lr_0 = 9.7596e-04
Loss = 3.0802e-03, PNorm = 36.7290, GNorm = 1.1745, lr_0 = 9.7494e-04
Loss = 3.4683e-03, PNorm = 36.7585, GNorm = 1.9150, lr_0 = 9.7393e-04
Loss = 3.4368e-03, PNorm = 36.7875, GNorm = 1.5622, lr_0 = 9.7291e-04
Loss = 3.1938e-03, PNorm = 36.8136, GNorm = 1.1741, lr_0 = 9.7189e-04
Loss = 3.1052e-03, PNorm = 36.8576, GNorm = 1.2288, lr_0 = 9.7088e-04
Loss = 4.0607e-03, PNorm = 36.8825, GNorm = 1.6254, lr_0 = 9.6987e-04
Loss = 2.7088e-03, PNorm = 36.9119, GNorm = 0.7164, lr_0 = 9.6885e-04
Loss = 3.3425e-03, PNorm = 36.9466, GNorm = 0.7653, lr_0 = 9.6784e-04
Loss = 3.3599e-03, PNorm = 36.9784, GNorm = 1.3950, lr_0 = 9.6683e-04
Loss = 2.9879e-03, PNorm = 37.0158, GNorm = 1.3803, lr_0 = 9.6582e-04
Loss = 3.0273e-03, PNorm = 37.0295, GNorm = 3.4277, lr_0 = 9.6482e-04
Loss = 4.0576e-03, PNorm = 37.0469, GNorm = 1.4266, lr_0 = 9.6381e-04
Loss = 3.5080e-03, PNorm = 37.0763, GNorm = 1.3508, lr_0 = 9.6280e-04
Loss = 3.4138e-03, PNorm = 37.1045, GNorm = 1.7842, lr_0 = 9.6180e-04
Loss = 3.6472e-03, PNorm = 37.1496, GNorm = 1.0940, lr_0 = 9.6079e-04
Loss = 3.7265e-03, PNorm = 37.1733, GNorm = 1.4869, lr_0 = 9.5979e-04
Loss = 2.4423e-03, PNorm = 37.1938, GNorm = 0.5775, lr_0 = 9.5879e-04
Loss = 2.4095e-03, PNorm = 37.2203, GNorm = 0.9051, lr_0 = 9.5779e-04
Loss = 2.8995e-03, PNorm = 37.2465, GNorm = 1.0787, lr_0 = 9.5679e-04
Loss = 2.3865e-03, PNorm = 37.2688, GNorm = 0.7422, lr_0 = 9.5579e-04
Loss = 2.4985e-03, PNorm = 37.2971, GNorm = 0.8221, lr_0 = 9.5479e-04
Loss = 3.1115e-03, PNorm = 37.3143, GNorm = 1.8813, lr_0 = 9.5380e-04
Validation rmse logD = 0.724253
Validation R2 logD = 0.633147
Validation rmse logP = 0.591757
Validation R2 logP = 0.903603
Epoch 4
Train function
Loss = 2.0705e-03, PNorm = 37.3479, GNorm = 0.8599, lr_0 = 9.5270e-04
Loss = 2.3107e-03, PNorm = 37.3709, GNorm = 0.8527, lr_0 = 9.5171e-04
Loss = 2.5842e-03, PNorm = 37.3951, GNorm = 2.6153, lr_0 = 9.5071e-04
Loss = 2.5753e-03, PNorm = 37.4265, GNorm = 1.2196, lr_0 = 9.4972e-04
Loss = 2.2702e-03, PNorm = 37.4536, GNorm = 0.8524, lr_0 = 9.4873e-04
Loss = 2.6867e-03, PNorm = 37.4776, GNorm = 1.2419, lr_0 = 9.4774e-04
Loss = 2.9355e-03, PNorm = 37.4995, GNorm = 1.2074, lr_0 = 9.4675e-04
Loss = 2.7933e-03, PNorm = 37.5316, GNorm = 2.8635, lr_0 = 9.4576e-04
Loss = 2.7762e-03, PNorm = 37.5680, GNorm = 1.7573, lr_0 = 9.4478e-04
Loss = 3.3659e-03, PNorm = 37.6004, GNorm = 1.6474, lr_0 = 9.4379e-04
Loss = 2.5243e-03, PNorm = 37.6368, GNorm = 1.3246, lr_0 = 9.4280e-04
Loss = 2.7198e-03, PNorm = 37.6777, GNorm = 1.5593, lr_0 = 9.4182e-04
Loss = 2.9325e-03, PNorm = 37.7102, GNorm = 1.6313, lr_0 = 9.4084e-04
Loss = 2.4453e-03, PNorm = 37.7294, GNorm = 1.2015, lr_0 = 9.3986e-04
Loss = 2.3716e-03, PNorm = 37.7455, GNorm = 0.7348, lr_0 = 9.3887e-04
Loss = 3.1044e-03, PNorm = 37.7777, GNorm = 1.0506, lr_0 = 9.3789e-04
Loss = 2.8759e-03, PNorm = 37.8048, GNorm = 2.0216, lr_0 = 9.3692e-04
Loss = 2.8055e-03, PNorm = 37.8317, GNorm = 1.6178, lr_0 = 9.3594e-04
Loss = 3.4447e-03, PNorm = 37.8579, GNorm = 1.1647, lr_0 = 9.3496e-04
Loss = 2.5967e-03, PNorm = 37.9007, GNorm = 0.4892, lr_0 = 9.3399e-04
Loss = 3.2199e-03, PNorm = 37.9248, GNorm = 0.8208, lr_0 = 9.3301e-04
Loss = 2.4377e-03, PNorm = 37.9459, GNorm = 0.9798, lr_0 = 9.3204e-04
Validation rmse logD = 0.750871
Validation R2 logD = 0.605685
Validation rmse logP = 0.660493
Validation R2 logP = 0.879909
Epoch 5
Train function
Loss = 3.4935e-03, PNorm = 37.9788, GNorm = 1.5248, lr_0 = 9.3106e-04
Loss = 2.5566e-03, PNorm = 38.0091, GNorm = 2.4225, lr_0 = 9.3009e-04
Loss = 2.4171e-03, PNorm = 38.0339, GNorm = 1.1823, lr_0 = 9.2912e-04
Loss = 2.7307e-03, PNorm = 38.0622, GNorm = 2.4976, lr_0 = 9.2815e-04
Loss = 2.7589e-03, PNorm = 38.0944, GNorm = 0.9575, lr_0 = 9.2718e-04
Loss = 2.9620e-03, PNorm = 38.1345, GNorm = 0.9856, lr_0 = 9.2622e-04
Loss = 2.3637e-03, PNorm = 38.1724, GNorm = 0.7640, lr_0 = 9.2525e-04
Loss = 2.2658e-03, PNorm = 38.2042, GNorm = 1.1233, lr_0 = 9.2428e-04
Loss = 2.3378e-03, PNorm = 38.2305, GNorm = 0.7452, lr_0 = 9.2332e-04
Loss = 2.4747e-03, PNorm = 38.2480, GNorm = 1.4221, lr_0 = 9.2235e-04
Loss = 2.5573e-03, PNorm = 38.2764, GNorm = 2.0941, lr_0 = 9.2139e-04
Loss = 2.9111e-03, PNorm = 38.3042, GNorm = 1.0631, lr_0 = 9.2043e-04
Loss = 2.7511e-03, PNorm = 38.3407, GNorm = 1.3758, lr_0 = 9.1947e-04
Loss = 2.2644e-03, PNorm = 38.3693, GNorm = 0.5925, lr_0 = 9.1851e-04
Loss = 2.2130e-03, PNorm = 38.3941, GNorm = 1.4364, lr_0 = 9.1755e-04
Loss = 3.0309e-03, PNorm = 38.4055, GNorm = 1.4506, lr_0 = 9.1659e-04
Loss = 2.5500e-03, PNorm = 38.4296, GNorm = 1.0440, lr_0 = 9.1564e-04
Loss = 2.3933e-03, PNorm = 38.4495, GNorm = 1.3062, lr_0 = 9.1468e-04
Loss = 2.2083e-03, PNorm = 38.4756, GNorm = 1.3693, lr_0 = 9.1373e-04
Loss = 1.8771e-03, PNorm = 38.5045, GNorm = 0.9581, lr_0 = 9.1277e-04
Loss = 2.0494e-03, PNorm = 38.5305, GNorm = 1.0243, lr_0 = 9.1182e-04
Loss = 2.0717e-03, PNorm = 38.5618, GNorm = 1.3444, lr_0 = 9.1087e-04
Loss = 2.5271e-03, PNorm = 38.5915, GNorm = 1.2314, lr_0 = 9.0992e-04
Validation rmse logD = 0.714466
Validation R2 logD = 0.642994
Validation rmse logP = 0.549506
Validation R2 logP = 0.916877
Epoch 6
Train function
Loss = 2.8042e-03, PNorm = 38.6211, GNorm = 2.2463, lr_0 = 9.0887e-04
Loss = 2.2023e-03, PNorm = 38.6391, GNorm = 0.9680, lr_0 = 9.0792e-04
Loss = 2.1188e-03, PNorm = 38.6680, GNorm = 1.6145, lr_0 = 9.0698e-04
Loss = 2.0070e-03, PNorm = 38.6863, GNorm = 1.2918, lr_0 = 9.0603e-04
Loss = 1.9091e-03, PNorm = 38.7190, GNorm = 1.4519, lr_0 = 9.0508e-04
Loss = 2.8962e-03, PNorm = 38.7397, GNorm = 2.6468, lr_0 = 9.0414e-04
Loss = 2.0513e-03, PNorm = 38.7682, GNorm = 1.3973, lr_0 = 9.0320e-04
Loss = 1.9960e-03, PNorm = 38.8010, GNorm = 0.8151, lr_0 = 9.0225e-04
Loss = 2.5483e-03, PNorm = 38.8319, GNorm = 1.2384, lr_0 = 9.0131e-04
Loss = 2.1484e-03, PNorm = 38.8671, GNorm = 1.0508, lr_0 = 9.0037e-04
Loss = 1.7506e-03, PNorm = 38.9033, GNorm = 0.6756, lr_0 = 8.9943e-04
Loss = 1.8758e-03, PNorm = 38.9222, GNorm = 0.8490, lr_0 = 8.9849e-04
Loss = 2.7173e-03, PNorm = 38.9597, GNorm = 0.8946, lr_0 = 8.9756e-04
Loss = 2.0794e-03, PNorm = 38.9811, GNorm = 1.5586, lr_0 = 8.9662e-04
Loss = 2.0432e-03, PNorm = 39.0094, GNorm = 0.6782, lr_0 = 8.9568e-04
Loss = 1.6395e-03, PNorm = 39.0345, GNorm = 1.1230, lr_0 = 8.9475e-04
Loss = 2.1477e-03, PNorm = 39.0626, GNorm = 1.1751, lr_0 = 8.9381e-04
Loss = 2.0656e-03, PNorm = 39.0843, GNorm = 1.8185, lr_0 = 8.9288e-04
Loss = 2.3211e-03, PNorm = 39.1046, GNorm = 1.4362, lr_0 = 8.9195e-04
Loss = 2.2543e-03, PNorm = 39.1267, GNorm = 0.5083, lr_0 = 8.9102e-04
Loss = 2.3050e-03, PNorm = 39.1533, GNorm = 0.7521, lr_0 = 8.9009e-04
Loss = 1.7230e-03, PNorm = 39.1719, GNorm = 0.7125, lr_0 = 8.8916e-04
Validation rmse logD = 0.694142
Validation R2 logD = 0.663016
Validation rmse logP = 0.557383
Validation R2 logP = 0.914477
Epoch 7
Train function
Loss = 2.1703e-03, PNorm = 39.2013, GNorm = 1.4654, lr_0 = 8.8823e-04
Loss = 1.7278e-03, PNorm = 39.2273, GNorm = 0.9457, lr_0 = 8.8730e-04
Loss = 1.4814e-03, PNorm = 39.2531, GNorm = 0.7003, lr_0 = 8.8638e-04
Loss = 1.5647e-03, PNorm = 39.2728, GNorm = 0.7731, lr_0 = 8.8545e-04
Loss = 2.1106e-03, PNorm = 39.2945, GNorm = 1.4330, lr_0 = 8.8453e-04
Loss = 1.3726e-03, PNorm = 39.3161, GNorm = 0.5047, lr_0 = 8.8361e-04
Loss = 1.6515e-03, PNorm = 39.3413, GNorm = 0.5682, lr_0 = 8.8268e-04
Loss = 2.2264e-03, PNorm = 39.3596, GNorm = 0.9900, lr_0 = 8.8176e-04
Loss = 2.1358e-03, PNorm = 39.3805, GNorm = 0.8245, lr_0 = 8.8084e-04
Loss = 1.8388e-03, PNorm = 39.3992, GNorm = 0.9823, lr_0 = 8.7992e-04
Loss = 1.8428e-03, PNorm = 39.4318, GNorm = 1.0608, lr_0 = 8.7900e-04
Loss = 2.8377e-03, PNorm = 39.4547, GNorm = 1.6794, lr_0 = 8.7809e-04
Loss = 1.9930e-03, PNorm = 39.4860, GNorm = 1.2421, lr_0 = 8.7717e-04
Loss = 1.9046e-03, PNorm = 39.5221, GNorm = 1.8465, lr_0 = 8.7625e-04
Loss = 2.3597e-03, PNorm = 39.5541, GNorm = 1.3232, lr_0 = 8.7534e-04
Loss = 2.2544e-03, PNorm = 39.5853, GNorm = 1.4043, lr_0 = 8.7443e-04
Loss = 1.8434e-03, PNorm = 39.6201, GNorm = 1.9302, lr_0 = 8.7351e-04
Loss = 1.9941e-03, PNorm = 39.6492, GNorm = 0.5000, lr_0 = 8.7260e-04
Loss = 1.8365e-03, PNorm = 39.6793, GNorm = 0.9536, lr_0 = 8.7169e-04
Loss = 1.8100e-03, PNorm = 39.7031, GNorm = 0.7562, lr_0 = 8.7078e-04
Loss = 2.2027e-03, PNorm = 39.7252, GNorm = 0.8522, lr_0 = 8.6987e-04
Loss = 2.0183e-03, PNorm = 39.7523, GNorm = 1.0112, lr_0 = 8.6896e-04
Loss = 1.9280e-03, PNorm = 39.7802, GNorm = 0.9518, lr_0 = 8.6806e-04
Validation rmse logD = 0.765450
Validation R2 logD = 0.590224
Validation rmse logP = 0.573843
Validation R2 logP = 0.909352
Epoch 8
Train function
Loss = 2.0204e-03, PNorm = 39.8002, GNorm = 0.8338, lr_0 = 8.6706e-04
Loss = 1.8089e-03, PNorm = 39.8314, GNorm = 1.4821, lr_0 = 8.6616e-04
Loss = 2.1955e-03, PNorm = 39.8504, GNorm = 0.5007, lr_0 = 8.6525e-04
Loss = 1.5899e-03, PNorm = 39.8791, GNorm = 1.1620, lr_0 = 8.6435e-04
Loss = 1.7880e-03, PNorm = 39.9062, GNorm = 1.4630, lr_0 = 8.6345e-04
Loss = 1.6261e-03, PNorm = 39.9251, GNorm = 1.1327, lr_0 = 8.6255e-04
Loss = 1.6256e-03, PNorm = 39.9517, GNorm = 1.0080, lr_0 = 8.6165e-04
Loss = 1.6783e-03, PNorm = 39.9718, GNorm = 0.9253, lr_0 = 8.6075e-04
Loss = 1.8395e-03, PNorm = 39.9824, GNorm = 1.4438, lr_0 = 8.5985e-04
Loss = 1.5850e-03, PNorm = 40.0017, GNorm = 0.3699, lr_0 = 8.5895e-04
Loss = 1.7470e-03, PNorm = 40.0264, GNorm = 0.7576, lr_0 = 8.5805e-04
Loss = 1.7210e-03, PNorm = 40.0440, GNorm = 1.0126, lr_0 = 8.5716e-04
Loss = 1.8450e-03, PNorm = 40.0774, GNorm = 1.5217, lr_0 = 8.5626e-04
Loss = 1.6290e-03, PNorm = 40.1038, GNorm = 1.2336, lr_0 = 8.5537e-04
Loss = 1.8200e-03, PNorm = 40.1249, GNorm = 1.0798, lr_0 = 8.5448e-04
Loss = 1.7788e-03, PNorm = 40.1523, GNorm = 1.9296, lr_0 = 8.5359e-04
Loss = 1.8573e-03, PNorm = 40.1831, GNorm = 1.0015, lr_0 = 8.5269e-04
Loss = 1.6414e-03, PNorm = 40.2168, GNorm = 0.8884, lr_0 = 8.5180e-04
Loss = 1.7159e-03, PNorm = 40.2368, GNorm = 1.3457, lr_0 = 8.5092e-04
Loss = 1.8769e-03, PNorm = 40.2556, GNorm = 1.0909, lr_0 = 8.5003e-04
Loss = 1.5969e-03, PNorm = 40.2848, GNorm = 0.7446, lr_0 = 8.4914e-04
Loss = 1.5320e-03, PNorm = 40.3041, GNorm = 0.8242, lr_0 = 8.4825e-04
Validation rmse logD = 0.663055
Validation R2 logD = 0.692524
Validation rmse logP = 0.519441
Validation R2 logP = 0.925725
Epoch 9
Train function
Loss = 7.9141e-04, PNorm = 40.3357, GNorm = 0.4673, lr_0 = 8.4737e-04
Loss = 1.3950e-03, PNorm = 40.3620, GNorm = 1.5063, lr_0 = 8.4648e-04
Loss = 1.4257e-03, PNorm = 40.3867, GNorm = 0.8656, lr_0 = 8.4560e-04
Loss = 1.0844e-03, PNorm = 40.4072, GNorm = 0.7841, lr_0 = 8.4472e-04
Loss = 1.2958e-03, PNorm = 40.4250, GNorm = 1.2089, lr_0 = 8.4384e-04
Loss = 1.3842e-03, PNorm = 40.4460, GNorm = 0.6705, lr_0 = 8.4296e-04
Loss = 1.5725e-03, PNorm = 40.4697, GNorm = 1.2918, lr_0 = 8.4208e-04
Loss = 1.5348e-03, PNorm = 40.4901, GNorm = 1.1498, lr_0 = 8.4120e-04
Loss = 1.5106e-03, PNorm = 40.5126, GNorm = 0.6244, lr_0 = 8.4032e-04
Loss = 1.7415e-03, PNorm = 40.5358, GNorm = 1.4120, lr_0 = 8.3944e-04
Loss = 1.5589e-03, PNorm = 40.5650, GNorm = 0.6583, lr_0 = 8.3857e-04
Loss = 1.7201e-03, PNorm = 40.5946, GNorm = 0.7958, lr_0 = 8.3769e-04
Loss = 1.4608e-03, PNorm = 40.6142, GNorm = 0.6664, lr_0 = 8.3682e-04
Loss = 1.3269e-03, PNorm = 40.6310, GNorm = 0.7539, lr_0 = 8.3594e-04
Loss = 1.7345e-03, PNorm = 40.6533, GNorm = 1.3251, lr_0 = 8.3507e-04
Loss = 1.4997e-03, PNorm = 40.6859, GNorm = 1.1627, lr_0 = 8.3420e-04
Loss = 1.9569e-03, PNorm = 40.7043, GNorm = 1.0967, lr_0 = 8.3333e-04
Loss = 1.5133e-03, PNorm = 40.7304, GNorm = 1.6241, lr_0 = 8.3246e-04
Loss = 1.3198e-03, PNorm = 40.7630, GNorm = 0.5829, lr_0 = 8.3159e-04
Loss = 1.5745e-03, PNorm = 40.7801, GNorm = 0.7273, lr_0 = 8.3072e-04
Loss = 1.4949e-03, PNorm = 40.8038, GNorm = 1.2576, lr_0 = 8.2986e-04
Loss = 1.6289e-03, PNorm = 40.8162, GNorm = 0.8191, lr_0 = 8.2899e-04
Loss = 1.5520e-03, PNorm = 40.8375, GNorm = 0.6177, lr_0 = 8.2812e-04
Validation rmse logD = 0.719077
Validation R2 logD = 0.638371
Validation rmse logP = 0.511442
Validation R2 logP = 0.927994
Epoch 10
Train function
Loss = 1.5123e-03, PNorm = 40.8584, GNorm = 1.7028, lr_0 = 8.2717e-04
Loss = 1.4497e-03, PNorm = 40.8724, GNorm = 1.4741, lr_0 = 8.2631e-04
Loss = 1.3188e-03, PNorm = 40.8962, GNorm = 0.8155, lr_0 = 8.2545e-04
Loss = 1.4393e-03, PNorm = 40.9279, GNorm = 0.7508, lr_0 = 8.2459e-04
Loss = 1.6674e-03, PNorm = 40.9548, GNorm = 0.6739, lr_0 = 8.2373e-04
Loss = 1.1952e-03, PNorm = 40.9766, GNorm = 0.7035, lr_0 = 8.2287e-04
Loss = 1.4609e-03, PNorm = 41.0034, GNorm = 0.9022, lr_0 = 8.2201e-04
Loss = 1.5111e-03, PNorm = 41.0297, GNorm = 1.3652, lr_0 = 8.2115e-04
Loss = 1.6068e-03, PNorm = 41.0526, GNorm = 0.8141, lr_0 = 8.2029e-04
Loss = 1.3943e-03, PNorm = 41.0732, GNorm = 1.3531, lr_0 = 8.1944e-04
Loss = 1.4310e-03, PNorm = 41.1063, GNorm = 0.4838, lr_0 = 8.1858e-04
Loss = 1.1070e-03, PNorm = 41.1324, GNorm = 1.1204, lr_0 = 8.1773e-04
Loss = 1.3845e-03, PNorm = 41.1599, GNorm = 0.7002, lr_0 = 8.1687e-04
Loss = 1.7358e-03, PNorm = 41.1940, GNorm = 0.5885, lr_0 = 8.1602e-04
Loss = 1.5914e-03, PNorm = 41.2190, GNorm = 0.6711, lr_0 = 8.1517e-04
Loss = 1.6033e-03, PNorm = 41.2377, GNorm = 0.9348, lr_0 = 8.1432e-04
Loss = 1.3997e-03, PNorm = 41.2580, GNorm = 0.5675, lr_0 = 8.1347e-04
Loss = 1.3577e-03, PNorm = 41.2831, GNorm = 0.8200, lr_0 = 8.1262e-04
Loss = 1.1424e-03, PNorm = 41.3010, GNorm = 0.4920, lr_0 = 8.1177e-04
Loss = 1.3693e-03, PNorm = 41.3174, GNorm = 0.6688, lr_0 = 8.1092e-04
Loss = 1.3373e-03, PNorm = 41.3315, GNorm = 0.6560, lr_0 = 8.1008e-04
Loss = 1.7498e-03, PNorm = 41.3548, GNorm = 0.4593, lr_0 = 8.0923e-04
Loss = 1.4316e-03, PNorm = 41.3799, GNorm = 0.6072, lr_0 = 8.0839e-04
Validation rmse logD = 0.672780
Validation R2 logD = 0.683439
Validation rmse logP = 0.499437
Validation R2 logP = 0.931335
Epoch 11
Train function
Loss = 1.1962e-03, PNorm = 41.3985, GNorm = 1.1785, lr_0 = 8.0754e-04
Loss = 1.0669e-03, PNorm = 41.4141, GNorm = 0.5019, lr_0 = 8.0670e-04
Loss = 1.3766e-03, PNorm = 41.4421, GNorm = 0.3642, lr_0 = 8.0586e-04
Loss = 1.3436e-03, PNorm = 41.4613, GNorm = 0.5124, lr_0 = 8.0502e-04
Loss = 1.3518e-03, PNorm = 41.4863, GNorm = 0.7896, lr_0 = 8.0418e-04
Loss = 1.5096e-03, PNorm = 41.5148, GNorm = 0.9988, lr_0 = 8.0334e-04
Loss = 1.3866e-03, PNorm = 41.5411, GNorm = 1.0166, lr_0 = 8.0250e-04
Loss = 1.1837e-03, PNorm = 41.5544, GNorm = 0.7855, lr_0 = 8.0166e-04
Loss = 1.1660e-03, PNorm = 41.5722, GNorm = 0.7470, lr_0 = 8.0082e-04
Loss = 1.1653e-03, PNorm = 41.5922, GNorm = 0.9974, lr_0 = 7.9999e-04
Loss = 1.0279e-03, PNorm = 41.6129, GNorm = 0.6145, lr_0 = 7.9915e-04
Loss = 1.2354e-03, PNorm = 41.6295, GNorm = 0.8629, lr_0 = 7.9832e-04
Loss = 1.3967e-03, PNorm = 41.6438, GNorm = 1.4015, lr_0 = 7.9749e-04
Loss = 1.5024e-03, PNorm = 41.6687, GNorm = 1.6413, lr_0 = 7.9665e-04
Loss = 1.3092e-03, PNorm = 41.7010, GNorm = 0.6214, lr_0 = 7.9582e-04
Loss = 1.5275e-03, PNorm = 41.7265, GNorm = 1.5335, lr_0 = 7.9499e-04
Loss = 1.1113e-03, PNorm = 41.7588, GNorm = 1.5540, lr_0 = 7.9416e-04
Loss = 1.4919e-03, PNorm = 41.7829, GNorm = 0.5457, lr_0 = 7.9333e-04
Loss = 1.6123e-03, PNorm = 41.8082, GNorm = 0.9642, lr_0 = 7.9251e-04
Loss = 1.1870e-03, PNorm = 41.8237, GNorm = 0.6089, lr_0 = 7.9168e-04
Loss = 1.7556e-03, PNorm = 41.8452, GNorm = 1.4757, lr_0 = 7.9085e-04
Loss = 1.6652e-03, PNorm = 41.8694, GNorm = 1.5301, lr_0 = 7.9003e-04
Validation rmse logD = 0.717849
Validation R2 logD = 0.639605
Validation rmse logP = 0.610379
Validation R2 logP = 0.897441
Epoch 12
Train function
Loss = 1.2378e-03, PNorm = 41.8915, GNorm = 1.8148, lr_0 = 7.8912e-04
Loss = 1.4159e-03, PNorm = 41.9190, GNorm = 0.9253, lr_0 = 7.8830e-04
Loss = 1.1736e-03, PNorm = 41.9466, GNorm = 0.8079, lr_0 = 7.8747e-04
Loss = 1.2429e-03, PNorm = 41.9699, GNorm = 1.2943, lr_0 = 7.8665e-04
Loss = 1.1462e-03, PNorm = 41.9989, GNorm = 0.4395, lr_0 = 7.8583e-04
Loss = 1.2592e-03, PNorm = 42.0181, GNorm = 0.9023, lr_0 = 7.8501e-04
Loss = 1.1841e-03, PNorm = 42.0355, GNorm = 0.8178, lr_0 = 7.8419e-04
Loss = 9.1932e-04, PNorm = 42.0517, GNorm = 0.9985, lr_0 = 7.8337e-04
Loss = 1.1366e-03, PNorm = 42.0605, GNorm = 0.8817, lr_0 = 7.8255e-04
Loss = 1.7977e-03, PNorm = 42.0782, GNorm = 1.7878, lr_0 = 7.8174e-04
Loss = 1.5463e-03, PNorm = 42.1124, GNorm = 0.8063, lr_0 = 7.8092e-04
Loss = 1.3120e-03, PNorm = 42.1349, GNorm = 1.1122, lr_0 = 7.8011e-04
Loss = 1.0248e-03, PNorm = 42.1523, GNorm = 0.4231, lr_0 = 7.7929e-04
Loss = 1.2203e-03, PNorm = 42.1730, GNorm = 1.5189, lr_0 = 7.7848e-04
Loss = 1.0981e-03, PNorm = 42.1928, GNorm = 0.9081, lr_0 = 7.7767e-04
Loss = 1.1593e-03, PNorm = 42.2166, GNorm = 0.4281, lr_0 = 7.7686e-04
Loss = 1.1607e-03, PNorm = 42.2384, GNorm = 0.6640, lr_0 = 7.7604e-04
Loss = 1.0677e-03, PNorm = 42.2565, GNorm = 0.9647, lr_0 = 7.7523e-04
Loss = 1.3928e-03, PNorm = 42.2681, GNorm = 0.5055, lr_0 = 7.7443e-04
Loss = 1.1092e-03, PNorm = 42.2886, GNorm = 0.6940, lr_0 = 7.7362e-04
Loss = 1.2764e-03, PNorm = 42.3093, GNorm = 0.6600, lr_0 = 7.7281e-04
Loss = 9.6936e-04, PNorm = 42.3249, GNorm = 1.3981, lr_0 = 7.7200e-04
Loss = 1.0547e-03, PNorm = 42.3463, GNorm = 0.7416, lr_0 = 7.7120e-04
Validation rmse logD = 0.674060
Validation R2 logD = 0.682233
Validation rmse logP = 0.490265
Validation R2 logP = 0.933834
Epoch 13
Train function
Loss = 1.2351e-03, PNorm = 42.3646, GNorm = 0.8981, lr_0 = 7.7039e-04
Loss = 1.0045e-03, PNorm = 42.3846, GNorm = 0.5955, lr_0 = 7.6959e-04
Loss = 1.0028e-03, PNorm = 42.3939, GNorm = 0.6924, lr_0 = 7.6879e-04
Loss = 9.8918e-04, PNorm = 42.4112, GNorm = 1.0526, lr_0 = 7.6798e-04
Loss = 1.1537e-03, PNorm = 42.4347, GNorm = 1.4137, lr_0 = 7.6718e-04
Loss = 9.7469e-04, PNorm = 42.4522, GNorm = 0.7463, lr_0 = 7.6638e-04
Loss = 1.0026e-03, PNorm = 42.4646, GNorm = 0.8745, lr_0 = 7.6558e-04
Loss = 1.1769e-03, PNorm = 42.4861, GNorm = 0.8689, lr_0 = 7.6478e-04
Loss = 1.1703e-03, PNorm = 42.4992, GNorm = 0.8645, lr_0 = 7.6398e-04
Loss = 1.0958e-03, PNorm = 42.5266, GNorm = 1.1213, lr_0 = 7.6319e-04
Loss = 1.1603e-03, PNorm = 42.5466, GNorm = 0.7447, lr_0 = 7.6239e-04
Loss = 1.0422e-03, PNorm = 42.5705, GNorm = 0.4825, lr_0 = 7.6159e-04
Loss = 1.1863e-03, PNorm = 42.5919, GNorm = 0.7388, lr_0 = 7.6080e-04
Loss = 1.5003e-03, PNorm = 42.6088, GNorm = 0.9147, lr_0 = 7.6000e-04
Loss = 1.1679e-03, PNorm = 42.6329, GNorm = 0.7571, lr_0 = 7.5921e-04
Loss = 1.1019e-03, PNorm = 42.6586, GNorm = 0.8184, lr_0 = 7.5842e-04
Loss = 1.0876e-03, PNorm = 42.6785, GNorm = 0.5443, lr_0 = 7.5763e-04
Loss = 1.1760e-03, PNorm = 42.6931, GNorm = 0.4639, lr_0 = 7.5684e-04
Loss = 9.6726e-04, PNorm = 42.7130, GNorm = 0.7494, lr_0 = 7.5605e-04
Loss = 1.3761e-03, PNorm = 42.7434, GNorm = 0.9508, lr_0 = 7.5526e-04
Loss = 1.2535e-03, PNorm = 42.7651, GNorm = 0.6583, lr_0 = 7.5447e-04
Loss = 1.1460e-03, PNorm = 42.7906, GNorm = 0.5074, lr_0 = 7.5368e-04
Validation rmse logD = 0.655549
Validation R2 logD = 0.699446
Validation rmse logP = 0.487615
Validation R2 logP = 0.934547
Epoch 14
Train function
Loss = 6.6587e-04, PNorm = 42.8182, GNorm = 0.6405, lr_0 = 7.5282e-04
Loss = 9.3246e-04, PNorm = 42.8436, GNorm = 0.5876, lr_0 = 7.5203e-04
Loss = 9.8021e-04, PNorm = 42.8639, GNorm = 0.4065, lr_0 = 7.5125e-04
Loss = 8.6732e-04, PNorm = 42.8787, GNorm = 0.7288, lr_0 = 7.5046e-04
Loss = 1.2643e-03, PNorm = 42.8951, GNorm = 1.1569, lr_0 = 7.4968e-04
Loss = 1.3784e-03, PNorm = 42.9174, GNorm = 1.1889, lr_0 = 7.4890e-04
Loss = 1.0188e-03, PNorm = 42.9407, GNorm = 0.6671, lr_0 = 7.4811e-04
Loss = 1.1796e-03, PNorm = 42.9678, GNorm = 1.1645, lr_0 = 7.4733e-04
Loss = 1.0115e-03, PNorm = 42.9912, GNorm = 0.9592, lr_0 = 7.4655e-04
Loss = 1.0844e-03, PNorm = 43.0062, GNorm = 0.4922, lr_0 = 7.4577e-04
Loss = 1.3220e-03, PNorm = 43.0202, GNorm = 1.2869, lr_0 = 7.4500e-04
Loss = 1.1136e-03, PNorm = 43.0471, GNorm = 1.6421, lr_0 = 7.4422e-04
Loss = 1.1186e-03, PNorm = 43.0722, GNorm = 0.4621, lr_0 = 7.4344e-04
Loss = 9.6763e-04, PNorm = 43.0978, GNorm = 0.6477, lr_0 = 7.4267e-04
Loss = 9.6806e-04, PNorm = 43.1157, GNorm = 1.1017, lr_0 = 7.4189e-04
Loss = 9.3137e-04, PNorm = 43.1390, GNorm = 0.9774, lr_0 = 7.4112e-04
Loss = 1.0708e-03, PNorm = 43.1655, GNorm = 0.6503, lr_0 = 7.4034e-04
Loss = 7.6975e-04, PNorm = 43.1892, GNorm = 1.0308, lr_0 = 7.3957e-04
Loss = 9.5974e-04, PNorm = 43.2002, GNorm = 0.5479, lr_0 = 7.3880e-04
Loss = 9.0013e-04, PNorm = 43.2159, GNorm = 1.0128, lr_0 = 7.3803e-04
Loss = 8.0839e-04, PNorm = 43.2270, GNorm = 0.4005, lr_0 = 7.3726e-04
Loss = 9.9025e-04, PNorm = 43.2392, GNorm = 0.9986, lr_0 = 7.3649e-04
Loss = 9.6846e-04, PNorm = 43.2552, GNorm = 0.6047, lr_0 = 7.3572e-04
Validation rmse logD = 0.643053
Validation R2 logD = 0.710795
Validation rmse logP = 0.487234
Validation R2 logP = 0.934649
Epoch 15
Train function
Loss = 7.5805e-04, PNorm = 43.2711, GNorm = 0.9447, lr_0 = 7.3495e-04
Loss = 8.7945e-04, PNorm = 43.2792, GNorm = 0.9091, lr_0 = 7.3418e-04
Loss = 7.8140e-04, PNorm = 43.2962, GNorm = 0.8293, lr_0 = 7.3342e-04
Loss = 1.0177e-03, PNorm = 43.3104, GNorm = 0.4398, lr_0 = 7.3265e-04
Loss = 9.6188e-04, PNorm = 43.3383, GNorm = 0.4967, lr_0 = 7.3189e-04
Loss = 9.5274e-04, PNorm = 43.3576, GNorm = 0.4857, lr_0 = 7.3112e-04
Loss = 9.4593e-04, PNorm = 43.3779, GNorm = 0.7763, lr_0 = 7.3036e-04
Loss = 8.1888e-04, PNorm = 43.3975, GNorm = 0.6449, lr_0 = 7.2960e-04
Loss = 8.7284e-04, PNorm = 43.4184, GNorm = 0.6124, lr_0 = 7.2884e-04
Loss = 7.2416e-04, PNorm = 43.4338, GNorm = 0.6025, lr_0 = 7.2808e-04
Loss = 8.9644e-04, PNorm = 43.4495, GNorm = 0.6958, lr_0 = 7.2732e-04
Loss = 7.9102e-04, PNorm = 43.4618, GNorm = 0.5783, lr_0 = 7.2656e-04
Loss = 9.6176e-04, PNorm = 43.4789, GNorm = 1.2970, lr_0 = 7.2580e-04
Loss = 8.8066e-04, PNorm = 43.4886, GNorm = 0.5975, lr_0 = 7.2504e-04
Loss = 8.8670e-04, PNorm = 43.5076, GNorm = 0.6222, lr_0 = 7.2428e-04
Loss = 8.1105e-04, PNorm = 43.5209, GNorm = 0.4339, lr_0 = 7.2353e-04
Loss = 8.6664e-04, PNorm = 43.5400, GNorm = 0.5044, lr_0 = 7.2277e-04
Loss = 8.1607e-04, PNorm = 43.5522, GNorm = 0.2981, lr_0 = 7.2202e-04
Loss = 9.4491e-04, PNorm = 43.5641, GNorm = 1.0245, lr_0 = 7.2127e-04
Loss = 1.0671e-03, PNorm = 43.5891, GNorm = 0.6156, lr_0 = 7.2051e-04
Loss = 1.0001e-03, PNorm = 43.6098, GNorm = 0.7419, lr_0 = 7.1976e-04
Loss = 9.6079e-04, PNorm = 43.6262, GNorm = 0.5125, lr_0 = 7.1901e-04
Validation rmse logD = 0.655943
Validation R2 logD = 0.699085
Validation rmse logP = 0.499952
Validation R2 logP = 0.931193
Epoch 16
Train function
Loss = 6.8623e-04, PNorm = 43.6476, GNorm = 0.5544, lr_0 = 7.1818e-04
Loss = 5.7685e-04, PNorm = 43.6620, GNorm = 0.4348, lr_0 = 7.1743e-04
Loss = 7.7859e-04, PNorm = 43.6793, GNorm = 0.7022, lr_0 = 7.1669e-04
Loss = 8.0402e-04, PNorm = 43.6892, GNorm = 0.9156, lr_0 = 7.1594e-04
Loss = 7.8123e-04, PNorm = 43.7093, GNorm = 0.7191, lr_0 = 7.1519e-04
Loss = 9.0066e-04, PNorm = 43.7275, GNorm = 1.0781, lr_0 = 7.1444e-04
Loss = 9.0366e-04, PNorm = 43.7404, GNorm = 0.4510, lr_0 = 7.1370e-04
Loss = 9.2458e-04, PNorm = 43.7632, GNorm = 0.5169, lr_0 = 7.1295e-04
Loss = 9.9226e-04, PNorm = 43.7838, GNorm = 1.0018, lr_0 = 7.1221e-04
Loss = 7.9525e-04, PNorm = 43.7986, GNorm = 0.7029, lr_0 = 7.1147e-04
Loss = 8.1016e-04, PNorm = 43.8170, GNorm = 0.5073, lr_0 = 7.1072e-04
Loss = 1.0050e-03, PNorm = 43.8356, GNorm = 0.5870, lr_0 = 7.0998e-04
Loss = 9.3854e-04, PNorm = 43.8593, GNorm = 1.3374, lr_0 = 7.0924e-04
Loss = 1.1099e-03, PNorm = 43.8875, GNorm = 0.7790, lr_0 = 7.0850e-04
Loss = 9.6431e-04, PNorm = 43.9123, GNorm = 0.5750, lr_0 = 7.0776e-04
Loss = 1.0838e-03, PNorm = 43.9296, GNorm = 1.6291, lr_0 = 7.0702e-04
Loss = 9.5448e-04, PNorm = 43.9537, GNorm = 1.2088, lr_0 = 7.0628e-04
Loss = 1.0661e-03, PNorm = 43.9685, GNorm = 1.0932, lr_0 = 7.0555e-04
Loss = 1.0614e-03, PNorm = 43.9867, GNorm = 0.9094, lr_0 = 7.0481e-04
Loss = 1.0246e-03, PNorm = 44.0182, GNorm = 1.2691, lr_0 = 7.0408e-04
Loss = 8.8451e-04, PNorm = 44.0484, GNorm = 0.4305, lr_0 = 7.0334e-04
Loss = 7.5209e-04, PNorm = 44.0680, GNorm = 0.7650, lr_0 = 7.0261e-04
Loss = 7.8880e-04, PNorm = 44.0853, GNorm = 0.6526, lr_0 = 7.0187e-04
Validation rmse logD = 0.656234
Validation R2 logD = 0.698817
Validation rmse logP = 0.481769
Validation R2 logP = 0.936107
Epoch 17
Train function
Loss = 7.0742e-04, PNorm = 44.1019, GNorm = 0.7175, lr_0 = 7.0114e-04
Loss = 7.3873e-04, PNorm = 44.1234, GNorm = 0.5549, lr_0 = 7.0041e-04
Loss = 7.1603e-04, PNorm = 44.1399, GNorm = 0.4100, lr_0 = 6.9968e-04
Loss = 8.4234e-04, PNorm = 44.1504, GNorm = 0.4501, lr_0 = 6.9895e-04
Loss = 1.0329e-03, PNorm = 44.1726, GNorm = 0.4907, lr_0 = 6.9822e-04
Loss = 7.9919e-04, PNorm = 44.1931, GNorm = 0.7108, lr_0 = 6.9749e-04
Loss = 6.3988e-04, PNorm = 44.2092, GNorm = 0.7880, lr_0 = 6.9676e-04
Loss = 7.6076e-04, PNorm = 44.2238, GNorm = 0.7204, lr_0 = 6.9603e-04
Loss = 7.3267e-04, PNorm = 44.2338, GNorm = 0.4523, lr_0 = 6.9531e-04
Loss = 7.2898e-04, PNorm = 44.2496, GNorm = 0.8226, lr_0 = 6.9458e-04
Loss = 7.3552e-04, PNorm = 44.2616, GNorm = 0.7456, lr_0 = 6.9386e-04
Loss = 8.0937e-04, PNorm = 44.2760, GNorm = 0.6147, lr_0 = 6.9313e-04
Loss = 8.2779e-04, PNorm = 44.2918, GNorm = 0.5342, lr_0 = 6.9241e-04
Loss = 7.7700e-04, PNorm = 44.3026, GNorm = 0.5142, lr_0 = 6.9169e-04
Loss = 8.7422e-04, PNorm = 44.3166, GNorm = 0.5579, lr_0 = 6.9096e-04
Loss = 7.6080e-04, PNorm = 44.3368, GNorm = 0.4808, lr_0 = 6.9024e-04
Loss = 7.6699e-04, PNorm = 44.3514, GNorm = 0.5968, lr_0 = 6.8952e-04
Loss = 8.3159e-04, PNorm = 44.3723, GNorm = 0.4237, lr_0 = 6.8880e-04
Loss = 7.2105e-04, PNorm = 44.3892, GNorm = 0.6253, lr_0 = 6.8808e-04
Loss = 6.8458e-04, PNorm = 44.4018, GNorm = 0.6552, lr_0 = 6.8737e-04
Loss = 6.6437e-04, PNorm = 44.4138, GNorm = 0.5469, lr_0 = 6.8665e-04
Loss = 7.3932e-04, PNorm = 44.4245, GNorm = 0.3309, lr_0 = 6.8593e-04
Validation rmse logD = 0.646970
Validation R2 logD = 0.707261
Validation rmse logP = 0.472845
Validation R2 logP = 0.938452
Epoch 18
Train function
Loss = 6.3652e-04, PNorm = 44.4445, GNorm = 0.3890, lr_0 = 6.8514e-04
Loss = 5.3410e-04, PNorm = 44.4621, GNorm = 0.3841, lr_0 = 6.8443e-04
Loss = 5.9116e-04, PNorm = 44.4729, GNorm = 0.3932, lr_0 = 6.8372e-04
Loss = 5.1579e-04, PNorm = 44.4875, GNorm = 0.4919, lr_0 = 6.8300e-04
Loss = 7.5353e-04, PNorm = 44.5016, GNorm = 0.6422, lr_0 = 6.8229e-04
Loss = 7.1860e-04, PNorm = 44.5138, GNorm = 0.7980, lr_0 = 6.8158e-04
Loss = 6.8881e-04, PNorm = 44.5240, GNorm = 0.6963, lr_0 = 6.8087e-04
Loss = 7.7490e-04, PNorm = 44.5461, GNorm = 0.4079, lr_0 = 6.8015e-04
Loss = 6.1747e-04, PNorm = 44.5609, GNorm = 0.9554, lr_0 = 6.7944e-04
Loss = 6.7496e-04, PNorm = 44.5743, GNorm = 0.9051, lr_0 = 6.7874e-04
Loss = 7.8081e-04, PNorm = 44.5880, GNorm = 0.6084, lr_0 = 6.7803e-04
Loss = 8.3494e-04, PNorm = 44.5986, GNorm = 1.0464, lr_0 = 6.7732e-04
Loss = 7.6837e-04, PNorm = 44.6123, GNorm = 0.5473, lr_0 = 6.7661e-04
Loss = 7.1896e-04, PNorm = 44.6297, GNorm = 0.8660, lr_0 = 6.7591e-04
Loss = 6.2340e-04, PNorm = 44.6466, GNorm = 0.4334, lr_0 = 6.7520e-04
Loss = 7.0937e-04, PNorm = 44.6652, GNorm = 0.6054, lr_0 = 6.7450e-04
Loss = 7.2011e-04, PNorm = 44.6800, GNorm = 0.5872, lr_0 = 6.7379e-04
Loss = 6.5764e-04, PNorm = 44.6935, GNorm = 0.4243, lr_0 = 6.7309e-04
Loss = 6.8294e-04, PNorm = 44.7079, GNorm = 0.5579, lr_0 = 6.7239e-04
Loss = 8.8069e-04, PNorm = 44.7246, GNorm = 0.8958, lr_0 = 6.7168e-04
Loss = 8.5572e-04, PNorm = 44.7432, GNorm = 0.7675, lr_0 = 6.7098e-04
Loss = 7.8789e-04, PNorm = 44.7645, GNorm = 0.7480, lr_0 = 6.7028e-04
Loss = 9.8140e-04, PNorm = 44.7798, GNorm = 1.2652, lr_0 = 6.6958e-04
Validation rmse logD = 0.644513
Validation R2 logD = 0.709480
Validation rmse logP = 0.530784
Validation R2 logP = 0.922445
Epoch 19
Train function
Loss = 6.4000e-04, PNorm = 44.7957, GNorm = 0.5969, lr_0 = 6.6889e-04
Loss = 6.3082e-04, PNorm = 44.8143, GNorm = 0.6368, lr_0 = 6.6819e-04
Loss = 6.6694e-04, PNorm = 44.8337, GNorm = 0.5125, lr_0 = 6.6749e-04
Loss = 6.0463e-04, PNorm = 44.8480, GNorm = 0.5369, lr_0 = 6.6679e-04
Loss = 7.5614e-04, PNorm = 44.8573, GNorm = 0.8142, lr_0 = 6.6610e-04
Loss = 6.3847e-04, PNorm = 44.8718, GNorm = 1.1988, lr_0 = 6.6540e-04
Loss = 8.3334e-04, PNorm = 44.8850, GNorm = 0.5159, lr_0 = 6.6471e-04
Loss = 7.8949e-04, PNorm = 44.9110, GNorm = 0.6845, lr_0 = 6.6401e-04
Loss = 7.5881e-04, PNorm = 44.9314, GNorm = 0.4813, lr_0 = 6.6332e-04
Loss = 7.4680e-04, PNorm = 44.9491, GNorm = 0.9024, lr_0 = 6.6263e-04
Loss = 6.2566e-04, PNorm = 44.9635, GNorm = 0.5728, lr_0 = 6.6194e-04
Loss = 5.4451e-04, PNorm = 44.9772, GNorm = 0.5316, lr_0 = 6.6125e-04
Loss = 5.6796e-04, PNorm = 44.9874, GNorm = 0.7531, lr_0 = 6.6056e-04
Loss = 7.2511e-04, PNorm = 44.9966, GNorm = 0.3127, lr_0 = 6.5987e-04
Loss = 5.9268e-04, PNorm = 45.0076, GNorm = 0.5796, lr_0 = 6.5918e-04
Loss = 6.1665e-04, PNorm = 45.0190, GNorm = 0.7357, lr_0 = 6.5849e-04
Loss = 7.1816e-04, PNorm = 45.0314, GNorm = 0.9348, lr_0 = 6.5780e-04
Loss = 6.6561e-04, PNorm = 45.0516, GNorm = 0.3600, lr_0 = 6.5712e-04
Loss = 6.7516e-04, PNorm = 45.0634, GNorm = 0.4237, lr_0 = 6.5643e-04
Loss = 6.3745e-04, PNorm = 45.0783, GNorm = 0.5958, lr_0 = 6.5574e-04
Loss = 7.8347e-04, PNorm = 45.0976, GNorm = 0.6250, lr_0 = 6.5506e-04
Loss = 7.0458e-04, PNorm = 45.1152, GNorm = 0.5712, lr_0 = 6.5438e-04
Validation rmse logD = 0.666950
Validation R2 logD = 0.688901
Validation rmse logP = 0.470599
Validation R2 logP = 0.939036
Epoch 20
Train function
Loss = 5.7435e-04, PNorm = 45.1318, GNorm = 0.8311, lr_0 = 6.5363e-04
Loss = 5.1641e-04, PNorm = 45.1450, GNorm = 0.4620, lr_0 = 6.5294e-04
Loss = 5.5633e-04, PNorm = 45.1609, GNorm = 0.6039, lr_0 = 6.5226e-04
Loss = 5.4984e-04, PNorm = 45.1751, GNorm = 0.6782, lr_0 = 6.5158e-04
Loss = 4.4015e-04, PNorm = 45.1868, GNorm = 0.4851, lr_0 = 6.5090e-04
Loss = 6.3275e-04, PNorm = 45.1979, GNorm = 0.6246, lr_0 = 6.5022e-04
Loss = 5.8327e-04, PNorm = 45.2131, GNorm = 0.4279, lr_0 = 6.4954e-04
Loss = 6.6681e-04, PNorm = 45.2277, GNorm = 0.7611, lr_0 = 6.4886e-04
Loss = 5.3747e-04, PNorm = 45.2447, GNorm = 0.6605, lr_0 = 6.4819e-04
Loss = 6.3328e-04, PNorm = 45.2640, GNorm = 0.5013, lr_0 = 6.4751e-04
Loss = 6.4033e-04, PNorm = 45.2835, GNorm = 0.8953, lr_0 = 6.4684e-04
Loss = 5.9383e-04, PNorm = 45.3012, GNorm = 0.4933, lr_0 = 6.4616e-04
Loss = 7.2522e-04, PNorm = 45.3127, GNorm = 1.0175, lr_0 = 6.4549e-04
Loss = 7.3087e-04, PNorm = 45.3302, GNorm = 1.3861, lr_0 = 6.4481e-04
Loss = 6.2157e-04, PNorm = 45.3463, GNorm = 0.9281, lr_0 = 6.4414e-04
Loss = 8.3683e-04, PNorm = 45.3665, GNorm = 0.8846, lr_0 = 6.4347e-04
Loss = 6.2662e-04, PNorm = 45.3819, GNorm = 0.7557, lr_0 = 6.4280e-04
Loss = 8.2713e-04, PNorm = 45.3971, GNorm = 0.8443, lr_0 = 6.4212e-04
Loss = 7.2201e-04, PNorm = 45.4146, GNorm = 0.4015, lr_0 = 6.4145e-04
Loss = 8.5954e-04, PNorm = 45.4325, GNorm = 0.7904, lr_0 = 6.4078e-04
Loss = 7.0028e-04, PNorm = 45.4542, GNorm = 1.1263, lr_0 = 6.4012e-04
Loss = 6.6530e-04, PNorm = 45.4708, GNorm = 0.3324, lr_0 = 6.3945e-04
Loss = 5.6556e-04, PNorm = 45.4847, GNorm = 0.5584, lr_0 = 6.3878e-04
Validation rmse logD = 0.646029
Validation R2 logD = 0.708112
Validation rmse logP = 0.472561
Validation R2 logP = 0.938526
Epoch 21
Train function
Loss = 5.0931e-04, PNorm = 45.4990, GNorm = 0.4049, lr_0 = 6.3811e-04
Loss = 5.9007e-04, PNorm = 45.5152, GNorm = 0.3197, lr_0 = 6.3745e-04
Loss = 6.5883e-04, PNorm = 45.5340, GNorm = 0.7976, lr_0 = 6.3678e-04
Loss = 4.5973e-04, PNorm = 45.5474, GNorm = 0.3753, lr_0 = 6.3612e-04
Loss = 5.7441e-04, PNorm = 45.5562, GNorm = 0.4369, lr_0 = 6.3545e-04
Loss = 4.7902e-04, PNorm = 45.5707, GNorm = 0.5142, lr_0 = 6.3479e-04
Loss = 4.8837e-04, PNorm = 45.5817, GNorm = 0.6257, lr_0 = 6.3413e-04
Loss = 5.2894e-04, PNorm = 45.5930, GNorm = 0.7251, lr_0 = 6.3347e-04
Loss = 4.9128e-04, PNorm = 45.6050, GNorm = 0.4316, lr_0 = 6.3280e-04
Loss = 4.6828e-04, PNorm = 45.6153, GNorm = 0.7165, lr_0 = 6.3214e-04
Loss = 5.3094e-04, PNorm = 45.6292, GNorm = 0.4209, lr_0 = 6.3148e-04
Loss = 6.6354e-04, PNorm = 45.6451, GNorm = 0.5908, lr_0 = 6.3083e-04
Loss = 7.0777e-04, PNorm = 45.6618, GNorm = 1.2764, lr_0 = 6.3017e-04
Loss = 5.7899e-04, PNorm = 45.6714, GNorm = 0.6170, lr_0 = 6.2951e-04
Loss = 5.1098e-04, PNorm = 45.6869, GNorm = 0.3419, lr_0 = 6.2885e-04
Loss = 5.4723e-04, PNorm = 45.6998, GNorm = 0.3627, lr_0 = 6.2820e-04
Loss = 6.1214e-04, PNorm = 45.7119, GNorm = 0.4994, lr_0 = 6.2754e-04
Loss = 6.2605e-04, PNorm = 45.7257, GNorm = 0.6019, lr_0 = 6.2689e-04
Loss = 4.8131e-04, PNorm = 45.7449, GNorm = 0.3238, lr_0 = 6.2623e-04
Loss = 5.6557e-04, PNorm = 45.7565, GNorm = 0.7606, lr_0 = 6.2558e-04
Loss = 5.5317e-04, PNorm = 45.7645, GNorm = 0.5972, lr_0 = 6.2492e-04
Loss = 7.4447e-04, PNorm = 45.7729, GNorm = 0.9068, lr_0 = 6.2427e-04
Loss = 6.8920e-04, PNorm = 45.7867, GNorm = 0.5781, lr_0 = 6.2362e-04
Loss = 1.9912e-03, PNorm = 45.7889, GNorm = 1.2789, lr_0 = 6.2356e-04
Validation rmse logD = 0.655944
Validation R2 logD = 0.699084
Validation rmse logP = 0.469600
Validation R2 logP = 0.939294
Epoch 22
Train function
Loss = 6.5275e-04, PNorm = 45.8064, GNorm = 0.7535, lr_0 = 6.2290e-04
Loss = 5.8625e-04, PNorm = 45.8239, GNorm = 0.6753, lr_0 = 6.2225e-04
Loss = 5.1399e-04, PNorm = 45.8397, GNorm = 0.7295, lr_0 = 6.2161e-04
Loss = 5.3393e-04, PNorm = 45.8534, GNorm = 0.6087, lr_0 = 6.2096e-04
Loss = 6.7863e-04, PNorm = 45.8701, GNorm = 0.6466, lr_0 = 6.2031e-04
Loss = 6.0525e-04, PNorm = 45.8831, GNorm = 0.6143, lr_0 = 6.1966e-04
Loss = 5.5645e-04, PNorm = 45.9011, GNorm = 0.5871, lr_0 = 6.1901e-04
Loss = 4.5634e-04, PNorm = 45.9117, GNorm = 0.5028, lr_0 = 6.1837e-04
Loss = 4.8860e-04, PNorm = 45.9209, GNorm = 0.3807, lr_0 = 6.1772e-04
Loss = 4.3636e-04, PNorm = 45.9354, GNorm = 0.6246, lr_0 = 6.1708e-04
Loss = 5.8708e-04, PNorm = 45.9456, GNorm = 0.6191, lr_0 = 6.1643e-04
Loss = 6.9765e-04, PNorm = 45.9634, GNorm = 1.2652, lr_0 = 6.1579e-04
Loss = 8.5439e-04, PNorm = 45.9873, GNorm = 1.1126, lr_0 = 6.1515e-04
Loss = 8.8393e-04, PNorm = 46.0031, GNorm = 1.0196, lr_0 = 6.1451e-04
Loss = 7.1425e-04, PNorm = 46.0204, GNorm = 0.3240, lr_0 = 6.1386e-04
Loss = 7.7848e-04, PNorm = 46.0421, GNorm = 0.8067, lr_0 = 6.1322e-04
Loss = 8.7192e-04, PNorm = 46.0610, GNorm = 0.7589, lr_0 = 6.1258e-04
Loss = 6.9828e-04, PNorm = 46.0803, GNorm = 0.4448, lr_0 = 6.1194e-04
Loss = 5.2361e-04, PNorm = 46.0937, GNorm = 0.4233, lr_0 = 6.1131e-04
Loss = 5.7881e-04, PNorm = 46.1112, GNorm = 0.4461, lr_0 = 6.1067e-04
Loss = 4.8798e-04, PNorm = 46.1244, GNorm = 0.4605, lr_0 = 6.1003e-04
Loss = 6.1819e-04, PNorm = 46.1369, GNorm = 0.9646, lr_0 = 6.0939e-04
Validation rmse logD = 0.629033
Validation R2 logD = 0.723268
Validation rmse logP = 0.466401
Validation R2 logP = 0.940118
Epoch 23
Train function
Loss = 5.4000e-04, PNorm = 46.1475, GNorm = 0.9424, lr_0 = 6.0876e-04
Loss = 5.7004e-04, PNorm = 46.1604, GNorm = 0.4148, lr_0 = 6.0812e-04
Loss = 4.4710e-04, PNorm = 46.1734, GNorm = 0.4648, lr_0 = 6.0749e-04
Loss = 4.3779e-04, PNorm = 46.1836, GNorm = 0.4476, lr_0 = 6.0685e-04
Loss = 4.2561e-04, PNorm = 46.1959, GNorm = 0.5767, lr_0 = 6.0622e-04
Loss = 5.4672e-04, PNorm = 46.2091, GNorm = 0.4055, lr_0 = 6.0559e-04
Loss = 3.9967e-04, PNorm = 46.2247, GNorm = 0.5020, lr_0 = 6.0496e-04
Loss = 3.9448e-04, PNorm = 46.2336, GNorm = 0.4005, lr_0 = 6.0432e-04
Loss = 4.9794e-04, PNorm = 46.2493, GNorm = 0.5588, lr_0 = 6.0369e-04
Loss = 6.5193e-04, PNorm = 46.2573, GNorm = 0.8032, lr_0 = 6.0306e-04
Loss = 5.5990e-04, PNorm = 46.2708, GNorm = 0.4912, lr_0 = 6.0243e-04
Loss = 5.3669e-04, PNorm = 46.2826, GNorm = 0.6995, lr_0 = 6.0180e-04
Loss = 5.3635e-04, PNorm = 46.2988, GNorm = 0.3453, lr_0 = 6.0118e-04
Loss = 4.7287e-04, PNorm = 46.3120, GNorm = 0.6675, lr_0 = 6.0055e-04
Loss = 4.6447e-04, PNorm = 46.3269, GNorm = 0.3957, lr_0 = 5.9992e-04
Loss = 5.1184e-04, PNorm = 46.3350, GNorm = 1.0161, lr_0 = 5.9930e-04
Loss = 4.3617e-04, PNorm = 46.3459, GNorm = 0.5817, lr_0 = 5.9867e-04
Loss = 4.5858e-04, PNorm = 46.3567, GNorm = 0.2803, lr_0 = 5.9805e-04
Loss = 5.7654e-04, PNorm = 46.3732, GNorm = 0.4434, lr_0 = 5.9742e-04
Loss = 7.2072e-04, PNorm = 46.3823, GNorm = 0.8644, lr_0 = 5.9680e-04
Loss = 6.0157e-04, PNorm = 46.3998, GNorm = 0.3387, lr_0 = 5.9618e-04
Loss = 5.3292e-04, PNorm = 46.4181, GNorm = 0.6001, lr_0 = 5.9555e-04
Loss = 4.9691e-04, PNorm = 46.4332, GNorm = 0.5137, lr_0 = 5.9493e-04
Validation rmse logD = 0.629377
Validation R2 logD = 0.722965
Validation rmse logP = 0.470611
Validation R2 logP = 0.939032
Epoch 24
Train function
Loss = 5.0081e-04, PNorm = 46.4485, GNorm = 0.7124, lr_0 = 5.9425e-04
Loss = 4.2115e-04, PNorm = 46.4614, GNorm = 0.4577, lr_0 = 5.9363e-04
Loss = 4.6935e-04, PNorm = 46.4669, GNorm = 0.5369, lr_0 = 5.9301e-04
Loss = 4.0408e-04, PNorm = 46.4747, GNorm = 0.6283, lr_0 = 5.9239e-04
Loss = 4.0007e-04, PNorm = 46.4892, GNorm = 0.5523, lr_0 = 5.9177e-04
Loss = 4.2875e-04, PNorm = 46.5055, GNorm = 0.3115, lr_0 = 5.9115e-04
Loss = 5.5566e-04, PNorm = 46.5173, GNorm = 0.4219, lr_0 = 5.9054e-04
Loss = 3.9709e-04, PNorm = 46.5296, GNorm = 0.3574, lr_0 = 5.8992e-04
Loss = 4.5880e-04, PNorm = 46.5440, GNorm = 0.6004, lr_0 = 5.8931e-04
Loss = 6.4473e-04, PNorm = 46.5556, GNorm = 0.6175, lr_0 = 5.8869e-04
Loss = 4.2990e-04, PNorm = 46.5712, GNorm = 0.4088, lr_0 = 5.8808e-04
Loss = 5.2777e-04, PNorm = 46.5803, GNorm = 0.4174, lr_0 = 5.8746e-04
Loss = 4.3504e-04, PNorm = 46.5926, GNorm = 0.3198, lr_0 = 5.8685e-04
Loss = 4.3135e-04, PNorm = 46.6009, GNorm = 0.3593, lr_0 = 5.8624e-04
Loss = 4.1173e-04, PNorm = 46.6078, GNorm = 0.4065, lr_0 = 5.8562e-04
Loss = 4.8587e-04, PNorm = 46.6182, GNorm = 0.6606, lr_0 = 5.8501e-04
Loss = 4.8797e-04, PNorm = 46.6253, GNorm = 0.4537, lr_0 = 5.8440e-04
Loss = 4.9012e-04, PNorm = 46.6435, GNorm = 0.6205, lr_0 = 5.8379e-04
Loss = 4.6600e-04, PNorm = 46.6479, GNorm = 0.8132, lr_0 = 5.8318e-04
Loss = 5.5061e-04, PNorm = 46.6561, GNorm = 0.3454, lr_0 = 5.8257e-04
Loss = 4.3559e-04, PNorm = 46.6664, GNorm = 0.2348, lr_0 = 5.8197e-04
Loss = 5.1968e-04, PNorm = 46.6806, GNorm = 0.4744, lr_0 = 5.8136e-04
Validation rmse logD = 0.645652
Validation R2 logD = 0.708453
Validation rmse logP = 0.469347
Validation R2 logP = 0.939360
Epoch 25
Train function
Loss = 3.3416e-04, PNorm = 46.6950, GNorm = 0.3610, lr_0 = 5.8075e-04
Loss = 4.2246e-04, PNorm = 46.7092, GNorm = 0.2936, lr_0 = 5.8015e-04
Loss = 4.4205e-04, PNorm = 46.7231, GNorm = 1.0361, lr_0 = 5.7954e-04
Loss = 4.5719e-04, PNorm = 46.7362, GNorm = 0.5098, lr_0 = 5.7894e-04
Loss = 4.3591e-04, PNorm = 46.7542, GNorm = 0.6621, lr_0 = 5.7833e-04
Loss = 4.4766e-04, PNorm = 46.7663, GNorm = 0.4488, lr_0 = 5.7773e-04
Loss = 4.5704e-04, PNorm = 46.7803, GNorm = 0.3816, lr_0 = 5.7712e-04
Loss = 3.4940e-04, PNorm = 46.7892, GNorm = 0.3219, lr_0 = 5.7652e-04
Loss = 4.1333e-04, PNorm = 46.7992, GNorm = 0.3154, lr_0 = 5.7592e-04
Loss = 2.9067e-04, PNorm = 46.8049, GNorm = 0.3534, lr_0 = 5.7532e-04
Loss = 3.9753e-04, PNorm = 46.8160, GNorm = 0.3303, lr_0 = 5.7472e-04
Loss = 3.9384e-04, PNorm = 46.8241, GNorm = 0.5300, lr_0 = 5.7412e-04
Loss = 4.2403e-04, PNorm = 46.8331, GNorm = 0.3035, lr_0 = 5.7352e-04
Loss = 6.0023e-04, PNorm = 46.8461, GNorm = 0.5540, lr_0 = 5.7292e-04
Loss = 5.5971e-04, PNorm = 46.8634, GNorm = 0.4549, lr_0 = 5.7232e-04
Loss = 3.9204e-04, PNorm = 46.8760, GNorm = 0.5342, lr_0 = 5.7173e-04
Loss = 4.8331e-04, PNorm = 46.8855, GNorm = 0.6026, lr_0 = 5.7113e-04
Loss = 5.4371e-04, PNorm = 46.8910, GNorm = 0.5562, lr_0 = 5.7053e-04
Loss = 5.1783e-04, PNorm = 46.9052, GNorm = 0.3233, lr_0 = 5.6994e-04
Loss = 5.3959e-04, PNorm = 46.9220, GNorm = 0.4868, lr_0 = 5.6934e-04
Loss = 4.9261e-04, PNorm = 46.9366, GNorm = 0.7129, lr_0 = 5.6875e-04
Loss = 4.6247e-04, PNorm = 46.9469, GNorm = 0.7481, lr_0 = 5.6816e-04
Loss = 5.5934e-04, PNorm = 46.9576, GNorm = 0.6337, lr_0 = 5.6756e-04
Validation rmse logD = 0.640481
Validation R2 logD = 0.713104
Validation rmse logP = 0.471971
Validation R2 logP = 0.938680
Epoch 26
Train function
Loss = 4.7700e-04, PNorm = 46.9745, GNorm = 0.4607, lr_0 = 5.6691e-04
Loss = 4.6509e-04, PNorm = 46.9926, GNorm = 0.5101, lr_0 = 5.6632e-04
Loss = 3.3228e-04, PNorm = 47.0030, GNorm = 0.2280, lr_0 = 5.6573e-04
Loss = 3.6828e-04, PNorm = 47.0139, GNorm = 0.4145, lr_0 = 5.6514e-04
Loss = 3.4144e-04, PNorm = 47.0228, GNorm = 0.4274, lr_0 = 5.6455e-04
Loss = 4.3918e-04, PNorm = 47.0306, GNorm = 0.4055, lr_0 = 5.6396e-04
Loss = 4.4270e-04, PNorm = 47.0444, GNorm = 0.5136, lr_0 = 5.6337e-04
Loss = 3.6322e-04, PNorm = 47.0590, GNorm = 0.3832, lr_0 = 5.6278e-04
Loss = 3.9387e-04, PNorm = 47.0683, GNorm = 0.7920, lr_0 = 5.6219e-04
Loss = 4.1192e-04, PNorm = 47.0763, GNorm = 0.4364, lr_0 = 5.6161e-04
Loss = 4.2446e-04, PNorm = 47.0889, GNorm = 0.4073, lr_0 = 5.6102e-04
Loss = 4.4295e-04, PNorm = 47.0996, GNorm = 0.6197, lr_0 = 5.6044e-04
Loss = 4.7854e-04, PNorm = 47.1113, GNorm = 0.5519, lr_0 = 5.5985e-04
Loss = 4.4699e-04, PNorm = 47.1260, GNorm = 0.3913, lr_0 = 5.5927e-04
Loss = 4.7376e-04, PNorm = 47.1369, GNorm = 0.3950, lr_0 = 5.5868e-04
Loss = 4.0281e-04, PNorm = 47.1514, GNorm = 0.2930, lr_0 = 5.5810e-04
Loss = 4.6188e-04, PNorm = 47.1605, GNorm = 0.4008, lr_0 = 5.5752e-04
Loss = 3.8955e-04, PNorm = 47.1715, GNorm = 0.5121, lr_0 = 5.5694e-04
Loss = 3.9947e-04, PNorm = 47.1806, GNorm = 0.5396, lr_0 = 5.5635e-04
Loss = 4.1422e-04, PNorm = 47.1913, GNorm = 0.2995, lr_0 = 5.5577e-04
Loss = 4.1675e-04, PNorm = 47.2047, GNorm = 0.7440, lr_0 = 5.5519e-04
Loss = 3.7997e-04, PNorm = 47.2146, GNorm = 0.3102, lr_0 = 5.5461e-04
Validation rmse logD = 0.646409
Validation R2 logD = 0.707769
Validation rmse logP = 0.487668
Validation R2 logP = 0.934533
Epoch 27
Train function
Loss = 5.8637e-04, PNorm = 47.2232, GNorm = 0.5166, lr_0 = 5.5398e-04
Loss = 4.4814e-04, PNorm = 47.2326, GNorm = 0.3525, lr_0 = 5.5340e-04
Loss = 5.1538e-04, PNorm = 47.2395, GNorm = 0.7655, lr_0 = 5.5282e-04
Loss = 4.4060e-04, PNorm = 47.2517, GNorm = 1.1292, lr_0 = 5.5224e-04
Loss = 3.6307e-04, PNorm = 47.2650, GNorm = 0.6351, lr_0 = 5.5167e-04
Loss = 3.8585e-04, PNorm = 47.2749, GNorm = 0.2948, lr_0 = 5.5109e-04
Loss = 4.2800e-04, PNorm = 47.2912, GNorm = 0.7211, lr_0 = 5.5052e-04
Loss = 3.5952e-04, PNorm = 47.3056, GNorm = 0.9314, lr_0 = 5.4994e-04
Loss = 3.3988e-04, PNorm = 47.3131, GNorm = 0.3017, lr_0 = 5.4937e-04
Loss = 3.9940e-04, PNorm = 47.3191, GNorm = 0.5021, lr_0 = 5.4880e-04
Loss = 3.6544e-04, PNorm = 47.3292, GNorm = 0.3111, lr_0 = 5.4822e-04
Loss = 3.6709e-04, PNorm = 47.3385, GNorm = 0.6548, lr_0 = 5.4765e-04
Loss = 3.3837e-04, PNorm = 47.3494, GNorm = 0.5188, lr_0 = 5.4708e-04
Loss = 4.5628e-04, PNorm = 47.3580, GNorm = 0.7394, lr_0 = 5.4651e-04
Loss = 3.7192e-04, PNorm = 47.3711, GNorm = 0.3242, lr_0 = 5.4594e-04
Loss = 3.7263e-04, PNorm = 47.3858, GNorm = 0.4226, lr_0 = 5.4537e-04
Loss = 3.7865e-04, PNorm = 47.3941, GNorm = 0.5416, lr_0 = 5.4480e-04
Loss = 3.8521e-04, PNorm = 47.4003, GNorm = 0.5797, lr_0 = 5.4423e-04
Loss = 4.4388e-04, PNorm = 47.4097, GNorm = 0.6521, lr_0 = 5.4366e-04
Loss = 2.8531e-04, PNorm = 47.4171, GNorm = 0.5762, lr_0 = 5.4309e-04
Loss = 3.8592e-04, PNorm = 47.4254, GNorm = 0.3042, lr_0 = 5.4253e-04
Loss = 4.0323e-04, PNorm = 47.4326, GNorm = 0.3104, lr_0 = 5.4196e-04
Loss = 3.2845e-04, PNorm = 47.4361, GNorm = 0.3060, lr_0 = 5.4140e-04
Validation rmse logD = 0.616766
Validation R2 logD = 0.733956
Validation rmse logP = 0.460672
Validation R2 logP = 0.941581
Epoch 28
Train function
Loss = 2.8715e-04, PNorm = 47.4441, GNorm = 0.4455, lr_0 = 5.4083e-04
Loss = 3.0371e-04, PNorm = 47.4507, GNorm = 0.2355, lr_0 = 5.4027e-04
Loss = 3.1923e-04, PNorm = 47.4636, GNorm = 0.3942, lr_0 = 5.3970e-04
Loss = 2.9242e-04, PNorm = 47.4759, GNorm = 0.4858, lr_0 = 5.3914e-04
Loss = 2.9656e-04, PNorm = 47.4830, GNorm = 0.4147, lr_0 = 5.3858e-04
Loss = 2.7552e-04, PNorm = 47.4880, GNorm = 0.3369, lr_0 = 5.3801e-04
Loss = 2.8052e-04, PNorm = 47.4980, GNorm = 0.3446, lr_0 = 5.3745e-04
Loss = 3.1107e-04, PNorm = 47.5064, GNorm = 0.5229, lr_0 = 5.3689e-04
Loss = 3.5306e-04, PNorm = 47.5188, GNorm = 0.4354, lr_0 = 5.3633e-04
Loss = 3.0758e-04, PNorm = 47.5257, GNorm = 0.3475, lr_0 = 5.3577e-04
Loss = 3.9792e-04, PNorm = 47.5382, GNorm = 0.3113, lr_0 = 5.3521e-04
Loss = 3.1961e-04, PNorm = 47.5515, GNorm = 0.3582, lr_0 = 5.3465e-04
Loss = 3.7162e-04, PNorm = 47.5614, GNorm = 0.6864, lr_0 = 5.3410e-04
Loss = 4.3651e-04, PNorm = 47.5716, GNorm = 0.9855, lr_0 = 5.3354e-04
Loss = 4.9801e-04, PNorm = 47.5873, GNorm = 0.2921, lr_0 = 5.3298e-04
Loss = 4.4905e-04, PNorm = 47.5992, GNorm = 0.4003, lr_0 = 5.3243e-04
Loss = 3.8785e-04, PNorm = 47.6084, GNorm = 0.4053, lr_0 = 5.3187e-04
Loss = 4.7604e-04, PNorm = 47.6191, GNorm = 0.3631, lr_0 = 5.3131e-04
Loss = 3.7227e-04, PNorm = 47.6310, GNorm = 0.5162, lr_0 = 5.3076e-04
Loss = 3.3904e-04, PNorm = 47.6378, GNorm = 0.3784, lr_0 = 5.3021e-04
Loss = 3.1621e-04, PNorm = 47.6482, GNorm = 0.2993, lr_0 = 5.2965e-04
Loss = 3.7768e-04, PNorm = 47.6540, GNorm = 0.2336, lr_0 = 5.2910e-04
Validation rmse logD = 0.631403
Validation R2 logD = 0.721179
Validation rmse logP = 0.461950
Validation R2 logP = 0.941256
Epoch 29
Train function
Loss = 2.7955e-04, PNorm = 47.6576, GNorm = 0.2747, lr_0 = 5.2849e-04
Loss = 3.0041e-04, PNorm = 47.6706, GNorm = 0.2325, lr_0 = 5.2794e-04
Loss = 3.3261e-04, PNorm = 47.6787, GNorm = 0.2903, lr_0 = 5.2739e-04
Loss = 2.9932e-04, PNorm = 47.6852, GNorm = 0.3926, lr_0 = 5.2684e-04
Loss = 3.4300e-04, PNorm = 47.6928, GNorm = 0.4028, lr_0 = 5.2629e-04
Loss = 3.1997e-04, PNorm = 47.7034, GNorm = 0.3908, lr_0 = 5.2574e-04
Loss = 3.5544e-04, PNorm = 47.7141, GNorm = 0.4960, lr_0 = 5.2519e-04
Loss = 2.9719e-04, PNorm = 47.7227, GNorm = 0.3554, lr_0 = 5.2464e-04
Loss = 3.3245e-04, PNorm = 47.7348, GNorm = 0.5452, lr_0 = 5.2410e-04
Loss = 2.7621e-04, PNorm = 47.7415, GNorm = 0.7316, lr_0 = 5.2355e-04
Loss = 3.4029e-04, PNorm = 47.7509, GNorm = 0.5128, lr_0 = 5.2300e-04
Loss = 3.0394e-04, PNorm = 47.7619, GNorm = 0.4163, lr_0 = 5.2246e-04
Loss = 2.8256e-04, PNorm = 47.7741, GNorm = 0.2971, lr_0 = 5.2191e-04
Loss = 2.6228e-04, PNorm = 47.7837, GNorm = 0.2977, lr_0 = 5.2137e-04
Loss = 2.9528e-04, PNorm = 47.7962, GNorm = 0.4953, lr_0 = 5.2082e-04
Loss = 3.1199e-04, PNorm = 47.8020, GNorm = 0.3485, lr_0 = 5.2028e-04
Loss = 3.4882e-04, PNorm = 47.8091, GNorm = 0.3791, lr_0 = 5.1974e-04
Loss = 3.3609e-04, PNorm = 47.8191, GNorm = 0.3273, lr_0 = 5.1919e-04
Loss = 3.2193e-04, PNorm = 47.8284, GNorm = 0.3711, lr_0 = 5.1865e-04
Loss = 4.3790e-04, PNorm = 47.8388, GNorm = 0.3887, lr_0 = 5.1811e-04
Loss = 3.6376e-04, PNorm = 47.8520, GNorm = 0.2667, lr_0 = 5.1757e-04
Loss = 3.0940e-04, PNorm = 47.8606, GNorm = 0.2996, lr_0 = 5.1703e-04
Loss = 2.9169e-04, PNorm = 47.8697, GNorm = 0.3691, lr_0 = 5.1649e-04
Validation rmse logD = 0.637102
Validation R2 logD = 0.716123
Validation rmse logP = 0.464576
Validation R2 logP = 0.940586
Epoch 30
Train function
Loss = 2.4019e-04, PNorm = 47.8781, GNorm = 0.3964, lr_0 = 5.1595e-04
Loss = 2.4544e-04, PNorm = 47.8842, GNorm = 0.3472, lr_0 = 5.1541e-04
Loss = 2.5901e-04, PNorm = 47.8893, GNorm = 0.4587, lr_0 = 5.1487e-04
Loss = 3.6665e-04, PNorm = 47.8957, GNorm = 0.3729, lr_0 = 5.1434e-04
Loss = 2.4188e-04, PNorm = 47.9080, GNorm = 0.3002, lr_0 = 5.1380e-04
Loss = 3.3318e-04, PNorm = 47.9164, GNorm = 0.3523, lr_0 = 5.1326e-04
Loss = 3.4067e-04, PNorm = 47.9242, GNorm = 0.7956, lr_0 = 5.1273e-04
Loss = 3.5099e-04, PNorm = 47.9324, GNorm = 0.6902, lr_0 = 5.1219e-04
Loss = 2.7633e-04, PNorm = 47.9416, GNorm = 0.5857, lr_0 = 5.1166e-04
Loss = 2.9667e-04, PNorm = 47.9587, GNorm = 0.3695, lr_0 = 5.1112e-04
Loss = 3.5464e-04, PNorm = 47.9644, GNorm = 0.4979, lr_0 = 5.1059e-04
Loss = 3.9276e-04, PNorm = 47.9770, GNorm = 0.6517, lr_0 = 5.1006e-04
Loss = 3.1636e-04, PNorm = 47.9861, GNorm = 0.4767, lr_0 = 5.0953e-04
Loss = 3.2734e-04, PNorm = 47.9984, GNorm = 0.6691, lr_0 = 5.0899e-04
Loss = 3.4909e-04, PNorm = 48.0092, GNorm = 0.3197, lr_0 = 5.0846e-04
Loss = 3.3787e-04, PNorm = 48.0168, GNorm = 0.4573, lr_0 = 5.0793e-04
Loss = 3.0216e-04, PNorm = 48.0247, GNorm = 0.4481, lr_0 = 5.0740e-04
Loss = 2.9641e-04, PNorm = 48.0337, GNorm = 0.3836, lr_0 = 5.0687e-04
Loss = 3.0124e-04, PNorm = 48.0413, GNorm = 0.4095, lr_0 = 5.0634e-04
Loss = 2.9482e-04, PNorm = 48.0476, GNorm = 0.5304, lr_0 = 5.0581e-04
Loss = 3.3160e-04, PNorm = 48.0568, GNorm = 0.4287, lr_0 = 5.0529e-04
Loss = 2.9199e-04, PNorm = 48.0685, GNorm = 0.2598, lr_0 = 5.0476e-04
Validation rmse logD = 0.624161
Validation R2 logD = 0.727538
Validation rmse logP = 0.465322
Validation R2 logP = 0.940395
Epoch 31
Train function
Loss = 1.7836e-04, PNorm = 48.0834, GNorm = 0.2840, lr_0 = 5.0418e-04
Loss = 3.1600e-04, PNorm = 48.0946, GNorm = 0.4770, lr_0 = 5.0365e-04
Loss = 2.6980e-04, PNorm = 48.1082, GNorm = 0.2627, lr_0 = 5.0313e-04
Loss = 2.5331e-04, PNorm = 48.1138, GNorm = 0.4087, lr_0 = 5.0260e-04
Loss = 2.8987e-04, PNorm = 48.1192, GNorm = 0.1920, lr_0 = 5.0208e-04
Loss = 3.4311e-04, PNorm = 48.1324, GNorm = 0.5905, lr_0 = 5.0155e-04
Loss = 2.6931e-04, PNorm = 48.1409, GNorm = 0.4004, lr_0 = 5.0103e-04
Loss = 2.7146e-04, PNorm = 48.1515, GNorm = 0.2515, lr_0 = 5.0051e-04
Loss = 3.5838e-04, PNorm = 48.1594, GNorm = 0.2807, lr_0 = 4.9998e-04
Loss = 2.5327e-04, PNorm = 48.1684, GNorm = 0.3168, lr_0 = 4.9946e-04
Loss = 3.7122e-04, PNorm = 48.1751, GNorm = 0.6472, lr_0 = 4.9894e-04
Loss = 3.3686e-04, PNorm = 48.1862, GNorm = 0.2727, lr_0 = 4.9842e-04
Loss = 2.8143e-04, PNorm = 48.1967, GNorm = 0.3852, lr_0 = 4.9790e-04
Loss = 2.8294e-04, PNorm = 48.2050, GNorm = 0.4546, lr_0 = 4.9738e-04
Loss = 3.4585e-04, PNorm = 48.2115, GNorm = 0.4450, lr_0 = 4.9686e-04
Loss = 2.5647e-04, PNorm = 48.2200, GNorm = 0.5935, lr_0 = 4.9634e-04
Loss = 2.9750e-04, PNorm = 48.2297, GNorm = 0.2590, lr_0 = 4.9583e-04
Loss = 2.6287e-04, PNorm = 48.2420, GNorm = 0.3236, lr_0 = 4.9531e-04
Loss = 2.7856e-04, PNorm = 48.2483, GNorm = 0.2967, lr_0 = 4.9479e-04
Loss = 2.8271e-04, PNorm = 48.2536, GNorm = 0.3052, lr_0 = 4.9427e-04
Loss = 2.9322e-04, PNorm = 48.2575, GNorm = 0.2467, lr_0 = 4.9376e-04
Loss = 3.8365e-04, PNorm = 48.2653, GNorm = 0.2188, lr_0 = 4.9324e-04
Loss = 3.1156e-04, PNorm = 48.2758, GNorm = 0.4787, lr_0 = 4.9273e-04
Validation rmse logD = 0.615638
Validation R2 logD = 0.734929
Validation rmse logP = 0.455135
Validation R2 logP = 0.942976
Epoch 32
Train function
Loss = 2.0866e-04, PNorm = 48.2865, GNorm = 0.2162, lr_0 = 4.9221e-04
Loss = 2.6893e-04, PNorm = 48.2959, GNorm = 0.2701, lr_0 = 4.9170e-04
Loss = 2.2032e-04, PNorm = 48.3074, GNorm = 0.6014, lr_0 = 4.9119e-04
Loss = 2.5745e-04, PNorm = 48.3150, GNorm = 0.2773, lr_0 = 4.9067e-04
Loss = 2.4625e-04, PNorm = 48.3171, GNorm = 0.5710, lr_0 = 4.9016e-04
Loss = 2.0438e-04, PNorm = 48.3235, GNorm = 0.2735, lr_0 = 4.8965e-04
Loss = 1.9753e-04, PNorm = 48.3339, GNorm = 0.4486, lr_0 = 4.8914e-04
Loss = 3.4416e-04, PNorm = 48.3409, GNorm = 1.0845, lr_0 = 4.8863e-04
Loss = 3.0445e-04, PNorm = 48.3514, GNorm = 0.2416, lr_0 = 4.8812e-04
Loss = 3.4448e-04, PNorm = 48.3607, GNorm = 0.7166, lr_0 = 4.8761e-04
Loss = 2.6708e-04, PNorm = 48.3704, GNorm = 0.4206, lr_0 = 4.8710e-04
Loss = 3.1201e-04, PNorm = 48.3759, GNorm = 0.6683, lr_0 = 4.8659e-04
Loss = 3.0131e-04, PNorm = 48.3829, GNorm = 0.6608, lr_0 = 4.8608e-04
Loss = 2.5770e-04, PNorm = 48.3937, GNorm = 0.3080, lr_0 = 4.8558e-04
Loss = 2.6395e-04, PNorm = 48.4043, GNorm = 0.2998, lr_0 = 4.8507e-04
Loss = 2.5856e-04, PNorm = 48.4122, GNorm = 0.3118, lr_0 = 4.8456e-04
Loss = 2.6215e-04, PNorm = 48.4163, GNorm = 0.5224, lr_0 = 4.8406e-04
Loss = 2.8487e-04, PNorm = 48.4265, GNorm = 0.2987, lr_0 = 4.8355e-04
Loss = 3.1851e-04, PNorm = 48.4335, GNorm = 0.4384, lr_0 = 4.8305e-04
Loss = 2.6757e-04, PNorm = 48.4423, GNorm = 0.3403, lr_0 = 4.8254e-04
Loss = 3.0258e-04, PNorm = 48.4532, GNorm = 0.3644, lr_0 = 4.8204e-04
Loss = 3.7471e-04, PNorm = 48.4634, GNorm = 0.3321, lr_0 = 4.8154e-04
Loss = 2.9842e-04, PNorm = 48.4709, GNorm = 0.6801, lr_0 = 4.8104e-04
Loss = 6.9195e-04, PNorm = 48.4723, GNorm = 0.4363, lr_0 = 4.8098e-04
Validation rmse logD = 0.615305
Validation R2 logD = 0.735216
Validation rmse logP = 0.476051
Validation R2 logP = 0.937615
Epoch 33
Train function
Loss = 3.1643e-04, PNorm = 48.4816, GNorm = 0.1988, lr_0 = 4.8048e-04
Loss = 3.6865e-04, PNorm = 48.4937, GNorm = 0.3963, lr_0 = 4.7998e-04
Loss = 2.5575e-04, PNorm = 48.5014, GNorm = 0.2772, lr_0 = 4.7948e-04
Loss = 3.0812e-04, PNorm = 48.5113, GNorm = 0.2851, lr_0 = 4.7898e-04
Loss = 2.6607e-04, PNorm = 48.5206, GNorm = 0.5098, lr_0 = 4.7848e-04
Loss = 2.4783e-04, PNorm = 48.5289, GNorm = 0.3115, lr_0 = 4.7798e-04
Loss = 2.8101e-04, PNorm = 48.5354, GNorm = 0.2981, lr_0 = 4.7748e-04
Loss = 3.0344e-04, PNorm = 48.5425, GNorm = 0.3186, lr_0 = 4.7698e-04
Loss = 2.7960e-04, PNorm = 48.5478, GNorm = 0.3568, lr_0 = 4.7649e-04
Loss = 2.3857e-04, PNorm = 48.5573, GNorm = 0.2667, lr_0 = 4.7599e-04
Loss = 2.7849e-04, PNorm = 48.5645, GNorm = 0.6194, lr_0 = 4.7549e-04
Loss = 2.9107e-04, PNorm = 48.5749, GNorm = 0.4518, lr_0 = 4.7500e-04
Loss = 2.1076e-04, PNorm = 48.5821, GNorm = 0.2227, lr_0 = 4.7450e-04
Loss = 2.4757e-04, PNorm = 48.5888, GNorm = 0.3210, lr_0 = 4.7400e-04
Loss = 2.3490e-04, PNorm = 48.5970, GNorm = 0.3947, lr_0 = 4.7351e-04
Loss = 2.4942e-04, PNorm = 48.6050, GNorm = 0.3919, lr_0 = 4.7302e-04
Loss = 2.8498e-04, PNorm = 48.6128, GNorm = 0.7183, lr_0 = 4.7252e-04
Loss = 2.6237e-04, PNorm = 48.6155, GNorm = 0.4227, lr_0 = 4.7203e-04
Loss = 3.2191e-04, PNorm = 48.6277, GNorm = 0.3293, lr_0 = 4.7154e-04
Loss = 2.7468e-04, PNorm = 48.6347, GNorm = 0.6233, lr_0 = 4.7104e-04
Loss = 2.9807e-04, PNorm = 48.6418, GNorm = 0.6151, lr_0 = 4.7055e-04
Loss = 2.9334e-04, PNorm = 48.6517, GNorm = 0.3823, lr_0 = 4.7006e-04
Validation rmse logD = 0.631880
Validation R2 logD = 0.720757
Validation rmse logP = 0.458857
Validation R2 logP = 0.942040
Epoch 34
Train function
Loss = 1.9826e-04, PNorm = 48.6607, GNorm = 0.4278, lr_0 = 4.6957e-04
Loss = 2.6989e-04, PNorm = 48.6697, GNorm = 0.6812, lr_0 = 4.6908e-04
Loss = 2.5083e-04, PNorm = 48.6766, GNorm = 0.3074, lr_0 = 4.6859e-04
Loss = 2.3833e-04, PNorm = 48.6849, GNorm = 0.4278, lr_0 = 4.6810e-04
Loss = 2.8102e-04, PNorm = 48.6918, GNorm = 0.5155, lr_0 = 4.6761e-04
Loss = 2.8389e-04, PNorm = 48.7002, GNorm = 0.7114, lr_0 = 4.6712e-04
Loss = 3.0767e-04, PNorm = 48.7103, GNorm = 0.3673, lr_0 = 4.6664e-04
Loss = 1.7836e-04, PNorm = 48.7166, GNorm = 0.2266, lr_0 = 4.6615e-04
Loss = 2.7226e-04, PNorm = 48.7245, GNorm = 0.6073, lr_0 = 4.6566e-04
Loss = 2.4446e-04, PNorm = 48.7341, GNorm = 0.2087, lr_0 = 4.6518e-04
Loss = 2.6404e-04, PNorm = 48.7415, GNorm = 0.2426, lr_0 = 4.6469e-04
Loss = 3.6391e-04, PNorm = 48.7478, GNorm = 0.4453, lr_0 = 4.6421e-04
Loss = 2.9387e-04, PNorm = 48.7572, GNorm = 0.5270, lr_0 = 4.6372e-04
Loss = 2.3486e-04, PNorm = 48.7655, GNorm = 0.3660, lr_0 = 4.6324e-04
Loss = 2.6768e-04, PNorm = 48.7723, GNorm = 0.5410, lr_0 = 4.6276e-04
Loss = 2.8637e-04, PNorm = 48.7808, GNorm = 0.5376, lr_0 = 4.6227e-04
Loss = 2.5766e-04, PNorm = 48.7863, GNorm = 0.4649, lr_0 = 4.6179e-04
Loss = 3.3279e-04, PNorm = 48.7992, GNorm = 0.5806, lr_0 = 4.6131e-04
Loss = 3.2236e-04, PNorm = 48.8076, GNorm = 0.3178, lr_0 = 4.6083e-04
Loss = 2.5373e-04, PNorm = 48.8163, GNorm = 0.3449, lr_0 = 4.6035e-04
Loss = 3.1530e-04, PNorm = 48.8253, GNorm = 0.6748, lr_0 = 4.5987e-04
Loss = 3.3364e-04, PNorm = 48.8368, GNorm = 0.2823, lr_0 = 4.5939e-04
Loss = 3.2250e-04, PNorm = 48.8479, GNorm = 0.7266, lr_0 = 4.5891e-04
Validation rmse logD = 0.624362
Validation R2 logD = 0.727363
Validation rmse logP = 0.465928
Validation R2 logP = 0.940240
Epoch 35
Train function
Loss = 1.9748e-04, PNorm = 48.8598, GNorm = 0.3508, lr_0 = 4.5838e-04
Loss = 2.0004e-04, PNorm = 48.8694, GNorm = 0.3872, lr_0 = 4.5790e-04
Loss = 2.2482e-04, PNorm = 48.8814, GNorm = 0.3055, lr_0 = 4.5742e-04
Loss = 2.5048e-04, PNorm = 48.8910, GNorm = 0.4781, lr_0 = 4.5695e-04
Loss = 2.6795e-04, PNorm = 48.9000, GNorm = 0.2082, lr_0 = 4.5647e-04
Loss = 3.0326e-04, PNorm = 48.9120, GNorm = 0.5495, lr_0 = 4.5599e-04
Loss = 3.9558e-04, PNorm = 48.9229, GNorm = 0.5616, lr_0 = 4.5552e-04
Loss = 3.2234e-04, PNorm = 48.9353, GNorm = 0.4026, lr_0 = 4.5504e-04
Loss = 2.8728e-04, PNorm = 48.9425, GNorm = 0.3669, lr_0 = 4.5457e-04
Loss = 2.7672e-04, PNorm = 48.9520, GNorm = 0.5594, lr_0 = 4.5409e-04
Loss = 2.1545e-04, PNorm = 48.9590, GNorm = 0.3103, lr_0 = 4.5362e-04
Loss = 2.5862e-04, PNorm = 48.9665, GNorm = 0.3413, lr_0 = 4.5314e-04
Loss = 2.5282e-04, PNorm = 48.9714, GNorm = 0.2673, lr_0 = 4.5267e-04
Loss = 2.6235e-04, PNorm = 48.9800, GNorm = 0.3420, lr_0 = 4.5220e-04
Loss = 1.1076e-03, PNorm = 48.9845, GNorm = 0.3900, lr_0 = 4.5173e-04
Loss = 4.1928e-04, PNorm = 49.0067, GNorm = 0.2996, lr_0 = 4.5125e-04
Loss = 5.2532e-04, PNorm = 49.0321, GNorm = 1.1686, lr_0 = 4.5078e-04
Loss = 5.2527e-04, PNorm = 49.0551, GNorm = 0.3424, lr_0 = 4.5031e-04
Loss = 5.5147e-04, PNorm = 49.0757, GNorm = 0.3422, lr_0 = 4.4984e-04
Loss = 3.9930e-04, PNorm = 49.0882, GNorm = 0.5064, lr_0 = 4.4937e-04
Loss = 4.0017e-04, PNorm = 49.1020, GNorm = 0.5957, lr_0 = 4.4890e-04
Loss = 6.1904e-04, PNorm = 49.1167, GNorm = 0.4745, lr_0 = 4.4844e-04
Validation rmse logD = 0.634688
Validation R2 logD = 0.718270
Validation rmse logP = 0.476231
Validation R2 logP = 0.937568
Epoch 36
Train function
Loss = 5.3954e-04, PNorm = 49.1303, GNorm = 0.8330, lr_0 = 4.4797e-04
Loss = 4.2258e-04, PNorm = 49.1472, GNorm = 0.4082, lr_0 = 4.4750e-04
Loss = 3.8146e-04, PNorm = 49.1665, GNorm = 0.4770, lr_0 = 4.4703e-04
Loss = 3.4181e-04, PNorm = 49.1766, GNorm = 0.2769, lr_0 = 4.4657e-04
Loss = 3.0116e-04, PNorm = 49.1868, GNorm = 0.3116, lr_0 = 4.4610e-04
Loss = 3.0481e-04, PNorm = 49.1979, GNorm = 0.3639, lr_0 = 4.4564e-04
Loss = 3.0017e-04, PNorm = 49.2091, GNorm = 0.4132, lr_0 = 4.4517e-04
Loss = 3.1036e-04, PNorm = 49.2166, GNorm = 0.3311, lr_0 = 4.4471e-04
Loss = 3.4187e-04, PNorm = 49.2233, GNorm = 0.3733, lr_0 = 4.4424e-04
Loss = 2.9847e-04, PNorm = 49.2300, GNorm = 0.4908, lr_0 = 4.4378e-04
Loss = 2.7183e-04, PNorm = 49.2404, GNorm = 0.4123, lr_0 = 4.4331e-04
Loss = 2.1250e-04, PNorm = 49.2489, GNorm = 0.2181, lr_0 = 4.4285e-04
Loss = 2.8160e-04, PNorm = 49.2560, GNorm = 0.4051, lr_0 = 4.4239e-04
Loss = 2.5511e-04, PNorm = 49.2625, GNorm = 0.3105, lr_0 = 4.4193e-04
Loss = 2.7079e-04, PNorm = 49.2649, GNorm = 0.2819, lr_0 = 4.4147e-04
Loss = 2.9217e-04, PNorm = 49.2709, GNorm = 0.7235, lr_0 = 4.4101e-04
Loss = 2.9316e-04, PNorm = 49.2814, GNorm = 0.3544, lr_0 = 4.4055e-04
Loss = 3.1407e-04, PNorm = 49.2899, GNorm = 0.3007, lr_0 = 4.4009e-04
Loss = 2.6904e-04, PNorm = 49.2997, GNorm = 0.3002, lr_0 = 4.3963e-04
Loss = 2.8264e-04, PNorm = 49.3053, GNorm = 0.3204, lr_0 = 4.3917e-04
Loss = 3.0486e-04, PNorm = 49.3135, GNorm = 0.2841, lr_0 = 4.3871e-04
Loss = 2.2752e-04, PNorm = 49.3189, GNorm = 0.3298, lr_0 = 4.3825e-04
Loss = 2.5323e-04, PNorm = 49.3223, GNorm = 0.3190, lr_0 = 4.3779e-04
Validation rmse logD = 0.616136
Validation R2 logD = 0.734499
Validation rmse logP = 0.461250
Validation R2 logP = 0.941434
Epoch 37
Train function
Loss = 2.1435e-04, PNorm = 49.3334, GNorm = 0.3172, lr_0 = 4.3729e-04
Loss = 2.5307e-04, PNorm = 49.3387, GNorm = 0.5744, lr_0 = 4.3684e-04
Loss = 2.3729e-04, PNorm = 49.3436, GNorm = 0.8555, lr_0 = 4.3638e-04
Loss = 2.4512e-04, PNorm = 49.3529, GNorm = 0.4081, lr_0 = 4.3592e-04
Loss = 2.4270e-04, PNorm = 49.3636, GNorm = 0.2057, lr_0 = 4.3547e-04
Loss = 2.5640e-04, PNorm = 49.3720, GNorm = 0.6207, lr_0 = 4.3501e-04
Loss = 2.2411e-04, PNorm = 49.3757, GNorm = 0.5565, lr_0 = 4.3456e-04
Loss = 2.9346e-04, PNorm = 49.3818, GNorm = 0.3938, lr_0 = 4.3411e-04
Loss = 2.6546e-04, PNorm = 49.3884, GNorm = 0.6233, lr_0 = 4.3365e-04
Loss = 2.2276e-04, PNorm = 49.3924, GNorm = 0.3526, lr_0 = 4.3320e-04
Loss = 2.2797e-04, PNorm = 49.3995, GNorm = 0.2190, lr_0 = 4.3275e-04
Loss = 2.2350e-04, PNorm = 49.4076, GNorm = 0.4727, lr_0 = 4.3230e-04
Loss = 2.0091e-04, PNorm = 49.4121, GNorm = 0.3109, lr_0 = 4.3185e-04
Loss = 2.1615e-04, PNorm = 49.4192, GNorm = 0.3933, lr_0 = 4.3140e-04
Loss = 2.3527e-04, PNorm = 49.4299, GNorm = 0.3129, lr_0 = 4.3094e-04
Loss = 2.0746e-04, PNorm = 49.4377, GNorm = 0.2756, lr_0 = 4.3050e-04
Loss = 2.2862e-04, PNorm = 49.4442, GNorm = 0.2223, lr_0 = 4.3005e-04
Loss = 2.2422e-04, PNorm = 49.4484, GNorm = 0.3602, lr_0 = 4.2960e-04
Loss = 2.2440e-04, PNorm = 49.4546, GNorm = 0.5961, lr_0 = 4.2915e-04
Loss = 1.9205e-04, PNorm = 49.4612, GNorm = 0.2952, lr_0 = 4.2870e-04
Loss = 2.2058e-04, PNorm = 49.4673, GNorm = 0.3044, lr_0 = 4.2825e-04
Loss = 2.3215e-04, PNorm = 49.4735, GNorm = 0.5205, lr_0 = 4.2781e-04
Validation rmse logD = 0.606337
Validation R2 logD = 0.742878
Validation rmse logP = 0.456543
Validation R2 logP = 0.942623
Epoch 38
Train function
Loss = 1.6555e-04, PNorm = 49.4811, GNorm = 0.3384, lr_0 = 4.2736e-04
Loss = 1.9159e-04, PNorm = 49.4856, GNorm = 0.3343, lr_0 = 4.2691e-04
Loss = 1.8082e-04, PNorm = 49.4906, GNorm = 0.5353, lr_0 = 4.2647e-04
Loss = 1.9055e-04, PNorm = 49.4971, GNorm = 0.1865, lr_0 = 4.2602e-04
Loss = 1.8011e-04, PNorm = 49.5054, GNorm = 0.3832, lr_0 = 4.2558e-04
Loss = 2.2452e-04, PNorm = 49.5141, GNorm = 0.8514, lr_0 = 4.2513e-04
Loss = 2.5480e-04, PNorm = 49.5186, GNorm = 0.2548, lr_0 = 4.2469e-04
Loss = 2.3043e-04, PNorm = 49.5249, GNorm = 0.4640, lr_0 = 4.2425e-04
Loss = 2.1136e-04, PNorm = 49.5322, GNorm = 0.4256, lr_0 = 4.2380e-04
Loss = 2.1806e-04, PNorm = 49.5394, GNorm = 0.2298, lr_0 = 4.2336e-04
Loss = 2.2666e-04, PNorm = 49.5449, GNorm = 0.1909, lr_0 = 4.2292e-04
Loss = 2.3130e-04, PNorm = 49.5493, GNorm = 0.2809, lr_0 = 4.2248e-04
Loss = 2.2360e-04, PNorm = 49.5550, GNorm = 0.5655, lr_0 = 4.2204e-04
Loss = 2.0869e-04, PNorm = 49.5626, GNorm = 0.2676, lr_0 = 4.2160e-04
Loss = 1.8759e-04, PNorm = 49.5680, GNorm = 0.2737, lr_0 = 4.2116e-04
Loss = 1.6566e-04, PNorm = 49.5744, GNorm = 0.2835, lr_0 = 4.2072e-04
Loss = 1.8456e-04, PNorm = 49.5798, GNorm = 0.3576, lr_0 = 4.2028e-04
Loss = 1.7742e-04, PNorm = 49.5860, GNorm = 0.3722, lr_0 = 4.1984e-04
Loss = 2.1667e-04, PNorm = 49.5912, GNorm = 0.3275, lr_0 = 4.1940e-04
Loss = 2.5455e-04, PNorm = 49.5970, GNorm = 0.2566, lr_0 = 4.1896e-04
Loss = 1.9212e-04, PNorm = 49.6033, GNorm = 0.4455, lr_0 = 4.1853e-04
Loss = 2.2000e-04, PNorm = 49.6123, GNorm = 0.2453, lr_0 = 4.1809e-04
Loss = 2.0277e-04, PNorm = 49.6203, GNorm = 0.4010, lr_0 = 4.1765e-04
Validation rmse logD = 0.641074
Validation R2 logD = 0.712573
Validation rmse logP = 0.455586
Validation R2 logP = 0.942863
Epoch 39
Train function
Loss = 1.4503e-04, PNorm = 49.6287, GNorm = 0.2205, lr_0 = 4.1717e-04
Loss = 1.8835e-04, PNorm = 49.6347, GNorm = 0.3212, lr_0 = 4.1674e-04
Loss = 1.9360e-04, PNorm = 49.6404, GNorm = 0.3276, lr_0 = 4.1630e-04
Loss = 1.6274e-04, PNorm = 49.6467, GNorm = 0.2483, lr_0 = 4.1587e-04
Loss = 2.0676e-04, PNorm = 49.6469, GNorm = 0.4875, lr_0 = 4.1544e-04
Loss = 1.8098e-04, PNorm = 49.6511, GNorm = 0.2920, lr_0 = 4.1500e-04
Loss = 1.9245e-04, PNorm = 49.6600, GNorm = 0.3207, lr_0 = 4.1457e-04
Loss = 2.2612e-04, PNorm = 49.6669, GNorm = 0.3018, lr_0 = 4.1414e-04
Loss = 2.1151e-04, PNorm = 49.6741, GNorm = 0.3721, lr_0 = 4.1370e-04
Loss = 1.5290e-04, PNorm = 49.6808, GNorm = 0.2415, lr_0 = 4.1327e-04
Loss = 1.5534e-04, PNorm = 49.6879, GNorm = 0.3557, lr_0 = 4.1284e-04
Loss = 2.0920e-04, PNorm = 49.6928, GNorm = 0.3408, lr_0 = 4.1241e-04
Loss = 1.7059e-04, PNorm = 49.6976, GNorm = 0.4629, lr_0 = 4.1198e-04
Loss = 2.3105e-04, PNorm = 49.7037, GNorm = 0.3666, lr_0 = 4.1155e-04
Loss = 1.5957e-04, PNorm = 49.7066, GNorm = 0.2744, lr_0 = 4.1112e-04
Loss = 1.7902e-04, PNorm = 49.7101, GNorm = 0.4090, lr_0 = 4.1069e-04
Loss = 1.8331e-04, PNorm = 49.7145, GNorm = 0.3423, lr_0 = 4.1026e-04
Loss = 2.1748e-04, PNorm = 49.7222, GNorm = 0.2637, lr_0 = 4.0983e-04
Loss = 2.1301e-04, PNorm = 49.7293, GNorm = 0.3850, lr_0 = 4.0941e-04
Loss = 2.4640e-04, PNorm = 49.7333, GNorm = 0.3591, lr_0 = 4.0898e-04
Loss = 2.2241e-04, PNorm = 49.7439, GNorm = 0.6070, lr_0 = 4.0855e-04
Loss = 2.3242e-04, PNorm = 49.7505, GNorm = 0.2148, lr_0 = 4.0813e-04
Validation rmse logD = 0.618741
Validation R2 logD = 0.732249
Validation rmse logP = 0.467051
Validation R2 logP = 0.939951
Epoch 40
Train function
Loss = 1.1759e-04, PNorm = 49.7582, GNorm = 0.2754, lr_0 = 4.0770e-04
Loss = 1.6589e-04, PNorm = 49.7639, GNorm = 0.6127, lr_0 = 4.0727e-04
Loss = 1.8478e-04, PNorm = 49.7717, GNorm = 0.2063, lr_0 = 4.0685e-04
Loss = 1.7678e-04, PNorm = 49.7795, GNorm = 0.3564, lr_0 = 4.0642e-04
Loss = 1.7282e-04, PNorm = 49.7831, GNorm = 0.2450, lr_0 = 4.0600e-04
Loss = 1.6875e-04, PNorm = 49.7872, GNorm = 0.2073, lr_0 = 4.0558e-04
Loss = 1.2387e-04, PNorm = 49.7922, GNorm = 0.2150, lr_0 = 4.0515e-04
Loss = 1.4724e-04, PNorm = 49.7955, GNorm = 0.4118, lr_0 = 4.0473e-04
Loss = 1.7922e-04, PNorm = 49.7986, GNorm = 0.3113, lr_0 = 4.0431e-04
Loss = 1.7432e-04, PNorm = 49.8045, GNorm = 0.2481, lr_0 = 4.0389e-04
Loss = 1.5709e-04, PNorm = 49.8111, GNorm = 0.1817, lr_0 = 4.0346e-04
Loss = 1.5964e-04, PNorm = 49.8139, GNorm = 0.2784, lr_0 = 4.0304e-04
Loss = 1.7511e-04, PNorm = 49.8179, GNorm = 0.1770, lr_0 = 4.0262e-04
Loss = 1.6991e-04, PNorm = 49.8224, GNorm = 0.2506, lr_0 = 4.0220e-04
Loss = 1.6416e-04, PNorm = 49.8283, GNorm = 0.2802, lr_0 = 4.0178e-04
Loss = 1.7129e-04, PNorm = 49.8328, GNorm = 0.2862, lr_0 = 4.0136e-04
Loss = 2.2567e-04, PNorm = 49.8373, GNorm = 0.6784, lr_0 = 4.0094e-04
Loss = 1.8290e-04, PNorm = 49.8429, GNorm = 0.3806, lr_0 = 4.0053e-04
Loss = 1.8729e-04, PNorm = 49.8485, GNorm = 0.3639, lr_0 = 4.0011e-04
Loss = 1.7882e-04, PNorm = 49.8540, GNorm = 0.4327, lr_0 = 3.9969e-04
Loss = 1.7440e-04, PNorm = 49.8600, GNorm = 0.2666, lr_0 = 3.9927e-04
Loss = 1.5907e-04, PNorm = 49.8622, GNorm = 0.3695, lr_0 = 3.9886e-04
Loss = 2.1378e-04, PNorm = 49.8695, GNorm = 0.7160, lr_0 = 3.9844e-04
Validation rmse logD = 0.625318
Validation R2 logD = 0.726527
Validation rmse logP = 0.458589
Validation R2 logP = 0.942108
Epoch 41
Train function
Loss = 2.3257e-04, PNorm = 49.8761, GNorm = 0.3232, lr_0 = 3.9798e-04
Loss = 1.6643e-04, PNorm = 49.8831, GNorm = 0.3154, lr_0 = 3.9757e-04
Loss = 1.5650e-04, PNorm = 49.8883, GNorm = 0.3299, lr_0 = 3.9715e-04
Loss = 1.4506e-04, PNorm = 49.8914, GNorm = 0.2082, lr_0 = 3.9674e-04
Loss = 1.7915e-04, PNorm = 49.9003, GNorm = 0.2487, lr_0 = 3.9632e-04
Loss = 1.3396e-04, PNorm = 49.9058, GNorm = 0.1613, lr_0 = 3.9591e-04
Loss = 1.8524e-04, PNorm = 49.9104, GNorm = 0.4206, lr_0 = 3.9550e-04
Loss = 1.7588e-04, PNorm = 49.9178, GNorm = 0.2342, lr_0 = 3.9508e-04
Loss = 1.7741e-04, PNorm = 49.9221, GNorm = 0.5637, lr_0 = 3.9467e-04
Loss = 1.4161e-04, PNorm = 49.9265, GNorm = 0.2040, lr_0 = 3.9426e-04
Loss = 1.8903e-04, PNorm = 49.9330, GNorm = 0.6222, lr_0 = 3.9385e-04
Loss = 2.0675e-04, PNorm = 49.9401, GNorm = 0.3459, lr_0 = 3.9344e-04
Loss = 1.5984e-04, PNorm = 49.9439, GNorm = 0.3569, lr_0 = 3.9303e-04
Loss = 1.9424e-04, PNorm = 49.9522, GNorm = 0.4274, lr_0 = 3.9262e-04
Loss = 1.4301e-04, PNorm = 49.9567, GNorm = 0.2398, lr_0 = 3.9221e-04
Loss = 1.2707e-04, PNorm = 49.9601, GNorm = 0.2025, lr_0 = 3.9180e-04
Loss = 1.7957e-04, PNorm = 49.9650, GNorm = 0.2849, lr_0 = 3.9139e-04
Loss = 1.5118e-04, PNorm = 49.9717, GNorm = 0.3794, lr_0 = 3.9098e-04
Loss = 1.7837e-04, PNorm = 49.9750, GNorm = 0.2910, lr_0 = 3.9057e-04
Loss = 1.4047e-04, PNorm = 49.9826, GNorm = 0.2463, lr_0 = 3.9016e-04
Loss = 1.7240e-04, PNorm = 49.9890, GNorm = 0.4646, lr_0 = 3.8976e-04
Loss = 1.6958e-04, PNorm = 49.9943, GNorm = 0.2920, lr_0 = 3.8935e-04
Loss = 1.7941e-04, PNorm = 49.9999, GNorm = 0.3531, lr_0 = 3.8894e-04
Validation rmse logD = 0.605358
Validation R2 logD = 0.743707
Validation rmse logP = 0.454899
Validation R2 logP = 0.943036
Epoch 42
Train function
Loss = 1.5142e-04, PNorm = 50.0082, GNorm = 0.4011, lr_0 = 3.8854e-04
Loss = 1.3590e-04, PNorm = 50.0139, GNorm = 0.2665, lr_0 = 3.8813e-04
Loss = 1.3951e-04, PNorm = 50.0178, GNorm = 0.2087, lr_0 = 3.8773e-04
Loss = 1.7822e-04, PNorm = 50.0203, GNorm = 0.1878, lr_0 = 3.8732e-04
Loss = 1.5093e-04, PNorm = 50.0272, GNorm = 0.4202, lr_0 = 3.8692e-04
Loss = 2.0111e-04, PNorm = 50.0342, GNorm = 0.3441, lr_0 = 3.8651e-04
Loss = 1.5491e-04, PNorm = 50.0382, GNorm = 0.1577, lr_0 = 3.8611e-04
Loss = 1.7273e-04, PNorm = 50.0469, GNorm = 0.2887, lr_0 = 3.8571e-04
Loss = 1.5283e-04, PNorm = 50.0528, GNorm = 0.2929, lr_0 = 3.8531e-04
Loss = 1.5506e-04, PNorm = 50.0559, GNorm = 0.2860, lr_0 = 3.8490e-04
Loss = 1.6902e-04, PNorm = 50.0612, GNorm = 0.2446, lr_0 = 3.8450e-04
Loss = 1.5561e-04, PNorm = 50.0636, GNorm = 0.2953, lr_0 = 3.8410e-04
Loss = 1.6390e-04, PNorm = 50.0680, GNorm = 0.2266, lr_0 = 3.8370e-04
Loss = 1.4647e-04, PNorm = 50.0742, GNorm = 0.3043, lr_0 = 3.8330e-04
Loss = 1.4826e-04, PNorm = 50.0788, GNorm = 0.2149, lr_0 = 3.8290e-04
Loss = 1.6862e-04, PNorm = 50.0819, GNorm = 0.2667, lr_0 = 3.8250e-04
Loss = 1.2650e-04, PNorm = 50.0854, GNorm = 0.1978, lr_0 = 3.8210e-04
Loss = 2.0390e-04, PNorm = 50.0925, GNorm = 0.5723, lr_0 = 3.8170e-04
Loss = 1.8450e-04, PNorm = 50.0982, GNorm = 0.3116, lr_0 = 3.8130e-04
Loss = 1.7949e-04, PNorm = 50.1039, GNorm = 0.4359, lr_0 = 3.8090e-04
Loss = 1.8464e-04, PNorm = 50.1111, GNorm = 0.3744, lr_0 = 3.8051e-04
Loss = 1.8352e-04, PNorm = 50.1154, GNorm = 0.2531, lr_0 = 3.8011e-04
Validation rmse logD = 0.609250
Validation R2 logD = 0.740401
Validation rmse logP = 0.458974
Validation R2 logP = 0.942010
Epoch 43
Train function
Loss = 1.1631e-04, PNorm = 50.1223, GNorm = 0.3090, lr_0 = 3.7967e-04
Loss = 1.5160e-04, PNorm = 50.1277, GNorm = 0.2011, lr_0 = 3.7928e-04
Loss = 1.4225e-04, PNorm = 50.1345, GNorm = 0.3101, lr_0 = 3.7888e-04
Loss = 1.3530e-04, PNorm = 50.1389, GNorm = 0.3239, lr_0 = 3.7849e-04
Loss = 1.2786e-04, PNorm = 50.1452, GNorm = 0.1940, lr_0 = 3.7809e-04
Loss = 1.2613e-04, PNorm = 50.1532, GNorm = 0.1670, lr_0 = 3.7770e-04
Loss = 1.5173e-04, PNorm = 50.1580, GNorm = 0.4337, lr_0 = 3.7730e-04
Loss = 1.2371e-04, PNorm = 50.1623, GNorm = 0.2605, lr_0 = 3.7691e-04
Loss = 1.3457e-04, PNorm = 50.1665, GNorm = 0.3162, lr_0 = 3.7652e-04
Loss = 1.7982e-04, PNorm = 50.1688, GNorm = 0.2371, lr_0 = 3.7612e-04
Loss = 1.5998e-04, PNorm = 50.1759, GNorm = 0.3276, lr_0 = 3.7573e-04
Loss = 1.4802e-04, PNorm = 50.1784, GNorm = 0.3634, lr_0 = 3.7534e-04
Loss = 1.6325e-04, PNorm = 50.1839, GNorm = 0.4917, lr_0 = 3.7495e-04
Loss = 1.9572e-04, PNorm = 50.1860, GNorm = 0.5084, lr_0 = 3.7455e-04
Loss = 2.3290e-04, PNorm = 50.1915, GNorm = 0.2718, lr_0 = 3.7416e-04
Loss = 2.1216e-04, PNorm = 50.1993, GNorm = 0.4943, lr_0 = 3.7377e-04
Loss = 1.8042e-04, PNorm = 50.2062, GNorm = 0.2292, lr_0 = 3.7338e-04
Loss = 1.5339e-04, PNorm = 50.2124, GNorm = 0.3055, lr_0 = 3.7299e-04
Loss = 1.2746e-04, PNorm = 50.2147, GNorm = 0.1808, lr_0 = 3.7260e-04
Loss = 1.5047e-04, PNorm = 50.2197, GNorm = 0.2746, lr_0 = 3.7221e-04
Loss = 1.8059e-04, PNorm = 50.2263, GNorm = 0.5288, lr_0 = 3.7183e-04
Loss = 1.9169e-04, PNorm = 50.2336, GNorm = 0.3709, lr_0 = 3.7144e-04
Loss = 1.7471e-04, PNorm = 50.2410, GNorm = 0.2761, lr_0 = 3.7105e-04
Validation rmse logD = 0.611683
Validation R2 logD = 0.738323
Validation rmse logP = 0.463753
Validation R2 logP = 0.940797
Epoch 44
Train function
Loss = 1.5110e-04, PNorm = 50.2463, GNorm = 0.3248, lr_0 = 3.7066e-04
Loss = 1.5122e-04, PNorm = 50.2544, GNorm = 0.2962, lr_0 = 3.7028e-04
Loss = 1.6815e-04, PNorm = 50.2604, GNorm = 0.5706, lr_0 = 3.6989e-04
Loss = 1.5800e-04, PNorm = 50.2676, GNorm = 0.6992, lr_0 = 3.6950e-04
Loss = 1.4790e-04, PNorm = 50.2748, GNorm = 0.2656, lr_0 = 3.6912e-04
Loss = 1.5635e-04, PNorm = 50.2795, GNorm = 0.7782, lr_0 = 3.6873e-04
Loss = 1.4784e-04, PNorm = 50.2839, GNorm = 0.2155, lr_0 = 3.6835e-04
Loss = 1.3089e-04, PNorm = 50.2899, GNorm = 0.3092, lr_0 = 3.6796e-04
Loss = 1.7446e-04, PNorm = 50.2946, GNorm = 0.4898, lr_0 = 3.6758e-04
Loss = 2.0741e-04, PNorm = 50.2991, GNorm = 0.2465, lr_0 = 3.6720e-04
Loss = 1.4522e-04, PNorm = 50.3014, GNorm = 0.2996, lr_0 = 3.6681e-04
Loss = 1.2184e-04, PNorm = 50.3077, GNorm = 0.2338, lr_0 = 3.6643e-04
Loss = 1.3044e-04, PNorm = 50.3126, GNorm = 0.2537, lr_0 = 3.6605e-04
Loss = 1.4147e-04, PNorm = 50.3158, GNorm = 0.2494, lr_0 = 3.6567e-04
Loss = 1.4165e-04, PNorm = 50.3207, GNorm = 0.6130, lr_0 = 3.6528e-04
Loss = 1.9255e-04, PNorm = 50.3254, GNorm = 0.4139, lr_0 = 3.6490e-04
Loss = 1.6896e-04, PNorm = 50.3324, GNorm = 0.4234, lr_0 = 3.6452e-04
Loss = 1.3871e-04, PNorm = 50.3334, GNorm = 0.4724, lr_0 = 3.6414e-04
Loss = 1.5009e-04, PNorm = 50.3390, GNorm = 0.2768, lr_0 = 3.6376e-04
Loss = 1.4708e-04, PNorm = 50.3442, GNorm = 0.3251, lr_0 = 3.6338e-04
Loss = 1.7911e-04, PNorm = 50.3494, GNorm = 0.2833, lr_0 = 3.6300e-04
Loss = 1.5121e-04, PNorm = 50.3531, GNorm = 0.2680, lr_0 = 3.6262e-04
Validation rmse logD = 0.603238
Validation R2 logD = 0.745499
Validation rmse logP = 0.452111
Validation R2 logP = 0.943732
Epoch 45
Train function
Loss = 8.4260e-05, PNorm = 50.3542, GNorm = 0.1550, lr_0 = 3.6221e-04
Loss = 1.3633e-04, PNorm = 50.3592, GNorm = 0.4551, lr_0 = 3.6183e-04
Loss = 1.6751e-04, PNorm = 50.3650, GNorm = 0.3447, lr_0 = 3.6145e-04
Loss = 1.1637e-04, PNorm = 50.3680, GNorm = 0.3634, lr_0 = 3.6107e-04
Loss = 1.3686e-04, PNorm = 50.3727, GNorm = 0.5214, lr_0 = 3.6070e-04
Loss = 1.7376e-04, PNorm = 50.3807, GNorm = 0.2743, lr_0 = 3.6032e-04
Loss = 1.6520e-04, PNorm = 50.3870, GNorm = 0.7072, lr_0 = 3.5994e-04
Loss = 1.4464e-04, PNorm = 50.3932, GNorm = 0.1974, lr_0 = 3.5957e-04
Loss = 1.9338e-04, PNorm = 50.3974, GNorm = 0.2492, lr_0 = 3.5919e-04
Loss = 1.5231e-04, PNorm = 50.4023, GNorm = 0.4789, lr_0 = 3.5882e-04
Loss = 1.1167e-04, PNorm = 50.4077, GNorm = 0.1675, lr_0 = 3.5844e-04
Loss = 1.0353e-04, PNorm = 50.4125, GNorm = 0.1385, lr_0 = 3.5807e-04
Loss = 1.0707e-04, PNorm = 50.4175, GNorm = 0.2360, lr_0 = 3.5770e-04
Loss = 1.2795e-04, PNorm = 50.4217, GNorm = 0.3010, lr_0 = 3.5732e-04
Loss = 1.1937e-04, PNorm = 50.4280, GNorm = 0.4334, lr_0 = 3.5695e-04
Loss = 1.3058e-04, PNorm = 50.4328, GNorm = 0.2476, lr_0 = 3.5658e-04
Loss = 1.4283e-04, PNorm = 50.4397, GNorm = 0.2002, lr_0 = 3.5621e-04
Loss = 1.3600e-04, PNorm = 50.4434, GNorm = 0.2845, lr_0 = 3.5583e-04
Loss = 1.6755e-04, PNorm = 50.4505, GNorm = 0.4803, lr_0 = 3.5546e-04
Loss = 1.2574e-04, PNorm = 50.4555, GNorm = 0.2336, lr_0 = 3.5509e-04
Loss = 1.4552e-04, PNorm = 50.4608, GNorm = 0.2701, lr_0 = 3.5472e-04
Loss = 1.8081e-04, PNorm = 50.4633, GNorm = 0.3215, lr_0 = 3.5435e-04
Loss = 1.2607e-04, PNorm = 50.4673, GNorm = 0.2546, lr_0 = 3.5398e-04
Validation rmse logD = 0.630672
Validation R2 logD = 0.721825
Validation rmse logP = 0.451166
Validation R2 logP = 0.943967
Epoch 46
Train function
Loss = 1.4951e-04, PNorm = 50.4738, GNorm = 0.3749, lr_0 = 3.5361e-04
Loss = 1.4625e-04, PNorm = 50.4762, GNorm = 0.3622, lr_0 = 3.5324e-04
Loss = 1.6942e-04, PNorm = 50.4798, GNorm = 0.3065, lr_0 = 3.5287e-04
Loss = 1.6107e-04, PNorm = 50.4872, GNorm = 0.2541, lr_0 = 3.5251e-04
Loss = 1.4886e-04, PNorm = 50.4922, GNorm = 0.5177, lr_0 = 3.5214e-04
Loss = 1.3978e-04, PNorm = 50.4967, GNorm = 0.1691, lr_0 = 3.5177e-04
Loss = 1.4824e-04, PNorm = 50.5029, GNorm = 0.3664, lr_0 = 3.5140e-04
Loss = 2.1082e-04, PNorm = 50.5085, GNorm = 0.4726, lr_0 = 3.5104e-04
Loss = 1.7083e-04, PNorm = 50.5136, GNorm = 0.2145, lr_0 = 3.5067e-04
Loss = 1.5435e-04, PNorm = 50.5182, GNorm = 0.2008, lr_0 = 3.5030e-04
Loss = 1.3950e-04, PNorm = 50.5220, GNorm = 0.3612, lr_0 = 3.4994e-04
Loss = 1.3155e-04, PNorm = 50.5258, GNorm = 0.3206, lr_0 = 3.4957e-04
Loss = 1.3973e-04, PNorm = 50.5351, GNorm = 0.2420, lr_0 = 3.4921e-04
Loss = 1.2810e-04, PNorm = 50.5392, GNorm = 0.2852, lr_0 = 3.4884e-04
Loss = 1.3771e-04, PNorm = 50.5426, GNorm = 0.2208, lr_0 = 3.4848e-04
Loss = 1.4648e-04, PNorm = 50.5465, GNorm = 0.3508, lr_0 = 3.4812e-04
Loss = 1.5999e-04, PNorm = 50.5556, GNorm = 0.2327, lr_0 = 3.4775e-04
Loss = 1.0714e-04, PNorm = 50.5601, GNorm = 0.1911, lr_0 = 3.4739e-04
Loss = 1.1975e-04, PNorm = 50.5635, GNorm = 0.1571, lr_0 = 3.4703e-04
Loss = 1.2677e-04, PNorm = 50.5690, GNorm = 0.3299, lr_0 = 3.4666e-04
Loss = 1.5637e-04, PNorm = 50.5743, GNorm = 0.1977, lr_0 = 3.4630e-04
Loss = 1.4130e-04, PNorm = 50.5818, GNorm = 0.3279, lr_0 = 3.4594e-04
Validation rmse logD = 0.612129
Validation R2 logD = 0.737942
Validation rmse logP = 0.459838
Validation R2 logP = 0.941792
Epoch 47
Train function
Loss = 1.0344e-04, PNorm = 50.5887, GNorm = 0.1999, lr_0 = 3.4554e-04
Loss = 1.2310e-04, PNorm = 50.5924, GNorm = 0.2627, lr_0 = 3.4518e-04
Loss = 7.7526e-05, PNorm = 50.5942, GNorm = 0.1410, lr_0 = 3.4482e-04
Loss = 1.2384e-04, PNorm = 50.5987, GNorm = 0.2024, lr_0 = 3.4446e-04
Loss = 1.3260e-04, PNorm = 50.6051, GNorm = 0.1963, lr_0 = 3.4410e-04
Loss = 1.0190e-04, PNorm = 50.6074, GNorm = 0.3458, lr_0 = 3.4374e-04
Loss = 1.1326e-04, PNorm = 50.6099, GNorm = 0.2629, lr_0 = 3.4339e-04
Loss = 9.5450e-05, PNorm = 50.6148, GNorm = 0.1902, lr_0 = 3.4303e-04
Loss = 1.0816e-04, PNorm = 50.6212, GNorm = 0.2449, lr_0 = 3.4267e-04
Loss = 9.9357e-05, PNorm = 50.6223, GNorm = 0.2696, lr_0 = 3.4231e-04
Loss = 9.9918e-05, PNorm = 50.6248, GNorm = 0.1853, lr_0 = 3.4195e-04
Loss = 1.2018e-04, PNorm = 50.6277, GNorm = 0.4152, lr_0 = 3.4160e-04
Loss = 1.1363e-04, PNorm = 50.6306, GNorm = 0.1754, lr_0 = 3.4124e-04
Loss = 1.3098e-04, PNorm = 50.6305, GNorm = 0.2209, lr_0 = 3.4088e-04
Loss = 1.3444e-04, PNorm = 50.6307, GNorm = 0.2060, lr_0 = 3.4053e-04
Loss = 1.3679e-04, PNorm = 50.6365, GNorm = 0.2825, lr_0 = 3.4017e-04
Loss = 1.2681e-04, PNorm = 50.6403, GNorm = 0.1959, lr_0 = 3.3982e-04
Loss = 1.3790e-04, PNorm = 50.6455, GNorm = 0.2890, lr_0 = 3.3946e-04
Loss = 1.0745e-04, PNorm = 50.6513, GNorm = 0.2239, lr_0 = 3.3911e-04
Loss = 1.1463e-04, PNorm = 50.6554, GNorm = 0.2441, lr_0 = 3.3876e-04
Loss = 1.1530e-04, PNorm = 50.6588, GNorm = 0.2026, lr_0 = 3.3840e-04
Loss = 1.4860e-04, PNorm = 50.6623, GNorm = 0.5801, lr_0 = 3.3805e-04
Loss = 1.4862e-04, PNorm = 50.6696, GNorm = 0.1833, lr_0 = 3.3770e-04
Validation rmse logD = 0.604371
Validation R2 logD = 0.744542
Validation rmse logP = 0.462868
Validation R2 logP = 0.941022
Epoch 48
Train function
Loss = 1.1316e-04, PNorm = 50.6722, GNorm = 0.3212, lr_0 = 3.3734e-04
Loss = 9.9317e-05, PNorm = 50.6756, GNorm = 0.2722, lr_0 = 3.3699e-04
Loss = 1.0076e-04, PNorm = 50.6797, GNorm = 0.2159, lr_0 = 3.3664e-04
Loss = 8.9297e-05, PNorm = 50.6834, GNorm = 0.1560, lr_0 = 3.3629e-04
Loss = 9.2218e-05, PNorm = 50.6879, GNorm = 0.3458, lr_0 = 3.3594e-04
Loss = 1.0477e-04, PNorm = 50.6912, GNorm = 0.3368, lr_0 = 3.3559e-04
Loss = 1.4557e-04, PNorm = 50.6966, GNorm = 0.1632, lr_0 = 3.3524e-04
Loss = 1.2640e-04, PNorm = 50.7033, GNorm = 0.2728, lr_0 = 3.3489e-04
Loss = 1.0463e-04, PNorm = 50.7089, GNorm = 0.1789, lr_0 = 3.3454e-04
Loss = 1.1994e-04, PNorm = 50.7141, GNorm = 0.2208, lr_0 = 3.3419e-04
Loss = 1.0991e-04, PNorm = 50.7200, GNorm = 0.1556, lr_0 = 3.3384e-04
Loss = 9.6650e-05, PNorm = 50.7236, GNorm = 0.1802, lr_0 = 3.3349e-04
Loss = 1.1904e-04, PNorm = 50.7277, GNorm = 0.3433, lr_0 = 3.3314e-04
Loss = 1.1573e-04, PNorm = 50.7331, GNorm = 0.2520, lr_0 = 3.3280e-04
Loss = 1.1391e-04, PNorm = 50.7356, GNorm = 0.1801, lr_0 = 3.3245e-04
Loss = 1.2986e-04, PNorm = 50.7417, GNorm = 0.2954, lr_0 = 3.3210e-04
Loss = 1.1437e-04, PNorm = 50.7467, GNorm = 0.2502, lr_0 = 3.3175e-04
Loss = 8.9380e-05, PNorm = 50.7477, GNorm = 0.1774, lr_0 = 3.3141e-04
Loss = 8.4359e-05, PNorm = 50.7512, GNorm = 0.1487, lr_0 = 3.3106e-04
Loss = 1.0304e-04, PNorm = 50.7535, GNorm = 0.2726, lr_0 = 3.3072e-04
Loss = 1.3496e-04, PNorm = 50.7578, GNorm = 0.1951, lr_0 = 3.3037e-04
Loss = 1.4923e-04, PNorm = 50.7605, GNorm = 0.5644, lr_0 = 3.3003e-04
Validation rmse logD = 0.620482
Validation R2 logD = 0.730741
Validation rmse logP = 0.459176
Validation R2 logP = 0.941959
Epoch 49
Train function
Loss = 1.7804e-04, PNorm = 50.7629, GNorm = 0.2962, lr_0 = 3.2965e-04
Loss = 1.5777e-04, PNorm = 50.7680, GNorm = 0.3881, lr_0 = 3.2930e-04
Loss = 1.5174e-04, PNorm = 50.7731, GNorm = 0.3411, lr_0 = 3.2896e-04
Loss = 1.5410e-04, PNorm = 50.7805, GNorm = 0.3546, lr_0 = 3.2862e-04
Loss = 1.2429e-04, PNorm = 50.7839, GNorm = 0.3531, lr_0 = 3.2827e-04
Loss = 1.2359e-04, PNorm = 50.7849, GNorm = 0.3221, lr_0 = 3.2793e-04
Loss = 1.1749e-04, PNorm = 50.7881, GNorm = 0.2746, lr_0 = 3.2759e-04
Loss = 1.3322e-04, PNorm = 50.7952, GNorm = 0.4455, lr_0 = 3.2725e-04
Loss = 1.4072e-04, PNorm = 50.8032, GNorm = 0.3034, lr_0 = 3.2691e-04
Loss = 1.3957e-04, PNorm = 50.8089, GNorm = 0.5024, lr_0 = 3.2656e-04
Loss = 1.6669e-04, PNorm = 50.8145, GNorm = 0.2449, lr_0 = 3.2622e-04
Loss = 1.4577e-04, PNorm = 50.8180, GNorm = 0.2445, lr_0 = 3.2588e-04
Loss = 1.1520e-04, PNorm = 50.8226, GNorm = 0.1399, lr_0 = 3.2554e-04
Loss = 1.1638e-04, PNorm = 50.8258, GNorm = 0.2438, lr_0 = 3.2520e-04
Loss = 1.3930e-04, PNorm = 50.8295, GNorm = 0.2964, lr_0 = 3.2486e-04
Loss = 1.4788e-04, PNorm = 50.8373, GNorm = 0.4043, lr_0 = 3.2452e-04
Loss = 1.2283e-04, PNorm = 50.8398, GNorm = 0.1924, lr_0 = 3.2419e-04
Loss = 1.0493e-04, PNorm = 50.8431, GNorm = 0.2711, lr_0 = 3.2385e-04
Loss = 1.1746e-04, PNorm = 50.8473, GNorm = 0.2491, lr_0 = 3.2351e-04
Loss = 1.0121e-04, PNorm = 50.8500, GNorm = 0.1724, lr_0 = 3.2317e-04
Loss = 1.1964e-04, PNorm = 50.8556, GNorm = 0.4742, lr_0 = 3.2283e-04
Loss = 1.1733e-04, PNorm = 50.8602, GNorm = 0.2244, lr_0 = 3.2250e-04
Loss = 1.3309e-04, PNorm = 50.8678, GNorm = 0.4412, lr_0 = 3.2216e-04
Validation rmse logD = 0.612188
Validation R2 logD = 0.737891
Validation rmse logP = 0.455377
Validation R2 logP = 0.942916
Epoch 50
Train function
Loss = 1.5808e-04, PNorm = 50.8716, GNorm = 0.3684, lr_0 = 3.2182e-04
Loss = 1.4198e-04, PNorm = 50.8743, GNorm = 0.1986, lr_0 = 3.2149e-04
Loss = 1.0853e-04, PNorm = 50.8806, GNorm = 0.2021, lr_0 = 3.2115e-04
Loss = 1.0982e-04, PNorm = 50.8857, GNorm = 0.2867, lr_0 = 3.2082e-04
Loss = 9.5835e-05, PNorm = 50.8907, GNorm = 0.2832, lr_0 = 3.2048e-04
Loss = 1.4312e-04, PNorm = 50.8939, GNorm = 0.3524, lr_0 = 3.2015e-04
Loss = 1.2997e-04, PNorm = 50.8971, GNorm = 0.1805, lr_0 = 3.1981e-04
Loss = 1.3647e-04, PNorm = 50.9028, GNorm = 0.2259, lr_0 = 3.1948e-04
Loss = 1.1079e-04, PNorm = 50.9066, GNorm = 0.1843, lr_0 = 3.1915e-04
Loss = 1.2893e-04, PNorm = 50.9100, GNorm = 0.2997, lr_0 = 3.1881e-04
Loss = 1.0953e-04, PNorm = 50.9153, GNorm = 0.3497, lr_0 = 3.1848e-04
Loss = 1.0532e-04, PNorm = 50.9200, GNorm = 0.3300, lr_0 = 3.1815e-04
Loss = 9.5852e-05, PNorm = 50.9226, GNorm = 0.2527, lr_0 = 3.1782e-04
Loss = 1.2170e-04, PNorm = 50.9257, GNorm = 0.1584, lr_0 = 3.1749e-04
Loss = 1.1325e-04, PNorm = 50.9278, GNorm = 0.2070, lr_0 = 3.1715e-04
Loss = 1.2330e-04, PNorm = 50.9318, GNorm = 0.1625, lr_0 = 3.1682e-04
Loss = 1.1767e-04, PNorm = 50.9351, GNorm = 0.4640, lr_0 = 3.1649e-04
Loss = 1.2560e-04, PNorm = 50.9387, GNorm = 0.2931, lr_0 = 3.1616e-04
Loss = 1.3313e-04, PNorm = 50.9465, GNorm = 0.2214, lr_0 = 3.1583e-04
Loss = 1.0016e-04, PNorm = 50.9529, GNorm = 0.2215, lr_0 = 3.1550e-04
Loss = 1.3042e-04, PNorm = 50.9587, GNorm = 0.2825, lr_0 = 3.1517e-04
Loss = 9.9983e-05, PNorm = 50.9630, GNorm = 0.2548, lr_0 = 3.1484e-04
Validation rmse logD = 0.601321
Validation R2 logD = 0.747114
Validation rmse logP = 0.456267
Validation R2 logP = 0.942692
Epoch 51
Train function
Loss = 1.3930e-04, PNorm = 50.9668, GNorm = 0.3450, lr_0 = 3.1448e-04
Loss = 9.4389e-05, PNorm = 50.9686, GNorm = 0.2708, lr_0 = 3.1415e-04
Loss = 1.0587e-04, PNorm = 50.9708, GNorm = 0.3910, lr_0 = 3.1383e-04
Loss = 1.2097e-04, PNorm = 50.9764, GNorm = 0.1896, lr_0 = 3.1350e-04
Loss = 9.6514e-05, PNorm = 50.9797, GNorm = 0.1886, lr_0 = 3.1317e-04
Loss = 1.1703e-04, PNorm = 50.9842, GNorm = 0.2060, lr_0 = 3.1284e-04
Loss = 1.0031e-04, PNorm = 50.9879, GNorm = 0.2846, lr_0 = 3.1252e-04
Loss = 1.1015e-04, PNorm = 50.9941, GNorm = 0.2080, lr_0 = 3.1219e-04
Loss = 1.0447e-04, PNorm = 51.0000, GNorm = 0.2627, lr_0 = 3.1187e-04
Loss = 9.8271e-05, PNorm = 51.0020, GNorm = 0.2484, lr_0 = 3.1154e-04
Loss = 1.1967e-04, PNorm = 51.0023, GNorm = 0.5012, lr_0 = 3.1122e-04
Loss = 1.3763e-04, PNorm = 51.0066, GNorm = 0.5506, lr_0 = 3.1089e-04
Loss = 1.3685e-04, PNorm = 51.0127, GNorm = 0.3233, lr_0 = 3.1057e-04
Loss = 1.1935e-04, PNorm = 51.0162, GNorm = 0.2745, lr_0 = 3.1024e-04
Loss = 1.1154e-04, PNorm = 51.0233, GNorm = 0.2228, lr_0 = 3.0992e-04
Loss = 1.0862e-04, PNorm = 51.0301, GNorm = 0.2909, lr_0 = 3.0959e-04
Loss = 8.4981e-05, PNorm = 51.0325, GNorm = 0.1857, lr_0 = 3.0927e-04
Loss = 7.9471e-05, PNorm = 51.0356, GNorm = 0.1564, lr_0 = 3.0895e-04
Loss = 8.9595e-05, PNorm = 51.0383, GNorm = 0.2431, lr_0 = 3.0863e-04
Loss = 8.2908e-05, PNorm = 51.0390, GNorm = 0.1740, lr_0 = 3.0830e-04
Loss = 9.7863e-05, PNorm = 51.0406, GNorm = 0.3155, lr_0 = 3.0798e-04
Loss = 1.1770e-04, PNorm = 51.0434, GNorm = 0.2441, lr_0 = 3.0766e-04
Loss = 1.0536e-04, PNorm = 51.0458, GNorm = 0.2239, lr_0 = 3.0734e-04
Validation rmse logD = 0.608918
Validation R2 logD = 0.740684
Validation rmse logP = 0.458616
Validation R2 logP = 0.942101
Epoch 52
Train function
Loss = 1.0800e-04, PNorm = 51.0491, GNorm = 0.2976, lr_0 = 3.0699e-04
Loss = 9.2925e-05, PNorm = 51.0520, GNorm = 0.2807, lr_0 = 3.0667e-04
Loss = 8.9054e-05, PNorm = 51.0577, GNorm = 0.2727, lr_0 = 3.0635e-04
Loss = 7.6242e-05, PNorm = 51.0613, GNorm = 0.2615, lr_0 = 3.0603e-04
Loss = 9.0438e-05, PNorm = 51.0647, GNorm = 0.2265, lr_0 = 3.0571e-04
Loss = 8.5830e-05, PNorm = 51.0674, GNorm = 0.3734, lr_0 = 3.0539e-04
Loss = 8.8066e-05, PNorm = 51.0700, GNorm = 0.2652, lr_0 = 3.0507e-04
Loss = 8.2496e-05, PNorm = 51.0732, GNorm = 0.1685, lr_0 = 3.0475e-04
Loss = 9.8531e-05, PNorm = 51.0789, GNorm = 0.2780, lr_0 = 3.0443e-04
Loss = 1.2031e-04, PNorm = 51.0817, GNorm = 0.3504, lr_0 = 3.0412e-04
Loss = 9.2753e-05, PNorm = 51.0844, GNorm = 0.1810, lr_0 = 3.0380e-04
Loss = 1.0429e-04, PNorm = 51.0900, GNorm = 0.2114, lr_0 = 3.0348e-04
Loss = 1.0352e-04, PNorm = 51.0965, GNorm = 0.4051, lr_0 = 3.0316e-04
Loss = 9.5918e-05, PNorm = 51.1010, GNorm = 0.1817, lr_0 = 3.0285e-04
Loss = 9.3840e-05, PNorm = 51.1061, GNorm = 0.1979, lr_0 = 3.0253e-04
Loss = 1.0592e-04, PNorm = 51.1108, GNorm = 0.2859, lr_0 = 3.0222e-04
Loss = 8.8677e-05, PNorm = 51.1157, GNorm = 0.1615, lr_0 = 3.0190e-04
Loss = 1.2305e-04, PNorm = 51.1203, GNorm = 0.1594, lr_0 = 3.0159e-04
Loss = 1.1963e-04, PNorm = 51.1242, GNorm = 0.3396, lr_0 = 3.0127e-04
Loss = 1.1019e-04, PNorm = 51.1256, GNorm = 0.1992, lr_0 = 3.0096e-04
Loss = 1.7719e-04, PNorm = 51.1289, GNorm = 0.5403, lr_0 = 3.0064e-04
Loss = 1.1282e-04, PNorm = 51.1347, GNorm = 0.2199, lr_0 = 3.0033e-04
Loss = 1.1034e-04, PNorm = 51.1408, GNorm = 0.3084, lr_0 = 3.0001e-04
Validation rmse logD = 0.607159
Validation R2 logD = 0.742180
Validation rmse logP = 0.457041
Validation R2 logP = 0.942498
Epoch 53
Train function
Loss = 9.9209e-05, PNorm = 51.1417, GNorm = 0.1991, lr_0 = 2.9970e-04
Loss = 8.3130e-05, PNorm = 51.1468, GNorm = 0.1401, lr_0 = 2.9939e-04
Loss = 9.0884e-05, PNorm = 51.1495, GNorm = 0.2288, lr_0 = 2.9908e-04
Loss = 9.8468e-05, PNorm = 51.1514, GNorm = 0.1869, lr_0 = 2.9876e-04
Loss = 1.0065e-04, PNorm = 51.1550, GNorm = 0.3850, lr_0 = 2.9845e-04
Loss = 8.4208e-05, PNorm = 51.1580, GNorm = 0.1733, lr_0 = 2.9814e-04
Loss = 6.6255e-05, PNorm = 51.1592, GNorm = 0.1709, lr_0 = 2.9783e-04
Loss = 7.0522e-05, PNorm = 51.1626, GNorm = 0.1218, lr_0 = 2.9752e-04
Loss = 7.7376e-05, PNorm = 51.1641, GNorm = 0.2291, lr_0 = 2.9721e-04
Loss = 1.0462e-04, PNorm = 51.1657, GNorm = 0.2392, lr_0 = 2.9690e-04
Loss = 9.1915e-05, PNorm = 51.1665, GNorm = 0.2952, lr_0 = 2.9659e-04
Loss = 9.1430e-05, PNorm = 51.1711, GNorm = 0.3042, lr_0 = 2.9628e-04
Loss = 8.1555e-05, PNorm = 51.1746, GNorm = 0.1214, lr_0 = 2.9597e-04
Loss = 9.1718e-05, PNorm = 51.1780, GNorm = 0.2238, lr_0 = 2.9566e-04
Loss = 1.0341e-04, PNorm = 51.1826, GNorm = 0.2373, lr_0 = 2.9535e-04
Loss = 1.2489e-04, PNorm = 51.1891, GNorm = 0.3710, lr_0 = 2.9504e-04
Loss = 1.3110e-04, PNorm = 51.1924, GNorm = 0.1973, lr_0 = 2.9474e-04
Loss = 1.1099e-04, PNorm = 51.1969, GNorm = 0.2513, lr_0 = 2.9443e-04
Loss = 8.4128e-05, PNorm = 51.1999, GNorm = 0.2695, lr_0 = 2.9412e-04
Loss = 1.1491e-04, PNorm = 51.2026, GNorm = 0.2878, lr_0 = 2.9381e-04
Loss = 8.6877e-05, PNorm = 51.2074, GNorm = 0.1425, lr_0 = 2.9351e-04
Loss = 8.9153e-05, PNorm = 51.2118, GNorm = 0.1457, lr_0 = 2.9320e-04
Validation rmse logD = 0.604076
Validation R2 logD = 0.744791
Validation rmse logP = 0.456401
Validation R2 logP = 0.942659
Epoch 54
Train function
Loss = 7.3421e-05, PNorm = 51.2127, GNorm = 0.2398, lr_0 = 2.9286e-04
Loss = 7.1453e-05, PNorm = 51.2150, GNorm = 0.1775, lr_0 = 2.9256e-04
Loss = 7.4051e-05, PNorm = 51.2161, GNorm = 0.1470, lr_0 = 2.9225e-04
Loss = 7.3522e-05, PNorm = 51.2179, GNorm = 0.1779, lr_0 = 2.9195e-04
Loss = 8.7727e-05, PNorm = 51.2208, GNorm = 0.1503, lr_0 = 2.9164e-04
Loss = 7.0609e-05, PNorm = 51.2249, GNorm = 0.1587, lr_0 = 2.9134e-04
Loss = 7.1198e-05, PNorm = 51.2290, GNorm = 0.1501, lr_0 = 2.9104e-04
Loss = 7.3301e-05, PNorm = 51.2305, GNorm = 0.1624, lr_0 = 2.9073e-04
Loss = 6.6416e-05, PNorm = 51.2331, GNorm = 0.2632, lr_0 = 2.9043e-04
Loss = 7.0772e-05, PNorm = 51.2361, GNorm = 0.1875, lr_0 = 2.9012e-04
Loss = 6.1909e-05, PNorm = 51.2386, GNorm = 0.1698, lr_0 = 2.8982e-04
Loss = 7.2889e-05, PNorm = 51.2406, GNorm = 0.1252, lr_0 = 2.8952e-04
Loss = 6.7122e-05, PNorm = 51.2429, GNorm = 0.1625, lr_0 = 2.8922e-04
Loss = 6.6523e-05, PNorm = 51.2455, GNorm = 0.1316, lr_0 = 2.8892e-04
Loss = 7.2344e-05, PNorm = 51.2492, GNorm = 0.2619, lr_0 = 2.8861e-04
Loss = 8.5975e-05, PNorm = 51.2559, GNorm = 0.4001, lr_0 = 2.8831e-04
Loss = 1.0066e-04, PNorm = 51.2604, GNorm = 0.2724, lr_0 = 2.8801e-04
Loss = 9.9831e-05, PNorm = 51.2640, GNorm = 0.2006, lr_0 = 2.8771e-04
Loss = 7.8195e-05, PNorm = 51.2662, GNorm = 0.2779, lr_0 = 2.8741e-04
Loss = 9.6784e-05, PNorm = 51.2677, GNorm = 0.2021, lr_0 = 2.8711e-04
Loss = 9.3781e-05, PNorm = 51.2728, GNorm = 0.1715, lr_0 = 2.8681e-04
Loss = 9.2867e-05, PNorm = 51.2768, GNorm = 0.1684, lr_0 = 2.8651e-04
Loss = 1.2365e-04, PNorm = 51.2811, GNorm = 0.1422, lr_0 = 2.8621e-04
Validation rmse logD = 0.611646
Validation R2 logD = 0.738355
Validation rmse logP = 0.455455
Validation R2 logP = 0.942896
Epoch 55
Train function
Loss = 8.3336e-05, PNorm = 51.2841, GNorm = 0.1934, lr_0 = 2.8591e-04
Loss = 7.9104e-05, PNorm = 51.2876, GNorm = 0.1956, lr_0 = 2.8562e-04
Loss = 5.8833e-05, PNorm = 51.2900, GNorm = 0.2019, lr_0 = 2.8532e-04
Loss = 7.7153e-05, PNorm = 51.2909, GNorm = 0.2079, lr_0 = 2.8502e-04
Loss = 6.2426e-05, PNorm = 51.2935, GNorm = 0.1354, lr_0 = 2.8472e-04
Loss = 7.3542e-05, PNorm = 51.2975, GNorm = 0.1330, lr_0 = 2.8443e-04
Loss = 6.4144e-05, PNorm = 51.2989, GNorm = 0.1634, lr_0 = 2.8413e-04
Loss = 6.5520e-05, PNorm = 51.3013, GNorm = 0.1453, lr_0 = 2.8383e-04
Loss = 6.8281e-05, PNorm = 51.3039, GNorm = 0.1008, lr_0 = 2.8354e-04
Loss = 8.1434e-05, PNorm = 51.3069, GNorm = 0.2122, lr_0 = 2.8324e-04
Loss = 7.3894e-05, PNorm = 51.3084, GNorm = 0.2128, lr_0 = 2.8294e-04
Loss = 6.6097e-05, PNorm = 51.3130, GNorm = 0.1127, lr_0 = 2.8265e-04
Loss = 6.6722e-05, PNorm = 51.3148, GNorm = 0.1552, lr_0 = 2.8235e-04
Loss = 7.5572e-05, PNorm = 51.3179, GNorm = 0.2083, lr_0 = 2.8206e-04
Loss = 9.2360e-05, PNorm = 51.3209, GNorm = 0.1908, lr_0 = 2.8176e-04
Loss = 7.1414e-05, PNorm = 51.3250, GNorm = 0.1642, lr_0 = 2.8147e-04
Loss = 8.7180e-05, PNorm = 51.3287, GNorm = 0.1548, lr_0 = 2.8118e-04
Loss = 8.7056e-05, PNorm = 51.3316, GNorm = 0.2937, lr_0 = 2.8088e-04
Loss = 7.4309e-05, PNorm = 51.3337, GNorm = 0.1302, lr_0 = 2.8059e-04
Loss = 8.2729e-05, PNorm = 51.3377, GNorm = 0.1706, lr_0 = 2.8030e-04
Loss = 1.0112e-04, PNorm = 51.3417, GNorm = 0.2573, lr_0 = 2.8000e-04
Loss = 8.4318e-05, PNorm = 51.3447, GNorm = 0.1529, lr_0 = 2.7971e-04
Validation rmse logD = 0.604778
Validation R2 logD = 0.744198
Validation rmse logP = 0.457111
Validation R2 logP = 0.942480
Epoch 56
Train function
Loss = 8.7716e-05, PNorm = 51.3456, GNorm = 0.2893, lr_0 = 2.7939e-04
Loss = 7.2917e-05, PNorm = 51.3493, GNorm = 0.1879, lr_0 = 2.7910e-04
Loss = 8.4415e-05, PNorm = 51.3514, GNorm = 0.1567, lr_0 = 2.7881e-04
Loss = 7.1075e-05, PNorm = 51.3545, GNorm = 0.3068, lr_0 = 2.7852e-04
Loss = 7.1168e-05, PNorm = 51.3586, GNorm = 0.1680, lr_0 = 2.7823e-04
Loss = 8.0585e-05, PNorm = 51.3605, GNorm = 0.3209, lr_0 = 2.7794e-04
Loss = 8.8131e-05, PNorm = 51.3644, GNorm = 0.4239, lr_0 = 2.7765e-04
Loss = 6.5919e-05, PNorm = 51.3678, GNorm = 0.2038, lr_0 = 2.7736e-04
Loss = 6.2048e-05, PNorm = 51.3727, GNorm = 0.2293, lr_0 = 2.7707e-04
Loss = 9.0444e-05, PNorm = 51.3753, GNorm = 0.3393, lr_0 = 2.7678e-04
Loss = 7.6385e-05, PNorm = 51.3768, GNorm = 0.1396, lr_0 = 2.7649e-04
Loss = 8.2085e-05, PNorm = 51.3772, GNorm = 0.1524, lr_0 = 2.7620e-04
Loss = 8.5377e-05, PNorm = 51.3797, GNorm = 0.1707, lr_0 = 2.7591e-04
Loss = 1.0131e-04, PNorm = 51.3849, GNorm = 0.2254, lr_0 = 2.7562e-04
Loss = 7.1925e-05, PNorm = 51.3882, GNorm = 0.2555, lr_0 = 2.7534e-04
Loss = 8.6525e-05, PNorm = 51.3930, GNorm = 0.2222, lr_0 = 2.7505e-04
Loss = 7.8202e-05, PNorm = 51.3943, GNorm = 0.3745, lr_0 = 2.7476e-04
Loss = 7.7995e-05, PNorm = 51.3970, GNorm = 0.3755, lr_0 = 2.7448e-04
Loss = 7.3110e-05, PNorm = 51.3988, GNorm = 0.0826, lr_0 = 2.7419e-04
Loss = 8.7387e-05, PNorm = 51.3996, GNorm = 0.2189, lr_0 = 2.7390e-04
Loss = 9.1594e-05, PNorm = 51.4039, GNorm = 0.1411, lr_0 = 2.7362e-04
Loss = 6.7782e-05, PNorm = 51.4067, GNorm = 0.1289, lr_0 = 2.7333e-04
Loss = 9.5507e-05, PNorm = 51.4085, GNorm = 0.3120, lr_0 = 2.7305e-04
Validation rmse logD = 0.613162
Validation R2 logD = 0.737056
Validation rmse logP = 0.454356
Validation R2 logP = 0.943172
Epoch 57
Train function
Loss = 8.6620e-05, PNorm = 51.4117, GNorm = 0.1976, lr_0 = 2.7276e-04
Loss = 9.8441e-05, PNorm = 51.4129, GNorm = 0.2794, lr_0 = 2.7248e-04
Loss = 8.7571e-05, PNorm = 51.4178, GNorm = 0.1873, lr_0 = 2.7219e-04
Loss = 7.3593e-05, PNorm = 51.4222, GNorm = 0.1342, lr_0 = 2.7191e-04
Loss = 6.7092e-05, PNorm = 51.4244, GNorm = 0.1905, lr_0 = 2.7162e-04
Loss = 7.9448e-05, PNorm = 51.4279, GNorm = 0.1830, lr_0 = 2.7134e-04
Loss = 8.6409e-05, PNorm = 51.4311, GNorm = 0.2742, lr_0 = 2.7106e-04
Loss = 8.0929e-05, PNorm = 51.4338, GNorm = 0.2791, lr_0 = 2.7077e-04
Loss = 7.4336e-05, PNorm = 51.4358, GNorm = 0.2091, lr_0 = 2.7049e-04
Loss = 8.6785e-05, PNorm = 51.4391, GNorm = 0.1744, lr_0 = 2.7021e-04
Loss = 7.5326e-05, PNorm = 51.4429, GNorm = 0.2431, lr_0 = 2.6993e-04
Loss = 8.6644e-05, PNorm = 51.4472, GNorm = 0.1324, lr_0 = 2.6965e-04
Loss = 9.5305e-05, PNorm = 51.4508, GNorm = 0.1777, lr_0 = 2.6936e-04
Loss = 8.1018e-05, PNorm = 51.4550, GNorm = 0.2374, lr_0 = 2.6908e-04
Loss = 6.1932e-05, PNorm = 51.4576, GNorm = 0.1853, lr_0 = 2.6880e-04
Loss = 7.5940e-05, PNorm = 51.4602, GNorm = 0.2121, lr_0 = 2.6852e-04
Loss = 7.8499e-05, PNorm = 51.4621, GNorm = 0.3211, lr_0 = 2.6824e-04
Loss = 6.5648e-05, PNorm = 51.4648, GNorm = 0.1719, lr_0 = 2.6796e-04
Loss = 7.1841e-05, PNorm = 51.4677, GNorm = 0.1742, lr_0 = 2.6768e-04
Loss = 6.9612e-05, PNorm = 51.4696, GNorm = 0.1999, lr_0 = 2.6740e-04
Loss = 6.2418e-05, PNorm = 51.4724, GNorm = 0.1893, lr_0 = 2.6712e-04
Loss = 8.4588e-05, PNorm = 51.4745, GNorm = 0.4417, lr_0 = 2.6684e-04
Validation rmse logD = 0.610060
Validation R2 logD = 0.739710
Validation rmse logP = 0.460437
Validation R2 logP = 0.941640
Epoch 58
Train function
Loss = 7.1364e-05, PNorm = 51.4795, GNorm = 0.1998, lr_0 = 2.6654e-04
Loss = 7.1727e-05, PNorm = 51.4813, GNorm = 0.3151, lr_0 = 2.6626e-04
Loss = 7.5855e-05, PNorm = 51.4835, GNorm = 0.2290, lr_0 = 2.6598e-04
Loss = 6.8421e-05, PNorm = 51.4865, GNorm = 0.2558, lr_0 = 2.6570e-04
Loss = 6.1582e-05, PNorm = 51.4914, GNorm = 0.1219, lr_0 = 2.6543e-04
Loss = 5.6551e-05, PNorm = 51.4945, GNorm = 0.1181, lr_0 = 2.6515e-04
Loss = 5.9427e-05, PNorm = 51.4969, GNorm = 0.1344, lr_0 = 2.6487e-04
Loss = 5.4836e-05, PNorm = 51.4998, GNorm = 0.1913, lr_0 = 2.6460e-04
Loss = 5.9324e-05, PNorm = 51.5006, GNorm = 0.1232, lr_0 = 2.6432e-04
Loss = 5.1937e-05, PNorm = 51.5029, GNorm = 0.1090, lr_0 = 2.6405e-04
Loss = 6.1736e-05, PNorm = 51.5055, GNorm = 0.1438, lr_0 = 2.6377e-04
Loss = 5.3823e-05, PNorm = 51.5083, GNorm = 0.2151, lr_0 = 2.6349e-04
Loss = 5.9543e-05, PNorm = 51.5113, GNorm = 0.1194, lr_0 = 2.6322e-04
Loss = 7.6401e-05, PNorm = 51.5148, GNorm = 0.1835, lr_0 = 2.6294e-04
Loss = 6.6830e-05, PNorm = 51.5196, GNorm = 0.1663, lr_0 = 2.6267e-04
Loss = 8.0381e-05, PNorm = 51.5212, GNorm = 0.2625, lr_0 = 2.6240e-04
Loss = 7.4180e-05, PNorm = 51.5245, GNorm = 0.2296, lr_0 = 2.6212e-04
Loss = 8.0874e-05, PNorm = 51.5272, GNorm = 0.2685, lr_0 = 2.6185e-04
Loss = 8.4764e-05, PNorm = 51.5295, GNorm = 0.2699, lr_0 = 2.6158e-04
Loss = 8.4155e-05, PNorm = 51.5321, GNorm = 0.1508, lr_0 = 2.6130e-04
Loss = 6.5114e-05, PNorm = 51.5355, GNorm = 0.1853, lr_0 = 2.6103e-04
Loss = 7.3002e-05, PNorm = 51.5380, GNorm = 0.1326, lr_0 = 2.6076e-04
Loss = 8.0927e-05, PNorm = 51.5410, GNorm = 0.2298, lr_0 = 2.6048e-04
Validation rmse logD = 0.613066
Validation R2 logD = 0.737139
Validation rmse logP = 0.456552
Validation R2 logP = 0.942621
Epoch 59
Train function
Loss = 6.5617e-05, PNorm = 51.5435, GNorm = 0.2062, lr_0 = 2.6021e-04
Loss = 7.5327e-05, PNorm = 51.5463, GNorm = 0.1470, lr_0 = 2.5994e-04
Loss = 6.5717e-05, PNorm = 51.5481, GNorm = 0.1541, lr_0 = 2.5967e-04
Loss = 7.7056e-05, PNorm = 51.5514, GNorm = 0.2403, lr_0 = 2.5940e-04
Loss = 7.7989e-05, PNorm = 51.5565, GNorm = 0.2346, lr_0 = 2.5913e-04
Loss = 5.8981e-05, PNorm = 51.5599, GNorm = 0.1631, lr_0 = 2.5886e-04
Loss = 6.0895e-05, PNorm = 51.5613, GNorm = 0.1879, lr_0 = 2.5859e-04
Loss = 6.9334e-05, PNorm = 51.5640, GNorm = 0.2461, lr_0 = 2.5832e-04
Loss = 6.6634e-05, PNorm = 51.5678, GNorm = 0.1951, lr_0 = 2.5805e-04
Loss = 8.7989e-05, PNorm = 51.5715, GNorm = 0.2232, lr_0 = 2.5778e-04
Loss = 7.0991e-05, PNorm = 51.5740, GNorm = 0.2684, lr_0 = 2.5751e-04
Loss = 1.0341e-04, PNorm = 51.5773, GNorm = 0.2861, lr_0 = 2.5724e-04
Loss = 1.0699e-04, PNorm = 51.5806, GNorm = 0.4069, lr_0 = 2.5697e-04
Loss = 9.2409e-05, PNorm = 51.5824, GNorm = 0.1843, lr_0 = 2.5670e-04
Loss = 7.8177e-05, PNorm = 51.5846, GNorm = 0.1266, lr_0 = 2.5644e-04
Loss = 6.3782e-05, PNorm = 51.5857, GNorm = 0.2695, lr_0 = 2.5617e-04
Loss = 6.0483e-05, PNorm = 51.5887, GNorm = 0.1261, lr_0 = 2.5590e-04
Loss = 6.2419e-05, PNorm = 51.5929, GNorm = 0.1905, lr_0 = 2.5563e-04
Loss = 8.2079e-05, PNorm = 51.5951, GNorm = 0.3796, lr_0 = 2.5537e-04
Loss = 8.3869e-05, PNorm = 51.5986, GNorm = 0.2293, lr_0 = 2.5510e-04
Loss = 7.4656e-05, PNorm = 51.6048, GNorm = 0.3463, lr_0 = 2.5483e-04
Loss = 7.5101e-05, PNorm = 51.6078, GNorm = 0.1861, lr_0 = 2.5457e-04
Validation rmse logD = 0.605138
Validation R2 logD = 0.743893
Validation rmse logP = 0.458886
Validation R2 logP = 0.942033
Epoch 60
Train function
Loss = 4.8696e-05, PNorm = 51.6127, GNorm = 0.1613, lr_0 = 2.5428e-04
Loss = 6.6463e-05, PNorm = 51.6145, GNorm = 0.2891, lr_0 = 2.5401e-04
Loss = 6.0807e-05, PNorm = 51.6178, GNorm = 0.1554, lr_0 = 2.5375e-04
Loss = 6.0883e-05, PNorm = 51.6207, GNorm = 0.1361, lr_0 = 2.5348e-04
Loss = 6.1880e-05, PNorm = 51.6238, GNorm = 0.2885, lr_0 = 2.5322e-04
Loss = 6.9225e-05, PNorm = 51.6263, GNorm = 0.2482, lr_0 = 2.5295e-04
Loss = 6.2338e-05, PNorm = 51.6293, GNorm = 0.2330, lr_0 = 2.5269e-04
Loss = 7.8545e-05, PNorm = 51.6331, GNorm = 0.4475, lr_0 = 2.5242e-04
Loss = 9.0369e-05, PNorm = 51.6358, GNorm = 0.3140, lr_0 = 2.5216e-04
Loss = 8.0415e-05, PNorm = 51.6407, GNorm = 0.1123, lr_0 = 2.5190e-04
Loss = 8.5409e-05, PNorm = 51.6448, GNorm = 0.2458, lr_0 = 2.5163e-04
Loss = 8.1312e-05, PNorm = 51.6474, GNorm = 0.2924, lr_0 = 2.5137e-04
Loss = 7.0375e-05, PNorm = 51.6504, GNorm = 0.1348, lr_0 = 2.5111e-04
Loss = 7.0123e-05, PNorm = 51.6533, GNorm = 0.1947, lr_0 = 2.5085e-04
Loss = 7.8085e-05, PNorm = 51.6572, GNorm = 0.2112, lr_0 = 2.5059e-04
Loss = 6.0307e-05, PNorm = 51.6613, GNorm = 0.2461, lr_0 = 2.5032e-04
Loss = 7.0424e-05, PNorm = 51.6637, GNorm = 0.1678, lr_0 = 2.5006e-04
Loss = 8.0805e-05, PNorm = 51.6652, GNorm = 0.2690, lr_0 = 2.4980e-04
Loss = 7.2237e-05, PNorm = 51.6667, GNorm = 0.1480, lr_0 = 2.4954e-04
Loss = 6.9214e-05, PNorm = 51.6700, GNorm = 0.1472, lr_0 = 2.4928e-04
Loss = 6.4512e-05, PNorm = 51.6730, GNorm = 0.1097, lr_0 = 2.4902e-04
Loss = 5.3236e-05, PNorm = 51.6738, GNorm = 0.1101, lr_0 = 2.4876e-04
Loss = 7.0209e-05, PNorm = 51.6762, GNorm = 0.1617, lr_0 = 2.4850e-04
Validation rmse logD = 0.612843
Validation R2 logD = 0.737330
Validation rmse logP = 0.458428
Validation R2 logP = 0.942148
Epoch 61
Train function
Loss = 5.8753e-05, PNorm = 51.6779, GNorm = 0.3230, lr_0 = 2.4824e-04
Loss = 7.0089e-05, PNorm = 51.6810, GNorm = 0.1090, lr_0 = 2.4798e-04
Loss = 6.6486e-05, PNorm = 51.6841, GNorm = 0.2012, lr_0 = 2.4772e-04
Loss = 5.3198e-05, PNorm = 51.6884, GNorm = 0.1730, lr_0 = 2.4747e-04
Loss = 4.9073e-05, PNorm = 51.6911, GNorm = 0.1830, lr_0 = 2.4721e-04
Loss = 4.8863e-05, PNorm = 51.6921, GNorm = 0.0947, lr_0 = 2.4695e-04
Loss = 4.4475e-05, PNorm = 51.6925, GNorm = 0.1182, lr_0 = 2.4669e-04
Loss = 5.0899e-05, PNorm = 51.6939, GNorm = 0.1575, lr_0 = 2.4643e-04
Loss = 5.9467e-05, PNorm = 51.6975, GNorm = 0.3004, lr_0 = 2.4618e-04
Loss = 5.0879e-05, PNorm = 51.7006, GNorm = 0.1611, lr_0 = 2.4592e-04
Loss = 6.0049e-05, PNorm = 51.7035, GNorm = 0.1785, lr_0 = 2.4566e-04
Loss = 5.8439e-05, PNorm = 51.7060, GNorm = 0.1628, lr_0 = 2.4541e-04
Loss = 5.0027e-05, PNorm = 51.7077, GNorm = 0.1103, lr_0 = 2.4515e-04
Loss = 5.5169e-05, PNorm = 51.7088, GNorm = 0.1817, lr_0 = 2.4489e-04
Loss = 6.0098e-05, PNorm = 51.7106, GNorm = 0.3224, lr_0 = 2.4464e-04
Loss = 6.4193e-05, PNorm = 51.7117, GNorm = 0.2260, lr_0 = 2.4438e-04
Loss = 6.8209e-05, PNorm = 51.7156, GNorm = 0.1844, lr_0 = 2.4413e-04
Loss = 5.1182e-05, PNorm = 51.7192, GNorm = 0.1586, lr_0 = 2.4387e-04
Loss = 5.2442e-05, PNorm = 51.7199, GNorm = 0.1342, lr_0 = 2.4362e-04
Loss = 6.6200e-05, PNorm = 51.7219, GNorm = 0.2115, lr_0 = 2.4337e-04
Loss = 6.0485e-05, PNorm = 51.7250, GNorm = 0.1392, lr_0 = 2.4311e-04
Loss = 7.1919e-05, PNorm = 51.7275, GNorm = 0.2395, lr_0 = 2.4286e-04
Validation rmse logD = 0.610223
Validation R2 logD = 0.739571
Validation rmse logP = 0.456748
Validation R2 logP = 0.942572
Epoch 62
Train function
Loss = 6.0058e-05, PNorm = 51.7319, GNorm = 0.2020, lr_0 = 2.4258e-04
Loss = 4.7100e-05, PNorm = 51.7352, GNorm = 0.1082, lr_0 = 2.4233e-04
Loss = 5.1982e-05, PNorm = 51.7376, GNorm = 0.1367, lr_0 = 2.4207e-04
Loss = 4.1640e-05, PNorm = 51.7402, GNorm = 0.1199, lr_0 = 2.4182e-04
Loss = 5.0694e-05, PNorm = 51.7435, GNorm = 0.2618, lr_0 = 2.4157e-04
Loss = 5.5205e-05, PNorm = 51.7455, GNorm = 0.1309, lr_0 = 2.4132e-04
Loss = 5.2227e-05, PNorm = 51.7474, GNorm = 0.2276, lr_0 = 2.4106e-04
Loss = 4.4950e-05, PNorm = 51.7479, GNorm = 0.1415, lr_0 = 2.4081e-04
Loss = 3.9043e-05, PNorm = 51.7497, GNorm = 0.1738, lr_0 = 2.4056e-04
Loss = 4.5234e-05, PNorm = 51.7516, GNorm = 0.1105, lr_0 = 2.4031e-04
Loss = 4.5746e-05, PNorm = 51.7541, GNorm = 0.0801, lr_0 = 2.4006e-04
Loss = 5.3035e-05, PNorm = 51.7559, GNorm = 0.1597, lr_0 = 2.3981e-04
Loss = 4.6567e-05, PNorm = 51.7564, GNorm = 0.1844, lr_0 = 2.3956e-04
Loss = 6.9680e-05, PNorm = 51.7589, GNorm = 0.1453, lr_0 = 2.3931e-04
Loss = 6.0815e-05, PNorm = 51.7613, GNorm = 0.1583, lr_0 = 2.3906e-04
Loss = 4.5803e-05, PNorm = 51.7621, GNorm = 0.2452, lr_0 = 2.3881e-04
Loss = 5.8092e-05, PNorm = 51.7648, GNorm = 0.2137, lr_0 = 2.3856e-04
Loss = 5.9355e-05, PNorm = 51.7680, GNorm = 0.1939, lr_0 = 2.3831e-04
Loss = 5.6355e-05, PNorm = 51.7708, GNorm = 0.1522, lr_0 = 2.3806e-04
Loss = 5.5588e-05, PNorm = 51.7722, GNorm = 0.2220, lr_0 = 2.3781e-04
Loss = 6.2608e-05, PNorm = 51.7753, GNorm = 0.3306, lr_0 = 2.3756e-04
Loss = 7.3046e-05, PNorm = 51.7781, GNorm = 0.1024, lr_0 = 2.3732e-04
Loss = 7.0269e-05, PNorm = 51.7802, GNorm = 0.3525, lr_0 = 2.3707e-04
Validation rmse logD = 0.616830
Validation R2 logD = 0.733901
Validation rmse logP = 0.458000
Validation R2 logP = 0.942256
Epoch 63
Train function
Loss = 6.1348e-05, PNorm = 51.7823, GNorm = 0.2663, lr_0 = 2.3682e-04
Loss = 7.5893e-05, PNorm = 51.7869, GNorm = 0.2904, lr_0 = 2.3657e-04
Loss = 8.0140e-05, PNorm = 51.7906, GNorm = 0.2780, lr_0 = 2.3633e-04
Loss = 6.5882e-05, PNorm = 51.7947, GNorm = 0.1707, lr_0 = 2.3608e-04
Loss = 6.0804e-05, PNorm = 51.7976, GNorm = 0.2472, lr_0 = 2.3583e-04
Loss = 6.2867e-05, PNorm = 51.7997, GNorm = 0.1965, lr_0 = 2.3559e-04
Loss = 7.2348e-05, PNorm = 51.8029, GNorm = 0.3645, lr_0 = 2.3534e-04
Loss = 6.0095e-05, PNorm = 51.8041, GNorm = 0.3296, lr_0 = 2.3510e-04
Loss = 7.3189e-05, PNorm = 51.8067, GNorm = 0.1504, lr_0 = 2.3485e-04
Loss = 6.8240e-05, PNorm = 51.8094, GNorm = 0.3506, lr_0 = 2.3461e-04
Loss = 6.7952e-05, PNorm = 51.8128, GNorm = 0.1316, lr_0 = 2.3436e-04
Loss = 5.9651e-05, PNorm = 51.8142, GNorm = 0.2114, lr_0 = 2.3412e-04
Loss = 5.9994e-05, PNorm = 51.8157, GNorm = 0.1289, lr_0 = 2.3387e-04
Loss = 6.1351e-05, PNorm = 51.8182, GNorm = 0.1904, lr_0 = 2.3363e-04
Loss = 5.5275e-05, PNorm = 51.8205, GNorm = 0.1572, lr_0 = 2.3338e-04
Loss = 5.0064e-05, PNorm = 51.8234, GNorm = 0.2454, lr_0 = 2.3314e-04
Loss = 4.9283e-05, PNorm = 51.8248, GNorm = 0.0879, lr_0 = 2.3290e-04
Loss = 6.6434e-05, PNorm = 51.8262, GNorm = 0.4072, lr_0 = 2.3265e-04
Loss = 5.5062e-05, PNorm = 51.8276, GNorm = 0.1468, lr_0 = 2.3241e-04
Loss = 6.9147e-05, PNorm = 51.8305, GNorm = 0.2385, lr_0 = 2.3217e-04
Loss = 5.5864e-05, PNorm = 51.8334, GNorm = 0.1480, lr_0 = 2.3193e-04
Loss = 6.8619e-05, PNorm = 51.8388, GNorm = 0.1165, lr_0 = 2.3169e-04
Loss = 5.1234e-05, PNorm = 51.8414, GNorm = 0.0977, lr_0 = 2.3144e-04
Loss = 1.0286e-04, PNorm = 51.8414, GNorm = 0.2801, lr_0 = 2.3142e-04
Validation rmse logD = 0.614188
Validation R2 logD = 0.736176
Validation rmse logP = 0.457920
Validation R2 logP = 0.942276
Epoch 64
Train function
Loss = 5.3874e-05, PNorm = 51.8415, GNorm = 0.1954, lr_0 = 2.3118e-04
Loss = 5.5264e-05, PNorm = 51.8420, GNorm = 0.2514, lr_0 = 2.3094e-04
Loss = 5.5779e-05, PNorm = 51.8467, GNorm = 0.1171, lr_0 = 2.3070e-04
Loss = 5.3750e-05, PNorm = 51.8496, GNorm = 0.0917, lr_0 = 2.3045e-04
Loss = 6.5386e-05, PNorm = 51.8518, GNorm = 0.1009, lr_0 = 2.3021e-04
Loss = 4.9193e-05, PNorm = 51.8526, GNorm = 0.1779, lr_0 = 2.2997e-04
Loss = 6.0010e-05, PNorm = 51.8543, GNorm = 0.1629, lr_0 = 2.2973e-04
Loss = 6.1564e-05, PNorm = 51.8568, GNorm = 0.2272, lr_0 = 2.2949e-04
Loss = 4.6429e-05, PNorm = 51.8588, GNorm = 0.1654, lr_0 = 2.2925e-04
Loss = 6.1734e-05, PNorm = 51.8619, GNorm = 0.2093, lr_0 = 2.2902e-04
Loss = 5.4138e-05, PNorm = 51.8644, GNorm = 0.1789, lr_0 = 2.2878e-04
Loss = 7.4452e-05, PNorm = 51.8684, GNorm = 0.2063, lr_0 = 2.2854e-04
Loss = 6.6918e-05, PNorm = 51.8709, GNorm = 0.2965, lr_0 = 2.2830e-04
Loss = 6.1660e-05, PNorm = 51.8745, GNorm = 0.0990, lr_0 = 2.2806e-04
Loss = 4.8357e-05, PNorm = 51.8779, GNorm = 0.0929, lr_0 = 2.2782e-04
Loss = 6.5064e-05, PNorm = 51.8783, GNorm = 0.2596, lr_0 = 2.2758e-04
Loss = 5.4651e-05, PNorm = 51.8803, GNorm = 0.1023, lr_0 = 2.2735e-04
Loss = 4.5367e-05, PNorm = 51.8836, GNorm = 0.2329, lr_0 = 2.2711e-04
Loss = 5.0210e-05, PNorm = 51.8853, GNorm = 0.2422, lr_0 = 2.2687e-04
Loss = 5.1523e-05, PNorm = 51.8884, GNorm = 0.1327, lr_0 = 2.2664e-04
Loss = 5.2841e-05, PNorm = 51.8900, GNorm = 0.1972, lr_0 = 2.2640e-04
Loss = 5.5560e-05, PNorm = 51.8931, GNorm = 0.2193, lr_0 = 2.2616e-04
Validation rmse logD = 0.612347
Validation R2 logD = 0.737755
Validation rmse logP = 0.454356
Validation R2 logP = 0.943172
Epoch 65
Train function
Loss = 4.2138e-05, PNorm = 51.8947, GNorm = 0.1850, lr_0 = 2.2593e-04
Loss = 4.0176e-05, PNorm = 51.8954, GNorm = 0.1587, lr_0 = 2.2569e-04
Loss = 4.3332e-05, PNorm = 51.8962, GNorm = 0.1633, lr_0 = 2.2546e-04
Loss = 4.8206e-05, PNorm = 51.8965, GNorm = 0.2608, lr_0 = 2.2522e-04
Loss = 4.4891e-05, PNorm = 51.8983, GNorm = 0.1395, lr_0 = 2.2499e-04
Loss = 4.8062e-05, PNorm = 51.9024, GNorm = 0.1394, lr_0 = 2.2475e-04
Loss = 4.8266e-05, PNorm = 51.9037, GNorm = 0.1346, lr_0 = 2.2452e-04
Loss = 5.8758e-05, PNorm = 51.9051, GNorm = 0.1347, lr_0 = 2.2428e-04
Loss = 6.6337e-05, PNorm = 51.9066, GNorm = 0.1623, lr_0 = 2.2405e-04
Loss = 6.1650e-05, PNorm = 51.9104, GNorm = 0.3569, lr_0 = 2.2381e-04
Loss = 5.1964e-05, PNorm = 51.9109, GNorm = 0.2505, lr_0 = 2.2358e-04
Loss = 5.0472e-05, PNorm = 51.9132, GNorm = 0.2408, lr_0 = 2.2335e-04
Loss = 5.1107e-05, PNorm = 51.9161, GNorm = 0.1179, lr_0 = 2.2311e-04
Loss = 3.8892e-05, PNorm = 51.9184, GNorm = 0.2639, lr_0 = 2.2288e-04
Loss = 5.0685e-05, PNorm = 51.9203, GNorm = 0.2085, lr_0 = 2.2265e-04
Loss = 4.3836e-05, PNorm = 51.9220, GNorm = 0.1095, lr_0 = 2.2242e-04
Loss = 6.0538e-05, PNorm = 51.9233, GNorm = 0.1977, lr_0 = 2.2218e-04
Loss = 7.3086e-05, PNorm = 51.9241, GNorm = 0.1666, lr_0 = 2.2195e-04
Loss = 6.0776e-05, PNorm = 51.9268, GNorm = 0.2323, lr_0 = 2.2172e-04
Loss = 7.5164e-05, PNorm = 51.9287, GNorm = 0.1180, lr_0 = 2.2149e-04
Loss = 5.5137e-05, PNorm = 51.9300, GNorm = 0.2019, lr_0 = 2.2126e-04
Loss = 8.1336e-05, PNorm = 51.9351, GNorm = 0.2017, lr_0 = 2.2103e-04
Loss = 7.1579e-05, PNorm = 51.9375, GNorm = 0.4734, lr_0 = 2.2080e-04
Validation rmse logD = 0.612113
Validation R2 logD = 0.737956
Validation rmse logP = 0.467776
Validation R2 logP = 0.939765
Epoch 66
Train function
Loss = 6.3352e-05, PNorm = 51.9397, GNorm = 0.2518, lr_0 = 2.2054e-04
Loss = 6.1441e-05, PNorm = 51.9420, GNorm = 0.1389, lr_0 = 2.2031e-04
Loss = 5.3079e-05, PNorm = 51.9447, GNorm = 0.1607, lr_0 = 2.2008e-04
Loss = 4.1287e-05, PNorm = 51.9474, GNorm = 0.1277, lr_0 = 2.1985e-04
Loss = 5.7153e-05, PNorm = 51.9508, GNorm = 0.1722, lr_0 = 2.1962e-04
Loss = 5.2227e-05, PNorm = 51.9535, GNorm = 0.1840, lr_0 = 2.1939e-04
Loss = 3.9302e-05, PNorm = 51.9534, GNorm = 0.1031, lr_0 = 2.1916e-04
Loss = 4.4342e-05, PNorm = 51.9554, GNorm = 0.1103, lr_0 = 2.1894e-04
Loss = 4.5492e-05, PNorm = 51.9565, GNorm = 0.1110, lr_0 = 2.1871e-04
Loss = 4.7453e-05, PNorm = 51.9587, GNorm = 0.1365, lr_0 = 2.1848e-04
Loss = 4.6420e-05, PNorm = 51.9613, GNorm = 0.1850, lr_0 = 2.1825e-04
Loss = 4.3182e-05, PNorm = 51.9650, GNorm = 0.1350, lr_0 = 2.1802e-04
Loss = 4.6500e-05, PNorm = 51.9672, GNorm = 0.0935, lr_0 = 2.1780e-04
Loss = 4.2362e-05, PNorm = 51.9690, GNorm = 0.1983, lr_0 = 2.1757e-04
Loss = 4.1024e-05, PNorm = 51.9707, GNorm = 0.1419, lr_0 = 2.1734e-04
Loss = 4.8927e-05, PNorm = 51.9725, GNorm = 0.1550, lr_0 = 2.1711e-04
Loss = 5.3921e-05, PNorm = 51.9742, GNorm = 0.1598, lr_0 = 2.1689e-04
Loss = 5.5260e-05, PNorm = 51.9773, GNorm = 0.1247, lr_0 = 2.1666e-04
Loss = 4.8685e-05, PNorm = 51.9791, GNorm = 0.1397, lr_0 = 2.1644e-04
Loss = 4.0060e-05, PNorm = 51.9813, GNorm = 0.1088, lr_0 = 2.1621e-04
Loss = 5.0748e-05, PNorm = 51.9840, GNorm = 0.1741, lr_0 = 2.1598e-04
Loss = 4.7970e-05, PNorm = 51.9863, GNorm = 0.1861, lr_0 = 2.1576e-04
Validation rmse logD = 0.610599
Validation R2 logD = 0.739250
Validation rmse logP = 0.457282
Validation R2 logP = 0.942437
Epoch 67
Train function
Loss = 3.4436e-05, PNorm = 51.9873, GNorm = 0.1120, lr_0 = 2.1553e-04
Loss = 3.7391e-05, PNorm = 51.9888, GNorm = 0.1431, lr_0 = 2.1531e-04
Loss = 4.0999e-05, PNorm = 51.9909, GNorm = 0.1273, lr_0 = 2.1508e-04
Loss = 5.4985e-05, PNorm = 51.9928, GNorm = 0.2054, lr_0 = 2.1486e-04
Loss = 4.3915e-05, PNorm = 51.9953, GNorm = 0.1255, lr_0 = 2.1464e-04
Loss = 3.8939e-05, PNorm = 51.9963, GNorm = 0.1019, lr_0 = 2.1441e-04
Loss = 4.0084e-05, PNorm = 51.9977, GNorm = 0.1432, lr_0 = 2.1419e-04
Loss = 4.2735e-05, PNorm = 52.0011, GNorm = 0.2378, lr_0 = 2.1396e-04
Loss = 4.7818e-05, PNorm = 52.0037, GNorm = 0.1943, lr_0 = 2.1374e-04
Loss = 5.3525e-05, PNorm = 52.0053, GNorm = 0.2239, lr_0 = 2.1352e-04
Loss = 4.8882e-05, PNorm = 52.0078, GNorm = 0.0871, lr_0 = 2.1329e-04
Loss = 4.8451e-05, PNorm = 52.0119, GNorm = 0.1345, lr_0 = 2.1307e-04
Loss = 3.7368e-05, PNorm = 52.0134, GNorm = 0.1315, lr_0 = 2.1285e-04
Loss = 3.4993e-05, PNorm = 52.0144, GNorm = 0.1929, lr_0 = 2.1263e-04
Loss = 5.6446e-05, PNorm = 52.0161, GNorm = 0.2376, lr_0 = 2.1241e-04
Loss = 4.7517e-05, PNorm = 52.0170, GNorm = 0.0906, lr_0 = 2.1218e-04
Loss = 4.8330e-05, PNorm = 52.0198, GNorm = 0.2210, lr_0 = 2.1196e-04
Loss = 4.8541e-05, PNorm = 52.0224, GNorm = 0.1176, lr_0 = 2.1174e-04
Loss = 3.4682e-05, PNorm = 52.0245, GNorm = 0.1265, lr_0 = 2.1152e-04
Loss = 4.0666e-05, PNorm = 52.0259, GNorm = 0.0719, lr_0 = 2.1130e-04
Loss = 4.0121e-05, PNorm = 52.0269, GNorm = 0.1593, lr_0 = 2.1108e-04
Loss = 4.8218e-05, PNorm = 52.0273, GNorm = 0.1548, lr_0 = 2.1086e-04
Loss = 3.7564e-05, PNorm = 52.0293, GNorm = 0.1421, lr_0 = 2.1064e-04
Validation rmse logD = 0.605695
Validation R2 logD = 0.743421
Validation rmse logP = 0.460165
Validation R2 logP = 0.941709
Epoch 68
Train function
Loss = 3.7619e-05, PNorm = 52.0330, GNorm = 0.1064, lr_0 = 2.1040e-04
Loss = 3.9659e-05, PNorm = 52.0351, GNorm = 0.2397, lr_0 = 2.1018e-04
Loss = 4.3490e-05, PNorm = 52.0368, GNorm = 0.2342, lr_0 = 2.0996e-04
Loss = 3.9631e-05, PNorm = 52.0390, GNorm = 0.1094, lr_0 = 2.0974e-04
Loss = 3.7038e-05, PNorm = 52.0410, GNorm = 0.1091, lr_0 = 2.0952e-04
Loss = 4.2226e-05, PNorm = 52.0430, GNorm = 0.1659, lr_0 = 2.0930e-04
Loss = 4.6260e-05, PNorm = 52.0445, GNorm = 0.1148, lr_0 = 2.0908e-04
Loss = 4.2534e-05, PNorm = 52.0471, GNorm = 0.1528, lr_0 = 2.0886e-04
Loss = 3.9006e-05, PNorm = 52.0485, GNorm = 0.1285, lr_0 = 2.0865e-04
Loss = 5.8690e-05, PNorm = 52.0500, GNorm = 0.1850, lr_0 = 2.0843e-04
Loss = 4.4128e-05, PNorm = 52.0517, GNorm = 0.1479, lr_0 = 2.0821e-04
Loss = 5.3397e-05, PNorm = 52.0543, GNorm = 0.1881, lr_0 = 2.0799e-04
Loss = 4.7847e-05, PNorm = 52.0557, GNorm = 0.1379, lr_0 = 2.0778e-04
Loss = 4.5343e-05, PNorm = 52.0560, GNorm = 0.1289, lr_0 = 2.0756e-04
Loss = 3.6841e-05, PNorm = 52.0579, GNorm = 0.0789, lr_0 = 2.0734e-04
Loss = 4.4998e-05, PNorm = 52.0583, GNorm = 0.1114, lr_0 = 2.0713e-04
Loss = 6.3648e-05, PNorm = 52.0611, GNorm = 0.3763, lr_0 = 2.0691e-04
Loss = 6.2937e-05, PNorm = 52.0613, GNorm = 0.1802, lr_0 = 2.0669e-04
Loss = 4.9530e-05, PNorm = 52.0629, GNorm = 0.1264, lr_0 = 2.0648e-04
Loss = 5.1448e-05, PNorm = 52.0648, GNorm = 0.2847, lr_0 = 2.0626e-04
Loss = 5.0221e-05, PNorm = 52.0661, GNorm = 0.2121, lr_0 = 2.0605e-04
Loss = 4.3273e-05, PNorm = 52.0702, GNorm = 0.1251, lr_0 = 2.0583e-04
Validation rmse logD = 0.612436
Validation R2 logD = 0.737678
Validation rmse logP = 0.458058
Validation R2 logP = 0.942242
Epoch 69
Train function
Loss = 4.4579e-05, PNorm = 52.0718, GNorm = 0.1624, lr_0 = 2.0562e-04
Loss = 3.9118e-05, PNorm = 52.0732, GNorm = 0.1031, lr_0 = 2.0540e-04
Loss = 3.3370e-05, PNorm = 52.0741, GNorm = 0.1356, lr_0 = 2.0519e-04
Loss = 3.6207e-05, PNorm = 52.0761, GNorm = 0.1726, lr_0 = 2.0497e-04
Loss = 3.6731e-05, PNorm = 52.0786, GNorm = 0.1274, lr_0 = 2.0476e-04
Loss = 3.0693e-05, PNorm = 52.0808, GNorm = 0.1349, lr_0 = 2.0455e-04
Loss = 4.2417e-05, PNorm = 52.0817, GNorm = 0.1512, lr_0 = 2.0433e-04
Loss = 4.6099e-05, PNorm = 52.0842, GNorm = 0.2123, lr_0 = 2.0412e-04
Loss = 3.5944e-05, PNorm = 52.0858, GNorm = 0.1796, lr_0 = 2.0391e-04
Loss = 5.2735e-05, PNorm = 52.0892, GNorm = 0.1113, lr_0 = 2.0369e-04
Loss = 4.2797e-05, PNorm = 52.0913, GNorm = 0.2303, lr_0 = 2.0348e-04
Loss = 3.8669e-05, PNorm = 52.0926, GNorm = 0.0874, lr_0 = 2.0327e-04
Loss = 5.1309e-05, PNorm = 52.0935, GNorm = 0.1992, lr_0 = 2.0306e-04
Loss = 4.2984e-05, PNorm = 52.0938, GNorm = 0.1213, lr_0 = 2.0285e-04
Loss = 3.7146e-05, PNorm = 52.0945, GNorm = 0.1341, lr_0 = 2.0263e-04
Loss = 3.6706e-05, PNorm = 52.0966, GNorm = 0.2238, lr_0 = 2.0242e-04
Loss = 4.4529e-05, PNorm = 52.0979, GNorm = 0.1527, lr_0 = 2.0221e-04
Loss = 4.0231e-05, PNorm = 52.0995, GNorm = 0.2099, lr_0 = 2.0200e-04
Loss = 4.4675e-05, PNorm = 52.1009, GNorm = 0.1240, lr_0 = 2.0179e-04
Loss = 6.2034e-05, PNorm = 52.1047, GNorm = 0.1528, lr_0 = 2.0158e-04
Loss = 7.4540e-05, PNorm = 52.1091, GNorm = 0.1877, lr_0 = 2.0137e-04
Loss = 6.6566e-05, PNorm = 52.1132, GNorm = 0.4701, lr_0 = 2.0116e-04
Loss = 5.8962e-05, PNorm = 52.1153, GNorm = 0.2162, lr_0 = 2.0095e-04
Validation rmse logD = 0.610292
Validation R2 logD = 0.739512
Validation rmse logP = 0.456609
Validation R2 logP = 0.942606
Epoch 70
Train function
Loss = 4.6980e-05, PNorm = 52.1175, GNorm = 0.1089, lr_0 = 2.0072e-04
Loss = 4.2694e-05, PNorm = 52.1187, GNorm = 0.2552, lr_0 = 2.0051e-04
Loss = 3.7121e-05, PNorm = 52.1196, GNorm = 0.1089, lr_0 = 2.0030e-04
Loss = 4.3580e-05, PNorm = 52.1213, GNorm = 0.1248, lr_0 = 2.0009e-04
Loss = 3.9583e-05, PNorm = 52.1229, GNorm = 0.2139, lr_0 = 1.9988e-04
Loss = 3.2054e-05, PNorm = 52.1223, GNorm = 0.1147, lr_0 = 1.9967e-04
Loss = 4.0404e-05, PNorm = 52.1231, GNorm = 0.2171, lr_0 = 1.9946e-04
Loss = 4.5672e-05, PNorm = 52.1253, GNorm = 0.2142, lr_0 = 1.9926e-04
Loss = 4.3004e-05, PNorm = 52.1272, GNorm = 0.1111, lr_0 = 1.9905e-04
Loss = 5.4281e-05, PNorm = 52.1278, GNorm = 0.1981, lr_0 = 1.9884e-04
Loss = 4.5552e-05, PNorm = 52.1283, GNorm = 0.1655, lr_0 = 1.9863e-04
Loss = 4.2293e-05, PNorm = 52.1296, GNorm = 0.1109, lr_0 = 1.9842e-04
Loss = 3.7862e-05, PNorm = 52.1313, GNorm = 0.2211, lr_0 = 1.9822e-04
Loss = 4.2536e-05, PNorm = 52.1343, GNorm = 0.2158, lr_0 = 1.9801e-04
Loss = 5.0803e-05, PNorm = 52.1383, GNorm = 0.1489, lr_0 = 1.9780e-04
Loss = 3.5958e-05, PNorm = 52.1386, GNorm = 0.0939, lr_0 = 1.9760e-04
Loss = 4.1600e-05, PNorm = 52.1404, GNorm = 0.1557, lr_0 = 1.9739e-04
Loss = 5.5077e-05, PNorm = 52.1429, GNorm = 0.2246, lr_0 = 1.9719e-04
Loss = 6.1028e-05, PNorm = 52.1459, GNorm = 0.2530, lr_0 = 1.9698e-04
Loss = 4.3834e-05, PNorm = 52.1499, GNorm = 0.1339, lr_0 = 1.9677e-04
Loss = 4.1675e-05, PNorm = 52.1523, GNorm = 0.1138, lr_0 = 1.9657e-04
Loss = 5.3848e-05, PNorm = 52.1571, GNorm = 0.0994, lr_0 = 1.9636e-04
Validation rmse logD = 0.612186
Validation R2 logD = 0.737893
Validation rmse logP = 0.459144
Validation R2 logP = 0.941967
Epoch 71
Train function
Loss = 3.4058e-05, PNorm = 52.1586, GNorm = 0.0992, lr_0 = 1.9616e-04
Loss = 3.1360e-05, PNorm = 52.1587, GNorm = 0.1040, lr_0 = 1.9595e-04
Loss = 2.9798e-05, PNorm = 52.1586, GNorm = 0.1089, lr_0 = 1.9575e-04
Loss = 3.0501e-05, PNorm = 52.1587, GNorm = 0.0977, lr_0 = 1.9555e-04
Loss = 3.2995e-05, PNorm = 52.1596, GNorm = 0.1299, lr_0 = 1.9534e-04
Loss = 3.3773e-05, PNorm = 52.1621, GNorm = 0.1454, lr_0 = 1.9514e-04
Loss = 3.1852e-05, PNorm = 52.1627, GNorm = 0.1525, lr_0 = 1.9493e-04
Loss = 4.1025e-05, PNorm = 52.1630, GNorm = 0.1456, lr_0 = 1.9473e-04
Loss = 3.6745e-05, PNorm = 52.1637, GNorm = 0.1738, lr_0 = 1.9453e-04
Loss = 4.4549e-05, PNorm = 52.1669, GNorm = 0.1458, lr_0 = 1.9432e-04
Loss = 4.9004e-05, PNorm = 52.1675, GNorm = 0.1303, lr_0 = 1.9412e-04
Loss = 3.4525e-05, PNorm = 52.1698, GNorm = 0.1942, lr_0 = 1.9392e-04
Loss = 3.0180e-05, PNorm = 52.1712, GNorm = 0.1211, lr_0 = 1.9372e-04
Loss = 3.2392e-05, PNorm = 52.1730, GNorm = 0.0960, lr_0 = 1.9351e-04
Loss = 5.0093e-05, PNorm = 52.1751, GNorm = 0.1978, lr_0 = 1.9331e-04
Loss = 4.7182e-05, PNorm = 52.1760, GNorm = 0.2153, lr_0 = 1.9311e-04
Loss = 5.6451e-05, PNorm = 52.1777, GNorm = 0.2588, lr_0 = 1.9291e-04
Loss = 3.6968e-05, PNorm = 52.1797, GNorm = 0.1539, lr_0 = 1.9271e-04
Loss = 4.2219e-05, PNorm = 52.1815, GNorm = 0.1499, lr_0 = 1.9251e-04
Loss = 4.2529e-05, PNorm = 52.1838, GNorm = 0.2055, lr_0 = 1.9231e-04
Loss = 4.1227e-05, PNorm = 52.1868, GNorm = 0.2058, lr_0 = 1.9210e-04
Loss = 3.6508e-05, PNorm = 52.1883, GNorm = 0.1043, lr_0 = 1.9190e-04
Loss = 3.3192e-05, PNorm = 52.1905, GNorm = 0.1156, lr_0 = 1.9170e-04
Validation rmse logD = 0.607490
Validation R2 logD = 0.741899
Validation rmse logP = 0.457245
Validation R2 logP = 0.942446
Epoch 72
Train function
Loss = 2.9342e-05, PNorm = 52.1938, GNorm = 0.0807, lr_0 = 1.9148e-04
Loss = 3.7726e-05, PNorm = 52.1956, GNorm = 0.2627, lr_0 = 1.9128e-04
Loss = 3.4271e-05, PNorm = 52.1961, GNorm = 0.1355, lr_0 = 1.9108e-04
Loss = 3.9737e-05, PNorm = 52.1984, GNorm = 0.2492, lr_0 = 1.9088e-04
Loss = 4.0037e-05, PNorm = 52.2000, GNorm = 0.1182, lr_0 = 1.9069e-04
Loss = 4.5410e-05, PNorm = 52.2001, GNorm = 0.1644, lr_0 = 1.9049e-04
Loss = 4.9086e-05, PNorm = 52.2024, GNorm = 0.1541, lr_0 = 1.9029e-04
Loss = 3.9677e-05, PNorm = 52.2040, GNorm = 0.1722, lr_0 = 1.9009e-04
Loss = 3.5358e-05, PNorm = 52.2053, GNorm = 0.1242, lr_0 = 1.8989e-04
Loss = 3.5663e-05, PNorm = 52.2057, GNorm = 0.1424, lr_0 = 1.8969e-04
Loss = 3.5164e-05, PNorm = 52.2065, GNorm = 0.0966, lr_0 = 1.8949e-04
Loss = 2.9861e-05, PNorm = 52.2065, GNorm = 0.1163, lr_0 = 1.8930e-04
Loss = 2.9640e-05, PNorm = 52.2081, GNorm = 0.1417, lr_0 = 1.8910e-04
Loss = 4.1976e-05, PNorm = 52.2096, GNorm = 0.2795, lr_0 = 1.8890e-04
Loss = 4.4768e-05, PNorm = 52.2113, GNorm = 0.1345, lr_0 = 1.8870e-04
Loss = 6.1536e-05, PNorm = 52.2139, GNorm = 0.2830, lr_0 = 1.8851e-04
Loss = 4.5634e-05, PNorm = 52.2145, GNorm = 0.1777, lr_0 = 1.8831e-04
Loss = 5.1161e-05, PNorm = 52.2162, GNorm = 0.2060, lr_0 = 1.8811e-04
Loss = 4.2665e-05, PNorm = 52.2185, GNorm = 0.2182, lr_0 = 1.8792e-04
Loss = 5.0242e-05, PNorm = 52.2195, GNorm = 0.1711, lr_0 = 1.8772e-04
Loss = 3.8504e-05, PNorm = 52.2217, GNorm = 0.1988, lr_0 = 1.8753e-04
Loss = 4.1179e-05, PNorm = 52.2215, GNorm = 0.1426, lr_0 = 1.8733e-04
Loss = 4.9731e-05, PNorm = 52.2234, GNorm = 0.1443, lr_0 = 1.8713e-04
Validation rmse logD = 0.614594
Validation R2 logD = 0.735827
Validation rmse logP = 0.459917
Validation R2 logP = 0.941772
Epoch 73
Train function
Loss = 5.2554e-05, PNorm = 52.2263, GNorm = 0.1496, lr_0 = 1.8694e-04
Loss = 4.6580e-05, PNorm = 52.2285, GNorm = 0.2216, lr_0 = 1.8674e-04
Loss = 4.3263e-05, PNorm = 52.2307, GNorm = 0.1001, lr_0 = 1.8655e-04
Loss = 4.4500e-05, PNorm = 52.2314, GNorm = 0.2384, lr_0 = 1.8635e-04
Loss = 3.9600e-05, PNorm = 52.2326, GNorm = 0.1604, lr_0 = 1.8616e-04
Loss = 3.2229e-05, PNorm = 52.2341, GNorm = 0.1197, lr_0 = 1.8597e-04
Loss = 3.6968e-05, PNorm = 52.2357, GNorm = 0.0983, lr_0 = 1.8577e-04
Loss = 3.6896e-05, PNorm = 52.2378, GNorm = 0.1347, lr_0 = 1.8558e-04
Loss = 3.5206e-05, PNorm = 52.2398, GNorm = 0.1589, lr_0 = 1.8538e-04
Loss = 3.3463e-05, PNorm = 52.2415, GNorm = 0.1216, lr_0 = 1.8519e-04
Loss = 3.6847e-05, PNorm = 52.2431, GNorm = 0.0967, lr_0 = 1.8500e-04
Loss = 4.0594e-05, PNorm = 52.2452, GNorm = 0.1536, lr_0 = 1.8480e-04
Loss = 2.7278e-05, PNorm = 52.2476, GNorm = 0.1164, lr_0 = 1.8461e-04
Loss = 3.4391e-05, PNorm = 52.2496, GNorm = 0.1443, lr_0 = 1.8442e-04
Loss = 3.5474e-05, PNorm = 52.2513, GNorm = 0.2038, lr_0 = 1.8423e-04
Loss = 4.8213e-05, PNorm = 52.2543, GNorm = 0.2359, lr_0 = 1.8403e-04
Loss = 3.3573e-05, PNorm = 52.2574, GNorm = 0.1528, lr_0 = 1.8384e-04
Loss = 4.5300e-05, PNorm = 52.2596, GNorm = 0.1633, lr_0 = 1.8365e-04
Loss = 4.8033e-05, PNorm = 52.2611, GNorm = 0.1510, lr_0 = 1.8346e-04
Loss = 3.4566e-05, PNorm = 52.2628, GNorm = 0.1093, lr_0 = 1.8327e-04
Loss = 3.2804e-05, PNorm = 52.2639, GNorm = 0.2727, lr_0 = 1.8308e-04
Loss = 3.8206e-05, PNorm = 52.2671, GNorm = 0.1217, lr_0 = 1.8288e-04
Validation rmse logD = 0.607151
Validation R2 logD = 0.742186
Validation rmse logP = 0.459511
Validation R2 logP = 0.941875
Epoch 74
Train function
Loss = 2.8997e-05, PNorm = 52.2686, GNorm = 0.0706, lr_0 = 1.8267e-04
Loss = 3.6330e-05, PNorm = 52.2686, GNorm = 0.2274, lr_0 = 1.8248e-04
Loss = 3.0583e-05, PNorm = 52.2707, GNorm = 0.0985, lr_0 = 1.8229e-04
Loss = 2.7128e-05, PNorm = 52.2711, GNorm = 0.1465, lr_0 = 1.8210e-04
Loss = 2.6598e-05, PNorm = 52.2714, GNorm = 0.1237, lr_0 = 1.8191e-04
Loss = 2.5746e-05, PNorm = 52.2714, GNorm = 0.1129, lr_0 = 1.8172e-04
Loss = 3.3024e-05, PNorm = 52.2731, GNorm = 0.1020, lr_0 = 1.8153e-04
Loss = 2.6861e-05, PNorm = 52.2753, GNorm = 0.1789, lr_0 = 1.8134e-04
Loss = 3.4976e-05, PNorm = 52.2757, GNorm = 0.0720, lr_0 = 1.8115e-04
Loss = 3.3563e-05, PNorm = 52.2760, GNorm = 0.0928, lr_0 = 1.8097e-04
Loss = 3.7593e-05, PNorm = 52.2778, GNorm = 0.1705, lr_0 = 1.8078e-04
Loss = 3.3033e-05, PNorm = 52.2792, GNorm = 0.1799, lr_0 = 1.8059e-04
Loss = 3.0186e-05, PNorm = 52.2807, GNorm = 0.1121, lr_0 = 1.8040e-04
Loss = 3.4616e-05, PNorm = 52.2811, GNorm = 0.0786, lr_0 = 1.8021e-04
Loss = 2.8426e-05, PNorm = 52.2816, GNorm = 0.1153, lr_0 = 1.8002e-04
Loss = 2.9695e-05, PNorm = 52.2829, GNorm = 0.0996, lr_0 = 1.7984e-04
Loss = 2.4608e-05, PNorm = 52.2851, GNorm = 0.1486, lr_0 = 1.7965e-04
Loss = 2.8023e-05, PNorm = 52.2865, GNorm = 0.1127, lr_0 = 1.7946e-04
Loss = 3.1373e-05, PNorm = 52.2877, GNorm = 0.1270, lr_0 = 1.7927e-04
Loss = 4.3515e-05, PNorm = 52.2904, GNorm = 0.2220, lr_0 = 1.7909e-04
Loss = 3.8513e-05, PNorm = 52.2924, GNorm = 0.1256, lr_0 = 1.7890e-04
Loss = 5.4778e-05, PNorm = 52.2949, GNorm = 0.2573, lr_0 = 1.7871e-04
Loss = 3.8215e-05, PNorm = 52.2967, GNorm = 0.2125, lr_0 = 1.7853e-04
Validation rmse logD = 0.610931
Validation R2 logD = 0.738966
Validation rmse logP = 0.457441
Validation R2 logP = 0.942397
Epoch 75
Train function
Loss = 3.6825e-05, PNorm = 52.2985, GNorm = 0.0710, lr_0 = 1.7834e-04
Loss = 3.0247e-05, PNorm = 52.3007, GNorm = 0.1143, lr_0 = 1.7815e-04
Loss = 3.3217e-05, PNorm = 52.3030, GNorm = 0.1599, lr_0 = 1.7797e-04
Loss = 2.8099e-05, PNorm = 52.3049, GNorm = 0.1746, lr_0 = 1.7778e-04
Loss = 2.7291e-05, PNorm = 52.3046, GNorm = 0.1053, lr_0 = 1.7760e-04
Loss = 2.4633e-05, PNorm = 52.3055, GNorm = 0.1237, lr_0 = 1.7741e-04
Loss = 2.9210e-05, PNorm = 52.3068, GNorm = 0.0721, lr_0 = 1.7723e-04
Loss = 2.6574e-05, PNorm = 52.3073, GNorm = 0.1618, lr_0 = 1.7704e-04
Loss = 2.6812e-05, PNorm = 52.3088, GNorm = 0.0956, lr_0 = 1.7686e-04
Loss = 3.7089e-05, PNorm = 52.3094, GNorm = 0.2945, lr_0 = 1.7667e-04
Loss = 2.5927e-05, PNorm = 52.3113, GNorm = 0.1302, lr_0 = 1.7649e-04
Loss = 4.2224e-05, PNorm = 52.3137, GNorm = 0.1749, lr_0 = 1.7630e-04
Loss = 3.4645e-05, PNorm = 52.3152, GNorm = 0.1801, lr_0 = 1.7612e-04
Loss = 3.7938e-05, PNorm = 52.3172, GNorm = 0.1302, lr_0 = 1.7593e-04
Loss = 2.7686e-05, PNorm = 52.3180, GNorm = 0.0990, lr_0 = 1.7575e-04
Loss = 3.1094e-05, PNorm = 52.3198, GNorm = 0.1490, lr_0 = 1.7557e-04
Loss = 4.2845e-05, PNorm = 52.3209, GNorm = 0.2832, lr_0 = 1.7538e-04
Loss = 4.8659e-05, PNorm = 52.3231, GNorm = 0.1699, lr_0 = 1.7520e-04
Loss = 4.1029e-05, PNorm = 52.3257, GNorm = 0.1113, lr_0 = 1.7502e-04
Loss = 3.3217e-05, PNorm = 52.3284, GNorm = 0.1043, lr_0 = 1.7484e-04
Loss = 3.3843e-05, PNorm = 52.3302, GNorm = 0.1361, lr_0 = 1.7465e-04
Loss = 3.1855e-05, PNorm = 52.3319, GNorm = 0.0726, lr_0 = 1.7447e-04
Validation rmse logD = 0.609286
Validation R2 logD = 0.740370
Validation rmse logP = 0.457332
Validation R2 logP = 0.942425
Epoch 76
Train function
Loss = 2.7736e-05, PNorm = 52.3324, GNorm = 0.1145, lr_0 = 1.7427e-04
Loss = 2.4980e-05, PNorm = 52.3338, GNorm = 0.0829, lr_0 = 1.7409e-04
Loss = 3.3809e-05, PNorm = 52.3362, GNorm = 0.1360, lr_0 = 1.7391e-04
Loss = 3.5549e-05, PNorm = 52.3384, GNorm = 0.1953, lr_0 = 1.7373e-04
Loss = 3.2110e-05, PNorm = 52.3392, GNorm = 0.1365, lr_0 = 1.7354e-04
Loss = 3.5964e-05, PNorm = 52.3377, GNorm = 0.1450, lr_0 = 1.7336e-04
Loss = 3.9001e-05, PNorm = 52.3394, GNorm = 0.1782, lr_0 = 1.7318e-04
Loss = 3.5381e-05, PNorm = 52.3414, GNorm = 0.1406, lr_0 = 1.7300e-04
Loss = 3.6231e-05, PNorm = 52.3403, GNorm = 0.2444, lr_0 = 1.7282e-04
Loss = 5.4944e-05, PNorm = 52.3427, GNorm = 0.2267, lr_0 = 1.7264e-04
Loss = 4.8849e-05, PNorm = 52.3456, GNorm = 0.1901, lr_0 = 1.7246e-04
Loss = 4.4823e-05, PNorm = 52.3481, GNorm = 0.2238, lr_0 = 1.7228e-04
Loss = 4.8471e-05, PNorm = 52.3509, GNorm = 0.3471, lr_0 = 1.7210e-04
Loss = 4.2806e-05, PNorm = 52.3535, GNorm = 0.1099, lr_0 = 1.7192e-04
Loss = 3.6169e-05, PNorm = 52.3562, GNorm = 0.2208, lr_0 = 1.7174e-04
Loss = 2.7761e-05, PNorm = 52.3570, GNorm = 0.0769, lr_0 = 1.7156e-04
Loss = 3.6357e-05, PNorm = 52.3588, GNorm = 0.1642, lr_0 = 1.7138e-04
Loss = 3.0061e-05, PNorm = 52.3601, GNorm = 0.1481, lr_0 = 1.7120e-04
Loss = 2.9180e-05, PNorm = 52.3616, GNorm = 0.1027, lr_0 = 1.7103e-04
Loss = 3.6630e-05, PNorm = 52.3629, GNorm = 0.1744, lr_0 = 1.7085e-04
Loss = 3.2513e-05, PNorm = 52.3638, GNorm = 0.1086, lr_0 = 1.7067e-04
Loss = 4.6632e-05, PNorm = 52.3651, GNorm = 0.0961, lr_0 = 1.7049e-04
Loss = 3.9238e-05, PNorm = 52.3668, GNorm = 0.1302, lr_0 = 1.7031e-04
Validation rmse logD = 0.604965
Validation R2 logD = 0.744039
Validation rmse logP = 0.456584
Validation R2 logP = 0.942613
Epoch 77
Train function
Loss = 3.1919e-05, PNorm = 52.3690, GNorm = 0.1251, lr_0 = 1.7012e-04
Loss = 2.3416e-05, PNorm = 52.3695, GNorm = 0.1014, lr_0 = 1.6994e-04
Loss = 2.8432e-05, PNorm = 52.3699, GNorm = 0.1329, lr_0 = 1.6976e-04
Loss = 2.7893e-05, PNorm = 52.3717, GNorm = 0.1194, lr_0 = 1.6959e-04
Loss = 2.7668e-05, PNorm = 52.3721, GNorm = 0.1530, lr_0 = 1.6941e-04
Loss = 2.1623e-05, PNorm = 52.3730, GNorm = 0.1143, lr_0 = 1.6923e-04
Loss = 2.6933e-05, PNorm = 52.3744, GNorm = 0.1044, lr_0 = 1.6905e-04
Loss = 2.4230e-05, PNorm = 52.3761, GNorm = 0.0891, lr_0 = 1.6888e-04
Loss = 2.5282e-05, PNorm = 52.3772, GNorm = 0.1606, lr_0 = 1.6870e-04
Loss = 3.2455e-05, PNorm = 52.3788, GNorm = 0.1852, lr_0 = 1.6853e-04
Loss = 4.6031e-05, PNorm = 52.3791, GNorm = 0.1276, lr_0 = 1.6835e-04
Loss = 3.9675e-05, PNorm = 52.3797, GNorm = 0.2323, lr_0 = 1.6817e-04
Loss = 3.7674e-05, PNorm = 52.3807, GNorm = 0.1954, lr_0 = 1.6800e-04
Loss = 5.5685e-05, PNorm = 52.3822, GNorm = 0.1903, lr_0 = 1.6782e-04
Loss = 5.7834e-05, PNorm = 52.3837, GNorm = 0.2347, lr_0 = 1.6765e-04
Loss = 3.2926e-05, PNorm = 52.3840, GNorm = 0.1910, lr_0 = 1.6747e-04
Loss = 3.5913e-05, PNorm = 52.3857, GNorm = 0.1146, lr_0 = 1.6730e-04
Loss = 4.2476e-05, PNorm = 52.3877, GNorm = 0.1573, lr_0 = 1.6712e-04
Loss = 2.3840e-05, PNorm = 52.3898, GNorm = 0.1129, lr_0 = 1.6695e-04
Loss = 2.8135e-05, PNorm = 52.3906, GNorm = 0.0738, lr_0 = 1.6678e-04
Loss = 2.8092e-05, PNorm = 52.3912, GNorm = 0.1748, lr_0 = 1.6660e-04
Loss = 3.4706e-05, PNorm = 52.3927, GNorm = 0.1677, lr_0 = 1.6643e-04
Validation rmse logD = 0.611181
Validation R2 logD = 0.738753
Validation rmse logP = 0.458455
Validation R2 logP = 0.942141
Epoch 78
Train function
Loss = 3.4233e-05, PNorm = 52.3938, GNorm = 0.1767, lr_0 = 1.6625e-04
Loss = 4.2759e-05, PNorm = 52.3948, GNorm = 0.2554, lr_0 = 1.6608e-04
Loss = 2.8937e-05, PNorm = 52.3970, GNorm = 0.1225, lr_0 = 1.6591e-04
Loss = 2.6059e-05, PNorm = 52.3992, GNorm = 0.2095, lr_0 = 1.6573e-04
Loss = 2.8391e-05, PNorm = 52.4000, GNorm = 0.1442, lr_0 = 1.6556e-04
Loss = 2.8303e-05, PNorm = 52.4011, GNorm = 0.1210, lr_0 = 1.6539e-04
Loss = 2.3620e-05, PNorm = 52.4022, GNorm = 0.0716, lr_0 = 1.6522e-04
Loss = 2.2135e-05, PNorm = 52.4036, GNorm = 0.0713, lr_0 = 1.6504e-04
Loss = 2.2883e-05, PNorm = 52.4049, GNorm = 0.1524, lr_0 = 1.6487e-04
Loss = 2.8355e-05, PNorm = 52.4061, GNorm = 0.1793, lr_0 = 1.6470e-04
Loss = 2.3804e-05, PNorm = 52.4073, GNorm = 0.1585, lr_0 = 1.6453e-04
Loss = 2.4134e-05, PNorm = 52.4090, GNorm = 0.1650, lr_0 = 1.6435e-04
Loss = 4.1637e-05, PNorm = 52.4096, GNorm = 0.1500, lr_0 = 1.6418e-04
Loss = 3.4751e-05, PNorm = 52.4105, GNorm = 0.1516, lr_0 = 1.6401e-04
Loss = 4.1188e-05, PNorm = 52.4122, GNorm = 0.2917, lr_0 = 1.6384e-04
Loss = 3.3058e-05, PNorm = 52.4134, GNorm = 0.1435, lr_0 = 1.6367e-04
Loss = 2.9048e-05, PNorm = 52.4153, GNorm = 0.0778, lr_0 = 1.6350e-04
Loss = 3.2172e-05, PNorm = 52.4175, GNorm = 0.0911, lr_0 = 1.6333e-04
Loss = 2.4138e-05, PNorm = 52.4186, GNorm = 0.1695, lr_0 = 1.6316e-04
Loss = 3.1418e-05, PNorm = 52.4189, GNorm = 0.0921, lr_0 = 1.6299e-04
Loss = 3.3265e-05, PNorm = 52.4190, GNorm = 0.1280, lr_0 = 1.6282e-04
Loss = 3.5066e-05, PNorm = 52.4199, GNorm = 0.1689, lr_0 = 1.6265e-04
Loss = 3.7252e-05, PNorm = 52.4210, GNorm = 0.1360, lr_0 = 1.6248e-04
Validation rmse logD = 0.602048
Validation R2 logD = 0.746502
Validation rmse logP = 0.458025
Validation R2 logP = 0.942250
Epoch 79
Train function
Loss = 3.0480e-05, PNorm = 52.4229, GNorm = 0.1921, lr_0 = 1.6229e-04
Loss = 3.1142e-05, PNorm = 52.4235, GNorm = 0.0930, lr_0 = 1.6212e-04
Loss = 2.8406e-05, PNorm = 52.4258, GNorm = 0.1102, lr_0 = 1.6195e-04
Loss = 2.4729e-05, PNorm = 52.4281, GNorm = 0.0919, lr_0 = 1.6178e-04
Loss = 3.5593e-05, PNorm = 52.4312, GNorm = 0.1418, lr_0 = 1.6161e-04
Loss = 2.8426e-05, PNorm = 52.4315, GNorm = 0.1132, lr_0 = 1.6145e-04
Loss = 3.3492e-05, PNorm = 52.4322, GNorm = 0.1240, lr_0 = 1.6128e-04
Loss = 2.6847e-05, PNorm = 52.4351, GNorm = 0.2828, lr_0 = 1.6111e-04
Loss = 2.8602e-05, PNorm = 52.4359, GNorm = 0.1786, lr_0 = 1.6094e-04
Loss = 2.1693e-05, PNorm = 52.4373, GNorm = 0.1002, lr_0 = 1.6077e-04
Loss = 3.4080e-05, PNorm = 52.4374, GNorm = 0.1230, lr_0 = 1.6061e-04
Loss = 2.9002e-05, PNorm = 52.4389, GNorm = 0.1220, lr_0 = 1.6044e-04
Loss = 2.6268e-05, PNorm = 52.4400, GNorm = 0.0849, lr_0 = 1.6027e-04
Loss = 3.0727e-05, PNorm = 52.4403, GNorm = 0.1715, lr_0 = 1.6010e-04
Loss = 2.4018e-05, PNorm = 52.4423, GNorm = 0.0703, lr_0 = 1.5994e-04
Loss = 2.9676e-05, PNorm = 52.4443, GNorm = 0.1731, lr_0 = 1.5977e-04
Loss = 2.7342e-05, PNorm = 52.4459, GNorm = 0.0561, lr_0 = 1.5960e-04
Loss = 2.8584e-05, PNorm = 52.4466, GNorm = 0.1153, lr_0 = 1.5944e-04
Loss = 2.7915e-05, PNorm = 52.4473, GNorm = 0.0723, lr_0 = 1.5927e-04
Loss = 2.7818e-05, PNorm = 52.4492, GNorm = 0.0829, lr_0 = 1.5910e-04
Loss = 2.6890e-05, PNorm = 52.4500, GNorm = 0.1277, lr_0 = 1.5894e-04
Loss = 2.3306e-05, PNorm = 52.4509, GNorm = 0.0884, lr_0 = 1.5877e-04
Validation rmse logD = 0.603318
Validation R2 logD = 0.745431
Validation rmse logP = 0.458010
Validation R2 logP = 0.942254
Epoch 80
Train function
Loss = 4.0854e-05, PNorm = 52.4519, GNorm = 0.1299, lr_0 = 1.5861e-04
Loss = 2.4798e-05, PNorm = 52.4523, GNorm = 0.0901, lr_0 = 1.5844e-04
Loss = 1.8895e-05, PNorm = 52.4525, GNorm = 0.0780, lr_0 = 1.5827e-04
Loss = 2.0840e-05, PNorm = 52.4538, GNorm = 0.1095, lr_0 = 1.5811e-04
Loss = 2.1879e-05, PNorm = 52.4547, GNorm = 0.1236, lr_0 = 1.5794e-04
Loss = 2.8327e-05, PNorm = 52.4549, GNorm = 0.0896, lr_0 = 1.5778e-04
Loss = 2.4234e-05, PNorm = 52.4556, GNorm = 0.2028, lr_0 = 1.5761e-04
Loss = 2.3423e-05, PNorm = 52.4572, GNorm = 0.0556, lr_0 = 1.5745e-04
Loss = 2.4177e-05, PNorm = 52.4583, GNorm = 0.0912, lr_0 = 1.5729e-04
Loss = 2.8072e-05, PNorm = 52.4584, GNorm = 0.0793, lr_0 = 1.5712e-04
Loss = 2.3855e-05, PNorm = 52.4591, GNorm = 0.0989, lr_0 = 1.5696e-04
Loss = 2.7611e-05, PNorm = 52.4603, GNorm = 0.1441, lr_0 = 1.5679e-04
Loss = 2.5195e-05, PNorm = 52.4619, GNorm = 0.1689, lr_0 = 1.5663e-04
Loss = 2.2891e-05, PNorm = 52.4634, GNorm = 0.1309, lr_0 = 1.5647e-04
Loss = 2.2633e-05, PNorm = 52.4644, GNorm = 0.0881, lr_0 = 1.5630e-04
Loss = 2.8343e-05, PNorm = 52.4653, GNorm = 0.1849, lr_0 = 1.5614e-04
Loss = 2.7305e-05, PNorm = 52.4661, GNorm = 0.0903, lr_0 = 1.5598e-04
Loss = 2.3341e-05, PNorm = 52.4673, GNorm = 0.0531, lr_0 = 1.5581e-04
Loss = 2.8292e-05, PNorm = 52.4688, GNorm = 0.1669, lr_0 = 1.5565e-04
Loss = 3.0808e-05, PNorm = 52.4687, GNorm = 0.1623, lr_0 = 1.5549e-04
Loss = 2.4239e-05, PNorm = 52.4707, GNorm = 0.1266, lr_0 = 1.5533e-04
Loss = 2.5503e-05, PNorm = 52.4722, GNorm = 0.1297, lr_0 = 1.5516e-04
Loss = 2.4509e-05, PNorm = 52.4729, GNorm = 0.1037, lr_0 = 1.5500e-04
Validation rmse logD = 0.606121
Validation R2 logD = 0.743061
Validation rmse logP = 0.457568
Validation R2 logP = 0.942365
Epoch 81
Train function
Loss = 3.0529e-05, PNorm = 52.4758, GNorm = 0.1274, lr_0 = 1.5483e-04
Loss = 2.7712e-05, PNorm = 52.4774, GNorm = 0.1947, lr_0 = 1.5466e-04
Loss = 2.4991e-05, PNorm = 52.4777, GNorm = 0.0919, lr_0 = 1.5450e-04
Loss = 3.1182e-05, PNorm = 52.4786, GNorm = 0.0749, lr_0 = 1.5434e-04
Loss = 4.1487e-05, PNorm = 52.4806, GNorm = 0.1315, lr_0 = 1.5418e-04
Loss = 3.0660e-05, PNorm = 52.4821, GNorm = 0.1266, lr_0 = 1.5402e-04
Loss = 3.0633e-05, PNorm = 52.4844, GNorm = 0.1195, lr_0 = 1.5386e-04
Loss = 2.5427e-05, PNorm = 52.4851, GNorm = 0.1059, lr_0 = 1.5370e-04
Loss = 2.4148e-05, PNorm = 52.4845, GNorm = 0.1386, lr_0 = 1.5354e-04
Loss = 2.5879e-05, PNorm = 52.4863, GNorm = 0.2389, lr_0 = 1.5338e-04
Loss = 2.6457e-05, PNorm = 52.4881, GNorm = 0.2445, lr_0 = 1.5322e-04
Loss = 2.7635e-05, PNorm = 52.4898, GNorm = 0.0810, lr_0 = 1.5306e-04
Loss = 2.4005e-05, PNorm = 52.4914, GNorm = 0.1118, lr_0 = 1.5290e-04
Loss = 2.2794e-05, PNorm = 52.4922, GNorm = 0.1050, lr_0 = 1.5274e-04
Loss = 1.9142e-05, PNorm = 52.4931, GNorm = 0.1122, lr_0 = 1.5258e-04
Loss = 1.8335e-05, PNorm = 52.4930, GNorm = 0.0673, lr_0 = 1.5242e-04
Loss = 2.2402e-05, PNorm = 52.4941, GNorm = 0.0891, lr_0 = 1.5226e-04
Loss = 2.2738e-05, PNorm = 52.4944, GNorm = 0.1354, lr_0 = 1.5210e-04
Loss = 2.8523e-05, PNorm = 52.4955, GNorm = 0.1113, lr_0 = 1.5194e-04
Loss = 3.3506e-05, PNorm = 52.4962, GNorm = 0.1754, lr_0 = 1.5178e-04
Loss = 2.3205e-05, PNorm = 52.4979, GNorm = 0.1002, lr_0 = 1.5163e-04
Loss = 2.1098e-05, PNorm = 52.4993, GNorm = 0.1172, lr_0 = 1.5147e-04
Validation rmse logD = 0.605819
Validation R2 logD = 0.743317
Validation rmse logP = 0.458669
Validation R2 logP = 0.942087
Epoch 82
Train function
Loss = 2.7022e-05, PNorm = 52.5000, GNorm = 0.1380, lr_0 = 1.5131e-04
Loss = 2.8913e-05, PNorm = 52.5015, GNorm = 0.1260, lr_0 = 1.5115e-04
Loss = 2.7157e-05, PNorm = 52.5032, GNorm = 0.1031, lr_0 = 1.5099e-04
Loss = 2.5579e-05, PNorm = 52.5040, GNorm = 0.1133, lr_0 = 1.5084e-04
Loss = 2.7487e-05, PNorm = 52.5052, GNorm = 0.0871, lr_0 = 1.5068e-04
Loss = 2.3589e-05, PNorm = 52.5064, GNorm = 0.1055, lr_0 = 1.5052e-04
Loss = 2.4995e-05, PNorm = 52.5072, GNorm = 0.1423, lr_0 = 1.5036e-04
Loss = 2.7265e-05, PNorm = 52.5085, GNorm = 0.1022, lr_0 = 1.5021e-04
Loss = 2.1861e-05, PNorm = 52.5102, GNorm = 0.0858, lr_0 = 1.5005e-04
Loss = 2.2920e-05, PNorm = 52.5113, GNorm = 0.1542, lr_0 = 1.4989e-04
Loss = 3.3237e-05, PNorm = 52.5124, GNorm = 0.1056, lr_0 = 1.4974e-04
Loss = 2.9106e-05, PNorm = 52.5131, GNorm = 0.1372, lr_0 = 1.4958e-04
Loss = 2.5532e-05, PNorm = 52.5127, GNorm = 0.1853, lr_0 = 1.4942e-04
Loss = 2.5994e-05, PNorm = 52.5143, GNorm = 0.0875, lr_0 = 1.4927e-04
Loss = 1.9674e-05, PNorm = 52.5162, GNorm = 0.0804, lr_0 = 1.4911e-04
Loss = 2.7856e-05, PNorm = 52.5170, GNorm = 0.0922, lr_0 = 1.4896e-04
Loss = 2.8532e-05, PNorm = 52.5186, GNorm = 0.0732, lr_0 = 1.4880e-04
Loss = 2.5238e-05, PNorm = 52.5198, GNorm = 0.0898, lr_0 = 1.4865e-04
Loss = 2.8184e-05, PNorm = 52.5206, GNorm = 0.0838, lr_0 = 1.4849e-04
Loss = 2.9986e-05, PNorm = 52.5211, GNorm = 0.1822, lr_0 = 1.4834e-04
Loss = 2.3780e-05, PNorm = 52.5219, GNorm = 0.1196, lr_0 = 1.4818e-04
Loss = 2.2934e-05, PNorm = 52.5224, GNorm = 0.1463, lr_0 = 1.4803e-04
Loss = 3.1438e-05, PNorm = 52.5236, GNorm = 0.0972, lr_0 = 1.4787e-04
Validation rmse logD = 0.610582
Validation R2 logD = 0.739264
Validation rmse logP = 0.458883
Validation R2 logP = 0.942033
Epoch 83
Train function
Loss = 2.1983e-05, PNorm = 52.5268, GNorm = 0.0926, lr_0 = 1.4770e-04
Loss = 2.2535e-05, PNorm = 52.5279, GNorm = 0.1074, lr_0 = 1.4755e-04
Loss = 1.4906e-05, PNorm = 52.5284, GNorm = 0.0854, lr_0 = 1.4739e-04
Loss = 2.5317e-05, PNorm = 52.5286, GNorm = 0.1131, lr_0 = 1.4724e-04
Loss = 2.9727e-05, PNorm = 52.5287, GNorm = 0.1421, lr_0 = 1.4709e-04
Loss = 2.5469e-05, PNorm = 52.5298, GNorm = 0.1744, lr_0 = 1.4693e-04
Loss = 2.8973e-05, PNorm = 52.5311, GNorm = 0.1126, lr_0 = 1.4678e-04
Loss = 2.6582e-05, PNorm = 52.5321, GNorm = 0.2238, lr_0 = 1.4663e-04
Loss = 3.4130e-05, PNorm = 52.5343, GNorm = 0.1137, lr_0 = 1.4647e-04
Loss = 3.0247e-05, PNorm = 52.5357, GNorm = 0.1011, lr_0 = 1.4632e-04
Loss = 3.0645e-05, PNorm = 52.5366, GNorm = 0.1065, lr_0 = 1.4617e-04
Loss = 3.7122e-05, PNorm = 52.5372, GNorm = 0.1580, lr_0 = 1.4602e-04
Loss = 2.7905e-05, PNorm = 52.5390, GNorm = 0.1609, lr_0 = 1.4586e-04
Loss = 2.3059e-05, PNorm = 52.5412, GNorm = 0.1095, lr_0 = 1.4571e-04
Loss = 2.3817e-05, PNorm = 52.5423, GNorm = 0.0588, lr_0 = 1.4556e-04
Loss = 2.3996e-05, PNorm = 52.5427, GNorm = 0.1112, lr_0 = 1.4541e-04
Loss = 2.0679e-05, PNorm = 52.5440, GNorm = 0.0946, lr_0 = 1.4526e-04
Loss = 1.9877e-05, PNorm = 52.5449, GNorm = 0.1076, lr_0 = 1.4510e-04
Loss = 2.9702e-05, PNorm = 52.5454, GNorm = 0.1203, lr_0 = 1.4495e-04
Loss = 2.2480e-05, PNorm = 52.5469, GNorm = 0.0981, lr_0 = 1.4480e-04
Loss = 2.0470e-05, PNorm = 52.5484, GNorm = 0.0937, lr_0 = 1.4465e-04
Loss = 2.1088e-05, PNorm = 52.5495, GNorm = 0.0887, lr_0 = 1.4450e-04
Loss = 2.7772e-05, PNorm = 52.5496, GNorm = 0.2773, lr_0 = 1.4435e-04
Validation rmse logD = 0.609734
Validation R2 logD = 0.739988
Validation rmse logP = 0.456914
Validation R2 logP = 0.942530
Epoch 84
Train function
Loss = 2.3125e-05, PNorm = 52.5507, GNorm = 0.1480, lr_0 = 1.4420e-04
Loss = 3.1112e-05, PNorm = 52.5517, GNorm = 0.0953, lr_0 = 1.4405e-04
Loss = 2.0390e-05, PNorm = 52.5531, GNorm = 0.0829, lr_0 = 1.4390e-04
Loss = 2.1695e-05, PNorm = 52.5537, GNorm = 0.0760, lr_0 = 1.4375e-04
Loss = 2.5783e-05, PNorm = 52.5544, GNorm = 0.0860, lr_0 = 1.4360e-04
Loss = 1.5340e-05, PNorm = 52.5554, GNorm = 0.0694, lr_0 = 1.4345e-04
Loss = 1.7791e-05, PNorm = 52.5561, GNorm = 0.1128, lr_0 = 1.4330e-04
Loss = 1.8597e-05, PNorm = 52.5562, GNorm = 0.1461, lr_0 = 1.4315e-04
Loss = 1.5360e-05, PNorm = 52.5564, GNorm = 0.0735, lr_0 = 1.4300e-04
Loss = 1.9018e-05, PNorm = 52.5580, GNorm = 0.1151, lr_0 = 1.4285e-04
Loss = 2.2072e-05, PNorm = 52.5588, GNorm = 0.0717, lr_0 = 1.4270e-04
Loss = 1.9038e-05, PNorm = 52.5603, GNorm = 0.1890, lr_0 = 1.4255e-04
Loss = 1.4623e-05, PNorm = 52.5616, GNorm = 0.0944, lr_0 = 1.4240e-04
Loss = 2.2233e-05, PNorm = 52.5623, GNorm = 0.1054, lr_0 = 1.4225e-04
Loss = 2.1769e-05, PNorm = 52.5625, GNorm = 0.1036, lr_0 = 1.4210e-04
Loss = 2.2870e-05, PNorm = 52.5634, GNorm = 0.1154, lr_0 = 1.4196e-04
Loss = 2.4328e-05, PNorm = 52.5650, GNorm = 0.0944, lr_0 = 1.4181e-04
Loss = 2.1442e-05, PNorm = 52.5670, GNorm = 0.1210, lr_0 = 1.4166e-04
Loss = 2.4033e-05, PNorm = 52.5679, GNorm = 0.0777, lr_0 = 1.4151e-04
Loss = 2.0819e-05, PNorm = 52.5674, GNorm = 0.0965, lr_0 = 1.4136e-04
Loss = 2.0153e-05, PNorm = 52.5670, GNorm = 0.0694, lr_0 = 1.4122e-04
Loss = 1.9253e-05, PNorm = 52.5676, GNorm = 0.0660, lr_0 = 1.4107e-04
Validation rmse logD = 0.610693
Validation R2 logD = 0.739169
Validation rmse logP = 0.460337
Validation R2 logP = 0.941665
Epoch 85
Train function
Loss = 2.1757e-05, PNorm = 52.5687, GNorm = 0.0698, lr_0 = 1.4091e-04
Loss = 2.0558e-05, PNorm = 52.5695, GNorm = 0.1414, lr_0 = 1.4076e-04
Loss = 1.8256e-05, PNorm = 52.5697, GNorm = 0.1053, lr_0 = 1.4061e-04
Loss = 1.4326e-05, PNorm = 52.5711, GNorm = 0.0913, lr_0 = 1.4047e-04
Loss = 2.2146e-05, PNorm = 52.5715, GNorm = 0.0965, lr_0 = 1.4032e-04
Loss = 1.9371e-05, PNorm = 52.5720, GNorm = 0.1138, lr_0 = 1.4017e-04
Loss = 1.9226e-05, PNorm = 52.5727, GNorm = 0.1112, lr_0 = 1.4003e-04
Loss = 1.6169e-05, PNorm = 52.5733, GNorm = 0.0613, lr_0 = 1.3988e-04
Loss = 1.4145e-05, PNorm = 52.5736, GNorm = 0.0816, lr_0 = 1.3974e-04
Loss = 1.4261e-05, PNorm = 52.5743, GNorm = 0.0885, lr_0 = 1.3959e-04
Loss = 1.7898e-05, PNorm = 52.5746, GNorm = 0.0685, lr_0 = 1.3944e-04
Loss = 2.1312e-05, PNorm = 52.5747, GNorm = 0.1345, lr_0 = 1.3930e-04
Loss = 2.5581e-05, PNorm = 52.5756, GNorm = 0.0913, lr_0 = 1.3915e-04
Loss = 2.0236e-05, PNorm = 52.5762, GNorm = 0.0672, lr_0 = 1.3901e-04
Loss = 1.8325e-05, PNorm = 52.5759, GNorm = 0.0648, lr_0 = 1.3886e-04
Loss = 1.4499e-05, PNorm = 52.5764, GNorm = 0.0701, lr_0 = 1.3872e-04
Loss = 1.5521e-05, PNorm = 52.5782, GNorm = 0.0713, lr_0 = 1.3857e-04
Loss = 2.0260e-05, PNorm = 52.5794, GNorm = 0.1283, lr_0 = 1.3843e-04
Loss = 1.6732e-05, PNorm = 52.5804, GNorm = 0.0902, lr_0 = 1.3828e-04
Loss = 1.4478e-05, PNorm = 52.5812, GNorm = 0.0836, lr_0 = 1.3814e-04
Loss = 2.5246e-05, PNorm = 52.5827, GNorm = 0.1387, lr_0 = 1.3800e-04
Loss = 2.6284e-05, PNorm = 52.5847, GNorm = 0.1727, lr_0 = 1.3785e-04
Loss = 1.9626e-05, PNorm = 52.5857, GNorm = 0.0796, lr_0 = 1.3771e-04
Validation rmse logD = 0.611413
Validation R2 logD = 0.738554
Validation rmse logP = 0.456823
Validation R2 logP = 0.942553
Epoch 86
Train function
Loss = 2.0319e-05, PNorm = 52.5859, GNorm = 0.1338, lr_0 = 1.3756e-04
Loss = 1.7444e-05, PNorm = 52.5875, GNorm = 0.0851, lr_0 = 1.3742e-04
Loss = 1.5007e-05, PNorm = 52.5884, GNorm = 0.0592, lr_0 = 1.3728e-04
Loss = 1.6397e-05, PNorm = 52.5887, GNorm = 0.0971, lr_0 = 1.3713e-04
Loss = 1.7755e-05, PNorm = 52.5896, GNorm = 0.1100, lr_0 = 1.3699e-04
Loss = 1.8090e-05, PNorm = 52.5898, GNorm = 0.1328, lr_0 = 1.3685e-04
Loss = 2.4106e-05, PNorm = 52.5908, GNorm = 0.2020, lr_0 = 1.3670e-04
Loss = 1.6418e-05, PNorm = 52.5920, GNorm = 0.0540, lr_0 = 1.3656e-04
Loss = 2.1479e-05, PNorm = 52.5932, GNorm = 0.1850, lr_0 = 1.3642e-04
Loss = 2.6442e-05, PNorm = 52.5945, GNorm = 0.0987, lr_0 = 1.3628e-04
Loss = 2.1434e-05, PNorm = 52.5967, GNorm = 0.1073, lr_0 = 1.3613e-04
Loss = 2.0238e-05, PNorm = 52.5980, GNorm = 0.2276, lr_0 = 1.3599e-04
Loss = 2.0232e-05, PNorm = 52.5984, GNorm = 0.2002, lr_0 = 1.3585e-04
Loss = 1.8965e-05, PNorm = 52.6001, GNorm = 0.0801, lr_0 = 1.3571e-04
Loss = 2.1548e-05, PNorm = 52.6004, GNorm = 0.0905, lr_0 = 1.3557e-04
Loss = 2.1034e-05, PNorm = 52.6014, GNorm = 0.1459, lr_0 = 1.3543e-04
Loss = 1.9492e-05, PNorm = 52.6020, GNorm = 0.1312, lr_0 = 1.3528e-04
Loss = 1.4529e-05, PNorm = 52.6027, GNorm = 0.0919, lr_0 = 1.3514e-04
Loss = 1.9867e-05, PNorm = 52.6031, GNorm = 0.0568, lr_0 = 1.3500e-04
Loss = 2.0957e-05, PNorm = 52.6039, GNorm = 0.1835, lr_0 = 1.3486e-04
Loss = 1.9155e-05, PNorm = 52.6053, GNorm = 0.1019, lr_0 = 1.3472e-04
Loss = 2.6932e-05, PNorm = 52.6071, GNorm = 0.1752, lr_0 = 1.3458e-04
Validation rmse logD = 0.608302
Validation R2 logD = 0.741208
Validation rmse logP = 0.458070
Validation R2 logP = 0.942239
Epoch 87
Train function
Loss = 2.3394e-05, PNorm = 52.6082, GNorm = 0.1090, lr_0 = 1.3443e-04
Loss = 2.2980e-05, PNorm = 52.6083, GNorm = 0.1126, lr_0 = 1.3428e-04
Loss = 2.6495e-05, PNorm = 52.6080, GNorm = 0.1449, lr_0 = 1.3414e-04
Loss = 2.4484e-05, PNorm = 52.6090, GNorm = 0.1161, lr_0 = 1.3400e-04
Loss = 2.4739e-05, PNorm = 52.6098, GNorm = 0.1431, lr_0 = 1.3386e-04
Loss = 2.0032e-05, PNorm = 52.6112, GNorm = 0.1077, lr_0 = 1.3373e-04
Loss = 1.8021e-05, PNorm = 52.6121, GNorm = 0.0787, lr_0 = 1.3359e-04
Loss = 1.6962e-05, PNorm = 52.6132, GNorm = 0.1119, lr_0 = 1.3345e-04
Loss = 1.8070e-05, PNorm = 52.6141, GNorm = 0.1248, lr_0 = 1.3331e-04
Loss = 1.9807e-05, PNorm = 52.6156, GNorm = 0.1323, lr_0 = 1.3317e-04
Loss = 2.1890e-05, PNorm = 52.6167, GNorm = 0.1533, lr_0 = 1.3303e-04
Loss = 2.1727e-05, PNorm = 52.6176, GNorm = 0.1947, lr_0 = 1.3289e-04
Loss = 2.1123e-05, PNorm = 52.6191, GNorm = 0.1526, lr_0 = 1.3275e-04
Loss = 2.0756e-05, PNorm = 52.6205, GNorm = 0.1112, lr_0 = 1.3261e-04
Loss = 1.9769e-05, PNorm = 52.6218, GNorm = 0.0901, lr_0 = 1.3247e-04
Loss = 1.8030e-05, PNorm = 52.6226, GNorm = 0.0974, lr_0 = 1.3234e-04
Loss = 3.1099e-05, PNorm = 52.6236, GNorm = 0.1593, lr_0 = 1.3220e-04
Loss = 3.1987e-05, PNorm = 52.6241, GNorm = 0.2730, lr_0 = 1.3206e-04
Loss = 2.6466e-05, PNorm = 52.6250, GNorm = 0.1109, lr_0 = 1.3192e-04
Loss = 3.0749e-05, PNorm = 52.6255, GNorm = 0.1472, lr_0 = 1.3178e-04
Loss = 2.9354e-05, PNorm = 52.6269, GNorm = 0.1479, lr_0 = 1.3165e-04
Loss = 2.7020e-05, PNorm = 52.6277, GNorm = 0.1523, lr_0 = 1.3151e-04
Loss = 2.7905e-05, PNorm = 52.6296, GNorm = 0.1105, lr_0 = 1.3137e-04
Validation rmse logD = 0.609623
Validation R2 logD = 0.740083
Validation rmse logP = 0.456236
Validation R2 logP = 0.942700
Epoch 88
Train function
Loss = 2.7731e-05, PNorm = 52.6313, GNorm = 0.1278, lr_0 = 1.3124e-04
Loss = 2.8367e-05, PNorm = 52.6332, GNorm = 0.1423, lr_0 = 1.3110e-04
Loss = 2.1649e-05, PNorm = 52.6353, GNorm = 0.1008, lr_0 = 1.3096e-04
Loss = 2.5642e-05, PNorm = 52.6366, GNorm = 0.1441, lr_0 = 1.3082e-04
Loss = 1.8819e-05, PNorm = 52.6366, GNorm = 0.1287, lr_0 = 1.3069e-04
Loss = 1.7027e-05, PNorm = 52.6367, GNorm = 0.0593, lr_0 = 1.3055e-04
Loss = 1.3874e-05, PNorm = 52.6375, GNorm = 0.0720, lr_0 = 1.3042e-04
Loss = 1.8942e-05, PNorm = 52.6388, GNorm = 0.0739, lr_0 = 1.3028e-04
Loss = 1.8994e-05, PNorm = 52.6398, GNorm = 0.1058, lr_0 = 1.3014e-04
Loss = 2.6289e-05, PNorm = 52.6406, GNorm = 0.1303, lr_0 = 1.3001e-04
Loss = 3.1147e-05, PNorm = 52.6423, GNorm = 0.3410, lr_0 = 1.2987e-04
Loss = 2.7472e-05, PNorm = 52.6434, GNorm = 0.1491, lr_0 = 1.2974e-04
Loss = 2.7202e-05, PNorm = 52.6443, GNorm = 0.1349, lr_0 = 1.2960e-04
Loss = 2.3928e-05, PNorm = 52.6453, GNorm = 0.0981, lr_0 = 1.2947e-04
Loss = 2.2862e-05, PNorm = 52.6464, GNorm = 0.1083, lr_0 = 1.2933e-04
Loss = 3.1894e-05, PNorm = 52.6482, GNorm = 0.1521, lr_0 = 1.2920e-04
Loss = 3.2459e-05, PNorm = 52.6489, GNorm = 0.1070, lr_0 = 1.2906e-04
Loss = 3.1406e-05, PNorm = 52.6513, GNorm = 0.1556, lr_0 = 1.2893e-04
Loss = 2.4857e-05, PNorm = 52.6519, GNorm = 0.1275, lr_0 = 1.2879e-04
Loss = 2.0521e-05, PNorm = 52.6527, GNorm = 0.1081, lr_0 = 1.2866e-04
Loss = 2.2629e-05, PNorm = 52.6533, GNorm = 0.1071, lr_0 = 1.2852e-04
Loss = 2.2841e-05, PNorm = 52.6540, GNorm = 0.1312, lr_0 = 1.2839e-04
Validation rmse logD = 0.608293
Validation R2 logD = 0.741216
Validation rmse logP = 0.457810
Validation R2 logP = 0.942304
Epoch 89
Train function
Loss = 1.7541e-05, PNorm = 52.6555, GNorm = 0.0638, lr_0 = 1.2824e-04
Loss = 1.9002e-05, PNorm = 52.6559, GNorm = 0.0982, lr_0 = 1.2811e-04
Loss = 2.0525e-05, PNorm = 52.6561, GNorm = 0.1161, lr_0 = 1.2797e-04
Loss = 1.8403e-05, PNorm = 52.6572, GNorm = 0.0697, lr_0 = 1.2784e-04
Loss = 2.1487e-05, PNorm = 52.6577, GNorm = 0.0917, lr_0 = 1.2771e-04
Loss = 1.7922e-05, PNorm = 52.6571, GNorm = 0.0740, lr_0 = 1.2757e-04
Loss = 2.3246e-05, PNorm = 52.6584, GNorm = 0.0506, lr_0 = 1.2744e-04
Loss = 1.7623e-05, PNorm = 52.6602, GNorm = 0.1186, lr_0 = 1.2731e-04
Loss = 1.8347e-05, PNorm = 52.6604, GNorm = 0.1090, lr_0 = 1.2717e-04
Loss = 2.3329e-05, PNorm = 52.6615, GNorm = 0.0781, lr_0 = 1.2704e-04
Loss = 1.8088e-05, PNorm = 52.6615, GNorm = 0.1452, lr_0 = 1.2691e-04
Loss = 1.9585e-05, PNorm = 52.6624, GNorm = 0.1021, lr_0 = 1.2678e-04
Loss = 1.8641e-05, PNorm = 52.6629, GNorm = 0.0777, lr_0 = 1.2664e-04
Loss = 1.9502e-05, PNorm = 52.6643, GNorm = 0.0809, lr_0 = 1.2651e-04
Loss = 1.4816e-05, PNorm = 52.6659, GNorm = 0.0758, lr_0 = 1.2638e-04
Loss = 1.6300e-05, PNorm = 52.6673, GNorm = 0.1554, lr_0 = 1.2625e-04
Loss = 1.8952e-05, PNorm = 52.6680, GNorm = 0.0975, lr_0 = 1.2612e-04
Loss = 1.8561e-05, PNorm = 52.6684, GNorm = 0.1075, lr_0 = 1.2598e-04
Loss = 1.6280e-05, PNorm = 52.6693, GNorm = 0.1714, lr_0 = 1.2585e-04
Loss = 2.6499e-05, PNorm = 52.6714, GNorm = 0.1421, lr_0 = 1.2572e-04
Loss = 2.1988e-05, PNorm = 52.6718, GNorm = 0.1302, lr_0 = 1.2559e-04
Loss = 1.8902e-05, PNorm = 52.6722, GNorm = 0.1026, lr_0 = 1.2546e-04
Loss = 1.6849e-05, PNorm = 52.6734, GNorm = 0.1649, lr_0 = 1.2533e-04
Validation rmse logD = 0.609953
Validation R2 logD = 0.739801
Validation rmse logP = 0.459235
Validation R2 logP = 0.941944
Epoch 90
Train function
Loss = 1.2857e-05, PNorm = 52.6747, GNorm = 0.0812, lr_0 = 1.2520e-04
Loss = 1.6337e-05, PNorm = 52.6760, GNorm = 0.1602, lr_0 = 1.2507e-04
Loss = 1.6955e-05, PNorm = 52.6777, GNorm = 0.0598, lr_0 = 1.2494e-04
Loss = 1.4079e-05, PNorm = 52.6786, GNorm = 0.0903, lr_0 = 1.2481e-04
Loss = 1.1672e-05, PNorm = 52.6793, GNorm = 0.0690, lr_0 = 1.2468e-04
Loss = 1.0036e-05, PNorm = 52.6798, GNorm = 0.0527, lr_0 = 1.2455e-04
Loss = 1.4465e-05, PNorm = 52.6806, GNorm = 0.0563, lr_0 = 1.2442e-04
Loss = 1.2927e-05, PNorm = 52.6806, GNorm = 0.0831, lr_0 = 1.2429e-04
Loss = 1.4132e-05, PNorm = 52.6812, GNorm = 0.0954, lr_0 = 1.2416e-04
Loss = 2.0344e-05, PNorm = 52.6819, GNorm = 0.1506, lr_0 = 1.2403e-04
Loss = 1.3751e-05, PNorm = 52.6822, GNorm = 0.1260, lr_0 = 1.2390e-04
Loss = 1.3671e-05, PNorm = 52.6823, GNorm = 0.0636, lr_0 = 1.2377e-04
Loss = 2.1274e-05, PNorm = 52.6836, GNorm = 0.1181, lr_0 = 1.2364e-04
Loss = 1.4655e-05, PNorm = 52.6845, GNorm = 0.0934, lr_0 = 1.2351e-04
Loss = 1.8290e-05, PNorm = 52.6850, GNorm = 0.0999, lr_0 = 1.2338e-04
Loss = 1.6711e-05, PNorm = 52.6871, GNorm = 0.1352, lr_0 = 1.2325e-04
Loss = 1.3641e-05, PNorm = 52.6875, GNorm = 0.0826, lr_0 = 1.2312e-04
Loss = 2.0179e-05, PNorm = 52.6879, GNorm = 0.0763, lr_0 = 1.2299e-04
Loss = 1.7246e-05, PNorm = 52.6893, GNorm = 0.2335, lr_0 = 1.2287e-04
Loss = 1.6689e-05, PNorm = 52.6900, GNorm = 0.0615, lr_0 = 1.2274e-04
Loss = 2.0845e-05, PNorm = 52.6907, GNorm = 0.0690, lr_0 = 1.2261e-04
Loss = 2.1349e-05, PNorm = 52.6915, GNorm = 0.0811, lr_0 = 1.2248e-04
Validation rmse logD = 0.609467
Validation R2 logD = 0.740216
Validation rmse logP = 0.458323
Validation R2 logP = 0.942175
Epoch 91
Train function
Loss = 6.8964e-06, PNorm = 52.6915, GNorm = 0.0350, lr_0 = 1.2234e-04
Loss = 1.5687e-05, PNorm = 52.6930, GNorm = 0.0553, lr_0 = 1.2221e-04
Loss = 1.5416e-05, PNorm = 52.6937, GNorm = 0.1762, lr_0 = 1.2209e-04
Loss = 2.4758e-05, PNorm = 52.6945, GNorm = 0.1301, lr_0 = 1.2196e-04
Loss = 2.3554e-05, PNorm = 52.6951, GNorm = 0.1213, lr_0 = 1.2183e-04
Loss = 1.9646e-05, PNorm = 52.6965, GNorm = 0.0970, lr_0 = 1.2170e-04
Loss = 1.5824e-05, PNorm = 52.6981, GNorm = 0.1163, lr_0 = 1.2158e-04
Loss = 1.7886e-05, PNorm = 52.6983, GNorm = 0.1847, lr_0 = 1.2145e-04
Loss = 1.4715e-05, PNorm = 52.6985, GNorm = 0.0726, lr_0 = 1.2132e-04
Loss = 1.4153e-05, PNorm = 52.6989, GNorm = 0.1020, lr_0 = 1.2120e-04
Loss = 1.5591e-05, PNorm = 52.6986, GNorm = 0.1443, lr_0 = 1.2107e-04
Loss = 2.0390e-05, PNorm = 52.6991, GNorm = 0.0886, lr_0 = 1.2094e-04
Loss = 1.8222e-05, PNorm = 52.7001, GNorm = 0.1297, lr_0 = 1.2082e-04
Loss = 1.5656e-05, PNorm = 52.7007, GNorm = 0.0769, lr_0 = 1.2069e-04
Loss = 1.6544e-05, PNorm = 52.7013, GNorm = 0.1094, lr_0 = 1.2057e-04
Loss = 1.5872e-05, PNorm = 52.7019, GNorm = 0.0982, lr_0 = 1.2044e-04
Loss = 1.1053e-05, PNorm = 52.7017, GNorm = 0.0782, lr_0 = 1.2031e-04
Loss = 1.8482e-05, PNorm = 52.7027, GNorm = 0.0864, lr_0 = 1.2019e-04
Loss = 1.1861e-05, PNorm = 52.7042, GNorm = 0.0905, lr_0 = 1.2006e-04
Loss = 1.4523e-05, PNorm = 52.7051, GNorm = 0.0909, lr_0 = 1.1994e-04
Loss = 1.4228e-05, PNorm = 52.7056, GNorm = 0.1667, lr_0 = 1.1981e-04
Loss = 1.6456e-05, PNorm = 52.7065, GNorm = 0.1520, lr_0 = 1.1969e-04
Loss = 1.7019e-05, PNorm = 52.7075, GNorm = 0.0989, lr_0 = 1.1956e-04
Validation rmse logD = 0.607730
Validation R2 logD = 0.741694
Validation rmse logP = 0.460050
Validation R2 logP = 0.941738
Epoch 92
Train function
Loss = 1.7304e-05, PNorm = 52.7080, GNorm = 0.1147, lr_0 = 1.1944e-04
Loss = 2.0290e-05, PNorm = 52.7086, GNorm = 0.0950, lr_0 = 1.1931e-04
Loss = 1.9841e-05, PNorm = 52.7101, GNorm = 0.0354, lr_0 = 1.1919e-04
Loss = 2.0123e-05, PNorm = 52.7107, GNorm = 0.1381, lr_0 = 1.1906e-04
Loss = 2.0524e-05, PNorm = 52.7108, GNorm = 0.0779, lr_0 = 1.1894e-04
Loss = 1.6458e-05, PNorm = 52.7116, GNorm = 0.1575, lr_0 = 1.1882e-04
Loss = 1.4639e-05, PNorm = 52.7129, GNorm = 0.0706, lr_0 = 1.1869e-04
Loss = 2.1196e-05, PNorm = 52.7135, GNorm = 0.1692, lr_0 = 1.1857e-04
Loss = 1.6596e-05, PNorm = 52.7141, GNorm = 0.0808, lr_0 = 1.1844e-04
Loss = 2.0786e-05, PNorm = 52.7156, GNorm = 0.2161, lr_0 = 1.1832e-04
Loss = 2.0187e-05, PNorm = 52.7168, GNorm = 0.0946, lr_0 = 1.1820e-04
Loss = 1.6606e-05, PNorm = 52.7174, GNorm = 0.1068, lr_0 = 1.1807e-04
Loss = 1.6445e-05, PNorm = 52.7181, GNorm = 0.0826, lr_0 = 1.1795e-04
Loss = 1.2043e-05, PNorm = 52.7189, GNorm = 0.0850, lr_0 = 1.1783e-04
Loss = 1.0960e-05, PNorm = 52.7192, GNorm = 0.0618, lr_0 = 1.1770e-04
Loss = 1.5494e-05, PNorm = 52.7191, GNorm = 0.0623, lr_0 = 1.1758e-04
Loss = 1.0895e-05, PNorm = 52.7196, GNorm = 0.1326, lr_0 = 1.1746e-04
Loss = 1.3081e-05, PNorm = 52.7196, GNorm = 0.0927, lr_0 = 1.1734e-04
Loss = 1.3560e-05, PNorm = 52.7197, GNorm = 0.0831, lr_0 = 1.1721e-04
Loss = 2.0304e-05, PNorm = 52.7207, GNorm = 0.1164, lr_0 = 1.1709e-04
Loss = 1.3990e-05, PNorm = 52.7224, GNorm = 0.0859, lr_0 = 1.1697e-04
Loss = 2.1073e-05, PNorm = 52.7219, GNorm = 0.0533, lr_0 = 1.1685e-04
Validation rmse logD = 0.610007
Validation R2 logD = 0.739756
Validation rmse logP = 0.459388
Validation R2 logP = 0.941906
Epoch 93
Train function
Loss = 1.6125e-05, PNorm = 52.7228, GNorm = 0.1019, lr_0 = 1.1671e-04
Loss = 1.7327e-05, PNorm = 52.7234, GNorm = 0.1246, lr_0 = 1.1659e-04
Loss = 1.1676e-05, PNorm = 52.7239, GNorm = 0.1207, lr_0 = 1.1647e-04
Loss = 1.2496e-05, PNorm = 52.7255, GNorm = 0.0655, lr_0 = 1.1635e-04
Loss = 2.0260e-05, PNorm = 52.7267, GNorm = 0.0900, lr_0 = 1.1623e-04
Loss = 1.9315e-05, PNorm = 52.7275, GNorm = 0.0740, lr_0 = 1.1611e-04
Loss = 1.5824e-05, PNorm = 52.7281, GNorm = 0.0942, lr_0 = 1.1598e-04
Loss = 1.6882e-05, PNorm = 52.7282, GNorm = 0.1530, lr_0 = 1.1586e-04
Loss = 1.1747e-05, PNorm = 52.7284, GNorm = 0.0701, lr_0 = 1.1574e-04
Loss = 1.2479e-05, PNorm = 52.7285, GNorm = 0.0552, lr_0 = 1.1562e-04
Loss = 1.3878e-05, PNorm = 52.7286, GNorm = 0.0562, lr_0 = 1.1550e-04
Loss = 1.2871e-05, PNorm = 52.7293, GNorm = 0.0813, lr_0 = 1.1538e-04
Loss = 1.1681e-05, PNorm = 52.7304, GNorm = 0.0583, lr_0 = 1.1526e-04
Loss = 9.6104e-06, PNorm = 52.7299, GNorm = 0.0773, lr_0 = 1.1514e-04
Loss = 1.3978e-05, PNorm = 52.7302, GNorm = 0.0690, lr_0 = 1.1502e-04
Loss = 1.6271e-05, PNorm = 52.7312, GNorm = 0.0925, lr_0 = 1.1490e-04
Loss = 1.7250e-05, PNorm = 52.7319, GNorm = 0.0594, lr_0 = 1.1478e-04
Loss = 1.2154e-05, PNorm = 52.7327, GNorm = 0.0608, lr_0 = 1.1466e-04
Loss = 1.6489e-05, PNorm = 52.7340, GNorm = 0.0867, lr_0 = 1.1454e-04
Loss = 1.1966e-05, PNorm = 52.7348, GNorm = 0.0797, lr_0 = 1.1442e-04
Loss = 1.5017e-05, PNorm = 52.7353, GNorm = 0.1024, lr_0 = 1.1430e-04
Loss = 1.7822e-05, PNorm = 52.7359, GNorm = 0.1447, lr_0 = 1.1418e-04
Loss = 2.2343e-05, PNorm = 52.7367, GNorm = 0.1151, lr_0 = 1.1406e-04
Validation rmse logD = 0.610320
Validation R2 logD = 0.739488
Validation rmse logP = 0.459094
Validation R2 logP = 0.941980
Epoch 94
Train function
Loss = 1.5333e-05, PNorm = 52.7376, GNorm = 0.1165, lr_0 = 1.1394e-04
Loss = 1.5990e-05, PNorm = 52.7386, GNorm = 0.0691, lr_0 = 1.1382e-04
Loss = 1.3515e-05, PNorm = 52.7389, GNorm = 0.0752, lr_0 = 1.1371e-04
Loss = 1.2256e-05, PNorm = 52.7402, GNorm = 0.0806, lr_0 = 1.1359e-04
Loss = 1.0773e-05, PNorm = 52.7407, GNorm = 0.0764, lr_0 = 1.1347e-04
Loss = 9.0324e-06, PNorm = 52.7419, GNorm = 0.0720, lr_0 = 1.1335e-04
Loss = 1.2567e-05, PNorm = 52.7421, GNorm = 0.0604, lr_0 = 1.1323e-04
Loss = 2.3967e-05, PNorm = 52.7436, GNorm = 0.1513, lr_0 = 1.1311e-04
Loss = 1.7500e-05, PNorm = 52.7450, GNorm = 0.0903, lr_0 = 1.1300e-04
Loss = 1.7275e-05, PNorm = 52.7452, GNorm = 0.1703, lr_0 = 1.1288e-04
Loss = 1.3175e-05, PNorm = 52.7450, GNorm = 0.1144, lr_0 = 1.1276e-04
Loss = 1.3182e-05, PNorm = 52.7469, GNorm = 0.0610, lr_0 = 1.1264e-04
Loss = 1.7280e-05, PNorm = 52.7475, GNorm = 0.1885, lr_0 = 1.1252e-04
Loss = 1.8482e-05, PNorm = 52.7493, GNorm = 0.1689, lr_0 = 1.1241e-04
Loss = 1.4328e-05, PNorm = 52.7497, GNorm = 0.0618, lr_0 = 1.1229e-04
Loss = 1.7454e-05, PNorm = 52.7510, GNorm = 0.0787, lr_0 = 1.1217e-04
Loss = 1.6273e-05, PNorm = 52.7517, GNorm = 0.0655, lr_0 = 1.1206e-04
Loss = 1.1059e-05, PNorm = 52.7521, GNorm = 0.0913, lr_0 = 1.1194e-04
Loss = 1.4816e-05, PNorm = 52.7529, GNorm = 0.0736, lr_0 = 1.1182e-04
Loss = 1.1435e-05, PNorm = 52.7536, GNorm = 0.0527, lr_0 = 1.1170e-04
Loss = 1.4338e-05, PNorm = 52.7541, GNorm = 0.1437, lr_0 = 1.1159e-04
Loss = 1.7549e-05, PNorm = 52.7549, GNorm = 0.0809, lr_0 = 1.1147e-04
Loss = 1.6345e-05, PNorm = 52.7555, GNorm = 0.1812, lr_0 = 1.1136e-04
Loss = 9.6461e-06, PNorm = 52.7557, GNorm = 0.0673, lr_0 = 1.1134e-04
Validation rmse logD = 0.607059
Validation R2 logD = 0.742265
Validation rmse logP = 0.458538
Validation R2 logP = 0.942121
Epoch 95
Train function
Loss = 1.5856e-05, PNorm = 52.7569, GNorm = 0.1213, lr_0 = 1.1123e-04
Loss = 1.0256e-05, PNorm = 52.7571, GNorm = 0.0760, lr_0 = 1.1111e-04
Loss = 9.3913e-06, PNorm = 52.7575, GNorm = 0.0868, lr_0 = 1.1100e-04
Loss = 1.1692e-05, PNorm = 52.7572, GNorm = 0.0995, lr_0 = 1.1088e-04
Loss = 1.2188e-05, PNorm = 52.7574, GNorm = 0.0577, lr_0 = 1.1076e-04
Loss = 1.1116e-05, PNorm = 52.7583, GNorm = 0.1366, lr_0 = 1.1065e-04
Loss = 1.0930e-05, PNorm = 52.7582, GNorm = 0.0975, lr_0 = 1.1053e-04
Loss = 1.3195e-05, PNorm = 52.7588, GNorm = 0.0979, lr_0 = 1.1042e-04
Loss = 1.1030e-05, PNorm = 52.7588, GNorm = 0.0742, lr_0 = 1.1030e-04
Loss = 1.2249e-05, PNorm = 52.7588, GNorm = 0.0625, lr_0 = 1.1019e-04
Loss = 1.2126e-05, PNorm = 52.7596, GNorm = 0.0858, lr_0 = 1.1007e-04
Loss = 2.1729e-05, PNorm = 52.7606, GNorm = 0.0612, lr_0 = 1.0996e-04
Loss = 1.5289e-05, PNorm = 52.7620, GNorm = 0.1581, lr_0 = 1.0984e-04
Loss = 1.3772e-05, PNorm = 52.7622, GNorm = 0.0668, lr_0 = 1.0973e-04
Loss = 1.4433e-05, PNorm = 52.7620, GNorm = 0.1008, lr_0 = 1.0961e-04
Loss = 1.4009e-05, PNorm = 52.7629, GNorm = 0.0950, lr_0 = 1.0950e-04
Loss = 1.5193e-05, PNorm = 52.7641, GNorm = 0.1094, lr_0 = 1.0938e-04
Loss = 1.3231e-05, PNorm = 52.7650, GNorm = 0.1281, lr_0 = 1.0927e-04
Loss = 1.6999e-05, PNorm = 52.7653, GNorm = 0.1003, lr_0 = 1.0916e-04
Loss = 1.3947e-05, PNorm = 52.7663, GNorm = 0.0778, lr_0 = 1.0904e-04
Loss = 1.7532e-05, PNorm = 52.7681, GNorm = 0.1058, lr_0 = 1.0893e-04
Loss = 1.6240e-05, PNorm = 52.7695, GNorm = 0.1127, lr_0 = 1.0882e-04
Validation rmse logD = 0.609754
Validation R2 logD = 0.739971
Validation rmse logP = 0.458178
Validation R2 logP = 0.942211
Epoch 96
Train function
Loss = 1.2178e-05, PNorm = 52.7694, GNorm = 0.0750, lr_0 = 1.0870e-04
Loss = 1.1969e-05, PNorm = 52.7694, GNorm = 0.0937, lr_0 = 1.0859e-04
Loss = 1.0654e-05, PNorm = 52.7699, GNorm = 0.0564, lr_0 = 1.0847e-04
Loss = 1.2186e-05, PNorm = 52.7709, GNorm = 0.1814, lr_0 = 1.0836e-04
Loss = 1.6226e-05, PNorm = 52.7717, GNorm = 0.0969, lr_0 = 1.0825e-04
Loss = 1.9060e-05, PNorm = 52.7729, GNorm = 0.0635, lr_0 = 1.0814e-04
Loss = 1.3168e-05, PNorm = 52.7735, GNorm = 0.1165, lr_0 = 1.0802e-04
Loss = 1.1842e-05, PNorm = 52.7743, GNorm = 0.0645, lr_0 = 1.0791e-04
Loss = 1.2945e-05, PNorm = 52.7753, GNorm = 0.0636, lr_0 = 1.0780e-04
Loss = 1.0935e-05, PNorm = 52.7760, GNorm = 0.1429, lr_0 = 1.0768e-04
Loss = 1.3973e-05, PNorm = 52.7762, GNorm = 0.1425, lr_0 = 1.0757e-04
Loss = 1.7924e-05, PNorm = 52.7762, GNorm = 0.0619, lr_0 = 1.0746e-04
Loss = 1.4109e-05, PNorm = 52.7774, GNorm = 0.1104, lr_0 = 1.0735e-04
Loss = 1.2025e-05, PNorm = 52.7781, GNorm = 0.0555, lr_0 = 1.0724e-04
Loss = 1.1629e-05, PNorm = 52.7783, GNorm = 0.0912, lr_0 = 1.0712e-04
Loss = 1.8426e-05, PNorm = 52.7786, GNorm = 0.1234, lr_0 = 1.0701e-04
Loss = 1.9309e-05, PNorm = 52.7792, GNorm = 0.1305, lr_0 = 1.0690e-04
Loss = 1.3389e-05, PNorm = 52.7800, GNorm = 0.0817, lr_0 = 1.0679e-04
Loss = 1.4258e-05, PNorm = 52.7803, GNorm = 0.0901, lr_0 = 1.0668e-04
Loss = 1.4550e-05, PNorm = 52.7810, GNorm = 0.0889, lr_0 = 1.0657e-04
Loss = 1.6275e-05, PNorm = 52.7809, GNorm = 0.0843, lr_0 = 1.0645e-04
Loss = 1.8520e-05, PNorm = 52.7827, GNorm = 0.0954, lr_0 = 1.0634e-04
Loss = 1.2533e-05, PNorm = 52.7843, GNorm = 0.0754, lr_0 = 1.0623e-04
Validation rmse logD = 0.607416
Validation R2 logD = 0.741962
Validation rmse logP = 0.458700
Validation R2 logP = 0.942080
Epoch 97
Train function
Loss = 1.3634e-05, PNorm = 52.7853, GNorm = 0.0534, lr_0 = 1.0611e-04
Loss = 1.3433e-05, PNorm = 52.7849, GNorm = 0.1282, lr_0 = 1.0600e-04
Loss = 1.3458e-05, PNorm = 52.7848, GNorm = 0.1263, lr_0 = 1.0589e-04
Loss = 1.1830e-05, PNorm = 52.7853, GNorm = 0.1128, lr_0 = 1.0578e-04
Loss = 1.1581e-05, PNorm = 52.7852, GNorm = 0.0995, lr_0 = 1.0567e-04
Loss = 1.0783e-05, PNorm = 52.7855, GNorm = 0.0593, lr_0 = 1.0556e-04
Loss = 1.2215e-05, PNorm = 52.7863, GNorm = 0.0628, lr_0 = 1.0545e-04
Loss = 1.1053e-05, PNorm = 52.7866, GNorm = 0.1102, lr_0 = 1.0534e-04
Loss = 1.1843e-05, PNorm = 52.7874, GNorm = 0.0672, lr_0 = 1.0523e-04
Loss = 1.0333e-05, PNorm = 52.7879, GNorm = 0.0858, lr_0 = 1.0512e-04
Loss = 1.6225e-05, PNorm = 52.7879, GNorm = 0.0820, lr_0 = 1.0501e-04
Loss = 1.1632e-05, PNorm = 52.7888, GNorm = 0.1076, lr_0 = 1.0490e-04
Loss = 9.8001e-06, PNorm = 52.7887, GNorm = 0.0738, lr_0 = 1.0479e-04
Loss = 1.1605e-05, PNorm = 52.7892, GNorm = 0.0708, lr_0 = 1.0468e-04
Loss = 1.3875e-05, PNorm = 52.7902, GNorm = 0.0962, lr_0 = 1.0457e-04
Loss = 1.8069e-05, PNorm = 52.7915, GNorm = 0.1705, lr_0 = 1.0446e-04
Loss = 1.7384e-05, PNorm = 52.7921, GNorm = 0.1173, lr_0 = 1.0435e-04
Loss = 1.3030e-05, PNorm = 52.7924, GNorm = 0.0429, lr_0 = 1.0424e-04
Loss = 2.0199e-05, PNorm = 52.7933, GNorm = 0.1692, lr_0 = 1.0413e-04
Loss = 1.7728e-05, PNorm = 52.7942, GNorm = 0.1129, lr_0 = 1.0403e-04
Loss = 2.4411e-05, PNorm = 52.7945, GNorm = 0.1033, lr_0 = 1.0392e-04
Loss = 2.6657e-05, PNorm = 52.7956, GNorm = 0.1218, lr_0 = 1.0381e-04
Validation rmse logD = 0.606175
Validation R2 logD = 0.743015
Validation rmse logP = 0.458770
Validation R2 logP = 0.942062
Epoch 98
Train function
Loss = 1.7080e-05, PNorm = 52.7962, GNorm = 0.1437, lr_0 = 1.0370e-04
Loss = 1.2535e-05, PNorm = 52.7968, GNorm = 0.0615, lr_0 = 1.0359e-04
Loss = 1.3995e-05, PNorm = 52.7972, GNorm = 0.0570, lr_0 = 1.0348e-04
Loss = 1.3991e-05, PNorm = 52.7975, GNorm = 0.0950, lr_0 = 1.0338e-04
Loss = 1.2304e-05, PNorm = 52.7986, GNorm = 0.1199, lr_0 = 1.0327e-04
Loss = 1.4630e-05, PNorm = 52.7991, GNorm = 0.2013, lr_0 = 1.0316e-04
Loss = 9.5269e-06, PNorm = 52.7999, GNorm = 0.0549, lr_0 = 1.0305e-04
Loss = 1.4450e-05, PNorm = 52.8006, GNorm = 0.0577, lr_0 = 1.0295e-04
Loss = 1.0823e-05, PNorm = 52.8014, GNorm = 0.0671, lr_0 = 1.0284e-04
Loss = 1.5685e-05, PNorm = 52.8029, GNorm = 0.0672, lr_0 = 1.0273e-04
Loss = 1.4148e-05, PNorm = 52.8039, GNorm = 0.1123, lr_0 = 1.0262e-04
Loss = 1.7334e-05, PNorm = 52.8045, GNorm = 0.1360, lr_0 = 1.0252e-04
Loss = 1.5613e-05, PNorm = 52.8046, GNorm = 0.0782, lr_0 = 1.0241e-04
Loss = 1.9356e-05, PNorm = 52.8051, GNorm = 0.0534, lr_0 = 1.0230e-04
Loss = 1.4655e-05, PNorm = 52.8044, GNorm = 0.1616, lr_0 = 1.0220e-04
Loss = 1.6481e-05, PNorm = 52.8050, GNorm = 0.1437, lr_0 = 1.0209e-04
Loss = 1.0814e-05, PNorm = 52.8057, GNorm = 0.0691, lr_0 = 1.0198e-04
Loss = 1.3637e-05, PNorm = 52.8062, GNorm = 0.0663, lr_0 = 1.0188e-04
Loss = 1.2294e-05, PNorm = 52.8064, GNorm = 0.1250, lr_0 = 1.0177e-04
Loss = 1.1431e-05, PNorm = 52.8067, GNorm = 0.0474, lr_0 = 1.0166e-04
Loss = 9.7494e-06, PNorm = 52.8076, GNorm = 0.0644, lr_0 = 1.0156e-04
Loss = 1.4225e-05, PNorm = 52.8081, GNorm = 0.0828, lr_0 = 1.0145e-04
Loss = 1.7658e-05, PNorm = 52.8095, GNorm = 0.1451, lr_0 = 1.0135e-04
Validation rmse logD = 0.610077
Validation R2 logD = 0.739696
Validation rmse logP = 0.458345
Validation R2 logP = 0.942169
Epoch 99
Train function
Loss = 1.0591e-05, PNorm = 52.8108, GNorm = 0.0686, lr_0 = 1.0123e-04
Loss = 1.2504e-05, PNorm = 52.8120, GNorm = 0.0616, lr_0 = 1.0112e-04
Loss = 1.4513e-05, PNorm = 52.8132, GNorm = 0.1066, lr_0 = 1.0102e-04
Loss = 1.1523e-05, PNorm = 52.8134, GNorm = 0.1056, lr_0 = 1.0091e-04
Loss = 1.5657e-05, PNorm = 52.8143, GNorm = 0.1087, lr_0 = 1.0081e-04
Loss = 1.9446e-05, PNorm = 52.8155, GNorm = 0.0474, lr_0 = 1.0070e-04
Loss = 1.3982e-05, PNorm = 52.8161, GNorm = 0.0661, lr_0 = 1.0060e-04
Loss = 1.9274e-05, PNorm = 52.8168, GNorm = 0.1143, lr_0 = 1.0049e-04
Loss = 1.1256e-05, PNorm = 52.8169, GNorm = 0.0940, lr_0 = 1.0039e-04
Loss = 1.2140e-05, PNorm = 52.8170, GNorm = 0.0703, lr_0 = 1.0028e-04
Loss = 1.0969e-05, PNorm = 52.8171, GNorm = 0.0791, lr_0 = 1.0018e-04
Loss = 8.2144e-06, PNorm = 52.8175, GNorm = 0.0557, lr_0 = 1.0007e-04
Loss = 1.0290e-05, PNorm = 52.8186, GNorm = 0.0922, lr_0 = 1.0000e-04
Loss = 9.0756e-06, PNorm = 52.8187, GNorm = 0.0974, lr_0 = 1.0000e-04
Loss = 1.1347e-05, PNorm = 52.8198, GNorm = 0.0630, lr_0 = 1.0000e-04
Loss = 9.2603e-06, PNorm = 52.8202, GNorm = 0.0830, lr_0 = 1.0000e-04
Loss = 1.0715e-05, PNorm = 52.8206, GNorm = 0.0672, lr_0 = 1.0000e-04
Loss = 1.0072e-05, PNorm = 52.8210, GNorm = 0.1372, lr_0 = 1.0000e-04
Loss = 1.7022e-05, PNorm = 52.8220, GNorm = 0.0677, lr_0 = 1.0000e-04
Loss = 1.3527e-05, PNorm = 52.8229, GNorm = 0.0810, lr_0 = 1.0000e-04
Loss = 1.1583e-05, PNorm = 52.8238, GNorm = 0.1325, lr_0 = 1.0000e-04
Loss = 1.3501e-05, PNorm = 52.8245, GNorm = 0.0931, lr_0 = 1.0000e-04
Validation rmse logD = 0.607030
Validation R2 logD = 0.742289
Validation rmse logP = 0.459909
Validation R2 logP = 0.941774
Model 0 best validation rmse = 0.527675 on epoch 44
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.569817
Model 0 test R2 logD = 0.794068
Model 0 test rmse logP = 0.441359
Model 0 test R2 logP = 0.944049
Ensemble test rmse  logD= 0.569817
Ensemble test R2  logD= 0.794068
Ensemble test rmse  logP= 0.441359
Ensemble test R2  logP= 0.944049
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 1.8669e-02, PNorm = 35.0899, GNorm = 3.4243, lr_0 = 1.2200e-04
Loss = 1.7509e-02, PNorm = 35.0916, GNorm = 4.8485, lr_0 = 1.4200e-04
Loss = 1.4350e-02, PNorm = 35.0958, GNorm = 2.2642, lr_0 = 1.6200e-04
Loss = 1.2368e-02, PNorm = 35.1001, GNorm = 3.6023, lr_0 = 1.8200e-04
Loss = 1.2053e-02, PNorm = 35.1054, GNorm = 2.5574, lr_0 = 2.0200e-04
Loss = 9.6621e-03, PNorm = 35.1117, GNorm = 5.8210, lr_0 = 2.2200e-04
Loss = 1.1169e-02, PNorm = 35.1180, GNorm = 4.9913, lr_0 = 2.4200e-04
Loss = 1.0278e-02, PNorm = 35.1220, GNorm = 8.7372, lr_0 = 2.6200e-04
Loss = 1.0860e-02, PNorm = 35.1301, GNorm = 4.5087, lr_0 = 2.8200e-04
Loss = 9.8303e-03, PNorm = 35.1410, GNorm = 2.6989, lr_0 = 3.0200e-04
Loss = 7.9733e-03, PNorm = 35.1511, GNorm = 5.9913, lr_0 = 3.2200e-04
Loss = 9.0732e-03, PNorm = 35.1609, GNorm = 2.2750, lr_0 = 3.4200e-04
Loss = 7.0866e-03, PNorm = 35.1721, GNorm = 1.7374, lr_0 = 3.6200e-04
Loss = 7.9604e-03, PNorm = 35.1818, GNorm = 5.3364, lr_0 = 3.8200e-04
Loss = 7.2620e-03, PNorm = 35.1931, GNorm = 3.8980, lr_0 = 4.0200e-04
Loss = 7.6543e-03, PNorm = 35.2065, GNorm = 2.4880, lr_0 = 4.2200e-04
Loss = 6.1483e-03, PNorm = 35.2178, GNorm = 2.7920, lr_0 = 4.4200e-04
Loss = 6.5079e-03, PNorm = 35.2302, GNorm = 3.3080, lr_0 = 4.6200e-04
Loss = 7.3858e-03, PNorm = 35.2445, GNorm = 1.3501, lr_0 = 4.8200e-04
Loss = 6.9670e-03, PNorm = 35.2592, GNorm = 3.2604, lr_0 = 5.0200e-04
Loss = 6.5911e-03, PNorm = 35.2772, GNorm = 4.0236, lr_0 = 5.2200e-04
Loss = 5.4037e-03, PNorm = 35.2978, GNorm = 2.4853, lr_0 = 5.4200e-04
Validation rmse logD = 0.886086
Validation R2 logD = 0.426643
Validation rmse logP = 0.878693
Validation R2 logP = 0.775995
Epoch 1
Train function
Loss = 5.9469e-03, PNorm = 35.3169, GNorm = 3.2980, lr_0 = 5.6400e-04
Loss = 6.3087e-03, PNorm = 35.3348, GNorm = 3.7745, lr_0 = 5.8400e-04
Loss = 5.4867e-03, PNorm = 35.3525, GNorm = 3.1080, lr_0 = 6.0400e-04
Loss = 5.9063e-03, PNorm = 35.3690, GNorm = 2.2398, lr_0 = 6.2400e-04
Loss = 5.3560e-03, PNorm = 35.3918, GNorm = 2.1611, lr_0 = 6.4400e-04
Loss = 5.5200e-03, PNorm = 35.4128, GNorm = 3.4236, lr_0 = 6.6400e-04
Loss = 7.4679e-03, PNorm = 35.4376, GNorm = 2.6496, lr_0 = 6.8400e-04
Loss = 6.6477e-03, PNorm = 35.4655, GNorm = 2.6047, lr_0 = 7.0400e-04
Loss = 5.9262e-03, PNorm = 35.4954, GNorm = 2.2639, lr_0 = 7.2400e-04
Loss = 5.2626e-03, PNorm = 35.5180, GNorm = 1.4985, lr_0 = 7.4400e-04
Loss = 4.6970e-03, PNorm = 35.5457, GNorm = 2.2243, lr_0 = 7.6400e-04
Loss = 4.9441e-03, PNorm = 35.5709, GNorm = 1.5730, lr_0 = 7.8400e-04
Loss = 4.3067e-03, PNorm = 35.5975, GNorm = 2.0186, lr_0 = 8.0400e-04
Loss = 5.2884e-03, PNorm = 35.6287, GNorm = 1.3627, lr_0 = 8.2400e-04
Loss = 4.2265e-03, PNorm = 35.6517, GNorm = 2.8444, lr_0 = 8.4400e-04
Loss = 5.8791e-03, PNorm = 35.6676, GNorm = 4.4479, lr_0 = 8.6400e-04
Loss = 5.9432e-03, PNorm = 35.6939, GNorm = 2.1260, lr_0 = 8.8400e-04
Loss = 5.5560e-03, PNorm = 35.7252, GNorm = 1.7287, lr_0 = 9.0400e-04
Loss = 4.9717e-03, PNorm = 35.7621, GNorm = 1.7430, lr_0 = 9.2400e-04
Loss = 4.3483e-03, PNorm = 35.7965, GNorm = 2.1965, lr_0 = 9.4400e-04
Loss = 4.7684e-03, PNorm = 35.8358, GNorm = 1.1050, lr_0 = 9.6400e-04
Loss = 4.1529e-03, PNorm = 35.8639, GNorm = 3.0855, lr_0 = 9.8400e-04
Loss = 5.7482e-03, PNorm = 35.8978, GNorm = 3.5366, lr_0 = 9.9979e-04
Loss = 6.8379e-03, PNorm = 35.9015, GNorm = 2.2283, lr_0 = 9.9969e-04
Validation rmse logD = 0.804150
Validation R2 logD = 0.527776
Validation rmse logP = 0.798688
Validation R2 logP = 0.814929
Epoch 2
Train function
Loss = 4.0479e-03, PNorm = 35.9328, GNorm = 2.4430, lr_0 = 9.9864e-04
Loss = 4.6538e-03, PNorm = 35.9723, GNorm = 2.4228, lr_0 = 9.9760e-04
Loss = 5.0896e-03, PNorm = 36.0053, GNorm = 1.7841, lr_0 = 9.9656e-04
Loss = 3.9307e-03, PNorm = 36.0461, GNorm = 3.1120, lr_0 = 9.9552e-04
Loss = 3.9181e-03, PNorm = 36.0712, GNorm = 1.1963, lr_0 = 9.9448e-04
Loss = 4.5032e-03, PNorm = 36.1019, GNorm = 1.9780, lr_0 = 9.9344e-04
Loss = 3.9818e-03, PNorm = 36.1323, GNorm = 1.1290, lr_0 = 9.9241e-04
Loss = 4.4527e-03, PNorm = 36.1683, GNorm = 1.0106, lr_0 = 9.9137e-04
Loss = 5.2639e-03, PNorm = 36.2028, GNorm = 2.9577, lr_0 = 9.9034e-04
Loss = 4.2370e-03, PNorm = 36.2345, GNorm = 1.2261, lr_0 = 9.8930e-04
Loss = 4.4082e-03, PNorm = 36.2636, GNorm = 1.1754, lr_0 = 9.8827e-04
Loss = 4.2074e-03, PNorm = 36.2874, GNorm = 2.7010, lr_0 = 9.8724e-04
Loss = 3.9436e-03, PNorm = 36.3250, GNorm = 1.5188, lr_0 = 9.8621e-04
Loss = 4.5019e-03, PNorm = 36.3542, GNorm = 1.0640, lr_0 = 9.8518e-04
Loss = 3.4314e-03, PNorm = 36.3887, GNorm = 2.8797, lr_0 = 9.8415e-04
Loss = 3.7353e-03, PNorm = 36.4121, GNorm = 1.6185, lr_0 = 9.8312e-04
Loss = 4.0518e-03, PNorm = 36.4365, GNorm = 1.8041, lr_0 = 9.8210e-04
Loss = 4.6404e-03, PNorm = 36.4668, GNorm = 1.5484, lr_0 = 9.8107e-04
Loss = 3.7229e-03, PNorm = 36.4977, GNorm = 0.6332, lr_0 = 9.8005e-04
Loss = 2.8514e-03, PNorm = 36.5266, GNorm = 1.4178, lr_0 = 9.7902e-04
Loss = 3.8234e-03, PNorm = 36.5586, GNorm = 1.5203, lr_0 = 9.7800e-04
Loss = 4.2260e-03, PNorm = 36.5886, GNorm = 1.3696, lr_0 = 9.7698e-04
Validation rmse logD = 0.783231
Validation R2 logD = 0.552025
Validation rmse logP = 0.613872
Validation R2 logP = 0.890670
Epoch 3
Train function
Loss = 2.9979e-03, PNorm = 36.6203, GNorm = 1.2830, lr_0 = 9.7596e-04
Loss = 3.3850e-03, PNorm = 36.6628, GNorm = 1.3394, lr_0 = 9.7494e-04
Loss = 3.3566e-03, PNorm = 36.6976, GNorm = 1.7533, lr_0 = 9.7393e-04
Loss = 3.1830e-03, PNorm = 36.7249, GNorm = 1.5665, lr_0 = 9.7291e-04
Loss = 3.1340e-03, PNorm = 36.7576, GNorm = 1.7614, lr_0 = 9.7189e-04
Loss = 3.4473e-03, PNorm = 36.7835, GNorm = 1.3557, lr_0 = 9.7088e-04
Loss = 3.6522e-03, PNorm = 36.8177, GNorm = 2.9294, lr_0 = 9.6987e-04
Loss = 3.1732e-03, PNorm = 36.8536, GNorm = 3.2408, lr_0 = 9.6885e-04
Loss = 2.9748e-03, PNorm = 36.8876, GNorm = 0.9134, lr_0 = 9.6784e-04
Loss = 3.1258e-03, PNorm = 36.9194, GNorm = 1.5862, lr_0 = 9.6683e-04
Loss = 3.3207e-03, PNorm = 36.9602, GNorm = 1.4803, lr_0 = 9.6582e-04
Loss = 3.0394e-03, PNorm = 36.9913, GNorm = 1.0974, lr_0 = 9.6482e-04
Loss = 2.8341e-03, PNorm = 37.0193, GNorm = 0.7338, lr_0 = 9.6381e-04
Loss = 3.1434e-03, PNorm = 37.0479, GNorm = 2.0396, lr_0 = 9.6280e-04
Loss = 3.1784e-03, PNorm = 37.0728, GNorm = 2.5540, lr_0 = 9.6180e-04
Loss = 4.1529e-03, PNorm = 37.1066, GNorm = 2.0239, lr_0 = 9.6079e-04
Loss = 3.2595e-03, PNorm = 37.1485, GNorm = 1.4129, lr_0 = 9.5979e-04
Loss = 3.0152e-03, PNorm = 37.1781, GNorm = 0.9078, lr_0 = 9.5879e-04
Loss = 3.7713e-03, PNorm = 37.2089, GNorm = 2.3559, lr_0 = 9.5779e-04
Loss = 3.8309e-03, PNorm = 37.2277, GNorm = 1.6261, lr_0 = 9.5679e-04
Loss = 3.6501e-03, PNorm = 37.2502, GNorm = 1.8526, lr_0 = 9.5579e-04
Loss = 3.8857e-03, PNorm = 37.2802, GNorm = 2.0368, lr_0 = 9.5479e-04
Loss = 3.1161e-03, PNorm = 37.3009, GNorm = 1.2048, lr_0 = 9.5380e-04
Validation rmse logD = 0.744192
Validation R2 logD = 0.595570
Validation rmse logP = 0.593570
Validation R2 logP = 0.897782
Epoch 4
Train function
Loss = 2.9666e-03, PNorm = 37.3284, GNorm = 1.2617, lr_0 = 9.5270e-04
Loss = 2.7007e-03, PNorm = 37.3626, GNorm = 1.1183, lr_0 = 9.5171e-04
Loss = 3.2456e-03, PNorm = 37.3866, GNorm = 1.6630, lr_0 = 9.5071e-04
Loss = 2.8856e-03, PNorm = 37.4170, GNorm = 0.7450, lr_0 = 9.4972e-04
Loss = 2.8272e-03, PNorm = 37.4313, GNorm = 1.4566, lr_0 = 9.4873e-04
Loss = 2.5976e-03, PNorm = 37.4599, GNorm = 1.2908, lr_0 = 9.4774e-04
Loss = 2.9137e-03, PNorm = 37.4898, GNorm = 2.9049, lr_0 = 9.4675e-04
Loss = 3.1005e-03, PNorm = 37.5077, GNorm = 0.9550, lr_0 = 9.4576e-04
Loss = 2.8146e-03, PNorm = 37.5326, GNorm = 1.2040, lr_0 = 9.4478e-04
Loss = 2.5633e-03, PNorm = 37.5692, GNorm = 1.5219, lr_0 = 9.4379e-04
Loss = 3.4376e-03, PNorm = 37.6026, GNorm = 1.4448, lr_0 = 9.4280e-04
Loss = 2.7511e-03, PNorm = 37.6363, GNorm = 1.5621, lr_0 = 9.4182e-04
Loss = 3.0977e-03, PNorm = 37.6621, GNorm = 0.9066, lr_0 = 9.4084e-04
Loss = 2.3860e-03, PNorm = 37.6876, GNorm = 1.0017, lr_0 = 9.3986e-04
Loss = 2.9967e-03, PNorm = 37.7209, GNorm = 1.5010, lr_0 = 9.3887e-04
Loss = 2.7495e-03, PNorm = 37.7500, GNorm = 0.9888, lr_0 = 9.3789e-04
Loss = 2.6212e-03, PNorm = 37.7759, GNorm = 1.0679, lr_0 = 9.3692e-04
Loss = 2.5888e-03, PNorm = 37.8020, GNorm = 1.4432, lr_0 = 9.3594e-04
Loss = 2.4064e-03, PNorm = 37.8160, GNorm = 1.4665, lr_0 = 9.3496e-04
Loss = 2.5536e-03, PNorm = 37.8367, GNorm = 0.9396, lr_0 = 9.3399e-04
Loss = 3.1031e-03, PNorm = 37.8661, GNorm = 1.3248, lr_0 = 9.3301e-04
Loss = 2.8198e-03, PNorm = 37.8937, GNorm = 0.8642, lr_0 = 9.3204e-04
Validation rmse logD = 0.749434
Validation R2 logD = 0.589852
Validation rmse logP = 0.606437
Validation R2 logP = 0.893302
Epoch 5
Train function
Loss = 3.1662e-03, PNorm = 37.9267, GNorm = 1.2203, lr_0 = 9.3106e-04
Loss = 2.5906e-03, PNorm = 37.9525, GNorm = 0.9580, lr_0 = 9.3009e-04
Loss = 2.2388e-03, PNorm = 37.9708, GNorm = 0.9211, lr_0 = 9.2912e-04
Loss = 2.2924e-03, PNorm = 37.9937, GNorm = 1.0199, lr_0 = 9.2815e-04
Loss = 2.6910e-03, PNorm = 38.0204, GNorm = 1.7396, lr_0 = 9.2718e-04
Loss = 2.4113e-03, PNorm = 38.0518, GNorm = 0.8143, lr_0 = 9.2622e-04
Loss = 2.4720e-03, PNorm = 38.0778, GNorm = 0.9221, lr_0 = 9.2525e-04
Loss = 2.7898e-03, PNorm = 38.0992, GNorm = 2.3876, lr_0 = 9.2428e-04
Loss = 2.3597e-03, PNorm = 38.1326, GNorm = 1.2336, lr_0 = 9.2332e-04
Loss = 2.4236e-03, PNorm = 38.1580, GNorm = 1.1849, lr_0 = 9.2235e-04
Loss = 2.4384e-03, PNorm = 38.1928, GNorm = 1.5540, lr_0 = 9.2139e-04
Loss = 2.5712e-03, PNorm = 38.2146, GNorm = 1.8727, lr_0 = 9.2043e-04
Loss = 2.8415e-03, PNorm = 38.2430, GNorm = 1.5894, lr_0 = 9.1947e-04
Loss = 2.1629e-03, PNorm = 38.2732, GNorm = 1.2990, lr_0 = 9.1851e-04
Loss = 2.6324e-03, PNorm = 38.3025, GNorm = 1.6911, lr_0 = 9.1755e-04
Loss = 2.5328e-03, PNorm = 38.3383, GNorm = 1.1087, lr_0 = 9.1659e-04
Loss = 2.8823e-03, PNorm = 38.3687, GNorm = 1.6785, lr_0 = 9.1564e-04
Loss = 2.6626e-03, PNorm = 38.4040, GNorm = 1.0253, lr_0 = 9.1468e-04
Loss = 1.9367e-03, PNorm = 38.4351, GNorm = 0.5055, lr_0 = 9.1373e-04
Loss = 2.3650e-03, PNorm = 38.4526, GNorm = 0.9391, lr_0 = 9.1277e-04
Loss = 2.6604e-03, PNorm = 38.4761, GNorm = 1.4693, lr_0 = 9.1182e-04
Loss = 2.7358e-03, PNorm = 38.4999, GNorm = 1.4262, lr_0 = 9.1087e-04
Loss = 2.0299e-03, PNorm = 38.5270, GNorm = 0.7946, lr_0 = 9.0992e-04
Validation rmse logD = 0.643707
Validation R2 logD = 0.697413
Validation rmse logP = 0.533621
Validation R2 logP = 0.917387
Epoch 6
Train function
Loss = 1.7220e-03, PNorm = 38.5576, GNorm = 0.7412, lr_0 = 9.0887e-04
Loss = 1.9723e-03, PNorm = 38.5794, GNorm = 1.0819, lr_0 = 9.0792e-04
Loss = 2.1689e-03, PNorm = 38.6053, GNorm = 1.4482, lr_0 = 9.0698e-04
Loss = 2.3285e-03, PNorm = 38.6384, GNorm = 1.8499, lr_0 = 9.0603e-04
Loss = 2.4705e-03, PNorm = 38.6697, GNorm = 2.1298, lr_0 = 9.0508e-04
Loss = 1.8251e-03, PNorm = 38.6982, GNorm = 1.2173, lr_0 = 9.0414e-04
Loss = 2.1164e-03, PNorm = 38.7326, GNorm = 0.6605, lr_0 = 9.0320e-04
Loss = 2.1876e-03, PNorm = 38.7641, GNorm = 1.4718, lr_0 = 9.0225e-04
Loss = 1.8857e-03, PNorm = 38.7838, GNorm = 0.7528, lr_0 = 9.0131e-04
Loss = 2.2752e-03, PNorm = 38.8128, GNorm = 1.0584, lr_0 = 9.0037e-04
Loss = 2.0739e-03, PNorm = 38.8301, GNorm = 1.2615, lr_0 = 8.9943e-04
Loss = 2.1961e-03, PNorm = 38.8461, GNorm = 1.4014, lr_0 = 8.9849e-04
Loss = 2.3265e-03, PNorm = 38.8751, GNorm = 0.9133, lr_0 = 8.9756e-04
Loss = 2.3586e-03, PNorm = 38.9013, GNorm = 1.3023, lr_0 = 8.9662e-04
Loss = 2.0045e-03, PNorm = 38.9176, GNorm = 0.7902, lr_0 = 8.9568e-04
Loss = 2.3132e-03, PNorm = 38.9381, GNorm = 1.2388, lr_0 = 8.9475e-04
Loss = 2.4455e-03, PNorm = 38.9609, GNorm = 1.0665, lr_0 = 8.9381e-04
Loss = 2.0568e-03, PNorm = 38.9815, GNorm = 0.6293, lr_0 = 8.9288e-04
Loss = 2.3525e-03, PNorm = 39.0014, GNorm = 0.8042, lr_0 = 8.9195e-04
Loss = 2.5873e-03, PNorm = 39.0281, GNorm = 1.5845, lr_0 = 8.9102e-04
Loss = 2.5294e-03, PNorm = 39.0647, GNorm = 1.5737, lr_0 = 8.9009e-04
Loss = 2.0255e-03, PNorm = 39.0962, GNorm = 1.6803, lr_0 = 8.8916e-04
Validation rmse logD = 0.630747
Validation R2 logD = 0.709475
Validation rmse logP = 0.517915
Validation R2 logP = 0.922178
Epoch 7
Train function
Loss = 1.3997e-03, PNorm = 39.1210, GNorm = 0.8853, lr_0 = 8.8823e-04
Loss = 2.0052e-03, PNorm = 39.1466, GNorm = 1.5306, lr_0 = 8.8730e-04
Loss = 1.7829e-03, PNorm = 39.1713, GNorm = 1.1273, lr_0 = 8.8638e-04
Loss = 2.2425e-03, PNorm = 39.2019, GNorm = 1.3184, lr_0 = 8.8545e-04
Loss = 1.8307e-03, PNorm = 39.2278, GNorm = 1.0908, lr_0 = 8.8453e-04
Loss = 1.7090e-03, PNorm = 39.2498, GNorm = 0.4866, lr_0 = 8.8361e-04
Loss = 1.9652e-03, PNorm = 39.2690, GNorm = 1.0668, lr_0 = 8.8268e-04
Loss = 1.6713e-03, PNorm = 39.2867, GNorm = 0.5993, lr_0 = 8.8176e-04
Loss = 1.8727e-03, PNorm = 39.3116, GNorm = 1.4191, lr_0 = 8.8084e-04
Loss = 1.8283e-03, PNorm = 39.3358, GNorm = 0.7503, lr_0 = 8.7992e-04
Loss = 1.5640e-03, PNorm = 39.3477, GNorm = 0.5568, lr_0 = 8.7900e-04
Loss = 1.7886e-03, PNorm = 39.3648, GNorm = 1.0123, lr_0 = 8.7809e-04
Loss = 2.0708e-03, PNorm = 39.3887, GNorm = 3.1168, lr_0 = 8.7717e-04
Loss = 2.7169e-03, PNorm = 39.4198, GNorm = 1.8430, lr_0 = 8.7625e-04
Loss = 2.7764e-03, PNorm = 39.4654, GNorm = 2.0327, lr_0 = 8.7534e-04
Loss = 2.3626e-03, PNorm = 39.5017, GNorm = 0.7971, lr_0 = 8.7443e-04
Loss = 1.8020e-03, PNorm = 39.5283, GNorm = 1.3159, lr_0 = 8.7351e-04
Loss = 2.1646e-03, PNorm = 39.5519, GNorm = 0.9166, lr_0 = 8.7260e-04
Loss = 1.8830e-03, PNorm = 39.5773, GNorm = 1.2385, lr_0 = 8.7169e-04
Loss = 2.1805e-03, PNorm = 39.5967, GNorm = 1.6603, lr_0 = 8.7078e-04
Loss = 2.4646e-03, PNorm = 39.6251, GNorm = 1.6736, lr_0 = 8.6987e-04
Loss = 2.3308e-03, PNorm = 39.6625, GNorm = 0.6712, lr_0 = 8.6896e-04
Loss = 2.3827e-03, PNorm = 39.6921, GNorm = 0.8400, lr_0 = 8.6806e-04
Validation rmse logD = 0.645388
Validation R2 logD = 0.695831
Validation rmse logP = 0.534340
Validation R2 logP = 0.917164
Epoch 8
Train function
Loss = 1.8270e-03, PNorm = 39.7181, GNorm = 1.2742, lr_0 = 8.6706e-04
Loss = 1.6054e-03, PNorm = 39.7422, GNorm = 1.0318, lr_0 = 8.6616e-04
Loss = 1.2071e-03, PNorm = 39.7652, GNorm = 0.8587, lr_0 = 8.6525e-04
Loss = 1.2627e-03, PNorm = 39.7822, GNorm = 0.6756, lr_0 = 8.6435e-04
Loss = 1.6280e-03, PNorm = 39.8057, GNorm = 1.0825, lr_0 = 8.6345e-04
Loss = 1.5421e-03, PNorm = 39.8296, GNorm = 1.4745, lr_0 = 8.6255e-04
Loss = 1.7611e-03, PNorm = 39.8522, GNorm = 0.5480, lr_0 = 8.6165e-04
Loss = 1.7318e-03, PNorm = 39.8748, GNorm = 0.6252, lr_0 = 8.6075e-04
Loss = 1.7291e-03, PNorm = 39.8920, GNorm = 1.1823, lr_0 = 8.5985e-04
Loss = 1.6189e-03, PNorm = 39.9139, GNorm = 1.1597, lr_0 = 8.5895e-04
Loss = 1.6147e-03, PNorm = 39.9373, GNorm = 0.6208, lr_0 = 8.5805e-04
Loss = 1.8186e-03, PNorm = 39.9582, GNorm = 0.7053, lr_0 = 8.5716e-04
Loss = 1.5709e-03, PNorm = 39.9843, GNorm = 1.0268, lr_0 = 8.5626e-04
Loss = 1.6051e-03, PNorm = 40.0118, GNorm = 1.1656, lr_0 = 8.5537e-04
Loss = 1.6994e-03, PNorm = 40.0348, GNorm = 1.1061, lr_0 = 8.5448e-04
Loss = 1.6965e-03, PNorm = 40.0593, GNorm = 0.8383, lr_0 = 8.5359e-04
Loss = 2.0556e-03, PNorm = 40.0848, GNorm = 1.1667, lr_0 = 8.5269e-04
Loss = 1.7703e-03, PNorm = 40.1105, GNorm = 1.2437, lr_0 = 8.5180e-04
Loss = 1.9747e-03, PNorm = 40.1363, GNorm = 1.3593, lr_0 = 8.5092e-04
Loss = 2.2747e-03, PNorm = 40.1686, GNorm = 2.4133, lr_0 = 8.5003e-04
Loss = 1.9866e-03, PNorm = 40.1959, GNorm = 2.2092, lr_0 = 8.4914e-04
Loss = 2.0657e-03, PNorm = 40.2213, GNorm = 0.7414, lr_0 = 8.4825e-04
Validation rmse logD = 0.640848
Validation R2 logD = 0.700095
Validation rmse logP = 0.525225
Validation R2 logP = 0.919966
Epoch 9
Train function
Loss = 1.3146e-03, PNorm = 40.2439, GNorm = 0.6616, lr_0 = 8.4737e-04
Loss = 2.2010e-03, PNorm = 40.2668, GNorm = 1.1434, lr_0 = 8.4648e-04
Loss = 2.0575e-03, PNorm = 40.3032, GNorm = 1.1417, lr_0 = 8.4560e-04
Loss = 1.4927e-03, PNorm = 40.3268, GNorm = 0.9109, lr_0 = 8.4472e-04
Loss = 1.6114e-03, PNorm = 40.3491, GNorm = 0.8911, lr_0 = 8.4384e-04
Loss = 1.6845e-03, PNorm = 40.3703, GNorm = 0.9361, lr_0 = 8.4296e-04
Loss = 1.6696e-03, PNorm = 40.3884, GNorm = 0.7505, lr_0 = 8.4208e-04
Loss = 1.3114e-03, PNorm = 40.4127, GNorm = 0.9239, lr_0 = 8.4120e-04
Loss = 1.6919e-03, PNorm = 40.4423, GNorm = 1.7896, lr_0 = 8.4032e-04
Loss = 1.6064e-03, PNorm = 40.4672, GNorm = 0.5437, lr_0 = 8.3944e-04
Loss = 1.8146e-03, PNorm = 40.4854, GNorm = 0.7301, lr_0 = 8.3857e-04
Loss = 1.4276e-03, PNorm = 40.5103, GNorm = 0.5401, lr_0 = 8.3769e-04
Loss = 1.3700e-03, PNorm = 40.5351, GNorm = 0.5706, lr_0 = 8.3682e-04
Loss = 1.4574e-03, PNorm = 40.5581, GNorm = 0.8324, lr_0 = 8.3594e-04
Loss = 1.5320e-03, PNorm = 40.5791, GNorm = 0.7922, lr_0 = 8.3507e-04
Loss = 1.6570e-03, PNorm = 40.6012, GNorm = 0.6569, lr_0 = 8.3420e-04
Loss = 1.4958e-03, PNorm = 40.6229, GNorm = 2.0707, lr_0 = 8.3333e-04
Loss = 1.6325e-03, PNorm = 40.6332, GNorm = 1.0666, lr_0 = 8.3246e-04
Loss = 1.7529e-03, PNorm = 40.6525, GNorm = 0.5688, lr_0 = 8.3159e-04
Loss = 1.5690e-03, PNorm = 40.6799, GNorm = 1.7658, lr_0 = 8.3072e-04
Loss = 1.4912e-03, PNorm = 40.6984, GNorm = 0.4865, lr_0 = 8.2986e-04
Loss = 1.5558e-03, PNorm = 40.7189, GNorm = 1.7103, lr_0 = 8.2899e-04
Loss = 1.2686e-03, PNorm = 40.7453, GNorm = 0.5739, lr_0 = 8.2812e-04
Validation rmse logD = 0.593581
Validation R2 logD = 0.742704
Validation rmse logP = 0.481743
Validation R2 logP = 0.932669
Epoch 10
Train function
Loss = 1.3563e-03, PNorm = 40.7688, GNorm = 0.5674, lr_0 = 8.2717e-04
Loss = 1.3181e-03, PNorm = 40.7907, GNorm = 0.7626, lr_0 = 8.2631e-04
Loss = 1.6745e-03, PNorm = 40.8097, GNorm = 0.8959, lr_0 = 8.2545e-04
Loss = 1.2286e-03, PNorm = 40.8341, GNorm = 0.6721, lr_0 = 8.2459e-04
Loss = 1.2093e-03, PNorm = 40.8539, GNorm = 1.2870, lr_0 = 8.2373e-04
Loss = 1.3620e-03, PNorm = 40.8737, GNorm = 1.1093, lr_0 = 8.2287e-04
Loss = 1.4807e-03, PNorm = 40.8971, GNorm = 0.6917, lr_0 = 8.2201e-04
Loss = 1.3249e-03, PNorm = 40.9225, GNorm = 0.8203, lr_0 = 8.2115e-04
Loss = 1.2143e-03, PNorm = 40.9381, GNorm = 0.5820, lr_0 = 8.2029e-04
Loss = 1.5348e-03, PNorm = 40.9486, GNorm = 0.5303, lr_0 = 8.1944e-04
Loss = 1.4056e-03, PNorm = 40.9710, GNorm = 1.1314, lr_0 = 8.1858e-04
Loss = 1.1573e-03, PNorm = 40.9766, GNorm = 0.7030, lr_0 = 8.1773e-04
Loss = 1.5392e-03, PNorm = 40.9927, GNorm = 0.6348, lr_0 = 8.1687e-04
Loss = 1.2966e-03, PNorm = 41.0159, GNorm = 0.9104, lr_0 = 8.1602e-04
Loss = 1.6021e-03, PNorm = 41.0457, GNorm = 0.9915, lr_0 = 8.1517e-04
Loss = 1.5858e-03, PNorm = 41.0726, GNorm = 0.7219, lr_0 = 8.1432e-04
Loss = 1.7483e-03, PNorm = 41.0980, GNorm = 1.4111, lr_0 = 8.1347e-04
Loss = 1.3796e-03, PNorm = 41.1235, GNorm = 0.5606, lr_0 = 8.1262e-04
Loss = 1.2633e-03, PNorm = 41.1475, GNorm = 1.1000, lr_0 = 8.1177e-04
Loss = 1.9328e-03, PNorm = 41.1750, GNorm = 1.5403, lr_0 = 8.1092e-04
Loss = 1.6290e-03, PNorm = 41.1997, GNorm = 0.9188, lr_0 = 8.1008e-04
Loss = 1.7097e-03, PNorm = 41.2231, GNorm = 1.8825, lr_0 = 8.0923e-04
Loss = 1.7585e-03, PNorm = 41.2431, GNorm = 0.8643, lr_0 = 8.0839e-04
Validation rmse logD = 0.577587
Validation R2 logD = 0.756383
Validation rmse logP = 0.540155
Validation R2 logP = 0.915351
Epoch 11
Train function
Loss = 1.3559e-03, PNorm = 41.2720, GNorm = 1.1030, lr_0 = 8.0754e-04
Loss = 1.3140e-03, PNorm = 41.2937, GNorm = 1.2207, lr_0 = 8.0670e-04
Loss = 1.3934e-03, PNorm = 41.3189, GNorm = 1.1411, lr_0 = 8.0586e-04
Loss = 1.6929e-03, PNorm = 41.3446, GNorm = 1.3301, lr_0 = 8.0502e-04
Loss = 1.6508e-03, PNorm = 41.3704, GNorm = 1.0519, lr_0 = 8.0418e-04
Loss = 1.0798e-03, PNorm = 41.3959, GNorm = 0.5763, lr_0 = 8.0334e-04
Loss = 1.2393e-03, PNorm = 41.4124, GNorm = 0.9051, lr_0 = 8.0250e-04
Loss = 1.2153e-03, PNorm = 41.4345, GNorm = 0.8550, lr_0 = 8.0166e-04
Loss = 1.1696e-03, PNorm = 41.4498, GNorm = 0.7688, lr_0 = 8.0082e-04
Loss = 1.0437e-03, PNorm = 41.4730, GNorm = 1.1146, lr_0 = 7.9999e-04
Loss = 1.4194e-03, PNorm = 41.4987, GNorm = 1.0071, lr_0 = 7.9915e-04
Loss = 1.5947e-03, PNorm = 41.5202, GNorm = 1.2752, lr_0 = 7.9832e-04
Loss = 1.3149e-03, PNorm = 41.5378, GNorm = 1.4757, lr_0 = 7.9749e-04
Loss = 1.6916e-03, PNorm = 41.5560, GNorm = 1.1013, lr_0 = 7.9665e-04
Loss = 1.6063e-03, PNorm = 41.5800, GNorm = 0.8684, lr_0 = 7.9582e-04
Loss = 1.4726e-03, PNorm = 41.6074, GNorm = 1.3450, lr_0 = 7.9499e-04
Loss = 1.6272e-03, PNorm = 41.6272, GNorm = 1.0663, lr_0 = 7.9416e-04
Loss = 1.7743e-03, PNorm = 41.6513, GNorm = 0.7502, lr_0 = 7.9333e-04
Loss = 1.6833e-03, PNorm = 41.6696, GNorm = 0.6993, lr_0 = 7.9251e-04
Loss = 1.8113e-03, PNorm = 41.7042, GNorm = 1.8132, lr_0 = 7.9168e-04
Loss = 1.4835e-03, PNorm = 41.7322, GNorm = 1.5160, lr_0 = 7.9085e-04
Loss = 1.5998e-03, PNorm = 41.7633, GNorm = 1.2775, lr_0 = 7.9003e-04
Validation rmse logD = 0.619848
Validation R2 logD = 0.719428
Validation rmse logP = 0.538860
Validation R2 logP = 0.915756
Epoch 12
Train function
Loss = 1.0788e-03, PNorm = 41.7960, GNorm = 1.4155, lr_0 = 7.8912e-04
Loss = 1.1234e-03, PNorm = 41.8174, GNorm = 0.7820, lr_0 = 7.8830e-04
Loss = 1.1277e-03, PNorm = 41.8287, GNorm = 0.8752, lr_0 = 7.8747e-04
Loss = 1.3299e-03, PNorm = 41.8544, GNorm = 0.6907, lr_0 = 7.8665e-04
Loss = 1.1233e-03, PNorm = 41.8762, GNorm = 0.7012, lr_0 = 7.8583e-04
Loss = 1.4363e-03, PNorm = 41.9010, GNorm = 0.6948, lr_0 = 7.8501e-04
Loss = 1.3567e-03, PNorm = 41.9247, GNorm = 0.5666, lr_0 = 7.8419e-04
Loss = 9.7591e-04, PNorm = 41.9486, GNorm = 0.4053, lr_0 = 7.8337e-04
Loss = 1.1981e-03, PNorm = 41.9692, GNorm = 0.8841, lr_0 = 7.8255e-04
Loss = 1.3855e-03, PNorm = 41.9906, GNorm = 0.8802, lr_0 = 7.8174e-04
Loss = 1.1917e-03, PNorm = 42.0076, GNorm = 0.8379, lr_0 = 7.8092e-04
Loss = 1.2864e-03, PNorm = 42.0176, GNorm = 0.9403, lr_0 = 7.8011e-04
Loss = 1.5295e-03, PNorm = 42.0438, GNorm = 0.7967, lr_0 = 7.7929e-04
Loss = 1.0963e-03, PNorm = 42.0686, GNorm = 0.6682, lr_0 = 7.7848e-04
Loss = 1.1677e-03, PNorm = 42.0855, GNorm = 0.9057, lr_0 = 7.7767e-04
Loss = 1.0468e-03, PNorm = 42.1051, GNorm = 0.4805, lr_0 = 7.7686e-04
Loss = 1.1918e-03, PNorm = 42.1268, GNorm = 0.8664, lr_0 = 7.7604e-04
Loss = 1.3732e-03, PNorm = 42.1479, GNorm = 0.5342, lr_0 = 7.7523e-04
Loss = 1.3978e-03, PNorm = 42.1634, GNorm = 0.5869, lr_0 = 7.7443e-04
Loss = 1.2103e-03, PNorm = 42.1848, GNorm = 0.9136, lr_0 = 7.7362e-04
Loss = 1.1560e-03, PNorm = 42.2085, GNorm = 0.8359, lr_0 = 7.7281e-04
Loss = 1.1988e-03, PNorm = 42.2287, GNorm = 0.4948, lr_0 = 7.7200e-04
Loss = 1.1863e-03, PNorm = 42.2487, GNorm = 0.6771, lr_0 = 7.7120e-04
Validation rmse logD = 0.575094
Validation R2 logD = 0.758481
Validation rmse logP = 0.537104
Validation R2 logP = 0.916305
Epoch 13
Train function
Loss = 1.2164e-03, PNorm = 42.2819, GNorm = 0.8118, lr_0 = 7.7039e-04
Loss = 1.0464e-03, PNorm = 42.3013, GNorm = 0.5649, lr_0 = 7.6959e-04
Loss = 1.1021e-03, PNorm = 42.3187, GNorm = 0.9118, lr_0 = 7.6879e-04
Loss = 9.7024e-04, PNorm = 42.3387, GNorm = 0.8145, lr_0 = 7.6798e-04
Loss = 9.4960e-04, PNorm = 42.3582, GNorm = 0.6383, lr_0 = 7.6718e-04
Loss = 9.1059e-04, PNorm = 42.3697, GNorm = 0.8910, lr_0 = 7.6638e-04
Loss = 1.0364e-03, PNorm = 42.3863, GNorm = 0.5678, lr_0 = 7.6558e-04
Loss = 8.0955e-04, PNorm = 42.4015, GNorm = 0.4886, lr_0 = 7.6478e-04
Loss = 8.9980e-04, PNorm = 42.4173, GNorm = 0.5991, lr_0 = 7.6398e-04
Loss = 1.1576e-03, PNorm = 42.4332, GNorm = 0.6991, lr_0 = 7.6319e-04
Loss = 9.1360e-04, PNorm = 42.4479, GNorm = 0.6116, lr_0 = 7.6239e-04
Loss = 8.0543e-04, PNorm = 42.4567, GNorm = 0.6121, lr_0 = 7.6159e-04
Loss = 1.1482e-03, PNorm = 42.4760, GNorm = 0.4954, lr_0 = 7.6080e-04
Loss = 1.0075e-03, PNorm = 42.4948, GNorm = 0.6564, lr_0 = 7.6000e-04
Loss = 1.2496e-03, PNorm = 42.5160, GNorm = 0.8299, lr_0 = 7.5921e-04
Loss = 1.1697e-03, PNorm = 42.5342, GNorm = 0.8473, lr_0 = 7.5842e-04
Loss = 1.3277e-03, PNorm = 42.5571, GNorm = 0.6245, lr_0 = 7.5763e-04
Loss = 1.2310e-03, PNorm = 42.5737, GNorm = 0.7344, lr_0 = 7.5684e-04
Loss = 1.2267e-03, PNorm = 42.5965, GNorm = 0.8882, lr_0 = 7.5605e-04
Loss = 1.3343e-03, PNorm = 42.6190, GNorm = 1.4374, lr_0 = 7.5526e-04
Loss = 1.3396e-03, PNorm = 42.6415, GNorm = 0.7205, lr_0 = 7.5447e-04
Loss = 1.3314e-03, PNorm = 42.6684, GNorm = 0.7525, lr_0 = 7.5368e-04
Validation rmse logD = 0.578412
Validation R2 logD = 0.755686
Validation rmse logP = 0.484158
Validation R2 logP = 0.931992
Epoch 14
Train function
Loss = 9.7504e-04, PNorm = 42.6993, GNorm = 0.3587, lr_0 = 7.5282e-04
Loss = 8.9620e-04, PNorm = 42.7202, GNorm = 0.6216, lr_0 = 7.5203e-04
Loss = 7.8017e-04, PNorm = 42.7414, GNorm = 0.6111, lr_0 = 7.5125e-04
Loss = 8.5839e-04, PNorm = 42.7575, GNorm = 0.7576, lr_0 = 7.5046e-04
Loss = 9.9896e-04, PNorm = 42.7720, GNorm = 1.4928, lr_0 = 7.4968e-04
Loss = 7.8014e-04, PNorm = 42.7842, GNorm = 0.4902, lr_0 = 7.4890e-04
Loss = 1.0229e-03, PNorm = 42.8023, GNorm = 0.7736, lr_0 = 7.4811e-04
Loss = 7.9364e-04, PNorm = 42.8181, GNorm = 0.6116, lr_0 = 7.4733e-04
Loss = 8.9590e-04, PNorm = 42.8358, GNorm = 0.4934, lr_0 = 7.4655e-04
Loss = 8.3396e-04, PNorm = 42.8512, GNorm = 0.4697, lr_0 = 7.4577e-04
Loss = 9.0446e-04, PNorm = 42.8640, GNorm = 0.8389, lr_0 = 7.4500e-04
Loss = 1.0329e-03, PNorm = 42.8835, GNorm = 0.4906, lr_0 = 7.4422e-04
Loss = 1.3027e-03, PNorm = 42.9031, GNorm = 1.6973, lr_0 = 7.4344e-04
Loss = 1.1479e-03, PNorm = 42.9152, GNorm = 0.6620, lr_0 = 7.4267e-04
Loss = 1.2025e-03, PNorm = 42.9365, GNorm = 0.9473, lr_0 = 7.4189e-04
Loss = 1.2528e-03, PNorm = 42.9674, GNorm = 1.2092, lr_0 = 7.4112e-04
Loss = 1.2598e-03, PNorm = 42.9911, GNorm = 1.1269, lr_0 = 7.4034e-04
Loss = 8.9630e-04, PNorm = 43.0101, GNorm = 0.6661, lr_0 = 7.3957e-04
Loss = 1.1713e-03, PNorm = 43.0224, GNorm = 1.2888, lr_0 = 7.3880e-04
Loss = 9.9941e-04, PNorm = 43.0432, GNorm = 0.6250, lr_0 = 7.3803e-04
Loss = 1.0327e-03, PNorm = 43.0609, GNorm = 0.4246, lr_0 = 7.3726e-04
Loss = 9.1237e-04, PNorm = 43.0815, GNorm = 0.7595, lr_0 = 7.3649e-04
Loss = 7.9605e-04, PNorm = 43.0975, GNorm = 0.4790, lr_0 = 7.3572e-04
Validation rmse logD = 0.565910
Validation R2 logD = 0.766133
Validation rmse logP = 0.464793
Validation R2 logP = 0.937324
Epoch 15
Train function
Loss = 6.4093e-04, PNorm = 43.1145, GNorm = 0.5139, lr_0 = 7.3495e-04
Loss = 7.3467e-04, PNorm = 43.1205, GNorm = 0.4843, lr_0 = 7.3418e-04
Loss = 9.0541e-04, PNorm = 43.1402, GNorm = 0.7357, lr_0 = 7.3342e-04
Loss = 8.6092e-04, PNorm = 43.1625, GNorm = 0.5279, lr_0 = 7.3265e-04
Loss = 9.2990e-04, PNorm = 43.1835, GNorm = 0.8864, lr_0 = 7.3189e-04
Loss = 1.0744e-03, PNorm = 43.2011, GNorm = 0.5562, lr_0 = 7.3112e-04
Loss = 1.1390e-03, PNorm = 43.2277, GNorm = 1.4582, lr_0 = 7.3036e-04
Loss = 1.4000e-03, PNorm = 43.2512, GNorm = 1.0416, lr_0 = 7.2960e-04
Loss = 1.1455e-03, PNorm = 43.2820, GNorm = 0.8826, lr_0 = 7.2884e-04
Loss = 9.7469e-04, PNorm = 43.3021, GNorm = 1.0192, lr_0 = 7.2808e-04
Loss = 1.2945e-03, PNorm = 43.3245, GNorm = 1.0885, lr_0 = 7.2732e-04
Loss = 1.0961e-03, PNorm = 43.3514, GNorm = 0.5491, lr_0 = 7.2656e-04
Loss = 1.0763e-03, PNorm = 43.3740, GNorm = 0.6198, lr_0 = 7.2580e-04
Loss = 1.1773e-03, PNorm = 43.3977, GNorm = 1.2119, lr_0 = 7.2504e-04
Loss = 1.1714e-03, PNorm = 43.4183, GNorm = 0.9630, lr_0 = 7.2428e-04
Loss = 1.0939e-03, PNorm = 43.4440, GNorm = 0.8791, lr_0 = 7.2353e-04
Loss = 1.2291e-03, PNorm = 43.4668, GNorm = 0.8794, lr_0 = 7.2277e-04
Loss = 9.9589e-04, PNorm = 43.4889, GNorm = 0.6676, lr_0 = 7.2202e-04
Loss = 1.3514e-03, PNorm = 43.5128, GNorm = 0.8042, lr_0 = 7.2127e-04
Loss = 9.2373e-04, PNorm = 43.5312, GNorm = 0.8402, lr_0 = 7.2051e-04
Loss = 8.4739e-04, PNorm = 43.5502, GNorm = 0.4412, lr_0 = 7.1976e-04
Loss = 7.6626e-04, PNorm = 43.5653, GNorm = 0.3990, lr_0 = 7.1901e-04
Validation rmse logD = 0.583378
Validation R2 logD = 0.751473
Validation rmse logP = 0.479337
Validation R2 logP = 0.933340
Epoch 16
Train function
Loss = 7.4294e-04, PNorm = 43.5880, GNorm = 0.4176, lr_0 = 7.1818e-04
Loss = 8.1674e-04, PNorm = 43.6046, GNorm = 0.3925, lr_0 = 7.1743e-04
Loss = 7.3982e-04, PNorm = 43.6188, GNorm = 0.5146, lr_0 = 7.1669e-04
Loss = 7.5745e-04, PNorm = 43.6296, GNorm = 0.4267, lr_0 = 7.1594e-04
Loss = 6.8797e-04, PNorm = 43.6400, GNorm = 0.4247, lr_0 = 7.1519e-04
Loss = 9.7846e-04, PNorm = 43.6572, GNorm = 0.9314, lr_0 = 7.1444e-04
Loss = 6.5862e-04, PNorm = 43.6788, GNorm = 0.6040, lr_0 = 7.1370e-04
Loss = 8.7483e-04, PNorm = 43.6964, GNorm = 0.7843, lr_0 = 7.1295e-04
Loss = 1.0910e-03, PNorm = 43.7112, GNorm = 1.0120, lr_0 = 7.1221e-04
Loss = 7.3928e-04, PNorm = 43.7291, GNorm = 0.3815, lr_0 = 7.1147e-04
Loss = 9.0498e-04, PNorm = 43.7517, GNorm = 0.7687, lr_0 = 7.1072e-04
Loss = 7.8911e-04, PNorm = 43.7646, GNorm = 0.4376, lr_0 = 7.0998e-04
Loss = 8.5113e-04, PNorm = 43.7819, GNorm = 0.8828, lr_0 = 7.0924e-04
Loss = 9.6157e-04, PNorm = 43.8036, GNorm = 0.8627, lr_0 = 7.0850e-04
Loss = 7.5959e-04, PNorm = 43.8284, GNorm = 0.8391, lr_0 = 7.0776e-04
Loss = 8.5895e-04, PNorm = 43.8450, GNorm = 0.6010, lr_0 = 7.0702e-04
Loss = 1.1290e-03, PNorm = 43.8625, GNorm = 1.4224, lr_0 = 7.0628e-04
Loss = 1.0363e-03, PNorm = 43.8763, GNorm = 0.7675, lr_0 = 7.0555e-04
Loss = 1.1270e-03, PNorm = 43.8974, GNorm = 0.6002, lr_0 = 7.0481e-04
Loss = 9.5131e-04, PNorm = 43.9169, GNorm = 0.8028, lr_0 = 7.0408e-04
Loss = 7.5011e-04, PNorm = 43.9317, GNorm = 0.6317, lr_0 = 7.0334e-04
Loss = 1.0398e-03, PNorm = 43.9480, GNorm = 0.4208, lr_0 = 7.0261e-04
Loss = 8.7469e-04, PNorm = 43.9668, GNorm = 0.6585, lr_0 = 7.0187e-04
Validation rmse logD = 0.597404
Validation R2 logD = 0.739379
Validation rmse logP = 0.462088
Validation R2 logP = 0.938051
Epoch 17
Train function
Loss = 7.9885e-04, PNorm = 43.9892, GNorm = 0.4898, lr_0 = 7.0114e-04
Loss = 9.2561e-04, PNorm = 44.0060, GNorm = 0.6316, lr_0 = 7.0041e-04
Loss = 8.2488e-04, PNorm = 44.0255, GNorm = 0.4385, lr_0 = 6.9968e-04
Loss = 6.6992e-04, PNorm = 44.0454, GNorm = 0.2895, lr_0 = 6.9895e-04
Loss = 7.4520e-04, PNorm = 44.0632, GNorm = 0.6011, lr_0 = 6.9822e-04
Loss = 8.0383e-04, PNorm = 44.0844, GNorm = 0.8875, lr_0 = 6.9749e-04
Loss = 8.6689e-04, PNorm = 44.1028, GNorm = 0.5213, lr_0 = 6.9676e-04
Loss = 9.4271e-04, PNorm = 44.1182, GNorm = 1.1455, lr_0 = 6.9603e-04
Loss = 8.2070e-04, PNorm = 44.1333, GNorm = 0.5739, lr_0 = 6.9531e-04
Loss = 7.9207e-04, PNorm = 44.1532, GNorm = 0.3701, lr_0 = 6.9458e-04
Loss = 6.9317e-04, PNorm = 44.1653, GNorm = 0.5616, lr_0 = 6.9386e-04
Loss = 7.4964e-04, PNorm = 44.1783, GNorm = 0.4425, lr_0 = 6.9313e-04
Loss = 7.4919e-04, PNorm = 44.1903, GNorm = 0.5647, lr_0 = 6.9241e-04
Loss = 6.3829e-04, PNorm = 44.2046, GNorm = 0.3305, lr_0 = 6.9169e-04
Loss = 7.6508e-04, PNorm = 44.2193, GNorm = 0.5497, lr_0 = 6.9096e-04
Loss = 8.8707e-04, PNorm = 44.2332, GNorm = 0.3508, lr_0 = 6.9024e-04
Loss = 6.7621e-04, PNorm = 44.2502, GNorm = 0.4278, lr_0 = 6.8952e-04
Loss = 8.2162e-04, PNorm = 44.2689, GNorm = 0.7718, lr_0 = 6.8880e-04
Loss = 7.7863e-04, PNorm = 44.2892, GNorm = 0.4396, lr_0 = 6.8808e-04
Loss = 8.6711e-04, PNorm = 44.3065, GNorm = 0.8589, lr_0 = 6.8737e-04
Loss = 9.0859e-04, PNorm = 44.3257, GNorm = 0.4663, lr_0 = 6.8665e-04
Loss = 9.0303e-04, PNorm = 44.3460, GNorm = 0.3603, lr_0 = 6.8593e-04
Validation rmse logD = 0.604869
Validation R2 logD = 0.732825
Validation rmse logP = 0.477241
Validation R2 logP = 0.933921
Epoch 18
Train function
Loss = 5.5111e-04, PNorm = 44.3633, GNorm = 0.5556, lr_0 = 6.8514e-04
Loss = 8.0203e-04, PNorm = 44.3773, GNorm = 0.5459, lr_0 = 6.8443e-04
Loss = 6.7059e-04, PNorm = 44.3975, GNorm = 0.9054, lr_0 = 6.8372e-04
Loss = 7.3561e-04, PNorm = 44.4225, GNorm = 1.6295, lr_0 = 6.8300e-04
Loss = 6.2697e-04, PNorm = 44.4462, GNorm = 0.8853, lr_0 = 6.8229e-04
Loss = 8.9072e-04, PNorm = 44.4630, GNorm = 1.1493, lr_0 = 6.8158e-04
Loss = 7.9852e-04, PNorm = 44.4777, GNorm = 0.9102, lr_0 = 6.8087e-04
Loss = 8.3195e-04, PNorm = 44.4943, GNorm = 0.5466, lr_0 = 6.8015e-04
Loss = 6.2048e-04, PNorm = 44.5157, GNorm = 0.4542, lr_0 = 6.7944e-04
Loss = 7.2641e-04, PNorm = 44.5311, GNorm = 0.6368, lr_0 = 6.7874e-04
Loss = 7.7230e-04, PNorm = 44.5392, GNorm = 0.7962, lr_0 = 6.7803e-04
Loss = 8.0364e-04, PNorm = 44.5565, GNorm = 0.8584, lr_0 = 6.7732e-04
Loss = 7.7001e-04, PNorm = 44.5764, GNorm = 0.6210, lr_0 = 6.7661e-04
Loss = 8.6354e-04, PNorm = 44.5948, GNorm = 0.5217, lr_0 = 6.7591e-04
Loss = 6.3566e-04, PNorm = 44.6117, GNorm = 0.4803, lr_0 = 6.7520e-04
Loss = 7.6287e-04, PNorm = 44.6264, GNorm = 0.3542, lr_0 = 6.7450e-04
Loss = 9.2921e-04, PNorm = 44.6439, GNorm = 1.3114, lr_0 = 6.7379e-04
Loss = 6.9419e-04, PNorm = 44.6612, GNorm = 0.9537, lr_0 = 6.7309e-04
Loss = 7.7760e-04, PNorm = 44.6687, GNorm = 0.4664, lr_0 = 6.7239e-04
Loss = 8.7428e-04, PNorm = 44.6823, GNorm = 0.5783, lr_0 = 6.7168e-04
Loss = 9.1360e-04, PNorm = 44.7002, GNorm = 1.2783, lr_0 = 6.7098e-04
Loss = 5.4758e-04, PNorm = 44.7109, GNorm = 0.7797, lr_0 = 6.7028e-04
Loss = 7.6744e-04, PNorm = 44.7261, GNorm = 0.5477, lr_0 = 6.6958e-04
Validation rmse logD = 0.585390
Validation R2 logD = 0.749755
Validation rmse logP = 0.507338
Validation R2 logP = 0.925324
Epoch 19
Train function
Loss = 6.4705e-04, PNorm = 44.7429, GNorm = 0.9633, lr_0 = 6.6889e-04
Loss = 7.1005e-04, PNorm = 44.7662, GNorm = 0.5120, lr_0 = 6.6819e-04
Loss = 6.5236e-04, PNorm = 44.7853, GNorm = 0.4622, lr_0 = 6.6749e-04
Loss = 7.9989e-04, PNorm = 44.7998, GNorm = 1.3195, lr_0 = 6.6679e-04
Loss = 7.7553e-04, PNorm = 44.8186, GNorm = 0.9650, lr_0 = 6.6610e-04
Loss = 7.7543e-04, PNorm = 44.8354, GNorm = 0.7280, lr_0 = 6.6540e-04
Loss = 7.5981e-04, PNorm = 44.8528, GNorm = 0.3549, lr_0 = 6.6471e-04
Loss = 9.2756e-04, PNorm = 44.8675, GNorm = 1.3054, lr_0 = 6.6401e-04
Loss = 1.2835e-03, PNorm = 44.8913, GNorm = 1.6428, lr_0 = 6.6332e-04
Loss = 7.7119e-04, PNorm = 44.9162, GNorm = 0.6726, lr_0 = 6.6263e-04
Loss = 8.4075e-04, PNorm = 44.9320, GNorm = 0.4659, lr_0 = 6.6194e-04
Loss = 7.5132e-04, PNorm = 44.9441, GNorm = 0.4817, lr_0 = 6.6125e-04
Loss = 8.2956e-04, PNorm = 44.9602, GNorm = 0.7658, lr_0 = 6.6056e-04
Loss = 6.7258e-04, PNorm = 44.9808, GNorm = 0.6233, lr_0 = 6.5987e-04
Loss = 7.6987e-04, PNorm = 45.0078, GNorm = 0.3940, lr_0 = 6.5918e-04
Loss = 6.4719e-04, PNorm = 45.0268, GNorm = 0.4839, lr_0 = 6.5849e-04
Loss = 6.4290e-04, PNorm = 45.0375, GNorm = 0.6346, lr_0 = 6.5780e-04
Loss = 6.0609e-04, PNorm = 45.0484, GNorm = 0.3155, lr_0 = 6.5712e-04
Loss = 7.3465e-04, PNorm = 45.0612, GNorm = 0.9235, lr_0 = 6.5643e-04
Loss = 6.2480e-04, PNorm = 45.0729, GNorm = 0.8792, lr_0 = 6.5574e-04
Loss = 6.9972e-04, PNorm = 45.0858, GNorm = 0.3487, lr_0 = 6.5506e-04
Loss = 6.2828e-04, PNorm = 45.0981, GNorm = 0.5560, lr_0 = 6.5438e-04
Validation rmse logD = 0.565484
Validation R2 logD = 0.766485
Validation rmse logP = 0.456793
Validation R2 logP = 0.939463
Epoch 20
Train function
Loss = 5.6982e-04, PNorm = 45.1142, GNorm = 0.4146, lr_0 = 6.5363e-04
Loss = 5.5164e-04, PNorm = 45.1279, GNorm = 0.7633, lr_0 = 6.5294e-04
Loss = 5.7324e-04, PNorm = 45.1441, GNorm = 0.6731, lr_0 = 6.5226e-04
Loss = 4.8831e-04, PNorm = 45.1552, GNorm = 0.4676, lr_0 = 6.5158e-04
Loss = 6.1431e-04, PNorm = 45.1682, GNorm = 0.6212, lr_0 = 6.5090e-04
Loss = 6.9260e-04, PNorm = 45.1796, GNorm = 0.4831, lr_0 = 6.5022e-04
Loss = 6.1230e-04, PNorm = 45.1939, GNorm = 0.5617, lr_0 = 6.4954e-04
Loss = 6.5634e-04, PNorm = 45.2064, GNorm = 1.1449, lr_0 = 6.4886e-04
Loss = 5.4256e-04, PNorm = 45.2153, GNorm = 0.5337, lr_0 = 6.4819e-04
Loss = 8.5363e-04, PNorm = 45.2344, GNorm = 0.8526, lr_0 = 6.4751e-04
Loss = 8.7143e-04, PNorm = 45.2544, GNorm = 1.0950, lr_0 = 6.4684e-04
Loss = 9.1865e-04, PNorm = 45.2713, GNorm = 0.7446, lr_0 = 6.4616e-04
Loss = 1.0128e-03, PNorm = 45.2924, GNorm = 0.9339, lr_0 = 6.4549e-04
Loss = 7.5587e-04, PNorm = 45.3131, GNorm = 0.3065, lr_0 = 6.4481e-04
Loss = 7.1329e-04, PNorm = 45.3279, GNorm = 0.5263, lr_0 = 6.4414e-04
Loss = 8.4714e-04, PNorm = 45.3457, GNorm = 0.9347, lr_0 = 6.4347e-04
Loss = 6.5361e-04, PNorm = 45.3672, GNorm = 0.8975, lr_0 = 6.4280e-04
Loss = 6.0730e-04, PNorm = 45.3840, GNorm = 0.5580, lr_0 = 6.4212e-04
Loss = 5.6497e-04, PNorm = 45.3969, GNorm = 0.5624, lr_0 = 6.4145e-04
Loss = 6.2845e-04, PNorm = 45.4148, GNorm = 0.9100, lr_0 = 6.4078e-04
Loss = 6.4424e-04, PNorm = 45.4302, GNorm = 0.2577, lr_0 = 6.4012e-04
Loss = 7.1311e-04, PNorm = 45.4426, GNorm = 1.0644, lr_0 = 6.3945e-04
Loss = 6.6700e-04, PNorm = 45.4580, GNorm = 0.3589, lr_0 = 6.3878e-04
Validation rmse logD = 0.565977
Validation R2 logD = 0.766078
Validation rmse logP = 0.459306
Validation R2 logP = 0.938795
Epoch 21
Train function
Loss = 6.3691e-04, PNorm = 45.4715, GNorm = 0.5170, lr_0 = 6.3811e-04
Loss = 5.7732e-04, PNorm = 45.4861, GNorm = 0.4952, lr_0 = 6.3745e-04
Loss = 5.9500e-04, PNorm = 45.5003, GNorm = 0.7800, lr_0 = 6.3678e-04
Loss = 4.7466e-04, PNorm = 45.5122, GNorm = 0.6907, lr_0 = 6.3612e-04
Loss = 4.6948e-04, PNorm = 45.5225, GNorm = 0.4182, lr_0 = 6.3545e-04
Loss = 5.8276e-04, PNorm = 45.5335, GNorm = 0.3390, lr_0 = 6.3479e-04
Loss = 4.8949e-04, PNorm = 45.5463, GNorm = 0.2677, lr_0 = 6.3413e-04
Loss = 4.9630e-04, PNorm = 45.5567, GNorm = 0.4171, lr_0 = 6.3347e-04
Loss = 4.9822e-04, PNorm = 45.5703, GNorm = 0.4539, lr_0 = 6.3280e-04
Loss = 5.1871e-04, PNorm = 45.5835, GNorm = 0.4867, lr_0 = 6.3214e-04
Loss = 5.9644e-04, PNorm = 45.5950, GNorm = 0.7531, lr_0 = 6.3148e-04
Loss = 4.5048e-04, PNorm = 45.6081, GNorm = 0.6446, lr_0 = 6.3083e-04
Loss = 5.5135e-04, PNorm = 45.6212, GNorm = 0.4156, lr_0 = 6.3017e-04
Loss = 6.6339e-04, PNorm = 45.6352, GNorm = 0.4028, lr_0 = 6.2951e-04
Loss = 5.1064e-04, PNorm = 45.6462, GNorm = 0.3186, lr_0 = 6.2885e-04
Loss = 6.2199e-04, PNorm = 45.6608, GNorm = 0.4429, lr_0 = 6.2820e-04
Loss = 5.4580e-04, PNorm = 45.6726, GNorm = 0.4948, lr_0 = 6.2754e-04
Loss = 5.5028e-04, PNorm = 45.6858, GNorm = 0.6769, lr_0 = 6.2689e-04
Loss = 7.0878e-04, PNorm = 45.6969, GNorm = 0.5043, lr_0 = 6.2623e-04
Loss = 7.1810e-04, PNorm = 45.7098, GNorm = 1.0411, lr_0 = 6.2558e-04
Loss = 5.4889e-04, PNorm = 45.7258, GNorm = 0.4734, lr_0 = 6.2492e-04
Loss = 6.4367e-04, PNorm = 45.7476, GNorm = 0.4358, lr_0 = 6.2427e-04
Loss = 5.9158e-04, PNorm = 45.7655, GNorm = 0.4701, lr_0 = 6.2362e-04
Loss = 1.0167e-03, PNorm = 45.7670, GNorm = 0.7517, lr_0 = 6.2356e-04
Validation rmse logD = 0.555911
Validation R2 logD = 0.774325
Validation rmse logP = 0.466850
Validation R2 logP = 0.936768
Epoch 22
Train function
Loss = 4.2849e-04, PNorm = 45.7791, GNorm = 0.5876, lr_0 = 6.2290e-04
Loss = 5.3053e-04, PNorm = 45.7886, GNorm = 0.6457, lr_0 = 6.2225e-04
Loss = 4.9032e-04, PNorm = 45.8036, GNorm = 0.5747, lr_0 = 6.2161e-04
Loss = 5.0702e-04, PNorm = 45.8180, GNorm = 0.4417, lr_0 = 6.2096e-04
Loss = 5.2298e-04, PNorm = 45.8289, GNorm = 0.3973, lr_0 = 6.2031e-04
Loss = 5.8874e-04, PNorm = 45.8350, GNorm = 0.6584, lr_0 = 6.1966e-04
Loss = 4.7872e-04, PNorm = 45.8495, GNorm = 0.6058, lr_0 = 6.1901e-04
Loss = 5.8348e-04, PNorm = 45.8635, GNorm = 0.5759, lr_0 = 6.1837e-04
Loss = 5.7907e-04, PNorm = 45.8789, GNorm = 0.4117, lr_0 = 6.1772e-04
Loss = 6.3054e-04, PNorm = 45.8921, GNorm = 0.6773, lr_0 = 6.1708e-04
Loss = 6.6209e-04, PNorm = 45.9102, GNorm = 0.7497, lr_0 = 6.1643e-04
Loss = 5.7051e-04, PNorm = 45.9219, GNorm = 0.9252, lr_0 = 6.1579e-04
Loss = 5.5600e-04, PNorm = 45.9389, GNorm = 0.5026, lr_0 = 6.1515e-04
Loss = 7.6712e-04, PNorm = 45.9587, GNorm = 0.5430, lr_0 = 6.1451e-04
Loss = 7.9019e-04, PNorm = 45.9800, GNorm = 0.8102, lr_0 = 6.1386e-04
Loss = 6.0391e-04, PNorm = 45.9999, GNorm = 0.3825, lr_0 = 6.1322e-04
Loss = 6.0877e-04, PNorm = 46.0135, GNorm = 0.8503, lr_0 = 6.1258e-04
Loss = 5.6341e-04, PNorm = 46.0297, GNorm = 0.8144, lr_0 = 6.1194e-04
Loss = 5.7742e-04, PNorm = 46.0498, GNorm = 0.5611, lr_0 = 6.1131e-04
Loss = 7.4581e-04, PNorm = 46.0604, GNorm = 0.3453, lr_0 = 6.1067e-04
Loss = 6.1262e-04, PNorm = 46.0796, GNorm = 0.4935, lr_0 = 6.1003e-04
Loss = 6.1394e-04, PNorm = 46.0990, GNorm = 0.6843, lr_0 = 6.0939e-04
Validation rmse logD = 0.566761
Validation R2 logD = 0.765430
Validation rmse logP = 0.454983
Validation R2 logP = 0.939941
Epoch 23
Train function
Loss = 5.6955e-04, PNorm = 46.1138, GNorm = 0.9185, lr_0 = 6.0876e-04
Loss = 6.2902e-04, PNorm = 46.1312, GNorm = 0.3998, lr_0 = 6.0812e-04
Loss = 5.6213e-04, PNorm = 46.1450, GNorm = 0.8111, lr_0 = 6.0749e-04
Loss = 6.2517e-04, PNorm = 46.1589, GNorm = 0.4088, lr_0 = 6.0685e-04
Loss = 5.8117e-04, PNorm = 46.1783, GNorm = 0.9354, lr_0 = 6.0622e-04
Loss = 6.1467e-04, PNorm = 46.1943, GNorm = 0.6356, lr_0 = 6.0559e-04
Loss = 5.5327e-04, PNorm = 46.2102, GNorm = 0.5441, lr_0 = 6.0496e-04
Loss = 5.3743e-04, PNorm = 46.2271, GNorm = 0.4352, lr_0 = 6.0432e-04
Loss = 5.2559e-04, PNorm = 46.2441, GNorm = 0.6171, lr_0 = 6.0369e-04
Loss = 5.6182e-04, PNorm = 46.2565, GNorm = 0.6160, lr_0 = 6.0306e-04
Loss = 5.1596e-04, PNorm = 46.2676, GNorm = 0.6484, lr_0 = 6.0243e-04
Loss = 5.0934e-04, PNorm = 46.2789, GNorm = 0.6825, lr_0 = 6.0180e-04
Loss = 4.3603e-04, PNorm = 46.2865, GNorm = 0.5451, lr_0 = 6.0118e-04
Loss = 5.4392e-04, PNorm = 46.2961, GNorm = 0.4407, lr_0 = 6.0055e-04
Loss = 6.2733e-04, PNorm = 46.3081, GNorm = 0.6009, lr_0 = 5.9992e-04
Loss = 4.9818e-04, PNorm = 46.3220, GNorm = 0.5784, lr_0 = 5.9930e-04
Loss = 7.3361e-04, PNorm = 46.3376, GNorm = 0.4900, lr_0 = 5.9867e-04
Loss = 4.8306e-04, PNorm = 46.3509, GNorm = 0.3491, lr_0 = 5.9805e-04
Loss = 5.5446e-04, PNorm = 46.3631, GNorm = 0.4785, lr_0 = 5.9742e-04
Loss = 4.5082e-04, PNorm = 46.3771, GNorm = 0.3746, lr_0 = 5.9680e-04
Loss = 5.2849e-04, PNorm = 46.3911, GNorm = 0.4225, lr_0 = 5.9618e-04
Loss = 6.4877e-04, PNorm = 46.4029, GNorm = 0.6771, lr_0 = 5.9555e-04
Loss = 5.8807e-04, PNorm = 46.4198, GNorm = 0.7654, lr_0 = 5.9493e-04
Validation rmse logD = 0.570630
Validation R2 logD = 0.762216
Validation rmse logP = 0.462785
Validation R2 logP = 0.937864
Epoch 24
Train function
Loss = 4.8550e-04, PNorm = 46.4347, GNorm = 0.4461, lr_0 = 5.9425e-04
Loss = 5.8902e-04, PNorm = 46.4483, GNorm = 0.4955, lr_0 = 5.9363e-04
Loss = 4.5477e-04, PNorm = 46.4631, GNorm = 0.4765, lr_0 = 5.9301e-04
Loss = 4.4757e-04, PNorm = 46.4794, GNorm = 0.7157, lr_0 = 5.9239e-04
Loss = 4.6219e-04, PNorm = 46.4918, GNorm = 0.7068, lr_0 = 5.9177e-04
Loss = 4.5288e-04, PNorm = 46.5023, GNorm = 0.6800, lr_0 = 5.9115e-04
Loss = 4.4045e-04, PNorm = 46.5048, GNorm = 0.4460, lr_0 = 5.9054e-04
Loss = 5.6003e-04, PNorm = 46.5122, GNorm = 0.4624, lr_0 = 5.8992e-04
Loss = 5.2144e-04, PNorm = 46.5235, GNorm = 0.4897, lr_0 = 5.8931e-04
Loss = 4.4377e-04, PNorm = 46.5346, GNorm = 0.3422, lr_0 = 5.8869e-04
Loss = 4.4338e-04, PNorm = 46.5451, GNorm = 0.5778, lr_0 = 5.8808e-04
Loss = 4.9411e-04, PNorm = 46.5554, GNorm = 0.6900, lr_0 = 5.8746e-04
Loss = 4.3677e-04, PNorm = 46.5660, GNorm = 0.6162, lr_0 = 5.8685e-04
Loss = 4.2845e-04, PNorm = 46.5807, GNorm = 0.4254, lr_0 = 5.8624e-04
Loss = 4.5566e-04, PNorm = 46.5953, GNorm = 0.5103, lr_0 = 5.8562e-04
Loss = 5.4681e-04, PNorm = 46.6064, GNorm = 0.3554, lr_0 = 5.8501e-04
Loss = 5.4782e-04, PNorm = 46.6242, GNorm = 0.9310, lr_0 = 5.8440e-04
Loss = 8.5234e-04, PNorm = 46.6487, GNorm = 0.3518, lr_0 = 5.8379e-04
Loss = 6.8437e-04, PNorm = 46.6665, GNorm = 1.1104, lr_0 = 5.8318e-04
Loss = 6.0080e-04, PNorm = 46.6832, GNorm = 0.2964, lr_0 = 5.8257e-04
Loss = 6.0075e-04, PNorm = 46.6986, GNorm = 0.9989, lr_0 = 5.8197e-04
Loss = 6.6758e-04, PNorm = 46.7056, GNorm = 0.5939, lr_0 = 5.8136e-04
Validation rmse logD = 0.583469
Validation R2 logD = 0.751395
Validation rmse logP = 0.461638
Validation R2 logP = 0.938172
Epoch 25
Train function
Loss = 6.5582e-04, PNorm = 46.7214, GNorm = 0.6823, lr_0 = 5.8075e-04
Loss = 4.5702e-04, PNorm = 46.7342, GNorm = 0.4449, lr_0 = 5.8015e-04
Loss = 4.3491e-04, PNorm = 46.7441, GNorm = 0.4143, lr_0 = 5.7954e-04
Loss = 3.9264e-04, PNorm = 46.7571, GNorm = 0.5827, lr_0 = 5.7894e-04
Loss = 4.6804e-04, PNorm = 46.7661, GNorm = 0.8556, lr_0 = 5.7833e-04
Loss = 4.9916e-04, PNorm = 46.7809, GNorm = 0.5375, lr_0 = 5.7773e-04
Loss = 3.8662e-04, PNorm = 46.7909, GNorm = 0.3583, lr_0 = 5.7712e-04
Loss = 4.6138e-04, PNorm = 46.8012, GNorm = 0.8691, lr_0 = 5.7652e-04
Loss = 4.3254e-04, PNorm = 46.8187, GNorm = 0.4048, lr_0 = 5.7592e-04
Loss = 5.0187e-04, PNorm = 46.8319, GNorm = 0.2801, lr_0 = 5.7532e-04
Loss = 4.6206e-04, PNorm = 46.8421, GNorm = 0.6507, lr_0 = 5.7472e-04
Loss = 6.1721e-04, PNorm = 46.8573, GNorm = 0.6207, lr_0 = 5.7412e-04
Loss = 1.0754e-03, PNorm = 46.8700, GNorm = 1.2025, lr_0 = 5.7352e-04
Loss = 7.0080e-04, PNorm = 46.9010, GNorm = 0.5577, lr_0 = 5.7292e-04
Loss = 7.0296e-04, PNorm = 46.9317, GNorm = 0.4657, lr_0 = 5.7232e-04
Loss = 6.3231e-04, PNorm = 46.9575, GNorm = 0.4092, lr_0 = 5.7173e-04
Loss = 7.0104e-04, PNorm = 46.9766, GNorm = 0.6101, lr_0 = 5.7113e-04
Loss = 6.8283e-04, PNorm = 46.9999, GNorm = 0.8500, lr_0 = 5.7053e-04
Loss = 7.7226e-04, PNorm = 47.0166, GNorm = 0.6803, lr_0 = 5.6994e-04
Loss = 4.7254e-04, PNorm = 47.0325, GNorm = 0.3921, lr_0 = 5.6934e-04
Loss = 4.8828e-04, PNorm = 47.0463, GNorm = 0.3780, lr_0 = 5.6875e-04
Loss = 4.8394e-04, PNorm = 47.0602, GNorm = 0.4236, lr_0 = 5.6816e-04
Loss = 6.1973e-04, PNorm = 47.0658, GNorm = 0.3526, lr_0 = 5.6756e-04
Validation rmse logD = 0.556873
Validation R2 logD = 0.773543
Validation rmse logP = 0.461864
Validation R2 logP = 0.938111
Epoch 26
Train function
Loss = 3.6969e-04, PNorm = 47.0824, GNorm = 0.4572, lr_0 = 5.6691e-04
Loss = 4.1747e-04, PNorm = 47.0908, GNorm = 0.3743, lr_0 = 5.6632e-04
Loss = 3.9983e-04, PNorm = 47.0978, GNorm = 0.4875, lr_0 = 5.6573e-04
Loss = 4.5414e-04, PNorm = 47.1130, GNorm = 0.5335, lr_0 = 5.6514e-04
Loss = 3.4903e-04, PNorm = 47.1273, GNorm = 0.3267, lr_0 = 5.6455e-04
Loss = 4.6954e-04, PNorm = 47.1372, GNorm = 0.2433, lr_0 = 5.6396e-04
Loss = 3.8681e-04, PNorm = 47.1471, GNorm = 0.4703, lr_0 = 5.6337e-04
Loss = 3.5215e-04, PNorm = 47.1588, GNorm = 0.5408, lr_0 = 5.6278e-04
Loss = 4.6929e-04, PNorm = 47.1701, GNorm = 1.1344, lr_0 = 5.6219e-04
Loss = 4.5842e-04, PNorm = 47.1826, GNorm = 0.2680, lr_0 = 5.6161e-04
Loss = 4.9589e-04, PNorm = 47.1907, GNorm = 0.5256, lr_0 = 5.6102e-04
Loss = 4.2755e-04, PNorm = 47.1995, GNorm = 0.3307, lr_0 = 5.6044e-04
Loss = 5.9809e-04, PNorm = 47.2089, GNorm = 0.7146, lr_0 = 5.5985e-04
Loss = 5.1819e-04, PNorm = 47.2175, GNorm = 0.3890, lr_0 = 5.5927e-04
Loss = 5.6677e-04, PNorm = 47.2301, GNorm = 0.6424, lr_0 = 5.5868e-04
Loss = 4.4081e-04, PNorm = 47.2463, GNorm = 0.4909, lr_0 = 5.5810e-04
Loss = 4.4465e-04, PNorm = 47.2591, GNorm = 0.4743, lr_0 = 5.5752e-04
Loss = 4.9313e-04, PNorm = 47.2740, GNorm = 0.3740, lr_0 = 5.5694e-04
Loss = 5.9726e-04, PNorm = 47.2866, GNorm = 0.7149, lr_0 = 5.5635e-04
Loss = 5.4034e-04, PNorm = 47.3050, GNorm = 0.5866, lr_0 = 5.5577e-04
Loss = 5.1586e-04, PNorm = 47.3213, GNorm = 0.6045, lr_0 = 5.5519e-04
Loss = 4.4037e-04, PNorm = 47.3324, GNorm = 0.6493, lr_0 = 5.5461e-04
Validation rmse logD = 0.557519
Validation R2 logD = 0.773017
Validation rmse logP = 0.464185
Validation R2 logP = 0.937487
Epoch 27
Train function
Loss = 6.2377e-04, PNorm = 47.3469, GNorm = 0.8825, lr_0 = 5.5398e-04
Loss = 4.0870e-04, PNorm = 47.3554, GNorm = 0.3919, lr_0 = 5.5340e-04
Loss = 3.9149e-04, PNorm = 47.3676, GNorm = 0.6758, lr_0 = 5.5282e-04
Loss = 3.8958e-04, PNorm = 47.3782, GNorm = 0.2420, lr_0 = 5.5224e-04
Loss = 3.9756e-04, PNorm = 47.3855, GNorm = 0.3618, lr_0 = 5.5167e-04
Loss = 4.5291e-04, PNorm = 47.3939, GNorm = 0.3635, lr_0 = 5.5109e-04
Loss = 4.1220e-04, PNorm = 47.4063, GNorm = 0.4454, lr_0 = 5.5052e-04
Loss = 3.6678e-04, PNorm = 47.4180, GNorm = 0.4004, lr_0 = 5.4994e-04
Loss = 4.7184e-04, PNorm = 47.4268, GNorm = 0.4579, lr_0 = 5.4937e-04
Loss = 4.3058e-04, PNorm = 47.4351, GNorm = 0.7229, lr_0 = 5.4880e-04
Loss = 5.8061e-04, PNorm = 47.4510, GNorm = 0.4571, lr_0 = 5.4822e-04
Loss = 4.4482e-04, PNorm = 47.4669, GNorm = 0.5929, lr_0 = 5.4765e-04
Loss = 3.8454e-04, PNorm = 47.4821, GNorm = 0.3559, lr_0 = 5.4708e-04
Loss = 4.8683e-04, PNorm = 47.4924, GNorm = 0.3535, lr_0 = 5.4651e-04
Loss = 4.0984e-04, PNorm = 47.5026, GNorm = 0.3869, lr_0 = 5.4594e-04
Loss = 4.9016e-04, PNorm = 47.5137, GNorm = 0.7105, lr_0 = 5.4537e-04
Loss = 4.8981e-04, PNorm = 47.5210, GNorm = 0.7111, lr_0 = 5.4480e-04
Loss = 4.3350e-04, PNorm = 47.5280, GNorm = 0.4925, lr_0 = 5.4423e-04
Loss = 3.7827e-04, PNorm = 47.5419, GNorm = 0.6276, lr_0 = 5.4366e-04
Loss = 5.3285e-04, PNorm = 47.5497, GNorm = 0.4519, lr_0 = 5.4309e-04
Loss = 4.0107e-04, PNorm = 47.5598, GNorm = 0.2665, lr_0 = 5.4253e-04
Loss = 4.0635e-04, PNorm = 47.5711, GNorm = 0.4629, lr_0 = 5.4196e-04
Loss = 4.2691e-04, PNorm = 47.5824, GNorm = 0.5830, lr_0 = 5.4140e-04
Validation rmse logD = 0.562818
Validation R2 logD = 0.768682
Validation rmse logP = 0.464670
Validation R2 logP = 0.937357
Epoch 28
Train function
Loss = 3.4167e-04, PNorm = 47.5950, GNorm = 0.2054, lr_0 = 5.4083e-04
Loss = 3.5408e-04, PNorm = 47.6073, GNorm = 0.5123, lr_0 = 5.4027e-04
Loss = 3.2586e-04, PNorm = 47.6120, GNorm = 0.3469, lr_0 = 5.3970e-04
Loss = 3.1931e-04, PNorm = 47.6210, GNorm = 0.3669, lr_0 = 5.3914e-04
Loss = 4.0320e-04, PNorm = 47.6295, GNorm = 0.3714, lr_0 = 5.3858e-04
Loss = 4.2028e-04, PNorm = 47.6408, GNorm = 0.5855, lr_0 = 5.3801e-04
Loss = 3.9589e-04, PNorm = 47.6516, GNorm = 0.8704, lr_0 = 5.3745e-04
Loss = 3.3565e-04, PNorm = 47.6583, GNorm = 0.3034, lr_0 = 5.3689e-04
Loss = 3.2693e-04, PNorm = 47.6682, GNorm = 0.3831, lr_0 = 5.3633e-04
Loss = 3.5459e-04, PNorm = 47.6791, GNorm = 0.3785, lr_0 = 5.3577e-04
Loss = 4.0781e-04, PNorm = 47.6861, GNorm = 0.3125, lr_0 = 5.3521e-04
Loss = 3.8356e-04, PNorm = 47.6973, GNorm = 0.7835, lr_0 = 5.3465e-04
Loss = 3.7714e-04, PNorm = 47.7065, GNorm = 0.3050, lr_0 = 5.3410e-04
Loss = 3.8700e-04, PNorm = 47.7172, GNorm = 0.2900, lr_0 = 5.3354e-04
Loss = 3.3426e-04, PNorm = 47.7257, GNorm = 0.3385, lr_0 = 5.3298e-04
Loss = 4.2957e-04, PNorm = 47.7358, GNorm = 0.3990, lr_0 = 5.3243e-04
Loss = 3.2413e-04, PNorm = 47.7445, GNorm = 0.3497, lr_0 = 5.3187e-04
Loss = 3.5361e-04, PNorm = 47.7567, GNorm = 0.3542, lr_0 = 5.3131e-04
Loss = 3.5142e-04, PNorm = 47.7702, GNorm = 0.3212, lr_0 = 5.3076e-04
Loss = 4.6706e-04, PNorm = 47.7792, GNorm = 0.3726, lr_0 = 5.3021e-04
Loss = 3.6749e-04, PNorm = 47.7866, GNorm = 0.3830, lr_0 = 5.2965e-04
Loss = 3.6239e-04, PNorm = 47.7961, GNorm = 0.2953, lr_0 = 5.2910e-04
Validation rmse logD = 0.562811
Validation R2 logD = 0.768688
Validation rmse logP = 0.458827
Validation R2 logP = 0.938922
Epoch 29
Train function
Loss = 3.2937e-04, PNorm = 47.8066, GNorm = 0.5039, lr_0 = 5.2849e-04
Loss = 2.6925e-04, PNorm = 47.8138, GNorm = 0.3190, lr_0 = 5.2794e-04
Loss = 3.7908e-04, PNorm = 47.8203, GNorm = 0.5824, lr_0 = 5.2739e-04
Loss = 2.7753e-04, PNorm = 47.8301, GNorm = 0.3475, lr_0 = 5.2684e-04
Loss = 3.3415e-04, PNorm = 47.8369, GNorm = 0.2627, lr_0 = 5.2629e-04
Loss = 3.1223e-04, PNorm = 47.8460, GNorm = 0.4116, lr_0 = 5.2574e-04
Loss = 2.8368e-04, PNorm = 47.8549, GNorm = 0.2429, lr_0 = 5.2519e-04
Loss = 2.4616e-04, PNorm = 47.8612, GNorm = 0.4669, lr_0 = 5.2464e-04
Loss = 2.8216e-04, PNorm = 47.8658, GNorm = 0.3198, lr_0 = 5.2410e-04
Loss = 2.8620e-04, PNorm = 47.8721, GNorm = 0.2504, lr_0 = 5.2355e-04
Loss = 3.4240e-04, PNorm = 47.8781, GNorm = 0.5476, lr_0 = 5.2300e-04
Loss = 3.2185e-04, PNorm = 47.8900, GNorm = 0.3081, lr_0 = 5.2246e-04
Loss = 2.8971e-04, PNorm = 47.9006, GNorm = 0.4873, lr_0 = 5.2191e-04
Loss = 3.8019e-04, PNorm = 47.9159, GNorm = 0.3621, lr_0 = 5.2137e-04
Loss = 3.8940e-04, PNorm = 47.9289, GNorm = 0.6892, lr_0 = 5.2082e-04
Loss = 3.3516e-04, PNorm = 47.9395, GNorm = 0.3755, lr_0 = 5.2028e-04
Loss = 3.9145e-04, PNorm = 47.9479, GNorm = 0.4761, lr_0 = 5.1974e-04
Loss = 4.3439e-04, PNorm = 47.9585, GNorm = 0.5402, lr_0 = 5.1919e-04
Loss = 3.4838e-04, PNorm = 47.9684, GNorm = 0.3458, lr_0 = 5.1865e-04
Loss = 3.8321e-04, PNorm = 47.9771, GNorm = 0.7251, lr_0 = 5.1811e-04
Loss = 3.2766e-04, PNorm = 47.9824, GNorm = 0.3506, lr_0 = 5.1757e-04
Loss = 2.5798e-04, PNorm = 47.9882, GNorm = 0.3960, lr_0 = 5.1703e-04
Loss = 3.0786e-04, PNorm = 47.9929, GNorm = 0.4255, lr_0 = 5.1649e-04
Validation rmse logD = 0.556027
Validation R2 logD = 0.774231
Validation rmse logP = 0.451450
Validation R2 logP = 0.940871
Epoch 30
Train function
Loss = 2.7904e-04, PNorm = 48.0030, GNorm = 0.2663, lr_0 = 5.1595e-04
Loss = 2.9190e-04, PNorm = 48.0142, GNorm = 0.2936, lr_0 = 5.1541e-04
Loss = 3.3513e-04, PNorm = 48.0217, GNorm = 0.4405, lr_0 = 5.1487e-04
Loss = 2.6634e-04, PNorm = 48.0297, GNorm = 0.3924, lr_0 = 5.1434e-04
Loss = 3.7388e-04, PNorm = 48.0362, GNorm = 0.5640, lr_0 = 5.1380e-04
Loss = 2.8255e-04, PNorm = 48.0458, GNorm = 0.3669, lr_0 = 5.1326e-04
Loss = 2.7241e-04, PNorm = 48.0559, GNorm = 0.4671, lr_0 = 5.1273e-04
Loss = 2.8834e-04, PNorm = 48.0658, GNorm = 0.3803, lr_0 = 5.1219e-04
Loss = 3.5259e-04, PNorm = 48.0724, GNorm = 0.4105, lr_0 = 5.1166e-04
Loss = 2.8831e-04, PNorm = 48.0851, GNorm = 0.4938, lr_0 = 5.1112e-04
Loss = 3.6077e-04, PNorm = 48.0928, GNorm = 0.2557, lr_0 = 5.1059e-04
Loss = 3.0039e-04, PNorm = 48.1035, GNorm = 0.3939, lr_0 = 5.1006e-04
Loss = 2.8437e-04, PNorm = 48.1138, GNorm = 0.3846, lr_0 = 5.0953e-04
Loss = 3.6318e-04, PNorm = 48.1215, GNorm = 0.3944, lr_0 = 5.0899e-04
Loss = 3.1286e-04, PNorm = 48.1259, GNorm = 0.3824, lr_0 = 5.0846e-04
Loss = 3.1010e-04, PNorm = 48.1333, GNorm = 0.7584, lr_0 = 5.0793e-04
Loss = 2.6751e-04, PNorm = 48.1376, GNorm = 0.2799, lr_0 = 5.0740e-04
Loss = 3.7337e-04, PNorm = 48.1470, GNorm = 0.4887, lr_0 = 5.0687e-04
Loss = 4.2331e-04, PNorm = 48.1584, GNorm = 0.5218, lr_0 = 5.0634e-04
Loss = 4.3802e-04, PNorm = 48.1710, GNorm = 1.0436, lr_0 = 5.0581e-04
Loss = 3.9184e-04, PNorm = 48.1815, GNorm = 0.4348, lr_0 = 5.0529e-04
Loss = 3.2468e-04, PNorm = 48.1911, GNorm = 0.5078, lr_0 = 5.0476e-04
Validation rmse logD = 0.560904
Validation R2 logD = 0.770253
Validation rmse logP = 0.454507
Validation R2 logP = 0.940067
Epoch 31
Train function
Loss = 4.8797e-04, PNorm = 48.1969, GNorm = 0.8243, lr_0 = 5.0418e-04
Loss = 2.7157e-04, PNorm = 48.2007, GNorm = 0.6318, lr_0 = 5.0365e-04
Loss = 3.0986e-04, PNorm = 48.2136, GNorm = 0.3055, lr_0 = 5.0313e-04
Loss = 2.9570e-04, PNorm = 48.2220, GNorm = 0.4897, lr_0 = 5.0260e-04
Loss = 2.7922e-04, PNorm = 48.2293, GNorm = 0.2900, lr_0 = 5.0208e-04
Loss = 3.4242e-04, PNorm = 48.2396, GNorm = 0.2711, lr_0 = 5.0155e-04
Loss = 3.4826e-04, PNorm = 48.2463, GNorm = 0.3881, lr_0 = 5.0103e-04
Loss = 3.3095e-04, PNorm = 48.2554, GNorm = 0.2674, lr_0 = 5.0051e-04
Loss = 2.7726e-04, PNorm = 48.2670, GNorm = 0.3333, lr_0 = 4.9998e-04
Loss = 2.6787e-04, PNorm = 48.2792, GNorm = 0.4386, lr_0 = 4.9946e-04
Loss = 3.4501e-04, PNorm = 48.2925, GNorm = 1.0106, lr_0 = 4.9894e-04
Loss = 4.2564e-04, PNorm = 48.3047, GNorm = 0.7555, lr_0 = 4.9842e-04
Loss = 3.4908e-04, PNorm = 48.3101, GNorm = 0.5263, lr_0 = 4.9790e-04
Loss = 3.0491e-04, PNorm = 48.3232, GNorm = 0.4070, lr_0 = 4.9738e-04
Loss = 2.7455e-04, PNorm = 48.3339, GNorm = 0.6384, lr_0 = 4.9686e-04
Loss = 3.2998e-04, PNorm = 48.3444, GNorm = 0.3322, lr_0 = 4.9634e-04
Loss = 2.5528e-04, PNorm = 48.3519, GNorm = 0.2742, lr_0 = 4.9583e-04
Loss = 3.1149e-04, PNorm = 48.3593, GNorm = 0.5518, lr_0 = 4.9531e-04
Loss = 2.8000e-04, PNorm = 48.3710, GNorm = 0.4179, lr_0 = 4.9479e-04
Loss = 2.7325e-04, PNorm = 48.3838, GNorm = 0.3310, lr_0 = 4.9427e-04
Loss = 2.8580e-04, PNorm = 48.3892, GNorm = 0.3320, lr_0 = 4.9376e-04
Loss = 3.9207e-04, PNorm = 48.3973, GNorm = 1.1207, lr_0 = 4.9324e-04
Loss = 3.3118e-04, PNorm = 48.4020, GNorm = 0.3888, lr_0 = 4.9273e-04
Validation rmse logD = 0.559476
Validation R2 logD = 0.771421
Validation rmse logP = 0.477436
Validation R2 logP = 0.933867
Epoch 32
Train function
Loss = 3.6898e-04, PNorm = 48.4153, GNorm = 0.8372, lr_0 = 4.9221e-04
Loss = 3.1486e-04, PNorm = 48.4278, GNorm = 0.8390, lr_0 = 4.9170e-04
Loss = 3.0138e-04, PNorm = 48.4368, GNorm = 0.5221, lr_0 = 4.9119e-04
Loss = 3.5353e-04, PNorm = 48.4476, GNorm = 0.3085, lr_0 = 4.9067e-04
Loss = 3.4934e-04, PNorm = 48.4566, GNorm = 0.5319, lr_0 = 4.9016e-04
Loss = 3.0323e-04, PNorm = 48.4695, GNorm = 0.3465, lr_0 = 4.8965e-04
Loss = 2.8765e-04, PNorm = 48.4791, GNorm = 0.5424, lr_0 = 4.8914e-04
Loss = 3.2114e-04, PNorm = 48.4864, GNorm = 0.3832, lr_0 = 4.8863e-04
Loss = 2.7919e-04, PNorm = 48.4920, GNorm = 0.3407, lr_0 = 4.8812e-04
Loss = 3.1262e-04, PNorm = 48.5033, GNorm = 0.4274, lr_0 = 4.8761e-04
Loss = 2.9515e-04, PNorm = 48.5100, GNorm = 0.3188, lr_0 = 4.8710e-04
Loss = 3.2927e-04, PNorm = 48.5221, GNorm = 0.4411, lr_0 = 4.8659e-04
Loss = 2.3178e-04, PNorm = 48.5309, GNorm = 0.4173, lr_0 = 4.8608e-04
Loss = 2.9200e-04, PNorm = 48.5416, GNorm = 0.3473, lr_0 = 4.8558e-04
Loss = 3.0208e-04, PNorm = 48.5547, GNorm = 0.5157, lr_0 = 4.8507e-04
Loss = 3.3862e-04, PNorm = 48.5634, GNorm = 0.6698, lr_0 = 4.8456e-04
Loss = 3.6038e-04, PNorm = 48.5729, GNorm = 0.3571, lr_0 = 4.8406e-04
Loss = 2.8214e-04, PNorm = 48.5790, GNorm = 0.5276, lr_0 = 4.8355e-04
Loss = 3.5812e-04, PNorm = 48.5894, GNorm = 0.4282, lr_0 = 4.8305e-04
Loss = 3.4237e-04, PNorm = 48.5981, GNorm = 0.6174, lr_0 = 4.8254e-04
Loss = 3.1816e-04, PNorm = 48.6049, GNorm = 0.5754, lr_0 = 4.8204e-04
Loss = 3.3580e-04, PNorm = 48.6122, GNorm = 0.3348, lr_0 = 4.8154e-04
Loss = 3.2972e-04, PNorm = 48.6241, GNorm = 0.2860, lr_0 = 4.8104e-04
Loss = 8.1541e-04, PNorm = 48.6250, GNorm = 0.5659, lr_0 = 4.8098e-04
Validation rmse logD = 0.558508
Validation R2 logD = 0.772211
Validation rmse logP = 0.460327
Validation R2 logP = 0.938522
Epoch 33
Train function
Loss = 2.5541e-04, PNorm = 48.6346, GNorm = 0.2475, lr_0 = 4.8048e-04
Loss = 2.3562e-04, PNorm = 48.6429, GNorm = 0.3300, lr_0 = 4.7998e-04
Loss = 2.8802e-04, PNorm = 48.6522, GNorm = 0.6291, lr_0 = 4.7948e-04
Loss = 2.5569e-04, PNorm = 48.6569, GNorm = 0.2550, lr_0 = 4.7898e-04
Loss = 2.9914e-04, PNorm = 48.6626, GNorm = 0.2905, lr_0 = 4.7848e-04
Loss = 2.2474e-04, PNorm = 48.6699, GNorm = 0.5782, lr_0 = 4.7798e-04
Loss = 2.5618e-04, PNorm = 48.6790, GNorm = 0.5150, lr_0 = 4.7748e-04
Loss = 2.5143e-04, PNorm = 48.6898, GNorm = 0.3101, lr_0 = 4.7698e-04
Loss = 3.4219e-04, PNorm = 48.6968, GNorm = 0.4078, lr_0 = 4.7649e-04
Loss = 2.3615e-04, PNorm = 48.7037, GNorm = 0.3001, lr_0 = 4.7599e-04
Loss = 2.7492e-04, PNorm = 48.7087, GNorm = 0.5537, lr_0 = 4.7549e-04
Loss = 2.8263e-04, PNorm = 48.7201, GNorm = 0.6851, lr_0 = 4.7500e-04
Loss = 2.8769e-04, PNorm = 48.7290, GNorm = 0.4436, lr_0 = 4.7450e-04
Loss = 2.4456e-04, PNorm = 48.7343, GNorm = 0.4962, lr_0 = 4.7400e-04
Loss = 4.4207e-04, PNorm = 48.7475, GNorm = 0.4657, lr_0 = 4.7351e-04
Loss = 3.6291e-04, PNorm = 48.7620, GNorm = 0.6212, lr_0 = 4.7302e-04
Loss = 3.4965e-04, PNorm = 48.7709, GNorm = 0.4504, lr_0 = 4.7252e-04
Loss = 3.2779e-04, PNorm = 48.7783, GNorm = 0.6415, lr_0 = 4.7203e-04
Loss = 2.9687e-04, PNorm = 48.7899, GNorm = 0.3127, lr_0 = 4.7154e-04
Loss = 2.8522e-04, PNorm = 48.8006, GNorm = 0.4536, lr_0 = 4.7104e-04
Loss = 2.9415e-04, PNorm = 48.8092, GNorm = 0.3013, lr_0 = 4.7055e-04
Loss = 3.1288e-04, PNorm = 48.8182, GNorm = 0.6124, lr_0 = 4.7006e-04
Validation rmse logD = 0.563421
Validation R2 logD = 0.768186
Validation rmse logP = 0.452613
Validation R2 logP = 0.940566
Epoch 34
Train function
Loss = 2.4292e-04, PNorm = 48.8277, GNorm = 0.4407, lr_0 = 4.6957e-04
Loss = 2.2351e-04, PNorm = 48.8361, GNorm = 0.4774, lr_0 = 4.6908e-04
Loss = 2.5240e-04, PNorm = 48.8465, GNorm = 0.4152, lr_0 = 4.6859e-04
Loss = 2.5220e-04, PNorm = 48.8513, GNorm = 0.2424, lr_0 = 4.6810e-04
Loss = 2.2848e-04, PNorm = 48.8595, GNorm = 0.2054, lr_0 = 4.6761e-04
Loss = 2.2937e-04, PNorm = 48.8649, GNorm = 0.3088, lr_0 = 4.6712e-04
Loss = 2.3824e-04, PNorm = 48.8752, GNorm = 0.2775, lr_0 = 4.6664e-04
Loss = 2.4357e-04, PNorm = 48.8819, GNorm = 0.6663, lr_0 = 4.6615e-04
Loss = 2.3380e-04, PNorm = 48.8866, GNorm = 0.5537, lr_0 = 4.6566e-04
Loss = 2.9141e-04, PNorm = 48.8964, GNorm = 0.5704, lr_0 = 4.6518e-04
Loss = 2.8166e-04, PNorm = 48.9023, GNorm = 0.3962, lr_0 = 4.6469e-04
Loss = 2.7758e-04, PNorm = 48.9093, GNorm = 0.3644, lr_0 = 4.6421e-04
Loss = 2.6536e-04, PNorm = 48.9162, GNorm = 0.3653, lr_0 = 4.6372e-04
Loss = 2.6620e-04, PNorm = 48.9198, GNorm = 0.4125, lr_0 = 4.6324e-04
Loss = 2.9612e-04, PNorm = 48.9241, GNorm = 0.7510, lr_0 = 4.6276e-04
Loss = 2.1990e-04, PNorm = 48.9301, GNorm = 0.3316, lr_0 = 4.6227e-04
Loss = 2.8649e-04, PNorm = 48.9345, GNorm = 0.3504, lr_0 = 4.6179e-04
Loss = 3.1700e-04, PNorm = 48.9435, GNorm = 0.2601, lr_0 = 4.6131e-04
Loss = 2.6112e-04, PNorm = 48.9527, GNorm = 0.2546, lr_0 = 4.6083e-04
Loss = 2.1256e-04, PNorm = 48.9624, GNorm = 0.4486, lr_0 = 4.6035e-04
Loss = 3.7073e-04, PNorm = 48.9720, GNorm = 0.7750, lr_0 = 4.5987e-04
Loss = 2.5382e-04, PNorm = 48.9813, GNorm = 0.5128, lr_0 = 4.5939e-04
Loss = 2.6255e-04, PNorm = 48.9879, GNorm = 0.4116, lr_0 = 4.5891e-04
Validation rmse logD = 0.555993
Validation R2 logD = 0.774258
Validation rmse logP = 0.455710
Validation R2 logP = 0.939749
Epoch 35
Train function
Loss = 2.4745e-04, PNorm = 48.9972, GNorm = 0.3133, lr_0 = 4.5838e-04
Loss = 3.6610e-04, PNorm = 49.0078, GNorm = 0.4545, lr_0 = 4.5790e-04
Loss = 3.3087e-04, PNorm = 49.0192, GNorm = 0.8710, lr_0 = 4.5742e-04
Loss = 3.0811e-04, PNorm = 49.0260, GNorm = 0.4846, lr_0 = 4.5695e-04
Loss = 2.8873e-04, PNorm = 49.0369, GNorm = 0.3764, lr_0 = 4.5647e-04
Loss = 3.0879e-04, PNorm = 49.0435, GNorm = 0.3073, lr_0 = 4.5599e-04
Loss = 3.0293e-04, PNorm = 49.0544, GNorm = 0.5512, lr_0 = 4.5552e-04
Loss = 2.8862e-04, PNorm = 49.0624, GNorm = 0.6567, lr_0 = 4.5504e-04
Loss = 1.9521e-04, PNorm = 49.0719, GNorm = 0.3319, lr_0 = 4.5457e-04
Loss = 2.2784e-04, PNorm = 49.0832, GNorm = 0.4007, lr_0 = 4.5409e-04
Loss = 2.6245e-04, PNorm = 49.0925, GNorm = 0.4593, lr_0 = 4.5362e-04
Loss = 2.8814e-04, PNorm = 49.0973, GNorm = 0.5721, lr_0 = 4.5314e-04
Loss = 2.6551e-04, PNorm = 49.1076, GNorm = 0.4682, lr_0 = 4.5267e-04
Loss = 2.7483e-04, PNorm = 49.1154, GNorm = 0.4195, lr_0 = 4.5220e-04
Loss = 2.4611e-04, PNorm = 49.1238, GNorm = 0.2860, lr_0 = 4.5173e-04
Loss = 2.5865e-04, PNorm = 49.1328, GNorm = 0.3340, lr_0 = 4.5125e-04
Loss = 2.6441e-04, PNorm = 49.1369, GNorm = 0.4070, lr_0 = 4.5078e-04
Loss = 2.8535e-04, PNorm = 49.1423, GNorm = 0.4901, lr_0 = 4.5031e-04
Loss = 2.2441e-04, PNorm = 49.1546, GNorm = 0.4385, lr_0 = 4.4984e-04
Loss = 2.9438e-04, PNorm = 49.1617, GNorm = 0.5262, lr_0 = 4.4937e-04
Loss = 3.3355e-04, PNorm = 49.1705, GNorm = 0.6595, lr_0 = 4.4890e-04
Loss = 2.7898e-04, PNorm = 49.1837, GNorm = 0.4723, lr_0 = 4.4844e-04
Validation rmse logD = 0.560479
Validation R2 logD = 0.770600
Validation rmse logP = 0.472323
Validation R2 logP = 0.935276
Epoch 36
Train function
Loss = 4.1315e-04, PNorm = 49.1933, GNorm = 0.3326, lr_0 = 4.4797e-04
Loss = 2.3394e-04, PNorm = 49.2059, GNorm = 0.3305, lr_0 = 4.4750e-04
Loss = 3.0227e-04, PNorm = 49.2145, GNorm = 0.4454, lr_0 = 4.4703e-04
Loss = 2.0077e-04, PNorm = 49.2179, GNorm = 0.3470, lr_0 = 4.4657e-04
Loss = 2.3179e-04, PNorm = 49.2216, GNorm = 0.3991, lr_0 = 4.4610e-04
Loss = 2.7683e-04, PNorm = 49.2298, GNorm = 0.2946, lr_0 = 4.4564e-04
Loss = 2.2535e-04, PNorm = 49.2394, GNorm = 0.4736, lr_0 = 4.4517e-04
Loss = 2.4472e-04, PNorm = 49.2471, GNorm = 0.2797, lr_0 = 4.4471e-04
Loss = 2.2265e-04, PNorm = 49.2537, GNorm = 0.1948, lr_0 = 4.4424e-04
Loss = 2.7897e-04, PNorm = 49.2626, GNorm = 0.2779, lr_0 = 4.4378e-04
Loss = 2.6543e-04, PNorm = 49.2704, GNorm = 0.6762, lr_0 = 4.4331e-04
Loss = 2.9233e-04, PNorm = 49.2786, GNorm = 0.2746, lr_0 = 4.4285e-04
Loss = 2.0751e-04, PNorm = 49.2850, GNorm = 0.3017, lr_0 = 4.4239e-04
Loss = 1.8818e-04, PNorm = 49.2925, GNorm = 0.2691, lr_0 = 4.4193e-04
Loss = 1.7517e-04, PNorm = 49.2973, GNorm = 0.3639, lr_0 = 4.4147e-04
Loss = 2.3618e-04, PNorm = 49.3082, GNorm = 0.3264, lr_0 = 4.4101e-04
Loss = 2.4631e-04, PNorm = 49.3174, GNorm = 0.6257, lr_0 = 4.4055e-04
Loss = 2.6113e-04, PNorm = 49.3255, GNorm = 0.2244, lr_0 = 4.4009e-04
Loss = 2.4195e-04, PNorm = 49.3308, GNorm = 0.3246, lr_0 = 4.3963e-04
Loss = 2.1673e-04, PNorm = 49.3353, GNorm = 0.2883, lr_0 = 4.3917e-04
Loss = 2.8830e-04, PNorm = 49.3427, GNorm = 0.3535, lr_0 = 4.3871e-04
Loss = 1.9689e-04, PNorm = 49.3494, GNorm = 0.5926, lr_0 = 4.3825e-04
Loss = 2.5334e-04, PNorm = 49.3583, GNorm = 0.3035, lr_0 = 4.3779e-04
Validation rmse logD = 0.549612
Validation R2 logD = 0.779410
Validation rmse logP = 0.454802
Validation R2 logP = 0.939989
Epoch 37
Train function
Loss = 1.8957e-04, PNorm = 49.3682, GNorm = 0.2249, lr_0 = 4.3729e-04
Loss = 2.8401e-04, PNorm = 49.3744, GNorm = 0.3171, lr_0 = 4.3684e-04
Loss = 1.9632e-04, PNorm = 49.3833, GNorm = 0.2217, lr_0 = 4.3638e-04
Loss = 1.9632e-04, PNorm = 49.3865, GNorm = 0.2701, lr_0 = 4.3592e-04
Loss = 1.6075e-04, PNorm = 49.3923, GNorm = 0.2520, lr_0 = 4.3547e-04
Loss = 1.9905e-04, PNorm = 49.3967, GNorm = 0.2593, lr_0 = 4.3501e-04
Loss = 2.0697e-04, PNorm = 49.4027, GNorm = 0.3891, lr_0 = 4.3456e-04
Loss = 2.3274e-04, PNorm = 49.4115, GNorm = 0.5520, lr_0 = 4.3411e-04
Loss = 2.1276e-04, PNorm = 49.4177, GNorm = 0.3026, lr_0 = 4.3365e-04
Loss = 2.0014e-04, PNorm = 49.4265, GNorm = 0.3362, lr_0 = 4.3320e-04
Loss = 2.1730e-04, PNorm = 49.4315, GNorm = 0.1734, lr_0 = 4.3275e-04
Loss = 2.0256e-04, PNorm = 49.4379, GNorm = 0.2696, lr_0 = 4.3230e-04
Loss = 1.8975e-04, PNorm = 49.4438, GNorm = 0.3651, lr_0 = 4.3185e-04
Loss = 1.8841e-04, PNorm = 49.4511, GNorm = 0.3351, lr_0 = 4.3140e-04
Loss = 2.1069e-04, PNorm = 49.4556, GNorm = 0.3046, lr_0 = 4.3094e-04
Loss = 1.7020e-04, PNorm = 49.4600, GNorm = 0.2877, lr_0 = 4.3050e-04
Loss = 2.1603e-04, PNorm = 49.4643, GNorm = 0.2060, lr_0 = 4.3005e-04
Loss = 2.1758e-04, PNorm = 49.4690, GNorm = 0.3679, lr_0 = 4.2960e-04
Loss = 2.2590e-04, PNorm = 49.4731, GNorm = 0.3184, lr_0 = 4.2915e-04
Loss = 1.9885e-04, PNorm = 49.4813, GNorm = 0.2648, lr_0 = 4.2870e-04
Loss = 2.1964e-04, PNorm = 49.4904, GNorm = 0.5472, lr_0 = 4.2825e-04
Loss = 2.3991e-04, PNorm = 49.4988, GNorm = 0.4606, lr_0 = 4.2781e-04
Validation rmse logD = 0.565775
Validation R2 logD = 0.766245
Validation rmse logP = 0.469513
Validation R2 logP = 0.936044
Epoch 38
Train function
Loss = 3.0001e-04, PNorm = 49.5069, GNorm = 0.5234, lr_0 = 4.2736e-04
Loss = 2.4444e-04, PNorm = 49.5146, GNorm = 0.7369, lr_0 = 4.2691e-04
Loss = 2.5405e-04, PNorm = 49.5256, GNorm = 0.3785, lr_0 = 4.2647e-04
Loss = 2.1166e-04, PNorm = 49.5323, GNorm = 0.2859, lr_0 = 4.2602e-04
Loss = 2.0161e-04, PNorm = 49.5388, GNorm = 0.1914, lr_0 = 4.2558e-04
Loss = 1.8915e-04, PNorm = 49.5430, GNorm = 0.2433, lr_0 = 4.2513e-04
Loss = 1.9020e-04, PNorm = 49.5503, GNorm = 0.3009, lr_0 = 4.2469e-04
Loss = 2.4860e-04, PNorm = 49.5558, GNorm = 0.2371, lr_0 = 4.2425e-04
Loss = 1.9847e-04, PNorm = 49.5620, GNorm = 0.3819, lr_0 = 4.2380e-04
Loss = 2.2142e-04, PNorm = 49.5689, GNorm = 0.1698, lr_0 = 4.2336e-04
Loss = 1.9464e-04, PNorm = 49.5736, GNorm = 0.3157, lr_0 = 4.2292e-04
Loss = 1.5360e-04, PNorm = 49.5810, GNorm = 0.1950, lr_0 = 4.2248e-04
Loss = 1.9694e-04, PNorm = 49.5884, GNorm = 0.2442, lr_0 = 4.2204e-04
Loss = 2.8804e-04, PNorm = 49.5942, GNorm = 0.2132, lr_0 = 4.2160e-04
Loss = 2.1195e-04, PNorm = 49.6003, GNorm = 0.6633, lr_0 = 4.2116e-04
Loss = 2.2208e-04, PNorm = 49.6097, GNorm = 0.5164, lr_0 = 4.2072e-04
Loss = 3.2103e-04, PNorm = 49.6214, GNorm = 0.8183, lr_0 = 4.2028e-04
Loss = 2.7983e-04, PNorm = 49.6263, GNorm = 0.4296, lr_0 = 4.1984e-04
Loss = 2.6903e-04, PNorm = 49.6327, GNorm = 0.2256, lr_0 = 4.1940e-04
Loss = 2.7978e-04, PNorm = 49.6419, GNorm = 0.3789, lr_0 = 4.1896e-04
Loss = 2.5677e-04, PNorm = 49.6503, GNorm = 0.2804, lr_0 = 4.1853e-04
Loss = 2.9945e-04, PNorm = 49.6625, GNorm = 0.6763, lr_0 = 4.1809e-04
Loss = 2.6523e-04, PNorm = 49.6712, GNorm = 0.3405, lr_0 = 4.1765e-04
Validation rmse logD = 0.553676
Validation R2 logD = 0.776135
Validation rmse logP = 0.453784
Validation R2 logP = 0.940258
Epoch 39
Train function
Loss = 1.9667e-04, PNorm = 49.6840, GNorm = 0.2273, lr_0 = 4.1717e-04
Loss = 2.4052e-04, PNorm = 49.6892, GNorm = 0.4935, lr_0 = 4.1674e-04
Loss = 2.1011e-04, PNorm = 49.6982, GNorm = 0.3903, lr_0 = 4.1630e-04
Loss = 2.1609e-04, PNorm = 49.7081, GNorm = 0.5757, lr_0 = 4.1587e-04
Loss = 2.1084e-04, PNorm = 49.7142, GNorm = 0.2150, lr_0 = 4.1544e-04
Loss = 2.0120e-04, PNorm = 49.7207, GNorm = 0.4937, lr_0 = 4.1500e-04
Loss = 2.7784e-04, PNorm = 49.7320, GNorm = 0.4955, lr_0 = 4.1457e-04
Loss = 2.7949e-04, PNorm = 49.7403, GNorm = 0.3687, lr_0 = 4.1414e-04
Loss = 1.8529e-04, PNorm = 49.7458, GNorm = 0.2754, lr_0 = 4.1370e-04
Loss = 2.1208e-04, PNorm = 49.7532, GNorm = 0.1939, lr_0 = 4.1327e-04
Loss = 1.7494e-04, PNorm = 49.7601, GNorm = 0.2765, lr_0 = 4.1284e-04
Loss = 1.6625e-04, PNorm = 49.7649, GNorm = 0.1506, lr_0 = 4.1241e-04
Loss = 1.9375e-04, PNorm = 49.7688, GNorm = 0.4399, lr_0 = 4.1198e-04
Loss = 1.7213e-04, PNorm = 49.7731, GNorm = 0.1659, lr_0 = 4.1155e-04
Loss = 2.1132e-04, PNorm = 49.7787, GNorm = 0.2879, lr_0 = 4.1112e-04
Loss = 1.8500e-04, PNorm = 49.7852, GNorm = 0.2768, lr_0 = 4.1069e-04
Loss = 1.7402e-04, PNorm = 49.7898, GNorm = 0.2977, lr_0 = 4.1026e-04
Loss = 1.8190e-04, PNorm = 49.7944, GNorm = 0.5122, lr_0 = 4.0983e-04
Loss = 2.0631e-04, PNorm = 49.8008, GNorm = 0.4141, lr_0 = 4.0941e-04
Loss = 1.7232e-04, PNorm = 49.8050, GNorm = 0.3581, lr_0 = 4.0898e-04
Loss = 2.0720e-04, PNorm = 49.8106, GNorm = 0.4531, lr_0 = 4.0855e-04
Loss = 3.1175e-04, PNorm = 49.8136, GNorm = 0.6233, lr_0 = 4.0813e-04
Validation rmse logD = 0.555917
Validation R2 logD = 0.774320
Validation rmse logP = 0.456010
Validation R2 logP = 0.939670
Epoch 40
Train function
Loss = 1.8010e-04, PNorm = 49.8231, GNorm = 0.2720, lr_0 = 4.0770e-04
Loss = 1.6169e-04, PNorm = 49.8294, GNorm = 0.3294, lr_0 = 4.0727e-04
Loss = 2.0703e-04, PNorm = 49.8386, GNorm = 0.4036, lr_0 = 4.0685e-04
Loss = 1.6312e-04, PNorm = 49.8470, GNorm = 0.2066, lr_0 = 4.0642e-04
Loss = 1.7364e-04, PNorm = 49.8506, GNorm = 0.3279, lr_0 = 4.0600e-04
Loss = 2.3812e-04, PNorm = 49.8590, GNorm = 0.3409, lr_0 = 4.0558e-04
Loss = 2.0689e-04, PNorm = 49.8653, GNorm = 0.2617, lr_0 = 4.0515e-04
Loss = 1.8394e-04, PNorm = 49.8691, GNorm = 0.2170, lr_0 = 4.0473e-04
Loss = 1.8369e-04, PNorm = 49.8749, GNorm = 0.3885, lr_0 = 4.0431e-04
Loss = 2.2192e-04, PNorm = 49.8828, GNorm = 0.4505, lr_0 = 4.0389e-04
Loss = 2.4433e-04, PNorm = 49.8921, GNorm = 0.3664, lr_0 = 4.0346e-04
Loss = 1.9698e-04, PNorm = 49.9017, GNorm = 0.3685, lr_0 = 4.0304e-04
Loss = 2.4464e-04, PNorm = 49.9119, GNorm = 0.4738, lr_0 = 4.0262e-04
Loss = 1.7881e-04, PNorm = 49.9172, GNorm = 0.5203, lr_0 = 4.0220e-04
Loss = 2.0858e-04, PNorm = 49.9228, GNorm = 0.4316, lr_0 = 4.0178e-04
Loss = 1.8391e-04, PNorm = 49.9306, GNorm = 0.3278, lr_0 = 4.0136e-04
Loss = 1.9181e-04, PNorm = 49.9374, GNorm = 0.5568, lr_0 = 4.0094e-04
Loss = 2.2838e-04, PNorm = 49.9426, GNorm = 0.4030, lr_0 = 4.0053e-04
Loss = 1.7690e-04, PNorm = 49.9498, GNorm = 0.3078, lr_0 = 4.0011e-04
Loss = 1.5940e-04, PNorm = 49.9547, GNorm = 0.2348, lr_0 = 3.9969e-04
Loss = 1.6102e-04, PNorm = 49.9596, GNorm = 0.2090, lr_0 = 3.9927e-04
Loss = 1.5745e-04, PNorm = 49.9648, GNorm = 0.3086, lr_0 = 3.9886e-04
Loss = 1.9066e-04, PNorm = 49.9693, GNorm = 0.2407, lr_0 = 3.9844e-04
Validation rmse logD = 0.560128
Validation R2 logD = 0.770888
Validation rmse logP = 0.453210
Validation R2 logP = 0.940409
Epoch 41
Train function
Loss = 1.5358e-04, PNorm = 49.9725, GNorm = 0.2694, lr_0 = 3.9798e-04
Loss = 1.9426e-04, PNorm = 49.9742, GNorm = 0.2378, lr_0 = 3.9757e-04
Loss = 1.5127e-04, PNorm = 49.9790, GNorm = 0.1953, lr_0 = 3.9715e-04
Loss = 1.8203e-04, PNorm = 49.9850, GNorm = 0.3005, lr_0 = 3.9674e-04
Loss = 1.3644e-04, PNorm = 49.9943, GNorm = 0.2049, lr_0 = 3.9632e-04
Loss = 1.4739e-04, PNorm = 49.9990, GNorm = 0.3581, lr_0 = 3.9591e-04
Loss = 1.2657e-04, PNorm = 50.0059, GNorm = 0.3095, lr_0 = 3.9550e-04
Loss = 1.2177e-04, PNorm = 50.0114, GNorm = 0.1995, lr_0 = 3.9508e-04
Loss = 1.6408e-04, PNorm = 50.0139, GNorm = 0.2910, lr_0 = 3.9467e-04
Loss = 1.7266e-04, PNorm = 50.0201, GNorm = 0.1797, lr_0 = 3.9426e-04
Loss = 1.4305e-04, PNorm = 50.0254, GNorm = 0.1763, lr_0 = 3.9385e-04
Loss = 1.4825e-04, PNorm = 50.0316, GNorm = 0.2772, lr_0 = 3.9344e-04
Loss = 1.4717e-04, PNorm = 50.0377, GNorm = 0.1457, lr_0 = 3.9303e-04
Loss = 1.5916e-04, PNorm = 50.0428, GNorm = 0.5308, lr_0 = 3.9262e-04
Loss = 1.5530e-04, PNorm = 50.0495, GNorm = 0.2969, lr_0 = 3.9221e-04
Loss = 1.5347e-04, PNorm = 50.0542, GNorm = 0.3732, lr_0 = 3.9180e-04
Loss = 2.5198e-04, PNorm = 50.0597, GNorm = 0.4885, lr_0 = 3.9139e-04
Loss = 2.0748e-04, PNorm = 50.0668, GNorm = 0.4739, lr_0 = 3.9098e-04
Loss = 1.5437e-04, PNorm = 50.0724, GNorm = 0.2179, lr_0 = 3.9057e-04
Loss = 1.5656e-04, PNorm = 50.0779, GNorm = 0.2736, lr_0 = 3.9016e-04
Loss = 2.6718e-04, PNorm = 50.0864, GNorm = 0.4179, lr_0 = 3.8976e-04
Loss = 1.9566e-04, PNorm = 50.0977, GNorm = 0.2650, lr_0 = 3.8935e-04
Loss = 1.7180e-04, PNorm = 50.1047, GNorm = 0.2828, lr_0 = 3.8894e-04
Validation rmse logD = 0.564632
Validation R2 logD = 0.767188
Validation rmse logP = 0.455255
Validation R2 logP = 0.939869
Epoch 42
Train function
Loss = 1.6189e-04, PNorm = 50.1100, GNorm = 0.1585, lr_0 = 3.8854e-04
Loss = 1.6367e-04, PNorm = 50.1149, GNorm = 0.3076, lr_0 = 3.8813e-04
Loss = 1.3615e-04, PNorm = 50.1202, GNorm = 0.2295, lr_0 = 3.8773e-04
Loss = 1.3560e-04, PNorm = 50.1254, GNorm = 0.3368, lr_0 = 3.8732e-04
Loss = 1.6376e-04, PNorm = 50.1300, GNorm = 0.1923, lr_0 = 3.8692e-04
Loss = 1.3655e-04, PNorm = 50.1342, GNorm = 0.2121, lr_0 = 3.8651e-04
Loss = 1.6932e-04, PNorm = 50.1415, GNorm = 0.3287, lr_0 = 3.8611e-04
Loss = 1.3912e-04, PNorm = 50.1459, GNorm = 0.2286, lr_0 = 3.8571e-04
Loss = 1.8656e-04, PNorm = 50.1507, GNorm = 0.1879, lr_0 = 3.8531e-04
Loss = 1.5231e-04, PNorm = 50.1569, GNorm = 0.3841, lr_0 = 3.8490e-04
Loss = 1.1979e-04, PNorm = 50.1608, GNorm = 0.2409, lr_0 = 3.8450e-04
Loss = 1.4648e-04, PNorm = 50.1666, GNorm = 0.3266, lr_0 = 3.8410e-04
Loss = 1.5387e-04, PNorm = 50.1730, GNorm = 0.3379, lr_0 = 3.8370e-04
Loss = 1.4370e-04, PNorm = 50.1773, GNorm = 0.3184, lr_0 = 3.8330e-04
Loss = 1.3116e-04, PNorm = 50.1819, GNorm = 0.2277, lr_0 = 3.8290e-04
Loss = 1.9242e-04, PNorm = 50.1864, GNorm = 0.2527, lr_0 = 3.8250e-04
Loss = 1.8447e-04, PNorm = 50.1910, GNorm = 0.6750, lr_0 = 3.8210e-04
Loss = 1.9639e-04, PNorm = 50.1972, GNorm = 0.6389, lr_0 = 3.8170e-04
Loss = 2.1703e-04, PNorm = 50.2015, GNorm = 0.6149, lr_0 = 3.8130e-04
Loss = 1.8102e-04, PNorm = 50.2061, GNorm = 0.1992, lr_0 = 3.8090e-04
Loss = 1.6793e-04, PNorm = 50.2128, GNorm = 0.3556, lr_0 = 3.8051e-04
Loss = 2.0935e-04, PNorm = 50.2218, GNorm = 0.2692, lr_0 = 3.8011e-04
Validation rmse logD = 0.558127
Validation R2 logD = 0.772522
Validation rmse logP = 0.449693
Validation R2 logP = 0.941330
Epoch 43
Train function
Loss = 1.6947e-04, PNorm = 50.2301, GNorm = 0.1998, lr_0 = 3.7967e-04
Loss = 1.5102e-04, PNorm = 50.2387, GNorm = 0.1717, lr_0 = 3.7928e-04
Loss = 1.8852e-04, PNorm = 50.2477, GNorm = 0.2686, lr_0 = 3.7888e-04
Loss = 1.5536e-04, PNorm = 50.2543, GNorm = 0.6656, lr_0 = 3.7849e-04
Loss = 1.8610e-04, PNorm = 50.2606, GNorm = 0.2168, lr_0 = 3.7809e-04
Loss = 1.2034e-04, PNorm = 50.2655, GNorm = 0.2193, lr_0 = 3.7770e-04
Loss = 1.3957e-04, PNorm = 50.2699, GNorm = 0.1569, lr_0 = 3.7730e-04
Loss = 1.5336e-04, PNorm = 50.2727, GNorm = 0.4333, lr_0 = 3.7691e-04
Loss = 1.4190e-04, PNorm = 50.2764, GNorm = 0.2821, lr_0 = 3.7652e-04
Loss = 1.4255e-04, PNorm = 50.2829, GNorm = 0.3056, lr_0 = 3.7612e-04
Loss = 1.3761e-04, PNorm = 50.2886, GNorm = 0.2165, lr_0 = 3.7573e-04
Loss = 1.4639e-04, PNorm = 50.2919, GNorm = 0.2295, lr_0 = 3.7534e-04
Loss = 1.4871e-04, PNorm = 50.2994, GNorm = 0.3940, lr_0 = 3.7495e-04
Loss = 1.3895e-04, PNorm = 50.3028, GNorm = 0.3599, lr_0 = 3.7455e-04
Loss = 1.5301e-04, PNorm = 50.3074, GNorm = 0.1394, lr_0 = 3.7416e-04
Loss = 1.8096e-04, PNorm = 50.3127, GNorm = 0.4152, lr_0 = 3.7377e-04
Loss = 1.7866e-04, PNorm = 50.3205, GNorm = 0.3014, lr_0 = 3.7338e-04
Loss = 1.5688e-04, PNorm = 50.3245, GNorm = 0.1481, lr_0 = 3.7299e-04
Loss = 1.6725e-04, PNorm = 50.3294, GNorm = 0.2892, lr_0 = 3.7260e-04
Loss = 1.8838e-04, PNorm = 50.3315, GNorm = 0.2529, lr_0 = 3.7221e-04
Loss = 1.6288e-04, PNorm = 50.3372, GNorm = 0.2417, lr_0 = 3.7183e-04
Loss = 1.8992e-04, PNorm = 50.3394, GNorm = 0.3188, lr_0 = 3.7144e-04
Loss = 1.7957e-04, PNorm = 50.3445, GNorm = 0.3624, lr_0 = 3.7105e-04
Validation rmse logD = 0.560171
Validation R2 logD = 0.770853
Validation rmse logP = 0.455551
Validation R2 logP = 0.939791
Epoch 44
Train function
Loss = 1.7801e-04, PNorm = 50.3520, GNorm = 0.3449, lr_0 = 3.7066e-04
Loss = 1.8371e-04, PNorm = 50.3614, GNorm = 0.4944, lr_0 = 3.7028e-04
Loss = 1.9875e-04, PNorm = 50.3692, GNorm = 0.3612, lr_0 = 3.6989e-04
Loss = 1.9540e-04, PNorm = 50.3747, GNorm = 0.2471, lr_0 = 3.6950e-04
Loss = 1.6845e-04, PNorm = 50.3834, GNorm = 0.2678, lr_0 = 3.6912e-04
Loss = 1.3619e-04, PNorm = 50.3860, GNorm = 0.2303, lr_0 = 3.6873e-04
Loss = 1.3646e-04, PNorm = 50.3900, GNorm = 0.2810, lr_0 = 3.6835e-04
Loss = 1.4312e-04, PNorm = 50.3962, GNorm = 0.2502, lr_0 = 3.6796e-04
Loss = 1.5457e-04, PNorm = 50.4023, GNorm = 0.3246, lr_0 = 3.6758e-04
Loss = 1.4190e-04, PNorm = 50.4085, GNorm = 0.3397, lr_0 = 3.6720e-04
Loss = 1.3864e-04, PNorm = 50.4150, GNorm = 0.2526, lr_0 = 3.6681e-04
Loss = 1.4471e-04, PNorm = 50.4216, GNorm = 0.2303, lr_0 = 3.6643e-04
Loss = 1.3924e-04, PNorm = 50.4264, GNorm = 0.2235, lr_0 = 3.6605e-04
Loss = 1.7958e-04, PNorm = 50.4311, GNorm = 0.2403, lr_0 = 3.6567e-04
Loss = 1.6653e-04, PNorm = 50.4375, GNorm = 0.2934, lr_0 = 3.6528e-04
Loss = 1.4059e-04, PNorm = 50.4470, GNorm = 0.1854, lr_0 = 3.6490e-04
Loss = 1.3252e-04, PNorm = 50.4542, GNorm = 0.2533, lr_0 = 3.6452e-04
Loss = 1.4075e-04, PNorm = 50.4581, GNorm = 0.4057, lr_0 = 3.6414e-04
Loss = 1.7964e-04, PNorm = 50.4641, GNorm = 0.4301, lr_0 = 3.6376e-04
Loss = 1.8769e-04, PNorm = 50.4693, GNorm = 0.3396, lr_0 = 3.6338e-04
Loss = 1.8043e-04, PNorm = 50.4748, GNorm = 0.3915, lr_0 = 3.6300e-04
Loss = 1.9144e-04, PNorm = 50.4828, GNorm = 0.3837, lr_0 = 3.6262e-04
Validation rmse logD = 0.564982
Validation R2 logD = 0.766900
Validation rmse logP = 0.455050
Validation R2 logP = 0.939924
Epoch 45
Train function
Loss = 1.3491e-04, PNorm = 50.4886, GNorm = 0.2741, lr_0 = 3.6221e-04
Loss = 1.4131e-04, PNorm = 50.4938, GNorm = 0.2396, lr_0 = 3.6183e-04
Loss = 1.1762e-04, PNorm = 50.4982, GNorm = 0.1640, lr_0 = 3.6145e-04
Loss = 1.3183e-04, PNorm = 50.5023, GNorm = 0.5011, lr_0 = 3.6107e-04
Loss = 1.1090e-04, PNorm = 50.5058, GNorm = 0.1434, lr_0 = 3.6070e-04
Loss = 1.2217e-04, PNorm = 50.5114, GNorm = 0.2378, lr_0 = 3.6032e-04
Loss = 1.3382e-04, PNorm = 50.5155, GNorm = 0.4653, lr_0 = 3.5994e-04
Loss = 1.4943e-04, PNorm = 50.5230, GNorm = 0.3321, lr_0 = 3.5957e-04
Loss = 2.0611e-04, PNorm = 50.5280, GNorm = 0.5003, lr_0 = 3.5919e-04
Loss = 1.8874e-04, PNorm = 50.5360, GNorm = 0.4525, lr_0 = 3.5882e-04
Loss = 1.5628e-04, PNorm = 50.5407, GNorm = 0.1875, lr_0 = 3.5844e-04
Loss = 1.5865e-04, PNorm = 50.5475, GNorm = 0.2930, lr_0 = 3.5807e-04
Loss = 1.2922e-04, PNorm = 50.5527, GNorm = 0.3291, lr_0 = 3.5770e-04
Loss = 1.4174e-04, PNorm = 50.5557, GNorm = 0.1572, lr_0 = 3.5732e-04
Loss = 1.3462e-04, PNorm = 50.5587, GNorm = 0.2610, lr_0 = 3.5695e-04
Loss = 1.8838e-04, PNorm = 50.5648, GNorm = 0.5183, lr_0 = 3.5658e-04
Loss = 1.4691e-04, PNorm = 50.5732, GNorm = 0.3205, lr_0 = 3.5621e-04
Loss = 1.3159e-04, PNorm = 50.5778, GNorm = 0.4039, lr_0 = 3.5583e-04
Loss = 1.4973e-04, PNorm = 50.5808, GNorm = 0.1662, lr_0 = 3.5546e-04
Loss = 1.4711e-04, PNorm = 50.5863, GNorm = 0.2561, lr_0 = 3.5509e-04
Loss = 1.2905e-04, PNorm = 50.5911, GNorm = 0.2136, lr_0 = 3.5472e-04
Loss = 1.5754e-04, PNorm = 50.5957, GNorm = 0.5697, lr_0 = 3.5435e-04
Loss = 1.8599e-04, PNorm = 50.6022, GNorm = 0.3356, lr_0 = 3.5398e-04
Validation rmse logD = 0.560461
Validation R2 logD = 0.770616
Validation rmse logP = 0.459222
Validation R2 logP = 0.938817
Epoch 46
Train function
Loss = 1.2620e-04, PNorm = 50.6062, GNorm = 0.1876, lr_0 = 3.5361e-04
Loss = 1.2142e-04, PNorm = 50.6101, GNorm = 0.2951, lr_0 = 3.5324e-04
Loss = 1.2598e-04, PNorm = 50.6155, GNorm = 0.2414, lr_0 = 3.5287e-04
Loss = 1.2132e-04, PNorm = 50.6213, GNorm = 0.2221, lr_0 = 3.5251e-04
Loss = 1.3541e-04, PNorm = 50.6257, GNorm = 0.3070, lr_0 = 3.5214e-04
Loss = 1.7374e-04, PNorm = 50.6286, GNorm = 0.2907, lr_0 = 3.5177e-04
Loss = 1.4124e-04, PNorm = 50.6316, GNorm = 0.2784, lr_0 = 3.5140e-04
Loss = 1.5592e-04, PNorm = 50.6372, GNorm = 0.1680, lr_0 = 3.5104e-04
Loss = 1.2758e-04, PNorm = 50.6429, GNorm = 0.2796, lr_0 = 3.5067e-04
Loss = 1.3575e-04, PNorm = 50.6458, GNorm = 0.3121, lr_0 = 3.5030e-04
Loss = 1.2188e-04, PNorm = 50.6527, GNorm = 0.3198, lr_0 = 3.4994e-04
Loss = 1.6552e-04, PNorm = 50.6587, GNorm = 0.2673, lr_0 = 3.4957e-04
Loss = 1.7749e-04, PNorm = 50.6655, GNorm = 0.4055, lr_0 = 3.4921e-04
Loss = 1.7980e-04, PNorm = 50.6722, GNorm = 0.4203, lr_0 = 3.4884e-04
Loss = 1.6831e-04, PNorm = 50.6768, GNorm = 0.3214, lr_0 = 3.4848e-04
Loss = 1.3167e-04, PNorm = 50.6817, GNorm = 0.1966, lr_0 = 3.4812e-04
Loss = 1.2067e-04, PNorm = 50.6881, GNorm = 0.3575, lr_0 = 3.4775e-04
Loss = 1.2320e-04, PNorm = 50.6938, GNorm = 0.2656, lr_0 = 3.4739e-04
Loss = 1.6309e-04, PNorm = 50.6994, GNorm = 0.3120, lr_0 = 3.4703e-04
Loss = 1.7037e-04, PNorm = 50.7052, GNorm = 0.2747, lr_0 = 3.4666e-04
Loss = 1.4386e-04, PNorm = 50.7125, GNorm = 0.2052, lr_0 = 3.4630e-04
Loss = 1.8973e-04, PNorm = 50.7173, GNorm = 0.2796, lr_0 = 3.4594e-04
Validation rmse logD = 0.559264
Validation R2 logD = 0.771594
Validation rmse logP = 0.451958
Validation R2 logP = 0.940738
Epoch 47
Train function
Loss = 1.5960e-04, PNorm = 50.7244, GNorm = 0.2001, lr_0 = 3.4554e-04
Loss = 1.2272e-04, PNorm = 50.7305, GNorm = 0.2854, lr_0 = 3.4518e-04
Loss = 1.2750e-04, PNorm = 50.7353, GNorm = 0.1618, lr_0 = 3.4482e-04
Loss = 1.0427e-04, PNorm = 50.7392, GNorm = 0.1487, lr_0 = 3.4446e-04
Loss = 1.1000e-04, PNorm = 50.7437, GNorm = 0.2738, lr_0 = 3.4410e-04
Loss = 1.1266e-04, PNorm = 50.7484, GNorm = 0.1700, lr_0 = 3.4374e-04
Loss = 1.1383e-04, PNorm = 50.7517, GNorm = 0.3367, lr_0 = 3.4339e-04
Loss = 9.2647e-05, PNorm = 50.7546, GNorm = 0.2264, lr_0 = 3.4303e-04
Loss = 1.2815e-04, PNorm = 50.7563, GNorm = 0.1942, lr_0 = 3.4267e-04
Loss = 1.2597e-04, PNorm = 50.7591, GNorm = 0.1968, lr_0 = 3.4231e-04
Loss = 1.2228e-04, PNorm = 50.7626, GNorm = 0.1863, lr_0 = 3.4195e-04
Loss = 1.1012e-04, PNorm = 50.7681, GNorm = 0.2257, lr_0 = 3.4160e-04
Loss = 1.1040e-04, PNorm = 50.7725, GNorm = 0.4026, lr_0 = 3.4124e-04
Loss = 1.4630e-04, PNorm = 50.7763, GNorm = 0.2584, lr_0 = 3.4088e-04
Loss = 2.0404e-04, PNorm = 50.7800, GNorm = 0.3227, lr_0 = 3.4053e-04
Loss = 1.5189e-04, PNorm = 50.7846, GNorm = 0.4778, lr_0 = 3.4017e-04
Loss = 1.2582e-04, PNorm = 50.7893, GNorm = 0.4156, lr_0 = 3.3982e-04
Loss = 1.4746e-04, PNorm = 50.7938, GNorm = 0.3443, lr_0 = 3.3946e-04
Loss = 1.5992e-04, PNorm = 50.8011, GNorm = 0.2994, lr_0 = 3.3911e-04
Loss = 1.2969e-04, PNorm = 50.8064, GNorm = 0.2240, lr_0 = 3.3876e-04
Loss = 1.1421e-04, PNorm = 50.8105, GNorm = 0.1842, lr_0 = 3.3840e-04
Loss = 1.3792e-04, PNorm = 50.8151, GNorm = 0.3938, lr_0 = 3.3805e-04
Loss = 1.2398e-04, PNorm = 50.8196, GNorm = 0.1981, lr_0 = 3.3770e-04
Validation rmse logD = 0.554313
Validation R2 logD = 0.775620
Validation rmse logP = 0.451239
Validation R2 logP = 0.940926
Epoch 48
Train function
Loss = 1.0679e-04, PNorm = 50.8239, GNorm = 0.1679, lr_0 = 3.3734e-04
Loss = 1.0616e-04, PNorm = 50.8286, GNorm = 0.1965, lr_0 = 3.3699e-04
Loss = 1.0398e-04, PNorm = 50.8316, GNorm = 0.2399, lr_0 = 3.3664e-04
Loss = 1.0201e-04, PNorm = 50.8351, GNorm = 0.3229, lr_0 = 3.3629e-04
Loss = 1.0770e-04, PNorm = 50.8410, GNorm = 0.1565, lr_0 = 3.3594e-04
Loss = 1.2160e-04, PNorm = 50.8460, GNorm = 0.3637, lr_0 = 3.3559e-04
Loss = 1.2009e-04, PNorm = 50.8511, GNorm = 0.2933, lr_0 = 3.3524e-04
Loss = 1.1435e-04, PNorm = 50.8543, GNorm = 0.3343, lr_0 = 3.3489e-04
Loss = 1.3452e-04, PNorm = 50.8591, GNorm = 0.2371, lr_0 = 3.3454e-04
Loss = 1.1371e-04, PNorm = 50.8656, GNorm = 0.1981, lr_0 = 3.3419e-04
Loss = 1.3309e-04, PNorm = 50.8729, GNorm = 0.2606, lr_0 = 3.3384e-04
Loss = 1.3361e-04, PNorm = 50.8775, GNorm = 0.3676, lr_0 = 3.3349e-04
Loss = 9.4959e-05, PNorm = 50.8816, GNorm = 0.2089, lr_0 = 3.3314e-04
Loss = 1.1932e-04, PNorm = 50.8837, GNorm = 0.1561, lr_0 = 3.3280e-04
Loss = 1.7197e-04, PNorm = 50.8882, GNorm = 0.3870, lr_0 = 3.3245e-04
Loss = 1.0964e-04, PNorm = 50.8899, GNorm = 0.1808, lr_0 = 3.3210e-04
Loss = 1.2417e-04, PNorm = 50.8959, GNorm = 0.2065, lr_0 = 3.3175e-04
Loss = 1.2784e-04, PNorm = 50.8980, GNorm = 0.3253, lr_0 = 3.3141e-04
Loss = 1.2554e-04, PNorm = 50.9028, GNorm = 0.2014, lr_0 = 3.3106e-04
Loss = 1.2761e-04, PNorm = 50.9064, GNorm = 0.2223, lr_0 = 3.3072e-04
Loss = 1.2762e-04, PNorm = 50.9136, GNorm = 0.3675, lr_0 = 3.3037e-04
Loss = 1.5602e-04, PNorm = 50.9223, GNorm = 0.2804, lr_0 = 3.3003e-04
Validation rmse logD = 0.562407
Validation R2 logD = 0.769019
Validation rmse logP = 0.451164
Validation R2 logP = 0.940945
Epoch 49
Train function
Loss = 1.1881e-04, PNorm = 50.9278, GNorm = 0.3215, lr_0 = 3.2965e-04
Loss = 1.2723e-04, PNorm = 50.9356, GNorm = 0.1317, lr_0 = 3.2930e-04
Loss = 1.3514e-04, PNorm = 50.9420, GNorm = 0.2023, lr_0 = 3.2896e-04
Loss = 1.1295e-04, PNorm = 50.9459, GNorm = 0.3698, lr_0 = 3.2862e-04
Loss = 1.0628e-04, PNorm = 50.9517, GNorm = 0.2207, lr_0 = 3.2827e-04
Loss = 9.7558e-05, PNorm = 50.9526, GNorm = 0.1979, lr_0 = 3.2793e-04
Loss = 1.0388e-04, PNorm = 50.9564, GNorm = 0.1843, lr_0 = 3.2759e-04
Loss = 9.9094e-05, PNorm = 50.9611, GNorm = 0.2182, lr_0 = 3.2725e-04
Loss = 8.9519e-05, PNorm = 50.9650, GNorm = 0.2650, lr_0 = 3.2691e-04
Loss = 1.1329e-04, PNorm = 50.9692, GNorm = 0.2221, lr_0 = 3.2656e-04
Loss = 1.2406e-04, PNorm = 50.9719, GNorm = 0.2077, lr_0 = 3.2622e-04
Loss = 1.0726e-04, PNorm = 50.9769, GNorm = 0.2672, lr_0 = 3.2588e-04
Loss = 1.1132e-04, PNorm = 50.9790, GNorm = 0.2512, lr_0 = 3.2554e-04
Loss = 1.1397e-04, PNorm = 50.9817, GNorm = 0.4028, lr_0 = 3.2520e-04
Loss = 9.9749e-05, PNorm = 50.9860, GNorm = 0.3522, lr_0 = 3.2486e-04
Loss = 9.4334e-05, PNorm = 50.9894, GNorm = 0.3528, lr_0 = 3.2452e-04
Loss = 1.2175e-04, PNorm = 50.9935, GNorm = 0.3206, lr_0 = 3.2419e-04
Loss = 1.2128e-04, PNorm = 50.9976, GNorm = 0.3200, lr_0 = 3.2385e-04
Loss = 1.7311e-04, PNorm = 51.0039, GNorm = 0.5529, lr_0 = 3.2351e-04
Loss = 1.4648e-04, PNorm = 51.0111, GNorm = 0.4102, lr_0 = 3.2317e-04
Loss = 2.0450e-04, PNorm = 51.0194, GNorm = 0.4115, lr_0 = 3.2283e-04
Loss = 1.5415e-04, PNorm = 51.0270, GNorm = 0.3177, lr_0 = 3.2250e-04
Loss = 2.0723e-04, PNorm = 51.0357, GNorm = 0.2005, lr_0 = 3.2216e-04
Validation rmse logD = 0.558551
Validation R2 logD = 0.772176
Validation rmse logP = 0.457827
Validation R2 logP = 0.939188
Epoch 50
Train function
Loss = 1.3988e-04, PNorm = 51.0421, GNorm = 0.3366, lr_0 = 3.2182e-04
Loss = 1.1276e-04, PNorm = 51.0467, GNorm = 0.2400, lr_0 = 3.2149e-04
Loss = 1.0651e-04, PNorm = 51.0515, GNorm = 0.1688, lr_0 = 3.2115e-04
Loss = 9.5789e-05, PNorm = 51.0544, GNorm = 0.2097, lr_0 = 3.2082e-04
Loss = 9.9248e-05, PNorm = 51.0539, GNorm = 0.2935, lr_0 = 3.2048e-04
Loss = 9.6756e-05, PNorm = 51.0563, GNorm = 0.2677, lr_0 = 3.2015e-04
Loss = 9.7232e-05, PNorm = 51.0582, GNorm = 0.2510, lr_0 = 3.1981e-04
Loss = 1.0049e-04, PNorm = 51.0626, GNorm = 0.1439, lr_0 = 3.1948e-04
Loss = 1.2504e-04, PNorm = 51.0682, GNorm = 0.4115, lr_0 = 3.1915e-04
Loss = 1.0287e-04, PNorm = 51.0729, GNorm = 0.1816, lr_0 = 3.1881e-04
Loss = 9.5616e-05, PNorm = 51.0751, GNorm = 0.1758, lr_0 = 3.1848e-04
Loss = 9.0904e-05, PNorm = 51.0772, GNorm = 0.2909, lr_0 = 3.1815e-04
Loss = 1.1020e-04, PNorm = 51.0807, GNorm = 0.2670, lr_0 = 3.1782e-04
Loss = 1.0153e-04, PNorm = 51.0856, GNorm = 0.2045, lr_0 = 3.1749e-04
Loss = 1.2069e-04, PNorm = 51.0901, GNorm = 0.1957, lr_0 = 3.1715e-04
Loss = 1.1675e-04, PNorm = 51.0950, GNorm = 0.2876, lr_0 = 3.1682e-04
Loss = 1.1231e-04, PNorm = 51.1013, GNorm = 0.2431, lr_0 = 3.1649e-04
Loss = 1.0881e-04, PNorm = 51.1039, GNorm = 0.2059, lr_0 = 3.1616e-04
Loss = 1.0052e-04, PNorm = 51.1067, GNorm = 0.1963, lr_0 = 3.1583e-04
Loss = 1.0995e-04, PNorm = 51.1125, GNorm = 0.2138, lr_0 = 3.1550e-04
Loss = 1.1048e-04, PNorm = 51.1190, GNorm = 0.2188, lr_0 = 3.1517e-04
Loss = 1.1079e-04, PNorm = 51.1235, GNorm = 0.3902, lr_0 = 3.1484e-04
Validation rmse logD = 0.552625
Validation R2 logD = 0.776985
Validation rmse logP = 0.449943
Validation R2 logP = 0.941265
Epoch 51
Train function
Loss = 1.0366e-04, PNorm = 51.1281, GNorm = 0.1838, lr_0 = 3.1448e-04
Loss = 7.7119e-05, PNorm = 51.1313, GNorm = 0.2280, lr_0 = 3.1415e-04
Loss = 9.7963e-05, PNorm = 51.1336, GNorm = 0.2108, lr_0 = 3.1383e-04
Loss = 1.1132e-04, PNorm = 51.1362, GNorm = 0.2369, lr_0 = 3.1350e-04
Loss = 1.3781e-04, PNorm = 51.1413, GNorm = 0.4371, lr_0 = 3.1317e-04
Loss = 1.3491e-04, PNorm = 51.1476, GNorm = 0.3208, lr_0 = 3.1284e-04
Loss = 1.2993e-04, PNorm = 51.1536, GNorm = 0.1720, lr_0 = 3.1252e-04
Loss = 1.1147e-04, PNorm = 51.1590, GNorm = 0.2969, lr_0 = 3.1219e-04
Loss = 1.5439e-04, PNorm = 51.1628, GNorm = 0.2789, lr_0 = 3.1187e-04
Loss = 1.2354e-04, PNorm = 51.1668, GNorm = 0.3356, lr_0 = 3.1154e-04
Loss = 1.4332e-04, PNorm = 51.1740, GNorm = 0.4390, lr_0 = 3.1122e-04
Loss = 1.2428e-04, PNorm = 51.1790, GNorm = 0.2963, lr_0 = 3.1089e-04
Loss = 1.2005e-04, PNorm = 51.1842, GNorm = 0.2307, lr_0 = 3.1057e-04
Loss = 1.2219e-04, PNorm = 51.1912, GNorm = 0.2189, lr_0 = 3.1024e-04
Loss = 1.1639e-04, PNorm = 51.1949, GNorm = 0.3321, lr_0 = 3.0992e-04
Loss = 1.0683e-04, PNorm = 51.2003, GNorm = 0.2112, lr_0 = 3.0959e-04
Loss = 1.0811e-04, PNorm = 51.2057, GNorm = 0.2393, lr_0 = 3.0927e-04
Loss = 9.0747e-05, PNorm = 51.2082, GNorm = 0.2821, lr_0 = 3.0895e-04
Loss = 1.1008e-04, PNorm = 51.2118, GNorm = 0.1924, lr_0 = 3.0863e-04
Loss = 1.0594e-04, PNorm = 51.2182, GNorm = 0.3593, lr_0 = 3.0830e-04
Loss = 1.3607e-04, PNorm = 51.2226, GNorm = 0.2633, lr_0 = 3.0798e-04
Loss = 1.3512e-04, PNorm = 51.2298, GNorm = 0.2561, lr_0 = 3.0766e-04
Loss = 1.5146e-04, PNorm = 51.2346, GNorm = 0.6157, lr_0 = 3.0734e-04
Validation rmse logD = 0.555371
Validation R2 logD = 0.774763
Validation rmse logP = 0.460928
Validation R2 logP = 0.938362
Epoch 52
Train function
Loss = 1.4149e-04, PNorm = 51.2398, GNorm = 0.3672, lr_0 = 3.0699e-04
Loss = 1.1917e-04, PNorm = 51.2443, GNorm = 0.2783, lr_0 = 3.0667e-04
Loss = 1.1852e-04, PNorm = 51.2492, GNorm = 0.2983, lr_0 = 3.0635e-04
Loss = 1.0012e-04, PNorm = 51.2538, GNorm = 0.1624, lr_0 = 3.0603e-04
Loss = 1.0243e-04, PNorm = 51.2581, GNorm = 0.2070, lr_0 = 3.0571e-04
Loss = 1.0095e-04, PNorm = 51.2601, GNorm = 0.2462, lr_0 = 3.0539e-04
Loss = 8.9865e-05, PNorm = 51.2626, GNorm = 0.1714, lr_0 = 3.0507e-04
Loss = 8.1513e-05, PNorm = 51.2646, GNorm = 0.2407, lr_0 = 3.0475e-04
Loss = 8.0592e-05, PNorm = 51.2691, GNorm = 0.1505, lr_0 = 3.0443e-04
Loss = 8.8447e-05, PNorm = 51.2736, GNorm = 0.2853, lr_0 = 3.0412e-04
Loss = 7.0208e-05, PNorm = 51.2775, GNorm = 0.1608, lr_0 = 3.0380e-04
Loss = 9.1096e-05, PNorm = 51.2802, GNorm = 0.1598, lr_0 = 3.0348e-04
Loss = 8.4843e-05, PNorm = 51.2821, GNorm = 0.2292, lr_0 = 3.0316e-04
Loss = 8.4231e-05, PNorm = 51.2865, GNorm = 0.3046, lr_0 = 3.0285e-04
Loss = 1.0421e-04, PNorm = 51.2905, GNorm = 0.1924, lr_0 = 3.0253e-04
Loss = 1.0132e-04, PNorm = 51.2962, GNorm = 0.2645, lr_0 = 3.0222e-04
Loss = 8.6818e-05, PNorm = 51.2992, GNorm = 0.1565, lr_0 = 3.0190e-04
Loss = 7.9561e-05, PNorm = 51.3029, GNorm = 0.2109, lr_0 = 3.0159e-04
Loss = 8.1853e-05, PNorm = 51.3064, GNorm = 0.1576, lr_0 = 3.0127e-04
Loss = 7.9807e-05, PNorm = 51.3103, GNorm = 0.2012, lr_0 = 3.0096e-04
Loss = 1.0360e-04, PNorm = 51.3120, GNorm = 0.1990, lr_0 = 3.0064e-04
Loss = 8.9434e-05, PNorm = 51.3171, GNorm = 0.2821, lr_0 = 3.0033e-04
Loss = 9.5762e-05, PNorm = 51.3191, GNorm = 0.2272, lr_0 = 3.0001e-04
Validation rmse logD = 0.552629
Validation R2 logD = 0.776981
Validation rmse logP = 0.447773
Validation R2 logP = 0.941830
Epoch 53
Train function
Loss = 8.5242e-05, PNorm = 51.3235, GNorm = 0.1349, lr_0 = 2.9970e-04
Loss = 6.4410e-05, PNorm = 51.3289, GNorm = 0.1587, lr_0 = 2.9939e-04
Loss = 7.7247e-05, PNorm = 51.3317, GNorm = 0.1762, lr_0 = 2.9908e-04
Loss = 6.6281e-05, PNorm = 51.3320, GNorm = 0.1768, lr_0 = 2.9876e-04
Loss = 7.3980e-05, PNorm = 51.3354, GNorm = 0.1539, lr_0 = 2.9845e-04
Loss = 8.2081e-05, PNorm = 51.3388, GNorm = 0.2097, lr_0 = 2.9814e-04
Loss = 8.4160e-05, PNorm = 51.3416, GNorm = 0.1885, lr_0 = 2.9783e-04
Loss = 7.9109e-05, PNorm = 51.3452, GNorm = 0.2738, lr_0 = 2.9752e-04
Loss = 8.3308e-05, PNorm = 51.3485, GNorm = 0.3061, lr_0 = 2.9721e-04
Loss = 7.4649e-05, PNorm = 51.3522, GNorm = 0.1028, lr_0 = 2.9690e-04
Loss = 9.0479e-05, PNorm = 51.3539, GNorm = 0.1358, lr_0 = 2.9659e-04
Loss = 9.1350e-05, PNorm = 51.3565, GNorm = 0.1877, lr_0 = 2.9628e-04
Loss = 1.0099e-04, PNorm = 51.3579, GNorm = 0.2312, lr_0 = 2.9597e-04
Loss = 7.2240e-05, PNorm = 51.3645, GNorm = 0.1070, lr_0 = 2.9566e-04
Loss = 7.4744e-05, PNorm = 51.3686, GNorm = 0.2597, lr_0 = 2.9535e-04
Loss = 8.9729e-05, PNorm = 51.3712, GNorm = 0.1766, lr_0 = 2.9504e-04
Loss = 7.5655e-05, PNorm = 51.3738, GNorm = 0.2213, lr_0 = 2.9474e-04
Loss = 8.8139e-05, PNorm = 51.3775, GNorm = 0.1978, lr_0 = 2.9443e-04
Loss = 1.0944e-04, PNorm = 51.3809, GNorm = 0.1426, lr_0 = 2.9412e-04
Loss = 1.1106e-04, PNorm = 51.3852, GNorm = 0.2717, lr_0 = 2.9381e-04
Loss = 9.6725e-05, PNorm = 51.3907, GNorm = 0.2505, lr_0 = 2.9351e-04
Loss = 8.7455e-05, PNorm = 51.3942, GNorm = 0.2200, lr_0 = 2.9320e-04
Validation rmse logD = 0.555565
Validation R2 logD = 0.774606
Validation rmse logP = 0.451887
Validation R2 logP = 0.940756
Epoch 54
Train function
Loss = 9.5780e-05, PNorm = 51.3975, GNorm = 0.1521, lr_0 = 2.9286e-04
Loss = 9.1968e-05, PNorm = 51.3991, GNorm = 0.2734, lr_0 = 2.9256e-04
Loss = 8.0209e-05, PNorm = 51.4023, GNorm = 0.2046, lr_0 = 2.9225e-04
Loss = 8.8624e-05, PNorm = 51.4053, GNorm = 0.1997, lr_0 = 2.9195e-04
Loss = 8.3984e-05, PNorm = 51.4096, GNorm = 0.1748, lr_0 = 2.9164e-04
Loss = 7.5806e-05, PNorm = 51.4141, GNorm = 0.1324, lr_0 = 2.9134e-04
Loss = 6.9605e-05, PNorm = 51.4177, GNorm = 0.1798, lr_0 = 2.9104e-04
Loss = 8.4543e-05, PNorm = 51.4196, GNorm = 0.3789, lr_0 = 2.9073e-04
Loss = 7.7469e-05, PNorm = 51.4220, GNorm = 0.2362, lr_0 = 2.9043e-04
Loss = 6.8760e-05, PNorm = 51.4255, GNorm = 0.1229, lr_0 = 2.9012e-04
Loss = 7.3676e-05, PNorm = 51.4299, GNorm = 0.2046, lr_0 = 2.8982e-04
Loss = 7.4491e-05, PNorm = 51.4336, GNorm = 0.1667, lr_0 = 2.8952e-04
Loss = 1.0001e-04, PNorm = 51.4359, GNorm = 0.1872, lr_0 = 2.8922e-04
Loss = 6.8313e-05, PNorm = 51.4370, GNorm = 0.2119, lr_0 = 2.8892e-04
Loss = 6.5783e-05, PNorm = 51.4403, GNorm = 0.2872, lr_0 = 2.8861e-04
Loss = 6.8829e-05, PNorm = 51.4421, GNorm = 0.1855, lr_0 = 2.8831e-04
Loss = 9.5894e-05, PNorm = 51.4421, GNorm = 0.1596, lr_0 = 2.8801e-04
Loss = 9.1218e-05, PNorm = 51.4433, GNorm = 0.2298, lr_0 = 2.8771e-04
Loss = 6.9410e-05, PNorm = 51.4474, GNorm = 0.1993, lr_0 = 2.8741e-04
Loss = 9.1797e-05, PNorm = 51.4501, GNorm = 0.3011, lr_0 = 2.8711e-04
Loss = 7.7709e-05, PNorm = 51.4545, GNorm = 0.2067, lr_0 = 2.8681e-04
Loss = 6.3764e-05, PNorm = 51.4585, GNorm = 0.2354, lr_0 = 2.8651e-04
Loss = 1.1367e-04, PNorm = 51.4640, GNorm = 0.3679, lr_0 = 2.8621e-04
Validation rmse logD = 0.554679
Validation R2 logD = 0.775324
Validation rmse logP = 0.450239
Validation R2 logP = 0.941187
Epoch 55
Train function
Loss = 8.3658e-05, PNorm = 51.4680, GNorm = 0.2650, lr_0 = 2.8591e-04
Loss = 7.5372e-05, PNorm = 51.4733, GNorm = 0.2280, lr_0 = 2.8562e-04
Loss = 6.3528e-05, PNorm = 51.4780, GNorm = 0.1680, lr_0 = 2.8532e-04
Loss = 5.8880e-05, PNorm = 51.4804, GNorm = 0.2171, lr_0 = 2.8502e-04
Loss = 7.7104e-05, PNorm = 51.4839, GNorm = 0.2101, lr_0 = 2.8472e-04
Loss = 7.7700e-05, PNorm = 51.4875, GNorm = 0.2569, lr_0 = 2.8443e-04
Loss = 7.7507e-05, PNorm = 51.4880, GNorm = 0.1914, lr_0 = 2.8413e-04
Loss = 8.4830e-05, PNorm = 51.4921, GNorm = 0.2155, lr_0 = 2.8383e-04
Loss = 1.0774e-04, PNorm = 51.4968, GNorm = 0.1986, lr_0 = 2.8354e-04
Loss = 8.3426e-05, PNorm = 51.5006, GNorm = 0.2296, lr_0 = 2.8324e-04
Loss = 1.0226e-04, PNorm = 51.5058, GNorm = 0.4000, lr_0 = 2.8294e-04
Loss = 6.8995e-05, PNorm = 51.5131, GNorm = 0.2047, lr_0 = 2.8265e-04
Loss = 9.3142e-05, PNorm = 51.5167, GNorm = 0.3532, lr_0 = 2.8235e-04
Loss = 9.7029e-05, PNorm = 51.5188, GNorm = 0.1993, lr_0 = 2.8206e-04
Loss = 7.5792e-05, PNorm = 51.5208, GNorm = 0.1419, lr_0 = 2.8176e-04
Loss = 6.1931e-05, PNorm = 51.5206, GNorm = 0.1830, lr_0 = 2.8147e-04
Loss = 8.7833e-05, PNorm = 51.5243, GNorm = 0.1172, lr_0 = 2.8118e-04
Loss = 7.8532e-05, PNorm = 51.5295, GNorm = 0.1258, lr_0 = 2.8088e-04
Loss = 7.2454e-05, PNorm = 51.5310, GNorm = 0.2177, lr_0 = 2.8059e-04
Loss = 6.6522e-05, PNorm = 51.5336, GNorm = 0.1972, lr_0 = 2.8030e-04
Loss = 7.1141e-05, PNorm = 51.5355, GNorm = 0.1257, lr_0 = 2.8000e-04
Loss = 8.3125e-05, PNorm = 51.5398, GNorm = 0.2212, lr_0 = 2.7971e-04
Validation rmse logD = 0.558916
Validation R2 logD = 0.771878
Validation rmse logP = 0.450893
Validation R2 logP = 0.941016
Epoch 56
Train function
Loss = 6.9511e-05, PNorm = 51.5439, GNorm = 0.1710, lr_0 = 2.7939e-04
Loss = 6.8329e-05, PNorm = 51.5451, GNorm = 0.1324, lr_0 = 2.7910e-04
Loss = 6.7905e-05, PNorm = 51.5466, GNorm = 0.1731, lr_0 = 2.7881e-04
Loss = 6.9652e-05, PNorm = 51.5492, GNorm = 0.3001, lr_0 = 2.7852e-04
Loss = 7.8528e-05, PNorm = 51.5533, GNorm = 0.1839, lr_0 = 2.7823e-04
Loss = 6.9481e-05, PNorm = 51.5557, GNorm = 0.1491, lr_0 = 2.7794e-04
Loss = 7.5869e-05, PNorm = 51.5579, GNorm = 0.2081, lr_0 = 2.7765e-04
Loss = 6.1641e-05, PNorm = 51.5595, GNorm = 0.1333, lr_0 = 2.7736e-04
Loss = 7.6187e-05, PNorm = 51.5636, GNorm = 0.3462, lr_0 = 2.7707e-04
Loss = 8.9291e-05, PNorm = 51.5689, GNorm = 0.2878, lr_0 = 2.7678e-04
Loss = 7.9170e-05, PNorm = 51.5738, GNorm = 0.2838, lr_0 = 2.7649e-04
Loss = 8.0092e-05, PNorm = 51.5761, GNorm = 0.2124, lr_0 = 2.7620e-04
Loss = 9.6122e-05, PNorm = 51.5794, GNorm = 0.1652, lr_0 = 2.7591e-04
Loss = 9.1880e-05, PNorm = 51.5813, GNorm = 0.1787, lr_0 = 2.7562e-04
Loss = 7.0029e-05, PNorm = 51.5852, GNorm = 0.1693, lr_0 = 2.7534e-04
Loss = 8.3514e-05, PNorm = 51.5893, GNorm = 0.1690, lr_0 = 2.7505e-04
Loss = 9.9471e-05, PNorm = 51.5930, GNorm = 0.1864, lr_0 = 2.7476e-04
Loss = 7.5045e-05, PNorm = 51.5977, GNorm = 0.2120, lr_0 = 2.7448e-04
Loss = 8.8012e-05, PNorm = 51.6026, GNorm = 0.1539, lr_0 = 2.7419e-04
Loss = 1.2295e-04, PNorm = 51.6070, GNorm = 0.3390, lr_0 = 2.7390e-04
Loss = 1.0492e-04, PNorm = 51.6096, GNorm = 0.3821, lr_0 = 2.7362e-04
Loss = 1.1584e-04, PNorm = 51.6135, GNorm = 0.2143, lr_0 = 2.7333e-04
Loss = 9.1636e-05, PNorm = 51.6169, GNorm = 0.1793, lr_0 = 2.7305e-04
Validation rmse logD = 0.553483
Validation R2 logD = 0.776292
Validation rmse logP = 0.450686
Validation R2 logP = 0.941070
Epoch 57
Train function
Loss = 7.7814e-05, PNorm = 51.6202, GNorm = 0.2947, lr_0 = 2.7276e-04
Loss = 7.1835e-05, PNorm = 51.6256, GNorm = 0.1483, lr_0 = 2.7248e-04
Loss = 1.1072e-04, PNorm = 51.6296, GNorm = 0.5898, lr_0 = 2.7219e-04
Loss = 8.1486e-05, PNorm = 51.6352, GNorm = 0.4811, lr_0 = 2.7191e-04
Loss = 7.3196e-05, PNorm = 51.6390, GNorm = 0.1470, lr_0 = 2.7162e-04
Loss = 6.6266e-05, PNorm = 51.6404, GNorm = 0.1622, lr_0 = 2.7134e-04
Loss = 5.7509e-05, PNorm = 51.6432, GNorm = 0.0816, lr_0 = 2.7106e-04
Loss = 7.3852e-05, PNorm = 51.6472, GNorm = 0.2184, lr_0 = 2.7077e-04
Loss = 8.0901e-05, PNorm = 51.6509, GNorm = 0.2135, lr_0 = 2.7049e-04
Loss = 6.3061e-05, PNorm = 51.6556, GNorm = 0.1295, lr_0 = 2.7021e-04
Loss = 7.2254e-05, PNorm = 51.6575, GNorm = 0.1259, lr_0 = 2.6993e-04
Loss = 8.0707e-05, PNorm = 51.6588, GNorm = 0.1996, lr_0 = 2.6965e-04
Loss = 8.6472e-05, PNorm = 51.6607, GNorm = 0.2825, lr_0 = 2.6936e-04
Loss = 7.3777e-05, PNorm = 51.6651, GNorm = 0.2121, lr_0 = 2.6908e-04
Loss = 8.7290e-05, PNorm = 51.6682, GNorm = 0.2262, lr_0 = 2.6880e-04
Loss = 7.0043e-05, PNorm = 51.6705, GNorm = 0.1244, lr_0 = 2.6852e-04
Loss = 8.0946e-05, PNorm = 51.6744, GNorm = 0.2165, lr_0 = 2.6824e-04
Loss = 6.5566e-05, PNorm = 51.6788, GNorm = 0.1694, lr_0 = 2.6796e-04
Loss = 6.8398e-05, PNorm = 51.6797, GNorm = 0.1672, lr_0 = 2.6768e-04
Loss = 7.5915e-05, PNorm = 51.6813, GNorm = 0.2732, lr_0 = 2.6740e-04
Loss = 9.8014e-05, PNorm = 51.6857, GNorm = 0.6215, lr_0 = 2.6712e-04
Loss = 9.4885e-05, PNorm = 51.6898, GNorm = 0.2908, lr_0 = 2.6684e-04
Validation rmse logD = 0.557028
Validation R2 logD = 0.773417
Validation rmse logP = 0.456744
Validation R2 logP = 0.939476
Epoch 58
Train function
Loss = 9.7396e-05, PNorm = 51.6939, GNorm = 0.2546, lr_0 = 2.6654e-04
Loss = 6.9473e-05, PNorm = 51.6993, GNorm = 0.2575, lr_0 = 2.6626e-04
Loss = 8.9049e-05, PNorm = 51.7042, GNorm = 0.2358, lr_0 = 2.6598e-04
Loss = 9.4803e-05, PNorm = 51.7070, GNorm = 0.3998, lr_0 = 2.6570e-04
Loss = 5.9825e-05, PNorm = 51.7073, GNorm = 0.1247, lr_0 = 2.6543e-04
Loss = 5.9475e-05, PNorm = 51.7090, GNorm = 0.2335, lr_0 = 2.6515e-04
Loss = 6.9501e-05, PNorm = 51.7127, GNorm = 0.1504, lr_0 = 2.6487e-04
Loss = 5.8628e-05, PNorm = 51.7146, GNorm = 0.1110, lr_0 = 2.6460e-04
Loss = 6.5317e-05, PNorm = 51.7153, GNorm = 0.2559, lr_0 = 2.6432e-04
Loss = 6.0998e-05, PNorm = 51.7170, GNorm = 0.1171, lr_0 = 2.6405e-04
Loss = 6.0083e-05, PNorm = 51.7193, GNorm = 0.1855, lr_0 = 2.6377e-04
Loss = 6.0402e-05, PNorm = 51.7242, GNorm = 0.2670, lr_0 = 2.6349e-04
Loss = 6.8394e-05, PNorm = 51.7277, GNorm = 0.1946, lr_0 = 2.6322e-04
Loss = 6.4796e-05, PNorm = 51.7314, GNorm = 0.1140, lr_0 = 2.6294e-04
Loss = 8.3009e-05, PNorm = 51.7329, GNorm = 0.3351, lr_0 = 2.6267e-04
Loss = 7.6892e-05, PNorm = 51.7360, GNorm = 0.3402, lr_0 = 2.6240e-04
Loss = 7.7306e-05, PNorm = 51.7392, GNorm = 0.2067, lr_0 = 2.6212e-04
Loss = 9.3949e-05, PNorm = 51.7442, GNorm = 0.4269, lr_0 = 2.6185e-04
Loss = 7.7720e-05, PNorm = 51.7492, GNorm = 0.2062, lr_0 = 2.6158e-04
Loss = 8.4050e-05, PNorm = 51.7536, GNorm = 0.2708, lr_0 = 2.6130e-04
Loss = 1.0419e-04, PNorm = 51.7558, GNorm = 0.2366, lr_0 = 2.6103e-04
Loss = 7.8167e-05, PNorm = 51.7600, GNorm = 0.2162, lr_0 = 2.6076e-04
Loss = 7.2005e-05, PNorm = 51.7631, GNorm = 0.1404, lr_0 = 2.6048e-04
Validation rmse logD = 0.556336
Validation R2 logD = 0.773980
Validation rmse logP = 0.448844
Validation R2 logP = 0.941551
Epoch 59
Train function
Loss = 6.7227e-05, PNorm = 51.7650, GNorm = 0.1939, lr_0 = 2.6021e-04
Loss = 8.0487e-05, PNorm = 51.7677, GNorm = 0.1798, lr_0 = 2.5994e-04
Loss = 6.8934e-05, PNorm = 51.7732, GNorm = 0.1709, lr_0 = 2.5967e-04
Loss = 5.7764e-05, PNorm = 51.7786, GNorm = 0.0941, lr_0 = 2.5940e-04
Loss = 6.4312e-05, PNorm = 51.7805, GNorm = 0.2854, lr_0 = 2.5913e-04
Loss = 5.4261e-05, PNorm = 51.7825, GNorm = 0.1265, lr_0 = 2.5886e-04
Loss = 6.8672e-05, PNorm = 51.7862, GNorm = 0.3124, lr_0 = 2.5859e-04
Loss = 7.6298e-05, PNorm = 51.7882, GNorm = 0.1875, lr_0 = 2.5832e-04
Loss = 7.3350e-05, PNorm = 51.7908, GNorm = 0.2127, lr_0 = 2.5805e-04
Loss = 7.8677e-05, PNorm = 51.7926, GNorm = 0.2338, lr_0 = 2.5778e-04
Loss = 6.9622e-05, PNorm = 51.7927, GNorm = 0.3532, lr_0 = 2.5751e-04
Loss = 5.6185e-05, PNorm = 51.7945, GNorm = 0.1191, lr_0 = 2.5724e-04
Loss = 5.7312e-05, PNorm = 51.7966, GNorm = 0.1968, lr_0 = 2.5697e-04
Loss = 5.8726e-05, PNorm = 51.8013, GNorm = 0.2283, lr_0 = 2.5670e-04
Loss = 7.3698e-05, PNorm = 51.8044, GNorm = 0.2220, lr_0 = 2.5644e-04
Loss = 7.7116e-05, PNorm = 51.8071, GNorm = 0.1867, lr_0 = 2.5617e-04
Loss = 7.8397e-05, PNorm = 51.8090, GNorm = 0.1660, lr_0 = 2.5590e-04
Loss = 6.7266e-05, PNorm = 51.8119, GNorm = 0.1804, lr_0 = 2.5563e-04
Loss = 5.4155e-05, PNorm = 51.8134, GNorm = 0.1268, lr_0 = 2.5537e-04
Loss = 6.2300e-05, PNorm = 51.8164, GNorm = 0.1160, lr_0 = 2.5510e-04
Loss = 7.1141e-05, PNorm = 51.8195, GNorm = 0.2524, lr_0 = 2.5483e-04
Loss = 6.7012e-05, PNorm = 51.8203, GNorm = 0.2279, lr_0 = 2.5457e-04
Validation rmse logD = 0.554443
Validation R2 logD = 0.775515
Validation rmse logP = 0.446725
Validation R2 logP = 0.942102
Epoch 60
Train function
Loss = 5.2404e-05, PNorm = 51.8241, GNorm = 0.1129, lr_0 = 2.5428e-04
Loss = 5.8664e-05, PNorm = 51.8271, GNorm = 0.1489, lr_0 = 2.5401e-04
Loss = 7.3140e-05, PNorm = 51.8302, GNorm = 0.3342, lr_0 = 2.5375e-04
Loss = 6.7458e-05, PNorm = 51.8332, GNorm = 0.1205, lr_0 = 2.5348e-04
Loss = 5.5794e-05, PNorm = 51.8366, GNorm = 0.1229, lr_0 = 2.5322e-04
Loss = 5.9763e-05, PNorm = 51.8401, GNorm = 0.1669, lr_0 = 2.5295e-04
Loss = 5.0907e-05, PNorm = 51.8426, GNorm = 0.0988, lr_0 = 2.5269e-04
Loss = 6.6350e-05, PNorm = 51.8450, GNorm = 0.1575, lr_0 = 2.5242e-04
Loss = 5.2305e-05, PNorm = 51.8478, GNorm = 0.1188, lr_0 = 2.5216e-04
Loss = 5.2409e-05, PNorm = 51.8498, GNorm = 0.1779, lr_0 = 2.5190e-04
Loss = 6.3905e-05, PNorm = 51.8489, GNorm = 0.1973, lr_0 = 2.5163e-04
Loss = 6.3732e-05, PNorm = 51.8514, GNorm = 0.3273, lr_0 = 2.5137e-04
Loss = 5.9738e-05, PNorm = 51.8534, GNorm = 0.1197, lr_0 = 2.5111e-04
Loss = 5.8464e-05, PNorm = 51.8559, GNorm = 0.1799, lr_0 = 2.5085e-04
Loss = 5.7296e-05, PNorm = 51.8595, GNorm = 0.1449, lr_0 = 2.5059e-04
Loss = 6.5673e-05, PNorm = 51.8602, GNorm = 0.1554, lr_0 = 2.5032e-04
Loss = 5.8618e-05, PNorm = 51.8639, GNorm = 0.2230, lr_0 = 2.5006e-04
Loss = 7.7457e-05, PNorm = 51.8677, GNorm = 0.2099, lr_0 = 2.4980e-04
Loss = 5.9919e-05, PNorm = 51.8730, GNorm = 0.1063, lr_0 = 2.4954e-04
Loss = 6.9131e-05, PNorm = 51.8777, GNorm = 0.2987, lr_0 = 2.4928e-04
Loss = 7.5153e-05, PNorm = 51.8802, GNorm = 0.1911, lr_0 = 2.4902e-04
Loss = 7.6885e-05, PNorm = 51.8841, GNorm = 0.2613, lr_0 = 2.4876e-04
Loss = 8.2731e-05, PNorm = 51.8890, GNorm = 0.1930, lr_0 = 2.4850e-04
Validation rmse logD = 0.564916
Validation R2 logD = 0.766954
Validation rmse logP = 0.457116
Validation R2 logP = 0.939377
Epoch 61
Train function
Loss = 9.6406e-05, PNorm = 51.8943, GNorm = 0.2055, lr_0 = 2.4824e-04
Loss = 9.0320e-05, PNorm = 51.8979, GNorm = 0.1756, lr_0 = 2.4798e-04
Loss = 6.3770e-05, PNorm = 51.9032, GNorm = 0.2803, lr_0 = 2.4772e-04
Loss = 6.2594e-05, PNorm = 51.9068, GNorm = 0.2625, lr_0 = 2.4747e-04
Loss = 5.7719e-05, PNorm = 51.9085, GNorm = 0.2120, lr_0 = 2.4721e-04
Loss = 5.1238e-05, PNorm = 51.9087, GNorm = 0.1620, lr_0 = 2.4695e-04
Loss = 4.4308e-05, PNorm = 51.9105, GNorm = 0.2023, lr_0 = 2.4669e-04
Loss = 7.6474e-05, PNorm = 51.9123, GNorm = 0.2435, lr_0 = 2.4643e-04
Loss = 6.5030e-05, PNorm = 51.9145, GNorm = 0.2993, lr_0 = 2.4618e-04
Loss = 6.1395e-05, PNorm = 51.9166, GNorm = 0.1477, lr_0 = 2.4592e-04
Loss = 5.9913e-05, PNorm = 51.9186, GNorm = 0.2319, lr_0 = 2.4566e-04
Loss = 4.9890e-05, PNorm = 51.9206, GNorm = 0.0982, lr_0 = 2.4541e-04
Loss = 5.9732e-05, PNorm = 51.9245, GNorm = 0.1878, lr_0 = 2.4515e-04
Loss = 7.0924e-05, PNorm = 51.9282, GNorm = 0.1717, lr_0 = 2.4489e-04
Loss = 5.8468e-05, PNorm = 51.9310, GNorm = 0.1213, lr_0 = 2.4464e-04
Loss = 5.7966e-05, PNorm = 51.9341, GNorm = 0.1577, lr_0 = 2.4438e-04
Loss = 6.0454e-05, PNorm = 51.9377, GNorm = 0.1832, lr_0 = 2.4413e-04
Loss = 5.4655e-05, PNorm = 51.9409, GNorm = 0.1665, lr_0 = 2.4387e-04
Loss = 6.2367e-05, PNorm = 51.9419, GNorm = 0.2269, lr_0 = 2.4362e-04
Loss = 6.2487e-05, PNorm = 51.9447, GNorm = 0.3692, lr_0 = 2.4337e-04
Loss = 8.1100e-05, PNorm = 51.9471, GNorm = 0.2181, lr_0 = 2.4311e-04
Loss = 8.1095e-05, PNorm = 51.9475, GNorm = 0.2821, lr_0 = 2.4286e-04
Validation rmse logD = 0.556116
Validation R2 logD = 0.774158
Validation rmse logP = 0.452796
Validation R2 logP = 0.940517
Epoch 62
Train function
Loss = 6.0083e-05, PNorm = 51.9506, GNorm = 0.2316, lr_0 = 2.4258e-04
Loss = 6.2037e-05, PNorm = 51.9532, GNorm = 0.1743, lr_0 = 2.4233e-04
Loss = 7.1456e-05, PNorm = 51.9564, GNorm = 0.2743, lr_0 = 2.4207e-04
Loss = 8.0697e-05, PNorm = 51.9600, GNorm = 0.1610, lr_0 = 2.4182e-04
Loss = 6.5242e-05, PNorm = 51.9623, GNorm = 0.1775, lr_0 = 2.4157e-04
Loss = 5.8358e-05, PNorm = 51.9653, GNorm = 0.1465, lr_0 = 2.4132e-04
Loss = 6.1252e-05, PNorm = 51.9698, GNorm = 0.2227, lr_0 = 2.4106e-04
Loss = 5.3978e-05, PNorm = 51.9728, GNorm = 0.2848, lr_0 = 2.4081e-04
Loss = 5.5825e-05, PNorm = 51.9758, GNorm = 0.1563, lr_0 = 2.4056e-04
Loss = 4.5593e-05, PNorm = 51.9782, GNorm = 0.0908, lr_0 = 2.4031e-04
Loss = 5.5965e-05, PNorm = 51.9802, GNorm = 0.1769, lr_0 = 2.4006e-04
Loss = 5.4586e-05, PNorm = 51.9845, GNorm = 0.2006, lr_0 = 2.3981e-04
Loss = 5.7030e-05, PNorm = 51.9878, GNorm = 0.1363, lr_0 = 2.3956e-04
Loss = 5.2202e-05, PNorm = 51.9876, GNorm = 0.1616, lr_0 = 2.3931e-04
Loss = 4.8863e-05, PNorm = 51.9904, GNorm = 0.2094, lr_0 = 2.3906e-04
Loss = 5.7916e-05, PNorm = 51.9933, GNorm = 0.1788, lr_0 = 2.3881e-04
Loss = 4.5999e-05, PNorm = 51.9960, GNorm = 0.1267, lr_0 = 2.3856e-04
Loss = 7.2379e-05, PNorm = 51.9984, GNorm = 0.1312, lr_0 = 2.3831e-04
Loss = 6.4395e-05, PNorm = 51.9995, GNorm = 0.3477, lr_0 = 2.3806e-04
Loss = 7.3496e-05, PNorm = 52.0008, GNorm = 0.1441, lr_0 = 2.3781e-04
Loss = 6.1447e-05, PNorm = 52.0052, GNorm = 0.3715, lr_0 = 2.3756e-04
Loss = 5.8813e-05, PNorm = 52.0080, GNorm = 0.1368, lr_0 = 2.3732e-04
Loss = 5.0087e-05, PNorm = 52.0099, GNorm = 0.1067, lr_0 = 2.3707e-04
Validation rmse logD = 0.558977
Validation R2 logD = 0.771829
Validation rmse logP = 0.449769
Validation R2 logP = 0.941310
Epoch 63
Train function
Loss = 5.8305e-05, PNorm = 52.0132, GNorm = 0.1548, lr_0 = 2.3682e-04
Loss = 6.7364e-05, PNorm = 52.0163, GNorm = 0.2932, lr_0 = 2.3657e-04
Loss = 5.6727e-05, PNorm = 52.0192, GNorm = 0.1468, lr_0 = 2.3633e-04
Loss = 5.0872e-05, PNorm = 52.0224, GNorm = 0.1900, lr_0 = 2.3608e-04
Loss = 6.7067e-05, PNorm = 52.0239, GNorm = 0.2645, lr_0 = 2.3583e-04
Loss = 4.8174e-05, PNorm = 52.0264, GNorm = 0.1553, lr_0 = 2.3559e-04
Loss = 5.5821e-05, PNorm = 52.0272, GNorm = 0.1582, lr_0 = 2.3534e-04
Loss = 5.1044e-05, PNorm = 52.0295, GNorm = 0.1399, lr_0 = 2.3510e-04
Loss = 5.3630e-05, PNorm = 52.0317, GNorm = 0.1664, lr_0 = 2.3485e-04
Loss = 4.4759e-05, PNorm = 52.0345, GNorm = 0.1306, lr_0 = 2.3461e-04
Loss = 4.5290e-05, PNorm = 52.0338, GNorm = 0.1299, lr_0 = 2.3436e-04
Loss = 5.4536e-05, PNorm = 52.0363, GNorm = 0.1796, lr_0 = 2.3412e-04
Loss = 5.0955e-05, PNorm = 52.0384, GNorm = 0.1789, lr_0 = 2.3387e-04
Loss = 5.0826e-05, PNorm = 52.0403, GNorm = 0.2318, lr_0 = 2.3363e-04
Loss = 6.2170e-05, PNorm = 52.0419, GNorm = 0.1693, lr_0 = 2.3338e-04
Loss = 4.8438e-05, PNorm = 52.0438, GNorm = 0.2093, lr_0 = 2.3314e-04
Loss = 4.5415e-05, PNorm = 52.0456, GNorm = 0.0992, lr_0 = 2.3290e-04
Loss = 5.3038e-05, PNorm = 52.0470, GNorm = 0.1382, lr_0 = 2.3265e-04
Loss = 4.6765e-05, PNorm = 52.0475, GNorm = 0.1422, lr_0 = 2.3241e-04
Loss = 5.1606e-05, PNorm = 52.0502, GNorm = 0.1357, lr_0 = 2.3217e-04
Loss = 5.6627e-05, PNorm = 52.0530, GNorm = 0.1117, lr_0 = 2.3193e-04
Loss = 5.0198e-05, PNorm = 52.0545, GNorm = 0.1817, lr_0 = 2.3169e-04
Loss = 5.2095e-05, PNorm = 52.0562, GNorm = 0.2911, lr_0 = 2.3144e-04
Loss = 1.1017e-04, PNorm = 52.0563, GNorm = 0.2223, lr_0 = 2.3142e-04
Validation rmse logD = 0.556390
Validation R2 logD = 0.773936
Validation rmse logP = 0.450551
Validation R2 logP = 0.941106
Epoch 64
Train function
Loss = 3.8322e-05, PNorm = 52.0595, GNorm = 0.1947, lr_0 = 2.3118e-04
Loss = 5.5815e-05, PNorm = 52.0622, GNorm = 0.1282, lr_0 = 2.3094e-04
Loss = 5.1669e-05, PNorm = 52.0642, GNorm = 0.1847, lr_0 = 2.3070e-04
Loss = 5.0200e-05, PNorm = 52.0673, GNorm = 0.1938, lr_0 = 2.3045e-04
Loss = 4.3578e-05, PNorm = 52.0701, GNorm = 0.1072, lr_0 = 2.3021e-04
Loss = 4.1327e-05, PNorm = 52.0724, GNorm = 0.1025, lr_0 = 2.2997e-04
Loss = 4.9444e-05, PNorm = 52.0759, GNorm = 0.1433, lr_0 = 2.2973e-04
Loss = 3.7046e-05, PNorm = 52.0796, GNorm = 0.1174, lr_0 = 2.2949e-04
Loss = 4.0235e-05, PNorm = 52.0814, GNorm = 0.1515, lr_0 = 2.2925e-04
Loss = 3.7469e-05, PNorm = 52.0829, GNorm = 0.1794, lr_0 = 2.2902e-04
Loss = 3.4733e-05, PNorm = 52.0856, GNorm = 0.2335, lr_0 = 2.2878e-04
Loss = 4.9238e-05, PNorm = 52.0864, GNorm = 0.1619, lr_0 = 2.2854e-04
Loss = 5.2285e-05, PNorm = 52.0884, GNorm = 0.3016, lr_0 = 2.2830e-04
Loss = 6.4609e-05, PNorm = 52.0906, GNorm = 0.1795, lr_0 = 2.2806e-04
Loss = 6.1588e-05, PNorm = 52.0943, GNorm = 0.3256, lr_0 = 2.2782e-04
Loss = 4.5580e-05, PNorm = 52.0982, GNorm = 0.1505, lr_0 = 2.2758e-04
Loss = 5.6010e-05, PNorm = 52.0984, GNorm = 0.2300, lr_0 = 2.2735e-04
Loss = 6.4654e-05, PNorm = 52.0986, GNorm = 0.2214, lr_0 = 2.2711e-04
Loss = 5.7849e-05, PNorm = 52.1014, GNorm = 0.2250, lr_0 = 2.2687e-04
Loss = 5.5890e-05, PNorm = 52.1026, GNorm = 0.1660, lr_0 = 2.2664e-04
Loss = 6.8303e-05, PNorm = 52.1048, GNorm = 0.2672, lr_0 = 2.2640e-04
Loss = 5.2068e-05, PNorm = 52.1053, GNorm = 0.1586, lr_0 = 2.2616e-04
Validation rmse logD = 0.555639
Validation R2 logD = 0.774545
Validation rmse logP = 0.448962
Validation R2 logP = 0.941521
Epoch 65
Train function
Loss = 3.8620e-05, PNorm = 52.1073, GNorm = 0.1176, lr_0 = 2.2593e-04
Loss = 5.7382e-05, PNorm = 52.1120, GNorm = 0.1013, lr_0 = 2.2569e-04
Loss = 4.5109e-05, PNorm = 52.1137, GNorm = 0.1296, lr_0 = 2.2546e-04
Loss = 4.4364e-05, PNorm = 52.1156, GNorm = 0.2487, lr_0 = 2.2522e-04
Loss = 5.5999e-05, PNorm = 52.1176, GNorm = 0.1835, lr_0 = 2.2499e-04
Loss = 5.5785e-05, PNorm = 52.1210, GNorm = 0.1858, lr_0 = 2.2475e-04
Loss = 4.6994e-05, PNorm = 52.1246, GNorm = 0.1334, lr_0 = 2.2452e-04
Loss = 4.7289e-05, PNorm = 52.1255, GNorm = 0.2138, lr_0 = 2.2428e-04
Loss = 4.8051e-05, PNorm = 52.1283, GNorm = 0.1322, lr_0 = 2.2405e-04
Loss = 4.1091e-05, PNorm = 52.1302, GNorm = 0.1581, lr_0 = 2.2381e-04
Loss = 5.0813e-05, PNorm = 52.1319, GNorm = 0.1046, lr_0 = 2.2358e-04
Loss = 4.3434e-05, PNorm = 52.1331, GNorm = 0.1634, lr_0 = 2.2335e-04
Loss = 4.1835e-05, PNorm = 52.1352, GNorm = 0.1529, lr_0 = 2.2311e-04
Loss = 4.7769e-05, PNorm = 52.1386, GNorm = 0.1122, lr_0 = 2.2288e-04
Loss = 4.7079e-05, PNorm = 52.1407, GNorm = 0.1715, lr_0 = 2.2265e-04
Loss = 4.8350e-05, PNorm = 52.1422, GNorm = 0.1729, lr_0 = 2.2242e-04
Loss = 4.5357e-05, PNorm = 52.1438, GNorm = 0.1610, lr_0 = 2.2218e-04
Loss = 6.2255e-05, PNorm = 52.1450, GNorm = 0.1397, lr_0 = 2.2195e-04
Loss = 5.3196e-05, PNorm = 52.1466, GNorm = 0.1492, lr_0 = 2.2172e-04
Loss = 5.2682e-05, PNorm = 52.1465, GNorm = 0.1907, lr_0 = 2.2149e-04
Loss = 4.7601e-05, PNorm = 52.1479, GNorm = 0.1955, lr_0 = 2.2126e-04
Loss = 4.7809e-05, PNorm = 52.1504, GNorm = 0.1744, lr_0 = 2.2103e-04
Loss = 4.4225e-05, PNorm = 52.1523, GNorm = 0.2057, lr_0 = 2.2080e-04
Validation rmse logD = 0.558872
Validation R2 logD = 0.771914
Validation rmse logP = 0.448509
Validation R2 logP = 0.941638
Epoch 66
Train function
Loss = 5.4220e-05, PNorm = 52.1566, GNorm = 0.1583, lr_0 = 2.2054e-04
Loss = 4.3599e-05, PNorm = 52.1583, GNorm = 0.1401, lr_0 = 2.2031e-04
Loss = 4.5962e-05, PNorm = 52.1624, GNorm = 0.1572, lr_0 = 2.2008e-04
Loss = 4.2228e-05, PNorm = 52.1657, GNorm = 0.1988, lr_0 = 2.1985e-04
Loss = 5.6635e-05, PNorm = 52.1682, GNorm = 0.1610, lr_0 = 2.1962e-04
Loss = 5.2201e-05, PNorm = 52.1704, GNorm = 0.2364, lr_0 = 2.1939e-04
Loss = 7.1810e-05, PNorm = 52.1726, GNorm = 0.3978, lr_0 = 2.1916e-04
Loss = 6.9655e-05, PNorm = 52.1739, GNorm = 0.3433, lr_0 = 2.1894e-04
Loss = 5.0822e-05, PNorm = 52.1747, GNorm = 0.1121, lr_0 = 2.1871e-04
Loss = 5.9149e-05, PNorm = 52.1766, GNorm = 0.3852, lr_0 = 2.1848e-04
Loss = 6.7322e-05, PNorm = 52.1802, GNorm = 0.2185, lr_0 = 2.1825e-04
Loss = 6.1175e-05, PNorm = 52.1820, GNorm = 0.2437, lr_0 = 2.1802e-04
Loss = 5.9014e-05, PNorm = 52.1841, GNorm = 0.1803, lr_0 = 2.1780e-04
Loss = 5.4202e-05, PNorm = 52.1871, GNorm = 0.1386, lr_0 = 2.1757e-04
Loss = 4.0862e-05, PNorm = 52.1895, GNorm = 0.1442, lr_0 = 2.1734e-04
Loss = 5.6032e-05, PNorm = 52.1909, GNorm = 0.1440, lr_0 = 2.1711e-04
Loss = 6.2897e-05, PNorm = 52.1928, GNorm = 0.3352, lr_0 = 2.1689e-04
Loss = 5.3525e-05, PNorm = 52.1956, GNorm = 0.2772, lr_0 = 2.1666e-04
Loss = 4.8421e-05, PNorm = 52.1981, GNorm = 0.1457, lr_0 = 2.1644e-04
Loss = 5.0166e-05, PNorm = 52.2009, GNorm = 0.1505, lr_0 = 2.1621e-04
Loss = 4.3034e-05, PNorm = 52.2034, GNorm = 0.1077, lr_0 = 2.1598e-04
Loss = 5.0317e-05, PNorm = 52.2063, GNorm = 0.0902, lr_0 = 2.1576e-04
Validation rmse logD = 0.557838
Validation R2 logD = 0.772757
Validation rmse logP = 0.448551
Validation R2 logP = 0.941628
Epoch 67
Train function
Loss = 3.7933e-05, PNorm = 52.2082, GNorm = 0.1678, lr_0 = 2.1553e-04
Loss = 5.1352e-05, PNorm = 52.2092, GNorm = 0.0958, lr_0 = 2.1531e-04
Loss = 4.1778e-05, PNorm = 52.2115, GNorm = 0.1524, lr_0 = 2.1508e-04
Loss = 4.0023e-05, PNorm = 52.2141, GNorm = 0.1365, lr_0 = 2.1486e-04
Loss = 5.9720e-05, PNorm = 52.2142, GNorm = 0.1037, lr_0 = 2.1464e-04
Loss = 4.1922e-05, PNorm = 52.2167, GNorm = 0.1953, lr_0 = 2.1441e-04
Loss = 4.7531e-05, PNorm = 52.2208, GNorm = 0.2307, lr_0 = 2.1419e-04
Loss = 5.8050e-05, PNorm = 52.2211, GNorm = 0.4213, lr_0 = 2.1396e-04
Loss = 5.9842e-05, PNorm = 52.2231, GNorm = 0.2134, lr_0 = 2.1374e-04
Loss = 4.5000e-05, PNorm = 52.2258, GNorm = 0.1176, lr_0 = 2.1352e-04
Loss = 6.1836e-05, PNorm = 52.2288, GNorm = 0.2423, lr_0 = 2.1329e-04
Loss = 5.1566e-05, PNorm = 52.2327, GNorm = 0.1630, lr_0 = 2.1307e-04
Loss = 4.2497e-05, PNorm = 52.2361, GNorm = 0.1073, lr_0 = 2.1285e-04
Loss = 4.3475e-05, PNorm = 52.2367, GNorm = 0.1844, lr_0 = 2.1263e-04
Loss = 4.6135e-05, PNorm = 52.2365, GNorm = 0.1899, lr_0 = 2.1241e-04
Loss = 4.7614e-05, PNorm = 52.2391, GNorm = 0.1726, lr_0 = 2.1218e-04
Loss = 4.2808e-05, PNorm = 52.2423, GNorm = 0.1314, lr_0 = 2.1196e-04
Loss = 4.9389e-05, PNorm = 52.2419, GNorm = 0.1681, lr_0 = 2.1174e-04
Loss = 5.7692e-05, PNorm = 52.2447, GNorm = 0.4023, lr_0 = 2.1152e-04
Loss = 4.5358e-05, PNorm = 52.2467, GNorm = 0.1490, lr_0 = 2.1130e-04
Loss = 6.7173e-05, PNorm = 52.2501, GNorm = 0.1819, lr_0 = 2.1108e-04
Loss = 6.0593e-05, PNorm = 52.2537, GNorm = 0.2078, lr_0 = 2.1086e-04
Loss = 6.6964e-05, PNorm = 52.2573, GNorm = 0.2245, lr_0 = 2.1064e-04
Validation rmse logD = 0.558157
Validation R2 logD = 0.772497
Validation rmse logP = 0.451952
Validation R2 logP = 0.940739
Epoch 68
Train function
Loss = 7.7754e-05, PNorm = 52.2622, GNorm = 0.2573, lr_0 = 2.1040e-04
Loss = 8.3051e-05, PNorm = 52.2663, GNorm = 0.2373, lr_0 = 2.1018e-04
Loss = 6.5468e-05, PNorm = 52.2707, GNorm = 0.2105, lr_0 = 2.0996e-04
Loss = 6.5894e-05, PNorm = 52.2735, GNorm = 0.2653, lr_0 = 2.0974e-04
Loss = 5.9969e-05, PNorm = 52.2755, GNorm = 0.1180, lr_0 = 2.0952e-04
Loss = 4.9113e-05, PNorm = 52.2777, GNorm = 0.1694, lr_0 = 2.0930e-04
Loss = 4.2696e-05, PNorm = 52.2802, GNorm = 0.2405, lr_0 = 2.0908e-04
Loss = 3.6902e-05, PNorm = 52.2812, GNorm = 0.1090, lr_0 = 2.0886e-04
Loss = 3.2458e-05, PNorm = 52.2815, GNorm = 0.1238, lr_0 = 2.0865e-04
Loss = 4.6716e-05, PNorm = 52.2832, GNorm = 0.1531, lr_0 = 2.0843e-04
Loss = 5.1793e-05, PNorm = 52.2854, GNorm = 0.1936, lr_0 = 2.0821e-04
Loss = 5.8845e-05, PNorm = 52.2881, GNorm = 0.2423, lr_0 = 2.0799e-04
Loss = 5.2854e-05, PNorm = 52.2888, GNorm = 0.1413, lr_0 = 2.0778e-04
Loss = 4.6751e-05, PNorm = 52.2914, GNorm = 0.2771, lr_0 = 2.0756e-04
Loss = 5.0188e-05, PNorm = 52.2940, GNorm = 0.3565, lr_0 = 2.0734e-04
Loss = 4.5691e-05, PNorm = 52.2965, GNorm = 0.0879, lr_0 = 2.0713e-04
Loss = 4.9330e-05, PNorm = 52.2992, GNorm = 0.1464, lr_0 = 2.0691e-04
Loss = 5.2330e-05, PNorm = 52.3000, GNorm = 0.1347, lr_0 = 2.0669e-04
Loss = 4.3233e-05, PNorm = 52.3026, GNorm = 0.1726, lr_0 = 2.0648e-04
Loss = 3.7922e-05, PNorm = 52.3044, GNorm = 0.1839, lr_0 = 2.0626e-04
Loss = 4.2489e-05, PNorm = 52.3058, GNorm = 0.1347, lr_0 = 2.0605e-04
Loss = 5.0050e-05, PNorm = 52.3083, GNorm = 0.1888, lr_0 = 2.0583e-04
Validation rmse logD = 0.558444
Validation R2 logD = 0.772264
Validation rmse logP = 0.449128
Validation R2 logP = 0.941477
Epoch 69
Train function
Loss = 4.9195e-05, PNorm = 52.3090, GNorm = 0.1898, lr_0 = 2.0562e-04
Loss = 4.5268e-05, PNorm = 52.3111, GNorm = 0.2335, lr_0 = 2.0540e-04
Loss = 4.9304e-05, PNorm = 52.3121, GNorm = 0.1512, lr_0 = 2.0519e-04
Loss = 3.5384e-05, PNorm = 52.3123, GNorm = 0.1281, lr_0 = 2.0497e-04
Loss = 4.1398e-05, PNorm = 52.3136, GNorm = 0.0782, lr_0 = 2.0476e-04
Loss = 3.1637e-05, PNorm = 52.3148, GNorm = 0.1274, lr_0 = 2.0455e-04
Loss = 4.7755e-05, PNorm = 52.3171, GNorm = 0.1759, lr_0 = 2.0433e-04
Loss = 3.5054e-05, PNorm = 52.3190, GNorm = 0.1251, lr_0 = 2.0412e-04
Loss = 4.6086e-05, PNorm = 52.3208, GNorm = 0.1475, lr_0 = 2.0391e-04
Loss = 3.0214e-05, PNorm = 52.3233, GNorm = 0.1159, lr_0 = 2.0369e-04
Loss = 3.0409e-05, PNorm = 52.3253, GNorm = 0.1166, lr_0 = 2.0348e-04
Loss = 4.2214e-05, PNorm = 52.3270, GNorm = 0.1991, lr_0 = 2.0327e-04
Loss = 3.3316e-05, PNorm = 52.3286, GNorm = 0.1973, lr_0 = 2.0306e-04
Loss = 3.8125e-05, PNorm = 52.3288, GNorm = 0.1297, lr_0 = 2.0285e-04
Loss = 3.6930e-05, PNorm = 52.3300, GNorm = 0.0923, lr_0 = 2.0263e-04
Loss = 3.4511e-05, PNorm = 52.3320, GNorm = 0.1578, lr_0 = 2.0242e-04
Loss = 3.8338e-05, PNorm = 52.3330, GNorm = 0.1545, lr_0 = 2.0221e-04
Loss = 4.5556e-05, PNorm = 52.3331, GNorm = 0.1539, lr_0 = 2.0200e-04
Loss = 4.0951e-05, PNorm = 52.3351, GNorm = 0.1832, lr_0 = 2.0179e-04
Loss = 5.3083e-05, PNorm = 52.3382, GNorm = 0.1235, lr_0 = 2.0158e-04
Loss = 4.4860e-05, PNorm = 52.3413, GNorm = 0.2187, lr_0 = 2.0137e-04
Loss = 4.2131e-05, PNorm = 52.3450, GNorm = 0.1385, lr_0 = 2.0116e-04
Loss = 3.6212e-05, PNorm = 52.3481, GNorm = 0.1277, lr_0 = 2.0095e-04
Validation rmse logD = 0.556934
Validation R2 logD = 0.773493
Validation rmse logP = 0.451213
Validation R2 logP = 0.940932
Epoch 70
Train function
Loss = 3.6521e-05, PNorm = 52.3505, GNorm = 0.1702, lr_0 = 2.0072e-04
Loss = 3.9352e-05, PNorm = 52.3516, GNorm = 0.2059, lr_0 = 2.0051e-04
Loss = 5.3110e-05, PNorm = 52.3519, GNorm = 0.1577, lr_0 = 2.0030e-04
Loss = 4.6329e-05, PNorm = 52.3541, GNorm = 0.2508, lr_0 = 2.0009e-04
Loss = 4.8156e-05, PNorm = 52.3564, GNorm = 0.1746, lr_0 = 1.9988e-04
Loss = 3.8387e-05, PNorm = 52.3595, GNorm = 0.1839, lr_0 = 1.9967e-04
Loss = 3.2945e-05, PNorm = 52.3607, GNorm = 0.1503, lr_0 = 1.9946e-04
Loss = 3.4920e-05, PNorm = 52.3632, GNorm = 0.2180, lr_0 = 1.9926e-04
Loss = 3.8256e-05, PNorm = 52.3643, GNorm = 0.1670, lr_0 = 1.9905e-04
Loss = 3.7856e-05, PNorm = 52.3657, GNorm = 0.1752, lr_0 = 1.9884e-04
Loss = 3.2925e-05, PNorm = 52.3679, GNorm = 0.1293, lr_0 = 1.9863e-04
Loss = 3.3746e-05, PNorm = 52.3699, GNorm = 0.1047, lr_0 = 1.9842e-04
Loss = 3.9546e-05, PNorm = 52.3716, GNorm = 0.1118, lr_0 = 1.9822e-04
Loss = 3.2518e-05, PNorm = 52.3733, GNorm = 0.1001, lr_0 = 1.9801e-04
Loss = 3.6542e-05, PNorm = 52.3727, GNorm = 0.1151, lr_0 = 1.9780e-04
Loss = 3.9442e-05, PNorm = 52.3739, GNorm = 0.1275, lr_0 = 1.9760e-04
Loss = 4.1404e-05, PNorm = 52.3759, GNorm = 0.1667, lr_0 = 1.9739e-04
Loss = 2.9651e-05, PNorm = 52.3775, GNorm = 0.1270, lr_0 = 1.9719e-04
Loss = 4.0526e-05, PNorm = 52.3793, GNorm = 0.0659, lr_0 = 1.9698e-04
Loss = 3.3367e-05, PNorm = 52.3795, GNorm = 0.0995, lr_0 = 1.9677e-04
Loss = 3.6510e-05, PNorm = 52.3796, GNorm = 0.1364, lr_0 = 1.9657e-04
Loss = 4.3987e-05, PNorm = 52.3817, GNorm = 0.1658, lr_0 = 1.9636e-04
Validation rmse logD = 0.558892
Validation R2 logD = 0.771898
Validation rmse logP = 0.449142
Validation R2 logP = 0.941474
Epoch 71
Train function
Loss = 2.0968e-05, PNorm = 52.3839, GNorm = 0.0883, lr_0 = 1.9616e-04
Loss = 4.0743e-05, PNorm = 52.3856, GNorm = 0.1774, lr_0 = 1.9595e-04
Loss = 4.8522e-05, PNorm = 52.3885, GNorm = 0.2342, lr_0 = 1.9575e-04
Loss = 3.8168e-05, PNorm = 52.3910, GNorm = 0.1085, lr_0 = 1.9555e-04
Loss = 4.2715e-05, PNorm = 52.3930, GNorm = 0.3037, lr_0 = 1.9534e-04
Loss = 4.4687e-05, PNorm = 52.3948, GNorm = 0.2209, lr_0 = 1.9514e-04
Loss = 3.7016e-05, PNorm = 52.3964, GNorm = 0.1783, lr_0 = 1.9493e-04
Loss = 3.5580e-05, PNorm = 52.3982, GNorm = 0.1462, lr_0 = 1.9473e-04
Loss = 3.2194e-05, PNorm = 52.3987, GNorm = 0.1425, lr_0 = 1.9453e-04
Loss = 3.0009e-05, PNorm = 52.4011, GNorm = 0.1370, lr_0 = 1.9432e-04
Loss = 2.9142e-05, PNorm = 52.4034, GNorm = 0.1773, lr_0 = 1.9412e-04
Loss = 4.3231e-05, PNorm = 52.4048, GNorm = 0.1736, lr_0 = 1.9392e-04
Loss = 3.7845e-05, PNorm = 52.4063, GNorm = 0.1713, lr_0 = 1.9372e-04
Loss = 2.7362e-05, PNorm = 52.4071, GNorm = 0.1421, lr_0 = 1.9351e-04
Loss = 2.8197e-05, PNorm = 52.4081, GNorm = 0.1037, lr_0 = 1.9331e-04
Loss = 3.7821e-05, PNorm = 52.4090, GNorm = 0.1125, lr_0 = 1.9311e-04
Loss = 3.2645e-05, PNorm = 52.4104, GNorm = 0.1371, lr_0 = 1.9291e-04
Loss = 3.1463e-05, PNorm = 52.4120, GNorm = 0.1225, lr_0 = 1.9271e-04
Loss = 3.2094e-05, PNorm = 52.4140, GNorm = 0.1733, lr_0 = 1.9251e-04
Loss = 3.2487e-05, PNorm = 52.4141, GNorm = 0.0826, lr_0 = 1.9231e-04
Loss = 3.1448e-05, PNorm = 52.4158, GNorm = 0.1177, lr_0 = 1.9210e-04
Loss = 3.4573e-05, PNorm = 52.4182, GNorm = 0.1328, lr_0 = 1.9190e-04
Loss = 2.6739e-05, PNorm = 52.4198, GNorm = 0.1096, lr_0 = 1.9170e-04
Validation rmse logD = 0.557670
Validation R2 logD = 0.772895
Validation rmse logP = 0.447105
Validation R2 logP = 0.942003
Epoch 72
Train function
Loss = 2.7700e-05, PNorm = 52.4225, GNorm = 0.0820, lr_0 = 1.9148e-04
Loss = 2.5385e-05, PNorm = 52.4240, GNorm = 0.0793, lr_0 = 1.9128e-04
Loss = 3.0328e-05, PNorm = 52.4256, GNorm = 0.1161, lr_0 = 1.9108e-04
Loss = 2.9861e-05, PNorm = 52.4283, GNorm = 0.1227, lr_0 = 1.9088e-04
Loss = 2.6741e-05, PNorm = 52.4303, GNorm = 0.1168, lr_0 = 1.9069e-04
Loss = 2.8836e-05, PNorm = 52.4310, GNorm = 0.1215, lr_0 = 1.9049e-04
Loss = 3.3940e-05, PNorm = 52.4330, GNorm = 0.1255, lr_0 = 1.9029e-04
Loss = 3.3733e-05, PNorm = 52.4329, GNorm = 0.1175, lr_0 = 1.9009e-04
Loss = 3.2879e-05, PNorm = 52.4345, GNorm = 0.0881, lr_0 = 1.8989e-04
Loss = 2.8903e-05, PNorm = 52.4349, GNorm = 0.1954, lr_0 = 1.8969e-04
Loss = 3.3892e-05, PNorm = 52.4394, GNorm = 0.1896, lr_0 = 1.8949e-04
Loss = 3.0129e-05, PNorm = 52.4414, GNorm = 0.1035, lr_0 = 1.8930e-04
Loss = 2.8308e-05, PNorm = 52.4431, GNorm = 0.1786, lr_0 = 1.8910e-04
Loss = 3.5947e-05, PNorm = 52.4447, GNorm = 0.1116, lr_0 = 1.8890e-04
Loss = 3.1014e-05, PNorm = 52.4465, GNorm = 0.0956, lr_0 = 1.8870e-04
Loss = 2.2874e-05, PNorm = 52.4483, GNorm = 0.0852, lr_0 = 1.8851e-04
Loss = 3.2287e-05, PNorm = 52.4493, GNorm = 0.1283, lr_0 = 1.8831e-04
Loss = 3.6726e-05, PNorm = 52.4519, GNorm = 0.1063, lr_0 = 1.8811e-04
Loss = 3.1834e-05, PNorm = 52.4530, GNorm = 0.1068, lr_0 = 1.8792e-04
Loss = 3.2707e-05, PNorm = 52.4542, GNorm = 0.0837, lr_0 = 1.8772e-04
Loss = 3.0568e-05, PNorm = 52.4549, GNorm = 0.1209, lr_0 = 1.8753e-04
Loss = 3.2778e-05, PNorm = 52.4561, GNorm = 0.2109, lr_0 = 1.8733e-04
Loss = 3.5258e-05, PNorm = 52.4569, GNorm = 0.1858, lr_0 = 1.8713e-04
Validation rmse logD = 0.557110
Validation R2 logD = 0.773350
Validation rmse logP = 0.451987
Validation R2 logP = 0.940730
Epoch 73
Train function
Loss = 3.3599e-05, PNorm = 52.4596, GNorm = 0.2508, lr_0 = 1.8694e-04
Loss = 3.9179e-05, PNorm = 52.4613, GNorm = 0.2172, lr_0 = 1.8674e-04
Loss = 3.1022e-05, PNorm = 52.4614, GNorm = 0.1430, lr_0 = 1.8655e-04
Loss = 3.7966e-05, PNorm = 52.4633, GNorm = 0.1454, lr_0 = 1.8635e-04
Loss = 5.2155e-05, PNorm = 52.4649, GNorm = 0.2504, lr_0 = 1.8616e-04
Loss = 4.0253e-05, PNorm = 52.4674, GNorm = 0.2426, lr_0 = 1.8597e-04
Loss = 3.9814e-05, PNorm = 52.4709, GNorm = 0.1216, lr_0 = 1.8577e-04
Loss = 4.1186e-05, PNorm = 52.4731, GNorm = 0.2168, lr_0 = 1.8558e-04
Loss = 3.8335e-05, PNorm = 52.4745, GNorm = 0.1666, lr_0 = 1.8538e-04
Loss = 4.5072e-05, PNorm = 52.4755, GNorm = 0.1800, lr_0 = 1.8519e-04
Loss = 3.5886e-05, PNorm = 52.4765, GNorm = 0.1756, lr_0 = 1.8500e-04
Loss = 3.4535e-05, PNorm = 52.4785, GNorm = 0.1808, lr_0 = 1.8480e-04
Loss = 3.4241e-05, PNorm = 52.4800, GNorm = 0.0930, lr_0 = 1.8461e-04
Loss = 3.8260e-05, PNorm = 52.4819, GNorm = 0.1375, lr_0 = 1.8442e-04
Loss = 5.2190e-05, PNorm = 52.4835, GNorm = 0.1372, lr_0 = 1.8423e-04
Loss = 4.4529e-05, PNorm = 52.4848, GNorm = 0.2095, lr_0 = 1.8403e-04
Loss = 3.9766e-05, PNorm = 52.4867, GNorm = 0.0850, lr_0 = 1.8384e-04
Loss = 4.5200e-05, PNorm = 52.4900, GNorm = 0.1691, lr_0 = 1.8365e-04
Loss = 3.1096e-05, PNorm = 52.4918, GNorm = 0.1234, lr_0 = 1.8346e-04
Loss = 3.8650e-05, PNorm = 52.4941, GNorm = 0.1721, lr_0 = 1.8327e-04
Loss = 3.6154e-05, PNorm = 52.4955, GNorm = 0.1912, lr_0 = 1.8308e-04
Loss = 3.5045e-05, PNorm = 52.4968, GNorm = 0.0831, lr_0 = 1.8288e-04
Validation rmse logD = 0.557022
Validation R2 logD = 0.773422
Validation rmse logP = 0.452402
Validation R2 logP = 0.940621
Epoch 74
Train function
Loss = 3.0289e-05, PNorm = 52.4990, GNorm = 0.1675, lr_0 = 1.8267e-04
Loss = 3.1905e-05, PNorm = 52.5005, GNorm = 0.1187, lr_0 = 1.8248e-04
Loss = 4.3863e-05, PNorm = 52.5018, GNorm = 0.2101, lr_0 = 1.8229e-04
Loss = 4.4238e-05, PNorm = 52.5038, GNorm = 0.3063, lr_0 = 1.8210e-04
Loss = 4.3739e-05, PNorm = 52.5040, GNorm = 0.1456, lr_0 = 1.8191e-04
Loss = 4.3627e-05, PNorm = 52.5055, GNorm = 0.1529, lr_0 = 1.8172e-04
Loss = 4.0486e-05, PNorm = 52.5073, GNorm = 0.1685, lr_0 = 1.8153e-04
Loss = 3.4502e-05, PNorm = 52.5088, GNorm = 0.1215, lr_0 = 1.8134e-04
Loss = 3.2835e-05, PNorm = 52.5093, GNorm = 0.1707, lr_0 = 1.8115e-04
Loss = 3.8428e-05, PNorm = 52.5105, GNorm = 0.2151, lr_0 = 1.8097e-04
Loss = 3.3717e-05, PNorm = 52.5126, GNorm = 0.1786, lr_0 = 1.8078e-04
Loss = 3.2394e-05, PNorm = 52.5138, GNorm = 0.1074, lr_0 = 1.8059e-04
Loss = 2.7588e-05, PNorm = 52.5150, GNorm = 0.1005, lr_0 = 1.8040e-04
Loss = 3.0254e-05, PNorm = 52.5172, GNorm = 0.1403, lr_0 = 1.8021e-04
Loss = 4.3316e-05, PNorm = 52.5181, GNorm = 0.1390, lr_0 = 1.8002e-04
Loss = 4.4290e-05, PNorm = 52.5200, GNorm = 0.1622, lr_0 = 1.7984e-04
Loss = 3.6288e-05, PNorm = 52.5234, GNorm = 0.2570, lr_0 = 1.7965e-04
Loss = 3.9284e-05, PNorm = 52.5254, GNorm = 0.1303, lr_0 = 1.7946e-04
Loss = 4.2539e-05, PNorm = 52.5289, GNorm = 0.2021, lr_0 = 1.7927e-04
Loss = 4.4572e-05, PNorm = 52.5319, GNorm = 0.1354, lr_0 = 1.7909e-04
Loss = 4.3711e-05, PNorm = 52.5332, GNorm = 0.1967, lr_0 = 1.7890e-04
Loss = 3.0886e-05, PNorm = 52.5347, GNorm = 0.0674, lr_0 = 1.7871e-04
Loss = 3.9185e-05, PNorm = 52.5350, GNorm = 0.1753, lr_0 = 1.7853e-04
Validation rmse logD = 0.559310
Validation R2 logD = 0.771557
Validation rmse logP = 0.449824
Validation R2 logP = 0.941296
Epoch 75
Train function
Loss = 3.4959e-05, PNorm = 52.5356, GNorm = 0.1755, lr_0 = 1.7834e-04
Loss = 2.6988e-05, PNorm = 52.5374, GNorm = 0.0986, lr_0 = 1.7815e-04
Loss = 2.7169e-05, PNorm = 52.5380, GNorm = 0.0958, lr_0 = 1.7797e-04
Loss = 2.2298e-05, PNorm = 52.5377, GNorm = 0.0978, lr_0 = 1.7778e-04
Loss = 2.1874e-05, PNorm = 52.5396, GNorm = 0.0900, lr_0 = 1.7760e-04
Loss = 2.1383e-05, PNorm = 52.5412, GNorm = 0.0781, lr_0 = 1.7741e-04
Loss = 2.7759e-05, PNorm = 52.5428, GNorm = 0.1506, lr_0 = 1.7723e-04
Loss = 2.7619e-05, PNorm = 52.5443, GNorm = 0.0789, lr_0 = 1.7704e-04
Loss = 2.5565e-05, PNorm = 52.5463, GNorm = 0.1335, lr_0 = 1.7686e-04
Loss = 2.7459e-05, PNorm = 52.5465, GNorm = 0.1168, lr_0 = 1.7667e-04
Loss = 3.5715e-05, PNorm = 52.5460, GNorm = 0.1749, lr_0 = 1.7649e-04
Loss = 3.6848e-05, PNorm = 52.5476, GNorm = 0.1244, lr_0 = 1.7630e-04
Loss = 3.1763e-05, PNorm = 52.5484, GNorm = 0.1192, lr_0 = 1.7612e-04
Loss = 3.5654e-05, PNorm = 52.5507, GNorm = 0.1296, lr_0 = 1.7593e-04
Loss = 3.4993e-05, PNorm = 52.5510, GNorm = 0.1036, lr_0 = 1.7575e-04
Loss = 3.0316e-05, PNorm = 52.5524, GNorm = 0.0806, lr_0 = 1.7557e-04
Loss = 3.5710e-05, PNorm = 52.5533, GNorm = 0.2140, lr_0 = 1.7538e-04
Loss = 2.8278e-05, PNorm = 52.5557, GNorm = 0.0928, lr_0 = 1.7520e-04
Loss = 4.0204e-05, PNorm = 52.5581, GNorm = 0.0848, lr_0 = 1.7502e-04
Loss = 3.8771e-05, PNorm = 52.5593, GNorm = 0.1098, lr_0 = 1.7484e-04
Loss = 4.3432e-05, PNorm = 52.5618, GNorm = 0.1665, lr_0 = 1.7465e-04
Loss = 3.3144e-05, PNorm = 52.5639, GNorm = 0.0923, lr_0 = 1.7447e-04
Validation rmse logD = 0.557636
Validation R2 logD = 0.772922
Validation rmse logP = 0.453123
Validation R2 logP = 0.940431
Epoch 76
Train function
Loss = 3.0956e-05, PNorm = 52.5655, GNorm = 0.1795, lr_0 = 1.7427e-04
Loss = 2.9597e-05, PNorm = 52.5664, GNorm = 0.1522, lr_0 = 1.7409e-04
Loss = 3.3350e-05, PNorm = 52.5679, GNorm = 0.1944, lr_0 = 1.7391e-04
Loss = 2.7451e-05, PNorm = 52.5702, GNorm = 0.1510, lr_0 = 1.7373e-04
Loss = 2.6346e-05, PNorm = 52.5705, GNorm = 0.0844, lr_0 = 1.7354e-04
Loss = 2.9092e-05, PNorm = 52.5723, GNorm = 0.1645, lr_0 = 1.7336e-04
Loss = 3.0705e-05, PNorm = 52.5740, GNorm = 0.1128, lr_0 = 1.7318e-04
Loss = 3.5143e-05, PNorm = 52.5752, GNorm = 0.1050, lr_0 = 1.7300e-04
Loss = 2.5876e-05, PNorm = 52.5763, GNorm = 0.1153, lr_0 = 1.7282e-04
Loss = 2.3931e-05, PNorm = 52.5763, GNorm = 0.1369, lr_0 = 1.7264e-04
Loss = 2.9928e-05, PNorm = 52.5779, GNorm = 0.1539, lr_0 = 1.7246e-04
Loss = 4.4886e-05, PNorm = 52.5798, GNorm = 0.2828, lr_0 = 1.7228e-04
Loss = 3.4620e-05, PNorm = 52.5805, GNorm = 0.1173, lr_0 = 1.7210e-04
Loss = 3.3696e-05, PNorm = 52.5819, GNorm = 0.1426, lr_0 = 1.7192e-04
Loss = 3.2302e-05, PNorm = 52.5828, GNorm = 0.1222, lr_0 = 1.7174e-04
Loss = 3.1946e-05, PNorm = 52.5845, GNorm = 0.1246, lr_0 = 1.7156e-04
Loss = 3.3835e-05, PNorm = 52.5870, GNorm = 0.2297, lr_0 = 1.7138e-04
Loss = 2.6283e-05, PNorm = 52.5888, GNorm = 0.1044, lr_0 = 1.7120e-04
Loss = 3.4270e-05, PNorm = 52.5895, GNorm = 0.1326, lr_0 = 1.7103e-04
Loss = 2.9945e-05, PNorm = 52.5915, GNorm = 0.0957, lr_0 = 1.7085e-04
Loss = 2.9329e-05, PNorm = 52.5927, GNorm = 0.1921, lr_0 = 1.7067e-04
Loss = 3.1531e-05, PNorm = 52.5928, GNorm = 0.1546, lr_0 = 1.7049e-04
Loss = 2.8058e-05, PNorm = 52.5947, GNorm = 0.0901, lr_0 = 1.7031e-04
Validation rmse logD = 0.556433
Validation R2 logD = 0.773900
Validation rmse logP = 0.452974
Validation R2 logP = 0.940471
Epoch 77
Train function
Loss = 3.4499e-05, PNorm = 52.5960, GNorm = 0.2122, lr_0 = 1.7012e-04
Loss = 2.8198e-05, PNorm = 52.5980, GNorm = 0.1434, lr_0 = 1.6994e-04
Loss = 2.3582e-05, PNorm = 52.6006, GNorm = 0.1088, lr_0 = 1.6976e-04
Loss = 2.0106e-05, PNorm = 52.6013, GNorm = 0.0625, lr_0 = 1.6959e-04
Loss = 2.0716e-05, PNorm = 52.6017, GNorm = 0.1282, lr_0 = 1.6941e-04
Loss = 2.4502e-05, PNorm = 52.6027, GNorm = 0.1093, lr_0 = 1.6923e-04
Loss = 2.0030e-05, PNorm = 52.6031, GNorm = 0.0628, lr_0 = 1.6905e-04
Loss = 2.3538e-05, PNorm = 52.6043, GNorm = 0.0754, lr_0 = 1.6888e-04
Loss = 2.3271e-05, PNorm = 52.6049, GNorm = 0.0951, lr_0 = 1.6870e-04
Loss = 2.5039e-05, PNorm = 52.6065, GNorm = 0.0657, lr_0 = 1.6853e-04
Loss = 3.1847e-05, PNorm = 52.6076, GNorm = 0.1858, lr_0 = 1.6835e-04
Loss = 2.6060e-05, PNorm = 52.6082, GNorm = 0.1138, lr_0 = 1.6817e-04
Loss = 2.6197e-05, PNorm = 52.6103, GNorm = 0.0944, lr_0 = 1.6800e-04
Loss = 2.1944e-05, PNorm = 52.6119, GNorm = 0.0941, lr_0 = 1.6782e-04
Loss = 2.1815e-05, PNorm = 52.6139, GNorm = 0.0873, lr_0 = 1.6765e-04
Loss = 3.0156e-05, PNorm = 52.6159, GNorm = 0.1918, lr_0 = 1.6747e-04
Loss = 2.5502e-05, PNorm = 52.6158, GNorm = 0.1048, lr_0 = 1.6730e-04
Loss = 2.9176e-05, PNorm = 52.6169, GNorm = 0.0986, lr_0 = 1.6712e-04
Loss = 3.5874e-05, PNorm = 52.6181, GNorm = 0.0753, lr_0 = 1.6695e-04
Loss = 4.5833e-05, PNorm = 52.6191, GNorm = 0.2817, lr_0 = 1.6678e-04
Loss = 4.3763e-05, PNorm = 52.6202, GNorm = 0.1541, lr_0 = 1.6660e-04
Loss = 4.6043e-05, PNorm = 52.6233, GNorm = 0.2019, lr_0 = 1.6643e-04
Validation rmse logD = 0.555878
Validation R2 logD = 0.774351
Validation rmse logP = 0.450397
Validation R2 logP = 0.941146
Epoch 78
Train function
Loss = 4.7440e-05, PNorm = 52.6249, GNorm = 0.2398, lr_0 = 1.6625e-04
Loss = 3.0888e-05, PNorm = 52.6265, GNorm = 0.1608, lr_0 = 1.6608e-04
Loss = 3.0792e-05, PNorm = 52.6273, GNorm = 0.1260, lr_0 = 1.6591e-04
Loss = 2.9339e-05, PNorm = 52.6295, GNorm = 0.0647, lr_0 = 1.6573e-04
Loss = 3.0073e-05, PNorm = 52.6310, GNorm = 0.1108, lr_0 = 1.6556e-04
Loss = 2.7761e-05, PNorm = 52.6333, GNorm = 0.1077, lr_0 = 1.6539e-04
Loss = 2.7439e-05, PNorm = 52.6353, GNorm = 0.0926, lr_0 = 1.6522e-04
Loss = 2.4983e-05, PNorm = 52.6354, GNorm = 0.1115, lr_0 = 1.6504e-04
Loss = 2.4549e-05, PNorm = 52.6363, GNorm = 0.0805, lr_0 = 1.6487e-04
Loss = 2.3561e-05, PNorm = 52.6374, GNorm = 0.1602, lr_0 = 1.6470e-04
Loss = 2.4896e-05, PNorm = 52.6386, GNorm = 0.1325, lr_0 = 1.6453e-04
Loss = 2.4886e-05, PNorm = 52.6400, GNorm = 0.2197, lr_0 = 1.6435e-04
Loss = 3.2893e-05, PNorm = 52.6415, GNorm = 0.1359, lr_0 = 1.6418e-04
Loss = 2.4757e-05, PNorm = 52.6435, GNorm = 0.1588, lr_0 = 1.6401e-04
Loss = 2.1828e-05, PNorm = 52.6450, GNorm = 0.1090, lr_0 = 1.6384e-04
Loss = 3.9151e-05, PNorm = 52.6460, GNorm = 0.1711, lr_0 = 1.6367e-04
Loss = 3.0896e-05, PNorm = 52.6464, GNorm = 0.1227, lr_0 = 1.6350e-04
Loss = 3.0355e-05, PNorm = 52.6478, GNorm = 0.0937, lr_0 = 1.6333e-04
Loss = 2.7347e-05, PNorm = 52.6486, GNorm = 0.1080, lr_0 = 1.6316e-04
Loss = 3.0434e-05, PNorm = 52.6509, GNorm = 0.0918, lr_0 = 1.6299e-04
Loss = 3.5250e-05, PNorm = 52.6516, GNorm = 0.1857, lr_0 = 1.6282e-04
Loss = 3.3203e-05, PNorm = 52.6535, GNorm = 0.0670, lr_0 = 1.6265e-04
Loss = 2.4935e-05, PNorm = 52.6554, GNorm = 0.1148, lr_0 = 1.6248e-04
Validation rmse logD = 0.557964
Validation R2 logD = 0.772655
Validation rmse logP = 0.451064
Validation R2 logP = 0.940972
Epoch 79
Train function
Loss = 2.2648e-05, PNorm = 52.6584, GNorm = 0.1884, lr_0 = 1.6229e-04
Loss = 2.1759e-05, PNorm = 52.6603, GNorm = 0.1318, lr_0 = 1.6212e-04
Loss = 2.1917e-05, PNorm = 52.6618, GNorm = 0.1018, lr_0 = 1.6195e-04
Loss = 2.4939e-05, PNorm = 52.6635, GNorm = 0.1584, lr_0 = 1.6178e-04
Loss = 2.5025e-05, PNorm = 52.6646, GNorm = 0.1013, lr_0 = 1.6161e-04
Loss = 2.8310e-05, PNorm = 52.6653, GNorm = 0.1169, lr_0 = 1.6145e-04
Loss = 2.9681e-05, PNorm = 52.6663, GNorm = 0.1149, lr_0 = 1.6128e-04
Loss = 2.2073e-05, PNorm = 52.6671, GNorm = 0.1751, lr_0 = 1.6111e-04
Loss = 3.3229e-05, PNorm = 52.6673, GNorm = 0.2315, lr_0 = 1.6094e-04
Loss = 2.4849e-05, PNorm = 52.6682, GNorm = 0.0976, lr_0 = 1.6077e-04
Loss = 2.7188e-05, PNorm = 52.6690, GNorm = 0.1743, lr_0 = 1.6061e-04
Loss = 3.1825e-05, PNorm = 52.6704, GNorm = 0.0991, lr_0 = 1.6044e-04
Loss = 3.4035e-05, PNorm = 52.6712, GNorm = 0.1314, lr_0 = 1.6027e-04
Loss = 2.6684e-05, PNorm = 52.6732, GNorm = 0.0655, lr_0 = 1.6010e-04
Loss = 2.3175e-05, PNorm = 52.6748, GNorm = 0.1469, lr_0 = 1.5994e-04
Loss = 2.2746e-05, PNorm = 52.6757, GNorm = 0.1185, lr_0 = 1.5977e-04
Loss = 3.0253e-05, PNorm = 52.6768, GNorm = 0.0684, lr_0 = 1.5960e-04
Loss = 2.4448e-05, PNorm = 52.6780, GNorm = 0.0797, lr_0 = 1.5944e-04
Loss = 2.3708e-05, PNorm = 52.6791, GNorm = 0.0905, lr_0 = 1.5927e-04
Loss = 2.0854e-05, PNorm = 52.6800, GNorm = 0.1530, lr_0 = 1.5910e-04
Loss = 1.4349e-05, PNorm = 52.6814, GNorm = 0.0889, lr_0 = 1.5894e-04
Loss = 2.3918e-05, PNorm = 52.6819, GNorm = 0.1228, lr_0 = 1.5877e-04
Validation rmse logD = 0.556085
Validation R2 logD = 0.774184
Validation rmse logP = 0.449229
Validation R2 logP = 0.941451
Epoch 80
Train function
Loss = 2.0077e-05, PNorm = 52.6822, GNorm = 0.0817, lr_0 = 1.5861e-04
Loss = 2.2309e-05, PNorm = 52.6832, GNorm = 0.0697, lr_0 = 1.5844e-04
Loss = 1.9268e-05, PNorm = 52.6851, GNorm = 0.0813, lr_0 = 1.5827e-04
Loss = 1.5919e-05, PNorm = 52.6865, GNorm = 0.0879, lr_0 = 1.5811e-04
Loss = 1.8808e-05, PNorm = 52.6868, GNorm = 0.1046, lr_0 = 1.5794e-04
Loss = 2.2544e-05, PNorm = 52.6871, GNorm = 0.1173, lr_0 = 1.5778e-04
Loss = 2.4856e-05, PNorm = 52.6880, GNorm = 0.1870, lr_0 = 1.5761e-04
Loss = 3.0204e-05, PNorm = 52.6885, GNorm = 0.1708, lr_0 = 1.5745e-04
Loss = 2.7951e-05, PNorm = 52.6902, GNorm = 0.0947, lr_0 = 1.5729e-04
Loss = 2.1157e-05, PNorm = 52.6926, GNorm = 0.0977, lr_0 = 1.5712e-04
Loss = 2.2071e-05, PNorm = 52.6942, GNorm = 0.0940, lr_0 = 1.5696e-04
Loss = 1.8474e-05, PNorm = 52.6948, GNorm = 0.0931, lr_0 = 1.5679e-04
Loss = 2.1723e-05, PNorm = 52.6953, GNorm = 0.1064, lr_0 = 1.5663e-04
Loss = 2.0538e-05, PNorm = 52.6955, GNorm = 0.1136, lr_0 = 1.5647e-04
Loss = 2.1590e-05, PNorm = 52.6970, GNorm = 0.1406, lr_0 = 1.5630e-04
Loss = 2.0506e-05, PNorm = 52.6972, GNorm = 0.0939, lr_0 = 1.5614e-04
Loss = 2.3808e-05, PNorm = 52.6963, GNorm = 0.1177, lr_0 = 1.5598e-04
Loss = 2.0092e-05, PNorm = 52.6967, GNorm = 0.0959, lr_0 = 1.5581e-04
Loss = 2.1381e-05, PNorm = 52.6977, GNorm = 0.1032, lr_0 = 1.5565e-04
Loss = 2.2853e-05, PNorm = 52.6979, GNorm = 0.0873, lr_0 = 1.5549e-04
Loss = 1.6686e-05, PNorm = 52.6985, GNorm = 0.0661, lr_0 = 1.5533e-04
Loss = 2.4328e-05, PNorm = 52.6999, GNorm = 0.1124, lr_0 = 1.5516e-04
Loss = 1.9654e-05, PNorm = 52.7011, GNorm = 0.0731, lr_0 = 1.5500e-04
Validation rmse logD = 0.560613
Validation R2 logD = 0.770491
Validation rmse logP = 0.450501
Validation R2 logP = 0.941119
Epoch 81
Train function
Loss = 2.9379e-05, PNorm = 52.7014, GNorm = 0.1102, lr_0 = 1.5483e-04
Loss = 2.9490e-05, PNorm = 52.7045, GNorm = 0.1497, lr_0 = 1.5466e-04
Loss = 3.0775e-05, PNorm = 52.7054, GNorm = 0.1901, lr_0 = 1.5450e-04
Loss = 2.3758e-05, PNorm = 52.7071, GNorm = 0.2505, lr_0 = 1.5434e-04
Loss = 2.3127e-05, PNorm = 52.7090, GNorm = 0.1084, lr_0 = 1.5418e-04
Loss = 2.0202e-05, PNorm = 52.7104, GNorm = 0.1506, lr_0 = 1.5402e-04
Loss = 2.4153e-05, PNorm = 52.7123, GNorm = 0.1231, lr_0 = 1.5386e-04
Loss = 2.2473e-05, PNorm = 52.7146, GNorm = 0.1518, lr_0 = 1.5370e-04
Loss = 2.2283e-05, PNorm = 52.7162, GNorm = 0.1094, lr_0 = 1.5354e-04
Loss = 1.9957e-05, PNorm = 52.7176, GNorm = 0.1125, lr_0 = 1.5338e-04
Loss = 1.7330e-05, PNorm = 52.7190, GNorm = 0.1013, lr_0 = 1.5322e-04
Loss = 2.1251e-05, PNorm = 52.7198, GNorm = 0.0810, lr_0 = 1.5306e-04
Loss = 2.2377e-05, PNorm = 52.7206, GNorm = 0.1274, lr_0 = 1.5290e-04
Loss = 2.5614e-05, PNorm = 52.7209, GNorm = 0.1297, lr_0 = 1.5274e-04
Loss = 2.2463e-05, PNorm = 52.7227, GNorm = 0.0948, lr_0 = 1.5258e-04
Loss = 2.6423e-05, PNorm = 52.7232, GNorm = 0.0894, lr_0 = 1.5242e-04
Loss = 1.8261e-05, PNorm = 52.7243, GNorm = 0.0864, lr_0 = 1.5226e-04
Loss = 2.0833e-05, PNorm = 52.7248, GNorm = 0.0820, lr_0 = 1.5210e-04
Loss = 2.2188e-05, PNorm = 52.7254, GNorm = 0.0994, lr_0 = 1.5194e-04
Loss = 2.1707e-05, PNorm = 52.7282, GNorm = 0.1128, lr_0 = 1.5178e-04
Loss = 1.7700e-05, PNorm = 52.7294, GNorm = 0.0676, lr_0 = 1.5163e-04
Loss = 2.7705e-05, PNorm = 52.7295, GNorm = 0.1890, lr_0 = 1.5147e-04
Validation rmse logD = 0.557014
Validation R2 logD = 0.773428
Validation rmse logP = 0.450287
Validation R2 logP = 0.941175
Epoch 82
Train function
Loss = 2.7675e-05, PNorm = 52.7300, GNorm = 0.1583, lr_0 = 1.5131e-04
Loss = 2.5777e-05, PNorm = 52.7312, GNorm = 0.1887, lr_0 = 1.5115e-04
Loss = 2.5114e-05, PNorm = 52.7307, GNorm = 0.1956, lr_0 = 1.5099e-04
Loss = 3.1045e-05, PNorm = 52.7320, GNorm = 0.0904, lr_0 = 1.5084e-04
Loss = 2.4691e-05, PNorm = 52.7332, GNorm = 0.1007, lr_0 = 1.5068e-04
Loss = 2.0902e-05, PNorm = 52.7347, GNorm = 0.0871, lr_0 = 1.5052e-04
Loss = 2.3707e-05, PNorm = 52.7357, GNorm = 0.0953, lr_0 = 1.5036e-04
Loss = 1.7430e-05, PNorm = 52.7361, GNorm = 0.1078, lr_0 = 1.5021e-04
Loss = 2.0427e-05, PNorm = 52.7383, GNorm = 0.0842, lr_0 = 1.5005e-04
Loss = 2.2376e-05, PNorm = 52.7385, GNorm = 0.1517, lr_0 = 1.4989e-04
Loss = 2.0484e-05, PNorm = 52.7388, GNorm = 0.1050, lr_0 = 1.4974e-04
Loss = 1.9705e-05, PNorm = 52.7398, GNorm = 0.0905, lr_0 = 1.4958e-04
Loss = 2.1632e-05, PNorm = 52.7413, GNorm = 0.0915, lr_0 = 1.4942e-04
Loss = 2.5732e-05, PNorm = 52.7414, GNorm = 0.1987, lr_0 = 1.4927e-04
Loss = 2.6081e-05, PNorm = 52.7426, GNorm = 0.0965, lr_0 = 1.4911e-04
Loss = 2.1416e-05, PNorm = 52.7435, GNorm = 0.0863, lr_0 = 1.4896e-04
Loss = 2.3543e-05, PNorm = 52.7435, GNorm = 0.1035, lr_0 = 1.4880e-04
Loss = 1.8668e-05, PNorm = 52.7435, GNorm = 0.0630, lr_0 = 1.4865e-04
Loss = 2.3063e-05, PNorm = 52.7448, GNorm = 0.1174, lr_0 = 1.4849e-04
Loss = 2.3757e-05, PNorm = 52.7462, GNorm = 0.1796, lr_0 = 1.4834e-04
Loss = 1.9842e-05, PNorm = 52.7477, GNorm = 0.1113, lr_0 = 1.4818e-04
Loss = 2.2120e-05, PNorm = 52.7492, GNorm = 0.1510, lr_0 = 1.4803e-04
Loss = 2.3214e-05, PNorm = 52.7496, GNorm = 0.1857, lr_0 = 1.4787e-04
Validation rmse logD = 0.556679
Validation R2 logD = 0.773700
Validation rmse logP = 0.450214
Validation R2 logP = 0.941194
Epoch 83
Train function
Loss = 2.6351e-05, PNorm = 52.7504, GNorm = 0.1671, lr_0 = 1.4770e-04
Loss = 2.3736e-05, PNorm = 52.7524, GNorm = 0.0942, lr_0 = 1.4755e-04
Loss = 2.6409e-05, PNorm = 52.7534, GNorm = 0.1666, lr_0 = 1.4739e-04
Loss = 2.9360e-05, PNorm = 52.7545, GNorm = 0.1113, lr_0 = 1.4724e-04
Loss = 2.5915e-05, PNorm = 52.7555, GNorm = 0.1185, lr_0 = 1.4709e-04
Loss = 2.5297e-05, PNorm = 52.7571, GNorm = 0.1053, lr_0 = 1.4693e-04
Loss = 2.4912e-05, PNorm = 52.7583, GNorm = 0.0999, lr_0 = 1.4678e-04
Loss = 2.3379e-05, PNorm = 52.7596, GNorm = 0.1162, lr_0 = 1.4663e-04
Loss = 1.7600e-05, PNorm = 52.7610, GNorm = 0.1072, lr_0 = 1.4647e-04
Loss = 1.6762e-05, PNorm = 52.7621, GNorm = 0.1149, lr_0 = 1.4632e-04
Loss = 2.0396e-05, PNorm = 52.7618, GNorm = 0.1057, lr_0 = 1.4617e-04
Loss = 1.9294e-05, PNorm = 52.7619, GNorm = 0.1570, lr_0 = 1.4602e-04
Loss = 1.9698e-05, PNorm = 52.7635, GNorm = 0.1409, lr_0 = 1.4586e-04
Loss = 1.7270e-05, PNorm = 52.7651, GNorm = 0.1370, lr_0 = 1.4571e-04
Loss = 2.8349e-05, PNorm = 52.7665, GNorm = 0.2230, lr_0 = 1.4556e-04
Loss = 1.8372e-05, PNorm = 52.7675, GNorm = 0.1021, lr_0 = 1.4541e-04
Loss = 1.9103e-05, PNorm = 52.7690, GNorm = 0.0632, lr_0 = 1.4526e-04
Loss = 2.0126e-05, PNorm = 52.7703, GNorm = 0.0912, lr_0 = 1.4510e-04
Loss = 1.7748e-05, PNorm = 52.7708, GNorm = 0.0775, lr_0 = 1.4495e-04
Loss = 2.1830e-05, PNorm = 52.7719, GNorm = 0.0856, lr_0 = 1.4480e-04
Loss = 1.4654e-05, PNorm = 52.7729, GNorm = 0.0684, lr_0 = 1.4465e-04
Loss = 1.9677e-05, PNorm = 52.7734, GNorm = 0.1159, lr_0 = 1.4450e-04
Loss = 2.4551e-05, PNorm = 52.7748, GNorm = 0.0849, lr_0 = 1.4435e-04
Validation rmse logD = 0.557996
Validation R2 logD = 0.772629
Validation rmse logP = 0.449257
Validation R2 logP = 0.941444
Epoch 84
Train function
Loss = 1.8973e-05, PNorm = 52.7761, GNorm = 0.1223, lr_0 = 1.4420e-04
Loss = 2.1101e-05, PNorm = 52.7772, GNorm = 0.0754, lr_0 = 1.4405e-04
Loss = 2.9575e-05, PNorm = 52.7781, GNorm = 0.1350, lr_0 = 1.4390e-04
Loss = 2.3714e-05, PNorm = 52.7793, GNorm = 0.1510, lr_0 = 1.4375e-04
Loss = 1.9607e-05, PNorm = 52.7803, GNorm = 0.0968, lr_0 = 1.4360e-04
Loss = 2.3325e-05, PNorm = 52.7815, GNorm = 0.1044, lr_0 = 1.4345e-04
Loss = 2.5846e-05, PNorm = 52.7826, GNorm = 0.2016, lr_0 = 1.4330e-04
Loss = 2.0351e-05, PNorm = 52.7845, GNorm = 0.1146, lr_0 = 1.4315e-04
Loss = 2.0133e-05, PNorm = 52.7853, GNorm = 0.0574, lr_0 = 1.4300e-04
Loss = 2.0979e-05, PNorm = 52.7856, GNorm = 0.1227, lr_0 = 1.4285e-04
Loss = 1.6663e-05, PNorm = 52.7867, GNorm = 0.0823, lr_0 = 1.4270e-04
Loss = 2.1118e-05, PNorm = 52.7871, GNorm = 0.1706, lr_0 = 1.4255e-04
Loss = 2.1280e-05, PNorm = 52.7881, GNorm = 0.1416, lr_0 = 1.4240e-04
Loss = 2.2705e-05, PNorm = 52.7889, GNorm = 0.1418, lr_0 = 1.4225e-04
Loss = 2.4380e-05, PNorm = 52.7897, GNorm = 0.1161, lr_0 = 1.4210e-04
Loss = 2.5013e-05, PNorm = 52.7908, GNorm = 0.1400, lr_0 = 1.4196e-04
Loss = 3.9899e-05, PNorm = 52.7911, GNorm = 0.2278, lr_0 = 1.4181e-04
Loss = 3.3377e-05, PNorm = 52.7919, GNorm = 0.1705, lr_0 = 1.4166e-04
Loss = 2.6997e-05, PNorm = 52.7947, GNorm = 0.1019, lr_0 = 1.4151e-04
Loss = 2.4555e-05, PNorm = 52.7960, GNorm = 0.0918, lr_0 = 1.4136e-04
Loss = 2.6579e-05, PNorm = 52.7983, GNorm = 0.0853, lr_0 = 1.4122e-04
Loss = 2.3630e-05, PNorm = 52.7998, GNorm = 0.1030, lr_0 = 1.4107e-04
Validation rmse logD = 0.558942
Validation R2 logD = 0.771857
Validation rmse logP = 0.451618
Validation R2 logP = 0.940826
Epoch 85
Train function
Loss = 1.7242e-05, PNorm = 52.8001, GNorm = 0.1086, lr_0 = 1.4091e-04
Loss = 1.9307e-05, PNorm = 52.8016, GNorm = 0.1354, lr_0 = 1.4076e-04
Loss = 1.6808e-05, PNorm = 52.8029, GNorm = 0.0805, lr_0 = 1.4061e-04
Loss = 1.9981e-05, PNorm = 52.8038, GNorm = 0.0970, lr_0 = 1.4047e-04
Loss = 2.9148e-05, PNorm = 52.8048, GNorm = 0.1499, lr_0 = 1.4032e-04
Loss = 2.9094e-05, PNorm = 52.8070, GNorm = 0.1990, lr_0 = 1.4017e-04
Loss = 2.9979e-05, PNorm = 52.8095, GNorm = 0.1960, lr_0 = 1.4003e-04
Loss = 2.2583e-05, PNorm = 52.8096, GNorm = 0.1028, lr_0 = 1.3988e-04
Loss = 2.4552e-05, PNorm = 52.8105, GNorm = 0.1424, lr_0 = 1.3974e-04
Loss = 3.0910e-05, PNorm = 52.8113, GNorm = 0.1625, lr_0 = 1.3959e-04
Loss = 2.0741e-05, PNorm = 52.8108, GNorm = 0.1235, lr_0 = 1.3944e-04
Loss = 1.5960e-05, PNorm = 52.8119, GNorm = 0.0999, lr_0 = 1.3930e-04
Loss = 2.4790e-05, PNorm = 52.8126, GNorm = 0.1186, lr_0 = 1.3915e-04
Loss = 1.9192e-05, PNorm = 52.8133, GNorm = 0.1087, lr_0 = 1.3901e-04
Loss = 2.6073e-05, PNorm = 52.8132, GNorm = 0.0755, lr_0 = 1.3886e-04
Loss = 2.1113e-05, PNorm = 52.8145, GNorm = 0.1007, lr_0 = 1.3872e-04
Loss = 2.1291e-05, PNorm = 52.8155, GNorm = 0.1006, lr_0 = 1.3857e-04
Loss = 2.6525e-05, PNorm = 52.8166, GNorm = 0.1794, lr_0 = 1.3843e-04
Loss = 2.5777e-05, PNorm = 52.8186, GNorm = 0.1719, lr_0 = 1.3828e-04
Loss = 2.0901e-05, PNorm = 52.8202, GNorm = 0.0682, lr_0 = 1.3814e-04
Loss = 2.9019e-05, PNorm = 52.8214, GNorm = 0.1569, lr_0 = 1.3800e-04
Loss = 3.3177e-05, PNorm = 52.8218, GNorm = 0.1505, lr_0 = 1.3785e-04
Loss = 2.6929e-05, PNorm = 52.8234, GNorm = 0.1057, lr_0 = 1.3771e-04
Validation rmse logD = 0.556603
Validation R2 logD = 0.773763
Validation rmse logP = 0.449790
Validation R2 logP = 0.941305
Epoch 86
Train function
Loss = 2.1917e-05, PNorm = 52.8247, GNorm = 0.0830, lr_0 = 1.3756e-04
Loss = 2.1334e-05, PNorm = 52.8255, GNorm = 0.1206, lr_0 = 1.3742e-04
Loss = 1.7640e-05, PNorm = 52.8265, GNorm = 0.0718, lr_0 = 1.3728e-04
Loss = 2.0721e-05, PNorm = 52.8274, GNorm = 0.2149, lr_0 = 1.3713e-04
Loss = 2.3940e-05, PNorm = 52.8282, GNorm = 0.1026, lr_0 = 1.3699e-04
Loss = 1.9965e-05, PNorm = 52.8298, GNorm = 0.1202, lr_0 = 1.3685e-04
Loss = 1.9235e-05, PNorm = 52.8308, GNorm = 0.1192, lr_0 = 1.3670e-04
Loss = 1.8823e-05, PNorm = 52.8315, GNorm = 0.1061, lr_0 = 1.3656e-04
Loss = 2.1634e-05, PNorm = 52.8330, GNorm = 0.1410, lr_0 = 1.3642e-04
Loss = 1.6039e-05, PNorm = 52.8343, GNorm = 0.0539, lr_0 = 1.3628e-04
Loss = 1.8863e-05, PNorm = 52.8356, GNorm = 0.0744, lr_0 = 1.3613e-04
Loss = 1.8521e-05, PNorm = 52.8362, GNorm = 0.1116, lr_0 = 1.3599e-04
Loss = 2.0443e-05, PNorm = 52.8368, GNorm = 0.0846, lr_0 = 1.3585e-04
Loss = 1.8404e-05, PNorm = 52.8367, GNorm = 0.0994, lr_0 = 1.3571e-04
Loss = 1.6356e-05, PNorm = 52.8364, GNorm = 0.0965, lr_0 = 1.3557e-04
Loss = 1.7500e-05, PNorm = 52.8372, GNorm = 0.0430, lr_0 = 1.3543e-04
Loss = 2.2104e-05, PNorm = 52.8375, GNorm = 0.0837, lr_0 = 1.3528e-04
Loss = 1.6560e-05, PNorm = 52.8390, GNorm = 0.1291, lr_0 = 1.3514e-04
Loss = 1.6341e-05, PNorm = 52.8410, GNorm = 0.0809, lr_0 = 1.3500e-04
Loss = 2.0551e-05, PNorm = 52.8420, GNorm = 0.0686, lr_0 = 1.3486e-04
Loss = 2.8746e-05, PNorm = 52.8426, GNorm = 0.1263, lr_0 = 1.3472e-04
Loss = 2.5072e-05, PNorm = 52.8422, GNorm = 0.1587, lr_0 = 1.3458e-04
Validation rmse logD = 0.559283
Validation R2 logD = 0.771578
Validation rmse logP = 0.451019
Validation R2 logP = 0.940983
Epoch 87
Train function
Loss = 2.0326e-05, PNorm = 52.8410, GNorm = 0.0959, lr_0 = 1.3443e-04
Loss = 2.2921e-05, PNorm = 52.8408, GNorm = 0.1562, lr_0 = 1.3428e-04
Loss = 1.7184e-05, PNorm = 52.8421, GNorm = 0.1520, lr_0 = 1.3414e-04
Loss = 3.2977e-05, PNorm = 52.8435, GNorm = 0.0927, lr_0 = 1.3400e-04
Loss = 2.3170e-05, PNorm = 52.8442, GNorm = 0.1553, lr_0 = 1.3386e-04
Loss = 2.1636e-05, PNorm = 52.8458, GNorm = 0.1171, lr_0 = 1.3373e-04
Loss = 1.9897e-05, PNorm = 52.8476, GNorm = 0.1109, lr_0 = 1.3359e-04
Loss = 1.6284e-05, PNorm = 52.8491, GNorm = 0.0994, lr_0 = 1.3345e-04
Loss = 1.8260e-05, PNorm = 52.8496, GNorm = 0.1629, lr_0 = 1.3331e-04
Loss = 1.8259e-05, PNorm = 52.8504, GNorm = 0.0799, lr_0 = 1.3317e-04
Loss = 1.3600e-05, PNorm = 52.8515, GNorm = 0.0924, lr_0 = 1.3303e-04
Loss = 1.7337e-05, PNorm = 52.8525, GNorm = 0.0839, lr_0 = 1.3289e-04
Loss = 1.7821e-05, PNorm = 52.8537, GNorm = 0.0645, lr_0 = 1.3275e-04
Loss = 1.4579e-05, PNorm = 52.8549, GNorm = 0.1061, lr_0 = 1.3261e-04
Loss = 1.4889e-05, PNorm = 52.8561, GNorm = 0.0709, lr_0 = 1.3247e-04
Loss = 1.8326e-05, PNorm = 52.8574, GNorm = 0.0722, lr_0 = 1.3234e-04
Loss = 1.9499e-05, PNorm = 52.8577, GNorm = 0.1277, lr_0 = 1.3220e-04
Loss = 1.5507e-05, PNorm = 52.8580, GNorm = 0.0620, lr_0 = 1.3206e-04
Loss = 1.8794e-05, PNorm = 52.8578, GNorm = 0.1066, lr_0 = 1.3192e-04
Loss = 1.1852e-05, PNorm = 52.8577, GNorm = 0.0436, lr_0 = 1.3178e-04
Loss = 1.4149e-05, PNorm = 52.8585, GNorm = 0.0928, lr_0 = 1.3165e-04
Loss = 1.5391e-05, PNorm = 52.8595, GNorm = 0.0869, lr_0 = 1.3151e-04
Loss = 1.8041e-05, PNorm = 52.8596, GNorm = 0.0781, lr_0 = 1.3137e-04
Validation rmse logD = 0.556951
Validation R2 logD = 0.773480
Validation rmse logP = 0.450292
Validation R2 logP = 0.941174
Epoch 88
Train function
Loss = 1.4568e-05, PNorm = 52.8606, GNorm = 0.0916, lr_0 = 1.3124e-04
Loss = 1.4951e-05, PNorm = 52.8612, GNorm = 0.0685, lr_0 = 1.3110e-04
Loss = 1.2998e-05, PNorm = 52.8626, GNorm = 0.0748, lr_0 = 1.3096e-04
Loss = 1.2045e-05, PNorm = 52.8631, GNorm = 0.0608, lr_0 = 1.3082e-04
Loss = 1.5943e-05, PNorm = 52.8639, GNorm = 0.0759, lr_0 = 1.3069e-04
Loss = 1.2987e-05, PNorm = 52.8645, GNorm = 0.0743, lr_0 = 1.3055e-04
Loss = 1.4676e-05, PNorm = 52.8656, GNorm = 0.0755, lr_0 = 1.3042e-04
Loss = 1.5888e-05, PNorm = 52.8665, GNorm = 0.0924, lr_0 = 1.3028e-04
Loss = 1.2334e-05, PNorm = 52.8667, GNorm = 0.0927, lr_0 = 1.3014e-04
Loss = 1.6195e-05, PNorm = 52.8671, GNorm = 0.0922, lr_0 = 1.3001e-04
Loss = 1.4902e-05, PNorm = 52.8673, GNorm = 0.1178, lr_0 = 1.2987e-04
Loss = 2.0266e-05, PNorm = 52.8686, GNorm = 0.1110, lr_0 = 1.2974e-04
Loss = 2.2878e-05, PNorm = 52.8699, GNorm = 0.1288, lr_0 = 1.2960e-04
Loss = 2.4645e-05, PNorm = 52.8713, GNorm = 0.1811, lr_0 = 1.2947e-04
Loss = 2.5719e-05, PNorm = 52.8719, GNorm = 0.0953, lr_0 = 1.2933e-04
Loss = 1.9732e-05, PNorm = 52.8725, GNorm = 0.1955, lr_0 = 1.2920e-04
Loss = 2.4028e-05, PNorm = 52.8732, GNorm = 0.0680, lr_0 = 1.2906e-04
Loss = 2.2277e-05, PNorm = 52.8755, GNorm = 0.1299, lr_0 = 1.2893e-04
Loss = 2.1552e-05, PNorm = 52.8771, GNorm = 0.1332, lr_0 = 1.2879e-04
Loss = 2.0116e-05, PNorm = 52.8774, GNorm = 0.0951, lr_0 = 1.2866e-04
Loss = 2.3047e-05, PNorm = 52.8781, GNorm = 0.0739, lr_0 = 1.2852e-04
Loss = 2.0195e-05, PNorm = 52.8794, GNorm = 0.1163, lr_0 = 1.2839e-04
Validation rmse logD = 0.558665
Validation R2 logD = 0.772083
Validation rmse logP = 0.452350
Validation R2 logP = 0.940635
Epoch 89
Train function
Loss = 1.6051e-05, PNorm = 52.8795, GNorm = 0.0775, lr_0 = 1.2824e-04
Loss = 1.8815e-05, PNorm = 52.8808, GNorm = 0.0918, lr_0 = 1.2811e-04
Loss = 1.9284e-05, PNorm = 52.8821, GNorm = 0.0783, lr_0 = 1.2797e-04
Loss = 1.4885e-05, PNorm = 52.8834, GNorm = 0.0647, lr_0 = 1.2784e-04
Loss = 1.6342e-05, PNorm = 52.8830, GNorm = 0.0556, lr_0 = 1.2771e-04
Loss = 1.7289e-05, PNorm = 52.8839, GNorm = 0.0806, lr_0 = 1.2757e-04
Loss = 1.5774e-05, PNorm = 52.8844, GNorm = 0.0714, lr_0 = 1.2744e-04
Loss = 1.5824e-05, PNorm = 52.8856, GNorm = 0.0808, lr_0 = 1.2731e-04
Loss = 1.7622e-05, PNorm = 52.8871, GNorm = 0.0684, lr_0 = 1.2717e-04
Loss = 1.6282e-05, PNorm = 52.8882, GNorm = 0.0866, lr_0 = 1.2704e-04
Loss = 1.9983e-05, PNorm = 52.8890, GNorm = 0.1477, lr_0 = 1.2691e-04
Loss = 1.7383e-05, PNorm = 52.8887, GNorm = 0.1015, lr_0 = 1.2678e-04
Loss = 1.5058e-05, PNorm = 52.8891, GNorm = 0.0813, lr_0 = 1.2664e-04
Loss = 1.4430e-05, PNorm = 52.8898, GNorm = 0.0721, lr_0 = 1.2651e-04
Loss = 1.2823e-05, PNorm = 52.8907, GNorm = 0.0770, lr_0 = 1.2638e-04
Loss = 1.4710e-05, PNorm = 52.8915, GNorm = 0.0735, lr_0 = 1.2625e-04
Loss = 1.9550e-05, PNorm = 52.8915, GNorm = 0.0826, lr_0 = 1.2612e-04
Loss = 1.6011e-05, PNorm = 52.8920, GNorm = 0.1060, lr_0 = 1.2598e-04
Loss = 1.5193e-05, PNorm = 52.8925, GNorm = 0.1046, lr_0 = 1.2585e-04
Loss = 1.7146e-05, PNorm = 52.8935, GNorm = 0.0765, lr_0 = 1.2572e-04
Loss = 1.3563e-05, PNorm = 52.8933, GNorm = 0.1024, lr_0 = 1.2559e-04
Loss = 1.7658e-05, PNorm = 52.8935, GNorm = 0.1005, lr_0 = 1.2546e-04
Loss = 1.8007e-05, PNorm = 52.8941, GNorm = 0.0713, lr_0 = 1.2533e-04
Validation rmse logD = 0.556604
Validation R2 logD = 0.773762
Validation rmse logP = 0.450263
Validation R2 logP = 0.941181
Epoch 90
Train function
Loss = 1.0231e-05, PNorm = 52.8949, GNorm = 0.0799, lr_0 = 1.2520e-04
Loss = 1.5855e-05, PNorm = 52.8963, GNorm = 0.0458, lr_0 = 1.2507e-04
Loss = 1.2363e-05, PNorm = 52.8974, GNorm = 0.0746, lr_0 = 1.2494e-04
Loss = 1.3904e-05, PNorm = 52.8979, GNorm = 0.0539, lr_0 = 1.2481e-04
Loss = 1.4335e-05, PNorm = 52.8992, GNorm = 0.0970, lr_0 = 1.2468e-04
Loss = 1.2134e-05, PNorm = 52.8996, GNorm = 0.0677, lr_0 = 1.2455e-04
Loss = 1.5544e-05, PNorm = 52.9006, GNorm = 0.1830, lr_0 = 1.2442e-04
Loss = 1.4010e-05, PNorm = 52.9008, GNorm = 0.0716, lr_0 = 1.2429e-04
Loss = 2.2834e-05, PNorm = 52.9011, GNorm = 0.2325, lr_0 = 1.2416e-04
Loss = 1.5657e-05, PNorm = 52.9020, GNorm = 0.0881, lr_0 = 1.2403e-04
Loss = 2.0452e-05, PNorm = 52.9021, GNorm = 0.1036, lr_0 = 1.2390e-04
Loss = 1.4711e-05, PNorm = 52.9026, GNorm = 0.1051, lr_0 = 1.2377e-04
Loss = 1.6540e-05, PNorm = 52.9039, GNorm = 0.0762, lr_0 = 1.2364e-04
Loss = 1.2943e-05, PNorm = 52.9053, GNorm = 0.0999, lr_0 = 1.2351e-04
Loss = 1.8223e-05, PNorm = 52.9062, GNorm = 0.1203, lr_0 = 1.2338e-04
Loss = 1.3817e-05, PNorm = 52.9067, GNorm = 0.0732, lr_0 = 1.2325e-04
Loss = 1.2392e-05, PNorm = 52.9074, GNorm = 0.0619, lr_0 = 1.2312e-04
Loss = 1.2763e-05, PNorm = 52.9082, GNorm = 0.1005, lr_0 = 1.2299e-04
Loss = 1.0636e-05, PNorm = 52.9094, GNorm = 0.0882, lr_0 = 1.2287e-04
Loss = 1.5571e-05, PNorm = 52.9104, GNorm = 0.1213, lr_0 = 1.2274e-04
Loss = 1.5985e-05, PNorm = 52.9112, GNorm = 0.0931, lr_0 = 1.2261e-04
Loss = 1.2522e-05, PNorm = 52.9126, GNorm = 0.1067, lr_0 = 1.2248e-04
Validation rmse logD = 0.556653
Validation R2 logD = 0.773722
Validation rmse logP = 0.451396
Validation R2 logP = 0.940885
Epoch 91
Train function
Loss = 1.2221e-05, PNorm = 52.9131, GNorm = 0.0545, lr_0 = 1.2234e-04
Loss = 1.6895e-05, PNorm = 52.9136, GNorm = 0.0753, lr_0 = 1.2221e-04
Loss = 1.1569e-05, PNorm = 52.9142, GNorm = 0.1135, lr_0 = 1.2209e-04
Loss = 1.5566e-05, PNorm = 52.9146, GNorm = 0.1268, lr_0 = 1.2196e-04
Loss = 1.6769e-05, PNorm = 52.9150, GNorm = 0.1324, lr_0 = 1.2183e-04
Loss = 1.5470e-05, PNorm = 52.9149, GNorm = 0.0616, lr_0 = 1.2170e-04
Loss = 1.4205e-05, PNorm = 52.9156, GNorm = 0.1073, lr_0 = 1.2158e-04
Loss = 1.5827e-05, PNorm = 52.9164, GNorm = 0.0949, lr_0 = 1.2145e-04
Loss = 1.2662e-05, PNorm = 52.9167, GNorm = 0.0857, lr_0 = 1.2132e-04
Loss = 1.9051e-05, PNorm = 52.9176, GNorm = 0.1884, lr_0 = 1.2120e-04
Loss = 1.5410e-05, PNorm = 52.9189, GNorm = 0.1018, lr_0 = 1.2107e-04
Loss = 1.6426e-05, PNorm = 52.9185, GNorm = 0.0830, lr_0 = 1.2094e-04
Loss = 1.7255e-05, PNorm = 52.9194, GNorm = 0.1252, lr_0 = 1.2082e-04
Loss = 1.7796e-05, PNorm = 52.9210, GNorm = 0.0518, lr_0 = 1.2069e-04
Loss = 2.6520e-05, PNorm = 52.9229, GNorm = 0.1507, lr_0 = 1.2057e-04
Loss = 2.0757e-05, PNorm = 52.9249, GNorm = 0.1343, lr_0 = 1.2044e-04
Loss = 1.6136e-05, PNorm = 52.9261, GNorm = 0.0838, lr_0 = 1.2031e-04
Loss = 1.8141e-05, PNorm = 52.9270, GNorm = 0.1457, lr_0 = 1.2019e-04
Loss = 2.0332e-05, PNorm = 52.9277, GNorm = 0.0863, lr_0 = 1.2006e-04
Loss = 1.5965e-05, PNorm = 52.9280, GNorm = 0.0537, lr_0 = 1.1994e-04
Loss = 1.5772e-05, PNorm = 52.9291, GNorm = 0.1158, lr_0 = 1.1981e-04
Loss = 1.6255e-05, PNorm = 52.9314, GNorm = 0.1260, lr_0 = 1.1969e-04
Loss = 1.7089e-05, PNorm = 52.9338, GNorm = 0.1405, lr_0 = 1.1956e-04
Validation rmse logD = 0.558819
Validation R2 logD = 0.771958
Validation rmse logP = 0.450353
Validation R2 logP = 0.941157
Epoch 92
Train function
Loss = 1.6818e-05, PNorm = 52.9340, GNorm = 0.1345, lr_0 = 1.1944e-04
Loss = 1.3773e-05, PNorm = 52.9342, GNorm = 0.0725, lr_0 = 1.1931e-04
Loss = 1.3144e-05, PNorm = 52.9351, GNorm = 0.0658, lr_0 = 1.1919e-04
Loss = 1.9006e-05, PNorm = 52.9367, GNorm = 0.0973, lr_0 = 1.1906e-04
Loss = 1.8375e-05, PNorm = 52.9368, GNorm = 0.1039, lr_0 = 1.1894e-04
Loss = 1.4774e-05, PNorm = 52.9375, GNorm = 0.0642, lr_0 = 1.1882e-04
Loss = 1.0856e-05, PNorm = 52.9387, GNorm = 0.0896, lr_0 = 1.1869e-04
Loss = 1.4401e-05, PNorm = 52.9388, GNorm = 0.0543, lr_0 = 1.1857e-04
Loss = 1.7322e-05, PNorm = 52.9404, GNorm = 0.1148, lr_0 = 1.1844e-04
Loss = 1.3025e-05, PNorm = 52.9411, GNorm = 0.0679, lr_0 = 1.1832e-04
Loss = 1.5345e-05, PNorm = 52.9419, GNorm = 0.0590, lr_0 = 1.1820e-04
Loss = 1.2727e-05, PNorm = 52.9426, GNorm = 0.0795, lr_0 = 1.1807e-04
Loss = 1.2768e-05, PNorm = 52.9424, GNorm = 0.1258, lr_0 = 1.1795e-04
Loss = 1.5505e-05, PNorm = 52.9417, GNorm = 0.1106, lr_0 = 1.1783e-04
Loss = 1.7433e-05, PNorm = 52.9425, GNorm = 0.1055, lr_0 = 1.1770e-04
Loss = 1.0978e-05, PNorm = 52.9432, GNorm = 0.0500, lr_0 = 1.1758e-04
Loss = 1.4547e-05, PNorm = 52.9443, GNorm = 0.0843, lr_0 = 1.1746e-04
Loss = 1.3253e-05, PNorm = 52.9453, GNorm = 0.1302, lr_0 = 1.1734e-04
Loss = 1.3102e-05, PNorm = 52.9457, GNorm = 0.0644, lr_0 = 1.1721e-04
Loss = 1.5088e-05, PNorm = 52.9466, GNorm = 0.0678, lr_0 = 1.1709e-04
Loss = 1.6015e-05, PNorm = 52.9485, GNorm = 0.0694, lr_0 = 1.1697e-04
Loss = 1.3835e-05, PNorm = 52.9489, GNorm = 0.0624, lr_0 = 1.1685e-04
Validation rmse logD = 0.558220
Validation R2 logD = 0.772446
Validation rmse logP = 0.450851
Validation R2 logP = 0.941027
Epoch 93
Train function
Loss = 9.2089e-06, PNorm = 52.9502, GNorm = 0.0687, lr_0 = 1.1671e-04
Loss = 9.6178e-06, PNorm = 52.9504, GNorm = 0.0696, lr_0 = 1.1659e-04
Loss = 1.1708e-05, PNorm = 52.9503, GNorm = 0.1588, lr_0 = 1.1647e-04
Loss = 1.1575e-05, PNorm = 52.9505, GNorm = 0.0723, lr_0 = 1.1635e-04
Loss = 1.1299e-05, PNorm = 52.9511, GNorm = 0.1026, lr_0 = 1.1623e-04
Loss = 1.2495e-05, PNorm = 52.9517, GNorm = 0.0432, lr_0 = 1.1611e-04
Loss = 1.2736e-05, PNorm = 52.9522, GNorm = 0.0743, lr_0 = 1.1598e-04
Loss = 1.2117e-05, PNorm = 52.9525, GNorm = 0.0491, lr_0 = 1.1586e-04
Loss = 1.2112e-05, PNorm = 52.9535, GNorm = 0.0700, lr_0 = 1.1574e-04
Loss = 1.3402e-05, PNorm = 52.9548, GNorm = 0.0607, lr_0 = 1.1562e-04
Loss = 1.2084e-05, PNorm = 52.9553, GNorm = 0.0636, lr_0 = 1.1550e-04
Loss = 1.3950e-05, PNorm = 52.9556, GNorm = 0.0626, lr_0 = 1.1538e-04
Loss = 9.5452e-06, PNorm = 52.9559, GNorm = 0.0869, lr_0 = 1.1526e-04
Loss = 1.3623e-05, PNorm = 52.9567, GNorm = 0.0652, lr_0 = 1.1514e-04
Loss = 1.1608e-05, PNorm = 52.9575, GNorm = 0.0768, lr_0 = 1.1502e-04
Loss = 1.3721e-05, PNorm = 52.9588, GNorm = 0.0664, lr_0 = 1.1490e-04
Loss = 1.3359e-05, PNorm = 52.9595, GNorm = 0.0873, lr_0 = 1.1478e-04
Loss = 1.4054e-05, PNorm = 52.9611, GNorm = 0.0633, lr_0 = 1.1466e-04
Loss = 1.8144e-05, PNorm = 52.9618, GNorm = 0.0636, lr_0 = 1.1454e-04
Loss = 1.2932e-05, PNorm = 52.9621, GNorm = 0.1365, lr_0 = 1.1442e-04
Loss = 1.6418e-05, PNorm = 52.9628, GNorm = 0.1878, lr_0 = 1.1430e-04
Loss = 2.2140e-05, PNorm = 52.9645, GNorm = 0.1037, lr_0 = 1.1418e-04
Loss = 2.0643e-05, PNorm = 52.9652, GNorm = 0.0749, lr_0 = 1.1406e-04
Validation rmse logD = 0.557382
Validation R2 logD = 0.773129
Validation rmse logP = 0.451194
Validation R2 logP = 0.940938
Epoch 94
Train function
Loss = 1.1625e-05, PNorm = 52.9664, GNorm = 0.0916, lr_0 = 1.1394e-04
Loss = 1.3529e-05, PNorm = 52.9669, GNorm = 0.0966, lr_0 = 1.1382e-04
Loss = 1.0674e-05, PNorm = 52.9673, GNorm = 0.0682, lr_0 = 1.1371e-04
Loss = 1.4304e-05, PNorm = 52.9676, GNorm = 0.0974, lr_0 = 1.1359e-04
Loss = 1.5231e-05, PNorm = 52.9683, GNorm = 0.1158, lr_0 = 1.1347e-04
Loss = 1.4055e-05, PNorm = 52.9688, GNorm = 0.0814, lr_0 = 1.1335e-04
Loss = 1.0657e-05, PNorm = 52.9702, GNorm = 0.0623, lr_0 = 1.1323e-04
Loss = 1.2666e-05, PNorm = 52.9710, GNorm = 0.0483, lr_0 = 1.1311e-04
Loss = 1.0687e-05, PNorm = 52.9713, GNorm = 0.1140, lr_0 = 1.1300e-04
Loss = 1.8412e-05, PNorm = 52.9721, GNorm = 0.1410, lr_0 = 1.1288e-04
Loss = 1.2006e-05, PNorm = 52.9732, GNorm = 0.1124, lr_0 = 1.1276e-04
Loss = 1.2663e-05, PNorm = 52.9739, GNorm = 0.0559, lr_0 = 1.1264e-04
Loss = 1.3372e-05, PNorm = 52.9743, GNorm = 0.0521, lr_0 = 1.1252e-04
Loss = 1.0567e-05, PNorm = 52.9743, GNorm = 0.0899, lr_0 = 1.1241e-04
Loss = 1.6658e-05, PNorm = 52.9745, GNorm = 0.0713, lr_0 = 1.1229e-04
Loss = 1.1449e-05, PNorm = 52.9761, GNorm = 0.0692, lr_0 = 1.1217e-04
Loss = 1.1962e-05, PNorm = 52.9767, GNorm = 0.0813, lr_0 = 1.1206e-04
Loss = 1.3788e-05, PNorm = 52.9772, GNorm = 0.0750, lr_0 = 1.1194e-04
Loss = 1.0983e-05, PNorm = 52.9785, GNorm = 0.0908, lr_0 = 1.1182e-04
Loss = 1.6282e-05, PNorm = 52.9782, GNorm = 0.1016, lr_0 = 1.1170e-04
Loss = 1.1590e-05, PNorm = 52.9782, GNorm = 0.0549, lr_0 = 1.1159e-04
Loss = 1.2181e-05, PNorm = 52.9791, GNorm = 0.0586, lr_0 = 1.1147e-04
Loss = 1.2268e-05, PNorm = 52.9790, GNorm = 0.0941, lr_0 = 1.1136e-04
Loss = 3.1086e-05, PNorm = 52.9791, GNorm = 0.0930, lr_0 = 1.1134e-04
Validation rmse logD = 0.556494
Validation R2 logD = 0.773851
Validation rmse logP = 0.449285
Validation R2 logP = 0.941436
Epoch 95
Train function
Loss = 1.1017e-05, PNorm = 52.9796, GNorm = 0.0792, lr_0 = 1.1123e-04
Loss = 1.3158e-05, PNorm = 52.9800, GNorm = 0.0845, lr_0 = 1.1111e-04
Loss = 1.1995e-05, PNorm = 52.9809, GNorm = 0.0684, lr_0 = 1.1100e-04
Loss = 1.2113e-05, PNorm = 52.9818, GNorm = 0.1116, lr_0 = 1.1088e-04
Loss = 1.0591e-05, PNorm = 52.9816, GNorm = 0.0697, lr_0 = 1.1076e-04
Loss = 9.3906e-06, PNorm = 52.9818, GNorm = 0.0541, lr_0 = 1.1065e-04
Loss = 9.8205e-06, PNorm = 52.9823, GNorm = 0.0734, lr_0 = 1.1053e-04
Loss = 7.7537e-06, PNorm = 52.9822, GNorm = 0.0684, lr_0 = 1.1042e-04
Loss = 1.2628e-05, PNorm = 52.9825, GNorm = 0.1161, lr_0 = 1.1030e-04
Loss = 1.4606e-05, PNorm = 52.9825, GNorm = 0.0561, lr_0 = 1.1019e-04
Loss = 1.6756e-05, PNorm = 52.9832, GNorm = 0.0858, lr_0 = 1.1007e-04
Loss = 1.3116e-05, PNorm = 52.9838, GNorm = 0.0678, lr_0 = 1.0996e-04
Loss = 1.0683e-05, PNorm = 52.9845, GNorm = 0.0902, lr_0 = 1.0984e-04
Loss = 1.3300e-05, PNorm = 52.9856, GNorm = 0.0894, lr_0 = 1.0973e-04
Loss = 1.6180e-05, PNorm = 52.9863, GNorm = 0.0859, lr_0 = 1.0961e-04
Loss = 1.0391e-05, PNorm = 52.9870, GNorm = 0.0554, lr_0 = 1.0950e-04
Loss = 9.3281e-06, PNorm = 52.9878, GNorm = 0.0351, lr_0 = 1.0938e-04
Loss = 1.2824e-05, PNorm = 52.9881, GNorm = 0.0850, lr_0 = 1.0927e-04
Loss = 1.3272e-05, PNorm = 52.9887, GNorm = 0.1465, lr_0 = 1.0916e-04
Loss = 1.2722e-05, PNorm = 52.9892, GNorm = 0.0648, lr_0 = 1.0904e-04
Loss = 1.3908e-05, PNorm = 52.9900, GNorm = 0.0677, lr_0 = 1.0893e-04
Loss = 1.1680e-05, PNorm = 52.9912, GNorm = 0.0667, lr_0 = 1.0882e-04
Validation rmse logD = 0.558323
Validation R2 logD = 0.772363
Validation rmse logP = 0.451248
Validation R2 logP = 0.940924
Epoch 96
Train function
Loss = 9.6767e-06, PNorm = 52.9926, GNorm = 0.0512, lr_0 = 1.0870e-04
Loss = 1.2568e-05, PNorm = 52.9930, GNorm = 0.1188, lr_0 = 1.0859e-04
Loss = 1.2226e-05, PNorm = 52.9928, GNorm = 0.0943, lr_0 = 1.0847e-04
Loss = 1.3030e-05, PNorm = 52.9936, GNorm = 0.1094, lr_0 = 1.0836e-04
Loss = 1.2078e-05, PNorm = 52.9945, GNorm = 0.1133, lr_0 = 1.0825e-04
Loss = 9.2041e-06, PNorm = 52.9944, GNorm = 0.0741, lr_0 = 1.0814e-04
Loss = 1.0449e-05, PNorm = 52.9949, GNorm = 0.0778, lr_0 = 1.0802e-04
Loss = 1.1665e-05, PNorm = 52.9957, GNorm = 0.1020, lr_0 = 1.0791e-04
Loss = 1.3167e-05, PNorm = 52.9961, GNorm = 0.0739, lr_0 = 1.0780e-04
Loss = 1.2984e-05, PNorm = 52.9966, GNorm = 0.1197, lr_0 = 1.0768e-04
Loss = 1.2361e-05, PNorm = 52.9970, GNorm = 0.1349, lr_0 = 1.0757e-04
Loss = 1.0961e-05, PNorm = 52.9976, GNorm = 0.0522, lr_0 = 1.0746e-04
Loss = 1.0920e-05, PNorm = 52.9983, GNorm = 0.0569, lr_0 = 1.0735e-04
Loss = 1.2436e-05, PNorm = 52.9987, GNorm = 0.0931, lr_0 = 1.0724e-04
Loss = 1.5920e-05, PNorm = 52.9996, GNorm = 0.0926, lr_0 = 1.0712e-04
Loss = 1.5789e-05, PNorm = 53.0012, GNorm = 0.0707, lr_0 = 1.0701e-04
Loss = 1.2993e-05, PNorm = 53.0019, GNorm = 0.0972, lr_0 = 1.0690e-04
Loss = 1.3554e-05, PNorm = 53.0016, GNorm = 0.1310, lr_0 = 1.0679e-04
Loss = 1.4182e-05, PNorm = 53.0024, GNorm = 0.0602, lr_0 = 1.0668e-04
Loss = 1.4354e-05, PNorm = 53.0029, GNorm = 0.0842, lr_0 = 1.0657e-04
Loss = 1.3144e-05, PNorm = 53.0033, GNorm = 0.0862, lr_0 = 1.0645e-04
Loss = 1.1971e-05, PNorm = 53.0053, GNorm = 0.0574, lr_0 = 1.0634e-04
Loss = 1.1495e-05, PNorm = 53.0063, GNorm = 0.0717, lr_0 = 1.0623e-04
Validation rmse logD = 0.557877
Validation R2 logD = 0.772726
Validation rmse logP = 0.449264
Validation R2 logP = 0.941442
Epoch 97
Train function
Loss = 1.4295e-05, PNorm = 53.0063, GNorm = 0.0754, lr_0 = 1.0611e-04
Loss = 1.3459e-05, PNorm = 53.0067, GNorm = 0.0709, lr_0 = 1.0600e-04
Loss = 1.3606e-05, PNorm = 53.0079, GNorm = 0.1098, lr_0 = 1.0589e-04
Loss = 1.1618e-05, PNorm = 53.0085, GNorm = 0.0458, lr_0 = 1.0578e-04
Loss = 1.2016e-05, PNorm = 53.0092, GNorm = 0.0533, lr_0 = 1.0567e-04
Loss = 1.1253e-05, PNorm = 53.0095, GNorm = 0.0859, lr_0 = 1.0556e-04
Loss = 9.7364e-06, PNorm = 53.0096, GNorm = 0.0698, lr_0 = 1.0545e-04
Loss = 1.3464e-05, PNorm = 53.0106, GNorm = 0.0925, lr_0 = 1.0534e-04
Loss = 1.3461e-05, PNorm = 53.0124, GNorm = 0.0583, lr_0 = 1.0523e-04
Loss = 1.5873e-05, PNorm = 53.0134, GNorm = 0.1386, lr_0 = 1.0512e-04
Loss = 1.4150e-05, PNorm = 53.0134, GNorm = 0.0902, lr_0 = 1.0501e-04
Loss = 9.1340e-06, PNorm = 53.0137, GNorm = 0.0577, lr_0 = 1.0490e-04
Loss = 9.4346e-06, PNorm = 53.0139, GNorm = 0.0551, lr_0 = 1.0479e-04
Loss = 1.1070e-05, PNorm = 53.0135, GNorm = 0.1007, lr_0 = 1.0468e-04
Loss = 1.3662e-05, PNorm = 53.0141, GNorm = 0.0543, lr_0 = 1.0457e-04
Loss = 9.5910e-06, PNorm = 53.0145, GNorm = 0.0951, lr_0 = 1.0446e-04
Loss = 1.3179e-05, PNorm = 53.0149, GNorm = 0.1644, lr_0 = 1.0435e-04
Loss = 1.3026e-05, PNorm = 53.0142, GNorm = 0.0748, lr_0 = 1.0424e-04
Loss = 1.0983e-05, PNorm = 53.0141, GNorm = 0.0960, lr_0 = 1.0413e-04
Loss = 1.3154e-05, PNorm = 53.0149, GNorm = 0.0501, lr_0 = 1.0403e-04
Loss = 1.5750e-05, PNorm = 53.0148, GNorm = 0.0542, lr_0 = 1.0392e-04
Loss = 1.1937e-05, PNorm = 53.0157, GNorm = 0.0619, lr_0 = 1.0381e-04
Validation rmse logD = 0.558261
Validation R2 logD = 0.772413
Validation rmse logP = 0.450716
Validation R2 logP = 0.941063
Epoch 98
Train function
Loss = 1.7325e-05, PNorm = 53.0165, GNorm = 0.0700, lr_0 = 1.0370e-04
Loss = 1.3965e-05, PNorm = 53.0180, GNorm = 0.1029, lr_0 = 1.0359e-04
Loss = 1.3524e-05, PNorm = 53.0185, GNorm = 0.0689, lr_0 = 1.0348e-04
Loss = 1.3218e-05, PNorm = 53.0192, GNorm = 0.0489, lr_0 = 1.0338e-04
Loss = 1.0932e-05, PNorm = 53.0196, GNorm = 0.0668, lr_0 = 1.0327e-04
Loss = 1.0236e-05, PNorm = 53.0202, GNorm = 0.0625, lr_0 = 1.0316e-04
Loss = 8.9404e-06, PNorm = 53.0207, GNorm = 0.1298, lr_0 = 1.0305e-04
Loss = 1.0774e-05, PNorm = 53.0212, GNorm = 0.0813, lr_0 = 1.0295e-04
Loss = 8.9600e-06, PNorm = 53.0213, GNorm = 0.0578, lr_0 = 1.0284e-04
Loss = 8.3640e-06, PNorm = 53.0217, GNorm = 0.0639, lr_0 = 1.0273e-04
Loss = 9.1469e-06, PNorm = 53.0219, GNorm = 0.0554, lr_0 = 1.0262e-04
Loss = 1.0261e-05, PNorm = 53.0228, GNorm = 0.0440, lr_0 = 1.0252e-04
Loss = 9.2293e-06, PNorm = 53.0238, GNorm = 0.0366, lr_0 = 1.0241e-04
Loss = 1.1329e-05, PNorm = 53.0239, GNorm = 0.0784, lr_0 = 1.0230e-04
Loss = 9.2480e-06, PNorm = 53.0246, GNorm = 0.1134, lr_0 = 1.0220e-04
Loss = 1.4246e-05, PNorm = 53.0250, GNorm = 0.0725, lr_0 = 1.0209e-04
Loss = 1.4684e-05, PNorm = 53.0255, GNorm = 0.0579, lr_0 = 1.0198e-04
Loss = 1.4555e-05, PNorm = 53.0255, GNorm = 0.0859, lr_0 = 1.0188e-04
Loss = 1.3500e-05, PNorm = 53.0261, GNorm = 0.0922, lr_0 = 1.0177e-04
Loss = 1.2955e-05, PNorm = 53.0273, GNorm = 0.0848, lr_0 = 1.0166e-04
Loss = 1.1932e-05, PNorm = 53.0286, GNorm = 0.1088, lr_0 = 1.0156e-04
Loss = 1.0265e-05, PNorm = 53.0297, GNorm = 0.0616, lr_0 = 1.0145e-04
Loss = 1.3486e-05, PNorm = 53.0307, GNorm = 0.0708, lr_0 = 1.0135e-04
Validation rmse logD = 0.557718
Validation R2 logD = 0.772855
Validation rmse logP = 0.449693
Validation R2 logP = 0.941330
Epoch 99
Train function
Loss = 1.0563e-05, PNorm = 53.0309, GNorm = 0.0961, lr_0 = 1.0123e-04
Loss = 8.5788e-06, PNorm = 53.0312, GNorm = 0.0785, lr_0 = 1.0112e-04
Loss = 1.1563e-05, PNorm = 53.0317, GNorm = 0.1273, lr_0 = 1.0102e-04
Loss = 1.3028e-05, PNorm = 53.0321, GNorm = 0.0916, lr_0 = 1.0091e-04
Loss = 1.4557e-05, PNorm = 53.0332, GNorm = 0.0885, lr_0 = 1.0081e-04
Loss = 1.2850e-05, PNorm = 53.0344, GNorm = 0.1093, lr_0 = 1.0070e-04
Loss = 9.7658e-06, PNorm = 53.0347, GNorm = 0.0404, lr_0 = 1.0060e-04
Loss = 1.1718e-05, PNorm = 53.0349, GNorm = 0.0552, lr_0 = 1.0049e-04
Loss = 1.1744e-05, PNorm = 53.0357, GNorm = 0.0728, lr_0 = 1.0039e-04
Loss = 9.9294e-06, PNorm = 53.0363, GNorm = 0.0659, lr_0 = 1.0028e-04
Loss = 1.0138e-05, PNorm = 53.0366, GNorm = 0.0642, lr_0 = 1.0018e-04
Loss = 1.1401e-05, PNorm = 53.0374, GNorm = 0.0747, lr_0 = 1.0007e-04
Loss = 1.3370e-05, PNorm = 53.0379, GNorm = 0.1539, lr_0 = 1.0000e-04
Loss = 1.1328e-05, PNorm = 53.0391, GNorm = 0.0910, lr_0 = 1.0000e-04
Loss = 1.1238e-05, PNorm = 53.0398, GNorm = 0.0725, lr_0 = 1.0000e-04
Loss = 1.0115e-05, PNorm = 53.0403, GNorm = 0.0741, lr_0 = 1.0000e-04
Loss = 9.2318e-06, PNorm = 53.0410, GNorm = 0.0645, lr_0 = 1.0000e-04
Loss = 1.3718e-05, PNorm = 53.0410, GNorm = 0.1299, lr_0 = 1.0000e-04
Loss = 1.5931e-05, PNorm = 53.0410, GNorm = 0.1217, lr_0 = 1.0000e-04
Loss = 1.7354e-05, PNorm = 53.0405, GNorm = 0.0700, lr_0 = 1.0000e-04
Loss = 2.1289e-05, PNorm = 53.0417, GNorm = 0.1126, lr_0 = 1.0000e-04
Loss = 1.9661e-05, PNorm = 53.0428, GNorm = 0.1331, lr_0 = 1.0000e-04
Validation rmse logD = 0.558450
Validation R2 logD = 0.772258
Validation rmse logP = 0.451761
Validation R2 logP = 0.940789
Model 0 best validation rmse = 0.500201 on epoch 52
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.557129
Model 0 test R2 logD = 0.803136
Model 0 test rmse logP = 0.436604
Model 0 test R2 logP = 0.945248
Ensemble test rmse  logD= 0.557129
Ensemble test R2  logD= 0.803136
Ensemble test rmse  logP= 0.436604
Ensemble test R2  logP= 0.945248
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 2.3879e-02, PNorm = 35.0903, GNorm = 4.4101, lr_0 = 1.2200e-04
Loss = 1.6667e-02, PNorm = 35.0923, GNorm = 3.6966, lr_0 = 1.4200e-04
Loss = 1.4629e-02, PNorm = 35.0953, GNorm = 2.3955, lr_0 = 1.6200e-04
Loss = 1.4800e-02, PNorm = 35.1003, GNorm = 1.9316, lr_0 = 1.8200e-04
Loss = 1.1833e-02, PNorm = 35.1053, GNorm = 8.7646, lr_0 = 2.0200e-04
Loss = 1.0397e-02, PNorm = 35.1114, GNorm = 2.2421, lr_0 = 2.2200e-04
Loss = 1.0352e-02, PNorm = 35.1182, GNorm = 3.8206, lr_0 = 2.4200e-04
Loss = 1.1112e-02, PNorm = 35.1233, GNorm = 1.2861, lr_0 = 2.6200e-04
Loss = 9.8195e-03, PNorm = 35.1294, GNorm = 3.4104, lr_0 = 2.8200e-04
Loss = 7.9210e-03, PNorm = 35.1373, GNorm = 3.3847, lr_0 = 3.0200e-04
Loss = 6.8639e-03, PNorm = 35.1442, GNorm = 6.5577, lr_0 = 3.2200e-04
Loss = 8.0577e-03, PNorm = 35.1497, GNorm = 3.6707, lr_0 = 3.4200e-04
Loss = 7.0708e-03, PNorm = 35.1587, GNorm = 1.6998, lr_0 = 3.6200e-04
Loss = 7.0683e-03, PNorm = 35.1733, GNorm = 2.2662, lr_0 = 3.8200e-04
Loss = 6.0326e-03, PNorm = 35.1850, GNorm = 4.4200, lr_0 = 4.0200e-04
Loss = 6.2068e-03, PNorm = 35.1923, GNorm = 4.3927, lr_0 = 4.2200e-04
Loss = 8.3222e-03, PNorm = 35.2066, GNorm = 3.5868, lr_0 = 4.4200e-04
Loss = 7.4077e-03, PNorm = 35.2182, GNorm = 5.6993, lr_0 = 4.6200e-04
Loss = 6.8256e-03, PNorm = 35.2317, GNorm = 2.6104, lr_0 = 4.8200e-04
Loss = 7.5028e-03, PNorm = 35.2435, GNorm = 3.1208, lr_0 = 5.0200e-04
Loss = 6.1654e-03, PNorm = 35.2585, GNorm = 2.7140, lr_0 = 5.2200e-04
Loss = 6.4384e-03, PNorm = 35.2770, GNorm = 5.9230, lr_0 = 5.4200e-04
Validation rmse logD = 0.927155
Validation R2 logD = 0.391596
Validation rmse logP = 0.836965
Validation R2 logP = 0.794953
Epoch 1
Train function
Loss = 5.3160e-03, PNorm = 35.3001, GNorm = 2.1271, lr_0 = 5.6400e-04
Loss = 5.9031e-03, PNorm = 35.3192, GNorm = 1.6688, lr_0 = 5.8400e-04
Loss = 5.9619e-03, PNorm = 35.3377, GNorm = 3.1069, lr_0 = 6.0400e-04
Loss = 6.4127e-03, PNorm = 35.3566, GNorm = 3.1290, lr_0 = 6.2400e-04
Loss = 5.2343e-03, PNorm = 35.3780, GNorm = 2.1227, lr_0 = 6.4400e-04
Loss = 5.0299e-03, PNorm = 35.4054, GNorm = 1.5147, lr_0 = 6.6400e-04
Loss = 6.2735e-03, PNorm = 35.4233, GNorm = 1.8770, lr_0 = 6.8400e-04
Loss = 5.6712e-03, PNorm = 35.4437, GNorm = 4.5450, lr_0 = 7.0400e-04
Loss = 5.0669e-03, PNorm = 35.4634, GNorm = 2.8027, lr_0 = 7.2400e-04
Loss = 5.6453e-03, PNorm = 35.4895, GNorm = 1.2023, lr_0 = 7.4400e-04
Loss = 4.7896e-03, PNorm = 35.5216, GNorm = 4.1499, lr_0 = 7.6400e-04
Loss = 5.2239e-03, PNorm = 35.5448, GNorm = 3.6244, lr_0 = 7.8400e-04
Loss = 6.3146e-03, PNorm = 35.5646, GNorm = 3.0662, lr_0 = 8.0400e-04
Loss = 6.1978e-03, PNorm = 35.5928, GNorm = 2.1447, lr_0 = 8.2400e-04
Loss = 7.4764e-03, PNorm = 35.6289, GNorm = 2.3853, lr_0 = 8.4400e-04
Loss = 5.5239e-03, PNorm = 35.6661, GNorm = 1.4845, lr_0 = 8.6400e-04
Loss = 6.5994e-03, PNorm = 35.7014, GNorm = 4.0729, lr_0 = 8.8400e-04
Loss = 5.4112e-03, PNorm = 35.7321, GNorm = 1.7133, lr_0 = 9.0400e-04
Loss = 4.8558e-03, PNorm = 35.7696, GNorm = 3.1421, lr_0 = 9.2400e-04
Loss = 5.2218e-03, PNorm = 35.8029, GNorm = 3.2692, lr_0 = 9.4400e-04
Loss = 5.2203e-03, PNorm = 35.8359, GNorm = 1.2810, lr_0 = 9.6400e-04
Loss = 4.3010e-03, PNorm = 35.8712, GNorm = 4.1999, lr_0 = 9.8400e-04
Loss = 5.4205e-03, PNorm = 35.9089, GNorm = 3.3792, lr_0 = 9.9979e-04
Loss = 9.4950e-03, PNorm = 35.9123, GNorm = 3.6174, lr_0 = 9.9969e-04
Validation rmse logD = 0.881355
Validation R2 logD = 0.450221
Validation rmse logP = 0.704349
Validation R2 logP = 0.854784
Epoch 2
Train function
Loss = 4.7367e-03, PNorm = 35.9529, GNorm = 1.7172, lr_0 = 9.9864e-04
Loss = 4.5544e-03, PNorm = 36.0003, GNorm = 1.9294, lr_0 = 9.9760e-04
Loss = 4.3353e-03, PNorm = 36.0403, GNorm = 1.3293, lr_0 = 9.9656e-04
Loss = 4.6844e-03, PNorm = 36.0747, GNorm = 2.2171, lr_0 = 9.9552e-04
Loss = 4.7152e-03, PNorm = 36.1038, GNorm = 1.2615, lr_0 = 9.9448e-04
Loss = 3.8988e-03, PNorm = 36.1369, GNorm = 0.9358, lr_0 = 9.9344e-04
Loss = 4.5470e-03, PNorm = 36.1669, GNorm = 2.5165, lr_0 = 9.9241e-04
Loss = 4.1600e-03, PNorm = 36.1970, GNorm = 3.1968, lr_0 = 9.9137e-04
Loss = 4.0166e-03, PNorm = 36.2210, GNorm = 2.6041, lr_0 = 9.9034e-04
Loss = 5.3755e-03, PNorm = 36.2436, GNorm = 1.6924, lr_0 = 9.8930e-04
Loss = 4.2354e-03, PNorm = 36.2690, GNorm = 0.7839, lr_0 = 9.8827e-04
Loss = 4.2039e-03, PNorm = 36.2941, GNorm = 0.8326, lr_0 = 9.8724e-04
Loss = 4.1943e-03, PNorm = 36.3291, GNorm = 1.9062, lr_0 = 9.8621e-04
Loss = 3.5654e-03, PNorm = 36.3564, GNorm = 2.8654, lr_0 = 9.8518e-04
Loss = 4.1871e-03, PNorm = 36.3815, GNorm = 1.0334, lr_0 = 9.8415e-04
Loss = 3.4451e-03, PNorm = 36.4054, GNorm = 1.0490, lr_0 = 9.8312e-04
Loss = 4.0564e-03, PNorm = 36.4404, GNorm = 3.1087, lr_0 = 9.8210e-04
Loss = 3.6621e-03, PNorm = 36.4581, GNorm = 1.1687, lr_0 = 9.8107e-04
Loss = 3.2324e-03, PNorm = 36.4820, GNorm = 0.7627, lr_0 = 9.8005e-04
Loss = 3.9474e-03, PNorm = 36.5040, GNorm = 2.4081, lr_0 = 9.7902e-04
Loss = 3.8311e-03, PNorm = 36.5203, GNorm = 3.2274, lr_0 = 9.7800e-04
Loss = 4.3542e-03, PNorm = 36.5613, GNorm = 1.4246, lr_0 = 9.7698e-04
Validation rmse logD = 0.794438
Validation R2 logD = 0.553309
Validation rmse logP = 0.744424
Validation R2 logP = 0.837789
Epoch 3
Train function
Loss = 3.5066e-03, PNorm = 36.6010, GNorm = 1.2726, lr_0 = 9.7596e-04
Loss = 4.1978e-03, PNorm = 36.6390, GNorm = 1.8778, lr_0 = 9.7494e-04
Loss = 4.5892e-03, PNorm = 36.6829, GNorm = 2.1282, lr_0 = 9.7393e-04
Loss = 3.4088e-03, PNorm = 36.7176, GNorm = 0.8910, lr_0 = 9.7291e-04
Loss = 3.4329e-03, PNorm = 36.7484, GNorm = 1.1863, lr_0 = 9.7189e-04
Loss = 2.8830e-03, PNorm = 36.7840, GNorm = 1.1138, lr_0 = 9.7088e-04
Loss = 3.2610e-03, PNorm = 36.8084, GNorm = 1.0745, lr_0 = 9.6987e-04
Loss = 2.9006e-03, PNorm = 36.8324, GNorm = 2.7778, lr_0 = 9.6885e-04
Loss = 3.5435e-03, PNorm = 36.8495, GNorm = 3.6240, lr_0 = 9.6784e-04
Loss = 2.6985e-03, PNorm = 36.8893, GNorm = 1.3780, lr_0 = 9.6683e-04
Loss = 2.9717e-03, PNorm = 36.9208, GNorm = 1.2273, lr_0 = 9.6582e-04
Loss = 3.3066e-03, PNorm = 36.9572, GNorm = 1.2406, lr_0 = 9.6482e-04
Loss = 2.9488e-03, PNorm = 36.9851, GNorm = 1.2733, lr_0 = 9.6381e-04
Loss = 3.3933e-03, PNorm = 37.0205, GNorm = 2.2817, lr_0 = 9.6280e-04
Loss = 4.2333e-03, PNorm = 37.0479, GNorm = 0.8071, lr_0 = 9.6180e-04
Loss = 3.5189e-03, PNorm = 37.0778, GNorm = 0.8184, lr_0 = 9.6079e-04
Loss = 4.1592e-03, PNorm = 37.1074, GNorm = 1.8095, lr_0 = 9.5979e-04
Loss = 3.3106e-03, PNorm = 37.1311, GNorm = 1.6292, lr_0 = 9.5879e-04
Loss = 3.4117e-03, PNorm = 37.1629, GNorm = 1.0463, lr_0 = 9.5779e-04
Loss = 2.9620e-03, PNorm = 37.1903, GNorm = 1.1284, lr_0 = 9.5679e-04
Loss = 3.3216e-03, PNorm = 37.2148, GNorm = 1.2571, lr_0 = 9.5579e-04
Loss = 3.1909e-03, PNorm = 37.2413, GNorm = 0.9817, lr_0 = 9.5479e-04
Loss = 2.9579e-03, PNorm = 37.2755, GNorm = 1.4638, lr_0 = 9.5380e-04
Validation rmse logD = 0.759724
Validation R2 logD = 0.591494
Validation rmse logP = 0.604129
Validation R2 logP = 0.893169
Epoch 4
Train function
Loss = 2.8229e-03, PNorm = 37.3073, GNorm = 1.1541, lr_0 = 9.5270e-04
Loss = 3.3452e-03, PNorm = 37.3322, GNorm = 2.2830, lr_0 = 9.5171e-04
Loss = 2.5416e-03, PNorm = 37.3572, GNorm = 0.9736, lr_0 = 9.5071e-04
Loss = 2.5831e-03, PNorm = 37.3806, GNorm = 0.8815, lr_0 = 9.4972e-04
Loss = 2.6566e-03, PNorm = 37.3996, GNorm = 1.0987, lr_0 = 9.4873e-04
Loss = 2.9618e-03, PNorm = 37.4256, GNorm = 1.5719, lr_0 = 9.4774e-04
Loss = 2.5858e-03, PNorm = 37.4541, GNorm = 0.8436, lr_0 = 9.4675e-04
Loss = 2.9443e-03, PNorm = 37.4860, GNorm = 0.7278, lr_0 = 9.4576e-04
Loss = 2.3885e-03, PNorm = 37.5211, GNorm = 1.0922, lr_0 = 9.4478e-04
Loss = 2.6892e-03, PNorm = 37.5441, GNorm = 1.3766, lr_0 = 9.4379e-04
Loss = 3.0618e-03, PNorm = 37.5614, GNorm = 0.8065, lr_0 = 9.4280e-04
Loss = 2.5965e-03, PNorm = 37.5922, GNorm = 0.8356, lr_0 = 9.4182e-04
Loss = 3.2523e-03, PNorm = 37.6282, GNorm = 0.6839, lr_0 = 9.4084e-04
Loss = 3.2208e-03, PNorm = 37.6652, GNorm = 1.8592, lr_0 = 9.3986e-04
Loss = 3.0643e-03, PNorm = 37.6928, GNorm = 0.9239, lr_0 = 9.3887e-04
Loss = 2.5421e-03, PNorm = 37.7136, GNorm = 1.2362, lr_0 = 9.3789e-04
Loss = 2.9787e-03, PNorm = 37.7416, GNorm = 1.2181, lr_0 = 9.3692e-04
Loss = 3.1266e-03, PNorm = 37.7785, GNorm = 1.2812, lr_0 = 9.3594e-04
Loss = 2.8543e-03, PNorm = 37.8145, GNorm = 0.5860, lr_0 = 9.3496e-04
Loss = 3.2008e-03, PNorm = 37.8511, GNorm = 1.3444, lr_0 = 9.3399e-04
Loss = 2.6300e-03, PNorm = 37.8802, GNorm = 1.3026, lr_0 = 9.3301e-04
Loss = 2.9628e-03, PNorm = 37.8987, GNorm = 2.5003, lr_0 = 9.3204e-04
Validation rmse logD = 0.717050
Validation R2 logD = 0.636097
Validation rmse logP = 0.581345
Validation R2 logP = 0.901075
Epoch 5
Train function
Loss = 3.6815e-03, PNorm = 37.9223, GNorm = 1.8085, lr_0 = 9.3106e-04
Loss = 1.8365e-03, PNorm = 37.9514, GNorm = 0.6028, lr_0 = 9.3009e-04
Loss = 2.7102e-03, PNorm = 37.9752, GNorm = 1.1838, lr_0 = 9.2912e-04
Loss = 2.6165e-03, PNorm = 38.0109, GNorm = 1.2622, lr_0 = 9.2815e-04
Loss = 2.5331e-03, PNorm = 38.0322, GNorm = 2.5507, lr_0 = 9.2718e-04
Loss = 2.7062e-03, PNorm = 38.0648, GNorm = 1.5384, lr_0 = 9.2622e-04
Loss = 2.6238e-03, PNorm = 38.1002, GNorm = 1.1750, lr_0 = 9.2525e-04
Loss = 2.6462e-03, PNorm = 38.1308, GNorm = 0.7314, lr_0 = 9.2428e-04
Loss = 2.6720e-03, PNorm = 38.1626, GNorm = 2.3293, lr_0 = 9.2332e-04
Loss = 3.1027e-03, PNorm = 38.1905, GNorm = 2.3505, lr_0 = 9.2235e-04
Loss = 2.4358e-03, PNorm = 38.2274, GNorm = 0.6850, lr_0 = 9.2139e-04
Loss = 3.2269e-03, PNorm = 38.2597, GNorm = 1.9141, lr_0 = 9.2043e-04
Loss = 3.2670e-03, PNorm = 38.2924, GNorm = 1.2112, lr_0 = 9.1947e-04
Loss = 2.2148e-03, PNorm = 38.3203, GNorm = 0.8709, lr_0 = 9.1851e-04
Loss = 2.7311e-03, PNorm = 38.3476, GNorm = 2.6282, lr_0 = 9.1755e-04
Loss = 2.2724e-03, PNorm = 38.3745, GNorm = 1.2023, lr_0 = 9.1659e-04
Loss = 2.7068e-03, PNorm = 38.3990, GNorm = 1.3245, lr_0 = 9.1564e-04
Loss = 2.3580e-03, PNorm = 38.4277, GNorm = 0.9370, lr_0 = 9.1468e-04
Loss = 2.1793e-03, PNorm = 38.4582, GNorm = 0.7941, lr_0 = 9.1373e-04
Loss = 2.1885e-03, PNorm = 38.4762, GNorm = 0.6464, lr_0 = 9.1277e-04
Loss = 1.9888e-03, PNorm = 38.4968, GNorm = 1.0933, lr_0 = 9.1182e-04
Loss = 2.3055e-03, PNorm = 38.5212, GNorm = 0.9154, lr_0 = 9.1087e-04
Loss = 2.4864e-03, PNorm = 38.5444, GNorm = 1.0330, lr_0 = 9.0992e-04
Validation rmse logD = 0.759388
Validation R2 logD = 0.591855
Validation rmse logP = 0.545641
Validation R2 logP = 0.912853
Epoch 6
Train function
Loss = 2.5690e-03, PNorm = 38.5682, GNorm = 1.2776, lr_0 = 9.0887e-04
Loss = 2.0321e-03, PNorm = 38.6058, GNorm = 1.8571, lr_0 = 9.0792e-04
Loss = 2.2752e-03, PNorm = 38.6250, GNorm = 1.0903, lr_0 = 9.0698e-04
Loss = 2.3141e-03, PNorm = 38.6564, GNorm = 1.8931, lr_0 = 9.0603e-04
Loss = 2.1681e-03, PNorm = 38.6820, GNorm = 0.7806, lr_0 = 9.0508e-04
Loss = 1.8016e-03, PNorm = 38.7119, GNorm = 1.0187, lr_0 = 9.0414e-04
Loss = 1.8374e-03, PNorm = 38.7290, GNorm = 0.7912, lr_0 = 9.0320e-04
Loss = 2.0744e-03, PNorm = 38.7582, GNorm = 0.8954, lr_0 = 9.0225e-04
Loss = 2.4711e-03, PNorm = 38.7838, GNorm = 1.4302, lr_0 = 9.0131e-04
Loss = 1.9811e-03, PNorm = 38.8140, GNorm = 1.1454, lr_0 = 9.0037e-04
Loss = 2.0151e-03, PNorm = 38.8368, GNorm = 0.9553, lr_0 = 8.9943e-04
Loss = 2.5578e-03, PNorm = 38.8662, GNorm = 1.0341, lr_0 = 8.9849e-04
Loss = 3.0596e-03, PNorm = 38.8903, GNorm = 0.8881, lr_0 = 8.9756e-04
Loss = 2.3004e-03, PNorm = 38.9262, GNorm = 1.4186, lr_0 = 8.9662e-04
Loss = 2.1331e-03, PNorm = 38.9535, GNorm = 0.8187, lr_0 = 8.9568e-04
Loss = 2.7629e-03, PNorm = 38.9741, GNorm = 1.0113, lr_0 = 8.9475e-04
Loss = 2.4811e-03, PNorm = 38.9967, GNorm = 1.1476, lr_0 = 8.9381e-04
Loss = 2.5528e-03, PNorm = 39.0251, GNorm = 1.1348, lr_0 = 8.9288e-04
Loss = 1.9012e-03, PNorm = 39.0514, GNorm = 1.2497, lr_0 = 8.9195e-04
Loss = 1.8908e-03, PNorm = 39.0709, GNorm = 0.9021, lr_0 = 8.9102e-04
Loss = 2.5218e-03, PNorm = 39.1010, GNorm = 1.2118, lr_0 = 8.9009e-04
Loss = 2.5960e-03, PNorm = 39.1306, GNorm = 0.8193, lr_0 = 8.8916e-04
Validation rmse logD = 0.601118
Validation R2 logD = 0.744256
Validation rmse logP = 0.553433
Validation R2 logP = 0.910346
Epoch 7
Train function
Loss = 1.4934e-03, PNorm = 39.1607, GNorm = 1.3032, lr_0 = 8.8823e-04
Loss = 2.1709e-03, PNorm = 39.1846, GNorm = 2.1731, lr_0 = 8.8730e-04
Loss = 1.9245e-03, PNorm = 39.2190, GNorm = 0.8636, lr_0 = 8.8638e-04
Loss = 1.5360e-03, PNorm = 39.2408, GNorm = 0.8550, lr_0 = 8.8545e-04
Loss = 2.1202e-03, PNorm = 39.2629, GNorm = 0.5973, lr_0 = 8.8453e-04
Loss = 2.0673e-03, PNorm = 39.2900, GNorm = 0.8381, lr_0 = 8.8361e-04
Loss = 2.4028e-03, PNorm = 39.3152, GNorm = 1.7297, lr_0 = 8.8268e-04
Loss = 1.9699e-03, PNorm = 39.3426, GNorm = 1.7037, lr_0 = 8.8176e-04
Loss = 2.0108e-03, PNorm = 39.3641, GNorm = 1.1477, lr_0 = 8.8084e-04
Loss = 1.9424e-03, PNorm = 39.3907, GNorm = 1.1220, lr_0 = 8.7992e-04
Loss = 2.1446e-03, PNorm = 39.4189, GNorm = 0.9038, lr_0 = 8.7900e-04
Loss = 1.7693e-03, PNorm = 39.4502, GNorm = 0.5927, lr_0 = 8.7809e-04
Loss = 2.0589e-03, PNorm = 39.4729, GNorm = 2.3566, lr_0 = 8.7717e-04
Loss = 2.3504e-03, PNorm = 39.5029, GNorm = 0.8162, lr_0 = 8.7625e-04
Loss = 2.4571e-03, PNorm = 39.5327, GNorm = 0.8871, lr_0 = 8.7534e-04
Loss = 2.2359e-03, PNorm = 39.5598, GNorm = 1.0900, lr_0 = 8.7443e-04
Loss = 2.0215e-03, PNorm = 39.5845, GNorm = 1.1866, lr_0 = 8.7351e-04
Loss = 2.2259e-03, PNorm = 39.6075, GNorm = 2.5164, lr_0 = 8.7260e-04
Loss = 2.1649e-03, PNorm = 39.6383, GNorm = 0.6695, lr_0 = 8.7169e-04
Loss = 2.5114e-03, PNorm = 39.6644, GNorm = 1.2291, lr_0 = 8.7078e-04
Loss = 2.3633e-03, PNorm = 39.6920, GNorm = 0.8476, lr_0 = 8.6987e-04
Loss = 1.6403e-03, PNorm = 39.7186, GNorm = 0.5094, lr_0 = 8.6896e-04
Loss = 2.4926e-03, PNorm = 39.7376, GNorm = 0.5067, lr_0 = 8.6806e-04
Validation rmse logD = 0.614944
Validation R2 logD = 0.732356
Validation rmse logP = 0.562278
Validation R2 logP = 0.907458
Epoch 8
Train function
Loss = 1.6956e-03, PNorm = 39.7649, GNorm = 1.2414, lr_0 = 8.6706e-04
Loss = 1.7030e-03, PNorm = 39.7926, GNorm = 1.4046, lr_0 = 8.6616e-04
Loss = 1.9626e-03, PNorm = 39.8167, GNorm = 0.8807, lr_0 = 8.6525e-04
Loss = 1.6828e-03, PNorm = 39.8485, GNorm = 0.8078, lr_0 = 8.6435e-04
Loss = 1.9701e-03, PNorm = 39.8789, GNorm = 1.8746, lr_0 = 8.6345e-04
Loss = 1.8034e-03, PNorm = 39.8967, GNorm = 1.0863, lr_0 = 8.6255e-04
Loss = 1.6338e-03, PNorm = 39.9261, GNorm = 1.2410, lr_0 = 8.6165e-04
Loss = 2.1137e-03, PNorm = 39.9507, GNorm = 2.5033, lr_0 = 8.6075e-04
Loss = 1.9528e-03, PNorm = 39.9792, GNorm = 0.7171, lr_0 = 8.5985e-04
Loss = 1.5931e-03, PNorm = 40.0094, GNorm = 0.7610, lr_0 = 8.5895e-04
Loss = 1.5789e-03, PNorm = 40.0324, GNorm = 0.5435, lr_0 = 8.5805e-04
Loss = 1.9671e-03, PNorm = 40.0513, GNorm = 0.7680, lr_0 = 8.5716e-04
Loss = 1.8192e-03, PNorm = 40.0727, GNorm = 1.5985, lr_0 = 8.5626e-04
Loss = 1.6760e-03, PNorm = 40.0917, GNorm = 0.4750, lr_0 = 8.5537e-04
Loss = 2.1600e-03, PNorm = 40.1258, GNorm = 1.1586, lr_0 = 8.5448e-04
Loss = 2.0157e-03, PNorm = 40.1465, GNorm = 1.1593, lr_0 = 8.5359e-04
Loss = 2.1676e-03, PNorm = 40.1777, GNorm = 1.2982, lr_0 = 8.5269e-04
Loss = 1.8139e-03, PNorm = 40.2039, GNorm = 0.7843, lr_0 = 8.5180e-04
Loss = 1.6492e-03, PNorm = 40.2244, GNorm = 0.7812, lr_0 = 8.5092e-04
Loss = 1.3382e-03, PNorm = 40.2478, GNorm = 0.6166, lr_0 = 8.5003e-04
Loss = 2.1756e-03, PNorm = 40.2669, GNorm = 0.8423, lr_0 = 8.4914e-04
Loss = 1.7710e-03, PNorm = 40.2830, GNorm = 1.2676, lr_0 = 8.4825e-04
Validation rmse logD = 0.608079
Validation R2 logD = 0.738298
Validation rmse logP = 0.525136
Validation R2 logP = 0.919280
Epoch 9
Train function
Loss = 1.1123e-03, PNorm = 40.3157, GNorm = 0.9514, lr_0 = 8.4737e-04
Loss = 1.8470e-03, PNorm = 40.3408, GNorm = 0.8906, lr_0 = 8.4648e-04
Loss = 1.4883e-03, PNorm = 40.3549, GNorm = 0.8632, lr_0 = 8.4560e-04
Loss = 1.6192e-03, PNorm = 40.3878, GNorm = 1.1875, lr_0 = 8.4472e-04
Loss = 1.2768e-03, PNorm = 40.4087, GNorm = 0.5355, lr_0 = 8.4384e-04
Loss = 1.3407e-03, PNorm = 40.4253, GNorm = 0.5964, lr_0 = 8.4296e-04
Loss = 1.4796e-03, PNorm = 40.4423, GNorm = 0.6960, lr_0 = 8.4208e-04
Loss = 1.4931e-03, PNorm = 40.4564, GNorm = 0.5915, lr_0 = 8.4120e-04
Loss = 1.8216e-03, PNorm = 40.4830, GNorm = 0.6834, lr_0 = 8.4032e-04
Loss = 1.7197e-03, PNorm = 40.4924, GNorm = 1.9061, lr_0 = 8.3944e-04
Loss = 2.1855e-03, PNorm = 40.5159, GNorm = 2.3904, lr_0 = 8.3857e-04
Loss = 2.1850e-03, PNorm = 40.5521, GNorm = 2.1151, lr_0 = 8.3769e-04
Loss = 1.9729e-03, PNorm = 40.5939, GNorm = 1.6339, lr_0 = 8.3682e-04
Loss = 1.6155e-03, PNorm = 40.6182, GNorm = 1.0357, lr_0 = 8.3594e-04
Loss = 1.5428e-03, PNorm = 40.6469, GNorm = 1.3349, lr_0 = 8.3507e-04
Loss = 1.6190e-03, PNorm = 40.6789, GNorm = 1.5867, lr_0 = 8.3420e-04
Loss = 1.8169e-03, PNorm = 40.7009, GNorm = 0.8507, lr_0 = 8.3333e-04
Loss = 1.3717e-03, PNorm = 40.7179, GNorm = 0.6269, lr_0 = 8.3246e-04
Loss = 1.3686e-03, PNorm = 40.7395, GNorm = 1.0633, lr_0 = 8.3159e-04
Loss = 1.8135e-03, PNorm = 40.7638, GNorm = 1.0873, lr_0 = 8.3072e-04
Loss = 1.7110e-03, PNorm = 40.7855, GNorm = 0.6912, lr_0 = 8.2986e-04
Loss = 1.5513e-03, PNorm = 40.8045, GNorm = 1.3509, lr_0 = 8.2899e-04
Loss = 1.5545e-03, PNorm = 40.8264, GNorm = 1.0185, lr_0 = 8.2812e-04
Validation rmse logD = 0.581878
Validation R2 logD = 0.760365
Validation rmse logP = 0.495723
Validation R2 logP = 0.928069
Epoch 10
Train function
Loss = 1.2907e-03, PNorm = 40.8437, GNorm = 0.8192, lr_0 = 8.2717e-04
Loss = 1.4469e-03, PNorm = 40.8609, GNorm = 0.4728, lr_0 = 8.2631e-04
Loss = 1.3798e-03, PNorm = 40.8816, GNorm = 0.8532, lr_0 = 8.2545e-04
Loss = 1.6191e-03, PNorm = 40.9075, GNorm = 1.0497, lr_0 = 8.2459e-04
Loss = 1.2790e-03, PNorm = 40.9287, GNorm = 1.0471, lr_0 = 8.2373e-04
Loss = 1.5654e-03, PNorm = 40.9553, GNorm = 0.6991, lr_0 = 8.2287e-04
Loss = 1.3229e-03, PNorm = 40.9820, GNorm = 0.9534, lr_0 = 8.2201e-04
Loss = 1.7550e-03, PNorm = 40.9996, GNorm = 1.7680, lr_0 = 8.2115e-04
Loss = 1.9836e-03, PNorm = 41.0255, GNorm = 1.3942, lr_0 = 8.2029e-04
Loss = 1.6601e-03, PNorm = 41.0444, GNorm = 1.4437, lr_0 = 8.1944e-04
Loss = 1.3930e-03, PNorm = 41.0742, GNorm = 0.9183, lr_0 = 8.1858e-04
Loss = 1.3369e-03, PNorm = 41.1020, GNorm = 0.8406, lr_0 = 8.1773e-04
Loss = 1.3685e-03, PNorm = 41.1185, GNorm = 0.7846, lr_0 = 8.1687e-04
Loss = 1.5159e-03, PNorm = 41.1369, GNorm = 0.4149, lr_0 = 8.1602e-04
Loss = 1.4853e-03, PNorm = 41.1650, GNorm = 1.0318, lr_0 = 8.1517e-04
Loss = 1.5733e-03, PNorm = 41.1846, GNorm = 1.2112, lr_0 = 8.1432e-04
Loss = 1.4670e-03, PNorm = 41.2082, GNorm = 1.0623, lr_0 = 8.1347e-04
Loss = 1.1429e-03, PNorm = 41.2246, GNorm = 0.5270, lr_0 = 8.1262e-04
Loss = 1.5030e-03, PNorm = 41.2499, GNorm = 0.8464, lr_0 = 8.1177e-04
Loss = 1.5573e-03, PNorm = 41.2924, GNorm = 0.6574, lr_0 = 8.1092e-04
Loss = 1.8727e-03, PNorm = 41.3228, GNorm = 1.3773, lr_0 = 8.1008e-04
Loss = 1.4797e-03, PNorm = 41.3454, GNorm = 1.1241, lr_0 = 8.0923e-04
Loss = 1.7244e-03, PNorm = 41.3601, GNorm = 1.5339, lr_0 = 8.0839e-04
Validation rmse logD = 0.583993
Validation R2 logD = 0.758619
Validation rmse logP = 0.516541
Validation R2 logP = 0.921900
Epoch 11
Train function
Loss = 1.4651e-03, PNorm = 41.3797, GNorm = 0.7090, lr_0 = 8.0754e-04
Loss = 1.3339e-03, PNorm = 41.4064, GNorm = 0.4958, lr_0 = 8.0670e-04
Loss = 1.3447e-03, PNorm = 41.4253, GNorm = 1.1316, lr_0 = 8.0586e-04
Loss = 1.0716e-03, PNorm = 41.4444, GNorm = 0.9124, lr_0 = 8.0502e-04
Loss = 1.4523e-03, PNorm = 41.4691, GNorm = 1.0082, lr_0 = 8.0418e-04
Loss = 1.6090e-03, PNorm = 41.4787, GNorm = 1.3781, lr_0 = 8.0334e-04
Loss = 1.5737e-03, PNorm = 41.4989, GNorm = 0.7873, lr_0 = 8.0250e-04
Loss = 1.3480e-03, PNorm = 41.5170, GNorm = 0.8835, lr_0 = 8.0166e-04
Loss = 1.2881e-03, PNorm = 41.5386, GNorm = 0.8588, lr_0 = 8.0082e-04
Loss = 1.2819e-03, PNorm = 41.5624, GNorm = 1.0211, lr_0 = 7.9999e-04
Loss = 1.1983e-03, PNorm = 41.5751, GNorm = 0.6306, lr_0 = 7.9915e-04
Loss = 1.4922e-03, PNorm = 41.5871, GNorm = 0.6967, lr_0 = 7.9832e-04
Loss = 1.2543e-03, PNorm = 41.6107, GNorm = 0.8714, lr_0 = 7.9749e-04
Loss = 1.3628e-03, PNorm = 41.6335, GNorm = 0.6837, lr_0 = 7.9665e-04
Loss = 1.1933e-03, PNorm = 41.6543, GNorm = 0.7667, lr_0 = 7.9582e-04
Loss = 1.5003e-03, PNorm = 41.6715, GNorm = 1.2027, lr_0 = 7.9499e-04
Loss = 1.3054e-03, PNorm = 41.6969, GNorm = 0.9902, lr_0 = 7.9416e-04
Loss = 1.2616e-03, PNorm = 41.7164, GNorm = 0.5682, lr_0 = 7.9333e-04
Loss = 1.2207e-03, PNorm = 41.7398, GNorm = 0.5752, lr_0 = 7.9251e-04
Loss = 1.5396e-03, PNorm = 41.7647, GNorm = 0.6148, lr_0 = 7.9168e-04
Loss = 1.6478e-03, PNorm = 41.7867, GNorm = 0.5660, lr_0 = 7.9085e-04
Loss = 1.5294e-03, PNorm = 41.8042, GNorm = 0.9533, lr_0 = 7.9003e-04
Validation rmse logD = 0.565180
Validation R2 logD = 0.773921
Validation rmse logP = 0.509677
Validation R2 logP = 0.923962
Epoch 12
Train function
Loss = 1.1824e-03, PNorm = 41.8320, GNorm = 0.8369, lr_0 = 7.8912e-04
Loss = 1.1733e-03, PNorm = 41.8402, GNorm = 0.8536, lr_0 = 7.8830e-04
Loss = 1.1336e-03, PNorm = 41.8586, GNorm = 0.9964, lr_0 = 7.8747e-04
Loss = 1.3342e-03, PNorm = 41.8784, GNorm = 0.5684, lr_0 = 7.8665e-04
Loss = 1.3943e-03, PNorm = 41.8998, GNorm = 1.5754, lr_0 = 7.8583e-04
Loss = 1.2270e-03, PNorm = 41.9258, GNorm = 0.9937, lr_0 = 7.8501e-04
Loss = 1.0205e-03, PNorm = 41.9532, GNorm = 0.5440, lr_0 = 7.8419e-04
Loss = 1.3731e-03, PNorm = 41.9745, GNorm = 1.9064, lr_0 = 7.8337e-04
Loss = 1.2601e-03, PNorm = 41.9824, GNorm = 0.7432, lr_0 = 7.8255e-04
Loss = 1.6056e-03, PNorm = 42.0194, GNorm = 1.4713, lr_0 = 7.8174e-04
Loss = 1.6023e-03, PNorm = 42.0476, GNorm = 0.6604, lr_0 = 7.8092e-04
Loss = 1.4105e-03, PNorm = 42.0674, GNorm = 0.5845, lr_0 = 7.8011e-04
Loss = 1.5399e-03, PNorm = 42.0936, GNorm = 0.5385, lr_0 = 7.7929e-04
Loss = 1.2718e-03, PNorm = 42.1138, GNorm = 0.9468, lr_0 = 7.7848e-04
Loss = 1.3929e-03, PNorm = 42.1404, GNorm = 0.6061, lr_0 = 7.7767e-04
Loss = 1.0988e-03, PNorm = 42.1639, GNorm = 0.5798, lr_0 = 7.7686e-04
Loss = 1.2416e-03, PNorm = 42.1927, GNorm = 0.8280, lr_0 = 7.7604e-04
Loss = 1.0772e-03, PNorm = 42.2128, GNorm = 1.3393, lr_0 = 7.7523e-04
Loss = 1.0450e-03, PNorm = 42.2196, GNorm = 0.6581, lr_0 = 7.7443e-04
Loss = 1.3234e-03, PNorm = 42.2363, GNorm = 0.6349, lr_0 = 7.7362e-04
Loss = 1.0495e-03, PNorm = 42.2513, GNorm = 0.8731, lr_0 = 7.7281e-04
Loss = 1.3683e-03, PNorm = 42.2636, GNorm = 1.0511, lr_0 = 7.7200e-04
Loss = 1.3977e-03, PNorm = 42.2820, GNorm = 0.9112, lr_0 = 7.7120e-04
Validation rmse logD = 0.567162
Validation R2 logD = 0.772332
Validation rmse logP = 0.502231
Validation R2 logP = 0.926168
Epoch 13
Train function
Loss = 9.6724e-04, PNorm = 42.3018, GNorm = 0.5874, lr_0 = 7.7039e-04
Loss = 1.0196e-03, PNorm = 42.3151, GNorm = 1.0158, lr_0 = 7.6959e-04
Loss = 9.2591e-04, PNorm = 42.3355, GNorm = 0.8042, lr_0 = 7.6879e-04
Loss = 1.0040e-03, PNorm = 42.3461, GNorm = 0.6708, lr_0 = 7.6798e-04
Loss = 1.1463e-03, PNorm = 42.3617, GNorm = 0.6966, lr_0 = 7.6718e-04
Loss = 1.1230e-03, PNorm = 42.3836, GNorm = 0.5093, lr_0 = 7.6638e-04
Loss = 1.1598e-03, PNorm = 42.4037, GNorm = 0.9809, lr_0 = 7.6558e-04
Loss = 9.8790e-04, PNorm = 42.4249, GNorm = 0.4886, lr_0 = 7.6478e-04
Loss = 1.4379e-03, PNorm = 42.4549, GNorm = 1.0002, lr_0 = 7.6398e-04
Loss = 1.1282e-03, PNorm = 42.4791, GNorm = 0.6959, lr_0 = 7.6319e-04
Loss = 9.4029e-04, PNorm = 42.5034, GNorm = 0.5612, lr_0 = 7.6239e-04
Loss = 1.2190e-03, PNorm = 42.5190, GNorm = 0.6781, lr_0 = 7.6159e-04
Loss = 1.1859e-03, PNorm = 42.5325, GNorm = 0.8422, lr_0 = 7.6080e-04
Loss = 1.0889e-03, PNorm = 42.5488, GNorm = 0.6730, lr_0 = 7.6000e-04
Loss = 1.3353e-03, PNorm = 42.5620, GNorm = 0.7408, lr_0 = 7.5921e-04
Loss = 1.4981e-03, PNorm = 42.5831, GNorm = 1.0596, lr_0 = 7.5842e-04
Loss = 9.8198e-04, PNorm = 42.6000, GNorm = 0.7723, lr_0 = 7.5763e-04
Loss = 1.3257e-03, PNorm = 42.6169, GNorm = 0.6447, lr_0 = 7.5684e-04
Loss = 1.2008e-03, PNorm = 42.6307, GNorm = 1.0905, lr_0 = 7.5605e-04
Loss = 1.3464e-03, PNorm = 42.6449, GNorm = 0.8255, lr_0 = 7.5526e-04
Loss = 1.2416e-03, PNorm = 42.6624, GNorm = 0.6405, lr_0 = 7.5447e-04
Loss = 1.3152e-03, PNorm = 42.6798, GNorm = 0.5254, lr_0 = 7.5368e-04
Validation rmse logD = 0.561167
Validation R2 logD = 0.777120
Validation rmse logP = 0.497311
Validation R2 logP = 0.927607
Epoch 14
Train function
Loss = 9.1164e-04, PNorm = 42.6984, GNorm = 0.6274, lr_0 = 7.5282e-04
Loss = 9.6679e-04, PNorm = 42.7120, GNorm = 0.8462, lr_0 = 7.5203e-04
Loss = 9.4588e-04, PNorm = 42.7293, GNorm = 0.3880, lr_0 = 7.5125e-04
Loss = 8.0740e-04, PNorm = 42.7456, GNorm = 0.5782, lr_0 = 7.5046e-04
Loss = 1.0005e-03, PNorm = 42.7669, GNorm = 0.4797, lr_0 = 7.4968e-04
Loss = 7.2756e-04, PNorm = 42.7792, GNorm = 0.5070, lr_0 = 7.4890e-04
Loss = 1.0270e-03, PNorm = 42.7976, GNorm = 0.6055, lr_0 = 7.4811e-04
Loss = 9.5995e-04, PNorm = 42.8132, GNorm = 0.5709, lr_0 = 7.4733e-04
Loss = 1.3045e-03, PNorm = 42.8295, GNorm = 0.9694, lr_0 = 7.4655e-04
Loss = 1.0724e-03, PNorm = 42.8481, GNorm = 0.4509, lr_0 = 7.4577e-04
Loss = 9.1274e-04, PNorm = 42.8631, GNorm = 0.7534, lr_0 = 7.4500e-04
Loss = 9.9926e-04, PNorm = 42.8759, GNorm = 0.4596, lr_0 = 7.4422e-04
Loss = 1.0726e-03, PNorm = 42.8949, GNorm = 0.6876, lr_0 = 7.4344e-04
Loss = 1.4465e-03, PNorm = 42.9143, GNorm = 0.9454, lr_0 = 7.4267e-04
Loss = 1.1061e-03, PNorm = 42.9348, GNorm = 0.7187, lr_0 = 7.4189e-04
Loss = 1.1412e-03, PNorm = 42.9613, GNorm = 0.6792, lr_0 = 7.4112e-04
Loss = 1.2484e-03, PNorm = 42.9783, GNorm = 1.4055, lr_0 = 7.4034e-04
Loss = 1.3419e-03, PNorm = 42.9959, GNorm = 0.8369, lr_0 = 7.3957e-04
Loss = 1.0625e-03, PNorm = 43.0192, GNorm = 0.4838, lr_0 = 7.3880e-04
Loss = 1.1179e-03, PNorm = 43.0431, GNorm = 0.8503, lr_0 = 7.3803e-04
Loss = 1.0594e-03, PNorm = 43.0592, GNorm = 0.5232, lr_0 = 7.3726e-04
Loss = 8.7746e-04, PNorm = 43.0844, GNorm = 0.6486, lr_0 = 7.3649e-04
Loss = 1.2312e-03, PNorm = 43.1140, GNorm = 2.0586, lr_0 = 7.3572e-04
Validation rmse logD = 0.585722
Validation R2 logD = 0.757188
Validation rmse logP = 0.503329
Validation R2 logP = 0.925845
Epoch 15
Train function
Loss = 7.8539e-04, PNorm = 43.1299, GNorm = 0.8537, lr_0 = 7.3495e-04
Loss = 8.5555e-04, PNorm = 43.1499, GNorm = 0.6183, lr_0 = 7.3418e-04
Loss = 9.8569e-04, PNorm = 43.1719, GNorm = 0.9210, lr_0 = 7.3342e-04
Loss = 8.7141e-04, PNorm = 43.1947, GNorm = 0.5249, lr_0 = 7.3265e-04
Loss = 9.2377e-04, PNorm = 43.2112, GNorm = 0.5079, lr_0 = 7.3189e-04
Loss = 8.3511e-04, PNorm = 43.2204, GNorm = 0.6651, lr_0 = 7.3112e-04
Loss = 7.6130e-04, PNorm = 43.2364, GNorm = 0.3791, lr_0 = 7.3036e-04
Loss = 8.5920e-04, PNorm = 43.2505, GNorm = 0.7768, lr_0 = 7.2960e-04
Loss = 9.5007e-04, PNorm = 43.2691, GNorm = 0.7517, lr_0 = 7.2884e-04
Loss = 1.1305e-03, PNorm = 43.2827, GNorm = 1.5165, lr_0 = 7.2808e-04
Loss = 1.2519e-03, PNorm = 43.3050, GNorm = 0.8614, lr_0 = 7.2732e-04
Loss = 9.6231e-04, PNorm = 43.3326, GNorm = 0.5883, lr_0 = 7.2656e-04
Loss = 1.0374e-03, PNorm = 43.3443, GNorm = 1.1558, lr_0 = 7.2580e-04
Loss = 9.4493e-04, PNorm = 43.3600, GNorm = 0.6056, lr_0 = 7.2504e-04
Loss = 9.4695e-04, PNorm = 43.3768, GNorm = 0.5469, lr_0 = 7.2428e-04
Loss = 8.6828e-04, PNorm = 43.3927, GNorm = 0.9584, lr_0 = 7.2353e-04
Loss = 1.0951e-03, PNorm = 43.4104, GNorm = 1.0042, lr_0 = 7.2277e-04
Loss = 9.8519e-04, PNorm = 43.4235, GNorm = 0.7751, lr_0 = 7.2202e-04
Loss = 1.2332e-03, PNorm = 43.4448, GNorm = 1.5665, lr_0 = 7.2127e-04
Loss = 1.4953e-03, PNorm = 43.4639, GNorm = 1.6124, lr_0 = 7.2051e-04
Loss = 1.3700e-03, PNorm = 43.4906, GNorm = 0.9243, lr_0 = 7.1976e-04
Loss = 9.5351e-04, PNorm = 43.5145, GNorm = 0.4403, lr_0 = 7.1901e-04
Validation rmse logD = 0.570421
Validation R2 logD = 0.769708
Validation rmse logP = 0.506518
Validation R2 logP = 0.924902
Epoch 16
Train function
Loss = 8.4521e-04, PNorm = 43.5338, GNorm = 1.0774, lr_0 = 7.1818e-04
Loss = 1.0977e-03, PNorm = 43.5563, GNorm = 0.9431, lr_0 = 7.1743e-04
Loss = 9.2630e-04, PNorm = 43.5743, GNorm = 0.4177, lr_0 = 7.1669e-04
Loss = 9.0476e-04, PNorm = 43.5971, GNorm = 0.9599, lr_0 = 7.1594e-04
Loss = 8.4671e-04, PNorm = 43.6166, GNorm = 0.4701, lr_0 = 7.1519e-04
Loss = 8.2451e-04, PNorm = 43.6336, GNorm = 0.6765, lr_0 = 7.1444e-04
Loss = 8.9694e-04, PNorm = 43.6544, GNorm = 0.5559, lr_0 = 7.1370e-04
Loss = 9.4052e-04, PNorm = 43.6645, GNorm = 0.8217, lr_0 = 7.1295e-04
Loss = 8.8590e-04, PNorm = 43.6799, GNorm = 0.6686, lr_0 = 7.1221e-04
Loss = 8.9988e-04, PNorm = 43.6928, GNorm = 0.7270, lr_0 = 7.1147e-04
Loss = 8.8503e-04, PNorm = 43.7113, GNorm = 0.6127, lr_0 = 7.1072e-04
Loss = 1.1891e-03, PNorm = 43.7317, GNorm = 0.9758, lr_0 = 7.0998e-04
Loss = 8.5850e-04, PNorm = 43.7516, GNorm = 0.5187, lr_0 = 7.0924e-04
Loss = 9.2604e-04, PNorm = 43.7667, GNorm = 0.8924, lr_0 = 7.0850e-04
Loss = 8.4765e-04, PNorm = 43.7745, GNorm = 0.6306, lr_0 = 7.0776e-04
Loss = 1.2128e-03, PNorm = 43.7959, GNorm = 0.9752, lr_0 = 7.0702e-04
Loss = 9.8533e-04, PNorm = 43.8143, GNorm = 0.8385, lr_0 = 7.0628e-04
Loss = 8.1187e-04, PNorm = 43.8349, GNorm = 1.0082, lr_0 = 7.0555e-04
Loss = 1.0419e-03, PNorm = 43.8515, GNorm = 0.9182, lr_0 = 7.0481e-04
Loss = 9.4393e-04, PNorm = 43.8728, GNorm = 0.6535, lr_0 = 7.0408e-04
Loss = 8.6783e-04, PNorm = 43.8956, GNorm = 0.7501, lr_0 = 7.0334e-04
Loss = 9.4095e-04, PNorm = 43.9212, GNorm = 0.9277, lr_0 = 7.0261e-04
Loss = 1.0225e-03, PNorm = 43.9434, GNorm = 0.6297, lr_0 = 7.0187e-04
Validation rmse logD = 0.592078
Validation R2 logD = 0.751890
Validation rmse logP = 0.487263
Validation R2 logP = 0.930503
Epoch 17
Train function
Loss = 8.6363e-04, PNorm = 43.9583, GNorm = 0.6530, lr_0 = 7.0114e-04
Loss = 7.7057e-04, PNorm = 43.9665, GNorm = 1.3278, lr_0 = 7.0041e-04
Loss = 1.0450e-03, PNorm = 43.9780, GNorm = 0.7901, lr_0 = 6.9968e-04
Loss = 8.5889e-04, PNorm = 43.9884, GNorm = 0.6495, lr_0 = 6.9895e-04
Loss = 9.2351e-04, PNorm = 44.0027, GNorm = 0.3022, lr_0 = 6.9822e-04
Loss = 8.2998e-04, PNorm = 44.0131, GNorm = 0.5594, lr_0 = 6.9749e-04
Loss = 8.2041e-04, PNorm = 44.0220, GNorm = 0.8245, lr_0 = 6.9676e-04
Loss = 8.2756e-04, PNorm = 44.0401, GNorm = 0.5149, lr_0 = 6.9603e-04
Loss = 8.0093e-04, PNorm = 44.0563, GNorm = 0.3544, lr_0 = 6.9531e-04
Loss = 7.3599e-04, PNorm = 44.0700, GNorm = 0.5799, lr_0 = 6.9458e-04
Loss = 7.2161e-04, PNorm = 44.0858, GNorm = 0.5310, lr_0 = 6.9386e-04
Loss = 6.3804e-04, PNorm = 44.0990, GNorm = 0.5999, lr_0 = 6.9313e-04
Loss = 9.8364e-04, PNorm = 44.1185, GNorm = 0.3981, lr_0 = 6.9241e-04
Loss = 9.7502e-04, PNorm = 44.1304, GNorm = 0.5699, lr_0 = 6.9169e-04
Loss = 9.2156e-04, PNorm = 44.1487, GNorm = 0.4922, lr_0 = 6.9096e-04
Loss = 8.5304e-04, PNorm = 44.1735, GNorm = 0.7599, lr_0 = 6.9024e-04
Loss = 8.9465e-04, PNorm = 44.1910, GNorm = 0.4276, lr_0 = 6.8952e-04
Loss = 9.4960e-04, PNorm = 44.2097, GNorm = 1.5681, lr_0 = 6.8880e-04
Loss = 8.5560e-04, PNorm = 44.2273, GNorm = 0.5459, lr_0 = 6.8808e-04
Loss = 7.0021e-04, PNorm = 44.2475, GNorm = 0.6234, lr_0 = 6.8737e-04
Loss = 9.6337e-04, PNorm = 44.2584, GNorm = 0.7333, lr_0 = 6.8665e-04
Loss = 7.5746e-04, PNorm = 44.2698, GNorm = 0.4536, lr_0 = 6.8593e-04
Validation rmse logD = 0.561119
Validation R2 logD = 0.777158
Validation rmse logP = 0.486344
Validation R2 logP = 0.930765
Epoch 18
Train function
Loss = 9.9317e-04, PNorm = 44.2888, GNorm = 0.8769, lr_0 = 6.8514e-04
Loss = 6.9174e-04, PNorm = 44.3007, GNorm = 0.5444, lr_0 = 6.8443e-04
Loss = 6.1159e-04, PNorm = 44.3190, GNorm = 0.4364, lr_0 = 6.8372e-04
Loss = 5.6764e-04, PNorm = 44.3311, GNorm = 0.4717, lr_0 = 6.8300e-04
Loss = 6.1695e-04, PNorm = 44.3418, GNorm = 0.4033, lr_0 = 6.8229e-04
Loss = 5.9976e-04, PNorm = 44.3529, GNorm = 0.3257, lr_0 = 6.8158e-04
Loss = 8.5299e-04, PNorm = 44.3698, GNorm = 0.8248, lr_0 = 6.8087e-04
Loss = 6.4323e-04, PNorm = 44.3838, GNorm = 0.4720, lr_0 = 6.8015e-04
Loss = 6.9441e-04, PNorm = 44.3914, GNorm = 0.6453, lr_0 = 6.7944e-04
Loss = 7.9056e-04, PNorm = 44.4041, GNorm = 1.2712, lr_0 = 6.7874e-04
Loss = 9.4464e-04, PNorm = 44.4233, GNorm = 1.1114, lr_0 = 6.7803e-04
Loss = 1.0562e-03, PNorm = 44.4409, GNorm = 0.4574, lr_0 = 6.7732e-04
Loss = 9.7002e-04, PNorm = 44.4593, GNorm = 1.0457, lr_0 = 6.7661e-04
Loss = 6.5290e-04, PNorm = 44.4803, GNorm = 0.4513, lr_0 = 6.7591e-04
Loss = 8.1283e-04, PNorm = 44.5032, GNorm = 0.5202, lr_0 = 6.7520e-04
Loss = 7.4966e-04, PNorm = 44.5143, GNorm = 0.9444, lr_0 = 6.7450e-04
Loss = 9.0834e-04, PNorm = 44.5254, GNorm = 0.5102, lr_0 = 6.7379e-04
Loss = 8.2088e-04, PNorm = 44.5445, GNorm = 0.4219, lr_0 = 6.7309e-04
Loss = 7.6289e-04, PNorm = 44.5666, GNorm = 0.9474, lr_0 = 6.7239e-04
Loss = 1.0146e-03, PNorm = 44.5820, GNorm = 1.5616, lr_0 = 6.7168e-04
Loss = 9.9892e-04, PNorm = 44.5973, GNorm = 1.3847, lr_0 = 6.7098e-04
Loss = 1.2081e-03, PNorm = 44.6251, GNorm = 1.0047, lr_0 = 6.7028e-04
Loss = 1.2838e-03, PNorm = 44.6563, GNorm = 1.6178, lr_0 = 6.6958e-04
Validation rmse logD = 0.645245
Validation R2 logD = 0.705330
Validation rmse logP = 0.486729
Validation R2 logP = 0.930655
Epoch 19
Train function
Loss = 8.4314e-04, PNorm = 44.6806, GNorm = 0.7630, lr_0 = 6.6889e-04
Loss = 7.4192e-04, PNorm = 44.6982, GNorm = 0.5384, lr_0 = 6.6819e-04
Loss = 7.0086e-04, PNorm = 44.7118, GNorm = 0.3700, lr_0 = 6.6749e-04
Loss = 7.3957e-04, PNorm = 44.7276, GNorm = 0.7274, lr_0 = 6.6679e-04
Loss = 6.9326e-04, PNorm = 44.7496, GNorm = 0.9928, lr_0 = 6.6610e-04
Loss = 6.9557e-04, PNorm = 44.7631, GNorm = 0.8641, lr_0 = 6.6540e-04
Loss = 6.6021e-04, PNorm = 44.7756, GNorm = 0.7371, lr_0 = 6.6471e-04
Loss = 6.9874e-04, PNorm = 44.7850, GNorm = 0.4647, lr_0 = 6.6401e-04
Loss = 7.7137e-04, PNorm = 44.7994, GNorm = 0.5248, lr_0 = 6.6332e-04
Loss = 8.3540e-04, PNorm = 44.8152, GNorm = 0.6816, lr_0 = 6.6263e-04
Loss = 6.9073e-04, PNorm = 44.8283, GNorm = 0.4282, lr_0 = 6.6194e-04
Loss = 8.7787e-04, PNorm = 44.8416, GNorm = 0.4881, lr_0 = 6.6125e-04
Loss = 7.3047e-04, PNorm = 44.8587, GNorm = 0.8244, lr_0 = 6.6056e-04
Loss = 6.7472e-04, PNorm = 44.8767, GNorm = 0.6317, lr_0 = 6.5987e-04
Loss = 6.8344e-04, PNorm = 44.8904, GNorm = 0.3878, lr_0 = 6.5918e-04
Loss = 7.5860e-04, PNorm = 44.9040, GNorm = 0.8213, lr_0 = 6.5849e-04
Loss = 7.0017e-04, PNorm = 44.9175, GNorm = 0.6037, lr_0 = 6.5780e-04
Loss = 9.4107e-04, PNorm = 44.9371, GNorm = 0.8881, lr_0 = 6.5712e-04
Loss = 1.0508e-03, PNorm = 44.9565, GNorm = 0.5250, lr_0 = 6.5643e-04
Loss = 8.0112e-04, PNorm = 44.9761, GNorm = 0.8514, lr_0 = 6.5574e-04
Loss = 6.7555e-04, PNorm = 44.9856, GNorm = 0.6226, lr_0 = 6.5506e-04
Loss = 6.8370e-04, PNorm = 45.0021, GNorm = 0.7125, lr_0 = 6.5438e-04
Validation rmse logD = 0.599739
Validation R2 logD = 0.745428
Validation rmse logP = 0.502383
Validation R2 logP = 0.926123
Epoch 20
Train function
Loss = 6.4196e-04, PNorm = 45.0159, GNorm = 0.9992, lr_0 = 6.5363e-04
Loss = 7.0371e-04, PNorm = 45.0352, GNorm = 0.7016, lr_0 = 6.5294e-04
Loss = 5.7775e-04, PNorm = 45.0517, GNorm = 0.4172, lr_0 = 6.5226e-04
Loss = 6.2355e-04, PNorm = 45.0684, GNorm = 0.9925, lr_0 = 6.5158e-04
Loss = 6.0423e-04, PNorm = 45.0824, GNorm = 0.6975, lr_0 = 6.5090e-04
Loss = 6.9498e-04, PNorm = 45.0972, GNorm = 1.6117, lr_0 = 6.5022e-04
Loss = 6.8414e-04, PNorm = 45.1180, GNorm = 0.4165, lr_0 = 6.4954e-04
Loss = 5.2733e-04, PNorm = 45.1257, GNorm = 0.6952, lr_0 = 6.4886e-04
Loss = 5.7684e-04, PNorm = 45.1320, GNorm = 0.5963, lr_0 = 6.4819e-04
Loss = 7.0294e-04, PNorm = 45.1460, GNorm = 0.7982, lr_0 = 6.4751e-04
Loss = 7.3276e-04, PNorm = 45.1615, GNorm = 0.5531, lr_0 = 6.4684e-04
Loss = 5.5144e-04, PNorm = 45.1769, GNorm = 0.8860, lr_0 = 6.4616e-04
Loss = 5.3974e-04, PNorm = 45.1855, GNorm = 0.4686, lr_0 = 6.4549e-04
Loss = 6.0226e-04, PNorm = 45.1973, GNorm = 0.5131, lr_0 = 6.4481e-04
Loss = 6.9719e-04, PNorm = 45.2150, GNorm = 0.8290, lr_0 = 6.4414e-04
Loss = 6.6540e-04, PNorm = 45.2275, GNorm = 0.5581, lr_0 = 6.4347e-04
Loss = 7.6609e-04, PNorm = 45.2398, GNorm = 0.8734, lr_0 = 6.4280e-04
Loss = 8.8529e-04, PNorm = 45.2581, GNorm = 0.6126, lr_0 = 6.4212e-04
Loss = 8.0031e-04, PNorm = 45.2767, GNorm = 0.7292, lr_0 = 6.4145e-04
Loss = 6.4117e-04, PNorm = 45.3011, GNorm = 0.7355, lr_0 = 6.4078e-04
Loss = 7.4434e-04, PNorm = 45.3114, GNorm = 0.7278, lr_0 = 6.4012e-04
Loss = 7.7790e-04, PNorm = 45.3280, GNorm = 0.7029, lr_0 = 6.3945e-04
Loss = 7.7106e-04, PNorm = 45.3436, GNorm = 0.5532, lr_0 = 6.3878e-04
Validation rmse logD = 0.550138
Validation R2 logD = 0.785795
Validation rmse logP = 0.482024
Validation R2 logP = 0.931990
Epoch 21
Train function
Loss = 5.5478e-04, PNorm = 45.3595, GNorm = 0.8589, lr_0 = 6.3811e-04
Loss = 5.8486e-04, PNorm = 45.3732, GNorm = 0.2474, lr_0 = 6.3745e-04
Loss = 5.8411e-04, PNorm = 45.3873, GNorm = 0.4817, lr_0 = 6.3678e-04
Loss = 6.3423e-04, PNorm = 45.3962, GNorm = 0.8495, lr_0 = 6.3612e-04
Loss = 5.5212e-04, PNorm = 45.4148, GNorm = 0.4185, lr_0 = 6.3545e-04
Loss = 5.3588e-04, PNorm = 45.4240, GNorm = 0.2751, lr_0 = 6.3479e-04
Loss = 5.6982e-04, PNorm = 45.4399, GNorm = 0.3809, lr_0 = 6.3413e-04
Loss = 5.4723e-04, PNorm = 45.4600, GNorm = 0.5038, lr_0 = 6.3347e-04
Loss = 6.6342e-04, PNorm = 45.4734, GNorm = 0.7006, lr_0 = 6.3280e-04
Loss = 7.1882e-04, PNorm = 45.4868, GNorm = 0.8925, lr_0 = 6.3214e-04
Loss = 6.2202e-04, PNorm = 45.5059, GNorm = 1.1011, lr_0 = 6.3148e-04
Loss = 6.2222e-04, PNorm = 45.5199, GNorm = 0.6687, lr_0 = 6.3083e-04
Loss = 6.5465e-04, PNorm = 45.5317, GNorm = 0.4190, lr_0 = 6.3017e-04
Loss = 6.0441e-04, PNorm = 45.5442, GNorm = 0.6785, lr_0 = 6.2951e-04
Loss = 7.5908e-04, PNorm = 45.5583, GNorm = 1.1162, lr_0 = 6.2885e-04
Loss = 6.0657e-04, PNorm = 45.5719, GNorm = 1.1116, lr_0 = 6.2820e-04
Loss = 7.7806e-04, PNorm = 45.5839, GNorm = 0.4537, lr_0 = 6.2754e-04
Loss = 8.0277e-04, PNorm = 45.6015, GNorm = 0.4345, lr_0 = 6.2689e-04
Loss = 5.9503e-04, PNorm = 45.6174, GNorm = 0.7759, lr_0 = 6.2623e-04
Loss = 8.3227e-04, PNorm = 45.6319, GNorm = 0.7314, lr_0 = 6.2558e-04
Loss = 8.0996e-04, PNorm = 45.6441, GNorm = 0.5919, lr_0 = 6.2492e-04
Loss = 6.7023e-04, PNorm = 45.6632, GNorm = 0.3331, lr_0 = 6.2427e-04
Loss = 7.0489e-04, PNorm = 45.6834, GNorm = 0.5280, lr_0 = 6.2362e-04
Loss = 1.3792e-03, PNorm = 45.6855, GNorm = 0.7264, lr_0 = 6.2356e-04
Validation rmse logD = 0.548701
Validation R2 logD = 0.786912
Validation rmse logP = 0.510474
Validation R2 logP = 0.923724
Epoch 22
Train function
Loss = 5.9483e-04, PNorm = 45.6970, GNorm = 0.6386, lr_0 = 6.2290e-04
Loss = 5.8660e-04, PNorm = 45.7115, GNorm = 1.0423, lr_0 = 6.2225e-04
Loss = 7.7398e-04, PNorm = 45.7266, GNorm = 0.5881, lr_0 = 6.2161e-04
Loss = 7.5311e-04, PNorm = 45.7382, GNorm = 1.0865, lr_0 = 6.2096e-04
Loss = 5.7361e-04, PNorm = 45.7578, GNorm = 0.8382, lr_0 = 6.2031e-04
Loss = 6.9409e-04, PNorm = 45.7749, GNorm = 0.8582, lr_0 = 6.1966e-04
Loss = 6.1714e-04, PNorm = 45.7902, GNorm = 0.7486, lr_0 = 6.1901e-04
Loss = 5.9274e-04, PNorm = 45.8036, GNorm = 0.5294, lr_0 = 6.1837e-04
Loss = 4.4760e-04, PNorm = 45.8103, GNorm = 0.3752, lr_0 = 6.1772e-04
Loss = 5.5956e-04, PNorm = 45.8229, GNorm = 0.3216, lr_0 = 6.1708e-04
Loss = 4.2626e-04, PNorm = 45.8317, GNorm = 0.7497, lr_0 = 6.1643e-04
Loss = 5.8453e-04, PNorm = 45.8439, GNorm = 0.6663, lr_0 = 6.1579e-04
Loss = 6.3731e-04, PNorm = 45.8547, GNorm = 0.9027, lr_0 = 6.1515e-04
Loss = 5.4223e-04, PNorm = 45.8686, GNorm = 0.3499, lr_0 = 6.1451e-04
Loss = 5.6768e-04, PNorm = 45.8845, GNorm = 0.5102, lr_0 = 6.1386e-04
Loss = 5.7997e-04, PNorm = 45.8978, GNorm = 0.3764, lr_0 = 6.1322e-04
Loss = 6.3778e-04, PNorm = 45.9093, GNorm = 0.8390, lr_0 = 6.1258e-04
Loss = 6.9578e-04, PNorm = 45.9157, GNorm = 0.7906, lr_0 = 6.1194e-04
Loss = 6.1899e-04, PNorm = 45.9340, GNorm = 1.0641, lr_0 = 6.1131e-04
Loss = 6.0985e-04, PNorm = 45.9432, GNorm = 0.6983, lr_0 = 6.1067e-04
Loss = 6.0423e-04, PNorm = 45.9575, GNorm = 0.3767, lr_0 = 6.1003e-04
Loss = 5.8800e-04, PNorm = 45.9712, GNorm = 0.5264, lr_0 = 6.0939e-04
Validation rmse logD = 0.551139
Validation R2 logD = 0.785014
Validation rmse logP = 0.483764
Validation R2 logP = 0.931497
Epoch 23
Train function
Loss = 7.0914e-04, PNorm = 45.9862, GNorm = 0.8606, lr_0 = 6.0876e-04
Loss = 4.5580e-04, PNorm = 46.0038, GNorm = 0.5283, lr_0 = 6.0812e-04
Loss = 4.7578e-04, PNorm = 46.0169, GNorm = 0.6043, lr_0 = 6.0749e-04
Loss = 4.7740e-04, PNorm = 46.0296, GNorm = 0.6870, lr_0 = 6.0685e-04
Loss = 5.3185e-04, PNorm = 46.0450, GNorm = 0.2933, lr_0 = 6.0622e-04
Loss = 4.8327e-04, PNorm = 46.0527, GNorm = 0.5749, lr_0 = 6.0559e-04
Loss = 4.7416e-04, PNorm = 46.0642, GNorm = 0.3694, lr_0 = 6.0496e-04
Loss = 6.1996e-04, PNorm = 46.0792, GNorm = 0.6207, lr_0 = 6.0432e-04
Loss = 6.3552e-04, PNorm = 46.0927, GNorm = 0.8761, lr_0 = 6.0369e-04
Loss = 6.1009e-04, PNorm = 46.1065, GNorm = 0.5920, lr_0 = 6.0306e-04
Loss = 5.3782e-04, PNorm = 46.1148, GNorm = 0.3948, lr_0 = 6.0243e-04
Loss = 6.7454e-04, PNorm = 46.1280, GNorm = 1.2013, lr_0 = 6.0180e-04
Loss = 6.4120e-04, PNorm = 46.1372, GNorm = 0.6046, lr_0 = 6.0118e-04
Loss = 8.0941e-04, PNorm = 46.1545, GNorm = 0.4293, lr_0 = 6.0055e-04
Loss = 7.1742e-04, PNorm = 46.1645, GNorm = 0.5815, lr_0 = 5.9992e-04
Loss = 6.7850e-04, PNorm = 46.1835, GNorm = 0.4823, lr_0 = 5.9930e-04
Loss = 6.2436e-04, PNorm = 46.1987, GNorm = 0.4624, lr_0 = 5.9867e-04
Loss = 5.2896e-04, PNorm = 46.2161, GNorm = 0.4794, lr_0 = 5.9805e-04
Loss = 4.7256e-04, PNorm = 46.2281, GNorm = 0.5559, lr_0 = 5.9742e-04
Loss = 4.7903e-04, PNorm = 46.2444, GNorm = 0.4837, lr_0 = 5.9680e-04
Loss = 5.4896e-04, PNorm = 46.2524, GNorm = 0.4516, lr_0 = 5.9618e-04
Loss = 4.9851e-04, PNorm = 46.2617, GNorm = 0.3211, lr_0 = 5.9555e-04
Loss = 4.3774e-04, PNorm = 46.2717, GNorm = 0.3162, lr_0 = 5.9493e-04
Validation rmse logD = 0.584310
Validation R2 logD = 0.758357
Validation rmse logP = 0.475311
Validation R2 logP = 0.933871
Epoch 24
Train function
Loss = 3.6806e-04, PNorm = 46.2823, GNorm = 0.2772, lr_0 = 5.9425e-04
Loss = 5.4546e-04, PNorm = 46.2950, GNorm = 0.3976, lr_0 = 5.9363e-04
Loss = 4.5892e-04, PNorm = 46.3088, GNorm = 0.7615, lr_0 = 5.9301e-04
Loss = 4.3412e-04, PNorm = 46.3247, GNorm = 0.4692, lr_0 = 5.9239e-04
Loss = 3.8420e-04, PNorm = 46.3377, GNorm = 0.3536, lr_0 = 5.9177e-04
Loss = 4.3952e-04, PNorm = 46.3450, GNorm = 0.3027, lr_0 = 5.9115e-04
Loss = 4.5172e-04, PNorm = 46.3549, GNorm = 0.4378, lr_0 = 5.9054e-04
Loss = 4.4730e-04, PNorm = 46.3624, GNorm = 0.5630, lr_0 = 5.8992e-04
Loss = 5.1918e-04, PNorm = 46.3719, GNorm = 0.6759, lr_0 = 5.8931e-04
Loss = 6.4779e-04, PNorm = 46.3809, GNorm = 0.8235, lr_0 = 5.8869e-04
Loss = 4.9420e-04, PNorm = 46.4001, GNorm = 0.4409, lr_0 = 5.8808e-04
Loss = 5.5817e-04, PNorm = 46.4203, GNorm = 0.7211, lr_0 = 5.8746e-04
Loss = 4.7130e-04, PNorm = 46.4274, GNorm = 0.5771, lr_0 = 5.8685e-04
Loss = 4.7383e-04, PNorm = 46.4364, GNorm = 0.6106, lr_0 = 5.8624e-04
Loss = 5.2573e-04, PNorm = 46.4428, GNorm = 0.3555, lr_0 = 5.8562e-04
Loss = 4.4998e-04, PNorm = 46.4491, GNorm = 0.2631, lr_0 = 5.8501e-04
Loss = 5.0541e-04, PNorm = 46.4540, GNorm = 0.4031, lr_0 = 5.8440e-04
Loss = 4.2186e-04, PNorm = 46.4626, GNorm = 0.5843, lr_0 = 5.8379e-04
Loss = 5.0508e-04, PNorm = 46.4746, GNorm = 0.3066, lr_0 = 5.8318e-04
Loss = 5.3652e-04, PNorm = 46.4887, GNorm = 0.4272, lr_0 = 5.8257e-04
Loss = 5.0508e-04, PNorm = 46.4968, GNorm = 0.7298, lr_0 = 5.8197e-04
Loss = 5.7966e-04, PNorm = 46.5088, GNorm = 0.6187, lr_0 = 5.8136e-04
Validation rmse logD = 0.535552
Validation R2 logD = 0.797002
Validation rmse logP = 0.475901
Validation R2 logP = 0.933706
Epoch 25
Train function
Loss = 3.0756e-04, PNorm = 46.5165, GNorm = 0.4643, lr_0 = 5.8075e-04
Loss = 4.2570e-04, PNorm = 46.5279, GNorm = 0.4500, lr_0 = 5.8015e-04
Loss = 4.6800e-04, PNorm = 46.5362, GNorm = 0.9995, lr_0 = 5.7954e-04
Loss = 4.3836e-04, PNorm = 46.5506, GNorm = 0.5143, lr_0 = 5.7894e-04
Loss = 4.6608e-04, PNorm = 46.5617, GNorm = 0.5885, lr_0 = 5.7833e-04
Loss = 5.1320e-04, PNorm = 46.5757, GNorm = 0.5199, lr_0 = 5.7773e-04
Loss = 5.2192e-04, PNorm = 46.5850, GNorm = 0.3947, lr_0 = 5.7712e-04
Loss = 4.4453e-04, PNorm = 46.5960, GNorm = 0.5639, lr_0 = 5.7652e-04
Loss = 3.9823e-04, PNorm = 46.6057, GNorm = 0.3989, lr_0 = 5.7592e-04
Loss = 5.4356e-04, PNorm = 46.6155, GNorm = 0.8569, lr_0 = 5.7532e-04
Loss = 4.3995e-04, PNorm = 46.6278, GNorm = 0.5379, lr_0 = 5.7472e-04
Loss = 4.7367e-04, PNorm = 46.6342, GNorm = 0.7314, lr_0 = 5.7412e-04
Loss = 4.5074e-04, PNorm = 46.6455, GNorm = 0.3887, lr_0 = 5.7352e-04
Loss = 4.9830e-04, PNorm = 46.6653, GNorm = 0.5114, lr_0 = 5.7292e-04
Loss = 4.8985e-04, PNorm = 46.6803, GNorm = 0.5288, lr_0 = 5.7232e-04
Loss = 3.9448e-04, PNorm = 46.6929, GNorm = 0.2586, lr_0 = 5.7173e-04
Loss = 5.2529e-04, PNorm = 46.7057, GNorm = 0.6066, lr_0 = 5.7113e-04
Loss = 5.3905e-04, PNorm = 46.7158, GNorm = 0.4368, lr_0 = 5.7053e-04
Loss = 5.0194e-04, PNorm = 46.7307, GNorm = 0.3785, lr_0 = 5.6994e-04
Loss = 4.8652e-04, PNorm = 46.7433, GNorm = 0.8308, lr_0 = 5.6934e-04
Loss = 4.9131e-04, PNorm = 46.7543, GNorm = 0.3842, lr_0 = 5.6875e-04
Loss = 4.2029e-04, PNorm = 46.7675, GNorm = 0.3453, lr_0 = 5.6816e-04
Loss = 4.3772e-04, PNorm = 46.7780, GNorm = 0.3656, lr_0 = 5.6756e-04
Validation rmse logD = 0.538754
Validation R2 logD = 0.794569
Validation rmse logP = 0.469823
Validation R2 logP = 0.935389
Epoch 26
Train function
Loss = 3.0573e-04, PNorm = 46.7889, GNorm = 0.5228, lr_0 = 5.6691e-04
Loss = 3.9927e-04, PNorm = 46.7977, GNorm = 0.7482, lr_0 = 5.6632e-04
Loss = 4.0939e-04, PNorm = 46.8087, GNorm = 0.4223, lr_0 = 5.6573e-04
Loss = 4.4883e-04, PNorm = 46.8228, GNorm = 0.5539, lr_0 = 5.6514e-04
Loss = 3.7594e-04, PNorm = 46.8344, GNorm = 0.4620, lr_0 = 5.6455e-04
Loss = 3.7730e-04, PNorm = 46.8423, GNorm = 0.3345, lr_0 = 5.6396e-04
Loss = 3.9689e-04, PNorm = 46.8504, GNorm = 0.3789, lr_0 = 5.6337e-04
Loss = 3.6650e-04, PNorm = 46.8576, GNorm = 0.2910, lr_0 = 5.6278e-04
Loss = 4.5215e-04, PNorm = 46.8713, GNorm = 0.8471, lr_0 = 5.6219e-04
Loss = 4.2469e-04, PNorm = 46.8848, GNorm = 0.6607, lr_0 = 5.6161e-04
Loss = 4.2018e-04, PNorm = 46.8888, GNorm = 0.4375, lr_0 = 5.6102e-04
Loss = 4.6525e-04, PNorm = 46.8995, GNorm = 0.6763, lr_0 = 5.6044e-04
Loss = 4.0798e-04, PNorm = 46.9140, GNorm = 0.5336, lr_0 = 5.5985e-04
Loss = 4.2308e-04, PNorm = 46.9262, GNorm = 0.4360, lr_0 = 5.5927e-04
Loss = 4.3612e-04, PNorm = 46.9348, GNorm = 0.3034, lr_0 = 5.5868e-04
Loss = 4.8011e-04, PNorm = 46.9470, GNorm = 0.5396, lr_0 = 5.5810e-04
Loss = 4.1510e-04, PNorm = 46.9615, GNorm = 0.4385, lr_0 = 5.5752e-04
Loss = 4.2662e-04, PNorm = 46.9681, GNorm = 0.2965, lr_0 = 5.5694e-04
Loss = 4.9442e-04, PNorm = 46.9846, GNorm = 0.2630, lr_0 = 5.5635e-04
Loss = 5.1371e-04, PNorm = 46.9958, GNorm = 0.3980, lr_0 = 5.5577e-04
Loss = 4.2005e-04, PNorm = 47.0040, GNorm = 0.3366, lr_0 = 5.5519e-04
Loss = 5.1911e-04, PNorm = 47.0125, GNorm = 0.2502, lr_0 = 5.5461e-04
Validation rmse logD = 0.535422
Validation R2 logD = 0.797102
Validation rmse logP = 0.474322
Validation R2 logP = 0.934146
Epoch 27
Train function
Loss = 3.1492e-04, PNorm = 47.0228, GNorm = 0.3297, lr_0 = 5.5398e-04
Loss = 3.7628e-04, PNorm = 47.0338, GNorm = 0.3680, lr_0 = 5.5340e-04
Loss = 5.6368e-04, PNorm = 47.0494, GNorm = 0.8625, lr_0 = 5.5282e-04
Loss = 4.4506e-04, PNorm = 47.0645, GNorm = 0.5644, lr_0 = 5.5224e-04
Loss = 3.5141e-04, PNorm = 47.0723, GNorm = 0.5961, lr_0 = 5.5167e-04
Loss = 4.3118e-04, PNorm = 47.0850, GNorm = 0.2781, lr_0 = 5.5109e-04
Loss = 4.1931e-04, PNorm = 47.0951, GNorm = 0.6650, lr_0 = 5.5052e-04
Loss = 3.7966e-04, PNorm = 47.1083, GNorm = 0.5631, lr_0 = 5.4994e-04
Loss = 3.8315e-04, PNorm = 47.1197, GNorm = 0.6328, lr_0 = 5.4937e-04
Loss = 3.9188e-04, PNorm = 47.1295, GNorm = 0.2797, lr_0 = 5.4880e-04
Loss = 4.9912e-04, PNorm = 47.1403, GNorm = 0.6133, lr_0 = 5.4822e-04
Loss = 4.8089e-04, PNorm = 47.1466, GNorm = 0.3705, lr_0 = 5.4765e-04
Loss = 4.6644e-04, PNorm = 47.1615, GNorm = 0.5797, lr_0 = 5.4708e-04
Loss = 4.5214e-04, PNorm = 47.1703, GNorm = 0.5008, lr_0 = 5.4651e-04
Loss = 4.2913e-04, PNorm = 47.1827, GNorm = 0.5214, lr_0 = 5.4594e-04
Loss = 3.6462e-04, PNorm = 47.1912, GNorm = 0.5960, lr_0 = 5.4537e-04
Loss = 4.6005e-04, PNorm = 47.2019, GNorm = 0.3598, lr_0 = 5.4480e-04
Loss = 5.0511e-04, PNorm = 47.2169, GNorm = 0.8055, lr_0 = 5.4423e-04
Loss = 5.1967e-04, PNorm = 47.2324, GNorm = 0.7533, lr_0 = 5.4366e-04
Loss = 4.3816e-04, PNorm = 47.2449, GNorm = 0.5854, lr_0 = 5.4309e-04
Loss = 5.5352e-04, PNorm = 47.2610, GNorm = 1.0719, lr_0 = 5.4253e-04
Loss = 5.5430e-04, PNorm = 47.2731, GNorm = 1.0473, lr_0 = 5.4196e-04
Loss = 4.5562e-04, PNorm = 47.2852, GNorm = 0.4580, lr_0 = 5.4140e-04
Validation rmse logD = 0.548839
Validation R2 logD = 0.786805
Validation rmse logP = 0.470147
Validation R2 logP = 0.935300
Epoch 28
Train function
Loss = 3.7383e-04, PNorm = 47.2993, GNorm = 0.5443, lr_0 = 5.4083e-04
Loss = 4.1580e-04, PNorm = 47.3117, GNorm = 0.2774, lr_0 = 5.4027e-04
Loss = 4.1627e-04, PNorm = 47.3224, GNorm = 0.8352, lr_0 = 5.3970e-04
Loss = 3.5474e-04, PNorm = 47.3317, GNorm = 0.2488, lr_0 = 5.3914e-04
Loss = 4.0217e-04, PNorm = 47.3437, GNorm = 0.4070, lr_0 = 5.3858e-04
Loss = 5.4494e-04, PNorm = 47.3587, GNorm = 0.4445, lr_0 = 5.3801e-04
Loss = 3.9729e-04, PNorm = 47.3725, GNorm = 0.4976, lr_0 = 5.3745e-04
Loss = 3.2114e-04, PNorm = 47.3765, GNorm = 0.4770, lr_0 = 5.3689e-04
Loss = 4.0885e-04, PNorm = 47.3892, GNorm = 0.5392, lr_0 = 5.3633e-04
Loss = 4.8261e-04, PNorm = 47.4034, GNorm = 0.6095, lr_0 = 5.3577e-04
Loss = 3.9957e-04, PNorm = 47.4132, GNorm = 0.4423, lr_0 = 5.3521e-04
Loss = 3.7003e-04, PNorm = 47.4277, GNorm = 0.4453, lr_0 = 5.3465e-04
Loss = 3.6657e-04, PNorm = 47.4382, GNorm = 0.5007, lr_0 = 5.3410e-04
Loss = 3.9540e-04, PNorm = 47.4464, GNorm = 0.3091, lr_0 = 5.3354e-04
Loss = 3.3170e-04, PNorm = 47.4558, GNorm = 0.4329, lr_0 = 5.3298e-04
Loss = 3.3472e-04, PNorm = 47.4651, GNorm = 0.6067, lr_0 = 5.3243e-04
Loss = 4.7839e-04, PNorm = 47.4763, GNorm = 0.8562, lr_0 = 5.3187e-04
Loss = 4.0203e-04, PNorm = 47.4877, GNorm = 0.3749, lr_0 = 5.3131e-04
Loss = 4.2774e-04, PNorm = 47.4998, GNorm = 0.6938, lr_0 = 5.3076e-04
Loss = 4.2944e-04, PNorm = 47.5119, GNorm = 0.5786, lr_0 = 5.3021e-04
Loss = 3.8008e-04, PNorm = 47.5223, GNorm = 0.5637, lr_0 = 5.2965e-04
Loss = 4.2608e-04, PNorm = 47.5334, GNorm = 0.5096, lr_0 = 5.2910e-04
Validation rmse logD = 0.548298
Validation R2 logD = 0.787225
Validation rmse logP = 0.468660
Validation R2 logP = 0.935708
Epoch 29
Train function
Loss = 2.2233e-04, PNorm = 47.5485, GNorm = 0.2900, lr_0 = 5.2849e-04
Loss = 3.6279e-04, PNorm = 47.5600, GNorm = 0.7951, lr_0 = 5.2794e-04
Loss = 4.2214e-04, PNorm = 47.5721, GNorm = 0.4621, lr_0 = 5.2739e-04
Loss = 4.5539e-04, PNorm = 47.5800, GNorm = 0.3429, lr_0 = 5.2684e-04
Loss = 3.8909e-04, PNorm = 47.5941, GNorm = 0.4591, lr_0 = 5.2629e-04
Loss = 4.4084e-04, PNorm = 47.6058, GNorm = 0.4394, lr_0 = 5.2574e-04
Loss = 4.6166e-04, PNorm = 47.6159, GNorm = 0.4832, lr_0 = 5.2519e-04
Loss = 3.6901e-04, PNorm = 47.6250, GNorm = 0.6134, lr_0 = 5.2464e-04
Loss = 4.1809e-04, PNorm = 47.6329, GNorm = 0.3462, lr_0 = 5.2410e-04
Loss = 4.7322e-04, PNorm = 47.6486, GNorm = 0.4123, lr_0 = 5.2355e-04
Loss = 3.3089e-04, PNorm = 47.6607, GNorm = 0.5237, lr_0 = 5.2300e-04
Loss = 3.4299e-04, PNorm = 47.6650, GNorm = 0.7275, lr_0 = 5.2246e-04
Loss = 3.3323e-04, PNorm = 47.6736, GNorm = 0.4396, lr_0 = 5.2191e-04
Loss = 3.5388e-04, PNorm = 47.6869, GNorm = 0.4256, lr_0 = 5.2137e-04
Loss = 4.1690e-04, PNorm = 47.6969, GNorm = 0.6149, lr_0 = 5.2082e-04
Loss = 3.5988e-04, PNorm = 47.7085, GNorm = 0.4545, lr_0 = 5.2028e-04
Loss = 3.5241e-04, PNorm = 47.7151, GNorm = 0.7280, lr_0 = 5.1974e-04
Loss = 4.3000e-04, PNorm = 47.7260, GNorm = 0.5309, lr_0 = 5.1919e-04
Loss = 5.9796e-04, PNorm = 47.7418, GNorm = 1.2226, lr_0 = 5.1865e-04
Loss = 4.8924e-04, PNorm = 47.7540, GNorm = 0.4170, lr_0 = 5.1811e-04
Loss = 3.9003e-04, PNorm = 47.7640, GNorm = 0.2980, lr_0 = 5.1757e-04
Loss = 4.0632e-04, PNorm = 47.7773, GNorm = 0.7374, lr_0 = 5.1703e-04
Loss = 4.3915e-04, PNorm = 47.7889, GNorm = 0.3285, lr_0 = 5.1649e-04
Validation rmse logD = 0.563741
Validation R2 logD = 0.775071
Validation rmse logP = 0.486108
Validation R2 logP = 0.930832
Epoch 30
Train function
Loss = 3.8980e-04, PNorm = 47.8024, GNorm = 0.7274, lr_0 = 5.1595e-04
Loss = 4.1333e-04, PNorm = 47.8131, GNorm = 0.5222, lr_0 = 5.1541e-04
Loss = 4.8226e-04, PNorm = 47.8231, GNorm = 0.5890, lr_0 = 5.1487e-04
Loss = 3.8026e-04, PNorm = 47.8368, GNorm = 0.5296, lr_0 = 5.1434e-04
Loss = 3.7524e-04, PNorm = 47.8458, GNorm = 0.5766, lr_0 = 5.1380e-04
Loss = 3.2910e-04, PNorm = 47.8552, GNorm = 0.2815, lr_0 = 5.1326e-04
Loss = 3.4399e-04, PNorm = 47.8665, GNorm = 0.4972, lr_0 = 5.1273e-04
Loss = 3.5155e-04, PNorm = 47.8769, GNorm = 0.2035, lr_0 = 5.1219e-04
Loss = 2.8892e-04, PNorm = 47.8844, GNorm = 0.4586, lr_0 = 5.1166e-04
Loss = 4.1790e-04, PNorm = 47.8941, GNorm = 0.2821, lr_0 = 5.1112e-04
Loss = 3.1416e-04, PNorm = 47.8992, GNorm = 0.4327, lr_0 = 5.1059e-04
Loss = 3.8248e-04, PNorm = 47.9063, GNorm = 0.4567, lr_0 = 5.1006e-04
Loss = 2.6570e-04, PNorm = 47.9175, GNorm = 0.3066, lr_0 = 5.0953e-04
Loss = 3.2450e-04, PNorm = 47.9292, GNorm = 0.4826, lr_0 = 5.0899e-04
Loss = 3.7064e-04, PNorm = 47.9315, GNorm = 0.6470, lr_0 = 5.0846e-04
Loss = 3.5102e-04, PNorm = 47.9398, GNorm = 0.3645, lr_0 = 5.0793e-04
Loss = 3.4075e-04, PNorm = 47.9528, GNorm = 0.3637, lr_0 = 5.0740e-04
Loss = 3.6717e-04, PNorm = 47.9635, GNorm = 0.3646, lr_0 = 5.0687e-04
Loss = 3.8671e-04, PNorm = 47.9740, GNorm = 0.4771, lr_0 = 5.0634e-04
Loss = 3.5696e-04, PNorm = 47.9847, GNorm = 0.6491, lr_0 = 5.0581e-04
Loss = 3.3766e-04, PNorm = 47.9927, GNorm = 0.3145, lr_0 = 5.0529e-04
Loss = 3.4418e-04, PNorm = 48.0032, GNorm = 0.5927, lr_0 = 5.0476e-04
Validation rmse logD = 0.565165
Validation R2 logD = 0.773933
Validation rmse logP = 0.475073
Validation R2 logP = 0.933937
Epoch 31
Train function
Loss = 4.8307e-04, PNorm = 48.0182, GNorm = 0.7869, lr_0 = 5.0418e-04
Loss = 3.5760e-04, PNorm = 48.0258, GNorm = 0.5995, lr_0 = 5.0365e-04
Loss = 3.8265e-04, PNorm = 48.0312, GNorm = 0.3441, lr_0 = 5.0313e-04
Loss = 2.5775e-04, PNorm = 48.0412, GNorm = 0.3484, lr_0 = 5.0260e-04
Loss = 2.7823e-04, PNorm = 48.0515, GNorm = 0.3575, lr_0 = 5.0208e-04
Loss = 2.5805e-04, PNorm = 48.0578, GNorm = 0.3093, lr_0 = 5.0155e-04
Loss = 2.3638e-04, PNorm = 48.0593, GNorm = 0.5253, lr_0 = 5.0103e-04
Loss = 3.9049e-04, PNorm = 48.0656, GNorm = 0.3411, lr_0 = 5.0051e-04
Loss = 2.9397e-04, PNorm = 48.0709, GNorm = 0.5666, lr_0 = 4.9998e-04
Loss = 3.2806e-04, PNorm = 48.0812, GNorm = 0.3168, lr_0 = 4.9946e-04
Loss = 3.1894e-04, PNorm = 48.0908, GNorm = 0.2793, lr_0 = 4.9894e-04
Loss = 3.1530e-04, PNorm = 48.1000, GNorm = 0.3942, lr_0 = 4.9842e-04
Loss = 3.9584e-04, PNorm = 48.1138, GNorm = 0.7606, lr_0 = 4.9790e-04
Loss = 4.2842e-04, PNorm = 48.1223, GNorm = 0.7284, lr_0 = 4.9738e-04
Loss = 3.2797e-04, PNorm = 48.1308, GNorm = 0.6685, lr_0 = 4.9686e-04
Loss = 3.8430e-04, PNorm = 48.1424, GNorm = 0.3741, lr_0 = 4.9634e-04
Loss = 3.2300e-04, PNorm = 48.1505, GNorm = 0.4348, lr_0 = 4.9583e-04
Loss = 3.2901e-04, PNorm = 48.1590, GNorm = 0.2804, lr_0 = 4.9531e-04
Loss = 4.1748e-04, PNorm = 48.1685, GNorm = 0.4264, lr_0 = 4.9479e-04
Loss = 3.6609e-04, PNorm = 48.1844, GNorm = 0.3609, lr_0 = 4.9427e-04
Loss = 3.5426e-04, PNorm = 48.1919, GNorm = 0.2489, lr_0 = 4.9376e-04
Loss = 2.7675e-04, PNorm = 48.1989, GNorm = 0.2808, lr_0 = 4.9324e-04
Loss = 2.9069e-04, PNorm = 48.2057, GNorm = 0.5013, lr_0 = 4.9273e-04
Validation rmse logD = 0.560861
Validation R2 logD = 0.777363
Validation rmse logP = 0.467855
Validation R2 logP = 0.935929
Epoch 32
Train function
Loss = 2.8012e-04, PNorm = 48.2166, GNorm = 0.6099, lr_0 = 4.9221e-04
Loss = 2.7768e-04, PNorm = 48.2224, GNorm = 0.4697, lr_0 = 4.9170e-04
Loss = 2.8681e-04, PNorm = 48.2317, GNorm = 0.3190, lr_0 = 4.9119e-04
Loss = 3.6567e-04, PNorm = 48.2409, GNorm = 0.3351, lr_0 = 4.9067e-04
Loss = 2.9397e-04, PNorm = 48.2503, GNorm = 0.5409, lr_0 = 4.9016e-04
Loss = 3.1360e-04, PNorm = 48.2608, GNorm = 0.6764, lr_0 = 4.8965e-04
Loss = 3.1131e-04, PNorm = 48.2703, GNorm = 0.4740, lr_0 = 4.8914e-04
Loss = 3.2055e-04, PNorm = 48.2781, GNorm = 0.3635, lr_0 = 4.8863e-04
Loss = 2.3544e-04, PNorm = 48.2820, GNorm = 0.4573, lr_0 = 4.8812e-04
Loss = 2.5193e-04, PNorm = 48.2852, GNorm = 0.3873, lr_0 = 4.8761e-04
Loss = 2.8155e-04, PNorm = 48.2915, GNorm = 0.4092, lr_0 = 4.8710e-04
Loss = 2.7301e-04, PNorm = 48.2999, GNorm = 0.3219, lr_0 = 4.8659e-04
Loss = 2.7037e-04, PNorm = 48.3064, GNorm = 0.2617, lr_0 = 4.8608e-04
Loss = 2.7242e-04, PNorm = 48.3151, GNorm = 0.5795, lr_0 = 4.8558e-04
Loss = 3.6606e-04, PNorm = 48.3238, GNorm = 0.3936, lr_0 = 4.8507e-04
Loss = 3.3021e-04, PNorm = 48.3354, GNorm = 0.5379, lr_0 = 4.8456e-04
Loss = 3.7938e-04, PNorm = 48.3457, GNorm = 0.2476, lr_0 = 4.8406e-04
Loss = 3.0744e-04, PNorm = 48.3535, GNorm = 0.5085, lr_0 = 4.8355e-04
Loss = 3.0137e-04, PNorm = 48.3606, GNorm = 0.5481, lr_0 = 4.8305e-04
Loss = 3.0218e-04, PNorm = 48.3715, GNorm = 0.5510, lr_0 = 4.8254e-04
Loss = 2.9094e-04, PNorm = 48.3795, GNorm = 0.2335, lr_0 = 4.8204e-04
Loss = 3.6965e-04, PNorm = 48.3920, GNorm = 0.2433, lr_0 = 4.8154e-04
Loss = 3.2924e-04, PNorm = 48.4029, GNorm = 0.3717, lr_0 = 4.8104e-04
Loss = 5.5841e-04, PNorm = 48.4040, GNorm = 0.4007, lr_0 = 4.8098e-04
Validation rmse logD = 0.531068
Validation R2 logD = 0.800388
Validation rmse logP = 0.466062
Validation R2 logP = 0.936419
Epoch 33
Train function
Loss = 2.4226e-04, PNorm = 48.4152, GNorm = 0.4953, lr_0 = 4.8048e-04
Loss = 2.0249e-04, PNorm = 48.4224, GNorm = 0.2387, lr_0 = 4.7998e-04
Loss = 2.5236e-04, PNorm = 48.4260, GNorm = 0.4738, lr_0 = 4.7948e-04
Loss = 2.4317e-04, PNorm = 48.4306, GNorm = 0.3551, lr_0 = 4.7898e-04
Loss = 2.2612e-04, PNorm = 48.4361, GNorm = 0.3067, lr_0 = 4.7848e-04
Loss = 2.7768e-04, PNorm = 48.4437, GNorm = 0.4487, lr_0 = 4.7798e-04
Loss = 2.1796e-04, PNorm = 48.4472, GNorm = 0.3407, lr_0 = 4.7748e-04
Loss = 2.8478e-04, PNorm = 48.4564, GNorm = 0.2916, lr_0 = 4.7698e-04
Loss = 3.3242e-04, PNorm = 48.4668, GNorm = 0.4009, lr_0 = 4.7649e-04
Loss = 2.4706e-04, PNorm = 48.4772, GNorm = 0.4072, lr_0 = 4.7599e-04
Loss = 2.2477e-04, PNorm = 48.4822, GNorm = 0.5106, lr_0 = 4.7549e-04
Loss = 2.8233e-04, PNorm = 48.4912, GNorm = 0.3708, lr_0 = 4.7500e-04
Loss = 2.8237e-04, PNorm = 48.4993, GNorm = 0.3172, lr_0 = 4.7450e-04
Loss = 2.6548e-04, PNorm = 48.5078, GNorm = 0.3760, lr_0 = 4.7400e-04
Loss = 3.0493e-04, PNorm = 48.5187, GNorm = 0.2531, lr_0 = 4.7351e-04
Loss = 2.7583e-04, PNorm = 48.5291, GNorm = 0.3586, lr_0 = 4.7302e-04
Loss = 2.6472e-04, PNorm = 48.5386, GNorm = 0.2914, lr_0 = 4.7252e-04
Loss = 2.7756e-04, PNorm = 48.5476, GNorm = 0.3478, lr_0 = 4.7203e-04
Loss = 2.7544e-04, PNorm = 48.5562, GNorm = 0.3501, lr_0 = 4.7154e-04
Loss = 4.5844e-04, PNorm = 48.5612, GNorm = 0.7127, lr_0 = 4.7104e-04
Loss = 3.3598e-04, PNorm = 48.5745, GNorm = 0.4672, lr_0 = 4.7055e-04
Loss = 3.5138e-04, PNorm = 48.5849, GNorm = 0.2557, lr_0 = 4.7006e-04
Validation rmse logD = 0.544130
Validation R2 logD = 0.790448
Validation rmse logP = 0.474192
Validation R2 logP = 0.934182
Epoch 34
Train function
Loss = 2.0928e-04, PNorm = 48.5964, GNorm = 0.4023, lr_0 = 4.6957e-04
Loss = 2.4424e-04, PNorm = 48.6025, GNorm = 0.3340, lr_0 = 4.6908e-04
Loss = 2.2800e-04, PNorm = 48.6042, GNorm = 0.3414, lr_0 = 4.6859e-04
Loss = 2.3032e-04, PNorm = 48.6123, GNorm = 0.3599, lr_0 = 4.6810e-04
Loss = 2.2540e-04, PNorm = 48.6188, GNorm = 0.2186, lr_0 = 4.6761e-04
Loss = 2.5343e-04, PNorm = 48.6247, GNorm = 0.4261, lr_0 = 4.6712e-04
Loss = 3.2223e-04, PNorm = 48.6338, GNorm = 0.4282, lr_0 = 4.6664e-04
Loss = 2.4646e-04, PNorm = 48.6442, GNorm = 0.5422, lr_0 = 4.6615e-04
Loss = 2.5873e-04, PNorm = 48.6517, GNorm = 0.3386, lr_0 = 4.6566e-04
Loss = 2.9104e-04, PNorm = 48.6589, GNorm = 0.6288, lr_0 = 4.6518e-04
Loss = 3.7358e-04, PNorm = 48.6654, GNorm = 1.1925, lr_0 = 4.6469e-04
Loss = 3.5690e-04, PNorm = 48.6759, GNorm = 0.4507, lr_0 = 4.6421e-04
Loss = 3.6978e-04, PNorm = 48.6885, GNorm = 0.4729, lr_0 = 4.6372e-04
Loss = 3.8064e-04, PNorm = 48.7019, GNorm = 0.6340, lr_0 = 4.6324e-04
Loss = 3.0859e-04, PNorm = 48.7127, GNorm = 0.4602, lr_0 = 4.6276e-04
Loss = 2.5473e-04, PNorm = 48.7217, GNorm = 0.3845, lr_0 = 4.6227e-04
Loss = 2.3735e-04, PNorm = 48.7269, GNorm = 0.3926, lr_0 = 4.6179e-04
Loss = 2.7824e-04, PNorm = 48.7345, GNorm = 0.4758, lr_0 = 4.6131e-04
Loss = 3.5559e-04, PNorm = 48.7442, GNorm = 0.5071, lr_0 = 4.6083e-04
Loss = 3.0315e-04, PNorm = 48.7544, GNorm = 0.3610, lr_0 = 4.6035e-04
Loss = 2.9997e-04, PNorm = 48.7660, GNorm = 0.2638, lr_0 = 4.5987e-04
Loss = 2.6455e-04, PNorm = 48.7750, GNorm = 0.3477, lr_0 = 4.5939e-04
Loss = 3.3491e-04, PNorm = 48.7860, GNorm = 0.4610, lr_0 = 4.5891e-04
Validation rmse logD = 0.547644
Validation R2 logD = 0.787733
Validation rmse logP = 0.467346
Validation R2 logP = 0.936068
Epoch 35
Train function
Loss = 2.6882e-04, PNorm = 48.7947, GNorm = 0.2838, lr_0 = 4.5838e-04
Loss = 3.0189e-04, PNorm = 48.8022, GNorm = 0.3783, lr_0 = 4.5790e-04
Loss = 2.7725e-04, PNorm = 48.8102, GNorm = 0.8022, lr_0 = 4.5742e-04
Loss = 3.2817e-04, PNorm = 48.8185, GNorm = 0.4041, lr_0 = 4.5695e-04
Loss = 2.2592e-04, PNorm = 48.8240, GNorm = 0.2759, lr_0 = 4.5647e-04
Loss = 2.6588e-04, PNorm = 48.8305, GNorm = 0.4320, lr_0 = 4.5599e-04
Loss = 2.3929e-04, PNorm = 48.8363, GNorm = 0.3027, lr_0 = 4.5552e-04
Loss = 2.6851e-04, PNorm = 48.8401, GNorm = 0.8157, lr_0 = 4.5504e-04
Loss = 2.6196e-04, PNorm = 48.8497, GNorm = 0.3279, lr_0 = 4.5457e-04
Loss = 2.5601e-04, PNorm = 48.8602, GNorm = 0.2451, lr_0 = 4.5409e-04
Loss = 2.6111e-04, PNorm = 48.8707, GNorm = 0.2680, lr_0 = 4.5362e-04
Loss = 2.4608e-04, PNorm = 48.8757, GNorm = 0.2134, lr_0 = 4.5314e-04
Loss = 2.5434e-04, PNorm = 48.8847, GNorm = 0.3873, lr_0 = 4.5267e-04
Loss = 2.4014e-04, PNorm = 48.8925, GNorm = 0.4717, lr_0 = 4.5220e-04
Loss = 3.1026e-04, PNorm = 48.9037, GNorm = 0.3768, lr_0 = 4.5173e-04
Loss = 2.7063e-04, PNorm = 48.9121, GNorm = 0.3241, lr_0 = 4.5125e-04
Loss = 2.5017e-04, PNorm = 48.9185, GNorm = 0.3800, lr_0 = 4.5078e-04
Loss = 2.2378e-04, PNorm = 48.9263, GNorm = 0.3411, lr_0 = 4.5031e-04
Loss = 2.7561e-04, PNorm = 48.9340, GNorm = 0.4350, lr_0 = 4.4984e-04
Loss = 3.3741e-04, PNorm = 48.9436, GNorm = 0.4611, lr_0 = 4.4937e-04
Loss = 2.9235e-04, PNorm = 48.9533, GNorm = 0.2551, lr_0 = 4.4890e-04
Loss = 3.9121e-04, PNorm = 48.9621, GNorm = 0.3606, lr_0 = 4.4844e-04
Validation rmse logD = 0.537712
Validation R2 logD = 0.795362
Validation rmse logP = 0.471399
Validation R2 logP = 0.934955
Epoch 36
Train function
Loss = 2.5250e-04, PNorm = 48.9701, GNorm = 0.3429, lr_0 = 4.4797e-04
Loss = 2.8797e-04, PNorm = 48.9813, GNorm = 0.2814, lr_0 = 4.4750e-04
Loss = 2.3218e-04, PNorm = 48.9897, GNorm = 0.2463, lr_0 = 4.4703e-04
Loss = 2.2469e-04, PNorm = 48.9978, GNorm = 0.2221, lr_0 = 4.4657e-04
Loss = 2.7501e-04, PNorm = 49.0031, GNorm = 0.4940, lr_0 = 4.4610e-04
Loss = 2.0044e-04, PNorm = 49.0112, GNorm = 0.2675, lr_0 = 4.4564e-04
Loss = 2.2507e-04, PNorm = 49.0183, GNorm = 0.4839, lr_0 = 4.4517e-04
Loss = 1.9721e-04, PNorm = 49.0239, GNorm = 0.3047, lr_0 = 4.4471e-04
Loss = 2.2577e-04, PNorm = 49.0314, GNorm = 0.4382, lr_0 = 4.4424e-04
Loss = 1.9462e-04, PNorm = 49.0356, GNorm = 0.2866, lr_0 = 4.4378e-04
Loss = 2.6149e-04, PNorm = 49.0393, GNorm = 0.3424, lr_0 = 4.4331e-04
Loss = 2.4325e-04, PNorm = 49.0476, GNorm = 0.2036, lr_0 = 4.4285e-04
Loss = 2.6631e-04, PNorm = 49.0530, GNorm = 0.3335, lr_0 = 4.4239e-04
Loss = 2.4259e-04, PNorm = 49.0601, GNorm = 0.6294, lr_0 = 4.4193e-04
Loss = 2.7911e-04, PNorm = 49.0670, GNorm = 0.2128, lr_0 = 4.4147e-04
Loss = 2.7295e-04, PNorm = 49.0773, GNorm = 0.1662, lr_0 = 4.4101e-04
Loss = 2.2520e-04, PNorm = 49.0892, GNorm = 0.2432, lr_0 = 4.4055e-04
Loss = 2.4115e-04, PNorm = 49.0975, GNorm = 0.6045, lr_0 = 4.4009e-04
Loss = 3.3082e-04, PNorm = 49.1050, GNorm = 0.3593, lr_0 = 4.3963e-04
Loss = 2.1526e-04, PNorm = 49.1125, GNorm = 0.2406, lr_0 = 4.3917e-04
Loss = 3.1159e-04, PNorm = 49.1213, GNorm = 0.2191, lr_0 = 4.3871e-04
Loss = 2.1526e-04, PNorm = 49.1304, GNorm = 0.2746, lr_0 = 4.3825e-04
Loss = 2.5326e-04, PNorm = 49.1380, GNorm = 0.3493, lr_0 = 4.3779e-04
Validation rmse logD = 0.537417
Validation R2 logD = 0.795587
Validation rmse logP = 0.468651
Validation R2 logP = 0.935711
Epoch 37
Train function
Loss = 2.1775e-04, PNorm = 49.1448, GNorm = 0.3375, lr_0 = 4.3729e-04
Loss = 2.5043e-04, PNorm = 49.1520, GNorm = 0.3813, lr_0 = 4.3684e-04
Loss = 2.3219e-04, PNorm = 49.1588, GNorm = 0.5665, lr_0 = 4.3638e-04
Loss = 2.4044e-04, PNorm = 49.1634, GNorm = 0.3462, lr_0 = 4.3592e-04
Loss = 1.9436e-04, PNorm = 49.1689, GNorm = 0.3929, lr_0 = 4.3547e-04
Loss = 2.2889e-04, PNorm = 49.1785, GNorm = 0.4218, lr_0 = 4.3501e-04
Loss = 2.9996e-04, PNorm = 49.1860, GNorm = 0.3847, lr_0 = 4.3456e-04
Loss = 2.2987e-04, PNorm = 49.1976, GNorm = 0.3185, lr_0 = 4.3411e-04
Loss = 3.6202e-04, PNorm = 49.2025, GNorm = 0.5499, lr_0 = 4.3365e-04
Loss = 3.8179e-04, PNorm = 49.2169, GNorm = 0.4561, lr_0 = 4.3320e-04
Loss = 3.5143e-04, PNorm = 49.2292, GNorm = 0.4819, lr_0 = 4.3275e-04
Loss = 3.3279e-04, PNorm = 49.2402, GNorm = 0.4053, lr_0 = 4.3230e-04
Loss = 3.0953e-04, PNorm = 49.2528, GNorm = 0.5831, lr_0 = 4.3185e-04
Loss = 2.0877e-04, PNorm = 49.2655, GNorm = 0.3161, lr_0 = 4.3140e-04
Loss = 2.6300e-04, PNorm = 49.2737, GNorm = 0.6198, lr_0 = 4.3094e-04
Loss = 2.2873e-04, PNorm = 49.2824, GNorm = 0.3927, lr_0 = 4.3050e-04
Loss = 2.4172e-04, PNorm = 49.2886, GNorm = 0.3387, lr_0 = 4.3005e-04
Loss = 2.2168e-04, PNorm = 49.2946, GNorm = 0.2335, lr_0 = 4.2960e-04
Loss = 2.6300e-04, PNorm = 49.3002, GNorm = 0.5983, lr_0 = 4.2915e-04
Loss = 2.1447e-04, PNorm = 49.3084, GNorm = 0.2512, lr_0 = 4.2870e-04
Loss = 2.1723e-04, PNorm = 49.3155, GNorm = 0.4014, lr_0 = 4.2825e-04
Loss = 2.3822e-04, PNorm = 49.3189, GNorm = 0.2317, lr_0 = 4.2781e-04
Validation rmse logD = 0.538259
Validation R2 logD = 0.794945
Validation rmse logP = 0.459063
Validation R2 logP = 0.938314
Epoch 38
Train function
Loss = 2.6583e-04, PNorm = 49.3255, GNorm = 0.2804, lr_0 = 4.2736e-04
Loss = 1.8911e-04, PNorm = 49.3289, GNorm = 0.3503, lr_0 = 4.2691e-04
Loss = 1.9793e-04, PNorm = 49.3340, GNorm = 0.1996, lr_0 = 4.2647e-04
Loss = 1.7149e-04, PNorm = 49.3401, GNorm = 0.3044, lr_0 = 4.2602e-04
Loss = 2.2630e-04, PNorm = 49.3463, GNorm = 0.4618, lr_0 = 4.2558e-04
Loss = 2.0946e-04, PNorm = 49.3565, GNorm = 0.2561, lr_0 = 4.2513e-04
Loss = 2.5571e-04, PNorm = 49.3633, GNorm = 0.4702, lr_0 = 4.2469e-04
Loss = 2.1822e-04, PNorm = 49.3703, GNorm = 0.4077, lr_0 = 4.2425e-04
Loss = 2.0287e-04, PNorm = 49.3788, GNorm = 0.6242, lr_0 = 4.2380e-04
Loss = 2.6931e-04, PNorm = 49.3840, GNorm = 0.3176, lr_0 = 4.2336e-04
Loss = 2.1707e-04, PNorm = 49.3912, GNorm = 0.3461, lr_0 = 4.2292e-04
Loss = 2.1953e-04, PNorm = 49.3964, GNorm = 0.3358, lr_0 = 4.2248e-04
Loss = 2.2349e-04, PNorm = 49.4068, GNorm = 0.2492, lr_0 = 4.2204e-04
Loss = 2.5207e-04, PNorm = 49.4138, GNorm = 0.3688, lr_0 = 4.2160e-04
Loss = 2.1749e-04, PNorm = 49.4213, GNorm = 0.4196, lr_0 = 4.2116e-04
Loss = 2.4260e-04, PNorm = 49.4263, GNorm = 0.4211, lr_0 = 4.2072e-04
Loss = 1.9399e-04, PNorm = 49.4306, GNorm = 0.4642, lr_0 = 4.2028e-04
Loss = 2.6141e-04, PNorm = 49.4363, GNorm = 0.5834, lr_0 = 4.1984e-04
Loss = 2.0119e-04, PNorm = 49.4416, GNorm = 0.1770, lr_0 = 4.1940e-04
Loss = 2.5038e-04, PNorm = 49.4468, GNorm = 0.5312, lr_0 = 4.1896e-04
Loss = 2.2133e-04, PNorm = 49.4538, GNorm = 0.4481, lr_0 = 4.1853e-04
Loss = 2.1404e-04, PNorm = 49.4611, GNorm = 0.5063, lr_0 = 4.1809e-04
Loss = 2.2112e-04, PNorm = 49.4617, GNorm = 0.4501, lr_0 = 4.1765e-04
Validation rmse logD = 0.561368
Validation R2 logD = 0.776960
Validation rmse logP = 0.482029
Validation R2 logP = 0.931988
Epoch 39
Train function
Loss = 2.7457e-04, PNorm = 49.4683, GNorm = 0.8201, lr_0 = 4.1717e-04
Loss = 2.7674e-04, PNorm = 49.4775, GNorm = 0.3112, lr_0 = 4.1674e-04
Loss = 2.9728e-04, PNorm = 49.4855, GNorm = 0.6328, lr_0 = 4.1630e-04
Loss = 2.8211e-04, PNorm = 49.4947, GNorm = 0.1850, lr_0 = 4.1587e-04
Loss = 2.8642e-04, PNorm = 49.5086, GNorm = 0.4347, lr_0 = 4.1544e-04
Loss = 2.1391e-04, PNorm = 49.5173, GNorm = 0.2301, lr_0 = 4.1500e-04
Loss = 1.6601e-04, PNorm = 49.5239, GNorm = 0.1795, lr_0 = 4.1457e-04
Loss = 1.6706e-04, PNorm = 49.5323, GNorm = 0.2845, lr_0 = 4.1414e-04
Loss = 1.8278e-04, PNorm = 49.5363, GNorm = 0.5471, lr_0 = 4.1370e-04
Loss = 2.2875e-04, PNorm = 49.5436, GNorm = 0.2531, lr_0 = 4.1327e-04
Loss = 2.0608e-04, PNorm = 49.5495, GNorm = 0.4683, lr_0 = 4.1284e-04
Loss = 1.7940e-04, PNorm = 49.5530, GNorm = 0.2366, lr_0 = 4.1241e-04
Loss = 1.8393e-04, PNorm = 49.5595, GNorm = 0.3659, lr_0 = 4.1198e-04
Loss = 1.7311e-04, PNorm = 49.5687, GNorm = 0.2245, lr_0 = 4.1155e-04
Loss = 1.8319e-04, PNorm = 49.5740, GNorm = 0.4685, lr_0 = 4.1112e-04
Loss = 1.8282e-04, PNorm = 49.5793, GNorm = 0.2646, lr_0 = 4.1069e-04
Loss = 2.0647e-04, PNorm = 49.5846, GNorm = 0.3373, lr_0 = 4.1026e-04
Loss = 2.7248e-04, PNorm = 49.5924, GNorm = 0.4077, lr_0 = 4.0983e-04
Loss = 2.0210e-04, PNorm = 49.6053, GNorm = 0.3027, lr_0 = 4.0941e-04
Loss = 1.9054e-04, PNorm = 49.6155, GNorm = 0.1920, lr_0 = 4.0898e-04
Loss = 2.1602e-04, PNorm = 49.6211, GNorm = 0.3024, lr_0 = 4.0855e-04
Loss = 1.9820e-04, PNorm = 49.6259, GNorm = 0.4393, lr_0 = 4.0813e-04
Validation rmse logD = 0.541854
Validation R2 logD = 0.792197
Validation rmse logP = 0.472405
Validation R2 logP = 0.934677
Epoch 40
Train function
Loss = 2.2017e-04, PNorm = 49.6307, GNorm = 0.5050, lr_0 = 4.0770e-04
Loss = 2.3405e-04, PNorm = 49.6355, GNorm = 0.5947, lr_0 = 4.0727e-04
Loss = 2.5147e-04, PNorm = 49.6447, GNorm = 0.4473, lr_0 = 4.0685e-04
Loss = 2.3600e-04, PNorm = 49.6523, GNorm = 0.7187, lr_0 = 4.0642e-04
Loss = 1.8531e-04, PNorm = 49.6560, GNorm = 0.3966, lr_0 = 4.0600e-04
Loss = 2.0423e-04, PNorm = 49.6624, GNorm = 0.3470, lr_0 = 4.0558e-04
Loss = 1.9815e-04, PNorm = 49.6667, GNorm = 0.3200, lr_0 = 4.0515e-04
Loss = 1.9574e-04, PNorm = 49.6719, GNorm = 0.3674, lr_0 = 4.0473e-04
Loss = 1.5985e-04, PNorm = 49.6787, GNorm = 0.1972, lr_0 = 4.0431e-04
Loss = 1.8139e-04, PNorm = 49.6830, GNorm = 0.3571, lr_0 = 4.0389e-04
Loss = 2.1067e-04, PNorm = 49.6873, GNorm = 0.2896, lr_0 = 4.0346e-04
Loss = 1.9532e-04, PNorm = 49.6943, GNorm = 0.3331, lr_0 = 4.0304e-04
Loss = 1.8041e-04, PNorm = 49.6991, GNorm = 0.3129, lr_0 = 4.0262e-04
Loss = 2.5066e-04, PNorm = 49.7048, GNorm = 0.3968, lr_0 = 4.0220e-04
Loss = 2.2958e-04, PNorm = 49.7097, GNorm = 0.2072, lr_0 = 4.0178e-04
Loss = 1.7498e-04, PNorm = 49.7128, GNorm = 0.5598, lr_0 = 4.0136e-04
Loss = 1.9749e-04, PNorm = 49.7202, GNorm = 0.2590, lr_0 = 4.0094e-04
Loss = 1.8431e-04, PNorm = 49.7289, GNorm = 0.2812, lr_0 = 4.0053e-04
Loss = 2.1778e-04, PNorm = 49.7341, GNorm = 0.6248, lr_0 = 4.0011e-04
Loss = 2.2960e-04, PNorm = 49.7424, GNorm = 0.2780, lr_0 = 3.9969e-04
Loss = 2.3677e-04, PNorm = 49.7508, GNorm = 0.4819, lr_0 = 3.9927e-04
Loss = 2.7680e-04, PNorm = 49.7572, GNorm = 0.7831, lr_0 = 3.9886e-04
Loss = 2.3727e-04, PNorm = 49.7626, GNorm = 0.3927, lr_0 = 3.9844e-04
Validation rmse logD = 0.545527
Validation R2 logD = 0.789371
Validation rmse logP = 0.474608
Validation R2 logP = 0.934066
Epoch 41
Train function
Loss = 2.1914e-04, PNorm = 49.7709, GNorm = 0.2504, lr_0 = 3.9798e-04
Loss = 2.2897e-04, PNorm = 49.7773, GNorm = 0.5681, lr_0 = 3.9757e-04
Loss = 2.3189e-04, PNorm = 49.7827, GNorm = 0.3895, lr_0 = 3.9715e-04
Loss = 2.0532e-04, PNorm = 49.7895, GNorm = 0.2360, lr_0 = 3.9674e-04
Loss = 1.9823e-04, PNorm = 49.7993, GNorm = 0.5112, lr_0 = 3.9632e-04
Loss = 2.0482e-04, PNorm = 49.8068, GNorm = 0.3354, lr_0 = 3.9591e-04
Loss = 1.8552e-04, PNorm = 49.8136, GNorm = 0.2542, lr_0 = 3.9550e-04
Loss = 1.9071e-04, PNorm = 49.8216, GNorm = 0.4495, lr_0 = 3.9508e-04
Loss = 1.8289e-04, PNorm = 49.8269, GNorm = 0.2869, lr_0 = 3.9467e-04
Loss = 1.7895e-04, PNorm = 49.8311, GNorm = 0.2897, lr_0 = 3.9426e-04
Loss = 1.7525e-04, PNorm = 49.8320, GNorm = 0.2785, lr_0 = 3.9385e-04
Loss = 1.7000e-04, PNorm = 49.8387, GNorm = 0.1930, lr_0 = 3.9344e-04
Loss = 2.1805e-04, PNorm = 49.8471, GNorm = 0.4046, lr_0 = 3.9303e-04
Loss = 1.9021e-04, PNorm = 49.8544, GNorm = 0.2164, lr_0 = 3.9262e-04
Loss = 1.8148e-04, PNorm = 49.8569, GNorm = 0.3720, lr_0 = 3.9221e-04
Loss = 2.1333e-04, PNorm = 49.8659, GNorm = 0.1666, lr_0 = 3.9180e-04
Loss = 1.8711e-04, PNorm = 49.8703, GNorm = 0.4727, lr_0 = 3.9139e-04
Loss = 1.6077e-04, PNorm = 49.8761, GNorm = 0.3040, lr_0 = 3.9098e-04
Loss = 1.5609e-04, PNorm = 49.8840, GNorm = 0.2801, lr_0 = 3.9057e-04
Loss = 1.6220e-04, PNorm = 49.8897, GNorm = 0.3253, lr_0 = 3.9016e-04
Loss = 1.4531e-04, PNorm = 49.8940, GNorm = 0.3187, lr_0 = 3.8976e-04
Loss = 1.9571e-04, PNorm = 49.9001, GNorm = 0.5372, lr_0 = 3.8935e-04
Loss = 1.9767e-04, PNorm = 49.9077, GNorm = 0.2862, lr_0 = 3.8894e-04
Validation rmse logD = 0.540934
Validation R2 logD = 0.792902
Validation rmse logP = 0.463777
Validation R2 logP = 0.937041
Epoch 42
Train function
Loss = 1.3954e-04, PNorm = 49.9148, GNorm = 0.2550, lr_0 = 3.8854e-04
Loss = 2.0577e-04, PNorm = 49.9154, GNorm = 0.6985, lr_0 = 3.8813e-04
Loss = 1.5041e-04, PNorm = 49.9195, GNorm = 0.3027, lr_0 = 3.8773e-04
Loss = 1.5500e-04, PNorm = 49.9243, GNorm = 0.3846, lr_0 = 3.8732e-04
Loss = 1.3021e-04, PNorm = 49.9296, GNorm = 0.2978, lr_0 = 3.8692e-04
Loss = 1.6741e-04, PNorm = 49.9343, GNorm = 0.2367, lr_0 = 3.8651e-04
Loss = 1.4444e-04, PNorm = 49.9386, GNorm = 0.2823, lr_0 = 3.8611e-04
Loss = 1.3491e-04, PNorm = 49.9440, GNorm = 0.2632, lr_0 = 3.8571e-04
Loss = 1.2640e-04, PNorm = 49.9480, GNorm = 0.2163, lr_0 = 3.8531e-04
Loss = 1.4430e-04, PNorm = 49.9536, GNorm = 0.2233, lr_0 = 3.8490e-04
Loss = 1.2072e-04, PNorm = 49.9583, GNorm = 0.2257, lr_0 = 3.8450e-04
Loss = 1.6200e-04, PNorm = 49.9629, GNorm = 0.2812, lr_0 = 3.8410e-04
Loss = 1.4499e-04, PNorm = 49.9681, GNorm = 0.2694, lr_0 = 3.8370e-04
Loss = 1.7444e-04, PNorm = 49.9720, GNorm = 0.2122, lr_0 = 3.8330e-04
Loss = 1.5375e-04, PNorm = 49.9778, GNorm = 0.2066, lr_0 = 3.8290e-04
Loss = 2.0738e-04, PNorm = 49.9848, GNorm = 0.3980, lr_0 = 3.8250e-04
Loss = 1.9812e-04, PNorm = 49.9891, GNorm = 0.7320, lr_0 = 3.8210e-04
Loss = 1.8910e-04, PNorm = 49.9965, GNorm = 0.3044, lr_0 = 3.8170e-04
Loss = 1.9260e-04, PNorm = 50.0040, GNorm = 0.3292, lr_0 = 3.8130e-04
Loss = 1.7967e-04, PNorm = 50.0105, GNorm = 0.3256, lr_0 = 3.8090e-04
Loss = 1.6720e-04, PNorm = 50.0180, GNorm = 0.2120, lr_0 = 3.8051e-04
Loss = 1.5129e-04, PNorm = 50.0234, GNorm = 0.2116, lr_0 = 3.8011e-04
Validation rmse logD = 0.532639
Validation R2 logD = 0.799205
Validation rmse logP = 0.464949
Validation R2 logP = 0.936723
Epoch 43
Train function
Loss = 1.3346e-04, PNorm = 50.0309, GNorm = 0.3914, lr_0 = 3.7967e-04
Loss = 1.2427e-04, PNorm = 50.0370, GNorm = 0.2328, lr_0 = 3.7928e-04
Loss = 1.5905e-04, PNorm = 50.0383, GNorm = 0.2084, lr_0 = 3.7888e-04
Loss = 1.5176e-04, PNorm = 50.0422, GNorm = 0.3678, lr_0 = 3.7849e-04
Loss = 1.3389e-04, PNorm = 50.0473, GNorm = 0.1494, lr_0 = 3.7809e-04
Loss = 1.9511e-04, PNorm = 50.0558, GNorm = 0.1482, lr_0 = 3.7770e-04
Loss = 1.9219e-04, PNorm = 50.0632, GNorm = 0.2303, lr_0 = 3.7730e-04
Loss = 1.4289e-04, PNorm = 50.0695, GNorm = 0.2709, lr_0 = 3.7691e-04
Loss = 1.7095e-04, PNorm = 50.0750, GNorm = 0.4685, lr_0 = 3.7652e-04
Loss = 1.7481e-04, PNorm = 50.0816, GNorm = 0.4241, lr_0 = 3.7612e-04
Loss = 1.3890e-04, PNorm = 50.0870, GNorm = 0.1838, lr_0 = 3.7573e-04
Loss = 1.6615e-04, PNorm = 50.0897, GNorm = 0.2972, lr_0 = 3.7534e-04
Loss = 1.5452e-04, PNorm = 50.0931, GNorm = 0.2846, lr_0 = 3.7495e-04
Loss = 2.1260e-04, PNorm = 50.1007, GNorm = 0.6219, lr_0 = 3.7455e-04
Loss = 1.9637e-04, PNorm = 50.1075, GNorm = 0.2641, lr_0 = 3.7416e-04
Loss = 1.7616e-04, PNorm = 50.1156, GNorm = 0.2852, lr_0 = 3.7377e-04
Loss = 1.9773e-04, PNorm = 50.1256, GNorm = 0.2192, lr_0 = 3.7338e-04
Loss = 2.2181e-04, PNorm = 50.1319, GNorm = 0.2904, lr_0 = 3.7299e-04
Loss = 1.7592e-04, PNorm = 50.1368, GNorm = 0.4385, lr_0 = 3.7260e-04
Loss = 1.7326e-04, PNorm = 50.1412, GNorm = 0.2643, lr_0 = 3.7221e-04
Loss = 1.7882e-04, PNorm = 50.1467, GNorm = 0.3804, lr_0 = 3.7183e-04
Loss = 1.7297e-04, PNorm = 50.1541, GNorm = 0.1907, lr_0 = 3.7144e-04
Loss = 1.7511e-04, PNorm = 50.1595, GNorm = 0.2294, lr_0 = 3.7105e-04
Validation rmse logD = 0.542223
Validation R2 logD = 0.791914
Validation rmse logP = 0.468904
Validation R2 logP = 0.935641
Epoch 44
Train function
Loss = 1.6249e-04, PNorm = 50.1656, GNorm = 0.4750, lr_0 = 3.7066e-04
Loss = 1.7452e-04, PNorm = 50.1706, GNorm = 0.1839, lr_0 = 3.7028e-04
Loss = 1.3154e-04, PNorm = 50.1777, GNorm = 0.2897, lr_0 = 3.6989e-04
Loss = 1.3519e-04, PNorm = 50.1832, GNorm = 0.2861, lr_0 = 3.6950e-04
Loss = 1.3942e-04, PNorm = 50.1889, GNorm = 0.4911, lr_0 = 3.6912e-04
Loss = 1.9009e-04, PNorm = 50.1932, GNorm = 0.3279, lr_0 = 3.6873e-04
Loss = 2.2207e-04, PNorm = 50.1977, GNorm = 0.4078, lr_0 = 3.6835e-04
Loss = 1.6609e-04, PNorm = 50.2003, GNorm = 0.3223, lr_0 = 3.6796e-04
Loss = 1.3531e-04, PNorm = 50.2051, GNorm = 0.3588, lr_0 = 3.6758e-04
Loss = 1.7608e-04, PNorm = 50.2133, GNorm = 0.4523, lr_0 = 3.6720e-04
Loss = 1.6113e-04, PNorm = 50.2151, GNorm = 0.3497, lr_0 = 3.6681e-04
Loss = 2.0502e-04, PNorm = 50.2206, GNorm = 0.3730, lr_0 = 3.6643e-04
Loss = 1.5648e-04, PNorm = 50.2270, GNorm = 0.3255, lr_0 = 3.6605e-04
Loss = 1.8235e-04, PNorm = 50.2320, GNorm = 0.2821, lr_0 = 3.6567e-04
Loss = 1.5970e-04, PNorm = 50.2379, GNorm = 0.3525, lr_0 = 3.6528e-04
Loss = 1.6835e-04, PNorm = 50.2443, GNorm = 0.3702, lr_0 = 3.6490e-04
Loss = 1.4411e-04, PNorm = 50.2518, GNorm = 0.2257, lr_0 = 3.6452e-04
Loss = 1.5484e-04, PNorm = 50.2574, GNorm = 0.3575, lr_0 = 3.6414e-04
Loss = 2.1314e-04, PNorm = 50.2609, GNorm = 0.6943, lr_0 = 3.6376e-04
Loss = 1.9015e-04, PNorm = 50.2641, GNorm = 0.2459, lr_0 = 3.6338e-04
Loss = 1.6379e-04, PNorm = 50.2704, GNorm = 0.2625, lr_0 = 3.6300e-04
Loss = 1.5782e-04, PNorm = 50.2775, GNorm = 0.2186, lr_0 = 3.6262e-04
Validation rmse logD = 0.542770
Validation R2 logD = 0.791494
Validation rmse logP = 0.469569
Validation R2 logP = 0.935459
Epoch 45
Train function
Loss = 1.4327e-04, PNorm = 50.2860, GNorm = 0.2907, lr_0 = 3.6221e-04
Loss = 1.3733e-04, PNorm = 50.2892, GNorm = 0.1683, lr_0 = 3.6183e-04
Loss = 1.4498e-04, PNorm = 50.2920, GNorm = 0.4438, lr_0 = 3.6145e-04
Loss = 1.3161e-04, PNorm = 50.2974, GNorm = 0.2591, lr_0 = 3.6107e-04
Loss = 1.3028e-04, PNorm = 50.3022, GNorm = 0.3784, lr_0 = 3.6070e-04
Loss = 1.4800e-04, PNorm = 50.3071, GNorm = 0.1697, lr_0 = 3.6032e-04
Loss = 1.4054e-04, PNorm = 50.3101, GNorm = 0.3107, lr_0 = 3.5994e-04
Loss = 2.0135e-04, PNorm = 50.3149, GNorm = 0.4139, lr_0 = 3.5957e-04
Loss = 1.4490e-04, PNorm = 50.3206, GNorm = 0.2562, lr_0 = 3.5919e-04
Loss = 1.3337e-04, PNorm = 50.3271, GNorm = 0.1716, lr_0 = 3.5882e-04
Loss = 1.1672e-04, PNorm = 50.3314, GNorm = 0.2405, lr_0 = 3.5844e-04
Loss = 1.2900e-04, PNorm = 50.3346, GNorm = 0.2928, lr_0 = 3.5807e-04
Loss = 1.9080e-04, PNorm = 50.3409, GNorm = 0.4840, lr_0 = 3.5770e-04
Loss = 1.3421e-04, PNorm = 50.3451, GNorm = 0.4081, lr_0 = 3.5732e-04
Loss = 1.1311e-04, PNorm = 50.3487, GNorm = 0.1782, lr_0 = 3.5695e-04
Loss = 1.3267e-04, PNorm = 50.3509, GNorm = 0.2296, lr_0 = 3.5658e-04
Loss = 1.2054e-04, PNorm = 50.3536, GNorm = 0.4306, lr_0 = 3.5621e-04
Loss = 1.8166e-04, PNorm = 50.3561, GNorm = 0.4579, lr_0 = 3.5583e-04
Loss = 1.6389e-04, PNorm = 50.3649, GNorm = 0.3335, lr_0 = 3.5546e-04
Loss = 1.6050e-04, PNorm = 50.3723, GNorm = 0.2541, lr_0 = 3.5509e-04
Loss = 1.6407e-04, PNorm = 50.3783, GNorm = 0.2530, lr_0 = 3.5472e-04
Loss = 1.3030e-04, PNorm = 50.3853, GNorm = 0.1966, lr_0 = 3.5435e-04
Loss = 1.4792e-04, PNorm = 50.3894, GNorm = 0.2373, lr_0 = 3.5398e-04
Validation rmse logD = 0.545217
Validation R2 logD = 0.789610
Validation rmse logP = 0.473073
Validation R2 logP = 0.934492
Epoch 46
Train function
Loss = 1.1822e-04, PNorm = 50.3922, GNorm = 0.2737, lr_0 = 3.5361e-04
Loss = 1.2146e-04, PNorm = 50.3948, GNorm = 0.3180, lr_0 = 3.5324e-04
Loss = 1.3466e-04, PNorm = 50.4006, GNorm = 0.2522, lr_0 = 3.5287e-04
Loss = 1.3737e-04, PNorm = 50.4054, GNorm = 0.4057, lr_0 = 3.5251e-04
Loss = 1.1462e-04, PNorm = 50.4095, GNorm = 0.2370, lr_0 = 3.5214e-04
Loss = 1.1644e-04, PNorm = 50.4125, GNorm = 0.3160, lr_0 = 3.5177e-04
Loss = 1.2451e-04, PNorm = 50.4173, GNorm = 0.2208, lr_0 = 3.5140e-04
Loss = 1.2325e-04, PNorm = 50.4263, GNorm = 0.4149, lr_0 = 3.5104e-04
Loss = 1.1510e-04, PNorm = 50.4290, GNorm = 0.2079, lr_0 = 3.5067e-04
Loss = 1.2569e-04, PNorm = 50.4355, GNorm = 0.3109, lr_0 = 3.5030e-04
Loss = 1.4160e-04, PNorm = 50.4404, GNorm = 0.5029, lr_0 = 3.4994e-04
Loss = 1.6254e-04, PNorm = 50.4480, GNorm = 0.2664, lr_0 = 3.4957e-04
Loss = 1.3513e-04, PNorm = 50.4552, GNorm = 0.1575, lr_0 = 3.4921e-04
Loss = 1.4743e-04, PNorm = 50.4583, GNorm = 0.2848, lr_0 = 3.4884e-04
Loss = 1.3336e-04, PNorm = 50.4602, GNorm = 0.3135, lr_0 = 3.4848e-04
Loss = 1.6475e-04, PNorm = 50.4637, GNorm = 0.2797, lr_0 = 3.4812e-04
Loss = 1.3631e-04, PNorm = 50.4689, GNorm = 0.2360, lr_0 = 3.4775e-04
Loss = 1.3495e-04, PNorm = 50.4721, GNorm = 0.2403, lr_0 = 3.4739e-04
Loss = 1.2718e-04, PNorm = 50.4789, GNorm = 0.1986, lr_0 = 3.4703e-04
Loss = 1.3907e-04, PNorm = 50.4851, GNorm = 0.2635, lr_0 = 3.4666e-04
Loss = 1.4373e-04, PNorm = 50.4898, GNorm = 0.2662, lr_0 = 3.4630e-04
Loss = 1.3388e-04, PNorm = 50.4931, GNorm = 0.1676, lr_0 = 3.4594e-04
Validation rmse logD = 0.539838
Validation R2 logD = 0.793741
Validation rmse logP = 0.464405
Validation R2 logP = 0.936871
Epoch 47
Train function
Loss = 1.5357e-04, PNorm = 50.4969, GNorm = 0.5340, lr_0 = 3.4554e-04
Loss = 1.4692e-04, PNorm = 50.5003, GNorm = 0.3638, lr_0 = 3.4518e-04
Loss = 1.1820e-04, PNorm = 50.5064, GNorm = 0.2840, lr_0 = 3.4482e-04
Loss = 1.1922e-04, PNorm = 50.5117, GNorm = 0.1958, lr_0 = 3.4446e-04
Loss = 1.2979e-04, PNorm = 50.5203, GNorm = 0.1899, lr_0 = 3.4410e-04
Loss = 1.2117e-04, PNorm = 50.5230, GNorm = 0.2003, lr_0 = 3.4374e-04
Loss = 1.1359e-04, PNorm = 50.5288, GNorm = 0.1913, lr_0 = 3.4339e-04
Loss = 1.1146e-04, PNorm = 50.5360, GNorm = 0.1894, lr_0 = 3.4303e-04
Loss = 1.1403e-04, PNorm = 50.5400, GNorm = 0.2470, lr_0 = 3.4267e-04
Loss = 1.2530e-04, PNorm = 50.5438, GNorm = 0.2998, lr_0 = 3.4231e-04
Loss = 1.0811e-04, PNorm = 50.5481, GNorm = 0.3678, lr_0 = 3.4195e-04
Loss = 1.5648e-04, PNorm = 50.5524, GNorm = 0.3172, lr_0 = 3.4160e-04
Loss = 1.5600e-04, PNorm = 50.5574, GNorm = 0.4967, lr_0 = 3.4124e-04
Loss = 1.1790e-04, PNorm = 50.5613, GNorm = 0.2638, lr_0 = 3.4088e-04
Loss = 1.0199e-04, PNorm = 50.5647, GNorm = 0.2182, lr_0 = 3.4053e-04
Loss = 1.1631e-04, PNorm = 50.5676, GNorm = 0.2169, lr_0 = 3.4017e-04
Loss = 9.7956e-05, PNorm = 50.5692, GNorm = 0.2292, lr_0 = 3.3982e-04
Loss = 1.0291e-04, PNorm = 50.5752, GNorm = 0.2107, lr_0 = 3.3946e-04
Loss = 1.8276e-04, PNorm = 50.5815, GNorm = 0.2838, lr_0 = 3.3911e-04
Loss = 1.8472e-04, PNorm = 50.5854, GNorm = 0.4080, lr_0 = 3.3876e-04
Loss = 1.2296e-04, PNorm = 50.5913, GNorm = 0.2272, lr_0 = 3.3840e-04
Loss = 1.3577e-04, PNorm = 50.5954, GNorm = 0.2438, lr_0 = 3.3805e-04
Loss = 1.5687e-04, PNorm = 50.5998, GNorm = 0.1561, lr_0 = 3.3770e-04
Validation rmse logD = 0.535865
Validation R2 logD = 0.796765
Validation rmse logP = 0.464761
Validation R2 logP = 0.936774
Epoch 48
Train function
Loss = 1.3377e-04, PNorm = 50.6055, GNorm = 0.2885, lr_0 = 3.3734e-04
Loss = 1.3293e-04, PNorm = 50.6144, GNorm = 0.2767, lr_0 = 3.3699e-04
Loss = 1.1154e-04, PNorm = 50.6183, GNorm = 0.2633, lr_0 = 3.3664e-04
Loss = 1.4026e-04, PNorm = 50.6211, GNorm = 0.2301, lr_0 = 3.3629e-04
Loss = 1.0074e-04, PNorm = 50.6234, GNorm = 0.2071, lr_0 = 3.3594e-04
Loss = 9.5235e-05, PNorm = 50.6260, GNorm = 0.1863, lr_0 = 3.3559e-04
Loss = 1.0823e-04, PNorm = 50.6308, GNorm = 0.2194, lr_0 = 3.3524e-04
Loss = 1.3612e-04, PNorm = 50.6350, GNorm = 0.2064, lr_0 = 3.3489e-04
Loss = 1.4415e-04, PNorm = 50.6393, GNorm = 0.3939, lr_0 = 3.3454e-04
Loss = 1.1633e-04, PNorm = 50.6436, GNorm = 0.2842, lr_0 = 3.3419e-04
Loss = 1.4532e-04, PNorm = 50.6476, GNorm = 0.3613, lr_0 = 3.3384e-04
Loss = 1.3967e-04, PNorm = 50.6512, GNorm = 0.2870, lr_0 = 3.3349e-04
Loss = 1.1597e-04, PNorm = 50.6560, GNorm = 0.2232, lr_0 = 3.3314e-04
Loss = 1.4950e-04, PNorm = 50.6609, GNorm = 0.1865, lr_0 = 3.3280e-04
Loss = 1.2003e-04, PNorm = 50.6662, GNorm = 0.2141, lr_0 = 3.3245e-04
Loss = 1.2634e-04, PNorm = 50.6709, GNorm = 0.2490, lr_0 = 3.3210e-04
Loss = 1.1334e-04, PNorm = 50.6761, GNorm = 0.2090, lr_0 = 3.3175e-04
Loss = 1.3302e-04, PNorm = 50.6803, GNorm = 0.2199, lr_0 = 3.3141e-04
Loss = 1.4017e-04, PNorm = 50.6831, GNorm = 0.2252, lr_0 = 3.3106e-04
Loss = 1.2977e-04, PNorm = 50.6887, GNorm = 0.3196, lr_0 = 3.3072e-04
Loss = 1.9231e-04, PNorm = 50.6922, GNorm = 0.3054, lr_0 = 3.3037e-04
Loss = 1.2350e-04, PNorm = 50.6954, GNorm = 0.2076, lr_0 = 3.3003e-04
Validation rmse logD = 0.535182
Validation R2 logD = 0.797283
Validation rmse logP = 0.465903
Validation R2 logP = 0.936463
Epoch 49
Train function
Loss = 1.1869e-04, PNorm = 50.7002, GNorm = 0.4584, lr_0 = 3.2965e-04
Loss = 1.2665e-04, PNorm = 50.7059, GNorm = 0.1866, lr_0 = 3.2930e-04
Loss = 1.1935e-04, PNorm = 50.7114, GNorm = 0.1642, lr_0 = 3.2896e-04
Loss = 1.1392e-04, PNorm = 50.7151, GNorm = 0.3562, lr_0 = 3.2862e-04
Loss = 1.0316e-04, PNorm = 50.7183, GNorm = 0.2225, lr_0 = 3.2827e-04
Loss = 1.4453e-04, PNorm = 50.7235, GNorm = 0.2612, lr_0 = 3.2793e-04
Loss = 1.2550e-04, PNorm = 50.7281, GNorm = 0.2620, lr_0 = 3.2759e-04
Loss = 1.2187e-04, PNorm = 50.7331, GNorm = 0.2416, lr_0 = 3.2725e-04
Loss = 9.6978e-05, PNorm = 50.7372, GNorm = 0.3812, lr_0 = 3.2691e-04
Loss = 1.0324e-04, PNorm = 50.7417, GNorm = 0.1353, lr_0 = 3.2656e-04
Loss = 1.2434e-04, PNorm = 50.7469, GNorm = 0.2498, lr_0 = 3.2622e-04
Loss = 1.0916e-04, PNorm = 50.7508, GNorm = 0.3596, lr_0 = 3.2588e-04
Loss = 1.4884e-04, PNorm = 50.7539, GNorm = 0.1878, lr_0 = 3.2554e-04
Loss = 1.4622e-04, PNorm = 50.7615, GNorm = 0.3830, lr_0 = 3.2520e-04
Loss = 1.0804e-04, PNorm = 50.7689, GNorm = 0.2148, lr_0 = 3.2486e-04
Loss = 1.4472e-04, PNorm = 50.7723, GNorm = 0.2620, lr_0 = 3.2452e-04
Loss = 1.1880e-04, PNorm = 50.7766, GNorm = 0.3914, lr_0 = 3.2419e-04
Loss = 1.0656e-04, PNorm = 50.7791, GNorm = 0.2138, lr_0 = 3.2385e-04
Loss = 1.6656e-04, PNorm = 50.7859, GNorm = 0.4326, lr_0 = 3.2351e-04
Loss = 1.8992e-04, PNorm = 50.7911, GNorm = 0.3157, lr_0 = 3.2317e-04
Loss = 1.6670e-04, PNorm = 50.7978, GNorm = 0.3325, lr_0 = 3.2283e-04
Loss = 1.8503e-04, PNorm = 50.8038, GNorm = 0.4067, lr_0 = 3.2250e-04
Loss = 1.3829e-04, PNorm = 50.8076, GNorm = 0.3476, lr_0 = 3.2216e-04
Validation rmse logD = 0.539154
Validation R2 logD = 0.794263
Validation rmse logP = 0.461431
Validation R2 logP = 0.937677
Epoch 50
Train function
Loss = 1.5003e-04, PNorm = 50.8139, GNorm = 0.2425, lr_0 = 3.2182e-04
Loss = 1.2540e-04, PNorm = 50.8143, GNorm = 0.3570, lr_0 = 3.2149e-04
Loss = 1.2114e-04, PNorm = 50.8162, GNorm = 0.2068, lr_0 = 3.2115e-04
Loss = 1.4446e-04, PNorm = 50.8212, GNorm = 0.2981, lr_0 = 3.2082e-04
Loss = 1.2805e-04, PNorm = 50.8254, GNorm = 0.2127, lr_0 = 3.2048e-04
Loss = 1.2158e-04, PNorm = 50.8294, GNorm = 0.3452, lr_0 = 3.2015e-04
Loss = 1.0032e-04, PNorm = 50.8366, GNorm = 0.5179, lr_0 = 3.1981e-04
Loss = 1.1707e-04, PNorm = 50.8405, GNorm = 0.2417, lr_0 = 3.1948e-04
Loss = 1.0258e-04, PNorm = 50.8424, GNorm = 0.4073, lr_0 = 3.1915e-04
Loss = 1.2837e-04, PNorm = 50.8434, GNorm = 0.1831, lr_0 = 3.1881e-04
Loss = 1.3217e-04, PNorm = 50.8475, GNorm = 0.3821, lr_0 = 3.1848e-04
Loss = 1.1885e-04, PNorm = 50.8526, GNorm = 0.3032, lr_0 = 3.1815e-04
Loss = 9.2155e-05, PNorm = 50.8556, GNorm = 0.1639, lr_0 = 3.1782e-04
Loss = 1.0432e-04, PNorm = 50.8600, GNorm = 0.1311, lr_0 = 3.1749e-04
Loss = 1.2270e-04, PNorm = 50.8630, GNorm = 0.2079, lr_0 = 3.1715e-04
Loss = 8.3629e-05, PNorm = 50.8669, GNorm = 0.1969, lr_0 = 3.1682e-04
Loss = 9.6269e-05, PNorm = 50.8710, GNorm = 0.2949, lr_0 = 3.1649e-04
Loss = 8.5516e-05, PNorm = 50.8752, GNorm = 0.2367, lr_0 = 3.1616e-04
Loss = 1.5049e-04, PNorm = 50.8794, GNorm = 0.2861, lr_0 = 3.1583e-04
Loss = 1.4900e-04, PNorm = 50.8829, GNorm = 0.3652, lr_0 = 3.1550e-04
Loss = 1.5393e-04, PNorm = 50.8876, GNorm = 0.4733, lr_0 = 3.1517e-04
Loss = 1.3251e-04, PNorm = 50.8929, GNorm = 0.2596, lr_0 = 3.1484e-04
Validation rmse logD = 0.536553
Validation R2 logD = 0.796244
Validation rmse logP = 0.462319
Validation R2 logP = 0.937436
Epoch 51
Train function
Loss = 1.6829e-04, PNorm = 50.8963, GNorm = 0.3540, lr_0 = 3.1448e-04
Loss = 8.2447e-05, PNorm = 50.9017, GNorm = 0.2014, lr_0 = 3.1415e-04
Loss = 1.0472e-04, PNorm = 50.9061, GNorm = 0.1940, lr_0 = 3.1383e-04
Loss = 1.1137e-04, PNorm = 50.9108, GNorm = 0.1960, lr_0 = 3.1350e-04
Loss = 8.9293e-05, PNorm = 50.9140, GNorm = 0.2526, lr_0 = 3.1317e-04
Loss = 1.1742e-04, PNorm = 50.9173, GNorm = 0.2344, lr_0 = 3.1284e-04
Loss = 1.1715e-04, PNorm = 50.9223, GNorm = 0.1983, lr_0 = 3.1252e-04
Loss = 1.1770e-04, PNorm = 50.9271, GNorm = 0.2896, lr_0 = 3.1219e-04
Loss = 9.8576e-05, PNorm = 50.9314, GNorm = 0.1768, lr_0 = 3.1187e-04
Loss = 8.3160e-05, PNorm = 50.9347, GNorm = 0.1672, lr_0 = 3.1154e-04
Loss = 1.2171e-04, PNorm = 50.9382, GNorm = 0.5023, lr_0 = 3.1122e-04
Loss = 1.1779e-04, PNorm = 50.9409, GNorm = 0.1591, lr_0 = 3.1089e-04
Loss = 1.1220e-04, PNorm = 50.9458, GNorm = 0.1976, lr_0 = 3.1057e-04
Loss = 9.5669e-05, PNorm = 50.9493, GNorm = 0.1919, lr_0 = 3.1024e-04
Loss = 1.0164e-04, PNorm = 50.9520, GNorm = 0.2494, lr_0 = 3.0992e-04
Loss = 9.8082e-05, PNorm = 50.9565, GNorm = 0.1708, lr_0 = 3.0959e-04
Loss = 9.7291e-05, PNorm = 50.9585, GNorm = 0.2486, lr_0 = 3.0927e-04
Loss = 8.5730e-05, PNorm = 50.9606, GNorm = 0.1813, lr_0 = 3.0895e-04
Loss = 1.0231e-04, PNorm = 50.9656, GNorm = 0.1295, lr_0 = 3.0863e-04
Loss = 1.2971e-04, PNorm = 50.9696, GNorm = 0.5369, lr_0 = 3.0830e-04
Loss = 1.1504e-04, PNorm = 50.9747, GNorm = 0.2731, lr_0 = 3.0798e-04
Loss = 1.6083e-04, PNorm = 50.9796, GNorm = 0.1681, lr_0 = 3.0766e-04
Loss = 1.1486e-04, PNorm = 50.9864, GNorm = 0.2558, lr_0 = 3.0734e-04
Validation rmse logD = 0.534823
Validation R2 logD = 0.797555
Validation rmse logP = 0.465534
Validation R2 logP = 0.936563
Epoch 52
Train function
Loss = 8.8261e-05, PNorm = 50.9899, GNorm = 0.1839, lr_0 = 3.0699e-04
Loss = 1.1187e-04, PNorm = 50.9920, GNorm = 0.2545, lr_0 = 3.0667e-04
Loss = 9.3891e-05, PNorm = 50.9938, GNorm = 0.2247, lr_0 = 3.0635e-04
Loss = 9.1576e-05, PNorm = 50.9988, GNorm = 0.1806, lr_0 = 3.0603e-04
Loss = 9.0146e-05, PNorm = 51.0022, GNorm = 0.3309, lr_0 = 3.0571e-04
Loss = 8.7713e-05, PNorm = 51.0074, GNorm = 0.1110, lr_0 = 3.0539e-04
Loss = 8.8986e-05, PNorm = 51.0106, GNorm = 0.2014, lr_0 = 3.0507e-04
Loss = 8.2106e-05, PNorm = 51.0143, GNorm = 0.1620, lr_0 = 3.0475e-04
Loss = 8.2788e-05, PNorm = 51.0154, GNorm = 0.2914, lr_0 = 3.0443e-04
Loss = 1.0203e-04, PNorm = 51.0196, GNorm = 0.2758, lr_0 = 3.0412e-04
Loss = 9.6825e-05, PNorm = 51.0233, GNorm = 0.1797, lr_0 = 3.0380e-04
Loss = 1.0127e-04, PNorm = 51.0256, GNorm = 0.2120, lr_0 = 3.0348e-04
Loss = 8.7034e-05, PNorm = 51.0301, GNorm = 0.2639, lr_0 = 3.0316e-04
Loss = 9.0327e-05, PNorm = 51.0342, GNorm = 0.3629, lr_0 = 3.0285e-04
Loss = 9.6775e-05, PNorm = 51.0364, GNorm = 0.2387, lr_0 = 3.0253e-04
Loss = 1.3092e-04, PNorm = 51.0413, GNorm = 0.2307, lr_0 = 3.0222e-04
Loss = 8.9434e-05, PNorm = 51.0468, GNorm = 0.1581, lr_0 = 3.0190e-04
Loss = 9.5150e-05, PNorm = 51.0514, GNorm = 0.1603, lr_0 = 3.0159e-04
Loss = 8.5400e-05, PNorm = 51.0550, GNorm = 0.1666, lr_0 = 3.0127e-04
Loss = 1.2221e-04, PNorm = 51.0604, GNorm = 0.2067, lr_0 = 3.0096e-04
Loss = 1.1830e-04, PNorm = 51.0646, GNorm = 0.3783, lr_0 = 3.0064e-04
Loss = 9.9232e-05, PNorm = 51.0686, GNorm = 0.1984, lr_0 = 3.0033e-04
Loss = 1.1952e-04, PNorm = 51.0727, GNorm = 0.1807, lr_0 = 3.0001e-04
Validation rmse logD = 0.538840
Validation R2 logD = 0.794503
Validation rmse logP = 0.463959
Validation R2 logP = 0.936992
Epoch 53
Train function
Loss = 8.4848e-05, PNorm = 51.0768, GNorm = 0.1976, lr_0 = 2.9970e-04
Loss = 1.1374e-04, PNorm = 51.0811, GNorm = 0.2735, lr_0 = 2.9939e-04
Loss = 9.0912e-05, PNorm = 51.0838, GNorm = 0.2868, lr_0 = 2.9908e-04
Loss = 9.3272e-05, PNorm = 51.0880, GNorm = 0.1251, lr_0 = 2.9876e-04
Loss = 8.2934e-05, PNorm = 51.0927, GNorm = 0.0986, lr_0 = 2.9845e-04
Loss = 8.1455e-05, PNorm = 51.0959, GNorm = 0.1459, lr_0 = 2.9814e-04
Loss = 7.3975e-05, PNorm = 51.0993, GNorm = 0.2000, lr_0 = 2.9783e-04
Loss = 7.6827e-05, PNorm = 51.1034, GNorm = 0.1398, lr_0 = 2.9752e-04
Loss = 8.4326e-05, PNorm = 51.1073, GNorm = 0.1697, lr_0 = 2.9721e-04
Loss = 7.8416e-05, PNorm = 51.1088, GNorm = 0.2595, lr_0 = 2.9690e-04
Loss = 9.0403e-05, PNorm = 51.1102, GNorm = 0.3547, lr_0 = 2.9659e-04
Loss = 9.6173e-05, PNorm = 51.1136, GNorm = 0.2092, lr_0 = 2.9628e-04
Loss = 9.3356e-05, PNorm = 51.1161, GNorm = 0.2537, lr_0 = 2.9597e-04
Loss = 1.0749e-04, PNorm = 51.1195, GNorm = 0.3774, lr_0 = 2.9566e-04
Loss = 1.1570e-04, PNorm = 51.1229, GNorm = 0.3095, lr_0 = 2.9535e-04
Loss = 9.2403e-05, PNorm = 51.1276, GNorm = 0.2009, lr_0 = 2.9504e-04
Loss = 1.0170e-04, PNorm = 51.1313, GNorm = 0.2761, lr_0 = 2.9474e-04
Loss = 1.3124e-04, PNorm = 51.1373, GNorm = 0.3207, lr_0 = 2.9443e-04
Loss = 1.2158e-04, PNorm = 51.1429, GNorm = 0.3175, lr_0 = 2.9412e-04
Loss = 1.0614e-04, PNorm = 51.1492, GNorm = 0.1914, lr_0 = 2.9381e-04
Loss = 1.1965e-04, PNorm = 51.1578, GNorm = 0.1879, lr_0 = 2.9351e-04
Loss = 9.3125e-05, PNorm = 51.1606, GNorm = 0.2372, lr_0 = 2.9320e-04
Validation rmse logD = 0.531462
Validation R2 logD = 0.800092
Validation rmse logP = 0.467429
Validation R2 logP = 0.936046
Epoch 54
Train function
Loss = 1.1227e-04, PNorm = 51.1631, GNorm = 0.1752, lr_0 = 2.9286e-04
Loss = 8.6651e-05, PNorm = 51.1670, GNorm = 0.1789, lr_0 = 2.9256e-04
Loss = 9.1931e-05, PNorm = 51.1714, GNorm = 0.2145, lr_0 = 2.9225e-04
Loss = 7.9491e-05, PNorm = 51.1739, GNorm = 0.2131, lr_0 = 2.9195e-04
Loss = 7.6514e-05, PNorm = 51.1741, GNorm = 0.1493, lr_0 = 2.9164e-04
Loss = 6.9908e-05, PNorm = 51.1755, GNorm = 0.1524, lr_0 = 2.9134e-04
Loss = 8.8207e-05, PNorm = 51.1771, GNorm = 0.1719, lr_0 = 2.9104e-04
Loss = 8.1051e-05, PNorm = 51.1793, GNorm = 0.1382, lr_0 = 2.9073e-04
Loss = 8.7270e-05, PNorm = 51.1822, GNorm = 0.1202, lr_0 = 2.9043e-04
Loss = 7.2441e-05, PNorm = 51.1848, GNorm = 0.1244, lr_0 = 2.9012e-04
Loss = 8.0510e-05, PNorm = 51.1897, GNorm = 0.2888, lr_0 = 2.8982e-04
Loss = 9.5548e-05, PNorm = 51.1938, GNorm = 0.1734, lr_0 = 2.8952e-04
Loss = 7.6579e-05, PNorm = 51.1957, GNorm = 0.2562, lr_0 = 2.8922e-04
Loss = 8.4567e-05, PNorm = 51.1990, GNorm = 0.4191, lr_0 = 2.8892e-04
Loss = 9.6918e-05, PNorm = 51.2005, GNorm = 0.3226, lr_0 = 2.8861e-04
Loss = 1.1077e-04, PNorm = 51.2036, GNorm = 0.1987, lr_0 = 2.8831e-04
Loss = 1.0786e-04, PNorm = 51.2100, GNorm = 0.2957, lr_0 = 2.8801e-04
Loss = 7.7276e-05, PNorm = 51.2148, GNorm = 0.1835, lr_0 = 2.8771e-04
Loss = 9.6153e-05, PNorm = 51.2169, GNorm = 0.2727, lr_0 = 2.8741e-04
Loss = 9.1168e-05, PNorm = 51.2196, GNorm = 0.1611, lr_0 = 2.8711e-04
Loss = 7.8860e-05, PNorm = 51.2228, GNorm = 0.2554, lr_0 = 2.8681e-04
Loss = 8.9953e-05, PNorm = 51.2264, GNorm = 0.4485, lr_0 = 2.8651e-04
Loss = 1.6009e-04, PNorm = 51.2333, GNorm = 0.5906, lr_0 = 2.8621e-04
Validation rmse logD = 0.533648
Validation R2 logD = 0.798444
Validation rmse logP = 0.460741
Validation R2 logP = 0.937863
Epoch 55
Train function
Loss = 1.6013e-04, PNorm = 51.2399, GNorm = 0.2998, lr_0 = 2.8591e-04
Loss = 1.5869e-04, PNorm = 51.2456, GNorm = 0.6006, lr_0 = 2.8562e-04
Loss = 1.3158e-04, PNorm = 51.2511, GNorm = 0.3205, lr_0 = 2.8532e-04
Loss = 1.1561e-04, PNorm = 51.2560, GNorm = 0.2998, lr_0 = 2.8502e-04
Loss = 9.6365e-05, PNorm = 51.2594, GNorm = 0.2264, lr_0 = 2.8472e-04
Loss = 1.0815e-04, PNorm = 51.2625, GNorm = 0.1948, lr_0 = 2.8443e-04
Loss = 1.0496e-04, PNorm = 51.2664, GNorm = 0.2889, lr_0 = 2.8413e-04
Loss = 8.4143e-05, PNorm = 51.2705, GNorm = 0.2433, lr_0 = 2.8383e-04
Loss = 7.9286e-05, PNorm = 51.2751, GNorm = 0.2239, lr_0 = 2.8354e-04
Loss = 7.8291e-05, PNorm = 51.2785, GNorm = 0.2444, lr_0 = 2.8324e-04
Loss = 6.6929e-05, PNorm = 51.2817, GNorm = 0.1256, lr_0 = 2.8294e-04
Loss = 7.5335e-05, PNorm = 51.2849, GNorm = 0.1771, lr_0 = 2.8265e-04
Loss = 9.7201e-05, PNorm = 51.2882, GNorm = 0.2084, lr_0 = 2.8235e-04
Loss = 8.9206e-05, PNorm = 51.2939, GNorm = 0.2368, lr_0 = 2.8206e-04
Loss = 1.0509e-04, PNorm = 51.2964, GNorm = 0.1098, lr_0 = 2.8176e-04
Loss = 7.4930e-05, PNorm = 51.3024, GNorm = 0.1492, lr_0 = 2.8147e-04
Loss = 9.3579e-05, PNorm = 51.3045, GNorm = 0.1791, lr_0 = 2.8118e-04
Loss = 9.8024e-05, PNorm = 51.3081, GNorm = 0.1753, lr_0 = 2.8088e-04
Loss = 8.1742e-05, PNorm = 51.3121, GNorm = 0.2079, lr_0 = 2.8059e-04
Loss = 9.5454e-05, PNorm = 51.3137, GNorm = 0.1887, lr_0 = 2.8030e-04
Loss = 1.0458e-04, PNorm = 51.3182, GNorm = 0.2236, lr_0 = 2.8000e-04
Loss = 8.8188e-05, PNorm = 51.3221, GNorm = 0.2460, lr_0 = 2.7971e-04
Validation rmse logD = 0.540176
Validation R2 logD = 0.793482
Validation rmse logP = 0.462207
Validation R2 logP = 0.937467
Epoch 56
Train function
Loss = 6.8102e-05, PNorm = 51.3243, GNorm = 0.2439, lr_0 = 2.7939e-04
Loss = 7.4781e-05, PNorm = 51.3275, GNorm = 0.2256, lr_0 = 2.7910e-04
Loss = 7.9956e-05, PNorm = 51.3307, GNorm = 0.1982, lr_0 = 2.7881e-04
Loss = 8.0458e-05, PNorm = 51.3330, GNorm = 0.2072, lr_0 = 2.7852e-04
Loss = 7.1773e-05, PNorm = 51.3355, GNorm = 0.2157, lr_0 = 2.7823e-04
Loss = 9.3008e-05, PNorm = 51.3375, GNorm = 0.1950, lr_0 = 2.7794e-04
Loss = 7.2343e-05, PNorm = 51.3419, GNorm = 0.1597, lr_0 = 2.7765e-04
Loss = 7.4029e-05, PNorm = 51.3441, GNorm = 0.2307, lr_0 = 2.7736e-04
Loss = 6.1994e-05, PNorm = 51.3464, GNorm = 0.1256, lr_0 = 2.7707e-04
Loss = 8.0187e-05, PNorm = 51.3488, GNorm = 0.4293, lr_0 = 2.7678e-04
Loss = 8.0824e-05, PNorm = 51.3508, GNorm = 0.1767, lr_0 = 2.7649e-04
Loss = 8.0627e-05, PNorm = 51.3554, GNorm = 0.1341, lr_0 = 2.7620e-04
Loss = 9.5295e-05, PNorm = 51.3589, GNorm = 0.2201, lr_0 = 2.7591e-04
Loss = 9.5980e-05, PNorm = 51.3625, GNorm = 0.1497, lr_0 = 2.7562e-04
Loss = 1.0100e-04, PNorm = 51.3677, GNorm = 0.2703, lr_0 = 2.7534e-04
Loss = 8.0278e-05, PNorm = 51.3722, GNorm = 0.2199, lr_0 = 2.7505e-04
Loss = 8.1408e-05, PNorm = 51.3744, GNorm = 0.1247, lr_0 = 2.7476e-04
Loss = 1.0916e-04, PNorm = 51.3778, GNorm = 0.3926, lr_0 = 2.7448e-04
Loss = 7.8050e-05, PNorm = 51.3818, GNorm = 0.2425, lr_0 = 2.7419e-04
Loss = 8.7947e-05, PNorm = 51.3857, GNorm = 0.2058, lr_0 = 2.7390e-04
Loss = 8.8680e-05, PNorm = 51.3882, GNorm = 0.3404, lr_0 = 2.7362e-04
Loss = 1.0424e-04, PNorm = 51.3928, GNorm = 0.1977, lr_0 = 2.7333e-04
Loss = 1.0600e-04, PNorm = 51.3976, GNorm = 0.4299, lr_0 = 2.7305e-04
Validation rmse logD = 0.543540
Validation R2 logD = 0.790902
Validation rmse logP = 0.474497
Validation R2 logP = 0.934097
Epoch 57
Train function
Loss = 1.4964e-04, PNorm = 51.4018, GNorm = 0.3109, lr_0 = 2.7276e-04
Loss = 1.4963e-04, PNorm = 51.4082, GNorm = 0.3261, lr_0 = 2.7248e-04
Loss = 9.8815e-05, PNorm = 51.4103, GNorm = 0.1781, lr_0 = 2.7219e-04
Loss = 8.9128e-05, PNorm = 51.4127, GNorm = 0.3062, lr_0 = 2.7191e-04
Loss = 8.1060e-05, PNorm = 51.4153, GNorm = 0.1516, lr_0 = 2.7162e-04
Loss = 8.6230e-05, PNorm = 51.4188, GNorm = 0.1709, lr_0 = 2.7134e-04
Loss = 7.5873e-05, PNorm = 51.4222, GNorm = 0.3192, lr_0 = 2.7106e-04
Loss = 7.5944e-05, PNorm = 51.4242, GNorm = 0.1904, lr_0 = 2.7077e-04
Loss = 6.3555e-05, PNorm = 51.4276, GNorm = 0.1506, lr_0 = 2.7049e-04
Loss = 6.6516e-05, PNorm = 51.4293, GNorm = 0.1997, lr_0 = 2.7021e-04
Loss = 6.6203e-05, PNorm = 51.4302, GNorm = 0.1750, lr_0 = 2.6993e-04
Loss = 1.0070e-04, PNorm = 51.4341, GNorm = 0.3612, lr_0 = 2.6965e-04
Loss = 7.9939e-05, PNorm = 51.4346, GNorm = 0.2638, lr_0 = 2.6936e-04
Loss = 8.2656e-05, PNorm = 51.4389, GNorm = 0.1866, lr_0 = 2.6908e-04
Loss = 9.1754e-05, PNorm = 51.4426, GNorm = 0.1747, lr_0 = 2.6880e-04
Loss = 7.5911e-05, PNorm = 51.4448, GNorm = 0.3081, lr_0 = 2.6852e-04
Loss = 8.0527e-05, PNorm = 51.4505, GNorm = 0.1223, lr_0 = 2.6824e-04
Loss = 7.1978e-05, PNorm = 51.4545, GNorm = 0.1359, lr_0 = 2.6796e-04
Loss = 6.9065e-05, PNorm = 51.4561, GNorm = 0.1524, lr_0 = 2.6768e-04
Loss = 8.0580e-05, PNorm = 51.4589, GNorm = 0.1405, lr_0 = 2.6740e-04
Loss = 7.0938e-05, PNorm = 51.4619, GNorm = 0.1348, lr_0 = 2.6712e-04
Loss = 8.3626e-05, PNorm = 51.4639, GNorm = 0.2166, lr_0 = 2.6684e-04
Validation rmse logD = 0.534471
Validation R2 logD = 0.797821
Validation rmse logP = 0.464693
Validation R2 logP = 0.936792
Epoch 58
Train function
Loss = 5.4249e-05, PNorm = 51.4666, GNorm = 0.1639, lr_0 = 2.6654e-04
Loss = 6.1531e-05, PNorm = 51.4690, GNorm = 0.1886, lr_0 = 2.6626e-04
Loss = 7.3686e-05, PNorm = 51.4692, GNorm = 0.2966, lr_0 = 2.6598e-04
Loss = 5.9241e-05, PNorm = 51.4711, GNorm = 0.1570, lr_0 = 2.6570e-04
Loss = 5.0846e-05, PNorm = 51.4737, GNorm = 0.2358, lr_0 = 2.6543e-04
Loss = 7.3692e-05, PNorm = 51.4757, GNorm = 0.1667, lr_0 = 2.6515e-04
Loss = 6.5114e-05, PNorm = 51.4779, GNorm = 0.1919, lr_0 = 2.6487e-04
Loss = 6.9964e-05, PNorm = 51.4802, GNorm = 0.1695, lr_0 = 2.6460e-04
Loss = 6.5166e-05, PNorm = 51.4817, GNorm = 0.2955, lr_0 = 2.6432e-04
Loss = 5.9907e-05, PNorm = 51.4822, GNorm = 0.1799, lr_0 = 2.6405e-04
Loss = 6.8296e-05, PNorm = 51.4826, GNorm = 0.2512, lr_0 = 2.6377e-04
Loss = 8.6703e-05, PNorm = 51.4867, GNorm = 0.4014, lr_0 = 2.6349e-04
Loss = 6.8943e-05, PNorm = 51.4886, GNorm = 0.1960, lr_0 = 2.6322e-04
Loss = 6.1727e-05, PNorm = 51.4919, GNorm = 0.1771, lr_0 = 2.6294e-04
Loss = 7.6285e-05, PNorm = 51.4947, GNorm = 0.2112, lr_0 = 2.6267e-04
Loss = 6.3568e-05, PNorm = 51.4976, GNorm = 0.1397, lr_0 = 2.6240e-04
Loss = 5.9168e-05, PNorm = 51.5009, GNorm = 0.1377, lr_0 = 2.6212e-04
Loss = 9.3605e-05, PNorm = 51.5033, GNorm = 0.1849, lr_0 = 2.6185e-04
Loss = 7.2814e-05, PNorm = 51.5060, GNorm = 0.1008, lr_0 = 2.6158e-04
Loss = 1.0450e-04, PNorm = 51.5081, GNorm = 0.1651, lr_0 = 2.6130e-04
Loss = 6.6151e-05, PNorm = 51.5122, GNorm = 0.1094, lr_0 = 2.6103e-04
Loss = 6.6226e-05, PNorm = 51.5157, GNorm = 0.1836, lr_0 = 2.6076e-04
Loss = 6.5701e-05, PNorm = 51.5198, GNorm = 0.1386, lr_0 = 2.6048e-04
Validation rmse logD = 0.536026
Validation R2 logD = 0.796643
Validation rmse logP = 0.467005
Validation R2 logP = 0.936162
Epoch 59
Train function
Loss = 5.3438e-05, PNorm = 51.5223, GNorm = 0.2155, lr_0 = 2.6021e-04
Loss = 5.4785e-05, PNorm = 51.5243, GNorm = 0.1339, lr_0 = 2.5994e-04
Loss = 5.3137e-05, PNorm = 51.5282, GNorm = 0.1264, lr_0 = 2.5967e-04
Loss = 5.7079e-05, PNorm = 51.5316, GNorm = 0.1376, lr_0 = 2.5940e-04
Loss = 5.4700e-05, PNorm = 51.5346, GNorm = 0.1752, lr_0 = 2.5913e-04
Loss = 6.3005e-05, PNorm = 51.5364, GNorm = 0.1073, lr_0 = 2.5886e-04
Loss = 5.3619e-05, PNorm = 51.5394, GNorm = 0.2542, lr_0 = 2.5859e-04
Loss = 5.4780e-05, PNorm = 51.5416, GNorm = 0.2173, lr_0 = 2.5832e-04
Loss = 5.6888e-05, PNorm = 51.5436, GNorm = 0.2469, lr_0 = 2.5805e-04
Loss = 5.4984e-05, PNorm = 51.5466, GNorm = 0.2345, lr_0 = 2.5778e-04
Loss = 5.8510e-05, PNorm = 51.5497, GNorm = 0.1454, lr_0 = 2.5751e-04
Loss = 6.1320e-05, PNorm = 51.5533, GNorm = 0.2738, lr_0 = 2.5724e-04
Loss = 9.1000e-05, PNorm = 51.5575, GNorm = 0.3026, lr_0 = 2.5697e-04
Loss = 7.7890e-05, PNorm = 51.5612, GNorm = 0.1949, lr_0 = 2.5670e-04
Loss = 6.7498e-05, PNorm = 51.5644, GNorm = 0.1415, lr_0 = 2.5644e-04
Loss = 6.3868e-05, PNorm = 51.5674, GNorm = 0.2401, lr_0 = 2.5617e-04
Loss = 6.9550e-05, PNorm = 51.5693, GNorm = 0.1665, lr_0 = 2.5590e-04
Loss = 6.8209e-05, PNorm = 51.5730, GNorm = 0.1807, lr_0 = 2.5563e-04
Loss = 7.1702e-05, PNorm = 51.5765, GNorm = 0.1844, lr_0 = 2.5537e-04
Loss = 7.9898e-05, PNorm = 51.5780, GNorm = 0.1675, lr_0 = 2.5510e-04
Loss = 7.9599e-05, PNorm = 51.5792, GNorm = 0.1924, lr_0 = 2.5483e-04
Loss = 6.7160e-05, PNorm = 51.5826, GNorm = 0.1976, lr_0 = 2.5457e-04
Validation rmse logD = 0.536107
Validation R2 logD = 0.796581
Validation rmse logP = 0.465683
Validation R2 logP = 0.936523
Epoch 60
Train function
Loss = 8.1168e-05, PNorm = 51.5858, GNorm = 0.2743, lr_0 = 2.5428e-04
Loss = 6.9721e-05, PNorm = 51.5896, GNorm = 0.1775, lr_0 = 2.5401e-04
Loss = 7.7883e-05, PNorm = 51.5922, GNorm = 0.1900, lr_0 = 2.5375e-04
Loss = 7.5401e-05, PNorm = 51.5969, GNorm = 0.2534, lr_0 = 2.5348e-04
Loss = 6.5177e-05, PNorm = 51.5995, GNorm = 0.2106, lr_0 = 2.5322e-04
Loss = 7.9770e-05, PNorm = 51.6019, GNorm = 0.1742, lr_0 = 2.5295e-04
Loss = 5.8201e-05, PNorm = 51.6029, GNorm = 0.2519, lr_0 = 2.5269e-04
Loss = 6.7736e-05, PNorm = 51.6047, GNorm = 0.1782, lr_0 = 2.5242e-04
Loss = 6.4215e-05, PNorm = 51.6076, GNorm = 0.1912, lr_0 = 2.5216e-04
Loss = 6.1121e-05, PNorm = 51.6102, GNorm = 0.1603, lr_0 = 2.5190e-04
Loss = 6.8491e-05, PNorm = 51.6132, GNorm = 0.2428, lr_0 = 2.5163e-04
Loss = 6.3683e-05, PNorm = 51.6167, GNorm = 0.1014, lr_0 = 2.5137e-04
Loss = 5.9419e-05, PNorm = 51.6201, GNorm = 0.2115, lr_0 = 2.5111e-04
Loss = 5.7760e-05, PNorm = 51.6214, GNorm = 0.2219, lr_0 = 2.5085e-04
Loss = 6.2774e-05, PNorm = 51.6245, GNorm = 0.1499, lr_0 = 2.5059e-04
Loss = 5.8217e-05, PNorm = 51.6276, GNorm = 0.1519, lr_0 = 2.5032e-04
Loss = 4.6508e-05, PNorm = 51.6297, GNorm = 0.1163, lr_0 = 2.5006e-04
Loss = 6.0505e-05, PNorm = 51.6335, GNorm = 0.2035, lr_0 = 2.4980e-04
Loss = 5.7511e-05, PNorm = 51.6358, GNorm = 0.1526, lr_0 = 2.4954e-04
Loss = 6.9813e-05, PNorm = 51.6389, GNorm = 0.1874, lr_0 = 2.4928e-04
Loss = 8.1184e-05, PNorm = 51.6430, GNorm = 0.1523, lr_0 = 2.4902e-04
Loss = 7.1168e-05, PNorm = 51.6458, GNorm = 0.3036, lr_0 = 2.4876e-04
Loss = 9.3136e-05, PNorm = 51.6507, GNorm = 0.2464, lr_0 = 2.4850e-04
Validation rmse logD = 0.536321
Validation R2 logD = 0.796419
Validation rmse logP = 0.469964
Validation R2 logP = 0.935350
Epoch 61
Train function
Loss = 9.3393e-05, PNorm = 51.6556, GNorm = 0.3810, lr_0 = 2.4824e-04
Loss = 7.4977e-05, PNorm = 51.6588, GNorm = 0.2323, lr_0 = 2.4798e-04
Loss = 7.8565e-05, PNorm = 51.6600, GNorm = 0.2068, lr_0 = 2.4772e-04
Loss = 8.8443e-05, PNorm = 51.6644, GNorm = 0.1864, lr_0 = 2.4747e-04
Loss = 6.4779e-05, PNorm = 51.6699, GNorm = 0.1544, lr_0 = 2.4721e-04
Loss = 6.6348e-05, PNorm = 51.6736, GNorm = 0.1603, lr_0 = 2.4695e-04
Loss = 6.0651e-05, PNorm = 51.6756, GNorm = 0.1371, lr_0 = 2.4669e-04
Loss = 4.9490e-05, PNorm = 51.6779, GNorm = 0.1921, lr_0 = 2.4643e-04
Loss = 5.1342e-05, PNorm = 51.6774, GNorm = 0.2084, lr_0 = 2.4618e-04
Loss = 5.0246e-05, PNorm = 51.6783, GNorm = 0.2664, lr_0 = 2.4592e-04
Loss = 5.7150e-05, PNorm = 51.6813, GNorm = 0.1798, lr_0 = 2.4566e-04
Loss = 5.8809e-05, PNorm = 51.6841, GNorm = 0.2031, lr_0 = 2.4541e-04
Loss = 5.4802e-05, PNorm = 51.6884, GNorm = 0.1047, lr_0 = 2.4515e-04
Loss = 7.2133e-05, PNorm = 51.6886, GNorm = 0.2867, lr_0 = 2.4489e-04
Loss = 6.0923e-05, PNorm = 51.6913, GNorm = 0.1905, lr_0 = 2.4464e-04
Loss = 5.7232e-05, PNorm = 51.6917, GNorm = 0.1390, lr_0 = 2.4438e-04
Loss = 5.6488e-05, PNorm = 51.6924, GNorm = 0.2054, lr_0 = 2.4413e-04
Loss = 6.8977e-05, PNorm = 51.6956, GNorm = 0.1202, lr_0 = 2.4387e-04
Loss = 5.6082e-05, PNorm = 51.6984, GNorm = 0.2362, lr_0 = 2.4362e-04
Loss = 7.2579e-05, PNorm = 51.7011, GNorm = 0.1898, lr_0 = 2.4337e-04
Loss = 6.9168e-05, PNorm = 51.7052, GNorm = 0.3496, lr_0 = 2.4311e-04
Loss = 7.6252e-05, PNorm = 51.7091, GNorm = 0.2711, lr_0 = 2.4286e-04
Validation rmse logD = 0.538037
Validation R2 logD = 0.795115
Validation rmse logP = 0.463985
Validation R2 logP = 0.936985
Epoch 62
Train function
Loss = 4.5508e-05, PNorm = 51.7105, GNorm = 0.1227, lr_0 = 2.4258e-04
Loss = 4.4398e-05, PNorm = 51.7116, GNorm = 0.1571, lr_0 = 2.4233e-04
Loss = 5.9397e-05, PNorm = 51.7131, GNorm = 0.1568, lr_0 = 2.4207e-04
Loss = 5.2054e-05, PNorm = 51.7158, GNorm = 0.1923, lr_0 = 2.4182e-04
Loss = 6.1817e-05, PNorm = 51.7191, GNorm = 0.1564, lr_0 = 2.4157e-04
Loss = 4.8700e-05, PNorm = 51.7194, GNorm = 0.2229, lr_0 = 2.4132e-04
Loss = 4.6663e-05, PNorm = 51.7217, GNorm = 0.1530, lr_0 = 2.4106e-04
Loss = 5.3583e-05, PNorm = 51.7252, GNorm = 0.1504, lr_0 = 2.4081e-04
Loss = 6.2320e-05, PNorm = 51.7269, GNorm = 0.2071, lr_0 = 2.4056e-04
Loss = 4.8788e-05, PNorm = 51.7293, GNorm = 0.1164, lr_0 = 2.4031e-04
Loss = 5.3862e-05, PNorm = 51.7321, GNorm = 0.1435, lr_0 = 2.4006e-04
Loss = 5.6973e-05, PNorm = 51.7348, GNorm = 0.2777, lr_0 = 2.3981e-04
Loss = 4.4465e-05, PNorm = 51.7374, GNorm = 0.1465, lr_0 = 2.3956e-04
Loss = 6.9153e-05, PNorm = 51.7380, GNorm = 0.1724, lr_0 = 2.3931e-04
Loss = 7.2461e-05, PNorm = 51.7414, GNorm = 0.3260, lr_0 = 2.3906e-04
Loss = 7.9643e-05, PNorm = 51.7462, GNorm = 0.2641, lr_0 = 2.3881e-04
Loss = 7.6340e-05, PNorm = 51.7489, GNorm = 0.1526, lr_0 = 2.3856e-04
Loss = 6.8445e-05, PNorm = 51.7526, GNorm = 0.1620, lr_0 = 2.3831e-04
Loss = 6.2526e-05, PNorm = 51.7549, GNorm = 0.1144, lr_0 = 2.3806e-04
Loss = 5.6239e-05, PNorm = 51.7577, GNorm = 0.1808, lr_0 = 2.3781e-04
Loss = 6.8738e-05, PNorm = 51.7585, GNorm = 0.1696, lr_0 = 2.3756e-04
Loss = 6.6296e-05, PNorm = 51.7600, GNorm = 0.2194, lr_0 = 2.3732e-04
Loss = 7.1635e-05, PNorm = 51.7630, GNorm = 0.2300, lr_0 = 2.3707e-04
Validation rmse logD = 0.534094
Validation R2 logD = 0.798107
Validation rmse logP = 0.472703
Validation R2 logP = 0.934594
Epoch 63
Train function
Loss = 7.2762e-05, PNorm = 51.7649, GNorm = 0.4034, lr_0 = 2.3682e-04
Loss = 6.7169e-05, PNorm = 51.7652, GNorm = 0.1886, lr_0 = 2.3657e-04
Loss = 8.4378e-05, PNorm = 51.7678, GNorm = 0.4215, lr_0 = 2.3633e-04
Loss = 9.3150e-05, PNorm = 51.7708, GNorm = 0.2174, lr_0 = 2.3608e-04
Loss = 8.1684e-05, PNorm = 51.7745, GNorm = 0.1816, lr_0 = 2.3583e-04
Loss = 7.1585e-05, PNorm = 51.7799, GNorm = 0.2856, lr_0 = 2.3559e-04
Loss = 6.1745e-05, PNorm = 51.7825, GNorm = 0.2163, lr_0 = 2.3534e-04
Loss = 5.4665e-05, PNorm = 51.7853, GNorm = 0.1203, lr_0 = 2.3510e-04
Loss = 6.5398e-05, PNorm = 51.7884, GNorm = 0.1128, lr_0 = 2.3485e-04
Loss = 6.2968e-05, PNorm = 51.7910, GNorm = 0.3311, lr_0 = 2.3461e-04
Loss = 8.8729e-05, PNorm = 51.7940, GNorm = 0.2092, lr_0 = 2.3436e-04
Loss = 7.6714e-05, PNorm = 51.7993, GNorm = 0.2597, lr_0 = 2.3412e-04
Loss = 6.4056e-05, PNorm = 51.8017, GNorm = 0.1058, lr_0 = 2.3387e-04
Loss = 8.3031e-05, PNorm = 51.8044, GNorm = 0.3356, lr_0 = 2.3363e-04
Loss = 6.2194e-05, PNorm = 51.8068, GNorm = 0.3326, lr_0 = 2.3338e-04
Loss = 5.9340e-05, PNorm = 51.8094, GNorm = 0.1573, lr_0 = 2.3314e-04
Loss = 7.4912e-05, PNorm = 51.8118, GNorm = 0.2130, lr_0 = 2.3290e-04
Loss = 6.7042e-05, PNorm = 51.8142, GNorm = 0.1740, lr_0 = 2.3265e-04
Loss = 5.2805e-05, PNorm = 51.8169, GNorm = 0.1467, lr_0 = 2.3241e-04
Loss = 8.1650e-05, PNorm = 51.8180, GNorm = 0.4051, lr_0 = 2.3217e-04
Loss = 6.4371e-05, PNorm = 51.8217, GNorm = 0.1088, lr_0 = 2.3193e-04
Loss = 5.6769e-05, PNorm = 51.8230, GNorm = 0.1994, lr_0 = 2.3169e-04
Loss = 5.5236e-05, PNorm = 51.8252, GNorm = 0.1922, lr_0 = 2.3144e-04
Loss = 1.3303e-04, PNorm = 51.8256, GNorm = 0.2973, lr_0 = 2.3142e-04
Validation rmse logD = 0.535168
Validation R2 logD = 0.797294
Validation rmse logP = 0.467896
Validation R2 logP = 0.935918
Epoch 64
Train function
Loss = 5.6877e-05, PNorm = 51.8270, GNorm = 0.1172, lr_0 = 2.3118e-04
Loss = 6.6175e-05, PNorm = 51.8299, GNorm = 0.3253, lr_0 = 2.3094e-04
Loss = 5.9719e-05, PNorm = 51.8321, GNorm = 0.1342, lr_0 = 2.3070e-04
Loss = 5.8657e-05, PNorm = 51.8344, GNorm = 0.0948, lr_0 = 2.3045e-04
Loss = 6.5671e-05, PNorm = 51.8367, GNorm = 0.2492, lr_0 = 2.3021e-04
Loss = 5.5511e-05, PNorm = 51.8397, GNorm = 0.2113, lr_0 = 2.2997e-04
Loss = 6.5312e-05, PNorm = 51.8424, GNorm = 0.2089, lr_0 = 2.2973e-04
Loss = 6.0726e-05, PNorm = 51.8448, GNorm = 0.2307, lr_0 = 2.2949e-04
Loss = 5.7623e-05, PNorm = 51.8472, GNorm = 0.2297, lr_0 = 2.2925e-04
Loss = 6.6306e-05, PNorm = 51.8515, GNorm = 0.1199, lr_0 = 2.2902e-04
Loss = 4.8982e-05, PNorm = 51.8543, GNorm = 0.1457, lr_0 = 2.2878e-04
Loss = 4.8740e-05, PNorm = 51.8568, GNorm = 0.1056, lr_0 = 2.2854e-04
Loss = 5.3854e-05, PNorm = 51.8583, GNorm = 0.1447, lr_0 = 2.2830e-04
Loss = 4.9265e-05, PNorm = 51.8593, GNorm = 0.1809, lr_0 = 2.2806e-04
Loss = 5.7465e-05, PNorm = 51.8598, GNorm = 0.1510, lr_0 = 2.2782e-04
Loss = 5.2490e-05, PNorm = 51.8611, GNorm = 0.2447, lr_0 = 2.2758e-04
Loss = 4.7889e-05, PNorm = 51.8640, GNorm = 0.1177, lr_0 = 2.2735e-04
Loss = 5.0753e-05, PNorm = 51.8667, GNorm = 0.1641, lr_0 = 2.2711e-04
Loss = 5.7495e-05, PNorm = 51.8688, GNorm = 0.1728, lr_0 = 2.2687e-04
Loss = 6.1322e-05, PNorm = 51.8700, GNorm = 0.1529, lr_0 = 2.2664e-04
Loss = 5.8730e-05, PNorm = 51.8708, GNorm = 0.1869, lr_0 = 2.2640e-04
Loss = 6.4597e-05, PNorm = 51.8726, GNorm = 0.3130, lr_0 = 2.2616e-04
Validation rmse logD = 0.535548
Validation R2 logD = 0.797005
Validation rmse logP = 0.465431
Validation R2 logP = 0.936591
Epoch 65
Train function
Loss = 6.1158e-05, PNorm = 51.8746, GNorm = 0.1815, lr_0 = 2.2593e-04
Loss = 6.6352e-05, PNorm = 51.8771, GNorm = 0.1293, lr_0 = 2.2569e-04
Loss = 5.8088e-05, PNorm = 51.8811, GNorm = 0.1235, lr_0 = 2.2546e-04
Loss = 5.3465e-05, PNorm = 51.8852, GNorm = 0.1631, lr_0 = 2.2522e-04
Loss = 6.9225e-05, PNorm = 51.8865, GNorm = 0.2918, lr_0 = 2.2499e-04
Loss = 6.8448e-05, PNorm = 51.8876, GNorm = 0.2994, lr_0 = 2.2475e-04
Loss = 6.6238e-05, PNorm = 51.8906, GNorm = 0.1942, lr_0 = 2.2452e-04
Loss = 4.9017e-05, PNorm = 51.8943, GNorm = 0.1525, lr_0 = 2.2428e-04
Loss = 5.1332e-05, PNorm = 51.8963, GNorm = 0.1763, lr_0 = 2.2405e-04
Loss = 5.5343e-05, PNorm = 51.8983, GNorm = 0.1894, lr_0 = 2.2381e-04
Loss = 7.6619e-05, PNorm = 51.8997, GNorm = 0.1734, lr_0 = 2.2358e-04
Loss = 5.6997e-05, PNorm = 51.8999, GNorm = 0.2194, lr_0 = 2.2335e-04
Loss = 5.9917e-05, PNorm = 51.9029, GNorm = 0.2399, lr_0 = 2.2311e-04
Loss = 5.7747e-05, PNorm = 51.9049, GNorm = 0.1192, lr_0 = 2.2288e-04
Loss = 6.6679e-05, PNorm = 51.9070, GNorm = 0.2750, lr_0 = 2.2265e-04
Loss = 6.1129e-05, PNorm = 51.9105, GNorm = 0.2084, lr_0 = 2.2242e-04
Loss = 6.0762e-05, PNorm = 51.9140, GNorm = 0.1689, lr_0 = 2.2218e-04
Loss = 4.5394e-05, PNorm = 51.9149, GNorm = 0.1735, lr_0 = 2.2195e-04
Loss = 5.0115e-05, PNorm = 51.9177, GNorm = 0.1879, lr_0 = 2.2172e-04
Loss = 4.4974e-05, PNorm = 51.9191, GNorm = 0.1866, lr_0 = 2.2149e-04
Loss = 4.9872e-05, PNorm = 51.9202, GNorm = 0.1418, lr_0 = 2.2126e-04
Loss = 5.2419e-05, PNorm = 51.9223, GNorm = 0.1949, lr_0 = 2.2103e-04
Loss = 3.9306e-05, PNorm = 51.9236, GNorm = 0.1328, lr_0 = 2.2080e-04
Validation rmse logD = 0.537867
Validation R2 logD = 0.795244
Validation rmse logP = 0.464504
Validation R2 logP = 0.936843
Epoch 66
Train function
Loss = 4.1243e-05, PNorm = 51.9261, GNorm = 0.1430, lr_0 = 2.2054e-04
Loss = 5.0751e-05, PNorm = 51.9279, GNorm = 0.1338, lr_0 = 2.2031e-04
Loss = 3.9912e-05, PNorm = 51.9297, GNorm = 0.2302, lr_0 = 2.2008e-04
Loss = 5.7581e-05, PNorm = 51.9308, GNorm = 0.3743, lr_0 = 2.1985e-04
Loss = 5.9719e-05, PNorm = 51.9343, GNorm = 0.1015, lr_0 = 2.1962e-04
Loss = 6.0606e-05, PNorm = 51.9379, GNorm = 0.1822, lr_0 = 2.1939e-04
Loss = 4.6268e-05, PNorm = 51.9401, GNorm = 0.1337, lr_0 = 2.1916e-04
Loss = 5.2108e-05, PNorm = 51.9420, GNorm = 0.1245, lr_0 = 2.1894e-04
Loss = 4.8098e-05, PNorm = 51.9448, GNorm = 0.1135, lr_0 = 2.1871e-04
Loss = 4.5701e-05, PNorm = 51.9469, GNorm = 0.1620, lr_0 = 2.1848e-04
Loss = 4.3407e-05, PNorm = 51.9485, GNorm = 0.0802, lr_0 = 2.1825e-04
Loss = 4.0178e-05, PNorm = 51.9498, GNorm = 0.1326, lr_0 = 2.1802e-04
Loss = 4.5527e-05, PNorm = 51.9488, GNorm = 0.1563, lr_0 = 2.1780e-04
Loss = 4.5059e-05, PNorm = 51.9501, GNorm = 0.1983, lr_0 = 2.1757e-04
Loss = 5.9174e-05, PNorm = 51.9519, GNorm = 0.1338, lr_0 = 2.1734e-04
Loss = 5.9666e-05, PNorm = 51.9544, GNorm = 0.2197, lr_0 = 2.1711e-04
Loss = 4.8239e-05, PNorm = 51.9575, GNorm = 0.1612, lr_0 = 2.1689e-04
Loss = 4.2977e-05, PNorm = 51.9606, GNorm = 0.3000, lr_0 = 2.1666e-04
Loss = 4.8263e-05, PNorm = 51.9621, GNorm = 0.1275, lr_0 = 2.1644e-04
Loss = 4.2236e-05, PNorm = 51.9625, GNorm = 0.1222, lr_0 = 2.1621e-04
Loss = 3.5393e-05, PNorm = 51.9644, GNorm = 0.0884, lr_0 = 2.1598e-04
Loss = 4.1504e-05, PNorm = 51.9662, GNorm = 0.1313, lr_0 = 2.1576e-04
Validation rmse logD = 0.536131
Validation R2 logD = 0.796563
Validation rmse logP = 0.465312
Validation R2 logP = 0.936624
Epoch 67
Train function
Loss = 3.6432e-05, PNorm = 51.9678, GNorm = 0.2281, lr_0 = 2.1553e-04
Loss = 4.3480e-05, PNorm = 51.9708, GNorm = 0.0871, lr_0 = 2.1531e-04
Loss = 4.4431e-05, PNorm = 51.9729, GNorm = 0.1206, lr_0 = 2.1508e-04
Loss = 4.0148e-05, PNorm = 51.9744, GNorm = 0.1050, lr_0 = 2.1486e-04
Loss = 5.0143e-05, PNorm = 51.9762, GNorm = 0.2036, lr_0 = 2.1464e-04
Loss = 4.7283e-05, PNorm = 51.9772, GNorm = 0.2403, lr_0 = 2.1441e-04
Loss = 5.0031e-05, PNorm = 51.9779, GNorm = 0.1244, lr_0 = 2.1419e-04
Loss = 4.9322e-05, PNorm = 51.9800, GNorm = 0.2167, lr_0 = 2.1396e-04
Loss = 5.7174e-05, PNorm = 51.9816, GNorm = 0.1484, lr_0 = 2.1374e-04
Loss = 4.9896e-05, PNorm = 51.9849, GNorm = 0.1985, lr_0 = 2.1352e-04
Loss = 4.3969e-05, PNorm = 51.9871, GNorm = 0.0807, lr_0 = 2.1329e-04
Loss = 3.5801e-05, PNorm = 51.9892, GNorm = 0.0893, lr_0 = 2.1307e-04
Loss = 4.0706e-05, PNorm = 51.9919, GNorm = 0.1277, lr_0 = 2.1285e-04
Loss = 3.8769e-05, PNorm = 51.9932, GNorm = 0.1136, lr_0 = 2.1263e-04
Loss = 4.5315e-05, PNorm = 51.9948, GNorm = 0.1171, lr_0 = 2.1241e-04
Loss = 4.6154e-05, PNorm = 51.9987, GNorm = 0.2226, lr_0 = 2.1218e-04
Loss = 4.5873e-05, PNorm = 52.0006, GNorm = 0.1397, lr_0 = 2.1196e-04
Loss = 5.3144e-05, PNorm = 52.0022, GNorm = 0.1380, lr_0 = 2.1174e-04
Loss = 6.5923e-05, PNorm = 52.0051, GNorm = 0.2851, lr_0 = 2.1152e-04
Loss = 5.1688e-05, PNorm = 52.0065, GNorm = 0.1366, lr_0 = 2.1130e-04
Loss = 4.6538e-05, PNorm = 52.0090, GNorm = 0.1337, lr_0 = 2.1108e-04
Loss = 5.9277e-05, PNorm = 52.0114, GNorm = 0.1020, lr_0 = 2.1086e-04
Loss = 4.5648e-05, PNorm = 52.0125, GNorm = 0.1886, lr_0 = 2.1064e-04
Validation rmse logD = 0.536480
Validation R2 logD = 0.796299
Validation rmse logP = 0.466624
Validation R2 logP = 0.936266
Epoch 68
Train function
Loss = 6.0453e-05, PNorm = 52.0152, GNorm = 0.1312, lr_0 = 2.1040e-04
Loss = 4.7139e-05, PNorm = 52.0177, GNorm = 0.1159, lr_0 = 2.1018e-04
Loss = 6.1164e-05, PNorm = 52.0204, GNorm = 0.1869, lr_0 = 2.0996e-04
Loss = 6.3094e-05, PNorm = 52.0224, GNorm = 0.2329, lr_0 = 2.0974e-04
Loss = 5.0786e-05, PNorm = 52.0237, GNorm = 0.1320, lr_0 = 2.0952e-04
Loss = 4.3620e-05, PNorm = 52.0259, GNorm = 0.1683, lr_0 = 2.0930e-04
Loss = 4.6092e-05, PNorm = 52.0269, GNorm = 0.1090, lr_0 = 2.0908e-04
Loss = 5.2546e-05, PNorm = 52.0276, GNorm = 0.1241, lr_0 = 2.0886e-04
Loss = 5.4760e-05, PNorm = 52.0299, GNorm = 0.2394, lr_0 = 2.0865e-04
Loss = 4.0083e-05, PNorm = 52.0325, GNorm = 0.1623, lr_0 = 2.0843e-04
Loss = 3.5716e-05, PNorm = 52.0336, GNorm = 0.1304, lr_0 = 2.0821e-04
Loss = 4.5147e-05, PNorm = 52.0361, GNorm = 0.1180, lr_0 = 2.0799e-04
Loss = 4.7387e-05, PNorm = 52.0383, GNorm = 0.1228, lr_0 = 2.0778e-04
Loss = 5.0296e-05, PNorm = 52.0410, GNorm = 0.1671, lr_0 = 2.0756e-04
Loss = 5.1135e-05, PNorm = 52.0426, GNorm = 0.2026, lr_0 = 2.0734e-04
Loss = 4.2785e-05, PNorm = 52.0440, GNorm = 0.2000, lr_0 = 2.0713e-04
Loss = 4.5467e-05, PNorm = 52.0465, GNorm = 0.1791, lr_0 = 2.0691e-04
Loss = 5.4827e-05, PNorm = 52.0494, GNorm = 0.1645, lr_0 = 2.0669e-04
Loss = 4.9050e-05, PNorm = 52.0516, GNorm = 0.1749, lr_0 = 2.0648e-04
Loss = 4.4927e-05, PNorm = 52.0530, GNorm = 0.1468, lr_0 = 2.0626e-04
Loss = 4.7005e-05, PNorm = 52.0544, GNorm = 0.1723, lr_0 = 2.0605e-04
Loss = 3.5241e-05, PNorm = 52.0546, GNorm = 0.1517, lr_0 = 2.0583e-04
Validation rmse logD = 0.536609
Validation R2 logD = 0.796201
Validation rmse logP = 0.462518
Validation R2 logP = 0.937383
Epoch 69
Train function
Loss = 2.2293e-05, PNorm = 52.0554, GNorm = 0.1493, lr_0 = 2.0562e-04
Loss = 3.2127e-05, PNorm = 52.0570, GNorm = 0.1059, lr_0 = 2.0540e-04
Loss = 4.0482e-05, PNorm = 52.0585, GNorm = 0.1193, lr_0 = 2.0519e-04
Loss = 3.6095e-05, PNorm = 52.0601, GNorm = 0.1650, lr_0 = 2.0497e-04
Loss = 4.5283e-05, PNorm = 52.0626, GNorm = 0.1578, lr_0 = 2.0476e-04
Loss = 3.8438e-05, PNorm = 52.0632, GNorm = 0.2695, lr_0 = 2.0455e-04
Loss = 4.1320e-05, PNorm = 52.0645, GNorm = 0.1714, lr_0 = 2.0433e-04
Loss = 4.8695e-05, PNorm = 52.0666, GNorm = 0.1265, lr_0 = 2.0412e-04
Loss = 3.8062e-05, PNorm = 52.0687, GNorm = 0.1627, lr_0 = 2.0391e-04
Loss = 4.3261e-05, PNorm = 52.0707, GNorm = 0.2542, lr_0 = 2.0369e-04
Loss = 4.4555e-05, PNorm = 52.0734, GNorm = 0.1313, lr_0 = 2.0348e-04
Loss = 4.9659e-05, PNorm = 52.0753, GNorm = 0.2677, lr_0 = 2.0327e-04
Loss = 5.1172e-05, PNorm = 52.0788, GNorm = 0.1325, lr_0 = 2.0306e-04
Loss = 4.6715e-05, PNorm = 52.0818, GNorm = 0.1448, lr_0 = 2.0285e-04
Loss = 4.7772e-05, PNorm = 52.0834, GNorm = 0.1006, lr_0 = 2.0263e-04
Loss = 5.4146e-05, PNorm = 52.0855, GNorm = 0.1940, lr_0 = 2.0242e-04
Loss = 4.1931e-05, PNorm = 52.0875, GNorm = 0.2749, lr_0 = 2.0221e-04
Loss = 3.5182e-05, PNorm = 52.0889, GNorm = 0.1733, lr_0 = 2.0200e-04
Loss = 4.3198e-05, PNorm = 52.0901, GNorm = 0.2032, lr_0 = 2.0179e-04
Loss = 4.6443e-05, PNorm = 52.0912, GNorm = 0.0958, lr_0 = 2.0158e-04
Loss = 4.6823e-05, PNorm = 52.0917, GNorm = 0.2244, lr_0 = 2.0137e-04
Loss = 4.9601e-05, PNorm = 52.0937, GNorm = 0.1022, lr_0 = 2.0116e-04
Loss = 4.8149e-05, PNorm = 52.0950, GNorm = 0.1235, lr_0 = 2.0095e-04
Validation rmse logD = 0.541752
Validation R2 logD = 0.792276
Validation rmse logP = 0.462703
Validation R2 logP = 0.937332
Epoch 70
Train function
Loss = 3.8524e-05, PNorm = 52.0978, GNorm = 0.0974, lr_0 = 2.0072e-04
Loss = 3.2489e-05, PNorm = 52.0990, GNorm = 0.2546, lr_0 = 2.0051e-04
Loss = 3.9302e-05, PNorm = 52.1009, GNorm = 0.1135, lr_0 = 2.0030e-04
Loss = 3.5999e-05, PNorm = 52.1031, GNorm = 0.1328, lr_0 = 2.0009e-04
Loss = 4.8608e-05, PNorm = 52.1053, GNorm = 0.1287, lr_0 = 1.9988e-04
Loss = 3.4858e-05, PNorm = 52.1060, GNorm = 0.0975, lr_0 = 1.9967e-04
Loss = 3.9659e-05, PNorm = 52.1081, GNorm = 0.1128, lr_0 = 1.9946e-04
Loss = 3.4578e-05, PNorm = 52.1083, GNorm = 0.1280, lr_0 = 1.9926e-04
Loss = 3.7377e-05, PNorm = 52.1076, GNorm = 0.1862, lr_0 = 1.9905e-04
Loss = 4.9399e-05, PNorm = 52.1096, GNorm = 0.1044, lr_0 = 1.9884e-04
Loss = 4.4172e-05, PNorm = 52.1102, GNorm = 0.1670, lr_0 = 1.9863e-04
Loss = 4.0669e-05, PNorm = 52.1118, GNorm = 0.1244, lr_0 = 1.9842e-04
Loss = 3.2509e-05, PNorm = 52.1140, GNorm = 0.0750, lr_0 = 1.9822e-04
Loss = 5.2035e-05, PNorm = 52.1170, GNorm = 0.2115, lr_0 = 1.9801e-04
Loss = 4.2509e-05, PNorm = 52.1192, GNorm = 0.1181, lr_0 = 1.9780e-04
Loss = 4.3085e-05, PNorm = 52.1226, GNorm = 0.1013, lr_0 = 1.9760e-04
Loss = 3.3977e-05, PNorm = 52.1261, GNorm = 0.1253, lr_0 = 1.9739e-04
Loss = 4.1101e-05, PNorm = 52.1289, GNorm = 0.0965, lr_0 = 1.9719e-04
Loss = 4.8443e-05, PNorm = 52.1301, GNorm = 0.1535, lr_0 = 1.9698e-04
Loss = 4.3095e-05, PNorm = 52.1330, GNorm = 0.1597, lr_0 = 1.9677e-04
Loss = 3.9830e-05, PNorm = 52.1347, GNorm = 0.1009, lr_0 = 1.9657e-04
Loss = 3.6892e-05, PNorm = 52.1361, GNorm = 0.1358, lr_0 = 1.9636e-04
Validation rmse logD = 0.537716
Validation R2 logD = 0.795359
Validation rmse logP = 0.465431
Validation R2 logP = 0.936591
Epoch 71
Train function
Loss = 3.8636e-05, PNorm = 52.1381, GNorm = 0.1357, lr_0 = 1.9616e-04
Loss = 3.2717e-05, PNorm = 52.1397, GNorm = 0.1530, lr_0 = 1.9595e-04
Loss = 2.9120e-05, PNorm = 52.1405, GNorm = 0.0896, lr_0 = 1.9575e-04
Loss = 3.1771e-05, PNorm = 52.1428, GNorm = 0.1346, lr_0 = 1.9555e-04
Loss = 3.9753e-05, PNorm = 52.1434, GNorm = 0.1284, lr_0 = 1.9534e-04
Loss = 3.1642e-05, PNorm = 52.1439, GNorm = 0.0795, lr_0 = 1.9514e-04
Loss = 3.3278e-05, PNorm = 52.1457, GNorm = 0.2155, lr_0 = 1.9493e-04
Loss = 4.1436e-05, PNorm = 52.1488, GNorm = 0.1108, lr_0 = 1.9473e-04
Loss = 2.7274e-05, PNorm = 52.1503, GNorm = 0.0876, lr_0 = 1.9453e-04
Loss = 3.3965e-05, PNorm = 52.1519, GNorm = 0.1125, lr_0 = 1.9432e-04
Loss = 3.9759e-05, PNorm = 52.1521, GNorm = 0.1741, lr_0 = 1.9412e-04
Loss = 3.0337e-05, PNorm = 52.1534, GNorm = 0.0924, lr_0 = 1.9392e-04
Loss = 3.7121e-05, PNorm = 52.1540, GNorm = 0.1556, lr_0 = 1.9372e-04
Loss = 3.4680e-05, PNorm = 52.1550, GNorm = 0.1114, lr_0 = 1.9351e-04
Loss = 4.0112e-05, PNorm = 52.1577, GNorm = 0.1744, lr_0 = 1.9331e-04
Loss = 4.4584e-05, PNorm = 52.1601, GNorm = 0.1601, lr_0 = 1.9311e-04
Loss = 3.5697e-05, PNorm = 52.1613, GNorm = 0.1589, lr_0 = 1.9291e-04
Loss = 4.2663e-05, PNorm = 52.1631, GNorm = 0.1046, lr_0 = 1.9271e-04
Loss = 2.8699e-05, PNorm = 52.1645, GNorm = 0.1131, lr_0 = 1.9251e-04
Loss = 3.8978e-05, PNorm = 52.1650, GNorm = 0.1463, lr_0 = 1.9231e-04
Loss = 3.3400e-05, PNorm = 52.1664, GNorm = 0.2942, lr_0 = 1.9210e-04
Loss = 3.4272e-05, PNorm = 52.1675, GNorm = 0.1180, lr_0 = 1.9190e-04
Loss = 3.0210e-05, PNorm = 52.1692, GNorm = 0.0809, lr_0 = 1.9170e-04
Validation rmse logD = 0.537205
Validation R2 logD = 0.795748
Validation rmse logP = 0.465296
Validation R2 logP = 0.936628
Epoch 72
Train function
Loss = 3.6901e-05, PNorm = 52.1715, GNorm = 0.1631, lr_0 = 1.9148e-04
Loss = 2.8382e-05, PNorm = 52.1712, GNorm = 0.1668, lr_0 = 1.9128e-04
Loss = 2.8406e-05, PNorm = 52.1722, GNorm = 0.1185, lr_0 = 1.9108e-04
Loss = 2.7703e-05, PNorm = 52.1727, GNorm = 0.0988, lr_0 = 1.9088e-04
Loss = 2.8425e-05, PNorm = 52.1732, GNorm = 0.1398, lr_0 = 1.9069e-04
Loss = 2.9384e-05, PNorm = 52.1741, GNorm = 0.0914, lr_0 = 1.9049e-04
Loss = 3.3858e-05, PNorm = 52.1768, GNorm = 0.2167, lr_0 = 1.9029e-04
Loss = 3.0687e-05, PNorm = 52.1785, GNorm = 0.1092, lr_0 = 1.9009e-04
Loss = 3.1412e-05, PNorm = 52.1804, GNorm = 0.1673, lr_0 = 1.8989e-04
Loss = 3.0484e-05, PNorm = 52.1824, GNorm = 0.1453, lr_0 = 1.8969e-04
Loss = 3.2121e-05, PNorm = 52.1840, GNorm = 0.0681, lr_0 = 1.8949e-04
Loss = 3.5623e-05, PNorm = 52.1845, GNorm = 0.1892, lr_0 = 1.8930e-04
Loss = 4.4390e-05, PNorm = 52.1863, GNorm = 0.2515, lr_0 = 1.8910e-04
Loss = 6.9734e-05, PNorm = 52.1887, GNorm = 0.3685, lr_0 = 1.8890e-04
Loss = 4.9950e-05, PNorm = 52.1914, GNorm = 0.2146, lr_0 = 1.8870e-04
Loss = 4.0648e-05, PNorm = 52.1931, GNorm = 0.2114, lr_0 = 1.8851e-04
Loss = 4.4423e-05, PNorm = 52.1953, GNorm = 0.2415, lr_0 = 1.8831e-04
Loss = 4.1308e-05, PNorm = 52.1974, GNorm = 0.1383, lr_0 = 1.8811e-04
Loss = 3.2136e-05, PNorm = 52.1997, GNorm = 0.1706, lr_0 = 1.8792e-04
Loss = 3.7653e-05, PNorm = 52.2025, GNorm = 0.1168, lr_0 = 1.8772e-04
Loss = 3.0340e-05, PNorm = 52.2025, GNorm = 0.1069, lr_0 = 1.8753e-04
Loss = 3.9412e-05, PNorm = 52.2038, GNorm = 0.2389, lr_0 = 1.8733e-04
Loss = 4.5529e-05, PNorm = 52.2066, GNorm = 0.1744, lr_0 = 1.8713e-04
Validation rmse logD = 0.536777
Validation R2 logD = 0.796073
Validation rmse logP = 0.464675
Validation R2 logP = 0.936797
Epoch 73
Train function
Loss = 3.2651e-05, PNorm = 52.2076, GNorm = 0.1106, lr_0 = 1.8694e-04
Loss = 3.4048e-05, PNorm = 52.2087, GNorm = 0.1043, lr_0 = 1.8674e-04
Loss = 3.4068e-05, PNorm = 52.2104, GNorm = 0.1541, lr_0 = 1.8655e-04
Loss = 3.8849e-05, PNorm = 52.2133, GNorm = 0.1759, lr_0 = 1.8635e-04
Loss = 3.9702e-05, PNorm = 52.2148, GNorm = 0.1228, lr_0 = 1.8616e-04
Loss = 4.3368e-05, PNorm = 52.2177, GNorm = 0.1627, lr_0 = 1.8597e-04
Loss = 3.6484e-05, PNorm = 52.2198, GNorm = 0.1912, lr_0 = 1.8577e-04
Loss = 4.2301e-05, PNorm = 52.2214, GNorm = 0.2207, lr_0 = 1.8558e-04
Loss = 4.7065e-05, PNorm = 52.2233, GNorm = 0.3880, lr_0 = 1.8538e-04
Loss = 5.1066e-05, PNorm = 52.2256, GNorm = 0.1386, lr_0 = 1.8519e-04
Loss = 3.9952e-05, PNorm = 52.2276, GNorm = 0.1317, lr_0 = 1.8500e-04
Loss = 3.2815e-05, PNorm = 52.2279, GNorm = 0.0948, lr_0 = 1.8480e-04
Loss = 3.0569e-05, PNorm = 52.2297, GNorm = 0.1204, lr_0 = 1.8461e-04
Loss = 3.2885e-05, PNorm = 52.2312, GNorm = 0.0989, lr_0 = 1.8442e-04
Loss = 3.7743e-05, PNorm = 52.2338, GNorm = 0.1353, lr_0 = 1.8423e-04
Loss = 3.6843e-05, PNorm = 52.2355, GNorm = 0.1396, lr_0 = 1.8403e-04
Loss = 2.8284e-05, PNorm = 52.2362, GNorm = 0.0777, lr_0 = 1.8384e-04
Loss = 3.3137e-05, PNorm = 52.2364, GNorm = 0.1554, lr_0 = 1.8365e-04
Loss = 2.6574e-05, PNorm = 52.2383, GNorm = 0.1015, lr_0 = 1.8346e-04
Loss = 3.1700e-05, PNorm = 52.2398, GNorm = 0.1418, lr_0 = 1.8327e-04
Loss = 3.9243e-05, PNorm = 52.2421, GNorm = 0.0912, lr_0 = 1.8308e-04
Loss = 3.2826e-05, PNorm = 52.2449, GNorm = 0.1527, lr_0 = 1.8288e-04
Validation rmse logD = 0.535536
Validation R2 logD = 0.797015
Validation rmse logP = 0.469265
Validation R2 logP = 0.935542
Epoch 74
Train function
Loss = 4.0650e-05, PNorm = 52.2438, GNorm = 0.1856, lr_0 = 1.8267e-04
Loss = 3.7249e-05, PNorm = 52.2444, GNorm = 0.2608, lr_0 = 1.8248e-04
Loss = 3.3246e-05, PNorm = 52.2456, GNorm = 0.1162, lr_0 = 1.8229e-04
Loss = 2.5972e-05, PNorm = 52.2478, GNorm = 0.0768, lr_0 = 1.8210e-04
Loss = 2.9600e-05, PNorm = 52.2494, GNorm = 0.1309, lr_0 = 1.8191e-04
Loss = 3.4678e-05, PNorm = 52.2520, GNorm = 0.1490, lr_0 = 1.8172e-04
Loss = 3.5270e-05, PNorm = 52.2538, GNorm = 0.1678, lr_0 = 1.8153e-04
Loss = 2.5972e-05, PNorm = 52.2557, GNorm = 0.1360, lr_0 = 1.8134e-04
Loss = 3.5889e-05, PNorm = 52.2578, GNorm = 0.0932, lr_0 = 1.8115e-04
Loss = 3.3629e-05, PNorm = 52.2582, GNorm = 0.2360, lr_0 = 1.8097e-04
Loss = 3.9826e-05, PNorm = 52.2605, GNorm = 0.1468, lr_0 = 1.8078e-04
Loss = 4.9783e-05, PNorm = 52.2614, GNorm = 0.1515, lr_0 = 1.8059e-04
Loss = 3.5180e-05, PNorm = 52.2617, GNorm = 0.1163, lr_0 = 1.8040e-04
Loss = 3.5910e-05, PNorm = 52.2637, GNorm = 0.1003, lr_0 = 1.8021e-04
Loss = 3.4948e-05, PNorm = 52.2670, GNorm = 0.1089, lr_0 = 1.8002e-04
Loss = 3.9518e-05, PNorm = 52.2684, GNorm = 0.1335, lr_0 = 1.7984e-04
Loss = 3.5175e-05, PNorm = 52.2698, GNorm = 0.0979, lr_0 = 1.7965e-04
Loss = 2.9892e-05, PNorm = 52.2711, GNorm = 0.1410, lr_0 = 1.7946e-04
Loss = 3.9146e-05, PNorm = 52.2722, GNorm = 0.1407, lr_0 = 1.7927e-04
Loss = 3.7991e-05, PNorm = 52.2746, GNorm = 0.1151, lr_0 = 1.7909e-04
Loss = 3.4107e-05, PNorm = 52.2762, GNorm = 0.1072, lr_0 = 1.7890e-04
Loss = 3.7737e-05, PNorm = 52.2782, GNorm = 0.1412, lr_0 = 1.7871e-04
Loss = 3.4864e-05, PNorm = 52.2797, GNorm = 0.1319, lr_0 = 1.7853e-04
Validation rmse logD = 0.532633
Validation R2 logD = 0.799210
Validation rmse logP = 0.461812
Validation R2 logP = 0.937573
Epoch 75
Train function
Loss = 3.1112e-05, PNorm = 52.2799, GNorm = 0.1809, lr_0 = 1.7834e-04
Loss = 2.8427e-05, PNorm = 52.2807, GNorm = 0.0947, lr_0 = 1.7815e-04
Loss = 3.3868e-05, PNorm = 52.2825, GNorm = 0.1593, lr_0 = 1.7797e-04
Loss = 4.1020e-05, PNorm = 52.2843, GNorm = 0.1083, lr_0 = 1.7778e-04
Loss = 3.9253e-05, PNorm = 52.2855, GNorm = 0.1982, lr_0 = 1.7760e-04
Loss = 3.3729e-05, PNorm = 52.2871, GNorm = 0.0935, lr_0 = 1.7741e-04
Loss = 3.6699e-05, PNorm = 52.2899, GNorm = 0.0942, lr_0 = 1.7723e-04
Loss = 3.2889e-05, PNorm = 52.2910, GNorm = 0.1077, lr_0 = 1.7704e-04
Loss = 3.3972e-05, PNorm = 52.2928, GNorm = 0.2205, lr_0 = 1.7686e-04
Loss = 3.4520e-05, PNorm = 52.2932, GNorm = 0.2556, lr_0 = 1.7667e-04
Loss = 2.6875e-05, PNorm = 52.2947, GNorm = 0.0780, lr_0 = 1.7649e-04
Loss = 3.0379e-05, PNorm = 52.2963, GNorm = 0.1286, lr_0 = 1.7630e-04
Loss = 2.8920e-05, PNorm = 52.2978, GNorm = 0.0924, lr_0 = 1.7612e-04
Loss = 2.1035e-05, PNorm = 52.2993, GNorm = 0.0668, lr_0 = 1.7593e-04
Loss = 2.8475e-05, PNorm = 52.3002, GNorm = 0.1658, lr_0 = 1.7575e-04
Loss = 3.3679e-05, PNorm = 52.3017, GNorm = 0.2277, lr_0 = 1.7557e-04
Loss = 3.6951e-05, PNorm = 52.3038, GNorm = 0.2166, lr_0 = 1.7538e-04
Loss = 4.1768e-05, PNorm = 52.3044, GNorm = 0.1200, lr_0 = 1.7520e-04
Loss = 4.4875e-05, PNorm = 52.3059, GNorm = 0.1477, lr_0 = 1.7502e-04
Loss = 4.1570e-05, PNorm = 52.3087, GNorm = 0.3525, lr_0 = 1.7484e-04
Loss = 5.2401e-05, PNorm = 52.3112, GNorm = 0.2332, lr_0 = 1.7465e-04
Loss = 5.9366e-05, PNorm = 52.3153, GNorm = 0.2837, lr_0 = 1.7447e-04
Validation rmse logD = 0.535617
Validation R2 logD = 0.796953
Validation rmse logP = 0.462934
Validation R2 logP = 0.937270
Epoch 76
Train function
Loss = 2.8463e-05, PNorm = 52.3182, GNorm = 0.1957, lr_0 = 1.7427e-04
Loss = 3.3778e-05, PNorm = 52.3193, GNorm = 0.0868, lr_0 = 1.7409e-04
Loss = 3.5307e-05, PNorm = 52.3192, GNorm = 0.1581, lr_0 = 1.7391e-04
Loss = 3.2494e-05, PNorm = 52.3197, GNorm = 0.2056, lr_0 = 1.7373e-04
Loss = 3.3772e-05, PNorm = 52.3228, GNorm = 0.1545, lr_0 = 1.7354e-04
Loss = 3.5828e-05, PNorm = 52.3240, GNorm = 0.1354, lr_0 = 1.7336e-04
Loss = 3.1617e-05, PNorm = 52.3248, GNorm = 0.1405, lr_0 = 1.7318e-04
Loss = 2.9311e-05, PNorm = 52.3256, GNorm = 0.1696, lr_0 = 1.7300e-04
Loss = 3.9554e-05, PNorm = 52.3274, GNorm = 0.1083, lr_0 = 1.7282e-04
Loss = 4.1762e-05, PNorm = 52.3287, GNorm = 0.1404, lr_0 = 1.7264e-04
Loss = 3.0797e-05, PNorm = 52.3301, GNorm = 0.1369, lr_0 = 1.7246e-04
Loss = 2.7542e-05, PNorm = 52.3321, GNorm = 0.1157, lr_0 = 1.7228e-04
Loss = 3.1728e-05, PNorm = 52.3334, GNorm = 0.1211, lr_0 = 1.7210e-04
Loss = 2.9610e-05, PNorm = 52.3359, GNorm = 0.1043, lr_0 = 1.7192e-04
Loss = 3.1785e-05, PNorm = 52.3390, GNorm = 0.1573, lr_0 = 1.7174e-04
Loss = 2.9628e-05, PNorm = 52.3413, GNorm = 0.0990, lr_0 = 1.7156e-04
Loss = 3.1402e-05, PNorm = 52.3415, GNorm = 0.1348, lr_0 = 1.7138e-04
Loss = 2.3834e-05, PNorm = 52.3419, GNorm = 0.0864, lr_0 = 1.7120e-04
Loss = 3.4882e-05, PNorm = 52.3441, GNorm = 0.1176, lr_0 = 1.7103e-04
Loss = 2.7688e-05, PNorm = 52.3462, GNorm = 0.1044, lr_0 = 1.7085e-04
Loss = 3.1306e-05, PNorm = 52.3470, GNorm = 0.1427, lr_0 = 1.7067e-04
Loss = 3.9113e-05, PNorm = 52.3486, GNorm = 0.0948, lr_0 = 1.7049e-04
Loss = 3.2939e-05, PNorm = 52.3501, GNorm = 0.1187, lr_0 = 1.7031e-04
Validation rmse logD = 0.534459
Validation R2 logD = 0.797831
Validation rmse logP = 0.461621
Validation R2 logP = 0.937625
Epoch 77
Train function
Loss = 3.2142e-05, PNorm = 52.3510, GNorm = 0.1469, lr_0 = 1.7012e-04
Loss = 2.8084e-05, PNorm = 52.3532, GNorm = 0.1017, lr_0 = 1.6994e-04
Loss = 2.6146e-05, PNorm = 52.3537, GNorm = 0.0744, lr_0 = 1.6976e-04
Loss = 3.0605e-05, PNorm = 52.3546, GNorm = 0.1689, lr_0 = 1.6959e-04
Loss = 2.4559e-05, PNorm = 52.3568, GNorm = 0.1049, lr_0 = 1.6941e-04
Loss = 2.4550e-05, PNorm = 52.3566, GNorm = 0.0872, lr_0 = 1.6923e-04
Loss = 2.7584e-05, PNorm = 52.3584, GNorm = 0.1091, lr_0 = 1.6905e-04
Loss = 2.8075e-05, PNorm = 52.3580, GNorm = 0.1706, lr_0 = 1.6888e-04
Loss = 3.6682e-05, PNorm = 52.3593, GNorm = 0.2472, lr_0 = 1.6870e-04
Loss = 3.2580e-05, PNorm = 52.3596, GNorm = 0.1267, lr_0 = 1.6853e-04
Loss = 2.9499e-05, PNorm = 52.3605, GNorm = 0.1218, lr_0 = 1.6835e-04
Loss = 3.0434e-05, PNorm = 52.3623, GNorm = 0.1989, lr_0 = 1.6817e-04
Loss = 3.0689e-05, PNorm = 52.3638, GNorm = 0.0938, lr_0 = 1.6800e-04
Loss = 3.1878e-05, PNorm = 52.3660, GNorm = 0.1684, lr_0 = 1.6782e-04
Loss = 3.0249e-05, PNorm = 52.3679, GNorm = 0.1383, lr_0 = 1.6765e-04
Loss = 3.0061e-05, PNorm = 52.3678, GNorm = 0.1842, lr_0 = 1.6747e-04
Loss = 3.2078e-05, PNorm = 52.3681, GNorm = 0.1512, lr_0 = 1.6730e-04
Loss = 2.7911e-05, PNorm = 52.3686, GNorm = 0.0929, lr_0 = 1.6712e-04
Loss = 2.9171e-05, PNorm = 52.3700, GNorm = 0.1180, lr_0 = 1.6695e-04
Loss = 2.4465e-05, PNorm = 52.3725, GNorm = 0.0848, lr_0 = 1.6678e-04
Loss = 2.6653e-05, PNorm = 52.3734, GNorm = 0.1060, lr_0 = 1.6660e-04
Loss = 2.5405e-05, PNorm = 52.3752, GNorm = 0.0960, lr_0 = 1.6643e-04
Validation rmse logD = 0.534597
Validation R2 logD = 0.797726
Validation rmse logP = 0.463032
Validation R2 logP = 0.937243
Epoch 78
Train function
Loss = 3.3477e-05, PNorm = 52.3776, GNorm = 0.1149, lr_0 = 1.6625e-04
Loss = 1.7999e-05, PNorm = 52.3788, GNorm = 0.0802, lr_0 = 1.6608e-04
Loss = 2.0066e-05, PNorm = 52.3797, GNorm = 0.1109, lr_0 = 1.6591e-04
Loss = 2.2872e-05, PNorm = 52.3810, GNorm = 0.0908, lr_0 = 1.6573e-04
Loss = 2.5723e-05, PNorm = 52.3813, GNorm = 0.1371, lr_0 = 1.6556e-04
Loss = 2.2462e-05, PNorm = 52.3828, GNorm = 0.0536, lr_0 = 1.6539e-04
Loss = 2.3267e-05, PNorm = 52.3840, GNorm = 0.1293, lr_0 = 1.6522e-04
Loss = 2.1317e-05, PNorm = 52.3863, GNorm = 0.1131, lr_0 = 1.6504e-04
Loss = 2.6644e-05, PNorm = 52.3876, GNorm = 0.1232, lr_0 = 1.6487e-04
Loss = 1.9647e-05, PNorm = 52.3898, GNorm = 0.1505, lr_0 = 1.6470e-04
Loss = 2.5747e-05, PNorm = 52.3910, GNorm = 0.1149, lr_0 = 1.6453e-04
Loss = 2.3297e-05, PNorm = 52.3918, GNorm = 0.1170, lr_0 = 1.6435e-04
Loss = 2.9545e-05, PNorm = 52.3936, GNorm = 0.1027, lr_0 = 1.6418e-04
Loss = 2.5535e-05, PNorm = 52.3951, GNorm = 0.1403, lr_0 = 1.6401e-04
Loss = 2.3954e-05, PNorm = 52.3958, GNorm = 0.1103, lr_0 = 1.6384e-04
Loss = 2.6231e-05, PNorm = 52.3954, GNorm = 0.1404, lr_0 = 1.6367e-04
Loss = 2.5015e-05, PNorm = 52.3966, GNorm = 0.1005, lr_0 = 1.6350e-04
Loss = 2.5421e-05, PNorm = 52.3973, GNorm = 0.0927, lr_0 = 1.6333e-04
Loss = 2.7312e-05, PNorm = 52.3987, GNorm = 0.0731, lr_0 = 1.6316e-04
Loss = 2.7357e-05, PNorm = 52.4004, GNorm = 0.1704, lr_0 = 1.6299e-04
Loss = 2.3393e-05, PNorm = 52.4016, GNorm = 0.1086, lr_0 = 1.6282e-04
Loss = 2.8089e-05, PNorm = 52.4032, GNorm = 0.1137, lr_0 = 1.6265e-04
Loss = 2.9323e-05, PNorm = 52.4055, GNorm = 0.1170, lr_0 = 1.6248e-04
Validation rmse logD = 0.535017
Validation R2 logD = 0.797408
Validation rmse logP = 0.465120
Validation R2 logP = 0.936676
Epoch 79
Train function
Loss = 2.9962e-05, PNorm = 52.4067, GNorm = 0.1129, lr_0 = 1.6229e-04
Loss = 3.6275e-05, PNorm = 52.4069, GNorm = 0.2187, lr_0 = 1.6212e-04
Loss = 2.8503e-05, PNorm = 52.4091, GNorm = 0.1285, lr_0 = 1.6195e-04
Loss = 3.3098e-05, PNorm = 52.4103, GNorm = 0.1811, lr_0 = 1.6178e-04
Loss = 2.7066e-05, PNorm = 52.4110, GNorm = 0.1374, lr_0 = 1.6161e-04
Loss = 2.8494e-05, PNorm = 52.4114, GNorm = 0.1609, lr_0 = 1.6145e-04
Loss = 2.3656e-05, PNorm = 52.4139, GNorm = 0.0746, lr_0 = 1.6128e-04
Loss = 2.7551e-05, PNorm = 52.4168, GNorm = 0.0949, lr_0 = 1.6111e-04
Loss = 2.9537e-05, PNorm = 52.4168, GNorm = 0.0864, lr_0 = 1.6094e-04
Loss = 2.5249e-05, PNorm = 52.4177, GNorm = 0.1480, lr_0 = 1.6077e-04
Loss = 2.4755e-05, PNorm = 52.4199, GNorm = 0.0728, lr_0 = 1.6061e-04
Loss = 2.1025e-05, PNorm = 52.4209, GNorm = 0.1132, lr_0 = 1.6044e-04
Loss = 2.1786e-05, PNorm = 52.4210, GNorm = 0.1949, lr_0 = 1.6027e-04
Loss = 2.6823e-05, PNorm = 52.4218, GNorm = 0.1301, lr_0 = 1.6010e-04
Loss = 2.6180e-05, PNorm = 52.4224, GNorm = 0.1822, lr_0 = 1.5994e-04
Loss = 2.7166e-05, PNorm = 52.4249, GNorm = 0.1417, lr_0 = 1.5977e-04
Loss = 2.4356e-05, PNorm = 52.4264, GNorm = 0.0907, lr_0 = 1.5960e-04
Loss = 3.1122e-05, PNorm = 52.4272, GNorm = 0.1072, lr_0 = 1.5944e-04
Loss = 2.7197e-05, PNorm = 52.4296, GNorm = 0.1082, lr_0 = 1.5927e-04
Loss = 2.8772e-05, PNorm = 52.4319, GNorm = 0.1195, lr_0 = 1.5910e-04
Loss = 2.9898e-05, PNorm = 52.4343, GNorm = 0.2114, lr_0 = 1.5894e-04
Loss = 3.3102e-05, PNorm = 52.4355, GNorm = 0.1726, lr_0 = 1.5877e-04
Validation rmse logD = 0.534508
Validation R2 logD = 0.797794
Validation rmse logP = 0.465049
Validation R2 logP = 0.936695
Epoch 80
Train function
Loss = 2.2972e-05, PNorm = 52.4369, GNorm = 0.0650, lr_0 = 1.5861e-04
Loss = 1.9787e-05, PNorm = 52.4382, GNorm = 0.1020, lr_0 = 1.5844e-04
Loss = 2.6609e-05, PNorm = 52.4398, GNorm = 0.1280, lr_0 = 1.5827e-04
Loss = 2.5677e-05, PNorm = 52.4417, GNorm = 0.0942, lr_0 = 1.5811e-04
Loss = 2.3232e-05, PNorm = 52.4441, GNorm = 0.0818, lr_0 = 1.5794e-04
Loss = 2.3454e-05, PNorm = 52.4447, GNorm = 0.0633, lr_0 = 1.5778e-04
Loss = 2.0675e-05, PNorm = 52.4456, GNorm = 0.0798, lr_0 = 1.5761e-04
Loss = 2.1127e-05, PNorm = 52.4466, GNorm = 0.0968, lr_0 = 1.5745e-04
Loss = 2.3195e-05, PNorm = 52.4476, GNorm = 0.0605, lr_0 = 1.5729e-04
Loss = 2.5787e-05, PNorm = 52.4482, GNorm = 0.1754, lr_0 = 1.5712e-04
Loss = 1.9515e-05, PNorm = 52.4500, GNorm = 0.0802, lr_0 = 1.5696e-04
Loss = 2.5685e-05, PNorm = 52.4506, GNorm = 0.1923, lr_0 = 1.5679e-04
Loss = 2.1078e-05, PNorm = 52.4512, GNorm = 0.0784, lr_0 = 1.5663e-04
Loss = 2.4841e-05, PNorm = 52.4526, GNorm = 0.0948, lr_0 = 1.5647e-04
Loss = 2.8239e-05, PNorm = 52.4542, GNorm = 0.0712, lr_0 = 1.5630e-04
Loss = 3.0463e-05, PNorm = 52.4550, GNorm = 0.1587, lr_0 = 1.5614e-04
Loss = 2.4606e-05, PNorm = 52.4557, GNorm = 0.1134, lr_0 = 1.5598e-04
Loss = 2.5044e-05, PNorm = 52.4565, GNorm = 0.0645, lr_0 = 1.5581e-04
Loss = 2.9194e-05, PNorm = 52.4572, GNorm = 0.1296, lr_0 = 1.5565e-04
Loss = 2.5817e-05, PNorm = 52.4589, GNorm = 0.1278, lr_0 = 1.5549e-04
Loss = 2.5485e-05, PNorm = 52.4600, GNorm = 0.1195, lr_0 = 1.5533e-04
Loss = 3.3548e-05, PNorm = 52.4626, GNorm = 0.1184, lr_0 = 1.5516e-04
Loss = 3.1371e-05, PNorm = 52.4636, GNorm = 0.1531, lr_0 = 1.5500e-04
Validation rmse logD = 0.537646
Validation R2 logD = 0.795412
Validation rmse logP = 0.464942
Validation R2 logP = 0.936724
Epoch 81
Train function
Loss = 2.8095e-05, PNorm = 52.4663, GNorm = 0.1758, lr_0 = 1.5483e-04
Loss = 2.5688e-05, PNorm = 52.4675, GNorm = 0.1045, lr_0 = 1.5466e-04
Loss = 2.6123e-05, PNorm = 52.4673, GNorm = 0.1369, lr_0 = 1.5450e-04
Loss = 2.8778e-05, PNorm = 52.4680, GNorm = 0.1528, lr_0 = 1.5434e-04
Loss = 2.6032e-05, PNorm = 52.4689, GNorm = 0.0821, lr_0 = 1.5418e-04
Loss = 2.4628e-05, PNorm = 52.4692, GNorm = 0.0969, lr_0 = 1.5402e-04
Loss = 2.1435e-05, PNorm = 52.4702, GNorm = 0.1178, lr_0 = 1.5386e-04
Loss = 2.2623e-05, PNorm = 52.4704, GNorm = 0.0871, lr_0 = 1.5370e-04
Loss = 2.6954e-05, PNorm = 52.4717, GNorm = 0.0838, lr_0 = 1.5354e-04
Loss = 2.1211e-05, PNorm = 52.4719, GNorm = 0.0824, lr_0 = 1.5338e-04
Loss = 2.5303e-05, PNorm = 52.4730, GNorm = 0.1383, lr_0 = 1.5322e-04
Loss = 2.7588e-05, PNorm = 52.4743, GNorm = 0.1051, lr_0 = 1.5306e-04
Loss = 2.2863e-05, PNorm = 52.4752, GNorm = 0.1303, lr_0 = 1.5290e-04
Loss = 1.9055e-05, PNorm = 52.4764, GNorm = 0.1125, lr_0 = 1.5274e-04
Loss = 1.8091e-05, PNorm = 52.4764, GNorm = 0.1525, lr_0 = 1.5258e-04
Loss = 2.5158e-05, PNorm = 52.4778, GNorm = 0.1406, lr_0 = 1.5242e-04
Loss = 2.0329e-05, PNorm = 52.4787, GNorm = 0.1087, lr_0 = 1.5226e-04
Loss = 1.8290e-05, PNorm = 52.4799, GNorm = 0.0655, lr_0 = 1.5210e-04
Loss = 1.9014e-05, PNorm = 52.4809, GNorm = 0.1062, lr_0 = 1.5194e-04
Loss = 2.5818e-05, PNorm = 52.4821, GNorm = 0.2403, lr_0 = 1.5178e-04
Loss = 2.6280e-05, PNorm = 52.4832, GNorm = 0.0823, lr_0 = 1.5163e-04
Loss = 3.0585e-05, PNorm = 52.4860, GNorm = 0.1589, lr_0 = 1.5147e-04
Validation rmse logD = 0.538038
Validation R2 logD = 0.795114
Validation rmse logP = 0.467515
Validation R2 logP = 0.936022
Epoch 82
Train function
Loss = 3.0625e-05, PNorm = 52.4868, GNorm = 0.1880, lr_0 = 1.5131e-04
Loss = 3.0422e-05, PNorm = 52.4878, GNorm = 0.1646, lr_0 = 1.5115e-04
Loss = 2.6724e-05, PNorm = 52.4886, GNorm = 0.1217, lr_0 = 1.5099e-04
Loss = 2.1153e-05, PNorm = 52.4900, GNorm = 0.1206, lr_0 = 1.5084e-04
Loss = 2.1110e-05, PNorm = 52.4911, GNorm = 0.1171, lr_0 = 1.5068e-04
Loss = 2.4421e-05, PNorm = 52.4934, GNorm = 0.1061, lr_0 = 1.5052e-04
Loss = 2.7441e-05, PNorm = 52.4939, GNorm = 0.2059, lr_0 = 1.5036e-04
Loss = 3.1683e-05, PNorm = 52.4969, GNorm = 0.1108, lr_0 = 1.5021e-04
Loss = 2.2472e-05, PNorm = 52.4971, GNorm = 0.1014, lr_0 = 1.5005e-04
Loss = 1.9235e-05, PNorm = 52.4979, GNorm = 0.0797, lr_0 = 1.4989e-04
Loss = 1.9209e-05, PNorm = 52.4990, GNorm = 0.0847, lr_0 = 1.4974e-04
Loss = 1.8582e-05, PNorm = 52.4993, GNorm = 0.0730, lr_0 = 1.4958e-04
Loss = 1.9514e-05, PNorm = 52.5002, GNorm = 0.0939, lr_0 = 1.4942e-04
Loss = 1.9952e-05, PNorm = 52.5013, GNorm = 0.1851, lr_0 = 1.4927e-04
Loss = 2.0172e-05, PNorm = 52.5025, GNorm = 0.1800, lr_0 = 1.4911e-04
Loss = 2.2894e-05, PNorm = 52.5039, GNorm = 0.1448, lr_0 = 1.4896e-04
Loss = 2.6207e-05, PNorm = 52.5045, GNorm = 0.0871, lr_0 = 1.4880e-04
Loss = 2.5941e-05, PNorm = 52.5060, GNorm = 0.0914, lr_0 = 1.4865e-04
Loss = 1.9028e-05, PNorm = 52.5071, GNorm = 0.0926, lr_0 = 1.4849e-04
Loss = 2.3922e-05, PNorm = 52.5083, GNorm = 0.0745, lr_0 = 1.4834e-04
Loss = 2.3226e-05, PNorm = 52.5094, GNorm = 0.0983, lr_0 = 1.4818e-04
Loss = 1.8146e-05, PNorm = 52.5105, GNorm = 0.0774, lr_0 = 1.4803e-04
Loss = 2.3853e-05, PNorm = 52.5125, GNorm = 0.1373, lr_0 = 1.4787e-04
Validation rmse logD = 0.536806
Validation R2 logD = 0.796051
Validation rmse logP = 0.465136
Validation R2 logP = 0.936672
Epoch 83
Train function
Loss = 2.0938e-05, PNorm = 52.5138, GNorm = 0.0797, lr_0 = 1.4770e-04
Loss = 1.6893e-05, PNorm = 52.5161, GNorm = 0.0908, lr_0 = 1.4755e-04
Loss = 1.7789e-05, PNorm = 52.5175, GNorm = 0.0933, lr_0 = 1.4739e-04
Loss = 1.8490e-05, PNorm = 52.5179, GNorm = 0.0586, lr_0 = 1.4724e-04
Loss = 2.3180e-05, PNorm = 52.5188, GNorm = 0.1250, lr_0 = 1.4709e-04
Loss = 2.5079e-05, PNorm = 52.5205, GNorm = 0.2007, lr_0 = 1.4693e-04
Loss = 2.4020e-05, PNorm = 52.5212, GNorm = 0.1762, lr_0 = 1.4678e-04
Loss = 1.9342e-05, PNorm = 52.5221, GNorm = 0.1018, lr_0 = 1.4663e-04
Loss = 1.9738e-05, PNorm = 52.5232, GNorm = 0.0766, lr_0 = 1.4647e-04
Loss = 1.8083e-05, PNorm = 52.5241, GNorm = 0.1013, lr_0 = 1.4632e-04
Loss = 2.3694e-05, PNorm = 52.5254, GNorm = 0.1067, lr_0 = 1.4617e-04
Loss = 2.4242e-05, PNorm = 52.5260, GNorm = 0.0989, lr_0 = 1.4602e-04
Loss = 2.0889e-05, PNorm = 52.5265, GNorm = 0.1362, lr_0 = 1.4586e-04
Loss = 2.4230e-05, PNorm = 52.5262, GNorm = 0.0918, lr_0 = 1.4571e-04
Loss = 2.6759e-05, PNorm = 52.5262, GNorm = 0.0712, lr_0 = 1.4556e-04
Loss = 3.0290e-05, PNorm = 52.5280, GNorm = 0.1021, lr_0 = 1.4541e-04
Loss = 2.0911e-05, PNorm = 52.5304, GNorm = 0.1322, lr_0 = 1.4526e-04
Loss = 2.2302e-05, PNorm = 52.5322, GNorm = 0.1057, lr_0 = 1.4510e-04
Loss = 1.6551e-05, PNorm = 52.5329, GNorm = 0.0728, lr_0 = 1.4495e-04
Loss = 2.2274e-05, PNorm = 52.5335, GNorm = 0.1005, lr_0 = 1.4480e-04
Loss = 2.1072e-05, PNorm = 52.5346, GNorm = 0.0946, lr_0 = 1.4465e-04
Loss = 2.2174e-05, PNorm = 52.5347, GNorm = 0.1023, lr_0 = 1.4450e-04
Loss = 2.2281e-05, PNorm = 52.5362, GNorm = 0.0867, lr_0 = 1.4435e-04
Validation rmse logD = 0.536854
Validation R2 logD = 0.796015
Validation rmse logP = 0.463934
Validation R2 logP = 0.936999
Epoch 84
Train function
Loss = 1.8612e-05, PNorm = 52.5367, GNorm = 0.1037, lr_0 = 1.4420e-04
Loss = 1.4952e-05, PNorm = 52.5370, GNorm = 0.0825, lr_0 = 1.4405e-04
Loss = 1.6027e-05, PNorm = 52.5373, GNorm = 0.0596, lr_0 = 1.4390e-04
Loss = 1.7050e-05, PNorm = 52.5379, GNorm = 0.0842, lr_0 = 1.4375e-04
Loss = 2.1311e-05, PNorm = 52.5392, GNorm = 0.1048, lr_0 = 1.4360e-04
Loss = 2.1471e-05, PNorm = 52.5401, GNorm = 0.1091, lr_0 = 1.4345e-04
Loss = 2.2372e-05, PNorm = 52.5415, GNorm = 0.1271, lr_0 = 1.4330e-04
Loss = 1.9987e-05, PNorm = 52.5431, GNorm = 0.1390, lr_0 = 1.4315e-04
Loss = 1.6688e-05, PNorm = 52.5441, GNorm = 0.0689, lr_0 = 1.4300e-04
Loss = 2.0252e-05, PNorm = 52.5456, GNorm = 0.0811, lr_0 = 1.4285e-04
Loss = 2.3429e-05, PNorm = 52.5471, GNorm = 0.1482, lr_0 = 1.4270e-04
Loss = 2.4020e-05, PNorm = 52.5470, GNorm = 0.1433, lr_0 = 1.4255e-04
Loss = 2.0390e-05, PNorm = 52.5495, GNorm = 0.0925, lr_0 = 1.4240e-04
Loss = 2.1916e-05, PNorm = 52.5516, GNorm = 0.0908, lr_0 = 1.4225e-04
Loss = 1.6872e-05, PNorm = 52.5521, GNorm = 0.0746, lr_0 = 1.4210e-04
Loss = 2.5933e-05, PNorm = 52.5523, GNorm = 0.1039, lr_0 = 1.4196e-04
Loss = 1.7074e-05, PNorm = 52.5537, GNorm = 0.0734, lr_0 = 1.4181e-04
Loss = 2.4073e-05, PNorm = 52.5552, GNorm = 0.0972, lr_0 = 1.4166e-04
Loss = 1.8847e-05, PNorm = 52.5568, GNorm = 0.1089, lr_0 = 1.4151e-04
Loss = 2.3939e-05, PNorm = 52.5580, GNorm = 0.0937, lr_0 = 1.4136e-04
Loss = 3.0401e-05, PNorm = 52.5575, GNorm = 0.1555, lr_0 = 1.4122e-04
Loss = 2.3568e-05, PNorm = 52.5588, GNorm = 0.0897, lr_0 = 1.4107e-04
Validation rmse logD = 0.538755
Validation R2 logD = 0.794567
Validation rmse logP = 0.465654
Validation R2 logP = 0.936530
Epoch 85
Train function
Loss = 1.7383e-05, PNorm = 52.5596, GNorm = 0.0739, lr_0 = 1.4091e-04
Loss = 2.1604e-05, PNorm = 52.5609, GNorm = 0.1318, lr_0 = 1.4076e-04
Loss = 2.2515e-05, PNorm = 52.5618, GNorm = 0.0487, lr_0 = 1.4061e-04
Loss = 2.4405e-05, PNorm = 52.5624, GNorm = 0.1902, lr_0 = 1.4047e-04
Loss = 2.2694e-05, PNorm = 52.5637, GNorm = 0.1506, lr_0 = 1.4032e-04
Loss = 1.8969e-05, PNorm = 52.5642, GNorm = 0.1108, lr_0 = 1.4017e-04
Loss = 1.5524e-05, PNorm = 52.5654, GNorm = 0.1332, lr_0 = 1.4003e-04
Loss = 1.9385e-05, PNorm = 52.5658, GNorm = 0.1126, lr_0 = 1.3988e-04
Loss = 2.0234e-05, PNorm = 52.5665, GNorm = 0.0930, lr_0 = 1.3974e-04
Loss = 1.5760e-05, PNorm = 52.5676, GNorm = 0.0839, lr_0 = 1.3959e-04
Loss = 1.4322e-05, PNorm = 52.5690, GNorm = 0.1365, lr_0 = 1.3944e-04
Loss = 1.4644e-05, PNorm = 52.5704, GNorm = 0.0848, lr_0 = 1.3930e-04
Loss = 2.1656e-05, PNorm = 52.5715, GNorm = 0.0877, lr_0 = 1.3915e-04
Loss = 1.8917e-05, PNorm = 52.5727, GNorm = 0.1169, lr_0 = 1.3901e-04
Loss = 1.9436e-05, PNorm = 52.5738, GNorm = 0.0974, lr_0 = 1.3886e-04
Loss = 2.4876e-05, PNorm = 52.5738, GNorm = 0.1713, lr_0 = 1.3872e-04
Loss = 2.3757e-05, PNorm = 52.5745, GNorm = 0.1322, lr_0 = 1.3857e-04
Loss = 2.1804e-05, PNorm = 52.5756, GNorm = 0.0844, lr_0 = 1.3843e-04
Loss = 1.8520e-05, PNorm = 52.5769, GNorm = 0.0619, lr_0 = 1.3828e-04
Loss = 2.2804e-05, PNorm = 52.5778, GNorm = 0.0779, lr_0 = 1.3814e-04
Loss = 2.0133e-05, PNorm = 52.5788, GNorm = 0.1120, lr_0 = 1.3800e-04
Loss = 2.3168e-05, PNorm = 52.5810, GNorm = 0.0902, lr_0 = 1.3785e-04
Loss = 2.3213e-05, PNorm = 52.5821, GNorm = 0.0953, lr_0 = 1.3771e-04
Validation rmse logD = 0.537470
Validation R2 logD = 0.795546
Validation rmse logP = 0.463234
Validation R2 logP = 0.937188
Epoch 86
Train function
Loss = 2.1738e-05, PNorm = 52.5832, GNorm = 0.1463, lr_0 = 1.3756e-04
Loss = 2.2034e-05, PNorm = 52.5837, GNorm = 0.0801, lr_0 = 1.3742e-04
Loss = 2.8330e-05, PNorm = 52.5865, GNorm = 0.2063, lr_0 = 1.3728e-04
Loss = 1.9098e-05, PNorm = 52.5891, GNorm = 0.0748, lr_0 = 1.3713e-04
Loss = 2.1861e-05, PNorm = 52.5907, GNorm = 0.0751, lr_0 = 1.3699e-04
Loss = 1.7302e-05, PNorm = 52.5918, GNorm = 0.0636, lr_0 = 1.3685e-04
Loss = 2.1520e-05, PNorm = 52.5924, GNorm = 0.1692, lr_0 = 1.3670e-04
Loss = 1.8644e-05, PNorm = 52.5936, GNorm = 0.0713, lr_0 = 1.3656e-04
Loss = 2.2289e-05, PNorm = 52.5952, GNorm = 0.1431, lr_0 = 1.3642e-04
Loss = 1.8651e-05, PNorm = 52.5964, GNorm = 0.0930, lr_0 = 1.3628e-04
Loss = 2.4121e-05, PNorm = 52.5974, GNorm = 0.1236, lr_0 = 1.3613e-04
Loss = 2.1471e-05, PNorm = 52.5978, GNorm = 0.0964, lr_0 = 1.3599e-04
Loss = 2.4735e-05, PNorm = 52.5992, GNorm = 0.1378, lr_0 = 1.3585e-04
Loss = 2.4074e-05, PNorm = 52.5994, GNorm = 0.1441, lr_0 = 1.3571e-04
Loss = 2.1955e-05, PNorm = 52.6003, GNorm = 0.1126, lr_0 = 1.3557e-04
Loss = 2.5287e-05, PNorm = 52.6010, GNorm = 0.0760, lr_0 = 1.3543e-04
Loss = 2.1481e-05, PNorm = 52.6037, GNorm = 0.0642, lr_0 = 1.3528e-04
Loss = 1.9251e-05, PNorm = 52.6054, GNorm = 0.1144, lr_0 = 1.3514e-04
Loss = 1.9545e-05, PNorm = 52.6052, GNorm = 0.0997, lr_0 = 1.3500e-04
Loss = 1.8792e-05, PNorm = 52.6053, GNorm = 0.0565, lr_0 = 1.3486e-04
Loss = 1.8185e-05, PNorm = 52.6061, GNorm = 0.1298, lr_0 = 1.3472e-04
Loss = 1.8402e-05, PNorm = 52.6057, GNorm = 0.1070, lr_0 = 1.3458e-04
Validation rmse logD = 0.535782
Validation R2 logD = 0.796828
Validation rmse logP = 0.463973
Validation R2 logP = 0.936988
Epoch 87
Train function
Loss = 2.1393e-05, PNorm = 52.6079, GNorm = 0.1759, lr_0 = 1.3443e-04
Loss = 1.7649e-05, PNorm = 52.6092, GNorm = 0.0888, lr_0 = 1.3428e-04
Loss = 1.5753e-05, PNorm = 52.6104, GNorm = 0.0728, lr_0 = 1.3414e-04
Loss = 2.0133e-05, PNorm = 52.6114, GNorm = 0.1477, lr_0 = 1.3400e-04
Loss = 1.8573e-05, PNorm = 52.6127, GNorm = 0.1050, lr_0 = 1.3386e-04
Loss = 1.7210e-05, PNorm = 52.6135, GNorm = 0.0637, lr_0 = 1.3373e-04
Loss = 2.3756e-05, PNorm = 52.6137, GNorm = 0.1228, lr_0 = 1.3359e-04
Loss = 2.3727e-05, PNorm = 52.6151, GNorm = 0.0889, lr_0 = 1.3345e-04
Loss = 1.9612e-05, PNorm = 52.6154, GNorm = 0.0986, lr_0 = 1.3331e-04
Loss = 1.9271e-05, PNorm = 52.6157, GNorm = 0.1677, lr_0 = 1.3317e-04
Loss = 2.0499e-05, PNorm = 52.6164, GNorm = 0.1100, lr_0 = 1.3303e-04
Loss = 1.7574e-05, PNorm = 52.6175, GNorm = 0.1332, lr_0 = 1.3289e-04
Loss = 1.8306e-05, PNorm = 52.6183, GNorm = 0.1191, lr_0 = 1.3275e-04
Loss = 1.7540e-05, PNorm = 52.6191, GNorm = 0.0904, lr_0 = 1.3261e-04
Loss = 1.8526e-05, PNorm = 52.6202, GNorm = 0.0755, lr_0 = 1.3247e-04
Loss = 1.4816e-05, PNorm = 52.6215, GNorm = 0.0563, lr_0 = 1.3234e-04
Loss = 1.7018e-05, PNorm = 52.6218, GNorm = 0.0846, lr_0 = 1.3220e-04
Loss = 1.7760e-05, PNorm = 52.6212, GNorm = 0.0969, lr_0 = 1.3206e-04
Loss = 1.6766e-05, PNorm = 52.6221, GNorm = 0.1389, lr_0 = 1.3192e-04
Loss = 1.3341e-05, PNorm = 52.6228, GNorm = 0.0762, lr_0 = 1.3178e-04
Loss = 1.3647e-05, PNorm = 52.6217, GNorm = 0.0846, lr_0 = 1.3165e-04
Loss = 2.0185e-05, PNorm = 52.6211, GNorm = 0.0960, lr_0 = 1.3151e-04
Loss = 1.8386e-05, PNorm = 52.6210, GNorm = 0.0815, lr_0 = 1.3137e-04
Validation rmse logD = 0.535572
Validation R2 logD = 0.796987
Validation rmse logP = 0.465020
Validation R2 logP = 0.936703
Epoch 88
Train function
Loss = 1.2472e-05, PNorm = 52.6223, GNorm = 0.0748, lr_0 = 1.3124e-04
Loss = 1.5398e-05, PNorm = 52.6236, GNorm = 0.1371, lr_0 = 1.3110e-04
Loss = 1.9273e-05, PNorm = 52.6241, GNorm = 0.1301, lr_0 = 1.3096e-04
Loss = 1.4873e-05, PNorm = 52.6251, GNorm = 0.0849, lr_0 = 1.3082e-04
Loss = 1.4495e-05, PNorm = 52.6249, GNorm = 0.1009, lr_0 = 1.3069e-04
Loss = 1.8717e-05, PNorm = 52.6259, GNorm = 0.1446, lr_0 = 1.3055e-04
Loss = 2.0515e-05, PNorm = 52.6278, GNorm = 0.0727, lr_0 = 1.3042e-04
Loss = 1.9012e-05, PNorm = 52.6284, GNorm = 0.1530, lr_0 = 1.3028e-04
Loss = 1.7584e-05, PNorm = 52.6296, GNorm = 0.1211, lr_0 = 1.3014e-04
Loss = 1.8513e-05, PNorm = 52.6306, GNorm = 0.1409, lr_0 = 1.3001e-04
Loss = 1.8651e-05, PNorm = 52.6315, GNorm = 0.0660, lr_0 = 1.2987e-04
Loss = 1.5280e-05, PNorm = 52.6319, GNorm = 0.0703, lr_0 = 1.2974e-04
Loss = 1.5643e-05, PNorm = 52.6324, GNorm = 0.0871, lr_0 = 1.2960e-04
Loss = 1.5819e-05, PNorm = 52.6336, GNorm = 0.1178, lr_0 = 1.2947e-04
Loss = 1.5528e-05, PNorm = 52.6349, GNorm = 0.0885, lr_0 = 1.2933e-04
Loss = 1.9144e-05, PNorm = 52.6365, GNorm = 0.0889, lr_0 = 1.2920e-04
Loss = 2.0278e-05, PNorm = 52.6373, GNorm = 0.0692, lr_0 = 1.2906e-04
Loss = 2.2963e-05, PNorm = 52.6384, GNorm = 0.1640, lr_0 = 1.2893e-04
Loss = 2.0003e-05, PNorm = 52.6390, GNorm = 0.1479, lr_0 = 1.2879e-04
Loss = 1.8269e-05, PNorm = 52.6400, GNorm = 0.0545, lr_0 = 1.2866e-04
Loss = 1.6737e-05, PNorm = 52.6413, GNorm = 0.0731, lr_0 = 1.2852e-04
Loss = 1.8631e-05, PNorm = 52.6437, GNorm = 0.0548, lr_0 = 1.2839e-04
Validation rmse logD = 0.535121
Validation R2 logD = 0.797329
Validation rmse logP = 0.467290
Validation R2 logP = 0.936084
Epoch 89
Train function
Loss = 2.0388e-05, PNorm = 52.6453, GNorm = 0.0615, lr_0 = 1.2824e-04
Loss = 1.7168e-05, PNorm = 52.6467, GNorm = 0.0975, lr_0 = 1.2811e-04
Loss = 1.3376e-05, PNorm = 52.6474, GNorm = 0.1275, lr_0 = 1.2797e-04
Loss = 1.5379e-05, PNorm = 52.6482, GNorm = 0.0567, lr_0 = 1.2784e-04
Loss = 1.5599e-05, PNorm = 52.6490, GNorm = 0.0777, lr_0 = 1.2771e-04
Loss = 1.5491e-05, PNorm = 52.6498, GNorm = 0.0647, lr_0 = 1.2757e-04
Loss = 1.7811e-05, PNorm = 52.6500, GNorm = 0.0862, lr_0 = 1.2744e-04
Loss = 1.4544e-05, PNorm = 52.6509, GNorm = 0.0503, lr_0 = 1.2731e-04
Loss = 1.3117e-05, PNorm = 52.6511, GNorm = 0.0719, lr_0 = 1.2717e-04
Loss = 1.6935e-05, PNorm = 52.6511, GNorm = 0.0868, lr_0 = 1.2704e-04
Loss = 1.9398e-05, PNorm = 52.6511, GNorm = 0.2294, lr_0 = 1.2691e-04
Loss = 1.7034e-05, PNorm = 52.6525, GNorm = 0.0770, lr_0 = 1.2678e-04
Loss = 1.6000e-05, PNorm = 52.6523, GNorm = 0.1271, lr_0 = 1.2664e-04
Loss = 1.3208e-05, PNorm = 52.6534, GNorm = 0.0704, lr_0 = 1.2651e-04
Loss = 1.5503e-05, PNorm = 52.6544, GNorm = 0.0659, lr_0 = 1.2638e-04
Loss = 1.8231e-05, PNorm = 52.6559, GNorm = 0.1047, lr_0 = 1.2625e-04
Loss = 1.8202e-05, PNorm = 52.6573, GNorm = 0.1846, lr_0 = 1.2612e-04
Loss = 1.7010e-05, PNorm = 52.6576, GNorm = 0.0903, lr_0 = 1.2598e-04
Loss = 1.8725e-05, PNorm = 52.6586, GNorm = 0.0927, lr_0 = 1.2585e-04
Loss = 1.7386e-05, PNorm = 52.6593, GNorm = 0.0867, lr_0 = 1.2572e-04
Loss = 1.9227e-05, PNorm = 52.6606, GNorm = 0.1317, lr_0 = 1.2559e-04
Loss = 2.0201e-05, PNorm = 52.6621, GNorm = 0.1013, lr_0 = 1.2546e-04
Loss = 2.0889e-05, PNorm = 52.6623, GNorm = 0.0827, lr_0 = 1.2533e-04
Validation rmse logD = 0.536833
Validation R2 logD = 0.796030
Validation rmse logP = 0.464747
Validation R2 logP = 0.936777
Epoch 90
Train function
Loss = 2.2724e-05, PNorm = 52.6640, GNorm = 0.1057, lr_0 = 1.2520e-04
Loss = 2.0263e-05, PNorm = 52.6654, GNorm = 0.1389, lr_0 = 1.2507e-04
Loss = 1.6137e-05, PNorm = 52.6659, GNorm = 0.1268, lr_0 = 1.2494e-04
Loss = 1.2931e-05, PNorm = 52.6664, GNorm = 0.0747, lr_0 = 1.2481e-04
Loss = 1.8622e-05, PNorm = 52.6674, GNorm = 0.0758, lr_0 = 1.2468e-04
Loss = 2.2108e-05, PNorm = 52.6682, GNorm = 0.2376, lr_0 = 1.2455e-04
Loss = 1.4267e-05, PNorm = 52.6684, GNorm = 0.0667, lr_0 = 1.2442e-04
Loss = 1.8971e-05, PNorm = 52.6703, GNorm = 0.1326, lr_0 = 1.2429e-04
Loss = 1.3696e-05, PNorm = 52.6703, GNorm = 0.0747, lr_0 = 1.2416e-04
Loss = 1.5211e-05, PNorm = 52.6715, GNorm = 0.0602, lr_0 = 1.2403e-04
Loss = 1.4569e-05, PNorm = 52.6714, GNorm = 0.0653, lr_0 = 1.2390e-04
Loss = 1.6626e-05, PNorm = 52.6714, GNorm = 0.1439, lr_0 = 1.2377e-04
Loss = 1.4721e-05, PNorm = 52.6720, GNorm = 0.0752, lr_0 = 1.2364e-04
Loss = 1.3514e-05, PNorm = 52.6728, GNorm = 0.0856, lr_0 = 1.2351e-04
Loss = 1.6607e-05, PNorm = 52.6732, GNorm = 0.1174, lr_0 = 1.2338e-04
Loss = 1.1241e-05, PNorm = 52.6736, GNorm = 0.1200, lr_0 = 1.2325e-04
Loss = 1.6179e-05, PNorm = 52.6746, GNorm = 0.1154, lr_0 = 1.2312e-04
Loss = 1.5518e-05, PNorm = 52.6756, GNorm = 0.0783, lr_0 = 1.2299e-04
Loss = 1.4444e-05, PNorm = 52.6767, GNorm = 0.1149, lr_0 = 1.2287e-04
Loss = 1.1067e-05, PNorm = 52.6773, GNorm = 0.0530, lr_0 = 1.2274e-04
Loss = 1.2738e-05, PNorm = 52.6784, GNorm = 0.1014, lr_0 = 1.2261e-04
Loss = 1.4366e-05, PNorm = 52.6794, GNorm = 0.1370, lr_0 = 1.2248e-04
Validation rmse logD = 0.534129
Validation R2 logD = 0.798080
Validation rmse logP = 0.464678
Validation R2 logP = 0.936796
Epoch 91
Train function
Loss = 2.2631e-05, PNorm = 52.6797, GNorm = 0.1008, lr_0 = 1.2234e-04
Loss = 2.1635e-05, PNorm = 52.6809, GNorm = 0.1776, lr_0 = 1.2221e-04
Loss = 1.8467e-05, PNorm = 52.6814, GNorm = 0.1438, lr_0 = 1.2209e-04
Loss = 1.4179e-05, PNorm = 52.6825, GNorm = 0.0932, lr_0 = 1.2196e-04
Loss = 1.8689e-05, PNorm = 52.6833, GNorm = 0.0767, lr_0 = 1.2183e-04
Loss = 1.3928e-05, PNorm = 52.6839, GNorm = 0.0842, lr_0 = 1.2170e-04
Loss = 1.5341e-05, PNorm = 52.6849, GNorm = 0.1061, lr_0 = 1.2158e-04
Loss = 1.2955e-05, PNorm = 52.6852, GNorm = 0.0848, lr_0 = 1.2145e-04
Loss = 1.2094e-05, PNorm = 52.6856, GNorm = 0.0903, lr_0 = 1.2132e-04
Loss = 1.2421e-05, PNorm = 52.6860, GNorm = 0.0505, lr_0 = 1.2120e-04
Loss = 1.4294e-05, PNorm = 52.6866, GNorm = 0.1505, lr_0 = 1.2107e-04
Loss = 1.5969e-05, PNorm = 52.6872, GNorm = 0.1380, lr_0 = 1.2094e-04
Loss = 1.5379e-05, PNorm = 52.6879, GNorm = 0.0767, lr_0 = 1.2082e-04
Loss = 1.1610e-05, PNorm = 52.6880, GNorm = 0.0752, lr_0 = 1.2069e-04
Loss = 2.6650e-05, PNorm = 52.6890, GNorm = 0.1310, lr_0 = 1.2057e-04
Loss = 2.0183e-05, PNorm = 52.6903, GNorm = 0.0646, lr_0 = 1.2044e-04
Loss = 1.4750e-05, PNorm = 52.6918, GNorm = 0.1254, lr_0 = 1.2031e-04
Loss = 1.4304e-05, PNorm = 52.6925, GNorm = 0.0860, lr_0 = 1.2019e-04
Loss = 1.6230e-05, PNorm = 52.6938, GNorm = 0.0575, lr_0 = 1.2006e-04
Loss = 1.5917e-05, PNorm = 52.6950, GNorm = 0.0820, lr_0 = 1.1994e-04
Loss = 1.9696e-05, PNorm = 52.6959, GNorm = 0.1232, lr_0 = 1.1981e-04
Loss = 1.6091e-05, PNorm = 52.6974, GNorm = 0.0572, lr_0 = 1.1969e-04
Loss = 1.5675e-05, PNorm = 52.6984, GNorm = 0.0918, lr_0 = 1.1956e-04
Validation rmse logD = 0.535617
Validation R2 logD = 0.796953
Validation rmse logP = 0.464992
Validation R2 logP = 0.936711
Epoch 92
Train function
Loss = 9.3067e-06, PNorm = 52.6989, GNorm = 0.0933, lr_0 = 1.1944e-04
Loss = 1.1395e-05, PNorm = 52.6998, GNorm = 0.0642, lr_0 = 1.1931e-04
Loss = 9.5452e-06, PNorm = 52.7004, GNorm = 0.0956, lr_0 = 1.1919e-04
Loss = 1.5293e-05, PNorm = 52.7015, GNorm = 0.0741, lr_0 = 1.1906e-04
Loss = 1.1398e-05, PNorm = 52.7028, GNorm = 0.0645, lr_0 = 1.1894e-04
Loss = 1.2298e-05, PNorm = 52.7042, GNorm = 0.0536, lr_0 = 1.1882e-04
Loss = 1.0739e-05, PNorm = 52.7042, GNorm = 0.0636, lr_0 = 1.1869e-04
Loss = 1.2008e-05, PNorm = 52.7048, GNorm = 0.0726, lr_0 = 1.1857e-04
Loss = 1.1568e-05, PNorm = 52.7054, GNorm = 0.0699, lr_0 = 1.1844e-04
Loss = 1.0730e-05, PNorm = 52.7057, GNorm = 0.0471, lr_0 = 1.1832e-04
Loss = 1.2775e-05, PNorm = 52.7064, GNorm = 0.0698, lr_0 = 1.1820e-04
Loss = 1.8117e-05, PNorm = 52.7061, GNorm = 0.1337, lr_0 = 1.1807e-04
Loss = 1.8523e-05, PNorm = 52.7073, GNorm = 0.0705, lr_0 = 1.1795e-04
Loss = 1.3277e-05, PNorm = 52.7080, GNorm = 0.0837, lr_0 = 1.1783e-04
Loss = 1.4860e-05, PNorm = 52.7089, GNorm = 0.1143, lr_0 = 1.1770e-04
Loss = 1.4208e-05, PNorm = 52.7097, GNorm = 0.0595, lr_0 = 1.1758e-04
Loss = 1.7165e-05, PNorm = 52.7107, GNorm = 0.1322, lr_0 = 1.1746e-04
Loss = 1.3997e-05, PNorm = 52.7110, GNorm = 0.0953, lr_0 = 1.1734e-04
Loss = 1.3293e-05, PNorm = 52.7106, GNorm = 0.0693, lr_0 = 1.1721e-04
Loss = 1.3027e-05, PNorm = 52.7110, GNorm = 0.0787, lr_0 = 1.1709e-04
Loss = 1.3103e-05, PNorm = 52.7114, GNorm = 0.0772, lr_0 = 1.1697e-04
Loss = 1.4062e-05, PNorm = 52.7112, GNorm = 0.0672, lr_0 = 1.1685e-04
Validation rmse logD = 0.535876
Validation R2 logD = 0.796757
Validation rmse logP = 0.463603
Validation R2 logP = 0.937088
Epoch 93
Train function
Loss = 1.0488e-05, PNorm = 52.7123, GNorm = 0.0641, lr_0 = 1.1671e-04
Loss = 2.0399e-05, PNorm = 52.7139, GNorm = 0.1453, lr_0 = 1.1659e-04
Loss = 1.4604e-05, PNorm = 52.7148, GNorm = 0.0763, lr_0 = 1.1647e-04
Loss = 1.5863e-05, PNorm = 52.7160, GNorm = 0.0768, lr_0 = 1.1635e-04
Loss = 1.8511e-05, PNorm = 52.7161, GNorm = 0.0688, lr_0 = 1.1623e-04
Loss = 1.2825e-05, PNorm = 52.7161, GNorm = 0.0819, lr_0 = 1.1611e-04
Loss = 1.2098e-05, PNorm = 52.7173, GNorm = 0.1078, lr_0 = 1.1598e-04
Loss = 1.3610e-05, PNorm = 52.7184, GNorm = 0.0592, lr_0 = 1.1586e-04
Loss = 1.2055e-05, PNorm = 52.7194, GNorm = 0.0792, lr_0 = 1.1574e-04
Loss = 1.4101e-05, PNorm = 52.7202, GNorm = 0.1100, lr_0 = 1.1562e-04
Loss = 1.4189e-05, PNorm = 52.7203, GNorm = 0.1165, lr_0 = 1.1550e-04
Loss = 1.7182e-05, PNorm = 52.7205, GNorm = 0.0811, lr_0 = 1.1538e-04
Loss = 1.5909e-05, PNorm = 52.7214, GNorm = 0.1177, lr_0 = 1.1526e-04
Loss = 1.4205e-05, PNorm = 52.7227, GNorm = 0.0807, lr_0 = 1.1514e-04
Loss = 1.6146e-05, PNorm = 52.7231, GNorm = 0.1062, lr_0 = 1.1502e-04
Loss = 1.5417e-05, PNorm = 52.7234, GNorm = 0.1442, lr_0 = 1.1490e-04
Loss = 1.1932e-05, PNorm = 52.7241, GNorm = 0.0953, lr_0 = 1.1478e-04
Loss = 1.6220e-05, PNorm = 52.7250, GNorm = 0.1263, lr_0 = 1.1466e-04
Loss = 1.5110e-05, PNorm = 52.7248, GNorm = 0.1070, lr_0 = 1.1454e-04
Loss = 1.6988e-05, PNorm = 52.7251, GNorm = 0.1523, lr_0 = 1.1442e-04
Loss = 1.2879e-05, PNorm = 52.7265, GNorm = 0.1083, lr_0 = 1.1430e-04
Loss = 1.3103e-05, PNorm = 52.7279, GNorm = 0.0798, lr_0 = 1.1418e-04
Loss = 1.5106e-05, PNorm = 52.7287, GNorm = 0.1649, lr_0 = 1.1406e-04
Validation rmse logD = 0.535173
Validation R2 logD = 0.797290
Validation rmse logP = 0.464692
Validation R2 logP = 0.936792
Epoch 94
Train function
Loss = 2.0480e-05, PNorm = 52.7293, GNorm = 0.2093, lr_0 = 1.1394e-04
Loss = 1.1487e-05, PNorm = 52.7296, GNorm = 0.1308, lr_0 = 1.1382e-04
Loss = 1.4912e-05, PNorm = 52.7306, GNorm = 0.0862, lr_0 = 1.1371e-04
Loss = 1.1314e-05, PNorm = 52.7311, GNorm = 0.0772, lr_0 = 1.1359e-04
Loss = 1.2755e-05, PNorm = 52.7315, GNorm = 0.0867, lr_0 = 1.1347e-04
Loss = 1.7733e-05, PNorm = 52.7318, GNorm = 0.1370, lr_0 = 1.1335e-04
Loss = 1.6138e-05, PNorm = 52.7324, GNorm = 0.1028, lr_0 = 1.1323e-04
Loss = 1.3741e-05, PNorm = 52.7338, GNorm = 0.1321, lr_0 = 1.1311e-04
Loss = 1.1568e-05, PNorm = 52.7355, GNorm = 0.0414, lr_0 = 1.1300e-04
Loss = 1.2830e-05, PNorm = 52.7361, GNorm = 0.0878, lr_0 = 1.1288e-04
Loss = 1.0077e-05, PNorm = 52.7369, GNorm = 0.0381, lr_0 = 1.1276e-04
Loss = 1.3680e-05, PNorm = 52.7373, GNorm = 0.0687, lr_0 = 1.1264e-04
Loss = 1.3355e-05, PNorm = 52.7379, GNorm = 0.0604, lr_0 = 1.1252e-04
Loss = 1.2839e-05, PNorm = 52.7379, GNorm = 0.1008, lr_0 = 1.1241e-04
Loss = 1.3682e-05, PNorm = 52.7386, GNorm = 0.0964, lr_0 = 1.1229e-04
Loss = 2.0792e-05, PNorm = 52.7402, GNorm = 0.0676, lr_0 = 1.1217e-04
Loss = 1.9484e-05, PNorm = 52.7415, GNorm = 0.1115, lr_0 = 1.1206e-04
Loss = 1.2982e-05, PNorm = 52.7422, GNorm = 0.0669, lr_0 = 1.1194e-04
Loss = 1.3376e-05, PNorm = 52.7431, GNorm = 0.1002, lr_0 = 1.1182e-04
Loss = 1.0761e-05, PNorm = 52.7439, GNorm = 0.0973, lr_0 = 1.1170e-04
Loss = 1.6037e-05, PNorm = 52.7443, GNorm = 0.1411, lr_0 = 1.1159e-04
Loss = 1.7046e-05, PNorm = 52.7445, GNorm = 0.1214, lr_0 = 1.1147e-04
Loss = 1.7155e-05, PNorm = 52.7462, GNorm = 0.1500, lr_0 = 1.1136e-04
Loss = 1.4228e-05, PNorm = 52.7463, GNorm = 0.0691, lr_0 = 1.1134e-04
Validation rmse logD = 0.534567
Validation R2 logD = 0.797749
Validation rmse logP = 0.463893
Validation R2 logP = 0.937010
Epoch 95
Train function
Loss = 1.2294e-05, PNorm = 52.7476, GNorm = 0.0869, lr_0 = 1.1123e-04
Loss = 1.0773e-05, PNorm = 52.7480, GNorm = 0.0502, lr_0 = 1.1111e-04
Loss = 1.4240e-05, PNorm = 52.7479, GNorm = 0.0881, lr_0 = 1.1100e-04
Loss = 1.0634e-05, PNorm = 52.7480, GNorm = 0.0699, lr_0 = 1.1088e-04
Loss = 1.3520e-05, PNorm = 52.7486, GNorm = 0.1210, lr_0 = 1.1076e-04
Loss = 1.6911e-05, PNorm = 52.7494, GNorm = 0.1936, lr_0 = 1.1065e-04
Loss = 1.8227e-05, PNorm = 52.7514, GNorm = 0.1788, lr_0 = 1.1053e-04
Loss = 1.1834e-05, PNorm = 52.7522, GNorm = 0.0993, lr_0 = 1.1042e-04
Loss = 1.3816e-05, PNorm = 52.7529, GNorm = 0.1048, lr_0 = 1.1030e-04
Loss = 1.6141e-05, PNorm = 52.7537, GNorm = 0.1648, lr_0 = 1.1019e-04
Loss = 1.4988e-05, PNorm = 52.7554, GNorm = 0.0784, lr_0 = 1.1007e-04
Loss = 1.2570e-05, PNorm = 52.7559, GNorm = 0.0515, lr_0 = 1.0996e-04
Loss = 1.0539e-05, PNorm = 52.7568, GNorm = 0.0808, lr_0 = 1.0984e-04
Loss = 1.2986e-05, PNorm = 52.7566, GNorm = 0.1505, lr_0 = 1.0973e-04
Loss = 1.2832e-05, PNorm = 52.7570, GNorm = 0.0369, lr_0 = 1.0961e-04
Loss = 1.7458e-05, PNorm = 52.7572, GNorm = 0.0664, lr_0 = 1.0950e-04
Loss = 1.1496e-05, PNorm = 52.7581, GNorm = 0.0740, lr_0 = 1.0938e-04
Loss = 1.3134e-05, PNorm = 52.7584, GNorm = 0.0807, lr_0 = 1.0927e-04
Loss = 1.2584e-05, PNorm = 52.7586, GNorm = 0.0645, lr_0 = 1.0916e-04
Loss = 1.1607e-05, PNorm = 52.7589, GNorm = 0.1262, lr_0 = 1.0904e-04
Loss = 1.3450e-05, PNorm = 52.7594, GNorm = 0.0813, lr_0 = 1.0893e-04
Loss = 1.8727e-05, PNorm = 52.7601, GNorm = 0.0997, lr_0 = 1.0882e-04
Validation rmse logD = 0.538708
Validation R2 logD = 0.794603
Validation rmse logP = 0.464313
Validation R2 logP = 0.936896
Epoch 96
Train function
Loss = 1.1521e-05, PNorm = 52.7606, GNorm = 0.0793, lr_0 = 1.0870e-04
Loss = 1.8037e-05, PNorm = 52.7614, GNorm = 0.1313, lr_0 = 1.0859e-04
Loss = 1.5323e-05, PNorm = 52.7620, GNorm = 0.1019, lr_0 = 1.0847e-04
Loss = 1.3573e-05, PNorm = 52.7614, GNorm = 0.0649, lr_0 = 1.0836e-04
Loss = 1.2716e-05, PNorm = 52.7620, GNorm = 0.1041, lr_0 = 1.0825e-04
Loss = 1.2150e-05, PNorm = 52.7628, GNorm = 0.1114, lr_0 = 1.0814e-04
Loss = 1.3974e-05, PNorm = 52.7631, GNorm = 0.0609, lr_0 = 1.0802e-04
Loss = 1.2697e-05, PNorm = 52.7635, GNorm = 0.0578, lr_0 = 1.0791e-04
Loss = 1.4274e-05, PNorm = 52.7641, GNorm = 0.0929, lr_0 = 1.0780e-04
Loss = 1.0595e-05, PNorm = 52.7646, GNorm = 0.0765, lr_0 = 1.0768e-04
Loss = 1.1684e-05, PNorm = 52.7650, GNorm = 0.0916, lr_0 = 1.0757e-04
Loss = 1.2323e-05, PNorm = 52.7664, GNorm = 0.0638, lr_0 = 1.0746e-04
Loss = 1.1543e-05, PNorm = 52.7678, GNorm = 0.1064, lr_0 = 1.0735e-04
Loss = 1.2632e-05, PNorm = 52.7681, GNorm = 0.0700, lr_0 = 1.0724e-04
Loss = 1.0263e-05, PNorm = 52.7687, GNorm = 0.0897, lr_0 = 1.0712e-04
Loss = 9.7581e-06, PNorm = 52.7692, GNorm = 0.1308, lr_0 = 1.0701e-04
Loss = 1.2940e-05, PNorm = 52.7701, GNorm = 0.1260, lr_0 = 1.0690e-04
Loss = 1.2136e-05, PNorm = 52.7720, GNorm = 0.1067, lr_0 = 1.0679e-04
Loss = 1.5908e-05, PNorm = 52.7722, GNorm = 0.1125, lr_0 = 1.0668e-04
Loss = 1.9272e-05, PNorm = 52.7725, GNorm = 0.2461, lr_0 = 1.0657e-04
Loss = 1.7332e-05, PNorm = 52.7741, GNorm = 0.0654, lr_0 = 1.0645e-04
Loss = 1.4061e-05, PNorm = 52.7745, GNorm = 0.1078, lr_0 = 1.0634e-04
Loss = 1.6213e-05, PNorm = 52.7757, GNorm = 0.0599, lr_0 = 1.0623e-04
Validation rmse logD = 0.537411
Validation R2 logD = 0.795591
Validation rmse logP = 0.464738
Validation R2 logP = 0.936780
Epoch 97
Train function
Loss = 1.4121e-05, PNorm = 52.7765, GNorm = 0.0693, lr_0 = 1.0611e-04
Loss = 1.7334e-05, PNorm = 52.7779, GNorm = 0.1921, lr_0 = 1.0600e-04
Loss = 2.2245e-05, PNorm = 52.7782, GNorm = 0.1033, lr_0 = 1.0589e-04
Loss = 1.3940e-05, PNorm = 52.7794, GNorm = 0.0806, lr_0 = 1.0578e-04
Loss = 1.2340e-05, PNorm = 52.7799, GNorm = 0.0583, lr_0 = 1.0567e-04
Loss = 1.2134e-05, PNorm = 52.7801, GNorm = 0.0596, lr_0 = 1.0556e-04
Loss = 1.2519e-05, PNorm = 52.7813, GNorm = 0.0535, lr_0 = 1.0545e-04
Loss = 1.0646e-05, PNorm = 52.7822, GNorm = 0.1073, lr_0 = 1.0534e-04
Loss = 1.2056e-05, PNorm = 52.7830, GNorm = 0.1117, lr_0 = 1.0523e-04
Loss = 1.1765e-05, PNorm = 52.7834, GNorm = 0.0536, lr_0 = 1.0512e-04
Loss = 1.5190e-05, PNorm = 52.7839, GNorm = 0.0696, lr_0 = 1.0501e-04
Loss = 1.2803e-05, PNorm = 52.7843, GNorm = 0.0702, lr_0 = 1.0490e-04
Loss = 1.2634e-05, PNorm = 52.7845, GNorm = 0.0858, lr_0 = 1.0479e-04
Loss = 1.2886e-05, PNorm = 52.7854, GNorm = 0.1016, lr_0 = 1.0468e-04
Loss = 9.9671e-06, PNorm = 52.7858, GNorm = 0.0737, lr_0 = 1.0457e-04
Loss = 1.3136e-05, PNorm = 52.7860, GNorm = 0.0939, lr_0 = 1.0446e-04
Loss = 1.1057e-05, PNorm = 52.7863, GNorm = 0.1363, lr_0 = 1.0435e-04
Loss = 9.7084e-06, PNorm = 52.7869, GNorm = 0.0609, lr_0 = 1.0424e-04
Loss = 1.2509e-05, PNorm = 52.7872, GNorm = 0.0691, lr_0 = 1.0413e-04
Loss = 1.6374e-05, PNorm = 52.7879, GNorm = 0.1427, lr_0 = 1.0403e-04
Loss = 1.2822e-05, PNorm = 52.7889, GNorm = 0.1410, lr_0 = 1.0392e-04
Loss = 1.1361e-05, PNorm = 52.7892, GNorm = 0.0621, lr_0 = 1.0381e-04
Validation rmse logD = 0.536018
Validation R2 logD = 0.796649
Validation rmse logP = 0.463505
Validation R2 logP = 0.937115
Epoch 98
Train function
Loss = 8.8092e-06, PNorm = 52.7894, GNorm = 0.0645, lr_0 = 1.0370e-04
Loss = 9.1842e-06, PNorm = 52.7901, GNorm = 0.0641, lr_0 = 1.0359e-04
Loss = 1.0470e-05, PNorm = 52.7904, GNorm = 0.1148, lr_0 = 1.0348e-04
Loss = 1.0263e-05, PNorm = 52.7912, GNorm = 0.0572, lr_0 = 1.0338e-04
Loss = 9.8897e-06, PNorm = 52.7914, GNorm = 0.0737, lr_0 = 1.0327e-04
Loss = 8.2698e-06, PNorm = 52.7920, GNorm = 0.0551, lr_0 = 1.0316e-04
Loss = 1.0825e-05, PNorm = 52.7921, GNorm = 0.0620, lr_0 = 1.0305e-04
Loss = 1.0304e-05, PNorm = 52.7925, GNorm = 0.1166, lr_0 = 1.0295e-04
Loss = 1.0261e-05, PNorm = 52.7927, GNorm = 0.0498, lr_0 = 1.0284e-04
Loss = 9.4012e-06, PNorm = 52.7934, GNorm = 0.0610, lr_0 = 1.0273e-04
Loss = 1.0088e-05, PNorm = 52.7937, GNorm = 0.0629, lr_0 = 1.0262e-04
Loss = 9.6881e-06, PNorm = 52.7938, GNorm = 0.0917, lr_0 = 1.0252e-04
Loss = 1.1969e-05, PNorm = 52.7946, GNorm = 0.0908, lr_0 = 1.0241e-04
Loss = 1.2322e-05, PNorm = 52.7953, GNorm = 0.1067, lr_0 = 1.0230e-04
Loss = 1.1748e-05, PNorm = 52.7955, GNorm = 0.0744, lr_0 = 1.0220e-04
Loss = 1.2503e-05, PNorm = 52.7961, GNorm = 0.0714, lr_0 = 1.0209e-04
Loss = 1.5453e-05, PNorm = 52.7970, GNorm = 0.1105, lr_0 = 1.0198e-04
Loss = 1.5562e-05, PNorm = 52.7983, GNorm = 0.0677, lr_0 = 1.0188e-04
Loss = 1.1304e-05, PNorm = 52.7992, GNorm = 0.0650, lr_0 = 1.0177e-04
Loss = 1.4621e-05, PNorm = 52.8004, GNorm = 0.1001, lr_0 = 1.0166e-04
Loss = 1.2774e-05, PNorm = 52.8012, GNorm = 0.1059, lr_0 = 1.0156e-04
Loss = 8.5443e-06, PNorm = 52.8017, GNorm = 0.0659, lr_0 = 1.0145e-04
Loss = 1.1165e-05, PNorm = 52.8027, GNorm = 0.0717, lr_0 = 1.0135e-04
Validation rmse logD = 0.535804
Validation R2 logD = 0.796812
Validation rmse logP = 0.463415
Validation R2 logP = 0.937139
Epoch 99
Train function
Loss = 7.7992e-06, PNorm = 52.8032, GNorm = 0.0483, lr_0 = 1.0123e-04
Loss = 1.0003e-05, PNorm = 52.8028, GNorm = 0.0592, lr_0 = 1.0112e-04
Loss = 1.5033e-05, PNorm = 52.8032, GNorm = 0.1465, lr_0 = 1.0102e-04
Loss = 8.2195e-06, PNorm = 52.8043, GNorm = 0.0455, lr_0 = 1.0091e-04
Loss = 8.5921e-06, PNorm = 52.8051, GNorm = 0.1118, lr_0 = 1.0081e-04
Loss = 1.1083e-05, PNorm = 52.8053, GNorm = 0.0907, lr_0 = 1.0070e-04
Loss = 9.6588e-06, PNorm = 52.8063, GNorm = 0.0788, lr_0 = 1.0060e-04
Loss = 1.5340e-05, PNorm = 52.8069, GNorm = 0.1243, lr_0 = 1.0049e-04
Loss = 1.2565e-05, PNorm = 52.8068, GNorm = 0.0705, lr_0 = 1.0039e-04
Loss = 1.2423e-05, PNorm = 52.8075, GNorm = 0.0969, lr_0 = 1.0028e-04
Loss = 1.2504e-05, PNorm = 52.8082, GNorm = 0.1071, lr_0 = 1.0018e-04
Loss = 1.4012e-05, PNorm = 52.8088, GNorm = 0.1110, lr_0 = 1.0007e-04
Loss = 1.1978e-05, PNorm = 52.8100, GNorm = 0.0564, lr_0 = 1.0000e-04
Loss = 1.2744e-05, PNorm = 52.8107, GNorm = 0.1426, lr_0 = 1.0000e-04
Loss = 9.7153e-06, PNorm = 52.8111, GNorm = 0.0843, lr_0 = 1.0000e-04
Loss = 9.5465e-06, PNorm = 52.8116, GNorm = 0.0782, lr_0 = 1.0000e-04
Loss = 1.0441e-05, PNorm = 52.8129, GNorm = 0.0764, lr_0 = 1.0000e-04
Loss = 1.2514e-05, PNorm = 52.8138, GNorm = 0.0918, lr_0 = 1.0000e-04
Loss = 1.0799e-05, PNorm = 52.8149, GNorm = 0.1148, lr_0 = 1.0000e-04
Loss = 1.2257e-05, PNorm = 52.8154, GNorm = 0.0863, lr_0 = 1.0000e-04
Loss = 1.2846e-05, PNorm = 52.8157, GNorm = 0.1376, lr_0 = 1.0000e-04
Loss = 1.2565e-05, PNorm = 52.8163, GNorm = 0.0416, lr_0 = 1.0000e-04
Validation rmse logD = 0.534871
Validation R2 logD = 0.797518
Validation rmse logP = 0.464881
Validation R2 logP = 0.936741
Model 0 best validation rmse = 0.497194 on epoch 54
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.553774
Model 0 test R2 logD = 0.805500
Model 0 test rmse logP = 0.444645
Model 0 test R2 logP = 0.943213
Ensemble test rmse  logD= 0.553774
Ensemble test R2  logD= 0.805500
Ensemble test rmse  logP= 0.444645
Ensemble test R2  logP= 0.943213
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 2.0380e-02, PNorm = 35.0908, GNorm = 6.9093, lr_0 = 1.2200e-04
Loss = 1.6877e-02, PNorm = 35.0929, GNorm = 4.7350, lr_0 = 1.4200e-04
Loss = 1.6629e-02, PNorm = 35.0952, GNorm = 2.8629, lr_0 = 1.6200e-04
Loss = 1.3592e-02, PNorm = 35.0992, GNorm = 3.0481, lr_0 = 1.8200e-04
Loss = 1.1434e-02, PNorm = 35.1048, GNorm = 6.1631, lr_0 = 2.0200e-04
Loss = 1.0383e-02, PNorm = 35.1108, GNorm = 3.9059, lr_0 = 2.2200e-04
Loss = 9.7494e-03, PNorm = 35.1188, GNorm = 4.4863, lr_0 = 2.4200e-04
Loss = 9.2847e-03, PNorm = 35.1248, GNorm = 4.7230, lr_0 = 2.6200e-04
Loss = 8.2885e-03, PNorm = 35.1326, GNorm = 3.4851, lr_0 = 2.8200e-04
Loss = 9.4989e-03, PNorm = 35.1396, GNorm = 8.6550, lr_0 = 3.0200e-04
Loss = 9.4086e-03, PNorm = 35.1469, GNorm = 5.0147, lr_0 = 3.2200e-04
Loss = 9.7746e-03, PNorm = 35.1586, GNorm = 2.8579, lr_0 = 3.4200e-04
Loss = 7.1181e-03, PNorm = 35.1704, GNorm = 1.5043, lr_0 = 3.6200e-04
Loss = 8.0021e-03, PNorm = 35.1824, GNorm = 2.6991, lr_0 = 3.8200e-04
Loss = 7.4672e-03, PNorm = 35.1947, GNorm = 1.9166, lr_0 = 4.0200e-04
Loss = 7.2182e-03, PNorm = 35.2073, GNorm = 3.7836, lr_0 = 4.2200e-04
Loss = 6.8098e-03, PNorm = 35.2207, GNorm = 4.6994, lr_0 = 4.4200e-04
Loss = 6.8405e-03, PNorm = 35.2365, GNorm = 2.7402, lr_0 = 4.6200e-04
Loss = 7.2033e-03, PNorm = 35.2538, GNorm = 2.1435, lr_0 = 4.8200e-04
Loss = 5.9455e-03, PNorm = 35.2706, GNorm = 1.2363, lr_0 = 5.0200e-04
Loss = 5.9773e-03, PNorm = 35.2867, GNorm = 2.1027, lr_0 = 5.2200e-04
Loss = 7.0227e-03, PNorm = 35.3053, GNorm = 3.8406, lr_0 = 5.4200e-04
Validation rmse logD = 0.951841
Validation R2 logD = 0.372510
Validation rmse logP = 0.871212
Validation R2 logP = 0.779713
Epoch 1
Train function
Loss = 5.4468e-03, PNorm = 35.3239, GNorm = 2.5739, lr_0 = 5.6400e-04
Loss = 4.6984e-03, PNorm = 35.3391, GNorm = 1.3349, lr_0 = 5.8400e-04
Loss = 4.9573e-03, PNorm = 35.3602, GNorm = 2.6577, lr_0 = 6.0400e-04
Loss = 5.7674e-03, PNorm = 35.3769, GNorm = 6.5272, lr_0 = 6.2400e-04
Loss = 6.7306e-03, PNorm = 35.3993, GNorm = 2.7031, lr_0 = 6.4400e-04
Loss = 6.1369e-03, PNorm = 35.4235, GNorm = 2.2680, lr_0 = 6.6400e-04
Loss = 5.0594e-03, PNorm = 35.4416, GNorm = 3.5911, lr_0 = 6.8400e-04
Loss = 4.6465e-03, PNorm = 35.4656, GNorm = 2.6501, lr_0 = 7.0400e-04
Loss = 4.9448e-03, PNorm = 35.4900, GNorm = 4.1805, lr_0 = 7.2400e-04
Loss = 4.6976e-03, PNorm = 35.5121, GNorm = 1.4466, lr_0 = 7.4400e-04
Loss = 4.9201e-03, PNorm = 35.5360, GNorm = 1.5399, lr_0 = 7.6400e-04
Loss = 4.6383e-03, PNorm = 35.5590, GNorm = 3.8469, lr_0 = 7.8400e-04
Loss = 5.3030e-03, PNorm = 35.5874, GNorm = 4.4918, lr_0 = 8.0400e-04
Loss = 5.6086e-03, PNorm = 35.6107, GNorm = 3.9135, lr_0 = 8.2400e-04
Loss = 5.3678e-03, PNorm = 35.6434, GNorm = 1.3014, lr_0 = 8.4400e-04
Loss = 5.2026e-03, PNorm = 35.6736, GNorm = 1.1863, lr_0 = 8.6400e-04
Loss = 4.5994e-03, PNorm = 35.7013, GNorm = 1.8341, lr_0 = 8.8400e-04
Loss = 5.3335e-03, PNorm = 35.7313, GNorm = 2.5219, lr_0 = 9.0400e-04
Loss = 4.0824e-03, PNorm = 35.7652, GNorm = 2.4931, lr_0 = 9.2400e-04
Loss = 4.5395e-03, PNorm = 35.7960, GNorm = 2.8973, lr_0 = 9.4400e-04
Loss = 4.8399e-03, PNorm = 35.8293, GNorm = 2.8594, lr_0 = 9.6400e-04
Loss = 4.6811e-03, PNorm = 35.8609, GNorm = 1.2571, lr_0 = 9.8400e-04
Loss = 5.1369e-03, PNorm = 35.9109, GNorm = 1.0286, lr_0 = 9.9979e-04
Loss = 5.9621e-03, PNorm = 35.9165, GNorm = 1.4695, lr_0 = 9.9969e-04
Validation rmse logD = 0.872543
Validation R2 logD = 0.472708
Validation rmse logP = 0.669897
Validation R2 logP = 0.869756
Epoch 2
Train function
Loss = 3.7164e-03, PNorm = 35.9537, GNorm = 1.2033, lr_0 = 9.9864e-04
Loss = 3.5709e-03, PNorm = 35.9851, GNorm = 2.4335, lr_0 = 9.9760e-04
Loss = 4.5563e-03, PNorm = 36.0097, GNorm = 2.3648, lr_0 = 9.9656e-04
Loss = 4.0299e-03, PNorm = 36.0495, GNorm = 2.5292, lr_0 = 9.9552e-04
Loss = 3.8830e-03, PNorm = 36.0839, GNorm = 2.9809, lr_0 = 9.9448e-04
Loss = 4.2163e-03, PNorm = 36.1143, GNorm = 5.6190, lr_0 = 9.9344e-04
Loss = 5.0812e-03, PNorm = 36.1520, GNorm = 0.8744, lr_0 = 9.9241e-04
Loss = 5.2086e-03, PNorm = 36.1875, GNorm = 3.7510, lr_0 = 9.9137e-04
Loss = 4.0385e-03, PNorm = 36.2184, GNorm = 2.4258, lr_0 = 9.9034e-04
Loss = 4.6777e-03, PNorm = 36.2603, GNorm = 4.7918, lr_0 = 9.8930e-04
Loss = 4.6453e-03, PNorm = 36.2988, GNorm = 2.9200, lr_0 = 9.8827e-04
Loss = 4.4223e-03, PNorm = 36.3343, GNorm = 2.1129, lr_0 = 9.8724e-04
Loss = 5.6688e-03, PNorm = 36.3737, GNorm = 1.4117, lr_0 = 9.8621e-04
Loss = 4.2441e-03, PNorm = 36.4097, GNorm = 2.6219, lr_0 = 9.8518e-04
Loss = 4.0355e-03, PNorm = 36.4401, GNorm = 1.6100, lr_0 = 9.8415e-04
Loss = 4.3893e-03, PNorm = 36.4780, GNorm = 1.7435, lr_0 = 9.8312e-04
Loss = 3.8873e-03, PNorm = 36.5145, GNorm = 1.4001, lr_0 = 9.8210e-04
Loss = 3.9972e-03, PNorm = 36.5405, GNorm = 1.0031, lr_0 = 9.8107e-04
Loss = 3.8215e-03, PNorm = 36.5776, GNorm = 1.7410, lr_0 = 9.8005e-04
Loss = 3.9109e-03, PNorm = 36.6092, GNorm = 1.7309, lr_0 = 9.7902e-04
Loss = 3.1576e-03, PNorm = 36.6344, GNorm = 2.3593, lr_0 = 9.7800e-04
Loss = 3.5874e-03, PNorm = 36.6670, GNorm = 3.1472, lr_0 = 9.7698e-04
Validation rmse logD = 0.872480
Validation R2 logD = 0.472784
Validation rmse logP = 0.649152
Validation R2 logP = 0.877698
Epoch 3
Train function
Loss = 3.7608e-03, PNorm = 36.6951, GNorm = 3.5134, lr_0 = 9.7596e-04
Loss = 3.4740e-03, PNorm = 36.7269, GNorm = 1.1870, lr_0 = 9.7494e-04
Loss = 4.2548e-03, PNorm = 36.7596, GNorm = 1.1791, lr_0 = 9.7393e-04
Loss = 3.0748e-03, PNorm = 36.7959, GNorm = 1.5424, lr_0 = 9.7291e-04
Loss = 3.3625e-03, PNorm = 36.8346, GNorm = 3.8715, lr_0 = 9.7189e-04
Loss = 3.3775e-03, PNorm = 36.8614, GNorm = 0.9377, lr_0 = 9.7088e-04
Loss = 3.8667e-03, PNorm = 36.8945, GNorm = 1.2409, lr_0 = 9.6987e-04
Loss = 3.3623e-03, PNorm = 36.9486, GNorm = 0.9204, lr_0 = 9.6885e-04
Loss = 3.1167e-03, PNorm = 36.9855, GNorm = 0.9206, lr_0 = 9.6784e-04
Loss = 3.7041e-03, PNorm = 37.0247, GNorm = 2.4319, lr_0 = 9.6683e-04
Loss = 3.6897e-03, PNorm = 37.0674, GNorm = 1.3532, lr_0 = 9.6582e-04
Loss = 3.0051e-03, PNorm = 37.0988, GNorm = 0.7256, lr_0 = 9.6482e-04
Loss = 3.2074e-03, PNorm = 37.1284, GNorm = 1.9927, lr_0 = 9.6381e-04
Loss = 3.0227e-03, PNorm = 37.1602, GNorm = 1.7447, lr_0 = 9.6280e-04
Loss = 3.2579e-03, PNorm = 37.1928, GNorm = 1.0504, lr_0 = 9.6180e-04
Loss = 3.0385e-03, PNorm = 37.2117, GNorm = 1.2209, lr_0 = 9.6079e-04
Loss = 2.8226e-03, PNorm = 37.2271, GNorm = 1.2191, lr_0 = 9.5979e-04
Loss = 2.7642e-03, PNorm = 37.2514, GNorm = 0.7534, lr_0 = 9.5879e-04
Loss = 2.7710e-03, PNorm = 37.2740, GNorm = 1.5541, lr_0 = 9.5779e-04
Loss = 2.7693e-03, PNorm = 37.3138, GNorm = 0.8502, lr_0 = 9.5679e-04
Loss = 4.0677e-03, PNorm = 37.3399, GNorm = 2.7171, lr_0 = 9.5579e-04
Loss = 3.1872e-03, PNorm = 37.3773, GNorm = 0.6689, lr_0 = 9.5479e-04
Loss = 3.1203e-03, PNorm = 37.4131, GNorm = 1.9672, lr_0 = 9.5380e-04
Validation rmse logD = 0.795705
Validation R2 logD = 0.561487
Validation rmse logP = 0.602184
Validation R2 logP = 0.894755
Epoch 4
Train function
Loss = 2.8444e-03, PNorm = 37.4518, GNorm = 2.2022, lr_0 = 9.5270e-04
Loss = 3.2764e-03, PNorm = 37.4928, GNorm = 1.0282, lr_0 = 9.5171e-04
Loss = 2.8841e-03, PNorm = 37.5241, GNorm = 1.1985, lr_0 = 9.5071e-04
Loss = 2.6347e-03, PNorm = 37.5616, GNorm = 1.6826, lr_0 = 9.4972e-04
Loss = 2.9559e-03, PNorm = 37.5873, GNorm = 2.3006, lr_0 = 9.4873e-04
Loss = 2.7686e-03, PNorm = 37.6089, GNorm = 1.0089, lr_0 = 9.4774e-04
Loss = 2.8127e-03, PNorm = 37.6405, GNorm = 1.6285, lr_0 = 9.4675e-04
Loss = 3.2731e-03, PNorm = 37.6795, GNorm = 0.9364, lr_0 = 9.4576e-04
Loss = 3.5257e-03, PNorm = 37.7117, GNorm = 2.3625, lr_0 = 9.4478e-04
Loss = 2.9299e-03, PNorm = 37.7525, GNorm = 1.6166, lr_0 = 9.4379e-04
Loss = 2.6290e-03, PNorm = 37.7767, GNorm = 1.5505, lr_0 = 9.4280e-04
Loss = 2.8202e-03, PNorm = 37.8053, GNorm = 1.4062, lr_0 = 9.4182e-04
Loss = 2.8597e-03, PNorm = 37.8384, GNorm = 1.4884, lr_0 = 9.4084e-04
Loss = 2.9953e-03, PNorm = 37.8657, GNorm = 0.9742, lr_0 = 9.3986e-04
Loss = 2.4761e-03, PNorm = 37.8942, GNorm = 1.1545, lr_0 = 9.3887e-04
Loss = 2.9641e-03, PNorm = 37.9190, GNorm = 1.0813, lr_0 = 9.3789e-04
Loss = 2.3635e-03, PNorm = 37.9442, GNorm = 1.1878, lr_0 = 9.3692e-04
Loss = 2.6248e-03, PNorm = 37.9686, GNorm = 1.4772, lr_0 = 9.3594e-04
Loss = 2.1341e-03, PNorm = 38.0061, GNorm = 0.8299, lr_0 = 9.3496e-04
Loss = 2.2568e-03, PNorm = 38.0163, GNorm = 1.5768, lr_0 = 9.3399e-04
Loss = 2.5787e-03, PNorm = 38.0358, GNorm = 0.5986, lr_0 = 9.3301e-04
Loss = 2.6152e-03, PNorm = 38.0635, GNorm = 1.0467, lr_0 = 9.3204e-04
Validation rmse logD = 0.659850
Validation R2 logD = 0.698444
Validation rmse logP = 0.577940
Validation R2 logP = 0.903059
Epoch 5
Train function
Loss = 2.1061e-03, PNorm = 38.0850, GNorm = 0.9962, lr_0 = 9.3106e-04
Loss = 2.3731e-03, PNorm = 38.1230, GNorm = 1.2709, lr_0 = 9.3009e-04
Loss = 2.3565e-03, PNorm = 38.1544, GNorm = 2.6988, lr_0 = 9.2912e-04
Loss = 2.8639e-03, PNorm = 38.1803, GNorm = 2.5609, lr_0 = 9.2815e-04
Loss = 2.2914e-03, PNorm = 38.2126, GNorm = 1.2015, lr_0 = 9.2718e-04
Loss = 2.4372e-03, PNorm = 38.2434, GNorm = 1.2790, lr_0 = 9.2622e-04
Loss = 1.8076e-03, PNorm = 38.2703, GNorm = 1.6027, lr_0 = 9.2525e-04
Loss = 2.1699e-03, PNorm = 38.2869, GNorm = 0.9805, lr_0 = 9.2428e-04
Loss = 2.1372e-03, PNorm = 38.3135, GNorm = 0.5015, lr_0 = 9.2332e-04
Loss = 2.2074e-03, PNorm = 38.3521, GNorm = 1.5142, lr_0 = 9.2235e-04
Loss = 1.9720e-03, PNorm = 38.3742, GNorm = 1.0795, lr_0 = 9.2139e-04
Loss = 2.2184e-03, PNorm = 38.3998, GNorm = 1.1873, lr_0 = 9.2043e-04
Loss = 2.9700e-03, PNorm = 38.4294, GNorm = 1.6945, lr_0 = 9.1947e-04
Loss = 2.3800e-03, PNorm = 38.4534, GNorm = 0.7467, lr_0 = 9.1851e-04
Loss = 2.5224e-03, PNorm = 38.4759, GNorm = 3.4821, lr_0 = 9.1755e-04
Loss = 2.8497e-03, PNorm = 38.4992, GNorm = 2.5267, lr_0 = 9.1659e-04
Loss = 2.9794e-03, PNorm = 38.5405, GNorm = 1.3390, lr_0 = 9.1564e-04
Loss = 2.5906e-03, PNorm = 38.5789, GNorm = 2.3419, lr_0 = 9.1468e-04
Loss = 2.6848e-03, PNorm = 38.6134, GNorm = 0.7998, lr_0 = 9.1373e-04
Loss = 2.4257e-03, PNorm = 38.6441, GNorm = 1.1264, lr_0 = 9.1277e-04
Loss = 2.6886e-03, PNorm = 38.6663, GNorm = 1.0202, lr_0 = 9.1182e-04
Loss = 2.3599e-03, PNorm = 38.6921, GNorm = 1.4060, lr_0 = 9.1087e-04
Loss = 2.3782e-03, PNorm = 38.7136, GNorm = 1.3273, lr_0 = 9.0992e-04
Validation rmse logD = 0.678620
Validation R2 logD = 0.681044
Validation rmse logP = 0.577019
Validation R2 logP = 0.903368
Epoch 6
Train function
Loss = 1.8376e-03, PNorm = 38.7502, GNorm = 0.8697, lr_0 = 9.0887e-04
Loss = 1.8755e-03, PNorm = 38.7765, GNorm = 0.7208, lr_0 = 9.0792e-04
Loss = 1.8514e-03, PNorm = 38.7998, GNorm = 1.5494, lr_0 = 9.0698e-04
Loss = 1.9996e-03, PNorm = 38.8177, GNorm = 1.9552, lr_0 = 9.0603e-04
Loss = 2.2360e-03, PNorm = 38.8432, GNorm = 0.6069, lr_0 = 9.0508e-04
Loss = 2.2621e-03, PNorm = 38.8779, GNorm = 0.6049, lr_0 = 9.0414e-04
Loss = 2.0798e-03, PNorm = 38.9078, GNorm = 0.7208, lr_0 = 9.0320e-04
Loss = 2.1154e-03, PNorm = 38.9323, GNorm = 1.4459, lr_0 = 9.0225e-04
Loss = 2.0752e-03, PNorm = 38.9715, GNorm = 0.8281, lr_0 = 9.0131e-04
Loss = 2.3324e-03, PNorm = 38.9985, GNorm = 1.5803, lr_0 = 9.0037e-04
Loss = 2.3013e-03, PNorm = 39.0238, GNorm = 1.9209, lr_0 = 8.9943e-04
Loss = 2.4807e-03, PNorm = 39.0450, GNorm = 1.8031, lr_0 = 8.9849e-04
Loss = 2.4643e-03, PNorm = 39.0780, GNorm = 0.7586, lr_0 = 8.9756e-04
Loss = 2.7399e-03, PNorm = 39.1110, GNorm = 1.3976, lr_0 = 8.9662e-04
Loss = 2.6044e-03, PNorm = 39.1424, GNorm = 1.6481, lr_0 = 8.9568e-04
Loss = 1.9699e-03, PNorm = 39.1774, GNorm = 0.8516, lr_0 = 8.9475e-04
Loss = 2.5521e-03, PNorm = 39.2125, GNorm = 1.1164, lr_0 = 8.9381e-04
Loss = 1.9400e-03, PNorm = 39.2393, GNorm = 1.2243, lr_0 = 8.9288e-04
Loss = 2.0516e-03, PNorm = 39.2710, GNorm = 0.7359, lr_0 = 8.9195e-04
Loss = 2.1219e-03, PNorm = 39.3086, GNorm = 1.1422, lr_0 = 8.9102e-04
Loss = 1.9295e-03, PNorm = 39.3283, GNorm = 0.9886, lr_0 = 8.9009e-04
Loss = 1.9477e-03, PNorm = 39.3554, GNorm = 0.9890, lr_0 = 8.8916e-04
Validation rmse logD = 0.698921
Validation R2 logD = 0.661675
Validation rmse logP = 0.525584
Validation R2 logP = 0.919828
Epoch 7
Train function
Loss = 2.2735e-03, PNorm = 39.3779, GNorm = 0.9150, lr_0 = 8.8823e-04
Loss = 1.7020e-03, PNorm = 39.4150, GNorm = 0.3694, lr_0 = 8.8730e-04
Loss = 1.5061e-03, PNorm = 39.4454, GNorm = 0.8976, lr_0 = 8.8638e-04
Loss = 2.2258e-03, PNorm = 39.4662, GNorm = 1.3266, lr_0 = 8.8545e-04
Loss = 1.7641e-03, PNorm = 39.4993, GNorm = 2.1068, lr_0 = 8.8453e-04
Loss = 2.8451e-03, PNorm = 39.5193, GNorm = 2.8334, lr_0 = 8.8361e-04
Loss = 2.2272e-03, PNorm = 39.5458, GNorm = 1.4944, lr_0 = 8.8268e-04
Loss = 2.2619e-03, PNorm = 39.5703, GNorm = 1.6564, lr_0 = 8.8176e-04
Loss = 2.0357e-03, PNorm = 39.5954, GNorm = 1.6047, lr_0 = 8.8084e-04
Loss = 2.2780e-03, PNorm = 39.6287, GNorm = 2.3995, lr_0 = 8.7992e-04
Loss = 1.9641e-03, PNorm = 39.6473, GNorm = 0.7902, lr_0 = 8.7900e-04
Loss = 1.5369e-03, PNorm = 39.6713, GNorm = 0.5614, lr_0 = 8.7809e-04
Loss = 1.6105e-03, PNorm = 39.6954, GNorm = 0.9750, lr_0 = 8.7717e-04
Loss = 1.8327e-03, PNorm = 39.7239, GNorm = 0.9553, lr_0 = 8.7625e-04
Loss = 1.7042e-03, PNorm = 39.7525, GNorm = 1.2963, lr_0 = 8.7534e-04
Loss = 2.5279e-03, PNorm = 39.7849, GNorm = 2.3698, lr_0 = 8.7443e-04
Loss = 1.5679e-03, PNorm = 39.8150, GNorm = 0.7022, lr_0 = 8.7351e-04
Loss = 1.6850e-03, PNorm = 39.8356, GNorm = 1.5690, lr_0 = 8.7260e-04
Loss = 1.6578e-03, PNorm = 39.8460, GNorm = 0.5201, lr_0 = 8.7169e-04
Loss = 1.5516e-03, PNorm = 39.8775, GNorm = 1.0191, lr_0 = 8.7078e-04
Loss = 1.8526e-03, PNorm = 39.9011, GNorm = 0.7654, lr_0 = 8.6987e-04
Loss = 1.9710e-03, PNorm = 39.9225, GNorm = 0.6927, lr_0 = 8.6896e-04
Loss = 1.9250e-03, PNorm = 39.9486, GNorm = 1.4165, lr_0 = 8.6806e-04
Validation rmse logD = 0.631594
Validation R2 logD = 0.723717
Validation rmse logP = 0.520502
Validation R2 logP = 0.921370
Epoch 8
Train function
Loss = 1.3607e-03, PNorm = 39.9767, GNorm = 1.0244, lr_0 = 8.6706e-04
Loss = 1.8199e-03, PNorm = 39.9936, GNorm = 1.2696, lr_0 = 8.6616e-04
Loss = 1.5879e-03, PNorm = 40.0121, GNorm = 0.9445, lr_0 = 8.6525e-04
Loss = 1.7963e-03, PNorm = 40.0433, GNorm = 0.8537, lr_0 = 8.6435e-04
Loss = 1.5789e-03, PNorm = 40.0700, GNorm = 0.5936, lr_0 = 8.6345e-04
Loss = 1.7132e-03, PNorm = 40.0999, GNorm = 0.7773, lr_0 = 8.6255e-04
Loss = 1.6291e-03, PNorm = 40.1256, GNorm = 0.7576, lr_0 = 8.6165e-04
Loss = 1.5082e-03, PNorm = 40.1460, GNorm = 0.7044, lr_0 = 8.6075e-04
Loss = 1.4861e-03, PNorm = 40.1670, GNorm = 1.2959, lr_0 = 8.5985e-04
Loss = 1.8058e-03, PNorm = 40.1856, GNorm = 0.5159, lr_0 = 8.5895e-04
Loss = 1.5645e-03, PNorm = 40.2099, GNorm = 0.3931, lr_0 = 8.5805e-04
Loss = 1.6140e-03, PNorm = 40.2356, GNorm = 0.8373, lr_0 = 8.5716e-04
Loss = 2.0252e-03, PNorm = 40.2584, GNorm = 1.4252, lr_0 = 8.5626e-04
Loss = 1.7879e-03, PNorm = 40.2795, GNorm = 0.9161, lr_0 = 8.5537e-04
Loss = 1.3786e-03, PNorm = 40.3009, GNorm = 1.1256, lr_0 = 8.5448e-04
Loss = 1.5616e-03, PNorm = 40.3192, GNorm = 0.6405, lr_0 = 8.5359e-04
Loss = 1.8807e-03, PNorm = 40.3418, GNorm = 1.1572, lr_0 = 8.5269e-04
Loss = 1.8053e-03, PNorm = 40.3635, GNorm = 1.5080, lr_0 = 8.5180e-04
Loss = 1.5782e-03, PNorm = 40.3860, GNorm = 0.6380, lr_0 = 8.5092e-04
Loss = 1.6316e-03, PNorm = 40.4055, GNorm = 0.7270, lr_0 = 8.5003e-04
Loss = 1.6911e-03, PNorm = 40.4329, GNorm = 0.8003, lr_0 = 8.4914e-04
Loss = 1.3439e-03, PNorm = 40.4567, GNorm = 0.6996, lr_0 = 8.4825e-04
Validation rmse logD = 0.632055
Validation R2 logD = 0.723314
Validation rmse logP = 0.525214
Validation R2 logP = 0.919940
Epoch 9
Train function
Loss = 2.0197e-03, PNorm = 40.4843, GNorm = 1.0648, lr_0 = 8.4737e-04
Loss = 1.4429e-03, PNorm = 40.5013, GNorm = 0.7403, lr_0 = 8.4648e-04
Loss = 1.4794e-03, PNorm = 40.5296, GNorm = 0.9028, lr_0 = 8.4560e-04
Loss = 1.5776e-03, PNorm = 40.5439, GNorm = 0.8635, lr_0 = 8.4472e-04
Loss = 1.4536e-03, PNorm = 40.5747, GNorm = 1.1865, lr_0 = 8.4384e-04
Loss = 1.6513e-03, PNorm = 40.5967, GNorm = 0.9265, lr_0 = 8.4296e-04
Loss = 1.4469e-03, PNorm = 40.6147, GNorm = 0.7651, lr_0 = 8.4208e-04
Loss = 1.1825e-03, PNorm = 40.6334, GNorm = 0.5999, lr_0 = 8.4120e-04
Loss = 1.4772e-03, PNorm = 40.6544, GNorm = 1.1433, lr_0 = 8.4032e-04
Loss = 1.2188e-03, PNorm = 40.6761, GNorm = 0.5670, lr_0 = 8.3944e-04
Loss = 1.5152e-03, PNorm = 40.7000, GNorm = 0.5993, lr_0 = 8.3857e-04
Loss = 2.0034e-03, PNorm = 40.7354, GNorm = 1.1451, lr_0 = 8.3769e-04
Loss = 1.3313e-03, PNorm = 40.7571, GNorm = 1.5171, lr_0 = 8.3682e-04
Loss = 1.6374e-03, PNorm = 40.7826, GNorm = 1.7328, lr_0 = 8.3594e-04
Loss = 1.4932e-03, PNorm = 40.8056, GNorm = 0.6728, lr_0 = 8.3507e-04
Loss = 1.4046e-03, PNorm = 40.8374, GNorm = 0.9135, lr_0 = 8.3420e-04
Loss = 1.1375e-03, PNorm = 40.8625, GNorm = 1.1769, lr_0 = 8.3333e-04
Loss = 1.4404e-03, PNorm = 40.8856, GNorm = 1.2027, lr_0 = 8.3246e-04
Loss = 1.4852e-03, PNorm = 40.9086, GNorm = 1.5447, lr_0 = 8.3159e-04
Loss = 1.9091e-03, PNorm = 40.9327, GNorm = 0.9160, lr_0 = 8.3072e-04
Loss = 1.5684e-03, PNorm = 40.9564, GNorm = 0.7571, lr_0 = 8.2986e-04
Loss = 1.4998e-03, PNorm = 40.9786, GNorm = 0.5227, lr_0 = 8.2899e-04
Loss = 1.4525e-03, PNorm = 41.0009, GNorm = 0.6606, lr_0 = 8.2812e-04
Validation rmse logD = 0.641476
Validation R2 logD = 0.715004
Validation rmse logP = 0.511177
Validation R2 logP = 0.924163
Epoch 10
Train function
Loss = 1.3136e-03, PNorm = 41.0264, GNorm = 0.6726, lr_0 = 8.2717e-04
Loss = 1.2103e-03, PNorm = 41.0525, GNorm = 0.6277, lr_0 = 8.2631e-04
Loss = 1.3463e-03, PNorm = 41.0722, GNorm = 0.9749, lr_0 = 8.2545e-04
Loss = 1.2789e-03, PNorm = 41.0901, GNorm = 0.7803, lr_0 = 8.2459e-04
Loss = 1.3108e-03, PNorm = 41.1023, GNorm = 0.7036, lr_0 = 8.2373e-04
Loss = 1.3523e-03, PNorm = 41.1330, GNorm = 0.9037, lr_0 = 8.2287e-04
Loss = 1.6207e-03, PNorm = 41.1607, GNorm = 1.1244, lr_0 = 8.2201e-04
Loss = 1.1696e-03, PNorm = 41.1797, GNorm = 0.4837, lr_0 = 8.2115e-04
Loss = 1.4379e-03, PNorm = 41.2027, GNorm = 1.2578, lr_0 = 8.2029e-04
Loss = 1.4350e-03, PNorm = 41.2269, GNorm = 1.1362, lr_0 = 8.1944e-04
Loss = 1.4236e-03, PNorm = 41.2609, GNorm = 0.8477, lr_0 = 8.1858e-04
Loss = 1.3159e-03, PNorm = 41.2871, GNorm = 0.5671, lr_0 = 8.1773e-04
Loss = 1.4243e-03, PNorm = 41.2988, GNorm = 1.2022, lr_0 = 8.1687e-04
Loss = 1.1953e-03, PNorm = 41.3117, GNorm = 0.9926, lr_0 = 8.1602e-04
Loss = 1.1182e-03, PNorm = 41.3344, GNorm = 0.8206, lr_0 = 8.1517e-04
Loss = 1.2808e-03, PNorm = 41.3591, GNorm = 0.9008, lr_0 = 8.1432e-04
Loss = 1.2305e-03, PNorm = 41.3786, GNorm = 0.7439, lr_0 = 8.1347e-04
Loss = 1.1273e-03, PNorm = 41.3904, GNorm = 1.3668, lr_0 = 8.1262e-04
Loss = 1.5679e-03, PNorm = 41.4092, GNorm = 0.8042, lr_0 = 8.1177e-04
Loss = 1.2045e-03, PNorm = 41.4340, GNorm = 0.6878, lr_0 = 8.1092e-04
Loss = 1.2864e-03, PNorm = 41.4489, GNorm = 0.5699, lr_0 = 8.1008e-04
Loss = 1.5035e-03, PNorm = 41.4643, GNorm = 1.0111, lr_0 = 8.0923e-04
Loss = 1.5403e-03, PNorm = 41.4926, GNorm = 1.5457, lr_0 = 8.0839e-04
Validation rmse logD = 0.618104
Validation R2 logD = 0.735394
Validation rmse logP = 0.517576
Validation R2 logP = 0.922252
Epoch 11
Train function
Loss = 1.2116e-03, PNorm = 41.5158, GNorm = 0.7740, lr_0 = 8.0754e-04
Loss = 1.2257e-03, PNorm = 41.5423, GNorm = 1.4248, lr_0 = 8.0670e-04
Loss = 1.2891e-03, PNorm = 41.5659, GNorm = 1.8442, lr_0 = 8.0586e-04
Loss = 1.0569e-03, PNorm = 41.5888, GNorm = 1.2890, lr_0 = 8.0502e-04
Loss = 1.0988e-03, PNorm = 41.6082, GNorm = 0.7013, lr_0 = 8.0418e-04
Loss = 1.3631e-03, PNorm = 41.6231, GNorm = 1.3520, lr_0 = 8.0334e-04
Loss = 1.8231e-03, PNorm = 41.6477, GNorm = 1.7311, lr_0 = 8.0250e-04
Loss = 1.6238e-03, PNorm = 41.6743, GNorm = 1.0956, lr_0 = 8.0166e-04
Loss = 2.0950e-03, PNorm = 41.7081, GNorm = 0.9820, lr_0 = 8.0082e-04
Loss = 1.8079e-03, PNorm = 41.7385, GNorm = 0.8788, lr_0 = 7.9999e-04
Loss = 1.2604e-03, PNorm = 41.7727, GNorm = 1.0030, lr_0 = 7.9915e-04
Loss = 1.2186e-03, PNorm = 41.8032, GNorm = 1.2865, lr_0 = 7.9832e-04
Loss = 9.8920e-04, PNorm = 41.8350, GNorm = 0.7854, lr_0 = 7.9749e-04
Loss = 1.1024e-03, PNorm = 41.8479, GNorm = 0.5345, lr_0 = 7.9665e-04
Loss = 9.5582e-04, PNorm = 41.8659, GNorm = 0.5614, lr_0 = 7.9582e-04
Loss = 1.1955e-03, PNorm = 41.8874, GNorm = 0.5987, lr_0 = 7.9499e-04
Loss = 1.2357e-03, PNorm = 41.9044, GNorm = 0.5679, lr_0 = 7.9416e-04
Loss = 1.5220e-03, PNorm = 41.9150, GNorm = 1.4273, lr_0 = 7.9333e-04
Loss = 1.4096e-03, PNorm = 41.9481, GNorm = 1.1491, lr_0 = 7.9251e-04
Loss = 1.5283e-03, PNorm = 41.9783, GNorm = 0.5638, lr_0 = 7.9168e-04
Loss = 1.2016e-03, PNorm = 42.0069, GNorm = 0.6753, lr_0 = 7.9085e-04
Loss = 1.3467e-03, PNorm = 42.0309, GNorm = 1.1718, lr_0 = 7.9003e-04
Validation rmse logD = 0.609583
Validation R2 logD = 0.742638
Validation rmse logP = 0.491514
Validation R2 logP = 0.929885
Epoch 12
Train function
Loss = 9.7218e-04, PNorm = 42.0502, GNorm = 1.3520, lr_0 = 7.8912e-04
Loss = 1.1055e-03, PNorm = 42.0688, GNorm = 0.8345, lr_0 = 7.8830e-04
Loss = 1.0089e-03, PNorm = 42.0879, GNorm = 0.5691, lr_0 = 7.8747e-04
Loss = 1.0781e-03, PNorm = 42.0924, GNorm = 0.6923, lr_0 = 7.8665e-04
Loss = 1.1200e-03, PNorm = 42.1051, GNorm = 0.6647, lr_0 = 7.8583e-04
Loss = 9.9713e-04, PNorm = 42.1284, GNorm = 0.6051, lr_0 = 7.8501e-04
Loss = 1.2298e-03, PNorm = 42.1459, GNorm = 0.4690, lr_0 = 7.8419e-04
Loss = 1.1260e-03, PNorm = 42.1678, GNorm = 0.6689, lr_0 = 7.8337e-04
Loss = 1.1568e-03, PNorm = 42.1911, GNorm = 1.3508, lr_0 = 7.8255e-04
Loss = 1.2280e-03, PNorm = 42.2240, GNorm = 1.4436, lr_0 = 7.8174e-04
Loss = 1.1007e-03, PNorm = 42.2586, GNorm = 0.5896, lr_0 = 7.8092e-04
Loss = 1.5103e-03, PNorm = 42.2846, GNorm = 1.3365, lr_0 = 7.8011e-04
Loss = 1.2617e-03, PNorm = 42.3047, GNorm = 0.8383, lr_0 = 7.7929e-04
Loss = 1.3126e-03, PNorm = 42.3263, GNorm = 1.3163, lr_0 = 7.7848e-04
Loss = 1.0799e-03, PNorm = 42.3495, GNorm = 0.5698, lr_0 = 7.7767e-04
Loss = 1.1919e-03, PNorm = 42.3656, GNorm = 0.9127, lr_0 = 7.7686e-04
Loss = 1.0748e-03, PNorm = 42.3828, GNorm = 0.5955, lr_0 = 7.7604e-04
Loss = 1.2982e-03, PNorm = 42.3954, GNorm = 0.8595, lr_0 = 7.7523e-04
Loss = 1.0474e-03, PNorm = 42.4107, GNorm = 0.4302, lr_0 = 7.7443e-04
Loss = 1.1441e-03, PNorm = 42.4313, GNorm = 0.8224, lr_0 = 7.7362e-04
Loss = 1.1426e-03, PNorm = 42.4460, GNorm = 0.3817, lr_0 = 7.7281e-04
Loss = 1.4973e-03, PNorm = 42.4688, GNorm = 0.7896, lr_0 = 7.7200e-04
Loss = 9.1368e-04, PNorm = 42.4938, GNorm = 0.6933, lr_0 = 7.7120e-04
Validation rmse logD = 0.605683
Validation R2 logD = 0.745921
Validation rmse logP = 0.515661
Validation R2 logP = 0.922826
Epoch 13
Train function
Loss = 8.2472e-04, PNorm = 42.5124, GNorm = 0.7253, lr_0 = 7.7039e-04
Loss = 1.0659e-03, PNorm = 42.5277, GNorm = 1.0285, lr_0 = 7.6959e-04
Loss = 1.1005e-03, PNorm = 42.5494, GNorm = 1.3473, lr_0 = 7.6879e-04
Loss = 1.1341e-03, PNorm = 42.5669, GNorm = 1.0962, lr_0 = 7.6798e-04
Loss = 1.0069e-03, PNorm = 42.5869, GNorm = 0.6040, lr_0 = 7.6718e-04
Loss = 1.1867e-03, PNorm = 42.6064, GNorm = 1.0306, lr_0 = 7.6638e-04
Loss = 1.0369e-03, PNorm = 42.6245, GNorm = 0.6751, lr_0 = 7.6558e-04
Loss = 1.1203e-03, PNorm = 42.6439, GNorm = 0.9337, lr_0 = 7.6478e-04
Loss = 1.0537e-03, PNorm = 42.6684, GNorm = 0.8007, lr_0 = 7.6398e-04
Loss = 9.2158e-04, PNorm = 42.6795, GNorm = 0.4293, lr_0 = 7.6319e-04
Loss = 1.1108e-03, PNorm = 42.6968, GNorm = 1.0956, lr_0 = 7.6239e-04
Loss = 1.0285e-03, PNorm = 42.7222, GNorm = 1.1163, lr_0 = 7.6159e-04
Loss = 1.0969e-03, PNorm = 42.7332, GNorm = 1.2600, lr_0 = 7.6080e-04
Loss = 1.0197e-03, PNorm = 42.7499, GNorm = 0.6739, lr_0 = 7.6000e-04
Loss = 1.0992e-03, PNorm = 42.7671, GNorm = 1.0258, lr_0 = 7.5921e-04
Loss = 1.0429e-03, PNorm = 42.7873, GNorm = 1.0515, lr_0 = 7.5842e-04
Loss = 9.8904e-04, PNorm = 42.8084, GNorm = 0.7473, lr_0 = 7.5763e-04
Loss = 1.0284e-03, PNorm = 42.8315, GNorm = 0.8613, lr_0 = 7.5684e-04
Loss = 1.0405e-03, PNorm = 42.8467, GNorm = 1.3781, lr_0 = 7.5605e-04
Loss = 8.9828e-04, PNorm = 42.8613, GNorm = 0.9116, lr_0 = 7.5526e-04
Loss = 9.8322e-04, PNorm = 42.8771, GNorm = 0.9382, lr_0 = 7.5447e-04
Loss = 1.1035e-03, PNorm = 42.8970, GNorm = 1.0306, lr_0 = 7.5368e-04
Validation rmse logD = 0.611828
Validation R2 logD = 0.740740
Validation rmse logP = 0.500135
Validation R2 logP = 0.927404
Epoch 14
Train function
Loss = 1.0491e-03, PNorm = 42.9256, GNorm = 0.8793, lr_0 = 7.5282e-04
Loss = 9.5090e-04, PNorm = 42.9419, GNorm = 0.7377, lr_0 = 7.5203e-04
Loss = 8.3922e-04, PNorm = 42.9587, GNorm = 0.5042, lr_0 = 7.5125e-04
Loss = 6.7719e-04, PNorm = 42.9676, GNorm = 0.4015, lr_0 = 7.5046e-04
Loss = 8.2122e-04, PNorm = 42.9779, GNorm = 0.6084, lr_0 = 7.4968e-04
Loss = 9.6228e-04, PNorm = 42.9936, GNorm = 1.5422, lr_0 = 7.4890e-04
Loss = 9.8027e-04, PNorm = 43.0154, GNorm = 0.9514, lr_0 = 7.4811e-04
Loss = 1.0135e-03, PNorm = 43.0368, GNorm = 1.1891, lr_0 = 7.4733e-04
Loss = 9.1046e-04, PNorm = 43.0522, GNorm = 0.4917, lr_0 = 7.4655e-04
Loss = 9.0532e-04, PNorm = 43.0662, GNorm = 0.8174, lr_0 = 7.4577e-04
Loss = 1.0283e-03, PNorm = 43.0762, GNorm = 1.1224, lr_0 = 7.4500e-04
Loss = 8.1048e-04, PNorm = 43.0970, GNorm = 0.9021, lr_0 = 7.4422e-04
Loss = 1.0773e-03, PNorm = 43.1131, GNorm = 0.7001, lr_0 = 7.4344e-04
Loss = 1.0764e-03, PNorm = 43.1282, GNorm = 0.6502, lr_0 = 7.4267e-04
Loss = 9.2570e-04, PNorm = 43.1487, GNorm = 0.5286, lr_0 = 7.4189e-04
Loss = 8.8174e-04, PNorm = 43.1654, GNorm = 0.4157, lr_0 = 7.4112e-04
Loss = 8.9840e-04, PNorm = 43.1819, GNorm = 0.6569, lr_0 = 7.4034e-04
Loss = 9.1857e-04, PNorm = 43.1962, GNorm = 0.7107, lr_0 = 7.3957e-04
Loss = 8.6302e-04, PNorm = 43.2149, GNorm = 0.5561, lr_0 = 7.3880e-04
Loss = 8.6907e-04, PNorm = 43.2356, GNorm = 0.7631, lr_0 = 7.3803e-04
Loss = 9.5580e-04, PNorm = 43.2513, GNorm = 0.9585, lr_0 = 7.3726e-04
Loss = 9.5719e-04, PNorm = 43.2678, GNorm = 0.7308, lr_0 = 7.3649e-04
Loss = 9.5947e-04, PNorm = 43.2868, GNorm = 0.5689, lr_0 = 7.3572e-04
Validation rmse logD = 0.587746
Validation R2 logD = 0.760747
Validation rmse logP = 0.487394
Validation R2 logP = 0.931055
Epoch 15
Train function
Loss = 7.4640e-04, PNorm = 43.3101, GNorm = 0.5238, lr_0 = 7.3495e-04
Loss = 6.6279e-04, PNorm = 43.3310, GNorm = 0.5670, lr_0 = 7.3418e-04
Loss = 1.0249e-03, PNorm = 43.3531, GNorm = 1.2682, lr_0 = 7.3342e-04
Loss = 1.0256e-03, PNorm = 43.3742, GNorm = 0.5423, lr_0 = 7.3265e-04
Loss = 1.0073e-03, PNorm = 43.3885, GNorm = 0.8067, lr_0 = 7.3189e-04
Loss = 8.6343e-04, PNorm = 43.4149, GNorm = 1.0338, lr_0 = 7.3112e-04
Loss = 9.8893e-04, PNorm = 43.4308, GNorm = 1.0667, lr_0 = 7.3036e-04
Loss = 7.6100e-04, PNorm = 43.4513, GNorm = 0.4189, lr_0 = 7.2960e-04
Loss = 9.0967e-04, PNorm = 43.4715, GNorm = 0.5374, lr_0 = 7.2884e-04
Loss = 8.7836e-04, PNorm = 43.4896, GNorm = 1.1577, lr_0 = 7.2808e-04
Loss = 6.7082e-04, PNorm = 43.4998, GNorm = 0.7050, lr_0 = 7.2732e-04
Loss = 9.5313e-04, PNorm = 43.5131, GNorm = 1.4602, lr_0 = 7.2656e-04
Loss = 9.2194e-04, PNorm = 43.5295, GNorm = 0.9153, lr_0 = 7.2580e-04
Loss = 1.0394e-03, PNorm = 43.5398, GNorm = 1.1045, lr_0 = 7.2504e-04
Loss = 7.9588e-04, PNorm = 43.5567, GNorm = 0.5183, lr_0 = 7.2428e-04
Loss = 9.8093e-04, PNorm = 43.5824, GNorm = 0.6988, lr_0 = 7.2353e-04
Loss = 1.0193e-03, PNorm = 43.6051, GNorm = 1.3571, lr_0 = 7.2277e-04
Loss = 9.8525e-04, PNorm = 43.6176, GNorm = 0.5140, lr_0 = 7.2202e-04
Loss = 7.8144e-04, PNorm = 43.6314, GNorm = 0.4952, lr_0 = 7.2127e-04
Loss = 6.1638e-04, PNorm = 43.6430, GNorm = 0.3231, lr_0 = 7.2051e-04
Loss = 8.4491e-04, PNorm = 43.6573, GNorm = 0.7362, lr_0 = 7.1976e-04
Loss = 8.4764e-04, PNorm = 43.6728, GNorm = 0.6633, lr_0 = 7.1901e-04
Validation rmse logD = 0.608577
Validation R2 logD = 0.743487
Validation rmse logP = 0.479751
Validation R2 logP = 0.933201
Epoch 16
Train function
Loss = 6.5687e-04, PNorm = 43.6915, GNorm = 0.5855, lr_0 = 7.1818e-04
Loss = 8.7937e-04, PNorm = 43.7113, GNorm = 0.7987, lr_0 = 7.1743e-04
Loss = 7.4013e-04, PNorm = 43.7340, GNorm = 0.6068, lr_0 = 7.1669e-04
Loss = 7.9354e-04, PNorm = 43.7544, GNorm = 0.6129, lr_0 = 7.1594e-04
Loss = 7.7284e-04, PNorm = 43.7707, GNorm = 0.6256, lr_0 = 7.1519e-04
Loss = 8.2073e-04, PNorm = 43.7904, GNorm = 0.4945, lr_0 = 7.1444e-04
Loss = 7.4041e-04, PNorm = 43.8049, GNorm = 0.4190, lr_0 = 7.1370e-04
Loss = 7.6567e-04, PNorm = 43.8192, GNorm = 0.4148, lr_0 = 7.1295e-04
Loss = 7.7700e-04, PNorm = 43.8313, GNorm = 1.0272, lr_0 = 7.1221e-04
Loss = 1.0170e-03, PNorm = 43.8453, GNorm = 1.0249, lr_0 = 7.1147e-04
Loss = 6.8823e-04, PNorm = 43.8621, GNorm = 0.6093, lr_0 = 7.1072e-04
Loss = 8.1465e-04, PNorm = 43.8760, GNorm = 0.4458, lr_0 = 7.0998e-04
Loss = 8.0673e-04, PNorm = 43.8948, GNorm = 0.4837, lr_0 = 7.0924e-04
Loss = 6.0165e-04, PNorm = 43.9093, GNorm = 0.7897, lr_0 = 7.0850e-04
Loss = 8.8848e-04, PNorm = 43.9325, GNorm = 0.6411, lr_0 = 7.0776e-04
Loss = 7.9181e-04, PNorm = 43.9587, GNorm = 0.3205, lr_0 = 7.0702e-04
Loss = 7.8782e-04, PNorm = 43.9733, GNorm = 0.9473, lr_0 = 7.0628e-04
Loss = 6.9466e-04, PNorm = 43.9914, GNorm = 0.3790, lr_0 = 7.0555e-04
Loss = 8.2929e-04, PNorm = 44.0096, GNorm = 0.7067, lr_0 = 7.0481e-04
Loss = 8.6263e-04, PNorm = 44.0283, GNorm = 1.6678, lr_0 = 7.0408e-04
Loss = 1.0650e-03, PNorm = 44.0389, GNorm = 1.4454, lr_0 = 7.0334e-04
Loss = 8.1146e-04, PNorm = 44.0564, GNorm = 0.9904, lr_0 = 7.0261e-04
Loss = 8.0861e-04, PNorm = 44.0722, GNorm = 0.7712, lr_0 = 7.0187e-04
Validation rmse logD = 0.607253
Validation R2 logD = 0.744602
Validation rmse logP = 0.479664
Validation R2 logP = 0.933225
Epoch 17
Train function
Loss = 6.4624e-04, PNorm = 44.0894, GNorm = 0.4167, lr_0 = 7.0114e-04
Loss = 6.5786e-04, PNorm = 44.1052, GNorm = 0.5894, lr_0 = 7.0041e-04
Loss = 6.1996e-04, PNorm = 44.1219, GNorm = 0.4721, lr_0 = 6.9968e-04
Loss = 6.0753e-04, PNorm = 44.1320, GNorm = 0.4380, lr_0 = 6.9895e-04
Loss = 6.4218e-04, PNorm = 44.1426, GNorm = 0.5368, lr_0 = 6.9822e-04
Loss = 6.3367e-04, PNorm = 44.1539, GNorm = 0.3774, lr_0 = 6.9749e-04
Loss = 6.7488e-04, PNorm = 44.1658, GNorm = 0.6569, lr_0 = 6.9676e-04
Loss = 7.0951e-04, PNorm = 44.1806, GNorm = 0.6441, lr_0 = 6.9603e-04
Loss = 8.5691e-04, PNorm = 44.1931, GNorm = 0.4028, lr_0 = 6.9531e-04
Loss = 7.6968e-04, PNorm = 44.2111, GNorm = 0.6574, lr_0 = 6.9458e-04
Loss = 7.5327e-04, PNorm = 44.2278, GNorm = 0.5687, lr_0 = 6.9386e-04
Loss = 6.9059e-04, PNorm = 44.2444, GNorm = 0.8352, lr_0 = 6.9313e-04
Loss = 6.9987e-04, PNorm = 44.2664, GNorm = 0.8024, lr_0 = 6.9241e-04
Loss = 8.3375e-04, PNorm = 44.2729, GNorm = 0.7893, lr_0 = 6.9169e-04
Loss = 7.8218e-04, PNorm = 44.2934, GNorm = 0.8069, lr_0 = 6.9096e-04
Loss = 7.8619e-04, PNorm = 44.3137, GNorm = 0.9435, lr_0 = 6.9024e-04
Loss = 9.0720e-04, PNorm = 44.3313, GNorm = 0.9903, lr_0 = 6.8952e-04
Loss = 6.8784e-04, PNorm = 44.3499, GNorm = 0.4446, lr_0 = 6.8880e-04
Loss = 7.6879e-04, PNorm = 44.3720, GNorm = 0.4330, lr_0 = 6.8808e-04
Loss = 7.1877e-04, PNorm = 44.3859, GNorm = 0.7156, lr_0 = 6.8737e-04
Loss = 7.1866e-04, PNorm = 44.3993, GNorm = 0.3695, lr_0 = 6.8665e-04
Loss = 8.1299e-04, PNorm = 44.4099, GNorm = 1.0312, lr_0 = 6.8593e-04
Validation rmse logD = 0.617381
Validation R2 logD = 0.736012
Validation rmse logP = 0.498831
Validation R2 logP = 0.927782
Epoch 18
Train function
Loss = 7.5274e-04, PNorm = 44.4289, GNorm = 1.1142, lr_0 = 6.8514e-04
Loss = 6.7539e-04, PNorm = 44.4488, GNorm = 0.5230, lr_0 = 6.8443e-04
Loss = 7.6949e-04, PNorm = 44.4647, GNorm = 1.0347, lr_0 = 6.8372e-04
Loss = 5.7904e-04, PNorm = 44.4717, GNorm = 0.8394, lr_0 = 6.8300e-04
Loss = 6.3402e-04, PNorm = 44.4913, GNorm = 0.4241, lr_0 = 6.8229e-04
Loss = 7.1960e-04, PNorm = 44.5049, GNorm = 1.1647, lr_0 = 6.8158e-04
Loss = 6.9201e-04, PNorm = 44.5205, GNorm = 0.6760, lr_0 = 6.8087e-04
Loss = 6.2452e-04, PNorm = 44.5358, GNorm = 0.7004, lr_0 = 6.8015e-04
Loss = 5.8012e-04, PNorm = 44.5423, GNorm = 0.5084, lr_0 = 6.7944e-04
Loss = 6.0812e-04, PNorm = 44.5584, GNorm = 0.3855, lr_0 = 6.7874e-04
Loss = 8.0427e-04, PNorm = 44.5721, GNorm = 0.7354, lr_0 = 6.7803e-04
Loss = 5.9476e-04, PNorm = 44.5875, GNorm = 0.4157, lr_0 = 6.7732e-04
Loss = 6.7159e-04, PNorm = 44.6025, GNorm = 0.5538, lr_0 = 6.7661e-04
Loss = 6.2941e-04, PNorm = 44.6188, GNorm = 1.3361, lr_0 = 6.7591e-04
Loss = 5.4700e-04, PNorm = 44.6308, GNorm = 0.7576, lr_0 = 6.7520e-04
Loss = 6.8991e-04, PNorm = 44.6447, GNorm = 1.0815, lr_0 = 6.7450e-04
Loss = 7.8131e-04, PNorm = 44.6648, GNorm = 0.6306, lr_0 = 6.7379e-04
Loss = 8.4204e-04, PNorm = 44.6870, GNorm = 0.5073, lr_0 = 6.7309e-04
Loss = 8.5798e-04, PNorm = 44.7037, GNorm = 0.8229, lr_0 = 6.7239e-04
Loss = 6.6513e-04, PNorm = 44.7175, GNorm = 0.4481, lr_0 = 6.7168e-04
Loss = 9.4441e-04, PNorm = 44.7307, GNorm = 0.7165, lr_0 = 6.7098e-04
Loss = 7.9447e-04, PNorm = 44.7524, GNorm = 0.9154, lr_0 = 6.7028e-04
Loss = 7.4658e-04, PNorm = 44.7685, GNorm = 0.5152, lr_0 = 6.6958e-04
Validation rmse logD = 0.581809
Validation R2 logD = 0.765556
Validation rmse logP = 0.485748
Validation R2 logP = 0.931520
Epoch 19
Train function
Loss = 5.8335e-04, PNorm = 44.7877, GNorm = 0.3958, lr_0 = 6.6889e-04
Loss = 6.1851e-04, PNorm = 44.8009, GNorm = 1.3062, lr_0 = 6.6819e-04
Loss = 7.0115e-04, PNorm = 44.8150, GNorm = 0.6872, lr_0 = 6.6749e-04
Loss = 5.7359e-04, PNorm = 44.8338, GNorm = 0.3524, lr_0 = 6.6679e-04
Loss = 5.6633e-04, PNorm = 44.8486, GNorm = 0.4712, lr_0 = 6.6610e-04
Loss = 5.9522e-04, PNorm = 44.8563, GNorm = 0.5634, lr_0 = 6.6540e-04
Loss = 7.5596e-04, PNorm = 44.8726, GNorm = 1.2979, lr_0 = 6.6471e-04
Loss = 5.2980e-04, PNorm = 44.8914, GNorm = 0.3218, lr_0 = 6.6401e-04
Loss = 7.2007e-04, PNorm = 44.9071, GNorm = 0.6162, lr_0 = 6.6332e-04
Loss = 5.5753e-04, PNorm = 44.9231, GNorm = 0.3669, lr_0 = 6.6263e-04
Loss = 5.5780e-04, PNorm = 44.9355, GNorm = 0.8475, lr_0 = 6.6194e-04
Loss = 6.4389e-04, PNorm = 44.9459, GNorm = 0.5799, lr_0 = 6.6125e-04
Loss = 5.4962e-04, PNorm = 44.9563, GNorm = 0.4559, lr_0 = 6.6056e-04
Loss = 5.2280e-04, PNorm = 44.9694, GNorm = 0.7376, lr_0 = 6.5987e-04
Loss = 8.2267e-04, PNorm = 44.9809, GNorm = 1.0112, lr_0 = 6.5918e-04
Loss = 7.9658e-04, PNorm = 44.9947, GNorm = 0.6056, lr_0 = 6.5849e-04
Loss = 7.3518e-04, PNorm = 45.0160, GNorm = 0.6144, lr_0 = 6.5780e-04
Loss = 6.2256e-04, PNorm = 45.0360, GNorm = 0.3870, lr_0 = 6.5712e-04
Loss = 6.3070e-04, PNorm = 45.0547, GNorm = 0.5266, lr_0 = 6.5643e-04
Loss = 5.9264e-04, PNorm = 45.0692, GNorm = 0.4296, lr_0 = 6.5574e-04
Loss = 6.9274e-04, PNorm = 45.0771, GNorm = 0.5251, lr_0 = 6.5506e-04
Loss = 6.8096e-04, PNorm = 45.0900, GNorm = 0.6429, lr_0 = 6.5438e-04
Validation rmse logD = 0.585374
Validation R2 logD = 0.762674
Validation rmse logP = 0.478441
Validation R2 logP = 0.933565
Epoch 20
Train function
Loss = 6.6194e-04, PNorm = 45.1015, GNorm = 0.7227, lr_0 = 6.5363e-04
Loss = 6.7327e-04, PNorm = 45.1171, GNorm = 0.6728, lr_0 = 6.5294e-04
Loss = 6.4515e-04, PNorm = 45.1308, GNorm = 0.6240, lr_0 = 6.5226e-04
Loss = 6.3544e-04, PNorm = 45.1500, GNorm = 0.3325, lr_0 = 6.5158e-04
Loss = 5.0147e-04, PNorm = 45.1633, GNorm = 0.5248, lr_0 = 6.5090e-04
Loss = 5.5426e-04, PNorm = 45.1790, GNorm = 0.5037, lr_0 = 6.5022e-04
Loss = 5.6588e-04, PNorm = 45.1938, GNorm = 0.7628, lr_0 = 6.4954e-04
Loss = 6.0119e-04, PNorm = 45.2098, GNorm = 0.6039, lr_0 = 6.4886e-04
Loss = 5.9426e-04, PNorm = 45.2217, GNorm = 0.5659, lr_0 = 6.4819e-04
Loss = 5.7975e-04, PNorm = 45.2348, GNorm = 0.3134, lr_0 = 6.4751e-04
Loss = 6.8013e-04, PNorm = 45.2475, GNorm = 0.6437, lr_0 = 6.4684e-04
Loss = 6.9361e-04, PNorm = 45.2585, GNorm = 0.7789, lr_0 = 6.4616e-04
Loss = 6.8537e-04, PNorm = 45.2719, GNorm = 0.7531, lr_0 = 6.4549e-04
Loss = 6.6051e-04, PNorm = 45.2862, GNorm = 0.3762, lr_0 = 6.4481e-04
Loss = 7.2464e-04, PNorm = 45.3005, GNorm = 0.5686, lr_0 = 6.4414e-04
Loss = 5.7611e-04, PNorm = 45.3136, GNorm = 0.4582, lr_0 = 6.4347e-04
Loss = 6.0900e-04, PNorm = 45.3299, GNorm = 0.3993, lr_0 = 6.4280e-04
Loss = 7.1712e-04, PNorm = 45.3498, GNorm = 0.4502, lr_0 = 6.4212e-04
Loss = 5.8449e-04, PNorm = 45.3722, GNorm = 0.4097, lr_0 = 6.4145e-04
Loss = 6.0274e-04, PNorm = 45.3896, GNorm = 0.6104, lr_0 = 6.4078e-04
Loss = 4.8248e-04, PNorm = 45.3982, GNorm = 0.2963, lr_0 = 6.4012e-04
Loss = 5.9596e-04, PNorm = 45.4090, GNorm = 1.1253, lr_0 = 6.3945e-04
Loss = 8.4717e-04, PNorm = 45.4274, GNorm = 0.4900, lr_0 = 6.3878e-04
Validation rmse logD = 0.637329
Validation R2 logD = 0.718677
Validation rmse logP = 0.477791
Validation R2 logP = 0.933745
Epoch 21
Train function
Loss = 6.4168e-04, PNorm = 45.4419, GNorm = 0.9883, lr_0 = 6.3811e-04
Loss = 7.1567e-04, PNorm = 45.4646, GNorm = 0.4755, lr_0 = 6.3745e-04
Loss = 5.2640e-04, PNorm = 45.4825, GNorm = 0.4488, lr_0 = 6.3678e-04
Loss = 5.6541e-04, PNorm = 45.4936, GNorm = 0.5917, lr_0 = 6.3612e-04
Loss = 4.6955e-04, PNorm = 45.5078, GNorm = 0.6719, lr_0 = 6.3545e-04
Loss = 4.7448e-04, PNorm = 45.5236, GNorm = 0.5321, lr_0 = 6.3479e-04
Loss = 5.2713e-04, PNorm = 45.5290, GNorm = 0.7279, lr_0 = 6.3413e-04
Loss = 4.9380e-04, PNorm = 45.5391, GNorm = 0.6301, lr_0 = 6.3347e-04
Loss = 4.8722e-04, PNorm = 45.5497, GNorm = 0.4147, lr_0 = 6.3280e-04
Loss = 5.4666e-04, PNorm = 45.5607, GNorm = 0.9367, lr_0 = 6.3214e-04
Loss = 5.4677e-04, PNorm = 45.5758, GNorm = 0.9055, lr_0 = 6.3148e-04
Loss = 6.3227e-04, PNorm = 45.5878, GNorm = 0.8230, lr_0 = 6.3083e-04
Loss = 5.7761e-04, PNorm = 45.6022, GNorm = 0.5733, lr_0 = 6.3017e-04
Loss = 6.0076e-04, PNorm = 45.6173, GNorm = 0.5479, lr_0 = 6.2951e-04
Loss = 5.4856e-04, PNorm = 45.6296, GNorm = 0.6798, lr_0 = 6.2885e-04
Loss = 6.1575e-04, PNorm = 45.6448, GNorm = 0.8843, lr_0 = 6.2820e-04
Loss = 6.1010e-04, PNorm = 45.6627, GNorm = 0.7639, lr_0 = 6.2754e-04
Loss = 6.1624e-04, PNorm = 45.6756, GNorm = 0.7904, lr_0 = 6.2689e-04
Loss = 6.6391e-04, PNorm = 45.6856, GNorm = 0.4273, lr_0 = 6.2623e-04
Loss = 7.9593e-04, PNorm = 45.6994, GNorm = 1.4799, lr_0 = 6.2558e-04
Loss = 6.9828e-04, PNorm = 45.7125, GNorm = 0.5725, lr_0 = 6.2492e-04
Loss = 6.4697e-04, PNorm = 45.7316, GNorm = 0.3862, lr_0 = 6.2427e-04
Loss = 6.7392e-04, PNorm = 45.7493, GNorm = 0.7346, lr_0 = 6.2362e-04
Loss = 6.6760e-04, PNorm = 45.7504, GNorm = 0.5341, lr_0 = 6.2356e-04
Validation rmse logD = 0.589563
Validation R2 logD = 0.759265
Validation rmse logP = 0.481887
Validation R2 logP = 0.932604
Epoch 22
Train function
Loss = 5.9229e-04, PNorm = 45.7659, GNorm = 0.5189, lr_0 = 6.2290e-04
Loss = 4.2418e-04, PNorm = 45.7775, GNorm = 0.3329, lr_0 = 6.2225e-04
Loss = 4.7569e-04, PNorm = 45.7860, GNorm = 0.4768, lr_0 = 6.2161e-04
Loss = 5.4433e-04, PNorm = 45.8055, GNorm = 0.2904, lr_0 = 6.2096e-04
Loss = 4.9225e-04, PNorm = 45.8206, GNorm = 0.9882, lr_0 = 6.2031e-04
Loss = 6.0099e-04, PNorm = 45.8277, GNorm = 0.4504, lr_0 = 6.1966e-04
Loss = 3.9825e-04, PNorm = 45.8360, GNorm = 0.3919, lr_0 = 6.1901e-04
Loss = 4.1220e-04, PNorm = 45.8487, GNorm = 0.2119, lr_0 = 6.1837e-04
Loss = 5.1189e-04, PNorm = 45.8580, GNorm = 0.9234, lr_0 = 6.1772e-04
Loss = 6.1962e-04, PNorm = 45.8719, GNorm = 0.7469, lr_0 = 6.1708e-04
Loss = 4.9295e-04, PNorm = 45.8870, GNorm = 0.5437, lr_0 = 6.1643e-04
Loss = 6.0868e-04, PNorm = 45.9040, GNorm = 0.3078, lr_0 = 6.1579e-04
Loss = 4.4226e-04, PNorm = 45.9154, GNorm = 0.5165, lr_0 = 6.1515e-04
Loss = 4.8718e-04, PNorm = 45.9250, GNorm = 0.5299, lr_0 = 6.1451e-04
Loss = 4.7227e-04, PNorm = 45.9378, GNorm = 0.5713, lr_0 = 6.1386e-04
Loss = 5.6663e-04, PNorm = 45.9509, GNorm = 0.5459, lr_0 = 6.1322e-04
Loss = 4.9143e-04, PNorm = 45.9646, GNorm = 0.5033, lr_0 = 6.1258e-04
Loss = 4.9968e-04, PNorm = 45.9763, GNorm = 0.4744, lr_0 = 6.1194e-04
Loss = 5.4888e-04, PNorm = 45.9859, GNorm = 0.5334, lr_0 = 6.1131e-04
Loss = 6.0247e-04, PNorm = 46.0002, GNorm = 0.7411, lr_0 = 6.1067e-04
Loss = 5.4688e-04, PNorm = 46.0093, GNorm = 0.4678, lr_0 = 6.1003e-04
Loss = 5.5225e-04, PNorm = 46.0237, GNorm = 0.7036, lr_0 = 6.0939e-04
Validation rmse logD = 0.607377
Validation R2 logD = 0.744498
Validation rmse logP = 0.478886
Validation R2 logP = 0.933441
Epoch 23
Train function
Loss = 4.4282e-04, PNorm = 46.0413, GNorm = 0.4292, lr_0 = 6.0876e-04
Loss = 5.1712e-04, PNorm = 46.0541, GNorm = 0.3637, lr_0 = 6.0812e-04
Loss = 4.0448e-04, PNorm = 46.0654, GNorm = 0.4171, lr_0 = 6.0749e-04
Loss = 3.9911e-04, PNorm = 46.0737, GNorm = 0.3088, lr_0 = 6.0685e-04
Loss = 3.9606e-04, PNorm = 46.0867, GNorm = 0.6003, lr_0 = 6.0622e-04
Loss = 4.8102e-04, PNorm = 46.0981, GNorm = 0.7448, lr_0 = 6.0559e-04
Loss = 4.5497e-04, PNorm = 46.1090, GNorm = 0.9868, lr_0 = 6.0496e-04
Loss = 5.1398e-04, PNorm = 46.1207, GNorm = 0.3564, lr_0 = 6.0432e-04
Loss = 3.9427e-04, PNorm = 46.1326, GNorm = 0.4631, lr_0 = 6.0369e-04
Loss = 4.4741e-04, PNorm = 46.1440, GNorm = 0.5877, lr_0 = 6.0306e-04
Loss = 4.7365e-04, PNorm = 46.1575, GNorm = 1.0040, lr_0 = 6.0243e-04
Loss = 4.7003e-04, PNorm = 46.1686, GNorm = 0.8625, lr_0 = 6.0180e-04
Loss = 5.5143e-04, PNorm = 46.1888, GNorm = 0.4683, lr_0 = 6.0118e-04
Loss = 6.9372e-04, PNorm = 46.2043, GNorm = 0.8377, lr_0 = 6.0055e-04
Loss = 5.5030e-04, PNorm = 46.2235, GNorm = 0.3736, lr_0 = 5.9992e-04
Loss = 6.0443e-04, PNorm = 46.2366, GNorm = 0.6969, lr_0 = 5.9930e-04
Loss = 5.9575e-04, PNorm = 46.2500, GNorm = 0.8470, lr_0 = 5.9867e-04
Loss = 7.6418e-04, PNorm = 46.2682, GNorm = 0.6476, lr_0 = 5.9805e-04
Loss = 5.7998e-04, PNorm = 46.2802, GNorm = 1.1247, lr_0 = 5.9742e-04
Loss = 6.1119e-04, PNorm = 46.2962, GNorm = 0.7792, lr_0 = 5.9680e-04
Loss = 4.6595e-04, PNorm = 46.3127, GNorm = 0.3677, lr_0 = 5.9618e-04
Loss = 6.0228e-04, PNorm = 46.3275, GNorm = 0.3457, lr_0 = 5.9555e-04
Loss = 4.7832e-04, PNorm = 46.3343, GNorm = 0.3317, lr_0 = 5.9493e-04
Validation rmse logD = 0.586434
Validation R2 logD = 0.761814
Validation rmse logP = 0.463575
Validation R2 logP = 0.937629
Epoch 24
Train function
Loss = 3.6635e-04, PNorm = 46.3442, GNorm = 0.4019, lr_0 = 5.9425e-04
Loss = 4.4356e-04, PNorm = 46.3537, GNorm = 0.4373, lr_0 = 5.9363e-04
Loss = 4.9563e-04, PNorm = 46.3639, GNorm = 0.7222, lr_0 = 5.9301e-04
Loss = 4.0541e-04, PNorm = 46.3769, GNorm = 0.5401, lr_0 = 5.9239e-04
Loss = 4.4627e-04, PNorm = 46.3880, GNorm = 0.5429, lr_0 = 5.9177e-04
Loss = 4.4542e-04, PNorm = 46.3983, GNorm = 0.3884, lr_0 = 5.9115e-04
Loss = 3.6886e-04, PNorm = 46.4122, GNorm = 0.4601, lr_0 = 5.9054e-04
Loss = 4.8879e-04, PNorm = 46.4259, GNorm = 0.8795, lr_0 = 5.8992e-04
Loss = 5.3085e-04, PNorm = 46.4320, GNorm = 0.6118, lr_0 = 5.8931e-04
Loss = 4.9891e-04, PNorm = 46.4420, GNorm = 1.0466, lr_0 = 5.8869e-04
Loss = 5.1631e-04, PNorm = 46.4575, GNorm = 0.3976, lr_0 = 5.8808e-04
Loss = 5.2034e-04, PNorm = 46.4801, GNorm = 0.3795, lr_0 = 5.8746e-04
Loss = 5.2552e-04, PNorm = 46.4915, GNorm = 0.6892, lr_0 = 5.8685e-04
Loss = 5.9972e-04, PNorm = 46.5104, GNorm = 0.6704, lr_0 = 5.8624e-04
Loss = 4.7862e-04, PNorm = 46.5260, GNorm = 0.6630, lr_0 = 5.8562e-04
Loss = 4.1442e-04, PNorm = 46.5393, GNorm = 0.4919, lr_0 = 5.8501e-04
Loss = 5.1781e-04, PNorm = 46.5552, GNorm = 0.5741, lr_0 = 5.8440e-04
Loss = 4.3137e-04, PNorm = 46.5655, GNorm = 0.4299, lr_0 = 5.8379e-04
Loss = 4.2711e-04, PNorm = 46.5748, GNorm = 0.4719, lr_0 = 5.8318e-04
Loss = 4.2218e-04, PNorm = 46.5861, GNorm = 0.5436, lr_0 = 5.8257e-04
Loss = 3.8814e-04, PNorm = 46.5964, GNorm = 0.4639, lr_0 = 5.8197e-04
Loss = 4.6715e-04, PNorm = 46.6044, GNorm = 0.5934, lr_0 = 5.8136e-04
Validation rmse logD = 0.597729
Validation R2 logD = 0.752550
Validation rmse logP = 0.479697
Validation R2 logP = 0.933216
Epoch 25
Train function
Loss = 4.9250e-04, PNorm = 46.6083, GNorm = 0.6848, lr_0 = 5.8075e-04
Loss = 4.4421e-04, PNorm = 46.6234, GNorm = 0.3298, lr_0 = 5.8015e-04
Loss = 3.8177e-04, PNorm = 46.6298, GNorm = 0.5936, lr_0 = 5.7954e-04
Loss = 4.9227e-04, PNorm = 46.6425, GNorm = 0.4379, lr_0 = 5.7894e-04
Loss = 3.6418e-04, PNorm = 46.6536, GNorm = 0.8196, lr_0 = 5.7833e-04
Loss = 4.4619e-04, PNorm = 46.6631, GNorm = 0.6051, lr_0 = 5.7773e-04
Loss = 3.4666e-04, PNorm = 46.6735, GNorm = 0.2294, lr_0 = 5.7712e-04
Loss = 4.6632e-04, PNorm = 46.6815, GNorm = 0.4154, lr_0 = 5.7652e-04
Loss = 3.9577e-04, PNorm = 46.6978, GNorm = 0.3488, lr_0 = 5.7592e-04
Loss = 4.1215e-04, PNorm = 46.7105, GNorm = 0.3285, lr_0 = 5.7532e-04
Loss = 3.7437e-04, PNorm = 46.7201, GNorm = 0.4407, lr_0 = 5.7472e-04
Loss = 4.3606e-04, PNorm = 46.7319, GNorm = 0.5349, lr_0 = 5.7412e-04
Loss = 3.6499e-04, PNorm = 46.7415, GNorm = 0.4600, lr_0 = 5.7352e-04
Loss = 4.8591e-04, PNorm = 46.7461, GNorm = 0.7137, lr_0 = 5.7292e-04
Loss = 5.2280e-04, PNorm = 46.7593, GNorm = 0.8900, lr_0 = 5.7232e-04
Loss = 3.6839e-04, PNorm = 46.7724, GNorm = 0.3919, lr_0 = 5.7173e-04
Loss = 4.4118e-04, PNorm = 46.7782, GNorm = 0.4787, lr_0 = 5.7113e-04
Loss = 3.7742e-04, PNorm = 46.7885, GNorm = 0.5534, lr_0 = 5.7053e-04
Loss = 4.4794e-04, PNorm = 46.7971, GNorm = 0.4545, lr_0 = 5.6994e-04
Loss = 4.0541e-04, PNorm = 46.8035, GNorm = 0.5230, lr_0 = 5.6934e-04
Loss = 5.0706e-04, PNorm = 46.8164, GNorm = 0.4559, lr_0 = 5.6875e-04
Loss = 4.7464e-04, PNorm = 46.8267, GNorm = 0.6440, lr_0 = 5.6816e-04
Loss = 4.5113e-04, PNorm = 46.8415, GNorm = 0.6458, lr_0 = 5.6756e-04
Validation rmse logD = 0.585267
Validation R2 logD = 0.762761
Validation rmse logP = 0.485050
Validation R2 logP = 0.931717
Epoch 26
Train function
Loss = 3.7441e-04, PNorm = 46.8534, GNorm = 0.5846, lr_0 = 5.6691e-04
Loss = 4.4652e-04, PNorm = 46.8644, GNorm = 0.3825, lr_0 = 5.6632e-04
Loss = 3.8875e-04, PNorm = 46.8753, GNorm = 0.4239, lr_0 = 5.6573e-04
Loss = 3.0058e-04, PNorm = 46.8885, GNorm = 0.5675, lr_0 = 5.6514e-04
Loss = 3.3739e-04, PNorm = 46.8971, GNorm = 0.5030, lr_0 = 5.6455e-04
Loss = 3.4353e-04, PNorm = 46.9021, GNorm = 0.5428, lr_0 = 5.6396e-04
Loss = 4.1051e-04, PNorm = 46.9130, GNorm = 0.5254, lr_0 = 5.6337e-04
Loss = 3.8222e-04, PNorm = 46.9231, GNorm = 0.6111, lr_0 = 5.6278e-04
Loss = 3.4907e-04, PNorm = 46.9342, GNorm = 0.5275, lr_0 = 5.6219e-04
Loss = 3.6788e-04, PNorm = 46.9451, GNorm = 0.7681, lr_0 = 5.6161e-04
Loss = 3.3430e-04, PNorm = 46.9539, GNorm = 0.3388, lr_0 = 5.6102e-04
Loss = 3.9789e-04, PNorm = 46.9643, GNorm = 0.4941, lr_0 = 5.6044e-04
Loss = 4.1228e-04, PNorm = 46.9739, GNorm = 0.5075, lr_0 = 5.5985e-04
Loss = 3.6180e-04, PNorm = 46.9885, GNorm = 0.2933, lr_0 = 5.5927e-04
Loss = 3.4262e-04, PNorm = 46.9964, GNorm = 0.4755, lr_0 = 5.5868e-04
Loss = 4.7827e-04, PNorm = 47.0093, GNorm = 0.7097, lr_0 = 5.5810e-04
Loss = 4.4128e-04, PNorm = 47.0180, GNorm = 0.2951, lr_0 = 5.5752e-04
Loss = 3.8138e-04, PNorm = 47.0289, GNorm = 0.4753, lr_0 = 5.5694e-04
Loss = 5.5784e-04, PNorm = 47.0365, GNorm = 0.7985, lr_0 = 5.5635e-04
Loss = 5.0702e-04, PNorm = 47.0455, GNorm = 0.5154, lr_0 = 5.5577e-04
Loss = 5.3627e-04, PNorm = 47.0546, GNorm = 0.6930, lr_0 = 5.5519e-04
Loss = 4.9862e-04, PNorm = 47.0744, GNorm = 0.6151, lr_0 = 5.5461e-04
Validation rmse logD = 0.599951
Validation R2 logD = 0.750707
Validation rmse logP = 0.476629
Validation R2 logP = 0.934067
Epoch 27
Train function
Loss = 3.6511e-04, PNorm = 47.0889, GNorm = 0.3408, lr_0 = 5.5398e-04
Loss = 3.8652e-04, PNorm = 47.0992, GNorm = 0.3094, lr_0 = 5.5340e-04
Loss = 3.7550e-04, PNorm = 47.1098, GNorm = 0.8678, lr_0 = 5.5282e-04
Loss = 3.7868e-04, PNorm = 47.1226, GNorm = 0.6421, lr_0 = 5.5224e-04
Loss = 3.9978e-04, PNorm = 47.1332, GNorm = 0.4424, lr_0 = 5.5167e-04
Loss = 3.4983e-04, PNorm = 47.1453, GNorm = 0.4784, lr_0 = 5.5109e-04
Loss = 3.2443e-04, PNorm = 47.1545, GNorm = 0.6305, lr_0 = 5.5052e-04
Loss = 4.3565e-04, PNorm = 47.1640, GNorm = 0.9436, lr_0 = 5.4994e-04
Loss = 5.0492e-04, PNorm = 47.1759, GNorm = 0.5455, lr_0 = 5.4937e-04
Loss = 4.1034e-04, PNorm = 47.1882, GNorm = 0.5984, lr_0 = 5.4880e-04
Loss = 3.5436e-04, PNorm = 47.2027, GNorm = 0.4171, lr_0 = 5.4822e-04
Loss = 4.6932e-04, PNorm = 47.2113, GNorm = 0.3354, lr_0 = 5.4765e-04
Loss = 4.6673e-04, PNorm = 47.2246, GNorm = 0.3329, lr_0 = 5.4708e-04
Loss = 4.6181e-04, PNorm = 47.2334, GNorm = 0.4454, lr_0 = 5.4651e-04
Loss = 4.5260e-04, PNorm = 47.2443, GNorm = 0.4162, lr_0 = 5.4594e-04
Loss = 3.8102e-04, PNorm = 47.2550, GNorm = 0.5596, lr_0 = 5.4537e-04
Loss = 3.4242e-04, PNorm = 47.2621, GNorm = 0.5797, lr_0 = 5.4480e-04
Loss = 3.7152e-04, PNorm = 47.2726, GNorm = 0.3144, lr_0 = 5.4423e-04
Loss = 3.8286e-04, PNorm = 47.2846, GNorm = 0.6738, lr_0 = 5.4366e-04
Loss = 3.6709e-04, PNorm = 47.2954, GNorm = 0.3151, lr_0 = 5.4309e-04
Loss = 4.1454e-04, PNorm = 47.3080, GNorm = 0.3224, lr_0 = 5.4253e-04
Loss = 3.4107e-04, PNorm = 47.3261, GNorm = 0.4664, lr_0 = 5.4196e-04
Loss = 3.5700e-04, PNorm = 47.3364, GNorm = 0.3196, lr_0 = 5.4140e-04
Validation rmse logD = 0.588215
Validation R2 logD = 0.760365
Validation rmse logP = 0.469835
Validation R2 logP = 0.935933
Epoch 28
Train function
Loss = 2.9960e-04, PNorm = 47.3427, GNorm = 0.4017, lr_0 = 5.4083e-04
Loss = 3.0822e-04, PNorm = 47.3529, GNorm = 0.5076, lr_0 = 5.4027e-04
Loss = 3.2467e-04, PNorm = 47.3651, GNorm = 0.3387, lr_0 = 5.3970e-04
Loss = 2.7341e-04, PNorm = 47.3729, GNorm = 0.4016, lr_0 = 5.3914e-04
Loss = 2.7192e-04, PNorm = 47.3782, GNorm = 0.4754, lr_0 = 5.3858e-04
Loss = 2.7352e-04, PNorm = 47.3870, GNorm = 0.2765, lr_0 = 5.3801e-04
Loss = 3.9469e-04, PNorm = 47.3954, GNorm = 0.6269, lr_0 = 5.3745e-04
Loss = 3.4165e-04, PNorm = 47.4036, GNorm = 0.6344, lr_0 = 5.3689e-04
Loss = 3.2803e-04, PNorm = 47.4132, GNorm = 0.3468, lr_0 = 5.3633e-04
Loss = 3.2208e-04, PNorm = 47.4219, GNorm = 0.4867, lr_0 = 5.3577e-04
Loss = 3.1146e-04, PNorm = 47.4283, GNorm = 0.3580, lr_0 = 5.3521e-04
Loss = 3.2785e-04, PNorm = 47.4355, GNorm = 0.5357, lr_0 = 5.3465e-04
Loss = 4.3901e-04, PNorm = 47.4479, GNorm = 0.4005, lr_0 = 5.3410e-04
Loss = 3.3190e-04, PNorm = 47.4572, GNorm = 0.3469, lr_0 = 5.3354e-04
Loss = 2.8086e-04, PNorm = 47.4694, GNorm = 0.2557, lr_0 = 5.3298e-04
Loss = 2.9207e-04, PNorm = 47.4789, GNorm = 0.3858, lr_0 = 5.3243e-04
Loss = 3.6004e-04, PNorm = 47.4876, GNorm = 0.6014, lr_0 = 5.3187e-04
Loss = 3.3528e-04, PNorm = 47.4948, GNorm = 0.3511, lr_0 = 5.3131e-04
Loss = 2.8351e-04, PNorm = 47.5036, GNorm = 0.3222, lr_0 = 5.3076e-04
Loss = 3.2561e-04, PNorm = 47.5097, GNorm = 0.4274, lr_0 = 5.3021e-04
Loss = 5.2289e-04, PNorm = 47.5178, GNorm = 0.5484, lr_0 = 5.2965e-04
Loss = 4.4802e-04, PNorm = 47.5312, GNorm = 0.3150, lr_0 = 5.2910e-04
Validation rmse logD = 0.582381
Validation R2 logD = 0.765095
Validation rmse logP = 0.464314
Validation R2 logP = 0.937430
Epoch 29
Train function
Loss = 2.6903e-04, PNorm = 47.5399, GNorm = 0.3519, lr_0 = 5.2849e-04
Loss = 3.0924e-04, PNorm = 47.5535, GNorm = 0.2924, lr_0 = 5.2794e-04
Loss = 3.8613e-04, PNorm = 47.5624, GNorm = 0.3816, lr_0 = 5.2739e-04
Loss = 2.9658e-04, PNorm = 47.5693, GNorm = 0.3741, lr_0 = 5.2684e-04
Loss = 3.0961e-04, PNorm = 47.5803, GNorm = 0.3366, lr_0 = 5.2629e-04
Loss = 3.1305e-04, PNorm = 47.5902, GNorm = 0.5184, lr_0 = 5.2574e-04
Loss = 3.9023e-04, PNorm = 47.6019, GNorm = 0.2764, lr_0 = 5.2519e-04
Loss = 4.3573e-04, PNorm = 47.6099, GNorm = 0.4238, lr_0 = 5.2464e-04
Loss = 3.0733e-04, PNorm = 47.6204, GNorm = 0.3692, lr_0 = 5.2410e-04
Loss = 3.1203e-04, PNorm = 47.6323, GNorm = 0.9944, lr_0 = 5.2355e-04
Loss = 3.6649e-04, PNorm = 47.6366, GNorm = 0.3338, lr_0 = 5.2300e-04
Loss = 4.4480e-04, PNorm = 47.6468, GNorm = 0.9038, lr_0 = 5.2246e-04
Loss = 3.7434e-04, PNorm = 47.6625, GNorm = 0.3412, lr_0 = 5.2191e-04
Loss = 3.0088e-04, PNorm = 47.6756, GNorm = 0.3751, lr_0 = 5.2137e-04
Loss = 3.2148e-04, PNorm = 47.6864, GNorm = 0.3544, lr_0 = 5.2082e-04
Loss = 3.6770e-04, PNorm = 47.6964, GNorm = 0.7041, lr_0 = 5.2028e-04
Loss = 4.6199e-04, PNorm = 47.7063, GNorm = 0.7334, lr_0 = 5.1974e-04
Loss = 4.0011e-04, PNorm = 47.7143, GNorm = 0.3056, lr_0 = 5.1919e-04
Loss = 3.2545e-04, PNorm = 47.7216, GNorm = 0.4771, lr_0 = 5.1865e-04
Loss = 3.7299e-04, PNorm = 47.7323, GNorm = 0.3887, lr_0 = 5.1811e-04
Loss = 4.0506e-04, PNorm = 47.7404, GNorm = 0.6214, lr_0 = 5.1757e-04
Loss = 3.4623e-04, PNorm = 47.7503, GNorm = 0.4129, lr_0 = 5.1703e-04
Loss = 3.2740e-04, PNorm = 47.7601, GNorm = 0.3229, lr_0 = 5.1649e-04
Validation rmse logD = 0.592101
Validation R2 logD = 0.757188
Validation rmse logP = 0.481851
Validation R2 logP = 0.932614
Epoch 30
Train function
Loss = 3.0194e-04, PNorm = 47.7696, GNorm = 0.8998, lr_0 = 5.1595e-04
Loss = 3.3936e-04, PNorm = 47.7798, GNorm = 0.4159, lr_0 = 5.1541e-04
Loss = 3.6384e-04, PNorm = 47.7919, GNorm = 0.8805, lr_0 = 5.1487e-04
Loss = 3.1842e-04, PNorm = 47.8049, GNorm = 0.4531, lr_0 = 5.1434e-04
Loss = 2.3622e-04, PNorm = 47.8143, GNorm = 0.3298, lr_0 = 5.1380e-04
Loss = 3.0263e-04, PNorm = 47.8221, GNorm = 0.5001, lr_0 = 5.1326e-04
Loss = 2.7524e-04, PNorm = 47.8335, GNorm = 0.3110, lr_0 = 5.1273e-04
Loss = 3.1177e-04, PNorm = 47.8343, GNorm = 0.3544, lr_0 = 5.1219e-04
Loss = 2.8452e-04, PNorm = 47.8410, GNorm = 0.3175, lr_0 = 5.1166e-04
Loss = 3.0011e-04, PNorm = 47.8510, GNorm = 0.3459, lr_0 = 5.1112e-04
Loss = 2.4429e-04, PNorm = 47.8594, GNorm = 0.4893, lr_0 = 5.1059e-04
Loss = 3.2049e-04, PNorm = 47.8665, GNorm = 0.3985, lr_0 = 5.1006e-04
Loss = 2.5506e-04, PNorm = 47.8743, GNorm = 0.4013, lr_0 = 5.0953e-04
Loss = 2.4448e-04, PNorm = 47.8782, GNorm = 0.4378, lr_0 = 5.0899e-04
Loss = 3.6286e-04, PNorm = 47.8793, GNorm = 0.3620, lr_0 = 5.0846e-04
Loss = 2.9819e-04, PNorm = 47.8925, GNorm = 0.4732, lr_0 = 5.0793e-04
Loss = 2.8199e-04, PNorm = 47.9009, GNorm = 0.3006, lr_0 = 5.0740e-04
Loss = 3.4895e-04, PNorm = 47.9069, GNorm = 0.3338, lr_0 = 5.0687e-04
Loss = 3.0606e-04, PNorm = 47.9129, GNorm = 0.4296, lr_0 = 5.0634e-04
Loss = 2.8035e-04, PNorm = 47.9190, GNorm = 0.3340, lr_0 = 5.0581e-04
Loss = 2.8226e-04, PNorm = 47.9310, GNorm = 0.3830, lr_0 = 5.0529e-04
Loss = 2.9073e-04, PNorm = 47.9409, GNorm = 0.3001, lr_0 = 5.0476e-04
Validation rmse logD = 0.601512
Validation R2 logD = 0.749408
Validation rmse logP = 0.465544
Validation R2 logP = 0.937098
Epoch 31
Train function
Loss = 1.8010e-04, PNorm = 47.9485, GNorm = 0.2417, lr_0 = 5.0418e-04
Loss = 2.7466e-04, PNorm = 47.9524, GNorm = 0.2644, lr_0 = 5.0365e-04
Loss = 2.0955e-04, PNorm = 47.9586, GNorm = 0.3185, lr_0 = 5.0313e-04
Loss = 2.3817e-04, PNorm = 47.9651, GNorm = 0.3265, lr_0 = 5.0260e-04
Loss = 2.2453e-04, PNorm = 47.9765, GNorm = 0.2092, lr_0 = 5.0208e-04
Loss = 3.2653e-04, PNorm = 47.9858, GNorm = 0.5623, lr_0 = 5.0155e-04
Loss = 2.7303e-04, PNorm = 47.9948, GNorm = 0.4091, lr_0 = 5.0103e-04
Loss = 2.3016e-04, PNorm = 48.0050, GNorm = 0.4497, lr_0 = 5.0051e-04
Loss = 2.7283e-04, PNorm = 48.0104, GNorm = 0.4059, lr_0 = 4.9998e-04
Loss = 2.4117e-04, PNorm = 48.0159, GNorm = 0.3509, lr_0 = 4.9946e-04
Loss = 2.3698e-04, PNorm = 48.0229, GNorm = 0.4389, lr_0 = 4.9894e-04
Loss = 2.7192e-04, PNorm = 48.0281, GNorm = 0.3276, lr_0 = 4.9842e-04
Loss = 2.6521e-04, PNorm = 48.0344, GNorm = 0.4026, lr_0 = 4.9790e-04
Loss = 2.9178e-04, PNorm = 48.0430, GNorm = 0.4109, lr_0 = 4.9738e-04
Loss = 2.5226e-04, PNorm = 48.0497, GNorm = 0.3198, lr_0 = 4.9686e-04
Loss = 2.9467e-04, PNorm = 48.0583, GNorm = 0.4328, lr_0 = 4.9634e-04
Loss = 2.7993e-04, PNorm = 48.0666, GNorm = 0.2680, lr_0 = 4.9583e-04
Loss = 3.1511e-04, PNorm = 48.0747, GNorm = 0.4708, lr_0 = 4.9531e-04
Loss = 2.9664e-04, PNorm = 48.0852, GNorm = 0.4369, lr_0 = 4.9479e-04
Loss = 3.1477e-04, PNorm = 48.0903, GNorm = 0.5137, lr_0 = 4.9427e-04
Loss = 2.8152e-04, PNorm = 48.0981, GNorm = 0.4154, lr_0 = 4.9376e-04
Loss = 3.4248e-04, PNorm = 48.1093, GNorm = 0.2055, lr_0 = 4.9324e-04
Loss = 3.1252e-04, PNorm = 48.1156, GNorm = 0.3068, lr_0 = 4.9273e-04
Validation rmse logD = 0.584510
Validation R2 logD = 0.763374
Validation rmse logP = 0.465248
Validation R2 logP = 0.937178
Epoch 32
Train function
Loss = 1.9869e-04, PNorm = 48.1224, GNorm = 0.3006, lr_0 = 4.9221e-04
Loss = 2.0762e-04, PNorm = 48.1287, GNorm = 0.2731, lr_0 = 4.9170e-04
Loss = 1.7624e-04, PNorm = 48.1357, GNorm = 0.2694, lr_0 = 4.9119e-04
Loss = 2.7730e-04, PNorm = 48.1400, GNorm = 0.4843, lr_0 = 4.9067e-04
Loss = 3.2584e-04, PNorm = 48.1482, GNorm = 0.6744, lr_0 = 4.9016e-04
Loss = 2.7280e-04, PNorm = 48.1553, GNorm = 0.2342, lr_0 = 4.8965e-04
Loss = 2.9945e-04, PNorm = 48.1619, GNorm = 0.3216, lr_0 = 4.8914e-04
Loss = 2.5639e-04, PNorm = 48.1702, GNorm = 0.3286, lr_0 = 4.8863e-04
Loss = 2.5099e-04, PNorm = 48.1790, GNorm = 0.2826, lr_0 = 4.8812e-04
Loss = 3.0729e-04, PNorm = 48.1893, GNorm = 0.4208, lr_0 = 4.8761e-04
Loss = 2.5600e-04, PNorm = 48.1985, GNorm = 0.3462, lr_0 = 4.8710e-04
Loss = 2.9098e-04, PNorm = 48.2096, GNorm = 0.2732, lr_0 = 4.8659e-04
Loss = 2.6654e-04, PNorm = 48.2169, GNorm = 0.4217, lr_0 = 4.8608e-04
Loss = 2.4927e-04, PNorm = 48.2255, GNorm = 0.3330, lr_0 = 4.8558e-04
Loss = 3.1434e-04, PNorm = 48.2321, GNorm = 0.2930, lr_0 = 4.8507e-04
Loss = 2.2799e-04, PNorm = 48.2411, GNorm = 0.3347, lr_0 = 4.8456e-04
Loss = 3.2245e-04, PNorm = 48.2501, GNorm = 0.3400, lr_0 = 4.8406e-04
Loss = 2.5075e-04, PNorm = 48.2595, GNorm = 0.3181, lr_0 = 4.8355e-04
Loss = 2.7070e-04, PNorm = 48.2667, GNorm = 0.3715, lr_0 = 4.8305e-04
Loss = 2.5278e-04, PNorm = 48.2709, GNorm = 0.2865, lr_0 = 4.8254e-04
Loss = 3.1873e-04, PNorm = 48.2763, GNorm = 0.3131, lr_0 = 4.8204e-04
Loss = 2.7497e-04, PNorm = 48.2867, GNorm = 0.2266, lr_0 = 4.8154e-04
Loss = 2.8514e-04, PNorm = 48.2902, GNorm = 0.3809, lr_0 = 4.8104e-04
Loss = 5.3410e-04, PNorm = 48.2909, GNorm = 0.4691, lr_0 = 4.8098e-04
Validation rmse logD = 0.586572
Validation R2 logD = 0.761702
Validation rmse logP = 0.473113
Validation R2 logP = 0.935036
Epoch 33
Train function
Loss = 2.4764e-04, PNorm = 48.2993, GNorm = 0.4031, lr_0 = 4.8048e-04
Loss = 2.1700e-04, PNorm = 48.3092, GNorm = 0.6629, lr_0 = 4.7998e-04
Loss = 2.4587e-04, PNorm = 48.3190, GNorm = 0.3629, lr_0 = 4.7948e-04
Loss = 2.5952e-04, PNorm = 48.3300, GNorm = 0.3529, lr_0 = 4.7898e-04
Loss = 2.6218e-04, PNorm = 48.3362, GNorm = 0.2601, lr_0 = 4.7848e-04
Loss = 2.2429e-04, PNorm = 48.3411, GNorm = 0.3383, lr_0 = 4.7798e-04
Loss = 2.5079e-04, PNorm = 48.3488, GNorm = 0.5520, lr_0 = 4.7748e-04
Loss = 2.1157e-04, PNorm = 48.3573, GNorm = 0.3944, lr_0 = 4.7698e-04
Loss = 2.0247e-04, PNorm = 48.3692, GNorm = 0.2884, lr_0 = 4.7649e-04
Loss = 2.4539e-04, PNorm = 48.3764, GNorm = 0.6153, lr_0 = 4.7599e-04
Loss = 2.6720e-04, PNorm = 48.3808, GNorm = 0.4710, lr_0 = 4.7549e-04
Loss = 2.5819e-04, PNorm = 48.3923, GNorm = 0.1985, lr_0 = 4.7500e-04
Loss = 2.3169e-04, PNorm = 48.4038, GNorm = 0.2906, lr_0 = 4.7450e-04
Loss = 2.1893e-04, PNorm = 48.4073, GNorm = 0.2449, lr_0 = 4.7400e-04
Loss = 2.6332e-04, PNorm = 48.4138, GNorm = 0.5649, lr_0 = 4.7351e-04
Loss = 2.8058e-04, PNorm = 48.4199, GNorm = 0.5658, lr_0 = 4.7302e-04
Loss = 2.6582e-04, PNorm = 48.4305, GNorm = 0.4860, lr_0 = 4.7252e-04
Loss = 2.6154e-04, PNorm = 48.4368, GNorm = 0.2309, lr_0 = 4.7203e-04
Loss = 2.3150e-04, PNorm = 48.4460, GNorm = 0.4712, lr_0 = 4.7154e-04
Loss = 3.4057e-04, PNorm = 48.4576, GNorm = 0.5202, lr_0 = 4.7104e-04
Loss = 3.3602e-04, PNorm = 48.4629, GNorm = 0.3525, lr_0 = 4.7055e-04
Loss = 2.9868e-04, PNorm = 48.4687, GNorm = 0.3009, lr_0 = 4.7006e-04
Validation rmse logD = 0.585078
Validation R2 logD = 0.762915
Validation rmse logP = 0.476538
Validation R2 logP = 0.934092
Epoch 34
Train function
Loss = 2.3811e-04, PNorm = 48.4827, GNorm = 0.3060, lr_0 = 4.6957e-04
Loss = 2.5582e-04, PNorm = 48.4924, GNorm = 0.4407, lr_0 = 4.6908e-04
Loss = 2.5127e-04, PNorm = 48.5003, GNorm = 0.3802, lr_0 = 4.6859e-04
Loss = 2.1708e-04, PNorm = 48.5038, GNorm = 0.3268, lr_0 = 4.6810e-04
Loss = 2.5320e-04, PNorm = 48.5129, GNorm = 0.4121, lr_0 = 4.6761e-04
Loss = 2.1211e-04, PNorm = 48.5249, GNorm = 0.3288, lr_0 = 4.6712e-04
Loss = 2.2377e-04, PNorm = 48.5326, GNorm = 0.2015, lr_0 = 4.6664e-04
Loss = 2.3407e-04, PNorm = 48.5400, GNorm = 0.3553, lr_0 = 4.6615e-04
Loss = 2.3684e-04, PNorm = 48.5474, GNorm = 0.3798, lr_0 = 4.6566e-04
Loss = 2.3663e-04, PNorm = 48.5562, GNorm = 0.6333, lr_0 = 4.6518e-04
Loss = 2.3291e-04, PNorm = 48.5638, GNorm = 0.1860, lr_0 = 4.6469e-04
Loss = 2.2959e-04, PNorm = 48.5717, GNorm = 0.2940, lr_0 = 4.6421e-04
Loss = 2.1175e-04, PNorm = 48.5740, GNorm = 0.6013, lr_0 = 4.6372e-04
Loss = 2.5609e-04, PNorm = 48.5828, GNorm = 0.3670, lr_0 = 4.6324e-04
Loss = 2.8277e-04, PNorm = 48.5854, GNorm = 0.2638, lr_0 = 4.6276e-04
Loss = 2.3355e-04, PNorm = 48.5891, GNorm = 0.2175, lr_0 = 4.6227e-04
Loss = 2.3175e-04, PNorm = 48.5960, GNorm = 0.3983, lr_0 = 4.6179e-04
Loss = 2.7960e-04, PNorm = 48.6037, GNorm = 0.4706, lr_0 = 4.6131e-04
Loss = 3.0695e-04, PNorm = 48.6135, GNorm = 0.7041, lr_0 = 4.6083e-04
Loss = 2.6059e-04, PNorm = 48.6237, GNorm = 0.3800, lr_0 = 4.6035e-04
Loss = 2.2990e-04, PNorm = 48.6340, GNorm = 0.4230, lr_0 = 4.5987e-04
Loss = 3.2799e-04, PNorm = 48.6446, GNorm = 0.6101, lr_0 = 4.5939e-04
Loss = 2.6790e-04, PNorm = 48.6528, GNorm = 0.5907, lr_0 = 4.5891e-04
Validation rmse logD = 0.584067
Validation R2 logD = 0.763733
Validation rmse logP = 0.472547
Validation R2 logP = 0.935192
Epoch 35
Train function
Loss = 2.2095e-04, PNorm = 48.6584, GNorm = 0.2645, lr_0 = 4.5838e-04
Loss = 2.2332e-04, PNorm = 48.6655, GNorm = 0.3476, lr_0 = 4.5790e-04
Loss = 2.2063e-04, PNorm = 48.6715, GNorm = 0.6100, lr_0 = 4.5742e-04
Loss = 1.6493e-04, PNorm = 48.6796, GNorm = 0.2628, lr_0 = 4.5695e-04
Loss = 2.3834e-04, PNorm = 48.6889, GNorm = 0.4675, lr_0 = 4.5647e-04
Loss = 2.2355e-04, PNorm = 48.6912, GNorm = 0.2871, lr_0 = 4.5599e-04
Loss = 1.9734e-04, PNorm = 48.6953, GNorm = 0.3097, lr_0 = 4.5552e-04
Loss = 2.1163e-04, PNorm = 48.7004, GNorm = 0.4341, lr_0 = 4.5504e-04
Loss = 1.7570e-04, PNorm = 48.7057, GNorm = 0.2876, lr_0 = 4.5457e-04
Loss = 2.0755e-04, PNorm = 48.7136, GNorm = 0.4031, lr_0 = 4.5409e-04
Loss = 1.9372e-04, PNorm = 48.7211, GNorm = 0.5789, lr_0 = 4.5362e-04
Loss = 2.5682e-04, PNorm = 48.7298, GNorm = 0.4600, lr_0 = 4.5314e-04
Loss = 2.3219e-04, PNorm = 48.7366, GNorm = 0.3325, lr_0 = 4.5267e-04
Loss = 2.3805e-04, PNorm = 48.7435, GNorm = 0.4750, lr_0 = 4.5220e-04
Loss = 2.7524e-04, PNorm = 48.7535, GNorm = 0.6818, lr_0 = 4.5173e-04
Loss = 2.9206e-04, PNorm = 48.7620, GNorm = 0.3384, lr_0 = 4.5125e-04
Loss = 2.4664e-04, PNorm = 48.7664, GNorm = 0.2541, lr_0 = 4.5078e-04
Loss = 2.4098e-04, PNorm = 48.7761, GNorm = 0.2510, lr_0 = 4.5031e-04
Loss = 2.5183e-04, PNorm = 48.7855, GNorm = 0.3183, lr_0 = 4.4984e-04
Loss = 2.6127e-04, PNorm = 48.7975, GNorm = 0.4997, lr_0 = 4.4937e-04
Loss = 2.6352e-04, PNorm = 48.8108, GNorm = 0.2293, lr_0 = 4.4890e-04
Loss = 2.4220e-04, PNorm = 48.8255, GNorm = 0.2281, lr_0 = 4.4844e-04
Validation rmse logD = 0.588104
Validation R2 logD = 0.760455
Validation rmse logP = 0.479373
Validation R2 logP = 0.933306
Epoch 36
Train function
Loss = 2.1315e-04, PNorm = 48.8277, GNorm = 0.2239, lr_0 = 4.4797e-04
Loss = 2.4659e-04, PNorm = 48.8345, GNorm = 0.2681, lr_0 = 4.4750e-04
Loss = 2.7016e-04, PNorm = 48.8436, GNorm = 0.3363, lr_0 = 4.4703e-04
Loss = 2.2762e-04, PNorm = 48.8560, GNorm = 0.5019, lr_0 = 4.4657e-04
Loss = 2.4396e-04, PNorm = 48.8631, GNorm = 0.2558, lr_0 = 4.4610e-04
Loss = 2.2662e-04, PNorm = 48.8706, GNorm = 0.3322, lr_0 = 4.4564e-04
Loss = 2.5896e-04, PNorm = 48.8819, GNorm = 0.8722, lr_0 = 4.4517e-04
Loss = 2.5039e-04, PNorm = 48.8876, GNorm = 0.6195, lr_0 = 4.4471e-04
Loss = 2.5029e-04, PNorm = 48.8964, GNorm = 0.3123, lr_0 = 4.4424e-04
Loss = 2.3026e-04, PNorm = 48.9038, GNorm = 0.3001, lr_0 = 4.4378e-04
Loss = 2.5332e-04, PNorm = 48.9155, GNorm = 0.6789, lr_0 = 4.4331e-04
Loss = 2.6389e-04, PNorm = 48.9247, GNorm = 0.5416, lr_0 = 4.4285e-04
Loss = 2.2466e-04, PNorm = 48.9302, GNorm = 0.3269, lr_0 = 4.4239e-04
Loss = 1.9973e-04, PNorm = 48.9385, GNorm = 0.2783, lr_0 = 4.4193e-04
Loss = 1.9995e-04, PNorm = 48.9470, GNorm = 0.2664, lr_0 = 4.4147e-04
Loss = 2.2395e-04, PNorm = 48.9567, GNorm = 0.5091, lr_0 = 4.4101e-04
Loss = 3.1239e-04, PNorm = 48.9637, GNorm = 0.4785, lr_0 = 4.4055e-04
Loss = 2.1297e-04, PNorm = 48.9728, GNorm = 0.2808, lr_0 = 4.4009e-04
Loss = 2.8571e-04, PNorm = 48.9814, GNorm = 0.6959, lr_0 = 4.3963e-04
Loss = 2.4846e-04, PNorm = 48.9905, GNorm = 0.2899, lr_0 = 4.3917e-04
Loss = 2.3402e-04, PNorm = 48.9993, GNorm = 0.3508, lr_0 = 4.3871e-04
Loss = 2.5136e-04, PNorm = 49.0078, GNorm = 0.2204, lr_0 = 4.3825e-04
Loss = 2.3563e-04, PNorm = 49.0124, GNorm = 0.6817, lr_0 = 4.3779e-04
Validation rmse logD = 0.579301
Validation R2 logD = 0.767573
Validation rmse logP = 0.465899
Validation R2 logP = 0.937002
Epoch 37
Train function
Loss = 1.6489e-04, PNorm = 49.0165, GNorm = 0.2051, lr_0 = 4.3729e-04
Loss = 2.1687e-04, PNorm = 49.0246, GNorm = 0.3408, lr_0 = 4.3684e-04
Loss = 1.9912e-04, PNorm = 49.0293, GNorm = 0.3071, lr_0 = 4.3638e-04
Loss = 2.4689e-04, PNorm = 49.0372, GNorm = 0.5508, lr_0 = 4.3592e-04
Loss = 1.8756e-04, PNorm = 49.0429, GNorm = 0.2992, lr_0 = 4.3547e-04
Loss = 2.0543e-04, PNorm = 49.0535, GNorm = 0.2732, lr_0 = 4.3501e-04
Loss = 1.9924e-04, PNorm = 49.0608, GNorm = 0.1672, lr_0 = 4.3456e-04
Loss = 1.8773e-04, PNorm = 49.0653, GNorm = 0.3030, lr_0 = 4.3411e-04
Loss = 1.8620e-04, PNorm = 49.0680, GNorm = 0.3289, lr_0 = 4.3365e-04
Loss = 3.3646e-04, PNorm = 49.0750, GNorm = 0.4105, lr_0 = 4.3320e-04
Loss = 3.1499e-04, PNorm = 49.0863, GNorm = 0.7297, lr_0 = 4.3275e-04
Loss = 3.7420e-04, PNorm = 49.1032, GNorm = 0.7595, lr_0 = 4.3230e-04
Loss = 3.6816e-04, PNorm = 49.1168, GNorm = 0.2716, lr_0 = 4.3185e-04
Loss = 2.5498e-04, PNorm = 49.1302, GNorm = 0.2753, lr_0 = 4.3140e-04
Loss = 2.1481e-04, PNorm = 49.1425, GNorm = 0.3381, lr_0 = 4.3094e-04
Loss = 2.0793e-04, PNorm = 49.1496, GNorm = 0.3563, lr_0 = 4.3050e-04
Loss = 2.3744e-04, PNorm = 49.1563, GNorm = 0.4137, lr_0 = 4.3005e-04
Loss = 2.3904e-04, PNorm = 49.1682, GNorm = 0.3283, lr_0 = 4.2960e-04
Loss = 2.3039e-04, PNorm = 49.1750, GNorm = 0.2513, lr_0 = 4.2915e-04
Loss = 2.5376e-04, PNorm = 49.1813, GNorm = 0.3346, lr_0 = 4.2870e-04
Loss = 2.2781e-04, PNorm = 49.1885, GNorm = 0.2477, lr_0 = 4.2825e-04
Loss = 2.4910e-04, PNorm = 49.1952, GNorm = 0.4096, lr_0 = 4.2781e-04
Validation rmse logD = 0.587376
Validation R2 logD = 0.761048
Validation rmse logP = 0.465596
Validation R2 logP = 0.937084
Epoch 38
Train function
Loss = 1.5993e-04, PNorm = 49.2041, GNorm = 0.3087, lr_0 = 4.2736e-04
Loss = 2.0303e-04, PNorm = 49.2134, GNorm = 0.3096, lr_0 = 4.2691e-04
Loss = 2.5831e-04, PNorm = 49.2229, GNorm = 0.5475, lr_0 = 4.2647e-04
Loss = 1.6410e-04, PNorm = 49.2313, GNorm = 0.2931, lr_0 = 4.2602e-04
Loss = 1.8916e-04, PNorm = 49.2377, GNorm = 0.3701, lr_0 = 4.2558e-04
Loss = 1.9824e-04, PNorm = 49.2450, GNorm = 0.3730, lr_0 = 4.2513e-04
Loss = 2.0546e-04, PNorm = 49.2519, GNorm = 0.2416, lr_0 = 4.2469e-04
Loss = 1.4849e-04, PNorm = 49.2555, GNorm = 0.2508, lr_0 = 4.2425e-04
Loss = 1.9109e-04, PNorm = 49.2604, GNorm = 0.4438, lr_0 = 4.2380e-04
Loss = 1.8283e-04, PNorm = 49.2687, GNorm = 0.6499, lr_0 = 4.2336e-04
Loss = 2.9673e-04, PNorm = 49.2631, GNorm = 0.5478, lr_0 = 4.2292e-04
Loss = 2.1939e-04, PNorm = 49.2746, GNorm = 0.2127, lr_0 = 4.2248e-04
Loss = 2.5043e-04, PNorm = 49.2878, GNorm = 0.5877, lr_0 = 4.2204e-04
Loss = 2.4685e-04, PNorm = 49.2962, GNorm = 0.2644, lr_0 = 4.2160e-04
Loss = 2.5281e-04, PNorm = 49.3029, GNorm = 0.2723, lr_0 = 4.2116e-04
Loss = 1.9441e-04, PNorm = 49.3093, GNorm = 0.2647, lr_0 = 4.2072e-04
Loss = 1.7484e-04, PNorm = 49.3157, GNorm = 0.2425, lr_0 = 4.2028e-04
Loss = 2.7834e-04, PNorm = 49.3248, GNorm = 0.2764, lr_0 = 4.1984e-04
Loss = 2.1126e-04, PNorm = 49.3316, GNorm = 0.2324, lr_0 = 4.1940e-04
Loss = 2.6001e-04, PNorm = 49.3423, GNorm = 0.3675, lr_0 = 4.1896e-04
Loss = 2.1509e-04, PNorm = 49.3541, GNorm = 0.2601, lr_0 = 4.1853e-04
Loss = 2.5270e-04, PNorm = 49.3593, GNorm = 0.3158, lr_0 = 4.1809e-04
Loss = 2.5972e-04, PNorm = 49.3673, GNorm = 0.4474, lr_0 = 4.1765e-04
Validation rmse logD = 0.587601
Validation R2 logD = 0.760865
Validation rmse logP = 0.480667
Validation R2 logP = 0.932945
Epoch 39
Train function
Loss = 2.1764e-04, PNorm = 49.3739, GNorm = 0.2300, lr_0 = 4.1717e-04
Loss = 2.0443e-04, PNorm = 49.3812, GNorm = 0.5350, lr_0 = 4.1674e-04
Loss = 1.9409e-04, PNorm = 49.3888, GNorm = 0.3421, lr_0 = 4.1630e-04
Loss = 1.5762e-04, PNorm = 49.3936, GNorm = 0.2005, lr_0 = 4.1587e-04
Loss = 1.8837e-04, PNorm = 49.3976, GNorm = 0.2348, lr_0 = 4.1544e-04
Loss = 1.5783e-04, PNorm = 49.4022, GNorm = 0.5753, lr_0 = 4.1500e-04
Loss = 1.7877e-04, PNorm = 49.4088, GNorm = 0.3254, lr_0 = 4.1457e-04
Loss = 1.8872e-04, PNorm = 49.4157, GNorm = 0.3616, lr_0 = 4.1414e-04
Loss = 2.1843e-04, PNorm = 49.4222, GNorm = 0.3974, lr_0 = 4.1370e-04
Loss = 1.9347e-04, PNorm = 49.4250, GNorm = 0.4643, lr_0 = 4.1327e-04
Loss = 1.6170e-04, PNorm = 49.4303, GNorm = 0.2964, lr_0 = 4.1284e-04
Loss = 1.6557e-04, PNorm = 49.4368, GNorm = 0.2617, lr_0 = 4.1241e-04
Loss = 2.1778e-04, PNorm = 49.4436, GNorm = 0.6741, lr_0 = 4.1198e-04
Loss = 2.4344e-04, PNorm = 49.4481, GNorm = 0.5325, lr_0 = 4.1155e-04
Loss = 1.6798e-04, PNorm = 49.4502, GNorm = 0.2458, lr_0 = 4.1112e-04
Loss = 1.6903e-04, PNorm = 49.4565, GNorm = 0.2596, lr_0 = 4.1069e-04
Loss = 1.7614e-04, PNorm = 49.4628, GNorm = 0.4023, lr_0 = 4.1026e-04
Loss = 2.0507e-04, PNorm = 49.4692, GNorm = 0.3779, lr_0 = 4.0983e-04
Loss = 1.6024e-04, PNorm = 49.4727, GNorm = 0.2357, lr_0 = 4.0941e-04
Loss = 2.2544e-04, PNorm = 49.4834, GNorm = 0.4071, lr_0 = 4.0898e-04
Loss = 1.6348e-04, PNorm = 49.4890, GNorm = 0.4992, lr_0 = 4.0855e-04
Loss = 2.5757e-04, PNorm = 49.5009, GNorm = 0.3840, lr_0 = 4.0813e-04
Validation rmse logD = 0.584917
Validation R2 logD = 0.763045
Validation rmse logP = 0.468729
Validation R2 logP = 0.936235
Epoch 40
Train function
Loss = 2.2464e-04, PNorm = 49.5101, GNorm = 0.4484, lr_0 = 4.0770e-04
Loss = 1.8199e-04, PNorm = 49.5185, GNorm = 0.3770, lr_0 = 4.0727e-04
Loss = 1.5744e-04, PNorm = 49.5249, GNorm = 0.1863, lr_0 = 4.0685e-04
Loss = 1.5090e-04, PNorm = 49.5317, GNorm = 0.2966, lr_0 = 4.0642e-04
Loss = 1.6151e-04, PNorm = 49.5400, GNorm = 0.3380, lr_0 = 4.0600e-04
Loss = 2.0572e-04, PNorm = 49.5459, GNorm = 0.2458, lr_0 = 4.0558e-04
Loss = 1.9002e-04, PNorm = 49.5489, GNorm = 0.3891, lr_0 = 4.0515e-04
Loss = 2.0106e-04, PNorm = 49.5519, GNorm = 0.3093, lr_0 = 4.0473e-04
Loss = 1.4964e-04, PNorm = 49.5541, GNorm = 0.4293, lr_0 = 4.0431e-04
Loss = 1.7971e-04, PNorm = 49.5582, GNorm = 0.4187, lr_0 = 4.0389e-04
Loss = 1.4428e-04, PNorm = 49.5658, GNorm = 0.2323, lr_0 = 4.0346e-04
Loss = 1.6944e-04, PNorm = 49.5713, GNorm = 0.3593, lr_0 = 4.0304e-04
Loss = 1.5110e-04, PNorm = 49.5759, GNorm = 0.3675, lr_0 = 4.0262e-04
Loss = 1.6984e-04, PNorm = 49.5816, GNorm = 0.3469, lr_0 = 4.0220e-04
Loss = 1.9096e-04, PNorm = 49.5869, GNorm = 0.3878, lr_0 = 4.0178e-04
Loss = 1.5656e-04, PNorm = 49.5933, GNorm = 0.4260, lr_0 = 4.0136e-04
Loss = 1.6428e-04, PNorm = 49.5981, GNorm = 0.2801, lr_0 = 4.0094e-04
Loss = 1.4812e-04, PNorm = 49.6033, GNorm = 0.3833, lr_0 = 4.0053e-04
Loss = 2.2702e-04, PNorm = 49.6097, GNorm = 0.9691, lr_0 = 4.0011e-04
Loss = 2.0955e-04, PNorm = 49.6188, GNorm = 0.5130, lr_0 = 3.9969e-04
Loss = 2.0140e-04, PNorm = 49.6255, GNorm = 0.2179, lr_0 = 3.9927e-04
Loss = 1.7691e-04, PNorm = 49.6290, GNorm = 0.3702, lr_0 = 3.9886e-04
Loss = 2.0421e-04, PNorm = 49.6340, GNorm = 0.3831, lr_0 = 3.9844e-04
Validation rmse logD = 0.586412
Validation R2 logD = 0.761832
Validation rmse logP = 0.465759
Validation R2 logP = 0.937040
Epoch 41
Train function
Loss = 2.1771e-04, PNorm = 49.6394, GNorm = 0.2767, lr_0 = 3.9798e-04
Loss = 1.5024e-04, PNorm = 49.6452, GNorm = 0.3994, lr_0 = 3.9757e-04
Loss = 1.7621e-04, PNorm = 49.6521, GNorm = 0.4762, lr_0 = 3.9715e-04
Loss = 1.5712e-04, PNorm = 49.6618, GNorm = 0.3669, lr_0 = 3.9674e-04
Loss = 1.9275e-04, PNorm = 49.6685, GNorm = 0.4361, lr_0 = 3.9632e-04
Loss = 1.8490e-04, PNorm = 49.6737, GNorm = 0.3702, lr_0 = 3.9591e-04
Loss = 2.0512e-04, PNorm = 49.6834, GNorm = 0.4512, lr_0 = 3.9550e-04
Loss = 1.8277e-04, PNorm = 49.6881, GNorm = 0.4168, lr_0 = 3.9508e-04
Loss = 1.4119e-04, PNorm = 49.6951, GNorm = 0.3849, lr_0 = 3.9467e-04
Loss = 1.5751e-04, PNorm = 49.7021, GNorm = 0.2933, lr_0 = 3.9426e-04
Loss = 1.4065e-04, PNorm = 49.7043, GNorm = 0.3508, lr_0 = 3.9385e-04
Loss = 1.6363e-04, PNorm = 49.7093, GNorm = 0.3429, lr_0 = 3.9344e-04
Loss = 1.3734e-04, PNorm = 49.7145, GNorm = 0.3276, lr_0 = 3.9303e-04
Loss = 1.5862e-04, PNorm = 49.7213, GNorm = 0.2196, lr_0 = 3.9262e-04
Loss = 1.4926e-04, PNorm = 49.7263, GNorm = 0.1912, lr_0 = 3.9221e-04
Loss = 1.8114e-04, PNorm = 49.7294, GNorm = 0.4637, lr_0 = 3.9180e-04
Loss = 1.8146e-04, PNorm = 49.7333, GNorm = 0.4230, lr_0 = 3.9139e-04
Loss = 2.8446e-04, PNorm = 49.7376, GNorm = 1.0646, lr_0 = 3.9098e-04
Loss = 2.9809e-04, PNorm = 49.7465, GNorm = 0.2674, lr_0 = 3.9057e-04
Loss = 2.8964e-04, PNorm = 49.7536, GNorm = 0.4631, lr_0 = 3.9016e-04
Loss = 1.9565e-04, PNorm = 49.7671, GNorm = 0.2707, lr_0 = 3.8976e-04
Loss = 1.9875e-04, PNorm = 49.7750, GNorm = 0.2816, lr_0 = 3.8935e-04
Loss = 2.3951e-04, PNorm = 49.7792, GNorm = 0.4673, lr_0 = 3.8894e-04
Validation rmse logD = 0.593622
Validation R2 logD = 0.755939
Validation rmse logP = 0.461172
Validation R2 logP = 0.938274
Epoch 42
Train function
Loss = 1.6117e-04, PNorm = 49.7857, GNorm = 0.1996, lr_0 = 3.8854e-04
Loss = 1.4690e-04, PNorm = 49.7901, GNorm = 0.2648, lr_0 = 3.8813e-04
Loss = 1.5793e-04, PNorm = 49.7953, GNorm = 0.1911, lr_0 = 3.8773e-04
Loss = 1.2099e-04, PNorm = 49.7996, GNorm = 0.2156, lr_0 = 3.8732e-04
Loss = 1.7401e-04, PNorm = 49.8038, GNorm = 0.2884, lr_0 = 3.8692e-04
Loss = 1.4502e-04, PNorm = 49.8087, GNorm = 0.3225, lr_0 = 3.8651e-04
Loss = 1.4082e-04, PNorm = 49.8117, GNorm = 0.3013, lr_0 = 3.8611e-04
Loss = 1.4739e-04, PNorm = 49.8142, GNorm = 0.4898, lr_0 = 3.8571e-04
Loss = 1.5156e-04, PNorm = 49.8206, GNorm = 0.2370, lr_0 = 3.8531e-04
Loss = 1.8243e-04, PNorm = 49.8270, GNorm = 0.4162, lr_0 = 3.8490e-04
Loss = 1.4775e-04, PNorm = 49.8316, GNorm = 0.1837, lr_0 = 3.8450e-04
Loss = 1.4755e-04, PNorm = 49.8371, GNorm = 0.2264, lr_0 = 3.8410e-04
Loss = 1.4551e-04, PNorm = 49.8434, GNorm = 0.2188, lr_0 = 3.8370e-04
Loss = 1.4280e-04, PNorm = 49.8493, GNorm = 0.3315, lr_0 = 3.8330e-04
Loss = 1.2870e-04, PNorm = 49.8528, GNorm = 0.2648, lr_0 = 3.8290e-04
Loss = 1.4613e-04, PNorm = 49.8577, GNorm = 0.4492, lr_0 = 3.8250e-04
Loss = 1.6248e-04, PNorm = 49.8627, GNorm = 0.2959, lr_0 = 3.8210e-04
Loss = 1.8803e-04, PNorm = 49.8682, GNorm = 0.4357, lr_0 = 3.8170e-04
Loss = 1.6649e-04, PNorm = 49.8723, GNorm = 0.1966, lr_0 = 3.8130e-04
Loss = 1.7292e-04, PNorm = 49.8780, GNorm = 0.3009, lr_0 = 3.8090e-04
Loss = 1.3588e-04, PNorm = 49.8827, GNorm = 0.2022, lr_0 = 3.8051e-04
Loss = 1.7462e-04, PNorm = 49.8886, GNorm = 0.2605, lr_0 = 3.8011e-04
Validation rmse logD = 0.581590
Validation R2 logD = 0.765733
Validation rmse logP = 0.466458
Validation R2 logP = 0.936851
Epoch 43
Train function
Loss = 1.3741e-04, PNorm = 49.8952, GNorm = 0.2218, lr_0 = 3.7967e-04
Loss = 1.5695e-04, PNorm = 49.8976, GNorm = 0.2657, lr_0 = 3.7928e-04
Loss = 1.4557e-04, PNorm = 49.9002, GNorm = 0.3033, lr_0 = 3.7888e-04
Loss = 1.3638e-04, PNorm = 49.9053, GNorm = 0.2885, lr_0 = 3.7849e-04
Loss = 1.1730e-04, PNorm = 49.9080, GNorm = 0.2284, lr_0 = 3.7809e-04
Loss = 1.4031e-04, PNorm = 49.9137, GNorm = 0.3097, lr_0 = 3.7770e-04
Loss = 1.5480e-04, PNorm = 49.9163, GNorm = 0.3692, lr_0 = 3.7730e-04
Loss = 1.2580e-04, PNorm = 49.9192, GNorm = 0.3226, lr_0 = 3.7691e-04
Loss = 1.0756e-04, PNorm = 49.9235, GNorm = 0.2228, lr_0 = 3.7652e-04
Loss = 1.0507e-04, PNorm = 49.9271, GNorm = 0.2314, lr_0 = 3.7612e-04
Loss = 1.0201e-04, PNorm = 49.9319, GNorm = 0.1851, lr_0 = 3.7573e-04
Loss = 1.4392e-04, PNorm = 49.9373, GNorm = 0.2329, lr_0 = 3.7534e-04
Loss = 1.5661e-04, PNorm = 49.9421, GNorm = 0.3300, lr_0 = 3.7495e-04
Loss = 1.2709e-04, PNorm = 49.9463, GNorm = 0.1507, lr_0 = 3.7455e-04
Loss = 1.3330e-04, PNorm = 49.9497, GNorm = 0.1551, lr_0 = 3.7416e-04
Loss = 1.2392e-04, PNorm = 49.9539, GNorm = 0.2195, lr_0 = 3.7377e-04
Loss = 1.8363e-04, PNorm = 49.9585, GNorm = 0.2987, lr_0 = 3.7338e-04
Loss = 1.4970e-04, PNorm = 49.9641, GNorm = 0.3167, lr_0 = 3.7299e-04
Loss = 1.5638e-04, PNorm = 49.9736, GNorm = 0.3059, lr_0 = 3.7260e-04
Loss = 1.5126e-04, PNorm = 49.9811, GNorm = 0.2587, lr_0 = 3.7221e-04
Loss = 1.2636e-04, PNorm = 49.9854, GNorm = 0.2717, lr_0 = 3.7183e-04
Loss = 1.3851e-04, PNorm = 49.9879, GNorm = 0.2506, lr_0 = 3.7144e-04
Loss = 1.3857e-04, PNorm = 49.9928, GNorm = 0.2297, lr_0 = 3.7105e-04
Validation rmse logD = 0.584601
Validation R2 logD = 0.763301
Validation rmse logP = 0.465487
Validation R2 logP = 0.937114
Epoch 44
Train function
Loss = 1.3196e-04, PNorm = 49.9976, GNorm = 0.3138, lr_0 = 3.7066e-04
Loss = 1.1863e-04, PNorm = 50.0023, GNorm = 0.1574, lr_0 = 3.7028e-04
Loss = 1.1556e-04, PNorm = 50.0065, GNorm = 0.1761, lr_0 = 3.6989e-04
Loss = 1.2821e-04, PNorm = 50.0091, GNorm = 0.2486, lr_0 = 3.6950e-04
Loss = 1.1502e-04, PNorm = 50.0131, GNorm = 0.1704, lr_0 = 3.6912e-04
Loss = 1.1516e-04, PNorm = 50.0180, GNorm = 0.3124, lr_0 = 3.6873e-04
Loss = 1.3982e-04, PNorm = 50.0236, GNorm = 0.2485, lr_0 = 3.6835e-04
Loss = 1.2269e-04, PNorm = 50.0293, GNorm = 0.2534, lr_0 = 3.6796e-04
Loss = 1.2223e-04, PNorm = 50.0332, GNorm = 0.1863, lr_0 = 3.6758e-04
Loss = 1.0982e-04, PNorm = 50.0417, GNorm = 0.2688, lr_0 = 3.6720e-04
Loss = 1.2587e-04, PNorm = 50.0469, GNorm = 0.2293, lr_0 = 3.6681e-04
Loss = 1.2618e-04, PNorm = 50.0528, GNorm = 0.1714, lr_0 = 3.6643e-04
Loss = 1.4861e-04, PNorm = 50.0556, GNorm = 0.4896, lr_0 = 3.6605e-04
Loss = 1.3539e-04, PNorm = 50.0615, GNorm = 0.3386, lr_0 = 3.6567e-04
Loss = 1.4867e-04, PNorm = 50.0666, GNorm = 0.1797, lr_0 = 3.6528e-04
Loss = 1.5304e-04, PNorm = 50.0702, GNorm = 0.1723, lr_0 = 3.6490e-04
Loss = 1.6145e-04, PNorm = 50.0763, GNorm = 0.2052, lr_0 = 3.6452e-04
Loss = 1.3275e-04, PNorm = 50.0813, GNorm = 0.2409, lr_0 = 3.6414e-04
Loss = 1.4299e-04, PNorm = 50.0856, GNorm = 0.4642, lr_0 = 3.6376e-04
Loss = 1.2944e-04, PNorm = 50.0872, GNorm = 0.2229, lr_0 = 3.6338e-04
Loss = 1.5334e-04, PNorm = 50.0916, GNorm = 0.2558, lr_0 = 3.6300e-04
Loss = 1.2242e-04, PNorm = 50.0977, GNorm = 0.1645, lr_0 = 3.6262e-04
Validation rmse logD = 0.584075
Validation R2 logD = 0.763727
Validation rmse logP = 0.463668
Validation R2 logP = 0.937604
Epoch 45
Train function
Loss = 1.0556e-04, PNorm = 50.1041, GNorm = 0.3003, lr_0 = 3.6221e-04
Loss = 1.1460e-04, PNorm = 50.1119, GNorm = 0.2746, lr_0 = 3.6183e-04
Loss = 1.2022e-04, PNorm = 50.1153, GNorm = 0.3319, lr_0 = 3.6145e-04
Loss = 1.0630e-04, PNorm = 50.1225, GNorm = 0.3015, lr_0 = 3.6107e-04
Loss = 1.2216e-04, PNorm = 50.1279, GNorm = 0.2460, lr_0 = 3.6070e-04
Loss = 1.1504e-04, PNorm = 50.1319, GNorm = 0.1718, lr_0 = 3.6032e-04
Loss = 1.0220e-04, PNorm = 50.1351, GNorm = 0.2094, lr_0 = 3.5994e-04
Loss = 1.2414e-04, PNorm = 50.1386, GNorm = 0.3227, lr_0 = 3.5957e-04
Loss = 1.1322e-04, PNorm = 50.1419, GNorm = 0.2062, lr_0 = 3.5919e-04
Loss = 1.1476e-04, PNorm = 50.1474, GNorm = 0.3232, lr_0 = 3.5882e-04
Loss = 1.3573e-04, PNorm = 50.1529, GNorm = 0.2427, lr_0 = 3.5844e-04
Loss = 1.1740e-04, PNorm = 50.1564, GNorm = 0.4645, lr_0 = 3.5807e-04
Loss = 1.3562e-04, PNorm = 50.1627, GNorm = 0.1777, lr_0 = 3.5770e-04
Loss = 1.0356e-04, PNorm = 50.1670, GNorm = 0.2146, lr_0 = 3.5732e-04
Loss = 1.3529e-04, PNorm = 50.1693, GNorm = 0.2496, lr_0 = 3.5695e-04
Loss = 1.3264e-04, PNorm = 50.1745, GNorm = 0.2534, lr_0 = 3.5658e-04
Loss = 1.2582e-04, PNorm = 50.1782, GNorm = 0.3917, lr_0 = 3.5621e-04
Loss = 1.4839e-04, PNorm = 50.1815, GNorm = 0.3335, lr_0 = 3.5583e-04
Loss = 1.3661e-04, PNorm = 50.1875, GNorm = 0.1940, lr_0 = 3.5546e-04
Loss = 1.4065e-04, PNorm = 50.1898, GNorm = 0.2020, lr_0 = 3.5509e-04
Loss = 1.4081e-04, PNorm = 50.1946, GNorm = 0.3155, lr_0 = 3.5472e-04
Loss = 1.4653e-04, PNorm = 50.2003, GNorm = 0.2778, lr_0 = 3.5435e-04
Loss = 1.3961e-04, PNorm = 50.2079, GNorm = 0.2904, lr_0 = 3.5398e-04
Validation rmse logD = 0.591170
Validation R2 logD = 0.757952
Validation rmse logP = 0.460710
Validation R2 logP = 0.938398
Epoch 46
Train function
Loss = 1.2047e-04, PNorm = 50.2128, GNorm = 0.2642, lr_0 = 3.5361e-04
Loss = 1.4228e-04, PNorm = 50.2155, GNorm = 0.4019, lr_0 = 3.5324e-04
Loss = 1.1686e-04, PNorm = 50.2191, GNorm = 0.2146, lr_0 = 3.5287e-04
Loss = 1.0490e-04, PNorm = 50.2236, GNorm = 0.3457, lr_0 = 3.5251e-04
Loss = 1.1839e-04, PNorm = 50.2299, GNorm = 0.2576, lr_0 = 3.5214e-04
Loss = 8.8595e-05, PNorm = 50.2335, GNorm = 0.2709, lr_0 = 3.5177e-04
Loss = 1.5942e-04, PNorm = 50.2374, GNorm = 0.2656, lr_0 = 3.5140e-04
Loss = 1.1393e-04, PNorm = 50.2395, GNorm = 0.2612, lr_0 = 3.5104e-04
Loss = 1.2883e-04, PNorm = 50.2433, GNorm = 0.3195, lr_0 = 3.5067e-04
Loss = 1.3676e-04, PNorm = 50.2467, GNorm = 0.3300, lr_0 = 3.5030e-04
Loss = 1.2375e-04, PNorm = 50.2545, GNorm = 0.3315, lr_0 = 3.4994e-04
Loss = 1.2433e-04, PNorm = 50.2587, GNorm = 0.1557, lr_0 = 3.4957e-04
Loss = 1.3483e-04, PNorm = 50.2633, GNorm = 0.2905, lr_0 = 3.4921e-04
Loss = 1.5845e-04, PNorm = 50.2682, GNorm = 0.4065, lr_0 = 3.4884e-04
Loss = 1.5768e-04, PNorm = 50.2738, GNorm = 0.5012, lr_0 = 3.4848e-04
Loss = 1.3073e-04, PNorm = 50.2812, GNorm = 0.3370, lr_0 = 3.4812e-04
Loss = 1.3754e-04, PNorm = 50.2899, GNorm = 0.2194, lr_0 = 3.4775e-04
Loss = 1.5255e-04, PNorm = 50.2957, GNorm = 0.1894, lr_0 = 3.4739e-04
Loss = 1.3278e-04, PNorm = 50.3012, GNorm = 0.4004, lr_0 = 3.4703e-04
Loss = 1.5309e-04, PNorm = 50.3066, GNorm = 0.3585, lr_0 = 3.4666e-04
Loss = 1.7840e-04, PNorm = 50.3152, GNorm = 0.5892, lr_0 = 3.4630e-04
Loss = 1.4154e-04, PNorm = 50.3184, GNorm = 0.3408, lr_0 = 3.4594e-04
Validation rmse logD = 0.584823
Validation R2 logD = 0.763121
Validation rmse logP = 0.469424
Validation R2 logP = 0.936046
Epoch 47
Train function
Loss = 1.0756e-04, PNorm = 50.3260, GNorm = 0.4001, lr_0 = 3.4554e-04
Loss = 1.4696e-04, PNorm = 50.3296, GNorm = 0.1806, lr_0 = 3.4518e-04
Loss = 1.4014e-04, PNorm = 50.3337, GNorm = 0.4863, lr_0 = 3.4482e-04
Loss = 1.1851e-04, PNorm = 50.3389, GNorm = 0.2154, lr_0 = 3.4446e-04
Loss = 1.1561e-04, PNorm = 50.3422, GNorm = 0.2808, lr_0 = 3.4410e-04
Loss = 1.3427e-04, PNorm = 50.3478, GNorm = 0.3382, lr_0 = 3.4374e-04
Loss = 1.9965e-04, PNorm = 50.3528, GNorm = 0.8839, lr_0 = 3.4339e-04
Loss = 1.2127e-04, PNorm = 50.3576, GNorm = 0.2126, lr_0 = 3.4303e-04
Loss = 1.0643e-04, PNorm = 50.3621, GNorm = 0.2847, lr_0 = 3.4267e-04
Loss = 1.0688e-04, PNorm = 50.3648, GNorm = 0.1342, lr_0 = 3.4231e-04
Loss = 1.6699e-04, PNorm = 50.3695, GNorm = 0.1504, lr_0 = 3.4195e-04
Loss = 9.5927e-05, PNorm = 50.3762, GNorm = 0.1917, lr_0 = 3.4160e-04
Loss = 1.2110e-04, PNorm = 50.3770, GNorm = 0.4155, lr_0 = 3.4124e-04
Loss = 1.2508e-04, PNorm = 50.3767, GNorm = 0.1688, lr_0 = 3.4088e-04
Loss = 1.1794e-04, PNorm = 50.3811, GNorm = 0.4482, lr_0 = 3.4053e-04
Loss = 1.0651e-04, PNorm = 50.3839, GNorm = 0.2296, lr_0 = 3.4017e-04
Loss = 1.1239e-04, PNorm = 50.3904, GNorm = 0.2302, lr_0 = 3.3982e-04
Loss = 1.4555e-04, PNorm = 50.3986, GNorm = 0.3926, lr_0 = 3.3946e-04
Loss = 1.3136e-04, PNorm = 50.4015, GNorm = 0.1979, lr_0 = 3.3911e-04
Loss = 1.2289e-04, PNorm = 50.4061, GNorm = 0.3569, lr_0 = 3.3876e-04
Loss = 1.3776e-04, PNorm = 50.4124, GNorm = 0.2108, lr_0 = 3.3840e-04
Loss = 1.2093e-04, PNorm = 50.4179, GNorm = 0.4978, lr_0 = 3.3805e-04
Loss = 1.0463e-04, PNorm = 50.4211, GNorm = 0.2316, lr_0 = 3.3770e-04
Validation rmse logD = 0.584390
Validation R2 logD = 0.763472
Validation rmse logP = 0.464574
Validation R2 logP = 0.937360
Epoch 48
Train function
Loss = 1.1243e-04, PNorm = 50.4254, GNorm = 0.5500, lr_0 = 3.3734e-04
Loss = 1.3416e-04, PNorm = 50.4299, GNorm = 0.3108, lr_0 = 3.3699e-04
Loss = 1.1241e-04, PNorm = 50.4351, GNorm = 0.3458, lr_0 = 3.3664e-04
Loss = 1.0794e-04, PNorm = 50.4407, GNorm = 0.2222, lr_0 = 3.3629e-04
Loss = 1.1429e-04, PNorm = 50.4485, GNorm = 0.1119, lr_0 = 3.3594e-04
Loss = 1.3109e-04, PNorm = 50.4547, GNorm = 0.1895, lr_0 = 3.3559e-04
Loss = 9.3408e-05, PNorm = 50.4586, GNorm = 0.2278, lr_0 = 3.3524e-04
Loss = 1.2973e-04, PNorm = 50.4630, GNorm = 0.1652, lr_0 = 3.3489e-04
Loss = 1.0544e-04, PNorm = 50.4673, GNorm = 0.2673, lr_0 = 3.3454e-04
Loss = 1.0599e-04, PNorm = 50.4700, GNorm = 0.3083, lr_0 = 3.3419e-04
Loss = 1.2041e-04, PNorm = 50.4749, GNorm = 0.2079, lr_0 = 3.3384e-04
Loss = 1.2809e-04, PNorm = 50.4812, GNorm = 0.1777, lr_0 = 3.3349e-04
Loss = 1.4608e-04, PNorm = 50.4840, GNorm = 0.2782, lr_0 = 3.3314e-04
Loss = 1.2911e-04, PNorm = 50.4905, GNorm = 0.3069, lr_0 = 3.3280e-04
Loss = 1.0975e-04, PNorm = 50.4955, GNorm = 0.1290, lr_0 = 3.3245e-04
Loss = 1.1988e-04, PNorm = 50.5003, GNorm = 0.1608, lr_0 = 3.3210e-04
Loss = 1.1335e-04, PNorm = 50.5047, GNorm = 0.2120, lr_0 = 3.3175e-04
Loss = 1.0441e-04, PNorm = 50.5087, GNorm = 0.1218, lr_0 = 3.3141e-04
Loss = 1.1670e-04, PNorm = 50.5126, GNorm = 0.1680, lr_0 = 3.3106e-04
Loss = 1.2168e-04, PNorm = 50.5137, GNorm = 0.2804, lr_0 = 3.3072e-04
Loss = 1.0336e-04, PNorm = 50.5180, GNorm = 0.2714, lr_0 = 3.3037e-04
Loss = 1.2414e-04, PNorm = 50.5212, GNorm = 0.2217, lr_0 = 3.3003e-04
Validation rmse logD = 0.589892
Validation R2 logD = 0.758997
Validation rmse logP = 0.466884
Validation R2 logP = 0.936736
Epoch 49
Train function
Loss = 9.8191e-05, PNorm = 50.5247, GNorm = 0.3739, lr_0 = 3.2965e-04
Loss = 1.3085e-04, PNorm = 50.5272, GNorm = 0.3086, lr_0 = 3.2930e-04
Loss = 1.0819e-04, PNorm = 50.5300, GNorm = 0.2300, lr_0 = 3.2896e-04
Loss = 9.4671e-05, PNorm = 50.5361, GNorm = 0.2961, lr_0 = 3.2862e-04
Loss = 9.9125e-05, PNorm = 50.5402, GNorm = 0.3162, lr_0 = 3.2827e-04
Loss = 1.3823e-04, PNorm = 50.5430, GNorm = 0.3949, lr_0 = 3.2793e-04
Loss = 1.0293e-04, PNorm = 50.5473, GNorm = 0.3548, lr_0 = 3.2759e-04
Loss = 8.7331e-05, PNorm = 50.5535, GNorm = 0.1760, lr_0 = 3.2725e-04
Loss = 7.9965e-05, PNorm = 50.5557, GNorm = 0.1872, lr_0 = 3.2691e-04
Loss = 9.1343e-05, PNorm = 50.5572, GNorm = 0.3307, lr_0 = 3.2656e-04
Loss = 1.1427e-04, PNorm = 50.5623, GNorm = 0.1749, lr_0 = 3.2622e-04
Loss = 1.5037e-04, PNorm = 50.5679, GNorm = 0.5330, lr_0 = 3.2588e-04
Loss = 1.5728e-04, PNorm = 50.5747, GNorm = 0.4927, lr_0 = 3.2554e-04
Loss = 1.2979e-04, PNorm = 50.5814, GNorm = 0.2783, lr_0 = 3.2520e-04
Loss = 1.1025e-04, PNorm = 50.5873, GNorm = 0.3109, lr_0 = 3.2486e-04
Loss = 1.3104e-04, PNorm = 50.5927, GNorm = 0.2129, lr_0 = 3.2452e-04
Loss = 1.4679e-04, PNorm = 50.5992, GNorm = 0.4477, lr_0 = 3.2419e-04
Loss = 1.2612e-04, PNorm = 50.6060, GNorm = 0.4115, lr_0 = 3.2385e-04
Loss = 1.1340e-04, PNorm = 50.6109, GNorm = 0.1636, lr_0 = 3.2351e-04
Loss = 1.1768e-04, PNorm = 50.6143, GNorm = 0.1881, lr_0 = 3.2317e-04
Loss = 1.2311e-04, PNorm = 50.6186, GNorm = 0.4329, lr_0 = 3.2283e-04
Loss = 1.0941e-04, PNorm = 50.6218, GNorm = 0.2785, lr_0 = 3.2250e-04
Loss = 9.0307e-05, PNorm = 50.6277, GNorm = 0.2171, lr_0 = 3.2216e-04
Validation rmse logD = 0.594486
Validation R2 logD = 0.755229
Validation rmse logP = 0.471222
Validation R2 logP = 0.935555
Epoch 50
Train function
Loss = 9.7906e-05, PNorm = 50.6330, GNorm = 0.1093, lr_0 = 3.2182e-04
Loss = 9.7374e-05, PNorm = 50.6357, GNorm = 0.1646, lr_0 = 3.2149e-04
Loss = 1.1982e-04, PNorm = 50.6378, GNorm = 0.3362, lr_0 = 3.2115e-04
Loss = 9.4020e-05, PNorm = 50.6432, GNorm = 0.2226, lr_0 = 3.2082e-04
Loss = 1.0744e-04, PNorm = 50.6469, GNorm = 0.2920, lr_0 = 3.2048e-04
Loss = 9.2741e-05, PNorm = 50.6515, GNorm = 0.2194, lr_0 = 3.2015e-04
Loss = 1.1921e-04, PNorm = 50.6537, GNorm = 0.4152, lr_0 = 3.1981e-04
Loss = 9.7987e-05, PNorm = 50.6595, GNorm = 0.3100, lr_0 = 3.1948e-04
Loss = 1.1014e-04, PNorm = 50.6628, GNorm = 0.3429, lr_0 = 3.1915e-04
Loss = 1.1092e-04, PNorm = 50.6666, GNorm = 0.3486, lr_0 = 3.1881e-04
Loss = 9.6657e-05, PNorm = 50.6693, GNorm = 0.1958, lr_0 = 3.1848e-04
Loss = 1.0562e-04, PNorm = 50.6733, GNorm = 0.2563, lr_0 = 3.1815e-04
Loss = 9.8027e-05, PNorm = 50.6760, GNorm = 0.1534, lr_0 = 3.1782e-04
Loss = 8.3144e-05, PNorm = 50.6792, GNorm = 0.2534, lr_0 = 3.1749e-04
Loss = 1.0368e-04, PNorm = 50.6840, GNorm = 0.2436, lr_0 = 3.1715e-04
Loss = 8.9221e-05, PNorm = 50.6884, GNorm = 0.3278, lr_0 = 3.1682e-04
Loss = 1.1892e-04, PNorm = 50.6904, GNorm = 0.2007, lr_0 = 3.1649e-04
Loss = 9.9391e-05, PNorm = 50.6953, GNorm = 0.2738, lr_0 = 3.1616e-04
Loss = 8.0753e-05, PNorm = 50.6994, GNorm = 0.2156, lr_0 = 3.1583e-04
Loss = 8.9561e-05, PNorm = 50.7022, GNorm = 0.2125, lr_0 = 3.1550e-04
Loss = 1.0467e-04, PNorm = 50.7047, GNorm = 0.1500, lr_0 = 3.1517e-04
Loss = 1.0622e-04, PNorm = 50.7085, GNorm = 0.4838, lr_0 = 3.1484e-04
Validation rmse logD = 0.584659
Validation R2 logD = 0.763254
Validation rmse logP = 0.465189
Validation R2 logP = 0.937194
Epoch 51
Train function
Loss = 4.4540e-05, PNorm = 50.7112, GNorm = 0.1608, lr_0 = 3.1448e-04
Loss = 7.2766e-05, PNorm = 50.7153, GNorm = 0.1537, lr_0 = 3.1415e-04
Loss = 8.1493e-05, PNorm = 50.7173, GNorm = 0.2497, lr_0 = 3.1383e-04
Loss = 8.6101e-05, PNorm = 50.7177, GNorm = 0.3158, lr_0 = 3.1350e-04
Loss = 9.3045e-05, PNorm = 50.7210, GNorm = 0.2966, lr_0 = 3.1317e-04
Loss = 8.4474e-05, PNorm = 50.7274, GNorm = 0.1486, lr_0 = 3.1284e-04
Loss = 7.7835e-05, PNorm = 50.7306, GNorm = 0.2474, lr_0 = 3.1252e-04
Loss = 8.7786e-05, PNorm = 50.7331, GNorm = 0.3225, lr_0 = 3.1219e-04
Loss = 1.1403e-04, PNorm = 50.7384, GNorm = 0.3177, lr_0 = 3.1187e-04
Loss = 8.3028e-05, PNorm = 50.7415, GNorm = 0.2656, lr_0 = 3.1154e-04
Loss = 8.7045e-05, PNorm = 50.7448, GNorm = 0.3392, lr_0 = 3.1122e-04
Loss = 1.0352e-04, PNorm = 50.7489, GNorm = 0.3896, lr_0 = 3.1089e-04
Loss = 1.0636e-04, PNorm = 50.7524, GNorm = 0.2948, lr_0 = 3.1057e-04
Loss = 1.1128e-04, PNorm = 50.7544, GNorm = 0.3175, lr_0 = 3.1024e-04
Loss = 9.0773e-05, PNorm = 50.7565, GNorm = 0.1970, lr_0 = 3.0992e-04
Loss = 1.1304e-04, PNorm = 50.7587, GNorm = 0.2662, lr_0 = 3.0959e-04
Loss = 1.1952e-04, PNorm = 50.7641, GNorm = 0.4208, lr_0 = 3.0927e-04
Loss = 1.1800e-04, PNorm = 50.7684, GNorm = 0.3130, lr_0 = 3.0895e-04
Loss = 1.0305e-04, PNorm = 50.7739, GNorm = 0.2726, lr_0 = 3.0863e-04
Loss = 1.0751e-04, PNorm = 50.7778, GNorm = 0.1483, lr_0 = 3.0830e-04
Loss = 1.0512e-04, PNorm = 50.7817, GNorm = 0.1540, lr_0 = 3.0798e-04
Loss = 1.0516e-04, PNorm = 50.7853, GNorm = 0.2049, lr_0 = 3.0766e-04
Loss = 1.0122e-04, PNorm = 50.7914, GNorm = 0.2917, lr_0 = 3.0734e-04
Validation rmse logD = 0.588967
Validation R2 logD = 0.759752
Validation rmse logP = 0.470456
Validation R2 logP = 0.935764
Epoch 52
Train function
Loss = 7.9948e-05, PNorm = 50.7959, GNorm = 0.2647, lr_0 = 3.0699e-04
Loss = 6.7843e-05, PNorm = 50.7993, GNorm = 0.1410, lr_0 = 3.0667e-04
Loss = 8.0580e-05, PNorm = 50.8032, GNorm = 0.2907, lr_0 = 3.0635e-04
Loss = 7.8992e-05, PNorm = 50.8070, GNorm = 0.2282, lr_0 = 3.0603e-04
Loss = 7.0857e-05, PNorm = 50.8085, GNorm = 0.1281, lr_0 = 3.0571e-04
Loss = 8.5004e-05, PNorm = 50.8103, GNorm = 0.1185, lr_0 = 3.0539e-04
Loss = 9.0815e-05, PNorm = 50.8144, GNorm = 0.4031, lr_0 = 3.0507e-04
Loss = 1.0606e-04, PNorm = 50.8179, GNorm = 0.2107, lr_0 = 3.0475e-04
Loss = 8.2723e-05, PNorm = 50.8211, GNorm = 0.2556, lr_0 = 3.0443e-04
Loss = 8.8048e-05, PNorm = 50.8238, GNorm = 0.3244, lr_0 = 3.0412e-04
Loss = 9.4125e-05, PNorm = 50.8242, GNorm = 0.2087, lr_0 = 3.0380e-04
Loss = 9.7239e-05, PNorm = 50.8267, GNorm = 0.2462, lr_0 = 3.0348e-04
Loss = 9.2184e-05, PNorm = 50.8331, GNorm = 0.2405, lr_0 = 3.0316e-04
Loss = 1.0485e-04, PNorm = 50.8367, GNorm = 0.2447, lr_0 = 3.0285e-04
Loss = 8.1049e-05, PNorm = 50.8377, GNorm = 0.1741, lr_0 = 3.0253e-04
Loss = 8.9788e-05, PNorm = 50.8412, GNorm = 0.1972, lr_0 = 3.0222e-04
Loss = 1.0135e-04, PNorm = 50.8443, GNorm = 0.2105, lr_0 = 3.0190e-04
Loss = 9.1836e-05, PNorm = 50.8466, GNorm = 0.2626, lr_0 = 3.0159e-04
Loss = 7.6578e-05, PNorm = 50.8476, GNorm = 0.1754, lr_0 = 3.0127e-04
Loss = 8.7016e-05, PNorm = 50.8537, GNorm = 0.1690, lr_0 = 3.0096e-04
Loss = 8.7719e-05, PNorm = 50.8603, GNorm = 0.1472, lr_0 = 3.0064e-04
Loss = 1.2068e-04, PNorm = 50.8630, GNorm = 0.3626, lr_0 = 3.0033e-04
Loss = 1.0427e-04, PNorm = 50.8671, GNorm = 0.3067, lr_0 = 3.0001e-04
Validation rmse logD = 0.584347
Validation R2 logD = 0.763506
Validation rmse logP = 0.475116
Validation R2 logP = 0.934485
Epoch 53
Train function
Loss = 7.7825e-05, PNorm = 50.8718, GNorm = 0.2264, lr_0 = 2.9970e-04
Loss = 8.8142e-05, PNorm = 50.8739, GNorm = 0.2958, lr_0 = 2.9939e-04
Loss = 1.0348e-04, PNorm = 50.8781, GNorm = 0.2236, lr_0 = 2.9908e-04
Loss = 8.1915e-05, PNorm = 50.8821, GNorm = 0.2587, lr_0 = 2.9876e-04
Loss = 9.7181e-05, PNorm = 50.8854, GNorm = 0.1781, lr_0 = 2.9845e-04
Loss = 7.9525e-05, PNorm = 50.8908, GNorm = 0.1984, lr_0 = 2.9814e-04
Loss = 7.3658e-05, PNorm = 50.8949, GNorm = 0.2129, lr_0 = 2.9783e-04
Loss = 7.1187e-05, PNorm = 50.8980, GNorm = 0.1653, lr_0 = 2.9752e-04
Loss = 7.9569e-05, PNorm = 50.9011, GNorm = 0.3195, lr_0 = 2.9721e-04
Loss = 8.0961e-05, PNorm = 50.9016, GNorm = 0.2098, lr_0 = 2.9690e-04
Loss = 9.3779e-05, PNorm = 50.9036, GNorm = 0.3288, lr_0 = 2.9659e-04
Loss = 9.0398e-05, PNorm = 50.9076, GNorm = 0.2249, lr_0 = 2.9628e-04
Loss = 1.2947e-04, PNorm = 50.9122, GNorm = 0.2597, lr_0 = 2.9597e-04
Loss = 1.4396e-04, PNorm = 50.9171, GNorm = 0.4104, lr_0 = 2.9566e-04
Loss = 1.1101e-04, PNorm = 50.9234, GNorm = 0.2121, lr_0 = 2.9535e-04
Loss = 1.0251e-04, PNorm = 50.9268, GNorm = 0.3872, lr_0 = 2.9504e-04
Loss = 9.3862e-05, PNorm = 50.9297, GNorm = 0.2370, lr_0 = 2.9474e-04
Loss = 9.3367e-05, PNorm = 50.9369, GNorm = 0.2266, lr_0 = 2.9443e-04
Loss = 1.0362e-04, PNorm = 50.9407, GNorm = 0.4554, lr_0 = 2.9412e-04
Loss = 8.7113e-05, PNorm = 50.9464, GNorm = 0.3189, lr_0 = 2.9381e-04
Loss = 9.6238e-05, PNorm = 50.9501, GNorm = 0.1958, lr_0 = 2.9351e-04
Loss = 9.6804e-05, PNorm = 50.9528, GNorm = 0.2618, lr_0 = 2.9320e-04
Validation rmse logD = 0.586073
Validation R2 logD = 0.762107
Validation rmse logP = 0.466562
Validation R2 logP = 0.936823
Epoch 54
Train function
Loss = 1.0013e-04, PNorm = 50.9579, GNorm = 0.2190, lr_0 = 2.9286e-04
Loss = 1.0437e-04, PNorm = 50.9626, GNorm = 0.2328, lr_0 = 2.9256e-04
Loss = 8.2074e-05, PNorm = 50.9678, GNorm = 0.1971, lr_0 = 2.9225e-04
Loss = 6.9063e-05, PNorm = 50.9723, GNorm = 0.1313, lr_0 = 2.9195e-04
Loss = 9.2685e-05, PNorm = 50.9753, GNorm = 0.2029, lr_0 = 2.9164e-04
Loss = 8.2261e-05, PNorm = 50.9776, GNorm = 0.2779, lr_0 = 2.9134e-04
Loss = 8.9863e-05, PNorm = 50.9797, GNorm = 0.1657, lr_0 = 2.9104e-04
Loss = 9.3612e-05, PNorm = 50.9819, GNorm = 0.2200, lr_0 = 2.9073e-04
Loss = 7.6302e-05, PNorm = 50.9841, GNorm = 0.2525, lr_0 = 2.9043e-04
Loss = 7.8291e-05, PNorm = 50.9880, GNorm = 0.2978, lr_0 = 2.9012e-04
Loss = 7.4549e-05, PNorm = 50.9932, GNorm = 0.3264, lr_0 = 2.8982e-04
Loss = 1.0183e-04, PNorm = 50.9962, GNorm = 0.4030, lr_0 = 2.8952e-04
Loss = 1.1780e-04, PNorm = 51.0009, GNorm = 0.3481, lr_0 = 2.8922e-04
Loss = 9.4949e-05, PNorm = 51.0023, GNorm = 0.3688, lr_0 = 2.8892e-04
Loss = 1.1299e-04, PNorm = 51.0054, GNorm = 0.1876, lr_0 = 2.8861e-04
Loss = 9.2694e-05, PNorm = 51.0095, GNorm = 0.3348, lr_0 = 2.8831e-04
Loss = 1.1736e-04, PNorm = 51.0150, GNorm = 0.2084, lr_0 = 2.8801e-04
Loss = 9.7582e-05, PNorm = 51.0168, GNorm = 0.1874, lr_0 = 2.8771e-04
Loss = 8.8747e-05, PNorm = 51.0181, GNorm = 0.2499, lr_0 = 2.8741e-04
Loss = 1.1906e-04, PNorm = 51.0229, GNorm = 0.2307, lr_0 = 2.8711e-04
Loss = 1.2857e-04, PNorm = 51.0301, GNorm = 0.2222, lr_0 = 2.8681e-04
Loss = 1.2314e-04, PNorm = 51.0339, GNorm = 0.5636, lr_0 = 2.8651e-04
Loss = 1.6872e-04, PNorm = 51.0419, GNorm = 0.5797, lr_0 = 2.8621e-04
Validation rmse logD = 0.584620
Validation R2 logD = 0.763285
Validation rmse logP = 0.473115
Validation R2 logP = 0.935036
Epoch 55
Train function
Loss = 1.3060e-04, PNorm = 51.0483, GNorm = 0.3123, lr_0 = 2.8591e-04
Loss = 1.2421e-04, PNorm = 51.0525, GNorm = 0.3675, lr_0 = 2.8562e-04
Loss = 1.2448e-04, PNorm = 51.0564, GNorm = 0.2020, lr_0 = 2.8532e-04
Loss = 9.1200e-05, PNorm = 51.0603, GNorm = 0.1586, lr_0 = 2.8502e-04
Loss = 1.1179e-04, PNorm = 51.0656, GNorm = 0.3707, lr_0 = 2.8472e-04
Loss = 1.2429e-04, PNorm = 51.0722, GNorm = 0.3271, lr_0 = 2.8443e-04
Loss = 1.2203e-04, PNorm = 51.0783, GNorm = 0.4343, lr_0 = 2.8413e-04
Loss = 1.1762e-04, PNorm = 51.0847, GNorm = 0.2928, lr_0 = 2.8383e-04
Loss = 8.0386e-05, PNorm = 51.0905, GNorm = 0.3289, lr_0 = 2.8354e-04
Loss = 9.4336e-05, PNorm = 51.0936, GNorm = 0.2780, lr_0 = 2.8324e-04
Loss = 7.4570e-05, PNorm = 51.0956, GNorm = 0.2323, lr_0 = 2.8294e-04
Loss = 7.3051e-05, PNorm = 51.0971, GNorm = 0.1266, lr_0 = 2.8265e-04
Loss = 8.5313e-05, PNorm = 51.0982, GNorm = 0.1447, lr_0 = 2.8235e-04
Loss = 1.0013e-04, PNorm = 51.1031, GNorm = 0.2858, lr_0 = 2.8206e-04
Loss = 8.8917e-05, PNorm = 51.1072, GNorm = 0.1647, lr_0 = 2.8176e-04
Loss = 9.2837e-05, PNorm = 51.1101, GNorm = 0.1689, lr_0 = 2.8147e-04
Loss = 9.4256e-05, PNorm = 51.1122, GNorm = 0.2448, lr_0 = 2.8118e-04
Loss = 8.2739e-05, PNorm = 51.1162, GNorm = 0.3817, lr_0 = 2.8088e-04
Loss = 7.9260e-05, PNorm = 51.1194, GNorm = 0.1883, lr_0 = 2.8059e-04
Loss = 6.4215e-05, PNorm = 51.1214, GNorm = 0.2773, lr_0 = 2.8030e-04
Loss = 9.0088e-05, PNorm = 51.1247, GNorm = 0.2345, lr_0 = 2.8000e-04
Loss = 7.3134e-05, PNorm = 51.1263, GNorm = 0.1596, lr_0 = 2.7971e-04
Validation rmse logD = 0.588406
Validation R2 logD = 0.760209
Validation rmse logP = 0.467036
Validation R2 logP = 0.936694
Epoch 56
Train function
Loss = 6.3465e-05, PNorm = 51.1289, GNorm = 0.1525, lr_0 = 2.7939e-04
Loss = 6.8151e-05, PNorm = 51.1303, GNorm = 0.1859, lr_0 = 2.7910e-04
Loss = 6.7558e-05, PNorm = 51.1308, GNorm = 0.1137, lr_0 = 2.7881e-04
Loss = 6.5170e-05, PNorm = 51.1329, GNorm = 0.1595, lr_0 = 2.7852e-04
Loss = 8.0272e-05, PNorm = 51.1341, GNorm = 0.1770, lr_0 = 2.7823e-04
Loss = 6.0531e-05, PNorm = 51.1359, GNorm = 0.1594, lr_0 = 2.7794e-04
Loss = 7.4120e-05, PNorm = 51.1402, GNorm = 0.1714, lr_0 = 2.7765e-04
Loss = 7.4449e-05, PNorm = 51.1435, GNorm = 0.1768, lr_0 = 2.7736e-04
Loss = 7.8690e-05, PNorm = 51.1449, GNorm = 0.1669, lr_0 = 2.7707e-04
Loss = 8.1230e-05, PNorm = 51.1457, GNorm = 0.1952, lr_0 = 2.7678e-04
Loss = 7.3106e-05, PNorm = 51.1465, GNorm = 0.2170, lr_0 = 2.7649e-04
Loss = 6.7693e-05, PNorm = 51.1491, GNorm = 0.1816, lr_0 = 2.7620e-04
Loss = 6.3920e-05, PNorm = 51.1508, GNorm = 0.1958, lr_0 = 2.7591e-04
Loss = 5.7023e-05, PNorm = 51.1556, GNorm = 0.1199, lr_0 = 2.7562e-04
Loss = 6.9284e-05, PNorm = 51.1582, GNorm = 0.2502, lr_0 = 2.7534e-04
Loss = 6.6455e-05, PNorm = 51.1604, GNorm = 0.2007, lr_0 = 2.7505e-04
Loss = 6.4970e-05, PNorm = 51.1625, GNorm = 0.1540, lr_0 = 2.7476e-04
Loss = 7.9054e-05, PNorm = 51.1649, GNorm = 0.2446, lr_0 = 2.7448e-04
Loss = 8.9447e-05, PNorm = 51.1677, GNorm = 0.2769, lr_0 = 2.7419e-04
Loss = 6.9422e-05, PNorm = 51.1706, GNorm = 0.2008, lr_0 = 2.7390e-04
Loss = 6.4864e-05, PNorm = 51.1747, GNorm = 0.1102, lr_0 = 2.7362e-04
Loss = 6.0451e-05, PNorm = 51.1785, GNorm = 0.1774, lr_0 = 2.7333e-04
Loss = 8.4430e-05, PNorm = 51.1823, GNorm = 0.1536, lr_0 = 2.7305e-04
Validation rmse logD = 0.584093
Validation R2 logD = 0.763712
Validation rmse logP = 0.468781
Validation R2 logP = 0.936221
Epoch 57
Train function
Loss = 7.2264e-05, PNorm = 51.1847, GNorm = 0.3394, lr_0 = 2.7276e-04
Loss = 8.0347e-05, PNorm = 51.1882, GNorm = 0.1460, lr_0 = 2.7248e-04
Loss = 6.0757e-05, PNorm = 51.1898, GNorm = 0.1542, lr_0 = 2.7219e-04
Loss = 5.9924e-05, PNorm = 51.1923, GNorm = 0.2313, lr_0 = 2.7191e-04
Loss = 6.3431e-05, PNorm = 51.1960, GNorm = 0.1192, lr_0 = 2.7162e-04
Loss = 7.0991e-05, PNorm = 51.1995, GNorm = 0.1070, lr_0 = 2.7134e-04
Loss = 6.8746e-05, PNorm = 51.2009, GNorm = 0.2845, lr_0 = 2.7106e-04
Loss = 6.1416e-05, PNorm = 51.2022, GNorm = 0.1527, lr_0 = 2.7077e-04
Loss = 6.3208e-05, PNorm = 51.2055, GNorm = 0.2911, lr_0 = 2.7049e-04
Loss = 8.7023e-05, PNorm = 51.2087, GNorm = 0.3087, lr_0 = 2.7021e-04
Loss = 7.7564e-05, PNorm = 51.2124, GNorm = 0.3048, lr_0 = 2.6993e-04
Loss = 7.0921e-05, PNorm = 51.2144, GNorm = 0.1763, lr_0 = 2.6965e-04
Loss = 5.3714e-05, PNorm = 51.2161, GNorm = 0.1786, lr_0 = 2.6936e-04
Loss = 6.5724e-05, PNorm = 51.2192, GNorm = 0.1390, lr_0 = 2.6908e-04
Loss = 7.9211e-05, PNorm = 51.2227, GNorm = 0.1640, lr_0 = 2.6880e-04
Loss = 7.0377e-05, PNorm = 51.2244, GNorm = 0.1806, lr_0 = 2.6852e-04
Loss = 6.9753e-05, PNorm = 51.2255, GNorm = 0.1722, lr_0 = 2.6824e-04
Loss = 7.5728e-05, PNorm = 51.2265, GNorm = 0.2168, lr_0 = 2.6796e-04
Loss = 6.9472e-05, PNorm = 51.2300, GNorm = 0.3405, lr_0 = 2.6768e-04
Loss = 7.2406e-05, PNorm = 51.2332, GNorm = 0.1570, lr_0 = 2.6740e-04
Loss = 7.4101e-05, PNorm = 51.2354, GNorm = 0.1659, lr_0 = 2.6712e-04
Loss = 6.5673e-05, PNorm = 51.2370, GNorm = 0.1856, lr_0 = 2.6684e-04
Validation rmse logD = 0.585516
Validation R2 logD = 0.762559
Validation rmse logP = 0.468942
Validation R2 logP = 0.936177
Epoch 58
Train function
Loss = 8.3526e-05, PNorm = 51.2406, GNorm = 0.2853, lr_0 = 2.6654e-04
Loss = 6.4574e-05, PNorm = 51.2444, GNorm = 0.3032, lr_0 = 2.6626e-04
Loss = 6.5924e-05, PNorm = 51.2481, GNorm = 0.2271, lr_0 = 2.6598e-04
Loss = 6.4819e-05, PNorm = 51.2500, GNorm = 0.1544, lr_0 = 2.6570e-04
Loss = 6.5722e-05, PNorm = 51.2518, GNorm = 0.1469, lr_0 = 2.6543e-04
Loss = 5.0133e-05, PNorm = 51.2553, GNorm = 0.1030, lr_0 = 2.6515e-04
Loss = 6.1134e-05, PNorm = 51.2591, GNorm = 0.2853, lr_0 = 2.6487e-04
Loss = 6.8651e-05, PNorm = 51.2613, GNorm = 0.1623, lr_0 = 2.6460e-04
Loss = 6.8536e-05, PNorm = 51.2638, GNorm = 0.1945, lr_0 = 2.6432e-04
Loss = 6.7548e-05, PNorm = 51.2653, GNorm = 0.2755, lr_0 = 2.6405e-04
Loss = 6.2178e-05, PNorm = 51.2673, GNorm = 0.1661, lr_0 = 2.6377e-04
Loss = 5.3671e-05, PNorm = 51.2716, GNorm = 0.2372, lr_0 = 2.6349e-04
Loss = 6.6904e-05, PNorm = 51.2751, GNorm = 0.3159, lr_0 = 2.6322e-04
Loss = 6.6300e-05, PNorm = 51.2790, GNorm = 0.1417, lr_0 = 2.6294e-04
Loss = 8.8423e-05, PNorm = 51.2800, GNorm = 0.1405, lr_0 = 2.6267e-04
Loss = 7.4170e-05, PNorm = 51.2839, GNorm = 0.1873, lr_0 = 2.6240e-04
Loss = 7.9287e-05, PNorm = 51.2878, GNorm = 0.4940, lr_0 = 2.6212e-04
Loss = 6.5279e-05, PNorm = 51.2937, GNorm = 0.2235, lr_0 = 2.6185e-04
Loss = 6.0048e-05, PNorm = 51.2958, GNorm = 0.2919, lr_0 = 2.6158e-04
Loss = 7.4208e-05, PNorm = 51.2986, GNorm = 0.1642, lr_0 = 2.6130e-04
Loss = 6.9828e-05, PNorm = 51.3005, GNorm = 0.1607, lr_0 = 2.6103e-04
Loss = 7.9128e-05, PNorm = 51.3054, GNorm = 0.2091, lr_0 = 2.6076e-04
Loss = 8.2675e-05, PNorm = 51.3043, GNorm = 0.1821, lr_0 = 2.6048e-04
Validation rmse logD = 0.584793
Validation R2 logD = 0.763146
Validation rmse logP = 0.466873
Validation R2 logP = 0.936739
Epoch 59
Train function
Loss = 7.2608e-05, PNorm = 51.3075, GNorm = 0.1728, lr_0 = 2.6021e-04
Loss = 6.3009e-05, PNorm = 51.3092, GNorm = 0.1639, lr_0 = 2.5994e-04
Loss = 6.3356e-05, PNorm = 51.3092, GNorm = 0.1848, lr_0 = 2.5967e-04
Loss = 6.0353e-05, PNorm = 51.3119, GNorm = 0.2028, lr_0 = 2.5940e-04
Loss = 5.5244e-05, PNorm = 51.3151, GNorm = 0.2222, lr_0 = 2.5913e-04
Loss = 6.1370e-05, PNorm = 51.3167, GNorm = 0.1906, lr_0 = 2.5886e-04
Loss = 5.6578e-05, PNorm = 51.3203, GNorm = 0.1378, lr_0 = 2.5859e-04
Loss = 6.5658e-05, PNorm = 51.3222, GNorm = 0.2007, lr_0 = 2.5832e-04
Loss = 5.3177e-05, PNorm = 51.3239, GNorm = 0.1336, lr_0 = 2.5805e-04
Loss = 5.1141e-05, PNorm = 51.3267, GNorm = 0.1233, lr_0 = 2.5778e-04
Loss = 7.6448e-05, PNorm = 51.3279, GNorm = 0.2655, lr_0 = 2.5751e-04
Loss = 7.7537e-05, PNorm = 51.3313, GNorm = 0.1484, lr_0 = 2.5724e-04
Loss = 5.7764e-05, PNorm = 51.3334, GNorm = 0.0949, lr_0 = 2.5697e-04
Loss = 7.0617e-05, PNorm = 51.3352, GNorm = 0.1725, lr_0 = 2.5670e-04
Loss = 6.3623e-05, PNorm = 51.3402, GNorm = 0.1785, lr_0 = 2.5644e-04
Loss = 6.7803e-05, PNorm = 51.3439, GNorm = 0.1431, lr_0 = 2.5617e-04
Loss = 6.8806e-05, PNorm = 51.3475, GNorm = 0.1535, lr_0 = 2.5590e-04
Loss = 6.3232e-05, PNorm = 51.3504, GNorm = 0.1442, lr_0 = 2.5563e-04
Loss = 5.8576e-05, PNorm = 51.3544, GNorm = 0.2516, lr_0 = 2.5537e-04
Loss = 6.2475e-05, PNorm = 51.3571, GNorm = 0.1414, lr_0 = 2.5510e-04
Loss = 5.5352e-05, PNorm = 51.3598, GNorm = 0.1734, lr_0 = 2.5483e-04
Loss = 6.0814e-05, PNorm = 51.3634, GNorm = 0.1015, lr_0 = 2.5457e-04
Validation rmse logD = 0.586390
Validation R2 logD = 0.761850
Validation rmse logP = 0.464154
Validation R2 logP = 0.937473
Epoch 60
Train function
Loss = 7.8188e-05, PNorm = 51.3651, GNorm = 0.2417, lr_0 = 2.5428e-04
Loss = 5.8246e-05, PNorm = 51.3665, GNorm = 0.1654, lr_0 = 2.5401e-04
Loss = 6.4711e-05, PNorm = 51.3697, GNorm = 0.1733, lr_0 = 2.5375e-04
Loss = 6.1861e-05, PNorm = 51.3709, GNorm = 0.2183, lr_0 = 2.5348e-04
Loss = 6.6856e-05, PNorm = 51.3735, GNorm = 0.1540, lr_0 = 2.5322e-04
Loss = 5.5157e-05, PNorm = 51.3764, GNorm = 0.1613, lr_0 = 2.5295e-04
Loss = 5.7646e-05, PNorm = 51.3802, GNorm = 0.0999, lr_0 = 2.5269e-04
Loss = 5.8359e-05, PNorm = 51.3832, GNorm = 0.1298, lr_0 = 2.5242e-04
Loss = 4.8648e-05, PNorm = 51.3870, GNorm = 0.2065, lr_0 = 2.5216e-04
Loss = 5.3611e-05, PNorm = 51.3890, GNorm = 0.4004, lr_0 = 2.5190e-04
Loss = 6.7182e-05, PNorm = 51.3891, GNorm = 0.2077, lr_0 = 2.5163e-04
Loss = 6.0684e-05, PNorm = 51.3922, GNorm = 0.1599, lr_0 = 2.5137e-04
Loss = 5.8891e-05, PNorm = 51.3958, GNorm = 0.1073, lr_0 = 2.5111e-04
Loss = 5.8668e-05, PNorm = 51.3987, GNorm = 0.2658, lr_0 = 2.5085e-04
Loss = 6.6259e-05, PNorm = 51.3999, GNorm = 0.1820, lr_0 = 2.5059e-04
Loss = 7.7278e-05, PNorm = 51.4032, GNorm = 0.2678, lr_0 = 2.5032e-04
Loss = 6.0402e-05, PNorm = 51.4044, GNorm = 0.1491, lr_0 = 2.5006e-04
Loss = 7.8768e-05, PNorm = 51.4059, GNorm = 0.2943, lr_0 = 2.4980e-04
Loss = 9.1373e-05, PNorm = 51.4100, GNorm = 0.2240, lr_0 = 2.4954e-04
Loss = 6.7695e-05, PNorm = 51.4133, GNorm = 0.2604, lr_0 = 2.4928e-04
Loss = 1.0846e-04, PNorm = 51.4169, GNorm = 0.2806, lr_0 = 2.4902e-04
Loss = 6.7465e-05, PNorm = 51.4211, GNorm = 0.2572, lr_0 = 2.4876e-04
Loss = 5.5361e-05, PNorm = 51.4250, GNorm = 0.1692, lr_0 = 2.4850e-04
Validation rmse logD = 0.585115
Validation R2 logD = 0.762885
Validation rmse logP = 0.468085
Validation R2 logP = 0.936410
Epoch 61
Train function
Loss = 5.9807e-05, PNorm = 51.4282, GNorm = 0.1893, lr_0 = 2.4824e-04
Loss = 7.9260e-05, PNorm = 51.4304, GNorm = 0.1226, lr_0 = 2.4798e-04
Loss = 6.9160e-05, PNorm = 51.4348, GNorm = 0.3166, lr_0 = 2.4772e-04
Loss = 6.6795e-05, PNorm = 51.4363, GNorm = 0.2261, lr_0 = 2.4747e-04
Loss = 5.4458e-05, PNorm = 51.4390, GNorm = 0.1345, lr_0 = 2.4721e-04
Loss = 5.4908e-05, PNorm = 51.4443, GNorm = 0.1649, lr_0 = 2.4695e-04
Loss = 4.7091e-05, PNorm = 51.4465, GNorm = 0.1217, lr_0 = 2.4669e-04
Loss = 5.1019e-05, PNorm = 51.4481, GNorm = 0.1222, lr_0 = 2.4643e-04
Loss = 5.3645e-05, PNorm = 51.4510, GNorm = 0.1500, lr_0 = 2.4618e-04
Loss = 5.4627e-05, PNorm = 51.4519, GNorm = 0.2232, lr_0 = 2.4592e-04
Loss = 5.3394e-05, PNorm = 51.4539, GNorm = 0.1663, lr_0 = 2.4566e-04
Loss = 5.3294e-05, PNorm = 51.4559, GNorm = 0.1502, lr_0 = 2.4541e-04
Loss = 5.6775e-05, PNorm = 51.4596, GNorm = 0.1770, lr_0 = 2.4515e-04
Loss = 6.2437e-05, PNorm = 51.4625, GNorm = 0.4048, lr_0 = 2.4489e-04
Loss = 6.1370e-05, PNorm = 51.4648, GNorm = 0.3229, lr_0 = 2.4464e-04
Loss = 5.5831e-05, PNorm = 51.4683, GNorm = 0.1268, lr_0 = 2.4438e-04
Loss = 5.4775e-05, PNorm = 51.4693, GNorm = 0.2165, lr_0 = 2.4413e-04
Loss = 5.8308e-05, PNorm = 51.4706, GNorm = 0.1153, lr_0 = 2.4387e-04
Loss = 6.2838e-05, PNorm = 51.4740, GNorm = 0.3074, lr_0 = 2.4362e-04
Loss = 7.5336e-05, PNorm = 51.4780, GNorm = 0.1906, lr_0 = 2.4337e-04
Loss = 6.3494e-05, PNorm = 51.4824, GNorm = 0.1504, lr_0 = 2.4311e-04
Loss = 7.0413e-05, PNorm = 51.4843, GNorm = 0.2145, lr_0 = 2.4286e-04
Validation rmse logD = 0.591524
Validation R2 logD = 0.757662
Validation rmse logP = 0.465880
Validation R2 logP = 0.937008
Epoch 62
Train function
Loss = 9.1891e-05, PNorm = 51.4851, GNorm = 0.3302, lr_0 = 2.4258e-04
Loss = 6.2546e-05, PNorm = 51.4895, GNorm = 0.2768, lr_0 = 2.4233e-04
Loss = 6.3146e-05, PNorm = 51.4917, GNorm = 0.2320, lr_0 = 2.4207e-04
Loss = 5.4283e-05, PNorm = 51.4941, GNorm = 0.1355, lr_0 = 2.4182e-04
Loss = 5.4448e-05, PNorm = 51.4975, GNorm = 0.1888, lr_0 = 2.4157e-04
Loss = 5.8601e-05, PNorm = 51.5015, GNorm = 0.2173, lr_0 = 2.4132e-04
Loss = 6.0523e-05, PNorm = 51.5056, GNorm = 0.1443, lr_0 = 2.4106e-04
Loss = 5.5389e-05, PNorm = 51.5087, GNorm = 0.1555, lr_0 = 2.4081e-04
Loss = 5.3467e-05, PNorm = 51.5131, GNorm = 0.1058, lr_0 = 2.4056e-04
Loss = 4.8651e-05, PNorm = 51.5140, GNorm = 0.1762, lr_0 = 2.4031e-04
Loss = 4.1413e-05, PNorm = 51.5161, GNorm = 0.1809, lr_0 = 2.4006e-04
Loss = 5.7662e-05, PNorm = 51.5176, GNorm = 0.2597, lr_0 = 2.3981e-04
Loss = 8.2479e-05, PNorm = 51.5203, GNorm = 0.3761, lr_0 = 2.3956e-04
Loss = 6.7072e-05, PNorm = 51.5214, GNorm = 0.2117, lr_0 = 2.3931e-04
Loss = 7.6377e-05, PNorm = 51.5245, GNorm = 0.2053, lr_0 = 2.3906e-04
Loss = 6.3915e-05, PNorm = 51.5288, GNorm = 0.2503, lr_0 = 2.3881e-04
Loss = 5.3146e-05, PNorm = 51.5317, GNorm = 0.1777, lr_0 = 2.3856e-04
Loss = 6.1680e-05, PNorm = 51.5339, GNorm = 0.1192, lr_0 = 2.3831e-04
Loss = 5.9214e-05, PNorm = 51.5363, GNorm = 0.1500, lr_0 = 2.3806e-04
Loss = 5.0697e-05, PNorm = 51.5397, GNorm = 0.1838, lr_0 = 2.3781e-04
Loss = 4.2745e-05, PNorm = 51.5405, GNorm = 0.1889, lr_0 = 2.3756e-04
Loss = 5.4016e-05, PNorm = 51.5423, GNorm = 0.1223, lr_0 = 2.3732e-04
Loss = 4.2366e-05, PNorm = 51.5441, GNorm = 0.1094, lr_0 = 2.3707e-04
Validation rmse logD = 0.586797
Validation R2 logD = 0.761519
Validation rmse logP = 0.464781
Validation R2 logP = 0.937304
Epoch 63
Train function
Loss = 5.0370e-05, PNorm = 51.5455, GNorm = 0.2875, lr_0 = 2.3682e-04
Loss = 5.9118e-05, PNorm = 51.5477, GNorm = 0.0923, lr_0 = 2.3657e-04
Loss = 5.2859e-05, PNorm = 51.5504, GNorm = 0.2024, lr_0 = 2.3633e-04
Loss = 4.5953e-05, PNorm = 51.5512, GNorm = 0.1972, lr_0 = 2.3608e-04
Loss = 4.4291e-05, PNorm = 51.5538, GNorm = 0.1353, lr_0 = 2.3583e-04
Loss = 5.3210e-05, PNorm = 51.5556, GNorm = 0.2110, lr_0 = 2.3559e-04
Loss = 4.7794e-05, PNorm = 51.5574, GNorm = 0.0910, lr_0 = 2.3534e-04
Loss = 5.5512e-05, PNorm = 51.5612, GNorm = 0.1705, lr_0 = 2.3510e-04
Loss = 4.6557e-05, PNorm = 51.5645, GNorm = 0.0882, lr_0 = 2.3485e-04
Loss = 4.9582e-05, PNorm = 51.5641, GNorm = 0.1563, lr_0 = 2.3461e-04
Loss = 5.2826e-05, PNorm = 51.5666, GNorm = 0.2368, lr_0 = 2.3436e-04
Loss = 6.0304e-05, PNorm = 51.5687, GNorm = 0.1175, lr_0 = 2.3412e-04
Loss = 4.6186e-05, PNorm = 51.5695, GNorm = 0.1527, lr_0 = 2.3387e-04
Loss = 4.5809e-05, PNorm = 51.5707, GNorm = 0.1510, lr_0 = 2.3363e-04
Loss = 5.2678e-05, PNorm = 51.5717, GNorm = 0.1792, lr_0 = 2.3338e-04
Loss = 6.2507e-05, PNorm = 51.5737, GNorm = 0.1611, lr_0 = 2.3314e-04
Loss = 6.6213e-05, PNorm = 51.5754, GNorm = 0.1150, lr_0 = 2.3290e-04
Loss = 8.4558e-05, PNorm = 51.5795, GNorm = 0.1762, lr_0 = 2.3265e-04
Loss = 8.5201e-05, PNorm = 51.5832, GNorm = 0.2701, lr_0 = 2.3241e-04
Loss = 8.0040e-05, PNorm = 51.5866, GNorm = 0.3878, lr_0 = 2.3217e-04
Loss = 9.2737e-05, PNorm = 51.5912, GNorm = 0.2178, lr_0 = 2.3193e-04
Loss = 9.4637e-05, PNorm = 51.5966, GNorm = 0.4002, lr_0 = 2.3169e-04
Loss = 8.5581e-05, PNorm = 51.5998, GNorm = 0.2211, lr_0 = 2.3144e-04
Loss = 1.8588e-04, PNorm = 51.6004, GNorm = 0.3463, lr_0 = 2.3142e-04
Validation rmse logD = 0.617071
Validation R2 logD = 0.736277
Validation rmse logP = 0.469375
Validation R2 logP = 0.936059
Epoch 64
Train function
Loss = 1.0494e-04, PNorm = 51.6067, GNorm = 0.1808, lr_0 = 2.3118e-04
Loss = 6.4791e-05, PNorm = 51.6089, GNorm = 0.1830, lr_0 = 2.3094e-04
Loss = 6.8241e-05, PNorm = 51.6090, GNorm = 0.1557, lr_0 = 2.3070e-04
Loss = 6.5160e-05, PNorm = 51.6100, GNorm = 0.2184, lr_0 = 2.3045e-04
Loss = 5.9802e-05, PNorm = 51.6128, GNorm = 0.2541, lr_0 = 2.3021e-04
Loss = 6.2340e-05, PNorm = 51.6145, GNorm = 0.1485, lr_0 = 2.2997e-04
Loss = 5.4745e-05, PNorm = 51.6176, GNorm = 0.1517, lr_0 = 2.2973e-04
Loss = 4.4622e-05, PNorm = 51.6206, GNorm = 0.1614, lr_0 = 2.2949e-04
Loss = 4.7251e-05, PNorm = 51.6229, GNorm = 0.1743, lr_0 = 2.2925e-04
Loss = 5.3426e-05, PNorm = 51.6246, GNorm = 0.2339, lr_0 = 2.2902e-04
Loss = 6.1541e-05, PNorm = 51.6249, GNorm = 0.2572, lr_0 = 2.2878e-04
Loss = 4.6773e-05, PNorm = 51.6260, GNorm = 0.2204, lr_0 = 2.2854e-04
Loss = 5.9817e-05, PNorm = 51.6292, GNorm = 0.1575, lr_0 = 2.2830e-04
Loss = 4.9176e-05, PNorm = 51.6317, GNorm = 0.2527, lr_0 = 2.2806e-04
Loss = 5.6537e-05, PNorm = 51.6337, GNorm = 0.1877, lr_0 = 2.2782e-04
Loss = 5.4263e-05, PNorm = 51.6377, GNorm = 0.1988, lr_0 = 2.2758e-04
Loss = 5.2383e-05, PNorm = 51.6392, GNorm = 0.1806, lr_0 = 2.2735e-04
Loss = 5.4564e-05, PNorm = 51.6397, GNorm = 0.1686, lr_0 = 2.2711e-04
Loss = 5.3373e-05, PNorm = 51.6423, GNorm = 0.1869, lr_0 = 2.2687e-04
Loss = 4.9568e-05, PNorm = 51.6444, GNorm = 0.1449, lr_0 = 2.2664e-04
Loss = 3.7649e-05, PNorm = 51.6461, GNorm = 0.1667, lr_0 = 2.2640e-04
Loss = 4.9130e-05, PNorm = 51.6475, GNorm = 0.2178, lr_0 = 2.2616e-04
Validation rmse logD = 0.582756
Validation R2 logD = 0.764793
Validation rmse logP = 0.466228
Validation R2 logP = 0.936913
Epoch 65
Train function
Loss = 3.8096e-05, PNorm = 51.6512, GNorm = 0.1436, lr_0 = 2.2593e-04
Loss = 4.4856e-05, PNorm = 51.6543, GNorm = 0.1196, lr_0 = 2.2569e-04
Loss = 3.6678e-05, PNorm = 51.6557, GNorm = 0.1310, lr_0 = 2.2546e-04
Loss = 4.4617e-05, PNorm = 51.6560, GNorm = 0.1763, lr_0 = 2.2522e-04
Loss = 4.7236e-05, PNorm = 51.6591, GNorm = 0.1387, lr_0 = 2.2499e-04
Loss = 3.6407e-05, PNorm = 51.6628, GNorm = 0.1324, lr_0 = 2.2475e-04
Loss = 4.8712e-05, PNorm = 51.6640, GNorm = 0.1171, lr_0 = 2.2452e-04
Loss = 5.6187e-05, PNorm = 51.6644, GNorm = 0.1869, lr_0 = 2.2428e-04
Loss = 4.9082e-05, PNorm = 51.6641, GNorm = 0.1887, lr_0 = 2.2405e-04
Loss = 5.7179e-05, PNorm = 51.6644, GNorm = 0.2822, lr_0 = 2.2381e-04
Loss = 5.5003e-05, PNorm = 51.6649, GNorm = 0.2720, lr_0 = 2.2358e-04
Loss = 5.3435e-05, PNorm = 51.6669, GNorm = 0.1973, lr_0 = 2.2335e-04
Loss = 4.6784e-05, PNorm = 51.6685, GNorm = 0.1026, lr_0 = 2.2311e-04
Loss = 4.6609e-05, PNorm = 51.6694, GNorm = 0.1245, lr_0 = 2.2288e-04
Loss = 4.8504e-05, PNorm = 51.6723, GNorm = 0.2589, lr_0 = 2.2265e-04
Loss = 5.3591e-05, PNorm = 51.6751, GNorm = 0.1544, lr_0 = 2.2242e-04
Loss = 4.9702e-05, PNorm = 51.6772, GNorm = 0.1364, lr_0 = 2.2218e-04
Loss = 4.7641e-05, PNorm = 51.6782, GNorm = 0.1890, lr_0 = 2.2195e-04
Loss = 4.3875e-05, PNorm = 51.6803, GNorm = 0.1320, lr_0 = 2.2172e-04
Loss = 5.3872e-05, PNorm = 51.6823, GNorm = 0.1293, lr_0 = 2.2149e-04
Loss = 4.3892e-05, PNorm = 51.6862, GNorm = 0.1140, lr_0 = 2.2126e-04
Loss = 4.1123e-05, PNorm = 51.6875, GNorm = 0.0826, lr_0 = 2.2103e-04
Loss = 5.0601e-05, PNorm = 51.6893, GNorm = 0.1915, lr_0 = 2.2080e-04
Validation rmse logD = 0.585844
Validation R2 logD = 0.762293
Validation rmse logP = 0.468461
Validation R2 logP = 0.936308
Epoch 66
Train function
Loss = 3.8278e-05, PNorm = 51.6910, GNorm = 0.2492, lr_0 = 2.2054e-04
Loss = 4.1089e-05, PNorm = 51.6950, GNorm = 0.1074, lr_0 = 2.2031e-04
Loss = 4.0634e-05, PNorm = 51.6990, GNorm = 0.1219, lr_0 = 2.2008e-04
Loss = 3.2417e-05, PNorm = 51.7020, GNorm = 0.2042, lr_0 = 2.1985e-04
Loss = 4.8165e-05, PNorm = 51.7029, GNorm = 0.2096, lr_0 = 2.1962e-04
Loss = 5.1166e-05, PNorm = 51.7038, GNorm = 0.1606, lr_0 = 2.1939e-04
Loss = 4.2507e-05, PNorm = 51.7068, GNorm = 0.2757, lr_0 = 2.1916e-04
Loss = 4.8670e-05, PNorm = 51.7074, GNorm = 0.1442, lr_0 = 2.1894e-04
Loss = 3.9552e-05, PNorm = 51.7096, GNorm = 0.0854, lr_0 = 2.1871e-04
Loss = 4.0894e-05, PNorm = 51.7109, GNorm = 0.1773, lr_0 = 2.1848e-04
Loss = 3.6772e-05, PNorm = 51.7143, GNorm = 0.1959, lr_0 = 2.1825e-04
Loss = 4.7234e-05, PNorm = 51.7160, GNorm = 0.2391, lr_0 = 2.1802e-04
Loss = 3.1871e-05, PNorm = 51.7179, GNorm = 0.1041, lr_0 = 2.1780e-04
Loss = 4.3640e-05, PNorm = 51.7201, GNorm = 0.1095, lr_0 = 2.1757e-04
Loss = 5.8224e-05, PNorm = 51.7224, GNorm = 0.0966, lr_0 = 2.1734e-04
Loss = 4.8050e-05, PNorm = 51.7250, GNorm = 0.1867, lr_0 = 2.1711e-04
Loss = 3.7580e-05, PNorm = 51.7261, GNorm = 0.1839, lr_0 = 2.1689e-04
Loss = 4.1297e-05, PNorm = 51.7279, GNorm = 0.1234, lr_0 = 2.1666e-04
Loss = 4.9826e-05, PNorm = 51.7285, GNorm = 0.1020, lr_0 = 2.1644e-04
Loss = 5.8360e-05, PNorm = 51.7306, GNorm = 0.1136, lr_0 = 2.1621e-04
Loss = 4.2892e-05, PNorm = 51.7318, GNorm = 0.1639, lr_0 = 2.1598e-04
Loss = 4.5067e-05, PNorm = 51.7321, GNorm = 0.3335, lr_0 = 2.1576e-04
Validation rmse logD = 0.582788
Validation R2 logD = 0.764766
Validation rmse logP = 0.465518
Validation R2 logP = 0.937105
Epoch 67
Train function
Loss = 4.7181e-05, PNorm = 51.7356, GNorm = 0.2578, lr_0 = 2.1553e-04
Loss = 5.1767e-05, PNorm = 51.7376, GNorm = 0.2374, lr_0 = 2.1531e-04
Loss = 3.9048e-05, PNorm = 51.7380, GNorm = 0.1168, lr_0 = 2.1508e-04
Loss = 4.6442e-05, PNorm = 51.7391, GNorm = 0.1668, lr_0 = 2.1486e-04
Loss = 3.8180e-05, PNorm = 51.7413, GNorm = 0.1498, lr_0 = 2.1464e-04
Loss = 4.5302e-05, PNorm = 51.7434, GNorm = 0.1089, lr_0 = 2.1441e-04
Loss = 3.2765e-05, PNorm = 51.7443, GNorm = 0.1532, lr_0 = 2.1419e-04
Loss = 3.6077e-05, PNorm = 51.7463, GNorm = 0.1853, lr_0 = 2.1396e-04
Loss = 3.8869e-05, PNorm = 51.7482, GNorm = 0.0801, lr_0 = 2.1374e-04
Loss = 3.4029e-05, PNorm = 51.7486, GNorm = 0.1456, lr_0 = 2.1352e-04
Loss = 4.4982e-05, PNorm = 51.7484, GNorm = 0.1476, lr_0 = 2.1329e-04
Loss = 4.1039e-05, PNorm = 51.7505, GNorm = 0.1014, lr_0 = 2.1307e-04
Loss = 4.1628e-05, PNorm = 51.7540, GNorm = 0.1406, lr_0 = 2.1285e-04
Loss = 3.9462e-05, PNorm = 51.7561, GNorm = 0.1627, lr_0 = 2.1263e-04
Loss = 4.8529e-05, PNorm = 51.7561, GNorm = 0.1273, lr_0 = 2.1241e-04
Loss = 4.7141e-05, PNorm = 51.7602, GNorm = 0.1943, lr_0 = 2.1218e-04
Loss = 3.9483e-05, PNorm = 51.7624, GNorm = 0.0957, lr_0 = 2.1196e-04
Loss = 4.9240e-05, PNorm = 51.7633, GNorm = 0.1405, lr_0 = 2.1174e-04
Loss = 3.8244e-05, PNorm = 51.7653, GNorm = 0.1360, lr_0 = 2.1152e-04
Loss = 5.2405e-05, PNorm = 51.7670, GNorm = 0.2895, lr_0 = 2.1130e-04
Loss = 4.9740e-05, PNorm = 51.7692, GNorm = 0.1346, lr_0 = 2.1108e-04
Loss = 5.0057e-05, PNorm = 51.7728, GNorm = 0.1132, lr_0 = 2.1086e-04
Loss = 3.9124e-05, PNorm = 51.7733, GNorm = 0.0904, lr_0 = 2.1064e-04
Validation rmse logD = 0.580794
Validation R2 logD = 0.766374
Validation rmse logP = 0.467629
Validation R2 logP = 0.936534
Epoch 68
Train function
Loss = 3.8461e-05, PNorm = 51.7758, GNorm = 0.2643, lr_0 = 2.1040e-04
Loss = 3.3990e-05, PNorm = 51.7782, GNorm = 0.1218, lr_0 = 2.1018e-04
Loss = 4.3731e-05, PNorm = 51.7784, GNorm = 0.1750, lr_0 = 2.0996e-04
Loss = 4.1491e-05, PNorm = 51.7800, GNorm = 0.1969, lr_0 = 2.0974e-04
Loss = 3.7422e-05, PNorm = 51.7818, GNorm = 0.2170, lr_0 = 2.0952e-04
Loss = 3.5038e-05, PNorm = 51.7831, GNorm = 0.2078, lr_0 = 2.0930e-04
Loss = 3.8420e-05, PNorm = 51.7865, GNorm = 0.1093, lr_0 = 2.0908e-04
Loss = 3.4689e-05, PNorm = 51.7893, GNorm = 0.1037, lr_0 = 2.0886e-04
Loss = 3.9209e-05, PNorm = 51.7909, GNorm = 0.1398, lr_0 = 2.0865e-04
Loss = 3.1206e-05, PNorm = 51.7909, GNorm = 0.1081, lr_0 = 2.0843e-04
Loss = 3.1295e-05, PNorm = 51.7920, GNorm = 0.1824, lr_0 = 2.0821e-04
Loss = 3.7681e-05, PNorm = 51.7945, GNorm = 0.1699, lr_0 = 2.0799e-04
Loss = 3.0721e-05, PNorm = 51.7957, GNorm = 0.1745, lr_0 = 2.0778e-04
Loss = 3.7184e-05, PNorm = 51.7973, GNorm = 0.1980, lr_0 = 2.0756e-04
Loss = 3.5672e-05, PNorm = 51.7999, GNorm = 0.1404, lr_0 = 2.0734e-04
Loss = 3.6898e-05, PNorm = 51.8014, GNorm = 0.0915, lr_0 = 2.0713e-04
Loss = 3.9504e-05, PNorm = 51.8052, GNorm = 0.1457, lr_0 = 2.0691e-04
Loss = 3.8009e-05, PNorm = 51.8067, GNorm = 0.1222, lr_0 = 2.0669e-04
Loss = 4.5675e-05, PNorm = 51.8072, GNorm = 0.1367, lr_0 = 2.0648e-04
Loss = 5.9631e-05, PNorm = 51.8112, GNorm = 0.2025, lr_0 = 2.0626e-04
Loss = 5.5685e-05, PNorm = 51.8138, GNorm = 0.2161, lr_0 = 2.0605e-04
Loss = 5.5387e-05, PNorm = 51.8157, GNorm = 0.1821, lr_0 = 2.0583e-04
Validation rmse logD = 0.580033
Validation R2 logD = 0.766985
Validation rmse logP = 0.469481
Validation R2 logP = 0.936030
Epoch 69
Train function
Loss = 6.1263e-05, PNorm = 51.8183, GNorm = 0.1869, lr_0 = 2.0562e-04
Loss = 5.1245e-05, PNorm = 51.8208, GNorm = 0.1622, lr_0 = 2.0540e-04
Loss = 5.1497e-05, PNorm = 51.8244, GNorm = 0.2004, lr_0 = 2.0519e-04
Loss = 5.3292e-05, PNorm = 51.8280, GNorm = 0.2804, lr_0 = 2.0497e-04
Loss = 6.3150e-05, PNorm = 51.8307, GNorm = 0.2185, lr_0 = 2.0476e-04
Loss = 6.0263e-05, PNorm = 51.8332, GNorm = 0.2396, lr_0 = 2.0455e-04
Loss = 5.7780e-05, PNorm = 51.8358, GNorm = 0.3564, lr_0 = 2.0433e-04
Loss = 4.4773e-05, PNorm = 51.8375, GNorm = 0.1237, lr_0 = 2.0412e-04
Loss = 4.6494e-05, PNorm = 51.8406, GNorm = 0.1529, lr_0 = 2.0391e-04
Loss = 5.2663e-05, PNorm = 51.8430, GNorm = 0.1521, lr_0 = 2.0369e-04
Loss = 3.7204e-05, PNorm = 51.8452, GNorm = 0.0990, lr_0 = 2.0348e-04
Loss = 5.0431e-05, PNorm = 51.8457, GNorm = 0.2546, lr_0 = 2.0327e-04
Loss = 3.9328e-05, PNorm = 51.8465, GNorm = 0.1617, lr_0 = 2.0306e-04
Loss = 4.1388e-05, PNorm = 51.8486, GNorm = 0.1354, lr_0 = 2.0285e-04
Loss = 4.0937e-05, PNorm = 51.8501, GNorm = 0.1915, lr_0 = 2.0263e-04
Loss = 4.0301e-05, PNorm = 51.8501, GNorm = 0.1763, lr_0 = 2.0242e-04
Loss = 3.8470e-05, PNorm = 51.8517, GNorm = 0.1703, lr_0 = 2.0221e-04
Loss = 3.5343e-05, PNorm = 51.8537, GNorm = 0.1769, lr_0 = 2.0200e-04
Loss = 4.4125e-05, PNorm = 51.8556, GNorm = 0.2315, lr_0 = 2.0179e-04
Loss = 4.0690e-05, PNorm = 51.8580, GNorm = 0.1299, lr_0 = 2.0158e-04
Loss = 4.0523e-05, PNorm = 51.8598, GNorm = 0.0893, lr_0 = 2.0137e-04
Loss = 3.4357e-05, PNorm = 51.8618, GNorm = 0.1348, lr_0 = 2.0116e-04
Loss = 3.3111e-05, PNorm = 51.8631, GNorm = 0.1685, lr_0 = 2.0095e-04
Validation rmse logD = 0.582049
Validation R2 logD = 0.765363
Validation rmse logP = 0.469575
Validation R2 logP = 0.936004
Epoch 70
Train function
Loss = 4.1387e-05, PNorm = 51.8654, GNorm = 0.1351, lr_0 = 2.0072e-04
Loss = 2.9452e-05, PNorm = 51.8690, GNorm = 0.1119, lr_0 = 2.0051e-04
Loss = 3.3735e-05, PNorm = 51.8695, GNorm = 0.1461, lr_0 = 2.0030e-04
Loss = 2.8731e-05, PNorm = 51.8714, GNorm = 0.1147, lr_0 = 2.0009e-04
Loss = 3.0065e-05, PNorm = 51.8734, GNorm = 0.1475, lr_0 = 1.9988e-04
Loss = 3.5217e-05, PNorm = 51.8736, GNorm = 0.1021, lr_0 = 1.9967e-04
Loss = 3.9433e-05, PNorm = 51.8749, GNorm = 0.2292, lr_0 = 1.9946e-04
Loss = 4.7470e-05, PNorm = 51.8786, GNorm = 0.2773, lr_0 = 1.9926e-04
Loss = 5.1567e-05, PNorm = 51.8792, GNorm = 0.1201, lr_0 = 1.9905e-04
Loss = 4.1835e-05, PNorm = 51.8817, GNorm = 0.1745, lr_0 = 1.9884e-04
Loss = 4.5198e-05, PNorm = 51.8849, GNorm = 0.2106, lr_0 = 1.9863e-04
Loss = 4.2285e-05, PNorm = 51.8864, GNorm = 0.2884, lr_0 = 1.9842e-04
Loss = 4.3169e-05, PNorm = 51.8888, GNorm = 0.1188, lr_0 = 1.9822e-04
Loss = 4.3777e-05, PNorm = 51.8890, GNorm = 0.2188, lr_0 = 1.9801e-04
Loss = 4.1544e-05, PNorm = 51.8907, GNorm = 0.2162, lr_0 = 1.9780e-04
Loss = 4.8386e-05, PNorm = 51.8920, GNorm = 0.1728, lr_0 = 1.9760e-04
Loss = 4.9375e-05, PNorm = 51.8931, GNorm = 0.1170, lr_0 = 1.9739e-04
Loss = 4.5654e-05, PNorm = 51.8942, GNorm = 0.2020, lr_0 = 1.9719e-04
Loss = 4.9165e-05, PNorm = 51.8968, GNorm = 0.2980, lr_0 = 1.9698e-04
Loss = 6.5531e-05, PNorm = 51.9015, GNorm = 0.3890, lr_0 = 1.9677e-04
Loss = 6.4705e-05, PNorm = 51.9035, GNorm = 0.2371, lr_0 = 1.9657e-04
Loss = 6.5199e-05, PNorm = 51.9062, GNorm = 0.2744, lr_0 = 1.9636e-04
Validation rmse logD = 0.586326
Validation R2 logD = 0.761902
Validation rmse logP = 0.468969
Validation R2 logP = 0.936169
Epoch 71
Train function
Loss = 4.1937e-05, PNorm = 51.9092, GNorm = 0.1234, lr_0 = 1.9616e-04
Loss = 4.5099e-05, PNorm = 51.9129, GNorm = 0.1226, lr_0 = 1.9595e-04
Loss = 4.6633e-05, PNorm = 51.9146, GNorm = 0.2061, lr_0 = 1.9575e-04
Loss = 5.1581e-05, PNorm = 51.9170, GNorm = 0.2327, lr_0 = 1.9555e-04
Loss = 6.4728e-05, PNorm = 51.9217, GNorm = 0.2655, lr_0 = 1.9534e-04
Loss = 7.7006e-05, PNorm = 51.9229, GNorm = 0.3010, lr_0 = 1.9514e-04
Loss = 4.9729e-05, PNorm = 51.9253, GNorm = 0.1682, lr_0 = 1.9493e-04
Loss = 4.9124e-05, PNorm = 51.9287, GNorm = 0.1570, lr_0 = 1.9473e-04
Loss = 5.0694e-05, PNorm = 51.9292, GNorm = 0.0828, lr_0 = 1.9453e-04
Loss = 3.9367e-05, PNorm = 51.9312, GNorm = 0.0900, lr_0 = 1.9432e-04
Loss = 3.9567e-05, PNorm = 51.9336, GNorm = 0.0899, lr_0 = 1.9412e-04
Loss = 4.1488e-05, PNorm = 51.9358, GNorm = 0.1313, lr_0 = 1.9392e-04
Loss = 3.7505e-05, PNorm = 51.9389, GNorm = 0.1170, lr_0 = 1.9372e-04
Loss = 4.2825e-05, PNorm = 51.9411, GNorm = 0.1466, lr_0 = 1.9351e-04
Loss = 3.9422e-05, PNorm = 51.9422, GNorm = 0.1517, lr_0 = 1.9331e-04
Loss = 2.8734e-05, PNorm = 51.9434, GNorm = 0.0852, lr_0 = 1.9311e-04
Loss = 3.1702e-05, PNorm = 51.9439, GNorm = 0.0973, lr_0 = 1.9291e-04
Loss = 3.7234e-05, PNorm = 51.9445, GNorm = 0.1743, lr_0 = 1.9271e-04
Loss = 3.6778e-05, PNorm = 51.9463, GNorm = 0.1396, lr_0 = 1.9251e-04
Loss = 3.5088e-05, PNorm = 51.9487, GNorm = 0.1730, lr_0 = 1.9231e-04
Loss = 3.3888e-05, PNorm = 51.9504, GNorm = 0.1413, lr_0 = 1.9210e-04
Loss = 3.7537e-05, PNorm = 51.9508, GNorm = 0.1794, lr_0 = 1.9190e-04
Loss = 3.6938e-05, PNorm = 51.9521, GNorm = 0.1284, lr_0 = 1.9170e-04
Validation rmse logD = 0.581848
Validation R2 logD = 0.765525
Validation rmse logP = 0.470726
Validation R2 logP = 0.935690
Epoch 72
Train function
Loss = 4.2778e-05, PNorm = 51.9534, GNorm = 0.1012, lr_0 = 1.9148e-04
Loss = 3.6567e-05, PNorm = 51.9549, GNorm = 0.1052, lr_0 = 1.9128e-04
Loss = 3.0362e-05, PNorm = 51.9553, GNorm = 0.0954, lr_0 = 1.9108e-04
Loss = 3.7419e-05, PNorm = 51.9569, GNorm = 0.1779, lr_0 = 1.9088e-04
Loss = 3.7076e-05, PNorm = 51.9584, GNorm = 0.1707, lr_0 = 1.9069e-04
Loss = 2.6532e-05, PNorm = 51.9591, GNorm = 0.1057, lr_0 = 1.9049e-04
Loss = 2.9838e-05, PNorm = 51.9607, GNorm = 0.1209, lr_0 = 1.9029e-04
Loss = 2.4493e-05, PNorm = 51.9619, GNorm = 0.1163, lr_0 = 1.9009e-04
Loss = 3.0421e-05, PNorm = 51.9628, GNorm = 0.2746, lr_0 = 1.8989e-04
Loss = 4.2241e-05, PNorm = 51.9643, GNorm = 0.1767, lr_0 = 1.8969e-04
Loss = 3.6607e-05, PNorm = 51.9663, GNorm = 0.1745, lr_0 = 1.8949e-04
Loss = 4.1107e-05, PNorm = 51.9677, GNorm = 0.1694, lr_0 = 1.8930e-04
Loss = 3.3668e-05, PNorm = 51.9704, GNorm = 0.1100, lr_0 = 1.8910e-04
Loss = 4.4414e-05, PNorm = 51.9730, GNorm = 0.1427, lr_0 = 1.8890e-04
Loss = 3.8615e-05, PNorm = 51.9732, GNorm = 0.1706, lr_0 = 1.8870e-04
Loss = 5.0265e-05, PNorm = 51.9755, GNorm = 0.1537, lr_0 = 1.8851e-04
Loss = 3.2852e-05, PNorm = 51.9776, GNorm = 0.1395, lr_0 = 1.8831e-04
Loss = 3.5685e-05, PNorm = 51.9792, GNorm = 0.1708, lr_0 = 1.8811e-04
Loss = 4.0691e-05, PNorm = 51.9811, GNorm = 0.1819, lr_0 = 1.8792e-04
Loss = 3.6589e-05, PNorm = 51.9827, GNorm = 0.0975, lr_0 = 1.8772e-04
Loss = 3.3999e-05, PNorm = 51.9851, GNorm = 0.1373, lr_0 = 1.8753e-04
Loss = 3.3859e-05, PNorm = 51.9877, GNorm = 0.1298, lr_0 = 1.8733e-04
Loss = 4.4689e-05, PNorm = 51.9904, GNorm = 0.3734, lr_0 = 1.8713e-04
Validation rmse logD = 0.579514
Validation R2 logD = 0.767402
Validation rmse logP = 0.468546
Validation R2 logP = 0.936284
Epoch 73
Train function
Loss = 3.1495e-05, PNorm = 51.9924, GNorm = 0.1868, lr_0 = 1.8694e-04
Loss = 2.7712e-05, PNorm = 51.9940, GNorm = 0.1940, lr_0 = 1.8674e-04
Loss = 2.5439e-05, PNorm = 51.9947, GNorm = 0.0990, lr_0 = 1.8655e-04
Loss = 2.5875e-05, PNorm = 51.9950, GNorm = 0.0976, lr_0 = 1.8635e-04
Loss = 2.7115e-05, PNorm = 51.9964, GNorm = 0.1242, lr_0 = 1.8616e-04
Loss = 2.4219e-05, PNorm = 51.9970, GNorm = 0.1331, lr_0 = 1.8597e-04
Loss = 2.4153e-05, PNorm = 51.9994, GNorm = 0.0996, lr_0 = 1.8577e-04
Loss = 2.8126e-05, PNorm = 52.0000, GNorm = 0.1180, lr_0 = 1.8558e-04
Loss = 2.6886e-05, PNorm = 52.0014, GNorm = 0.1096, lr_0 = 1.8538e-04
Loss = 3.0035e-05, PNorm = 52.0021, GNorm = 0.1882, lr_0 = 1.8519e-04
Loss = 3.2255e-05, PNorm = 52.0038, GNorm = 0.1185, lr_0 = 1.8500e-04
Loss = 3.2823e-05, PNorm = 52.0059, GNorm = 0.0768, lr_0 = 1.8480e-04
Loss = 3.6144e-05, PNorm = 52.0073, GNorm = 0.1956, lr_0 = 1.8461e-04
Loss = 3.5602e-05, PNorm = 52.0095, GNorm = 0.1677, lr_0 = 1.8442e-04
Loss = 3.8363e-05, PNorm = 52.0104, GNorm = 0.1804, lr_0 = 1.8423e-04
Loss = 3.4370e-05, PNorm = 52.0122, GNorm = 0.1827, lr_0 = 1.8403e-04
Loss = 3.6000e-05, PNorm = 52.0140, GNorm = 0.1153, lr_0 = 1.8384e-04
Loss = 3.3803e-05, PNorm = 52.0160, GNorm = 0.1754, lr_0 = 1.8365e-04
Loss = 3.0967e-05, PNorm = 52.0174, GNorm = 0.1803, lr_0 = 1.8346e-04
Loss = 3.2724e-05, PNorm = 52.0182, GNorm = 0.1836, lr_0 = 1.8327e-04
Loss = 3.4361e-05, PNorm = 52.0194, GNorm = 0.1931, lr_0 = 1.8308e-04
Loss = 4.7383e-05, PNorm = 52.0229, GNorm = 0.2358, lr_0 = 1.8288e-04
Validation rmse logD = 0.582846
Validation R2 logD = 0.764720
Validation rmse logP = 0.469629
Validation R2 logP = 0.935990
Epoch 74
Train function
Loss = 3.4256e-05, PNorm = 52.0235, GNorm = 0.1098, lr_0 = 1.8267e-04
Loss = 3.3768e-05, PNorm = 52.0235, GNorm = 0.1344, lr_0 = 1.8248e-04
Loss = 2.8838e-05, PNorm = 52.0254, GNorm = 0.1068, lr_0 = 1.8229e-04
Loss = 3.2679e-05, PNorm = 52.0270, GNorm = 0.1462, lr_0 = 1.8210e-04
Loss = 4.2374e-05, PNorm = 52.0263, GNorm = 0.3452, lr_0 = 1.8191e-04
Loss = 3.7445e-05, PNorm = 52.0274, GNorm = 0.1623, lr_0 = 1.8172e-04
Loss = 4.0384e-05, PNorm = 52.0293, GNorm = 0.2619, lr_0 = 1.8153e-04
Loss = 4.1992e-05, PNorm = 52.0323, GNorm = 0.2880, lr_0 = 1.8134e-04
Loss = 3.3556e-05, PNorm = 52.0342, GNorm = 0.2438, lr_0 = 1.8115e-04
Loss = 3.2949e-05, PNorm = 52.0351, GNorm = 0.1080, lr_0 = 1.8097e-04
Loss = 2.8466e-05, PNorm = 52.0364, GNorm = 0.0987, lr_0 = 1.8078e-04
Loss = 3.1888e-05, PNorm = 52.0393, GNorm = 0.0910, lr_0 = 1.8059e-04
Loss = 3.2228e-05, PNorm = 52.0400, GNorm = 0.1819, lr_0 = 1.8040e-04
Loss = 3.2350e-05, PNorm = 52.0410, GNorm = 0.1398, lr_0 = 1.8021e-04
Loss = 2.7384e-05, PNorm = 52.0419, GNorm = 0.1560, lr_0 = 1.8002e-04
Loss = 2.8327e-05, PNorm = 52.0437, GNorm = 0.0805, lr_0 = 1.7984e-04
Loss = 3.1045e-05, PNorm = 52.0439, GNorm = 0.0897, lr_0 = 1.7965e-04
Loss = 3.4785e-05, PNorm = 52.0439, GNorm = 0.1267, lr_0 = 1.7946e-04
Loss = 3.4239e-05, PNorm = 52.0452, GNorm = 0.1440, lr_0 = 1.7927e-04
Loss = 2.5131e-05, PNorm = 52.0462, GNorm = 0.0699, lr_0 = 1.7909e-04
Loss = 3.5635e-05, PNorm = 52.0475, GNorm = 0.3127, lr_0 = 1.7890e-04
Loss = 4.0467e-05, PNorm = 52.0502, GNorm = 0.1378, lr_0 = 1.7871e-04
Loss = 4.0422e-05, PNorm = 52.0520, GNorm = 0.1298, lr_0 = 1.7853e-04
Validation rmse logD = 0.587209
Validation R2 logD = 0.761184
Validation rmse logP = 0.469200
Validation R2 logP = 0.936106
Epoch 75
Train function
Loss = 3.7169e-05, PNorm = 52.0555, GNorm = 0.1785, lr_0 = 1.7834e-04
Loss = 3.7135e-05, PNorm = 52.0555, GNorm = 0.1588, lr_0 = 1.7815e-04
Loss = 2.9481e-05, PNorm = 52.0569, GNorm = 0.1299, lr_0 = 1.7797e-04
Loss = 3.0164e-05, PNorm = 52.0583, GNorm = 0.1351, lr_0 = 1.7778e-04
Loss = 3.4840e-05, PNorm = 52.0596, GNorm = 0.1008, lr_0 = 1.7760e-04
Loss = 2.4958e-05, PNorm = 52.0597, GNorm = 0.0771, lr_0 = 1.7741e-04
Loss = 3.4437e-05, PNorm = 52.0601, GNorm = 0.1516, lr_0 = 1.7723e-04
Loss = 3.2865e-05, PNorm = 52.0615, GNorm = 0.1375, lr_0 = 1.7704e-04
Loss = 2.6851e-05, PNorm = 52.0629, GNorm = 0.0785, lr_0 = 1.7686e-04
Loss = 2.0265e-05, PNorm = 52.0646, GNorm = 0.0876, lr_0 = 1.7667e-04
Loss = 2.6451e-05, PNorm = 52.0657, GNorm = 0.1421, lr_0 = 1.7649e-04
Loss = 2.6608e-05, PNorm = 52.0669, GNorm = 0.1676, lr_0 = 1.7630e-04
Loss = 2.5279e-05, PNorm = 52.0678, GNorm = 0.1289, lr_0 = 1.7612e-04
Loss = 2.7498e-05, PNorm = 52.0692, GNorm = 0.0807, lr_0 = 1.7593e-04
Loss = 2.5042e-05, PNorm = 52.0693, GNorm = 0.1068, lr_0 = 1.7575e-04
Loss = 2.3943e-05, PNorm = 52.0710, GNorm = 0.1086, lr_0 = 1.7557e-04
Loss = 2.5534e-05, PNorm = 52.0730, GNorm = 0.1639, lr_0 = 1.7538e-04
Loss = 2.8199e-05, PNorm = 52.0739, GNorm = 0.0839, lr_0 = 1.7520e-04
Loss = 3.1023e-05, PNorm = 52.0749, GNorm = 0.1106, lr_0 = 1.7502e-04
Loss = 3.2040e-05, PNorm = 52.0768, GNorm = 0.1179, lr_0 = 1.7484e-04
Loss = 3.0022e-05, PNorm = 52.0794, GNorm = 0.1398, lr_0 = 1.7465e-04
Loss = 2.6079e-05, PNorm = 52.0816, GNorm = 0.1323, lr_0 = 1.7447e-04
Validation rmse logD = 0.581249
Validation R2 logD = 0.766007
Validation rmse logP = 0.467723
Validation R2 logP = 0.936508
Epoch 76
Train function
Loss = 2.4606e-05, PNorm = 52.0839, GNorm = 0.1305, lr_0 = 1.7427e-04
Loss = 3.0027e-05, PNorm = 52.0849, GNorm = 0.1102, lr_0 = 1.7409e-04
Loss = 3.1776e-05, PNorm = 52.0864, GNorm = 0.1362, lr_0 = 1.7391e-04
Loss = 2.3760e-05, PNorm = 52.0876, GNorm = 0.0995, lr_0 = 1.7373e-04
Loss = 2.3971e-05, PNorm = 52.0877, GNorm = 0.1716, lr_0 = 1.7354e-04
Loss = 2.3083e-05, PNorm = 52.0878, GNorm = 0.0961, lr_0 = 1.7336e-04
Loss = 2.3185e-05, PNorm = 52.0887, GNorm = 0.0840, lr_0 = 1.7318e-04
Loss = 2.5727e-05, PNorm = 52.0899, GNorm = 0.0995, lr_0 = 1.7300e-04
Loss = 2.2566e-05, PNorm = 52.0914, GNorm = 0.0920, lr_0 = 1.7282e-04
Loss = 2.7016e-05, PNorm = 52.0933, GNorm = 0.1827, lr_0 = 1.7264e-04
Loss = 2.6077e-05, PNorm = 52.0953, GNorm = 0.1125, lr_0 = 1.7246e-04
Loss = 2.2402e-05, PNorm = 52.0958, GNorm = 0.0755, lr_0 = 1.7228e-04
Loss = 2.6298e-05, PNorm = 52.0963, GNorm = 0.1949, lr_0 = 1.7210e-04
Loss = 3.0638e-05, PNorm = 52.0972, GNorm = 0.0567, lr_0 = 1.7192e-04
Loss = 3.1097e-05, PNorm = 52.0996, GNorm = 0.1034, lr_0 = 1.7174e-04
Loss = 3.3660e-05, PNorm = 52.1011, GNorm = 0.1430, lr_0 = 1.7156e-04
Loss = 2.6974e-05, PNorm = 52.1016, GNorm = 0.2186, lr_0 = 1.7138e-04
Loss = 2.2169e-05, PNorm = 52.1026, GNorm = 0.1128, lr_0 = 1.7120e-04
Loss = 2.5973e-05, PNorm = 52.1043, GNorm = 0.0690, lr_0 = 1.7103e-04
Loss = 2.6146e-05, PNorm = 52.1050, GNorm = 0.0752, lr_0 = 1.7085e-04
Loss = 2.8371e-05, PNorm = 52.1051, GNorm = 0.1683, lr_0 = 1.7067e-04
Loss = 3.5370e-05, PNorm = 52.1062, GNorm = 0.1472, lr_0 = 1.7049e-04
Loss = 2.8049e-05, PNorm = 52.1080, GNorm = 0.1502, lr_0 = 1.7031e-04
Validation rmse logD = 0.579250
Validation R2 logD = 0.767614
Validation rmse logP = 0.468086
Validation R2 logP = 0.936409
Epoch 77
Train function
Loss = 3.1043e-05, PNorm = 52.1107, GNorm = 0.1381, lr_0 = 1.7012e-04
Loss = 2.7919e-05, PNorm = 52.1117, GNorm = 0.1114, lr_0 = 1.6994e-04
Loss = 2.4146e-05, PNorm = 52.1132, GNorm = 0.0968, lr_0 = 1.6976e-04
Loss = 2.4174e-05, PNorm = 52.1141, GNorm = 0.1303, lr_0 = 1.6959e-04
Loss = 2.0512e-05, PNorm = 52.1168, GNorm = 0.1098, lr_0 = 1.6941e-04
Loss = 2.2439e-05, PNorm = 52.1181, GNorm = 0.0878, lr_0 = 1.6923e-04
Loss = 2.8792e-05, PNorm = 52.1190, GNorm = 0.1202, lr_0 = 1.6905e-04
Loss = 1.7125e-05, PNorm = 52.1201, GNorm = 0.0642, lr_0 = 1.6888e-04
Loss = 2.9548e-05, PNorm = 52.1208, GNorm = 0.2127, lr_0 = 1.6870e-04
Loss = 3.1743e-05, PNorm = 52.1223, GNorm = 0.3135, lr_0 = 1.6853e-04
Loss = 3.7601e-05, PNorm = 52.1228, GNorm = 0.2266, lr_0 = 1.6835e-04
Loss = 4.8806e-05, PNorm = 52.1263, GNorm = 0.1595, lr_0 = 1.6817e-04
Loss = 4.9008e-05, PNorm = 52.1283, GNorm = 0.2920, lr_0 = 1.6800e-04
Loss = 3.2952e-05, PNorm = 52.1301, GNorm = 0.1301, lr_0 = 1.6782e-04
Loss = 2.8590e-05, PNorm = 52.1306, GNorm = 0.0855, lr_0 = 1.6765e-04
Loss = 3.0434e-05, PNorm = 52.1327, GNorm = 0.1535, lr_0 = 1.6747e-04
Loss = 3.1791e-05, PNorm = 52.1361, GNorm = 0.1925, lr_0 = 1.6730e-04
Loss = 3.2971e-05, PNorm = 52.1372, GNorm = 0.1923, lr_0 = 1.6712e-04
Loss = 3.2706e-05, PNorm = 52.1376, GNorm = 0.1836, lr_0 = 1.6695e-04
Loss = 2.9439e-05, PNorm = 52.1403, GNorm = 0.1123, lr_0 = 1.6678e-04
Loss = 2.6230e-05, PNorm = 52.1429, GNorm = 0.1160, lr_0 = 1.6660e-04
Loss = 3.1415e-05, PNorm = 52.1438, GNorm = 0.1405, lr_0 = 1.6643e-04
Validation rmse logD = 0.582563
Validation R2 logD = 0.764948
Validation rmse logP = 0.469991
Validation R2 logP = 0.935891
Epoch 78
Train function
Loss = 3.0242e-05, PNorm = 52.1455, GNorm = 0.1498, lr_0 = 1.6625e-04
Loss = 2.5075e-05, PNorm = 52.1467, GNorm = 0.1189, lr_0 = 1.6608e-04
Loss = 2.3611e-05, PNorm = 52.1461, GNorm = 0.1571, lr_0 = 1.6591e-04
Loss = 2.4867e-05, PNorm = 52.1467, GNorm = 0.0894, lr_0 = 1.6573e-04
Loss = 2.5000e-05, PNorm = 52.1477, GNorm = 0.1148, lr_0 = 1.6556e-04
Loss = 2.0414e-05, PNorm = 52.1485, GNorm = 0.1824, lr_0 = 1.6539e-04
Loss = 2.2642e-05, PNorm = 52.1486, GNorm = 0.0780, lr_0 = 1.6522e-04
Loss = 2.5365e-05, PNorm = 52.1504, GNorm = 0.0906, lr_0 = 1.6504e-04
Loss = 1.9219e-05, PNorm = 52.1521, GNorm = 0.0773, lr_0 = 1.6487e-04
Loss = 2.2941e-05, PNorm = 52.1539, GNorm = 0.1395, lr_0 = 1.6470e-04
Loss = 2.5045e-05, PNorm = 52.1550, GNorm = 0.0830, lr_0 = 1.6453e-04
Loss = 2.3867e-05, PNorm = 52.1559, GNorm = 0.1018, lr_0 = 1.6435e-04
Loss = 3.6496e-05, PNorm = 52.1562, GNorm = 0.2437, lr_0 = 1.6418e-04
Loss = 3.4185e-05, PNorm = 52.1569, GNorm = 0.1734, lr_0 = 1.6401e-04
Loss = 3.1237e-05, PNorm = 52.1601, GNorm = 0.1594, lr_0 = 1.6384e-04
Loss = 2.6812e-05, PNorm = 52.1617, GNorm = 0.1657, lr_0 = 1.6367e-04
Loss = 2.7342e-05, PNorm = 52.1628, GNorm = 0.1371, lr_0 = 1.6350e-04
Loss = 2.5916e-05, PNorm = 52.1638, GNorm = 0.0911, lr_0 = 1.6333e-04
Loss = 3.1995e-05, PNorm = 52.1650, GNorm = 0.1195, lr_0 = 1.6316e-04
Loss = 3.1783e-05, PNorm = 52.1652, GNorm = 0.2679, lr_0 = 1.6299e-04
Loss = 3.3582e-05, PNorm = 52.1669, GNorm = 0.0967, lr_0 = 1.6282e-04
Loss = 3.8139e-05, PNorm = 52.1700, GNorm = 0.0995, lr_0 = 1.6265e-04
Loss = 3.5305e-05, PNorm = 52.1713, GNorm = 0.1335, lr_0 = 1.6248e-04
Validation rmse logD = 0.584389
Validation R2 logD = 0.763472
Validation rmse logP = 0.471971
Validation R2 logP = 0.935350
Epoch 79
Train function
Loss = 3.7324e-05, PNorm = 52.1725, GNorm = 0.1498, lr_0 = 1.6229e-04
Loss = 3.6605e-05, PNorm = 52.1730, GNorm = 0.2517, lr_0 = 1.6212e-04
Loss = 3.2516e-05, PNorm = 52.1748, GNorm = 0.1023, lr_0 = 1.6195e-04
Loss = 3.2776e-05, PNorm = 52.1751, GNorm = 0.1439, lr_0 = 1.6178e-04
Loss = 2.6140e-05, PNorm = 52.1761, GNorm = 0.0760, lr_0 = 1.6161e-04
Loss = 2.5603e-05, PNorm = 52.1788, GNorm = 0.1414, lr_0 = 1.6145e-04
Loss = 2.5763e-05, PNorm = 52.1791, GNorm = 0.1063, lr_0 = 1.6128e-04
Loss = 2.8087e-05, PNorm = 52.1801, GNorm = 0.1062, lr_0 = 1.6111e-04
Loss = 2.3211e-05, PNorm = 52.1796, GNorm = 0.1013, lr_0 = 1.6094e-04
Loss = 2.6425e-05, PNorm = 52.1803, GNorm = 0.0763, lr_0 = 1.6077e-04
Loss = 2.5834e-05, PNorm = 52.1814, GNorm = 0.1028, lr_0 = 1.6061e-04
Loss = 2.8001e-05, PNorm = 52.1831, GNorm = 0.0961, lr_0 = 1.6044e-04
Loss = 3.0573e-05, PNorm = 52.1845, GNorm = 0.1501, lr_0 = 1.6027e-04
Loss = 2.6346e-05, PNorm = 52.1861, GNorm = 0.1048, lr_0 = 1.6010e-04
Loss = 3.2115e-05, PNorm = 52.1872, GNorm = 0.1457, lr_0 = 1.5994e-04
Loss = 2.9464e-05, PNorm = 52.1877, GNorm = 0.1582, lr_0 = 1.5977e-04
Loss = 2.8471e-05, PNorm = 52.1889, GNorm = 0.1112, lr_0 = 1.5960e-04
Loss = 2.2410e-05, PNorm = 52.1907, GNorm = 0.0758, lr_0 = 1.5944e-04
Loss = 2.0772e-05, PNorm = 52.1921, GNorm = 0.0942, lr_0 = 1.5927e-04
Loss = 2.2379e-05, PNorm = 52.1936, GNorm = 0.1556, lr_0 = 1.5910e-04
Loss = 2.4986e-05, PNorm = 52.1939, GNorm = 0.1031, lr_0 = 1.5894e-04
Loss = 3.0817e-05, PNorm = 52.1949, GNorm = 0.0800, lr_0 = 1.5877e-04
Validation rmse logD = 0.581603
Validation R2 logD = 0.765722
Validation rmse logP = 0.466181
Validation R2 logP = 0.936926
Epoch 80
Train function
Loss = 3.0290e-05, PNorm = 52.1958, GNorm = 0.0660, lr_0 = 1.5861e-04
Loss = 2.2273e-05, PNorm = 52.1969, GNorm = 0.0982, lr_0 = 1.5844e-04
Loss = 2.1907e-05, PNorm = 52.1978, GNorm = 0.1081, lr_0 = 1.5827e-04
Loss = 1.6910e-05, PNorm = 52.1992, GNorm = 0.0929, lr_0 = 1.5811e-04
Loss = 1.7615e-05, PNorm = 52.2003, GNorm = 0.1016, lr_0 = 1.5794e-04
Loss = 1.8093e-05, PNorm = 52.2008, GNorm = 0.0646, lr_0 = 1.5778e-04
Loss = 1.8678e-05, PNorm = 52.2013, GNorm = 0.0899, lr_0 = 1.5761e-04
Loss = 2.1157e-05, PNorm = 52.2029, GNorm = 0.0878, lr_0 = 1.5745e-04
Loss = 2.4551e-05, PNorm = 52.2035, GNorm = 0.1857, lr_0 = 1.5729e-04
Loss = 2.6210e-05, PNorm = 52.2055, GNorm = 0.1557, lr_0 = 1.5712e-04
Loss = 2.7061e-05, PNorm = 52.2082, GNorm = 0.0953, lr_0 = 1.5696e-04
Loss = 1.9924e-05, PNorm = 52.2099, GNorm = 0.1159, lr_0 = 1.5679e-04
Loss = 2.4786e-05, PNorm = 52.2100, GNorm = 0.2012, lr_0 = 1.5663e-04
Loss = 2.5786e-05, PNorm = 52.2116, GNorm = 0.1629, lr_0 = 1.5647e-04
Loss = 2.4228e-05, PNorm = 52.2137, GNorm = 0.0867, lr_0 = 1.5630e-04
Loss = 2.1727e-05, PNorm = 52.2147, GNorm = 0.0556, lr_0 = 1.5614e-04
Loss = 2.4387e-05, PNorm = 52.2156, GNorm = 0.0885, lr_0 = 1.5598e-04
Loss = 2.2522e-05, PNorm = 52.2169, GNorm = 0.0710, lr_0 = 1.5581e-04
Loss = 2.3318e-05, PNorm = 52.2176, GNorm = 0.1081, lr_0 = 1.5565e-04
Loss = 2.3507e-05, PNorm = 52.2181, GNorm = 0.0643, lr_0 = 1.5549e-04
Loss = 2.1300e-05, PNorm = 52.2186, GNorm = 0.1065, lr_0 = 1.5533e-04
Loss = 1.9465e-05, PNorm = 52.2194, GNorm = 0.1838, lr_0 = 1.5516e-04
Loss = 2.5238e-05, PNorm = 52.2204, GNorm = 0.1229, lr_0 = 1.5500e-04
Validation rmse logD = 0.584151
Validation R2 logD = 0.763665
Validation rmse logP = 0.469712
Validation R2 logP = 0.935967
Epoch 81
Train function
Loss = 1.6364e-05, PNorm = 52.2215, GNorm = 0.0825, lr_0 = 1.5483e-04
Loss = 2.4970e-05, PNorm = 52.2221, GNorm = 0.1082, lr_0 = 1.5466e-04
Loss = 1.9990e-05, PNorm = 52.2229, GNorm = 0.1525, lr_0 = 1.5450e-04
Loss = 2.0986e-05, PNorm = 52.2231, GNorm = 0.1288, lr_0 = 1.5434e-04
Loss = 2.4987e-05, PNorm = 52.2246, GNorm = 0.1306, lr_0 = 1.5418e-04
Loss = 2.6104e-05, PNorm = 52.2262, GNorm = 0.1014, lr_0 = 1.5402e-04
Loss = 2.3285e-05, PNorm = 52.2285, GNorm = 0.1966, lr_0 = 1.5386e-04
Loss = 2.4302e-05, PNorm = 52.2286, GNorm = 0.2000, lr_0 = 1.5370e-04
Loss = 2.6509e-05, PNorm = 52.2306, GNorm = 0.1362, lr_0 = 1.5354e-04
Loss = 2.5318e-05, PNorm = 52.2308, GNorm = 0.0944, lr_0 = 1.5338e-04
Loss = 2.4708e-05, PNorm = 52.2312, GNorm = 0.1056, lr_0 = 1.5322e-04
Loss = 2.7314e-05, PNorm = 52.2323, GNorm = 0.1831, lr_0 = 1.5306e-04
Loss = 2.5447e-05, PNorm = 52.2336, GNorm = 0.1857, lr_0 = 1.5290e-04
Loss = 2.8188e-05, PNorm = 52.2328, GNorm = 0.1474, lr_0 = 1.5274e-04
Loss = 2.7918e-05, PNorm = 52.2329, GNorm = 0.1063, lr_0 = 1.5258e-04
Loss = 3.1310e-05, PNorm = 52.2337, GNorm = 0.1349, lr_0 = 1.5242e-04
Loss = 3.3079e-05, PNorm = 52.2358, GNorm = 0.1851, lr_0 = 1.5226e-04
Loss = 2.3197e-05, PNorm = 52.2366, GNorm = 0.1003, lr_0 = 1.5210e-04
Loss = 2.9573e-05, PNorm = 52.2382, GNorm = 0.1199, lr_0 = 1.5194e-04
Loss = 3.4996e-05, PNorm = 52.2393, GNorm = 0.3184, lr_0 = 1.5178e-04
Loss = 2.6664e-05, PNorm = 52.2391, GNorm = 0.1013, lr_0 = 1.5163e-04
Loss = 2.6175e-05, PNorm = 52.2403, GNorm = 0.1113, lr_0 = 1.5147e-04
Validation rmse logD = 0.582422
Validation R2 logD = 0.765062
Validation rmse logP = 0.468514
Validation R2 logP = 0.936293
Epoch 82
Train function
Loss = 2.7856e-05, PNorm = 52.2410, GNorm = 0.1332, lr_0 = 1.5131e-04
Loss = 2.1177e-05, PNorm = 52.2413, GNorm = 0.1280, lr_0 = 1.5115e-04
Loss = 2.1088e-05, PNorm = 52.2414, GNorm = 0.0760, lr_0 = 1.5099e-04
Loss = 2.5122e-05, PNorm = 52.2427, GNorm = 0.0940, lr_0 = 1.5084e-04
Loss = 2.0206e-05, PNorm = 52.2455, GNorm = 0.1074, lr_0 = 1.5068e-04
Loss = 1.6510e-05, PNorm = 52.2478, GNorm = 0.0847, lr_0 = 1.5052e-04
Loss = 2.2065e-05, PNorm = 52.2489, GNorm = 0.0780, lr_0 = 1.5036e-04
Loss = 1.8518e-05, PNorm = 52.2502, GNorm = 0.0654, lr_0 = 1.5021e-04
Loss = 2.2522e-05, PNorm = 52.2516, GNorm = 0.1459, lr_0 = 1.5005e-04
Loss = 1.8474e-05, PNorm = 52.2527, GNorm = 0.1368, lr_0 = 1.4989e-04
Loss = 2.3511e-05, PNorm = 52.2542, GNorm = 0.1293, lr_0 = 1.4974e-04
Loss = 2.3362e-05, PNorm = 52.2551, GNorm = 0.1351, lr_0 = 1.4958e-04
Loss = 2.1219e-05, PNorm = 52.2574, GNorm = 0.1229, lr_0 = 1.4942e-04
Loss = 2.4948e-05, PNorm = 52.2584, GNorm = 0.0802, lr_0 = 1.4927e-04
Loss = 1.8685e-05, PNorm = 52.2601, GNorm = 0.0798, lr_0 = 1.4911e-04
Loss = 2.0562e-05, PNorm = 52.2612, GNorm = 0.1015, lr_0 = 1.4896e-04
Loss = 1.9023e-05, PNorm = 52.2630, GNorm = 0.0799, lr_0 = 1.4880e-04
Loss = 2.2503e-05, PNorm = 52.2642, GNorm = 0.0920, lr_0 = 1.4865e-04
Loss = 2.1635e-05, PNorm = 52.2651, GNorm = 0.0790, lr_0 = 1.4849e-04
Loss = 2.0906e-05, PNorm = 52.2673, GNorm = 0.1721, lr_0 = 1.4834e-04
Loss = 2.1674e-05, PNorm = 52.2678, GNorm = 0.1587, lr_0 = 1.4818e-04
Loss = 2.0991e-05, PNorm = 52.2692, GNorm = 0.1474, lr_0 = 1.4803e-04
Loss = 2.3730e-05, PNorm = 52.2697, GNorm = 0.1009, lr_0 = 1.4787e-04
Validation rmse logD = 0.582491
Validation R2 logD = 0.765006
Validation rmse logP = 0.469085
Validation R2 logP = 0.936138
Epoch 83
Train function
Loss = 2.6887e-05, PNorm = 52.2713, GNorm = 0.1904, lr_0 = 1.4770e-04
Loss = 2.4222e-05, PNorm = 52.2727, GNorm = 0.1366, lr_0 = 1.4755e-04
Loss = 2.2026e-05, PNorm = 52.2731, GNorm = 0.0812, lr_0 = 1.4739e-04
Loss = 1.7699e-05, PNorm = 52.2742, GNorm = 0.1097, lr_0 = 1.4724e-04
Loss = 1.8653e-05, PNorm = 52.2754, GNorm = 0.0864, lr_0 = 1.4709e-04
Loss = 1.7377e-05, PNorm = 52.2761, GNorm = 0.0730, lr_0 = 1.4693e-04
Loss = 1.6901e-05, PNorm = 52.2773, GNorm = 0.0532, lr_0 = 1.4678e-04
Loss = 1.9312e-05, PNorm = 52.2783, GNorm = 0.0565, lr_0 = 1.4663e-04
Loss = 1.9450e-05, PNorm = 52.2782, GNorm = 0.1842, lr_0 = 1.4647e-04
Loss = 2.0072e-05, PNorm = 52.2795, GNorm = 0.1220, lr_0 = 1.4632e-04
Loss = 1.7838e-05, PNorm = 52.2813, GNorm = 0.0882, lr_0 = 1.4617e-04
Loss = 2.9065e-05, PNorm = 52.2821, GNorm = 0.1341, lr_0 = 1.4602e-04
Loss = 1.9707e-05, PNorm = 52.2829, GNorm = 0.0670, lr_0 = 1.4586e-04
Loss = 2.1152e-05, PNorm = 52.2828, GNorm = 0.1063, lr_0 = 1.4571e-04
Loss = 1.6455e-05, PNorm = 52.2830, GNorm = 0.0888, lr_0 = 1.4556e-04
Loss = 1.5625e-05, PNorm = 52.2829, GNorm = 0.1246, lr_0 = 1.4541e-04
Loss = 1.4714e-05, PNorm = 52.2830, GNorm = 0.0749, lr_0 = 1.4526e-04
Loss = 1.7267e-05, PNorm = 52.2845, GNorm = 0.0720, lr_0 = 1.4510e-04
Loss = 2.6058e-05, PNorm = 52.2848, GNorm = 0.1086, lr_0 = 1.4495e-04
Loss = 1.8245e-05, PNorm = 52.2861, GNorm = 0.0612, lr_0 = 1.4480e-04
Loss = 1.8487e-05, PNorm = 52.2876, GNorm = 0.1007, lr_0 = 1.4465e-04
Loss = 1.8121e-05, PNorm = 52.2885, GNorm = 0.1746, lr_0 = 1.4450e-04
Loss = 2.1690e-05, PNorm = 52.2890, GNorm = 0.1899, lr_0 = 1.4435e-04
Validation rmse logD = 0.581731
Validation R2 logD = 0.765619
Validation rmse logP = 0.470124
Validation R2 logP = 0.935854
Epoch 84
Train function
Loss = 1.8105e-05, PNorm = 52.2886, GNorm = 0.1014, lr_0 = 1.4420e-04
Loss = 2.2620e-05, PNorm = 52.2896, GNorm = 0.0835, lr_0 = 1.4405e-04
Loss = 1.4216e-05, PNorm = 52.2906, GNorm = 0.0558, lr_0 = 1.4390e-04
Loss = 1.7207e-05, PNorm = 52.2920, GNorm = 0.0611, lr_0 = 1.4375e-04
Loss = 2.0218e-05, PNorm = 52.2931, GNorm = 0.0583, lr_0 = 1.4360e-04
Loss = 2.1464e-05, PNorm = 52.2942, GNorm = 0.0550, lr_0 = 1.4345e-04
Loss = 1.5592e-05, PNorm = 52.2945, GNorm = 0.1462, lr_0 = 1.4330e-04
Loss = 1.7953e-05, PNorm = 52.2953, GNorm = 0.1499, lr_0 = 1.4315e-04
Loss = 1.9677e-05, PNorm = 52.2967, GNorm = 0.0858, lr_0 = 1.4300e-04
Loss = 2.0771e-05, PNorm = 52.2984, GNorm = 0.1171, lr_0 = 1.4285e-04
Loss = 1.7637e-05, PNorm = 52.3005, GNorm = 0.0942, lr_0 = 1.4270e-04
Loss = 1.2147e-05, PNorm = 52.3020, GNorm = 0.0734, lr_0 = 1.4255e-04
Loss = 1.7104e-05, PNorm = 52.3040, GNorm = 0.0777, lr_0 = 1.4240e-04
Loss = 1.6103e-05, PNorm = 52.3049, GNorm = 0.1026, lr_0 = 1.4225e-04
Loss = 1.6970e-05, PNorm = 52.3065, GNorm = 0.0646, lr_0 = 1.4210e-04
Loss = 1.7039e-05, PNorm = 52.3075, GNorm = 0.0551, lr_0 = 1.4196e-04
Loss = 2.0970e-05, PNorm = 52.3086, GNorm = 0.1140, lr_0 = 1.4181e-04
Loss = 1.7055e-05, PNorm = 52.3092, GNorm = 0.0935, lr_0 = 1.4166e-04
Loss = 1.6745e-05, PNorm = 52.3094, GNorm = 0.0619, lr_0 = 1.4151e-04
Loss = 2.4006e-05, PNorm = 52.3105, GNorm = 0.1325, lr_0 = 1.4136e-04
Loss = 2.2723e-05, PNorm = 52.3118, GNorm = 0.1001, lr_0 = 1.4122e-04
Loss = 2.1310e-05, PNorm = 52.3136, GNorm = 0.0584, lr_0 = 1.4107e-04
Validation rmse logD = 0.581860
Validation R2 logD = 0.765515
Validation rmse logP = 0.467539
Validation R2 logP = 0.936558
Epoch 85
Train function
Loss = 1.5908e-05, PNorm = 52.3148, GNorm = 0.1057, lr_0 = 1.4091e-04
Loss = 2.2210e-05, PNorm = 52.3157, GNorm = 0.0924, lr_0 = 1.4076e-04
Loss = 2.1300e-05, PNorm = 52.3169, GNorm = 0.0830, lr_0 = 1.4061e-04
Loss = 2.1016e-05, PNorm = 52.3186, GNorm = 0.1213, lr_0 = 1.4047e-04
Loss = 1.5629e-05, PNorm = 52.3200, GNorm = 0.0839, lr_0 = 1.4032e-04
Loss = 1.6780e-05, PNorm = 52.3204, GNorm = 0.0774, lr_0 = 1.4017e-04
Loss = 1.9789e-05, PNorm = 52.3209, GNorm = 0.0781, lr_0 = 1.4003e-04
Loss = 1.8780e-05, PNorm = 52.3215, GNorm = 0.0764, lr_0 = 1.3988e-04
Loss = 1.5752e-05, PNorm = 52.3234, GNorm = 0.2019, lr_0 = 1.3974e-04
Loss = 1.7968e-05, PNorm = 52.3238, GNorm = 0.0940, lr_0 = 1.3959e-04
Loss = 1.5597e-05, PNorm = 52.3253, GNorm = 0.0916, lr_0 = 1.3944e-04
Loss = 1.5811e-05, PNorm = 52.3257, GNorm = 0.1385, lr_0 = 1.3930e-04
Loss = 1.4359e-05, PNorm = 52.3264, GNorm = 0.1163, lr_0 = 1.3915e-04
Loss = 1.3777e-05, PNorm = 52.3273, GNorm = 0.0869, lr_0 = 1.3901e-04
Loss = 1.8157e-05, PNorm = 52.3284, GNorm = 0.0623, lr_0 = 1.3886e-04
Loss = 2.0258e-05, PNorm = 52.3286, GNorm = 0.0623, lr_0 = 1.3872e-04
Loss = 2.1728e-05, PNorm = 52.3299, GNorm = 0.0651, lr_0 = 1.3857e-04
Loss = 1.9197e-05, PNorm = 52.3310, GNorm = 0.1498, lr_0 = 1.3843e-04
Loss = 1.5838e-05, PNorm = 52.3315, GNorm = 0.1450, lr_0 = 1.3828e-04
Loss = 1.8864e-05, PNorm = 52.3313, GNorm = 0.1091, lr_0 = 1.3814e-04
Loss = 1.6892e-05, PNorm = 52.3318, GNorm = 0.1603, lr_0 = 1.3800e-04
Loss = 1.7843e-05, PNorm = 52.3331, GNorm = 0.1018, lr_0 = 1.3785e-04
Loss = 1.7980e-05, PNorm = 52.3340, GNorm = 0.0940, lr_0 = 1.3771e-04
Validation rmse logD = 0.581879
Validation R2 logD = 0.765500
Validation rmse logP = 0.472109
Validation R2 logP = 0.935312
Epoch 86
Train function
Loss = 2.1285e-05, PNorm = 52.3357, GNorm = 0.0963, lr_0 = 1.3756e-04
Loss = 2.1676e-05, PNorm = 52.3367, GNorm = 0.0775, lr_0 = 1.3742e-04
Loss = 1.5956e-05, PNorm = 52.3369, GNorm = 0.0747, lr_0 = 1.3728e-04
Loss = 2.3972e-05, PNorm = 52.3378, GNorm = 0.1674, lr_0 = 1.3713e-04
Loss = 1.6013e-05, PNorm = 52.3380, GNorm = 0.1253, lr_0 = 1.3699e-04
Loss = 1.8056e-05, PNorm = 52.3394, GNorm = 0.0936, lr_0 = 1.3685e-04
Loss = 1.7910e-05, PNorm = 52.3401, GNorm = 0.0875, lr_0 = 1.3670e-04
Loss = 2.6034e-05, PNorm = 52.3417, GNorm = 0.0792, lr_0 = 1.3656e-04
Loss = 1.4291e-05, PNorm = 52.3423, GNorm = 0.1037, lr_0 = 1.3642e-04
Loss = 1.8605e-05, PNorm = 52.3435, GNorm = 0.0819, lr_0 = 1.3628e-04
Loss = 1.4821e-05, PNorm = 52.3443, GNorm = 0.0703, lr_0 = 1.3613e-04
Loss = 1.8077e-05, PNorm = 52.3444, GNorm = 0.1185, lr_0 = 1.3599e-04
Loss = 1.8054e-05, PNorm = 52.3452, GNorm = 0.1259, lr_0 = 1.3585e-04
Loss = 1.6593e-05, PNorm = 52.3469, GNorm = 0.1277, lr_0 = 1.3571e-04
Loss = 1.4923e-05, PNorm = 52.3475, GNorm = 0.0943, lr_0 = 1.3557e-04
Loss = 1.4707e-05, PNorm = 52.3484, GNorm = 0.0771, lr_0 = 1.3543e-04
Loss = 1.8115e-05, PNorm = 52.3492, GNorm = 0.0885, lr_0 = 1.3528e-04
Loss = 1.6069e-05, PNorm = 52.3503, GNorm = 0.1412, lr_0 = 1.3514e-04
Loss = 1.6836e-05, PNorm = 52.3506, GNorm = 0.0564, lr_0 = 1.3500e-04
Loss = 1.3012e-05, PNorm = 52.3512, GNorm = 0.1101, lr_0 = 1.3486e-04
Loss = 1.7894e-05, PNorm = 52.3521, GNorm = 0.1191, lr_0 = 1.3472e-04
Loss = 1.5629e-05, PNorm = 52.3531, GNorm = 0.0703, lr_0 = 1.3458e-04
Validation rmse logD = 0.581624
Validation R2 logD = 0.765705
Validation rmse logP = 0.468845
Validation R2 logP = 0.936203
Epoch 87
Train function
Loss = 1.2389e-05, PNorm = 52.3545, GNorm = 0.0694, lr_0 = 1.3443e-04
Loss = 1.4795e-05, PNorm = 52.3553, GNorm = 0.0701, lr_0 = 1.3428e-04
Loss = 1.3582e-05, PNorm = 52.3559, GNorm = 0.0769, lr_0 = 1.3414e-04
Loss = 1.8826e-05, PNorm = 52.3564, GNorm = 0.0932, lr_0 = 1.3400e-04
Loss = 1.5478e-05, PNorm = 52.3571, GNorm = 0.1950, lr_0 = 1.3386e-04
Loss = 1.7346e-05, PNorm = 52.3578, GNorm = 0.1103, lr_0 = 1.3373e-04
Loss = 1.6748e-05, PNorm = 52.3581, GNorm = 0.0947, lr_0 = 1.3359e-04
Loss = 1.8448e-05, PNorm = 52.3589, GNorm = 0.0751, lr_0 = 1.3345e-04
Loss = 1.5601e-05, PNorm = 52.3601, GNorm = 0.1244, lr_0 = 1.3331e-04
Loss = 1.8597e-05, PNorm = 52.3606, GNorm = 0.1154, lr_0 = 1.3317e-04
Loss = 1.9702e-05, PNorm = 52.3604, GNorm = 0.0963, lr_0 = 1.3303e-04
Loss = 1.6580e-05, PNorm = 52.3607, GNorm = 0.0995, lr_0 = 1.3289e-04
Loss = 1.9725e-05, PNorm = 52.3622, GNorm = 0.0844, lr_0 = 1.3275e-04
Loss = 2.1827e-05, PNorm = 52.3624, GNorm = 0.1064, lr_0 = 1.3261e-04
Loss = 1.6623e-05, PNorm = 52.3644, GNorm = 0.1300, lr_0 = 1.3247e-04
Loss = 1.5215e-05, PNorm = 52.3660, GNorm = 0.1005, lr_0 = 1.3234e-04
Loss = 1.7835e-05, PNorm = 52.3672, GNorm = 0.1423, lr_0 = 1.3220e-04
Loss = 2.0664e-05, PNorm = 52.3670, GNorm = 0.0677, lr_0 = 1.3206e-04
Loss = 1.5201e-05, PNorm = 52.3677, GNorm = 0.0552, lr_0 = 1.3192e-04
Loss = 1.5214e-05, PNorm = 52.3688, GNorm = 0.1037, lr_0 = 1.3178e-04
Loss = 1.5561e-05, PNorm = 52.3702, GNorm = 0.0558, lr_0 = 1.3165e-04
Loss = 1.3575e-05, PNorm = 52.3708, GNorm = 0.0719, lr_0 = 1.3151e-04
Loss = 1.8583e-05, PNorm = 52.3714, GNorm = 0.1045, lr_0 = 1.3137e-04
Validation rmse logD = 0.581574
Validation R2 logD = 0.765746
Validation rmse logP = 0.469270
Validation R2 logP = 0.936087
Epoch 88
Train function
Loss = 1.3256e-05, PNorm = 52.3726, GNorm = 0.0834, lr_0 = 1.3124e-04
Loss = 1.2867e-05, PNorm = 52.3727, GNorm = 0.0738, lr_0 = 1.3110e-04
Loss = 1.5831e-05, PNorm = 52.3736, GNorm = 0.0856, lr_0 = 1.3096e-04
Loss = 1.9929e-05, PNorm = 52.3744, GNorm = 0.1749, lr_0 = 1.3082e-04
Loss = 1.4918e-05, PNorm = 52.3756, GNorm = 0.1170, lr_0 = 1.3069e-04
Loss = 2.0418e-05, PNorm = 52.3774, GNorm = 0.1555, lr_0 = 1.3055e-04
Loss = 1.5615e-05, PNorm = 52.3793, GNorm = 0.1595, lr_0 = 1.3042e-04
Loss = 1.6005e-05, PNorm = 52.3804, GNorm = 0.1160, lr_0 = 1.3028e-04
Loss = 1.9973e-05, PNorm = 52.3806, GNorm = 0.0998, lr_0 = 1.3014e-04
Loss = 2.2228e-05, PNorm = 52.3824, GNorm = 0.1558, lr_0 = 1.3001e-04
Loss = 1.7617e-05, PNorm = 52.3832, GNorm = 0.0993, lr_0 = 1.2987e-04
Loss = 1.5065e-05, PNorm = 52.3841, GNorm = 0.1117, lr_0 = 1.2974e-04
Loss = 1.8819e-05, PNorm = 52.3857, GNorm = 0.0784, lr_0 = 1.2960e-04
Loss = 1.7406e-05, PNorm = 52.3877, GNorm = 0.1170, lr_0 = 1.2947e-04
Loss = 1.4623e-05, PNorm = 52.3889, GNorm = 0.0616, lr_0 = 1.2933e-04
Loss = 1.4712e-05, PNorm = 52.3901, GNorm = 0.1000, lr_0 = 1.2920e-04
Loss = 2.1336e-05, PNorm = 52.3906, GNorm = 0.0596, lr_0 = 1.2906e-04
Loss = 1.9071e-05, PNorm = 52.3913, GNorm = 0.0788, lr_0 = 1.2893e-04
Loss = 1.6318e-05, PNorm = 52.3924, GNorm = 0.1136, lr_0 = 1.2879e-04
Loss = 1.4905e-05, PNorm = 52.3929, GNorm = 0.1024, lr_0 = 1.2866e-04
Loss = 1.7618e-05, PNorm = 52.3939, GNorm = 0.1584, lr_0 = 1.2852e-04
Loss = 2.1780e-05, PNorm = 52.3949, GNorm = 0.1390, lr_0 = 1.2839e-04
Validation rmse logD = 0.582698
Validation R2 logD = 0.764839
Validation rmse logP = 0.469963
Validation R2 logP = 0.935898
Epoch 89
Train function
Loss = 1.3854e-05, PNorm = 52.3969, GNorm = 0.0748, lr_0 = 1.2824e-04
Loss = 1.6171e-05, PNorm = 52.3974, GNorm = 0.1028, lr_0 = 1.2811e-04
Loss = 1.4700e-05, PNorm = 52.3979, GNorm = 0.1275, lr_0 = 1.2797e-04
Loss = 1.5284e-05, PNorm = 52.3985, GNorm = 0.0843, lr_0 = 1.2784e-04
Loss = 1.7037e-05, PNorm = 52.3988, GNorm = 0.0485, lr_0 = 1.2771e-04
Loss = 1.3734e-05, PNorm = 52.4000, GNorm = 0.1088, lr_0 = 1.2757e-04
Loss = 1.7126e-05, PNorm = 52.4010, GNorm = 0.0562, lr_0 = 1.2744e-04
Loss = 1.4477e-05, PNorm = 52.4022, GNorm = 0.0975, lr_0 = 1.2731e-04
Loss = 1.7467e-05, PNorm = 52.4031, GNorm = 0.1197, lr_0 = 1.2717e-04
Loss = 1.4764e-05, PNorm = 52.4032, GNorm = 0.0739, lr_0 = 1.2704e-04
Loss = 1.6020e-05, PNorm = 52.4031, GNorm = 0.0744, lr_0 = 1.2691e-04
Loss = 1.7889e-05, PNorm = 52.4037, GNorm = 0.1149, lr_0 = 1.2678e-04
Loss = 1.8402e-05, PNorm = 52.4038, GNorm = 0.0807, lr_0 = 1.2664e-04
Loss = 1.7531e-05, PNorm = 52.4045, GNorm = 0.1365, lr_0 = 1.2651e-04
Loss = 1.8511e-05, PNorm = 52.4059, GNorm = 0.2075, lr_0 = 1.2638e-04
Loss = 1.4793e-05, PNorm = 52.4068, GNorm = 0.1186, lr_0 = 1.2625e-04
Loss = 1.6602e-05, PNorm = 52.4076, GNorm = 0.0929, lr_0 = 1.2612e-04
Loss = 1.5225e-05, PNorm = 52.4085, GNorm = 0.0693, lr_0 = 1.2598e-04
Loss = 1.4248e-05, PNorm = 52.4090, GNorm = 0.0603, lr_0 = 1.2585e-04
Loss = 1.4214e-05, PNorm = 52.4090, GNorm = 0.1293, lr_0 = 1.2572e-04
Loss = 1.4201e-05, PNorm = 52.4109, GNorm = 0.0728, lr_0 = 1.2559e-04
Loss = 1.5813e-05, PNorm = 52.4113, GNorm = 0.1621, lr_0 = 1.2546e-04
Loss = 1.4774e-05, PNorm = 52.4123, GNorm = 0.0712, lr_0 = 1.2533e-04
Validation rmse logD = 0.580824
Validation R2 logD = 0.766349
Validation rmse logP = 0.469557
Validation R2 logP = 0.936009
Epoch 90
Train function
Loss = 1.3483e-05, PNorm = 52.4129, GNorm = 0.0841, lr_0 = 1.2520e-04
Loss = 1.2101e-05, PNorm = 52.4131, GNorm = 0.0868, lr_0 = 1.2507e-04
Loss = 1.5917e-05, PNorm = 52.4136, GNorm = 0.0752, lr_0 = 1.2494e-04
Loss = 1.0765e-05, PNorm = 52.4136, GNorm = 0.0716, lr_0 = 1.2481e-04
Loss = 1.6465e-05, PNorm = 52.4149, GNorm = 0.1106, lr_0 = 1.2468e-04
Loss = 1.4102e-05, PNorm = 52.4161, GNorm = 0.1167, lr_0 = 1.2455e-04
Loss = 1.2404e-05, PNorm = 52.4173, GNorm = 0.0653, lr_0 = 1.2442e-04
Loss = 1.3554e-05, PNorm = 52.4176, GNorm = 0.0608, lr_0 = 1.2429e-04
Loss = 1.0925e-05, PNorm = 52.4184, GNorm = 0.0582, lr_0 = 1.2416e-04
Loss = 1.4049e-05, PNorm = 52.4197, GNorm = 0.0839, lr_0 = 1.2403e-04
Loss = 1.4665e-05, PNorm = 52.4212, GNorm = 0.0687, lr_0 = 1.2390e-04
Loss = 1.2164e-05, PNorm = 52.4221, GNorm = 0.0779, lr_0 = 1.2377e-04
Loss = 1.5787e-05, PNorm = 52.4229, GNorm = 0.0673, lr_0 = 1.2364e-04
Loss = 1.2030e-05, PNorm = 52.4233, GNorm = 0.0652, lr_0 = 1.2351e-04
Loss = 1.1227e-05, PNorm = 52.4235, GNorm = 0.1111, lr_0 = 1.2338e-04
Loss = 1.4562e-05, PNorm = 52.4250, GNorm = 0.0910, lr_0 = 1.2325e-04
Loss = 1.6691e-05, PNorm = 52.4263, GNorm = 0.1053, lr_0 = 1.2312e-04
Loss = 2.1966e-05, PNorm = 52.4273, GNorm = 0.1875, lr_0 = 1.2299e-04
Loss = 1.5813e-05, PNorm = 52.4287, GNorm = 0.0762, lr_0 = 1.2287e-04
Loss = 2.0605e-05, PNorm = 52.4312, GNorm = 0.1333, lr_0 = 1.2274e-04
Loss = 1.6693e-05, PNorm = 52.4321, GNorm = 0.0973, lr_0 = 1.2261e-04
Loss = 1.3974e-05, PNorm = 52.4330, GNorm = 0.0980, lr_0 = 1.2248e-04
Validation rmse logD = 0.580262
Validation R2 logD = 0.766801
Validation rmse logP = 0.469033
Validation R2 logP = 0.936152
Epoch 91
Train function
Loss = 9.6110e-06, PNorm = 52.4336, GNorm = 0.0680, lr_0 = 1.2234e-04
Loss = 1.4828e-05, PNorm = 52.4342, GNorm = 0.0720, lr_0 = 1.2221e-04
Loss = 1.1508e-05, PNorm = 52.4338, GNorm = 0.0863, lr_0 = 1.2209e-04
Loss = 1.0936e-05, PNorm = 52.4342, GNorm = 0.0648, lr_0 = 1.2196e-04
Loss = 1.1595e-05, PNorm = 52.4345, GNorm = 0.0708, lr_0 = 1.2183e-04
Loss = 1.1793e-05, PNorm = 52.4345, GNorm = 0.1699, lr_0 = 1.2170e-04
Loss = 1.4085e-05, PNorm = 52.4353, GNorm = 0.0566, lr_0 = 1.2158e-04
Loss = 2.3495e-05, PNorm = 52.4356, GNorm = 0.0986, lr_0 = 1.2145e-04
Loss = 1.8084e-05, PNorm = 52.4362, GNorm = 0.0671, lr_0 = 1.2132e-04
Loss = 1.8996e-05, PNorm = 52.4369, GNorm = 0.0537, lr_0 = 1.2120e-04
Loss = 1.8993e-05, PNorm = 52.4378, GNorm = 0.0837, lr_0 = 1.2107e-04
Loss = 1.3416e-05, PNorm = 52.4385, GNorm = 0.0642, lr_0 = 1.2094e-04
Loss = 1.5972e-05, PNorm = 52.4399, GNorm = 0.0785, lr_0 = 1.2082e-04
Loss = 1.3201e-05, PNorm = 52.4415, GNorm = 0.0544, lr_0 = 1.2069e-04
Loss = 1.8112e-05, PNorm = 52.4424, GNorm = 0.1232, lr_0 = 1.2057e-04
Loss = 1.2680e-05, PNorm = 52.4441, GNorm = 0.0816, lr_0 = 1.2044e-04
Loss = 1.5997e-05, PNorm = 52.4446, GNorm = 0.0954, lr_0 = 1.2031e-04
Loss = 1.3066e-05, PNorm = 52.4458, GNorm = 0.0696, lr_0 = 1.2019e-04
Loss = 1.1161e-05, PNorm = 52.4468, GNorm = 0.0713, lr_0 = 1.2006e-04
Loss = 1.4856e-05, PNorm = 52.4477, GNorm = 0.0791, lr_0 = 1.1994e-04
Loss = 1.5542e-05, PNorm = 52.4487, GNorm = 0.0613, lr_0 = 1.1981e-04
Loss = 1.7108e-05, PNorm = 52.4498, GNorm = 0.1435, lr_0 = 1.1969e-04
Loss = 1.5733e-05, PNorm = 52.4496, GNorm = 0.0743, lr_0 = 1.1956e-04
Validation rmse logD = 0.582050
Validation R2 logD = 0.765362
Validation rmse logP = 0.469340
Validation R2 logP = 0.936068
Epoch 92
Train function
Loss = 1.5222e-05, PNorm = 52.4489, GNorm = 0.0843, lr_0 = 1.1944e-04
Loss = 1.6105e-05, PNorm = 52.4494, GNorm = 0.1289, lr_0 = 1.1931e-04
Loss = 1.3007e-05, PNorm = 52.4496, GNorm = 0.0865, lr_0 = 1.1919e-04
Loss = 1.9933e-05, PNorm = 52.4500, GNorm = 0.0953, lr_0 = 1.1906e-04
Loss = 1.6581e-05, PNorm = 52.4505, GNorm = 0.0569, lr_0 = 1.1894e-04
Loss = 1.8599e-05, PNorm = 52.4514, GNorm = 0.0944, lr_0 = 1.1882e-04
Loss = 1.5797e-05, PNorm = 52.4534, GNorm = 0.0812, lr_0 = 1.1869e-04
Loss = 1.4256e-05, PNorm = 52.4552, GNorm = 0.1253, lr_0 = 1.1857e-04
Loss = 1.3472e-05, PNorm = 52.4562, GNorm = 0.1498, lr_0 = 1.1844e-04
Loss = 1.4584e-05, PNorm = 52.4573, GNorm = 0.1091, lr_0 = 1.1832e-04
Loss = 1.1648e-05, PNorm = 52.4574, GNorm = 0.0757, lr_0 = 1.1820e-04
Loss = 1.2649e-05, PNorm = 52.4575, GNorm = 0.0696, lr_0 = 1.1807e-04
Loss = 1.4163e-05, PNorm = 52.4578, GNorm = 0.0943, lr_0 = 1.1795e-04
Loss = 1.5003e-05, PNorm = 52.4576, GNorm = 0.0793, lr_0 = 1.1783e-04
Loss = 1.1465e-05, PNorm = 52.4583, GNorm = 0.0537, lr_0 = 1.1770e-04
Loss = 1.4137e-05, PNorm = 52.4594, GNorm = 0.1043, lr_0 = 1.1758e-04
Loss = 1.1192e-05, PNorm = 52.4597, GNorm = 0.0617, lr_0 = 1.1746e-04
Loss = 1.2798e-05, PNorm = 52.4593, GNorm = 0.1238, lr_0 = 1.1734e-04
Loss = 1.1922e-05, PNorm = 52.4601, GNorm = 0.0802, lr_0 = 1.1721e-04
Loss = 1.2257e-05, PNorm = 52.4616, GNorm = 0.1062, lr_0 = 1.1709e-04
Loss = 1.7150e-05, PNorm = 52.4626, GNorm = 0.1073, lr_0 = 1.1697e-04
Loss = 1.5382e-05, PNorm = 52.4644, GNorm = 0.0980, lr_0 = 1.1685e-04
Validation rmse logD = 0.583548
Validation R2 logD = 0.764153
Validation rmse logP = 0.469039
Validation R2 logP = 0.936150
Epoch 93
Train function
Loss = 3.3731e-05, PNorm = 52.4655, GNorm = 0.0960, lr_0 = 1.1671e-04
Loss = 1.6994e-05, PNorm = 52.4660, GNorm = 0.1656, lr_0 = 1.1659e-04
Loss = 3.0001e-05, PNorm = 52.4664, GNorm = 0.1552, lr_0 = 1.1647e-04
Loss = 2.6770e-05, PNorm = 52.4657, GNorm = 0.0983, lr_0 = 1.1635e-04
Loss = 2.2528e-05, PNorm = 52.4667, GNorm = 0.1238, lr_0 = 1.1623e-04
Loss = 1.9706e-05, PNorm = 52.4673, GNorm = 0.0715, lr_0 = 1.1611e-04
Loss = 1.7267e-05, PNorm = 52.4678, GNorm = 0.0907, lr_0 = 1.1598e-04
Loss = 1.4755e-05, PNorm = 52.4682, GNorm = 0.1786, lr_0 = 1.1586e-04
Loss = 1.7531e-05, PNorm = 52.4695, GNorm = 0.0946, lr_0 = 1.1574e-04
Loss = 1.7434e-05, PNorm = 52.4707, GNorm = 0.1205, lr_0 = 1.1562e-04
Loss = 1.5289e-05, PNorm = 52.4709, GNorm = 0.0819, lr_0 = 1.1550e-04
Loss = 1.4532e-05, PNorm = 52.4715, GNorm = 0.0934, lr_0 = 1.1538e-04
Loss = 1.7526e-05, PNorm = 52.4727, GNorm = 0.1239, lr_0 = 1.1526e-04
Loss = 1.3747e-05, PNorm = 52.4740, GNorm = 0.0823, lr_0 = 1.1514e-04
Loss = 1.3996e-05, PNorm = 52.4751, GNorm = 0.0649, lr_0 = 1.1502e-04
Loss = 1.3294e-05, PNorm = 52.4760, GNorm = 0.1429, lr_0 = 1.1490e-04
Loss = 1.2483e-05, PNorm = 52.4765, GNorm = 0.0755, lr_0 = 1.1478e-04
Loss = 1.2227e-05, PNorm = 52.4771, GNorm = 0.1034, lr_0 = 1.1466e-04
Loss = 1.4889e-05, PNorm = 52.4781, GNorm = 0.1449, lr_0 = 1.1454e-04
Loss = 1.6631e-05, PNorm = 52.4784, GNorm = 0.1312, lr_0 = 1.1442e-04
Loss = 2.0405e-05, PNorm = 52.4801, GNorm = 0.1875, lr_0 = 1.1430e-04
Loss = 2.2192e-05, PNorm = 52.4820, GNorm = 0.1628, lr_0 = 1.1418e-04
Loss = 1.5521e-05, PNorm = 52.4828, GNorm = 0.0791, lr_0 = 1.1406e-04
Validation rmse logD = 0.583109
Validation R2 logD = 0.764507
Validation rmse logP = 0.468690
Validation R2 logP = 0.936245
Epoch 94
Train function
Loss = 1.5545e-05, PNorm = 52.4844, GNorm = 0.1012, lr_0 = 1.1394e-04
Loss = 1.6379e-05, PNorm = 52.4852, GNorm = 0.0864, lr_0 = 1.1382e-04
Loss = 1.0797e-05, PNorm = 52.4862, GNorm = 0.0971, lr_0 = 1.1371e-04
Loss = 1.4273e-05, PNorm = 52.4861, GNorm = 0.0648, lr_0 = 1.1359e-04
Loss = 1.3390e-05, PNorm = 52.4866, GNorm = 0.1802, lr_0 = 1.1347e-04
Loss = 1.5831e-05, PNorm = 52.4881, GNorm = 0.0714, lr_0 = 1.1335e-04
Loss = 1.7196e-05, PNorm = 52.4893, GNorm = 0.1320, lr_0 = 1.1323e-04
Loss = 1.4029e-05, PNorm = 52.4897, GNorm = 0.0950, lr_0 = 1.1311e-04
Loss = 1.4190e-05, PNorm = 52.4903, GNorm = 0.1047, lr_0 = 1.1300e-04
Loss = 1.6257e-05, PNorm = 52.4904, GNorm = 0.1254, lr_0 = 1.1288e-04
Loss = 1.0026e-05, PNorm = 52.4906, GNorm = 0.0573, lr_0 = 1.1276e-04
Loss = 1.3384e-05, PNorm = 52.4919, GNorm = 0.0601, lr_0 = 1.1264e-04
Loss = 1.6915e-05, PNorm = 52.4926, GNorm = 0.1477, lr_0 = 1.1252e-04
Loss = 1.1313e-05, PNorm = 52.4929, GNorm = 0.0837, lr_0 = 1.1241e-04
Loss = 1.4091e-05, PNorm = 52.4941, GNorm = 0.1116, lr_0 = 1.1229e-04
Loss = 1.6593e-05, PNorm = 52.4946, GNorm = 0.0914, lr_0 = 1.1217e-04
Loss = 1.5581e-05, PNorm = 52.4945, GNorm = 0.0798, lr_0 = 1.1206e-04
Loss = 1.3848e-05, PNorm = 52.4957, GNorm = 0.1206, lr_0 = 1.1194e-04
Loss = 1.0835e-05, PNorm = 52.4970, GNorm = 0.0615, lr_0 = 1.1182e-04
Loss = 1.3395e-05, PNorm = 52.4970, GNorm = 0.0626, lr_0 = 1.1170e-04
Loss = 1.2856e-05, PNorm = 52.4977, GNorm = 0.0722, lr_0 = 1.1159e-04
Loss = 1.2195e-05, PNorm = 52.4980, GNorm = 0.0623, lr_0 = 1.1147e-04
Loss = 1.6475e-05, PNorm = 52.4994, GNorm = 0.0582, lr_0 = 1.1136e-04
Loss = 2.4826e-05, PNorm = 52.4996, GNorm = 0.0790, lr_0 = 1.1134e-04
Validation rmse logD = 0.582374
Validation R2 logD = 0.765101
Validation rmse logP = 0.467985
Validation R2 logP = 0.936437
Epoch 95
Train function
Loss = 1.3649e-05, PNorm = 52.5006, GNorm = 0.1140, lr_0 = 1.1123e-04
Loss = 1.3588e-05, PNorm = 52.5014, GNorm = 0.1608, lr_0 = 1.1111e-04
Loss = 1.6073e-05, PNorm = 52.5028, GNorm = 0.0752, lr_0 = 1.1100e-04
Loss = 1.7692e-05, PNorm = 52.5032, GNorm = 0.1499, lr_0 = 1.1088e-04
Loss = 1.5683e-05, PNorm = 52.5043, GNorm = 0.1241, lr_0 = 1.1076e-04
Loss = 1.1076e-05, PNorm = 52.5045, GNorm = 0.0975, lr_0 = 1.1065e-04
Loss = 1.2983e-05, PNorm = 52.5047, GNorm = 0.0599, lr_0 = 1.1053e-04
Loss = 1.0284e-05, PNorm = 52.5057, GNorm = 0.0914, lr_0 = 1.1042e-04
Loss = 1.2510e-05, PNorm = 52.5062, GNorm = 0.0726, lr_0 = 1.1030e-04
Loss = 1.3334e-05, PNorm = 52.5066, GNorm = 0.0663, lr_0 = 1.1019e-04
Loss = 1.1287e-05, PNorm = 52.5073, GNorm = 0.0655, lr_0 = 1.1007e-04
Loss = 1.0144e-05, PNorm = 52.5077, GNorm = 0.0816, lr_0 = 1.0996e-04
Loss = 1.1517e-05, PNorm = 52.5083, GNorm = 0.0697, lr_0 = 1.0984e-04
Loss = 1.1766e-05, PNorm = 52.5085, GNorm = 0.0580, lr_0 = 1.0973e-04
Loss = 1.3094e-05, PNorm = 52.5095, GNorm = 0.0792, lr_0 = 1.0961e-04
Loss = 1.0987e-05, PNorm = 52.5104, GNorm = 0.0984, lr_0 = 1.0950e-04
Loss = 9.6321e-06, PNorm = 52.5113, GNorm = 0.1060, lr_0 = 1.0938e-04
Loss = 1.3582e-05, PNorm = 52.5119, GNorm = 0.0578, lr_0 = 1.0927e-04
Loss = 1.0025e-05, PNorm = 52.5120, GNorm = 0.0741, lr_0 = 1.0916e-04
Loss = 1.0498e-05, PNorm = 52.5125, GNorm = 0.0744, lr_0 = 1.0904e-04
Loss = 1.0622e-05, PNorm = 52.5127, GNorm = 0.0490, lr_0 = 1.0893e-04
Loss = 1.2685e-05, PNorm = 52.5134, GNorm = 0.0882, lr_0 = 1.0882e-04
Validation rmse logD = 0.583454
Validation R2 logD = 0.764228
Validation rmse logP = 0.468824
Validation R2 logP = 0.936209
Epoch 96
Train function
Loss = 1.3070e-05, PNorm = 52.5144, GNorm = 0.1134, lr_0 = 1.0870e-04
Loss = 1.0024e-05, PNorm = 52.5146, GNorm = 0.0752, lr_0 = 1.0859e-04
Loss = 8.9842e-06, PNorm = 52.5146, GNorm = 0.0474, lr_0 = 1.0847e-04
Loss = 8.4064e-06, PNorm = 52.5153, GNorm = 0.1024, lr_0 = 1.0836e-04
Loss = 1.2780e-05, PNorm = 52.5171, GNorm = 0.0874, lr_0 = 1.0825e-04
Loss = 1.0381e-05, PNorm = 52.5179, GNorm = 0.0630, lr_0 = 1.0814e-04
Loss = 1.0184e-05, PNorm = 52.5186, GNorm = 0.0555, lr_0 = 1.0802e-04
Loss = 9.3016e-06, PNorm = 52.5198, GNorm = 0.0809, lr_0 = 1.0791e-04
Loss = 1.1896e-05, PNorm = 52.5210, GNorm = 0.0894, lr_0 = 1.0780e-04
Loss = 1.0509e-05, PNorm = 52.5225, GNorm = 0.0986, lr_0 = 1.0768e-04
Loss = 7.5689e-06, PNorm = 52.5222, GNorm = 0.0723, lr_0 = 1.0757e-04
Loss = 1.0970e-05, PNorm = 52.5225, GNorm = 0.1230, lr_0 = 1.0746e-04
Loss = 1.2352e-05, PNorm = 52.5228, GNorm = 0.0550, lr_0 = 1.0735e-04
Loss = 1.0949e-05, PNorm = 52.5228, GNorm = 0.0941, lr_0 = 1.0724e-04
Loss = 1.1967e-05, PNorm = 52.5233, GNorm = 0.0792, lr_0 = 1.0712e-04
Loss = 1.3865e-05, PNorm = 52.5240, GNorm = 0.1091, lr_0 = 1.0701e-04
Loss = 1.1978e-05, PNorm = 52.5247, GNorm = 0.0994, lr_0 = 1.0690e-04
Loss = 1.0882e-05, PNorm = 52.5255, GNorm = 0.0488, lr_0 = 1.0679e-04
Loss = 1.0026e-05, PNorm = 52.5261, GNorm = 0.0593, lr_0 = 1.0668e-04
Loss = 1.3880e-05, PNorm = 52.5275, GNorm = 0.0603, lr_0 = 1.0657e-04
Loss = 1.1490e-05, PNorm = 52.5285, GNorm = 0.1230, lr_0 = 1.0645e-04
Loss = 1.2012e-05, PNorm = 52.5284, GNorm = 0.0984, lr_0 = 1.0634e-04
Loss = 1.0365e-05, PNorm = 52.5293, GNorm = 0.0510, lr_0 = 1.0623e-04
Validation rmse logD = 0.581762
Validation R2 logD = 0.765594
Validation rmse logP = 0.467890
Validation R2 logP = 0.936463
Epoch 97
Train function
Loss = 1.0424e-05, PNorm = 52.5295, GNorm = 0.0769, lr_0 = 1.0611e-04
Loss = 9.3655e-06, PNorm = 52.5296, GNorm = 0.0886, lr_0 = 1.0600e-04
Loss = 1.1252e-05, PNorm = 52.5301, GNorm = 0.0883, lr_0 = 1.0589e-04
Loss = 1.2091e-05, PNorm = 52.5309, GNorm = 0.0527, lr_0 = 1.0578e-04
Loss = 1.1398e-05, PNorm = 52.5313, GNorm = 0.1127, lr_0 = 1.0567e-04
Loss = 9.9809e-06, PNorm = 52.5317, GNorm = 0.0594, lr_0 = 1.0556e-04
Loss = 8.2148e-06, PNorm = 52.5326, GNorm = 0.0708, lr_0 = 1.0545e-04
Loss = 1.0268e-05, PNorm = 52.5328, GNorm = 0.0851, lr_0 = 1.0534e-04
Loss = 1.3230e-05, PNorm = 52.5332, GNorm = 0.1248, lr_0 = 1.0523e-04
Loss = 1.3437e-05, PNorm = 52.5336, GNorm = 0.1446, lr_0 = 1.0512e-04
Loss = 1.0431e-05, PNorm = 52.5348, GNorm = 0.0896, lr_0 = 1.0501e-04
Loss = 8.5469e-06, PNorm = 52.5354, GNorm = 0.0645, lr_0 = 1.0490e-04
Loss = 9.5275e-06, PNorm = 52.5358, GNorm = 0.1074, lr_0 = 1.0479e-04
Loss = 1.5283e-05, PNorm = 52.5363, GNorm = 0.1012, lr_0 = 1.0468e-04
Loss = 1.0404e-05, PNorm = 52.5373, GNorm = 0.0683, lr_0 = 1.0457e-04
Loss = 8.9337e-06, PNorm = 52.5379, GNorm = 0.0648, lr_0 = 1.0446e-04
Loss = 9.6369e-06, PNorm = 52.5386, GNorm = 0.1767, lr_0 = 1.0435e-04
Loss = 1.3850e-05, PNorm = 52.5389, GNorm = 0.1190, lr_0 = 1.0424e-04
Loss = 1.1751e-05, PNorm = 52.5400, GNorm = 0.0304, lr_0 = 1.0413e-04
Loss = 1.2480e-05, PNorm = 52.5406, GNorm = 0.0520, lr_0 = 1.0403e-04
Loss = 1.2230e-05, PNorm = 52.5406, GNorm = 0.0971, lr_0 = 1.0392e-04
Loss = 1.0852e-05, PNorm = 52.5414, GNorm = 0.0685, lr_0 = 1.0381e-04
Validation rmse logD = 0.582717
Validation R2 logD = 0.764824
Validation rmse logP = 0.468515
Validation R2 logP = 0.936293
Epoch 98
Train function
Loss = 7.6770e-06, PNorm = 52.5419, GNorm = 0.1151, lr_0 = 1.0370e-04
Loss = 1.1049e-05, PNorm = 52.5422, GNorm = 0.1283, lr_0 = 1.0359e-04
Loss = 1.7182e-05, PNorm = 52.5429, GNorm = 0.0771, lr_0 = 1.0348e-04
Loss = 8.6525e-06, PNorm = 52.5440, GNorm = 0.0692, lr_0 = 1.0338e-04
Loss = 8.7097e-06, PNorm = 52.5444, GNorm = 0.0590, lr_0 = 1.0327e-04
Loss = 7.4724e-06, PNorm = 52.5447, GNorm = 0.0524, lr_0 = 1.0316e-04
Loss = 1.0464e-05, PNorm = 52.5451, GNorm = 0.0879, lr_0 = 1.0305e-04
Loss = 1.1489e-05, PNorm = 52.5445, GNorm = 0.0627, lr_0 = 1.0295e-04
Loss = 1.2726e-05, PNorm = 52.5457, GNorm = 0.0633, lr_0 = 1.0284e-04
Loss = 9.2980e-06, PNorm = 52.5463, GNorm = 0.0516, lr_0 = 1.0273e-04
Loss = 8.3093e-06, PNorm = 52.5469, GNorm = 0.0860, lr_0 = 1.0262e-04
Loss = 8.4098e-06, PNorm = 52.5479, GNorm = 0.0578, lr_0 = 1.0252e-04
Loss = 9.6692e-06, PNorm = 52.5484, GNorm = 0.0760, lr_0 = 1.0241e-04
Loss = 1.0407e-05, PNorm = 52.5495, GNorm = 0.0543, lr_0 = 1.0230e-04
Loss = 1.1507e-05, PNorm = 52.5502, GNorm = 0.0653, lr_0 = 1.0220e-04
Loss = 1.2629e-05, PNorm = 52.5513, GNorm = 0.0513, lr_0 = 1.0209e-04
Loss = 9.9393e-06, PNorm = 52.5520, GNorm = 0.0554, lr_0 = 1.0198e-04
Loss = 1.2977e-05, PNorm = 52.5528, GNorm = 0.1691, lr_0 = 1.0188e-04
Loss = 1.1963e-05, PNorm = 52.5547, GNorm = 0.0605, lr_0 = 1.0177e-04
Loss = 1.1082e-05, PNorm = 52.5554, GNorm = 0.2320, lr_0 = 1.0166e-04
Loss = 1.2177e-05, PNorm = 52.5558, GNorm = 0.1036, lr_0 = 1.0156e-04
Loss = 1.1464e-05, PNorm = 52.5568, GNorm = 0.0624, lr_0 = 1.0145e-04
Loss = 1.2748e-05, PNorm = 52.5567, GNorm = 0.1611, lr_0 = 1.0135e-04
Validation rmse logD = 0.581058
Validation R2 logD = 0.766161
Validation rmse logP = 0.469614
Validation R2 logP = 0.935994
Epoch 99
Train function
Loss = 1.6110e-05, PNorm = 52.5569, GNorm = 0.1155, lr_0 = 1.0123e-04
Loss = 1.3959e-05, PNorm = 52.5566, GNorm = 0.0970, lr_0 = 1.0112e-04
Loss = 1.0599e-05, PNorm = 52.5573, GNorm = 0.0545, lr_0 = 1.0102e-04
Loss = 8.7542e-06, PNorm = 52.5583, GNorm = 0.0796, lr_0 = 1.0091e-04
Loss = 9.0596e-06, PNorm = 52.5592, GNorm = 0.0925, lr_0 = 1.0081e-04
Loss = 9.5771e-06, PNorm = 52.5598, GNorm = 0.0981, lr_0 = 1.0070e-04
Loss = 9.1323e-06, PNorm = 52.5602, GNorm = 0.0528, lr_0 = 1.0060e-04
Loss = 1.0767e-05, PNorm = 52.5606, GNorm = 0.0724, lr_0 = 1.0049e-04
Loss = 1.1855e-05, PNorm = 52.5613, GNorm = 0.0882, lr_0 = 1.0039e-04
Loss = 1.2178e-05, PNorm = 52.5616, GNorm = 0.1320, lr_0 = 1.0028e-04
Loss = 1.2409e-05, PNorm = 52.5621, GNorm = 0.1029, lr_0 = 1.0018e-04
Loss = 1.2307e-05, PNorm = 52.5627, GNorm = 0.0776, lr_0 = 1.0007e-04
Loss = 1.0154e-05, PNorm = 52.5634, GNorm = 0.1173, lr_0 = 1.0000e-04
Loss = 1.0217e-05, PNorm = 52.5640, GNorm = 0.0624, lr_0 = 1.0000e-04
Loss = 9.1370e-06, PNorm = 52.5647, GNorm = 0.0546, lr_0 = 1.0000e-04
Loss = 8.7647e-06, PNorm = 52.5651, GNorm = 0.0773, lr_0 = 1.0000e-04
Loss = 8.1910e-06, PNorm = 52.5649, GNorm = 0.0996, lr_0 = 1.0000e-04
Loss = 7.2337e-06, PNorm = 52.5654, GNorm = 0.0474, lr_0 = 1.0000e-04
Loss = 8.2179e-06, PNorm = 52.5659, GNorm = 0.0761, lr_0 = 1.0000e-04
Loss = 1.0284e-05, PNorm = 52.5660, GNorm = 0.0545, lr_0 = 1.0000e-04
Loss = 1.3038e-05, PNorm = 52.5665, GNorm = 0.0741, lr_0 = 1.0000e-04
Loss = 1.1578e-05, PNorm = 52.5675, GNorm = 0.0772, lr_0 = 1.0000e-04
Validation rmse logD = 0.583348
Validation R2 logD = 0.764314
Validation rmse logP = 0.469713
Validation R2 logP = 0.935967
Model 0 best validation rmse = 0.522600 on epoch 36
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.534958
Model 0 test R2 logD = 0.818493
Model 0 test rmse logP = 0.448863
Model 0 test R2 logP = 0.942131
Ensemble test rmse  logD= 0.534958
Ensemble test R2  logD= 0.818493
Ensemble test rmse  logP= 0.448863
Ensemble test R2  logP= 0.942131
4-fold cross validation
	Seed 0 ==> test rmse = 0.505588
	Seed 0 ==> test R2 = 0.869058
	Seed 1 ==> test rmse = 0.496867
	Seed 1 ==> test R2 = 0.874192
	Seed 2 ==> test rmse = 0.499210
	Seed 2 ==> test R2 = 0.874357
	Seed 3 ==> test rmse = 0.491910
	Seed 3 ==> test R2 = 0.880312
Overall val rmse logD= 0.567204 +/- 0.026378
Overall val R2 logD = 0.772124 +/- 0.019013
Overall test rmse logD = 0.553920 +/- 0.012476
Overall test R2 logD = 0.805299 +/- 0.008731
Overall val rmse logP= 0.456631 +/- 0.007101
Overall val R2 logP = 0.940107 +/- 0.002774
Overall test rmse logP = 0.442868 +/- 0.004489
Overall test R2 logP = 0.943660 +/- 0.001142
Elapsed time = 4:14:02
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 0 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 0,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Loss = 2.0493e-02, PNorm = 34.0110, GNorm = 5.4938, lr_0 = 1.0849e-04
Loss = 1.9860e-02, PNorm = 34.0119, GNorm = 2.3289, lr_0 = 1.0849e-04
Loss = 1.7722e-02, PNorm = 34.0135, GNorm = 6.2600, lr_0 = 1.0849e-04
Loss = 1.8290e-02, PNorm = 34.0156, GNorm = 2.7477, lr_0 = 1.0849e-04
Loss = 1.9026e-02, PNorm = 34.0177, GNorm = 4.6016, lr_0 = 1.0849e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_best'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.8252e-02, PNorm = 35.0058, GNorm = 6.3649, lr_0 = 1.0849e-04
Loss = 2.0975e-02, PNorm = 35.0054, GNorm = 6.2100, lr_0 = 1.0849e-04
Loss = 1.8422e-02, PNorm = 35.0061, GNorm = 3.1628, lr_0 = 1.0849e-04
Loss = 1.7571e-02, PNorm = 35.0074, GNorm = 2.2595, lr_0 = 1.0849e-04
Loss = 1.7731e-02, PNorm = 35.0085, GNorm = 3.0250, lr_0 = 1.0849e-04
Validation rmse logD = 1.085169
Validation R2 logD = 0.180012
Epoch 1
Train function
Loss = 1.5315e-02, PNorm = 35.0100, GNorm = 1.9139, lr_0 = 1.0849e-04
Loss = 1.5058e-02, PNorm = 35.0120, GNorm = 1.6984, lr_0 = 1.0849e-04
Loss = 1.5388e-02, PNorm = 35.0138, GNorm = 2.5091, lr_0 = 1.0849e-04
Loss = 1.5452e-02, PNorm = 35.0162, GNorm = 2.6036, lr_0 = 1.0849e-04
Loss = 1.5136e-02, PNorm = 35.0187, GNorm = 4.6189, lr_0 = 1.0849e-04
Validation rmse logD = 1.016627
Validation R2 logD = 0.280325
Epoch 2
Train function
Loss = 1.7563e-02, PNorm = 35.0224, GNorm = 6.7419, lr_0 = 1.0849e-04
Loss = 1.3424e-02, PNorm = 35.0258, GNorm = 2.5288, lr_0 = 1.0849e-04
Loss = 1.2971e-02, PNorm = 35.0288, GNorm = 2.0841, lr_0 = 1.0849e-04
Loss = 1.4302e-02, PNorm = 35.0313, GNorm = 2.5320, lr_0 = 1.0849e-04
Loss = 1.2332e-02, PNorm = 35.0337, GNorm = 2.7913, lr_0 = 1.0849e-04
Validation rmse logD = 0.964078
Validation R2 logD = 0.352801
Epoch 3
Train function
Loss = 1.3470e-02, PNorm = 35.0369, GNorm = 1.9321, lr_0 = 1.0849e-04
Loss = 1.2649e-02, PNorm = 35.0404, GNorm = 3.8279, lr_0 = 1.0849e-04
Loss = 1.2827e-02, PNorm = 35.0441, GNorm = 2.5174, lr_0 = 1.0849e-04
Loss = 1.2564e-02, PNorm = 35.0472, GNorm = 2.0034, lr_0 = 1.0849e-04
Loss = 1.1792e-02, PNorm = 35.0496, GNorm = 2.0524, lr_0 = 1.0849e-04
Loss = 1.2236e-02, PNorm = 35.0530, GNorm = 4.3902, lr_0 = 1.0849e-04
Validation rmse logD = 0.930093
Validation R2 logD = 0.397627
Epoch 4
Train function
Loss = 1.2942e-02, PNorm = 35.0569, GNorm = 4.6581, lr_0 = 1.0849e-04
Loss = 1.2701e-02, PNorm = 35.0609, GNorm = 4.4028, lr_0 = 1.0849e-04
Loss = 9.8586e-03, PNorm = 35.0652, GNorm = 2.4944, lr_0 = 1.0849e-04
Loss = 1.1042e-02, PNorm = 35.0690, GNorm = 1.5788, lr_0 = 1.0849e-04
Loss = 1.1087e-02, PNorm = 35.0727, GNorm = 8.7399, lr_0 = 1.0849e-04
Validation rmse logD = 0.907776
Validation R2 logD = 0.426187
Epoch 5
Train function
Loss = 1.0098e-02, PNorm = 35.0760, GNorm = 8.6131, lr_0 = 1.0849e-04
Loss = 1.1555e-02, PNorm = 35.0792, GNorm = 1.7403, lr_0 = 1.0849e-04
Loss = 9.9559e-03, PNorm = 35.0834, GNorm = 1.6446, lr_0 = 1.0849e-04
Loss = 1.0090e-02, PNorm = 35.0876, GNorm = 4.1560, lr_0 = 1.0849e-04
Loss = 1.1017e-02, PNorm = 35.0925, GNorm = 8.6506, lr_0 = 1.0849e-04
Validation rmse logD = 0.890599
Validation R2 logD = 0.447696
Epoch 6
Train function
Loss = 1.2160e-02, PNorm = 35.0987, GNorm = 15.4786, lr_0 = 1.0849e-04
Loss = 9.9090e-03, PNorm = 35.1039, GNorm = 4.4291, lr_0 = 1.0849e-04
Loss = 1.0523e-02, PNorm = 35.1078, GNorm = 1.9455, lr_0 = 1.0849e-04
Loss = 9.6890e-03, PNorm = 35.1128, GNorm = 2.2957, lr_0 = 1.0849e-04
Loss = 1.0397e-02, PNorm = 35.1175, GNorm = 5.8155, lr_0 = 1.0849e-04
Loss = 9.3424e-03, PNorm = 35.1215, GNorm = 5.7653, lr_0 = 1.0849e-04
Validation rmse logD = 0.868406
Validation R2 logD = 0.474880
Epoch 7
Train function
Loss = 1.0960e-02, PNorm = 35.1251, GNorm = 6.2474, lr_0 = 1.0849e-04
Loss = 1.1329e-02, PNorm = 35.1290, GNorm = 3.2013, lr_0 = 1.0849e-04
Loss = 9.0295e-03, PNorm = 35.1333, GNorm = 2.3841, lr_0 = 1.0849e-04
Loss = 1.0155e-02, PNorm = 35.1380, GNorm = 7.0080, lr_0 = 1.0849e-04
Loss = 8.6096e-03, PNorm = 35.1422, GNorm = 2.6734, lr_0 = 1.0849e-04
Validation rmse logD = 0.843244
Validation R2 logD = 0.504869
Epoch 8
Train function
Loss = 8.7263e-03, PNorm = 35.1476, GNorm = 4.8038, lr_0 = 1.0849e-04
Loss = 8.9625e-03, PNorm = 35.1523, GNorm = 4.1522, lr_0 = 1.0849e-04
Loss = 8.8462e-03, PNorm = 35.1568, GNorm = 2.8371, lr_0 = 1.0849e-04
Loss = 9.5481e-03, PNorm = 35.1624, GNorm = 5.1688, lr_0 = 1.0849e-04
Loss = 8.7414e-03, PNorm = 35.1676, GNorm = 5.5836, lr_0 = 1.0849e-04
Validation rmse logD = 0.822853
Validation R2 logD = 0.528526
Epoch 9
Train function
Loss = 9.1725e-03, PNorm = 35.1727, GNorm = 7.0594, lr_0 = 1.0849e-04
Loss = 8.9633e-03, PNorm = 35.1775, GNorm = 5.0572, lr_0 = 1.0849e-04
Loss = 7.6303e-03, PNorm = 35.1824, GNorm = 8.4276, lr_0 = 1.0849e-04
Loss = 9.5800e-03, PNorm = 35.1864, GNorm = 7.0751, lr_0 = 1.0849e-04
Loss = 8.7766e-03, PNorm = 35.1918, GNorm = 4.6446, lr_0 = 1.0849e-04
Loss = 8.6880e-03, PNorm = 35.1981, GNorm = 4.3383, lr_0 = 1.0849e-04
Validation rmse logD = 0.819468
Validation R2 logD = 0.532398
Epoch 10
Train function
Loss = 7.4554e-03, PNorm = 35.2044, GNorm = 2.2849, lr_0 = 1.0849e-04
Loss = 7.2182e-03, PNorm = 35.2102, GNorm = 3.7649, lr_0 = 1.0849e-04
Loss = 9.3685e-03, PNorm = 35.2162, GNorm = 5.3614, lr_0 = 1.0849e-04
Loss = 8.7609e-03, PNorm = 35.2214, GNorm = 1.9385, lr_0 = 1.0849e-04
Loss = 8.9691e-03, PNorm = 35.2263, GNorm = 3.6606, lr_0 = 1.0849e-04
Validation rmse logD = 0.801214
Validation R2 logD = 0.552997
Epoch 11
Train function
Loss = 7.7266e-03, PNorm = 35.2323, GNorm = 2.9024, lr_0 = 1.0849e-04
Loss = 7.9873e-03, PNorm = 35.2380, GNorm = 8.4017, lr_0 = 1.0849e-04
Loss = 7.4925e-03, PNorm = 35.2436, GNorm = 3.8716, lr_0 = 1.0849e-04
Loss = 8.3598e-03, PNorm = 35.2498, GNorm = 3.9225, lr_0 = 1.0849e-04
Loss = 8.1799e-03, PNorm = 35.2554, GNorm = 3.4980, lr_0 = 1.0849e-04
Validation rmse logD = 0.779195
Validation R2 logD = 0.577229
Epoch 12
Train function
Loss = 7.9561e-03, PNorm = 35.2621, GNorm = 4.4820, lr_0 = 1.0849e-04
Loss = 6.9374e-03, PNorm = 35.2676, GNorm = 2.4604, lr_0 = 1.0849e-04
Loss = 7.4699e-03, PNorm = 35.2728, GNorm = 9.3015, lr_0 = 1.0849e-04
Loss = 7.2576e-03, PNorm = 35.2795, GNorm = 2.9733, lr_0 = 1.0849e-04
Loss = 7.8253e-03, PNorm = 35.2861, GNorm = 4.0716, lr_0 = 1.0849e-04
Loss = 7.3947e-03, PNorm = 35.2917, GNorm = 3.0572, lr_0 = 1.0849e-04
Loss = 1.6268e-01, PNorm = 35.2924, GNorm = 15.0693, lr_0 = 1.0849e-04
Validation rmse logD = 0.777836
Validation R2 logD = 0.578702
Epoch 13
Train function
Loss = 7.7426e-03, PNorm = 35.2976, GNorm = 1.8957, lr_0 = 1.0849e-04
Loss = 7.3271e-03, PNorm = 35.3039, GNorm = 2.4468, lr_0 = 1.0849e-04
Loss = 7.2520e-03, PNorm = 35.3105, GNorm = 4.9542, lr_0 = 1.0849e-04
Loss = 7.5835e-03, PNorm = 35.3166, GNorm = 7.2501, lr_0 = 1.0849e-04
Loss = 6.5373e-03, PNorm = 35.3212, GNorm = 10.0673, lr_0 = 1.0849e-04
Validation rmse logD = 0.888249
Validation R2 logD = 0.450608
Epoch 14
Train function
Loss = 7.8557e-03, PNorm = 35.3266, GNorm = 5.1445, lr_0 = 1.0849e-04
Loss = 5.8721e-03, PNorm = 35.3319, GNorm = 1.5929, lr_0 = 1.0849e-04
Loss = 6.8493e-03, PNorm = 35.3368, GNorm = 1.6069, lr_0 = 1.0849e-04
Loss = 7.3609e-03, PNorm = 35.3420, GNorm = 3.0053, lr_0 = 1.0849e-04
Loss = 7.1841e-03, PNorm = 35.3482, GNorm = 4.2335, lr_0 = 1.0849e-04
Validation rmse logD = 0.743657
Validation R2 logD = 0.614914
Epoch 15
Train function
Loss = 6.1159e-03, PNorm = 35.3545, GNorm = 12.4055, lr_0 = 1.0849e-04
Loss = 6.5344e-03, PNorm = 35.3601, GNorm = 3.7773, lr_0 = 1.0849e-04
Loss = 6.4370e-03, PNorm = 35.3649, GNorm = 2.4710, lr_0 = 1.0849e-04
Loss = 8.0378e-03, PNorm = 35.3694, GNorm = 8.5964, lr_0 = 1.0849e-04
Loss = 8.1111e-03, PNorm = 35.3740, GNorm = 5.2740, lr_0 = 1.0849e-04
Validation rmse logD = 0.789609
Validation R2 logD = 0.565853
Epoch 16
Train function
Loss = 5.4293e-03, PNorm = 35.3807, GNorm = 5.2406, lr_0 = 1.0849e-04
Loss = 6.9640e-03, PNorm = 35.3878, GNorm = 2.0502, lr_0 = 1.0849e-04
Loss = 6.7554e-03, PNorm = 35.3937, GNorm = 1.8575, lr_0 = 1.0849e-04
Loss = 6.3826e-03, PNorm = 35.3984, GNorm = 1.5058, lr_0 = 1.0849e-04
Loss = 5.8811e-03, PNorm = 35.4032, GNorm = 2.8688, lr_0 = 1.0849e-04
Loss = 6.5309e-03, PNorm = 35.4082, GNorm = 5.1579, lr_0 = 1.0849e-04
Validation rmse logD = 0.800045
Validation R2 logD = 0.554301
Epoch 17
Train function
Loss = 7.6844e-03, PNorm = 35.4127, GNorm = 7.5015, lr_0 = 1.0849e-04
Loss = 6.7110e-03, PNorm = 35.4174, GNorm = 4.2836, lr_0 = 1.0849e-04
Loss = 7.0019e-03, PNorm = 35.4219, GNorm = 8.0188, lr_0 = 1.0849e-04
Loss = 6.2805e-03, PNorm = 35.4275, GNorm = 3.3684, lr_0 = 1.0849e-04
Loss = 5.7391e-03, PNorm = 35.4336, GNorm = 6.2740, lr_0 = 1.0849e-04
Validation rmse logD = 0.742282
Validation R2 logD = 0.616336
Epoch 18
Train function
Loss = 6.0090e-03, PNorm = 35.4399, GNorm = 4.4895, lr_0 = 1.0849e-04
Loss = 5.9489e-03, PNorm = 35.4450, GNorm = 11.7071, lr_0 = 1.0849e-04
Loss = 5.6847e-03, PNorm = 35.4483, GNorm = 10.1017, lr_0 = 1.0849e-04
Loss = 6.4000e-03, PNorm = 35.4532, GNorm = 3.0046, lr_0 = 1.0849e-04
Loss = 7.3879e-03, PNorm = 35.4582, GNorm = 2.0840, lr_0 = 1.0849e-04
Validation rmse logD = 0.713016
Validation R2 logD = 0.645994
Epoch 19
Train function
Loss = 8.8580e-03, PNorm = 35.4637, GNorm = 8.9000, lr_0 = 1.0849e-04
Loss = 5.2737e-03, PNorm = 35.4691, GNorm = 6.9538, lr_0 = 1.0849e-04
Loss = 5.7282e-03, PNorm = 35.4739, GNorm = 2.8309, lr_0 = 1.0849e-04
Loss = 5.5248e-03, PNorm = 35.4784, GNorm = 3.8873, lr_0 = 1.0849e-04
Loss = 5.7917e-03, PNorm = 35.4829, GNorm = 9.9661, lr_0 = 1.0849e-04
Loss = 6.7134e-03, PNorm = 35.4872, GNorm = 12.6319, lr_0 = 1.0849e-04
Validation rmse logD = 0.716102
Validation R2 logD = 0.642922
Epoch 20
Train function
Loss = 7.1524e-03, PNorm = 35.4929, GNorm = 7.1837, lr_0 = 1.0849e-04
Loss = 5.7681e-03, PNorm = 35.4983, GNorm = 2.0602, lr_0 = 1.0849e-04
Loss = 5.4353e-03, PNorm = 35.5034, GNorm = 4.7506, lr_0 = 1.0849e-04
Loss = 5.6604e-03, PNorm = 35.5084, GNorm = 12.0647, lr_0 = 1.0849e-04
Loss = 5.9503e-03, PNorm = 35.5123, GNorm = 3.6183, lr_0 = 1.0849e-04
Validation rmse logD = 0.715513
Validation R2 logD = 0.643510
Epoch 21
Train function
Loss = 6.2151e-03, PNorm = 35.5164, GNorm = 3.3853, lr_0 = 1.0849e-04
Loss = 5.5415e-03, PNorm = 35.5210, GNorm = 5.6635, lr_0 = 1.0849e-04
Loss = 5.5027e-03, PNorm = 35.5269, GNorm = 3.2693, lr_0 = 1.0849e-04
Loss = 5.1148e-03, PNorm = 35.5326, GNorm = 2.4116, lr_0 = 1.0849e-04
Loss = 5.8149e-03, PNorm = 35.5376, GNorm = 8.0509, lr_0 = 1.0849e-04
Validation rmse logD = 0.706326
Validation R2 logD = 0.652605
Epoch 22
Train function
Loss = 4.8428e-03, PNorm = 35.5426, GNorm = 2.3376, lr_0 = 1.0849e-04
Loss = 5.3944e-03, PNorm = 35.5462, GNorm = 5.0091, lr_0 = 1.0849e-04
Loss = 5.7190e-03, PNorm = 35.5498, GNorm = 3.1219, lr_0 = 1.0849e-04
Loss = 5.4529e-03, PNorm = 35.5543, GNorm = 4.8616, lr_0 = 1.0849e-04
Loss = 5.7248e-03, PNorm = 35.5585, GNorm = 7.3089, lr_0 = 1.0849e-04
Loss = 6.2704e-03, PNorm = 35.5636, GNorm = 5.4877, lr_0 = 1.0849e-04
Validation rmse logD = 0.721517
Validation R2 logD = 0.637501
Epoch 23
Train function
Loss = 5.6839e-03, PNorm = 35.5682, GNorm = 1.3622, lr_0 = 1.0849e-04
Loss = 5.6509e-03, PNorm = 35.5729, GNorm = 5.7238, lr_0 = 1.0849e-04
Loss = 5.5397e-03, PNorm = 35.5781, GNorm = 3.7202, lr_0 = 1.0849e-04
Loss = 5.1308e-03, PNorm = 35.5820, GNorm = 3.9179, lr_0 = 1.0849e-04
Loss = 4.9099e-03, PNorm = 35.5865, GNorm = 3.7519, lr_0 = 1.0849e-04
Validation rmse logD = 0.684633
Validation R2 logD = 0.673616
Epoch 24
Train function
Loss = 5.0463e-03, PNorm = 35.5917, GNorm = 3.1880, lr_0 = 1.0849e-04
Loss = 4.4042e-03, PNorm = 35.5966, GNorm = 9.9630, lr_0 = 1.0849e-04
Loss = 5.2824e-03, PNorm = 35.6011, GNorm = 2.3190, lr_0 = 1.0849e-04
Loss = 5.4261e-03, PNorm = 35.6056, GNorm = 2.9892, lr_0 = 1.0849e-04
Loss = 4.9925e-03, PNorm = 35.6100, GNorm = 2.1387, lr_0 = 1.0849e-04
Validation rmse logD = 0.737030
Validation R2 logD = 0.621746
Epoch 25
Train function
Loss = 6.2566e-03, PNorm = 35.6140, GNorm = 10.6756, lr_0 = 1.0849e-04
Loss = 4.9537e-03, PNorm = 35.6183, GNorm = 4.7790, lr_0 = 1.0849e-04
Loss = 5.0961e-03, PNorm = 35.6232, GNorm = 3.5028, lr_0 = 1.0849e-04
Loss = 4.7621e-03, PNorm = 35.6281, GNorm = 5.3648, lr_0 = 1.0849e-04
Loss = 4.8523e-03, PNorm = 35.6329, GNorm = 8.1015, lr_0 = 1.0849e-04
Loss = 5.1567e-03, PNorm = 35.6374, GNorm = 6.4512, lr_0 = 1.0849e-04
Loss = 1.6885e-02, PNorm = 35.6380, GNorm = 3.9086, lr_0 = 1.0849e-04
Validation rmse logD = 0.703015
Validation R2 logD = 0.655854
Epoch 26
Train function
Loss = 3.9222e-03, PNorm = 35.6423, GNorm = 2.4814, lr_0 = 1.0849e-04
Loss = 4.5518e-03, PNorm = 35.6468, GNorm = 6.2781, lr_0 = 1.0849e-04
Loss = 5.0636e-03, PNorm = 35.6508, GNorm = 6.1491, lr_0 = 1.0849e-04
Loss = 5.1629e-03, PNorm = 35.6557, GNorm = 8.3937, lr_0 = 1.0849e-04
Loss = 5.1091e-03, PNorm = 35.6605, GNorm = 6.1458, lr_0 = 1.0849e-04
Validation rmse logD = 0.663731
Validation R2 logD = 0.693241
Epoch 27
Train function
Loss = 4.6180e-03, PNorm = 35.6658, GNorm = 4.3437, lr_0 = 1.0849e-04
Loss = 4.2641e-03, PNorm = 35.6705, GNorm = 4.7021, lr_0 = 1.0849e-04
Loss = 4.1340e-03, PNorm = 35.6743, GNorm = 2.8689, lr_0 = 1.0849e-04
Loss = 3.9984e-03, PNorm = 35.6785, GNorm = 3.5943, lr_0 = 1.0849e-04
Loss = 5.0045e-03, PNorm = 35.6831, GNorm = 2.0308, lr_0 = 1.0849e-04
Validation rmse logD = 0.667414
Validation R2 logD = 0.689828
Epoch 28
Train function
Loss = 3.9385e-03, PNorm = 35.6868, GNorm = 7.5301, lr_0 = 1.0849e-04
Loss = 4.4909e-03, PNorm = 35.6907, GNorm = 1.9223, lr_0 = 1.0849e-04
Loss = 4.9660e-03, PNorm = 35.6948, GNorm = 2.7352, lr_0 = 1.0849e-04
Loss = 4.2066e-03, PNorm = 35.6996, GNorm = 6.2635, lr_0 = 1.0849e-04
Loss = 4.2990e-03, PNorm = 35.7042, GNorm = 1.9777, lr_0 = 1.0849e-04
Validation rmse logD = 0.720691
Validation R2 logD = 0.638331
Epoch 29
Train function
Loss = 5.2833e-03, PNorm = 35.7103, GNorm = 11.5770, lr_0 = 1.0849e-04
Loss = 5.9146e-03, PNorm = 35.7135, GNorm = 14.1899, lr_0 = 1.0849e-04
Loss = 4.0851e-03, PNorm = 35.7172, GNorm = 4.8908, lr_0 = 1.0849e-04
Loss = 4.2876e-03, PNorm = 35.7212, GNorm = 9.6086, lr_0 = 1.0849e-04
Loss = 4.1241e-03, PNorm = 35.7260, GNorm = 2.6761, lr_0 = 1.0849e-04
Loss = 4.6931e-03, PNorm = 35.7304, GNorm = 4.8632, lr_0 = 1.0849e-04
Validation rmse logD = 0.673830
Validation R2 logD = 0.683835
Epoch 30
Train function
Loss = 4.0810e-03, PNorm = 35.7361, GNorm = 1.6732, lr_0 = 1.0849e-04
Loss = 4.4649e-03, PNorm = 35.7410, GNorm = 5.1109, lr_0 = 1.0849e-04
Loss = 4.2501e-03, PNorm = 35.7453, GNorm = 4.4107, lr_0 = 1.0849e-04
Loss = 4.2029e-03, PNorm = 35.7496, GNorm = 3.5513, lr_0 = 1.0849e-04
Loss = 3.7103e-03, PNorm = 35.7539, GNorm = 2.2158, lr_0 = 1.0849e-04
Validation rmse logD = 0.666882
Validation R2 logD = 0.690321
Epoch 31
Train function
Loss = 4.7594e-03, PNorm = 35.7585, GNorm = 3.3533, lr_0 = 1.0849e-04
Loss = 4.4080e-03, PNorm = 35.7627, GNorm = 4.9229, lr_0 = 1.0849e-04
Loss = 4.1166e-03, PNorm = 35.7670, GNorm = 6.9987, lr_0 = 1.0849e-04
Loss = 3.8691e-03, PNorm = 35.7711, GNorm = 3.6160, lr_0 = 1.0849e-04
Loss = 3.7555e-03, PNorm = 35.7752, GNorm = 6.6426, lr_0 = 1.0849e-04
Validation rmse logD = 0.704042
Validation R2 logD = 0.654848
Epoch 32
Train function
Loss = 7.2654e-03, PNorm = 35.7792, GNorm = 14.8556, lr_0 = 1.0849e-04
Loss = 3.4628e-03, PNorm = 35.7824, GNorm = 1.8464, lr_0 = 1.0849e-04
Loss = 4.3731e-03, PNorm = 35.7877, GNorm = 11.8947, lr_0 = 1.0849e-04
Loss = 4.3766e-03, PNorm = 35.7913, GNorm = 3.2884, lr_0 = 1.0849e-04
Loss = 3.5887e-03, PNorm = 35.7954, GNorm = 9.0851, lr_0 = 1.0849e-04
Loss = 3.9910e-03, PNorm = 35.7999, GNorm = 4.9250, lr_0 = 1.0849e-04
Validation rmse logD = 0.644434
Validation R2 logD = 0.710819
Epoch 33
Train function
Loss = 3.8228e-03, PNorm = 35.8032, GNorm = 5.4021, lr_0 = 1.0849e-04
Loss = 4.0175e-03, PNorm = 35.8079, GNorm = 4.1950, lr_0 = 1.0849e-04
Loss = 3.4879e-03, PNorm = 35.8117, GNorm = 3.6854, lr_0 = 1.0849e-04
Loss = 3.8061e-03, PNorm = 35.8167, GNorm = 2.0968, lr_0 = 1.0849e-04
Loss = 3.9299e-03, PNorm = 35.8216, GNorm = 2.6241, lr_0 = 1.0849e-04
Validation rmse logD = 0.647392
Validation R2 logD = 0.708158
Epoch 34
Train function
Loss = 3.4693e-03, PNorm = 35.8259, GNorm = 4.9789, lr_0 = 1.0849e-04
Loss = 3.8838e-03, PNorm = 35.8300, GNorm = 5.3224, lr_0 = 1.0849e-04
Loss = 3.6138e-03, PNorm = 35.8337, GNorm = 3.3776, lr_0 = 1.0849e-04
Loss = 4.2382e-03, PNorm = 35.8377, GNorm = 14.3629, lr_0 = 1.0849e-04
Loss = 3.5900e-03, PNorm = 35.8423, GNorm = 5.5865, lr_0 = 1.0849e-04
Validation rmse logD = 0.638180
Validation R2 logD = 0.716404
Epoch 35
Train function
Loss = 2.7223e-03, PNorm = 35.8458, GNorm = 2.3948, lr_0 = 1.0849e-04
Loss = 3.5340e-03, PNorm = 35.8494, GNorm = 2.3394, lr_0 = 1.0849e-04
Loss = 3.2786e-03, PNorm = 35.8531, GNorm = 3.9195, lr_0 = 1.0849e-04
Loss = 4.6448e-03, PNorm = 35.8569, GNorm = 5.6356, lr_0 = 1.0849e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD'],
 'task_names': ['logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 3,541 | train size = 2,655 | val size = 886 | test size = 625
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 414,601
Moving model to cuda
Epoch 0
Train function
Loss = 2.8252e-02, PNorm = 35.0058, GNorm = 6.3649, lr_0 = 1.0849e-04
Loss = 2.0975e-02, PNorm = 35.0054, GNorm = 6.2100, lr_0 = 1.0849e-04
Loss = 1.8422e-02, PNorm = 35.0061, GNorm = 3.1628, lr_0 = 1.0849e-04
Loss = 1.7571e-02, PNorm = 35.0074, GNorm = 2.2595, lr_0 = 1.0849e-04
Loss = 1.7731e-02, PNorm = 35.0085, GNorm = 3.0250, lr_0 = 1.0849e-04
Validation rmse logD = 1.085169
Validation R2 logD = 0.180012
Epoch 1
Train function
Loss = 1.5315e-02, PNorm = 35.0100, GNorm = 1.9139, lr_0 = 1.0849e-04
Loss = 1.5058e-02, PNorm = 35.0120, GNorm = 1.6984, lr_0 = 1.0849e-04
Loss = 1.5388e-02, PNorm = 35.0138, GNorm = 2.5091, lr_0 = 1.0849e-04
Loss = 1.5452e-02, PNorm = 35.0162, GNorm = 2.6036, lr_0 = 1.0849e-04
Loss = 1.5136e-02, PNorm = 35.0187, GNorm = 4.6189, lr_0 = 1.0849e-04
Validation rmse logD = 1.016627
Validation R2 logD = 0.280325
Epoch 2
Train function
Loss = 1.7563e-02, PNorm = 35.0224, GNorm = 6.7419, lr_0 = 1.0849e-04
Loss = 1.3424e-02, PNorm = 35.0258, GNorm = 2.5288, lr_0 = 1.0849e-04
Loss = 1.2971e-02, PNorm = 35.0288, GNorm = 2.0841, lr_0 = 1.0849e-04
Loss = 1.4302e-02, PNorm = 35.0313, GNorm = 2.5320, lr_0 = 1.0849e-04
Loss = 1.2332e-02, PNorm = 35.0337, GNorm = 2.7913, lr_0 = 1.0849e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 8,782 | val size = 2,928 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'one_out_crossval',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'one_out_crossval',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Loss = 1.7144e-02, PNorm = 34.0564, GNorm = 2.4991, lr_0 = 1.0200e-04
Loss = 2.0836e-02, PNorm = 34.0578, GNorm = 4.3161, lr_0 = 1.0200e-04
Loss = 1.6399e-02, PNorm = 34.0593, GNorm = 6.4932, lr_0 = 1.0200e-04
Loss = 1.7208e-02, PNorm = 34.0608, GNorm = 2.0625, lr_0 = 1.0200e-04
Loss = 1.7193e-02, PNorm = 34.0627, GNorm = 3.4313, lr_0 = 1.0200e-04
Loss = 1.6376e-02, PNorm = 34.0649, GNorm = 5.2201, lr_0 = 1.0200e-04
Loss = 1.4518e-02, PNorm = 34.0678, GNorm = 2.7939, lr_0 = 1.0200e-04
Loss = 1.5150e-02, PNorm = 34.0710, GNorm = 10.6618, lr_0 = 1.0200e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP', 'logD'],
 'task_names': ['logP', 'logD'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,202
Moving model to cuda
Epoch 0
Train function
Loss = 1.7144e-02, PNorm = 34.0564, GNorm = 2.4991, lr_0 = 1.0200e-04
Loss = 2.0836e-02, PNorm = 34.0578, GNorm = 4.3161, lr_0 = 1.0200e-04
Loss = 1.6399e-02, PNorm = 34.0593, GNorm = 6.4932, lr_0 = 1.0200e-04
Loss = 1.7208e-02, PNorm = 34.0608, GNorm = 2.0625, lr_0 = 1.0200e-04
Loss = 1.7193e-02, PNorm = 34.0627, GNorm = 3.4313, lr_0 = 1.0200e-04
Loss = 1.6376e-02, PNorm = 34.0649, GNorm = 5.2201, lr_0 = 1.0200e-04
Loss = 1.4518e-02, PNorm = 34.0678, GNorm = 2.7939, lr_0 = 1.0200e-04
Loss = 1.5150e-02, PNorm = 34.0710, GNorm = 10.6618, lr_0 = 1.0200e-04
Loss = 1.3435e-02, PNorm = 34.0732, GNorm = 10.3551, lr_0 = 1.0200e-04
Loss = 1.1961e-02, PNorm = 34.0761, GNorm = 4.3627, lr_0 = 1.0200e-04
Loss = 1.2771e-02, PNorm = 34.0794, GNorm = 2.7107, lr_0 = 1.0200e-04
Loss = 1.3138e-02, PNorm = 34.0829, GNorm = 4.9068, lr_0 = 1.0200e-04
Loss = 1.3105e-02, PNorm = 34.0865, GNorm = 19.9499, lr_0 = 1.0200e-04
Loss = 1.1540e-02, PNorm = 34.0891, GNorm = 6.5058, lr_0 = 1.0200e-04
Loss = 1.1791e-02, PNorm = 34.0913, GNorm = 9.2823, lr_0 = 1.0200e-04
Loss = 1.0747e-02, PNorm = 34.0949, GNorm = 7.5681, lr_0 = 1.0200e-04
Loss = 1.1345e-02, PNorm = 34.0984, GNorm = 4.6826, lr_0 = 1.0200e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 11,177 | val size = 533 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Loss = 1.6962e-02, PNorm = 34.0116, GNorm = 1.9700, lr_0 = 1.0202e-04
Loss = 1.7711e-02, PNorm = 34.0139, GNorm = 2.5146, lr_0 = 1.0202e-04
Loss = 1.5340e-02, PNorm = 34.0169, GNorm = 1.9349, lr_0 = 1.0202e-04
Loss = 1.5352e-02, PNorm = 34.0206, GNorm = 1.7695, lr_0 = 1.0202e-04
Loss = 1.4047e-02, PNorm = 34.0248, GNorm = 2.5131, lr_0 = 1.0202e-04
Loss = 1.3613e-02, PNorm = 34.0288, GNorm = 15.3018, lr_0 = 1.0202e-04
Loss = 1.2169e-02, PNorm = 34.0321, GNorm = 20.2297, lr_0 = 1.0202e-04
Loss = 1.2418e-02, PNorm = 34.0349, GNorm = 21.5383, lr_0 = 1.0202e-04
Loss = 1.0239e-02, PNorm = 34.0375, GNorm = 2.9857, lr_0 = 1.0202e-04
Loss = 1.0228e-02, PNorm = 34.0413, GNorm = 24.1786, lr_0 = 1.0202e-04
Loss = 8.8066e-03, PNorm = 34.0445, GNorm = 6.9430, lr_0 = 1.0202e-04
Loss = 1.0586e-02, PNorm = 34.0473, GNorm = 15.4734, lr_0 = 1.0202e-04
Loss = 1.0139e-02, PNorm = 34.0504, GNorm = 14.3769, lr_0 = 1.0202e-04
Loss = 1.0688e-02, PNorm = 34.0530, GNorm = 3.6074, lr_0 = 1.0202e-04
Loss = 9.4742e-03, PNorm = 34.0559, GNorm = 12.3202, lr_0 = 1.0202e-04
Loss = 9.0447e-03, PNorm = 34.0595, GNorm = 8.8030, lr_0 = 1.0202e-04
Loss = 7.7187e-03, PNorm = 34.0637, GNorm = 5.1046, lr_0 = 1.0202e-04
Loss = 6.7299e-03, PNorm = 34.0665, GNorm = 7.9823, lr_0 = 1.0202e-04
Loss = 8.8600e-03, PNorm = 34.0699, GNorm = 10.6906, lr_0 = 1.0202e-04
Loss = 6.9359e-03, PNorm = 34.0723, GNorm = 11.0408, lr_0 = 1.0202e-04
Loss = 8.2959e-03, PNorm = 34.0753, GNorm = 15.0221, lr_0 = 1.0202e-04
Loss = 6.3613e-03, PNorm = 34.0789, GNorm = 2.8511, lr_0 = 1.0202e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 11,177 | val size = 533 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Loss = 1.6962e-02, PNorm = 34.0116, GNorm = 1.9700, lr_0 = 1.0202e-04
Loss = 1.7711e-02, PNorm = 34.0139, GNorm = 2.5146, lr_0 = 1.0202e-04
Loss = 1.5340e-02, PNorm = 34.0169, GNorm = 1.9349, lr_0 = 1.0202e-04
Loss = 1.5352e-02, PNorm = 34.0206, GNorm = 1.7695, lr_0 = 1.0202e-04
Loss = 1.4047e-02, PNorm = 34.0248, GNorm = 2.5131, lr_0 = 1.0202e-04
Loss = 1.3613e-02, PNorm = 34.0288, GNorm = 15.3018, lr_0 = 1.0202e-04
Loss = 1.2169e-02, PNorm = 34.0321, GNorm = 20.2297, lr_0 = 1.0202e-04
Loss = 1.2418e-02, PNorm = 34.0349, GNorm = 21.5383, lr_0 = 1.0202e-04
Loss = 1.0239e-02, PNorm = 34.0375, GNorm = 2.9857, lr_0 = 1.0202e-04
Loss = 1.0228e-02, PNorm = 34.0413, GNorm = 24.1786, lr_0 = 1.0202e-04
Loss = 8.8066e-03, PNorm = 34.0445, GNorm = 6.9430, lr_0 = 1.0202e-04
Loss = 1.0586e-02, PNorm = 34.0473, GNorm = 15.4734, lr_0 = 1.0202e-04
Loss = 1.0139e-02, PNorm = 34.0504, GNorm = 14.3769, lr_0 = 1.0202e-04
Loss = 1.0688e-02, PNorm = 34.0530, GNorm = 3.6074, lr_0 = 1.0202e-04
Loss = 9.4742e-03, PNorm = 34.0559, GNorm = 12.3202, lr_0 = 1.0202e-04
Loss = 9.0447e-03, PNorm = 34.0595, GNorm = 8.8030, lr_0 = 1.0202e-04
Loss = 7.7187e-03, PNorm = 34.0637, GNorm = 5.1046, lr_0 = 1.0202e-04
Loss = 6.7299e-03, PNorm = 34.0665, GNorm = 7.9823, lr_0 = 1.0202e-04
Loss = 8.8600e-03, PNorm = 34.0699, GNorm = 10.6906, lr_0 = 1.0202e-04
Loss = 6.9359e-03, PNorm = 34.0723, GNorm = 11.0408, lr_0 = 1.0202e-04
Loss = 8.2959e-03, PNorm = 34.0753, GNorm = 15.0221, lr_0 = 1.0202e-04
Loss = 6.3613e-03, PNorm = 34.0789, GNorm = 2.8511, lr_0 = 1.0202e-04
Validation rmse logP = 1.072882
Validation R2 logP = 0.662762
Epoch 1
Train function
Loss = 7.2795e-03, PNorm = 34.0831, GNorm = 13.3237, lr_0 = 1.0202e-04
Loss = 5.7231e-03, PNorm = 34.0863, GNorm = 11.5603, lr_0 = 1.0202e-04
Loss = 6.1968e-03, PNorm = 34.0891, GNorm = 2.5603, lr_0 = 1.0202e-04
Loss = 5.9255e-03, PNorm = 34.0920, GNorm = 5.8651, lr_0 = 1.0202e-04
Loss = 5.6853e-03, PNorm = 34.0951, GNorm = 12.2037, lr_0 = 1.0202e-04
Loss = 6.3334e-03, PNorm = 34.0980, GNorm = 16.1343, lr_0 = 1.0202e-04
Loss = 5.9102e-03, PNorm = 34.1014, GNorm = 2.8133, lr_0 = 1.0202e-04
Loss = 5.9135e-03, PNorm = 34.1044, GNorm = 5.5456, lr_0 = 1.0202e-04
Loss = 6.2343e-03, PNorm = 34.1070, GNorm = 24.4747, lr_0 = 1.0202e-04
Loss = 6.4061e-03, PNorm = 34.1101, GNorm = 8.4209, lr_0 = 1.0202e-04
Loss = 5.9010e-03, PNorm = 34.1133, GNorm = 4.6929, lr_0 = 1.0202e-04
Loss = 5.8978e-03, PNorm = 34.1157, GNorm = 1.8397, lr_0 = 1.0202e-04
Loss = 4.8629e-03, PNorm = 34.1193, GNorm = 12.3852, lr_0 = 1.0202e-04
Loss = 5.2887e-03, PNorm = 34.1220, GNorm = 3.0351, lr_0 = 1.0202e-04
Loss = 5.6460e-03, PNorm = 34.1251, GNorm = 10.5021, lr_0 = 1.0202e-04
Loss = 5.0585e-03, PNorm = 34.1283, GNorm = 14.9942, lr_0 = 1.0202e-04
Loss = 5.2266e-03, PNorm = 34.1316, GNorm = 3.9659, lr_0 = 1.0202e-04
Loss = 5.1374e-03, PNorm = 34.1346, GNorm = 7.2599, lr_0 = 1.0202e-04
Loss = 4.2866e-03, PNorm = 34.1371, GNorm = 2.4246, lr_0 = 1.0202e-04
Loss = 5.0471e-03, PNorm = 34.1391, GNorm = 5.6410, lr_0 = 1.0202e-04
Loss = 6.4947e-03, PNorm = 34.1414, GNorm = 28.0426, lr_0 = 1.0202e-04
Loss = 5.4595e-03, PNorm = 34.1438, GNorm = 17.6084, lr_0 = 1.0202e-04
Validation rmse logP = 0.952799
Validation R2 logP = 0.734029
Epoch 2
Train function
Loss = 4.0591e-03, PNorm = 34.1465, GNorm = 13.4926, lr_0 = 1.0202e-04
Loss = 4.9461e-03, PNorm = 34.1483, GNorm = 4.3153, lr_0 = 1.0202e-04
Loss = 6.4834e-03, PNorm = 34.1514, GNorm = 29.8196, lr_0 = 1.0202e-04
Loss = 5.1567e-03, PNorm = 34.1536, GNorm = 24.0175, lr_0 = 1.0202e-04
Loss = 5.2143e-03, PNorm = 34.1559, GNorm = 21.5289, lr_0 = 1.0202e-04
Loss = 4.2826e-03, PNorm = 34.1586, GNorm = 12.5335, lr_0 = 1.0202e-04
Loss = 4.2552e-03, PNorm = 34.1610, GNorm = 13.6019, lr_0 = 1.0202e-04
Loss = 4.2537e-03, PNorm = 34.1627, GNorm = 5.7467, lr_0 = 1.0202e-04
Loss = 4.2979e-03, PNorm = 34.1655, GNorm = 13.7221, lr_0 = 1.0202e-04
Loss = 4.4376e-03, PNorm = 34.1680, GNorm = 5.1456, lr_0 = 1.0202e-04
Loss = 4.6663e-03, PNorm = 34.1706, GNorm = 7.2569, lr_0 = 1.0202e-04
Loss = 4.8437e-03, PNorm = 34.1735, GNorm = 5.3926, lr_0 = 1.0202e-04
Loss = 4.3787e-03, PNorm = 34.1757, GNorm = 6.9339, lr_0 = 1.0202e-04
Loss = 4.5440e-03, PNorm = 34.1789, GNorm = 9.1141, lr_0 = 1.0202e-04
Loss = 4.2564e-03, PNorm = 34.1817, GNorm = 9.2156, lr_0 = 1.0202e-04
Loss = 5.0423e-03, PNorm = 34.1844, GNorm = 4.5616, lr_0 = 1.0202e-04
Loss = 4.7976e-03, PNorm = 34.1875, GNorm = 19.3830, lr_0 = 1.0202e-04
Loss = 5.0343e-03, PNorm = 34.1903, GNorm = 20.0355, lr_0 = 1.0202e-04
Loss = 4.3390e-03, PNorm = 34.1936, GNorm = 11.6235, lr_0 = 1.0202e-04
Loss = 4.2202e-03, PNorm = 34.1969, GNorm = 4.4785, lr_0 = 1.0202e-04
Loss = 4.4324e-03, PNorm = 34.1993, GNorm = 17.3218, lr_0 = 1.0202e-04
Loss = 3.6087e-03, PNorm = 34.2018, GNorm = 3.5564, lr_0 = 1.0202e-04
Loss = 3.8527e-03, PNorm = 34.2034, GNorm = 6.2614, lr_0 = 1.0202e-04
Loss = 8.2009e-03, PNorm = 34.2036, GNorm = 13.2461, lr_0 = 1.0202e-04
Validation rmse logP = 0.797979
Validation R2 logP = 0.813441
Epoch 3
Train function
Loss = 3.7717e-03, PNorm = 34.2059, GNorm = 19.5343, lr_0 = 1.0202e-04
Loss = 3.2107e-03, PNorm = 34.2082, GNorm = 8.0051, lr_0 = 1.0202e-04
Loss = 3.7141e-03, PNorm = 34.2105, GNorm = 10.1286, lr_0 = 1.0202e-04
Loss = 3.8431e-03, PNorm = 34.2130, GNorm = 6.5624, lr_0 = 1.0202e-04
Loss = 3.7374e-03, PNorm = 34.2151, GNorm = 7.1734, lr_0 = 1.0202e-04
Loss = 3.5630e-03, PNorm = 34.2173, GNorm = 9.4605, lr_0 = 1.0202e-04
Loss = 3.7486e-03, PNorm = 34.2191, GNorm = 10.6165, lr_0 = 1.0202e-04
Loss = 3.7997e-03, PNorm = 34.2213, GNorm = 15.5627, lr_0 = 1.0202e-04
Loss = 4.4427e-03, PNorm = 34.2242, GNorm = 9.7345, lr_0 = 1.0202e-04
Loss = 3.9561e-03, PNorm = 34.2272, GNorm = 10.3794, lr_0 = 1.0202e-04
Loss = 3.5046e-03, PNorm = 34.2302, GNorm = 6.0206, lr_0 = 1.0202e-04
Loss = 3.5212e-03, PNorm = 34.2330, GNorm = 2.5651, lr_0 = 1.0202e-04
Loss = 3.7255e-03, PNorm = 34.2354, GNorm = 5.9512, lr_0 = 1.0202e-04
Loss = 3.9815e-03, PNorm = 34.2385, GNorm = 3.1020, lr_0 = 1.0202e-04
Loss = 3.2432e-03, PNorm = 34.2406, GNorm = 2.8622, lr_0 = 1.0202e-04
Loss = 3.6389e-03, PNorm = 34.2430, GNorm = 3.2545, lr_0 = 1.0202e-04
Loss = 3.2603e-03, PNorm = 34.2456, GNorm = 4.0075, lr_0 = 1.0202e-04
Loss = 3.1388e-03, PNorm = 34.2479, GNorm = 6.0379, lr_0 = 1.0202e-04
Loss = 3.0270e-03, PNorm = 34.2503, GNorm = 11.9728, lr_0 = 1.0202e-04
Loss = 3.4843e-03, PNorm = 34.2532, GNorm = 14.8658, lr_0 = 1.0202e-04
Loss = 3.8106e-03, PNorm = 34.2560, GNorm = 6.3226, lr_0 = 1.0202e-04
Loss = 3.8647e-03, PNorm = 34.2590, GNorm = 12.4843, lr_0 = 1.0202e-04
Validation rmse logP = 0.756336
Validation R2 logP = 0.832405
Epoch 4
Train function
Loss = 3.2865e-03, PNorm = 34.2618, GNorm = 7.3038, lr_0 = 1.0202e-04
Loss = 3.1658e-03, PNorm = 34.2641, GNorm = 7.3418, lr_0 = 1.0202e-04
Loss = 3.9188e-03, PNorm = 34.2664, GNorm = 10.2681, lr_0 = 1.0202e-04
Loss = 4.0255e-03, PNorm = 34.2695, GNorm = 4.8124, lr_0 = 1.0202e-04
Loss = 3.5399e-03, PNorm = 34.2724, GNorm = 9.8008, lr_0 = 1.0202e-04
Loss = 3.2681e-03, PNorm = 34.2760, GNorm = 22.9998, lr_0 = 1.0202e-04
Loss = 3.2963e-03, PNorm = 34.2782, GNorm = 16.3140, lr_0 = 1.0202e-04
Loss = 3.8480e-03, PNorm = 34.2812, GNorm = 2.8546, lr_0 = 1.0202e-04
Loss = 3.6048e-03, PNorm = 34.2837, GNorm = 4.5581, lr_0 = 1.0202e-04
Loss = 3.2755e-03, PNorm = 34.2857, GNorm = 12.1508, lr_0 = 1.0202e-04
Loss = 2.8672e-03, PNorm = 34.2872, GNorm = 7.1904, lr_0 = 1.0202e-04
Loss = 2.8840e-03, PNorm = 34.2893, GNorm = 2.7303, lr_0 = 1.0202e-04
Loss = 3.5341e-03, PNorm = 34.2917, GNorm = 6.9984, lr_0 = 1.0202e-04
Loss = 3.1694e-03, PNorm = 34.2939, GNorm = 12.7283, lr_0 = 1.0202e-04
Loss = 3.5548e-03, PNorm = 34.2968, GNorm = 2.2534, lr_0 = 1.0202e-04
Loss = 2.7982e-03, PNorm = 34.3002, GNorm = 9.7782, lr_0 = 1.0202e-04
Loss = 2.7344e-03, PNorm = 34.3030, GNorm = 5.0989, lr_0 = 1.0202e-04
Loss = 3.4206e-03, PNorm = 34.3053, GNorm = 9.7466, lr_0 = 1.0202e-04
Loss = 2.9429e-03, PNorm = 34.3078, GNorm = 22.8522, lr_0 = 1.0202e-04
Loss = 3.3368e-03, PNorm = 34.3097, GNorm = 9.7237, lr_0 = 1.0202e-04
Loss = 2.5483e-03, PNorm = 34.3117, GNorm = 2.9441, lr_0 = 1.0202e-04
Loss = 3.0391e-03, PNorm = 34.3132, GNorm = 14.6314, lr_0 = 1.0202e-04
Validation rmse logP = 0.697964
Validation R2 logP = 0.857276
Epoch 5
Train function
Loss = 3.1989e-03, PNorm = 34.3152, GNorm = 11.2701, lr_0 = 1.0202e-04
Loss = 2.7344e-03, PNorm = 34.3178, GNorm = 9.3287, lr_0 = 1.0202e-04
Loss = 2.6354e-03, PNorm = 34.3194, GNorm = 5.9615, lr_0 = 1.0202e-04
Loss = 2.9003e-03, PNorm = 34.3205, GNorm = 7.0320, lr_0 = 1.0202e-04
Loss = 3.3162e-03, PNorm = 34.3232, GNorm = 7.1071, lr_0 = 1.0202e-04
Loss = 3.0543e-03, PNorm = 34.3253, GNorm = 17.7850, lr_0 = 1.0202e-04
Loss = 3.2978e-03, PNorm = 34.3280, GNorm = 3.4564, lr_0 = 1.0202e-04
Loss = 2.2399e-03, PNorm = 34.3304, GNorm = 1.9615, lr_0 = 1.0202e-04
Loss = 3.0849e-03, PNorm = 34.3325, GNorm = 6.3568, lr_0 = 1.0202e-04
Loss = 3.2551e-03, PNorm = 34.3354, GNorm = 3.9055, lr_0 = 1.0202e-04
Loss = 2.6285e-03, PNorm = 34.3379, GNorm = 11.1965, lr_0 = 1.0202e-04
Loss = 3.1084e-03, PNorm = 34.3416, GNorm = 12.3188, lr_0 = 1.0202e-04
Loss = 2.9397e-03, PNorm = 34.3446, GNorm = 3.6968, lr_0 = 1.0202e-04
Loss = 3.0876e-03, PNorm = 34.3462, GNorm = 11.4447, lr_0 = 1.0202e-04
Loss = 3.3324e-03, PNorm = 34.3489, GNorm = 12.5428, lr_0 = 1.0202e-04
Loss = 2.5103e-03, PNorm = 34.3514, GNorm = 5.4814, lr_0 = 1.0202e-04
Loss = 3.0134e-03, PNorm = 34.3530, GNorm = 8.6215, lr_0 = 1.0202e-04
Loss = 2.7628e-03, PNorm = 34.3558, GNorm = 8.9114, lr_0 = 1.0202e-04
Loss = 2.7533e-03, PNorm = 34.3575, GNorm = 11.3383, lr_0 = 1.0202e-04
Loss = 3.1697e-03, PNorm = 34.3592, GNorm = 2.8043, lr_0 = 1.0202e-04
Loss = 3.1156e-03, PNorm = 34.3614, GNorm = 12.7698, lr_0 = 1.0202e-04
Loss = 2.6227e-03, PNorm = 34.3635, GNorm = 5.3330, lr_0 = 1.0202e-04
Loss = 2.8897e-03, PNorm = 34.3649, GNorm = 15.4464, lr_0 = 1.0202e-04
Validation rmse logP = 0.682541
Validation R2 logP = 0.863514
Epoch 6
Train function
Loss = 2.9852e-03, PNorm = 34.3661, GNorm = 10.0019, lr_0 = 1.0202e-04
Loss = 3.0579e-03, PNorm = 34.3680, GNorm = 14.2912, lr_0 = 1.0202e-04
Loss = 3.0250e-03, PNorm = 34.3704, GNorm = 8.0587, lr_0 = 1.0202e-04
Loss = 3.2706e-03, PNorm = 34.3731, GNorm = 14.6280, lr_0 = 1.0202e-04
Loss = 2.7077e-03, PNorm = 34.3753, GNorm = 3.4745, lr_0 = 1.0202e-04
Loss = 3.4054e-03, PNorm = 34.3774, GNorm = 19.4799, lr_0 = 1.0202e-04
Loss = 3.3471e-03, PNorm = 34.3799, GNorm = 21.2980, lr_0 = 1.0202e-04
Loss = 3.3071e-03, PNorm = 34.3820, GNorm = 9.4480, lr_0 = 1.0202e-04
Loss = 3.2846e-03, PNorm = 34.3847, GNorm = 7.5348, lr_0 = 1.0202e-04
Loss = 2.4097e-03, PNorm = 34.3866, GNorm = 5.4242, lr_0 = 1.0202e-04
Loss = 3.4583e-03, PNorm = 34.3888, GNorm = 7.5994, lr_0 = 1.0202e-04
Loss = 3.3416e-03, PNorm = 34.3906, GNorm = 9.8175, lr_0 = 1.0202e-04
Loss = 2.7860e-03, PNorm = 34.3943, GNorm = 1.5419, lr_0 = 1.0202e-04
Loss = 2.5718e-03, PNorm = 34.3971, GNorm = 2.5425, lr_0 = 1.0202e-04
Loss = 3.1053e-03, PNorm = 34.3999, GNorm = 5.1989, lr_0 = 1.0202e-04
Loss = 2.7548e-03, PNorm = 34.4021, GNorm = 9.3951, lr_0 = 1.0202e-04
Loss = 2.6500e-03, PNorm = 34.4040, GNorm = 5.1972, lr_0 = 1.0202e-04
Loss = 3.2142e-03, PNorm = 34.4064, GNorm = 19.7762, lr_0 = 1.0202e-04
Loss = 2.3738e-03, PNorm = 34.4091, GNorm = 2.0508, lr_0 = 1.0202e-04
Loss = 2.5479e-03, PNorm = 34.4109, GNorm = 8.4160, lr_0 = 1.0202e-04
Loss = 3.0408e-03, PNorm = 34.4123, GNorm = 11.2221, lr_0 = 1.0202e-04
Loss = 2.7426e-03, PNorm = 34.4139, GNorm = 16.9465, lr_0 = 1.0202e-04
Validation rmse logP = 0.691108
Validation R2 logP = 0.860065
Epoch 7
Train function
Loss = 2.2515e-03, PNorm = 34.4155, GNorm = 5.9209, lr_0 = 1.0202e-04
Loss = 2.6032e-03, PNorm = 34.4179, GNorm = 6.8838, lr_0 = 1.0202e-04
Loss = 2.6855e-03, PNorm = 34.4203, GNorm = 2.1573, lr_0 = 1.0202e-04
Loss = 2.7388e-03, PNorm = 34.4224, GNorm = 2.8488, lr_0 = 1.0202e-04
Loss = 2.6798e-03, PNorm = 34.4246, GNorm = 21.6886, lr_0 = 1.0202e-04
Loss = 2.7997e-03, PNorm = 34.4268, GNorm = 6.3319, lr_0 = 1.0202e-04
Loss = 2.5188e-03, PNorm = 34.4292, GNorm = 11.0373, lr_0 = 1.0202e-04
Loss = 1.9722e-03, PNorm = 34.4319, GNorm = 9.4748, lr_0 = 1.0202e-04
Loss = 2.4370e-03, PNorm = 34.4343, GNorm = 8.7261, lr_0 = 1.0202e-04
Loss = 3.2064e-03, PNorm = 34.4351, GNorm = 6.8155, lr_0 = 1.0202e-04
Loss = 2.8827e-03, PNorm = 34.4367, GNorm = 5.6518, lr_0 = 1.0202e-04
Loss = 2.2967e-03, PNorm = 34.4391, GNorm = 5.4470, lr_0 = 1.0202e-04
Loss = 2.4570e-03, PNorm = 34.4411, GNorm = 7.0090, lr_0 = 1.0202e-04
Loss = 2.6633e-03, PNorm = 34.4436, GNorm = 7.4419, lr_0 = 1.0202e-04
Loss = 2.6556e-03, PNorm = 34.4464, GNorm = 2.4037, lr_0 = 1.0202e-04
Loss = 2.1511e-03, PNorm = 34.4486, GNorm = 5.6395, lr_0 = 1.0202e-04
Loss = 2.3855e-03, PNorm = 34.4513, GNorm = 6.4019, lr_0 = 1.0202e-04
Loss = 2.3963e-03, PNorm = 34.4546, GNorm = 3.9489, lr_0 = 1.0202e-04
Loss = 2.6873e-03, PNorm = 34.4567, GNorm = 3.7251, lr_0 = 1.0202e-04
Loss = 2.6219e-03, PNorm = 34.4588, GNorm = 15.6698, lr_0 = 1.0202e-04
Loss = 2.3101e-03, PNorm = 34.4604, GNorm = 7.2156, lr_0 = 1.0202e-04
Loss = 2.4426e-03, PNorm = 34.4614, GNorm = 8.4564, lr_0 = 1.0202e-04
Validation rmse logP = 0.651569
Validation R2 logP = 0.875619
Epoch 8
Train function
Loss = 3.1666e-03, PNorm = 34.4620, GNorm = 4.9646, lr_0 = 1.0202e-04
Loss = 3.0805e-03, PNorm = 34.4639, GNorm = 1.8045, lr_0 = 1.0202e-04
Loss = 2.1892e-03, PNorm = 34.4661, GNorm = 9.9123, lr_0 = 1.0202e-04
Loss = 2.5836e-03, PNorm = 34.4683, GNorm = 5.2240, lr_0 = 1.0202e-04
Loss = 3.1116e-03, PNorm = 34.4701, GNorm = 7.2207, lr_0 = 1.0202e-04
Loss = 3.0615e-03, PNorm = 34.4715, GNorm = 7.3988, lr_0 = 1.0202e-04
Loss = 2.9343e-03, PNorm = 34.4738, GNorm = 5.3676, lr_0 = 1.0202e-04
Loss = 2.6004e-03, PNorm = 34.4758, GNorm = 6.9349, lr_0 = 1.0202e-04
Loss = 2.3206e-03, PNorm = 34.4776, GNorm = 14.7550, lr_0 = 1.0202e-04
Loss = 2.4096e-03, PNorm = 34.4794, GNorm = 8.5342, lr_0 = 1.0202e-04
Loss = 2.5810e-03, PNorm = 34.4809, GNorm = 2.4157, lr_0 = 1.0202e-04
Loss = 2.6923e-03, PNorm = 34.4830, GNorm = 1.9639, lr_0 = 1.0202e-04
Loss = 2.4860e-03, PNorm = 34.4850, GNorm = 14.5644, lr_0 = 1.0202e-04
Loss = 2.2741e-03, PNorm = 34.4868, GNorm = 9.1844, lr_0 = 1.0202e-04
Loss = 2.2137e-03, PNorm = 34.4888, GNorm = 9.2757, lr_0 = 1.0202e-04
Loss = 2.4170e-03, PNorm = 34.4911, GNorm = 1.7999, lr_0 = 1.0202e-04
Loss = 2.4016e-03, PNorm = 34.4932, GNorm = 4.8762, lr_0 = 1.0202e-04
Loss = 2.4143e-03, PNorm = 34.4958, GNorm = 12.0987, lr_0 = 1.0202e-04
Loss = 2.1553e-03, PNorm = 34.4977, GNorm = 4.5991, lr_0 = 1.0202e-04
Loss = 2.0353e-03, PNorm = 34.5003, GNorm = 6.1554, lr_0 = 1.0202e-04
Loss = 2.1710e-03, PNorm = 34.5028, GNorm = 7.9403, lr_0 = 1.0202e-04
Loss = 2.0286e-03, PNorm = 34.5042, GNorm = 12.7519, lr_0 = 1.0202e-04
Loss = 2.6676e-03, PNorm = 34.5059, GNorm = 2.6337, lr_0 = 1.0202e-04
Validation rmse logP = 0.635728
Validation R2 logP = 0.881594
Epoch 9
Train function
Loss = 1.9912e-03, PNorm = 34.5075, GNorm = 10.1412, lr_0 = 1.0202e-04
Loss = 1.8957e-03, PNorm = 34.5091, GNorm = 6.1231, lr_0 = 1.0202e-04
Loss = 2.4864e-03, PNorm = 34.5112, GNorm = 5.7706, lr_0 = 1.0202e-04
Loss = 2.3700e-03, PNorm = 34.5138, GNorm = 6.8004, lr_0 = 1.0202e-04
Loss = 2.3631e-03, PNorm = 34.5159, GNorm = 4.3818, lr_0 = 1.0202e-04
Loss = 2.3281e-03, PNorm = 34.5182, GNorm = 6.5017, lr_0 = 1.0202e-04
Loss = 2.1021e-03, PNorm = 34.5206, GNorm = 13.1937, lr_0 = 1.0202e-04
Loss = 2.3028e-03, PNorm = 34.5229, GNorm = 3.3260, lr_0 = 1.0202e-04
Loss = 2.4047e-03, PNorm = 34.5250, GNorm = 4.0315, lr_0 = 1.0202e-04
Loss = 2.0701e-03, PNorm = 34.5262, GNorm = 1.9092, lr_0 = 1.0202e-04
Loss = 2.1181e-03, PNorm = 34.5277, GNorm = 9.0149, lr_0 = 1.0202e-04
Loss = 2.6042e-03, PNorm = 34.5289, GNorm = 21.7067, lr_0 = 1.0202e-04
Loss = 2.6440e-03, PNorm = 34.5308, GNorm = 24.8861, lr_0 = 1.0202e-04
Loss = 2.3531e-03, PNorm = 34.5323, GNorm = 21.0915, lr_0 = 1.0202e-04
Loss = 2.7788e-03, PNorm = 34.5349, GNorm = 7.7533, lr_0 = 1.0202e-04
Loss = 2.3434e-03, PNorm = 34.5367, GNorm = 4.1132, lr_0 = 1.0202e-04
Loss = 2.9164e-03, PNorm = 34.5384, GNorm = 6.7316, lr_0 = 1.0202e-04
Loss = 2.2281e-03, PNorm = 34.5407, GNorm = 1.8412, lr_0 = 1.0202e-04
Loss = 1.9231e-03, PNorm = 34.5427, GNorm = 4.1811, lr_0 = 1.0202e-04
Loss = 2.2444e-03, PNorm = 34.5452, GNorm = 13.2182, lr_0 = 1.0202e-04
Loss = 2.9547e-03, PNorm = 34.5474, GNorm = 6.9509, lr_0 = 1.0202e-04
Loss = 1.9817e-03, PNorm = 34.5492, GNorm = 9.1436, lr_0 = 1.0202e-04
Validation rmse logP = 0.698034
Validation R2 logP = 0.857247
Epoch 10
Train function
Loss = 2.2539e-03, PNorm = 34.5509, GNorm = 13.9033, lr_0 = 1.0202e-04
Loss = 2.6022e-03, PNorm = 34.5529, GNorm = 21.8443, lr_0 = 1.0202e-04
Loss = 2.4055e-03, PNorm = 34.5543, GNorm = 15.4362, lr_0 = 1.0202e-04
Loss = 2.3282e-03, PNorm = 34.5562, GNorm = 8.5713, lr_0 = 1.0202e-04
Loss = 2.2453e-03, PNorm = 34.5583, GNorm = 2.8780, lr_0 = 1.0202e-04
Loss = 1.9133e-03, PNorm = 34.5599, GNorm = 7.8898, lr_0 = 1.0202e-04
Loss = 1.9005e-03, PNorm = 34.5616, GNorm = 2.7575, lr_0 = 1.0202e-04
Loss = 2.0195e-03, PNorm = 34.5630, GNorm = 3.6265, lr_0 = 1.0202e-04
Loss = 2.3060e-03, PNorm = 34.5646, GNorm = 8.5349, lr_0 = 1.0202e-04
Loss = 1.9424e-03, PNorm = 34.5667, GNorm = 3.6374, lr_0 = 1.0202e-04
Loss = 2.1162e-03, PNorm = 34.5687, GNorm = 8.2113, lr_0 = 1.0202e-04
Loss = 2.0303e-03, PNorm = 34.5708, GNorm = 4.8846, lr_0 = 1.0202e-04
Loss = 2.1683e-03, PNorm = 34.5732, GNorm = 5.8664, lr_0 = 1.0202e-04
Loss = 2.2538e-03, PNorm = 34.5749, GNorm = 2.5460, lr_0 = 1.0202e-04
Loss = 2.3971e-03, PNorm = 34.5761, GNorm = 15.1854, lr_0 = 1.0202e-04
Loss = 2.0572e-03, PNorm = 34.5774, GNorm = 2.7524, lr_0 = 1.0202e-04
Loss = 2.0556e-03, PNorm = 34.5788, GNorm = 15.9419, lr_0 = 1.0202e-04
Loss = 2.0441e-03, PNorm = 34.5808, GNorm = 10.5023, lr_0 = 1.0202e-04
Loss = 1.8072e-03, PNorm = 34.5830, GNorm = 6.1022, lr_0 = 1.0202e-04
Loss = 1.9734e-03, PNorm = 34.5853, GNorm = 6.2333, lr_0 = 1.0202e-04
Loss = 1.9241e-03, PNorm = 34.5867, GNorm = 2.2894, lr_0 = 1.0202e-04
Loss = 1.9727e-03, PNorm = 34.5884, GNorm = 2.0201, lr_0 = 1.0202e-04
Validation rmse logP = 0.648227
Validation R2 logP = 0.876892
Epoch 11
Train function
Loss = 2.7758e-03, PNorm = 34.5913, GNorm = 10.0083, lr_0 = 1.0202e-04
Loss = 1.9846e-03, PNorm = 34.5929, GNorm = 3.0146, lr_0 = 1.0202e-04
Loss = 2.1518e-03, PNorm = 34.5953, GNorm = 9.4307, lr_0 = 1.0202e-04
Loss = 1.8596e-03, PNorm = 34.5974, GNorm = 8.7576, lr_0 = 1.0202e-04
Loss = 2.0212e-03, PNorm = 34.5993, GNorm = 10.7892, lr_0 = 1.0202e-04
Loss = 2.3654e-03, PNorm = 34.6008, GNorm = 3.4196, lr_0 = 1.0202e-04
Loss = 1.8296e-03, PNorm = 34.6032, GNorm = 11.7694, lr_0 = 1.0202e-04
Loss = 2.1366e-03, PNorm = 34.6052, GNorm = 14.4856, lr_0 = 1.0202e-04
Loss = 2.3706e-03, PNorm = 34.6073, GNorm = 4.6136, lr_0 = 1.0202e-04
Loss = 2.5413e-03, PNorm = 34.6092, GNorm = 4.2518, lr_0 = 1.0202e-04
Loss = 1.6437e-03, PNorm = 34.6109, GNorm = 11.6936, lr_0 = 1.0202e-04
Loss = 2.0205e-03, PNorm = 34.6127, GNorm = 9.1068, lr_0 = 1.0202e-04
Loss = 2.6145e-03, PNorm = 34.6135, GNorm = 5.2516, lr_0 = 1.0202e-04
Loss = 2.2495e-03, PNorm = 34.6151, GNorm = 11.9134, lr_0 = 1.0202e-04
Loss = 1.6727e-03, PNorm = 34.6162, GNorm = 7.2560, lr_0 = 1.0202e-04
Loss = 2.0825e-03, PNorm = 34.6188, GNorm = 2.7044, lr_0 = 1.0202e-04
Loss = 2.5131e-03, PNorm = 34.6199, GNorm = 5.1918, lr_0 = 1.0202e-04
Loss = 2.3716e-03, PNorm = 34.6215, GNorm = 2.3169, lr_0 = 1.0202e-04
Loss = 2.0519e-03, PNorm = 34.6233, GNorm = 3.5205, lr_0 = 1.0202e-04
Loss = 2.0851e-03, PNorm = 34.6253, GNorm = 2.0271, lr_0 = 1.0202e-04
Loss = 1.9647e-03, PNorm = 34.6272, GNorm = 7.8722, lr_0 = 1.0202e-04
Loss = 1.8638e-03, PNorm = 34.6287, GNorm = 14.6014, lr_0 = 1.0202e-04
Loss = 2.3684e-03, PNorm = 34.6315, GNorm = 11.7314, lr_0 = 1.0202e-04
Validation rmse logP = 0.668902
Validation R2 logP = 0.868913
Epoch 12
Train function
Loss = 2.2304e-03, PNorm = 34.6333, GNorm = 10.8768, lr_0 = 1.0202e-04
Loss = 2.1407e-03, PNorm = 34.6361, GNorm = 11.8890, lr_0 = 1.0202e-04
Loss = 1.7447e-03, PNorm = 34.6381, GNorm = 3.7508, lr_0 = 1.0202e-04
Loss = 2.1368e-03, PNorm = 34.6406, GNorm = 2.6977, lr_0 = 1.0202e-04
Loss = 2.3562e-03, PNorm = 34.6430, GNorm = 11.1073, lr_0 = 1.0202e-04
Loss = 1.8079e-03, PNorm = 34.6444, GNorm = 2.2668, lr_0 = 1.0202e-04
Loss = 1.8601e-03, PNorm = 34.6466, GNorm = 2.4574, lr_0 = 1.0202e-04
Loss = 2.2749e-03, PNorm = 34.6483, GNorm = 3.6925, lr_0 = 1.0202e-04
Loss = 2.0241e-03, PNorm = 34.6503, GNorm = 4.8700, lr_0 = 1.0202e-04
Loss = 2.1762e-03, PNorm = 34.6520, GNorm = 18.2637, lr_0 = 1.0202e-04
Loss = 1.8496e-03, PNorm = 34.6533, GNorm = 8.9301, lr_0 = 1.0202e-04
Loss = 2.2133e-03, PNorm = 34.6553, GNorm = 3.1932, lr_0 = 1.0202e-04
Loss = 1.7783e-03, PNorm = 34.6577, GNorm = 2.4422, lr_0 = 1.0202e-04
Loss = 1.8751e-03, PNorm = 34.6599, GNorm = 7.4344, lr_0 = 1.0202e-04
Loss = 1.7302e-03, PNorm = 34.6614, GNorm = 8.5270, lr_0 = 1.0202e-04
Loss = 2.1009e-03, PNorm = 34.6627, GNorm = 2.5352, lr_0 = 1.0202e-04
Loss = 2.0782e-03, PNorm = 34.6645, GNorm = 5.4619, lr_0 = 1.0202e-04
Loss = 1.8450e-03, PNorm = 34.6660, GNorm = 2.0707, lr_0 = 1.0202e-04
Loss = 1.8031e-03, PNorm = 34.6682, GNorm = 3.1014, lr_0 = 1.0202e-04
Loss = 2.2399e-03, PNorm = 34.6702, GNorm = 12.0752, lr_0 = 1.0202e-04
Loss = 2.1646e-03, PNorm = 34.6717, GNorm = 3.2188, lr_0 = 1.0202e-04
Loss = 1.8274e-03, PNorm = 34.6731, GNorm = 6.6491, lr_0 = 1.0202e-04
Validation rmse logP = 0.683463
Validation R2 logP = 0.863145
Epoch 13
Train function
Loss = 2.5113e-03, PNorm = 34.6747, GNorm = 17.8675, lr_0 = 1.0202e-04
Loss = 2.1347e-03, PNorm = 34.6767, GNorm = 8.8378, lr_0 = 1.0202e-04
Loss = 2.3977e-03, PNorm = 34.6792, GNorm = 13.1585, lr_0 = 1.0202e-04
Loss = 1.6043e-03, PNorm = 34.6815, GNorm = 2.4968, lr_0 = 1.0202e-04
Loss = 1.6647e-03, PNorm = 34.6834, GNorm = 5.4518, lr_0 = 1.0202e-04
Loss = 1.6781e-03, PNorm = 34.6848, GNorm = 2.2426, lr_0 = 1.0202e-04
Loss = 1.7890e-03, PNorm = 34.6867, GNorm = 3.0335, lr_0 = 1.0202e-04
Loss = 1.9869e-03, PNorm = 34.6887, GNorm = 7.0111, lr_0 = 1.0202e-04
Loss = 1.6098e-03, PNorm = 34.6902, GNorm = 4.5938, lr_0 = 1.0202e-04
Loss = 2.2426e-03, PNorm = 34.6918, GNorm = 2.4871, lr_0 = 1.0202e-04
Loss = 1.5574e-03, PNorm = 34.6934, GNorm = 6.2523, lr_0 = 1.0202e-04
Loss = 1.7738e-03, PNorm = 34.6954, GNorm = 14.2954, lr_0 = 1.0202e-04
Loss = 2.0543e-03, PNorm = 34.6968, GNorm = 6.4621, lr_0 = 1.0202e-04
Loss = 1.8122e-03, PNorm = 34.6992, GNorm = 2.5775, lr_0 = 1.0202e-04
Loss = 1.8410e-03, PNorm = 34.7013, GNorm = 2.2227, lr_0 = 1.0202e-04
Loss = 2.0147e-03, PNorm = 34.7027, GNorm = 18.1662, lr_0 = 1.0202e-04
Loss = 2.1624e-03, PNorm = 34.7041, GNorm = 16.5033, lr_0 = 1.0202e-04
Loss = 2.3295e-03, PNorm = 34.7057, GNorm = 7.4862, lr_0 = 1.0202e-04
Loss = 1.9151e-03, PNorm = 34.7075, GNorm = 7.0291, lr_0 = 1.0202e-04
Loss = 2.3262e-03, PNorm = 34.7094, GNorm = 4.2976, lr_0 = 1.0202e-04
Loss = 1.9630e-03, PNorm = 34.7121, GNorm = 4.5897, lr_0 = 1.0202e-04
Loss = 1.7967e-03, PNorm = 34.7144, GNorm = 2.2145, lr_0 = 1.0202e-04
Validation rmse logP = 0.604799
Validation R2 logP = 0.892835
Epoch 14
Train function
Loss = 1.4707e-03, PNorm = 34.7159, GNorm = 4.1474, lr_0 = 1.0202e-04
Loss = 2.1726e-03, PNorm = 34.7184, GNorm = 7.6761, lr_0 = 1.0202e-04
Loss = 1.8393e-03, PNorm = 34.7211, GNorm = 4.0447, lr_0 = 1.0202e-04
Loss = 1.9051e-03, PNorm = 34.7237, GNorm = 10.3174, lr_0 = 1.0202e-04
Loss = 2.2780e-03, PNorm = 34.7258, GNorm = 6.7663, lr_0 = 1.0202e-04
Loss = 1.9445e-03, PNorm = 34.7272, GNorm = 15.8815, lr_0 = 1.0202e-04
Loss = 1.8845e-03, PNorm = 34.7289, GNorm = 8.0203, lr_0 = 1.0202e-04
Loss = 1.4340e-03, PNorm = 34.7302, GNorm = 8.5415, lr_0 = 1.0202e-04
Loss = 1.7589e-03, PNorm = 34.7312, GNorm = 5.1615, lr_0 = 1.0202e-04
Loss = 1.8304e-03, PNorm = 34.7328, GNorm = 14.4622, lr_0 = 1.0202e-04
Loss = 2.1924e-03, PNorm = 34.7345, GNorm = 10.8440, lr_0 = 1.0202e-04
Loss = 2.1751e-03, PNorm = 34.7358, GNorm = 7.6006, lr_0 = 1.0202e-04
Loss = 1.5570e-03, PNorm = 34.7377, GNorm = 6.0366, lr_0 = 1.0202e-04
Loss = 2.2767e-03, PNorm = 34.7402, GNorm = 7.9395, lr_0 = 1.0202e-04
Loss = 1.7418e-03, PNorm = 34.7433, GNorm = 8.8371, lr_0 = 1.0202e-04
Loss = 1.4400e-03, PNorm = 34.7446, GNorm = 3.2600, lr_0 = 1.0202e-04
Loss = 1.8967e-03, PNorm = 34.7460, GNorm = 4.4806, lr_0 = 1.0202e-04
Loss = 2.2718e-03, PNorm = 34.7482, GNorm = 11.6909, lr_0 = 1.0202e-04
Loss = 2.0914e-03, PNorm = 34.7499, GNorm = 3.9399, lr_0 = 1.0202e-04
Loss = 1.6264e-03, PNorm = 34.7522, GNorm = 3.1621, lr_0 = 1.0202e-04
Loss = 1.6495e-03, PNorm = 34.7534, GNorm = 15.5212, lr_0 = 1.0202e-04
Loss = 2.0572e-03, PNorm = 34.7549, GNorm = 14.0834, lr_0 = 1.0202e-04
Loss = 2.4299e-03, PNorm = 34.7563, GNorm = 21.3157, lr_0 = 1.0202e-04
Validation rmse logP = 0.728515
Validation R2 logP = 0.844508
Epoch 15
Train function
Loss = 2.2787e-03, PNorm = 34.7586, GNorm = 2.7803, lr_0 = 1.0202e-04
Loss = 2.4307e-03, PNorm = 34.7610, GNorm = 8.9113, lr_0 = 1.0202e-04
Loss = 1.7426e-03, PNorm = 34.7622, GNorm = 3.3662, lr_0 = 1.0202e-04
Loss = 1.4560e-03, PNorm = 34.7635, GNorm = 3.0934, lr_0 = 1.0202e-04
Loss = 1.7517e-03, PNorm = 34.7656, GNorm = 2.7319, lr_0 = 1.0202e-04
Loss = 1.9035e-03, PNorm = 34.7676, GNorm = 5.3989, lr_0 = 1.0202e-04
Loss = 1.9358e-03, PNorm = 34.7701, GNorm = 1.9884, lr_0 = 1.0202e-04
Loss = 1.7012e-03, PNorm = 34.7727, GNorm = 16.1676, lr_0 = 1.0202e-04
Loss = 1.7995e-03, PNorm = 34.7753, GNorm = 3.8468, lr_0 = 1.0202e-04
Loss = 1.9722e-03, PNorm = 34.7785, GNorm = 7.0851, lr_0 = 1.0202e-04
Loss = 1.9690e-03, PNorm = 34.7799, GNorm = 10.4136, lr_0 = 1.0202e-04
Loss = 2.0345e-03, PNorm = 34.7822, GNorm = 11.4839, lr_0 = 1.0202e-04
Loss = 1.9095e-03, PNorm = 34.7835, GNorm = 3.2823, lr_0 = 1.0202e-04
Loss = 2.0718e-03, PNorm = 34.7861, GNorm = 5.2363, lr_0 = 1.0202e-04
Loss = 1.7039e-03, PNorm = 34.7873, GNorm = 5.5315, lr_0 = 1.0202e-04
Loss = 1.6596e-03, PNorm = 34.7892, GNorm = 6.6152, lr_0 = 1.0202e-04
Loss = 1.8724e-03, PNorm = 34.7908, GNorm = 2.1654, lr_0 = 1.0202e-04
Loss = 1.8889e-03, PNorm = 34.7925, GNorm = 9.7988, lr_0 = 1.0202e-04
Loss = 1.7867e-03, PNorm = 34.7941, GNorm = 3.6947, lr_0 = 1.0202e-04
Loss = 1.9304e-03, PNorm = 34.7958, GNorm = 4.3770, lr_0 = 1.0202e-04
Loss = 1.8656e-03, PNorm = 34.7975, GNorm = 8.0428, lr_0 = 1.0202e-04
Loss = 2.3132e-03, PNorm = 34.7993, GNorm = 3.6183, lr_0 = 1.0202e-04
Validation rmse logP = 0.589096
Validation R2 logP = 0.898327
Epoch 16
Train function
Loss = 1.9962e-03, PNorm = 34.8010, GNorm = 8.3367, lr_0 = 1.0202e-04
Loss = 1.6306e-03, PNorm = 34.8026, GNorm = 10.5656, lr_0 = 1.0202e-04
Loss = 1.8341e-03, PNorm = 34.8052, GNorm = 12.0174, lr_0 = 1.0202e-04
Loss = 1.8875e-03, PNorm = 34.8077, GNorm = 9.4188, lr_0 = 1.0202e-04
Loss = 1.7984e-03, PNorm = 34.8094, GNorm = 2.8301, lr_0 = 1.0202e-04
Loss = 1.3605e-03, PNorm = 34.8105, GNorm = 1.9936, lr_0 = 1.0202e-04
Loss = 1.6952e-03, PNorm = 34.8128, GNorm = 2.5000, lr_0 = 1.0202e-04
Loss = 1.8834e-03, PNorm = 34.8155, GNorm = 9.4729, lr_0 = 1.0202e-04
Loss = 2.0716e-03, PNorm = 34.8177, GNorm = 2.4743, lr_0 = 1.0202e-04
Loss = 1.3485e-03, PNorm = 34.8205, GNorm = 1.0776, lr_0 = 1.0202e-04
Loss = 1.5885e-03, PNorm = 34.8221, GNorm = 5.8863, lr_0 = 1.0202e-04
Loss = 1.5822e-03, PNorm = 34.8236, GNorm = 1.6773, lr_0 = 1.0202e-04
Loss = 1.5756e-03, PNorm = 34.8246, GNorm = 3.3846, lr_0 = 1.0202e-04
Loss = 1.5987e-03, PNorm = 34.8260, GNorm = 5.1443, lr_0 = 1.0202e-04
Loss = 1.5553e-03, PNorm = 34.8279, GNorm = 8.5947, lr_0 = 1.0202e-04
Loss = 1.5886e-03, PNorm = 34.8301, GNorm = 3.2062, lr_0 = 1.0202e-04
Loss = 1.4994e-03, PNorm = 34.8321, GNorm = 2.2368, lr_0 = 1.0202e-04
Loss = 1.9492e-03, PNorm = 34.8345, GNorm = 15.3372, lr_0 = 1.0202e-04
Loss = 2.0504e-03, PNorm = 34.8358, GNorm = 12.6934, lr_0 = 1.0202e-04
Loss = 1.6622e-03, PNorm = 34.8380, GNorm = 9.0972, lr_0 = 1.0202e-04
Loss = 2.1565e-03, PNorm = 34.8399, GNorm = 5.9624, lr_0 = 1.0202e-04
Loss = 2.1232e-03, PNorm = 34.8418, GNorm = 2.7836, lr_0 = 1.0202e-04
Loss = 2.4055e-03, PNorm = 34.8437, GNorm = 13.6814, lr_0 = 1.0202e-04
Validation rmse logP = 0.561454
Validation R2 logP = 0.907645
Epoch 17
Train function
Loss = 1.9327e-03, PNorm = 34.8462, GNorm = 8.3127, lr_0 = 1.0202e-04
Loss = 1.5447e-03, PNorm = 34.8480, GNorm = 9.7930, lr_0 = 1.0202e-04
Loss = 1.7489e-03, PNorm = 34.8496, GNorm = 2.8745, lr_0 = 1.0202e-04
Loss = 1.4151e-03, PNorm = 34.8511, GNorm = 1.5820, lr_0 = 1.0202e-04
Loss = 1.8789e-03, PNorm = 34.8531, GNorm = 3.8713, lr_0 = 1.0202e-04
Loss = 1.6267e-03, PNorm = 34.8552, GNorm = 5.5371, lr_0 = 1.0202e-04
Loss = 1.3344e-03, PNorm = 34.8576, GNorm = 1.8693, lr_0 = 1.0202e-04
Loss = 1.4471e-03, PNorm = 34.8593, GNorm = 3.7551, lr_0 = 1.0202e-04
Loss = 1.7709e-03, PNorm = 34.8613, GNorm = 10.4332, lr_0 = 1.0202e-04
Loss = 1.9135e-03, PNorm = 34.8630, GNorm = 2.9872, lr_0 = 1.0202e-04
Loss = 1.9064e-03, PNorm = 34.8648, GNorm = 6.6241, lr_0 = 1.0202e-04
Loss = 1.4685e-03, PNorm = 34.8663, GNorm = 6.6782, lr_0 = 1.0202e-04
Loss = 1.7179e-03, PNorm = 34.8688, GNorm = 13.9869, lr_0 = 1.0202e-04
Loss = 1.9514e-03, PNorm = 34.8709, GNorm = 8.7660, lr_0 = 1.0202e-04
Loss = 1.8685e-03, PNorm = 34.8731, GNorm = 14.0009, lr_0 = 1.0202e-04
Loss = 2.2895e-03, PNorm = 34.8743, GNorm = 21.7919, lr_0 = 1.0202e-04
Loss = 1.9258e-03, PNorm = 34.8765, GNorm = 2.2524, lr_0 = 1.0202e-04
Loss = 1.8096e-03, PNorm = 34.8781, GNorm = 2.4477, lr_0 = 1.0202e-04
Loss = 2.0028e-03, PNorm = 34.8797, GNorm = 13.6166, lr_0 = 1.0202e-04
Loss = 2.1884e-03, PNorm = 34.8820, GNorm = 7.1715, lr_0 = 1.0202e-04
Loss = 1.7238e-03, PNorm = 34.8837, GNorm = 6.2272, lr_0 = 1.0202e-04
Loss = 1.8742e-03, PNorm = 34.8855, GNorm = 2.8046, lr_0 = 1.0202e-04
Validation rmse logP = 0.625071
Validation R2 logP = 0.885530
Epoch 18
Train function
Loss = 1.8544e-03, PNorm = 34.8872, GNorm = 8.8633, lr_0 = 1.0202e-04
Loss = 1.5808e-03, PNorm = 34.8894, GNorm = 3.5671, lr_0 = 1.0202e-04
Loss = 1.4607e-03, PNorm = 34.8914, GNorm = 8.9149, lr_0 = 1.0202e-04
Loss = 1.6615e-03, PNorm = 34.8934, GNorm = 7.7711, lr_0 = 1.0202e-04
Loss = 1.4797e-03, PNorm = 34.8953, GNorm = 5.5752, lr_0 = 1.0202e-04
Loss = 1.4262e-03, PNorm = 34.8978, GNorm = 11.7597, lr_0 = 1.0202e-04
Loss = 1.4961e-03, PNorm = 34.8996, GNorm = 2.0430, lr_0 = 1.0202e-04
Loss = 1.5541e-03, PNorm = 34.9017, GNorm = 7.2057, lr_0 = 1.0202e-04
Loss = 1.9396e-03, PNorm = 34.9036, GNorm = 6.0754, lr_0 = 1.0202e-04
Loss = 2.0845e-03, PNorm = 34.9051, GNorm = 5.6046, lr_0 = 1.0202e-04
Loss = 1.9415e-03, PNorm = 34.9055, GNorm = 16.6493, lr_0 = 1.0202e-04
Loss = 1.6220e-03, PNorm = 34.9077, GNorm = 10.4097, lr_0 = 1.0202e-04
Loss = 1.6303e-03, PNorm = 34.9090, GNorm = 2.4563, lr_0 = 1.0202e-04
Loss = 1.7342e-03, PNorm = 34.9106, GNorm = 12.7126, lr_0 = 1.0202e-04
Loss = 1.8821e-03, PNorm = 34.9132, GNorm = 3.1851, lr_0 = 1.0202e-04
Loss = 1.5927e-03, PNorm = 34.9161, GNorm = 4.0352, lr_0 = 1.0202e-04
Loss = 1.7162e-03, PNorm = 34.9179, GNorm = 13.9819, lr_0 = 1.0202e-04
Loss = 1.8956e-03, PNorm = 34.9184, GNorm = 16.8191, lr_0 = 1.0202e-04
Loss = 1.7797e-03, PNorm = 34.9201, GNorm = 6.2240, lr_0 = 1.0202e-04
Loss = 2.0101e-03, PNorm = 34.9223, GNorm = 17.0358, lr_0 = 1.0202e-04
Loss = 2.6852e-03, PNorm = 34.9235, GNorm = 3.8080, lr_0 = 1.0202e-04
Loss = 2.0175e-03, PNorm = 34.9255, GNorm = 5.7570, lr_0 = 1.0202e-04
Validation rmse logP = 0.572752
Validation R2 logP = 0.903891
Epoch 19
Train function
Loss = 1.3872e-03, PNorm = 34.9277, GNorm = 6.2109, lr_0 = 1.0202e-04
Loss = 1.5506e-03, PNorm = 34.9289, GNorm = 1.1733, lr_0 = 1.0202e-04
Loss = 1.5250e-03, PNorm = 34.9307, GNorm = 6.4893, lr_0 = 1.0202e-04
Loss = 1.7390e-03, PNorm = 34.9319, GNorm = 5.8875, lr_0 = 1.0202e-04
Loss = 1.7085e-03, PNorm = 34.9343, GNorm = 2.2862, lr_0 = 1.0202e-04
Loss = 1.4698e-03, PNorm = 34.9363, GNorm = 2.2109, lr_0 = 1.0202e-04
Loss = 1.5396e-03, PNorm = 34.9379, GNorm = 10.0668, lr_0 = 1.0202e-04
Loss = 1.8264e-03, PNorm = 34.9402, GNorm = 6.4604, lr_0 = 1.0202e-04
Loss = 1.7042e-03, PNorm = 34.9424, GNorm = 2.4785, lr_0 = 1.0202e-04
Loss = 1.7607e-03, PNorm = 34.9440, GNorm = 5.9111, lr_0 = 1.0202e-04
Loss = 1.5177e-03, PNorm = 34.9461, GNorm = 2.9631, lr_0 = 1.0202e-04
Loss = 1.3649e-03, PNorm = 34.9477, GNorm = 5.8855, lr_0 = 1.0202e-04
Loss = 1.3798e-03, PNorm = 34.9492, GNorm = 4.7162, lr_0 = 1.0202e-04
Loss = 2.1123e-03, PNorm = 34.9513, GNorm = 5.1881, lr_0 = 1.0202e-04
Loss = 1.5799e-03, PNorm = 34.9535, GNorm = 3.8408, lr_0 = 1.0202e-04
Loss = 1.7704e-03, PNorm = 34.9553, GNorm = 5.4486, lr_0 = 1.0202e-04
Loss = 1.3532e-03, PNorm = 34.9563, GNorm = 4.7671, lr_0 = 1.0202e-04
Loss = 1.0292e-03, PNorm = 34.9584, GNorm = 3.7850, lr_0 = 1.0202e-04
Loss = 1.7812e-03, PNorm = 34.9605, GNorm = 5.3025, lr_0 = 1.0202e-04
Loss = 1.8278e-03, PNorm = 34.9624, GNorm = 1.7612, lr_0 = 1.0202e-04
Loss = 1.4476e-03, PNorm = 34.9641, GNorm = 1.6266, lr_0 = 1.0202e-04
Loss = 1.4508e-03, PNorm = 34.9657, GNorm = 2.5511, lr_0 = 1.0202e-04
Loss = 1.2807e-03, PNorm = 34.9672, GNorm = 2.5310, lr_0 = 1.0202e-04
Loss = 5.2202e-03, PNorm = 34.9673, GNorm = 10.8515, lr_0 = 1.0202e-04
Validation rmse logP = 0.543162
Validation R2 logP = 0.913565
Epoch 20
Train function
Loss = 1.2268e-03, PNorm = 34.9696, GNorm = 5.1734, lr_0 = 1.0202e-04
Loss = 1.4909e-03, PNorm = 34.9713, GNorm = 4.1226, lr_0 = 1.0202e-04
Loss = 1.2410e-03, PNorm = 34.9726, GNorm = 1.7448, lr_0 = 1.0202e-04
Loss = 1.2238e-03, PNorm = 34.9744, GNorm = 9.0096, lr_0 = 1.0202e-04
Loss = 1.5409e-03, PNorm = 34.9767, GNorm = 23.5756, lr_0 = 1.0202e-04
Loss = 1.7237e-03, PNorm = 34.9784, GNorm = 14.6043, lr_0 = 1.0202e-04
Loss = 1.8835e-03, PNorm = 34.9803, GNorm = 8.8917, lr_0 = 1.0202e-04
Loss = 1.5488e-03, PNorm = 34.9817, GNorm = 11.8216, lr_0 = 1.0202e-04
Loss = 2.2315e-03, PNorm = 34.9838, GNorm = 2.4790, lr_0 = 1.0202e-04
Loss = 1.6290e-03, PNorm = 34.9867, GNorm = 2.6348, lr_0 = 1.0202e-04
Loss = 1.6249e-03, PNorm = 34.9891, GNorm = 2.5846, lr_0 = 1.0202e-04
Loss = 1.6307e-03, PNorm = 34.9917, GNorm = 5.3097, lr_0 = 1.0202e-04
Loss = 1.5126e-03, PNorm = 34.9940, GNorm = 3.5760, lr_0 = 1.0202e-04
Loss = 2.0086e-03, PNorm = 34.9951, GNorm = 19.0544, lr_0 = 1.0202e-04
Loss = 1.4616e-03, PNorm = 34.9960, GNorm = 4.3148, lr_0 = 1.0202e-04
Loss = 1.3567e-03, PNorm = 34.9978, GNorm = 4.6704, lr_0 = 1.0202e-04
Loss = 1.5379e-03, PNorm = 34.9997, GNorm = 9.3504, lr_0 = 1.0202e-04
Loss = 1.6062e-03, PNorm = 35.0015, GNorm = 11.2562, lr_0 = 1.0202e-04
Loss = 1.5424e-03, PNorm = 35.0028, GNorm = 2.5121, lr_0 = 1.0202e-04
Loss = 2.0305e-03, PNorm = 35.0038, GNorm = 5.4758, lr_0 = 1.0202e-04
Loss = 1.6702e-03, PNorm = 35.0059, GNorm = 2.8869, lr_0 = 1.0202e-04
Loss = 1.7329e-03, PNorm = 35.0084, GNorm = 5.5193, lr_0 = 1.0202e-04
Validation rmse logP = 0.553311
Validation R2 logP = 0.910304
Epoch 21
Train function
Loss = 1.5994e-03, PNorm = 35.0103, GNorm = 5.5797, lr_0 = 1.0202e-04
Loss = 1.6372e-03, PNorm = 35.0123, GNorm = 7.3100, lr_0 = 1.0202e-04
Loss = 1.6504e-03, PNorm = 35.0138, GNorm = 4.4846, lr_0 = 1.0202e-04
Loss = 1.6751e-03, PNorm = 35.0161, GNorm = 5.8466, lr_0 = 1.0202e-04
Loss = 1.5080e-03, PNorm = 35.0181, GNorm = 6.4787, lr_0 = 1.0202e-04
Loss = 1.5178e-03, PNorm = 35.0206, GNorm = 8.7784, lr_0 = 1.0202e-04
Loss = 1.6076e-03, PNorm = 35.0225, GNorm = 1.9271, lr_0 = 1.0202e-04
Loss = 1.4306e-03, PNorm = 35.0249, GNorm = 6.9036, lr_0 = 1.0202e-04
Loss = 1.9758e-03, PNorm = 35.0263, GNorm = 8.3988, lr_0 = 1.0202e-04
Loss = 1.4976e-03, PNorm = 35.0284, GNorm = 6.6290, lr_0 = 1.0202e-04
Loss = 1.7228e-03, PNorm = 35.0300, GNorm = 1.9808, lr_0 = 1.0202e-04
Loss = 1.5849e-03, PNorm = 35.0329, GNorm = 15.2841, lr_0 = 1.0202e-04
Loss = 1.8464e-03, PNorm = 35.0345, GNorm = 8.6690, lr_0 = 1.0202e-04
Loss = 1.3906e-03, PNorm = 35.0365, GNorm = 2.3183, lr_0 = 1.0202e-04
Loss = 1.4623e-03, PNorm = 35.0378, GNorm = 3.1176, lr_0 = 1.0202e-04
Loss = 1.5695e-03, PNorm = 35.0394, GNorm = 12.2906, lr_0 = 1.0202e-04
Loss = 1.6265e-03, PNorm = 35.0414, GNorm = 2.5848, lr_0 = 1.0202e-04
Loss = 1.2869e-03, PNorm = 35.0434, GNorm = 5.2601, lr_0 = 1.0202e-04
Loss = 1.4861e-03, PNorm = 35.0443, GNorm = 12.3905, lr_0 = 1.0202e-04
Loss = 1.4111e-03, PNorm = 35.0458, GNorm = 5.6097, lr_0 = 1.0202e-04
Loss = 1.5830e-03, PNorm = 35.0479, GNorm = 6.6528, lr_0 = 1.0202e-04
Loss = 1.3302e-03, PNorm = 35.0495, GNorm = 10.1960, lr_0 = 1.0202e-04
Validation rmse logP = 0.564275
Validation R2 logP = 0.906715
Epoch 22
Train function
Loss = 2.1536e-03, PNorm = 35.0513, GNorm = 14.8310, lr_0 = 1.0202e-04
Loss = 1.5729e-03, PNorm = 35.0535, GNorm = 7.3271, lr_0 = 1.0202e-04
Loss = 1.2294e-03, PNorm = 35.0554, GNorm = 3.1047, lr_0 = 1.0202e-04
Loss = 1.5530e-03, PNorm = 35.0579, GNorm = 7.6349, lr_0 = 1.0202e-04
Loss = 1.2814e-03, PNorm = 35.0598, GNorm = 2.7029, lr_0 = 1.0202e-04
Loss = 1.4955e-03, PNorm = 35.0618, GNorm = 8.5445, lr_0 = 1.0202e-04
Loss = 1.8337e-03, PNorm = 35.0635, GNorm = 8.2268, lr_0 = 1.0202e-04
Loss = 1.5711e-03, PNorm = 35.0655, GNorm = 3.1919, lr_0 = 1.0202e-04
Loss = 1.3924e-03, PNorm = 35.0670, GNorm = 10.3656, lr_0 = 1.0202e-04
Loss = 1.4714e-03, PNorm = 35.0687, GNorm = 5.8806, lr_0 = 1.0202e-04
Loss = 1.5339e-03, PNorm = 35.0706, GNorm = 10.9837, lr_0 = 1.0202e-04
Loss = 1.0958e-03, PNorm = 35.0723, GNorm = 11.0871, lr_0 = 1.0202e-04
Loss = 2.1164e-03, PNorm = 35.0736, GNorm = 6.2730, lr_0 = 1.0202e-04
Loss = 1.3715e-03, PNorm = 35.0755, GNorm = 3.6206, lr_0 = 1.0202e-04
Loss = 1.5149e-03, PNorm = 35.0768, GNorm = 2.7498, lr_0 = 1.0202e-04
Loss = 1.5967e-03, PNorm = 35.0788, GNorm = 6.4407, lr_0 = 1.0202e-04
Loss = 1.3608e-03, PNorm = 35.0801, GNorm = 3.0078, lr_0 = 1.0202e-04
Loss = 1.3171e-03, PNorm = 35.0817, GNorm = 3.5988, lr_0 = 1.0202e-04
Loss = 1.1812e-03, PNorm = 35.0831, GNorm = 1.5708, lr_0 = 1.0202e-04
Loss = 1.6898e-03, PNorm = 35.0850, GNorm = 9.6522, lr_0 = 1.0202e-04
Loss = 1.2107e-03, PNorm = 35.0869, GNorm = 2.0005, lr_0 = 1.0202e-04
Loss = 1.4304e-03, PNorm = 35.0886, GNorm = 7.9463, lr_0 = 1.0202e-04
Loss = 1.4788e-03, PNorm = 35.0899, GNorm = 5.1720, lr_0 = 1.0202e-04
Validation rmse logP = 0.572165
Validation R2 logP = 0.904087
Epoch 23
Train function
Loss = 1.1035e-03, PNorm = 35.0915, GNorm = 10.6612, lr_0 = 1.0202e-04
Loss = 1.6246e-03, PNorm = 35.0933, GNorm = 11.1153, lr_0 = 1.0202e-04
Loss = 1.4985e-03, PNorm = 35.0950, GNorm = 2.3093, lr_0 = 1.0202e-04
Loss = 1.3528e-03, PNorm = 35.0969, GNorm = 4.5431, lr_0 = 1.0202e-04
Loss = 1.4390e-03, PNorm = 35.0982, GNorm = 7.5210, lr_0 = 1.0202e-04
Loss = 1.5967e-03, PNorm = 35.1004, GNorm = 9.7566, lr_0 = 1.0202e-04
Loss = 1.2783e-03, PNorm = 35.1015, GNorm = 8.7633, lr_0 = 1.0202e-04
Loss = 1.1046e-03, PNorm = 35.1028, GNorm = 3.6301, lr_0 = 1.0202e-04
Loss = 1.3073e-03, PNorm = 35.1045, GNorm = 1.8119, lr_0 = 1.0202e-04
Loss = 1.3948e-03, PNorm = 35.1066, GNorm = 2.9081, lr_0 = 1.0202e-04
Loss = 1.4328e-03, PNorm = 35.1087, GNorm = 6.9548, lr_0 = 1.0202e-04
Loss = 1.5566e-03, PNorm = 35.1113, GNorm = 9.8195, lr_0 = 1.0202e-04
Loss = 1.3411e-03, PNorm = 35.1133, GNorm = 6.3526, lr_0 = 1.0202e-04
Loss = 1.3882e-03, PNorm = 35.1151, GNorm = 1.8056, lr_0 = 1.0202e-04
Loss = 1.5191e-03, PNorm = 35.1171, GNorm = 2.3945, lr_0 = 1.0202e-04
Loss = 1.4467e-03, PNorm = 35.1200, GNorm = 1.8162, lr_0 = 1.0202e-04
Loss = 1.4622e-03, PNorm = 35.1219, GNorm = 3.8575, lr_0 = 1.0202e-04
Loss = 1.2928e-03, PNorm = 35.1237, GNorm = 2.9463, lr_0 = 1.0202e-04
Loss = 1.5974e-03, PNorm = 35.1243, GNorm = 9.9270, lr_0 = 1.0202e-04
Loss = 1.3900e-03, PNorm = 35.1259, GNorm = 1.9845, lr_0 = 1.0202e-04
Loss = 1.6659e-03, PNorm = 35.1287, GNorm = 12.7060, lr_0 = 1.0202e-04
Loss = 1.4160e-03, PNorm = 35.1310, GNorm = 11.1520, lr_0 = 1.0202e-04
Validation rmse logP = 0.597122
Validation R2 logP = 0.895538
Epoch 24
Train function
Loss = 1.7373e-03, PNorm = 35.1330, GNorm = 17.0343, lr_0 = 1.0202e-04
Loss = 1.7219e-03, PNorm = 35.1348, GNorm = 18.1156, lr_0 = 1.0202e-04
Loss = 1.7993e-03, PNorm = 35.1367, GNorm = 8.5576, lr_0 = 1.0202e-04
Loss = 2.1844e-03, PNorm = 35.1375, GNorm = 6.8287, lr_0 = 1.0202e-04
Loss = 1.7846e-03, PNorm = 35.1399, GNorm = 6.1723, lr_0 = 1.0202e-04
Loss = 1.4913e-03, PNorm = 35.1412, GNorm = 7.3008, lr_0 = 1.0202e-04
Loss = 1.1341e-03, PNorm = 35.1427, GNorm = 4.4713, lr_0 = 1.0202e-04
Loss = 1.2273e-03, PNorm = 35.1450, GNorm = 1.1049, lr_0 = 1.0202e-04
Loss = 1.4218e-03, PNorm = 35.1475, GNorm = 9.5602, lr_0 = 1.0202e-04
Loss = 1.7941e-03, PNorm = 35.1493, GNorm = 8.4405, lr_0 = 1.0202e-04
Loss = 1.4338e-03, PNorm = 35.1524, GNorm = 2.2171, lr_0 = 1.0202e-04
Loss = 1.2940e-03, PNorm = 35.1543, GNorm = 3.1199, lr_0 = 1.0202e-04
Loss = 1.1945e-03, PNorm = 35.1563, GNorm = 2.8551, lr_0 = 1.0202e-04
Loss = 1.3032e-03, PNorm = 35.1580, GNorm = 5.7935, lr_0 = 1.0202e-04
Loss = 1.6329e-03, PNorm = 35.1601, GNorm = 3.4704, lr_0 = 1.0202e-04
Loss = 1.3769e-03, PNorm = 35.1614, GNorm = 7.2869, lr_0 = 1.0202e-04
Loss = 1.2710e-03, PNorm = 35.1627, GNorm = 7.7177, lr_0 = 1.0202e-04
Loss = 1.6335e-03, PNorm = 35.1645, GNorm = 3.3539, lr_0 = 1.0202e-04
Loss = 1.6891e-03, PNorm = 35.1658, GNorm = 1.6819, lr_0 = 1.0202e-04
Loss = 1.3217e-03, PNorm = 35.1679, GNorm = 3.4557, lr_0 = 1.0202e-04
Loss = 1.1798e-03, PNorm = 35.1696, GNorm = 5.2216, lr_0 = 1.0202e-04
Loss = 1.5941e-03, PNorm = 35.1717, GNorm = 13.5528, lr_0 = 1.0202e-04
Validation rmse logP = 0.605574
Validation R2 logP = 0.892560
Epoch 25
Train function
Loss = 1.4871e-03, PNorm = 35.1731, GNorm = 10.2472, lr_0 = 1.0202e-04
Loss = 1.6353e-03, PNorm = 35.1746, GNorm = 6.3389, lr_0 = 1.0202e-04
Loss = 1.5254e-03, PNorm = 35.1771, GNorm = 9.0797, lr_0 = 1.0202e-04
Loss = 1.3856e-03, PNorm = 35.1793, GNorm = 2.9625, lr_0 = 1.0202e-04
Loss = 1.4083e-03, PNorm = 35.1813, GNorm = 7.2772, lr_0 = 1.0202e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 11,177 | val size = 533 | test size = 2,067
Fitting scaler
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 22,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logP'],
 'task_names': ['logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 11,710 | train size = 11,177 | val size = 533 | test size = 2,067
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 354,901
Moving model to cuda
Epoch 0
Train function
Loss = 1.6962e-02, PNorm = 34.0116, GNorm = 1.9700, lr_0 = 1.0202e-04
Loss = 1.7711e-02, PNorm = 34.0139, GNorm = 2.5146, lr_0 = 1.0202e-04
Loss = 1.5340e-02, PNorm = 34.0169, GNorm = 1.9349, lr_0 = 1.0202e-04
Loss = 1.5352e-02, PNorm = 34.0206, GNorm = 1.7695, lr_0 = 1.0202e-04
Loss = 1.4047e-02, PNorm = 34.0248, GNorm = 2.5131, lr_0 = 1.0202e-04
Loss = 1.3613e-02, PNorm = 34.0288, GNorm = 15.3018, lr_0 = 1.0202e-04
Loss = 1.2169e-02, PNorm = 34.0321, GNorm = 20.2297, lr_0 = 1.0202e-04
Loss = 1.2418e-02, PNorm = 34.0349, GNorm = 21.5383, lr_0 = 1.0202e-04
Loss = 1.0239e-02, PNorm = 34.0375, GNorm = 2.9857, lr_0 = 1.0202e-04
Loss = 1.0228e-02, PNorm = 34.0413, GNorm = 24.1786, lr_0 = 1.0202e-04
Loss = 8.8066e-03, PNorm = 34.0445, GNorm = 6.9430, lr_0 = 1.0202e-04
Loss = 1.0586e-02, PNorm = 34.0473, GNorm = 15.4734, lr_0 = 1.0202e-04
Loss = 1.0139e-02, PNorm = 34.0504, GNorm = 14.3769, lr_0 = 1.0202e-04
Loss = 1.0688e-02, PNorm = 34.0530, GNorm = 3.6074, lr_0 = 1.0202e-04
Loss = 9.4742e-03, PNorm = 34.0559, GNorm = 12.3202, lr_0 = 1.0202e-04
Loss = 9.0447e-03, PNorm = 34.0595, GNorm = 8.8030, lr_0 = 1.0202e-04
Loss = 7.7187e-03, PNorm = 34.0637, GNorm = 5.1046, lr_0 = 1.0202e-04
Loss = 6.7299e-03, PNorm = 34.0665, GNorm = 7.9823, lr_0 = 1.0202e-04
Loss = 8.8600e-03, PNorm = 34.0699, GNorm = 10.6906, lr_0 = 1.0202e-04
Loss = 6.9359e-03, PNorm = 34.0723, GNorm = 11.0408, lr_0 = 1.0202e-04
Loss = 8.2959e-03, PNorm = 34.0753, GNorm = 15.0221, lr_0 = 1.0202e-04
Loss = 6.3613e-03, PNorm = 34.0789, GNorm = 2.8511, lr_0 = 1.0202e-04
Validation rmse logP = 1.072882
Validation R2 logP = 0.662762
Epoch 1
Train function
Loss = 7.2795e-03, PNorm = 34.0831, GNorm = 13.3237, lr_0 = 1.0202e-04
Loss = 5.7231e-03, PNorm = 34.0863, GNorm = 11.5603, lr_0 = 1.0202e-04
Loss = 6.1968e-03, PNorm = 34.0891, GNorm = 2.5603, lr_0 = 1.0202e-04
Loss = 5.9255e-03, PNorm = 34.0920, GNorm = 5.8651, lr_0 = 1.0202e-04
Loss = 5.6853e-03, PNorm = 34.0951, GNorm = 12.2037, lr_0 = 1.0202e-04
Loss = 6.3334e-03, PNorm = 34.0980, GNorm = 16.1343, lr_0 = 1.0202e-04
Loss = 5.9102e-03, PNorm = 34.1014, GNorm = 2.8133, lr_0 = 1.0202e-04
Loss = 5.9135e-03, PNorm = 34.1044, GNorm = 5.5456, lr_0 = 1.0202e-04
Loss = 6.2343e-03, PNorm = 34.1070, GNorm = 24.4747, lr_0 = 1.0202e-04
Loss = 6.4061e-03, PNorm = 34.1101, GNorm = 8.4209, lr_0 = 1.0202e-04
Loss = 5.9010e-03, PNorm = 34.1133, GNorm = 4.6929, lr_0 = 1.0202e-04
Loss = 5.8978e-03, PNorm = 34.1157, GNorm = 1.8397, lr_0 = 1.0202e-04
Loss = 4.8629e-03, PNorm = 34.1193, GNorm = 12.3852, lr_0 = 1.0202e-04
Loss = 5.2887e-03, PNorm = 34.1220, GNorm = 3.0351, lr_0 = 1.0202e-04
Loss = 5.6460e-03, PNorm = 34.1251, GNorm = 10.5021, lr_0 = 1.0202e-04
Loss = 5.0585e-03, PNorm = 34.1283, GNorm = 14.9942, lr_0 = 1.0202e-04
Loss = 5.2266e-03, PNorm = 34.1316, GNorm = 3.9659, lr_0 = 1.0202e-04
Loss = 5.1374e-03, PNorm = 34.1346, GNorm = 7.2599, lr_0 = 1.0202e-04
Loss = 4.2866e-03, PNorm = 34.1371, GNorm = 2.4246, lr_0 = 1.0202e-04
Loss = 5.0471e-03, PNorm = 34.1391, GNorm = 5.6410, lr_0 = 1.0202e-04
Loss = 6.4947e-03, PNorm = 34.1414, GNorm = 28.0426, lr_0 = 1.0202e-04
Loss = 5.4595e-03, PNorm = 34.1438, GNorm = 17.6084, lr_0 = 1.0202e-04
Validation rmse logP = 0.952799
Validation R2 logP = 0.734029
Epoch 2
Train function
Loss = 4.0591e-03, PNorm = 34.1465, GNorm = 13.4926, lr_0 = 1.0202e-04
Loss = 4.9461e-03, PNorm = 34.1483, GNorm = 4.3153, lr_0 = 1.0202e-04
Loss = 6.4834e-03, PNorm = 34.1514, GNorm = 29.8196, lr_0 = 1.0202e-04
Loss = 5.1567e-03, PNorm = 34.1536, GNorm = 24.0175, lr_0 = 1.0202e-04
Loss = 5.2143e-03, PNorm = 34.1559, GNorm = 21.5289, lr_0 = 1.0202e-04
Loss = 4.2826e-03, PNorm = 34.1586, GNorm = 12.5335, lr_0 = 1.0202e-04
Loss = 4.2552e-03, PNorm = 34.1610, GNorm = 13.6019, lr_0 = 1.0202e-04
Loss = 4.2537e-03, PNorm = 34.1627, GNorm = 5.7467, lr_0 = 1.0202e-04
Loss = 4.2979e-03, PNorm = 34.1655, GNorm = 13.7221, lr_0 = 1.0202e-04
Loss = 4.4376e-03, PNorm = 34.1680, GNorm = 5.1456, lr_0 = 1.0202e-04
Loss = 4.6663e-03, PNorm = 34.1706, GNorm = 7.2569, lr_0 = 1.0202e-04
Loss = 4.8437e-03, PNorm = 34.1735, GNorm = 5.3926, lr_0 = 1.0202e-04
Loss = 4.3787e-03, PNorm = 34.1757, GNorm = 6.9339, lr_0 = 1.0202e-04
Loss = 4.5440e-03, PNorm = 34.1789, GNorm = 9.1141, lr_0 = 1.0202e-04
Loss = 4.2564e-03, PNorm = 34.1817, GNorm = 9.2156, lr_0 = 1.0202e-04
Loss = 5.0423e-03, PNorm = 34.1844, GNorm = 4.5616, lr_0 = 1.0202e-04
Loss = 4.7976e-03, PNorm = 34.1875, GNorm = 19.3830, lr_0 = 1.0202e-04
Loss = 5.0343e-03, PNorm = 34.1903, GNorm = 20.0355, lr_0 = 1.0202e-04
Loss = 4.3390e-03, PNorm = 34.1936, GNorm = 11.6235, lr_0 = 1.0202e-04
Loss = 4.2202e-03, PNorm = 34.1969, GNorm = 4.4785, lr_0 = 1.0202e-04
Loss = 4.4324e-03, PNorm = 34.1993, GNorm = 17.3218, lr_0 = 1.0202e-04
Loss = 3.6087e-03, PNorm = 34.2018, GNorm = 3.5564, lr_0 = 1.0202e-04
Loss = 3.8527e-03, PNorm = 34.2034, GNorm = 6.2614, lr_0 = 1.0202e-04
Loss = 8.2009e-03, PNorm = 34.2036, GNorm = 13.2461, lr_0 = 1.0202e-04
Validation rmse logP = 0.797979
Validation R2 logP = 0.813441
Epoch 3
Train function
Loss = 3.7717e-03, PNorm = 34.2059, GNorm = 19.5343, lr_0 = 1.0202e-04
Loss = 3.2107e-03, PNorm = 34.2082, GNorm = 8.0051, lr_0 = 1.0202e-04
Loss = 3.7141e-03, PNorm = 34.2105, GNorm = 10.1286, lr_0 = 1.0202e-04
Loss = 3.8431e-03, PNorm = 34.2130, GNorm = 6.5624, lr_0 = 1.0202e-04
Loss = 3.7374e-03, PNorm = 34.2151, GNorm = 7.1734, lr_0 = 1.0202e-04
Loss = 3.5630e-03, PNorm = 34.2173, GNorm = 9.4605, lr_0 = 1.0202e-04
Loss = 3.7486e-03, PNorm = 34.2191, GNorm = 10.6165, lr_0 = 1.0202e-04
Loss = 3.7997e-03, PNorm = 34.2213, GNorm = 15.5627, lr_0 = 1.0202e-04
Loss = 4.4427e-03, PNorm = 34.2242, GNorm = 9.7345, lr_0 = 1.0202e-04
Loss = 3.9561e-03, PNorm = 34.2272, GNorm = 10.3794, lr_0 = 1.0202e-04
Loss = 3.5046e-03, PNorm = 34.2302, GNorm = 6.0206, lr_0 = 1.0202e-04
Loss = 3.5212e-03, PNorm = 34.2330, GNorm = 2.5651, lr_0 = 1.0202e-04
Loss = 3.7255e-03, PNorm = 34.2354, GNorm = 5.9512, lr_0 = 1.0202e-04
Loss = 3.9815e-03, PNorm = 34.2385, GNorm = 3.1020, lr_0 = 1.0202e-04
Loss = 3.2432e-03, PNorm = 34.2406, GNorm = 2.8622, lr_0 = 1.0202e-04
Loss = 3.6389e-03, PNorm = 34.2430, GNorm = 3.2545, lr_0 = 1.0202e-04
Loss = 3.2603e-03, PNorm = 34.2456, GNorm = 4.0075, lr_0 = 1.0202e-04
Loss = 3.1388e-03, PNorm = 34.2479, GNorm = 6.0379, lr_0 = 1.0202e-04
Loss = 3.0270e-03, PNorm = 34.2503, GNorm = 11.9728, lr_0 = 1.0202e-04
Loss = 3.4843e-03, PNorm = 34.2532, GNorm = 14.8658, lr_0 = 1.0202e-04
Loss = 3.8106e-03, PNorm = 34.2560, GNorm = 6.3226, lr_0 = 1.0202e-04
Loss = 3.8647e-03, PNorm = 34.2590, GNorm = 12.4843, lr_0 = 1.0202e-04
Validation rmse logP = 0.756336
Validation R2 logP = 0.832405
Epoch 4
Train function
Loss = 3.2865e-03, PNorm = 34.2618, GNorm = 7.3038, lr_0 = 1.0202e-04
Loss = 3.1658e-03, PNorm = 34.2641, GNorm = 7.3418, lr_0 = 1.0202e-04
Loss = 3.9188e-03, PNorm = 34.2664, GNorm = 10.2681, lr_0 = 1.0202e-04
Loss = 4.0255e-03, PNorm = 34.2695, GNorm = 4.8124, lr_0 = 1.0202e-04
Loss = 3.5399e-03, PNorm = 34.2724, GNorm = 9.8008, lr_0 = 1.0202e-04
Loss = 3.2681e-03, PNorm = 34.2760, GNorm = 22.9998, lr_0 = 1.0202e-04
Loss = 3.2963e-03, PNorm = 34.2782, GNorm = 16.3140, lr_0 = 1.0202e-04
Loss = 3.8480e-03, PNorm = 34.2812, GNorm = 2.8546, lr_0 = 1.0202e-04
Loss = 3.6048e-03, PNorm = 34.2837, GNorm = 4.5581, lr_0 = 1.0202e-04
Loss = 3.2755e-03, PNorm = 34.2857, GNorm = 12.1508, lr_0 = 1.0202e-04
Loss = 2.8672e-03, PNorm = 34.2872, GNorm = 7.1904, lr_0 = 1.0202e-04
Loss = 2.8840e-03, PNorm = 34.2893, GNorm = 2.7303, lr_0 = 1.0202e-04
Loss = 3.5341e-03, PNorm = 34.2917, GNorm = 6.9984, lr_0 = 1.0202e-04
Loss = 3.1694e-03, PNorm = 34.2939, GNorm = 12.7283, lr_0 = 1.0202e-04
Loss = 3.5548e-03, PNorm = 34.2968, GNorm = 2.2534, lr_0 = 1.0202e-04
Loss = 2.7982e-03, PNorm = 34.3002, GNorm = 9.7782, lr_0 = 1.0202e-04
Loss = 2.7344e-03, PNorm = 34.3030, GNorm = 5.0989, lr_0 = 1.0202e-04
Loss = 3.4206e-03, PNorm = 34.3053, GNorm = 9.7466, lr_0 = 1.0202e-04
Loss = 2.9429e-03, PNorm = 34.3078, GNorm = 22.8522, lr_0 = 1.0202e-04
Loss = 3.3368e-03, PNorm = 34.3097, GNorm = 9.7237, lr_0 = 1.0202e-04
Loss = 2.5483e-03, PNorm = 34.3117, GNorm = 2.9441, lr_0 = 1.0202e-04
Loss = 3.0391e-03, PNorm = 34.3132, GNorm = 14.6314, lr_0 = 1.0202e-04
Validation rmse logP = 0.697964
Validation R2 logP = 0.857276
Epoch 5
Train function
Loss = 3.1989e-03, PNorm = 34.3152, GNorm = 11.2701, lr_0 = 1.0202e-04
Loss = 2.7344e-03, PNorm = 34.3178, GNorm = 9.3287, lr_0 = 1.0202e-04
Loss = 2.6354e-03, PNorm = 34.3194, GNorm = 5.9615, lr_0 = 1.0202e-04
Loss = 2.9003e-03, PNorm = 34.3205, GNorm = 7.0320, lr_0 = 1.0202e-04
Loss = 3.3162e-03, PNorm = 34.3232, GNorm = 7.1071, lr_0 = 1.0202e-04
Loss = 3.0543e-03, PNorm = 34.3253, GNorm = 17.7850, lr_0 = 1.0202e-04
Loss = 3.2978e-03, PNorm = 34.3280, GNorm = 3.4564, lr_0 = 1.0202e-04
Loss = 2.2399e-03, PNorm = 34.3304, GNorm = 1.9615, lr_0 = 1.0202e-04
Loss = 3.0849e-03, PNorm = 34.3325, GNorm = 6.3568, lr_0 = 1.0202e-04
Loss = 3.2551e-03, PNorm = 34.3354, GNorm = 3.9055, lr_0 = 1.0202e-04
Loss = 2.6285e-03, PNorm = 34.3379, GNorm = 11.1965, lr_0 = 1.0202e-04
Loss = 3.1084e-03, PNorm = 34.3416, GNorm = 12.3188, lr_0 = 1.0202e-04
Loss = 2.9397e-03, PNorm = 34.3446, GNorm = 3.6968, lr_0 = 1.0202e-04
Loss = 3.0876e-03, PNorm = 34.3462, GNorm = 11.4447, lr_0 = 1.0202e-04
Loss = 3.3324e-03, PNorm = 34.3489, GNorm = 12.5428, lr_0 = 1.0202e-04
Loss = 2.5103e-03, PNorm = 34.3514, GNorm = 5.4814, lr_0 = 1.0202e-04
Loss = 3.0134e-03, PNorm = 34.3530, GNorm = 8.6215, lr_0 = 1.0202e-04
Loss = 2.7628e-03, PNorm = 34.3558, GNorm = 8.9114, lr_0 = 1.0202e-04
Loss = 2.7533e-03, PNorm = 34.3575, GNorm = 11.3383, lr_0 = 1.0202e-04
Loss = 3.1697e-03, PNorm = 34.3592, GNorm = 2.8043, lr_0 = 1.0202e-04
Loss = 3.1156e-03, PNorm = 34.3614, GNorm = 12.7698, lr_0 = 1.0202e-04
Loss = 2.6227e-03, PNorm = 34.3635, GNorm = 5.3330, lr_0 = 1.0202e-04
Loss = 2.8897e-03, PNorm = 34.3649, GNorm = 15.4464, lr_0 = 1.0202e-04
Validation rmse logP = 0.682541
Validation R2 logP = 0.863514
Epoch 6
Train function
Loss = 2.9852e-03, PNorm = 34.3661, GNorm = 10.0019, lr_0 = 1.0202e-04
Loss = 3.0579e-03, PNorm = 34.3680, GNorm = 14.2912, lr_0 = 1.0202e-04
Loss = 3.0250e-03, PNorm = 34.3704, GNorm = 8.0587, lr_0 = 1.0202e-04
Loss = 3.2706e-03, PNorm = 34.3731, GNorm = 14.6280, lr_0 = 1.0202e-04
Loss = 2.7077e-03, PNorm = 34.3753, GNorm = 3.4745, lr_0 = 1.0202e-04
Loss = 3.4054e-03, PNorm = 34.3774, GNorm = 19.4799, lr_0 = 1.0202e-04
Loss = 3.3471e-03, PNorm = 34.3799, GNorm = 21.2980, lr_0 = 1.0202e-04
Loss = 3.3071e-03, PNorm = 34.3820, GNorm = 9.4480, lr_0 = 1.0202e-04
Loss = 3.2846e-03, PNorm = 34.3847, GNorm = 7.5348, lr_0 = 1.0202e-04
Loss = 2.4097e-03, PNorm = 34.3866, GNorm = 5.4242, lr_0 = 1.0202e-04
Loss = 3.4583e-03, PNorm = 34.3888, GNorm = 7.5994, lr_0 = 1.0202e-04
Loss = 3.3416e-03, PNorm = 34.3906, GNorm = 9.8175, lr_0 = 1.0202e-04
Loss = 2.7860e-03, PNorm = 34.3943, GNorm = 1.5419, lr_0 = 1.0202e-04
Loss = 2.5718e-03, PNorm = 34.3971, GNorm = 2.5425, lr_0 = 1.0202e-04
Loss = 3.1053e-03, PNorm = 34.3999, GNorm = 5.1989, lr_0 = 1.0202e-04
Loss = 2.7548e-03, PNorm = 34.4021, GNorm = 9.3951, lr_0 = 1.0202e-04
Loss = 2.6500e-03, PNorm = 34.4040, GNorm = 5.1972, lr_0 = 1.0202e-04
Loss = 3.2142e-03, PNorm = 34.4064, GNorm = 19.7762, lr_0 = 1.0202e-04
Loss = 2.3738e-03, PNorm = 34.4091, GNorm = 2.0508, lr_0 = 1.0202e-04
Loss = 2.5479e-03, PNorm = 34.4109, GNorm = 8.4160, lr_0 = 1.0202e-04
Loss = 3.0408e-03, PNorm = 34.4123, GNorm = 11.2221, lr_0 = 1.0202e-04
Loss = 2.7426e-03, PNorm = 34.4139, GNorm = 16.9465, lr_0 = 1.0202e-04
Validation rmse logP = 0.691108
Validation R2 logP = 0.860065
Epoch 7
Train function
Loss = 2.2515e-03, PNorm = 34.4155, GNorm = 5.9209, lr_0 = 1.0202e-04
Loss = 2.6032e-03, PNorm = 34.4179, GNorm = 6.8838, lr_0 = 1.0202e-04
Loss = 2.6855e-03, PNorm = 34.4203, GNorm = 2.1573, lr_0 = 1.0202e-04
Loss = 2.7388e-03, PNorm = 34.4224, GNorm = 2.8488, lr_0 = 1.0202e-04
Loss = 2.6798e-03, PNorm = 34.4246, GNorm = 21.6886, lr_0 = 1.0202e-04
Loss = 2.7997e-03, PNorm = 34.4268, GNorm = 6.3319, lr_0 = 1.0202e-04
Loss = 2.5188e-03, PNorm = 34.4292, GNorm = 11.0373, lr_0 = 1.0202e-04
Loss = 1.9722e-03, PNorm = 34.4319, GNorm = 9.4748, lr_0 = 1.0202e-04
Loss = 2.4370e-03, PNorm = 34.4343, GNorm = 8.7261, lr_0 = 1.0202e-04
Loss = 3.2064e-03, PNorm = 34.4351, GNorm = 6.8155, lr_0 = 1.0202e-04
Loss = 2.8827e-03, PNorm = 34.4367, GNorm = 5.6518, lr_0 = 1.0202e-04
Loss = 2.2967e-03, PNorm = 34.4391, GNorm = 5.4470, lr_0 = 1.0202e-04
Loss = 2.4570e-03, PNorm = 34.4411, GNorm = 7.0090, lr_0 = 1.0202e-04
Loss = 2.6633e-03, PNorm = 34.4436, GNorm = 7.4419, lr_0 = 1.0202e-04
Loss = 2.6556e-03, PNorm = 34.4464, GNorm = 2.4037, lr_0 = 1.0202e-04
Loss = 2.1511e-03, PNorm = 34.4486, GNorm = 5.6395, lr_0 = 1.0202e-04
Loss = 2.3855e-03, PNorm = 34.4513, GNorm = 6.4019, lr_0 = 1.0202e-04
Loss = 2.3963e-03, PNorm = 34.4546, GNorm = 3.9489, lr_0 = 1.0202e-04
Loss = 2.6873e-03, PNorm = 34.4567, GNorm = 3.7251, lr_0 = 1.0202e-04
Loss = 2.6219e-03, PNorm = 34.4588, GNorm = 15.6698, lr_0 = 1.0202e-04
Loss = 2.3101e-03, PNorm = 34.4604, GNorm = 7.2156, lr_0 = 1.0202e-04
Loss = 2.4426e-03, PNorm = 34.4614, GNorm = 8.4564, lr_0 = 1.0202e-04
Validation rmse logP = 0.651569
Validation R2 logP = 0.875619
Epoch 8
Train function
Loss = 3.1666e-03, PNorm = 34.4620, GNorm = 4.9646, lr_0 = 1.0202e-04
Loss = 3.0805e-03, PNorm = 34.4639, GNorm = 1.8045, lr_0 = 1.0202e-04
Loss = 2.1892e-03, PNorm = 34.4661, GNorm = 9.9123, lr_0 = 1.0202e-04
Loss = 2.5836e-03, PNorm = 34.4683, GNorm = 5.2240, lr_0 = 1.0202e-04
Loss = 3.1116e-03, PNorm = 34.4701, GNorm = 7.2207, lr_0 = 1.0202e-04
Loss = 3.0615e-03, PNorm = 34.4715, GNorm = 7.3988, lr_0 = 1.0202e-04
Loss = 2.9343e-03, PNorm = 34.4738, GNorm = 5.3676, lr_0 = 1.0202e-04
Loss = 2.6004e-03, PNorm = 34.4758, GNorm = 6.9349, lr_0 = 1.0202e-04
Loss = 2.3206e-03, PNorm = 34.4776, GNorm = 14.7550, lr_0 = 1.0202e-04
Loss = 2.4096e-03, PNorm = 34.4794, GNorm = 8.5342, lr_0 = 1.0202e-04
Loss = 2.5810e-03, PNorm = 34.4809, GNorm = 2.4157, lr_0 = 1.0202e-04
Loss = 2.6923e-03, PNorm = 34.4830, GNorm = 1.9639, lr_0 = 1.0202e-04
Loss = 2.4860e-03, PNorm = 34.4850, GNorm = 14.5644, lr_0 = 1.0202e-04
Loss = 2.2741e-03, PNorm = 34.4868, GNorm = 9.1844, lr_0 = 1.0202e-04
Loss = 2.2137e-03, PNorm = 34.4888, GNorm = 9.2757, lr_0 = 1.0202e-04
Loss = 2.4170e-03, PNorm = 34.4911, GNorm = 1.7999, lr_0 = 1.0202e-04
Loss = 2.4016e-03, PNorm = 34.4932, GNorm = 4.8762, lr_0 = 1.0202e-04
Loss = 2.4143e-03, PNorm = 34.4958, GNorm = 12.0987, lr_0 = 1.0202e-04
Loss = 2.1553e-03, PNorm = 34.4977, GNorm = 4.5991, lr_0 = 1.0202e-04
Loss = 2.0353e-03, PNorm = 34.5003, GNorm = 6.1554, lr_0 = 1.0202e-04
Loss = 2.1710e-03, PNorm = 34.5028, GNorm = 7.9403, lr_0 = 1.0202e-04
Loss = 2.0286e-03, PNorm = 34.5042, GNorm = 12.7519, lr_0 = 1.0202e-04
Loss = 2.6676e-03, PNorm = 34.5059, GNorm = 2.6337, lr_0 = 1.0202e-04
Validation rmse logP = 0.635728
Validation R2 logP = 0.881594
Epoch 9
Train function
Loss = 1.9912e-03, PNorm = 34.5075, GNorm = 10.1412, lr_0 = 1.0202e-04
Loss = 1.8957e-03, PNorm = 34.5091, GNorm = 6.1231, lr_0 = 1.0202e-04
Loss = 2.4864e-03, PNorm = 34.5112, GNorm = 5.7706, lr_0 = 1.0202e-04
Loss = 2.3700e-03, PNorm = 34.5138, GNorm = 6.8004, lr_0 = 1.0202e-04
Loss = 2.3631e-03, PNorm = 34.5159, GNorm = 4.3818, lr_0 = 1.0202e-04
Loss = 2.3281e-03, PNorm = 34.5182, GNorm = 6.5017, lr_0 = 1.0202e-04
Loss = 2.1021e-03, PNorm = 34.5206, GNorm = 13.1937, lr_0 = 1.0202e-04
Loss = 2.3028e-03, PNorm = 34.5229, GNorm = 3.3260, lr_0 = 1.0202e-04
Loss = 2.4047e-03, PNorm = 34.5250, GNorm = 4.0315, lr_0 = 1.0202e-04
Loss = 2.0701e-03, PNorm = 34.5262, GNorm = 1.9092, lr_0 = 1.0202e-04
Loss = 2.1181e-03, PNorm = 34.5277, GNorm = 9.0149, lr_0 = 1.0202e-04
Loss = 2.6042e-03, PNorm = 34.5289, GNorm = 21.7067, lr_0 = 1.0202e-04
Loss = 2.6440e-03, PNorm = 34.5308, GNorm = 24.8861, lr_0 = 1.0202e-04
Loss = 2.3531e-03, PNorm = 34.5323, GNorm = 21.0915, lr_0 = 1.0202e-04
Loss = 2.7788e-03, PNorm = 34.5349, GNorm = 7.7533, lr_0 = 1.0202e-04
Loss = 2.3434e-03, PNorm = 34.5367, GNorm = 4.1132, lr_0 = 1.0202e-04
Loss = 2.9164e-03, PNorm = 34.5384, GNorm = 6.7316, lr_0 = 1.0202e-04
Loss = 2.2281e-03, PNorm = 34.5407, GNorm = 1.8412, lr_0 = 1.0202e-04
Loss = 1.9231e-03, PNorm = 34.5427, GNorm = 4.1811, lr_0 = 1.0202e-04
Loss = 2.2444e-03, PNorm = 34.5452, GNorm = 13.2182, lr_0 = 1.0202e-04
Loss = 2.9547e-03, PNorm = 34.5474, GNorm = 6.9509, lr_0 = 1.0202e-04
Loss = 1.9817e-03, PNorm = 34.5492, GNorm = 9.1436, lr_0 = 1.0202e-04
Validation rmse logP = 0.698034
Validation R2 logP = 0.857247
Epoch 10
Train function
Loss = 2.2539e-03, PNorm = 34.5509, GNorm = 13.9033, lr_0 = 1.0202e-04
Loss = 2.6022e-03, PNorm = 34.5529, GNorm = 21.8443, lr_0 = 1.0202e-04
Loss = 2.4055e-03, PNorm = 34.5543, GNorm = 15.4362, lr_0 = 1.0202e-04
Loss = 2.3282e-03, PNorm = 34.5562, GNorm = 8.5713, lr_0 = 1.0202e-04
Loss = 2.2453e-03, PNorm = 34.5583, GNorm = 2.8780, lr_0 = 1.0202e-04
Loss = 1.9133e-03, PNorm = 34.5599, GNorm = 7.8898, lr_0 = 1.0202e-04
Loss = 1.9005e-03, PNorm = 34.5616, GNorm = 2.7575, lr_0 = 1.0202e-04
Loss = 2.0195e-03, PNorm = 34.5630, GNorm = 3.6265, lr_0 = 1.0202e-04
Loss = 2.3060e-03, PNorm = 34.5646, GNorm = 8.5349, lr_0 = 1.0202e-04
Loss = 1.9424e-03, PNorm = 34.5667, GNorm = 3.6374, lr_0 = 1.0202e-04
Loss = 2.1162e-03, PNorm = 34.5687, GNorm = 8.2113, lr_0 = 1.0202e-04
Loss = 2.0303e-03, PNorm = 34.5708, GNorm = 4.8846, lr_0 = 1.0202e-04
Loss = 2.1683e-03, PNorm = 34.5732, GNorm = 5.8664, lr_0 = 1.0202e-04
Loss = 2.2538e-03, PNorm = 34.5749, GNorm = 2.5460, lr_0 = 1.0202e-04
Loss = 2.3971e-03, PNorm = 34.5761, GNorm = 15.1854, lr_0 = 1.0202e-04
Loss = 2.0572e-03, PNorm = 34.5774, GNorm = 2.7524, lr_0 = 1.0202e-04
Loss = 2.0556e-03, PNorm = 34.5788, GNorm = 15.9419, lr_0 = 1.0202e-04
Loss = 2.0441e-03, PNorm = 34.5808, GNorm = 10.5023, lr_0 = 1.0202e-04
Loss = 1.8072e-03, PNorm = 34.5830, GNorm = 6.1022, lr_0 = 1.0202e-04
Loss = 1.9734e-03, PNorm = 34.5853, GNorm = 6.2333, lr_0 = 1.0202e-04
Loss = 1.9241e-03, PNorm = 34.5867, GNorm = 2.2894, lr_0 = 1.0202e-04
Loss = 1.9727e-03, PNorm = 34.5884, GNorm = 2.0201, lr_0 = 1.0202e-04
Validation rmse logP = 0.648227
Validation R2 logP = 0.876892
Epoch 11
Train function
Loss = 2.7758e-03, PNorm = 34.5913, GNorm = 10.0083, lr_0 = 1.0202e-04
Loss = 1.9846e-03, PNorm = 34.5929, GNorm = 3.0146, lr_0 = 1.0202e-04
Loss = 2.1518e-03, PNorm = 34.5953, GNorm = 9.4307, lr_0 = 1.0202e-04
Loss = 1.8596e-03, PNorm = 34.5974, GNorm = 8.7576, lr_0 = 1.0202e-04
Loss = 2.0212e-03, PNorm = 34.5993, GNorm = 10.7892, lr_0 = 1.0202e-04
Loss = 2.3654e-03, PNorm = 34.6008, GNorm = 3.4196, lr_0 = 1.0202e-04
Loss = 1.8296e-03, PNorm = 34.6032, GNorm = 11.7694, lr_0 = 1.0202e-04
Loss = 2.1366e-03, PNorm = 34.6052, GNorm = 14.4856, lr_0 = 1.0202e-04
Loss = 2.3706e-03, PNorm = 34.6073, GNorm = 4.6136, lr_0 = 1.0202e-04
Loss = 2.5413e-03, PNorm = 34.6092, GNorm = 4.2518, lr_0 = 1.0202e-04
Loss = 1.6437e-03, PNorm = 34.6109, GNorm = 11.6936, lr_0 = 1.0202e-04
Loss = 2.0205e-03, PNorm = 34.6127, GNorm = 9.1068, lr_0 = 1.0202e-04
Loss = 2.6145e-03, PNorm = 34.6135, GNorm = 5.2516, lr_0 = 1.0202e-04
Loss = 2.2495e-03, PNorm = 34.6151, GNorm = 11.9134, lr_0 = 1.0202e-04
Loss = 1.6727e-03, PNorm = 34.6162, GNorm = 7.2560, lr_0 = 1.0202e-04
Loss = 2.0825e-03, PNorm = 34.6188, GNorm = 2.7044, lr_0 = 1.0202e-04
Loss = 2.5131e-03, PNorm = 34.6199, GNorm = 5.1918, lr_0 = 1.0202e-04
Loss = 2.3716e-03, PNorm = 34.6215, GNorm = 2.3169, lr_0 = 1.0202e-04
Loss = 2.0519e-03, PNorm = 34.6233, GNorm = 3.5205, lr_0 = 1.0202e-04
Loss = 2.0851e-03, PNorm = 34.6253, GNorm = 2.0271, lr_0 = 1.0202e-04
Loss = 1.9647e-03, PNorm = 34.6272, GNorm = 7.8722, lr_0 = 1.0202e-04
Loss = 1.8638e-03, PNorm = 34.6287, GNorm = 14.6014, lr_0 = 1.0202e-04
Loss = 2.3684e-03, PNorm = 34.6315, GNorm = 11.7314, lr_0 = 1.0202e-04
Validation rmse logP = 0.668902
Validation R2 logP = 0.868913
Epoch 12
Train function
Loss = 2.2304e-03, PNorm = 34.6333, GNorm = 10.8768, lr_0 = 1.0202e-04
Loss = 2.1407e-03, PNorm = 34.6361, GNorm = 11.8890, lr_0 = 1.0202e-04
Loss = 1.7447e-03, PNorm = 34.6381, GNorm = 3.7508, lr_0 = 1.0202e-04
Loss = 2.1368e-03, PNorm = 34.6406, GNorm = 2.6977, lr_0 = 1.0202e-04
Loss = 2.3562e-03, PNorm = 34.6430, GNorm = 11.1073, lr_0 = 1.0202e-04
Loss = 1.8079e-03, PNorm = 34.6444, GNorm = 2.2668, lr_0 = 1.0202e-04
Loss = 1.8601e-03, PNorm = 34.6466, GNorm = 2.4574, lr_0 = 1.0202e-04
Loss = 2.2749e-03, PNorm = 34.6483, GNorm = 3.6925, lr_0 = 1.0202e-04
Loss = 2.0241e-03, PNorm = 34.6503, GNorm = 4.8700, lr_0 = 1.0202e-04
Loss = 2.1762e-03, PNorm = 34.6520, GNorm = 18.2637, lr_0 = 1.0202e-04
Loss = 1.8496e-03, PNorm = 34.6533, GNorm = 8.9301, lr_0 = 1.0202e-04
Loss = 2.2133e-03, PNorm = 34.6553, GNorm = 3.1932, lr_0 = 1.0202e-04
Loss = 1.7783e-03, PNorm = 34.6577, GNorm = 2.4422, lr_0 = 1.0202e-04
Loss = 1.8751e-03, PNorm = 34.6599, GNorm = 7.4344, lr_0 = 1.0202e-04
Loss = 1.7302e-03, PNorm = 34.6614, GNorm = 8.5270, lr_0 = 1.0202e-04
Loss = 2.1009e-03, PNorm = 34.6627, GNorm = 2.5352, lr_0 = 1.0202e-04
Loss = 2.0782e-03, PNorm = 34.6645, GNorm = 5.4619, lr_0 = 1.0202e-04
Loss = 1.8450e-03, PNorm = 34.6660, GNorm = 2.0707, lr_0 = 1.0202e-04
Loss = 1.8031e-03, PNorm = 34.6682, GNorm = 3.1014, lr_0 = 1.0202e-04
Loss = 2.2399e-03, PNorm = 34.6702, GNorm = 12.0752, lr_0 = 1.0202e-04
Loss = 2.1646e-03, PNorm = 34.6717, GNorm = 3.2188, lr_0 = 1.0202e-04
Loss = 1.8274e-03, PNorm = 34.6731, GNorm = 6.6491, lr_0 = 1.0202e-04
Validation rmse logP = 0.683463
Validation R2 logP = 0.863145
Epoch 13
Train function
Loss = 2.5113e-03, PNorm = 34.6747, GNorm = 17.8675, lr_0 = 1.0202e-04
Loss = 2.1347e-03, PNorm = 34.6767, GNorm = 8.8378, lr_0 = 1.0202e-04
Loss = 2.3977e-03, PNorm = 34.6792, GNorm = 13.1585, lr_0 = 1.0202e-04
Loss = 1.6043e-03, PNorm = 34.6815, GNorm = 2.4968, lr_0 = 1.0202e-04
Loss = 1.6647e-03, PNorm = 34.6834, GNorm = 5.4518, lr_0 = 1.0202e-04
Loss = 1.6781e-03, PNorm = 34.6848, GNorm = 2.2426, lr_0 = 1.0202e-04
Loss = 1.7890e-03, PNorm = 34.6867, GNorm = 3.0335, lr_0 = 1.0202e-04
Loss = 1.9869e-03, PNorm = 34.6887, GNorm = 7.0111, lr_0 = 1.0202e-04
Loss = 1.6098e-03, PNorm = 34.6902, GNorm = 4.5938, lr_0 = 1.0202e-04
Loss = 2.2426e-03, PNorm = 34.6918, GNorm = 2.4871, lr_0 = 1.0202e-04
Loss = 1.5574e-03, PNorm = 34.6934, GNorm = 6.2523, lr_0 = 1.0202e-04
Loss = 1.7738e-03, PNorm = 34.6954, GNorm = 14.2954, lr_0 = 1.0202e-04
Loss = 2.0543e-03, PNorm = 34.6968, GNorm = 6.4621, lr_0 = 1.0202e-04
Loss = 1.8122e-03, PNorm = 34.6992, GNorm = 2.5775, lr_0 = 1.0202e-04
Loss = 1.8410e-03, PNorm = 34.7013, GNorm = 2.2227, lr_0 = 1.0202e-04
Loss = 2.0147e-03, PNorm = 34.7027, GNorm = 18.1662, lr_0 = 1.0202e-04
Loss = 2.1624e-03, PNorm = 34.7041, GNorm = 16.5033, lr_0 = 1.0202e-04
Loss = 2.3295e-03, PNorm = 34.7057, GNorm = 7.4862, lr_0 = 1.0202e-04
Loss = 1.9151e-03, PNorm = 34.7075, GNorm = 7.0291, lr_0 = 1.0202e-04
Loss = 2.3262e-03, PNorm = 34.7094, GNorm = 4.2976, lr_0 = 1.0202e-04
Loss = 1.9630e-03, PNorm = 34.7121, GNorm = 4.5897, lr_0 = 1.0202e-04
Loss = 1.7967e-03, PNorm = 34.7144, GNorm = 2.2145, lr_0 = 1.0202e-04
Validation rmse logP = 0.604799
Validation R2 logP = 0.892835
Epoch 14
Train function
Loss = 1.4707e-03, PNorm = 34.7159, GNorm = 4.1474, lr_0 = 1.0202e-04
Loss = 2.1726e-03, PNorm = 34.7184, GNorm = 7.6761, lr_0 = 1.0202e-04
Loss = 1.8393e-03, PNorm = 34.7211, GNorm = 4.0447, lr_0 = 1.0202e-04
Loss = 1.9051e-03, PNorm = 34.7237, GNorm = 10.3174, lr_0 = 1.0202e-04
Loss = 2.2780e-03, PNorm = 34.7258, GNorm = 6.7663, lr_0 = 1.0202e-04
Loss = 1.9445e-03, PNorm = 34.7272, GNorm = 15.8815, lr_0 = 1.0202e-04
Loss = 1.8845e-03, PNorm = 34.7289, GNorm = 8.0203, lr_0 = 1.0202e-04
Loss = 1.4340e-03, PNorm = 34.7302, GNorm = 8.5415, lr_0 = 1.0202e-04
Loss = 1.7589e-03, PNorm = 34.7312, GNorm = 5.1615, lr_0 = 1.0202e-04
Loss = 1.8304e-03, PNorm = 34.7328, GNorm = 14.4622, lr_0 = 1.0202e-04
Loss = 2.1924e-03, PNorm = 34.7345, GNorm = 10.8440, lr_0 = 1.0202e-04
Loss = 2.1751e-03, PNorm = 34.7358, GNorm = 7.6006, lr_0 = 1.0202e-04
Loss = 1.5570e-03, PNorm = 34.7377, GNorm = 6.0366, lr_0 = 1.0202e-04
Loss = 2.2767e-03, PNorm = 34.7402, GNorm = 7.9395, lr_0 = 1.0202e-04
Loss = 1.7418e-03, PNorm = 34.7433, GNorm = 8.8371, lr_0 = 1.0202e-04
Loss = 1.4400e-03, PNorm = 34.7446, GNorm = 3.2600, lr_0 = 1.0202e-04
Loss = 1.8967e-03, PNorm = 34.7460, GNorm = 4.4806, lr_0 = 1.0202e-04
Loss = 2.2718e-03, PNorm = 34.7482, GNorm = 11.6909, lr_0 = 1.0202e-04
Loss = 2.0914e-03, PNorm = 34.7499, GNorm = 3.9399, lr_0 = 1.0202e-04
Loss = 1.6264e-03, PNorm = 34.7522, GNorm = 3.1621, lr_0 = 1.0202e-04
Loss = 1.6495e-03, PNorm = 34.7534, GNorm = 15.5212, lr_0 = 1.0202e-04
Loss = 2.0572e-03, PNorm = 34.7549, GNorm = 14.0834, lr_0 = 1.0202e-04
Loss = 2.4299e-03, PNorm = 34.7563, GNorm = 21.3157, lr_0 = 1.0202e-04
Validation rmse logP = 0.728515
Validation R2 logP = 0.844508
Epoch 15
Train function
Loss = 2.2787e-03, PNorm = 34.7586, GNorm = 2.7803, lr_0 = 1.0202e-04
Loss = 2.4307e-03, PNorm = 34.7610, GNorm = 8.9113, lr_0 = 1.0202e-04
Loss = 1.7426e-03, PNorm = 34.7622, GNorm = 3.3662, lr_0 = 1.0202e-04
Loss = 1.4560e-03, PNorm = 34.7635, GNorm = 3.0934, lr_0 = 1.0202e-04
Loss = 1.7517e-03, PNorm = 34.7656, GNorm = 2.7319, lr_0 = 1.0202e-04
Loss = 1.9035e-03, PNorm = 34.7676, GNorm = 5.3989, lr_0 = 1.0202e-04
Loss = 1.9358e-03, PNorm = 34.7701, GNorm = 1.9884, lr_0 = 1.0202e-04
Loss = 1.7012e-03, PNorm = 34.7727, GNorm = 16.1676, lr_0 = 1.0202e-04
Loss = 1.7995e-03, PNorm = 34.7753, GNorm = 3.8468, lr_0 = 1.0202e-04
Loss = 1.9722e-03, PNorm = 34.7785, GNorm = 7.0851, lr_0 = 1.0202e-04
Loss = 1.9690e-03, PNorm = 34.7799, GNorm = 10.4136, lr_0 = 1.0202e-04
Loss = 2.0345e-03, PNorm = 34.7822, GNorm = 11.4839, lr_0 = 1.0202e-04
Loss = 1.9095e-03, PNorm = 34.7835, GNorm = 3.2823, lr_0 = 1.0202e-04
Loss = 2.0718e-03, PNorm = 34.7861, GNorm = 5.2363, lr_0 = 1.0202e-04
Loss = 1.7039e-03, PNorm = 34.7873, GNorm = 5.5315, lr_0 = 1.0202e-04
Loss = 1.6596e-03, PNorm = 34.7892, GNorm = 6.6152, lr_0 = 1.0202e-04
Loss = 1.8724e-03, PNorm = 34.7908, GNorm = 2.1654, lr_0 = 1.0202e-04
Loss = 1.8889e-03, PNorm = 34.7925, GNorm = 9.7988, lr_0 = 1.0202e-04
Loss = 1.7867e-03, PNorm = 34.7941, GNorm = 3.6947, lr_0 = 1.0202e-04
Loss = 1.9304e-03, PNorm = 34.7958, GNorm = 4.3770, lr_0 = 1.0202e-04
Loss = 1.8656e-03, PNorm = 34.7975, GNorm = 8.0428, lr_0 = 1.0202e-04
Loss = 2.3132e-03, PNorm = 34.7993, GNorm = 3.6183, lr_0 = 1.0202e-04
Validation rmse logP = 0.589096
Validation R2 logP = 0.898327
Epoch 16
Train function
Loss = 1.9962e-03, PNorm = 34.8010, GNorm = 8.3367, lr_0 = 1.0202e-04
Loss = 1.6306e-03, PNorm = 34.8026, GNorm = 10.5656, lr_0 = 1.0202e-04
Loss = 1.8341e-03, PNorm = 34.8052, GNorm = 12.0174, lr_0 = 1.0202e-04
Loss = 1.8875e-03, PNorm = 34.8077, GNorm = 9.4188, lr_0 = 1.0202e-04
Loss = 1.7984e-03, PNorm = 34.8094, GNorm = 2.8301, lr_0 = 1.0202e-04
Loss = 1.3605e-03, PNorm = 34.8105, GNorm = 1.9936, lr_0 = 1.0202e-04
Loss = 1.6952e-03, PNorm = 34.8128, GNorm = 2.5000, lr_0 = 1.0202e-04
Loss = 1.8834e-03, PNorm = 34.8155, GNorm = 9.4729, lr_0 = 1.0202e-04
Loss = 2.0716e-03, PNorm = 34.8177, GNorm = 2.4743, lr_0 = 1.0202e-04
Loss = 1.3485e-03, PNorm = 34.8205, GNorm = 1.0776, lr_0 = 1.0202e-04
Loss = 1.5885e-03, PNorm = 34.8221, GNorm = 5.8863, lr_0 = 1.0202e-04
Loss = 1.5822e-03, PNorm = 34.8236, GNorm = 1.6773, lr_0 = 1.0202e-04
Loss = 1.5756e-03, PNorm = 34.8246, GNorm = 3.3846, lr_0 = 1.0202e-04
Loss = 1.5987e-03, PNorm = 34.8260, GNorm = 5.1443, lr_0 = 1.0202e-04
Loss = 1.5553e-03, PNorm = 34.8279, GNorm = 8.5947, lr_0 = 1.0202e-04
Loss = 1.5886e-03, PNorm = 34.8301, GNorm = 3.2062, lr_0 = 1.0202e-04
Loss = 1.4994e-03, PNorm = 34.8321, GNorm = 2.2368, lr_0 = 1.0202e-04
Loss = 1.9492e-03, PNorm = 34.8345, GNorm = 15.3372, lr_0 = 1.0202e-04
Loss = 2.0504e-03, PNorm = 34.8358, GNorm = 12.6934, lr_0 = 1.0202e-04
Loss = 1.6622e-03, PNorm = 34.8380, GNorm = 9.0972, lr_0 = 1.0202e-04
Loss = 2.1565e-03, PNorm = 34.8399, GNorm = 5.9624, lr_0 = 1.0202e-04
Loss = 2.1232e-03, PNorm = 34.8418, GNorm = 2.7836, lr_0 = 1.0202e-04
Loss = 2.4055e-03, PNorm = 34.8437, GNorm = 13.6814, lr_0 = 1.0202e-04
Validation rmse logP = 0.561454
Validation R2 logP = 0.907645
Epoch 17
Train function
Loss = 1.9327e-03, PNorm = 34.8462, GNorm = 8.3127, lr_0 = 1.0202e-04
Loss = 1.5447e-03, PNorm = 34.8480, GNorm = 9.7930, lr_0 = 1.0202e-04
Loss = 1.7489e-03, PNorm = 34.8496, GNorm = 2.8745, lr_0 = 1.0202e-04
Loss = 1.4151e-03, PNorm = 34.8511, GNorm = 1.5820, lr_0 = 1.0202e-04
Loss = 1.8789e-03, PNorm = 34.8531, GNorm = 3.8713, lr_0 = 1.0202e-04
Loss = 1.6267e-03, PNorm = 34.8552, GNorm = 5.5371, lr_0 = 1.0202e-04
Loss = 1.3344e-03, PNorm = 34.8576, GNorm = 1.8693, lr_0 = 1.0202e-04
Loss = 1.4471e-03, PNorm = 34.8593, GNorm = 3.7551, lr_0 = 1.0202e-04
Loss = 1.7709e-03, PNorm = 34.8613, GNorm = 10.4332, lr_0 = 1.0202e-04
Loss = 1.9135e-03, PNorm = 34.8630, GNorm = 2.9872, lr_0 = 1.0202e-04
Loss = 1.9064e-03, PNorm = 34.8648, GNorm = 6.6241, lr_0 = 1.0202e-04
Loss = 1.4685e-03, PNorm = 34.8663, GNorm = 6.6782, lr_0 = 1.0202e-04
Loss = 1.7179e-03, PNorm = 34.8688, GNorm = 13.9869, lr_0 = 1.0202e-04
Loss = 1.9514e-03, PNorm = 34.8709, GNorm = 8.7660, lr_0 = 1.0202e-04
Loss = 1.8685e-03, PNorm = 34.8731, GNorm = 14.0009, lr_0 = 1.0202e-04
Loss = 2.2895e-03, PNorm = 34.8743, GNorm = 21.7919, lr_0 = 1.0202e-04
Loss = 1.9258e-03, PNorm = 34.8765, GNorm = 2.2524, lr_0 = 1.0202e-04
Loss = 1.8096e-03, PNorm = 34.8781, GNorm = 2.4477, lr_0 = 1.0202e-04
Loss = 2.0028e-03, PNorm = 34.8797, GNorm = 13.6166, lr_0 = 1.0202e-04
Loss = 2.1884e-03, PNorm = 34.8820, GNorm = 7.1715, lr_0 = 1.0202e-04
Loss = 1.7238e-03, PNorm = 34.8837, GNorm = 6.2272, lr_0 = 1.0202e-04
Loss = 1.8742e-03, PNorm = 34.8855, GNorm = 2.8046, lr_0 = 1.0202e-04
Validation rmse logP = 0.625071
Validation R2 logP = 0.885530
Epoch 18
Train function
Loss = 1.8544e-03, PNorm = 34.8872, GNorm = 8.8633, lr_0 = 1.0202e-04
Loss = 1.5808e-03, PNorm = 34.8894, GNorm = 3.5671, lr_0 = 1.0202e-04
Loss = 1.4607e-03, PNorm = 34.8914, GNorm = 8.9149, lr_0 = 1.0202e-04
Loss = 1.6615e-03, PNorm = 34.8934, GNorm = 7.7711, lr_0 = 1.0202e-04
Loss = 1.4797e-03, PNorm = 34.8953, GNorm = 5.5752, lr_0 = 1.0202e-04
Loss = 1.4262e-03, PNorm = 34.8978, GNorm = 11.7597, lr_0 = 1.0202e-04
Loss = 1.4961e-03, PNorm = 34.8996, GNorm = 2.0430, lr_0 = 1.0202e-04
Loss = 1.5541e-03, PNorm = 34.9017, GNorm = 7.2057, lr_0 = 1.0202e-04
Loss = 1.9396e-03, PNorm = 34.9036, GNorm = 6.0754, lr_0 = 1.0202e-04
Loss = 2.0845e-03, PNorm = 34.9051, GNorm = 5.6046, lr_0 = 1.0202e-04
Loss = 1.9415e-03, PNorm = 34.9055, GNorm = 16.6493, lr_0 = 1.0202e-04
Loss = 1.6220e-03, PNorm = 34.9077, GNorm = 10.4097, lr_0 = 1.0202e-04
Loss = 1.6303e-03, PNorm = 34.9090, GNorm = 2.4563, lr_0 = 1.0202e-04
Loss = 1.7342e-03, PNorm = 34.9106, GNorm = 12.7126, lr_0 = 1.0202e-04
Loss = 1.8821e-03, PNorm = 34.9132, GNorm = 3.1851, lr_0 = 1.0202e-04
Loss = 1.5927e-03, PNorm = 34.9161, GNorm = 4.0352, lr_0 = 1.0202e-04
Loss = 1.7162e-03, PNorm = 34.9179, GNorm = 13.9819, lr_0 = 1.0202e-04
Loss = 1.8956e-03, PNorm = 34.9184, GNorm = 16.8191, lr_0 = 1.0202e-04
Loss = 1.7797e-03, PNorm = 34.9201, GNorm = 6.2240, lr_0 = 1.0202e-04
Loss = 2.0101e-03, PNorm = 34.9223, GNorm = 17.0358, lr_0 = 1.0202e-04
Loss = 2.6852e-03, PNorm = 34.9235, GNorm = 3.8080, lr_0 = 1.0202e-04
Loss = 2.0175e-03, PNorm = 34.9255, GNorm = 5.7570, lr_0 = 1.0202e-04
Validation rmse logP = 0.572752
Validation R2 logP = 0.903891
Epoch 19
Train function
Loss = 1.3872e-03, PNorm = 34.9277, GNorm = 6.2109, lr_0 = 1.0202e-04
Loss = 1.5506e-03, PNorm = 34.9289, GNorm = 1.1733, lr_0 = 1.0202e-04
Loss = 1.5250e-03, PNorm = 34.9307, GNorm = 6.4893, lr_0 = 1.0202e-04
Loss = 1.7390e-03, PNorm = 34.9319, GNorm = 5.8875, lr_0 = 1.0202e-04
Loss = 1.7085e-03, PNorm = 34.9343, GNorm = 2.2862, lr_0 = 1.0202e-04
Loss = 1.4698e-03, PNorm = 34.9363, GNorm = 2.2109, lr_0 = 1.0202e-04
Loss = 1.5396e-03, PNorm = 34.9379, GNorm = 10.0668, lr_0 = 1.0202e-04
Loss = 1.8264e-03, PNorm = 34.9402, GNorm = 6.4604, lr_0 = 1.0202e-04
Loss = 1.7042e-03, PNorm = 34.9424, GNorm = 2.4785, lr_0 = 1.0202e-04
Loss = 1.7607e-03, PNorm = 34.9440, GNorm = 5.9111, lr_0 = 1.0202e-04
Loss = 1.5177e-03, PNorm = 34.9461, GNorm = 2.9631, lr_0 = 1.0202e-04
Loss = 1.3649e-03, PNorm = 34.9477, GNorm = 5.8855, lr_0 = 1.0202e-04
Loss = 1.3798e-03, PNorm = 34.9492, GNorm = 4.7162, lr_0 = 1.0202e-04
Loss = 2.1123e-03, PNorm = 34.9513, GNorm = 5.1881, lr_0 = 1.0202e-04
Loss = 1.5799e-03, PNorm = 34.9535, GNorm = 3.8408, lr_0 = 1.0202e-04
Loss = 1.7704e-03, PNorm = 34.9553, GNorm = 5.4486, lr_0 = 1.0202e-04
Loss = 1.3532e-03, PNorm = 34.9563, GNorm = 4.7671, lr_0 = 1.0202e-04
Loss = 1.0292e-03, PNorm = 34.9584, GNorm = 3.7850, lr_0 = 1.0202e-04
Loss = 1.7812e-03, PNorm = 34.9605, GNorm = 5.3025, lr_0 = 1.0202e-04
Loss = 1.8278e-03, PNorm = 34.9624, GNorm = 1.7612, lr_0 = 1.0202e-04
Loss = 1.4476e-03, PNorm = 34.9641, GNorm = 1.6266, lr_0 = 1.0202e-04
Loss = 1.4508e-03, PNorm = 34.9657, GNorm = 2.5511, lr_0 = 1.0202e-04
Loss = 1.2807e-03, PNorm = 34.9672, GNorm = 2.5310, lr_0 = 1.0202e-04
Loss = 5.2202e-03, PNorm = 34.9673, GNorm = 10.8515, lr_0 = 1.0202e-04
Validation rmse logP = 0.543162
Validation R2 logP = 0.913565
Epoch 20
Train function
Loss = 1.2268e-03, PNorm = 34.9696, GNorm = 5.1734, lr_0 = 1.0202e-04
Loss = 1.4909e-03, PNorm = 34.9713, GNorm = 4.1226, lr_0 = 1.0202e-04
Loss = 1.2410e-03, PNorm = 34.9726, GNorm = 1.7448, lr_0 = 1.0202e-04
Loss = 1.2238e-03, PNorm = 34.9744, GNorm = 9.0096, lr_0 = 1.0202e-04
Loss = 1.5409e-03, PNorm = 34.9767, GNorm = 23.5756, lr_0 = 1.0202e-04
Loss = 1.7237e-03, PNorm = 34.9784, GNorm = 14.6043, lr_0 = 1.0202e-04
Loss = 1.8835e-03, PNorm = 34.9803, GNorm = 8.8917, lr_0 = 1.0202e-04
Loss = 1.5488e-03, PNorm = 34.9817, GNorm = 11.8216, lr_0 = 1.0202e-04
Loss = 2.2315e-03, PNorm = 34.9838, GNorm = 2.4790, lr_0 = 1.0202e-04
Loss = 1.6290e-03, PNorm = 34.9867, GNorm = 2.6348, lr_0 = 1.0202e-04
Loss = 1.6249e-03, PNorm = 34.9891, GNorm = 2.5846, lr_0 = 1.0202e-04
Loss = 1.6307e-03, PNorm = 34.9917, GNorm = 5.3097, lr_0 = 1.0202e-04
Loss = 1.5126e-03, PNorm = 34.9940, GNorm = 3.5760, lr_0 = 1.0202e-04
Loss = 2.0086e-03, PNorm = 34.9951, GNorm = 19.0544, lr_0 = 1.0202e-04
Loss = 1.4616e-03, PNorm = 34.9960, GNorm = 4.3148, lr_0 = 1.0202e-04
Loss = 1.3567e-03, PNorm = 34.9978, GNorm = 4.6704, lr_0 = 1.0202e-04
Loss = 1.5379e-03, PNorm = 34.9997, GNorm = 9.3504, lr_0 = 1.0202e-04
Loss = 1.6062e-03, PNorm = 35.0015, GNorm = 11.2562, lr_0 = 1.0202e-04
Loss = 1.5424e-03, PNorm = 35.0028, GNorm = 2.5121, lr_0 = 1.0202e-04
Loss = 2.0305e-03, PNorm = 35.0038, GNorm = 5.4758, lr_0 = 1.0202e-04
Loss = 1.6702e-03, PNorm = 35.0059, GNorm = 2.8869, lr_0 = 1.0202e-04
Loss = 1.7329e-03, PNorm = 35.0084, GNorm = 5.5193, lr_0 = 1.0202e-04
Validation rmse logP = 0.553311
Validation R2 logP = 0.910304
Epoch 21
Train function
Loss = 1.5994e-03, PNorm = 35.0103, GNorm = 5.5797, lr_0 = 1.0202e-04
Loss = 1.6372e-03, PNorm = 35.0123, GNorm = 7.3100, lr_0 = 1.0202e-04
Loss = 1.6504e-03, PNorm = 35.0138, GNorm = 4.4846, lr_0 = 1.0202e-04
Loss = 1.6751e-03, PNorm = 35.0161, GNorm = 5.8466, lr_0 = 1.0202e-04
Loss = 1.5080e-03, PNorm = 35.0181, GNorm = 6.4787, lr_0 = 1.0202e-04
Loss = 1.5178e-03, PNorm = 35.0206, GNorm = 8.7784, lr_0 = 1.0202e-04
Loss = 1.6076e-03, PNorm = 35.0225, GNorm = 1.9271, lr_0 = 1.0202e-04
Loss = 1.4306e-03, PNorm = 35.0249, GNorm = 6.9036, lr_0 = 1.0202e-04
Loss = 1.9758e-03, PNorm = 35.0263, GNorm = 8.3988, lr_0 = 1.0202e-04
Loss = 1.4976e-03, PNorm = 35.0284, GNorm = 6.6290, lr_0 = 1.0202e-04
Loss = 1.7228e-03, PNorm = 35.0300, GNorm = 1.9808, lr_0 = 1.0202e-04
Loss = 1.5849e-03, PNorm = 35.0329, GNorm = 15.2841, lr_0 = 1.0202e-04
Loss = 1.8464e-03, PNorm = 35.0345, GNorm = 8.6690, lr_0 = 1.0202e-04
Loss = 1.3906e-03, PNorm = 35.0365, GNorm = 2.3183, lr_0 = 1.0202e-04
Loss = 1.4623e-03, PNorm = 35.0378, GNorm = 3.1176, lr_0 = 1.0202e-04
Loss = 1.5695e-03, PNorm = 35.0394, GNorm = 12.2906, lr_0 = 1.0202e-04
Loss = 1.6265e-03, PNorm = 35.0414, GNorm = 2.5848, lr_0 = 1.0202e-04
Loss = 1.2869e-03, PNorm = 35.0434, GNorm = 5.2601, lr_0 = 1.0202e-04
Loss = 1.4861e-03, PNorm = 35.0443, GNorm = 12.3905, lr_0 = 1.0202e-04
Loss = 1.4111e-03, PNorm = 35.0458, GNorm = 5.6097, lr_0 = 1.0202e-04
Loss = 1.5830e-03, PNorm = 35.0479, GNorm = 6.6528, lr_0 = 1.0202e-04
Loss = 1.3302e-03, PNorm = 35.0495, GNorm = 10.1960, lr_0 = 1.0202e-04
Validation rmse logP = 0.564275
Validation R2 logP = 0.906715
Epoch 22
Train function
Loss = 2.1536e-03, PNorm = 35.0513, GNorm = 14.8310, lr_0 = 1.0202e-04
Loss = 1.5729e-03, PNorm = 35.0535, GNorm = 7.3271, lr_0 = 1.0202e-04
Loss = 1.2294e-03, PNorm = 35.0554, GNorm = 3.1047, lr_0 = 1.0202e-04
Loss = 1.5530e-03, PNorm = 35.0579, GNorm = 7.6349, lr_0 = 1.0202e-04
Loss = 1.2814e-03, PNorm = 35.0598, GNorm = 2.7029, lr_0 = 1.0202e-04
Loss = 1.4955e-03, PNorm = 35.0618, GNorm = 8.5445, lr_0 = 1.0202e-04
Loss = 1.8337e-03, PNorm = 35.0635, GNorm = 8.2268, lr_0 = 1.0202e-04
Loss = 1.5711e-03, PNorm = 35.0655, GNorm = 3.1919, lr_0 = 1.0202e-04
Loss = 1.3924e-03, PNorm = 35.0670, GNorm = 10.3656, lr_0 = 1.0202e-04
Loss = 1.4714e-03, PNorm = 35.0687, GNorm = 5.8806, lr_0 = 1.0202e-04
Loss = 1.5339e-03, PNorm = 35.0706, GNorm = 10.9837, lr_0 = 1.0202e-04
Loss = 1.0958e-03, PNorm = 35.0723, GNorm = 11.0871, lr_0 = 1.0202e-04
Loss = 2.1164e-03, PNorm = 35.0736, GNorm = 6.2730, lr_0 = 1.0202e-04
Loss = 1.3715e-03, PNorm = 35.0755, GNorm = 3.6206, lr_0 = 1.0202e-04
Loss = 1.5149e-03, PNorm = 35.0768, GNorm = 2.7498, lr_0 = 1.0202e-04
Loss = 1.5967e-03, PNorm = 35.0788, GNorm = 6.4407, lr_0 = 1.0202e-04
Loss = 1.3608e-03, PNorm = 35.0801, GNorm = 3.0078, lr_0 = 1.0202e-04
Loss = 1.3171e-03, PNorm = 35.0817, GNorm = 3.5988, lr_0 = 1.0202e-04
Loss = 1.1812e-03, PNorm = 35.0831, GNorm = 1.5708, lr_0 = 1.0202e-04
Loss = 1.6898e-03, PNorm = 35.0850, GNorm = 9.6522, lr_0 = 1.0202e-04
Loss = 1.2107e-03, PNorm = 35.0869, GNorm = 2.0005, lr_0 = 1.0202e-04
Loss = 1.4304e-03, PNorm = 35.0886, GNorm = 7.9463, lr_0 = 1.0202e-04
Loss = 1.4788e-03, PNorm = 35.0899, GNorm = 5.1720, lr_0 = 1.0202e-04
Validation rmse logP = 0.572165
Validation R2 logP = 0.904087
Epoch 23
Train function
Loss = 1.1035e-03, PNorm = 35.0915, GNorm = 10.6612, lr_0 = 1.0202e-04
Loss = 1.6246e-03, PNorm = 35.0933, GNorm = 11.1153, lr_0 = 1.0202e-04
Loss = 1.4985e-03, PNorm = 35.0950, GNorm = 2.3093, lr_0 = 1.0202e-04
Loss = 1.3528e-03, PNorm = 35.0969, GNorm = 4.5431, lr_0 = 1.0202e-04
Loss = 1.4390e-03, PNorm = 35.0982, GNorm = 7.5210, lr_0 = 1.0202e-04
Loss = 1.5967e-03, PNorm = 35.1004, GNorm = 9.7566, lr_0 = 1.0202e-04
Loss = 1.2783e-03, PNorm = 35.1015, GNorm = 8.7633, lr_0 = 1.0202e-04
Loss = 1.1046e-03, PNorm = 35.1028, GNorm = 3.6301, lr_0 = 1.0202e-04
Loss = 1.3073e-03, PNorm = 35.1045, GNorm = 1.8119, lr_0 = 1.0202e-04
Loss = 1.3948e-03, PNorm = 35.1066, GNorm = 2.9081, lr_0 = 1.0202e-04
Loss = 1.4328e-03, PNorm = 35.1087, GNorm = 6.9548, lr_0 = 1.0202e-04
Loss = 1.5566e-03, PNorm = 35.1113, GNorm = 9.8195, lr_0 = 1.0202e-04
Loss = 1.3411e-03, PNorm = 35.1133, GNorm = 6.3526, lr_0 = 1.0202e-04
Loss = 1.3882e-03, PNorm = 35.1151, GNorm = 1.8056, lr_0 = 1.0202e-04
Loss = 1.5191e-03, PNorm = 35.1171, GNorm = 2.3945, lr_0 = 1.0202e-04
Loss = 1.4467e-03, PNorm = 35.1200, GNorm = 1.8162, lr_0 = 1.0202e-04
Loss = 1.4622e-03, PNorm = 35.1219, GNorm = 3.8575, lr_0 = 1.0202e-04
Loss = 1.2928e-03, PNorm = 35.1237, GNorm = 2.9463, lr_0 = 1.0202e-04
Loss = 1.5974e-03, PNorm = 35.1243, GNorm = 9.9270, lr_0 = 1.0202e-04
Loss = 1.3900e-03, PNorm = 35.1259, GNorm = 1.9845, lr_0 = 1.0202e-04
Loss = 1.6659e-03, PNorm = 35.1287, GNorm = 12.7060, lr_0 = 1.0202e-04
Loss = 1.4160e-03, PNorm = 35.1310, GNorm = 11.1520, lr_0 = 1.0202e-04
Validation rmse logP = 0.597122
Validation R2 logP = 0.895538
Epoch 24
Train function
Loss = 1.7373e-03, PNorm = 35.1330, GNorm = 17.0343, lr_0 = 1.0202e-04
Loss = 1.7219e-03, PNorm = 35.1348, GNorm = 18.1156, lr_0 = 1.0202e-04
Loss = 1.7993e-03, PNorm = 35.1367, GNorm = 8.5576, lr_0 = 1.0202e-04
Loss = 2.1844e-03, PNorm = 35.1375, GNorm = 6.8287, lr_0 = 1.0202e-04
Loss = 1.7846e-03, PNorm = 35.1399, GNorm = 6.1723, lr_0 = 1.0202e-04
Loss = 1.4913e-03, PNorm = 35.1412, GNorm = 7.3008, lr_0 = 1.0202e-04
Loss = 1.1341e-03, PNorm = 35.1427, GNorm = 4.4713, lr_0 = 1.0202e-04
Loss = 1.2273e-03, PNorm = 35.1450, GNorm = 1.1049, lr_0 = 1.0202e-04
Loss = 1.4218e-03, PNorm = 35.1475, GNorm = 9.5602, lr_0 = 1.0202e-04
Loss = 1.7941e-03, PNorm = 35.1493, GNorm = 8.4405, lr_0 = 1.0202e-04
Loss = 1.4338e-03, PNorm = 35.1524, GNorm = 2.2171, lr_0 = 1.0202e-04
Loss = 1.2940e-03, PNorm = 35.1543, GNorm = 3.1199, lr_0 = 1.0202e-04
Loss = 1.1945e-03, PNorm = 35.1563, GNorm = 2.8551, lr_0 = 1.0202e-04
Loss = 1.3032e-03, PNorm = 35.1580, GNorm = 5.7935, lr_0 = 1.0202e-04
Loss = 1.6329e-03, PNorm = 35.1601, GNorm = 3.4704, lr_0 = 1.0202e-04
Loss = 1.3769e-03, PNorm = 35.1614, GNorm = 7.2869, lr_0 = 1.0202e-04
Loss = 1.2710e-03, PNorm = 35.1627, GNorm = 7.7177, lr_0 = 1.0202e-04
Loss = 1.6335e-03, PNorm = 35.1645, GNorm = 3.3539, lr_0 = 1.0202e-04
Loss = 1.6891e-03, PNorm = 35.1658, GNorm = 1.6819, lr_0 = 1.0202e-04
Loss = 1.3217e-03, PNorm = 35.1679, GNorm = 3.4557, lr_0 = 1.0202e-04
Loss = 1.1798e-03, PNorm = 35.1696, GNorm = 5.2216, lr_0 = 1.0202e-04
Loss = 1.5941e-03, PNorm = 35.1717, GNorm = 13.5528, lr_0 = 1.0202e-04
Validation rmse logP = 0.605574
Validation R2 logP = 0.892560
Epoch 25
Train function
Loss = 1.4871e-03, PNorm = 35.1731, GNorm = 10.2472, lr_0 = 1.0202e-04
Loss = 1.6353e-03, PNorm = 35.1746, GNorm = 6.3389, lr_0 = 1.0202e-04
Loss = 1.5254e-03, PNorm = 35.1771, GNorm = 9.0797, lr_0 = 1.0202e-04
Loss = 1.3856e-03, PNorm = 35.1793, GNorm = 2.9625, lr_0 = 1.0202e-04
Loss = 1.4083e-03, PNorm = 35.1813, GNorm = 7.2772, lr_0 = 1.0202e-04
Loss = 1.6106e-03, PNorm = 35.1836, GNorm = 5.4823, lr_0 = 1.0202e-04
Loss = 1.6128e-03, PNorm = 35.1857, GNorm = 3.0313, lr_0 = 1.0202e-04
Loss = 1.4688e-03, PNorm = 35.1880, GNorm = 16.7136, lr_0 = 1.0202e-04
Loss = 1.4889e-03, PNorm = 35.1893, GNorm = 6.6692, lr_0 = 1.0202e-04
Loss = 1.6035e-03, PNorm = 35.1914, GNorm = 3.8697, lr_0 = 1.0202e-04
Loss = 1.2090e-03, PNorm = 35.1927, GNorm = 3.8551, lr_0 = 1.0202e-04
Loss = 1.2087e-03, PNorm = 35.1945, GNorm = 3.2791, lr_0 = 1.0202e-04
Loss = 1.2431e-03, PNorm = 35.1957, GNorm = 3.5777, lr_0 = 1.0202e-04
Loss = 1.4379e-03, PNorm = 35.1972, GNorm = 2.3117, lr_0 = 1.0202e-04
Loss = 1.6122e-03, PNorm = 35.1989, GNorm = 3.9446, lr_0 = 1.0202e-04
Loss = 1.7148e-03, PNorm = 35.2014, GNorm = 9.6865, lr_0 = 1.0202e-04
Loss = 1.4181e-03, PNorm = 35.2035, GNorm = 1.7731, lr_0 = 1.0202e-04
Loss = 1.2272e-03, PNorm = 35.2056, GNorm = 5.1995, lr_0 = 1.0202e-04
Loss = 1.6266e-03, PNorm = 35.2074, GNorm = 4.7166, lr_0 = 1.0202e-04
Loss = 1.3144e-03, PNorm = 35.2094, GNorm = 7.8344, lr_0 = 1.0202e-04
Loss = 1.4832e-03, PNorm = 35.2109, GNorm = 11.7667, lr_0 = 1.0202e-04
Loss = 1.5748e-03, PNorm = 35.2120, GNorm = 9.3176, lr_0 = 1.0202e-04
Loss = 1.1293e-03, PNorm = 35.2136, GNorm = 5.6028, lr_0 = 1.0202e-04
Validation rmse logP = 0.521197
Validation R2 logP = 0.920414
Epoch 26
Train function
Loss = 1.4403e-03, PNorm = 35.2157, GNorm = 8.0386, lr_0 = 1.0202e-04
Loss = 1.7370e-03, PNorm = 35.2173, GNorm = 10.7696, lr_0 = 1.0202e-04
Loss = 1.7544e-03, PNorm = 35.2198, GNorm = 2.3600, lr_0 = 1.0202e-04
Loss = 1.4174e-03, PNorm = 35.2217, GNorm = 6.0367, lr_0 = 1.0202e-04
Loss = 1.3738e-03, PNorm = 35.2248, GNorm = 3.1110, lr_0 = 1.0202e-04
Loss = 1.2951e-03, PNorm = 35.2262, GNorm = 5.9284, lr_0 = 1.0202e-04
Loss = 1.5783e-03, PNorm = 35.2279, GNorm = 10.3322, lr_0 = 1.0202e-04
Loss = 1.1482e-03, PNorm = 35.2291, GNorm = 4.1234, lr_0 = 1.0202e-04
Loss = 1.3669e-03, PNorm = 35.2299, GNorm = 12.9817, lr_0 = 1.0202e-04
Loss = 1.7431e-03, PNorm = 35.2313, GNorm = 6.7368, lr_0 = 1.0202e-04
Loss = 1.1984e-03, PNorm = 35.2340, GNorm = 7.3338, lr_0 = 1.0202e-04
Loss = 1.3056e-03, PNorm = 35.2356, GNorm = 2.5135, lr_0 = 1.0202e-04
Loss = 1.1927e-03, PNorm = 35.2373, GNorm = 4.8639, lr_0 = 1.0202e-04
Loss = 1.1982e-03, PNorm = 35.2399, GNorm = 4.1493, lr_0 = 1.0202e-04
Loss = 1.6497e-03, PNorm = 35.2417, GNorm = 2.4565, lr_0 = 1.0202e-04
Loss = 1.2739e-03, PNorm = 35.2437, GNorm = 5.0338, lr_0 = 1.0202e-04
Loss = 1.0909e-03, PNorm = 35.2456, GNorm = 1.4050, lr_0 = 1.0202e-04
Loss = 1.3093e-03, PNorm = 35.2475, GNorm = 5.4046, lr_0 = 1.0202e-04
Loss = 1.1539e-03, PNorm = 35.2497, GNorm = 4.9831, lr_0 = 1.0202e-04
Loss = 1.2871e-03, PNorm = 35.2518, GNorm = 1.8923, lr_0 = 1.0202e-04
Loss = 1.2619e-03, PNorm = 35.2536, GNorm = 7.5779, lr_0 = 1.0202e-04
Loss = 1.3582e-03, PNorm = 35.2552, GNorm = 2.5896, lr_0 = 1.0202e-04
Validation rmse logP = 0.511455
Validation R2 logP = 0.923361
Epoch 27
Train function
Loss = 8.2176e-04, PNorm = 35.2561, GNorm = 4.0327, lr_0 = 1.0202e-04
Loss = 1.0743e-03, PNorm = 35.2574, GNorm = 1.6218, lr_0 = 1.0202e-04
Loss = 1.0580e-03, PNorm = 35.2586, GNorm = 3.8196, lr_0 = 1.0202e-04
Loss = 1.1991e-03, PNorm = 35.2600, GNorm = 3.4696, lr_0 = 1.0202e-04
Loss = 1.1513e-03, PNorm = 35.2615, GNorm = 3.2847, lr_0 = 1.0202e-04
Loss = 1.4636e-03, PNorm = 35.2631, GNorm = 5.2408, lr_0 = 1.0202e-04
Loss = 1.5669e-03, PNorm = 35.2649, GNorm = 2.2544, lr_0 = 1.0202e-04
Loss = 1.3033e-03, PNorm = 35.2659, GNorm = 10.4337, lr_0 = 1.0202e-04
Loss = 1.3749e-03, PNorm = 35.2675, GNorm = 6.0200, lr_0 = 1.0202e-04
Loss = 1.6386e-03, PNorm = 35.2690, GNorm = 11.8837, lr_0 = 1.0202e-04
Loss = 1.4480e-03, PNorm = 35.2705, GNorm = 3.3755, lr_0 = 1.0202e-04
Loss = 1.5326e-03, PNorm = 35.2725, GNorm = 2.3414, lr_0 = 1.0202e-04
Loss = 1.2028e-03, PNorm = 35.2748, GNorm = 1.9540, lr_0 = 1.0202e-04
Loss = 1.3327e-03, PNorm = 35.2768, GNorm = 4.4854, lr_0 = 1.0202e-04
Loss = 1.0964e-03, PNorm = 35.2786, GNorm = 2.5758, lr_0 = 1.0202e-04
Loss = 1.2806e-03, PNorm = 35.2803, GNorm = 2.6530, lr_0 = 1.0202e-04
Loss = 9.9163e-04, PNorm = 35.2817, GNorm = 4.3030, lr_0 = 1.0202e-04
Loss = 1.2641e-03, PNorm = 35.2841, GNorm = 6.2031, lr_0 = 1.0202e-04
Loss = 1.3001e-03, PNorm = 35.2866, GNorm = 3.3852, lr_0 = 1.0202e-04
Loss = 1.4017e-03, PNorm = 35.2893, GNorm = 7.5261, lr_0 = 1.0202e-04
Loss = 1.2071e-03, PNorm = 35.2919, GNorm = 8.1840, lr_0 = 1.0202e-04
Loss = 1.2455e-03, PNorm = 35.2943, GNorm = 10.4479, lr_0 = 1.0202e-04
Validation rmse logP = 0.517864
Validation R2 logP = 0.921429
Epoch 28
Train function
Loss = 7.7189e-04, PNorm = 35.2953, GNorm = 3.1450, lr_0 = 1.0202e-04
Loss = 1.3399e-03, PNorm = 35.2975, GNorm = 11.4868, lr_0 = 1.0202e-04
Loss = 1.3814e-03, PNorm = 35.2993, GNorm = 3.9397, lr_0 = 1.0202e-04
Loss = 1.1267e-03, PNorm = 35.3005, GNorm = 4.2107, lr_0 = 1.0202e-04
Loss = 1.2954e-03, PNorm = 35.3017, GNorm = 3.6045, lr_0 = 1.0202e-04
Loss = 1.4698e-03, PNorm = 35.3041, GNorm = 2.4020, lr_0 = 1.0202e-04
Loss = 1.4060e-03, PNorm = 35.3063, GNorm = 2.6961, lr_0 = 1.0202e-04
Loss = 1.1966e-03, PNorm = 35.3084, GNorm = 2.9350, lr_0 = 1.0202e-04
Loss = 1.5701e-03, PNorm = 35.3092, GNorm = 4.2124, lr_0 = 1.0202e-04
Loss = 1.4497e-03, PNorm = 35.3109, GNorm = 2.6034, lr_0 = 1.0202e-04
Loss = 1.4831e-03, PNorm = 35.3121, GNorm = 5.9224, lr_0 = 1.0202e-04
Loss = 1.0872e-03, PNorm = 35.3142, GNorm = 10.1728, lr_0 = 1.0202e-04
Loss = 1.1151e-03, PNorm = 35.3160, GNorm = 1.7703, lr_0 = 1.0202e-04
Loss = 1.2362e-03, PNorm = 35.3179, GNorm = 6.7119, lr_0 = 1.0202e-04
Loss = 9.6593e-04, PNorm = 35.3196, GNorm = 5.5336, lr_0 = 1.0202e-04
Loss = 1.6479e-03, PNorm = 35.3224, GNorm = 5.6284, lr_0 = 1.0202e-04
Loss = 1.4239e-03, PNorm = 35.3246, GNorm = 5.2907, lr_0 = 1.0202e-04
Loss = 1.1927e-03, PNorm = 35.3269, GNorm = 2.7000, lr_0 = 1.0202e-04
Loss = 1.3564e-03, PNorm = 35.3288, GNorm = 7.7538, lr_0 = 1.0202e-04
Loss = 1.0952e-03, PNorm = 35.3303, GNorm = 7.3615, lr_0 = 1.0202e-04
Loss = 1.3078e-03, PNorm = 35.3313, GNorm = 10.3857, lr_0 = 1.0202e-04
Loss = 1.3180e-03, PNorm = 35.3334, GNorm = 6.7470, lr_0 = 1.0202e-04
Loss = 1.2290e-03, PNorm = 35.3348, GNorm = 2.9711, lr_0 = 1.0202e-04
Validation rmse logP = 0.514811
Validation R2 logP = 0.922352
Epoch 29
Train function
Loss = 9.8636e-04, PNorm = 35.3358, GNorm = 9.0988, lr_0 = 1.0202e-04
Loss = 1.5699e-03, PNorm = 35.3371, GNorm = 6.3369, lr_0 = 1.0202e-04
Loss = 1.4458e-03, PNorm = 35.3398, GNorm = 2.9808, lr_0 = 1.0202e-04
Loss = 1.0211e-03, PNorm = 35.3414, GNorm = 2.0945, lr_0 = 1.0202e-04
Loss = 1.3190e-03, PNorm = 35.3431, GNorm = 3.1068, lr_0 = 1.0202e-04
Loss = 1.1971e-03, PNorm = 35.3447, GNorm = 1.3723, lr_0 = 1.0202e-04
Loss = 1.4595e-03, PNorm = 35.3470, GNorm = 1.9094, lr_0 = 1.0202e-04
Loss = 1.1899e-03, PNorm = 35.3482, GNorm = 4.3040, lr_0 = 1.0202e-04
Loss = 1.3157e-03, PNorm = 35.3499, GNorm = 5.1759, lr_0 = 1.0202e-04
Loss = 1.1344e-03, PNorm = 35.3513, GNorm = 4.6066, lr_0 = 1.0202e-04
Loss = 1.2700e-03, PNorm = 35.3533, GNorm = 1.5828, lr_0 = 1.0202e-04
Loss = 1.4214e-03, PNorm = 35.3556, GNorm = 2.7774, lr_0 = 1.0202e-04
Loss = 1.4248e-03, PNorm = 35.3573, GNorm = 11.1465, lr_0 = 1.0202e-04
Loss = 1.4591e-03, PNorm = 35.3594, GNorm = 6.9354, lr_0 = 1.0202e-04
Loss = 1.1539e-03, PNorm = 35.3606, GNorm = 10.3457, lr_0 = 1.0202e-04
Loss = 1.4021e-03, PNorm = 35.3627, GNorm = 10.1121, lr_0 = 1.0202e-04
Loss = 1.9281e-03, PNorm = 35.3641, GNorm = 10.6587, lr_0 = 1.0202e-04
Loss = 1.5055e-03, PNorm = 35.3664, GNorm = 4.3565, lr_0 = 1.0202e-04
Loss = 1.4628e-03, PNorm = 35.3687, GNorm = 5.2760, lr_0 = 1.0202e-04
Loss = 1.1293e-03, PNorm = 35.3708, GNorm = 9.6086, lr_0 = 1.0202e-04
Loss = 1.3943e-03, PNorm = 35.3737, GNorm = 16.5703, lr_0 = 1.0202e-04
Loss = 1.2439e-03, PNorm = 35.3753, GNorm = 1.8852, lr_0 = 1.0202e-04
Validation rmse logP = 0.505446
Validation R2 logP = 0.925152
Epoch 30
Train function
Loss = 1.2901e-03, PNorm = 35.3768, GNorm = 2.6306, lr_0 = 1.0202e-04
Loss = 1.0864e-03, PNorm = 35.3786, GNorm = 4.5190, lr_0 = 1.0202e-04
Loss = 1.4407e-03, PNorm = 35.3811, GNorm = 4.3401, lr_0 = 1.0202e-04
Loss = 1.1510e-03, PNorm = 35.3825, GNorm = 4.0631, lr_0 = 1.0202e-04
Loss = 1.0534e-03, PNorm = 35.3843, GNorm = 7.9416, lr_0 = 1.0202e-04
Loss = 1.1101e-03, PNorm = 35.3857, GNorm = 7.5740, lr_0 = 1.0202e-04
Loss = 1.0451e-03, PNorm = 35.3884, GNorm = 5.5419, lr_0 = 1.0202e-04
Loss = 1.2053e-03, PNorm = 35.3902, GNorm = 9.3325, lr_0 = 1.0202e-04
Loss = 9.9593e-04, PNorm = 35.3913, GNorm = 6.7201, lr_0 = 1.0202e-04
Loss = 1.8610e-03, PNorm = 35.3938, GNorm = 2.6149, lr_0 = 1.0202e-04
Loss = 1.3256e-03, PNorm = 35.3954, GNorm = 4.0096, lr_0 = 1.0202e-04
Loss = 1.1318e-03, PNorm = 35.3977, GNorm = 4.4449, lr_0 = 1.0202e-04
Loss = 1.2052e-03, PNorm = 35.3995, GNorm = 1.9714, lr_0 = 1.0202e-04
Loss = 1.1808e-03, PNorm = 35.4012, GNorm = 2.5660, lr_0 = 1.0202e-04
Loss = 1.1667e-03, PNorm = 35.4041, GNorm = 4.0639, lr_0 = 1.0202e-04
Loss = 1.5912e-03, PNorm = 35.4064, GNorm = 7.0831, lr_0 = 1.0202e-04
Loss = 1.2834e-03, PNorm = 35.4088, GNorm = 6.4731, lr_0 = 1.0202e-04
Loss = 1.3257e-03, PNorm = 35.4103, GNorm = 5.0893, lr_0 = 1.0202e-04
Loss = 1.3544e-03, PNorm = 35.4130, GNorm = 2.5407, lr_0 = 1.0202e-04
Loss = 1.2145e-03, PNorm = 35.4139, GNorm = 2.0010, lr_0 = 1.0202e-04
Loss = 1.3771e-03, PNorm = 35.4157, GNorm = 3.8847, lr_0 = 1.0202e-04
Loss = 1.0335e-03, PNorm = 35.4178, GNorm = 3.2162, lr_0 = 1.0202e-04
Validation rmse logP = 0.525791
Validation R2 logP = 0.919005
Epoch 31
Train function
Loss = 7.8898e-04, PNorm = 35.4199, GNorm = 1.8418, lr_0 = 1.0202e-04
Loss = 1.0692e-03, PNorm = 35.4214, GNorm = 6.8035, lr_0 = 1.0202e-04
Loss = 1.4993e-03, PNorm = 35.4224, GNorm = 15.0864, lr_0 = 1.0202e-04
Loss = 1.0957e-03, PNorm = 35.4239, GNorm = 5.2809, lr_0 = 1.0202e-04
Loss = 1.0698e-03, PNorm = 35.4264, GNorm = 3.2423, lr_0 = 1.0202e-04
Loss = 1.1200e-03, PNorm = 35.4291, GNorm = 7.2525, lr_0 = 1.0202e-04
Loss = 1.1641e-03, PNorm = 35.4310, GNorm = 6.5849, lr_0 = 1.0202e-04
Loss = 1.3903e-03, PNorm = 35.4338, GNorm = 5.0745, lr_0 = 1.0202e-04
Loss = 1.1802e-03, PNorm = 35.4351, GNorm = 2.7159, lr_0 = 1.0202e-04
Loss = 1.5914e-03, PNorm = 35.4376, GNorm = 3.1094, lr_0 = 1.0202e-04
Loss = 1.2394e-03, PNorm = 35.4394, GNorm = 11.1848, lr_0 = 1.0202e-04
Loss = 1.1161e-03, PNorm = 35.4405, GNorm = 3.4570, lr_0 = 1.0202e-04
Loss = 1.3459e-03, PNorm = 35.4417, GNorm = 2.6391, lr_0 = 1.0202e-04
Loss = 1.3055e-03, PNorm = 35.4434, GNorm = 4.1923, lr_0 = 1.0202e-04
Loss = 1.3310e-03, PNorm = 35.4449, GNorm = 4.2838, lr_0 = 1.0202e-04
Loss = 1.3907e-03, PNorm = 35.4470, GNorm = 2.8706, lr_0 = 1.0202e-04
Loss = 1.4447e-03, PNorm = 35.4477, GNorm = 2.5344, lr_0 = 1.0202e-04
Loss = 1.3567e-03, PNorm = 35.4496, GNorm = 7.3737, lr_0 = 1.0202e-04
Loss = 9.5364e-04, PNorm = 35.4508, GNorm = 4.7905, lr_0 = 1.0202e-04
Loss = 9.5468e-04, PNorm = 35.4525, GNorm = 1.9758, lr_0 = 1.0202e-04
Loss = 1.1521e-03, PNorm = 35.4542, GNorm = 2.4939, lr_0 = 1.0202e-04
Loss = 1.2788e-03, PNorm = 35.4562, GNorm = 6.3960, lr_0 = 1.0202e-04
Loss = 1.0606e-03, PNorm = 35.4586, GNorm = 2.5755, lr_0 = 1.0202e-04
Validation rmse logP = 0.516308
Validation R2 logP = 0.921900
Epoch 32
Train function
Loss = 1.1889e-03, PNorm = 35.4607, GNorm = 5.2269, lr_0 = 1.0202e-04
Loss = 1.0994e-03, PNorm = 35.4623, GNorm = 5.2170, lr_0 = 1.0202e-04
Loss = 1.3793e-03, PNorm = 35.4637, GNorm = 16.1790, lr_0 = 1.0202e-04
Loss = 1.8535e-03, PNorm = 35.4659, GNorm = 19.5552, lr_0 = 1.0202e-04
Loss = 1.3968e-03, PNorm = 35.4686, GNorm = 6.7200, lr_0 = 1.0202e-04
Loss = 1.6268e-03, PNorm = 35.4704, GNorm = 1.6456, lr_0 = 1.0202e-04
Loss = 1.3343e-03, PNorm = 35.4726, GNorm = 4.5928, lr_0 = 1.0202e-04
Loss = 1.4898e-03, PNorm = 35.4739, GNorm = 2.0092, lr_0 = 1.0202e-04
Loss = 1.1640e-03, PNorm = 35.4760, GNorm = 5.7849, lr_0 = 1.0202e-04
Loss = 1.3142e-03, PNorm = 35.4780, GNorm = 8.4922, lr_0 = 1.0202e-04
Loss = 1.1087e-03, PNorm = 35.4797, GNorm = 2.2324, lr_0 = 1.0202e-04
Loss = 9.7111e-04, PNorm = 35.4811, GNorm = 4.2234, lr_0 = 1.0202e-04
Loss = 1.0976e-03, PNorm = 35.4827, GNorm = 3.6126, lr_0 = 1.0202e-04
Loss = 1.1656e-03, PNorm = 35.4847, GNorm = 2.4645, lr_0 = 1.0202e-04
Loss = 1.0670e-03, PNorm = 35.4866, GNorm = 5.6283, lr_0 = 1.0202e-04
Loss = 9.6196e-04, PNorm = 35.4885, GNorm = 4.8640, lr_0 = 1.0202e-04
Loss = 1.4287e-03, PNorm = 35.4912, GNorm = 5.2276, lr_0 = 1.0202e-04
Loss = 1.2559e-03, PNorm = 35.4921, GNorm = 7.0435, lr_0 = 1.0202e-04
Loss = 1.1816e-03, PNorm = 35.4945, GNorm = 6.9628, lr_0 = 1.0202e-04
Loss = 1.1049e-03, PNorm = 35.4969, GNorm = 2.5938, lr_0 = 1.0202e-04
Loss = 1.2150e-03, PNorm = 35.4989, GNorm = 7.1083, lr_0 = 1.0202e-04
Loss = 1.4898e-03, PNorm = 35.5006, GNorm = 5.5126, lr_0 = 1.0202e-04
Validation rmse logP = 0.543991
Validation R2 logP = 0.913301
Epoch 33
Train function
Loss = 1.2073e-03, PNorm = 35.5017, GNorm = 3.3707, lr_0 = 1.0202e-04
Loss = 1.1424e-03, PNorm = 35.5018, GNorm = 7.3205, lr_0 = 1.0202e-04
Loss = 1.2931e-03, PNorm = 35.5036, GNorm = 3.4552, lr_0 = 1.0202e-04
Loss = 1.0057e-03, PNorm = 35.5063, GNorm = 1.7693, lr_0 = 1.0202e-04
Loss = 1.0028e-03, PNorm = 35.5082, GNorm = 2.9097, lr_0 = 1.0202e-04
Loss = 9.0259e-04, PNorm = 35.5092, GNorm = 1.7384, lr_0 = 1.0202e-04
Loss = 1.1825e-03, PNorm = 35.5116, GNorm = 5.3617, lr_0 = 1.0202e-04
Loss = 1.2089e-03, PNorm = 35.5136, GNorm = 3.3415, lr_0 = 1.0202e-04
Loss = 1.2221e-03, PNorm = 35.5174, GNorm = 4.7446, lr_0 = 1.0202e-04
Loss = 1.4576e-03, PNorm = 35.5198, GNorm = 8.3500, lr_0 = 1.0202e-04
Loss = 1.2716e-03, PNorm = 35.5213, GNorm = 4.9135, lr_0 = 1.0202e-04
Loss = 1.1786e-03, PNorm = 35.5230, GNorm = 5.5134, lr_0 = 1.0202e-04
Loss = 1.2013e-03, PNorm = 35.5245, GNorm = 6.5806, lr_0 = 1.0202e-04
Loss = 1.5105e-03, PNorm = 35.5261, GNorm = 12.2231, lr_0 = 1.0202e-04
Loss = 1.1736e-03, PNorm = 35.5275, GNorm = 2.9398, lr_0 = 1.0202e-04
Loss = 1.1849e-03, PNorm = 35.5291, GNorm = 2.4413, lr_0 = 1.0202e-04
Loss = 1.1078e-03, PNorm = 35.5314, GNorm = 2.8095, lr_0 = 1.0202e-04
Loss = 8.7221e-04, PNorm = 35.5327, GNorm = 4.2878, lr_0 = 1.0202e-04
Loss = 9.7051e-04, PNorm = 35.5339, GNorm = 4.1847, lr_0 = 1.0202e-04
Loss = 1.2267e-03, PNorm = 35.5355, GNorm = 1.7767, lr_0 = 1.0202e-04
Loss = 1.2094e-03, PNorm = 35.5372, GNorm = 2.6306, lr_0 = 1.0202e-04
Loss = 1.0210e-03, PNorm = 35.5388, GNorm = 1.3722, lr_0 = 1.0202e-04
Loss = 1.3126e-03, PNorm = 35.5409, GNorm = 3.7514, lr_0 = 1.0202e-04
Validation rmse logP = 0.537631
Validation R2 logP = 0.915316
Epoch 34
Train function
Loss = 1.0090e-03, PNorm = 35.5421, GNorm = 4.1618, lr_0 = 1.0202e-04
Loss = 1.0597e-03, PNorm = 35.5433, GNorm = 5.7506, lr_0 = 1.0202e-04
Loss = 1.0359e-03, PNorm = 35.5452, GNorm = 2.8033, lr_0 = 1.0202e-04
Loss = 1.2957e-03, PNorm = 35.5480, GNorm = 2.7792, lr_0 = 1.0202e-04
Loss = 1.0681e-03, PNorm = 35.5502, GNorm = 3.5424, lr_0 = 1.0202e-04
Loss = 1.2395e-03, PNorm = 35.5519, GNorm = 2.7999, lr_0 = 1.0202e-04
Loss = 9.4370e-04, PNorm = 35.5532, GNorm = 3.6983, lr_0 = 1.0202e-04
Loss = 8.9871e-04, PNorm = 35.5545, GNorm = 1.6138, lr_0 = 1.0202e-04
Loss = 1.2348e-03, PNorm = 35.5561, GNorm = 9.6911, lr_0 = 1.0202e-04
Loss = 1.2895e-03, PNorm = 35.5576, GNorm = 10.3137, lr_0 = 1.0202e-04
Loss = 1.2801e-03, PNorm = 35.5597, GNorm = 9.9453, lr_0 = 1.0202e-04
Loss = 1.1365e-03, PNorm = 35.5611, GNorm = 2.7165, lr_0 = 1.0202e-04
Loss = 1.0568e-03, PNorm = 35.5632, GNorm = 2.1279, lr_0 = 1.0202e-04
Loss = 1.2623e-03, PNorm = 35.5661, GNorm = 7.3126, lr_0 = 1.0202e-04
Loss = 1.0749e-03, PNorm = 35.5685, GNorm = 4.8549, lr_0 = 1.0202e-04
Loss = 1.2114e-03, PNorm = 35.5701, GNorm = 4.2752, lr_0 = 1.0202e-04
Loss = 9.2364e-04, PNorm = 35.5720, GNorm = 4.4043, lr_0 = 1.0202e-04
Loss = 1.1464e-03, PNorm = 35.5738, GNorm = 8.1454, lr_0 = 1.0202e-04
Loss = 1.3053e-03, PNorm = 35.5751, GNorm = 3.2330, lr_0 = 1.0202e-04
Loss = 1.3698e-03, PNorm = 35.5769, GNorm = 12.0802, lr_0 = 1.0202e-04
Loss = 1.4009e-03, PNorm = 35.5789, GNorm = 2.9876, lr_0 = 1.0202e-04
Loss = 9.3219e-04, PNorm = 35.5802, GNorm = 5.1130, lr_0 = 1.0202e-04
Validation rmse logP = 0.496040
Validation R2 logP = 0.927911
Epoch 35
Train function
Loss = 1.1457e-03, PNorm = 35.5824, GNorm = 2.9748, lr_0 = 1.0202e-04
Loss = 1.1491e-03, PNorm = 35.5833, GNorm = 5.9472, lr_0 = 1.0202e-04
Loss = 1.0900e-03, PNorm = 35.5847, GNorm = 3.3322, lr_0 = 1.0202e-04
Loss = 1.2569e-03, PNorm = 35.5854, GNorm = 9.9967, lr_0 = 1.0202e-04
Loss = 1.2329e-03, PNorm = 35.5876, GNorm = 5.4912, lr_0 = 1.0202e-04
Loss = 1.6094e-03, PNorm = 35.5891, GNorm = 6.7010, lr_0 = 1.0202e-04
Loss = 1.3459e-03, PNorm = 35.5910, GNorm = 5.9438, lr_0 = 1.0202e-04
Loss = 1.2116e-03, PNorm = 35.5937, GNorm = 3.2328, lr_0 = 1.0202e-04
Loss = 1.1467e-03, PNorm = 35.5965, GNorm = 2.1302, lr_0 = 1.0202e-04
Loss = 9.2819e-04, PNorm = 35.5989, GNorm = 2.6087, lr_0 = 1.0202e-04
Loss = 1.1070e-03, PNorm = 35.5998, GNorm = 3.5128, lr_0 = 1.0202e-04
Loss = 9.5650e-04, PNorm = 35.6024, GNorm = 2.8703, lr_0 = 1.0202e-04
Loss = 1.0125e-03, PNorm = 35.6044, GNorm = 9.5020, lr_0 = 1.0202e-04
Loss = 1.2170e-03, PNorm = 35.6056, GNorm = 9.2989, lr_0 = 1.0202e-04
Loss = 1.2268e-03, PNorm = 35.6068, GNorm = 9.3226, lr_0 = 1.0202e-04
Loss = 1.1046e-03, PNorm = 35.6088, GNorm = 3.4781, lr_0 = 1.0202e-04
Loss = 1.0743e-03, PNorm = 35.6108, GNorm = 3.0213, lr_0 = 1.0202e-04
Loss = 1.1403e-03, PNorm = 35.6126, GNorm = 5.1527, lr_0 = 1.0202e-04
Loss = 1.0376e-03, PNorm = 35.6144, GNorm = 8.6570, lr_0 = 1.0202e-04
Loss = 1.0329e-03, PNorm = 35.6163, GNorm = 1.8047, lr_0 = 1.0202e-04
Loss = 8.9684e-04, PNorm = 35.6177, GNorm = 1.6749, lr_0 = 1.0202e-04
Loss = 1.0494e-03, PNorm = 35.6203, GNorm = 1.6240, lr_0 = 1.0202e-04
Validation rmse logP = 0.510657
Validation R2 logP = 0.923601
Epoch 36
Train function
Loss = 9.4126e-04, PNorm = 35.6221, GNorm = 5.7619, lr_0 = 1.0202e-04
Loss = 1.1793e-03, PNorm = 35.6251, GNorm = 4.7224, lr_0 = 1.0202e-04
Loss = 9.5210e-04, PNorm = 35.6271, GNorm = 7.7626, lr_0 = 1.0202e-04
Loss = 8.9532e-04, PNorm = 35.6296, GNorm = 4.5230, lr_0 = 1.0202e-04
Loss = 8.5113e-04, PNorm = 35.6318, GNorm = 2.2568, lr_0 = 1.0202e-04
Loss = 1.2131e-03, PNorm = 35.6332, GNorm = 5.9528, lr_0 = 1.0202e-04
Loss = 1.4847e-03, PNorm = 35.6359, GNorm = 12.2361, lr_0 = 1.0202e-04
Loss = 1.0655e-03, PNorm = 35.6378, GNorm = 3.4081, lr_0 = 1.0202e-04
Loss = 1.3905e-03, PNorm = 35.6398, GNorm = 1.8718, lr_0 = 1.0202e-04
Loss = 1.0365e-03, PNorm = 35.6404, GNorm = 4.7666, lr_0 = 1.0202e-04
Loss = 1.1372e-03, PNorm = 35.6412, GNorm = 5.6734, lr_0 = 1.0202e-04
Loss = 1.0363e-03, PNorm = 35.6419, GNorm = 3.8939, lr_0 = 1.0202e-04
Loss = 1.0523e-03, PNorm = 35.6435, GNorm = 3.4086, lr_0 = 1.0202e-04
Loss = 1.0299e-03, PNorm = 35.6452, GNorm = 8.1462, lr_0 = 1.0202e-04
Loss = 9.9618e-04, PNorm = 35.6466, GNorm = 2.3904, lr_0 = 1.0202e-04
Loss = 1.0699e-03, PNorm = 35.6479, GNorm = 6.3178, lr_0 = 1.0202e-04
Loss = 1.0879e-03, PNorm = 35.6500, GNorm = 1.5325, lr_0 = 1.0202e-04
Loss = 1.0252e-03, PNorm = 35.6515, GNorm = 2.9870, lr_0 = 1.0202e-04
Loss = 1.1886e-03, PNorm = 35.6527, GNorm = 5.6130, lr_0 = 1.0202e-04
Loss = 1.0106e-03, PNorm = 35.6541, GNorm = 6.4724, lr_0 = 1.0202e-04
Loss = 1.0451e-03, PNorm = 35.6563, GNorm = 4.4075, lr_0 = 1.0202e-04
Loss = 1.1469e-03, PNorm = 35.6578, GNorm = 8.3979, lr_0 = 1.0202e-04
Loss = 1.4985e-03, PNorm = 35.6594, GNorm = 12.9279, lr_0 = 1.0202e-04
Loss = 1.7999e-03, PNorm = 35.6594, GNorm = 4.0901, lr_0 = 1.0202e-04
Validation rmse logP = 0.591166
Validation R2 logP = 0.897611
Epoch 37
Train function
Loss = 1.4477e-03, PNorm = 35.6614, GNorm = 2.6806, lr_0 = 1.0202e-04
Loss = 1.2897e-03, PNorm = 35.6633, GNorm = 5.9319, lr_0 = 1.0202e-04
Loss = 1.3963e-03, PNorm = 35.6654, GNorm = 4.2151, lr_0 = 1.0202e-04
Loss = 1.0781e-03, PNorm = 35.6678, GNorm = 8.1221, lr_0 = 1.0202e-04
Loss = 1.1557e-03, PNorm = 35.6698, GNorm = 3.5927, lr_0 = 1.0202e-04
Loss = 1.3761e-03, PNorm = 35.6724, GNorm = 6.8353, lr_0 = 1.0202e-04
Loss = 9.6968e-04, PNorm = 35.6740, GNorm = 4.6409, lr_0 = 1.0202e-04
Loss = 1.1618e-03, PNorm = 35.6745, GNorm = 5.2332, lr_0 = 1.0202e-04
Loss = 1.1213e-03, PNorm = 35.6762, GNorm = 9.4280, lr_0 = 1.0202e-04
Loss = 1.2786e-03, PNorm = 35.6776, GNorm = 9.6105, lr_0 = 1.0202e-04
Loss = 1.1695e-03, PNorm = 35.6794, GNorm = 4.0684, lr_0 = 1.0202e-04
Loss = 1.2333e-03, PNorm = 35.6804, GNorm = 8.1038, lr_0 = 1.0202e-04
Loss = 1.1375e-03, PNorm = 35.6814, GNorm = 5.0240, lr_0 = 1.0202e-04
Loss = 1.0722e-03, PNorm = 35.6832, GNorm = 4.7117, lr_0 = 1.0202e-04
Loss = 1.0807e-03, PNorm = 35.6847, GNorm = 7.3762, lr_0 = 1.0202e-04
Loss = 1.0254e-03, PNorm = 35.6868, GNorm = 2.6311, lr_0 = 1.0202e-04
Loss = 9.4176e-04, PNorm = 35.6880, GNorm = 4.2615, lr_0 = 1.0202e-04
Loss = 9.8063e-04, PNorm = 35.6911, GNorm = 1.3293, lr_0 = 1.0202e-04
Loss = 1.1478e-03, PNorm = 35.6929, GNorm = 8.1458, lr_0 = 1.0202e-04
Loss = 1.2208e-03, PNorm = 35.6951, GNorm = 10.7609, lr_0 = 1.0202e-04
Loss = 9.6777e-04, PNorm = 35.6960, GNorm = 2.5352, lr_0 = 1.0202e-04
Loss = 8.8119e-04, PNorm = 35.6976, GNorm = 1.2915, lr_0 = 1.0202e-04
Validation rmse logP = 0.528869
Validation R2 logP = 0.918054
Epoch 38
Train function
Loss = 1.0834e-03, PNorm = 35.6987, GNorm = 4.1417, lr_0 = 1.0202e-04
Loss = 1.3313e-03, PNorm = 35.7006, GNorm = 2.6362, lr_0 = 1.0202e-04
Loss = 1.0666e-03, PNorm = 35.7026, GNorm = 2.4214, lr_0 = 1.0202e-04
Loss = 1.0954e-03, PNorm = 35.7036, GNorm = 3.9622, lr_0 = 1.0202e-04
Loss = 9.6182e-04, PNorm = 35.7046, GNorm = 4.2130, lr_0 = 1.0202e-04
Loss = 1.0022e-03, PNorm = 35.7059, GNorm = 10.2295, lr_0 = 1.0202e-04
Loss = 1.0268e-03, PNorm = 35.7082, GNorm = 7.0192, lr_0 = 1.0202e-04
Loss = 1.0171e-03, PNorm = 35.7099, GNorm = 4.0624, lr_0 = 1.0202e-04
Loss = 9.8645e-04, PNorm = 35.7121, GNorm = 2.6648, lr_0 = 1.0202e-04
Loss = 8.7035e-04, PNorm = 35.7140, GNorm = 6.9065, lr_0 = 1.0202e-04
Loss = 9.6998e-04, PNorm = 35.7162, GNorm = 1.4944, lr_0 = 1.0202e-04
Loss = 9.3598e-04, PNorm = 35.7185, GNorm = 4.3458, lr_0 = 1.0202e-04
Loss = 9.0600e-04, PNorm = 35.7208, GNorm = 10.8101, lr_0 = 1.0202e-04
Loss = 9.9711e-04, PNorm = 35.7222, GNorm = 5.5364, lr_0 = 1.0202e-04
Loss = 1.0931e-03, PNorm = 35.7233, GNorm = 7.3046, lr_0 = 1.0202e-04
Loss = 8.9262e-04, PNorm = 35.7259, GNorm = 2.0915, lr_0 = 1.0202e-04
Loss = 1.3102e-03, PNorm = 35.7276, GNorm = 4.6728, lr_0 = 1.0202e-04
Loss = 1.1847e-03, PNorm = 35.7296, GNorm = 5.5717, lr_0 = 1.0202e-04
Loss = 1.0534e-03, PNorm = 35.7320, GNorm = 1.8979, lr_0 = 1.0202e-04
Loss = 1.0438e-03, PNorm = 35.7334, GNorm = 11.8705, lr_0 = 1.0202e-04
Loss = 1.2901e-03, PNorm = 35.7340, GNorm = 1.9817, lr_0 = 1.0202e-04
Loss = 1.2032e-03, PNorm = 35.7352, GNorm = 2.6179, lr_0 = 1.0202e-04
Validation rmse logP = 0.601094
Validation R2 logP = 0.894144
Epoch 39
Train function
Loss = 1.4593e-03, PNorm = 35.7378, GNorm = 4.7971, lr_0 = 1.0202e-04
Loss = 1.1834e-03, PNorm = 35.7404, GNorm = 9.1501, lr_0 = 1.0202e-04
Loss = 1.1675e-03, PNorm = 35.7429, GNorm = 5.8446, lr_0 = 1.0202e-04
Loss = 1.2256e-03, PNorm = 35.7454, GNorm = 6.4731, lr_0 = 1.0202e-04
Loss = 1.3612e-03, PNorm = 35.7468, GNorm = 1.9347, lr_0 = 1.0202e-04
Loss = 1.1829e-03, PNorm = 35.7485, GNorm = 5.9007, lr_0 = 1.0202e-04
Loss = 1.1580e-03, PNorm = 35.7499, GNorm = 2.2038, lr_0 = 1.0202e-04
Loss = 8.1099e-04, PNorm = 35.7512, GNorm = 4.4400, lr_0 = 1.0202e-04
Loss = 1.1934e-03, PNorm = 35.7533, GNorm = 3.8936, lr_0 = 1.0202e-04
Loss = 1.1057e-03, PNorm = 35.7547, GNorm = 3.6845, lr_0 = 1.0202e-04
Loss = 9.2331e-04, PNorm = 35.7554, GNorm = 1.7008, lr_0 = 1.0202e-04
Loss = 9.2235e-04, PNorm = 35.7574, GNorm = 4.3527, lr_0 = 1.0202e-04
Loss = 1.1446e-03, PNorm = 35.7585, GNorm = 3.6560, lr_0 = 1.0202e-04
Loss = 9.7473e-04, PNorm = 35.7596, GNorm = 7.7063, lr_0 = 1.0202e-04
Loss = 1.0131e-03, PNorm = 35.7615, GNorm = 1.7021, lr_0 = 1.0202e-04
Loss = 9.8746e-04, PNorm = 35.7633, GNorm = 6.7297, lr_0 = 1.0202e-04
Loss = 9.8414e-04, PNorm = 35.7645, GNorm = 4.4352, lr_0 = 1.0202e-04
Loss = 9.9799e-04, PNorm = 35.7665, GNorm = 4.9685, lr_0 = 1.0202e-04
Loss = 9.7782e-04, PNorm = 35.7678, GNorm = 5.1079, lr_0 = 1.0202e-04
Loss = 1.2975e-03, PNorm = 35.7703, GNorm = 1.4800, lr_0 = 1.0202e-04
Loss = 1.1545e-03, PNorm = 35.7732, GNorm = 2.3446, lr_0 = 1.0202e-04
Loss = 8.7037e-04, PNorm = 35.7747, GNorm = 3.1720, lr_0 = 1.0202e-04
Loss = 8.9724e-04, PNorm = 35.7768, GNorm = 4.7197, lr_0 = 1.0202e-04
Validation rmse logP = 0.494919
Validation R2 logP = 0.928237
Epoch 40
Train function
Loss = 1.0445e-03, PNorm = 35.7783, GNorm = 1.8524, lr_0 = 1.0202e-04
Loss = 8.3132e-04, PNorm = 35.7803, GNorm = 2.4441, lr_0 = 1.0202e-04
Loss = 1.0575e-03, PNorm = 35.7821, GNorm = 2.5234, lr_0 = 1.0202e-04
Loss = 7.7916e-04, PNorm = 35.7841, GNorm = 5.6586, lr_0 = 1.0202e-04
Loss = 1.0362e-03, PNorm = 35.7855, GNorm = 1.4177, lr_0 = 1.0202e-04
Loss = 1.1135e-03, PNorm = 35.7877, GNorm = 2.3904, lr_0 = 1.0202e-04
Loss = 8.3053e-04, PNorm = 35.7893, GNorm = 4.1426, lr_0 = 1.0202e-04
Loss = 9.2005e-04, PNorm = 35.7909, GNorm = 4.5140, lr_0 = 1.0202e-04
Loss = 1.0348e-03, PNorm = 35.7932, GNorm = 2.9203, lr_0 = 1.0202e-04
Loss = 9.1801e-04, PNorm = 35.7949, GNorm = 7.9817, lr_0 = 1.0202e-04
Loss = 8.8542e-04, PNorm = 35.7971, GNorm = 4.7221, lr_0 = 1.0202e-04
Loss = 1.0472e-03, PNorm = 35.7982, GNorm = 3.3529, lr_0 = 1.0202e-04
Loss = 1.1400e-03, PNorm = 35.8002, GNorm = 6.4501, lr_0 = 1.0202e-04
Loss = 1.2763e-03, PNorm = 35.8021, GNorm = 10.0600, lr_0 = 1.0202e-04
Loss = 1.3656e-03, PNorm = 35.8045, GNorm = 6.7973, lr_0 = 1.0202e-04
Loss = 1.2691e-03, PNorm = 35.8070, GNorm = 4.5199, lr_0 = 1.0202e-04
Loss = 9.5594e-04, PNorm = 35.8083, GNorm = 6.5636, lr_0 = 1.0202e-04
Loss = 1.0406e-03, PNorm = 35.8087, GNorm = 7.9929, lr_0 = 1.0202e-04
Loss = 1.1235e-03, PNorm = 35.8114, GNorm = 6.7362, lr_0 = 1.0202e-04
Loss = 1.0603e-03, PNorm = 35.8129, GNorm = 2.4217, lr_0 = 1.0202e-04
Loss = 9.1870e-04, PNorm = 35.8145, GNorm = 7.7506, lr_0 = 1.0202e-04
Loss = 1.1562e-03, PNorm = 35.8164, GNorm = 8.4493, lr_0 = 1.0202e-04
Validation rmse logP = 0.495879
Validation R2 logP = 0.927958
Epoch 41
Train function
Loss = 8.1644e-04, PNorm = 35.8182, GNorm = 6.2538, lr_0 = 1.0202e-04
Loss = 1.0848e-03, PNorm = 35.8202, GNorm = 2.9968, lr_0 = 1.0202e-04
Loss = 8.6840e-04, PNorm = 35.8222, GNorm = 3.3785, lr_0 = 1.0202e-04
Loss = 8.5690e-04, PNorm = 35.8244, GNorm = 1.4980, lr_0 = 1.0202e-04
Loss = 8.2730e-04, PNorm = 35.8273, GNorm = 2.6541, lr_0 = 1.0202e-04
Loss = 1.1523e-03, PNorm = 35.8294, GNorm = 4.7303, lr_0 = 1.0202e-04
Loss = 9.2865e-04, PNorm = 35.8305, GNorm = 5.1980, lr_0 = 1.0202e-04
Loss = 8.4794e-04, PNorm = 35.8321, GNorm = 2.4460, lr_0 = 1.0202e-04
Loss = 1.0510e-03, PNorm = 35.8337, GNorm = 12.7737, lr_0 = 1.0202e-04
Loss = 1.1942e-03, PNorm = 35.8355, GNorm = 5.0735, lr_0 = 1.0202e-04
Loss = 9.8945e-04, PNorm = 35.8375, GNorm = 9.9776, lr_0 = 1.0202e-04
Loss = 1.3727e-03, PNorm = 35.8393, GNorm = 1.7769, lr_0 = 1.0202e-04
Loss = 9.9945e-04, PNorm = 35.8398, GNorm = 2.8107, lr_0 = 1.0202e-04
Loss = 9.7561e-04, PNorm = 35.8424, GNorm = 6.6416, lr_0 = 1.0202e-04
Loss = 1.1640e-03, PNorm = 35.8434, GNorm = 2.2695, lr_0 = 1.0202e-04
Loss = 1.4024e-03, PNorm = 35.8454, GNorm = 1.1271, lr_0 = 1.0202e-04
Loss = 1.1197e-03, PNorm = 35.8465, GNorm = 3.2831, lr_0 = 1.0202e-04
Loss = 8.7295e-04, PNorm = 35.8481, GNorm = 6.0868, lr_0 = 1.0202e-04
Loss = 1.0116e-03, PNorm = 35.8495, GNorm = 3.3641, lr_0 = 1.0202e-04
Loss = 1.0204e-03, PNorm = 35.8509, GNorm = 4.6329, lr_0 = 1.0202e-04
Loss = 8.6012e-04, PNorm = 35.8529, GNorm = 1.8296, lr_0 = 1.0202e-04
Loss = 8.3729e-04, PNorm = 35.8546, GNorm = 4.0959, lr_0 = 1.0202e-04
Validation rmse logP = 0.499493
Validation R2 logP = 0.926904
Epoch 42
Train function
Loss = 6.4809e-04, PNorm = 35.8562, GNorm = 2.7452, lr_0 = 1.0202e-04
Loss = 1.2082e-03, PNorm = 35.8588, GNorm = 3.0187, lr_0 = 1.0202e-04
Loss = 1.0046e-03, PNorm = 35.8603, GNorm = 1.4177, lr_0 = 1.0202e-04
Loss = 1.0648e-03, PNorm = 35.8625, GNorm = 5.0430, lr_0 = 1.0202e-04
Loss = 7.9273e-04, PNorm = 35.8637, GNorm = 4.5919, lr_0 = 1.0202e-04
Loss = 1.4394e-03, PNorm = 35.8660, GNorm = 12.0614, lr_0 = 1.0202e-04
Loss = 9.4248e-04, PNorm = 35.8679, GNorm = 0.9821, lr_0 = 1.0202e-04
Loss = 1.0790e-03, PNorm = 35.8700, GNorm = 2.4035, lr_0 = 1.0202e-04
Loss = 1.0072e-03, PNorm = 35.8721, GNorm = 2.7174, lr_0 = 1.0202e-04
Loss = 9.4871e-04, PNorm = 35.8739, GNorm = 2.7815, lr_0 = 1.0202e-04
Loss = 9.7124e-04, PNorm = 35.8760, GNorm = 1.5746, lr_0 = 1.0202e-04
Loss = 9.9194e-04, PNorm = 35.8775, GNorm = 9.9791, lr_0 = 1.0202e-04
Loss = 9.6096e-04, PNorm = 35.8798, GNorm = 3.1227, lr_0 = 1.0202e-04
Loss = 9.4546e-04, PNorm = 35.8815, GNorm = 1.1391, lr_0 = 1.0202e-04
Loss = 1.0464e-03, PNorm = 35.8832, GNorm = 9.8534, lr_0 = 1.0202e-04
Loss = 1.1224e-03, PNorm = 35.8843, GNorm = 7.7752, lr_0 = 1.0202e-04
Loss = 9.8216e-04, PNorm = 35.8859, GNorm = 1.9972, lr_0 = 1.0202e-04
Loss = 9.3429e-04, PNorm = 35.8876, GNorm = 9.9501, lr_0 = 1.0202e-04
Loss = 1.2955e-03, PNorm = 35.8880, GNorm = 9.1236, lr_0 = 1.0202e-04
Loss = 1.1724e-03, PNorm = 35.8903, GNorm = 3.4381, lr_0 = 1.0202e-04
Loss = 1.3279e-03, PNorm = 35.8914, GNorm = 1.6232, lr_0 = 1.0202e-04
Loss = 9.6068e-04, PNorm = 35.8927, GNorm = 8.7494, lr_0 = 1.0202e-04
Loss = 1.1143e-03, PNorm = 35.8951, GNorm = 13.9069, lr_0 = 1.0202e-04
Validation rmse logP = 0.641818
Validation R2 logP = 0.879314
Epoch 43
Train function
Loss = 1.5440e-03, PNorm = 35.8962, GNorm = 12.1268, lr_0 = 1.0202e-04
Loss = 9.8096e-04, PNorm = 35.8992, GNorm = 6.1660, lr_0 = 1.0202e-04
Loss = 9.4788e-04, PNorm = 35.9010, GNorm = 3.9406, lr_0 = 1.0202e-04
Loss = 7.9406e-04, PNorm = 35.9030, GNorm = 4.5375, lr_0 = 1.0202e-04
Loss = 8.3982e-04, PNorm = 35.9046, GNorm = 3.7978, lr_0 = 1.0202e-04
Loss = 7.0103e-04, PNorm = 35.9065, GNorm = 3.7104, lr_0 = 1.0202e-04
Loss = 9.9824e-04, PNorm = 35.9080, GNorm = 1.4116, lr_0 = 1.0202e-04
Loss = 8.1828e-04, PNorm = 35.9101, GNorm = 2.2564, lr_0 = 1.0202e-04
Loss = 8.9785e-04, PNorm = 35.9121, GNorm = 2.0286, lr_0 = 1.0202e-04
Loss = 9.3985e-04, PNorm = 35.9136, GNorm = 1.4211, lr_0 = 1.0202e-04
Loss = 9.7024e-04, PNorm = 35.9162, GNorm = 5.8170, lr_0 = 1.0202e-04
Loss = 8.7875e-04, PNorm = 35.9180, GNorm = 5.8854, lr_0 = 1.0202e-04
Loss = 9.4477e-04, PNorm = 35.9203, GNorm = 2.2456, lr_0 = 1.0202e-04
Loss = 6.8238e-04, PNorm = 35.9217, GNorm = 2.8930, lr_0 = 1.0202e-04
Loss = 1.0889e-03, PNorm = 35.9240, GNorm = 1.5109, lr_0 = 1.0202e-04
Loss = 1.0613e-03, PNorm = 35.9261, GNorm = 2.1210, lr_0 = 1.0202e-04
Loss = 9.4992e-04, PNorm = 35.9273, GNorm = 1.6668, lr_0 = 1.0202e-04
Loss = 9.4062e-04, PNorm = 35.9293, GNorm = 3.8779, lr_0 = 1.0202e-04
Loss = 9.8638e-04, PNorm = 35.9303, GNorm = 2.3533, lr_0 = 1.0202e-04
Loss = 1.1149e-03, PNorm = 35.9318, GNorm = 1.3271, lr_0 = 1.0202e-04
Loss = 1.1919e-03, PNorm = 35.9335, GNorm = 7.5452, lr_0 = 1.0202e-04
Loss = 1.0190e-03, PNorm = 35.9349, GNorm = 2.0157, lr_0 = 1.0202e-04
Validation rmse logP = 0.519733
Validation R2 logP = 0.920861
Epoch 44
Train function
Loss = 1.1562e-03, PNorm = 35.9361, GNorm = 5.4317, lr_0 = 1.0202e-04
Loss = 1.0946e-03, PNorm = 35.9381, GNorm = 2.6949, lr_0 = 1.0202e-04
Loss = 9.1462e-04, PNorm = 35.9402, GNorm = 1.6282, lr_0 = 1.0202e-04
Loss = 1.0406e-03, PNorm = 35.9421, GNorm = 2.3252, lr_0 = 1.0202e-04
Loss = 9.8650e-04, PNorm = 35.9439, GNorm = 1.3890, lr_0 = 1.0202e-04
Loss = 9.0302e-04, PNorm = 35.9457, GNorm = 1.5382, lr_0 = 1.0202e-04
Loss = 8.0189e-04, PNorm = 35.9479, GNorm = 8.1070, lr_0 = 1.0202e-04
Loss = 8.1520e-04, PNorm = 35.9496, GNorm = 4.5102, lr_0 = 1.0202e-04
Loss = 7.6107e-04, PNorm = 35.9514, GNorm = 3.5099, lr_0 = 1.0202e-04
Loss = 8.8916e-04, PNorm = 35.9523, GNorm = 2.8868, lr_0 = 1.0202e-04
Loss = 8.1921e-04, PNorm = 35.9540, GNorm = 5.4497, lr_0 = 1.0202e-04
Loss = 7.0809e-04, PNorm = 35.9553, GNorm = 2.8271, lr_0 = 1.0202e-04
Loss = 8.4602e-04, PNorm = 35.9567, GNorm = 1.4266, lr_0 = 1.0202e-04
Loss = 8.7718e-04, PNorm = 35.9581, GNorm = 9.3276, lr_0 = 1.0202e-04
Loss = 1.4076e-03, PNorm = 35.9591, GNorm = 9.3872, lr_0 = 1.0202e-04
Loss = 1.2833e-03, PNorm = 35.9606, GNorm = 5.8086, lr_0 = 1.0202e-04
Loss = 1.2562e-03, PNorm = 35.9622, GNorm = 1.7893, lr_0 = 1.0202e-04
Loss = 1.0571e-03, PNorm = 35.9638, GNorm = 2.3072, lr_0 = 1.0202e-04
Loss = 1.0439e-03, PNorm = 35.9662, GNorm = 5.2395, lr_0 = 1.0202e-04
Loss = 1.0286e-03, PNorm = 35.9689, GNorm = 2.3931, lr_0 = 1.0202e-04
Loss = 8.7864e-04, PNorm = 35.9713, GNorm = 5.5747, lr_0 = 1.0202e-04
Loss = 7.7959e-04, PNorm = 35.9731, GNorm = 1.5477, lr_0 = 1.0202e-04
Validation rmse logP = 0.531791
Validation R2 logP = 0.917146
Epoch 45
Train function
Loss = 1.0526e-03, PNorm = 35.9742, GNorm = 6.9668, lr_0 = 1.0202e-04
Loss = 8.1502e-04, PNorm = 35.9756, GNorm = 2.8538, lr_0 = 1.0202e-04
Loss = 1.0319e-03, PNorm = 35.9771, GNorm = 1.4964, lr_0 = 1.0202e-04
Loss = 1.1362e-03, PNorm = 35.9789, GNorm = 3.0219, lr_0 = 1.0202e-04
Loss = 7.9279e-04, PNorm = 35.9811, GNorm = 1.6371, lr_0 = 1.0202e-04
Loss = 7.9606e-04, PNorm = 35.9829, GNorm = 2.5444, lr_0 = 1.0202e-04
Loss = 1.0156e-03, PNorm = 35.9842, GNorm = 6.8157, lr_0 = 1.0202e-04
Loss = 8.9975e-04, PNorm = 35.9851, GNorm = 4.1237, lr_0 = 1.0202e-04
Loss = 1.0909e-03, PNorm = 35.9864, GNorm = 3.9375, lr_0 = 1.0202e-04
Loss = 1.1644e-03, PNorm = 35.9892, GNorm = 3.3423, lr_0 = 1.0202e-04
Loss = 9.4972e-04, PNorm = 35.9915, GNorm = 2.2661, lr_0 = 1.0202e-04
Loss = 8.2321e-04, PNorm = 35.9932, GNorm = 3.0137, lr_0 = 1.0202e-04
Loss = 9.1627e-04, PNorm = 35.9949, GNorm = 3.1349, lr_0 = 1.0202e-04
Loss = 7.7492e-04, PNorm = 35.9972, GNorm = 5.5596, lr_0 = 1.0202e-04
Loss = 1.0371e-03, PNorm = 36.0001, GNorm = 2.4061, lr_0 = 1.0202e-04
Loss = 7.8580e-04, PNorm = 36.0020, GNorm = 1.5736, lr_0 = 1.0202e-04
Loss = 9.0388e-04, PNorm = 36.0037, GNorm = 3.9461, lr_0 = 1.0202e-04
Loss = 7.6697e-04, PNorm = 36.0051, GNorm = 4.1264, lr_0 = 1.0202e-04
Loss = 7.9516e-04, PNorm = 36.0070, GNorm = 3.2699, lr_0 = 1.0202e-04
Loss = 9.2001e-04, PNorm = 36.0082, GNorm = 6.9459, lr_0 = 1.0202e-04
Loss = 1.2641e-03, PNorm = 36.0098, GNorm = 7.3129, lr_0 = 1.0202e-04
Loss = 7.7450e-04, PNorm = 36.0119, GNorm = 4.1725, lr_0 = 1.0202e-04
Loss = 1.0737e-03, PNorm = 36.0121, GNorm = 2.0338, lr_0 = 1.0202e-04
Validation rmse logP = 0.581868
Validation R2 logP = 0.900807
Epoch 46
Train function
Loss = 1.1500e-03, PNorm = 36.0131, GNorm = 6.9619, lr_0 = 1.0202e-04
Loss = 1.0561e-03, PNorm = 36.0154, GNorm = 1.3082, lr_0 = 1.0202e-04
Loss = 1.0495e-03, PNorm = 36.0179, GNorm = 2.1607, lr_0 = 1.0202e-04
Loss = 1.0133e-03, PNorm = 36.0202, GNorm = 7.4492, lr_0 = 1.0202e-04
Loss = 1.1251e-03, PNorm = 36.0215, GNorm = 7.5940, lr_0 = 1.0202e-04
Loss = 1.0091e-03, PNorm = 36.0236, GNorm = 4.7335, lr_0 = 1.0202e-04
Loss = 9.7133e-04, PNorm = 36.0264, GNorm = 4.1542, lr_0 = 1.0202e-04
Loss = 1.0276e-03, PNorm = 36.0286, GNorm = 3.2766, lr_0 = 1.0202e-04
Loss = 1.0628e-03, PNorm = 36.0298, GNorm = 7.8080, lr_0 = 1.0202e-04
Loss = 8.6051e-04, PNorm = 36.0318, GNorm = 2.7811, lr_0 = 1.0202e-04
Loss = 7.8938e-04, PNorm = 36.0328, GNorm = 1.7232, lr_0 = 1.0202e-04
Loss = 8.6911e-04, PNorm = 36.0348, GNorm = 1.7068, lr_0 = 1.0202e-04
Loss = 8.8158e-04, PNorm = 36.0373, GNorm = 2.6735, lr_0 = 1.0202e-04
Loss = 8.7611e-04, PNorm = 36.0392, GNorm = 4.8662, lr_0 = 1.0202e-04
Loss = 7.9989e-04, PNorm = 36.0405, GNorm = 6.2776, lr_0 = 1.0202e-04
Loss = 1.0965e-03, PNorm = 36.0412, GNorm = 2.0841, lr_0 = 1.0202e-04
Loss = 9.9947e-04, PNorm = 36.0423, GNorm = 1.6731, lr_0 = 1.0202e-04
Loss = 8.9286e-04, PNorm = 36.0432, GNorm = 1.1191, lr_0 = 1.0202e-04
Loss = 7.9553e-04, PNorm = 36.0447, GNorm = 1.5929, lr_0 = 1.0202e-04
Loss = 9.9075e-04, PNorm = 36.0467, GNorm = 6.3095, lr_0 = 1.0202e-04
Loss = 1.1505e-03, PNorm = 36.0484, GNorm = 7.0107, lr_0 = 1.0202e-04
Loss = 1.2486e-03, PNorm = 36.0507, GNorm = 9.8726, lr_0 = 1.0202e-04
Validation rmse logP = 0.491486
Validation R2 logP = 0.929229
Epoch 47
Train function
Loss = 7.8984e-04, PNorm = 36.0523, GNorm = 2.1284, lr_0 = 1.0202e-04
Loss = 7.8736e-04, PNorm = 36.0540, GNorm = 4.4219, lr_0 = 1.0202e-04
Loss = 8.0411e-04, PNorm = 36.0561, GNorm = 2.1009, lr_0 = 1.0202e-04
Loss = 7.9750e-04, PNorm = 36.0577, GNorm = 4.5906, lr_0 = 1.0202e-04
Loss = 8.3293e-04, PNorm = 36.0588, GNorm = 5.4469, lr_0 = 1.0202e-04
Loss = 8.6440e-04, PNorm = 36.0601, GNorm = 2.3381, lr_0 = 1.0202e-04
Loss = 8.8731e-04, PNorm = 36.0621, GNorm = 3.3746, lr_0 = 1.0202e-04
Loss = 1.2713e-03, PNorm = 36.0637, GNorm = 5.1830, lr_0 = 1.0202e-04
Loss = 9.4132e-04, PNorm = 36.0646, GNorm = 2.6984, lr_0 = 1.0202e-04
Loss = 8.6937e-04, PNorm = 36.0671, GNorm = 5.9807, lr_0 = 1.0202e-04
Loss = 8.3215e-04, PNorm = 36.0696, GNorm = 1.5209, lr_0 = 1.0202e-04
Loss = 9.0352e-04, PNorm = 36.0721, GNorm = 2.4345, lr_0 = 1.0202e-04
Loss = 8.3554e-04, PNorm = 36.0744, GNorm = 4.2496, lr_0 = 1.0202e-04
Loss = 6.1864e-04, PNorm = 36.0764, GNorm = 1.9237, lr_0 = 1.0202e-04
Loss = 9.5788e-04, PNorm = 36.0780, GNorm = 1.4938, lr_0 = 1.0202e-04
Loss = 8.7535e-04, PNorm = 36.0796, GNorm = 2.3176, lr_0 = 1.0202e-04
Loss = 1.1132e-03, PNorm = 36.0806, GNorm = 7.5918, lr_0 = 1.0202e-04
Loss = 8.3942e-04, PNorm = 36.0821, GNorm = 1.5286, lr_0 = 1.0202e-04
Loss = 7.2139e-04, PNorm = 36.0839, GNorm = 4.1892, lr_0 = 1.0202e-04
Loss = 8.2649e-04, PNorm = 36.0855, GNorm = 6.3752, lr_0 = 1.0202e-04
Loss = 8.1145e-04, PNorm = 36.0863, GNorm = 2.0120, lr_0 = 1.0202e-04
Loss = 9.5547e-04, PNorm = 36.0878, GNorm = 2.0497, lr_0 = 1.0202e-04
Validation rmse logP = 0.502833
Validation R2 logP = 0.925923
Epoch 48
Train function
Loss = 1.6558e-03, PNorm = 36.0898, GNorm = 8.2468, lr_0 = 1.0202e-04
Loss = 8.5602e-04, PNorm = 36.0912, GNorm = 6.0275, lr_0 = 1.0202e-04
Loss = 7.7314e-04, PNorm = 36.0930, GNorm = 2.7816, lr_0 = 1.0202e-04
Loss = 9.5147e-04, PNorm = 36.0949, GNorm = 6.4213, lr_0 = 1.0202e-04
Loss = 9.2562e-04, PNorm = 36.0968, GNorm = 2.7681, lr_0 = 1.0202e-04
Loss = 7.6727e-04, PNorm = 36.0983, GNorm = 1.2858, lr_0 = 1.0202e-04
Loss = 7.1567e-04, PNorm = 36.0998, GNorm = 2.4009, lr_0 = 1.0202e-04
Loss = 7.9299e-04, PNorm = 36.1023, GNorm = 1.9578, lr_0 = 1.0202e-04
Loss = 9.5466e-04, PNorm = 36.1048, GNorm = 2.7101, lr_0 = 1.0202e-04
Loss = 6.6655e-04, PNorm = 36.1071, GNorm = 1.6990, lr_0 = 1.0202e-04
Loss = 1.0804e-03, PNorm = 36.1082, GNorm = 1.8334, lr_0 = 1.0202e-04
Loss = 1.1420e-03, PNorm = 36.1100, GNorm = 14.2145, lr_0 = 1.0202e-04
Loss = 1.2175e-03, PNorm = 36.1120, GNorm = 10.2265, lr_0 = 1.0202e-04
Loss = 1.0842e-03, PNorm = 36.1138, GNorm = 4.3497, lr_0 = 1.0202e-04
Loss = 9.2560e-04, PNorm = 36.1147, GNorm = 2.1595, lr_0 = 1.0202e-04
Loss = 9.0053e-04, PNorm = 36.1157, GNorm = 2.1250, lr_0 = 1.0202e-04
Loss = 1.0421e-03, PNorm = 36.1167, GNorm = 5.8152, lr_0 = 1.0202e-04
Loss = 8.2309e-04, PNorm = 36.1184, GNorm = 3.9795, lr_0 = 1.0202e-04
Loss = 8.6772e-04, PNorm = 36.1193, GNorm = 1.2999, lr_0 = 1.0202e-04
Loss = 7.7054e-04, PNorm = 36.1210, GNorm = 4.7668, lr_0 = 1.0202e-04
Loss = 9.1442e-04, PNorm = 36.1224, GNorm = 4.7271, lr_0 = 1.0202e-04
Loss = 7.9972e-04, PNorm = 36.1241, GNorm = 5.5574, lr_0 = 1.0202e-04
Loss = 8.6152e-04, PNorm = 36.1254, GNorm = 5.2847, lr_0 = 1.0202e-04
Validation rmse logP = 0.527797
Validation R2 logP = 0.918386
Epoch 49
Train function
Loss = 1.1249e-03, PNorm = 36.1256, GNorm = 8.6106, lr_0 = 1.0202e-04
Loss = 1.1916e-03, PNorm = 36.1284, GNorm = 5.7618, lr_0 = 1.0202e-04
Loss = 8.5630e-04, PNorm = 36.1306, GNorm = 4.8156, lr_0 = 1.0202e-04
Loss = 8.4088e-04, PNorm = 36.1329, GNorm = 4.6748, lr_0 = 1.0202e-04
Loss = 7.3809e-04, PNorm = 36.1352, GNorm = 2.8950, lr_0 = 1.0202e-04
Loss = 8.2832e-04, PNorm = 36.1361, GNorm = 1.1259, lr_0 = 1.0202e-04
Loss = 7.7675e-04, PNorm = 36.1380, GNorm = 2.1141, lr_0 = 1.0202e-04
Loss = 7.1887e-04, PNorm = 36.1396, GNorm = 2.4438, lr_0 = 1.0202e-04
Loss = 8.6577e-04, PNorm = 36.1410, GNorm = 1.8948, lr_0 = 1.0202e-04
Loss = 8.8014e-04, PNorm = 36.1423, GNorm = 1.8152, lr_0 = 1.0202e-04
Loss = 8.0585e-04, PNorm = 36.1434, GNorm = 4.7600, lr_0 = 1.0202e-04
Loss = 7.5825e-04, PNorm = 36.1442, GNorm = 2.0226, lr_0 = 1.0202e-04
Loss = 8.8809e-04, PNorm = 36.1457, GNorm = 4.0873, lr_0 = 1.0202e-04
Loss = 9.2558e-04, PNorm = 36.1480, GNorm = 3.4935, lr_0 = 1.0202e-04
Loss = 8.8476e-04, PNorm = 36.1501, GNorm = 7.2439, lr_0 = 1.0202e-04
Loss = 8.6410e-04, PNorm = 36.1518, GNorm = 1.5793, lr_0 = 1.0202e-04
Loss = 8.5419e-04, PNorm = 36.1543, GNorm = 1.5572, lr_0 = 1.0202e-04
Loss = 8.0197e-04, PNorm = 36.1555, GNorm = 2.7019, lr_0 = 1.0202e-04
Loss = 9.2810e-04, PNorm = 36.1574, GNorm = 3.5991, lr_0 = 1.0202e-04
Loss = 9.6832e-04, PNorm = 36.1588, GNorm = 1.7598, lr_0 = 1.0202e-04
Loss = 9.1984e-04, PNorm = 36.1597, GNorm = 1.2502, lr_0 = 1.0202e-04
Loss = 8.5337e-04, PNorm = 36.1613, GNorm = 1.9643, lr_0 = 1.0202e-04
Validation rmse logP = 0.493824
Validation R2 logP = 0.928554
Epoch 50
Train function
Loss = 1.0354e-03, PNorm = 36.1632, GNorm = 7.2087, lr_0 = 1.0202e-04
Loss = 8.8327e-04, PNorm = 36.1648, GNorm = 5.7901, lr_0 = 1.0202e-04
Loss = 1.1235e-03, PNorm = 36.1663, GNorm = 8.1963, lr_0 = 1.0202e-04
Loss = 7.8335e-04, PNorm = 36.1676, GNorm = 5.0008, lr_0 = 1.0202e-04
Loss = 7.2789e-04, PNorm = 36.1695, GNorm = 3.9096, lr_0 = 1.0202e-04
Loss = 7.7836e-04, PNorm = 36.1708, GNorm = 5.5417, lr_0 = 1.0202e-04
Loss = 9.3561e-04, PNorm = 36.1720, GNorm = 4.3345, lr_0 = 1.0202e-04
Loss = 7.7197e-04, PNorm = 36.1737, GNorm = 3.2651, lr_0 = 1.0202e-04
Loss = 8.0894e-04, PNorm = 36.1753, GNorm = 1.7353, lr_0 = 1.0202e-04
Loss = 8.6623e-04, PNorm = 36.1766, GNorm = 3.9705, lr_0 = 1.0202e-04
Loss = 9.0903e-04, PNorm = 36.1790, GNorm = 6.7439, lr_0 = 1.0202e-04
Loss = 9.5811e-04, PNorm = 36.1808, GNorm = 12.0212, lr_0 = 1.0202e-04
Loss = 1.1776e-03, PNorm = 36.1828, GNorm = 6.7818, lr_0 = 1.0202e-04
Loss = 9.6897e-04, PNorm = 36.1836, GNorm = 7.3757, lr_0 = 1.0202e-04
Loss = 7.6357e-04, PNorm = 36.1846, GNorm = 3.7565, lr_0 = 1.0202e-04
Loss = 8.9711e-04, PNorm = 36.1865, GNorm = 1.3891, lr_0 = 1.0202e-04
Loss = 8.0023e-04, PNorm = 36.1886, GNorm = 9.1808, lr_0 = 1.0202e-04
Loss = 8.7189e-04, PNorm = 36.1898, GNorm = 4.9712, lr_0 = 1.0202e-04
Loss = 9.3388e-04, PNorm = 36.1922, GNorm = 5.3358, lr_0 = 1.0202e-04
Loss = 9.6578e-04, PNorm = 36.1945, GNorm = 5.9512, lr_0 = 1.0202e-04
Loss = 1.1846e-03, PNorm = 36.1966, GNorm = 8.7087, lr_0 = 1.0202e-04
Loss = 1.0495e-03, PNorm = 36.1989, GNorm = 6.3403, lr_0 = 1.0202e-04
Loss = 8.8181e-04, PNorm = 36.2006, GNorm = 3.4758, lr_0 = 1.0202e-04
Loss = 7.1885e-04, PNorm = 36.2008, GNorm = 2.9090, lr_0 = 1.0202e-04
Validation rmse logP = 0.480829
Validation R2 logP = 0.932265
Epoch 51
Train function
Loss = 7.1186e-04, PNorm = 36.2026, GNorm = 4.2225, lr_0 = 1.0202e-04
Loss = 8.7978e-04, PNorm = 36.2039, GNorm = 2.5283, lr_0 = 1.0202e-04
Loss = 1.0411e-03, PNorm = 36.2053, GNorm = 4.3554, lr_0 = 1.0202e-04
Loss = 1.1098e-03, PNorm = 36.2069, GNorm = 4.0535, lr_0 = 1.0202e-04
Loss = 8.9618e-04, PNorm = 36.2089, GNorm = 7.1164, lr_0 = 1.0202e-04
Loss = 8.1470e-04, PNorm = 36.2115, GNorm = 3.8312, lr_0 = 1.0202e-04
Loss = 8.2869e-04, PNorm = 36.2135, GNorm = 3.6156, lr_0 = 1.0202e-04
Loss = 9.3940e-04, PNorm = 36.2153, GNorm = 7.6018, lr_0 = 1.0202e-04
Loss = 1.0354e-03, PNorm = 36.2168, GNorm = 12.6429, lr_0 = 1.0202e-04
Loss = 1.0069e-03, PNorm = 36.2186, GNorm = 1.8396, lr_0 = 1.0202e-04
Loss = 8.6756e-04, PNorm = 36.2196, GNorm = 3.4436, lr_0 = 1.0202e-04
Loss = 1.1350e-03, PNorm = 36.2214, GNorm = 9.4715, lr_0 = 1.0202e-04
Loss = 8.7118e-04, PNorm = 36.2230, GNorm = 2.8629, lr_0 = 1.0202e-04
Loss = 9.5148e-04, PNorm = 36.2246, GNorm = 2.5914, lr_0 = 1.0202e-04
Loss = 9.2519e-04, PNorm = 36.2264, GNorm = 4.9383, lr_0 = 1.0202e-04
Loss = 8.8211e-04, PNorm = 36.2275, GNorm = 5.8532, lr_0 = 1.0202e-04
Loss = 8.7905e-04, PNorm = 36.2279, GNorm = 5.6501, lr_0 = 1.0202e-04
Loss = 8.0916e-04, PNorm = 36.2292, GNorm = 3.1189, lr_0 = 1.0202e-04
Loss = 8.2052e-04, PNorm = 36.2309, GNorm = 1.5635, lr_0 = 1.0202e-04
Loss = 7.7829e-04, PNorm = 36.2327, GNorm = 2.6076, lr_0 = 1.0202e-04
Loss = 6.7649e-04, PNorm = 36.2349, GNorm = 2.4808, lr_0 = 1.0202e-04
Loss = 8.4323e-04, PNorm = 36.2362, GNorm = 3.9732, lr_0 = 1.0202e-04
Validation rmse logP = 0.503980
Validation R2 logP = 0.925585
Epoch 52
Train function
Loss = 7.2762e-04, PNorm = 36.2377, GNorm = 1.8018, lr_0 = 1.0202e-04
Loss = 7.4497e-04, PNorm = 36.2393, GNorm = 2.6968, lr_0 = 1.0202e-04
Loss = 7.6374e-04, PNorm = 36.2412, GNorm = 5.3703, lr_0 = 1.0202e-04
Loss = 8.3330e-04, PNorm = 36.2434, GNorm = 2.4461, lr_0 = 1.0202e-04
Loss = 6.9168e-04, PNorm = 36.2461, GNorm = 4.5465, lr_0 = 1.0202e-04
Loss = 8.8942e-04, PNorm = 36.2482, GNorm = 2.2218, lr_0 = 1.0202e-04
Loss = 1.0075e-03, PNorm = 36.2493, GNorm = 9.1794, lr_0 = 1.0202e-04
Loss = 1.0865e-03, PNorm = 36.2508, GNorm = 1.3565, lr_0 = 1.0202e-04
Loss = 8.5541e-04, PNorm = 36.2521, GNorm = 2.8167, lr_0 = 1.0202e-04
Loss = 7.8627e-04, PNorm = 36.2541, GNorm = 1.8179, lr_0 = 1.0202e-04
Loss = 6.7616e-04, PNorm = 36.2558, GNorm = 1.9732, lr_0 = 1.0202e-04
Loss = 5.7645e-04, PNorm = 36.2568, GNorm = 1.2597, lr_0 = 1.0202e-04
Loss = 7.5674e-04, PNorm = 36.2586, GNorm = 3.5779, lr_0 = 1.0202e-04
Loss = 1.0762e-03, PNorm = 36.2607, GNorm = 4.3996, lr_0 = 1.0202e-04
Loss = 8.5252e-04, PNorm = 36.2624, GNorm = 2.5919, lr_0 = 1.0202e-04
Loss = 8.6395e-04, PNorm = 36.2631, GNorm = 2.6840, lr_0 = 1.0202e-04
Loss = 8.5863e-04, PNorm = 36.2648, GNorm = 3.7432, lr_0 = 1.0202e-04
Loss = 9.5485e-04, PNorm = 36.2662, GNorm = 5.3634, lr_0 = 1.0202e-04
Loss = 7.0080e-04, PNorm = 36.2679, GNorm = 1.7503, lr_0 = 1.0202e-04
Loss = 8.3413e-04, PNorm = 36.2693, GNorm = 1.3868, lr_0 = 1.0202e-04
Loss = 8.8634e-04, PNorm = 36.2705, GNorm = 1.2250, lr_0 = 1.0202e-04
Loss = 8.3612e-04, PNorm = 36.2718, GNorm = 7.4829, lr_0 = 1.0202e-04
Validation rmse logP = 0.483575
Validation R2 logP = 0.931489
Epoch 53
Train function
Loss = 1.0705e-03, PNorm = 36.2733, GNorm = 7.8478, lr_0 = 1.0202e-04
Loss = 7.1556e-04, PNorm = 36.2751, GNorm = 1.8015, lr_0 = 1.0202e-04
Loss = 7.8729e-04, PNorm = 36.2773, GNorm = 2.6403, lr_0 = 1.0202e-04
Loss = 9.2862e-04, PNorm = 36.2787, GNorm = 8.6684, lr_0 = 1.0202e-04
Loss = 8.9784e-04, PNorm = 36.2812, GNorm = 5.9176, lr_0 = 1.0202e-04
Loss = 7.4543e-04, PNorm = 36.2834, GNorm = 4.4041, lr_0 = 1.0202e-04
Loss = 8.2475e-04, PNorm = 36.2859, GNorm = 1.8470, lr_0 = 1.0202e-04
Loss = 7.0189e-04, PNorm = 36.2877, GNorm = 2.4316, lr_0 = 1.0202e-04
Loss = 6.7200e-04, PNorm = 36.2893, GNorm = 3.9453, lr_0 = 1.0202e-04
Loss = 6.8455e-04, PNorm = 36.2903, GNorm = 3.4894, lr_0 = 1.0202e-04
Loss = 6.6767e-04, PNorm = 36.2919, GNorm = 3.0657, lr_0 = 1.0202e-04
Loss = 9.3296e-04, PNorm = 36.2937, GNorm = 4.4775, lr_0 = 1.0202e-04
Loss = 6.5977e-04, PNorm = 36.2952, GNorm = 4.6607, lr_0 = 1.0202e-04
Loss = 1.0115e-03, PNorm = 36.2968, GNorm = 7.5367, lr_0 = 1.0202e-04
Loss = 8.3687e-04, PNorm = 36.2978, GNorm = 4.5719, lr_0 = 1.0202e-04
Loss = 9.4670e-04, PNorm = 36.2993, GNorm = 3.0178, lr_0 = 1.0202e-04
Loss = 9.2556e-04, PNorm = 36.3012, GNorm = 4.8970, lr_0 = 1.0202e-04
Loss = 8.7498e-04, PNorm = 36.3034, GNorm = 1.6259, lr_0 = 1.0202e-04
Loss = 7.0794e-04, PNorm = 36.3055, GNorm = 1.3414, lr_0 = 1.0202e-04
Loss = 8.7384e-04, PNorm = 36.3070, GNorm = 7.3404, lr_0 = 1.0202e-04
Loss = 8.0332e-04, PNorm = 36.3091, GNorm = 1.5093, lr_0 = 1.0202e-04
Loss = 7.9031e-04, PNorm = 36.3108, GNorm = 2.1277, lr_0 = 1.0202e-04
Loss = 8.3367e-04, PNorm = 36.3116, GNorm = 2.0474, lr_0 = 1.0202e-04
Validation rmse logP = 0.501545
Validation R2 logP = 0.926303
Epoch 54
Train function
Loss = 7.0057e-04, PNorm = 36.3141, GNorm = 0.7717, lr_0 = 1.0202e-04
Loss = 8.1250e-04, PNorm = 36.3164, GNorm = 1.4634, lr_0 = 1.0202e-04
Loss = 7.9044e-04, PNorm = 36.3176, GNorm = 3.1664, lr_0 = 1.0202e-04
Loss = 8.7445e-04, PNorm = 36.3188, GNorm = 8.4311, lr_0 = 1.0202e-04
Loss = 1.1106e-03, PNorm = 36.3189, GNorm = 1.9340, lr_0 = 1.0202e-04
Loss = 8.8644e-04, PNorm = 36.3198, GNorm = 4.9167, lr_0 = 1.0202e-04
Loss = 6.6827e-04, PNorm = 36.3217, GNorm = 4.8456, lr_0 = 1.0202e-04
Loss = 7.2590e-04, PNorm = 36.3240, GNorm = 2.7564, lr_0 = 1.0202e-04
Loss = 9.5084e-04, PNorm = 36.3261, GNorm = 5.5124, lr_0 = 1.0202e-04
Loss = 7.4332e-04, PNorm = 36.3273, GNorm = 3.2061, lr_0 = 1.0202e-04
Loss = 7.2370e-04, PNorm = 36.3284, GNorm = 1.1567, lr_0 = 1.0202e-04
Loss = 8.8742e-04, PNorm = 36.3305, GNorm = 2.8377, lr_0 = 1.0202e-04
Loss = 7.8901e-04, PNorm = 36.3326, GNorm = 5.9703, lr_0 = 1.0202e-04
Loss = 1.0358e-03, PNorm = 36.3353, GNorm = 1.1637, lr_0 = 1.0202e-04
Loss = 8.2577e-04, PNorm = 36.3386, GNorm = 3.3921, lr_0 = 1.0202e-04
Loss = 6.1227e-04, PNorm = 36.3406, GNorm = 1.4590, lr_0 = 1.0202e-04
Loss = 7.5031e-04, PNorm = 36.3417, GNorm = 6.0934, lr_0 = 1.0202e-04
Loss = 8.3521e-04, PNorm = 36.3415, GNorm = 3.5815, lr_0 = 1.0202e-04
Loss = 7.0878e-04, PNorm = 36.3423, GNorm = 7.1242, lr_0 = 1.0202e-04
Loss = 7.8869e-04, PNorm = 36.3440, GNorm = 5.5101, lr_0 = 1.0202e-04
Loss = 8.1070e-04, PNorm = 36.3461, GNorm = 1.8480, lr_0 = 1.0202e-04
Loss = 8.6310e-04, PNorm = 36.3489, GNorm = 5.9749, lr_0 = 1.0202e-04
Validation rmse logP = 0.489520
Validation R2 logP = 0.929794
Epoch 55
Train function
Loss = 7.6450e-04, PNorm = 36.3508, GNorm = 2.3865, lr_0 = 1.0202e-04
Loss = 6.0972e-04, PNorm = 36.3525, GNorm = 4.0978, lr_0 = 1.0202e-04
Loss = 7.0745e-04, PNorm = 36.3536, GNorm = 6.4237, lr_0 = 1.0202e-04
Loss = 6.0558e-04, PNorm = 36.3544, GNorm = 4.4168, lr_0 = 1.0202e-04
Loss = 6.9731e-04, PNorm = 36.3558, GNorm = 3.1329, lr_0 = 1.0202e-04
Loss = 7.4082e-04, PNorm = 36.3569, GNorm = 4.5198, lr_0 = 1.0202e-04
Loss = 7.0144e-04, PNorm = 36.3584, GNorm = 2.3371, lr_0 = 1.0202e-04
Loss = 9.0170e-04, PNorm = 36.3595, GNorm = 3.7139, lr_0 = 1.0202e-04
Loss = 8.3483e-04, PNorm = 36.3605, GNorm = 1.7219, lr_0 = 1.0202e-04
Loss = 6.8179e-04, PNorm = 36.3624, GNorm = 1.2552, lr_0 = 1.0202e-04
Loss = 6.8035e-04, PNorm = 36.3643, GNorm = 2.0838, lr_0 = 1.0202e-04
Loss = 8.0313e-04, PNorm = 36.3665, GNorm = 2.6852, lr_0 = 1.0202e-04
Loss = 9.5292e-04, PNorm = 36.3686, GNorm = 3.6651, lr_0 = 1.0202e-04
Loss = 6.3242e-04, PNorm = 36.3702, GNorm = 0.9850, lr_0 = 1.0202e-04
Loss = 8.4751e-04, PNorm = 36.3706, GNorm = 5.2627, lr_0 = 1.0202e-04
Loss = 8.4198e-04, PNorm = 36.3717, GNorm = 3.2284, lr_0 = 1.0202e-04
Loss = 8.6582e-04, PNorm = 36.3730, GNorm = 1.7997, lr_0 = 1.0202e-04
Loss = 7.0164e-04, PNorm = 36.3743, GNorm = 1.9898, lr_0 = 1.0202e-04
Loss = 7.8614e-04, PNorm = 36.3763, GNorm = 4.1472, lr_0 = 1.0202e-04
Loss = 8.7110e-04, PNorm = 36.3786, GNorm = 7.4443, lr_0 = 1.0202e-04
Loss = 1.2003e-03, PNorm = 36.3807, GNorm = 8.6918, lr_0 = 1.0202e-04
Loss = 8.3850e-04, PNorm = 36.3832, GNorm = 4.1591, lr_0 = 1.0202e-04
Validation rmse logP = 0.515608
Validation R2 logP = 0.922112
Epoch 56
Train function
Loss = 9.0412e-04, PNorm = 36.3849, GNorm = 6.1159, lr_0 = 1.0202e-04
Loss = 6.0366e-04, PNorm = 36.3868, GNorm = 1.6267, lr_0 = 1.0202e-04
Loss = 7.4442e-04, PNorm = 36.3890, GNorm = 2.8313, lr_0 = 1.0202e-04
Loss = 7.4871e-04, PNorm = 36.3916, GNorm = 3.6406, lr_0 = 1.0202e-04
Loss = 8.7188e-04, PNorm = 36.3931, GNorm = 3.3915, lr_0 = 1.0202e-04
Loss = 8.2891e-04, PNorm = 36.3949, GNorm = 8.5647, lr_0 = 1.0202e-04
Loss = 8.6744e-04, PNorm = 36.3965, GNorm = 3.0999, lr_0 = 1.0202e-04
Loss = 7.7199e-04, PNorm = 36.3982, GNorm = 2.7039, lr_0 = 1.0202e-04
Loss = 9.0133e-04, PNorm = 36.4004, GNorm = 8.5874, lr_0 = 1.0202e-04
Loss = 8.6714e-04, PNorm = 36.4028, GNorm = 4.9122, lr_0 = 1.0202e-04
Loss = 9.2798e-04, PNorm = 36.4044, GNorm = 3.1324, lr_0 = 1.0202e-04
Loss = 8.1866e-04, PNorm = 36.4054, GNorm = 7.4312, lr_0 = 1.0202e-04
Loss = 8.5405e-04, PNorm = 36.4059, GNorm = 3.7975, lr_0 = 1.0202e-04
Loss = 8.9952e-04, PNorm = 36.4066, GNorm = 2.5908, lr_0 = 1.0202e-04
Loss = 8.3333e-04, PNorm = 36.4082, GNorm = 1.3806, lr_0 = 1.0202e-04
Loss = 7.7966e-04, PNorm = 36.4096, GNorm = 3.5717, lr_0 = 1.0202e-04
Loss = 7.9950e-04, PNorm = 36.4111, GNorm = 1.5206, lr_0 = 1.0202e-04
Loss = 7.2885e-04, PNorm = 36.4131, GNorm = 3.6866, lr_0 = 1.0202e-04
Loss = 8.4275e-04, PNorm = 36.4159, GNorm = 7.2034, lr_0 = 1.0202e-04
Loss = 8.0493e-04, PNorm = 36.4172, GNorm = 3.6243, lr_0 = 1.0202e-04
Loss = 6.7828e-04, PNorm = 36.4191, GNorm = 3.9805, lr_0 = 1.0202e-04
Loss = 8.2196e-04, PNorm = 36.4198, GNorm = 5.2547, lr_0 = 1.0202e-04
Loss = 9.1250e-04, PNorm = 36.4218, GNorm = 6.6651, lr_0 = 1.0202e-04
Validation rmse logP = 0.517760
Validation R2 logP = 0.921460
Epoch 57
Train function
Loss = 6.6302e-04, PNorm = 36.4240, GNorm = 3.6032, lr_0 = 1.0202e-04
Loss = 7.6333e-04, PNorm = 36.4258, GNorm = 2.9427, lr_0 = 1.0202e-04
Loss = 7.2205e-04, PNorm = 36.4276, GNorm = 1.8071, lr_0 = 1.0202e-04
Loss = 7.3509e-04, PNorm = 36.4297, GNorm = 1.2507, lr_0 = 1.0202e-04
Loss = 7.5362e-04, PNorm = 36.4313, GNorm = 1.1323, lr_0 = 1.0202e-04
Loss = 7.0489e-04, PNorm = 36.4331, GNorm = 5.4012, lr_0 = 1.0202e-04
Loss = 6.8157e-04, PNorm = 36.4343, GNorm = 3.3637, lr_0 = 1.0202e-04
Loss = 8.7897e-04, PNorm = 36.4375, GNorm = 1.9198, lr_0 = 1.0202e-04
Loss = 7.4074e-04, PNorm = 36.4398, GNorm = 4.1173, lr_0 = 1.0202e-04
Loss = 8.9548e-04, PNorm = 36.4416, GNorm = 5.3163, lr_0 = 1.0202e-04
Loss = 9.8005e-04, PNorm = 36.4428, GNorm = 9.5658, lr_0 = 1.0202e-04
Loss = 9.2139e-04, PNorm = 36.4449, GNorm = 4.7941, lr_0 = 1.0202e-04
Loss = 8.8386e-04, PNorm = 36.4473, GNorm = 4.7957, lr_0 = 1.0202e-04
Loss = 7.9307e-04, PNorm = 36.4487, GNorm = 2.4424, lr_0 = 1.0202e-04
Loss = 8.5949e-04, PNorm = 36.4500, GNorm = 2.3093, lr_0 = 1.0202e-04
Loss = 6.5100e-04, PNorm = 36.4517, GNorm = 1.9392, lr_0 = 1.0202e-04
Loss = 7.4273e-04, PNorm = 36.4535, GNorm = 2.4161, lr_0 = 1.0202e-04
Loss = 7.5427e-04, PNorm = 36.4543, GNorm = 7.9908, lr_0 = 1.0202e-04
Loss = 7.4623e-04, PNorm = 36.4559, GNorm = 2.6732, lr_0 = 1.0202e-04
Loss = 7.5224e-04, PNorm = 36.4577, GNorm = 1.8300, lr_0 = 1.0202e-04
Loss = 7.8987e-04, PNorm = 36.4583, GNorm = 1.3547, lr_0 = 1.0202e-04
Loss = 7.0826e-04, PNorm = 36.4596, GNorm = 7.7966, lr_0 = 1.0202e-04
Validation rmse logP = 0.466453
Validation R2 logP = 0.936255
Epoch 58
Train function
Loss = 8.2661e-04, PNorm = 36.4615, GNorm = 1.9360, lr_0 = 1.0202e-04
Loss = 7.0352e-04, PNorm = 36.4634, GNorm = 1.6049, lr_0 = 1.0202e-04
Loss = 6.4063e-04, PNorm = 36.4662, GNorm = 4.2406, lr_0 = 1.0202e-04
Loss = 9.7418e-04, PNorm = 36.4685, GNorm = 3.6126, lr_0 = 1.0202e-04
Loss = 8.2000e-04, PNorm = 36.4705, GNorm = 2.7706, lr_0 = 1.0202e-04
Loss = 8.3044e-04, PNorm = 36.4718, GNorm = 2.3406, lr_0 = 1.0202e-04
Loss = 6.4826e-04, PNorm = 36.4736, GNorm = 1.2590, lr_0 = 1.0202e-04
Loss = 8.3158e-04, PNorm = 36.4753, GNorm = 1.8687, lr_0 = 1.0202e-04
Loss = 5.6464e-04, PNorm = 36.4763, GNorm = 2.6011, lr_0 = 1.0202e-04
Loss = 6.4383e-04, PNorm = 36.4773, GNorm = 3.6040, lr_0 = 1.0202e-04
Loss = 6.3012e-04, PNorm = 36.4785, GNorm = 1.2938, lr_0 = 1.0202e-04
Loss = 6.3221e-04, PNorm = 36.4793, GNorm = 2.7377, lr_0 = 1.0202e-04
Loss = 6.8653e-04, PNorm = 36.4809, GNorm = 1.5339, lr_0 = 1.0202e-04
Loss = 7.5821e-04, PNorm = 36.4823, GNorm = 1.8197, lr_0 = 1.0202e-04
Loss = 6.4158e-04, PNorm = 36.4836, GNorm = 4.8601, lr_0 = 1.0202e-04
Loss = 7.3278e-04, PNorm = 36.4848, GNorm = 3.4926, lr_0 = 1.0202e-04
Loss = 6.5125e-04, PNorm = 36.4864, GNorm = 2.0033, lr_0 = 1.0202e-04
Loss = 6.6784e-04, PNorm = 36.4878, GNorm = 3.0471, lr_0 = 1.0202e-04
Loss = 5.3720e-04, PNorm = 36.4885, GNorm = 0.9788, lr_0 = 1.0202e-04
Loss = 7.2501e-04, PNorm = 36.4899, GNorm = 3.0860, lr_0 = 1.0202e-04
Loss = 9.2332e-04, PNorm = 36.4920, GNorm = 1.8577, lr_0 = 1.0202e-04
Loss = 1.0365e-03, PNorm = 36.4941, GNorm = 5.8379, lr_0 = 1.0202e-04
Validation rmse logP = 0.478436
Validation R2 logP = 0.932937
Epoch 59
Train function
Loss = 7.3108e-04, PNorm = 36.4966, GNorm = 4.7948, lr_0 = 1.0202e-04
Loss = 6.1844e-04, PNorm = 36.4993, GNorm = 1.8752, lr_0 = 1.0202e-04
Loss = 6.3577e-04, PNorm = 36.5009, GNorm = 2.4756, lr_0 = 1.0202e-04
Loss = 5.2617e-04, PNorm = 36.5027, GNorm = 1.6234, lr_0 = 1.0202e-04
Loss = 6.2300e-04, PNorm = 36.5040, GNorm = 2.4445, lr_0 = 1.0202e-04
Loss = 7.5142e-04, PNorm = 36.5053, GNorm = 2.5632, lr_0 = 1.0202e-04
Loss = 7.2819e-04, PNorm = 36.5066, GNorm = 2.2644, lr_0 = 1.0202e-04
Loss = 7.9980e-04, PNorm = 36.5081, GNorm = 3.9558, lr_0 = 1.0202e-04
Loss = 8.7620e-04, PNorm = 36.5104, GNorm = 6.8925, lr_0 = 1.0202e-04
Loss = 6.9955e-04, PNorm = 36.5124, GNorm = 5.0906, lr_0 = 1.0202e-04
Loss = 6.1441e-04, PNorm = 36.5148, GNorm = 4.0162, lr_0 = 1.0202e-04
Loss = 8.4508e-04, PNorm = 36.5163, GNorm = 1.2022, lr_0 = 1.0202e-04
Loss = 7.5297e-04, PNorm = 36.5168, GNorm = 4.0237, lr_0 = 1.0202e-04
Loss = 6.2872e-04, PNorm = 36.5175, GNorm = 1.3697, lr_0 = 1.0202e-04
Loss = 6.5518e-04, PNorm = 36.5177, GNorm = 1.6368, lr_0 = 1.0202e-04
Loss = 7.9708e-04, PNorm = 36.5182, GNorm = 9.3229, lr_0 = 1.0202e-04
Loss = 7.8486e-04, PNorm = 36.5199, GNorm = 4.7015, lr_0 = 1.0202e-04
Loss = 1.0394e-03, PNorm = 36.5209, GNorm = 3.0896, lr_0 = 1.0202e-04
Loss = 1.0917e-03, PNorm = 36.5225, GNorm = 15.8245, lr_0 = 1.0202e-04
Loss = 1.1300e-03, PNorm = 36.5239, GNorm = 3.8251, lr_0 = 1.0202e-04
Loss = 9.2883e-04, PNorm = 36.5260, GNorm = 4.9250, lr_0 = 1.0202e-04
Loss = 8.9042e-04, PNorm = 36.5286, GNorm = 2.9372, lr_0 = 1.0202e-04
Loss = 8.2294e-04, PNorm = 36.5309, GNorm = 5.9074, lr_0 = 1.0202e-04
Validation rmse logP = 0.521811
Validation R2 logP = 0.920227
Epoch 60
Train function
Loss = 7.8894e-04, PNorm = 36.5326, GNorm = 4.2649, lr_0 = 1.0202e-04
Loss = 6.4203e-04, PNorm = 36.5351, GNorm = 4.0518, lr_0 = 1.0202e-04
Loss = 7.8248e-04, PNorm = 36.5364, GNorm = 3.8458, lr_0 = 1.0202e-04
Loss = 6.9517e-04, PNorm = 36.5387, GNorm = 7.5931, lr_0 = 1.0202e-04
Loss = 6.5245e-04, PNorm = 36.5401, GNorm = 4.3905, lr_0 = 1.0202e-04
Loss = 7.2613e-04, PNorm = 36.5421, GNorm = 2.1265, lr_0 = 1.0202e-04
Loss = 6.9724e-04, PNorm = 36.5441, GNorm = 1.9847, lr_0 = 1.0202e-04
Loss = 7.0197e-04, PNorm = 36.5456, GNorm = 4.7752, lr_0 = 1.0202e-04
Loss = 6.3246e-04, PNorm = 36.5468, GNorm = 2.3364, lr_0 = 1.0202e-04
Loss = 7.2108e-04, PNorm = 36.5485, GNorm = 2.0607, lr_0 = 1.0202e-04
Loss = 6.1985e-04, PNorm = 36.5502, GNorm = 3.2900, lr_0 = 1.0202e-04
Loss = 6.2997e-04, PNorm = 36.5518, GNorm = 2.8607, lr_0 = 1.0202e-04
Loss = 8.3069e-04, PNorm = 36.5545, GNorm = 4.9840, lr_0 = 1.0202e-04
Loss = 7.4534e-04, PNorm = 36.5552, GNorm = 2.0480, lr_0 = 1.0202e-04
Loss = 6.9487e-04, PNorm = 36.5564, GNorm = 2.6884, lr_0 = 1.0202e-04
Loss = 7.1196e-04, PNorm = 36.5576, GNorm = 2.2079, lr_0 = 1.0202e-04
Loss = 9.3752e-04, PNorm = 36.5591, GNorm = 3.2083, lr_0 = 1.0202e-04
Loss = 9.1411e-04, PNorm = 36.5610, GNorm = 2.2185, lr_0 = 1.0202e-04
Loss = 5.6947e-04, PNorm = 36.5626, GNorm = 0.9154, lr_0 = 1.0202e-04
Loss = 7.4641e-04, PNorm = 36.5647, GNorm = 2.3836, lr_0 = 1.0202e-04
Loss = 6.7419e-04, PNorm = 36.5670, GNorm = 7.0838, lr_0 = 1.0202e-04
Loss = 7.2317e-04, PNorm = 36.5679, GNorm = 4.9091, lr_0 = 1.0202e-04
Validation rmse logP = 0.494094
Validation R2 logP = 0.928476
Epoch 61
Train function
Loss = 6.9346e-04, PNorm = 36.5692, GNorm = 4.5447, lr_0 = 1.0202e-04
Loss = 9.7055e-04, PNorm = 36.5710, GNorm = 4.1274, lr_0 = 1.0202e-04
Loss = 8.6237e-04, PNorm = 36.5740, GNorm = 3.3470, lr_0 = 1.0202e-04
Loss = 7.8684e-04, PNorm = 36.5752, GNorm = 3.4377, lr_0 = 1.0202e-04
Loss = 8.2367e-04, PNorm = 36.5778, GNorm = 2.5131, lr_0 = 1.0202e-04
Loss = 6.7519e-04, PNorm = 36.5795, GNorm = 2.2952, lr_0 = 1.0202e-04
Loss = 5.5917e-04, PNorm = 36.5802, GNorm = 3.4133, lr_0 = 1.0202e-04
Loss = 6.6756e-04, PNorm = 36.5818, GNorm = 4.2648, lr_0 = 1.0202e-04
Loss = 7.6924e-04, PNorm = 36.5820, GNorm = 5.9858, lr_0 = 1.0202e-04
Loss = 5.8541e-04, PNorm = 36.5834, GNorm = 4.8225, lr_0 = 1.0202e-04
Loss = 8.0449e-04, PNorm = 36.5853, GNorm = 2.8832, lr_0 = 1.0202e-04
Loss = 7.5934e-04, PNorm = 36.5868, GNorm = 1.7267, lr_0 = 1.0202e-04
Loss = 6.7380e-04, PNorm = 36.5894, GNorm = 3.2590, lr_0 = 1.0202e-04
Loss = 8.7906e-04, PNorm = 36.5913, GNorm = 1.9857, lr_0 = 1.0202e-04
Loss = 6.9279e-04, PNorm = 36.5932, GNorm = 2.7831, lr_0 = 1.0202e-04
Loss = 8.0185e-04, PNorm = 36.5942, GNorm = 3.2870, lr_0 = 1.0202e-04
Loss = 8.7855e-04, PNorm = 36.5962, GNorm = 2.3324, lr_0 = 1.0202e-04
Loss = 8.8445e-04, PNorm = 36.5978, GNorm = 2.1438, lr_0 = 1.0202e-04
Loss = 9.0910e-04, PNorm = 36.5987, GNorm = 3.7780, lr_0 = 1.0202e-04
Loss = 1.0526e-03, PNorm = 36.6001, GNorm = 6.6979, lr_0 = 1.0202e-04
Loss = 1.0011e-03, PNorm = 36.6016, GNorm = 2.5431, lr_0 = 1.0202e-04
Loss = 6.9747e-04, PNorm = 36.6033, GNorm = 4.3864, lr_0 = 1.0202e-04
Validation rmse logP = 0.473207
Validation R2 logP = 0.934395
Epoch 62
Train function
Loss = 3.8423e-04, PNorm = 36.6048, GNorm = 2.3871, lr_0 = 1.0202e-04
Loss = 7.3496e-04, PNorm = 36.6066, GNorm = 3.8022, lr_0 = 1.0202e-04
Loss = 7.1902e-04, PNorm = 36.6075, GNorm = 7.9703, lr_0 = 1.0202e-04
Loss = 8.1552e-04, PNorm = 36.6089, GNorm = 2.4887, lr_0 = 1.0202e-04
Loss = 1.0726e-03, PNorm = 36.6104, GNorm = 1.7494, lr_0 = 1.0202e-04
Loss = 8.5959e-04, PNorm = 36.6126, GNorm = 3.7270, lr_0 = 1.0202e-04
Loss = 9.2206e-04, PNorm = 36.6157, GNorm = 2.4873, lr_0 = 1.0202e-04
Loss = 8.5591e-04, PNorm = 36.6175, GNorm = 1.5300, lr_0 = 1.0202e-04
Loss = 8.0319e-04, PNorm = 36.6196, GNorm = 3.0170, lr_0 = 1.0202e-04
Loss = 6.3679e-04, PNorm = 36.6208, GNorm = 2.0233, lr_0 = 1.0202e-04
Loss = 7.0109e-04, PNorm = 36.6223, GNorm = 2.1339, lr_0 = 1.0202e-04
Loss = 6.1934e-04, PNorm = 36.6248, GNorm = 3.3517, lr_0 = 1.0202e-04
Loss = 8.4017e-04, PNorm = 36.6274, GNorm = 6.4211, lr_0 = 1.0202e-04
Loss = 7.6564e-04, PNorm = 36.6296, GNorm = 3.2626, lr_0 = 1.0202e-04
Loss = 5.9981e-04, PNorm = 36.6312, GNorm = 0.8891, lr_0 = 1.0202e-04
Loss = 6.6488e-04, PNorm = 36.6336, GNorm = 2.6153, lr_0 = 1.0202e-04
Loss = 8.1599e-04, PNorm = 36.6350, GNorm = 2.0383, lr_0 = 1.0202e-04
Loss = 7.0439e-04, PNorm = 36.6363, GNorm = 3.8085, lr_0 = 1.0202e-04
Loss = 7.7222e-04, PNorm = 36.6374, GNorm = 4.2636, lr_0 = 1.0202e-04
Loss = 6.2168e-04, PNorm = 36.6389, GNorm = 4.8086, lr_0 = 1.0202e-04
Loss = 5.4988e-04, PNorm = 36.6396, GNorm = 1.4036, lr_0 = 1.0202e-04
Loss = 6.6946e-04, PNorm = 36.6416, GNorm = 1.6072, lr_0 = 1.0202e-04
Loss = 7.5233e-04, PNorm = 36.6433, GNorm = 2.7978, lr_0 = 1.0202e-04
Validation rmse logP = 0.484281
Validation R2 logP = 0.931289
Epoch 63
Train function
Loss = 7.2855e-04, PNorm = 36.6454, GNorm = 5.6623, lr_0 = 1.0202e-04
Loss = 5.1161e-04, PNorm = 36.6472, GNorm = 1.6058, lr_0 = 1.0202e-04
Loss = 7.0904e-04, PNorm = 36.6487, GNorm = 1.0812, lr_0 = 1.0202e-04
Loss = 4.9029e-04, PNorm = 36.6497, GNorm = 2.2495, lr_0 = 1.0202e-04
Loss = 7.6971e-04, PNorm = 36.6505, GNorm = 1.9132, lr_0 = 1.0202e-04
Loss = 8.0870e-04, PNorm = 36.6524, GNorm = 3.8922, lr_0 = 1.0202e-04
Loss = 7.1451e-04, PNorm = 36.6546, GNorm = 4.6308, lr_0 = 1.0202e-04
Loss = 6.6525e-04, PNorm = 36.6569, GNorm = 1.2119, lr_0 = 1.0202e-04
Loss = 5.9513e-04, PNorm = 36.6577, GNorm = 1.4208, lr_0 = 1.0202e-04
Loss = 4.7843e-04, PNorm = 36.6590, GNorm = 1.3161, lr_0 = 1.0202e-04
Loss = 7.2025e-04, PNorm = 36.6599, GNorm = 2.8830, lr_0 = 1.0202e-04
Loss = 6.9503e-04, PNorm = 36.6615, GNorm = 3.9762, lr_0 = 1.0202e-04
Loss = 7.4035e-04, PNorm = 36.6634, GNorm = 3.9151, lr_0 = 1.0202e-04
Loss = 6.0627e-04, PNorm = 36.6655, GNorm = 2.2147, lr_0 = 1.0202e-04
Loss = 9.5202e-04, PNorm = 36.6673, GNorm = 2.4328, lr_0 = 1.0202e-04
Loss = 6.2884e-04, PNorm = 36.6693, GNorm = 1.8863, lr_0 = 1.0202e-04
Loss = 6.3096e-04, PNorm = 36.6708, GNorm = 1.0371, lr_0 = 1.0202e-04
Loss = 6.7716e-04, PNorm = 36.6728, GNorm = 4.3504, lr_0 = 1.0202e-04
Loss = 6.4731e-04, PNorm = 36.6735, GNorm = 1.5133, lr_0 = 1.0202e-04
Loss = 8.1228e-04, PNorm = 36.6746, GNorm = 2.9227, lr_0 = 1.0202e-04
Loss = 7.0844e-04, PNorm = 36.6751, GNorm = 1.5114, lr_0 = 1.0202e-04
Loss = 6.9426e-04, PNorm = 36.6752, GNorm = 5.1724, lr_0 = 1.0202e-04
Validation rmse logP = 0.471223
Validation R2 logP = 0.934944
Epoch 64
Train function
Loss = 6.7782e-04, PNorm = 36.6766, GNorm = 2.1282, lr_0 = 1.0202e-04
Loss = 5.6200e-04, PNorm = 36.6781, GNorm = 2.4929, lr_0 = 1.0202e-04
Loss = 6.0100e-04, PNorm = 36.6793, GNorm = 1.9775, lr_0 = 1.0202e-04
Loss = 6.1950e-04, PNorm = 36.6809, GNorm = 1.8189, lr_0 = 1.0202e-04
Loss = 7.1247e-04, PNorm = 36.6828, GNorm = 6.5251, lr_0 = 1.0202e-04
Loss = 6.6392e-04, PNorm = 36.6845, GNorm = 5.0954, lr_0 = 1.0202e-04
Loss = 7.5105e-04, PNorm = 36.6860, GNorm = 6.8785, lr_0 = 1.0202e-04
Loss = 7.1036e-04, PNorm = 36.6882, GNorm = 2.9344, lr_0 = 1.0202e-04
Loss = 6.9944e-04, PNorm = 36.6903, GNorm = 6.0402, lr_0 = 1.0202e-04
Loss = 7.4853e-04, PNorm = 36.6917, GNorm = 3.5685, lr_0 = 1.0202e-04
Loss = 7.2145e-04, PNorm = 36.6935, GNorm = 4.1480, lr_0 = 1.0202e-04
Loss = 8.1148e-04, PNorm = 36.6950, GNorm = 4.9461, lr_0 = 1.0202e-04
Loss = 6.6460e-04, PNorm = 36.6972, GNorm = 1.8406, lr_0 = 1.0202e-04
Loss = 7.5225e-04, PNorm = 36.6995, GNorm = 0.8916, lr_0 = 1.0202e-04
Loss = 7.4023e-04, PNorm = 36.7015, GNorm = 2.3315, lr_0 = 1.0202e-04
Loss = 7.1545e-04, PNorm = 36.7028, GNorm = 2.8999, lr_0 = 1.0202e-04
Loss = 6.7827e-04, PNorm = 36.7040, GNorm = 1.4790, lr_0 = 1.0202e-04
Loss = 5.8213e-04, PNorm = 36.7053, GNorm = 1.6292, lr_0 = 1.0202e-04
Loss = 6.2534e-04, PNorm = 36.7058, GNorm = 1.9692, lr_0 = 1.0202e-04
Loss = 6.9454e-04, PNorm = 36.7067, GNorm = 6.1986, lr_0 = 1.0202e-04
Loss = 1.0793e-03, PNorm = 36.7080, GNorm = 3.8438, lr_0 = 1.0202e-04
Loss = 7.5344e-04, PNorm = 36.7097, GNorm = 1.6592, lr_0 = 1.0202e-04
Loss = 6.6306e-04, PNorm = 36.7120, GNorm = 2.4968, lr_0 = 1.0202e-04
Validation rmse logP = 0.490890
Validation R2 logP = 0.929401
Epoch 65
Train function
Loss = 6.0759e-04, PNorm = 36.7128, GNorm = 2.0067, lr_0 = 1.0202e-04
Loss = 6.9104e-04, PNorm = 36.7151, GNorm = 3.5362, lr_0 = 1.0202e-04
Loss = 6.8247e-04, PNorm = 36.7160, GNorm = 4.8819, lr_0 = 1.0202e-04
Loss = 8.0144e-04, PNorm = 36.7173, GNorm = 3.9225, lr_0 = 1.0202e-04
Loss = 7.3990e-04, PNorm = 36.7191, GNorm = 2.6729, lr_0 = 1.0202e-04
Loss = 6.5447e-04, PNorm = 36.7208, GNorm = 5.5504, lr_0 = 1.0202e-04
Loss = 6.5469e-04, PNorm = 36.7224, GNorm = 1.1218, lr_0 = 1.0202e-04
Loss = 6.7212e-04, PNorm = 36.7239, GNorm = 3.9913, lr_0 = 1.0202e-04
Loss = 7.2060e-04, PNorm = 36.7255, GNorm = 10.2700, lr_0 = 1.0202e-04
Loss = 5.8941e-04, PNorm = 36.7271, GNorm = 3.5545, lr_0 = 1.0202e-04
Loss = 6.9252e-04, PNorm = 36.7289, GNorm = 3.5333, lr_0 = 1.0202e-04
Loss = 5.0415e-04, PNorm = 36.7299, GNorm = 1.6322, lr_0 = 1.0202e-04
Loss = 6.5650e-04, PNorm = 36.7312, GNorm = 2.6763, lr_0 = 1.0202e-04
Loss = 5.7376e-04, PNorm = 36.7320, GNorm = 2.4230, lr_0 = 1.0202e-04
Loss = 6.2142e-04, PNorm = 36.7336, GNorm = 3.3775, lr_0 = 1.0202e-04
Loss = 7.2507e-04, PNorm = 36.7354, GNorm = 2.9965, lr_0 = 1.0202e-04
Loss = 6.4672e-04, PNorm = 36.7365, GNorm = 3.3312, lr_0 = 1.0202e-04
Loss = 7.9140e-04, PNorm = 36.7387, GNorm = 2.2795, lr_0 = 1.0202e-04
Loss = 7.0555e-04, PNorm = 36.7410, GNorm = 6.7741, lr_0 = 1.0202e-04
Loss = 7.7345e-04, PNorm = 36.7431, GNorm = 2.5280, lr_0 = 1.0202e-04
Loss = 6.6962e-04, PNorm = 36.7442, GNorm = 6.7180, lr_0 = 1.0202e-04
Loss = 8.0015e-04, PNorm = 36.7448, GNorm = 5.1663, lr_0 = 1.0202e-04
Validation rmse logP = 0.481672
Validation R2 logP = 0.932027
Epoch 66
Train function
Loss = 7.8841e-04, PNorm = 36.7465, GNorm = 1.8800, lr_0 = 1.0202e-04
Loss = 6.7577e-04, PNorm = 36.7474, GNorm = 6.5016, lr_0 = 1.0202e-04
Loss = 1.0253e-03, PNorm = 36.7489, GNorm = 8.4795, lr_0 = 1.0202e-04
Loss = 7.7117e-04, PNorm = 36.7500, GNorm = 2.1013, lr_0 = 1.0202e-04
Loss = 5.3665e-04, PNorm = 36.7521, GNorm = 4.5798, lr_0 = 1.0202e-04
Loss = 5.1003e-04, PNorm = 36.7529, GNorm = 1.6982, lr_0 = 1.0202e-04
Loss = 7.3958e-04, PNorm = 36.7548, GNorm = 4.3465, lr_0 = 1.0202e-04
Loss = 7.1370e-04, PNorm = 36.7574, GNorm = 3.6939, lr_0 = 1.0202e-04
Loss = 7.1907e-04, PNorm = 36.7591, GNorm = 2.2458, lr_0 = 1.0202e-04
Loss = 7.1341e-04, PNorm = 36.7611, GNorm = 2.3482, lr_0 = 1.0202e-04
Loss = 6.2210e-04, PNorm = 36.7625, GNorm = 2.6726, lr_0 = 1.0202e-04
Loss = 5.0274e-04, PNorm = 36.7647, GNorm = 2.5992, lr_0 = 1.0202e-04
Loss = 6.2060e-04, PNorm = 36.7659, GNorm = 2.9733, lr_0 = 1.0202e-04
Loss = 5.3921e-04, PNorm = 36.7671, GNorm = 3.1804, lr_0 = 1.0202e-04
Loss = 6.6484e-04, PNorm = 36.7688, GNorm = 1.1991, lr_0 = 1.0202e-04
Loss = 8.2630e-04, PNorm = 36.7698, GNorm = 8.4658, lr_0 = 1.0202e-04
Loss = 6.9871e-04, PNorm = 36.7710, GNorm = 3.0056, lr_0 = 1.0202e-04
Loss = 6.5889e-04, PNorm = 36.7722, GNorm = 3.0187, lr_0 = 1.0202e-04
Loss = 6.7161e-04, PNorm = 36.7745, GNorm = 1.9414, lr_0 = 1.0202e-04
Loss = 6.9448e-04, PNorm = 36.7765, GNorm = 3.3553, lr_0 = 1.0202e-04
Loss = 8.3099e-04, PNorm = 36.7779, GNorm = 2.2759, lr_0 = 1.0202e-04
Loss = 5.7234e-04, PNorm = 36.7797, GNorm = 2.8152, lr_0 = 1.0202e-04
Validation rmse logP = 0.476265
Validation R2 logP = 0.933545
Epoch 67
Train function
Loss = 6.8297e-04, PNorm = 36.7813, GNorm = 2.0576, lr_0 = 1.0202e-04
Loss = 6.1170e-04, PNorm = 36.7826, GNorm = 5.3438, lr_0 = 1.0202e-04
Loss = 6.4121e-04, PNorm = 36.7839, GNorm = 7.0772, lr_0 = 1.0202e-04
Loss = 6.4296e-04, PNorm = 36.7856, GNorm = 5.0074, lr_0 = 1.0202e-04
Loss = 5.4858e-04, PNorm = 36.7877, GNorm = 1.1959, lr_0 = 1.0202e-04
Loss = 5.6274e-04, PNorm = 36.7900, GNorm = 1.7198, lr_0 = 1.0202e-04
Loss = 6.0696e-04, PNorm = 36.7918, GNorm = 1.4917, lr_0 = 1.0202e-04
Loss = 6.5844e-04, PNorm = 36.7936, GNorm = 3.2795, lr_0 = 1.0202e-04
Loss = 5.8980e-04, PNorm = 36.7950, GNorm = 2.0747, lr_0 = 1.0202e-04
Loss = 5.8285e-04, PNorm = 36.7964, GNorm = 4.3334, lr_0 = 1.0202e-04
Loss = 6.7250e-04, PNorm = 36.7980, GNorm = 4.6538, lr_0 = 1.0202e-04
Loss = 7.7348e-04, PNorm = 36.7998, GNorm = 6.2465, lr_0 = 1.0202e-04
Loss = 6.3872e-04, PNorm = 36.8031, GNorm = 1.5128, lr_0 = 1.0202e-04
Loss = 6.2535e-04, PNorm = 36.8051, GNorm = 1.0015, lr_0 = 1.0202e-04
Loss = 7.5815e-04, PNorm = 36.8067, GNorm = 4.1969, lr_0 = 1.0202e-04
Loss = 8.7930e-04, PNorm = 36.8084, GNorm = 2.1876, lr_0 = 1.0202e-04
Loss = 6.5936e-04, PNorm = 36.8092, GNorm = 1.8317, lr_0 = 1.0202e-04
Loss = 6.3369e-04, PNorm = 36.8101, GNorm = 2.6481, lr_0 = 1.0202e-04
Loss = 6.5336e-04, PNorm = 36.8113, GNorm = 4.0576, lr_0 = 1.0202e-04
Loss = 5.7729e-04, PNorm = 36.8122, GNorm = 2.5302, lr_0 = 1.0202e-04
Loss = 6.4518e-04, PNorm = 36.8135, GNorm = 2.7562, lr_0 = 1.0202e-04
Loss = 7.7734e-04, PNorm = 36.8137, GNorm = 3.5550, lr_0 = 1.0202e-04
Loss = 8.3229e-04, PNorm = 36.8144, GNorm = 4.0617, lr_0 = 1.0202e-04
Loss = 1.1546e-03, PNorm = 36.8146, GNorm = 7.7178, lr_0 = 1.0202e-04
Validation rmse logP = 0.461443
Validation R2 logP = 0.937617
Epoch 68
Train function
Loss = 6.0546e-04, PNorm = 36.8165, GNorm = 6.8823, lr_0 = 1.0202e-04
Loss = 6.1729e-04, PNorm = 36.8189, GNorm = 1.7713, lr_0 = 1.0202e-04
Loss = 5.3608e-04, PNorm = 36.8209, GNorm = 3.0291, lr_0 = 1.0202e-04
Loss = 8.0465e-04, PNorm = 36.8229, GNorm = 7.5116, lr_0 = 1.0202e-04
Loss = 6.2582e-04, PNorm = 36.8255, GNorm = 1.2087, lr_0 = 1.0202e-04
Loss = 8.7314e-04, PNorm = 36.8268, GNorm = 1.7080, lr_0 = 1.0202e-04
Loss = 7.6334e-04, PNorm = 36.8296, GNorm = 1.9252, lr_0 = 1.0202e-04
Loss = 7.2917e-04, PNorm = 36.8309, GNorm = 2.9333, lr_0 = 1.0202e-04
Loss = 6.3695e-04, PNorm = 36.8328, GNorm = 3.8921, lr_0 = 1.0202e-04
Loss = 6.6152e-04, PNorm = 36.8337, GNorm = 1.5739, lr_0 = 1.0202e-04
Loss = 6.7701e-04, PNorm = 36.8356, GNorm = 1.2501, lr_0 = 1.0202e-04
Loss = 5.0744e-04, PNorm = 36.8372, GNorm = 5.4307, lr_0 = 1.0202e-04
Loss = 7.3831e-04, PNorm = 36.8390, GNorm = 3.3757, lr_0 = 1.0202e-04
Loss = 6.5199e-04, PNorm = 36.8414, GNorm = 3.0667, lr_0 = 1.0202e-04
Loss = 6.9796e-04, PNorm = 36.8425, GNorm = 3.4048, lr_0 = 1.0202e-04
Loss = 6.7799e-04, PNorm = 36.8430, GNorm = 2.0858, lr_0 = 1.0202e-04
Loss = 7.6684e-04, PNorm = 36.8442, GNorm = 6.3594, lr_0 = 1.0202e-04
Fold 0
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_0',
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 0
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 2.0014e-02, PNorm = 35.0897, GNorm = 4.6046, lr_0 = 1.0200e-04
Loss = 2.0192e-02, PNorm = 35.0910, GNorm = 4.9352, lr_0 = 1.0200e-04
Loss = 1.5744e-02, PNorm = 35.0931, GNorm = 6.5925, lr_0 = 1.0200e-04
Loss = 1.4838e-02, PNorm = 35.0950, GNorm = 3.1034, lr_0 = 1.0200e-04
Loss = 1.4904e-02, PNorm = 35.0974, GNorm = 3.3247, lr_0 = 1.0200e-04
Loss = 1.3450e-02, PNorm = 35.0994, GNorm = 3.7768, lr_0 = 1.0200e-04
Loss = 1.1290e-02, PNorm = 35.1020, GNorm = 1.9791, lr_0 = 1.0200e-04
Loss = 1.2396e-02, PNorm = 35.1048, GNorm = 6.4800, lr_0 = 1.0200e-04
Loss = 1.0730e-02, PNorm = 35.1075, GNorm = 3.2993, lr_0 = 1.0200e-04
Loss = 9.1554e-03, PNorm = 35.1106, GNorm = 2.6752, lr_0 = 1.0200e-04
Loss = 9.8614e-03, PNorm = 35.1136, GNorm = 2.9880, lr_0 = 1.0200e-04
Loss = 1.0199e-02, PNorm = 35.1167, GNorm = 1.6778, lr_0 = 1.0200e-04
Loss = 1.0030e-02, PNorm = 35.1201, GNorm = 4.0028, lr_0 = 1.0200e-04
Loss = 8.5461e-03, PNorm = 35.1237, GNorm = 4.5680, lr_0 = 1.0200e-04
Loss = 9.0782e-03, PNorm = 35.1263, GNorm = 3.8185, lr_0 = 1.0200e-04
Loss = 8.3317e-03, PNorm = 35.1295, GNorm = 4.7412, lr_0 = 1.0200e-04
Loss = 9.3066e-03, PNorm = 35.1329, GNorm = 6.0971, lr_0 = 1.0200e-04
Loss = 8.8599e-03, PNorm = 35.1360, GNorm = 2.9131, lr_0 = 1.0200e-04
Loss = 6.3876e-03, PNorm = 35.1388, GNorm = 2.1273, lr_0 = 1.0200e-04
Loss = 8.2420e-03, PNorm = 35.1413, GNorm = 9.6568, lr_0 = 1.0200e-04
Loss = 7.6535e-03, PNorm = 35.1440, GNorm = 4.8383, lr_0 = 1.0200e-04
Loss = 7.6028e-03, PNorm = 35.1468, GNorm = 5.5119, lr_0 = 1.0200e-04
Validation rmse logD = 1.022935
Validation R2 logD = 0.268173
Validation rmse logP = 0.950799
Validation R2 logP = 0.751142
Epoch 1
Train function
Loss = 6.3958e-03, PNorm = 35.1497, GNorm = 4.2903, lr_0 = 1.0200e-04
Loss = 7.1350e-03, PNorm = 35.1523, GNorm = 6.0003, lr_0 = 1.0200e-04
Loss = 7.2882e-03, PNorm = 35.1551, GNorm = 2.5513, lr_0 = 1.0200e-04
Loss = 6.9187e-03, PNorm = 35.1581, GNorm = 11.8870, lr_0 = 1.0200e-04
Loss = 6.9322e-03, PNorm = 35.1609, GNorm = 4.7056, lr_0 = 1.0200e-04
Loss = 6.9224e-03, PNorm = 35.1640, GNorm = 7.5817, lr_0 = 1.0200e-04
Loss = 6.0946e-03, PNorm = 35.1672, GNorm = 3.9451, lr_0 = 1.0200e-04
Loss = 6.1560e-03, PNorm = 35.1692, GNorm = 4.8848, lr_0 = 1.0200e-04
Loss = 6.1979e-03, PNorm = 35.1721, GNorm = 3.5289, lr_0 = 1.0200e-04
Loss = 7.2391e-03, PNorm = 35.1756, GNorm = 7.3026, lr_0 = 1.0200e-04
Loss = 5.9317e-03, PNorm = 35.1787, GNorm = 4.3998, lr_0 = 1.0200e-04
Loss = 6.5033e-03, PNorm = 35.1820, GNorm = 8.4817, lr_0 = 1.0200e-04
Loss = 6.5866e-03, PNorm = 35.1852, GNorm = 2.7905, lr_0 = 1.0200e-04
Loss = 6.0084e-03, PNorm = 35.1872, GNorm = 2.9428, lr_0 = 1.0200e-04
Loss = 6.4059e-03, PNorm = 35.1903, GNorm = 3.5162, lr_0 = 1.0200e-04
Loss = 6.3549e-03, PNorm = 35.1922, GNorm = 4.9724, lr_0 = 1.0200e-04
Loss = 5.4810e-03, PNorm = 35.1955, GNorm = 3.9836, lr_0 = 1.0200e-04
Loss = 6.4435e-03, PNorm = 35.1994, GNorm = 2.9133, lr_0 = 1.0200e-04
Loss = 6.2604e-03, PNorm = 35.2023, GNorm = 3.0731, lr_0 = 1.0200e-04
Loss = 6.3377e-03, PNorm = 35.2051, GNorm = 6.0920, lr_0 = 1.0200e-04
Loss = 5.3819e-03, PNorm = 35.2081, GNorm = 13.2500, lr_0 = 1.0200e-04
Loss = 6.2283e-03, PNorm = 35.2110, GNorm = 7.4759, lr_0 = 1.0200e-04
Loss = 6.5047e-03, PNorm = 35.2138, GNorm = 5.2596, lr_0 = 1.0200e-04
Loss = 5.9050e-03, PNorm = 35.2140, GNorm = 5.6758, lr_0 = 1.0200e-04
Validation rmse logD = 0.930268
Validation R2 logD = 0.394759
Validation rmse logP = 0.806411
Validation R2 logP = 0.820986
Epoch 2
Train function
Loss = 5.6340e-03, PNorm = 35.2160, GNorm = 3.3778, lr_0 = 1.0200e-04
Loss = 7.1067e-03, PNorm = 35.2190, GNorm = 5.7077, lr_0 = 1.0200e-04
Loss = 4.8957e-03, PNorm = 35.2227, GNorm = 2.2758, lr_0 = 1.0200e-04
Loss = 4.8324e-03, PNorm = 35.2256, GNorm = 3.4852, lr_0 = 1.0200e-04
Loss = 5.2862e-03, PNorm = 35.2278, GNorm = 3.4777, lr_0 = 1.0200e-04
Loss = 5.3699e-03, PNorm = 35.2314, GNorm = 8.6449, lr_0 = 1.0200e-04
Loss = 6.1383e-03, PNorm = 35.2342, GNorm = 2.9955, lr_0 = 1.0200e-04
Loss = 4.8110e-03, PNorm = 35.2367, GNorm = 2.5958, lr_0 = 1.0200e-04
Loss = 5.8070e-03, PNorm = 35.2397, GNorm = 4.0689, lr_0 = 1.0200e-04
Loss = 6.1993e-03, PNorm = 35.2434, GNorm = 7.3248, lr_0 = 1.0200e-04
Loss = 5.5820e-03, PNorm = 35.2475, GNorm = 1.8919, lr_0 = 1.0200e-04
Loss = 4.6828e-03, PNorm = 35.2509, GNorm = 3.5652, lr_0 = 1.0200e-04
Loss = 5.4361e-03, PNorm = 35.2538, GNorm = 5.2353, lr_0 = 1.0200e-04
Loss = 4.8895e-03, PNorm = 35.2565, GNorm = 8.5548, lr_0 = 1.0200e-04
Loss = 5.8811e-03, PNorm = 35.2591, GNorm = 2.9472, lr_0 = 1.0200e-04
Loss = 6.5387e-03, PNorm = 35.2615, GNorm = 5.0856, lr_0 = 1.0200e-04
Loss = 5.6214e-03, PNorm = 35.2636, GNorm = 5.4565, lr_0 = 1.0200e-04
Loss = 5.0161e-03, PNorm = 35.2657, GNorm = 6.7295, lr_0 = 1.0200e-04
Loss = 5.1043e-03, PNorm = 35.2688, GNorm = 3.1344, lr_0 = 1.0200e-04
Loss = 4.8252e-03, PNorm = 35.2719, GNorm = 4.2456, lr_0 = 1.0200e-04
Loss = 4.9326e-03, PNorm = 35.2742, GNorm = 2.7070, lr_0 = 1.0200e-04
Loss = 4.0538e-03, PNorm = 35.2766, GNorm = 3.4439, lr_0 = 1.0200e-04
Validation rmse logD = 0.888018
Validation R2 logD = 0.448487
Validation rmse logP = 0.786688
Validation R2 logP = 0.829635
Epoch 3
Train function
Loss = 4.1670e-03, PNorm = 35.2792, GNorm = 2.2166, lr_0 = 1.0200e-04
Loss = 4.4068e-03, PNorm = 35.2815, GNorm = 1.2327, lr_0 = 1.0200e-04
Loss = 4.7203e-03, PNorm = 35.2849, GNorm = 5.6100, lr_0 = 1.0200e-04
Loss = 5.3264e-03, PNorm = 35.2876, GNorm = 4.0823, lr_0 = 1.0200e-04
Loss = 4.3859e-03, PNorm = 35.2906, GNorm = 3.8412, lr_0 = 1.0200e-04
Loss = 5.4639e-03, PNorm = 35.2944, GNorm = 3.5140, lr_0 = 1.0200e-04
Loss = 5.0126e-03, PNorm = 35.2974, GNorm = 5.9312, lr_0 = 1.0200e-04
Loss = 4.3530e-03, PNorm = 35.2998, GNorm = 3.7418, lr_0 = 1.0200e-04
Loss = 5.2148e-03, PNorm = 35.3026, GNorm = 4.5676, lr_0 = 1.0200e-04
Loss = 4.7918e-03, PNorm = 35.3052, GNorm = 2.2273, lr_0 = 1.0200e-04
Loss = 4.2303e-03, PNorm = 35.3086, GNorm = 5.5951, lr_0 = 1.0200e-04
Loss = 4.1164e-03, PNorm = 35.3110, GNorm = 9.9744, lr_0 = 1.0200e-04
Loss = 5.2609e-03, PNorm = 35.3129, GNorm = 6.9452, lr_0 = 1.0200e-04
Loss = 4.9958e-03, PNorm = 35.3152, GNorm = 3.7250, lr_0 = 1.0200e-04
Loss = 4.5704e-03, PNorm = 35.3173, GNorm = 2.9811, lr_0 = 1.0200e-04
Loss = 5.1359e-03, PNorm = 35.3199, GNorm = 3.3775, lr_0 = 1.0200e-04
Loss = 4.8220e-03, PNorm = 35.3227, GNorm = 1.5081, lr_0 = 1.0200e-04
Loss = 4.2191e-03, PNorm = 35.3260, GNorm = 3.6518, lr_0 = 1.0200e-04
Loss = 3.8939e-03, PNorm = 35.3286, GNorm = 1.9595, lr_0 = 1.0200e-04
Loss = 4.2482e-03, PNorm = 35.3313, GNorm = 1.1945, lr_0 = 1.0200e-04
Loss = 3.5780e-03, PNorm = 35.3336, GNorm = 1.4265, lr_0 = 1.0200e-04
Loss = 4.6494e-03, PNorm = 35.3367, GNorm = 1.4036, lr_0 = 1.0200e-04
Loss = 5.0195e-03, PNorm = 35.3395, GNorm = 5.2287, lr_0 = 1.0200e-04
Validation rmse logD = 0.846428
Validation R2 logD = 0.498937
Validation rmse logP = 0.718906
Validation R2 logP = 0.857729
Epoch 4
Train function
Loss = 3.8369e-03, PNorm = 35.3434, GNorm = 7.2170, lr_0 = 1.0200e-04
Loss = 4.4686e-03, PNorm = 35.3468, GNorm = 4.6766, lr_0 = 1.0200e-04
Loss = 3.9741e-03, PNorm = 35.3493, GNorm = 3.7319, lr_0 = 1.0200e-04
Loss = 4.1029e-03, PNorm = 35.3527, GNorm = 2.4710, lr_0 = 1.0200e-04
Loss = 3.6129e-03, PNorm = 35.3554, GNorm = 5.9529, lr_0 = 1.0200e-04
Loss = 4.1773e-03, PNorm = 35.3572, GNorm = 2.8409, lr_0 = 1.0200e-04
Loss = 4.3833e-03, PNorm = 35.3595, GNorm = 3.8391, lr_0 = 1.0200e-04
Loss = 4.1013e-03, PNorm = 35.3624, GNorm = 5.7536, lr_0 = 1.0200e-04
Loss = 4.3027e-03, PNorm = 35.3655, GNorm = 5.9664, lr_0 = 1.0200e-04
Loss = 4.9283e-03, PNorm = 35.3684, GNorm = 1.8195, lr_0 = 1.0200e-04
Loss = 4.2775e-03, PNorm = 35.3715, GNorm = 4.0037, lr_0 = 1.0200e-04
Loss = 4.6377e-03, PNorm = 35.3746, GNorm = 6.8489, lr_0 = 1.0200e-04
Loss = 4.1932e-03, PNorm = 35.3778, GNorm = 2.1100, lr_0 = 1.0200e-04
Loss = 3.2232e-03, PNorm = 35.3804, GNorm = 1.7643, lr_0 = 1.0200e-04
Loss = 3.1058e-03, PNorm = 35.3826, GNorm = 1.9078, lr_0 = 1.0200e-04
Loss = 4.6800e-03, PNorm = 35.3849, GNorm = 3.9582, lr_0 = 1.0200e-04
Loss = 4.1348e-03, PNorm = 35.3875, GNorm = 8.1820, lr_0 = 1.0200e-04
Loss = 4.9502e-03, PNorm = 35.3903, GNorm = 2.4070, lr_0 = 1.0200e-04
Loss = 4.7646e-03, PNorm = 35.3931, GNorm = 2.9499, lr_0 = 1.0200e-04
Loss = 4.2045e-03, PNorm = 35.3963, GNorm = 2.3990, lr_0 = 1.0200e-04
Loss = 5.1804e-03, PNorm = 35.3990, GNorm = 2.6325, lr_0 = 1.0200e-04
Loss = 4.0739e-03, PNorm = 35.4015, GNorm = 3.9726, lr_0 = 1.0200e-04
Validation rmse logD = 0.838110
Validation R2 logD = 0.508736
Validation rmse logP = 0.761238
Validation R2 logP = 0.840480
Epoch 5
Train function
Loss = 5.0996e-03, PNorm = 35.4034, GNorm = 2.8913, lr_0 = 1.0200e-04
Loss = 3.7967e-03, PNorm = 35.4070, GNorm = 5.7911, lr_0 = 1.0200e-04
Loss = 4.3444e-03, PNorm = 35.4099, GNorm = 3.1355, lr_0 = 1.0200e-04
Loss = 4.5168e-03, PNorm = 35.4124, GNorm = 7.1430, lr_0 = 1.0200e-04
Loss = 4.4378e-03, PNorm = 35.4155, GNorm = 2.5603, lr_0 = 1.0200e-04
Loss = 4.4965e-03, PNorm = 35.4182, GNorm = 9.3303, lr_0 = 1.0200e-04
Loss = 3.5164e-03, PNorm = 35.4211, GNorm = 2.8825, lr_0 = 1.0200e-04
Loss = 3.5983e-03, PNorm = 35.4236, GNorm = 1.8299, lr_0 = 1.0200e-04
Loss = 3.8363e-03, PNorm = 35.4267, GNorm = 2.0429, lr_0 = 1.0200e-04
Loss = 3.9865e-03, PNorm = 35.4296, GNorm = 2.2006, lr_0 = 1.0200e-04
Loss = 4.2233e-03, PNorm = 35.4325, GNorm = 5.0268, lr_0 = 1.0200e-04
Loss = 4.7468e-03, PNorm = 35.4336, GNorm = 3.0695, lr_0 = 1.0200e-04
Loss = 4.6285e-03, PNorm = 35.4364, GNorm = 3.4881, lr_0 = 1.0200e-04
Loss = 3.5837e-03, PNorm = 35.4399, GNorm = 2.7209, lr_0 = 1.0200e-04
Loss = 3.8676e-03, PNorm = 35.4432, GNorm = 2.8599, lr_0 = 1.0200e-04
Loss = 4.3004e-03, PNorm = 35.4458, GNorm = 4.5694, lr_0 = 1.0200e-04
Loss = 3.9679e-03, PNorm = 35.4478, GNorm = 4.4155, lr_0 = 1.0200e-04
Loss = 3.5525e-03, PNorm = 35.4508, GNorm = 4.0374, lr_0 = 1.0200e-04
Loss = 3.5723e-03, PNorm = 35.4533, GNorm = 2.9605, lr_0 = 1.0200e-04
Loss = 3.1489e-03, PNorm = 35.4550, GNorm = 2.9886, lr_0 = 1.0200e-04
Loss = 3.3884e-03, PNorm = 35.4574, GNorm = 3.2729, lr_0 = 1.0200e-04
Loss = 3.5006e-03, PNorm = 35.4606, GNorm = 2.7689, lr_0 = 1.0200e-04
Loss = 3.7447e-03, PNorm = 35.4633, GNorm = 2.2059, lr_0 = 1.0200e-04
Validation rmse logD = 0.865238
Validation R2 logD = 0.476420
Validation rmse logP = 0.651221
Validation R2 logP = 0.883257
Epoch 6
Train function
Loss = 3.7635e-03, PNorm = 35.4666, GNorm = 2.1140, lr_0 = 1.0200e-04
Loss = 3.5420e-03, PNorm = 35.4682, GNorm = 4.1656, lr_0 = 1.0200e-04
Loss = 3.6690e-03, PNorm = 35.4705, GNorm = 3.0357, lr_0 = 1.0200e-04
Loss = 3.4012e-03, PNorm = 35.4730, GNorm = 8.4442, lr_0 = 1.0200e-04
Loss = 4.0987e-03, PNorm = 35.4761, GNorm = 5.8096, lr_0 = 1.0200e-04
Loss = 4.6716e-03, PNorm = 35.4790, GNorm = 4.0464, lr_0 = 1.0200e-04
Loss = 3.7253e-03, PNorm = 35.4803, GNorm = 2.0437, lr_0 = 1.0200e-04
Loss = 4.0113e-03, PNorm = 35.4828, GNorm = 2.5783, lr_0 = 1.0200e-04
Loss = 3.8785e-03, PNorm = 35.4867, GNorm = 6.6852, lr_0 = 1.0200e-04
Loss = 3.7784e-03, PNorm = 35.4897, GNorm = 3.9560, lr_0 = 1.0200e-04
Loss = 2.9577e-03, PNorm = 35.4931, GNorm = 5.1541, lr_0 = 1.0200e-04
Loss = 3.3087e-03, PNorm = 35.4955, GNorm = 4.1931, lr_0 = 1.0200e-04
Loss = 4.6751e-03, PNorm = 35.4983, GNorm = 2.4219, lr_0 = 1.0200e-04
Loss = 3.1407e-03, PNorm = 35.5004, GNorm = 7.7717, lr_0 = 1.0200e-04
Loss = 4.0666e-03, PNorm = 35.5037, GNorm = 3.4487, lr_0 = 1.0200e-04
Loss = 3.3083e-03, PNorm = 35.5067, GNorm = 3.6569, lr_0 = 1.0200e-04
Loss = 3.7191e-03, PNorm = 35.5091, GNorm = 3.9537, lr_0 = 1.0200e-04
Loss = 3.7753e-03, PNorm = 35.5121, GNorm = 1.9640, lr_0 = 1.0200e-04
Loss = 3.7863e-03, PNorm = 35.5149, GNorm = 3.0580, lr_0 = 1.0200e-04
Loss = 3.3493e-03, PNorm = 35.5174, GNorm = 1.0797, lr_0 = 1.0200e-04
Loss = 3.4322e-03, PNorm = 35.5197, GNorm = 2.0588, lr_0 = 1.0200e-04
Loss = 3.3796e-03, PNorm = 35.5216, GNorm = 2.3878, lr_0 = 1.0200e-04
Validation rmse logD = 0.823230
Validation R2 logD = 0.526026
Validation rmse logP = 0.655141
Validation R2 logP = 0.881847
Epoch 7
Train function
Loss = 5.0763e-03, PNorm = 35.5251, GNorm = 2.7697, lr_0 = 1.0200e-04
Loss = 3.3191e-03, PNorm = 35.5278, GNorm = 4.7395, lr_0 = 1.0200e-04
Loss = 3.3440e-03, PNorm = 35.5316, GNorm = 2.0335, lr_0 = 1.0200e-04
Loss = 3.0109e-03, PNorm = 35.5345, GNorm = 2.5331, lr_0 = 1.0200e-04
Loss = 3.9096e-03, PNorm = 35.5376, GNorm = 9.3520, lr_0 = 1.0200e-04
Loss = 3.5587e-03, PNorm = 35.5396, GNorm = 7.8005, lr_0 = 1.0200e-04
Loss = 3.2637e-03, PNorm = 35.5422, GNorm = 7.2443, lr_0 = 1.0200e-04
Loss = 3.7028e-03, PNorm = 35.5457, GNorm = 1.7565, lr_0 = 1.0200e-04
Loss = 3.1640e-03, PNorm = 35.5489, GNorm = 4.0070, lr_0 = 1.0200e-04
Loss = 2.9398e-03, PNorm = 35.5509, GNorm = 1.7763, lr_0 = 1.0200e-04
Loss = 3.2777e-03, PNorm = 35.5533, GNorm = 4.4693, lr_0 = 1.0200e-04
Loss = 3.6819e-03, PNorm = 35.5554, GNorm = 3.5267, lr_0 = 1.0200e-04
Loss = 2.8473e-03, PNorm = 35.5579, GNorm = 2.1540, lr_0 = 1.0200e-04
Loss = 3.3255e-03, PNorm = 35.5606, GNorm = 1.6478, lr_0 = 1.0200e-04
Loss = 3.9994e-03, PNorm = 35.5629, GNorm = 5.1974, lr_0 = 1.0200e-04
Loss = 3.7549e-03, PNorm = 35.5650, GNorm = 4.3583, lr_0 = 1.0200e-04
Loss = 3.5500e-03, PNorm = 35.5681, GNorm = 6.6545, lr_0 = 1.0200e-04
Loss = 3.8210e-03, PNorm = 35.5708, GNorm = 2.0400, lr_0 = 1.0200e-04
Loss = 3.3730e-03, PNorm = 35.5728, GNorm = 5.2058, lr_0 = 1.0200e-04
Loss = 3.2189e-03, PNorm = 35.5747, GNorm = 3.1890, lr_0 = 1.0200e-04
Loss = 3.5014e-03, PNorm = 35.5770, GNorm = 1.7337, lr_0 = 1.0200e-04
Loss = 3.6243e-03, PNorm = 35.5804, GNorm = 2.4754, lr_0 = 1.0200e-04
Loss = 3.8032e-03, PNorm = 35.5836, GNorm = 2.5859, lr_0 = 1.0200e-04
Validation rmse logD = 0.780555
Validation R2 logD = 0.573893
Validation rmse logP = 0.630216
Validation R2 logP = 0.890667
Epoch 8
Train function
Loss = 3.2289e-03, PNorm = 35.5873, GNorm = 3.0993, lr_0 = 1.0200e-04
Loss = 3.1066e-03, PNorm = 35.5900, GNorm = 2.3679, lr_0 = 1.0200e-04
Loss = 3.9316e-03, PNorm = 35.5918, GNorm = 3.4252, lr_0 = 1.0200e-04
Loss = 3.1334e-03, PNorm = 35.5942, GNorm = 3.9795, lr_0 = 1.0200e-04
Loss = 3.2015e-03, PNorm = 35.5973, GNorm = 4.0865, lr_0 = 1.0200e-04
Loss = 3.5458e-03, PNorm = 35.6010, GNorm = 4.1709, lr_0 = 1.0200e-04
Loss = 3.2324e-03, PNorm = 35.6045, GNorm = 3.6671, lr_0 = 1.0200e-04
Loss = 3.2363e-03, PNorm = 35.6071, GNorm = 2.0769, lr_0 = 1.0200e-04
Loss = 2.6333e-03, PNorm = 35.6093, GNorm = 3.6897, lr_0 = 1.0200e-04
Loss = 3.4026e-03, PNorm = 35.6115, GNorm = 3.3695, lr_0 = 1.0200e-04
Loss = 3.6227e-03, PNorm = 35.6141, GNorm = 5.2513, lr_0 = 1.0200e-04
Loss = 3.1364e-03, PNorm = 35.6160, GNorm = 2.6648, lr_0 = 1.0200e-04
Loss = 3.4040e-03, PNorm = 35.6188, GNorm = 3.4528, lr_0 = 1.0200e-04
Loss = 3.2844e-03, PNorm = 35.6218, GNorm = 4.7311, lr_0 = 1.0200e-04
Loss = 3.4621e-03, PNorm = 35.6238, GNorm = 3.5456, lr_0 = 1.0200e-04
Loss = 2.9675e-03, PNorm = 35.6258, GNorm = 5.9873, lr_0 = 1.0200e-04
Loss = 3.2759e-03, PNorm = 35.6283, GNorm = 2.8893, lr_0 = 1.0200e-04
Loss = 3.2477e-03, PNorm = 35.6318, GNorm = 1.3242, lr_0 = 1.0200e-04
Loss = 3.4066e-03, PNorm = 35.6347, GNorm = 2.5798, lr_0 = 1.0200e-04
Loss = 2.7476e-03, PNorm = 35.6362, GNorm = 3.9781, lr_0 = 1.0200e-04
Loss = 2.6736e-03, PNorm = 35.6384, GNorm = 1.5175, lr_0 = 1.0200e-04
Loss = 3.3612e-03, PNorm = 35.6409, GNorm = 1.9341, lr_0 = 1.0200e-04
Validation rmse logD = 0.770347
Validation R2 logD = 0.584964
Validation rmse logP = 0.613341
Validation R2 logP = 0.896443
Epoch 9
Train function
Loss = 1.6399e-03, PNorm = 35.6434, GNorm = 1.1688, lr_0 = 1.0200e-04
Loss = 3.0023e-03, PNorm = 35.6466, GNorm = 2.6329, lr_0 = 1.0200e-04
Loss = 3.0843e-03, PNorm = 35.6489, GNorm = 3.4086, lr_0 = 1.0200e-04
Loss = 2.5000e-03, PNorm = 35.6522, GNorm = 1.2754, lr_0 = 1.0200e-04
Loss = 2.6659e-03, PNorm = 35.6548, GNorm = 4.6339, lr_0 = 1.0200e-04
Loss = 3.2012e-03, PNorm = 35.6576, GNorm = 7.9101, lr_0 = 1.0200e-04
Loss = 2.9103e-03, PNorm = 35.6599, GNorm = 4.0767, lr_0 = 1.0200e-04
Loss = 2.8655e-03, PNorm = 35.6617, GNorm = 2.2044, lr_0 = 1.0200e-04
Loss = 3.0005e-03, PNorm = 35.6636, GNorm = 3.2357, lr_0 = 1.0200e-04
Loss = 3.7433e-03, PNorm = 35.6654, GNorm = 7.0302, lr_0 = 1.0200e-04
Loss = 3.1861e-03, PNorm = 35.6683, GNorm = 3.4236, lr_0 = 1.0200e-04
Loss = 3.5203e-03, PNorm = 35.6710, GNorm = 4.3459, lr_0 = 1.0200e-04
Loss = 2.5764e-03, PNorm = 35.6743, GNorm = 1.7954, lr_0 = 1.0200e-04
Loss = 3.0195e-03, PNorm = 35.6770, GNorm = 3.7781, lr_0 = 1.0200e-04
Loss = 3.8019e-03, PNorm = 35.6792, GNorm = 3.4430, lr_0 = 1.0200e-04
Loss = 3.3376e-03, PNorm = 35.6822, GNorm = 3.5931, lr_0 = 1.0200e-04
Loss = 3.6742e-03, PNorm = 35.6838, GNorm = 2.3923, lr_0 = 1.0200e-04
Loss = 2.8704e-03, PNorm = 35.6868, GNorm = 8.2294, lr_0 = 1.0200e-04
Loss = 3.0608e-03, PNorm = 35.6900, GNorm = 1.1686, lr_0 = 1.0200e-04
Loss = 2.8965e-03, PNorm = 35.6931, GNorm = 4.9347, lr_0 = 1.0200e-04
Loss = 3.0843e-03, PNorm = 35.6965, GNorm = 6.3326, lr_0 = 1.0200e-04
Loss = 3.4688e-03, PNorm = 35.6996, GNorm = 4.8478, lr_0 = 1.0200e-04
Loss = 3.3123e-03, PNorm = 35.7017, GNorm = 3.0054, lr_0 = 1.0200e-04
Validation rmse logD = 0.755123
Validation R2 logD = 0.601207
Validation rmse logP = 0.628109
Validation R2 logP = 0.891396
Epoch 10
Train function
Loss = 2.4721e-03, PNorm = 35.7042, GNorm = 2.7396, lr_0 = 1.0200e-04
Loss = 2.4044e-03, PNorm = 35.7065, GNorm = 3.1652, lr_0 = 1.0200e-04
Loss = 2.6217e-03, PNorm = 35.7093, GNorm = 1.2957, lr_0 = 1.0200e-04
Loss = 2.9087e-03, PNorm = 35.7121, GNorm = 6.8922, lr_0 = 1.0200e-04
Loss = 3.3437e-03, PNorm = 35.7149, GNorm = 4.1870, lr_0 = 1.0200e-04
Loss = 2.3179e-03, PNorm = 35.7171, GNorm = 1.9154, lr_0 = 1.0200e-04
Loss = 2.8540e-03, PNorm = 35.7198, GNorm = 1.4469, lr_0 = 1.0200e-04
Loss = 2.9813e-03, PNorm = 35.7217, GNorm = 3.0538, lr_0 = 1.0200e-04
Loss = 3.3538e-03, PNorm = 35.7251, GNorm = 2.5521, lr_0 = 1.0200e-04
Loss = 3.0022e-03, PNorm = 35.7280, GNorm = 2.7272, lr_0 = 1.0200e-04
Loss = 3.4494e-03, PNorm = 35.7308, GNorm = 2.8795, lr_0 = 1.0200e-04
Loss = 2.8034e-03, PNorm = 35.7332, GNorm = 8.2088, lr_0 = 1.0200e-04
Loss = 3.4717e-03, PNorm = 35.7360, GNorm = 5.9106, lr_0 = 1.0200e-04
Loss = 3.5287e-03, PNorm = 35.7388, GNorm = 8.9496, lr_0 = 1.0200e-04
Loss = 3.3025e-03, PNorm = 35.7409, GNorm = 5.0817, lr_0 = 1.0200e-04
Loss = 2.5811e-03, PNorm = 35.7437, GNorm = 5.1741, lr_0 = 1.0200e-04
Loss = 2.9749e-03, PNorm = 35.7459, GNorm = 3.8630, lr_0 = 1.0200e-04
Loss = 2.8678e-03, PNorm = 35.7487, GNorm = 4.3828, lr_0 = 1.0200e-04
Loss = 2.6041e-03, PNorm = 35.7508, GNorm = 3.6217, lr_0 = 1.0200e-04
Loss = 2.8907e-03, PNorm = 35.7533, GNorm = 1.4702, lr_0 = 1.0200e-04
Loss = 2.5728e-03, PNorm = 35.7552, GNorm = 1.6758, lr_0 = 1.0200e-04
Loss = 3.4352e-03, PNorm = 35.7571, GNorm = 2.3186, lr_0 = 1.0200e-04
Loss = 2.6619e-03, PNorm = 35.7595, GNorm = 1.7058, lr_0 = 1.0200e-04
Validation rmse logD = 0.841563
Validation R2 logD = 0.504681
Validation rmse logP = 0.614688
Validation R2 logP = 0.895988
Epoch 11
Train function
Loss = 2.9052e-03, PNorm = 35.7622, GNorm = 7.2807, lr_0 = 1.0200e-04
Loss = 2.5697e-03, PNorm = 35.7651, GNorm = 2.7037, lr_0 = 1.0200e-04
Loss = 3.1851e-03, PNorm = 35.7686, GNorm = 2.1380, lr_0 = 1.0200e-04
Loss = 2.7325e-03, PNorm = 35.7716, GNorm = 4.8108, lr_0 = 1.0200e-04
Loss = 2.6331e-03, PNorm = 35.7747, GNorm = 2.6634, lr_0 = 1.0200e-04
Loss = 2.9391e-03, PNorm = 35.7778, GNorm = 2.5944, lr_0 = 1.0200e-04
Loss = 2.9852e-03, PNorm = 35.7799, GNorm = 2.2326, lr_0 = 1.0200e-04
Loss = 2.7534e-03, PNorm = 35.7812, GNorm = 4.8557, lr_0 = 1.0200e-04
Loss = 2.7801e-03, PNorm = 35.7829, GNorm = 7.1386, lr_0 = 1.0200e-04
Loss = 2.5038e-03, PNorm = 35.7855, GNorm = 3.1451, lr_0 = 1.0200e-04
Loss = 2.4315e-03, PNorm = 35.7877, GNorm = 4.7972, lr_0 = 1.0200e-04
Loss = 2.7656e-03, PNorm = 35.7891, GNorm = 4.4436, lr_0 = 1.0200e-04
Loss = 3.1250e-03, PNorm = 35.7910, GNorm = 5.5465, lr_0 = 1.0200e-04
Loss = 3.4265e-03, PNorm = 35.7935, GNorm = 1.8805, lr_0 = 1.0200e-04
Loss = 2.5379e-03, PNorm = 35.7961, GNorm = 2.6893, lr_0 = 1.0200e-04
Loss = 2.8416e-03, PNorm = 35.7983, GNorm = 5.0180, lr_0 = 1.0200e-04
Loss = 2.6386e-03, PNorm = 35.8018, GNorm = 7.3049, lr_0 = 1.0200e-04
Loss = 2.9660e-03, PNorm = 35.8042, GNorm = 4.5383, lr_0 = 1.0200e-04
Loss = 3.6867e-03, PNorm = 35.8067, GNorm = 2.5359, lr_0 = 1.0200e-04
Loss = 2.7114e-03, PNorm = 35.8091, GNorm = 5.8322, lr_0 = 1.0200e-04
Loss = 3.0341e-03, PNorm = 35.8112, GNorm = 5.5062, lr_0 = 1.0200e-04
Loss = 3.0109e-03, PNorm = 35.8134, GNorm = 4.0934, lr_0 = 1.0200e-04
Validation rmse logD = 0.732970
Validation R2 logD = 0.624263
Validation rmse logP = 0.593534
Validation R2 logP = 0.903024
Epoch 12
Train function
Loss = 2.1298e-03, PNorm = 35.8160, GNorm = 2.3666, lr_0 = 1.0200e-04
Loss = 2.5879e-03, PNorm = 35.8182, GNorm = 7.2030, lr_0 = 1.0200e-04
Loss = 2.6640e-03, PNorm = 35.8207, GNorm = 3.5031, lr_0 = 1.0200e-04
Loss = 2.7539e-03, PNorm = 35.8233, GNorm = 2.7031, lr_0 = 1.0200e-04
Loss = 3.0097e-03, PNorm = 35.8266, GNorm = 3.4157, lr_0 = 1.0200e-04
Loss = 3.1741e-03, PNorm = 35.8300, GNorm = 8.2507, lr_0 = 1.0200e-04
Loss = 2.6016e-03, PNorm = 35.8320, GNorm = 3.2001, lr_0 = 1.0200e-04
Loss = 2.4079e-03, PNorm = 35.8346, GNorm = 2.4723, lr_0 = 1.0200e-04
Loss = 2.5431e-03, PNorm = 35.8364, GNorm = 4.3904, lr_0 = 1.0200e-04
Loss = 3.9136e-03, PNorm = 35.8373, GNorm = 5.7153, lr_0 = 1.0200e-04
Loss = 3.4760e-03, PNorm = 35.8392, GNorm = 2.7100, lr_0 = 1.0200e-04
Loss = 2.8665e-03, PNorm = 35.8424, GNorm = 5.0314, lr_0 = 1.0200e-04
Loss = 2.4331e-03, PNorm = 35.8454, GNorm = 2.8035, lr_0 = 1.0200e-04
Loss = 2.5281e-03, PNorm = 35.8484, GNorm = 4.5230, lr_0 = 1.0200e-04
Loss = 2.4947e-03, PNorm = 35.8517, GNorm = 2.6911, lr_0 = 1.0200e-04
Loss = 2.7339e-03, PNorm = 35.8546, GNorm = 2.2697, lr_0 = 1.0200e-04
Loss = 2.4350e-03, PNorm = 35.8572, GNorm = 5.4243, lr_0 = 1.0200e-04
Loss = 2.9141e-03, PNorm = 35.8602, GNorm = 2.6926, lr_0 = 1.0200e-04
Loss = 3.2292e-03, PNorm = 35.8628, GNorm = 8.2189, lr_0 = 1.0200e-04
Loss = 2.8882e-03, PNorm = 35.8641, GNorm = 7.8561, lr_0 = 1.0200e-04
Loss = 3.2238e-03, PNorm = 35.8658, GNorm = 3.4155, lr_0 = 1.0200e-04
Loss = 2.3938e-03, PNorm = 35.8684, GNorm = 1.6233, lr_0 = 1.0200e-04
Loss = 2.6431e-03, PNorm = 35.8709, GNorm = 1.6812, lr_0 = 1.0200e-04
Validation rmse logD = 0.729216
Validation R2 logD = 0.628101
Validation rmse logP = 0.602188
Validation R2 logP = 0.900175
Epoch 13
Train function
Loss = 2.9808e-03, PNorm = 35.8738, GNorm = 2.3676, lr_0 = 1.0200e-04
Loss = 1.9832e-03, PNorm = 35.8763, GNorm = 2.3365, lr_0 = 1.0200e-04
Loss = 2.8808e-03, PNorm = 35.8788, GNorm = 3.6150, lr_0 = 1.0200e-04
Loss = 2.5432e-03, PNorm = 35.8813, GNorm = 2.2488, lr_0 = 1.0200e-04
Loss = 2.3986e-03, PNorm = 35.8837, GNorm = 3.7564, lr_0 = 1.0200e-04
Loss = 1.9880e-03, PNorm = 35.8858, GNorm = 2.9802, lr_0 = 1.0200e-04
Loss = 2.1203e-03, PNorm = 35.8876, GNorm = 2.4933, lr_0 = 1.0200e-04
Loss = 2.7799e-03, PNorm = 35.8893, GNorm = 2.2056, lr_0 = 1.0200e-04
Loss = 2.4490e-03, PNorm = 35.8912, GNorm = 3.8333, lr_0 = 1.0200e-04
Loss = 3.0875e-03, PNorm = 35.8942, GNorm = 6.6373, lr_0 = 1.0200e-04
Loss = 2.2967e-03, PNorm = 35.8970, GNorm = 1.8869, lr_0 = 1.0200e-04
Loss = 2.4792e-03, PNorm = 35.9000, GNorm = 4.2245, lr_0 = 1.0200e-04
Loss = 2.7123e-03, PNorm = 35.9021, GNorm = 2.5315, lr_0 = 1.0200e-04
Loss = 2.9420e-03, PNorm = 35.9052, GNorm = 3.7781, lr_0 = 1.0200e-04
Loss = 2.7846e-03, PNorm = 35.9088, GNorm = 2.1904, lr_0 = 1.0200e-04
Loss = 2.6179e-03, PNorm = 35.9108, GNorm = 5.5729, lr_0 = 1.0200e-04
Loss = 2.3673e-03, PNorm = 35.9137, GNorm = 3.6593, lr_0 = 1.0200e-04
Loss = 2.6386e-03, PNorm = 35.9154, GNorm = 2.0279, lr_0 = 1.0200e-04
Loss = 2.4917e-03, PNorm = 35.9180, GNorm = 3.0797, lr_0 = 1.0200e-04
Loss = 2.9054e-03, PNorm = 35.9210, GNorm = 2.8103, lr_0 = 1.0200e-04
Loss = 2.6266e-03, PNorm = 35.9229, GNorm = 4.9280, lr_0 = 1.0200e-04
Loss = 2.9682e-03, PNorm = 35.9264, GNorm = 3.8597, lr_0 = 1.0200e-04
Validation rmse logD = 0.734890
Validation R2 logD = 0.622292
Validation rmse logP = 0.573614
Validation R2 logP = 0.909424
Epoch 14
Train function
Loss = 1.9761e-03, PNorm = 35.9290, GNorm = 1.0103, lr_0 = 1.0200e-04
Loss = 2.5533e-03, PNorm = 35.9315, GNorm = 2.6903, lr_0 = 1.0200e-04
Loss = 2.7986e-03, PNorm = 35.9342, GNorm = 1.4931, lr_0 = 1.0200e-04
Loss = 1.8511e-03, PNorm = 35.9361, GNorm = 1.3728, lr_0 = 1.0200e-04
Loss = 2.6010e-03, PNorm = 35.9373, GNorm = 5.0063, lr_0 = 1.0200e-04
Loss = 2.9737e-03, PNorm = 35.9400, GNorm = 1.6970, lr_0 = 1.0200e-04
Loss = 2.5567e-03, PNorm = 35.9432, GNorm = 5.5785, lr_0 = 1.0200e-04
Loss = 3.4894e-03, PNorm = 35.9449, GNorm = 9.4775, lr_0 = 1.0200e-04
Loss = 2.6411e-03, PNorm = 35.9467, GNorm = 3.5589, lr_0 = 1.0200e-04
Loss = 2.7737e-03, PNorm = 35.9487, GNorm = 6.8828, lr_0 = 1.0200e-04
Loss = 2.4616e-03, PNorm = 35.9509, GNorm = 5.1022, lr_0 = 1.0200e-04
Loss = 2.7158e-03, PNorm = 35.9543, GNorm = 5.4006, lr_0 = 1.0200e-04
Loss = 2.2607e-03, PNorm = 35.9564, GNorm = 1.8359, lr_0 = 1.0200e-04
Loss = 2.6325e-03, PNorm = 35.9597, GNorm = 3.6479, lr_0 = 1.0200e-04
Loss = 2.6159e-03, PNorm = 35.9623, GNorm = 2.7649, lr_0 = 1.0200e-04
Loss = 2.4288e-03, PNorm = 35.9645, GNorm = 1.9590, lr_0 = 1.0200e-04
Loss = 2.5492e-03, PNorm = 35.9667, GNorm = 1.9445, lr_0 = 1.0200e-04
Loss = 1.9826e-03, PNorm = 35.9698, GNorm = 1.3782, lr_0 = 1.0200e-04
Loss = 2.1542e-03, PNorm = 35.9725, GNorm = 1.5632, lr_0 = 1.0200e-04
Loss = 2.4855e-03, PNorm = 35.9747, GNorm = 10.1681, lr_0 = 1.0200e-04
Loss = 2.5005e-03, PNorm = 35.9782, GNorm = 3.6592, lr_0 = 1.0200e-04
Loss = 2.9310e-03, PNorm = 35.9806, GNorm = 7.5202, lr_0 = 1.0200e-04
Loss = 2.9852e-03, PNorm = 35.9826, GNorm = 3.5542, lr_0 = 1.0200e-04
Validation rmse logD = 0.724223
Validation R2 logD = 0.633177
Validation rmse logP = 0.724392
Validation R2 logP = 0.855549
Epoch 15
Train function
Loss = 2.9916e-03, PNorm = 35.9854, GNorm = 4.1042, lr_0 = 1.0200e-04
Loss = 2.5014e-03, PNorm = 35.9889, GNorm = 3.5066, lr_0 = 1.0200e-04
Loss = 2.5100e-03, PNorm = 35.9929, GNorm = 2.1127, lr_0 = 1.0200e-04
Loss = 2.8746e-03, PNorm = 35.9952, GNorm = 1.4177, lr_0 = 1.0200e-04
Loss = 2.8494e-03, PNorm = 35.9971, GNorm = 6.0668, lr_0 = 1.0200e-04
Loss = 2.9202e-03, PNorm = 35.9997, GNorm = 10.7131, lr_0 = 1.0200e-04
Loss = 3.1575e-03, PNorm = 36.0026, GNorm = 8.7661, lr_0 = 1.0200e-04
Loss = 2.7412e-03, PNorm = 36.0047, GNorm = 1.5177, lr_0 = 1.0200e-04
Loss = 2.3439e-03, PNorm = 36.0078, GNorm = 2.2943, lr_0 = 1.0200e-04
Loss = 2.1674e-03, PNorm = 36.0112, GNorm = 1.0538, lr_0 = 1.0200e-04
Loss = 2.5367e-03, PNorm = 36.0142, GNorm = 2.7504, lr_0 = 1.0200e-04
Loss = 2.1566e-03, PNorm = 36.0170, GNorm = 1.0707, lr_0 = 1.0200e-04
Loss = 2.4754e-03, PNorm = 36.0191, GNorm = 4.8824, lr_0 = 1.0200e-04
Loss = 2.1313e-03, PNorm = 36.0209, GNorm = 2.5742, lr_0 = 1.0200e-04
Loss = 2.4821e-03, PNorm = 36.0227, GNorm = 3.5992, lr_0 = 1.0200e-04
Loss = 1.7565e-03, PNorm = 36.0251, GNorm = 1.6868, lr_0 = 1.0200e-04
Loss = 2.0981e-03, PNorm = 36.0275, GNorm = 1.4156, lr_0 = 1.0200e-04
Loss = 1.6946e-03, PNorm = 36.0299, GNorm = 2.0016, lr_0 = 1.0200e-04
Loss = 2.6638e-03, PNorm = 36.0321, GNorm = 3.0240, lr_0 = 1.0200e-04
Loss = 2.4094e-03, PNorm = 36.0337, GNorm = 1.8326, lr_0 = 1.0200e-04
Loss = 2.2140e-03, PNorm = 36.0357, GNorm = 1.7645, lr_0 = 1.0200e-04
Loss = 2.5333e-03, PNorm = 36.0378, GNorm = 5.5589, lr_0 = 1.0200e-04
Validation rmse logD = 0.712793
Validation R2 logD = 0.644664
Validation rmse logP = 0.578211
Validation R2 logP = 0.907966
Epoch 16
Train function
Loss = 1.9399e-03, PNorm = 36.0395, GNorm = 4.5552, lr_0 = 1.0200e-04
Loss = 1.9638e-03, PNorm = 36.0415, GNorm = 3.1029, lr_0 = 1.0200e-04
Loss = 2.5622e-03, PNorm = 36.0443, GNorm = 2.2854, lr_0 = 1.0200e-04
Loss = 2.2385e-03, PNorm = 36.0475, GNorm = 3.1791, lr_0 = 1.0200e-04
Loss = 2.3112e-03, PNorm = 36.0505, GNorm = 4.4097, lr_0 = 1.0200e-04
Loss = 2.5300e-03, PNorm = 36.0538, GNorm = 2.5190, lr_0 = 1.0200e-04
Loss = 2.5870e-03, PNorm = 36.0555, GNorm = 2.3666, lr_0 = 1.0200e-04
Loss = 2.0999e-03, PNorm = 36.0568, GNorm = 2.6828, lr_0 = 1.0200e-04
Loss = 3.1579e-03, PNorm = 36.0602, GNorm = 1.9594, lr_0 = 1.0200e-04
Loss = 2.6036e-03, PNorm = 36.0637, GNorm = 3.1969, lr_0 = 1.0200e-04
Loss = 2.4715e-03, PNorm = 36.0660, GNorm = 3.3702, lr_0 = 1.0200e-04
Loss = 3.1347e-03, PNorm = 36.0682, GNorm = 3.1195, lr_0 = 1.0200e-04
Loss = 2.5244e-03, PNorm = 36.0694, GNorm = 2.4514, lr_0 = 1.0200e-04
Loss = 2.7185e-03, PNorm = 36.0713, GNorm = 2.4947, lr_0 = 1.0200e-04
Loss = 2.2878e-03, PNorm = 36.0743, GNorm = 1.7448, lr_0 = 1.0200e-04
Loss = 2.3639e-03, PNorm = 36.0775, GNorm = 3.2595, lr_0 = 1.0200e-04
Loss = 2.0187e-03, PNorm = 36.0811, GNorm = 3.0788, lr_0 = 1.0200e-04
Loss = 2.0091e-03, PNorm = 36.0835, GNorm = 4.5885, lr_0 = 1.0200e-04
Loss = 2.4783e-03, PNorm = 36.0849, GNorm = 1.4306, lr_0 = 1.0200e-04
Loss = 2.4708e-03, PNorm = 36.0864, GNorm = 3.6473, lr_0 = 1.0200e-04
Loss = 2.5550e-03, PNorm = 36.0877, GNorm = 1.7100, lr_0 = 1.0200e-04
Loss = 2.2029e-03, PNorm = 36.0901, GNorm = 2.8761, lr_0 = 1.0200e-04
Loss = 1.9063e-03, PNorm = 36.0920, GNorm = 2.5853, lr_0 = 1.0200e-04
Validation rmse logD = 0.707174
Validation R2 logD = 0.650244
Validation rmse logP = 0.582206
Validation R2 logP = 0.906690
Epoch 17
Train function
Loss = 2.5895e-03, PNorm = 36.0950, GNorm = 3.2964, lr_0 = 1.0200e-04
Loss = 2.3767e-03, PNorm = 36.0981, GNorm = 4.0774, lr_0 = 1.0200e-04
Loss = 2.2799e-03, PNorm = 36.1017, GNorm = 2.5334, lr_0 = 1.0200e-04
Loss = 2.7309e-03, PNorm = 36.1040, GNorm = 3.4839, lr_0 = 1.0200e-04
Loss = 2.4175e-03, PNorm = 36.1062, GNorm = 2.4553, lr_0 = 1.0200e-04
Loss = 2.2676e-03, PNorm = 36.1085, GNorm = 1.4739, lr_0 = 1.0200e-04
Loss = 2.0778e-03, PNorm = 36.1118, GNorm = 2.2269, lr_0 = 1.0200e-04
Loss = 2.2088e-03, PNorm = 36.1140, GNorm = 1.4084, lr_0 = 1.0200e-04
Loss = 2.1114e-03, PNorm = 36.1165, GNorm = 2.6560, lr_0 = 1.0200e-04
Loss = 2.2612e-03, PNorm = 36.1190, GNorm = 1.7754, lr_0 = 1.0200e-04
Loss = 1.9177e-03, PNorm = 36.1205, GNorm = 1.7547, lr_0 = 1.0200e-04
Loss = 1.8398e-03, PNorm = 36.1226, GNorm = 2.1846, lr_0 = 1.0200e-04
Loss = 2.2085e-03, PNorm = 36.1249, GNorm = 2.9956, lr_0 = 1.0200e-04
Loss = 1.9179e-03, PNorm = 36.1266, GNorm = 1.4133, lr_0 = 1.0200e-04
Loss = 2.4068e-03, PNorm = 36.1286, GNorm = 2.9815, lr_0 = 1.0200e-04
Loss = 2.6764e-03, PNorm = 36.1307, GNorm = 7.6628, lr_0 = 1.0200e-04
Loss = 2.3392e-03, PNorm = 36.1323, GNorm = 7.9428, lr_0 = 1.0200e-04
Loss = 2.5545e-03, PNorm = 36.1341, GNorm = 2.9416, lr_0 = 1.0200e-04
Loss = 2.2551e-03, PNorm = 36.1373, GNorm = 2.3944, lr_0 = 1.0200e-04
Loss = 2.0257e-03, PNorm = 36.1402, GNorm = 2.4802, lr_0 = 1.0200e-04
Loss = 1.9529e-03, PNorm = 36.1433, GNorm = 1.6939, lr_0 = 1.0200e-04
Loss = 1.8448e-03, PNorm = 36.1457, GNorm = 1.8128, lr_0 = 1.0200e-04
Validation rmse logD = 0.700498
Validation R2 logD = 0.656817
Validation rmse logP = 0.558388
Validation R2 logP = 0.914169
Epoch 18
Train function
Loss = 1.7569e-03, PNorm = 36.1476, GNorm = 1.0712, lr_0 = 1.0200e-04
Loss = 1.8491e-03, PNorm = 36.1497, GNorm = 3.3152, lr_0 = 1.0200e-04
Loss = 2.1420e-03, PNorm = 36.1526, GNorm = 1.3329, lr_0 = 1.0200e-04
Loss = 1.9844e-03, PNorm = 36.1549, GNorm = 1.9703, lr_0 = 1.0200e-04
Loss = 2.4892e-03, PNorm = 36.1577, GNorm = 4.3879, lr_0 = 1.0200e-04
Loss = 2.3008e-03, PNorm = 36.1609, GNorm = 1.8365, lr_0 = 1.0200e-04
Loss = 2.4899e-03, PNorm = 36.1633, GNorm = 1.5499, lr_0 = 1.0200e-04
Loss = 2.3721e-03, PNorm = 36.1653, GNorm = 2.2755, lr_0 = 1.0200e-04
Loss = 2.1112e-03, PNorm = 36.1684, GNorm = 3.9516, lr_0 = 1.0200e-04
Loss = 1.9094e-03, PNorm = 36.1702, GNorm = 3.9903, lr_0 = 1.0200e-04
Loss = 2.3253e-03, PNorm = 36.1732, GNorm = 1.5678, lr_0 = 1.0200e-04
Loss = 1.9687e-03, PNorm = 36.1752, GNorm = 2.9478, lr_0 = 1.0200e-04
Loss = 2.1110e-03, PNorm = 36.1775, GNorm = 1.9207, lr_0 = 1.0200e-04
Loss = 2.0989e-03, PNorm = 36.1796, GNorm = 1.9981, lr_0 = 1.0200e-04
Loss = 2.1368e-03, PNorm = 36.1816, GNorm = 1.1107, lr_0 = 1.0200e-04
Loss = 2.4611e-03, PNorm = 36.1836, GNorm = 4.7807, lr_0 = 1.0200e-04
Loss = 2.2776e-03, PNorm = 36.1856, GNorm = 3.7252, lr_0 = 1.0200e-04
Loss = 1.6744e-03, PNorm = 36.1881, GNorm = 5.1512, lr_0 = 1.0200e-04
Loss = 2.3741e-03, PNorm = 36.1900, GNorm = 2.9165, lr_0 = 1.0200e-04
Loss = 2.4178e-03, PNorm = 36.1930, GNorm = 3.0622, lr_0 = 1.0200e-04
Loss = 2.0722e-03, PNorm = 36.1956, GNorm = 1.7356, lr_0 = 1.0200e-04
Loss = 1.9442e-03, PNorm = 36.1982, GNorm = 1.8860, lr_0 = 1.0200e-04
Loss = 2.0983e-03, PNorm = 36.2004, GNorm = 2.8054, lr_0 = 1.0200e-04
Validation rmse logD = 0.768524
Validation R2 logD = 0.586927
Validation rmse logP = 0.561144
Validation R2 logP = 0.913319
Epoch 19
Train function
Loss = 2.1137e-03, PNorm = 36.2028, GNorm = 3.6313, lr_0 = 1.0200e-04
Loss = 1.7202e-03, PNorm = 36.2044, GNorm = 1.5905, lr_0 = 1.0200e-04
Loss = 2.5479e-03, PNorm = 36.2071, GNorm = 2.0598, lr_0 = 1.0200e-04
Loss = 1.6545e-03, PNorm = 36.2096, GNorm = 1.7974, lr_0 = 1.0200e-04
Loss = 2.0614e-03, PNorm = 36.2115, GNorm = 2.3644, lr_0 = 1.0200e-04
Loss = 2.1470e-03, PNorm = 36.2125, GNorm = 4.2756, lr_0 = 1.0200e-04
Loss = 2.2671e-03, PNorm = 36.2147, GNorm = 2.1570, lr_0 = 1.0200e-04
Loss = 1.9473e-03, PNorm = 36.2183, GNorm = 4.5669, lr_0 = 1.0200e-04
Loss = 2.0719e-03, PNorm = 36.2209, GNorm = 1.1423, lr_0 = 1.0200e-04
Loss = 2.1212e-03, PNorm = 36.2227, GNorm = 1.7566, lr_0 = 1.0200e-04
Loss = 1.8540e-03, PNorm = 36.2252, GNorm = 4.6233, lr_0 = 1.0200e-04
Loss = 1.8265e-03, PNorm = 36.2275, GNorm = 1.1780, lr_0 = 1.0200e-04
Loss = 1.8782e-03, PNorm = 36.2301, GNorm = 1.7314, lr_0 = 1.0200e-04
Loss = 2.1405e-03, PNorm = 36.2329, GNorm = 2.0875, lr_0 = 1.0200e-04
Loss = 1.9121e-03, PNorm = 36.2348, GNorm = 2.3678, lr_0 = 1.0200e-04
Loss = 2.0218e-03, PNorm = 36.2363, GNorm = 1.6394, lr_0 = 1.0200e-04
Loss = 2.4104e-03, PNorm = 36.2381, GNorm = 3.1557, lr_0 = 1.0200e-04
Loss = 2.7205e-03, PNorm = 36.2407, GNorm = 5.0129, lr_0 = 1.0200e-04
Loss = 2.3235e-03, PNorm = 36.2430, GNorm = 1.3665, lr_0 = 1.0200e-04
Loss = 2.0974e-03, PNorm = 36.2459, GNorm = 3.0590, lr_0 = 1.0200e-04
Loss = 2.5387e-03, PNorm = 36.2485, GNorm = 3.0156, lr_0 = 1.0200e-04
Loss = 2.0400e-03, PNorm = 36.2502, GNorm = 2.0606, lr_0 = 1.0200e-04
Validation rmse logD = 0.724161
Validation R2 logD = 0.633239
Validation rmse logP = 0.614569
Validation R2 logP = 0.896028
Epoch 20
Train function
Loss = 1.6711e-03, PNorm = 36.2533, GNorm = 4.4585, lr_0 = 1.0200e-04
Loss = 1.7463e-03, PNorm = 36.2568, GNorm = 2.5358, lr_0 = 1.0200e-04
Loss = 1.7178e-03, PNorm = 36.2596, GNorm = 1.2232, lr_0 = 1.0200e-04
Loss = 2.0652e-03, PNorm = 36.2620, GNorm = 1.9101, lr_0 = 1.0200e-04
Loss = 1.7439e-03, PNorm = 36.2648, GNorm = 2.9979, lr_0 = 1.0200e-04
Loss = 2.0133e-03, PNorm = 36.2672, GNorm = 2.3701, lr_0 = 1.0200e-04
Loss = 2.0620e-03, PNorm = 36.2692, GNorm = 1.8943, lr_0 = 1.0200e-04
Loss = 1.8704e-03, PNorm = 36.2720, GNorm = 5.2650, lr_0 = 1.0200e-04
Loss = 2.0577e-03, PNorm = 36.2736, GNorm = 1.9785, lr_0 = 1.0200e-04
Loss = 2.1163e-03, PNorm = 36.2755, GNorm = 6.3786, lr_0 = 1.0200e-04
Loss = 2.2429e-03, PNorm = 36.2781, GNorm = 5.4234, lr_0 = 1.0200e-04
Loss = 2.2195e-03, PNorm = 36.2808, GNorm = 5.6089, lr_0 = 1.0200e-04
Loss = 2.7724e-03, PNorm = 36.2833, GNorm = 9.4322, lr_0 = 1.0200e-04
Loss = 2.3592e-03, PNorm = 36.2851, GNorm = 3.2533, lr_0 = 1.0200e-04
Loss = 1.7007e-03, PNorm = 36.2870, GNorm = 5.3115, lr_0 = 1.0200e-04
Loss = 2.0676e-03, PNorm = 36.2886, GNorm = 3.4194, lr_0 = 1.0200e-04
Loss = 1.8369e-03, PNorm = 36.2911, GNorm = 1.0992, lr_0 = 1.0200e-04
Loss = 1.5457e-03, PNorm = 36.2934, GNorm = 2.8761, lr_0 = 1.0200e-04
Loss = 1.9227e-03, PNorm = 36.2959, GNorm = 1.4925, lr_0 = 1.0200e-04
Loss = 2.4269e-03, PNorm = 36.2982, GNorm = 3.7913, lr_0 = 1.0200e-04
Loss = 2.2758e-03, PNorm = 36.3003, GNorm = 3.9057, lr_0 = 1.0200e-04
Loss = 1.8368e-03, PNorm = 36.3031, GNorm = 1.1147, lr_0 = 1.0200e-04
Loss = 1.7318e-03, PNorm = 36.3052, GNorm = 1.4276, lr_0 = 1.0200e-04
Validation rmse logD = 0.688881
Validation R2 logD = 0.668105
Validation rmse logP = 0.539592
Validation R2 logP = 0.919850
Epoch 21
Train function
Loss = 1.9575e-03, PNorm = 36.3076, GNorm = 1.9084, lr_0 = 1.0200e-04
Loss = 2.0977e-03, PNorm = 36.3112, GNorm = 1.2809, lr_0 = 1.0200e-04
Loss = 2.1699e-03, PNorm = 36.3141, GNorm = 3.2657, lr_0 = 1.0200e-04
Loss = 2.0209e-03, PNorm = 36.3162, GNorm = 6.0774, lr_0 = 1.0200e-04
Loss = 1.8157e-03, PNorm = 36.3174, GNorm = 3.0864, lr_0 = 1.0200e-04
Loss = 1.7703e-03, PNorm = 36.3192, GNorm = 1.9165, lr_0 = 1.0200e-04
Loss = 1.6254e-03, PNorm = 36.3208, GNorm = 3.4110, lr_0 = 1.0200e-04
Loss = 2.2220e-03, PNorm = 36.3235, GNorm = 4.7158, lr_0 = 1.0200e-04
Loss = 1.7490e-03, PNorm = 36.3261, GNorm = 5.1725, lr_0 = 1.0200e-04
Loss = 1.7773e-03, PNorm = 36.3281, GNorm = 1.8919, lr_0 = 1.0200e-04
Loss = 2.1225e-03, PNorm = 36.3295, GNorm = 1.7944, lr_0 = 1.0200e-04
Loss = 2.5832e-03, PNorm = 36.3320, GNorm = 2.3914, lr_0 = 1.0200e-04
Loss = 1.9867e-03, PNorm = 36.3352, GNorm = 2.2950, lr_0 = 1.0200e-04
Loss = 1.8292e-03, PNorm = 36.3378, GNorm = 1.2942, lr_0 = 1.0200e-04
Loss = 1.6628e-03, PNorm = 36.3395, GNorm = 1.2071, lr_0 = 1.0200e-04
Loss = 1.9498e-03, PNorm = 36.3414, GNorm = 1.9926, lr_0 = 1.0200e-04
Loss = 1.6175e-03, PNorm = 36.3430, GNorm = 1.4458, lr_0 = 1.0200e-04
Loss = 1.7781e-03, PNorm = 36.3451, GNorm = 2.4624, lr_0 = 1.0200e-04
Loss = 1.4831e-03, PNorm = 36.3477, GNorm = 3.3606, lr_0 = 1.0200e-04
Loss = 2.0182e-03, PNorm = 36.3498, GNorm = 1.7646, lr_0 = 1.0200e-04
Loss = 1.6144e-03, PNorm = 36.3517, GNorm = 2.8118, lr_0 = 1.0200e-04
Loss = 1.9190e-03, PNorm = 36.3538, GNorm = 3.3014, lr_0 = 1.0200e-04
Loss = 2.1020e-03, PNorm = 36.3558, GNorm = 1.4891, lr_0 = 1.0200e-04
Loss = 2.9111e-03, PNorm = 36.3561, GNorm = 1.9486, lr_0 = 1.0200e-04
Validation rmse logD = 0.736461
Validation R2 logD = 0.620675
Validation rmse logP = 0.564488
Validation R2 logP = 0.912283
Epoch 22
Train function
Loss = 1.8155e-03, PNorm = 36.3583, GNorm = 0.8437, lr_0 = 1.0200e-04
Loss = 1.4393e-03, PNorm = 36.3599, GNorm = 2.2867, lr_0 = 1.0200e-04
Loss = 1.8044e-03, PNorm = 36.3617, GNorm = 4.2369, lr_0 = 1.0200e-04
Loss = 1.9298e-03, PNorm = 36.3637, GNorm = 3.3569, lr_0 = 1.0200e-04
Loss = 2.3933e-03, PNorm = 36.3660, GNorm = 4.1298, lr_0 = 1.0200e-04
Loss = 2.1467e-03, PNorm = 36.3678, GNorm = 4.3558, lr_0 = 1.0200e-04
Loss = 2.2255e-03, PNorm = 36.3701, GNorm = 2.9864, lr_0 = 1.0200e-04
Loss = 2.0325e-03, PNorm = 36.3733, GNorm = 2.2321, lr_0 = 1.0200e-04
Loss = 2.3162e-03, PNorm = 36.3765, GNorm = 3.3499, lr_0 = 1.0200e-04
Loss = 2.0143e-03, PNorm = 36.3780, GNorm = 2.2895, lr_0 = 1.0200e-04
Loss = 1.9710e-03, PNorm = 36.3793, GNorm = 3.2168, lr_0 = 1.0200e-04
Loss = 1.7465e-03, PNorm = 36.3827, GNorm = 1.9710, lr_0 = 1.0200e-04
Loss = 1.6885e-03, PNorm = 36.3851, GNorm = 2.3958, lr_0 = 1.0200e-04
Loss = 2.1434e-03, PNorm = 36.3877, GNorm = 2.5835, lr_0 = 1.0200e-04
Loss = 2.0558e-03, PNorm = 36.3889, GNorm = 1.9600, lr_0 = 1.0200e-04
Loss = 1.9264e-03, PNorm = 36.3915, GNorm = 2.3872, lr_0 = 1.0200e-04
Loss = 1.9558e-03, PNorm = 36.3935, GNorm = 1.4574, lr_0 = 1.0200e-04
Loss = 2.1143e-03, PNorm = 36.3963, GNorm = 1.8884, lr_0 = 1.0200e-04
Loss = 1.7399e-03, PNorm = 36.3992, GNorm = 1.3230, lr_0 = 1.0200e-04
Loss = 2.1742e-03, PNorm = 36.4016, GNorm = 2.4187, lr_0 = 1.0200e-04
Loss = 1.5552e-03, PNorm = 36.4037, GNorm = 1.7758, lr_0 = 1.0200e-04
Loss = 1.9882e-03, PNorm = 36.4058, GNorm = 4.1202, lr_0 = 1.0200e-04
Validation rmse logD = 0.679542
Validation R2 logD = 0.677043
Validation rmse logP = 0.551647
Validation R2 logP = 0.916229
Epoch 23
Train function
Loss = 1.5746e-03, PNorm = 36.4082, GNorm = 4.4828, lr_0 = 1.0200e-04
Loss = 1.8299e-03, PNorm = 36.4103, GNorm = 4.9009, lr_0 = 1.0200e-04
Loss = 1.6927e-03, PNorm = 36.4128, GNorm = 2.0499, lr_0 = 1.0200e-04
Loss = 1.5650e-03, PNorm = 36.4143, GNorm = 3.0358, lr_0 = 1.0200e-04
Loss = 1.7285e-03, PNorm = 36.4155, GNorm = 1.6965, lr_0 = 1.0200e-04
Loss = 1.9505e-03, PNorm = 36.4176, GNorm = 1.5734, lr_0 = 1.0200e-04
Loss = 1.4987e-03, PNorm = 36.4201, GNorm = 2.3050, lr_0 = 1.0200e-04
Loss = 1.5837e-03, PNorm = 36.4223, GNorm = 1.2160, lr_0 = 1.0200e-04
Loss = 2.1058e-03, PNorm = 36.4242, GNorm = 3.9728, lr_0 = 1.0200e-04
Loss = 2.2235e-03, PNorm = 36.4264, GNorm = 4.9240, lr_0 = 1.0200e-04
Loss = 2.1426e-03, PNorm = 36.4288, GNorm = 3.9403, lr_0 = 1.0200e-04
Loss = 2.1347e-03, PNorm = 36.4310, GNorm = 4.1134, lr_0 = 1.0200e-04
Loss = 1.7696e-03, PNorm = 36.4333, GNorm = 2.7330, lr_0 = 1.0200e-04
Loss = 1.7106e-03, PNorm = 36.4351, GNorm = 5.3911, lr_0 = 1.0200e-04
Loss = 1.8657e-03, PNorm = 36.4368, GNorm = 1.0331, lr_0 = 1.0200e-04
Loss = 1.6056e-03, PNorm = 36.4383, GNorm = 1.4593, lr_0 = 1.0200e-04
Loss = 1.3130e-03, PNorm = 36.4408, GNorm = 2.1624, lr_0 = 1.0200e-04
Loss = 1.7833e-03, PNorm = 36.4434, GNorm = 1.4932, lr_0 = 1.0200e-04
Loss = 1.8855e-03, PNorm = 36.4468, GNorm = 5.6983, lr_0 = 1.0200e-04
Loss = 1.9690e-03, PNorm = 36.4487, GNorm = 4.4911, lr_0 = 1.0200e-04
Loss = 2.0649e-03, PNorm = 36.4522, GNorm = 3.7248, lr_0 = 1.0200e-04
Loss = 1.9872e-03, PNorm = 36.4552, GNorm = 2.4061, lr_0 = 1.0200e-04
Loss = 2.2374e-03, PNorm = 36.4572, GNorm = 5.8865, lr_0 = 1.0200e-04
Validation rmse logD = 0.682868
Validation R2 logD = 0.673874
Validation rmse logP = 0.565165
Validation R2 logP = 0.912072
Epoch 24
Train function
Loss = 2.0230e-03, PNorm = 36.4595, GNorm = 4.9104, lr_0 = 1.0200e-04
Loss = 2.2599e-03, PNorm = 36.4618, GNorm = 1.3635, lr_0 = 1.0200e-04
Loss = 1.7058e-03, PNorm = 36.4635, GNorm = 1.1837, lr_0 = 1.0200e-04
Loss = 1.7842e-03, PNorm = 36.4656, GNorm = 4.8724, lr_0 = 1.0200e-04
Loss = 1.3033e-03, PNorm = 36.4674, GNorm = 1.0158, lr_0 = 1.0200e-04
Loss = 2.3160e-03, PNorm = 36.4708, GNorm = 3.2434, lr_0 = 1.0200e-04
Loss = 1.6793e-03, PNorm = 36.4730, GNorm = 1.8582, lr_0 = 1.0200e-04
Loss = 1.6536e-03, PNorm = 36.4748, GNorm = 2.3426, lr_0 = 1.0200e-04
Loss = 2.0657e-03, PNorm = 36.4779, GNorm = 3.5985, lr_0 = 1.0200e-04
Loss = 2.2896e-03, PNorm = 36.4790, GNorm = 4.5044, lr_0 = 1.0200e-04
Loss = 2.0635e-03, PNorm = 36.4808, GNorm = 2.9959, lr_0 = 1.0200e-04
Loss = 1.9277e-03, PNorm = 36.4827, GNorm = 4.6907, lr_0 = 1.0200e-04
Loss = 1.6435e-03, PNorm = 36.4847, GNorm = 1.5055, lr_0 = 1.0200e-04
Loss = 1.6857e-03, PNorm = 36.4875, GNorm = 1.5220, lr_0 = 1.0200e-04
Loss = 1.7860e-03, PNorm = 36.4903, GNorm = 8.3300, lr_0 = 1.0200e-04
Loss = 2.1606e-03, PNorm = 36.4929, GNorm = 3.7241, lr_0 = 1.0200e-04
Loss = 1.7929e-03, PNorm = 36.4952, GNorm = 1.5728, lr_0 = 1.0200e-04
Loss = 1.9926e-03, PNorm = 36.4984, GNorm = 4.8436, lr_0 = 1.0200e-04
Loss = 1.3959e-03, PNorm = 36.5013, GNorm = 2.3758, lr_0 = 1.0200e-04
Loss = 1.7401e-03, PNorm = 36.5031, GNorm = 3.4626, lr_0 = 1.0200e-04
Loss = 1.6865e-03, PNorm = 36.5057, GNorm = 1.5212, lr_0 = 1.0200e-04
Loss = 1.8383e-03, PNorm = 36.5086, GNorm = 1.5985, lr_0 = 1.0200e-04
Validation rmse logD = 0.709115
Validation R2 logD = 0.648322
Validation rmse logP = 0.580594
Validation R2 logP = 0.907206
Epoch 25
Train function
Loss = 1.9698e-03, PNorm = 36.5110, GNorm = 4.4974, lr_0 = 1.0200e-04
Loss = 1.7578e-03, PNorm = 36.5126, GNorm = 1.6342, lr_0 = 1.0200e-04
Loss = 1.8892e-03, PNorm = 36.5150, GNorm = 3.1188, lr_0 = 1.0200e-04
Loss = 1.9070e-03, PNorm = 36.5174, GNorm = 5.1984, lr_0 = 1.0200e-04
Loss = 1.6506e-03, PNorm = 36.5198, GNorm = 1.9400, lr_0 = 1.0200e-04
Loss = 1.9779e-03, PNorm = 36.5212, GNorm = 2.9135, lr_0 = 1.0200e-04
Loss = 1.5925e-03, PNorm = 36.5232, GNorm = 4.3532, lr_0 = 1.0200e-04
Loss = 1.9350e-03, PNorm = 36.5254, GNorm = 1.4227, lr_0 = 1.0200e-04
Loss = 1.7562e-03, PNorm = 36.5273, GNorm = 1.7384, lr_0 = 1.0200e-04
Loss = 1.5140e-03, PNorm = 36.5294, GNorm = 1.4239, lr_0 = 1.0200e-04
Loss = 1.8811e-03, PNorm = 36.5314, GNorm = 2.3994, lr_0 = 1.0200e-04
Loss = 1.4997e-03, PNorm = 36.5338, GNorm = 4.0336, lr_0 = 1.0200e-04
Loss = 1.8554e-03, PNorm = 36.5357, GNorm = 2.0698, lr_0 = 1.0200e-04
Loss = 1.8404e-03, PNorm = 36.5381, GNorm = 1.6709, lr_0 = 1.0200e-04
Loss = 1.9355e-03, PNorm = 36.5397, GNorm = 1.6697, lr_0 = 1.0200e-04
Loss = 1.8571e-03, PNorm = 36.5408, GNorm = 2.3118, lr_0 = 1.0200e-04
Loss = 1.7786e-03, PNorm = 36.5430, GNorm = 3.4893, lr_0 = 1.0200e-04
Loss = 1.5351e-03, PNorm = 36.5458, GNorm = 1.6864, lr_0 = 1.0200e-04
Loss = 1.8099e-03, PNorm = 36.5477, GNorm = 3.3534, lr_0 = 1.0200e-04
Loss = 1.8540e-03, PNorm = 36.5503, GNorm = 5.1171, lr_0 = 1.0200e-04
Loss = 1.6934e-03, PNorm = 36.5529, GNorm = 2.8201, lr_0 = 1.0200e-04
Loss = 1.5734e-03, PNorm = 36.5547, GNorm = 3.7871, lr_0 = 1.0200e-04
Loss = 1.5150e-03, PNorm = 36.5569, GNorm = 1.4295, lr_0 = 1.0200e-04
Validation rmse logD = 0.665189
Validation R2 logD = 0.690542
Validation rmse logP = 0.571412
Validation R2 logP = 0.910118
Epoch 26
Train function
Loss = 1.8781e-03, PNorm = 36.5590, GNorm = 2.4345, lr_0 = 1.0200e-04
Loss = 1.8164e-03, PNorm = 36.5607, GNorm = 3.5287, lr_0 = 1.0200e-04
Loss = 1.8372e-03, PNorm = 36.5633, GNorm = 1.5837, lr_0 = 1.0200e-04
Loss = 1.7359e-03, PNorm = 36.5654, GNorm = 2.9764, lr_0 = 1.0200e-04
Loss = 1.8661e-03, PNorm = 36.5681, GNorm = 5.2999, lr_0 = 1.0200e-04
Loss = 1.9426e-03, PNorm = 36.5698, GNorm = 1.8333, lr_0 = 1.0200e-04
Loss = 1.5874e-03, PNorm = 36.5720, GNorm = 1.9718, lr_0 = 1.0200e-04
Loss = 1.5475e-03, PNorm = 36.5751, GNorm = 1.3095, lr_0 = 1.0200e-04
Loss = 1.3649e-03, PNorm = 36.5775, GNorm = 2.3617, lr_0 = 1.0200e-04
Loss = 1.6316e-03, PNorm = 36.5797, GNorm = 2.9157, lr_0 = 1.0200e-04
Loss = 1.6172e-03, PNorm = 36.5818, GNorm = 1.9709, lr_0 = 1.0200e-04
Loss = 1.7745e-03, PNorm = 36.5836, GNorm = 2.1571, lr_0 = 1.0200e-04
Loss = 1.7250e-03, PNorm = 36.5851, GNorm = 3.1868, lr_0 = 1.0200e-04
Loss = 1.6080e-03, PNorm = 36.5877, GNorm = 2.6173, lr_0 = 1.0200e-04
Loss = 1.7344e-03, PNorm = 36.5902, GNorm = 7.9504, lr_0 = 1.0200e-04
Loss = 1.7719e-03, PNorm = 36.5926, GNorm = 1.4278, lr_0 = 1.0200e-04
Loss = 1.6137e-03, PNorm = 36.5950, GNorm = 5.6858, lr_0 = 1.0200e-04
Loss = 1.6495e-03, PNorm = 36.5975, GNorm = 1.4356, lr_0 = 1.0200e-04
Loss = 1.5635e-03, PNorm = 36.5990, GNorm = 5.9560, lr_0 = 1.0200e-04
Loss = 1.5039e-03, PNorm = 36.6004, GNorm = 3.7926, lr_0 = 1.0200e-04
Loss = 1.8461e-03, PNorm = 36.6025, GNorm = 2.0300, lr_0 = 1.0200e-04
Loss = 1.5266e-03, PNorm = 36.6043, GNorm = 2.5102, lr_0 = 1.0200e-04
Validation rmse logD = 0.692159
Validation R2 logD = 0.664939
Validation rmse logP = 0.526639
Validation R2 logP = 0.923652
Epoch 27
Train function
Loss = 1.7984e-03, PNorm = 36.6062, GNorm = 1.6651, lr_0 = 1.0200e-04
Loss = 1.5323e-03, PNorm = 36.6078, GNorm = 1.3626, lr_0 = 1.0200e-04
Loss = 1.8088e-03, PNorm = 36.6094, GNorm = 5.7560, lr_0 = 1.0200e-04
Loss = 1.4204e-03, PNorm = 36.6123, GNorm = 2.2954, lr_0 = 1.0200e-04
Loss = 1.8242e-03, PNorm = 36.6147, GNorm = 1.8639, lr_0 = 1.0200e-04
Loss = 1.7207e-03, PNorm = 36.6173, GNorm = 3.8105, lr_0 = 1.0200e-04
Loss = 2.0128e-03, PNorm = 36.6194, GNorm = 2.9096, lr_0 = 1.0200e-04
Loss = 1.8447e-03, PNorm = 36.6210, GNorm = 3.9678, lr_0 = 1.0200e-04
Loss = 1.6753e-03, PNorm = 36.6239, GNorm = 2.3035, lr_0 = 1.0200e-04
Loss = 1.6283e-03, PNorm = 36.6254, GNorm = 2.2260, lr_0 = 1.0200e-04
Loss = 1.6251e-03, PNorm = 36.6274, GNorm = 2.2967, lr_0 = 1.0200e-04
Loss = 1.7774e-03, PNorm = 36.6318, GNorm = 3.8561, lr_0 = 1.0200e-04
Loss = 1.3405e-03, PNorm = 36.6349, GNorm = 2.1572, lr_0 = 1.0200e-04
Loss = 1.7852e-03, PNorm = 36.6366, GNorm = 2.1910, lr_0 = 1.0200e-04
Loss = 1.5911e-03, PNorm = 36.6376, GNorm = 3.5435, lr_0 = 1.0200e-04
Loss = 1.5229e-03, PNorm = 36.6402, GNorm = 1.4525, lr_0 = 1.0200e-04
Loss = 1.3234e-03, PNorm = 36.6420, GNorm = 1.1290, lr_0 = 1.0200e-04
Loss = 1.5450e-03, PNorm = 36.6438, GNorm = 1.7014, lr_0 = 1.0200e-04
Loss = 1.9140e-03, PNorm = 36.6459, GNorm = 4.6611, lr_0 = 1.0200e-04
Loss = 1.4182e-03, PNorm = 36.6473, GNorm = 1.7159, lr_0 = 1.0200e-04
Loss = 1.4983e-03, PNorm = 36.6487, GNorm = 3.7593, lr_0 = 1.0200e-04
Loss = 1.4883e-03, PNorm = 36.6506, GNorm = 2.5591, lr_0 = 1.0200e-04
Loss = 1.5910e-03, PNorm = 36.6520, GNorm = 3.9497, lr_0 = 1.0200e-04
Validation rmse logD = 0.668758
Validation R2 logD = 0.687212
Validation rmse logP = 0.535676
Validation R2 logP = 0.921009
Epoch 28
Train function
Loss = 1.3228e-03, PNorm = 36.6541, GNorm = 1.5987, lr_0 = 1.0200e-04
Loss = 1.4302e-03, PNorm = 36.6560, GNorm = 0.8666, lr_0 = 1.0200e-04
Loss = 1.8132e-03, PNorm = 36.6588, GNorm = 2.3635, lr_0 = 1.0200e-04
Loss = 2.2731e-03, PNorm = 36.6615, GNorm = 2.2938, lr_0 = 1.0200e-04
Loss = 1.3503e-03, PNorm = 36.6637, GNorm = 2.0004, lr_0 = 1.0200e-04
Loss = 1.4410e-03, PNorm = 36.6654, GNorm = 1.1685, lr_0 = 1.0200e-04
Loss = 1.6555e-03, PNorm = 36.6679, GNorm = 2.1157, lr_0 = 1.0200e-04
Loss = 1.5408e-03, PNorm = 36.6701, GNorm = 1.2733, lr_0 = 1.0200e-04
Loss = 1.7680e-03, PNorm = 36.6730, GNorm = 5.2585, lr_0 = 1.0200e-04
Loss = 1.4053e-03, PNorm = 36.6749, GNorm = 1.8946, lr_0 = 1.0200e-04
Loss = 1.7929e-03, PNorm = 36.6775, GNorm = 5.1353, lr_0 = 1.0200e-04
Loss = 1.6809e-03, PNorm = 36.6802, GNorm = 1.7008, lr_0 = 1.0200e-04
Loss = 1.3729e-03, PNorm = 36.6815, GNorm = 3.2874, lr_0 = 1.0200e-04
Loss = 2.1996e-03, PNorm = 36.6819, GNorm = 5.3448, lr_0 = 1.0200e-04
Loss = 1.8101e-03, PNorm = 36.6831, GNorm = 5.0759, lr_0 = 1.0200e-04
Loss = 1.6044e-03, PNorm = 36.6850, GNorm = 6.5655, lr_0 = 1.0200e-04
Loss = 1.7295e-03, PNorm = 36.6883, GNorm = 5.2563, lr_0 = 1.0200e-04
Loss = 1.8206e-03, PNorm = 36.6907, GNorm = 2.7762, lr_0 = 1.0200e-04
Loss = 1.5386e-03, PNorm = 36.6924, GNorm = 1.8495, lr_0 = 1.0200e-04
Loss = 1.5966e-03, PNorm = 36.6939, GNorm = 1.6484, lr_0 = 1.0200e-04
Loss = 1.6439e-03, PNorm = 36.6963, GNorm = 2.0319, lr_0 = 1.0200e-04
Loss = 1.2913e-03, PNorm = 36.6988, GNorm = 1.2225, lr_0 = 1.0200e-04
Validation rmse logD = 0.683447
Validation R2 logD = 0.673320
Validation rmse logP = 0.522651
Validation R2 logP = 0.924803
Epoch 29
Train function
Loss = 1.4022e-03, PNorm = 36.7007, GNorm = 2.3287, lr_0 = 1.0200e-04
Loss = 1.5671e-03, PNorm = 36.7031, GNorm = 4.3444, lr_0 = 1.0200e-04
Loss = 1.5334e-03, PNorm = 36.7044, GNorm = 4.4444, lr_0 = 1.0200e-04
Loss = 1.2887e-03, PNorm = 36.7063, GNorm = 1.7104, lr_0 = 1.0200e-04
Loss = 1.7144e-03, PNorm = 36.7076, GNorm = 2.8479, lr_0 = 1.0200e-04
Loss = 1.6906e-03, PNorm = 36.7093, GNorm = 2.4562, lr_0 = 1.0200e-04
Loss = 1.4904e-03, PNorm = 36.7120, GNorm = 1.6143, lr_0 = 1.0200e-04
Loss = 1.2890e-03, PNorm = 36.7138, GNorm = 2.4825, lr_0 = 1.0200e-04
Loss = 1.3431e-03, PNorm = 36.7162, GNorm = 2.4871, lr_0 = 1.0200e-04
Loss = 1.4558e-03, PNorm = 36.7182, GNorm = 1.2887, lr_0 = 1.0200e-04
Loss = 1.6537e-03, PNorm = 36.7202, GNorm = 6.1919, lr_0 = 1.0200e-04
Loss = 1.7510e-03, PNorm = 36.7214, GNorm = 3.4869, lr_0 = 1.0200e-04
Loss = 1.3997e-03, PNorm = 36.7235, GNorm = 1.7511, lr_0 = 1.0200e-04
Loss = 1.4205e-03, PNorm = 36.7268, GNorm = 2.1383, lr_0 = 1.0200e-04
Loss = 1.5663e-03, PNorm = 36.7305, GNorm = 1.5763, lr_0 = 1.0200e-04
Loss = 1.5457e-03, PNorm = 36.7334, GNorm = 4.1726, lr_0 = 1.0200e-04
Loss = 1.3327e-03, PNorm = 36.7352, GNorm = 1.5679, lr_0 = 1.0200e-04
Loss = 1.6587e-03, PNorm = 36.7376, GNorm = 2.5032, lr_0 = 1.0200e-04
Loss = 1.5494e-03, PNorm = 36.7397, GNorm = 2.6002, lr_0 = 1.0200e-04
Loss = 1.6494e-03, PNorm = 36.7410, GNorm = 2.4091, lr_0 = 1.0200e-04
Loss = 1.8801e-03, PNorm = 36.7417, GNorm = 2.9027, lr_0 = 1.0200e-04
Loss = 1.8050e-03, PNorm = 36.7430, GNorm = 5.3288, lr_0 = 1.0200e-04
Loss = 1.6742e-03, PNorm = 36.7452, GNorm = 2.7904, lr_0 = 1.0200e-04
Validation rmse logD = 0.671889
Validation R2 logD = 0.684277
Validation rmse logP = 0.549770
Validation R2 logP = 0.916798
Epoch 30
Train function
Loss = 1.2540e-03, PNorm = 36.7481, GNorm = 1.3193, lr_0 = 1.0200e-04
Loss = 1.2604e-03, PNorm = 36.7504, GNorm = 1.3842, lr_0 = 1.0200e-04
Loss = 1.5287e-03, PNorm = 36.7530, GNorm = 1.8627, lr_0 = 1.0200e-04
Loss = 1.3441e-03, PNorm = 36.7552, GNorm = 1.1534, lr_0 = 1.0200e-04
Loss = 1.3105e-03, PNorm = 36.7570, GNorm = 3.5039, lr_0 = 1.0200e-04
Loss = 1.2363e-03, PNorm = 36.7584, GNorm = 1.2755, lr_0 = 1.0200e-04
Loss = 1.8829e-03, PNorm = 36.7612, GNorm = 2.4214, lr_0 = 1.0200e-04
Loss = 1.6040e-03, PNorm = 36.7626, GNorm = 2.8755, lr_0 = 1.0200e-04
Loss = 1.9005e-03, PNorm = 36.7649, GNorm = 4.7602, lr_0 = 1.0200e-04
Loss = 1.6528e-03, PNorm = 36.7666, GNorm = 2.3062, lr_0 = 1.0200e-04
Loss = 1.4379e-03, PNorm = 36.7686, GNorm = 1.7321, lr_0 = 1.0200e-04
Loss = 1.7682e-03, PNorm = 36.7706, GNorm = 3.6052, lr_0 = 1.0200e-04
Loss = 1.2645e-03, PNorm = 36.7726, GNorm = 1.2599, lr_0 = 1.0200e-04
Loss = 1.5352e-03, PNorm = 36.7743, GNorm = 2.3992, lr_0 = 1.0200e-04
Loss = 1.3443e-03, PNorm = 36.7771, GNorm = 1.3283, lr_0 = 1.0200e-04
Loss = 1.7378e-03, PNorm = 36.7793, GNorm = 1.7582, lr_0 = 1.0200e-04
Loss = 1.5308e-03, PNorm = 36.7815, GNorm = 2.6398, lr_0 = 1.0200e-04
Loss = 1.5409e-03, PNorm = 36.7838, GNorm = 1.9756, lr_0 = 1.0200e-04
Loss = 1.3877e-03, PNorm = 36.7855, GNorm = 2.1248, lr_0 = 1.0200e-04
Loss = 1.3283e-03, PNorm = 36.7869, GNorm = 3.3575, lr_0 = 1.0200e-04
Loss = 1.5821e-03, PNorm = 36.7883, GNorm = 4.6409, lr_0 = 1.0200e-04
Loss = 1.5232e-03, PNorm = 36.7910, GNorm = 4.8993, lr_0 = 1.0200e-04
Validation rmse logD = 0.741113
Validation R2 logD = 0.615867
Validation rmse logP = 0.517223
Validation R2 logP = 0.926357
Epoch 31
Train function
Loss = 1.9364e-03, PNorm = 36.7935, GNorm = 5.9164, lr_0 = 1.0200e-04
Loss = 1.5805e-03, PNorm = 36.7956, GNorm = 2.6883, lr_0 = 1.0200e-04
Loss = 1.4414e-03, PNorm = 36.7984, GNorm = 1.2270, lr_0 = 1.0200e-04
Loss = 1.0791e-03, PNorm = 36.8005, GNorm = 1.6204, lr_0 = 1.0200e-04
Loss = 1.5093e-03, PNorm = 36.8018, GNorm = 3.4508, lr_0 = 1.0200e-04
Loss = 1.5447e-03, PNorm = 36.8035, GNorm = 3.2914, lr_0 = 1.0200e-04
Loss = 1.5799e-03, PNorm = 36.8054, GNorm = 3.4299, lr_0 = 1.0200e-04
Loss = 1.2187e-03, PNorm = 36.8072, GNorm = 1.1589, lr_0 = 1.0200e-04
Loss = 1.5168e-03, PNorm = 36.8087, GNorm = 0.7510, lr_0 = 1.0200e-04
Loss = 1.1083e-03, PNorm = 36.8113, GNorm = 3.4612, lr_0 = 1.0200e-04
Loss = 1.4238e-03, PNorm = 36.8136, GNorm = 1.3573, lr_0 = 1.0200e-04
Loss = 1.5628e-03, PNorm = 36.8158, GNorm = 1.7241, lr_0 = 1.0200e-04
Loss = 1.5401e-03, PNorm = 36.8185, GNorm = 2.3925, lr_0 = 1.0200e-04
Loss = 1.3175e-03, PNorm = 36.8210, GNorm = 2.8584, lr_0 = 1.0200e-04
Loss = 1.5257e-03, PNorm = 36.8225, GNorm = 5.4315, lr_0 = 1.0200e-04
Loss = 1.4621e-03, PNorm = 36.8242, GNorm = 2.4608, lr_0 = 1.0200e-04
Loss = 1.4097e-03, PNorm = 36.8268, GNorm = 2.3126, lr_0 = 1.0200e-04
Loss = 1.5602e-03, PNorm = 36.8300, GNorm = 4.2850, lr_0 = 1.0200e-04
Loss = 1.6078e-03, PNorm = 36.8321, GNorm = 1.1500, lr_0 = 1.0200e-04
Loss = 1.5851e-03, PNorm = 36.8341, GNorm = 3.1909, lr_0 = 1.0200e-04
Loss = 1.4661e-03, PNorm = 36.8353, GNorm = 2.9014, lr_0 = 1.0200e-04
Loss = 1.4537e-03, PNorm = 36.8362, GNorm = 3.5030, lr_0 = 1.0200e-04
Loss = 1.6476e-03, PNorm = 36.8390, GNorm = 1.9591, lr_0 = 1.0200e-04
Validation rmse logD = 0.641102
Validation R2 logD = 0.712548
Validation rmse logP = 0.515941
Validation R2 logP = 0.926722
Epoch 32
Train function
Loss = 1.1706e-03, PNorm = 36.8417, GNorm = 2.1259, lr_0 = 1.0200e-04
Loss = 1.4189e-03, PNorm = 36.8436, GNorm = 2.0220, lr_0 = 1.0200e-04
Loss = 1.3365e-03, PNorm = 36.8454, GNorm = 5.6802, lr_0 = 1.0200e-04
Loss = 1.3398e-03, PNorm = 36.8483, GNorm = 3.5619, lr_0 = 1.0200e-04
Loss = 1.7442e-03, PNorm = 36.8506, GNorm = 3.8914, lr_0 = 1.0200e-04
Loss = 1.0730e-03, PNorm = 36.8517, GNorm = 1.7211, lr_0 = 1.0200e-04
Loss = 1.2275e-03, PNorm = 36.8538, GNorm = 6.0226, lr_0 = 1.0200e-04
Loss = 1.4543e-03, PNorm = 36.8552, GNorm = 1.8619, lr_0 = 1.0200e-04
Loss = 1.5092e-03, PNorm = 36.8567, GNorm = 1.6020, lr_0 = 1.0200e-04
Loss = 1.4135e-03, PNorm = 36.8582, GNorm = 1.7334, lr_0 = 1.0200e-04
Loss = 1.4380e-03, PNorm = 36.8610, GNorm = 1.3997, lr_0 = 1.0200e-04
Loss = 1.6821e-03, PNorm = 36.8634, GNorm = 6.9239, lr_0 = 1.0200e-04
Loss = 1.3178e-03, PNorm = 36.8647, GNorm = 2.0089, lr_0 = 1.0200e-04
Loss = 1.5208e-03, PNorm = 36.8666, GNorm = 2.6598, lr_0 = 1.0200e-04
Loss = 1.4290e-03, PNorm = 36.8686, GNorm = 1.8096, lr_0 = 1.0200e-04
Loss = 1.4182e-03, PNorm = 36.8709, GNorm = 2.6267, lr_0 = 1.0200e-04
Loss = 1.1883e-03, PNorm = 36.8738, GNorm = 3.0145, lr_0 = 1.0200e-04
Loss = 1.5716e-03, PNorm = 36.8764, GNorm = 2.3326, lr_0 = 1.0200e-04
Loss = 1.3157e-03, PNorm = 36.8775, GNorm = 1.5452, lr_0 = 1.0200e-04
Loss = 1.2914e-03, PNorm = 36.8796, GNorm = 2.1022, lr_0 = 1.0200e-04
Loss = 1.7877e-03, PNorm = 36.8821, GNorm = 2.1251, lr_0 = 1.0200e-04
Loss = 1.6381e-03, PNorm = 36.8841, GNorm = 4.9708, lr_0 = 1.0200e-04
Loss = 1.3012e-03, PNorm = 36.8859, GNorm = 3.2701, lr_0 = 1.0200e-04
Loss = 3.2394e-03, PNorm = 36.8861, GNorm = 2.6322, lr_0 = 1.0200e-04
Validation rmse logD = 0.644608
Validation R2 logD = 0.709395
Validation rmse logP = 0.522521
Validation R2 logP = 0.924841
Epoch 33
Train function
Loss = 1.1409e-03, PNorm = 36.8879, GNorm = 2.3392, lr_0 = 1.0200e-04
Loss = 1.4173e-03, PNorm = 36.8913, GNorm = 3.1878, lr_0 = 1.0200e-04
Loss = 1.4641e-03, PNorm = 36.8928, GNorm = 1.8895, lr_0 = 1.0200e-04
Loss = 1.2396e-03, PNorm = 36.8948, GNorm = 2.4887, lr_0 = 1.0200e-04
Loss = 1.2242e-03, PNorm = 36.8966, GNorm = 1.4862, lr_0 = 1.0200e-04
Loss = 1.3823e-03, PNorm = 36.8989, GNorm = 0.8986, lr_0 = 1.0200e-04
Loss = 1.3360e-03, PNorm = 36.9002, GNorm = 3.7151, lr_0 = 1.0200e-04
Loss = 1.3593e-03, PNorm = 36.9025, GNorm = 1.7842, lr_0 = 1.0200e-04
Loss = 1.2738e-03, PNorm = 36.9051, GNorm = 1.0836, lr_0 = 1.0200e-04
Loss = 1.2930e-03, PNorm = 36.9068, GNorm = 1.5192, lr_0 = 1.0200e-04
Loss = 1.7175e-03, PNorm = 36.9089, GNorm = 2.1976, lr_0 = 1.0200e-04
Loss = 1.3844e-03, PNorm = 36.9115, GNorm = 2.9859, lr_0 = 1.0200e-04
Loss = 1.2791e-03, PNorm = 36.9135, GNorm = 1.9812, lr_0 = 1.0200e-04
Loss = 1.2224e-03, PNorm = 36.9163, GNorm = 1.4996, lr_0 = 1.0200e-04
Loss = 1.4982e-03, PNorm = 36.9182, GNorm = 2.1519, lr_0 = 1.0200e-04
Loss = 1.7015e-03, PNorm = 36.9199, GNorm = 2.1993, lr_0 = 1.0200e-04
Loss = 1.5659e-03, PNorm = 36.9214, GNorm = 3.9065, lr_0 = 1.0200e-04
Loss = 1.3597e-03, PNorm = 36.9226, GNorm = 1.9467, lr_0 = 1.0200e-04
Loss = 1.5823e-03, PNorm = 36.9240, GNorm = 3.3025, lr_0 = 1.0200e-04
Loss = 1.0847e-03, PNorm = 36.9259, GNorm = 3.0269, lr_0 = 1.0200e-04
Loss = 1.5223e-03, PNorm = 36.9279, GNorm = 3.7372, lr_0 = 1.0200e-04
Loss = 1.4912e-03, PNorm = 36.9299, GNorm = 4.5674, lr_0 = 1.0200e-04
Validation rmse logD = 0.651281
Validation R2 logD = 0.703347
Validation rmse logP = 0.505374
Validation R2 logP = 0.929693
Epoch 34
Train function
Loss = 1.3228e-03, PNorm = 36.9314, GNorm = 1.6617, lr_0 = 1.0200e-04
Loss = 1.1637e-03, PNorm = 36.9331, GNorm = 3.6879, lr_0 = 1.0200e-04
Loss = 1.1643e-03, PNorm = 36.9348, GNorm = 1.0008, lr_0 = 1.0200e-04
Loss = 1.7284e-03, PNorm = 36.9372, GNorm = 3.7235, lr_0 = 1.0200e-04
Loss = 1.0705e-03, PNorm = 36.9390, GNorm = 1.3076, lr_0 = 1.0200e-04
Loss = 1.5059e-03, PNorm = 36.9416, GNorm = 3.3745, lr_0 = 1.0200e-04
Loss = 1.3741e-03, PNorm = 36.9441, GNorm = 2.6362, lr_0 = 1.0200e-04
Loss = 1.0056e-03, PNorm = 36.9461, GNorm = 2.8783, lr_0 = 1.0200e-04
Loss = 1.1947e-03, PNorm = 36.9479, GNorm = 3.9009, lr_0 = 1.0200e-04
Loss = 1.2435e-03, PNorm = 36.9509, GNorm = 1.3337, lr_0 = 1.0200e-04
Loss = 1.4295e-03, PNorm = 36.9531, GNorm = 1.9562, lr_0 = 1.0200e-04
Loss = 1.3875e-03, PNorm = 36.9553, GNorm = 6.9650, lr_0 = 1.0200e-04
Loss = 1.2283e-03, PNorm = 36.9566, GNorm = 1.3131, lr_0 = 1.0200e-04
Loss = 1.4238e-03, PNorm = 36.9582, GNorm = 1.1716, lr_0 = 1.0200e-04
Loss = 1.5171e-03, PNorm = 36.9608, GNorm = 3.0739, lr_0 = 1.0200e-04
Loss = 1.4602e-03, PNorm = 36.9640, GNorm = 2.8336, lr_0 = 1.0200e-04
Loss = 1.1660e-03, PNorm = 36.9655, GNorm = 1.2573, lr_0 = 1.0200e-04
Loss = 1.5051e-03, PNorm = 36.9676, GNorm = 1.9474, lr_0 = 1.0200e-04
Loss = 1.9577e-03, PNorm = 36.9697, GNorm = 4.9431, lr_0 = 1.0200e-04
Loss = 1.6885e-03, PNorm = 36.9700, GNorm = 5.9222, lr_0 = 1.0200e-04
Loss = 1.7935e-03, PNorm = 36.9713, GNorm = 2.0128, lr_0 = 1.0200e-04
Loss = 1.7218e-03, PNorm = 36.9730, GNorm = 4.7583, lr_0 = 1.0200e-04
Loss = 1.4130e-03, PNorm = 36.9761, GNorm = 3.0806, lr_0 = 1.0200e-04
Validation rmse logD = 0.641719
Validation R2 logD = 0.711994
Validation rmse logP = 0.501587
Validation R2 logP = 0.930742
Epoch 35
Train function
Loss = 1.3413e-03, PNorm = 36.9789, GNorm = 3.5492, lr_0 = 1.0200e-04
Loss = 1.4569e-03, PNorm = 36.9812, GNorm = 3.4574, lr_0 = 1.0200e-04
Loss = 1.5302e-03, PNorm = 36.9844, GNorm = 4.1223, lr_0 = 1.0200e-04
Loss = 1.5524e-03, PNorm = 36.9876, GNorm = 3.2423, lr_0 = 1.0200e-04
Loss = 1.5585e-03, PNorm = 36.9915, GNorm = 2.0100, lr_0 = 1.0200e-04
Loss = 1.3805e-03, PNorm = 36.9946, GNorm = 2.4115, lr_0 = 1.0200e-04
Loss = 1.6041e-03, PNorm = 36.9966, GNorm = 3.0571, lr_0 = 1.0200e-04
Loss = 1.3641e-03, PNorm = 36.9989, GNorm = 2.9074, lr_0 = 1.0200e-04
Loss = 1.0946e-03, PNorm = 37.0003, GNorm = 2.8374, lr_0 = 1.0200e-04
Loss = 1.1408e-03, PNorm = 37.0030, GNorm = 1.6972, lr_0 = 1.0200e-04
Loss = 1.0149e-03, PNorm = 37.0051, GNorm = 1.5772, lr_0 = 1.0200e-04
Loss = 1.1336e-03, PNorm = 37.0069, GNorm = 1.9013, lr_0 = 1.0200e-04
Loss = 1.1912e-03, PNorm = 37.0075, GNorm = 1.5665, lr_0 = 1.0200e-04
Loss = 1.2620e-03, PNorm = 37.0090, GNorm = 1.7566, lr_0 = 1.0200e-04
Loss = 1.3112e-03, PNorm = 37.0108, GNorm = 1.4270, lr_0 = 1.0200e-04
Loss = 1.1932e-03, PNorm = 37.0128, GNorm = 4.9597, lr_0 = 1.0200e-04
Loss = 1.5390e-03, PNorm = 37.0142, GNorm = 3.6611, lr_0 = 1.0200e-04
Loss = 1.3387e-03, PNorm = 37.0156, GNorm = 2.2832, lr_0 = 1.0200e-04
Loss = 1.5452e-03, PNorm = 37.0175, GNorm = 2.1220, lr_0 = 1.0200e-04
Loss = 1.2900e-03, PNorm = 37.0184, GNorm = 2.3619, lr_0 = 1.0200e-04
Loss = 1.3080e-03, PNorm = 37.0207, GNorm = 2.3705, lr_0 = 1.0200e-04
Loss = 1.4876e-03, PNorm = 37.0228, GNorm = 3.0246, lr_0 = 1.0200e-04
Validation rmse logD = 0.642232
Validation R2 logD = 0.711533
Validation rmse logP = 0.503345
Validation R2 logP = 0.930256
Epoch 36
Train function
Loss = 1.1673e-03, PNorm = 37.0249, GNorm = 2.4233, lr_0 = 1.0200e-04
Loss = 1.1644e-03, PNorm = 37.0275, GNorm = 2.2533, lr_0 = 1.0200e-04
Loss = 1.0767e-03, PNorm = 37.0292, GNorm = 1.2747, lr_0 = 1.0200e-04
Loss = 1.3767e-03, PNorm = 37.0314, GNorm = 1.8953, lr_0 = 1.0200e-04
Loss = 1.2205e-03, PNorm = 37.0334, GNorm = 2.3156, lr_0 = 1.0200e-04
Loss = 1.2567e-03, PNorm = 37.0358, GNorm = 1.6939, lr_0 = 1.0200e-04
Loss = 1.5547e-03, PNorm = 37.0372, GNorm = 5.3235, lr_0 = 1.0200e-04
Loss = 1.5424e-03, PNorm = 37.0387, GNorm = 2.2290, lr_0 = 1.0200e-04
Loss = 1.3208e-03, PNorm = 37.0402, GNorm = 1.2550, lr_0 = 1.0200e-04
Loss = 1.4221e-03, PNorm = 37.0422, GNorm = 0.8404, lr_0 = 1.0200e-04
Loss = 1.1911e-03, PNorm = 37.0451, GNorm = 2.6601, lr_0 = 1.0200e-04
Loss = 1.2461e-03, PNorm = 37.0476, GNorm = 1.4596, lr_0 = 1.0200e-04
Loss = 1.2394e-03, PNorm = 37.0501, GNorm = 1.9456, lr_0 = 1.0200e-04
Loss = 1.2702e-03, PNorm = 37.0514, GNorm = 2.8197, lr_0 = 1.0200e-04
Loss = 1.2330e-03, PNorm = 37.0520, GNorm = 1.6268, lr_0 = 1.0200e-04
Loss = 1.4378e-03, PNorm = 37.0533, GNorm = 5.3878, lr_0 = 1.0200e-04
Loss = 1.4384e-03, PNorm = 37.0557, GNorm = 2.0115, lr_0 = 1.0200e-04
Loss = 1.2904e-03, PNorm = 37.0569, GNorm = 2.3171, lr_0 = 1.0200e-04
Loss = 1.2146e-03, PNorm = 37.0583, GNorm = 1.0746, lr_0 = 1.0200e-04
Loss = 1.2511e-03, PNorm = 37.0615, GNorm = 2.7480, lr_0 = 1.0200e-04
Loss = 1.2190e-03, PNorm = 37.0642, GNorm = 1.8731, lr_0 = 1.0200e-04
Loss = 9.8463e-04, PNorm = 37.0662, GNorm = 1.5739, lr_0 = 1.0200e-04
Loss = 1.2193e-03, PNorm = 37.0668, GNorm = 2.1549, lr_0 = 1.0200e-04
Validation rmse logD = 0.648083
Validation R2 logD = 0.706253
Validation rmse logP = 0.505740
Validation R2 logP = 0.929591
Epoch 37
Train function
Loss = 1.0356e-03, PNorm = 37.0689, GNorm = 1.5439, lr_0 = 1.0200e-04
Loss = 1.2834e-03, PNorm = 37.0708, GNorm = 4.2303, lr_0 = 1.0200e-04
Loss = 1.4362e-03, PNorm = 37.0725, GNorm = 8.6096, lr_0 = 1.0200e-04
Loss = 1.3585e-03, PNorm = 37.0747, GNorm = 2.8802, lr_0 = 1.0200e-04
Loss = 1.3418e-03, PNorm = 37.0773, GNorm = 1.3764, lr_0 = 1.0200e-04
Loss = 1.3506e-03, PNorm = 37.0800, GNorm = 3.0450, lr_0 = 1.0200e-04
Loss = 1.1828e-03, PNorm = 37.0814, GNorm = 1.6710, lr_0 = 1.0200e-04
Loss = 1.2627e-03, PNorm = 37.0828, GNorm = 1.6646, lr_0 = 1.0200e-04
Loss = 1.2705e-03, PNorm = 37.0849, GNorm = 1.7376, lr_0 = 1.0200e-04
Loss = 1.1946e-03, PNorm = 37.0865, GNorm = 1.9174, lr_0 = 1.0200e-04
Loss = 1.0372e-03, PNorm = 37.0889, GNorm = 1.9631, lr_0 = 1.0200e-04
Loss = 1.2821e-03, PNorm = 37.0911, GNorm = 2.1739, lr_0 = 1.0200e-04
Loss = 1.0440e-03, PNorm = 37.0930, GNorm = 4.5211, lr_0 = 1.0200e-04
Loss = 1.3426e-03, PNorm = 37.0952, GNorm = 4.0166, lr_0 = 1.0200e-04
Loss = 1.3975e-03, PNorm = 37.0980, GNorm = 2.7574, lr_0 = 1.0200e-04
Loss = 1.4135e-03, PNorm = 37.1001, GNorm = 6.6110, lr_0 = 1.0200e-04
Loss = 1.4608e-03, PNorm = 37.1014, GNorm = 1.1685, lr_0 = 1.0200e-04
Loss = 9.4808e-04, PNorm = 37.1025, GNorm = 1.7582, lr_0 = 1.0200e-04
Loss = 1.1614e-03, PNorm = 37.1052, GNorm = 2.5200, lr_0 = 1.0200e-04
Loss = 1.0738e-03, PNorm = 37.1075, GNorm = 3.9856, lr_0 = 1.0200e-04
Loss = 9.1664e-04, PNorm = 37.1085, GNorm = 2.9648, lr_0 = 1.0200e-04
Loss = 1.3797e-03, PNorm = 37.1098, GNorm = 3.2724, lr_0 = 1.0200e-04
Validation rmse logD = 0.679179
Validation R2 logD = 0.677388
Validation rmse logP = 0.516036
Validation R2 logP = 0.926695
Epoch 38
Train function
Loss = 1.1740e-03, PNorm = 37.1121, GNorm = 3.0431, lr_0 = 1.0200e-04
Loss = 1.2591e-03, PNorm = 37.1143, GNorm = 2.2811, lr_0 = 1.0200e-04
Loss = 1.0746e-03, PNorm = 37.1171, GNorm = 2.2198, lr_0 = 1.0200e-04
Loss = 1.3608e-03, PNorm = 37.1194, GNorm = 2.3630, lr_0 = 1.0200e-04
Loss = 1.2246e-03, PNorm = 37.1224, GNorm = 0.8144, lr_0 = 1.0200e-04
Loss = 9.7523e-04, PNorm = 37.1245, GNorm = 2.0799, lr_0 = 1.0200e-04
Loss = 1.3437e-03, PNorm = 37.1263, GNorm = 1.9267, lr_0 = 1.0200e-04
Loss = 1.1108e-03, PNorm = 37.1281, GNorm = 3.8416, lr_0 = 1.0200e-04
Loss = 1.1429e-03, PNorm = 37.1290, GNorm = 4.0400, lr_0 = 1.0200e-04
Loss = 1.3738e-03, PNorm = 37.1312, GNorm = 1.8170, lr_0 = 1.0200e-04
Loss = 1.3248e-03, PNorm = 37.1332, GNorm = 3.0528, lr_0 = 1.0200e-04
Loss = 1.3734e-03, PNorm = 37.1353, GNorm = 3.1561, lr_0 = 1.0200e-04
Loss = 1.7145e-03, PNorm = 37.1376, GNorm = 5.0589, lr_0 = 1.0200e-04
Loss = 1.0951e-03, PNorm = 37.1388, GNorm = 1.0693, lr_0 = 1.0200e-04
Loss = 1.0475e-03, PNorm = 37.1409, GNorm = 1.9254, lr_0 = 1.0200e-04
Loss = 1.1298e-03, PNorm = 37.1428, GNorm = 1.5143, lr_0 = 1.0200e-04
Loss = 9.8285e-04, PNorm = 37.1437, GNorm = 2.6656, lr_0 = 1.0200e-04
Loss = 1.1223e-03, PNorm = 37.1450, GNorm = 4.3839, lr_0 = 1.0200e-04
Loss = 1.3303e-03, PNorm = 37.1468, GNorm = 1.0019, lr_0 = 1.0200e-04
Loss = 1.1569e-03, PNorm = 37.1491, GNorm = 1.9057, lr_0 = 1.0200e-04
Loss = 1.3416e-03, PNorm = 37.1513, GNorm = 4.7006, lr_0 = 1.0200e-04
Loss = 1.3385e-03, PNorm = 37.1539, GNorm = 4.1912, lr_0 = 1.0200e-04
Loss = 1.1166e-03, PNorm = 37.1558, GNorm = 1.6217, lr_0 = 1.0200e-04
Validation rmse logD = 0.633964
Validation R2 logD = 0.718912
Validation rmse logP = 0.500308
Validation R2 logP = 0.931095
Epoch 39
Train function
Loss = 1.5899e-03, PNorm = 37.1580, GNorm = 1.5550, lr_0 = 1.0200e-04
Loss = 1.1884e-03, PNorm = 37.1606, GNorm = 1.4662, lr_0 = 1.0200e-04
Loss = 1.1873e-03, PNorm = 37.1621, GNorm = 3.0993, lr_0 = 1.0200e-04
Loss = 1.2966e-03, PNorm = 37.1642, GNorm = 1.9589, lr_0 = 1.0200e-04
Loss = 1.2113e-03, PNorm = 37.1664, GNorm = 3.6246, lr_0 = 1.0200e-04
Loss = 1.2584e-03, PNorm = 37.1692, GNorm = 1.8921, lr_0 = 1.0200e-04
Loss = 1.1709e-03, PNorm = 37.1714, GNorm = 2.1727, lr_0 = 1.0200e-04
Loss = 1.3704e-03, PNorm = 37.1736, GNorm = 1.9710, lr_0 = 1.0200e-04
Loss = 1.2010e-03, PNorm = 37.1749, GNorm = 3.3641, lr_0 = 1.0200e-04
Loss = 1.0427e-03, PNorm = 37.1766, GNorm = 2.4739, lr_0 = 1.0200e-04
Loss = 9.9561e-04, PNorm = 37.1786, GNorm = 1.8282, lr_0 = 1.0200e-04
Loss = 1.2953e-03, PNorm = 37.1800, GNorm = 2.3388, lr_0 = 1.0200e-04
Loss = 1.1449e-03, PNorm = 37.1824, GNorm = 3.0188, lr_0 = 1.0200e-04
Loss = 1.5489e-03, PNorm = 37.1847, GNorm = 3.0993, lr_0 = 1.0200e-04
Loss = 1.2969e-03, PNorm = 37.1872, GNorm = 6.3469, lr_0 = 1.0200e-04
Loss = 1.2631e-03, PNorm = 37.1893, GNorm = 1.4996, lr_0 = 1.0200e-04
Loss = 1.1564e-03, PNorm = 37.1909, GNorm = 4.0356, lr_0 = 1.0200e-04
Loss = 1.2509e-03, PNorm = 37.1929, GNorm = 2.8596, lr_0 = 1.0200e-04
Loss = 1.1402e-03, PNorm = 37.1947, GNorm = 1.8883, lr_0 = 1.0200e-04
Loss = 1.3155e-03, PNorm = 37.1966, GNorm = 1.9625, lr_0 = 1.0200e-04
Loss = 1.2742e-03, PNorm = 37.1979, GNorm = 2.7103, lr_0 = 1.0200e-04
Loss = 1.2134e-03, PNorm = 37.1997, GNorm = 1.8299, lr_0 = 1.0200e-04
Validation rmse logD = 0.634360
Validation R2 logD = 0.718561
Validation rmse logP = 0.496044
Validation R2 logP = 0.932265
Epoch 40
Train function
Loss = 1.3161e-03, PNorm = 37.2026, GNorm = 2.4971, lr_0 = 1.0200e-04
Loss = 9.8886e-04, PNorm = 37.2047, GNorm = 2.1053, lr_0 = 1.0200e-04
Loss = 1.0959e-03, PNorm = 37.2066, GNorm = 2.1507, lr_0 = 1.0200e-04
Loss = 1.0834e-03, PNorm = 37.2085, GNorm = 3.2220, lr_0 = 1.0200e-04
Loss = 8.3081e-04, PNorm = 37.2102, GNorm = 3.1933, lr_0 = 1.0200e-04
Loss = 1.2149e-03, PNorm = 37.2119, GNorm = 3.3535, lr_0 = 1.0200e-04
Loss = 1.0761e-03, PNorm = 37.2135, GNorm = 2.2593, lr_0 = 1.0200e-04
Loss = 9.6594e-04, PNorm = 37.2152, GNorm = 2.8401, lr_0 = 1.0200e-04
Loss = 1.3138e-03, PNorm = 37.2168, GNorm = 3.1230, lr_0 = 1.0200e-04
Loss = 1.2900e-03, PNorm = 37.2190, GNorm = 3.6444, lr_0 = 1.0200e-04
Loss = 1.1114e-03, PNorm = 37.2209, GNorm = 3.5076, lr_0 = 1.0200e-04
Loss = 1.1763e-03, PNorm = 37.2229, GNorm = 2.5637, lr_0 = 1.0200e-04
Loss = 1.1287e-03, PNorm = 37.2252, GNorm = 2.1766, lr_0 = 1.0200e-04
Loss = 1.2365e-03, PNorm = 37.2278, GNorm = 3.4996, lr_0 = 1.0200e-04
Loss = 1.1714e-03, PNorm = 37.2301, GNorm = 2.3301, lr_0 = 1.0200e-04
Loss = 1.3614e-03, PNorm = 37.2318, GNorm = 1.8871, lr_0 = 1.0200e-04
Loss = 1.0405e-03, PNorm = 37.2331, GNorm = 2.4723, lr_0 = 1.0200e-04
Loss = 1.1570e-03, PNorm = 37.2341, GNorm = 5.3709, lr_0 = 1.0200e-04
Loss = 1.1015e-03, PNorm = 37.2363, GNorm = 1.8216, lr_0 = 1.0200e-04
Loss = 1.2236e-03, PNorm = 37.2385, GNorm = 2.1092, lr_0 = 1.0200e-04
Loss = 1.1228e-03, PNorm = 37.2400, GNorm = 0.9933, lr_0 = 1.0200e-04
Loss = 1.0700e-03, PNorm = 37.2419, GNorm = 3.8251, lr_0 = 1.0200e-04
Loss = 1.2122e-03, PNorm = 37.2444, GNorm = 1.7706, lr_0 = 1.0200e-04
Validation rmse logD = 0.649254
Validation R2 logD = 0.705190
Validation rmse logP = 0.495434
Validation R2 logP = 0.932431
Epoch 41
Train function
Loss = 1.0827e-03, PNorm = 37.2467, GNorm = 1.6987, lr_0 = 1.0200e-04
Loss = 9.4041e-04, PNorm = 37.2481, GNorm = 1.8505, lr_0 = 1.0200e-04
Loss = 9.7538e-04, PNorm = 37.2500, GNorm = 1.4639, lr_0 = 1.0200e-04
Loss = 9.4206e-04, PNorm = 37.2512, GNorm = 0.7634, lr_0 = 1.0200e-04
Loss = 1.2034e-03, PNorm = 37.2536, GNorm = 1.1558, lr_0 = 1.0200e-04
Loss = 1.1183e-03, PNorm = 37.2551, GNorm = 1.6145, lr_0 = 1.0200e-04
Loss = 1.1007e-03, PNorm = 37.2567, GNorm = 2.2205, lr_0 = 1.0200e-04
Loss = 9.4544e-04, PNorm = 37.2583, GNorm = 1.2001, lr_0 = 1.0200e-04
Loss = 1.2483e-03, PNorm = 37.2603, GNorm = 4.0068, lr_0 = 1.0200e-04
Loss = 1.0595e-03, PNorm = 37.2619, GNorm = 2.2132, lr_0 = 1.0200e-04
Loss = 1.4218e-03, PNorm = 37.2641, GNorm = 1.2098, lr_0 = 1.0200e-04
Loss = 1.2625e-03, PNorm = 37.2672, GNorm = 2.1024, lr_0 = 1.0200e-04
Loss = 1.2412e-03, PNorm = 37.2695, GNorm = 2.5454, lr_0 = 1.0200e-04
Loss = 1.0901e-03, PNorm = 37.2716, GNorm = 2.4999, lr_0 = 1.0200e-04
Loss = 1.0932e-03, PNorm = 37.2732, GNorm = 3.8388, lr_0 = 1.0200e-04
Loss = 9.6191e-04, PNorm = 37.2749, GNorm = 2.5159, lr_0 = 1.0200e-04
Loss = 9.7194e-04, PNorm = 37.2755, GNorm = 2.4369, lr_0 = 1.0200e-04
Loss = 1.1945e-03, PNorm = 37.2772, GNorm = 1.7702, lr_0 = 1.0200e-04
Loss = 1.1822e-03, PNorm = 37.2786, GNorm = 2.1578, lr_0 = 1.0200e-04
Loss = 1.0749e-03, PNorm = 37.2812, GNorm = 2.6061, lr_0 = 1.0200e-04
Loss = 1.2300e-03, PNorm = 37.2833, GNorm = 1.3746, lr_0 = 1.0200e-04
Loss = 9.3204e-04, PNorm = 37.2852, GNorm = 1.6394, lr_0 = 1.0200e-04
Loss = 1.1839e-03, PNorm = 37.2877, GNorm = 2.7732, lr_0 = 1.0200e-04
Validation rmse logD = 0.652171
Validation R2 logD = 0.702536
Validation rmse logP = 0.526782
Validation R2 logP = 0.923610
Epoch 42
Train function
Loss = 1.2349e-03, PNorm = 37.2890, GNorm = 2.0514, lr_0 = 1.0200e-04
Loss = 1.2406e-03, PNorm = 37.2906, GNorm = 2.8352, lr_0 = 1.0200e-04
Loss = 1.1744e-03, PNorm = 37.2932, GNorm = 1.9676, lr_0 = 1.0200e-04
Loss = 9.8051e-04, PNorm = 37.2941, GNorm = 1.5438, lr_0 = 1.0200e-04
Loss = 1.1401e-03, PNorm = 37.2949, GNorm = 1.4774, lr_0 = 1.0200e-04
Loss = 1.0926e-03, PNorm = 37.2977, GNorm = 2.3736, lr_0 = 1.0200e-04
Loss = 9.7779e-04, PNorm = 37.2994, GNorm = 2.4557, lr_0 = 1.0200e-04
Loss = 1.0362e-03, PNorm = 37.3016, GNorm = 2.5701, lr_0 = 1.0200e-04
Loss = 1.1950e-03, PNorm = 37.3030, GNorm = 3.8270, lr_0 = 1.0200e-04
Loss = 9.5296e-04, PNorm = 37.3043, GNorm = 2.2806, lr_0 = 1.0200e-04
Loss = 1.1469e-03, PNorm = 37.3069, GNorm = 2.4239, lr_0 = 1.0200e-04
Loss = 1.2753e-03, PNorm = 37.3074, GNorm = 2.3584, lr_0 = 1.0200e-04
Loss = 1.1454e-03, PNorm = 37.3090, GNorm = 3.8435, lr_0 = 1.0200e-04
Loss = 1.2129e-03, PNorm = 37.3113, GNorm = 5.1559, lr_0 = 1.0200e-04
Loss = 1.0285e-03, PNorm = 37.3148, GNorm = 5.7918, lr_0 = 1.0200e-04
Loss = 1.3915e-03, PNorm = 37.3169, GNorm = 4.1867, lr_0 = 1.0200e-04
Loss = 1.2838e-03, PNorm = 37.3189, GNorm = 6.2065, lr_0 = 1.0200e-04
Loss = 1.4663e-03, PNorm = 37.3218, GNorm = 4.3559, lr_0 = 1.0200e-04
Loss = 1.3609e-03, PNorm = 37.3232, GNorm = 1.7182, lr_0 = 1.0200e-04
Loss = 1.3505e-03, PNorm = 37.3251, GNorm = 5.1460, lr_0 = 1.0200e-04
Loss = 1.2201e-03, PNorm = 37.3273, GNorm = 2.0049, lr_0 = 1.0200e-04
Loss = 1.0719e-03, PNorm = 37.3311, GNorm = 2.7908, lr_0 = 1.0200e-04
Validation rmse logD = 0.626370
Validation R2 logD = 0.725607
Validation rmse logP = 0.515820
Validation R2 logP = 0.926756
Epoch 43
Train function
Loss = 7.7827e-04, PNorm = 37.3339, GNorm = 1.8548, lr_0 = 1.0200e-04
Loss = 1.2788e-03, PNorm = 37.3359, GNorm = 2.0820, lr_0 = 1.0200e-04
Loss = 8.8013e-04, PNorm = 37.3371, GNorm = 1.0952, lr_0 = 1.0200e-04
Loss = 9.3834e-04, PNorm = 37.3390, GNorm = 2.2374, lr_0 = 1.0200e-04
Loss = 1.2960e-03, PNorm = 37.3411, GNorm = 3.4515, lr_0 = 1.0200e-04
Loss = 1.1711e-03, PNorm = 37.3433, GNorm = 2.1452, lr_0 = 1.0200e-04
Loss = 1.4495e-03, PNorm = 37.3453, GNorm = 3.5740, lr_0 = 1.0200e-04
Loss = 9.7057e-04, PNorm = 37.3471, GNorm = 1.1356, lr_0 = 1.0200e-04
Loss = 8.4000e-04, PNorm = 37.3492, GNorm = 2.3413, lr_0 = 1.0200e-04
Loss = 1.1126e-03, PNorm = 37.3510, GNorm = 3.1712, lr_0 = 1.0200e-04
Loss = 9.3388e-04, PNorm = 37.3533, GNorm = 2.8143, lr_0 = 1.0200e-04
Loss = 1.0173e-03, PNorm = 37.3538, GNorm = 1.6684, lr_0 = 1.0200e-04
Loss = 1.1508e-03, PNorm = 37.3549, GNorm = 1.4875, lr_0 = 1.0200e-04
Loss = 1.0286e-03, PNorm = 37.3568, GNorm = 2.5362, lr_0 = 1.0200e-04
Loss = 8.8933e-04, PNorm = 37.3600, GNorm = 2.2083, lr_0 = 1.0200e-04
Loss = 9.9593e-04, PNorm = 37.3624, GNorm = 2.7892, lr_0 = 1.0200e-04
Loss = 1.0272e-03, PNorm = 37.3647, GNorm = 3.1437, lr_0 = 1.0200e-04
Loss = 1.0932e-03, PNorm = 37.3666, GNorm = 4.4428, lr_0 = 1.0200e-04
Loss = 1.0427e-03, PNorm = 37.3683, GNorm = 3.0099, lr_0 = 1.0200e-04
Loss = 9.3520e-04, PNorm = 37.3699, GNorm = 1.4209, lr_0 = 1.0200e-04
Loss = 1.2086e-03, PNorm = 37.3721, GNorm = 3.5396, lr_0 = 1.0200e-04
Loss = 1.1350e-03, PNorm = 37.3732, GNorm = 2.2630, lr_0 = 1.0200e-04
Loss = 1.2365e-03, PNorm = 37.3743, GNorm = 1.2217, lr_0 = 1.0200e-04
Validation rmse logD = 0.639255
Validation R2 logD = 0.714201
Validation rmse logP = 0.491150
Validation R2 logP = 0.933595
Epoch 44
Train function
Loss = 1.0372e-03, PNorm = 37.3756, GNorm = 1.0601, lr_0 = 1.0200e-04
Loss = 8.8340e-04, PNorm = 37.3772, GNorm = 1.9137, lr_0 = 1.0200e-04
Loss = 1.2317e-03, PNorm = 37.3787, GNorm = 6.6464, lr_0 = 1.0200e-04
Loss = 1.2302e-03, PNorm = 37.3798, GNorm = 5.8876, lr_0 = 1.0200e-04
Loss = 1.1701e-03, PNorm = 37.3823, GNorm = 1.3714, lr_0 = 1.0200e-04
Loss = 1.1261e-03, PNorm = 37.3854, GNorm = 2.0908, lr_0 = 1.0200e-04
Loss = 8.7130e-04, PNorm = 37.3888, GNorm = 2.6076, lr_0 = 1.0200e-04
Loss = 1.1855e-03, PNorm = 37.3918, GNorm = 1.5185, lr_0 = 1.0200e-04
Loss = 1.1924e-03, PNorm = 37.3928, GNorm = 2.9499, lr_0 = 1.0200e-04
Loss = 1.2699e-03, PNorm = 37.3948, GNorm = 1.5650, lr_0 = 1.0200e-04
Loss = 9.2460e-04, PNorm = 37.3962, GNorm = 1.2073, lr_0 = 1.0200e-04
Loss = 1.1226e-03, PNorm = 37.3982, GNorm = 3.4749, lr_0 = 1.0200e-04
Loss = 1.0177e-03, PNorm = 37.4006, GNorm = 2.1845, lr_0 = 1.0200e-04
Loss = 1.0895e-03, PNorm = 37.4030, GNorm = 1.8813, lr_0 = 1.0200e-04
Loss = 1.0697e-03, PNorm = 37.4053, GNorm = 7.4313, lr_0 = 1.0200e-04
Loss = 1.2169e-03, PNorm = 37.4076, GNorm = 1.5178, lr_0 = 1.0200e-04
Loss = 9.1208e-04, PNorm = 37.4087, GNorm = 2.2381, lr_0 = 1.0200e-04
Loss = 1.0548e-03, PNorm = 37.4092, GNorm = 1.1815, lr_0 = 1.0200e-04
Loss = 8.0167e-04, PNorm = 37.4109, GNorm = 1.4553, lr_0 = 1.0200e-04
Loss = 1.0220e-03, PNorm = 37.4123, GNorm = 3.4298, lr_0 = 1.0200e-04
Loss = 1.2239e-03, PNorm = 37.4134, GNorm = 1.2270, lr_0 = 1.0200e-04
Loss = 1.0106e-03, PNorm = 37.4150, GNorm = 3.1129, lr_0 = 1.0200e-04
Validation rmse logD = 0.626563
Validation R2 logD = 0.725437
Validation rmse logP = 0.518536
Validation R2 logP = 0.925983
Epoch 45
Train function
Loss = 8.7004e-04, PNorm = 37.4167, GNorm = 1.2736, lr_0 = 1.0200e-04
Loss = 9.7012e-04, PNorm = 37.4180, GNorm = 1.8107, lr_0 = 1.0200e-04
Loss = 1.0843e-03, PNorm = 37.4191, GNorm = 2.4509, lr_0 = 1.0200e-04
Loss = 1.0031e-03, PNorm = 37.4199, GNorm = 2.8836, lr_0 = 1.0200e-04
Loss = 1.1660e-03, PNorm = 37.4218, GNorm = 3.7506, lr_0 = 1.0200e-04
Loss = 1.0686e-03, PNorm = 37.4239, GNorm = 2.9858, lr_0 = 1.0200e-04
Loss = 8.6022e-04, PNorm = 37.4271, GNorm = 1.6945, lr_0 = 1.0200e-04
Loss = 1.0179e-03, PNorm = 37.4290, GNorm = 2.7482, lr_0 = 1.0200e-04
Loss = 9.4533e-04, PNorm = 37.4310, GNorm = 1.1135, lr_0 = 1.0200e-04
Loss = 9.2111e-04, PNorm = 37.4327, GNorm = 1.3147, lr_0 = 1.0200e-04
Loss = 8.5564e-04, PNorm = 37.4339, GNorm = 1.3536, lr_0 = 1.0200e-04
Loss = 9.3425e-04, PNorm = 37.4351, GNorm = 2.1197, lr_0 = 1.0200e-04
Loss = 1.2344e-03, PNorm = 37.4361, GNorm = 2.4149, lr_0 = 1.0200e-04
Loss = 1.2947e-03, PNorm = 37.4381, GNorm = 1.7862, lr_0 = 1.0200e-04
Loss = 1.1145e-03, PNorm = 37.4398, GNorm = 2.7866, lr_0 = 1.0200e-04
Loss = 8.2778e-04, PNorm = 37.4419, GNorm = 1.5868, lr_0 = 1.0200e-04
Loss = 1.2207e-03, PNorm = 37.4457, GNorm = 2.6887, lr_0 = 1.0200e-04
Loss = 9.5637e-04, PNorm = 37.4474, GNorm = 1.3535, lr_0 = 1.0200e-04
Loss = 1.0707e-03, PNorm = 37.4492, GNorm = 3.1231, lr_0 = 1.0200e-04
Loss = 9.9446e-04, PNorm = 37.4504, GNorm = 2.5542, lr_0 = 1.0200e-04
Loss = 1.2288e-03, PNorm = 37.4519, GNorm = 2.1211, lr_0 = 1.0200e-04
Loss = 1.0140e-03, PNorm = 37.4539, GNorm = 2.2036, lr_0 = 1.0200e-04
Loss = 8.6704e-04, PNorm = 37.4554, GNorm = 2.9774, lr_0 = 1.0200e-04
Validation rmse logD = 0.652826
Validation R2 logD = 0.701938
Validation rmse logP = 0.526502
Validation R2 logP = 0.923691
Epoch 46
Train function
Loss = 1.1094e-03, PNorm = 37.4584, GNorm = 1.8196, lr_0 = 1.0200e-04
Loss = 9.8092e-04, PNorm = 37.4605, GNorm = 1.8233, lr_0 = 1.0200e-04
Loss = 1.0200e-03, PNorm = 37.4624, GNorm = 1.6661, lr_0 = 1.0200e-04
Loss = 9.8481e-04, PNorm = 37.4649, GNorm = 3.2740, lr_0 = 1.0200e-04
Loss = 8.4480e-04, PNorm = 37.4672, GNorm = 3.1845, lr_0 = 1.0200e-04
Loss = 9.4822e-04, PNorm = 37.4692, GNorm = 1.7140, lr_0 = 1.0200e-04
Loss = 9.6452e-04, PNorm = 37.4710, GNorm = 1.8316, lr_0 = 1.0200e-04
Loss = 9.7460e-04, PNorm = 37.4725, GNorm = 2.0518, lr_0 = 1.0200e-04
Loss = 8.6582e-04, PNorm = 37.4741, GNorm = 1.2270, lr_0 = 1.0200e-04
Loss = 1.1048e-03, PNorm = 37.4749, GNorm = 3.1702, lr_0 = 1.0200e-04
Loss = 8.7315e-04, PNorm = 37.4767, GNorm = 1.7522, lr_0 = 1.0200e-04
Loss = 9.5004e-04, PNorm = 37.4785, GNorm = 3.5223, lr_0 = 1.0200e-04
Loss = 1.0229e-03, PNorm = 37.4802, GNorm = 4.3792, lr_0 = 1.0200e-04
Loss = 9.2831e-04, PNorm = 37.4818, GNorm = 2.4757, lr_0 = 1.0200e-04
Loss = 1.1098e-03, PNorm = 37.4835, GNorm = 1.1229, lr_0 = 1.0200e-04
Loss = 8.5861e-04, PNorm = 37.4853, GNorm = 1.8702, lr_0 = 1.0200e-04
Loss = 1.0873e-03, PNorm = 37.4867, GNorm = 1.6446, lr_0 = 1.0200e-04
Loss = 1.0015e-03, PNorm = 37.4879, GNorm = 2.2257, lr_0 = 1.0200e-04
Loss = 9.2416e-04, PNorm = 37.4900, GNorm = 1.8784, lr_0 = 1.0200e-04
Loss = 8.7832e-04, PNorm = 37.4921, GNorm = 1.8115, lr_0 = 1.0200e-04
Loss = 1.0494e-03, PNorm = 37.4928, GNorm = 2.4169, lr_0 = 1.0200e-04
Loss = 8.7762e-04, PNorm = 37.4944, GNorm = 2.2260, lr_0 = 1.0200e-04
Validation rmse logD = 0.646021
Validation R2 logD = 0.708119
Validation rmse logP = 0.518579
Validation R2 logP = 0.925971
Epoch 47
Train function
Loss = 1.3245e-03, PNorm = 37.4969, GNorm = 6.2220, lr_0 = 1.0200e-04
Loss = 1.2095e-03, PNorm = 37.4990, GNorm = 1.3171, lr_0 = 1.0200e-04
Loss = 9.5511e-04, PNorm = 37.5010, GNorm = 2.8054, lr_0 = 1.0200e-04
Loss = 1.1397e-03, PNorm = 37.5024, GNorm = 0.9374, lr_0 = 1.0200e-04
Loss = 9.7681e-04, PNorm = 37.5049, GNorm = 1.0884, lr_0 = 1.0200e-04
Loss = 1.0250e-03, PNorm = 37.5067, GNorm = 1.6871, lr_0 = 1.0200e-04
Loss = 1.1974e-03, PNorm = 37.5095, GNorm = 3.0829, lr_0 = 1.0200e-04
Loss = 9.5997e-04, PNorm = 37.5115, GNorm = 1.7575, lr_0 = 1.0200e-04
Loss = 8.3458e-04, PNorm = 37.5141, GNorm = 2.4894, lr_0 = 1.0200e-04
Loss = 7.6393e-04, PNorm = 37.5163, GNorm = 1.2911, lr_0 = 1.0200e-04
Loss = 1.0349e-03, PNorm = 37.5179, GNorm = 2.9125, lr_0 = 1.0200e-04
Loss = 9.0155e-04, PNorm = 37.5185, GNorm = 1.6960, lr_0 = 1.0200e-04
Loss = 7.5768e-04, PNorm = 37.5208, GNorm = 2.9969, lr_0 = 1.0200e-04
Loss = 8.7543e-04, PNorm = 37.5226, GNorm = 1.3073, lr_0 = 1.0200e-04
Loss = 8.8752e-04, PNorm = 37.5236, GNorm = 1.0691, lr_0 = 1.0200e-04
Loss = 1.0022e-03, PNorm = 37.5254, GNorm = 1.9467, lr_0 = 1.0200e-04
Loss = 9.0192e-04, PNorm = 37.5274, GNorm = 2.0960, lr_0 = 1.0200e-04
Loss = 9.4285e-04, PNorm = 37.5295, GNorm = 1.6804, lr_0 = 1.0200e-04
Loss = 8.6811e-04, PNorm = 37.5317, GNorm = 1.5612, lr_0 = 1.0200e-04
Loss = 9.6456e-04, PNorm = 37.5328, GNorm = 1.8067, lr_0 = 1.0200e-04
Loss = 9.5522e-04, PNorm = 37.5333, GNorm = 4.4398, lr_0 = 1.0200e-04
Loss = 1.0344e-03, PNorm = 37.5351, GNorm = 3.5255, lr_0 = 1.0200e-04
Loss = 1.0298e-03, PNorm = 37.5374, GNorm = 1.3855, lr_0 = 1.0200e-04
Validation rmse logD = 0.628054
Validation R2 logD = 0.724129
Validation rmse logP = 0.489161
Validation R2 logP = 0.934132
Epoch 48
Train function
Loss = 8.1024e-04, PNorm = 37.5396, GNorm = 1.1138, lr_0 = 1.0200e-04
Loss = 8.4587e-04, PNorm = 37.5416, GNorm = 2.6628, lr_0 = 1.0200e-04
Loss = 1.0327e-03, PNorm = 37.5436, GNorm = 1.8584, lr_0 = 1.0200e-04
Loss = 8.8445e-04, PNorm = 37.5452, GNorm = 2.9128, lr_0 = 1.0200e-04
Loss = 9.6238e-04, PNorm = 37.5477, GNorm = 1.5810, lr_0 = 1.0200e-04
Loss = 9.8503e-04, PNorm = 37.5498, GNorm = 1.7091, lr_0 = 1.0200e-04
Loss = 9.4104e-04, PNorm = 37.5515, GNorm = 2.2930, lr_0 = 1.0200e-04
Loss = 1.0803e-03, PNorm = 37.5536, GNorm = 2.7478, lr_0 = 1.0200e-04
Loss = 7.0041e-04, PNorm = 37.5549, GNorm = 1.3838, lr_0 = 1.0200e-04
Loss = 8.6842e-04, PNorm = 37.5564, GNorm = 2.4987, lr_0 = 1.0200e-04
Loss = 9.6451e-04, PNorm = 37.5580, GNorm = 2.9129, lr_0 = 1.0200e-04
Loss = 8.6398e-04, PNorm = 37.5600, GNorm = 1.4200, lr_0 = 1.0200e-04
Loss = 1.2523e-03, PNorm = 37.5614, GNorm = 1.7581, lr_0 = 1.0200e-04
Loss = 1.1688e-03, PNorm = 37.5635, GNorm = 3.6679, lr_0 = 1.0200e-04
Loss = 9.8483e-04, PNorm = 37.5646, GNorm = 2.6566, lr_0 = 1.0200e-04
Loss = 1.0951e-03, PNorm = 37.5662, GNorm = 4.5110, lr_0 = 1.0200e-04
Loss = 1.0050e-03, PNorm = 37.5671, GNorm = 1.4602, lr_0 = 1.0200e-04
Loss = 8.8336e-04, PNorm = 37.5691, GNorm = 3.7769, lr_0 = 1.0200e-04
Loss = 9.6862e-04, PNorm = 37.5716, GNorm = 1.2701, lr_0 = 1.0200e-04
Loss = 8.1281e-04, PNorm = 37.5737, GNorm = 1.7567, lr_0 = 1.0200e-04
Loss = 9.9733e-04, PNorm = 37.5762, GNorm = 1.9349, lr_0 = 1.0200e-04
Loss = 1.1665e-03, PNorm = 37.5773, GNorm = 4.1087, lr_0 = 1.0200e-04
Validation rmse logD = 0.699628
Validation R2 logD = 0.657669
Validation rmse logP = 0.498840
Validation R2 logP = 0.931499
Epoch 49
Train function
Loss = 1.4999e-03, PNorm = 37.5794, GNorm = 2.7644, lr_0 = 1.0200e-04
Loss = 1.3436e-03, PNorm = 37.5811, GNorm = 3.2747, lr_0 = 1.0200e-04
Loss = 8.0622e-04, PNorm = 37.5825, GNorm = 1.5480, lr_0 = 1.0200e-04
Loss = 8.5578e-04, PNorm = 37.5842, GNorm = 1.2299, lr_0 = 1.0200e-04
Loss = 7.9521e-04, PNorm = 37.5861, GNorm = 1.2545, lr_0 = 1.0200e-04
Loss = 7.5559e-04, PNorm = 37.5878, GNorm = 2.6535, lr_0 = 1.0200e-04
Loss = 9.1620e-04, PNorm = 37.5895, GNorm = 2.1241, lr_0 = 1.0200e-04
Loss = 1.1808e-03, PNorm = 37.5902, GNorm = 2.4003, lr_0 = 1.0200e-04
Loss = 9.7600e-04, PNorm = 37.5924, GNorm = 2.4964, lr_0 = 1.0200e-04
Loss = 1.0150e-03, PNorm = 37.5948, GNorm = 1.6758, lr_0 = 1.0200e-04
Loss = 9.8645e-04, PNorm = 37.5967, GNorm = 1.1897, lr_0 = 1.0200e-04
Loss = 7.9106e-04, PNorm = 37.5982, GNorm = 1.6438, lr_0 = 1.0200e-04
Loss = 9.2081e-04, PNorm = 37.6000, GNorm = 1.3245, lr_0 = 1.0200e-04
Loss = 8.6018e-04, PNorm = 37.6008, GNorm = 0.8951, lr_0 = 1.0200e-04
Loss = 8.9408e-04, PNorm = 37.6026, GNorm = 3.6099, lr_0 = 1.0200e-04
Loss = 1.0396e-03, PNorm = 37.6044, GNorm = 4.1819, lr_0 = 1.0200e-04
Loss = 1.0387e-03, PNorm = 37.6069, GNorm = 2.5162, lr_0 = 1.0200e-04
Loss = 1.0403e-03, PNorm = 37.6085, GNorm = 1.8721, lr_0 = 1.0200e-04
Loss = 8.9023e-04, PNorm = 37.6104, GNorm = 1.7759, lr_0 = 1.0200e-04
Loss = 6.7816e-04, PNorm = 37.6118, GNorm = 1.9605, lr_0 = 1.0200e-04
Loss = 7.9011e-04, PNorm = 37.6141, GNorm = 3.1859, lr_0 = 1.0200e-04
Loss = 1.1489e-03, PNorm = 37.6169, GNorm = 2.2189, lr_0 = 1.0200e-04
Loss = 1.2616e-03, PNorm = 37.6201, GNorm = 5.0168, lr_0 = 1.0200e-04
Validation rmse logD = 0.621076
Validation R2 logD = 0.730225
Validation rmse logP = 0.486104
Validation R2 logP = 0.934952
Epoch 50
Train function
Loss = 1.1826e-03, PNorm = 37.6218, GNorm = 3.7416, lr_0 = 1.0200e-04
Loss = 1.0990e-03, PNorm = 37.6237, GNorm = 2.5200, lr_0 = 1.0200e-04
Loss = 1.1280e-03, PNorm = 37.6255, GNorm = 2.1436, lr_0 = 1.0200e-04
Loss = 1.1440e-03, PNorm = 37.6277, GNorm = 4.5288, lr_0 = 1.0200e-04
Loss = 7.8962e-04, PNorm = 37.6301, GNorm = 1.3139, lr_0 = 1.0200e-04
Loss = 8.5285e-04, PNorm = 37.6326, GNorm = 0.9745, lr_0 = 1.0200e-04
Loss = 8.6624e-04, PNorm = 37.6343, GNorm = 1.7135, lr_0 = 1.0200e-04
Loss = 8.6340e-04, PNorm = 37.6359, GNorm = 2.3811, lr_0 = 1.0200e-04
Loss = 8.1029e-04, PNorm = 37.6376, GNorm = 2.0023, lr_0 = 1.0200e-04
Loss = 9.3460e-04, PNorm = 37.6395, GNorm = 1.8744, lr_0 = 1.0200e-04
Loss = 8.1813e-04, PNorm = 37.6426, GNorm = 1.5666, lr_0 = 1.0200e-04
Loss = 7.8886e-04, PNorm = 37.6454, GNorm = 2.2329, lr_0 = 1.0200e-04
Loss = 8.0213e-04, PNorm = 37.6466, GNorm = 0.8610, lr_0 = 1.0200e-04
Loss = 8.9331e-04, PNorm = 37.6476, GNorm = 1.1362, lr_0 = 1.0200e-04
Loss = 8.7246e-04, PNorm = 37.6485, GNorm = 1.9253, lr_0 = 1.0200e-04
Loss = 7.6925e-04, PNorm = 37.6497, GNorm = 1.5904, lr_0 = 1.0200e-04
Loss = 9.2763e-04, PNorm = 37.6510, GNorm = 3.1797, lr_0 = 1.0200e-04
Loss = 8.6854e-04, PNorm = 37.6518, GNorm = 1.5435, lr_0 = 1.0200e-04
Loss = 1.0813e-03, PNorm = 37.6535, GNorm = 2.0794, lr_0 = 1.0200e-04
Loss = 8.2368e-04, PNorm = 37.6563, GNorm = 1.2838, lr_0 = 1.0200e-04
Loss = 1.0217e-03, PNorm = 37.6581, GNorm = 2.5568, lr_0 = 1.0200e-04
Loss = 8.0339e-04, PNorm = 37.6594, GNorm = 2.5504, lr_0 = 1.0200e-04
Validation rmse logD = 0.621747
Validation R2 logD = 0.729641
Validation rmse logP = 0.494326
Validation R2 logP = 0.932733
Epoch 51
Train function
Loss = 1.4416e-03, PNorm = 37.6614, GNorm = 2.5164, lr_0 = 1.0200e-04
Loss = 7.2152e-04, PNorm = 37.6635, GNorm = 2.8935, lr_0 = 1.0200e-04
Loss = 6.8692e-04, PNorm = 37.6654, GNorm = 3.5285, lr_0 = 1.0200e-04
Loss = 9.4922e-04, PNorm = 37.6676, GNorm = 2.6998, lr_0 = 1.0200e-04
Loss = 7.1682e-04, PNorm = 37.6696, GNorm = 1.6179, lr_0 = 1.0200e-04
Loss = 8.4796e-04, PNorm = 37.6708, GNorm = 2.3480, lr_0 = 1.0200e-04
Loss = 8.4672e-04, PNorm = 37.6728, GNorm = 2.6204, lr_0 = 1.0200e-04
Loss = 1.0717e-03, PNorm = 37.6744, GNorm = 2.0450, lr_0 = 1.0200e-04
Loss = 9.7008e-04, PNorm = 37.6767, GNorm = 1.6850, lr_0 = 1.0200e-04
Loss = 7.4035e-04, PNorm = 37.6783, GNorm = 1.6109, lr_0 = 1.0200e-04
Loss = 9.3020e-04, PNorm = 37.6800, GNorm = 1.5804, lr_0 = 1.0200e-04
Loss = 9.8679e-04, PNorm = 37.6812, GNorm = 3.2376, lr_0 = 1.0200e-04
Loss = 9.9959e-04, PNorm = 37.6828, GNorm = 2.6742, lr_0 = 1.0200e-04
Loss = 8.6283e-04, PNorm = 37.6844, GNorm = 3.1585, lr_0 = 1.0200e-04
Loss = 7.6692e-04, PNorm = 37.6854, GNorm = 1.5221, lr_0 = 1.0200e-04
Loss = 1.1831e-03, PNorm = 37.6890, GNorm = 2.9085, lr_0 = 1.0200e-04
Loss = 7.6173e-04, PNorm = 37.6910, GNorm = 2.2958, lr_0 = 1.0200e-04
Loss = 6.2625e-04, PNorm = 37.6926, GNorm = 1.3643, lr_0 = 1.0200e-04
Loss = 9.7427e-04, PNorm = 37.6935, GNorm = 1.1914, lr_0 = 1.0200e-04
Loss = 7.6041e-04, PNorm = 37.6950, GNorm = 2.5842, lr_0 = 1.0200e-04
Loss = 9.8122e-04, PNorm = 37.6967, GNorm = 1.7547, lr_0 = 1.0200e-04
Loss = 9.9809e-04, PNorm = 37.6980, GNorm = 3.5104, lr_0 = 1.0200e-04
Loss = 8.9614e-04, PNorm = 37.6985, GNorm = 1.0075, lr_0 = 1.0200e-04
Validation rmse logD = 0.617596
Validation R2 logD = 0.733240
Validation rmse logP = 0.494423
Validation R2 logP = 0.932707
Epoch 52
Train function
Loss = 7.9808e-04, PNorm = 37.7002, GNorm = 1.5042, lr_0 = 1.0200e-04
Loss = 9.9318e-04, PNorm = 37.7017, GNorm = 2.5230, lr_0 = 1.0200e-04
Loss = 6.9225e-04, PNorm = 37.7033, GNorm = 1.8252, lr_0 = 1.0200e-04
Loss = 7.4180e-04, PNorm = 37.7054, GNorm = 4.2057, lr_0 = 1.0200e-04
Loss = 8.4593e-04, PNorm = 37.7077, GNorm = 1.7502, lr_0 = 1.0200e-04
Loss = 7.9719e-04, PNorm = 37.7093, GNorm = 1.8071, lr_0 = 1.0200e-04
Loss = 8.2631e-04, PNorm = 37.7109, GNorm = 3.2101, lr_0 = 1.0200e-04
Loss = 7.7426e-04, PNorm = 37.7125, GNorm = 1.7773, lr_0 = 1.0200e-04
Loss = 7.8933e-04, PNorm = 37.7149, GNorm = 1.4480, lr_0 = 1.0200e-04
Loss = 8.2594e-04, PNorm = 37.7168, GNorm = 1.3287, lr_0 = 1.0200e-04
Loss = 9.0100e-04, PNorm = 37.7184, GNorm = 3.8853, lr_0 = 1.0200e-04
Loss = 8.6887e-04, PNorm = 37.7205, GNorm = 2.5948, lr_0 = 1.0200e-04
Loss = 9.3716e-04, PNorm = 37.7221, GNorm = 1.8075, lr_0 = 1.0200e-04
Loss = 9.0825e-04, PNorm = 37.7234, GNorm = 2.8545, lr_0 = 1.0200e-04
Loss = 8.9118e-04, PNorm = 37.7247, GNorm = 2.3272, lr_0 = 1.0200e-04
Loss = 8.8282e-04, PNorm = 37.7267, GNorm = 2.8215, lr_0 = 1.0200e-04
Loss = 9.1176e-04, PNorm = 37.7281, GNorm = 1.6022, lr_0 = 1.0200e-04
Loss = 8.3164e-04, PNorm = 37.7300, GNorm = 2.7547, lr_0 = 1.0200e-04
Loss = 9.4474e-04, PNorm = 37.7325, GNorm = 4.0240, lr_0 = 1.0200e-04
Loss = 9.3449e-04, PNorm = 37.7349, GNorm = 2.5077, lr_0 = 1.0200e-04
Loss = 1.0081e-03, PNorm = 37.7364, GNorm = 3.3734, lr_0 = 1.0200e-04
Loss = 1.1143e-03, PNorm = 37.7377, GNorm = 1.2601, lr_0 = 1.0200e-04
Loss = 1.2650e-03, PNorm = 37.7388, GNorm = 6.1039, lr_0 = 1.0200e-04
Validation rmse logD = 0.661089
Validation R2 logD = 0.694345
Validation rmse logP = 0.490486
Validation R2 logP = 0.933774
Epoch 53
Train function
Loss = 7.2726e-04, PNorm = 37.7411, GNorm = 1.5315, lr_0 = 1.0200e-04
Loss = 7.2232e-04, PNorm = 37.7430, GNorm = 2.8196, lr_0 = 1.0200e-04
Loss = 8.5014e-04, PNorm = 37.7443, GNorm = 3.3832, lr_0 = 1.0200e-04
Loss = 9.2549e-04, PNorm = 37.7462, GNorm = 2.2549, lr_0 = 1.0200e-04
Loss = 9.5478e-04, PNorm = 37.7491, GNorm = 1.6257, lr_0 = 1.0200e-04
Loss = 7.3673e-04, PNorm = 37.7508, GNorm = 3.3540, lr_0 = 1.0200e-04
Loss = 9.5830e-04, PNorm = 37.7526, GNorm = 3.0499, lr_0 = 1.0200e-04
Loss = 9.3425e-04, PNorm = 37.7545, GNorm = 2.3094, lr_0 = 1.0200e-04
Loss = 8.6706e-04, PNorm = 37.7563, GNorm = 1.2857, lr_0 = 1.0200e-04
Loss = 8.1895e-04, PNorm = 37.7587, GNorm = 2.3001, lr_0 = 1.0200e-04
Loss = 7.7446e-04, PNorm = 37.7595, GNorm = 2.5261, lr_0 = 1.0200e-04
Loss = 8.8539e-04, PNorm = 37.7615, GNorm = 1.8492, lr_0 = 1.0200e-04
Loss = 8.6671e-04, PNorm = 37.7625, GNorm = 1.4615, lr_0 = 1.0200e-04
Loss = 8.4761e-04, PNorm = 37.7640, GNorm = 1.6701, lr_0 = 1.0200e-04
Loss = 8.2686e-04, PNorm = 37.7649, GNorm = 1.2022, lr_0 = 1.0200e-04
Loss = 1.2144e-03, PNorm = 37.7671, GNorm = 5.5630, lr_0 = 1.0200e-04
Loss = 1.0970e-03, PNorm = 37.7694, GNorm = 1.5056, lr_0 = 1.0200e-04
Loss = 1.0309e-03, PNorm = 37.7716, GNorm = 2.0484, lr_0 = 1.0200e-04
Loss = 1.0922e-03, PNorm = 37.7736, GNorm = 1.0160, lr_0 = 1.0200e-04
Loss = 1.0930e-03, PNorm = 37.7747, GNorm = 4.1878, lr_0 = 1.0200e-04
Loss = 8.1384e-04, PNorm = 37.7768, GNorm = 1.0721, lr_0 = 1.0200e-04
Loss = 7.6110e-04, PNorm = 37.7788, GNorm = 1.1950, lr_0 = 1.0200e-04
Validation rmse logD = 0.621701
Validation R2 logD = 0.729681
Validation rmse logP = 0.482490
Validation R2 logP = 0.935916
Epoch 54
Train function
Loss = 6.9815e-04, PNorm = 37.7804, GNorm = 1.2747, lr_0 = 1.0200e-04
Loss = 6.2617e-04, PNorm = 37.7815, GNorm = 0.9059, lr_0 = 1.0200e-04
Loss = 7.9041e-04, PNorm = 37.7832, GNorm = 3.4532, lr_0 = 1.0200e-04
Loss = 7.6178e-04, PNorm = 37.7845, GNorm = 1.4799, lr_0 = 1.0200e-04
Loss = 9.1262e-04, PNorm = 37.7861, GNorm = 1.7181, lr_0 = 1.0200e-04
Loss = 8.4046e-04, PNorm = 37.7878, GNorm = 1.6376, lr_0 = 1.0200e-04
Loss = 7.4416e-04, PNorm = 37.7894, GNorm = 0.8819, lr_0 = 1.0200e-04
Loss = 7.1524e-04, PNorm = 37.7906, GNorm = 1.2642, lr_0 = 1.0200e-04
Loss = 8.0025e-04, PNorm = 37.7929, GNorm = 5.9918, lr_0 = 1.0200e-04
Loss = 7.8342e-04, PNorm = 37.7954, GNorm = 0.9571, lr_0 = 1.0200e-04
Loss = 8.2059e-04, PNorm = 37.7988, GNorm = 1.6757, lr_0 = 1.0200e-04
Loss = 9.2699e-04, PNorm = 37.8006, GNorm = 1.5309, lr_0 = 1.0200e-04
Loss = 9.8450e-04, PNorm = 37.8024, GNorm = 4.2299, lr_0 = 1.0200e-04
Loss = 8.3413e-04, PNorm = 37.8031, GNorm = 1.5344, lr_0 = 1.0200e-04
Loss = 8.0939e-04, PNorm = 37.8054, GNorm = 1.2224, lr_0 = 1.0200e-04
Loss = 7.3110e-04, PNorm = 37.8082, GNorm = 1.8186, lr_0 = 1.0200e-04
Loss = 7.6773e-04, PNorm = 37.8108, GNorm = 1.4525, lr_0 = 1.0200e-04
Loss = 6.4834e-04, PNorm = 37.8119, GNorm = 0.7596, lr_0 = 1.0200e-04
Loss = 7.4052e-04, PNorm = 37.8130, GNorm = 1.9211, lr_0 = 1.0200e-04
Loss = 8.0935e-04, PNorm = 37.8138, GNorm = 2.3277, lr_0 = 1.0200e-04
Loss = 9.5732e-04, PNorm = 37.8153, GNorm = 2.2653, lr_0 = 1.0200e-04
Loss = 7.8295e-04, PNorm = 37.8168, GNorm = 1.5549, lr_0 = 1.0200e-04
Loss = 9.5445e-04, PNorm = 37.8177, GNorm = 1.8626, lr_0 = 1.0200e-04
Validation rmse logD = 0.615065
Validation R2 logD = 0.735422
Validation rmse logP = 0.495355
Validation R2 logP = 0.932453
Epoch 55
Train function
Loss = 8.9268e-04, PNorm = 37.8198, GNorm = 2.8894, lr_0 = 1.0200e-04
Loss = 9.4113e-04, PNorm = 37.8209, GNorm = 1.7639, lr_0 = 1.0200e-04
Loss = 7.2231e-04, PNorm = 37.8219, GNorm = 1.4855, lr_0 = 1.0200e-04
Loss = 8.6447e-04, PNorm = 37.8232, GNorm = 1.9018, lr_0 = 1.0200e-04
Loss = 7.1888e-04, PNorm = 37.8250, GNorm = 2.4861, lr_0 = 1.0200e-04
Loss = 7.0517e-04, PNorm = 37.8271, GNorm = 1.5689, lr_0 = 1.0200e-04
Loss = 6.8057e-04, PNorm = 37.8281, GNorm = 1.1099, lr_0 = 1.0200e-04
Loss = 7.0269e-04, PNorm = 37.8295, GNorm = 2.5068, lr_0 = 1.0200e-04
Loss = 8.2034e-04, PNorm = 37.8315, GNorm = 1.5410, lr_0 = 1.0200e-04
Loss = 7.3657e-04, PNorm = 37.8336, GNorm = 2.3639, lr_0 = 1.0200e-04
Loss = 9.0420e-04, PNorm = 37.8359, GNorm = 2.2555, lr_0 = 1.0200e-04
Loss = 8.2767e-04, PNorm = 37.8380, GNorm = 1.3805, lr_0 = 1.0200e-04
Loss = 6.7440e-04, PNorm = 37.8389, GNorm = 1.5846, lr_0 = 1.0200e-04
Loss = 9.9384e-04, PNorm = 37.8400, GNorm = 4.6462, lr_0 = 1.0200e-04
Loss = 9.8425e-04, PNorm = 37.8424, GNorm = 2.8141, lr_0 = 1.0200e-04
Loss = 8.7776e-04, PNorm = 37.8443, GNorm = 1.2283, lr_0 = 1.0200e-04
Loss = 7.7573e-04, PNorm = 37.8462, GNorm = 2.1078, lr_0 = 1.0200e-04
Loss = 8.4905e-04, PNorm = 37.8481, GNorm = 4.3177, lr_0 = 1.0200e-04
Loss = 8.0274e-04, PNorm = 37.8496, GNorm = 1.5718, lr_0 = 1.0200e-04
Loss = 9.8085e-04, PNorm = 37.8511, GNorm = 4.8124, lr_0 = 1.0200e-04
Loss = 1.2259e-03, PNorm = 37.8526, GNorm = 1.3973, lr_0 = 1.0200e-04
Loss = 9.5216e-04, PNorm = 37.8552, GNorm = 2.3669, lr_0 = 1.0200e-04
Validation rmse logD = 0.615536
Validation R2 logD = 0.735016
Validation rmse logP = 0.483095
Validation R2 logP = 0.935755
Epoch 56
Train function
Loss = 8.8204e-04, PNorm = 37.8567, GNorm = 3.0772, lr_0 = 1.0200e-04
Loss = 7.7613e-04, PNorm = 37.8582, GNorm = 2.1890, lr_0 = 1.0200e-04
Loss = 9.1398e-04, PNorm = 37.8605, GNorm = 1.7313, lr_0 = 1.0200e-04
Loss = 7.5644e-04, PNorm = 37.8616, GNorm = 2.0236, lr_0 = 1.0200e-04
Loss = 7.7340e-04, PNorm = 37.8624, GNorm = 1.3108, lr_0 = 1.0200e-04
Loss = 7.5634e-04, PNorm = 37.8644, GNorm = 1.4725, lr_0 = 1.0200e-04
Loss = 7.7217e-04, PNorm = 37.8672, GNorm = 3.3387, lr_0 = 1.0200e-04
Loss = 7.0967e-04, PNorm = 37.8691, GNorm = 2.5956, lr_0 = 1.0200e-04
Loss = 7.0083e-04, PNorm = 37.8711, GNorm = 1.9275, lr_0 = 1.0200e-04
Loss = 9.7512e-04, PNorm = 37.8731, GNorm = 1.2370, lr_0 = 1.0200e-04
Loss = 7.8987e-04, PNorm = 37.8749, GNorm = 1.9107, lr_0 = 1.0200e-04
Loss = 6.8825e-04, PNorm = 37.8758, GNorm = 2.4337, lr_0 = 1.0200e-04
Loss = 7.6454e-04, PNorm = 37.8769, GNorm = 1.5145, lr_0 = 1.0200e-04
Loss = 1.0081e-03, PNorm = 37.8799, GNorm = 2.8721, lr_0 = 1.0200e-04
Loss = 7.1388e-04, PNorm = 37.8815, GNorm = 3.0764, lr_0 = 1.0200e-04
Loss = 8.7637e-04, PNorm = 37.8824, GNorm = 2.0466, lr_0 = 1.0200e-04
Loss = 8.4619e-04, PNorm = 37.8835, GNorm = 1.4782, lr_0 = 1.0200e-04
Loss = 7.2781e-04, PNorm = 37.8852, GNorm = 2.0626, lr_0 = 1.0200e-04
Loss = 7.4666e-04, PNorm = 37.8860, GNorm = 0.7700, lr_0 = 1.0200e-04
Loss = 9.1096e-04, PNorm = 37.8873, GNorm = 5.1566, lr_0 = 1.0200e-04
Loss = 9.7711e-04, PNorm = 37.8885, GNorm = 1.6495, lr_0 = 1.0200e-04
Loss = 7.5771e-04, PNorm = 37.8911, GNorm = 1.3346, lr_0 = 1.0200e-04
Loss = 6.9042e-04, PNorm = 37.8927, GNorm = 2.0616, lr_0 = 1.0200e-04
Validation rmse logD = 0.615207
Validation R2 logD = 0.735299
Validation rmse logP = 0.485379
Validation R2 logP = 0.935146
Epoch 57
Train function
Loss = 7.5351e-04, PNorm = 37.8939, GNorm = 1.5935, lr_0 = 1.0200e-04
Loss = 6.7260e-04, PNorm = 37.8954, GNorm = 1.5767, lr_0 = 1.0200e-04
Loss = 7.5228e-04, PNorm = 37.8973, GNorm = 3.2750, lr_0 = 1.0200e-04
Loss = 6.9447e-04, PNorm = 37.8994, GNorm = 1.7337, lr_0 = 1.0200e-04
Loss = 8.0029e-04, PNorm = 37.9016, GNorm = 1.9881, lr_0 = 1.0200e-04
Loss = 7.6052e-04, PNorm = 37.9034, GNorm = 2.7070, lr_0 = 1.0200e-04
Loss = 8.7993e-04, PNorm = 37.9054, GNorm = 3.2111, lr_0 = 1.0200e-04
Loss = 7.7094e-04, PNorm = 37.9071, GNorm = 2.5299, lr_0 = 1.0200e-04
Loss = 8.5234e-04, PNorm = 37.9075, GNorm = 2.2507, lr_0 = 1.0200e-04
Loss = 9.4507e-04, PNorm = 37.9086, GNorm = 3.4509, lr_0 = 1.0200e-04
Loss = 8.1003e-04, PNorm = 37.9096, GNorm = 2.7069, lr_0 = 1.0200e-04
Loss = 6.8669e-04, PNorm = 37.9113, GNorm = 2.6610, lr_0 = 1.0200e-04
Loss = 6.9047e-04, PNorm = 37.9136, GNorm = 1.7106, lr_0 = 1.0200e-04
Loss = 7.0639e-04, PNorm = 37.9155, GNorm = 2.9893, lr_0 = 1.0200e-04
Loss = 8.2375e-04, PNorm = 37.9161, GNorm = 1.0471, lr_0 = 1.0200e-04
Loss = 7.6784e-04, PNorm = 37.9180, GNorm = 5.2086, lr_0 = 1.0200e-04
Loss = 1.0065e-03, PNorm = 37.9196, GNorm = 2.2697, lr_0 = 1.0200e-04
Loss = 7.7226e-04, PNorm = 37.9214, GNorm = 1.1817, lr_0 = 1.0200e-04
Loss = 8.2442e-04, PNorm = 37.9242, GNorm = 1.7184, lr_0 = 1.0200e-04
Loss = 6.7089e-04, PNorm = 37.9262, GNorm = 1.6706, lr_0 = 1.0200e-04
Loss = 7.3797e-04, PNorm = 37.9279, GNorm = 1.8480, lr_0 = 1.0200e-04
Loss = 7.2745e-04, PNorm = 37.9297, GNorm = 1.1545, lr_0 = 1.0200e-04
Validation rmse logD = 0.623867
Validation R2 logD = 0.727795
Validation rmse logP = 0.476849
Validation R2 logP = 0.937405
Epoch 58
Train function
Loss = 7.6760e-04, PNorm = 37.9321, GNorm = 1.1372, lr_0 = 1.0200e-04
Loss = 6.4616e-04, PNorm = 37.9344, GNorm = 1.1685, lr_0 = 1.0200e-04
Loss = 6.1590e-04, PNorm = 37.9364, GNorm = 1.0624, lr_0 = 1.0200e-04
Loss = 6.3596e-04, PNorm = 37.9381, GNorm = 1.5607, lr_0 = 1.0200e-04
Loss = 7.6839e-04, PNorm = 37.9389, GNorm = 1.8844, lr_0 = 1.0200e-04
Loss = 7.4483e-04, PNorm = 37.9401, GNorm = 1.0628, lr_0 = 1.0200e-04
Loss = 7.5609e-04, PNorm = 37.9413, GNorm = 1.3249, lr_0 = 1.0200e-04
Loss = 6.8287e-04, PNorm = 37.9424, GNorm = 1.4454, lr_0 = 1.0200e-04
Loss = 7.9604e-04, PNorm = 37.9437, GNorm = 1.6773, lr_0 = 1.0200e-04
Loss = 6.2870e-04, PNorm = 37.9455, GNorm = 2.4076, lr_0 = 1.0200e-04
Loss = 7.6623e-04, PNorm = 37.9481, GNorm = 1.5925, lr_0 = 1.0200e-04
Loss = 6.5098e-04, PNorm = 37.9501, GNorm = 1.3139, lr_0 = 1.0200e-04
Loss = 7.2487e-04, PNorm = 37.9524, GNorm = 3.0824, lr_0 = 1.0200e-04
Loss = 8.2888e-04, PNorm = 37.9548, GNorm = 1.5234, lr_0 = 1.0200e-04
Loss = 7.9697e-04, PNorm = 37.9576, GNorm = 1.7400, lr_0 = 1.0200e-04
Loss = 6.4782e-04, PNorm = 37.9583, GNorm = 1.7394, lr_0 = 1.0200e-04
Loss = 6.7252e-04, PNorm = 37.9603, GNorm = 2.2187, lr_0 = 1.0200e-04
Loss = 7.1079e-04, PNorm = 37.9618, GNorm = 2.0215, lr_0 = 1.0200e-04
Loss = 9.3092e-04, PNorm = 37.9632, GNorm = 2.6177, lr_0 = 1.0200e-04
Loss = 9.4410e-04, PNorm = 37.9646, GNorm = 5.7175, lr_0 = 1.0200e-04
Loss = 9.3045e-04, PNorm = 37.9660, GNorm = 4.0625, lr_0 = 1.0200e-04
Loss = 1.0944e-03, PNorm = 37.9680, GNorm = 2.2628, lr_0 = 1.0200e-04
Loss = 9.3280e-04, PNorm = 37.9707, GNorm = 1.3780, lr_0 = 1.0200e-04
Validation rmse logD = 0.620680
Validation R2 logD = 0.730569
Validation rmse logP = 0.478657
Validation R2 logP = 0.936930
Epoch 59
Train function
Loss = 7.1034e-04, PNorm = 37.9724, GNorm = 4.1771, lr_0 = 1.0200e-04
Loss = 1.1702e-03, PNorm = 37.9740, GNorm = 4.1626, lr_0 = 1.0200e-04
Loss = 8.3627e-04, PNorm = 37.9751, GNorm = 2.3040, lr_0 = 1.0200e-04
Loss = 7.8753e-04, PNorm = 37.9773, GNorm = 1.3689, lr_0 = 1.0200e-04
Loss = 7.3789e-04, PNorm = 37.9796, GNorm = 4.0108, lr_0 = 1.0200e-04
Loss = 7.9073e-04, PNorm = 37.9818, GNorm = 2.0574, lr_0 = 1.0200e-04
Loss = 8.3695e-04, PNorm = 37.9836, GNorm = 3.3683, lr_0 = 1.0200e-04
Loss = 6.2399e-04, PNorm = 37.9848, GNorm = 1.2658, lr_0 = 1.0200e-04
Loss = 6.2945e-04, PNorm = 37.9859, GNorm = 1.6458, lr_0 = 1.0200e-04
Loss = 8.9508e-04, PNorm = 37.9868, GNorm = 2.8371, lr_0 = 1.0200e-04
Loss = 6.9875e-04, PNorm = 37.9884, GNorm = 2.9214, lr_0 = 1.0200e-04
Loss = 7.7952e-04, PNorm = 37.9895, GNorm = 2.0551, lr_0 = 1.0200e-04
Loss = 6.3705e-04, PNorm = 37.9907, GNorm = 1.1174, lr_0 = 1.0200e-04
Loss = 5.6272e-04, PNorm = 37.9917, GNorm = 1.6394, lr_0 = 1.0200e-04
Loss = 5.8409e-04, PNorm = 37.9925, GNorm = 1.0981, lr_0 = 1.0200e-04
Loss = 7.5676e-04, PNorm = 37.9940, GNorm = 2.6683, lr_0 = 1.0200e-04
Loss = 6.7339e-04, PNorm = 37.9967, GNorm = 2.3645, lr_0 = 1.0200e-04
Loss = 8.7898e-04, PNorm = 37.9999, GNorm = 1.7032, lr_0 = 1.0200e-04
Loss = 7.2649e-04, PNorm = 38.0024, GNorm = 1.3846, lr_0 = 1.0200e-04
Loss = 8.1422e-04, PNorm = 38.0041, GNorm = 1.4735, lr_0 = 1.0200e-04
Loss = 7.0150e-04, PNorm = 38.0062, GNorm = 1.5617, lr_0 = 1.0200e-04
Loss = 6.7666e-04, PNorm = 38.0075, GNorm = 2.5534, lr_0 = 1.0200e-04
Validation rmse logD = 0.614082
Validation R2 logD = 0.736267
Validation rmse logP = 0.478704
Validation R2 logP = 0.936918
Epoch 60
Train function
Loss = 6.7923e-04, PNorm = 38.0096, GNorm = 2.7896, lr_0 = 1.0200e-04
Loss = 6.1557e-04, PNorm = 38.0111, GNorm = 1.1406, lr_0 = 1.0200e-04
Loss = 8.4842e-04, PNorm = 38.0121, GNorm = 2.8848, lr_0 = 1.0200e-04
Loss = 7.0807e-04, PNorm = 38.0135, GNorm = 1.2477, lr_0 = 1.0200e-04
Loss = 6.5862e-04, PNorm = 38.0156, GNorm = 2.1044, lr_0 = 1.0200e-04
Loss = 6.7869e-04, PNorm = 38.0180, GNorm = 2.0240, lr_0 = 1.0200e-04
Loss = 6.4053e-04, PNorm = 38.0200, GNorm = 1.5747, lr_0 = 1.0200e-04
Loss = 8.1393e-04, PNorm = 38.0209, GNorm = 4.0045, lr_0 = 1.0200e-04
Loss = 9.6101e-04, PNorm = 38.0224, GNorm = 3.5668, lr_0 = 1.0200e-04
Loss = 8.7765e-04, PNorm = 38.0245, GNorm = 2.8023, lr_0 = 1.0200e-04
Loss = 7.7016e-04, PNorm = 38.0263, GNorm = 1.9556, lr_0 = 1.0200e-04
Loss = 9.2713e-04, PNorm = 38.0273, GNorm = 2.4561, lr_0 = 1.0200e-04
Loss = 8.1795e-04, PNorm = 38.0288, GNorm = 1.1430, lr_0 = 1.0200e-04
Loss = 7.3127e-04, PNorm = 38.0309, GNorm = 3.2176, lr_0 = 1.0200e-04
Loss = 7.6904e-04, PNorm = 38.0326, GNorm = 1.7399, lr_0 = 1.0200e-04
Loss = 7.2150e-04, PNorm = 38.0337, GNorm = 2.3222, lr_0 = 1.0200e-04
Loss = 6.9142e-04, PNorm = 38.0352, GNorm = 2.5163, lr_0 = 1.0200e-04
Loss = 6.3575e-04, PNorm = 38.0363, GNorm = 1.3008, lr_0 = 1.0200e-04
Loss = 6.0014e-04, PNorm = 38.0379, GNorm = 0.8462, lr_0 = 1.0200e-04
Loss = 6.2762e-04, PNorm = 38.0393, GNorm = 1.6936, lr_0 = 1.0200e-04
Loss = 6.0616e-04, PNorm = 38.0416, GNorm = 0.9022, lr_0 = 1.0200e-04
Loss = 6.8790e-04, PNorm = 38.0429, GNorm = 3.4063, lr_0 = 1.0200e-04
Loss = 8.9797e-04, PNorm = 38.0448, GNorm = 3.1142, lr_0 = 1.0200e-04
Validation rmse logD = 0.614526
Validation R2 logD = 0.735885
Validation rmse logP = 0.476011
Validation R2 logP = 0.937626
Epoch 61
Train function
Loss = 5.0975e-04, PNorm = 38.0473, GNorm = 1.5860, lr_0 = 1.0200e-04
Loss = 6.6621e-04, PNorm = 38.0485, GNorm = 1.4795, lr_0 = 1.0200e-04
Loss = 5.1789e-04, PNorm = 38.0495, GNorm = 0.9102, lr_0 = 1.0200e-04
Loss = 6.0222e-04, PNorm = 38.0510, GNorm = 1.0021, lr_0 = 1.0200e-04
Loss = 6.1435e-04, PNorm = 38.0527, GNorm = 1.1977, lr_0 = 1.0200e-04
Loss = 7.1756e-04, PNorm = 38.0541, GNorm = 1.6554, lr_0 = 1.0200e-04
Loss = 7.0254e-04, PNorm = 38.0559, GNorm = 3.7662, lr_0 = 1.0200e-04
Loss = 6.9329e-04, PNorm = 38.0579, GNorm = 3.8093, lr_0 = 1.0200e-04
Loss = 7.9887e-04, PNorm = 38.0598, GNorm = 2.2104, lr_0 = 1.0200e-04
Loss = 8.5443e-04, PNorm = 38.0614, GNorm = 0.6072, lr_0 = 1.0200e-04
Loss = 6.8365e-04, PNorm = 38.0634, GNorm = 2.0246, lr_0 = 1.0200e-04
Loss = 6.7846e-04, PNorm = 38.0655, GNorm = 1.0711, lr_0 = 1.0200e-04
Loss = 7.8096e-04, PNorm = 38.0675, GNorm = 1.8929, lr_0 = 1.0200e-04
Loss = 6.6696e-04, PNorm = 38.0697, GNorm = 1.3961, lr_0 = 1.0200e-04
Loss = 6.8389e-04, PNorm = 38.0710, GNorm = 2.2127, lr_0 = 1.0200e-04
Loss = 7.6993e-04, PNorm = 38.0712, GNorm = 1.2973, lr_0 = 1.0200e-04
Loss = 7.4446e-04, PNorm = 38.0723, GNorm = 1.3223, lr_0 = 1.0200e-04
Loss = 8.3334e-04, PNorm = 38.0740, GNorm = 1.9647, lr_0 = 1.0200e-04
Loss = 8.1130e-04, PNorm = 38.0756, GNorm = 2.0288, lr_0 = 1.0200e-04
Loss = 7.5469e-04, PNorm = 38.0780, GNorm = 3.1885, lr_0 = 1.0200e-04
Loss = 8.3972e-04, PNorm = 38.0806, GNorm = 1.8444, lr_0 = 1.0200e-04
Loss = 8.3348e-04, PNorm = 38.0816, GNorm = 3.2530, lr_0 = 1.0200e-04
Validation rmse logD = 0.645796
Validation R2 logD = 0.708323
Validation rmse logP = 0.487653
Validation R2 logP = 0.934537
Epoch 62
Train function
Loss = 6.4995e-04, PNorm = 38.0832, GNorm = 3.2903, lr_0 = 1.0200e-04
Loss = 6.7170e-04, PNorm = 38.0841, GNorm = 1.1934, lr_0 = 1.0200e-04
Loss = 6.4632e-04, PNorm = 38.0856, GNorm = 1.1090, lr_0 = 1.0200e-04
Loss = 7.2311e-04, PNorm = 38.0863, GNorm = 0.7280, lr_0 = 1.0200e-04
Loss = 7.4508e-04, PNorm = 38.0881, GNorm = 3.2560, lr_0 = 1.0200e-04
Loss = 7.0165e-04, PNorm = 38.0901, GNorm = 1.8680, lr_0 = 1.0200e-04
Loss = 5.5559e-04, PNorm = 38.0917, GNorm = 3.2682, lr_0 = 1.0200e-04
Loss = 6.5010e-04, PNorm = 38.0939, GNorm = 0.9589, lr_0 = 1.0200e-04
Loss = 8.5694e-04, PNorm = 38.0950, GNorm = 1.6723, lr_0 = 1.0200e-04
Loss = 6.6495e-04, PNorm = 38.0968, GNorm = 1.1147, lr_0 = 1.0200e-04
Loss = 5.6413e-04, PNorm = 38.1000, GNorm = 1.1099, lr_0 = 1.0200e-04
Loss = 5.9157e-04, PNorm = 38.1006, GNorm = 2.3028, lr_0 = 1.0200e-04
Loss = 7.1335e-04, PNorm = 38.1014, GNorm = 1.6059, lr_0 = 1.0200e-04
Loss = 7.9060e-04, PNorm = 38.1026, GNorm = 2.8967, lr_0 = 1.0200e-04
Loss = 6.5564e-04, PNorm = 38.1045, GNorm = 1.3966, lr_0 = 1.0200e-04
Loss = 8.1909e-04, PNorm = 38.1057, GNorm = 2.7973, lr_0 = 1.0200e-04
Loss = 8.0111e-04, PNorm = 38.1077, GNorm = 2.0278, lr_0 = 1.0200e-04
Loss = 7.8393e-04, PNorm = 38.1090, GNorm = 2.2115, lr_0 = 1.0200e-04
Loss = 7.4118e-04, PNorm = 38.1101, GNorm = 1.4233, lr_0 = 1.0200e-04
Loss = 6.1268e-04, PNorm = 38.1123, GNorm = 1.1629, lr_0 = 1.0200e-04
Loss = 7.1207e-04, PNorm = 38.1132, GNorm = 1.0384, lr_0 = 1.0200e-04
Loss = 6.8045e-04, PNorm = 38.1138, GNorm = 1.7180, lr_0 = 1.0200e-04
Loss = 5.9125e-04, PNorm = 38.1152, GNorm = 1.8320, lr_0 = 1.0200e-04
Validation rmse logD = 0.624994
Validation R2 logD = 0.726811
Validation rmse logP = 0.475596
Validation R2 logP = 0.937734
Epoch 63
Train function
Loss = 6.0829e-04, PNorm = 38.1167, GNorm = 2.2164, lr_0 = 1.0200e-04
Loss = 7.4218e-04, PNorm = 38.1185, GNorm = 3.2098, lr_0 = 1.0200e-04
Loss = 7.8301e-04, PNorm = 38.1203, GNorm = 0.9507, lr_0 = 1.0200e-04
Loss = 7.9050e-04, PNorm = 38.1215, GNorm = 2.1777, lr_0 = 1.0200e-04
Loss = 5.7866e-04, PNorm = 38.1232, GNorm = 1.9795, lr_0 = 1.0200e-04
Loss = 6.1443e-04, PNorm = 38.1246, GNorm = 1.0979, lr_0 = 1.0200e-04
Loss = 7.6604e-04, PNorm = 38.1264, GNorm = 3.3920, lr_0 = 1.0200e-04
Loss = 7.2834e-04, PNorm = 38.1282, GNorm = 3.2002, lr_0 = 1.0200e-04
Loss = 7.9321e-04, PNorm = 38.1295, GNorm = 1.6036, lr_0 = 1.0200e-04
Loss = 7.3586e-04, PNorm = 38.1313, GNorm = 1.7712, lr_0 = 1.0200e-04
Loss = 9.1148e-04, PNorm = 38.1327, GNorm = 2.7056, lr_0 = 1.0200e-04
Loss = 7.1278e-04, PNorm = 38.1347, GNorm = 1.2960, lr_0 = 1.0200e-04
Loss = 6.9728e-04, PNorm = 38.1362, GNorm = 1.3415, lr_0 = 1.0200e-04
Loss = 6.4293e-04, PNorm = 38.1375, GNorm = 2.4768, lr_0 = 1.0200e-04
Loss = 5.9742e-04, PNorm = 38.1388, GNorm = 1.1006, lr_0 = 1.0200e-04
Loss = 6.0403e-04, PNorm = 38.1400, GNorm = 1.2093, lr_0 = 1.0200e-04
Loss = 6.6955e-04, PNorm = 38.1412, GNorm = 1.6895, lr_0 = 1.0200e-04
Loss = 8.4384e-04, PNorm = 38.1435, GNorm = 4.7331, lr_0 = 1.0200e-04
Loss = 8.1682e-04, PNorm = 38.1449, GNorm = 2.4146, lr_0 = 1.0200e-04
Loss = 6.6555e-04, PNorm = 38.1468, GNorm = 2.8447, lr_0 = 1.0200e-04
Loss = 6.2334e-04, PNorm = 38.1482, GNorm = 2.7500, lr_0 = 1.0200e-04
Loss = 5.3789e-04, PNorm = 38.1500, GNorm = 1.0137, lr_0 = 1.0200e-04
Loss = 5.9303e-04, PNorm = 38.1520, GNorm = 2.5207, lr_0 = 1.0200e-04
Loss = 1.8604e-03, PNorm = 38.1522, GNorm = 2.0590, lr_0 = 1.0200e-04
Validation rmse logD = 0.619066
Validation R2 logD = 0.731968
Validation rmse logP = 0.474773
Validation R2 logP = 0.937950
Epoch 64
Train function
Loss = 6.4149e-04, PNorm = 38.1535, GNorm = 1.0798, lr_0 = 1.0200e-04
Loss = 5.7903e-04, PNorm = 38.1551, GNorm = 1.2373, lr_0 = 1.0200e-04
Loss = 5.3655e-04, PNorm = 38.1568, GNorm = 2.2735, lr_0 = 1.0200e-04
Loss = 5.3656e-04, PNorm = 38.1577, GNorm = 1.4015, lr_0 = 1.0200e-04
Loss = 5.5694e-04, PNorm = 38.1590, GNorm = 2.2587, lr_0 = 1.0200e-04
Loss = 5.2709e-04, PNorm = 38.1603, GNorm = 1.6085, lr_0 = 1.0200e-04
Loss = 5.7819e-04, PNorm = 38.1619, GNorm = 1.6180, lr_0 = 1.0200e-04
Loss = 8.0136e-04, PNorm = 38.1643, GNorm = 2.7743, lr_0 = 1.0200e-04
Loss = 5.8911e-04, PNorm = 38.1667, GNorm = 1.3180, lr_0 = 1.0200e-04
Loss = 6.5242e-04, PNorm = 38.1677, GNorm = 1.1765, lr_0 = 1.0200e-04
Loss = 6.6066e-04, PNorm = 38.1697, GNorm = 1.2326, lr_0 = 1.0200e-04
Loss = 5.8577e-04, PNorm = 38.1703, GNorm = 2.1579, lr_0 = 1.0200e-04
Loss = 6.6872e-04, PNorm = 38.1715, GNorm = 1.2715, lr_0 = 1.0200e-04
Loss = 6.4467e-04, PNorm = 38.1731, GNorm = 1.2164, lr_0 = 1.0200e-04
Loss = 6.8233e-04, PNorm = 38.1751, GNorm = 1.3566, lr_0 = 1.0200e-04
Loss = 5.6205e-04, PNorm = 38.1768, GNorm = 2.8333, lr_0 = 1.0200e-04
Loss = 7.7058e-04, PNorm = 38.1777, GNorm = 1.0639, lr_0 = 1.0200e-04
Loss = 6.6219e-04, PNorm = 38.1789, GNorm = 1.7285, lr_0 = 1.0200e-04
Loss = 6.3022e-04, PNorm = 38.1803, GNorm = 3.0107, lr_0 = 1.0200e-04
Loss = 6.9631e-04, PNorm = 38.1817, GNorm = 2.4458, lr_0 = 1.0200e-04
Loss = 7.0431e-04, PNorm = 38.1833, GNorm = 3.4280, lr_0 = 1.0200e-04
Loss = 7.7867e-04, PNorm = 38.1849, GNorm = 1.6903, lr_0 = 1.0200e-04
Validation rmse logD = 0.612175
Validation R2 logD = 0.737903
Validation rmse logP = 0.482265
Validation R2 logP = 0.935976
Epoch 65
Train function
Loss = 9.2216e-04, PNorm = 38.1877, GNorm = 2.5182, lr_0 = 1.0200e-04
Loss = 6.6154e-04, PNorm = 38.1901, GNorm = 4.8366, lr_0 = 1.0200e-04
Loss = 5.6058e-04, PNorm = 38.1914, GNorm = 2.4206, lr_0 = 1.0200e-04
Loss = 6.0168e-04, PNorm = 38.1919, GNorm = 2.4510, lr_0 = 1.0200e-04
Loss = 6.2640e-04, PNorm = 38.1935, GNorm = 2.0936, lr_0 = 1.0200e-04
Loss = 5.9827e-04, PNorm = 38.1954, GNorm = 0.8452, lr_0 = 1.0200e-04
Loss = 6.0552e-04, PNorm = 38.1976, GNorm = 1.8570, lr_0 = 1.0200e-04
Loss = 5.9987e-04, PNorm = 38.1998, GNorm = 1.7343, lr_0 = 1.0200e-04
Loss = 6.5933e-04, PNorm = 38.2000, GNorm = 1.1736, lr_0 = 1.0200e-04
Loss = 7.1984e-04, PNorm = 38.2006, GNorm = 2.2750, lr_0 = 1.0200e-04
Loss = 5.0079e-04, PNorm = 38.2021, GNorm = 2.8626, lr_0 = 1.0200e-04
Loss = 8.4223e-04, PNorm = 38.2025, GNorm = 2.0928, lr_0 = 1.0200e-04
Loss = 8.0919e-04, PNorm = 38.2041, GNorm = 1.4461, lr_0 = 1.0200e-04
Loss = 5.6558e-04, PNorm = 38.2068, GNorm = 0.9398, lr_0 = 1.0200e-04
Loss = 6.1386e-04, PNorm = 38.2079, GNorm = 1.1183, lr_0 = 1.0200e-04
Loss = 5.8520e-04, PNorm = 38.2098, GNorm = 1.3059, lr_0 = 1.0200e-04
Loss = 6.3408e-04, PNorm = 38.2114, GNorm = 1.1726, lr_0 = 1.0200e-04
Loss = 6.0622e-04, PNorm = 38.2126, GNorm = 1.5118, lr_0 = 1.0200e-04
Loss = 6.6947e-04, PNorm = 38.2142, GNorm = 1.0512, lr_0 = 1.0200e-04
Loss = 7.2538e-04, PNorm = 38.2165, GNorm = 2.9718, lr_0 = 1.0200e-04
Loss = 9.6976e-04, PNorm = 38.2178, GNorm = 2.3000, lr_0 = 1.0200e-04
Loss = 7.2048e-04, PNorm = 38.2193, GNorm = 1.0578, lr_0 = 1.0200e-04
Loss = 5.7071e-04, PNorm = 38.2223, GNorm = 1.1188, lr_0 = 1.0200e-04
Validation rmse logD = 0.610356
Validation R2 logD = 0.739458
Validation rmse logP = 0.471482
Validation R2 logP = 0.938807
Epoch 66
Train function
Loss = 6.1193e-04, PNorm = 38.2245, GNorm = 1.1109, lr_0 = 1.0200e-04
Loss = 6.3516e-04, PNorm = 38.2260, GNorm = 1.7429, lr_0 = 1.0200e-04
Loss = 5.9172e-04, PNorm = 38.2278, GNorm = 1.8376, lr_0 = 1.0200e-04
Loss = 5.1960e-04, PNorm = 38.2289, GNorm = 1.3713, lr_0 = 1.0200e-04
Loss = 8.4099e-04, PNorm = 38.2301, GNorm = 4.2774, lr_0 = 1.0200e-04
Loss = 7.3896e-04, PNorm = 38.2324, GNorm = 2.1019, lr_0 = 1.0200e-04
Loss = 5.7204e-04, PNorm = 38.2347, GNorm = 3.5105, lr_0 = 1.0200e-04
Loss = 7.6345e-04, PNorm = 38.2359, GNorm = 2.9039, lr_0 = 1.0200e-04
Loss = 8.9295e-04, PNorm = 38.2360, GNorm = 3.5823, lr_0 = 1.0200e-04
Loss = 8.3551e-04, PNorm = 38.2382, GNorm = 4.6543, lr_0 = 1.0200e-04
Loss = 6.7707e-04, PNorm = 38.2401, GNorm = 1.0751, lr_0 = 1.0200e-04
Loss = 6.1914e-04, PNorm = 38.2414, GNorm = 1.4600, lr_0 = 1.0200e-04
Loss = 6.3728e-04, PNorm = 38.2423, GNorm = 5.8295, lr_0 = 1.0200e-04
Loss = 5.8480e-04, PNorm = 38.2434, GNorm = 0.7395, lr_0 = 1.0200e-04
Loss = 7.4051e-04, PNorm = 38.2444, GNorm = 2.7072, lr_0 = 1.0200e-04
Loss = 7.5264e-04, PNorm = 38.2461, GNorm = 2.5179, lr_0 = 1.0200e-04
Loss = 6.0388e-04, PNorm = 38.2476, GNorm = 1.4828, lr_0 = 1.0200e-04
Loss = 6.2172e-04, PNorm = 38.2498, GNorm = 1.5363, lr_0 = 1.0200e-04
Loss = 5.3849e-04, PNorm = 38.2527, GNorm = 1.0358, lr_0 = 1.0200e-04
Loss = 5.8917e-04, PNorm = 38.2548, GNorm = 1.4507, lr_0 = 1.0200e-04
Loss = 5.9818e-04, PNorm = 38.2564, GNorm = 1.9244, lr_0 = 1.0200e-04
Loss = 8.3742e-04, PNorm = 38.2582, GNorm = 2.7435, lr_0 = 1.0200e-04
Validation rmse logD = 0.685117
Validation R2 logD = 0.671722
Validation rmse logP = 0.472890
Validation R2 logP = 0.938441
Epoch 67
Train function
Loss = 8.8354e-04, PNorm = 38.2598, GNorm = 2.0398, lr_0 = 1.0200e-04
Loss = 7.6884e-04, PNorm = 38.2613, GNorm = 1.8096, lr_0 = 1.0200e-04
Loss = 7.1436e-04, PNorm = 38.2635, GNorm = 2.3351, lr_0 = 1.0200e-04
Loss = 8.0393e-04, PNorm = 38.2654, GNorm = 1.4699, lr_0 = 1.0200e-04
Loss = 6.0980e-04, PNorm = 38.2676, GNorm = 2.3357, lr_0 = 1.0200e-04
Loss = 7.5833e-04, PNorm = 38.2701, GNorm = 3.1042, lr_0 = 1.0200e-04
Loss = 6.9195e-04, PNorm = 38.2708, GNorm = 1.4264, lr_0 = 1.0200e-04
Loss = 5.7707e-04, PNorm = 38.2717, GNorm = 1.8262, lr_0 = 1.0200e-04
Loss = 8.5630e-04, PNorm = 38.2724, GNorm = 2.7947, lr_0 = 1.0200e-04
Loss = 8.9388e-04, PNorm = 38.2729, GNorm = 3.1885, lr_0 = 1.0200e-04
Loss = 5.9709e-04, PNorm = 38.2746, GNorm = 1.3168, lr_0 = 1.0200e-04
Loss = 6.4028e-04, PNorm = 38.2762, GNorm = 0.8415, lr_0 = 1.0200e-04
Loss = 6.3065e-04, PNorm = 38.2780, GNorm = 1.2938, lr_0 = 1.0200e-04
Loss = 6.0866e-04, PNorm = 38.2803, GNorm = 1.5468, lr_0 = 1.0200e-04
Loss = 7.2117e-04, PNorm = 38.2814, GNorm = 3.4417, lr_0 = 1.0200e-04
Loss = 6.8533e-04, PNorm = 38.2825, GNorm = 1.1826, lr_0 = 1.0200e-04
Loss = 7.0288e-04, PNorm = 38.2844, GNorm = 2.3004, lr_0 = 1.0200e-04
Loss = 7.5430e-04, PNorm = 38.2861, GNorm = 1.3379, lr_0 = 1.0200e-04
Loss = 5.7757e-04, PNorm = 38.2881, GNorm = 1.1074, lr_0 = 1.0200e-04
Loss = 6.7334e-04, PNorm = 38.2898, GNorm = 0.9720, lr_0 = 1.0200e-04
Loss = 5.2371e-04, PNorm = 38.2916, GNorm = 1.1268, lr_0 = 1.0200e-04
Loss = 5.1962e-04, PNorm = 38.2931, GNorm = 1.5699, lr_0 = 1.0200e-04
Loss = 4.8712e-04, PNorm = 38.2940, GNorm = 1.9355, lr_0 = 1.0200e-04
Validation rmse logD = 0.608956
Validation R2 logD = 0.740651
Validation rmse logP = 0.471688
Validation R2 logP = 0.938753
Epoch 68
Train function
Loss = 4.4204e-04, PNorm = 38.2957, GNorm = 0.9948, lr_0 = 1.0200e-04
Loss = 6.8318e-04, PNorm = 38.2972, GNorm = 3.9080, lr_0 = 1.0200e-04
Loss = 5.7052e-04, PNorm = 38.2985, GNorm = 1.1917, lr_0 = 1.0200e-04
Loss = 5.8779e-04, PNorm = 38.3001, GNorm = 2.1121, lr_0 = 1.0200e-04
Loss = 5.9768e-04, PNorm = 38.3018, GNorm = 1.9655, lr_0 = 1.0200e-04
Loss = 6.4219e-04, PNorm = 38.3028, GNorm = 2.2424, lr_0 = 1.0200e-04
Loss = 6.1501e-04, PNorm = 38.3037, GNorm = 2.5805, lr_0 = 1.0200e-04
Loss = 6.3146e-04, PNorm = 38.3049, GNorm = 1.5183, lr_0 = 1.0200e-04
Loss = 4.8789e-04, PNorm = 38.3067, GNorm = 0.8939, lr_0 = 1.0200e-04
Loss = 5.6927e-04, PNorm = 38.3079, GNorm = 1.5184, lr_0 = 1.0200e-04
Loss = 7.0172e-04, PNorm = 38.3092, GNorm = 1.4750, lr_0 = 1.0200e-04
Loss = 5.7683e-04, PNorm = 38.3108, GNorm = 1.2483, lr_0 = 1.0200e-04
Loss = 6.0917e-04, PNorm = 38.3124, GNorm = 1.2006, lr_0 = 1.0200e-04
Loss = 5.3494e-04, PNorm = 38.3143, GNorm = 1.5667, lr_0 = 1.0200e-04
Loss = 6.1435e-04, PNorm = 38.3155, GNorm = 2.1507, lr_0 = 1.0200e-04
Loss = 6.8209e-04, PNorm = 38.3164, GNorm = 1.7172, lr_0 = 1.0200e-04
Loss = 7.0430e-04, PNorm = 38.3188, GNorm = 4.8196, lr_0 = 1.0200e-04
Loss = 6.1252e-04, PNorm = 38.3207, GNorm = 1.4461, lr_0 = 1.0200e-04
Loss = 6.0174e-04, PNorm = 38.3219, GNorm = 1.1228, lr_0 = 1.0200e-04
Loss = 6.4743e-04, PNorm = 38.3232, GNorm = 4.2819, lr_0 = 1.0200e-04
Loss = 6.3054e-04, PNorm = 38.3248, GNorm = 1.7293, lr_0 = 1.0200e-04
Loss = 7.2000e-04, PNorm = 38.3266, GNorm = 2.0267, lr_0 = 1.0200e-04
Validation rmse logD = 0.648170
Validation R2 logD = 0.706174
Validation rmse logP = 0.481494
Validation R2 logP = 0.936180
Epoch 69
Train function
Loss = 5.4853e-04, PNorm = 38.3279, GNorm = 1.7943, lr_0 = 1.0200e-04
Loss = 5.6671e-04, PNorm = 38.3293, GNorm = 0.9454, lr_0 = 1.0200e-04
Loss = 4.6701e-04, PNorm = 38.3302, GNorm = 1.9917, lr_0 = 1.0200e-04
Loss = 5.9699e-04, PNorm = 38.3315, GNorm = 1.8820, lr_0 = 1.0200e-04
Loss = 8.5958e-04, PNorm = 38.3331, GNorm = 3.8462, lr_0 = 1.0200e-04
Loss = 4.7230e-04, PNorm = 38.3344, GNorm = 1.7227, lr_0 = 1.0200e-04
Loss = 6.9805e-04, PNorm = 38.3345, GNorm = 1.0709, lr_0 = 1.0200e-04
Loss = 4.4547e-04, PNorm = 38.3359, GNorm = 0.9076, lr_0 = 1.0200e-04
Loss = 4.9544e-04, PNorm = 38.3374, GNorm = 1.2002, lr_0 = 1.0200e-04
Loss = 5.8789e-04, PNorm = 38.3391, GNorm = 0.9749, lr_0 = 1.0200e-04
Loss = 5.5422e-04, PNorm = 38.3406, GNorm = 1.3561, lr_0 = 1.0200e-04
Loss = 5.1746e-04, PNorm = 38.3419, GNorm = 2.1856, lr_0 = 1.0200e-04
Loss = 5.1739e-04, PNorm = 38.3432, GNorm = 2.6014, lr_0 = 1.0200e-04
Loss = 5.0330e-04, PNorm = 38.3447, GNorm = 1.7349, lr_0 = 1.0200e-04
Loss = 5.9638e-04, PNorm = 38.3458, GNorm = 1.5605, lr_0 = 1.0200e-04
Loss = 6.5149e-04, PNorm = 38.3482, GNorm = 2.1600, lr_0 = 1.0200e-04
Loss = 6.3737e-04, PNorm = 38.3501, GNorm = 2.5997, lr_0 = 1.0200e-04
Loss = 5.6809e-04, PNorm = 38.3520, GNorm = 1.2339, lr_0 = 1.0200e-04
Loss = 6.4549e-04, PNorm = 38.3528, GNorm = 1.1122, lr_0 = 1.0200e-04
Loss = 5.9728e-04, PNorm = 38.3542, GNorm = 2.9332, lr_0 = 1.0200e-04
Loss = 7.5185e-04, PNorm = 38.3559, GNorm = 1.5215, lr_0 = 1.0200e-04
Loss = 6.8156e-04, PNorm = 38.3587, GNorm = 2.3135, lr_0 = 1.0200e-04
Loss = 6.5824e-04, PNorm = 38.3617, GNorm = 2.4183, lr_0 = 1.0200e-04
Validation rmse logD = 0.613743
Validation R2 logD = 0.736558
Validation rmse logP = 0.475313
Validation R2 logP = 0.937808
Epoch 70
Train function
Loss = 5.1602e-04, PNorm = 38.3632, GNorm = 0.9034, lr_0 = 1.0200e-04
Loss = 4.2304e-04, PNorm = 38.3656, GNorm = 1.2855, lr_0 = 1.0200e-04
Loss = 3.7314e-04, PNorm = 38.3677, GNorm = 1.4940, lr_0 = 1.0200e-04
Loss = 4.8787e-04, PNorm = 38.3697, GNorm = 1.1951, lr_0 = 1.0200e-04
Loss = 5.8155e-04, PNorm = 38.3717, GNorm = 1.0016, lr_0 = 1.0200e-04
Loss = 5.1994e-04, PNorm = 38.3724, GNorm = 1.8318, lr_0 = 1.0200e-04
Loss = 6.0854e-04, PNorm = 38.3730, GNorm = 2.4663, lr_0 = 1.0200e-04
Loss = 5.5036e-04, PNorm = 38.3747, GNorm = 0.8952, lr_0 = 1.0200e-04
Loss = 6.5006e-04, PNorm = 38.3762, GNorm = 1.5426, lr_0 = 1.0200e-04
Loss = 6.0815e-04, PNorm = 38.3775, GNorm = 2.4376, lr_0 = 1.0200e-04
Loss = 6.0695e-04, PNorm = 38.3778, GNorm = 0.8692, lr_0 = 1.0200e-04
Loss = 6.4313e-04, PNorm = 38.3792, GNorm = 1.3280, lr_0 = 1.0200e-04
Loss = 4.6003e-04, PNorm = 38.3805, GNorm = 1.6117, lr_0 = 1.0200e-04
Loss = 5.0003e-04, PNorm = 38.3817, GNorm = 1.1253, lr_0 = 1.0200e-04
Loss = 5.7621e-04, PNorm = 38.3831, GNorm = 1.2073, lr_0 = 1.0200e-04
Loss = 4.7261e-04, PNorm = 38.3847, GNorm = 0.8166, lr_0 = 1.0200e-04
Loss = 6.0260e-04, PNorm = 38.3860, GNorm = 3.5580, lr_0 = 1.0200e-04
Loss = 5.6706e-04, PNorm = 38.3873, GNorm = 4.0728, lr_0 = 1.0200e-04
Loss = 7.4160e-04, PNorm = 38.3889, GNorm = 3.7100, lr_0 = 1.0200e-04
Loss = 6.6349e-04, PNorm = 38.3893, GNorm = 2.9649, lr_0 = 1.0200e-04
Loss = 7.5970e-04, PNorm = 38.3908, GNorm = 2.8864, lr_0 = 1.0200e-04
Loss = 7.9891e-04, PNorm = 38.3928, GNorm = 3.0200, lr_0 = 1.0200e-04
Validation rmse logD = 0.678202
Validation R2 logD = 0.678315
Validation rmse logP = 0.509968
Validation R2 logP = 0.928409
Epoch 71
Train function
Loss = 1.4693e-03, PNorm = 38.3952, GNorm = 5.3482, lr_0 = 1.0200e-04
Loss = 4.9020e-04, PNorm = 38.3963, GNorm = 1.7795, lr_0 = 1.0200e-04
Loss = 6.0766e-04, PNorm = 38.3975, GNorm = 3.1870, lr_0 = 1.0200e-04
Loss = 5.2508e-04, PNorm = 38.3995, GNorm = 0.9373, lr_0 = 1.0200e-04
Loss = 4.9446e-04, PNorm = 38.4013, GNorm = 2.4671, lr_0 = 1.0200e-04
Loss = 5.8044e-04, PNorm = 38.4028, GNorm = 1.7845, lr_0 = 1.0200e-04
Loss = 4.4617e-04, PNorm = 38.4040, GNorm = 1.2363, lr_0 = 1.0200e-04
Loss = 6.3244e-04, PNorm = 38.4063, GNorm = 3.4651, lr_0 = 1.0200e-04
Loss = 6.9528e-04, PNorm = 38.4077, GNorm = 2.8437, lr_0 = 1.0200e-04
Loss = 6.9962e-04, PNorm = 38.4101, GNorm = 1.3675, lr_0 = 1.0200e-04
Loss = 6.4565e-04, PNorm = 38.4118, GNorm = 1.5408, lr_0 = 1.0200e-04
Loss = 6.4063e-04, PNorm = 38.4137, GNorm = 1.4547, lr_0 = 1.0200e-04
Loss = 6.8916e-04, PNorm = 38.4159, GNorm = 3.7298, lr_0 = 1.0200e-04
Loss = 6.3273e-04, PNorm = 38.4181, GNorm = 1.8659, lr_0 = 1.0200e-04
Loss = 7.1625e-04, PNorm = 38.4210, GNorm = 1.5089, lr_0 = 1.0200e-04
Loss = 6.5673e-04, PNorm = 38.4227, GNorm = 1.1930, lr_0 = 1.0200e-04
Loss = 6.5366e-04, PNorm = 38.4240, GNorm = 1.3841, lr_0 = 1.0200e-04
Loss = 5.7969e-04, PNorm = 38.4246, GNorm = 1.4850, lr_0 = 1.0200e-04
Loss = 5.5996e-04, PNorm = 38.4251, GNorm = 1.3523, lr_0 = 1.0200e-04
Loss = 5.4385e-04, PNorm = 38.4268, GNorm = 1.5856, lr_0 = 1.0200e-04
Loss = 7.0733e-04, PNorm = 38.4287, GNorm = 2.0270, lr_0 = 1.0200e-04
Loss = 5.7486e-04, PNorm = 38.4300, GNorm = 2.7716, lr_0 = 1.0200e-04
Loss = 4.7382e-04, PNorm = 38.4316, GNorm = 1.0780, lr_0 = 1.0200e-04
Validation rmse logD = 0.614109
Validation R2 logD = 0.736243
Validation rmse logP = 0.473516
Validation R2 logP = 0.938278
Epoch 72
Train function
Loss = 9.2972e-04, PNorm = 38.4333, GNorm = 2.6015, lr_0 = 1.0200e-04
Loss = 5.5895e-04, PNorm = 38.4357, GNorm = 1.9593, lr_0 = 1.0200e-04
Loss = 4.7647e-04, PNorm = 38.4366, GNorm = 0.7771, lr_0 = 1.0200e-04
Loss = 4.6452e-04, PNorm = 38.4373, GNorm = 2.6672, lr_0 = 1.0200e-04
Loss = 5.3578e-04, PNorm = 38.4389, GNorm = 1.2447, lr_0 = 1.0200e-04
Loss = 5.3231e-04, PNorm = 38.4401, GNorm = 1.0348, lr_0 = 1.0200e-04
Loss = 5.2220e-04, PNorm = 38.4419, GNorm = 1.4730, lr_0 = 1.0200e-04
Loss = 5.2539e-04, PNorm = 38.4431, GNorm = 0.8161, lr_0 = 1.0200e-04
Loss = 5.4733e-04, PNorm = 38.4454, GNorm = 1.7614, lr_0 = 1.0200e-04
Loss = 5.1848e-04, PNorm = 38.4480, GNorm = 1.5661, lr_0 = 1.0200e-04
Loss = 5.0621e-04, PNorm = 38.4504, GNorm = 1.7059, lr_0 = 1.0200e-04
Loss = 5.3358e-04, PNorm = 38.4515, GNorm = 1.3044, lr_0 = 1.0200e-04
Loss = 6.3829e-04, PNorm = 38.4531, GNorm = 1.3552, lr_0 = 1.0200e-04
Loss = 6.2058e-04, PNorm = 38.4546, GNorm = 1.3023, lr_0 = 1.0200e-04
Loss = 5.7945e-04, PNorm = 38.4551, GNorm = 1.2028, lr_0 = 1.0200e-04
Loss = 5.4010e-04, PNorm = 38.4553, GNorm = 0.9259, lr_0 = 1.0200e-04
Loss = 5.0011e-04, PNorm = 38.4565, GNorm = 1.0356, lr_0 = 1.0200e-04
Loss = 5.6189e-04, PNorm = 38.4582, GNorm = 2.7800, lr_0 = 1.0200e-04
Loss = 6.0214e-04, PNorm = 38.4593, GNorm = 1.3145, lr_0 = 1.0200e-04
Loss = 5.5104e-04, PNorm = 38.4611, GNorm = 2.5250, lr_0 = 1.0200e-04
Loss = 5.6220e-04, PNorm = 38.4628, GNorm = 1.7866, lr_0 = 1.0200e-04
Loss = 6.8950e-04, PNorm = 38.4641, GNorm = 3.2285, lr_0 = 1.0200e-04
Loss = 7.1660e-04, PNorm = 38.4662, GNorm = 1.8891, lr_0 = 1.0200e-04
Validation rmse logD = 0.630583
Validation R2 logD = 0.721902
Validation rmse logP = 0.473640
Validation R2 logP = 0.938245
Epoch 73
Train function
Loss = 5.9230e-04, PNorm = 38.4676, GNorm = 3.1044, lr_0 = 1.0200e-04
Loss = 5.7290e-04, PNorm = 38.4696, GNorm = 1.2358, lr_0 = 1.0200e-04
Loss = 5.7228e-04, PNorm = 38.4712, GNorm = 0.6420, lr_0 = 1.0200e-04
Loss = 5.1663e-04, PNorm = 38.4728, GNorm = 2.1245, lr_0 = 1.0200e-04
Loss = 5.5627e-04, PNorm = 38.4737, GNorm = 1.3710, lr_0 = 1.0200e-04
Loss = 4.9709e-04, PNorm = 38.4745, GNorm = 1.1921, lr_0 = 1.0200e-04
Loss = 6.9809e-04, PNorm = 38.4781, GNorm = 1.4488, lr_0 = 1.0200e-04
Loss = 5.4690e-04, PNorm = 38.4800, GNorm = 1.3955, lr_0 = 1.0200e-04
Loss = 4.8721e-04, PNorm = 38.4814, GNorm = 0.9764, lr_0 = 1.0200e-04
Loss = 4.6281e-04, PNorm = 38.4831, GNorm = 1.5517, lr_0 = 1.0200e-04
Loss = 5.1732e-04, PNorm = 38.4852, GNorm = 1.6475, lr_0 = 1.0200e-04
Loss = 3.8814e-04, PNorm = 38.4864, GNorm = 0.8275, lr_0 = 1.0200e-04
Loss = 5.5266e-04, PNorm = 38.4874, GNorm = 3.3115, lr_0 = 1.0200e-04
Loss = 6.5787e-04, PNorm = 38.4895, GNorm = 3.1377, lr_0 = 1.0200e-04
Loss = 6.9235e-04, PNorm = 38.4921, GNorm = 2.1059, lr_0 = 1.0200e-04
Loss = 8.0166e-04, PNorm = 38.4943, GNorm = 3.1845, lr_0 = 1.0200e-04
Loss = 7.7179e-04, PNorm = 38.4953, GNorm = 3.2178, lr_0 = 1.0200e-04
Loss = 7.2729e-04, PNorm = 38.4961, GNorm = 1.1060, lr_0 = 1.0200e-04
Loss = 5.1984e-04, PNorm = 38.4968, GNorm = 1.0558, lr_0 = 1.0200e-04
Loss = 4.6955e-04, PNorm = 38.4992, GNorm = 0.5066, lr_0 = 1.0200e-04
Loss = 5.6665e-04, PNorm = 38.5004, GNorm = 1.2806, lr_0 = 1.0200e-04
Loss = 5.0063e-04, PNorm = 38.5020, GNorm = 2.4119, lr_0 = 1.0200e-04
Validation rmse logD = 0.628125
Validation R2 logD = 0.724067
Validation rmse logP = 0.508993
Validation R2 logP = 0.928682
Epoch 74
Train function
Loss = 6.6244e-04, PNorm = 38.5035, GNorm = 2.6963, lr_0 = 1.0200e-04
Loss = 4.1525e-04, PNorm = 38.5047, GNorm = 1.3387, lr_0 = 1.0200e-04
Loss = 4.7034e-04, PNorm = 38.5062, GNorm = 1.8372, lr_0 = 1.0200e-04
Loss = 4.6994e-04, PNorm = 38.5078, GNorm = 3.7645, lr_0 = 1.0200e-04
Loss = 5.3293e-04, PNorm = 38.5089, GNorm = 3.2230, lr_0 = 1.0200e-04
Loss = 5.5292e-04, PNorm = 38.5104, GNorm = 1.4781, lr_0 = 1.0200e-04
Loss = 4.2547e-04, PNorm = 38.5118, GNorm = 0.8134, lr_0 = 1.0200e-04
Loss = 4.7404e-04, PNorm = 38.5131, GNorm = 1.0152, lr_0 = 1.0200e-04
Loss = 5.3838e-04, PNorm = 38.5140, GNorm = 1.2299, lr_0 = 1.0200e-04
Loss = 5.8304e-04, PNorm = 38.5151, GNorm = 3.4751, lr_0 = 1.0200e-04
Loss = 5.4936e-04, PNorm = 38.5167, GNorm = 2.1032, lr_0 = 1.0200e-04
Loss = 5.3413e-04, PNorm = 38.5175, GNorm = 2.9796, lr_0 = 1.0200e-04
Loss = 5.0124e-04, PNorm = 38.5196, GNorm = 1.6016, lr_0 = 1.0200e-04
Loss = 6.1590e-04, PNorm = 38.5201, GNorm = 2.0660, lr_0 = 1.0200e-04
Loss = 5.1167e-04, PNorm = 38.5217, GNorm = 3.5133, lr_0 = 1.0200e-04
Loss = 4.7665e-04, PNorm = 38.5234, GNorm = 1.9827, lr_0 = 1.0200e-04
Loss = 5.3479e-04, PNorm = 38.5246, GNorm = 1.2400, lr_0 = 1.0200e-04
Loss = 6.2677e-04, PNorm = 38.5265, GNorm = 1.2035, lr_0 = 1.0200e-04
Loss = 6.3642e-04, PNorm = 38.5284, GNorm = 2.5081, lr_0 = 1.0200e-04
Loss = 6.1439e-04, PNorm = 38.5289, GNorm = 1.8185, lr_0 = 1.0200e-04
Loss = 6.7002e-04, PNorm = 38.5308, GNorm = 2.3159, lr_0 = 1.0200e-04
Loss = 7.0501e-04, PNorm = 38.5330, GNorm = 2.8804, lr_0 = 1.0200e-04
Loss = 5.8789e-04, PNorm = 38.5345, GNorm = 4.2856, lr_0 = 1.0200e-04
Validation rmse logD = 0.628209
Validation R2 logD = 0.723992
Validation rmse logP = 0.474082
Validation R2 logP = 0.938130
Epoch 75
Train function
Loss = 5.8684e-04, PNorm = 38.5356, GNorm = 1.1542, lr_0 = 1.0200e-04
Loss = 4.2465e-04, PNorm = 38.5365, GNorm = 1.0080, lr_0 = 1.0200e-04
Loss = 4.0224e-04, PNorm = 38.5376, GNorm = 1.2773, lr_0 = 1.0200e-04
Loss = 5.1682e-04, PNorm = 38.5392, GNorm = 1.8725, lr_0 = 1.0200e-04
Loss = 5.5356e-04, PNorm = 38.5405, GNorm = 2.2787, lr_0 = 1.0200e-04
Loss = 5.9702e-04, PNorm = 38.5404, GNorm = 2.3917, lr_0 = 1.0200e-04
Loss = 5.8938e-04, PNorm = 38.5428, GNorm = 2.0289, lr_0 = 1.0200e-04
Loss = 5.9286e-04, PNorm = 38.5445, GNorm = 2.2657, lr_0 = 1.0200e-04
Loss = 5.8850e-04, PNorm = 38.5451, GNorm = 1.0304, lr_0 = 1.0200e-04
Loss = 5.1395e-04, PNorm = 38.5464, GNorm = 3.9675, lr_0 = 1.0200e-04
Loss = 5.3018e-04, PNorm = 38.5486, GNorm = 1.5035, lr_0 = 1.0200e-04
Loss = 5.9212e-04, PNorm = 38.5502, GNorm = 1.8325, lr_0 = 1.0200e-04
Loss = 6.6964e-04, PNorm = 38.5522, GNorm = 1.7011, lr_0 = 1.0200e-04
Loss = 5.2523e-04, PNorm = 38.5548, GNorm = 1.1044, lr_0 = 1.0200e-04
Loss = 5.2035e-04, PNorm = 38.5562, GNorm = 0.7178, lr_0 = 1.0200e-04
Loss = 6.9276e-04, PNorm = 38.5576, GNorm = 3.0102, lr_0 = 1.0200e-04
Loss = 6.0403e-04, PNorm = 38.5596, GNorm = 1.2698, lr_0 = 1.0200e-04
Loss = 5.2500e-04, PNorm = 38.5609, GNorm = 1.5447, lr_0 = 1.0200e-04
Loss = 6.4072e-04, PNorm = 38.5635, GNorm = 0.9083, lr_0 = 1.0200e-04
Loss = 5.5689e-04, PNorm = 38.5655, GNorm = 0.9843, lr_0 = 1.0200e-04
Loss = 4.8533e-04, PNorm = 38.5669, GNorm = 1.1566, lr_0 = 1.0200e-04
Loss = 4.9853e-04, PNorm = 38.5679, GNorm = 1.0134, lr_0 = 1.0200e-04
Validation rmse logD = 0.618696
Validation R2 logD = 0.732289
Validation rmse logP = 0.499314
Validation R2 logP = 0.931369
Epoch 76
Train function
Loss = 4.7472e-04, PNorm = 38.5693, GNorm = 1.2671, lr_0 = 1.0200e-04
Loss = 6.6136e-04, PNorm = 38.5709, GNorm = 1.1995, lr_0 = 1.0200e-04
Loss = 7.6272e-04, PNorm = 38.5721, GNorm = 4.0658, lr_0 = 1.0200e-04
Loss = 7.0175e-04, PNorm = 38.5738, GNorm = 1.7471, lr_0 = 1.0200e-04
Loss = 5.3282e-04, PNorm = 38.5756, GNorm = 2.6379, lr_0 = 1.0200e-04
Loss = 4.5346e-04, PNorm = 38.5771, GNorm = 2.1241, lr_0 = 1.0200e-04
Loss = 6.1054e-04, PNorm = 38.5780, GNorm = 2.6555, lr_0 = 1.0200e-04
Loss = 4.8685e-04, PNorm = 38.5793, GNorm = 2.6848, lr_0 = 1.0200e-04
Loss = 4.8417e-04, PNorm = 38.5806, GNorm = 1.7568, lr_0 = 1.0200e-04
Loss = 5.4932e-04, PNorm = 38.5827, GNorm = 1.7848, lr_0 = 1.0200e-04
Loss = 5.7612e-04, PNorm = 38.5851, GNorm = 1.1639, lr_0 = 1.0200e-04
Loss = 4.5181e-04, PNorm = 38.5858, GNorm = 0.7890, lr_0 = 1.0200e-04
Loss = 6.0804e-04, PNorm = 38.5873, GNorm = 2.4527, lr_0 = 1.0200e-04
Loss = 5.4920e-04, PNorm = 38.5886, GNorm = 1.1705, lr_0 = 1.0200e-04
Loss = 4.9733e-04, PNorm = 38.5905, GNorm = 1.6117, lr_0 = 1.0200e-04
Loss = 5.0985e-04, PNorm = 38.5921, GNorm = 1.3146, lr_0 = 1.0200e-04
Loss = 5.5701e-04, PNorm = 38.5938, GNorm = 2.1096, lr_0 = 1.0200e-04
Loss = 5.3307e-04, PNorm = 38.5949, GNorm = 1.1112, lr_0 = 1.0200e-04
Loss = 5.6008e-04, PNorm = 38.5958, GNorm = 2.4122, lr_0 = 1.0200e-04
Loss = 6.3642e-04, PNorm = 38.5967, GNorm = 1.2854, lr_0 = 1.0200e-04
Loss = 5.0738e-04, PNorm = 38.5980, GNorm = 2.2772, lr_0 = 1.0200e-04
Loss = 5.6531e-04, PNorm = 38.5999, GNorm = 1.6216, lr_0 = 1.0200e-04
Loss = 6.5357e-04, PNorm = 38.6016, GNorm = 1.4482, lr_0 = 1.0200e-04
Validation rmse logD = 0.610757
Validation R2 logD = 0.739115
Validation rmse logP = 0.472124
Validation R2 logP = 0.938640
Epoch 77
Train function
Loss = 5.6297e-04, PNorm = 38.6033, GNorm = 2.4695, lr_0 = 1.0200e-04
Loss = 4.9430e-04, PNorm = 38.6048, GNorm = 1.2970, lr_0 = 1.0200e-04
Loss = 4.9043e-04, PNorm = 38.6067, GNorm = 1.8180, lr_0 = 1.0200e-04
Loss = 4.9844e-04, PNorm = 38.6078, GNorm = 1.4383, lr_0 = 1.0200e-04
Loss = 4.7292e-04, PNorm = 38.6094, GNorm = 1.7666, lr_0 = 1.0200e-04
Loss = 4.3369e-04, PNorm = 38.6109, GNorm = 1.2995, lr_0 = 1.0200e-04
Loss = 6.5851e-04, PNorm = 38.6124, GNorm = 2.2403, lr_0 = 1.0200e-04
Loss = 4.5236e-04, PNorm = 38.6139, GNorm = 1.9917, lr_0 = 1.0200e-04
Loss = 4.7421e-04, PNorm = 38.6148, GNorm = 1.7235, lr_0 = 1.0200e-04
Loss = 5.1790e-04, PNorm = 38.6157, GNorm = 1.2008, lr_0 = 1.0200e-04
Loss = 5.6204e-04, PNorm = 38.6161, GNorm = 2.7901, lr_0 = 1.0200e-04
Loss = 3.6492e-04, PNorm = 38.6175, GNorm = 1.7473, lr_0 = 1.0200e-04
Loss = 4.2408e-04, PNorm = 38.6184, GNorm = 1.3781, lr_0 = 1.0200e-04
Loss = 5.2318e-04, PNorm = 38.6195, GNorm = 1.2822, lr_0 = 1.0200e-04
Loss = 5.8513e-04, PNorm = 38.6209, GNorm = 1.5978, lr_0 = 1.0200e-04
Loss = 4.2480e-04, PNorm = 38.6217, GNorm = 2.3200, lr_0 = 1.0200e-04
Loss = 5.0301e-04, PNorm = 38.6232, GNorm = 1.2127, lr_0 = 1.0200e-04
Loss = 6.5158e-04, PNorm = 38.6251, GNorm = 1.4065, lr_0 = 1.0200e-04
Loss = 5.4763e-04, PNorm = 38.6269, GNorm = 1.4222, lr_0 = 1.0200e-04
Loss = 4.5392e-04, PNorm = 38.6286, GNorm = 1.6298, lr_0 = 1.0200e-04
Loss = 4.3239e-04, PNorm = 38.6299, GNorm = 1.2025, lr_0 = 1.0200e-04
Loss = 4.9557e-04, PNorm = 38.6313, GNorm = 1.9611, lr_0 = 1.0200e-04
Validation rmse logD = 0.605745
Validation R2 logD = 0.743379
Validation rmse logP = 0.478273
Validation R2 logP = 0.937031
Epoch 78
Train function
Loss = 5.0042e-04, PNorm = 38.6325, GNorm = 1.2694, lr_0 = 1.0200e-04
Loss = 5.3821e-04, PNorm = 38.6341, GNorm = 2.4648, lr_0 = 1.0200e-04
Loss = 5.6174e-04, PNorm = 38.6358, GNorm = 2.4421, lr_0 = 1.0200e-04
Loss = 3.9241e-04, PNorm = 38.6381, GNorm = 2.6959, lr_0 = 1.0200e-04
Loss = 5.8180e-04, PNorm = 38.6398, GNorm = 2.1605, lr_0 = 1.0200e-04
Loss = 4.0742e-04, PNorm = 38.6412, GNorm = 1.6416, lr_0 = 1.0200e-04
Loss = 5.2842e-04, PNorm = 38.6429, GNorm = 1.3177, lr_0 = 1.0200e-04
Loss = 3.9451e-04, PNorm = 38.6441, GNorm = 1.4581, lr_0 = 1.0200e-04
Loss = 5.0281e-04, PNorm = 38.6456, GNorm = 1.5047, lr_0 = 1.0200e-04
Loss = 5.3817e-04, PNorm = 38.6465, GNorm = 1.8308, lr_0 = 1.0200e-04
Loss = 5.6462e-04, PNorm = 38.6475, GNorm = 0.7694, lr_0 = 1.0200e-04
Loss = 4.6372e-04, PNorm = 38.6485, GNorm = 1.2748, lr_0 = 1.0200e-04
Loss = 4.0985e-04, PNorm = 38.6498, GNorm = 1.0441, lr_0 = 1.0200e-04
Loss = 5.3084e-04, PNorm = 38.6515, GNorm = 1.7372, lr_0 = 1.0200e-04
Loss = 5.1274e-04, PNorm = 38.6525, GNorm = 2.0546, lr_0 = 1.0200e-04
Loss = 4.2415e-04, PNorm = 38.6537, GNorm = 1.4150, lr_0 = 1.0200e-04
Loss = 5.0798e-04, PNorm = 38.6554, GNorm = 1.1742, lr_0 = 1.0200e-04
Loss = 5.0058e-04, PNorm = 38.6573, GNorm = 1.6200, lr_0 = 1.0200e-04
Loss = 5.4821e-04, PNorm = 38.6591, GNorm = 1.5033, lr_0 = 1.0200e-04
Loss = 5.1130e-04, PNorm = 38.6604, GNorm = 1.2803, lr_0 = 1.0200e-04
Loss = 4.9717e-04, PNorm = 38.6619, GNorm = 2.6449, lr_0 = 1.0200e-04
Loss = 4.6301e-04, PNorm = 38.6628, GNorm = 1.0440, lr_0 = 1.0200e-04
Loss = 4.5371e-04, PNorm = 38.6636, GNorm = 1.9032, lr_0 = 1.0200e-04
Validation rmse logD = 0.635906
Validation R2 logD = 0.717188
Validation rmse logP = 0.468763
Validation R2 logP = 0.939510
Epoch 79
Train function
Loss = 5.2127e-04, PNorm = 38.6649, GNorm = 2.5046, lr_0 = 1.0200e-04
Loss = 6.2962e-04, PNorm = 38.6669, GNorm = 1.2106, lr_0 = 1.0200e-04
Loss = 4.8490e-04, PNorm = 38.6688, GNorm = 1.2399, lr_0 = 1.0200e-04
Loss = 5.2174e-04, PNorm = 38.6707, GNorm = 2.4842, lr_0 = 1.0200e-04
Loss = 5.3177e-04, PNorm = 38.6723, GNorm = 1.5936, lr_0 = 1.0200e-04
Loss = 5.4422e-04, PNorm = 38.6734, GNorm = 2.4814, lr_0 = 1.0200e-04
Loss = 5.7988e-04, PNorm = 38.6738, GNorm = 1.3449, lr_0 = 1.0200e-04
Loss = 5.5094e-04, PNorm = 38.6753, GNorm = 2.4339, lr_0 = 1.0200e-04
Loss = 6.8091e-04, PNorm = 38.6773, GNorm = 2.5689, lr_0 = 1.0200e-04
Loss = 5.0406e-04, PNorm = 38.6785, GNorm = 1.1517, lr_0 = 1.0200e-04
Loss = 6.3409e-04, PNorm = 38.6795, GNorm = 1.9216, lr_0 = 1.0200e-04
Loss = 6.1702e-04, PNorm = 38.6807, GNorm = 1.7555, lr_0 = 1.0200e-04
Loss = 6.4364e-04, PNorm = 38.6823, GNorm = 2.4150, lr_0 = 1.0200e-04
Loss = 5.6881e-04, PNorm = 38.6843, GNorm = 2.1653, lr_0 = 1.0200e-04
Loss = 4.2410e-04, PNorm = 38.6862, GNorm = 2.3293, lr_0 = 1.0200e-04
Loss = 4.5499e-04, PNorm = 38.6883, GNorm = 1.7036, lr_0 = 1.0200e-04
Loss = 4.5567e-04, PNorm = 38.6896, GNorm = 1.1390, lr_0 = 1.0200e-04
Loss = 4.0564e-04, PNorm = 38.6909, GNorm = 0.8735, lr_0 = 1.0200e-04
Loss = 4.2780e-04, PNorm = 38.6923, GNorm = 0.8071, lr_0 = 1.0200e-04
Loss = 4.4417e-04, PNorm = 38.6936, GNorm = 1.2030, lr_0 = 1.0200e-04
Loss = 4.6451e-04, PNorm = 38.6940, GNorm = 1.9972, lr_0 = 1.0200e-04
Loss = 4.8683e-04, PNorm = 38.6952, GNorm = 1.4262, lr_0 = 1.0200e-04
Validation rmse logD = 0.620533
Validation R2 logD = 0.730696
Validation rmse logP = 0.463253
Validation R2 logP = 0.940924
Epoch 80
Train function
Loss = 4.6750e-04, PNorm = 38.6961, GNorm = 1.9131, lr_0 = 1.0200e-04
Loss = 4.0504e-04, PNorm = 38.6978, GNorm = 1.5606, lr_0 = 1.0200e-04
Loss = 3.5864e-04, PNorm = 38.6987, GNorm = 1.6573, lr_0 = 1.0200e-04
Loss = 4.6754e-04, PNorm = 38.6999, GNorm = 2.8037, lr_0 = 1.0200e-04
Loss = 4.1487e-04, PNorm = 38.7011, GNorm = 0.9504, lr_0 = 1.0200e-04
Loss = 5.3902e-04, PNorm = 38.7015, GNorm = 1.3675, lr_0 = 1.0200e-04
Loss = 5.4001e-04, PNorm = 38.7027, GNorm = 4.0701, lr_0 = 1.0200e-04
Loss = 5.1916e-04, PNorm = 38.7046, GNorm = 1.3410, lr_0 = 1.0200e-04
Loss = 5.2267e-04, PNorm = 38.7068, GNorm = 1.2459, lr_0 = 1.0200e-04
Loss = 4.5145e-04, PNorm = 38.7076, GNorm = 1.6271, lr_0 = 1.0200e-04
Loss = 4.2817e-04, PNorm = 38.7095, GNorm = 0.7894, lr_0 = 1.0200e-04
Loss = 4.1318e-04, PNorm = 38.7110, GNorm = 1.1370, lr_0 = 1.0200e-04
Loss = 5.0757e-04, PNorm = 38.7129, GNorm = 1.5689, lr_0 = 1.0200e-04
Loss = 5.3869e-04, PNorm = 38.7143, GNorm = 1.8972, lr_0 = 1.0200e-04
Loss = 4.4245e-04, PNorm = 38.7156, GNorm = 1.9955, lr_0 = 1.0200e-04
Loss = 4.2611e-04, PNorm = 38.7161, GNorm = 1.4120, lr_0 = 1.0200e-04
Loss = 4.7227e-04, PNorm = 38.7169, GNorm = 1.1039, lr_0 = 1.0200e-04
Loss = 4.9883e-04, PNorm = 38.7188, GNorm = 2.5967, lr_0 = 1.0200e-04
Loss = 5.0084e-04, PNorm = 38.7208, GNorm = 4.2017, lr_0 = 1.0200e-04
Loss = 4.7973e-04, PNorm = 38.7222, GNorm = 1.9570, lr_0 = 1.0200e-04
Loss = 6.3779e-04, PNorm = 38.7243, GNorm = 2.5514, lr_0 = 1.0200e-04
Loss = 5.4941e-04, PNorm = 38.7262, GNorm = 1.6079, lr_0 = 1.0200e-04
Loss = 8.8067e-04, PNorm = 38.7280, GNorm = 1.8066, lr_0 = 1.0200e-04
Validation rmse logD = 0.629987
Validation R2 logD = 0.722428
Validation rmse logP = 0.521536
Validation R2 logP = 0.925124
Epoch 81
Train function
Loss = 6.0935e-04, PNorm = 38.7286, GNorm = 1.4891, lr_0 = 1.0200e-04
Loss = 4.7672e-04, PNorm = 38.7303, GNorm = 0.8842, lr_0 = 1.0200e-04
Loss = 4.1406e-04, PNorm = 38.7311, GNorm = 1.5391, lr_0 = 1.0200e-04
Loss = 4.9950e-04, PNorm = 38.7319, GNorm = 2.8154, lr_0 = 1.0200e-04
Loss = 4.6841e-04, PNorm = 38.7339, GNorm = 1.0411, lr_0 = 1.0200e-04
Loss = 5.1565e-04, PNorm = 38.7343, GNorm = 1.6974, lr_0 = 1.0200e-04
Loss = 5.4997e-04, PNorm = 38.7372, GNorm = 3.0744, lr_0 = 1.0200e-04
Loss = 4.4078e-04, PNorm = 38.7392, GNorm = 1.6472, lr_0 = 1.0200e-04
Loss = 3.8026e-04, PNorm = 38.7400, GNorm = 1.4621, lr_0 = 1.0200e-04
Loss = 5.5369e-04, PNorm = 38.7416, GNorm = 2.0924, lr_0 = 1.0200e-04
Loss = 4.9418e-04, PNorm = 38.7426, GNorm = 1.8413, lr_0 = 1.0200e-04
Loss = 4.6547e-04, PNorm = 38.7446, GNorm = 3.4495, lr_0 = 1.0200e-04
Loss = 4.6405e-04, PNorm = 38.7457, GNorm = 1.5149, lr_0 = 1.0200e-04
Loss = 4.6705e-04, PNorm = 38.7473, GNorm = 0.8164, lr_0 = 1.0200e-04
Loss = 4.5137e-04, PNorm = 38.7488, GNorm = 0.9794, lr_0 = 1.0200e-04
Loss = 4.3850e-04, PNorm = 38.7491, GNorm = 1.3966, lr_0 = 1.0200e-04
Loss = 3.7598e-04, PNorm = 38.7503, GNorm = 1.0031, lr_0 = 1.0200e-04
Loss = 4.1532e-04, PNorm = 38.7517, GNorm = 1.2648, lr_0 = 1.0200e-04
Loss = 6.0891e-04, PNorm = 38.7540, GNorm = 3.2645, lr_0 = 1.0200e-04
Loss = 8.2551e-04, PNorm = 38.7542, GNorm = 1.3931, lr_0 = 1.0200e-04
Loss = 7.6801e-04, PNorm = 38.7559, GNorm = 3.1137, lr_0 = 1.0200e-04
Loss = 6.0940e-04, PNorm = 38.7579, GNorm = 1.6665, lr_0 = 1.0200e-04
Validation rmse logD = 0.629116
Validation R2 logD = 0.723195
Validation rmse logP = 0.470544
Validation R2 logP = 0.939050
Epoch 82
Train function
Loss = 4.1419e-04, PNorm = 38.7597, GNorm = 1.2069, lr_0 = 1.0200e-04
Loss = 4.7540e-04, PNorm = 38.7620, GNorm = 0.9772, lr_0 = 1.0200e-04
Loss = 3.3697e-04, PNorm = 38.7640, GNorm = 1.1300, lr_0 = 1.0200e-04
Loss = 4.3580e-04, PNorm = 38.7648, GNorm = 1.3449, lr_0 = 1.0200e-04
Loss = 4.6585e-04, PNorm = 38.7659, GNorm = 1.2884, lr_0 = 1.0200e-04
Loss = 3.7339e-04, PNorm = 38.7670, GNorm = 1.2019, lr_0 = 1.0200e-04
Loss = 5.4067e-04, PNorm = 38.7682, GNorm = 1.0789, lr_0 = 1.0200e-04
Loss = 4.5475e-04, PNorm = 38.7694, GNorm = 0.7174, lr_0 = 1.0200e-04
Loss = 5.2394e-04, PNorm = 38.7710, GNorm = 2.8137, lr_0 = 1.0200e-04
Loss = 4.4172e-04, PNorm = 38.7725, GNorm = 1.3626, lr_0 = 1.0200e-04
Loss = 4.6383e-04, PNorm = 38.7742, GNorm = 0.9904, lr_0 = 1.0200e-04
Loss = 4.3412e-04, PNorm = 38.7757, GNorm = 0.9791, lr_0 = 1.0200e-04
Loss = 4.8513e-04, PNorm = 38.7766, GNorm = 0.9506, lr_0 = 1.0200e-04
Loss = 3.8549e-04, PNorm = 38.7781, GNorm = 1.3295, lr_0 = 1.0200e-04
Loss = 3.5597e-04, PNorm = 38.7792, GNorm = 0.5445, lr_0 = 1.0200e-04
Loss = 4.9532e-04, PNorm = 38.7807, GNorm = 1.3004, lr_0 = 1.0200e-04
Loss = 4.5927e-04, PNorm = 38.7825, GNorm = 1.9430, lr_0 = 1.0200e-04
Loss = 5.5543e-04, PNorm = 38.7836, GNorm = 1.0833, lr_0 = 1.0200e-04
Loss = 5.1548e-04, PNorm = 38.7847, GNorm = 2.7773, lr_0 = 1.0200e-04
Loss = 5.5091e-04, PNorm = 38.7855, GNorm = 2.1638, lr_0 = 1.0200e-04
Loss = 5.6618e-04, PNorm = 38.7865, GNorm = 1.7636, lr_0 = 1.0200e-04
Loss = 4.3025e-04, PNorm = 38.7875, GNorm = 2.5264, lr_0 = 1.0200e-04
Loss = 4.3378e-04, PNorm = 38.7883, GNorm = 1.2027, lr_0 = 1.0200e-04
Validation rmse logD = 0.616571
Validation R2 logD = 0.734125
Validation rmse logP = 0.465864
Validation R2 logP = 0.940256
Epoch 83
Train function
Loss = 3.1188e-04, PNorm = 38.7895, GNorm = 1.2467, lr_0 = 1.0200e-04
Loss = 3.8622e-04, PNorm = 38.7913, GNorm = 0.8853, lr_0 = 1.0200e-04
Loss = 4.3338e-04, PNorm = 38.7934, GNorm = 2.0103, lr_0 = 1.0200e-04
Loss = 4.1527e-04, PNorm = 38.7942, GNorm = 0.5982, lr_0 = 1.0200e-04
Loss = 4.9483e-04, PNorm = 38.7944, GNorm = 2.4039, lr_0 = 1.0200e-04
Loss = 5.5733e-04, PNorm = 38.7957, GNorm = 0.9044, lr_0 = 1.0200e-04
Loss = 4.5453e-04, PNorm = 38.7966, GNorm = 1.4217, lr_0 = 1.0200e-04
Loss = 4.1787e-04, PNorm = 38.7985, GNorm = 1.4712, lr_0 = 1.0200e-04
Loss = 5.2220e-04, PNorm = 38.8000, GNorm = 1.7007, lr_0 = 1.0200e-04
Loss = 4.0521e-04, PNorm = 38.8013, GNorm = 1.0352, lr_0 = 1.0200e-04
Loss = 4.4040e-04, PNorm = 38.8021, GNorm = 1.0076, lr_0 = 1.0200e-04
Loss = 5.4140e-04, PNorm = 38.8032, GNorm = 3.6399, lr_0 = 1.0200e-04
Loss = 4.8644e-04, PNorm = 38.8052, GNorm = 3.2529, lr_0 = 1.0200e-04
Loss = 5.7016e-04, PNorm = 38.8074, GNorm = 1.7421, lr_0 = 1.0200e-04
Loss = 5.3103e-04, PNorm = 38.8089, GNorm = 0.9648, lr_0 = 1.0200e-04
Loss = 4.5724e-04, PNorm = 38.8102, GNorm = 0.6709, lr_0 = 1.0200e-04
Loss = 4.5916e-04, PNorm = 38.8119, GNorm = 1.2007, lr_0 = 1.0200e-04
Loss = 5.8065e-04, PNorm = 38.8138, GNorm = 1.7576, lr_0 = 1.0200e-04
Loss = 4.3851e-04, PNorm = 38.8157, GNorm = 2.8571, lr_0 = 1.0200e-04
Loss = 3.5716e-04, PNorm = 38.8175, GNorm = 0.6602, lr_0 = 1.0200e-04
Loss = 5.0199e-04, PNorm = 38.8198, GNorm = 1.1028, lr_0 = 1.0200e-04
Loss = 3.5732e-04, PNorm = 38.8209, GNorm = 0.7813, lr_0 = 1.0200e-04
Loss = 4.4029e-04, PNorm = 38.8218, GNorm = 1.5700, lr_0 = 1.0200e-04
Validation rmse logD = 0.701146
Validation R2 logD = 0.656181
Validation rmse logP = 0.477578
Validation R2 logP = 0.937214
Epoch 84
Train function
Loss = 5.5335e-04, PNorm = 38.8230, GNorm = 2.0455, lr_0 = 1.0200e-04
Loss = 4.0879e-04, PNorm = 38.8245, GNorm = 1.4463, lr_0 = 1.0200e-04
Loss = 4.2127e-04, PNorm = 38.8264, GNorm = 0.6209, lr_0 = 1.0200e-04
Loss = 3.7593e-04, PNorm = 38.8274, GNorm = 1.5799, lr_0 = 1.0200e-04
Loss = 3.8069e-04, PNorm = 38.8287, GNorm = 1.2095, lr_0 = 1.0200e-04
Loss = 4.0826e-04, PNorm = 38.8296, GNorm = 0.6763, lr_0 = 1.0200e-04
Loss = 6.0754e-04, PNorm = 38.8309, GNorm = 1.0663, lr_0 = 1.0200e-04
Loss = 4.7483e-04, PNorm = 38.8333, GNorm = 1.8083, lr_0 = 1.0200e-04
Loss = 5.8903e-04, PNorm = 38.8339, GNorm = 1.7962, lr_0 = 1.0200e-04
Loss = 4.4834e-04, PNorm = 38.8357, GNorm = 1.0072, lr_0 = 1.0200e-04
Loss = 4.8425e-04, PNorm = 38.8377, GNorm = 2.0728, lr_0 = 1.0200e-04
Loss = 3.9682e-04, PNorm = 38.8389, GNorm = 2.5769, lr_0 = 1.0200e-04
Loss = 3.8555e-04, PNorm = 38.8401, GNorm = 1.9389, lr_0 = 1.0200e-04
Loss = 3.9548e-04, PNorm = 38.8411, GNorm = 1.7355, lr_0 = 1.0200e-04
Loss = 3.9359e-04, PNorm = 38.8424, GNorm = 1.2542, lr_0 = 1.0200e-04
Loss = 4.5929e-04, PNorm = 38.8436, GNorm = 1.1127, lr_0 = 1.0200e-04
Loss = 3.8560e-04, PNorm = 38.8457, GNorm = 0.9355, lr_0 = 1.0200e-04
Loss = 3.5525e-04, PNorm = 38.8474, GNorm = 1.6346, lr_0 = 1.0200e-04
Loss = 4.0012e-04, PNorm = 38.8486, GNorm = 0.9478, lr_0 = 1.0200e-04
Loss = 4.6464e-04, PNorm = 38.8492, GNorm = 1.4406, lr_0 = 1.0200e-04
Loss = 5.4484e-04, PNorm = 38.8490, GNorm = 1.6239, lr_0 = 1.0200e-04
Loss = 4.0781e-04, PNorm = 38.8500, GNorm = 0.7367, lr_0 = 1.0200e-04
Validation rmse logD = 0.617431
Validation R2 logD = 0.733382
Validation rmse logP = 0.470471
Validation R2 logP = 0.939069
Epoch 85
Train function
Loss = 5.1351e-04, PNorm = 38.8517, GNorm = 1.5526, lr_0 = 1.0200e-04
Loss = 4.2376e-04, PNorm = 38.8522, GNorm = 2.3597, lr_0 = 1.0200e-04
Loss = 3.6754e-04, PNorm = 38.8529, GNorm = 1.7430, lr_0 = 1.0200e-04
Loss = 3.7806e-04, PNorm = 38.8541, GNorm = 1.1225, lr_0 = 1.0200e-04
Loss = 3.8521e-04, PNorm = 38.8553, GNorm = 1.3564, lr_0 = 1.0200e-04
Loss = 3.5908e-04, PNorm = 38.8565, GNorm = 0.8674, lr_0 = 1.0200e-04
Loss = 3.8657e-04, PNorm = 38.8584, GNorm = 1.4018, lr_0 = 1.0200e-04
Loss = 3.6065e-04, PNorm = 38.8595, GNorm = 0.6892, lr_0 = 1.0200e-04
Loss = 4.9964e-04, PNorm = 38.8611, GNorm = 3.0998, lr_0 = 1.0200e-04
Loss = 4.0408e-04, PNorm = 38.8623, GNorm = 2.0714, lr_0 = 1.0200e-04
Loss = 4.3064e-04, PNorm = 38.8635, GNorm = 2.1987, lr_0 = 1.0200e-04
Loss = 4.5353e-04, PNorm = 38.8641, GNorm = 1.8143, lr_0 = 1.0200e-04
Loss = 4.6033e-04, PNorm = 38.8658, GNorm = 1.6935, lr_0 = 1.0200e-04
Loss = 4.3824e-04, PNorm = 38.8678, GNorm = 1.2297, lr_0 = 1.0200e-04
Loss = 3.7708e-04, PNorm = 38.8699, GNorm = 1.0256, lr_0 = 1.0200e-04
Loss = 5.8455e-04, PNorm = 38.8716, GNorm = 0.8022, lr_0 = 1.0200e-04
Loss = 4.0954e-04, PNorm = 38.8731, GNorm = 1.9671, lr_0 = 1.0200e-04
Loss = 4.4434e-04, PNorm = 38.8742, GNorm = 1.5716, lr_0 = 1.0200e-04
Loss = 4.8714e-04, PNorm = 38.8751, GNorm = 2.6940, lr_0 = 1.0200e-04
Loss = 4.6079e-04, PNorm = 38.8748, GNorm = 1.8188, lr_0 = 1.0200e-04
Loss = 6.0502e-04, PNorm = 38.8765, GNorm = 0.6420, lr_0 = 1.0200e-04
Loss = 5.1880e-04, PNorm = 38.8787, GNorm = 1.6769, lr_0 = 1.0200e-04
Loss = 5.5390e-04, PNorm = 38.8803, GNorm = 1.1791, lr_0 = 1.0200e-04
Validation rmse logD = 0.641812
Validation R2 logD = 0.711911
Validation rmse logP = 0.470429
Validation R2 logP = 0.939080
Epoch 86
Train function
Loss = 4.3209e-04, PNorm = 38.8808, GNorm = 3.2098, lr_0 = 1.0200e-04
Loss = 3.7655e-04, PNorm = 38.8818, GNorm = 1.2347, lr_0 = 1.0200e-04
Loss = 3.7970e-04, PNorm = 38.8836, GNorm = 0.9523, lr_0 = 1.0200e-04
Loss = 4.0691e-04, PNorm = 38.8851, GNorm = 1.4707, lr_0 = 1.0200e-04
Loss = 4.2691e-04, PNorm = 38.8866, GNorm = 1.0586, lr_0 = 1.0200e-04
Loss = 3.9429e-04, PNorm = 38.8876, GNorm = 3.2358, lr_0 = 1.0200e-04
Loss = 4.3009e-04, PNorm = 38.8893, GNorm = 1.2751, lr_0 = 1.0200e-04
Loss = 3.8980e-04, PNorm = 38.8907, GNorm = 1.2374, lr_0 = 1.0200e-04
Loss = 4.5219e-04, PNorm = 38.8916, GNorm = 0.9579, lr_0 = 1.0200e-04
Loss = 3.8689e-04, PNorm = 38.8931, GNorm = 0.5846, lr_0 = 1.0200e-04
Loss = 4.7956e-04, PNorm = 38.8949, GNorm = 0.6221, lr_0 = 1.0200e-04
Loss = 4.2591e-04, PNorm = 38.8963, GNorm = 3.5590, lr_0 = 1.0200e-04
Loss = 4.6930e-04, PNorm = 38.8978, GNorm = 1.2572, lr_0 = 1.0200e-04
Loss = 4.8429e-04, PNorm = 38.8994, GNorm = 4.8740, lr_0 = 1.0200e-04
Loss = 6.2855e-04, PNorm = 38.9010, GNorm = 2.7711, lr_0 = 1.0200e-04
Loss = 5.8516e-04, PNorm = 38.9014, GNorm = 1.7718, lr_0 = 1.0200e-04
Loss = 5.3958e-04, PNorm = 38.9029, GNorm = 1.0728, lr_0 = 1.0200e-04
Loss = 4.1304e-04, PNorm = 38.9045, GNorm = 1.3568, lr_0 = 1.0200e-04
Loss = 3.7359e-04, PNorm = 38.9065, GNorm = 0.6937, lr_0 = 1.0200e-04
Loss = 4.2784e-04, PNorm = 38.9076, GNorm = 2.1811, lr_0 = 1.0200e-04
Loss = 5.4711e-04, PNorm = 38.9096, GNorm = 0.8440, lr_0 = 1.0200e-04
Loss = 5.7433e-04, PNorm = 38.9112, GNorm = 1.6107, lr_0 = 1.0200e-04
Validation rmse logD = 0.645003
Validation R2 logD = 0.709038
Validation rmse logP = 0.462078
Validation R2 logP = 0.941223
Epoch 87
Train function
Loss = 3.9940e-04, PNorm = 38.9126, GNorm = 1.1742, lr_0 = 1.0200e-04
Loss = 5.1034e-04, PNorm = 38.9130, GNorm = 2.0934, lr_0 = 1.0200e-04
Loss = 4.0778e-04, PNorm = 38.9147, GNorm = 1.2898, lr_0 = 1.0200e-04
Loss = 3.8626e-04, PNorm = 38.9160, GNorm = 1.3764, lr_0 = 1.0200e-04
Loss = 4.4590e-04, PNorm = 38.9169, GNorm = 1.0054, lr_0 = 1.0200e-04
Loss = 3.7889e-04, PNorm = 38.9187, GNorm = 1.0482, lr_0 = 1.0200e-04
Loss = 3.9451e-04, PNorm = 38.9203, GNorm = 1.8995, lr_0 = 1.0200e-04
Loss = 4.0779e-04, PNorm = 38.9219, GNorm = 0.6073, lr_0 = 1.0200e-04
Loss = 4.0802e-04, PNorm = 38.9226, GNorm = 1.6404, lr_0 = 1.0200e-04
Loss = 4.0263e-04, PNorm = 38.9236, GNorm = 2.2669, lr_0 = 1.0200e-04
Loss = 4.2535e-04, PNorm = 38.9246, GNorm = 1.8336, lr_0 = 1.0200e-04
Loss = 5.8346e-04, PNorm = 38.9261, GNorm = 1.1996, lr_0 = 1.0200e-04
Loss = 3.5276e-04, PNorm = 38.9275, GNorm = 1.3097, lr_0 = 1.0200e-04
Loss = 4.2288e-04, PNorm = 38.9291, GNorm = 3.0193, lr_0 = 1.0200e-04
Loss = 4.0613e-04, PNorm = 38.9305, GNorm = 0.7999, lr_0 = 1.0200e-04
Loss = 4.8589e-04, PNorm = 38.9320, GNorm = 1.7078, lr_0 = 1.0200e-04
Loss = 3.9748e-04, PNorm = 38.9335, GNorm = 1.6682, lr_0 = 1.0200e-04
Loss = 3.6498e-04, PNorm = 38.9334, GNorm = 0.5552, lr_0 = 1.0200e-04
Loss = 4.3629e-04, PNorm = 38.9340, GNorm = 1.1638, lr_0 = 1.0200e-04
Loss = 3.5808e-04, PNorm = 38.9357, GNorm = 1.4028, lr_0 = 1.0200e-04
Loss = 3.6231e-04, PNorm = 38.9366, GNorm = 1.6171, lr_0 = 1.0200e-04
Loss = 4.5928e-04, PNorm = 38.9384, GNorm = 1.1391, lr_0 = 1.0200e-04
Loss = 4.2264e-04, PNorm = 38.9403, GNorm = 1.5235, lr_0 = 1.0200e-04
Validation rmse logD = 0.619571
Validation R2 logD = 0.731531
Validation rmse logP = 0.464063
Validation R2 logP = 0.940717
Epoch 88
Train function
Loss = 4.2429e-04, PNorm = 38.9410, GNorm = 1.9558, lr_0 = 1.0200e-04
Loss = 3.8638e-04, PNorm = 38.9422, GNorm = 0.8401, lr_0 = 1.0200e-04
Loss = 3.5208e-04, PNorm = 38.9432, GNorm = 1.0211, lr_0 = 1.0200e-04
Loss = 3.4534e-04, PNorm = 38.9441, GNorm = 1.8776, lr_0 = 1.0200e-04
Loss = 3.5370e-04, PNorm = 38.9449, GNorm = 2.1439, lr_0 = 1.0200e-04
Loss = 3.1883e-04, PNorm = 38.9462, GNorm = 1.3094, lr_0 = 1.0200e-04
Loss = 3.7968e-04, PNorm = 38.9469, GNorm = 2.7495, lr_0 = 1.0200e-04
Loss = 3.3301e-04, PNorm = 38.9477, GNorm = 0.6264, lr_0 = 1.0200e-04
Loss = 4.8051e-04, PNorm = 38.9480, GNorm = 2.0160, lr_0 = 1.0200e-04
Loss = 5.6675e-04, PNorm = 38.9494, GNorm = 2.7557, lr_0 = 1.0200e-04
Loss = 6.1623e-04, PNorm = 38.9511, GNorm = 4.3147, lr_0 = 1.0200e-04
Loss = 5.3954e-04, PNorm = 38.9530, GNorm = 1.9419, lr_0 = 1.0200e-04
Loss = 5.2709e-04, PNorm = 38.9550, GNorm = 1.3767, lr_0 = 1.0200e-04
Loss = 4.3693e-04, PNorm = 38.9561, GNorm = 1.6491, lr_0 = 1.0200e-04
Loss = 3.7645e-04, PNorm = 38.9578, GNorm = 0.7927, lr_0 = 1.0200e-04
Loss = 5.8728e-04, PNorm = 38.9594, GNorm = 4.6614, lr_0 = 1.0200e-04
Loss = 7.1849e-04, PNorm = 38.9585, GNorm = 1.5295, lr_0 = 1.0200e-04
Loss = 4.7937e-04, PNorm = 38.9612, GNorm = 1.8596, lr_0 = 1.0200e-04
Loss = 4.2487e-04, PNorm = 38.9629, GNorm = 0.6064, lr_0 = 1.0200e-04
Loss = 3.8283e-04, PNorm = 38.9640, GNorm = 1.9323, lr_0 = 1.0200e-04
Loss = 3.8692e-04, PNorm = 38.9647, GNorm = 2.2447, lr_0 = 1.0200e-04
Loss = 4.0953e-04, PNorm = 38.9662, GNorm = 1.2005, lr_0 = 1.0200e-04
Validation rmse logD = 0.609839
Validation R2 logD = 0.739899
Validation rmse logP = 0.465373
Validation R2 logP = 0.940382
Epoch 89
Train function
Loss = 3.9279e-04, PNorm = 38.9679, GNorm = 1.2868, lr_0 = 1.0200e-04
Loss = 3.3322e-04, PNorm = 38.9690, GNorm = 0.6728, lr_0 = 1.0200e-04
Loss = 3.9464e-04, PNorm = 38.9699, GNorm = 1.4008, lr_0 = 1.0200e-04
Loss = 3.0297e-04, PNorm = 38.9713, GNorm = 0.5386, lr_0 = 1.0200e-04
Loss = 4.1658e-04, PNorm = 38.9727, GNorm = 1.2167, lr_0 = 1.0200e-04
Loss = 4.0165e-04, PNorm = 38.9749, GNorm = 0.9261, lr_0 = 1.0200e-04
Loss = 3.5400e-04, PNorm = 38.9769, GNorm = 1.3359, lr_0 = 1.0200e-04
Loss = 4.2106e-04, PNorm = 38.9786, GNorm = 1.2860, lr_0 = 1.0200e-04
Loss = 4.3239e-04, PNorm = 38.9792, GNorm = 0.7804, lr_0 = 1.0200e-04
Loss = 3.5521e-04, PNorm = 38.9810, GNorm = 1.0810, lr_0 = 1.0200e-04
Loss = 4.2380e-04, PNorm = 38.9818, GNorm = 2.8345, lr_0 = 1.0200e-04
Loss = 3.6751e-04, PNorm = 38.9835, GNorm = 0.9011, lr_0 = 1.0200e-04
Loss = 4.2611e-04, PNorm = 38.9846, GNorm = 0.9752, lr_0 = 1.0200e-04
Loss = 4.1290e-04, PNorm = 38.9869, GNorm = 0.6621, lr_0 = 1.0200e-04
Loss = 4.5342e-04, PNorm = 38.9885, GNorm = 4.1963, lr_0 = 1.0200e-04
Loss = 4.3311e-04, PNorm = 38.9902, GNorm = 2.3778, lr_0 = 1.0200e-04
Loss = 4.6798e-04, PNorm = 38.9913, GNorm = 1.8488, lr_0 = 1.0200e-04
Loss = 4.6053e-04, PNorm = 38.9924, GNorm = 2.6178, lr_0 = 1.0200e-04
Loss = 4.0928e-04, PNorm = 38.9933, GNorm = 1.3685, lr_0 = 1.0200e-04
Loss = 4.1246e-04, PNorm = 38.9951, GNorm = 2.5761, lr_0 = 1.0200e-04
Loss = 3.5809e-04, PNorm = 38.9951, GNorm = 1.1106, lr_0 = 1.0200e-04
Loss = 3.9501e-04, PNorm = 38.9959, GNorm = 2.1341, lr_0 = 1.0200e-04
Loss = 4.7081e-04, PNorm = 38.9975, GNorm = 1.0493, lr_0 = 1.0200e-04
Validation rmse logD = 0.624414
Validation R2 logD = 0.727318
Validation rmse logP = 0.476821
Validation R2 logP = 0.937413
Epoch 90
Train function
Loss = 3.5791e-04, PNorm = 38.9987, GNorm = 1.3127, lr_0 = 1.0200e-04
Loss = 2.8504e-04, PNorm = 38.9992, GNorm = 1.3593, lr_0 = 1.0200e-04
Loss = 3.4642e-04, PNorm = 38.9999, GNorm = 1.0619, lr_0 = 1.0200e-04
Loss = 2.7634e-04, PNorm = 39.0005, GNorm = 1.3725, lr_0 = 1.0200e-04
Loss = 3.6786e-04, PNorm = 39.0013, GNorm = 1.0252, lr_0 = 1.0200e-04
Loss = 3.9143e-04, PNorm = 39.0033, GNorm = 0.9235, lr_0 = 1.0200e-04
Loss = 4.2286e-04, PNorm = 39.0043, GNorm = 4.3061, lr_0 = 1.0200e-04
Loss = 5.5936e-04, PNorm = 39.0054, GNorm = 2.5950, lr_0 = 1.0200e-04
Loss = 4.3809e-04, PNorm = 39.0072, GNorm = 0.9928, lr_0 = 1.0200e-04
Loss = 3.5101e-04, PNorm = 39.0084, GNorm = 1.3566, lr_0 = 1.0200e-04
Loss = 3.9903e-04, PNorm = 39.0097, GNorm = 1.7627, lr_0 = 1.0200e-04
Loss = 4.2863e-04, PNorm = 39.0110, GNorm = 1.4271, lr_0 = 1.0200e-04
Loss = 4.0683e-04, PNorm = 39.0124, GNorm = 0.8675, lr_0 = 1.0200e-04
Loss = 3.5339e-04, PNorm = 39.0145, GNorm = 0.8831, lr_0 = 1.0200e-04
Loss = 3.9208e-04, PNorm = 39.0153, GNorm = 1.1624, lr_0 = 1.0200e-04
Loss = 4.1172e-04, PNorm = 39.0160, GNorm = 1.8294, lr_0 = 1.0200e-04
Loss = 4.1336e-04, PNorm = 39.0174, GNorm = 0.9465, lr_0 = 1.0200e-04
Loss = 4.9154e-04, PNorm = 39.0191, GNorm = 0.7302, lr_0 = 1.0200e-04
Loss = 3.4420e-04, PNorm = 39.0204, GNorm = 0.7395, lr_0 = 1.0200e-04
Loss = 4.1142e-04, PNorm = 39.0218, GNorm = 1.1873, lr_0 = 1.0200e-04
Loss = 3.3413e-04, PNorm = 39.0230, GNorm = 1.2581, lr_0 = 1.0200e-04
Loss = 4.9368e-04, PNorm = 39.0239, GNorm = 0.9764, lr_0 = 1.0200e-04
Validation rmse logD = 0.613149
Validation R2 logD = 0.737068
Validation rmse logP = 0.466293
Validation R2 logP = 0.940146
Epoch 91
Train function
Loss = 3.1851e-04, PNorm = 39.0257, GNorm = 1.8614, lr_0 = 1.0200e-04
Loss = 4.1617e-04, PNorm = 39.0270, GNorm = 1.0276, lr_0 = 1.0200e-04
Loss = 3.2513e-04, PNorm = 39.0282, GNorm = 0.8008, lr_0 = 1.0200e-04
Loss = 3.4755e-04, PNorm = 39.0292, GNorm = 0.8212, lr_0 = 1.0200e-04
Loss = 4.0493e-04, PNorm = 39.0310, GNorm = 1.5464, lr_0 = 1.0200e-04
Loss = 4.8248e-04, PNorm = 39.0325, GNorm = 2.4997, lr_0 = 1.0200e-04
Loss = 4.0498e-04, PNorm = 39.0338, GNorm = 1.6421, lr_0 = 1.0200e-04
Loss = 3.9625e-04, PNorm = 39.0354, GNorm = 2.1135, lr_0 = 1.0200e-04
Loss = 4.9608e-04, PNorm = 39.0371, GNorm = 2.8919, lr_0 = 1.0200e-04
Loss = 4.5862e-04, PNorm = 39.0386, GNorm = 0.9925, lr_0 = 1.0200e-04
Loss = 3.9689e-04, PNorm = 39.0397, GNorm = 1.5316, lr_0 = 1.0200e-04
Loss = 4.4444e-04, PNorm = 39.0405, GNorm = 1.7559, lr_0 = 1.0200e-04
Loss = 3.3697e-04, PNorm = 39.0412, GNorm = 0.8972, lr_0 = 1.0200e-04
Loss = 3.6407e-04, PNorm = 39.0421, GNorm = 1.2655, lr_0 = 1.0200e-04
Loss = 4.3586e-04, PNorm = 39.0427, GNorm = 2.8151, lr_0 = 1.0200e-04
Loss = 3.6758e-04, PNorm = 39.0432, GNorm = 0.9898, lr_0 = 1.0200e-04
Loss = 4.2378e-04, PNorm = 39.0432, GNorm = 0.5992, lr_0 = 1.0200e-04
Loss = 4.9187e-04, PNorm = 39.0439, GNorm = 2.1188, lr_0 = 1.0200e-04
Loss = 4.1946e-04, PNorm = 39.0453, GNorm = 1.5382, lr_0 = 1.0200e-04
Loss = 3.7684e-04, PNorm = 39.0474, GNorm = 1.7155, lr_0 = 1.0200e-04
Loss = 5.6018e-04, PNorm = 39.0489, GNorm = 2.8004, lr_0 = 1.0200e-04
Loss = 3.6581e-04, PNorm = 39.0501, GNorm = 1.0042, lr_0 = 1.0200e-04
Loss = 3.7229e-04, PNorm = 39.0509, GNorm = 1.2626, lr_0 = 1.0200e-04
Validation rmse logD = 0.627959
Validation R2 logD = 0.724213
Validation rmse logP = 0.463653
Validation R2 logP = 0.940822
Epoch 92
Train function
Loss = 3.3304e-04, PNorm = 39.0523, GNorm = 1.2675, lr_0 = 1.0200e-04
Loss = 3.7999e-04, PNorm = 39.0530, GNorm = 1.4464, lr_0 = 1.0200e-04
Loss = 3.1185e-04, PNorm = 39.0537, GNorm = 0.6708, lr_0 = 1.0200e-04
Loss = 3.4799e-04, PNorm = 39.0547, GNorm = 0.8712, lr_0 = 1.0200e-04
Loss = 3.3481e-04, PNorm = 39.0560, GNorm = 1.4295, lr_0 = 1.0200e-04
Loss = 2.8590e-04, PNorm = 39.0575, GNorm = 1.2416, lr_0 = 1.0200e-04
Loss = 3.6629e-04, PNorm = 39.0586, GNorm = 1.3857, lr_0 = 1.0200e-04
Loss = 4.4168e-04, PNorm = 39.0600, GNorm = 2.2158, lr_0 = 1.0200e-04
Loss = 5.0057e-04, PNorm = 39.0612, GNorm = 1.7255, lr_0 = 1.0200e-04
Loss = 5.4498e-04, PNorm = 39.0628, GNorm = 1.9326, lr_0 = 1.0200e-04
Loss = 5.9931e-04, PNorm = 39.0646, GNorm = 2.4950, lr_0 = 1.0200e-04
Loss = 4.5118e-04, PNorm = 39.0653, GNorm = 2.4255, lr_0 = 1.0200e-04
Loss = 3.3750e-04, PNorm = 39.0669, GNorm = 1.2259, lr_0 = 1.0200e-04
Loss = 3.2260e-04, PNorm = 39.0681, GNorm = 1.5078, lr_0 = 1.0200e-04
Loss = 4.7539e-04, PNorm = 39.0693, GNorm = 2.0438, lr_0 = 1.0200e-04
Loss = 5.3338e-04, PNorm = 39.0698, GNorm = 4.3304, lr_0 = 1.0200e-04
Loss = 4.5770e-04, PNorm = 39.0706, GNorm = 2.8309, lr_0 = 1.0200e-04
Loss = 3.5512e-04, PNorm = 39.0715, GNorm = 0.9716, lr_0 = 1.0200e-04
Loss = 4.0142e-04, PNorm = 39.0740, GNorm = 1.8749, lr_0 = 1.0200e-04
Loss = 4.9418e-04, PNorm = 39.0759, GNorm = 1.9642, lr_0 = 1.0200e-04
Loss = 3.2318e-04, PNorm = 39.0778, GNorm = 0.6284, lr_0 = 1.0200e-04
Loss = 3.2485e-04, PNorm = 39.0799, GNorm = 1.8750, lr_0 = 1.0200e-04
Validation rmse logD = 0.680827
Validation R2 logD = 0.675820
Validation rmse logP = 0.462791
Validation R2 logP = 0.941042
Epoch 93
Train function
Loss = 7.1940e-04, PNorm = 39.0816, GNorm = 4.3652, lr_0 = 1.0200e-04
Loss = 3.8196e-04, PNorm = 39.0832, GNorm = 2.0470, lr_0 = 1.0200e-04
Loss = 3.8915e-04, PNorm = 39.0840, GNorm = 2.0653, lr_0 = 1.0200e-04
Loss = 4.2252e-04, PNorm = 39.0845, GNorm = 1.1460, lr_0 = 1.0200e-04
Loss = 3.3475e-04, PNorm = 39.0861, GNorm = 0.7443, lr_0 = 1.0200e-04
Loss = 3.2417e-04, PNorm = 39.0870, GNorm = 1.1005, lr_0 = 1.0200e-04
Loss = 3.4395e-04, PNorm = 39.0890, GNorm = 0.9823, lr_0 = 1.0200e-04
Loss = 3.0040e-04, PNorm = 39.0907, GNorm = 1.4815, lr_0 = 1.0200e-04
Loss = 3.7307e-04, PNorm = 39.0917, GNorm = 2.4457, lr_0 = 1.0200e-04
Loss = 4.1087e-04, PNorm = 39.0932, GNorm = 1.0456, lr_0 = 1.0200e-04
Loss = 3.7731e-04, PNorm = 39.0942, GNorm = 1.2807, lr_0 = 1.0200e-04
Loss = 4.0279e-04, PNorm = 39.0963, GNorm = 2.2869, lr_0 = 1.0200e-04
Loss = 3.7965e-04, PNorm = 39.0979, GNorm = 1.1278, lr_0 = 1.0200e-04
Loss = 3.9865e-04, PNorm = 39.1001, GNorm = 1.7739, lr_0 = 1.0200e-04
Loss = 3.9673e-04, PNorm = 39.1016, GNorm = 1.1152, lr_0 = 1.0200e-04
Loss = 3.7808e-04, PNorm = 39.1031, GNorm = 1.0370, lr_0 = 1.0200e-04
Loss = 3.6860e-04, PNorm = 39.1037, GNorm = 1.3298, lr_0 = 1.0200e-04
Loss = 3.6464e-04, PNorm = 39.1041, GNorm = 1.9562, lr_0 = 1.0200e-04
Loss = 3.8434e-04, PNorm = 39.1047, GNorm = 1.9277, lr_0 = 1.0200e-04
Loss = 3.7247e-04, PNorm = 39.1060, GNorm = 1.2773, lr_0 = 1.0200e-04
Loss = 4.6399e-04, PNorm = 39.1062, GNorm = 2.3152, lr_0 = 1.0200e-04
Loss = 3.5597e-04, PNorm = 39.1072, GNorm = 0.9358, lr_0 = 1.0200e-04
Loss = 3.9026e-04, PNorm = 39.1086, GNorm = 0.9240, lr_0 = 1.0200e-04
Validation rmse logD = 0.618019
Validation R2 logD = 0.732874
Validation rmse logP = 0.473271
Validation R2 logP = 0.938341
Epoch 94
Train function
Loss = 3.5853e-04, PNorm = 39.1097, GNorm = 2.9259, lr_0 = 1.0200e-04
Loss = 5.9672e-04, PNorm = 39.1117, GNorm = 2.1416, lr_0 = 1.0200e-04
Loss = 4.6789e-04, PNorm = 39.1135, GNorm = 0.7370, lr_0 = 1.0200e-04
Loss = 3.9844e-04, PNorm = 39.1148, GNorm = 0.7075, lr_0 = 1.0200e-04
Loss = 3.0329e-04, PNorm = 39.1164, GNorm = 0.9188, lr_0 = 1.0200e-04
Loss = 2.7668e-04, PNorm = 39.1179, GNorm = 1.5158, lr_0 = 1.0200e-04
Loss = 3.2008e-04, PNorm = 39.1191, GNorm = 1.6286, lr_0 = 1.0200e-04
Loss = 3.4153e-04, PNorm = 39.1196, GNorm = 1.2591, lr_0 = 1.0200e-04
Loss = 2.8067e-04, PNorm = 39.1208, GNorm = 1.0006, lr_0 = 1.0200e-04
Loss = 3.1805e-04, PNorm = 39.1218, GNorm = 1.0767, lr_0 = 1.0200e-04
Loss = 3.3237e-04, PNorm = 39.1230, GNorm = 2.0647, lr_0 = 1.0200e-04
Loss = 3.4968e-04, PNorm = 39.1242, GNorm = 1.5439, lr_0 = 1.0200e-04
Loss = 4.0586e-04, PNorm = 39.1252, GNorm = 1.8853, lr_0 = 1.0200e-04
Loss = 4.8770e-04, PNorm = 39.1266, GNorm = 2.6460, lr_0 = 1.0200e-04
Loss = 4.5260e-04, PNorm = 39.1274, GNorm = 1.5510, lr_0 = 1.0200e-04
Loss = 3.6861e-04, PNorm = 39.1292, GNorm = 0.9090, lr_0 = 1.0200e-04
Loss = 3.3495e-04, PNorm = 39.1310, GNorm = 0.7900, lr_0 = 1.0200e-04
Loss = 4.1579e-04, PNorm = 39.1325, GNorm = 1.0723, lr_0 = 1.0200e-04
Loss = 4.8788e-04, PNorm = 39.1343, GNorm = 0.8133, lr_0 = 1.0200e-04
Loss = 3.3953e-04, PNorm = 39.1366, GNorm = 0.6092, lr_0 = 1.0200e-04
Loss = 2.9456e-04, PNorm = 39.1369, GNorm = 1.1146, lr_0 = 1.0200e-04
Loss = 4.0527e-04, PNorm = 39.1376, GNorm = 0.8844, lr_0 = 1.0200e-04
Loss = 5.1725e-04, PNorm = 39.1385, GNorm = 1.9682, lr_0 = 1.0200e-04
Loss = 6.3056e-04, PNorm = 39.1385, GNorm = 1.7150, lr_0 = 1.0200e-04
Validation rmse logD = 0.616370
Validation R2 logD = 0.734298
Validation rmse logP = 0.463271
Validation R2 logP = 0.940920
Epoch 95
Train function
Loss = 3.7602e-04, PNorm = 39.1408, GNorm = 2.3139, lr_0 = 1.0200e-04
Loss = 3.6132e-04, PNorm = 39.1421, GNorm = 1.5071, lr_0 = 1.0200e-04
Loss = 3.6839e-04, PNorm = 39.1431, GNorm = 0.9568, lr_0 = 1.0200e-04
Loss = 4.4624e-04, PNorm = 39.1449, GNorm = 1.9918, lr_0 = 1.0200e-04
Loss = 3.8664e-04, PNorm = 39.1464, GNorm = 0.9326, lr_0 = 1.0200e-04
Loss = 3.5369e-04, PNorm = 39.1481, GNorm = 1.0765, lr_0 = 1.0200e-04
Loss = 3.2158e-04, PNorm = 39.1493, GNorm = 1.6170, lr_0 = 1.0200e-04
Loss = 4.0914e-04, PNorm = 39.1511, GNorm = 1.1084, lr_0 = 1.0200e-04
Loss = 3.7722e-04, PNorm = 39.1521, GNorm = 1.9527, lr_0 = 1.0200e-04
Loss = 3.8883e-04, PNorm = 39.1533, GNorm = 1.0664, lr_0 = 1.0200e-04
Loss = 3.7318e-04, PNorm = 39.1540, GNorm = 1.2657, lr_0 = 1.0200e-04
Loss = 3.5590e-04, PNorm = 39.1552, GNorm = 1.1678, lr_0 = 1.0200e-04
Loss = 2.9181e-04, PNorm = 39.1567, GNorm = 1.4108, lr_0 = 1.0200e-04
Loss = 3.0491e-04, PNorm = 39.1584, GNorm = 0.8411, lr_0 = 1.0200e-04
Loss = 3.2169e-04, PNorm = 39.1600, GNorm = 1.0434, lr_0 = 1.0200e-04
Loss = 3.4534e-04, PNorm = 39.1619, GNorm = 1.2857, lr_0 = 1.0200e-04
Loss = 3.7636e-04, PNorm = 39.1630, GNorm = 1.1492, lr_0 = 1.0200e-04
Loss = 3.5326e-04, PNorm = 39.1637, GNorm = 1.9495, lr_0 = 1.0200e-04
Loss = 3.3983e-04, PNorm = 39.1653, GNorm = 1.0044, lr_0 = 1.0200e-04
Loss = 4.1877e-04, PNorm = 39.1658, GNorm = 1.8670, lr_0 = 1.0200e-04
Loss = 4.6386e-04, PNorm = 39.1661, GNorm = 1.5209, lr_0 = 1.0200e-04
Loss = 3.5137e-04, PNorm = 39.1666, GNorm = 2.0370, lr_0 = 1.0200e-04
Validation rmse logD = 0.631382
Validation R2 logD = 0.721198
Validation rmse logP = 0.476477
Validation R2 logP = 0.937503
Epoch 96
Train function
Loss = 3.6421e-04, PNorm = 39.1676, GNorm = 2.6140, lr_0 = 1.0200e-04
Loss = 4.3884e-04, PNorm = 39.1675, GNorm = 1.3084, lr_0 = 1.0200e-04
Loss = 2.8565e-04, PNorm = 39.1686, GNorm = 1.2629, lr_0 = 1.0200e-04
Loss = 3.4213e-04, PNorm = 39.1705, GNorm = 1.4371, lr_0 = 1.0200e-04
Loss = 2.5673e-04, PNorm = 39.1712, GNorm = 0.8344, lr_0 = 1.0200e-04
Loss = 3.6112e-04, PNorm = 39.1721, GNorm = 1.5701, lr_0 = 1.0200e-04
Loss = 3.1100e-04, PNorm = 39.1738, GNorm = 1.2510, lr_0 = 1.0200e-04
Loss = 2.9098e-04, PNorm = 39.1750, GNorm = 2.2522, lr_0 = 1.0200e-04
Loss = 3.8053e-04, PNorm = 39.1758, GNorm = 1.0221, lr_0 = 1.0200e-04
Loss = 3.1028e-04, PNorm = 39.1765, GNorm = 1.0806, lr_0 = 1.0200e-04
Loss = 3.0763e-04, PNorm = 39.1780, GNorm = 0.9773, lr_0 = 1.0200e-04
Loss = 3.9247e-04, PNorm = 39.1790, GNorm = 0.8710, lr_0 = 1.0200e-04
Loss = 4.4040e-04, PNorm = 39.1807, GNorm = 1.2586, lr_0 = 1.0200e-04
Loss = 3.4553e-04, PNorm = 39.1825, GNorm = 1.4507, lr_0 = 1.0200e-04
Loss = 4.6454e-04, PNorm = 39.1853, GNorm = 0.9991, lr_0 = 1.0200e-04
Loss = 3.5171e-04, PNorm = 39.1865, GNorm = 1.4170, lr_0 = 1.0200e-04
Loss = 4.5629e-04, PNorm = 39.1876, GNorm = 1.4476, lr_0 = 1.0200e-04
Loss = 3.4884e-04, PNorm = 39.1893, GNorm = 1.3233, lr_0 = 1.0200e-04
Loss = 3.5815e-04, PNorm = 39.1901, GNorm = 2.0425, lr_0 = 1.0200e-04
Loss = 3.4520e-04, PNorm = 39.1914, GNorm = 1.1047, lr_0 = 1.0200e-04
Loss = 3.4824e-04, PNorm = 39.1933, GNorm = 1.3799, lr_0 = 1.0200e-04
Loss = 3.4834e-04, PNorm = 39.1949, GNorm = 1.6786, lr_0 = 1.0200e-04
Loss = 3.5314e-04, PNorm = 39.1956, GNorm = 1.6488, lr_0 = 1.0200e-04
Validation rmse logD = 0.632856
Validation R2 logD = 0.719894
Validation rmse logP = 0.486340
Validation R2 logP = 0.934889
Epoch 97
Train function
Loss = 3.6100e-04, PNorm = 39.1970, GNorm = 3.3537, lr_0 = 1.0200e-04
Loss = 3.4755e-04, PNorm = 39.1976, GNorm = 1.1233, lr_0 = 1.0200e-04
Loss = 3.0392e-04, PNorm = 39.1989, GNorm = 1.9921, lr_0 = 1.0200e-04
Loss = 2.9991e-04, PNorm = 39.2002, GNorm = 1.0512, lr_0 = 1.0200e-04
Loss = 3.9272e-04, PNorm = 39.2007, GNorm = 2.2268, lr_0 = 1.0200e-04
Loss = 3.5301e-04, PNorm = 39.2024, GNorm = 1.3236, lr_0 = 1.0200e-04
Loss = 3.9031e-04, PNorm = 39.2039, GNorm = 1.0131, lr_0 = 1.0200e-04
Loss = 2.9508e-04, PNorm = 39.2043, GNorm = 1.0009, lr_0 = 1.0200e-04
Loss = 3.4165e-04, PNorm = 39.2049, GNorm = 1.4110, lr_0 = 1.0200e-04
Loss = 3.3113e-04, PNorm = 39.2061, GNorm = 1.0797, lr_0 = 1.0200e-04
Loss = 3.3038e-04, PNorm = 39.2076, GNorm = 0.7878, lr_0 = 1.0200e-04
Loss = 3.4798e-04, PNorm = 39.2095, GNorm = 1.1035, lr_0 = 1.0200e-04
Loss = 4.3603e-04, PNorm = 39.2105, GNorm = 0.8299, lr_0 = 1.0200e-04
Loss = 3.2135e-04, PNorm = 39.2110, GNorm = 2.4202, lr_0 = 1.0200e-04
Loss = 3.7670e-04, PNorm = 39.2123, GNorm = 1.8234, lr_0 = 1.0200e-04
Loss = 4.5395e-04, PNorm = 39.2131, GNorm = 1.6749, lr_0 = 1.0200e-04
Loss = 4.5280e-04, PNorm = 39.2149, GNorm = 1.0199, lr_0 = 1.0200e-04
Loss = 3.9547e-04, PNorm = 39.2167, GNorm = 1.9319, lr_0 = 1.0200e-04
Loss = 4.6731e-04, PNorm = 39.2177, GNorm = 3.7163, lr_0 = 1.0200e-04
Loss = 3.6637e-04, PNorm = 39.2188, GNorm = 0.4959, lr_0 = 1.0200e-04
Loss = 3.7414e-04, PNorm = 39.2197, GNorm = 1.1505, lr_0 = 1.0200e-04
Loss = 4.0886e-04, PNorm = 39.2215, GNorm = 0.9135, lr_0 = 1.0200e-04
Validation rmse logD = 0.625370
Validation R2 logD = 0.726482
Validation rmse logP = 0.492171
Validation R2 logP = 0.933318
Epoch 98
Train function
Loss = 3.6693e-04, PNorm = 39.2234, GNorm = 1.9512, lr_0 = 1.0200e-04
Loss = 3.4451e-04, PNorm = 39.2250, GNorm = 1.3515, lr_0 = 1.0200e-04
Loss = 4.2354e-04, PNorm = 39.2264, GNorm = 2.4148, lr_0 = 1.0200e-04
Loss = 3.4835e-04, PNorm = 39.2277, GNorm = 0.7811, lr_0 = 1.0200e-04
Loss = 3.5494e-04, PNorm = 39.2291, GNorm = 1.4229, lr_0 = 1.0200e-04
Loss = 2.9357e-04, PNorm = 39.2294, GNorm = 0.8425, lr_0 = 1.0200e-04
Loss = 3.3421e-04, PNorm = 39.2306, GNorm = 1.0358, lr_0 = 1.0200e-04
Loss = 3.4214e-04, PNorm = 39.2321, GNorm = 1.7133, lr_0 = 1.0200e-04
Loss = 2.9792e-04, PNorm = 39.2331, GNorm = 0.9358, lr_0 = 1.0200e-04
Loss = 3.0904e-04, PNorm = 39.2341, GNorm = 1.0959, lr_0 = 1.0200e-04
Loss = 2.8159e-04, PNorm = 39.2354, GNorm = 1.1555, lr_0 = 1.0200e-04
Loss = 3.1950e-04, PNorm = 39.2361, GNorm = 1.0129, lr_0 = 1.0200e-04
Loss = 3.0067e-04, PNorm = 39.2375, GNorm = 0.6652, lr_0 = 1.0200e-04
Loss = 3.7839e-04, PNorm = 39.2385, GNorm = 1.8206, lr_0 = 1.0200e-04
Loss = 4.1840e-04, PNorm = 39.2395, GNorm = 1.0820, lr_0 = 1.0200e-04
Loss = 3.5435e-04, PNorm = 39.2416, GNorm = 0.7692, lr_0 = 1.0200e-04
Loss = 3.2457e-04, PNorm = 39.2439, GNorm = 1.3921, lr_0 = 1.0200e-04
Loss = 3.3672e-04, PNorm = 39.2446, GNorm = 1.1613, lr_0 = 1.0200e-04
Loss = 3.9037e-04, PNorm = 39.2459, GNorm = 1.9368, lr_0 = 1.0200e-04
Loss = 2.9998e-04, PNorm = 39.2476, GNorm = 1.2306, lr_0 = 1.0200e-04
Loss = 3.1487e-04, PNorm = 39.2483, GNorm = 0.8422, lr_0 = 1.0200e-04
Loss = 3.8659e-04, PNorm = 39.2491, GNorm = 1.9566, lr_0 = 1.0200e-04
Loss = 3.4897e-04, PNorm = 39.2510, GNorm = 1.5711, lr_0 = 1.0200e-04
Validation rmse logD = 0.614283
Validation R2 logD = 0.736094
Validation rmse logP = 0.462867
Validation R2 logP = 0.941023
Epoch 99
Train function
Loss = 3.1079e-04, PNorm = 39.2520, GNorm = 1.3129, lr_0 = 1.0200e-04
Loss = 3.6469e-04, PNorm = 39.2532, GNorm = 1.7246, lr_0 = 1.0200e-04
Loss = 3.6204e-04, PNorm = 39.2550, GNorm = 1.7394, lr_0 = 1.0200e-04
Loss = 3.6319e-04, PNorm = 39.2556, GNorm = 1.5629, lr_0 = 1.0200e-04
Loss = 5.3362e-04, PNorm = 39.2560, GNorm = 1.1272, lr_0 = 1.0200e-04
Loss = 4.7682e-04, PNorm = 39.2577, GNorm = 1.4057, lr_0 = 1.0200e-04
Loss = 4.4071e-04, PNorm = 39.2578, GNorm = 1.8829, lr_0 = 1.0200e-04
Loss = 4.6383e-04, PNorm = 39.2580, GNorm = 1.3071, lr_0 = 1.0200e-04
Loss = 5.0919e-04, PNorm = 39.2591, GNorm = 0.6972, lr_0 = 1.0200e-04
Loss = 4.8695e-04, PNorm = 39.2607, GNorm = 4.1755, lr_0 = 1.0200e-04
Loss = 4.2320e-04, PNorm = 39.2615, GNorm = 1.2388, lr_0 = 1.0200e-04
Loss = 3.1330e-04, PNorm = 39.2638, GNorm = 0.7525, lr_0 = 1.0200e-04
Loss = 2.8874e-04, PNorm = 39.2654, GNorm = 0.7724, lr_0 = 1.0200e-04
Loss = 2.6123e-04, PNorm = 39.2666, GNorm = 0.7374, lr_0 = 1.0200e-04
Loss = 3.7862e-04, PNorm = 39.2678, GNorm = 1.4766, lr_0 = 1.0200e-04
Loss = 2.6994e-04, PNorm = 39.2683, GNorm = 0.8650, lr_0 = 1.0200e-04
Loss = 3.7029e-04, PNorm = 39.2697, GNorm = 1.9287, lr_0 = 1.0200e-04
Loss = 3.3836e-04, PNorm = 39.2723, GNorm = 0.8027, lr_0 = 1.0200e-04
Loss = 5.0118e-04, PNorm = 39.2737, GNorm = 4.6409, lr_0 = 1.0200e-04
Loss = 2.8672e-04, PNorm = 39.2748, GNorm = 0.9382, lr_0 = 1.0200e-04
Loss = 2.9444e-04, PNorm = 39.2764, GNorm = 1.4184, lr_0 = 1.0200e-04
Loss = 3.5295e-04, PNorm = 39.2782, GNorm = 1.9628, lr_0 = 1.0200e-04
Validation rmse logD = 0.616979
Validation R2 logD = 0.733773
Validation rmse logP = 0.469126
Validation R2 logP = 0.939417
Model 0 best validation rmse = 0.537606 on epoch 88
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.582870
Model 0 test R2 logD = 0.784525
Model 0 test rmse logP = 0.441929
Model 0 test R2 logP = 0.943905
Ensemble test rmse  logD= 0.582870
Ensemble test R2  logD= 0.784525
Ensemble test rmse  logP= 0.441929
Ensemble test R2  logP= 0.943905
Fold 1
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_1',
 'save_smiles_splits': False,
 'seed': 1,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 1
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 1.8702e-02, PNorm = 35.0899, GNorm = 3.7721, lr_0 = 1.0200e-04
Loss = 1.7745e-02, PNorm = 35.0910, GNorm = 4.6203, lr_0 = 1.0200e-04
Loss = 1.5197e-02, PNorm = 35.0936, GNorm = 3.5727, lr_0 = 1.0200e-04
Loss = 1.3351e-02, PNorm = 35.0962, GNorm = 3.6960, lr_0 = 1.0200e-04
Loss = 1.3437e-02, PNorm = 35.0987, GNorm = 3.1092, lr_0 = 1.0200e-04
Loss = 1.1057e-02, PNorm = 35.1015, GNorm = 5.1034, lr_0 = 1.0200e-04
Loss = 1.1999e-02, PNorm = 35.1043, GNorm = 1.9601, lr_0 = 1.0200e-04
Loss = 1.0228e-02, PNorm = 35.1068, GNorm = 6.9079, lr_0 = 1.0200e-04
Loss = 1.2369e-02, PNorm = 35.1095, GNorm = 6.3640, lr_0 = 1.0200e-04
Loss = 1.1144e-02, PNorm = 35.1130, GNorm = 4.7930, lr_0 = 1.0200e-04
Loss = 9.1516e-03, PNorm = 35.1161, GNorm = 3.0751, lr_0 = 1.0200e-04
Loss = 1.1206e-02, PNorm = 35.1188, GNorm = 4.7528, lr_0 = 1.0200e-04
Loss = 8.2551e-03, PNorm = 35.1213, GNorm = 2.2437, lr_0 = 1.0200e-04
Loss = 9.0792e-03, PNorm = 35.1237, GNorm = 4.2901, lr_0 = 1.0200e-04
Loss = 8.4722e-03, PNorm = 35.1267, GNorm = 3.2146, lr_0 = 1.0200e-04
Loss = 8.9646e-03, PNorm = 35.1305, GNorm = 7.9602, lr_0 = 1.0200e-04
Loss = 7.3624e-03, PNorm = 35.1334, GNorm = 14.5304, lr_0 = 1.0200e-04
Loss = 7.3946e-03, PNorm = 35.1352, GNorm = 4.2669, lr_0 = 1.0200e-04
Loss = 8.4805e-03, PNorm = 35.1382, GNorm = 3.2232, lr_0 = 1.0200e-04
Loss = 8.2317e-03, PNorm = 35.1414, GNorm = 2.3509, lr_0 = 1.0200e-04
Loss = 7.8437e-03, PNorm = 35.1446, GNorm = 8.4533, lr_0 = 1.0200e-04
Loss = 6.8571e-03, PNorm = 35.1484, GNorm = 6.5247, lr_0 = 1.0200e-04
Validation rmse logD = 0.971157
Validation R2 logD = 0.311264
Validation rmse logP = 0.943337
Validation R2 logP = 0.741823
Epoch 1
Train function
Loss = 7.3224e-03, PNorm = 35.1518, GNorm = 4.7119, lr_0 = 1.0200e-04
Loss = 7.2809e-03, PNorm = 35.1552, GNorm = 2.3600, lr_0 = 1.0200e-04
Loss = 6.7698e-03, PNorm = 35.1585, GNorm = 3.6471, lr_0 = 1.0200e-04
Loss = 7.3680e-03, PNorm = 35.1610, GNorm = 3.4567, lr_0 = 1.0200e-04
Loss = 6.3352e-03, PNorm = 35.1646, GNorm = 3.3233, lr_0 = 1.0200e-04
Loss = 6.7085e-03, PNorm = 35.1681, GNorm = 3.8058, lr_0 = 1.0200e-04
Loss = 8.1517e-03, PNorm = 35.1706, GNorm = 6.8262, lr_0 = 1.0200e-04
Loss = 6.8830e-03, PNorm = 35.1734, GNorm = 2.9626, lr_0 = 1.0200e-04
Loss = 6.8547e-03, PNorm = 35.1763, GNorm = 1.4333, lr_0 = 1.0200e-04
Loss = 6.4117e-03, PNorm = 35.1781, GNorm = 2.7763, lr_0 = 1.0200e-04
Loss = 6.5123e-03, PNorm = 35.1796, GNorm = 4.3383, lr_0 = 1.0200e-04
Loss = 5.8718e-03, PNorm = 35.1822, GNorm = 1.8207, lr_0 = 1.0200e-04
Loss = 5.6739e-03, PNorm = 35.1854, GNorm = 4.7530, lr_0 = 1.0200e-04
Loss = 7.1949e-03, PNorm = 35.1894, GNorm = 4.7827, lr_0 = 1.0200e-04
Loss = 5.1189e-03, PNorm = 35.1927, GNorm = 2.2715, lr_0 = 1.0200e-04
Loss = 5.6917e-03, PNorm = 35.1954, GNorm = 5.1034, lr_0 = 1.0200e-04
Loss = 6.3603e-03, PNorm = 35.1976, GNorm = 2.1313, lr_0 = 1.0200e-04
Loss = 6.4511e-03, PNorm = 35.1998, GNorm = 8.2324, lr_0 = 1.0200e-04
Loss = 5.9521e-03, PNorm = 35.2026, GNorm = 8.1655, lr_0 = 1.0200e-04
Loss = 5.5701e-03, PNorm = 35.2057, GNorm = 4.0678, lr_0 = 1.0200e-04
Loss = 5.7259e-03, PNorm = 35.2091, GNorm = 3.1383, lr_0 = 1.0200e-04
Loss = 4.9742e-03, PNorm = 35.2122, GNorm = 3.2414, lr_0 = 1.0200e-04
Loss = 6.2454e-03, PNorm = 35.2151, GNorm = 4.9143, lr_0 = 1.0200e-04
Loss = 7.3983e-03, PNorm = 35.2153, GNorm = 4.9643, lr_0 = 1.0200e-04
Validation rmse logD = 0.900058
Validation R2 logD = 0.408419
Validation rmse logP = 0.779463
Validation R2 logP = 0.823731
Epoch 2
Train function
Loss = 4.9734e-03, PNorm = 35.2182, GNorm = 4.7862, lr_0 = 1.0200e-04
Loss = 6.3290e-03, PNorm = 35.2223, GNorm = 2.7861, lr_0 = 1.0200e-04
Loss = 5.4750e-03, PNorm = 35.2250, GNorm = 5.7871, lr_0 = 1.0200e-04
Loss = 4.9591e-03, PNorm = 35.2284, GNorm = 3.4638, lr_0 = 1.0200e-04
Loss = 5.1110e-03, PNorm = 35.2309, GNorm = 7.1047, lr_0 = 1.0200e-04
Loss = 5.6112e-03, PNorm = 35.2339, GNorm = 4.0075, lr_0 = 1.0200e-04
Loss = 4.9810e-03, PNorm = 35.2364, GNorm = 1.9113, lr_0 = 1.0200e-04
Loss = 5.6019e-03, PNorm = 35.2390, GNorm = 2.9519, lr_0 = 1.0200e-04
Loss = 6.3357e-03, PNorm = 35.2419, GNorm = 3.2537, lr_0 = 1.0200e-04
Loss = 5.4272e-03, PNorm = 35.2454, GNorm = 9.2699, lr_0 = 1.0200e-04
Loss = 4.8511e-03, PNorm = 35.2477, GNorm = 3.6419, lr_0 = 1.0200e-04
Loss = 5.4418e-03, PNorm = 35.2504, GNorm = 9.1429, lr_0 = 1.0200e-04
Loss = 5.7937e-03, PNorm = 35.2541, GNorm = 6.5491, lr_0 = 1.0200e-04
Loss = 5.5105e-03, PNorm = 35.2572, GNorm = 3.3149, lr_0 = 1.0200e-04
Loss = 4.5898e-03, PNorm = 35.2592, GNorm = 4.1313, lr_0 = 1.0200e-04
Loss = 5.2033e-03, PNorm = 35.2616, GNorm = 6.1582, lr_0 = 1.0200e-04
Loss = 5.3939e-03, PNorm = 35.2641, GNorm = 2.7498, lr_0 = 1.0200e-04
Loss = 5.3232e-03, PNorm = 35.2666, GNorm = 0.9825, lr_0 = 1.0200e-04
Loss = 5.2789e-03, PNorm = 35.2690, GNorm = 4.1363, lr_0 = 1.0200e-04
Loss = 4.2391e-03, PNorm = 35.2713, GNorm = 2.1931, lr_0 = 1.0200e-04
Loss = 5.0449e-03, PNorm = 35.2741, GNorm = 6.6950, lr_0 = 1.0200e-04
Loss = 5.4094e-03, PNorm = 35.2771, GNorm = 3.1727, lr_0 = 1.0200e-04
Validation rmse logD = 0.859810
Validation R2 logD = 0.460143
Validation rmse logP = 0.746428
Validation R2 logP = 0.838356
Epoch 3
Train function
Loss = 4.3560e-03, PNorm = 35.2792, GNorm = 2.2640, lr_0 = 1.0200e-04
Loss = 4.3675e-03, PNorm = 35.2822, GNorm = 4.0273, lr_0 = 1.0200e-04
Loss = 4.5046e-03, PNorm = 35.2847, GNorm = 4.6269, lr_0 = 1.0200e-04
Loss = 4.6386e-03, PNorm = 35.2874, GNorm = 6.1478, lr_0 = 1.0200e-04
Loss = 4.6843e-03, PNorm = 35.2902, GNorm = 3.4838, lr_0 = 1.0200e-04
Loss = 4.4864e-03, PNorm = 35.2934, GNorm = 3.8180, lr_0 = 1.0200e-04
Loss = 4.9558e-03, PNorm = 35.2959, GNorm = 3.5065, lr_0 = 1.0200e-04
Loss = 4.7546e-03, PNorm = 35.2985, GNorm = 3.5086, lr_0 = 1.0200e-04
Loss = 3.9087e-03, PNorm = 35.3022, GNorm = 2.4417, lr_0 = 1.0200e-04
Loss = 4.8537e-03, PNorm = 35.3045, GNorm = 11.0565, lr_0 = 1.0200e-04
Loss = 5.0977e-03, PNorm = 35.3078, GNorm = 8.1771, lr_0 = 1.0200e-04
Loss = 4.6619e-03, PNorm = 35.3107, GNorm = 6.0994, lr_0 = 1.0200e-04
Loss = 4.2169e-03, PNorm = 35.3130, GNorm = 5.2367, lr_0 = 1.0200e-04
Loss = 4.5619e-03, PNorm = 35.3155, GNorm = 1.5971, lr_0 = 1.0200e-04
Loss = 4.2402e-03, PNorm = 35.3189, GNorm = 3.7442, lr_0 = 1.0200e-04
Loss = 5.7214e-03, PNorm = 35.3219, GNorm = 2.6655, lr_0 = 1.0200e-04
Loss = 4.6366e-03, PNorm = 35.3249, GNorm = 2.8632, lr_0 = 1.0200e-04
Loss = 4.4537e-03, PNorm = 35.3276, GNorm = 4.3014, lr_0 = 1.0200e-04
Loss = 4.3707e-03, PNorm = 35.3302, GNorm = 6.2438, lr_0 = 1.0200e-04
Loss = 4.6300e-03, PNorm = 35.3332, GNorm = 4.0409, lr_0 = 1.0200e-04
Loss = 4.7001e-03, PNorm = 35.3356, GNorm = 7.0703, lr_0 = 1.0200e-04
Loss = 4.7739e-03, PNorm = 35.3373, GNorm = 6.1934, lr_0 = 1.0200e-04
Loss = 4.1654e-03, PNorm = 35.3392, GNorm = 3.3621, lr_0 = 1.0200e-04
Validation rmse logD = 0.837189
Validation R2 logD = 0.488176
Validation rmse logP = 0.700273
Validation R2 logP = 0.857728
Epoch 4
Train function
Loss = 4.1743e-03, PNorm = 35.3412, GNorm = 5.6642, lr_0 = 1.0200e-04
Loss = 4.8525e-03, PNorm = 35.3446, GNorm = 2.2360, lr_0 = 1.0200e-04
Loss = 4.4072e-03, PNorm = 35.3476, GNorm = 7.1458, lr_0 = 1.0200e-04
Loss = 4.2172e-03, PNorm = 35.3499, GNorm = 1.6993, lr_0 = 1.0200e-04
Loss = 3.8758e-03, PNorm = 35.3517, GNorm = 2.0876, lr_0 = 1.0200e-04
Loss = 4.5521e-03, PNorm = 35.3544, GNorm = 3.7669, lr_0 = 1.0200e-04
Loss = 4.2594e-03, PNorm = 35.3576, GNorm = 7.4799, lr_0 = 1.0200e-04
Loss = 4.1645e-03, PNorm = 35.3600, GNorm = 6.5429, lr_0 = 1.0200e-04
Loss = 4.2183e-03, PNorm = 35.3626, GNorm = 3.1221, lr_0 = 1.0200e-04
Loss = 4.2860e-03, PNorm = 35.3665, GNorm = 4.1988, lr_0 = 1.0200e-04
Loss = 4.1868e-03, PNorm = 35.3686, GNorm = 4.8450, lr_0 = 1.0200e-04
Loss = 3.8988e-03, PNorm = 35.3707, GNorm = 6.2107, lr_0 = 1.0200e-04
Loss = 4.4682e-03, PNorm = 35.3731, GNorm = 1.7435, lr_0 = 1.0200e-04
Loss = 3.6667e-03, PNorm = 35.3756, GNorm = 4.4114, lr_0 = 1.0200e-04
Loss = 4.5018e-03, PNorm = 35.3783, GNorm = 3.4740, lr_0 = 1.0200e-04
Loss = 3.9803e-03, PNorm = 35.3809, GNorm = 1.3712, lr_0 = 1.0200e-04
Loss = 4.0443e-03, PNorm = 35.3830, GNorm = 6.1820, lr_0 = 1.0200e-04
Loss = 4.1039e-03, PNorm = 35.3865, GNorm = 4.1368, lr_0 = 1.0200e-04
Loss = 3.8568e-03, PNorm = 35.3891, GNorm = 6.6103, lr_0 = 1.0200e-04
Loss = 3.7570e-03, PNorm = 35.3920, GNorm = 1.9393, lr_0 = 1.0200e-04
Loss = 4.7720e-03, PNorm = 35.3947, GNorm = 5.0687, lr_0 = 1.0200e-04
Loss = 4.0359e-03, PNorm = 35.3972, GNorm = 2.8042, lr_0 = 1.0200e-04
Validation rmse logD = 0.816931
Validation R2 logD = 0.512646
Validation rmse logP = 0.727153
Validation R2 logP = 0.846596
Epoch 5
Train function
Loss = 4.5096e-03, PNorm = 35.3999, GNorm = 10.8874, lr_0 = 1.0200e-04
Loss = 3.8030e-03, PNorm = 35.4029, GNorm = 2.5126, lr_0 = 1.0200e-04
Loss = 3.5100e-03, PNorm = 35.4059, GNorm = 3.6221, lr_0 = 1.0200e-04
Loss = 3.7239e-03, PNorm = 35.4084, GNorm = 3.8618, lr_0 = 1.0200e-04
Loss = 4.6420e-03, PNorm = 35.4103, GNorm = 4.6111, lr_0 = 1.0200e-04
Loss = 3.9636e-03, PNorm = 35.4134, GNorm = 2.6185, lr_0 = 1.0200e-04
Loss = 3.9385e-03, PNorm = 35.4164, GNorm = 5.5057, lr_0 = 1.0200e-04
Loss = 4.6634e-03, PNorm = 35.4194, GNorm = 9.8962, lr_0 = 1.0200e-04
Loss = 4.4257e-03, PNorm = 35.4224, GNorm = 15.5429, lr_0 = 1.0200e-04
Loss = 3.7993e-03, PNorm = 35.4242, GNorm = 8.3509, lr_0 = 1.0200e-04
Loss = 4.5093e-03, PNorm = 35.4258, GNorm = 7.7595, lr_0 = 1.0200e-04
Loss = 4.2554e-03, PNorm = 35.4276, GNorm = 1.1035, lr_0 = 1.0200e-04
Loss = 4.3582e-03, PNorm = 35.4300, GNorm = 5.8190, lr_0 = 1.0200e-04
Loss = 3.6077e-03, PNorm = 35.4319, GNorm = 4.9441, lr_0 = 1.0200e-04
Loss = 4.2359e-03, PNorm = 35.4342, GNorm = 2.9222, lr_0 = 1.0200e-04
Loss = 4.0330e-03, PNorm = 35.4365, GNorm = 3.3745, lr_0 = 1.0200e-04
Loss = 3.8708e-03, PNorm = 35.4395, GNorm = 2.9124, lr_0 = 1.0200e-04
Loss = 4.2771e-03, PNorm = 35.4414, GNorm = 3.0174, lr_0 = 1.0200e-04
Loss = 3.2156e-03, PNorm = 35.4437, GNorm = 1.8027, lr_0 = 1.0200e-04
Loss = 3.8969e-03, PNorm = 35.4461, GNorm = 4.7488, lr_0 = 1.0200e-04
Loss = 4.8599e-03, PNorm = 35.4489, GNorm = 10.3417, lr_0 = 1.0200e-04
Loss = 3.9769e-03, PNorm = 35.4515, GNorm = 4.2290, lr_0 = 1.0200e-04
Loss = 3.6417e-03, PNorm = 35.4542, GNorm = 3.9358, lr_0 = 1.0200e-04
Validation rmse logD = 0.834078
Validation R2 logD = 0.491973
Validation rmse logP = 0.749144
Validation R2 logP = 0.837177
Epoch 6
Train function
Loss = 3.7372e-03, PNorm = 35.4572, GNorm = 7.5955, lr_0 = 1.0200e-04
Loss = 3.4371e-03, PNorm = 35.4595, GNorm = 6.6068, lr_0 = 1.0200e-04
Loss = 4.7648e-03, PNorm = 35.4623, GNorm = 12.5289, lr_0 = 1.0200e-04
Loss = 5.1049e-03, PNorm = 35.4646, GNorm = 10.6658, lr_0 = 1.0200e-04
Loss = 3.7846e-03, PNorm = 35.4672, GNorm = 4.8449, lr_0 = 1.0200e-04
Loss = 3.5649e-03, PNorm = 35.4696, GNorm = 6.0800, lr_0 = 1.0200e-04
Loss = 4.7161e-03, PNorm = 35.4723, GNorm = 3.4451, lr_0 = 1.0200e-04
Loss = 4.1760e-03, PNorm = 35.4755, GNorm = 4.3074, lr_0 = 1.0200e-04
Loss = 3.3923e-03, PNorm = 35.4780, GNorm = 3.9602, lr_0 = 1.0200e-04
Loss = 4.0538e-03, PNorm = 35.4810, GNorm = 4.0072, lr_0 = 1.0200e-04
Loss = 2.9386e-03, PNorm = 35.4838, GNorm = 4.0542, lr_0 = 1.0200e-04
Loss = 3.6275e-03, PNorm = 35.4853, GNorm = 8.7696, lr_0 = 1.0200e-04
Loss = 3.6789e-03, PNorm = 35.4873, GNorm = 6.8998, lr_0 = 1.0200e-04
Loss = 3.8200e-03, PNorm = 35.4896, GNorm = 7.8678, lr_0 = 1.0200e-04
Loss = 3.5299e-03, PNorm = 35.4916, GNorm = 2.6000, lr_0 = 1.0200e-04
Loss = 3.2862e-03, PNorm = 35.4940, GNorm = 1.3326, lr_0 = 1.0200e-04
Loss = 3.6450e-03, PNorm = 35.4967, GNorm = 2.3007, lr_0 = 1.0200e-04
Loss = 3.2151e-03, PNorm = 35.4994, GNorm = 1.8652, lr_0 = 1.0200e-04
Loss = 3.2337e-03, PNorm = 35.5016, GNorm = 1.5139, lr_0 = 1.0200e-04
Loss = 3.7678e-03, PNorm = 35.5039, GNorm = 2.0167, lr_0 = 1.0200e-04
Loss = 3.8332e-03, PNorm = 35.5071, GNorm = 6.2188, lr_0 = 1.0200e-04
Loss = 3.2358e-03, PNorm = 35.5103, GNorm = 5.0291, lr_0 = 1.0200e-04
Validation rmse logD = 0.784613
Validation R2 logD = 0.550444
Validation rmse logP = 0.660695
Validation R2 logP = 0.873355
Epoch 7
Train function
Loss = 3.4473e-03, PNorm = 35.5126, GNorm = 5.5520, lr_0 = 1.0200e-04
Loss = 3.8191e-03, PNorm = 35.5145, GNorm = 5.4664, lr_0 = 1.0200e-04
Loss = 3.3036e-03, PNorm = 35.5166, GNorm = 1.8912, lr_0 = 1.0200e-04
Loss = 4.0774e-03, PNorm = 35.5197, GNorm = 3.9230, lr_0 = 1.0200e-04
Loss = 3.4422e-03, PNorm = 35.5232, GNorm = 4.7995, lr_0 = 1.0200e-04
Loss = 3.2727e-03, PNorm = 35.5264, GNorm = 2.4580, lr_0 = 1.0200e-04
Loss = 3.5464e-03, PNorm = 35.5282, GNorm = 4.4429, lr_0 = 1.0200e-04
Loss = 2.8394e-03, PNorm = 35.5298, GNorm = 1.7344, lr_0 = 1.0200e-04
Loss = 3.0041e-03, PNorm = 35.5321, GNorm = 3.5730, lr_0 = 1.0200e-04
Loss = 3.1075e-03, PNorm = 35.5352, GNorm = 2.4211, lr_0 = 1.0200e-04
Loss = 2.9428e-03, PNorm = 35.5379, GNorm = 5.1374, lr_0 = 1.0200e-04
Loss = 4.1043e-03, PNorm = 35.5404, GNorm = 13.0376, lr_0 = 1.0200e-04
Loss = 3.6427e-03, PNorm = 35.5433, GNorm = 1.9809, lr_0 = 1.0200e-04
Loss = 4.0447e-03, PNorm = 35.5452, GNorm = 2.5495, lr_0 = 1.0200e-04
Loss = 3.9272e-03, PNorm = 35.5476, GNorm = 8.0816, lr_0 = 1.0200e-04
Loss = 3.3296e-03, PNorm = 35.5506, GNorm = 2.7671, lr_0 = 1.0200e-04
Loss = 2.9993e-03, PNorm = 35.5528, GNorm = 1.5933, lr_0 = 1.0200e-04
Loss = 3.5903e-03, PNorm = 35.5554, GNorm = 3.1185, lr_0 = 1.0200e-04
Loss = 3.4041e-03, PNorm = 35.5570, GNorm = 6.2412, lr_0 = 1.0200e-04
Loss = 3.7215e-03, PNorm = 35.5593, GNorm = 7.5304, lr_0 = 1.0200e-04
Loss = 4.2106e-03, PNorm = 35.5617, GNorm = 8.5665, lr_0 = 1.0200e-04
Loss = 3.8437e-03, PNorm = 35.5644, GNorm = 1.3267, lr_0 = 1.0200e-04
Loss = 3.6709e-03, PNorm = 35.5674, GNorm = 2.7946, lr_0 = 1.0200e-04
Validation rmse logD = 0.757895
Validation R2 logD = 0.580539
Validation rmse logP = 0.688127
Validation R2 logP = 0.862621
Epoch 8
Train function
Loss = 3.3605e-03, PNorm = 35.5706, GNorm = 2.8780, lr_0 = 1.0200e-04
Loss = 2.5878e-03, PNorm = 35.5737, GNorm = 3.6685, lr_0 = 1.0200e-04
Loss = 2.8607e-03, PNorm = 35.5766, GNorm = 4.0081, lr_0 = 1.0200e-04
Loss = 2.7459e-03, PNorm = 35.5784, GNorm = 3.4186, lr_0 = 1.0200e-04
Loss = 3.1797e-03, PNorm = 35.5812, GNorm = 4.8125, lr_0 = 1.0200e-04
Loss = 3.2315e-03, PNorm = 35.5840, GNorm = 12.8001, lr_0 = 1.0200e-04
Loss = 4.0840e-03, PNorm = 35.5866, GNorm = 7.1497, lr_0 = 1.0200e-04
Loss = 3.7632e-03, PNorm = 35.5895, GNorm = 5.2270, lr_0 = 1.0200e-04
Loss = 3.0050e-03, PNorm = 35.5924, GNorm = 2.8063, lr_0 = 1.0200e-04
Loss = 2.9152e-03, PNorm = 35.5958, GNorm = 3.3885, lr_0 = 1.0200e-04
Loss = 3.3496e-03, PNorm = 35.5986, GNorm = 2.1571, lr_0 = 1.0200e-04
Loss = 3.6716e-03, PNorm = 35.6001, GNorm = 1.9159, lr_0 = 1.0200e-04
Loss = 3.2565e-03, PNorm = 35.6014, GNorm = 2.2934, lr_0 = 1.0200e-04
Loss = 3.4582e-03, PNorm = 35.6036, GNorm = 3.0313, lr_0 = 1.0200e-04
Loss = 3.4734e-03, PNorm = 35.6058, GNorm = 5.2905, lr_0 = 1.0200e-04
Loss = 2.9931e-03, PNorm = 35.6081, GNorm = 2.2228, lr_0 = 1.0200e-04
Loss = 3.8100e-03, PNorm = 35.6109, GNorm = 2.4871, lr_0 = 1.0200e-04
Loss = 3.3840e-03, PNorm = 35.6138, GNorm = 4.3037, lr_0 = 1.0200e-04
Loss = 3.6806e-03, PNorm = 35.6168, GNorm = 5.7436, lr_0 = 1.0200e-04
Loss = 3.7089e-03, PNorm = 35.6206, GNorm = 2.9808, lr_0 = 1.0200e-04
Loss = 3.4921e-03, PNorm = 35.6231, GNorm = 2.6478, lr_0 = 1.0200e-04
Loss = 2.8516e-03, PNorm = 35.6251, GNorm = 1.9687, lr_0 = 1.0200e-04
Validation rmse logD = 0.769778
Validation R2 logD = 0.567282
Validation rmse logP = 0.609255
Validation R2 logP = 0.892308
Epoch 9
Train function
Loss = 3.3756e-03, PNorm = 35.6270, GNorm = 2.3092, lr_0 = 1.0200e-04
Loss = 4.0551e-03, PNorm = 35.6302, GNorm = 3.1471, lr_0 = 1.0200e-04
Loss = 4.0211e-03, PNorm = 35.6325, GNorm = 3.2410, lr_0 = 1.0200e-04
Loss = 2.6418e-03, PNorm = 35.6347, GNorm = 2.8793, lr_0 = 1.0200e-04
Loss = 3.4320e-03, PNorm = 35.6370, GNorm = 4.3825, lr_0 = 1.0200e-04
Loss = 3.0583e-03, PNorm = 35.6391, GNorm = 2.8939, lr_0 = 1.0200e-04
Loss = 3.1111e-03, PNorm = 35.6412, GNorm = 2.5244, lr_0 = 1.0200e-04
Loss = 2.8848e-03, PNorm = 35.6433, GNorm = 5.3051, lr_0 = 1.0200e-04
Loss = 2.9386e-03, PNorm = 35.6462, GNorm = 3.1210, lr_0 = 1.0200e-04
Loss = 3.3854e-03, PNorm = 35.6492, GNorm = 4.7265, lr_0 = 1.0200e-04
Loss = 3.3285e-03, PNorm = 35.6509, GNorm = 2.0862, lr_0 = 1.0200e-04
Loss = 2.8211e-03, PNorm = 35.6534, GNorm = 1.9207, lr_0 = 1.0200e-04
Loss = 2.7518e-03, PNorm = 35.6566, GNorm = 4.2465, lr_0 = 1.0200e-04
Loss = 3.3322e-03, PNorm = 35.6591, GNorm = 2.4949, lr_0 = 1.0200e-04
Loss = 3.3506e-03, PNorm = 35.6618, GNorm = 6.7599, lr_0 = 1.0200e-04
Loss = 3.7676e-03, PNorm = 35.6642, GNorm = 6.0217, lr_0 = 1.0200e-04
Loss = 2.7799e-03, PNorm = 35.6667, GNorm = 4.3663, lr_0 = 1.0200e-04
Loss = 2.5663e-03, PNorm = 35.6683, GNorm = 1.4428, lr_0 = 1.0200e-04
Loss = 3.4495e-03, PNorm = 35.6699, GNorm = 2.8022, lr_0 = 1.0200e-04
Loss = 3.2905e-03, PNorm = 35.6729, GNorm = 3.7685, lr_0 = 1.0200e-04
Loss = 2.8544e-03, PNorm = 35.6758, GNorm = 1.5932, lr_0 = 1.0200e-04
Loss = 2.7043e-03, PNorm = 35.6778, GNorm = 10.1903, lr_0 = 1.0200e-04
Loss = 2.6250e-03, PNorm = 35.6803, GNorm = 1.5672, lr_0 = 1.0200e-04
Validation rmse logD = 0.745891
Validation R2 logD = 0.593721
Validation rmse logP = 0.590786
Validation R2 logP = 0.898738
Epoch 10
Train function
Loss = 2.6956e-03, PNorm = 35.6831, GNorm = 2.6950, lr_0 = 1.0200e-04
Loss = 2.6229e-03, PNorm = 35.6859, GNorm = 2.0268, lr_0 = 1.0200e-04
Loss = 3.0396e-03, PNorm = 35.6878, GNorm = 5.6855, lr_0 = 1.0200e-04
Loss = 3.0495e-03, PNorm = 35.6899, GNorm = 8.6469, lr_0 = 1.0200e-04
Loss = 3.3277e-03, PNorm = 35.6915, GNorm = 5.9339, lr_0 = 1.0200e-04
Loss = 3.4554e-03, PNorm = 35.6936, GNorm = 3.0472, lr_0 = 1.0200e-04
Loss = 3.3918e-03, PNorm = 35.6966, GNorm = 3.9771, lr_0 = 1.0200e-04
Loss = 2.9050e-03, PNorm = 35.6999, GNorm = 5.3210, lr_0 = 1.0200e-04
Loss = 2.5227e-03, PNorm = 35.7032, GNorm = 2.8806, lr_0 = 1.0200e-04
Loss = 2.9220e-03, PNorm = 35.7047, GNorm = 2.1215, lr_0 = 1.0200e-04
Loss = 2.6481e-03, PNorm = 35.7071, GNorm = 3.7735, lr_0 = 1.0200e-04
Loss = 2.5398e-03, PNorm = 35.7096, GNorm = 1.8224, lr_0 = 1.0200e-04
Loss = 2.7505e-03, PNorm = 35.7120, GNorm = 3.2601, lr_0 = 1.0200e-04
Loss = 2.7654e-03, PNorm = 35.7147, GNorm = 3.4244, lr_0 = 1.0200e-04
Loss = 3.2995e-03, PNorm = 35.7176, GNorm = 1.5738, lr_0 = 1.0200e-04
Loss = 2.8119e-03, PNorm = 35.7199, GNorm = 3.1909, lr_0 = 1.0200e-04
Loss = 3.4239e-03, PNorm = 35.7218, GNorm = 4.0982, lr_0 = 1.0200e-04
Loss = 2.6537e-03, PNorm = 35.7243, GNorm = 1.3513, lr_0 = 1.0200e-04
Loss = 2.8240e-03, PNorm = 35.7269, GNorm = 1.3721, lr_0 = 1.0200e-04
Loss = 3.6733e-03, PNorm = 35.7304, GNorm = 2.6102, lr_0 = 1.0200e-04
Loss = 3.3932e-03, PNorm = 35.7337, GNorm = 1.9348, lr_0 = 1.0200e-04
Loss = 2.9400e-03, PNorm = 35.7363, GNorm = 2.1952, lr_0 = 1.0200e-04
Loss = 4.1387e-03, PNorm = 35.7388, GNorm = 2.9750, lr_0 = 1.0200e-04
Validation rmse logD = 0.727319
Validation R2 logD = 0.613701
Validation rmse logP = 0.603189
Validation R2 logP = 0.894442
Epoch 11
Train function
Loss = 2.8179e-03, PNorm = 35.7414, GNorm = 2.9992, lr_0 = 1.0200e-04
Loss = 2.7679e-03, PNorm = 35.7442, GNorm = 3.9571, lr_0 = 1.0200e-04
Loss = 2.5747e-03, PNorm = 35.7469, GNorm = 1.7171, lr_0 = 1.0200e-04
Loss = 3.1102e-03, PNorm = 35.7492, GNorm = 1.9823, lr_0 = 1.0200e-04
Loss = 2.9661e-03, PNorm = 35.7520, GNorm = 1.4185, lr_0 = 1.0200e-04
Loss = 2.6092e-03, PNorm = 35.7552, GNorm = 1.9816, lr_0 = 1.0200e-04
Loss = 3.1679e-03, PNorm = 35.7586, GNorm = 4.2826, lr_0 = 1.0200e-04
Loss = 2.7950e-03, PNorm = 35.7613, GNorm = 5.7770, lr_0 = 1.0200e-04
Loss = 2.5477e-03, PNorm = 35.7639, GNorm = 4.5267, lr_0 = 1.0200e-04
Loss = 2.1991e-03, PNorm = 35.7668, GNorm = 6.7765, lr_0 = 1.0200e-04
Loss = 2.9587e-03, PNorm = 35.7696, GNorm = 4.7928, lr_0 = 1.0200e-04
Loss = 2.8863e-03, PNorm = 35.7717, GNorm = 3.5942, lr_0 = 1.0200e-04
Loss = 2.4171e-03, PNorm = 35.7737, GNorm = 4.0560, lr_0 = 1.0200e-04
Loss = 3.0540e-03, PNorm = 35.7755, GNorm = 9.0588, lr_0 = 1.0200e-04
Loss = 3.4238e-03, PNorm = 35.7772, GNorm = 5.3726, lr_0 = 1.0200e-04
Loss = 3.1444e-03, PNorm = 35.7798, GNorm = 5.2379, lr_0 = 1.0200e-04
Loss = 3.2577e-03, PNorm = 35.7822, GNorm = 3.0620, lr_0 = 1.0200e-04
Loss = 3.7319e-03, PNorm = 35.7849, GNorm = 2.0443, lr_0 = 1.0200e-04
Loss = 2.9181e-03, PNorm = 35.7868, GNorm = 1.9840, lr_0 = 1.0200e-04
Loss = 3.2589e-03, PNorm = 35.7887, GNorm = 1.5936, lr_0 = 1.0200e-04
Loss = 2.5107e-03, PNorm = 35.7912, GNorm = 6.1517, lr_0 = 1.0200e-04
Loss = 3.3109e-03, PNorm = 35.7948, GNorm = 8.0930, lr_0 = 1.0200e-04
Validation rmse logD = 0.749071
Validation R2 logD = 0.590250
Validation rmse logP = 0.589171
Validation R2 logP = 0.899291
Epoch 12
Train function
Loss = 2.5473e-03, PNorm = 35.7977, GNorm = 1.3294, lr_0 = 1.0200e-04
Loss = 2.6016e-03, PNorm = 35.8006, GNorm = 1.1192, lr_0 = 1.0200e-04
Loss = 2.6029e-03, PNorm = 35.8032, GNorm = 2.1091, lr_0 = 1.0200e-04
Loss = 3.1735e-03, PNorm = 35.8067, GNorm = 2.3083, lr_0 = 1.0200e-04
Loss = 2.9493e-03, PNorm = 35.8096, GNorm = 3.3116, lr_0 = 1.0200e-04
Loss = 3.2901e-03, PNorm = 35.8125, GNorm = 3.6756, lr_0 = 1.0200e-04
Loss = 2.6525e-03, PNorm = 35.8154, GNorm = 2.9177, lr_0 = 1.0200e-04
Loss = 2.6125e-03, PNorm = 35.8181, GNorm = 6.1105, lr_0 = 1.0200e-04
Loss = 3.0656e-03, PNorm = 35.8207, GNorm = 7.5085, lr_0 = 1.0200e-04
Loss = 2.7492e-03, PNorm = 35.8239, GNorm = 3.2518, lr_0 = 1.0200e-04
Loss = 2.3884e-03, PNorm = 35.8272, GNorm = 6.4872, lr_0 = 1.0200e-04
Loss = 2.8539e-03, PNorm = 35.8290, GNorm = 3.0244, lr_0 = 1.0200e-04
Loss = 3.3213e-03, PNorm = 35.8311, GNorm = 2.2284, lr_0 = 1.0200e-04
Loss = 2.2722e-03, PNorm = 35.8332, GNorm = 2.3795, lr_0 = 1.0200e-04
Loss = 2.5063e-03, PNorm = 35.8357, GNorm = 2.0664, lr_0 = 1.0200e-04
Loss = 2.4977e-03, PNorm = 35.8381, GNorm = 1.9978, lr_0 = 1.0200e-04
Loss = 2.5125e-03, PNorm = 35.8407, GNorm = 2.5242, lr_0 = 1.0200e-04
Loss = 2.9760e-03, PNorm = 35.8429, GNorm = 3.3800, lr_0 = 1.0200e-04
Loss = 2.6152e-03, PNorm = 35.8449, GNorm = 1.0210, lr_0 = 1.0200e-04
Loss = 2.5687e-03, PNorm = 35.8469, GNorm = 3.2089, lr_0 = 1.0200e-04
Loss = 2.2220e-03, PNorm = 35.8496, GNorm = 4.0655, lr_0 = 1.0200e-04
Loss = 2.7418e-03, PNorm = 35.8521, GNorm = 5.6783, lr_0 = 1.0200e-04
Loss = 2.7941e-03, PNorm = 35.8536, GNorm = 5.1939, lr_0 = 1.0200e-04
Validation rmse logD = 0.692866
Validation R2 logD = 0.649432
Validation rmse logP = 0.574782
Validation R2 logP = 0.904150
Epoch 13
Train function
Loss = 2.9935e-03, PNorm = 35.8559, GNorm = 2.1960, lr_0 = 1.0200e-04
Loss = 2.4022e-03, PNorm = 35.8586, GNorm = 1.5749, lr_0 = 1.0200e-04
Loss = 2.5684e-03, PNorm = 35.8605, GNorm = 5.2017, lr_0 = 1.0200e-04
Loss = 2.4931e-03, PNorm = 35.8625, GNorm = 2.9463, lr_0 = 1.0200e-04
Loss = 2.2831e-03, PNorm = 35.8650, GNorm = 2.1694, lr_0 = 1.0200e-04
Loss = 2.1818e-03, PNorm = 35.8677, GNorm = 1.9426, lr_0 = 1.0200e-04
Loss = 2.7474e-03, PNorm = 35.8697, GNorm = 2.5382, lr_0 = 1.0200e-04
Loss = 1.9803e-03, PNorm = 35.8725, GNorm = 1.7754, lr_0 = 1.0200e-04
Loss = 2.1037e-03, PNorm = 35.8754, GNorm = 1.4901, lr_0 = 1.0200e-04
Loss = 2.6108e-03, PNorm = 35.8777, GNorm = 2.2240, lr_0 = 1.0200e-04
Loss = 2.2521e-03, PNorm = 35.8804, GNorm = 5.0307, lr_0 = 1.0200e-04
Loss = 1.8448e-03, PNorm = 35.8827, GNorm = 4.5651, lr_0 = 1.0200e-04
Loss = 3.0185e-03, PNorm = 35.8856, GNorm = 3.3263, lr_0 = 1.0200e-04
Loss = 2.5249e-03, PNorm = 35.8891, GNorm = 1.6099, lr_0 = 1.0200e-04
Loss = 3.0120e-03, PNorm = 35.8921, GNorm = 2.3045, lr_0 = 1.0200e-04
Loss = 2.6026e-03, PNorm = 35.8943, GNorm = 4.5812, lr_0 = 1.0200e-04
Loss = 2.8651e-03, PNorm = 35.8964, GNorm = 2.6967, lr_0 = 1.0200e-04
Loss = 2.9479e-03, PNorm = 35.8989, GNorm = 4.0725, lr_0 = 1.0200e-04
Loss = 2.6967e-03, PNorm = 35.9021, GNorm = 2.4814, lr_0 = 1.0200e-04
Loss = 3.0572e-03, PNorm = 35.9046, GNorm = 9.1750, lr_0 = 1.0200e-04
Loss = 3.2012e-03, PNorm = 35.9067, GNorm = 3.4981, lr_0 = 1.0200e-04
Loss = 3.0420e-03, PNorm = 35.9092, GNorm = 2.0891, lr_0 = 1.0200e-04
Validation rmse logD = 0.689727
Validation R2 logD = 0.652602
Validation rmse logP = 0.564916
Validation R2 logP = 0.907412
Epoch 14
Train function
Loss = 2.2826e-03, PNorm = 35.9121, GNorm = 1.5202, lr_0 = 1.0200e-04
Loss = 2.3521e-03, PNorm = 35.9151, GNorm = 4.6425, lr_0 = 1.0200e-04
Loss = 2.2229e-03, PNorm = 35.9172, GNorm = 3.4056, lr_0 = 1.0200e-04
Loss = 2.5598e-03, PNorm = 35.9196, GNorm = 3.2104, lr_0 = 1.0200e-04
Loss = 2.3931e-03, PNorm = 35.9220, GNorm = 7.2919, lr_0 = 1.0200e-04
Loss = 2.4276e-03, PNorm = 35.9237, GNorm = 1.6271, lr_0 = 1.0200e-04
Loss = 2.8725e-03, PNorm = 35.9256, GNorm = 5.7477, lr_0 = 1.0200e-04
Loss = 2.6425e-03, PNorm = 35.9286, GNorm = 3.6316, lr_0 = 1.0200e-04
Loss = 2.4303e-03, PNorm = 35.9327, GNorm = 3.8664, lr_0 = 1.0200e-04
Loss = 2.0982e-03, PNorm = 35.9356, GNorm = 2.3034, lr_0 = 1.0200e-04
Loss = 2.2729e-03, PNorm = 35.9383, GNorm = 3.0653, lr_0 = 1.0200e-04
Loss = 2.9312e-03, PNorm = 35.9415, GNorm = 2.6238, lr_0 = 1.0200e-04
Loss = 2.8410e-03, PNorm = 35.9427, GNorm = 3.7836, lr_0 = 1.0200e-04
Loss = 2.5274e-03, PNorm = 35.9446, GNorm = 2.6112, lr_0 = 1.0200e-04
Loss = 2.9871e-03, PNorm = 35.9464, GNorm = 5.1137, lr_0 = 1.0200e-04
Loss = 3.1335e-03, PNorm = 35.9488, GNorm = 3.6158, lr_0 = 1.0200e-04
Loss = 2.6784e-03, PNorm = 35.9510, GNorm = 2.6577, lr_0 = 1.0200e-04
Loss = 2.3084e-03, PNorm = 35.9531, GNorm = 2.8107, lr_0 = 1.0200e-04
Loss = 2.3875e-03, PNorm = 35.9560, GNorm = 2.9212, lr_0 = 1.0200e-04
Loss = 2.6372e-03, PNorm = 35.9586, GNorm = 1.9362, lr_0 = 1.0200e-04
Loss = 2.3393e-03, PNorm = 35.9608, GNorm = 5.3075, lr_0 = 1.0200e-04
Loss = 2.8126e-03, PNorm = 35.9634, GNorm = 1.5679, lr_0 = 1.0200e-04
Loss = 2.0729e-03, PNorm = 35.9663, GNorm = 1.5597, lr_0 = 1.0200e-04
Validation rmse logD = 0.717456
Validation R2 logD = 0.624107
Validation rmse logP = 0.568524
Validation R2 logP = 0.906226
Epoch 15
Train function
Loss = 2.9263e-03, PNorm = 35.9692, GNorm = 7.6431, lr_0 = 1.0200e-04
Loss = 1.9398e-03, PNorm = 35.9708, GNorm = 1.7128, lr_0 = 1.0200e-04
Loss = 2.9164e-03, PNorm = 35.9730, GNorm = 2.6622, lr_0 = 1.0200e-04
Loss = 2.6132e-03, PNorm = 35.9761, GNorm = 2.0466, lr_0 = 1.0200e-04
Loss = 2.4667e-03, PNorm = 35.9787, GNorm = 5.4307, lr_0 = 1.0200e-04
Loss = 2.6396e-03, PNorm = 35.9813, GNorm = 4.1099, lr_0 = 1.0200e-04
Loss = 2.5745e-03, PNorm = 35.9833, GNorm = 5.7330, lr_0 = 1.0200e-04
Loss = 2.5034e-03, PNorm = 35.9854, GNorm = 2.2142, lr_0 = 1.0200e-04
Loss = 2.7199e-03, PNorm = 35.9883, GNorm = 2.7608, lr_0 = 1.0200e-04
Loss = 2.2915e-03, PNorm = 35.9905, GNorm = 1.8720, lr_0 = 1.0200e-04
Loss = 2.5604e-03, PNorm = 35.9928, GNorm = 1.2893, lr_0 = 1.0200e-04
Loss = 2.1938e-03, PNorm = 35.9963, GNorm = 2.9515, lr_0 = 1.0200e-04
Loss = 2.6378e-03, PNorm = 35.9979, GNorm = 2.7629, lr_0 = 1.0200e-04
Loss = 2.7477e-03, PNorm = 36.0001, GNorm = 5.5244, lr_0 = 1.0200e-04
Loss = 2.4342e-03, PNorm = 36.0025, GNorm = 7.7226, lr_0 = 1.0200e-04
Loss = 2.5461e-03, PNorm = 36.0053, GNorm = 4.5109, lr_0 = 1.0200e-04
Loss = 2.7109e-03, PNorm = 36.0072, GNorm = 3.1944, lr_0 = 1.0200e-04
Loss = 2.4067e-03, PNorm = 36.0097, GNorm = 3.1761, lr_0 = 1.0200e-04
Loss = 2.7629e-03, PNorm = 36.0132, GNorm = 3.7094, lr_0 = 1.0200e-04
Loss = 2.3695e-03, PNorm = 36.0162, GNorm = 3.8187, lr_0 = 1.0200e-04
Loss = 2.0424e-03, PNorm = 36.0183, GNorm = 3.2648, lr_0 = 1.0200e-04
Loss = 2.0464e-03, PNorm = 36.0202, GNorm = 2.2591, lr_0 = 1.0200e-04
Validation rmse logD = 0.705834
Validation R2 logD = 0.636186
Validation rmse logP = 0.573859
Validation R2 logP = 0.904458
Epoch 16
Train function
Loss = 1.9081e-03, PNorm = 36.0242, GNorm = 2.1299, lr_0 = 1.0200e-04
Loss = 2.2876e-03, PNorm = 36.0268, GNorm = 3.7408, lr_0 = 1.0200e-04
Loss = 2.1570e-03, PNorm = 36.0292, GNorm = 3.1278, lr_0 = 1.0200e-04
Loss = 1.8481e-03, PNorm = 36.0317, GNorm = 1.5620, lr_0 = 1.0200e-04
Loss = 2.1129e-03, PNorm = 36.0337, GNorm = 2.7145, lr_0 = 1.0200e-04
Loss = 2.4691e-03, PNorm = 36.0356, GNorm = 2.1832, lr_0 = 1.0200e-04
Loss = 1.7729e-03, PNorm = 36.0383, GNorm = 3.8897, lr_0 = 1.0200e-04
Loss = 2.2266e-03, PNorm = 36.0406, GNorm = 2.5666, lr_0 = 1.0200e-04
Loss = 2.6610e-03, PNorm = 36.0423, GNorm = 3.3975, lr_0 = 1.0200e-04
Loss = 2.1322e-03, PNorm = 36.0451, GNorm = 1.7040, lr_0 = 1.0200e-04
Loss = 2.2108e-03, PNorm = 36.0475, GNorm = 2.2280, lr_0 = 1.0200e-04
Loss = 2.3733e-03, PNorm = 36.0494, GNorm = 4.8151, lr_0 = 1.0200e-04
Loss = 2.5483e-03, PNorm = 36.0515, GNorm = 2.9636, lr_0 = 1.0200e-04
Loss = 2.4380e-03, PNorm = 36.0541, GNorm = 3.0621, lr_0 = 1.0200e-04
Loss = 2.0343e-03, PNorm = 36.0571, GNorm = 4.4493, lr_0 = 1.0200e-04
Loss = 3.0957e-03, PNorm = 36.0602, GNorm = 7.1048, lr_0 = 1.0200e-04
Loss = 3.3209e-03, PNorm = 36.0619, GNorm = 6.2736, lr_0 = 1.0200e-04
Loss = 2.9000e-03, PNorm = 36.0635, GNorm = 5.2839, lr_0 = 1.0200e-04
Loss = 2.7709e-03, PNorm = 36.0660, GNorm = 2.2364, lr_0 = 1.0200e-04
Loss = 2.2419e-03, PNorm = 36.0694, GNorm = 2.7764, lr_0 = 1.0200e-04
Loss = 2.4369e-03, PNorm = 36.0733, GNorm = 4.0787, lr_0 = 1.0200e-04
Loss = 2.2318e-03, PNorm = 36.0757, GNorm = 1.4540, lr_0 = 1.0200e-04
Loss = 2.4925e-03, PNorm = 36.0791, GNorm = 2.9152, lr_0 = 1.0200e-04
Validation rmse logD = 0.666601
Validation R2 logD = 0.675507
Validation rmse logP = 0.573024
Validation R2 logP = 0.904736
Epoch 17
Train function
Loss = 2.2832e-03, PNorm = 36.0832, GNorm = 2.0630, lr_0 = 1.0200e-04
Loss = 2.1888e-03, PNorm = 36.0859, GNorm = 2.3546, lr_0 = 1.0200e-04
Loss = 2.1552e-03, PNorm = 36.0883, GNorm = 1.9963, lr_0 = 1.0200e-04
Loss = 2.0905e-03, PNorm = 36.0904, GNorm = 2.8271, lr_0 = 1.0200e-04
Loss = 2.3149e-03, PNorm = 36.0929, GNorm = 2.4076, lr_0 = 1.0200e-04
Loss = 2.2095e-03, PNorm = 36.0957, GNorm = 3.3393, lr_0 = 1.0200e-04
Loss = 2.3712e-03, PNorm = 36.0981, GNorm = 4.5619, lr_0 = 1.0200e-04
Loss = 2.4731e-03, PNorm = 36.0998, GNorm = 8.2210, lr_0 = 1.0200e-04
Loss = 2.2808e-03, PNorm = 36.1020, GNorm = 3.3735, lr_0 = 1.0200e-04
Loss = 2.1079e-03, PNorm = 36.1055, GNorm = 1.6485, lr_0 = 1.0200e-04
Loss = 2.1246e-03, PNorm = 36.1070, GNorm = 1.6587, lr_0 = 1.0200e-04
Loss = 1.8339e-03, PNorm = 36.1082, GNorm = 1.7893, lr_0 = 1.0200e-04
Loss = 1.8576e-03, PNorm = 36.1098, GNorm = 1.7731, lr_0 = 1.0200e-04
Loss = 1.7716e-03, PNorm = 36.1118, GNorm = 1.1035, lr_0 = 1.0200e-04
Loss = 2.4473e-03, PNorm = 36.1144, GNorm = 6.7670, lr_0 = 1.0200e-04
Loss = 2.1175e-03, PNorm = 36.1170, GNorm = 2.0622, lr_0 = 1.0200e-04
Loss = 1.9572e-03, PNorm = 36.1195, GNorm = 2.4214, lr_0 = 1.0200e-04
Loss = 2.2866e-03, PNorm = 36.1219, GNorm = 3.9206, lr_0 = 1.0200e-04
Loss = 2.6143e-03, PNorm = 36.1252, GNorm = 3.7593, lr_0 = 1.0200e-04
Loss = 2.5120e-03, PNorm = 36.1279, GNorm = 4.5151, lr_0 = 1.0200e-04
Loss = 2.6055e-03, PNorm = 36.1309, GNorm = 2.5815, lr_0 = 1.0200e-04
Loss = 2.3560e-03, PNorm = 36.1338, GNorm = 1.1478, lr_0 = 1.0200e-04
Validation rmse logD = 0.667410
Validation R2 logD = 0.674719
Validation rmse logP = 0.630721
Validation R2 logP = 0.884586
Epoch 18
Train function
Loss = 2.1584e-03, PNorm = 36.1362, GNorm = 3.9185, lr_0 = 1.0200e-04
Loss = 2.3230e-03, PNorm = 36.1377, GNorm = 5.1370, lr_0 = 1.0200e-04
Loss = 2.1281e-03, PNorm = 36.1391, GNorm = 2.6631, lr_0 = 1.0200e-04
Loss = 2.8809e-03, PNorm = 36.1416, GNorm = 9.2918, lr_0 = 1.0200e-04
Loss = 1.9107e-03, PNorm = 36.1456, GNorm = 4.5868, lr_0 = 1.0200e-04
Loss = 2.3529e-03, PNorm = 36.1495, GNorm = 1.3169, lr_0 = 1.0200e-04
Loss = 2.3839e-03, PNorm = 36.1511, GNorm = 3.0939, lr_0 = 1.0200e-04
Loss = 2.6372e-03, PNorm = 36.1532, GNorm = 3.5606, lr_0 = 1.0200e-04
Loss = 2.4935e-03, PNorm = 36.1556, GNorm = 4.8856, lr_0 = 1.0200e-04
Loss = 2.4814e-03, PNorm = 36.1588, GNorm = 1.5147, lr_0 = 1.0200e-04
Loss = 2.3988e-03, PNorm = 36.1618, GNorm = 1.9615, lr_0 = 1.0200e-04
Loss = 2.6627e-03, PNorm = 36.1635, GNorm = 6.7965, lr_0 = 1.0200e-04
Loss = 1.7323e-03, PNorm = 36.1654, GNorm = 1.8804, lr_0 = 1.0200e-04
Loss = 2.3105e-03, PNorm = 36.1677, GNorm = 5.5291, lr_0 = 1.0200e-04
Loss = 2.3020e-03, PNorm = 36.1707, GNorm = 4.1646, lr_0 = 1.0200e-04
Loss = 2.3642e-03, PNorm = 36.1727, GNorm = 3.4233, lr_0 = 1.0200e-04
Loss = 2.6625e-03, PNorm = 36.1746, GNorm = 2.5292, lr_0 = 1.0200e-04
Loss = 1.9805e-03, PNorm = 36.1775, GNorm = 2.2439, lr_0 = 1.0200e-04
Loss = 2.0014e-03, PNorm = 36.1795, GNorm = 2.1441, lr_0 = 1.0200e-04
Loss = 2.3580e-03, PNorm = 36.1816, GNorm = 2.3820, lr_0 = 1.0200e-04
Loss = 2.0710e-03, PNorm = 36.1834, GNorm = 6.5715, lr_0 = 1.0200e-04
Loss = 1.4933e-03, PNorm = 36.1854, GNorm = 1.1327, lr_0 = 1.0200e-04
Loss = 2.3024e-03, PNorm = 36.1877, GNorm = 2.4357, lr_0 = 1.0200e-04
Validation rmse logD = 0.668143
Validation R2 logD = 0.674004
Validation rmse logP = 0.544946
Validation R2 logP = 0.913843
Epoch 19
Train function
Loss = 1.9840e-03, PNorm = 36.1901, GNorm = 1.4303, lr_0 = 1.0200e-04
Loss = 2.5009e-03, PNorm = 36.1922, GNorm = 2.2152, lr_0 = 1.0200e-04
Loss = 2.1368e-03, PNorm = 36.1948, GNorm = 2.4229, lr_0 = 1.0200e-04
Loss = 2.0918e-03, PNorm = 36.1982, GNorm = 3.8460, lr_0 = 1.0200e-04
Loss = 2.0759e-03, PNorm = 36.2010, GNorm = 2.0441, lr_0 = 1.0200e-04
Loss = 1.8797e-03, PNorm = 36.2041, GNorm = 1.3437, lr_0 = 1.0200e-04
Loss = 2.5399e-03, PNorm = 36.2062, GNorm = 3.6778, lr_0 = 1.0200e-04
Loss = 2.3307e-03, PNorm = 36.2071, GNorm = 1.6779, lr_0 = 1.0200e-04
Loss = 2.9744e-03, PNorm = 36.2092, GNorm = 1.9927, lr_0 = 1.0200e-04
Loss = 2.2086e-03, PNorm = 36.2120, GNorm = 1.1926, lr_0 = 1.0200e-04
Loss = 2.1562e-03, PNorm = 36.2134, GNorm = 1.9400, lr_0 = 1.0200e-04
Loss = 2.4280e-03, PNorm = 36.2160, GNorm = 2.0916, lr_0 = 1.0200e-04
Loss = 2.7280e-03, PNorm = 36.2185, GNorm = 6.5520, lr_0 = 1.0200e-04
Loss = 2.6032e-03, PNorm = 36.2211, GNorm = 3.4927, lr_0 = 1.0200e-04
Loss = 2.0566e-03, PNorm = 36.2239, GNorm = 1.5885, lr_0 = 1.0200e-04
Loss = 1.8605e-03, PNorm = 36.2268, GNorm = 1.0839, lr_0 = 1.0200e-04
Loss = 1.8680e-03, PNorm = 36.2297, GNorm = 2.5490, lr_0 = 1.0200e-04
Loss = 1.8570e-03, PNorm = 36.2313, GNorm = 3.6692, lr_0 = 1.0200e-04
Loss = 2.2217e-03, PNorm = 36.2335, GNorm = 2.4904, lr_0 = 1.0200e-04
Loss = 1.6554e-03, PNorm = 36.2359, GNorm = 3.2900, lr_0 = 1.0200e-04
Loss = 2.1666e-03, PNorm = 36.2382, GNorm = 4.1826, lr_0 = 1.0200e-04
Loss = 2.0881e-03, PNorm = 36.2403, GNorm = 4.7334, lr_0 = 1.0200e-04
Validation rmse logD = 0.646854
Validation R2 logD = 0.694447
Validation rmse logP = 0.548658
Validation R2 logP = 0.912665
Epoch 20
Train function
Loss = 2.3122e-03, PNorm = 36.2425, GNorm = 3.3273, lr_0 = 1.0200e-04
Loss = 2.2633e-03, PNorm = 36.2444, GNorm = 3.9104, lr_0 = 1.0200e-04
Loss = 2.1543e-03, PNorm = 36.2467, GNorm = 1.9303, lr_0 = 1.0200e-04
Loss = 1.8389e-03, PNorm = 36.2504, GNorm = 2.2688, lr_0 = 1.0200e-04
Loss = 1.8996e-03, PNorm = 36.2542, GNorm = 3.7835, lr_0 = 1.0200e-04
Loss = 2.0691e-03, PNorm = 36.2568, GNorm = 1.1091, lr_0 = 1.0200e-04
Loss = 2.2371e-03, PNorm = 36.2591, GNorm = 2.4004, lr_0 = 1.0200e-04
Loss = 1.8159e-03, PNorm = 36.2611, GNorm = 1.8587, lr_0 = 1.0200e-04
Loss = 1.6108e-03, PNorm = 36.2638, GNorm = 2.0951, lr_0 = 1.0200e-04
Loss = 2.1830e-03, PNorm = 36.2672, GNorm = 3.2878, lr_0 = 1.0200e-04
Loss = 2.4801e-03, PNorm = 36.2695, GNorm = 4.2054, lr_0 = 1.0200e-04
Loss = 1.7680e-03, PNorm = 36.2720, GNorm = 1.1109, lr_0 = 1.0200e-04
Loss = 2.3600e-03, PNorm = 36.2740, GNorm = 2.1292, lr_0 = 1.0200e-04
Loss = 1.9797e-03, PNorm = 36.2756, GNorm = 1.7822, lr_0 = 1.0200e-04
Loss = 1.8657e-03, PNorm = 36.2772, GNorm = 2.0630, lr_0 = 1.0200e-04
Loss = 1.7596e-03, PNorm = 36.2788, GNorm = 2.3072, lr_0 = 1.0200e-04
Loss = 1.6409e-03, PNorm = 36.2804, GNorm = 2.2322, lr_0 = 1.0200e-04
Loss = 1.6887e-03, PNorm = 36.2820, GNorm = 2.7242, lr_0 = 1.0200e-04
Loss = 2.1067e-03, PNorm = 36.2839, GNorm = 5.4476, lr_0 = 1.0200e-04
Loss = 2.4773e-03, PNorm = 36.2865, GNorm = 3.4235, lr_0 = 1.0200e-04
Loss = 1.9092e-03, PNorm = 36.2891, GNorm = 1.3394, lr_0 = 1.0200e-04
Loss = 2.0542e-03, PNorm = 36.2913, GNorm = 6.0606, lr_0 = 1.0200e-04
Loss = 2.1269e-03, PNorm = 36.2935, GNorm = 1.5408, lr_0 = 1.0200e-04
Validation rmse logD = 0.654487
Validation R2 logD = 0.687194
Validation rmse logP = 0.531627
Validation R2 logP = 0.918003
Epoch 21
Train function
Loss = 2.0352e-03, PNorm = 36.2959, GNorm = 1.4352, lr_0 = 1.0200e-04
Loss = 2.1793e-03, PNorm = 36.2977, GNorm = 5.3166, lr_0 = 1.0200e-04
Loss = 1.8632e-03, PNorm = 36.2994, GNorm = 2.8694, lr_0 = 1.0200e-04
Loss = 1.8067e-03, PNorm = 36.3021, GNorm = 1.7078, lr_0 = 1.0200e-04
Loss = 2.4987e-03, PNorm = 36.3042, GNorm = 10.4268, lr_0 = 1.0200e-04
Loss = 2.0781e-03, PNorm = 36.3061, GNorm = 1.7586, lr_0 = 1.0200e-04
Loss = 1.8316e-03, PNorm = 36.3081, GNorm = 1.0597, lr_0 = 1.0200e-04
Loss = 1.7965e-03, PNorm = 36.3111, GNorm = 1.9354, lr_0 = 1.0200e-04
Loss = 2.0690e-03, PNorm = 36.3144, GNorm = 1.5195, lr_0 = 1.0200e-04
Loss = 1.5081e-03, PNorm = 36.3169, GNorm = 2.2426, lr_0 = 1.0200e-04
Loss = 1.6249e-03, PNorm = 36.3183, GNorm = 1.9112, lr_0 = 1.0200e-04
Loss = 1.6017e-03, PNorm = 36.3202, GNorm = 1.3381, lr_0 = 1.0200e-04
Loss = 2.0676e-03, PNorm = 36.3220, GNorm = 2.2111, lr_0 = 1.0200e-04
Loss = 2.1437e-03, PNorm = 36.3236, GNorm = 2.2066, lr_0 = 1.0200e-04
Loss = 1.9890e-03, PNorm = 36.3257, GNorm = 2.5961, lr_0 = 1.0200e-04
Loss = 2.1383e-03, PNorm = 36.3290, GNorm = 3.3184, lr_0 = 1.0200e-04
Loss = 1.5847e-03, PNorm = 36.3328, GNorm = 2.4908, lr_0 = 1.0200e-04
Loss = 1.8011e-03, PNorm = 36.3346, GNorm = 1.8560, lr_0 = 1.0200e-04
Loss = 1.7101e-03, PNorm = 36.3364, GNorm = 1.5018, lr_0 = 1.0200e-04
Loss = 2.1586e-03, PNorm = 36.3386, GNorm = 3.2599, lr_0 = 1.0200e-04
Loss = 1.9547e-03, PNorm = 36.3410, GNorm = 3.8121, lr_0 = 1.0200e-04
Loss = 2.1832e-03, PNorm = 36.3437, GNorm = 2.9170, lr_0 = 1.0200e-04
Loss = 2.1451e-03, PNorm = 36.3467, GNorm = 2.9006, lr_0 = 1.0200e-04
Loss = 5.6286e-03, PNorm = 36.3469, GNorm = 5.3950, lr_0 = 1.0200e-04
Validation rmse logD = 0.638458
Validation R2 logD = 0.702328
Validation rmse logP = 0.567700
Validation R2 logP = 0.906498
Epoch 22
Train function
Loss = 1.8015e-03, PNorm = 36.3492, GNorm = 1.6103, lr_0 = 1.0200e-04
Loss = 1.8491e-03, PNorm = 36.3522, GNorm = 3.0752, lr_0 = 1.0200e-04
Loss = 1.4830e-03, PNorm = 36.3547, GNorm = 2.2882, lr_0 = 1.0200e-04
Loss = 2.3304e-03, PNorm = 36.3570, GNorm = 4.8785, lr_0 = 1.0200e-04
Loss = 2.1012e-03, PNorm = 36.3591, GNorm = 0.8650, lr_0 = 1.0200e-04
Loss = 1.7859e-03, PNorm = 36.3613, GNorm = 2.5786, lr_0 = 1.0200e-04
Loss = 1.8513e-03, PNorm = 36.3631, GNorm = 1.3208, lr_0 = 1.0200e-04
Loss = 2.2967e-03, PNorm = 36.3644, GNorm = 7.4913, lr_0 = 1.0200e-04
Loss = 2.2704e-03, PNorm = 36.3662, GNorm = 2.0914, lr_0 = 1.0200e-04
Loss = 1.8892e-03, PNorm = 36.3685, GNorm = 4.1697, lr_0 = 1.0200e-04
Loss = 2.2632e-03, PNorm = 36.3721, GNorm = 3.0704, lr_0 = 1.0200e-04
Loss = 1.7606e-03, PNorm = 36.3752, GNorm = 3.9040, lr_0 = 1.0200e-04
Loss = 1.7286e-03, PNorm = 36.3774, GNorm = 3.1678, lr_0 = 1.0200e-04
Loss = 2.0260e-03, PNorm = 36.3792, GNorm = 2.5385, lr_0 = 1.0200e-04
Loss = 1.9789e-03, PNorm = 36.3809, GNorm = 0.8858, lr_0 = 1.0200e-04
Loss = 1.5709e-03, PNorm = 36.3832, GNorm = 1.3758, lr_0 = 1.0200e-04
Loss = 1.5113e-03, PNorm = 36.3856, GNorm = 3.2415, lr_0 = 1.0200e-04
Loss = 1.4967e-03, PNorm = 36.3878, GNorm = 4.2680, lr_0 = 1.0200e-04
Loss = 1.8573e-03, PNorm = 36.3904, GNorm = 3.4788, lr_0 = 1.0200e-04
Loss = 2.3406e-03, PNorm = 36.3935, GNorm = 1.9533, lr_0 = 1.0200e-04
Loss = 1.9659e-03, PNorm = 36.3966, GNorm = 1.1579, lr_0 = 1.0200e-04
Loss = 2.0803e-03, PNorm = 36.3987, GNorm = 1.8045, lr_0 = 1.0200e-04
Validation rmse logD = 0.671162
Validation R2 logD = 0.671051
Validation rmse logP = 0.525706
Validation R2 logP = 0.919819
Epoch 23
Train function
Loss = 2.0008e-03, PNorm = 36.4017, GNorm = 6.7268, lr_0 = 1.0200e-04
Loss = 1.6944e-03, PNorm = 36.4042, GNorm = 7.6547, lr_0 = 1.0200e-04
Loss = 1.8761e-03, PNorm = 36.4068, GNorm = 3.8971, lr_0 = 1.0200e-04
Loss = 2.1366e-03, PNorm = 36.4088, GNorm = 1.3218, lr_0 = 1.0200e-04
Loss = 2.2210e-03, PNorm = 36.4106, GNorm = 3.1975, lr_0 = 1.0200e-04
Loss = 2.1958e-03, PNorm = 36.4137, GNorm = 4.0447, lr_0 = 1.0200e-04
Loss = 1.8261e-03, PNorm = 36.4158, GNorm = 1.5950, lr_0 = 1.0200e-04
Loss = 2.0069e-03, PNorm = 36.4190, GNorm = 2.2526, lr_0 = 1.0200e-04
Loss = 1.7887e-03, PNorm = 36.4220, GNorm = 2.2231, lr_0 = 1.0200e-04
Loss = 1.4851e-03, PNorm = 36.4251, GNorm = 1.5912, lr_0 = 1.0200e-04
Loss = 1.9550e-03, PNorm = 36.4277, GNorm = 1.7927, lr_0 = 1.0200e-04
Loss = 1.5376e-03, PNorm = 36.4293, GNorm = 1.4544, lr_0 = 1.0200e-04
Loss = 1.6598e-03, PNorm = 36.4313, GNorm = 3.5672, lr_0 = 1.0200e-04
Loss = 1.6188e-03, PNorm = 36.4340, GNorm = 1.7376, lr_0 = 1.0200e-04
Loss = 2.0929e-03, PNorm = 36.4361, GNorm = 1.6672, lr_0 = 1.0200e-04
Loss = 1.7361e-03, PNorm = 36.4379, GNorm = 1.7075, lr_0 = 1.0200e-04
Loss = 1.7512e-03, PNorm = 36.4397, GNorm = 2.8364, lr_0 = 1.0200e-04
Loss = 1.5838e-03, PNorm = 36.4418, GNorm = 3.5837, lr_0 = 1.0200e-04
Loss = 1.7741e-03, PNorm = 36.4435, GNorm = 3.7111, lr_0 = 1.0200e-04
Loss = 2.0087e-03, PNorm = 36.4451, GNorm = 2.0172, lr_0 = 1.0200e-04
Loss = 1.7739e-03, PNorm = 36.4477, GNorm = 1.9730, lr_0 = 1.0200e-04
Loss = 1.7741e-03, PNorm = 36.4492, GNorm = 2.2144, lr_0 = 1.0200e-04
Loss = 1.9503e-03, PNorm = 36.4514, GNorm = 3.7134, lr_0 = 1.0200e-04
Validation rmse logD = 0.641773
Validation R2 logD = 0.699229
Validation rmse logP = 0.524909
Validation R2 logP = 0.920062
Epoch 24
Train function
Loss = 1.7962e-03, PNorm = 36.4540, GNorm = 1.8188, lr_0 = 1.0200e-04
Loss = 1.9415e-03, PNorm = 36.4565, GNorm = 3.2239, lr_0 = 1.0200e-04
Loss = 1.5066e-03, PNorm = 36.4590, GNorm = 3.4130, lr_0 = 1.0200e-04
Loss = 1.8978e-03, PNorm = 36.4619, GNorm = 2.1800, lr_0 = 1.0200e-04
Loss = 1.6629e-03, PNorm = 36.4643, GNorm = 5.8828, lr_0 = 1.0200e-04
Loss = 1.6238e-03, PNorm = 36.4665, GNorm = 2.0722, lr_0 = 1.0200e-04
Loss = 1.8517e-03, PNorm = 36.4691, GNorm = 1.4064, lr_0 = 1.0200e-04
Loss = 2.5344e-03, PNorm = 36.4717, GNorm = 1.9322, lr_0 = 1.0200e-04
Loss = 2.0549e-03, PNorm = 36.4737, GNorm = 2.2335, lr_0 = 1.0200e-04
Loss = 1.9841e-03, PNorm = 36.4769, GNorm = 1.5201, lr_0 = 1.0200e-04
Loss = 1.9637e-03, PNorm = 36.4788, GNorm = 1.7759, lr_0 = 1.0200e-04
Loss = 1.9200e-03, PNorm = 36.4811, GNorm = 4.2422, lr_0 = 1.0200e-04
Loss = 2.1436e-03, PNorm = 36.4830, GNorm = 3.0037, lr_0 = 1.0200e-04
Loss = 2.0851e-03, PNorm = 36.4843, GNorm = 4.7694, lr_0 = 1.0200e-04
Loss = 2.2782e-03, PNorm = 36.4864, GNorm = 2.8254, lr_0 = 1.0200e-04
Loss = 1.6663e-03, PNorm = 36.4880, GNorm = 2.3534, lr_0 = 1.0200e-04
Loss = 1.6147e-03, PNorm = 36.4907, GNorm = 1.4736, lr_0 = 1.0200e-04
Loss = 2.0011e-03, PNorm = 36.4935, GNorm = 1.5285, lr_0 = 1.0200e-04
Loss = 1.7730e-03, PNorm = 36.4956, GNorm = 5.0804, lr_0 = 1.0200e-04
Loss = 1.6458e-03, PNorm = 36.4982, GNorm = 1.8134, lr_0 = 1.0200e-04
Loss = 1.6186e-03, PNorm = 36.5006, GNorm = 2.8125, lr_0 = 1.0200e-04
Loss = 1.6822e-03, PNorm = 36.5022, GNorm = 3.1292, lr_0 = 1.0200e-04
Validation rmse logD = 0.663442
Validation R2 logD = 0.678575
Validation rmse logP = 0.515605
Validation R2 logP = 0.922871
Epoch 25
Train function
Loss = 1.3272e-03, PNorm = 36.5049, GNorm = 2.0375, lr_0 = 1.0200e-04
Loss = 1.4001e-03, PNorm = 36.5072, GNorm = 0.9282, lr_0 = 1.0200e-04
Loss = 1.6394e-03, PNorm = 36.5087, GNorm = 1.9453, lr_0 = 1.0200e-04
Loss = 1.5616e-03, PNorm = 36.5112, GNorm = 2.5066, lr_0 = 1.0200e-04
Loss = 1.8371e-03, PNorm = 36.5127, GNorm = 7.1052, lr_0 = 1.0200e-04
Loss = 2.0245e-03, PNorm = 36.5151, GNorm = 2.1621, lr_0 = 1.0200e-04
Loss = 1.4426e-03, PNorm = 36.5181, GNorm = 2.8694, lr_0 = 1.0200e-04
Loss = 2.1529e-03, PNorm = 36.5208, GNorm = 4.6423, lr_0 = 1.0200e-04
Loss = 1.4754e-03, PNorm = 36.5241, GNorm = 4.9085, lr_0 = 1.0200e-04
Loss = 1.6882e-03, PNorm = 36.5264, GNorm = 2.1453, lr_0 = 1.0200e-04
Loss = 1.6282e-03, PNorm = 36.5286, GNorm = 2.4249, lr_0 = 1.0200e-04
Loss = 2.0952e-03, PNorm = 36.5308, GNorm = 4.2960, lr_0 = 1.0200e-04
Loss = 2.1063e-03, PNorm = 36.5328, GNorm = 2.6950, lr_0 = 1.0200e-04
Loss = 1.5027e-03, PNorm = 36.5337, GNorm = 1.7392, lr_0 = 1.0200e-04
Loss = 1.5141e-03, PNorm = 36.5349, GNorm = 1.2929, lr_0 = 1.0200e-04
Loss = 1.5293e-03, PNorm = 36.5370, GNorm = 2.9660, lr_0 = 1.0200e-04
Loss = 1.7396e-03, PNorm = 36.5390, GNorm = 6.5140, lr_0 = 1.0200e-04
Loss = 2.3374e-03, PNorm = 36.5413, GNorm = 1.3791, lr_0 = 1.0200e-04
Loss = 2.2727e-03, PNorm = 36.5428, GNorm = 1.4981, lr_0 = 1.0200e-04
Loss = 1.5616e-03, PNorm = 36.5455, GNorm = 2.3857, lr_0 = 1.0200e-04
Loss = 1.6123e-03, PNorm = 36.5480, GNorm = 1.3316, lr_0 = 1.0200e-04
Loss = 1.7483e-03, PNorm = 36.5505, GNorm = 1.3773, lr_0 = 1.0200e-04
Loss = 1.9261e-03, PNorm = 36.5528, GNorm = 9.0089, lr_0 = 1.0200e-04
Validation rmse logD = 0.644959
Validation R2 logD = 0.696235
Validation rmse logP = 0.600756
Validation R2 logP = 0.895292
Epoch 26
Train function
Loss = 1.6896e-03, PNorm = 36.5549, GNorm = 1.5994, lr_0 = 1.0200e-04
Loss = 1.7019e-03, PNorm = 36.5576, GNorm = 1.5997, lr_0 = 1.0200e-04
Loss = 1.6384e-03, PNorm = 36.5601, GNorm = 1.9041, lr_0 = 1.0200e-04
Loss = 1.7202e-03, PNorm = 36.5621, GNorm = 1.6065, lr_0 = 1.0200e-04
Loss = 1.7004e-03, PNorm = 36.5648, GNorm = 1.2974, lr_0 = 1.0200e-04
Loss = 1.7846e-03, PNorm = 36.5673, GNorm = 2.3765, lr_0 = 1.0200e-04
Loss = 1.4071e-03, PNorm = 36.5698, GNorm = 2.1038, lr_0 = 1.0200e-04
Loss = 1.3287e-03, PNorm = 36.5719, GNorm = 2.0990, lr_0 = 1.0200e-04
Loss = 1.6911e-03, PNorm = 36.5741, GNorm = 1.9202, lr_0 = 1.0200e-04
Loss = 1.9070e-03, PNorm = 36.5764, GNorm = 2.6520, lr_0 = 1.0200e-04
Loss = 1.5757e-03, PNorm = 36.5783, GNorm = 1.6425, lr_0 = 1.0200e-04
Loss = 1.4163e-03, PNorm = 36.5803, GNorm = 2.1077, lr_0 = 1.0200e-04
Loss = 1.4885e-03, PNorm = 36.5814, GNorm = 3.0939, lr_0 = 1.0200e-04
Loss = 1.5307e-03, PNorm = 36.5822, GNorm = 2.5781, lr_0 = 1.0200e-04
Loss = 2.0625e-03, PNorm = 36.5835, GNorm = 3.5523, lr_0 = 1.0200e-04
Loss = 1.4599e-03, PNorm = 36.5852, GNorm = 2.3659, lr_0 = 1.0200e-04
Loss = 1.7144e-03, PNorm = 36.5874, GNorm = 4.0782, lr_0 = 1.0200e-04
Loss = 1.9476e-03, PNorm = 36.5902, GNorm = 3.5715, lr_0 = 1.0200e-04
Loss = 1.9934e-03, PNorm = 36.5925, GNorm = 4.2704, lr_0 = 1.0200e-04
Loss = 1.9061e-03, PNorm = 36.5959, GNorm = 2.9777, lr_0 = 1.0200e-04
Loss = 1.6761e-03, PNorm = 36.5980, GNorm = 2.6219, lr_0 = 1.0200e-04
Loss = 1.5700e-03, PNorm = 36.5996, GNorm = 3.0934, lr_0 = 1.0200e-04
Validation rmse logD = 0.641685
Validation R2 logD = 0.699311
Validation rmse logP = 0.511314
Validation R2 logP = 0.924149
Epoch 27
Train function
Loss = 1.7625e-03, PNorm = 36.6026, GNorm = 4.2617, lr_0 = 1.0200e-04
Loss = 1.6163e-03, PNorm = 36.6046, GNorm = 2.5406, lr_0 = 1.0200e-04
Loss = 1.3696e-03, PNorm = 36.6066, GNorm = 2.6391, lr_0 = 1.0200e-04
Loss = 1.6512e-03, PNorm = 36.6089, GNorm = 1.0770, lr_0 = 1.0200e-04
Loss = 1.9770e-03, PNorm = 36.6110, GNorm = 4.9716, lr_0 = 1.0200e-04
Loss = 1.4381e-03, PNorm = 36.6133, GNorm = 1.0394, lr_0 = 1.0200e-04
Loss = 2.1129e-03, PNorm = 36.6151, GNorm = 2.3188, lr_0 = 1.0200e-04
Loss = 1.4711e-03, PNorm = 36.6172, GNorm = 4.3398, lr_0 = 1.0200e-04
Loss = 1.4635e-03, PNorm = 36.6190, GNorm = 2.0119, lr_0 = 1.0200e-04
Loss = 1.5644e-03, PNorm = 36.6211, GNorm = 3.0204, lr_0 = 1.0200e-04
Loss = 2.0114e-03, PNorm = 36.6241, GNorm = 1.7310, lr_0 = 1.0200e-04
Loss = 1.3761e-03, PNorm = 36.6265, GNorm = 4.1141, lr_0 = 1.0200e-04
Loss = 1.7067e-03, PNorm = 36.6289, GNorm = 3.6095, lr_0 = 1.0200e-04
Loss = 1.6004e-03, PNorm = 36.6310, GNorm = 2.6613, lr_0 = 1.0200e-04
Loss = 1.7683e-03, PNorm = 36.6329, GNorm = 1.8107, lr_0 = 1.0200e-04
Loss = 2.5136e-03, PNorm = 36.6342, GNorm = 2.7905, lr_0 = 1.0200e-04
Loss = 2.1480e-03, PNorm = 36.6368, GNorm = 1.4649, lr_0 = 1.0200e-04
Loss = 1.9985e-03, PNorm = 36.6395, GNorm = 2.4623, lr_0 = 1.0200e-04
Loss = 1.5490e-03, PNorm = 36.6423, GNorm = 1.6888, lr_0 = 1.0200e-04
Loss = 1.7267e-03, PNorm = 36.6448, GNorm = 2.2184, lr_0 = 1.0200e-04
Loss = 1.5920e-03, PNorm = 36.6477, GNorm = 1.8321, lr_0 = 1.0200e-04
Loss = 1.8410e-03, PNorm = 36.6498, GNorm = 2.7045, lr_0 = 1.0200e-04
Loss = 1.7981e-03, PNorm = 36.6521, GNorm = 4.4559, lr_0 = 1.0200e-04
Validation rmse logD = 0.693289
Validation R2 logD = 0.649004
Validation rmse logP = 0.506326
Validation R2 logP = 0.925622
Epoch 28
Train function
Loss = 1.5192e-03, PNorm = 36.6542, GNorm = 2.5487, lr_0 = 1.0200e-04
Loss = 1.2400e-03, PNorm = 36.6559, GNorm = 1.8357, lr_0 = 1.0200e-04
Loss = 1.6334e-03, PNorm = 36.6579, GNorm = 3.8695, lr_0 = 1.0200e-04
Loss = 1.4158e-03, PNorm = 36.6603, GNorm = 1.9790, lr_0 = 1.0200e-04
Loss = 1.9620e-03, PNorm = 36.6618, GNorm = 2.4967, lr_0 = 1.0200e-04
Loss = 1.5927e-03, PNorm = 36.6631, GNorm = 2.4120, lr_0 = 1.0200e-04
Loss = 1.6074e-03, PNorm = 36.6651, GNorm = 4.6420, lr_0 = 1.0200e-04
Loss = 1.6830e-03, PNorm = 36.6677, GNorm = 2.7974, lr_0 = 1.0200e-04
Loss = 1.4714e-03, PNorm = 36.6702, GNorm = 1.7689, lr_0 = 1.0200e-04
Loss = 1.5603e-03, PNorm = 36.6731, GNorm = 2.4109, lr_0 = 1.0200e-04
Loss = 1.5149e-03, PNorm = 36.6745, GNorm = 3.2421, lr_0 = 1.0200e-04
Loss = 1.8239e-03, PNorm = 36.6775, GNorm = 1.1935, lr_0 = 1.0200e-04
Loss = 1.3816e-03, PNorm = 36.6802, GNorm = 1.4408, lr_0 = 1.0200e-04
Loss = 1.4501e-03, PNorm = 36.6814, GNorm = 2.9234, lr_0 = 1.0200e-04
Loss = 1.5290e-03, PNorm = 36.6839, GNorm = 1.4165, lr_0 = 1.0200e-04
Loss = 1.6191e-03, PNorm = 36.6852, GNorm = 1.8068, lr_0 = 1.0200e-04
Loss = 1.8400e-03, PNorm = 36.6871, GNorm = 1.4007, lr_0 = 1.0200e-04
Loss = 1.3614e-03, PNorm = 36.6894, GNorm = 2.8639, lr_0 = 1.0200e-04
Loss = 1.9136e-03, PNorm = 36.6920, GNorm = 1.4511, lr_0 = 1.0200e-04
Loss = 1.9464e-03, PNorm = 36.6943, GNorm = 1.6681, lr_0 = 1.0200e-04
Loss = 1.5919e-03, PNorm = 36.6965, GNorm = 1.0973, lr_0 = 1.0200e-04
Loss = 1.5224e-03, PNorm = 36.6982, GNorm = 2.1691, lr_0 = 1.0200e-04
Validation rmse logD = 0.607851
Validation R2 logD = 0.730184
Validation rmse logP = 0.506402
Validation R2 logP = 0.925600
Epoch 29
Train function
Loss = 1.1629e-03, PNorm = 36.7008, GNorm = 1.6322, lr_0 = 1.0200e-04
Loss = 1.3326e-03, PNorm = 36.7039, GNorm = 2.2226, lr_0 = 1.0200e-04
Loss = 1.7593e-03, PNorm = 36.7057, GNorm = 2.1169, lr_0 = 1.0200e-04
Loss = 1.3778e-03, PNorm = 36.7067, GNorm = 1.6083, lr_0 = 1.0200e-04
Loss = 1.6071e-03, PNorm = 36.7089, GNorm = 2.3645, lr_0 = 1.0200e-04
Loss = 1.4147e-03, PNorm = 36.7112, GNorm = 2.9504, lr_0 = 1.0200e-04
Loss = 1.2293e-03, PNorm = 36.7129, GNorm = 4.5381, lr_0 = 1.0200e-04
Loss = 1.3202e-03, PNorm = 36.7144, GNorm = 2.0594, lr_0 = 1.0200e-04
Loss = 1.4688e-03, PNorm = 36.7160, GNorm = 4.7415, lr_0 = 1.0200e-04
Loss = 1.4942e-03, PNorm = 36.7177, GNorm = 1.5000, lr_0 = 1.0200e-04
Loss = 1.5013e-03, PNorm = 36.7192, GNorm = 2.2028, lr_0 = 1.0200e-04
Loss = 1.9242e-03, PNorm = 36.7221, GNorm = 3.7881, lr_0 = 1.0200e-04
Loss = 1.4837e-03, PNorm = 36.7248, GNorm = 2.3430, lr_0 = 1.0200e-04
Loss = 1.5230e-03, PNorm = 36.7280, GNorm = 2.1309, lr_0 = 1.0200e-04
Loss = 1.7675e-03, PNorm = 36.7304, GNorm = 1.2211, lr_0 = 1.0200e-04
Loss = 1.4341e-03, PNorm = 36.7323, GNorm = 2.3129, lr_0 = 1.0200e-04
Loss = 1.5705e-03, PNorm = 36.7342, GNorm = 2.4895, lr_0 = 1.0200e-04
Loss = 1.5527e-03, PNorm = 36.7364, GNorm = 1.0333, lr_0 = 1.0200e-04
Loss = 1.3495e-03, PNorm = 36.7387, GNorm = 2.3998, lr_0 = 1.0200e-04
Loss = 1.5639e-03, PNorm = 36.7411, GNorm = 2.3456, lr_0 = 1.0200e-04
Loss = 1.6488e-03, PNorm = 36.7434, GNorm = 2.1620, lr_0 = 1.0200e-04
Loss = 1.2599e-03, PNorm = 36.7452, GNorm = 1.4585, lr_0 = 1.0200e-04
Loss = 1.6839e-03, PNorm = 36.7469, GNorm = 1.9171, lr_0 = 1.0200e-04
Validation rmse logD = 0.609094
Validation R2 logD = 0.729079
Validation rmse logP = 0.501198
Validation R2 logP = 0.927121
Epoch 30
Train function
Loss = 1.4956e-03, PNorm = 36.7499, GNorm = 2.2304, lr_0 = 1.0200e-04
Loss = 1.5916e-03, PNorm = 36.7528, GNorm = 3.4804, lr_0 = 1.0200e-04
Loss = 1.5688e-03, PNorm = 36.7546, GNorm = 5.0582, lr_0 = 1.0200e-04
Loss = 1.3673e-03, PNorm = 36.7566, GNorm = 5.0931, lr_0 = 1.0200e-04
Loss = 1.7496e-03, PNorm = 36.7575, GNorm = 2.3740, lr_0 = 1.0200e-04
Loss = 1.4783e-03, PNorm = 36.7595, GNorm = 3.2365, lr_0 = 1.0200e-04
Loss = 1.3307e-03, PNorm = 36.7617, GNorm = 2.2894, lr_0 = 1.0200e-04
Loss = 1.4169e-03, PNorm = 36.7642, GNorm = 1.7027, lr_0 = 1.0200e-04
Loss = 1.5262e-03, PNorm = 36.7652, GNorm = 3.2896, lr_0 = 1.0200e-04
Loss = 1.3814e-03, PNorm = 36.7661, GNorm = 3.3644, lr_0 = 1.0200e-04
Loss = 1.4365e-03, PNorm = 36.7682, GNorm = 4.2611, lr_0 = 1.0200e-04
Loss = 1.5825e-03, PNorm = 36.7703, GNorm = 2.3954, lr_0 = 1.0200e-04
Loss = 1.7196e-03, PNorm = 36.7734, GNorm = 2.9417, lr_0 = 1.0200e-04
Loss = 1.2642e-03, PNorm = 36.7754, GNorm = 1.5209, lr_0 = 1.0200e-04
Loss = 1.4009e-03, PNorm = 36.7776, GNorm = 2.9008, lr_0 = 1.0200e-04
Loss = 1.3631e-03, PNorm = 36.7791, GNorm = 1.3198, lr_0 = 1.0200e-04
Loss = 1.2350e-03, PNorm = 36.7808, GNorm = 1.4696, lr_0 = 1.0200e-04
Loss = 1.4755e-03, PNorm = 36.7825, GNorm = 1.6089, lr_0 = 1.0200e-04
Loss = 1.6261e-03, PNorm = 36.7847, GNorm = 2.3182, lr_0 = 1.0200e-04
Loss = 1.6247e-03, PNorm = 36.7869, GNorm = 4.2882, lr_0 = 1.0200e-04
Loss = 1.3856e-03, PNorm = 36.7883, GNorm = 5.1744, lr_0 = 1.0200e-04
Loss = 1.3313e-03, PNorm = 36.7904, GNorm = 2.6104, lr_0 = 1.0200e-04
Validation rmse logD = 0.625168
Validation R2 logD = 0.714591
Validation rmse logP = 0.533854
Validation R2 logP = 0.917314
Epoch 31
Train function
Loss = 1.3988e-03, PNorm = 36.7933, GNorm = 2.1989, lr_0 = 1.0200e-04
Loss = 1.3113e-03, PNorm = 36.7954, GNorm = 4.5229, lr_0 = 1.0200e-04
Loss = 1.4018e-03, PNorm = 36.7966, GNorm = 1.6134, lr_0 = 1.0200e-04
Loss = 1.3202e-03, PNorm = 36.7987, GNorm = 4.9234, lr_0 = 1.0200e-04
Loss = 1.6491e-03, PNorm = 36.8018, GNorm = 2.9335, lr_0 = 1.0200e-04
Loss = 1.5595e-03, PNorm = 36.8036, GNorm = 3.9796, lr_0 = 1.0200e-04
Loss = 1.4045e-03, PNorm = 36.8050, GNorm = 2.5196, lr_0 = 1.0200e-04
Loss = 1.2903e-03, PNorm = 36.8067, GNorm = 2.1410, lr_0 = 1.0200e-04
Loss = 1.5004e-03, PNorm = 36.8085, GNorm = 1.5663, lr_0 = 1.0200e-04
Loss = 1.2373e-03, PNorm = 36.8104, GNorm = 3.5704, lr_0 = 1.0200e-04
Loss = 1.3958e-03, PNorm = 36.8127, GNorm = 1.5192, lr_0 = 1.0200e-04
Loss = 1.7049e-03, PNorm = 36.8146, GNorm = 5.7998, lr_0 = 1.0200e-04
Loss = 1.4148e-03, PNorm = 36.8166, GNorm = 2.1787, lr_0 = 1.0200e-04
Loss = 1.6873e-03, PNorm = 36.8193, GNorm = 2.3937, lr_0 = 1.0200e-04
Loss = 1.3507e-03, PNorm = 36.8222, GNorm = 4.4876, lr_0 = 1.0200e-04
Loss = 1.7302e-03, PNorm = 36.8246, GNorm = 2.2584, lr_0 = 1.0200e-04
Loss = 1.3670e-03, PNorm = 36.8275, GNorm = 3.6795, lr_0 = 1.0200e-04
Loss = 2.0721e-03, PNorm = 36.8298, GNorm = 1.8848, lr_0 = 1.0200e-04
Loss = 1.4742e-03, PNorm = 36.8312, GNorm = 1.7562, lr_0 = 1.0200e-04
Loss = 1.4555e-03, PNorm = 36.8340, GNorm = 1.9638, lr_0 = 1.0200e-04
Loss = 1.2270e-03, PNorm = 36.8362, GNorm = 1.4946, lr_0 = 1.0200e-04
Loss = 1.5524e-03, PNorm = 36.8384, GNorm = 4.0498, lr_0 = 1.0200e-04
Loss = 1.8950e-03, PNorm = 36.8403, GNorm = 4.2139, lr_0 = 1.0200e-04
Validation rmse logD = 0.612983
Validation R2 logD = 0.725609
Validation rmse logP = 0.552177
Validation R2 logP = 0.911541
Epoch 32
Train function
Loss = 1.3424e-03, PNorm = 36.8425, GNorm = 1.9319, lr_0 = 1.0200e-04
Loss = 1.2410e-03, PNorm = 36.8444, GNorm = 1.8573, lr_0 = 1.0200e-04
Loss = 1.2947e-03, PNorm = 36.8462, GNorm = 1.9550, lr_0 = 1.0200e-04
Loss = 1.2148e-03, PNorm = 36.8484, GNorm = 2.8097, lr_0 = 1.0200e-04
Loss = 1.5740e-03, PNorm = 36.8505, GNorm = 5.3260, lr_0 = 1.0200e-04
Loss = 1.5605e-03, PNorm = 36.8531, GNorm = 4.2945, lr_0 = 1.0200e-04
Loss = 1.5729e-03, PNorm = 36.8551, GNorm = 2.5920, lr_0 = 1.0200e-04
Loss = 1.5210e-03, PNorm = 36.8558, GNorm = 4.7147, lr_0 = 1.0200e-04
Loss = 1.4084e-03, PNorm = 36.8581, GNorm = 1.9371, lr_0 = 1.0200e-04
Loss = 1.3067e-03, PNorm = 36.8603, GNorm = 1.3442, lr_0 = 1.0200e-04
Loss = 1.4277e-03, PNorm = 36.8621, GNorm = 1.1721, lr_0 = 1.0200e-04
Loss = 1.9248e-03, PNorm = 36.8638, GNorm = 1.2538, lr_0 = 1.0200e-04
Loss = 1.2179e-03, PNorm = 36.8657, GNorm = 2.6208, lr_0 = 1.0200e-04
Loss = 1.4971e-03, PNorm = 36.8681, GNorm = 2.1520, lr_0 = 1.0200e-04
Loss = 1.2724e-03, PNorm = 36.8702, GNorm = 1.5052, lr_0 = 1.0200e-04
Loss = 1.4840e-03, PNorm = 36.8722, GNorm = 1.7615, lr_0 = 1.0200e-04
Loss = 1.2966e-03, PNorm = 36.8744, GNorm = 2.7538, lr_0 = 1.0200e-04
Loss = 1.1209e-03, PNorm = 36.8764, GNorm = 2.0386, lr_0 = 1.0200e-04
Loss = 1.6362e-03, PNorm = 36.8782, GNorm = 4.6105, lr_0 = 1.0200e-04
Loss = 1.5566e-03, PNorm = 36.8791, GNorm = 5.4685, lr_0 = 1.0200e-04
Loss = 1.6925e-03, PNorm = 36.8815, GNorm = 5.3616, lr_0 = 1.0200e-04
Loss = 1.4944e-03, PNorm = 36.8845, GNorm = 3.0427, lr_0 = 1.0200e-04
Loss = 1.4918e-03, PNorm = 36.8884, GNorm = 3.2714, lr_0 = 1.0200e-04
Loss = 1.3818e-03, PNorm = 36.8888, GNorm = 1.2405, lr_0 = 1.0200e-04
Validation rmse logD = 0.623705
Validation R2 logD = 0.715926
Validation rmse logP = 0.496025
Validation R2 logP = 0.928617
Epoch 33
Train function
Loss = 1.2223e-03, PNorm = 36.8916, GNorm = 1.1370, lr_0 = 1.0200e-04
Loss = 1.1562e-03, PNorm = 36.8935, GNorm = 3.1121, lr_0 = 1.0200e-04
Loss = 1.3835e-03, PNorm = 36.8953, GNorm = 2.2988, lr_0 = 1.0200e-04
Loss = 1.1252e-03, PNorm = 36.8967, GNorm = 1.1187, lr_0 = 1.0200e-04
Loss = 1.6968e-03, PNorm = 36.8981, GNorm = 2.1493, lr_0 = 1.0200e-04
Loss = 1.5991e-03, PNorm = 36.8997, GNorm = 1.8143, lr_0 = 1.0200e-04
Loss = 1.8236e-03, PNorm = 36.9014, GNorm = 4.2373, lr_0 = 1.0200e-04
Loss = 1.5734e-03, PNorm = 36.9035, GNorm = 4.9497, lr_0 = 1.0200e-04
Loss = 1.8501e-03, PNorm = 36.9071, GNorm = 1.8985, lr_0 = 1.0200e-04
Loss = 1.3797e-03, PNorm = 36.9098, GNorm = 0.9967, lr_0 = 1.0200e-04
Loss = 1.1870e-03, PNorm = 36.9122, GNorm = 2.2058, lr_0 = 1.0200e-04
Loss = 1.1176e-03, PNorm = 36.9149, GNorm = 1.6492, lr_0 = 1.0200e-04
Loss = 1.3421e-03, PNorm = 36.9168, GNorm = 3.4002, lr_0 = 1.0200e-04
Loss = 1.2597e-03, PNorm = 36.9192, GNorm = 1.5821, lr_0 = 1.0200e-04
Loss = 1.6629e-03, PNorm = 36.9215, GNorm = 2.9436, lr_0 = 1.0200e-04
Loss = 1.2643e-03, PNorm = 36.9238, GNorm = 1.8569, lr_0 = 1.0200e-04
Loss = 1.3877e-03, PNorm = 36.9255, GNorm = 3.0529, lr_0 = 1.0200e-04
Loss = 1.3096e-03, PNorm = 36.9267, GNorm = 3.0804, lr_0 = 1.0200e-04
Loss = 1.3029e-03, PNorm = 36.9290, GNorm = 1.2521, lr_0 = 1.0200e-04
Loss = 1.5693e-03, PNorm = 36.9311, GNorm = 2.3556, lr_0 = 1.0200e-04
Loss = 1.3212e-03, PNorm = 36.9330, GNorm = 2.8871, lr_0 = 1.0200e-04
Loss = 1.2851e-03, PNorm = 36.9340, GNorm = 1.7547, lr_0 = 1.0200e-04
Validation rmse logD = 0.602668
Validation R2 logD = 0.734766
Validation rmse logP = 0.495050
Validation R2 logP = 0.928898
Epoch 34
Train function
Loss = 1.1647e-03, PNorm = 36.9362, GNorm = 1.5558, lr_0 = 1.0200e-04
Loss = 1.3672e-03, PNorm = 36.9384, GNorm = 5.1986, lr_0 = 1.0200e-04
Loss = 1.4029e-03, PNorm = 36.9404, GNorm = 3.0055, lr_0 = 1.0200e-04
Loss = 1.6913e-03, PNorm = 36.9421, GNorm = 6.1970, lr_0 = 1.0200e-04
Loss = 1.2667e-03, PNorm = 36.9445, GNorm = 3.6587, lr_0 = 1.0200e-04
Loss = 1.3609e-03, PNorm = 36.9463, GNorm = 1.4787, lr_0 = 1.0200e-04
Loss = 1.3779e-03, PNorm = 36.9481, GNorm = 3.1492, lr_0 = 1.0200e-04
Loss = 1.2980e-03, PNorm = 36.9501, GNorm = 3.3172, lr_0 = 1.0200e-04
Loss = 1.1520e-03, PNorm = 36.9521, GNorm = 2.5147, lr_0 = 1.0200e-04
Loss = 1.2705e-03, PNorm = 36.9540, GNorm = 1.2738, lr_0 = 1.0200e-04
Loss = 1.2398e-03, PNorm = 36.9556, GNorm = 2.7637, lr_0 = 1.0200e-04
Loss = 1.3482e-03, PNorm = 36.9575, GNorm = 1.2929, lr_0 = 1.0200e-04
Loss = 1.2703e-03, PNorm = 36.9599, GNorm = 1.5209, lr_0 = 1.0200e-04
Loss = 1.3564e-03, PNorm = 36.9622, GNorm = 1.4536, lr_0 = 1.0200e-04
Loss = 1.0591e-03, PNorm = 36.9645, GNorm = 1.5822, lr_0 = 1.0200e-04
Loss = 1.3608e-03, PNorm = 36.9669, GNorm = 5.8078, lr_0 = 1.0200e-04
Loss = 1.3340e-03, PNorm = 36.9676, GNorm = 2.0001, lr_0 = 1.0200e-04
Loss = 1.2478e-03, PNorm = 36.9696, GNorm = 2.5798, lr_0 = 1.0200e-04
Loss = 1.3143e-03, PNorm = 36.9720, GNorm = 5.0599, lr_0 = 1.0200e-04
Loss = 1.3430e-03, PNorm = 36.9738, GNorm = 3.3305, lr_0 = 1.0200e-04
Loss = 1.7591e-03, PNorm = 36.9759, GNorm = 1.2179, lr_0 = 1.0200e-04
Loss = 1.2734e-03, PNorm = 36.9781, GNorm = 3.2274, lr_0 = 1.0200e-04
Loss = 1.1435e-03, PNorm = 36.9811, GNorm = 1.2733, lr_0 = 1.0200e-04
Validation rmse logD = 0.616876
Validation R2 logD = 0.722112
Validation rmse logP = 0.493832
Validation R2 logP = 0.929247
Epoch 35
Train function
Loss = 1.1038e-03, PNorm = 36.9839, GNorm = 1.2873, lr_0 = 1.0200e-04
Loss = 1.2104e-03, PNorm = 36.9859, GNorm = 1.8164, lr_0 = 1.0200e-04
Loss = 1.1723e-03, PNorm = 36.9880, GNorm = 4.1425, lr_0 = 1.0200e-04
Loss = 1.1111e-03, PNorm = 36.9899, GNorm = 3.6100, lr_0 = 1.0200e-04
Loss = 1.2125e-03, PNorm = 36.9911, GNorm = 1.6870, lr_0 = 1.0200e-04
Loss = 1.3746e-03, PNorm = 36.9926, GNorm = 4.2305, lr_0 = 1.0200e-04
Loss = 1.5701e-03, PNorm = 36.9948, GNorm = 3.5237, lr_0 = 1.0200e-04
Loss = 1.3748e-03, PNorm = 36.9977, GNorm = 4.3222, lr_0 = 1.0200e-04
Loss = 9.9551e-04, PNorm = 36.9994, GNorm = 1.4827, lr_0 = 1.0200e-04
Loss = 1.6346e-03, PNorm = 37.0020, GNorm = 4.6243, lr_0 = 1.0200e-04
Loss = 1.3698e-03, PNorm = 37.0042, GNorm = 4.9929, lr_0 = 1.0200e-04
Loss = 1.3081e-03, PNorm = 37.0056, GNorm = 2.5280, lr_0 = 1.0200e-04
Loss = 1.4323e-03, PNorm = 37.0079, GNorm = 2.0862, lr_0 = 1.0200e-04
Loss = 1.6109e-03, PNorm = 37.0103, GNorm = 1.5384, lr_0 = 1.0200e-04
Loss = 1.2843e-03, PNorm = 37.0122, GNorm = 3.3269, lr_0 = 1.0200e-04
Loss = 1.3508e-03, PNorm = 37.0143, GNorm = 1.6104, lr_0 = 1.0200e-04
Loss = 1.4989e-03, PNorm = 37.0162, GNorm = 2.8093, lr_0 = 1.0200e-04
Loss = 1.4084e-03, PNorm = 37.0171, GNorm = 2.6463, lr_0 = 1.0200e-04
Loss = 1.2292e-03, PNorm = 37.0180, GNorm = 4.0998, lr_0 = 1.0200e-04
Loss = 1.5739e-03, PNorm = 37.0197, GNorm = 2.5342, lr_0 = 1.0200e-04
Loss = 1.4290e-03, PNorm = 37.0209, GNorm = 0.9000, lr_0 = 1.0200e-04
Loss = 1.2086e-03, PNorm = 37.0229, GNorm = 1.7646, lr_0 = 1.0200e-04
Validation rmse logD = 0.613611
Validation R2 logD = 0.725046
Validation rmse logP = 0.495970
Validation R2 logP = 0.928633
Epoch 36
Train function
Loss = 1.4148e-03, PNorm = 37.0250, GNorm = 2.0922, lr_0 = 1.0200e-04
Loss = 1.2481e-03, PNorm = 37.0272, GNorm = 2.4249, lr_0 = 1.0200e-04
Loss = 1.1867e-03, PNorm = 37.0299, GNorm = 2.9483, lr_0 = 1.0200e-04
Loss = 1.3947e-03, PNorm = 37.0318, GNorm = 3.0383, lr_0 = 1.0200e-04
Loss = 1.3580e-03, PNorm = 37.0334, GNorm = 3.6846, lr_0 = 1.0200e-04
Loss = 1.2803e-03, PNorm = 37.0354, GNorm = 3.7766, lr_0 = 1.0200e-04
Loss = 1.2383e-03, PNorm = 37.0377, GNorm = 2.2475, lr_0 = 1.0200e-04
Loss = 9.8761e-04, PNorm = 37.0393, GNorm = 0.8845, lr_0 = 1.0200e-04
Loss = 1.4903e-03, PNorm = 37.0418, GNorm = 1.7155, lr_0 = 1.0200e-04
Loss = 1.2285e-03, PNorm = 37.0442, GNorm = 1.9350, lr_0 = 1.0200e-04
Loss = 1.4305e-03, PNorm = 37.0456, GNorm = 2.3225, lr_0 = 1.0200e-04
Loss = 1.3305e-03, PNorm = 37.0487, GNorm = 3.1243, lr_0 = 1.0200e-04
Loss = 1.3627e-03, PNorm = 37.0516, GNorm = 2.7632, lr_0 = 1.0200e-04
Loss = 1.2064e-03, PNorm = 37.0536, GNorm = 2.1317, lr_0 = 1.0200e-04
Loss = 1.1153e-03, PNorm = 37.0557, GNorm = 2.8171, lr_0 = 1.0200e-04
Loss = 1.6398e-03, PNorm = 37.0581, GNorm = 2.4438, lr_0 = 1.0200e-04
Loss = 1.3397e-03, PNorm = 37.0605, GNorm = 7.0334, lr_0 = 1.0200e-04
Loss = 1.4920e-03, PNorm = 37.0637, GNorm = 3.0167, lr_0 = 1.0200e-04
Loss = 1.2663e-03, PNorm = 37.0652, GNorm = 2.3325, lr_0 = 1.0200e-04
Loss = 1.3925e-03, PNorm = 37.0659, GNorm = 6.5352, lr_0 = 1.0200e-04
Loss = 1.7663e-03, PNorm = 37.0675, GNorm = 3.8460, lr_0 = 1.0200e-04
Loss = 1.3526e-03, PNorm = 37.0694, GNorm = 3.7285, lr_0 = 1.0200e-04
Loss = 1.8116e-03, PNorm = 37.0724, GNorm = 0.7389, lr_0 = 1.0200e-04
Validation rmse logD = 0.602761
Validation R2 logD = 0.734684
Validation rmse logP = 0.493960
Validation R2 logP = 0.929211
Epoch 37
Train function
Loss = 1.6555e-03, PNorm = 37.0742, GNorm = 3.5818, lr_0 = 1.0200e-04
Loss = 1.3064e-03, PNorm = 37.0775, GNorm = 3.2570, lr_0 = 1.0200e-04
Loss = 1.0267e-03, PNorm = 37.0795, GNorm = 1.4903, lr_0 = 1.0200e-04
Loss = 1.2908e-03, PNorm = 37.0810, GNorm = 2.2948, lr_0 = 1.0200e-04
Loss = 1.1903e-03, PNorm = 37.0828, GNorm = 1.4270, lr_0 = 1.0200e-04
Loss = 1.1042e-03, PNorm = 37.0844, GNorm = 2.2816, lr_0 = 1.0200e-04
Loss = 1.4847e-03, PNorm = 37.0860, GNorm = 6.1313, lr_0 = 1.0200e-04
Loss = 1.7251e-03, PNorm = 37.0883, GNorm = 2.5761, lr_0 = 1.0200e-04
Loss = 1.4151e-03, PNorm = 37.0901, GNorm = 2.9138, lr_0 = 1.0200e-04
Loss = 1.3306e-03, PNorm = 37.0919, GNorm = 2.3196, lr_0 = 1.0200e-04
Loss = 1.3757e-03, PNorm = 37.0933, GNorm = 2.0110, lr_0 = 1.0200e-04
Loss = 1.4221e-03, PNorm = 37.0952, GNorm = 2.4928, lr_0 = 1.0200e-04
Loss = 1.0876e-03, PNorm = 37.0966, GNorm = 1.4161, lr_0 = 1.0200e-04
Loss = 1.4798e-03, PNorm = 37.0991, GNorm = 2.3248, lr_0 = 1.0200e-04
Loss = 9.4744e-04, PNorm = 37.1012, GNorm = 1.4555, lr_0 = 1.0200e-04
Loss = 1.0699e-03, PNorm = 37.1031, GNorm = 2.6890, lr_0 = 1.0200e-04
Loss = 1.1539e-03, PNorm = 37.1044, GNorm = 1.6744, lr_0 = 1.0200e-04
Loss = 1.2112e-03, PNorm = 37.1063, GNorm = 2.1620, lr_0 = 1.0200e-04
Loss = 1.1742e-03, PNorm = 37.1087, GNorm = 2.0762, lr_0 = 1.0200e-04
Loss = 1.0828e-03, PNorm = 37.1106, GNorm = 1.2334, lr_0 = 1.0200e-04
Loss = 1.3541e-03, PNorm = 37.1135, GNorm = 1.9048, lr_0 = 1.0200e-04
Loss = 1.4261e-03, PNorm = 37.1160, GNorm = 3.6086, lr_0 = 1.0200e-04
Validation rmse logD = 0.795221
Validation R2 logD = 0.538205
Validation rmse logP = 0.524669
Validation R2 logP = 0.920135
Epoch 38
Train function
Loss = 3.0732e-03, PNorm = 37.1181, GNorm = 7.5443, lr_0 = 1.0200e-04
Loss = 1.7947e-03, PNorm = 37.1198, GNorm = 2.7182, lr_0 = 1.0200e-04
Loss = 1.2145e-03, PNorm = 37.1219, GNorm = 1.3889, lr_0 = 1.0200e-04
Loss = 1.1356e-03, PNorm = 37.1236, GNorm = 1.5151, lr_0 = 1.0200e-04
Loss = 1.0977e-03, PNorm = 37.1258, GNorm = 1.5864, lr_0 = 1.0200e-04
Loss = 1.0597e-03, PNorm = 37.1279, GNorm = 2.1230, lr_0 = 1.0200e-04
Loss = 1.1911e-03, PNorm = 37.1305, GNorm = 1.8345, lr_0 = 1.0200e-04
Loss = 1.3283e-03, PNorm = 37.1325, GNorm = 4.9398, lr_0 = 1.0200e-04
Loss = 1.0061e-03, PNorm = 37.1345, GNorm = 1.9996, lr_0 = 1.0200e-04
Loss = 1.1808e-03, PNorm = 37.1366, GNorm = 1.5102, lr_0 = 1.0200e-04
Loss = 1.1385e-03, PNorm = 37.1382, GNorm = 2.0549, lr_0 = 1.0200e-04
Loss = 1.1250e-03, PNorm = 37.1396, GNorm = 3.1347, lr_0 = 1.0200e-04
Loss = 9.5772e-04, PNorm = 37.1421, GNorm = 1.8231, lr_0 = 1.0200e-04
Loss = 1.3802e-03, PNorm = 37.1448, GNorm = 2.3147, lr_0 = 1.0200e-04
Loss = 1.1675e-03, PNorm = 37.1475, GNorm = 2.7623, lr_0 = 1.0200e-04
Loss = 1.4294e-03, PNorm = 37.1489, GNorm = 1.9137, lr_0 = 1.0200e-04
Loss = 1.2091e-03, PNorm = 37.1508, GNorm = 2.2579, lr_0 = 1.0200e-04
Loss = 1.4364e-03, PNorm = 37.1527, GNorm = 3.5189, lr_0 = 1.0200e-04
Loss = 1.3937e-03, PNorm = 37.1535, GNorm = 2.5360, lr_0 = 1.0200e-04
Loss = 1.2100e-03, PNorm = 37.1556, GNorm = 1.6940, lr_0 = 1.0200e-04
Loss = 9.9542e-04, PNorm = 37.1585, GNorm = 1.9482, lr_0 = 1.0200e-04
Loss = 1.3064e-03, PNorm = 37.1610, GNorm = 1.4166, lr_0 = 1.0200e-04
Loss = 1.1545e-03, PNorm = 37.1619, GNorm = 1.2294, lr_0 = 1.0200e-04
Validation rmse logD = 0.596647
Validation R2 logD = 0.740039
Validation rmse logP = 0.515639
Validation R2 logP = 0.922861
Epoch 39
Train function
Loss = 1.2016e-03, PNorm = 37.1636, GNorm = 1.9691, lr_0 = 1.0200e-04
Loss = 1.3341e-03, PNorm = 37.1656, GNorm = 4.7564, lr_0 = 1.0200e-04
Loss = 1.4557e-03, PNorm = 37.1669, GNorm = 2.8548, lr_0 = 1.0200e-04
Loss = 1.1861e-03, PNorm = 37.1691, GNorm = 2.9155, lr_0 = 1.0200e-04
Loss = 9.6819e-04, PNorm = 37.1720, GNorm = 1.3053, lr_0 = 1.0200e-04
Loss = 1.1271e-03, PNorm = 37.1736, GNorm = 2.4243, lr_0 = 1.0200e-04
Loss = 1.2689e-03, PNorm = 37.1751, GNorm = 2.1275, lr_0 = 1.0200e-04
Loss = 1.2515e-03, PNorm = 37.1762, GNorm = 2.3231, lr_0 = 1.0200e-04
Loss = 1.1863e-03, PNorm = 37.1780, GNorm = 2.1521, lr_0 = 1.0200e-04
Loss = 1.1782e-03, PNorm = 37.1798, GNorm = 4.0982, lr_0 = 1.0200e-04
Loss = 1.3711e-03, PNorm = 37.1828, GNorm = 2.9187, lr_0 = 1.0200e-04
Loss = 1.1369e-03, PNorm = 37.1852, GNorm = 1.8825, lr_0 = 1.0200e-04
Loss = 1.4485e-03, PNorm = 37.1869, GNorm = 2.1169, lr_0 = 1.0200e-04
Loss = 1.0622e-03, PNorm = 37.1891, GNorm = 1.5999, lr_0 = 1.0200e-04
Loss = 1.0998e-03, PNorm = 37.1917, GNorm = 1.1855, lr_0 = 1.0200e-04
Loss = 1.0140e-03, PNorm = 37.1942, GNorm = 1.2579, lr_0 = 1.0200e-04
Loss = 1.0132e-03, PNorm = 37.1961, GNorm = 1.9365, lr_0 = 1.0200e-04
Loss = 1.0777e-03, PNorm = 37.1986, GNorm = 0.9349, lr_0 = 1.0200e-04
Loss = 1.2112e-03, PNorm = 37.2010, GNorm = 3.7037, lr_0 = 1.0200e-04
Loss = 1.1255e-03, PNorm = 37.2022, GNorm = 3.5962, lr_0 = 1.0200e-04
Loss = 1.0524e-03, PNorm = 37.2039, GNorm = 2.5470, lr_0 = 1.0200e-04
Loss = 1.1053e-03, PNorm = 37.2052, GNorm = 3.6221, lr_0 = 1.0200e-04
Validation rmse logD = 0.598857
Validation R2 logD = 0.738109
Validation rmse logP = 0.507086
Validation R2 logP = 0.925398
Epoch 40
Train function
Loss = 1.5122e-03, PNorm = 37.2067, GNorm = 3.7711, lr_0 = 1.0200e-04
Loss = 1.2784e-03, PNorm = 37.2087, GNorm = 2.3205, lr_0 = 1.0200e-04
Loss = 1.1571e-03, PNorm = 37.2120, GNorm = 2.7608, lr_0 = 1.0200e-04
Loss = 9.8969e-04, PNorm = 37.2153, GNorm = 1.5727, lr_0 = 1.0200e-04
Loss = 1.1803e-03, PNorm = 37.2179, GNorm = 1.9862, lr_0 = 1.0200e-04
Loss = 1.1694e-03, PNorm = 37.2201, GNorm = 2.4057, lr_0 = 1.0200e-04
Loss = 1.0855e-03, PNorm = 37.2216, GNorm = 1.2373, lr_0 = 1.0200e-04
Loss = 1.1399e-03, PNorm = 37.2229, GNorm = 1.2708, lr_0 = 1.0200e-04
Loss = 1.1480e-03, PNorm = 37.2238, GNorm = 1.8819, lr_0 = 1.0200e-04
Loss = 9.9121e-04, PNorm = 37.2251, GNorm = 1.9300, lr_0 = 1.0200e-04
Loss = 1.1503e-03, PNorm = 37.2275, GNorm = 4.1011, lr_0 = 1.0200e-04
Loss = 1.1945e-03, PNorm = 37.2293, GNorm = 2.9011, lr_0 = 1.0200e-04
Loss = 1.8139e-03, PNorm = 37.2310, GNorm = 3.1882, lr_0 = 1.0200e-04
Loss = 1.0512e-03, PNorm = 37.2329, GNorm = 1.4174, lr_0 = 1.0200e-04
Loss = 9.8654e-04, PNorm = 37.2357, GNorm = 1.2645, lr_0 = 1.0200e-04
Loss = 1.3884e-03, PNorm = 37.2371, GNorm = 2.9204, lr_0 = 1.0200e-04
Loss = 1.0361e-03, PNorm = 37.2388, GNorm = 4.0587, lr_0 = 1.0200e-04
Loss = 1.4697e-03, PNorm = 37.2409, GNorm = 3.6371, lr_0 = 1.0200e-04
Loss = 1.0082e-03, PNorm = 37.2424, GNorm = 3.7500, lr_0 = 1.0200e-04
Loss = 1.0104e-03, PNorm = 37.2438, GNorm = 1.0840, lr_0 = 1.0200e-04
Loss = 1.0655e-03, PNorm = 37.2453, GNorm = 2.7810, lr_0 = 1.0200e-04
Loss = 1.1488e-03, PNorm = 37.2468, GNorm = 1.5823, lr_0 = 1.0200e-04
Loss = 1.1097e-03, PNorm = 37.2483, GNorm = 1.0704, lr_0 = 1.0200e-04
Validation rmse logD = 0.603251
Validation R2 logD = 0.734253
Validation rmse logP = 0.500586
Validation R2 logP = 0.927299
Epoch 41
Train function
Loss = 8.1304e-04, PNorm = 37.2510, GNorm = 4.5878, lr_0 = 1.0200e-04
Loss = 1.1116e-03, PNorm = 37.2519, GNorm = 1.2985, lr_0 = 1.0200e-04
Loss = 9.8494e-04, PNorm = 37.2529, GNorm = 4.1915, lr_0 = 1.0200e-04
Loss = 1.2117e-03, PNorm = 37.2549, GNorm = 2.2788, lr_0 = 1.0200e-04
Loss = 1.1856e-03, PNorm = 37.2575, GNorm = 1.6806, lr_0 = 1.0200e-04
Loss = 1.1003e-03, PNorm = 37.2594, GNorm = 2.3448, lr_0 = 1.0200e-04
Loss = 1.0075e-03, PNorm = 37.2622, GNorm = 1.8110, lr_0 = 1.0200e-04
Loss = 1.3538e-03, PNorm = 37.2642, GNorm = 2.2993, lr_0 = 1.0200e-04
Loss = 9.1735e-04, PNorm = 37.2659, GNorm = 1.8906, lr_0 = 1.0200e-04
Loss = 1.2402e-03, PNorm = 37.2684, GNorm = 3.5121, lr_0 = 1.0200e-04
Loss = 1.2029e-03, PNorm = 37.2705, GNorm = 1.4501, lr_0 = 1.0200e-04
Loss = 1.3161e-03, PNorm = 37.2733, GNorm = 1.9834, lr_0 = 1.0200e-04
Loss = 1.0768e-03, PNorm = 37.2759, GNorm = 2.0698, lr_0 = 1.0200e-04
Loss = 1.0814e-03, PNorm = 37.2774, GNorm = 4.0171, lr_0 = 1.0200e-04
Loss = 1.1986e-03, PNorm = 37.2794, GNorm = 1.7937, lr_0 = 1.0200e-04
Loss = 9.4231e-04, PNorm = 37.2812, GNorm = 2.5468, lr_0 = 1.0200e-04
Loss = 1.3585e-03, PNorm = 37.2826, GNorm = 4.0604, lr_0 = 1.0200e-04
Loss = 1.2765e-03, PNorm = 37.2845, GNorm = 2.8271, lr_0 = 1.0200e-04
Loss = 1.0273e-03, PNorm = 37.2865, GNorm = 2.1232, lr_0 = 1.0200e-04
Loss = 9.7188e-04, PNorm = 37.2885, GNorm = 2.2174, lr_0 = 1.0200e-04
Loss = 1.1905e-03, PNorm = 37.2897, GNorm = 1.5149, lr_0 = 1.0200e-04
Loss = 1.1252e-03, PNorm = 37.2915, GNorm = 3.7941, lr_0 = 1.0200e-04
Loss = 1.3308e-03, PNorm = 37.2938, GNorm = 1.2037, lr_0 = 1.0200e-04
Validation rmse logD = 0.611128
Validation R2 logD = 0.727267
Validation rmse logP = 0.480901
Validation R2 logP = 0.932904
Epoch 42
Train function
Loss = 1.0796e-03, PNorm = 37.2952, GNorm = 1.6585, lr_0 = 1.0200e-04
Loss = 1.0590e-03, PNorm = 37.2956, GNorm = 2.2671, lr_0 = 1.0200e-04
Loss = 1.1065e-03, PNorm = 37.2973, GNorm = 2.9753, lr_0 = 1.0200e-04
Loss = 8.6576e-04, PNorm = 37.2993, GNorm = 1.8643, lr_0 = 1.0200e-04
Loss = 1.0715e-03, PNorm = 37.3012, GNorm = 1.5459, lr_0 = 1.0200e-04
Loss = 1.0228e-03, PNorm = 37.3029, GNorm = 1.4863, lr_0 = 1.0200e-04
Loss = 1.0767e-03, PNorm = 37.3049, GNorm = 1.7749, lr_0 = 1.0200e-04
Loss = 1.0453e-03, PNorm = 37.3066, GNorm = 1.7941, lr_0 = 1.0200e-04
Loss = 1.0386e-03, PNorm = 37.3093, GNorm = 2.0788, lr_0 = 1.0200e-04
Loss = 9.7455e-04, PNorm = 37.3126, GNorm = 2.9978, lr_0 = 1.0200e-04
Loss = 1.0161e-03, PNorm = 37.3150, GNorm = 1.1877, lr_0 = 1.0200e-04
Loss = 1.1708e-03, PNorm = 37.3159, GNorm = 3.0594, lr_0 = 1.0200e-04
Loss = 1.0542e-03, PNorm = 37.3170, GNorm = 1.8235, lr_0 = 1.0200e-04
Loss = 1.1074e-03, PNorm = 37.3196, GNorm = 3.1902, lr_0 = 1.0200e-04
Loss = 1.0982e-03, PNorm = 37.3216, GNorm = 1.8145, lr_0 = 1.0200e-04
Loss = 1.2639e-03, PNorm = 37.3235, GNorm = 1.8915, lr_0 = 1.0200e-04
Loss = 1.1730e-03, PNorm = 37.3250, GNorm = 1.8063, lr_0 = 1.0200e-04
Loss = 1.0976e-03, PNorm = 37.3268, GNorm = 3.0975, lr_0 = 1.0200e-04
Loss = 1.2384e-03, PNorm = 37.3295, GNorm = 2.9774, lr_0 = 1.0200e-04
Loss = 1.0403e-03, PNorm = 37.3315, GNorm = 2.4988, lr_0 = 1.0200e-04
Loss = 9.5793e-04, PNorm = 37.3327, GNorm = 2.2756, lr_0 = 1.0200e-04
Loss = 1.0832e-03, PNorm = 37.3343, GNorm = 1.4154, lr_0 = 1.0200e-04
Validation rmse logD = 0.623934
Validation R2 logD = 0.715718
Validation rmse logP = 0.481201
Validation R2 logP = 0.932820
Epoch 43
Train function
Loss = 1.1735e-03, PNorm = 37.3374, GNorm = 1.9073, lr_0 = 1.0200e-04
Loss = 9.4256e-04, PNorm = 37.3392, GNorm = 2.3440, lr_0 = 1.0200e-04
Loss = 1.0730e-03, PNorm = 37.3415, GNorm = 2.4570, lr_0 = 1.0200e-04
Loss = 9.9872e-04, PNorm = 37.3440, GNorm = 1.9140, lr_0 = 1.0200e-04
Loss = 1.2336e-03, PNorm = 37.3464, GNorm = 3.2050, lr_0 = 1.0200e-04
Loss = 9.6436e-04, PNorm = 37.3475, GNorm = 4.5395, lr_0 = 1.0200e-04
Loss = 1.0018e-03, PNorm = 37.3487, GNorm = 1.9491, lr_0 = 1.0200e-04
Loss = 1.2776e-03, PNorm = 37.3512, GNorm = 1.7664, lr_0 = 1.0200e-04
Loss = 8.5783e-04, PNorm = 37.3534, GNorm = 1.9442, lr_0 = 1.0200e-04
Loss = 1.0520e-03, PNorm = 37.3554, GNorm = 2.8588, lr_0 = 1.0200e-04
Loss = 1.0711e-03, PNorm = 37.3579, GNorm = 2.0383, lr_0 = 1.0200e-04
Loss = 1.2063e-03, PNorm = 37.3582, GNorm = 2.7201, lr_0 = 1.0200e-04
Loss = 1.1037e-03, PNorm = 37.3596, GNorm = 3.3682, lr_0 = 1.0200e-04
Loss = 1.1226e-03, PNorm = 37.3613, GNorm = 2.6680, lr_0 = 1.0200e-04
Loss = 9.5404e-04, PNorm = 37.3635, GNorm = 3.1952, lr_0 = 1.0200e-04
Loss = 8.7574e-04, PNorm = 37.3655, GNorm = 2.9467, lr_0 = 1.0200e-04
Loss = 1.1341e-03, PNorm = 37.3682, GNorm = 6.0442, lr_0 = 1.0200e-04
Loss = 1.1280e-03, PNorm = 37.3704, GNorm = 0.9219, lr_0 = 1.0200e-04
Loss = 1.1246e-03, PNorm = 37.3722, GNorm = 6.1923, lr_0 = 1.0200e-04
Loss = 1.2844e-03, PNorm = 37.3738, GNorm = 4.2066, lr_0 = 1.0200e-04
Loss = 1.0629e-03, PNorm = 37.3753, GNorm = 0.9565, lr_0 = 1.0200e-04
Loss = 1.5365e-03, PNorm = 37.3773, GNorm = 2.4269, lr_0 = 1.0200e-04
Loss = 9.8234e-04, PNorm = 37.3789, GNorm = 1.9614, lr_0 = 1.0200e-04
Validation rmse logD = 0.595831
Validation R2 logD = 0.740749
Validation rmse logP = 0.479648
Validation R2 logP = 0.933253
Epoch 44
Train function
Loss = 1.2620e-03, PNorm = 37.3812, GNorm = 3.8288, lr_0 = 1.0200e-04
Loss = 9.8909e-04, PNorm = 37.3832, GNorm = 1.7479, lr_0 = 1.0200e-04
Loss = 8.2975e-04, PNorm = 37.3844, GNorm = 1.5608, lr_0 = 1.0200e-04
Loss = 8.6133e-04, PNorm = 37.3851, GNorm = 1.9638, lr_0 = 1.0200e-04
Loss = 9.1548e-04, PNorm = 37.3867, GNorm = 2.1964, lr_0 = 1.0200e-04
Loss = 8.9271e-04, PNorm = 37.3886, GNorm = 4.2578, lr_0 = 1.0200e-04
Loss = 9.0879e-04, PNorm = 37.3898, GNorm = 0.9558, lr_0 = 1.0200e-04
Loss = 1.0374e-03, PNorm = 37.3918, GNorm = 0.8983, lr_0 = 1.0200e-04
Loss = 1.1468e-03, PNorm = 37.3932, GNorm = 4.2640, lr_0 = 1.0200e-04
Loss = 9.3058e-04, PNorm = 37.3948, GNorm = 2.7619, lr_0 = 1.0200e-04
Loss = 1.0579e-03, PNorm = 37.3968, GNorm = 4.3216, lr_0 = 1.0200e-04
Loss = 1.0983e-03, PNorm = 37.3990, GNorm = 1.3963, lr_0 = 1.0200e-04
Loss = 1.0341e-03, PNorm = 37.4016, GNorm = 1.9933, lr_0 = 1.0200e-04
Loss = 1.2175e-03, PNorm = 37.4042, GNorm = 3.2746, lr_0 = 1.0200e-04
Loss = 1.0385e-03, PNorm = 37.4066, GNorm = 1.8532, lr_0 = 1.0200e-04
Loss = 1.1057e-03, PNorm = 37.4087, GNorm = 2.2871, lr_0 = 1.0200e-04
Loss = 1.1746e-03, PNorm = 37.4112, GNorm = 3.0508, lr_0 = 1.0200e-04
Loss = 9.7400e-04, PNorm = 37.4128, GNorm = 5.6092, lr_0 = 1.0200e-04
Loss = 9.3533e-04, PNorm = 37.4155, GNorm = 1.1227, lr_0 = 1.0200e-04
Loss = 1.1222e-03, PNorm = 37.4168, GNorm = 4.8902, lr_0 = 1.0200e-04
Loss = 1.4019e-03, PNorm = 37.4188, GNorm = 2.9870, lr_0 = 1.0200e-04
Loss = 1.3632e-03, PNorm = 37.4207, GNorm = 2.2089, lr_0 = 1.0200e-04
Validation rmse logD = 0.595245
Validation R2 logD = 0.741259
Validation rmse logP = 0.480211
Validation R2 logP = 0.933096
Epoch 45
Train function
Loss = 8.8417e-04, PNorm = 37.4234, GNorm = 1.4504, lr_0 = 1.0200e-04
Loss = 9.1658e-04, PNorm = 37.4255, GNorm = 3.4565, lr_0 = 1.0200e-04
Loss = 1.1066e-03, PNorm = 37.4272, GNorm = 1.2969, lr_0 = 1.0200e-04
Loss = 9.6674e-04, PNorm = 37.4285, GNorm = 1.9422, lr_0 = 1.0200e-04
Loss = 9.5375e-04, PNorm = 37.4294, GNorm = 2.0402, lr_0 = 1.0200e-04
Loss = 9.2592e-04, PNorm = 37.4305, GNorm = 1.9283, lr_0 = 1.0200e-04
Loss = 8.9431e-04, PNorm = 37.4330, GNorm = 2.1602, lr_0 = 1.0200e-04
Loss = 9.8155e-04, PNorm = 37.4358, GNorm = 3.0102, lr_0 = 1.0200e-04
Loss = 1.1602e-03, PNorm = 37.4376, GNorm = 3.0592, lr_0 = 1.0200e-04
Loss = 1.0120e-03, PNorm = 37.4398, GNorm = 3.6664, lr_0 = 1.0200e-04
Loss = 8.8671e-04, PNorm = 37.4414, GNorm = 2.0344, lr_0 = 1.0200e-04
Loss = 8.8115e-04, PNorm = 37.4433, GNorm = 2.4479, lr_0 = 1.0200e-04
Loss = 8.8698e-04, PNorm = 37.4455, GNorm = 1.2609, lr_0 = 1.0200e-04
Loss = 1.0501e-03, PNorm = 37.4472, GNorm = 1.5314, lr_0 = 1.0200e-04
Loss = 8.8655e-04, PNorm = 37.4491, GNorm = 1.0177, lr_0 = 1.0200e-04
Loss = 1.2298e-03, PNorm = 37.4516, GNorm = 1.6617, lr_0 = 1.0200e-04
Loss = 8.5375e-04, PNorm = 37.4531, GNorm = 2.2755, lr_0 = 1.0200e-04
Loss = 7.7678e-04, PNorm = 37.4548, GNorm = 1.9158, lr_0 = 1.0200e-04
Loss = 9.6160e-04, PNorm = 37.4561, GNorm = 1.7458, lr_0 = 1.0200e-04
Loss = 1.1908e-03, PNorm = 37.4575, GNorm = 2.4812, lr_0 = 1.0200e-04
Loss = 9.3721e-04, PNorm = 37.4597, GNorm = 2.0343, lr_0 = 1.0200e-04
Loss = 1.3311e-03, PNorm = 37.4612, GNorm = 5.7358, lr_0 = 1.0200e-04
Loss = 1.4946e-03, PNorm = 37.4627, GNorm = 4.8031, lr_0 = 1.0200e-04
Validation rmse logD = 0.704789
Validation R2 logD = 0.637263
Validation rmse logP = 0.475216
Validation R2 logP = 0.934481
Epoch 46
Train function
Loss = 1.3469e-03, PNorm = 37.4646, GNorm = 6.7082, lr_0 = 1.0200e-04
Loss = 1.0906e-03, PNorm = 37.4667, GNorm = 2.9730, lr_0 = 1.0200e-04
Loss = 1.2038e-03, PNorm = 37.4687, GNorm = 2.7468, lr_0 = 1.0200e-04
Loss = 9.9372e-04, PNorm = 37.4713, GNorm = 2.9573, lr_0 = 1.0200e-04
Loss = 9.8739e-04, PNorm = 37.4737, GNorm = 2.2699, lr_0 = 1.0200e-04
Loss = 1.1423e-03, PNorm = 37.4751, GNorm = 1.5453, lr_0 = 1.0200e-04
Loss = 8.1393e-04, PNorm = 37.4774, GNorm = 1.4029, lr_0 = 1.0200e-04
Loss = 1.2163e-03, PNorm = 37.4796, GNorm = 1.2526, lr_0 = 1.0200e-04
Loss = 1.0697e-03, PNorm = 37.4816, GNorm = 3.0114, lr_0 = 1.0200e-04
Loss = 8.3566e-04, PNorm = 37.4830, GNorm = 1.9837, lr_0 = 1.0200e-04
Loss = 1.0461e-03, PNorm = 37.4851, GNorm = 5.2712, lr_0 = 1.0200e-04
Loss = 1.1860e-03, PNorm = 37.4865, GNorm = 2.3388, lr_0 = 1.0200e-04
Loss = 1.0509e-03, PNorm = 37.4886, GNorm = 1.0240, lr_0 = 1.0200e-04
Loss = 8.2888e-04, PNorm = 37.4901, GNorm = 1.3923, lr_0 = 1.0200e-04
Loss = 8.8292e-04, PNorm = 37.4913, GNorm = 1.7482, lr_0 = 1.0200e-04
Loss = 9.4300e-04, PNorm = 37.4927, GNorm = 1.5961, lr_0 = 1.0200e-04
Loss = 6.8994e-04, PNorm = 37.4948, GNorm = 1.2106, lr_0 = 1.0200e-04
Loss = 1.2764e-03, PNorm = 37.4963, GNorm = 2.9072, lr_0 = 1.0200e-04
Loss = 1.3074e-03, PNorm = 37.4986, GNorm = 3.6091, lr_0 = 1.0200e-04
Loss = 9.2398e-04, PNorm = 37.5004, GNorm = 1.2915, lr_0 = 1.0200e-04
Loss = 1.1547e-03, PNorm = 37.5025, GNorm = 1.9035, lr_0 = 1.0200e-04
Loss = 1.0416e-03, PNorm = 37.5044, GNorm = 2.0772, lr_0 = 1.0200e-04
Validation rmse logD = 0.586603
Validation R2 logD = 0.748717
Validation rmse logP = 0.470545
Validation R2 logP = 0.935763
Epoch 47
Train function
Loss = 1.4252e-03, PNorm = 37.5076, GNorm = 3.8489, lr_0 = 1.0200e-04
Loss = 8.6666e-04, PNorm = 37.5105, GNorm = 1.4480, lr_0 = 1.0200e-04
Loss = 8.8085e-04, PNorm = 37.5127, GNorm = 1.9815, lr_0 = 1.0200e-04
Loss = 8.6160e-04, PNorm = 37.5143, GNorm = 1.4956, lr_0 = 1.0200e-04
Loss = 9.2243e-04, PNorm = 37.5165, GNorm = 2.2464, lr_0 = 1.0200e-04
Loss = 1.0196e-03, PNorm = 37.5181, GNorm = 0.9837, lr_0 = 1.0200e-04
Loss = 9.0413e-04, PNorm = 37.5195, GNorm = 1.3326, lr_0 = 1.0200e-04
Loss = 8.1731e-04, PNorm = 37.5205, GNorm = 2.7881, lr_0 = 1.0200e-04
Loss = 1.1140e-03, PNorm = 37.5227, GNorm = 2.8337, lr_0 = 1.0200e-04
Loss = 9.7290e-04, PNorm = 37.5247, GNorm = 1.9015, lr_0 = 1.0200e-04
Loss = 1.0453e-03, PNorm = 37.5264, GNorm = 2.1930, lr_0 = 1.0200e-04
Loss = 1.1298e-03, PNorm = 37.5280, GNorm = 1.4206, lr_0 = 1.0200e-04
Loss = 8.9093e-04, PNorm = 37.5302, GNorm = 2.0017, lr_0 = 1.0200e-04
Loss = 9.8585e-04, PNorm = 37.5313, GNorm = 2.9774, lr_0 = 1.0200e-04
Loss = 9.4764e-04, PNorm = 37.5314, GNorm = 1.2625, lr_0 = 1.0200e-04
Loss = 9.5133e-04, PNorm = 37.5327, GNorm = 1.9669, lr_0 = 1.0200e-04
Loss = 1.0730e-03, PNorm = 37.5349, GNorm = 2.1963, lr_0 = 1.0200e-04
Loss = 8.4916e-04, PNorm = 37.5362, GNorm = 2.2864, lr_0 = 1.0200e-04
Loss = 1.0217e-03, PNorm = 37.5380, GNorm = 2.0414, lr_0 = 1.0200e-04
Loss = 1.1113e-03, PNorm = 37.5407, GNorm = 2.2585, lr_0 = 1.0200e-04
Loss = 9.1459e-04, PNorm = 37.5423, GNorm = 1.8891, lr_0 = 1.0200e-04
Loss = 1.0037e-03, PNorm = 37.5438, GNorm = 3.1778, lr_0 = 1.0200e-04
Loss = 9.5163e-04, PNorm = 37.5455, GNorm = 1.3972, lr_0 = 1.0200e-04
Validation rmse logD = 0.589356
Validation R2 logD = 0.746354
Validation rmse logP = 0.472481
Validation R2 logP = 0.935233
Epoch 48
Train function
Loss = 8.4171e-04, PNorm = 37.5478, GNorm = 2.6520, lr_0 = 1.0200e-04
Loss = 7.7975e-04, PNorm = 37.5489, GNorm = 2.1398, lr_0 = 1.0200e-04
Loss = 9.1162e-04, PNorm = 37.5501, GNorm = 3.8933, lr_0 = 1.0200e-04
Loss = 9.3993e-04, PNorm = 37.5514, GNorm = 1.3018, lr_0 = 1.0200e-04
Loss = 9.6357e-04, PNorm = 37.5523, GNorm = 1.0219, lr_0 = 1.0200e-04
Loss = 1.0433e-03, PNorm = 37.5539, GNorm = 2.2516, lr_0 = 1.0200e-04
Loss = 9.6606e-04, PNorm = 37.5561, GNorm = 1.4309, lr_0 = 1.0200e-04
Loss = 8.7295e-04, PNorm = 37.5586, GNorm = 1.4167, lr_0 = 1.0200e-04
Loss = 8.9626e-04, PNorm = 37.5614, GNorm = 1.5366, lr_0 = 1.0200e-04
Loss = 8.5512e-04, PNorm = 37.5631, GNorm = 2.0098, lr_0 = 1.0200e-04
Loss = 8.9942e-04, PNorm = 37.5648, GNorm = 2.2086, lr_0 = 1.0200e-04
Loss = 1.3809e-03, PNorm = 37.5665, GNorm = 3.6291, lr_0 = 1.0200e-04
Loss = 6.0987e-04, PNorm = 37.5680, GNorm = 2.7399, lr_0 = 1.0200e-04
Loss = 1.0496e-03, PNorm = 37.5701, GNorm = 1.1408, lr_0 = 1.0200e-04
Loss = 9.7636e-04, PNorm = 37.5714, GNorm = 2.1864, lr_0 = 1.0200e-04
Loss = 8.2003e-04, PNorm = 37.5729, GNorm = 2.1410, lr_0 = 1.0200e-04
Loss = 7.7918e-04, PNorm = 37.5740, GNorm = 1.3426, lr_0 = 1.0200e-04
Loss = 7.6278e-04, PNorm = 37.5751, GNorm = 1.7513, lr_0 = 1.0200e-04
Loss = 1.0948e-03, PNorm = 37.5769, GNorm = 3.1610, lr_0 = 1.0200e-04
Loss = 1.0073e-03, PNorm = 37.5784, GNorm = 1.5761, lr_0 = 1.0200e-04
Loss = 1.0399e-03, PNorm = 37.5811, GNorm = 1.4707, lr_0 = 1.0200e-04
Loss = 9.9126e-04, PNorm = 37.5838, GNorm = 1.5145, lr_0 = 1.0200e-04
Validation rmse logD = 0.593273
Validation R2 logD = 0.742971
Validation rmse logP = 0.476239
Validation R2 logP = 0.934199
Epoch 49
Train function
Loss = 6.3263e-04, PNorm = 37.5858, GNorm = 1.4117, lr_0 = 1.0200e-04
Loss = 8.5219e-04, PNorm = 37.5875, GNorm = 3.3479, lr_0 = 1.0200e-04
Loss = 8.6814e-04, PNorm = 37.5897, GNorm = 1.5506, lr_0 = 1.0200e-04
Loss = 8.8809e-04, PNorm = 37.5915, GNorm = 2.1266, lr_0 = 1.0200e-04
Loss = 8.5827e-04, PNorm = 37.5931, GNorm = 1.4667, lr_0 = 1.0200e-04
Loss = 8.4948e-04, PNorm = 37.5946, GNorm = 2.0316, lr_0 = 1.0200e-04
Loss = 8.0343e-04, PNorm = 37.5967, GNorm = 1.8200, lr_0 = 1.0200e-04
Loss = 9.4827e-04, PNorm = 37.5983, GNorm = 0.9854, lr_0 = 1.0200e-04
Loss = 1.0293e-03, PNorm = 37.5993, GNorm = 1.5305, lr_0 = 1.0200e-04
Loss = 1.1012e-03, PNorm = 37.6015, GNorm = 1.3927, lr_0 = 1.0200e-04
Loss = 9.2801e-04, PNorm = 37.6035, GNorm = 1.8631, lr_0 = 1.0200e-04
Loss = 8.2839e-04, PNorm = 37.6059, GNorm = 1.7448, lr_0 = 1.0200e-04
Loss = 7.6052e-04, PNorm = 37.6067, GNorm = 1.5568, lr_0 = 1.0200e-04
Loss = 9.5017e-04, PNorm = 37.6081, GNorm = 2.6692, lr_0 = 1.0200e-04
Loss = 8.1556e-04, PNorm = 37.6101, GNorm = 2.3789, lr_0 = 1.0200e-04
Loss = 7.9023e-04, PNorm = 37.6120, GNorm = 2.7443, lr_0 = 1.0200e-04
Loss = 8.3797e-04, PNorm = 37.6139, GNorm = 3.1331, lr_0 = 1.0200e-04
Loss = 8.5387e-04, PNorm = 37.6154, GNorm = 1.6543, lr_0 = 1.0200e-04
Loss = 1.2212e-03, PNorm = 37.6174, GNorm = 2.3632, lr_0 = 1.0200e-04
Loss = 1.2220e-03, PNorm = 37.6189, GNorm = 5.5452, lr_0 = 1.0200e-04
Loss = 1.2241e-03, PNorm = 37.6208, GNorm = 4.2745, lr_0 = 1.0200e-04
Loss = 1.0580e-03, PNorm = 37.6226, GNorm = 2.5282, lr_0 = 1.0200e-04
Loss = 1.2475e-03, PNorm = 37.6254, GNorm = 1.8025, lr_0 = 1.0200e-04
Validation rmse logD = 0.609577
Validation R2 logD = 0.728649
Validation rmse logP = 0.507592
Validation R2 logP = 0.925249
Epoch 50
Train function
Loss = 9.4772e-04, PNorm = 37.6283, GNorm = 1.3644, lr_0 = 1.0200e-04
Loss = 8.6922e-04, PNorm = 37.6304, GNorm = 1.5139, lr_0 = 1.0200e-04
Loss = 9.6645e-04, PNorm = 37.6322, GNorm = 1.8991, lr_0 = 1.0200e-04
Loss = 8.8071e-04, PNorm = 37.6343, GNorm = 1.1195, lr_0 = 1.0200e-04
Loss = 8.0610e-04, PNorm = 37.6357, GNorm = 1.4366, lr_0 = 1.0200e-04
Loss = 7.2283e-04, PNorm = 37.6375, GNorm = 3.8296, lr_0 = 1.0200e-04
Loss = 8.0937e-04, PNorm = 37.6385, GNorm = 1.7994, lr_0 = 1.0200e-04
Loss = 6.7708e-04, PNorm = 37.6404, GNorm = 1.0671, lr_0 = 1.0200e-04
Loss = 1.1656e-03, PNorm = 37.6413, GNorm = 1.0653, lr_0 = 1.0200e-04
Loss = 9.3393e-04, PNorm = 37.6432, GNorm = 2.0322, lr_0 = 1.0200e-04
Loss = 1.0379e-03, PNorm = 37.6458, GNorm = 3.1785, lr_0 = 1.0200e-04
Loss = 9.6591e-04, PNorm = 37.6478, GNorm = 4.2517, lr_0 = 1.0200e-04
Loss = 9.7246e-04, PNorm = 37.6501, GNorm = 2.9968, lr_0 = 1.0200e-04
Loss = 9.1062e-04, PNorm = 37.6515, GNorm = 1.2972, lr_0 = 1.0200e-04
Loss = 9.3767e-04, PNorm = 37.6537, GNorm = 1.3465, lr_0 = 1.0200e-04
Loss = 8.9618e-04, PNorm = 37.6563, GNorm = 4.1100, lr_0 = 1.0200e-04
Loss = 9.6464e-04, PNorm = 37.6586, GNorm = 2.3081, lr_0 = 1.0200e-04
Loss = 1.0166e-03, PNorm = 37.6602, GNorm = 3.7578, lr_0 = 1.0200e-04
Loss = 1.0041e-03, PNorm = 37.6618, GNorm = 3.8712, lr_0 = 1.0200e-04
Loss = 1.2999e-03, PNorm = 37.6634, GNorm = 3.4120, lr_0 = 1.0200e-04
Loss = 1.0176e-03, PNorm = 37.6648, GNorm = 2.4563, lr_0 = 1.0200e-04
Loss = 9.8681e-04, PNorm = 37.6665, GNorm = 1.6154, lr_0 = 1.0200e-04
Validation rmse logD = 0.635406
Validation R2 logD = 0.705167
Validation rmse logP = 0.481326
Validation R2 logP = 0.932785
Epoch 51
Train function
Loss = 8.5033e-04, PNorm = 37.6686, GNorm = 1.9813, lr_0 = 1.0200e-04
Loss = 9.7703e-04, PNorm = 37.6706, GNorm = 1.0370, lr_0 = 1.0200e-04
Loss = 8.4741e-04, PNorm = 37.6726, GNorm = 2.6142, lr_0 = 1.0200e-04
Loss = 9.3345e-04, PNorm = 37.6739, GNorm = 2.4659, lr_0 = 1.0200e-04
Loss = 9.8600e-04, PNorm = 37.6752, GNorm = 2.8372, lr_0 = 1.0200e-04
Loss = 9.4489e-04, PNorm = 37.6771, GNorm = 1.7425, lr_0 = 1.0200e-04
Loss = 8.7610e-04, PNorm = 37.6801, GNorm = 1.2633, lr_0 = 1.0200e-04
Loss = 7.5542e-04, PNorm = 37.6822, GNorm = 1.4507, lr_0 = 1.0200e-04
Loss = 8.0573e-04, PNorm = 37.6834, GNorm = 1.3296, lr_0 = 1.0200e-04
Loss = 7.4917e-04, PNorm = 37.6851, GNorm = 4.6880, lr_0 = 1.0200e-04
Loss = 7.8889e-04, PNorm = 37.6864, GNorm = 2.8796, lr_0 = 1.0200e-04
Loss = 1.0383e-03, PNorm = 37.6875, GNorm = 2.4095, lr_0 = 1.0200e-04
Loss = 7.8630e-04, PNorm = 37.6892, GNorm = 1.8251, lr_0 = 1.0200e-04
Loss = 9.7440e-04, PNorm = 37.6908, GNorm = 1.3803, lr_0 = 1.0200e-04
Loss = 9.1319e-04, PNorm = 37.6927, GNorm = 2.9653, lr_0 = 1.0200e-04
Loss = 9.7518e-04, PNorm = 37.6951, GNorm = 2.2561, lr_0 = 1.0200e-04
Loss = 8.5865e-04, PNorm = 37.6971, GNorm = 1.9027, lr_0 = 1.0200e-04
Loss = 8.4782e-04, PNorm = 37.6986, GNorm = 1.7137, lr_0 = 1.0200e-04
Loss = 7.5778e-04, PNorm = 37.7003, GNorm = 1.9903, lr_0 = 1.0200e-04
Loss = 6.9999e-04, PNorm = 37.7027, GNorm = 1.8740, lr_0 = 1.0200e-04
Loss = 9.6327e-04, PNorm = 37.7040, GNorm = 2.4823, lr_0 = 1.0200e-04
Loss = 1.0335e-03, PNorm = 37.7064, GNorm = 2.4488, lr_0 = 1.0200e-04
Loss = 8.3585e-04, PNorm = 37.7082, GNorm = 1.5773, lr_0 = 1.0200e-04
Validation rmse logD = 0.585035
Validation R2 logD = 0.750059
Validation rmse logP = 0.488062
Validation R2 logP = 0.930891
Epoch 52
Train function
Loss = 9.0273e-04, PNorm = 37.7106, GNorm = 4.6430, lr_0 = 1.0200e-04
Loss = 8.5995e-04, PNorm = 37.7122, GNorm = 1.2638, lr_0 = 1.0200e-04
Loss = 8.9150e-04, PNorm = 37.7141, GNorm = 4.4842, lr_0 = 1.0200e-04
Loss = 9.9309e-04, PNorm = 37.7166, GNorm = 2.1313, lr_0 = 1.0200e-04
Loss = 8.3801e-04, PNorm = 37.7177, GNorm = 1.7482, lr_0 = 1.0200e-04
Loss = 9.0288e-04, PNorm = 37.7198, GNorm = 1.6043, lr_0 = 1.0200e-04
Loss = 8.3637e-04, PNorm = 37.7215, GNorm = 2.0174, lr_0 = 1.0200e-04
Loss = 8.1931e-04, PNorm = 37.7237, GNorm = 3.0505, lr_0 = 1.0200e-04
Loss = 9.3612e-04, PNorm = 37.7254, GNorm = 2.2653, lr_0 = 1.0200e-04
Loss = 8.1846e-04, PNorm = 37.7276, GNorm = 2.6243, lr_0 = 1.0200e-04
Loss = 7.4271e-04, PNorm = 37.7300, GNorm = 2.8816, lr_0 = 1.0200e-04
Loss = 8.7283e-04, PNorm = 37.7319, GNorm = 2.2824, lr_0 = 1.0200e-04
Loss = 7.8447e-04, PNorm = 37.7336, GNorm = 1.7415, lr_0 = 1.0200e-04
Loss = 8.3951e-04, PNorm = 37.7363, GNorm = 3.2720, lr_0 = 1.0200e-04
Loss = 7.6115e-04, PNorm = 37.7373, GNorm = 1.9946, lr_0 = 1.0200e-04
Loss = 8.1713e-04, PNorm = 37.7382, GNorm = 3.4016, lr_0 = 1.0200e-04
Loss = 8.4716e-04, PNorm = 37.7390, GNorm = 1.0849, lr_0 = 1.0200e-04
Loss = 8.5881e-04, PNorm = 37.7404, GNorm = 1.9055, lr_0 = 1.0200e-04
Loss = 8.7363e-04, PNorm = 37.7422, GNorm = 2.5462, lr_0 = 1.0200e-04
Loss = 6.9912e-04, PNorm = 37.7436, GNorm = 0.9789, lr_0 = 1.0200e-04
Loss = 8.2400e-04, PNorm = 37.7455, GNorm = 1.6711, lr_0 = 1.0200e-04
Loss = 1.2126e-03, PNorm = 37.7472, GNorm = 1.2576, lr_0 = 1.0200e-04
Loss = 1.0161e-03, PNorm = 37.7493, GNorm = 1.2578, lr_0 = 1.0200e-04
Validation rmse logD = 0.596582
Validation R2 logD = 0.740096
Validation rmse logP = 0.480555
Validation R2 logP = 0.933001
Epoch 53
Train function
Loss = 8.4405e-04, PNorm = 37.7513, GNorm = 2.4042, lr_0 = 1.0200e-04
Loss = 7.8235e-04, PNorm = 37.7531, GNorm = 1.1476, lr_0 = 1.0200e-04
Loss = 7.5089e-04, PNorm = 37.7543, GNorm = 2.0348, lr_0 = 1.0200e-04
Loss = 8.7272e-04, PNorm = 37.7560, GNorm = 1.7079, lr_0 = 1.0200e-04
Loss = 1.0022e-03, PNorm = 37.7584, GNorm = 2.0328, lr_0 = 1.0200e-04
Loss = 1.1344e-03, PNorm = 37.7604, GNorm = 2.7986, lr_0 = 1.0200e-04
Loss = 8.8268e-04, PNorm = 37.7618, GNorm = 2.2972, lr_0 = 1.0200e-04
Loss = 8.6235e-04, PNorm = 37.7632, GNorm = 1.4768, lr_0 = 1.0200e-04
Loss = 8.6176e-04, PNorm = 37.7653, GNorm = 1.6212, lr_0 = 1.0200e-04
Loss = 7.2435e-04, PNorm = 37.7680, GNorm = 1.0890, lr_0 = 1.0200e-04
Loss = 8.2378e-04, PNorm = 37.7699, GNorm = 2.5489, lr_0 = 1.0200e-04
Loss = 8.6988e-04, PNorm = 37.7713, GNorm = 2.5444, lr_0 = 1.0200e-04
Loss = 8.6447e-04, PNorm = 37.7724, GNorm = 3.1902, lr_0 = 1.0200e-04
Loss = 9.1749e-04, PNorm = 37.7735, GNorm = 1.7682, lr_0 = 1.0200e-04
Loss = 9.4431e-04, PNorm = 37.7760, GNorm = 2.2842, lr_0 = 1.0200e-04
Loss = 7.2829e-04, PNorm = 37.7782, GNorm = 2.1627, lr_0 = 1.0200e-04
Loss = 9.7536e-04, PNorm = 37.7807, GNorm = 2.1267, lr_0 = 1.0200e-04
Loss = 9.0645e-04, PNorm = 37.7821, GNorm = 1.4579, lr_0 = 1.0200e-04
Loss = 8.5134e-04, PNorm = 37.7826, GNorm = 1.7335, lr_0 = 1.0200e-04
Loss = 7.5073e-04, PNorm = 37.7839, GNorm = 1.3460, lr_0 = 1.0200e-04
Loss = 7.6486e-04, PNorm = 37.7860, GNorm = 0.9873, lr_0 = 1.0200e-04
Loss = 6.5990e-04, PNorm = 37.7874, GNorm = 0.7747, lr_0 = 1.0200e-04
Validation rmse logD = 0.591188
Validation R2 logD = 0.744774
Validation rmse logP = 0.472777
Validation R2 logP = 0.935152
Epoch 54
Train function
Loss = 1.0794e-03, PNorm = 37.7900, GNorm = 1.0892, lr_0 = 1.0200e-04
Loss = 8.2828e-04, PNorm = 37.7918, GNorm = 1.1146, lr_0 = 1.0200e-04
Loss = 7.7732e-04, PNorm = 37.7937, GNorm = 1.5248, lr_0 = 1.0200e-04
Loss = 7.1768e-04, PNorm = 37.7954, GNorm = 0.9356, lr_0 = 1.0200e-04
Loss = 8.9430e-04, PNorm = 37.7966, GNorm = 1.6480, lr_0 = 1.0200e-04
Loss = 8.9792e-04, PNorm = 37.7984, GNorm = 1.7460, lr_0 = 1.0200e-04
Loss = 7.4012e-04, PNorm = 37.8003, GNorm = 1.7423, lr_0 = 1.0200e-04
Loss = 8.2405e-04, PNorm = 37.8025, GNorm = 2.8486, lr_0 = 1.0200e-04
Loss = 8.7690e-04, PNorm = 37.8046, GNorm = 3.3492, lr_0 = 1.0200e-04
Loss = 7.7230e-04, PNorm = 37.8060, GNorm = 2.2426, lr_0 = 1.0200e-04
Loss = 1.0353e-03, PNorm = 37.8080, GNorm = 3.3039, lr_0 = 1.0200e-04
Loss = 9.4812e-04, PNorm = 37.8101, GNorm = 1.0047, lr_0 = 1.0200e-04
Loss = 7.9434e-04, PNorm = 37.8127, GNorm = 1.4792, lr_0 = 1.0200e-04
Loss = 8.1722e-04, PNorm = 37.8148, GNorm = 3.8278, lr_0 = 1.0200e-04
Loss = 8.7500e-04, PNorm = 37.8167, GNorm = 3.8800, lr_0 = 1.0200e-04
Loss = 7.5441e-04, PNorm = 37.8180, GNorm = 1.8865, lr_0 = 1.0200e-04
Loss = 7.5694e-04, PNorm = 37.8192, GNorm = 1.1301, lr_0 = 1.0200e-04
Loss = 9.8520e-04, PNorm = 37.8203, GNorm = 3.9039, lr_0 = 1.0200e-04
Loss = 1.0463e-03, PNorm = 37.8216, GNorm = 5.6678, lr_0 = 1.0200e-04
Loss = 7.8724e-04, PNorm = 37.8234, GNorm = 2.2664, lr_0 = 1.0200e-04
Loss = 7.1002e-04, PNorm = 37.8242, GNorm = 1.6382, lr_0 = 1.0200e-04
Loss = 8.4099e-04, PNorm = 37.8253, GNorm = 1.8192, lr_0 = 1.0200e-04
Loss = 8.2345e-04, PNorm = 37.8274, GNorm = 1.8530, lr_0 = 1.0200e-04
Validation rmse logD = 0.584985
Validation R2 logD = 0.750102
Validation rmse logP = 0.493333
Validation R2 logP = 0.929390
Epoch 55
Train function
Loss = 9.5058e-04, PNorm = 37.8290, GNorm = 2.8168, lr_0 = 1.0200e-04
Loss = 8.7752e-04, PNorm = 37.8301, GNorm = 1.2449, lr_0 = 1.0200e-04
Loss = 6.7952e-04, PNorm = 37.8322, GNorm = 1.4394, lr_0 = 1.0200e-04
Loss = 6.9252e-04, PNorm = 37.8339, GNorm = 2.5487, lr_0 = 1.0200e-04
Loss = 6.9991e-04, PNorm = 37.8356, GNorm = 1.6239, lr_0 = 1.0200e-04
Loss = 6.5093e-04, PNorm = 37.8376, GNorm = 0.9363, lr_0 = 1.0200e-04
Loss = 7.1168e-04, PNorm = 37.8377, GNorm = 1.0574, lr_0 = 1.0200e-04
Loss = 8.7778e-04, PNorm = 37.8386, GNorm = 1.4025, lr_0 = 1.0200e-04
Loss = 8.5008e-04, PNorm = 37.8406, GNorm = 4.7742, lr_0 = 1.0200e-04
Loss = 8.4282e-04, PNorm = 37.8417, GNorm = 1.4775, lr_0 = 1.0200e-04
Loss = 8.0751e-04, PNorm = 37.8431, GNorm = 1.3653, lr_0 = 1.0200e-04
Loss = 7.2271e-04, PNorm = 37.8454, GNorm = 1.4531, lr_0 = 1.0200e-04
Loss = 7.7734e-04, PNorm = 37.8477, GNorm = 0.9830, lr_0 = 1.0200e-04
Loss = 7.7566e-04, PNorm = 37.8486, GNorm = 1.5280, lr_0 = 1.0200e-04
Loss = 7.8185e-04, PNorm = 37.8510, GNorm = 1.7093, lr_0 = 1.0200e-04
Loss = 1.0644e-03, PNorm = 37.8525, GNorm = 3.0816, lr_0 = 1.0200e-04
Loss = 7.8702e-04, PNorm = 37.8547, GNorm = 1.2466, lr_0 = 1.0200e-04
Loss = 7.9060e-04, PNorm = 37.8569, GNorm = 1.9685, lr_0 = 1.0200e-04
Loss = 8.6683e-04, PNorm = 37.8579, GNorm = 1.1370, lr_0 = 1.0200e-04
Loss = 8.7082e-04, PNorm = 37.8593, GNorm = 1.7306, lr_0 = 1.0200e-04
Loss = 7.3614e-04, PNorm = 37.8615, GNorm = 2.3287, lr_0 = 1.0200e-04
Loss = 8.8459e-04, PNorm = 37.8629, GNorm = 2.1720, lr_0 = 1.0200e-04
Validation rmse logD = 0.587666
Validation R2 logD = 0.747806
Validation rmse logP = 0.486997
Validation R2 logP = 0.931192
Epoch 56
Train function
Loss = 7.4989e-04, PNorm = 37.8651, GNorm = 4.3016, lr_0 = 1.0200e-04
Loss = 7.1102e-04, PNorm = 37.8667, GNorm = 1.6618, lr_0 = 1.0200e-04
Loss = 7.0016e-04, PNorm = 37.8681, GNorm = 2.2216, lr_0 = 1.0200e-04
Loss = 7.4653e-04, PNorm = 37.8697, GNorm = 0.9005, lr_0 = 1.0200e-04
Loss = 6.4550e-04, PNorm = 37.8716, GNorm = 1.4089, lr_0 = 1.0200e-04
Loss = 5.9068e-04, PNorm = 37.8736, GNorm = 1.4467, lr_0 = 1.0200e-04
Loss = 6.7486e-04, PNorm = 37.8748, GNorm = 1.5630, lr_0 = 1.0200e-04
Loss = 7.9514e-04, PNorm = 37.8755, GNorm = 1.7948, lr_0 = 1.0200e-04
Loss = 7.7088e-04, PNorm = 37.8760, GNorm = 1.8824, lr_0 = 1.0200e-04
Loss = 1.1359e-03, PNorm = 37.8777, GNorm = 2.6432, lr_0 = 1.0200e-04
Loss = 8.0553e-04, PNorm = 37.8795, GNorm = 2.3020, lr_0 = 1.0200e-04
Loss = 6.6920e-04, PNorm = 37.8808, GNorm = 1.2756, lr_0 = 1.0200e-04
Loss = 7.2946e-04, PNorm = 37.8821, GNorm = 1.8068, lr_0 = 1.0200e-04
Loss = 7.6028e-04, PNorm = 37.8831, GNorm = 2.2337, lr_0 = 1.0200e-04
Loss = 7.6606e-04, PNorm = 37.8847, GNorm = 1.0077, lr_0 = 1.0200e-04
Loss = 8.2458e-04, PNorm = 37.8864, GNorm = 1.6342, lr_0 = 1.0200e-04
Loss = 8.7155e-04, PNorm = 37.8887, GNorm = 2.6138, lr_0 = 1.0200e-04
Loss = 1.2533e-03, PNorm = 37.8898, GNorm = 1.6495, lr_0 = 1.0200e-04
Loss = 1.1578e-03, PNorm = 37.8912, GNorm = 1.8205, lr_0 = 1.0200e-04
Loss = 1.0372e-03, PNorm = 37.8938, GNorm = 1.7053, lr_0 = 1.0200e-04
Loss = 7.9108e-04, PNorm = 37.8953, GNorm = 3.2019, lr_0 = 1.0200e-04
Loss = 7.7594e-04, PNorm = 37.8976, GNorm = 1.7853, lr_0 = 1.0200e-04
Loss = 8.7808e-04, PNorm = 37.8998, GNorm = 1.0285, lr_0 = 1.0200e-04
Validation rmse logD = 0.589847
Validation R2 logD = 0.745930
Validation rmse logP = 0.479850
Validation R2 logP = 0.933197
Epoch 57
Train function
Loss = 6.9522e-04, PNorm = 37.9010, GNorm = 0.9614, lr_0 = 1.0200e-04
Loss = 7.3070e-04, PNorm = 37.9031, GNorm = 2.0308, lr_0 = 1.0200e-04
Loss = 5.5021e-04, PNorm = 37.9051, GNorm = 2.8168, lr_0 = 1.0200e-04
Loss = 6.6815e-04, PNorm = 37.9071, GNorm = 1.8644, lr_0 = 1.0200e-04
Loss = 9.2989e-04, PNorm = 37.9084, GNorm = 0.9877, lr_0 = 1.0200e-04
Loss = 8.4454e-04, PNorm = 37.9097, GNorm = 3.0549, lr_0 = 1.0200e-04
Loss = 7.6675e-04, PNorm = 37.9112, GNorm = 2.8375, lr_0 = 1.0200e-04
Loss = 6.5410e-04, PNorm = 37.9120, GNorm = 1.9822, lr_0 = 1.0200e-04
Loss = 8.4224e-04, PNorm = 37.9133, GNorm = 1.2631, lr_0 = 1.0200e-04
Loss = 9.1289e-04, PNorm = 37.9153, GNorm = 1.7779, lr_0 = 1.0200e-04
Loss = 7.4801e-04, PNorm = 37.9165, GNorm = 3.2196, lr_0 = 1.0200e-04
Loss = 8.5141e-04, PNorm = 37.9186, GNorm = 0.9534, lr_0 = 1.0200e-04
Loss = 8.9200e-04, PNorm = 37.9208, GNorm = 3.5540, lr_0 = 1.0200e-04
Loss = 8.7297e-04, PNorm = 37.9238, GNorm = 1.2757, lr_0 = 1.0200e-04
Loss = 1.0528e-03, PNorm = 37.9267, GNorm = 5.0267, lr_0 = 1.0200e-04
Loss = 8.0519e-04, PNorm = 37.9289, GNorm = 1.2220, lr_0 = 1.0200e-04
Loss = 6.4887e-04, PNorm = 37.9306, GNorm = 1.3782, lr_0 = 1.0200e-04
Loss = 6.6627e-04, PNorm = 37.9325, GNorm = 1.6766, lr_0 = 1.0200e-04
Loss = 7.5596e-04, PNorm = 37.9338, GNorm = 1.0354, lr_0 = 1.0200e-04
Loss = 8.0968e-04, PNorm = 37.9350, GNorm = 1.6926, lr_0 = 1.0200e-04
Loss = 7.3861e-04, PNorm = 37.9370, GNorm = 3.6057, lr_0 = 1.0200e-04
Loss = 6.2294e-04, PNorm = 37.9380, GNorm = 2.3495, lr_0 = 1.0200e-04
Validation rmse logD = 0.589034
Validation R2 logD = 0.746631
Validation rmse logP = 0.478170
Validation R2 logP = 0.933664
Epoch 58
Train function
Loss = 7.2370e-04, PNorm = 37.9400, GNorm = 3.5594, lr_0 = 1.0200e-04
Loss = 6.7507e-04, PNorm = 37.9422, GNorm = 2.0823, lr_0 = 1.0200e-04
Loss = 7.0416e-04, PNorm = 37.9450, GNorm = 1.3191, lr_0 = 1.0200e-04
Loss = 8.7396e-04, PNorm = 37.9464, GNorm = 2.9732, lr_0 = 1.0200e-04
Loss = 8.4589e-04, PNorm = 37.9481, GNorm = 1.9376, lr_0 = 1.0200e-04
Loss = 8.3261e-04, PNorm = 37.9495, GNorm = 1.2025, lr_0 = 1.0200e-04
Loss = 8.3444e-04, PNorm = 37.9510, GNorm = 3.6759, lr_0 = 1.0200e-04
Loss = 7.4801e-04, PNorm = 37.9524, GNorm = 0.9825, lr_0 = 1.0200e-04
Loss = 6.4727e-04, PNorm = 37.9534, GNorm = 2.8597, lr_0 = 1.0200e-04
Loss = 6.5159e-04, PNorm = 37.9549, GNorm = 2.1561, lr_0 = 1.0200e-04
Loss = 6.6149e-04, PNorm = 37.9568, GNorm = 2.3185, lr_0 = 1.0200e-04
Loss = 6.8765e-04, PNorm = 37.9585, GNorm = 1.8184, lr_0 = 1.0200e-04
Loss = 6.5258e-04, PNorm = 37.9595, GNorm = 1.3659, lr_0 = 1.0200e-04
Loss = 6.3593e-04, PNorm = 37.9606, GNorm = 0.9755, lr_0 = 1.0200e-04
Loss = 6.0897e-04, PNorm = 37.9619, GNorm = 1.7909, lr_0 = 1.0200e-04
Loss = 6.7463e-04, PNorm = 37.9633, GNorm = 2.5268, lr_0 = 1.0200e-04
Loss = 9.0494e-04, PNorm = 37.9643, GNorm = 1.4517, lr_0 = 1.0200e-04
Loss = 7.5012e-04, PNorm = 37.9660, GNorm = 2.6406, lr_0 = 1.0200e-04
Loss = 8.6354e-04, PNorm = 37.9680, GNorm = 4.2102, lr_0 = 1.0200e-04
Loss = 7.4393e-04, PNorm = 37.9706, GNorm = 3.2638, lr_0 = 1.0200e-04
Loss = 7.5481e-04, PNorm = 37.9718, GNorm = 1.4338, lr_0 = 1.0200e-04
Loss = 7.2190e-04, PNorm = 37.9742, GNorm = 1.2788, lr_0 = 1.0200e-04
Loss = 6.9730e-04, PNorm = 37.9756, GNorm = 1.2313, lr_0 = 1.0200e-04
Validation rmse logD = 0.665864
Validation R2 logD = 0.676224
Validation rmse logP = 0.562666
Validation R2 logP = 0.908149
Epoch 59
Train function
Loss = 1.3300e-03, PNorm = 37.9772, GNorm = 5.4539, lr_0 = 1.0200e-04
Loss = 1.2801e-03, PNorm = 37.9788, GNorm = 2.8138, lr_0 = 1.0200e-04
Loss = 9.9027e-04, PNorm = 37.9805, GNorm = 2.5880, lr_0 = 1.0200e-04
Loss = 6.7603e-04, PNorm = 37.9823, GNorm = 1.5657, lr_0 = 1.0200e-04
Loss = 6.0389e-04, PNorm = 37.9833, GNorm = 1.9094, lr_0 = 1.0200e-04
Loss = 5.4449e-04, PNorm = 37.9845, GNorm = 1.4354, lr_0 = 1.0200e-04
Loss = 7.6415e-04, PNorm = 37.9865, GNorm = 1.2919, lr_0 = 1.0200e-04
Loss = 9.3580e-04, PNorm = 37.9880, GNorm = 2.9300, lr_0 = 1.0200e-04
Loss = 7.6736e-04, PNorm = 37.9897, GNorm = 2.2914, lr_0 = 1.0200e-04
Loss = 6.5242e-04, PNorm = 37.9922, GNorm = 2.4561, lr_0 = 1.0200e-04
Loss = 6.9955e-04, PNorm = 37.9938, GNorm = 2.2062, lr_0 = 1.0200e-04
Loss = 7.3402e-04, PNorm = 37.9956, GNorm = 1.1261, lr_0 = 1.0200e-04
Loss = 7.7718e-04, PNorm = 37.9971, GNorm = 1.1959, lr_0 = 1.0200e-04
Loss = 6.5880e-04, PNorm = 37.9991, GNorm = 1.1942, lr_0 = 1.0200e-04
Loss = 7.3268e-04, PNorm = 38.0009, GNorm = 1.8032, lr_0 = 1.0200e-04
Loss = 1.0398e-03, PNorm = 38.0020, GNorm = 1.5231, lr_0 = 1.0200e-04
Loss = 7.5486e-04, PNorm = 38.0030, GNorm = 1.7290, lr_0 = 1.0200e-04
Loss = 7.9056e-04, PNorm = 38.0052, GNorm = 2.0394, lr_0 = 1.0200e-04
Loss = 6.8503e-04, PNorm = 38.0072, GNorm = 1.0633, lr_0 = 1.0200e-04
Loss = 7.0978e-04, PNorm = 38.0093, GNorm = 0.6519, lr_0 = 1.0200e-04
Loss = 7.4477e-04, PNorm = 38.0114, GNorm = 1.3741, lr_0 = 1.0200e-04
Loss = 7.5341e-04, PNorm = 38.0127, GNorm = 3.2636, lr_0 = 1.0200e-04
Validation rmse logD = 0.583815
Validation R2 logD = 0.751101
Validation rmse logP = 0.465259
Validation R2 logP = 0.937198
Epoch 60
Train function
Loss = 6.1626e-04, PNorm = 38.0136, GNorm = 2.7110, lr_0 = 1.0200e-04
Loss = 5.8526e-04, PNorm = 38.0162, GNorm = 1.2819, lr_0 = 1.0200e-04
Loss = 7.0590e-04, PNorm = 38.0174, GNorm = 2.4209, lr_0 = 1.0200e-04
Loss = 7.5780e-04, PNorm = 38.0179, GNorm = 0.7688, lr_0 = 1.0200e-04
Loss = 5.9462e-04, PNorm = 38.0194, GNorm = 2.1672, lr_0 = 1.0200e-04
Loss = 5.8194e-04, PNorm = 38.0214, GNorm = 1.5298, lr_0 = 1.0200e-04
Loss = 6.5707e-04, PNorm = 38.0233, GNorm = 3.8708, lr_0 = 1.0200e-04
Loss = 5.6683e-04, PNorm = 38.0246, GNorm = 2.2290, lr_0 = 1.0200e-04
Loss = 7.6629e-04, PNorm = 38.0258, GNorm = 1.2570, lr_0 = 1.0200e-04
Loss = 6.2124e-04, PNorm = 38.0276, GNorm = 3.3935, lr_0 = 1.0200e-04
Loss = 6.6210e-04, PNorm = 38.0302, GNorm = 1.2587, lr_0 = 1.0200e-04
Loss = 8.4354e-04, PNorm = 38.0322, GNorm = 1.8592, lr_0 = 1.0200e-04
Loss = 6.6493e-04, PNorm = 38.0332, GNorm = 0.8986, lr_0 = 1.0200e-04
Loss = 7.1309e-04, PNorm = 38.0341, GNorm = 1.8974, lr_0 = 1.0200e-04
Loss = 6.5892e-04, PNorm = 38.0359, GNorm = 1.3943, lr_0 = 1.0200e-04
Loss = 6.4156e-04, PNorm = 38.0366, GNorm = 2.0468, lr_0 = 1.0200e-04
Loss = 6.6705e-04, PNorm = 38.0384, GNorm = 1.6324, lr_0 = 1.0200e-04
Loss = 6.6593e-04, PNorm = 38.0398, GNorm = 1.3401, lr_0 = 1.0200e-04
Loss = 6.9622e-04, PNorm = 38.0409, GNorm = 1.1628, lr_0 = 1.0200e-04
Loss = 8.4761e-04, PNorm = 38.0426, GNorm = 2.3046, lr_0 = 1.0200e-04
Loss = 7.9310e-04, PNorm = 38.0435, GNorm = 1.3586, lr_0 = 1.0200e-04
Loss = 9.4757e-04, PNorm = 38.0448, GNorm = 2.6548, lr_0 = 1.0200e-04
Loss = 8.0880e-04, PNorm = 38.0457, GNorm = 1.0278, lr_0 = 1.0200e-04
Validation rmse logD = 0.630935
Validation R2 logD = 0.709302
Validation rmse logP = 0.519483
Validation R2 logP = 0.921706
Epoch 61
Train function
Loss = 1.1040e-03, PNorm = 38.0467, GNorm = 5.5181, lr_0 = 1.0200e-04
Loss = 1.0048e-03, PNorm = 38.0476, GNorm = 3.2297, lr_0 = 1.0200e-04
Loss = 6.7260e-04, PNorm = 38.0499, GNorm = 1.5275, lr_0 = 1.0200e-04
Loss = 7.1122e-04, PNorm = 38.0527, GNorm = 1.4605, lr_0 = 1.0200e-04
Loss = 4.8303e-04, PNorm = 38.0547, GNorm = 0.8131, lr_0 = 1.0200e-04
Loss = 6.5178e-04, PNorm = 38.0556, GNorm = 1.4034, lr_0 = 1.0200e-04
Loss = 5.2477e-04, PNorm = 38.0574, GNorm = 2.2400, lr_0 = 1.0200e-04
Loss = 7.9968e-04, PNorm = 38.0597, GNorm = 1.7240, lr_0 = 1.0200e-04
Loss = 6.7120e-04, PNorm = 38.0617, GNorm = 1.0399, lr_0 = 1.0200e-04
Loss = 5.5624e-04, PNorm = 38.0626, GNorm = 1.1818, lr_0 = 1.0200e-04
Loss = 6.2511e-04, PNorm = 38.0641, GNorm = 2.7447, lr_0 = 1.0200e-04
Loss = 7.7131e-04, PNorm = 38.0651, GNorm = 0.9658, lr_0 = 1.0200e-04
Loss = 6.8170e-04, PNorm = 38.0677, GNorm = 1.4648, lr_0 = 1.0200e-04
Loss = 9.0029e-04, PNorm = 38.0698, GNorm = 3.5354, lr_0 = 1.0200e-04
Loss = 7.3522e-04, PNorm = 38.0719, GNorm = 1.7081, lr_0 = 1.0200e-04
Loss = 7.4670e-04, PNorm = 38.0738, GNorm = 2.1514, lr_0 = 1.0200e-04
Loss = 6.2981e-04, PNorm = 38.0757, GNorm = 1.7269, lr_0 = 1.0200e-04
Loss = 6.3757e-04, PNorm = 38.0773, GNorm = 2.6796, lr_0 = 1.0200e-04
Loss = 7.5469e-04, PNorm = 38.0795, GNorm = 1.9192, lr_0 = 1.0200e-04
Loss = 7.4814e-04, PNorm = 38.0806, GNorm = 1.5820, lr_0 = 1.0200e-04
Loss = 7.3808e-04, PNorm = 38.0813, GNorm = 1.9265, lr_0 = 1.0200e-04
Loss = 6.4610e-04, PNorm = 38.0822, GNorm = 3.2163, lr_0 = 1.0200e-04
Validation rmse logD = 0.613439
Validation R2 logD = 0.725200
Validation rmse logP = 0.487820
Validation R2 logP = 0.930960
Epoch 62
Train function
Loss = 8.9578e-04, PNorm = 38.0838, GNorm = 2.6349, lr_0 = 1.0200e-04
Loss = 7.4946e-04, PNorm = 38.0862, GNorm = 3.1982, lr_0 = 1.0200e-04
Loss = 6.5210e-04, PNorm = 38.0877, GNorm = 1.9528, lr_0 = 1.0200e-04
Loss = 5.4873e-04, PNorm = 38.0893, GNorm = 1.6555, lr_0 = 1.0200e-04
Loss = 6.2782e-04, PNorm = 38.0903, GNorm = 3.7365, lr_0 = 1.0200e-04
Loss = 7.9824e-04, PNorm = 38.0919, GNorm = 3.2461, lr_0 = 1.0200e-04
Loss = 7.2593e-04, PNorm = 38.0940, GNorm = 1.7276, lr_0 = 1.0200e-04
Loss = 5.7861e-04, PNorm = 38.0953, GNorm = 1.0245, lr_0 = 1.0200e-04
Loss = 7.5101e-04, PNorm = 38.0963, GNorm = 2.5888, lr_0 = 1.0200e-04
Loss = 7.6196e-04, PNorm = 38.0980, GNorm = 2.5602, lr_0 = 1.0200e-04
Loss = 7.5669e-04, PNorm = 38.0993, GNorm = 4.5279, lr_0 = 1.0200e-04
Loss = 1.0207e-03, PNorm = 38.1010, GNorm = 1.8679, lr_0 = 1.0200e-04
Loss = 8.9067e-04, PNorm = 38.1031, GNorm = 4.4983, lr_0 = 1.0200e-04
Loss = 8.3131e-04, PNorm = 38.1048, GNorm = 2.3090, lr_0 = 1.0200e-04
Loss = 9.0503e-04, PNorm = 38.1069, GNorm = 1.8975, lr_0 = 1.0200e-04
Loss = 7.6845e-04, PNorm = 38.1095, GNorm = 2.4756, lr_0 = 1.0200e-04
Loss = 5.9208e-04, PNorm = 38.1118, GNorm = 0.7299, lr_0 = 1.0200e-04
Loss = 7.6703e-04, PNorm = 38.1142, GNorm = 1.1947, lr_0 = 1.0200e-04
Loss = 7.2709e-04, PNorm = 38.1165, GNorm = 1.6931, lr_0 = 1.0200e-04
Loss = 6.4326e-04, PNorm = 38.1186, GNorm = 1.2570, lr_0 = 1.0200e-04
Loss = 7.7433e-04, PNorm = 38.1196, GNorm = 3.0255, lr_0 = 1.0200e-04
Loss = 8.6017e-04, PNorm = 38.1206, GNorm = 1.2647, lr_0 = 1.0200e-04
Loss = 8.0003e-04, PNorm = 38.1221, GNorm = 3.0247, lr_0 = 1.0200e-04
Validation rmse logD = 0.582332
Validation R2 logD = 0.752364
Validation rmse logP = 0.463757
Validation R2 logP = 0.937603
Epoch 63
Train function
Loss = 5.5854e-04, PNorm = 38.1238, GNorm = 1.6412, lr_0 = 1.0200e-04
Loss = 6.7461e-04, PNorm = 38.1253, GNorm = 1.1907, lr_0 = 1.0200e-04
Loss = 6.2871e-04, PNorm = 38.1263, GNorm = 1.2454, lr_0 = 1.0200e-04
Loss = 5.9106e-04, PNorm = 38.1281, GNorm = 1.0971, lr_0 = 1.0200e-04
Loss = 6.4541e-04, PNorm = 38.1289, GNorm = 2.0166, lr_0 = 1.0200e-04
Loss = 6.0292e-04, PNorm = 38.1300, GNorm = 0.8721, lr_0 = 1.0200e-04
Loss = 6.5716e-04, PNorm = 38.1313, GNorm = 3.6511, lr_0 = 1.0200e-04
Loss = 6.1557e-04, PNorm = 38.1344, GNorm = 1.1667, lr_0 = 1.0200e-04
Loss = 6.8288e-04, PNorm = 38.1363, GNorm = 2.3944, lr_0 = 1.0200e-04
Loss = 6.7062e-04, PNorm = 38.1380, GNorm = 1.1700, lr_0 = 1.0200e-04
Loss = 5.3908e-04, PNorm = 38.1393, GNorm = 1.2158, lr_0 = 1.0200e-04
Loss = 6.4516e-04, PNorm = 38.1409, GNorm = 2.4509, lr_0 = 1.0200e-04
Loss = 5.6833e-04, PNorm = 38.1423, GNorm = 1.2578, lr_0 = 1.0200e-04
Loss = 5.5951e-04, PNorm = 38.1434, GNorm = 2.8707, lr_0 = 1.0200e-04
Loss = 8.2296e-04, PNorm = 38.1451, GNorm = 1.5171, lr_0 = 1.0200e-04
Loss = 6.4835e-04, PNorm = 38.1474, GNorm = 1.9625, lr_0 = 1.0200e-04
Loss = 8.7308e-04, PNorm = 38.1488, GNorm = 3.2999, lr_0 = 1.0200e-04
Loss = 6.4538e-04, PNorm = 38.1498, GNorm = 1.0684, lr_0 = 1.0200e-04
Loss = 6.1314e-04, PNorm = 38.1520, GNorm = 0.8199, lr_0 = 1.0200e-04
Loss = 5.7577e-04, PNorm = 38.1535, GNorm = 1.2260, lr_0 = 1.0200e-04
Loss = 7.9694e-04, PNorm = 38.1547, GNorm = 1.5895, lr_0 = 1.0200e-04
Loss = 6.8341e-04, PNorm = 38.1570, GNorm = 1.0630, lr_0 = 1.0200e-04
Loss = 6.1150e-04, PNorm = 38.1591, GNorm = 1.6781, lr_0 = 1.0200e-04
Loss = 1.2478e-03, PNorm = 38.1593, GNorm = 3.0424, lr_0 = 1.0200e-04
Validation rmse logD = 0.614356
Validation R2 logD = 0.724378
Validation rmse logP = 0.462432
Validation R2 logP = 0.937959
Epoch 64
Train function
Loss = 5.6572e-04, PNorm = 38.1603, GNorm = 1.8913, lr_0 = 1.0200e-04
Loss = 5.7991e-04, PNorm = 38.1612, GNorm = 0.7717, lr_0 = 1.0200e-04
Loss = 4.5529e-04, PNorm = 38.1627, GNorm = 1.4245, lr_0 = 1.0200e-04
Loss = 7.6604e-04, PNorm = 38.1642, GNorm = 2.0552, lr_0 = 1.0200e-04
Loss = 6.1680e-04, PNorm = 38.1653, GNorm = 2.0361, lr_0 = 1.0200e-04
Loss = 7.0652e-04, PNorm = 38.1669, GNorm = 1.4477, lr_0 = 1.0200e-04
Loss = 8.1389e-04, PNorm = 38.1693, GNorm = 3.7560, lr_0 = 1.0200e-04
Loss = 6.3561e-04, PNorm = 38.1713, GNorm = 2.1088, lr_0 = 1.0200e-04
Loss = 7.2374e-04, PNorm = 38.1723, GNorm = 1.4441, lr_0 = 1.0200e-04
Loss = 7.5185e-04, PNorm = 38.1741, GNorm = 2.7807, lr_0 = 1.0200e-04
Loss = 6.3806e-04, PNorm = 38.1771, GNorm = 1.7925, lr_0 = 1.0200e-04
Loss = 8.0927e-04, PNorm = 38.1796, GNorm = 2.0221, lr_0 = 1.0200e-04
Loss = 5.9738e-04, PNorm = 38.1815, GNorm = 2.1539, lr_0 = 1.0200e-04
Loss = 8.5114e-04, PNorm = 38.1827, GNorm = 1.2822, lr_0 = 1.0200e-04
Loss = 5.3613e-04, PNorm = 38.1833, GNorm = 1.0122, lr_0 = 1.0200e-04
Loss = 5.5221e-04, PNorm = 38.1844, GNorm = 2.2128, lr_0 = 1.0200e-04
Loss = 7.7534e-04, PNorm = 38.1856, GNorm = 1.1055, lr_0 = 1.0200e-04
Loss = 6.1643e-04, PNorm = 38.1868, GNorm = 1.0074, lr_0 = 1.0200e-04
Loss = 7.4107e-04, PNorm = 38.1885, GNorm = 1.8147, lr_0 = 1.0200e-04
Loss = 8.3188e-04, PNorm = 38.1903, GNorm = 1.5130, lr_0 = 1.0200e-04
Loss = 6.4244e-04, PNorm = 38.1920, GNorm = 1.5883, lr_0 = 1.0200e-04
Loss = 6.9913e-04, PNorm = 38.1935, GNorm = 2.8179, lr_0 = 1.0200e-04
Validation rmse logD = 0.589076
Validation R2 logD = 0.746595
Validation rmse logP = 0.466774
Validation R2 logP = 0.936788
Epoch 65
Train function
Loss = 5.8438e-04, PNorm = 38.1957, GNorm = 0.8531, lr_0 = 1.0200e-04
Loss = 8.2994e-04, PNorm = 38.1971, GNorm = 2.3022, lr_0 = 1.0200e-04
Loss = 5.9511e-04, PNorm = 38.1987, GNorm = 1.2322, lr_0 = 1.0200e-04
Loss = 5.5272e-04, PNorm = 38.2004, GNorm = 1.6041, lr_0 = 1.0200e-04
Loss = 6.4886e-04, PNorm = 38.2010, GNorm = 1.2995, lr_0 = 1.0200e-04
Loss = 7.5849e-04, PNorm = 38.2014, GNorm = 1.3468, lr_0 = 1.0200e-04
Loss = 7.0548e-04, PNorm = 38.2032, GNorm = 1.3563, lr_0 = 1.0200e-04
Loss = 6.4209e-04, PNorm = 38.2052, GNorm = 3.0108, lr_0 = 1.0200e-04
Loss = 6.4318e-04, PNorm = 38.2073, GNorm = 4.7612, lr_0 = 1.0200e-04
Loss = 5.5937e-04, PNorm = 38.2085, GNorm = 0.9402, lr_0 = 1.0200e-04
Loss = 6.3360e-04, PNorm = 38.2098, GNorm = 0.8988, lr_0 = 1.0200e-04
Loss = 8.5741e-04, PNorm = 38.2110, GNorm = 2.9632, lr_0 = 1.0200e-04
Loss = 6.6701e-04, PNorm = 38.2130, GNorm = 1.9459, lr_0 = 1.0200e-04
Loss = 6.8531e-04, PNorm = 38.2139, GNorm = 1.6562, lr_0 = 1.0200e-04
Loss = 5.5262e-04, PNorm = 38.2148, GNorm = 1.0194, lr_0 = 1.0200e-04
Loss = 6.3080e-04, PNorm = 38.2159, GNorm = 2.0686, lr_0 = 1.0200e-04
Loss = 6.6513e-04, PNorm = 38.2175, GNorm = 2.4319, lr_0 = 1.0200e-04
Loss = 7.4649e-04, PNorm = 38.2186, GNorm = 1.7027, lr_0 = 1.0200e-04
Loss = 6.0678e-04, PNorm = 38.2206, GNorm = 1.7210, lr_0 = 1.0200e-04
Loss = 4.9325e-04, PNorm = 38.2223, GNorm = 1.9217, lr_0 = 1.0200e-04
Loss = 6.3317e-04, PNorm = 38.2231, GNorm = 1.4462, lr_0 = 1.0200e-04
Loss = 5.7681e-04, PNorm = 38.2246, GNorm = 1.2752, lr_0 = 1.0200e-04
Loss = 4.9338e-04, PNorm = 38.2260, GNorm = 1.9913, lr_0 = 1.0200e-04
Validation rmse logD = 0.577778
Validation R2 logD = 0.756222
Validation rmse logP = 0.473899
Validation R2 logP = 0.934844
Epoch 66
Train function
Loss = 6.1526e-04, PNorm = 38.2285, GNorm = 1.4738, lr_0 = 1.0200e-04
Loss = 6.4907e-04, PNorm = 38.2299, GNorm = 2.7154, lr_0 = 1.0200e-04
Loss = 6.2661e-04, PNorm = 38.2312, GNorm = 2.3815, lr_0 = 1.0200e-04
Loss = 5.3853e-04, PNorm = 38.2328, GNorm = 2.8192, lr_0 = 1.0200e-04
Loss = 7.2506e-04, PNorm = 38.2342, GNorm = 0.9226, lr_0 = 1.0200e-04
Loss = 6.0546e-04, PNorm = 38.2356, GNorm = 1.1655, lr_0 = 1.0200e-04
Loss = 6.6093e-04, PNorm = 38.2372, GNorm = 2.9087, lr_0 = 1.0200e-04
Loss = 7.0786e-04, PNorm = 38.2387, GNorm = 2.9749, lr_0 = 1.0200e-04
Loss = 5.2106e-04, PNorm = 38.2398, GNorm = 0.9724, lr_0 = 1.0200e-04
Loss = 6.2586e-04, PNorm = 38.2416, GNorm = 1.8041, lr_0 = 1.0200e-04
Loss = 5.4429e-04, PNorm = 38.2432, GNorm = 1.2940, lr_0 = 1.0200e-04
Loss = 4.6544e-04, PNorm = 38.2448, GNorm = 0.9388, lr_0 = 1.0200e-04
Loss = 5.9455e-04, PNorm = 38.2459, GNorm = 2.6168, lr_0 = 1.0200e-04
Loss = 6.5444e-04, PNorm = 38.2482, GNorm = 3.1938, lr_0 = 1.0200e-04
Loss = 8.7136e-04, PNorm = 38.2494, GNorm = 4.9925, lr_0 = 1.0200e-04
Loss = 7.6617e-04, PNorm = 38.2498, GNorm = 2.2220, lr_0 = 1.0200e-04
Loss = 7.7122e-04, PNorm = 38.2509, GNorm = 3.1631, lr_0 = 1.0200e-04
Loss = 6.6373e-04, PNorm = 38.2523, GNorm = 1.5802, lr_0 = 1.0200e-04
Loss = 6.4727e-04, PNorm = 38.2535, GNorm = 1.2401, lr_0 = 1.0200e-04
Loss = 6.9140e-04, PNorm = 38.2549, GNorm = 2.5891, lr_0 = 1.0200e-04
Loss = 5.1625e-04, PNorm = 38.2567, GNorm = 1.5004, lr_0 = 1.0200e-04
Loss = 7.6848e-04, PNorm = 38.2588, GNorm = 2.0222, lr_0 = 1.0200e-04
Validation rmse logD = 0.584762
Validation R2 logD = 0.750292
Validation rmse logP = 0.463523
Validation R2 logP = 0.937666
Epoch 67
Train function
Loss = 4.1265e-04, PNorm = 38.2605, GNorm = 0.6005, lr_0 = 1.0200e-04
Loss = 5.6996e-04, PNorm = 38.2628, GNorm = 1.2155, lr_0 = 1.0200e-04
Loss = 5.7738e-04, PNorm = 38.2647, GNorm = 2.5816, lr_0 = 1.0200e-04
Loss = 6.7857e-04, PNorm = 38.2655, GNorm = 3.4633, lr_0 = 1.0200e-04
Loss = 6.3073e-04, PNorm = 38.2660, GNorm = 2.1222, lr_0 = 1.0200e-04
Loss = 5.6358e-04, PNorm = 38.2669, GNorm = 1.3320, lr_0 = 1.0200e-04
Loss = 5.4843e-04, PNorm = 38.2685, GNorm = 1.2680, lr_0 = 1.0200e-04
Loss = 5.6808e-04, PNorm = 38.2702, GNorm = 3.5296, lr_0 = 1.0200e-04
Loss = 6.7150e-04, PNorm = 38.2725, GNorm = 1.0940, lr_0 = 1.0200e-04
Loss = 5.8576e-04, PNorm = 38.2739, GNorm = 0.8178, lr_0 = 1.0200e-04
Loss = 6.6638e-04, PNorm = 38.2751, GNorm = 1.7997, lr_0 = 1.0200e-04
Loss = 5.4339e-04, PNorm = 38.2769, GNorm = 0.7796, lr_0 = 1.0200e-04
Loss = 5.8481e-04, PNorm = 38.2789, GNorm = 1.3031, lr_0 = 1.0200e-04
Loss = 6.3868e-04, PNorm = 38.2799, GNorm = 3.9512, lr_0 = 1.0200e-04
Loss = 6.0710e-04, PNorm = 38.2809, GNorm = 1.6313, lr_0 = 1.0200e-04
Loss = 5.8670e-04, PNorm = 38.2818, GNorm = 2.1139, lr_0 = 1.0200e-04
Loss = 5.1616e-04, PNorm = 38.2834, GNorm = 2.0345, lr_0 = 1.0200e-04
Loss = 5.7144e-04, PNorm = 38.2844, GNorm = 1.1903, lr_0 = 1.0200e-04
Loss = 8.4156e-04, PNorm = 38.2854, GNorm = 6.3153, lr_0 = 1.0200e-04
Loss = 6.9460e-04, PNorm = 38.2866, GNorm = 2.5529, lr_0 = 1.0200e-04
Loss = 1.0783e-03, PNorm = 38.2871, GNorm = 3.8485, lr_0 = 1.0200e-04
Loss = 7.2074e-04, PNorm = 38.2884, GNorm = 3.3392, lr_0 = 1.0200e-04
Loss = 9.2272e-04, PNorm = 38.2906, GNorm = 4.1849, lr_0 = 1.0200e-04
Validation rmse logD = 0.598466
Validation R2 logD = 0.738452
Validation rmse logP = 0.485220
Validation R2 logP = 0.931694
Epoch 68
Train function
Loss = 8.0708e-04, PNorm = 38.2940, GNorm = 2.3831, lr_0 = 1.0200e-04
Loss = 6.6298e-04, PNorm = 38.2961, GNorm = 1.8455, lr_0 = 1.0200e-04
Loss = 5.5811e-04, PNorm = 38.2980, GNorm = 1.4524, lr_0 = 1.0200e-04
Loss = 6.9881e-04, PNorm = 38.3002, GNorm = 2.0437, lr_0 = 1.0200e-04
Loss = 6.9454e-04, PNorm = 38.3015, GNorm = 1.4611, lr_0 = 1.0200e-04
Loss = 6.7775e-04, PNorm = 38.3035, GNorm = 1.4192, lr_0 = 1.0200e-04
Loss = 6.3188e-04, PNorm = 38.3052, GNorm = 1.8477, lr_0 = 1.0200e-04
Loss = 5.0216e-04, PNorm = 38.3070, GNorm = 1.1351, lr_0 = 1.0200e-04
Loss = 6.4042e-04, PNorm = 38.3077, GNorm = 1.8750, lr_0 = 1.0200e-04
Loss = 7.4226e-04, PNorm = 38.3089, GNorm = 0.6534, lr_0 = 1.0200e-04
Loss = 7.6181e-04, PNorm = 38.3110, GNorm = 2.6250, lr_0 = 1.0200e-04
Loss = 7.4887e-04, PNorm = 38.3125, GNorm = 4.5967, lr_0 = 1.0200e-04
Loss = 5.7001e-04, PNorm = 38.3141, GNorm = 1.7839, lr_0 = 1.0200e-04
Loss = 5.5351e-04, PNorm = 38.3157, GNorm = 2.0717, lr_0 = 1.0200e-04
Loss = 6.6856e-04, PNorm = 38.3175, GNorm = 3.7978, lr_0 = 1.0200e-04
Loss = 7.0266e-04, PNorm = 38.3189, GNorm = 2.1481, lr_0 = 1.0200e-04
Loss = 4.9633e-04, PNorm = 38.3196, GNorm = 1.2071, lr_0 = 1.0200e-04
Loss = 4.9198e-04, PNorm = 38.3216, GNorm = 1.1887, lr_0 = 1.0200e-04
Loss = 6.2162e-04, PNorm = 38.3229, GNorm = 1.5894, lr_0 = 1.0200e-04
Loss = 5.6379e-04, PNorm = 38.3244, GNorm = 1.2793, lr_0 = 1.0200e-04
Loss = 6.5068e-04, PNorm = 38.3253, GNorm = 2.3126, lr_0 = 1.0200e-04
Loss = 6.2623e-04, PNorm = 38.3268, GNorm = 1.9881, lr_0 = 1.0200e-04
Validation rmse logD = 0.606974
Validation R2 logD = 0.730962
Validation rmse logP = 0.463854
Validation R2 logP = 0.937577
Epoch 69
Train function
Loss = 5.4845e-04, PNorm = 38.3282, GNorm = 3.5686, lr_0 = 1.0200e-04
Loss = 5.4840e-04, PNorm = 38.3298, GNorm = 1.4805, lr_0 = 1.0200e-04
Loss = 5.1892e-04, PNorm = 38.3312, GNorm = 1.0737, lr_0 = 1.0200e-04
Loss = 5.6574e-04, PNorm = 38.3331, GNorm = 2.6627, lr_0 = 1.0200e-04
Loss = 5.5992e-04, PNorm = 38.3355, GNorm = 1.1512, lr_0 = 1.0200e-04
Loss = 6.1971e-04, PNorm = 38.3375, GNorm = 2.4925, lr_0 = 1.0200e-04
Loss = 6.5660e-04, PNorm = 38.3391, GNorm = 1.6704, lr_0 = 1.0200e-04
Loss = 5.8362e-04, PNorm = 38.3407, GNorm = 1.8533, lr_0 = 1.0200e-04
Loss = 5.6819e-04, PNorm = 38.3423, GNorm = 0.7108, lr_0 = 1.0200e-04
Loss = 4.9443e-04, PNorm = 38.3436, GNorm = 0.9761, lr_0 = 1.0200e-04
Loss = 5.2499e-04, PNorm = 38.3446, GNorm = 1.8017, lr_0 = 1.0200e-04
Loss = 5.4957e-04, PNorm = 38.3457, GNorm = 1.4490, lr_0 = 1.0200e-04
Loss = 4.4737e-04, PNorm = 38.3472, GNorm = 1.2019, lr_0 = 1.0200e-04
Loss = 7.8987e-04, PNorm = 38.3487, GNorm = 1.8864, lr_0 = 1.0200e-04
Loss = 6.7210e-04, PNorm = 38.3495, GNorm = 1.8690, lr_0 = 1.0200e-04
Loss = 5.1515e-04, PNorm = 38.3512, GNorm = 1.1714, lr_0 = 1.0200e-04
Loss = 5.5399e-04, PNorm = 38.3521, GNorm = 1.6539, lr_0 = 1.0200e-04
Loss = 6.1092e-04, PNorm = 38.3531, GNorm = 1.3253, lr_0 = 1.0200e-04
Loss = 6.0443e-04, PNorm = 38.3544, GNorm = 1.7219, lr_0 = 1.0200e-04
Loss = 5.5479e-04, PNorm = 38.3552, GNorm = 1.7170, lr_0 = 1.0200e-04
Loss = 5.4847e-04, PNorm = 38.3561, GNorm = 1.0535, lr_0 = 1.0200e-04
Loss = 5.7344e-04, PNorm = 38.3578, GNorm = 0.9831, lr_0 = 1.0200e-04
Loss = 5.7274e-04, PNorm = 38.3593, GNorm = 1.8891, lr_0 = 1.0200e-04
Validation rmse logD = 0.583923
Validation R2 logD = 0.751008
Validation rmse logP = 0.471346
Validation R2 logP = 0.935544
Epoch 70
Train function
Loss = 5.9545e-04, PNorm = 38.3613, GNorm = 1.0744, lr_0 = 1.0200e-04
Loss = 5.8029e-04, PNorm = 38.3624, GNorm = 0.8534, lr_0 = 1.0200e-04
Loss = 5.1272e-04, PNorm = 38.3647, GNorm = 1.8458, lr_0 = 1.0200e-04
Loss = 5.9764e-04, PNorm = 38.3656, GNorm = 1.0951, lr_0 = 1.0200e-04
Loss = 6.1233e-04, PNorm = 38.3668, GNorm = 0.8632, lr_0 = 1.0200e-04
Loss = 6.9280e-04, PNorm = 38.3689, GNorm = 5.3493, lr_0 = 1.0200e-04
Loss = 7.1858e-04, PNorm = 38.3705, GNorm = 2.9849, lr_0 = 1.0200e-04
Loss = 6.0706e-04, PNorm = 38.3722, GNorm = 1.6511, lr_0 = 1.0200e-04
Loss = 5.2017e-04, PNorm = 38.3742, GNorm = 0.9181, lr_0 = 1.0200e-04
Loss = 4.8178e-04, PNorm = 38.3757, GNorm = 0.8773, lr_0 = 1.0200e-04
Loss = 5.0462e-04, PNorm = 38.3776, GNorm = 1.5428, lr_0 = 1.0200e-04
Loss = 4.9244e-04, PNorm = 38.3790, GNorm = 0.8357, lr_0 = 1.0200e-04
Loss = 6.0509e-04, PNorm = 38.3803, GNorm = 2.3742, lr_0 = 1.0200e-04
Loss = 5.3285e-04, PNorm = 38.3819, GNorm = 2.3934, lr_0 = 1.0200e-04
Loss = 6.0286e-04, PNorm = 38.3835, GNorm = 0.9412, lr_0 = 1.0200e-04
Loss = 4.8318e-04, PNorm = 38.3852, GNorm = 1.4466, lr_0 = 1.0200e-04
Loss = 6.5608e-04, PNorm = 38.3864, GNorm = 1.3952, lr_0 = 1.0200e-04
Loss = 7.0632e-04, PNorm = 38.3881, GNorm = 4.2446, lr_0 = 1.0200e-04
Loss = 6.1524e-04, PNorm = 38.3894, GNorm = 2.3700, lr_0 = 1.0200e-04
Loss = 5.6181e-04, PNorm = 38.3910, GNorm = 1.6173, lr_0 = 1.0200e-04
Loss = 4.9204e-04, PNorm = 38.3921, GNorm = 2.2017, lr_0 = 1.0200e-04
Loss = 5.9035e-04, PNorm = 38.3926, GNorm = 2.4719, lr_0 = 1.0200e-04
Validation rmse logD = 0.581453
Validation R2 logD = 0.753111
Validation rmse logP = 0.467671
Validation R2 logP = 0.936545
Epoch 71
Train function
Loss = 6.2508e-04, PNorm = 38.3934, GNorm = 1.4593, lr_0 = 1.0200e-04
Loss = 5.4848e-04, PNorm = 38.3946, GNorm = 1.1603, lr_0 = 1.0200e-04
Loss = 5.2284e-04, PNorm = 38.3963, GNorm = 0.9784, lr_0 = 1.0200e-04
Loss = 5.8945e-04, PNorm = 38.3978, GNorm = 2.5284, lr_0 = 1.0200e-04
Loss = 5.6973e-04, PNorm = 38.3990, GNorm = 1.5477, lr_0 = 1.0200e-04
Loss = 5.6896e-04, PNorm = 38.4005, GNorm = 2.4152, lr_0 = 1.0200e-04
Loss = 6.5660e-04, PNorm = 38.4015, GNorm = 2.1271, lr_0 = 1.0200e-04
Loss = 4.9345e-04, PNorm = 38.4024, GNorm = 1.7864, lr_0 = 1.0200e-04
Loss = 5.9712e-04, PNorm = 38.4040, GNorm = 2.7764, lr_0 = 1.0200e-04
Loss = 6.5230e-04, PNorm = 38.4054, GNorm = 2.0725, lr_0 = 1.0200e-04
Loss = 5.0577e-04, PNorm = 38.4071, GNorm = 3.5113, lr_0 = 1.0200e-04
Loss = 6.4638e-04, PNorm = 38.4085, GNorm = 2.3379, lr_0 = 1.0200e-04
Loss = 5.0969e-04, PNorm = 38.4097, GNorm = 1.4604, lr_0 = 1.0200e-04
Loss = 5.2645e-04, PNorm = 38.4110, GNorm = 1.5455, lr_0 = 1.0200e-04
Loss = 4.8709e-04, PNorm = 38.4123, GNorm = 1.0388, lr_0 = 1.0200e-04
Loss = 5.6012e-04, PNorm = 38.4138, GNorm = 1.5030, lr_0 = 1.0200e-04
Loss = 6.9778e-04, PNorm = 38.4142, GNorm = 1.0836, lr_0 = 1.0200e-04
Loss = 6.9763e-04, PNorm = 38.4154, GNorm = 1.6392, lr_0 = 1.0200e-04
Loss = 6.1975e-04, PNorm = 38.4172, GNorm = 2.5158, lr_0 = 1.0200e-04
Loss = 6.7826e-04, PNorm = 38.4185, GNorm = 1.0127, lr_0 = 1.0200e-04
Loss = 5.6185e-04, PNorm = 38.4202, GNorm = 1.5610, lr_0 = 1.0200e-04
Loss = 5.2536e-04, PNorm = 38.4216, GNorm = 1.4703, lr_0 = 1.0200e-04
Loss = 5.3838e-04, PNorm = 38.4236, GNorm = 1.1478, lr_0 = 1.0200e-04
Validation rmse logD = 0.602318
Validation R2 logD = 0.735073
Validation rmse logP = 0.467725
Validation R2 logP = 0.936530
Epoch 72
Train function
Loss = 6.6141e-04, PNorm = 38.4253, GNorm = 2.3370, lr_0 = 1.0200e-04
Loss = 4.9415e-04, PNorm = 38.4267, GNorm = 1.8730, lr_0 = 1.0200e-04
Loss = 4.7389e-04, PNorm = 38.4277, GNorm = 1.3880, lr_0 = 1.0200e-04
Loss = 5.0859e-04, PNorm = 38.4291, GNorm = 0.9737, lr_0 = 1.0200e-04
Loss = 5.1481e-04, PNorm = 38.4309, GNorm = 1.4327, lr_0 = 1.0200e-04
Loss = 6.5020e-04, PNorm = 38.4316, GNorm = 3.9482, lr_0 = 1.0200e-04
Loss = 8.9534e-04, PNorm = 38.4331, GNorm = 6.3911, lr_0 = 1.0200e-04
Loss = 9.5105e-04, PNorm = 38.4343, GNorm = 1.3933, lr_0 = 1.0200e-04
Loss = 7.5195e-04, PNorm = 38.4359, GNorm = 2.0875, lr_0 = 1.0200e-04
Loss = 4.8340e-04, PNorm = 38.4373, GNorm = 1.3876, lr_0 = 1.0200e-04
Loss = 6.4391e-04, PNorm = 38.4396, GNorm = 1.3816, lr_0 = 1.0200e-04
Loss = 6.9164e-04, PNorm = 38.4413, GNorm = 2.7510, lr_0 = 1.0200e-04
Loss = 6.5302e-04, PNorm = 38.4426, GNorm = 1.2894, lr_0 = 1.0200e-04
Loss = 7.0071e-04, PNorm = 38.4437, GNorm = 2.6829, lr_0 = 1.0200e-04
Loss = 6.6502e-04, PNorm = 38.4459, GNorm = 1.8477, lr_0 = 1.0200e-04
Loss = 5.3426e-04, PNorm = 38.4478, GNorm = 3.0615, lr_0 = 1.0200e-04
Loss = 7.0018e-04, PNorm = 38.4483, GNorm = 1.1793, lr_0 = 1.0200e-04
Loss = 5.8240e-04, PNorm = 38.4504, GNorm = 1.0544, lr_0 = 1.0200e-04
Loss = 4.6297e-04, PNorm = 38.4517, GNorm = 0.8191, lr_0 = 1.0200e-04
Loss = 4.1902e-04, PNorm = 38.4536, GNorm = 1.4587, lr_0 = 1.0200e-04
Loss = 5.5137e-04, PNorm = 38.4554, GNorm = 1.6394, lr_0 = 1.0200e-04
Loss = 5.0015e-04, PNorm = 38.4574, GNorm = 2.9064, lr_0 = 1.0200e-04
Loss = 7.0732e-04, PNorm = 38.4586, GNorm = 4.4772, lr_0 = 1.0200e-04
Validation rmse logD = 0.580355
Validation R2 logD = 0.754042
Validation rmse logP = 0.491986
Validation R2 logP = 0.929775
Epoch 73
Train function
Loss = 5.5210e-04, PNorm = 38.4591, GNorm = 1.2145, lr_0 = 1.0200e-04
Loss = 4.6682e-04, PNorm = 38.4607, GNorm = 1.8758, lr_0 = 1.0200e-04
Loss = 4.4625e-04, PNorm = 38.4618, GNorm = 0.9828, lr_0 = 1.0200e-04
Loss = 4.3419e-04, PNorm = 38.4632, GNorm = 0.8824, lr_0 = 1.0200e-04
Loss = 6.4401e-04, PNorm = 38.4631, GNorm = 1.2338, lr_0 = 1.0200e-04
Loss = 7.8651e-04, PNorm = 38.4649, GNorm = 3.8988, lr_0 = 1.0200e-04
Loss = 7.2728e-04, PNorm = 38.4668, GNorm = 1.9225, lr_0 = 1.0200e-04
Loss = 6.2456e-04, PNorm = 38.4682, GNorm = 1.4993, lr_0 = 1.0200e-04
Loss = 4.9697e-04, PNorm = 38.4697, GNorm = 1.6354, lr_0 = 1.0200e-04
Loss = 5.7664e-04, PNorm = 38.4708, GNorm = 2.3106, lr_0 = 1.0200e-04
Loss = 5.6727e-04, PNorm = 38.4721, GNorm = 1.4093, lr_0 = 1.0200e-04
Loss = 4.3941e-04, PNorm = 38.4743, GNorm = 1.0030, lr_0 = 1.0200e-04
Loss = 5.6212e-04, PNorm = 38.4755, GNorm = 2.5193, lr_0 = 1.0200e-04
Loss = 4.6205e-04, PNorm = 38.4767, GNorm = 1.8003, lr_0 = 1.0200e-04
Loss = 5.7009e-04, PNorm = 38.4775, GNorm = 1.9757, lr_0 = 1.0200e-04
Loss = 5.5139e-04, PNorm = 38.4790, GNorm = 0.8634, lr_0 = 1.0200e-04
Loss = 4.7999e-04, PNorm = 38.4804, GNorm = 0.9540, lr_0 = 1.0200e-04
Loss = 5.8327e-04, PNorm = 38.4825, GNorm = 1.7485, lr_0 = 1.0200e-04
Loss = 5.0899e-04, PNorm = 38.4844, GNorm = 0.8666, lr_0 = 1.0200e-04
Loss = 6.7706e-04, PNorm = 38.4860, GNorm = 3.1936, lr_0 = 1.0200e-04
Loss = 6.2726e-04, PNorm = 38.4867, GNorm = 0.9314, lr_0 = 1.0200e-04
Loss = 5.2408e-04, PNorm = 38.4874, GNorm = 2.0963, lr_0 = 1.0200e-04
Validation rmse logD = 0.583724
Validation R2 logD = 0.751178
Validation rmse logP = 0.461474
Validation R2 logP = 0.938215
Epoch 74
Train function
Loss = 6.1097e-04, PNorm = 38.4889, GNorm = 2.3118, lr_0 = 1.0200e-04
Loss = 4.7532e-04, PNorm = 38.4910, GNorm = 0.9744, lr_0 = 1.0200e-04
Loss = 6.5567e-04, PNorm = 38.4924, GNorm = 1.9242, lr_0 = 1.0200e-04
Loss = 5.1483e-04, PNorm = 38.4944, GNorm = 0.6280, lr_0 = 1.0200e-04
Loss = 4.7311e-04, PNorm = 38.4959, GNorm = 1.7498, lr_0 = 1.0200e-04
Loss = 4.0282e-04, PNorm = 38.4973, GNorm = 0.8153, lr_0 = 1.0200e-04
Loss = 4.2574e-04, PNorm = 38.4989, GNorm = 1.0579, lr_0 = 1.0200e-04
Loss = 4.1252e-04, PNorm = 38.4998, GNorm = 0.8907, lr_0 = 1.0200e-04
Loss = 5.4993e-04, PNorm = 38.5008, GNorm = 1.1270, lr_0 = 1.0200e-04
Loss = 5.6875e-04, PNorm = 38.5017, GNorm = 2.6505, lr_0 = 1.0200e-04
Loss = 5.1862e-04, PNorm = 38.5038, GNorm = 1.4670, lr_0 = 1.0200e-04
Loss = 6.0121e-04, PNorm = 38.5058, GNorm = 2.1752, lr_0 = 1.0200e-04
Loss = 5.3768e-04, PNorm = 38.5070, GNorm = 1.4434, lr_0 = 1.0200e-04
Loss = 4.9345e-04, PNorm = 38.5083, GNorm = 1.1403, lr_0 = 1.0200e-04
Loss = 4.9172e-04, PNorm = 38.5091, GNorm = 1.1296, lr_0 = 1.0200e-04
Loss = 5.3746e-04, PNorm = 38.5105, GNorm = 2.0157, lr_0 = 1.0200e-04
Loss = 5.4101e-04, PNorm = 38.5110, GNorm = 1.3659, lr_0 = 1.0200e-04
Loss = 4.9536e-04, PNorm = 38.5121, GNorm = 1.4549, lr_0 = 1.0200e-04
Loss = 4.7418e-04, PNorm = 38.5139, GNorm = 2.2439, lr_0 = 1.0200e-04
Loss = 5.6207e-04, PNorm = 38.5157, GNorm = 1.0305, lr_0 = 1.0200e-04
Loss = 4.9986e-04, PNorm = 38.5170, GNorm = 1.0427, lr_0 = 1.0200e-04
Loss = 5.3954e-04, PNorm = 38.5186, GNorm = 0.8381, lr_0 = 1.0200e-04
Loss = 5.5064e-04, PNorm = 38.5201, GNorm = 1.2877, lr_0 = 1.0200e-04
Validation rmse logD = 0.640033
Validation R2 logD = 0.700858
Validation rmse logP = 0.465358
Validation R2 logP = 0.937171
Epoch 75
Train function
Loss = 4.9993e-04, PNorm = 38.5207, GNorm = 2.3832, lr_0 = 1.0200e-04
Loss = 5.9125e-04, PNorm = 38.5212, GNorm = 2.7563, lr_0 = 1.0200e-04
Loss = 5.5697e-04, PNorm = 38.5219, GNorm = 4.4092, lr_0 = 1.0200e-04
Loss = 4.4086e-04, PNorm = 38.5232, GNorm = 1.1064, lr_0 = 1.0200e-04
Loss = 5.2427e-04, PNorm = 38.5246, GNorm = 0.8216, lr_0 = 1.0200e-04
Loss = 3.8907e-04, PNorm = 38.5255, GNorm = 1.2376, lr_0 = 1.0200e-04
Loss = 5.2142e-04, PNorm = 38.5267, GNorm = 0.7133, lr_0 = 1.0200e-04
Loss = 5.3851e-04, PNorm = 38.5287, GNorm = 0.8073, lr_0 = 1.0200e-04
Loss = 4.9195e-04, PNorm = 38.5302, GNorm = 0.6428, lr_0 = 1.0200e-04
Loss = 6.4062e-04, PNorm = 38.5318, GNorm = 1.3804, lr_0 = 1.0200e-04
Loss = 4.1502e-04, PNorm = 38.5326, GNorm = 1.8355, lr_0 = 1.0200e-04
Loss = 5.6231e-04, PNorm = 38.5341, GNorm = 1.5846, lr_0 = 1.0200e-04
Loss = 4.7439e-04, PNorm = 38.5358, GNorm = 1.7382, lr_0 = 1.0200e-04
Loss = 4.7075e-04, PNorm = 38.5372, GNorm = 1.3963, lr_0 = 1.0200e-04
Loss = 5.2128e-04, PNorm = 38.5384, GNorm = 1.6025, lr_0 = 1.0200e-04
Loss = 4.8910e-04, PNorm = 38.5395, GNorm = 1.8393, lr_0 = 1.0200e-04
Loss = 4.6093e-04, PNorm = 38.5415, GNorm = 1.2006, lr_0 = 1.0200e-04
Loss = 5.0997e-04, PNorm = 38.5422, GNorm = 2.1901, lr_0 = 1.0200e-04
Loss = 6.1416e-04, PNorm = 38.5433, GNorm = 2.5677, lr_0 = 1.0200e-04
Loss = 5.5980e-04, PNorm = 38.5452, GNorm = 1.5887, lr_0 = 1.0200e-04
Loss = 5.1695e-04, PNorm = 38.5465, GNorm = 1.9589, lr_0 = 1.0200e-04
Loss = 6.4291e-04, PNorm = 38.5478, GNorm = 1.6310, lr_0 = 1.0200e-04
Validation rmse logD = 0.606814
Validation R2 logD = 0.731104
Validation rmse logP = 0.460841
Validation R2 logP = 0.938385
Epoch 76
Train function
Loss = 4.3145e-04, PNorm = 38.5488, GNorm = 1.0562, lr_0 = 1.0200e-04
Loss = 5.4282e-04, PNorm = 38.5504, GNorm = 2.0357, lr_0 = 1.0200e-04
Loss = 5.2976e-04, PNorm = 38.5522, GNorm = 0.8892, lr_0 = 1.0200e-04
Loss = 6.7355e-04, PNorm = 38.5537, GNorm = 4.7538, lr_0 = 1.0200e-04
Loss = 5.6626e-04, PNorm = 38.5554, GNorm = 1.2548, lr_0 = 1.0200e-04
Loss = 5.0452e-04, PNorm = 38.5570, GNorm = 2.4190, lr_0 = 1.0200e-04
Loss = 5.0636e-04, PNorm = 38.5582, GNorm = 0.8948, lr_0 = 1.0200e-04
Loss = 4.7682e-04, PNorm = 38.5592, GNorm = 1.5008, lr_0 = 1.0200e-04
Loss = 4.4246e-04, PNorm = 38.5609, GNorm = 0.8565, lr_0 = 1.0200e-04
Loss = 4.1426e-04, PNorm = 38.5626, GNorm = 2.0052, lr_0 = 1.0200e-04
Loss = 5.3865e-04, PNorm = 38.5634, GNorm = 1.4875, lr_0 = 1.0200e-04
Loss = 6.4270e-04, PNorm = 38.5643, GNorm = 2.1748, lr_0 = 1.0200e-04
Loss = 6.0815e-04, PNorm = 38.5647, GNorm = 2.7286, lr_0 = 1.0200e-04
Loss = 4.8021e-04, PNorm = 38.5662, GNorm = 0.9769, lr_0 = 1.0200e-04
Loss = 5.4303e-04, PNorm = 38.5677, GNorm = 0.9969, lr_0 = 1.0200e-04
Loss = 5.1797e-04, PNorm = 38.5696, GNorm = 3.1660, lr_0 = 1.0200e-04
Loss = 6.8076e-04, PNorm = 38.5722, GNorm = 1.8292, lr_0 = 1.0200e-04
Loss = 5.4098e-04, PNorm = 38.5735, GNorm = 1.2851, lr_0 = 1.0200e-04
Loss = 5.8682e-04, PNorm = 38.5754, GNorm = 2.9456, lr_0 = 1.0200e-04
Loss = 5.7836e-04, PNorm = 38.5769, GNorm = 2.7617, lr_0 = 1.0200e-04
Loss = 5.0281e-04, PNorm = 38.5781, GNorm = 1.6922, lr_0 = 1.0200e-04
Loss = 4.6501e-04, PNorm = 38.5791, GNorm = 1.6446, lr_0 = 1.0200e-04
Loss = 4.0805e-04, PNorm = 38.5805, GNorm = 0.6227, lr_0 = 1.0200e-04
Validation rmse logD = 0.594182
Validation R2 logD = 0.742183
Validation rmse logP = 0.468621
Validation R2 logP = 0.936287
Epoch 77
Train function
Loss = 4.9427e-04, PNorm = 38.5815, GNorm = 0.9360, lr_0 = 1.0200e-04
Loss = 5.0370e-04, PNorm = 38.5828, GNorm = 1.2274, lr_0 = 1.0200e-04
Loss = 4.5066e-04, PNorm = 38.5835, GNorm = 1.1515, lr_0 = 1.0200e-04
Loss = 3.8582e-04, PNorm = 38.5850, GNorm = 2.7540, lr_0 = 1.0200e-04
Loss = 4.7295e-04, PNorm = 38.5857, GNorm = 2.1387, lr_0 = 1.0200e-04
Loss = 4.1182e-04, PNorm = 38.5874, GNorm = 1.7393, lr_0 = 1.0200e-04
Loss = 6.3276e-04, PNorm = 38.5886, GNorm = 2.2008, lr_0 = 1.0200e-04
Loss = 6.0986e-04, PNorm = 38.5898, GNorm = 3.2619, lr_0 = 1.0200e-04
Loss = 6.4662e-04, PNorm = 38.5906, GNorm = 1.0088, lr_0 = 1.0200e-04
Loss = 5.8999e-04, PNorm = 38.5917, GNorm = 2.2285, lr_0 = 1.0200e-04
Loss = 5.0539e-04, PNorm = 38.5928, GNorm = 0.9701, lr_0 = 1.0200e-04
Loss = 5.3738e-04, PNorm = 38.5940, GNorm = 1.4090, lr_0 = 1.0200e-04
Loss = 5.1751e-04, PNorm = 38.5954, GNorm = 1.8586, lr_0 = 1.0200e-04
Loss = 4.3216e-04, PNorm = 38.5972, GNorm = 0.8648, lr_0 = 1.0200e-04
Loss = 5.0646e-04, PNorm = 38.5992, GNorm = 1.2200, lr_0 = 1.0200e-04
Loss = 4.8995e-04, PNorm = 38.5998, GNorm = 1.5166, lr_0 = 1.0200e-04
Loss = 5.5186e-04, PNorm = 38.6013, GNorm = 1.2353, lr_0 = 1.0200e-04
Loss = 6.1066e-04, PNorm = 38.6036, GNorm = 2.8730, lr_0 = 1.0200e-04
Loss = 6.0850e-04, PNorm = 38.6057, GNorm = 1.0522, lr_0 = 1.0200e-04
Loss = 6.3527e-04, PNorm = 38.6073, GNorm = 2.2107, lr_0 = 1.0200e-04
Loss = 6.4610e-04, PNorm = 38.6086, GNorm = 1.1446, lr_0 = 1.0200e-04
Loss = 5.9378e-04, PNorm = 38.6109, GNorm = 0.9601, lr_0 = 1.0200e-04
Validation rmse logD = 0.586286
Validation R2 logD = 0.748989
Validation rmse logP = 0.460827
Validation R2 logP = 0.938389
Epoch 78
Train function
Loss = 3.4755e-04, PNorm = 38.6116, GNorm = 1.9303, lr_0 = 1.0200e-04
Loss = 4.1008e-04, PNorm = 38.6130, GNorm = 0.8900, lr_0 = 1.0200e-04
Loss = 4.2679e-04, PNorm = 38.6144, GNorm = 1.7353, lr_0 = 1.0200e-04
Loss = 4.3888e-04, PNorm = 38.6158, GNorm = 0.9282, lr_0 = 1.0200e-04
Loss = 5.5214e-04, PNorm = 38.6167, GNorm = 1.2826, lr_0 = 1.0200e-04
Loss = 4.4774e-04, PNorm = 38.6185, GNorm = 3.2058, lr_0 = 1.0200e-04
Loss = 6.7552e-04, PNorm = 38.6194, GNorm = 2.0217, lr_0 = 1.0200e-04
Loss = 5.6059e-04, PNorm = 38.6203, GNorm = 1.2862, lr_0 = 1.0200e-04
Loss = 5.2988e-04, PNorm = 38.6215, GNorm = 2.2717, lr_0 = 1.0200e-04
Loss = 4.2095e-04, PNorm = 38.6237, GNorm = 1.8083, lr_0 = 1.0200e-04
Loss = 6.3218e-04, PNorm = 38.6253, GNorm = 1.4393, lr_0 = 1.0200e-04
Loss = 5.4802e-04, PNorm = 38.6269, GNorm = 3.1222, lr_0 = 1.0200e-04
Loss = 5.3537e-04, PNorm = 38.6286, GNorm = 0.9677, lr_0 = 1.0200e-04
Loss = 5.4591e-04, PNorm = 38.6302, GNorm = 1.4767, lr_0 = 1.0200e-04
Loss = 5.0457e-04, PNorm = 38.6321, GNorm = 1.6938, lr_0 = 1.0200e-04
Loss = 5.9897e-04, PNorm = 38.6338, GNorm = 3.1121, lr_0 = 1.0200e-04
Loss = 4.8645e-04, PNorm = 38.6349, GNorm = 1.5688, lr_0 = 1.0200e-04
Loss = 4.0804e-04, PNorm = 38.6364, GNorm = 0.7664, lr_0 = 1.0200e-04
Loss = 5.3908e-04, PNorm = 38.6383, GNorm = 1.8750, lr_0 = 1.0200e-04
Loss = 7.0312e-04, PNorm = 38.6397, GNorm = 5.2660, lr_0 = 1.0200e-04
Loss = 6.7533e-04, PNorm = 38.6400, GNorm = 1.2389, lr_0 = 1.0200e-04
Loss = 5.6144e-04, PNorm = 38.6413, GNorm = 1.9149, lr_0 = 1.0200e-04
Loss = 4.3807e-04, PNorm = 38.6426, GNorm = 1.1794, lr_0 = 1.0200e-04
Validation rmse logD = 0.593347
Validation R2 logD = 0.742906
Validation rmse logP = 0.458952
Validation R2 logP = 0.938889
Epoch 79
Train function
Loss = 4.5658e-04, PNorm = 38.6440, GNorm = 2.2469, lr_0 = 1.0200e-04
Loss = 4.5896e-04, PNorm = 38.6458, GNorm = 1.1670, lr_0 = 1.0200e-04
Loss = 5.5220e-04, PNorm = 38.6480, GNorm = 4.6041, lr_0 = 1.0200e-04
Loss = 7.4381e-04, PNorm = 38.6498, GNorm = 2.2970, lr_0 = 1.0200e-04
Loss = 5.6143e-04, PNorm = 38.6514, GNorm = 1.4167, lr_0 = 1.0200e-04
Loss = 4.6417e-04, PNorm = 38.6518, GNorm = 1.1766, lr_0 = 1.0200e-04
Loss = 6.0991e-04, PNorm = 38.6533, GNorm = 1.1659, lr_0 = 1.0200e-04
Loss = 5.0066e-04, PNorm = 38.6548, GNorm = 0.8190, lr_0 = 1.0200e-04
Loss = 4.3066e-04, PNorm = 38.6552, GNorm = 1.4669, lr_0 = 1.0200e-04
Loss = 4.5131e-04, PNorm = 38.6561, GNorm = 2.2122, lr_0 = 1.0200e-04
Loss = 5.0402e-04, PNorm = 38.6577, GNorm = 1.1392, lr_0 = 1.0200e-04
Loss = 4.7544e-04, PNorm = 38.6593, GNorm = 1.1503, lr_0 = 1.0200e-04
Loss = 4.4111e-04, PNorm = 38.6609, GNorm = 1.6133, lr_0 = 1.0200e-04
Loss = 4.6362e-04, PNorm = 38.6622, GNorm = 1.4140, lr_0 = 1.0200e-04
Loss = 5.5232e-04, PNorm = 38.6634, GNorm = 1.8142, lr_0 = 1.0200e-04
Loss = 4.5632e-04, PNorm = 38.6644, GNorm = 1.3239, lr_0 = 1.0200e-04
Loss = 4.4045e-04, PNorm = 38.6658, GNorm = 2.6087, lr_0 = 1.0200e-04
Loss = 5.4484e-04, PNorm = 38.6670, GNorm = 0.9495, lr_0 = 1.0200e-04
Loss = 4.8521e-04, PNorm = 38.6676, GNorm = 2.0517, lr_0 = 1.0200e-04
Loss = 4.5255e-04, PNorm = 38.6685, GNorm = 0.8311, lr_0 = 1.0200e-04
Loss = 4.3431e-04, PNorm = 38.6698, GNorm = 0.8096, lr_0 = 1.0200e-04
Loss = 4.2858e-04, PNorm = 38.6709, GNorm = 0.8484, lr_0 = 1.0200e-04
Validation rmse logD = 0.589872
Validation R2 logD = 0.745909
Validation rmse logP = 0.457994
Validation R2 logP = 0.939144
Epoch 80
Train function
Loss = 5.4260e-04, PNorm = 38.6720, GNorm = 2.8539, lr_0 = 1.0200e-04
Loss = 4.9835e-04, PNorm = 38.6728, GNorm = 1.0889, lr_0 = 1.0200e-04
Loss = 5.2490e-04, PNorm = 38.6732, GNorm = 3.4287, lr_0 = 1.0200e-04
Loss = 5.7131e-04, PNorm = 38.6750, GNorm = 2.6950, lr_0 = 1.0200e-04
Loss = 4.5665e-04, PNorm = 38.6769, GNorm = 0.7831, lr_0 = 1.0200e-04
Loss = 6.9415e-04, PNorm = 38.6784, GNorm = 1.7593, lr_0 = 1.0200e-04
Loss = 6.5125e-04, PNorm = 38.6810, GNorm = 1.1462, lr_0 = 1.0200e-04
Loss = 4.8002e-04, PNorm = 38.6833, GNorm = 2.7671, lr_0 = 1.0200e-04
Loss = 4.9504e-04, PNorm = 38.6855, GNorm = 1.4751, lr_0 = 1.0200e-04
Loss = 3.7866e-04, PNorm = 38.6865, GNorm = 1.2195, lr_0 = 1.0200e-04
Loss = 4.3103e-04, PNorm = 38.6879, GNorm = 0.9881, lr_0 = 1.0200e-04
Loss = 4.5265e-04, PNorm = 38.6892, GNorm = 4.2027, lr_0 = 1.0200e-04
Loss = 5.3791e-04, PNorm = 38.6906, GNorm = 1.7552, lr_0 = 1.0200e-04
Loss = 5.2143e-04, PNorm = 38.6917, GNorm = 1.3046, lr_0 = 1.0200e-04
Loss = 5.0690e-04, PNorm = 38.6935, GNorm = 1.5300, lr_0 = 1.0200e-04
Loss = 6.2722e-04, PNorm = 38.6947, GNorm = 3.0378, lr_0 = 1.0200e-04
Loss = 7.0036e-04, PNorm = 38.6950, GNorm = 1.2495, lr_0 = 1.0200e-04
Loss = 4.8687e-04, PNorm = 38.6962, GNorm = 2.6653, lr_0 = 1.0200e-04
Loss = 4.1474e-04, PNorm = 38.6978, GNorm = 1.0660, lr_0 = 1.0200e-04
Loss = 4.6099e-04, PNorm = 38.6994, GNorm = 1.7816, lr_0 = 1.0200e-04
Loss = 5.4961e-04, PNorm = 38.7014, GNorm = 2.3976, lr_0 = 1.0200e-04
Loss = 6.3854e-04, PNorm = 38.7026, GNorm = 2.2994, lr_0 = 1.0200e-04
Loss = 5.6472e-04, PNorm = 38.7032, GNorm = 2.8574, lr_0 = 1.0200e-04
Validation rmse logD = 0.595717
Validation R2 logD = 0.740848
Validation rmse logP = 0.460393
Validation R2 logP = 0.938505
Epoch 81
Train function
Loss = 4.0305e-04, PNorm = 38.7043, GNorm = 0.8989, lr_0 = 1.0200e-04
Loss = 4.5796e-04, PNorm = 38.7057, GNorm = 1.5597, lr_0 = 1.0200e-04
Loss = 4.0116e-04, PNorm = 38.7079, GNorm = 0.6113, lr_0 = 1.0200e-04
Loss = 3.4693e-04, PNorm = 38.7090, GNorm = 1.0311, lr_0 = 1.0200e-04
Loss = 3.8781e-04, PNorm = 38.7102, GNorm = 1.1234, lr_0 = 1.0200e-04
Loss = 3.5909e-04, PNorm = 38.7108, GNorm = 1.0578, lr_0 = 1.0200e-04
Loss = 3.6885e-04, PNorm = 38.7115, GNorm = 0.6374, lr_0 = 1.0200e-04
Loss = 5.3454e-04, PNorm = 38.7127, GNorm = 1.1807, lr_0 = 1.0200e-04
Loss = 5.0729e-04, PNorm = 38.7143, GNorm = 0.8603, lr_0 = 1.0200e-04
Loss = 5.2590e-04, PNorm = 38.7162, GNorm = 2.2118, lr_0 = 1.0200e-04
Loss = 4.4050e-04, PNorm = 38.7175, GNorm = 1.4585, lr_0 = 1.0200e-04
Loss = 5.7287e-04, PNorm = 38.7190, GNorm = 1.6812, lr_0 = 1.0200e-04
Loss = 4.5552e-04, PNorm = 38.7208, GNorm = 1.9576, lr_0 = 1.0200e-04
Loss = 4.0371e-04, PNorm = 38.7221, GNorm = 1.7760, lr_0 = 1.0200e-04
Loss = 4.4474e-04, PNorm = 38.7237, GNorm = 0.9815, lr_0 = 1.0200e-04
Loss = 4.1529e-04, PNorm = 38.7254, GNorm = 1.5870, lr_0 = 1.0200e-04
Loss = 4.2331e-04, PNorm = 38.7267, GNorm = 1.2073, lr_0 = 1.0200e-04
Loss = 4.2240e-04, PNorm = 38.7278, GNorm = 1.4698, lr_0 = 1.0200e-04
Loss = 6.0202e-04, PNorm = 38.7288, GNorm = 1.3214, lr_0 = 1.0200e-04
Loss = 3.7270e-04, PNorm = 38.7299, GNorm = 0.9009, lr_0 = 1.0200e-04
Loss = 4.2428e-04, PNorm = 38.7320, GNorm = 1.5540, lr_0 = 1.0200e-04
Loss = 4.2059e-04, PNorm = 38.7334, GNorm = 1.0544, lr_0 = 1.0200e-04
Validation rmse logD = 0.579896
Validation R2 logD = 0.754431
Validation rmse logP = 0.468363
Validation R2 logP = 0.936357
Epoch 82
Train function
Loss = 3.6205e-04, PNorm = 38.7345, GNorm = 1.8408, lr_0 = 1.0200e-04
Loss = 4.2888e-04, PNorm = 38.7357, GNorm = 1.0184, lr_0 = 1.0200e-04
Loss = 4.7891e-04, PNorm = 38.7369, GNorm = 2.3901, lr_0 = 1.0200e-04
Loss = 6.6701e-04, PNorm = 38.7382, GNorm = 2.2857, lr_0 = 1.0200e-04
Loss = 4.5568e-04, PNorm = 38.7398, GNorm = 1.1128, lr_0 = 1.0200e-04
Loss = 4.4134e-04, PNorm = 38.7414, GNorm = 0.8379, lr_0 = 1.0200e-04
Loss = 5.8864e-04, PNorm = 38.7425, GNorm = 3.0143, lr_0 = 1.0200e-04
Loss = 4.9977e-04, PNorm = 38.7439, GNorm = 2.1530, lr_0 = 1.0200e-04
Loss = 6.0060e-04, PNorm = 38.7451, GNorm = 1.3912, lr_0 = 1.0200e-04
Loss = 4.7856e-04, PNorm = 38.7465, GNorm = 2.1215, lr_0 = 1.0200e-04
Loss = 4.8412e-04, PNorm = 38.7472, GNorm = 1.3334, lr_0 = 1.0200e-04
Loss = 3.6721e-04, PNorm = 38.7487, GNorm = 1.0576, lr_0 = 1.0200e-04
Loss = 4.2612e-04, PNorm = 38.7507, GNorm = 0.7779, lr_0 = 1.0200e-04
Loss = 4.7090e-04, PNorm = 38.7527, GNorm = 1.5977, lr_0 = 1.0200e-04
Loss = 3.7109e-04, PNorm = 38.7543, GNorm = 1.0037, lr_0 = 1.0200e-04
Loss = 4.8739e-04, PNorm = 38.7562, GNorm = 1.0408, lr_0 = 1.0200e-04
Loss = 5.4558e-04, PNorm = 38.7578, GNorm = 3.0942, lr_0 = 1.0200e-04
Loss = 4.0378e-04, PNorm = 38.7595, GNorm = 1.0280, lr_0 = 1.0200e-04
Loss = 4.2822e-04, PNorm = 38.7608, GNorm = 1.0191, lr_0 = 1.0200e-04
Loss = 4.0957e-04, PNorm = 38.7618, GNorm = 1.5389, lr_0 = 1.0200e-04
Loss = 4.0989e-04, PNorm = 38.7633, GNorm = 1.8765, lr_0 = 1.0200e-04
Loss = 4.0191e-04, PNorm = 38.7645, GNorm = 1.1770, lr_0 = 1.0200e-04
Loss = 5.4122e-04, PNorm = 38.7649, GNorm = 2.6187, lr_0 = 1.0200e-04
Validation rmse logD = 0.602434
Validation R2 logD = 0.734971
Validation rmse logP = 0.454636
Validation R2 logP = 0.940033
Epoch 83
Train function
Loss = 6.0399e-04, PNorm = 38.7661, GNorm = 1.6644, lr_0 = 1.0200e-04
Loss = 3.9891e-04, PNorm = 38.7676, GNorm = 1.5285, lr_0 = 1.0200e-04
Loss = 4.5437e-04, PNorm = 38.7696, GNorm = 2.5310, lr_0 = 1.0200e-04
Loss = 5.6069e-04, PNorm = 38.7713, GNorm = 2.9764, lr_0 = 1.0200e-04
Loss = 6.1236e-04, PNorm = 38.7713, GNorm = 2.4179, lr_0 = 1.0200e-04
Loss = 5.5650e-04, PNorm = 38.7715, GNorm = 1.1000, lr_0 = 1.0200e-04
Loss = 4.8095e-04, PNorm = 38.7724, GNorm = 2.4920, lr_0 = 1.0200e-04
Loss = 5.4368e-04, PNorm = 38.7734, GNorm = 1.5282, lr_0 = 1.0200e-04
Loss = 4.8745e-04, PNorm = 38.7750, GNorm = 1.4579, lr_0 = 1.0200e-04
Loss = 3.7785e-04, PNorm = 38.7771, GNorm = 0.9590, lr_0 = 1.0200e-04
Loss = 3.6072e-04, PNorm = 38.7784, GNorm = 0.7209, lr_0 = 1.0200e-04
Loss = 3.7244e-04, PNorm = 38.7791, GNorm = 1.1283, lr_0 = 1.0200e-04
Loss = 4.1915e-04, PNorm = 38.7803, GNorm = 1.0396, lr_0 = 1.0200e-04
Loss = 4.5305e-04, PNorm = 38.7816, GNorm = 1.6427, lr_0 = 1.0200e-04
Loss = 5.0700e-04, PNorm = 38.7830, GNorm = 2.0359, lr_0 = 1.0200e-04
Loss = 5.2051e-04, PNorm = 38.7847, GNorm = 2.0158, lr_0 = 1.0200e-04
Loss = 4.6788e-04, PNorm = 38.7866, GNorm = 0.8744, lr_0 = 1.0200e-04
Loss = 3.7939e-04, PNorm = 38.7872, GNorm = 0.9713, lr_0 = 1.0200e-04
Loss = 4.2920e-04, PNorm = 38.7894, GNorm = 1.9458, lr_0 = 1.0200e-04
Loss = 4.7195e-04, PNorm = 38.7909, GNorm = 1.2105, lr_0 = 1.0200e-04
Loss = 5.0535e-04, PNorm = 38.7924, GNorm = 1.8844, lr_0 = 1.0200e-04
Loss = 4.6955e-04, PNorm = 38.7932, GNorm = 1.6284, lr_0 = 1.0200e-04
Loss = 4.1685e-04, PNorm = 38.7946, GNorm = 2.2297, lr_0 = 1.0200e-04
Validation rmse logD = 0.579542
Validation R2 logD = 0.754731
Validation rmse logP = 0.485210
Validation R2 logP = 0.931696
Epoch 84
Train function
Loss = 5.3798e-04, PNorm = 38.7942, GNorm = 4.6529, lr_0 = 1.0200e-04
Loss = 6.3732e-04, PNorm = 38.7954, GNorm = 3.7333, lr_0 = 1.0200e-04
Loss = 6.7806e-04, PNorm = 38.7974, GNorm = 2.5837, lr_0 = 1.0200e-04
Loss = 5.9140e-04, PNorm = 38.7987, GNorm = 1.7400, lr_0 = 1.0200e-04
Loss = 4.7541e-04, PNorm = 38.8005, GNorm = 2.1448, lr_0 = 1.0200e-04
Loss = 5.3897e-04, PNorm = 38.8018, GNorm = 1.9229, lr_0 = 1.0200e-04
Loss = 3.9374e-04, PNorm = 38.8035, GNorm = 0.8701, lr_0 = 1.0200e-04
Loss = 3.6935e-04, PNorm = 38.8054, GNorm = 2.0916, lr_0 = 1.0200e-04
Loss = 4.2483e-04, PNorm = 38.8070, GNorm = 1.5931, lr_0 = 1.0200e-04
Loss = 3.5875e-04, PNorm = 38.8082, GNorm = 0.9029, lr_0 = 1.0200e-04
Loss = 4.0035e-04, PNorm = 38.8092, GNorm = 0.9553, lr_0 = 1.0200e-04
Loss = 4.5521e-04, PNorm = 38.8108, GNorm = 3.6197, lr_0 = 1.0200e-04
Loss = 4.3016e-04, PNorm = 38.8132, GNorm = 1.2514, lr_0 = 1.0200e-04
Loss = 3.9934e-04, PNorm = 38.8146, GNorm = 2.2786, lr_0 = 1.0200e-04
Loss = 4.2703e-04, PNorm = 38.8155, GNorm = 0.8422, lr_0 = 1.0200e-04
Loss = 4.7759e-04, PNorm = 38.8165, GNorm = 1.1317, lr_0 = 1.0200e-04
Loss = 4.8678e-04, PNorm = 38.8178, GNorm = 1.7131, lr_0 = 1.0200e-04
Loss = 5.0581e-04, PNorm = 38.8192, GNorm = 2.4262, lr_0 = 1.0200e-04
Loss = 4.9654e-04, PNorm = 38.8204, GNorm = 1.4942, lr_0 = 1.0200e-04
Loss = 5.8774e-04, PNorm = 38.8220, GNorm = 1.6357, lr_0 = 1.0200e-04
Loss = 5.1449e-04, PNorm = 38.8229, GNorm = 1.7773, lr_0 = 1.0200e-04
Loss = 4.7273e-04, PNorm = 38.8240, GNorm = 0.8967, lr_0 = 1.0200e-04
Validation rmse logD = 0.593002
Validation R2 logD = 0.743206
Validation rmse logP = 0.460567
Validation R2 logP = 0.938458
Epoch 85
Train function
Loss = 3.4827e-04, PNorm = 38.8251, GNorm = 0.8040, lr_0 = 1.0200e-04
Loss = 4.4602e-04, PNorm = 38.8258, GNorm = 0.7748, lr_0 = 1.0200e-04
Loss = 4.3487e-04, PNorm = 38.8269, GNorm = 2.1674, lr_0 = 1.0200e-04
Loss = 4.3240e-04, PNorm = 38.8283, GNorm = 1.2839, lr_0 = 1.0200e-04
Loss = 3.4175e-04, PNorm = 38.8300, GNorm = 0.6040, lr_0 = 1.0200e-04
Loss = 5.3424e-04, PNorm = 38.8319, GNorm = 2.1667, lr_0 = 1.0200e-04
Loss = 5.0630e-04, PNorm = 38.8337, GNorm = 3.1783, lr_0 = 1.0200e-04
Loss = 3.9761e-04, PNorm = 38.8351, GNorm = 2.0561, lr_0 = 1.0200e-04
Loss = 4.1330e-04, PNorm = 38.8357, GNorm = 1.6095, lr_0 = 1.0200e-04
Loss = 4.5287e-04, PNorm = 38.8367, GNorm = 2.5452, lr_0 = 1.0200e-04
Loss = 4.9032e-04, PNorm = 38.8378, GNorm = 1.4102, lr_0 = 1.0200e-04
Loss = 6.4232e-04, PNorm = 38.8394, GNorm = 3.6941, lr_0 = 1.0200e-04
Loss = 5.4516e-04, PNorm = 38.8406, GNorm = 2.2832, lr_0 = 1.0200e-04
Loss = 4.3845e-04, PNorm = 38.8421, GNorm = 1.9683, lr_0 = 1.0200e-04
Loss = 5.5601e-04, PNorm = 38.8432, GNorm = 2.7886, lr_0 = 1.0200e-04
Loss = 5.0391e-04, PNorm = 38.8434, GNorm = 3.1437, lr_0 = 1.0200e-04
Loss = 5.0026e-04, PNorm = 38.8448, GNorm = 0.6113, lr_0 = 1.0200e-04
Loss = 4.3856e-04, PNorm = 38.8467, GNorm = 1.6318, lr_0 = 1.0200e-04
Loss = 4.8023e-04, PNorm = 38.8483, GNorm = 2.2139, lr_0 = 1.0200e-04
Loss = 3.9795e-04, PNorm = 38.8496, GNorm = 0.7802, lr_0 = 1.0200e-04
Loss = 5.5156e-04, PNorm = 38.8509, GNorm = 2.0552, lr_0 = 1.0200e-04
Loss = 3.3876e-04, PNorm = 38.8526, GNorm = 1.2242, lr_0 = 1.0200e-04
Loss = 4.3592e-04, PNorm = 38.8547, GNorm = 0.7794, lr_0 = 1.0200e-04
Validation rmse logD = 0.592658
Validation R2 logD = 0.743504
Validation rmse logP = 0.456954
Validation R2 logP = 0.939420
Epoch 86
Train function
Loss = 4.4635e-04, PNorm = 38.8567, GNorm = 1.7297, lr_0 = 1.0200e-04
Loss = 5.2471e-04, PNorm = 38.8576, GNorm = 1.7245, lr_0 = 1.0200e-04
Loss = 4.4728e-04, PNorm = 38.8591, GNorm = 3.2001, lr_0 = 1.0200e-04
Loss = 3.2997e-04, PNorm = 38.8599, GNorm = 1.9023, lr_0 = 1.0200e-04
Loss = 4.5002e-04, PNorm = 38.8615, GNorm = 1.5154, lr_0 = 1.0200e-04
Loss = 5.1585e-04, PNorm = 38.8638, GNorm = 1.6569, lr_0 = 1.0200e-04
Loss = 4.9804e-04, PNorm = 38.8656, GNorm = 1.4738, lr_0 = 1.0200e-04
Loss = 4.0713e-04, PNorm = 38.8665, GNorm = 1.9930, lr_0 = 1.0200e-04
Loss = 4.9676e-04, PNorm = 38.8672, GNorm = 2.4150, lr_0 = 1.0200e-04
Loss = 4.9917e-04, PNorm = 38.8676, GNorm = 1.4240, lr_0 = 1.0200e-04
Loss = 4.7998e-04, PNorm = 38.8686, GNorm = 1.2750, lr_0 = 1.0200e-04
Loss = 4.7245e-04, PNorm = 38.8694, GNorm = 1.9416, lr_0 = 1.0200e-04
Loss = 4.3024e-04, PNorm = 38.8711, GNorm = 0.8803, lr_0 = 1.0200e-04
Loss = 4.2205e-04, PNorm = 38.8719, GNorm = 0.9757, lr_0 = 1.0200e-04
Loss = 4.2195e-04, PNorm = 38.8725, GNorm = 1.8495, lr_0 = 1.0200e-04
Loss = 3.1788e-04, PNorm = 38.8728, GNorm = 0.5528, lr_0 = 1.0200e-04
Loss = 3.9540e-04, PNorm = 38.8735, GNorm = 1.3866, lr_0 = 1.0200e-04
Loss = 4.6031e-04, PNorm = 38.8751, GNorm = 0.5956, lr_0 = 1.0200e-04
Loss = 3.4942e-04, PNorm = 38.8766, GNorm = 1.0045, lr_0 = 1.0200e-04
Loss = 4.8290e-04, PNorm = 38.8781, GNorm = 0.9064, lr_0 = 1.0200e-04
Loss = 4.5607e-04, PNorm = 38.8807, GNorm = 0.7503, lr_0 = 1.0200e-04
Loss = 4.7559e-04, PNorm = 38.8822, GNorm = 0.8078, lr_0 = 1.0200e-04
Validation rmse logD = 0.590431
Validation R2 logD = 0.745427
Validation rmse logP = 0.476898
Validation R2 logP = 0.934016
Epoch 87
Train function
Loss = 4.4973e-04, PNorm = 38.8838, GNorm = 1.6698, lr_0 = 1.0200e-04
Loss = 3.3718e-04, PNorm = 38.8850, GNorm = 2.1438, lr_0 = 1.0200e-04
Loss = 3.8102e-04, PNorm = 38.8859, GNorm = 1.7792, lr_0 = 1.0200e-04
Loss = 5.0413e-04, PNorm = 38.8866, GNorm = 1.0646, lr_0 = 1.0200e-04
Loss = 4.6004e-04, PNorm = 38.8876, GNorm = 1.8980, lr_0 = 1.0200e-04
Loss = 4.9730e-04, PNorm = 38.8893, GNorm = 3.5052, lr_0 = 1.0200e-04
Loss = 4.5544e-04, PNorm = 38.8910, GNorm = 1.6174, lr_0 = 1.0200e-04
Loss = 5.4167e-04, PNorm = 38.8920, GNorm = 1.2725, lr_0 = 1.0200e-04
Loss = 3.9362e-04, PNorm = 38.8929, GNorm = 1.4105, lr_0 = 1.0200e-04
Loss = 3.5626e-04, PNorm = 38.8941, GNorm = 0.7300, lr_0 = 1.0200e-04
Loss = 3.7370e-04, PNorm = 38.8954, GNorm = 1.2206, lr_0 = 1.0200e-04
Loss = 5.7664e-04, PNorm = 38.8970, GNorm = 1.9787, lr_0 = 1.0200e-04
Loss = 5.0415e-04, PNorm = 38.8978, GNorm = 0.8553, lr_0 = 1.0200e-04
Loss = 4.2790e-04, PNorm = 38.8989, GNorm = 1.1107, lr_0 = 1.0200e-04
Loss = 3.6577e-04, PNorm = 38.8994, GNorm = 0.7947, lr_0 = 1.0200e-04
Loss = 3.4124e-04, PNorm = 38.9010, GNorm = 1.4792, lr_0 = 1.0200e-04
Loss = 3.3724e-04, PNorm = 38.9016, GNorm = 1.7893, lr_0 = 1.0200e-04
Loss = 4.3607e-04, PNorm = 38.9033, GNorm = 3.0166, lr_0 = 1.0200e-04
Loss = 6.8146e-04, PNorm = 38.9047, GNorm = 4.1158, lr_0 = 1.0200e-04
Loss = 5.1766e-04, PNorm = 38.9058, GNorm = 1.4151, lr_0 = 1.0200e-04
Loss = 5.8321e-04, PNorm = 38.9077, GNorm = 2.8103, lr_0 = 1.0200e-04
Loss = 4.1514e-04, PNorm = 38.9097, GNorm = 1.3584, lr_0 = 1.0200e-04
Loss = 4.1072e-04, PNorm = 38.9109, GNorm = 1.3646, lr_0 = 1.0200e-04
Validation rmse logD = 0.611470
Validation R2 logD = 0.726962
Validation rmse logP = 0.477011
Validation R2 logP = 0.933985
Epoch 88
Train function
Loss = 3.7250e-04, PNorm = 38.9119, GNorm = 1.9016, lr_0 = 1.0200e-04
Loss = 4.7688e-04, PNorm = 38.9131, GNorm = 2.5028, lr_0 = 1.0200e-04
Loss = 3.8109e-04, PNorm = 38.9146, GNorm = 1.1055, lr_0 = 1.0200e-04
Loss = 3.1542e-04, PNorm = 38.9156, GNorm = 0.6441, lr_0 = 1.0200e-04
Loss = 3.6855e-04, PNorm = 38.9164, GNorm = 2.0241, lr_0 = 1.0200e-04
Loss = 3.6223e-04, PNorm = 38.9171, GNorm = 1.0401, lr_0 = 1.0200e-04
Loss = 4.5551e-04, PNorm = 38.9180, GNorm = 1.8783, lr_0 = 1.0200e-04
Loss = 4.2203e-04, PNorm = 38.9199, GNorm = 1.8073, lr_0 = 1.0200e-04
Loss = 4.0124e-04, PNorm = 38.9211, GNorm = 3.4691, lr_0 = 1.0200e-04
Loss = 3.9751e-04, PNorm = 38.9217, GNorm = 1.0313, lr_0 = 1.0200e-04
Loss = 3.8188e-04, PNorm = 38.9222, GNorm = 1.1900, lr_0 = 1.0200e-04
Loss = 4.8350e-04, PNorm = 38.9235, GNorm = 1.4480, lr_0 = 1.0200e-04
Loss = 4.1237e-04, PNorm = 38.9243, GNorm = 0.9998, lr_0 = 1.0200e-04
Loss = 3.8132e-04, PNorm = 38.9256, GNorm = 1.3222, lr_0 = 1.0200e-04
Loss = 4.0608e-04, PNorm = 38.9261, GNorm = 1.5208, lr_0 = 1.0200e-04
Loss = 4.7888e-04, PNorm = 38.9272, GNorm = 1.3342, lr_0 = 1.0200e-04
Loss = 4.8648e-04, PNorm = 38.9287, GNorm = 1.3840, lr_0 = 1.0200e-04
Loss = 4.5458e-04, PNorm = 38.9291, GNorm = 0.7968, lr_0 = 1.0200e-04
Loss = 3.3606e-04, PNorm = 38.9301, GNorm = 1.5135, lr_0 = 1.0200e-04
Loss = 3.8439e-04, PNorm = 38.9317, GNorm = 1.5720, lr_0 = 1.0200e-04
Loss = 5.6383e-04, PNorm = 38.9335, GNorm = 1.7456, lr_0 = 1.0200e-04
Loss = 3.9532e-04, PNorm = 38.9352, GNorm = 2.2601, lr_0 = 1.0200e-04
Validation rmse logD = 0.588522
Validation R2 logD = 0.747071
Validation rmse logP = 0.461428
Validation R2 logP = 0.938228
Epoch 89
Train function
Loss = 3.2576e-04, PNorm = 38.9365, GNorm = 1.6328, lr_0 = 1.0200e-04
Loss = 3.4120e-04, PNorm = 38.9370, GNorm = 1.0289, lr_0 = 1.0200e-04
Loss = 3.6879e-04, PNorm = 38.9387, GNorm = 2.2767, lr_0 = 1.0200e-04
Loss = 3.3449e-04, PNorm = 38.9396, GNorm = 0.8859, lr_0 = 1.0200e-04
Loss = 3.9932e-04, PNorm = 38.9408, GNorm = 0.5640, lr_0 = 1.0200e-04
Loss = 4.5140e-04, PNorm = 38.9420, GNorm = 2.3094, lr_0 = 1.0200e-04
Loss = 4.9838e-04, PNorm = 38.9437, GNorm = 1.8301, lr_0 = 1.0200e-04
Loss = 3.7834e-04, PNorm = 38.9448, GNorm = 1.6082, lr_0 = 1.0200e-04
Loss = 5.0649e-04, PNorm = 38.9461, GNorm = 1.8206, lr_0 = 1.0200e-04
Loss = 4.1129e-04, PNorm = 38.9472, GNorm = 1.7538, lr_0 = 1.0200e-04
Loss = 3.6621e-04, PNorm = 38.9487, GNorm = 1.1473, lr_0 = 1.0200e-04
Loss = 4.7382e-04, PNorm = 38.9494, GNorm = 0.7334, lr_0 = 1.0200e-04
Loss = 3.9677e-04, PNorm = 38.9497, GNorm = 0.7622, lr_0 = 1.0200e-04
Loss = 4.4529e-04, PNorm = 38.9501, GNorm = 1.0001, lr_0 = 1.0200e-04
Loss = 4.1117e-04, PNorm = 38.9509, GNorm = 1.3897, lr_0 = 1.0200e-04
Loss = 3.9204e-04, PNorm = 38.9518, GNorm = 2.2749, lr_0 = 1.0200e-04
Loss = 3.8863e-04, PNorm = 38.9530, GNorm = 1.0985, lr_0 = 1.0200e-04
Loss = 4.6830e-04, PNorm = 38.9548, GNorm = 2.0975, lr_0 = 1.0200e-04
Loss = 5.6391e-04, PNorm = 38.9559, GNorm = 2.3219, lr_0 = 1.0200e-04
Loss = 4.1202e-04, PNorm = 38.9573, GNorm = 0.8089, lr_0 = 1.0200e-04
Loss = 5.1303e-04, PNorm = 38.9594, GNorm = 1.2260, lr_0 = 1.0200e-04
Loss = 4.2896e-04, PNorm = 38.9611, GNorm = 1.4948, lr_0 = 1.0200e-04
Loss = 4.4912e-04, PNorm = 38.9624, GNorm = 1.4083, lr_0 = 1.0200e-04
Validation rmse logD = 0.581555
Validation R2 logD = 0.753024
Validation rmse logP = 0.457674
Validation R2 logP = 0.939229
Epoch 90
Train function
Loss = 3.2126e-04, PNorm = 38.9635, GNorm = 0.8202, lr_0 = 1.0200e-04
Loss = 2.3185e-04, PNorm = 38.9647, GNorm = 0.4353, lr_0 = 1.0200e-04
Loss = 3.4374e-04, PNorm = 38.9652, GNorm = 0.8797, lr_0 = 1.0200e-04
Loss = 4.1631e-04, PNorm = 38.9661, GNorm = 1.1205, lr_0 = 1.0200e-04
Loss = 4.0054e-04, PNorm = 38.9671, GNorm = 1.5588, lr_0 = 1.0200e-04
Loss = 5.5914e-04, PNorm = 38.9682, GNorm = 3.8820, lr_0 = 1.0200e-04
Loss = 3.7745e-04, PNorm = 38.9696, GNorm = 2.0155, lr_0 = 1.0200e-04
Loss = 3.7143e-04, PNorm = 38.9713, GNorm = 2.4980, lr_0 = 1.0200e-04
Loss = 5.4588e-04, PNorm = 38.9735, GNorm = 2.6677, lr_0 = 1.0200e-04
Loss = 5.0692e-04, PNorm = 38.9760, GNorm = 3.8652, lr_0 = 1.0200e-04
Loss = 5.8143e-04, PNorm = 38.9776, GNorm = 3.5694, lr_0 = 1.0200e-04
Loss = 4.0906e-04, PNorm = 38.9782, GNorm = 1.5847, lr_0 = 1.0200e-04
Loss = 4.0116e-04, PNorm = 38.9794, GNorm = 0.8166, lr_0 = 1.0200e-04
Loss = 4.3058e-04, PNorm = 38.9808, GNorm = 2.4586, lr_0 = 1.0200e-04
Loss = 4.7260e-04, PNorm = 38.9816, GNorm = 1.3891, lr_0 = 1.0200e-04
Loss = 4.4320e-04, PNorm = 38.9827, GNorm = 1.2113, lr_0 = 1.0200e-04
Loss = 3.4929e-04, PNorm = 38.9844, GNorm = 0.7143, lr_0 = 1.0200e-04
Loss = 3.8475e-04, PNorm = 38.9855, GNorm = 0.8209, lr_0 = 1.0200e-04
Loss = 4.0253e-04, PNorm = 38.9876, GNorm = 1.8435, lr_0 = 1.0200e-04
Loss = 4.1910e-04, PNorm = 38.9893, GNorm = 0.9017, lr_0 = 1.0200e-04
Loss = 3.2784e-04, PNorm = 38.9906, GNorm = 0.8859, lr_0 = 1.0200e-04
Loss = 3.6419e-04, PNorm = 38.9924, GNorm = 1.5058, lr_0 = 1.0200e-04
Validation rmse logD = 0.583161
Validation R2 logD = 0.751658
Validation rmse logP = 0.457208
Validation R2 logP = 0.939353
Epoch 91
Train function
Loss = 4.3382e-04, PNorm = 38.9933, GNorm = 3.1266, lr_0 = 1.0200e-04
Loss = 2.7158e-04, PNorm = 38.9937, GNorm = 1.2473, lr_0 = 1.0200e-04
Loss = 2.8337e-04, PNorm = 38.9945, GNorm = 0.6816, lr_0 = 1.0200e-04
Loss = 3.4582e-04, PNorm = 38.9956, GNorm = 1.0281, lr_0 = 1.0200e-04
Loss = 4.1706e-04, PNorm = 38.9963, GNorm = 1.6517, lr_0 = 1.0200e-04
Loss = 3.5814e-04, PNorm = 38.9974, GNorm = 0.9090, lr_0 = 1.0200e-04
Loss = 3.6760e-04, PNorm = 38.9981, GNorm = 0.6518, lr_0 = 1.0200e-04
Loss = 4.7926e-04, PNorm = 38.9991, GNorm = 1.3106, lr_0 = 1.0200e-04
Loss = 5.4067e-04, PNorm = 39.0001, GNorm = 4.3932, lr_0 = 1.0200e-04
Loss = 5.2040e-04, PNorm = 39.0016, GNorm = 2.6175, lr_0 = 1.0200e-04
Loss = 5.5179e-04, PNorm = 39.0040, GNorm = 1.9230, lr_0 = 1.0200e-04
Loss = 5.3424e-04, PNorm = 39.0054, GNorm = 3.2535, lr_0 = 1.0200e-04
Loss = 5.7106e-04, PNorm = 39.0069, GNorm = 1.6814, lr_0 = 1.0200e-04
Loss = 4.1607e-04, PNorm = 39.0090, GNorm = 0.7262, lr_0 = 1.0200e-04
Loss = 4.4006e-04, PNorm = 39.0111, GNorm = 2.4565, lr_0 = 1.0200e-04
Loss = 4.4964e-04, PNorm = 39.0124, GNorm = 2.8579, lr_0 = 1.0200e-04
Loss = 5.1348e-04, PNorm = 39.0141, GNorm = 2.8627, lr_0 = 1.0200e-04
Loss = 4.4822e-04, PNorm = 39.0168, GNorm = 1.8366, lr_0 = 1.0200e-04
Loss = 4.2105e-04, PNorm = 39.0187, GNorm = 2.9046, lr_0 = 1.0200e-04
Loss = 4.8958e-04, PNorm = 39.0202, GNorm = 2.7449, lr_0 = 1.0200e-04
Loss = 3.6914e-04, PNorm = 39.0205, GNorm = 1.9118, lr_0 = 1.0200e-04
Loss = 3.7893e-04, PNorm = 39.0212, GNorm = 1.2586, lr_0 = 1.0200e-04
Loss = 3.6155e-04, PNorm = 39.0219, GNorm = 0.9803, lr_0 = 1.0200e-04
Validation rmse logD = 0.580867
Validation R2 logD = 0.753608
Validation rmse logP = 0.459331
Validation R2 logP = 0.938788
Epoch 92
Train function
Loss = 3.5816e-04, PNorm = 39.0234, GNorm = 2.9908, lr_0 = 1.0200e-04
Loss = 3.7733e-04, PNorm = 39.0250, GNorm = 1.7813, lr_0 = 1.0200e-04
Loss = 3.2025e-04, PNorm = 39.0267, GNorm = 1.5480, lr_0 = 1.0200e-04
Loss = 4.2843e-04, PNorm = 39.0281, GNorm = 1.2541, lr_0 = 1.0200e-04
Loss = 3.2429e-04, PNorm = 39.0292, GNorm = 1.5120, lr_0 = 1.0200e-04
Loss = 4.1050e-04, PNorm = 39.0304, GNorm = 2.1069, lr_0 = 1.0200e-04
Loss = 4.1607e-04, PNorm = 39.0307, GNorm = 0.9763, lr_0 = 1.0200e-04
Loss = 3.9570e-04, PNorm = 39.0315, GNorm = 0.7207, lr_0 = 1.0200e-04
Loss = 3.4187e-04, PNorm = 39.0333, GNorm = 1.2652, lr_0 = 1.0200e-04
Loss = 3.9612e-04, PNorm = 39.0348, GNorm = 1.4911, lr_0 = 1.0200e-04
Loss = 3.2556e-04, PNorm = 39.0369, GNorm = 2.0234, lr_0 = 1.0200e-04
Loss = 3.3680e-04, PNorm = 39.0383, GNorm = 1.0502, lr_0 = 1.0200e-04
Loss = 3.5305e-04, PNorm = 39.0392, GNorm = 1.2822, lr_0 = 1.0200e-04
Loss = 3.3742e-04, PNorm = 39.0394, GNorm = 1.9619, lr_0 = 1.0200e-04
Loss = 4.3349e-04, PNorm = 39.0405, GNorm = 2.0219, lr_0 = 1.0200e-04
Loss = 4.2073e-04, PNorm = 39.0409, GNorm = 1.2782, lr_0 = 1.0200e-04
Loss = 3.9830e-04, PNorm = 39.0419, GNorm = 1.9504, lr_0 = 1.0200e-04
Loss = 2.9360e-04, PNorm = 39.0424, GNorm = 1.4317, lr_0 = 1.0200e-04
Loss = 4.2659e-04, PNorm = 39.0430, GNorm = 2.4729, lr_0 = 1.0200e-04
Loss = 3.8051e-04, PNorm = 39.0441, GNorm = 1.0928, lr_0 = 1.0200e-04
Loss = 5.0012e-04, PNorm = 39.0457, GNorm = 2.1509, lr_0 = 1.0200e-04
Loss = 3.8470e-04, PNorm = 39.0474, GNorm = 1.8884, lr_0 = 1.0200e-04
Validation rmse logD = 0.582691
Validation R2 logD = 0.752058
Validation rmse logP = 0.483855
Validation R2 logP = 0.932077
Epoch 93
Train function
Loss = 4.2014e-04, PNorm = 39.0492, GNorm = 2.5373, lr_0 = 1.0200e-04
Loss = 4.0498e-04, PNorm = 39.0505, GNorm = 0.8436, lr_0 = 1.0200e-04
Loss = 3.8779e-04, PNorm = 39.0512, GNorm = 1.4428, lr_0 = 1.0200e-04
Loss = 3.3249e-04, PNorm = 39.0519, GNorm = 1.0256, lr_0 = 1.0200e-04
Loss = 3.7116e-04, PNorm = 39.0535, GNorm = 1.3385, lr_0 = 1.0200e-04
Loss = 3.4573e-04, PNorm = 39.0553, GNorm = 0.7910, lr_0 = 1.0200e-04
Loss = 4.0191e-04, PNorm = 39.0566, GNorm = 1.6896, lr_0 = 1.0200e-04
Loss = 3.0741e-04, PNorm = 39.0569, GNorm = 1.2978, lr_0 = 1.0200e-04
Loss = 3.6718e-04, PNorm = 39.0580, GNorm = 1.0491, lr_0 = 1.0200e-04
Loss = 3.4726e-04, PNorm = 39.0581, GNorm = 1.2696, lr_0 = 1.0200e-04
Loss = 3.5585e-04, PNorm = 39.0594, GNorm = 1.2874, lr_0 = 1.0200e-04
Loss = 3.4984e-04, PNorm = 39.0604, GNorm = 1.0364, lr_0 = 1.0200e-04
Loss = 3.1593e-04, PNorm = 39.0617, GNorm = 1.5878, lr_0 = 1.0200e-04
Loss = 3.6784e-04, PNorm = 39.0616, GNorm = 0.8021, lr_0 = 1.0200e-04
Loss = 3.5788e-04, PNorm = 39.0619, GNorm = 1.4108, lr_0 = 1.0200e-04
Loss = 4.3806e-04, PNorm = 39.0630, GNorm = 0.9013, lr_0 = 1.0200e-04
Loss = 3.6157e-04, PNorm = 39.0643, GNorm = 1.1233, lr_0 = 1.0200e-04
Loss = 3.6237e-04, PNorm = 39.0658, GNorm = 1.0275, lr_0 = 1.0200e-04
Loss = 3.8329e-04, PNorm = 39.0670, GNorm = 1.1209, lr_0 = 1.0200e-04
Loss = 3.1852e-04, PNorm = 39.0682, GNorm = 1.3446, lr_0 = 1.0200e-04
Loss = 3.2679e-04, PNorm = 39.0697, GNorm = 1.4933, lr_0 = 1.0200e-04
Loss = 3.0024e-04, PNorm = 39.0714, GNorm = 0.8302, lr_0 = 1.0200e-04
Loss = 3.2706e-04, PNorm = 39.0730, GNorm = 2.4152, lr_0 = 1.0200e-04
Validation rmse logD = 0.583412
Validation R2 logD = 0.751444
Validation rmse logP = 0.460027
Validation R2 logP = 0.938602
Epoch 94
Train function
Loss = 3.1190e-04, PNorm = 39.0742, GNorm = 1.3548, lr_0 = 1.0200e-04
Loss = 3.9353e-04, PNorm = 39.0750, GNorm = 1.8199, lr_0 = 1.0200e-04
Loss = 3.0067e-04, PNorm = 39.0763, GNorm = 0.6535, lr_0 = 1.0200e-04
Loss = 3.4474e-04, PNorm = 39.0772, GNorm = 1.1143, lr_0 = 1.0200e-04
Loss = 3.5144e-04, PNorm = 39.0783, GNorm = 2.6559, lr_0 = 1.0200e-04
Loss = 3.4531e-04, PNorm = 39.0791, GNorm = 2.1008, lr_0 = 1.0200e-04
Loss = 3.5339e-04, PNorm = 39.0799, GNorm = 1.0802, lr_0 = 1.0200e-04
Loss = 3.1597e-04, PNorm = 39.0813, GNorm = 0.6780, lr_0 = 1.0200e-04
Loss = 2.5171e-04, PNorm = 39.0824, GNorm = 1.2217, lr_0 = 1.0200e-04
Loss = 4.3408e-04, PNorm = 39.0838, GNorm = 1.5163, lr_0 = 1.0200e-04
Loss = 3.9614e-04, PNorm = 39.0862, GNorm = 1.5193, lr_0 = 1.0200e-04
Loss = 3.1193e-04, PNorm = 39.0871, GNorm = 2.5473, lr_0 = 1.0200e-04
Loss = 3.1108e-04, PNorm = 39.0883, GNorm = 0.9253, lr_0 = 1.0200e-04
Loss = 3.1391e-04, PNorm = 39.0890, GNorm = 2.3991, lr_0 = 1.0200e-04
Loss = 2.9711e-04, PNorm = 39.0902, GNorm = 1.4410, lr_0 = 1.0200e-04
Loss = 3.9080e-04, PNorm = 39.0910, GNorm = 1.1978, lr_0 = 1.0200e-04
Loss = 5.1655e-04, PNorm = 39.0922, GNorm = 1.6793, lr_0 = 1.0200e-04
Loss = 3.8835e-04, PNorm = 39.0934, GNorm = 2.6987, lr_0 = 1.0200e-04
Loss = 4.1303e-04, PNorm = 39.0951, GNorm = 1.3735, lr_0 = 1.0200e-04
Loss = 4.3898e-04, PNorm = 39.0959, GNorm = 0.5467, lr_0 = 1.0200e-04
Loss = 4.0159e-04, PNorm = 39.0968, GNorm = 0.9208, lr_0 = 1.0200e-04
Loss = 4.2389e-04, PNorm = 39.0977, GNorm = 1.6239, lr_0 = 1.0200e-04
Loss = 3.3842e-04, PNorm = 39.0984, GNorm = 1.8333, lr_0 = 1.0200e-04
Loss = 6.8702e-04, PNorm = 39.0984, GNorm = 1.2111, lr_0 = 1.0200e-04
Validation rmse logD = 0.580748
Validation R2 logD = 0.753708
Validation rmse logP = 0.465248
Validation R2 logP = 0.937201
Epoch 95
Train function
Loss = 4.4363e-04, PNorm = 39.0987, GNorm = 3.4824, lr_0 = 1.0200e-04
Loss = 3.8334e-04, PNorm = 39.1004, GNorm = 3.7637, lr_0 = 1.0200e-04
Loss = 3.5752e-04, PNorm = 39.1019, GNorm = 0.9778, lr_0 = 1.0200e-04
Loss = 3.7324e-04, PNorm = 39.1031, GNorm = 2.2259, lr_0 = 1.0200e-04
Loss = 2.7884e-04, PNorm = 39.1049, GNorm = 1.0873, lr_0 = 1.0200e-04
Loss = 3.8477e-04, PNorm = 39.1065, GNorm = 0.9435, lr_0 = 1.0200e-04
Loss = 2.9845e-04, PNorm = 39.1071, GNorm = 2.1155, lr_0 = 1.0200e-04
Loss = 3.1782e-04, PNorm = 39.1082, GNorm = 0.8117, lr_0 = 1.0200e-04
Loss = 3.1542e-04, PNorm = 39.1094, GNorm = 1.0371, lr_0 = 1.0200e-04
Loss = 3.8559e-04, PNorm = 39.1109, GNorm = 0.9310, lr_0 = 1.0200e-04
Loss = 4.0736e-04, PNorm = 39.1129, GNorm = 2.1982, lr_0 = 1.0200e-04
Loss = 3.8041e-04, PNorm = 39.1141, GNorm = 0.9939, lr_0 = 1.0200e-04
Loss = 3.3240e-04, PNorm = 39.1150, GNorm = 0.9924, lr_0 = 1.0200e-04
Loss = 3.5664e-04, PNorm = 39.1165, GNorm = 1.2136, lr_0 = 1.0200e-04
Loss = 4.6331e-04, PNorm = 39.1179, GNorm = 1.4456, lr_0 = 1.0200e-04
Loss = 3.2554e-04, PNorm = 39.1191, GNorm = 2.5503, lr_0 = 1.0200e-04
Loss = 3.1230e-04, PNorm = 39.1203, GNorm = 1.1770, lr_0 = 1.0200e-04
Loss = 3.7169e-04, PNorm = 39.1215, GNorm = 1.6414, lr_0 = 1.0200e-04
Loss = 3.6400e-04, PNorm = 39.1228, GNorm = 0.9965, lr_0 = 1.0200e-04
Loss = 4.4549e-04, PNorm = 39.1243, GNorm = 1.7749, lr_0 = 1.0200e-04
Loss = 4.4730e-04, PNorm = 39.1250, GNorm = 1.5299, lr_0 = 1.0200e-04
Loss = 4.6087e-04, PNorm = 39.1264, GNorm = 2.9521, lr_0 = 1.0200e-04
Validation rmse logD = 0.581462
Validation R2 logD = 0.753103
Validation rmse logP = 0.478929
Validation R2 logP = 0.933453
Epoch 96
Train function
Loss = 3.9678e-04, PNorm = 39.1281, GNorm = 1.1816, lr_0 = 1.0200e-04
Loss = 3.0799e-04, PNorm = 39.1296, GNorm = 2.6066, lr_0 = 1.0200e-04
Loss = 4.5485e-04, PNorm = 39.1310, GNorm = 2.6544, lr_0 = 1.0200e-04
Loss = 4.5487e-04, PNorm = 39.1316, GNorm = 1.7665, lr_0 = 1.0200e-04
Loss = 5.2940e-04, PNorm = 39.1326, GNorm = 1.1663, lr_0 = 1.0200e-04
Loss = 3.8597e-04, PNorm = 39.1336, GNorm = 1.2726, lr_0 = 1.0200e-04
Loss = 4.8719e-04, PNorm = 39.1345, GNorm = 1.2974, lr_0 = 1.0200e-04
Loss = 3.3660e-04, PNorm = 39.1357, GNorm = 1.0019, lr_0 = 1.0200e-04
Loss = 3.3153e-04, PNorm = 39.1359, GNorm = 1.1751, lr_0 = 1.0200e-04
Loss = 3.4198e-04, PNorm = 39.1367, GNorm = 0.9312, lr_0 = 1.0200e-04
Loss = 3.5540e-04, PNorm = 39.1393, GNorm = 0.7716, lr_0 = 1.0200e-04
Loss = 2.8501e-04, PNorm = 39.1411, GNorm = 0.8234, lr_0 = 1.0200e-04
Loss = 3.4244e-04, PNorm = 39.1420, GNorm = 1.5298, lr_0 = 1.0200e-04
Loss = 4.1681e-04, PNorm = 39.1428, GNorm = 1.3937, lr_0 = 1.0200e-04
Loss = 4.7050e-04, PNorm = 39.1444, GNorm = 1.0719, lr_0 = 1.0200e-04
Loss = 3.7999e-04, PNorm = 39.1457, GNorm = 0.7981, lr_0 = 1.0200e-04
Loss = 3.5252e-04, PNorm = 39.1472, GNorm = 1.5234, lr_0 = 1.0200e-04
Loss = 3.7220e-04, PNorm = 39.1481, GNorm = 0.8738, lr_0 = 1.0200e-04
Loss = 2.4143e-04, PNorm = 39.1493, GNorm = 1.1582, lr_0 = 1.0200e-04
Loss = 2.9601e-04, PNorm = 39.1502, GNorm = 1.4098, lr_0 = 1.0200e-04
Loss = 3.9192e-04, PNorm = 39.1509, GNorm = 2.3877, lr_0 = 1.0200e-04
Loss = 4.5206e-04, PNorm = 39.1526, GNorm = 1.2909, lr_0 = 1.0200e-04
Loss = 3.6276e-04, PNorm = 39.1544, GNorm = 1.2324, lr_0 = 1.0200e-04
Validation rmse logD = 0.588120
Validation R2 logD = 0.747416
Validation rmse logP = 0.457324
Validation R2 logP = 0.939322
Epoch 97
Train function
Loss = 3.9253e-04, PNorm = 39.1565, GNorm = 1.6397, lr_0 = 1.0200e-04
Loss = 4.1060e-04, PNorm = 39.1580, GNorm = 1.9830, lr_0 = 1.0200e-04
Loss = 4.3958e-04, PNorm = 39.1587, GNorm = 1.3574, lr_0 = 1.0200e-04
Loss = 3.5298e-04, PNorm = 39.1598, GNorm = 1.0113, lr_0 = 1.0200e-04
Loss = 3.2148e-04, PNorm = 39.1611, GNorm = 2.1249, lr_0 = 1.0200e-04
Loss = 3.4105e-04, PNorm = 39.1626, GNorm = 1.7021, lr_0 = 1.0200e-04
Loss = 3.2396e-04, PNorm = 39.1634, GNorm = 1.1124, lr_0 = 1.0200e-04
Loss = 5.9150e-04, PNorm = 39.1644, GNorm = 1.7163, lr_0 = 1.0200e-04
Loss = 4.8433e-04, PNorm = 39.1656, GNorm = 1.8000, lr_0 = 1.0200e-04
Loss = 3.8906e-04, PNorm = 39.1674, GNorm = 0.8962, lr_0 = 1.0200e-04
Loss = 2.8597e-04, PNorm = 39.1691, GNorm = 1.4323, lr_0 = 1.0200e-04
Loss = 3.8335e-04, PNorm = 39.1705, GNorm = 1.7326, lr_0 = 1.0200e-04
Loss = 3.9729e-04, PNorm = 39.1714, GNorm = 1.1585, lr_0 = 1.0200e-04
Loss = 3.4143e-04, PNorm = 39.1730, GNorm = 1.8213, lr_0 = 1.0200e-04
Loss = 3.6263e-04, PNorm = 39.1744, GNorm = 1.3844, lr_0 = 1.0200e-04
Loss = 4.1151e-04, PNorm = 39.1758, GNorm = 0.8118, lr_0 = 1.0200e-04
Loss = 2.7914e-04, PNorm = 39.1776, GNorm = 0.9508, lr_0 = 1.0200e-04
Loss = 3.2596e-04, PNorm = 39.1781, GNorm = 1.2437, lr_0 = 1.0200e-04
Loss = 3.3035e-04, PNorm = 39.1801, GNorm = 1.2846, lr_0 = 1.0200e-04
Loss = 3.1580e-04, PNorm = 39.1815, GNorm = 1.8478, lr_0 = 1.0200e-04
Loss = 3.4989e-04, PNorm = 39.1822, GNorm = 1.6780, lr_0 = 1.0200e-04
Loss = 3.8437e-04, PNorm = 39.1826, GNorm = 1.6347, lr_0 = 1.0200e-04
Validation rmse logD = 0.610524
Validation R2 logD = 0.727806
Validation rmse logP = 0.458003
Validation R2 logP = 0.939142
Epoch 98
Train function
Loss = 3.6177e-04, PNorm = 39.1835, GNorm = 0.7823, lr_0 = 1.0200e-04
Loss = 3.8715e-04, PNorm = 39.1843, GNorm = 0.8002, lr_0 = 1.0200e-04
Loss = 3.6023e-04, PNorm = 39.1860, GNorm = 1.7376, lr_0 = 1.0200e-04
Loss = 3.1611e-04, PNorm = 39.1872, GNorm = 1.4176, lr_0 = 1.0200e-04
Loss = 2.4422e-04, PNorm = 39.1881, GNorm = 1.6353, lr_0 = 1.0200e-04
Loss = 3.2424e-04, PNorm = 39.1894, GNorm = 1.4133, lr_0 = 1.0200e-04
Loss = 2.6742e-04, PNorm = 39.1907, GNorm = 0.7090, lr_0 = 1.0200e-04
Loss = 3.7781e-04, PNorm = 39.1911, GNorm = 1.6549, lr_0 = 1.0200e-04
Loss = 3.9347e-04, PNorm = 39.1920, GNorm = 1.0551, lr_0 = 1.0200e-04
Loss = 2.8991e-04, PNorm = 39.1928, GNorm = 1.0084, lr_0 = 1.0200e-04
Loss = 3.0578e-04, PNorm = 39.1941, GNorm = 0.6933, lr_0 = 1.0200e-04
Loss = 3.2548e-04, PNorm = 39.1954, GNorm = 1.2766, lr_0 = 1.0200e-04
Loss = 3.6995e-04, PNorm = 39.1969, GNorm = 0.8813, lr_0 = 1.0200e-04
Loss = 3.4442e-04, PNorm = 39.1981, GNorm = 1.0544, lr_0 = 1.0200e-04
Loss = 3.2714e-04, PNorm = 39.1990, GNorm = 1.1155, lr_0 = 1.0200e-04
Loss = 2.9904e-04, PNorm = 39.1998, GNorm = 0.7653, lr_0 = 1.0200e-04
Loss = 3.5630e-04, PNorm = 39.2006, GNorm = 0.9292, lr_0 = 1.0200e-04
Loss = 4.7648e-04, PNorm = 39.2019, GNorm = 1.9792, lr_0 = 1.0200e-04
Loss = 4.2919e-04, PNorm = 39.2023, GNorm = 3.3247, lr_0 = 1.0200e-04
Loss = 4.8150e-04, PNorm = 39.2026, GNorm = 3.2312, lr_0 = 1.0200e-04
Loss = 3.5124e-04, PNorm = 39.2034, GNorm = 1.3299, lr_0 = 1.0200e-04
Loss = 4.9010e-04, PNorm = 39.2037, GNorm = 1.4621, lr_0 = 1.0200e-04
Loss = 3.8044e-04, PNorm = 39.2053, GNorm = 1.0165, lr_0 = 1.0200e-04
Validation rmse logD = 0.586092
Validation R2 logD = 0.749155
Validation rmse logP = 0.457522
Validation R2 logP = 0.939269
Epoch 99
Train function
Loss = 5.4178e-04, PNorm = 39.2068, GNorm = 2.1484, lr_0 = 1.0200e-04
Loss = 3.0949e-04, PNorm = 39.2085, GNorm = 0.8806, lr_0 = 1.0200e-04
Loss = 3.6925e-04, PNorm = 39.2104, GNorm = 0.9796, lr_0 = 1.0200e-04
Loss = 3.2893e-04, PNorm = 39.2121, GNorm = 0.9343, lr_0 = 1.0200e-04
Loss = 3.1411e-04, PNorm = 39.2133, GNorm = 1.7891, lr_0 = 1.0200e-04
Loss = 3.0484e-04, PNorm = 39.2143, GNorm = 1.3437, lr_0 = 1.0200e-04
Loss = 3.1608e-04, PNorm = 39.2147, GNorm = 0.8298, lr_0 = 1.0200e-04
Loss = 2.7684e-04, PNorm = 39.2160, GNorm = 0.8896, lr_0 = 1.0200e-04
Loss = 3.7703e-04, PNorm = 39.2178, GNorm = 2.2330, lr_0 = 1.0200e-04
Loss = 3.0949e-04, PNorm = 39.2190, GNorm = 0.8428, lr_0 = 1.0200e-04
Loss = 2.9348e-04, PNorm = 39.2202, GNorm = 1.0920, lr_0 = 1.0200e-04
Loss = 3.0977e-04, PNorm = 39.2211, GNorm = 0.7810, lr_0 = 1.0200e-04
Loss = 3.2879e-04, PNorm = 39.2227, GNorm = 1.8861, lr_0 = 1.0200e-04
Loss = 3.6298e-04, PNorm = 39.2239, GNorm = 1.2646, lr_0 = 1.0200e-04
Loss = 3.3324e-04, PNorm = 39.2248, GNorm = 1.2095, lr_0 = 1.0200e-04
Loss = 2.9586e-04, PNorm = 39.2258, GNorm = 0.7245, lr_0 = 1.0200e-04
Loss = 3.1326e-04, PNorm = 39.2271, GNorm = 0.9646, lr_0 = 1.0200e-04
Loss = 3.7719e-04, PNorm = 39.2282, GNorm = 1.7839, lr_0 = 1.0200e-04
Loss = 5.2417e-04, PNorm = 39.2293, GNorm = 3.2419, lr_0 = 1.0200e-04
Loss = 4.0197e-04, PNorm = 39.2301, GNorm = 2.0568, lr_0 = 1.0200e-04
Loss = 3.6447e-04, PNorm = 39.2310, GNorm = 1.8641, lr_0 = 1.0200e-04
Loss = 3.3576e-04, PNorm = 39.2323, GNorm = 0.7169, lr_0 = 1.0200e-04
Validation rmse logD = 0.581873
Validation R2 logD = 0.752754
Validation rmse logP = 0.454109
Validation R2 logP = 0.940172
Model 0 best validation rmse = 0.517991 on epoch 99
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.575485
Model 0 test R2 logD = 0.789950
Model 0 test rmse logP = 0.455384
Model 0 test R2 logP = 0.940437
Ensemble test rmse  logD= 0.575485
Ensemble test R2  logD= 0.789950
Ensemble test rmse  logP= 0.455384
Ensemble test R2  logP= 0.940437
Fold 2
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_2',
 'save_smiles_splits': False,
 'seed': 2,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 2
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 2.3900e-02, PNorm = 35.0902, GNorm = 4.3217, lr_0 = 1.0200e-04
Loss = 1.7035e-02, PNorm = 35.0916, GNorm = 2.8586, lr_0 = 1.0200e-04
Loss = 1.5133e-02, PNorm = 35.0935, GNorm = 2.7271, lr_0 = 1.0200e-04
Loss = 1.5729e-02, PNorm = 35.0964, GNorm = 1.9733, lr_0 = 1.0200e-04
Loss = 1.2928e-02, PNorm = 35.0991, GNorm = 5.7954, lr_0 = 1.0200e-04
Loss = 1.1667e-02, PNorm = 35.1017, GNorm = 2.3242, lr_0 = 1.0200e-04
Loss = 1.1720e-02, PNorm = 35.1042, GNorm = 5.6869, lr_0 = 1.0200e-04
Loss = 1.2626e-02, PNorm = 35.1058, GNorm = 3.6281, lr_0 = 1.0200e-04
Loss = 1.1677e-02, PNorm = 35.1079, GNorm = 4.9211, lr_0 = 1.0200e-04
Loss = 9.4356e-03, PNorm = 35.1104, GNorm = 4.6593, lr_0 = 1.0200e-04
Loss = 7.9993e-03, PNorm = 35.1125, GNorm = 4.0156, lr_0 = 1.0200e-04
Loss = 9.3551e-03, PNorm = 35.1148, GNorm = 2.3908, lr_0 = 1.0200e-04
Loss = 9.2202e-03, PNorm = 35.1170, GNorm = 3.0878, lr_0 = 1.0200e-04
Loss = 9.0237e-03, PNorm = 35.1200, GNorm = 6.2175, lr_0 = 1.0200e-04
Loss = 7.1372e-03, PNorm = 35.1231, GNorm = 1.4326, lr_0 = 1.0200e-04
Loss = 7.9392e-03, PNorm = 35.1260, GNorm = 8.2677, lr_0 = 1.0200e-04
Loss = 1.0300e-02, PNorm = 35.1289, GNorm = 3.1096, lr_0 = 1.0200e-04
Loss = 8.1205e-03, PNorm = 35.1317, GNorm = 6.1868, lr_0 = 1.0200e-04
Loss = 8.4222e-03, PNorm = 35.1345, GNorm = 8.4961, lr_0 = 1.0200e-04
Loss = 7.7522e-03, PNorm = 35.1366, GNorm = 8.8080, lr_0 = 1.0200e-04
Loss = 6.8608e-03, PNorm = 35.1385, GNorm = 3.0032, lr_0 = 1.0200e-04
Loss = 7.3772e-03, PNorm = 35.1410, GNorm = 2.3826, lr_0 = 1.0200e-04
Validation rmse logD = 1.096928
Validation R2 logD = 0.148386
Validation rmse logP = 0.931962
Validation R2 logP = 0.745765
Epoch 1
Train function
Loss = 6.9320e-03, PNorm = 35.1452, GNorm = 5.9341, lr_0 = 1.0200e-04
Loss = 7.5387e-03, PNorm = 35.1483, GNorm = 6.0808, lr_0 = 1.0200e-04
Loss = 7.2780e-03, PNorm = 35.1505, GNorm = 2.1995, lr_0 = 1.0200e-04
Loss = 7.0762e-03, PNorm = 35.1537, GNorm = 5.3451, lr_0 = 1.0200e-04
Loss = 6.2828e-03, PNorm = 35.1570, GNorm = 1.3107, lr_0 = 1.0200e-04
Loss = 6.2787e-03, PNorm = 35.1601, GNorm = 2.9728, lr_0 = 1.0200e-04
Loss = 7.7998e-03, PNorm = 35.1620, GNorm = 6.7378, lr_0 = 1.0200e-04
Loss = 6.8088e-03, PNorm = 35.1644, GNorm = 1.8596, lr_0 = 1.0200e-04
Loss = 6.4084e-03, PNorm = 35.1668, GNorm = 1.7466, lr_0 = 1.0200e-04
Loss = 7.6800e-03, PNorm = 35.1696, GNorm = 4.1275, lr_0 = 1.0200e-04
Loss = 6.6541e-03, PNorm = 35.1723, GNorm = 11.1469, lr_0 = 1.0200e-04
Loss = 6.9234e-03, PNorm = 35.1754, GNorm = 3.1848, lr_0 = 1.0200e-04
Loss = 6.2579e-03, PNorm = 35.1784, GNorm = 2.0810, lr_0 = 1.0200e-04
Loss = 6.6747e-03, PNorm = 35.1810, GNorm = 4.0062, lr_0 = 1.0200e-04
Loss = 6.8974e-03, PNorm = 35.1833, GNorm = 5.9277, lr_0 = 1.0200e-04
Loss = 5.4246e-03, PNorm = 35.1861, GNorm = 5.9094, lr_0 = 1.0200e-04
Loss = 7.1872e-03, PNorm = 35.1897, GNorm = 4.2908, lr_0 = 1.0200e-04
Loss = 6.0899e-03, PNorm = 35.1924, GNorm = 5.9548, lr_0 = 1.0200e-04
Loss = 5.6526e-03, PNorm = 35.1944, GNorm = 7.2296, lr_0 = 1.0200e-04
Loss = 5.6199e-03, PNorm = 35.1964, GNorm = 3.3366, lr_0 = 1.0200e-04
Loss = 6.1396e-03, PNorm = 35.1990, GNorm = 3.7000, lr_0 = 1.0200e-04
Loss = 5.4193e-03, PNorm = 35.2020, GNorm = 9.2309, lr_0 = 1.0200e-04
Loss = 6.6606e-03, PNorm = 35.2046, GNorm = 3.8286, lr_0 = 1.0200e-04
Loss = 1.1642e-02, PNorm = 35.2048, GNorm = 6.5401, lr_0 = 1.0200e-04
Validation rmse logD = 0.947104
Validation R2 logD = 0.365134
Validation rmse logP = 0.796698
Validation R2 logP = 0.814208
Epoch 2
Train function
Loss = 5.9814e-03, PNorm = 35.2083, GNorm = 4.8467, lr_0 = 1.0200e-04
Loss = 5.9129e-03, PNorm = 35.2120, GNorm = 2.6081, lr_0 = 1.0200e-04
Loss = 5.6542e-03, PNorm = 35.2149, GNorm = 1.8141, lr_0 = 1.0200e-04
Loss = 6.0793e-03, PNorm = 35.2179, GNorm = 5.2443, lr_0 = 1.0200e-04
Loss = 5.8313e-03, PNorm = 35.2211, GNorm = 1.5221, lr_0 = 1.0200e-04
Loss = 5.2240e-03, PNorm = 35.2246, GNorm = 2.5647, lr_0 = 1.0200e-04
Loss = 6.1325e-03, PNorm = 35.2276, GNorm = 8.4399, lr_0 = 1.0200e-04
Loss = 4.9063e-03, PNorm = 35.2308, GNorm = 5.8341, lr_0 = 1.0200e-04
Loss = 4.6610e-03, PNorm = 35.2323, GNorm = 4.8243, lr_0 = 1.0200e-04
Loss = 5.8246e-03, PNorm = 35.2339, GNorm = 4.1904, lr_0 = 1.0200e-04
Loss = 5.4321e-03, PNorm = 35.2370, GNorm = 5.8756, lr_0 = 1.0200e-04
Loss = 5.3564e-03, PNorm = 35.2396, GNorm = 2.6938, lr_0 = 1.0200e-04
Loss = 5.8377e-03, PNorm = 35.2416, GNorm = 3.4948, lr_0 = 1.0200e-04
Loss = 4.5161e-03, PNorm = 35.2447, GNorm = 4.6771, lr_0 = 1.0200e-04
Loss = 5.5671e-03, PNorm = 35.2472, GNorm = 4.4889, lr_0 = 1.0200e-04
Loss = 4.7718e-03, PNorm = 35.2498, GNorm = 3.3517, lr_0 = 1.0200e-04
Loss = 5.8694e-03, PNorm = 35.2527, GNorm = 6.9707, lr_0 = 1.0200e-04
Loss = 4.8790e-03, PNorm = 35.2563, GNorm = 5.1115, lr_0 = 1.0200e-04
Loss = 4.6836e-03, PNorm = 35.2587, GNorm = 3.1320, lr_0 = 1.0200e-04
Loss = 4.9695e-03, PNorm = 35.2609, GNorm = 5.2932, lr_0 = 1.0200e-04
Loss = 5.2969e-03, PNorm = 35.2636, GNorm = 6.5433, lr_0 = 1.0200e-04
Loss = 5.4944e-03, PNorm = 35.2661, GNorm = 4.4671, lr_0 = 1.0200e-04
Validation rmse logD = 0.883279
Validation R2 logD = 0.447818
Validation rmse logP = 0.732692
Validation R2 logP = 0.842862
Epoch 3
Train function
Loss = 4.9681e-03, PNorm = 35.2687, GNorm = 1.9022, lr_0 = 1.0200e-04
Loss = 5.2103e-03, PNorm = 35.2707, GNorm = 1.9385, lr_0 = 1.0200e-04
Loss = 5.5954e-03, PNorm = 35.2737, GNorm = 4.6716, lr_0 = 1.0200e-04
Loss = 5.2174e-03, PNorm = 35.2773, GNorm = 2.2292, lr_0 = 1.0200e-04
Loss = 4.6498e-03, PNorm = 35.2804, GNorm = 2.9524, lr_0 = 1.0200e-04
Loss = 4.4128e-03, PNorm = 35.2838, GNorm = 8.4859, lr_0 = 1.0200e-04
Loss = 4.8875e-03, PNorm = 35.2865, GNorm = 6.1330, lr_0 = 1.0200e-04
Loss = 5.0803e-03, PNorm = 35.2895, GNorm = 8.5941, lr_0 = 1.0200e-04
Loss = 4.8729e-03, PNorm = 35.2933, GNorm = 4.4871, lr_0 = 1.0200e-04
Loss = 4.2606e-03, PNorm = 35.2963, GNorm = 3.9354, lr_0 = 1.0200e-04
Loss = 4.6372e-03, PNorm = 35.2990, GNorm = 2.8016, lr_0 = 1.0200e-04
Loss = 4.8673e-03, PNorm = 35.3026, GNorm = 2.8424, lr_0 = 1.0200e-04
Loss = 4.4476e-03, PNorm = 35.3047, GNorm = 4.5716, lr_0 = 1.0200e-04
Loss = 4.8388e-03, PNorm = 35.3071, GNorm = 6.3227, lr_0 = 1.0200e-04
Loss = 4.9266e-03, PNorm = 35.3094, GNorm = 3.0291, lr_0 = 1.0200e-04
Loss = 4.7198e-03, PNorm = 35.3114, GNorm = 2.6674, lr_0 = 1.0200e-04
Loss = 5.1670e-03, PNorm = 35.3138, GNorm = 5.6620, lr_0 = 1.0200e-04
Loss = 4.7321e-03, PNorm = 35.3157, GNorm = 9.8856, lr_0 = 1.0200e-04
Loss = 4.6749e-03, PNorm = 35.3180, GNorm = 4.5037, lr_0 = 1.0200e-04
Loss = 4.7221e-03, PNorm = 35.3199, GNorm = 7.3486, lr_0 = 1.0200e-04
Loss = 4.8939e-03, PNorm = 35.3222, GNorm = 1.4547, lr_0 = 1.0200e-04
Loss = 4.5778e-03, PNorm = 35.3246, GNorm = 2.3024, lr_0 = 1.0200e-04
Loss = 4.4598e-03, PNorm = 35.3283, GNorm = 2.2452, lr_0 = 1.0200e-04
Validation rmse logD = 0.849606
Validation R2 logD = 0.489117
Validation rmse logP = 0.730400
Validation R2 logP = 0.843843
Epoch 4
Train function
Loss = 5.0782e-03, PNorm = 35.3303, GNorm = 3.2461, lr_0 = 1.0200e-04
Loss = 4.8435e-03, PNorm = 35.3339, GNorm = 7.0188, lr_0 = 1.0200e-04
Loss = 3.8285e-03, PNorm = 35.3366, GNorm = 4.6723, lr_0 = 1.0200e-04
Loss = 4.4161e-03, PNorm = 35.3392, GNorm = 2.6377, lr_0 = 1.0200e-04
Loss = 4.1705e-03, PNorm = 35.3420, GNorm = 3.3191, lr_0 = 1.0200e-04
Loss = 4.3166e-03, PNorm = 35.3449, GNorm = 2.4015, lr_0 = 1.0200e-04
Loss = 4.4697e-03, PNorm = 35.3482, GNorm = 4.9537, lr_0 = 1.0200e-04
Loss = 4.8023e-03, PNorm = 35.3511, GNorm = 5.1305, lr_0 = 1.0200e-04
Loss = 3.7082e-03, PNorm = 35.3539, GNorm = 2.5709, lr_0 = 1.0200e-04
Loss = 3.6890e-03, PNorm = 35.3567, GNorm = 1.6764, lr_0 = 1.0200e-04
Loss = 3.8762e-03, PNorm = 35.3594, GNorm = 3.3605, lr_0 = 1.0200e-04
Loss = 4.2378e-03, PNorm = 35.3626, GNorm = 5.5191, lr_0 = 1.0200e-04
Loss = 4.6214e-03, PNorm = 35.3647, GNorm = 3.4214, lr_0 = 1.0200e-04
Loss = 4.6267e-03, PNorm = 35.3672, GNorm = 3.7714, lr_0 = 1.0200e-04
Loss = 4.7180e-03, PNorm = 35.3695, GNorm = 1.1651, lr_0 = 1.0200e-04
Loss = 4.2033e-03, PNorm = 35.3718, GNorm = 1.8290, lr_0 = 1.0200e-04
Loss = 4.4194e-03, PNorm = 35.3749, GNorm = 2.8958, lr_0 = 1.0200e-04
Loss = 4.8131e-03, PNorm = 35.3780, GNorm = 3.3601, lr_0 = 1.0200e-04
Loss = 4.7010e-03, PNorm = 35.3805, GNorm = 2.0575, lr_0 = 1.0200e-04
Loss = 4.7946e-03, PNorm = 35.3832, GNorm = 2.3244, lr_0 = 1.0200e-04
Loss = 4.0800e-03, PNorm = 35.3853, GNorm = 3.8980, lr_0 = 1.0200e-04
Loss = 4.6193e-03, PNorm = 35.3884, GNorm = 2.6130, lr_0 = 1.0200e-04
Validation rmse logD = 0.814893
Validation R2 logD = 0.530011
Validation rmse logP = 0.690016
Validation R2 logP = 0.860634
Epoch 5
Train function
Loss = 5.2865e-03, PNorm = 35.3912, GNorm = 6.4380, lr_0 = 1.0200e-04
Loss = 3.5801e-03, PNorm = 35.3941, GNorm = 6.1139, lr_0 = 1.0200e-04
Loss = 4.2910e-03, PNorm = 35.3974, GNorm = 1.9692, lr_0 = 1.0200e-04
Loss = 4.2927e-03, PNorm = 35.4001, GNorm = 3.1196, lr_0 = 1.0200e-04
Loss = 4.0761e-03, PNorm = 35.4030, GNorm = 7.9347, lr_0 = 1.0200e-04
Loss = 4.4654e-03, PNorm = 35.4051, GNorm = 3.7352, lr_0 = 1.0200e-04
Loss = 4.0229e-03, PNorm = 35.4075, GNorm = 1.7685, lr_0 = 1.0200e-04
Loss = 4.4444e-03, PNorm = 35.4106, GNorm = 3.9455, lr_0 = 1.0200e-04
Loss = 4.7487e-03, PNorm = 35.4133, GNorm = 4.5228, lr_0 = 1.0200e-04
Loss = 4.1227e-03, PNorm = 35.4164, GNorm = 5.8208, lr_0 = 1.0200e-04
Loss = 3.6315e-03, PNorm = 35.4200, GNorm = 2.0020, lr_0 = 1.0200e-04
Loss = 4.5905e-03, PNorm = 35.4232, GNorm = 8.2189, lr_0 = 1.0200e-04
Loss = 4.9818e-03, PNorm = 35.4257, GNorm = 2.0653, lr_0 = 1.0200e-04
Loss = 3.4623e-03, PNorm = 35.4285, GNorm = 6.9777, lr_0 = 1.0200e-04
Loss = 3.9241e-03, PNorm = 35.4307, GNorm = 3.9959, lr_0 = 1.0200e-04
Loss = 3.7864e-03, PNorm = 35.4340, GNorm = 2.8428, lr_0 = 1.0200e-04
Loss = 4.6302e-03, PNorm = 35.4368, GNorm = 4.5816, lr_0 = 1.0200e-04
Loss = 3.2631e-03, PNorm = 35.4394, GNorm = 4.9134, lr_0 = 1.0200e-04
Loss = 3.5554e-03, PNorm = 35.4419, GNorm = 1.6734, lr_0 = 1.0200e-04
Loss = 3.2846e-03, PNorm = 35.4441, GNorm = 1.9046, lr_0 = 1.0200e-04
Loss = 3.8635e-03, PNorm = 35.4463, GNorm = 5.5720, lr_0 = 1.0200e-04
Loss = 3.9647e-03, PNorm = 35.4489, GNorm = 3.8819, lr_0 = 1.0200e-04
Loss = 3.6711e-03, PNorm = 35.4517, GNorm = 2.2148, lr_0 = 1.0200e-04
Validation rmse logD = 0.810362
Validation R2 logD = 0.535223
Validation rmse logP = 0.640715
Validation R2 logP = 0.879837
Epoch 6
Train function
Loss = 4.1313e-03, PNorm = 35.4542, GNorm = 5.0283, lr_0 = 1.0200e-04
Loss = 3.8402e-03, PNorm = 35.4566, GNorm = 5.8783, lr_0 = 1.0200e-04
Loss = 3.8953e-03, PNorm = 35.4593, GNorm = 3.8370, lr_0 = 1.0200e-04
Loss = 4.2492e-03, PNorm = 35.4618, GNorm = 6.1366, lr_0 = 1.0200e-04
Loss = 3.5265e-03, PNorm = 35.4638, GNorm = 4.6296, lr_0 = 1.0200e-04
Loss = 3.5572e-03, PNorm = 35.4664, GNorm = 4.8564, lr_0 = 1.0200e-04
Loss = 2.9328e-03, PNorm = 35.4682, GNorm = 3.4347, lr_0 = 1.0200e-04
Loss = 3.7830e-03, PNorm = 35.4704, GNorm = 2.2504, lr_0 = 1.0200e-04
Loss = 4.2000e-03, PNorm = 35.4733, GNorm = 5.4604, lr_0 = 1.0200e-04
Loss = 3.1733e-03, PNorm = 35.4763, GNorm = 4.9892, lr_0 = 1.0200e-04
Loss = 3.9422e-03, PNorm = 35.4790, GNorm = 4.7436, lr_0 = 1.0200e-04
Loss = 4.0035e-03, PNorm = 35.4826, GNorm = 5.8253, lr_0 = 1.0200e-04
Loss = 4.1979e-03, PNorm = 35.4849, GNorm = 4.5778, lr_0 = 1.0200e-04
Loss = 3.9103e-03, PNorm = 35.4876, GNorm = 6.2170, lr_0 = 1.0200e-04
Loss = 3.5857e-03, PNorm = 35.4912, GNorm = 2.0451, lr_0 = 1.0200e-04
Loss = 3.9001e-03, PNorm = 35.4940, GNorm = 2.9592, lr_0 = 1.0200e-04
Loss = 3.6416e-03, PNorm = 35.4964, GNorm = 3.0202, lr_0 = 1.0200e-04
Loss = 4.0732e-03, PNorm = 35.4988, GNorm = 4.1299, lr_0 = 1.0200e-04
Loss = 2.9029e-03, PNorm = 35.5016, GNorm = 8.2973, lr_0 = 1.0200e-04
Loss = 3.4782e-03, PNorm = 35.5043, GNorm = 3.2501, lr_0 = 1.0200e-04
Loss = 4.2219e-03, PNorm = 35.5065, GNorm = 6.8305, lr_0 = 1.0200e-04
Loss = 4.1174e-03, PNorm = 35.5092, GNorm = 6.3972, lr_0 = 1.0200e-04
Validation rmse logD = 0.774873
Validation R2 logD = 0.575040
Validation rmse logP = 0.639121
Validation R2 logP = 0.880435
Epoch 7
Train function
Loss = 3.1852e-03, PNorm = 35.5123, GNorm = 4.8644, lr_0 = 1.0200e-04
Loss = 4.0214e-03, PNorm = 35.5155, GNorm = 6.2201, lr_0 = 1.0200e-04
Loss = 3.5602e-03, PNorm = 35.5191, GNorm = 2.9363, lr_0 = 1.0200e-04
Loss = 3.0251e-03, PNorm = 35.5222, GNorm = 2.9857, lr_0 = 1.0200e-04
Loss = 3.5744e-03, PNorm = 35.5244, GNorm = 2.9162, lr_0 = 1.0200e-04
Loss = 4.1022e-03, PNorm = 35.5271, GNorm = 6.5155, lr_0 = 1.0200e-04
Loss = 4.2688e-03, PNorm = 35.5299, GNorm = 2.7024, lr_0 = 1.0200e-04
Loss = 3.2790e-03, PNorm = 35.5328, GNorm = 2.3883, lr_0 = 1.0200e-04
Loss = 3.6184e-03, PNorm = 35.5350, GNorm = 3.1370, lr_0 = 1.0200e-04
Loss = 3.4425e-03, PNorm = 35.5372, GNorm = 7.9927, lr_0 = 1.0200e-04
Loss = 3.8098e-03, PNorm = 35.5389, GNorm = 4.0369, lr_0 = 1.0200e-04
Loss = 3.6105e-03, PNorm = 35.5419, GNorm = 5.7992, lr_0 = 1.0200e-04
Loss = 3.6944e-03, PNorm = 35.5452, GNorm = 1.4271, lr_0 = 1.0200e-04
Loss = 3.6885e-03, PNorm = 35.5479, GNorm = 2.2375, lr_0 = 1.0200e-04
Loss = 3.4422e-03, PNorm = 35.5512, GNorm = 1.6576, lr_0 = 1.0200e-04
Loss = 3.7390e-03, PNorm = 35.5547, GNorm = 2.0260, lr_0 = 1.0200e-04
Loss = 3.4993e-03, PNorm = 35.5581, GNorm = 5.7837, lr_0 = 1.0200e-04
Loss = 3.3528e-03, PNorm = 35.5604, GNorm = 10.0330, lr_0 = 1.0200e-04
Loss = 3.5135e-03, PNorm = 35.5636, GNorm = 3.2109, lr_0 = 1.0200e-04
Loss = 3.6779e-03, PNorm = 35.5665, GNorm = 2.3964, lr_0 = 1.0200e-04
Loss = 3.5776e-03, PNorm = 35.5689, GNorm = 1.9500, lr_0 = 1.0200e-04
Loss = 2.8347e-03, PNorm = 35.5714, GNorm = 1.4693, lr_0 = 1.0200e-04
Loss = 3.7287e-03, PNorm = 35.5728, GNorm = 5.5320, lr_0 = 1.0200e-04
Validation rmse logD = 0.754193
Validation R2 logD = 0.597420
Validation rmse logP = 0.612550
Validation R2 logP = 0.890170
Epoch 8
Train function
Loss = 2.9061e-03, PNorm = 35.5758, GNorm = 1.9639, lr_0 = 1.0200e-04
Loss = 3.3660e-03, PNorm = 35.5785, GNorm = 6.6578, lr_0 = 1.0200e-04
Loss = 3.8193e-03, PNorm = 35.5808, GNorm = 5.2391, lr_0 = 1.0200e-04
Loss = 3.5169e-03, PNorm = 35.5832, GNorm = 2.3847, lr_0 = 1.0200e-04
Loss = 3.6436e-03, PNorm = 35.5856, GNorm = 6.8604, lr_0 = 1.0200e-04
Loss = 3.1614e-03, PNorm = 35.5881, GNorm = 1.8301, lr_0 = 1.0200e-04
Loss = 3.2903e-03, PNorm = 35.5908, GNorm = 3.7012, lr_0 = 1.0200e-04
Loss = 3.9096e-03, PNorm = 35.5932, GNorm = 11.9006, lr_0 = 1.0200e-04
Loss = 3.3478e-03, PNorm = 35.5954, GNorm = 2.2364, lr_0 = 1.0200e-04
Loss = 3.0354e-03, PNorm = 35.5982, GNorm = 4.7630, lr_0 = 1.0200e-04
Loss = 3.2320e-03, PNorm = 35.6014, GNorm = 2.2098, lr_0 = 1.0200e-04
Loss = 3.4434e-03, PNorm = 35.6040, GNorm = 2.3981, lr_0 = 1.0200e-04
Loss = 3.4182e-03, PNorm = 35.6069, GNorm = 2.5674, lr_0 = 1.0200e-04
Loss = 2.8533e-03, PNorm = 35.6092, GNorm = 2.9098, lr_0 = 1.0200e-04
Loss = 3.8051e-03, PNorm = 35.6117, GNorm = 2.0073, lr_0 = 1.0200e-04
Loss = 2.8072e-03, PNorm = 35.6143, GNorm = 2.7241, lr_0 = 1.0200e-04
Loss = 3.8979e-03, PNorm = 35.6162, GNorm = 4.3188, lr_0 = 1.0200e-04
Loss = 3.7398e-03, PNorm = 35.6187, GNorm = 5.7772, lr_0 = 1.0200e-04
Loss = 3.5741e-03, PNorm = 35.6214, GNorm = 5.1913, lr_0 = 1.0200e-04
Loss = 2.6756e-03, PNorm = 35.6244, GNorm = 3.4797, lr_0 = 1.0200e-04
Loss = 3.8120e-03, PNorm = 35.6274, GNorm = 2.7559, lr_0 = 1.0200e-04
Loss = 3.2150e-03, PNorm = 35.6299, GNorm = 5.2833, lr_0 = 1.0200e-04
Validation rmse logD = 0.764128
Validation R2 logD = 0.586745
Validation rmse logP = 0.663694
Validation R2 logP = 0.871064
Epoch 9
Train function
Loss = 2.9839e-03, PNorm = 35.6326, GNorm = 3.8729, lr_0 = 1.0200e-04
Loss = 3.5790e-03, PNorm = 35.6354, GNorm = 5.8554, lr_0 = 1.0200e-04
Loss = 2.8968e-03, PNorm = 35.6382, GNorm = 5.3660, lr_0 = 1.0200e-04
Loss = 3.6444e-03, PNorm = 35.6411, GNorm = 3.6948, lr_0 = 1.0200e-04
Loss = 2.8696e-03, PNorm = 35.6435, GNorm = 1.4714, lr_0 = 1.0200e-04
Loss = 3.0571e-03, PNorm = 35.6458, GNorm = 4.1448, lr_0 = 1.0200e-04
Loss = 3.2536e-03, PNorm = 35.6488, GNorm = 1.4674, lr_0 = 1.0200e-04
Loss = 3.0104e-03, PNorm = 35.6518, GNorm = 2.0364, lr_0 = 1.0200e-04
Loss = 3.6551e-03, PNorm = 35.6554, GNorm = 3.6645, lr_0 = 1.0200e-04
Loss = 2.7517e-03, PNorm = 35.6579, GNorm = 2.6147, lr_0 = 1.0200e-04
Loss = 3.6735e-03, PNorm = 35.6597, GNorm = 6.0687, lr_0 = 1.0200e-04
Loss = 3.0685e-03, PNorm = 35.6623, GNorm = 3.6561, lr_0 = 1.0200e-04
Loss = 3.4231e-03, PNorm = 35.6655, GNorm = 3.5966, lr_0 = 1.0200e-04
Loss = 3.3070e-03, PNorm = 35.6682, GNorm = 2.4095, lr_0 = 1.0200e-04
Loss = 3.5738e-03, PNorm = 35.6706, GNorm = 6.4834, lr_0 = 1.0200e-04
Loss = 2.8752e-03, PNorm = 35.6734, GNorm = 4.4175, lr_0 = 1.0200e-04
Loss = 3.4226e-03, PNorm = 35.6770, GNorm = 3.6582, lr_0 = 1.0200e-04
Loss = 3.0315e-03, PNorm = 35.6792, GNorm = 1.4327, lr_0 = 1.0200e-04
Loss = 3.1715e-03, PNorm = 35.6816, GNorm = 5.6286, lr_0 = 1.0200e-04
Loss = 3.3059e-03, PNorm = 35.6837, GNorm = 3.3232, lr_0 = 1.0200e-04
Loss = 3.0566e-03, PNorm = 35.6867, GNorm = 2.4177, lr_0 = 1.0200e-04
Loss = 3.0099e-03, PNorm = 35.6892, GNorm = 5.5174, lr_0 = 1.0200e-04
Loss = 2.6595e-03, PNorm = 35.6917, GNorm = 4.8678, lr_0 = 1.0200e-04
Validation rmse logD = 0.730751
Validation R2 logD = 0.622058
Validation rmse logP = 0.593361
Validation R2 logP = 0.896943
Epoch 10
Train function
Loss = 2.5270e-03, PNorm = 35.6940, GNorm = 1.8672, lr_0 = 1.0200e-04
Loss = 2.8831e-03, PNorm = 35.6963, GNorm = 3.2390, lr_0 = 1.0200e-04
Loss = 2.7672e-03, PNorm = 35.6989, GNorm = 2.3157, lr_0 = 1.0200e-04
Loss = 3.6036e-03, PNorm = 35.7014, GNorm = 6.5674, lr_0 = 1.0200e-04
Loss = 3.0279e-03, PNorm = 35.7042, GNorm = 7.1038, lr_0 = 1.0200e-04
Loss = 3.5150e-03, PNorm = 35.7068, GNorm = 2.7619, lr_0 = 1.0200e-04
Loss = 3.0153e-03, PNorm = 35.7096, GNorm = 4.7808, lr_0 = 1.0200e-04
Loss = 3.6463e-03, PNorm = 35.7117, GNorm = 5.1930, lr_0 = 1.0200e-04
Loss = 3.4983e-03, PNorm = 35.7146, GNorm = 2.4802, lr_0 = 1.0200e-04
Loss = 3.2414e-03, PNorm = 35.7170, GNorm = 5.2372, lr_0 = 1.0200e-04
Loss = 3.1359e-03, PNorm = 35.7194, GNorm = 1.6536, lr_0 = 1.0200e-04
Loss = 3.2166e-03, PNorm = 35.7223, GNorm = 3.1125, lr_0 = 1.0200e-04
Loss = 2.7467e-03, PNorm = 35.7258, GNorm = 3.4489, lr_0 = 1.0200e-04
Loss = 2.6695e-03, PNorm = 35.7282, GNorm = 4.1435, lr_0 = 1.0200e-04
Loss = 3.2106e-03, PNorm = 35.7306, GNorm = 5.5723, lr_0 = 1.0200e-04
Loss = 3.0930e-03, PNorm = 35.7328, GNorm = 2.1638, lr_0 = 1.0200e-04
Loss = 2.7811e-03, PNorm = 35.7366, GNorm = 3.6218, lr_0 = 1.0200e-04
Loss = 2.3565e-03, PNorm = 35.7401, GNorm = 1.5655, lr_0 = 1.0200e-04
Loss = 3.4571e-03, PNorm = 35.7429, GNorm = 2.7028, lr_0 = 1.0200e-04
Loss = 3.2857e-03, PNorm = 35.7449, GNorm = 2.0742, lr_0 = 1.0200e-04
Loss = 3.2266e-03, PNorm = 35.7471, GNorm = 4.0985, lr_0 = 1.0200e-04
Loss = 3.0987e-03, PNorm = 35.7496, GNorm = 5.7553, lr_0 = 1.0200e-04
Loss = 3.2345e-03, PNorm = 35.7517, GNorm = 5.1123, lr_0 = 1.0200e-04
Validation rmse logD = 0.765295
Validation R2 logD = 0.585481
Validation rmse logP = 0.612462
Validation R2 logP = 0.890201
Epoch 11
Train function
Loss = 3.1610e-03, PNorm = 35.7542, GNorm = 8.3012, lr_0 = 1.0200e-04
Loss = 3.5171e-03, PNorm = 35.7571, GNorm = 7.4757, lr_0 = 1.0200e-04
Loss = 3.6486e-03, PNorm = 35.7601, GNorm = 6.6024, lr_0 = 1.0200e-04
Loss = 2.8879e-03, PNorm = 35.7625, GNorm = 2.5263, lr_0 = 1.0200e-04
Loss = 3.7468e-03, PNorm = 35.7650, GNorm = 1.7959, lr_0 = 1.0200e-04
Loss = 2.7932e-03, PNorm = 35.7677, GNorm = 2.3900, lr_0 = 1.0200e-04
Loss = 3.3224e-03, PNorm = 35.7705, GNorm = 5.3490, lr_0 = 1.0200e-04
Loss = 2.9635e-03, PNorm = 35.7728, GNorm = 6.8234, lr_0 = 1.0200e-04
Loss = 2.6656e-03, PNorm = 35.7754, GNorm = 3.6243, lr_0 = 1.0200e-04
Loss = 2.4071e-03, PNorm = 35.7779, GNorm = 1.2320, lr_0 = 1.0200e-04
Loss = 2.2380e-03, PNorm = 35.7806, GNorm = 1.6184, lr_0 = 1.0200e-04
Loss = 3.1982e-03, PNorm = 35.7838, GNorm = 1.1364, lr_0 = 1.0200e-04
Loss = 2.3872e-03, PNorm = 35.7866, GNorm = 2.7210, lr_0 = 1.0200e-04
Loss = 3.4422e-03, PNorm = 35.7883, GNorm = 4.8279, lr_0 = 1.0200e-04
Loss = 2.6645e-03, PNorm = 35.7899, GNorm = 2.4393, lr_0 = 1.0200e-04
Loss = 2.7994e-03, PNorm = 35.7922, GNorm = 1.7613, lr_0 = 1.0200e-04
Loss = 2.9552e-03, PNorm = 35.7951, GNorm = 2.5935, lr_0 = 1.0200e-04
Loss = 2.8541e-03, PNorm = 35.7988, GNorm = 4.1184, lr_0 = 1.0200e-04
Loss = 2.6339e-03, PNorm = 35.8026, GNorm = 2.0005, lr_0 = 1.0200e-04
Loss = 3.6456e-03, PNorm = 35.8048, GNorm = 6.7520, lr_0 = 1.0200e-04
Loss = 3.3533e-03, PNorm = 35.8069, GNorm = 4.5185, lr_0 = 1.0200e-04
Loss = 3.1308e-03, PNorm = 35.8085, GNorm = 5.9729, lr_0 = 1.0200e-04
Validation rmse logD = 0.712893
Validation R2 logD = 0.640304
Validation rmse logP = 0.633388
Validation R2 logP = 0.882570
Epoch 12
Train function
Loss = 2.6693e-03, PNorm = 35.8113, GNorm = 3.1498, lr_0 = 1.0200e-04
Loss = 2.9729e-03, PNorm = 35.8146, GNorm = 5.4207, lr_0 = 1.0200e-04
Loss = 2.6798e-03, PNorm = 35.8174, GNorm = 2.2140, lr_0 = 1.0200e-04
Loss = 2.8198e-03, PNorm = 35.8205, GNorm = 2.7531, lr_0 = 1.0200e-04
Loss = 2.5778e-03, PNorm = 35.8223, GNorm = 3.2784, lr_0 = 1.0200e-04
Loss = 2.6791e-03, PNorm = 35.8246, GNorm = 4.6540, lr_0 = 1.0200e-04
Loss = 2.9188e-03, PNorm = 35.8268, GNorm = 7.3036, lr_0 = 1.0200e-04
Loss = 3.0441e-03, PNorm = 35.8303, GNorm = 9.1798, lr_0 = 1.0200e-04
Loss = 2.3485e-03, PNorm = 35.8322, GNorm = 5.1806, lr_0 = 1.0200e-04
Loss = 4.1982e-03, PNorm = 35.8340, GNorm = 1.2689, lr_0 = 1.0200e-04
Loss = 3.0311e-03, PNorm = 35.8367, GNorm = 1.9220, lr_0 = 1.0200e-04
Loss = 2.8885e-03, PNorm = 35.8384, GNorm = 3.6409, lr_0 = 1.0200e-04
Loss = 2.7259e-03, PNorm = 35.8413, GNorm = 3.6206, lr_0 = 1.0200e-04
Loss = 3.0286e-03, PNorm = 35.8440, GNorm = 4.8129, lr_0 = 1.0200e-04
Loss = 2.9315e-03, PNorm = 35.8467, GNorm = 3.2783, lr_0 = 1.0200e-04
Loss = 2.6061e-03, PNorm = 35.8498, GNorm = 5.8275, lr_0 = 1.0200e-04
Loss = 2.8547e-03, PNorm = 35.8524, GNorm = 1.3813, lr_0 = 1.0200e-04
Loss = 2.4182e-03, PNorm = 35.8550, GNorm = 7.9265, lr_0 = 1.0200e-04
Loss = 2.4161e-03, PNorm = 35.8569, GNorm = 3.4030, lr_0 = 1.0200e-04
Loss = 2.8589e-03, PNorm = 35.8599, GNorm = 4.7690, lr_0 = 1.0200e-04
Loss = 2.2127e-03, PNorm = 35.8623, GNorm = 3.8716, lr_0 = 1.0200e-04
Loss = 2.4708e-03, PNorm = 35.8644, GNorm = 4.6405, lr_0 = 1.0200e-04
Loss = 2.8868e-03, PNorm = 35.8673, GNorm = 2.8507, lr_0 = 1.0200e-04
Validation rmse logD = 0.702879
Validation R2 logD = 0.650338
Validation rmse logP = 0.582978
Validation R2 logP = 0.900518
Epoch 13
Train function
Loss = 2.5763e-03, PNorm = 35.8702, GNorm = 1.8104, lr_0 = 1.0200e-04
Loss = 2.6454e-03, PNorm = 35.8727, GNorm = 7.5220, lr_0 = 1.0200e-04
Loss = 2.3654e-03, PNorm = 35.8754, GNorm = 7.4756, lr_0 = 1.0200e-04
Loss = 2.9222e-03, PNorm = 35.8773, GNorm = 9.3302, lr_0 = 1.0200e-04
Loss = 3.7653e-03, PNorm = 35.8798, GNorm = 8.8542, lr_0 = 1.0200e-04
Loss = 3.0174e-03, PNorm = 35.8821, GNorm = 8.5319, lr_0 = 1.0200e-04
Loss = 2.9056e-03, PNorm = 35.8853, GNorm = 4.6176, lr_0 = 1.0200e-04
Loss = 2.1674e-03, PNorm = 35.8882, GNorm = 2.8656, lr_0 = 1.0200e-04
Loss = 4.4839e-03, PNorm = 35.8921, GNorm = 2.5898, lr_0 = 1.0200e-04
Loss = 3.0613e-03, PNorm = 35.8953, GNorm = 6.0890, lr_0 = 1.0200e-04
Loss = 2.1581e-03, PNorm = 35.8979, GNorm = 2.9497, lr_0 = 1.0200e-04
Loss = 2.4568e-03, PNorm = 35.9004, GNorm = 2.3753, lr_0 = 1.0200e-04
Loss = 2.6039e-03, PNorm = 35.9030, GNorm = 4.4560, lr_0 = 1.0200e-04
Loss = 2.0850e-03, PNorm = 35.9057, GNorm = 3.7746, lr_0 = 1.0200e-04
Loss = 2.9308e-03, PNorm = 35.9083, GNorm = 3.1394, lr_0 = 1.0200e-04
Loss = 2.8833e-03, PNorm = 35.9107, GNorm = 3.9044, lr_0 = 1.0200e-04
Loss = 2.0231e-03, PNorm = 35.9125, GNorm = 2.3954, lr_0 = 1.0200e-04
Loss = 2.7866e-03, PNorm = 35.9152, GNorm = 3.1985, lr_0 = 1.0200e-04
Loss = 2.5780e-03, PNorm = 35.9178, GNorm = 2.2141, lr_0 = 1.0200e-04
Loss = 2.5369e-03, PNorm = 35.9194, GNorm = 0.8148, lr_0 = 1.0200e-04
Loss = 2.5455e-03, PNorm = 35.9222, GNorm = 4.3252, lr_0 = 1.0200e-04
Loss = 2.6485e-03, PNorm = 35.9243, GNorm = 1.7787, lr_0 = 1.0200e-04
Validation rmse logD = 0.704018
Validation R2 logD = 0.649205
Validation rmse logP = 0.617412
Validation R2 logP = 0.888420
Epoch 14
Train function
Loss = 2.5786e-03, PNorm = 35.9269, GNorm = 3.7153, lr_0 = 1.0200e-04
Loss = 2.7825e-03, PNorm = 35.9293, GNorm = 5.2339, lr_0 = 1.0200e-04
Loss = 2.2369e-03, PNorm = 35.9313, GNorm = 1.3746, lr_0 = 1.0200e-04
Loss = 2.4652e-03, PNorm = 35.9339, GNorm = 3.2886, lr_0 = 1.0200e-04
Loss = 2.7293e-03, PNorm = 35.9372, GNorm = 3.1393, lr_0 = 1.0200e-04
Loss = 1.9848e-03, PNorm = 35.9399, GNorm = 2.7328, lr_0 = 1.0200e-04
Loss = 2.3121e-03, PNorm = 35.9431, GNorm = 1.6491, lr_0 = 1.0200e-04
Loss = 2.5444e-03, PNorm = 35.9459, GNorm = 3.4475, lr_0 = 1.0200e-04
Loss = 3.1652e-03, PNorm = 35.9479, GNorm = 2.9038, lr_0 = 1.0200e-04
Loss = 2.2696e-03, PNorm = 35.9502, GNorm = 2.5251, lr_0 = 1.0200e-04
Loss = 2.2178e-03, PNorm = 35.9524, GNorm = 1.9009, lr_0 = 1.0200e-04
Loss = 2.6682e-03, PNorm = 35.9545, GNorm = 1.6276, lr_0 = 1.0200e-04
Loss = 2.7031e-03, PNorm = 35.9576, GNorm = 3.3933, lr_0 = 1.0200e-04
Loss = 3.6010e-03, PNorm = 35.9605, GNorm = 4.3635, lr_0 = 1.0200e-04
Loss = 2.1772e-03, PNorm = 35.9635, GNorm = 3.6255, lr_0 = 1.0200e-04
Loss = 2.5333e-03, PNorm = 35.9653, GNorm = 3.9528, lr_0 = 1.0200e-04
Loss = 2.2678e-03, PNorm = 35.9668, GNorm = 4.7102, lr_0 = 1.0200e-04
Loss = 2.5491e-03, PNorm = 35.9692, GNorm = 2.6027, lr_0 = 1.0200e-04
Loss = 2.2779e-03, PNorm = 35.9720, GNorm = 3.0791, lr_0 = 1.0200e-04
Loss = 2.5197e-03, PNorm = 35.9738, GNorm = 2.1029, lr_0 = 1.0200e-04
Loss = 2.3660e-03, PNorm = 35.9753, GNorm = 1.6261, lr_0 = 1.0200e-04
Loss = 3.0493e-03, PNorm = 35.9767, GNorm = 2.1544, lr_0 = 1.0200e-04
Loss = 2.9948e-03, PNorm = 35.9800, GNorm = 5.6544, lr_0 = 1.0200e-04
Validation rmse logD = 0.759281
Validation R2 logD = 0.591971
Validation rmse logP = 0.561393
Validation R2 logP = 0.907749
Epoch 15
Train function
Loss = 2.7039e-03, PNorm = 35.9832, GNorm = 5.8933, lr_0 = 1.0200e-04
Loss = 2.4052e-03, PNorm = 35.9859, GNorm = 4.4597, lr_0 = 1.0200e-04
Loss = 2.8290e-03, PNorm = 35.9880, GNorm = 2.4235, lr_0 = 1.0200e-04
Loss = 2.8277e-03, PNorm = 35.9912, GNorm = 3.7518, lr_0 = 1.0200e-04
Loss = 2.6070e-03, PNorm = 35.9943, GNorm = 2.9982, lr_0 = 1.0200e-04
Loss = 2.4569e-03, PNorm = 35.9965, GNorm = 2.9718, lr_0 = 1.0200e-04
Loss = 2.4158e-03, PNorm = 35.9983, GNorm = 3.6006, lr_0 = 1.0200e-04
Loss = 2.4990e-03, PNorm = 36.0000, GNorm = 5.2022, lr_0 = 1.0200e-04
Loss = 2.9502e-03, PNorm = 36.0026, GNorm = 4.9478, lr_0 = 1.0200e-04
Loss = 2.4090e-03, PNorm = 36.0047, GNorm = 3.7083, lr_0 = 1.0200e-04
Loss = 2.4884e-03, PNorm = 36.0078, GNorm = 2.6402, lr_0 = 1.0200e-04
Loss = 2.3273e-03, PNorm = 36.0108, GNorm = 3.1693, lr_0 = 1.0200e-04
Loss = 2.2261e-03, PNorm = 36.0139, GNorm = 3.5087, lr_0 = 1.0200e-04
Loss = 2.5498e-03, PNorm = 36.0167, GNorm = 1.9714, lr_0 = 1.0200e-04
Loss = 2.6907e-03, PNorm = 36.0184, GNorm = 2.0373, lr_0 = 1.0200e-04
Loss = 2.6888e-03, PNorm = 36.0205, GNorm = 5.9156, lr_0 = 1.0200e-04
Loss = 2.2994e-03, PNorm = 36.0234, GNorm = 4.3886, lr_0 = 1.0200e-04
Loss = 2.4439e-03, PNorm = 36.0261, GNorm = 1.9520, lr_0 = 1.0200e-04
Loss = 2.4061e-03, PNorm = 36.0289, GNorm = 1.5887, lr_0 = 1.0200e-04
Loss = 2.4880e-03, PNorm = 36.0307, GNorm = 3.1010, lr_0 = 1.0200e-04
Loss = 2.8210e-03, PNorm = 36.0323, GNorm = 2.5069, lr_0 = 1.0200e-04
Loss = 2.1818e-03, PNorm = 36.0348, GNorm = 2.3825, lr_0 = 1.0200e-04
Validation rmse logD = 0.692043
Validation R2 logD = 0.661037
Validation rmse logP = 0.549754
Validation R2 logP = 0.911534
Epoch 16
Train function
Loss = 2.8872e-03, PNorm = 36.0372, GNorm = 3.4269, lr_0 = 1.0200e-04
Loss = 2.4015e-03, PNorm = 36.0407, GNorm = 3.4054, lr_0 = 1.0200e-04
Loss = 2.3038e-03, PNorm = 36.0429, GNorm = 3.9051, lr_0 = 1.0200e-04
Loss = 2.4349e-03, PNorm = 36.0455, GNorm = 2.2443, lr_0 = 1.0200e-04
Loss = 2.0215e-03, PNorm = 36.0481, GNorm = 3.2227, lr_0 = 1.0200e-04
Loss = 1.9754e-03, PNorm = 36.0505, GNorm = 2.5077, lr_0 = 1.0200e-04
Loss = 2.7833e-03, PNorm = 36.0531, GNorm = 5.4468, lr_0 = 1.0200e-04
Loss = 2.3887e-03, PNorm = 36.0560, GNorm = 1.5375, lr_0 = 1.0200e-04
Loss = 2.5134e-03, PNorm = 36.0587, GNorm = 2.6683, lr_0 = 1.0200e-04
Loss = 2.4879e-03, PNorm = 36.0606, GNorm = 4.8389, lr_0 = 1.0200e-04
Loss = 2.2769e-03, PNorm = 36.0625, GNorm = 1.8284, lr_0 = 1.0200e-04
Loss = 2.4025e-03, PNorm = 36.0652, GNorm = 2.2375, lr_0 = 1.0200e-04
Loss = 2.1749e-03, PNorm = 36.0675, GNorm = 1.2068, lr_0 = 1.0200e-04
Loss = 2.2044e-03, PNorm = 36.0693, GNorm = 1.9875, lr_0 = 1.0200e-04
Loss = 2.0981e-03, PNorm = 36.0710, GNorm = 2.0776, lr_0 = 1.0200e-04
Loss = 2.8273e-03, PNorm = 36.0732, GNorm = 3.2203, lr_0 = 1.0200e-04
Loss = 2.4257e-03, PNorm = 36.0750, GNorm = 2.3349, lr_0 = 1.0200e-04
Loss = 1.9922e-03, PNorm = 36.0778, GNorm = 4.5499, lr_0 = 1.0200e-04
Loss = 2.4241e-03, PNorm = 36.0806, GNorm = 3.7677, lr_0 = 1.0200e-04
Loss = 2.7746e-03, PNorm = 36.0837, GNorm = 4.4485, lr_0 = 1.0200e-04
Loss = 2.9657e-03, PNorm = 36.0871, GNorm = 3.1043, lr_0 = 1.0200e-04
Loss = 2.3267e-03, PNorm = 36.0905, GNorm = 2.4913, lr_0 = 1.0200e-04
Loss = 2.4938e-03, PNorm = 36.0936, GNorm = 1.8591, lr_0 = 1.0200e-04
Validation rmse logD = 0.759323
Validation R2 logD = 0.591925
Validation rmse logP = 0.547921
Validation R2 logP = 0.912123
Epoch 17
Train function
Loss = 2.4877e-03, PNorm = 36.0960, GNorm = 2.5692, lr_0 = 1.0200e-04
Loss = 2.0277e-03, PNorm = 36.0986, GNorm = 6.9310, lr_0 = 1.0200e-04
Loss = 2.3286e-03, PNorm = 36.1013, GNorm = 2.0196, lr_0 = 1.0200e-04
Loss = 2.3279e-03, PNorm = 36.1047, GNorm = 5.2524, lr_0 = 1.0200e-04
Loss = 2.5858e-03, PNorm = 36.1072, GNorm = 6.2505, lr_0 = 1.0200e-04
Loss = 2.8952e-03, PNorm = 36.1100, GNorm = 5.4815, lr_0 = 1.0200e-04
Loss = 1.9328e-03, PNorm = 36.1118, GNorm = 2.2844, lr_0 = 1.0200e-04
Loss = 2.4857e-03, PNorm = 36.1145, GNorm = 1.9799, lr_0 = 1.0200e-04
Loss = 2.5004e-03, PNorm = 36.1164, GNorm = 2.0199, lr_0 = 1.0200e-04
Loss = 2.0699e-03, PNorm = 36.1190, GNorm = 1.8336, lr_0 = 1.0200e-04
Loss = 2.5199e-03, PNorm = 36.1218, GNorm = 2.2666, lr_0 = 1.0200e-04
Loss = 1.8024e-03, PNorm = 36.1243, GNorm = 2.8604, lr_0 = 1.0200e-04
Loss = 2.8983e-03, PNorm = 36.1271, GNorm = 5.5456, lr_0 = 1.0200e-04
Loss = 2.3071e-03, PNorm = 36.1291, GNorm = 6.0504, lr_0 = 1.0200e-04
Loss = 2.2848e-03, PNorm = 36.1315, GNorm = 4.5131, lr_0 = 1.0200e-04
Loss = 2.0942e-03, PNorm = 36.1345, GNorm = 2.3259, lr_0 = 1.0200e-04
Loss = 2.0925e-03, PNorm = 36.1367, GNorm = 3.0449, lr_0 = 1.0200e-04
Loss = 1.9863e-03, PNorm = 36.1390, GNorm = 2.7334, lr_0 = 1.0200e-04
Loss = 2.4260e-03, PNorm = 36.1416, GNorm = 4.3223, lr_0 = 1.0200e-04
Loss = 2.4309e-03, PNorm = 36.1438, GNorm = 4.7627, lr_0 = 1.0200e-04
Loss = 2.4387e-03, PNorm = 36.1452, GNorm = 2.0740, lr_0 = 1.0200e-04
Loss = 2.7100e-03, PNorm = 36.1468, GNorm = 2.5023, lr_0 = 1.0200e-04
Validation rmse logD = 0.643973
Validation R2 logD = 0.706491
Validation rmse logP = 0.569894
Validation R2 logP = 0.904933
Epoch 18
Train function
Loss = 2.4032e-03, PNorm = 36.1491, GNorm = 2.4756, lr_0 = 1.0200e-04
Loss = 2.3399e-03, PNorm = 36.1515, GNorm = 3.6386, lr_0 = 1.0200e-04
Loss = 2.0303e-03, PNorm = 36.1543, GNorm = 3.9539, lr_0 = 1.0200e-04
Loss = 1.7928e-03, PNorm = 36.1572, GNorm = 2.1747, lr_0 = 1.0200e-04
Loss = 2.2260e-03, PNorm = 36.1596, GNorm = 2.3724, lr_0 = 1.0200e-04
Loss = 1.8242e-03, PNorm = 36.1617, GNorm = 2.0438, lr_0 = 1.0200e-04
Loss = 2.3639e-03, PNorm = 36.1633, GNorm = 2.7063, lr_0 = 1.0200e-04
Loss = 1.8510e-03, PNorm = 36.1663, GNorm = 1.5754, lr_0 = 1.0200e-04
Loss = 2.4417e-03, PNorm = 36.1693, GNorm = 3.7092, lr_0 = 1.0200e-04
Loss = 2.7749e-03, PNorm = 36.1719, GNorm = 6.0451, lr_0 = 1.0200e-04
Loss = 2.6387e-03, PNorm = 36.1742, GNorm = 2.4014, lr_0 = 1.0200e-04
Loss = 2.3334e-03, PNorm = 36.1773, GNorm = 3.1904, lr_0 = 1.0200e-04
Loss = 2.4691e-03, PNorm = 36.1802, GNorm = 2.4156, lr_0 = 1.0200e-04
Loss = 1.8236e-03, PNorm = 36.1822, GNorm = 1.0642, lr_0 = 1.0200e-04
Loss = 2.2554e-03, PNorm = 36.1844, GNorm = 2.0050, lr_0 = 1.0200e-04
Loss = 1.9183e-03, PNorm = 36.1870, GNorm = 1.2779, lr_0 = 1.0200e-04
Loss = 2.0870e-03, PNorm = 36.1887, GNorm = 1.9071, lr_0 = 1.0200e-04
Loss = 2.2963e-03, PNorm = 36.1899, GNorm = 1.3667, lr_0 = 1.0200e-04
Loss = 2.6911e-03, PNorm = 36.1921, GNorm = 6.7377, lr_0 = 1.0200e-04
Loss = 2.5849e-03, PNorm = 36.1940, GNorm = 1.8644, lr_0 = 1.0200e-04
Loss = 2.2291e-03, PNorm = 36.1961, GNorm = 6.3061, lr_0 = 1.0200e-04
Loss = 2.0901e-03, PNorm = 36.1987, GNorm = 2.6564, lr_0 = 1.0200e-04
Loss = 2.4070e-03, PNorm = 36.2017, GNorm = 8.9036, lr_0 = 1.0200e-04
Validation rmse logD = 0.734790
Validation R2 logD = 0.617868
Validation rmse logP = 0.601176
Validation R2 logP = 0.894211
Epoch 19
Train function
Loss = 1.9813e-03, PNorm = 36.2051, GNorm = 3.5789, lr_0 = 1.0200e-04
Loss = 2.1937e-03, PNorm = 36.2071, GNorm = 7.9811, lr_0 = 1.0200e-04
Loss = 2.0817e-03, PNorm = 36.2096, GNorm = 2.4047, lr_0 = 1.0200e-04
Loss = 2.4873e-03, PNorm = 36.2126, GNorm = 2.6546, lr_0 = 1.0200e-04
Loss = 2.1935e-03, PNorm = 36.2155, GNorm = 2.9650, lr_0 = 1.0200e-04
Loss = 2.3519e-03, PNorm = 36.2180, GNorm = 2.7884, lr_0 = 1.0200e-04
Loss = 2.1766e-03, PNorm = 36.2207, GNorm = 2.5446, lr_0 = 1.0200e-04
Loss = 2.0711e-03, PNorm = 36.2236, GNorm = 1.4733, lr_0 = 1.0200e-04
Loss = 2.1584e-03, PNorm = 36.2266, GNorm = 1.4677, lr_0 = 1.0200e-04
Loss = 2.1175e-03, PNorm = 36.2285, GNorm = 5.5298, lr_0 = 1.0200e-04
Loss = 1.8587e-03, PNorm = 36.2299, GNorm = 3.5949, lr_0 = 1.0200e-04
Loss = 2.2459e-03, PNorm = 36.2322, GNorm = 1.1887, lr_0 = 1.0200e-04
Loss = 1.7710e-03, PNorm = 36.2352, GNorm = 2.4574, lr_0 = 1.0200e-04
Loss = 2.2213e-03, PNorm = 36.2381, GNorm = 1.4315, lr_0 = 1.0200e-04
Loss = 2.1291e-03, PNorm = 36.2411, GNorm = 3.5956, lr_0 = 1.0200e-04
Loss = 2.0907e-03, PNorm = 36.2435, GNorm = 4.3360, lr_0 = 1.0200e-04
Loss = 1.8848e-03, PNorm = 36.2457, GNorm = 1.7208, lr_0 = 1.0200e-04
Loss = 2.5264e-03, PNorm = 36.2486, GNorm = 4.2121, lr_0 = 1.0200e-04
Loss = 3.0501e-03, PNorm = 36.2510, GNorm = 2.9853, lr_0 = 1.0200e-04
Loss = 2.0455e-03, PNorm = 36.2539, GNorm = 1.6590, lr_0 = 1.0200e-04
Loss = 1.6525e-03, PNorm = 36.2560, GNorm = 2.6753, lr_0 = 1.0200e-04
Loss = 2.2604e-03, PNorm = 36.2582, GNorm = 2.0701, lr_0 = 1.0200e-04
Validation rmse logD = 0.670228
Validation R2 logD = 0.682069
Validation rmse logP = 0.544209
Validation R2 logP = 0.913310
Epoch 20
Train function
Loss = 1.0976e-03, PNorm = 36.2597, GNorm = 2.0859, lr_0 = 1.0200e-04
Loss = 2.8350e-03, PNorm = 36.2615, GNorm = 2.5692, lr_0 = 1.0200e-04
Loss = 1.9281e-03, PNorm = 36.2650, GNorm = 1.8524, lr_0 = 1.0200e-04
Loss = 2.0903e-03, PNorm = 36.2677, GNorm = 1.9879, lr_0 = 1.0200e-04
Loss = 1.7508e-03, PNorm = 36.2696, GNorm = 1.5355, lr_0 = 1.0200e-04
Loss = 2.4452e-03, PNorm = 36.2718, GNorm = 5.4885, lr_0 = 1.0200e-04
Loss = 1.9318e-03, PNorm = 36.2747, GNorm = 1.5944, lr_0 = 1.0200e-04
Loss = 1.8662e-03, PNorm = 36.2775, GNorm = 1.8734, lr_0 = 1.0200e-04
Loss = 1.6616e-03, PNorm = 36.2800, GNorm = 2.2854, lr_0 = 1.0200e-04
Loss = 1.9153e-03, PNorm = 36.2823, GNorm = 2.9006, lr_0 = 1.0200e-04
Loss = 1.8586e-03, PNorm = 36.2844, GNorm = 4.5724, lr_0 = 1.0200e-04
Loss = 1.8039e-03, PNorm = 36.2863, GNorm = 3.3900, lr_0 = 1.0200e-04
Loss = 1.7296e-03, PNorm = 36.2885, GNorm = 1.5313, lr_0 = 1.0200e-04
Loss = 2.1355e-03, PNorm = 36.2907, GNorm = 4.8145, lr_0 = 1.0200e-04
Loss = 1.9160e-03, PNorm = 36.2930, GNorm = 2.7727, lr_0 = 1.0200e-04
Loss = 1.7783e-03, PNorm = 36.2959, GNorm = 3.6587, lr_0 = 1.0200e-04
Loss = 2.2187e-03, PNorm = 36.2986, GNorm = 2.2476, lr_0 = 1.0200e-04
Loss = 1.8963e-03, PNorm = 36.3014, GNorm = 2.3323, lr_0 = 1.0200e-04
Loss = 2.4658e-03, PNorm = 36.3039, GNorm = 3.3310, lr_0 = 1.0200e-04
Loss = 2.5737e-03, PNorm = 36.3052, GNorm = 3.2279, lr_0 = 1.0200e-04
Loss = 1.9075e-03, PNorm = 36.3067, GNorm = 2.5986, lr_0 = 1.0200e-04
Loss = 1.8496e-03, PNorm = 36.3083, GNorm = 0.9773, lr_0 = 1.0200e-04
Loss = 2.4076e-03, PNorm = 36.3102, GNorm = 3.1920, lr_0 = 1.0200e-04
Validation rmse logD = 0.616750
Validation R2 logD = 0.730781
Validation rmse logP = 0.549063
Validation R2 logP = 0.911756
Epoch 21
Train function
Loss = 1.9318e-03, PNorm = 36.3120, GNorm = 6.2088, lr_0 = 1.0200e-04
Loss = 1.5425e-03, PNorm = 36.3135, GNorm = 3.1585, lr_0 = 1.0200e-04
Loss = 2.1226e-03, PNorm = 36.3157, GNorm = 5.0908, lr_0 = 1.0200e-04
Loss = 1.9940e-03, PNorm = 36.3183, GNorm = 3.5118, lr_0 = 1.0200e-04
Loss = 1.9003e-03, PNorm = 36.3205, GNorm = 1.2318, lr_0 = 1.0200e-04
Loss = 1.7623e-03, PNorm = 36.3230, GNorm = 0.8852, lr_0 = 1.0200e-04
Loss = 2.3971e-03, PNorm = 36.3254, GNorm = 1.8158, lr_0 = 1.0200e-04
Loss = 2.1521e-03, PNorm = 36.3292, GNorm = 1.7754, lr_0 = 1.0200e-04
Loss = 2.0888e-03, PNorm = 36.3329, GNorm = 1.3973, lr_0 = 1.0200e-04
Loss = 2.3522e-03, PNorm = 36.3345, GNorm = 5.8292, lr_0 = 1.0200e-04
Loss = 2.0800e-03, PNorm = 36.3366, GNorm = 1.7692, lr_0 = 1.0200e-04
Loss = 1.8104e-03, PNorm = 36.3396, GNorm = 1.7577, lr_0 = 1.0200e-04
Loss = 2.0374e-03, PNorm = 36.3417, GNorm = 1.7884, lr_0 = 1.0200e-04
Loss = 1.8184e-03, PNorm = 36.3440, GNorm = 1.9855, lr_0 = 1.0200e-04
Loss = 1.9881e-03, PNorm = 36.3465, GNorm = 5.1023, lr_0 = 1.0200e-04
Loss = 2.0757e-03, PNorm = 36.3484, GNorm = 7.1434, lr_0 = 1.0200e-04
Loss = 2.2667e-03, PNorm = 36.3512, GNorm = 6.3084, lr_0 = 1.0200e-04
Loss = 2.1676e-03, PNorm = 36.3534, GNorm = 2.6484, lr_0 = 1.0200e-04
Loss = 2.0349e-03, PNorm = 36.3556, GNorm = 3.1246, lr_0 = 1.0200e-04
Loss = 1.8592e-03, PNorm = 36.3580, GNorm = 2.0113, lr_0 = 1.0200e-04
Loss = 2.4912e-03, PNorm = 36.3616, GNorm = 2.6846, lr_0 = 1.0200e-04
Loss = 1.8981e-03, PNorm = 36.3634, GNorm = 4.9698, lr_0 = 1.0200e-04
Loss = 2.0899e-03, PNorm = 36.3651, GNorm = 4.1069, lr_0 = 1.0200e-04
Loss = 3.1403e-03, PNorm = 36.3654, GNorm = 2.2597, lr_0 = 1.0200e-04
Validation rmse logD = 0.649460
Validation R2 logD = 0.701468
Validation rmse logP = 0.542485
Validation R2 logP = 0.913858
Epoch 22
Train function
Loss = 2.1525e-03, PNorm = 36.3676, GNorm = 3.2587, lr_0 = 1.0200e-04
Loss = 1.8277e-03, PNorm = 36.3696, GNorm = 4.9523, lr_0 = 1.0200e-04
Loss = 1.9842e-03, PNorm = 36.3723, GNorm = 4.9269, lr_0 = 1.0200e-04
Loss = 1.9854e-03, PNorm = 36.3743, GNorm = 4.2883, lr_0 = 1.0200e-04
Loss = 1.5989e-03, PNorm = 36.3758, GNorm = 2.3953, lr_0 = 1.0200e-04
Loss = 1.7270e-03, PNorm = 36.3777, GNorm = 4.2497, lr_0 = 1.0200e-04
Loss = 1.6928e-03, PNorm = 36.3801, GNorm = 2.9229, lr_0 = 1.0200e-04
Loss = 1.8167e-03, PNorm = 36.3819, GNorm = 2.4487, lr_0 = 1.0200e-04
Loss = 1.7052e-03, PNorm = 36.3839, GNorm = 3.6215, lr_0 = 1.0200e-04
Loss = 1.6050e-03, PNorm = 36.3855, GNorm = 3.4396, lr_0 = 1.0200e-04
Loss = 1.6797e-03, PNorm = 36.3870, GNorm = 2.7419, lr_0 = 1.0200e-04
Loss = 2.3923e-03, PNorm = 36.3901, GNorm = 3.0667, lr_0 = 1.0200e-04
Loss = 1.9510e-03, PNorm = 36.3926, GNorm = 5.2982, lr_0 = 1.0200e-04
Loss = 2.0145e-03, PNorm = 36.3951, GNorm = 1.9430, lr_0 = 1.0200e-04
Loss = 2.1329e-03, PNorm = 36.3977, GNorm = 1.3559, lr_0 = 1.0200e-04
Loss = 1.7790e-03, PNorm = 36.3993, GNorm = 1.5620, lr_0 = 1.0200e-04
Loss = 1.8482e-03, PNorm = 36.4024, GNorm = 2.7487, lr_0 = 1.0200e-04
Loss = 2.1836e-03, PNorm = 36.4043, GNorm = 2.4770, lr_0 = 1.0200e-04
Loss = 2.1815e-03, PNorm = 36.4072, GNorm = 2.9072, lr_0 = 1.0200e-04
Loss = 2.0758e-03, PNorm = 36.4110, GNorm = 3.1360, lr_0 = 1.0200e-04
Loss = 2.3853e-03, PNorm = 36.4134, GNorm = 4.4887, lr_0 = 1.0200e-04
Loss = 1.5668e-03, PNorm = 36.4159, GNorm = 1.8930, lr_0 = 1.0200e-04
Validation rmse logD = 0.606091
Validation R2 logD = 0.740006
Validation rmse logP = 0.520729
Validation R2 logP = 0.920629
Epoch 23
Train function
Loss = 2.0862e-03, PNorm = 36.4186, GNorm = 3.8510, lr_0 = 1.0200e-04
Loss = 1.6183e-03, PNorm = 36.4217, GNorm = 2.7210, lr_0 = 1.0200e-04
Loss = 2.0870e-03, PNorm = 36.4234, GNorm = 3.8121, lr_0 = 1.0200e-04
Loss = 2.1880e-03, PNorm = 36.4248, GNorm = 1.5839, lr_0 = 1.0200e-04
Loss = 2.0573e-03, PNorm = 36.4270, GNorm = 4.0335, lr_0 = 1.0200e-04
Loss = 1.5426e-03, PNorm = 36.4296, GNorm = 1.7663, lr_0 = 1.0200e-04
Loss = 1.6612e-03, PNorm = 36.4317, GNorm = 1.3565, lr_0 = 1.0200e-04
Loss = 1.4966e-03, PNorm = 36.4329, GNorm = 2.4554, lr_0 = 1.0200e-04
Loss = 2.5440e-03, PNorm = 36.4353, GNorm = 3.8977, lr_0 = 1.0200e-04
Loss = 2.2105e-03, PNorm = 36.4382, GNorm = 2.4241, lr_0 = 1.0200e-04
Loss = 1.8554e-03, PNorm = 36.4408, GNorm = 2.2865, lr_0 = 1.0200e-04
Loss = 1.7453e-03, PNorm = 36.4435, GNorm = 1.8483, lr_0 = 1.0200e-04
Loss = 1.5611e-03, PNorm = 36.4457, GNorm = 2.1499, lr_0 = 1.0200e-04
Loss = 2.2625e-03, PNorm = 36.4487, GNorm = 7.8266, lr_0 = 1.0200e-04
Loss = 2.0175e-03, PNorm = 36.4514, GNorm = 6.8481, lr_0 = 1.0200e-04
Loss = 1.7622e-03, PNorm = 36.4531, GNorm = 3.9563, lr_0 = 1.0200e-04
Loss = 1.9710e-03, PNorm = 36.4554, GNorm = 1.3923, lr_0 = 1.0200e-04
Loss = 2.0451e-03, PNorm = 36.4578, GNorm = 3.7436, lr_0 = 1.0200e-04
Loss = 2.2335e-03, PNorm = 36.4602, GNorm = 4.5352, lr_0 = 1.0200e-04
Loss = 2.0012e-03, PNorm = 36.4632, GNorm = 1.9372, lr_0 = 1.0200e-04
Loss = 1.7569e-03, PNorm = 36.4659, GNorm = 2.4515, lr_0 = 1.0200e-04
Loss = 1.5311e-03, PNorm = 36.4675, GNorm = 1.3261, lr_0 = 1.0200e-04
Loss = 1.5427e-03, PNorm = 36.4688, GNorm = 1.5910, lr_0 = 1.0200e-04
Validation rmse logD = 0.613056
Validation R2 logD = 0.733997
Validation rmse logP = 0.523633
Validation R2 logP = 0.919741
Epoch 24
Train function
Loss = 1.4462e-03, PNorm = 36.4718, GNorm = 3.0659, lr_0 = 1.0200e-04
Loss = 2.0338e-03, PNorm = 36.4741, GNorm = 3.1237, lr_0 = 1.0200e-04
Loss = 1.5831e-03, PNorm = 36.4750, GNorm = 1.9735, lr_0 = 1.0200e-04
Loss = 2.2112e-03, PNorm = 36.4773, GNorm = 4.8108, lr_0 = 1.0200e-04
Loss = 1.6127e-03, PNorm = 36.4799, GNorm = 4.6329, lr_0 = 1.0200e-04
Loss = 1.7270e-03, PNorm = 36.4818, GNorm = 2.1424, lr_0 = 1.0200e-04
Loss = 1.6087e-03, PNorm = 36.4832, GNorm = 1.4710, lr_0 = 1.0200e-04
Loss = 1.6323e-03, PNorm = 36.4857, GNorm = 1.8204, lr_0 = 1.0200e-04
Loss = 2.1295e-03, PNorm = 36.4883, GNorm = 3.3631, lr_0 = 1.0200e-04
Loss = 1.8047e-03, PNorm = 36.4900, GNorm = 2.3613, lr_0 = 1.0200e-04
Loss = 1.9100e-03, PNorm = 36.4921, GNorm = 3.9648, lr_0 = 1.0200e-04
Loss = 2.0968e-03, PNorm = 36.4945, GNorm = 1.2180, lr_0 = 1.0200e-04
Loss = 2.4430e-03, PNorm = 36.4963, GNorm = 3.2379, lr_0 = 1.0200e-04
Loss = 2.2116e-03, PNorm = 36.4986, GNorm = 6.3635, lr_0 = 1.0200e-04
Loss = 2.1914e-03, PNorm = 36.5007, GNorm = 6.9851, lr_0 = 1.0200e-04
Loss = 2.0245e-03, PNorm = 36.5052, GNorm = 2.0708, lr_0 = 1.0200e-04
Loss = 1.6332e-03, PNorm = 36.5083, GNorm = 4.3754, lr_0 = 1.0200e-04
Loss = 1.7010e-03, PNorm = 36.5112, GNorm = 3.2426, lr_0 = 1.0200e-04
Loss = 2.0456e-03, PNorm = 36.5137, GNorm = 2.1336, lr_0 = 1.0200e-04
Loss = 1.4882e-03, PNorm = 36.5166, GNorm = 1.8935, lr_0 = 1.0200e-04
Loss = 2.1714e-03, PNorm = 36.5186, GNorm = 7.8944, lr_0 = 1.0200e-04
Loss = 2.1430e-03, PNorm = 36.5211, GNorm = 4.5936, lr_0 = 1.0200e-04
Validation rmse logD = 0.594611
Validation R2 logD = 0.749762
Validation rmse logP = 0.529842
Validation R2 logP = 0.917827
Epoch 25
Train function
Loss = 1.1814e-03, PNorm = 36.5235, GNorm = 1.7451, lr_0 = 1.0200e-04
Loss = 1.8810e-03, PNorm = 36.5257, GNorm = 2.4089, lr_0 = 1.0200e-04
Loss = 1.7119e-03, PNorm = 36.5268, GNorm = 3.7706, lr_0 = 1.0200e-04
Loss = 2.4004e-03, PNorm = 36.5292, GNorm = 2.0402, lr_0 = 1.0200e-04
Loss = 1.4207e-03, PNorm = 36.5313, GNorm = 3.0607, lr_0 = 1.0200e-04
Loss = 2.0345e-03, PNorm = 36.5339, GNorm = 2.0061, lr_0 = 1.0200e-04
Loss = 1.8495e-03, PNorm = 36.5357, GNorm = 10.6746, lr_0 = 1.0200e-04
Loss = 1.5720e-03, PNorm = 36.5384, GNorm = 2.8339, lr_0 = 1.0200e-04
Loss = 1.5615e-03, PNorm = 36.5412, GNorm = 5.1945, lr_0 = 1.0200e-04
Loss = 1.6849e-03, PNorm = 36.5436, GNorm = 3.3190, lr_0 = 1.0200e-04
Loss = 1.8070e-03, PNorm = 36.5456, GNorm = 1.9347, lr_0 = 1.0200e-04
Loss = 1.6515e-03, PNorm = 36.5482, GNorm = 4.0418, lr_0 = 1.0200e-04
Loss = 1.7644e-03, PNorm = 36.5506, GNorm = 2.6925, lr_0 = 1.0200e-04
Loss = 1.9581e-03, PNorm = 36.5531, GNorm = 3.0276, lr_0 = 1.0200e-04
Loss = 1.6982e-03, PNorm = 36.5561, GNorm = 5.2532, lr_0 = 1.0200e-04
Loss = 1.6178e-03, PNorm = 36.5578, GNorm = 2.9043, lr_0 = 1.0200e-04
Loss = 1.7666e-03, PNorm = 36.5598, GNorm = 3.8506, lr_0 = 1.0200e-04
Loss = 1.8089e-03, PNorm = 36.5626, GNorm = 4.5090, lr_0 = 1.0200e-04
Loss = 1.7907e-03, PNorm = 36.5649, GNorm = 1.4078, lr_0 = 1.0200e-04
Loss = 1.9203e-03, PNorm = 36.5674, GNorm = 3.1940, lr_0 = 1.0200e-04
Loss = 1.6519e-03, PNorm = 36.5698, GNorm = 2.6690, lr_0 = 1.0200e-04
Loss = 1.6066e-03, PNorm = 36.5713, GNorm = 2.0489, lr_0 = 1.0200e-04
Loss = 2.3555e-03, PNorm = 36.5734, GNorm = 3.8701, lr_0 = 1.0200e-04
Validation rmse logD = 0.621976
Validation R2 logD = 0.726200
Validation rmse logP = 0.522202
Validation R2 logP = 0.920179
Epoch 26
Train function
Loss = 1.3945e-03, PNorm = 36.5756, GNorm = 2.2067, lr_0 = 1.0200e-04
Loss = 1.5894e-03, PNorm = 36.5777, GNorm = 1.7678, lr_0 = 1.0200e-04
Loss = 1.7738e-03, PNorm = 36.5801, GNorm = 3.6033, lr_0 = 1.0200e-04
Loss = 1.7425e-03, PNorm = 36.5826, GNorm = 2.2822, lr_0 = 1.0200e-04
Loss = 1.6821e-03, PNorm = 36.5850, GNorm = 1.6303, lr_0 = 1.0200e-04
Loss = 1.5888e-03, PNorm = 36.5880, GNorm = 2.5862, lr_0 = 1.0200e-04
Loss = 1.5612e-03, PNorm = 36.5902, GNorm = 1.5436, lr_0 = 1.0200e-04
Loss = 1.7057e-03, PNorm = 36.5920, GNorm = 3.0733, lr_0 = 1.0200e-04
Loss = 1.7005e-03, PNorm = 36.5941, GNorm = 2.7711, lr_0 = 1.0200e-04
Loss = 1.7394e-03, PNorm = 36.5970, GNorm = 3.6687, lr_0 = 1.0200e-04
Loss = 1.6059e-03, PNorm = 36.5986, GNorm = 1.9238, lr_0 = 1.0200e-04
Loss = 1.7706e-03, PNorm = 36.5998, GNorm = 2.9517, lr_0 = 1.0200e-04
Loss = 1.5937e-03, PNorm = 36.6013, GNorm = 6.0186, lr_0 = 1.0200e-04
Loss = 1.8943e-03, PNorm = 36.6031, GNorm = 1.4209, lr_0 = 1.0200e-04
Loss = 1.6173e-03, PNorm = 36.6051, GNorm = 2.5694, lr_0 = 1.0200e-04
Loss = 1.8265e-03, PNorm = 36.6069, GNorm = 2.7537, lr_0 = 1.0200e-04
Loss = 1.9533e-03, PNorm = 36.6093, GNorm = 3.3352, lr_0 = 1.0200e-04
Loss = 1.9612e-03, PNorm = 36.6118, GNorm = 3.3789, lr_0 = 1.0200e-04
Loss = 1.8338e-03, PNorm = 36.6141, GNorm = 2.8481, lr_0 = 1.0200e-04
Loss = 1.8360e-03, PNorm = 36.6166, GNorm = 1.7490, lr_0 = 1.0200e-04
Loss = 1.2747e-03, PNorm = 36.6194, GNorm = 1.5893, lr_0 = 1.0200e-04
Loss = 1.8062e-03, PNorm = 36.6215, GNorm = 1.4556, lr_0 = 1.0200e-04
Validation rmse logD = 0.640333
Validation R2 logD = 0.709799
Validation rmse logP = 0.516553
Validation R2 logP = 0.921897
Epoch 27
Train function
Loss = 1.5108e-03, PNorm = 36.6242, GNorm = 5.0923, lr_0 = 1.0200e-04
Loss = 1.8720e-03, PNorm = 36.6263, GNorm = 1.6645, lr_0 = 1.0200e-04
Loss = 2.2183e-03, PNorm = 36.6286, GNorm = 6.2279, lr_0 = 1.0200e-04
Loss = 1.6602e-03, PNorm = 36.6311, GNorm = 2.3091, lr_0 = 1.0200e-04
Loss = 1.7030e-03, PNorm = 36.6333, GNorm = 6.7969, lr_0 = 1.0200e-04
Loss = 1.8065e-03, PNorm = 36.6368, GNorm = 2.4900, lr_0 = 1.0200e-04
Loss = 1.3997e-03, PNorm = 36.6394, GNorm = 1.2642, lr_0 = 1.0200e-04
Loss = 1.7589e-03, PNorm = 36.6416, GNorm = 2.9379, lr_0 = 1.0200e-04
Loss = 1.4809e-03, PNorm = 36.6436, GNorm = 1.7092, lr_0 = 1.0200e-04
Loss = 1.7119e-03, PNorm = 36.6461, GNorm = 4.0079, lr_0 = 1.0200e-04
Loss = 1.4285e-03, PNorm = 36.6491, GNorm = 1.1647, lr_0 = 1.0200e-04
Loss = 1.5714e-03, PNorm = 36.6502, GNorm = 2.0799, lr_0 = 1.0200e-04
Loss = 1.5235e-03, PNorm = 36.6526, GNorm = 1.5716, lr_0 = 1.0200e-04
Loss = 1.4648e-03, PNorm = 36.6546, GNorm = 1.4202, lr_0 = 1.0200e-04
Loss = 1.8555e-03, PNorm = 36.6565, GNorm = 1.8567, lr_0 = 1.0200e-04
Loss = 1.5205e-03, PNorm = 36.6582, GNorm = 2.1779, lr_0 = 1.0200e-04
Loss = 2.0636e-03, PNorm = 36.6603, GNorm = 6.6474, lr_0 = 1.0200e-04
Loss = 1.5731e-03, PNorm = 36.6624, GNorm = 2.4172, lr_0 = 1.0200e-04
Loss = 1.8183e-03, PNorm = 36.6648, GNorm = 1.6328, lr_0 = 1.0200e-04
Loss = 1.7812e-03, PNorm = 36.6677, GNorm = 1.0913, lr_0 = 1.0200e-04
Loss = 1.3671e-03, PNorm = 36.6697, GNorm = 1.3444, lr_0 = 1.0200e-04
Loss = 1.7477e-03, PNorm = 36.6714, GNorm = 2.3369, lr_0 = 1.0200e-04
Loss = 1.9053e-03, PNorm = 36.6729, GNorm = 1.5297, lr_0 = 1.0200e-04
Validation rmse logD = 0.613656
Validation R2 logD = 0.733476
Validation rmse logP = 0.509471
Validation R2 logP = 0.924024
Epoch 28
Train function
Loss = 1.3738e-03, PNorm = 36.6753, GNorm = 2.1354, lr_0 = 1.0200e-04
Loss = 1.3684e-03, PNorm = 36.6771, GNorm = 5.0391, lr_0 = 1.0200e-04
Loss = 1.8251e-03, PNorm = 36.6799, GNorm = 4.0163, lr_0 = 1.0200e-04
Loss = 1.3142e-03, PNorm = 36.6817, GNorm = 1.7372, lr_0 = 1.0200e-04
Loss = 1.9474e-03, PNorm = 36.6831, GNorm = 3.5338, lr_0 = 1.0200e-04
Loss = 2.0029e-03, PNorm = 36.6853, GNorm = 4.5642, lr_0 = 1.0200e-04
Loss = 1.2489e-03, PNorm = 36.6883, GNorm = 2.2871, lr_0 = 1.0200e-04
Loss = 1.2175e-03, PNorm = 36.6917, GNorm = 2.0948, lr_0 = 1.0200e-04
Loss = 1.7813e-03, PNorm = 36.6944, GNorm = 2.4679, lr_0 = 1.0200e-04
Loss = 2.1875e-03, PNorm = 36.6972, GNorm = 4.3264, lr_0 = 1.0200e-04
Loss = 1.8175e-03, PNorm = 36.6991, GNorm = 4.0792, lr_0 = 1.0200e-04
Loss = 1.6573e-03, PNorm = 36.7002, GNorm = 1.7112, lr_0 = 1.0200e-04
Loss = 1.4804e-03, PNorm = 36.7023, GNorm = 1.6021, lr_0 = 1.0200e-04
Loss = 1.3979e-03, PNorm = 36.7044, GNorm = 1.9478, lr_0 = 1.0200e-04
Loss = 1.7216e-03, PNorm = 36.7056, GNorm = 3.5721, lr_0 = 1.0200e-04
Loss = 1.4865e-03, PNorm = 36.7071, GNorm = 1.9548, lr_0 = 1.0200e-04
Loss = 1.9147e-03, PNorm = 36.7089, GNorm = 6.5297, lr_0 = 1.0200e-04
Loss = 1.6409e-03, PNorm = 36.7116, GNorm = 2.2575, lr_0 = 1.0200e-04
Loss = 1.7339e-03, PNorm = 36.7147, GNorm = 1.5053, lr_0 = 1.0200e-04
Loss = 1.7721e-03, PNorm = 36.7160, GNorm = 2.3617, lr_0 = 1.0200e-04
Loss = 1.5771e-03, PNorm = 36.7186, GNorm = 2.3254, lr_0 = 1.0200e-04
Loss = 1.4717e-03, PNorm = 36.7211, GNorm = 3.1546, lr_0 = 1.0200e-04
Validation rmse logD = 0.582930
Validation R2 logD = 0.759497
Validation rmse logP = 0.502409
Validation R2 logP = 0.926115
Epoch 29
Train function
Loss = 9.6897e-04, PNorm = 36.7236, GNorm = 2.5623, lr_0 = 1.0200e-04
Loss = 1.3218e-03, PNorm = 36.7258, GNorm = 2.2629, lr_0 = 1.0200e-04
Loss = 1.5603e-03, PNorm = 36.7273, GNorm = 2.2436, lr_0 = 1.0200e-04
Loss = 1.5471e-03, PNorm = 36.7294, GNorm = 5.4094, lr_0 = 1.0200e-04
Loss = 1.7146e-03, PNorm = 36.7318, GNorm = 6.9158, lr_0 = 1.0200e-04
Loss = 1.9647e-03, PNorm = 36.7342, GNorm = 8.3146, lr_0 = 1.0200e-04
Loss = 2.1776e-03, PNorm = 36.7361, GNorm = 6.1031, lr_0 = 1.0200e-04
Loss = 1.5813e-03, PNorm = 36.7379, GNorm = 5.0391, lr_0 = 1.0200e-04
Loss = 1.5208e-03, PNorm = 36.7399, GNorm = 2.7914, lr_0 = 1.0200e-04
Loss = 1.7228e-03, PNorm = 36.7436, GNorm = 1.6057, lr_0 = 1.0200e-04
Loss = 1.2698e-03, PNorm = 36.7459, GNorm = 1.2695, lr_0 = 1.0200e-04
Loss = 1.5120e-03, PNorm = 36.7477, GNorm = 1.8169, lr_0 = 1.0200e-04
Loss = 1.3670e-03, PNorm = 36.7496, GNorm = 1.9335, lr_0 = 1.0200e-04
Loss = 1.6980e-03, PNorm = 36.7516, GNorm = 2.3420, lr_0 = 1.0200e-04
Loss = 1.5187e-03, PNorm = 36.7533, GNorm = 2.4226, lr_0 = 1.0200e-04
Loss = 1.8325e-03, PNorm = 36.7549, GNorm = 4.6308, lr_0 = 1.0200e-04
Loss = 1.7140e-03, PNorm = 36.7574, GNorm = 3.7547, lr_0 = 1.0200e-04
Loss = 1.7409e-03, PNorm = 36.7602, GNorm = 2.6634, lr_0 = 1.0200e-04
Loss = 1.7752e-03, PNorm = 36.7630, GNorm = 4.9217, lr_0 = 1.0200e-04
Loss = 1.6267e-03, PNorm = 36.7653, GNorm = 2.3775, lr_0 = 1.0200e-04
Loss = 1.4198e-03, PNorm = 36.7673, GNorm = 2.8019, lr_0 = 1.0200e-04
Loss = 2.0463e-03, PNorm = 36.7696, GNorm = 3.1337, lr_0 = 1.0200e-04
Loss = 1.7697e-03, PNorm = 36.7714, GNorm = 1.7457, lr_0 = 1.0200e-04
Validation rmse logD = 0.582494
Validation R2 logD = 0.759857
Validation rmse logP = 0.569666
Validation R2 logP = 0.905010
Epoch 30
Train function
Loss = 1.3305e-03, PNorm = 36.7737, GNorm = 3.8335, lr_0 = 1.0200e-04
Loss = 1.4290e-03, PNorm = 36.7762, GNorm = 2.0004, lr_0 = 1.0200e-04
Loss = 1.4054e-03, PNorm = 36.7785, GNorm = 1.4062, lr_0 = 1.0200e-04
Loss = 1.3488e-03, PNorm = 36.7808, GNorm = 2.9964, lr_0 = 1.0200e-04
Loss = 1.4419e-03, PNorm = 36.7829, GNorm = 2.6624, lr_0 = 1.0200e-04
Loss = 1.3086e-03, PNorm = 36.7849, GNorm = 1.4632, lr_0 = 1.0200e-04
Loss = 1.4099e-03, PNorm = 36.7870, GNorm = 1.4854, lr_0 = 1.0200e-04
Loss = 1.9402e-03, PNorm = 36.7891, GNorm = 3.1090, lr_0 = 1.0200e-04
Loss = 1.6062e-03, PNorm = 36.7902, GNorm = 3.7687, lr_0 = 1.0200e-04
Loss = 1.7894e-03, PNorm = 36.7927, GNorm = 1.8096, lr_0 = 1.0200e-04
Loss = 1.3131e-03, PNorm = 36.7948, GNorm = 2.0574, lr_0 = 1.0200e-04
Loss = 1.6764e-03, PNorm = 36.7969, GNorm = 2.7356, lr_0 = 1.0200e-04
Loss = 1.2483e-03, PNorm = 36.7987, GNorm = 1.5461, lr_0 = 1.0200e-04
Loss = 1.4740e-03, PNorm = 36.8003, GNorm = 1.5789, lr_0 = 1.0200e-04
Loss = 1.3791e-03, PNorm = 36.8031, GNorm = 4.3988, lr_0 = 1.0200e-04
Loss = 1.5942e-03, PNorm = 36.8048, GNorm = 2.9368, lr_0 = 1.0200e-04
Loss = 1.4742e-03, PNorm = 36.8067, GNorm = 1.5424, lr_0 = 1.0200e-04
Loss = 1.4617e-03, PNorm = 36.8095, GNorm = 4.0596, lr_0 = 1.0200e-04
Loss = 1.9309e-03, PNorm = 36.8111, GNorm = 4.0559, lr_0 = 1.0200e-04
Loss = 1.6098e-03, PNorm = 36.8131, GNorm = 3.8798, lr_0 = 1.0200e-04
Loss = 1.5769e-03, PNorm = 36.8147, GNorm = 0.9465, lr_0 = 1.0200e-04
Loss = 1.5496e-03, PNorm = 36.8165, GNorm = 2.2352, lr_0 = 1.0200e-04
Validation rmse logD = 0.599520
Validation R2 logD = 0.745613
Validation rmse logP = 0.516750
Validation R2 logP = 0.921837
Epoch 31
Train function
Loss = 1.8799e-03, PNorm = 36.8188, GNorm = 3.7867, lr_0 = 1.0200e-04
Loss = 1.5633e-03, PNorm = 36.8216, GNorm = 5.5391, lr_0 = 1.0200e-04
Loss = 1.7454e-03, PNorm = 36.8239, GNorm = 2.1214, lr_0 = 1.0200e-04
Loss = 1.7153e-03, PNorm = 36.8261, GNorm = 4.0269, lr_0 = 1.0200e-04
Loss = 1.6770e-03, PNorm = 36.8277, GNorm = 1.3092, lr_0 = 1.0200e-04
Loss = 1.8119e-03, PNorm = 36.8303, GNorm = 3.8777, lr_0 = 1.0200e-04
Loss = 1.6003e-03, PNorm = 36.8332, GNorm = 1.7512, lr_0 = 1.0200e-04
Loss = 1.2181e-03, PNorm = 36.8360, GNorm = 2.2691, lr_0 = 1.0200e-04
Loss = 1.3277e-03, PNorm = 36.8378, GNorm = 1.8824, lr_0 = 1.0200e-04
Loss = 1.3102e-03, PNorm = 36.8394, GNorm = 1.9230, lr_0 = 1.0200e-04
Loss = 1.2962e-03, PNorm = 36.8411, GNorm = 2.9636, lr_0 = 1.0200e-04
Loss = 1.4773e-03, PNorm = 36.8424, GNorm = 2.5310, lr_0 = 1.0200e-04
Loss = 1.4980e-03, PNorm = 36.8450, GNorm = 1.1191, lr_0 = 1.0200e-04
Loss = 1.3683e-03, PNorm = 36.8480, GNorm = 3.6130, lr_0 = 1.0200e-04
Loss = 1.3317e-03, PNorm = 36.8500, GNorm = 4.1692, lr_0 = 1.0200e-04
Loss = 1.5756e-03, PNorm = 36.8528, GNorm = 2.2195, lr_0 = 1.0200e-04
Loss = 1.1980e-03, PNorm = 36.8540, GNorm = 2.5377, lr_0 = 1.0200e-04
Loss = 1.4265e-03, PNorm = 36.8560, GNorm = 1.7047, lr_0 = 1.0200e-04
Loss = 1.3273e-03, PNorm = 36.8572, GNorm = 5.1971, lr_0 = 1.0200e-04
Loss = 1.7207e-03, PNorm = 36.8592, GNorm = 4.4003, lr_0 = 1.0200e-04
Loss = 1.4233e-03, PNorm = 36.8613, GNorm = 5.2360, lr_0 = 1.0200e-04
Loss = 1.6114e-03, PNorm = 36.8638, GNorm = 1.5536, lr_0 = 1.0200e-04
Loss = 1.2349e-03, PNorm = 36.8655, GNorm = 1.6928, lr_0 = 1.0200e-04
Validation rmse logD = 0.588330
Validation R2 logD = 0.755021
Validation rmse logP = 0.503835
Validation R2 logP = 0.925696
Epoch 32
Train function
Loss = 1.4078e-03, PNorm = 36.8679, GNorm = 1.8811, lr_0 = 1.0200e-04
Loss = 1.3175e-03, PNorm = 36.8704, GNorm = 3.1703, lr_0 = 1.0200e-04
Loss = 1.0898e-03, PNorm = 36.8719, GNorm = 4.0048, lr_0 = 1.0200e-04
Loss = 1.4820e-03, PNorm = 36.8740, GNorm = 4.0745, lr_0 = 1.0200e-04
Loss = 1.2667e-03, PNorm = 36.8754, GNorm = 2.6275, lr_0 = 1.0200e-04
Loss = 1.5090e-03, PNorm = 36.8776, GNorm = 2.3315, lr_0 = 1.0200e-04
Loss = 1.5197e-03, PNorm = 36.8805, GNorm = 4.9092, lr_0 = 1.0200e-04
Loss = 1.5967e-03, PNorm = 36.8814, GNorm = 5.6738, lr_0 = 1.0200e-04
Loss = 1.4281e-03, PNorm = 36.8831, GNorm = 4.0100, lr_0 = 1.0200e-04
Loss = 1.2620e-03, PNorm = 36.8861, GNorm = 2.5745, lr_0 = 1.0200e-04
Loss = 1.0859e-03, PNorm = 36.8884, GNorm = 2.1743, lr_0 = 1.0200e-04
Loss = 1.5041e-03, PNorm = 36.8901, GNorm = 3.3481, lr_0 = 1.0200e-04
Loss = 1.3239e-03, PNorm = 36.8922, GNorm = 2.7860, lr_0 = 1.0200e-04
Loss = 1.4523e-03, PNorm = 36.8940, GNorm = 2.8028, lr_0 = 1.0200e-04
Loss = 1.4732e-03, PNorm = 36.8959, GNorm = 3.0291, lr_0 = 1.0200e-04
Loss = 1.4163e-03, PNorm = 36.8974, GNorm = 1.0890, lr_0 = 1.0200e-04
Loss = 1.4770e-03, PNorm = 36.8994, GNorm = 1.1507, lr_0 = 1.0200e-04
Loss = 1.1735e-03, PNorm = 36.9013, GNorm = 1.4839, lr_0 = 1.0200e-04
Loss = 1.4371e-03, PNorm = 36.9032, GNorm = 3.6756, lr_0 = 1.0200e-04
Loss = 1.3322e-03, PNorm = 36.9055, GNorm = 3.8726, lr_0 = 1.0200e-04
Loss = 1.6071e-03, PNorm = 36.9079, GNorm = 2.4562, lr_0 = 1.0200e-04
Loss = 1.6247e-03, PNorm = 36.9103, GNorm = 1.5247, lr_0 = 1.0200e-04
Loss = 1.6927e-03, PNorm = 36.9127, GNorm = 2.7580, lr_0 = 1.0200e-04
Loss = 2.2786e-03, PNorm = 36.9128, GNorm = 2.5621, lr_0 = 1.0200e-04
Validation rmse logD = 0.596609
Validation R2 logD = 0.748078
Validation rmse logP = 0.507136
Validation R2 logP = 0.924719
Epoch 33
Train function
Loss = 1.2334e-03, PNorm = 36.9150, GNorm = 1.8038, lr_0 = 1.0200e-04
Loss = 9.9289e-04, PNorm = 36.9164, GNorm = 2.3558, lr_0 = 1.0200e-04
Loss = 1.1506e-03, PNorm = 36.9189, GNorm = 2.1182, lr_0 = 1.0200e-04
Loss = 1.1895e-03, PNorm = 36.9203, GNorm = 1.8636, lr_0 = 1.0200e-04
Loss = 1.4486e-03, PNorm = 36.9222, GNorm = 3.0119, lr_0 = 1.0200e-04
Loss = 1.7970e-03, PNorm = 36.9240, GNorm = 5.4834, lr_0 = 1.0200e-04
Loss = 1.6216e-03, PNorm = 36.9264, GNorm = 5.0382, lr_0 = 1.0200e-04
Loss = 1.8920e-03, PNorm = 36.9286, GNorm = 3.1309, lr_0 = 1.0200e-04
Loss = 1.3093e-03, PNorm = 36.9306, GNorm = 1.8311, lr_0 = 1.0200e-04
Loss = 1.3290e-03, PNorm = 36.9333, GNorm = 3.0052, lr_0 = 1.0200e-04
Loss = 1.5111e-03, PNorm = 36.9360, GNorm = 4.9204, lr_0 = 1.0200e-04
Loss = 1.3822e-03, PNorm = 36.9377, GNorm = 4.2378, lr_0 = 1.0200e-04
Loss = 1.4866e-03, PNorm = 36.9397, GNorm = 1.3972, lr_0 = 1.0200e-04
Loss = 1.6019e-03, PNorm = 36.9421, GNorm = 3.1752, lr_0 = 1.0200e-04
Loss = 1.6331e-03, PNorm = 36.9442, GNorm = 6.6201, lr_0 = 1.0200e-04
Loss = 1.4993e-03, PNorm = 36.9460, GNorm = 3.1337, lr_0 = 1.0200e-04
Loss = 1.6194e-03, PNorm = 36.9487, GNorm = 1.2792, lr_0 = 1.0200e-04
Loss = 1.2318e-03, PNorm = 36.9511, GNorm = 2.4255, lr_0 = 1.0200e-04
Loss = 1.5869e-03, PNorm = 36.9538, GNorm = 4.0211, lr_0 = 1.0200e-04
Loss = 1.7741e-03, PNorm = 36.9553, GNorm = 3.3484, lr_0 = 1.0200e-04
Loss = 1.2385e-03, PNorm = 36.9574, GNorm = 2.4173, lr_0 = 1.0200e-04
Loss = 1.6034e-03, PNorm = 36.9595, GNorm = 2.4697, lr_0 = 1.0200e-04
Validation rmse logD = 0.581031
Validation R2 logD = 0.761062
Validation rmse logP = 0.508009
Validation R2 logP = 0.924459
Epoch 34
Train function
Loss = 9.3380e-04, PNorm = 36.9609, GNorm = 2.5690, lr_0 = 1.0200e-04
Loss = 1.3259e-03, PNorm = 36.9633, GNorm = 1.6945, lr_0 = 1.0200e-04
Loss = 1.4975e-03, PNorm = 36.9650, GNorm = 1.7701, lr_0 = 1.0200e-04
Loss = 1.5621e-03, PNorm = 36.9666, GNorm = 2.2716, lr_0 = 1.0200e-04
Loss = 1.3362e-03, PNorm = 36.9691, GNorm = 2.9584, lr_0 = 1.0200e-04
Loss = 1.2106e-03, PNorm = 36.9713, GNorm = 1.8259, lr_0 = 1.0200e-04
Loss = 1.6986e-03, PNorm = 36.9742, GNorm = 2.9970, lr_0 = 1.0200e-04
Loss = 1.2045e-03, PNorm = 36.9768, GNorm = 2.8733, lr_0 = 1.0200e-04
Loss = 1.2714e-03, PNorm = 36.9787, GNorm = 1.4121, lr_0 = 1.0200e-04
Loss = 1.3238e-03, PNorm = 36.9803, GNorm = 6.1756, lr_0 = 1.0200e-04
Loss = 1.3211e-03, PNorm = 36.9829, GNorm = 3.1288, lr_0 = 1.0200e-04
Loss = 1.3549e-03, PNorm = 36.9862, GNorm = 2.4586, lr_0 = 1.0200e-04
Loss = 1.3736e-03, PNorm = 36.9880, GNorm = 2.3250, lr_0 = 1.0200e-04
Loss = 1.4489e-03, PNorm = 36.9902, GNorm = 1.1266, lr_0 = 1.0200e-04
Loss = 1.2752e-03, PNorm = 36.9916, GNorm = 1.9127, lr_0 = 1.0200e-04
Loss = 1.3850e-03, PNorm = 36.9936, GNorm = 4.6779, lr_0 = 1.0200e-04
Loss = 1.2249e-03, PNorm = 36.9944, GNorm = 2.1614, lr_0 = 1.0200e-04
Loss = 1.1561e-03, PNorm = 36.9960, GNorm = 2.9231, lr_0 = 1.0200e-04
Loss = 1.3918e-03, PNorm = 36.9980, GNorm = 2.0559, lr_0 = 1.0200e-04
Loss = 1.1228e-03, PNorm = 36.9995, GNorm = 1.1471, lr_0 = 1.0200e-04
Loss = 1.5672e-03, PNorm = 37.0010, GNorm = 3.5622, lr_0 = 1.0200e-04
Loss = 1.3995e-03, PNorm = 37.0028, GNorm = 2.2148, lr_0 = 1.0200e-04
Loss = 1.6729e-03, PNorm = 37.0045, GNorm = 1.7399, lr_0 = 1.0200e-04
Validation rmse logD = 0.599434
Validation R2 logD = 0.745686
Validation rmse logP = 0.503143
Validation R2 logP = 0.925899
Epoch 35
Train function
Loss = 1.3573e-03, PNorm = 37.0069, GNorm = 2.2965, lr_0 = 1.0200e-04
Loss = 1.3049e-03, PNorm = 37.0097, GNorm = 1.4731, lr_0 = 1.0200e-04
Loss = 1.0970e-03, PNorm = 37.0119, GNorm = 5.2492, lr_0 = 1.0200e-04
Loss = 1.2974e-03, PNorm = 37.0135, GNorm = 1.1092, lr_0 = 1.0200e-04
Loss = 1.3986e-03, PNorm = 37.0154, GNorm = 2.5773, lr_0 = 1.0200e-04
Loss = 1.2061e-03, PNorm = 37.0172, GNorm = 3.7606, lr_0 = 1.0200e-04
Loss = 1.2131e-03, PNorm = 37.0193, GNorm = 1.7672, lr_0 = 1.0200e-04
Loss = 1.4194e-03, PNorm = 37.0211, GNorm = 1.8080, lr_0 = 1.0200e-04
Loss = 1.0278e-03, PNorm = 37.0231, GNorm = 1.1651, lr_0 = 1.0200e-04
Loss = 1.1882e-03, PNorm = 37.0249, GNorm = 2.7994, lr_0 = 1.0200e-04
Loss = 1.6168e-03, PNorm = 37.0268, GNorm = 1.6223, lr_0 = 1.0200e-04
Loss = 1.0172e-03, PNorm = 37.0282, GNorm = 1.7502, lr_0 = 1.0200e-04
Loss = 1.3467e-03, PNorm = 37.0300, GNorm = 1.1290, lr_0 = 1.0200e-04
Loss = 1.2282e-03, PNorm = 37.0322, GNorm = 1.1538, lr_0 = 1.0200e-04
Loss = 1.4393e-03, PNorm = 37.0346, GNorm = 2.2508, lr_0 = 1.0200e-04
Loss = 1.6337e-03, PNorm = 37.0359, GNorm = 6.0485, lr_0 = 1.0200e-04
Loss = 1.4671e-03, PNorm = 37.0384, GNorm = 4.9783, lr_0 = 1.0200e-04
Loss = 1.6848e-03, PNorm = 37.0414, GNorm = 3.0681, lr_0 = 1.0200e-04
Loss = 1.4868e-03, PNorm = 37.0438, GNorm = 1.7735, lr_0 = 1.0200e-04
Loss = 1.2016e-03, PNorm = 37.0462, GNorm = 1.5717, lr_0 = 1.0200e-04
Loss = 1.4593e-03, PNorm = 37.0483, GNorm = 2.4730, lr_0 = 1.0200e-04
Loss = 1.4540e-03, PNorm = 37.0504, GNorm = 2.0135, lr_0 = 1.0200e-04
Validation rmse logD = 0.577981
Validation R2 logD = 0.763564
Validation rmse logP = 0.501085
Validation R2 logP = 0.926504
Epoch 36
Train function
Loss = 1.1528e-03, PNorm = 37.0529, GNorm = 1.8532, lr_0 = 1.0200e-04
Loss = 1.4398e-03, PNorm = 37.0548, GNorm = 1.5700, lr_0 = 1.0200e-04
Loss = 1.2193e-03, PNorm = 37.0564, GNorm = 2.5412, lr_0 = 1.0200e-04
Loss = 1.0993e-03, PNorm = 37.0582, GNorm = 1.2435, lr_0 = 1.0200e-04
Loss = 1.0579e-03, PNorm = 37.0590, GNorm = 1.9350, lr_0 = 1.0200e-04
Loss = 9.7477e-04, PNorm = 37.0600, GNorm = 1.0839, lr_0 = 1.0200e-04
Loss = 1.4850e-03, PNorm = 37.0616, GNorm = 1.7945, lr_0 = 1.0200e-04
Loss = 1.1825e-03, PNorm = 37.0634, GNorm = 6.0285, lr_0 = 1.0200e-04
Loss = 1.1251e-03, PNorm = 37.0660, GNorm = 2.7715, lr_0 = 1.0200e-04
Loss = 1.2097e-03, PNorm = 37.0677, GNorm = 1.9313, lr_0 = 1.0200e-04
Loss = 1.4479e-03, PNorm = 37.0696, GNorm = 3.9630, lr_0 = 1.0200e-04
Loss = 1.6392e-03, PNorm = 37.0724, GNorm = 5.7139, lr_0 = 1.0200e-04
Loss = 1.5919e-03, PNorm = 37.0750, GNorm = 2.8205, lr_0 = 1.0200e-04
Loss = 1.1345e-03, PNorm = 37.0780, GNorm = 2.6592, lr_0 = 1.0200e-04
Loss = 1.3871e-03, PNorm = 37.0793, GNorm = 2.6947, lr_0 = 1.0200e-04
Loss = 1.3306e-03, PNorm = 37.0812, GNorm = 3.0835, lr_0 = 1.0200e-04
Loss = 1.3189e-03, PNorm = 37.0831, GNorm = 1.9416, lr_0 = 1.0200e-04
Loss = 1.3526e-03, PNorm = 37.0856, GNorm = 2.1333, lr_0 = 1.0200e-04
Loss = 1.6425e-03, PNorm = 37.0878, GNorm = 4.6164, lr_0 = 1.0200e-04
Loss = 1.2360e-03, PNorm = 37.0900, GNorm = 2.3648, lr_0 = 1.0200e-04
Loss = 1.4906e-03, PNorm = 37.0915, GNorm = 1.0447, lr_0 = 1.0200e-04
Loss = 1.6353e-03, PNorm = 37.0943, GNorm = 3.9003, lr_0 = 1.0200e-04
Loss = 1.2358e-03, PNorm = 37.0964, GNorm = 2.9028, lr_0 = 1.0200e-04
Validation rmse logD = 0.568703
Validation R2 logD = 0.771094
Validation rmse logP = 0.518242
Validation R2 logP = 0.921385
Epoch 37
Train function
Loss = 9.7371e-04, PNorm = 37.0989, GNorm = 1.6523, lr_0 = 1.0200e-04
Loss = 1.4139e-03, PNorm = 37.1014, GNorm = 2.2318, lr_0 = 1.0200e-04
Loss = 1.2249e-03, PNorm = 37.1030, GNorm = 1.7742, lr_0 = 1.0200e-04
Loss = 1.2000e-03, PNorm = 37.1050, GNorm = 3.9951, lr_0 = 1.0200e-04
Loss = 1.1569e-03, PNorm = 37.1073, GNorm = 3.3746, lr_0 = 1.0200e-04
Loss = 1.0426e-03, PNorm = 37.1095, GNorm = 1.4046, lr_0 = 1.0200e-04
Loss = 1.3374e-03, PNorm = 37.1108, GNorm = 2.1605, lr_0 = 1.0200e-04
Loss = 1.0023e-03, PNorm = 37.1135, GNorm = 1.4793, lr_0 = 1.0200e-04
Loss = 1.2923e-03, PNorm = 37.1161, GNorm = 1.9569, lr_0 = 1.0200e-04
Loss = 1.7577e-03, PNorm = 37.1184, GNorm = 2.3959, lr_0 = 1.0200e-04
Loss = 1.4187e-03, PNorm = 37.1208, GNorm = 3.5577, lr_0 = 1.0200e-04
Loss = 1.4103e-03, PNorm = 37.1223, GNorm = 1.2253, lr_0 = 1.0200e-04
Loss = 1.4907e-03, PNorm = 37.1238, GNorm = 2.2882, lr_0 = 1.0200e-04
Loss = 1.1211e-03, PNorm = 37.1256, GNorm = 2.0517, lr_0 = 1.0200e-04
Loss = 1.2238e-03, PNorm = 37.1270, GNorm = 3.0823, lr_0 = 1.0200e-04
Loss = 1.2089e-03, PNorm = 37.1288, GNorm = 1.6284, lr_0 = 1.0200e-04
Loss = 1.2202e-03, PNorm = 37.1312, GNorm = 1.8018, lr_0 = 1.0200e-04
Loss = 1.0868e-03, PNorm = 37.1327, GNorm = 1.9052, lr_0 = 1.0200e-04
Loss = 1.4682e-03, PNorm = 37.1349, GNorm = 1.9785, lr_0 = 1.0200e-04
Loss = 1.0446e-03, PNorm = 37.1369, GNorm = 2.1378, lr_0 = 1.0200e-04
Loss = 9.5568e-04, PNorm = 37.1392, GNorm = 0.9200, lr_0 = 1.0200e-04
Loss = 1.2437e-03, PNorm = 37.1414, GNorm = 1.7476, lr_0 = 1.0200e-04
Validation rmse logD = 0.576908
Validation R2 logD = 0.764441
Validation rmse logP = 0.522250
Validation R2 logP = 0.920165
Epoch 38
Train function
Loss = 1.2602e-03, PNorm = 37.1428, GNorm = 1.4823, lr_0 = 1.0200e-04
Loss = 1.2787e-03, PNorm = 37.1454, GNorm = 2.3709, lr_0 = 1.0200e-04
Loss = 1.3894e-03, PNorm = 37.1477, GNorm = 2.3789, lr_0 = 1.0200e-04
Loss = 1.0795e-03, PNorm = 37.1499, GNorm = 2.2726, lr_0 = 1.0200e-04
Loss = 1.1985e-03, PNorm = 37.1521, GNorm = 3.0662, lr_0 = 1.0200e-04
Loss = 1.2491e-03, PNorm = 37.1540, GNorm = 1.5815, lr_0 = 1.0200e-04
Loss = 1.2202e-03, PNorm = 37.1562, GNorm = 5.4462, lr_0 = 1.0200e-04
Loss = 1.4882e-03, PNorm = 37.1582, GNorm = 2.0960, lr_0 = 1.0200e-04
Loss = 1.0782e-03, PNorm = 37.1607, GNorm = 4.9260, lr_0 = 1.0200e-04
Loss = 1.5839e-03, PNorm = 37.1623, GNorm = 4.1350, lr_0 = 1.0200e-04
Loss = 1.0694e-03, PNorm = 37.1641, GNorm = 1.4268, lr_0 = 1.0200e-04
Loss = 1.2126e-03, PNorm = 37.1658, GNorm = 0.9847, lr_0 = 1.0200e-04
Loss = 1.1985e-03, PNorm = 37.1680, GNorm = 2.9145, lr_0 = 1.0200e-04
Loss = 1.2472e-03, PNorm = 37.1703, GNorm = 1.5774, lr_0 = 1.0200e-04
Loss = 1.2406e-03, PNorm = 37.1724, GNorm = 3.7816, lr_0 = 1.0200e-04
Loss = 1.1404e-03, PNorm = 37.1734, GNorm = 2.5743, lr_0 = 1.0200e-04
Loss = 9.9377e-04, PNorm = 37.1748, GNorm = 2.3061, lr_0 = 1.0200e-04
Loss = 1.2837e-03, PNorm = 37.1771, GNorm = 3.3104, lr_0 = 1.0200e-04
Loss = 9.4961e-04, PNorm = 37.1791, GNorm = 1.5378, lr_0 = 1.0200e-04
Loss = 1.1560e-03, PNorm = 37.1810, GNorm = 1.6781, lr_0 = 1.0200e-04
Loss = 1.4448e-03, PNorm = 37.1823, GNorm = 1.9391, lr_0 = 1.0200e-04
Loss = 1.2007e-03, PNorm = 37.1849, GNorm = 2.5424, lr_0 = 1.0200e-04
Loss = 1.0544e-03, PNorm = 37.1863, GNorm = 2.1879, lr_0 = 1.0200e-04
Validation rmse logD = 0.631042
Validation R2 logD = 0.718160
Validation rmse logP = 0.570424
Validation R2 logP = 0.904757
Epoch 39
Train function
Loss = 1.3837e-03, PNorm = 37.1881, GNorm = 4.8513, lr_0 = 1.0200e-04
Loss = 1.2114e-03, PNorm = 37.1910, GNorm = 2.1132, lr_0 = 1.0200e-04
Loss = 1.3810e-03, PNorm = 37.1940, GNorm = 1.3328, lr_0 = 1.0200e-04
Loss = 1.3703e-03, PNorm = 37.1957, GNorm = 2.5380, lr_0 = 1.0200e-04
Loss = 1.1437e-03, PNorm = 37.1981, GNorm = 3.9466, lr_0 = 1.0200e-04
Loss = 1.2659e-03, PNorm = 37.2013, GNorm = 1.0418, lr_0 = 1.0200e-04
Loss = 1.0281e-03, PNorm = 37.2032, GNorm = 2.3779, lr_0 = 1.0200e-04
Loss = 1.1647e-03, PNorm = 37.2045, GNorm = 1.9656, lr_0 = 1.0200e-04
Loss = 9.9561e-04, PNorm = 37.2061, GNorm = 2.2228, lr_0 = 1.0200e-04
Loss = 1.2181e-03, PNorm = 37.2075, GNorm = 1.7468, lr_0 = 1.0200e-04
Loss = 1.1701e-03, PNorm = 37.2091, GNorm = 7.0142, lr_0 = 1.0200e-04
Loss = 1.0972e-03, PNorm = 37.2109, GNorm = 2.2365, lr_0 = 1.0200e-04
Loss = 9.6202e-04, PNorm = 37.2126, GNorm = 2.1775, lr_0 = 1.0200e-04
Loss = 1.1565e-03, PNorm = 37.2151, GNorm = 2.3196, lr_0 = 1.0200e-04
Loss = 1.1241e-03, PNorm = 37.2165, GNorm = 1.6346, lr_0 = 1.0200e-04
Loss = 1.2036e-03, PNorm = 37.2182, GNorm = 3.5984, lr_0 = 1.0200e-04
Loss = 1.4178e-03, PNorm = 37.2201, GNorm = 6.4824, lr_0 = 1.0200e-04
Loss = 1.3269e-03, PNorm = 37.2217, GNorm = 1.0802, lr_0 = 1.0200e-04
Loss = 1.2181e-03, PNorm = 37.2236, GNorm = 1.9135, lr_0 = 1.0200e-04
Loss = 1.3057e-03, PNorm = 37.2254, GNorm = 2.7898, lr_0 = 1.0200e-04
Loss = 1.6080e-03, PNorm = 37.2274, GNorm = 5.2582, lr_0 = 1.0200e-04
Loss = 1.1807e-03, PNorm = 37.2299, GNorm = 5.5192, lr_0 = 1.0200e-04
Validation rmse logD = 0.555450
Validation R2 logD = 0.781638
Validation rmse logP = 0.493424
Validation R2 logP = 0.928735
Epoch 40
Train function
Loss = 1.5124e-03, PNorm = 37.2317, GNorm = 1.7640, lr_0 = 1.0200e-04
Loss = 1.0319e-03, PNorm = 37.2326, GNorm = 2.2630, lr_0 = 1.0200e-04
Loss = 1.4177e-03, PNorm = 37.2352, GNorm = 1.9429, lr_0 = 1.0200e-04
Loss = 1.0454e-03, PNorm = 37.2381, GNorm = 2.1935, lr_0 = 1.0200e-04
Loss = 1.2779e-03, PNorm = 37.2399, GNorm = 1.9168, lr_0 = 1.0200e-04
Loss = 1.0350e-03, PNorm = 37.2411, GNorm = 2.2215, lr_0 = 1.0200e-04
Loss = 1.2387e-03, PNorm = 37.2428, GNorm = 2.3368, lr_0 = 1.0200e-04
Loss = 1.0127e-03, PNorm = 37.2447, GNorm = 1.2555, lr_0 = 1.0200e-04
Loss = 1.0703e-03, PNorm = 37.2464, GNorm = 2.7322, lr_0 = 1.0200e-04
Loss = 1.2363e-03, PNorm = 37.2478, GNorm = 3.7057, lr_0 = 1.0200e-04
Loss = 1.2061e-03, PNorm = 37.2496, GNorm = 3.3308, lr_0 = 1.0200e-04
Loss = 1.1615e-03, PNorm = 37.2523, GNorm = 4.1361, lr_0 = 1.0200e-04
Loss = 1.0775e-03, PNorm = 37.2552, GNorm = 3.4872, lr_0 = 1.0200e-04
Loss = 1.4364e-03, PNorm = 37.2565, GNorm = 1.5531, lr_0 = 1.0200e-04
Loss = 1.0575e-03, PNorm = 37.2593, GNorm = 1.7303, lr_0 = 1.0200e-04
Loss = 9.5402e-04, PNorm = 37.2624, GNorm = 1.6492, lr_0 = 1.0200e-04
Loss = 1.1189e-03, PNorm = 37.2644, GNorm = 2.0798, lr_0 = 1.0200e-04
Loss = 1.4810e-03, PNorm = 37.2654, GNorm = 1.6414, lr_0 = 1.0200e-04
Loss = 1.1451e-03, PNorm = 37.2674, GNorm = 1.5499, lr_0 = 1.0200e-04
Loss = 1.1633e-03, PNorm = 37.2702, GNorm = 1.1143, lr_0 = 1.0200e-04
Loss = 1.3260e-03, PNorm = 37.2712, GNorm = 4.2863, lr_0 = 1.0200e-04
Loss = 1.3446e-03, PNorm = 37.2726, GNorm = 3.9012, lr_0 = 1.0200e-04
Loss = 1.1219e-03, PNorm = 37.2749, GNorm = 4.2584, lr_0 = 1.0200e-04
Validation rmse logD = 0.563795
Validation R2 logD = 0.775028
Validation rmse logP = 0.497026
Validation R2 logP = 0.927690
Epoch 41
Train function
Loss = 1.0143e-03, PNorm = 37.2772, GNorm = 3.2308, lr_0 = 1.0200e-04
Loss = 1.0657e-03, PNorm = 37.2797, GNorm = 1.5440, lr_0 = 1.0200e-04
Loss = 1.1321e-03, PNorm = 37.2811, GNorm = 1.9606, lr_0 = 1.0200e-04
Loss = 9.4827e-04, PNorm = 37.2821, GNorm = 1.2633, lr_0 = 1.0200e-04
Loss = 1.0704e-03, PNorm = 37.2834, GNorm = 2.2611, lr_0 = 1.0200e-04
Loss = 1.1032e-03, PNorm = 37.2856, GNorm = 2.5430, lr_0 = 1.0200e-04
Loss = 1.1613e-03, PNorm = 37.2882, GNorm = 4.3936, lr_0 = 1.0200e-04
Loss = 1.1578e-03, PNorm = 37.2904, GNorm = 1.6170, lr_0 = 1.0200e-04
Loss = 1.1969e-03, PNorm = 37.2923, GNorm = 3.4971, lr_0 = 1.0200e-04
Loss = 1.2055e-03, PNorm = 37.2945, GNorm = 1.6159, lr_0 = 1.0200e-04
Loss = 1.2110e-03, PNorm = 37.2961, GNorm = 2.3101, lr_0 = 1.0200e-04
Loss = 9.4900e-04, PNorm = 37.2976, GNorm = 1.1916, lr_0 = 1.0200e-04
Loss = 1.1771e-03, PNorm = 37.2993, GNorm = 1.5623, lr_0 = 1.0200e-04
Loss = 1.3012e-03, PNorm = 37.3014, GNorm = 2.4819, lr_0 = 1.0200e-04
Loss = 9.0247e-04, PNorm = 37.3034, GNorm = 2.1931, lr_0 = 1.0200e-04
Loss = 9.2983e-04, PNorm = 37.3053, GNorm = 1.5261, lr_0 = 1.0200e-04
Loss = 1.2091e-03, PNorm = 37.3063, GNorm = 2.7389, lr_0 = 1.0200e-04
Loss = 1.2057e-03, PNorm = 37.3078, GNorm = 2.8167, lr_0 = 1.0200e-04
Loss = 1.3856e-03, PNorm = 37.3095, GNorm = 2.2789, lr_0 = 1.0200e-04
Loss = 1.1147e-03, PNorm = 37.3126, GNorm = 4.2027, lr_0 = 1.0200e-04
Loss = 1.0970e-03, PNorm = 37.3142, GNorm = 2.6086, lr_0 = 1.0200e-04
Loss = 1.4978e-03, PNorm = 37.3155, GNorm = 3.4371, lr_0 = 1.0200e-04
Loss = 1.3025e-03, PNorm = 37.3174, GNorm = 2.2367, lr_0 = 1.0200e-04
Validation rmse logD = 0.589592
Validation R2 logD = 0.753969
Validation rmse logP = 0.526772
Validation R2 logP = 0.918776
Epoch 42
Train function
Loss = 1.1317e-03, PNorm = 37.3189, GNorm = 3.2628, lr_0 = 1.0200e-04
Loss = 1.0995e-03, PNorm = 37.3214, GNorm = 2.9896, lr_0 = 1.0200e-04
Loss = 1.1541e-03, PNorm = 37.3232, GNorm = 2.4436, lr_0 = 1.0200e-04
Loss = 1.0309e-03, PNorm = 37.3257, GNorm = 2.9287, lr_0 = 1.0200e-04
Loss = 1.1306e-03, PNorm = 37.3277, GNorm = 1.8163, lr_0 = 1.0200e-04
Loss = 1.1435e-03, PNorm = 37.3283, GNorm = 1.9523, lr_0 = 1.0200e-04
Loss = 1.3444e-03, PNorm = 37.3295, GNorm = 2.9065, lr_0 = 1.0200e-04
Loss = 9.8082e-04, PNorm = 37.3315, GNorm = 0.8884, lr_0 = 1.0200e-04
Loss = 1.0396e-03, PNorm = 37.3326, GNorm = 2.2239, lr_0 = 1.0200e-04
Loss = 1.0690e-03, PNorm = 37.3343, GNorm = 1.7166, lr_0 = 1.0200e-04
Loss = 1.1685e-03, PNorm = 37.3363, GNorm = 3.6932, lr_0 = 1.0200e-04
Loss = 1.1951e-03, PNorm = 37.3400, GNorm = 3.9403, lr_0 = 1.0200e-04
Loss = 1.1130e-03, PNorm = 37.3423, GNorm = 1.7649, lr_0 = 1.0200e-04
Loss = 1.2556e-03, PNorm = 37.3445, GNorm = 2.8432, lr_0 = 1.0200e-04
Loss = 1.1448e-03, PNorm = 37.3461, GNorm = 3.2460, lr_0 = 1.0200e-04
Loss = 8.7216e-04, PNorm = 37.3479, GNorm = 3.2731, lr_0 = 1.0200e-04
Loss = 1.0492e-03, PNorm = 37.3503, GNorm = 1.2522, lr_0 = 1.0200e-04
Loss = 8.9943e-04, PNorm = 37.3521, GNorm = 1.8119, lr_0 = 1.0200e-04
Loss = 1.2140e-03, PNorm = 37.3537, GNorm = 4.4222, lr_0 = 1.0200e-04
Loss = 9.3475e-04, PNorm = 37.3548, GNorm = 1.7591, lr_0 = 1.0200e-04
Loss = 1.1181e-03, PNorm = 37.3562, GNorm = 3.3608, lr_0 = 1.0200e-04
Loss = 1.0299e-03, PNorm = 37.3581, GNorm = 2.9934, lr_0 = 1.0200e-04
Validation rmse logD = 0.600199
Validation R2 logD = 0.745037
Validation rmse logP = 0.499338
Validation R2 logP = 0.927016
Epoch 43
Train function
Loss = 1.2414e-03, PNorm = 37.3606, GNorm = 3.5974, lr_0 = 1.0200e-04
Loss = 8.8996e-04, PNorm = 37.3628, GNorm = 1.5025, lr_0 = 1.0200e-04
Loss = 1.2083e-03, PNorm = 37.3649, GNorm = 1.6002, lr_0 = 1.0200e-04
Loss = 1.0162e-03, PNorm = 37.3668, GNorm = 1.5305, lr_0 = 1.0200e-04
Loss = 9.3546e-04, PNorm = 37.3685, GNorm = 1.0787, lr_0 = 1.0200e-04
Loss = 1.0215e-03, PNorm = 37.3703, GNorm = 1.0878, lr_0 = 1.0200e-04
Loss = 1.0619e-03, PNorm = 37.3722, GNorm = 2.1490, lr_0 = 1.0200e-04
Loss = 1.0533e-03, PNorm = 37.3741, GNorm = 1.4475, lr_0 = 1.0200e-04
Loss = 1.0332e-03, PNorm = 37.3762, GNorm = 2.2241, lr_0 = 1.0200e-04
Loss = 1.2158e-03, PNorm = 37.3789, GNorm = 1.8533, lr_0 = 1.0200e-04
Loss = 9.2464e-04, PNorm = 37.3810, GNorm = 2.0471, lr_0 = 1.0200e-04
Loss = 1.3008e-03, PNorm = 37.3832, GNorm = 1.9149, lr_0 = 1.0200e-04
Loss = 1.1051e-03, PNorm = 37.3846, GNorm = 3.4453, lr_0 = 1.0200e-04
Loss = 1.2954e-03, PNorm = 37.3864, GNorm = 1.7457, lr_0 = 1.0200e-04
Loss = 1.2460e-03, PNorm = 37.3882, GNorm = 2.1117, lr_0 = 1.0200e-04
Loss = 9.1078e-04, PNorm = 37.3900, GNorm = 2.2455, lr_0 = 1.0200e-04
Loss = 1.1131e-03, PNorm = 37.3910, GNorm = 1.9219, lr_0 = 1.0200e-04
Loss = 1.0355e-03, PNorm = 37.3920, GNorm = 1.8160, lr_0 = 1.0200e-04
Loss = 9.2629e-04, PNorm = 37.3943, GNorm = 4.2359, lr_0 = 1.0200e-04
Loss = 9.8980e-04, PNorm = 37.3956, GNorm = 3.1973, lr_0 = 1.0200e-04
Loss = 9.9778e-04, PNorm = 37.3970, GNorm = 3.2983, lr_0 = 1.0200e-04
Loss = 1.0421e-03, PNorm = 37.3988, GNorm = 3.6208, lr_0 = 1.0200e-04
Loss = 1.3051e-03, PNorm = 37.4008, GNorm = 5.3954, lr_0 = 1.0200e-04
Validation rmse logD = 0.657176
Validation R2 logD = 0.694332
Validation rmse logP = 0.547874
Validation R2 logP = 0.912138
Epoch 44
Train function
Loss = 1.3187e-03, PNorm = 37.4027, GNorm = 1.7671, lr_0 = 1.0200e-04
Loss = 1.2148e-03, PNorm = 37.4037, GNorm = 2.7323, lr_0 = 1.0200e-04
Loss = 1.0925e-03, PNorm = 37.4051, GNorm = 4.6029, lr_0 = 1.0200e-04
Loss = 1.1120e-03, PNorm = 37.4070, GNorm = 1.2919, lr_0 = 1.0200e-04
Loss = 1.2280e-03, PNorm = 37.4097, GNorm = 5.6663, lr_0 = 1.0200e-04
Loss = 1.2029e-03, PNorm = 37.4116, GNorm = 1.6247, lr_0 = 1.0200e-04
Loss = 1.3064e-03, PNorm = 37.4139, GNorm = 2.8747, lr_0 = 1.0200e-04
Loss = 1.1296e-03, PNorm = 37.4155, GNorm = 1.5994, lr_0 = 1.0200e-04
Loss = 1.0063e-03, PNorm = 37.4176, GNorm = 1.9989, lr_0 = 1.0200e-04
Loss = 9.7805e-04, PNorm = 37.4197, GNorm = 1.1190, lr_0 = 1.0200e-04
Loss = 9.5758e-04, PNorm = 37.4221, GNorm = 4.1477, lr_0 = 1.0200e-04
Loss = 1.1328e-03, PNorm = 37.4238, GNorm = 3.1593, lr_0 = 1.0200e-04
Loss = 1.0141e-03, PNorm = 37.4263, GNorm = 1.7224, lr_0 = 1.0200e-04
Loss = 9.7882e-04, PNorm = 37.4277, GNorm = 3.8824, lr_0 = 1.0200e-04
Loss = 9.3637e-04, PNorm = 37.4287, GNorm = 2.3341, lr_0 = 1.0200e-04
Loss = 9.8802e-04, PNorm = 37.4304, GNorm = 1.6062, lr_0 = 1.0200e-04
Loss = 1.3136e-03, PNorm = 37.4329, GNorm = 3.7865, lr_0 = 1.0200e-04
Loss = 1.1396e-03, PNorm = 37.4348, GNorm = 3.3139, lr_0 = 1.0200e-04
Loss = 1.0406e-03, PNorm = 37.4360, GNorm = 3.7813, lr_0 = 1.0200e-04
Loss = 8.2284e-04, PNorm = 37.4375, GNorm = 1.9552, lr_0 = 1.0200e-04
Loss = 1.1628e-03, PNorm = 37.4404, GNorm = 2.3689, lr_0 = 1.0200e-04
Loss = 1.0490e-03, PNorm = 37.4431, GNorm = 2.2333, lr_0 = 1.0200e-04
Validation rmse logD = 0.554060
Validation R2 logD = 0.782730
Validation rmse logP = 0.502789
Validation R2 logP = 0.926004
Epoch 45
Train function
Loss = 1.1567e-03, PNorm = 37.4463, GNorm = 4.2022, lr_0 = 1.0200e-04
Loss = 9.5009e-04, PNorm = 37.4479, GNorm = 1.4593, lr_0 = 1.0200e-04
Loss = 1.1838e-03, PNorm = 37.4491, GNorm = 1.9999, lr_0 = 1.0200e-04
Loss = 1.1323e-03, PNorm = 37.4517, GNorm = 2.3207, lr_0 = 1.0200e-04
Loss = 1.1128e-03, PNorm = 37.4533, GNorm = 4.8910, lr_0 = 1.0200e-04
Loss = 8.9046e-04, PNorm = 37.4555, GNorm = 1.5906, lr_0 = 1.0200e-04
Loss = 9.4947e-04, PNorm = 37.4579, GNorm = 2.2900, lr_0 = 1.0200e-04
Loss = 9.2409e-04, PNorm = 37.4600, GNorm = 1.9004, lr_0 = 1.0200e-04
Loss = 8.9395e-04, PNorm = 37.4619, GNorm = 1.9432, lr_0 = 1.0200e-04
Loss = 8.7439e-04, PNorm = 37.4642, GNorm = 2.5252, lr_0 = 1.0200e-04
Loss = 9.6538e-04, PNorm = 37.4659, GNorm = 1.4860, lr_0 = 1.0200e-04
Loss = 9.8250e-04, PNorm = 37.4675, GNorm = 0.7037, lr_0 = 1.0200e-04
Loss = 1.0279e-03, PNorm = 37.4694, GNorm = 1.8340, lr_0 = 1.0200e-04
Loss = 1.0834e-03, PNorm = 37.4710, GNorm = 2.0872, lr_0 = 1.0200e-04
Loss = 8.9921e-04, PNorm = 37.4729, GNorm = 1.5148, lr_0 = 1.0200e-04
Loss = 8.7301e-04, PNorm = 37.4747, GNorm = 2.6316, lr_0 = 1.0200e-04
Loss = 8.7547e-04, PNorm = 37.4761, GNorm = 1.3877, lr_0 = 1.0200e-04
Loss = 1.2122e-03, PNorm = 37.4776, GNorm = 4.3634, lr_0 = 1.0200e-04
Loss = 1.0357e-03, PNorm = 37.4793, GNorm = 1.8858, lr_0 = 1.0200e-04
Loss = 1.0779e-03, PNorm = 37.4818, GNorm = 1.3782, lr_0 = 1.0200e-04
Loss = 1.0251e-03, PNorm = 37.4835, GNorm = 1.2165, lr_0 = 1.0200e-04
Loss = 9.6717e-04, PNorm = 37.4847, GNorm = 1.4940, lr_0 = 1.0200e-04
Loss = 1.3098e-03, PNorm = 37.4866, GNorm = 1.5746, lr_0 = 1.0200e-04
Validation rmse logD = 0.598393
Validation R2 logD = 0.746569
Validation rmse logP = 0.490205
Validation R2 logP = 0.929661
Epoch 46
Train function
Loss = 8.4400e-04, PNorm = 37.4883, GNorm = 2.2471, lr_0 = 1.0200e-04
Loss = 9.5756e-04, PNorm = 37.4894, GNorm = 2.0083, lr_0 = 1.0200e-04
Loss = 8.3331e-04, PNorm = 37.4913, GNorm = 2.3859, lr_0 = 1.0200e-04
Loss = 8.2005e-04, PNorm = 37.4930, GNorm = 1.5106, lr_0 = 1.0200e-04
Loss = 8.3967e-04, PNorm = 37.4942, GNorm = 1.2236, lr_0 = 1.0200e-04
Loss = 8.7120e-04, PNorm = 37.4957, GNorm = 3.7651, lr_0 = 1.0200e-04
Loss = 8.1953e-04, PNorm = 37.4977, GNorm = 1.7195, lr_0 = 1.0200e-04
Loss = 1.0242e-03, PNorm = 37.5001, GNorm = 2.9992, lr_0 = 1.0200e-04
Loss = 8.9750e-04, PNorm = 37.5019, GNorm = 1.7292, lr_0 = 1.0200e-04
Loss = 9.3817e-04, PNorm = 37.5030, GNorm = 1.9623, lr_0 = 1.0200e-04
Loss = 8.4544e-04, PNorm = 37.5041, GNorm = 1.9020, lr_0 = 1.0200e-04
Loss = 1.1549e-03, PNorm = 37.5062, GNorm = 4.0161, lr_0 = 1.0200e-04
Loss = 9.7288e-04, PNorm = 37.5080, GNorm = 0.9895, lr_0 = 1.0200e-04
Loss = 1.0876e-03, PNorm = 37.5091, GNorm = 1.7329, lr_0 = 1.0200e-04
Loss = 9.8324e-04, PNorm = 37.5104, GNorm = 3.9091, lr_0 = 1.0200e-04
Loss = 1.0179e-03, PNorm = 37.5129, GNorm = 2.0970, lr_0 = 1.0200e-04
Loss = 1.1013e-03, PNorm = 37.5157, GNorm = 2.9534, lr_0 = 1.0200e-04
Loss = 1.4907e-03, PNorm = 37.5173, GNorm = 4.9734, lr_0 = 1.0200e-04
Loss = 1.2913e-03, PNorm = 37.5208, GNorm = 1.9841, lr_0 = 1.0200e-04
Loss = 9.7891e-04, PNorm = 37.5233, GNorm = 1.3089, lr_0 = 1.0200e-04
Loss = 8.2392e-04, PNorm = 37.5251, GNorm = 1.6800, lr_0 = 1.0200e-04
Loss = 1.0596e-03, PNorm = 37.5262, GNorm = 4.8569, lr_0 = 1.0200e-04
Validation rmse logD = 0.568611
Validation R2 logD = 0.771168
Validation rmse logP = 0.542115
Validation R2 logP = 0.913976
Epoch 47
Train function
Loss = 9.7212e-04, PNorm = 37.5272, GNorm = 4.4556, lr_0 = 1.0200e-04
Loss = 9.6913e-04, PNorm = 37.5288, GNorm = 3.0875, lr_0 = 1.0200e-04
Loss = 1.0109e-03, PNorm = 37.5311, GNorm = 1.6709, lr_0 = 1.0200e-04
Loss = 7.6907e-04, PNorm = 37.5327, GNorm = 1.9542, lr_0 = 1.0200e-04
Loss = 1.0012e-03, PNorm = 37.5356, GNorm = 2.2107, lr_0 = 1.0200e-04
Loss = 9.4441e-04, PNorm = 37.5372, GNorm = 1.1933, lr_0 = 1.0200e-04
Loss = 1.0416e-03, PNorm = 37.5385, GNorm = 1.7755, lr_0 = 1.0200e-04
Loss = 1.0118e-03, PNorm = 37.5401, GNorm = 2.6102, lr_0 = 1.0200e-04
Loss = 8.0947e-04, PNorm = 37.5422, GNorm = 2.4956, lr_0 = 1.0200e-04
Loss = 8.5847e-04, PNorm = 37.5441, GNorm = 1.3309, lr_0 = 1.0200e-04
Loss = 1.0796e-03, PNorm = 37.5461, GNorm = 3.8493, lr_0 = 1.0200e-04
Loss = 1.0043e-03, PNorm = 37.5489, GNorm = 2.9491, lr_0 = 1.0200e-04
Loss = 1.0106e-03, PNorm = 37.5515, GNorm = 2.3897, lr_0 = 1.0200e-04
Loss = 8.6991e-04, PNorm = 37.5523, GNorm = 1.3921, lr_0 = 1.0200e-04
Loss = 7.2021e-04, PNorm = 37.5538, GNorm = 2.2661, lr_0 = 1.0200e-04
Loss = 6.9366e-04, PNorm = 37.5552, GNorm = 1.6303, lr_0 = 1.0200e-04
Loss = 1.0451e-03, PNorm = 37.5558, GNorm = 5.5703, lr_0 = 1.0200e-04
Loss = 1.3002e-03, PNorm = 37.5572, GNorm = 3.8559, lr_0 = 1.0200e-04
Loss = 1.2497e-03, PNorm = 37.5591, GNorm = 1.2366, lr_0 = 1.0200e-04
Loss = 1.1319e-03, PNorm = 37.5606, GNorm = 5.3567, lr_0 = 1.0200e-04
Loss = 1.0523e-03, PNorm = 37.5618, GNorm = 1.6864, lr_0 = 1.0200e-04
Loss = 7.7655e-04, PNorm = 37.5634, GNorm = 1.4899, lr_0 = 1.0200e-04
Loss = 1.1834e-03, PNorm = 37.5658, GNorm = 3.8059, lr_0 = 1.0200e-04
Validation rmse logD = 0.556222
Validation R2 logD = 0.781031
Validation rmse logP = 0.491944
Validation R2 logP = 0.929161
Epoch 48
Train function
Loss = 8.4513e-04, PNorm = 37.5679, GNorm = 2.0112, lr_0 = 1.0200e-04
Loss = 9.2403e-04, PNorm = 37.5703, GNorm = 0.9710, lr_0 = 1.0200e-04
Loss = 8.7886e-04, PNorm = 37.5719, GNorm = 2.8263, lr_0 = 1.0200e-04
Loss = 9.0910e-04, PNorm = 37.5730, GNorm = 3.1269, lr_0 = 1.0200e-04
Loss = 8.1559e-04, PNorm = 37.5745, GNorm = 1.8336, lr_0 = 1.0200e-04
Loss = 9.4151e-04, PNorm = 37.5764, GNorm = 1.8079, lr_0 = 1.0200e-04
Loss = 1.0426e-03, PNorm = 37.5782, GNorm = 1.2659, lr_0 = 1.0200e-04
Loss = 6.9577e-04, PNorm = 37.5794, GNorm = 1.1505, lr_0 = 1.0200e-04
Loss = 1.0947e-03, PNorm = 37.5816, GNorm = 1.7437, lr_0 = 1.0200e-04
Loss = 7.0771e-04, PNorm = 37.5840, GNorm = 1.4414, lr_0 = 1.0200e-04
Loss = 8.7231e-04, PNorm = 37.5855, GNorm = 3.1378, lr_0 = 1.0200e-04
Loss = 1.1508e-03, PNorm = 37.5881, GNorm = 1.8129, lr_0 = 1.0200e-04
Loss = 9.9471e-04, PNorm = 37.5902, GNorm = 1.8034, lr_0 = 1.0200e-04
Loss = 1.0626e-03, PNorm = 37.5929, GNorm = 2.5773, lr_0 = 1.0200e-04
Loss = 9.2990e-04, PNorm = 37.5954, GNorm = 1.9822, lr_0 = 1.0200e-04
Loss = 8.3040e-04, PNorm = 37.5966, GNorm = 1.1736, lr_0 = 1.0200e-04
Loss = 1.0057e-03, PNorm = 37.5974, GNorm = 1.3425, lr_0 = 1.0200e-04
Loss = 1.0529e-03, PNorm = 37.5987, GNorm = 1.6550, lr_0 = 1.0200e-04
Loss = 1.1090e-03, PNorm = 37.5998, GNorm = 2.3440, lr_0 = 1.0200e-04
Loss = 9.4746e-04, PNorm = 37.6020, GNorm = 1.4696, lr_0 = 1.0200e-04
Loss = 1.0520e-03, PNorm = 37.6042, GNorm = 2.0292, lr_0 = 1.0200e-04
Loss = 8.7116e-04, PNorm = 37.6066, GNorm = 1.1259, lr_0 = 1.0200e-04
Validation rmse logD = 0.561350
Validation R2 logD = 0.776975
Validation rmse logP = 0.497479
Validation R2 logP = 0.927559
Epoch 49
Train function
Loss = 6.4730e-04, PNorm = 37.6088, GNorm = 1.0341, lr_0 = 1.0200e-04
Loss = 9.2721e-04, PNorm = 37.6099, GNorm = 1.0213, lr_0 = 1.0200e-04
Loss = 9.8462e-04, PNorm = 37.6120, GNorm = 1.2935, lr_0 = 1.0200e-04
Loss = 7.6130e-04, PNorm = 37.6140, GNorm = 3.0644, lr_0 = 1.0200e-04
Loss = 7.1663e-04, PNorm = 37.6153, GNorm = 1.2429, lr_0 = 1.0200e-04
Loss = 8.4893e-04, PNorm = 37.6166, GNorm = 2.3829, lr_0 = 1.0200e-04
Loss = 1.0724e-03, PNorm = 37.6186, GNorm = 2.3638, lr_0 = 1.0200e-04
Loss = 8.9429e-04, PNorm = 37.6202, GNorm = 3.1721, lr_0 = 1.0200e-04
Loss = 7.1240e-04, PNorm = 37.6221, GNorm = 2.6845, lr_0 = 1.0200e-04
Loss = 7.2674e-04, PNorm = 37.6241, GNorm = 1.1318, lr_0 = 1.0200e-04
Loss = 9.1963e-04, PNorm = 37.6260, GNorm = 2.6044, lr_0 = 1.0200e-04
Loss = 9.1111e-04, PNorm = 37.6269, GNorm = 1.6760, lr_0 = 1.0200e-04
Loss = 1.1188e-03, PNorm = 37.6292, GNorm = 1.9750, lr_0 = 1.0200e-04
Loss = 1.1780e-03, PNorm = 37.6306, GNorm = 2.0391, lr_0 = 1.0200e-04
Loss = 7.2717e-04, PNorm = 37.6330, GNorm = 1.3307, lr_0 = 1.0200e-04
Loss = 8.3485e-04, PNorm = 37.6351, GNorm = 1.4082, lr_0 = 1.0200e-04
Loss = 1.0003e-03, PNorm = 37.6370, GNorm = 1.4223, lr_0 = 1.0200e-04
Loss = 9.6479e-04, PNorm = 37.6381, GNorm = 3.2805, lr_0 = 1.0200e-04
Loss = 1.2411e-03, PNorm = 37.6398, GNorm = 4.6396, lr_0 = 1.0200e-04
Loss = 1.0308e-03, PNorm = 37.6416, GNorm = 2.0053, lr_0 = 1.0200e-04
Loss = 9.4438e-04, PNorm = 37.6441, GNorm = 1.4814, lr_0 = 1.0200e-04
Loss = 1.1744e-03, PNorm = 37.6453, GNorm = 2.7434, lr_0 = 1.0200e-04
Loss = 9.1859e-04, PNorm = 37.6471, GNorm = 1.7377, lr_0 = 1.0200e-04
Validation rmse logD = 0.566421
Validation R2 logD = 0.772927
Validation rmse logP = 0.493702
Validation R2 logP = 0.928654
Epoch 50
Train function
Loss = 7.6072e-04, PNorm = 37.6503, GNorm = 2.1493, lr_0 = 1.0200e-04
Loss = 9.3058e-04, PNorm = 37.6536, GNorm = 2.3932, lr_0 = 1.0200e-04
Loss = 8.3857e-04, PNorm = 37.6568, GNorm = 1.4666, lr_0 = 1.0200e-04
Loss = 9.1119e-04, PNorm = 37.6587, GNorm = 1.9499, lr_0 = 1.0200e-04
Loss = 7.8150e-04, PNorm = 37.6601, GNorm = 2.1631, lr_0 = 1.0200e-04
Loss = 9.9264e-04, PNorm = 37.6613, GNorm = 1.8533, lr_0 = 1.0200e-04
Loss = 8.7869e-04, PNorm = 37.6635, GNorm = 3.2616, lr_0 = 1.0200e-04
Loss = 1.1599e-03, PNorm = 37.6651, GNorm = 2.1535, lr_0 = 1.0200e-04
Loss = 7.4389e-04, PNorm = 37.6673, GNorm = 1.3827, lr_0 = 1.0200e-04
Loss = 1.1339e-03, PNorm = 37.6691, GNorm = 4.7180, lr_0 = 1.0200e-04
Loss = 9.7350e-04, PNorm = 37.6707, GNorm = 2.4616, lr_0 = 1.0200e-04
Loss = 1.0939e-03, PNorm = 37.6716, GNorm = 1.4331, lr_0 = 1.0200e-04
Loss = 7.5763e-04, PNorm = 37.6719, GNorm = 3.3224, lr_0 = 1.0200e-04
Loss = 8.9915e-04, PNorm = 37.6738, GNorm = 2.2877, lr_0 = 1.0200e-04
Loss = 1.0343e-03, PNorm = 37.6758, GNorm = 2.3344, lr_0 = 1.0200e-04
Loss = 8.4765e-04, PNorm = 37.6769, GNorm = 1.1035, lr_0 = 1.0200e-04
Loss = 9.5401e-04, PNorm = 37.6791, GNorm = 3.0601, lr_0 = 1.0200e-04
Loss = 9.0667e-04, PNorm = 37.6805, GNorm = 1.3477, lr_0 = 1.0200e-04
Loss = 1.0231e-03, PNorm = 37.6822, GNorm = 3.8196, lr_0 = 1.0200e-04
Loss = 8.3355e-04, PNorm = 37.6842, GNorm = 1.5305, lr_0 = 1.0200e-04
Loss = 9.4185e-04, PNorm = 37.6864, GNorm = 2.4211, lr_0 = 1.0200e-04
Loss = 9.0344e-04, PNorm = 37.6889, GNorm = 1.2214, lr_0 = 1.0200e-04
Validation rmse logD = 0.577113
Validation R2 logD = 0.764274
Validation rmse logP = 0.516739
Validation R2 logP = 0.921840
Epoch 51
Train function
Loss = 1.1170e-03, PNorm = 37.6903, GNorm = 3.0235, lr_0 = 1.0200e-04
Loss = 8.1962e-04, PNorm = 37.6926, GNorm = 2.1621, lr_0 = 1.0200e-04
Loss = 1.0207e-03, PNorm = 37.6943, GNorm = 3.8179, lr_0 = 1.0200e-04
Loss = 8.8991e-04, PNorm = 37.6962, GNorm = 1.4921, lr_0 = 1.0200e-04
Loss = 9.3050e-04, PNorm = 37.6981, GNorm = 2.0422, lr_0 = 1.0200e-04
Loss = 7.3697e-04, PNorm = 37.6998, GNorm = 1.7096, lr_0 = 1.0200e-04
Loss = 8.0909e-04, PNorm = 37.7016, GNorm = 2.2996, lr_0 = 1.0200e-04
Loss = 7.6736e-04, PNorm = 37.7034, GNorm = 1.5487, lr_0 = 1.0200e-04
Loss = 7.9008e-04, PNorm = 37.7044, GNorm = 1.2570, lr_0 = 1.0200e-04
Loss = 6.3261e-04, PNorm = 37.7054, GNorm = 1.3260, lr_0 = 1.0200e-04
Loss = 8.8346e-04, PNorm = 37.7074, GNorm = 1.7334, lr_0 = 1.0200e-04
Loss = 7.9025e-04, PNorm = 37.7087, GNorm = 2.2551, lr_0 = 1.0200e-04
Loss = 1.0798e-03, PNorm = 37.7102, GNorm = 2.8949, lr_0 = 1.0200e-04
Loss = 7.7888e-04, PNorm = 37.7117, GNorm = 3.0318, lr_0 = 1.0200e-04
Loss = 1.0433e-03, PNorm = 37.7131, GNorm = 2.4792, lr_0 = 1.0200e-04
Loss = 7.6486e-04, PNorm = 37.7150, GNorm = 1.4379, lr_0 = 1.0200e-04
Loss = 8.3425e-04, PNorm = 37.7165, GNorm = 2.4856, lr_0 = 1.0200e-04
Loss = 8.2723e-04, PNorm = 37.7172, GNorm = 2.4558, lr_0 = 1.0200e-04
Loss = 8.2761e-04, PNorm = 37.7184, GNorm = 1.7335, lr_0 = 1.0200e-04
Loss = 8.8346e-04, PNorm = 37.7194, GNorm = 3.7109, lr_0 = 1.0200e-04
Loss = 9.0410e-04, PNorm = 37.7217, GNorm = 1.3889, lr_0 = 1.0200e-04
Loss = 9.4638e-04, PNorm = 37.7237, GNorm = 3.2866, lr_0 = 1.0200e-04
Loss = 8.3919e-04, PNorm = 37.7249, GNorm = 1.5494, lr_0 = 1.0200e-04
Validation rmse logD = 0.553174
Validation R2 logD = 0.783424
Validation rmse logP = 0.480052
Validation R2 logP = 0.932545
Epoch 52
Train function
Loss = 5.8442e-04, PNorm = 37.7271, GNorm = 2.7285, lr_0 = 1.0200e-04
Loss = 8.8224e-04, PNorm = 37.7292, GNorm = 3.7905, lr_0 = 1.0200e-04
Loss = 7.5384e-04, PNorm = 37.7312, GNorm = 3.5042, lr_0 = 1.0200e-04
Loss = 7.8801e-04, PNorm = 37.7334, GNorm = 1.6780, lr_0 = 1.0200e-04
Loss = 9.7906e-04, PNorm = 37.7352, GNorm = 1.4711, lr_0 = 1.0200e-04
Loss = 9.3177e-04, PNorm = 37.7368, GNorm = 3.2014, lr_0 = 1.0200e-04
Loss = 1.0763e-03, PNorm = 37.7387, GNorm = 2.7437, lr_0 = 1.0200e-04
Loss = 7.4912e-04, PNorm = 37.7405, GNorm = 2.4996, lr_0 = 1.0200e-04
Loss = 8.4086e-04, PNorm = 37.7421, GNorm = 1.7237, lr_0 = 1.0200e-04
Loss = 7.1087e-04, PNorm = 37.7426, GNorm = 2.9950, lr_0 = 1.0200e-04
Loss = 8.7087e-04, PNorm = 37.7443, GNorm = 3.9053, lr_0 = 1.0200e-04
Loss = 8.3723e-04, PNorm = 37.7467, GNorm = 2.2771, lr_0 = 1.0200e-04
Loss = 6.5374e-04, PNorm = 37.7488, GNorm = 1.5072, lr_0 = 1.0200e-04
Loss = 6.9431e-04, PNorm = 37.7502, GNorm = 1.3764, lr_0 = 1.0200e-04
Loss = 8.1441e-04, PNorm = 37.7528, GNorm = 3.1193, lr_0 = 1.0200e-04
Loss = 9.7717e-04, PNorm = 37.7542, GNorm = 3.2223, lr_0 = 1.0200e-04
Loss = 7.5671e-04, PNorm = 37.7564, GNorm = 2.0044, lr_0 = 1.0200e-04
Loss = 1.1607e-03, PNorm = 37.7579, GNorm = 1.0550, lr_0 = 1.0200e-04
Loss = 9.6462e-04, PNorm = 37.7594, GNorm = 3.0278, lr_0 = 1.0200e-04
Loss = 1.1625e-03, PNorm = 37.7617, GNorm = 2.1884, lr_0 = 1.0200e-04
Loss = 9.4542e-04, PNorm = 37.7637, GNorm = 1.5563, lr_0 = 1.0200e-04
Loss = 7.8021e-04, PNorm = 37.7655, GNorm = 1.7957, lr_0 = 1.0200e-04
Loss = 8.3559e-04, PNorm = 37.7669, GNorm = 3.7739, lr_0 = 1.0200e-04
Validation rmse logD = 0.541647
Validation R2 logD = 0.792356
Validation rmse logP = 0.501810
Validation R2 logP = 0.926292
Epoch 53
Train function
Loss = 7.6945e-04, PNorm = 37.7691, GNorm = 2.2936, lr_0 = 1.0200e-04
Loss = 9.5322e-04, PNorm = 37.7703, GNorm = 1.8010, lr_0 = 1.0200e-04
Loss = 8.4020e-04, PNorm = 37.7716, GNorm = 2.3370, lr_0 = 1.0200e-04
Loss = 1.0094e-03, PNorm = 37.7739, GNorm = 1.3489, lr_0 = 1.0200e-04
Loss = 7.6536e-04, PNorm = 37.7756, GNorm = 1.8890, lr_0 = 1.0200e-04
Loss = 7.0295e-04, PNorm = 37.7775, GNorm = 1.7961, lr_0 = 1.0200e-04
Loss = 8.1347e-04, PNorm = 37.7794, GNorm = 3.8854, lr_0 = 1.0200e-04
Loss = 9.5413e-04, PNorm = 37.7812, GNorm = 1.3823, lr_0 = 1.0200e-04
Loss = 1.0451e-03, PNorm = 37.7837, GNorm = 2.8279, lr_0 = 1.0200e-04
Loss = 8.9935e-04, PNorm = 37.7856, GNorm = 3.2751, lr_0 = 1.0200e-04
Loss = 7.0995e-04, PNorm = 37.7872, GNorm = 1.4962, lr_0 = 1.0200e-04
Loss = 6.8884e-04, PNorm = 37.7886, GNorm = 0.7387, lr_0 = 1.0200e-04
Loss = 7.7754e-04, PNorm = 37.7902, GNorm = 1.0466, lr_0 = 1.0200e-04
Loss = 8.8544e-04, PNorm = 37.7924, GNorm = 1.3551, lr_0 = 1.0200e-04
Loss = 8.7439e-04, PNorm = 37.7934, GNorm = 2.7704, lr_0 = 1.0200e-04
Loss = 1.0202e-03, PNorm = 37.7948, GNorm = 2.0967, lr_0 = 1.0200e-04
Loss = 8.1929e-04, PNorm = 37.7962, GNorm = 1.1547, lr_0 = 1.0200e-04
Loss = 8.1873e-04, PNorm = 37.7978, GNorm = 2.5205, lr_0 = 1.0200e-04
Loss = 8.3810e-04, PNorm = 37.7994, GNorm = 1.8575, lr_0 = 1.0200e-04
Loss = 8.5619e-04, PNorm = 37.8014, GNorm = 3.2574, lr_0 = 1.0200e-04
Loss = 8.6146e-04, PNorm = 37.8030, GNorm = 1.0320, lr_0 = 1.0200e-04
Loss = 8.2682e-04, PNorm = 37.8051, GNorm = 2.5250, lr_0 = 1.0200e-04
Validation rmse logD = 0.606646
Validation R2 logD = 0.739530
Validation rmse logP = 0.491411
Validation R2 logP = 0.929315
Epoch 54
Train function
Loss = 1.0375e-03, PNorm = 37.8072, GNorm = 3.2526, lr_0 = 1.0200e-04
Loss = 8.3298e-04, PNorm = 37.8077, GNorm = 0.9764, lr_0 = 1.0200e-04
Loss = 8.1687e-04, PNorm = 37.8092, GNorm = 1.8262, lr_0 = 1.0200e-04
Loss = 6.5182e-04, PNorm = 37.8111, GNorm = 2.0024, lr_0 = 1.0200e-04
Loss = 8.7996e-04, PNorm = 37.8131, GNorm = 1.5901, lr_0 = 1.0200e-04
Loss = 6.8968e-04, PNorm = 37.8149, GNorm = 1.1034, lr_0 = 1.0200e-04
Loss = 9.2857e-04, PNorm = 37.8164, GNorm = 3.1946, lr_0 = 1.0200e-04
Loss = 7.7919e-04, PNorm = 37.8181, GNorm = 1.5350, lr_0 = 1.0200e-04
Loss = 7.3578e-04, PNorm = 37.8208, GNorm = 1.2807, lr_0 = 1.0200e-04
Loss = 8.8882e-04, PNorm = 37.8233, GNorm = 1.2092, lr_0 = 1.0200e-04
Loss = 1.0032e-03, PNorm = 37.8253, GNorm = 4.0548, lr_0 = 1.0200e-04
Loss = 8.0766e-04, PNorm = 37.8275, GNorm = 1.6034, lr_0 = 1.0200e-04
Loss = 8.8184e-04, PNorm = 37.8294, GNorm = 1.3745, lr_0 = 1.0200e-04
Loss = 7.2413e-04, PNorm = 37.8302, GNorm = 1.8817, lr_0 = 1.0200e-04
Loss = 6.5767e-04, PNorm = 37.8315, GNorm = 0.9113, lr_0 = 1.0200e-04
Loss = 9.2183e-04, PNorm = 37.8333, GNorm = 2.1226, lr_0 = 1.0200e-04
Loss = 8.2287e-04, PNorm = 37.8345, GNorm = 1.0579, lr_0 = 1.0200e-04
Loss = 7.6378e-04, PNorm = 37.8358, GNorm = 1.5760, lr_0 = 1.0200e-04
Loss = 8.0601e-04, PNorm = 37.8367, GNorm = 5.0068, lr_0 = 1.0200e-04
Loss = 7.3920e-04, PNorm = 37.8380, GNorm = 1.2478, lr_0 = 1.0200e-04
Loss = 7.9014e-04, PNorm = 37.8403, GNorm = 1.1432, lr_0 = 1.0200e-04
Loss = 8.6912e-04, PNorm = 37.8424, GNorm = 1.5454, lr_0 = 1.0200e-04
Loss = 9.1901e-04, PNorm = 37.8447, GNorm = 3.4223, lr_0 = 1.0200e-04
Validation rmse logD = 0.552491
Validation R2 logD = 0.783958
Validation rmse logP = 0.476166
Validation R2 logP = 0.933632
Epoch 55
Train function
Loss = 7.6943e-04, PNorm = 37.8465, GNorm = 1.2392, lr_0 = 1.0200e-04
Loss = 7.0588e-04, PNorm = 37.8474, GNorm = 2.7025, lr_0 = 1.0200e-04
Loss = 8.7083e-04, PNorm = 37.8492, GNorm = 2.3484, lr_0 = 1.0200e-04
Loss = 7.7639e-04, PNorm = 37.8505, GNorm = 4.1101, lr_0 = 1.0200e-04
Loss = 9.5339e-04, PNorm = 37.8522, GNorm = 2.7895, lr_0 = 1.0200e-04
Loss = 6.9919e-04, PNorm = 37.8542, GNorm = 3.1951, lr_0 = 1.0200e-04
Loss = 7.6092e-04, PNorm = 37.8561, GNorm = 1.4040, lr_0 = 1.0200e-04
Loss = 7.3666e-04, PNorm = 37.8582, GNorm = 1.4227, lr_0 = 1.0200e-04
Loss = 7.2255e-04, PNorm = 37.8590, GNorm = 1.2153, lr_0 = 1.0200e-04
Loss = 8.0216e-04, PNorm = 37.8609, GNorm = 1.9258, lr_0 = 1.0200e-04
Loss = 8.2403e-04, PNorm = 37.8630, GNorm = 1.2928, lr_0 = 1.0200e-04
Loss = 6.7048e-04, PNorm = 37.8651, GNorm = 2.1090, lr_0 = 1.0200e-04
Loss = 8.6300e-04, PNorm = 37.8670, GNorm = 1.3682, lr_0 = 1.0200e-04
Loss = 7.7417e-04, PNorm = 37.8682, GNorm = 3.6639, lr_0 = 1.0200e-04
Loss = 9.7610e-04, PNorm = 37.8695, GNorm = 4.3617, lr_0 = 1.0200e-04
Loss = 8.4828e-04, PNorm = 37.8705, GNorm = 1.6654, lr_0 = 1.0200e-04
Loss = 7.7067e-04, PNorm = 37.8727, GNorm = 2.1983, lr_0 = 1.0200e-04
Loss = 8.2503e-04, PNorm = 37.8752, GNorm = 2.1056, lr_0 = 1.0200e-04
Loss = 8.9519e-04, PNorm = 37.8770, GNorm = 3.3171, lr_0 = 1.0200e-04
Loss = 1.0097e-03, PNorm = 37.8779, GNorm = 2.2444, lr_0 = 1.0200e-04
Loss = 8.4506e-04, PNorm = 37.8791, GNorm = 1.4127, lr_0 = 1.0200e-04
Loss = 7.2643e-04, PNorm = 37.8806, GNorm = 2.1399, lr_0 = 1.0200e-04
Validation rmse logD = 0.558355
Validation R2 logD = 0.779348
Validation rmse logP = 0.503528
Validation R2 logP = 0.925786
Epoch 56
Train function
Loss = 9.0671e-04, PNorm = 37.8821, GNorm = 1.7630, lr_0 = 1.0200e-04
Loss = 7.2879e-04, PNorm = 37.8833, GNorm = 3.0896, lr_0 = 1.0200e-04
Loss = 7.6119e-04, PNorm = 37.8854, GNorm = 1.8317, lr_0 = 1.0200e-04
Loss = 6.8932e-04, PNorm = 37.8865, GNorm = 4.2412, lr_0 = 1.0200e-04
Loss = 8.5818e-04, PNorm = 37.8879, GNorm = 0.9873, lr_0 = 1.0200e-04
Loss = 8.7548e-04, PNorm = 37.8881, GNorm = 1.0314, lr_0 = 1.0200e-04
Loss = 7.3756e-04, PNorm = 37.8902, GNorm = 2.0958, lr_0 = 1.0200e-04
Loss = 7.6988e-04, PNorm = 37.8926, GNorm = 0.8403, lr_0 = 1.0200e-04
Loss = 7.3358e-04, PNorm = 37.8942, GNorm = 1.6272, lr_0 = 1.0200e-04
Loss = 1.0145e-03, PNorm = 37.8953, GNorm = 1.2624, lr_0 = 1.0200e-04
Loss = 6.7482e-04, PNorm = 37.8967, GNorm = 1.6274, lr_0 = 1.0200e-04
Loss = 9.0176e-04, PNorm = 37.8985, GNorm = 0.9168, lr_0 = 1.0200e-04
Loss = 7.2108e-04, PNorm = 37.8998, GNorm = 0.9702, lr_0 = 1.0200e-04
Loss = 8.9302e-04, PNorm = 37.9015, GNorm = 1.1313, lr_0 = 1.0200e-04
Loss = 9.1865e-04, PNorm = 37.9023, GNorm = 3.3883, lr_0 = 1.0200e-04
Loss = 9.3725e-04, PNorm = 37.9048, GNorm = 1.2812, lr_0 = 1.0200e-04
Loss = 7.8892e-04, PNorm = 37.9072, GNorm = 1.3346, lr_0 = 1.0200e-04
Loss = 8.5162e-04, PNorm = 37.9100, GNorm = 1.7745, lr_0 = 1.0200e-04
Loss = 7.9296e-04, PNorm = 37.9117, GNorm = 2.8333, lr_0 = 1.0200e-04
Loss = 8.5973e-04, PNorm = 37.9131, GNorm = 3.2788, lr_0 = 1.0200e-04
Loss = 8.5678e-04, PNorm = 37.9147, GNorm = 1.9459, lr_0 = 1.0200e-04
Loss = 7.8454e-04, PNorm = 37.9162, GNorm = 1.2505, lr_0 = 1.0200e-04
Loss = 6.9273e-04, PNorm = 37.9188, GNorm = 2.5100, lr_0 = 1.0200e-04
Validation rmse logD = 0.542949
Validation R2 logD = 0.791356
Validation rmse logP = 0.475299
Validation R2 logP = 0.933874
Epoch 57
Train function
Loss = 5.7676e-04, PNorm = 37.9209, GNorm = 2.6204, lr_0 = 1.0200e-04
Loss = 6.8058e-04, PNorm = 37.9222, GNorm = 1.0674, lr_0 = 1.0200e-04
Loss = 7.0319e-04, PNorm = 37.9237, GNorm = 1.3216, lr_0 = 1.0200e-04
Loss = 7.9491e-04, PNorm = 37.9258, GNorm = 2.3390, lr_0 = 1.0200e-04
Loss = 6.9772e-04, PNorm = 37.9274, GNorm = 1.8593, lr_0 = 1.0200e-04
Loss = 6.9786e-04, PNorm = 37.9292, GNorm = 1.8435, lr_0 = 1.0200e-04
Loss = 9.5232e-04, PNorm = 37.9307, GNorm = 5.8265, lr_0 = 1.0200e-04
Loss = 6.7607e-04, PNorm = 37.9324, GNorm = 1.3629, lr_0 = 1.0200e-04
Loss = 7.2640e-04, PNorm = 37.9349, GNorm = 1.3323, lr_0 = 1.0200e-04
Loss = 7.9494e-04, PNorm = 37.9359, GNorm = 1.9324, lr_0 = 1.0200e-04
Loss = 5.9333e-04, PNorm = 37.9360, GNorm = 2.0833, lr_0 = 1.0200e-04
Loss = 8.7545e-04, PNorm = 37.9377, GNorm = 3.0932, lr_0 = 1.0200e-04
Loss = 6.9499e-04, PNorm = 37.9392, GNorm = 1.1941, lr_0 = 1.0200e-04
Loss = 8.4501e-04, PNorm = 37.9414, GNorm = 1.1539, lr_0 = 1.0200e-04
Loss = 8.1684e-04, PNorm = 37.9433, GNorm = 3.1690, lr_0 = 1.0200e-04
Loss = 7.7780e-04, PNorm = 37.9446, GNorm = 1.1655, lr_0 = 1.0200e-04
Loss = 8.4491e-04, PNorm = 37.9456, GNorm = 1.5631, lr_0 = 1.0200e-04
Loss = 6.2355e-04, PNorm = 37.9473, GNorm = 2.4143, lr_0 = 1.0200e-04
Loss = 9.3166e-04, PNorm = 37.9481, GNorm = 1.4009, lr_0 = 1.0200e-04
Loss = 9.4294e-04, PNorm = 37.9497, GNorm = 2.9741, lr_0 = 1.0200e-04
Loss = 9.2281e-04, PNorm = 37.9510, GNorm = 3.1728, lr_0 = 1.0200e-04
Loss = 1.0366e-03, PNorm = 37.9528, GNorm = 3.1067, lr_0 = 1.0200e-04
Validation rmse logD = 0.545668
Validation R2 logD = 0.789262
Validation rmse logP = 0.486701
Validation R2 logP = 0.930663
Epoch 58
Train function
Loss = 6.3807e-04, PNorm = 37.9549, GNorm = 1.3628, lr_0 = 1.0200e-04
Loss = 7.9483e-04, PNorm = 37.9561, GNorm = 1.7279, lr_0 = 1.0200e-04
Loss = 7.8086e-04, PNorm = 37.9590, GNorm = 1.4067, lr_0 = 1.0200e-04
Loss = 8.7725e-04, PNorm = 37.9607, GNorm = 3.1843, lr_0 = 1.0200e-04
Loss = 7.6412e-04, PNorm = 37.9626, GNorm = 1.6491, lr_0 = 1.0200e-04
Loss = 8.9844e-04, PNorm = 37.9640, GNorm = 1.8897, lr_0 = 1.0200e-04
Loss = 6.7513e-04, PNorm = 37.9665, GNorm = 1.4539, lr_0 = 1.0200e-04
Loss = 6.8921e-04, PNorm = 37.9681, GNorm = 1.5304, lr_0 = 1.0200e-04
Loss = 7.2306e-04, PNorm = 37.9698, GNorm = 1.3897, lr_0 = 1.0200e-04
Loss = 7.5971e-04, PNorm = 37.9710, GNorm = 1.9835, lr_0 = 1.0200e-04
Loss = 8.6149e-04, PNorm = 37.9730, GNorm = 2.1841, lr_0 = 1.0200e-04
Loss = 9.2677e-04, PNorm = 37.9744, GNorm = 1.8761, lr_0 = 1.0200e-04
Loss = 1.0618e-03, PNorm = 37.9757, GNorm = 2.0490, lr_0 = 1.0200e-04
Loss = 7.4063e-04, PNorm = 37.9775, GNorm = 4.7046, lr_0 = 1.0200e-04
Loss = 8.2473e-04, PNorm = 37.9786, GNorm = 2.4923, lr_0 = 1.0200e-04
Loss = 7.7124e-04, PNorm = 37.9806, GNorm = 3.0889, lr_0 = 1.0200e-04
Loss = 7.8297e-04, PNorm = 37.9818, GNorm = 2.1567, lr_0 = 1.0200e-04
Loss = 7.2025e-04, PNorm = 37.9832, GNorm = 2.8507, lr_0 = 1.0200e-04
Loss = 7.8493e-04, PNorm = 37.9862, GNorm = 1.2087, lr_0 = 1.0200e-04
Loss = 7.1927e-04, PNorm = 37.9887, GNorm = 1.6397, lr_0 = 1.0200e-04
Loss = 7.3921e-04, PNorm = 37.9909, GNorm = 1.7529, lr_0 = 1.0200e-04
Loss = 5.8614e-04, PNorm = 37.9921, GNorm = 1.1125, lr_0 = 1.0200e-04
Loss = 7.6495e-04, PNorm = 37.9948, GNorm = 1.7900, lr_0 = 1.0200e-04
Validation rmse logD = 0.551954
Validation R2 logD = 0.784378
Validation rmse logP = 0.493101
Validation R2 logP = 0.928828
Epoch 59
Train function
Loss = 6.5563e-04, PNorm = 37.9966, GNorm = 1.8010, lr_0 = 1.0200e-04
Loss = 7.6198e-04, PNorm = 37.9979, GNorm = 2.7921, lr_0 = 1.0200e-04
Loss = 7.1701e-04, PNorm = 38.0014, GNorm = 0.9402, lr_0 = 1.0200e-04
Loss = 8.8520e-04, PNorm = 38.0037, GNorm = 5.9749, lr_0 = 1.0200e-04
Loss = 7.2557e-04, PNorm = 38.0054, GNorm = 0.7860, lr_0 = 1.0200e-04
Loss = 8.8672e-04, PNorm = 38.0065, GNorm = 1.3768, lr_0 = 1.0200e-04
Loss = 8.1158e-04, PNorm = 38.0086, GNorm = 2.8789, lr_0 = 1.0200e-04
Loss = 7.4000e-04, PNorm = 38.0094, GNorm = 4.3054, lr_0 = 1.0200e-04
Loss = 7.3626e-04, PNorm = 38.0106, GNorm = 1.4153, lr_0 = 1.0200e-04
Loss = 8.8667e-04, PNorm = 38.0121, GNorm = 4.4205, lr_0 = 1.0200e-04
Loss = 7.3067e-04, PNorm = 38.0136, GNorm = 1.2616, lr_0 = 1.0200e-04
Loss = 6.5939e-04, PNorm = 38.0145, GNorm = 2.3370, lr_0 = 1.0200e-04
Loss = 8.2879e-04, PNorm = 38.0165, GNorm = 2.2529, lr_0 = 1.0200e-04
Loss = 8.5594e-04, PNorm = 38.0184, GNorm = 4.3882, lr_0 = 1.0200e-04
Loss = 9.3329e-04, PNorm = 38.0190, GNorm = 4.1693, lr_0 = 1.0200e-04
Loss = 7.8658e-04, PNorm = 38.0205, GNorm = 3.2743, lr_0 = 1.0200e-04
Loss = 8.1120e-04, PNorm = 38.0221, GNorm = 1.1182, lr_0 = 1.0200e-04
Loss = 7.5228e-04, PNorm = 38.0237, GNorm = 1.4125, lr_0 = 1.0200e-04
Loss = 7.4763e-04, PNorm = 38.0254, GNorm = 1.1754, lr_0 = 1.0200e-04
Loss = 6.5799e-04, PNorm = 38.0277, GNorm = 0.8946, lr_0 = 1.0200e-04
Loss = 7.5499e-04, PNorm = 38.0299, GNorm = 1.3987, lr_0 = 1.0200e-04
Loss = 7.1122e-04, PNorm = 38.0324, GNorm = 1.1286, lr_0 = 1.0200e-04
Validation rmse logD = 0.560666
Validation R2 logD = 0.777518
Validation rmse logP = 0.482809
Validation R2 logP = 0.931768
Epoch 60
Train function
Loss = 7.5054e-04, PNorm = 38.0339, GNorm = 1.1570, lr_0 = 1.0200e-04
Loss = 6.9885e-04, PNorm = 38.0357, GNorm = 1.0616, lr_0 = 1.0200e-04
Loss = 5.9322e-04, PNorm = 38.0373, GNorm = 4.6048, lr_0 = 1.0200e-04
Loss = 6.5884e-04, PNorm = 38.0383, GNorm = 2.1631, lr_0 = 1.0200e-04
Loss = 6.9266e-04, PNorm = 38.0389, GNorm = 2.1361, lr_0 = 1.0200e-04
Loss = 8.7646e-04, PNorm = 38.0402, GNorm = 2.2428, lr_0 = 1.0200e-04
Loss = 5.5810e-04, PNorm = 38.0414, GNorm = 2.0055, lr_0 = 1.0200e-04
Loss = 5.6109e-04, PNorm = 38.0427, GNorm = 1.2845, lr_0 = 1.0200e-04
Loss = 7.5618e-04, PNorm = 38.0443, GNorm = 1.3242, lr_0 = 1.0200e-04
Loss = 7.3550e-04, PNorm = 38.0449, GNorm = 2.2779, lr_0 = 1.0200e-04
Loss = 6.1041e-04, PNorm = 38.0461, GNorm = 2.1096, lr_0 = 1.0200e-04
Loss = 7.3721e-04, PNorm = 38.0475, GNorm = 1.1993, lr_0 = 1.0200e-04
Loss = 6.8116e-04, PNorm = 38.0482, GNorm = 2.3911, lr_0 = 1.0200e-04
Loss = 6.4689e-04, PNorm = 38.0505, GNorm = 2.2527, lr_0 = 1.0200e-04
Loss = 6.9776e-04, PNorm = 38.0520, GNorm = 1.9636, lr_0 = 1.0200e-04
Loss = 9.6501e-04, PNorm = 38.0538, GNorm = 3.5709, lr_0 = 1.0200e-04
Loss = 6.1039e-04, PNorm = 38.0558, GNorm = 1.5891, lr_0 = 1.0200e-04
Loss = 6.3619e-04, PNorm = 38.0589, GNorm = 1.9671, lr_0 = 1.0200e-04
Loss = 7.3335e-04, PNorm = 38.0607, GNorm = 2.3817, lr_0 = 1.0200e-04
Loss = 6.5340e-04, PNorm = 38.0626, GNorm = 1.3157, lr_0 = 1.0200e-04
Loss = 7.6325e-04, PNorm = 38.0643, GNorm = 2.8496, lr_0 = 1.0200e-04
Loss = 6.2409e-04, PNorm = 38.0658, GNorm = 1.3828, lr_0 = 1.0200e-04
Loss = 7.0246e-04, PNorm = 38.0677, GNorm = 1.7238, lr_0 = 1.0200e-04
Validation rmse logD = 0.550947
Validation R2 logD = 0.785165
Validation rmse logP = 0.489985
Validation R2 logP = 0.929724
Epoch 61
Train function
Loss = 6.4098e-04, PNorm = 38.0687, GNorm = 3.9595, lr_0 = 1.0200e-04
Loss = 6.6026e-04, PNorm = 38.0701, GNorm = 0.8204, lr_0 = 1.0200e-04
Loss = 7.4332e-04, PNorm = 38.0721, GNorm = 4.4543, lr_0 = 1.0200e-04
Loss = 8.8663e-04, PNorm = 38.0738, GNorm = 1.4073, lr_0 = 1.0200e-04
Loss = 6.6293e-04, PNorm = 38.0756, GNorm = 1.8263, lr_0 = 1.0200e-04
Loss = 6.4980e-04, PNorm = 38.0771, GNorm = 1.5836, lr_0 = 1.0200e-04
Loss = 6.3591e-04, PNorm = 38.0792, GNorm = 2.1792, lr_0 = 1.0200e-04
Loss = 8.5231e-04, PNorm = 38.0809, GNorm = 4.2891, lr_0 = 1.0200e-04
Loss = 7.2546e-04, PNorm = 38.0825, GNorm = 1.2556, lr_0 = 1.0200e-04
Loss = 6.3825e-04, PNorm = 38.0842, GNorm = 2.7338, lr_0 = 1.0200e-04
Loss = 8.1311e-04, PNorm = 38.0860, GNorm = 3.2442, lr_0 = 1.0200e-04
Loss = 6.8749e-04, PNorm = 38.0867, GNorm = 0.8596, lr_0 = 1.0200e-04
Loss = 8.7904e-04, PNorm = 38.0895, GNorm = 1.4630, lr_0 = 1.0200e-04
Loss = 8.5649e-04, PNorm = 38.0915, GNorm = 4.1633, lr_0 = 1.0200e-04
Loss = 9.5002e-04, PNorm = 38.0927, GNorm = 1.9389, lr_0 = 1.0200e-04
Loss = 1.1669e-03, PNorm = 38.0940, GNorm = 2.0115, lr_0 = 1.0200e-04
Loss = 9.4146e-04, PNorm = 38.0955, GNorm = 2.2715, lr_0 = 1.0200e-04
Loss = 7.9858e-04, PNorm = 38.0976, GNorm = 1.1820, lr_0 = 1.0200e-04
Loss = 5.7757e-04, PNorm = 38.0992, GNorm = 2.0643, lr_0 = 1.0200e-04
Loss = 6.7888e-04, PNorm = 38.1007, GNorm = 1.7492, lr_0 = 1.0200e-04
Loss = 6.5627e-04, PNorm = 38.1036, GNorm = 1.4569, lr_0 = 1.0200e-04
Loss = 6.6974e-04, PNorm = 38.1056, GNorm = 1.8955, lr_0 = 1.0200e-04
Validation rmse logD = 0.554447
Validation R2 logD = 0.782426
Validation rmse logP = 0.477982
Validation R2 logP = 0.933125
Epoch 62
Train function
Loss = 6.7527e-04, PNorm = 38.1069, GNorm = 1.3357, lr_0 = 1.0200e-04
Loss = 6.4239e-04, PNorm = 38.1076, GNorm = 0.9105, lr_0 = 1.0200e-04
Loss = 6.9778e-04, PNorm = 38.1091, GNorm = 1.9922, lr_0 = 1.0200e-04
Loss = 7.8808e-04, PNorm = 38.1107, GNorm = 2.2102, lr_0 = 1.0200e-04
Loss = 8.1815e-04, PNorm = 38.1125, GNorm = 0.9307, lr_0 = 1.0200e-04
Loss = 8.6310e-04, PNorm = 38.1157, GNorm = 4.4553, lr_0 = 1.0200e-04
Loss = 7.4349e-04, PNorm = 38.1181, GNorm = 2.0766, lr_0 = 1.0200e-04
Loss = 5.9738e-04, PNorm = 38.1197, GNorm = 2.3915, lr_0 = 1.0200e-04
Loss = 9.8911e-04, PNorm = 38.1217, GNorm = 4.8715, lr_0 = 1.0200e-04
Loss = 7.4734e-04, PNorm = 38.1233, GNorm = 1.2158, lr_0 = 1.0200e-04
Loss = 7.6393e-04, PNorm = 38.1247, GNorm = 1.9370, lr_0 = 1.0200e-04
Loss = 6.4759e-04, PNorm = 38.1261, GNorm = 1.4007, lr_0 = 1.0200e-04
Loss = 6.3419e-04, PNorm = 38.1277, GNorm = 1.6912, lr_0 = 1.0200e-04
Loss = 7.3628e-04, PNorm = 38.1288, GNorm = 3.5547, lr_0 = 1.0200e-04
Loss = 6.2137e-04, PNorm = 38.1295, GNorm = 1.7263, lr_0 = 1.0200e-04
Loss = 6.2152e-04, PNorm = 38.1308, GNorm = 1.3589, lr_0 = 1.0200e-04
Loss = 5.8356e-04, PNorm = 38.1319, GNorm = 0.7697, lr_0 = 1.0200e-04
Loss = 6.7837e-04, PNorm = 38.1334, GNorm = 1.9307, lr_0 = 1.0200e-04
Loss = 7.7428e-04, PNorm = 38.1348, GNorm = 3.3132, lr_0 = 1.0200e-04
Loss = 8.4643e-04, PNorm = 38.1365, GNorm = 0.6992, lr_0 = 1.0200e-04
Loss = 7.0445e-04, PNorm = 38.1376, GNorm = 0.9638, lr_0 = 1.0200e-04
Loss = 7.5370e-04, PNorm = 38.1384, GNorm = 1.4360, lr_0 = 1.0200e-04
Loss = 7.3362e-04, PNorm = 38.1397, GNorm = 1.3634, lr_0 = 1.0200e-04
Validation rmse logD = 0.555675
Validation R2 logD = 0.781462
Validation rmse logP = 0.494105
Validation R2 logP = 0.928538
Epoch 63
Train function
Loss = 6.0492e-04, PNorm = 38.1420, GNorm = 1.1368, lr_0 = 1.0200e-04
Loss = 8.1048e-04, PNorm = 38.1438, GNorm = 0.7272, lr_0 = 1.0200e-04
Loss = 6.1275e-04, PNorm = 38.1463, GNorm = 0.8367, lr_0 = 1.0200e-04
Loss = 7.3573e-04, PNorm = 38.1481, GNorm = 1.2655, lr_0 = 1.0200e-04
Loss = 6.1000e-04, PNorm = 38.1499, GNorm = 1.0355, lr_0 = 1.0200e-04
Loss = 5.1504e-04, PNorm = 38.1517, GNorm = 1.1823, lr_0 = 1.0200e-04
Loss = 5.8374e-04, PNorm = 38.1531, GNorm = 1.3348, lr_0 = 1.0200e-04
Loss = 5.3814e-04, PNorm = 38.1546, GNorm = 1.6144, lr_0 = 1.0200e-04
Loss = 5.4649e-04, PNorm = 38.1562, GNorm = 0.9841, lr_0 = 1.0200e-04
Loss = 8.4452e-04, PNorm = 38.1578, GNorm = 2.8929, lr_0 = 1.0200e-04
Loss = 6.9599e-04, PNorm = 38.1594, GNorm = 1.5016, lr_0 = 1.0200e-04
Loss = 7.3488e-04, PNorm = 38.1622, GNorm = 1.8192, lr_0 = 1.0200e-04
Loss = 6.7364e-04, PNorm = 38.1635, GNorm = 1.5150, lr_0 = 1.0200e-04
Loss = 7.2109e-04, PNorm = 38.1651, GNorm = 1.6724, lr_0 = 1.0200e-04
Loss = 5.6796e-04, PNorm = 38.1669, GNorm = 1.8136, lr_0 = 1.0200e-04
Loss = 6.2242e-04, PNorm = 38.1684, GNorm = 2.4956, lr_0 = 1.0200e-04
Loss = 6.0986e-04, PNorm = 38.1693, GNorm = 2.4799, lr_0 = 1.0200e-04
Loss = 6.1644e-04, PNorm = 38.1702, GNorm = 2.9219, lr_0 = 1.0200e-04
Loss = 6.7329e-04, PNorm = 38.1717, GNorm = 2.3293, lr_0 = 1.0200e-04
Loss = 6.7060e-04, PNorm = 38.1732, GNorm = 2.8664, lr_0 = 1.0200e-04
Loss = 6.7459e-04, PNorm = 38.1755, GNorm = 1.1272, lr_0 = 1.0200e-04
Loss = 5.5220e-04, PNorm = 38.1773, GNorm = 0.9062, lr_0 = 1.0200e-04
Loss = 5.5549e-04, PNorm = 38.1787, GNorm = 1.3718, lr_0 = 1.0200e-04
Loss = 1.3669e-03, PNorm = 38.1789, GNorm = 1.8670, lr_0 = 1.0200e-04
Validation rmse logD = 0.565621
Validation R2 logD = 0.773568
Validation rmse logP = 0.477522
Validation R2 logP = 0.933254
Epoch 64
Train function
Loss = 5.2296e-04, PNorm = 38.1805, GNorm = 0.8808, lr_0 = 1.0200e-04
Loss = 5.0798e-04, PNorm = 38.1818, GNorm = 0.7821, lr_0 = 1.0200e-04
Loss = 5.9083e-04, PNorm = 38.1834, GNorm = 0.7118, lr_0 = 1.0200e-04
Loss = 6.5053e-04, PNorm = 38.1845, GNorm = 3.7409, lr_0 = 1.0200e-04
Loss = 5.8722e-04, PNorm = 38.1863, GNorm = 1.6857, lr_0 = 1.0200e-04
Loss = 7.0946e-04, PNorm = 38.1876, GNorm = 2.1069, lr_0 = 1.0200e-04
Loss = 6.4163e-04, PNorm = 38.1895, GNorm = 3.4922, lr_0 = 1.0200e-04
Loss = 5.4499e-04, PNorm = 38.1912, GNorm = 1.5803, lr_0 = 1.0200e-04
Loss = 6.7272e-04, PNorm = 38.1926, GNorm = 2.4183, lr_0 = 1.0200e-04
Loss = 6.3043e-04, PNorm = 38.1942, GNorm = 0.7947, lr_0 = 1.0200e-04
Loss = 6.4867e-04, PNorm = 38.1951, GNorm = 1.2978, lr_0 = 1.0200e-04
Loss = 5.5242e-04, PNorm = 38.1964, GNorm = 1.7894, lr_0 = 1.0200e-04
Loss = 7.8519e-04, PNorm = 38.1981, GNorm = 2.2004, lr_0 = 1.0200e-04
Loss = 7.8838e-04, PNorm = 38.2000, GNorm = 1.3696, lr_0 = 1.0200e-04
Loss = 4.8129e-04, PNorm = 38.2008, GNorm = 1.3295, lr_0 = 1.0200e-04
Loss = 6.8218e-04, PNorm = 38.2016, GNorm = 2.1133, lr_0 = 1.0200e-04
Loss = 6.5820e-04, PNorm = 38.2027, GNorm = 3.7238, lr_0 = 1.0200e-04
Loss = 8.3843e-04, PNorm = 38.2049, GNorm = 1.3112, lr_0 = 1.0200e-04
Loss = 7.2718e-04, PNorm = 38.2065, GNorm = 1.6065, lr_0 = 1.0200e-04
Loss = 5.4069e-04, PNorm = 38.2086, GNorm = 1.1205, lr_0 = 1.0200e-04
Loss = 7.2506e-04, PNorm = 38.2104, GNorm = 0.8788, lr_0 = 1.0200e-04
Loss = 7.3478e-04, PNorm = 38.2125, GNorm = 2.1245, lr_0 = 1.0200e-04
Validation rmse logD = 0.547484
Validation R2 logD = 0.787856
Validation rmse logP = 0.498376
Validation R2 logP = 0.927297
Epoch 65
Train function
Loss = 6.9994e-04, PNorm = 38.2143, GNorm = 1.7861, lr_0 = 1.0200e-04
Loss = 5.9668e-04, PNorm = 38.2152, GNorm = 0.7834, lr_0 = 1.0200e-04
Loss = 5.8090e-04, PNorm = 38.2156, GNorm = 0.7882, lr_0 = 1.0200e-04
Loss = 5.8016e-04, PNorm = 38.2173, GNorm = 1.1806, lr_0 = 1.0200e-04
Loss = 5.5109e-04, PNorm = 38.2189, GNorm = 1.2334, lr_0 = 1.0200e-04
Loss = 6.2573e-04, PNorm = 38.2202, GNorm = 2.8099, lr_0 = 1.0200e-04
Loss = 6.4067e-04, PNorm = 38.2214, GNorm = 1.9748, lr_0 = 1.0200e-04
Loss = 5.5404e-04, PNorm = 38.2234, GNorm = 1.9825, lr_0 = 1.0200e-04
Loss = 6.2670e-04, PNorm = 38.2256, GNorm = 1.2652, lr_0 = 1.0200e-04
Loss = 6.2052e-04, PNorm = 38.2272, GNorm = 2.0420, lr_0 = 1.0200e-04
Loss = 6.0395e-04, PNorm = 38.2287, GNorm = 1.3699, lr_0 = 1.0200e-04
Loss = 5.2267e-04, PNorm = 38.2303, GNorm = 1.2661, lr_0 = 1.0200e-04
Loss = 6.8241e-04, PNorm = 38.2320, GNorm = 2.8105, lr_0 = 1.0200e-04
Loss = 7.0052e-04, PNorm = 38.2336, GNorm = 1.7442, lr_0 = 1.0200e-04
Loss = 6.7367e-04, PNorm = 38.2349, GNorm = 4.0538, lr_0 = 1.0200e-04
Loss = 6.4345e-04, PNorm = 38.2365, GNorm = 1.6976, lr_0 = 1.0200e-04
Loss = 5.5645e-04, PNorm = 38.2377, GNorm = 1.3643, lr_0 = 1.0200e-04
Loss = 6.2577e-04, PNorm = 38.2383, GNorm = 0.9233, lr_0 = 1.0200e-04
Loss = 6.4345e-04, PNorm = 38.2403, GNorm = 1.3681, lr_0 = 1.0200e-04
Loss = 6.9872e-04, PNorm = 38.2421, GNorm = 2.7957, lr_0 = 1.0200e-04
Loss = 8.3607e-04, PNorm = 38.2437, GNorm = 4.1760, lr_0 = 1.0200e-04
Loss = 6.9005e-04, PNorm = 38.2451, GNorm = 2.9451, lr_0 = 1.0200e-04
Loss = 5.7548e-04, PNorm = 38.2471, GNorm = 1.8385, lr_0 = 1.0200e-04
Validation rmse logD = 0.547494
Validation R2 logD = 0.787849
Validation rmse logP = 0.485220
Validation R2 logP = 0.931085
Epoch 66
Train function
Loss = 5.8024e-04, PNorm = 38.2489, GNorm = 3.0468, lr_0 = 1.0200e-04
Loss = 7.0138e-04, PNorm = 38.2510, GNorm = 1.0040, lr_0 = 1.0200e-04
Loss = 4.7865e-04, PNorm = 38.2520, GNorm = 1.3761, lr_0 = 1.0200e-04
Loss = 4.8164e-04, PNorm = 38.2535, GNorm = 1.2514, lr_0 = 1.0200e-04
Loss = 5.8166e-04, PNorm = 38.2545, GNorm = 0.8384, lr_0 = 1.0200e-04
Loss = 6.6093e-04, PNorm = 38.2558, GNorm = 1.6731, lr_0 = 1.0200e-04
Loss = 4.7543e-04, PNorm = 38.2577, GNorm = 1.2633, lr_0 = 1.0200e-04
Loss = 5.8541e-04, PNorm = 38.2595, GNorm = 1.1496, lr_0 = 1.0200e-04
Loss = 6.0596e-04, PNorm = 38.2611, GNorm = 1.7309, lr_0 = 1.0200e-04
Loss = 6.5164e-04, PNorm = 38.2617, GNorm = 1.1474, lr_0 = 1.0200e-04
Loss = 5.7828e-04, PNorm = 38.2625, GNorm = 0.9600, lr_0 = 1.0200e-04
Loss = 6.5304e-04, PNorm = 38.2644, GNorm = 0.9997, lr_0 = 1.0200e-04
Loss = 6.4205e-04, PNorm = 38.2662, GNorm = 2.5418, lr_0 = 1.0200e-04
Loss = 7.2114e-04, PNorm = 38.2673, GNorm = 3.2911, lr_0 = 1.0200e-04
Loss = 8.0774e-04, PNorm = 38.2684, GNorm = 3.2414, lr_0 = 1.0200e-04
Loss = 7.9537e-04, PNorm = 38.2700, GNorm = 1.3640, lr_0 = 1.0200e-04
Loss = 5.3670e-04, PNorm = 38.2717, GNorm = 1.0459, lr_0 = 1.0200e-04
Loss = 6.2163e-04, PNorm = 38.2734, GNorm = 1.8781, lr_0 = 1.0200e-04
Loss = 5.8776e-04, PNorm = 38.2747, GNorm = 2.3519, lr_0 = 1.0200e-04
Loss = 6.6727e-04, PNorm = 38.2760, GNorm = 1.9186, lr_0 = 1.0200e-04
Loss = 6.9104e-04, PNorm = 38.2767, GNorm = 2.3142, lr_0 = 1.0200e-04
Loss = 6.2785e-04, PNorm = 38.2788, GNorm = 1.3070, lr_0 = 1.0200e-04
Validation rmse logD = 0.546185
Validation R2 logD = 0.788862
Validation rmse logP = 0.475201
Validation R2 logP = 0.933901
Epoch 67
Train function
Loss = 7.7382e-04, PNorm = 38.2802, GNorm = 2.5556, lr_0 = 1.0200e-04
Loss = 6.4686e-04, PNorm = 38.2813, GNorm = 2.4441, lr_0 = 1.0200e-04
Loss = 5.8475e-04, PNorm = 38.2827, GNorm = 1.1917, lr_0 = 1.0200e-04
Loss = 5.9681e-04, PNorm = 38.2845, GNorm = 1.4932, lr_0 = 1.0200e-04
Loss = 5.0092e-04, PNorm = 38.2862, GNorm = 1.0782, lr_0 = 1.0200e-04
Loss = 6.6449e-04, PNorm = 38.2870, GNorm = 2.5996, lr_0 = 1.0200e-04
Loss = 6.7274e-04, PNorm = 38.2880, GNorm = 1.2490, lr_0 = 1.0200e-04
Loss = 4.8475e-04, PNorm = 38.2894, GNorm = 1.8376, lr_0 = 1.0200e-04
Loss = 7.5459e-04, PNorm = 38.2921, GNorm = 3.6341, lr_0 = 1.0200e-04
Loss = 8.0582e-04, PNorm = 38.2928, GNorm = 2.1260, lr_0 = 1.0200e-04
Loss = 6.7205e-04, PNorm = 38.2938, GNorm = 2.3228, lr_0 = 1.0200e-04
Loss = 5.7771e-04, PNorm = 38.2958, GNorm = 3.4207, lr_0 = 1.0200e-04
Loss = 6.8231e-04, PNorm = 38.2992, GNorm = 1.4434, lr_0 = 1.0200e-04
Loss = 5.1777e-04, PNorm = 38.3023, GNorm = 1.3073, lr_0 = 1.0200e-04
Loss = 6.7263e-04, PNorm = 38.3045, GNorm = 1.3375, lr_0 = 1.0200e-04
Loss = 6.8520e-04, PNorm = 38.3072, GNorm = 2.3815, lr_0 = 1.0200e-04
Loss = 5.6133e-04, PNorm = 38.3093, GNorm = 1.5735, lr_0 = 1.0200e-04
Loss = 5.9311e-04, PNorm = 38.3105, GNorm = 2.1563, lr_0 = 1.0200e-04
Loss = 5.6311e-04, PNorm = 38.3124, GNorm = 0.8921, lr_0 = 1.0200e-04
Loss = 6.3731e-04, PNorm = 38.3135, GNorm = 1.4611, lr_0 = 1.0200e-04
Loss = 5.9162e-04, PNorm = 38.3146, GNorm = 1.0106, lr_0 = 1.0200e-04
Loss = 6.4097e-04, PNorm = 38.3162, GNorm = 2.5676, lr_0 = 1.0200e-04
Loss = 5.8933e-04, PNorm = 38.3187, GNorm = 1.0552, lr_0 = 1.0200e-04
Validation rmse logD = 0.561212
Validation R2 logD = 0.777084
Validation rmse logP = 0.481888
Validation R2 logP = 0.932028
Epoch 68
Train function
Loss = 5.5740e-04, PNorm = 38.3199, GNorm = 1.3725, lr_0 = 1.0200e-04
Loss = 4.3888e-04, PNorm = 38.3213, GNorm = 1.1093, lr_0 = 1.0200e-04
Loss = 7.2783e-04, PNorm = 38.3230, GNorm = 1.5186, lr_0 = 1.0200e-04
Loss = 6.6388e-04, PNorm = 38.3239, GNorm = 2.1052, lr_0 = 1.0200e-04
Loss = 5.6665e-04, PNorm = 38.3252, GNorm = 1.2845, lr_0 = 1.0200e-04
Loss = 4.5859e-04, PNorm = 38.3266, GNorm = 1.5044, lr_0 = 1.0200e-04
Loss = 6.0609e-04, PNorm = 38.3284, GNorm = 1.5597, lr_0 = 1.0200e-04
Loss = 5.5424e-04, PNorm = 38.3300, GNorm = 1.6728, lr_0 = 1.0200e-04
Loss = 6.3380e-04, PNorm = 38.3314, GNorm = 1.8425, lr_0 = 1.0200e-04
Loss = 5.4559e-04, PNorm = 38.3327, GNorm = 1.7407, lr_0 = 1.0200e-04
Loss = 6.0413e-04, PNorm = 38.3341, GNorm = 2.6368, lr_0 = 1.0200e-04
Loss = 6.3873e-04, PNorm = 38.3363, GNorm = 1.9053, lr_0 = 1.0200e-04
Loss = 6.3716e-04, PNorm = 38.3378, GNorm = 2.4450, lr_0 = 1.0200e-04
Loss = 5.9672e-04, PNorm = 38.3384, GNorm = 1.1797, lr_0 = 1.0200e-04
Loss = 5.3355e-04, PNorm = 38.3405, GNorm = 1.1646, lr_0 = 1.0200e-04
Loss = 5.7681e-04, PNorm = 38.3423, GNorm = 1.8849, lr_0 = 1.0200e-04
Loss = 7.8884e-04, PNorm = 38.3429, GNorm = 3.0291, lr_0 = 1.0200e-04
Loss = 7.6493e-04, PNorm = 38.3433, GNorm = 1.1444, lr_0 = 1.0200e-04
Loss = 6.9178e-04, PNorm = 38.3457, GNorm = 4.0905, lr_0 = 1.0200e-04
Loss = 7.3075e-04, PNorm = 38.3476, GNorm = 1.2354, lr_0 = 1.0200e-04
Loss = 5.8966e-04, PNorm = 38.3489, GNorm = 0.9967, lr_0 = 1.0200e-04
Loss = 5.8152e-04, PNorm = 38.3510, GNorm = 1.6725, lr_0 = 1.0200e-04
Validation rmse logD = 0.558256
Validation R2 logD = 0.779426
Validation rmse logP = 0.474827
Validation R2 logP = 0.934005
Epoch 69
Train function
Loss = 4.8822e-04, PNorm = 38.3531, GNorm = 1.9899, lr_0 = 1.0200e-04
Loss = 6.6047e-04, PNorm = 38.3545, GNorm = 2.1416, lr_0 = 1.0200e-04
Loss = 6.8378e-04, PNorm = 38.3557, GNorm = 2.8530, lr_0 = 1.0200e-04
Loss = 6.4131e-04, PNorm = 38.3571, GNorm = 1.4488, lr_0 = 1.0200e-04
Loss = 6.7789e-04, PNorm = 38.3585, GNorm = 1.3223, lr_0 = 1.0200e-04
Loss = 5.5266e-04, PNorm = 38.3597, GNorm = 2.8739, lr_0 = 1.0200e-04
Loss = 6.8264e-04, PNorm = 38.3611, GNorm = 1.0506, lr_0 = 1.0200e-04
Loss = 7.9380e-04, PNorm = 38.3636, GNorm = 4.3096, lr_0 = 1.0200e-04
Loss = 7.0051e-04, PNorm = 38.3656, GNorm = 1.7977, lr_0 = 1.0200e-04
Loss = 4.9829e-04, PNorm = 38.3678, GNorm = 3.8322, lr_0 = 1.0200e-04
Loss = 7.0804e-04, PNorm = 38.3701, GNorm = 0.7805, lr_0 = 1.0200e-04
Loss = 4.8181e-04, PNorm = 38.3713, GNorm = 2.0064, lr_0 = 1.0200e-04
Loss = 6.0173e-04, PNorm = 38.3725, GNorm = 1.0456, lr_0 = 1.0200e-04
Loss = 6.2072e-04, PNorm = 38.3738, GNorm = 0.8130, lr_0 = 1.0200e-04
Loss = 6.7765e-04, PNorm = 38.3755, GNorm = 4.7435, lr_0 = 1.0200e-04
Loss = 6.0425e-04, PNorm = 38.3766, GNorm = 1.0896, lr_0 = 1.0200e-04
Loss = 5.8252e-04, PNorm = 38.3775, GNorm = 2.5004, lr_0 = 1.0200e-04
Loss = 4.7249e-04, PNorm = 38.3792, GNorm = 1.7077, lr_0 = 1.0200e-04
Loss = 5.7696e-04, PNorm = 38.3812, GNorm = 0.7914, lr_0 = 1.0200e-04
Loss = 5.0249e-04, PNorm = 38.3827, GNorm = 2.4301, lr_0 = 1.0200e-04
Loss = 5.3629e-04, PNorm = 38.3838, GNorm = 1.9213, lr_0 = 1.0200e-04
Loss = 6.2540e-04, PNorm = 38.3850, GNorm = 2.1694, lr_0 = 1.0200e-04
Loss = 6.1943e-04, PNorm = 38.3861, GNorm = 3.3119, lr_0 = 1.0200e-04
Validation rmse logD = 0.562863
Validation R2 logD = 0.775770
Validation rmse logP = 0.492869
Validation R2 logP = 0.928895
Epoch 70
Train function
Loss = 5.9483e-04, PNorm = 38.3869, GNorm = 1.0423, lr_0 = 1.0200e-04
Loss = 5.4004e-04, PNorm = 38.3888, GNorm = 1.6209, lr_0 = 1.0200e-04
Loss = 5.6118e-04, PNorm = 38.3912, GNorm = 1.2077, lr_0 = 1.0200e-04
Loss = 5.8682e-04, PNorm = 38.3930, GNorm = 3.5223, lr_0 = 1.0200e-04
Loss = 5.3209e-04, PNorm = 38.3945, GNorm = 1.7479, lr_0 = 1.0200e-04
Loss = 5.1356e-04, PNorm = 38.3963, GNorm = 0.7862, lr_0 = 1.0200e-04
Loss = 4.5962e-04, PNorm = 38.3981, GNorm = 1.3715, lr_0 = 1.0200e-04
Loss = 5.5427e-04, PNorm = 38.3995, GNorm = 1.5442, lr_0 = 1.0200e-04
Loss = 5.7908e-04, PNorm = 38.4002, GNorm = 1.5165, lr_0 = 1.0200e-04
Loss = 7.2746e-04, PNorm = 38.4009, GNorm = 1.5880, lr_0 = 1.0200e-04
Loss = 6.1071e-04, PNorm = 38.4014, GNorm = 0.9240, lr_0 = 1.0200e-04
Loss = 5.9414e-04, PNorm = 38.4022, GNorm = 1.6793, lr_0 = 1.0200e-04
Loss = 5.7840e-04, PNorm = 38.4036, GNorm = 2.3007, lr_0 = 1.0200e-04
Loss = 6.2120e-04, PNorm = 38.4050, GNorm = 2.1032, lr_0 = 1.0200e-04
Loss = 5.2640e-04, PNorm = 38.4064, GNorm = 1.0012, lr_0 = 1.0200e-04
Loss = 5.4204e-04, PNorm = 38.4082, GNorm = 1.1266, lr_0 = 1.0200e-04
Loss = 5.2375e-04, PNorm = 38.4100, GNorm = 0.9683, lr_0 = 1.0200e-04
Loss = 4.7500e-04, PNorm = 38.4112, GNorm = 0.9576, lr_0 = 1.0200e-04
Loss = 6.8652e-04, PNorm = 38.4120, GNorm = 2.7467, lr_0 = 1.0200e-04
Loss = 6.3844e-04, PNorm = 38.4138, GNorm = 1.0930, lr_0 = 1.0200e-04
Loss = 6.5686e-04, PNorm = 38.4154, GNorm = 1.1732, lr_0 = 1.0200e-04
Loss = 4.9136e-04, PNorm = 38.4174, GNorm = 1.3072, lr_0 = 1.0200e-04
Validation rmse logD = 0.555907
Validation R2 logD = 0.781279
Validation rmse logP = 0.477601
Validation R2 logP = 0.933232
Epoch 71
Train function
Loss = 1.3672e-03, PNorm = 38.4196, GNorm = 1.8500, lr_0 = 1.0200e-04
Loss = 4.4877e-04, PNorm = 38.4214, GNorm = 1.3555, lr_0 = 1.0200e-04
Loss = 5.4119e-04, PNorm = 38.4224, GNorm = 1.2433, lr_0 = 1.0200e-04
Loss = 4.2434e-04, PNorm = 38.4237, GNorm = 0.7902, lr_0 = 1.0200e-04
Loss = 5.2533e-04, PNorm = 38.4255, GNorm = 1.7595, lr_0 = 1.0200e-04
Loss = 5.4658e-04, PNorm = 38.4269, GNorm = 1.9188, lr_0 = 1.0200e-04
Loss = 5.0449e-04, PNorm = 38.4286, GNorm = 2.6283, lr_0 = 1.0200e-04
Loss = 6.0452e-04, PNorm = 38.4310, GNorm = 0.6938, lr_0 = 1.0200e-04
Loss = 4.6213e-04, PNorm = 38.4324, GNorm = 2.4809, lr_0 = 1.0200e-04
Loss = 6.4507e-04, PNorm = 38.4332, GNorm = 1.8585, lr_0 = 1.0200e-04
Loss = 6.0655e-04, PNorm = 38.4345, GNorm = 3.2691, lr_0 = 1.0200e-04
Loss = 5.3237e-04, PNorm = 38.4362, GNorm = 2.2744, lr_0 = 1.0200e-04
Loss = 4.3275e-04, PNorm = 38.4377, GNorm = 0.9421, lr_0 = 1.0200e-04
Loss = 5.0661e-04, PNorm = 38.4396, GNorm = 1.4691, lr_0 = 1.0200e-04
Loss = 5.5343e-04, PNorm = 38.4415, GNorm = 2.7541, lr_0 = 1.0200e-04
Loss = 5.4288e-04, PNorm = 38.4424, GNorm = 1.0296, lr_0 = 1.0200e-04
Loss = 6.1325e-04, PNorm = 38.4439, GNorm = 1.2062, lr_0 = 1.0200e-04
Loss = 6.1434e-04, PNorm = 38.4458, GNorm = 4.4074, lr_0 = 1.0200e-04
Loss = 5.8117e-04, PNorm = 38.4461, GNorm = 1.8534, lr_0 = 1.0200e-04
Loss = 6.1482e-04, PNorm = 38.4470, GNorm = 3.3412, lr_0 = 1.0200e-04
Loss = 5.8471e-04, PNorm = 38.4486, GNorm = 1.6944, lr_0 = 1.0200e-04
Loss = 6.5553e-04, PNorm = 38.4508, GNorm = 1.8732, lr_0 = 1.0200e-04
Loss = 4.9168e-04, PNorm = 38.4512, GNorm = 1.4544, lr_0 = 1.0200e-04
Validation rmse logD = 0.628383
Validation R2 logD = 0.720530
Validation rmse logP = 0.472670
Validation R2 logP = 0.934603
Epoch 72
Train function
Loss = 6.0025e-04, PNorm = 38.4537, GNorm = 2.5944, lr_0 = 1.0200e-04
Loss = 5.2655e-04, PNorm = 38.4556, GNorm = 1.6874, lr_0 = 1.0200e-04
Loss = 4.7103e-04, PNorm = 38.4581, GNorm = 0.7029, lr_0 = 1.0200e-04
Loss = 4.9252e-04, PNorm = 38.4596, GNorm = 0.9162, lr_0 = 1.0200e-04
Loss = 6.2932e-04, PNorm = 38.4609, GNorm = 2.5530, lr_0 = 1.0200e-04
Loss = 6.0024e-04, PNorm = 38.4622, GNorm = 0.7096, lr_0 = 1.0200e-04
Loss = 6.5184e-04, PNorm = 38.4641, GNorm = 2.0153, lr_0 = 1.0200e-04
Loss = 4.5226e-04, PNorm = 38.4655, GNorm = 1.3425, lr_0 = 1.0200e-04
Loss = 6.0954e-04, PNorm = 38.4659, GNorm = 3.5721, lr_0 = 1.0200e-04
Loss = 5.2914e-04, PNorm = 38.4670, GNorm = 2.1002, lr_0 = 1.0200e-04
Loss = 6.5002e-04, PNorm = 38.4685, GNorm = 1.9516, lr_0 = 1.0200e-04
Loss = 5.8615e-04, PNorm = 38.4692, GNorm = 2.6842, lr_0 = 1.0200e-04
Loss = 6.5634e-04, PNorm = 38.4712, GNorm = 2.2565, lr_0 = 1.0200e-04
Loss = 6.4833e-04, PNorm = 38.4733, GNorm = 1.1100, lr_0 = 1.0200e-04
Loss = 5.8010e-04, PNorm = 38.4747, GNorm = 1.9128, lr_0 = 1.0200e-04
Loss = 5.3292e-04, PNorm = 38.4774, GNorm = 1.0839, lr_0 = 1.0200e-04
Loss = 6.6859e-04, PNorm = 38.4785, GNorm = 2.8539, lr_0 = 1.0200e-04
Loss = 5.6947e-04, PNorm = 38.4799, GNorm = 1.6622, lr_0 = 1.0200e-04
Loss = 5.5731e-04, PNorm = 38.4815, GNorm = 1.5410, lr_0 = 1.0200e-04
Loss = 5.8615e-04, PNorm = 38.4832, GNorm = 1.3402, lr_0 = 1.0200e-04
Loss = 4.6195e-04, PNorm = 38.4845, GNorm = 0.9496, lr_0 = 1.0200e-04
Loss = 5.0129e-04, PNorm = 38.4863, GNorm = 1.1421, lr_0 = 1.0200e-04
Loss = 4.6443e-04, PNorm = 38.4879, GNorm = 1.0878, lr_0 = 1.0200e-04
Validation rmse logD = 0.555178
Validation R2 logD = 0.781852
Validation rmse logP = 0.476062
Validation R2 logP = 0.933662
Epoch 73
Train function
Loss = 3.8232e-04, PNorm = 38.4885, GNorm = 1.9970, lr_0 = 1.0200e-04
Loss = 5.6430e-04, PNorm = 38.4897, GNorm = 1.9644, lr_0 = 1.0200e-04
Loss = 5.0557e-04, PNorm = 38.4913, GNorm = 1.4732, lr_0 = 1.0200e-04
Loss = 5.5702e-04, PNorm = 38.4920, GNorm = 1.5677, lr_0 = 1.0200e-04
Loss = 7.0505e-04, PNorm = 38.4937, GNorm = 1.6879, lr_0 = 1.0200e-04
Loss = 7.9386e-04, PNorm = 38.4942, GNorm = 3.6588, lr_0 = 1.0200e-04
Loss = 6.6754e-04, PNorm = 38.4955, GNorm = 4.5576, lr_0 = 1.0200e-04
Loss = 6.0832e-04, PNorm = 38.4979, GNorm = 1.7955, lr_0 = 1.0200e-04
Loss = 6.0389e-04, PNorm = 38.4999, GNorm = 2.4795, lr_0 = 1.0200e-04
Loss = 5.6213e-04, PNorm = 38.5012, GNorm = 2.0006, lr_0 = 1.0200e-04
Loss = 5.3496e-04, PNorm = 38.5033, GNorm = 1.3618, lr_0 = 1.0200e-04
Loss = 5.2288e-04, PNorm = 38.5049, GNorm = 1.4948, lr_0 = 1.0200e-04
Loss = 6.9747e-04, PNorm = 38.5066, GNorm = 6.7002, lr_0 = 1.0200e-04
Loss = 6.8186e-04, PNorm = 38.5070, GNorm = 0.8684, lr_0 = 1.0200e-04
Loss = 6.7022e-04, PNorm = 38.5087, GNorm = 3.7200, lr_0 = 1.0200e-04
Loss = 6.8289e-04, PNorm = 38.5107, GNorm = 0.9093, lr_0 = 1.0200e-04
Loss = 4.4461e-04, PNorm = 38.5128, GNorm = 0.5235, lr_0 = 1.0200e-04
Loss = 6.3044e-04, PNorm = 38.5137, GNorm = 1.4719, lr_0 = 1.0200e-04
Loss = 5.4630e-04, PNorm = 38.5150, GNorm = 2.9942, lr_0 = 1.0200e-04
Loss = 4.8026e-04, PNorm = 38.5174, GNorm = 1.0720, lr_0 = 1.0200e-04
Loss = 4.6972e-04, PNorm = 38.5195, GNorm = 1.1634, lr_0 = 1.0200e-04
Loss = 6.7996e-04, PNorm = 38.5204, GNorm = 2.6861, lr_0 = 1.0200e-04
Validation rmse logD = 0.567892
Validation R2 logD = 0.771746
Validation rmse logP = 0.518070
Validation R2 logP = 0.921438
Epoch 74
Train function
Loss = 6.9753e-04, PNorm = 38.5214, GNorm = 3.0052, lr_0 = 1.0200e-04
Loss = 4.9022e-04, PNorm = 38.5236, GNorm = 1.0826, lr_0 = 1.0200e-04
Loss = 5.2379e-04, PNorm = 38.5254, GNorm = 1.9075, lr_0 = 1.0200e-04
Loss = 6.7101e-04, PNorm = 38.5271, GNorm = 1.2437, lr_0 = 1.0200e-04
Loss = 6.2474e-04, PNorm = 38.5287, GNorm = 2.2830, lr_0 = 1.0200e-04
Loss = 7.7594e-04, PNorm = 38.5302, GNorm = 2.3357, lr_0 = 1.0200e-04
Loss = 5.6209e-04, PNorm = 38.5320, GNorm = 2.4764, lr_0 = 1.0200e-04
Loss = 5.3061e-04, PNorm = 38.5330, GNorm = 0.9646, lr_0 = 1.0200e-04
Loss = 4.6562e-04, PNorm = 38.5343, GNorm = 1.4952, lr_0 = 1.0200e-04
Loss = 4.8111e-04, PNorm = 38.5357, GNorm = 1.2622, lr_0 = 1.0200e-04
Loss = 4.8600e-04, PNorm = 38.5377, GNorm = 1.7770, lr_0 = 1.0200e-04
Loss = 5.3872e-04, PNorm = 38.5387, GNorm = 1.8501, lr_0 = 1.0200e-04
Loss = 5.2849e-04, PNorm = 38.5398, GNorm = 1.6183, lr_0 = 1.0200e-04
Loss = 6.3001e-04, PNorm = 38.5411, GNorm = 1.9231, lr_0 = 1.0200e-04
Loss = 4.8880e-04, PNorm = 38.5429, GNorm = 1.3092, lr_0 = 1.0200e-04
Loss = 5.6347e-04, PNorm = 38.5457, GNorm = 1.4056, lr_0 = 1.0200e-04
Loss = 5.6035e-04, PNorm = 38.5473, GNorm = 0.9581, lr_0 = 1.0200e-04
Loss = 6.0865e-04, PNorm = 38.5496, GNorm = 1.9557, lr_0 = 1.0200e-04
Loss = 4.5356e-04, PNorm = 38.5512, GNorm = 1.0325, lr_0 = 1.0200e-04
Loss = 4.3954e-04, PNorm = 38.5518, GNorm = 1.1158, lr_0 = 1.0200e-04
Loss = 4.2373e-04, PNorm = 38.5527, GNorm = 1.4123, lr_0 = 1.0200e-04
Loss = 5.7379e-04, PNorm = 38.5538, GNorm = 0.8891, lr_0 = 1.0200e-04
Loss = 5.0825e-04, PNorm = 38.5549, GNorm = 1.4941, lr_0 = 1.0200e-04
Validation rmse logD = 0.552337
Validation R2 logD = 0.784079
Validation rmse logP = 0.477043
Validation R2 logP = 0.933388
Epoch 75
Train function
Loss = 4.0870e-04, PNorm = 38.5564, GNorm = 0.7672, lr_0 = 1.0200e-04
Loss = 4.5371e-04, PNorm = 38.5579, GNorm = 0.6537, lr_0 = 1.0200e-04
Loss = 5.2640e-04, PNorm = 38.5598, GNorm = 1.6167, lr_0 = 1.0200e-04
Loss = 4.9883e-04, PNorm = 38.5608, GNorm = 1.6814, lr_0 = 1.0200e-04
Loss = 5.2470e-04, PNorm = 38.5623, GNorm = 0.7412, lr_0 = 1.0200e-04
Loss = 4.1252e-04, PNorm = 38.5632, GNorm = 1.7444, lr_0 = 1.0200e-04
Loss = 4.5430e-04, PNorm = 38.5643, GNorm = 2.2497, lr_0 = 1.0200e-04
Loss = 4.6802e-04, PNorm = 38.5653, GNorm = 0.9142, lr_0 = 1.0200e-04
Loss = 4.5715e-04, PNorm = 38.5669, GNorm = 1.1458, lr_0 = 1.0200e-04
Loss = 4.9086e-04, PNorm = 38.5681, GNorm = 2.0316, lr_0 = 1.0200e-04
Loss = 4.5618e-04, PNorm = 38.5689, GNorm = 1.0345, lr_0 = 1.0200e-04
Loss = 5.0064e-04, PNorm = 38.5698, GNorm = 1.8598, lr_0 = 1.0200e-04
Loss = 4.6616e-04, PNorm = 38.5711, GNorm = 0.7603, lr_0 = 1.0200e-04
Loss = 5.4743e-04, PNorm = 38.5722, GNorm = 0.7819, lr_0 = 1.0200e-04
Loss = 4.0587e-04, PNorm = 38.5740, GNorm = 2.1981, lr_0 = 1.0200e-04
Loss = 4.9949e-04, PNorm = 38.5753, GNorm = 1.0793, lr_0 = 1.0200e-04
Loss = 6.1304e-04, PNorm = 38.5769, GNorm = 1.4604, lr_0 = 1.0200e-04
Loss = 5.8614e-04, PNorm = 38.5787, GNorm = 1.9686, lr_0 = 1.0200e-04
Loss = 5.5081e-04, PNorm = 38.5806, GNorm = 2.3492, lr_0 = 1.0200e-04
Loss = 5.3976e-04, PNorm = 38.5824, GNorm = 2.2616, lr_0 = 1.0200e-04
Loss = 5.8031e-04, PNorm = 38.5844, GNorm = 1.6995, lr_0 = 1.0200e-04
Loss = 5.4601e-04, PNorm = 38.5861, GNorm = 0.8170, lr_0 = 1.0200e-04
Validation rmse logD = 0.610424
Validation R2 logD = 0.736276
Validation rmse logP = 0.500837
Validation R2 logP = 0.926577
Epoch 76
Train function
Loss = 6.6344e-04, PNorm = 38.5869, GNorm = 1.9906, lr_0 = 1.0200e-04
Loss = 6.0142e-04, PNorm = 38.5883, GNorm = 1.3544, lr_0 = 1.0200e-04
Loss = 4.8370e-04, PNorm = 38.5892, GNorm = 1.6825, lr_0 = 1.0200e-04
Loss = 4.1055e-04, PNorm = 38.5906, GNorm = 1.2075, lr_0 = 1.0200e-04
Loss = 3.9689e-04, PNorm = 38.5923, GNorm = 1.9669, lr_0 = 1.0200e-04
Loss = 4.4263e-04, PNorm = 38.5940, GNorm = 0.9274, lr_0 = 1.0200e-04
Loss = 4.9780e-04, PNorm = 38.5951, GNorm = 1.3563, lr_0 = 1.0200e-04
Loss = 5.1994e-04, PNorm = 38.5967, GNorm = 1.9088, lr_0 = 1.0200e-04
Loss = 4.9406e-04, PNorm = 38.5983, GNorm = 0.7664, lr_0 = 1.0200e-04
Loss = 4.1327e-04, PNorm = 38.5998, GNorm = 0.7865, lr_0 = 1.0200e-04
Loss = 4.7075e-04, PNorm = 38.6007, GNorm = 2.6784, lr_0 = 1.0200e-04
Loss = 4.5899e-04, PNorm = 38.6014, GNorm = 1.7185, lr_0 = 1.0200e-04
Loss = 5.8007e-04, PNorm = 38.6024, GNorm = 1.1776, lr_0 = 1.0200e-04
Loss = 5.5737e-04, PNorm = 38.6029, GNorm = 1.0286, lr_0 = 1.0200e-04
Loss = 5.6688e-04, PNorm = 38.6041, GNorm = 2.4730, lr_0 = 1.0200e-04
Loss = 6.2949e-04, PNorm = 38.6060, GNorm = 1.6134, lr_0 = 1.0200e-04
Loss = 5.8395e-04, PNorm = 38.6080, GNorm = 0.9790, lr_0 = 1.0200e-04
Loss = 4.2983e-04, PNorm = 38.6101, GNorm = 1.7746, lr_0 = 1.0200e-04
Loss = 4.6617e-04, PNorm = 38.6116, GNorm = 2.0421, lr_0 = 1.0200e-04
Loss = 5.3413e-04, PNorm = 38.6131, GNorm = 3.6335, lr_0 = 1.0200e-04
Loss = 5.6387e-04, PNorm = 38.6146, GNorm = 1.8304, lr_0 = 1.0200e-04
Loss = 6.3001e-04, PNorm = 38.6154, GNorm = 1.2723, lr_0 = 1.0200e-04
Loss = 6.4340e-04, PNorm = 38.6176, GNorm = 3.6269, lr_0 = 1.0200e-04
Validation rmse logD = 0.549403
Validation R2 logD = 0.786367
Validation rmse logP = 0.476037
Validation R2 logP = 0.933669
Epoch 77
Train function
Loss = 3.4954e-04, PNorm = 38.6190, GNorm = 0.9799, lr_0 = 1.0200e-04
Loss = 4.0248e-04, PNorm = 38.6198, GNorm = 0.6228, lr_0 = 1.0200e-04
Loss = 4.4886e-04, PNorm = 38.6209, GNorm = 1.7932, lr_0 = 1.0200e-04
Loss = 4.7756e-04, PNorm = 38.6216, GNorm = 1.2545, lr_0 = 1.0200e-04
Loss = 6.1434e-04, PNorm = 38.6226, GNorm = 1.6613, lr_0 = 1.0200e-04
Loss = 4.5156e-04, PNorm = 38.6238, GNorm = 1.2198, lr_0 = 1.0200e-04
Loss = 3.1609e-04, PNorm = 38.6246, GNorm = 0.9286, lr_0 = 1.0200e-04
Loss = 4.1149e-04, PNorm = 38.6248, GNorm = 1.1451, lr_0 = 1.0200e-04
Loss = 4.6889e-04, PNorm = 38.6261, GNorm = 1.7029, lr_0 = 1.0200e-04
Loss = 5.6771e-04, PNorm = 38.6278, GNorm = 1.7295, lr_0 = 1.0200e-04
Loss = 5.9287e-04, PNorm = 38.6288, GNorm = 1.7921, lr_0 = 1.0200e-04
Loss = 5.6373e-04, PNorm = 38.6307, GNorm = 0.8357, lr_0 = 1.0200e-04
Loss = 4.7702e-04, PNorm = 38.6318, GNorm = 1.5106, lr_0 = 1.0200e-04
Loss = 6.0840e-04, PNorm = 38.6333, GNorm = 0.7762, lr_0 = 1.0200e-04
Loss = 6.2377e-04, PNorm = 38.6349, GNorm = 1.6462, lr_0 = 1.0200e-04
Loss = 5.4620e-04, PNorm = 38.6376, GNorm = 1.9683, lr_0 = 1.0200e-04
Loss = 5.3270e-04, PNorm = 38.6400, GNorm = 2.3517, lr_0 = 1.0200e-04
Loss = 6.1863e-04, PNorm = 38.6419, GNorm = 2.1421, lr_0 = 1.0200e-04
Loss = 5.8401e-04, PNorm = 38.6430, GNorm = 1.5560, lr_0 = 1.0200e-04
Loss = 4.7561e-04, PNorm = 38.6447, GNorm = 2.3582, lr_0 = 1.0200e-04
Loss = 4.4750e-04, PNorm = 38.6461, GNorm = 1.6935, lr_0 = 1.0200e-04
Loss = 4.9525e-04, PNorm = 38.6476, GNorm = 1.3857, lr_0 = 1.0200e-04
Validation rmse logD = 0.553885
Validation R2 logD = 0.782867
Validation rmse logP = 0.472023
Validation R2 logP = 0.934782
Epoch 78
Train function
Loss = 4.7804e-04, PNorm = 38.6492, GNorm = 1.5236, lr_0 = 1.0200e-04
Loss = 4.3309e-04, PNorm = 38.6507, GNorm = 1.2990, lr_0 = 1.0200e-04
Loss = 3.8618e-04, PNorm = 38.6527, GNorm = 1.6656, lr_0 = 1.0200e-04
Loss = 4.1142e-04, PNorm = 38.6542, GNorm = 1.0010, lr_0 = 1.0200e-04
Loss = 3.9780e-04, PNorm = 38.6557, GNorm = 0.6246, lr_0 = 1.0200e-04
Loss = 4.4969e-04, PNorm = 38.6575, GNorm = 0.7683, lr_0 = 1.0200e-04
Loss = 4.5096e-04, PNorm = 38.6595, GNorm = 0.9833, lr_0 = 1.0200e-04
Loss = 3.5287e-04, PNorm = 38.6610, GNorm = 0.9441, lr_0 = 1.0200e-04
Loss = 4.0837e-04, PNorm = 38.6631, GNorm = 1.9323, lr_0 = 1.0200e-04
Loss = 6.3951e-04, PNorm = 38.6640, GNorm = 1.9234, lr_0 = 1.0200e-04
Loss = 5.7133e-04, PNorm = 38.6655, GNorm = 1.2271, lr_0 = 1.0200e-04
Loss = 4.6663e-04, PNorm = 38.6668, GNorm = 1.5382, lr_0 = 1.0200e-04
Loss = 7.0293e-04, PNorm = 38.6689, GNorm = 2.9623, lr_0 = 1.0200e-04
Loss = 5.5759e-04, PNorm = 38.6696, GNorm = 1.7693, lr_0 = 1.0200e-04
Loss = 4.1522e-04, PNorm = 38.6710, GNorm = 0.8693, lr_0 = 1.0200e-04
Loss = 4.8932e-04, PNorm = 38.6728, GNorm = 3.8788, lr_0 = 1.0200e-04
Loss = 5.5686e-04, PNorm = 38.6739, GNorm = 1.2586, lr_0 = 1.0200e-04
Loss = 5.5702e-04, PNorm = 38.6756, GNorm = 0.7256, lr_0 = 1.0200e-04
Loss = 5.3996e-04, PNorm = 38.6771, GNorm = 1.4787, lr_0 = 1.0200e-04
Loss = 5.0639e-04, PNorm = 38.6786, GNorm = 1.2968, lr_0 = 1.0200e-04
Loss = 5.0337e-04, PNorm = 38.6794, GNorm = 1.3209, lr_0 = 1.0200e-04
Loss = 4.7420e-04, PNorm = 38.6799, GNorm = 1.0989, lr_0 = 1.0200e-04
Loss = 4.8483e-04, PNorm = 38.6809, GNorm = 1.6009, lr_0 = 1.0200e-04
Validation rmse logD = 0.585143
Validation R2 logD = 0.757668
Validation rmse logP = 0.472194
Validation R2 logP = 0.934735
Epoch 79
Train function
Loss = 5.5903e-04, PNorm = 38.6824, GNorm = 1.5621, lr_0 = 1.0200e-04
Loss = 7.4214e-04, PNorm = 38.6840, GNorm = 2.1940, lr_0 = 1.0200e-04
Loss = 4.8993e-04, PNorm = 38.6863, GNorm = 1.1321, lr_0 = 1.0200e-04
Loss = 4.4000e-04, PNorm = 38.6869, GNorm = 0.9802, lr_0 = 1.0200e-04
Loss = 4.3742e-04, PNorm = 38.6881, GNorm = 1.1898, lr_0 = 1.0200e-04
Loss = 3.9584e-04, PNorm = 38.6896, GNorm = 1.3499, lr_0 = 1.0200e-04
Loss = 4.6219e-04, PNorm = 38.6906, GNorm = 1.3021, lr_0 = 1.0200e-04
Loss = 5.9763e-04, PNorm = 38.6920, GNorm = 1.5052, lr_0 = 1.0200e-04
Loss = 5.4387e-04, PNorm = 38.6939, GNorm = 1.1661, lr_0 = 1.0200e-04
Loss = 7.2496e-04, PNorm = 38.6950, GNorm = 4.4146, lr_0 = 1.0200e-04
Loss = 5.0800e-04, PNorm = 38.6960, GNorm = 2.3754, lr_0 = 1.0200e-04
Loss = 5.0084e-04, PNorm = 38.6980, GNorm = 0.8456, lr_0 = 1.0200e-04
Loss = 4.5457e-04, PNorm = 38.6995, GNorm = 1.5729, lr_0 = 1.0200e-04
Loss = 4.4953e-04, PNorm = 38.7010, GNorm = 1.3130, lr_0 = 1.0200e-04
Loss = 4.3893e-04, PNorm = 38.7030, GNorm = 1.4350, lr_0 = 1.0200e-04
Loss = 4.5313e-04, PNorm = 38.7036, GNorm = 0.9526, lr_0 = 1.0200e-04
Loss = 4.7432e-04, PNorm = 38.7055, GNorm = 0.8189, lr_0 = 1.0200e-04
Loss = 3.7201e-04, PNorm = 38.7064, GNorm = 1.3317, lr_0 = 1.0200e-04
Loss = 4.1159e-04, PNorm = 38.7075, GNorm = 1.6701, lr_0 = 1.0200e-04
Loss = 3.8345e-04, PNorm = 38.7076, GNorm = 1.4993, lr_0 = 1.0200e-04
Loss = 5.3618e-04, PNorm = 38.7087, GNorm = 2.5771, lr_0 = 1.0200e-04
Loss = 6.3323e-04, PNorm = 38.7102, GNorm = 1.2760, lr_0 = 1.0200e-04
Validation rmse logD = 0.566225
Validation R2 logD = 0.773084
Validation rmse logP = 0.493693
Validation R2 logP = 0.928657
Epoch 80
Train function
Loss = 4.1954e-04, PNorm = 38.7119, GNorm = 1.3125, lr_0 = 1.0200e-04
Loss = 3.8509e-04, PNorm = 38.7129, GNorm = 1.4993, lr_0 = 1.0200e-04
Loss = 4.6383e-04, PNorm = 38.7139, GNorm = 1.2578, lr_0 = 1.0200e-04
Loss = 3.7393e-04, PNorm = 38.7159, GNorm = 1.4612, lr_0 = 1.0200e-04
Loss = 4.3514e-04, PNorm = 38.7172, GNorm = 2.4104, lr_0 = 1.0200e-04
Loss = 3.5796e-04, PNorm = 38.7183, GNorm = 0.8026, lr_0 = 1.0200e-04
Loss = 4.9107e-04, PNorm = 38.7197, GNorm = 0.7257, lr_0 = 1.0200e-04
Loss = 5.6225e-04, PNorm = 38.7207, GNorm = 2.5835, lr_0 = 1.0200e-04
Loss = 4.5692e-04, PNorm = 38.7223, GNorm = 1.9407, lr_0 = 1.0200e-04
Loss = 4.7571e-04, PNorm = 38.7232, GNorm = 1.5129, lr_0 = 1.0200e-04
Loss = 6.1590e-04, PNorm = 38.7253, GNorm = 1.3424, lr_0 = 1.0200e-04
Loss = 5.3685e-04, PNorm = 38.7274, GNorm = 2.8269, lr_0 = 1.0200e-04
Loss = 4.9415e-04, PNorm = 38.7289, GNorm = 3.1802, lr_0 = 1.0200e-04
Loss = 4.1029e-04, PNorm = 38.7300, GNorm = 1.9287, lr_0 = 1.0200e-04
Loss = 4.6079e-04, PNorm = 38.7315, GNorm = 1.0227, lr_0 = 1.0200e-04
Loss = 5.1567e-04, PNorm = 38.7330, GNorm = 1.9756, lr_0 = 1.0200e-04
Loss = 3.8388e-04, PNorm = 38.7345, GNorm = 1.1491, lr_0 = 1.0200e-04
Loss = 4.5887e-04, PNorm = 38.7351, GNorm = 1.1119, lr_0 = 1.0200e-04
Loss = 5.6178e-04, PNorm = 38.7356, GNorm = 1.0047, lr_0 = 1.0200e-04
Loss = 5.2998e-04, PNorm = 38.7367, GNorm = 1.4937, lr_0 = 1.0200e-04
Loss = 6.0693e-04, PNorm = 38.7378, GNorm = 1.5613, lr_0 = 1.0200e-04
Loss = 4.2628e-04, PNorm = 38.7400, GNorm = 2.0245, lr_0 = 1.0200e-04
Loss = 4.9034e-04, PNorm = 38.7420, GNorm = 3.6387, lr_0 = 1.0200e-04
Validation rmse logD = 0.580673
Validation R2 logD = 0.761357
Validation rmse logP = 0.485567
Validation R2 logP = 0.930986
Epoch 81
Train function
Loss = 4.0754e-04, PNorm = 38.7446, GNorm = 0.9281, lr_0 = 1.0200e-04
Loss = 4.2132e-04, PNorm = 38.7463, GNorm = 1.0017, lr_0 = 1.0200e-04
Loss = 3.1099e-04, PNorm = 38.7483, GNorm = 1.2891, lr_0 = 1.0200e-04
Loss = 4.7967e-04, PNorm = 38.7499, GNorm = 1.3218, lr_0 = 1.0200e-04
Loss = 4.3842e-04, PNorm = 38.7511, GNorm = 0.9148, lr_0 = 1.0200e-04
Loss = 4.9898e-04, PNorm = 38.7522, GNorm = 1.0477, lr_0 = 1.0200e-04
Loss = 4.6333e-04, PNorm = 38.7542, GNorm = 0.9366, lr_0 = 1.0200e-04
Loss = 4.4058e-04, PNorm = 38.7555, GNorm = 2.1465, lr_0 = 1.0200e-04
Loss = 4.4028e-04, PNorm = 38.7573, GNorm = 1.1921, lr_0 = 1.0200e-04
Loss = 4.2664e-04, PNorm = 38.7585, GNorm = 1.2707, lr_0 = 1.0200e-04
Loss = 5.7002e-04, PNorm = 38.7596, GNorm = 1.4099, lr_0 = 1.0200e-04
Loss = 4.8920e-04, PNorm = 38.7603, GNorm = 3.2756, lr_0 = 1.0200e-04
Loss = 5.6338e-04, PNorm = 38.7602, GNorm = 3.1849, lr_0 = 1.0200e-04
Loss = 4.9866e-04, PNorm = 38.7617, GNorm = 1.1559, lr_0 = 1.0200e-04
Loss = 5.1791e-04, PNorm = 38.7628, GNorm = 1.9207, lr_0 = 1.0200e-04
Loss = 7.2710e-04, PNorm = 38.7635, GNorm = 0.9168, lr_0 = 1.0200e-04
Loss = 3.9461e-04, PNorm = 38.7647, GNorm = 1.5172, lr_0 = 1.0200e-04
Loss = 5.5929e-04, PNorm = 38.7659, GNorm = 2.3956, lr_0 = 1.0200e-04
Loss = 5.0794e-04, PNorm = 38.7677, GNorm = 1.3523, lr_0 = 1.0200e-04
Loss = 3.9180e-04, PNorm = 38.7680, GNorm = 1.8932, lr_0 = 1.0200e-04
Loss = 4.5411e-04, PNorm = 38.7696, GNorm = 1.4287, lr_0 = 1.0200e-04
Loss = 3.9424e-04, PNorm = 38.7708, GNorm = 0.8109, lr_0 = 1.0200e-04
Validation rmse logD = 0.559950
Validation R2 logD = 0.778086
Validation rmse logP = 0.482000
Validation R2 logP = 0.931996
Epoch 82
Train function
Loss = 5.1812e-04, PNorm = 38.7725, GNorm = 2.4432, lr_0 = 1.0200e-04
Loss = 4.2411e-04, PNorm = 38.7734, GNorm = 1.0782, lr_0 = 1.0200e-04
Loss = 4.0398e-04, PNorm = 38.7745, GNorm = 0.7804, lr_0 = 1.0200e-04
Loss = 4.0425e-04, PNorm = 38.7758, GNorm = 0.6797, lr_0 = 1.0200e-04
Loss = 4.0659e-04, PNorm = 38.7775, GNorm = 2.0060, lr_0 = 1.0200e-04
Loss = 5.1709e-04, PNorm = 38.7790, GNorm = 2.5532, lr_0 = 1.0200e-04
Loss = 3.9411e-04, PNorm = 38.7805, GNorm = 1.1918, lr_0 = 1.0200e-04
Loss = 3.6271e-04, PNorm = 38.7823, GNorm = 1.2957, lr_0 = 1.0200e-04
Loss = 4.3145e-04, PNorm = 38.7843, GNorm = 2.3137, lr_0 = 1.0200e-04
Loss = 5.9399e-04, PNorm = 38.7854, GNorm = 5.0589, lr_0 = 1.0200e-04
Loss = 5.4047e-04, PNorm = 38.7870, GNorm = 2.8363, lr_0 = 1.0200e-04
Loss = 4.9230e-04, PNorm = 38.7884, GNorm = 0.8330, lr_0 = 1.0200e-04
Loss = 4.6147e-04, PNorm = 38.7910, GNorm = 2.3017, lr_0 = 1.0200e-04
Loss = 4.4547e-04, PNorm = 38.7936, GNorm = 2.6477, lr_0 = 1.0200e-04
Loss = 6.1960e-04, PNorm = 38.7949, GNorm = 3.5775, lr_0 = 1.0200e-04
Loss = 6.5305e-04, PNorm = 38.7956, GNorm = 2.4513, lr_0 = 1.0200e-04
Loss = 5.1219e-04, PNorm = 38.7973, GNorm = 1.6209, lr_0 = 1.0200e-04
Loss = 5.4421e-04, PNorm = 38.7985, GNorm = 2.5984, lr_0 = 1.0200e-04
Loss = 4.7214e-04, PNorm = 38.7996, GNorm = 1.7506, lr_0 = 1.0200e-04
Loss = 5.5945e-04, PNorm = 38.8004, GNorm = 2.0480, lr_0 = 1.0200e-04
Loss = 7.5223e-04, PNorm = 38.8004, GNorm = 4.4313, lr_0 = 1.0200e-04
Loss = 6.5073e-04, PNorm = 38.8021, GNorm = 1.8777, lr_0 = 1.0200e-04
Loss = 5.0703e-04, PNorm = 38.8043, GNorm = 1.3591, lr_0 = 1.0200e-04
Validation rmse logD = 0.552774
Validation R2 logD = 0.783737
Validation rmse logP = 0.467971
Validation R2 logP = 0.935897
Epoch 83
Train function
Loss = 3.1902e-04, PNorm = 38.8068, GNorm = 1.4877, lr_0 = 1.0200e-04
Loss = 4.5612e-04, PNorm = 38.8077, GNorm = 0.6770, lr_0 = 1.0200e-04
Loss = 5.1139e-04, PNorm = 38.8090, GNorm = 2.8152, lr_0 = 1.0200e-04
Loss = 4.8687e-04, PNorm = 38.8104, GNorm = 0.9661, lr_0 = 1.0200e-04
Loss = 4.3275e-04, PNorm = 38.8118, GNorm = 0.9888, lr_0 = 1.0200e-04
Loss = 4.7061e-04, PNorm = 38.8141, GNorm = 1.3423, lr_0 = 1.0200e-04
Loss = 3.4930e-04, PNorm = 38.8157, GNorm = 1.3939, lr_0 = 1.0200e-04
Loss = 4.6908e-04, PNorm = 38.8176, GNorm = 1.1579, lr_0 = 1.0200e-04
Loss = 4.4354e-04, PNorm = 38.8191, GNorm = 1.0154, lr_0 = 1.0200e-04
Loss = 4.0339e-04, PNorm = 38.8200, GNorm = 0.9499, lr_0 = 1.0200e-04
Loss = 3.4701e-04, PNorm = 38.8217, GNorm = 1.1816, lr_0 = 1.0200e-04
Loss = 4.2190e-04, PNorm = 38.8226, GNorm = 2.3581, lr_0 = 1.0200e-04
Loss = 4.8064e-04, PNorm = 38.8228, GNorm = 1.3338, lr_0 = 1.0200e-04
Loss = 4.6467e-04, PNorm = 38.8232, GNorm = 0.8878, lr_0 = 1.0200e-04
Loss = 5.1383e-04, PNorm = 38.8240, GNorm = 3.3502, lr_0 = 1.0200e-04
Loss = 4.6216e-04, PNorm = 38.8251, GNorm = 2.6903, lr_0 = 1.0200e-04
Loss = 5.9333e-04, PNorm = 38.8266, GNorm = 2.4365, lr_0 = 1.0200e-04
Loss = 3.9445e-04, PNorm = 38.8279, GNorm = 1.2704, lr_0 = 1.0200e-04
Loss = 3.3744e-04, PNorm = 38.8287, GNorm = 0.5423, lr_0 = 1.0200e-04
Loss = 4.5518e-04, PNorm = 38.8298, GNorm = 0.6893, lr_0 = 1.0200e-04
Loss = 3.9689e-04, PNorm = 38.8313, GNorm = 1.0684, lr_0 = 1.0200e-04
Loss = 5.0689e-04, PNorm = 38.8329, GNorm = 1.4303, lr_0 = 1.0200e-04
Loss = 5.8829e-04, PNorm = 38.8342, GNorm = 1.2010, lr_0 = 1.0200e-04
Validation rmse logD = 0.558787
Validation R2 logD = 0.779006
Validation rmse logP = 0.487647
Validation R2 logP = 0.930393
Epoch 84
Train function
Loss = 3.7934e-04, PNorm = 38.8348, GNorm = 1.5764, lr_0 = 1.0200e-04
Loss = 4.5919e-04, PNorm = 38.8367, GNorm = 2.0338, lr_0 = 1.0200e-04
Loss = 3.8500e-04, PNorm = 38.8386, GNorm = 2.3689, lr_0 = 1.0200e-04
Loss = 3.4572e-04, PNorm = 38.8394, GNorm = 1.4762, lr_0 = 1.0200e-04
Loss = 3.9398e-04, PNorm = 38.8405, GNorm = 0.7909, lr_0 = 1.0200e-04
Loss = 4.4250e-04, PNorm = 38.8421, GNorm = 1.2382, lr_0 = 1.0200e-04
Loss = 5.0743e-04, PNorm = 38.8440, GNorm = 2.0059, lr_0 = 1.0200e-04
Loss = 4.5694e-04, PNorm = 38.8456, GNorm = 0.8733, lr_0 = 1.0200e-04
Loss = 4.8932e-04, PNorm = 38.8464, GNorm = 1.9635, lr_0 = 1.0200e-04
Loss = 4.4297e-04, PNorm = 38.8477, GNorm = 0.8387, lr_0 = 1.0200e-04
Loss = 4.6104e-04, PNorm = 38.8496, GNorm = 1.2587, lr_0 = 1.0200e-04
Loss = 4.8901e-04, PNorm = 38.8507, GNorm = 1.1831, lr_0 = 1.0200e-04
Loss = 3.5649e-04, PNorm = 38.8518, GNorm = 1.0542, lr_0 = 1.0200e-04
Loss = 4.7546e-04, PNorm = 38.8535, GNorm = 3.2136, lr_0 = 1.0200e-04
Loss = 3.8606e-04, PNorm = 38.8544, GNorm = 0.8789, lr_0 = 1.0200e-04
Loss = 4.5880e-04, PNorm = 38.8560, GNorm = 1.7430, lr_0 = 1.0200e-04
Loss = 4.1571e-04, PNorm = 38.8570, GNorm = 1.1233, lr_0 = 1.0200e-04
Loss = 4.1985e-04, PNorm = 38.8581, GNorm = 2.5734, lr_0 = 1.0200e-04
Loss = 3.7172e-04, PNorm = 38.8597, GNorm = 1.0463, lr_0 = 1.0200e-04
Loss = 4.1331e-04, PNorm = 38.8616, GNorm = 0.8367, lr_0 = 1.0200e-04
Loss = 4.6401e-04, PNorm = 38.8624, GNorm = 1.6297, lr_0 = 1.0200e-04
Loss = 3.7468e-04, PNorm = 38.8630, GNorm = 1.2680, lr_0 = 1.0200e-04
Validation rmse logD = 0.559543
Validation R2 logD = 0.778408
Validation rmse logP = 0.483710
Validation R2 logP = 0.931513
Epoch 85
Train function
Loss = 3.9988e-04, PNorm = 38.8642, GNorm = 1.1982, lr_0 = 1.0200e-04
Loss = 3.6824e-04, PNorm = 38.8651, GNorm = 0.8682, lr_0 = 1.0200e-04
Loss = 3.4935e-04, PNorm = 38.8656, GNorm = 1.2024, lr_0 = 1.0200e-04
Loss = 5.0966e-04, PNorm = 38.8673, GNorm = 2.7166, lr_0 = 1.0200e-04
Loss = 3.6142e-04, PNorm = 38.8684, GNorm = 2.0644, lr_0 = 1.0200e-04
Loss = 4.4184e-04, PNorm = 38.8699, GNorm = 0.8401, lr_0 = 1.0200e-04
Loss = 4.0392e-04, PNorm = 38.8716, GNorm = 0.8082, lr_0 = 1.0200e-04
Loss = 3.3710e-04, PNorm = 38.8728, GNorm = 1.0515, lr_0 = 1.0200e-04
Loss = 3.8634e-04, PNorm = 38.8740, GNorm = 1.0313, lr_0 = 1.0200e-04
Loss = 3.2809e-04, PNorm = 38.8750, GNorm = 1.4746, lr_0 = 1.0200e-04
Loss = 3.4137e-04, PNorm = 38.8762, GNorm = 1.3213, lr_0 = 1.0200e-04
Loss = 4.1238e-04, PNorm = 38.8772, GNorm = 1.8139, lr_0 = 1.0200e-04
Loss = 4.6904e-04, PNorm = 38.8779, GNorm = 0.9969, lr_0 = 1.0200e-04
Loss = 5.2713e-04, PNorm = 38.8789, GNorm = 1.0502, lr_0 = 1.0200e-04
Loss = 4.5972e-04, PNorm = 38.8800, GNorm = 0.9887, lr_0 = 1.0200e-04
Loss = 3.4532e-04, PNorm = 38.8816, GNorm = 0.6650, lr_0 = 1.0200e-04
Loss = 4.0357e-04, PNorm = 38.8827, GNorm = 1.0293, lr_0 = 1.0200e-04
Loss = 4.1710e-04, PNorm = 38.8840, GNorm = 1.4332, lr_0 = 1.0200e-04
Loss = 4.8956e-04, PNorm = 38.8854, GNorm = 0.8413, lr_0 = 1.0200e-04
Loss = 4.3534e-04, PNorm = 38.8870, GNorm = 1.0945, lr_0 = 1.0200e-04
Loss = 4.4201e-04, PNorm = 38.8871, GNorm = 2.5784, lr_0 = 1.0200e-04
Loss = 4.4283e-04, PNorm = 38.8878, GNorm = 1.4108, lr_0 = 1.0200e-04
Loss = 3.9302e-04, PNorm = 38.8892, GNorm = 0.6513, lr_0 = 1.0200e-04
Validation rmse logD = 0.557056
Validation R2 logD = 0.780373
Validation rmse logP = 0.469041
Validation R2 logP = 0.935604
Epoch 86
Train function
Loss = 3.5922e-04, PNorm = 38.8910, GNorm = 1.1754, lr_0 = 1.0200e-04
Loss = 3.5107e-04, PNorm = 38.8917, GNorm = 1.0192, lr_0 = 1.0200e-04
Loss = 3.1650e-04, PNorm = 38.8928, GNorm = 1.8511, lr_0 = 1.0200e-04
Loss = 3.3441e-04, PNorm = 38.8944, GNorm = 1.6265, lr_0 = 1.0200e-04
Loss = 3.3538e-04, PNorm = 38.8959, GNorm = 1.6782, lr_0 = 1.0200e-04
Loss = 3.3146e-04, PNorm = 38.8970, GNorm = 0.7442, lr_0 = 1.0200e-04
Loss = 4.7829e-04, PNorm = 38.8982, GNorm = 1.8297, lr_0 = 1.0200e-04
Loss = 4.1534e-04, PNorm = 38.8995, GNorm = 1.0497, lr_0 = 1.0200e-04
Loss = 5.3364e-04, PNorm = 38.9003, GNorm = 4.6369, lr_0 = 1.0200e-04
Loss = 4.8118e-04, PNorm = 38.9022, GNorm = 1.6042, lr_0 = 1.0200e-04
Loss = 4.4907e-04, PNorm = 38.9038, GNorm = 1.5686, lr_0 = 1.0200e-04
Loss = 3.9272e-04, PNorm = 38.9057, GNorm = 1.0492, lr_0 = 1.0200e-04
Loss = 4.0744e-04, PNorm = 38.9069, GNorm = 2.8771, lr_0 = 1.0200e-04
Loss = 5.4040e-04, PNorm = 38.9079, GNorm = 4.8717, lr_0 = 1.0200e-04
Loss = 5.1798e-04, PNorm = 38.9092, GNorm = 1.2337, lr_0 = 1.0200e-04
Loss = 5.4237e-04, PNorm = 38.9108, GNorm = 3.4159, lr_0 = 1.0200e-04
Loss = 4.7390e-04, PNorm = 38.9126, GNorm = 1.4709, lr_0 = 1.0200e-04
Loss = 5.5266e-04, PNorm = 38.9150, GNorm = 3.3819, lr_0 = 1.0200e-04
Loss = 5.0222e-04, PNorm = 38.9164, GNorm = 1.8922, lr_0 = 1.0200e-04
Loss = 5.7569e-04, PNorm = 38.9186, GNorm = 1.3865, lr_0 = 1.0200e-04
Loss = 5.2993e-04, PNorm = 38.9208, GNorm = 1.9539, lr_0 = 1.0200e-04
Loss = 5.3405e-04, PNorm = 38.9227, GNorm = 1.1120, lr_0 = 1.0200e-04
Validation rmse logD = 0.567508
Validation R2 logD = 0.772054
Validation rmse logP = 0.472766
Validation R2 logP = 0.934577
Epoch 87
Train function
Loss = 4.3943e-04, PNorm = 38.9240, GNorm = 2.1544, lr_0 = 1.0200e-04
Loss = 3.7772e-04, PNorm = 38.9255, GNorm = 0.7851, lr_0 = 1.0200e-04
Loss = 3.2903e-04, PNorm = 38.9276, GNorm = 1.6478, lr_0 = 1.0200e-04
Loss = 3.7872e-04, PNorm = 38.9287, GNorm = 1.4310, lr_0 = 1.0200e-04
Loss = 4.1475e-04, PNorm = 38.9297, GNorm = 1.9681, lr_0 = 1.0200e-04
Loss = 3.7424e-04, PNorm = 38.9303, GNorm = 1.5136, lr_0 = 1.0200e-04
Loss = 3.7182e-04, PNorm = 38.9309, GNorm = 1.1823, lr_0 = 1.0200e-04
Loss = 4.0142e-04, PNorm = 38.9319, GNorm = 0.7453, lr_0 = 1.0200e-04
Loss = 3.7519e-04, PNorm = 38.9333, GNorm = 1.2727, lr_0 = 1.0200e-04
Loss = 4.0321e-04, PNorm = 38.9345, GNorm = 1.0769, lr_0 = 1.0200e-04
Loss = 3.9143e-04, PNorm = 38.9350, GNorm = 1.5065, lr_0 = 1.0200e-04
Loss = 4.5471e-04, PNorm = 38.9358, GNorm = 1.1548, lr_0 = 1.0200e-04
Loss = 4.5256e-04, PNorm = 38.9371, GNorm = 1.1163, lr_0 = 1.0200e-04
Loss = 4.2999e-04, PNorm = 38.9384, GNorm = 1.0961, lr_0 = 1.0200e-04
Loss = 3.7520e-04, PNorm = 38.9404, GNorm = 1.2075, lr_0 = 1.0200e-04
Loss = 4.5505e-04, PNorm = 38.9420, GNorm = 1.8289, lr_0 = 1.0200e-04
Loss = 4.4549e-04, PNorm = 38.9434, GNorm = 1.7983, lr_0 = 1.0200e-04
Loss = 3.9068e-04, PNorm = 38.9451, GNorm = 1.0049, lr_0 = 1.0200e-04
Loss = 4.8584e-04, PNorm = 38.9465, GNorm = 0.9836, lr_0 = 1.0200e-04
Loss = 4.0612e-04, PNorm = 38.9482, GNorm = 1.7681, lr_0 = 1.0200e-04
Loss = 4.1199e-04, PNorm = 38.9487, GNorm = 1.3163, lr_0 = 1.0200e-04
Loss = 4.1998e-04, PNorm = 38.9497, GNorm = 1.0925, lr_0 = 1.0200e-04
Loss = 4.4803e-04, PNorm = 38.9506, GNorm = 3.2068, lr_0 = 1.0200e-04
Validation rmse logD = 0.591579
Validation R2 logD = 0.752308
Validation rmse logP = 0.476441
Validation R2 logP = 0.933556
Epoch 88
Train function
Loss = 5.2698e-04, PNorm = 38.9523, GNorm = 3.6470, lr_0 = 1.0200e-04
Loss = 4.5866e-04, PNorm = 38.9539, GNorm = 1.1068, lr_0 = 1.0200e-04
Loss = 4.3939e-04, PNorm = 38.9551, GNorm = 0.9882, lr_0 = 1.0200e-04
Loss = 4.0904e-04, PNorm = 38.9565, GNorm = 1.2037, lr_0 = 1.0200e-04
Loss = 2.9552e-04, PNorm = 38.9580, GNorm = 1.2137, lr_0 = 1.0200e-04
Loss = 4.7415e-04, PNorm = 38.9595, GNorm = 0.8982, lr_0 = 1.0200e-04
Loss = 5.3495e-04, PNorm = 38.9605, GNorm = 0.9166, lr_0 = 1.0200e-04
Loss = 4.3656e-04, PNorm = 38.9614, GNorm = 2.9934, lr_0 = 1.0200e-04
Loss = 3.9735e-04, PNorm = 38.9626, GNorm = 1.8041, lr_0 = 1.0200e-04
Loss = 4.2084e-04, PNorm = 38.9637, GNorm = 1.4643, lr_0 = 1.0200e-04
Loss = 4.1683e-04, PNorm = 38.9654, GNorm = 2.5087, lr_0 = 1.0200e-04
Loss = 5.2018e-04, PNorm = 38.9673, GNorm = 2.3649, lr_0 = 1.0200e-04
Loss = 4.8179e-04, PNorm = 38.9676, GNorm = 1.2437, lr_0 = 1.0200e-04
Loss = 4.7437e-04, PNorm = 38.9685, GNorm = 2.4347, lr_0 = 1.0200e-04
Loss = 3.6471e-04, PNorm = 38.9702, GNorm = 1.7114, lr_0 = 1.0200e-04
Loss = 4.0945e-04, PNorm = 38.9706, GNorm = 1.0151, lr_0 = 1.0200e-04
Loss = 3.6397e-04, PNorm = 38.9715, GNorm = 1.1018, lr_0 = 1.0200e-04
Loss = 4.3675e-04, PNorm = 38.9729, GNorm = 1.1773, lr_0 = 1.0200e-04
Loss = 3.9657e-04, PNorm = 38.9733, GNorm = 1.3445, lr_0 = 1.0200e-04
Loss = 4.0858e-04, PNorm = 38.9745, GNorm = 2.9881, lr_0 = 1.0200e-04
Loss = 3.8045e-04, PNorm = 38.9764, GNorm = 2.0822, lr_0 = 1.0200e-04
Loss = 4.2378e-04, PNorm = 38.9780, GNorm = 2.5446, lr_0 = 1.0200e-04
Validation rmse logD = 0.557623
Validation R2 logD = 0.779926
Validation rmse logP = 0.473843
Validation R2 logP = 0.934278
Epoch 89
Train function
Loss = 3.5340e-04, PNorm = 38.9799, GNorm = 1.5814, lr_0 = 1.0200e-04
Loss = 3.6475e-04, PNorm = 38.9813, GNorm = 2.1862, lr_0 = 1.0200e-04
Loss = 3.2874e-04, PNorm = 38.9825, GNorm = 2.1315, lr_0 = 1.0200e-04
Loss = 3.4513e-04, PNorm = 38.9837, GNorm = 1.1197, lr_0 = 1.0200e-04
Loss = 5.0472e-04, PNorm = 38.9849, GNorm = 3.3293, lr_0 = 1.0200e-04
Loss = 4.8386e-04, PNorm = 38.9859, GNorm = 0.9037, lr_0 = 1.0200e-04
Loss = 3.7978e-04, PNorm = 38.9866, GNorm = 1.1980, lr_0 = 1.0200e-04
Loss = 3.4190e-04, PNorm = 38.9880, GNorm = 0.7214, lr_0 = 1.0200e-04
Loss = 3.8781e-04, PNorm = 38.9890, GNorm = 1.4830, lr_0 = 1.0200e-04
Loss = 3.4013e-04, PNorm = 38.9901, GNorm = 0.6688, lr_0 = 1.0200e-04
Loss = 3.5088e-04, PNorm = 38.9917, GNorm = 1.5510, lr_0 = 1.0200e-04
Loss = 3.4746e-04, PNorm = 38.9933, GNorm = 0.4968, lr_0 = 1.0200e-04
Loss = 3.4205e-04, PNorm = 38.9943, GNorm = 1.0375, lr_0 = 1.0200e-04
Loss = 3.4067e-04, PNorm = 38.9953, GNorm = 1.2451, lr_0 = 1.0200e-04
Loss = 3.7126e-04, PNorm = 38.9960, GNorm = 1.2945, lr_0 = 1.0200e-04
Loss = 4.6026e-04, PNorm = 38.9969, GNorm = 1.9228, lr_0 = 1.0200e-04
Loss = 4.6003e-04, PNorm = 38.9983, GNorm = 0.9171, lr_0 = 1.0200e-04
Loss = 4.2958e-04, PNorm = 38.9995, GNorm = 1.5745, lr_0 = 1.0200e-04
Loss = 3.4078e-04, PNorm = 39.0012, GNorm = 1.6689, lr_0 = 1.0200e-04
Loss = 3.5965e-04, PNorm = 39.0023, GNorm = 0.7624, lr_0 = 1.0200e-04
Loss = 3.7955e-04, PNorm = 39.0037, GNorm = 0.6602, lr_0 = 1.0200e-04
Loss = 4.5933e-04, PNorm = 39.0056, GNorm = 2.2311, lr_0 = 1.0200e-04
Loss = 4.4589e-04, PNorm = 39.0065, GNorm = 1.3581, lr_0 = 1.0200e-04
Validation rmse logD = 0.568876
Validation R2 logD = 0.770955
Validation rmse logP = 0.476208
Validation R2 logP = 0.933621
Epoch 90
Train function
Loss = 3.5223e-04, PNorm = 39.0074, GNorm = 0.8094, lr_0 = 1.0200e-04
Loss = 3.4294e-04, PNorm = 39.0085, GNorm = 1.5982, lr_0 = 1.0200e-04
Loss = 3.8797e-04, PNorm = 39.0099, GNorm = 2.7987, lr_0 = 1.0200e-04
Loss = 3.7806e-04, PNorm = 39.0113, GNorm = 1.3111, lr_0 = 1.0200e-04
Loss = 4.5443e-04, PNorm = 39.0119, GNorm = 1.7634, lr_0 = 1.0200e-04
Loss = 4.2357e-04, PNorm = 39.0126, GNorm = 2.7811, lr_0 = 1.0200e-04
Loss = 4.5393e-04, PNorm = 39.0134, GNorm = 1.2069, lr_0 = 1.0200e-04
Loss = 5.0702e-04, PNorm = 39.0146, GNorm = 1.7549, lr_0 = 1.0200e-04
Loss = 4.3523e-04, PNorm = 39.0153, GNorm = 2.6144, lr_0 = 1.0200e-04
Loss = 4.1414e-04, PNorm = 39.0162, GNorm = 1.2549, lr_0 = 1.0200e-04
Loss = 3.6685e-04, PNorm = 39.0186, GNorm = 2.7044, lr_0 = 1.0200e-04
Loss = 3.4193e-04, PNorm = 39.0201, GNorm = 0.9885, lr_0 = 1.0200e-04
Loss = 3.3628e-04, PNorm = 39.0216, GNorm = 1.0347, lr_0 = 1.0200e-04
Loss = 3.5305e-04, PNorm = 39.0234, GNorm = 1.0210, lr_0 = 1.0200e-04
Loss = 3.6963e-04, PNorm = 39.0250, GNorm = 2.4362, lr_0 = 1.0200e-04
Loss = 4.4531e-04, PNorm = 39.0270, GNorm = 1.0670, lr_0 = 1.0200e-04
Loss = 4.8510e-04, PNorm = 39.0280, GNorm = 0.9506, lr_0 = 1.0200e-04
Loss = 3.3024e-04, PNorm = 39.0293, GNorm = 2.3724, lr_0 = 1.0200e-04
Loss = 4.1744e-04, PNorm = 39.0308, GNorm = 1.4496, lr_0 = 1.0200e-04
Loss = 4.9678e-04, PNorm = 39.0318, GNorm = 1.6308, lr_0 = 1.0200e-04
Loss = 4.1576e-04, PNorm = 39.0334, GNorm = 3.1590, lr_0 = 1.0200e-04
Loss = 5.3268e-04, PNorm = 39.0345, GNorm = 2.1938, lr_0 = 1.0200e-04
Validation rmse logD = 0.554927
Validation R2 logD = 0.782050
Validation rmse logP = 0.507283
Validation R2 logP = 0.924675
Epoch 91
Train function
Loss = 5.1366e-04, PNorm = 39.0356, GNorm = 2.9715, lr_0 = 1.0200e-04
Loss = 3.6797e-04, PNorm = 39.0368, GNorm = 1.2965, lr_0 = 1.0200e-04
Loss = 2.6732e-04, PNorm = 39.0382, GNorm = 0.9788, lr_0 = 1.0200e-04
Loss = 2.7572e-04, PNorm = 39.0393, GNorm = 1.1930, lr_0 = 1.0200e-04
Loss = 3.6315e-04, PNorm = 39.0402, GNorm = 0.7931, lr_0 = 1.0200e-04
Loss = 5.2644e-04, PNorm = 39.0406, GNorm = 2.6347, lr_0 = 1.0200e-04
Loss = 5.9832e-04, PNorm = 39.0411, GNorm = 3.1713, lr_0 = 1.0200e-04
Loss = 3.6169e-04, PNorm = 39.0421, GNorm = 1.0801, lr_0 = 1.0200e-04
Loss = 4.0639e-04, PNorm = 39.0433, GNorm = 1.4651, lr_0 = 1.0200e-04
Loss = 4.2717e-04, PNorm = 39.0453, GNorm = 1.1635, lr_0 = 1.0200e-04
Loss = 4.5633e-04, PNorm = 39.0472, GNorm = 1.6941, lr_0 = 1.0200e-04
Loss = 4.4622e-04, PNorm = 39.0481, GNorm = 1.1856, lr_0 = 1.0200e-04
Loss = 4.3317e-04, PNorm = 39.0489, GNorm = 1.9428, lr_0 = 1.0200e-04
Loss = 5.2229e-04, PNorm = 39.0513, GNorm = 0.7797, lr_0 = 1.0200e-04
Loss = 4.6015e-04, PNorm = 39.0531, GNorm = 1.7969, lr_0 = 1.0200e-04
Loss = 3.3329e-04, PNorm = 39.0541, GNorm = 0.8156, lr_0 = 1.0200e-04
Loss = 4.0455e-04, PNorm = 39.0555, GNorm = 2.0996, lr_0 = 1.0200e-04
Loss = 4.4736e-04, PNorm = 39.0570, GNorm = 0.9389, lr_0 = 1.0200e-04
Loss = 3.4743e-04, PNorm = 39.0593, GNorm = 0.9857, lr_0 = 1.0200e-04
Loss = 3.5552e-04, PNorm = 39.0602, GNorm = 1.3095, lr_0 = 1.0200e-04
Loss = 4.3173e-04, PNorm = 39.0605, GNorm = 2.4173, lr_0 = 1.0200e-04
Loss = 4.3911e-04, PNorm = 39.0623, GNorm = 0.9393, lr_0 = 1.0200e-04
Loss = 4.0688e-04, PNorm = 39.0640, GNorm = 2.6892, lr_0 = 1.0200e-04
Validation rmse logD = 0.554168
Validation R2 logD = 0.782645
Validation rmse logP = 0.503878
Validation R2 logP = 0.925683
Epoch 92
Train function
Loss = 7.6022e-04, PNorm = 39.0649, GNorm = 3.8241, lr_0 = 1.0200e-04
Loss = 4.9418e-04, PNorm = 39.0656, GNorm = 3.0580, lr_0 = 1.0200e-04
Loss = 3.9909e-04, PNorm = 39.0666, GNorm = 1.1170, lr_0 = 1.0200e-04
Loss = 3.5120e-04, PNorm = 39.0675, GNorm = 1.8172, lr_0 = 1.0200e-04
Loss = 3.8638e-04, PNorm = 39.0692, GNorm = 1.0947, lr_0 = 1.0200e-04
Loss = 3.1117e-04, PNorm = 39.0714, GNorm = 1.0993, lr_0 = 1.0200e-04
Loss = 4.5153e-04, PNorm = 39.0728, GNorm = 0.6611, lr_0 = 1.0200e-04
Loss = 4.0508e-04, PNorm = 39.0744, GNorm = 0.7938, lr_0 = 1.0200e-04
Loss = 3.3816e-04, PNorm = 39.0760, GNorm = 1.1973, lr_0 = 1.0200e-04
Loss = 3.8039e-04, PNorm = 39.0775, GNorm = 0.7106, lr_0 = 1.0200e-04
Loss = 3.6146e-04, PNorm = 39.0788, GNorm = 1.8969, lr_0 = 1.0200e-04
Loss = 3.5247e-04, PNorm = 39.0789, GNorm = 1.4600, lr_0 = 1.0200e-04
Loss = 4.7358e-04, PNorm = 39.0799, GNorm = 1.0897, lr_0 = 1.0200e-04
Loss = 3.2229e-04, PNorm = 39.0805, GNorm = 1.4327, lr_0 = 1.0200e-04
Loss = 3.4945e-04, PNorm = 39.0814, GNorm = 1.8267, lr_0 = 1.0200e-04
Loss = 4.3291e-04, PNorm = 39.0831, GNorm = 2.2223, lr_0 = 1.0200e-04
Loss = 4.3608e-04, PNorm = 39.0837, GNorm = 1.6803, lr_0 = 1.0200e-04
Loss = 3.5501e-04, PNorm = 39.0845, GNorm = 1.7728, lr_0 = 1.0200e-04
Loss = 3.1526e-04, PNorm = 39.0854, GNorm = 0.6512, lr_0 = 1.0200e-04
Loss = 2.6511e-04, PNorm = 39.0859, GNorm = 0.7512, lr_0 = 1.0200e-04
Loss = 4.0429e-04, PNorm = 39.0868, GNorm = 0.9795, lr_0 = 1.0200e-04
Loss = 5.0535e-04, PNorm = 39.0871, GNorm = 2.6582, lr_0 = 1.0200e-04
Validation rmse logD = 0.586804
Validation R2 logD = 0.756290
Validation rmse logP = 0.484260
Validation R2 logP = 0.931357
Epoch 93
Train function
Loss = 4.6125e-04, PNorm = 39.0885, GNorm = 3.0660, lr_0 = 1.0200e-04
Loss = 4.0934e-04, PNorm = 39.0913, GNorm = 1.1546, lr_0 = 1.0200e-04
Loss = 3.3682e-04, PNorm = 39.0924, GNorm = 1.1798, lr_0 = 1.0200e-04
Loss = 4.3902e-04, PNorm = 39.0941, GNorm = 1.6719, lr_0 = 1.0200e-04
Loss = 4.2421e-04, PNorm = 39.0960, GNorm = 2.4971, lr_0 = 1.0200e-04
Loss = 3.1044e-04, PNorm = 39.0969, GNorm = 0.7204, lr_0 = 1.0200e-04
Loss = 3.5836e-04, PNorm = 39.0979, GNorm = 1.5321, lr_0 = 1.0200e-04
Loss = 3.9145e-04, PNorm = 39.0984, GNorm = 1.9425, lr_0 = 1.0200e-04
Loss = 4.1480e-04, PNorm = 39.0996, GNorm = 2.8198, lr_0 = 1.0200e-04
Loss = 3.7944e-04, PNorm = 39.1009, GNorm = 2.3938, lr_0 = 1.0200e-04
Loss = 2.9945e-04, PNorm = 39.1018, GNorm = 0.8238, lr_0 = 1.0200e-04
Loss = 3.7448e-04, PNorm = 39.1033, GNorm = 1.2199, lr_0 = 1.0200e-04
Loss = 3.7667e-04, PNorm = 39.1038, GNorm = 1.9472, lr_0 = 1.0200e-04
Loss = 4.0920e-04, PNorm = 39.1056, GNorm = 0.5993, lr_0 = 1.0200e-04
Loss = 3.6018e-04, PNorm = 39.1069, GNorm = 1.1301, lr_0 = 1.0200e-04
Loss = 2.8953e-04, PNorm = 39.1077, GNorm = 0.8856, lr_0 = 1.0200e-04
Loss = 3.4217e-04, PNorm = 39.1085, GNorm = 1.4957, lr_0 = 1.0200e-04
Loss = 3.4529e-04, PNorm = 39.1096, GNorm = 2.2673, lr_0 = 1.0200e-04
Loss = 3.2867e-04, PNorm = 39.1106, GNorm = 0.7852, lr_0 = 1.0200e-04
Loss = 4.8863e-04, PNorm = 39.1122, GNorm = 0.7020, lr_0 = 1.0200e-04
Loss = 4.7700e-04, PNorm = 39.1142, GNorm = 2.3731, lr_0 = 1.0200e-04
Loss = 3.0960e-04, PNorm = 39.1148, GNorm = 1.2245, lr_0 = 1.0200e-04
Loss = 4.4798e-04, PNorm = 39.1160, GNorm = 1.8368, lr_0 = 1.0200e-04
Validation rmse logD = 0.552977
Validation R2 logD = 0.783579
Validation rmse logP = 0.472858
Validation R2 logP = 0.934551
Epoch 94
Train function
Loss = 2.9511e-04, PNorm = 39.1177, GNorm = 0.8515, lr_0 = 1.0200e-04
Loss = 4.3541e-04, PNorm = 39.1190, GNorm = 1.5797, lr_0 = 1.0200e-04
Loss = 3.1759e-04, PNorm = 39.1201, GNorm = 2.1300, lr_0 = 1.0200e-04
Loss = 4.1524e-04, PNorm = 39.1212, GNorm = 2.2751, lr_0 = 1.0200e-04
Loss = 3.1066e-04, PNorm = 39.1224, GNorm = 1.1470, lr_0 = 1.0200e-04
Loss = 3.7634e-04, PNorm = 39.1231, GNorm = 1.6049, lr_0 = 1.0200e-04
Loss = 4.0991e-04, PNorm = 39.1245, GNorm = 1.9825, lr_0 = 1.0200e-04
Loss = 3.8068e-04, PNorm = 39.1255, GNorm = 0.7938, lr_0 = 1.0200e-04
Loss = 3.8466e-04, PNorm = 39.1270, GNorm = 1.4577, lr_0 = 1.0200e-04
Loss = 3.2504e-04, PNorm = 39.1285, GNorm = 2.1433, lr_0 = 1.0200e-04
Loss = 3.4304e-04, PNorm = 39.1291, GNorm = 1.8122, lr_0 = 1.0200e-04
Loss = 3.0863e-04, PNorm = 39.1311, GNorm = 1.5826, lr_0 = 1.0200e-04
Loss = 2.9295e-04, PNorm = 39.1323, GNorm = 0.6246, lr_0 = 1.0200e-04
Loss = 3.1820e-04, PNorm = 39.1340, GNorm = 0.7042, lr_0 = 1.0200e-04
Loss = 3.2522e-04, PNorm = 39.1348, GNorm = 0.5948, lr_0 = 1.0200e-04
Loss = 3.1691e-04, PNorm = 39.1362, GNorm = 2.9716, lr_0 = 1.0200e-04
Loss = 3.9299e-04, PNorm = 39.1368, GNorm = 2.5565, lr_0 = 1.0200e-04
Loss = 3.7632e-04, PNorm = 39.1375, GNorm = 1.8047, lr_0 = 1.0200e-04
Loss = 3.4288e-04, PNorm = 39.1387, GNorm = 1.4402, lr_0 = 1.0200e-04
Loss = 4.7103e-04, PNorm = 39.1400, GNorm = 1.9713, lr_0 = 1.0200e-04
Loss = 3.7174e-04, PNorm = 39.1411, GNorm = 1.1112, lr_0 = 1.0200e-04
Loss = 4.0692e-04, PNorm = 39.1434, GNorm = 1.6825, lr_0 = 1.0200e-04
Loss = 4.4192e-04, PNorm = 39.1455, GNorm = 3.2590, lr_0 = 1.0200e-04
Loss = 5.9484e-04, PNorm = 39.1456, GNorm = 1.4050, lr_0 = 1.0200e-04
Validation rmse logD = 0.561515
Validation R2 logD = 0.776844
Validation rmse logP = 0.476555
Validation R2 logP = 0.933524
Epoch 95
Train function
Loss = 3.4233e-04, PNorm = 39.1483, GNorm = 1.7064, lr_0 = 1.0200e-04
Loss = 3.8985e-04, PNorm = 39.1498, GNorm = 0.9314, lr_0 = 1.0200e-04
Loss = 3.8945e-04, PNorm = 39.1511, GNorm = 0.8923, lr_0 = 1.0200e-04
Loss = 3.1845e-04, PNorm = 39.1523, GNorm = 1.4837, lr_0 = 1.0200e-04
Loss = 3.4368e-04, PNorm = 39.1535, GNorm = 1.1406, lr_0 = 1.0200e-04
Loss = 2.8154e-04, PNorm = 39.1543, GNorm = 1.0098, lr_0 = 1.0200e-04
Loss = 3.6803e-04, PNorm = 39.1556, GNorm = 1.1766, lr_0 = 1.0200e-04
Loss = 3.1176e-04, PNorm = 39.1570, GNorm = 1.0570, lr_0 = 1.0200e-04
Loss = 3.3962e-04, PNorm = 39.1585, GNorm = 1.0399, lr_0 = 1.0200e-04
Loss = 4.1771e-04, PNorm = 39.1589, GNorm = 1.2939, lr_0 = 1.0200e-04
Loss = 3.2134e-04, PNorm = 39.1605, GNorm = 1.3105, lr_0 = 1.0200e-04
Loss = 3.1802e-04, PNorm = 39.1615, GNorm = 0.7635, lr_0 = 1.0200e-04
Loss = 3.7244e-04, PNorm = 39.1634, GNorm = 2.5086, lr_0 = 1.0200e-04
Loss = 3.4855e-04, PNorm = 39.1643, GNorm = 0.7389, lr_0 = 1.0200e-04
Loss = 3.6868e-04, PNorm = 39.1663, GNorm = 0.8691, lr_0 = 1.0200e-04
Loss = 4.5262e-04, PNorm = 39.1679, GNorm = 1.2428, lr_0 = 1.0200e-04
Loss = 4.3995e-04, PNorm = 39.1691, GNorm = 1.0503, lr_0 = 1.0200e-04
Loss = 3.5075e-04, PNorm = 39.1693, GNorm = 0.8364, lr_0 = 1.0200e-04
Loss = 3.8866e-04, PNorm = 39.1697, GNorm = 0.8667, lr_0 = 1.0200e-04
Loss = 2.9125e-04, PNorm = 39.1705, GNorm = 2.9897, lr_0 = 1.0200e-04
Loss = 3.7565e-04, PNorm = 39.1716, GNorm = 1.1365, lr_0 = 1.0200e-04
Loss = 3.5935e-04, PNorm = 39.1722, GNorm = 1.2181, lr_0 = 1.0200e-04
Validation rmse logD = 0.563594
Validation R2 logD = 0.775188
Validation rmse logP = 0.476993
Validation R2 logP = 0.933402
Epoch 96
Train function
Loss = 3.4674e-04, PNorm = 39.1727, GNorm = 0.9368, lr_0 = 1.0200e-04
Loss = 3.7340e-04, PNorm = 39.1741, GNorm = 1.0820, lr_0 = 1.0200e-04
Loss = 3.0989e-04, PNorm = 39.1756, GNorm = 1.2935, lr_0 = 1.0200e-04
Loss = 2.8757e-04, PNorm = 39.1773, GNorm = 0.7400, lr_0 = 1.0200e-04
Loss = 2.6005e-04, PNorm = 39.1784, GNorm = 1.5181, lr_0 = 1.0200e-04
Loss = 2.9166e-04, PNorm = 39.1797, GNorm = 1.2518, lr_0 = 1.0200e-04
Loss = 3.1914e-04, PNorm = 39.1809, GNorm = 0.9111, lr_0 = 1.0200e-04
Loss = 2.6224e-04, PNorm = 39.1820, GNorm = 1.9298, lr_0 = 1.0200e-04
Loss = 2.9848e-04, PNorm = 39.1827, GNorm = 1.5288, lr_0 = 1.0200e-04
Loss = 3.5105e-04, PNorm = 39.1842, GNorm = 0.6172, lr_0 = 1.0200e-04
Loss = 3.7592e-04, PNorm = 39.1852, GNorm = 3.2257, lr_0 = 1.0200e-04
Loss = 3.3435e-04, PNorm = 39.1860, GNorm = 1.3017, lr_0 = 1.0200e-04
Loss = 3.4307e-04, PNorm = 39.1882, GNorm = 2.1419, lr_0 = 1.0200e-04
Loss = 2.6380e-04, PNorm = 39.1897, GNorm = 0.9534, lr_0 = 1.0200e-04
Loss = 2.9344e-04, PNorm = 39.1901, GNorm = 0.9094, lr_0 = 1.0200e-04
Loss = 2.8113e-04, PNorm = 39.1912, GNorm = 0.7925, lr_0 = 1.0200e-04
Loss = 3.0111e-04, PNorm = 39.1929, GNorm = 0.9463, lr_0 = 1.0200e-04
Loss = 4.1515e-04, PNorm = 39.1942, GNorm = 2.3458, lr_0 = 1.0200e-04
Loss = 3.4977e-04, PNorm = 39.1956, GNorm = 1.6665, lr_0 = 1.0200e-04
Loss = 4.8403e-04, PNorm = 39.1967, GNorm = 0.7927, lr_0 = 1.0200e-04
Loss = 3.3266e-04, PNorm = 39.1974, GNorm = 0.4992, lr_0 = 1.0200e-04
Loss = 4.5666e-04, PNorm = 39.1978, GNorm = 3.6023, lr_0 = 1.0200e-04
Loss = 4.3239e-04, PNorm = 39.1994, GNorm = 1.2741, lr_0 = 1.0200e-04
Validation rmse logD = 0.589994
Validation R2 logD = 0.753633
Validation rmse logP = 0.473192
Validation R2 logP = 0.934459
Epoch 97
Train function
Loss = 3.8283e-04, PNorm = 39.2004, GNorm = 0.6832, lr_0 = 1.0200e-04
Loss = 3.8416e-04, PNorm = 39.2026, GNorm = 1.4024, lr_0 = 1.0200e-04
Loss = 4.5635e-04, PNorm = 39.2034, GNorm = 1.4765, lr_0 = 1.0200e-04
Loss = 3.2957e-04, PNorm = 39.2051, GNorm = 1.7162, lr_0 = 1.0200e-04
Loss = 4.0417e-04, PNorm = 39.2054, GNorm = 2.8136, lr_0 = 1.0200e-04
Loss = 5.1324e-04, PNorm = 39.2077, GNorm = 3.6687, lr_0 = 1.0200e-04
Loss = 3.7782e-04, PNorm = 39.2084, GNorm = 0.9719, lr_0 = 1.0200e-04
Loss = 3.4260e-04, PNorm = 39.2091, GNorm = 1.3523, lr_0 = 1.0200e-04
Loss = 3.5350e-04, PNorm = 39.2116, GNorm = 0.8884, lr_0 = 1.0200e-04
Loss = 3.2048e-04, PNorm = 39.2140, GNorm = 1.1983, lr_0 = 1.0200e-04
Loss = 3.8767e-04, PNorm = 39.2159, GNorm = 1.6191, lr_0 = 1.0200e-04
Loss = 3.1572e-04, PNorm = 39.2180, GNorm = 1.0092, lr_0 = 1.0200e-04
Loss = 3.2772e-04, PNorm = 39.2188, GNorm = 1.1040, lr_0 = 1.0200e-04
Loss = 3.5571e-04, PNorm = 39.2202, GNorm = 1.7647, lr_0 = 1.0200e-04
Loss = 3.5094e-04, PNorm = 39.2217, GNorm = 1.6108, lr_0 = 1.0200e-04
Loss = 3.9258e-04, PNorm = 39.2223, GNorm = 1.2791, lr_0 = 1.0200e-04
Loss = 3.1731e-04, PNorm = 39.2232, GNorm = 1.0195, lr_0 = 1.0200e-04
Loss = 3.4238e-04, PNorm = 39.2248, GNorm = 2.3328, lr_0 = 1.0200e-04
Loss = 2.8548e-04, PNorm = 39.2256, GNorm = 0.5530, lr_0 = 1.0200e-04
Loss = 4.1258e-04, PNorm = 39.2266, GNorm = 1.6279, lr_0 = 1.0200e-04
Loss = 4.0303e-04, PNorm = 39.2280, GNorm = 1.1759, lr_0 = 1.0200e-04
Loss = 3.4643e-04, PNorm = 39.2289, GNorm = 1.5793, lr_0 = 1.0200e-04
Validation rmse logD = 0.610168
Validation R2 logD = 0.736497
Validation rmse logP = 0.473714
Validation R2 logP = 0.934314
Epoch 98
Train function
Loss = 4.4106e-04, PNorm = 39.2302, GNorm = 2.1363, lr_0 = 1.0200e-04
Loss = 3.0773e-04, PNorm = 39.2311, GNorm = 0.8278, lr_0 = 1.0200e-04
Loss = 5.0142e-04, PNorm = 39.2332, GNorm = 1.5632, lr_0 = 1.0200e-04
Loss = 3.0932e-04, PNorm = 39.2341, GNorm = 1.4056, lr_0 = 1.0200e-04
Loss = 4.2493e-04, PNorm = 39.2350, GNorm = 1.6119, lr_0 = 1.0200e-04
Loss = 4.4073e-04, PNorm = 39.2363, GNorm = 2.8095, lr_0 = 1.0200e-04
Loss = 4.5839e-04, PNorm = 39.2380, GNorm = 1.5932, lr_0 = 1.0200e-04
Loss = 2.8949e-04, PNorm = 39.2388, GNorm = 1.4474, lr_0 = 1.0200e-04
Loss = 4.7187e-04, PNorm = 39.2407, GNorm = 3.8352, lr_0 = 1.0200e-04
Loss = 4.2290e-04, PNorm = 39.2427, GNorm = 3.0441, lr_0 = 1.0200e-04
Loss = 3.2885e-04, PNorm = 39.2442, GNorm = 0.7442, lr_0 = 1.0200e-04
Loss = 2.8178e-04, PNorm = 39.2451, GNorm = 0.8211, lr_0 = 1.0200e-04
Loss = 2.7072e-04, PNorm = 39.2457, GNorm = 0.8131, lr_0 = 1.0200e-04
Loss = 3.0505e-04, PNorm = 39.2466, GNorm = 0.9590, lr_0 = 1.0200e-04
Loss = 3.3289e-04, PNorm = 39.2468, GNorm = 2.0860, lr_0 = 1.0200e-04
Loss = 4.9492e-04, PNorm = 39.2467, GNorm = 3.2023, lr_0 = 1.0200e-04
Loss = 4.4489e-04, PNorm = 39.2483, GNorm = 0.9758, lr_0 = 1.0200e-04
Loss = 3.7578e-04, PNorm = 39.2494, GNorm = 1.1746, lr_0 = 1.0200e-04
Loss = 3.6371e-04, PNorm = 39.2508, GNorm = 1.6184, lr_0 = 1.0200e-04
Loss = 3.3884e-04, PNorm = 39.2527, GNorm = 1.8784, lr_0 = 1.0200e-04
Loss = 4.7680e-04, PNorm = 39.2544, GNorm = 3.8589, lr_0 = 1.0200e-04
Loss = 4.1042e-04, PNorm = 39.2556, GNorm = 1.5298, lr_0 = 1.0200e-04
Loss = 4.4489e-04, PNorm = 39.2576, GNorm = 1.1715, lr_0 = 1.0200e-04
Validation rmse logD = 0.568751
Validation R2 logD = 0.771055
Validation rmse logP = 0.473189
Validation R2 logP = 0.934460
Epoch 99
Train function
Loss = 3.7065e-04, PNorm = 39.2590, GNorm = 2.5749, lr_0 = 1.0200e-04
Loss = 2.6750e-04, PNorm = 39.2599, GNorm = 1.1524, lr_0 = 1.0200e-04
Loss = 3.2144e-04, PNorm = 39.2618, GNorm = 1.3886, lr_0 = 1.0200e-04
Loss = 2.5674e-04, PNorm = 39.2636, GNorm = 0.9475, lr_0 = 1.0200e-04
Loss = 2.9153e-04, PNorm = 39.2651, GNorm = 0.9069, lr_0 = 1.0200e-04
Loss = 2.8131e-04, PNorm = 39.2668, GNorm = 0.5469, lr_0 = 1.0200e-04
Loss = 3.1616e-04, PNorm = 39.2682, GNorm = 1.0893, lr_0 = 1.0200e-04
Loss = 2.5350e-04, PNorm = 39.2683, GNorm = 1.8319, lr_0 = 1.0200e-04
Loss = 2.7864e-04, PNorm = 39.2684, GNorm = 1.6207, lr_0 = 1.0200e-04
Loss = 2.6772e-04, PNorm = 39.2699, GNorm = 0.6430, lr_0 = 1.0200e-04
Loss = 2.6808e-04, PNorm = 39.2711, GNorm = 1.0636, lr_0 = 1.0200e-04
Loss = 3.0767e-04, PNorm = 39.2717, GNorm = 1.6824, lr_0 = 1.0200e-04
Loss = 4.5321e-04, PNorm = 39.2727, GNorm = 0.8040, lr_0 = 1.0200e-04
Loss = 4.2285e-04, PNorm = 39.2742, GNorm = 1.0240, lr_0 = 1.0200e-04
Loss = 3.6448e-04, PNorm = 39.2758, GNorm = 2.2319, lr_0 = 1.0200e-04
Loss = 3.7594e-04, PNorm = 39.2768, GNorm = 1.3062, lr_0 = 1.0200e-04
Loss = 3.6761e-04, PNorm = 39.2783, GNorm = 0.9902, lr_0 = 1.0200e-04
Loss = 3.3779e-04, PNorm = 39.2804, GNorm = 1.1212, lr_0 = 1.0200e-04
Loss = 3.1784e-04, PNorm = 39.2811, GNorm = 1.5209, lr_0 = 1.0200e-04
Loss = 2.9592e-04, PNorm = 39.2822, GNorm = 1.7351, lr_0 = 1.0200e-04
Loss = 3.5766e-04, PNorm = 39.2834, GNorm = 0.6914, lr_0 = 1.0200e-04
Loss = 3.8004e-04, PNorm = 39.2848, GNorm = 1.1861, lr_0 = 1.0200e-04
Validation rmse logD = 0.558260
Validation R2 logD = 0.779423
Validation rmse logP = 0.490270
Validation R2 logP = 0.929643
Model 0 best validation rmse = 0.509124 on epoch 56
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.558478
Model 0 test R2 logD = 0.802182
Model 0 test rmse logP = 0.456495
Model 0 test R2 logP = 0.940146
Ensemble test rmse  logD= 0.558478
Ensemble test R2  logD= 0.802182
Ensemble test rmse  logP= 0.456495
Ensemble test R2  logP= 0.940146
Fold 3
Command line
python ./scripts/SOTA/dmpnn/train.py --dataset_type regression --num_workers 4 --config_path_yaml ./params.yaml
Args
{'activation': 'ReLU',
 'additional_encoder': False,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'config_path_yaml': './params.yaml',
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': True,
 'data_path': './data/raw/baselines/dmpnn/logp_logd_Lip_wo_averaging_train_val_dataset.csv',
 'dataset_type': 'regression',
 'depth': 6,
 'device': device(type='cuda'),
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 100,
 'features_generator': ['rdkit_2d_normalized_wo_MolLogP'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': 199,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 4,
 'num_lrs': 1,
 'num_tasks': 2,
 'num_workers': 4,
 'pytorch_seed': 0,
 'quiet': False,
 'save_dir': './data/raw/baselines/dmpnn/logs/exp_341/folds/fold_3',
 'save_smiles_splits': False,
 'seed': 3,
 'separate_test_features_path': None,
 'separate_test_path': './data/3_final_data/split_data/logp_logd_Lip_wo_averaging_test.csv',
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_column': 'smiles',
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'k-fold',
 'substructures_atom_messages': False,
 'substructures_depth': False,
 'substructures_hidden_size': 300,
 'substructures_merge': False,
 'substructures_undirected': False,
 'substructures_use_substructures': True,
 'symmetry_feature': False,
 'target_columns': ['logD', 'logP'],
 'task_names': ['logD', 'logP'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': 11274,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 2
Splitting data with seed 3
Total size = 15,032 | train size = 11,274 | val size = 3,758 | test size = 2,653
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=147, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=433, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=499, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 414,902
Moving model to cuda
Epoch 0
Train function
Loss = 2.0438e-02, PNorm = 35.0907, GNorm = 6.8554, lr_0 = 1.0200e-04
Loss = 1.7284e-02, PNorm = 35.0922, GNorm = 6.3844, lr_0 = 1.0200e-04
Loss = 1.7021e-02, PNorm = 35.0937, GNorm = 5.9151, lr_0 = 1.0200e-04
Loss = 1.4250e-02, PNorm = 35.0961, GNorm = 3.6195, lr_0 = 1.0200e-04
Loss = 1.2574e-02, PNorm = 35.0986, GNorm = 2.3323, lr_0 = 1.0200e-04
Loss = 1.2209e-02, PNorm = 35.1013, GNorm = 3.1086, lr_0 = 1.0200e-04
Loss = 1.1324e-02, PNorm = 35.1047, GNorm = 6.1541, lr_0 = 1.0200e-04
Loss = 1.0794e-02, PNorm = 35.1069, GNorm = 1.7913, lr_0 = 1.0200e-04
Loss = 9.6001e-03, PNorm = 35.1099, GNorm = 6.4485, lr_0 = 1.0200e-04
Loss = 9.6825e-03, PNorm = 35.1127, GNorm = 8.6697, lr_0 = 1.0200e-04
Loss = 1.0363e-02, PNorm = 35.1145, GNorm = 4.5125, lr_0 = 1.0200e-04
Loss = 1.0934e-02, PNorm = 35.1171, GNorm = 5.1590, lr_0 = 1.0200e-04
Loss = 8.5328e-03, PNorm = 35.1201, GNorm = 4.9584, lr_0 = 1.0200e-04
Loss = 8.8138e-03, PNorm = 35.1233, GNorm = 6.2763, lr_0 = 1.0200e-04
Loss = 9.8903e-03, PNorm = 35.1257, GNorm = 8.0537, lr_0 = 1.0200e-04
Loss = 8.6120e-03, PNorm = 35.1279, GNorm = 2.3133, lr_0 = 1.0200e-04
Loss = 8.4087e-03, PNorm = 35.1306, GNorm = 5.4822, lr_0 = 1.0200e-04
Loss = 8.2487e-03, PNorm = 35.1333, GNorm = 5.9185, lr_0 = 1.0200e-04
Loss = 8.1230e-03, PNorm = 35.1357, GNorm = 4.9635, lr_0 = 1.0200e-04
Loss = 7.3383e-03, PNorm = 35.1388, GNorm = 2.1604, lr_0 = 1.0200e-04
Loss = 7.6137e-03, PNorm = 35.1416, GNorm = 4.3475, lr_0 = 1.0200e-04
Loss = 8.1225e-03, PNorm = 35.1446, GNorm = 2.1963, lr_0 = 1.0200e-04
Validation rmse logD = 1.112398
Validation R2 logD = 0.142966
Validation rmse logP = 0.978149
Validation R2 logP = 0.722316
Epoch 1
Train function
Loss = 6.3344e-03, PNorm = 35.1477, GNorm = 4.9785, lr_0 = 1.0200e-04
Loss = 6.0342e-03, PNorm = 35.1504, GNorm = 2.5198, lr_0 = 1.0200e-04
Loss = 6.5772e-03, PNorm = 35.1536, GNorm = 2.1834, lr_0 = 1.0200e-04
Loss = 7.4857e-03, PNorm = 35.1563, GNorm = 6.0094, lr_0 = 1.0200e-04
Loss = 8.8541e-03, PNorm = 35.1590, GNorm = 4.2011, lr_0 = 1.0200e-04
Loss = 8.0621e-03, PNorm = 35.1626, GNorm = 5.9400, lr_0 = 1.0200e-04
Loss = 6.3188e-03, PNorm = 35.1652, GNorm = 6.3969, lr_0 = 1.0200e-04
Loss = 5.9819e-03, PNorm = 35.1671, GNorm = 3.9863, lr_0 = 1.0200e-04
Loss = 6.4565e-03, PNorm = 35.1708, GNorm = 3.5235, lr_0 = 1.0200e-04
Loss = 6.1099e-03, PNorm = 35.1743, GNorm = 6.9340, lr_0 = 1.0200e-04
Loss = 5.8417e-03, PNorm = 35.1772, GNorm = 0.8261, lr_0 = 1.0200e-04
Loss = 5.9587e-03, PNorm = 35.1803, GNorm = 7.0421, lr_0 = 1.0200e-04
Loss = 6.6825e-03, PNorm = 35.1830, GNorm = 4.8674, lr_0 = 1.0200e-04
Loss = 6.1452e-03, PNorm = 35.1855, GNorm = 7.1716, lr_0 = 1.0200e-04
Loss = 6.2432e-03, PNorm = 35.1887, GNorm = 1.7287, lr_0 = 1.0200e-04
Loss = 6.1155e-03, PNorm = 35.1912, GNorm = 2.5157, lr_0 = 1.0200e-04
Loss = 5.0688e-03, PNorm = 35.1929, GNorm = 3.2258, lr_0 = 1.0200e-04
Loss = 6.8209e-03, PNorm = 35.1954, GNorm = 1.7716, lr_0 = 1.0200e-04
Loss = 5.5319e-03, PNorm = 35.1984, GNorm = 6.4660, lr_0 = 1.0200e-04
Loss = 5.8867e-03, PNorm = 35.2006, GNorm = 2.5666, lr_0 = 1.0200e-04
Loss = 6.1007e-03, PNorm = 35.2028, GNorm = 6.3951, lr_0 = 1.0200e-04
Loss = 5.7651e-03, PNorm = 35.2049, GNorm = 3.4404, lr_0 = 1.0200e-04
Loss = 6.8142e-03, PNorm = 35.2085, GNorm = 5.0119, lr_0 = 1.0200e-04
Loss = 1.0694e-02, PNorm = 35.2089, GNorm = 7.1163, lr_0 = 1.0200e-04
Validation rmse logD = 0.962749
Validation R2 logD = 0.358046
Validation rmse logP = 0.843347
Validation R2 logP = 0.793579
Epoch 2
Train function
Loss = 4.8215e-03, PNorm = 35.2116, GNorm = 2.8927, lr_0 = 1.0200e-04
Loss = 4.6792e-03, PNorm = 35.2141, GNorm = 2.5056, lr_0 = 1.0200e-04
Loss = 6.1702e-03, PNorm = 35.2170, GNorm = 2.7724, lr_0 = 1.0200e-04
Loss = 5.4767e-03, PNorm = 35.2198, GNorm = 3.4665, lr_0 = 1.0200e-04
Loss = 5.0940e-03, PNorm = 35.2231, GNorm = 3.4808, lr_0 = 1.0200e-04
Loss = 5.0166e-03, PNorm = 35.2250, GNorm = 7.6487, lr_0 = 1.0200e-04
Loss = 5.9047e-03, PNorm = 35.2275, GNorm = 5.7049, lr_0 = 1.0200e-04
Loss = 5.9862e-03, PNorm = 35.2304, GNorm = 2.9634, lr_0 = 1.0200e-04
Loss = 5.3564e-03, PNorm = 35.2327, GNorm = 2.5303, lr_0 = 1.0200e-04
Loss = 5.7051e-03, PNorm = 35.2373, GNorm = 5.9865, lr_0 = 1.0200e-04
Loss = 5.4289e-03, PNorm = 35.2405, GNorm = 5.1307, lr_0 = 1.0200e-04
Loss = 4.7206e-03, PNorm = 35.2431, GNorm = 2.3739, lr_0 = 1.0200e-04
Loss = 6.5896e-03, PNorm = 35.2452, GNorm = 4.0745, lr_0 = 1.0200e-04
Loss = 4.7406e-03, PNorm = 35.2480, GNorm = 1.0930, lr_0 = 1.0200e-04
Loss = 4.8586e-03, PNorm = 35.2504, GNorm = 4.1342, lr_0 = 1.0200e-04
Loss = 5.5811e-03, PNorm = 35.2533, GNorm = 3.9980, lr_0 = 1.0200e-04
Loss = 5.5370e-03, PNorm = 35.2565, GNorm = 4.3822, lr_0 = 1.0200e-04
Loss = 5.0843e-03, PNorm = 35.2598, GNorm = 4.2662, lr_0 = 1.0200e-04
Loss = 5.5788e-03, PNorm = 35.2622, GNorm = 2.2815, lr_0 = 1.0200e-04
Loss = 5.2410e-03, PNorm = 35.2650, GNorm = 6.5600, lr_0 = 1.0200e-04
Loss = 4.8621e-03, PNorm = 35.2665, GNorm = 2.2820, lr_0 = 1.0200e-04
Loss = 5.0022e-03, PNorm = 35.2680, GNorm = 2.8961, lr_0 = 1.0200e-04
Validation rmse logD = 0.903971
Validation R2 logD = 0.434038
Validation rmse logP = 0.807943
Validation R2 logP = 0.810546
Epoch 3
Train function
Loss = 5.1498e-03, PNorm = 35.2708, GNorm = 2.3099, lr_0 = 1.0200e-04
Loss = 4.8116e-03, PNorm = 35.2735, GNorm = 3.5518, lr_0 = 1.0200e-04
Loss = 5.7636e-03, PNorm = 35.2764, GNorm = 3.4198, lr_0 = 1.0200e-04
Loss = 5.0609e-03, PNorm = 35.2794, GNorm = 6.1382, lr_0 = 1.0200e-04
Loss = 5.2197e-03, PNorm = 35.2828, GNorm = 5.4483, lr_0 = 1.0200e-04
Loss = 4.3662e-03, PNorm = 35.2858, GNorm = 2.3873, lr_0 = 1.0200e-04
Loss = 5.7330e-03, PNorm = 35.2885, GNorm = 4.2661, lr_0 = 1.0200e-04
Loss = 4.5451e-03, PNorm = 35.2909, GNorm = 1.9234, lr_0 = 1.0200e-04
Loss = 4.2978e-03, PNorm = 35.2942, GNorm = 2.1731, lr_0 = 1.0200e-04
Loss = 5.1696e-03, PNorm = 35.2965, GNorm = 4.4945, lr_0 = 1.0200e-04
Loss = 4.6116e-03, PNorm = 35.2997, GNorm = 2.5244, lr_0 = 1.0200e-04
Loss = 4.1247e-03, PNorm = 35.3021, GNorm = 1.5945, lr_0 = 1.0200e-04
Loss = 4.4354e-03, PNorm = 35.3046, GNorm = 5.8216, lr_0 = 1.0200e-04
Loss = 4.3790e-03, PNorm = 35.3065, GNorm = 2.3197, lr_0 = 1.0200e-04
Loss = 4.8121e-03, PNorm = 35.3092, GNorm = 3.7573, lr_0 = 1.0200e-04
Loss = 4.4622e-03, PNorm = 35.3123, GNorm = 4.2603, lr_0 = 1.0200e-04
Loss = 4.3414e-03, PNorm = 35.3147, GNorm = 3.8276, lr_0 = 1.0200e-04
Loss = 4.0785e-03, PNorm = 35.3170, GNorm = 3.0157, lr_0 = 1.0200e-04
Loss = 4.4877e-03, PNorm = 35.3188, GNorm = 5.6535, lr_0 = 1.0200e-04
Loss = 4.2189e-03, PNorm = 35.3215, GNorm = 6.3430, lr_0 = 1.0200e-04
Loss = 4.8801e-03, PNorm = 35.3229, GNorm = 9.3390, lr_0 = 1.0200e-04
Loss = 4.2803e-03, PNorm = 35.3248, GNorm = 1.3414, lr_0 = 1.0200e-04
Loss = 4.2436e-03, PNorm = 35.3277, GNorm = 5.9856, lr_0 = 1.0200e-04
Validation rmse logD = 0.881023
Validation R2 logD = 0.462408
Validation rmse logP = 0.728604
Validation R2 logP = 0.845928
Epoch 4
Train function
Loss = 4.1247e-03, PNorm = 35.3316, GNorm = 5.7494, lr_0 = 1.0200e-04
Loss = 4.8683e-03, PNorm = 35.3355, GNorm = 1.6054, lr_0 = 1.0200e-04
Loss = 4.7596e-03, PNorm = 35.3381, GNorm = 4.1645, lr_0 = 1.0200e-04
Loss = 4.0869e-03, PNorm = 35.3410, GNorm = 1.6498, lr_0 = 1.0200e-04
Loss = 4.2081e-03, PNorm = 35.3432, GNorm = 3.4051, lr_0 = 1.0200e-04
Loss = 5.1253e-03, PNorm = 35.3453, GNorm = 6.3260, lr_0 = 1.0200e-04
Loss = 4.0462e-03, PNorm = 35.3483, GNorm = 5.6329, lr_0 = 1.0200e-04
Loss = 4.4859e-03, PNorm = 35.3510, GNorm = 2.0278, lr_0 = 1.0200e-04
Loss = 4.9965e-03, PNorm = 35.3525, GNorm = 5.7848, lr_0 = 1.0200e-04
Loss = 4.1266e-03, PNorm = 35.3540, GNorm = 3.1779, lr_0 = 1.0200e-04
Loss = 4.1411e-03, PNorm = 35.3567, GNorm = 7.1805, lr_0 = 1.0200e-04
Loss = 4.3980e-03, PNorm = 35.3597, GNorm = 4.9371, lr_0 = 1.0200e-04
Loss = 3.9571e-03, PNorm = 35.3623, GNorm = 3.3740, lr_0 = 1.0200e-04
Loss = 4.2436e-03, PNorm = 35.3646, GNorm = 6.4078, lr_0 = 1.0200e-04
Loss = 4.2513e-03, PNorm = 35.3662, GNorm = 8.0424, lr_0 = 1.0200e-04
Loss = 4.4963e-03, PNorm = 35.3683, GNorm = 3.6103, lr_0 = 1.0200e-04
Loss = 3.6302e-03, PNorm = 35.3718, GNorm = 3.0459, lr_0 = 1.0200e-04
Loss = 4.4513e-03, PNorm = 35.3744, GNorm = 1.5298, lr_0 = 1.0200e-04
Loss = 3.6399e-03, PNorm = 35.3775, GNorm = 2.9419, lr_0 = 1.0200e-04
Loss = 3.8428e-03, PNorm = 35.3799, GNorm = 3.9150, lr_0 = 1.0200e-04
Loss = 3.9695e-03, PNorm = 35.3822, GNorm = 2.4974, lr_0 = 1.0200e-04
Loss = 4.2475e-03, PNorm = 35.3860, GNorm = 4.8708, lr_0 = 1.0200e-04
Validation rmse logD = 0.836613
Validation R2 logD = 0.515240
Validation rmse logP = 0.704760
Validation R2 logP = 0.855847
Epoch 5
Train function
Loss = 3.4073e-03, PNorm = 35.3876, GNorm = 3.5878, lr_0 = 1.0200e-04
Loss = 4.3276e-03, PNorm = 35.3903, GNorm = 2.6357, lr_0 = 1.0200e-04
Loss = 3.9299e-03, PNorm = 35.3929, GNorm = 2.5447, lr_0 = 1.0200e-04
Loss = 3.6632e-03, PNorm = 35.3953, GNorm = 5.4126, lr_0 = 1.0200e-04
Loss = 3.5389e-03, PNorm = 35.3980, GNorm = 5.0534, lr_0 = 1.0200e-04
Loss = 3.8976e-03, PNorm = 35.4004, GNorm = 1.5753, lr_0 = 1.0200e-04
Loss = 2.9861e-03, PNorm = 35.4029, GNorm = 5.7131, lr_0 = 1.0200e-04
Loss = 3.9356e-03, PNorm = 35.4058, GNorm = 3.5762, lr_0 = 1.0200e-04
Loss = 3.5429e-03, PNorm = 35.4087, GNorm = 1.5056, lr_0 = 1.0200e-04
Loss = 4.0045e-03, PNorm = 35.4116, GNorm = 1.7043, lr_0 = 1.0200e-04
Loss = 3.9213e-03, PNorm = 35.4144, GNorm = 2.6573, lr_0 = 1.0200e-04
Loss = 4.1780e-03, PNorm = 35.4167, GNorm = 3.8993, lr_0 = 1.0200e-04
Loss = 4.8036e-03, PNorm = 35.4188, GNorm = 6.2082, lr_0 = 1.0200e-04
Loss = 4.1547e-03, PNorm = 35.4213, GNorm = 1.4445, lr_0 = 1.0200e-04
Loss = 4.1132e-03, PNorm = 35.4240, GNorm = 6.0803, lr_0 = 1.0200e-04
Loss = 4.2459e-03, PNorm = 35.4252, GNorm = 6.2672, lr_0 = 1.0200e-04
Loss = 4.1835e-03, PNorm = 35.4275, GNorm = 7.6343, lr_0 = 1.0200e-04
Loss = 3.7770e-03, PNorm = 35.4305, GNorm = 1.8942, lr_0 = 1.0200e-04
Loss = 3.7072e-03, PNorm = 35.4332, GNorm = 2.5349, lr_0 = 1.0200e-04
Loss = 4.3072e-03, PNorm = 35.4357, GNorm = 3.0875, lr_0 = 1.0200e-04
Loss = 4.3945e-03, PNorm = 35.4384, GNorm = 3.5541, lr_0 = 1.0200e-04
Loss = 3.6319e-03, PNorm = 35.4409, GNorm = 3.0766, lr_0 = 1.0200e-04
Loss = 4.2393e-03, PNorm = 35.4435, GNorm = 2.3748, lr_0 = 1.0200e-04
Validation rmse logD = 0.824699
Validation R2 logD = 0.528949
Validation rmse logP = 0.681166
Validation R2 logP = 0.865338
Epoch 6
Train function
Loss = 3.6356e-03, PNorm = 35.4471, GNorm = 4.4048, lr_0 = 1.0200e-04
Loss = 3.3143e-03, PNorm = 35.4491, GNorm = 2.0345, lr_0 = 1.0200e-04
Loss = 3.4867e-03, PNorm = 35.4518, GNorm = 5.1814, lr_0 = 1.0200e-04
Loss = 4.0571e-03, PNorm = 35.4551, GNorm = 7.8642, lr_0 = 1.0200e-04
Loss = 4.4281e-03, PNorm = 35.4571, GNorm = 5.5332, lr_0 = 1.0200e-04
Loss = 4.2700e-03, PNorm = 35.4591, GNorm = 2.4438, lr_0 = 1.0200e-04
Loss = 4.0027e-03, PNorm = 35.4612, GNorm = 2.3558, lr_0 = 1.0200e-04
Loss = 3.6266e-03, PNorm = 35.4630, GNorm = 2.7316, lr_0 = 1.0200e-04
Loss = 3.6597e-03, PNorm = 35.4662, GNorm = 5.3804, lr_0 = 1.0200e-04
Loss = 3.7596e-03, PNorm = 35.4693, GNorm = 3.3899, lr_0 = 1.0200e-04
Loss = 3.3458e-03, PNorm = 35.4727, GNorm = 2.1540, lr_0 = 1.0200e-04
Loss = 3.3452e-03, PNorm = 35.4756, GNorm = 3.6548, lr_0 = 1.0200e-04
Loss = 3.9484e-03, PNorm = 35.4786, GNorm = 6.8331, lr_0 = 1.0200e-04
Loss = 4.0180e-03, PNorm = 35.4805, GNorm = 2.9387, lr_0 = 1.0200e-04
Loss = 3.7509e-03, PNorm = 35.4826, GNorm = 4.4224, lr_0 = 1.0200e-04
Loss = 3.1298e-03, PNorm = 35.4854, GNorm = 5.1624, lr_0 = 1.0200e-04
Loss = 4.1540e-03, PNorm = 35.4886, GNorm = 5.7879, lr_0 = 1.0200e-04
Loss = 3.4804e-03, PNorm = 35.4919, GNorm = 5.5499, lr_0 = 1.0200e-04
Loss = 3.9435e-03, PNorm = 35.4939, GNorm = 4.6703, lr_0 = 1.0200e-04
Loss = 3.9663e-03, PNorm = 35.4968, GNorm = 9.1949, lr_0 = 1.0200e-04
Loss = 3.3857e-03, PNorm = 35.4998, GNorm = 1.8771, lr_0 = 1.0200e-04
Loss = 3.6016e-03, PNorm = 35.5020, GNorm = 2.1535, lr_0 = 1.0200e-04
Validation rmse logD = 0.793837
Validation R2 logD = 0.563544
Validation rmse logP = 0.640844
Validation R2 logP = 0.880809
Epoch 7
Train function
Loss = 5.6114e-03, PNorm = 35.5048, GNorm = 3.4683, lr_0 = 1.0200e-04
Loss = 3.4467e-03, PNorm = 35.5068, GNorm = 2.2972, lr_0 = 1.0200e-04
Loss = 3.0160e-03, PNorm = 35.5090, GNorm = 1.5952, lr_0 = 1.0200e-04
Loss = 3.7640e-03, PNorm = 35.5112, GNorm = 1.9313, lr_0 = 1.0200e-04
Loss = 3.7058e-03, PNorm = 35.5147, GNorm = 4.4672, lr_0 = 1.0200e-04
Loss = 3.5963e-03, PNorm = 35.5176, GNorm = 3.7846, lr_0 = 1.0200e-04
Loss = 3.2497e-03, PNorm = 35.5199, GNorm = 5.5880, lr_0 = 1.0200e-04
Loss = 4.3918e-03, PNorm = 35.5224, GNorm = 6.5445, lr_0 = 1.0200e-04
Loss = 3.5116e-03, PNorm = 35.5256, GNorm = 3.3764, lr_0 = 1.0200e-04
Loss = 4.1664e-03, PNorm = 35.5283, GNorm = 6.6328, lr_0 = 1.0200e-04
Loss = 3.8036e-03, PNorm = 35.5312, GNorm = 2.4937, lr_0 = 1.0200e-04
Loss = 2.6537e-03, PNorm = 35.5338, GNorm = 2.0201, lr_0 = 1.0200e-04
Loss = 2.7034e-03, PNorm = 35.5368, GNorm = 2.6304, lr_0 = 1.0200e-04
Loss = 3.3549e-03, PNorm = 35.5395, GNorm = 2.5082, lr_0 = 1.0200e-04
Loss = 3.3938e-03, PNorm = 35.5415, GNorm = 3.3623, lr_0 = 1.0200e-04
Loss = 3.8588e-03, PNorm = 35.5449, GNorm = 2.5254, lr_0 = 1.0200e-04
Loss = 2.7579e-03, PNorm = 35.5479, GNorm = 2.7749, lr_0 = 1.0200e-04
Loss = 3.1971e-03, PNorm = 35.5505, GNorm = 5.6317, lr_0 = 1.0200e-04
Loss = 3.2482e-03, PNorm = 35.5516, GNorm = 4.3556, lr_0 = 1.0200e-04
Loss = 2.9715e-03, PNorm = 35.5536, GNorm = 2.0756, lr_0 = 1.0200e-04
Loss = 3.6560e-03, PNorm = 35.5563, GNorm = 7.1348, lr_0 = 1.0200e-04
Loss = 3.5919e-03, PNorm = 35.5591, GNorm = 2.8609, lr_0 = 1.0200e-04
Loss = 3.7504e-03, PNorm = 35.5627, GNorm = 3.6235, lr_0 = 1.0200e-04
Validation rmse logD = 0.790218
Validation R2 logD = 0.567515
Validation rmse logP = 0.619148
Validation R2 logP = 0.888742
Epoch 8
Train function
Loss = 3.2293e-03, PNorm = 35.5659, GNorm = 2.0140, lr_0 = 1.0200e-04
Loss = 3.4115e-03, PNorm = 35.5686, GNorm = 1.8436, lr_0 = 1.0200e-04
Loss = 3.7146e-03, PNorm = 35.5712, GNorm = 3.7656, lr_0 = 1.0200e-04
Loss = 4.0074e-03, PNorm = 35.5736, GNorm = 4.0831, lr_0 = 1.0200e-04
Loss = 3.6077e-03, PNorm = 35.5764, GNorm = 3.8988, lr_0 = 1.0200e-04
Loss = 4.6076e-03, PNorm = 35.5786, GNorm = 5.4508, lr_0 = 1.0200e-04
Loss = 4.0576e-03, PNorm = 35.5807, GNorm = 3.7648, lr_0 = 1.0200e-04
Loss = 2.8417e-03, PNorm = 35.5830, GNorm = 3.2986, lr_0 = 1.0200e-04
Loss = 3.0655e-03, PNorm = 35.5851, GNorm = 4.8574, lr_0 = 1.0200e-04
Loss = 3.3877e-03, PNorm = 35.5882, GNorm = 1.2344, lr_0 = 1.0200e-04
Loss = 3.6907e-03, PNorm = 35.5917, GNorm = 2.2428, lr_0 = 1.0200e-04
Loss = 3.2685e-03, PNorm = 35.5954, GNorm = 3.5445, lr_0 = 1.0200e-04
Loss = 3.1805e-03, PNorm = 35.5984, GNorm = 1.8437, lr_0 = 1.0200e-04
Loss = 2.8468e-03, PNorm = 35.6008, GNorm = 1.6805, lr_0 = 1.0200e-04
Loss = 2.7625e-03, PNorm = 35.6028, GNorm = 4.2004, lr_0 = 1.0200e-04
Loss = 3.2016e-03, PNorm = 35.6050, GNorm = 3.5720, lr_0 = 1.0200e-04
Loss = 3.4797e-03, PNorm = 35.6069, GNorm = 5.7221, lr_0 = 1.0200e-04
Loss = 3.3772e-03, PNorm = 35.6094, GNorm = 4.3587, lr_0 = 1.0200e-04
Loss = 2.7990e-03, PNorm = 35.6122, GNorm = 2.0473, lr_0 = 1.0200e-04
Loss = 3.7649e-03, PNorm = 35.6149, GNorm = 4.4437, lr_0 = 1.0200e-04
Loss = 3.2527e-03, PNorm = 35.6182, GNorm = 1.4473, lr_0 = 1.0200e-04
Loss = 2.7546e-03, PNorm = 35.6207, GNorm = 1.2616, lr_0 = 1.0200e-04
Validation rmse logD = 0.801757
Validation R2 logD = 0.554792
Validation rmse logP = 0.607164
Validation R2 logP = 0.893008
Epoch 9
Train function
Loss = 2.1160e-03, PNorm = 35.6237, GNorm = 5.6982, lr_0 = 1.0200e-04
Loss = 2.9069e-03, PNorm = 35.6260, GNorm = 7.2440, lr_0 = 1.0200e-04
Loss = 3.1152e-03, PNorm = 35.6284, GNorm = 3.0975, lr_0 = 1.0200e-04
Loss = 3.1857e-03, PNorm = 35.6308, GNorm = 3.5015, lr_0 = 1.0200e-04
Loss = 3.3538e-03, PNorm = 35.6339, GNorm = 7.0486, lr_0 = 1.0200e-04
Loss = 3.4798e-03, PNorm = 35.6360, GNorm = 4.1675, lr_0 = 1.0200e-04
Loss = 3.2502e-03, PNorm = 35.6392, GNorm = 3.0245, lr_0 = 1.0200e-04
Loss = 2.8658e-03, PNorm = 35.6419, GNorm = 4.0760, lr_0 = 1.0200e-04
Loss = 2.9449e-03, PNorm = 35.6441, GNorm = 6.2852, lr_0 = 1.0200e-04
Loss = 2.7953e-03, PNorm = 35.6465, GNorm = 3.0996, lr_0 = 1.0200e-04
Loss = 2.6236e-03, PNorm = 35.6490, GNorm = 2.8896, lr_0 = 1.0200e-04
Loss = 3.9776e-03, PNorm = 35.6515, GNorm = 3.7358, lr_0 = 1.0200e-04
Loss = 2.7654e-03, PNorm = 35.6544, GNorm = 5.9235, lr_0 = 1.0200e-04
Loss = 3.0559e-03, PNorm = 35.6573, GNorm = 4.2824, lr_0 = 1.0200e-04
Loss = 3.1669e-03, PNorm = 35.6596, GNorm = 4.4155, lr_0 = 1.0200e-04
Loss = 3.5274e-03, PNorm = 35.6621, GNorm = 2.7549, lr_0 = 1.0200e-04
Loss = 3.0380e-03, PNorm = 35.6651, GNorm = 3.5127, lr_0 = 1.0200e-04
Loss = 3.7465e-03, PNorm = 35.6672, GNorm = 2.0572, lr_0 = 1.0200e-04
Loss = 3.3306e-03, PNorm = 35.6700, GNorm = 10.5226, lr_0 = 1.0200e-04
Loss = 4.1829e-03, PNorm = 35.6727, GNorm = 5.5743, lr_0 = 1.0200e-04
Loss = 3.4393e-03, PNorm = 35.6761, GNorm = 1.8233, lr_0 = 1.0200e-04
Loss = 2.9124e-03, PNorm = 35.6788, GNorm = 5.3322, lr_0 = 1.0200e-04
Loss = 2.7228e-03, PNorm = 35.6809, GNorm = 1.4585, lr_0 = 1.0200e-04
Validation rmse logD = 0.773622
Validation R2 logD = 0.585489
Validation rmse logP = 0.607970
Validation R2 logP = 0.892723
Epoch 10
Train function
Loss = 3.2899e-03, PNorm = 35.6842, GNorm = 2.9773, lr_0 = 1.0200e-04
Loss = 2.7900e-03, PNorm = 35.6871, GNorm = 3.2227, lr_0 = 1.0200e-04
Loss = 3.2341e-03, PNorm = 35.6899, GNorm = 4.9210, lr_0 = 1.0200e-04
Loss = 2.5355e-03, PNorm = 35.6919, GNorm = 3.6718, lr_0 = 1.0200e-04
Loss = 2.8126e-03, PNorm = 35.6946, GNorm = 2.8713, lr_0 = 1.0200e-04
Loss = 3.6409e-03, PNorm = 35.6977, GNorm = 7.7292, lr_0 = 1.0200e-04
Loss = 3.6944e-03, PNorm = 35.7006, GNorm = 3.6599, lr_0 = 1.0200e-04
Loss = 2.9239e-03, PNorm = 35.7038, GNorm = 4.8559, lr_0 = 1.0200e-04
Loss = 3.3302e-03, PNorm = 35.7062, GNorm = 2.4688, lr_0 = 1.0200e-04
Loss = 3.0925e-03, PNorm = 35.7089, GNorm = 2.8737, lr_0 = 1.0200e-04
Loss = 3.4207e-03, PNorm = 35.7117, GNorm = 6.0819, lr_0 = 1.0200e-04
Loss = 2.8348e-03, PNorm = 35.7142, GNorm = 1.5027, lr_0 = 1.0200e-04
Loss = 2.7525e-03, PNorm = 35.7164, GNorm = 2.2387, lr_0 = 1.0200e-04
Loss = 2.5620e-03, PNorm = 35.7189, GNorm = 3.9147, lr_0 = 1.0200e-04
Loss = 3.2470e-03, PNorm = 35.7218, GNorm = 2.6110, lr_0 = 1.0200e-04
Loss = 2.9585e-03, PNorm = 35.7242, GNorm = 4.4612, lr_0 = 1.0200e-04
Loss = 2.6314e-03, PNorm = 35.7262, GNorm = 3.0832, lr_0 = 1.0200e-04
Loss = 2.6739e-03, PNorm = 35.7293, GNorm = 2.4701, lr_0 = 1.0200e-04
Loss = 3.4150e-03, PNorm = 35.7321, GNorm = 7.3823, lr_0 = 1.0200e-04
Loss = 2.7593e-03, PNorm = 35.7350, GNorm = 4.1978, lr_0 = 1.0200e-04
Loss = 2.6331e-03, PNorm = 35.7383, GNorm = 1.8961, lr_0 = 1.0200e-04
Loss = 2.6383e-03, PNorm = 35.7407, GNorm = 3.3805, lr_0 = 1.0200e-04
Loss = 2.7530e-03, PNorm = 35.7435, GNorm = 3.9935, lr_0 = 1.0200e-04
Validation rmse logD = 0.736749
Validation R2 logD = 0.624062
Validation rmse logP = 0.577566
Validation R2 logP = 0.903185
Epoch 11
Train function
Loss = 2.3506e-03, PNorm = 35.7453, GNorm = 2.8746, lr_0 = 1.0200e-04
Loss = 3.2541e-03, PNorm = 35.7477, GNorm = 11.1747, lr_0 = 1.0200e-04
Loss = 2.7225e-03, PNorm = 35.7504, GNorm = 3.8235, lr_0 = 1.0200e-04
Loss = 2.7760e-03, PNorm = 35.7542, GNorm = 6.1388, lr_0 = 1.0200e-04
Loss = 2.7544e-03, PNorm = 35.7573, GNorm = 3.6254, lr_0 = 1.0200e-04
Loss = 3.2872e-03, PNorm = 35.7597, GNorm = 0.9361, lr_0 = 1.0200e-04
Loss = 3.0969e-03, PNorm = 35.7621, GNorm = 3.7489, lr_0 = 1.0200e-04
Loss = 2.6842e-03, PNorm = 35.7646, GNorm = 5.6800, lr_0 = 1.0200e-04
Loss = 3.4419e-03, PNorm = 35.7671, GNorm = 5.7667, lr_0 = 1.0200e-04
Loss = 2.9988e-03, PNorm = 35.7683, GNorm = 3.2698, lr_0 = 1.0200e-04
Loss = 2.8208e-03, PNorm = 35.7703, GNorm = 2.5408, lr_0 = 1.0200e-04
Loss = 3.1647e-03, PNorm = 35.7731, GNorm = 2.6633, lr_0 = 1.0200e-04
Loss = 2.3497e-03, PNorm = 35.7763, GNorm = 1.0865, lr_0 = 1.0200e-04
Loss = 2.4202e-03, PNorm = 35.7791, GNorm = 1.6680, lr_0 = 1.0200e-04
Loss = 2.5964e-03, PNorm = 35.7814, GNorm = 1.6495, lr_0 = 1.0200e-04
Loss = 3.0818e-03, PNorm = 35.7840, GNorm = 2.1121, lr_0 = 1.0200e-04
Loss = 3.2944e-03, PNorm = 35.7866, GNorm = 5.2690, lr_0 = 1.0200e-04
Loss = 2.7012e-03, PNorm = 35.7894, GNorm = 2.1952, lr_0 = 1.0200e-04
Loss = 3.1218e-03, PNorm = 35.7928, GNorm = 3.6478, lr_0 = 1.0200e-04
Loss = 3.4654e-03, PNorm = 35.7961, GNorm = 1.7038, lr_0 = 1.0200e-04
Loss = 2.6396e-03, PNorm = 35.7989, GNorm = 4.1203, lr_0 = 1.0200e-04
Loss = 2.7276e-03, PNorm = 35.8015, GNorm = 4.8453, lr_0 = 1.0200e-04
Validation rmse logD = 0.715114
Validation R2 logD = 0.645816
Validation rmse logP = 0.575297
Validation R2 logP = 0.903944
Epoch 12
Train function
Loss = 2.4121e-03, PNorm = 35.8042, GNorm = 2.0200, lr_0 = 1.0200e-04
Loss = 3.0578e-03, PNorm = 35.8063, GNorm = 7.1380, lr_0 = 1.0200e-04
Loss = 2.4642e-03, PNorm = 35.8094, GNorm = 2.3915, lr_0 = 1.0200e-04
Loss = 2.3705e-03, PNorm = 35.8119, GNorm = 1.9349, lr_0 = 1.0200e-04
Loss = 3.0883e-03, PNorm = 35.8146, GNorm = 4.4204, lr_0 = 1.0200e-04
Loss = 2.3822e-03, PNorm = 35.8178, GNorm = 1.5596, lr_0 = 1.0200e-04
Loss = 2.2628e-03, PNorm = 35.8211, GNorm = 1.3163, lr_0 = 1.0200e-04
Loss = 2.8616e-03, PNorm = 35.8241, GNorm = 3.1050, lr_0 = 1.0200e-04
Loss = 3.2651e-03, PNorm = 35.8268, GNorm = 11.3996, lr_0 = 1.0200e-04
Loss = 3.3341e-03, PNorm = 35.8299, GNorm = 4.4698, lr_0 = 1.0200e-04
Loss = 3.2804e-03, PNorm = 35.8328, GNorm = 2.4963, lr_0 = 1.0200e-04
Loss = 3.0657e-03, PNorm = 35.8366, GNorm = 8.2729, lr_0 = 1.0200e-04
Loss = 2.1557e-03, PNorm = 35.8392, GNorm = 2.5733, lr_0 = 1.0200e-04
Loss = 2.5410e-03, PNorm = 35.8414, GNorm = 2.5726, lr_0 = 1.0200e-04
Loss = 2.3997e-03, PNorm = 35.8435, GNorm = 3.3932, lr_0 = 1.0200e-04
Loss = 3.0745e-03, PNorm = 35.8454, GNorm = 5.9059, lr_0 = 1.0200e-04
Loss = 2.4673e-03, PNorm = 35.8478, GNorm = 1.3641, lr_0 = 1.0200e-04
Loss = 2.6889e-03, PNorm = 35.8503, GNorm = 1.7464, lr_0 = 1.0200e-04
Loss = 2.6391e-03, PNorm = 35.8521, GNorm = 1.7902, lr_0 = 1.0200e-04
Loss = 2.6147e-03, PNorm = 35.8540, GNorm = 2.4664, lr_0 = 1.0200e-04
Loss = 2.6002e-03, PNorm = 35.8567, GNorm = 1.3899, lr_0 = 1.0200e-04
Loss = 2.6707e-03, PNorm = 35.8597, GNorm = 3.8107, lr_0 = 1.0200e-04
Loss = 2.4335e-03, PNorm = 35.8621, GNorm = 2.7165, lr_0 = 1.0200e-04
Validation rmse logD = 0.712643
Validation R2 logD = 0.648260
Validation rmse logP = 0.560578
Validation R2 logP = 0.908796
Epoch 13
Train function
Loss = 2.1954e-03, PNorm = 35.8651, GNorm = 1.7385, lr_0 = 1.0200e-04
Loss = 2.9360e-03, PNorm = 35.8677, GNorm = 8.6150, lr_0 = 1.0200e-04
Loss = 2.7879e-03, PNorm = 35.8697, GNorm = 2.3904, lr_0 = 1.0200e-04
Loss = 2.6395e-03, PNorm = 35.8723, GNorm = 7.4123, lr_0 = 1.0200e-04
Loss = 2.8370e-03, PNorm = 35.8742, GNorm = 5.0730, lr_0 = 1.0200e-04
Loss = 2.9417e-03, PNorm = 35.8763, GNorm = 9.2898, lr_0 = 1.0200e-04
Loss = 2.4072e-03, PNorm = 35.8787, GNorm = 4.3614, lr_0 = 1.0200e-04
Loss = 2.4743e-03, PNorm = 35.8809, GNorm = 3.7464, lr_0 = 1.0200e-04
Loss = 2.7069e-03, PNorm = 35.8841, GNorm = 1.6241, lr_0 = 1.0200e-04
Loss = 2.2145e-03, PNorm = 35.8862, GNorm = 0.9850, lr_0 = 1.0200e-04
Loss = 2.5054e-03, PNorm = 35.8889, GNorm = 3.3174, lr_0 = 1.0200e-04
Loss = 2.7338e-03, PNorm = 35.8924, GNorm = 2.5029, lr_0 = 1.0200e-04
Loss = 2.6151e-03, PNorm = 35.8955, GNorm = 3.5706, lr_0 = 1.0200e-04
Loss = 2.7053e-03, PNorm = 35.8994, GNorm = 4.5501, lr_0 = 1.0200e-04
Loss = 3.7377e-03, PNorm = 35.9028, GNorm = 9.5296, lr_0 = 1.0200e-04
Loss = 2.8853e-03, PNorm = 35.9061, GNorm = 3.2607, lr_0 = 1.0200e-04
Loss = 2.5541e-03, PNorm = 35.9085, GNorm = 2.6112, lr_0 = 1.0200e-04
Loss = 2.7431e-03, PNorm = 35.9108, GNorm = 3.8917, lr_0 = 1.0200e-04
Loss = 2.3240e-03, PNorm = 35.9127, GNorm = 4.4382, lr_0 = 1.0200e-04
Loss = 2.7110e-03, PNorm = 35.9144, GNorm = 3.2339, lr_0 = 1.0200e-04
Loss = 2.4576e-03, PNorm = 35.9166, GNorm = 1.8575, lr_0 = 1.0200e-04
Loss = 2.4624e-03, PNorm = 35.9205, GNorm = 3.5527, lr_0 = 1.0200e-04
Validation rmse logD = 0.705273
Validation R2 logD = 0.655498
Validation rmse logP = 0.566256
Validation R2 logP = 0.906939
Epoch 14
Train function
Loss = 1.8843e-03, PNorm = 35.9250, GNorm = 2.3166, lr_0 = 1.0200e-04
Loss = 2.4388e-03, PNorm = 35.9286, GNorm = 2.4854, lr_0 = 1.0200e-04
Loss = 2.6027e-03, PNorm = 35.9316, GNorm = 5.0289, lr_0 = 1.0200e-04
Loss = 2.1869e-03, PNorm = 35.9331, GNorm = 1.6481, lr_0 = 1.0200e-04
Loss = 2.5193e-03, PNorm = 35.9353, GNorm = 4.9120, lr_0 = 1.0200e-04
Loss = 3.0366e-03, PNorm = 35.9378, GNorm = 2.2550, lr_0 = 1.0200e-04
Loss = 2.1266e-03, PNorm = 35.9400, GNorm = 3.5956, lr_0 = 1.0200e-04
Loss = 2.4800e-03, PNorm = 35.9422, GNorm = 5.0253, lr_0 = 1.0200e-04
Loss = 2.3465e-03, PNorm = 35.9451, GNorm = 4.0323, lr_0 = 1.0200e-04
Loss = 2.3686e-03, PNorm = 35.9483, GNorm = 2.6946, lr_0 = 1.0200e-04
Loss = 2.4896e-03, PNorm = 35.9510, GNorm = 2.7090, lr_0 = 1.0200e-04
Loss = 2.2283e-03, PNorm = 35.9536, GNorm = 6.2437, lr_0 = 1.0200e-04
Loss = 3.1856e-03, PNorm = 35.9553, GNorm = 2.1785, lr_0 = 1.0200e-04
Loss = 2.8546e-03, PNorm = 35.9568, GNorm = 3.4325, lr_0 = 1.0200e-04
Loss = 2.3635e-03, PNorm = 35.9592, GNorm = 1.5836, lr_0 = 1.0200e-04
Loss = 2.1901e-03, PNorm = 35.9626, GNorm = 1.6381, lr_0 = 1.0200e-04
Loss = 2.5263e-03, PNorm = 35.9650, GNorm = 4.5214, lr_0 = 1.0200e-04
Loss = 2.2682e-03, PNorm = 35.9671, GNorm = 1.9885, lr_0 = 1.0200e-04
Loss = 2.3636e-03, PNorm = 35.9689, GNorm = 3.0521, lr_0 = 1.0200e-04
Loss = 2.5389e-03, PNorm = 35.9713, GNorm = 5.3778, lr_0 = 1.0200e-04
Loss = 2.5350e-03, PNorm = 35.9739, GNorm = 1.8113, lr_0 = 1.0200e-04
Loss = 2.5978e-03, PNorm = 35.9761, GNorm = 4.7140, lr_0 = 1.0200e-04
Loss = 2.3104e-03, PNorm = 35.9784, GNorm = 1.8355, lr_0 = 1.0200e-04
Validation rmse logD = 0.716239
Validation R2 logD = 0.644701
Validation rmse logP = 0.601184
Validation R2 logP = 0.895105
Epoch 15
Train function
Loss = 2.5380e-03, PNorm = 35.9810, GNorm = 5.9631, lr_0 = 1.0200e-04
Loss = 2.5443e-03, PNorm = 35.9837, GNorm = 1.5406, lr_0 = 1.0200e-04
Loss = 2.7925e-03, PNorm = 35.9867, GNorm = 3.8671, lr_0 = 1.0200e-04
Loss = 2.7267e-03, PNorm = 35.9893, GNorm = 3.4776, lr_0 = 1.0200e-04
Loss = 2.2589e-03, PNorm = 35.9925, GNorm = 2.4098, lr_0 = 1.0200e-04
Loss = 2.0729e-03, PNorm = 35.9951, GNorm = 5.2690, lr_0 = 1.0200e-04
Loss = 1.9662e-03, PNorm = 35.9975, GNorm = 3.2045, lr_0 = 1.0200e-04
Loss = 2.4778e-03, PNorm = 35.9999, GNorm = 1.4031, lr_0 = 1.0200e-04
Loss = 2.5840e-03, PNorm = 36.0021, GNorm = 3.5819, lr_0 = 1.0200e-04
Loss = 2.7839e-03, PNorm = 36.0059, GNorm = 3.4295, lr_0 = 1.0200e-04
Loss = 2.2519e-03, PNorm = 36.0090, GNorm = 1.3763, lr_0 = 1.0200e-04
Loss = 2.3705e-03, PNorm = 36.0117, GNorm = 3.9995, lr_0 = 1.0200e-04
Loss = 2.1488e-03, PNorm = 36.0146, GNorm = 7.0806, lr_0 = 1.0200e-04
Loss = 3.2517e-03, PNorm = 36.0177, GNorm = 6.8734, lr_0 = 1.0200e-04
Loss = 2.2551e-03, PNorm = 36.0209, GNorm = 3.7349, lr_0 = 1.0200e-04
Loss = 2.5567e-03, PNorm = 36.0240, GNorm = 4.2709, lr_0 = 1.0200e-04
Loss = 2.3393e-03, PNorm = 36.0271, GNorm = 3.2162, lr_0 = 1.0200e-04
Loss = 2.6035e-03, PNorm = 36.0286, GNorm = 5.2894, lr_0 = 1.0200e-04
Loss = 1.9623e-03, PNorm = 36.0295, GNorm = 2.3964, lr_0 = 1.0200e-04
Loss = 1.8467e-03, PNorm = 36.0306, GNorm = 3.5179, lr_0 = 1.0200e-04
Loss = 2.2287e-03, PNorm = 36.0331, GNorm = 2.4155, lr_0 = 1.0200e-04
Loss = 2.4304e-03, PNorm = 36.0353, GNorm = 2.6680, lr_0 = 1.0200e-04
Validation rmse logD = 0.681324
Validation R2 logD = 0.678497
Validation rmse logP = 0.550598
Validation R2 logP = 0.912015
Epoch 16
Train function
Loss = 1.7917e-03, PNorm = 36.0370, GNorm = 4.0151, lr_0 = 1.0200e-04
Loss = 2.4211e-03, PNorm = 36.0390, GNorm = 2.0261, lr_0 = 1.0200e-04
Loss = 2.9490e-03, PNorm = 36.0414, GNorm = 11.1866, lr_0 = 1.0200e-04
Loss = 2.3567e-03, PNorm = 36.0440, GNorm = 2.6154, lr_0 = 1.0200e-04
Loss = 2.2722e-03, PNorm = 36.0469, GNorm = 1.9664, lr_0 = 1.0200e-04
Loss = 2.2510e-03, PNorm = 36.0501, GNorm = 2.2485, lr_0 = 1.0200e-04
Loss = 2.6644e-03, PNorm = 36.0530, GNorm = 1.9272, lr_0 = 1.0200e-04
Loss = 2.1112e-03, PNorm = 36.0556, GNorm = 1.8573, lr_0 = 1.0200e-04
Loss = 2.3236e-03, PNorm = 36.0579, GNorm = 3.8799, lr_0 = 1.0200e-04
Loss = 2.1363e-03, PNorm = 36.0592, GNorm = 2.4328, lr_0 = 1.0200e-04
Loss = 2.2648e-03, PNorm = 36.0619, GNorm = 2.2828, lr_0 = 1.0200e-04
Loss = 2.4745e-03, PNorm = 36.0643, GNorm = 1.1103, lr_0 = 1.0200e-04
Loss = 2.8589e-03, PNorm = 36.0668, GNorm = 2.9301, lr_0 = 1.0200e-04
Loss = 1.8995e-03, PNorm = 36.0688, GNorm = 3.6690, lr_0 = 1.0200e-04
Loss = 2.7320e-03, PNorm = 36.0711, GNorm = 1.4128, lr_0 = 1.0200e-04
Loss = 2.4410e-03, PNorm = 36.0738, GNorm = 1.8067, lr_0 = 1.0200e-04
Loss = 1.9594e-03, PNorm = 36.0766, GNorm = 2.5919, lr_0 = 1.0200e-04
Loss = 2.3936e-03, PNorm = 36.0793, GNorm = 5.4414, lr_0 = 1.0200e-04
Loss = 2.1934e-03, PNorm = 36.0814, GNorm = 2.7755, lr_0 = 1.0200e-04
Loss = 1.9524e-03, PNorm = 36.0845, GNorm = 4.0263, lr_0 = 1.0200e-04
Loss = 1.9811e-03, PNorm = 36.0875, GNorm = 1.3551, lr_0 = 1.0200e-04
Loss = 2.3365e-03, PNorm = 36.0899, GNorm = 4.2069, lr_0 = 1.0200e-04
Loss = 2.2991e-03, PNorm = 36.0918, GNorm = 2.9746, lr_0 = 1.0200e-04
Validation rmse logD = 0.680502
Validation R2 logD = 0.679272
Validation rmse logP = 0.578321
Validation R2 logP = 0.902931
Epoch 17
Train function
Loss = 2.3155e-03, PNorm = 36.0943, GNorm = 3.6018, lr_0 = 1.0200e-04
Loss = 2.3556e-03, PNorm = 36.0967, GNorm = 4.6139, lr_0 = 1.0200e-04
Loss = 2.2087e-03, PNorm = 36.1002, GNorm = 4.1190, lr_0 = 1.0200e-04
Loss = 2.0585e-03, PNorm = 36.1033, GNorm = 2.0300, lr_0 = 1.0200e-04
Loss = 2.4821e-03, PNorm = 36.1047, GNorm = 2.8379, lr_0 = 1.0200e-04
Loss = 2.2093e-03, PNorm = 36.1074, GNorm = 4.0891, lr_0 = 1.0200e-04
Loss = 2.0677e-03, PNorm = 36.1097, GNorm = 3.7446, lr_0 = 1.0200e-04
Loss = 2.6349e-03, PNorm = 36.1130, GNorm = 3.4857, lr_0 = 1.0200e-04
Loss = 2.4942e-03, PNorm = 36.1153, GNorm = 3.3987, lr_0 = 1.0200e-04
Loss = 1.9987e-03, PNorm = 36.1176, GNorm = 2.8992, lr_0 = 1.0200e-04
Loss = 2.2972e-03, PNorm = 36.1203, GNorm = 1.3578, lr_0 = 1.0200e-04
Loss = 1.9356e-03, PNorm = 36.1233, GNorm = 3.4210, lr_0 = 1.0200e-04
Loss = 2.1786e-03, PNorm = 36.1266, GNorm = 2.5368, lr_0 = 1.0200e-04
Loss = 1.7968e-03, PNorm = 36.1292, GNorm = 5.2929, lr_0 = 1.0200e-04
Loss = 2.1883e-03, PNorm = 36.1319, GNorm = 3.7357, lr_0 = 1.0200e-04
Loss = 2.1936e-03, PNorm = 36.1345, GNorm = 1.7705, lr_0 = 1.0200e-04
Loss = 2.5485e-03, PNorm = 36.1359, GNorm = 6.8384, lr_0 = 1.0200e-04
Loss = 2.4049e-03, PNorm = 36.1381, GNorm = 3.7358, lr_0 = 1.0200e-04
Loss = 2.3443e-03, PNorm = 36.1396, GNorm = 2.5476, lr_0 = 1.0200e-04
Loss = 2.1059e-03, PNorm = 36.1415, GNorm = 3.0407, lr_0 = 1.0200e-04
Loss = 2.4849e-03, PNorm = 36.1441, GNorm = 2.3266, lr_0 = 1.0200e-04
Loss = 2.6807e-03, PNorm = 36.1460, GNorm = 6.8556, lr_0 = 1.0200e-04
Validation rmse logD = 0.667222
Validation R2 logD = 0.691668
Validation rmse logP = 0.545398
Validation R2 logP = 0.913669
Epoch 18
Train function
Loss = 2.7791e-03, PNorm = 36.1481, GNorm = 1.8988, lr_0 = 1.0200e-04
Loss = 2.2472e-03, PNorm = 36.1506, GNorm = 2.3678, lr_0 = 1.0200e-04
Loss = 1.6492e-03, PNorm = 36.1527, GNorm = 4.1916, lr_0 = 1.0200e-04
Loss = 1.9178e-03, PNorm = 36.1557, GNorm = 1.7448, lr_0 = 1.0200e-04
Loss = 2.3473e-03, PNorm = 36.1591, GNorm = 2.5761, lr_0 = 1.0200e-04
Loss = 2.4361e-03, PNorm = 36.1619, GNorm = 5.4389, lr_0 = 1.0200e-04
Loss = 2.1108e-03, PNorm = 36.1636, GNorm = 7.3888, lr_0 = 1.0200e-04
Loss = 2.2111e-03, PNorm = 36.1660, GNorm = 0.9107, lr_0 = 1.0200e-04
Loss = 2.0053e-03, PNorm = 36.1685, GNorm = 4.5113, lr_0 = 1.0200e-04
Loss = 1.7847e-03, PNorm = 36.1710, GNorm = 2.0342, lr_0 = 1.0200e-04
Loss = 2.0061e-03, PNorm = 36.1730, GNorm = 2.9451, lr_0 = 1.0200e-04
Loss = 2.0457e-03, PNorm = 36.1754, GNorm = 4.6772, lr_0 = 1.0200e-04
Loss = 2.6576e-03, PNorm = 36.1779, GNorm = 2.4644, lr_0 = 1.0200e-04
Loss = 2.2597e-03, PNorm = 36.1796, GNorm = 1.7612, lr_0 = 1.0200e-04
Loss = 1.7300e-03, PNorm = 36.1819, GNorm = 6.9453, lr_0 = 1.0200e-04
Loss = 2.0651e-03, PNorm = 36.1837, GNorm = 6.7471, lr_0 = 1.0200e-04
Loss = 2.3295e-03, PNorm = 36.1862, GNorm = 1.7250, lr_0 = 1.0200e-04
Loss = 2.4306e-03, PNorm = 36.1885, GNorm = 5.2628, lr_0 = 1.0200e-04
Loss = 1.9575e-03, PNorm = 36.1902, GNorm = 3.9540, lr_0 = 1.0200e-04
Loss = 1.8536e-03, PNorm = 36.1924, GNorm = 5.8662, lr_0 = 1.0200e-04
Loss = 2.5856e-03, PNorm = 36.1949, GNorm = 2.2617, lr_0 = 1.0200e-04
Loss = 2.2125e-03, PNorm = 36.1971, GNorm = 1.6059, lr_0 = 1.0200e-04
Loss = 2.1084e-03, PNorm = 36.1998, GNorm = 2.2979, lr_0 = 1.0200e-04
Validation rmse logD = 0.674926
Validation R2 logD = 0.684507
Validation rmse logP = 0.556816
Validation R2 logP = 0.910016
Epoch 19
Train function
Loss = 2.2984e-03, PNorm = 36.2026, GNorm = 2.4960, lr_0 = 1.0200e-04
Loss = 2.0175e-03, PNorm = 36.2053, GNorm = 7.7567, lr_0 = 1.0200e-04
Loss = 2.2750e-03, PNorm = 36.2084, GNorm = 3.4637, lr_0 = 1.0200e-04
Loss = 1.7659e-03, PNorm = 36.2106, GNorm = 4.3452, lr_0 = 1.0200e-04
Loss = 1.9961e-03, PNorm = 36.2129, GNorm = 2.4623, lr_0 = 1.0200e-04
Loss = 2.3860e-03, PNorm = 36.2142, GNorm = 4.6770, lr_0 = 1.0200e-04
Loss = 2.2907e-03, PNorm = 36.2160, GNorm = 2.8227, lr_0 = 1.0200e-04
Loss = 2.2389e-03, PNorm = 36.2190, GNorm = 4.6194, lr_0 = 1.0200e-04
Loss = 2.0759e-03, PNorm = 36.2217, GNorm = 2.7374, lr_0 = 1.0200e-04
Loss = 1.9199e-03, PNorm = 36.2244, GNorm = 1.7799, lr_0 = 1.0200e-04
Loss = 1.9783e-03, PNorm = 36.2267, GNorm = 3.0181, lr_0 = 1.0200e-04
Loss = 2.4262e-03, PNorm = 36.2293, GNorm = 1.3281, lr_0 = 1.0200e-04
Loss = 2.4738e-03, PNorm = 36.2315, GNorm = 7.1386, lr_0 = 1.0200e-04
Loss = 1.7707e-03, PNorm = 36.2342, GNorm = 1.7970, lr_0 = 1.0200e-04
Loss = 2.3108e-03, PNorm = 36.2366, GNorm = 2.3332, lr_0 = 1.0200e-04
Loss = 2.1935e-03, PNorm = 36.2388, GNorm = 4.2102, lr_0 = 1.0200e-04
Loss = 1.8325e-03, PNorm = 36.2412, GNorm = 2.3176, lr_0 = 1.0200e-04
Loss = 2.1220e-03, PNorm = 36.2433, GNorm = 6.0134, lr_0 = 1.0200e-04
Loss = 2.0165e-03, PNorm = 36.2463, GNorm = 1.8939, lr_0 = 1.0200e-04
Loss = 2.2318e-03, PNorm = 36.2488, GNorm = 3.1404, lr_0 = 1.0200e-04
Loss = 2.2135e-03, PNorm = 36.2517, GNorm = 1.8570, lr_0 = 1.0200e-04
Loss = 2.1380e-03, PNorm = 36.2537, GNorm = 3.8632, lr_0 = 1.0200e-04
Validation rmse logD = 0.656164
Validation R2 logD = 0.701803
Validation rmse logP = 0.531836
Validation R2 logP = 0.917909
Epoch 20
Train function
Loss = 4.3252e-03, PNorm = 36.2554, GNorm = 5.3352, lr_0 = 1.0200e-04
Loss = 1.8807e-03, PNorm = 36.2579, GNorm = 3.2313, lr_0 = 1.0200e-04
Loss = 1.9449e-03, PNorm = 36.2602, GNorm = 2.4763, lr_0 = 1.0200e-04
Loss = 2.1642e-03, PNorm = 36.2623, GNorm = 2.3841, lr_0 = 1.0200e-04
Loss = 1.6127e-03, PNorm = 36.2636, GNorm = 1.6036, lr_0 = 1.0200e-04
Loss = 2.0893e-03, PNorm = 36.2655, GNorm = 1.7824, lr_0 = 1.0200e-04
Loss = 2.2597e-03, PNorm = 36.2680, GNorm = 3.5623, lr_0 = 1.0200e-04
Loss = 2.0074e-03, PNorm = 36.2708, GNorm = 1.6338, lr_0 = 1.0200e-04
Loss = 1.9805e-03, PNorm = 36.2730, GNorm = 3.1271, lr_0 = 1.0200e-04
Loss = 1.6847e-03, PNorm = 36.2756, GNorm = 1.0557, lr_0 = 1.0200e-04
Loss = 2.0631e-03, PNorm = 36.2786, GNorm = 1.4551, lr_0 = 1.0200e-04
Loss = 1.8623e-03, PNorm = 36.2812, GNorm = 2.5684, lr_0 = 1.0200e-04
Loss = 2.2629e-03, PNorm = 36.2842, GNorm = 2.6033, lr_0 = 1.0200e-04
Loss = 1.6748e-03, PNorm = 36.2865, GNorm = 2.2942, lr_0 = 1.0200e-04
Loss = 2.0679e-03, PNorm = 36.2888, GNorm = 4.4878, lr_0 = 1.0200e-04
Loss = 1.8571e-03, PNorm = 36.2905, GNorm = 2.2564, lr_0 = 1.0200e-04
Loss = 1.9231e-03, PNorm = 36.2926, GNorm = 3.9176, lr_0 = 1.0200e-04
Loss = 2.3292e-03, PNorm = 36.2939, GNorm = 1.5528, lr_0 = 1.0200e-04
Loss = 2.2418e-03, PNorm = 36.2967, GNorm = 4.0495, lr_0 = 1.0200e-04
Loss = 2.4564e-03, PNorm = 36.3001, GNorm = 2.0124, lr_0 = 1.0200e-04
Loss = 1.6987e-03, PNorm = 36.3024, GNorm = 2.1346, lr_0 = 1.0200e-04
Loss = 1.9987e-03, PNorm = 36.3043, GNorm = 3.3216, lr_0 = 1.0200e-04
Loss = 2.7670e-03, PNorm = 36.3067, GNorm = 4.0404, lr_0 = 1.0200e-04
Validation rmse logD = 0.670317
Validation R2 logD = 0.688801
Validation rmse logP = 0.544741
Validation R2 logP = 0.913877
Epoch 21
Train function
Loss = 1.9535e-03, PNorm = 36.3086, GNorm = 5.4549, lr_0 = 1.0200e-04
Loss = 2.1007e-03, PNorm = 36.3108, GNorm = 5.2891, lr_0 = 1.0200e-04
Loss = 1.7954e-03, PNorm = 36.3131, GNorm = 6.3690, lr_0 = 1.0200e-04
Loss = 1.8141e-03, PNorm = 36.3157, GNorm = 2.0790, lr_0 = 1.0200e-04
Loss = 1.6694e-03, PNorm = 36.3180, GNorm = 1.7196, lr_0 = 1.0200e-04
Loss = 1.7387e-03, PNorm = 36.3201, GNorm = 0.9390, lr_0 = 1.0200e-04
Loss = 1.7790e-03, PNorm = 36.3223, GNorm = 3.9151, lr_0 = 1.0200e-04
Loss = 2.0746e-03, PNorm = 36.3242, GNorm = 4.3877, lr_0 = 1.0200e-04
Loss = 1.6759e-03, PNorm = 36.3265, GNorm = 2.6905, lr_0 = 1.0200e-04
Loss = 1.8912e-03, PNorm = 36.3283, GNorm = 2.4137, lr_0 = 1.0200e-04
Loss = 2.0149e-03, PNorm = 36.3310, GNorm = 5.2218, lr_0 = 1.0200e-04
Loss = 2.1025e-03, PNorm = 36.3340, GNorm = 1.3716, lr_0 = 1.0200e-04
Loss = 2.0794e-03, PNorm = 36.3361, GNorm = 7.3385, lr_0 = 1.0200e-04
Loss = 1.6811e-03, PNorm = 36.3380, GNorm = 2.4996, lr_0 = 1.0200e-04
Loss = 1.6158e-03, PNorm = 36.3402, GNorm = 2.5284, lr_0 = 1.0200e-04
Loss = 1.8662e-03, PNorm = 36.3430, GNorm = 1.6089, lr_0 = 1.0200e-04
Loss = 1.8005e-03, PNorm = 36.3459, GNorm = 3.4461, lr_0 = 1.0200e-04
Loss = 2.0986e-03, PNorm = 36.3477, GNorm = 6.6518, lr_0 = 1.0200e-04
Loss = 2.5241e-03, PNorm = 36.3488, GNorm = 5.1754, lr_0 = 1.0200e-04
Loss = 2.2951e-03, PNorm = 36.3513, GNorm = 3.5469, lr_0 = 1.0200e-04
Loss = 2.4684e-03, PNorm = 36.3533, GNorm = 4.6401, lr_0 = 1.0200e-04
Loss = 2.3330e-03, PNorm = 36.3561, GNorm = 2.6451, lr_0 = 1.0200e-04
Loss = 1.9923e-03, PNorm = 36.3593, GNorm = 2.9148, lr_0 = 1.0200e-04
Loss = 2.3881e-03, PNorm = 36.3595, GNorm = 2.0934, lr_0 = 1.0200e-04
Validation rmse logD = 0.679643
Validation R2 logD = 0.680081
Validation rmse logP = 0.530674
Validation R2 logP = 0.918267
Epoch 22
Train function
Loss = 1.8812e-03, PNorm = 36.3619, GNorm = 3.3897, lr_0 = 1.0200e-04
Loss = 1.9286e-03, PNorm = 36.3650, GNorm = 3.6174, lr_0 = 1.0200e-04
Loss = 1.9271e-03, PNorm = 36.3669, GNorm = 2.0628, lr_0 = 1.0200e-04
Loss = 1.8645e-03, PNorm = 36.3699, GNorm = 1.8223, lr_0 = 1.0200e-04
Loss = 1.8609e-03, PNorm = 36.3719, GNorm = 1.6944, lr_0 = 1.0200e-04
Loss = 2.2668e-03, PNorm = 36.3745, GNorm = 3.3661, lr_0 = 1.0200e-04
Loss = 1.5127e-03, PNorm = 36.3768, GNorm = 1.3898, lr_0 = 1.0200e-04
Loss = 1.7660e-03, PNorm = 36.3798, GNorm = 1.5567, lr_0 = 1.0200e-04
Loss = 1.6572e-03, PNorm = 36.3818, GNorm = 3.0277, lr_0 = 1.0200e-04
Loss = 2.1958e-03, PNorm = 36.3848, GNorm = 2.4063, lr_0 = 1.0200e-04
Loss = 1.6202e-03, PNorm = 36.3865, GNorm = 2.4629, lr_0 = 1.0200e-04
Loss = 1.9370e-03, PNorm = 36.3888, GNorm = 3.2107, lr_0 = 1.0200e-04
Loss = 1.7178e-03, PNorm = 36.3907, GNorm = 2.0362, lr_0 = 1.0200e-04
Loss = 1.9501e-03, PNorm = 36.3928, GNorm = 5.8684, lr_0 = 1.0200e-04
Loss = 1.7201e-03, PNorm = 36.3958, GNorm = 1.8878, lr_0 = 1.0200e-04
Loss = 1.8667e-03, PNorm = 36.3975, GNorm = 3.1107, lr_0 = 1.0200e-04
Loss = 1.7219e-03, PNorm = 36.4005, GNorm = 1.6535, lr_0 = 1.0200e-04
Loss = 2.0040e-03, PNorm = 36.4031, GNorm = 4.6542, lr_0 = 1.0200e-04
Loss = 1.7543e-03, PNorm = 36.4047, GNorm = 1.7168, lr_0 = 1.0200e-04
Loss = 1.5751e-03, PNorm = 36.4071, GNorm = 3.7127, lr_0 = 1.0200e-04
Loss = 1.8465e-03, PNorm = 36.4086, GNorm = 2.5465, lr_0 = 1.0200e-04
Loss = 1.9165e-03, PNorm = 36.4107, GNorm = 4.3669, lr_0 = 1.0200e-04
Validation rmse logD = 0.647401
Validation R2 logD = 0.709715
Validation rmse logP = 0.533577
Validation R2 logP = 0.917371
Epoch 23
Train function
Loss = 1.4186e-03, PNorm = 36.4127, GNorm = 3.0324, lr_0 = 1.0200e-04
Loss = 2.0196e-03, PNorm = 36.4155, GNorm = 7.1533, lr_0 = 1.0200e-04
Loss = 1.8860e-03, PNorm = 36.4182, GNorm = 2.4587, lr_0 = 1.0200e-04
Loss = 1.6029e-03, PNorm = 36.4203, GNorm = 0.9756, lr_0 = 1.0200e-04
Loss = 1.5291e-03, PNorm = 36.4223, GNorm = 1.9680, lr_0 = 1.0200e-04
Loss = 1.6478e-03, PNorm = 36.4238, GNorm = 5.4777, lr_0 = 1.0200e-04
Loss = 1.7553e-03, PNorm = 36.4262, GNorm = 6.6072, lr_0 = 1.0200e-04
Loss = 2.0543e-03, PNorm = 36.4277, GNorm = 7.2630, lr_0 = 1.0200e-04
Loss = 1.3762e-03, PNorm = 36.4301, GNorm = 1.8676, lr_0 = 1.0200e-04
Loss = 2.0577e-03, PNorm = 36.4324, GNorm = 1.2112, lr_0 = 1.0200e-04
Loss = 2.2127e-03, PNorm = 36.4351, GNorm = 5.4370, lr_0 = 1.0200e-04
Loss = 1.6938e-03, PNorm = 36.4372, GNorm = 3.5168, lr_0 = 1.0200e-04
Loss = 1.9925e-03, PNorm = 36.4397, GNorm = 1.9427, lr_0 = 1.0200e-04
Loss = 2.1453e-03, PNorm = 36.4414, GNorm = 2.1314, lr_0 = 1.0200e-04
Loss = 2.0596e-03, PNorm = 36.4447, GNorm = 2.1397, lr_0 = 1.0200e-04
Loss = 1.8757e-03, PNorm = 36.4461, GNorm = 1.6486, lr_0 = 1.0200e-04
Loss = 1.7991e-03, PNorm = 36.4484, GNorm = 2.6461, lr_0 = 1.0200e-04
Loss = 2.0252e-03, PNorm = 36.4514, GNorm = 5.8714, lr_0 = 1.0200e-04
Loss = 1.8598e-03, PNorm = 36.4543, GNorm = 2.8520, lr_0 = 1.0200e-04
Loss = 1.5856e-03, PNorm = 36.4564, GNorm = 1.8887, lr_0 = 1.0200e-04
Loss = 1.8884e-03, PNorm = 36.4596, GNorm = 2.9042, lr_0 = 1.0200e-04
Loss = 1.6738e-03, PNorm = 36.4615, GNorm = 5.6544, lr_0 = 1.0200e-04
Loss = 1.8592e-03, PNorm = 36.4633, GNorm = 1.8455, lr_0 = 1.0200e-04
Validation rmse logD = 0.673852
Validation R2 logD = 0.685510
Validation rmse logP = 0.521630
Validation R2 logP = 0.921029
Epoch 24
Train function
Loss = 1.2108e-03, PNorm = 36.4651, GNorm = 1.7017, lr_0 = 1.0200e-04
Loss = 1.6767e-03, PNorm = 36.4670, GNorm = 3.6082, lr_0 = 1.0200e-04
Loss = 2.0647e-03, PNorm = 36.4692, GNorm = 3.1822, lr_0 = 1.0200e-04
Loss = 1.3453e-03, PNorm = 36.4713, GNorm = 3.0715, lr_0 = 1.0200e-04
Loss = 1.9087e-03, PNorm = 36.4724, GNorm = 2.6446, lr_0 = 1.0200e-04
Loss = 2.0001e-03, PNorm = 36.4749, GNorm = 3.8039, lr_0 = 1.0200e-04
Loss = 1.5132e-03, PNorm = 36.4777, GNorm = 3.4315, lr_0 = 1.0200e-04
Loss = 1.9854e-03, PNorm = 36.4797, GNorm = 5.2789, lr_0 = 1.0200e-04
Loss = 1.6693e-03, PNorm = 36.4815, GNorm = 1.7531, lr_0 = 1.0200e-04
Loss = 1.6933e-03, PNorm = 36.4833, GNorm = 3.6811, lr_0 = 1.0200e-04
Loss = 1.9648e-03, PNorm = 36.4852, GNorm = 1.9145, lr_0 = 1.0200e-04
Loss = 2.1294e-03, PNorm = 36.4888, GNorm = 1.7178, lr_0 = 1.0200e-04
Loss = 1.9093e-03, PNorm = 36.4921, GNorm = 2.5647, lr_0 = 1.0200e-04
Loss = 2.0912e-03, PNorm = 36.4945, GNorm = 1.8772, lr_0 = 1.0200e-04
Loss = 1.7897e-03, PNorm = 36.4970, GNorm = 1.5263, lr_0 = 1.0200e-04
Loss = 1.6575e-03, PNorm = 36.4996, GNorm = 3.7295, lr_0 = 1.0200e-04
Loss = 1.9152e-03, PNorm = 36.5024, GNorm = 4.3036, lr_0 = 1.0200e-04
Loss = 1.5626e-03, PNorm = 36.5049, GNorm = 2.1388, lr_0 = 1.0200e-04
Loss = 1.5215e-03, PNorm = 36.5065, GNorm = 2.2855, lr_0 = 1.0200e-04
Loss = 1.7353e-03, PNorm = 36.5087, GNorm = 1.7349, lr_0 = 1.0200e-04
Loss = 1.7445e-03, PNorm = 36.5108, GNorm = 2.3997, lr_0 = 1.0200e-04
Loss = 1.5627e-03, PNorm = 36.5126, GNorm = 3.5931, lr_0 = 1.0200e-04
Validation rmse logD = 0.683050
Validation R2 logD = 0.676866
Validation rmse logP = 0.527997
Validation R2 logP = 0.919090
Epoch 25
Train function
Loss = 1.7888e-03, PNorm = 36.5136, GNorm = 3.7206, lr_0 = 1.0200e-04
Loss = 1.7056e-03, PNorm = 36.5160, GNorm = 1.7435, lr_0 = 1.0200e-04
Loss = 1.5068e-03, PNorm = 36.5183, GNorm = 5.5347, lr_0 = 1.0200e-04
Loss = 1.8348e-03, PNorm = 36.5213, GNorm = 1.8917, lr_0 = 1.0200e-04
Loss = 1.2223e-03, PNorm = 36.5237, GNorm = 1.6479, lr_0 = 1.0200e-04
Loss = 1.6202e-03, PNorm = 36.5253, GNorm = 2.6222, lr_0 = 1.0200e-04
Loss = 1.6449e-03, PNorm = 36.5277, GNorm = 1.5081, lr_0 = 1.0200e-04
Loss = 1.9389e-03, PNorm = 36.5292, GNorm = 1.6742, lr_0 = 1.0200e-04
Loss = 1.5880e-03, PNorm = 36.5307, GNorm = 3.3006, lr_0 = 1.0200e-04
Loss = 1.7937e-03, PNorm = 36.5328, GNorm = 2.2436, lr_0 = 1.0200e-04
Loss = 1.5462e-03, PNorm = 36.5351, GNorm = 0.8881, lr_0 = 1.0200e-04
Loss = 1.7367e-03, PNorm = 36.5365, GNorm = 1.5333, lr_0 = 1.0200e-04
Loss = 1.3425e-03, PNorm = 36.5390, GNorm = 3.3581, lr_0 = 1.0200e-04
Loss = 2.0865e-03, PNorm = 36.5417, GNorm = 1.9513, lr_0 = 1.0200e-04
Loss = 1.9134e-03, PNorm = 36.5437, GNorm = 5.8450, lr_0 = 1.0200e-04
Loss = 1.5623e-03, PNorm = 36.5457, GNorm = 1.3847, lr_0 = 1.0200e-04
Loss = 1.4893e-03, PNorm = 36.5474, GNorm = 2.2992, lr_0 = 1.0200e-04
Loss = 1.6596e-03, PNorm = 36.5492, GNorm = 2.9522, lr_0 = 1.0200e-04
Loss = 1.8709e-03, PNorm = 36.5525, GNorm = 1.9800, lr_0 = 1.0200e-04
Loss = 1.9185e-03, PNorm = 36.5553, GNorm = 4.9321, lr_0 = 1.0200e-04
Loss = 2.1302e-03, PNorm = 36.5578, GNorm = 6.0597, lr_0 = 1.0200e-04
Loss = 1.7236e-03, PNorm = 36.5596, GNorm = 1.7450, lr_0 = 1.0200e-04
Loss = 1.7388e-03, PNorm = 36.5615, GNorm = 1.3157, lr_0 = 1.0200e-04
Validation rmse logD = 0.635075
Validation R2 logD = 0.720664
Validation rmse logP = 0.513409
Validation R2 logP = 0.923499
Epoch 26
Train function
Loss = 1.4166e-03, PNorm = 36.5641, GNorm = 2.3394, lr_0 = 1.0200e-04
Loss = 1.7297e-03, PNorm = 36.5661, GNorm = 2.5184, lr_0 = 1.0200e-04
Loss = 1.5186e-03, PNorm = 36.5674, GNorm = 1.4541, lr_0 = 1.0200e-04
Loss = 1.5891e-03, PNorm = 36.5702, GNorm = 4.4804, lr_0 = 1.0200e-04
Loss = 1.6330e-03, PNorm = 36.5726, GNorm = 2.5355, lr_0 = 1.0200e-04
Loss = 1.5831e-03, PNorm = 36.5751, GNorm = 2.7819, lr_0 = 1.0200e-04
Loss = 2.0372e-03, PNorm = 36.5774, GNorm = 3.0673, lr_0 = 1.0200e-04
Loss = 1.6066e-03, PNorm = 36.5794, GNorm = 4.7479, lr_0 = 1.0200e-04
Loss = 1.6442e-03, PNorm = 36.5818, GNorm = 3.4187, lr_0 = 1.0200e-04
Loss = 1.8722e-03, PNorm = 36.5840, GNorm = 3.0385, lr_0 = 1.0200e-04
Loss = 1.7225e-03, PNorm = 36.5855, GNorm = 5.5565, lr_0 = 1.0200e-04
Loss = 1.6715e-03, PNorm = 36.5877, GNorm = 5.0105, lr_0 = 1.0200e-04
Loss = 1.6400e-03, PNorm = 36.5902, GNorm = 1.3832, lr_0 = 1.0200e-04
Loss = 1.7250e-03, PNorm = 36.5922, GNorm = 2.7872, lr_0 = 1.0200e-04
Loss = 1.6614e-03, PNorm = 36.5939, GNorm = 1.9777, lr_0 = 1.0200e-04
Loss = 2.0359e-03, PNorm = 36.5973, GNorm = 3.3511, lr_0 = 1.0200e-04
Loss = 1.7280e-03, PNorm = 36.5996, GNorm = 1.7360, lr_0 = 1.0200e-04
Loss = 1.7952e-03, PNorm = 36.6015, GNorm = 6.8416, lr_0 = 1.0200e-04
Loss = 2.0431e-03, PNorm = 36.6039, GNorm = 4.6308, lr_0 = 1.0200e-04
Loss = 1.5743e-03, PNorm = 36.6056, GNorm = 7.9050, lr_0 = 1.0200e-04
Loss = 1.7821e-03, PNorm = 36.6072, GNorm = 4.0978, lr_0 = 1.0200e-04
Loss = 1.6818e-03, PNorm = 36.6096, GNorm = 5.0759, lr_0 = 1.0200e-04
Validation rmse logD = 0.624889
Validation R2 logD = 0.729552
Validation rmse logP = 0.504135
Validation R2 logP = 0.926238
Epoch 27
Train function
Loss = 1.4535e-03, PNorm = 36.6126, GNorm = 1.2026, lr_0 = 1.0200e-04
Loss = 1.2267e-03, PNorm = 36.6146, GNorm = 1.7011, lr_0 = 1.0200e-04
Loss = 1.2376e-03, PNorm = 36.6164, GNorm = 3.8442, lr_0 = 1.0200e-04
Loss = 1.6213e-03, PNorm = 36.6175, GNorm = 2.5838, lr_0 = 1.0200e-04
Loss = 1.8638e-03, PNorm = 36.6203, GNorm = 3.0669, lr_0 = 1.0200e-04
Loss = 1.5394e-03, PNorm = 36.6237, GNorm = 2.7660, lr_0 = 1.0200e-04
Loss = 1.4002e-03, PNorm = 36.6260, GNorm = 2.9827, lr_0 = 1.0200e-04
Loss = 1.8735e-03, PNorm = 36.6282, GNorm = 2.2565, lr_0 = 1.0200e-04
Loss = 1.9234e-03, PNorm = 36.6301, GNorm = 2.6154, lr_0 = 1.0200e-04
Loss = 1.6120e-03, PNorm = 36.6328, GNorm = 1.4806, lr_0 = 1.0200e-04
Loss = 1.7892e-03, PNorm = 36.6351, GNorm = 5.7084, lr_0 = 1.0200e-04
Loss = 1.9053e-03, PNorm = 36.6376, GNorm = 1.9111, lr_0 = 1.0200e-04
Loss = 1.4456e-03, PNorm = 36.6397, GNorm = 2.6527, lr_0 = 1.0200e-04
Loss = 1.9811e-03, PNorm = 36.6424, GNorm = 9.0767, lr_0 = 1.0200e-04
Loss = 1.5636e-03, PNorm = 36.6453, GNorm = 2.6537, lr_0 = 1.0200e-04
Loss = 1.5119e-03, PNorm = 36.6478, GNorm = 1.8767, lr_0 = 1.0200e-04
Loss = 1.4460e-03, PNorm = 36.6487, GNorm = 1.4627, lr_0 = 1.0200e-04
Loss = 1.4385e-03, PNorm = 36.6508, GNorm = 1.1530, lr_0 = 1.0200e-04
Loss = 1.5816e-03, PNorm = 36.6529, GNorm = 1.6688, lr_0 = 1.0200e-04
Loss = 1.3588e-03, PNorm = 36.6547, GNorm = 2.3831, lr_0 = 1.0200e-04
Loss = 1.4968e-03, PNorm = 36.6560, GNorm = 4.4079, lr_0 = 1.0200e-04
Loss = 1.6871e-03, PNorm = 36.6575, GNorm = 4.1219, lr_0 = 1.0200e-04
Loss = 1.8191e-03, PNorm = 36.6587, GNorm = 3.0831, lr_0 = 1.0200e-04
Validation rmse logD = 0.629512
Validation R2 logD = 0.725536
Validation rmse logP = 0.508823
Validation R2 logP = 0.924859
Epoch 28
Train function
Loss = 1.5780e-03, PNorm = 36.6609, GNorm = 2.4047, lr_0 = 1.0200e-04
Loss = 1.5894e-03, PNorm = 36.6642, GNorm = 1.8308, lr_0 = 1.0200e-04
Loss = 1.5076e-03, PNorm = 36.6659, GNorm = 2.9735, lr_0 = 1.0200e-04
Loss = 1.4264e-03, PNorm = 36.6676, GNorm = 1.0135, lr_0 = 1.0200e-04
Loss = 1.4316e-03, PNorm = 36.6697, GNorm = 2.5142, lr_0 = 1.0200e-04
Loss = 1.3885e-03, PNorm = 36.6721, GNorm = 3.2572, lr_0 = 1.0200e-04
Loss = 1.8628e-03, PNorm = 36.6750, GNorm = 3.3527, lr_0 = 1.0200e-04
Loss = 1.5334e-03, PNorm = 36.6771, GNorm = 5.4934, lr_0 = 1.0200e-04
Loss = 1.7556e-03, PNorm = 36.6805, GNorm = 4.2227, lr_0 = 1.0200e-04
Loss = 1.6824e-03, PNorm = 36.6826, GNorm = 2.0570, lr_0 = 1.0200e-04
Loss = 1.9052e-03, PNorm = 36.6842, GNorm = 5.5407, lr_0 = 1.0200e-04
Loss = 1.7703e-03, PNorm = 36.6867, GNorm = 1.7634, lr_0 = 1.0200e-04
Loss = 1.7168e-03, PNorm = 36.6892, GNorm = 4.5564, lr_0 = 1.0200e-04
Loss = 1.7019e-03, PNorm = 36.6913, GNorm = 1.2121, lr_0 = 1.0200e-04
Loss = 1.2899e-03, PNorm = 36.6943, GNorm = 2.8379, lr_0 = 1.0200e-04
Loss = 1.3261e-03, PNorm = 36.6964, GNorm = 1.1079, lr_0 = 1.0200e-04
Loss = 1.5254e-03, PNorm = 36.6980, GNorm = 4.7940, lr_0 = 1.0200e-04
Loss = 1.4790e-03, PNorm = 36.6998, GNorm = 1.2414, lr_0 = 1.0200e-04
Loss = 1.4719e-03, PNorm = 36.7014, GNorm = 4.9203, lr_0 = 1.0200e-04
Loss = 1.3909e-03, PNorm = 36.7032, GNorm = 2.3908, lr_0 = 1.0200e-04
Loss = 1.6461e-03, PNorm = 36.7052, GNorm = 2.1360, lr_0 = 1.0200e-04
Loss = 1.3892e-03, PNorm = 36.7074, GNorm = 2.3054, lr_0 = 1.0200e-04
Validation rmse logD = 0.620643
Validation R2 logD = 0.733215
Validation rmse logP = 0.505433
Validation R2 logP = 0.925857
Epoch 29
Train function
Loss = 1.6917e-03, PNorm = 36.7092, GNorm = 2.9651, lr_0 = 1.0200e-04
Loss = 1.2326e-03, PNorm = 36.7115, GNorm = 2.9257, lr_0 = 1.0200e-04
Loss = 1.2761e-03, PNorm = 36.7133, GNorm = 1.5098, lr_0 = 1.0200e-04
Loss = 1.3853e-03, PNorm = 36.7149, GNorm = 3.1517, lr_0 = 1.0200e-04
Loss = 1.4539e-03, PNorm = 36.7165, GNorm = 5.2107, lr_0 = 1.0200e-04
Loss = 1.1969e-03, PNorm = 36.7179, GNorm = 1.7095, lr_0 = 1.0200e-04
Loss = 1.7282e-03, PNorm = 36.7203, GNorm = 1.5447, lr_0 = 1.0200e-04
Loss = 1.7493e-03, PNorm = 36.7235, GNorm = 4.6713, lr_0 = 1.0200e-04
Loss = 1.6077e-03, PNorm = 36.7258, GNorm = 5.1342, lr_0 = 1.0200e-04
Loss = 1.3128e-03, PNorm = 36.7283, GNorm = 3.3839, lr_0 = 1.0200e-04
Loss = 1.5888e-03, PNorm = 36.7299, GNorm = 3.7667, lr_0 = 1.0200e-04
Loss = 1.8238e-03, PNorm = 36.7316, GNorm = 2.2139, lr_0 = 1.0200e-04
Loss = 2.0324e-03, PNorm = 36.7342, GNorm = 2.4288, lr_0 = 1.0200e-04
Loss = 1.6089e-03, PNorm = 36.7366, GNorm = 2.9217, lr_0 = 1.0200e-04
Loss = 1.5873e-03, PNorm = 36.7388, GNorm = 2.8963, lr_0 = 1.0200e-04
Loss = 1.3765e-03, PNorm = 36.7413, GNorm = 2.7786, lr_0 = 1.0200e-04
Loss = 1.4494e-03, PNorm = 36.7432, GNorm = 2.9896, lr_0 = 1.0200e-04
Loss = 1.6456e-03, PNorm = 36.7444, GNorm = 4.5592, lr_0 = 1.0200e-04
Loss = 1.9656e-03, PNorm = 36.7458, GNorm = 2.3033, lr_0 = 1.0200e-04
Loss = 1.5280e-03, PNorm = 36.7476, GNorm = 1.3488, lr_0 = 1.0200e-04
Loss = 1.3218e-03, PNorm = 36.7507, GNorm = 3.6037, lr_0 = 1.0200e-04
Loss = 1.5822e-03, PNorm = 36.7539, GNorm = 1.6944, lr_0 = 1.0200e-04
Loss = 1.6505e-03, PNorm = 36.7563, GNorm = 2.4723, lr_0 = 1.0200e-04
Validation rmse logD = 0.618962
Validation R2 logD = 0.734658
Validation rmse logP = 0.502828
Validation R2 logP = 0.926620
Epoch 30
Train function
Loss = 1.4143e-03, PNorm = 36.7586, GNorm = 2.1168, lr_0 = 1.0200e-04
Loss = 1.5861e-03, PNorm = 36.7613, GNorm = 3.3094, lr_0 = 1.0200e-04
Loss = 1.3599e-03, PNorm = 36.7636, GNorm = 1.5327, lr_0 = 1.0200e-04
Loss = 1.4828e-03, PNorm = 36.7662, GNorm = 5.3276, lr_0 = 1.0200e-04
Loss = 1.4714e-03, PNorm = 36.7685, GNorm = 1.7307, lr_0 = 1.0200e-04
Loss = 1.4773e-03, PNorm = 36.7699, GNorm = 2.4551, lr_0 = 1.0200e-04
Loss = 1.5580e-03, PNorm = 36.7722, GNorm = 2.2222, lr_0 = 1.0200e-04
Loss = 1.2597e-03, PNorm = 36.7738, GNorm = 3.6887, lr_0 = 1.0200e-04
Loss = 1.4822e-03, PNorm = 36.7758, GNorm = 1.6061, lr_0 = 1.0200e-04
Loss = 1.3953e-03, PNorm = 36.7777, GNorm = 1.9935, lr_0 = 1.0200e-04
Loss = 1.2072e-03, PNorm = 36.7794, GNorm = 3.3157, lr_0 = 1.0200e-04
Loss = 1.7096e-03, PNorm = 36.7812, GNorm = 1.8705, lr_0 = 1.0200e-04
Loss = 1.3854e-03, PNorm = 36.7820, GNorm = 3.7553, lr_0 = 1.0200e-04
Loss = 1.5854e-03, PNorm = 36.7847, GNorm = 2.7608, lr_0 = 1.0200e-04
Loss = 2.0245e-03, PNorm = 36.7875, GNorm = 5.1950, lr_0 = 1.0200e-04
Loss = 1.6694e-03, PNorm = 36.7897, GNorm = 1.4411, lr_0 = 1.0200e-04
Loss = 1.7524e-03, PNorm = 36.7916, GNorm = 7.3584, lr_0 = 1.0200e-04
Loss = 1.9520e-03, PNorm = 36.7933, GNorm = 3.5278, lr_0 = 1.0200e-04
Loss = 1.8638e-03, PNorm = 36.7968, GNorm = 4.2248, lr_0 = 1.0200e-04
Loss = 1.6288e-03, PNorm = 36.7989, GNorm = 5.8331, lr_0 = 1.0200e-04
Loss = 1.7005e-03, PNorm = 36.8009, GNorm = 4.1121, lr_0 = 1.0200e-04
Loss = 1.7293e-03, PNorm = 36.8038, GNorm = 3.9379, lr_0 = 1.0200e-04
Validation rmse logD = 0.640966
Validation R2 logD = 0.715457
Validation rmse logP = 0.516707
Validation R2 logP = 0.922513
Epoch 31
Train function
Loss = 1.3391e-03, PNorm = 36.8062, GNorm = 1.2829, lr_0 = 1.0200e-04
Loss = 1.2060e-03, PNorm = 36.8081, GNorm = 1.7777, lr_0 = 1.0200e-04
Loss = 1.3539e-03, PNorm = 36.8100, GNorm = 4.6754, lr_0 = 1.0200e-04
Loss = 1.5651e-03, PNorm = 36.8119, GNorm = 3.9664, lr_0 = 1.0200e-04
Loss = 1.5089e-03, PNorm = 36.8149, GNorm = 2.0797, lr_0 = 1.0200e-04
Loss = 1.8868e-03, PNorm = 36.8180, GNorm = 4.5486, lr_0 = 1.0200e-04
Loss = 1.2408e-03, PNorm = 36.8204, GNorm = 2.6230, lr_0 = 1.0200e-04
Loss = 1.2971e-03, PNorm = 36.8226, GNorm = 2.6885, lr_0 = 1.0200e-04
Loss = 1.1209e-03, PNorm = 36.8252, GNorm = 1.9234, lr_0 = 1.0200e-04
Loss = 1.2684e-03, PNorm = 36.8268, GNorm = 3.2125, lr_0 = 1.0200e-04
Loss = 1.3971e-03, PNorm = 36.8286, GNorm = 1.8165, lr_0 = 1.0200e-04
Loss = 1.4804e-03, PNorm = 36.8305, GNorm = 2.0497, lr_0 = 1.0200e-04
Loss = 1.2883e-03, PNorm = 36.8321, GNorm = 1.4078, lr_0 = 1.0200e-04
Loss = 1.6347e-03, PNorm = 36.8343, GNorm = 1.6168, lr_0 = 1.0200e-04
Loss = 1.2230e-03, PNorm = 36.8365, GNorm = 3.3567, lr_0 = 1.0200e-04
Loss = 1.4035e-03, PNorm = 36.8384, GNorm = 1.5513, lr_0 = 1.0200e-04
Loss = 1.3688e-03, PNorm = 36.8408, GNorm = 1.2517, lr_0 = 1.0200e-04
Loss = 1.3007e-03, PNorm = 36.8422, GNorm = 2.0176, lr_0 = 1.0200e-04
Loss = 1.1376e-03, PNorm = 36.8441, GNorm = 1.7690, lr_0 = 1.0200e-04
Loss = 1.4380e-03, PNorm = 36.8460, GNorm = 2.3850, lr_0 = 1.0200e-04
Loss = 1.3926e-03, PNorm = 36.8479, GNorm = 7.4398, lr_0 = 1.0200e-04
Loss = 1.5456e-03, PNorm = 36.8491, GNorm = 2.0832, lr_0 = 1.0200e-04
Loss = 1.6895e-03, PNorm = 36.8504, GNorm = 2.1999, lr_0 = 1.0200e-04
Validation rmse logD = 0.619995
Validation R2 logD = 0.733772
Validation rmse logP = 0.531888
Validation R2 logP = 0.917893
Epoch 32
Train function
Loss = 1.2273e-03, PNorm = 36.8521, GNorm = 1.8359, lr_0 = 1.0200e-04
Loss = 1.0695e-03, PNorm = 36.8529, GNorm = 1.2530, lr_0 = 1.0200e-04
Loss = 1.0377e-03, PNorm = 36.8541, GNorm = 2.2338, lr_0 = 1.0200e-04
Loss = 1.4866e-03, PNorm = 36.8568, GNorm = 3.5312, lr_0 = 1.0200e-04
Loss = 1.4973e-03, PNorm = 36.8599, GNorm = 1.6518, lr_0 = 1.0200e-04
Loss = 1.3333e-03, PNorm = 36.8624, GNorm = 2.1070, lr_0 = 1.0200e-04
Loss = 1.2890e-03, PNorm = 36.8650, GNorm = 1.4195, lr_0 = 1.0200e-04
Loss = 1.1754e-03, PNorm = 36.8661, GNorm = 1.1370, lr_0 = 1.0200e-04
Loss = 1.1552e-03, PNorm = 36.8675, GNorm = 3.8271, lr_0 = 1.0200e-04
Loss = 1.4612e-03, PNorm = 36.8690, GNorm = 2.4372, lr_0 = 1.0200e-04
Loss = 1.1498e-03, PNorm = 36.8717, GNorm = 4.3765, lr_0 = 1.0200e-04
Loss = 1.4076e-03, PNorm = 36.8735, GNorm = 4.3786, lr_0 = 1.0200e-04
Loss = 1.2778e-03, PNorm = 36.8752, GNorm = 3.3084, lr_0 = 1.0200e-04
Loss = 1.4744e-03, PNorm = 36.8775, GNorm = 3.9044, lr_0 = 1.0200e-04
Loss = 1.4928e-03, PNorm = 36.8800, GNorm = 3.3067, lr_0 = 1.0200e-04
Loss = 1.4271e-03, PNorm = 36.8826, GNorm = 0.9304, lr_0 = 1.0200e-04
Loss = 1.8776e-03, PNorm = 36.8852, GNorm = 3.8562, lr_0 = 1.0200e-04
Loss = 1.5993e-03, PNorm = 36.8877, GNorm = 1.6874, lr_0 = 1.0200e-04
Loss = 1.2260e-03, PNorm = 36.8902, GNorm = 2.2382, lr_0 = 1.0200e-04
Loss = 1.2519e-03, PNorm = 36.8920, GNorm = 3.2427, lr_0 = 1.0200e-04
Loss = 1.3208e-03, PNorm = 36.8934, GNorm = 2.0868, lr_0 = 1.0200e-04
Loss = 1.2900e-03, PNorm = 36.8957, GNorm = 2.1795, lr_0 = 1.0200e-04
Loss = 1.3377e-03, PNorm = 36.8973, GNorm = 2.2485, lr_0 = 1.0200e-04
Loss = 3.6094e-03, PNorm = 36.8975, GNorm = 5.7771, lr_0 = 1.0200e-04
Validation rmse logD = 0.618416
Validation R2 logD = 0.735126
Validation rmse logP = 0.521990
Validation R2 logP = 0.920920
Epoch 33
Train function
Loss = 1.5560e-03, PNorm = 36.8990, GNorm = 5.0283, lr_0 = 1.0200e-04
Loss = 1.2835e-03, PNorm = 36.9009, GNorm = 2.4450, lr_0 = 1.0200e-04
Loss = 1.2923e-03, PNorm = 36.9031, GNorm = 1.6080, lr_0 = 1.0200e-04
Loss = 1.3371e-03, PNorm = 36.9064, GNorm = 1.0168, lr_0 = 1.0200e-04
Loss = 1.4692e-03, PNorm = 36.9091, GNorm = 4.3441, lr_0 = 1.0200e-04
Loss = 1.0952e-03, PNorm = 36.9096, GNorm = 1.7059, lr_0 = 1.0200e-04
Loss = 1.1511e-03, PNorm = 36.9108, GNorm = 1.3953, lr_0 = 1.0200e-04
Loss = 1.5254e-03, PNorm = 36.9138, GNorm = 2.2379, lr_0 = 1.0200e-04
Loss = 1.0703e-03, PNorm = 36.9159, GNorm = 1.9843, lr_0 = 1.0200e-04
Loss = 1.5784e-03, PNorm = 36.9185, GNorm = 2.1830, lr_0 = 1.0200e-04
Loss = 1.3543e-03, PNorm = 36.9200, GNorm = 1.5554, lr_0 = 1.0200e-04
Loss = 1.4951e-03, PNorm = 36.9222, GNorm = 1.3408, lr_0 = 1.0200e-04
Loss = 1.3649e-03, PNorm = 36.9244, GNorm = 2.8900, lr_0 = 1.0200e-04
Loss = 1.1642e-03, PNorm = 36.9260, GNorm = 3.4304, lr_0 = 1.0200e-04
Loss = 1.4006e-03, PNorm = 36.9277, GNorm = 4.5233, lr_0 = 1.0200e-04
Loss = 1.3145e-03, PNorm = 36.9284, GNorm = 3.2851, lr_0 = 1.0200e-04
Loss = 1.1544e-03, PNorm = 36.9306, GNorm = 4.6682, lr_0 = 1.0200e-04
Loss = 1.5740e-03, PNorm = 36.9325, GNorm = 3.2988, lr_0 = 1.0200e-04
Loss = 1.2779e-03, PNorm = 36.9344, GNorm = 1.7465, lr_0 = 1.0200e-04
Loss = 1.3504e-03, PNorm = 36.9366, GNorm = 1.5992, lr_0 = 1.0200e-04
Loss = 1.2369e-03, PNorm = 36.9381, GNorm = 3.1447, lr_0 = 1.0200e-04
Loss = 1.2239e-03, PNorm = 36.9400, GNorm = 1.3184, lr_0 = 1.0200e-04
Validation rmse logD = 0.657503
Validation R2 logD = 0.700585
Validation rmse logP = 0.505241
Validation R2 logP = 0.925914
Epoch 34
Train function
Loss = 1.3350e-03, PNorm = 36.9419, GNorm = 3.8476, lr_0 = 1.0200e-04
Loss = 1.8605e-03, PNorm = 36.9441, GNorm = 4.8157, lr_0 = 1.0200e-04
Loss = 1.5579e-03, PNorm = 36.9465, GNorm = 2.8206, lr_0 = 1.0200e-04
Loss = 1.2841e-03, PNorm = 36.9477, GNorm = 2.0017, lr_0 = 1.0200e-04
Loss = 1.2317e-03, PNorm = 36.9491, GNorm = 1.6780, lr_0 = 1.0200e-04
Loss = 1.3916e-03, PNorm = 36.9516, GNorm = 1.5831, lr_0 = 1.0200e-04
Loss = 1.3626e-03, PNorm = 36.9531, GNorm = 5.4467, lr_0 = 1.0200e-04
Loss = 1.3930e-03, PNorm = 36.9554, GNorm = 1.9880, lr_0 = 1.0200e-04
Loss = 1.4289e-03, PNorm = 36.9580, GNorm = 2.2978, lr_0 = 1.0200e-04
Loss = 1.1921e-03, PNorm = 36.9604, GNorm = 1.9053, lr_0 = 1.0200e-04
Loss = 1.2544e-03, PNorm = 36.9627, GNorm = 1.1150, lr_0 = 1.0200e-04
Loss = 1.1883e-03, PNorm = 36.9653, GNorm = 1.5922, lr_0 = 1.0200e-04
Loss = 1.1991e-03, PNorm = 36.9679, GNorm = 3.4625, lr_0 = 1.0200e-04
Loss = 1.3452e-03, PNorm = 36.9700, GNorm = 2.1173, lr_0 = 1.0200e-04
Loss = 1.0970e-03, PNorm = 36.9724, GNorm = 1.6773, lr_0 = 1.0200e-04
Loss = 1.2327e-03, PNorm = 36.9733, GNorm = 2.8995, lr_0 = 1.0200e-04
Loss = 1.2250e-03, PNorm = 36.9743, GNorm = 0.8356, lr_0 = 1.0200e-04
Loss = 1.1661e-03, PNorm = 36.9767, GNorm = 1.3799, lr_0 = 1.0200e-04
Loss = 1.3811e-03, PNorm = 36.9787, GNorm = 5.2799, lr_0 = 1.0200e-04
Loss = 1.4621e-03, PNorm = 36.9804, GNorm = 3.3570, lr_0 = 1.0200e-04
Loss = 1.3391e-03, PNorm = 36.9821, GNorm = 1.0382, lr_0 = 1.0200e-04
Loss = 1.2659e-03, PNorm = 36.9836, GNorm = 1.5051, lr_0 = 1.0200e-04
Loss = 1.1474e-03, PNorm = 36.9858, GNorm = 3.0126, lr_0 = 1.0200e-04
Validation rmse logD = 0.612155
Validation R2 logD = 0.740462
Validation rmse logP = 0.533459
Validation R2 logP = 0.917407
Epoch 35
Train function
Loss = 1.1991e-03, PNorm = 36.9878, GNorm = 5.3648, lr_0 = 1.0200e-04
Loss = 1.3254e-03, PNorm = 36.9900, GNorm = 4.1457, lr_0 = 1.0200e-04
Loss = 1.5226e-03, PNorm = 36.9910, GNorm = 1.4458, lr_0 = 1.0200e-04
Loss = 1.4601e-03, PNorm = 36.9934, GNorm = 1.2070, lr_0 = 1.0200e-04
Loss = 1.3604e-03, PNorm = 36.9959, GNorm = 1.6058, lr_0 = 1.0200e-04
Loss = 1.3458e-03, PNorm = 36.9985, GNorm = 1.2419, lr_0 = 1.0200e-04
Loss = 1.0949e-03, PNorm = 37.0003, GNorm = 0.8065, lr_0 = 1.0200e-04
Loss = 1.1672e-03, PNorm = 37.0019, GNorm = 1.5043, lr_0 = 1.0200e-04
Loss = 1.0499e-03, PNorm = 37.0035, GNorm = 2.8542, lr_0 = 1.0200e-04
Loss = 1.4147e-03, PNorm = 37.0055, GNorm = 2.5834, lr_0 = 1.0200e-04
Loss = 1.1186e-03, PNorm = 37.0073, GNorm = 4.6423, lr_0 = 1.0200e-04
Loss = 1.2945e-03, PNorm = 37.0092, GNorm = 4.5814, lr_0 = 1.0200e-04
Loss = 1.4317e-03, PNorm = 37.0109, GNorm = 1.3286, lr_0 = 1.0200e-04
Loss = 1.2480e-03, PNorm = 37.0125, GNorm = 2.8822, lr_0 = 1.0200e-04
Loss = 1.0980e-03, PNorm = 37.0144, GNorm = 1.3458, lr_0 = 1.0200e-04
Loss = 1.3243e-03, PNorm = 37.0164, GNorm = 1.6792, lr_0 = 1.0200e-04
Loss = 1.2501e-03, PNorm = 37.0179, GNorm = 0.9601, lr_0 = 1.0200e-04
Loss = 1.3185e-03, PNorm = 37.0195, GNorm = 2.0889, lr_0 = 1.0200e-04
Loss = 1.1621e-03, PNorm = 37.0219, GNorm = 2.8615, lr_0 = 1.0200e-04
Loss = 1.4710e-03, PNorm = 37.0248, GNorm = 1.7975, lr_0 = 1.0200e-04
Loss = 1.0958e-03, PNorm = 37.0275, GNorm = 2.7141, lr_0 = 1.0200e-04
Loss = 1.3958e-03, PNorm = 37.0310, GNorm = 1.6852, lr_0 = 1.0200e-04
Validation rmse logD = 0.619633
Validation R2 logD = 0.734082
Validation rmse logP = 0.502133
Validation R2 logP = 0.926822
Epoch 36
Train function
Loss = 1.2348e-03, PNorm = 37.0329, GNorm = 6.0833, lr_0 = 1.0200e-04
Loss = 1.1837e-03, PNorm = 37.0343, GNorm = 2.8779, lr_0 = 1.0200e-04
Loss = 1.2780e-03, PNorm = 37.0357, GNorm = 1.5076, lr_0 = 1.0200e-04
Loss = 1.0763e-03, PNorm = 37.0380, GNorm = 1.2702, lr_0 = 1.0200e-04
Loss = 1.3103e-03, PNorm = 37.0403, GNorm = 1.0887, lr_0 = 1.0200e-04
Loss = 1.3024e-03, PNorm = 37.0423, GNorm = 1.9154, lr_0 = 1.0200e-04
Loss = 1.1518e-03, PNorm = 37.0448, GNorm = 1.5518, lr_0 = 1.0200e-04
Loss = 1.2652e-03, PNorm = 37.0469, GNorm = 1.1358, lr_0 = 1.0200e-04
Loss = 1.0425e-03, PNorm = 37.0489, GNorm = 3.0722, lr_0 = 1.0200e-04
Loss = 1.4012e-03, PNorm = 37.0509, GNorm = 3.9483, lr_0 = 1.0200e-04
Loss = 1.2485e-03, PNorm = 37.0528, GNorm = 2.0989, lr_0 = 1.0200e-04
Loss = 1.3426e-03, PNorm = 37.0548, GNorm = 3.2130, lr_0 = 1.0200e-04
Loss = 1.1544e-03, PNorm = 37.0564, GNorm = 2.3238, lr_0 = 1.0200e-04
Loss = 1.1542e-03, PNorm = 37.0573, GNorm = 2.6905, lr_0 = 1.0200e-04
Loss = 1.2542e-03, PNorm = 37.0589, GNorm = 3.9104, lr_0 = 1.0200e-04
Loss = 1.2398e-03, PNorm = 37.0613, GNorm = 2.2199, lr_0 = 1.0200e-04
Loss = 1.1314e-03, PNorm = 37.0628, GNorm = 3.0354, lr_0 = 1.0200e-04
Loss = 1.0809e-03, PNorm = 37.0647, GNorm = 1.0379, lr_0 = 1.0200e-04
Loss = 1.2871e-03, PNorm = 37.0684, GNorm = 2.0752, lr_0 = 1.0200e-04
Loss = 1.1734e-03, PNorm = 37.0708, GNorm = 1.7255, lr_0 = 1.0200e-04
Loss = 1.2408e-03, PNorm = 37.0719, GNorm = 1.8883, lr_0 = 1.0200e-04
Loss = 1.4800e-03, PNorm = 37.0744, GNorm = 1.4901, lr_0 = 1.0200e-04
Loss = 1.1705e-03, PNorm = 37.0764, GNorm = 4.6615, lr_0 = 1.0200e-04
Validation rmse logD = 0.611549
Validation R2 logD = 0.740976
Validation rmse logP = 0.491380
Validation R2 logP = 0.929923
Epoch 37
Train function
Loss = 1.0431e-03, PNorm = 37.0778, GNorm = 1.6470, lr_0 = 1.0200e-04
Loss = 1.1684e-03, PNorm = 37.0793, GNorm = 1.8277, lr_0 = 1.0200e-04
Loss = 1.0802e-03, PNorm = 37.0817, GNorm = 1.9525, lr_0 = 1.0200e-04
Loss = 1.0869e-03, PNorm = 37.0844, GNorm = 2.3847, lr_0 = 1.0200e-04
Loss = 9.9938e-04, PNorm = 37.0855, GNorm = 2.8445, lr_0 = 1.0200e-04
Loss = 1.3149e-03, PNorm = 37.0874, GNorm = 2.8088, lr_0 = 1.0200e-04
Loss = 1.2557e-03, PNorm = 37.0893, GNorm = 1.3607, lr_0 = 1.0200e-04
Loss = 1.3210e-03, PNorm = 37.0901, GNorm = 6.1796, lr_0 = 1.0200e-04
Loss = 1.3277e-03, PNorm = 37.0926, GNorm = 2.4074, lr_0 = 1.0200e-04
Loss = 1.2895e-03, PNorm = 37.0949, GNorm = 1.6014, lr_0 = 1.0200e-04
Loss = 1.1264e-03, PNorm = 37.0962, GNorm = 1.1345, lr_0 = 1.0200e-04
Loss = 1.2526e-03, PNorm = 37.0977, GNorm = 3.4572, lr_0 = 1.0200e-04
Loss = 1.2675e-03, PNorm = 37.0990, GNorm = 3.0297, lr_0 = 1.0200e-04
Loss = 1.0426e-03, PNorm = 37.1011, GNorm = 2.6304, lr_0 = 1.0200e-04
Loss = 1.1200e-03, PNorm = 37.1029, GNorm = 2.2748, lr_0 = 1.0200e-04
Loss = 1.3297e-03, PNorm = 37.1053, GNorm = 2.4146, lr_0 = 1.0200e-04
Loss = 1.1784e-03, PNorm = 37.1074, GNorm = 2.3126, lr_0 = 1.0200e-04
Loss = 1.4807e-03, PNorm = 37.1090, GNorm = 2.4756, lr_0 = 1.0200e-04
Loss = 1.2088e-03, PNorm = 37.1104, GNorm = 3.1070, lr_0 = 1.0200e-04
Loss = 1.1602e-03, PNorm = 37.1121, GNorm = 1.8916, lr_0 = 1.0200e-04
Loss = 1.1355e-03, PNorm = 37.1138, GNorm = 2.4592, lr_0 = 1.0200e-04
Loss = 1.0568e-03, PNorm = 37.1161, GNorm = 1.8603, lr_0 = 1.0200e-04
Validation rmse logD = 0.605360
Validation R2 logD = 0.746192
Validation rmse logP = 0.492306
Validation R2 logP = 0.929659
Epoch 38
Train function
Loss = 8.1017e-04, PNorm = 37.1187, GNorm = 1.3804, lr_0 = 1.0200e-04
Loss = 1.0678e-03, PNorm = 37.1211, GNorm = 2.1314, lr_0 = 1.0200e-04
Loss = 1.0553e-03, PNorm = 37.1225, GNorm = 2.5717, lr_0 = 1.0200e-04
Loss = 9.3260e-04, PNorm = 37.1243, GNorm = 1.6899, lr_0 = 1.0200e-04
Loss = 1.1084e-03, PNorm = 37.1259, GNorm = 1.9483, lr_0 = 1.0200e-04
Loss = 1.0061e-03, PNorm = 37.1274, GNorm = 3.7201, lr_0 = 1.0200e-04
Loss = 1.1155e-03, PNorm = 37.1289, GNorm = 1.9228, lr_0 = 1.0200e-04
Loss = 9.0957e-04, PNorm = 37.1309, GNorm = 2.8433, lr_0 = 1.0200e-04
Loss = 1.4414e-03, PNorm = 37.1323, GNorm = 3.3740, lr_0 = 1.0200e-04
Loss = 1.2099e-03, PNorm = 37.1343, GNorm = 2.8306, lr_0 = 1.0200e-04
Loss = 1.2004e-03, PNorm = 37.1364, GNorm = 2.1478, lr_0 = 1.0200e-04
Loss = 1.1151e-03, PNorm = 37.1381, GNorm = 0.9533, lr_0 = 1.0200e-04
Loss = 1.0059e-03, PNorm = 37.1400, GNorm = 1.5588, lr_0 = 1.0200e-04
Loss = 1.1984e-03, PNorm = 37.1428, GNorm = 1.5802, lr_0 = 1.0200e-04
Loss = 1.2153e-03, PNorm = 37.1453, GNorm = 2.0293, lr_0 = 1.0200e-04
Loss = 1.0703e-03, PNorm = 37.1479, GNorm = 1.5779, lr_0 = 1.0200e-04
Loss = 1.0431e-03, PNorm = 37.1501, GNorm = 2.2659, lr_0 = 1.0200e-04
Loss = 1.1760e-03, PNorm = 37.1517, GNorm = 3.8308, lr_0 = 1.0200e-04
Loss = 1.1870e-03, PNorm = 37.1535, GNorm = 1.2566, lr_0 = 1.0200e-04
Loss = 1.2999e-03, PNorm = 37.1554, GNorm = 1.5903, lr_0 = 1.0200e-04
Loss = 1.1121e-03, PNorm = 37.1576, GNorm = 3.0227, lr_0 = 1.0200e-04
Loss = 1.0145e-03, PNorm = 37.1595, GNorm = 1.3714, lr_0 = 1.0200e-04
Loss = 1.0186e-03, PNorm = 37.1600, GNorm = 1.9154, lr_0 = 1.0200e-04
Validation rmse logD = 0.614276
Validation R2 logD = 0.738660
Validation rmse logP = 0.489508
Validation R2 logP = 0.930456
Epoch 39
Train function
Loss = 1.0982e-03, PNorm = 37.1623, GNorm = 2.7556, lr_0 = 1.0200e-04
Loss = 1.0505e-03, PNorm = 37.1643, GNorm = 4.6155, lr_0 = 1.0200e-04
Loss = 1.2858e-03, PNorm = 37.1660, GNorm = 1.8454, lr_0 = 1.0200e-04
Loss = 9.9533e-04, PNorm = 37.1678, GNorm = 2.3649, lr_0 = 1.0200e-04
Loss = 1.0496e-03, PNorm = 37.1692, GNorm = 1.9092, lr_0 = 1.0200e-04
Loss = 1.1388e-03, PNorm = 37.1705, GNorm = 1.6103, lr_0 = 1.0200e-04
Loss = 9.2131e-04, PNorm = 37.1722, GNorm = 1.4884, lr_0 = 1.0200e-04
Loss = 1.0541e-03, PNorm = 37.1739, GNorm = 2.1124, lr_0 = 1.0200e-04
Loss = 1.2305e-03, PNorm = 37.1762, GNorm = 2.8843, lr_0 = 1.0200e-04
Loss = 1.0357e-03, PNorm = 37.1780, GNorm = 1.7320, lr_0 = 1.0200e-04
Loss = 1.0868e-03, PNorm = 37.1794, GNorm = 1.4683, lr_0 = 1.0200e-04
Loss = 1.0359e-03, PNorm = 37.1806, GNorm = 1.4139, lr_0 = 1.0200e-04
Loss = 1.0471e-03, PNorm = 37.1827, GNorm = 1.9330, lr_0 = 1.0200e-04
Loss = 1.1276e-03, PNorm = 37.1847, GNorm = 4.7593, lr_0 = 1.0200e-04
Loss = 1.0777e-03, PNorm = 37.1867, GNorm = 1.8475, lr_0 = 1.0200e-04
Loss = 9.5257e-04, PNorm = 37.1882, GNorm = 1.9977, lr_0 = 1.0200e-04
Loss = 1.3511e-03, PNorm = 37.1902, GNorm = 7.2959, lr_0 = 1.0200e-04
Loss = 9.5897e-04, PNorm = 37.1918, GNorm = 1.5295, lr_0 = 1.0200e-04
Loss = 1.0707e-03, PNorm = 37.1939, GNorm = 1.2178, lr_0 = 1.0200e-04
Loss = 1.1900e-03, PNorm = 37.1959, GNorm = 1.6656, lr_0 = 1.0200e-04
Loss = 1.0432e-03, PNorm = 37.1980, GNorm = 4.1104, lr_0 = 1.0200e-04
Loss = 1.5188e-03, PNorm = 37.2003, GNorm = 2.4796, lr_0 = 1.0200e-04
Validation rmse logD = 0.605585
Validation R2 logD = 0.746003
Validation rmse logP = 0.494181
Validation R2 logP = 0.929122
Epoch 40
Train function
Loss = 1.4917e-03, PNorm = 37.2026, GNorm = 3.1667, lr_0 = 1.0200e-04
Loss = 1.0756e-03, PNorm = 37.2053, GNorm = 2.2186, lr_0 = 1.0200e-04
Loss = 1.0270e-03, PNorm = 37.2081, GNorm = 1.3460, lr_0 = 1.0200e-04
Loss = 1.0969e-03, PNorm = 37.2109, GNorm = 1.0170, lr_0 = 1.0200e-04
Loss = 1.2563e-03, PNorm = 37.2135, GNorm = 1.8564, lr_0 = 1.0200e-04
Loss = 1.2630e-03, PNorm = 37.2148, GNorm = 2.7796, lr_0 = 1.0200e-04
Loss = 1.1030e-03, PNorm = 37.2163, GNorm = 1.9012, lr_0 = 1.0200e-04
Loss = 9.2953e-04, PNorm = 37.2174, GNorm = 4.0387, lr_0 = 1.0200e-04
Loss = 9.9737e-04, PNorm = 37.2189, GNorm = 1.1929, lr_0 = 1.0200e-04
Loss = 1.0005e-03, PNorm = 37.2210, GNorm = 2.2001, lr_0 = 1.0200e-04
Loss = 1.1881e-03, PNorm = 37.2225, GNorm = 4.3037, lr_0 = 1.0200e-04
Loss = 1.2328e-03, PNorm = 37.2238, GNorm = 1.8569, lr_0 = 1.0200e-04
Loss = 1.2076e-03, PNorm = 37.2255, GNorm = 3.0320, lr_0 = 1.0200e-04
Loss = 8.6638e-04, PNorm = 37.2284, GNorm = 1.6561, lr_0 = 1.0200e-04
Loss = 1.0365e-03, PNorm = 37.2300, GNorm = 3.0598, lr_0 = 1.0200e-04
Loss = 1.1749e-03, PNorm = 37.2320, GNorm = 4.8385, lr_0 = 1.0200e-04
Loss = 1.2502e-03, PNorm = 37.2344, GNorm = 2.8174, lr_0 = 1.0200e-04
Loss = 1.1199e-03, PNorm = 37.2361, GNorm = 2.4144, lr_0 = 1.0200e-04
Loss = 1.3781e-03, PNorm = 37.2380, GNorm = 2.0875, lr_0 = 1.0200e-04
Loss = 1.1517e-03, PNorm = 37.2398, GNorm = 1.9557, lr_0 = 1.0200e-04
Loss = 1.0706e-03, PNorm = 37.2412, GNorm = 1.1637, lr_0 = 1.0200e-04
Loss = 1.1093e-03, PNorm = 37.2430, GNorm = 1.5993, lr_0 = 1.0200e-04
Loss = 9.1902e-04, PNorm = 37.2447, GNorm = 1.9065, lr_0 = 1.0200e-04
Validation rmse logD = 0.605431
Validation R2 logD = 0.746133
Validation rmse logP = 0.504593
Validation R2 logP = 0.926104
Epoch 41
Train function
Loss = 1.1324e-03, PNorm = 37.2465, GNorm = 3.4455, lr_0 = 1.0200e-04
Loss = 9.0329e-04, PNorm = 37.2477, GNorm = 2.2487, lr_0 = 1.0200e-04
Loss = 8.7287e-04, PNorm = 37.2486, GNorm = 1.8396, lr_0 = 1.0200e-04
Loss = 9.4532e-04, PNorm = 37.2498, GNorm = 4.6379, lr_0 = 1.0200e-04
Loss = 9.6167e-04, PNorm = 37.2519, GNorm = 1.4155, lr_0 = 1.0200e-04
Loss = 1.0851e-03, PNorm = 37.2537, GNorm = 4.0210, lr_0 = 1.0200e-04
Loss = 1.0876e-03, PNorm = 37.2552, GNorm = 0.8055, lr_0 = 1.0200e-04
Loss = 1.1184e-03, PNorm = 37.2568, GNorm = 1.9709, lr_0 = 1.0200e-04
Loss = 1.1325e-03, PNorm = 37.2597, GNorm = 7.9061, lr_0 = 1.0200e-04
Loss = 1.1940e-03, PNorm = 37.2617, GNorm = 1.2417, lr_0 = 1.0200e-04
Loss = 9.8593e-04, PNorm = 37.2632, GNorm = 2.2903, lr_0 = 1.0200e-04
Loss = 8.2367e-04, PNorm = 37.2649, GNorm = 2.4945, lr_0 = 1.0200e-04
Loss = 1.2301e-03, PNorm = 37.2669, GNorm = 5.9192, lr_0 = 1.0200e-04
Loss = 9.4551e-04, PNorm = 37.2688, GNorm = 1.0223, lr_0 = 1.0200e-04
Loss = 1.0974e-03, PNorm = 37.2708, GNorm = 1.4004, lr_0 = 1.0200e-04
Loss = 1.2301e-03, PNorm = 37.2744, GNorm = 1.0539, lr_0 = 1.0200e-04
Loss = 1.2044e-03, PNorm = 37.2764, GNorm = 3.2545, lr_0 = 1.0200e-04
Loss = 1.2154e-03, PNorm = 37.2783, GNorm = 5.3264, lr_0 = 1.0200e-04
Loss = 1.3460e-03, PNorm = 37.2798, GNorm = 2.2643, lr_0 = 1.0200e-04
Loss = 1.1739e-03, PNorm = 37.2817, GNorm = 2.4665, lr_0 = 1.0200e-04
Loss = 1.3505e-03, PNorm = 37.2838, GNorm = 3.1092, lr_0 = 1.0200e-04
Loss = 9.9208e-04, PNorm = 37.2856, GNorm = 1.0480, lr_0 = 1.0200e-04
Loss = 1.2450e-03, PNorm = 37.2877, GNorm = 2.9070, lr_0 = 1.0200e-04
Validation rmse logD = 0.603066
Validation R2 logD = 0.748112
Validation rmse logP = 0.496187
Validation R2 logP = 0.928545
Epoch 42
Train function
Loss = 1.0312e-03, PNorm = 37.2897, GNorm = 3.7383, lr_0 = 1.0200e-04
Loss = 1.1897e-03, PNorm = 37.2912, GNorm = 1.9261, lr_0 = 1.0200e-04
Loss = 1.2517e-03, PNorm = 37.2933, GNorm = 2.6364, lr_0 = 1.0200e-04
Loss = 1.1036e-03, PNorm = 37.2959, GNorm = 2.2513, lr_0 = 1.0200e-04
Loss = 1.0239e-03, PNorm = 37.2987, GNorm = 1.0158, lr_0 = 1.0200e-04
Loss = 1.2664e-03, PNorm = 37.3000, GNorm = 2.5716, lr_0 = 1.0200e-04
Loss = 8.9906e-04, PNorm = 37.3020, GNorm = 0.9922, lr_0 = 1.0200e-04
Loss = 9.7995e-04, PNorm = 37.3031, GNorm = 1.7768, lr_0 = 1.0200e-04
Loss = 1.1321e-03, PNorm = 37.3044, GNorm = 1.7996, lr_0 = 1.0200e-04
Loss = 1.0493e-03, PNorm = 37.3064, GNorm = 2.1107, lr_0 = 1.0200e-04
Loss = 9.6014e-04, PNorm = 37.3080, GNorm = 1.5649, lr_0 = 1.0200e-04
Loss = 1.1096e-03, PNorm = 37.3101, GNorm = 2.2305, lr_0 = 1.0200e-04
Loss = 1.1695e-03, PNorm = 37.3120, GNorm = 5.1330, lr_0 = 1.0200e-04
Loss = 1.0648e-03, PNorm = 37.3134, GNorm = 1.9538, lr_0 = 1.0200e-04
Loss = 1.1208e-03, PNorm = 37.3150, GNorm = 2.9453, lr_0 = 1.0200e-04
Loss = 9.8002e-04, PNorm = 37.3179, GNorm = 1.5105, lr_0 = 1.0200e-04
Loss = 1.0013e-03, PNorm = 37.3203, GNorm = 2.8743, lr_0 = 1.0200e-04
Loss = 1.0661e-03, PNorm = 37.3213, GNorm = 2.1178, lr_0 = 1.0200e-04
Loss = 1.1628e-03, PNorm = 37.3231, GNorm = 4.3857, lr_0 = 1.0200e-04
Loss = 1.1737e-03, PNorm = 37.3258, GNorm = 2.6245, lr_0 = 1.0200e-04
Loss = 9.9354e-04, PNorm = 37.3277, GNorm = 1.9283, lr_0 = 1.0200e-04
Loss = 1.0138e-03, PNorm = 37.3291, GNorm = 3.8726, lr_0 = 1.0200e-04
Validation rmse logD = 0.610870
Validation R2 logD = 0.741551
Validation rmse logP = 0.493234
Validation R2 logP = 0.929393
Epoch 43
Train function
Loss = 9.3114e-04, PNorm = 37.3314, GNorm = 1.5178, lr_0 = 1.0200e-04
Loss = 7.8110e-04, PNorm = 37.3334, GNorm = 1.8456, lr_0 = 1.0200e-04
Loss = 1.0029e-03, PNorm = 37.3350, GNorm = 2.5708, lr_0 = 1.0200e-04
Loss = 1.0400e-03, PNorm = 37.3381, GNorm = 2.1011, lr_0 = 1.0200e-04
Loss = 1.1281e-03, PNorm = 37.3409, GNorm = 1.3824, lr_0 = 1.0200e-04
Loss = 1.0811e-03, PNorm = 37.3435, GNorm = 3.4937, lr_0 = 1.0200e-04
Loss = 8.9073e-04, PNorm = 37.3453, GNorm = 1.3085, lr_0 = 1.0200e-04
Loss = 8.4711e-04, PNorm = 37.3466, GNorm = 1.6989, lr_0 = 1.0200e-04
Loss = 9.2417e-04, PNorm = 37.3481, GNorm = 1.4293, lr_0 = 1.0200e-04
Loss = 1.0268e-03, PNorm = 37.3502, GNorm = 0.9223, lr_0 = 1.0200e-04
Loss = 9.6454e-04, PNorm = 37.3509, GNorm = 1.5270, lr_0 = 1.0200e-04
Loss = 1.0837e-03, PNorm = 37.3530, GNorm = 3.3723, lr_0 = 1.0200e-04
Loss = 1.1094e-03, PNorm = 37.3548, GNorm = 1.3956, lr_0 = 1.0200e-04
Loss = 1.0149e-03, PNorm = 37.3562, GNorm = 1.4532, lr_0 = 1.0200e-04
Loss = 9.7644e-04, PNorm = 37.3574, GNorm = 1.2192, lr_0 = 1.0200e-04
Loss = 1.0748e-03, PNorm = 37.3599, GNorm = 1.5211, lr_0 = 1.0200e-04
Loss = 1.1218e-03, PNorm = 37.3613, GNorm = 1.9388, lr_0 = 1.0200e-04
Loss = 1.0339e-03, PNorm = 37.3631, GNorm = 2.4050, lr_0 = 1.0200e-04
Loss = 1.1792e-03, PNorm = 37.3647, GNorm = 2.7130, lr_0 = 1.0200e-04
Loss = 1.1433e-03, PNorm = 37.3664, GNorm = 2.2823, lr_0 = 1.0200e-04
Loss = 1.1303e-03, PNorm = 37.3688, GNorm = 1.8267, lr_0 = 1.0200e-04
Loss = 8.9910e-04, PNorm = 37.3704, GNorm = 2.5295, lr_0 = 1.0200e-04
Loss = 9.2348e-04, PNorm = 37.3722, GNorm = 1.0223, lr_0 = 1.0200e-04
Validation rmse logD = 0.597933
Validation R2 logD = 0.752382
Validation rmse logP = 0.501842
Validation R2 logP = 0.926907
Epoch 44
Train function
Loss = 8.6060e-04, PNorm = 37.3727, GNorm = 4.9745, lr_0 = 1.0200e-04
Loss = 1.1023e-03, PNorm = 37.3732, GNorm = 1.2599, lr_0 = 1.0200e-04
Loss = 8.9625e-04, PNorm = 37.3749, GNorm = 1.6767, lr_0 = 1.0200e-04
Loss = 1.1524e-03, PNorm = 37.3769, GNorm = 1.7762, lr_0 = 1.0200e-04
Loss = 8.3759e-04, PNorm = 37.3793, GNorm = 1.6853, lr_0 = 1.0200e-04
Loss = 8.8204e-04, PNorm = 37.3819, GNorm = 2.2375, lr_0 = 1.0200e-04
Loss = 9.6233e-04, PNorm = 37.3842, GNorm = 2.5940, lr_0 = 1.0200e-04
Loss = 1.1610e-03, PNorm = 37.3854, GNorm = 1.7320, lr_0 = 1.0200e-04
Loss = 8.4353e-04, PNorm = 37.3864, GNorm = 1.0120, lr_0 = 1.0200e-04
Loss = 9.8340e-04, PNorm = 37.3886, GNorm = 2.9571, lr_0 = 1.0200e-04
Loss = 9.1243e-04, PNorm = 37.3907, GNorm = 1.5281, lr_0 = 1.0200e-04
Loss = 1.1290e-03, PNorm = 37.3927, GNorm = 2.3895, lr_0 = 1.0200e-04
Loss = 8.2513e-04, PNorm = 37.3953, GNorm = 2.0900, lr_0 = 1.0200e-04
Loss = 8.9707e-04, PNorm = 37.3970, GNorm = 1.9508, lr_0 = 1.0200e-04
Loss = 8.7442e-04, PNorm = 37.3992, GNorm = 1.0429, lr_0 = 1.0200e-04
Loss = 8.3961e-04, PNorm = 37.4014, GNorm = 1.9098, lr_0 = 1.0200e-04
Loss = 9.9440e-04, PNorm = 37.4021, GNorm = 2.9002, lr_0 = 1.0200e-04
Loss = 8.3877e-04, PNorm = 37.4031, GNorm = 1.1782, lr_0 = 1.0200e-04
Loss = 1.0230e-03, PNorm = 37.4045, GNorm = 4.9090, lr_0 = 1.0200e-04
Loss = 9.5840e-04, PNorm = 37.4058, GNorm = 1.7169, lr_0 = 1.0200e-04
Loss = 1.0533e-03, PNorm = 37.4076, GNorm = 1.9823, lr_0 = 1.0200e-04
Loss = 1.1434e-03, PNorm = 37.4098, GNorm = 1.0218, lr_0 = 1.0200e-04
Validation rmse logD = 0.608575
Validation R2 logD = 0.743489
Validation rmse logP = 0.487640
Validation R2 logP = 0.930986
Epoch 45
Train function
Loss = 5.2200e-04, PNorm = 37.4128, GNorm = 1.6387, lr_0 = 1.0200e-04
Loss = 9.8702e-04, PNorm = 37.4152, GNorm = 2.1111, lr_0 = 1.0200e-04
Loss = 8.8334e-04, PNorm = 37.4169, GNorm = 5.3682, lr_0 = 1.0200e-04
Loss = 9.2239e-04, PNorm = 37.4179, GNorm = 1.4072, lr_0 = 1.0200e-04
Loss = 1.0601e-03, PNorm = 37.4202, GNorm = 1.1994, lr_0 = 1.0200e-04
Loss = 9.1368e-04, PNorm = 37.4217, GNorm = 1.5821, lr_0 = 1.0200e-04
Loss = 8.3904e-04, PNorm = 37.4233, GNorm = 1.5518, lr_0 = 1.0200e-04
Loss = 1.1897e-03, PNorm = 37.4254, GNorm = 3.3635, lr_0 = 1.0200e-04
Loss = 1.0768e-03, PNorm = 37.4279, GNorm = 2.8320, lr_0 = 1.0200e-04
Loss = 9.6013e-04, PNorm = 37.4299, GNorm = 2.5449, lr_0 = 1.0200e-04
Loss = 1.0119e-03, PNorm = 37.4316, GNorm = 2.5010, lr_0 = 1.0200e-04
Loss = 8.6259e-04, PNorm = 37.4334, GNorm = 2.2930, lr_0 = 1.0200e-04
Loss = 8.2958e-04, PNorm = 37.4354, GNorm = 2.7308, lr_0 = 1.0200e-04
Loss = 8.6769e-04, PNorm = 37.4372, GNorm = 2.8138, lr_0 = 1.0200e-04
Loss = 9.5961e-04, PNorm = 37.4386, GNorm = 1.5286, lr_0 = 1.0200e-04
Loss = 9.2455e-04, PNorm = 37.4398, GNorm = 1.7450, lr_0 = 1.0200e-04
Loss = 9.2545e-04, PNorm = 37.4417, GNorm = 1.2702, lr_0 = 1.0200e-04
Loss = 8.9220e-04, PNorm = 37.4437, GNorm = 3.6616, lr_0 = 1.0200e-04
Loss = 1.2531e-03, PNorm = 37.4448, GNorm = 2.1679, lr_0 = 1.0200e-04
Loss = 9.1236e-04, PNorm = 37.4465, GNorm = 2.8847, lr_0 = 1.0200e-04
Loss = 1.0183e-03, PNorm = 37.4493, GNorm = 1.0493, lr_0 = 1.0200e-04
Loss = 1.0845e-03, PNorm = 37.4509, GNorm = 3.3337, lr_0 = 1.0200e-04
Loss = 1.2029e-03, PNorm = 37.4514, GNorm = 2.3465, lr_0 = 1.0200e-04
Validation rmse logD = 0.607001
Validation R2 logD = 0.744814
Validation rmse logP = 0.533257
Validation R2 logP = 0.917470
Epoch 46
Train function
Loss = 8.8292e-04, PNorm = 37.4522, GNorm = 3.9772, lr_0 = 1.0200e-04
Loss = 8.6116e-04, PNorm = 37.4537, GNorm = 1.9452, lr_0 = 1.0200e-04
Loss = 9.3192e-04, PNorm = 37.4555, GNorm = 1.5975, lr_0 = 1.0200e-04
Loss = 9.9468e-04, PNorm = 37.4576, GNorm = 1.6830, lr_0 = 1.0200e-04
Loss = 7.8780e-04, PNorm = 37.4595, GNorm = 5.3622, lr_0 = 1.0200e-04
Loss = 1.0170e-03, PNorm = 37.4608, GNorm = 4.1290, lr_0 = 1.0200e-04
Loss = 1.0418e-03, PNorm = 37.4625, GNorm = 2.7107, lr_0 = 1.0200e-04
Loss = 7.9802e-04, PNorm = 37.4638, GNorm = 1.4812, lr_0 = 1.0200e-04
Loss = 9.1847e-04, PNorm = 37.4656, GNorm = 1.5955, lr_0 = 1.0200e-04
Loss = 9.8621e-04, PNorm = 37.4667, GNorm = 3.2105, lr_0 = 1.0200e-04
Loss = 9.3295e-04, PNorm = 37.4686, GNorm = 1.4059, lr_0 = 1.0200e-04
Loss = 9.0536e-04, PNorm = 37.4711, GNorm = 3.6361, lr_0 = 1.0200e-04
Loss = 1.0651e-03, PNorm = 37.4728, GNorm = 2.0919, lr_0 = 1.0200e-04
Loss = 1.0598e-03, PNorm = 37.4744, GNorm = 2.9097, lr_0 = 1.0200e-04
Loss = 8.8749e-04, PNorm = 37.4760, GNorm = 1.1570, lr_0 = 1.0200e-04
Loss = 9.3411e-04, PNorm = 37.4786, GNorm = 2.2049, lr_0 = 1.0200e-04
Loss = 1.1397e-03, PNorm = 37.4813, GNorm = 1.8977, lr_0 = 1.0200e-04
Loss = 1.2925e-03, PNorm = 37.4838, GNorm = 4.4478, lr_0 = 1.0200e-04
Loss = 9.4134e-04, PNorm = 37.4861, GNorm = 1.2287, lr_0 = 1.0200e-04
Loss = 8.4640e-04, PNorm = 37.4882, GNorm = 1.0634, lr_0 = 1.0200e-04
Loss = 8.6461e-04, PNorm = 37.4900, GNorm = 2.4117, lr_0 = 1.0200e-04
Loss = 9.2217e-04, PNorm = 37.4917, GNorm = 2.9562, lr_0 = 1.0200e-04
Validation rmse logD = 0.598344
Validation R2 logD = 0.752041
Validation rmse logP = 0.482392
Validation R2 logP = 0.932463
Epoch 47
Train function
Loss = 1.0194e-03, PNorm = 37.4942, GNorm = 1.7795, lr_0 = 1.0200e-04
Loss = 7.2222e-04, PNorm = 37.4954, GNorm = 0.9721, lr_0 = 1.0200e-04
Loss = 9.8617e-04, PNorm = 37.4967, GNorm = 4.0647, lr_0 = 1.0200e-04
Loss = 8.3655e-04, PNorm = 37.4977, GNorm = 3.0485, lr_0 = 1.0200e-04
Loss = 7.7773e-04, PNorm = 37.4987, GNorm = 1.1406, lr_0 = 1.0200e-04
Loss = 8.0555e-04, PNorm = 37.5005, GNorm = 0.8462, lr_0 = 1.0200e-04
Loss = 9.1487e-04, PNorm = 37.5026, GNorm = 2.7543, lr_0 = 1.0200e-04
Loss = 8.2276e-04, PNorm = 37.5043, GNorm = 1.6904, lr_0 = 1.0200e-04
Loss = 8.6377e-04, PNorm = 37.5055, GNorm = 2.2212, lr_0 = 1.0200e-04
Loss = 1.0526e-03, PNorm = 37.5066, GNorm = 2.6018, lr_0 = 1.0200e-04
Loss = 9.8146e-04, PNorm = 37.5085, GNorm = 1.3959, lr_0 = 1.0200e-04
Loss = 8.0074e-04, PNorm = 37.5115, GNorm = 0.9778, lr_0 = 1.0200e-04
Loss = 8.5968e-04, PNorm = 37.5132, GNorm = 1.0008, lr_0 = 1.0200e-04
Loss = 7.8463e-04, PNorm = 37.5144, GNorm = 1.6532, lr_0 = 1.0200e-04
Loss = 7.8516e-04, PNorm = 37.5166, GNorm = 1.9235, lr_0 = 1.0200e-04
Loss = 8.8288e-04, PNorm = 37.5177, GNorm = 1.3665, lr_0 = 1.0200e-04
Loss = 8.9286e-04, PNorm = 37.5191, GNorm = 2.1470, lr_0 = 1.0200e-04
Loss = 1.1249e-03, PNorm = 37.5212, GNorm = 1.8799, lr_0 = 1.0200e-04
Loss = 1.0243e-03, PNorm = 37.5230, GNorm = 3.1533, lr_0 = 1.0200e-04
Loss = 8.0227e-04, PNorm = 37.5246, GNorm = 4.3246, lr_0 = 1.0200e-04
Loss = 9.9927e-04, PNorm = 37.5260, GNorm = 2.8455, lr_0 = 1.0200e-04
Loss = 7.8971e-04, PNorm = 37.5284, GNorm = 1.6387, lr_0 = 1.0200e-04
Loss = 8.7767e-04, PNorm = 37.5298, GNorm = 4.3539, lr_0 = 1.0200e-04
Validation rmse logD = 0.601866
Validation R2 logD = 0.749114
Validation rmse logP = 0.487079
Validation R2 logP = 0.931144
Epoch 48
Train function
Loss = 7.8732e-04, PNorm = 37.5310, GNorm = 3.6713, lr_0 = 1.0200e-04
Loss = 1.0009e-03, PNorm = 37.5323, GNorm = 7.0387, lr_0 = 1.0200e-04
Loss = 8.6515e-04, PNorm = 37.5334, GNorm = 2.0495, lr_0 = 1.0200e-04
Loss = 9.1360e-04, PNorm = 37.5347, GNorm = 2.2193, lr_0 = 1.0200e-04
Loss = 9.7658e-04, PNorm = 37.5373, GNorm = 1.9509, lr_0 = 1.0200e-04
Loss = 8.2984e-04, PNorm = 37.5382, GNorm = 1.6469, lr_0 = 1.0200e-04
Loss = 8.6151e-04, PNorm = 37.5401, GNorm = 2.3025, lr_0 = 1.0200e-04
Loss = 9.6810e-04, PNorm = 37.5416, GNorm = 1.2104, lr_0 = 1.0200e-04
Loss = 7.8866e-04, PNorm = 37.5441, GNorm = 1.7642, lr_0 = 1.0200e-04
Loss = 7.9703e-04, PNorm = 37.5461, GNorm = 4.2736, lr_0 = 1.0200e-04
Loss = 1.1308e-03, PNorm = 37.5482, GNorm = 1.6737, lr_0 = 1.0200e-04
Loss = 9.7829e-04, PNorm = 37.5505, GNorm = 2.7723, lr_0 = 1.0200e-04
Loss = 9.3058e-04, PNorm = 37.5519, GNorm = 1.7577, lr_0 = 1.0200e-04
Loss = 9.4564e-04, PNorm = 37.5535, GNorm = 1.3830, lr_0 = 1.0200e-04
Loss = 9.7424e-04, PNorm = 37.5548, GNorm = 1.1111, lr_0 = 1.0200e-04
Loss = 8.7601e-04, PNorm = 37.5561, GNorm = 1.2051, lr_0 = 1.0200e-04
Loss = 1.2554e-03, PNorm = 37.5571, GNorm = 6.0666, lr_0 = 1.0200e-04
Loss = 1.1160e-03, PNorm = 37.5589, GNorm = 2.9829, lr_0 = 1.0200e-04
Loss = 9.3811e-04, PNorm = 37.5609, GNorm = 1.4139, lr_0 = 1.0200e-04
Loss = 7.4822e-04, PNorm = 37.5637, GNorm = 3.4157, lr_0 = 1.0200e-04
Loss = 7.8064e-04, PNorm = 37.5662, GNorm = 2.6510, lr_0 = 1.0200e-04
Loss = 9.9276e-04, PNorm = 37.5678, GNorm = 2.1205, lr_0 = 1.0200e-04
Validation rmse logD = 0.615349
Validation R2 logD = 0.737747
Validation rmse logP = 0.481679
Validation R2 logP = 0.932663
Epoch 49
Train function
Loss = 8.7931e-04, PNorm = 37.5700, GNorm = 3.5948, lr_0 = 1.0200e-04
Loss = 7.1984e-04, PNorm = 37.5704, GNorm = 1.0578, lr_0 = 1.0200e-04
Loss = 7.4603e-04, PNorm = 37.5719, GNorm = 0.7752, lr_0 = 1.0200e-04
Loss = 7.0557e-04, PNorm = 37.5739, GNorm = 1.4703, lr_0 = 1.0200e-04
Loss = 1.0361e-03, PNorm = 37.5754, GNorm = 1.4026, lr_0 = 1.0200e-04
Loss = 7.5885e-04, PNorm = 37.5775, GNorm = 2.6784, lr_0 = 1.0200e-04
Loss = 8.4513e-04, PNorm = 37.5793, GNorm = 3.4036, lr_0 = 1.0200e-04
Loss = 7.6051e-04, PNorm = 37.5814, GNorm = 1.8704, lr_0 = 1.0200e-04
Loss = 8.9827e-04, PNorm = 37.5832, GNorm = 1.4968, lr_0 = 1.0200e-04
Loss = 7.8424e-04, PNorm = 37.5847, GNorm = 1.7330, lr_0 = 1.0200e-04
Loss = 7.7238e-04, PNorm = 37.5875, GNorm = 1.7316, lr_0 = 1.0200e-04
Loss = 8.0662e-04, PNorm = 37.5893, GNorm = 1.6925, lr_0 = 1.0200e-04
Loss = 9.4593e-04, PNorm = 37.5911, GNorm = 1.4017, lr_0 = 1.0200e-04
Loss = 7.5401e-04, PNorm = 37.5931, GNorm = 1.5731, lr_0 = 1.0200e-04
Loss = 7.1937e-04, PNorm = 37.5949, GNorm = 2.2272, lr_0 = 1.0200e-04
Loss = 8.2878e-04, PNorm = 37.5965, GNorm = 2.4183, lr_0 = 1.0200e-04
Loss = 1.1957e-03, PNorm = 37.5981, GNorm = 5.6892, lr_0 = 1.0200e-04
Loss = 1.1379e-03, PNorm = 37.6008, GNorm = 3.4647, lr_0 = 1.0200e-04
Loss = 8.1690e-04, PNorm = 37.6028, GNorm = 1.6223, lr_0 = 1.0200e-04
Loss = 1.0054e-03, PNorm = 37.6045, GNorm = 2.1382, lr_0 = 1.0200e-04
Loss = 7.8068e-04, PNorm = 37.6061, GNorm = 1.6444, lr_0 = 1.0200e-04
Loss = 8.8435e-04, PNorm = 37.6078, GNorm = 1.5356, lr_0 = 1.0200e-04
Loss = 8.2150e-04, PNorm = 37.6095, GNorm = 0.9872, lr_0 = 1.0200e-04
Validation rmse logD = 0.608175
Validation R2 logD = 0.743826
Validation rmse logP = 0.510001
Validation R2 logP = 0.924511
Epoch 50
Train function
Loss = 9.2592e-04, PNorm = 37.6115, GNorm = 2.6930, lr_0 = 1.0200e-04
Loss = 8.1349e-04, PNorm = 37.6136, GNorm = 2.6864, lr_0 = 1.0200e-04
Loss = 1.1079e-03, PNorm = 37.6160, GNorm = 1.2714, lr_0 = 1.0200e-04
Loss = 7.8450e-04, PNorm = 37.6185, GNorm = 1.1242, lr_0 = 1.0200e-04
Loss = 9.2982e-04, PNorm = 37.6201, GNorm = 1.9859, lr_0 = 1.0200e-04
Loss = 8.1441e-04, PNorm = 37.6222, GNorm = 3.4955, lr_0 = 1.0200e-04
Loss = 8.1766e-04, PNorm = 37.6239, GNorm = 2.2449, lr_0 = 1.0200e-04
Loss = 6.8337e-04, PNorm = 37.6259, GNorm = 2.0378, lr_0 = 1.0200e-04
Loss = 7.1096e-04, PNorm = 37.6272, GNorm = 1.4180, lr_0 = 1.0200e-04
Loss = 7.2060e-04, PNorm = 37.6281, GNorm = 1.7858, lr_0 = 1.0200e-04
Loss = 8.1789e-04, PNorm = 37.6298, GNorm = 1.6425, lr_0 = 1.0200e-04
Loss = 8.1788e-04, PNorm = 37.6327, GNorm = 3.1874, lr_0 = 1.0200e-04
Loss = 1.0038e-03, PNorm = 37.6339, GNorm = 2.0241, lr_0 = 1.0200e-04
Loss = 9.0393e-04, PNorm = 37.6359, GNorm = 3.0155, lr_0 = 1.0200e-04
Loss = 9.0236e-04, PNorm = 37.6376, GNorm = 1.5202, lr_0 = 1.0200e-04
Loss = 6.7065e-04, PNorm = 37.6384, GNorm = 1.2083, lr_0 = 1.0200e-04
Loss = 8.9185e-04, PNorm = 37.6396, GNorm = 1.0728, lr_0 = 1.0200e-04
Loss = 8.7158e-04, PNorm = 37.6410, GNorm = 1.8098, lr_0 = 1.0200e-04
Loss = 7.3556e-04, PNorm = 37.6424, GNorm = 1.4246, lr_0 = 1.0200e-04
Loss = 9.2512e-04, PNorm = 37.6446, GNorm = 1.8710, lr_0 = 1.0200e-04
Loss = 7.1261e-04, PNorm = 37.6465, GNorm = 0.9947, lr_0 = 1.0200e-04
Loss = 8.4982e-04, PNorm = 37.6482, GNorm = 1.4653, lr_0 = 1.0200e-04
Validation rmse logD = 0.600191
Validation R2 logD = 0.750508
Validation rmse logP = 0.480794
Validation R2 logP = 0.932910
Epoch 51
Train function
Loss = 4.6972e-04, PNorm = 37.6494, GNorm = 2.1832, lr_0 = 1.0200e-04
Loss = 7.4270e-04, PNorm = 37.6508, GNorm = 2.1172, lr_0 = 1.0200e-04
Loss = 7.6839e-04, PNorm = 37.6519, GNorm = 1.7448, lr_0 = 1.0200e-04
Loss = 6.9103e-04, PNorm = 37.6530, GNorm = 1.3153, lr_0 = 1.0200e-04
Loss = 9.1729e-04, PNorm = 37.6551, GNorm = 2.9316, lr_0 = 1.0200e-04
Loss = 9.4701e-04, PNorm = 37.6574, GNorm = 2.7541, lr_0 = 1.0200e-04
Loss = 8.1194e-04, PNorm = 37.6600, GNorm = 1.8964, lr_0 = 1.0200e-04
Loss = 9.8572e-04, PNorm = 37.6619, GNorm = 2.1628, lr_0 = 1.0200e-04
Loss = 7.6968e-04, PNorm = 37.6640, GNorm = 1.8393, lr_0 = 1.0200e-04
Loss = 7.4125e-04, PNorm = 37.6661, GNorm = 1.6717, lr_0 = 1.0200e-04
Loss = 6.8598e-04, PNorm = 37.6670, GNorm = 0.8708, lr_0 = 1.0200e-04
Loss = 8.7604e-04, PNorm = 37.6687, GNorm = 1.7936, lr_0 = 1.0200e-04
Loss = 7.9715e-04, PNorm = 37.6707, GNorm = 1.8989, lr_0 = 1.0200e-04
Loss = 7.9262e-04, PNorm = 37.6725, GNorm = 2.5589, lr_0 = 1.0200e-04
Loss = 8.2321e-04, PNorm = 37.6743, GNorm = 1.0521, lr_0 = 1.0200e-04
Loss = 7.9996e-04, PNorm = 37.6756, GNorm = 1.9931, lr_0 = 1.0200e-04
Loss = 8.3759e-04, PNorm = 37.6777, GNorm = 3.3654, lr_0 = 1.0200e-04
Loss = 9.5251e-04, PNorm = 37.6792, GNorm = 0.9555, lr_0 = 1.0200e-04
Loss = 7.7897e-04, PNorm = 37.6811, GNorm = 4.4307, lr_0 = 1.0200e-04
Loss = 7.5866e-04, PNorm = 37.6823, GNorm = 1.1578, lr_0 = 1.0200e-04
Loss = 9.0193e-04, PNorm = 37.6843, GNorm = 2.0096, lr_0 = 1.0200e-04
Loss = 9.2488e-04, PNorm = 37.6865, GNorm = 1.5311, lr_0 = 1.0200e-04
Loss = 8.1078e-04, PNorm = 37.6878, GNorm = 1.7689, lr_0 = 1.0200e-04
Validation rmse logD = 0.593050
Validation R2 logD = 0.756410
Validation rmse logP = 0.483470
Validation R2 logP = 0.932161
Epoch 52
Train function
Loss = 7.3781e-04, PNorm = 37.6887, GNorm = 3.7748, lr_0 = 1.0200e-04
Loss = 8.8154e-04, PNorm = 37.6897, GNorm = 3.3071, lr_0 = 1.0200e-04
Loss = 7.2448e-04, PNorm = 37.6916, GNorm = 1.3008, lr_0 = 1.0200e-04
Loss = 8.0091e-04, PNorm = 37.6944, GNorm = 2.8546, lr_0 = 1.0200e-04
Loss = 8.5874e-04, PNorm = 37.6965, GNorm = 3.4766, lr_0 = 1.0200e-04
Loss = 7.7630e-04, PNorm = 37.6973, GNorm = 2.2364, lr_0 = 1.0200e-04
Loss = 1.0046e-03, PNorm = 37.6990, GNorm = 2.4952, lr_0 = 1.0200e-04
Loss = 7.7098e-04, PNorm = 37.7008, GNorm = 0.8997, lr_0 = 1.0200e-04
Loss = 7.0676e-04, PNorm = 37.7027, GNorm = 1.1170, lr_0 = 1.0200e-04
Loss = 7.2304e-04, PNorm = 37.7042, GNorm = 2.9253, lr_0 = 1.0200e-04
Loss = 8.9033e-04, PNorm = 37.7063, GNorm = 1.2049, lr_0 = 1.0200e-04
Loss = 7.9587e-04, PNorm = 37.7073, GNorm = 1.9817, lr_0 = 1.0200e-04
Loss = 7.4859e-04, PNorm = 37.7086, GNorm = 2.4738, lr_0 = 1.0200e-04
Loss = 8.5651e-04, PNorm = 37.7107, GNorm = 3.1115, lr_0 = 1.0200e-04
Loss = 1.1943e-03, PNorm = 37.7122, GNorm = 3.6446, lr_0 = 1.0200e-04
Loss = 7.9161e-04, PNorm = 37.7134, GNorm = 1.2575, lr_0 = 1.0200e-04
Loss = 8.4339e-04, PNorm = 37.7153, GNorm = 0.9406, lr_0 = 1.0200e-04
Loss = 5.4350e-04, PNorm = 37.7171, GNorm = 0.7698, lr_0 = 1.0200e-04
Loss = 7.4952e-04, PNorm = 37.7179, GNorm = 1.8480, lr_0 = 1.0200e-04
Loss = 8.3412e-04, PNorm = 37.7192, GNorm = 2.3164, lr_0 = 1.0200e-04
Loss = 8.2477e-04, PNorm = 37.7213, GNorm = 4.1114, lr_0 = 1.0200e-04
Loss = 1.0330e-03, PNorm = 37.7228, GNorm = 1.8379, lr_0 = 1.0200e-04
Loss = 1.0432e-03, PNorm = 37.7238, GNorm = 4.4896, lr_0 = 1.0200e-04
Validation rmse logD = 0.598505
Validation R2 logD = 0.751908
Validation rmse logP = 0.493592
Validation R2 logP = 0.929291
Epoch 53
Train function
Loss = 7.5653e-04, PNorm = 37.7256, GNorm = 1.2975, lr_0 = 1.0200e-04
Loss = 8.6682e-04, PNorm = 37.7268, GNorm = 2.6427, lr_0 = 1.0200e-04
Loss = 8.6704e-04, PNorm = 37.7287, GNorm = 1.9632, lr_0 = 1.0200e-04
Loss = 6.2489e-04, PNorm = 37.7313, GNorm = 0.6306, lr_0 = 1.0200e-04
Loss = 9.6572e-04, PNorm = 37.7336, GNorm = 3.6930, lr_0 = 1.0200e-04
Loss = 7.5952e-04, PNorm = 37.7361, GNorm = 2.5846, lr_0 = 1.0200e-04
Loss = 8.3942e-04, PNorm = 37.7379, GNorm = 1.6733, lr_0 = 1.0200e-04
Loss = 8.7847e-04, PNorm = 37.7403, GNorm = 2.1195, lr_0 = 1.0200e-04
Loss = 9.4341e-04, PNorm = 37.7423, GNorm = 6.3618, lr_0 = 1.0200e-04
Loss = 8.6184e-04, PNorm = 37.7444, GNorm = 3.1768, lr_0 = 1.0200e-04
Loss = 8.1876e-04, PNorm = 37.7454, GNorm = 1.9385, lr_0 = 1.0200e-04
Loss = 8.2323e-04, PNorm = 37.7461, GNorm = 1.6906, lr_0 = 1.0200e-04
Loss = 8.1212e-04, PNorm = 37.7475, GNorm = 2.0414, lr_0 = 1.0200e-04
Loss = 9.7007e-04, PNorm = 37.7492, GNorm = 1.7069, lr_0 = 1.0200e-04
Loss = 7.8552e-04, PNorm = 37.7515, GNorm = 0.8927, lr_0 = 1.0200e-04
Loss = 7.0236e-04, PNorm = 37.7536, GNorm = 1.1514, lr_0 = 1.0200e-04
Loss = 5.9635e-04, PNorm = 37.7552, GNorm = 1.1951, lr_0 = 1.0200e-04
Loss = 7.3892e-04, PNorm = 37.7570, GNorm = 2.3437, lr_0 = 1.0200e-04
Loss = 9.0917e-04, PNorm = 37.7584, GNorm = 6.0304, lr_0 = 1.0200e-04
Loss = 8.0524e-04, PNorm = 37.7600, GNorm = 2.6478, lr_0 = 1.0200e-04
Loss = 1.0180e-03, PNorm = 37.7610, GNorm = 3.4474, lr_0 = 1.0200e-04
Loss = 8.3996e-04, PNorm = 37.7626, GNorm = 4.2674, lr_0 = 1.0200e-04
Validation rmse logD = 0.583007
Validation R2 logD = 0.764590
Validation rmse logP = 0.473344
Validation R2 logP = 0.934973
Epoch 54
Train function
Loss = 8.4363e-04, PNorm = 37.7648, GNorm = 1.7072, lr_0 = 1.0200e-04
Loss = 8.1323e-04, PNorm = 37.7667, GNorm = 3.4073, lr_0 = 1.0200e-04
Loss = 8.6904e-04, PNorm = 37.7688, GNorm = 1.5666, lr_0 = 1.0200e-04
Loss = 6.9807e-04, PNorm = 37.7705, GNorm = 1.0888, lr_0 = 1.0200e-04
Loss = 8.0048e-04, PNorm = 37.7722, GNorm = 2.7583, lr_0 = 1.0200e-04
Loss = 9.7995e-04, PNorm = 37.7740, GNorm = 1.6757, lr_0 = 1.0200e-04
Loss = 7.5494e-04, PNorm = 37.7745, GNorm = 1.1293, lr_0 = 1.0200e-04
Loss = 1.0191e-03, PNorm = 37.7753, GNorm = 4.9231, lr_0 = 1.0200e-04
Loss = 1.0101e-03, PNorm = 37.7764, GNorm = 4.5092, lr_0 = 1.0200e-04
Loss = 6.8220e-04, PNorm = 37.7781, GNorm = 1.4371, lr_0 = 1.0200e-04
Loss = 7.3929e-04, PNorm = 37.7804, GNorm = 1.8129, lr_0 = 1.0200e-04
Loss = 7.9561e-04, PNorm = 37.7828, GNorm = 2.9623, lr_0 = 1.0200e-04
Loss = 7.8690e-04, PNorm = 37.7853, GNorm = 2.6873, lr_0 = 1.0200e-04
Loss = 6.8806e-04, PNorm = 37.7873, GNorm = 1.3965, lr_0 = 1.0200e-04
Loss = 6.9348e-04, PNorm = 37.7892, GNorm = 1.4017, lr_0 = 1.0200e-04
Loss = 6.4527e-04, PNorm = 37.7906, GNorm = 1.3655, lr_0 = 1.0200e-04
Loss = 7.4997e-04, PNorm = 37.7923, GNorm = 1.6070, lr_0 = 1.0200e-04
Loss = 6.1284e-04, PNorm = 37.7935, GNorm = 1.9401, lr_0 = 1.0200e-04
Loss = 6.7818e-04, PNorm = 37.7951, GNorm = 1.0469, lr_0 = 1.0200e-04
Loss = 7.7573e-04, PNorm = 37.7967, GNorm = 1.7352, lr_0 = 1.0200e-04
Loss = 7.7920e-04, PNorm = 37.7975, GNorm = 2.4660, lr_0 = 1.0200e-04
Loss = 1.1691e-03, PNorm = 37.7994, GNorm = 2.2160, lr_0 = 1.0200e-04
Loss = 8.4032e-04, PNorm = 37.8018, GNorm = 1.6197, lr_0 = 1.0200e-04
Validation rmse logD = 0.602617
Validation R2 logD = 0.748487
Validation rmse logP = 0.477654
Validation R2 logP = 0.933783
Epoch 55
Train function
Loss = 8.7645e-04, PNorm = 37.8047, GNorm = 2.8713, lr_0 = 1.0200e-04
Loss = 6.7994e-04, PNorm = 37.8063, GNorm = 2.3191, lr_0 = 1.0200e-04
Loss = 7.3158e-04, PNorm = 37.8072, GNorm = 2.3375, lr_0 = 1.0200e-04
Loss = 9.3745e-04, PNorm = 37.8092, GNorm = 5.3060, lr_0 = 1.0200e-04
Loss = 7.1576e-04, PNorm = 37.8113, GNorm = 2.4465, lr_0 = 1.0200e-04
Loss = 8.8665e-04, PNorm = 37.8128, GNorm = 4.3786, lr_0 = 1.0200e-04
Loss = 7.8560e-04, PNorm = 37.8140, GNorm = 2.2599, lr_0 = 1.0200e-04
Loss = 9.1833e-04, PNorm = 37.8163, GNorm = 3.2913, lr_0 = 1.0200e-04
Loss = 5.8833e-04, PNorm = 37.8184, GNorm = 1.1973, lr_0 = 1.0200e-04
Loss = 6.9236e-04, PNorm = 37.8206, GNorm = 1.3071, lr_0 = 1.0200e-04
Loss = 7.4242e-04, PNorm = 37.8216, GNorm = 2.0994, lr_0 = 1.0200e-04
Loss = 7.9057e-04, PNorm = 37.8229, GNorm = 3.5941, lr_0 = 1.0200e-04
Loss = 9.6634e-04, PNorm = 37.8245, GNorm = 3.7872, lr_0 = 1.0200e-04
Loss = 6.7058e-04, PNorm = 37.8264, GNorm = 2.2206, lr_0 = 1.0200e-04
Loss = 6.7361e-04, PNorm = 37.8284, GNorm = 1.2100, lr_0 = 1.0200e-04
Loss = 7.4987e-04, PNorm = 37.8301, GNorm = 2.9284, lr_0 = 1.0200e-04
Loss = 7.1027e-04, PNorm = 37.8321, GNorm = 2.2545, lr_0 = 1.0200e-04
Loss = 7.0603e-04, PNorm = 37.8333, GNorm = 1.3092, lr_0 = 1.0200e-04
Loss = 6.4921e-04, PNorm = 37.8348, GNorm = 0.9577, lr_0 = 1.0200e-04
Loss = 6.6892e-04, PNorm = 37.8374, GNorm = 1.2566, lr_0 = 1.0200e-04
Loss = 7.7597e-04, PNorm = 37.8388, GNorm = 2.5098, lr_0 = 1.0200e-04
Loss = 7.0625e-04, PNorm = 37.8395, GNorm = 1.8036, lr_0 = 1.0200e-04
Validation rmse logD = 0.594852
Validation R2 logD = 0.754927
Validation rmse logP = 0.494972
Validation R2 logP = 0.928895
Epoch 56
Train function
Loss = 9.2396e-04, PNorm = 37.8410, GNorm = 1.3973, lr_0 = 1.0200e-04
Loss = 6.8065e-04, PNorm = 37.8430, GNorm = 1.7403, lr_0 = 1.0200e-04
Loss = 7.2279e-04, PNorm = 37.8441, GNorm = 2.0075, lr_0 = 1.0200e-04
Loss = 6.0697e-04, PNorm = 37.8453, GNorm = 1.3423, lr_0 = 1.0200e-04
Loss = 6.9028e-04, PNorm = 37.8459, GNorm = 4.2838, lr_0 = 1.0200e-04
Loss = 8.2029e-04, PNorm = 37.8469, GNorm = 4.2680, lr_0 = 1.0200e-04
Loss = 7.0699e-04, PNorm = 37.8497, GNorm = 0.9547, lr_0 = 1.0200e-04
Loss = 6.2411e-04, PNorm = 37.8519, GNorm = 4.2657, lr_0 = 1.0200e-04
Loss = 6.7783e-04, PNorm = 37.8536, GNorm = 2.7478, lr_0 = 1.0200e-04
Loss = 7.7735e-04, PNorm = 37.8555, GNorm = 2.8834, lr_0 = 1.0200e-04
Loss = 7.7049e-04, PNorm = 37.8564, GNorm = 3.8209, lr_0 = 1.0200e-04
Loss = 6.8850e-04, PNorm = 37.8574, GNorm = 1.1944, lr_0 = 1.0200e-04
Loss = 6.5877e-04, PNorm = 37.8578, GNorm = 1.4344, lr_0 = 1.0200e-04
Loss = 7.4853e-04, PNorm = 37.8602, GNorm = 4.1712, lr_0 = 1.0200e-04
Loss = 8.6324e-04, PNorm = 37.8621, GNorm = 2.8879, lr_0 = 1.0200e-04
Loss = 8.2990e-04, PNorm = 37.8639, GNorm = 1.9980, lr_0 = 1.0200e-04
Loss = 8.5079e-04, PNorm = 37.8644, GNorm = 2.6241, lr_0 = 1.0200e-04
Loss = 8.8772e-04, PNorm = 37.8657, GNorm = 3.6621, lr_0 = 1.0200e-04
Loss = 8.7751e-04, PNorm = 37.8681, GNorm = 1.2546, lr_0 = 1.0200e-04
Loss = 7.7663e-04, PNorm = 37.8699, GNorm = 2.8261, lr_0 = 1.0200e-04
Loss = 8.5328e-04, PNorm = 37.8724, GNorm = 1.5934, lr_0 = 1.0200e-04
Loss = 8.1624e-04, PNorm = 37.8735, GNorm = 1.6214, lr_0 = 1.0200e-04
Loss = 8.1993e-04, PNorm = 37.8759, GNorm = 0.9171, lr_0 = 1.0200e-04
Validation rmse logD = 0.585897
Validation R2 logD = 0.762250
Validation rmse logP = 0.472773
Validation R2 logP = 0.935130
Epoch 57
Train function
Loss = 7.4373e-04, PNorm = 37.8775, GNorm = 1.8626, lr_0 = 1.0200e-04
Loss = 1.0241e-03, PNorm = 37.8796, GNorm = 1.8080, lr_0 = 1.0200e-04
Loss = 7.0478e-04, PNorm = 37.8817, GNorm = 0.8973, lr_0 = 1.0200e-04
Loss = 6.9642e-04, PNorm = 37.8834, GNorm = 0.6980, lr_0 = 1.0200e-04
Loss = 6.6239e-04, PNorm = 37.8851, GNorm = 2.2345, lr_0 = 1.0200e-04
Loss = 7.6555e-04, PNorm = 37.8868, GNorm = 1.8878, lr_0 = 1.0200e-04
Loss = 8.9852e-04, PNorm = 37.8891, GNorm = 4.9571, lr_0 = 1.0200e-04
Loss = 7.5779e-04, PNorm = 37.8907, GNorm = 0.9109, lr_0 = 1.0200e-04
Loss = 8.5263e-04, PNorm = 37.8926, GNorm = 2.5731, lr_0 = 1.0200e-04
Loss = 7.1776e-04, PNorm = 37.8948, GNorm = 1.2562, lr_0 = 1.0200e-04
Loss = 7.7205e-04, PNorm = 37.8964, GNorm = 1.4968, lr_0 = 1.0200e-04
Loss = 7.7694e-04, PNorm = 37.8986, GNorm = 1.7230, lr_0 = 1.0200e-04
Loss = 7.8713e-04, PNorm = 37.9000, GNorm = 3.6627, lr_0 = 1.0200e-04
Loss = 6.2656e-04, PNorm = 37.9010, GNorm = 2.5348, lr_0 = 1.0200e-04
Loss = 8.6657e-04, PNorm = 37.9018, GNorm = 1.1822, lr_0 = 1.0200e-04
Loss = 6.3265e-04, PNorm = 37.9038, GNorm = 2.3505, lr_0 = 1.0200e-04
Loss = 5.8519e-04, PNorm = 37.9050, GNorm = 1.2793, lr_0 = 1.0200e-04
Loss = 8.1496e-04, PNorm = 37.9060, GNorm = 1.9083, lr_0 = 1.0200e-04
Loss = 7.4254e-04, PNorm = 37.9075, GNorm = 3.9805, lr_0 = 1.0200e-04
Loss = 6.5894e-04, PNorm = 37.9090, GNorm = 1.6857, lr_0 = 1.0200e-04
Loss = 6.1896e-04, PNorm = 37.9101, GNorm = 1.3128, lr_0 = 1.0200e-04
Loss = 7.0700e-04, PNorm = 37.9113, GNorm = 3.5181, lr_0 = 1.0200e-04
Validation rmse logD = 0.594989
Validation R2 logD = 0.754814
Validation rmse logP = 0.487185
Validation R2 logP = 0.931114
Epoch 58
Train function
Loss = 7.8840e-04, PNorm = 37.9132, GNorm = 3.4268, lr_0 = 1.0200e-04
Loss = 6.3515e-04, PNorm = 37.9145, GNorm = 1.4232, lr_0 = 1.0200e-04
Loss = 5.8322e-04, PNorm = 37.9162, GNorm = 1.5614, lr_0 = 1.0200e-04
Loss = 6.5408e-04, PNorm = 37.9176, GNorm = 1.6652, lr_0 = 1.0200e-04
Loss = 7.1907e-04, PNorm = 37.9191, GNorm = 4.1364, lr_0 = 1.0200e-04
Loss = 7.4637e-04, PNorm = 37.9204, GNorm = 1.4439, lr_0 = 1.0200e-04
Loss = 6.0259e-04, PNorm = 37.9218, GNorm = 1.5296, lr_0 = 1.0200e-04
Loss = 7.1187e-04, PNorm = 37.9236, GNorm = 3.9094, lr_0 = 1.0200e-04
Loss = 7.3675e-04, PNorm = 37.9256, GNorm = 1.3413, lr_0 = 1.0200e-04
Loss = 7.3907e-04, PNorm = 37.9281, GNorm = 2.1183, lr_0 = 1.0200e-04
Loss = 6.3512e-04, PNorm = 37.9289, GNorm = 1.6511, lr_0 = 1.0200e-04
Loss = 8.0566e-04, PNorm = 37.9305, GNorm = 3.2719, lr_0 = 1.0200e-04
Loss = 8.2216e-04, PNorm = 37.9323, GNorm = 2.9009, lr_0 = 1.0200e-04
Loss = 6.8891e-04, PNorm = 37.9341, GNorm = 1.7293, lr_0 = 1.0200e-04
Loss = 8.6040e-04, PNorm = 37.9349, GNorm = 4.7869, lr_0 = 1.0200e-04
Loss = 7.6757e-04, PNorm = 37.9372, GNorm = 2.2391, lr_0 = 1.0200e-04
Loss = 7.1594e-04, PNorm = 37.9388, GNorm = 1.6115, lr_0 = 1.0200e-04
Loss = 5.6099e-04, PNorm = 37.9405, GNorm = 1.2512, lr_0 = 1.0200e-04
Loss = 8.1947e-04, PNorm = 37.9417, GNorm = 1.6368, lr_0 = 1.0200e-04
Loss = 8.2484e-04, PNorm = 37.9439, GNorm = 1.5973, lr_0 = 1.0200e-04
Loss = 7.0067e-04, PNorm = 37.9451, GNorm = 1.1639, lr_0 = 1.0200e-04
Loss = 8.3069e-04, PNorm = 37.9463, GNorm = 2.9808, lr_0 = 1.0200e-04
Loss = 7.7399e-04, PNorm = 37.9473, GNorm = 1.3434, lr_0 = 1.0200e-04
Validation rmse logD = 0.597735
Validation R2 logD = 0.752545
Validation rmse logP = 0.484973
Validation R2 logP = 0.931739
Epoch 59
Train function
Loss = 7.6223e-04, PNorm = 37.9488, GNorm = 2.3148, lr_0 = 1.0200e-04
Loss = 8.2715e-04, PNorm = 37.9506, GNorm = 1.2754, lr_0 = 1.0200e-04
Loss = 5.5401e-04, PNorm = 37.9527, GNorm = 1.6326, lr_0 = 1.0200e-04
Loss = 7.0826e-04, PNorm = 37.9540, GNorm = 3.4643, lr_0 = 1.0200e-04
Loss = 7.0487e-04, PNorm = 37.9547, GNorm = 3.0042, lr_0 = 1.0200e-04
Loss = 6.2681e-04, PNorm = 37.9568, GNorm = 1.4818, lr_0 = 1.0200e-04
Loss = 6.9137e-04, PNorm = 37.9583, GNorm = 1.8933, lr_0 = 1.0200e-04
Loss = 6.8736e-04, PNorm = 37.9600, GNorm = 0.9497, lr_0 = 1.0200e-04
Loss = 6.9000e-04, PNorm = 37.9610, GNorm = 1.0101, lr_0 = 1.0200e-04
Loss = 5.7333e-04, PNorm = 37.9624, GNorm = 0.8141, lr_0 = 1.0200e-04
Loss = 6.5090e-04, PNorm = 37.9646, GNorm = 2.0993, lr_0 = 1.0200e-04
Loss = 6.8714e-04, PNorm = 37.9660, GNorm = 2.4633, lr_0 = 1.0200e-04
Loss = 6.2622e-04, PNorm = 37.9676, GNorm = 1.9510, lr_0 = 1.0200e-04
Loss = 6.4289e-04, PNorm = 37.9694, GNorm = 2.7576, lr_0 = 1.0200e-04
Loss = 7.5595e-04, PNorm = 37.9709, GNorm = 1.8682, lr_0 = 1.0200e-04
Loss = 7.1905e-04, PNorm = 37.9721, GNorm = 1.6441, lr_0 = 1.0200e-04
Loss = 8.1986e-04, PNorm = 37.9738, GNorm = 1.1952, lr_0 = 1.0200e-04
Loss = 8.0207e-04, PNorm = 37.9756, GNorm = 2.7728, lr_0 = 1.0200e-04
Loss = 7.4001e-04, PNorm = 37.9776, GNorm = 2.5168, lr_0 = 1.0200e-04
Loss = 5.6423e-04, PNorm = 37.9791, GNorm = 0.9646, lr_0 = 1.0200e-04
Loss = 8.2549e-04, PNorm = 37.9806, GNorm = 2.5408, lr_0 = 1.0200e-04
Loss = 6.5354e-04, PNorm = 37.9831, GNorm = 1.3559, lr_0 = 1.0200e-04
Validation rmse logD = 0.634265
Validation R2 logD = 0.721375
Validation rmse logP = 0.501622
Validation R2 logP = 0.926971
Epoch 60
Train function
Loss = 8.2640e-04, PNorm = 37.9864, GNorm = 2.9020, lr_0 = 1.0200e-04
Loss = 5.4226e-04, PNorm = 37.9883, GNorm = 0.8053, lr_0 = 1.0200e-04
Loss = 7.1212e-04, PNorm = 37.9892, GNorm = 1.4776, lr_0 = 1.0200e-04
Loss = 7.8384e-04, PNorm = 37.9900, GNorm = 2.7774, lr_0 = 1.0200e-04
Loss = 5.8598e-04, PNorm = 37.9920, GNorm = 1.9419, lr_0 = 1.0200e-04
Loss = 5.9533e-04, PNorm = 37.9944, GNorm = 1.4629, lr_0 = 1.0200e-04
Loss = 6.0378e-04, PNorm = 37.9958, GNorm = 0.8204, lr_0 = 1.0200e-04
Loss = 7.3488e-04, PNorm = 37.9973, GNorm = 2.1654, lr_0 = 1.0200e-04
Loss = 6.9616e-04, PNorm = 37.9980, GNorm = 4.7515, lr_0 = 1.0200e-04
Loss = 7.2324e-04, PNorm = 37.9994, GNorm = 2.4540, lr_0 = 1.0200e-04
Loss = 6.9547e-04, PNorm = 38.0005, GNorm = 2.3582, lr_0 = 1.0200e-04
Loss = 8.3276e-04, PNorm = 38.0017, GNorm = 2.2957, lr_0 = 1.0200e-04
Loss = 9.6861e-04, PNorm = 38.0041, GNorm = 3.3381, lr_0 = 1.0200e-04
Loss = 8.0879e-04, PNorm = 38.0057, GNorm = 2.8976, lr_0 = 1.0200e-04
Loss = 7.3901e-04, PNorm = 38.0075, GNorm = 1.2361, lr_0 = 1.0200e-04
Loss = 6.6593e-04, PNorm = 38.0095, GNorm = 1.3243, lr_0 = 1.0200e-04
Loss = 5.8679e-04, PNorm = 38.0109, GNorm = 1.1779, lr_0 = 1.0200e-04
Loss = 7.0182e-04, PNorm = 38.0123, GNorm = 1.6295, lr_0 = 1.0200e-04
Loss = 7.7666e-04, PNorm = 38.0140, GNorm = 2.1180, lr_0 = 1.0200e-04
Loss = 6.0341e-04, PNorm = 38.0164, GNorm = 2.8559, lr_0 = 1.0200e-04
Loss = 9.0358e-04, PNorm = 38.0179, GNorm = 1.7534, lr_0 = 1.0200e-04
Loss = 6.9327e-04, PNorm = 38.0192, GNorm = 2.7258, lr_0 = 1.0200e-04
Loss = 6.8560e-04, PNorm = 38.0209, GNorm = 3.1715, lr_0 = 1.0200e-04
Validation rmse logD = 0.592342
Validation R2 logD = 0.756991
Validation rmse logP = 0.471170
Validation R2 logP = 0.935569
Epoch 61
Train function
Loss = 5.2873e-04, PNorm = 38.0226, GNorm = 2.5233, lr_0 = 1.0200e-04
Loss = 5.3836e-04, PNorm = 38.0241, GNorm = 2.8269, lr_0 = 1.0200e-04
Loss = 5.0400e-04, PNorm = 38.0259, GNorm = 1.3860, lr_0 = 1.0200e-04
Loss = 5.7985e-04, PNorm = 38.0271, GNorm = 3.2570, lr_0 = 1.0200e-04
Loss = 5.8105e-04, PNorm = 38.0289, GNorm = 1.6063, lr_0 = 1.0200e-04
Loss = 6.5950e-04, PNorm = 38.0299, GNorm = 2.2795, lr_0 = 1.0200e-04
Loss = 5.6984e-04, PNorm = 38.0317, GNorm = 1.3666, lr_0 = 1.0200e-04
Loss = 6.1521e-04, PNorm = 38.0335, GNorm = 1.4841, lr_0 = 1.0200e-04
Loss = 5.8438e-04, PNorm = 38.0350, GNorm = 1.3492, lr_0 = 1.0200e-04
Loss = 4.7382e-04, PNorm = 38.0356, GNorm = 1.2767, lr_0 = 1.0200e-04
Loss = 6.1330e-04, PNorm = 38.0363, GNorm = 1.6198, lr_0 = 1.0200e-04
Loss = 7.4517e-04, PNorm = 38.0376, GNorm = 2.2247, lr_0 = 1.0200e-04
Loss = 7.2850e-04, PNorm = 38.0409, GNorm = 1.3492, lr_0 = 1.0200e-04
Loss = 6.3020e-04, PNorm = 38.0417, GNorm = 3.4456, lr_0 = 1.0200e-04
Loss = 7.0851e-04, PNorm = 38.0426, GNorm = 1.9183, lr_0 = 1.0200e-04
Loss = 6.4244e-04, PNorm = 38.0437, GNorm = 1.9162, lr_0 = 1.0200e-04
Loss = 6.8765e-04, PNorm = 38.0451, GNorm = 4.2660, lr_0 = 1.0200e-04
Loss = 8.5432e-04, PNorm = 38.0471, GNorm = 2.9850, lr_0 = 1.0200e-04
Loss = 7.4589e-04, PNorm = 38.0491, GNorm = 1.2982, lr_0 = 1.0200e-04
Loss = 6.7527e-04, PNorm = 38.0507, GNorm = 1.2155, lr_0 = 1.0200e-04
Loss = 6.6745e-04, PNorm = 38.0520, GNorm = 1.6053, lr_0 = 1.0200e-04
Loss = 7.3156e-04, PNorm = 38.0544, GNorm = 2.0058, lr_0 = 1.0200e-04
Validation rmse logD = 0.666151
Validation R2 logD = 0.692657
Validation rmse logP = 0.537056
Validation R2 logP = 0.916289
Epoch 62
Train function
Loss = 1.0423e-03, PNorm = 38.0548, GNorm = 5.0592, lr_0 = 1.0200e-04
Loss = 6.3847e-04, PNorm = 38.0561, GNorm = 1.5323, lr_0 = 1.0200e-04
Loss = 5.1448e-04, PNorm = 38.0572, GNorm = 0.8955, lr_0 = 1.0200e-04
Loss = 7.0380e-04, PNorm = 38.0584, GNorm = 2.8109, lr_0 = 1.0200e-04
Loss = 6.8341e-04, PNorm = 38.0611, GNorm = 2.2235, lr_0 = 1.0200e-04
Loss = 6.7174e-04, PNorm = 38.0632, GNorm = 1.8641, lr_0 = 1.0200e-04
Loss = 6.6067e-04, PNorm = 38.0657, GNorm = 2.0285, lr_0 = 1.0200e-04
Loss = 5.9548e-04, PNorm = 38.0676, GNorm = 2.3273, lr_0 = 1.0200e-04
Loss = 6.4267e-04, PNorm = 38.0681, GNorm = 1.2445, lr_0 = 1.0200e-04
Loss = 6.2087e-04, PNorm = 38.0700, GNorm = 1.0811, lr_0 = 1.0200e-04
Loss = 5.5565e-04, PNorm = 38.0714, GNorm = 2.2870, lr_0 = 1.0200e-04
Loss = 6.7557e-04, PNorm = 38.0729, GNorm = 3.9036, lr_0 = 1.0200e-04
Loss = 6.2249e-04, PNorm = 38.0745, GNorm = 1.4103, lr_0 = 1.0200e-04
Loss = 6.1145e-04, PNorm = 38.0756, GNorm = 1.1500, lr_0 = 1.0200e-04
Loss = 5.2718e-04, PNorm = 38.0767, GNorm = 1.0579, lr_0 = 1.0200e-04
Loss = 6.4193e-04, PNorm = 38.0781, GNorm = 1.9283, lr_0 = 1.0200e-04
Loss = 5.6808e-04, PNorm = 38.0796, GNorm = 1.1048, lr_0 = 1.0200e-04
Loss = 6.3097e-04, PNorm = 38.0811, GNorm = 2.7397, lr_0 = 1.0200e-04
Loss = 7.6764e-04, PNorm = 38.0832, GNorm = 4.6705, lr_0 = 1.0200e-04
Loss = 5.6104e-04, PNorm = 38.0848, GNorm = 2.0488, lr_0 = 1.0200e-04
Loss = 6.0017e-04, PNorm = 38.0863, GNorm = 2.1641, lr_0 = 1.0200e-04
Loss = 6.7340e-04, PNorm = 38.0875, GNorm = 2.0171, lr_0 = 1.0200e-04
Loss = 6.4458e-04, PNorm = 38.0887, GNorm = 1.2520, lr_0 = 1.0200e-04
Validation rmse logD = 0.597155
Validation R2 logD = 0.753025
Validation rmse logP = 0.476369
Validation R2 logP = 0.934139
Epoch 63
Train function
Loss = 4.9716e-04, PNorm = 38.0900, GNorm = 2.4150, lr_0 = 1.0200e-04
Loss = 5.5828e-04, PNorm = 38.0906, GNorm = 1.6401, lr_0 = 1.0200e-04
Loss = 6.1978e-04, PNorm = 38.0915, GNorm = 0.9220, lr_0 = 1.0200e-04
Loss = 6.5482e-04, PNorm = 38.0925, GNorm = 2.5086, lr_0 = 1.0200e-04
Loss = 6.6288e-04, PNorm = 38.0935, GNorm = 3.8164, lr_0 = 1.0200e-04
Loss = 7.5404e-04, PNorm = 38.0943, GNorm = 2.1023, lr_0 = 1.0200e-04
Loss = 6.1735e-04, PNorm = 38.0958, GNorm = 3.2668, lr_0 = 1.0200e-04
Loss = 6.6147e-04, PNorm = 38.0987, GNorm = 1.1636, lr_0 = 1.0200e-04
Loss = 7.6036e-04, PNorm = 38.1005, GNorm = 1.1491, lr_0 = 1.0200e-04
Loss = 6.0669e-04, PNorm = 38.1021, GNorm = 3.3120, lr_0 = 1.0200e-04
Loss = 6.3555e-04, PNorm = 38.1042, GNorm = 1.1253, lr_0 = 1.0200e-04
Loss = 6.7937e-04, PNorm = 38.1054, GNorm = 1.4966, lr_0 = 1.0200e-04
Loss = 6.2213e-04, PNorm = 38.1068, GNorm = 2.9567, lr_0 = 1.0200e-04
Loss = 7.6298e-04, PNorm = 38.1084, GNorm = 1.6124, lr_0 = 1.0200e-04
Loss = 6.6155e-04, PNorm = 38.1104, GNorm = 2.8180, lr_0 = 1.0200e-04
Loss = 7.3266e-04, PNorm = 38.1118, GNorm = 1.2611, lr_0 = 1.0200e-04
Loss = 7.9704e-04, PNorm = 38.1142, GNorm = 1.2268, lr_0 = 1.0200e-04
Loss = 8.5714e-04, PNorm = 38.1161, GNorm = 3.4272, lr_0 = 1.0200e-04
Loss = 6.8052e-04, PNorm = 38.1165, GNorm = 1.7111, lr_0 = 1.0200e-04
Loss = 8.3708e-04, PNorm = 38.1177, GNorm = 4.3136, lr_0 = 1.0200e-04
Loss = 8.1980e-04, PNorm = 38.1200, GNorm = 3.3561, lr_0 = 1.0200e-04
Loss = 8.3040e-04, PNorm = 38.1223, GNorm = 2.0441, lr_0 = 1.0200e-04
Loss = 8.4436e-04, PNorm = 38.1243, GNorm = 1.5720, lr_0 = 1.0200e-04
Loss = 1.1687e-03, PNorm = 38.1243, GNorm = 1.7366, lr_0 = 1.0200e-04
Validation rmse logD = 0.711624
Validation R2 logD = 0.649265
Validation rmse logP = 0.501578
Validation R2 logP = 0.926984
Epoch 64
Train function
Loss = 8.9313e-04, PNorm = 38.1269, GNorm = 3.1246, lr_0 = 1.0200e-04
Loss = 6.3243e-04, PNorm = 38.1290, GNorm = 1.6674, lr_0 = 1.0200e-04
Loss = 7.9356e-04, PNorm = 38.1301, GNorm = 2.1473, lr_0 = 1.0200e-04
Loss = 8.7921e-04, PNorm = 38.1316, GNorm = 2.1304, lr_0 = 1.0200e-04
Loss = 6.6971e-04, PNorm = 38.1336, GNorm = 0.9646, lr_0 = 1.0200e-04
Loss = 7.6040e-04, PNorm = 38.1351, GNorm = 3.7949, lr_0 = 1.0200e-04
Loss = 8.2950e-04, PNorm = 38.1371, GNorm = 0.9297, lr_0 = 1.0200e-04
Loss = 5.8818e-04, PNorm = 38.1395, GNorm = 2.6562, lr_0 = 1.0200e-04
Loss = 6.8801e-04, PNorm = 38.1414, GNorm = 1.0479, lr_0 = 1.0200e-04
Loss = 6.4481e-04, PNorm = 38.1431, GNorm = 2.2998, lr_0 = 1.0200e-04
Loss = 6.0749e-04, PNorm = 38.1456, GNorm = 1.7610, lr_0 = 1.0200e-04
Loss = 5.3039e-04, PNorm = 38.1472, GNorm = 1.5719, lr_0 = 1.0200e-04
Loss = 6.0110e-04, PNorm = 38.1484, GNorm = 1.7661, lr_0 = 1.0200e-04
Loss = 4.9378e-04, PNorm = 38.1494, GNorm = 2.0410, lr_0 = 1.0200e-04
Loss = 5.6570e-04, PNorm = 38.1504, GNorm = 0.8198, lr_0 = 1.0200e-04
Loss = 6.0885e-04, PNorm = 38.1518, GNorm = 1.2935, lr_0 = 1.0200e-04
Loss = 6.0264e-04, PNorm = 38.1538, GNorm = 1.8496, lr_0 = 1.0200e-04
Loss = 6.0601e-04, PNorm = 38.1546, GNorm = 1.5365, lr_0 = 1.0200e-04
Loss = 6.0451e-04, PNorm = 38.1556, GNorm = 1.1643, lr_0 = 1.0200e-04
Loss = 6.4044e-04, PNorm = 38.1569, GNorm = 2.2598, lr_0 = 1.0200e-04
Loss = 5.3191e-04, PNorm = 38.1586, GNorm = 0.9156, lr_0 = 1.0200e-04
Loss = 5.9501e-04, PNorm = 38.1605, GNorm = 1.0264, lr_0 = 1.0200e-04
Validation rmse logD = 0.594419
Validation R2 logD = 0.755283
Validation rmse logP = 0.468703
Validation R2 logP = 0.936242
Epoch 65
Train function
Loss = 5.7481e-04, PNorm = 38.1612, GNorm = 1.6040, lr_0 = 1.0200e-04
Loss = 5.0570e-04, PNorm = 38.1618, GNorm = 1.6619, lr_0 = 1.0200e-04
Loss = 5.4051e-04, PNorm = 38.1633, GNorm = 1.2021, lr_0 = 1.0200e-04
Loss = 6.0543e-04, PNorm = 38.1646, GNorm = 5.0319, lr_0 = 1.0200e-04
Loss = 8.1212e-04, PNorm = 38.1665, GNorm = 1.8954, lr_0 = 1.0200e-04
Loss = 6.5545e-04, PNorm = 38.1690, GNorm = 1.1583, lr_0 = 1.0200e-04
Loss = 6.4020e-04, PNorm = 38.1712, GNorm = 2.4228, lr_0 = 1.0200e-04
Loss = 6.3144e-04, PNorm = 38.1725, GNorm = 2.2156, lr_0 = 1.0200e-04
Loss = 5.3833e-04, PNorm = 38.1737, GNorm = 1.0899, lr_0 = 1.0200e-04
Loss = 5.1331e-04, PNorm = 38.1745, GNorm = 1.9391, lr_0 = 1.0200e-04
Loss = 5.9426e-04, PNorm = 38.1749, GNorm = 1.2178, lr_0 = 1.0200e-04
Loss = 4.8062e-04, PNorm = 38.1755, GNorm = 1.2657, lr_0 = 1.0200e-04
Loss = 5.9419e-04, PNorm = 38.1757, GNorm = 1.7921, lr_0 = 1.0200e-04
Loss = 6.5056e-04, PNorm = 38.1775, GNorm = 1.4244, lr_0 = 1.0200e-04
Loss = 6.4662e-04, PNorm = 38.1787, GNorm = 2.9833, lr_0 = 1.0200e-04
Loss = 9.0150e-04, PNorm = 38.1801, GNorm = 7.8042, lr_0 = 1.0200e-04
Loss = 7.3568e-04, PNorm = 38.1822, GNorm = 2.4969, lr_0 = 1.0200e-04
Loss = 9.2487e-04, PNorm = 38.1835, GNorm = 2.9755, lr_0 = 1.0200e-04
Loss = 8.5043e-04, PNorm = 38.1849, GNorm = 2.2697, lr_0 = 1.0200e-04
Loss = 7.7286e-04, PNorm = 38.1869, GNorm = 1.7781, lr_0 = 1.0200e-04
Loss = 5.4300e-04, PNorm = 38.1896, GNorm = 1.5186, lr_0 = 1.0200e-04
Loss = 5.7928e-04, PNorm = 38.1915, GNorm = 0.7695, lr_0 = 1.0200e-04
Loss = 6.6892e-04, PNorm = 38.1930, GNorm = 2.3609, lr_0 = 1.0200e-04
Validation rmse logD = 0.594215
Validation R2 logD = 0.755451
Validation rmse logP = 0.471622
Validation R2 logP = 0.935445
Epoch 66
Train function
Loss = 5.7033e-04, PNorm = 38.1946, GNorm = 1.1861, lr_0 = 1.0200e-04
Loss = 4.8335e-04, PNorm = 38.1969, GNorm = 1.1548, lr_0 = 1.0200e-04
Loss = 5.0667e-04, PNorm = 38.1985, GNorm = 1.3339, lr_0 = 1.0200e-04
Loss = 5.3723e-04, PNorm = 38.1994, GNorm = 1.2978, lr_0 = 1.0200e-04
Loss = 6.9238e-04, PNorm = 38.2016, GNorm = 2.3620, lr_0 = 1.0200e-04
Loss = 5.5492e-04, PNorm = 38.2030, GNorm = 2.4675, lr_0 = 1.0200e-04
Loss = 4.9079e-04, PNorm = 38.2043, GNorm = 0.7944, lr_0 = 1.0200e-04
Loss = 5.4664e-04, PNorm = 38.2056, GNorm = 1.6693, lr_0 = 1.0200e-04
Loss = 5.6295e-04, PNorm = 38.2065, GNorm = 1.3311, lr_0 = 1.0200e-04
Loss = 5.9930e-04, PNorm = 38.2078, GNorm = 1.4128, lr_0 = 1.0200e-04
Loss = 5.0040e-04, PNorm = 38.2095, GNorm = 1.1160, lr_0 = 1.0200e-04
Loss = 5.1163e-04, PNorm = 38.2110, GNorm = 1.8976, lr_0 = 1.0200e-04
Loss = 5.7198e-04, PNorm = 38.2127, GNorm = 1.8801, lr_0 = 1.0200e-04
Loss = 5.4315e-04, PNorm = 38.2146, GNorm = 0.9675, lr_0 = 1.0200e-04
Loss = 5.9061e-04, PNorm = 38.2169, GNorm = 1.0752, lr_0 = 1.0200e-04
Loss = 5.5543e-04, PNorm = 38.2188, GNorm = 1.3832, lr_0 = 1.0200e-04
Loss = 6.6370e-04, PNorm = 38.2202, GNorm = 3.2945, lr_0 = 1.0200e-04
Loss = 5.7281e-04, PNorm = 38.2220, GNorm = 1.5614, lr_0 = 1.0200e-04
Loss = 6.4062e-04, PNorm = 38.2235, GNorm = 3.2850, lr_0 = 1.0200e-04
Loss = 6.5510e-04, PNorm = 38.2249, GNorm = 0.8857, lr_0 = 1.0200e-04
Loss = 7.4997e-04, PNorm = 38.2264, GNorm = 2.5575, lr_0 = 1.0200e-04
Loss = 7.1803e-04, PNorm = 38.2271, GNorm = 2.0145, lr_0 = 1.0200e-04
Validation rmse logD = 0.608446
Validation R2 logD = 0.743598
Validation rmse logP = 0.472749
Validation R2 logP = 0.935136
Epoch 67
Train function
Loss = 4.8058e-04, PNorm = 38.2280, GNorm = 2.1386, lr_0 = 1.0200e-04
Loss = 5.8995e-04, PNorm = 38.2294, GNorm = 2.0619, lr_0 = 1.0200e-04
Loss = 5.7004e-04, PNorm = 38.2306, GNorm = 1.8879, lr_0 = 1.0200e-04
Loss = 4.6666e-04, PNorm = 38.2324, GNorm = 0.7430, lr_0 = 1.0200e-04
Loss = 5.1574e-04, PNorm = 38.2345, GNorm = 1.2436, lr_0 = 1.0200e-04
Loss = 5.9642e-04, PNorm = 38.2359, GNorm = 2.1226, lr_0 = 1.0200e-04
Loss = 5.8056e-04, PNorm = 38.2378, GNorm = 1.7439, lr_0 = 1.0200e-04
Loss = 5.6866e-04, PNorm = 38.2391, GNorm = 1.1716, lr_0 = 1.0200e-04
Loss = 6.1728e-04, PNorm = 38.2409, GNorm = 1.5694, lr_0 = 1.0200e-04
Loss = 5.2824e-04, PNorm = 38.2424, GNorm = 1.6554, lr_0 = 1.0200e-04
Loss = 7.4523e-04, PNorm = 38.2435, GNorm = 1.8183, lr_0 = 1.0200e-04
Loss = 6.7651e-04, PNorm = 38.2450, GNorm = 1.5856, lr_0 = 1.0200e-04
Loss = 4.7884e-04, PNorm = 38.2472, GNorm = 0.6306, lr_0 = 1.0200e-04
Loss = 5.5237e-04, PNorm = 38.2487, GNorm = 3.4530, lr_0 = 1.0200e-04
Loss = 6.0833e-04, PNorm = 38.2491, GNorm = 1.1002, lr_0 = 1.0200e-04
Loss = 4.9521e-04, PNorm = 38.2505, GNorm = 0.9235, lr_0 = 1.0200e-04
Loss = 4.8114e-04, PNorm = 38.2517, GNorm = 1.9062, lr_0 = 1.0200e-04
Loss = 6.7075e-04, PNorm = 38.2519, GNorm = 2.5446, lr_0 = 1.0200e-04
Loss = 6.2004e-04, PNorm = 38.2536, GNorm = 1.3448, lr_0 = 1.0200e-04
Loss = 6.1173e-04, PNorm = 38.2548, GNorm = 2.2248, lr_0 = 1.0200e-04
Loss = 5.1986e-04, PNorm = 38.2556, GNorm = 1.6009, lr_0 = 1.0200e-04
Loss = 4.9734e-04, PNorm = 38.2570, GNorm = 1.1438, lr_0 = 1.0200e-04
Loss = 5.8689e-04, PNorm = 38.2582, GNorm = 1.1771, lr_0 = 1.0200e-04
Validation rmse logD = 0.595826
Validation R2 logD = 0.754124
Validation rmse logP = 0.470102
Validation R2 logP = 0.935861
Epoch 68
Train function
Loss = 4.7786e-04, PNorm = 38.2589, GNorm = 1.5436, lr_0 = 1.0200e-04
Loss = 5.6747e-04, PNorm = 38.2603, GNorm = 3.4570, lr_0 = 1.0200e-04
Loss = 7.1139e-04, PNorm = 38.2620, GNorm = 2.7852, lr_0 = 1.0200e-04
Loss = 5.1916e-04, PNorm = 38.2639, GNorm = 2.3623, lr_0 = 1.0200e-04
Loss = 5.1710e-04, PNorm = 38.2654, GNorm = 2.7091, lr_0 = 1.0200e-04
Loss = 4.4264e-04, PNorm = 38.2671, GNorm = 0.7188, lr_0 = 1.0200e-04
Loss = 7.8343e-04, PNorm = 38.2686, GNorm = 1.4771, lr_0 = 1.0200e-04
Loss = 6.4509e-04, PNorm = 38.2697, GNorm = 3.9959, lr_0 = 1.0200e-04
Loss = 4.8269e-04, PNorm = 38.2710, GNorm = 1.7836, lr_0 = 1.0200e-04
Loss = 5.2569e-04, PNorm = 38.2718, GNorm = 3.4401, lr_0 = 1.0200e-04
Loss = 4.7695e-04, PNorm = 38.2726, GNorm = 1.3574, lr_0 = 1.0200e-04
Loss = 5.8307e-04, PNorm = 38.2744, GNorm = 2.7246, lr_0 = 1.0200e-04
Loss = 5.1948e-04, PNorm = 38.2763, GNorm = 1.5693, lr_0 = 1.0200e-04
Loss = 4.7993e-04, PNorm = 38.2772, GNorm = 1.7048, lr_0 = 1.0200e-04
Loss = 5.0134e-04, PNorm = 38.2789, GNorm = 1.6904, lr_0 = 1.0200e-04
Loss = 5.0814e-04, PNorm = 38.2800, GNorm = 1.6449, lr_0 = 1.0200e-04
Loss = 5.3060e-04, PNorm = 38.2820, GNorm = 1.0299, lr_0 = 1.0200e-04
Loss = 6.7930e-04, PNorm = 38.2837, GNorm = 1.6056, lr_0 = 1.0200e-04
Loss = 5.8528e-04, PNorm = 38.2844, GNorm = 2.9929, lr_0 = 1.0200e-04
Loss = 7.6335e-04, PNorm = 38.2861, GNorm = 3.3617, lr_0 = 1.0200e-04
Loss = 8.7312e-04, PNorm = 38.2875, GNorm = 3.3216, lr_0 = 1.0200e-04
Loss = 8.0887e-04, PNorm = 38.2891, GNorm = 1.7277, lr_0 = 1.0200e-04
Validation rmse logD = 0.640085
Validation R2 logD = 0.716239
Validation rmse logP = 0.482916
Validation R2 logP = 0.932316
Epoch 69
Train function
Loss = 9.1199e-04, PNorm = 38.2897, GNorm = 1.8725, lr_0 = 1.0200e-04
Loss = 7.0111e-04, PNorm = 38.2905, GNorm = 1.8287, lr_0 = 1.0200e-04
Loss = 5.5739e-04, PNorm = 38.2924, GNorm = 3.3865, lr_0 = 1.0200e-04
Loss = 6.7422e-04, PNorm = 38.2945, GNorm = 1.6237, lr_0 = 1.0200e-04
Loss = 4.7059e-04, PNorm = 38.2961, GNorm = 0.6788, lr_0 = 1.0200e-04
Loss = 5.3505e-04, PNorm = 38.2976, GNorm = 1.0872, lr_0 = 1.0200e-04
Loss = 5.3733e-04, PNorm = 38.2996, GNorm = 0.8593, lr_0 = 1.0200e-04
Loss = 5.6241e-04, PNorm = 38.3005, GNorm = 2.2036, lr_0 = 1.0200e-04
Loss = 5.4009e-04, PNorm = 38.3027, GNorm = 1.5981, lr_0 = 1.0200e-04
Loss = 5.7814e-04, PNorm = 38.3046, GNorm = 2.5446, lr_0 = 1.0200e-04
Loss = 5.0770e-04, PNorm = 38.3057, GNorm = 1.6373, lr_0 = 1.0200e-04
Loss = 5.3107e-04, PNorm = 38.3073, GNorm = 0.8398, lr_0 = 1.0200e-04
Loss = 5.1123e-04, PNorm = 38.3092, GNorm = 0.9061, lr_0 = 1.0200e-04
Loss = 5.6997e-04, PNorm = 38.3100, GNorm = 0.8359, lr_0 = 1.0200e-04
Loss = 5.7197e-04, PNorm = 38.3106, GNorm = 1.1131, lr_0 = 1.0200e-04
Loss = 5.1125e-04, PNorm = 38.3115, GNorm = 1.6217, lr_0 = 1.0200e-04
Loss = 4.5910e-04, PNorm = 38.3129, GNorm = 1.0983, lr_0 = 1.0200e-04
Loss = 4.5070e-04, PNorm = 38.3140, GNorm = 2.3855, lr_0 = 1.0200e-04
Loss = 5.8162e-04, PNorm = 38.3156, GNorm = 1.8041, lr_0 = 1.0200e-04
Loss = 6.0309e-04, PNorm = 38.3178, GNorm = 1.2649, lr_0 = 1.0200e-04
Loss = 5.6508e-04, PNorm = 38.3196, GNorm = 2.2931, lr_0 = 1.0200e-04
Loss = 4.6891e-04, PNorm = 38.3209, GNorm = 1.4894, lr_0 = 1.0200e-04
Loss = 6.8222e-04, PNorm = 38.3220, GNorm = 2.1684, lr_0 = 1.0200e-04
Validation rmse logD = 0.608410
Validation R2 logD = 0.743628
Validation rmse logP = 0.473764
Validation R2 logP = 0.934857
Epoch 70
Train function
Loss = 5.8380e-04, PNorm = 38.3235, GNorm = 2.2563, lr_0 = 1.0200e-04
Loss = 5.4827e-04, PNorm = 38.3256, GNorm = 3.0317, lr_0 = 1.0200e-04
Loss = 5.6370e-04, PNorm = 38.3264, GNorm = 1.1284, lr_0 = 1.0200e-04
Loss = 5.1642e-04, PNorm = 38.3283, GNorm = 2.2981, lr_0 = 1.0200e-04
Loss = 4.7978e-04, PNorm = 38.3310, GNorm = 1.4737, lr_0 = 1.0200e-04
Loss = 5.8788e-04, PNorm = 38.3326, GNorm = 2.7911, lr_0 = 1.0200e-04
Loss = 5.8763e-04, PNorm = 38.3343, GNorm = 3.9643, lr_0 = 1.0200e-04
Loss = 6.2518e-04, PNorm = 38.3356, GNorm = 1.0887, lr_0 = 1.0200e-04
Loss = 5.8608e-04, PNorm = 38.3371, GNorm = 1.0150, lr_0 = 1.0200e-04
Loss = 4.5365e-04, PNorm = 38.3392, GNorm = 1.9966, lr_0 = 1.0200e-04
Loss = 6.1919e-04, PNorm = 38.3412, GNorm = 2.0665, lr_0 = 1.0200e-04
Loss = 5.1483e-04, PNorm = 38.3423, GNorm = 2.2529, lr_0 = 1.0200e-04
Loss = 4.5954e-04, PNorm = 38.3435, GNorm = 1.8855, lr_0 = 1.0200e-04
Loss = 5.3536e-04, PNorm = 38.3446, GNorm = 1.2493, lr_0 = 1.0200e-04
Loss = 5.4008e-04, PNorm = 38.3466, GNorm = 3.6248, lr_0 = 1.0200e-04
Loss = 7.5528e-04, PNorm = 38.3472, GNorm = 1.1588, lr_0 = 1.0200e-04
Loss = 8.1059e-04, PNorm = 38.3491, GNorm = 2.0111, lr_0 = 1.0200e-04
Loss = 7.5371e-04, PNorm = 38.3513, GNorm = 3.3872, lr_0 = 1.0200e-04
Loss = 7.1050e-04, PNorm = 38.3529, GNorm = 2.0573, lr_0 = 1.0200e-04
Loss = 5.2481e-04, PNorm = 38.3543, GNorm = 2.0774, lr_0 = 1.0200e-04
Loss = 6.3337e-04, PNorm = 38.3548, GNorm = 1.8405, lr_0 = 1.0200e-04
Loss = 7.8233e-04, PNorm = 38.3561, GNorm = 2.5810, lr_0 = 1.0200e-04
Validation rmse logD = 0.613518
Validation R2 logD = 0.739305
Validation rmse logP = 0.483942
Validation R2 logP = 0.932029
Epoch 71
Train function
Loss = 6.5937e-04, PNorm = 38.3579, GNorm = 2.9374, lr_0 = 1.0200e-04
Loss = 6.7085e-04, PNorm = 38.3594, GNorm = 2.9632, lr_0 = 1.0200e-04
Loss = 5.5831e-04, PNorm = 38.3610, GNorm = 0.8268, lr_0 = 1.0200e-04
Loss = 5.2925e-04, PNorm = 38.3626, GNorm = 1.5661, lr_0 = 1.0200e-04
Loss = 5.2727e-04, PNorm = 38.3642, GNorm = 1.0328, lr_0 = 1.0200e-04
Loss = 5.5905e-04, PNorm = 38.3657, GNorm = 2.0378, lr_0 = 1.0200e-04
Loss = 5.4188e-04, PNorm = 38.3671, GNorm = 1.6028, lr_0 = 1.0200e-04
Loss = 4.5704e-04, PNorm = 38.3686, GNorm = 2.0227, lr_0 = 1.0200e-04
Loss = 4.0761e-04, PNorm = 38.3694, GNorm = 0.9466, lr_0 = 1.0200e-04
Loss = 5.1236e-04, PNorm = 38.3703, GNorm = 1.1738, lr_0 = 1.0200e-04
Loss = 5.7321e-04, PNorm = 38.3713, GNorm = 2.6176, lr_0 = 1.0200e-04
Loss = 5.7334e-04, PNorm = 38.3722, GNorm = 1.1418, lr_0 = 1.0200e-04
Loss = 5.0707e-04, PNorm = 38.3736, GNorm = 1.0843, lr_0 = 1.0200e-04
Loss = 4.8798e-04, PNorm = 38.3753, GNorm = 0.8004, lr_0 = 1.0200e-04
Loss = 5.6351e-04, PNorm = 38.3770, GNorm = 1.0264, lr_0 = 1.0200e-04
Loss = 4.8594e-04, PNorm = 38.3787, GNorm = 1.7438, lr_0 = 1.0200e-04
Loss = 4.9984e-04, PNorm = 38.3807, GNorm = 1.5140, lr_0 = 1.0200e-04
Loss = 5.3278e-04, PNorm = 38.3823, GNorm = 2.2121, lr_0 = 1.0200e-04
Loss = 6.4486e-04, PNorm = 38.3835, GNorm = 1.1248, lr_0 = 1.0200e-04
Loss = 4.7831e-04, PNorm = 38.3852, GNorm = 1.9332, lr_0 = 1.0200e-04
Loss = 5.1651e-04, PNorm = 38.3873, GNorm = 1.7984, lr_0 = 1.0200e-04
Loss = 5.4630e-04, PNorm = 38.3884, GNorm = 1.6658, lr_0 = 1.0200e-04
Loss = 5.8125e-04, PNorm = 38.3897, GNorm = 1.7564, lr_0 = 1.0200e-04
Validation rmse logD = 0.601437
Validation R2 logD = 0.749471
Validation rmse logP = 0.475750
Validation R2 logP = 0.934310
Epoch 72
Train function
Loss = 5.4503e-04, PNorm = 38.3915, GNorm = 0.8230, lr_0 = 1.0200e-04
Loss = 4.7711e-04, PNorm = 38.3935, GNorm = 0.9627, lr_0 = 1.0200e-04
Loss = 4.9968e-04, PNorm = 38.3949, GNorm = 1.6869, lr_0 = 1.0200e-04
Loss = 5.1174e-04, PNorm = 38.3961, GNorm = 1.9071, lr_0 = 1.0200e-04
Loss = 7.2673e-04, PNorm = 38.3971, GNorm = 1.1610, lr_0 = 1.0200e-04
Loss = 7.1222e-04, PNorm = 38.3983, GNorm = 3.9930, lr_0 = 1.0200e-04
Loss = 6.5624e-04, PNorm = 38.3999, GNorm = 2.3246, lr_0 = 1.0200e-04
Loss = 5.4040e-04, PNorm = 38.4019, GNorm = 1.7999, lr_0 = 1.0200e-04
Loss = 5.9656e-04, PNorm = 38.4039, GNorm = 4.0018, lr_0 = 1.0200e-04
Loss = 7.2482e-04, PNorm = 38.4064, GNorm = 2.1545, lr_0 = 1.0200e-04
Loss = 5.5085e-04, PNorm = 38.4077, GNorm = 2.0693, lr_0 = 1.0200e-04
Loss = 5.4659e-04, PNorm = 38.4095, GNorm = 1.3603, lr_0 = 1.0200e-04
Loss = 4.5260e-04, PNorm = 38.4112, GNorm = 1.3419, lr_0 = 1.0200e-04
Loss = 5.5940e-04, PNorm = 38.4122, GNorm = 1.3478, lr_0 = 1.0200e-04
Loss = 4.5762e-04, PNorm = 38.4137, GNorm = 2.3964, lr_0 = 1.0200e-04
Loss = 4.6630e-04, PNorm = 38.4150, GNorm = 1.4717, lr_0 = 1.0200e-04
Loss = 4.9256e-04, PNorm = 38.4160, GNorm = 2.1463, lr_0 = 1.0200e-04
Loss = 5.0622e-04, PNorm = 38.4172, GNorm = 1.5770, lr_0 = 1.0200e-04
Loss = 5.6509e-04, PNorm = 38.4191, GNorm = 1.4989, lr_0 = 1.0200e-04
Loss = 5.0851e-04, PNorm = 38.4205, GNorm = 1.7548, lr_0 = 1.0200e-04
Loss = 6.8833e-04, PNorm = 38.4219, GNorm = 1.3546, lr_0 = 1.0200e-04
Loss = 6.9188e-04, PNorm = 38.4224, GNorm = 2.2626, lr_0 = 1.0200e-04
Loss = 6.4307e-04, PNorm = 38.4227, GNorm = 1.2602, lr_0 = 1.0200e-04
Validation rmse logD = 0.604630
Validation R2 logD = 0.746804
Validation rmse logP = 0.470742
Validation R2 logP = 0.935686
Epoch 73
Train function
Loss = 5.7512e-04, PNorm = 38.4244, GNorm = 1.4494, lr_0 = 1.0200e-04
Loss = 4.5539e-04, PNorm = 38.4262, GNorm = 0.8923, lr_0 = 1.0200e-04
Loss = 5.2848e-04, PNorm = 38.4283, GNorm = 2.5276, lr_0 = 1.0200e-04
Loss = 5.8107e-04, PNorm = 38.4290, GNorm = 1.3057, lr_0 = 1.0200e-04
Loss = 5.9423e-04, PNorm = 38.4301, GNorm = 1.6449, lr_0 = 1.0200e-04
Loss = 5.4990e-04, PNorm = 38.4323, GNorm = 1.8257, lr_0 = 1.0200e-04
Loss = 4.5213e-04, PNorm = 38.4341, GNorm = 1.0781, lr_0 = 1.0200e-04
Loss = 4.0874e-04, PNorm = 38.4356, GNorm = 1.7150, lr_0 = 1.0200e-04
Loss = 5.6839e-04, PNorm = 38.4371, GNorm = 0.8802, lr_0 = 1.0200e-04
Loss = 5.7345e-04, PNorm = 38.4385, GNorm = 0.8637, lr_0 = 1.0200e-04
Loss = 5.2588e-04, PNorm = 38.4397, GNorm = 2.1798, lr_0 = 1.0200e-04
Loss = 4.4461e-04, PNorm = 38.4414, GNorm = 0.9198, lr_0 = 1.0200e-04
Loss = 4.8980e-04, PNorm = 38.4432, GNorm = 0.8301, lr_0 = 1.0200e-04
Loss = 4.6392e-04, PNorm = 38.4452, GNorm = 2.3734, lr_0 = 1.0200e-04
Loss = 4.9674e-04, PNorm = 38.4460, GNorm = 1.8755, lr_0 = 1.0200e-04
Loss = 5.7840e-04, PNorm = 38.4473, GNorm = 1.2316, lr_0 = 1.0200e-04
Loss = 5.3892e-04, PNorm = 38.4491, GNorm = 0.9699, lr_0 = 1.0200e-04
Loss = 5.0903e-04, PNorm = 38.4504, GNorm = 0.9100, lr_0 = 1.0200e-04
Loss = 5.0517e-04, PNorm = 38.4518, GNorm = 1.4684, lr_0 = 1.0200e-04
Loss = 5.6805e-04, PNorm = 38.4528, GNorm = 4.1281, lr_0 = 1.0200e-04
Loss = 6.7400e-04, PNorm = 38.4545, GNorm = 2.8218, lr_0 = 1.0200e-04
Loss = 6.2344e-04, PNorm = 38.4561, GNorm = 3.2547, lr_0 = 1.0200e-04
Validation rmse logD = 0.582195
Validation R2 logD = 0.765245
Validation rmse logP = 0.474145
Validation R2 logP = 0.934753
Epoch 74
Train function
Loss = 5.6122e-04, PNorm = 38.4562, GNorm = 1.5588, lr_0 = 1.0200e-04
Loss = 4.4921e-04, PNorm = 38.4574, GNorm = 0.9429, lr_0 = 1.0200e-04
Loss = 4.1117e-04, PNorm = 38.4590, GNorm = 1.3417, lr_0 = 1.0200e-04
Loss = 5.8265e-04, PNorm = 38.4612, GNorm = 1.6189, lr_0 = 1.0200e-04
Loss = 5.6565e-04, PNorm = 38.4614, GNorm = 3.4287, lr_0 = 1.0200e-04
Loss = 6.8464e-04, PNorm = 38.4622, GNorm = 1.9969, lr_0 = 1.0200e-04
Loss = 6.3962e-04, PNorm = 38.4632, GNorm = 1.2309, lr_0 = 1.0200e-04
Loss = 5.2083e-04, PNorm = 38.4645, GNorm = 2.0301, lr_0 = 1.0200e-04
Loss = 4.6291e-04, PNorm = 38.4663, GNorm = 1.5055, lr_0 = 1.0200e-04
Loss = 5.4692e-04, PNorm = 38.4675, GNorm = 1.4544, lr_0 = 1.0200e-04
Loss = 4.4153e-04, PNorm = 38.4689, GNorm = 1.3715, lr_0 = 1.0200e-04
Loss = 4.6314e-04, PNorm = 38.4704, GNorm = 0.9146, lr_0 = 1.0200e-04
Loss = 5.3231e-04, PNorm = 38.4718, GNorm = 2.1985, lr_0 = 1.0200e-04
Loss = 4.3648e-04, PNorm = 38.4736, GNorm = 1.2272, lr_0 = 1.0200e-04
Loss = 4.4345e-04, PNorm = 38.4749, GNorm = 0.7053, lr_0 = 1.0200e-04
Loss = 5.3063e-04, PNorm = 38.4768, GNorm = 0.8142, lr_0 = 1.0200e-04
Loss = 4.7367e-04, PNorm = 38.4786, GNorm = 0.9352, lr_0 = 1.0200e-04
Loss = 5.0132e-04, PNorm = 38.4807, GNorm = 1.1116, lr_0 = 1.0200e-04
Loss = 3.9110e-04, PNorm = 38.4815, GNorm = 1.7694, lr_0 = 1.0200e-04
Loss = 4.8809e-04, PNorm = 38.4832, GNorm = 0.6754, lr_0 = 1.0200e-04
Loss = 5.0941e-04, PNorm = 38.4838, GNorm = 0.8868, lr_0 = 1.0200e-04
Loss = 4.8283e-04, PNorm = 38.4848, GNorm = 0.9702, lr_0 = 1.0200e-04
Loss = 5.8562e-04, PNorm = 38.4859, GNorm = 2.1912, lr_0 = 1.0200e-04
Validation rmse logD = 0.584872
Validation R2 logD = 0.763081
Validation rmse logP = 0.473998
Validation R2 logP = 0.934793
Epoch 75
Train function
Loss = 4.8065e-04, PNorm = 38.4870, GNorm = 1.6231, lr_0 = 1.0200e-04
Loss = 4.7860e-04, PNorm = 38.4878, GNorm = 0.8648, lr_0 = 1.0200e-04
Loss = 3.8423e-04, PNorm = 38.4893, GNorm = 0.8737, lr_0 = 1.0200e-04
Loss = 4.3350e-04, PNorm = 38.4908, GNorm = 1.1230, lr_0 = 1.0200e-04
Loss = 5.5173e-04, PNorm = 38.4923, GNorm = 2.8760, lr_0 = 1.0200e-04
Loss = 4.6222e-04, PNorm = 38.4935, GNorm = 0.8923, lr_0 = 1.0200e-04
Loss = 5.1397e-04, PNorm = 38.4954, GNorm = 2.9963, lr_0 = 1.0200e-04
Loss = 4.1207e-04, PNorm = 38.4970, GNorm = 1.1027, lr_0 = 1.0200e-04
Loss = 4.2775e-04, PNorm = 38.4987, GNorm = 1.1276, lr_0 = 1.0200e-04
Loss = 3.8761e-04, PNorm = 38.5004, GNorm = 1.1891, lr_0 = 1.0200e-04
Loss = 5.1356e-04, PNorm = 38.5010, GNorm = 4.0123, lr_0 = 1.0200e-04
Loss = 6.8553e-04, PNorm = 38.5012, GNorm = 4.7267, lr_0 = 1.0200e-04
Loss = 4.6581e-04, PNorm = 38.5016, GNorm = 1.0560, lr_0 = 1.0200e-04
Loss = 5.2400e-04, PNorm = 38.5028, GNorm = 2.4882, lr_0 = 1.0200e-04
Loss = 4.6748e-04, PNorm = 38.5051, GNorm = 1.0239, lr_0 = 1.0200e-04
Loss = 4.1267e-04, PNorm = 38.5066, GNorm = 1.0432, lr_0 = 1.0200e-04
Loss = 4.4713e-04, PNorm = 38.5080, GNorm = 0.9061, lr_0 = 1.0200e-04
Loss = 5.6297e-04, PNorm = 38.5094, GNorm = 0.7989, lr_0 = 1.0200e-04
Loss = 5.0375e-04, PNorm = 38.5108, GNorm = 1.5376, lr_0 = 1.0200e-04
Loss = 6.0448e-04, PNorm = 38.5114, GNorm = 1.6830, lr_0 = 1.0200e-04
Loss = 4.9247e-04, PNorm = 38.5132, GNorm = 1.2390, lr_0 = 1.0200e-04
Loss = 4.3531e-04, PNorm = 38.5146, GNorm = 1.0891, lr_0 = 1.0200e-04
Validation rmse logD = 0.573855
Validation R2 logD = 0.771922
Validation rmse logP = 0.487614
Validation R2 logP = 0.930993
Epoch 76
Train function
Loss = 4.4518e-04, PNorm = 38.5159, GNorm = 0.7620, lr_0 = 1.0200e-04
Loss = 4.6132e-04, PNorm = 38.5179, GNorm = 1.1431, lr_0 = 1.0200e-04
Loss = 5.3906e-04, PNorm = 38.5198, GNorm = 2.1317, lr_0 = 1.0200e-04
Loss = 5.0064e-04, PNorm = 38.5217, GNorm = 3.1458, lr_0 = 1.0200e-04
Loss = 4.0270e-04, PNorm = 38.5228, GNorm = 2.0576, lr_0 = 1.0200e-04
Loss = 5.0551e-04, PNorm = 38.5243, GNorm = 1.0852, lr_0 = 1.0200e-04
Loss = 4.9309e-04, PNorm = 38.5251, GNorm = 1.6057, lr_0 = 1.0200e-04
Loss = 4.2124e-04, PNorm = 38.5268, GNorm = 0.9566, lr_0 = 1.0200e-04
Loss = 5.9489e-04, PNorm = 38.5278, GNorm = 1.6695, lr_0 = 1.0200e-04
Loss = 6.5413e-04, PNorm = 38.5299, GNorm = 1.1499, lr_0 = 1.0200e-04
Loss = 5.1003e-04, PNorm = 38.5319, GNorm = 2.4243, lr_0 = 1.0200e-04
Loss = 5.8554e-04, PNorm = 38.5333, GNorm = 1.4297, lr_0 = 1.0200e-04
Loss = 5.4171e-04, PNorm = 38.5350, GNorm = 1.2701, lr_0 = 1.0200e-04
Loss = 5.8730e-04, PNorm = 38.5364, GNorm = 2.1121, lr_0 = 1.0200e-04
Loss = 5.1271e-04, PNorm = 38.5381, GNorm = 1.6153, lr_0 = 1.0200e-04
Loss = 4.4512e-04, PNorm = 38.5402, GNorm = 1.1105, lr_0 = 1.0200e-04
Loss = 3.9949e-04, PNorm = 38.5418, GNorm = 1.1596, lr_0 = 1.0200e-04
Loss = 3.9608e-04, PNorm = 38.5421, GNorm = 1.1242, lr_0 = 1.0200e-04
Loss = 4.5314e-04, PNorm = 38.5427, GNorm = 1.4487, lr_0 = 1.0200e-04
Loss = 5.7084e-04, PNorm = 38.5436, GNorm = 2.1484, lr_0 = 1.0200e-04
Loss = 5.0181e-04, PNorm = 38.5448, GNorm = 2.1590, lr_0 = 1.0200e-04
Loss = 6.1608e-04, PNorm = 38.5457, GNorm = 3.6765, lr_0 = 1.0200e-04
Loss = 5.0621e-04, PNorm = 38.5469, GNorm = 3.5223, lr_0 = 1.0200e-04
Validation rmse logD = 0.593341
Validation R2 logD = 0.756171
Validation rmse logP = 0.483675
Validation R2 logP = 0.932103
Epoch 77
Train function
Loss = 4.9009e-04, PNorm = 38.5486, GNorm = 3.2476, lr_0 = 1.0200e-04
Loss = 4.1734e-04, PNorm = 38.5493, GNorm = 1.2501, lr_0 = 1.0200e-04
Loss = 4.4253e-04, PNorm = 38.5514, GNorm = 1.4752, lr_0 = 1.0200e-04
Loss = 4.5009e-04, PNorm = 38.5530, GNorm = 1.1201, lr_0 = 1.0200e-04
Loss = 3.8267e-04, PNorm = 38.5549, GNorm = 1.6372, lr_0 = 1.0200e-04
Loss = 4.5582e-04, PNorm = 38.5568, GNorm = 2.0856, lr_0 = 1.0200e-04
Loss = 5.4595e-04, PNorm = 38.5580, GNorm = 1.1313, lr_0 = 1.0200e-04
Loss = 4.0068e-04, PNorm = 38.5590, GNorm = 1.1303, lr_0 = 1.0200e-04
Loss = 4.6416e-04, PNorm = 38.5600, GNorm = 1.2655, lr_0 = 1.0200e-04
Loss = 4.1570e-04, PNorm = 38.5612, GNorm = 1.4883, lr_0 = 1.0200e-04
Loss = 5.3103e-04, PNorm = 38.5616, GNorm = 1.5470, lr_0 = 1.0200e-04
Loss = 5.1887e-04, PNorm = 38.5632, GNorm = 1.3172, lr_0 = 1.0200e-04
Loss = 4.9316e-04, PNorm = 38.5645, GNorm = 1.7097, lr_0 = 1.0200e-04
Loss = 4.7865e-04, PNorm = 38.5665, GNorm = 1.4946, lr_0 = 1.0200e-04
Loss = 4.7347e-04, PNorm = 38.5686, GNorm = 1.7970, lr_0 = 1.0200e-04
Loss = 4.9954e-04, PNorm = 38.5698, GNorm = 3.7377, lr_0 = 1.0200e-04
Loss = 5.0876e-04, PNorm = 38.5704, GNorm = 1.4381, lr_0 = 1.0200e-04
Loss = 3.6652e-04, PNorm = 38.5713, GNorm = 1.4262, lr_0 = 1.0200e-04
Loss = 4.8502e-04, PNorm = 38.5719, GNorm = 2.8126, lr_0 = 1.0200e-04
Loss = 5.5201e-04, PNorm = 38.5737, GNorm = 3.4897, lr_0 = 1.0200e-04
Loss = 5.4354e-04, PNorm = 38.5754, GNorm = 1.1202, lr_0 = 1.0200e-04
Loss = 4.8031e-04, PNorm = 38.5770, GNorm = 0.8698, lr_0 = 1.0200e-04
Validation rmse logD = 0.599183
Validation R2 logD = 0.751345
Validation rmse logP = 0.471368
Validation R2 logP = 0.935515
Epoch 78
Train function
Loss = 4.8431e-04, PNorm = 38.5798, GNorm = 0.9702, lr_0 = 1.0200e-04
Loss = 3.6936e-04, PNorm = 38.5817, GNorm = 0.8645, lr_0 = 1.0200e-04
Loss = 4.7211e-04, PNorm = 38.5824, GNorm = 1.8817, lr_0 = 1.0200e-04
Loss = 5.1445e-04, PNorm = 38.5826, GNorm = 0.8082, lr_0 = 1.0200e-04
Loss = 4.3155e-04, PNorm = 38.5834, GNorm = 1.0990, lr_0 = 1.0200e-04
Loss = 4.4069e-04, PNorm = 38.5848, GNorm = 0.9965, lr_0 = 1.0200e-04
Loss = 4.2942e-04, PNorm = 38.5856, GNorm = 1.2387, lr_0 = 1.0200e-04
Loss = 4.3658e-04, PNorm = 38.5866, GNorm = 0.9713, lr_0 = 1.0200e-04
Loss = 4.4379e-04, PNorm = 38.5882, GNorm = 2.6056, lr_0 = 1.0200e-04
Loss = 4.4629e-04, PNorm = 38.5901, GNorm = 0.8308, lr_0 = 1.0200e-04
Loss = 4.4150e-04, PNorm = 38.5911, GNorm = 1.7147, lr_0 = 1.0200e-04
Loss = 4.6593e-04, PNorm = 38.5928, GNorm = 0.8108, lr_0 = 1.0200e-04
Loss = 4.9309e-04, PNorm = 38.5948, GNorm = 3.1238, lr_0 = 1.0200e-04
Loss = 4.8049e-04, PNorm = 38.5964, GNorm = 1.0134, lr_0 = 1.0200e-04
Loss = 3.5479e-04, PNorm = 38.5983, GNorm = 1.6193, lr_0 = 1.0200e-04
Loss = 5.7212e-04, PNorm = 38.5993, GNorm = 2.1494, lr_0 = 1.0200e-04
Loss = 5.4663e-04, PNorm = 38.6006, GNorm = 2.3711, lr_0 = 1.0200e-04
Loss = 5.0189e-04, PNorm = 38.6017, GNorm = 2.0361, lr_0 = 1.0200e-04
Loss = 4.6050e-04, PNorm = 38.6033, GNorm = 1.0126, lr_0 = 1.0200e-04
Loss = 5.0355e-04, PNorm = 38.6050, GNorm = 1.1959, lr_0 = 1.0200e-04
Loss = 4.3685e-04, PNorm = 38.6059, GNorm = 1.1864, lr_0 = 1.0200e-04
Loss = 5.7843e-04, PNorm = 38.6076, GNorm = 1.3806, lr_0 = 1.0200e-04
Loss = 6.7949e-04, PNorm = 38.6094, GNorm = 1.8749, lr_0 = 1.0200e-04
Validation rmse logD = 0.582343
Validation R2 logD = 0.765126
Validation rmse logP = 0.474041
Validation R2 logP = 0.934781
Epoch 79
Train function
Loss = 4.6296e-04, PNorm = 38.6111, GNorm = 1.6351, lr_0 = 1.0200e-04
Loss = 4.6405e-04, PNorm = 38.6110, GNorm = 1.1443, lr_0 = 1.0200e-04
Loss = 4.9537e-04, PNorm = 38.6126, GNorm = 1.8777, lr_0 = 1.0200e-04
Loss = 4.7185e-04, PNorm = 38.6136, GNorm = 2.8723, lr_0 = 1.0200e-04
Loss = 6.1396e-04, PNorm = 38.6141, GNorm = 2.0016, lr_0 = 1.0200e-04
Loss = 6.4256e-04, PNorm = 38.6152, GNorm = 5.7119, lr_0 = 1.0200e-04
Loss = 5.7461e-04, PNorm = 38.6166, GNorm = 0.8801, lr_0 = 1.0200e-04
Loss = 5.1062e-04, PNorm = 38.6194, GNorm = 1.7847, lr_0 = 1.0200e-04
Loss = 4.2501e-04, PNorm = 38.6210, GNorm = 1.0547, lr_0 = 1.0200e-04
Loss = 4.6174e-04, PNorm = 38.6229, GNorm = 3.1891, lr_0 = 1.0200e-04
Loss = 5.1367e-04, PNorm = 38.6245, GNorm = 2.5215, lr_0 = 1.0200e-04
Loss = 5.7828e-04, PNorm = 38.6256, GNorm = 1.8422, lr_0 = 1.0200e-04
Loss = 6.2200e-04, PNorm = 38.6278, GNorm = 3.1787, lr_0 = 1.0200e-04
Loss = 6.4261e-04, PNorm = 38.6303, GNorm = 2.1857, lr_0 = 1.0200e-04
Loss = 6.5985e-04, PNorm = 38.6328, GNorm = 0.6946, lr_0 = 1.0200e-04
Loss = 6.2628e-04, PNorm = 38.6343, GNorm = 1.3797, lr_0 = 1.0200e-04
Loss = 5.3737e-04, PNorm = 38.6355, GNorm = 1.1214, lr_0 = 1.0200e-04
Loss = 4.9374e-04, PNorm = 38.6373, GNorm = 1.7912, lr_0 = 1.0200e-04
Loss = 4.8040e-04, PNorm = 38.6394, GNorm = 2.2013, lr_0 = 1.0200e-04
Loss = 3.8217e-04, PNorm = 38.6403, GNorm = 2.0907, lr_0 = 1.0200e-04
Loss = 4.4602e-04, PNorm = 38.6414, GNorm = 0.7837, lr_0 = 1.0200e-04
Loss = 5.0931e-04, PNorm = 38.6426, GNorm = 1.8114, lr_0 = 1.0200e-04
Validation rmse logD = 0.582425
Validation R2 logD = 0.765060
Validation rmse logP = 0.466808
Validation R2 logP = 0.936756
Epoch 80
Train function
Loss = 4.5202e-04, PNorm = 38.6436, GNorm = 1.0839, lr_0 = 1.0200e-04
Loss = 3.4117e-04, PNorm = 38.6447, GNorm = 0.7767, lr_0 = 1.0200e-04
Loss = 4.0070e-04, PNorm = 38.6457, GNorm = 1.4481, lr_0 = 1.0200e-04
Loss = 4.4055e-04, PNorm = 38.6466, GNorm = 2.8697, lr_0 = 1.0200e-04
Loss = 4.9535e-04, PNorm = 38.6479, GNorm = 2.2285, lr_0 = 1.0200e-04
Loss = 4.9299e-04, PNorm = 38.6487, GNorm = 2.4337, lr_0 = 1.0200e-04
Loss = 5.2103e-04, PNorm = 38.6504, GNorm = 1.7193, lr_0 = 1.0200e-04
Loss = 4.7249e-04, PNorm = 38.6527, GNorm = 1.9737, lr_0 = 1.0200e-04
Loss = 4.3754e-04, PNorm = 38.6530, GNorm = 1.0745, lr_0 = 1.0200e-04
Loss = 4.1459e-04, PNorm = 38.6544, GNorm = 1.6554, lr_0 = 1.0200e-04
Loss = 3.8756e-04, PNorm = 38.6556, GNorm = 1.6710, lr_0 = 1.0200e-04
Loss = 3.7419e-04, PNorm = 38.6565, GNorm = 1.0116, lr_0 = 1.0200e-04
Loss = 3.8640e-04, PNorm = 38.6576, GNorm = 1.4566, lr_0 = 1.0200e-04
Loss = 3.9834e-04, PNorm = 38.6577, GNorm = 1.6047, lr_0 = 1.0200e-04
Loss = 5.4630e-04, PNorm = 38.6585, GNorm = 3.6420, lr_0 = 1.0200e-04
Loss = 5.6576e-04, PNorm = 38.6596, GNorm = 1.6758, lr_0 = 1.0200e-04
Loss = 6.2287e-04, PNorm = 38.6613, GNorm = 1.2258, lr_0 = 1.0200e-04
Loss = 5.0732e-04, PNorm = 38.6622, GNorm = 1.5950, lr_0 = 1.0200e-04
Loss = 4.0412e-04, PNorm = 38.6643, GNorm = 1.2251, lr_0 = 1.0200e-04
Loss = 4.0437e-04, PNorm = 38.6657, GNorm = 0.9816, lr_0 = 1.0200e-04
Loss = 4.9343e-04, PNorm = 38.6675, GNorm = 0.7443, lr_0 = 1.0200e-04
Loss = 4.0144e-04, PNorm = 38.6694, GNorm = 1.1582, lr_0 = 1.0200e-04
Loss = 4.6215e-04, PNorm = 38.6711, GNorm = 2.3530, lr_0 = 1.0200e-04
Validation rmse logD = 0.599141
Validation R2 logD = 0.751380
Validation rmse logP = 0.475619
Validation R2 logP = 0.934346
Epoch 81
Train function
Loss = 4.5616e-04, PNorm = 38.6732, GNorm = 1.9250, lr_0 = 1.0200e-04
Loss = 5.2598e-04, PNorm = 38.6744, GNorm = 0.9338, lr_0 = 1.0200e-04
Loss = 4.6677e-04, PNorm = 38.6763, GNorm = 1.4260, lr_0 = 1.0200e-04
Loss = 4.0247e-04, PNorm = 38.6774, GNorm = 0.7767, lr_0 = 1.0200e-04
Loss = 3.7507e-04, PNorm = 38.6786, GNorm = 1.1225, lr_0 = 1.0200e-04
Loss = 5.1133e-04, PNorm = 38.6796, GNorm = 1.8997, lr_0 = 1.0200e-04
Loss = 3.5861e-04, PNorm = 38.6804, GNorm = 2.4774, lr_0 = 1.0200e-04
Loss = 4.2975e-04, PNorm = 38.6818, GNorm = 1.0259, lr_0 = 1.0200e-04
Loss = 4.6215e-04, PNorm = 38.6824, GNorm = 2.2412, lr_0 = 1.0200e-04
Loss = 3.8105e-04, PNorm = 38.6841, GNorm = 2.3255, lr_0 = 1.0200e-04
Loss = 3.7548e-04, PNorm = 38.6844, GNorm = 1.0204, lr_0 = 1.0200e-04
Loss = 3.9976e-04, PNorm = 38.6846, GNorm = 0.5402, lr_0 = 1.0200e-04
Loss = 4.6216e-04, PNorm = 38.6853, GNorm = 2.1807, lr_0 = 1.0200e-04
Loss = 5.4795e-04, PNorm = 38.6869, GNorm = 2.0071, lr_0 = 1.0200e-04
Loss = 3.9554e-04, PNorm = 38.6890, GNorm = 2.2167, lr_0 = 1.0200e-04
Loss = 5.5130e-04, PNorm = 38.6902, GNorm = 1.5771, lr_0 = 1.0200e-04
Loss = 4.9139e-04, PNorm = 38.6920, GNorm = 1.8602, lr_0 = 1.0200e-04
Loss = 4.3989e-04, PNorm = 38.6936, GNorm = 1.0878, lr_0 = 1.0200e-04
Loss = 4.2520e-04, PNorm = 38.6948, GNorm = 1.0883, lr_0 = 1.0200e-04
Loss = 4.7503e-04, PNorm = 38.6967, GNorm = 1.4600, lr_0 = 1.0200e-04
Loss = 4.2128e-04, PNorm = 38.6974, GNorm = 1.1038, lr_0 = 1.0200e-04
Loss = 4.5719e-04, PNorm = 38.6991, GNorm = 1.2618, lr_0 = 1.0200e-04
Validation rmse logD = 0.593143
Validation R2 logD = 0.756333
Validation rmse logP = 0.493952
Validation R2 logP = 0.929187
Epoch 82
Train function
Loss = 3.9398e-04, PNorm = 38.7006, GNorm = 1.2910, lr_0 = 1.0200e-04
Loss = 3.9792e-04, PNorm = 38.7022, GNorm = 0.9571, lr_0 = 1.0200e-04
Loss = 3.8263e-04, PNorm = 38.7024, GNorm = 2.8682, lr_0 = 1.0200e-04
Loss = 4.0343e-04, PNorm = 38.7027, GNorm = 1.7375, lr_0 = 1.0200e-04
Loss = 3.7721e-04, PNorm = 38.7040, GNorm = 0.8862, lr_0 = 1.0200e-04
Loss = 6.1566e-04, PNorm = 38.7062, GNorm = 2.1031, lr_0 = 1.0200e-04
Loss = 6.0746e-04, PNorm = 38.7077, GNorm = 2.6363, lr_0 = 1.0200e-04
Loss = 4.9778e-04, PNorm = 38.7114, GNorm = 1.0748, lr_0 = 1.0200e-04
Loss = 4.8669e-04, PNorm = 38.7140, GNorm = 1.6350, lr_0 = 1.0200e-04
Loss = 4.3555e-04, PNorm = 38.7155, GNorm = 1.4071, lr_0 = 1.0200e-04
Loss = 4.2645e-04, PNorm = 38.7168, GNorm = 0.9155, lr_0 = 1.0200e-04
Loss = 5.2975e-04, PNorm = 38.7186, GNorm = 0.9174, lr_0 = 1.0200e-04
Loss = 3.7337e-04, PNorm = 38.7202, GNorm = 1.1548, lr_0 = 1.0200e-04
Loss = 3.2750e-04, PNorm = 38.7209, GNorm = 0.7263, lr_0 = 1.0200e-04
Loss = 4.4450e-04, PNorm = 38.7220, GNorm = 3.2809, lr_0 = 1.0200e-04
Loss = 4.6271e-04, PNorm = 38.7233, GNorm = 0.8421, lr_0 = 1.0200e-04
Loss = 5.5148e-04, PNorm = 38.7243, GNorm = 2.2255, lr_0 = 1.0200e-04
Loss = 5.0918e-04, PNorm = 38.7252, GNorm = 2.8907, lr_0 = 1.0200e-04
Loss = 4.5513e-04, PNorm = 38.7259, GNorm = 1.5985, lr_0 = 1.0200e-04
Loss = 4.0672e-04, PNorm = 38.7269, GNorm = 0.8949, lr_0 = 1.0200e-04
Loss = 3.6656e-04, PNorm = 38.7279, GNorm = 1.6272, lr_0 = 1.0200e-04
Loss = 4.2446e-04, PNorm = 38.7292, GNorm = 1.7801, lr_0 = 1.0200e-04
Loss = 3.6296e-04, PNorm = 38.7311, GNorm = 0.7883, lr_0 = 1.0200e-04
Validation rmse logD = 0.595203
Validation R2 logD = 0.754638
Validation rmse logP = 0.470172
Validation R2 logP = 0.935842
Epoch 83
Train function
Loss = 4.3883e-04, PNorm = 38.7328, GNorm = 2.1870, lr_0 = 1.0200e-04
Loss = 4.5511e-04, PNorm = 38.7343, GNorm = 1.3686, lr_0 = 1.0200e-04
Loss = 4.5943e-04, PNorm = 38.7358, GNorm = 2.0706, lr_0 = 1.0200e-04
Loss = 4.1935e-04, PNorm = 38.7366, GNorm = 2.1454, lr_0 = 1.0200e-04
Loss = 3.7372e-04, PNorm = 38.7376, GNorm = 0.9112, lr_0 = 1.0200e-04
Loss = 4.8716e-04, PNorm = 38.7388, GNorm = 1.1818, lr_0 = 1.0200e-04
Loss = 3.6373e-04, PNorm = 38.7400, GNorm = 1.7725, lr_0 = 1.0200e-04
Loss = 3.9431e-04, PNorm = 38.7411, GNorm = 1.7828, lr_0 = 1.0200e-04
Loss = 6.6423e-04, PNorm = 38.7428, GNorm = 2.9906, lr_0 = 1.0200e-04
Loss = 4.2041e-04, PNorm = 38.7437, GNorm = 1.7674, lr_0 = 1.0200e-04
Loss = 4.6493e-04, PNorm = 38.7459, GNorm = 1.9172, lr_0 = 1.0200e-04
Loss = 5.2067e-04, PNorm = 38.7474, GNorm = 1.8762, lr_0 = 1.0200e-04
Loss = 4.3695e-04, PNorm = 38.7485, GNorm = 1.3254, lr_0 = 1.0200e-04
Loss = 4.1785e-04, PNorm = 38.7499, GNorm = 1.5136, lr_0 = 1.0200e-04
Loss = 4.0056e-04, PNorm = 38.7519, GNorm = 0.9758, lr_0 = 1.0200e-04
Loss = 3.4577e-04, PNorm = 38.7542, GNorm = 0.8186, lr_0 = 1.0200e-04
Loss = 4.0781e-04, PNorm = 38.7560, GNorm = 1.6664, lr_0 = 1.0200e-04
Loss = 4.5771e-04, PNorm = 38.7577, GNorm = 0.7801, lr_0 = 1.0200e-04
Loss = 4.5218e-04, PNorm = 38.7587, GNorm = 1.3152, lr_0 = 1.0200e-04
Loss = 6.4169e-04, PNorm = 38.7597, GNorm = 1.1761, lr_0 = 1.0200e-04
Loss = 5.5539e-04, PNorm = 38.7607, GNorm = 3.4275, lr_0 = 1.0200e-04
Loss = 4.4467e-04, PNorm = 38.7619, GNorm = 1.6749, lr_0 = 1.0200e-04
Loss = 4.1259e-04, PNorm = 38.7635, GNorm = 1.5462, lr_0 = 1.0200e-04
Validation rmse logD = 0.581257
Validation R2 logD = 0.766001
Validation rmse logP = 0.463866
Validation R2 logP = 0.937551
Epoch 84
Train function
Loss = 4.3961e-04, PNorm = 38.7651, GNorm = 1.4670, lr_0 = 1.0200e-04
Loss = 3.6789e-04, PNorm = 38.7660, GNorm = 1.8732, lr_0 = 1.0200e-04
Loss = 4.3365e-04, PNorm = 38.7673, GNorm = 0.9263, lr_0 = 1.0200e-04
Loss = 3.9798e-04, PNorm = 38.7687, GNorm = 0.8967, lr_0 = 1.0200e-04
Loss = 4.8463e-04, PNorm = 38.7707, GNorm = 0.8374, lr_0 = 1.0200e-04
Loss = 4.1310e-04, PNorm = 38.7712, GNorm = 1.4942, lr_0 = 1.0200e-04
Loss = 3.1336e-04, PNorm = 38.7727, GNorm = 1.1637, lr_0 = 1.0200e-04
Loss = 3.5393e-04, PNorm = 38.7737, GNorm = 3.0049, lr_0 = 1.0200e-04
Loss = 4.0669e-04, PNorm = 38.7750, GNorm = 1.1450, lr_0 = 1.0200e-04
Loss = 4.0554e-04, PNorm = 38.7761, GNorm = 1.7016, lr_0 = 1.0200e-04
Loss = 3.8333e-04, PNorm = 38.7777, GNorm = 1.2118, lr_0 = 1.0200e-04
Loss = 3.6126e-04, PNorm = 38.7790, GNorm = 1.5636, lr_0 = 1.0200e-04
Loss = 4.9363e-04, PNorm = 38.7804, GNorm = 2.2479, lr_0 = 1.0200e-04
Loss = 4.0254e-04, PNorm = 38.7811, GNorm = 0.9111, lr_0 = 1.0200e-04
Loss = 3.8793e-04, PNorm = 38.7819, GNorm = 1.4291, lr_0 = 1.0200e-04
Loss = 3.7556e-04, PNorm = 38.7830, GNorm = 2.4226, lr_0 = 1.0200e-04
Loss = 4.4371e-04, PNorm = 38.7844, GNorm = 1.3181, lr_0 = 1.0200e-04
Loss = 3.9120e-04, PNorm = 38.7855, GNorm = 1.6437, lr_0 = 1.0200e-04
Loss = 3.6845e-04, PNorm = 38.7863, GNorm = 1.2727, lr_0 = 1.0200e-04
Loss = 4.2282e-04, PNorm = 38.7876, GNorm = 1.0809, lr_0 = 1.0200e-04
Loss = 4.4180e-04, PNorm = 38.7884, GNorm = 1.4810, lr_0 = 1.0200e-04
Loss = 4.4554e-04, PNorm = 38.7892, GNorm = 0.9236, lr_0 = 1.0200e-04
Validation rmse logD = 0.618369
Validation R2 logD = 0.735166
Validation rmse logP = 0.471307
Validation R2 logP = 0.935531
Epoch 85
Train function
Loss = 4.6175e-04, PNorm = 38.7909, GNorm = 2.5415, lr_0 = 1.0200e-04
Loss = 4.2373e-04, PNorm = 38.7914, GNorm = 2.0041, lr_0 = 1.0200e-04
Loss = 4.4212e-04, PNorm = 38.7921, GNorm = 2.1955, lr_0 = 1.0200e-04
Loss = 4.6822e-04, PNorm = 38.7928, GNorm = 1.5052, lr_0 = 1.0200e-04
Loss = 4.2900e-04, PNorm = 38.7944, GNorm = 2.0296, lr_0 = 1.0200e-04
Loss = 3.6258e-04, PNorm = 38.7960, GNorm = 0.9042, lr_0 = 1.0200e-04
Loss = 3.7433e-04, PNorm = 38.7980, GNorm = 1.5546, lr_0 = 1.0200e-04
Loss = 4.8329e-04, PNorm = 38.7995, GNorm = 1.7976, lr_0 = 1.0200e-04
Loss = 3.0223e-04, PNorm = 38.8015, GNorm = 0.8349, lr_0 = 1.0200e-04
Loss = 3.4854e-04, PNorm = 38.8026, GNorm = 0.8517, lr_0 = 1.0200e-04
Loss = 3.2418e-04, PNorm = 38.8035, GNorm = 2.2937, lr_0 = 1.0200e-04
Loss = 3.7206e-04, PNorm = 38.8052, GNorm = 1.3640, lr_0 = 1.0200e-04
Loss = 4.5253e-04, PNorm = 38.8056, GNorm = 0.9510, lr_0 = 1.0200e-04
Loss = 3.4999e-04, PNorm = 38.8062, GNorm = 1.2217, lr_0 = 1.0200e-04
Loss = 3.4836e-04, PNorm = 38.8075, GNorm = 0.7738, lr_0 = 1.0200e-04
Loss = 4.1924e-04, PNorm = 38.8088, GNorm = 3.0630, lr_0 = 1.0200e-04
Loss = 4.5425e-04, PNorm = 38.8098, GNorm = 2.9032, lr_0 = 1.0200e-04
Loss = 4.6798e-04, PNorm = 38.8104, GNorm = 2.2602, lr_0 = 1.0200e-04
Loss = 4.3064e-04, PNorm = 38.8118, GNorm = 3.2754, lr_0 = 1.0200e-04
Loss = 4.0308e-04, PNorm = 38.8132, GNorm = 1.1018, lr_0 = 1.0200e-04
Loss = 4.3862e-04, PNorm = 38.8146, GNorm = 0.7569, lr_0 = 1.0200e-04
Loss = 4.0878e-04, PNorm = 38.8161, GNorm = 1.5361, lr_0 = 1.0200e-04
Loss = 3.8767e-04, PNorm = 38.8175, GNorm = 1.1940, lr_0 = 1.0200e-04
Validation rmse logD = 0.590475
Validation R2 logD = 0.758520
Validation rmse logP = 0.480702
Validation R2 logP = 0.932935
Epoch 86
Train function
Loss = 3.4136e-04, PNorm = 38.8196, GNorm = 0.6846, lr_0 = 1.0200e-04
Loss = 3.4900e-04, PNorm = 38.8210, GNorm = 1.1448, lr_0 = 1.0200e-04
Loss = 3.7404e-04, PNorm = 38.8220, GNorm = 1.8586, lr_0 = 1.0200e-04
Loss = 3.5767e-04, PNorm = 38.8235, GNorm = 3.3289, lr_0 = 1.0200e-04
Loss = 3.4846e-04, PNorm = 38.8245, GNorm = 2.4543, lr_0 = 1.0200e-04
Loss = 3.8215e-04, PNorm = 38.8254, GNorm = 1.4913, lr_0 = 1.0200e-04
Loss = 4.7661e-04, PNorm = 38.8263, GNorm = 1.2945, lr_0 = 1.0200e-04
Loss = 4.3967e-04, PNorm = 38.8276, GNorm = 1.2692, lr_0 = 1.0200e-04
Loss = 3.5417e-04, PNorm = 38.8286, GNorm = 0.7033, lr_0 = 1.0200e-04
Loss = 4.8293e-04, PNorm = 38.8305, GNorm = 1.8587, lr_0 = 1.0200e-04
Loss = 3.4310e-04, PNorm = 38.8316, GNorm = 0.6322, lr_0 = 1.0200e-04
Loss = 4.2140e-04, PNorm = 38.8321, GNorm = 1.0992, lr_0 = 1.0200e-04
Loss = 4.8707e-04, PNorm = 38.8340, GNorm = 3.0633, lr_0 = 1.0200e-04
Loss = 5.5191e-04, PNorm = 38.8354, GNorm = 1.7806, lr_0 = 1.0200e-04
Loss = 5.2716e-04, PNorm = 38.8369, GNorm = 2.0656, lr_0 = 1.0200e-04
Loss = 4.7079e-04, PNorm = 38.8383, GNorm = 2.5465, lr_0 = 1.0200e-04
Loss = 4.3308e-04, PNorm = 38.8399, GNorm = 1.7443, lr_0 = 1.0200e-04
Loss = 3.5693e-04, PNorm = 38.8413, GNorm = 1.0179, lr_0 = 1.0200e-04
Loss = 3.0452e-04, PNorm = 38.8428, GNorm = 0.5164, lr_0 = 1.0200e-04
Loss = 3.6885e-04, PNorm = 38.8441, GNorm = 1.4858, lr_0 = 1.0200e-04
Loss = 3.4003e-04, PNorm = 38.8454, GNorm = 1.2153, lr_0 = 1.0200e-04
Loss = 3.1528e-04, PNorm = 38.8467, GNorm = 1.1628, lr_0 = 1.0200e-04
Validation rmse logD = 0.578504
Validation R2 logD = 0.768212
Validation rmse logP = 0.467232
Validation R2 logP = 0.936641
Epoch 87
Train function
Loss = 3.0543e-04, PNorm = 38.8477, GNorm = 1.3396, lr_0 = 1.0200e-04
Loss = 2.9106e-04, PNorm = 38.8489, GNorm = 1.3383, lr_0 = 1.0200e-04
Loss = 3.7296e-04, PNorm = 38.8499, GNorm = 1.3662, lr_0 = 1.0200e-04
Loss = 3.3419e-04, PNorm = 38.8510, GNorm = 1.2972, lr_0 = 1.0200e-04
Loss = 3.0076e-04, PNorm = 38.8518, GNorm = 1.7649, lr_0 = 1.0200e-04
Loss = 3.6904e-04, PNorm = 38.8528, GNorm = 1.7139, lr_0 = 1.0200e-04
Loss = 3.9339e-04, PNorm = 38.8536, GNorm = 1.7382, lr_0 = 1.0200e-04
Loss = 3.9609e-04, PNorm = 38.8552, GNorm = 1.2888, lr_0 = 1.0200e-04
Loss = 3.5923e-04, PNorm = 38.8564, GNorm = 2.1825, lr_0 = 1.0200e-04
Loss = 3.4065e-04, PNorm = 38.8575, GNorm = 0.7377, lr_0 = 1.0200e-04
Loss = 4.2972e-04, PNorm = 38.8586, GNorm = 0.9842, lr_0 = 1.0200e-04
Loss = 4.7069e-04, PNorm = 38.8593, GNorm = 2.2224, lr_0 = 1.0200e-04
Loss = 4.8868e-04, PNorm = 38.8610, GNorm = 3.0609, lr_0 = 1.0200e-04
Loss = 4.5211e-04, PNorm = 38.8615, GNorm = 1.4727, lr_0 = 1.0200e-04
Loss = 4.4872e-04, PNorm = 38.8631, GNorm = 1.0930, lr_0 = 1.0200e-04
Loss = 3.8230e-04, PNorm = 38.8653, GNorm = 1.1409, lr_0 = 1.0200e-04
Loss = 4.4282e-04, PNorm = 38.8672, GNorm = 1.2133, lr_0 = 1.0200e-04
Loss = 3.8976e-04, PNorm = 38.8685, GNorm = 1.2026, lr_0 = 1.0200e-04
Loss = 3.1023e-04, PNorm = 38.8701, GNorm = 0.8401, lr_0 = 1.0200e-04
Loss = 4.1366e-04, PNorm = 38.8725, GNorm = 1.1245, lr_0 = 1.0200e-04
Loss = 4.0601e-04, PNorm = 38.8730, GNorm = 1.1115, lr_0 = 1.0200e-04
Loss = 3.5770e-04, PNorm = 38.8735, GNorm = 0.9620, lr_0 = 1.0200e-04
Loss = 4.7793e-04, PNorm = 38.8749, GNorm = 0.9498, lr_0 = 1.0200e-04
Validation rmse logD = 0.606204
Validation R2 logD = 0.745483
Validation rmse logP = 0.474036
Validation R2 logP = 0.934783
Epoch 88
Train function
Loss = 4.4197e-04, PNorm = 38.8777, GNorm = 2.7797, lr_0 = 1.0200e-04
Loss = 3.3156e-04, PNorm = 38.8792, GNorm = 1.6706, lr_0 = 1.0200e-04
Loss = 3.4169e-04, PNorm = 38.8804, GNorm = 1.7547, lr_0 = 1.0200e-04
Loss = 3.8268e-04, PNorm = 38.8819, GNorm = 1.1207, lr_0 = 1.0200e-04
Loss = 3.1578e-04, PNorm = 38.8835, GNorm = 0.9878, lr_0 = 1.0200e-04
Loss = 3.7823e-04, PNorm = 38.8846, GNorm = 1.1358, lr_0 = 1.0200e-04
Loss = 2.7653e-04, PNorm = 38.8859, GNorm = 2.3643, lr_0 = 1.0200e-04
Loss = 3.6170e-04, PNorm = 38.8868, GNorm = 2.4264, lr_0 = 1.0200e-04
Loss = 3.6121e-04, PNorm = 38.8875, GNorm = 2.2378, lr_0 = 1.0200e-04
Loss = 3.9917e-04, PNorm = 38.8887, GNorm = 1.5218, lr_0 = 1.0200e-04
Loss = 3.8311e-04, PNorm = 38.8899, GNorm = 1.2853, lr_0 = 1.0200e-04
Loss = 3.7576e-04, PNorm = 38.8914, GNorm = 1.0580, lr_0 = 1.0200e-04
Loss = 3.9401e-04, PNorm = 38.8920, GNorm = 0.8967, lr_0 = 1.0200e-04
Loss = 3.5877e-04, PNorm = 38.8937, GNorm = 1.1414, lr_0 = 1.0200e-04
Loss = 3.3774e-04, PNorm = 38.8949, GNorm = 1.6004, lr_0 = 1.0200e-04
Loss = 3.8452e-04, PNorm = 38.8957, GNorm = 2.1694, lr_0 = 1.0200e-04
Loss = 4.1552e-04, PNorm = 38.8973, GNorm = 0.9603, lr_0 = 1.0200e-04
Loss = 4.1818e-04, PNorm = 38.8979, GNorm = 1.2514, lr_0 = 1.0200e-04
Loss = 4.6873e-04, PNorm = 38.8986, GNorm = 1.6410, lr_0 = 1.0200e-04
Loss = 2.7811e-04, PNorm = 38.8989, GNorm = 0.7893, lr_0 = 1.0200e-04
Loss = 4.1474e-04, PNorm = 38.9001, GNorm = 0.8858, lr_0 = 1.0200e-04
Loss = 4.3130e-04, PNorm = 38.9006, GNorm = 0.7858, lr_0 = 1.0200e-04
Validation rmse logD = 0.593973
Validation R2 logD = 0.755651
Validation rmse logP = 0.475808
Validation R2 logP = 0.934294
Epoch 89
Train function
Loss = 3.0286e-04, PNorm = 38.9016, GNorm = 1.1324, lr_0 = 1.0200e-04
Loss = 4.6049e-04, PNorm = 38.9025, GNorm = 2.5870, lr_0 = 1.0200e-04
Loss = 4.1281e-04, PNorm = 38.9040, GNorm = 3.8042, lr_0 = 1.0200e-04
Loss = 3.9608e-04, PNorm = 38.9052, GNorm = 2.6412, lr_0 = 1.0200e-04
Loss = 4.9143e-04, PNorm = 38.9075, GNorm = 1.3663, lr_0 = 1.0200e-04
Loss = 4.1515e-04, PNorm = 38.9084, GNorm = 1.1668, lr_0 = 1.0200e-04
Loss = 4.3989e-04, PNorm = 38.9111, GNorm = 1.0496, lr_0 = 1.0200e-04
Loss = 3.2766e-04, PNorm = 38.9125, GNorm = 1.6761, lr_0 = 1.0200e-04
Loss = 3.4194e-04, PNorm = 38.9135, GNorm = 1.0535, lr_0 = 1.0200e-04
Loss = 3.8602e-04, PNorm = 38.9154, GNorm = 0.8601, lr_0 = 1.0200e-04
Loss = 3.4891e-04, PNorm = 38.9176, GNorm = 1.1405, lr_0 = 1.0200e-04
Loss = 4.4010e-04, PNorm = 38.9197, GNorm = 1.0883, lr_0 = 1.0200e-04
Loss = 4.7881e-04, PNorm = 38.9215, GNorm = 2.5580, lr_0 = 1.0200e-04
Loss = 6.0284e-04, PNorm = 38.9228, GNorm = 3.4675, lr_0 = 1.0200e-04
Loss = 3.8792e-04, PNorm = 38.9242, GNorm = 2.1464, lr_0 = 1.0200e-04
Loss = 3.7973e-04, PNorm = 38.9252, GNorm = 1.4963, lr_0 = 1.0200e-04
Loss = 4.7861e-04, PNorm = 38.9267, GNorm = 1.7378, lr_0 = 1.0200e-04
Loss = 4.0403e-04, PNorm = 38.9278, GNorm = 0.6742, lr_0 = 1.0200e-04
Loss = 4.0389e-04, PNorm = 38.9293, GNorm = 1.7076, lr_0 = 1.0200e-04
Loss = 4.0374e-04, PNorm = 38.9298, GNorm = 1.1005, lr_0 = 1.0200e-04
Loss = 4.1664e-04, PNorm = 38.9304, GNorm = 1.0747, lr_0 = 1.0200e-04
Loss = 4.0969e-04, PNorm = 38.9319, GNorm = 2.5627, lr_0 = 1.0200e-04
Loss = 3.1486e-04, PNorm = 38.9333, GNorm = 2.4206, lr_0 = 1.0200e-04
Validation rmse logD = 0.585010
Validation R2 logD = 0.762969
Validation rmse logP = 0.469477
Validation R2 logP = 0.936031
Epoch 90
Train function
Loss = 2.9090e-04, PNorm = 38.9354, GNorm = 1.1527, lr_0 = 1.0200e-04
Loss = 3.1036e-04, PNorm = 38.9363, GNorm = 0.6727, lr_0 = 1.0200e-04
Loss = 2.9114e-04, PNorm = 38.9371, GNorm = 0.8980, lr_0 = 1.0200e-04
Loss = 2.7305e-04, PNorm = 38.9381, GNorm = 1.5311, lr_0 = 1.0200e-04
Loss = 3.6061e-04, PNorm = 38.9397, GNorm = 1.8384, lr_0 = 1.0200e-04
Loss = 3.5682e-04, PNorm = 38.9406, GNorm = 1.8923, lr_0 = 1.0200e-04
Loss = 4.3817e-04, PNorm = 38.9422, GNorm = 3.6014, lr_0 = 1.0200e-04
Loss = 3.4351e-04, PNorm = 38.9433, GNorm = 1.3254, lr_0 = 1.0200e-04
Loss = 3.5065e-04, PNorm = 38.9442, GNorm = 2.0403, lr_0 = 1.0200e-04
Loss = 3.3222e-04, PNorm = 38.9449, GNorm = 0.9940, lr_0 = 1.0200e-04
Loss = 3.4783e-04, PNorm = 38.9455, GNorm = 1.4804, lr_0 = 1.0200e-04
Loss = 3.9070e-04, PNorm = 38.9463, GNorm = 1.4412, lr_0 = 1.0200e-04
Loss = 3.7438e-04, PNorm = 38.9472, GNorm = 0.8751, lr_0 = 1.0200e-04
Loss = 3.4700e-04, PNorm = 38.9478, GNorm = 1.2144, lr_0 = 1.0200e-04
Loss = 3.2810e-04, PNorm = 38.9487, GNorm = 1.3785, lr_0 = 1.0200e-04
Loss = 3.7597e-04, PNorm = 38.9501, GNorm = 0.8161, lr_0 = 1.0200e-04
Loss = 3.5289e-04, PNorm = 38.9521, GNorm = 1.0667, lr_0 = 1.0200e-04
Loss = 4.0326e-04, PNorm = 38.9537, GNorm = 0.9082, lr_0 = 1.0200e-04
Loss = 3.4062e-04, PNorm = 38.9559, GNorm = 1.3891, lr_0 = 1.0200e-04
Loss = 3.5384e-04, PNorm = 38.9583, GNorm = 1.0521, lr_0 = 1.0200e-04
Loss = 3.0391e-04, PNorm = 38.9595, GNorm = 1.6430, lr_0 = 1.0200e-04
Loss = 3.5146e-04, PNorm = 38.9603, GNorm = 0.9697, lr_0 = 1.0200e-04
Validation rmse logD = 0.576656
Validation R2 logD = 0.769691
Validation rmse logP = 0.475590
Validation R2 logP = 0.934354
Epoch 91
Train function
Loss = 3.1062e-04, PNorm = 38.9616, GNorm = 1.4015, lr_0 = 1.0200e-04
Loss = 3.4390e-04, PNorm = 38.9629, GNorm = 1.5342, lr_0 = 1.0200e-04
Loss = 4.1089e-04, PNorm = 38.9645, GNorm = 1.4383, lr_0 = 1.0200e-04
Loss = 4.1847e-04, PNorm = 38.9656, GNorm = 1.3335, lr_0 = 1.0200e-04
Loss = 3.8631e-04, PNorm = 38.9669, GNorm = 1.6741, lr_0 = 1.0200e-04
Loss = 3.3626e-04, PNorm = 38.9675, GNorm = 2.1651, lr_0 = 1.0200e-04
Loss = 3.8060e-04, PNorm = 38.9685, GNorm = 1.6449, lr_0 = 1.0200e-04
Loss = 3.4560e-04, PNorm = 38.9690, GNorm = 0.9713, lr_0 = 1.0200e-04
Loss = 3.8843e-04, PNorm = 38.9707, GNorm = 1.2040, lr_0 = 1.0200e-04
Loss = 3.7700e-04, PNorm = 38.9722, GNorm = 1.3091, lr_0 = 1.0200e-04
Loss = 4.4435e-04, PNorm = 38.9740, GNorm = 2.0283, lr_0 = 1.0200e-04
Loss = 3.5963e-04, PNorm = 38.9749, GNorm = 2.2171, lr_0 = 1.0200e-04
Loss = 3.7657e-04, PNorm = 38.9767, GNorm = 1.0758, lr_0 = 1.0200e-04
Loss = 3.5987e-04, PNorm = 38.9776, GNorm = 1.3754, lr_0 = 1.0200e-04
Loss = 3.8610e-04, PNorm = 38.9779, GNorm = 1.3195, lr_0 = 1.0200e-04
Loss = 3.3786e-04, PNorm = 38.9793, GNorm = 2.5094, lr_0 = 1.0200e-04
Loss = 4.9064e-04, PNorm = 38.9810, GNorm = 2.3856, lr_0 = 1.0200e-04
Loss = 3.6889e-04, PNorm = 38.9819, GNorm = 2.4679, lr_0 = 1.0200e-04
Loss = 3.4857e-04, PNorm = 38.9828, GNorm = 1.7619, lr_0 = 1.0200e-04
Loss = 3.7622e-04, PNorm = 38.9844, GNorm = 1.9752, lr_0 = 1.0200e-04
Loss = 4.2086e-04, PNorm = 38.9851, GNorm = 1.0322, lr_0 = 1.0200e-04
Loss = 3.4838e-04, PNorm = 38.9875, GNorm = 1.5641, lr_0 = 1.0200e-04
Loss = 3.3451e-04, PNorm = 38.9893, GNorm = 1.3375, lr_0 = 1.0200e-04
Validation rmse logD = 0.594439
Validation R2 logD = 0.755267
Validation rmse logP = 0.463802
Validation R2 logP = 0.937568
Epoch 92
Train function
Loss = 5.1272e-04, PNorm = 38.9909, GNorm = 2.6945, lr_0 = 1.0200e-04
Loss = 5.1381e-04, PNorm = 38.9925, GNorm = 1.3264, lr_0 = 1.0200e-04
Loss = 3.5844e-04, PNorm = 38.9938, GNorm = 1.2702, lr_0 = 1.0200e-04
Loss = 3.2508e-04, PNorm = 38.9952, GNorm = 0.8738, lr_0 = 1.0200e-04
Loss = 3.4887e-04, PNorm = 38.9963, GNorm = 1.3351, lr_0 = 1.0200e-04
Loss = 3.5031e-04, PNorm = 38.9978, GNorm = 2.5692, lr_0 = 1.0200e-04
Loss = 4.0088e-04, PNorm = 38.9982, GNorm = 0.9615, lr_0 = 1.0200e-04
Loss = 3.9767e-04, PNorm = 38.9989, GNorm = 1.2696, lr_0 = 1.0200e-04
Loss = 3.7981e-04, PNorm = 38.9997, GNorm = 3.2191, lr_0 = 1.0200e-04
Loss = 4.8871e-04, PNorm = 39.0002, GNorm = 1.6207, lr_0 = 1.0200e-04
Loss = 4.0838e-04, PNorm = 39.0021, GNorm = 1.8575, lr_0 = 1.0200e-04
Loss = 3.1025e-04, PNorm = 39.0037, GNorm = 0.9996, lr_0 = 1.0200e-04
Loss = 3.3353e-04, PNorm = 39.0053, GNorm = 0.6232, lr_0 = 1.0200e-04
Loss = 2.8510e-04, PNorm = 39.0068, GNorm = 1.2034, lr_0 = 1.0200e-04
Loss = 4.4109e-04, PNorm = 39.0076, GNorm = 1.4272, lr_0 = 1.0200e-04
Loss = 4.2228e-04, PNorm = 39.0082, GNorm = 1.6115, lr_0 = 1.0200e-04
Loss = 3.0344e-04, PNorm = 39.0082, GNorm = 0.6362, lr_0 = 1.0200e-04
Loss = 3.1805e-04, PNorm = 39.0098, GNorm = 0.6885, lr_0 = 1.0200e-04
Loss = 3.8064e-04, PNorm = 39.0112, GNorm = 0.9056, lr_0 = 1.0200e-04
Loss = 3.2219e-04, PNorm = 39.0130, GNorm = 1.1443, lr_0 = 1.0200e-04
Loss = 3.8754e-04, PNorm = 39.0145, GNorm = 0.7948, lr_0 = 1.0200e-04
Loss = 3.9340e-04, PNorm = 39.0164, GNorm = 1.0431, lr_0 = 1.0200e-04
Validation rmse logD = 0.578767
Validation R2 logD = 0.768001
Validation rmse logP = 0.465185
Validation R2 logP = 0.937195
Epoch 93
Train function
Loss = 1.6882e-04, PNorm = 39.0175, GNorm = 0.8356, lr_0 = 1.0200e-04
Loss = 4.4257e-04, PNorm = 39.0188, GNorm = 1.2829, lr_0 = 1.0200e-04
Loss = 3.4063e-04, PNorm = 39.0189, GNorm = 1.7650, lr_0 = 1.0200e-04
Loss = 3.6872e-04, PNorm = 39.0195, GNorm = 1.1716, lr_0 = 1.0200e-04
Loss = 3.2385e-04, PNorm = 39.0204, GNorm = 0.9441, lr_0 = 1.0200e-04
Loss = 3.9450e-04, PNorm = 39.0215, GNorm = 2.1476, lr_0 = 1.0200e-04
Loss = 3.5207e-04, PNorm = 39.0220, GNorm = 1.8232, lr_0 = 1.0200e-04
Loss = 3.3439e-04, PNorm = 39.0235, GNorm = 1.9449, lr_0 = 1.0200e-04
Loss = 3.1460e-04, PNorm = 39.0245, GNorm = 1.2701, lr_0 = 1.0200e-04
Loss = 3.0636e-04, PNorm = 39.0265, GNorm = 0.8297, lr_0 = 1.0200e-04
Loss = 3.2738e-04, PNorm = 39.0274, GNorm = 2.7069, lr_0 = 1.0200e-04
Loss = 3.4129e-04, PNorm = 39.0286, GNorm = 1.3455, lr_0 = 1.0200e-04
Loss = 3.1968e-04, PNorm = 39.0302, GNorm = 1.2482, lr_0 = 1.0200e-04
Loss = 3.2117e-04, PNorm = 39.0311, GNorm = 1.0266, lr_0 = 1.0200e-04
Loss = 4.6300e-04, PNorm = 39.0327, GNorm = 1.2814, lr_0 = 1.0200e-04
Loss = 4.1487e-04, PNorm = 39.0341, GNorm = 0.9708, lr_0 = 1.0200e-04
Loss = 3.6816e-04, PNorm = 39.0351, GNorm = 1.7790, lr_0 = 1.0200e-04
Loss = 4.1310e-04, PNorm = 39.0365, GNorm = 2.0445, lr_0 = 1.0200e-04
Loss = 3.7992e-04, PNorm = 39.0377, GNorm = 0.9471, lr_0 = 1.0200e-04
Loss = 3.2357e-04, PNorm = 39.0393, GNorm = 0.8933, lr_0 = 1.0200e-04
Loss = 3.4555e-04, PNorm = 39.0399, GNorm = 0.8273, lr_0 = 1.0200e-04
Loss = 3.0069e-04, PNorm = 39.0406, GNorm = 0.8496, lr_0 = 1.0200e-04
Loss = 3.9924e-04, PNorm = 39.0421, GNorm = 2.2743, lr_0 = 1.0200e-04
Validation rmse logD = 0.604143
Validation R2 logD = 0.747211
Validation rmse logP = 0.478570
Validation R2 logP = 0.933529
Epoch 94
Train function
Loss = 3.9326e-04, PNorm = 39.0427, GNorm = 1.0301, lr_0 = 1.0200e-04
Loss = 4.8181e-04, PNorm = 39.0441, GNorm = 1.0326, lr_0 = 1.0200e-04
Loss = 3.3820e-04, PNorm = 39.0446, GNorm = 0.8538, lr_0 = 1.0200e-04
Loss = 4.1046e-04, PNorm = 39.0460, GNorm = 2.6129, lr_0 = 1.0200e-04
Loss = 3.7252e-04, PNorm = 39.0475, GNorm = 2.3951, lr_0 = 1.0200e-04
Loss = 4.6484e-04, PNorm = 39.0491, GNorm = 2.6486, lr_0 = 1.0200e-04
Loss = 3.9407e-04, PNorm = 39.0509, GNorm = 1.4214, lr_0 = 1.0200e-04
Loss = 3.3545e-04, PNorm = 39.0522, GNorm = 0.9763, lr_0 = 1.0200e-04
Loss = 4.1211e-04, PNorm = 39.0539, GNorm = 0.8483, lr_0 = 1.0200e-04
Loss = 4.3379e-04, PNorm = 39.0562, GNorm = 1.2084, lr_0 = 1.0200e-04
Loss = 3.5427e-04, PNorm = 39.0577, GNorm = 2.2514, lr_0 = 1.0200e-04
Loss = 3.7283e-04, PNorm = 39.0588, GNorm = 1.1034, lr_0 = 1.0200e-04
Loss = 3.0968e-04, PNorm = 39.0600, GNorm = 0.8304, lr_0 = 1.0200e-04
Loss = 2.7589e-04, PNorm = 39.0608, GNorm = 0.7467, lr_0 = 1.0200e-04
Loss = 3.6255e-04, PNorm = 39.0620, GNorm = 1.0250, lr_0 = 1.0200e-04
Loss = 3.7201e-04, PNorm = 39.0629, GNorm = 1.7313, lr_0 = 1.0200e-04
Loss = 4.0498e-04, PNorm = 39.0652, GNorm = 1.1592, lr_0 = 1.0200e-04
Loss = 3.5237e-04, PNorm = 39.0666, GNorm = 1.1964, lr_0 = 1.0200e-04
Loss = 3.5112e-04, PNorm = 39.0687, GNorm = 1.1408, lr_0 = 1.0200e-04
Loss = 4.4100e-04, PNorm = 39.0702, GNorm = 1.2216, lr_0 = 1.0200e-04
Loss = 3.3293e-04, PNorm = 39.0712, GNorm = 0.6742, lr_0 = 1.0200e-04
Loss = 3.6304e-04, PNorm = 39.0724, GNorm = 2.2271, lr_0 = 1.0200e-04
Loss = 3.7405e-04, PNorm = 39.0739, GNorm = 1.2929, lr_0 = 1.0200e-04
Loss = 4.1885e-04, PNorm = 39.0741, GNorm = 1.2077, lr_0 = 1.0200e-04
Validation rmse logD = 0.580759
Validation R2 logD = 0.766402
Validation rmse logP = 0.469211
Validation R2 logP = 0.936103
Epoch 95
Train function
Loss = 3.1967e-04, PNorm = 39.0750, GNorm = 2.3083, lr_0 = 1.0200e-04
Loss = 3.7353e-04, PNorm = 39.0756, GNorm = 1.3707, lr_0 = 1.0200e-04
Loss = 3.1072e-04, PNorm = 39.0759, GNorm = 1.6246, lr_0 = 1.0200e-04
Loss = 3.9593e-04, PNorm = 39.0772, GNorm = 1.3895, lr_0 = 1.0200e-04
Loss = 2.6576e-04, PNorm = 39.0790, GNorm = 1.5957, lr_0 = 1.0200e-04
Loss = 2.8934e-04, PNorm = 39.0798, GNorm = 1.7880, lr_0 = 1.0200e-04
Loss = 2.4388e-04, PNorm = 39.0812, GNorm = 0.6195, lr_0 = 1.0200e-04
Loss = 2.8692e-04, PNorm = 39.0819, GNorm = 0.8015, lr_0 = 1.0200e-04
Loss = 2.9300e-04, PNorm = 39.0827, GNorm = 0.9815, lr_0 = 1.0200e-04
Loss = 3.1785e-04, PNorm = 39.0840, GNorm = 1.1999, lr_0 = 1.0200e-04
Loss = 3.7852e-04, PNorm = 39.0849, GNorm = 1.6562, lr_0 = 1.0200e-04
Loss = 2.7674e-04, PNorm = 39.0863, GNorm = 1.2249, lr_0 = 1.0200e-04
Loss = 2.9313e-04, PNorm = 39.0872, GNorm = 1.5870, lr_0 = 1.0200e-04
Loss = 3.4433e-04, PNorm = 39.0887, GNorm = 0.9951, lr_0 = 1.0200e-04
Loss = 2.8236e-04, PNorm = 39.0897, GNorm = 1.2377, lr_0 = 1.0200e-04
Loss = 2.9052e-04, PNorm = 39.0910, GNorm = 1.0873, lr_0 = 1.0200e-04
Loss = 3.9535e-04, PNorm = 39.0924, GNorm = 0.9733, lr_0 = 1.0200e-04
Loss = 3.3736e-04, PNorm = 39.0934, GNorm = 1.4603, lr_0 = 1.0200e-04
Loss = 3.6403e-04, PNorm = 39.0937, GNorm = 1.1169, lr_0 = 1.0200e-04
Loss = 4.1936e-04, PNorm = 39.0957, GNorm = 2.0731, lr_0 = 1.0200e-04
Loss = 4.2196e-04, PNorm = 39.0972, GNorm = 1.4716, lr_0 = 1.0200e-04
Loss = 3.1647e-04, PNorm = 39.0993, GNorm = 1.2828, lr_0 = 1.0200e-04
Validation rmse logD = 0.578773
Validation R2 logD = 0.767997
Validation rmse logP = 0.470937
Validation R2 logP = 0.935633
Epoch 96
Train function
Loss = 2.5638e-04, PNorm = 39.1012, GNorm = 0.8865, lr_0 = 1.0200e-04
Loss = 3.4362e-04, PNorm = 39.1027, GNorm = 1.4000, lr_0 = 1.0200e-04
Loss = 3.0689e-04, PNorm = 39.1035, GNorm = 0.8237, lr_0 = 1.0200e-04
Loss = 3.2173e-04, PNorm = 39.1043, GNorm = 1.1802, lr_0 = 1.0200e-04
Loss = 3.9541e-04, PNorm = 39.1048, GNorm = 1.4670, lr_0 = 1.0200e-04
Loss = 3.4996e-04, PNorm = 39.1066, GNorm = 0.8927, lr_0 = 1.0200e-04
Loss = 4.4098e-04, PNorm = 39.1078, GNorm = 1.1218, lr_0 = 1.0200e-04
Loss = 3.8377e-04, PNorm = 39.1096, GNorm = 1.6049, lr_0 = 1.0200e-04
Loss = 3.8213e-04, PNorm = 39.1112, GNorm = 0.7986, lr_0 = 1.0200e-04
Loss = 4.4143e-04, PNorm = 39.1124, GNorm = 1.6378, lr_0 = 1.0200e-04
Loss = 3.7116e-04, PNorm = 39.1142, GNorm = 2.6521, lr_0 = 1.0200e-04
Loss = 4.1575e-04, PNorm = 39.1161, GNorm = 1.1382, lr_0 = 1.0200e-04
Loss = 3.1656e-04, PNorm = 39.1177, GNorm = 1.1530, lr_0 = 1.0200e-04
Loss = 3.4685e-04, PNorm = 39.1192, GNorm = 1.3153, lr_0 = 1.0200e-04
Loss = 3.0229e-04, PNorm = 39.1195, GNorm = 1.0679, lr_0 = 1.0200e-04
Loss = 3.0675e-04, PNorm = 39.1201, GNorm = 1.3230, lr_0 = 1.0200e-04
Loss = 3.6946e-04, PNorm = 39.1212, GNorm = 1.9478, lr_0 = 1.0200e-04
Loss = 3.1485e-04, PNorm = 39.1218, GNorm = 1.2309, lr_0 = 1.0200e-04
Loss = 3.5806e-04, PNorm = 39.1226, GNorm = 2.1203, lr_0 = 1.0200e-04
Loss = 3.3329e-04, PNorm = 39.1237, GNorm = 0.7768, lr_0 = 1.0200e-04
Loss = 3.0311e-04, PNorm = 39.1243, GNorm = 0.8292, lr_0 = 1.0200e-04
Loss = 3.2408e-04, PNorm = 39.1251, GNorm = 1.1028, lr_0 = 1.0200e-04
Loss = 2.9738e-04, PNorm = 39.1267, GNorm = 0.7988, lr_0 = 1.0200e-04
Validation rmse logD = 0.574921
Validation R2 logD = 0.771074
Validation rmse logP = 0.471050
Validation R2 logP = 0.935602
Epoch 97
Train function
Loss = 3.1247e-04, PNorm = 39.1282, GNorm = 1.9396, lr_0 = 1.0200e-04
Loss = 2.5396e-04, PNorm = 39.1295, GNorm = 2.2216, lr_0 = 1.0200e-04
Loss = 2.7671e-04, PNorm = 39.1305, GNorm = 0.5542, lr_0 = 1.0200e-04
Loss = 3.4423e-04, PNorm = 39.1314, GNorm = 3.5743, lr_0 = 1.0200e-04
Loss = 3.9658e-04, PNorm = 39.1327, GNorm = 2.8049, lr_0 = 1.0200e-04
Loss = 2.9274e-04, PNorm = 39.1334, GNorm = 1.0634, lr_0 = 1.0200e-04
Loss = 3.3245e-04, PNorm = 39.1347, GNorm = 0.7122, lr_0 = 1.0200e-04
Loss = 2.9517e-04, PNorm = 39.1354, GNorm = 1.3949, lr_0 = 1.0200e-04
Loss = 3.8982e-04, PNorm = 39.1367, GNorm = 0.6496, lr_0 = 1.0200e-04
Loss = 3.8533e-04, PNorm = 39.1382, GNorm = 1.2556, lr_0 = 1.0200e-04
Loss = 3.8749e-04, PNorm = 39.1395, GNorm = 1.0055, lr_0 = 1.0200e-04
Loss = 3.4164e-04, PNorm = 39.1406, GNorm = 1.5416, lr_0 = 1.0200e-04
Loss = 3.4843e-04, PNorm = 39.1410, GNorm = 2.3848, lr_0 = 1.0200e-04
Loss = 3.8528e-04, PNorm = 39.1416, GNorm = 0.7784, lr_0 = 1.0200e-04
Loss = 3.5367e-04, PNorm = 39.1431, GNorm = 1.9809, lr_0 = 1.0200e-04
Loss = 2.6700e-04, PNorm = 39.1452, GNorm = 0.6449, lr_0 = 1.0200e-04
Loss = 2.4300e-04, PNorm = 39.1468, GNorm = 1.0406, lr_0 = 1.0200e-04
Loss = 3.0919e-04, PNorm = 39.1489, GNorm = 1.0598, lr_0 = 1.0200e-04
Loss = 3.5836e-04, PNorm = 39.1502, GNorm = 1.7587, lr_0 = 1.0200e-04
Loss = 5.1032e-04, PNorm = 39.1507, GNorm = 0.8509, lr_0 = 1.0200e-04
Loss = 3.8750e-04, PNorm = 39.1529, GNorm = 1.3275, lr_0 = 1.0200e-04
Loss = 3.9577e-04, PNorm = 39.1540, GNorm = 1.7847, lr_0 = 1.0200e-04
Validation rmse logD = 0.583323
Validation R2 logD = 0.764335
Validation rmse logP = 0.472038
Validation R2 logP = 0.935331
Epoch 98
Train function
Loss = 3.1407e-04, PNorm = 39.1549, GNorm = 0.7713, lr_0 = 1.0200e-04
Loss = 3.3748e-04, PNorm = 39.1556, GNorm = 1.4363, lr_0 = 1.0200e-04
Loss = 3.1438e-04, PNorm = 39.1566, GNorm = 0.8065, lr_0 = 1.0200e-04
Loss = 2.7043e-04, PNorm = 39.1577, GNorm = 1.6541, lr_0 = 1.0200e-04
Loss = 2.8176e-04, PNorm = 39.1591, GNorm = 0.9610, lr_0 = 1.0200e-04
Loss = 2.7892e-04, PNorm = 39.1603, GNorm = 1.8479, lr_0 = 1.0200e-04
Loss = 3.1155e-04, PNorm = 39.1616, GNorm = 2.2094, lr_0 = 1.0200e-04
Loss = 2.9569e-04, PNorm = 39.1623, GNorm = 0.4760, lr_0 = 1.0200e-04
Loss = 3.5463e-04, PNorm = 39.1635, GNorm = 1.3199, lr_0 = 1.0200e-04
Loss = 3.6811e-04, PNorm = 39.1650, GNorm = 2.1118, lr_0 = 1.0200e-04
Loss = 3.9095e-04, PNorm = 39.1666, GNorm = 2.7505, lr_0 = 1.0200e-04
Loss = 3.9995e-04, PNorm = 39.1682, GNorm = 3.0805, lr_0 = 1.0200e-04
Loss = 4.3053e-04, PNorm = 39.1690, GNorm = 2.4887, lr_0 = 1.0200e-04
Loss = 3.6494e-04, PNorm = 39.1697, GNorm = 0.7169, lr_0 = 1.0200e-04
Loss = 3.0494e-04, PNorm = 39.1708, GNorm = 1.5250, lr_0 = 1.0200e-04
Loss = 3.6563e-04, PNorm = 39.1723, GNorm = 2.6865, lr_0 = 1.0200e-04
Loss = 3.5206e-04, PNorm = 39.1734, GNorm = 1.5085, lr_0 = 1.0200e-04
Loss = 2.8255e-04, PNorm = 39.1743, GNorm = 2.3956, lr_0 = 1.0200e-04
Loss = 3.1096e-04, PNorm = 39.1755, GNorm = 1.4566, lr_0 = 1.0200e-04
Loss = 2.8161e-04, PNorm = 39.1776, GNorm = 1.0716, lr_0 = 1.0200e-04
Loss = 3.0919e-04, PNorm = 39.1780, GNorm = 0.9548, lr_0 = 1.0200e-04
Loss = 3.4021e-04, PNorm = 39.1786, GNorm = 2.1992, lr_0 = 1.0200e-04
Loss = 3.1811e-04, PNorm = 39.1794, GNorm = 1.7540, lr_0 = 1.0200e-04
Validation rmse logD = 0.579109
Validation R2 logD = 0.767728
Validation rmse logP = 0.469594
Validation R2 logP = 0.935999
Epoch 99
Train function
Loss = 2.4407e-04, PNorm = 39.1804, GNorm = 1.6228, lr_0 = 1.0200e-04
Loss = 3.6059e-04, PNorm = 39.1807, GNorm = 0.7960, lr_0 = 1.0200e-04
Loss = 2.8019e-04, PNorm = 39.1812, GNorm = 0.7330, lr_0 = 1.0200e-04
Loss = 2.8067e-04, PNorm = 39.1825, GNorm = 1.6261, lr_0 = 1.0200e-04
Loss = 3.2468e-04, PNorm = 39.1840, GNorm = 1.1263, lr_0 = 1.0200e-04
Loss = 3.3949e-04, PNorm = 39.1861, GNorm = 1.5697, lr_0 = 1.0200e-04
Loss = 3.3200e-04, PNorm = 39.1880, GNorm = 1.8042, lr_0 = 1.0200e-04
Loss = 4.7937e-04, PNorm = 39.1892, GNorm = 2.6683, lr_0 = 1.0200e-04
Loss = 3.0916e-04, PNorm = 39.1913, GNorm = 2.5503, lr_0 = 1.0200e-04
Loss = 3.1525e-04, PNorm = 39.1915, GNorm = 1.4669, lr_0 = 1.0200e-04
Loss = 3.0333e-04, PNorm = 39.1929, GNorm = 0.9820, lr_0 = 1.0200e-04
Loss = 2.9809e-04, PNorm = 39.1941, GNorm = 1.1758, lr_0 = 1.0200e-04
Loss = 2.7814e-04, PNorm = 39.1952, GNorm = 1.2023, lr_0 = 1.0200e-04
Loss = 2.7009e-04, PNorm = 39.1969, GNorm = 0.7786, lr_0 = 1.0200e-04
Loss = 3.4912e-04, PNorm = 39.1984, GNorm = 2.7840, lr_0 = 1.0200e-04
Loss = 3.2715e-04, PNorm = 39.1990, GNorm = 2.5836, lr_0 = 1.0200e-04
Loss = 4.3358e-04, PNorm = 39.1997, GNorm = 1.1659, lr_0 = 1.0200e-04
Loss = 4.8595e-04, PNorm = 39.2003, GNorm = 2.4383, lr_0 = 1.0200e-04
Loss = 4.2347e-04, PNorm = 39.2004, GNorm = 1.1837, lr_0 = 1.0200e-04
Loss = 3.6024e-04, PNorm = 39.2015, GNorm = 1.5178, lr_0 = 1.0200e-04
Loss = 3.6277e-04, PNorm = 39.2031, GNorm = 1.4121, lr_0 = 1.0200e-04
Loss = 3.0477e-04, PNorm = 39.2034, GNorm = 0.8874, lr_0 = 1.0200e-04
Validation rmse logD = 0.578138
Validation R2 logD = 0.768505
Validation rmse logP = 0.466261
Validation R2 logP = 0.936904
Model 0 best validation rmse = 0.521976 on epoch 92
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Moving model to cuda
Model 0 test rmse logD = 0.572709
Model 0 test R2 logD = 0.791972
Model 0 test rmse logP = 0.440423
Model 0 test R2 logP = 0.944286
Ensemble test rmse  logD= 0.572709
Ensemble test R2  logD= 0.791972
Ensemble test rmse  logP= 0.440423
Ensemble test R2  logP= 0.944286
4-fold cross validation
	Seed 0 ==> test rmse = 0.512399
	Seed 0 ==> test R2 = 0.864215
	Seed 1 ==> test rmse = 0.515435
	Seed 1 ==> test R2 = 0.865194
	Seed 2 ==> test rmse = 0.507487
	Seed 2 ==> test R2 = 0.871164
	Seed 3 ==> test rmse = 0.506566
	Seed 3 ==> test R2 = 0.868129
Overall val rmse logD= 0.578357 +/- 0.023756
Overall val R2 logD = 0.763003 +/- 0.019155
Overall test rmse logD = 0.572385 +/- 0.008846
Overall test R2 logD = 0.792157 +/- 0.006396
Overall val rmse logP= 0.464991 +/- 0.007498
Overall val R2 logP = 0.937906 +/- 0.002647
Overall test rmse logP = 0.448558 +/- 0.007412
Overall test R2 logP = 0.942193 +/- 0.001910
Elapsed time = 4:19:58
